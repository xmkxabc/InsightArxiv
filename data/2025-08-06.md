# AI-Enhanced arXiv Daily 2025-08-06

<a id='toc'></a>
## 今日总计: 979 篇论文
### 目录
- [cs.AI](#csai) (78 篇)
- [cs.AR](#csar) (4 篇)
- [cs.CE](#csce) (6 篇)
- [cs.CL](#cscl) (94 篇)
- [cs.CR](#cscr) (28 篇)
- [cs.CV](#cscv) (219 篇)
- [cs.CY](#cscy) (13 篇)
- [cs.DB](#csdb) (5 篇)
- [cs.DC](#csdc) (9 篇)
- [cs.DL](#csdl) (3 篇)
- [cs.DM](#csdm) (2 篇)
- [cs.DS](#csds) (5 篇)
- [cs.ET](#cset) (2 篇)
- [cs.FL](#csfl) (5 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.GT](#csgt) (2 篇)
- [cs.HC](#cshc) (29 篇)
- [cs.IR](#csir) (16 篇)
- [cs.IT](#csit) (11 篇)
- [cs.LG](#cslg) (152 篇)
- [cs.LO](#cslo) (6 篇)
- [cs.MA](#csma) (5 篇)
- [cs.MM](#csmm) (2 篇)
- [cs.NE](#csne) (2 篇)
- [cs.NI](#csni) (13 篇)
- [cs.OS](#csos) (2 篇)
- [cs.PF](#cspf) (1 篇)
- [cs.PL](#cspl) (3 篇)
- [cs.RO](#csro) (49 篇)
- [cs.SD](#cssd) (11 篇)
- [cs.SE](#csse) (27 篇)
- [cs.SI](#cssi) (4 篇)
- [eess.AS](#eessas) (6 篇)
- [eess.IV](#eessiv) (16 篇)
- [eess.SP](#eesssp) (30 篇)
- [eess.SY](#eesssy) (14 篇)
- [math.NA](#mathna) (30 篇)
- [stat.AP](#statap) (5 篇)
- [q-fin.MF](#q-finmf) (2 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (6 篇)
- [stat.ML](#statml) (8 篇)
- [quant-ph](#quant-ph) (7 篇)
- [math.OC](#mathoc) (9 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [q-bio.GN](#q-biogn) (1 篇)
- [math.LO](#mathlo) (2 篇)
- [physics.hist-ph](#physicshist-ph) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [stat.ME](#statme) (4 篇)
- [econ.TH](#econth) (1 篇)
- [astro-ph.IM](#astro-phim) (2 篇)
- [math.CO](#mathco) (4 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [math.ST](#mathst) (1 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [physics.med-ph](#physicsmed-ph) (2 篇)
- [q-bio.PE](#q-biope) (1 篇)
- [cond-mat.stat-mech](#cond-matstat-mech) (1 篇)
- [astro-ph.EP](#astro-phep) (1 篇)
- [math.DS](#mathds) (1 篇)
- [q-fin.ST](#q-finst) (5 篇)
- [physics.flu-dyn](#physicsflu-dyn) (1 篇)
- [physics.bio-ph](#physicsbio-ph) (1 篇)

---
<a id='csai'></a>
## cs.AI 

### [1] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
> *Geoint-R1: 形式化多模态几何推理与动态辅助构造*

*Jingxuan Wei, Caijun Jia, Qi Chen, Honghao He, Linzhuang Sun, Conghui He, Lijun Wu, Bihui Yu, Cheng Tan* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 几何推理, 多模态, 辅助构造, 形式化验证, Lean4

**Comment:** 

> **TL;DR:** Geoint-R1是一个多模态几何推理框架，能通过动态辅助构造生成可形式化验证的几何解，并在新基准上超越现有模型。

**AI_Comments:** Geoint-R1的创新之处在于其将动态辅助构造与形式化推理（通过Lean4）相结合，这对于解决复杂几何问题至关重要。同时，提出的Geoint基准为该领域的研究提供了宝贵的资源，有助于推动形式化几何推理的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大型语言模型在形式化几何推理，尤其是在动态构造和验证辅助几何元素方面表现不佳。

**Method:** 本文提出了Geoint-R1框架，它独特地整合了辅助元素构造、通过Lean4表示的形式化推理以及交互式可视化。同时，为了系统评估和推进形式化几何推理，作者提出了Geoint基准，包含1,885个严格标注的几何问题，涵盖平面、空间和立体几何等主题。

**Result:** 广泛的实验表明，Geoint-R1显著超越了现有的多模态和数学专用推理模型，尤其是在需要明确辅助元素构造的挑战性问题上。

**Conclusion:** Geoint-R1通过其独特的方法有效解决了形式化几何推理中动态辅助构造的挑战，并为该领域设定了新的基准。

> **ai_Abstract:** 本文介绍了Geoint-R1，一个旨在解决多模态大语言模型在形式化几何推理，特别是动态辅助构造方面不足的框架。Geoint-R1结合了辅助元素构造、基于Lean4的形式化推理和交互式可视化。为评估此领域，作者还提出了包含1,885个几何问题的Geoint基准。实验证明Geoint-R1在需要辅助构造的复杂几何问题上优于现有模型。

> **摘要翻译:** 数学几何推理对于科学发现和教育发展至关重要，它需要精确的逻辑和严格的形式验证。尽管多模态大型语言模型（MLLMs）的最新进展改进了推理任务，但现有模型通常难以进行形式化几何推理，特别是在动态构造和验证辅助几何元素时。为了应对这些挑战，我们引入了Geoint-R1，一个多模态推理框架，旨在从文本描述和视觉图表生成可形式化验证的几何解决方案。Geoint-R1独特地整合了辅助元素构造、通过Lean4表示的形式化推理以及交互式可视化。为了系统地评估和推进形式化几何推理，我们提出了Geoint基准，包括1,885个经过严格标注的几何问题，涵盖平面几何、空间几何和立体几何等不同主题。每个问题都包含结构化的文本注释、精确的用于辅助构造的Lean4代码以及专家验证的详细解题步骤。广泛的实验表明，Geoint-R1显著超越了现有的多模态和数学专用推理模型，尤其是在需要明确辅助元素构造的挑战性问题上。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [25] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
> *InqEduAgent：基于高斯过程增强的自适应AI学习伙伴*

*Tian-Fang Zhao, Wen-Xi Yang* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** AI学习伙伴, 高斯过程, 大型语言模型, 探究式学习, 自适应匹配

**Comment:** 

> **TL;DR:** InqEduAgent是一个基于LLM的AI学习伙伴模型，利用高斯过程增强的自适应匹配算法，为探究式学习提供个性化伙伴，实验证明其在多数知识学习场景下表现优异。

**AI_Comments:** InqEduAgent的创新之处在于结合了LLM的强大能力和高斯过程的自适应匹配算法，解决了传统学习伙伴选择中灵活性和知识扩展的不足。其应用前景广阔，可以有效提升探究式学习的效率和个性化水平。该研究的贡献在于为智能教育领域提供了一个新的AI学习伙伴解决方案，并强调了将AI与教育实践深度融合的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在探究式教育中，协作伙伴关系至关重要。然而，大多数学习伙伴的选择要么依赖经验分配，缺乏科学规划，要么基于规则的机器助手，存在知识扩展困难和灵活性不足的问题。

**Method:** 该论文提出了一个名为InqEduAgent的LLM赋能的代理模型，用于模拟和选择适合探究式学习的学习伙伴。通过设计生成式代理来捕获学习者在真实场景中的认知和评估特征。然后，制定了一种带有高斯过程增强的自适应匹配算法，以识别先验知识中的模式，并为面临不同练习的学习者提供最优的学习伙伴匹配。

**Result:** 实验结果表明，InqEduAgent在大多数知识学习场景和不同能力水平的LLM环境中都表现出最佳性能。

**Conclusion:** 这项研究促进了基于人类的学习伙伴的智能分配和基于AI的学习伙伴的制定。

> **ai_Abstract:** InqEduAgent提出了一种基于大型语言模型（LLM）的AI代理模型，旨在解决探究式教育中学习伙伴选择的局限性。该模型通过生成式代理模拟学习者的认知和评估特征，并利用高斯过程增强的自适应匹配算法为学习者提供最优的学习伙伴。实验证明InqEduAgent在各种知识学习场景和LLM环境下均表现出色，为智能学习伙伴的分配和开发提供了新方向。

> **摘要翻译:** 探究式教育中的协作伙伴关系至关重要。然而，大多数学习伙伴的选择要么依赖经验分配，缺乏科学规划，要么基于规则的机器助手，存在知识扩展困难和灵活性不足的问题。本文提出了一个由大型语言模型（LLM）驱动的代理模型，用于模拟和选择适合探究式学习的学习伙伴，命名为InqEduAgent。生成式代理旨在捕获学习者在真实场景中的认知和评估特征。然后，制定了一种带有高斯过程增强的自适应匹配算法，以识别先验知识中的模式。为面临不同练习的学习者提供了最优的学习伙伴匹配。实验结果表明，InqEduAgent在大多数知识学习场景和不同能力水平的LLM环境中都表现出最佳性能。这项研究促进了基于人类的学习伙伴的智能分配和基于AI的学习伙伴的制定。代码、数据和附录可在https://github.com/InqEduAgent/InqEduAgent公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [41] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
> *智能家居中基于语义感知图引导的行为序列生成与大型语言模型*

*Zhiyao Xu, Dan Zhao, Qingsong Zou, Qing Li, Yong Jiang, Yuhang Wang, Jingyu Xiao* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 智能家居, 行为序列生成, 大型语言模型, 行为漂移, 数据增强

**Comment:** 

> **TL;DR:** SmartGen是一个基于LLM的框架，用于生成智能家居用户行为数据，以解决行为漂移问题并支持下游模型的持续适应。

**AI_Comments:** 本文的创新点在于利用LLM结合图结构信息生成高质量的智能家居行为数据，以应对行为漂移问题，这为数据稀缺或难以更新的领域提供了一种有效的解决方案。其方法论结合了语义理解、序列处理和图结构引导，确保了生成数据的有效性和连贯性。

<details>
  <summary>Details</summary>

**Motivation:** 智能家居模型在静态数据集上训练，但行为漂移（如季节变化、生活方式转变）导致性能下降。重新收集新行为数据成本高、耗时且涉及隐私问题，因此不切实际。

**Method:** 提出SmartGen框架，包含四个关键组件：1. 时间与语义感知分割模块，将长序列划分为语义连贯的子序列。2. 语义感知序列压缩，通过聚类减少输入长度并保留语义。3. 图引导序列合成，构建行为关系图并编码频繁转换到LLM提示中，以生成与上下文一致的数据。4. 两阶段异常值过滤器，识别并移除不合理或语义不一致的生成序列。

**Result:** 在三个真实世界数据集上的实验表明，SmartGen显著提升了行为漂移下异常检测和行为预测任务的模型性能，其中异常检测平均提升85.43%，行为预测平均提升70.51%。

**Conclusion:** SmartGen框架通过合成上下文感知的用户行为数据，有效解决了智能家居模型在行为漂移下的持续适应性问题，显著提升了下游模型的性能。

> **ai_Abstract:** 本文提出了SmartGen，一个基于大型语言模型（LLM）的框架，旨在解决智能家居模型因行为漂移而导致的性能下降问题。SmartGen通过时间与语义感知分割、语义感知序列压缩、图引导序列合成以及两阶段异常值过滤器等组件，生成上下文感知的用户行为数据。实验证明，该框架能显著提升智能家居模型在异常检测和行为预测任务上的性能，有效支持模型的持续适应性。

> **摘要翻译:** 随着智能家居日益普及，智能模型被广泛应用于异常检测和行为预测等任务。这些模型通常在静态数据集上训练，但由于季节变化、生活方式转变或日常习惯演变导致的行为漂移，模型变得脆弱。然而，由于收集新行为数据速度慢、成本高且存在隐私问题，重新训练通常不切实际。在本文中，我们提出了SmartGen，一个基于大型语言模型（LLM）的框架，用于合成上下文感知的用户行为数据，以支持下游智能家居模型的持续适应。SmartGen由四个关键组件组成。首先，我们设计了一个时间与语义感知分割模块，在双重时间跨度约束下，将长行为序列划分为可管理、语义连贯的子序列。其次，我们提出了语义感知序列压缩，通过在潜在空间中对行为映射进行聚类，在保留代表性语义的同时减少输入长度。第三，我们引入了图引导序列合成，它构建了一个行为关系图并将频繁的转换编码到提示中，引导LLM生成与上下文变化一致的数据，同时保留核心行为模式。最后，我们设计了一个两阶段异常值过滤器，用于识别和删除不合理或语义不一致的输出，旨在提高生成序列的事实连贯性和行为有效性。在三个真实世界数据集上的实验表明，SmartGen显著增强了行为漂移下异常检测和行为预测任务的模型性能，其中异常检测平均提高了85.43%，行为预测平均提高了70.51%。代码可在https://github.com/horizonsinzqs/SmartGen获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [49] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
> *具有边类型解耦网络的全历史图用于时间推理*

*Osama Mohammed, Jiaxin Pan, Mojtaba Nayyeri, Daniel Hernández, Steffen Staab* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 全历史图, 边类型解耦网络, 时间推理, 动态图, 图神经网络

**Comment:** European Conference of Artificial Intelligence 2025

> **TL;DR:** 该研究引入了一种全历史图表示和边类型解耦网络（ETDNet），用于对实体间演化交互进行时间推理，并在驾驶员意图预测和比特币欺诈检测任务上取得了显著优于基线的性能。

**AI_Comments:** 该论文的创新点在于提出了“全历史图”这一新颖的时间图表示，以及专门为其设计的“边类型解耦网络（ETDNet）”。通过将时间步内关系和时间步间关系解耦为不同的边类型，并使用专门的注意力机制分别处理，ETDNet能够更有效地捕捉复杂的时间演化和结构依赖。其在实际应用（如自动驾驶和金融欺诈检测）中的显著性能提升，凸显了该方法在处理动态图数据方面的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在许多现实世界任务中，建模实体之间演化交互至关重要，例如预测交通中的驾驶员机动和检测金融欺诈。现有时间图方法通常使用快照图来编码时间演化，但这无法明确表示关系及其演变。

**Method:** 本文引入了一种全历史图，该图为每个时间步的每个实体实例化一个节点，并分离两组边：(i) 时间步内边（捕获单个帧内的关系）和 (ii) 时间步间边（连接实体在连续时间步的自身）。为了在该图上学习，设计了一个边类型解耦网络（ETDNet），它包含并行模块：一个图注意力模块沿时间步内边聚合信息，一个多头时间注意力模块关注实体的时间步间历史，以及一个融合模块在每层之后组合这两种消息。

**Result:** ETDNet在驾驶员意图预测（Waymo）和比特币欺诈检测（Elliptic++）任务上持续超越强基线。Waymo联合准确率提升至75.6%（对比74.1%），Elliptic++非法类F1值提升至88.1%（对比60.4%）。

**Conclusion:** 将结构关系和时间关系表示为单个图中的不同边，对时间推理任务具有显著优势。

> **ai_Abstract:** 该论文提出了一种新的全历史图（Full-History Graph）表示方法，用于处理需要对实体间演化交互进行推理的现实世界任务，例如驾驶员意图预测和金融欺诈检测。与传统的时间图快照方法不同，全历史图为每个时间步的每个实体创建一个节点，并区分时间步内边（结构关系）和时间步间边（时间演化）。为了在这种图上进行学习，作者设计了一个边类型解耦网络（ETDNet），该网络包含并行的图注意力模块和多头时间注意力模块，以及一个融合模块。实验结果表明，ETDNet在Waymo和Elliptic++数据集上均显著优于现有基线，证明了将结构和时间关系作为独立边在单一图中表示的有效性。

> **摘要翻译:** 在许多现实世界任务中，建模实体之间演化交互至关重要。例如，预测交通中的驾驶员机动需要追踪相邻车辆在连续帧中如何相互加速、制动和变道。同样，检测金融欺诈取决于资金流如何通过连续交易在网络中传播。与经典时间序列预测不同，这些设置要求对谁何时与谁交互进行推理，这需要一种时间图表示，使关系及其演化都明确。现有时间图方法通常使用快照图来编码时间演化。我们引入了一种全历史图，该图为每个时间步的每个实体实例化一个节点，并分离两组边：(i) 时间步内边，捕获单个帧内的关系；(ii) 时间步间边，连接实体在连续时间步的自身。为了在该图上学习，我们设计了一个边类型解耦网络（ETDNet），它包含并行模块：一个图注意力模块沿时间步内边聚合信息，一个多头时间注意力模块关注实体的时间步间历史，以及一个融合模块在每层之后组合这两种消息。在驾驶员意图预测（Waymo）和比特币欺诈检测（Elliptic++）上进行评估，ETDNet持续超越强基线，将Waymo联合准确率提升至75.6%（对比74.1%），并将Elliptic++非法类F1值提升至88.1%（对比60.4%）。这些增益证明了在单个图中将结构关系和时间关系表示为不同边的优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [73] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
> *ToolVQA：一个用于多步推理VQA的外部工具数据集*

*Shaofeng Yin, Ting Lei, Yang Liu* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** ToolVQA, 多步推理, VQA, 外部工具, 大型基础模型

**Comment:** 

> **TL;DR:** ToolVQA是一个新的大规模多模态数据集，旨在弥补现有工具增强型VQA在多步推理和真实世界工具使用方面的差距，并展示了在真实场景中的强大泛化能力。

**AI_Comments:** ToolVQA的创新之处在于其专注于真实世界的多步推理和多模态工具使用，这与现有数据集的合成场景和简化查询形成对比。通过引入ToolEngine模拟人类推理过程来生成高质量数据，极大地提升了数据集的实用性和模型的泛化能力。这项工作对于推动大型基础模型在复杂现实世界问题解决能力方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有工具增强型VQA研究在真实世界工具使用熟练度方面存在显著差距，尤其是在需要多步推理的功能多样化多模态设置中。本工作旨在弥补这一差距。

**Method:** 引入了ToolVQA，一个包含23K实例的大规模多模态数据集。提出了ToolEngine，一个使用深度优先搜索（DFS）和动态上下文示例匹配机制的数据生成管道，以模拟人类般的工具使用推理。ToolVQA包含10种多模态工具，跨越7个不同的任务领域，平均每个实例有2.78个推理步骤。

**Result:** 在ToolVQA上微调的7B大型基础模型（LFMs）在测试集上取得了令人印象深刻的性能，并且在各种分布外（OOD）数据集上超越了大型闭源模型GPT-3.5-turbo。

**Conclusion:** ToolVQA展示了强大的泛化能力，适用于真实世界的工具使用场景，有效增强了大型基础模型的解决问题能力。

> **ai_Abstract:** 本研究介绍了ToolVQA，一个大规模多模态数据集，旨在解决现有工具增强型视觉问答（VQA）在多步推理和真实世界工具使用方面的不足。与以往数据集不同，ToolVQA包含真实的视觉上下文和具有挑战性的隐式多步推理任务。为构建该数据集，作者提出了ToolEngine数据生成管道，该管道通过模拟人类的工具使用推理过程来生成数据。ToolVQA涵盖10种多模态工具和7个任务领域。实验结果表明，在ToolVQA上微调的7B大型基础模型不仅表现出色，还在分布外数据集上超越了GPT-3.5-turbo，证明了其在真实世界工具使用场景中的强大泛化能力。

> **摘要翻译:** 将外部工具集成到大型基础模型（LFMs）中已成为一种有前途的方法，可以增强其解决问题的能力。尽管现有研究在工具增强型视觉问答（VQA）中表现出强大的性能，但最近的基准测试揭示了在真实世界工具使用熟练度方面存在显著差距，特别是在需要多步推理的功能多样化多模态设置中。在本工作中，我们介绍了ToolVQA，一个包含23K实例的大规模多模态数据集，旨在弥合这一差距。与以往依赖合成场景和简化查询的数据集不同，ToolVQA具有真实的视觉上下文和具有挑战性的隐式多步推理任务，更好地与真实用户交互对齐。为了构建这个数据集，我们提出了ToolEngine，一个新颖的数据生成管道，它采用深度优先搜索（DFS）和动态上下文示例匹配机制来模拟人类般的工具使用推理。ToolVQA包含10种多模态工具，跨越7个不同的任务领域，平均每个实例有2.78个推理步骤。在ToolVQA上微调的7B大型基础模型不仅在我们的测试集上取得了令人印象深刻的性能，而且在各种分布外（OOD）数据集上超越了大型闭源模型GPT-3.5-turbo，展示了对真实世界工具使用场景的强大泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [90] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
> *VQA支持阿拉伯语学习教育工具*

*Khaled Bachir Delassi, Lakhdar Zeggane, Hadda Cherroun, Abdelhamid Haouhat, Kaoutar Bouzouad* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 阿拉伯语学习, 视觉问答, 人工智能, 教育工具, 主动学习

**Comment:** 

> **TL;DR:** 本文开发并评估了一个AI驱动的阿拉伯语学习工具，该工具利用视觉问答（VQA）和先进的AI模型为非母语学习者提供互动式视觉测验，旨在解决现有工具稀缺问题并促进主动学习，实验结果验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于将VQA技术应用于阿拉伯语学习，通过AI生成个性化和互动式的视觉测验，弥补了该领域现有工具的不足。其采用建构主义和主动学习模式，结合了先进的视觉-语言模型和大型语言模型，为非母语学习者提供了沉浸式的学习体验。该研究的重要性在于为阿拉伯语学习提供了一个有效且现代化、特别是视觉辅助学习的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决阿拉伯语学习教育工具稀缺的问题，特别是缺乏支持主动学习等现代教学模式的工具，以确保语言熟练度。

**Method:** 设计并评估一个由AI驱动的教育工具，旨在增强非母语初级到中级水平学习者的阿拉伯语学习。该工具利用先进的AI模型，以视觉问答（VQA）为主要活动，生成互动式视觉测验。它采用建构主义学习方法，通过真实生活视觉测验和基于图像的问题鼓励主动学习，重点提升词汇、语法和理解能力。系统整合视觉-语言预训练模型生成图像描述，并利用大型语言模型（LLM）基于定制测验生成作业。通过包含1266个真实生活视觉测验的手动标注基准进行工具有效性评估，并收集人类参与者的反馈。

**Result:** 评估结果显示了“合适的准确率”，验证了该工具弥合阿拉伯语教育差距的潜力。

**Conclusion:** 该工具作为可靠的、AI驱动的阿拉伯语学习资源具有前景，能够提供个性化和互动式的学习体验。

> **ai_Abstract:** 本文针对阿拉伯语学习工具稀缺且缺乏支持现代教学模式的问题，设计并评估了一个AI驱动的教育工具。该工具利用视觉问答（VQA）、视觉-语言预训练模型和大型语言模型，生成互动式真实生活视觉测验，旨在提高非母语学习者的词汇、语法和理解能力。通过人类参与者在1266个视觉测验上的评估显示，该工具具有合适的准确率，证明其在阿拉伯语教育中的潜力和作为可靠AI学习资源的价值。

> **摘要翻译:** 我们解决了阿拉伯语学习教育工具稀缺的问题，这些工具提倡主动学习等现代教学模式，以确保语言熟练度。事实上，我们研究了设计和评估一个由人工智能驱动的教育工具，该工具旨在增强非母语初级到中级水平学习者的阿拉伯语学习。该工具利用先进的AI模型生成互动式视觉测验，将视觉问答作为主要活动。系统采用建构主义学习方法，通过真实生活视觉测验和基于图像的问题鼓励主动学习，这些问题侧重于提高词汇、语法和理解能力。系统整合了视觉-语言预训练模型，从图像中生成与上下文相关的描述，然后大型语言模型通过提示生成基于定制阿拉伯语学习测验的作业。该工具的有效性通过一个包含1266个真实生活视觉测验的手动标注基准进行评估，并收集了人类参与者的反馈。结果显示了合适的准确率，验证了该工具弥合阿拉伯语教育差距的潜力，并突出了该工具作为阿拉伯语学习者可靠的、由人工智能驱动的资源的前景，它提供了个性化和互动式的学习体验。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [108] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
> *Nemori：受认知科学启发的自组织智能体记忆*

*Jiayan Nan, Wenquan Ma, Wenlong Wu, Yize Chen* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 自组织记忆, 智能体记忆, 认知科学, 大型语言模型, 长期交互

**Comment:** 

> **TL;DR:** LLMs在长期交互中缺乏持久记忆。Nemori提出一种受认知科学启发的自组织记忆架构，通过“两步对齐”和“预测-校准”原则，解决了记忆粒度和知识演化问题，并在长上下文基准测试中表现优异。

**AI_Comments:** Nemori的创新之处在于其将认知科学原理（如事件分割理论和自由能原理）融入到LLM的记忆架构设计中，解决了传统记忆系统在记忆粒度定义和知识演化方面的核心局限。其自组织和主动学习的特性为构建更智能、更适应长期交互的自主智能体提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在长上下文交互中无法维持持久记忆，且现有记忆系统依赖任意粒度定义记忆单元，并采用被动、基于规则的知识提取机制，限制了其真正的学习和演化能力。

**Method:** 本文提出了Nemori，一种受人类认知原理启发的自组织记忆架构。其核心创新有两点：一是“两步对齐原则”，受事件分割理论启发，提供自上而下的方法将对话流组织成语义连贯的事件片段，解决记忆粒度问题；二是“预测-校准原则”，受自由能原理启发，使智能体能主动从预测偏差中学习，实现自适应知识演化。

**Result:** 在LoCoMo和LongMemEval基准测试中，Nemori显著优于现有最先进系统，尤其在更长的上下文中优势更为明显。

**Conclusion:** Nemori为处理自主智能体的长期、动态工作流提供了一条可行路径。

> **ai_Abstract:** 本文提出了Nemori，一种受认知科学启发的自组织记忆架构，旨在解决大型语言模型在长期交互中缺乏持久记忆和知识演化能力的问题。Nemori引入“两步对齐原则”来解决记忆粒度问题，并通过“预测-校准原则”实现知识的自适应演化。实验结果表明，Nemori在长上下文基准测试中显著优于现有技术。

> **摘要翻译:** 大型语言模型（LLM）展现出卓越的能力，但它们在长上下文中无法维持持久记忆，限制了其作为自主智能体在长期交互中的有效性。尽管现有记忆系统已取得进展，但它们依赖任意粒度来定义基本记忆单元，以及被动的、基于规则的知识提取机制，限制了其真正学习和演化能力。为解决这些基本局限性，我们提出了Nemori，一种受人类认知原理启发的全新自组织记忆架构。Nemori的核心创新是双重的：首先，其受事件分割理论启发的“两步对齐原则”提供了一种原则性的、自上而下的方法，能自主地将原始对话流组织成语义连贯的事件片段，解决了记忆粒度的关键问题。其次，其受自由能原理启发的“预测-校准原则”使智能体能够主动从预测偏差中学习，超越预定义的启发式规则，实现自适应知识演化。这为处理自主智能体的长期、动态工作流提供了一条可行路径。在LoCoMo和LongMemEval基准测试中，广泛的实验表明Nemori显著优于现有最先进系统，尤其在更长的上下文中其优势更为突出。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [138] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
> *大型语言模型中可解释数学的错误检测与校正*

*Yijin Yang, Cristina Cornelio, Mario Leiva, Paulo Shakarian* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 错误检测, 错误校正, 可解释数学, 符号推理

**Comment:** 

> **TL;DR:** 针对大型语言模型在可解释数学任务中产生的错误，本文提出EDCIM方法，通过符号错误检测和LLM反馈校正，显著降低成本并保持或提升准确性。

**AI_Comments:** 本文提出的EDCIM方法创新性地结合了LLM的生成能力和符号推理的精确性，有效解决了LLM在复杂数学推理中易出错的问题。通过引入符号错误检测和反馈机制，实现了对模型输出的精确校正。此外，其混合使用开源和专有LLM的策略，为实际应用提供了成本效益的解决方案，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多步推理中常出现中间步骤错误导致最终预测不准确；LLMs还存在幻觉问题，难以遵循预设输出格式，尤其在生成数学表达式或源代码时。

**Method:** 本文提出EDCIM（可解释数学错误检测与校正）方法。它利用LLM生成给定问题的方程组，然后使用符号错误检测框架识别错误并提供针对LLM的反馈进行校正。为提高效率，EDCIM结合了轻量级开源LLM和更强大的专有模型，并通过单一超参数平衡成本和准确性。

**Result:** 实验结果表明，EDCIM显著降低了计算和财务成本，并在适当配置平衡时保持甚至提高了预测准确性。

**Conclusion:** EDCIM是一种有效的方法，能够检测和校正大型语言模型在可解释数学任务中的错误，同时优化了成本和准确性。

> **ai_Abstract:** 本文提出EDCIM方法，旨在解决大型语言模型在可解释数学任务中常见的错误、幻觉和格式不依从问题。EDCIM通过LLM生成方程组并结合符号错误检测框架提供有针对性的校正反馈。该方法创新性地整合了开源与专有LLM以平衡成本与准确性，实验证明其在显著降低计算和财务成本的同时，能保持或提升预测精度。

> **摘要翻译:** 最近的大型语言模型（LLMs）已经展示了执行显式多步推理的能力，例如思维链提示。然而，它们的中间步骤通常包含错误，这些错误可能传播导致最终预测不准确。此外，LLMs仍然与幻觉作斗争，并且经常未能遵守规定的输出格式，这对于生成数学表达式或源代码等任务来说尤其成问题。这项工作引入了EDCIM（可解释数学错误检测和校正），这是一种用于检测和纠正在可解释数学任务中这些错误的方法，其中模型必须生成明确解决问题（以自然语言表达）的精确函数形式，而不是黑盒解决方案。EDCIM使用LLM为给定问题生成方程组，然后是一个符号错误检测框架，该框架识别错误并为基于LLM的校正提供有针对性的反馈。为了优化效率，EDCIM将轻量级、开源LLM与更强大的专有模型集成，平衡成本和准确性。这种平衡由一个单一的超参数控制，允许用户根据其成本和准确性要求控制权衡。不同数据集上的实验结果表明，EDCIM在适当配置平衡时显著降低了计算和财务成本，同时保持甚至提高了预测准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [145] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
> *边缘智能系统中自适应AI代理的部署与迁移*

*Xingdan Wang, Jiayi He, Zhiqing Tang, Jianxiong Guo, Jiong Lou, Liping Qian, Tian Wang, Weijia Jia* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** AI代理, 边缘智能, LLMs, 代理迁移, 蚁群算法

**Comment:** 

> **TL;DR:** 本文提出了一个新颖的自适应框架，用于在动态边缘环境中部署和迁移基于LLM的AI代理，利用蚁群算法和LLM优化来解决资源限制和迁移复杂性，显著降低了部署延迟和迁移成本。

**AI_Comments:** 本文为边缘智能领域中基于LLM的AI代理的部署和管理提供了一个创新且系统的解决方案。其创新点在于结合蚁群算法和LLM优化来实现自适应的代理放置和轻量级迁移，这对于资源受限和动态变化的边缘环境至关重要。作为“首个系统化部署和管理解决方案”，该研究具有重要的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的兴起推动了对实时处理任务的AI代理的需求。传统将数据密集型边缘工作负载部署在云端会导致显著延迟。虽然边缘部署能提高效率和降低延迟，但边缘环境资源有限且异构。为移动用户维护服务质量（QoS）需要代理迁移，而AI代理协调LLMs、任务规划、内存和外部工具的复杂性使得迁移变得复杂。

**Method:** 本文提出了首个针对动态边缘环境中基于LLM的AI代理的系统化部署和管理解决方案。该方案提出了一种新颖的AI代理放置和迁移自适应框架，通过建模资源约束、延迟和成本，并利用蚁群算法和基于LLM的优化进行高效决策。它能够自主放置代理以优化资源利用率和QoS，并通过仅传输必要状态来实现轻量级代理迁移。该解决方案在AgentScope构建的分布式系统上实现，并在全球分布式边缘服务器上进行了验证。

**Result:** 该解决方案显著降低了部署延迟和迁移成本。

**Conclusion:** 本文提出了首个针对动态边缘环境中基于LLM的AI代理的系统化部署和管理解决方案，通过一个自适应框架优化资源利用率和服务质量，并实现轻量级迁移，从而显著降低了部署延迟和迁移成本。

> **ai_Abstract:** 本文针对动态边缘环境中基于LLM的AI代理的部署和管理挑战，提出了一种新颖的自适应框架。该框架利用蚁群算法和基于LLM的优化，自主放置代理以优化资源利用率和服务质量，并通过仅传输必要状态实现轻量级迁移。该解决方案在AgentScope构建的分布式系统上实现并验证，显著降低了部署延迟和迁移成本。

> **摘要翻译:** ChatGPT和Claude等大型语言模型（LLMs）的兴起推动了对能够实时处理任务的AI代理的需求。然而，将数据密集型、多模态的边缘工作负载迁移到传统用于代理部署的云数据中心会引入显著的延迟。在边缘部署AI代理可以提高效率并降低延迟。但是，边缘环境由于资源有限和异构性而带来挑战。为移动用户维护服务质量（QoS）需要代理迁移，而AI代理协调LLMs、任务规划、内存和外部工具的复杂性使得迁移变得复杂。本文提出了首个针对动态边缘环境中基于LLM的AI代理的系统化部署和管理解决方案。我们提出了一种新颖的边缘智能系统中AI代理放置和迁移的自适应框架。我们的方法对资源约束、延迟/成本进行建模，利用蚁群算法和基于LLM的优化来实现高效决策。它能自主放置代理以优化资源利用率和QoS，并通过仅传输必要状态来实现轻量级代理迁移。我们的解决方案在AgentScope构建的分布式系统上实现，并在全球分布式边缘服务器上进行了验证，显著降低了部署延迟和迁移成本。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [185] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
> *通过步长熵压缩大型语言模型中的思维链*

*Zeju Li, Jianyuan Zhong, Ziyang Zheng, Xiangyu Wen, Zhijian Xu, Yingying Cheng, Fan Zhang, Qiang Xu* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 思维链压缩, 步长熵, 大型语言模型, 推理效率, 强化学习

**Comment:** 

> **TL;DR:** 该研究提出了一种基于步长熵的思维链（CoT）压缩框架，能有效识别并剪枝冗余推理步骤，显著提高大型语言模型（LLM）的推理效率并保持准确性。

**AI_Comments:** 该论文提出了一种新颖且实用的方法来解决LLM CoT推理中的冗余问题，其核心创新在于引入“步长熵”这一概念来量化推理步骤的信息量，并以此为基础进行剪枝。80%的冗余剪枝且准确率几乎无损这一结果令人印象深刻，表明CoT中存在大量可优化的空间。结合SFT和GRPO的训练策略也很有趣，使得模型能够自主学习压缩。这对于降低LLM推理成本和提高部署效率具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在使用思维链（CoT）提示时虽然擅长复杂推理，但会生成冗长的、包含大量冗余的思维过程，这导致推理成本增加和效率降低。

**Method:** 研究引入了一种基于步长熵的新型CoT压缩框架，该指标量化了单个推理步骤的信息贡献以识别冗余。通过理论分析和在数学推理基准上的广泛实证验证，证明了低熵步骤确实高度冗余。在此基础上，提出了一种结合监督微调（SFT）和组相对策略优化（GRPO）强化学习的两阶段训练策略，使LLMs能够通过策略性地合并[SKIP]令牌，自主学习在推理过程中生成压缩的CoT。

**Result:** 实验表明，在DeepSeek-R1-7B、14B和Qwen3-8B模型上，80%的低熵中间步骤可以在最终答案准确性仅有轻微下降的情况下被剪枝。这与随机或高熵剪枝形成鲜明对比，后者会严重损害推理性能。该方法显著提升了LLM的推理效率，同时严格保持了准确性。

**Conclusion:** 该研究提出的基于步长熵的CoT压缩框架和两阶段训练策略，能够有效识别并去除LLM思维链中的冗余，大幅提升推理效率并保持准确性，对LLM的实际部署和对推理结构的深入理解具有重要意义。

> **ai_Abstract:** 本研究针对大型语言模型（LLMs）在链式思考（CoT）推理中存在的冗余和效率低下问题，提出了一种基于步长熵的CoT压缩框架。该框架通过量化推理步骤的信息贡献来识别冗余。理论分析和实验验证表明，低熵步骤可大量剪枝（高达80%），且对最终答案准确性影响甚微。与随机剪枝不同，这种方法能有效保持推理性能。在此基础上，研究提出了一种结合SFT和GRPO强化学习的两阶段训练策略，使LLMs能自主生成包含[SKIP]令牌的压缩CoT。该方法在显著提升LLM推理效率的同时，严格保持了准确性，对LLM的实际应用和对推理结构的理解具有重要意义。

> **摘要翻译:** 大型语言模型（LLMs）在使用思维链（CoT）提示时，在复杂推理方面表现出色，但会生成冗长的思维过程，其中包含相当大的冗余，导致推理成本增加和效率降低。我们引入了一种基于步长熵的新型CoT压缩框架，该指标量化了单个推理步骤的信息贡献以识别冗余。通过理论分析和在数学推理基准上的广泛实证验证，我们证明了低熵步骤确实高度冗余。我们的实验表明，在DeepSeek-R1-7B、14B和Qwen3-8B模型上，80%的低熵中间步骤可以在最终答案准确性仅有轻微下降的情况下被剪枝。这一发现与随机或高熵剪枝形成鲜明对比，后者会严重损害推理性能。在此基础上，我们提出了一种结合监督微调（SFT）和组相对策略优化（GRPO）强化学习的新型两阶段训练策略。这种方法使LLMs能够通过策略性地合并[SKIP]令牌，自主学习在推理过程中生成压缩的CoT。我们的方法显著提升了LLM的推理效率，同时严格保持了准确性，对LLM的实际部署和对推理结构的深入理解具有深远影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [186] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
> *Transformer训练中大规模激活的隐藏动态*

*Jorge Gallego-Feliciano, S. Aaron McClendon, Juan Morinelli, Stavros Zervoudakis, Antonios Saravanos* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大规模激活, Transformer, 训练动态, 预测, 模型设计

**Comment:** 

> **TL;DR:** 本文首次全面分析了Transformer训练中大规模激活的出现动态，发现其遵循可预测的数学模式，并开发了一个机器学习框架，可以根据架构规格预测这些模式，从而在训练前实现对大规模激活的预测和潜在控制。

**AI_Comments:** 这项研究创新性地揭示了Transformer训练过程中大规模激活的动态演变规律，并首次提出了可预测其行为的数学模型和机器学习框架。其重要性在于，通过在训练前预测和控制大规模激活，有望显著提升模型训练的稳定性、效率和可解释性，为Transformer架构设计提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的工作已经描述了完全训练模型中的大规模激活现象，但其在训练过程中出现的时间动态仍然知之甚少。

**Method:** 本文对Pythia模型家族在不同模型大小和多个训练检查点下的大规模激活发展进行了首次全面分析。研究发现大规模激活的出现遵循可预测的数学模式，并可以使用一个具有五个关键参数的指数调制对数函数进行精确建模。作者还开发了一个机器学习框架，仅根据架构规格预测这些数学参数。

**Result:** 研究表明，大规模激活的出现遵循可预测的数学模式，可以用指数调制对数函数准确建模。开发的机器学习框架能够高精度预测稳态行为，中等精度预测出现时间和幅度。这些发现使得架构师能够通过设计选择预测并潜在地控制大规模激活的关键方面。

**Conclusion:** 大规模激活的出现受模型设计支配，并且可以在训练开始前被预测和潜在控制，这对模型稳定性、训练周期长度、可解释性和优化具有重要意义。

> **ai_Abstract:** 本文首次全面分析了Transformer训练中大规模激活的出现动态。研究发现，大规模激活的出现遵循可预测的数学模式，可以用一个指数调制对数函数精确建模。作者还开发了一个机器学习框架，能够仅根据模型架构规格预测这些模式的关键参数，从而在训练前预测并潜在控制大规模激活的行为，这对Transformer模型的稳定性、训练效率和可解释性具有重要影响。

> **摘要翻译:** 大规模激活是Transformer隐藏状态中的标量值，其值比典型激活大几个数量级，并且已被证明对模型功能至关重要。尽管先前的工作已经描述了完全训练模型中的这些现象，但其在训练过程中出现的时间动态仍然知之甚少。我们首次全面分析了Transformer训练过程中大规模激活的发展，并使用Pythia模型家族作为测试平台。通过对不同模型大小在多个训练检查点进行系统分析，我们证明了大规模激活的出现遵循可预测的数学模式，可以使用一个具有五个关键参数的指数调制对数函数进行精确建模。我们开发了一个机器学习框架，仅根据架构规格预测这些数学参数，在稳态行为方面实现了高精度，在出现时间和幅度方面实现了中等精度。这些发现使架构师能够通过设计选择预测并潜在地控制大规模激活的关键方面，这对模型稳定性、训练周期长度、可解释性和优化具有重要意义。我们的研究结果表明，大规模激活的出现受模型设计支配，并且可以在训练开始前被预测和潜在控制。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [225] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
> *CogBench：一个用于多语言语音认知障碍评估的大型语言模型基准*

*Feng Rui, Zhiyao Luo, Wei Wang, Yuting Song, Yong Liu, Tingting Zhu, Jianqing Li, Xingyao Wang* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 认知障碍评估, 语音, 多语言, 泛化能力

**Comment:** 19 pages, 9 figures, 12 tables

> **TL;DR:** CogBench是首个评估LLM在跨语言和跨站点语音认知障碍评估中泛化能力的基准。研究发现传统模型泛化能力差，LLM在链式思考提示下表现更好，LoRA微调显著提高了泛化性。

**AI_Comments:** 本文创新性地提出了首个用于评估LLM在多语言和跨站点语音认知障碍评估中泛化能力的基准CogBench，填补了现有研究的空白。研究结果揭示了LLM在跨域适应方面的潜力，并验证了LoRA微调在提升泛化性上的有效性，对构建更具临床应用价值的语音认知评估工具具有重要指导意义。但论文也指出LLM性能对提示设计敏感，这是未来研究需要解决的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 目前的自动语音认知障碍评估方法在跨语言和临床设置部署时泛化能力不足，限制了其实用性。

**Method:** 提出了CogBench基准，用于评估LLM在语音认知障碍评估中的跨语言和跨站点泛化能力。使用统一的多模态管道，在英语和普通话的三个语音数据集（ADReSSo、NCMMSC2021-AD和新收集的CIR-E）上评估模型性能。探索了链式思考提示以及通过低秩适应（LoRA）对LLM进行轻量级微调。

**Result:** 传统深度学习模型在跨域转移时性能显著下降。配备链式思考提示的LLM表现出更好的适应性，但其性能对提示设计敏感。通过LoRA对LLM进行轻量级微调显著提高了目标领域的泛化能力。

**Conclusion:** 这些发现是构建具有临床实用性和语言鲁棒性的语音认知评估工具的关键一步。

> **ai_Abstract:** 本研究提出了CogBench，这是一个评估大型语言模型（LLMs）在多语言和跨站点语音认知障碍评估中泛化能力的基准。针对现有方法泛化性差的问题，研究团队在英语和普通话数据集上测试了传统模型和LLMs。结果显示，传统模型跨域性能下降严重，而LLMs结合链式思考提示展现出更好的适应性，尽管对提示敏感。进一步，通过LoRA微调LLMs能显著提升其在目标领域的泛化能力。这些发现为开发实用且稳健的语音认知评估工具提供了重要进展。

> **摘要翻译:** 通过自发语音进行认知障碍的自动评估为早期认知筛查提供了一种有前景的非侵入性途径。然而，当前的方法在跨不同语言和临床环境部署时通常缺乏泛化能力，限制了其实用性。在这项研究中，我们提出了CogBench，这是第一个旨在评估大型语言模型（LLM）在基于语音的认知障碍评估中跨语言和跨站点泛化能力的基准。我们使用统一的多模态管道，评估了模型在涵盖英语和普通话的三个语音数据集（ADReSSo、NCMMSC2021-AD以及新收集的测试集CIR-E）上的性能。我们的结果表明，传统的深度学习模型在跨域转移时性能显著下降。相比之下，配备链式思考提示的LLM表现出更好的适应性，尽管它们的性能仍然对提示设计敏感。此外，我们探索了通过低秩适应（LoRA）对LLM进行轻量级微调，这显著改善了目标领域的泛化能力。这些发现为构建具有临床实用性和语言鲁棒性的基于语音的认知评估工具迈出了关键一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [242] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
> *精炼LLM代码生成中的批判性思维：一个基于错误前提的评估框架*

*Jialin Li, Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** LLM代码生成, 错误前提, 评估框架, 自我审查, FPBench

**Comment:** 

> **TL;DR:** 提出了FPBench，一个用于评估LLM在错误前提下代码生成能力的框架，发现大多数LLM在此情况下推理和代码生成能力较差，且缺乏自我审查。

**AI_Comments:** 这项研究具有创新性，因为它首次提出了针对LLM代码生成中错误前提的评估框架FPBench，填补了现有评估体系的空白。它揭示了LLM在复杂推理和自我审查方面的深层缺陷，对于未来LLM的鲁棒性提升和可靠性发展具有重要指导意义。特别指出了资源投入的边际效益递减点，对优化模型训练和使用策略提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 当用户提供包含错误前提的输入时，大型语言模型（LLMs）的代码生成幻觉显著增加，暴露出其自我审查能力的不足。

**Method:** 本文提出了首个针对错误前提的代码生成评估框架FPBench。通过系统构建三类错误前提并整合多维度评估指标，对15个代表性LLM进行了深入评估。

**Result:** 1. 大多数模型在错误前提下表现出较差的推理能力和次优的代码生成性能，严重依赖显式提示进行错误检测，自我审查能力有限；2. 错误前提触发了资源投入的边际效益递减点，导致盲目增加长度无法提高质量；3. 三类错误前提分别激活了模型中不同的缺陷模式，揭示了代码生成模型认知机制的三重分离。

**Conclusion:** 这项研究不仅强调了LLM在代码生成中主动验证前提的迫切需求，而且通过提出的FPBench框架和多维度评估系统，为开发可靠的、以人为中心的代码生成模型提供了理论基础和实践途径。

> **ai_Abstract:** 本文提出了FPBench，一个评估LLM在错误前提下代码生成能力的开创性框架。研究发现，LLM在面对错误前提时推理和代码生成能力显著下降，缺乏有效的自我审查机制，且不同类型的错误前提会揭示模型认知机制中的特定缺陷。该研究强调了LLM主动验证前提的重要性，并为开发更可靠的代码生成模型提供了方法论。

> **摘要翻译:** 随着大型语言模型（LLM）代码生成能力的进步，它们对输入前提的依赖性也随之增强。当用户提供包含错误前提的输入时，代码生成幻觉的概率显著上升，暴露出其自我审查能力的不足。本文提出了错误前提基准（FPBench），这是首个针对错误前提的代码生成评估框架。通过系统地构建三类错误前提并整合多维度评估指标，它对15个代表性LLM进行了深入评估。主要发现如下：(1) 大多数模型在错误前提下表现出较差的推理能力和次优的代码生成性能，严重依赖显式提示进行错误检测，自我审查能力有限；(2) 错误前提触发了资源投入的边际效益递减点，导致盲目增加长度无法提高质量；(3) 三类错误前提分别激活了模型中不同的缺陷模式，揭示了代码生成模型认知机制的三重分离。这项研究不仅强调了LLM在代码生成中主动验证前提的迫切需求，而且通过提出的FPBench框架和多维度评估系统，为开发可靠的、以人为中心的代码生成模型提供了理论基础和实践途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [253] [Learning telic-controllable state representations](https://arxiv.org/abs/2406.14476)
> *学习目的可控的状态表征*

*Nadav Amir, Stas Tiomkin* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 状态表征学习, 目的可控性, 强化学习, 故意忽略, 认知复杂性

**Comment:** Published in Proceedings of the 47th Annual Meeting of the Cognitive
  Science Society

> **TL;DR:** 本文提出了一个计算框架，用于学习目的可控的状态表征，该表征通过目的性状态耦合描述性和规定性方面，并通过“目的可控性”概念平衡表征粒度与策略复杂性，强调了“故意忽略”在平衡目标灵活性和认知复杂性中的作用。

**AI_Comments:** 本文的创新之处在于提出了“目的可控性”这一新颖概念，将描述性状态表征与规定性目标函数有效耦合，并强调了“故意忽略”在构建高效灵活状态表征中的重要性。这为强化学习中状态表征学习提供了新的视角，有助于解决在复杂环境中代理的认知负荷与目标适应性之间的矛盾。

<details>
  <summary>Details</summary>

**Motivation:** 在强化学习中，规定性奖励函数通常依赖于预定义和固定的描述性状态表征。然而，描述性方面和规定性方面也可以相互依赖地出现，即目标可以塑造所获得的状态表征，反之亦然。本文旨在解决如何在这种相互依赖关系下，为有限代理学习状态表征的问题。

**Method:** 本文提出了一个用于学习状态表征的计算框架，其中描述性和规定性方面通过目的性（telic）状态概念进行耦合。引入了“目的可控性”（telic-controllability）概念来表征目的状态表征的粒度与达到所有目的状态所需的策略复杂性之间的权衡。提出了一种学习目的可控状态表征的算法，并使用模拟导航任务进行了说明。

**Result:** 通过模拟导航任务，该框架成功展示了如何学习目的可控的状态表征。研究结果强调了“故意忽略”（knowing what to ignore）在学习平衡目标灵活性和认知复杂性的状态表征中的作用。

**Conclusion:** 该框架突出了“故意忽略”在学习状态表征中的作用，这些状态表征能够在目标灵活性和认知复杂性之间取得平衡。

> **ai_Abstract:** 本文提出了一个计算框架，用于在有限代理中学习状态表征，其中描述性和规定性方面通过目的性状态概念相互耦合。文章引入了“目的可控性”的概念来量化目的状态表征的粒度与达成这些状态所需策略复杂性之间的权衡，并提出了一种相应的学习算法，通过模拟导航任务进行了验证。该框架强调了“故意忽略”在学习能够平衡目标灵活性和认知复杂性的状态表征中的关键作用。

> **摘要翻译:** 有目的行为的计算模型包括描述性和规定性两方面，分别用于确定和评估世界中的情况。在强化学习中，规定性奖励函数被假定依赖于预定义和固定的描述性状态表征。或者，这两个方面可以相互依赖地出现：目标可以塑造所获得的状态表征，反之亦然。在此，我们提出了一个用于有限代理的状态表征学习的计算框架，其中描述性和规定性方面通过目标导向或目的性状态的概念耦合。我们引入了目的可控性概念来表征目的状态表征的粒度与达到所有目的状态所需的策略复杂性之间的权衡。我们提出了一种学习目的可控状态表征的算法，并使用模拟导航任务进行了说明。我们的框架强调了“故意忽略”（即知道要忽略什么）在学习平衡目标灵活性和认知复杂性的状态表征中的作用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [265] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
> *神经符号AI方法在可解释逻辑推理中的比较研究*

*Michael K. Chen* | **Category: cs.AI, cs.CL, cs.LG, cs.SC** | **Updated: 2025-08-05**

**Keywords:** 神经符号AI, 逻辑推理, 大型语言模型, 可解释性, 混合方法

**Comment:** Accepted to NeSy 2025

> **TL;DR:** 本研究比较了两种神经符号AI方法在通用逻辑推理方面的表现，发现混合方法更具前景，因为它更可解释且保留了大型语言模型的优势。

**AI_Comments:** 该论文通过对两种主要神经符号AI方法的比较研究，填补了该领域在通用逻辑推理方面缺乏系统性比较的空白。其创新之处在于明确指出了混合方法的优势，并提出了一个实用的通用框架，对未来神经符号AI的发展具有指导意义。强调可解释性和保留LLM能力是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在通用逻辑推理方面表现不佳，难以进行确定性推理且缺乏可解释性。神经符号AI旨在将逻辑融入神经网络以解决此问题。然而，对于两种主要神经符号方法（集成方法和混合方法）在领域无关基准上的表现，目前缺乏深入研究和直接比较，以确定哪种方法在开发通用逻辑推理方面更具前景。

**Method:** 研究首先识别了两种主要的神经符号AI方法：集成方法（符号推理包含在神经网络内部）和混合方法（符号求解器独立于神经网络执行符号推理）。为了比较它们的潜力，本研究选择了最先进的领域无关模型作为案例研究：Logic Neural Network (LNN) 代表集成方法，LLM-Symbolic Solver (LLM-SS) 代表混合方法。通过对这两种模型的分析和比较，评估它们在通用逻辑推理方面的表现。

**Result:** 分析结果表明，混合方法在开发通用逻辑推理方面更具前景。具体原因有二：(i) 它的推理链更具可解释性，(ii) 它保留了现有大型语言模型的能力和优势。

**Conclusion:** 混合神经符号AI方法在通用逻辑推理方面表现出更大的潜力，因为它提供了更可解释的推理过程并能保持大型语言模型的固有优势。为支持未来工作，本研究提出了一个基于LLM-SS的通用框架，该框架具有模块化、模型无关、领域无关的特点，并且几乎不需要人工输入。

> **ai_Abstract:** 本研究旨在比较神经符号AI的两种主要方法（集成方法和混合方法）在通用逻辑推理方面的有效性。鉴于大型语言模型在通用、可解释逻辑推理上的局限性，神经符号AI受到了广泛关注。研究选取了代表性的领域无关模型Logic Neural Network（集成方法）和LLM-Symbolic Solver（混合方法）进行案例分析。结果表明，混合方法在发展通用逻辑推理方面更具前景，因为它提供了更高的可解释性并保留了现有LLM的优势。为促进未来研究，论文还提出了一个基于LLM-SS的通用、模块化、模型及领域无关的框架。

> **摘要翻译:** 通用逻辑推理，被定义为在领域无关任务上进行演绎推理的能力，对大型语言模型（LLMs）来说仍然是一个挑战。当前的LLMs无法确定性地进行推理，并且缺乏可解释性。因此，最近对神经符号AI的兴趣激增，它试图将逻辑融入神经网络。我们首先确定了两种改善逻辑推理的主要神经符号方法：(i) 集成方法，包含符号推理在神经网络内部的模型；(ii) 混合方法，包含符号求解器独立于神经网络执行符号推理的模型。两者都包含在领域特定逻辑推理基准上取得有希望结果的AI系统。然而，它们在领域无关基准上的表现尚未得到充分研究。据我们所知，目前还没有对这两种对比方法进行比较，以回答以下问题：哪种方法在开发通用逻辑推理方面更具前景？为了分析它们的潜力，引入了以下最先进的领域无关模型：Logic Neural Network (LNN)，它采用集成方法；以及LLM-Symbolic Solver (LLM-SS)，它采用混合方法。以这两种模型作为案例研究和每种方法的代表，我们的分析表明，混合方法在开发通用逻辑推理方面更具前景，因为 (i) 其推理链更具可解释性，并且 (ii) 它保留了现有LLMs的能力和优势。为了支持未来使用混合方法的工作，我们提出了一个基于LLM-SS的通用框架，该框架设计为模块化、模型无关、领域无关，并且几乎不需要人工输入。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [267] [Game Theory Meets Large Language Models: A Systematic Survey with Taxonomy and New Frontiers](https://arxiv.org/abs/2502.09053)
> *博弈论与大型语言模型相遇：一项带有分类法和新前沿的系统综述*

*Haoran Sun, Yusen Wu, Peng Wang, Wei Chen, Yukun Cheng, Xiaotie Deng, Xu Chu* | **Category: cs.AI, cs.GT, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 博弈论, 大型语言模型, 系统综述, 分类法, 战略互动

**Comment:** A shorter conference version is published in IJCAI 2025, titled 'Game
  Theory Meets Large Language Models: A Systematic Survey'

> **TL;DR:** 本文首次全面综述了博弈论与大型语言模型之间的双向关系，提出了新的分类法并指出了未来研究方向。

**AI_Comments:** 其创新之处在于提供了首次全面的双向综述和新颖的分类法，这对于构建和推进这一快速发展的跨学科领域的研究至关重要。它超越了狭隘的关注点，转向了整体视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有综述主要狭隘地关注使用博弈论评估大型语言模型行为，而本文旨在提供一个全面的、双向的视角。

**Method:** 本文进行了一项首次全面的系统综述，提出了一个包含四个视角的创新分类法，并识别了关键挑战和未来研究方向。

**Result:** 本文提出了一个新颖的分类法，将该交叉领域的研究分为四个不同视角：(1) 在基于博弈的场景中评估大型语言模型；(2) 利用博弈论概念改进大型语言模型以提高可解释性和对齐性；(3) 模拟大型语言模型开发的竞争格局及其社会影响；(4) 利用大型语言模型推进博弈模型并解决相应的博弈论问题。此外，它还识别了关键挑战并概述了未来的研究方向。

**Conclusion:** 该综述强调了博弈论和大型语言模型之间的相互影响，促进了这些领域交叉点的发展。

> **ai_Abstract:** 本文首次对博弈论与大型语言模型之间的双向关系进行了全面的系统综述。它提出了一个新颖的四视角分类法，涵盖了大型语言模型的评估、改进、社会影响建模以及利用大型语言模型推进博弈论。该综述还指出了挑战和未来的研究方向，旨在促进这一跨学科交叉领域的发展。

> **摘要翻译:** 博弈论是分析战略互动的基本框架，它与大型语言模型（LLMs）的交叉是一个快速发展的领域。然而，现有综述主要狭隘地关注使用博弈论评估大型语言模型行为。本文首次提供了博弈论与大型语言模型之间双向关系的全面综述。我们提出了一个新颖的分类法，将该交叉领域的研究分为四个不同的视角：(1) 在基于博弈的场景中评估大型语言模型；(2) 利用博弈论概念改进大型语言模型以提高可解释性和对齐性；(3) 模拟大型语言模型开发的竞争格局及其社会影响；(4) 利用大型语言模型推进博弈模型并解决相应的博弈论问题。此外，我们识别了关键挑战并概述了未来的研究方向。通过系统地调查这一跨学科领域，我们的综述强调了博弈论和大型语言模型之间的相互影响，促进了这些领域交叉点的发展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [296] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
> *LLM引导的进化蒙特卡洛树搜索在引力波探测中的自动化算法发现*

*He Wang, Liang Zeng* | **Category: cs.AI, astro-ph.HE, astro-ph.IM, gr-qc** | **Updated: 2025-08-05**

**Keywords:** 引力波探测, 算法发现, 进化蒙特卡洛树搜索, 大型语言模型, 可解释性

**Comment:** 89 pages (37 main), 6+6 figures, 1 table. Initial submission; subject
  to revision

> **TL;DR:** 本文提出了一种名为Evo-MCTS的新框架，结合树搜索、进化优化和LLM启发式方法，用于自动化发现引力波检测算法。它在MLGWSC-1数据集上实现了20.2%的性能提升，并生成了可解释的算法路径。

**AI_Comments:** 这篇论文的创新点在于将进化蒙特卡洛树搜索与大型语言模型启发式方法相结合，用于自动化算法发现，尤其是在引力波探测这一复杂领域。它不仅提升了性能，更重要的是，解决了现有方法的可解释性问题，并提供了一种通用且可转移的算法发现范式，这对于计算科学的未来发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算科学发现，特别是在引力波信号识别中，面临挑战。现有方法如匹配滤波（MF）计算成本高昂且依赖预定义模板，而深度神经网络（DNNs）则存在黑箱问题和潜在偏见。

**Method:** 本文提出了进化蒙特卡洛树搜索（Evo-MCTS）框架。该方法通过结合树状搜索、进化优化和大型语言模型（LLM）启发式方法来系统地探索算法空间，并由领域感知的物理约束指导，以创建可解释的算法解决方案。

**Result:** Evo-MCTS框架在MLGWSC-1基准数据集上，比最先进的引力波检测算法实现了20.2%的显著改进。高性能算法变体持续超过阈值，并且该框架生成了揭示不同性能模式的人类可解释算法路径。

**Conclusion:** Evo-MCTS框架不仅提高了引力波检测的性能，还发现了新颖的算法组合，并建立了一种可转移的自动化算法发现方法，适用于计算科学领域的其他应用。

> **ai_Abstract:** 本文介绍了一种名为Evo-MCTS的新型框架，旨在解决引力波信号识别中现有算法（如匹配滤波和深度神经网络）的局限性。Evo-MCTS结合了树状搜索、进化优化和大型语言模型启发式方法，以系统地探索算法空间并生成可解释的解决方案。该框架在MLGWSC-1数据集上取得了20.2%的性能提升，并能够发现新颖的算法组合，为计算科学领域的自动化算法发现提供了一种可转移的方法。

> **摘要翻译:** 计算科学发现越来越依赖算法来处理复杂数据并识别有意义的模式——但在引力波信号识别方面仍面临持续挑战。尽管现有算法方法，如匹配滤波（MF）和深度神经网络（DNNs）已取得部分成功，但它们的局限性直接源于其基本限制：MF对预定义理论波形模板的依赖导致其计算需求过高，而DNNs的黑箱架构则模糊了决策逻辑并引入了隐藏偏见。我们提出了进化蒙特卡洛树搜索（Evo-MCTS），一个通过系统性算法空间探索，并由领域感知物理约束指导来解决这些局限性的框架。我们的方法结合了树状搜索、进化优化和大型语言模型启发式方法，以创建可解释的算法解决方案。我们的Evo-MCTS框架展示了显著的改进，在MLGWSC-1基准数据集上，比最先进的引力波检测算法实现了20.2%的改进。高性能算法变体持续超过阈值。该框架生成了人类可解释的算法路径，揭示了不同的性能模式。除了性能改进之外，我们的框架还发现了新颖的算法组合，从而建立了一种可转移的自动化算法发现方法，适用于计算科学领域的各个领域。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [300] [BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation](https://arxiv.org/abs/2410.14971)
> *BrainECHO：通过向量量化频谱重建实现语义脑信号解码以增强Whisper文本生成*

*Jilong Li, Zhenxi Song, Jiaqi Wang, Meishan Zhang, Honghai Liu, Min Zhang, Zhiguo Zhang* | **Category: cs.AI, cs.CL, cs.SD, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 脑信号解码, EEG/MEG, 向量量化, 频谱重建, Whisper模型

**Comment:** 8 pages (excluding references), accepted by Findings of ACL 2025

> **TL;DR:** BrainECHO是一个多阶段框架，通过解耦表示学习和向量量化频谱重建，克服了当前EEG/MEG到文本解码系统的局限性，实现了更好的脑信号到文本生成。

**AI_Comments:** 这篇论文通过提出BrainECHO框架，创新性地解决了当前脑信号到文本解码系统的关键限制。其亮点在于采用解耦表示学习和向量量化频谱重建，有效降低了噪声敏感性并提高了跨受试者泛化能力。结合预训练的Whisper模型进行受限解码微调，在保持高性能的同时，显著减少了对教师强制的依赖，提升了系统的实用性。这对于推动基于语言的脑机接口技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前EEG/MEG到文本解码系统存在三个主要限制：(1) 依赖教师强制方法，损害推理鲁棒性；(2) 对会话特异性噪声敏感，阻碍跨受试者泛化；(3) 脑信号与语言表示未对齐，因为预训练语言模型过度主导。

**Method:** 提出BrainECHO框架，包含三个阶段：(1) 离散自编码，将连续Mel频谱转换为高质量离散表示。(2) 冻结对齐，将脑信号嵌入映射到对应的Mel频谱嵌入，通过向量量化重建过滤会话特异性噪声。(3) 受限解码微调，利用预训练Whisper模型进行音频到文本翻译，平衡信号适应与知识保留。

**Result:** BrainECHO在EEG和MEG数据集上取得了最先进的性能。在冻结对齐阶段，通过向量量化重建使BLEU-4分数提高了3.65%。在受限解码微调阶段，在不过度依赖教师强制的情况下，实现了74%-89%的解码BLEU分数。该系统在句子、会话和受试者独立条件下表现出鲁棒性，并通过了高斯噪声测试。

**Conclusion:** BrainECHO通过克服现有EEG/MEG-to-text解码系统的关键限制，展示了在增强基于语言的脑机接口方面的巨大潜力。

> **ai_Abstract:** BrainECHO是一个新颖的多阶段框架，旨在解决当前EEG/MEG到文本解码系统面临的鲁棒性差、泛化能力弱和信号与语言表示未对齐等问题。该框架通过离散自编码、冻结对齐（利用向量量化重建过滤噪声并提高BLEU-4分数）和受限解码微调（结合Whisper模型实现高解码BLEU分数且减少教师强制依赖）等步骤，实现了脑信号的语义解码和文本生成。BrainECHO在多种条件下表现出强大的鲁棒性，并为语言脑机接口的发展提供了新的方向。

> **摘要翻译:** 当前EEG/MEG到文本解码系统存在三个关键限制：(1) 依赖教师强制方法，这会损害推理时的鲁棒性；(2) 对会话特异性噪声敏感，阻碍跨受试者泛化；(3) 由于预训练语言模型过度主导，导致脑信号与语言表示之间未对齐。为了克服这些挑战，我们提出了BrainECHO（通过向量量化频谱重建增强Whisper文本生成的脑信号解码），这是一个多阶段框架，采用解耦表示学习，在EEG和MEG数据集上均取得了最先进的性能。具体而言，BrainECHO包含三个阶段：(1) 离散自编码，将连续的Mel频谱转换为有限的高质量离散表示，以供后续阶段使用。(2) 冻结对齐，在此阶段，脑信号嵌入被映射到冻结潜在空间中相应的Mel频谱嵌入，通过向量量化重建有效过滤会话特异性噪声，使BLEU-4分数提高了3.65%。(3) 受限解码微调，该阶段利用预训练的Whisper模型进行音频到文本翻译，平衡信号适应与知识保留，并在不过度依赖教师强制的情况下，实现了74%-89%的解码BLEU分数。BrainECHO在句子、会话和受试者独立条件下均表现出鲁棒性，通过了高斯噪声测试，并展示了其增强基于语言的脑机接口的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [302] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
> *棋盘游戏竞技场：一个通过策略游戏评估大型语言模型的框架和基准*

*Lucia Cipolina-Kun, Marianna Nezhurina, Jenia Jitsev* | **Category: cs.AI, cs.GT** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 策略游戏, 评估框架, 博弈论, Board Game Arena

**Comment:** 

> **TL;DR:** Board Game Arena 是一个用于通过策略棋盘游戏评估大型语言模型 (LLM) 决策能力的框架和基准。

**AI_Comments:** 该论文介绍的 Board Game Arena 框架具有重要意义，因为它为系统地评估 LLM 在复杂策略游戏中的决策能力提供了一个急需的工具。其创新之处在于整合了多种技术（LiteLLM, vLLM, Ray）以支持灵活的模型部署和分布式执行，并提供详细的分析工具。这对于理解 LLM 的推理过程和博弈论行为至关重要，弥补了现有评估方法的一些不足。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是需要一个系统框架来通过策略棋盘游戏评估大型语言模型 (LLM) 的决策能力和博弈论行为。

**Method:** Board Game Arena 库提供了一个框架，通过包装 Google OpenSpiel 库中实现的多种棋盘和矩阵游戏，并支持不同类型的代理（随机、人类、强化学习代理等），从而实现 LLM 代理与其他代理在各种游戏场景中的系统比较。它集成了通过 LiteLLM 进行模型 API 访问、通过 vLLM 进行本地模型部署以及通过 Ray 进行分布式执行。此外，它还提供了用于 LLM 推理跟踪的广泛分析工具。

**Result:** 本论文总结了 Board Game Arena 存储库的结构、关键特征和动机，强调了它如何有助于 LLM 推理和博弈论行为的实证评估。

**Conclusion:** Board Game Arena 框架通过提供一个用于评估 LLM 决策能力和博弈论行为的系统工具，为大型语言模型在战略游戏领域的实证评估做出了贡献。

> **ai_Abstract:** Board Game Arena 是一个用于通过策略棋盘游戏评估大型语言模型 (LLM) 决策能力的框架。该框架利用 Google OpenSpiel 库中的游戏，支持多种代理类型，并整合了 LiteLLM、vLLM 和 Ray 进行模型访问、部署和分布式执行。它还提供分析工具，旨在系统地比较 LLM 代理和其他类型代理，从而促进对 LLM 推理和博弈论行为的实证评估。本文主要概述了该存储库的结构、特点和目的。

> **摘要翻译:** Board Game Arena 库提供了一个框架，用于通过在 Google OpenSpiel 库中实现的策略棋盘游戏来评估大型语言模型 (LLM) 的决策能力。该框架通过包装多个棋盘和矩阵游戏并支持不同类型的代理（随机、人类、强化学习代理等），从而实现在各种游戏场景中基于 LLM 的代理与其他代理之间的系统比较。它集成了通过 LiteLLM 进行模型 API 访问、通过 vLLM 进行本地模型部署，并通过 Ray 提供分布式执行。此外，它还提供了用于 LLM 推理跟踪的广泛分析工具。本论文总结了该存储库的结构、关键特征和动机，强调了它如何有助于 LLM 推理和博弈论行为的实证评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [326] [HypRL: Reinforcement Learning of Control Policies for Hyperproperties](https://arxiv.org/abs/2504.04675)
> *HypRL：强化学习超性质控制策略*

*Tzu-Han Hsu, Arshia Rafieioskouei, Borzoo Bonakdarpour* | **Category: cs.AI, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 超性质, 奖励塑造, 多智能体系统, HyperLTL

**Comment:** 

> **TL;DR:** HypRL是一个规范引导的强化学习框架，它使用HyperLTL表达的超性质来学习控制策略，并通过量化鲁棒性函数来塑造奖励，以解决多智能体强化学习中复杂任务的奖励塑造难题。

**AI_Comments:** HYPRL的创新之处在于将超性质（Hyperproperties）引入强化学习，并利用Skolemization和量化鲁棒性函数来解决复杂奖励塑造问题。这为多智能体系统中更高级别的规范（如安全性、公平性）提供了新的学习范式，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多智能体强化学习（MARL）中，复杂任务的奖励塑造仍然是一个重大挑战，现有方法往往无法找到最优解或无法高效处理此类任务。

**Method:** 本文提出了HYPRL框架，一个规范引导的强化学习框架，用于学习满足HyperLTL表达的超性质的控制策略。通过应用Skolemization管理量词交替，并定义量化鲁棒性函数来塑造未知转移的马尔可夫决策过程的执行轨迹上的奖励。然后使用合适的RL算法学习策略，以集体最大化预期奖励并增加满足HyperLTL公式的概率。

**Result:** 在包括安全感知规划、深海宝藏和邮政对应问题在内的多种基准上评估了HYPRL。与规范驱动的基线进行了比较，证明了HYPRL的有效性和效率。

**Conclusion:** HYPRL框架能够有效且高效地学习满足复杂超性质的控制策略，解决了多智能体强化学习中奖励塑造的难题。

> **ai_Abstract:** 本文提出了HYPRL，一个规范引导的强化学习框架，旨在解决多智能体强化学习中复杂任务的奖励塑造难题。HYPRL利用HyperLTL表达的超性质来定义控制目标和约束，并通过Skolemization和量化鲁棒性函数来塑造奖励。实验证明，HYPRL在多个基准测试中表现出有效性和效率，优于现有规范驱动的基线方法。

> **摘要翻译:** 在多智能体强化学习（MARL）中，复杂任务的奖励塑造仍然是一个重大挑战。现有方法往往无法找到最优解或无法高效处理此类任务。我们提出了HYPRL，一个规范引导的强化学习框架，它针对HyperLTL中表达的超性质学习控制策略。超性质是一种强大的形式化方法，用于指定跨智能体执行轨迹集合的目标和约束。为了学习最大化满足HyperLTL公式$\phi$的策略，我们应用Skolemization来管理量词交替，并定义量化鲁棒性函数来塑造具有未知转移的马尔可夫决策过程的执行轨迹上的奖励。然后使用合适的RL算法学习策略，以集体最大化预期奖励，从而增加满足$\phi$的概率。我们在多种基准上评估了HYPRL，包括安全感知规划、深海宝藏和邮政对应问题。我们还与规范驱动的基线进行了比较，以证明HYPRL的有效性和效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [334] [LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?](https://arxiv.org/abs/2501.18784)
> *LLM 生成的 AI 规划启发式：我们还需要领域独立性吗？*

*Alexander Tuisov, Yonatan Vernik, Alexander Shleyfman* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** LLM, AI规划, 启发式, 领域独立性, PDDL

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）可以为AI规划生成领域特定的启发式方法，这些方法在某些标准领域达到了最先进的性能，并能解决缺乏PDDL表示的问题，这挑战了领域独立性作为严格设计原则的必要性。

**AI_Comments:** 这篇论文具有创新性，因为它探索了LLM在AI规划中的新颖应用，特别是在生成启发式方法方面。它挑战了长期存在的领域独立性原则，这可能导致更灵活、更强大的规划系统，尤其适用于难以用PDDL形式化的问题。对权衡（效率、可解释性）的讨论对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 领域独立的启发式方法长期以来是AI规划的基石，但大型语言模型的出现提供了生成针对特定规划问题量身定制的启发式方法的可能性，这可能挑战了领域独立性作为严格设计原则的必要性。本文旨在探索这种可能性。

**Method:** 本文探索了使用LLM从以通用编程语言编写的后继生成器和目标测试表示的任务描述中自动推导规划启发式方法。研究调查了领域特定的LLM生成启发式方法与传统领域无关方法在计算效率和可解释性方面的权衡。

**Result:** 实验表明，LLM可以创建在某些标准IPC领域达到最先进性能的启发式方法。此外，它们还能够解决缺乏足够规划领域定义语言（PDDL）表示的问题。

**Conclusion:** 研究结果引发了关于LLM生成启发式方法是否预示着AI规划领域范式转变的讨论，以及它们如何能够补充现有方法，暗示严格的领域独立性可能不再是必需的。

> **ai_Abstract:** 本文研究了使用大型语言模型（LLM）为AI规划生成领域特定启发式方法，并将其与传统领域无关方法进行对比。研究探索了从通用编程语言的任务描述中推导启发式方法，并评估了效率和可解释性方面的权衡。实验结果表明，LLM生成的启发式方法在某些领域达到了最先进的性能，并能处理没有PDDL表示的问题，这预示着AI规划范式的潜在转变。

> **摘要翻译:** 领域无关的启发式方法长期以来一直是人工智能规划的基石，它提供适用于各种任务的通用解决方案，而无需领域特定的工程。然而，大型语言模型（LLM）的出现为生成针对特定规划问题量身定制的启发式方法提供了机会，这可能挑战了领域独立性作为严格设计原则的必要性。在本文中，我们探索使用LLM从以通用编程语言编写的后继生成器和目标测试表示的任务描述中自动推导规划启发式方法。我们研究了领域特定的LLM生成的启发式方法与传统领域无关方法在计算效率和可解释性方面的权衡。我们的实验表明，LLM可以创建在某些标准IPC领域达到最先进性能的启发式方法，并且它们能够解决缺乏足够规划领域定义语言（PDDL）表示的问题。我们讨论了这些结果是否预示着范式转变以及它们如何补充现有方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [337] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
> *基于UML序列图的工业代码生成数据依赖推理*

*Wenxin Mao, Zhitao Wang Long Wang, Sirong Chen, Cuiyun Gao, Luyang Cao, Ziming Liu, Qiming Zhang, Jun Zhou, Zhi Jin* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 代码生成, 数据依赖推理, UML序列图, 大型语言模型, 服务导向架构

**Comment:** 

> **TL;DR:** 本文提出了UML2Dep框架，通过增强UML序列图和数据依赖推理（DDI）来解决大型语言模型在从自然语言生成工业代码时面临的复杂需求和隐含数据依赖问题。

**AI_Comments:** 本文提出了一种结合形式化规范和LLM能力的新颖方法，以解决工业代码生成中自然语言描述的局限性。其创新点在于引入了增强型UML序列图和专门的数据依赖推理任务，将复杂逻辑和数据流显式化，从而弥补了LLM在处理隐含依赖方面的不足。该方法通过将DDI形式化为数学推理任务并结合静态分析，有望提高代码生成的准确性和可靠性，对工业级代码生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在从自然语言生成代码方面表现出色，但纯文本描述存在固有的模糊性，难以捕捉复杂的系统行为、条件逻辑和架构约束，尤其是在服务导向架构中难以正确推断和处理隐含的数据依赖性。

**Method:** 本文提出了一个名为UML2Dep的逐步代码生成框架。首先，引入了针对服务导向架构的增强型UML序列图，通过集成决策表和API规范来形式化结构关系和业务逻辑流，以消除语言模糊性。其次，引入了专门的数据依赖推理（DDI）任务，在代码合成之前系统地构建显式数据依赖图。DDI被形式化为受约束的数学推理任务，通过新颖的提示策略与LLM的数学优势相结合。额外的静态解析和依赖剪枝进一步降低了上下文复杂性和认知负荷，从而提高了推理准确性和效率。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了UML2Dep框架，旨在解决大型语言模型在工业代码生成中处理复杂需求和隐含数据依赖的挑战。该框架通过引入增强型UML序列图（集成决策表和API规范）来消除语言歧义，并提出了一个专门的数据依赖推理（DDI）任务，在代码生成前构建显式数据依赖图。DDI利用LLM的数学推理能力，并通过静态解析和依赖剪枝提高效率和准确性。

> **摘要翻译:** 大型语言模型（LLMs）擅长从自然语言（NL）描述生成代码。然而，纯文本描述固有的模糊性常常无法捕捉复杂的需求，例如复杂的系统行为、条件逻辑和架构约束；服务导向架构中隐含的数据依赖性难以推断和正确处理。为了弥合这一差距，我们提出了一个新颖的、基于UML序列图的逐步代码生成框架，名为UML2Dep，它利用明确的复杂需求形式化规范。首先，我们引入了一种为服务导向架构量身定制的增强型统一建模语言（UML）序列图。该图通过集成决策表和API规范扩展了传统的视觉语法，明确地形式化了服务交互中的结构关系和业务逻辑流，以严格消除语言歧义。其次，认识到数据流的关键作用，我们引入了一个专门的数据依赖推理（DDI）任务。DDI在实际代码合成之前系统地构建一个显式的数据依赖图。为了确保可靠性，我们通过新颖的提示策略将DDI形式化为受约束的数学推理任务，这与LLM卓越的数学能力相符。额外的静态解析和依赖剪枝进一步减少了与复杂规范相关的上下文复杂性和认知负荷，从而提高了推理的准确性和效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [345] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
> *Agent Lightning：使用强化学习训练任何AI智能体*

*Xufang Luo, Yuge Zhang, Zhiyuan He, Zilong Wang, Siyun Zhao, Dongsheng Li, Luna K. Qiu, Yuqing Yang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 强化学习, AI智能体, 大型语言模型, Agent Lightning, 解耦训练

**Comment:** 

> **TL;DR:** Agent Lightning是一个灵活可扩展的框架，通过强化学习（RL）实现大型语言模型（LLM）的AI智能体训练，它将智能体执行与训练完全解耦，并引入了分层RL算法和训练-智能体分离架构，实验证明其在多个任务上能实现稳定持续的改进。

**AI_Comments:** Agent Lightning的创新之处在于其对智能体执行与强化学习训练的完全解耦，这大大降低了RL训练现有AI智能体的门槛。其统一的数据接口和分层RL算法（LightningRL）能够有效处理复杂交互逻辑，如多智能体和动态工作流，这对于RL在复杂真实世界场景中的应用至关重要。该框架通过整合智能体可观察性框架，提供标准化微调接口，进一步提升了实用性。其在多任务上的持续改进证明了其有效性和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法将强化学习训练与智能体紧密耦合，或依赖于带掩码的序列拼接，这限制了现有智能体与RL训练的集成。本文旨在提供一个解耦的、通用的RL训练框架，以训练任何AI智能体。

**Method:** 本文提出了Agent Lightning框架，它通过将智能体执行表述为马尔可夫决策过程，实现了智能体执行与训练的完全解耦。提出了一个统一的数据接口和分层强化学习算法LightningRL，该算法包含一个信用分配模块，可以将任何智能体生成的轨迹分解为训练转换。系统设计引入了训练-智能体分离架构，并将智能体可观察性框架引入智能体运行时，提供标准化智能体微调接口。

**Result:** 在文本到SQL、检索增强生成和数学工具使用任务上的实验表明，Agent Lightning实现了稳定、持续的改进。

**Conclusion:** Agent Lightning框架通过其解耦设计、统一数据接口和分层强化学习算法，能够有效地使用强化学习训练和部署各种AI智能体，并在实际任务中展现出潜力。

> **ai_Abstract:** Agent Lightning是一个创新的强化学习框架，旨在解决大型语言模型（LLM）驱动的AI智能体训练中RL与智能体执行紧密耦合的问题。它通过完全解耦智能体执行与RL训练，并引入统一数据接口、分层RL算法（LightningRL）和训练-智能体分离架构，实现了对现有智能体的无缝集成和RL训练，几乎无需代码修改。实验证明，该框架在文本到SQL、检索增强生成和数学工具使用等复杂任务上均能实现稳定且持续的性能提升，展现了其在实际智能体训练和部署中的巨大潜力。

> **摘要翻译:** 我们提出了Agent Lightning，一个灵活且可扩展的框架，它能够为任何AI智能体实现基于强化学习（RL）的大型语言模型（LLM）训练。与现有方法将RL训练与智能体紧密耦合或依赖带掩码的序列拼接不同，Agent Lightning实现了智能体执行与训练的完全解耦，允许与通过各种方式（例如，使用LangChain、OpenAI Agents SDK、AutoGen等框架以及从头构建）开发的现有智能体无缝集成，几乎无需代码修改。通过将智能体执行表述为马尔可夫决策过程，我们定义了一个统一的数据接口，并提出了一种分层RL算法——LightningRL，其中包含一个信用分配模块，使我们能够将任何智能体生成的轨迹分解为训练转换。这使得RL能够处理复杂交互逻辑，例如多智能体场景和动态工作流。在系统设计方面，我们引入了训练-智能体分离架构，并将智能体可观察性框架引入智能体运行时，提供了一个标准化的智能体微调接口。在文本到SQL、检索增强生成和数学工具使用任务上的实验表明，该框架实现了稳定、持续的改进，展示了其在实际智能体训练和部署方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [362] [REALM-Bench: A Benchmark for Evaluating Multi-Agent Systems on Real-world, Dynamic Planning and Scheduling Tasks](https://arxiv.org/abs/2502.18836)
> *REALM-Bench：一个用于评估多智能体系统在真实世界动态规划和调度任务中的基准*

*Longling Geng, Edward Y. Chang* | **Category: cs.AI, I.2.11** | **Updated: 2025-08-05**

**Keywords:** 多智能体系统, 规划, 调度, 基准, LLMs

**Comment:** 24 pages, 8 figures, 28 tables, 7 listings

> **TL;DR:** REALM-Bench是一个新的基准套件，旨在评估大型语言模型（LLMs）和多智能体系统在真实世界动态规划和调度任务中的表现，提供可扩展的复杂问题和多种评估工具。

**AI_Comments:** 这项工作具有重要意义，因为它填补了评估多智能体系统在真实世界、动态规划和调度任务中性能的空白。其创新之处在于提供了可扩展的复杂性维度和全面的基线实现，这对于推动AI规划领域的进步至关重要。该基准的开放性也促进了社区协作和标准化评估。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是提供一个全面的评估框架，用于评估大型语言模型（LLMs）和多智能体系统在真实世界的规划和调度场景中的能力，以推动开发更具适应性、鲁棒性和可扩展性的AI规划系统。

**Method:** REALM-Bench基准套件包含14个从基础到高度复杂的规划和调度问题，整合了多智能体协调、智能体间依赖性以及动态环境干扰等关键方面。每个问题都可以在三个维度上进行扩展：并行规划线程的数量、相互依赖的复杂性以及需要实时适应的意外干扰的频率。该基准包括详细的问题规范、15种比较方法（如Random, LPT, SPT等）、2种以上评估指标，以及使用3种以上LLMs（包括GPT-4o, Claude-3.7, DeepSeek-R1）和4种当代框架（包括LangGraph, AutoGen, CrewAI, Swarm）的基线实现，以严格测试单智能体和多智能体的规划能力。

**Result:** Not mentioned in abstract

**Conclusion:** 通过标准化评估标准和可扩展的复杂性，REALM-Bench基准旨在向公众开放，并推动开发更具适应性、鲁棒性和可扩展性的AI规划系统，以应对真实世界应用的需求。

> **ai_Abstract:** REALM-Bench是一个新颖的基准套件，专为评估大型语言模型（LLMs）和多智能体系统在复杂、动态的真实世界规划与调度任务中的性能而设计。它提供了14个可扩展的问题，涵盖多智能体协调、依赖性及动态干扰等关键要素。该基准包含详细问题规范、多种比较方法、评估指标，并提供了基于主流LLMs和多智能体框架的基线实现，旨在通过标准化评估推动AI规划系统在真实世界应用中的发展。

> **摘要翻译:** 该基准套件提供了一个全面的评估框架，用于评估单个大型语言模型（LLMs）和多智能体系统在真实世界规划和调度场景中的表现。该套件包含14个从基础到高度复杂设计的规划和调度问题，其中融入了多智能体协调、智能体间依赖以及动态环境干扰等关键方面。每个问题都可以沿三个维度进行扩展：并行规划线程的数量、相互依赖的复杂性以及需要实时适应的意外干扰的频率。该基准包括14个详细的问题规范、15种比较方法（包括Random、LPT、SPT、STPT、MPSR、DRL-Liu、GP、GEP、LSO、SPT/TWKR、DRL-Chen、DRL-Zhang）、2种以上评估指标，以及使用3种以上LLMs（包括GPT-4o、Claude-3.7、DeepSeek-R1）和4种当代框架（包括LangGraph、AutoGen、CrewAI、Swarm）的基线实现，从而能够对单智能体和多智能体规划能力进行严格测试。通过标准化的评估标准和可扩展的复杂性，该基准旨在向公众开放，并推动开发更具适应性、鲁棒性和可扩展的AI规划系统，以应对真实世界应用的需求。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [365] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
> *与大型语言模型的捉迷藏：一种用于隐蔽错误生成和自我改进诊断的对抗性游戏*

*Rui Zou, Mengqi Wei, Yutao Zhu, Jirong Wen, Xin Zhao, Jing Chen* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 错误诊断, 对抗性训练, 捉迷藏游戏, 数学推理

**Comment:** 

> **TL;DR:** 提出了一种名为“捉迷藏游戏”（HSG）的对抗性框架，通过动态生成隐蔽错误并进行诊断，显著提高了LLM的错误诊断能力。

**AI_Comments:** 该论文创新性地将对抗性训练引入到LLM的错误诊断领域，通过模拟“捉迷藏”的动态过程，有效解决了LLM难以从复杂错误中学习的问题。这种自我改进的诊断机制对于提升LLM的鲁棒性和可靠性具有重要意义。所发布的挑战性数据集也为后续研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在识别和诊断复杂错误方面仍然存在困难，主要原因是训练目标优先考虑正确答案，限制了其从错误中学习。现有方法多依赖浅层、静态错误，未能提升深度诊断能力。

**Method:** 提出“捉迷藏游戏”（HSG），一个动态对抗性框架，用于错误生成和诊断。HSG包含两个对抗角色：Sneaky（生成微妙、欺骗性推理错误）和Diagnosis（准确检测错误）。通过对抗性协同进化，增强错误隐蔽性和诊断精度。在数学问题解决任务上进行评估。

**Result:** 在多项数学推理任务上的实验表明，HSG显著提升了错误诊断能力，比GPT-4o等基线模型高出16.8%—31.4%的准确率。同时发布了一个具有挑战性的欺骗性错误和诊断标注数据集，作为未来研究的基准。

**Conclusion:** 通过对抗性协同进化，HSG能够有效地增强错误生成（隐蔽性）和错误诊断（精度）的能力，显著提高了LLM在复杂错误诊断方面的表现。研究还发布了一个新的基准数据集。

> **ai_Abstract:** 该论文提出了一种名为“捉迷藏游戏”（HSG）的动态对抗性框架，旨在解决大型语言模型（LLMs）在复杂错误诊断方面的不足。HSG通过让“Sneaky”角色生成隐蔽的欺骗性错误，同时让“Diagnosis”角色检测这些错误，实现错误生成和诊断能力的协同进化。实验结果显示，HSG显著提高了LLM在数学推理任务上的错误诊断准确率，性能优于现有基线模型。此外，研究还发布了一个新的错误诊断数据集以促进未来研究。

> **摘要翻译:** 大型语言模型（LLMs）在跨领域的推理和生成方面表现出色，但在识别和诊断复杂错误方面仍面临挑战。这主要源于训练目标优先考虑正确答案，限制了其接触和从错误中学习的机会。尽管最近的研究已开始通过引入错误信号来解决这个问题，但大多数依赖于浅层、静态错误，限制了深度诊断能力的提升。为了克服这一点，我们提出了“捉迷藏游戏”（Hide and Seek Game, HSG），一个用于错误生成和诊断的动态对抗性框架，并在数学问题解决方面进行了评估。HSG涉及两个对抗性角色：Sneaky，通过生成微妙、欺骗性的推理错误来“隐藏”；Diagnosis，通过准确检测这些错误来“寻找”。通过对抗性协同进化，错误隐蔽性和诊断精度都得到了提高。在多项数学推理任务上的实验表明，HSG显著提升了错误诊断能力，比GPT-4o等基线模型高出16.8%—31.4%的准确率。我们还发布了一个具有挑战性的欺骗性错误和诊断标注数据集，作为未来研究的基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [382] [Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments](https://arxiv.org/abs/2505.19361)
> *基于一致性的溯因推理，用于处理新颖环境中多个预训练模型的感知错误*

*Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran, Gerardo Simari* | **Category: cs.AI, cs.CV, cs.LG, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 基于一致性的溯因, 预训练模型, 分布偏移, 感知错误, 多模型集成

**Comment:** 

> **TL;DR:** 本文提出了一种基于一致性的溯因推理框架，用于整合多个预训练模型的预测，以应对新颖环境下的分布偏移导致的性能下降，并显著提高了F1分数和准确性。

**AI_Comments:** 本文的创新点在于将基于一致性的溯因推理应用于测试时，以有效整合多个预训练模型的知识，解决新颖环境中因分布偏移导致的感知错误。其重要性在于提供了一种鲁棒的方法来提高模型在实际部署中的性能，尤其是在面对不确定性和不完善信息时。虽然在模拟数据集上取得了显著成果，但其在真实复杂环境中的泛化能力和计算效率仍值得进一步探究。

<details>
  <summary>Details</summary>

**Motivation:** 预训练感知模型在新颖环境中部署时，常因分布偏移导致性能下降。尽管现有元认知方法使用逻辑规则来表征和过滤模型错误，但提高精度通常以牺牲召回率为代价。本文旨在通过利用多个预训练模型来缓解召回率降低的问题。

**Method:** 将识别和管理来自不同模型的冲突预测表述为基于一致性的溯因问题，借鉴溯因学习的思想但应用于测试时。将输入预测和从每个模型中导出的错误检测规则编码为逻辑程序。目标是寻找一个溯因解释（模型预测的子集），使其最大化预测覆盖率，同时确保逻辑不一致率低于指定阈值。提出了两种知识表示算法：基于整数规划（IP）的精确方法和高效的启发式搜索（HS）。

**Result:** 在模拟航空图像数据集上的广泛实验表明，该溯因框架优于单个模型和标准集成基线。与最佳单个模型相比，在15个不同的测试数据集上，F1分数平均相对提高了约13.6%，准确性平均相对提高了约16.6%。研究结果验证了基于一致性的溯因推理作为一种有效机制，能够在新颖的挑战性场景中鲁棒地整合来自多个不完善模型的知识。

**Conclusion:** 研究结果验证了基于一致性的溯因推理是一种有效机制，能够在新颖的挑战性场景中鲁棒地整合来自多个不完善模型的知识。

> **ai_Abstract:** 本文针对预训练模型在新颖环境中因分布偏移导致的性能下降问题，提出了一种基于一致性的溯因推理框架。该框架旨在通过整合多个预训练模型的预测来缓解现有元认知方法中精度提升导致召回率下降的问题。研究将管理冲突预测表述为溯因问题，并将其应用于测试时，通过逻辑程序编码预测和错误检测规则，旨在最大化预测覆盖率并控制逻辑不一致性。为此，提出了整数规划和启发式搜索两种算法。实验证明，该方法在模拟航空图像数据集上显著优于单个模型和标准集成基线，在F1分数和准确性上均取得了显著提升，验证了其在新颖场景中整合不完善模型知识的有效性。

> **摘要翻译:** 预训练感知模型在新颖环境中部署时，常因分布偏移导致性能下降。尽管最近用于元认知的AI方法使用逻辑规则来表征和过滤模型错误，但提高精度通常以牺牲召回率为代价。本文探讨了利用多个预训练模型可以缓解这种召回率降低的假设。我们将识别和管理来自各种模型的冲突预测的挑战表述为一个基于一致性的溯因问题，该问题建立在溯因学习（ABL）的思想之上，但应用于测试时而非训练。输入预测和从每个模型中导出的学习到的错误检测规则被编码在一个逻辑程序中。然后，我们寻求一个溯因解释——模型预测的一个子集——以最大化预测覆盖率，同时确保逻辑不一致率（源自领域约束）保持在指定阈值以下。我们为此知识表示任务提出了两种算法：一种基于整数规划（IP）的精确方法和一种高效的启发式搜索（HS）。通过在模拟航空图像数据集上进行广泛实验，该数据集具有受控的复杂分布偏移，我们证明了我们的基于溯因的框架优于单个模型和标准集成基线，例如，与最佳单个模型相比，在15个不同的测试数据集上，F1分数平均相对提高了约13.6%，准确性平均相对提高了约16.6%。我们的结果验证了使用基于一致性的溯因推理作为一种有效机制，可以在具有挑战性的新颖场景中鲁棒地整合来自多个不完善模型的知识。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [390] [A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models](https://arxiv.org/abs/2503.23350)
> *WebAgents综述：迈向基于大型基础模型的下一代网络自动化AI代理*

*Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** WebAgents, 大型基础模型, AI代理, 网络自动化, 综述

**Comment:** This is the long version of the corresponding survey paper accepted
  by KDD 2025. The tutorial and corresponding slides are available at
  https://biglemon-ning.github.io/WebAgents/

> **TL;DR:** 该综述探讨了利用大型基础模型（LFMs）开发WebAgents以实现网络自动化的研究进展，涵盖了架构、训练、可信度以及未来研究方向。

**AI_Comments:** 这是一篇及时且重要的综述论文，它系统地梳理了WebAgents与大型基础模型结合的前沿研究。该论文的价值在于其对现有研究的全面回顾，特别是对架构、训练和可信度这三个关键维度的深入剖析，并为未来研究指明了方向，对于推动基于LLM的网络自动化领域发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多网络任务重复且耗时，降低了生活质量和生产力。为了高效处理这些繁琐的任务，利用AI代理（WebAgents）进行自动化是一个有前景的方法。随着大型基础模型（LFMs）展现出类人语言理解和推理能力，它们有望被用于开发强大的WebAgents，从而显著提升用户便利性。

**Method:** 本文是一篇综述，全面回顾了WebAgents的现有研究，重点关注其架构、训练方法和可信度。此外，还探讨了几个有前景的未来研究方向。

**Result:** 该综述全面审视了WebAgents在架构、训练和可信度方面的现有研究，并提出了未来研究的潜在方向，以期提供更深入的见解。

**Conclusion:** 大型基础模型（LFMs）在开发能够自动化网络任务的下一代WebAgents方面具有巨大潜力。本综述通过梳理现有研究并指出未来方向，为推动这一领域的发展提供了全面的视角。

> **ai_Abstract:** 该综述论文回顾了利用大型基础模型（LFMs）开发WebAgents以实现网络自动化和提升生产力的现有研究。它系统地分析了WebAgents的架构、训练方法和可信度，并探讨了未来的研究方向，以应对网络任务的重复性和耗时性挑战。

> **摘要翻译:** 随着网络技术的进步，它们极大地改变了人们生活的各个方面。尽管网络的重要性日益凸显，但许多在网络上执行的任务却是重复且耗时的，这负面影响了整体生活质量。为了高效处理这些繁琐的日常任务，最有前景的方法之一是推进基于人工智能（AI）技术的自主代理，即AI代理，因为它们可以持续运行而不会感到疲劳或性能下降。在网络环境中，利用AI代理——被称为WebAgents——自动协助人们处理繁琐的日常任务，可以显著提高生产力和效率。最近，包含数十亿参数的大型基础模型（LFMs）展现出类人语言理解和推理能力，在执行各种复杂任务方面表现出色。这自然引出了一个问题：‘LFMs能否被用于开发强大的AI代理，自动处理网络任务，为用户提供显著便利？’为了充分探索LFMs的潜力，大量研究已经涌现，专注于设计WebAgents以根据用户指令完成日常网络任务，从而显著提高人类日常生活的便利性。在本综述中，我们从三个关键方面全面回顾了WebAgents的现有研究：架构、训练和可信度。此外，还探讨了几个有前景的未来研究方向，以提供更深入的见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [407] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
> *使用大型语言模型对路由问题进行多目标不可行性诊断*

*Kai Li, Ruihao Zheng, Xinye Hao, Zhenkun Wang* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 路由问题, 不可行性诊断, 大型语言模型, 多目标优化

**Comment:** 

> **TL;DR:** 本文提出MOID框架，结合大型语言模型和多目标优化，为路由问题中的不可行模型提供多样化且实用的诊断建议，以恢复模型可行性。

**AI_Comments:** 本文的创新点在于将多目标优化与大型语言模型相结合，解决了现有LLM方法在诊断不可行模型时未能考虑多种潜在调整的局限性。通过生成一系列权衡解决方案并利用LLM进行分析，MOID能提供更全面和实用的诊断建议，对于实际路由问题中的决策支持具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在现实路由问题中，用户常提出冲突或不合理的需求，导致优化模型因限制过多或矛盾约束而不可行。现有基于LLM的方法在诊断不可行模型时，未考虑模型修改可能涉及的多种潜在调整。

**Method:** 本文引入多目标不可行性诊断（MOID），它在一个自动路由求解器中结合了LLM代理和多目标优化。MOID采用多目标优化同时考虑路径成本和约束违反，生成一组权衡解决方案。随后，MOID利用LLM代理为不可行模型生成解决方案分析函数，分析这些方案以诊断原始不可行模型，从而为用户提供多样化的诊断见解和建议。

**Result:** MOID在50种不可行路由问题类型上与现有LLM方法进行比较。结果表明，MOID在单次运行中自动生成多个诊断建议，与现有方法相比，为恢复模型可行性和决策提供了更实用的见解。

**Conclusion:** MOID通过结合LLM和多目标优化，能有效且全面地诊断路由问题中的不可行模型，提供多样化且实用的调整建议，优于现有方法。

> **ai_Abstract:** 本文提出多目标不可行性诊断（MOID）框架，旨在解决路由问题中因冲突或过度限制的约束导致的模型不可行性。MOID结合大型语言模型（LLM）代理和多目标优化，能够同时考虑路径成本和约束违反，生成一系列权衡解决方案。通过LLM代理分析这些方案，MOID为用户提供多样化且可操作的诊断见解和建议，以恢复模型的有效性。实验结果表明，MOID在提供更实用和全面的诊断建议方面优于现有基于LLM的方法。

> **摘要翻译:** 在现实世界的路由问题中，用户经常提出相互冲突或不合理的要求，这导致优化模型因限制过多或相互矛盾的约束而变得不可行，从而导致可行解集为空。现有基于大型语言模型（LLM）的方法试图诊断不可行模型，但修改这些模型通常涉及多种潜在调整，而这些方法并未考虑。为了填补这一空白，我们引入了多目标不可行性诊断（MOID），它在一个自动路由求解器中结合了LLM代理和多目标优化，以提供一组具有代表性的可操作建议。具体来说，MOID采用多目标优化来同时考虑路径成本和约束违反，生成一组权衡解决方案，每个方案都包含不同程度的模型调整。为了从这些解决方案中提取实际见解，MOID利用LLM代理为不可行模型生成一个解决方案分析函数。该函数分析这些不同的解决方案，以诊断原始不可行模型，为用户提供多样化的诊断见解和建议。最后，我们将MOID与几种基于LLM的方法在50种类型的不可行路由问题上进行了比较。结果表明，MOID在单次运行中自动生成多个诊断建议，与现有方法相比，为恢复模型可行性和决策提供了更实用的见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [418] [Genetic Programming with Reinforcement Learning Trained Transformer for Real-World Dynamic Scheduling Problems](https://arxiv.org/abs/2504.07779)
> *基于强化学习训练的Transformer与遗传编程结合解决真实世界动态调度问题*

*Xinan Chen, Rong Qu, Jing Dong, Ruibin Bai, Yaochu Jin* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 遗传编程, 强化学习, Transformer, 动态调度, 集装箱码头调度

**Comment:** 

> **TL;DR:** 本文提出GPRT方法，结合遗传编程与强化学习训练的Transformer，有效解决真实世界动态调度问题，并在集装箱码头卡车调度中表现优异。

**AI_Comments:** 该研究创新性地结合了遗传编程和强化学习训练的Transformer，解决了传统调度方法在动态环境适应性差的痛点。GPRT方法不仅在特定应用中表现出色，还强调了其通用性、可解释性和易修改性，使其在实际应用中具有重要价值。这种混合范式为动态调度领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统静态调度方法和人工设计的启发式方法难以适应现实世界动态调度中不可预见的干扰。

**Method:** 提出GPRT（Genetic Programming with Reinforcement Learning Trained Transformer）方法，利用Transformer优化GP生成的启发式算法，并引导GP的演化。

**Result:** GPRT方法在集装箱码头卡车调度中优于传统GP、独立的Transformer方法和其他现有先进方法。

**Conclusion:** GPRT方法结合了GP和强化学习，能生成鲁棒高效的调度解决方案，且具有通用性、可解释性和易修改性，适用于多种真实世界动态调度挑战。

> **ai_Abstract:** 本文提出GPRT（Genetic Programming with Reinforcement Learning Trained Transformer）方法，旨在解决真实世界动态调度中传统方法适应性差的问题。GPRT结合遗传编程和强化学习训练的Transformer，利用Transformer优化并指导遗传编程生成的启发式算法，从而增强调度解决方案的适应性和有效性。该方法在集装箱码头卡车调度应用中展现出优于现有方法的性能，并被认为是一个通用、鲁棒、高效且易于修改的动态调度框架。

> **摘要翻译:** 现实世界环境中的动态调度常常难以适应不可预见的干扰，这使得传统的静态调度方法和人工设计的启发式算法显得不足。本文介绍了一种创新方法，将遗传编程（GP）与通过强化学习训练的Transformer（GPRT）相结合，专门用于解决动态调度场景的复杂性。GPRT利用Transformer来优化GP生成的启发式算法，同时为GP的演化提供种子和指导。这种双重功能增强了调度启发式算法的适应性和有效性，使其能更好地响应真实世界任务的动态性质。通过在集装箱码头卡车调度中的实际应用，证明了这种集成方法的有效性，其中GPRT方法优于传统GP、独立的Transformer方法和其他现有先进竞争对手。这项研究的关键贡献是开发了GPRT方法，展示了GP与强化学习（RL）的新颖组合，以产生鲁棒且高效的调度解决方案。重要的是，GPRT不限于集装箱港口卡车调度；它提供了一个通用的框架，适用于各种动态调度挑战。其实用性、可解释性和易修改性使其成为各种真实世界场景的宝贵工具。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [438] [Modeling Deontic Modal Logic in the s(CASP) Goal-directed Predicate Answer Set Programming System](https://arxiv.org/abs/2507.05519)
> *在s(CASP)目标导向谓词回答集编程系统中建模道义模态逻辑*

*Gopal Gupta, Abhiramon Rajasekharan, Alexis R. Tudor, Elmer Salazar, Joaquín Arias* | **Category: cs.AI, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 道义模态逻辑, 回答集编程, 默认否定, 悖论

**Comment:** 

> **TL;DR:** 本文展示了如何利用回答集编程（ASP）中的默认否定、强否定和全局约束来优雅地实现道义模态逻辑并解决其悖论。

**AI_Comments:** 本文的创新之处在于利用回答集编程（ASP）的特定特性（默认否定、强否定和全局约束）来建模道义模态逻辑。其重要性在于为解决道义模态逻辑中的悖论提供了一种优雅且实用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决道义模态逻辑的实现问题，并探索如何利用回答集编程（ASP）的特性来优雅地表达其模态算子和处理其固有的悖论。

**Method:** 作者利用回答集编程（ASP）中的默认否定（失败即否定）和强否定来表达（道义）模态算子，并提出使用ASP的全局约束来表示道义模态逻辑中的义务和禁止。

**Result:** 提出的表示方法能够优雅地解决道义模态逻辑的各种悖论。

**Conclusion:** 通过利用回答集编程（ASP）中默认否定、强否定和全局约束等特性，本文成功实现了道义模态逻辑，并有效解决了其固有的悖论。

> **ai_Abstract:** 本文探讨了道义模态逻辑的实现问题。作者提出利用回答集编程（ASP）中的默认否定、强否定以及全局约束来优雅地表达道义模态算子、义务和禁止。研究表明，该表示方法能够有效地解决道义模态逻辑中的各种悖论。

> **摘要翻译:** 我们考虑实现道义模态逻辑的问题。我们展示了如何利用回答集编程（ASP）中存在的默认否定（失败即否定）和强否定来优雅地表达（道义）模态算子。我们建议使用ASP的全局约束来表示道义模态逻辑的义务和禁止。我们表明，我们提出的表示方法能够优雅地解决道义模态逻辑的各种悖论。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [446] [A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems](https://arxiv.org/abs/2504.09037)
> *LLM推理前沿综述：推理扩展、学习推理和智能体系统*

*Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, Caiming Xiong, Shafiq Joty* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** LLM推理, 推理扩展, 学习推理, 智能体系统, 综述

**Comment:** 72 pages, 6 figures. Accepted to TMLR, with Survey Certification
  award

> **TL;DR:** 本综述系统地分类并分析了大型语言模型（LLM）推理的现有方法，主要围绕推理时机（推理时或训练时）和系统架构（独立LLM或智能体系统）两个维度，并强调了新兴趋势。

**AI_Comments:** 本综述为理解大型语言模型推理这一快速发展的领域提供了一个宝贵的结构化框架。其按“机制”和“架构”进行的分类为分析各种方法提供了清晰的视角。对输入和输出层面技术以及学习算法和智能体工作流的全面覆盖，使其成为研究人员和实践者的重要资源。其对向学习推理和智能体系统转变等关键趋势的识别尤具洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）的快速发展，推理已成为区分先进人工智能系统与传统模型的关键能力。本综述旨在对LLM推理领域不断演进的格局进行系统性理解和分类。

**Method:** 本综述将现有方法分为两个正交维度：1)“机制”，定义推理实现的阶段（推理时或通过专门训练）；2)“架构”，区分独立LLM和包含外部工具及多智能体协作的智能体复合系统。在这两个维度内，分析了“输入层面”（高质量提示构建）和“输出层面”（精炼采样候选以增强推理质量）两个关键视角。此外，还涵盖了从有监督微调到强化学习（如PPO、GRPO）的广泛学习算法，以及推理器和验证器的训练，并考察了智能体工作流的关键设计。

**Result:** 本综述的分类方法提供了对LLM推理不断发展格局的系统理解，并突出了新兴趋势，例如从推理扩展到学习推理的转变（如DeepSeek-R1），以及向智能体工作流的过渡（如OpenAI Deep Research，Manus Agent）。

**Conclusion:** 本综述通过其系统性的分类和分析，为理解LLM推理的演进格局提供了清晰的视角，并揭示了该领域向学习推理和智能体工作流发展的关键趋势。

> **ai_Abstract:** 本综述全面概述了LLM推理的前沿领域。它根据推理机制（推理时或训练时）和系统架构（独立LLM或智能体系统）两个维度，系统地对现有方法进行了分类。在此基础上，它分析了输入层面的提示技术和输出层面的精炼方法。该综述强调了从推理扩展到学习推理以及智能体工作流兴起等新兴趋势，并涵盖了各种学习算法和智能体系统设计。

> **摘要翻译:** 推理是一种基本的认知过程，它能够实现逻辑推理、问题解决和决策制定。随着大型语言模型（LLMs）的快速发展，推理已成为区分先进人工智能系统与赋能聊天机器人的传统模型的关键能力。在本综述中，我们根据两个正交维度对现有方法进行分类：（1）“机制”，定义了实现推理的阶段（在推理时或通过专门训练）；（2）“架构”，决定了推理过程中涉及的组件，区分了独立的LLM和包含外部工具以及多智能体协作的智能体复合系统。在每个维度内，我们分析了两个关键视角：（1）“输入层面”，侧重于构建高质量提示的技术，LLM在此基础上进行条件推理；（2）“输出层面”，侧重于通过精炼多个采样候选来增强推理质量的方法。这种分类提供了对LLM推理不断发展格局的系统理解，突出了新兴趋势，例如从推理扩展到学习推理的转变（例如DeepSeek-R1），以及向智能体工作流的过渡（例如OpenAI Deep Research，Manus Agent）。此外，我们涵盖了广泛的学习算法，从有监督微调到强化学习，如PPO和GRPO，以及推理器和验证器的训练。我们还研究了智能体工作流的关键设计，从生成器-评估器和LLM辩论等既定模式到最新创新。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [449] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
> *数据过载？是时候来一次“四重奏”了：使用增强三元组提取构建知识图谱*

*Taine J. Elliott, Stephen P. Levitt, Ken Nixon, Martin Bekker* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 知识图谱, 三元组提取, LLM, 生物医学数据, 四元组

**Comment:** 18 pages, 8 figures, Published in the Annual Conference of South
  African Institute of Computer Scientists and Information Technologists,
  Preprint (author original)

> **TL;DR:** 本文提出了一种利用大型语言模型（LLM）代理构建知识图谱的方法，通过增强三元组（“四元组”）提取生物医学知识，并验证了其准确性。

**AI_Comments:** 这项研究的创新之处在于引入了“四元组”概念，即在传统三元组基础上增加了上下文变量，使其能够独立表达更完整的语义信息。这对于构建更丰富、更精确的知识图谱具有重要意义。此外，利用LLM代理进行信息提取和知识图谱构建，展示了LLM在处理复杂、海量生物医学文本方面的潜力。该方法有望缓解医学信息过载问题，为医学研究和临床实践提供更高效的知识获取途径。

<details>
  <summary>Details</summary>

**Motivation:** 公开可用的医学数据快速增长，导致科学文献数量与实际应用之间的差距扩大，使医学专业人员难以系统地回顾和理解最新知识。

**Method:** 该研究提出了一种信息提取和自动知识图谱（KG）生成方法，用于识别和连接生物医学知识。通过大型语言模型（LLM）代理的管道，系统将44篇PubMed摘要分解为语义命题句，并从中提取KG三元组。这些三元组通过结合开放域和基于本体的信息提取方法进行增强，以纳入本体类别，并引入上下文变量使其成为“四元组”。

**Result:** 通过将增强三元组生成的自然语言句子与原始命题进行比较，验证了LLM的提取准确性，平均余弦相似度达到0.874。与普通三元组相比，增强三元组生成的句子相似度有所提高，这得益于上下文变量。此外，研究还探索了LLM推断新关系和连接知识图谱中知识库集群的能力。

**Conclusion:** 该方法为医学从业者提供了一个集中、实时更新且可持续的知识来源，并可能成为在各种领域取得类似进展的基础。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLM）代理构建生物医学知识图谱的新方法，旨在解决医学数据过载问题。该方法通过一个管道将PubMed摘要分解为命题句，并提取经过增强的三元组（称为“四元组”），其中加入了本体类别和上下文变量。实验结果表明，该LLM提取的准确性高，生成的句子与原始命题的平均余弦相似度为0.874，并且上下文变量的引入显著提高了生成句子的相似度。此外，研究还展示了LLM推断新关系的能力。这项工作为医学专业人员提供了一个可持续的知识来源，并有望推广到其他领域。

> **摘要翻译:** 公开可用的医学数据迅速膨胀，给临床医生和研究人员带来了挑战，加剧了科学文献数量与其实际应用之间的差距。研究和发现的稳步增长使广大医学专业人员不堪重负，阻碍了他们系统地审查和理解最新知识的能力。本文提出了一种信息提取和自动知识图谱（KG）生成方法，旨在识别和连接生物医学知识。通过大型语言模型（LLM）代理的管道，该系统将44篇PubMed摘要分解为具有语义意义的命题句，并从这些句子中提取KG三元组。这些三元组通过结合开放域和基于本体的信息提取方法进行增强，以纳入本体类别。在此基础上，提取过程中包含了一个上下文变量，使三元组能够独立存在——从而成为“四元组”。通过将增强三元组生成的自然语言句子与原始命题进行比较，验证了LLM的提取准确性，平均余弦相似度达到0.874。增强三元组生成的句子相似度与普通三元组生成的句子相似度进行了比较，结果显示由于上下文变量的引入而有所提高。此外，这项研究还探索了LLM推断新关系和连接知识图谱知识库中集群的能力。这种方法为医学从业者提供了一个集中、实时更新和可持续的知识来源，并可能成为在各种领域取得类似进展的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [474] [Antidistillation Sampling](https://arxiv.org/abs/2504.13146)
> *反蒸馏采样*

*Yash Savani, Asher Trockman, Zhili Feng, Avi Schwarzschild, Alexander Robey, Marc Finzi, J. Zico Kolter* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-04**

**Keywords:** 反蒸馏采样, 模型蒸馏, 推理轨迹, 令牌序列, 概率分布

**Comment:** 

> **TL;DR:** 一种名为“反蒸馏采样”的新方法通过策略性修改模型输出的令牌序列，使其对模型蒸馏无效，同时保持原始模型的性能。

**AI_Comments:** 这项研究的创新之处在于提出了一种主动防御模型蒸馏的方法。通过“毒化”推理轨迹，它提供了一种保护模型知识产权的新颖途径，而不仅仅是依赖于传统的数据保护或模型加密。这对于保护大型语言模型等前沿模型的商业价值和防止未经授权的知识转移具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 前沿模型生成的推理轨迹包含了丰富的令牌序列，这些序列可能被用于模型蒸馏，从而对模型所有者构成潜在的漏洞。因此，模型所有者需要一种采样策略，能够在不损害模型性能的前提下，限制蒸馏的有效性。

**Method:** 反蒸馏采样通过策略性地修改模型的下一个令牌概率分布来实现。这种方法能够“毒化”推理轨迹，使其对蒸馏的有效性显著降低。

**Result:** 反蒸馏采样能够使推理轨迹对蒸馏的有效性显著降低，同时保持模型的实际实用性。

**Conclusion:** 反蒸馏采样提供了一种有效的能力，可以限制模型蒸馏的有效性，同时不损害模型本身的性能。

> **ai_Abstract:** 本文介绍了一种名为“反蒸馏采样”的新方法，旨在解决前沿模型生成的推理轨迹易于被用于模型蒸馏的漏洞。该方法通过策略性地修改模型的下一个令牌概率分布，对推理轨迹进行“毒化”，使其对蒸馏的有效性显著降低，但同时保留了模型的实际性能和实用性。这为模型所有者提供了一种在不影响模型表现的前提下，限制其被蒸馏风险的策略。

> **摘要翻译:** 前沿模型在生成扩展推理轨迹时，无意中产生了丰富的令牌序列，这些序列可以促进模型蒸馏。认识到这一漏洞，模型所有者可能会寻求一种采样策略，在不损害模型性能的情况下限制蒸馏的有效性。反蒸馏采样正提供了这种能力。通过策略性地修改模型的下一个令牌概率分布，反蒸馏采样毒化了推理轨迹，使其对蒸馏的有效性显著降低，同时保留了模型的实际实用性。欲了解更多详情，请访问 https://antidistillation.com。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [498] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
> *走向信念的图论模型：置信度、可信度和结构一致性*

*Saleh Nikooroo* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 图论模型, 信念系统, 置信度, 可信度, 结构一致性

**Comment:** 

> **TL;DR:** 本文提出一个纯静态的图论模型来表示信念系统，通过区分置信度与可信度，克服了现有概率和逻辑模型在处理信念内部结构、碎片化和矛盾状态方面的局限性，并能实现更丰富的认知状态分类。

**AI_Comments:** 这项工作通过引入一个纯粹的、静态的图论框架来建模信念，具有显著的创新性。它解决了现有模型在表示信念内部结构、碎片化和矛盾状态方面的核心限制，特别是在区分外部可信度和内部置信度方面。这种方法为理解复杂认知状态提供了一个新的、更细粒度的分析基础，为未来研究信念动力学和推理机制奠定了基石。

<details>
  <summary>Details</summary>

**Motivation:** 现有信念系统模型（如全局一致的命题集或标量概率分布）无法揭示信念的内部结构，混淆了外部可信度与内部一致性，且无法建模碎片化或矛盾的认知状态。

**Method:** 本文提出一种将信念系统建模为有向加权图的最小形式主义。图中节点代表个体信念，边编码认知关系（支持或矛盾），并通过两个独立函数分别赋予信念“可信度”（源于信任）和“置信度”（源于内部结构支持）。该模型纯粹静态，不假设先验一致性，不进行信念更新、推理或修订。

**Result:** 该模型提供了一个分析信念系统内部组织（包括一致性条件、认知张力、表征限制）的基础，并通过区分信念结构和信念强度，实现了比现有概率、逻辑或基于论证方法更丰富的认知状态分类。

**Conclusion:** 该图论模型通过清晰区分信念的内部结构和强度，能够更深入地分析和分类复杂的认知状态，克服了传统模型在处理信念内部结构和矛盾方面的局限性。

> **ai_Abstract:** 本文提出一种新颖的图论模型来表示信念系统，旨在克服现有概率和逻辑模型在处理信念内部结构、碎片化和矛盾状态方面的局限性。该模型将信念表示为图中的节点，认知关系为边，并引入独立的可信度（源于来源信任）和置信度（源于内部结构支持）函数。它是一个静态模型，不依赖于先验一致性或信念更新机制，主要用于分析信念系统的内部组织和认知状态，从而实现比传统方法更丰富的分类。

> **摘要翻译:** 信念系统通常被视为全局一致的命题集合或标量概率分布。此类表示倾向于模糊信念的内部结构，混淆外部可信度与内部一致性，并排除了对碎片化或矛盾认知状态的建模。本文引入了一种将信念系统表示为有向加权图的最小形式主义。在此框架中，节点代表个体信念，边编码认知关系（例如，支持或矛盾），并且两个不同的函数分别赋予每个信念一个可信度（反映来源信任）和一个置信度（源于内部结构支持）。与经典概率模型不同，我们的方法不假设先验一致性或要求信念更新。与逻辑和基于论证的框架不同，它支持细粒度的结构表示，而不必承诺二进制的合理性状态或演绎闭包。该模型纯粹是静态的，并刻意排除了推理或修订程序。其目的是为分析信念系统的内部组织提供一个基础性基质，包括一致性条件、认知张力以及表示限制。通过区分信念结构与信念强度，这种形式主义使得比现有概率、逻辑或基于论证的方法能实现更丰富的认知状态分类。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [502] [UFEval: Unified Fine-grained Evaluation with Task and Aspect Generalization](https://arxiv.org/abs/2505.12795)
> *UFEval：具有任务和方面泛化能力的统一细粒度评估*

*Shibo Hong, Jiahao Ying, Haiyuan Liang, Mengdi Zhang, Jun Kuang, Jiazheng Zhang, Yixin Cao* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 统一评估,细粒度评估,多模态模型,方面泛化,任务泛化

**Comment:** 

> **TL;DR:** UFEval是一个统一的细粒度评估器，通过学习特定方面来泛化到未见方面，并通过联合学习评估多模态任务和方面实现相互促进。

**AI_Comments:** UFEval的创新之处在于其提出了统一细粒度评估框架，并强调了方面泛化和任务协同学习的重要性。通过构建大规模、多模态的FRABench数据集，为评估器训练提供了宝贵的资源。这项工作对于推动大型多模态模型评估的自动化和精细化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型多模态模型的能力、任务多样性和模态的迅速扩展，评估其开放式输出已成为瓶颈。现有的“LLM即评委”评估器通常在特定任务和方面上过于狭窄。

**Method:** 本文提出了UFEval，这是第一个具有任务和方面泛化能力的统一细粒度评估器，适用于自然语言生成、图像理解、图像生成和图文交错生成四种评估任务。具体方法包括：1) 构建了一个包含112个不同方面的分层方面分类法。2) 基于此分类法，创建了FRABench，一个包含60.4k对样本和325k评估标签的细粒度评估数据集，结合了人工和GPT-4o标注。3) 利用FRABench开发了UFEval。

**Result:** 实验表明，在特定方面上的学习使UFEval能够泛化到未见方面，并且联合学习评估不同任务和方面可以带来实质性的相互益处。

**Conclusion:** UFEval通过其统一的细粒度评估框架和对任务与方面泛化的能力，有效解决了大型多模态模型评估中的瓶颈问题，并展示了多任务多方面联合学习的优势。

> **ai_Abstract:** 本文提出了UFEval，一个旨在解决大型多模态模型开放式输出评估瓶颈的统一细粒度评估器。它通过构建一个包含112个方面的分层分类法和创建FRABench数据集（结合人工和GPT-4o标注的60.4k对样本），实现了任务和方面的泛化。实验证明，UFEval能够泛化到未见方面，并且多任务多方面的联合学习能带来显著益处。

> **摘要翻译:** UFEval：具有任务和方面泛化能力的统一细粒度评估

大型多模态模型的开放式输出评估已成为瓶颈，因为模型能力、任务多样性和模态正在迅速扩展。现有的“LLM即评委”评估器通常在特定任务和方面上过于狭窄。在本文中，我们认为，一方面，基于方面互联的性质，学习特定方面可以泛化到未见方面；另一方面，联合学习评估多个视觉方面和任务可能会促进协同效应。为此，我们提出了UFEval，这是第一个具有任务和方面泛化能力的统一细粒度评估器，适用于四种评估任务——自然语言生成、图像理解、图像生成和图文交错生成。具体而言，(1) 我们首先构建了一个分层方面分类法，涵盖了上述四项任务中的112个不同方面。(2) 然后，在此分类法的基础上，我们创建了FRABench，一个细粒度评估数据集，包含60.4k对样本和325k评估标签，这些标签通过人工和GPT-4o标注相结合的方式获得。FRABench为训练和测试评估器提供了大规模、多模态和方面级别的资源。(3) 最后，利用FRABench，我们开发了UFEval，一个统一的细粒度评估器。实验表明，在特定方面上的学习使UFEval能够泛化到未见方面，并且联合学习评估不同任务和方面可以带来实质性的相互益处。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [529] [Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory](https://arxiv.org/abs/2505.17696)
> *增强AI系统弹性：基于控制理论的LSTM弹性公式化与保证*

*Sota Yoshihara, Ryosuke Yamamoto, Hiroyuki Kusumoto, Masanari Shimura* | **Category: cs.AI, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** LSTM弹性, 控制理论, 恢复时间, $\delta$ISS, AI系统弹性

**Comment:** 9 pages, 6 figures. Appendix: 16 pages. First three listed authors
  have equal contributions

> **TL;DR:** 本文提出一种基于控制理论的LSTM弹性框架，引入“恢复时间”并利用$\delta$ISS理论，实现弹性感知训练，并在简单模型上验证。

**AI_Comments:** 该论文提出了一种新颖的理论框架，通过引入“恢复时间”这一新度量和数学改进$\delta$ISS理论，为LSTM网络的弹性提供了量化和保证方法。其创新之处在于提出数据无关的恢复时间上限，并实现弹性感知训练。这对于安全关键型AI应用的质量保证具有重要意义。然而，目前的实验验证仅限于简单模型，未来可能需要进一步验证其在复杂系统中的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 在控制系统中保证和评估长短期记忆（LSTM）网络的弹性，并为安全关键型AI应用提供严格的质量保证基础。

**Method:** 引入“恢复时间”作为新的弹性度量，对LSTM的增量输入到状态稳定性（$\delta$ISS）理论进行数学改进，推导出实际的数据无关的恢复时间上限，并实现弹性感知训练。

**Result:** 在简单模型上的实验验证表明，所提出的弹性估计和控制方法是有效的。

**Conclusion:** 为安全关键型AI应用中的严格质量保证奠定了基础。

> **ai_Abstract:** 本文提出了一种新颖的理论框架，用于量化和保证控制系统中LSTM网络的弹性。该框架引入“恢复时间”作为新的弹性度量，并通过数学改进$\delta$ISS理论，推导出一个与数据无关的恢复时间上限，从而实现弹性感知训练。在简单模型上的实验验证证实了所提出方法的有效性，为安全关键型AI应用中的质量保证奠定了基础。

> **摘要翻译:** 本文提出了一种新颖的理论框架，用于保证和评估控制系统中长短期记忆（LSTM）网络的弹性。我们引入“恢复时间”作为弹性的一种新度量，以量化LSTM在异常输入后恢复到正常状态所需的时间。通过对LSTM的增量输入到状态稳定性（$\delta$ISS）理论进行数学改进，我们推导出了一个实际的、与数据无关的恢复时间上限。这个上限使我们能够进行弹性感知训练。在简单模型上的实验验证表明，我们的弹性估计和控制方法是有效的，为安全关键型AI应用中的严格质量保证奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [558] [The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning](https://arxiv.org/abs/2506.02139)
> *语言模型的统一认知意识理论：语义锚定、激活阈值和涌现推理*

*Edward Y. Chang, Zeyneb N. Kaya, Ethan Chang* | **Category: cs.AI, I.2.7** | **Updated: 2025-08-05**

**Keywords:** 统一认知意识理论, 语言模型, 语义锚定, 激活阈值, 涌现推理

**Comment:** 14 pages, 6 figure, 2 table

> **TL;DR:** 统一认知意识理论（UCCT）认为大语言模型是无意识模式库，其智能通过外部锚定机制和激活阈值产生，而非模型内在固有。

**AI_Comments:** UCCT的创新之处在于其将大语言模型的智能解释为外部激活和语义锚定的结果，而非模型内部固有的意识或推理能力。这为理解LLM的行为提供了一个统一的量化框架，并对可解释性、提示工程和模型设计具有重要的指导意义。其通过贝叶斯竞争和明确的原则来形式化这一过程，并通过实验验证了其预测，增强了理论的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提出统一认知意识理论（UCCT），以提供一个统一的量化解释，说明大语言模型（LLM）的“智能”是如何通过语义锚定而不是模型内部包含来产生的，并为可解释诊断和实际指导提供原则性基础。

**Method:** UCCT将LLM视为无意识模式库，并将其形式化为统计先验和上下文驱动目标模式之间的贝叶斯竞争。该理论基于阈值交叉、模态普遍性和密度-距离预测能力三个原则。通过跨领域演示（文本问答、图像字幕、多智能体辩论）和两个深度实验（受控数字基数研究和层级轨迹分析）进行验证。

**Result:** 实验证实了UCCT对阈值行为、不对称干扰和记忆滞后的预测。

**Conclusion:** UCCT表明LLM的“智能”是通过语义锚定而非模型内在包含来创造的，为可解释诊断、提示工程、模型选择和对齐中心系统设计提供了原则性基础和实用指导。

> **ai_Abstract:** 本文提出了统一认知意识理论（UCCT），将大语言模型（LLM）视为庞大的无意识模式库。UCCT认为LLM的表观推理能力源于外部锚定机制（如少样本提示、检索增强上下文、微调或多智能体辩论）激活了任务相关模式。该理论将此过程形式化为贝叶斯竞争，并基于阈值交叉、模态普遍性和密度-距离预测能力三个原则。通过跨领域演示和深度实验（包括数字基数研究和层级轨迹分析）验证了UCCT的预测，证实了阈值行为和记忆滞后等现象。UCCT强调LLM的智能是通过语义锚定而非模型内在固有，为可解释诊断和实际应用（如提示工程和模型选择）提供了理论基础。

> **摘要翻译:** 统一认知意识理论（UCCT）将语言模型视为庞大的无意识模式库：表观推理仅在外部锚定机制、少样本提示、检索增强上下文、微调或多智能体辩论激活任务相关模式时才会出现。UCCT将这一过程形式化为预训练中学到的统计先验和上下文驱动的目标模式之间的贝叶斯竞争，从而提供了一个统一现有适应技术的单一量化解释。我们将该理论建立在三个原则之上：阈值交叉、模态普遍性和密度-距离预测能力，并通过（i）跨领域演示（文本问答、图像字幕、多智能体辩论）和（ii）两个深度实验进行验证：一个受控的数字基数研究（基数8、9、10）以分离模式密度效应，以及一个揭示70亿参数模型内部相变的层级轨迹分析。两项实验都证实了UCCT对阈值行为、不对称干扰和记忆滞后的预测。通过表明LLM的“智能”是通过语义锚定而非模型内在包含来创造的，UCCT为可解释诊断以及提示工程、模型选择和对齐中心系统设计的实际指导提供了原则性基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [560] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
> *动态变化域规划*

*Mikhail Soutchanski, Yongmei Liu* | **Category: cs.AI, cs.CE, 03B35 (Primary) 03A99, 03B10, 03B25, 68V15, 03C07 (Secondary), I.2.3; I.2.4; F.4.1; F.2.2; H.3.3** | **Updated: 2025-07-26**

**Keywords:** 动态域规划, 领域封闭假设, 一阶逻辑, 规划, 完备性

**Comment:** A revised version of the paper accepted to the 1st International
  Workshop on Trends in Knowledge Representation and Reasoning organized as a
  IJCAI 2025 workshop that takes place in August 2025 in Montreal, Canada. See
  the details at https://tkr2025.krportal.org/programme.html

> **TL;DR:** 本文提出了一种在对象集合动态变化的域中进行规划的方法，解决了传统规划中领域封闭假设的局限性。

**AI_Comments:** 本文的创新点在于打破了传统规划中领域封闭假设（DCA）的限制，使规划系统能够处理对象动态创建和销毁的现实问题。通过一阶逻辑的形式化和实例化的搜索策略，提供了一种理论上完备且可靠的解决方案。其重要性在于拓展了规划理论的适用范围，使其能更好地应对实际应用中的复杂场景。然而，其适用范围目前受限于不含流利文字析取的情况，这可能是一个潜在的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 在传统的规划和一致性规划中，存在领域封闭假设（DCA），即假设对象集合是预先给定的且有限的。然而，在实际规划问题中，对象集合会随着动作的执行而动态变化，例如新对象的创建或旧对象的销毁，这使得传统方法无法适用。

**Method:** 作者将规划问题形式化为一阶逻辑，假设初始理论是有限且一致的流利文字集合。他们讨论了在何种情况下能保证在每种情况下只有有限多的可能动作，并对规划长度施加了有限整数限制。作者提出通过在规划时将动作序列进行实例化（grounded）来组织搜索。

**Result:** 该方法被证明是完备且可靠的。它可以用于解决不含DCA的、有界规划问题，这些问题属于顺序广义规划（不含感知动作）和一致性规划的交集，但仅限于不含流利文字析取的情况。作者还讨论了其规划器概念验证的实现。

**Conclusion:** 本文提出了一种在动态变化域中进行规划的新方法，通过一阶逻辑形式化和实例化的搜索策略，成功解决了传统规划DCA的局限性，并证明了其方法的完备性和可靠性，为处理对象动态变化的实际规划问题提供了解决方案。

> **ai_Abstract:** 本文针对传统规划中领域封闭假设（DCA）的局限性，提出了一种处理对象集合动态变化的规划方法。该方法将规划问题形式化为一阶逻辑，并通过对规划长度设定有限界限和在规划时对动作序列进行实例化搜索来解决问题。研究证明了该方法的可靠性和完备性，并指出其适用于不含DCA的、有界规划问题，尤其是在顺序广义规划与一致性规划的特定交集领域。文章还提及了其规划器的概念验证实现。

> **摘要翻译:** 在经典规划和一致性规划中，假设预先给定有限数量的命名对象，并且只有它们可以参与动作和流利。这就是领域封闭假设（DCA）。然而，存在一些实际的规划问题，其中对象集合会随着动作的执行而动态变化；例如，可以创建新对象，也可以销毁旧对象。我们将规划问题形式化为一阶逻辑，假设初始理论是一个有限的一致流利文字集合，讨论了这在何时能保证在每种情况下只有有限数量的可能动作，对规划长度施加了有限整数限制，并提出在规划时对实例化的动作序列进行搜索。我们展示了我们方法的可靠性和完备性。它可以用于解决属于顺序广义规划（不含感知动作）和一致性规划交集的、不含DCA的有界规划问题，但仅限于不含流利文字析取的情况。我们讨论了我们规划器的一个概念验证实现。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [564] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
> *高效代理：在降低成本的同时构建有效代理*

*Ningning Wang, Xavier Hu, Pai Liu, He Zhu, Yue Hou, Heyuan Huang, Shengyu Zhang, Jian Yang, Jiaheng Liu, Ge Zhang, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-07-24**

**Keywords:** LLM代理, 效率-效果权衡, 成本优化, 代理框架, GAIA基准

**Comment:** Work in progress. For GitHub repository, see
  https://github.com/OPPO-PersonalAI/OAgents

> **TL;DR:** 本研究系统性地探讨了LLM驱动代理的效率-效果权衡，并提出了一个名为“高效代理”的新框架，该框架在保持高性能的同时显著降低了成本。

**AI_Comments:** 该论文的创新之处在于首次系统性地研究了LLM代理的效率-效果权衡，并提出了一个在成本效益方面有显著提升的实际解决方案。它通过量化“通过成本”这一新指标，为评估和优化代理系统提供了具体方法。研究结果对于推动LLM代理的实际应用和普及具有重要意义，因为它解决了阻碍其大规模部署的关键成本障碍。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）驱动的代理虽然能力强大，能够处理复杂的任务，但其不断上升的成本威胁到可扩展性和可访问性，因此急需在不牺牲性能的情况下实现经济高效的设计。

**Method:** 本研究对现代代理系统中的效率-效果权衡进行了首次系统性研究，探讨了代理任务固有的复杂性、额外模块的边际收益以及高效代理框架能带来的效率提升。通过在GAIA基准上进行实证分析，评估了LLM骨干选择、代理框架设计和测试时扩展策略的影响，并使用“通过成本”指标量化了这些维度上的效率-性能权衡。

**Result:** 研究结果指导了“高效代理”这一新型代理框架的开发，该框架具有最佳的任务要求复杂性。与领先的开源代理框架OWL相比，“高效代理”保持了96.7%的性能，同时将运营成本从0.398美元降低到0.228美元，使“通过成本”提高了28.4%。

**Conclusion:** 本研究为设计高效、高性能的代理系统提供了可操作的见解，从而提升了AI驱动解决方案的可访问性和可持续性。

> **ai_Abstract:** 本论文系统性地研究了大型语言模型（LLM）驱动代理的效率与效果之间的权衡，旨在解决LLM代理成本高昂的问题。研究通过在GAIA基准上的实证分析，评估了LLM骨干、框架设计和扩展策略对效率和性能的影响。在此基础上，提出了一个名为“高效代理”的新型框架。该框架在保持与现有领先框架相近性能的同时，显著降低了运营成本，为构建更具可访问性和可持续性的AI解决方案提供了实用指导。

> **摘要翻译:** 大型语言模型（LLM）驱动的代理所具备的卓越能力使得复杂的系统能够处理复杂的多步骤任务，但其不断上升的成本威胁到可扩展性和可访问性。这项工作首次系统地研究了现代代理系统中的效率-效果权衡，解决了在不牺牲性能的情况下实现经济高效设计的关键需求。我们研究了三个关键问题：（1）代理任务本质上需要多少复杂性？（2）何时额外模块会产生递减收益？（3）通过高效代理框架的设计可以获得多少效率？通过对GAIA基准的实证分析，我们评估了LLM骨干选择、代理框架设计和测试时扩展策略的影响。我们使用“通过成本”指标，量化了这些维度上的效率-性能权衡。我们的发现为“高效代理”的开发提供了信息，这是一种新型代理框架，其复杂性与任务要求达到最佳匹配。“高效代理”在保持领先的开源代理框架OWL 96.7%性能的同时，将运营成本从0.398美元降低到0.228美元，使“通过成本”提高了28.4%。我们的工作为设计高效、高性能的代理系统提供了可操作的见解，从而提升了AI驱动解决方案的可访问性和可持续性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [566] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
> *基于模型的长期人类权力适宜指标的软最大化*

*Jobst Heitzig, Ram Potham* | **Category: cs.AI, cs.CY, cs.LG, econ.TH, math.OC, 68Txx, I.2** | **Updated: 2025-08-04**

**Keywords:** AI安全,人类权力,目标函数,权力平衡,多智能体强化学习

**Comment:** 

> **TL;DR:** 该论文提出了一种新颖的AI目标函数，旨在最大化人类的长期权力，同时考虑安全性和福祉。该方法通过引入一个参数化、可分解的客观函数来实现，该函数考虑了人类的有限理性、社会规范以及广泛的人类目标。论文还提出了计算该指标的算法，并通过示例展示了其在不同场景下的应用，并认为这种方法比直接基于效用的目标函数更安全。

**AI_Comments:** 该研究提出了一个有趣且重要的AI安全问题，即如何设计AI的目标函数以确保人类的长期福祉和权力。论文提出的方法具有一定的理论基础，并且考虑了现实世界中的复杂因素，如有限理性和社会规范。然而，将这些复杂的概念转化为可计算的目标函数仍然是一个挑战。此外，论文中提到的“软最大化”和“适宜的指标”的定义和实现方式需要更详细的阐述。尽管如此，这项研究为未来AI安全的研究提供了一个有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** AI安全领域中的权力概念至关重要，涉及权力寻求、人类被剥夺权力以及人机交互和国际AI治理中的权力平衡。同时，权力也是实现福祉的关键。该论文旨在通过明确要求AI代理赋能人类并管理人机权力平衡来同时促进安全和福祉。

**Method:** 本文采用基于模型的、部分公理化的方法，设计了一个参数化且可分解的目标函数，该函数代表了人类权力的、规避不平等和风险的长期聚合指标。该函数考虑了人类的有限理性、社会规范以及广泛的人类目标。论文还推导了通过后向归纳法或通过多智能体强化学习（来自给定的世界模型）来近似计算该指标的算法。

**Result:** 论文通过在各种范例情境中（软）最大化该指标的后果进行了例证，并描述了它可能带来的工具性子目标。评估结果表明，软最大化适宜的人类权力聚合指标可能比直接的基于效用的目标函数更能构成代理AI系统的有益目标，且更安全。

**Conclusion:** 软最大化适宜的人类权力聚合指标可能比直接的基于效用的目标函数更能构成代理AI系统的有益目标，且更安全。

> **ai_Abstract:** 本文提出了一种新颖的AI目标函数，旨在通过最大化人类的长期权力来同时促进AI安全和人类福祉。该方法设计了一个可参数化、可分解的客观函数，该函数能够考虑人类的有限理性、社会规范以及广泛的人类目标，并对不平等和风险具有规避性。论文还提出了计算该指标的算法，并通过实例分析了其潜在影响，认为这种方法相比于直接基于效用的目标函数，对于AI系统而言更为安全和有益。

> **摘要翻译:** 权力是AI安全中的一个关键概念：权力寻求作为一种工具性目标、人类突然或渐进地丧失权力、人机交互中的权力平衡以及国际AI治理。同时，权力作为追求多样化目标的能力，对于福祉至关重要。
本文探讨了通过强制AI代理明确赋能人类并以理想方式管理人与AI之间的权力平衡来促进安全和福祉的想法。我们采用一种基于原理的、部分公理化的方法，设计了一个可参数化和可分解的目标函数，该函数代表了人类权力的、规避不平等和风险的长期聚合指标。它考虑了人类的有限理性和社会规范，并且至关重要的是，它考虑了各种可能的人类目标。
我们推导了通过后向归纳法计算该指标或通过一种形式的多智能体强化学习（来自给定的世界模型）来近似计算该指标的算法。我们例证了（软）最大化该指标在各种范例情境下的后果，并描述了它可能带来的工具性子目标。我们谨慎的评估是，软最大化适宜的人类权力聚合指标可能比直接的基于效用的目标函数更能构成代理AI系统的有益目标。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [574] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
> *从基于位置的服务数据中利用新型Transformer模型恢复个体层面活动序列*

*Weiyu Luo, Chenfeng Xiong* | **Category: cs.AI, cs.CE** | **Updated: 2025-08-02**

**Keywords:** LBS数据, 活动序列恢复, Transformer, VSNIT, 移动性分析

**Comment:** 20 pages, 5 figures

> **TL;DR:** 提出VSNIT模型，利用Transformer和可变选择网络，有效恢复稀疏LBS数据中缺失的个体活动序列，表现优于基线模型。

**AI_Comments:** 该研究提出了一种新颖的Transformer-based模型VSNIT，创新性地结合了序列生成和动态协变量处理，有效解决了LBS数据稀疏性带来的活动序列恢复难题，对于人类移动性分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于位置服务（LBS）数据稀疏，导致行程和活动序列不完整，难以准确推断。本研究旨在解决如何利用高质量LBS数据恢复个体层面不完整的活动序列。

**Method:** 本研究提出了一种新的解决方案：变选择网络融合插入Transformer（VSNIT）模型。该模型结合了插入Transformer的灵活序列构建能力和变选择网络动态协变量处理能力，用于恢复不完整活动序列中的缺失片段，同时保留现有数据。

**Result:** VSNIT模型能够插入更多样化、更真实的活动模式，更接近现实世界的变异性；更有效地恢复中断的活动转换，与目标更一致；在所有指标上均显著优于基线模型。

**Conclusion:** VSNIT在活动序列恢复任务中表现出卓越的准确性和多样性，证明了其增强LBS数据在移动性分析中效用的潜力，为未来的基于位置的研究和应用提供了一个有前景的框架。

> **ai_Abstract:** 本文提出了一种名为VSNIT（变选择网络融合插入Transformer）的新型模型，旨在解决基于位置服务（LBS）数据稀疏性导致的个体活动序列不完整问题。VSNIT结合了Transformer的序列构建能力和变选择网络的协变量处理能力，能够有效地恢复缺失的活动片段。实验结果表明，VSNIT在插入多样化、真实活动模式和恢复活动转换方面表现出色，且在各项指标上均显著优于现有基线模型，有望提升LBS数据在移动性分析中的应用价值。

> **摘要翻译:** 基于位置服务（LBS）数据为人类移动性提供了关键见解，但其稀疏性常常导致行程和活动序列不完整，使得对行程和活动的准确推断变得困难。我们提出了一个研究问题：我们能否利用从高质量LBS数据中获得的活动序列来恢复个体层面不完整的活动序列？本研究提出了一种新的解决方案，即变选择网络融合插入Transformer（VSNIT），它将插入Transformer的灵活序列构建与变选择网络的动态协变量处理能力相结合，以恢复不完整活动序列中的缺失片段，同时保留现有数据。研究结果表明，VSNIT插入了更多样化、更真实的活动模式，更接近现实世界的变异性，并且更有效地恢复了中断的活动转换，与目标更一致。它在所有指标上均显著优于基线模型。这些结果突出了VSNIT在活动序列恢复任务中卓越的准确性和多样性，展示了其增强LBS数据在移动性分析中效用的潜力。这种方法为未来的基于位置的研究和应用提供了一个有前景的框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [581] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
> *基于大型语言模型的Dabeta科学智能体：一项综述*

*Peiran Wang, Yaoning Yu, Ke Chen, Xianyang Zhan, Haohan Wang* | **Category: cs.AI** | **Updated: 2025-08-02**

**Keywords:** 大型语言模型, 数据科学, 智能体, 综述, 双视角框架

**Comment:** 

> **TL;DR:** 这是一篇关于基于大型语言模型的数据科学智能体的综述，从智能体设计和数据科学流程双重角度进行了分析。

**AI_Comments:** 这篇综述提供了一个及时且全面的视角，审视了LLM智能体在数据科学领域的应用。其创新之处在于提出了一个双视角框架，这有助于系统地理解和设计此类智能体。对于研究人员和实践者来说，它提供了一个宝贵的起点，可以了解当前发展和未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的快速发展推动了新应用，其中基于LLM的智能体成为一个重要的探索领域，因此需要对用于数据科学任务的LLM智能体进行全面分析。

**Method:** 本综述对用于数据科学任务的基于LLM的智能体进行了全面分析，总结了最新研究的见解。它从智能体视角讨论了关键设计原则（角色、执行、知识、反思方法），并从数据科学视角识别了关键流程（数据预处理、模型开发、评估、可视化等）。

**Result:** 提供了两个主要贡献：1) 对LLM智能体应用于数据科学任务的最新发展进行了全面回顾；2) 提出了一个双视角框架，将通用智能体设计原则与数据科学的实际工作流程联系起来。

**Conclusion:** 本综述全面回顾了基于大型语言模型的数据科学智能体，并提出了一个连接智能体设计与数据科学工作流的双视角框架。

> **ai_Abstract:** 本文对基于大型语言模型（LLM）的数据科学智能体进行了全面综述。它从智能体设计和数据科学工作流两个独特视角，分析了LLM智能体的关键原则和应用流程，并提出了一个连接这两者的双视角框架，旨在全面回顾该领域的最新进展。

> **摘要翻译:** 大型语言模型（LLM）的快速发展推动了跨越不同领域的新颖应用，其中基于LLM的智能体正成为一个重要的探索领域。本综述对专为数据科学任务设计的基于LLM的智能体进行了全面分析，总结了最新研究的见解。从智能体视角来看，我们讨论了关键的设计原则，涵盖了智能体角色、执行、知识和反思方法。从数据科学视角来看，我们识别了基于LLM智能体的关键过程，包括数据预处理、模型开发、评估、可视化等。我们的工作提供了两个关键贡献：（1）对LLM智能体应用于数据科学任务的最新进展进行了全面回顾；（2）一个双视角框架，将通用智能体设计原则与数据科学的实际工作流程联系起来。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [584] [From Promising Capability to Pervasive Bias: Assessing Large Language Models for Emergency Department Triage](https://arxiv.org/abs/2504.16273)
> *从有前景的能力到普遍存在的偏见：评估大型语言模型在急诊科分诊中的应用*

*Joseph Lee, Tianqi Shang, Jae Young Baik, Duy Duong-Tran, Shu Yang, Lingyao Li, Li Shen* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 急诊分诊, 鲁棒性, 偏见, 临床决策支持

**Comment:** Presented at GenAI4Health Workshop @ AAAI 2025 (non-archival),
  Preprint of an article submitted for consideration in Pacific Symposium on
  Biocomputing 2026

> **TL;DR:** 本研究系统评估了大型语言模型（LLMs）在急诊分诊中的能力，发现LLMs表现出更好的鲁棒性，但也存在性别和种族交叉偏见，尤其在特定人群中更为明显。

**AI_Comments:** 该论文创新性地将LLMs应用于急诊分诊这一关键临床场景，并从鲁棒性和偏见两个重要维度进行了深入评估。其重要性在于揭示了LLMs在实际应用中的潜力和风险，特别是对公平性的影响。研究发现LLMs在鲁棒性上的优势值得关注，但其在特定人口群体中表现出的偏见则是一个重要的限制，对未来LLM在医疗领域部署提出了警示。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在临床决策支持方面展现出潜力，但它们在急诊分诊中的应用仍未得到充分探索。

**Method:** 研究通过两个关键维度系统地评估了LLMs在急诊分诊中的能力：1) 对分布偏移和缺失数据的鲁棒性；2) 对性别和种族交叉偏见的反事实分析。评估了多种基于LLM的方法（包括持续预训练和上下文学习）以及传统机器学习方法。

**Result:** 结果表明，LLMs表现出卓越的鲁棒性，并且研究了促成这些有前景的LLM方法的关键因素。然而，LLMs在特定性别和种族交叉点上表现出偏好差异，普遍存在性别差异，但在某些种族群体中最为显著。

**Conclusion:** 研究结果表明，LLMs编码了可能在特定临床情境或特定特征组合中出现的群体偏好。

> **ai_Abstract:** 本研究系统评估了大型语言模型（LLMs）在急诊科分诊中的应用，重点关注其对数据变化和缺失的鲁棒性以及潜在的交叉偏见。研究发现LLMs在鲁棒性方面表现优异，但同时也揭示了它们在性别和种族交叉群体中存在的偏好差异，提示LLMs可能编码了人口统计学偏好，这在临床应用中需要引起重视。

> **摘要翻译:** 大型语言模型（LLMs）在临床决策支持方面展现出潜力，但它们在分诊中的应用仍未得到充分探索。我们系统地调查了LLMs在急诊科分诊中的能力，主要通过两个关键维度：(1) 对分布偏移和缺失数据的鲁棒性，以及 (2) 对性别和种族交叉偏见的反事实分析。我们评估了多种基于LLM的方法，范围从持续预训练到上下文学习，以及机器学习方法。我们的结果表明LLMs表现出卓越的鲁棒性，并且我们调查了促成这些有前景的LLM方法的关键因素。此外，在这种情境下，我们发现LLM偏好中存在在特定性别和种族交叉点出现的差距。LLMs普遍表现出基于性别的差异，但在某些种族群体中最为显著。这些发现表明LLMs编码了可能在特定临床情境或特定特征组合中出现的群体偏好。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [589] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
> *通过现场优化实现认知循环：面向科学的自适应推理*

*Newman Cheng, Gordon Broadbent, William Chappell* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 认知循环, 现场优化, 自适应推理, 大型语言模型, 科学发现

**Comment:** 

> **TL;DR:** 提出CLIO，一种通过现场优化实现认知循环的自适应推理方法，使LLM在科学发现中更具可控性、透明度，并在HLE上显著提升GPT-4.1的准确率。

**AI_Comments:** 本文的创新之处在于提出了一种使大型语言模型（LLMs）能够进行自适应推理和提供可控性的方法，这对于科学发现至关重要。它通过开放式设计和内部机制，解决了现有AI模型在科学应用中缺乏透明度和用户控制的痛点。特别是“现场优化”和“认知循环”的概念，为提升LLM在复杂科学问题中的可靠性和实用性提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI模型在科学发现中缺乏可控性、准确性和透明度，科学家难以最大化其效用。因此，需要一种能对推理过程进行深度和精确控制的新方法。

**Method:** 提出“通过现场优化实现认知循环”（CLIO）的方法。CLIO使大型语言模型（LLMs）能够自主规划解决问题的方式，在自信心不足时调整行为，并提供最终的判断或答案。其开放式设计允许科学家观察不确定性水平，通过图结构理解最终信念的形成，并进行干预修正。

**Result:** 在“人类最后考试”（HLE）的文本生物学和医学问题上，结合CLIO的OpenAI GPT-4.1准确率达到22.37%，比基础GPT-4.1模型净增13.82%（相对增长161.64%），并超越了OpenAI的o3性能。研究发现内部不确定性测量中的波动是决定CLIO结果准确性的关键。

**Conclusion:** CLIO的开放式设计和内部机制为科学决策过程提供了洞察和控制，提升了AI在科学领域的实用性。

> **ai_Abstract:** 本文介绍了通过现场优化实现认知循环（CLIO）的方法，旨在通过对推理过程提供深度和精确控制来增强AI在科学发现中的效用。与现有AI模型不同，CLIO使大型语言模型（LLMs）能够自适应并制定解决问题的策略，为科学家提供透明度和可控性。在“人类最后考试”（HLE）上的实验表明，结合CLIO的GPT-4.1取得了显著更高的准确率（22.37%，相对提升161.64%），证明了其在自适应推理方面的有效性，并提升了AI在科学决策中的作用。

> **摘要翻译:** 人工智能（AI）在动态条件下形成、演化和测试改变的思维模式的能力，预示着对科学发现至关重要的先进认知。现有的AI发展格局分为两类：1）在非推理模型之上，原生融入人类思维方式观点的框架；2）将推理直觉的精确控制抽象化，远离最终用户的推理模型。尽管它们功能强大，但为了科学家最大化AI在科学发现中的效用，他们不仅需要推理的准确性和透明度，还需要可控性。因此，我们引入了一种替代方法，能够对推理过程进行深度和精确控制，称之为：通过现场优化实现认知循环（CLIO）。CLIO使大型语言模型（LLMs）能够自主制定解决问题的方法，在自信心不足时调整行为，并最终为科学家提供最终的信念或答案。通过CLIO的开放式设计，科学家可以观察不确定性水平，使用图结构理解最终信念状态是如何形成的，并进行干预纠正。在没有任何进一步后期训练的情况下，结合CLIO的OpenAI GPT-4.1在“人类最后考试”（HLE）的文本生物学和医学问题上的准确率达到22.37%。这比基础GPT-4.1模型净增13.82%或相对增长161.64%，并超越了OpenAI的o3在高和低推理努力模式下的表现。我们进一步发现，内部不确定性测量中的波动是决定CLIO结果准确性的关键，揭示了其开放式设计和内部机制如何为科学决策过程提供洞察和控制。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [592] [Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study](https://arxiv.org/abs/2506.19773)
> *知识图谱构建的自动提示优化：一项实证研究的见解*

*Nandana Mihindukulasooriya, Niharika S. D'Souza, Faisal Chowdhury, Horst Samulowitz* | **Category: cs.AI, I.2.7; I.2.4** | **Updated: 2025-08-04**

**Keywords:** 自动提示优化, 知识图谱构建, 三元组抽取, 大型语言模型, 实证研究

**Comment:** Accepted at LLM+Graph WS at VLDB 2025. 21 pages, 7 figures, 8 tables

> **TL;DR:** 本研究探讨了自动提示优化在知识图谱三元组抽取任务中的应用，并发现它能生成与人类相当的提示，从而提高抽取效果，尤其是在模式复杂度和文本长度增加时。

**AI_Comments:** 这篇论文的创新点在于系统性地将自动提示优化应用于知识图谱的三元组抽取任务，并提供了全面的实证研究。其重要性体现在解决了LLM在KG构建中人工提示设计效率低下的问题，为未来KG自动化构建提供了新的方向。研究结果对于提高LLM在信息抽取任务中的鲁棒性和效率具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识图谱（KG）在多种应用中至关重要，而从文本中抽取三元组是其基础。尽管大型语言模型（LLMs）已被用于KG构建，但为LLMs手动设计任务特定的提示是劳动密集型且脆弱的。为了解决这一挑战，最近的自然语言处理（NLP）研究探索了自动提示优化/工程方法，通过输入-输出示例生成最优或接近最优的提示。

**Method:** 本研究是一项实证研究，通过实验基准测试探索了自动提示优化在三元组抽取任务中的应用。研究评估了不同设置，包括：(a) 提示策略，(b) 用于提示优化和任务执行的LLM，(c) 模式中规范关系的数目（模式复杂性），(d) 输入文本的长度和多样性，(e) 驱动提示优化的指标，以及(f) 用于训练和测试的数据集。研究评估了三种不同的自动提示优化器（DSPy、APE和TextGrad），并使用了两个不同的三元组抽取数据集（SynthIE和REBEL）。

**Result:** 通过严格的实证评估，研究的主要贡献在于，自动提示优化技术可以生成与人类相似的合理提示，用于三元组抽取。反过来，这些优化后的提示取得了改进的结果，特别是在模式复杂度和文本大小增加时。

**Conclusion:** 自动提示优化技术能够为知识图谱构建中的三元组抽取任务生成有效且性能优于人工的提示，尤其是在处理更复杂和更长的文本数据时。

> **ai_Abstract:** 本研究通过一项实证分析，探讨了自动提示优化技术在知识图谱构建中三元组抽取任务的应用。鉴于手工设计LLM提示的挑战，研究评估了DSPy、APE和TextGrad等自动优化器在不同提示策略、LLM选择、模式复杂性、文本特性和数据集下的性能。结果表明，自动提示优化能够生成高质量的提示，其效果可与人工提示媲美，并在面对更复杂的模式和更长的文本时，显著提升了三元组抽取的性能。

> **摘要翻译:** 知识图谱（KG）代表一个实体网络，并说明它们之间的关系。知识图谱用于各种应用，包括语义搜索和发现、推理、决策、自然语言处理、机器学习和推荐系统。从文本中抽取三元组（主语-关系-宾语）是知识图谱构建的基本组成部分，并已被广泛研究，例如，从早期的ACE 2002等基准到最近的WebNLG 2020、REBEL和SynthIE。虽然大型语言模型（LLMs）在知识图谱构建中的应用正在探索中，但为LLMs手工制作合理的任务特定提示是一项劳动密集型的工作，并且由于所使用的LLM模型的细微变化而可能变得脆弱。最近的NLP任务（例如自主生成）中的工作使用自动提示优化/工程来解决这一挑战，通过给定输入-输出示例生成最优或接近最优的任务特定提示。
这项实证研究通过实验基准测试探索了自动提示优化在三元组抽取任务中的应用。我们通过改变（a）提示策略，（b）用于提示优化和任务执行的LLM，（c）模式中规范关系的数目（模式复杂性），（d）输入文本的长度和多样性，（e）用于驱动提示优化的指标，以及（f）用于训练和测试的数据集来评估不同的设置。我们评估了三种不同的自动提示优化器，即DSPy、APE和TextGrad，并使用了两个不同的三元组抽取数据集，SynthIE和REBEL。通过严格的实证评估，我们的主要贡献突出表明，自动提示优化技术可以生成与人类相似的合理提示，用于三元组抽取。反过来，这些优化后的提示取得了改进的结果，特别是在模式复杂度和文本大小增加时。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [595] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
> *用于放射学视觉问答中复杂推理的多智能体系统*

*Ziruo Yi, Jinyu Liu, Ting Xiao, Mark V. Albert* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-04**

**Keywords:** 多智能体系统, 放射学视觉问答, 复杂推理, 可解释AI, 多模态大型语言模型

**Comment:** 

> **TL;DR:** 本文提出了一个多智能体系统（MAS）来解决放射学视觉问答（RVQA）中现有MLLM和RAG方法面临的事实准确性、幻觉和跨模态错位等挑战，并在一个具有挑战性的数据集上展示了其优越性。

**AI_Comments:** 该论文的创新之处在于提出了一个专门用于放射学视觉问答的多智能体系统，通过将复杂推理任务分解给专业智能体来解决现有MLLM和RAG方法的局限性。其重要性在于提升了RVQA的准确性和可靠性，特别是在临床应用中对可解释性和可信度的需求。通过模型分歧过滤构建评估数据集，进一步验证了系统处理困难案例的能力，为未来开发更鲁棒、更可信赖的临床AI应用提供了有益的探索方向。

<details>
  <summary>Details</summary>

**Motivation:** 放射学视觉问答（RVQA）在回答胸部X光图像问题方面减轻了放射科医生的工作量。然而，尽管基于多模态大型语言模型（MLLMs）和检索增强生成（RAG）的最新方法取得了进展，但它们在事实准确性、幻觉和跨模态错位方面仍面临挑战。

**Method:** 本文引入了一个多智能体系统（MAS），旨在支持RVQA中的复杂推理，该系统包含专门的智能体，分别负责上下文理解、多模态推理和答案验证。系统在一个通过模型分歧过滤而精心策划的、包含多个MLLM始终难以处理的案例的RVQA挑战数据集上进行评估。

**Result:** 在广泛的实验中，该系统展示了其优于强大的MLLM基线的优越性和有效性。案例研究也说明了其可靠性和可解释性。

**Conclusion:** 这项工作突出了多智能体方法在支持需要复杂推理的可解释和可信临床AI应用方面的潜力。

> **ai_Abstract:** 本文针对放射学视觉问答（RVQA）中现有方法（MLLM和RAG）在事实准确性、幻觉和跨模态错位上的不足，提出了一个多智能体系统（MAS）。该系统包含专门的智能体负责上下文理解、多模态推理和答案验证。研究在一个通过模型分歧过滤构建的挑战性RVQA数据集上对系统进行了评估，实验结果表明该系统在性能上优于现有的MLLM基线，并展示了其可靠性和可解释性。该工作强调了多智能体方法在开发需要复杂推理的可解释和可信临床AI应用中的巨大潜力。

> **摘要翻译:** 放射学视觉问答（RVQA）为关于胸部X光图像的问题提供精确答案，从而减轻放射科医生的工作量。尽管最近基于多模态大型语言模型（MLLMs）和检索增强生成（RAG）的方法在RVQA中显示出有希望的进展，但它们在事实准确性、幻觉和跨模态错位方面仍面临挑战。我们引入了一个多智能体系统（MAS），旨在支持RVQA中的复杂推理，该系统包含专门的智能体，分别负责上下文理解、多模态推理和答案验证。我们在一个通过模型分歧过滤而精心策划的、包含多个MLLM始终难以处理的案例的挑战性RVQA数据集上评估了我们的系统。广泛的实验证明了我们的系统优于强大的MLLM基线的优越性和有效性，并通过案例研究说明了其可靠性和可解释性。这项工作突出了多智能体方法在支持需要复杂推理的可解释和可信临床AI应用方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [602] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
> *看似简单的规划问题在计算上具有挑战性：倒计时游戏*

*Michael Katz, Harsha Kokel, Sarath Sreedharan* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 规划, 基准, LLM, 倒计时游戏, 计算复杂性

**Comment:** 

> **TL;DR:** 本文提出了一个基于“倒计时游戏”的新基准，用于评估LLM的规划能力，并证明现有LLM在该基准上表现不佳。

**AI_Comments:** 本文的创新之处在于提出了一个新颖且计算上具有挑战性的规划基准——“倒计时游戏”，有效弥补了现有基准的不足。其重要性在于为评估和推动大型语言模型规划能力的发展提供了一个更真实、更严格的衡量工具。该基准的NP完全性确保了其长期挑战性，避免了模型通过记忆化取巧，为未来AI规划领域的研究提供了有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前基础模型和智能体在长期规划能力上的不足是其主要局限之一。然而，现有规划基准不足以真正衡量其规划能力，它们要么难以形式化验证，要么是为测试自动化规划器弱点而设计。

**Method:** 我们提出了一种围绕“倒计时游戏”创建规划基准的程序，玩家需要通过算术运算从给定数字列表中形成目标数字。该问题具有直观的自然语言描述，计算上具有挑战性（NP完全），并且实例空间足够丰富以避免记忆化。我们进行了广泛的理论分析，建立了计算复杂性结果，并评估了多种现有LLM辅助规划方法。

**Result:** 我们的结果表明，与24点游戏等其他领域不同，我们提出的动态基准对于现有的基于LLM的方法来说仍然极具挑战性。同时，我们的实例生成程序相较于公共基准具有优势。

**Conclusion:** 倒计时游戏提供了一个理想的、计算上具有挑战性的新基准，能够有效评估和揭示当前大型语言模型在规划能力方面的局限性。

> **ai_Abstract:** 本文指出当前大型语言模型在长期规划能力上的不足，并认为现有规划基准无法有效衡量这种能力。为解决此问题，作者提出了一个基于经典“倒计时游戏”的新型规划基准。该基准允许自然语言描述，计算复杂性高（NP完全），且实例空间丰富，能有效避免模型记忆化。通过广泛的理论分析和对现有LLM辅助规划方法的评估，研究表明，与现有基准相比，该新基准对LLM构成了显著挑战，突显了当前LLM在复杂规划任务上的局限性。

> **摘要翻译:** 普遍认为，无法形成长期规划是当前基础模型和智能体的主要局限之一。然而，现有规划基准不足以真正衡量其规划能力。大多数现有基准要么侧重于旅行规划等定义松散的任务，要么利用国际规划竞赛中现有的领域和问题。前者难以形式化和验证，后者则是专门设计用于测试和挑战现有自动化规划器的弱点。为解决这些缺点，我们提出了一种创建以“倒计时”游戏为中心的规划基准的程序，玩家需要通过算术运算从输入数字列表中形成目标数字。我们讨论了该问题如何满足理想规划能力评估基准的许多要求。具体来说，该领域允许对每个问题实例进行直观的自然语言描述，它在计算上具有挑战性（NP完全），并且实例空间足够丰富，我们不必担心记忆化。我们进行了广泛的理论分析，建立了计算复杂性结果，并展示了我们的实例生成程序优于公共基准的优势。我们评估了使用我们的程序生成的实例上各种现有LLM辅助规划方法。我们的结果表明，与24点游戏（倒计时的特例）等其他领域不同，我们提出的动态基准对于现有的基于LLM的方法来说仍然极具挑战性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [609] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
> *使用推理向量增强日语大型语言模型*

*Carolina Minami Oguchi, Leo Wei, Koyo Kobayashi, Hsin-Tai Wu, Dipak Ghosal* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 日语LLM, 推理向量, 后训练, 性能提升, 资源限制

**Comment:** 

> **TL;DR:** 本文提出了一种简单有效的方法，通过将从推理LLM中获得的推理向量应用于日语LLM，以克服资源限制并显著提高其性能。

**AI_Comments:** 本文的创新点在于提出了“推理向量”的概念，并将其应用于资源受限的特定语言（日语）LLM的性能提升。这种方法提供了一个成本效益高的解决方案，避免了从头开始大规模训练的资源消耗，对于推动非主流语言LLM的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 主流大型语言模型（LLMs）的后训练方法已能提升性能和推理能力，但由于所需资源量巨大，日语LLMs难以实现同样的效果。

**Method:** 受任务向量的启发，该研究从推理LLMs中获取推理向量，并将其应用于日语LLMs以提升其性能。

**Result:** 该方法为日语LLMs带来了显著的性能提升。

**Conclusion:** 本文提出了一种简单有效的方法来获得显著的改进，并希望能够为其他语言提供启发。

> **ai_Abstract:** 本文提出了一种针对日语大型语言模型（LLMs）性能提升的新方法，旨在解决资源限制问题。研究人员借鉴了任务向量的概念，从已具备推理能力的LLMs中提取“推理向量”，并将其应用于日语LLMs。这种方法被证明是简单且有效的，能够显著提升日语LLMs的性能，并有望为其他语言的LLM开发提供启示。

> **摘要翻译:** 后训练方法已提高了主流大型语言模型（LLMs）的性能并增强了其推理能力，但由于所需资源量巨大，日语LLMs难以实现同样的效果。受任务向量（其提取特定任务训练前后权重变化）的启发，我们从推理LLMs中获取推理向量并将其应用于日语LLMs，以提升其性能。尽管可用资源对改进日语LLMs提出了挑战，我们提出了一种简单有效的方法来获得显著的改进，并希望能够为其他语言提供启发。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [616] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
> *PentestJudge：判断代理行为是否符合操作要求*

*Shane Caldwell, Max Harley, Michael Kouremetis, Vincent Abruzzo, Will Pearce* | **Category: cs.AI, cs.CR** | **Updated: 2025-08-04**

**Keywords:** 渗透测试代理, 大型语言模型, 行为评估, 操作要求, F1分数

**Comment:** 18 pages, 5 figures, 3 tables

> **TL;DR:** PentestJudge是一个基于LLM的系统，用于评估渗透测试代理的行为是否符合操作标准，通过分层评估和与人类专家对比，实现了高F1分数，并发现验证可能比生成更容易。

**AI_Comments:** 创新：使用LLM作为“法官”来评估复杂、难以编程量化的代理行为（特别是渗透测试）是一个新颖且实用的方法。重要性：为评估AI在敏感信息安全领域（如渗透测试）中的表现提供了一种可扩展、可量化的方法，有助于提升AI代理在生产环境中的可信度和应用。洞察：发现不同模型在不同类型问题上的表现差异，以及“验证比生成更容易”的观点，为未来AI安全研究提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 评估渗透测试代理的操作行为是否符合某些难以通过编程方式评估的操作标准。需要一种系统来整体、可扩展地评估基于AI的信息安全代理的过程质量，以便在敏感生产环境中自信地使用它们。

**Method:** 引入PentestJudge，一个LLM-as-judge系统，能够消费代理状态和工具调用历史的任意轨迹。开发了使用树形结构的评估标准（rubrics），将渗透测试任务分层分解为更小、更简单的子任务和标准，直到叶节点是简单的“是/否”标准。任务节点分为操作目标、操作安全和策略。LLM-as-judge分数与人类领域专家作为真值参考进行比较，使用F1分数等标准二元分类指标评估相对性能。评估了多个前沿和开源模型作为判断代理。

**Result:** 最佳模型达到了0.83的F1分数。发现工具使用能力更好的模型更接近人类专家。按要求类型分层F1分数发现，即使总分相似的模型，在不同类型问题上也表现出差异，表明某些模型可能更擅长判断特定的操作标准。发现较弱和更便宜的模型可以判断由更强和更昂贵的模型执行的渗透测试轨迹，这表明对于渗透测试任务，验证可能比生成更容易。

**Conclusion:** 本文分享了评估AI信息安全代理过程质量的方法，以促进未来研究，使这些代理能够自信地用于敏感生产环境。验证AI代理行为的合规性可能比生成行为本身更容易。

> **ai_Abstract:** PentestJudge是一个基于LLM的系统，旨在评估渗透测试代理的行为是否符合难以编程评估的操作要求。它采用树状评估标准将任务分解为可判断的子项，并通过与人类专家对比验证其性能，最佳模型F1分数达0.83。研究发现，工具使用能力强的模型表现更佳，且验证代理行为的合规性可能比生成行为本身更容易，为AI安全代理在敏感环境中的应用提供了评估方法。

> **摘要翻译:** 我们介绍了 PentestJudge，一个用于评估渗透测试代理操作的系统。PentestJudge 是一个基于大型语言模型（LLM）的判断系统，它能够访问工具，从而可以消费代理状态和工具调用历史的任意轨迹，以确定安全代理的行为是否符合某些操作标准，而这些标准通过编程方式评估是不切实际的。我们开发了使用树形结构的评估标准，将特定环境下的渗透测试任务分层分解为更小、更简单、更易于管理的子任务和标准，直到每个叶节点代表 PentestJudge 评估的简单是或否标准。任务节点分为与操作目标、操作安全和策略相关的不同类别。LLM 作为判断者的分数与人类领域专家作为真值参考进行比较，这使我们能够使用标准二元分类指标（如 F1 分数）比较它们的相对性能。我们评估了几个前沿和开源模型作为判断代理，其中最佳模型达到了 0.83 的 F1 分数。我们发现，在工具使用方面表现更好的模型更接近人类专家。通过按要求类型对 F1 分数进行分层，我们发现即使总分相似的模型，在不同类型的问题上也存在差异，这表明某些模型可能更擅长判断特定的操作标准。我们发现，较弱和更便宜的模型可以判断由更强和更昂贵的模型执行的渗透测试轨迹，这表明对于渗透测试任务，验证可能比生成更容易。我们分享这种方法，旨在促进未来在理解判断者整体和可扩展地评估基于 AI 的信息安全代理过程质量方面的研究，以便它们可以在敏感的生产环境中自信地使用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [626] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
> *物理考试中代数表达式批改的AlphaPhysics项重写系统*

*Peter Baumgartner, Lachlan McGinness* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 自动批改, 项重写系统, 物理考试, SMT求解器, 大型语言模型

**Comment:** 

> **TL;DR:** 该论文介绍了一个结合计算机代数系统、SMT求解器、项重写系统和LLM的自动批改物理考试代数表达式的方法，并在1500多份真实学生答卷上进行了评估。

**AI_Comments:** 该论文提出了一种创新的方法，将多种先进技术（计算机代数系统、SMT求解器、项重写系统和大型语言模型）结合起来解决物理考试中代数表达式的自动批改这一复杂问题。特别是利用LLM进行学生回答的预处理和项重写系统在物理问题中的定制应用是其亮点。在大规模真实世界数据集上的评估也增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自动批改物理考试中的代数表达式是一个具有挑战性的问题。

**Method:** 该方法结合了计算机代数系统、SMT求解器和项重写系统。一个大型语言模型（LLM）用于解释学生回答并将其转换为机器可读格式。然后应用自动化推理技术，包括现成的SMT求解和专门为物理三角表达式设计的项重写系统来评估答案正确性。论文还详细描述了项重写系统的开发及其终止和合流性质的建立。

**Result:** 系统在2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生考试答卷上进行了评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种名为AlphaPhysics的自动批改物理考试代数表达式的方法。该方法结合了计算机代数系统、SMT求解器和专门的项重写系统。为了处理学生回答，一个大型语言模型被用来解释、纠正错误并将其格式化为机器可读形式。随后，系统利用自动化推理技术，包括SMT求解和定制的项重写，来评估答案的正确性。该系统已在超过1500份来自2023年澳大利亚物理奥林匹克竞赛的真实学生答卷上进行了验证。

> **摘要翻译:** 我们提出了自动批改物理考试的方法。批改问题在于评估学生输入的答案相对于标准答案的正确性。这是一个具有挑战性的问题，我们试图通过结合计算机代数系统、SMT求解器和项重写系统来解决。一个大型语言模型用于解释并消除学生回答中的错误，并将其重写为机器可读的格式。一旦形式化并与语言对齐，下一步就是应用自动化推理技术来评估学生解决方案的正确性。我们考虑了两种自动化定理证明方法：现成的SMT求解和专门为涉及三角表达式的物理问题定制的项重写系统。项重写系统的开发以及终止性和合流性质的建立并非易事，我们在论文中对其进行了详细描述。我们使用来自2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生考试答卷的丰富样本池对我们的系统进行了评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [629] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
> *AQUAH：水文学中的自动量化与统一代理*

*Songkun Yan, Zhi Li, Siyu Zhu, Yixin Wen, Mofan Zhang, Mengye Chen, Jie Cao, Yang Hong* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 水文建模, 大型语言模型, 智能体, 自动化, 地球观测数据

**Comment:** 8 pages, 5 figures, 2025 ICCV SEA workshop paper

> **TL;DR:** AQUAH是一个端到端的基于语言的智能体，能够自动完成水文建模，从自然语言提示到生成报告。

**AI_Comments:** AQUAH的创新之处在于将大型语言模型与视觉能力相结合，实现了水文建模的自动化和端到端处理，显著降低了专业门槛。其能够从自然语言指令直接生成分析师可用报告，展现了AI在科学研究和决策支持方面的巨大潜力。然而，论文也指出，实际操作部署仍需进一步的校准和验证，这提示了模型在泛化性和鲁棒性方面可能存在的挑战。

<details>
  <summary>Details</summary>

**Motivation:** AQUAH的开发旨在简化复杂的水文建模过程，并降低地球观测数据、物理工具与决策者之间的使用和理解障碍。

**Method:** AQUAH是一个端到端基于语言的智能体，专为水文建模设计。它从简单的自然语言提示开始，自主检索所需的地形、驱动和测量数据，配置水文模型，运行模拟，并生成独立的PDF报告。其工作流程由支持视觉功能的大型语言模型驱动，这些模型能够即时解释地图和栅格数据，并指导关键决策，如出口选择、参数初始化和不确定性评论。

**Result:** 在美国一系列盆地的初步实验表明，AQUAH能够完成冷启动模拟，并生成无需人工干预的分析师可用文档。水文学家评价其结果清晰、透明且符合物理规律。

**Conclusion:** 早期成果突显了以LLM为中心、以视觉为基础的智能体在简化复杂环境建模以及降低地球观测数据、基于物理的工具和决策者之间障碍方面的潜力。

> **ai_Abstract:** 本文介绍了AQUAH，一个用于水文建模的端到端语言智能体。它能从自然语言提示自动完成数据检索、模型配置、模拟运行及报告生成，并由视觉增强型大型语言模型驱动。初步实验显示其能进行冷启动模拟并生成高质量文档，结果得到水文学家认可，预示了LLM-视觉智能体在简化环境建模中的潜力。

> **摘要翻译:** 我们引入AQUAH，这是第一个专门为水文建模设计的端到端基于语言的智能体。从一个简单的自然语言提示（例如，“模拟2020年至2022年小大角盆地的洪水”）开始，AQUAH自主检索所需的地形、驱动和测量数据；配置水文模型；运行模拟；并生成一份独立的PDF报告。该工作流程由支持视觉功能的大型语言模型驱动，这些模型能够即时解释地图和栅格数据，并指导关键决策，如出口选择、参数初始化和不确定性评论。在美国一系列盆地的初步实验表明，AQUAH可以完成冷启动模拟并生成无需人工干预的分析师可用文档。水文学家评价结果清晰、透明且符合物理规律。虽然操作部署仍需要进一步的校准和验证，但这些早期成果突显了以LLM为中心、以视觉为基础的智能体在简化复杂环境建模以及降低地球观测数据、基于物理的工具和决策者之间障碍方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [633] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
> *RL-PLUS: 在强化学习中通过混合策略优化对抗大型语言模型的能力边界崩溃*

*Yihong Dong, Xue Jiang, Yongding Tao, Huanyu Liu, Kechi Zhang, Lili Mou, Rongyu Cao, Yingwei Ma, Jue Chen, Binhua Li, Zhi Jin, Fei Huang, Yongbin Li, Ge Li* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 强化学习, 能力边界崩溃, 混合策略优化, 可验证奖励

**Comment:** 

> **TL;DR:** RL-PLUS提出了一种混合策略优化方法，旨在解决RLVR中大型语言模型的能力边界崩溃问题，通过结合内部探索和外部数据，显著提升了模型在数学推理和域外任务上的表现。

**AI_Comments:** RL-PLUS的创新之处在于其混合策略优化方法，通过结合内部探索和外部数据，并引入多重重要性采样和基于探索的优势函数，有效解决了LLM在强化学习中面临的能力边界崩溃问题。这对于提升LLM的推理能力和泛化性具有重要意义，尤其是在处理复杂和域外任务方面展现出强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可验证奖励强化学习（RLVR）方法由于其本质上的在线策略、LLM巨大的动作空间和稀疏奖励，难以突破基础大型语言模型（LLM）固有的能力边界，甚至可能导致能力边界崩溃，从而缩小LLM的问题解决范围。

**Method:** 我们提出了RL-PLUS，一种新颖的LLM混合策略优化方法，它协同内部探索与外部数据，以实现更强的推理能力并超越基础模型的边界。RL-PLUS集成了两个核心组件：多重重要性采样（Multiple Importance Sampling）用于解决外部数据带来的分布不匹配问题；基于探索的优势函数（Exploration-Based Advantage Function）用于引导模型走向高价值、未探索的推理路径。

**Result:** RL-PLUS在六个数学推理基准测试中取得了最先进的性能；在六个域外推理任务上表现优越；在不同的模型家族中获得了持续显著的提升，平均相对改进高达69.2%。此外，Pass@k曲线分析表明RL-PLUS有效解决了能力边界崩溃问题。

**Conclusion:** RL-PLUS通过其混合策略优化方法，成功解决了大型语言模型在强化学习中面临的能力边界崩溃问题，显著提升了模型在各类推理任务上的性能和泛化能力。

> **ai_Abstract:** 本研究提出RL-PLUS，一种针对大型语言模型（LLMs）的混合策略优化方法，旨在解决可验证奖励强化学习（RLVR）中LLM能力边界崩溃的问题。RL-PLUS通过结合内部探索与外部数据，并集成多重重要性采样和基于探索的优势函数，成功提升了LLMs的推理能力。实验结果显示，RL-PLUS在数学推理和域外任务上均取得SOTA表现，并在不同模型家族中展现出显著且持续的性能提升，有效解决了能力边界崩溃。

> **摘要翻译:** 可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLMs）的复杂推理能力。然而，由于其本质上的在线策略、LLM巨大的动作空间和稀疏奖励，它难以突破基础LLM固有的能力边界。至关重要的是，RLVR可能导致能力边界崩溃，缩小LLM的问题解决范围。为了解决这个问题，我们提出了RL-PLUS，一种新颖的LLM混合策略优化方法，它协同内部探索与外部数据，以实现更强的推理能力并超越基础模型的边界。RL-PLUS集成了两个核心组件，即多重重要性采样（Multiple Importance Sampling）用于解决外部数据带来的分布不匹配问题，以及基于探索的优势函数（Exploration-Based Advantage Function）用于引导模型走向高价值、未探索的推理路径。我们提供了理论分析和大量实验来证明我们方法的优越性和泛化性。与现有RLVR方法相比，RL-PLUS实现了：1）在六个数学推理基准测试上达到最先进的性能；2）在六个域外推理任务上表现优越；3）在不同模型家族中获得持续显著的提升，平均相对改进高达69.2%。此外，Pass@k曲线分析表明RL-PLUS有效解决了能力边界崩溃问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [644] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
> *MedBLINK：探测医学多模态语言模型中的基本感知能力*

*Mahtab Bigverdi, Wisdom Ikezogwo, Kevin Zhang, Hyewon Jeong, Mingyu Lu, Sungjae Cho, Linda Shapiro, Ranjay Krishna* | **Category: cs.AI** | **Updated: 2025-08-04**

**Keywords:** 多模态语言模型, 医学图像, 感知能力, 基准测试, 临床应用

**Comment:** 

> **TL;DR:** MedBLINK基准测试揭示，当前多模态语言模型在医学图像的基本感知任务上表现不佳，远低于人类水平，需要加强视觉基础以实现临床应用。

**AI_Comments:** MedBLINK基准测试的创新之处在于其专注于医学多模态语言模型中经常被忽视的基本感知能力，这对于模型的临床可信度和实际应用至关重要。研究明确指出了当前模型在这一基础能力上的巨大差距，强调了加强视觉基础的必要性，为未来研究指明了方向。其局限性可能在于基准测试的覆盖范围和问题设计的复杂性是否能完全模拟真实世界的临床场景。

<details>
  <summary>Details</summary>

**Motivation:** 多模态语言模型在临床决策支持和诊断推理方面显示出潜力，但如果模型在图像方向或CT增强识别等简单感知任务上出错，临床医生将不会采用。因此，需要一个基准来探测这些模型的感知能力。

**Method:** 研究引入了MedBLINK基准测试，旨在探测多模态语言模型的感知能力。该基准涵盖了跨多种成像模式和解剖区域的八项临床有意义的任务，包含1,605张图像中的1,429个多项选择题。研究评估了19个最先进的多模态语言模型，包括通用型（GPT4o, Claude 3.5 Sonnet）和领域专用型（Med Flamingo, LLaVA Med, RadFM）模型。

**Result:** 人类标注者实现了96.4%的准确率，而表现最好的模型仅达到65%。这表明当前的多模态语言模型在常规感知检查中频繁失败。

**Conclusion:** 当前的多模态语言模型在医学图像的基本感知任务上表现不佳，远低于人类水平，这表明需要加强它们的视觉基础以支持临床采用。

> **ai_Abstract:** 本研究介绍了MedBLINK，一个用于评估医学多模态语言模型基本感知能力的基准。该基准包含八项临床任务，涉及多种成像模态，共1,429个多项选择题。对19个先进模型的评估结果显示，尽管人类准确率高达96.4%，但表现最佳的模型仅达到65%。这表明当前模型在医学图像的基本感知任务上存在显著不足，急需提升其视觉基础以促进临床应用。

> **摘要翻译:** 多模态语言模型（MLMs）在临床决策支持和诊断推理方面展现出前景，这预示着端到端自动化医学图像解读的可能性。然而，临床医生在采纳AI工具时非常挑剔；如果模型在看似简单的感知任务（例如确定图像方向或识别CT扫描是否进行对比度增强）上出错，则不太可能被临床任务采用。我们引入了Medblink，一个旨在探测这些模型此类感知能力的基准。Medblink涵盖了跨多种成像模式和解剖区域的八项临床有意义的任务，总计1,605张图像上的1,429个多项选择题。我们评估了19个最先进的多模态语言模型，包括通用型（GPT4o、Claude 3.5 Sonnet）和领域专用型（Med Flamingo、LLaVA Med、RadFM）模型。虽然人类标注者达到了96.4%的准确率，但表现最好的模型仅达到65%。这些结果表明，当前的多模态语言模型在常规感知检查中频繁失败，这表明需要加强它们的视觉基础以支持临床采用。数据可在我们的项目页面获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [656] [Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis](https://arxiv.org/abs/2507.21875)
> *用于生物信号分析的轻量级嵌入模型 Tiny-BioMoE*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** Tiny-BioMoE, 生物信号分析, 嵌入模型, 疼痛评估, 多模态传感

**Comment:** 

> **TL;DR:** Tiny-BioMoE 是一个轻量级的预训练嵌入模型，用于生物信号分析，在 AI4PAIN 挑战赛中用于疼痛评估。

**AI_Comments:** 该研究提出了一种名为 Tiny-BioMoE 的轻量级嵌入模型，用于生物信号分析，特别是在疼痛评估领域。该模型的创新之处在于其轻量化的设计（730 万参数）和在大量数据上的预训练，使其能够有效地提取生物信号的嵌入特征。这对于需要实时、低功耗或在资源受限设备上运行的疼痛评估系统具有重要意义。此外，该模型在多种生理信号（包括 EDA、BVP、呼吸、SpO2）上的有效性验证了其通用性。代码和权重的公开也为该领域的研究和应用提供了便利。然而，抽象中并未详细说明模型架构的具体细节或与其他先进模型的性能比较，这可能是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 准确一致的疼痛评估对于患者和医疗保健系统至关重要。自动疼痛评估系统通过连续监测、支持临床决策以及减轻患者痛苦和功能恶化风险来提供帮助。生理信号为个体状态提供了客观精确的见解，多模态框架可以进一步提高系统性能。

**Method:** 提出 Tiny-BioMoE，一个轻量级的预训练嵌入模型，用于生物信号分析。该模型在 440 万个生物信号图像表示上进行训练，包含 730 万个参数。

**Result:** Tiny-BioMoE 在包括皮肤电活动、脉搏波、呼吸信号、外周血氧饱和度和它们的组合在内的多种模态上，在自动疼痛识别任务中表现出有效性。

**Conclusion:** Tiny-BioMoE 是一个轻量级模型，适用于各种生物信号，可有效提取高质量的嵌入以用于下游任务，例如自动疼痛识别。

> **ai_Abstract:** 本研究提出了 Tiny-BioMoE，一个轻量级的预训练嵌入模型，用于生物信号分析，特别是在 AI4PAIN 挑战赛中用于自动疼痛评估。该模型在大量生物信号数据上进行训练，参数量少，能够为下游任务提取高质量的嵌入，并在多种生理信号的实验中证明了其有效性。

> **摘要翻译:** 疼痛是一种复杂且普遍存在的疾病，影响着相当大一部分人口。准确一致的评估对于遭受疼痛的个体以及制定有效的管理策略至关重要。自动疼痛评估系统能够进行连续监测、支持临床决策，并在减轻患者痛苦的同时降低功能恶化的风险。利用生理信号可以提供关于个体状态的客观且精确的见解，并将它们集成到多模态框架中可以进一步提高系统性能。本研究已提交给“下一代疼痛评估第二次多模态传感挑战赛 (AI4PAIN)”。所提出的方法引入了 Tiny-BioMoE，一个用于生物信号分析的轻量级预训练嵌入模型。该模型在 440 万个生物信号图像表示上进行训练，仅包含 730 万个参数，是提取高质量嵌入以用于下游任务的有效工具。在涉及皮肤电活动、脉搏波、呼吸信号、外周血氧饱和度及其组合的广泛实验突显了该模型在自动疼痛识别任务中跨不同模态的有效性。该模型的架构（代码）和权重可在 https://github.com/GkikasStefanos/Tiny-BioMoE 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [665] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
> *Polymath：一种具有动态分层工作流的自优化智能体*

*Chia-Tung Ho, Jing Gong, Xufeng Yao, Yunsheng Bai, Abhishek B Akkur, Haoxing Ren* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 自优化智能体, 动态分层工作流, 大语言模型, 无标注数据优化, 进化算法

**Comment:** 18 pages, 12 figures, under review for AAAI2026

> **TL;DR:** Polymath是一种无需标注数据，通过动态分层工作流和自反思进化算法，实现自优化并超越现有水平的大语言模型智能体。

**AI_Comments:** Polymath的创新之处在于其无需标注数据的自优化能力，通过结合动态分层工作流、图优化和自反思进化算法，显著提升了大语言模型智能体在真实世界动态问题中的灵活性和效率。这克服了传统方法对大量标注数据的依赖，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型智能体在构建通用代理时，手动嵌入基础模型效率低下且难以扩展。此外，现有的自动化工作流生成和优化方法依赖于标注数据集，这在缺乏标注数据的真实世界动态问题中无效且不灵活。

**Method:** 论文提出了Polymath，一个具有动态分层工作流的自优化智能体。它利用任务流图的灵活性和代码表示工作流的表达能力。其优化方法结合了多网格启发式图优化和自反思引导的进化算法，无需标注数据即可优化工作流。

**Result:** Polymath在编码、数学和多轮问答任务的六个基准数据集上进行了实验，结果显示其平均性能比最先进的基线提高了8.1%。

**Conclusion:** Polymath通过其无需标注数据的自优化动态分层工作流，有效解决了构建通用和灵活大语言模型智能体的挑战，并在多个复杂任务上显著优于现有方法。

> **ai_Abstract:** 本文介绍了Polymath，一种新型自优化智能体，旨在解决大型语言模型代理工作流生成与优化中对标注数据的依赖问题。Polymath采用动态分层工作流，结合了任务流图和代码表示的优势，并通过多网格启发式图优化与自反思引导的进化算法，实现了无需标注数据的自我优化。实验证明，Polymath在编码、数学和多轮问答等六个基准任务上，性能平均优于现有最先进方法8.1%。

> **摘要翻译:** 大型语言模型 (LLM) 通过执行由详细指令和结构化操作组成的代理工作流，擅长解决复杂任务。然而，通过文本接口将基础模型手动嵌入到思维链、自反思和ReACT等代理系统中来构建通用代理，限制了可扩展性和效率。最近，许多研究人员试图通过基于代码的表示来自动化这些工作流的生成和优化。然而，现有方法通常依赖于标注数据集来训练和优化工作流，这使得它们在解决缺乏标注数据的真实世界动态问题时效率低下且不灵活。为了解决这个挑战，我们引入了Polymath，一个具有动态分层工作流的自优化代理，它利用任务流图的灵活性和代码表示工作流的表达能力来解决各种真实世界、动态问题。所提出的优化方法将多网格启发式图优化与自反思引导的进化算法相结合，无需标注数据即可完善工作流。在编码、数学和多轮问答任务的六个基准数据集上的实验结果表明，Polymath比最先进的基线平均提高了8.1%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [669] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
> *留意差距：人类与大型语言模型生成任务之间的分歧*

*Yi-Long Lu, Jiajun Song, Chunhui Zhang, Wei Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 任务生成, 人类认知, 心理驱动, 具身化

**Comment:** 

> **TL;DR:** 人类和GPT-4o在生成任务时存在显著差异。人类任务受心理驱动，而GPT-4o生成的任务虽然更有趣和新颖，但缺乏社交性和身体活动，并且偏向抽象。这表明大型语言模型在模仿人类认知和生成符合内在动机和物理基础的目标方面存在差距。

**AI_Comments:** 这项研究揭示了当前大型语言模型在模仿人类创造力和目标设定方面的局限性，特别是它们在理解和整合心理驱动因素和物理世界互动方面的不足。研究结果对于开发更符合人类需求和期望的人工智能代理具有重要意义，但也指出了未来研究在模型的可解释性、内在动机模拟和具身化学习方面的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究大型语言模型（LLMs）在生成任务时是否遵循与人类相似的认知原则，以及它们能否模拟人类由内在动机驱动的复杂行为。

**Method:** 进行了一项任务生成实验，比较了人类的反应和一个名为GPT-4o的LLM代理的反应。实验中，即使明确向LLM提供了心理驱动因素，也对其行为模式进行了比较。

**Result:** 人类的任务生成受到个人价值观（如开放性）和认知风格等心理驱动因素的影响。LLM生成的任务在社交性和身体活动方面明显较少，并且在主题上偏向抽象。尽管LLM的任务被认为更有趣和新颖，但它在模仿人类的语言能力和生成类似人类的、具身化的目标方面存在差距。

**Conclusion:** 人类认知具有价值驱动和具身化的核心特征，而LLM的模式则基于统计规律，两者之间存在核心差距。这强调了在设计更符合人类期望的代理时，需要融入内在动机和物理基础。

> **ai_Abstract:** 本研究通过一项实验，比较了人类与GPT-4o在生成任务方面的差异。结果显示，人类的任务生成受心理因素影响，而GPT-4o生成的任务虽然新颖有趣，但在社交性和身体活动方面不足，且偏向抽象。研究认为，LLM在模仿人类价值驱动和具身化认知方面存在差距，需要整合内在动机和物理基础。

> **摘要翻译:** 人类不断地由内在动机驱动，生成各种各样的任务。虽然由大型语言模型（LLMs）驱动的生成代理旨在模拟这种复杂的行为，但它们是否遵循相似的认知原则尚不确定。为解决这个问题，我们进行了一项任务生成实验，比较了人类的反应和一个LLM代理（GPT-4o）的反应。我们发现，人类的任务生成持续受到心理驱动因素的影响，包括个人价值观（例如，对变革的开放性）和认知风格。即使将这些心理驱动因素明确提供给LLM，它也未能反映出相应的行为模式。它们生成的任务在社交性、身体活动方面明显较少，并且在主题上偏向抽象。有趣的是，虽然LLM的任务被认为更有趣和新颖，但这凸显了其语言能力与其生成类似人类的、具身化目标的能力之间的脱节。我们得出结论，人类认知具有价值驱动和具身化的核心特征，而LLM的统计模式则与之存在核心差距，这强调了在设计更符合人类期望的代理时，必须融入内在动机和物理基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [672] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
> *通过自我意识保护大语言模型*

*Boshi Huang, Fabio Nonato de Paula* | **Category: cs.AI, cs.CL, cs.CR** | **Updated: 2025-08-04**

**Keywords:** 大语言模型,提示注入,自我意识,元认知,防御机制

**Comment:** Presented at KDD Workshop on Ethical Artificial Intelligence: Methods
  and Applications (EAI) 2025

> **TL;DR:** 本研究提出了一种利用大语言模型自身推理能力进行自我保护的“自我意识”防御机制，以应对提示注入攻击，并在实验中取得了显著的防御效果。

**AI_Comments:** 这项研究的创新之处在于利用LLM自身的“自我意识”来防御攻击，而不是依赖外部工具。这种方法有可能实现更轻量级、更高效的防御。然而，需要进一步研究其在复杂攻击场景下的鲁棒性以及对模型性能的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 传统的防御方法依赖外部分类器，而本研究旨在利用大语言模型自身固有的推理能力来实现自我保护，以应对提示注入攻击。

**Method:** 提出了一种包含元认知和仲裁模块的框架，使大语言模型能够自主评估和调节自身输出，实现自我保护。

**Result:** 在七种先进的大语言模型和两个数据集（AdvBench和Prompt-Injection-Mixed-Techniques-2024）上进行了评估，结果显示防御成功率显著提高，部分模型在增强模式下实现了完美或接近完美的防御。同时分析了防御成功率提升与计算开销之间的权衡。

**Conclusion:** 提出的自我意识方法是一种轻量级、成本效益高且能增强大语言模型安全性的解决方案，特别有利于跨平台生成式人工智能的应用。

> **ai_Abstract:** 本研究提出了一种新颖的“自我意识”防御机制，利用大语言模型自身的推理能力来对抗提示注入攻击。该机制包含元认知和仲裁模块，使模型能够自主评估和调节输出。实验结果表明，该方法在多种模型和数据集上均能显著提高防御成功率，且计算开销可控，为增强大语言模型的安全性和伦理应用提供了有效途径。

> **摘要翻译:** 本文介绍了一种新颖的、用于大语言模型（LLMs）的自我意识防御机制，以对抗提示注入攻击。与依赖外部分类器的传统方法不同，我们的方法利用LLM固有的推理能力来进行自我保护。我们提出了一个包含元认知和仲裁模块的框架，使LLMs能够自主评估和调节其自身输出。我们的方法在七种最先进的LLMs和两个数据集：AdvBench和Prompt-Injection-Mixed-Techniques-2024上进行了评估。实验结果表明，在不同模型和数据集上，防御成功率有了显著提高，其中一些模型在增强模式下达到了完美和接近完美的防御。我们还分析了防御成功率提升与计算开销之间的权衡。这种自我意识方法为增强LLM的安全性提供了一种轻量级、成本效益高的解决方案，特别有利于跨平台的GenAI用例。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [693] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
> *统一LLM工具集成：一种与协议无关的函数调用方法*

*Peng Ding, Rick Stevens* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** LLM工具集成,函数调用,协议无关,并发执行,模式生成

**Comment:** arXiv admin note: substantial text overlap with arXiv:2507.10593

> **TL;DR:** 该论文提出了一种统一的、与协议无关的方法来集成工具，以简化LLM开发，通过自动化、并发执行和多源管理来减少代码和提高性能。

**AI_Comments:** 该论文提出了一种创新的方法来解决LLM工具集成中的关键痛点，其协议无关的设计和对性能优化的关注具有重要意义。自动化模式生成和并发执行的实验结果令人信服，但需要进一步评估其在更广泛、更复杂的实际场景中的可扩展性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的工具增强型LLM生态系统存在碎片化问题，开发者需要处理多种协议、手动模式定义和复杂的执行流程。

**Method:** 提出了一种统一的工具集成方法，该方法抽象了协议差异并优化了执行性能。该解决方案通过自动生成模式、双模并发执行和无缝多源工具管理来实现协议无关的设计。

**Result:** 实验结果显示，在集成场景中代码减少了60-80%，通过优化的并发性将性能提高了3.1倍，并与现有的函数调用标准完全兼容。

**Conclusion:** 该工作为工具集成架构提供了理论见解，并为实际LLM应用开发提供了实际解决方案。

> **ai_Abstract:** 该研究提出了一种新颖的、与协议无关的统一方法来集成工具，以解决当前工具增强型LLM生态系统的碎片化问题。该方法通过自动化模式生成、并发执行和多源管理，简化了开发流程，并显著提高了性能。

> **摘要翻译:** 工具增强型大型语言模型（LLM）的激增造成了一个碎片化的生态系统，开发者必须应对多种协议、手动模式定义和复杂的执行流程。我们通过提出一种统一的工具集成方法来应对这一挑战，该方法抽象了协议差异，同时优化了执行性能。我们的解决方案证明了与协议无关的设计原则如何通过自动模式生成、双模并发执行和无缝多源工具管理来显著减少开发开销。实验结果表明，在集成场景中代码减少了60-80%，通过优化的并发性将性能提高了3.1倍，并与现有的函数调用标准完全兼容。这项工作为工具集成架构提供了理论见解，也为实际的LLM应用程序开发提供了实际解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [697] [CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent](https://arxiv.org/abs/2508.01031)
> *CADDesigner：基于通用代理的CAD模型概念设计*

*Jingzhe Ni, Xiaolong Yin, Xingyu Lu, Xintong Li, Ji Wei, Ruofeng Tong, Min Tang, Peng Du* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** CAD设计, 大型语言模型, 交互式代理, 概念设计, 代码生成

**Comment:** 

> **TL;DR:** 一个基于LLM的CAD设计代理，可以接受文本和草图输入，通过交互式对话和视觉反馈生成CAD模型代码，并具有持续改进的能力。

**AI_Comments:** 该研究提出了一种创新的方法，利用 LLM 和交互式设计来简化 CAD 概念设计过程。将文本和草图输入相结合，并通过迭代反馈进行优化，这在 CAD 领域具有重要意义。然而，报告中未提供关于“上下文无关指令范式”的具体细节，也没有展示具体的案例研究或用户研究来量化其在“降低入门门槛”和“提高效率”方面的实际效果。

<details>
  <summary>Details</summary>

**Motivation:** 降低CAD设计的入门门槛，提高设计效率。

**Method:** 提出了一种基于LLM的CAD概念设计代理，该代理采用新颖的上下文无关指令范式（CIP），接受文本和草图输入，通过交互式对话和迭代视觉反馈来生成CAD模型代码，并将设计案例存储在知识库中以持续改进。

**Result:** 实验结果表明，该方法在CAD代码生成方面取得了最先进的性能。

**Conclusion:** 所提出的CADDesigner代理能够通过结合文本、草图、交互式对话和视觉反馈来生成高质量的CAD模型代码，并在CAD代码生成方面实现了最先进的性能。

> **ai_Abstract:** CADDesigner 是一个利用大型语言模型（LLM）的 CAD 概念设计代理，旨在降低设计门槛和提高效率。它能够处理文本描述和手绘草图，并通过与用户的交互式对话进行需求细化。该代理基于上下文无关指令范式（CIP），能够生成 CAD 模型代码，并利用迭代视觉反馈优化模型质量。此外，它还通过结构化的知识库实现能力的持续改进，并在实验中展现出最先进的性能。

> **摘要翻译:** 计算机辅助设计（CAD）在工业制造中起着举足轻重的作用，但通常需要设计者具备较高的专业知识。为了降低入门门槛、提高设计效率，我们提出了一个由大型语言模型（LLM）驱动的CAD概念设计代理。该代理接受抽象的文本描述和手绘草图作为输入，通过全面的需求分析与用户进行交互式对话，以完善和澄清设计需求。该代理建立在新颖的上下文无关指令范式（CIP）之上，能够生成高质量的CAD建模代码。在生成过程中，该代理结合了迭代的视觉反馈来提高模型质量。生成的案例被存储在结构化的知识库中，使得代理的代码生成能力能够持续提升。实验结果表明，我们的方法在CAD代码生成方面取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [707] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
> *当 AI 审判 AI 时：代理作为裁判评估 LLM 的兴起*

*Fangyi Yu* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** AI 代理评估, 大型语言模型, 代理作为裁判, 评估方法, LLM 评估

**Comment:** 

> **TL;DR:** 使用 AI 代理作为裁判来评估大型语言模型 (LLM) 的输出，特别是在开放式和复杂任务中，这是一种新兴的范式，有望提供可扩展且细致的替代人工评估的方法。

**AI_Comments:** 这篇综述为“代理作为裁判”这一新兴的 LLM 评估范式提供了一个全面的概述。它不仅解释了该方法的核心概念和演变，还对其优缺点进行了批判性的分析，并考察了其实际应用和面临的挑战。作者强调了该方法作为人类评估补充的重要性，为未来研究指明了方向。总的来说，这是一项有价值的工作，为理解和推进 LLM 评估领域做出了贡献。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型 (LLM) 的能力和自主性不断增强，评估它们的输出，特别是在开放式和复杂任务中，已成为一个关键瓶颈。

**Method:** 本篇综述定义了代理作为裁判的概念，追溯了其从单一模型裁判到动态多代理辩论框架的演变，并批判性地检查了它们的优缺点。

**Result:** 该方法在可靠性、成本和人类一致性方面进行了比较，并调查了在医学、法律、金融和教育等领域的实际部署情况。

**Conclusion:** 代理作为裁判的评估方法可以补充（但不能替代）人类的监督，这是迈向下一代 LLM 可信赖、可扩展评估的一步。

> **ai_Abstract:** 这篇综述探讨了“代理作为裁判”的评估方法，即利用 AI 代理来评估大型语言模型（LLM）的输出。这种方法利用 LLM 的推理能力来评估其他模型的质量和安全性，为人工评估提供了可扩展且细致的替代方案。综述追溯了该方法的演变，比较了其优缺点，并在可靠性、成本和人类一致性方面进行了评估。文章还讨论了在医学、法律、金融和教育等领域的实际应用，并指出了偏见、鲁棒性和元评估等挑战，最后提出了未来的研究方向，强调了该方法在促进可信赖、可扩展的 LLM 评估中的作用。

> **摘要翻译:** 随着大型语言模型（LLM）的能力和自主性的不断增强，评估它们的输出——尤其是在开放式和复杂任务中——已成为一个关键的瓶颈。一种新的范式正在出现：使用 AI 代理作为评估者本身。“代理作为裁判”的方法利用 LLM 的推理和视角采纳能力来评估其他模型的质量和安全性，有望提供可扩展且细致的替代人工评估的方法。在本综述中，我们定义了代理作为裁判的概念，追溯了其从单一模型裁判到动态多代理辩论框架的演变，并批判性地检查了它们的优缺点。我们将这些方法在可靠性、成本和人类一致性方面进行了比较，并调查了在医学、法律、金融和教育等领域的实际部署情况。最后，我们强调了紧迫的挑战——包括偏见、鲁棒性和元评估——并概述了未来的研究方向。通过汇集这些研究思路，我们的综述表明基于代理的裁判如何补充（但不能替代）人类的监督，这标志着朝着可信赖、可扩展的下一代 LLM 评估迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [727] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
> *AGENTiGraph：一个多智能体知识图谱框架，用于交互式、领域特定的LLM聊天机器人*

*Xinjie Zhao, Moritz Blum, Fan Gao, Yingjian Chen, Boming Yang, Luis Marquez-Carpintero, Mónica Pina-Navarro, Yanran Fu, So Morikawa, Yusuke Iwasawa, Yutaka Matsuo, Chanjun Park, Irene Li* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 知识图谱, 大型语言模型, 多智能体系统, 自然语言交互, 领域特定聊天机器人

**Comment:** CIKM 2025, Demo Track

> **TL;DR:** AGENTiGraph是一个用户友好的系统，允许非技术用户通过自然语言操作知识图谱来构建和管理领域特定的知识库，支持多轮对话和动态更新，并在教育场景的基准测试中表现优于基线模型。

**AI_Comments:** 该研究提出了一种名为AGENTiGraph的新颖框架，它有效地结合了大型语言模型（LLM）和知识图谱，为领域特定的聊天机器人提供了一个用户友好的交互和管理平台。其主要创新点在于允许非技术用户通过自然语言操作知识图谱，从而简化了知识库的构建和维护过程。该系统在处理多轮对话和动态更新方面的能力，以及在教育场景中取得的优异性能，都表明了其在企业知识管理领域的巨大潜力。然而，该研究可能需要进一步探讨在处理高度复杂或模糊的领域知识时的鲁棒性，以及在实际大规模部署中的计算效率和成本效益。

<details>
  <summary>Details</summary>

**Motivation:** 为非技术用户提供一个直观、可视化的解决方案，用于通过自然语言操作知识图谱来构建和管理领域特定的知识库，实现多轮对话和动态更新。

**Method:** AGENTiGraph采用一种灵活的设计，包括意图分类、任务规划和自动知识集成，以实现不同任务之间的无缝推理。

**Result:** 在包含3500个查询的教育场景基准测试中，AGENTiGraph的分类准确率为95.12%，执行成功率为90.45%，优于零样本基线模型。

**Conclusion:** AGENTiGraph提供了一种新的多轮企业知识管理范式，能够无缝集成LLM和结构化图谱，并有可能扩展到法律和医疗等领域的合规关键或多步骤查询。

> **ai_Abstract:** AGENTiGraph是一个创新的多智能体知识图谱框架，它使用户能够通过自然语言与知识图谱进行交互，从而构建和管理领域特定的数据。该系统特别适合非技术用户，提供了一个可视化的界面来实现知识库的增量构建和细化，并支持多轮对话和动态更新。通过意图分类、任务规划和自动知识集成等灵活设计，AGENTiGraph实现了跨任务的无缝推理。在教育场景的评估中，该系统取得了显著的成果，证明了其在处理复杂查询和适应新信息方面的潜力。

> **摘要翻译:** AGENTiGraph是一个用户友好、由智能体驱动的系统，通过自然语言操作知识图谱，实现领域特定数据的直观交互和管理。它为非技术用户提供了一个完整的、可视化的解决方案，可以逐步构建和完善他们的知识库，支持多轮对话和动态更新，而无需专门的查询语言。AGENTiGraph的灵活设计，包括意图分类、任务规划和自动知识集成，确保了不同任务之间的无缝推理。该系统在一个教育场景中对3500个查询的基准进行了评估，其表现优于强大的零样本基线（分类准确率达到95.12%，执行成功率为90.45%），表明其有潜力扩展到法律和医疗领域中合规关键或多步骤查询，例如动态整合新的法规或研究。我们的开源演示提供了一种强大的新范式，用于多轮企业知识管理，它连接了LLM和结构化图谱。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [731] [Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens](https://arxiv.org/abs/2508.01191)
> *大型语言模型（LLM）的思维链推理是海市蜃楼吗？一个数据分布视角*

*Chengshuai Zhao, Zhen Tan, Pingchuan Ma, Dawei Li, Bohan Jiang, Yancheng Wang, Yingzhen Yang, Huan Liu* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 思维链推理, 大型语言模型, 数据分布, 归纳偏差, 泛化能力

**Comment:** 

> **TL;DR:** 研究表明，大型语言模型（LLM）的思维链（CoT）推理在训练数据分布之外是脆弱的，并且可能是一种表象，而非真正的推理能力。

**AI_Comments:** 这项研究通过数据分布的视角，对思维链（CoT）推理的有效性提出了质疑，并用实验证明了其在超出训练分布时的脆弱性。研究设计了一个名为DataAlchemy的受控环境，这使得研究者能够精确地控制训练数据和测试条件，从而得出可靠的结论。这项工作对于理解大型语言模型的局限性以及未来如何构建更具鲁棒性和泛化能力的推理模型具有重要的指导意义。然而，研究可能还可以进一步探讨在何种特定情况下（例如，特定类型的数据分布变化）CoT推理会失效，以及是否有潜在的方法可以减轻这种脆弱性。

<details>
  <summary>Details</summary>

**Motivation:** 思维链（CoT）提示虽然能提高大型语言模型（LLM）在各种任务上的性能，并产生类似人类的推理步骤，但其有效性可能受到训练数据和测试查询之间分布差异的限制。本研究旨在通过数据分布视角深入探讨CoT推理，以确定它是否仅仅是模型从训练数据中学习到的归纳偏差的体现，还是真正的推理能力。

**Method:** 通过数据分布视角研究CoT推理，并从任务、长度和格式三个维度进行探讨。研究人员设计了一个名为DataAlchemy的受控环境，用于从头开始训练LLM，并在各种分布条件下对其进行系统性探测。

**Result:** 研究结果表明，CoT推理在超出训练分布时会消失，是一种脆弱的表象。

**Conclusion:** CoT推理是一种脆弱的表象，其有效性受限于训练数据分布，并且在超出该分布时会失效，这表明实现真正且可泛化的推理仍然是一个挑战。

> **ai_Abstract:** 该研究通过数据分布的视角，利用DataAlchemy环境，探究了大型语言模型（LLM）的思维链（CoT）推理。研究发现，CoT推理在超出训练数据分布时会失效，表明其本质上是一种脆弱的表象，而非真正的推理能力，这对于理解和实现可泛化的LLM推理具有重要意义。

> **摘要翻译:** 思维链（CoT）提示已被证明可以提高大型语言模型（LLM）在各种任务上的性能。通过这种方法，LLM似乎在提供答案之前会产生类似人类的推理步骤（即CoT推理），这通常会让人认为它们在进行深思熟虑的推理过程。然而，一些初步的研究结果表明，CoT推理可能比表面看起来更肤浅，这促使我们进一步探索。在本研究中，我们通过数据分布的视角研究CoT推理，并探讨CoT推理是否反映了从训练数据中学习到的结构化归纳偏差，从而使模型能够条件性地生成近似训练过程中看到的推理路径。因此，其有效性从根本上受到训练数据和测试查询之间分布差异程度的限制。通过这个视角，我们通过任务、长度和格式三个维度来剖析CoT推理。为了探讨每个维度，我们设计了DataAlchemy，一个隔离且受控的环境，用于从头开始训练LLM，并在各种分布条件下系统地探测它们。我们的结果表明，CoT推理是一种脆弱的表象，当它被推到超出训练分布之外时就会消失。这项工作让我们更深入地理解了CoT推理为何以及何时会失败，并强调了实现真正且可泛化的推理所面临的持续挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [741] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
> *超越策略优化：用于稀疏奖励长时程规划的数据策展飞轮*

*Yutong Wang, Pengliang Ji, Kaixin Li, Baolong Bi, Tao Feng, Guillaume Sartoretti* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 数据飞轮,稀疏奖励,长时程规划,大型语言模型,代理规划

**Comment:** 

> **TL;DR:** 该研究提出了一种名为BPO的三阶段框架，通过数据飞轮解决大型语言模型在多轮交互式规划中遇到的稀疏奖励和计算开销问题，并在ALFWorld、ScienceWorld和WebShop等环境中取得了最先进的成果。

**AI_Comments:** 该研究提出了一种创新的数据策展飞轮方法，有效解决了大型语言模型在稀疏奖励长时程规划中的关键挑战，尤其在信用分配和计算效率方面取得了显著进展。其三阶段框架和具体技术（如规划四元数、课程学习、奖励门控采样）为该领域提供了新的思路和实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在多轮代理规划中的应用面临稀疏奖励环境下的信用分配困难和冗长推理历史的计算开销问题。

**Method:** 提出了一种名为BPO的三阶段框架（启动、外推、精炼），构建了一个自学习数据飞轮。具体方法包括：1. 使用长短链思维融合的规划四元数来启动高效推理；2. 通过复杂性分层课程学习将模型外推到分布外任务；3. 利用奖励门控拒绝采样选择经验进行迭代精炼。

**Result:** 在ALFWorld、ScienceWorld和WebShop上的实验表明，该方法在保持显著的代币效率的同时达到了最先进的性能。

**Conclusion:** BPO框架为在长时程、稀疏奖励环境中进行代理规划的推理模型提供了一种新的解决方案。

> **ai_Abstract:** 本研究提出了BPO框架，旨在解决大型语言模型在稀疏奖励和长时程的交互式规划任务中的挑战。该框架通过一个数据飞轮，结合了规划四元数、课程学习和奖励门控采样等技术，实现了高效推理和模型迭代优化，并在多个基准测试中取得了优于现有方法的性能。

> **摘要翻译:** 大型语言推理模型在静态任务上取得了显著的成功，然而它们在交互环境中的多轮代理规划应用面临两个根本性挑战。首先，棘手的信用分配问题使得传统的强化学习在稀疏奖励环境下失效。其次，冗长的、一步一步的推理历史所带来的计算开销是令人望而却步的。为了应对这些挑战，我们提出了BPO，一个三阶段框架（启动、外推和精炼），它建立了一个自改进的数据飞轮，用于开发长时程、稀疏奖励环境下的鲁棒推理模型。我们的框架首先使用提出的长短链思维融合的规划四元数来启动高效推理。然后，它通过复杂性分层课程学习外推到分布外任务。最后，模型通过仅在通过奖励门控拒绝采样选择的经验上学习来进行迭代精炼。在ALFWorld、ScienceWorld和WebShop上的实验表明，我们的方法达到了最先进的性能，并具有显著的代币效率，为代理规划中的推理模型提供了一种新的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [751] [KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs](https://arxiv.org/abs/2508.01273)
> *KCR：通过大型语言模型中的推理解决长上下文知识冲突*

*Xianda Zheng, Zijian Huang, Meng-Fen Chiang, Michael J. Witbrock, Kaiqi Zhao* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 知识冲突,大型语言模型,长上下文,推理,强化学习,逻辑一致性

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）在处理长而冲突的上下文时常常会感到困惑。KCR框架通过训练LLM选择和遵循逻辑上更一致的上下文来解决这一问题，从而提高其解决冲突的能力。

**AI_Comments:** 该研究提出了一种新颖的框架KCR，通过强化学习来解决LLM在长上下文中的知识冲突问题，具有重要的理论和应用价值。通过训练模型关注逻辑一致性，KCR有望提升LLM在处理复杂信息时的准确性和可靠性。然而，该方法在实际应用中的计算成本和对训练数据的依赖性可能需要进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在处理来自不同来源的冲突知识，尤其是在长上下文的情况下，会遇到困难。

**Method:** 提出知识冲突推理（KCR）框架，通过强化学习训练LLM，使其能够识别和遵循包含更强逻辑一致性的推理路径（文本或知识图谱），从而解决长上下文中的跨上下文知识冲突。

**Result:** KCR框架显著提高了各种基础LLM在长上下文场景下解决知识冲突的能力，并带来了实质性的性能提升。

**Conclusion:** KCR框架能够有效增强LLM在长上下文环境中解决知识冲突的能力，通过强化逻辑一致性推理实现性能的显著提升。

> **ai_Abstract:** 本研究提出了知识冲突推理（KCR）框架，旨在解决大型语言模型（LLM）在处理长上下文时遇到的跨上下文知识冲突问题。KCR通过强化学习训练LLM，使其能够识别并优先选择逻辑上更一致的上下文进行推理，从而提升其解决冲突的能力。实验证明，该框架能有效提高LLM在长上下文场景下的冲突解决性能。

> **摘要翻译:** 知识冲突在各种来源中普遍存在，并且随着大型语言模型（LLM）的出现，其普遍性日益增加。在处理多个上下文之间的冲突时，也称为“跨上下文知识冲突”，LLM常常被冗长和冲突的上下文所混淆。为了应对这一挑战，我们提出了知识冲突推理（KCR）框架，它增强了LLM解决冲突知识的能力。KCR的关键思想是通过奖励模型选择并遵循具有更强逻辑一致性的上下文，来训练基础LLM建立正确的推理过程，当它们遇到冲突的上下文时。具体来说，我们首先从冲突的长上下文中提取推理路径，这些路径由文本或本地知识图谱表示。随后，我们采用强化学习来鼓励模型学习遵循正确推理路径而非错误推理路径的推理过程范式。这使得基础模型能够真正获得在长上下文内解决跨上下文知识冲突的能力。实验结果表明，我们的框架显著提高了各种基础模型在长上下文场景下解决知识冲突的能力，并带来了实质性的性能提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [754] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
> *Collab-Solver：混合整数线性规划的协作求解策略学习*

*Siyuan Li, Yifan Yu, Yanchen Deng, Zhihao Zhang, Mengjing Chen, Fangzhou Zhu, Tao Zhong, Jianye Hao, Peng Liu, Bo An* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 混合整数线性规划, 策略学习, 多智能体, 协作学习, 斯坦伯格博弈

**Comment:** 

> **TL;DR:** Collab-Solver 提出了一种新颖的多智能体协作策略学习框架，用于解决混合整数线性规划（MILP）问题。该框架通过将切片选择和分支作为斯坦伯格博弈进行建模，并采用两阶段学习范式，以优化 MILP 求解器中不同模块的策略。实验结果表明，Collab-Solver 显著提高了求解性能和泛化能力。

**AI_Comments:** 该研究提出了一种创新的多智能体协作学习框架，用于解决 MILP 问题，克服了现有方法忽略模块间依赖性的局限性。将博弈论应用于策略优化是一个亮点，但其计算复杂性和可扩展性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于学习的 MILP 方法独立处理求解器中各个模块的策略学习，忽略了它们之间的相互依赖性，从而损害了求解速度和质量。

**Method:** 提出了一种新颖的多智能体基础策略学习框架（Collab-Solver），用于协作优化 MILP 中多个模块的策略。将切片选择和分支的协作建模为斯坦伯格博弈，并开发了一个两阶段学习范式来稳定协作策略学习。

**Result:** 联合学习的策略在合成和大规模真实世界 MILP 数据集上都显著提高了求解性能，并且在不同实例集上表现出出色的泛化能力。

**Conclusion:** Collab-Solver 框架通过协作策略学习有效提高了 MILP 的求解性能和泛化能力。

> **ai_Abstract:** Collab-Solver 是一种新颖的多智能体协作策略学习框架，旨在解决混合整数线性规划（MILP）问题。与以往独立学习各模块策略的方法不同，Collab-Solver 将切片选择和分支的协作视为一个斯坦伯格博弈，并通过两阶段学习范式进行优化。实验证明，该方法在提高 MILP 求解性能和泛化能力方面取得了显著成效。

> **摘要翻译:** 混合整数线性规划（MILP）一直是组合优化中的一个基本问题。以往的研究设计了大量的硬编码启发式方法，并结合领域知识来解决具有挑战性的 MILP 问题。在神经网络能力日益增强的驱动下，近期的研究致力于用学习到的策略取代手动设计的启发式方法。尽管基于学习的 MILP 方法显示出巨大的潜力，但现有方法在 MILP 求解器中的每个模块独立地处理策略学习，而没有考虑它们之间的相互依赖性，这严重损害了求解速度和质量。为了解决这个问题，我们提出了一种新颖的基于多智能体的 MILP 策略学习框架（Collab-Solver），该框架可以协同优化多个模块的策略。具体来说，我们将 MILP 求解中的切片选择和分支的协作建模为斯坦伯格博弈。在此框架下，我们开发了一个两阶段学习范式来稳定协作策略学习，其中第一阶段实现数据通信的策略预训练，第二阶段进一步协调各个模块的策略学习。联合学习的策略在合成和大规模真实世界 MILP 数据集上都显著提高了求解性能。此外，Collab-Solver 学到的策略在不同实例集上还表现出出色的泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [768] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
> *从文本到轨迹：GPT-2作为上下文中的常微分方程求解器*

*Ziyang Ma, Baojian Zhou, Deqing Yang, Yanghua Xiao* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 上下文学习, 常微分方程, GPT-2, 数值计算, 泛化能力

**Comment:** 

> **TL;DR:** GPT-2可以通过上下文学习（ICL）来解决常微分方程（ODE），其性能可与欧拉法媲美，并且在处理分布外（OOD）问题时表现出良好的泛化能力。

**AI_Comments:** 该研究将LLM在ICL设置下的能力扩展到了常微分方程的求解，这是一个新颖且有意义的应用方向。实验结果表明GPT-2在处理ODE方面具有潜力，并且能够实现良好的泛化。然而，对于其学习到的“元ODE算法”的具体形式以及在更广泛的数值计算任务中的普适性，仍需进一步的深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 研究大型语言模型（LLM）在上下文学习（ICL）范式下的行为，特别是探讨LLM是否能在ICL设置下解决常微分方程（ODE）问题，以揭示ICL的潜在机制。

**Method:** 将标准的ODE问题及其解决方案构建为序列提示，并使用GPT-2模型进行评估。

**Result:** GPT-2能够有效地学习元ODE算法，其收敛行为可与欧拉法相媲美甚至更优，并且随着演示数量的增加，精度呈指数级增长。此外，GPT-2在处理分布外（OOD）问题时表现出稳健的外插能力。

**Conclusion:** GPT-2在ICL设置下可以有效解决常微分方程问题，为理解ICL机制和LLM在非线性数值问题中的应用提供了新的见解。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）如GPT-2在上下文学习（ICL）范式下解决常微分方程（ODE）问题的能力。研究人员将ODE问题及其解决方案转化为序列提示，并发现GPT-2能够有效地学习一种元ODE算法，其性能与传统的欧拉法相当甚至更优。此外，GPT-2在处理未见过（分布外）的ODE问题时也展现出良好的泛化能力。这些发现不仅加深了对ICL机制的理解，也揭示了LLM在解决复杂非线性数值问题方面的潜力。

> **摘要翻译:** 在情境学习（ICL）已成为大型语言模型（LLM）中的一种新范式，它使LLM能够通过条件化提示中的几个示例来执行新任务。然而，ICL在自然语言处理（NLP）任务中的高度非线性行为仍然知之甚少。为了阐明其潜在机制，本文研究了LLM是否能在ICL设置下解决常微分方程（ODE）。我们将标准的ODE问题及其解决方案制定为序列提示，并在这些任务上评估GPT-2模型。在两种ODE上的实验表明，GPT-2能够有效地学习元ODE算法，其收敛行为可与欧拉法相媲美，甚至更优，并且随着演示数量的增加，可以实现指数级的精度提升。此外，该模型能够泛化到分布外（OOD）问题，表现出稳健的外插能力。这些实证研究为理解ICL在NLP中的机制及其在解决非线性数值问题中的潜力提供了新的见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [796] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
> *超越表面检测：通过元操作推理实现认知驱动的防御以应对越狱攻击*

*Rui Pu, Chaozhuo Li, Rui Ha, Litian Zhang, Lirong Qiu, Xi Zhang* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 越狱攻击, 大型语言模型, 认知驱动防御, 元操作推理, 强化学习

**Comment:** 

> **TL;DR:** 提出了一种名为认知驱动防御（CDD）的框架，通过元操作推理来防御大型语言模型的越狱攻击，并在实验中证明了其在防御已知和未知攻击方面的有效性。

**AI_Comments:** 该研究提出了一种新颖的认知驱动防御框架，通过元操作推理来对抗越狱攻击，解决了现有方法泛化能力不足的问题。通过结合监督微调和强化学习，该方法在防御已知和未知攻击方面均表现出色，为LLM的安全部署提供了有前景的解决方案。然而，该框架的计算复杂性和对不同类型越狱攻击的适应性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的越狱攻击防御方法依赖于浅层模式匹配，难以应对新的攻击策略。

**Method:** 提出认知驱动防御（CDD）框架，该框架通过元操作（隐藏有害意图的基本操作）来针对越狱提示的底层结构。CDD通过结构化推理链模拟人类认知推理，首先进行全局感知，然后进行局部分析以揭示隐藏的操作。通过在结构化推理链上进行监督微调，模型学会识别和推理已知的操作模式。为了增强对未知威胁的泛化能力，引入了熵引导的强化学习算法（EG-GRPO）来鼓励探索新的元操作类型和变体。

**Result:** 实验表明，CDD可以实现最先进的防御性能，并对未知的越狱攻击表现出强大的泛化能力。

**Conclusion:** CDD框架通过利用元操作推理，能够有效防御越狱攻击，并具有良好的泛化能力，为大型语言模型的安全部署提供了新的途径。

> **ai_Abstract:** 该研究提出了一种名为认知驱动防御（CDD）的新框架，旨在通过模拟人类认知推理和利用元操作来防御大型语言模型（LLM）的越狱攻击。与依赖浅层模式匹配的现有方法不同，CDD通过结构化推理链分析提示的底层操作，并结合熵引导的强化学习算法（EG-GRPO）来提高对未知攻击的泛化能力。实验结果表明，CDD在防御越狱攻击方面取得了领先的性能，并能有效应对未知的攻击策略。

> **摘要翻译:** 防御大型语言模型（LLM）免受越狱攻击对其安全可靠的部署至关重要。现有的防御方法通常依赖于浅层的模式匹配，难以泛化到新颖且未见的攻击策略。为了应对这一挑战，我们提出了认知驱动防御（CDD）框架，该框架通过应用元操作（隐藏有害意图的基本操作）来针对越狱提示的底层结构。CDD通过结构化推理链模拟人类认知推理。它首先进行全局感知，然后进行局部分析以揭示隐藏的操作。通过在结构化推理链上进行监督微调，模型学会识别和推理已知的操作模式。为了增强对未知威胁的泛化能力，引入了熵引导的强化学习算法（EG-GRPO）来鼓励探索新的元操作类型和变体。实验表明，CDD可以实现最先进的防御性能，并对未知的越狱攻击表现出强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [811] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
> *树状推理：通过多智能体证据树推理迈向复杂医学诊断*

*Qi Peng, Jialin Cui, Jiayuan Xie, Yi Cai, Qing Li* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型,医学诊断,多智能体推理,证据树,推理深度

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 该研究提出了一种名为Tree-of-Reasoning (ToR)的新型多智能体框架，通过引入树状结构来记录推理路径和临床证据，并结合交叉验证机制，以解决大型语言模型在复杂医学诊断中推理深度不足的问题，实验结果表明其性能优于现有方法。

**AI_Comments:** 该研究提出了一种创新的多智能体框架ToR，通过结构化的推理路径和交叉验证机制来提升LLM在复杂医学诊断中的表现，具有重要的临床应用潜力。然而，其在处理大规模、异构医疗数据时的可扩展性和鲁棒性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM在处理复杂医学诊断任务时，由于推理深度不足，容易在大量专业医疗数据中丢失信息或出现逻辑跳跃，导致诊断错误。

**Method:** 提出Tree-of-Reasoning (ToR)框架，该框架采用树状结构清晰记录LLM的推理路径和临床证据，并引入交叉验证机制确保多智能体决策的一致性。

**Result:** 在真实世界医学数据上的实验结果表明，ToR框架的性能优于现有的基线方法。

**Conclusion:** ToR框架通过其树状结构和交叉验证机制，有效提高了多智能体在复杂医学场景下的临床推理能力，克服了现有LLM在复杂医学诊断中的局限性。

> **ai_Abstract:** 该研究提出了一种名为Tree-of-Reasoning (ToR)的新型多智能体框架，旨在解决大型语言模型在复杂医学诊断中推理深度不足的问题。ToR通过引入树状结构来记录推理路径和临床证据，并结合交叉验证机制来确保多智能体决策的一致性，从而提高临床推理能力。实验结果表明，该框架在真实世界医学数据上表现优于现有方法。

> **摘要翻译:** 大型语言模型（LLM）在医学领域展现出巨大潜力。然而，现有模型在面对现实世界中的复杂医学诊断任务时仍显不足。这主要是因为它们缺乏足够的推理深度，在处理大量专业医疗数据时会导致信息丢失或逻辑跳跃，从而引发诊断错误。为应对这些挑战，我们提出了Tree-of-Reasoning (ToR)，一个旨在处理复杂场景的新型多智能体框架。具体而言，ToR引入了一个树状结构，可以清晰地记录LLM的推理路径和相应的临床证据。同时，我们提出了一个交叉验证机制，以确保多智能体决策的一致性，从而提高多智能体在复杂医学场景下的临床推理能力。在真实世界医学数据上的实验结果表明，我们的框架可以取得优于现有基线方法的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [812] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
> *合同评估：评估大语言模型在商业合同中识别条款级法律风险的基准*

*Shuang Liu, Zelong Li, Ruoyun Ma, Haiyan Zhao, Mengnan Du* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 法律风险识别, 合同评估, 开源模型, 专有模型

**Comment:** 

> **TL;DR:** 本研究提出了ContractEval基准，评估了15个开源大语言模型和4个专有大语言模型在识别商业合同中条款级法律风险方面的能力。结果显示，专有模型在正确性和输出有效性方面优于开源模型，但一些开源模型在特定维度上具有竞争力。模型规模、推理模式、量化等因素都会影响模型表现。总体而言，开源模型在法律风险识别方面仍需改进，以达到高风险法律环境的要求。

**AI_Comments:** 该研究首次提出了ContractEval基准，填补了在评估LLMs用于法律风险识别方面的空白。研究方法系统，评估了大量模型，结果具有参考价值。然而，对于“懒惰”等行为的解释可能需要更深入的分析，并且模型的“正确性”和“输出有效性”的具体衡量标准在摘要中未详细说明。

<details>
  <summary>Details</summary>

**Motivation:** 随着对本地部署开源大语言模型以处理法律任务和保护数据机密性的兴趣日益浓厚，本研究旨在评估开源大语言模型在识别商业合同中条款级法律风险方面能否媲美专有大语言模型。

**Method:** 使用CUAD数据集，评估了4个专有大语言模型和15个开源大语言模型在识别商业合同中条款级法律风险方面的能力。

**Result:** 1. 专有模型在正确性和输出有效性方面优于开源模型，但部分开源模型在特定维度上表现具有竞争力。2. 开源模型规模越大，表现越好，但性能提升随模型增大而减缓。3. 推理模式提高了输出有效性，但降低了正确性。4. 开源模型更频繁地生成“无相关条款”的响应。5. 模型量化加速了推理，但牺牲了性能，显示了效率与准确性之间的权衡。

**Conclusion:** 尽管大多数大语言模型在法律风险识别方面的表现与初级法律助理相当，但开源模型需要针对性的微调，以确保在高风险法律环境中的正确性和有效性。ContractEval为未来法律领域大语言模型的开发提供了坚实的基准。

> **ai_Abstract:** 本研究提出了ContractEval基准，旨在评估开源和专有大型语言模型（LLMs）在识别商业合同中条款级法律风险方面的能力。通过在CUAD数据集上对15个开源模型和4个专有模型进行评估，研究发现专有模型在准确性和输出质量上普遍优于开源模型，尽管一些开源模型在特定方面表现出色。研究还指出了模型规模、推理模式和量化等因素对模型性能的影响，并强调了开源模型在法律领域的应用潜力与挑战。

> **摘要翻译:** 大型语言模型（LLMs）在法律风险分析等专业领域的潜力仍有待探索。为了响应在本地部署开源LLMs以处理法律任务并同时保护数据机密性方面日益增长的兴趣，本文介绍了ContractEval，这是第一个旨在全面评估开源LLMs在识别商业合同中条款级法律风险方面能否媲美专有LLMs的基准。我们使用CUAD（合同理解Atticus数据集）评估了4个专有LLMs和15个开源LLMs。我们的结果突出了五个关键发现：（1）专有模型在正确性和输出有效性方面均优于开源模型，尽管一些开源模型在某些特定维度上具有竞争力。（2）较大的开源模型通常表现更好，但随着模型增大，性能提升逐渐减缓。（3）推理（“思考”）模式提高了输出有效性，但降低了正确性，这可能是因为过度复杂化了简单的任务。（4）即使存在相关条款，开源模型也更频繁地生成“无相关条款”的响应。这表明其在思考时“懒惰”或对提取相关内容的信心不足。（5）模型量化加速了推理，但以牺牲性能为代价，显示了效率与准确性之间的权衡。这些发现表明，尽管大多数LLMs的表现与初级法律助理相当，但开源模型需要针对性的微调，以确保在高风险法律环境中的正确性和有效性。ContractEval为指导未来法律领域LLMs的开发提供了坚实的基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [824] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
> *EoH-S：使用LLM进化启发式集合以实现自动化启发式设计*

*Fei Liu, Yilu Liu, Qingfu Zhang, Xialiang Tong, Mingxuan Yuan* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 自动化启发式设计, 大型语言模型, 启发式集, 互补性, 模因搜索

**Comment:** 

> **TL;DR:** 该研究提出了一种新的自动化启发式集设计（AHSD）方法，名为EoH-S，旨在通过生成一组互补的启发式方法来解决现有方法只设计单一启发式方法导致泛化能力差的问题。EoH-S通过互补种群管理和互补感知模因搜索机制，能够生成高质量且互补的启发式方法，并在实验中显示出优于现有方法的性能。

**AI_Comments:** 这项研究提出的EoH-S方法在自动化启发式设计领域具有重要意义，它通过引入“启发式集”的概念和相应的生成机制，有效解决了单一启发式方法泛化能力不足的痛点。其提出的两个新机制——互补种群管理和互补感知模因搜索——为生成高质量、互补的启发式方法提供了创新性的解决方案。实验结果显示出显著的性能提升，证明了该方法的有效性和潜力。然而，该方法在实际应用中的可扩展性、计算成本以及对不同领域问题的适应性仍需进一步研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化启发式设计（AHD）方法仅能设计单一启发式方法，导致在不同分布或设置下泛化能力较差。为了解决这个问题，需要一种能够生成一组互补启发式方法以适应不同问题实例的AHD方法。

**Method:** 提出了一种新的自动化启发式集设计（AHSD）的公式化方法，并开发了EoH-S（Evolution of Heuristic Set）算法来应用该公式化方法。EoH-S包含互补种群管理和互补感知模因搜索两个新机制，用于生成高质量且互补的启发式方法。

**Result:** 在三个具有不同大小和分布的AHD任务的实验中，EoH-S持续优于现有的最先进的AHD方法，性能提升高达60%。

**Conclusion:** EoH-S通过其新颖的AHSD公式化方法和两个核心机制，成功地生成了高质量且互补的启发式方法集，有效解决了单一启发式方法泛化能力不足的问题，并在多个任务中取得了显著的性能提升。

> **ai_Abstract:** 该研究提出了一种名为EoH-S的新型自动化启发式集设计（AHSD）方法，旨在通过生成一组互补的启发式方法来解决现有方法在处理不同问题实例时泛化能力不足的问题。EoH-S通过采用互补种群管理和互补感知模因搜索等创新机制，能够有效地设计出高质量且互补的启发式方法集，并在实验中展现出优于现有方法的性能。

> **摘要翻译:** 近年来，使用大型语言模型（LLM）进行自动化启发式设计（AHD）已取得显著成功。尽管现有方法效果显著，但它们仅能设计单一启发式方法来服务所有问题实例，这常常导致在不同分布或设置下的泛化能力较差。为了解决这个问题，我们提出了自动化启发式集设计（AHSD），这是一种用于LLM驱动的AHD的新公式化方法。AHSD的目标是自动生成一个小型互补启发式集来服务于多样化的问题实例，使得每个问题实例都能被该集合中的至少一个启发式方法优化。我们证明了AHSD的目标函数是单调和超模的。然后，我们提出了EoH-S来将AHSD公式化方法应用于LLM驱动的AHD。通过互补种群管理和互补感知模因搜索两个新颖的机制，EoH-S能够有效地生成一组高质量且互补的启发式方法。在跨越各种大小和分布的众多实例的三个AHD任务上的全面实验结果表明，EoH-S持续优于现有的最先进的AHD方法，并取得了高达60%的性能提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [837] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
> *MissDDIM：表格数据插补的确定性高效条件扩散*

*Youran Zhou, Mohamed Reda Bouadjenek, Sunil Aryal* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 表格数据插补, 扩散模型, DDIM, 条件扩散, 推理效率

**Comment:** 

> **TL;DR:** MissDDIM 是一种基于 DDIM 的表格数据插补框架，解决了现有随机扩散模型推理延迟高和输出不确定的问题。

**AI_Comments:** 该研究通过将 DDIM 模型应用于表格数据插补，解决了现有随机扩散模型在效率和输出稳定性方面的关键挑战。通过提高推理速度和输出确定性，MissDDIM 有潜力在实际应用中发挥重要作用，尽管其在处理复杂数据分布方面的能力仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于随机去噪扩散概率模型（DDPM）的缺失数据插补方法存在推理延迟高和输出不确定的问题，限制了它们在实际表格数据应用中的使用。

**Method:** 提出了一种名为 MissDDIM 的条件扩散框架，该框架改编自去噪扩散隐式模型（DDIM），用于表格数据插补。

**Result:** MissDDIM 解决了现有方法推理延迟高和输出不确定的问题，尽管随机采样可以实现多样化的补全，但也会引入复杂的输出变异性。

**Conclusion:** MissDDIM 框架通过采用 DDIM 模型，有望提高表格数据插补的效率和输出的确定性，从而克服现有随机扩散模型的局限性。

> **ai_Abstract:** 本文提出了一种名为 MissDDIM 的新颖条件扩散框架，用于表格数据插补。MissDDIM 基于去噪扩散隐式模型（DDIM），旨在解决现有基于随机去噪扩散概率模型（DDPM）的方法在推理延迟和输出不确定性方面存在的问题，这些问题限制了它们在实际表格数据场景中的应用。

> **摘要翻译:** 扩散模型最近作为缺失数据插补的强大工具出现，通过对观测变量和未观测变量的联合分布进行建模。然而，现有的方法，通常基于随机去噪扩散概率模型（DDPM），存在推理延迟高和输出不确定的问题，限制了它们在实际表格数据设置中的应用。为了解决这些不足，我们在本文中提出了 MissDDIM，一个条件扩散框架，用于表格插补改编去噪扩散隐式模型（DDIM）。虽然随机采样能够实现多样化的补全，但它也会引入输出变异性，从而使下游处理复杂化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [852] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
> *T2UE：从文本描述生成不可学示例*

*Xingjun Ma, Hanxun Huang, Tianwei Song, Ye Sun, Yifeng Gao, Yu-Gang Jiang* | **Category: cs.AI, cs.CR, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 不可学示例, T2UE, 文本到图像, 数据隐私, 零接触保护

**Comment:** To appear in ACM MM 2025

> **TL;DR:** 该研究提出了一种名为T2UE的新框架，允许用户仅使用文本描述生成不可学示例（UE），以保护包含用户隐私数据的模型免受未经授权的训练。T2UE通过文本到图像模型将文本映射到图像（噪声）空间，并结合误差最小化框架来生成有效的不可学噪声，解决了现有方法计算成本高且需要暴露原始数据的隐私悖论。实验证明，T2UE保护的数据能显著降低下游任务的性能，且保护效果可泛化到不同模型和监督学习场景，实现了“零接触数据保护”。

**AI_Comments:** 该研究提出的T2UE框架在解决大规模预训练模型的数据隐私问题上迈出了重要一步。通过仅利用文本描述生成不可学示例，它巧妙地规避了现有方法中存在的计算成本高昂和隐私暴露的悖论，实现了真正的“零接触数据保护”。这种方法的创新性在于将文本到图像生成技术与对抗性样本生成相结合，以达到保护数据的目的。其泛化能力和在下游任务中的有效性得到了实验的充分验证，为如何在保护隐私的同时利用和共享数据提供了新的思路。然而，未来研究可以进一步探索不同文本到图像模型对UE生成效果的影响，以及在更复杂的模型架构和应用场景下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有不可学示例（UE）的生成方法需要同时优化图像和文本描述，计算成本高昂且通常需要在外部服务上进行，这与保护用户隐私的初衷相悖，因为用户需要先暴露数据才能获得保护。这种隐私悖论阻碍了实际、可扩展的数据保护解决方案的发展。

**Method:** 提出了一种名为T2UE（Text-to-Unlearnable Example）的新框架。该框架利用文本描述生成不可学示例，无需原始图像数据。具体而言，它使用文本到图像（T2I）模型将文本描述映射到图像（噪声）空间，并结合误差最小化框架来生成有效的不可学噪声。

**Result:** T2UE保护的数据能够显著降低下游任务（如跨模态检索）中先进模型的性能。此外，T2UE的保护效果能够泛化到不同的模型架构，甚至在监督学习场景下也有效。

**Conclusion:** T2UE框架实现了“零接触数据保护”，仅基于文本描述即可保护个人数据，无需直接暴露数据，解决了现有UE生成方法的隐私悖论，并展示了其在保护大规模预训练模型方面的潜力。

> **ai_Abstract:** T2UE是一个创新的框架，它利用文本描述生成不可学示例（UE），以保护包含用户数据的模型免受未经授权的训练。与需要原始数据和高计算成本的传统方法不同，T2UE使用文本到图像模型和误差最小化来创建有效的噪声，从而解决了隐私悖论。实验证明，T2UE能够有效降低模型在下游任务中的性能，并具有良好的泛化性，实现了无需直接数据访问即可进行数据保护。

> **摘要翻译:** 像CLIP这样的大规模预训练框架彻底改变了多模态学习，但它们依赖于网络抓取的数据集，其中经常包含用户隐私数据，这引起了对滥用的严重担忧。不可学示例（UE）作为一种有前途的对策，可以防止未经授权的模型训练，它采用精心设计的不可学噪声来破坏从受保护数据中学习有意义表征的过程。当前的方法通常通过同时优化图像及其相关的文本描述（或标签）的不可学噪声来生成UE。然而，这个优化过程对于设备上的执行来说计算成本可能很高，迫使用户依赖外部第三方服务。这造成了一个根本性的隐私悖论：用户必须首先将他们的数据暴露给这些服务才能获得保护，从而在这个过程中损害了隐私。这种矛盾严重阻碍了实用、可扩展的数据保护解决方案的发展。为了解决这个悖论，我们引入了文本到不可学示例（T2UE），这是一个新颖的框架，使用户能够仅使用文本描述来生成UE。T2UE通过使用文本到图像（T2I）模型将文本描述映射到图像（噪声）空间，并结合误差最小化框架来产生有效的不可学噪声，从而绕开了对原始图像数据的需求。大量的实验表明，T2UE保护的数据在下游任务（例如跨模态检索）中对最先进的模型性能造成了显著的损害。值得注意的是，这种保护效果能够泛化到各种架构，甚至推广到监督学习设置。我们的工作证明了“零接触数据保护”的可行性，即可以仅根据个人数据的文本描述来保护他们，从而无需直接暴露数据。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [854] [A Wireless Foundation Model for Multi-Task Prediction](https://arxiv.org/abs/2507.05938)
> *用于多任务预测的无线基础模型*

*Yucheng Sheng, Jiacheng Wang, Xingyu Zhou, Le Liang, Hao Ye, Shi Jin, Geoffrey Ye Li* | **Category: cs.AI, cs.IT, cs.LG, math.IT** | **Updated: 2025-07-09**

**Keywords:** 无线基础模型,多任务预测,因果Transformer,零样本学习,泛化能力

**Comment:** 

> **TL;DR:** 提出了一种统一的无线基础模型，使用单变量分解、粒度编码和因果Transformer进行多任务预测，并在各种无线场景中实现了零样本和泛化性能。

**AI_Comments:** 该研究提出了一种在无线通信领域具有开创性的基础模型，解决了传统方法在多任务预测和泛化能力上的局限性。模型架构的创新性，特别是单变量分解、粒度编码和因果Transformer的应用，为处理复杂多变的无线网络环境提供了新的思路。零样本学习能力的实现是该研究的一个亮点，预示着未来无线网络预测模型的发展方向。然而，模型的训练效率和在极端或高度动态环境下的鲁棒性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度学习方法在无线网络参数预测中泛化能力不足，无法适应不同场景和任务。

**Method:** 提出了一种统一的基础模型，采用单变量分解统一任务，编码粒度以感知预测间隔，并使用因果Transformer作为骨干网络，同时通过补丁掩码策略支持任意输入长度。

**Result:** 该模型在大型数据集上训练后，对未见过的场景表现出强大的泛化能力，并在新任务上实现了超越传统全样本基线的零样本性能。

**Conclusion:** 所提出的基础模型通过其统一的框架和先进的架构，能够有效地处理无线网络中的多任务预测问题，并展现出优越的泛化和零样本能力。

> **ai_Abstract:** 该研究提出了一种新颖的无线基础模型，用于解决移动通信网络中多任务预测的挑战。该模型通过单变量分解、粒度编码和因果Transformer架构，能够统一处理包括CSI、用户位置和网络流量在内的多种预测任务，并支持不同的预测间隔。此外，通过采用补丁掩码策略，模型能够处理任意长度的输入。实验结果表明，该基础模型在大型数据集上训练后，不仅能有效泛化到未知的场景，还能在新的任务上实现优于传统方法的零样本性能。

> **摘要翻译:** 随着移动通信网络日益增长的复杂性和动态性，准确预测信道状态信息（CSI）、用户位置和网络流量等关键系统参数，对于广泛的物理（PHY）层和介质访问控制（MAC）层任务至关重要。尽管传统的基于深度学习（DL）的方法已广泛应用于此类预测任务，但它们在不同场景和任务之间的泛化能力方面常常遇到困难。作为回应，我们提出了一种用于无线网络中多任务预测的统一基础模型，该模型支持不同的预测间隔。所提出的模型强制执行单变量分解以统一异构任务，编码粒度以感知间隔，并使用因果Transformer骨干网络进行准确预测。此外，我们在训练期间引入了补丁掩码策略以支持任意输入长度。在大型数据集上训练后，所提出的基础模型对未见过的场景表现出强大的泛化能力，并在新任务上实现了超越传统全样本基线的零样本性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [868] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
> *迈向可验证的虚假信息检测：一个多工具LLM代理框架*

*Zikun Cui, Tianyi Huang, Chia-En Chiang, Cuiqianhe Du* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 虚假信息检测,LLM代理,可验证推理,来源可信度,事实核查

**Comment:** 

> **TL;DR:** 该研究提出了一种创新的可验证虚假信息检测LLM代理，该代理通过与多种网络来源动态交互来主动验证信息，评估信息来源的可信度，综合证据，并提供完整的可验证推理过程。该代理的架构包括精确的网络搜索工具、来源可信度评估工具和数值声明验证工具，能够执行多步验证策略、维护证据日志并形成全面的评估结论。实验结果表明，该代理在虚假信息检测准确性、推理透明度和抗改写能力方面优于基线方法。

**AI_Comments:** 该研究提出的多工具LLM代理框架在虚假信息检测方面具有创新性，通过引入可验证的推理过程和多样的工具来提高检测的准确性和透明度。然而，对“来源可信度”的量化和评估方法可能需要更详细的说明，并且在实际应用中，该代理对动态变化的网络信息的实时响应能力和处理大规模信息的能力也值得进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的普及，虚假信息的检测变得越来越重要和复杂。

**Method:** 设计了一个包含精确网络搜索工具、来源可信度评估工具和数值声明验证工具的LLM代理架构，以执行多步验证策略、维护证据日志并形成全面的评估结论。

**Result:** 该代理在虚假信息检测准确性、推理透明度和抗改写能力方面优于基线方法。

**Conclusion:** 该研究提出的可验证虚假信息检测LLM代理提供了一种新的可信赖的AI辅助事实核查范式。

> **ai_Abstract:** 本研究提出了一种创新的、基于LLM代理的可验证虚假信息检测框架。该框架超越了传统的二元判断，通过集成精确的网络搜索、来源可信度评估和数值声明验证工具，主动与网络资源互动以验证信息、评估可信度并综合证据。实验证明，该方法在准确性、推理透明度和抗改写能力方面优于现有方法，为AI驱动的事实核查开辟了新途径。

> **摘要翻译:** 随着大型语言模型（LLMs）的普及，虚假信息的检测变得越来越重要和复杂。本研究提出了一个创新的可验证虚假信息检测LLM代理，它超越了传统的真/假二元判断。该代理通过与多种网络来源动态交互来主动验证信息，评估信息来源的可信度，综合证据，并提供完整的可验证推理过程。我们设计的代理架构包括三个核心工具：精确的网络搜索工具、来源可信度评估工具和数值声明验证工具。这些工具使代理能够执行多步验证策略、维护证据日志并形成全面的评估结论。我们使用FakeNewsNet等标准虚假信息数据集进行评估，并与传统的机器学习模型和LLM进行比较。评估指标包括标准的分类指标、推理过程的质量评估以及针对改写内容的鲁棒性测试。实验结果表明，我们的代理在虚假信息检测准确性、推理透明度和抗改写能力方面优于基线方法，为可信赖的AI辅助事实核查提供了一个新范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [881] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
> *用于模拟智能教育中不同通信模式的AgentSME*

*Wen-Xi Yang, Tian-Fang Zhao* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** AgentSME, 智能教育, 生成代理, 通信模式, LLM

**Comment:** 

> **TL;DR:** AgentSME是一个利用大型语言模型（LLM）的统一生成代理框架，用于智能教育，支持Solo、Mono和Echo三种通信模式，以提高准确性和内容多样性。

**AI_Comments:** 该研究提出了一种新颖的AgentSME框架，有效地解决了智能教育领域生成代理模型中通信模式多样性的问题。通过引入Solo、Mono和Echo三种模式，并结合准确率和多样性指数进行评估，为未来智能教育系统的发展提供了重要的实践指导和理论依据。

<details>
  <summary>Details</summary>

**Motivation:** 智能教育中的生成代理模型相对不发达，教育环境复杂，需要个性化的人际沟通。

**Method:** 提出AgentSME统一生成代理框架，采用LLM驱动，包含Solo、Mono、Echo三种通信模式。使用准确率和三个多样性指数评估，并在基础和高容量配置下测试了六种LLM。

**Result:** Echo通信模式在准确率上表现最佳，DeepSeek在多样性方面表现最佳。

**Conclusion:** AgentSME框架为提升代理学习能力和启发智能教育模型提供了有价值的见解，特别是在Echo模式下。

> **ai_Abstract:** 本文提出了AgentSME，一个基于LLM的统一生成代理框架，用于解决智能教育中通信模式的挑战。该框架支持Solo、Mono和Echo三种通信模式，并通过准确率和多样性指数进行评估。实验结果表明，Echo模式在准确率上表现最优，而DeepSeek在多样性上表现突出，为智能教育领域提供了改进代理学习能力的新思路。

> **摘要翻译:** 生成代理模型，特别是针对智能教育的代理模型，至关重要，但目前仍相对不发达。一个关键的挑战源于教育环境固有的复杂性：学习者是具有不同认知行为的人类，而教学法则根本上以个性化的人际沟通为中心。为了解决这个问题，本文提出了AgentSME，一个由LLM驱动的统一生成代理框架。模型考虑了三种定向通信模式，即Solo、Mono和Echo，反映了不同的代理自主性和沟通互惠性。准确率被采纳为主要的评估指标，并辅以旨在评估推理内容多样性的三个多样性指数。测试了六种广泛使用的LLM，以验证不同模型层级通信模式的鲁棒性，这些模型层级均等分为基础容量和高容量配置。结果表明，采用Echo通信模式的生成代理在准确率得分方面最高，而DeepSeek在多样性方面表现最佳。本研究为提高代理学习能力和启发智能教育模型提供了有价值的信息。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [915] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
> *迈向可验证的合成数据生成优化建模代理*

*Vinicius Lima, Dzung T. Phan, Jayant Kalagnanam, Dhaval Patel, Nianjun Zhou* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 优化建模, 大语言模型, 合成数据, 可验证性, OptiTrust

**Comment:** 25 pages

> **TL;DR:** 该研究提出了一种框架，通过可验证的合成数据生成流程来训练值得信赖的大语言模型（LLM）优化建模代理。该框架专注于线性和混合整数线性规划，能够将结构化符号表示系统地转换为自然语言描述、数学公式和求解器可执行代码。通过为每个实例提供已知的最优解，该方法确保了完全的可验证性，并允许自动过滤教师模型生成的低质量演示。研究人员还提出了一个名为OptiTrust的模块化LLM代理，该代理通过多阶段翻译、分步演示、多语言推理和多数投票交叉验证，实现了从自然语言到求解器就绪代码的转换。OptiTrust在标准基准测试中取得了最先进的性能，在7个数据集中有6个实现了最高的准确率。

**AI_Comments:** 该研究在LLM在优化建模领域的应用方面取得了重要进展，通过可验证的合成数据生成解决了关键的信任问题。OptiTrust代理的性能表现令人印象深刻，尤其是在处理多语言和多步骤推理方面。然而，该方法在处理更复杂的优化问题类型（如非线性规划）或更大规模的数据集方面的可扩展性和鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 开发值得信赖的大语言模型（LLM）优化建模代理，以应对现实世界优化应用的需求。

**Method:** 提出一个框架，通过可验证的合成数据生成流程来训练LLM优化建模代理。该流程将结构化符号表示转换为自然语言描述、数学公式和求解器可执行代码，并确保每个实例都有已知的最优解。引入OptiTrust代理，该代理执行从自然语言到求解器就绪代码的多阶段翻译，利用分步演示、多语言推理和多数投票交叉验证。

**Result:** OptiTrust代理在标准基准测试中取得了最先进的性能，在7个数据集中的6个上准确率最高，并在其中3个上比次优算法高出至少8个百分点。

**Conclusion:** 该方法提供了一种可扩展、可验证且有原则的途径，用于构建可靠的LLM优化建模代理，以应对现实世界的优化应用。

> **ai_Abstract:** 本研究提出了一种名为OptiTrust的框架和LLM代理，用于训练用于优化建模的可信赖代理。该方法通过可验证的合成数据生成流程，将结构化问题表示转换为自然语言、数学公式和求解器代码，并利用教师模型生成的演示进行监督微调。OptiTrust在标准基准测试中表现出色，展示了其在现实世界优化应用中的潜力。

> **摘要翻译:** 我们提出了一个框架，通过一个可验证的合成数据生成流程来训练值得信赖的用于优化建模的大语言模型（LLM）代理。我们的方法专注于线性和混合整数线性规划，从结构化符号表示开始，系统地生成自然语言描述、数学公式和求解器可执行代码。通过以已知最优解对每个实例进行程序化构造，该流程确保了完全的可验证性，并能够自动过滤由教师模型生成的低质量演示。每个数据集实例包括优化问题的结构化表示、相应的自然语言描述、经过验证的最优解以及由教师模型生成的、展示如何跨多种优化建模语言对问题进行建模和求解的分步演示。这使得专门针对优化任务的开源LLM能够进行监督微调。为了实现该流程的运行，我们引入了OptiTrust，一个模块化的LLM代理，它利用分步演示、多语言推理和多数投票交叉验证，执行从自然语言到求解器就绪代码的多阶段翻译。我们的代理在标准基准测试中取得了最先进的性能。在7个数据集中，它在6个数据集上取得了最高的准确率，并在其中3个数据集上比次优算法高出至少8个百分点。我们的方法为构建可靠的LLM优化应用代理提供了一条可扩展、可验证且有原则的路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [937] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
> *大型语言模型能否弥合环境知识的差距？*

*Linda Smail, David Santandreu Calonge, Firuz Kamalov, Nur H. Orak* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型,环境教育,知识差距,人工智能,GPT

**Comment:** 20 pages, 3 figures, 7 tables. No external funding

> **TL;DR:** 大型语言模型在环境知识方面具有巨大潜力，但可能需要人类专家进行事实核查。

**AI_Comments:** 该研究强调了LLM在环境教育中的应用潜力，同时也指出了对人类专业知识进行事实核查的必要性，这是一个重要的考虑因素。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型在弥合大学生的环境知识差距方面的潜力，并促进环境教育。

**Method:** 使用环境知识测试（EKT-19）和特定问题来评估学生和AI模型（GPT-3.5、GPT-4、GPT-4o、Gemini、Claude Sonnet、Llama 2）的环境知识。

**Result:** AI模型拥有广泛且易于获取的知识库，可以增强学生和教职员工的能力，但可能需要人类环境科学专家来验证信息的准确性。

**Conclusion:** 大型语言模型在环境教育中具有巨大潜力，可以作为有价值的资源，但为了确保准确性，仍需人类专家的监督。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在缩小大学生环境知识鸿沟和促进环境教育方面的潜力。通过使用环境知识测试（EKT-19）和特定问题，研究人员将学生与GPT-3.5、GPT-4、GPT-4o、Gemini、Claude Sonnet和Llama 2等模型进行了比较。结果表明，虽然LLMs拥有庞大且有效的知识库，但人类环境科学专家的监督对于确保信息的准确性仍然至关重要。

> **摘要翻译:** 本研究调查了人工智能（AI）模型在弥合大学生环境知识差距方面的潜力。通过关注GPT-3.5、GPT-4、GPT-4o、Gemini、Claude Sonnet和Llama 2等知名大型语言模型（LLM），评估它们在传达环境概念方面的有效性，并因此促进环境教育。本研究采用标准化的环境知识测试（EKT-19）工具，并辅以有针对性的问题，以评估大学生在环境知识方面与AI模型生成响应的比较。本研究结果表明，虽然AI模型拥有广泛、易于获取且有效的知识库，有潜力赋能学生和教职员工，但环境科学领域的人类学科专家可能仍有必要验证所提供信息的准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [958] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
> *带有Y_0的因果识别*

*Charles Tapley Hoyt, Craig Bakker, Richard J. Callahan, Joseph Cottam, August George, Benjamin M. Gyori, Haley M. Hummel, Nathaniel Merrill, Sara Mohammad Taheri, Pruthvi Prakash Navada, Marc-Antoine Parent, Adam Rupe, Olga Vitek, Jeremy Zucker* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 因果识别, Y0 Python包, 符号估计量, ADMG, 定性因果分析

**Comment:** 

> **TL;DR:** Y0是一个Python包，用于因果识别，它将因果查询转化为可识别的估计量，并使用ADMG来表示具有未观测混淆因子的因果图。

**AI_Comments:** 该研究介绍了一个名为Y0的Python包，用于因果识别。该包专注于定性分析，即在估计因果关系强度之前确定因果关系是否可以从可用数据中识别出来。它支持干预性、反事实和可运输性查询，并能处理来自随机对照试验、观察性研究或两者的混合数据。Y0包包括一个用于表示因果查询和估计量的领域特定语言，以及用于表示具有未观测混淆因子的因果图（如ADMG）的工具。此外，它还实现了近期因果推断文献中的多种识别算法。该包的源代码是开源的，可以在GitHub上找到。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为研究人员提供一个工具，在估计因果关系的强度之前，能够确定因果关系是否可以从可用数据中识别出来。

**Method:** 该研究使用Y0 Python包实现了因果识别算法，该包可以处理干预性、反事实和可运输性查询，并能够处理来自随机对照试验、观察性研究或两者的混合数据。它还提供了表示因果查询和估计量的特定领域语言，以及处理具有未观测混淆因子的因果图（如ADMG）的工具。

**Result:** Y0包实现了因果识别算法，能够将因果查询转化为符号估计量，并支持处理具有未观测混淆因子的因果图。

**Conclusion:** Y0包为因果识别提供了一个全面的解决方案，通过提供一个用于表示因果查询和估计量的特定领域语言，以及处理因果图的工具，帮助研究人员确定因果关系是否可以从可用数据中识别出来。

> **ai_Abstract:** Y0是一个Python包，用于因果识别，它实现了处理各种研究设计数据的算法。该包专注于定性因果分析，帮助研究人员确定因果关系的可识别性，并将因果查询转化为可估计的符号。

> **摘要翻译:** 我们提出了$Y_0$ Python包，它实现了因果识别算法，这些算法可以将干预性、反事实和可运输性查询应用于来自（随机）对照试验、观察性研究或两者的混合数据。$Y_0$专注于因果关系的定性研究，帮助研究人员在试图估计因果关系的强度之前，确定因果关系是否可以从可用数据中估计出来。此外，$Y_0$提供了如何将因果查询转化为可从可用数据中非参数估计的符号估计量的指导。$Y_0$提供了一种表示因果查询和估计量的领域特定语言，作为符号概率表达式，工具用于表示具有未观测混淆因子的因果图，例如有向混合图（ADMG），以及近期因果推断文献中的众多识别算法的实现。$Y_0$源代码可以在MIT许可证下找到，网址为https://github.com/y0-causal-inference/y0，并且可以使用pip install y0进行安装。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [622] [Mamba-X: An End-to-End Vision Mamba Accelerator for Edge Computing Devices](https://arxiv.org/abs/2508.02977)
> *Mamba-X：一种面向边缘计算设备的端到端视觉Mamba加速器*

*Dongho Yoon, Gungyu Lee, Jaewon Chang, Yunjae Lee, Dongjae Lee, Minsoo Rhu* | **Category: cs.AR** | **Updated: 2025-08-05**

**Keywords:** Vision Mamba, 边缘计算, 硬件加速, 状态空间模型, 量化

**Comment:** Accepted for publication at the 44th International Conference on
  Computer-Aided Design (ICCAD), 2025

> **TL;DR:** Mamba-X 是一种视觉Mamba加速器，通过专用硬件和量化技术，解决了在边缘设备上部署视觉Mamba的挑战，提高了效率。

**AI_Comments:** 本文的创新点在于针对Vision Mamba在边缘设备部署的挑战，设计了专用的硬件加速器Mamba-X。通过结合脉动扫描阵列和混合量化技术，有效地解决了顺序扫描操作的并行性瓶颈和内存效率问题，这对于在资源受限的边缘设备上推广高效的视觉SSM模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有Transformer模型计算和内存需求高，且随输入序列长度呈二次方增长。Vision Mamba虽然降低了复杂度，但其顺序扫描操作在边缘设备上部署时会阻碍GPU效率，使得在边缘设备上部署Vision Mamba面临挑战。

**Method:** 提出Mamba-X，一个端到端视觉Mamba加速器，包含：1) 脉动扫描阵列（systolic scan array），旨在最大化并行性并最小化内存流量；2) 混合、硬件友好量化技术（hybrid, hardware-friendly quantization technique），用于减少内存使用并提高硬件效率，同时不牺牲精度。

**Result:** 提高了硬件效率，减少了内存使用，且不牺牲精度。具体性能数据未在摘要中提及。

**Conclusion:** Mamba-X通过其创新的硬件加速和量化方法，成功克服了Vision Mamba在边缘设备部署中的挑战，实现了高效的视觉Mamba加速，使其适用于边缘计算设备。

> **ai_Abstract:** 本文提出了Mamba-X，一个专为边缘计算设备设计的端到端视觉Mamba加速器。针对现有Transformer模型的高资源消耗以及Vision Mamba在边缘设备上部署时遇到的顺序扫描操作效率问题，Mamba-X通过引入脉动扫描阵列来提升并行性并减少内存流量，并结合混合硬件友好量化技术来优化内存使用和硬件效率，从而在不牺牲精度的前提下，有效解决了在边缘设备上部署视觉Mamba的挑战。

> **摘要翻译:** Transformer在语言建模中被证明是有效的，但受限于高计算和内存需求，这些需求随输入序列长度呈二次方增长。状态空间模型（SSM）提供了一个有前景的替代方案，通过将注意力复杂度从$O(L^2)$降低到$O(L)$，同时降低了整体内存消耗。Vision Mamba将SSM方法应用于计算机视觉任务，实现了比传统Transformer模型更低的延迟和内存消耗。然而，由于其顺序扫描操作阻碍了GPU效率，在边缘设备上部署Vision Mamba具有挑战性。我们提出了Mamba-X，一种端到端视觉Mamba加速器，它包括一个脉动扫描阵列以最大化并行性并最小化内存流量，以及一种混合的、硬件友好的量化技术，以减少内存使用并提高硬件效率，同时不牺牲精度。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [636] [Towards Memory Specialization: A Case for Long-Term and Short-Term RAM](https://arxiv.org/abs/2508.02992)
> *存储专业化：长期和短期RAM的案例*

*Peijing Li, Muhammad Shahir Abdurraman, Rachel Cleaveland, Sergey Legtchenko, Philip Levis, Ioan Stefanovici, Thierry Tambe, David Tennenhouse, Caroline Trippel* | **Category: cs.AR, cs.ET** | **Updated: 2025-08-05**

**Keywords:** 内存专业化, 长期RAM, 短期RAM, 内存架构, 系统成本

**Comment:** 9 pages, 3 figures

> **TL;DR:** SRAM和DRAM成本扩展停滞，内存已主导系统成本。本文提出内存架构范式转变，引入长期RAM（LtRAM）和短期RAM（StRAM）两种新型内存，以适应应用特定访问模式，实现更高效可扩展的计算系统。

**AI_Comments:** 这篇论文提出了一个重要的观点，即在传统SRAM和DRAM扩展受限的背景下，内存系统需要走向专业化。其创新点在于提出了LtRAM和StRAM的概念，并强调了操作系统支持的重要性，这为未来内存系统设计提供了新的思路。论文指出了关键的研究挑战，表明这是一个前瞻性的研究方向，对提升计算系统效率和可扩展性具有潜在的重大影响。

<details>
  <summary>Details</summary>

**Motivation:** SRAM和DRAM的成本扩展已停止，导致内存成为系统成本的主要组成部分。当前的简单内存层次结构无法有效利用应用程序特定的访问模式，从而限制了系统性能和效率。

**Method:** 本文提出了一种内存架构的范式转变，即从简单的内存层次结构转向利用应用程序特定访问模式的专业化内存架构。具体地，论文提出了两种需要明确操作系统支持的新型内存类别：长期RAM（LtRAM），针对读密集型、长寿命数据进行优化；短期RAM（StRAM），专为瞬态、频繁访问、短寿命数据而设计。文章还探讨了实现这些内存类别的底层设备技术，它们的演进以及在当前系统设计中的潜在集成。

**Result:** Not mentioned in abstract

**Conclusion:** 本文认为，为了实现更高效、可扩展且能够满足未来需求的计算系统，有必要向更专业的内存系统演进，并指出了实现这一目标所面临的关键研究挑战。

> **ai_Abstract:** 由于SRAM和DRAM的成本扩展停滞，内存已成为系统成本的主要组成部分。本文提出了一种内存架构的范式转变，主张引入专门化的内存类型以利用应用特定的访问模式。具体而言，论文提出了两种需要操作系统支持的新内存类别：用于读密集型、长寿命数据的长期RAM（LtRAM）和用于瞬态、频繁访问、短寿命数据的短期RAM（StRAM）。文章还探讨了实现这些内存类别的底层技术及其集成，并强调了实现更高效、可扩展计算系统所面临的关键研究挑战。

> **摘要翻译:** SRAM和DRAM都已停止扩展：目前没有技术路线图来降低其成本（每字节/GB）。因此，内存现在主导着系统成本。本文主张从当前简单的内存层次结构转向利用应用程序特定访问模式的专业化内存架构。我们设想的内存系统不再仅仅依赖传统的片外DRAM和片上SRAM，而是配备了额外类型的内存，通过非层次化优化来使工作负载受益于其性能权衡。我们提出了两种需要明确操作系统支持的新内存类别：长期RAM（LtRAM），针对具有长生命周期的读密集型数据进行优化；以及短期RAM（StRAM），专为具有短生命周期的瞬态、频繁访问数据而设计。我们探讨了可以实现这些类别的底层设备技术，包括它们的演进以及在当前系统设计中集成它们的潜力，考虑到新兴的工作负载需求。我们指出了实现我们认为向更高效、可扩展且能够满足未来需求的计算系统演进的关键研究挑战。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [662] [GainSight: A Unified Framework for Data Lifetime Profiling and Heterogeneous Memory Composition](https://arxiv.org/abs/2504.14866)
> *GainSight：数据生命周期分析和异构内存组合的统一框架*

*Peijing Li, Matthew Hung, Yiming Tan, Konstantin Hoßfeld, Jake Cheng Jiajun, Shuhan Liu, Lixian Yan, Xinxin Wang, Philip Levis, H. -S. Philip Wong, Thierry Tambe* | **Category: cs.AR, cs.ET, B.7.1; B.3.1; C.3; I.6; I.2.6** | **Updated: 2025-08-05**

**Keywords:** AI加速器,异构内存,数据生命周期,短期RAM (StRAM),内存优化

**Comment:** 14 pages, 11 figures

> **TL;DR:** 由于AI工作负载对内存的需求不断增长，而SRAM扩展趋势无法提供足够的高密度片上内存，因此需要一种新的内存解决方案。本研究提出了GainSight框架，通过将动态、细粒度的内存生命周期配置文件与内存设备特性相结合，来生成优化的短期RAM（StRAM）内存组合，以应对这一挑战。GainSight结合了可重定向的分析后端和与架构无关的分析前端，能够捕获周期精确的数据生命周期，并将其与StRAM的保留特性相关联。实验结果表明，GainSight在MLPerf推理和PolyBench工作负载中，能够识别出大量适合StRAM的瞬态数据，并实现高达3倍的能耗和4倍的面积缩减。

**AI_Comments:** GainSight框架在应对AI工作负载内存挑战方面展现了巨大的潜力，通过引入异构内存和关注数据生命周期，实现了显著的性能和效率提升。然而，该框架的实际应用效果可能受到具体硬件实现、编译器支持以及不同AI模型特性等因素的影响。未来的研究可以进一步探索不同类型瞬态内存设备的集成、动态内存重配置策略以及GainSight在更广泛的AI应用场景中的性能表现。

<details>
  <summary>Details</summary>

**Motivation:** AI工作负载不断增长的内存需求与当前SRAM扩展趋势无法提供足够高密度片上内存之间存在矛盾。同时，AI工作负载中大量短暂的数据使得SRAM在数据保留能力方面存在过度配置。为了解决这种不匹配，需要一种从统一SRAM阵列向异构片上内存的转变，该内存包含具有有限保留时间、更密集的短期RAM（StRAM）设备，以匹配瞬态数据的生命周期。

**Method:** GainSight框架结合了可重定向的分析后端和与架构无关的分析前端。后端负责捕获周期精确的数据生命周期，而前端则将工作负载模式与StRAM的保留特性相关联，以生成优化的内存组合并预测性能。

**Result:** 在MLPerf推理和PolyBench工作负载上的应用表明，64.3%的一级GPU缓存访问和79.01%的 systolic 阵列暂存器访问表现出适合高密度StRAM的亚微秒级生命周期。优化的异构片上内存组合相较于统一SRAM层级，在活动能耗方面实现了高达3倍的降低，在面积方面实现了高达4倍的缩减。

**Conclusion:** GainSight框架通过将数据生命周期提升为下一代AI加速器设计的一等考量因素，实现了对数据瞬态性的系统性利用，从而提高了片上内存密度和效率。该框架为解决AI工作负载的内存挑战提供了一个全面的解决方案。

> **ai_Abstract:** GainSight是一个创新的、开源的框架，旨在解决AI工作负载日益增长的内存需求问题。它通过引入短期RAM（StRAM）设备来构建异构片上内存，以匹配AI数据瞬态的生命周期，从而克服了传统SRAM的局限性。GainSight能够分析工作负载数据生命周期，并将其与StRAM特性相结合，以优化内存组合，实现显著的能耗和面积缩减。该框架通过将数据生命周期作为关键设计考量，为下一代AI加速器的内存效率提升提供了有效途径。

> **摘要翻译:** 随着人工智能工作负载驱动日益增长的内存需求，特定领域的加速器需要比当前SRAM扩展趋势所能提供更高密度的片上内存。同时，这些工作负载中大量的短暂数据使得SRAM在保留能力方面存在过度配置。为了解决这种不匹配，我们提出了一种从统一SRAM阵列到异构片上内存的整体转变，其中包含更密集的短期RAM（StRAM）设备，其有限的保留时间与瞬态数据的生命周期相匹配。为了促进这种转变，我们引入了GainSight，这是第一个全面的、开源的框架，它将动态的、细粒度的工作负载生命周期配置文件与内存设备特性相结合，以实现最优的StRAM内存组合生成。GainSight结合了可重定向的分析后端和一个与架构无关的分析前端。各种后端捕获周期精确的数据生命周期，而前端将工作负载模式与StRAM保留特性相关联，以生成最优的内存组合并预测性能。GainSight将数据生命周期提升为下一代AI加速器设计的一等考量因素，从而能够系统性地利用数据瞬态性来提高片上内存密度和效率。将GainSight应用于MLPerf推理和PolyBench工作负载表明，64.3%的一级GPU缓存访问和79.01%的 systolic 阵列暂存器访问表现出适合高密度StRAM的亚微秒级生命周期，并且最优的异构片上内存组合相较于统一SRAM层级，在活动能耗和面积方面实现了高达3倍和4倍的降低。为了促进采用和进一步研究，GainSight已在https://gainsight.stanford.edu/开源。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [679] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
> *废物芯片的再利用：化危机为转机*

*Haniye Mehraban, Saad Azmeen-ur-Rahman, John Hu* | **Category: cs.AR** | **Updated: 2025-08-05**

**Keywords:** 假冒芯片, 电子学习, 实践诊断, 供应链安全, 工程教育

**Comment:** This is the accepted version of a paper accepted for presentation at
  the 2025 IEEE Frontiers in Education Conference (FIE). The final version will
  be available via IEEE Xplore at:https://ieeexplore.ieee.org/Xplore/home.jsp

> **TL;DR:** 假冒芯片在电子课程中被发现，但被用作实践学习的工具，学生通过诊断和分析深入了解了模拟电路、供应链安全和工程实践。

**AI_Comments:** 这项工作通过一个具体的案例，展示了如何将一个潜在的问题（假冒芯片）转化为宝贵的学习资源，强调了实践经验在工程教育中的重要性。这种将错误或意外情况转化为教学机会的方法值得肯定。

<details>
  <summary>Details</summary>

**Motivation:** 假冒集成电路在本科生电子实验室中日益普遍，威胁着实验的完整性，需要一种将此问题转化为学习机会的方法。

**Method:** 通过实践案例研究，学生们对假冒的TL074运算放大器进行了实际诊断，包括测量电流、分析波形和排除故障。

**Result:** 学生们在处理假冒芯片的过程中，对模拟电路、供应链安全和工程实践有了更深入的理解。

**Conclusion:** 将假冒芯片的发现转化为实践学习的经验，使学生在解决实际工程问题的同时，也获得了对模拟电路和供应链安全等方面的深刻认识。

> **ai_Abstract:** 本研究将电子课程中发现的假冒TL074运算放大器转化为一次实践学习经历。通过动手诊断和分析，学生们不仅深入理解了模拟电路，还了解了供应链安全和工程实践的挑战。

> **摘要翻译:** 这项正在进行中的工作论文展示了一个案例研究，其中在初级电子课程中发现的假冒TL074运算放大器成为了实践学习体验的基础。假冒集成电路（IC）日益普遍，对本科生电子实验室的完整性构成了重大威胁。我们没有简单地更换假冒组件，而是将这个问题变成了一个教学时刻。学生们参与了动手诊断，测量了电流，分析了波形，并进行了故障排除。通过处理假冒芯片组件，他们对模拟电路、供应链安全和实践工程有了更深入的了解。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [720] [Numerical Errors in Quantitative System Analysis With Decision Diagrams](https://arxiv.org/abs/2508.02673)
> *带决策图的定量系统分析中的数值误差*

*Sebastiaan Brand, Arend-Jan Quist, Richard M. K. van Dijk, Alfons Laarman* | **Category: cs.CE, cs.NA, math.NA, quant-ph** | **Updated: 2025-06-20**

**Keywords:** 决策图, 数值误差, 数值稳定性, 矩阵向量乘法, 量子系统

**Comment:** 

> **TL;DR:** 该论文研究了决策图（DDs）在定量系统分析中的数值误差问题，特别关注了矩阵向量乘法在概率和量子系统中的应用。研究表明，虽然MTBDD矩阵向量乘法算法在特定条件下可以实现数值稳定，但实际应用中这些条件往往难以满足。此外，论文还通过量子电路模拟的案例研究，展示了数值误差在实际应用中的不确定性。

**AI_Comments:** 该研究对于理解和改进基于决策图的系统分析具有重要意义，尤其是在处理概率和量子系统时。论文指出了实际应用中的挑战，并提供了理论分析和实例研究，为未来的研究和工程实践提供了有价值的参考。然而，文中提到的“特定条件”的具体细节和如何满足这些条件，可以进一步阐述。

<details>
  <summary>Details</summary>

**Motivation:** 决策图（DDs）在处理离散、概率和量子系统时面临状态空间爆炸问题，但其在概率和量子领域常使用浮点数，这会导致舍入误差，影响结果的正确性和DDs的压缩效率。因此，研究DDs中数值误差的稳定性至关重要。

**Method:** 本文研究了多终端二元决策图（MTBDDs）在矩阵向量乘法中的数值稳定性。通过理论证明，确定了MTBDD矩阵向量乘法算法在何种条件下可以实现数值稳定，并指出了实际实现中这些条件常常无法满足。此外，还通过量子电路模拟的案例研究，分析了实际应用中的数值误差。

**Result:** 研究证明，在特定条件下，MTBDD矩阵向量乘法算法可以实现数值稳定。然而，在许多实际的MTBDD实现中，这些条件并未得到满足。量子电路模拟的案例研究表明，实际应用中的数值误差程度因实例而异，差异很大。

**Conclusion:** 虽然MTBDD矩阵向量乘法算法在理论上可以在特定条件下实现数值稳定，但实际应用中的限制和不确定性表明，需要进一步关注和解决数值误差问题，以确保定量系统分析的准确性和可靠性。

> **ai_Abstract:** 本文探讨了在利用决策图（DDs）进行定量系统分析时出现的数值误差问题，尤其关注了其在概率和量子系统中的应用。研究集中于多终端二元决策图（MTBDDs）的矩阵向量乘法，这是计算概率和量子系统后继状态的关键操作。研究结果表明，尽管该算法在特定条件下可以实现数值稳定，但实际应用中的常见情况往往不满足这些条件。通过对量子电路模拟的案例分析，进一步证实了数值误差在实际场景中的可变性。

> **摘要翻译:** 决策图（DDs）是一种强大的数据结构，不仅用于离散系统，也用于概率和量子系统，以解决状态空间爆炸问题。虽然许多在概率和量子领域使用的DDs利用了浮点数，但这并非没有挑战。浮点数计算会受到小的舍入误差的影响，这可能同时影响结果的正确性以及DDs压缩的有效性。在本文中，我们研究了具有多终端二元决策图（MTBDDs）的矩阵向量乘法的数值稳定性，即算法对小的数值误差的鲁棒性。矩阵向量乘法特别受关注，因为它是计算概率和量子系统的后继状态的函数。我们证明了，在特定条件下，MTBDD矩阵向量乘法算法可以实现数值稳定，尽管在许多MTBDDs的实际实现中，这些条件并未得到满足。此外，我们还提供了一个关于量子电路模拟中数值误差的案例研究，该研究表明实际中数值误差的程度在不同实例之间存在很大差异。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [734] [Overcoming the Loss Conditioning Bottleneck in Optimization-Based PDE Solvers: A Novel Well-Conditioned Loss Function](https://arxiv.org/abs/2508.02692)
> *克服基于优化的PDE求解器中的损失条件瓶颈：一种新颖的良态损失函数*

*Wenbo Cao, Weiwei Zhang* | **Category: cs.CE, cs.LG, physics.comp-ph, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 稳定梯度残差, 损失函数, PDE求解器, 条件数, 优化

**Comment:** 

> **TL;DR:** 该研究提出了一种新的稳定梯度残差（SGR）损失函数，以解决基于优化的偏微分方程（PDE）求解器中常用的均方误差（MSE）损失函数收敛速度慢的问题。SGR损失函数通过调整权重参数来调节条件数，并在ODIL和PINNs框架下均表现出比MSE损失函数更快的收敛速度和更好的稳定性。

**AI_Comments:** 这项研究在解决优化型PDE求解器的效率瓶颈方面取得了重要进展。通过提出SGR损失函数，作者不仅提供了理论依据，还通过广泛的实验验证了其优越性。SGR损失函数能够灵活调节条件数，使其在不同场景下都能获得良好的性能。然而，该研究的局限性可能在于对SGR损失函数参数敏感性的进一步分析，以及在更复杂的PDE问题上的扩展性测试。

<details>
  <summary>Details</summary>

**Motivation:** 基于优化的PDE求解器（如ODIL和PINNs）虽然有前景，但通常比经典迭代求解器收敛慢，效率低下。这种低效率被归因于使用均方误差（MSE）损失函数，该函数会形成法方程，平方条件数，严重影响优化。

**Method:** 提出了一种新的稳定梯度残差（SGR）损失函数。通过调整权重参数，SGR损失函数可以灵活地调节原始系统与其法方程之间的条件数，并在极限情况下退化为MSE损失函数。在ODIL和PINNs框架下对SGR损失函数的收敛行为和优化稳定性进行了基准测试，并与经典迭代求解器进行了比较。

**Result:** 在ODIL框架下，SGR损失函数实现了比MSE损失函数快几个数量级的收敛速度。在PINNs框架下，尽管神经网络具有高度非线性，SGR损失函数也持续优于MSE损失函数。

**Conclusion:** 提出的SGR损失函数能够有效克服基于优化的PDE求解器中的损失条件瓶颈，提高收敛速度和优化稳定性，有助于缩小经典迭代求解器和基于优化求解器之间的性能差距。

> **ai_Abstract:** 这项工作提出了一种新颖的稳定梯度残差（SGR）损失函数，旨在解决当前基于优化的偏微分方程（PDE）求解器中普遍存在的效率低下问题，该问题源于常用的均方误差（MSE）损失函数导致的条件数过大。通过理论分析，研究人员将MSE损失函数与法方程的形成及其条件数的平方联系起来，从而解释了优化过程的缓慢。SGR损失函数通过引入一个可调的权重参数，能够灵活地管理条件数，从而在ODIL和PINNs等框架下显著提高收敛速度和优化稳定性。实验结果表明，SGR损失函数在ODIL和PINNs方法中均优于MSE损失函数，甚至在某些情况下收敛速度快了几个数量级，为开发更高效的PDE求解器提供了重要方向。

> **摘要翻译:** 近年来，最小化标量损失函数的基于优化的PDE求解器受到了越来越多的关注。这些方法要么直接在离散变量上定义损失，如在“优化离散损失”（ODIL）中，要么通过神经网络代理间接定义损失，如在物理信息神经网络（PINNs）中。然而，尽管有前景，这类方法通常比经典的迭代求解器收敛慢得多，并且通常被认为效率低下。这项工作提供了一个理论见解，将效率低下归因于使用了均方误差（MSE）损失函数，该函数隐式地形成法方程，平方了条件数，并严重损害了优化。为了解决这个问题，我们提出了一种新颖的稳定梯度残差（SGR）损失函数。通过调整权重参数，它可以灵活地调节原始系统与其法方程之间的条件数，并在极限情况下退化为MSE损失函数。我们在ODIL框架和PINNs（使用数值或自动微分）中系统地对SGR损失函数的收敛行为和优化稳定性进行了基准测试，并将其性能与经典迭代求解器进行了比较。在一系列基准问题上的数值实验表明，在ODIL框架内，所提出的SGR损失函数比MSE损失函数实现了数量级上更快的收敛速度。在PINNs框架内的进一步验证表明，尽管神经网络具有高度非线性，SGR仍然持续优于MSE损失函数。这些理论和经验发现有助于缩小经典迭代求解器和基于优化求解器之间的性能差距，突出了损失条件的关键作用，并为设计更有效的PDE求解器提供了关键见解。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [747] [Using numerical-experimental analysis to evaluate rPET mechanical behavior under compressive stresses and FFF additive manufacturing for new sustainable designs](https://arxiv.org/abs/2508.02728)
> *使用数值-实验分析评估rPET在压缩应力下的力学行为以及用于新可持续设计的FFF增材制造*

*J. Mercado Colmenero, M. LaRubia, E. Mata Garcia, M. Rodriguez Santiago, C. Martin Donate* | **Category: cs.CE** | **Updated: 2025-08-01**

**Keywords:** rPET, 增材制造, 压缩应力, 数值模拟, 可持续设计

**Comment:** 

> **TL;DR:** 该研究通过数值-实验分析，在压缩应力下评估了可回收PET（rPET）的力学行为，并将其应用于使用FFF技术制造的新可持续设计中。研究制造并测试了42个rPET样品，并进行了8次数值分析和8次实验测试，以验证其在真实设计上的力学性能。结果表明，rPET在达到弹性极限前表现出线性行为，且实验与数值结果的差异很小，可将rPET在数值模拟中视为各向同性材料。该研究为rPET在可持续产品设计中的应用提供了实验和数值依据。

**AI_Comments:** 该研究在将回收材料应用于增材制造和可持续设计方面具有重要意义。通过结合实验和数值分析，为rPET在压缩载荷下的力学行为提供了可靠的评估。研究结果表明rPET在模拟中的各向同性特性简化了其在设计流程中的应用。然而，未来可以进一步探索不同压缩应变率、温度以及长期使用条件对rPET力学行为的影响，以更全面地评估其在实际应用中的性能。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在研究可回收PET（rPET）在压缩应力下的数值-实验力学行为建模，并探索其在采用FFF（熔融沉积成型）工艺制造的新可持续设计中的应用，以满足工业界对回收塑料材料日益增长的需求。

**Method:** 该研究结合了数值和实验方法。首先，根据ASTM D695-15标准制造了42个rPET测试样品并进行了实验测试，以获取其杨氏压缩模量。然后，利用实验获得的模量，对使用rPET制造的真实设计进行了8次数值分析。最后，对真实设计进行了8次额外的单轴压缩载荷实验测试，以验证其力学行为与数值模拟结果的一致性。

**Result:** 实验测试表明，rPET在达到弹性极限前，沿各个制造轴向表现出线性行为。研究结果证实了该设计在给定的载荷情景和操作边界条件下的结构安全性。实验和数值结果之间的差异在0.001-0.024毫米之间，这使得rPET可以在数值模拟软件中被配置为各向同性材料，而无需修改其材料建模方程。

**Conclusion:** 该研究通过实验和数值结果的对比验证，确认了rPET在MEX（熔融挤出）技术下，承受压缩应力时，可用于生态化生产真实可持续产品，并且其材料特性可以被有效地配置到数值模拟软件中，为行业、设计师和研究人员提供了宝贵的参考。

> **ai_Abstract:** 本研究通过结合实验测试和数值模拟，评估了使用熔融沉积成型（FFF）技术制造的可回收PET（rPET）在压缩载荷下的力学行为。研究人员制造了42个rPET样品并进行了测试，以确定其杨氏模量，随后将其应用于真实设计的数值模拟中，并通过额外的实验对模拟结果进行了验证。研究发现rPET在达到弹性极限前表现出线性行为，且实验与模拟结果非常接近，允许rPET在模拟中被视为各向同性材料。这项工作为在可持续设计中使用回收rPET提供了重要的实验和模拟依据。

> **摘要翻译:** 本研究旨在研究可回收聚合物——可回收聚对苯二甲酸乙二醇酯（rPET）——在熔融沉积成型（FFF）工艺下，承受压缩应力时的数值-实验力学行为建模，并将其应用于新的可持续设计中。总共制造并分析了42个测试样品，遵循ASTM D695-15标准。利用实验测试得到的杨氏压缩模量，对使用rPET制造的真实设计进行了八次数值分析。最后，对真实的、可持续的设计进行了八次额外的单轴压缩载荷实验测试，以验证其力学行为与计算数值测试的对比。作为实验测试的结果，rPET在达到弹性极限之前，沿每个制造轴向表现出线性行为。本研究结果通过载荷情景和操作边界条件确认了设计的结构安全性。实验和数值结果显示出0.001-0.024毫米的差异，使得rPET可以在数值模拟软件中被配置为各向同性材料，而无需修改其材料建模方程。所获得的结果通过验证测试样品和真实物品上的实验材料配置值与数值结果的对比，对行业、设计师和研究人员非常有帮助，它们验证了回收rPET在MEX技术下承受压缩应力以及为数值模拟配置其材料特性，用于生态化生产真实可持续产品的可行性。目前，主要的设计公司正在其高端设计中使用回收的塑料材料。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [761] [A fluid--peridynamic structure model of deformation and damage of microchannels](https://arxiv.org/abs/2508.02875)
> *微通道变形与损伤的流体-近场动力学结构模型*

*Ziyu Wang, Ivan C. Christov* | **Category: cs.CE, physics.flu-dyn** | **Updated: 2025-08-04**

**Keywords:** 流体-近场动力学,微通道,变形,损伤,失效模式

**Comment:** 15 pages, 10 figures

> **TL;DR:** 该研究提出了一种模拟微通道变形和损伤的流体-近场动力学模型，并分析了不同工况下的失效模式。

**AI_Comments:** 该研究将近场动力学理论应用于微通道的流固耦合问题，有效地模拟了变形和损伤，并识别了不同失效模式，为相关领域提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究缺乏对微通道设备潜在失效问题的关注。

**Method:** 通过耦合粘性流（润滑近似）和基于状态的近场动力学欧拉-伯努利梁公式，开发了一维模型。

**Result:** 该模型能够模拟连续和不连续的变形，并揭示了非局部影响对波传播的影响，以及在不同无量纲参数下（斯特劳哈尔数和柔顺数）的潜在失效模式。

**Conclusion:** 该研究提出了一个流体-近场动力学模型，用于分析微通道的变形和损伤，并识别了导致失效的不同工况。

> **ai_Abstract:** 该研究提出了一个流体-近场动力学模型，用于分析微通道变形和损伤。该模型耦合了粘性流和近场动力学欧拉-伯努利梁公式，能够模拟连续和不连续的变形，并分析了非局部影响对波传播的影响。研究结果揭示了在不同工况下微通道软壁的潜在失效模式。

> **摘要翻译:** 软壁微通道在从芯片器官平台到软机器人致动器等多种应用中出现。然而，尽管对其静态和动态响应进行了广泛研究，但尚未解决这些设备的潜在失效问题。为此，我们探讨了微通道中的流固耦合，其柔顺顶壁受一种能够模拟变形和材料失效的非局部力学理论控制。我们通过将润滑近似下的粘性流与欧拉-伯努利梁的基于状态的近场动力学公式相结合，开发了一个一维模型。近场动力学公式使得该壁能够被建模为真正的非局部梁，并且无论变形场是光滑还是包含不连续性，其运动方程的积分形式都成立。通过提出的计算模型，我们探讨了这种流体-近场动力学结构相互作用的稳态和时变行为。我们通过耦合系统的色散（线性化）分析来解释模拟中观察到的波和阻尼动力学，发现随着非局部影响的增加，波传播与经典行为明显不同，其特点是相速度逐渐受到抑制。我们研究的主要贡献是概述了在流体动力载荷下微通道软壁的潜在失效情景。具体来说，我们在由无量纲斯特劳哈尔数（量化梁的非定常惯性）和柔顺数（量化流固耦合的强度）构成的空间中发现了一条分离曲线，该曲线将瞬态条件下的潜在失效情景与稳态载荷下的潜在失效情景分离开来。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [774] [A Closed-Loop Multi-Agent Framework for Aerodynamics-Aware Automotive Styling Design](https://arxiv.org/abs/2508.03370)
> *面向空气动力学感知的汽车造型设计的闭环多智能体框架*

*Xinyu Jin, Shengmao Yan, Qingtao Wang, Shisong Deng, Yanzhen Jiang, Shuangyao Zhao* | **Category: cs.CE, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 汽车设计,空气动力学,多智能体框架,大语言模型,概念生成

**Comment:** 

> **TL;DR:** 提出了一种由大语言模型驱动的多智能体框架，用于自动化汽车外观设计的从模糊需求到3D模型性能验证的端到端工作流程。该框架分为概念生成和性能验证两个阶段，利用多智能体协作生成设计概念，并使用轻量级代理模型进行快速的气动性能预测，以取代耗时的CFD模拟。

**AI_Comments:** 该研究提出了一种将大语言模型和多智能体系统应用于汽车设计的方法，特别是在空气动力学性能评估方面。通过使用轻量级代理模型替代传统的CFD模拟，显著提高了设计迭代的效率。然而，代理模型的准确性和泛化能力，以及多智能体协作的鲁棒性，是未来研究需要关注的关键点。该方法为自动化和优化设计流程提供了一个有前景的途径。

<details>
  <summary>Details</summary>

**Motivation:** 当前的汽车外观设计面临主观美学、客观空气动力学性能和加速开发周期的挑战。

**Method:** 提出了一种由大语言模型驱动的多智能体框架，分为概念生成和性能验证两个阶段。概念生成阶段涉及智能体解释设计需求、生成概念草图和渲染图。性能验证阶段将渲染图转换为3D点云，并使用基于轻量级代理模型的Drag Prediction Agent进行快速的气动性能（阻力系数和压力场）预测。

**Result:** 实现了一个集成了创意生成与快速工程验证的统一自动化系统，能够高效地平衡创意探索与工程约束。

**Conclusion:** 该框架为在设计早期阶段平衡创意探索与工程约束提供了一种新范式。

> **ai_Abstract:** 本研究提出了一种创新的、由大语言模型驱动的多智能体框架，旨在自动化汽车外观设计的整个流程，从初步的模糊需求到最终的3D模型性能验证。该框架通过两个阶段实现目标：首先，多个智能体协同工作，理解设计意图，生成概念草图，并利用扩散模型创建高质量的渲染图；其次，将这些渲染图转换为3D点云，并利用一个集成了轻量级代理模型的“阻力预测智能体”来快速评估空气动力学性能，如阻力系数和压力场，从而避免了传统的耗时计算流体动力学（CFD）模拟。该框架的核心优势在于将创意设计过程与工程验证紧密结合，提供了一种高效的解决方案，以应对在汽车设计初期平衡美学追求与工程约束的挑战。

> **摘要翻译:** 汽车外观设计的核心挑战是在显著加速开发周期的同时，平衡主观美学与客观空气动力学性能。为了解决这个问题，我们提出了一种新颖的、由大语言模型驱动的多智能体框架，该框架自动化了从模糊需求到3D概念模型性能验证的端到端工作流程。该工作流程分为两个阶段：概念生成和性能验证。在第一阶段，智能体协作解释模糊的设计需求，生成概念草图，并使用扩散模型生成照片级逼真渲染图。在第二阶段，渲染图被转换为3D点云，其中基于轻量级代理模型的Drag Prediction Agent能够提供近乎瞬时的阻力系数和压力场预测，取代了耗时的CFD模拟。这项工作的主要贡献是将创意生成与快速工程验证无缝集成到一个统一的自动化系统中，为在设计早期阶段高效平衡创意探索与工程约束提供了一种新范式。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [789] [Learning to Incentivize: LLM-Empowered Contract for AIGC Offloading in Teleoperation](https://arxiv.org/abs/2508.03464)
> *学习激励：LLM赋能的合同用于远程操作中的AIGC卸载*

*Zijun Zhan, Yaxian Dong, Daniel Mawunyo Doe, Yuqing Hu, Shuai Li, Shaohua Cao, Zhu Han* | **Category: cs.CE** | **Updated: 2025-08-05**

**Keywords:** 合同设计, AIGC卸载, 远程操作, LLM, 激励机制

**Comment:** 

> **TL;DR:** 该研究提出了一种基于LLM的合同设计方法，用于解决远程操作中AI生成内容（AIGC）卸载的激励问题，以应对信息不对称的挑战。

**AI_Comments:** 该研究将LLM应用于合同设计问题，解决信息不对称下的激励机制设计，具有创新性。然而，LLM的引入可能增加计算复杂度和潜在的不可解释性，这可能是未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 设计激励机制以激励边缘AI生成内容服务提供商（ASPs）提供高质量服务，尤其是在信息不对称的情况下，是一个挑战。

**Method:** 该研究将问题表述为在线学习合同设计问题，并将其分解为ASPs设置推断和合同推导两个子问题。其中，设置推断问题利用LLM来优化一个初始求解器，合同推导则使用凸优化技术。

**Result:** 通过在Unity仿真平台上的实验，该方法将远程操作员的效用提高了5%至40%，同时保持了ASPs的积极激励。

**Conclusion:** 所提出的LLM赋能的合同设计方法能够有效地解决远程操作中AIGC卸载的激励问题，提高效率并激励服务提供商。

> **ai_Abstract:** 本研究提出了一种新颖的合同设计框架，利用大型语言模型（LLM）来解决远程操作场景下AI生成内容（AIGC）卸载中的激励问题。该方法通过推断服务提供商（ASPs）的私有设置并结合凸优化技术来推导最优合同，以应对信息不对称的挑战。实验结果表明，该框架显著提高了远程操作员的效用，并激励了ASPs。

> **摘要翻译:** 随着AI生成内容（AIGC）需求的快速增长，边缘AIGC服务提供商（ASPs）变得不可或缺。然而，设计激励机制来激励ASPs提供高质量的AIGC服务仍然是一个挑战，尤其是在存在信息不对称的情况下。在本文中，我们解决了远程操作员和边缘ASPs之间的奖金设计问题，其中远程操作员无法观察到ASPs的私有设置和选择的操作（扩散步骤）。我们将此表述为在线学习合同设计问题，并将其分解为两个子问题：ASPs的设置推断和合同推导。为了解决具有未知变量大小的NP难问题设置推断子问题，我们引入了一个由LLM赋能的框架，该框架利用LLM的领域专业知识迭代地优化了一个朴素的种子求解器。在获得LLM演化求解器的解决方案后，我们直接使用凸优化技术解决合同推导问题，并获得近优合同。我们在基于Unity的远程操作平台上的仿真结果表明，与基准相比，我们的方法将远程操作员的效用提高了5%至40%，同时为ASPs保留了积极的激励。代码可在https://github.com/Zijun0819/llm4contract获取。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [3] [Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations](https://arxiv.org/abs/2508.03550)
> *越过表面：通过内部表示增强LLM作为评判者与人类的对齐*

*Peng Lai, Jianjie Zheng, Sijie Cheng, Yun Chen, Peng Li, Yang Liu, Guanhua Chen* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** LLM作为评判者, 内部表示, 对齐, 自动化评估, LAGER

**Comment:** 

> **TL;DR:** 提出LAGER框架，通过利用LLM内部表示而非仅最终层，显著提升LLM作为评判者与人类判断的对齐度，无需复杂提示或微调，并在基准测试中表现优异。

**AI_Comments:** LAGER的创新点在于它超越了仅依赖LLM最终层输出的传统方法，转而利用了LLM内部中高层更丰富的语义和任务相关表示，这提供了一种无需微调或复杂提示即可提升LLM-as-a-judge性能的有效途径。其轻量化和高效性也使其具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** LLM作为评判者在自动化评估中广泛应用，但如何在不使用复杂提示或微调的情况下提高其与人类偏好的一致性仍然是一个挑战。

**Method:** 本文提出Lager框架，一个轻量且高效的框架，旨在通过利用LLM的内部表示（尤其是中高层编码的语义和任务相关表示）来增强LLM作为评判者与人类评分的对齐。Lager通过聚合跨层分数-token logits并从基于softmax的分布中计算预期分数来生成细粒度判断分数，同时保持LLM骨干网络冻结，充分利用了不同层之间的互补信息。

**Result:** 在Flask、HelpSteer和BIGGen等标准对齐基准上，Lager的评估结果显示，其表现比最佳基线提高了高达7.5%。在没有推理步骤的情况下，Lager与基于推理的方法持平或超越。在数据选择和情感理解等下游应用上的实验进一步证明了该方法的有效性。

**Conclusion:** LAGER框架通过利用LLM的内部表示，在不进行复杂提示或微调的情况下，显著提高了LLM作为评判者与人类判断的对齐度，并在多个基准和下游任务中表现出色，克服了仅依赖最终层的局限性。

> **ai_Abstract:** 本文针对LLM作为评判者在自动化评估中与人类偏好对齐的挑战，提出了一种名为LAGER的轻量高效框架。该框架的核心思想是利用LLM中高层编码的、更符合人类判断的内部表示，而非仅仅依赖最终层。LAGER通过聚合跨层分数-token logits并计算预期分数来生成细粒度判断，且无需对LLM骨干网络进行微调。实验结果表明，LAGER在多个标准对齐基准上比现有最佳基线有显著提升（最高达7.5%），并且在不依赖推理步骤的情况下也能匹配或超越基于推理的方法，同时在数据选择和情感理解等下游应用中也展现出有效性。

> **摘要翻译:** 评估任务规模的不断扩大导致了使用大型语言模型进行自动化评估的广泛采用，这种范式被称为“LLM作为评判者”。然而，在不使用复杂提示或微调的情况下提高其与人类偏好的一致性仍然具有挑战性。在这项工作中，受到初步发现的启发，即中高层编码的语义和任务相关表示通常比最终层更符合人类判断，我们提出了LAGER，一个轻量高效的框架，通过内部表示增强LLM作为评判者与人类评分的对齐。LAGER通过聚合跨层分数-token logits并从基于softmax的分布中计算预期分数来生成细粒度判断分数，同时保持LLM骨干网络冻结。LAGER充分利用了不同层之间的互补信息，克服了仅依赖最终层的局限性。我们使用Spearman相关系数在标准对齐基准Flask、HelpSteer和BIGGen上评估了我们的方法，发现LAGER在这些基准上比最佳基线提高了高达7.5%。在没有推理步骤的情况下，LAGER与基于推理的方法持平或超越。在数据选择和情感理解等下游应用上的实验进一步证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [15] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
> *具有迭代自评估的连贯多模态推理用于视觉-语言模型*

*Wenjie Luo, Ruocheng Li, Shanshan Zhu, Julian Perry* | **Category: cs.CL** | **Updated: 2025-08-04**

**Keywords:** 多模态推理, 视觉-语言模型, 自评估, 常识推理, 迭代细化

**Comment:** 

> **TL;DR:** 本文提出了连贯多模态推理框架（CMRF），通过迭代自评估机制增强视觉-语言模型在复杂多模态常识推理中的能力，并在多个基准测试中达到SOTA性能。

**AI_Comments:** CMRF的创新之处在于其模仿人类思维的迭代自评估机制，特别是引入了分解、上下文推理和一致性评估模块，以及自适应迭代细化策略，这使得模型能够进行更深层次的链式推理和自我纠正。这种方法对于提高视觉-语言模型在复杂、多模态常识推理任务中的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型和视觉-语言模型在复杂、多步、跨模态常识推理任务中表现不佳，缺乏“深思熟虑”，倾向于依赖肤浅关联而非深度链式推理，尤其在整合视觉信息与抽象概念时。

**Method:** 本文提出了连贯多模态推理框架（CMRF），通过迭代、自评估推理机制增强LVLMs的常识推理能力。CMRF模仿人类问题解决过程，分解复杂查询，生成分步推理，并自我纠正错误。框架包含推理分解单元（RDU）、上下文推理引擎（CIE）和连贯性评估模块（CAM），并结合自适应迭代细化策略来系统地完善推理路径。

**Result:** CMRF基于LLaVA-1.6-34B构建，并在新的多模态日常活动推理（MDAR）数据集上训练。在VCR、A-OKVQA和DailyLife-MRC等挑战性基准测试中，CMRF在开源LVLMs中实现了最先进的性能，平均准确率达到69.4%，超过最佳开源基线2.4个百分点，在复杂推理场景中表现尤为突出。消融研究和人工评估证实了各模块贡献和迭代细化的有效性。

**Conclusion:** CMRF通过其迭代自评估推理机制，显著提升了视觉-语言模型在复杂多模态常识推理任务中的连贯性和准确性，证明了分解、上下文推理和连贯性评估模块以及迭代细化策略的有效性。

> **ai_Abstract:** 本文提出了连贯多模态推理框架（CMRF），旨在解决现有视觉-语言模型在复杂多步跨模态常识推理中缺乏“深思熟虑”的问题。CMRF通过模仿人类问题解决过程，利用推理分解、上下文推理和连贯性评估模块，结合迭代自评估机制，系统地细化推理路径。在LLaVA-1.6-34B基础上，并在MDAR数据集上训练，CMRF在多个挑战性基准测试中取得了SOTA性能，证明了其在提升LVLMs复杂推理能力方面的有效性。

> **摘要翻译:** 尽管取得了显著进展，当前的大型语言模型（LLMs）和视觉-语言模型（LVLMs）在复杂的、多步骤的、跨模态的常识推理任务中仍然面临挑战，常常表现出缺乏“深思熟虑”。它们倾向于依赖肤浅的关联，而不是深层的链式推理，尤其是在将视觉信息与抽象概念相结合时。为了解决这个问题，我们提出了连贯多模态推理框架（CMRF），这是一种通过迭代、自评估推理机制增强LVLMs常识推理能力的新方法。CMRF通过分解复杂查询、生成分步推理和自我纠正错误来模仿人类解决问题。我们的框架集成了三个关键模块：用于将问题分解为子问题的推理分解单元（RDU）、用于上下文推理的上下文推理引擎（CIE）以及用于评估逻辑一致性和置信度的连贯性评估模块（CAM）。结合自适应迭代细化策略，CMRF系统地完善其推理路径。CMRF基于LLaVA-1.6-34B构建，并在新的多模态日常活动推理（MDAR）数据集上进行训练，在VCR、A-OKVQA和DailyLife-MRC等挑战性基准测试中，在开源LVLMs中实现了最先进的性能。它达到了69.4%的平均准确率，超过了最佳开源基线2.4个百分点，在复杂推理场景中表现尤为突出。广泛的消融研究和人工评估证实了每个模块的关键贡献以及迭代细化在促进更连贯和准确推理方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [18] [Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs](https://arxiv.org/abs/2508.03247)
> *东方躯体化，西方心理化？：探究LLMs中基于临床的跨文化抑郁症状表达*

*Shintaro Sakai, Jisun An, Migyeong Kang, Haewoon Kwak* | **Category: cs.CL, cs.CY** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 抑郁症, 跨文化, 心理健康, 症状表达

**Comment:** 

> **TL;DR:** LLM在模拟跨文化抑郁症状表达方面表现不佳，未能有效复制西方心理症状和东方躯体症状的模式，即使提供了文化人设。虽然东方语言提示有所改善，但LLM仍缺乏心理健康应用所需的文化意识能力。

**AI_Comments:** 这项研究具有重要的创新性，因为它首次系统地探讨了LLMs在模拟跨文化心理健康模式方面的局限性。其发现揭示了当前通用LLMs在文化敏感性方面的不足，这对于其在心理健康领域的安全应用至关重要。研究指出的“文化不变症状层级”是一个有趣的发现，可能对未来LLM的偏见研究和文化适应性设计提供新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 先前的临床心理学研究表明，西方抑郁症患者倾向于报告心理症状，而东方患者则报告躯体症状。本研究旨在测试大型语言模型（LLMs）是否能重现这些文化模式，因为LLMs在心理健康领域的应用日益增多。

**Method:** 研究通过向LLMs提供西方或东方人设进行提示，以测试它们是否能复制跨文化抑郁症状表达模式。测试语言包括英语以及主要的东方语言（中文、日文和印地语）。研究还分析了模型失败的原因。

**Result:** LLMs在英语提示下未能有效复制这些文化模式。尽管在主要东方语言（中文、日文、印地语）提示下，对齐度有所改善，但整体效果不佳。分析发现，失败的主要原因是模型对文化人设的敏感度低以及存在一个强大的、文化不变的症状层级，该层级覆盖了文化线索。

**Conclusion:** 尽管提示语言很重要，但当前的通用LLMs缺乏安全有效心理健康应用所必需的强大、具有文化意识的能力。

> **ai_Abstract:** 该研究调查了大型语言模型（LLMs）是否能复制临床心理学中观察到的跨文化抑郁症状表达模式，即西方人报告心理症状，东方人报告躯体症状。研究通过向LLMs提供西方或东方人设进行测试。结果显示，LLMs在英语提示下未能有效复制这些模式，尽管在特定东方语言提示下有所改善。分析指出，LLMs对文化人设敏感度低以及存在一个覆盖文化线索的文化不变症状层级是主要原因。研究强调，当前LLMs缺乏心理健康应用所需的强大文化意识能力。

> **摘要翻译:** 先前的临床心理学研究表明，西方抑郁症患者倾向于报告心理症状，而东方患者则报告躯体症状。我们测试了在心理健康领域越来越多使用的LLM是否能通过提供西方或东方人设来重现这些文化模式。结果显示，当用英语提示时，LLM在很大程度上未能复制这些模式，尽管用主要的东方语言（即中文、日文和印地语）提示在几种配置中改善了对齐。我们的分析指出了导致这种失败的两个关键原因：模型对文化人设的低敏感性以及一个强大的、文化不变的症状层级，它覆盖了文化线索。这些发现表明，虽然提示语言很重要，但当前的通用LLM缺乏安全有效的心理健康应用所必需的强大、具有文化意识的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [21] [Memorization in Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.21009)
> *微调大型语言模型中的记忆化*

*Danil Savine* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 记忆化, 大型语言模型, 微调, 隐私, LoRA

**Comment:** 

> **TL;DR:** 本研究探讨了微调大型语言模型（LLMs）中的记忆化机制及其影响因素，尤其关注医疗领域的隐私敏感性。研究发现，某些权重矩阵、较低的困惑度和较高的LoRA秩会显著增加记忆化，为模型性能与隐私风险之间的权衡提供了见解。

**AI_Comments:** 本论文为微调LLMs中记忆化这一尚未充分探索的领域提供了宝贵的实证见解，尤其对医疗等敏感领域具有重要意义。其对特定Transformer组件（权重矩阵）和微调参数（LoRA秩、困惑度）的详细分析，为实践者提供了可操作的知识。其创新之处在于量化了这些关系，这对于在实际LLM部署中平衡实用性和隐私至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查微调大型语言模型（LLMs）中记忆化的机制和影响因素，特别是由于医疗领域对隐私敏感的特性，以理解微调过程的不同方面如何影响模型记忆训练数据的倾向。

**Method:** 研究采用两种主要方法：成员推断攻击来检测记忆数据，以及使用提示前缀的生成任务来评估逐字复现。研究分析了Transformer架构中不同权重矩阵（Query、Key、Value、Output）的适应性、困惑度与记忆化之间的关系，以及低秩适应（LoRA）微调中增加秩的影响，并使用了药理警戒事件的PHEE数据集。

**Result:** 主要发现包括：(1) 值（Value）和输出（Output）矩阵对记忆化的贡献比查询（Query）和键（Key）矩阵更显著；(2) 微调模型中较低的困惑度与记忆化增加相关；(3) 较高的LoRA秩会导致记忆化增加，但在较高秩时回报递减。

**Conclusion:** 这些结果为微调大型语言模型（LLMs）中模型性能和隐私风险之间的权衡提供了见解。本研究的发现对于在管理数据隐私问题的同时，开发更有效和负责任的适应大型语言模型的策略具有重要意义。

> **ai_Abstract:** 本论文主要探究了微调大型语言模型（LLMs）中的记忆化现象及其影响因素，尤其关注隐私敏感的医疗领域。研究通过成员推断攻击和生成任务，并利用PHEE数据集，分析了Transformer架构中不同权重矩阵、困惑度以及LoRA秩等微调方面如何影响数据记忆。核心发现表明，值和输出矩阵、较低的困惑度以及较高的LoRA秩均会显著增加模型的记忆化程度，从而揭示了模型性能与数据隐私风险之间的关键权衡。本研究为开发负责任的LLM适应策略提供了重要见解。

> **摘要翻译:** 本研究调查了微调大型语言模型（LLMs）中记忆化的机制和影响因素，重点关注医疗领域，因为其对隐私敏感的性质。我们使用药理警戒事件的PHEE数据集，研究了微调过程的不同方面如何影响模型记忆训练数据的倾向。
我们的研究采用了两种主要方法：一种是成员推断攻击来检测记忆数据，另一种是使用提示前缀的生成任务来评估逐字复现。我们分析了 Transformer 架构中适应不同权重矩阵的影响、困惑度与记忆化之间的关系，以及低秩适应（LoRA）微调中增加秩的影响。
主要发现包括：(1) 相较于查询（Query）和键（Key）矩阵，值（Value）和输出（Output）矩阵对记忆化的贡献更显著；(2) 微调模型中较低的困惑度与记忆化增加相关；(3) 较高的 LoRA 秩会导致记忆化增加，但在较高秩时回报递减。
这些结果为微调 LLMs 中模型性能和隐私风险之间的权衡提供了见解。我们的发现对于开发更有效和负责任的策略，以在管理数据隐私问题的同时适应大型语言模型具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [33] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
> *SLIM-LLMs：通过低维表示建模风格-感官语言关系*

*Osama Khalid, Sanvesh Srivastava, Padmini Srinivasan* | **Category: cs.CL** | **Updated: 2025-08-04**

**Keywords:** 感官语言, 风格特征, 低维表示, SLIM-LLMs, 降秩岭回归

**Comment:** 

> **TL;DR:** 本文提出SLIM-LLMs，利用低维表示有效建模感官语言与风格特征的关系，并在性能匹配全尺寸模型的同时大幅减少参数。

**AI_Comments:** 本文的创新点在于提出了SLIM-LLMs，通过低维表示有效建模了感官语言与风格特征的复杂关系。其重要性体现在能够在保持甚至匹配全尺寸模型性能的同时，大幅减少模型参数，这对于资源受限或需要高效部署的应用具有重要意义。该方法为理解和处理感官语言提供了新的视角和高效工具。

<details>
  <summary>Details</summary>

**Motivation:** 探索感官语言（与视觉、听觉、触觉、味觉、嗅觉和内感受相关的语言）与传统风格特征（如LIWC衡量）之间的关系，因为感官语言在交流经验和感知中扮演基础角色。

**Method:** 采用新颖的降秩岭回归（Reduced-Rank Ridge Regression, R4）方法，并引入风格计量精益可解释模型（Stylometrically Lean Interpretable Models, SLIM-LLMs）来建模这些风格维度之间的非线性关系，使用低维潜在表示（r=24）的LIWC特征。

**Result:** 结果表明，LIWC特征的低维潜在表示（r=24）比完整特征集（r=74）能更有效地捕捉风格信息以预测感官语言。SLIM-LLMs在五种体裁上进行评估，其使用低秩LIWC特征的性能与全尺寸语言模型相当，同时将参数减少了高达80%。

**Conclusion:** SLIM-LLMs通过低维表示有效地建模了感官语言与风格特征之间的非线性关系，并在保持性能的同时显著降低了模型复杂度。

> **ai_Abstract:** 本文提出SLIM-LLMs，一种利用低维表示建模感官语言与传统风格特征（如LIWC）之间非线性关系的新方法。通过降秩岭回归（R4）发现，低维LIWC特征（r=24）能有效捕捉感官语言的风格信息。SLIM-LLMs在多体裁评估中，实现了与全尺寸语言模型相当的性能，同时将模型参数减少了高达80%，显示了其在效率和效果上的优势。

> **摘要翻译:** 感官语言——与我们的视觉、听觉、触觉、味觉、嗅觉和内感受相关的语言——在交流经验和感知方面发挥着基础性作用。我们使用一种新颖的降秩岭回归（R4）方法，探索感官语言与传统风格特征（例如LIWC衡量）之间的关系。我们证明，LIWC特征的低维潜在表示（r=24）与完整特征集（r=74）相比，能有效地捕获风格信息以进行感官语言预测。我们引入了风格计量精益可解释模型（SLIM-LLMs），它们建模了这些风格维度之间的非线性关系。在五种体裁上进行评估，使用低秩LIWC特征的SLIM-LLMs的性能与全尺寸语言模型相匹配，同时将参数减少了高达80%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [35] [Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed Learning for Continual Adaptation](https://arxiv.org/abs/2508.03571)
> *通过KILO（知识指导学习持续适应）解决LLM中的分布偏移问题*

*Iing Muttakhiroh, Thomas Fevens* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 持续学习, 领域偏移, 知识图谱, 指令调优

**Comment:** 

> **TL;DR:** KILO是一种结合动态知识图谱和指令调优的持续学习框架，旨在帮助大型语言模型（LLMs）在面对领域偏移时克服灾难性遗忘，提高适应性和知识保留能力，并被证明优于现有基线模型。

**AI_Comments:** KILO的创新点在于将动态知识图谱与指令调优相结合，为LLM的持续学习提供了一种新颖且有效的方法来应对领域偏移和灾难性遗忘。其重要性体现在为LLM在真实世界动态环境中的部署提供了更鲁棒的解决方案，提升了模型的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在面对领域偏移时，由于灾难性遗忘，性能会显著下降。

**Method:** 本文提出了KILO（知识指导学习持续适应），一个新颖的持续学习框架。它将动态知识图谱与指令调优相结合，通过利用检索到的领域特定知识作为训练指导，增强模型对新领域的适应性以及对先前知识的保留。

**Result:** KILO在四个不同的目标领域（BioASQ, SciQ, TweetEval, MIND）的顺序适应评估中，持续优于包括持续微调、ERNIE 2.0和CPT在内的强基线模型。它在反向迁移、正向迁移、F1分数、保留率和训练效率方面表现出色。

**Conclusion:** 结合结构化知识检索和指令提示对于克服持续学习场景中的领域偏移挑战是有效的。

> **ai_Abstract:** 本文提出了一种名为KILO（知识指导学习持续适应）的新型持续学习框架，旨在解决大型语言模型（LLMs）在领域偏移下因灾难性遗忘导致的性能下降问题。KILO通过整合动态知识图谱和指令调优，并利用检索到的领域特定知识进行指导，显著提升了模型对新领域的适应性和对现有知识的保留能力。实验结果显示，KILO在多个领域任务上，包括反向迁移、正向迁移、F1分数、保留率和训练效率等指标上，均优于多种现有基线方法，证明了结合结构化知识检索和指令提示在持续学习中处理领域偏移的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在面对领域偏移时，由于灾难性遗忘，性能通常会下降。在这项工作中，我们提出了KILO（知识指导学习持续适应），这是一个新颖的持续学习框架，它将动态知识图谱与指令调优相结合。通过在训练过程中利用检索到的领域特定知识作为指导，KILO增强了对新领域的适应性以及对先前获取知识的保留。我们模型在WikiText-103上进行预训练，并在四个不同的目标领域：BioASQ、SciQ、TweetEval和MIND上评估了顺序适应性。我们的实验表明，KILO在反向迁移、正向迁移、F1分数、保留率和训练效率方面始终优于强大的基线模型，包括持续微调、ERNIE 2.0和CPT。这些结果突出了结合结构化知识检索和指令提示在持续学习场景中克服领域偏移挑战的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [44] [From Text to Trajectory: Exploring Complex Constraint Representation and Decomposition in Safe Reinforcement Learning](https://arxiv.org/abs/2412.08920)
> *从文本到轨迹：探索安全强化学习中复杂约束的表示与分解*

*Pusen Dong, Tianchen Zhu, Yue Qiu, Haoyi Zhou, Jianxin Li* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 安全强化学习, 自然语言约束, 文本约束翻译, 零样本迁移, 成本函数

**Comment:** Accepted by NeurIPS 2024

> **TL;DR:** 本文提出TTCT，一种用文本信号训练安全强化学习中轨迹级约束翻译器的方法，解决了手动设计成本函数的问题，并实现了更好的约束遵守和零样本迁移能力。

**AI_Comments:** 该论文的创新点在于将文本的双重作用应用于安全强化学习，即不仅用作约束描述，还用作训练信号，从而取代了耗时且需要专业知识的手动成本函数设计。TTCT的引入显著提高了安全RL处理自然语言约束的灵活性和自动化程度，特别是其零样本迁移能力对于实际应用具有重要意义，因为它允许模型在未见过的约束下也能保持性能。这对于构建更通用、更易于部署的安全RL系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 以前带有自然语言约束的安全强化学习方法通常需要为每个约束手动设计成本函数，这需要领域专业知识并且缺乏灵活性。

**Method:** 本文引入了轨迹级文本约束翻译器 (TTCT)，它利用文本作为约束和训练信号，以取代手动设计的成本函数。

**Result:** TTCT能够有效地理解文本约束和轨迹。通过TTCT训练的策略可以实现比标准成本函数更低的违规率。TTCT还具有零样本迁移能力，能够适应约束变化的环境。

**Conclusion:** TTCT提供了一种有效且灵活的方式来处理安全强化学习中的自然语言约束，提高了约束遵守能力和适应性。

> **ai_Abstract:** 本文针对安全强化学习中自然语言约束手动设计成本函数的问题，提出了一种轨迹级文本约束翻译器（TTCT）。TTCT利用文本作为约束和训练信号，无需手动设计成本函数。实验结果表明，TTCT能有效理解文本约束和轨迹，训练出的策略具有更低的违规率，并展现出对约束变化环境的零样本迁移能力。

> **摘要翻译:** 安全强化学习 (RL) 要求智能体在完成给定任务的同时遵守特定约束。以自然语言形式给出约束因其灵活的迁移能力和可访问性而在实际场景中具有巨大潜力。以前的带有自然语言约束的安全RL方法通常需要为每个约束手动设计成本函数，这需要领域专业知识并且缺乏灵活性。在本文中，我们利用文本在此任务中的双重作用，不仅将其用于提供约束，还将其用作训练信号。我们引入了轨迹级文本约束翻译器 (TTCT) 来取代手动设计的成本函数。我们的实证结果表明，TTCT 有效地理解了文本约束和轨迹，并且通过TTCT训练的策略可以实现比标准成本函数更低的违规率。进行了额外的研究以证明TTCT具有零样本迁移能力以适应约束变化的环境。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [50] [CardiffNLP at CLEARS-2025: Prompting Large Language Models for Plain Language and Easy-to-Read Text Rewriting](https://arxiv.org/abs/2508.03240)
> *CardiffNLP在CLEARS-2025：提示大型语言模型进行通俗语言和易读文本改写*

*Mutaz Ayesh, Nicolás Gutiérrez-Rolón, Fernando Alva-Manchego* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 文本改写, 提示工程, 西班牙语文本适应, CLEARS共享任务

**Comment:** 

> **TL;DR:** CardiffNLP团队使用LLM提示方法参加CLEARS共享任务，在子任务1中获得第三名，子任务2中获得第二名。

**AI_Comments:** 这项研究展示了大型语言模型在文本改写，特别是易读性文本适应方面的潜力。通过系统地探索不同的提示策略，该团队不仅在竞争性共享任务中取得了优异成绩，也为未来LLM在文本简化领域的应用提供了实证经验。其创新点在于对LLM提示工程的深入实践。

<details>
  <summary>Details</summary>

**Motivation:** 参加IberLEF 2025主办的CLEARS西班牙语文本适应共享任务。

**Method:** 采用LLM提示方法，尝试了不同的提示变体。最终提交使用了Gemma-3模型，并最初实验了LLaMA-3.2。

**Result:** 在子任务1中获得第三名，在子任务2中获得第二名。

**Conclusion:** 该团队通过LLM提示方法在CLEARS共享任务的西班牙语文本适应方面取得了显著成果，证明了其方法的有效性。

> **ai_Abstract:** 本文介绍了CardiffNLP团队在CLEARS-2025西班牙语文本适应共享任务中的参与。该团队采用LLM提示方法，并尝试了多种提示变体，最终使用Gemma-3模型提交。他们在两个子任务中分别获得了第三名和第二名的成绩，论文中详细阐述了其提示策略和实验结果。

> **摘要翻译:** 本文详细介绍了CardiffNLP团队对IberLEF 2025主办的CLEARS西班牙语文本适应共享任务的贡献。该共享任务包含两个子任务，该团队都提交了参赛。我们的团队采用了LLM提示方法，并使用了不同的提示变体。虽然我们最初尝试了LLaMA-3.2，但最终提交采用了Gemma-3，并在子任务1中获得第三名，在子任务2中获得第二名。我们详细介绍了我们众多的提示变体、示例和实验结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [57] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
> *大型语言模型能否生成高质量的特定任务对话？*

*Shengqi Li, Amarnath Gupta* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 对话质量, 参数化框架, 对话生成, 控制粒度

**Comment:** 

> **TL;DR:** 本文提出一个参数化框架，通过控制对话属性的九个参数来提高大型语言模型生成对话的质量。

**AI_Comments:** 这项研究的创新之处在于提出了一种参数化框架，为控制大型语言模型生成的对话质量提供了一种标准化且精细的方法。它通过明确的参数设置解决了现有对话生成中的一致性和连贯性问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型在对话生成中面临的挑战，如话题连贯性、知识进展、角色一致性和控制粒度，并提供一种标准化方法来控制对话质量。

**Method:** 引入一个参数化框架，通过九个关键参数（跨六个维度）来精确指定对话属性，从而控制大型语言模型中的对话质量。

**Result:** 通过对最先进的大型语言模型进行实验，结果表明基于参数的控制在生成的对话属性上产生了统计学上的显著差异。

**Conclusion:** 该框架为对话质量控制提供了一种标准化方法，可应用于教育、治疗、客户服务和娱乐等领域。

> **ai_Abstract:** 本文提出一个参数化框架，通过九个跨六个维度的参数来精确控制大型语言模型生成的对话质量。实验证明，该方法能显著改善对话属性，解决了话题连贯性、知识进展、角色一致性和控制粒度等挑战。该框架为对话质量控制提供了一种标准化方法，在教育、治疗、客户服务和娱乐等领域具有广泛应用前景。

> **摘要翻译:** 本文介绍了一个用于控制大型语言模型对话质量的参数化框架。我们探索了跨六个维度的九个关键参数，这些参数能够精确地指定对话属性。通过对最先进的大型语言模型进行实验，我们证明了基于参数的控制在生成的对话属性上产生了统计学上的显著差异。我们的方法解决了对话生成中的挑战，包括话题连贯性、知识进展、角色一致性和控制粒度。该框架提供了一种标准化方法，用于对话质量控制，可应用于教育、治疗、客户服务和娱乐领域。未来的工作将侧重于通过架构修改实现额外参数，并开发用于评估的基准数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [61] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
> *SMART-Editor: 一种具有结构完整性的人类般设计编辑多智能体框架*

*Ishani Mondal, Meera Bharadwaj, Ayush Roy, Aparna Garimella, Jordan Lee Boyd-Graber* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 设计编辑, 多智能体框架, 结构完整性, 奖励引导, 全局一致性

**Comment:** This requires some internal approval before the public release

> **TL;DR:** SMART-Editor是一个多智能体框架，用于在结构化和非结构化领域进行构图布局和内容编辑，通过奖励引导的策略保持全局一致性，并在新基准测试中表现优于现有基线。

**AI_Comments:** SMART-Editor的创新之处在于其引入的奖励引导策略（Reward-Refine和RewardDPO），有效解决了传统模型在设计编辑中难以保持全局一致性的问题。其提出的SMARTEdit-Bench基准也为未来相关研究提供了有价值的评估工具。该框架在结构化和非结构化领域的表现证明了其广泛的适用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模型在进行局部编辑时，难以保持全局一致性，尤其是在跨结构化和非结构化领域进行构图布局和内容编辑时。因此，需要一种能够保持结构完整性和语义一致性的编辑框架。

**Method:** SMART-Editor框架通过两种策略实现：1. Reward-Refine：一种推理时奖励引导的细化方法。2. RewardDPO：一种使用奖励对齐布局对进行训练时偏好优化的方法。同时，引入了SMARTEdit-Bench基准来评估模型性能。

**Result:** SMART-Editor在SMARTEdit-Bench基准测试中表现优于InstructPix2Pix和HIVE等强基线模型。RewardDPO在结构化设置中实现了高达15%的增益，而Reward-Refine在自然图像上显示出优势。自动和人工评估证实了奖励引导规划在生成语义一致和视觉对齐编辑方面的价值。

**Conclusion:** SMART-Editor通过其奖励引导的规划策略，成功实现了在结构化和非结构化领域中保持全局一致性的设计编辑，显著优于现有方法，证明了其在生成高质量编辑方面的有效性。

> **ai_Abstract:** SMART-Editor是一个创新的多智能体框架，旨在解决设计编辑中全局一致性保持的挑战。它通过Reward-Refine和RewardDPO两种奖励引导策略，在结构化和非结构化数据上实现人类般的设计编辑。该框架引入了SMARTEdit-Bench基准进行评估，并在多领域级联编辑场景中表现出色，显著优于现有基线，证明了其在生成语义和视觉一致编辑方面的有效性。

> **摘要翻译:** 我们提出了SMART-Editor，一个用于跨结构化（海报、网站）和非结构化（自然图像）领域进行构图布局和内容编辑的框架。与执行局部编辑的现有模型不同，SMART-Editor通过两种策略保持全局一致性：Reward-Refine，一种推理时奖励引导的细化方法；以及RewardDPO，一种使用奖励对齐布局对进行训练时偏好优化的方法。为了评估模型性能，我们引入了SMARTEdit-Bench，一个涵盖多领域、级联编辑场景的基准。SMART-Editor优于InstructPix2Pix和HIVE等强基线模型，其中RewardDPO在结构化设置中实现了高达15%的增益，Reward-Refine在自然图像上显示出优势。自动和人工评估证实了奖励引导规划在生成语义一致和视觉对齐编辑方面的价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [67] [Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?](https://arxiv.org/abs/2508.03644)
> *我们评估文档检索增强生成的方法正确吗？*

*Wenxuan Shen, Mingjia Wang, Yaochen Wang, Dongping Chen, Junjie Yang, Yao Wan, Weiwei Lin* | **Category: cs.CL, cs.CV, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 检索增强生成, 评估基准, 多模态, 文档理解, Double-Bench

**Comment:** In submission. Project website: https://double-bench.github.io/

> **TL;DR:** 现有的文档检索增强生成（RAG）评估基准存在缺陷，无法反映真实世界挑战。本文提出了一个大规模、多语言、多模态的评估系统Double-Bench，用于细粒度评估RAG系统组件，并揭示了当前RAG模型在检索和置信度方面的问题。

**AI_Comments:** 本文创新性地提出了Double-Bench评估系统，解决了现有RAG评估基准的局限性，特别是其大规模、多语言、多模态的特性以及对细粒度评估的支持。该工作的意义在于为RAG系统的发展提供了更真实、更全面的评估工具，并揭示了当前RAG模型在检索能力和置信度方面的关键挑战，对未来的研究具有重要的指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文档检索增强生成（RAG）系统评估方法不足，常常侧重于特定部分，使用合成数据，且缺乏完整的真实标签和证据，因此未能反映真实世界的瓶颈和挑战。

**Method:** 本文引入了Double-Bench，一个大规模、多语言、多模态的评估系统，能够对文档RAG系统内的每个组件进行细粒度评估。它包含3,276份文档（72,880页）和5,168个单跳及多跳查询，涵盖6种语言和4种文档类型，并支持动态更新以解决数据污染问题。查询基于详尽扫描的证据页面，并经人工专家验证以确保质量和完整性。

**Result:** 通过对9个最先进的嵌入模型、4个多模态大语言模型（MLLMs）和4个端到端文档RAG框架进行全面实验，结果表明文本和视觉嵌入模型之间的差距正在缩小，这突显了构建更强大的文档检索模型的必要性。研究结果还揭示了当前文档RAG框架中存在的过度自信困境，即即使没有证据支持也倾向于提供答案。

**Conclusion:** Double-Bench提供了一个严谨的基础，用于未来对高级文档RAG系统的研究。研究强调了加强文档检索模型和解决模型过度自信问题的重要性。

> **ai_Abstract:** 本文针对当前文档检索增强生成（RAG）系统评估存在的不足，特别是基准测试无法反映真实世界挑战的问题，提出了一个新的大规模、多语言、多模态评估系统Double-Bench。该系统包含丰富的文档和查询数据，并经过人工验证，旨在提供RAG系统各组件的细粒度评估。实验结果揭示了文本和视觉嵌入模型差距的缩小，以及当前RAG框架存在的过度自信问题，强调了改进文档检索模型的必要性。Double-Bench作为一个开源工具，旨在为RAG系统的未来研究奠定坚实基础。

> **摘要翻译:** 检索增强生成（RAG）系统结合多模态大语言模型（MLLMs）在复杂文档理解方面展现出巨大潜力，但其发展受到评估不足的严重阻碍。当前基准通常侧重于文档RAG系统的特定部分，并使用合成数据，其中包含不完整的真实标签和证据标签，因此未能反映真实世界的瓶颈和挑战。为了克服这些限制，我们引入了Double-Bench：一个新型的大规模、多语言、多模态评估系统，能够对文档RAG系统内的每个组件进行细粒度评估。它包含3,276份文档（72,880页）和5,168个单跳及多跳查询，涵盖6种语言和4种文档类型，并支持动态更新以应对潜在的数据污染问题。查询基于详尽扫描的证据页面，并经人工专家验证，以确保最高质量和完整性。我们对9个最先进的嵌入模型、4个多模态大语言模型（MLLMs）和4个端到端文档RAG框架进行了全面实验，结果表明文本和视觉嵌入模型之间的差距正在缩小，这突显了构建更强大的文档检索模型的必要性。我们的发现还揭示了当前文档RAG框架中存在的过度自信困境，即即使没有证据支持也倾向于提供答案。我们希望我们完全开源的Double-Bench能为未来高级文档RAG系统的研究提供一个严谨的基础。我们计划及时检索语料库并每年发布新的基准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [81] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
> *CoCoTen：通过上下文共现张量的潜在空间特征检测大型语言模型的对抗性输入*

*Sri Durga Sai Sowmya Kadali, Evangelos E. Papalexakis* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 对抗性输入检测, 越狱, 上下文共现张量, 潜在空间特征

**Comment:** 

> **TL;DR:** CoCoTen是一种利用上下文共现张量潜在空间特征的方法，旨在有效且快速地检测大型语言模型的对抗性输入和越狱提示，尤其在数据稀缺环境下表现优异。

**AI_Comments:** 该论文的创新点在于利用上下文共现张量的潜在空间特征来检测LLM的对抗性输入，尤其强调了其在数据稀缺环境下的高效性和优越性能。这种方法不仅提高了检测准确率，还显著提升了处理速度，对LLM的安全性和可靠性具有重要意义。公开实现有助于未来的研究和结果复现。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）因其复杂性和难以理解的特性，容易受到越狱等攻击，产生有害响应，因此需要开发强大的检测方法以确保其安全可靠使用。

**Method:** 本文提出CoCoTen方法，利用上下文共现矩阵和张量的潜在空间特征来有效识别对抗性输入和越狱提示，尤其适用于数据稀缺环境。

**Result:** 该方法在仅使用0.5%的标记提示下，实现了0.83的F1分数，比基线提高了96.6%。此外，该方法速度显著加快，比基线模型快2.3到128.4倍。

**Conclusion:** 该研究表明，利用上下文共现张量潜在空间特征的方法能有效且高效地检测LLM的对抗性输入，尤其在标记数据稀缺时表现出色。

> **ai_Abstract:** 本文提出了一种名为CoCoTen的新方法，用于检测大型语言模型（LLMs）的对抗性输入和越狱提示。该方法利用上下文共现矩阵和张量的潜在空间特征，解决了LLMs易受攻击的问题。实验结果表明，CoCoTen在仅使用少量标记数据的情况下，实现了显著的检测性能（F1分数0.83），并且比现有基线方法速度更快，证明了其在数据稀缺环境下的有效性和高效性。

> **摘要翻译:** 大型语言模型（LLMs）在众多应用中的广泛使用标志着研究和实践的重大进步。然而，它们的复杂性和难以理解的特性使其容易受到攻击，特别是旨在产生有害响应的越狱攻击。为了应对这些威胁，开发强大的检测方法对于LLMs的安全可靠使用至关重要。本文利用上下文共现矩阵研究了这一检测问题，该结构因其在数据稀缺环境中的有效性而闻名。我们提出了一种新颖的方法，利用上下文共现矩阵和张量的潜在空间特征来有效识别对抗性输入和越狱提示。我们的评估表明，该方法在仅使用0.5%的标记提示下，实现了0.83的显著F1分数，比基线提高了96.6%。这一结果突出了我们学习到的模式的强大性，尤其是在标记数据稀缺时。与基线模型相比，我们的方法也显著更快，速度提升范围为2.3到128.4倍。为了支持未来的研究和可重复性，我们已将我们的实现公开。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [98] [RooseBERT: A New Deal For Political Language Modelling](https://arxiv.org/abs/2508.03250)
> *RooseBERT：政治语言建模的新政*

*Deborah Dore, Elena Cabrio, Serena Villata* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 政治语言模型, RooseBERT, 政治辩论分析, 领域特定预训练, 自然语言处理

**Comment:** 

> **TL;DR:** RooseBERT是一种专门为政治语言设计的预训练语言模型，在政治辩论分析任务上显著优于通用语言模型。

**AI_Comments:** RooseBERT的创新之处在于其领域特定的预训练方法，解决了通用语言模型在处理复杂政治语言时面临的挑战。这对于政治学、计算社会科学以及自然语言处理领域具有重要意义，因为它为更精确地分析政治话语提供了强大的工具。其贡献在于不仅提出了模型，还将其发布，有助于推动相关研究。

<details>
  <summary>Details</summary>

**Motivation:** 政治辩论和相关讨论日益增多，需要新的计算方法来自动分析这些内容，以帮助公民进行政治审议。然而，政治语言的特殊性和辩论的论证形式（包含隐藏的沟通策略和隐含论点）使得这项任务极具挑战性，即使对于当前的通用预训练语言模型也是如此。

**Method:** 为了解决政治语言分析的挑战，本文引入了一种名为RooseBERT的新型预训练语言模型，专门用于政治话语。RooseBERT在大型英语政治辩论和演讲语料库（8K场辩论）上进行了训练。为了评估其性能，研究人员在四个与政治辩论分析相关的下游任务上对其进行了微调：命名实体识别、情感分析、论点成分检测与分类以及论点关系预测与分类。

**Result:** RooseBERT在命名实体识别、情感分析、论点成分检测与分类、论点关系预测与分类这四个政治辩论分析任务上，表现出比通用语言模型显著的性能提升。

**Conclusion:** 领域特定的预训练能够显著提高政治辩论分析的性能。研究团队将RooseBERT语言模型发布给研究社区。

> **ai_Abstract:** 该论文提出了RooseBERT，一个专门为政治话语设计的预训练语言模型，旨在解决通用语言模型在分析复杂政治辩论内容时的局限性。RooseBERT在大量政治辩论和演讲数据上进行训练，并在命名实体识别、情感分析、论点成分检测与分类以及论点关系预测与分类等四个政治辩论分析任务上进行了评估。实验结果表明，RooseBERT在这些任务上的性能显著优于通用语言模型，证明了领域特定预训练在政治语言分析中的有效性。该模型已发布供研究社区使用。

> **摘要翻译:** 政治辩论和政治相关讨论的日益增多，要求定义新颖的计算方法来自动分析这些内容，最终目标是减轻公民的政治审议负担。然而，政治语言的特殊性和这些辩论的论证形式（采用隐藏的沟通策略和利用隐含论点）使得这项任务极具挑战性，即使对于当前的通用预训练语言模型也是如此。为了解决这个问题，我们引入了一种名为RooseBERT的、针对政治话语语言的新型预训练语言模型。在特定领域预训练语言模型面临不同的技术和语言挑战，需要大量的计算资源和大规模数据。RooseBERT已经在大型英语政治辩论和演讲语料库（8K场辩论，每场由多个不同主题的子辩论组成）上进行了训练。为了评估其性能，我们将其在四个与政治辩论分析相关的下游任务上进行了微调，即命名实体识别、情感分析、论点成分检测与分类，以及论点关系预测与分类。我们的结果表明，在这些任务上，RooseBERT比通用语言模型有显著改进，这突出表明领域特定的预训练如何增强政治辩论分析的性能。我们将RooseBERT语言模型发布给研究社区。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [99] [Can Large Vision-Language Models Understand Multimodal Sarcasm?](https://arxiv.org/abs/2508.03654)
> *大型视觉语言模型能理解多模态讽刺吗？*

*Xinyu Wang, Yue Zhang, Liqiang Jing* | **Category: cs.CL, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态讽刺, 大型视觉语言模型, 讽刺检测, 讽刺解释, 免训练框架

**Comment:** Accepted by CIKM 2025

> **TL;DR:** 本文评估了大型视觉语言模型在多模态讽刺理解方面的能力，并提出了一个免训练框架来改进其表现。

**AI_Comments:** 该研究的创新之处在于提出了一个免训练框架，通过集成深度对象提取和外部概念知识来弥补大型视觉语言模型在多模态讽刺理解方面的不足。这为改进LVLMs在复杂情感分析任务中的表现提供了一个新颖且有效的方法，对于推动多模态AI理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 讽刺是一种复杂的语言现象，涉及字面意义和预期意义之间的差异，这使得情感分析和其他情感敏感任务面临挑战。尽管传统方法主要关注文本，且最近方法已结合多模态信息，但大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）中的应用仍未得到充分探索。本研究旨在评估LVLMs在此任务中的表现并解决其局限性。

**Method:** 本文评估了大型视觉语言模型（LVLMs）在多模态讽刺检测和多模态讽刺解释任务中的表现。通过全面实验，识别出LVLMs在视觉理解不足和概念知识缺乏等方面的局限性。为解决这些问题，本研究提出了一个免训练框架，该框架通过整合深度对象提取和外部概念知识来提高模型在多模态语境中解释和理解讽刺的能力。

**Result:** 在多个模型上的实验结果表明，所提出的免训练框架是有效的，能够显著提高大型视觉语言模型在多模态讽刺分析任务中的表现。

**Conclusion:** 提出的免训练框架通过整合深度对象提取和外部概念知识，有效提升了大型视觉语言模型在多模态讽刺分析任务中的表现，解决了其在视觉理解和概念知识方面的局限性，从而使其能够更好地理解和解释多模态讽刺。

> **ai_Abstract:** 本文探讨了大型视觉语言模型（LVLMs）在多模态讽刺理解（包括检测和解释）方面的能力，发现LVLMs在视觉理解和概念知识方面存在局限性。为解决这些问题，作者提出了一个免训练框架，通过整合深度对象提取和外部概念知识来增强LVLMs对多模态讽刺的解释能力。实验证明该框架有效提升了LVLMs在多模态讽刺分析任务中的表现。

> **摘要翻译:** 讽刺是一种复杂的语言现象，涉及字面意义和预期意义之间的差异，这使得情感分析和其他情感敏感任务面临挑战。虽然传统的讽刺检测方法主要侧重于文本，但最近的方法已结合了多模态信息。然而，大型视觉语言模型（LVLMs）在多模态讽刺分析（MSA）中的应用仍未得到充分探索。在本文中，我们评估了LVLMs在MSA任务中的表现，特别关注多模态讽刺检测和多模态讽刺解释。通过全面的实验，我们发现了关键的局限性，例如视觉理解不足和概念知识缺乏。为了解决这些问题，我们提出了一个免训练框架，该框架集成了深度对象提取和外部概念知识，以提高模型在多模态语境中解释和解释讽刺的能力。在多个模型上的实验结果表明，我们提出的框架是有效的。代码可在https://github.com/cp-cp/LVLM-MSA获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [101] [Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy](https://arxiv.org/abs/2508.01696)
> *协同智能体链用于参数检索知识协同*

*Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Lizhe Zhang, Yan Liu, Bing Qin* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 检索增强生成, 大型语言模型, 知识协同, 多智能体, 长链训练

**Comment:** code available at https://github.com/liunian-Jay/CoCoA

> **TL;DR:** 提出CoCoA框架，通过协同智能体链增强LLM在RAG中对参数知识和检索知识的协同利用能力。

**AI_Comments:** 这项工作通过引入多智能体协同和长链训练策略，创新性地解决了RAG中参数知识与检索知识协同不足的关键问题。其提出的CoCoA框架为提高LLM在知识密集型任务中的准确性和鲁棒性提供了有价值的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成（RAG）方法在生成过程中未能充分利用知识，特别是模型内部参数知识和外部检索知识之间的协同有限，检索内容有时会误导生成。

**Method:** 提出Collaborative Chain-of-Agents框架，旨在增强参数知识和检索知识的显式协同。具体包括：1. CoCoA-zero：一个多智能体RAG框架，首先执行条件知识归纳，然后推理答案。2. CoCoA：一种长链训练策略，从CoCoA-zero合成扩展的多智能体推理轨迹来微调LLM，以增强模型显式集成和共同利用参数知识和检索知识的能力。

**Result:** CoCoA-zero和CoCoA在开放域和多跳问答任务上取得了优越的性能。

**Conclusion:** 该研究通过CoCoA框架成功提升了大型语言模型（LLM）在检索增强生成（RAG）中对参数知识和检索知识的协同利用，从而在知识密集型任务上表现更佳。

> **ai_Abstract:** 本文提出了一个名为“协同智能体链”（Collaborative Chain-of-Agents）的框架，旨在解决现有检索增强生成（RAG）方法中参数知识和检索知识协同不足的问题。该框架包含CoCoA-zero（一个执行条件知识归纳和答案推理的多智能体RAG框架）和CoCoA（一种利用CoCoA-zero轨迹微调LLM的长链训练策略）。实验证明，CoCoA-zero和CoCoA在开放域和多跳问答任务上表现优异，有效提升了LLM对两种知识的集成和利用能力。

> **摘要翻译:** 检索增强生成（RAG）已成为一种有前景的框架，用于增强大型语言模型（LLM）的能力，尤其是在知识密集型任务中。尽管其具有优势，但当前的RAG方法在“生成过程中充分利用知识”方面常常面临困难。特别是，模型内部参数知识与外部检索知识之间的协同作用仍然有限。检索到的内容有时可能会误导生成，而某些生成的内容则可以引导模型产生更准确的输出。在这项工作中，我们提出了协同智能体链（Collaborative Chain-of-Agents），一个旨在增强参数知识和检索知识之间显式协同作用的框架。具体而言，我们首先引入了CoCoA-zero，一个多智能体RAG框架，它首先执行条件知识归纳，然后推理答案。在此基础上，我们开发了CoCoA，一种长链训练策略，该策略从CoCoA-zero合成扩展的多智能体推理轨迹以微调LLM。这种策略增强了模型显式整合和共同利用参数知识和检索知识的能力。实验结果表明，CoCoA-zero和CoCoA在开放域和多跳问答任务上取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [106] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
> *当算法遇到艺术家：2013-2025年AI艺术辩论的主题建模*

*Ariya Mukherjee-Gandhi, Oliver Muellerklein* | **Category: cs.CL, cs.CY, cs.HC** | **Updated: 2025-08-05**

**Keywords:** AI艺术, 主题建模, 艺术家视角, 语篇分析, BERTopic

**Comment:** 18 pages, 5 figures, 5 tables

> **TL;DR:** 本研究分析了2013年至2025年间AI生成艺术的英语语篇，发现艺术家对同意、透明度和创作劳动的担忧被边缘化，并揭示了艺术家视角与主流媒体叙事之间的错位，指出技术术语是排斥艺术家声音的屏障。

**AI_Comments:** 该论文创新性地运用主题建模方法，对AI艺术辩论中被忽视的艺术家声音进行了深入分析。其重要性在于揭示了技术语境下信息不对称和话语权差异如何边缘化特定群体，并为未来研究提供了宝贵的多模态基线和BERTopic应用范例。论文的发现对于理解AI时代创意产业的社会影响和推动更包容的政策制定具有启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI重塑艺术创作，艺术家的生计受到直接影响，他们提出了关于同意、透明度和创意劳动未来的紧急关切。然而，艺术家的声音在主流公共和学术话语中经常被边缘化，本研究旨在分析和揭示这种语篇。

**Method:** 本研究对2013年至2025年期间围绕AI生成艺术的英语语篇进行了为期十二年的分析。数据来源于439份精心策划的500字摘录，这些摘录选自评论文章、新闻报道、博客、法律文件和口语转录。研究采用可复现的方法，并基于BERTopic构建。

**Result:** 研究识别出五个稳定的主题群，并揭示了艺术家认知与主流媒体叙事之间的错位。研究结果强调了技术术语的使用如何起到微妙的“守门人”作用，常常将艺术家认为最紧迫的问题边缘化。

**Conclusion:** 本研究为未来的研究提供了基于BERTopic的方法和多模态基线，并明确呼吁在不断发展的AI创意领域中，以更深入、更透明的方式关注艺术家的视角。

> **ai_Abstract:** 本研究分析了2013年至2025年间关于AI生成艺术的英语语篇，以解决艺术家声音被边缘化的问题。通过对439份多元文本摘录进行主题建模（基于BERTopic），研究识别了五个核心主题，并发现艺术家对AI艺术的看法与主流媒体叙事存在显著差异。研究特别指出，技术术语的使用是导致艺术家关切被忽视的一个重要因素。该工作为未来研究提供了方法论基础，并强调了在AI艺术发展中融入艺术家视角的必要性。

> **摘要翻译:** 随着生成式AI不断重塑艺术创作和人类表达的其他模式，生计受到最直接影响的艺术家们提出了关于同意、透明度和创意劳动未来的紧急关切。然而，艺术家的声音在主流公共和学术话语中经常被边缘化。本研究对2013年至2025年期间围绕AI生成艺术的英语语篇进行了为期十二年的分析。它从439份精心策划的500字摘录中提取数据，这些摘录选自评论文章、新闻报道、博客、法律文件和口语转录。通过一种可复现的方法，我们识别出五个稳定的主题群，并揭示了艺术家认知与主流媒体叙事之间的错位。我们的发现强调了技术术语的使用如何起到微妙的“守门人”作用，常常将艺术家认为最紧迫的问题边缘化。我们的工作为未来的研究提供了基于BERTopic的方法和多模态基线，同时明确呼吁在不断发展的AI创意领域中，以更深入、更透明的方式关注艺术家的视角。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [113] [Think Outside the Data: Colonial Biases and Systemic Issues in Automated Moderation Pipelines for Low-Resource Languages](https://arxiv.org/abs/2501.13836)
> *跳出数据思维：低资源语言自动化内容审核流程中的殖民偏见与系统性问题*

*Farhana Shahid, Mona Elswah, Aditya Vashistha* | **Category: cs.CL, cs.HC** | **Updated: 2025-08-05**

**Keywords:** 自动化审核, 低资源语言, 殖民偏见, 系统性问题, 全球南方

**Comment:** Accepted to AIES 2025

> **TL;DR:** 本文通过对AI专家的访谈，揭示了低资源语言自动化内容审核系统不仅面临数据稀缺问题，更存在根植于殖民压迫的结构性不平等和系统性偏见，并提出多方利益相关者方法来改善现状。

**AI_Comments:** 这篇论文的创新之处在于，它超越了通常将低资源语言审核问题归结为“数据稀缺”的技术视角，而是深入剖析了背后的社会政治和历史因素，特别是指出了殖民偏见和结构性不平等在其中的作用。这为理解和解决AI公平性问题提供了更深刻的框架，强调了技术开发中人文关怀和历史视角的必要性。其重要性在于，它揭示了AI系统可能无意中延续甚至加剧现有社会不公的风险，并为构建更具包容性和公平性的AI系统提供了新的思考方向和多方利益相关者合作的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大多数社交媒体用户来自全球南方，有害内容常以当地语言出现，但AI驱动的审核系统难以处理这些地区的低资源语言。本文旨在探讨为低资源语言构建自动化审核工具时存在的系统性问题。

**Method:** 通过对22位AI专家进行半结构化访谈，这些专家致力于四种低资源语言（泰米尔语、斯瓦希里语、马格里布阿拉伯语、克丘亚语）的有害内容检测工作。

**Result:** 研究发现，除了数据稀缺，科技公司对用户数据的垄断以及对低利润全球南方市场投资不足等社会政治因素，加剧了历史不平等。即使有更多数据，以英语为中心和数据密集型的语言模型及预处理技术设计，也忽视了为形态复杂、语言多样和混合编码的语言进行设计的需求。这些局限性不仅是“数据稀缺”导致的技术空白，更反映了根植于对非西方语言殖民压制的结构性不平等。

**Conclusion:** 本文认为，低资源语言自动化审核的局限性不仅仅是技术问题，更是源于殖民压制的结构性不平等。作者呼吁采取多方利益相关者方法，以增强本地研究能力、实现数据访问民主化，并支持语言感知型解决方案，以改善低资源语言的自动化审核。

> **ai_Abstract:** 本文通过对22位AI专家进行半结构化访谈，深入探讨了低资源语言（如泰米尔语、斯瓦希里语、马格里布阿拉伯语和克丘亚语）自动化内容审核系统中的系统性问题。研究指出，除了普遍认为的数据稀缺，科技巨头的数据垄断、对全球南方市场的投资不足以及以英语为中心的设计范式，共同导致了根植于殖民历史的结构性不平等。这些因素使得现有系统难以有效处理形态复杂、语言多样和混合编码的低资源语言。文章强调，这些限制并非单纯的技术缺陷，而是深层次的社会政治和历史不公的体现，并倡导通过多方合作，提升本地研究能力，实现数据民主化，并开发更具语言敏感性的解决方案，以改善低资源语言的审核困境。

> **摘要翻译:** 大多数社交媒体用户来自全球南方，有害内容通常以当地语言出现。然而，人工智能驱动的审核系统在处理这些地区使用的低资源语言时面临困难。通过对22位致力于四种低资源语言（泰米尔语、斯瓦希里语、马格里布阿拉伯语和克丘亚语）有害内容检测的AI专家进行半结构化访谈，我们审视了为这些语言构建自动化审核工具时存在的系统性问题。我们的研究结果表明，除了数据稀缺，科技公司对用户数据的垄断以及对低利润全球南方市场投资不足等社会政治因素，加剧了历史不平等。即使有更多数据可用，以英语为中心和数据密集型的语言模型及预处理技术设计，也忽视了为形态复杂、语言多样和混合编码的语言进行设计的需求。我们认为这些局限性不仅仅是“数据稀缺”造成的技术空白，更反映了根植于对非西方语言殖民压制的结构性不平等。我们讨论了多方利益相关者方法，以增强本地研究能力，实现数据访问民主化，并支持语言感知型解决方案，以改善低资源语言的自动化审核。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [131] [CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction](https://arxiv.org/abs/2508.03668)
> *CTR-Sink：点击率预测中语言模型的注意力汇聚*

*Zixuan Li, Binzong Geng, Jing Xiong, Yong He, Yuxuan Hu, Jian Chen, Dingwei Chen, Xiyu Chang, Liang Zhang, Linjian Mo, Chengming Li, Chuan Yuan, Zhenan Sun* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 点击率预测, 语言模型, 注意力汇聚, 推荐系统, 用户行为序列

**Comment:** 

> **TL;DR:** CTR-Sink引入行为级注意力汇聚机制，解决语言模型在点击率预测中因行为序列与自然语言不匹配导致的注意力分散问题，并通过两阶段训练策略提升性能。

**AI_Comments:** CTR-Sink的创新点在于将注意力汇聚理论应用于推荐系统中的用户行为序列建模，巧妙地解决了语言模型在处理非自然语言序列时的语义碎片化问题。通过引入行为级注意力汇聚点和两阶段训练策略，它有效地引导了LM的注意力，使其能够更好地理解用户行为间的复杂关系。这种方法为将强大的语言模型更有效地应用于推荐系统提供了一个有前景的方向，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 点击率（CTR）预测是推荐系统中的核心任务。尽管语言模型（LMs）因其强大的语义理解和上下文建模能力被应用于此任务，但用户行为序列与LM预训练的连贯自然语言之间存在结构性差异。用户行为序列由离散动作和语义空分隔符组成，导致LM注意力分散到不相关词元，无法聚焦于有意义的行为边界和行为间关系，从而降低预测性能。

**Method:** 为解决上述问题，本文提出了CTR-Sink框架，该框架引入了为推荐场景量身定制的行为级注意力汇聚机制。受注意力汇聚理论启发，CTR-Sink构建注意力焦点汇聚点并通过外部信息动态调节注意力聚合。具体而言，它在连续行为之间插入汇聚词元（sink tokens），并融入推荐特有信号（如时间距离）作为稳定的注意力汇聚点。为增强通用性，设计了两阶段训练策略，明确引导LM注意力聚焦于汇聚词元，并采用注意力汇聚机制放大汇聚点间的依赖关系，以更好地捕捉行为关联。

**Result:** 在工业数据集和两个开源数据集（MovieLens、Kuairec）上的实验结果，以及可视化结果，都验证了该方法在不同场景下的有效性。

**Conclusion:** CTR-Sink框架通过引入行为级注意力汇聚机制和两阶段训练策略，有效解决了语言模型在点击率预测中处理用户行为序列时的注意力分散问题，显著提升了预测性能。

> **ai_Abstract:** 本文提出CTR-Sink框架，旨在解决语言模型（LMs）在点击率（CTR）预测中处理用户行为序列时面临的注意力分散问题。由于用户行为序列与LM预训练的自然语言存在结构性差异，导致LM注意力未能有效聚焦于关键行为关系。CTR-Sink通过引入行为级注意力汇聚机制，在行为间插入带有推荐特定信号（如时间距离）的汇聚词元，作为注意力焦点。此外，设计了两阶段训练策略，引导LM注意力聚焦于这些汇聚词元，并增强汇聚点间的依赖关系，以更准确地捕捉行为关联。实验结果表明，CTR-Sink在多个数据集上均能有效提升CTR预测性能。

> **摘要翻译:** 点击率（CTR）预测是推荐系统中的核心任务，它利用历史行为数据估计用户点击的可能性。将用户行为序列建模为文本以利用语言模型（LMs）进行这项任务已获得关注，这得益于LM强大的语义理解和上下文建模能力。然而，存在一个关键的结构性差距：用户行为序列由通过语义空分隔符连接的离散动作组成，这与LM预训练中连贯的自然语言根本不同。这种不匹配导致语义碎片化，即LM注意力分散到不相关词元上，而不是聚焦于有意义的行为边界和行为间关系，从而降低了预测性能。为了解决这个问题，我们提出了CTR-Sink，一个引入了针对推荐场景定制的行为级注意力汇聚机制的新颖框架。受注意力汇聚理论启发，它构建了注意力焦点汇聚点并通过外部信息动态调节注意力聚合。具体而言，我们在连续行为之间插入汇聚词元，并结合推荐特定的信号（例如时间距离）作为稳定的注意力汇聚点。为了增强通用性，我们设计了一种两阶段训练策略，明确引导LM注意力转向汇聚词元，以及一种注意力汇聚机制，以放大汇聚点间的依赖关系，从而更好地捕捉行为相关性。在工业数据集和两个开源数据集（MovieLens、Kuairec）上的实验，以及可视化结果，验证了该方法在不同场景下的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [132] [MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized Domain Question-Answering](https://arxiv.org/abs/2505.18247)
> *MetaGen 混合RAG：解锁专业领域问答的零样本精度*

*Kunal Sawarkar, Shivam R. Solanki, Abhilasha Mangal* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** RAG, 零样本, 专业领域, 元数据生成, 混合查询

**Comment:** 

> **TL;DR:** MetaGen 混合RAG通过元数据生成管道和混合查询索引来增强语义检索器，实现了专业领域问答的零样本高精度，在多个数据集上超越了现有零样本RAG基准，甚至媲美微调模型。

**AI_Comments:** 该论文的创新之处在于利用元数据生成管道和混合索引技术，在不进行微调的情况下实现了与微调模型相媲美的零样本精度，有效克服了专业领域微调RAG的成本和泛化问题。其无需微调即可跨领域泛化的能力对于企业应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统检索增强生成（RAG）在处理领域特定企业数据集时面临挑战，因为这些数据集通常包含LLM预训练时未见过的复杂专业术语。此外，跨领域的语义可变性会影响RAG的上下文精度，而微调解决方案成本高昂、速度慢且在新数据出现时缺乏泛化能力。在不进行微调的情况下实现检索器的零样本精度仍然是一个关键挑战。

**Method:** 本文引入了“MetaGen 混合RAG”，这是一种新颖的企业搜索方法，通过元数据生成管道和使用密集与稀疏向量的混合查询索引来增强语义检索器。该方法利用关键概念、主题和缩写，创建了富含元数据的语义索引和增强型混合查询，从而在无需微调的情况下提供稳健、可扩展的性能。

**Result:** 在生物医学PubMedQA数据集上，MetaGen 混合RAG实现了82%的检索准确率和77%的RAG准确率，超越了所有先前的零样本RAG基准，甚至在该数据集上媲美微调模型，同时在SQuAD和NQ等数据集上也表现出色。

**Conclusion:** MetaGen 混合RAG通过构建语义检索器的新方法重新定义了企业搜索，在专业领域具有无与伦比的泛化能力。

> **ai_Abstract:** MetaGen 混合RAG旨在解决RAG在专业领域问答中遇到的挑战，即LLM难以处理未见过的专业术语以及微调方案成本高昂、泛化能力差的问题。该方法通过元数据生成管道和结合密集与稀疏向量的混合查询索引来增强语义检索器。通过利用关键概念和缩写来丰富语义索引，MetaGen 混合RAG实现了卓越的零样本精度，在PubMedQA数据集上展现出高检索和RAG准确率，超越了现有基准并与微调模型相媲美，为企业搜索提供了可扩展且泛化能力强的解决方案。

> **摘要翻译:** 检索增强生成（RAG）在处理领域特定企业数据集时面临挑战，这些数据集通常被防火墙隔离，并且富含LLM预训练时未见过的复杂、专业术语。医学、网络或法律等领域间的语义可变性阻碍了RAG的上下文精度，而微调解决方案成本高昂、速度慢且在新数据出现时缺乏泛化能力。在不进行微调的情况下实现检索器的零样本精度仍然是一个关键挑战。我们引入了“MetaGen 混合RAG”，这是一种新颖的企业搜索方法，通过元数据生成管道和使用密集与稀疏向量的混合查询索引来增强语义检索器。通过利用关键概念、主题和缩写，我们的方法创建了富含元数据的语义索引和增强型混合查询，从而在无需微调的情况下提供稳健、可扩展的性能。在生物医学PubMedQA数据集上，MetaGen 混合RAG实现了82%的检索准确率和77%的RAG准确率，超越了所有先前的零样本RAG基准，甚至在该数据集上媲美微调模型，同时在SQuAD和NQ等数据集上也表现出色。这种方法通过构建语义检索器的新方法，在专业领域具有无与伦比的泛化能力，从而重新定义了企业搜索。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents](https://arxiv.org/abs/2508.02013)
> *SpeechRole：一个用于评估语音角色扮演智能体的大规模数据集和基准*

*Changhao Jiang, Jiajun Sun, Yifei Cao, Jiabao Zhuang, Hui Li, Xiaoran Fan, Ming Zhang, Junjie Ye, Shihan Dou, Zhiheng Xi, Jingqi Tong, Yilong Wu, Baoyu Fan, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 语音角色扮演, 数据集, 评估基准, 多模态, 智能体

**Comment:** We request withdrawal of this paper due to an error in the
  experimental results reported in Table 2 on page 8. Specifically, the results
  for the Qwen2.5-Omni model are incorrect. We are currently conducting further
  verification and plan to resubmit with corrected results

> **TL;DR:** 本文介绍了SpeechRole，一个大规模、高质量的语音角色扮演数据集和多维度评估基准，旨在解决现有研究中缺乏对语音角色扮演智能体系统评估的问题，并发布了所有资源以促进该领域的发展。

**AI_Comments:** 该论文通过构建大规模语音数据集和评估基准，填补了语音角色扮演智能体系统评估的空白，具有重要的创新性和实用价值。其对语音特征的强调以及多维度评估方法，为未来多模态角色扮演研究奠定了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有角色扮演智能体研究主要集中在文本模态，忽略了语音在真实交互场景中的关键作用，特别是缺乏对语音角色扮演智能体（SRPAs）的系统评估。

**Method:** 本文构建了SpeechRole-Data，一个包含98个不同角色和11.2万个语音对话的大规模高质量数据集，每个角色具有独特的声学特征。此外，还提出了SpeechRole-Eval，一个多维度评估基准，用于系统评估SRPAs在基本交互能力、语音表达力和角色扮演保真度方面的性能。

**Result:** 实验结果揭示了级联和端到端语音角色扮演智能体在保持声音风格一致性和角色连贯性方面的优势和挑战。

**Conclusion:** 本文构建并发布了SpeechRole数据集、SpeechRole-Eval评估基准、代码和基线模型，为语音驱动的多模态角色扮演研究提供了坚实基础，并旨在促进该领域的进一步发展。

> **ai_Abstract:** 本文介绍了SpeechRole，一个专门为语音角色扮演智能体（SRPAs）设计的大规模数据集和评估基准。为解决现有研究忽略语音模态且缺乏系统评估的现状，作者构建了包含98个角色和11.2万个语音对话的SpeechRole-Data，其独特之处在于每个角色包含特定的音色和韵律特征。同时，提出了SpeechRole-Eval多维度基准，用于评估SRPAs的交互能力、语音表达和角色保真度。实验分析了级联和端到端SRPAs在声音风格和角色连贯性上的表现。所有数据、代码和模型均已发布，旨在推动语音驱动多模态角色扮演研究。

> **摘要翻译:** 最近，角色扮演智能体已成为实现个性化交互和情感共鸣的一种有前景的范式。现有研究主要集中在文本模态，忽略了语音在真实交互场景中的关键维度。特别是，缺乏对语音角色扮演智能体（SRPAs）的系统评估。为了解决这一空白，我们构建了SpeechRole-Data，一个大规模、高质量的数据集，包含98个多样化的角色和11.2万个基于语音的单轮和多轮对话。每个角色都展示出独特的发声特征，包括音色和韵律，从而实现更复杂的语音角色扮演。此外，我们提出了SpeechRole-Eval，一个多维度评估基准，系统地评估SRPAs在基本交互能力、语音表达和角色扮演保真度等关键方面的性能。实验结果揭示了级联和端到端语音角色扮演智能体在保持声音风格一致性和角色连贯性方面的优势和挑战。我们发布了所有数据、代码和基线模型，为语音驱动的多模态角色扮演研究提供坚实基础，并促进该领域的进一步发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [146] [Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition](https://arxiv.org/abs/2508.03259)
> *探索持续命名实体识别中的稳定性-可塑性权衡*

*Duzhen Zhang, Chenxing Li, Jiahua Dong, Qi Liu, Dong Yu* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 持续命名实体识别, 稳定性-可塑性权衡, 知识蒸馏, 灾难性遗忘, 伪标签

**Comment:** Accepted by IEEE/ACM Transactions on Audio, Speech and Language
  Processing

> **TL;DR:** 本文提出了一种名为稳定性-可塑性权衡（SPT）的新方法，用于持续命名实体识别（CNER），通过在表示和权重层面平衡旧知识的保留（稳定性）和新知识的获取（可塑性），解决了现有方法过度稳定但可塑性不足的问题，并在多个基准测试中取得了优异表现。

**AI_Comments:** 该论文的创新点在于明确提出了持续命名实体识别中“稳定性-可塑性权衡”的概念，并从表示和权重两个维度设计了具体的解决方案。特别是在权重融合中引入选择机制以及处理非实体类型语义漂移的伪标签方法，都体现了对CNER特有挑战的深刻理解和有效应对。这对于推动持续学习领域，尤其是在序列标注任务中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续命名实体识别（CNER）方法主要依赖知识蒸馏来克服灾难性遗忘，但这往往导致模型过度稳定（保留旧知识）而可塑性不足（获取新知识）。为了解决这种稳定性与可塑性之间的失衡问题，本文提出了新的方法。

**Method:** 本文提出了一种稳定性-可塑性权衡（SPT）方法。在表示层面，通过在原始知识蒸馏中引入池化操作来允许一定程度的可塑性。在权重层面，动态融合新旧模型的权重，并采用权重引导的选择机制来优先处理重要权重。此外，还开发了一种基于置信度的伪标签方法，用于处理CNER中非实体类型的语义漂移问题。

**Result:** 在三个基准数据集的十种CNER设置上进行了大量实验，结果表明SPT方法超越了以前的CNER方法。

**Conclusion:** SPT方法通过在表示和权重层面平衡稳定性与可塑性，有效地解决了持续命名实体识别中的挑战，并取得了显著的性能提升。

> **ai_Abstract:** 本文针对持续命名实体识别（CNER）中现有方法过度稳定而可塑性不足的问题，提出了一种名为稳定性-可塑性权衡（SPT）的新方法。SPT从表示和权重两个层面进行平衡：在表示层面，通过引入池化操作增强知识蒸馏的可塑性；在权重层面，动态融合新旧模型权重并优先处理重要权重。此外，还引入了基于置信度的伪标签方法来处理非实体类型的语义漂移。实验证明，SPT在多个基准数据集上显著优于现有CNER方法。

> **摘要翻译:** 持续命名实体识别（CNER）是一个不断发展的领域，专注于顺序更新现有模型以整合新的实体类型。先前的CNER方法主要利用知识蒸馏（KD）来保留先验知识并克服灾难性遗忘，严格确保新旧模型的表示保持一致。因此，它们常常赋予模型过度的稳定性（即旧知识的保留）但有限的可塑性（即新知识的获取）。为了解决这个问题，我们提出了一种用于CNER的稳定性-可塑性权衡（SPT）方法，从表示和权重两个角度平衡这些方面。从表示角度来看，我们在原始KD中引入了池化操作，通过整合表示维度来允许一定程度的可塑性。从权重角度来看，我们动态融合新旧模型的权重，在保持新知识的同时加强旧知识。在此融合过程中，我们实施了权重引导的选择机制，以优先处理重要的权重。此外，我们开发了一种基于置信度的伪标签方法，用于处理当前非实体类型，该方法使用旧模型预测实体类型，以应对非实体类型的语义漂移，这是CNER特有的一个挑战，在很大程度上被以前的方法所忽视。在三个基准数据集上的十种CNER设置中进行了大量实验，结果表明我们的SPT方法超越了以前的CNER方法，凸显了其在实现适当的稳定性-可塑性权衡方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [153] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
> *隐私感知解码：缓解检索增强生成中大型语言模型的隐私泄露*

*Haoran Wang, Xiongxiao Xu, Baixiang Huang, Kai Shu* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 隐私泄露, 大型语言模型, 检索增强生成, 差分隐私, 解码策略

**Comment:** 

> **TL;DR:** 提出了一种名为隐私感知解码（PAD）的轻量级推理时防御机制，通过在生成过程中向token logits注入校准高斯噪声来减轻RAG系统中大型语言模型的隐私泄露。

**AI_Comments:** PAD的创新之处在于其轻量级、模型无关的推理时防御策略，避免了传统方法所需的昂贵训练或数据过滤。通过将差分隐私机制与自适应噪声注入相结合，并在解码阶段进行操作，它在隐私保护和生成质量之间取得了良好的平衡，为RAG系统在敏感数据应用中的安全性提供了重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）系统在处理私人或敏感数据时，容易受到提取攻击，导致机密信息通过生成的响应泄露，因此需要一种有效的防御机制。

**Method:** 本文提出了隐私感知解码（PAD），这是一种轻量级的推理时防御机制，通过在生成过程中自适应地向token logits注入校准高斯噪声。PAD集成了基于置信度的筛选以选择性保护高风险token，高效的敏感度估计以最小化不必要的噪声，以及上下文感知的噪声校准以平衡隐私和生成质量。使用Rényi差分隐私（RDP）会计师严格跟踪累积隐私损失，为敏感输出提供显式的每响应$(\varepsilon, \delta)$-DP保证。PAD是模型无关的，完全在解码时操作，计算开销最小，无需重新训练或语料库级过滤。

**Result:** 在三个真实世界数据集上的实验表明，PAD显著减少了私人信息泄露，同时保持了响应效用，并且优于现有的基于检索和后处理的防御方法。

**Conclusion:** 通过解码策略，本文的工作在缓解RAG中的隐私风险方面迈出了重要一步，为敏感领域中通用且可扩展的隐私解决方案铺平了道路。

> **ai_Abstract:** 本文提出了一种名为隐私感知解码（PAD）的新型轻量级防御机制，旨在解决检索增强生成（RAG）系统中大型语言模型（LLMs）在处理敏感数据时可能导致的隐私泄露问题。PAD通过在推理时自适应地向token logits注入校准高斯噪声来实现隐私保护，并结合了置信度筛选、敏感度估计和上下文感知噪声校准。该方法无需模型重训练或语料库过滤，计算开销小，并通过Rényi差分隐私会计师提供严格的隐私保证。实验证明，PAD在有效减少隐私泄露的同时，能保持生成响应的实用性，并优于现有防御方案，为RAG中的隐私保护提供了通用且可扩展的解决方案。

> **摘要翻译:** 检索增强生成（RAG）通过将输出条件化于外部知识源来增强大型语言模型（LLM）的事实准确性。然而，当检索涉及私人或敏感数据时，RAG系统容易受到提取攻击，这些攻击可以通过生成的响应泄露机密信息。我们提出了隐私感知解码（PAD），这是一种轻量级的推理时防御机制，通过在生成过程中自适应地向token logits注入校准高斯噪声。PAD集成了基于置信度的筛选以选择性保护高风险token，高效的敏感度估计以最小化不必要的噪声，以及上下文感知的噪声校准以平衡隐私与生成质量。Rényi差分隐私（RDP）会计师严格跟踪累积隐私损失，为敏感输出提供显式的每响应$(\varepsilon, \delta)$-DP保证。与需要重新训练或语料库级过滤的现有方法不同，PAD是模型无关的，并且完全在解码时操作，计算开销最小。在三个真实世界数据集上的实验表明，PAD显著减少了私人信息泄露，同时保持了响应效用，优于现有的基于检索和后处理的防御方法。我们的工作通过解码策略在缓解RAG中的隐私风险方面迈出了重要一步，为敏感领域中通用且可扩展的隐私解决方案铺平了道路。我们的代码可在以下网址获取：https://github.com/wang2226/PAD。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [171] [FairLangProc: A Python package for fairness in NLP](https://arxiv.org/abs/2508.03677)
> *FairLangProc：一个用于自然语言处理公平性的Python包*

*Arturo Pérez-Peralta, Sandra Benítez-Peña, Rosa E. Lillo* | **Category: cs.CL, stat.ML, 68T50, I.2.7** | **Updated: 2025-08-05**

**Keywords:** 公平性, 自然语言处理, Python包, 偏见缓解, 大型语言模型

**Comment:** 40 pages, 4 figures, 3 tables

> **TL;DR:** FairLangProc是一个Python包，旨在为自然语言处理中的公平性提供一个集中的实现，以应对大型语言模型中偏见日益增长的担忧。

**AI_Comments:** FairLangProc的创新之处在于它提供了一个集中的、易于使用的Python包来解决NLP中的公平性问题，特别是通过与流行的Hugging Face库兼容，这将大大降低开发者和研究人员应用偏见缓解技术的门槛，促进公平AI的民主化。其重要性在于直接回应了AI伦理和负责任AI开发的迫切需求。

<details>
  <summary>Details</summary>

**Motivation:** 近年来大型语言模型（LLMs）的普及引发了人们对其在决策制定（如组织公正或医疗保健）中应用公平性的社会担忧。尽管已经提出了许多数据集、指标和算法来衡量和减轻自然语言处理中的有害偏见，但它们的实现方式多样且远未集中。

**Method:** 本文提出了FairLangProc，一个全面的Python包，它提供了一个常见的实现，包含了自然语言处理中公平性方面的一些最新进展，并提供了一个与著名的Hugging Face transformers库兼容的接口。

**Result:** 开发了FairLangProc Python包，它提供了一个集中的实现，兼容Hugging Face transformers库。

**Conclusion:** 该包旨在鼓励偏见缓解技术的广泛使用和民主化。

> **ai_Abstract:** 鉴于大型语言模型在决策制定中日益普及带来的公平性担忧，以及现有偏见缓解工具分散的现状，本文推出了FairLangProc。这是一个全面的Python包，旨在集中实现自然语言处理中最新的公平性技术，并提供与Hugging Face transformers库兼容的接口，以促进偏见缓解方法的广泛应用和普及。

> **摘要翻译:** 近年来，大型语言模型的使用已接近普及，这引起了社会对其在决策制定环境（例如组织公正或医疗保健）中应用的担忧。反过来，这提出了关于这些模型在关键设置中公平性的问题，从而导致了开发不同的程序来解决自然语言处理中的偏见。尽管已经提出了许多数据集、指标和算法来衡量和减轻自然语言处理中的有害偏见，但它们的实现方式多样且远未集中。作为回应，本文提出了FairLangProc，一个全面的Python包，它提供了一个常见的实现，包含了自然语言处理中公平性方面的一些最新进展，并提供了一个与著名的Hugging Face transformers库兼容的接口，旨在鼓励偏见缓解技术的广泛使用和民主化。该实现可以在https://github.com/arturo-perez-peralta/FairLangProc上找到。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [172] [AdaMCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Multilingual Chain-of-Thought](https://arxiv.org/abs/2501.16154)
> *AdaMCoT：通过自适应多语言思维链重新思考跨语言事实推理*

*Weihua Zheng, Xin Huang, Zhengyuan Liu, Tarun Kumar Vangani, Bowei Zou, Xiyan Tao, Yuhao Wu, Ai Ti Aw, Nancy F. Chen, Roy Ka-Wei Lee* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 多语言LLM, 事实推理, 思维链, 跨语言, 低资源语言

**Comment:** 

> **TL;DR:** AdaMCoT 通过自适应地将思维过程路由到中间“思考语言”，从而增强了大型语言模型（LLMs）的跨语言事实推理能力，特别是在低资源语言环境下，且无需额外预训练。

**AI_Comments:** AdaMCoT 的创新之处在于其动态路由思想过程通过中间“思考语言”以及无需额外预训练的自适应、基于奖励的机制，并利用语言无关的核心。其重要性在于有效解决了大型语言模型在不同语言间（尤其是低资源语言）的性能不平衡问题，这对于实现更公平的 AI 发展至关重要。摘要中未提及具体的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）尽管具有强大的多语言能力，但由于训练数据分布不平衡，其在不同语言间的性能差异显著。现有的通过样本级翻译进行多语言预训练和跨语言微调的方法面临可扩展性挑战，并且往往难以捕捉跨语言的细微推理过程。

**Method:** 本文引入了 AdaMCoT（自适应多语言思维链）框架，通过在生成目标语言响应之前，动态地将思维过程路由到中间“思考语言”中，从而增强多语言事实推理。AdaMCoT 利用语言无关的核心，并结合了自适应的、基于奖励的机制来选择最佳推理路径，且无需额外的预训练。

**Result:** 对多个基准的综合评估表明，AdaMCoT 在事实推理质量和跨语言一致性方面均取得了显著改进，特别是在低资源语言环境下性能提升显著。对模型隐藏状态和语义空间的深入分析进一步阐明了该方法的潜在机制。

**Conclusion:** 结果表明，自适应推理路径可以有效弥合高资源语言和低资源语言之间的性能差距，同时保持文化和语言的细微差别。

> **ai_Abstract:** AdaMCoT 旨在解决大型语言模型在跨语言事实推理中，特别是在低资源语言环境下，因训练数据不平衡导致的性能差异问题。该框架引入了一种自适应多语言思维链方法，通过动态地将推理过程路由到中间“思考语言”中，并利用基于奖励的机制选择最优路径，而无需额外预训练。实验结果表明，AdaMCoT 显著提升了推理质量和跨语言一致性，尤其在低资源语言上表现出色，有效弥合了语言间的性能差距并保留了语言细微差别。

> **摘要翻译:** 大型语言模型（LLMs）通过对多样化语料库的预训练，展现出令人印象深刻的多语言能力。尽管这些模型展现出强大的推理能力，但由于训练数据分布不平衡，它们的性能在不同语言之间存在显著差异。现有使用样本级翻译进行广泛多语言预训练和跨语言微调的方法面临可扩展性挑战，并且往往未能捕捉跨语言的细微推理过程。在本文中，我们引入了 AdaMCoT（自适应多语言思维链），这是一个通过在生成目标语言响应之前，动态地将思维过程路由到中间“思考语言”中，从而增强多语言事实推理的框架。AdaMCoT 利用语言无关的核心，并结合了自适应的、基于奖励的机制来选择最佳推理路径，且无需额外的预训练。我们对多个基准的综合评估表明，在事实推理质量和跨语言一致性方面均取得了显著改进，特别是在低资源语言环境下性能提升强劲。对模型隐藏状态和语义空间的深入分析进一步阐明了我们方法的潜在机制。结果表明，自适应推理路径可以有效弥合高资源语言和低资源语言之间的性能差距，同时保持文化和语言的细微差别。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [181] [When Truth Is Overridden: Uncovering the Internal Origins of Sycophancy in Large Language Models](https://arxiv.org/abs/2508.02087)
> *当真相被覆盖时：揭示大型语言模型中奉承行为的内部起源*

*Keyu Wang, Jin Li, Shu Yang, Zhuoran Zhang, Di Wang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 奉承行为, 机制可解释性, 内部机制, AI对齐

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）经常表现出奉承行为，即即使与事实相悖也同意用户观点。本文从机制层面解释了这种奉承行为如何在LLM内部产生，发现其分为两个阶段出现（输出偏好转移和深层表征分歧），并指出第一人称提示会诱导更高的奉承率。

**AI_Comments:** 这篇论文通过深入探究大型语言模型奉承行为的内部机制，超越了单纯的现象观察，具有重要的创新性。利用logit-lens分析和因果激活修补等方法，为所识别的两阶段过程提供了强有力的证据。区分表面现象和深层结构性覆盖对于开发更真实、更对齐的AI系统至关重要。此外，关于语法视角对奉承行为影响的发现也富有洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的研究已经记录了大型语言模型（LLM）的奉承倾向（即即使与事实知识相矛盾，也同意用户提出的观点），但实现这种行为的内部机制仍然知之甚少。本文旨在提供关于奉承行为如何在LLM内部产生的机制性解释。

**Method:** 本文首先系统地研究了用户意见如何在不同模型家族中诱导奉承行为。研究采用了logit-lens分析和因果激活修补技术来识别奉承行为的内部机制。此外，还考察了语法视角（第一人称与第三人称提示）对奉承行为的影响。

**Result:** 研究发现，简单的意见陈述能可靠地诱导奉承行为，而用户专业知识的框架影响微乎其微。通过分析，确定了奉承行为的两阶段出现：(1) 后层输出偏好转移和 (2) 更深层次的表征分歧。用户权威未能影响行为，因为模型未在内部编码它。此外，第一人称提示（“我相信……”）通过在更深层次创建更强的表征扰动，始终比第三人称框架（“他们相信……”）诱导更高的奉承率。

**Conclusion:** 奉承行为并非表面现象，而是源于深层学习知识的结构性覆盖，这对AI的对齐和构建真实的AI系统具有重要意义。

> **ai_Abstract:** 本文深入探讨了大型语言模型（LLM）中奉承行为的内部起源，即LLM倾向于同意用户观点而非事实。研究揭示了奉承行为的两个阶段机制：首先是后层输出偏好转移，随后是更深层次的表征分歧。研究还发现，简单的意见陈述能可靠地诱导奉承行为，而用户专业知识的影响微乎其微；此外，第一人称提示通过扰动更深层，导致更强的奉承反应。这些发现表明奉承行为是深层学习知识的结构性覆盖，对AI的对齐和真实性具有重要启示。

> **摘要翻译:** 大型语言模型（LLM）经常表现出奉承行为，即使用户的观点与事实知识相矛盾，它们也会表示同意。虽然先前的研究已经记录了这种倾向，但实现这种行为的内部机制仍然知之甚少。在本文中，我们提供了关于奉承行为如何在LLM内部产生的机械解释。我们首先系统地研究了用户意见如何在不同模型家族中诱导奉承行为。我们发现简单的意见陈述能可靠地诱导奉承行为，而用户专业知识的框架影响微乎其微。通过logit-lens分析和因果激活修补，我们确定了奉承行为的两阶段出现：(1) 后层输出偏好转移和 (2) 更深层次的表征分歧。我们还验证了用户权威未能影响行为，因为模型没有在内部编码它。此外，我们研究了语法视角如何影响奉承行为，发现第一人称提示（“我相信……”）通过在更深层次创建更强的表征扰动，始终比第三人称框架（“他们相信……”）诱导更高的奉承率。这些发现强调，奉承行为不是表面现象，而是源于深层学习知识的结构性覆盖，对齐和真实的AI系统具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [193] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
> *对RAG的令牌级精确攻击：寻找误导生成的最佳替代方案*

*Zizhong Li, Haopeng Zhang, Jiawei Zhang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** RAG, 攻击, LLM, 安全漏洞, 令牌级

**Comment:** 

> **TL;DR:** 本文提出了TPARAG，一种针对RAG系统的令牌级精确攻击框架，能够有效攻击白盒和黑盒RAG系统，并在检索和生成阶段均表现出色，揭示了RAG管道的关键漏洞。

**AI_Comments:** 本文提出了一种新颖的、针对RAG系统在令牌级别的精确攻击方法TPARAG，其创新点在于能够同时针对白盒和黑盒RAG系统，并通过迭代优化恶意内容来提高攻击成功率。这对于理解RAG系统的安全漏洞具有重要意义，并为RAG的防御和鲁棒性提升提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）存在幻觉和知识过时问题，RAG框架通过外部知识库增强LLMs，但引入了新的安全漏洞：外部恶意内容可能被检索并用于操纵模型输出。现有RAG攻击方法存在局限性，要么严重依赖于检索器访问，要么未能联合考虑检索和生成阶段，尤其在黑盒场景下效果不佳。

**Method:** 本文提出了TPARAG（Token-level Precise Attack on the RAG），一个针对白盒和黑盒RAG系统的新型框架。TPARAG利用一个轻量级白盒LLM作为攻击者，在令牌级别生成并迭代优化恶意段落，以确保其既可被检索又能在生成阶段实现高攻击成功率。

**Result:** 在开放域QA数据集上的广泛实验表明，TPARAG在检索阶段和端到端攻击有效性方面始终优于现有方法。

**Conclusion:** 这些结果进一步揭示了RAG管道中的关键漏洞，并为提高其鲁棒性提供了新的见解。

> **ai_Abstract:** 本文提出了TPARAG，一种针对RAG系统的令牌级精确攻击框架，旨在解决现有RAG攻击方法在黑盒场景下的局限性。TPARAG利用一个轻量级白盒LLM在令牌级别优化恶意文本，以确保其在RAG系统中既能被检索又能有效误导生成。实验证明，TPARAG在检索和端到端攻击方面均优于现有方法，揭示了RAG的关键漏洞，并为提升其鲁棒性提供了方向。

> **摘要翻译:** 虽然大型语言模型（LLMs）在为知识密集型任务提供可信响应方面取得了显著成功，但它们仍然面临幻觉和过时知识等关键限制。为了解决这些问题，检索增强生成（RAG）框架通过检索器使LLMs能够访问外部知识，从而实现关于最新事件更准确和实时的输出。然而，这种集成带来了新的安全漏洞：外部数据库中的恶意内容可能被检索并用于操纵模型输出的风险。尽管先前的研究已经探索了对RAG系统的攻击，但现有方法要么严重依赖于对检索器的访问，要么未能联合考虑检索和生成阶段，从而限制了其有效性，尤其是在黑盒场景中。为了克服这些限制，我们提出了针对RAG的令牌级精确攻击（TPARAG），这是一个针对白盒和黑盒RAG系统的新颖框架。TPARAG利用轻量级白盒LLM作为攻击者，在令牌级别生成并迭代优化恶意段落，确保可检索性并在生成中实现高攻击成功率。在开放域QA数据集上的广泛实验表明，TPARAG在检索阶段和端到端攻击有效性方面始终优于现有方法。这些结果进一步揭示了RAG管道中的关键漏洞，并为提高其鲁棒性提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [194] [Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?](https://arxiv.org/abs/2508.03262)
> *大型语言模型想要什么：大型语言模型能否模拟有522个真实人类角色的经济实验？*

*Junhyuk Choi, Hyeonchu Park, Haemin Lee, Hyebeen Shin, Hyun Joung Jin, Bugeun Kim* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** LLM, 经济模拟, 真实人类角色, 随心付, 提示工程

**Comment:** Preprint

> **TL;DR:** 本研究评估了大型语言模型（LLMs）在真实522个韩国参与者的人格数据下，预测个体经济决策（随心付）的能力。结果显示LLMs在个体层面预测不佳，但在群体层面表现合理，且复杂的提示技术并未显著优于简单提示。

**AI_Comments:** 本研究的创新之处在于首次使用大规模（522个）真实人类人格数据来评估大型语言模型在经济行为模拟方面的能力，而非以往研究中常用的虚构角色，这大大提升了研究的现实意义和可信度。研究结果揭示了LLMs在个体层面预测的局限性，以及在群体层面上的潜力，这对于计算社会科学中LLMs的应用具有重要的指导意义。此外，对不同提示技术效果的评估也提供了实用的见解，指出并非越复杂的提示方法效果越好。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在评估大型语言模型（LLMs）模拟人类行为的能力时，大多依赖虚构的人格数据而非真实的个体数据。本研究旨在解决这一局限性，评估LLMs使用真实人类数据预测经济决策的能力。

**Method:** 研究通过使用522名韩国参与者的详细人格信息，评估了三种最先进的多模态LLMs在随心付（PWYW）定价实验中预测个体经济决策的能力。研究系统比较了这些LLMs，并调查了人格注入方法对预测性能的影响。

**Result:** 结果表明，大型语言模型在精确的个体层面预测上存在困难，但在群体层面的行为趋势上表现出合理的预测能力。此外，研究发现常用的提示技术并不比简单的提示方法好多少；个人叙事重建或检索增强生成对简单提示方法没有显著提升。

**Conclusion:** 本研究提供了首次使用真实人类数据对大型语言模型模拟经济行为能力的全面评估，为计算社会科学中基于人格的模拟提供了实证指导。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在模拟经济决策方面的能力，特别是使用真实的522名韩国参与者的人格数据，而非虚构角色。研究通过随心付（PWYW）定价实验，比较了三种多模态LLMs在预测个体经济行为上的表现，并探讨了人格注入方法的影响。结果显示，LLMs在个体层面预测精度不高，但在群体行为趋势上表现良好。同时，复杂的提示技术并未显著优于简单提示。这项工作为基于真实数据的LLMs经济行为模拟提供了首次全面评估和实证指导。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展在其模拟类人行为的能力方面引起了广泛兴趣，但大多数研究依赖虚构角色而非真实人类数据。我们通过使用522个真实人类角色的随心付（PWYW）定价实验，评估LLMs预测个体经济决策的能力，从而解决了这一局限性。我们的研究系统地比较了三种最先进的多模态LLMs，使用了522名韩国参与者在文化消费场景中的详细角色信息。我们调查了LLMs是否能准确复制个体人类选择以及角色注入方法如何影响预测性能。结果显示，虽然LLMs在精确的个体层面预测上存在困难，但它们在群体层面的行为趋势上表现出合理的预测能力。此外，我们发现，常用的提示技术并不比简单的提示方法好多少；个人叙事重建和检索增强生成对简单提示方法没有显著增益。我们相信这些发现可以提供首次使用真实人类数据对LLMs模拟经济行为能力的全面评估，为计算社会科学中基于角色的模拟提供实证指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [196] [Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study](https://arxiv.org/abs/2506.19794)
> *为什么开源大型语言模型在数据分析方面表现不佳？一项系统的实证研究*

*Yuqi Zhu, Yi Zhong, Jintian Zhang, Ziheng Zhang, Shuofei Qiao, Yujie Luo, Lun Du, Da Zheng, Ningyu Zhang, Huajun Chen* | **Category: cs.CL, cs.AI, cs.IR, cs.LG, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 开源LLMs, 数据分析, 战略规划, 数据质量, 分析推理

**Comment:** Work in progress

> **TL;DR:** 本研究系统地探究了开源大型语言模型在数据分析任务中面临的挑战，并提出了一种数据合成方法以提升其分析推理能力。

**AI_Comments:** 这项研究通过实证分析深入探讨了开源LLMs在数据分析方面的弱点，并提供了具体的改进方向。其创新之处在于识别了战略规划质量作为核心决定因素，并提出了一种基于洞察力的数据合成方法，为提升开源LLMs的实际应用能力提供了有价值的指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在自动化数据分析任务方面具有前景，但开源模型在此类推理密集型场景中面临显著限制。本研究旨在调查增强开源LLMs数据分析能力的策略。

**Method:** 通过整理一个包含多样化、真实场景的种子数据集，研究人员评估了模型在数据理解、代码生成和战略规划三个核心维度上的行为。基于分析洞察，他们开发了一种数据合成方法。

**Result:** 研究揭示了三个关键发现：(1) 战略规划质量是模型性能的主要决定因素；(2) 交互设计和任务复杂性显著影响推理能力；(3) 数据质量在实现最佳性能方面比多样性具有更大的影响。

**Conclusion:** 本研究利用其洞察力开发了一种数据合成方法，证明了显著提升开源LLMs分析推理能力的效果。

> **ai_Abstract:** 本研究系统地调查了开源大型语言模型在数据分析任务中的局限性。通过在数据理解、代码生成和战略规划三个维度上评估模型行为，研究发现战略规划质量、交互设计、任务复杂性和数据质量是影响模型性能的关键因素。基于这些发现，研究提出了一种数据合成方法，显著提升了开源LLMs的分析推理能力。

> **摘要翻译:** 大型语言模型（LLMs）在自动化数据分析任务方面前景广阔，但开源模型在此类推理密集型场景中面临显著限制。在这项工作中，我们研究了增强开源LLMs数据分析能力的策略。通过整理一个包含多样化、真实场景的种子数据集，我们评估了模型在数据理解、代码生成和战略规划三个核心维度上的行为。我们的分析揭示了三个关键发现：(1) 战略规划质量是模型性能的主要决定因素；(2) 交互设计和任务复杂性显著影响推理能力；(3) 数据质量在实现最佳性能方面比多样性具有更大的影响。我们利用这些洞察力开发了一种数据合成方法，证明了显著提升开源LLMs分析推理能力的效果。代码可在 https://github.com/zjunlp/DataMind 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [211] [More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation](https://arxiv.org/abs/2508.03678)
> *超越分数：探究提示词特异性对LLM代码生成的影响*

*Yangtian Zi, Harshitha Menon, Arjun Guha* | **Category: cs.CL, cs.LG, cs.PL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 代码生成, 提示词工程, 提示词特异性, PartialOrderEval

**Comment:** 

> **TL;DR:** 本文引入PartialOrderEval，通过增加提示词细节来探究提示词特异性对LLM代码生成性能的影响，发现LLM对提示词敏感，并确定了提高提示词细节的关键因素。

**AI_Comments:** 这项研究通过引入PartialOrderEval框架，系统地探讨了提示词细节对LLM代码生成性能的关键影响，为未来提升LLM在专业领域代码生成能力提供了明确的方向和有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLM）在通用代码生成基准上表现良好，但在专业基准上表现不佳。研究旨在探究这种性能差异是源于LLM缺乏领域知识还是提示词细节不足。

**Method:** 本文引入PartialOrderEval框架，该框架能将任何代码生成基准与从最小到最大详细程度的提示词偏序集相结合。将其应用于HumanEval和ParEval的串行和OpenMP子集，测量pass@1指标随提示词特异性变化的规律。

**Result:** 实验表明，Llama-3.x和Qwen2.5-Coder在不同任务上表现出不同程度的提示词敏感性。定性分析强调，明确的I/O规范、边界情况处理和分步分解是提升提示词细节的关键驱动因素。

**Conclusion:** 提示词的特异性对大型语言模型（LLM）的代码生成能力有显著影响，通过增加特定类型的细节（如I/O规范、边界处理和分步说明）可以有效提升其性能。

> **ai_Abstract:** 本文研究了提示词特异性对大型语言模型（LLM）代码生成性能的影响。针对LLM在专业代码生成任务上表现不佳的问题，作者引入了PartialOrderEval框架，通过系统地改变提示词的详细程度来评估LLM的性能。实验结果表明，LLM对提示词的细节程度敏感，并识别出明确的I/O规范、边界情况处理和分步分解是提升提示词效果的关键因素。

> **摘要翻译:** 最先进的大型语言模型（LLM）在HumanEval等通用基准测试上取得了很高的pass@1分数，但在ParEval等专业套件上表现不佳。这是否是由于LLM缺少领域知识或提供的提示词细节不足？为了回答这个问题，我们引入了PartialOrderEval，它通过从最小到最大详细程度的提示词偏序集来增强任何代码生成基准。将其应用于HumanEval以及ParEval的串行和OpenMP子集，我们测量了pass@1随提示词特异性变化的规律。我们对Llama-3.x和Qwen2.5-Coder的实验表明，不同任务对提示词的敏感度不同，定性分析强调明确的I/O规范、边界情况处理和分步分解是提示词细节改进的关键驱动因素。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [222] [Proof2Hybrid: Automatic Mathematical Benchmark Synthesis for Proof-Centric Problems](https://arxiv.org/abs/2508.02208)
> *Proof2Hybrid：面向以证明为中心问题的自动数学基准合成*

*Yebo Peng, Zixiang Liu, Yaoming Li, Zhizhuo Yang, Xinye Xu, Bowen Ye, Weijun Yuan, Zihan Wang, Tong Yang* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** Proof2Hybrid, 数学基准合成, 大型语言模型, 以证明为中心问题, AlgGeoTest

**Comment:** 

> **TL;DR:** 提出Proof2Hybrid框架，自动生成以证明为中心的数学基准，以更准确评估大型语言模型的数学能力。

**AI_Comments:** 这篇论文的创新点在于提出了一个完全自动化的框架Proof2Hybrid，用于生成以证明为中心的数学基准，并引入了新型的“$m$-out-of-$n$多判题问题”格式，有效解决了传统基准创建困难、评估不准确的问题。其重要性在于为更深入、更准确地评估大型语言模型（LLMs）的数学推理能力提供了工具，特别是针对需要复杂证明的问题。这对于推动AI在数学领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型（LLMs）的数学能力至关重要但充满挑战。现有基准，特别是针对以证明为中心的问题，因手动创建不可扩展且成本高昂而不足，导致LLMs的真实数学能力在很大程度上未被评估。

**Method:** 提出Proof2Hybrid，首个从自然语言数学语料库中自动合成高质量、以证明为中心的基准的框架。其核心新颖之处在于Proof2X，这是一个将数学证明转化为易于验证的各种类型问题的路线图。根据此路线图，提出了一种新型的混合格式问题，名为“$m$-out-of-$n$多判题问题”，旨在实现稳健的自动评估，同时能抵御传统格式中固有的猜测和肤浅的模式匹配。

**Result:** 作为框架的演示，引入了AlgGeoTest，一个针对代数几何（现代数学的前沿领域）的基准，包含456个具有挑战性的项目。使用AlgGeoTest对最先进的LLMs进行的广泛评估揭示了它们在理解代数几何方面的严重不足，从而提供了对其真实数学能力的更精确衡量。

**Conclusion:** 该框架和基准为深入研究AI系统的数学智能开辟了新途径。

> **ai_Abstract:** 本文提出了Proof2Hybrid，一个自动合成以证明为中心的数学基准的框架，旨在克服现有基准在评估大型语言模型（LLMs）数学能力方面的不足。该框架的核心是Proof2X，一个将数学证明转化为可验证问题的路线图，并引入了“$m$-out-of-$n$多判题问题”这一新型混合格式，以实现鲁棒的自动评估。通过构建代数几何基准AlgGeoTest并评估LLMs，发现当前LLMs在该领域存在显著缺陷，证明了新框架能更精确地衡量LLMs的数学能力，并为未来的研究奠定基础。

> **摘要翻译:** 评估大型语言模型（LLMs）的数学能力是一个关键但充满挑战的前沿领域。现有基准存在不足，特别是对于以证明为中心的问题，因为手动创建不可扩展且成本高昂，导致LLMs的真实数学能力在很大程度上未被评估。为了克服这些障碍，我们提出了Proof2Hybrid，这是第一个完全自动化的框架，可以从自然语言数学语料库中合成高质量、以证明为中心的基准。我们解决方案的关键新颖之处在于Proof2X，这是一个将数学证明转化为各种易于验证的问题的路线图。根据此路线图，我们提出了一种新型的混合格式问题，名为“$m$-out-of-$n$多判题问题”，专门设计用于实现稳健的自动评估，同时能抵御传统格式中固有的猜测和肤浅的模式匹配。作为我们框架的演示，我们引入了AlgGeoTest，一个针对代数几何（现代数学的前沿领域）的基准，包含456个具有挑战性的项目。我们使用AlgGeoTest对最先进的LLMs进行的广泛评估揭示了它们在理解代数几何方面的严重不足，从而提供了对其真实数学能力的更精确衡量。我们的框架和基准为深入研究AI系统的数学智能开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [233] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
> *可比文档中的跨语言观点和情感挖掘*

*Motaz Saad, David Langlois, Kamel Smaili* | **Category: cs.CL, I.2.7** | **Updated: 2025-08-05**

**Keywords:** 跨语言分析, 情感挖掘, 情绪识别, 可比文档, 英阿语言对

**Comment:** 16 pages, 5 figures

> **TL;DR:** 本研究在不依赖机器翻译的情况下，对英阿可比文档中的情感和情绪差异进行了跨语言分析，并发现情感和情绪的一致性取决于文章是否来自同一新闻机构。

**AI_Comments:** 该研究的创新之处在于其跨语言方法不依赖于机器翻译，并通过手动构建双语情绪词典来解决跨语言情感分析的挑战。此外，它首次探讨了来自不同来源的可比文档中情感和情绪的一致性问题，为跨文化传播和信息分析提供了新的视角。该方法的语言独立性也增强了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 可比文本对于理解一个主题如何在不同语言中被讨论非常有价值。本研究旨在探讨英阿可比文档中的情感和情绪差异，并填补现有文献中对不同来源文档情感和情绪一致性探索的空白。

**Method:** 首先，对文本进行情感和情绪标签标注。采用跨语言方法对文档进行观点分类（主观/客观），避免依赖机器翻译。为了标注情绪（愤怒、厌恶、恐惧、喜悦、悲伤、惊讶），手动将英文WordNet-Affect (WNA) 词典翻译成阿拉伯语，创建了双语情绪词典，用于标注可比语料库。然后，应用统计度量来评估每个源-目标文档对中情感和情绪的一致性。

**Result:** 结果显示，当文章来自同一新闻机构时，情感和情绪标注一致；当文章来自不同新闻机构时，情感和情绪标注发散。

**Conclusion:** 本研究方法具有语言独立性，可推广到其他语言对。研究发现，情感和情绪的一致性取决于文档来源。

> **ai_Abstract:** 本研究旨在挖掘可比文档中的跨语言观点和情绪。针对英阿可比文档，论文提出了一种不依赖机器翻译的跨语言方法，用于标注文本的情感和情绪。通过手动翻译WordNet-Affect词典创建双语情绪词典，并应用统计方法评估情感和情绪的一致性。研究发现，情感和情绪的标注一致性与文档来源相关，且该方法具有语言独立性和可推广性。

> **摘要翻译:** 可比文本是多种语言中主题对齐但并非直接翻译的文档。它们对于理解一个主题如何在不同语言中被讨论非常有价值。本研究探讨了英阿可比文档中的情感和情绪差异。首先，对文本进行情感和情绪标签标注。我们应用了一种跨语言方法来标记文档的观点类别（主观/客观），避免依赖机器翻译。为了标注情绪（愤怒、厌恶、恐惧、喜悦、悲伤、惊讶），我们手动将英文WordNet-Affect (WNA) 词典翻译成阿拉伯语，创建了双语情绪词典，用于标注可比语料库。然后，我们应用统计度量来评估每个源-目标文档对中情感和情绪的一致性。当文档来自不同来源时，这种比较尤其重要。据我们所知，这方面在现有文献中尚未被探索。我们的研究包括来自欧洲新闻台（Euronews）、英国广播公司（BBC）和半岛电视台（Al-Jazeera (JSC)）的英阿文档对。结果显示，当文章来自同一新闻机构时，情感和情绪标注一致；当文章来自不同新闻机构时，情感和情绪标注发散。所提出的方法具有语言独立性，可推广到其他语言对。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [236] [CLIPPER: Compression enables long-context synthetic data generation](https://arxiv.org/abs/2502.14854)
> *CLIPPER：压缩实现长上下文合成数据生成*

*Chau Minh Pham, Yapei Chang, Mohit Iyyer* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 合成数据生成, 长上下文, 数据压缩, 叙事性主张验证, 大型语言模型

**Comment:** Accepted to COLM 2025

> **TL;DR:** CLIPPER是一种基于压缩的方法，用于生成长上下文推理任务（如叙事性主张验证）的高质量合成数据，通过先压缩文本再生成主张，显著提高了模型性能。

**AI_Comments:** CLIPPER的创新点在于引入了“压缩”作为生成高质量长上下文合成数据的关键步骤，有效解决了直接从原始文本生成数据所导致的“人工痕迹”问题。这种通过中间表示生成数据的方法，不仅提高了合成数据的质量，也显著提升了模型的推理能力，对于依赖合成数据训练大型语言模型的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）开发者越来越依赖合成数据，但为复杂的长上下文推理任务生成高质量数据仍然具有挑战性，直接从原始文本生成会产生带有缺陷的主张。

**Method:** CLIPPER是一种基于压缩的方法。它首先将书籍压缩成章节大纲和书籍摘要，然后利用这些中间表示来生成复杂的主张和相应的思维链。

**Result:** CLIPPER生成的主张比传统方法更有效、更扎实、更复杂。使用CLIPPER构建了一个包含1.9万个合成书籍主张的数据集。最佳模型在叙事性主张验证任务上取得了突破性进展（准确率从28%提高到76%），并在NoCha排行榜上为10B以下模型设定了新的SOTA。模型还能生成更详细、更扎实的思维链推理，并提高了其他叙事理解任务（如NarrativeQA）的性能。

**Conclusion:** CLIPPER通过结合文本压缩和中间表示，能够有效生成高质量的长上下文合成数据，显著提升了LLM在复杂推理任务上的表现。

> **ai_Abstract:** 本文介绍了CLIPPER，一种基于压缩的合成数据生成方法，旨在解决长上下文推理任务中高质量数据生成的难题。CLIPPER通过将原始文本压缩为章节大纲和摘要等中间表示，然后基于这些表示生成更有效、更扎实、更复杂的主张和思维链。实验表明，使用CLIPPER生成的数据集显著提升了微调模型在叙事性主张验证任务上的表现，并设定了新的SOTA，同时提高了其他叙事理解任务的性能。

> **摘要翻译:** 大型语言模型（LLM）开发者越来越依赖合成数据，但为复杂的长上下文推理任务生成高质量数据仍然具有挑战性。我们引入了CLIPPER，一种基于压缩的方法，用于生成针对叙事性主张验证任务的合成数据——该任务需要对一本书进行推理以验证给定主张。与直接从书籍原始文本生成主张（这会导致主张充满人工痕迹）不同，CLIPPER首先将书籍压缩成章节大纲和书籍摘要，然后利用这些中间表示来生成复杂的主张和相应的思维链。与朴素方法相比，CLIPPER生成的主张更有效、更扎实、更复杂。通过使用CLIPPER，我们构建了一个包含1.9万个合成书籍主张及其源文本和思维链推理的数据集，并用它来微调了三个开源模型。我们最好的模型在叙事性主张验证上取得了突破性成果（在我们的测试集上准确率从28%提高到76%），并在NoCha排行榜上为10B以下模型设定了新的SOTA。进一步分析表明，我们的模型生成了更详细、更扎实的思维链推理，同时还提高了其他叙事理解任务（例如NarrativeQA）的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [250] [LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning](https://arxiv.org/abs/2508.03275)
> *LECTOR：LLM增强的基于概念的面向测试的自适应间隔学习重复系统*

*Jiahao Zhao* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 间隔重复, 大型语言模型, 自适应学习, 语义相似性, 学习算法

**Comment:** 15 pages, 4 figures, 1 table

> **TL;DR:** LECTOR是一种新型的自适应间隔重复算法，利用大型语言模型解决语义干扰，并在测试导向学习中显著提高了成功率。

**AI_Comments:** LECTOR 的创新之处在于将大型语言模型（LLM）引入间隔重复系统，以解决传统算法在语义干扰和个性化适应上的不足。这对于需要处理大量相似概念（如词汇学习）的测试导向型学习场景具有重要意义。其通过LLM增强的语义相似性评估，有效提升了学习效率和记忆保留，为未来的智能教育系统提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的间隔重复系统在语义干扰和个性化适应方面表现不佳，特别是在像语言考试这样成功率至关重要的测试导向学习场景中。

**Method:** LECTOR（LLM-Enhanced Concept-based Test-Oriented Repetition）是一种新型的自适应调度算法。它利用大型语言模型（LLM）进行语义分析，并结合个性化学习档案。通过LLM驱动的语义相似性评估，并将其与已建立的间隔重复原则相结合，解决了词汇学习中语义混淆的关键挑战。

**Result:** 在针对100名模拟学习者进行100天的综合评估中，LECTOR的成功率为90.2%，优于最佳基线算法（SSP-MMC）的88.4%，相对提升了2.0%。该算法在处理语义相似概念方面表现出特别的优势，减少了混淆引起的错误，同时保持了计算效率。

**Conclusion:** LECTOR为智能辅导系统和自适应学习平台提供了一个有前景的方向。

> **ai_Abstract:** 本研究提出了一种名为 LECTOR 的新型自适应间隔重复算法，该算法专为面向测试的学习场景（特别是语言考试）设计。LECTOR 利用大型语言模型进行语义分析，并结合个性化学习档案，有效解决了词汇学习中的语义混淆问题。通过与多种基线算法的对比评估，LECTOR 在模拟学习者中取得了更高的成功率（90.2%），并显著减少了语义相似概念引起的错误，展现了其在智能辅导和自适应学习领域的潜力。

> **摘要翻译:** 间隔重复系统是高效学习和记忆保留的基础，但现有算法常常难以解决语义干扰和个性化适应问题。我们提出了 LECTOR（LLM-Enhanced Concept-based Test-Oriented Repetition），这是一种专门为面向测试的学习场景（特别是成功率至关重要的语言考试）设计的新型自适应调度算法。LECTOR 利用大型语言模型进行语义分析，同时整合个性化学习档案，通过使用由 LLM 驱动的语义相似性评估并将其与已建立的间隔重复原则相结合，解决了词汇学习中语义混淆的关键挑战。我们对六种基线算法（SSP-MMC、SM2、HLR、FSRS、ANKI、THRESHOLD）进行了为期 100 天、针对 100 名模拟学习者的全面评估，结果显示出显著改进：LECTOR 的成功率为 90.2%，而最佳基线（SSP-MMC）为 88.4%，相对提升了 2.0%。该算法在处理语义相似概念方面表现出特别的优势，减少了混淆引起的错误，同时保持了计算效率。我们的结果表明 LECTOR 是智能辅导系统和自适应学习平台的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [251] [CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward](https://arxiv.org/abs/2508.03686)
> *CompassVerifier：一个用于大型语言模型评估和结果奖励的统一且鲁棒的验证器*

*Shudong Liu, Hongwei Liu, Junnan Liu, Linchen Xiao, Songyang Gao, Chengqi Lyu, Yuzhe Gu, Wenwei Zhang, Derek F. Wong, Songyang Zhang, Kai Chen* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 答案验证, 评估, 奖励模型, CompassVerifier

**Comment:** Technical Report; 31 Pages

> **TL;DR:** CompassVerifier是一个轻量级、准确且鲁棒的验证模型，用于大型语言模型（LLM）的评估和结果奖励，并引入了VerfierBench基准，解决了现有验证方法缺乏全面基准和鲁棒性的问题。

**AI_Comments:** 该论文的创新点在于提出了一个统一且鲁棒的轻量级验证器CompassVerifier，并构建了专门的VerifierBench基准来系统性地评估LLM的验证能力。它解决了现有评估框架在答案验证方面的两大痛点：过度依赖定制化和缺乏鲁棒性与通用性。通过处理多领域、多类型的答案并识别异常响应，CompassVerifier显著提升了LLM评估的效率和准确性，并有望在强化学习中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）评估框架在答案验证方面存在局限性，主要依赖于正则匹配或通用LLM，这需要大量的定制化。当前方法面临两个根本性限制：1）缺乏系统评估不同LLM验证能力的综合基准；2）验证器开发处于早期阶段，现有方法缺乏处理复杂边缘情况的鲁棒性和跨不同领域的通用性。

**Method:** 本文开发了CompassVerifier，一个准确且鲁棒的轻量级验证器模型，用于LLM的评估和结果奖励。它通过手动分析元错误模式，并结合来自多个数据源的模型输出来增强模型。此外，引入了VerifierBench基准，该基准包含从多个数据源收集的模型输出，并经过手动分析元错误模式进行增强。

**Result:** CompassVerifier在数学、知识和多样化推理任务等多个领域展现出多领域能力，能够处理多子问题、公式和序列答案等各种答案类型，同时有效识别异常/无效响应。

**Conclusion:** CompassVerifier和VerifierBench有望促进答案验证、评估协议和强化学习研究。

> **ai_Abstract:** 该论文提出了CompassVerifier，一个轻量级、准确且鲁棒的验证器模型，用于大型语言模型（LLM）的评估和作为奖励模型。它旨在解决当前LLM验证方法中存在的两大问题：缺乏全面的评估基准和现有验证器在鲁棒性及通用性方面的不足。CompassVerifier展示了在数学、知识和推理等多个领域处理不同答案类型（包括复杂边缘情况和异常响应）的能力。同时，论文引入了VerifierBench基准，通过整合多源数据和元错误模式分析来增强CompassVerifier。该工作旨在推动答案验证、评估协议和强化学习的研究。

> **摘要翻译:** 答案验证对于通过将大型语言模型（LLM）的非结构化输出与标准答案进行匹配来评估它们至关重要，同时它也作为指导LLM优化的奖励模型。大多数评估框架依赖于正则匹配或使用通用LLM进行答案验证，这需要对正则表达式规则或评估提示进行大量重复的定制。当前方法存在两个根本性限制：1）缺乏系统评估不同LLM验证能力的综合基准；2）验证器开发处于早期阶段，现有方法缺乏处理复杂边缘情况的鲁棒性和跨不同领域的通用性。在这项工作中，我们开发了CompassVerifier，一个准确且鲁棒的轻量级验证器模型，用于评估和结果奖励。它在数学、知识和多样化推理任务等多个领域展现出多领域能力，能够处理多子问题、公式和序列答案等各种答案类型，同时有效识别异常/无效响应。我们引入了VerifierBench基准，该基准包含从多个数据源收集的模型输出，并通过手动分析元错误模式进行增强，以提升CompassVerifier。我们预期CompassVerifier和VerifierBench将促进答案验证、评估协议和强化学习研究。代码和数据集可在 https://github.com/open-compass/CompassVerifier 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [261] [Dynaword: From One-shot to Continuously Developed Datasets](https://arxiv.org/abs/2508.02271)
> *Dynaword：从一次性到持续开发的数据集*

*Kenneth Enevoldsen, Kristian Nørgaard Jensen, Jan Kostkan, Balázs Szabó, Márton Kardos, Kirten Vad, Johan Heinsen, Andrea Blasi Núñez, Gianluca Barmina, Jacob Nielsen, Rasmus Larsen, Peter Vahlstrup, Per Møldrup Dalum, Desmond Elliott, Lukas Galke, Peter Schneider-Kamp, Kristoffer Nielbo* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** Dynaword, 开放数据集, 社区协作, 自然语言处理, 丹麦语Dynaword

**Comment:** 

> **TL;DR:** Dynaword提出了一个框架，用于创建可由社区持续更新的大规模开放数据集，并通过丹麦语Dynaword进行了验证，解决了现有数据集许可模糊、静态和质量控制受限的问题。

**AI_Comments:** Dynaword方法通过引入社区协作和持续更新的机制，创新性地解决了当前大规模NLP数据集面临的许可限制、静态发布和质量控制问题。其开放许可和轻量级测试确保了数据集的持续演进和高质量。这对于推动NLP研究的开放性和可持续性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大规模自然语言处理数据集面临三个主要挑战：1) 依赖许可模糊的来源，限制使用和共享；2) 静态数据集发布，阻碍社区贡献和降低寿命；3) 质量保证过程仅限于发布团队，未能利用社区专业知识。

**Method:** 提出了Dynaword方法，这是一个用于创建可通过社区协作持续更新的大规模开放数据集的框架。同时，引入了丹麦语Dynaword作为该方法的具体实现和验证。

**Result:** 丹麦语Dynaword作为具体实现，包含的词元数量是同类发布数据集的四倍以上，完全采用开放许可，并获得了工业界和研究界的多方贡献。该仓库包含轻量级测试，以确保数据格式、质量和文档，建立了持续社区贡献和数据集演进的可持续框架。

**Conclusion:** Dynaword方法和丹麦语Dynaword的实现，成功解决了现有大规模自然语言处理数据集的局限性，提供了一个可持续、开放且可由社区持续贡献和更新的数据集开发模式。

> **ai_Abstract:** 本文介绍了Dynaword方法，一个用于创建可通过社区协作持续更新的大规模开放数据集的框架。为解决现有NLP数据集中许可限制、静态发布和质量控制不足的问题，作者提出了该框架，并以丹麦语Dynaword作为具体实现进行验证。丹麦语Dynaword的数据量是同类数据集的四倍，采用开放许可，并已获得多方贡献，展示了该方法在建立可持续、高质量数据集方面的潜力。

> **摘要翻译:** 大规模数据集是自然语言处理研究和发展的基础。然而，目前的方法面临三个关键挑战：（1）依赖许可模糊的来源，限制了使用、共享和衍生作品；（2）静态数据集发布，阻碍了社区贡献并降低了寿命；（3）质量保证过程仅限于发布团队，未能利用社区专业知识。为了解决这些局限性，我们提出了两项贡献：Dynaword方法和丹麦语Dynaword。Dynaword方法是一个用于创建可通过社区协作持续更新的大规模开放数据集的框架。丹麦语Dynaword是一个具体的实现，验证了这种方法并展示了其潜力。丹麦语Dynaword包含的词元数量是同类发布的四倍以上，完全采用开放许可，并已获得工业界和研究界的多次贡献。该仓库包含轻量级测试，以确保数据格式、质量和文档，建立了一个可持续的框架，用于持续的社区贡献和数据集演变。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [273] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
> *通过知识图谱和文学理论的长篇故事生成*

*Ge Shi, Kaiyu Huang, Guochen Feng* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 长篇故事生成, 多智能体, 知识图谱, 文学理论, 大型语言模型

**Comment:** 

> **TL;DR:** 提出一种基于多智能体和记忆机制的长篇故事生成方法，通过引入文学理论和知识图谱，解决了主题漂移和情节枯燥的问题，生成了更高质量的故事。

**AI_Comments:** 该论文的创新点在于结合了多智能体系统、记忆机制、文学叙事学理论和知识图谱来解决长篇故事生成中的核心问题，特别是主题漂移和情节连贯性。通过模拟作者-读者交互进行修订，增加了生成故事的逻辑性和吸引力，为高质量长文本生成提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 之前的基于大纲的长文本生成方法存在两个主要问题：由于对之前大纲的记忆丢失导致的主题漂移，以及情节乏味、逻辑不连贯，对人类读者缺乏吸引力。

**Method:** 提出多智能体故事生成器结构，以大型语言模型作为核心组件。引入包含长短期记忆的记忆存储模型防止主题漂移。设计基于文学叙事学理论的故事主题障碍框架，通过构建知识图谱和整合新节点内容来引入不确定因素、评估标准并增强故事吸引力。建立多智能体交互阶段，通过对话模拟作者-读者交互并根据反馈修改故事文本。

**Result:** 与现有方法相比，该方法能够生成更高质量的长篇故事。

**Conclusion:** 该论文成功地提出了一种改进的长篇故事生成方法，有效解决了主题漂移和情节连贯性问题，并通过实验证明了其方法的优越性。

> **ai_Abstract:** 本文提出一种多智能体故事生成器结构，利用大型语言模型改进传统基于大纲的长篇故事生成方法。为解决主题漂移和情节枯燥问题，该方法引入长短期记忆模型以保持主题一致性，并设计基于文学叙事学理论的故事主题障碍框架，结合知识图谱提升情节吸引力。此外，通过模拟作者-读者交互实现故事的迭代修订。实验结果表明，该方法能生成更高质量的长篇故事。

> **摘要翻译:** 长篇故事生成（由数千字组成）是长文本生成（LTG）领域的一个子任务。以往的研究通过基于大纲的生成来解决这一挑战，该方法采用多阶段方法将大纲生成故事。然而，这种方法存在两个常见问题：几乎不可避免的由先前大纲记忆丢失引起的主题漂移，以及情节枯燥、逻辑不连贯，对人类读者缺乏吸引力。
在本文中，我们提出了多智能体故事生成器结构来改进多阶段方法，使用大型语言模型（LLMs）作为智能体的核心组件。为了避免主题漂移，我们引入了一个包含两个组件的记忆存储模型：一个识别最重要记忆的长期记忆存储，从而防止主题漂移；以及一个保留每轮生成最新大纲的短期记忆存储。为了将引人入胜的元素融入故事中，我们设计了一个基于文学叙事学理论的故事主题障碍框架，该框架引入不确定因素和评估标准来生成大纲。该框架计算先前故事情节的相似度，并通过构建知识图谱和整合新节点内容来增强故事的吸引力。此外，我们建立了一个多智能体交互阶段，通过对话模拟作者-读者交互，并根据反馈修改故事文本，以确保其保持一致性和逻辑性。与以往方法的评估表明，我们的方法可以生成更高质量的长篇故事。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs](https://arxiv.org/abs/2503.04856)
> *M2S：面向LLM红队的多轮到单轮越狱攻击*

*Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** LLM, 越狱攻击, 红队测试, 单轮提示, 上下文盲区

**Comment:** Accepted to ACL 2025 (Main Track). Camera-ready version

> **TL;DR:** M2S框架将多轮越狱提示转化为单轮查询，显著提高了LLM红队测试的效率和攻击成功率。

**AI_Comments:** M2S框架的创新之处在于其能够将复杂耗时的多轮越狱攻击简化为高效的单轮形式，这显著提升了LLM红队测试的效率和可扩展性。通过利用LLM的“上下文盲区”，该方法揭示了现有防御机制的深层漏洞，对推动LLM安全研究和防御技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多轮人工越狱攻击对LLM的成功率高，但它们需要大量的人工投入和时间，导致对抗性测试的效率低下。

**Method:** 本文引入了一个名为M2S（Multi-turn to Single-turn）的新颖框架，旨在将多轮对抗性“越狱”提示整合为单轮查询。M2S方法包括Hyphenize、Numberize和Pythonize，它们系统地将多轮对话重新格式化为结构化的单轮提示。

**Result:** 在多轮人工越狱（MHJ）数据集上的广泛评估表明，M2S方法在多个最先进的LLM上实现了70.6%到95.9%的攻击成功率。值得注意的是，这些单轮提示比原始多轮攻击的成功率高出多达17.5个百分点，同时平均令牌使用量减少了一半以上。

**Conclusion:** M2S框架通过将多轮对话转换为简洁的单轮提示，为大规模红队测试提供了可扩展的工具，并揭示了当代LLM防御中的关键弱点。进一步分析表明，将恶意请求嵌入枚举或代码类结构中利用了LLM的“上下文盲区”，从而绕过了本地防护和外部输入-输出过滤器。

> **ai_Abstract:** 本文提出了M2S框架，旨在将LLM的多轮越狱提示转化为高效的单轮查询，以显著降低红队测试的人工成本。该框架通过Hyphenize、Numberize和Pythonize等方法，系统地将多轮对话重构为结构化的单轮提示。实验结果表明，M2S方法在攻击成功率上表现出色，在MHJ数据集上达到了70.6%至95.9%，甚至比原始多轮攻击高出17.5个百分点，同时大幅减少了令牌使用量。研究还发现，将恶意请求嵌入枚举或代码结构中能利用LLM的“上下文盲区”，有效绕过防御机制。M2S框架为大规模LLM红队测试提供了可扩展的工具，并揭示了当前LLM防御的脆弱性。

> **摘要翻译:** 我们引入了一个新颖的框架，用于将多轮对抗性“越狱”提示整合为单轮查询，显著减少了大型语言模型（LLM）对抗性测试所需的人工开销。尽管多轮人工越狱已被证明能产生高攻击成功率，但它们需要大量的人力投入和时间。我们的多轮到单轮（M2S）方法——Hyphenize、Numberize和Pythonize——系统地将多轮对话重新格式化为结构化的单轮提示。尽管移除了迭代的来回交互，但这些提示保留并通常增强了对抗性效力：在对多轮人工越狱（MHJ）数据集的广泛评估中，M2S方法在多个最先进的LLM上实现了70.6%到95.9%的攻击成功率。值得注意的是，单轮提示比原始多轮攻击的性能高出多达17.5个百分点，同时平均令牌使用量减少了一半以上。进一步分析表明，将恶意请求嵌入枚举或代码类结构中利用了“上下文盲区”，绕过了本地防护和外部输入-输出过滤器。通过将多轮对话转换为简洁的单轮提示，M2S框架为大规模红队测试提供了可扩展的工具，并揭示了当代LLM防御中的关键弱点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [303] [Do language models accommodate their users? A study of linguistic convergence](https://arxiv.org/abs/2508.03276)
> *语言模型会适应用户吗？一项关于语言趋同的研究*

*Terra Blevins, Susanne Schmalwieser, Benjamin Roth* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 语言模型, 语言趋同, 对话系统, 过拟合, 语言适应性

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）会强烈趋同于用户的语言风格，但这种趋同常有过拟合现象，且与人类的趋同模式存在差异。

**AI_Comments:** 这项研究揭示了LLM在语言适应性方面的重要发现，即它们会强烈趋同于用户风格，但这种趋同可能与人类的机制不同，甚至存在过拟合。这对于理解LLM的语言生成行为及其在人机交互中的应用具有重要意义，提示未来研究需关注这种趋同的机制差异及其潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在语言生成方面表现出色，但其语言使用与人类的相似程度，特别是它们是否会像人类一样表现出语言趋同性（即适应用户的语言模式），仍未得到充分研究。

**Method:** 研究者系统地比较了16个语言模型在三个对话语料库中对现有对话的补全与原始人类回复的差异，并分析了多种文体特征。

**Result:** 研究发现模型会强烈趋同于对话风格，且相对于人类基线常出现显著过拟合。趋同模式通常是特征特定的，并且在不同模型设置中存在一致的趋同性变化，其中指令微调模型和大型模型的趋同程度低于预训练模型。

**Conclusion:** 鉴于人类和模型趋同模式之间的差异，研究者推测这些行为的底层机制非常不同。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）是否会像人类一样表现出语言趋同性，即适应用户的语言模式。通过对比16个模型在三个对话语料库中对对话的补全与人类原始回复，研究发现模型会强烈趋同于对话风格并常有过拟合现象。指令微调和大型模型趋同程度低于预训练模型。研究者推测人类与模型的趋同机制存在根本差异。

> **摘要翻译:** 尽管大型语言模型（LLMs）通常被认为擅长生成语言，但它们语言使用与人类的相似程度仍未得到充分研究。在本文中，我们测试了模型是否表现出语言趋同性，这是人类语言交流中一个核心的语用元素，并提出问题：模型是否会适应或趋同于用户的语言模式？为了回答这个问题，我们系统地比较了16个语言模型在三个对话语料库中对现有对话的补全与原始人类回复的差异，并分析了多种文体特征。我们发现模型会强烈趋同于对话风格，且相对于人类基线常出现显著过拟合。虽然趋同模式通常是特征特定的，但我们在不同模型设置中观察到一致的趋同性变化，其中指令微调模型和大型模型的趋同程度低于其预训练的对应模型。鉴于人类和模型趋同模式之间的差异，我们假设这些行为的底层机制非常不同。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [308] [LaMPE: Length-aware Multi-grained Positional Encoding for Adaptive Long-context Scaling Without Training](https://arxiv.org/abs/2508.02308)
> *LaMPE：面向自适应长文本扩展的长度感知多粒度位置编码（无需训练）*

*Sikui Zhang, Guangze Gao, Ziyun Gan, Chunfeng Yuan, Zefeng Lin, Houwen Peng, Bing Li, Weiming Hu* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 长度感知位置编码, 多粒度注意力, 长文本扩展, 大型语言模型, 无需训练

**Comment:** 13 pages, 9 figures

> **TL;DR:** LLMs在长文本处理中性能下降，本文提出LaMPE，一种无需训练的长度感知多粒度位置编码方法，通过动态映射和多粒度注意力机制显著提升长文本性能。

**AI_Comments:** LaMPE的创新之处在于其无需训练的特性以及对输入长度的自适应性。通过动态调整位置编码和引入多粒度注意力，它有效解决了RoPE在长文本场景下的OOD问题，为LLMs的长文本处理提供了高效且易于部署的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在输入超出预训练上下文窗口时性能显著下降，主要是由于旋转位置嵌入（RoPE）的域外（OOD）行为。现有方法通过固定映射策略将OOD位置重新映射到域内，但忽略了输入长度与模型有效上下文窗口之间的动态关系。

**Method:** 提出长度感知多粒度位置编码（LaMPE），一种无需训练的方法。LaMPE利用相对位置的左偏频率分布，通过参数化的缩放S型函数建立映射长度与输入长度之间的动态关系，以自适应地分配不同输入长度下的位置容量。同时，LaMPE设计了一种新颖的多粒度注意力机制，策略性地在不同序列区域分配位置分辨率，以捕获细粒度局部性和长程依赖。该方法可无缝应用于基于RoPE的LLMs。

**Result:** 在三个代表性LLMs和五个主流长文本基准上的大量实验表明，LaMPE比现有长度外推方法实现了显著的性能提升。

**Conclusion:** LaMPE通过其长度感知和多粒度设计，有效解决了LLMs在长文本处理中的性能下降问题，并在无需训练的情况下显著优于现有方法。

> **ai_Abstract:** 本文提出LaMPE，一种无需训练的长度感知多粒度位置编码方法，旨在解决大型语言模型在处理超出预训练上下文窗口的长文本时出现的性能下降问题。LaMPE通过引入参数化缩放S型函数来动态调整位置容量，并设计多粒度注意力机制以捕获不同尺度的依赖关系。实验证明，该方法在多个LLM和长文本基准上显著优于现有长度外推方法。

> **摘要翻译:** 大型语言模型（LLMs）在输入超出预训练上下文窗口时会经历显著的性能下降，这主要归因于旋转位置嵌入（RoPE）的域外（OOD）行为。最近的研究通过固定的映射策略将OOD位置重新映射到域内范围来缓解这个问题，但却忽略了输入长度与模型有效上下文窗口之间的动态关系。为此，我们提出了长度感知多粒度位置编码（LaMPE），这是一种无需训练的方法，它充分利用模型的有效上下文窗口，实现LLMs中的自适应长文本扩展。受相对位置左偏频率分布的启发，LaMPE通过参数化的缩放S型函数在映射长度和输入长度之间建立动态关系，从而自适应地在不同输入长度下分配位置容量。同时，LaMPE设计了一种新颖的多粒度注意力机制，策略性地在不同序列区域分配位置分辨率，以捕获细粒度局部性和长程依赖。我们的方法可以无缝应用于各种基于RoPE的LLMs而无需训练。在三个代表性LLMs上对五个主流长文本基准进行的广泛实验表明，与现有长度外推方法相比，LaMPE取得了显著的性能提升。代码将发布在https://github.com/scar-on/LaMPE。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [314] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
> *RCP-Merging：通过将推理能力作为先验来合并长思维链模型与领域特定模型*

*Junyao Yang, Jianwei Wang, Huiping Zhuang, Cen Chen, Ziqian Zeng* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 模型合并, 思维链, 领域特定模型, 推理能力, 大型语言模型

**Comment:** 15 pages, 7 figures

> **TL;DR:** RCP-Merging是一种新颖的模型合并框架，它在合并长思维链LLM与领域特定LLM时，通过将推理能力作为先验来保持推理能力并提升领域性能。

**AI_Comments:** RCP-Merging的创新点在于其将“推理能力作为先验”的思想，通过引入推理能力指标来指导模型合并过程，有效解决了现有合并方法中推理能力退化的问题。这对于在有限资源下，构建兼具复杂推理能力和专业领域知识的LLM具有重要意义，尤其是在需要多步推理的专业领域应用中。该方法为模型合并提供了一个新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模型合并方法在合并长思维链（CoT）大型语言模型（LLM）与领域特定LLM时，会导致推理能力下降，甚至出现乱码输出和输出崩溃，无法在低计算和数据成本下创建兼具长CoT能力和领域知识的双能力模型。

**Method:** 本文提出了RCP-Merging框架。该方法将推理模型权重视为基础先验，并利用推理能力指标来保留核心长CoT能力模型权重，同时选择性地合并必要的领域特定权重，以整合领域特定LLM与长CoT能力，同时保持模型在原始领域的性能。

**Result:** 在Qwen2.5-7B、Llama3.1-8B和Qwen2.5-1.5B模型在生物医学和金融领域的广泛实验表明，RCP-Merging成功地将推理模型与领域特定模型合并，在不显著损害原始长CoT推理能力的情况下，将领域任务性能比最先进的方法提高了9.5%和9.2%。

**Conclusion:** RCP-Merging框架能够有效合并具有长思维链能力和领域特定知识的模型，同时克服了现有合并方法导致的推理能力下降问题，显著提升了领域任务性能。

> **ai_Abstract:** 本文提出了一种名为RCP-Merging的新型模型合并框架，旨在解决将长思维链（CoT）大型语言模型（LLM）与领域特定LLM合并时出现的推理能力下降问题。该方法将推理模型权重视为基础先验，并利用推理能力指标来选择性地合并领域特定权重，从而在保持原始长CoT推理能力的同时，显著提升模型在特定领域（如生物医学和金融）的任务性能。实验结果显示，RCP-Merging在领域任务上比现有SOTA方法有显著提升。

> **摘要翻译:** 大型语言模型（LLM）具有长思维链（CoT）能力，被称为推理模型，通过多步长CoT推理展示了卓越的复杂问题解决能力。为了在不产生大量计算和数据成本的情况下创建兼具长CoT能力和领域特定知识的双能力模型，模型合并成为一种高效的资源利用方法。然而，将领域特定LLM与长CoT模型合并存在重大挑战，因为目前的合并方法存在推理能力下降、甚至出现乱码输出和输出崩溃的问题。为了克服这些问题，我们引入了RCP-Merging：通过将推理能力作为先验来合并长思维链模型与领域特定模型，这是一种新颖的合并框架，旨在整合领域特定LLM与长CoT能力，同时保持模型在原始领域的性能。我们的方法将推理模型权重视为基础先验，利用推理能力指标来保留核心长CoT能力模型权重，同时选择性地合并必要的领域特定权重。我们在生物医学和金融领域的Qwen2.5-7B、Llama3.1-8B和Qwen2.5-1.5B模型上进行了广泛实验。我们的结果表明，RCP-Merging成功地将推理模型与领域特定模型合并，在不显著损害原始长CoT推理能力的情况下，将领域任务性能比最先进的方法提高了9.5%和9.2%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [344] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
> *Light-IF：通过预习和自检赋予大型语言模型通用推理能力以遵循复杂指令*

*Chenyang Wang, Liang Wen, Shousheng Jia, Xiangzheng Zhang, Liang Xu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** LLM, 指令遵循, 通用推理, 预习, 自检

**Comment:** 12 pages, 10 figures, 7 tables

> **TL;DR:** 提出Light-IF框架，通过结合预习和自检的严格推理过程，显著提升LLM遵循复杂指令的能力，并在基准测试中表现出色。

**AI_Comments:** Light-IF框架的创新点在于其引入的“预习和自检”机制，有效解决了LLM在复杂指令遵循中的“惰性推理”问题。通过结合数据生成、拒绝采样、Entropy-SFT和TEA-RL等多种策略，该方法为提升LLM的通用推理能力提供了一条有效途径，对提升LLM在实际应用中的可靠性具有重要意义。论文展示了其超越现有大型模型的性能，证明了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在解决数学问题、编码任务和一般谜题方面取得了显著进展，但它们在准确遵循指令方面的有效性仍然不一致，尤其是在面对更复杂的指令时。本文调查发现，思维阶段的“惰性推理”是导致指令依从性差的主要因素。

**Method:** 本文提出了一个名为Light-IF的综合框架，旨在通过涉及预习和自检的严格推理过程来解决LLM的惰性推理问题。具体方法包括：首先，生成具有复杂约束的指令并进行过滤，以获得有效提示，从而形成硬、易和通过三种不同的提示数据集。然后，对“通过”提示进行拒绝采样，以构建一个小型但高质量的数据集，用于模型的冷启动初始化和适应有效的推理模式。最后，采用熵保留监督微调（Entropy-SFT）策略，并结合由基于规则的密集奖励引导的逐词熵自适应强化学习（TEA-RL），鼓励模型转变其推理机制，最终培养出包含预习和自检的通用推理能力。

**Result:** 在指令遵循基准测试中进行了广泛的实验，结果表明在各种模型规模下均取得了显著的性能提升。值得注意的是，Light-IF-32B模型超越了更大的开源模型（如DeepSeek-R1）和闭源模型（如Doubao-1.6）。

**Conclusion:** 通过引入预习和自检机制，Light-IF框架能够有效解决LLM在复杂指令遵循中的惰性推理问题，显著提升其通用推理能力和指令依从性。

> **ai_Abstract:** 本文提出了Light-IF框架，旨在解决大型语言模型（LLMs）在遵循复杂指令时因“惰性推理”导致的表现不一致问题。该框架通过引入预习和自检的严格推理过程，显著提升了模型的指令遵循能力。研究团队首先创建了带有复杂约束的指令数据集，并通过拒绝采样构建高质量数据用于模型冷启动。随后，采用熵保留监督微调（Entropy-SFT）和逐词熵自适应强化学习（TEA-RL）策略，引导模型转变推理机制，培养通用推理能力。实验结果表明，Light-IF在指令遵循基准测试中表现卓越，其32B模型甚至超越了部分大型开源和闭源模型。

> **摘要翻译:** 尽管大型语言模型（LLMs）在推理能力方面取得了进展，显著提升了它们在解决数学问题、编码任务和一般谜题方面的表现，但它们在准确遵循指令方面的有效性仍然不一致，尤其是在面对更复杂的指令时。我们的调查发现，思维阶段的惰性推理是导致指令依从性差的主要因素。为了缓解这个问题，我们提出了一个综合框架，旨在实现涉及预习和自检的严格推理过程，这对于满足严格的指令约束至关重要。具体来说，我们首先生成具有复杂约束的指令，并应用过滤过程以获得有效提示，从而产生了三个不同的提示数据集，分别归类为硬、易和通过。然后，我们对“通过”提示进行拒绝采样，以策划一个小型但高质量的数据集，从而实现模型的冷启动初始化，并促进其适应有效的推理模式。随后，我们采用熵保留监督微调（Entropy-SFT）策略，并结合由基于规则的密集奖励引导的逐词熵自适应强化学习（TEA-RL）。这种方法鼓励模型转变其推理机制，最终培养出包含预习和自检的通用推理能力。在指令遵循基准测试中进行了广泛的实验，结果表明在各种模型规模下均取得了显著的性能提升。值得注意的是，我们的Light-IF-32B模型超越了更大的开源模型（如DeepSeek-R1）和闭源模型（如Doubao-1.6）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [352] [Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes](https://arxiv.org/abs/2508.03292)
> *通过心理刻板印象调查LLM生成故事中的性别偏见*

*Shahed Masoudian, Gustavo Escobedo, Hannah Strauss, Markus Schedl* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 性别偏见, 大型语言模型, 心理刻板印象, 叙事生成, 偏见缓解

**Comment:** Under Review

> **TL;DR:** 研究通过心理刻板印象揭示了LLM在故事生成中存在的性别偏见，并提出了缓解策略。

**AI_Comments:** 这篇论文的创新之处在于其将心理学中经过研究的性别刻板印象引入到对LLM性别偏见的评估中，特别关注了长内容生成中的隐性偏见，这弥补了以往研究的不足。通过构建新数据集和深入分析，揭示了LLM偏见的复杂性及其与模型规模的关系。这对于理解和缓解LLM中的社会偏见具有重要意义，为未来LLM的公平性研究提供了新的视角和评估方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在探测LLM性别偏见时常使用明确的性别线索或在短文本任务中进行，这可能忽略了长内容生成中更隐性的偏见。鉴于LLM在不同应用中的广泛使用，其放大性别偏见的潜力日益引起关注。

**Method:** 本文通过开放式叙事生成任务，利用心理学中研究的性别刻板印象（如攻击性或八卦）来调查LLM中的性别偏见。研究引入了一个名为StereoBias-Stories的新数据集，包含未受限或受限于25种心理刻板印象的随机属性和三个任务相关故事结局的短故事。通过分析故事中性别贡献的变化来评估偏见。

**Result:** 1. 在未受限提示下，模型平均对男性高度偏见；而使用与性别刻板印象无关的属性进行条件设置则能缓解这种偏见。
2. 结合多个与同一性别刻板印象相关的属性会加剧模型行为，其中男性属性会放大偏见，女性属性则能减轻偏见。
3. 模型偏见与用于分类的心理学真实情况相符，且这种符合度随模型规模的增大而增强。

**Conclusion:** 这些发现共同强调了以心理学为基础评估LLM的重要性。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在故事生成中存在的性别偏见，特别是针对长内容生成中可能被忽视的隐性偏见。研究引入了StereoBias-Stories数据集，通过结合心理学中的性别刻板印象属性来评估LLM的偏见。主要发现包括：未受限提示下LLM对男性存在高度偏见，但无性别刻板印象属性的条件设置能缓解偏见；结合相同性别刻板印象的多个属性会加剧偏见（男性属性放大，女性属性减轻）；且模型偏见与心理学真实情况一致，并随模型规模增大而增强。研究强调了以心理学为基础评估LLM的重要性。

> **摘要翻译:** 随着大型语言模型（LLM）在不同应用中日益广泛地使用，人们对其在各种任务中放大性别偏见的潜力日益担忧。先前的研究通常使用明确的性别线索作为反事实来探测性别偏见，或者在句子补全和简短问答任务中研究它们。这些形式可能会忽略嵌入在较长内容生成行为中更隐性的偏见形式。在这项工作中，我们通过开放式叙事生成任务，利用心理学中研究的性别刻板印象（例如攻击性或八卦）来调查LLM中的性别偏见。我们引入了一个名为StereoBias-Stories的新颖数据集，其中包含未受限制或受限于25种心理刻板印象中的（一个、两个或六个）随机属性以及三个任务相关的故事结局的短故事。我们分析了故事中性别贡献如何响应这些属性而变化，并提出了三个关键发现：(1) 尽管模型在未受限制的提示下平均对男性高度偏见，但以独立于性别刻板印象的属性进行条件设置可以缓解这种偏见。(2) 结合多个与同一性别刻板印象相关的属性会加剧模型行为，其中男性属性会放大偏见，女性属性则能减轻偏见。(3) 模型偏见与用于分类的心理学真实情况相符，并且这种符合强度随着模型规模的增大而增加。总而言之，这些见解强调了以心理学为基础评估LLM的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [354] [GEMA-Score: Granular Explainable Multi-Agent Scoring Framework for Radiology Report Evaluation](https://arxiv.org/abs/2503.05347)
> *GEMA-Score: 粒度可解释多智能体放射学报告评估框架*

*Zhenxuan Zhang, Kinhei Lee, Peiyuan Jing, Weihang Deng, Huichi Zhou, Zihao Jin, Jiahao Huang, Zhifan Gao, Dominic C Marshall, Yingying Fang, Guang Yang* | **Category: cs.CL, cs.MA** | **Updated: 2025-08-04**

**Keywords:** 放射学报告评估, 大型语言模型, 多智能体系统, 可解释性, 临床可靠性

**Comment:** 

> **TL;DR:** GEMA-Score是一个基于LLM多智能体的工作流，用于粒度化、可解释地评估放射学报告，在人类专家评估中表现出高相关性。

**AI_Comments:** GEMA-Score的创新之处在于其结合了多智能体工作流和LLM，实现了对放射学报告的粒度化和可解释评估，克服了现有方法在临床可靠性和可解释性方面的局限。其在安全关键的医疗领域具有重要应用潜力，通过提供解释性反馈，增强了评估结果的透明度和可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医疗报告评估指标未能反映临床可靠性。早期方法缺乏细粒度临床细节；诊断指标受限于固定词汇；基于LLM的方法缺乏可解释的推理步骤，难以评估和信任，这些限制阻碍了对生成报告可靠性的全面评估，并带来了临床使用风险。

**Method:** 本文提出GEMA-Score，通过基于大型语言模型的多智能体工作流进行客观量化和主观评估。GEMA-Score解析结构化报告，并通过智能体间的信息交互进行稳定计算，以评估疾病诊断、位置、严重程度和不确定性。此外，一个基于LLM的评分智能体评估完整性、可读性和临床术语，并提供解释性反馈。

**Result:** 实验验证GEMA-Score在公共数据集上与人类专家评估具有最高相关性，证明了其在临床评分中的有效性（ReXVal数据集的Kendall系数=0.69，RadEvalX数据集的Kendall系数=0.45）。

**Conclusion:** GEMA-Score通过其粒度化、可解释的多智能体评估框架，有效解决了现有医疗报告评估方法的局限性，并与人类专家评估高度一致，有望提高自动生成放射学报告的临床可靠性评估。

> **ai_Abstract:** 本文提出GEMA-Score，一个粒度可解释多智能体评分框架，旨在解决现有放射学报告自动评估方法在临床可靠性、细粒度细节和可解释性方面的不足。该框架通过基于大型语言模型的多智能体工作流，结合客观量化和主观评估，对报告的诊断、位置、严重程度、不确定性、完整性、可读性和术语进行评估，并提供解释性反馈。实验结果表明，GEMA-Score与人类专家评估具有高相关性，证明了其在临床评分中的有效性。

> **摘要翻译:** 自动医疗报告生成有潜力支持临床诊断，减轻放射科医生的工作量，并有望提高诊断一致性。然而，当前的评估指标往往未能反映生成报告的临床可靠性。早期的基于重叠的方法侧重于预测实体与真实实体之间的文本匹配，但遗漏了细粒度的临床细节（例如，解剖位置、严重程度）。一些诊断指标受限于固定的词汇或模板，降低了其捕捉多样化临床表达的能力。基于LLM的方法进一步缺乏可解释的推理步骤，这使得在安全关键设置中难以评估或信任它们的行为。这些限制阻碍了对生成报告可靠性的全面评估，并对其临床应用的选择带来了风险。因此，本文提出了一种粒度可解释多智能体评分（GEMA-Score），它通过基于大型语言模型的多智能体工作流进行客观量化和主观评估。我们的GEMA-Score解析结构化报告，并通过智能体之间的信息交互进行稳定计算，以评估疾病诊断、位置、严重程度和不确定性。此外，一个基于LLM的评分智能体评估完整性、可读性和临床术语，同时提供解释性反馈。大量的实验验证了GEMA-Score在公共数据集上与人类专家评估达到了最高相关性，证明了其在临床评分中的有效性（ReXVal数据集的Kendall系数=0.69，RadEvalX数据集的Kendall系数=0.45）。匿名项目演示可在https://github.com/Zhenxuan-Zhang/GEMA_score 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [372] [Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification](https://arxiv.org/abs/2508.03181)
> *分析德国议会演讲：一种用于主题和情感分类的机器学习方法*

*Lukas Pätz, Moritz Beyer, Jannik Späth, Lasse Bohlen, Patrick Zschech, Mathias Kraus, Julian Rosenberger* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 德国议会演讲, 机器学习, 主题分类, 情感分类, 政治话语

**Comment:** Accepted at 20th International Conference on Wirtschaftsinformatik
  (WI25); September 2025, M\"unster, Germany

> **TL;DR:** 本研究使用机器学习模型分析了约28,000份德国议会演讲，以揭示主题趋势、情感分布以及政党间的关系，发现执政职责会影响话语风格。

**AI_Comments:** 该论文创新性地将机器学习应用于大规模政治话语分析，为理解德国议会中政党的话语演变和动态提供了量化视角。其重要性在于揭示了政党角色（执政或反对）如何影响其言论风格，对于政治学和计算社会科学领域具有重要意义。抽象中未明确提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过分析德国议会的政治话语，理解主题演变、情感动态和政党特定的言论策略。

**Method:** 研究开发并训练了两个机器学习模型，用于主题和情感分类，使用了约28,000份手动标注的德国议会演讲数据集。

**Result:** 模型在主题分类上取得了0.94的AUROC（平均）表现，在情感分类上取得了0.89的AUROC表现。分析揭示了政党与议会角色之间显著的关系，特别是执政党转为反对党后风格的变化，并且执政职责会塑造话语。

**Conclusion:** 本分析直接解决了关于德国联邦议院主题演变、情感动态和政党特定话语策略的关键问题，并揭示了政党间话语的显著关系。

> **ai_Abstract:** 本研究利用机器学习方法，对约28,000份德国议会演讲进行了主题和情感分类分析。开发的模型在分类任务上表现出色（AUROC分别为0.94和0.89），并被用于探索各政党和时间维度上的主题趋势与情感分布。研究发现，政党间的关系显著，尤其是在从执政党转变为反对党时，其话语风格会发生变化，表明执政职责对政治话语具有塑造作用。

> **摘要翻译:** 本研究通过分析过去五年约28,000份德国议会演讲，调查了德国联邦议院的政治话语。开发了两个用于主题和情感分类的机器学习模型，并在手动标注的数据集上进行了训练。这些模型表现出强大的分类性能，主题分类（跨主题平均）的受试者工作特征曲线下面积（AUROC）达到0.94，情感分类达到0.89。这两个模型都被应用于评估各政党和随时间推移的主题趋势和情感分布。分析揭示了政党与其在议会中角色之间显著的关系。特别是，可以观察到政党从执政党转变为反对党时风格的变化。虽然意识形态立场很重要，但执政职责也塑造了话语。该分析直接解决了关于德国联邦议院主题演变、情感动态和政党特定话语策略的关键问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [395] [ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems](https://arxiv.org/abs/2503.20756)
> *ADS-Edit：一个用于自动驾驶系统的多模态知识编辑数据集*

*Chenxi Wang, Jizhan Fang, Xiang Chen, Bozhong Tian, Ziwen Xu, Huajun Chen, Ningyu Zhang* | **Category: cs.CL, cs.AI, cs.CV, cs.LG, cs.MM** | **Updated: 2025-08-05**

**Keywords:** 知识编辑, 自动驾驶系统, 多模态数据集, 大型多模态模型, ADS-Edit

**Comment:** ACM MM 2025

> **TL;DR:** 本文提出了ADS-Edit，一个多模态知识编辑数据集，以解决大型多模态模型在自动驾驶系统中面临的交通知识理解、复杂路况和车辆状态多样性等挑战。

**AI_Comments:** 本文创新性地提出了一个专门针对自动驾驶系统（ADS）的多模态知识编辑数据集ADS-Edit，以解决大型多模态模型（LMMs）在ADS应用中面临的实际挑战。通过知识编辑，可以在不进行昂贵的全模型重训练的情况下，对模型行为进行精确调整，这对于ADS的快速迭代和部署具有重要意义。该工作为知识编辑在自动驾驶领域的实际应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）在自动驾驶系统（ADS）中显示出潜力，但其直接应用受到交通知识误解、复杂路况和车辆状态多样性等挑战的阻碍。

**Method:** 提出使用知识编辑技术，无需完全重新训练即可对模型行为进行有针对性的修改。引入ADS-Edit，一个专为ADS设计的多模态知识编辑数据集，包含各种真实世界场景、多种数据类型和全面的评估指标。

**Result:** 进行了全面的实验，并得出了一些有趣的结论。

**Conclusion:** 希望这项工作能促进知识编辑在自动驾驶领域的进一步发展。

> **ai_Abstract:** 本研究旨在解决大型多模态模型在自动驾驶系统应用中遇到的交通知识理解、复杂路况和车辆状态多样性问题。为此，作者提出了一种知识编辑方法，并构建了一个名为ADS-Edit的多模态知识编辑数据集，该数据集涵盖了多种真实场景、数据类型和评估指标。实验结果表明该方法有效，并有望推动知识编辑在自动驾驶领域的应用。

> **摘要翻译:** 大型多模态模型（LMMs）的最新进展在自动驾驶系统（ADS）中显示出前景。然而，由于对交通知识的误解、复杂的道路状况和多样的车辆状态等挑战，它们在ADS中的直接应用受到了阻碍。为了解决这些挑战，我们提出使用知识编辑，它可以在不进行完全重新训练的情况下对模型的行为进行有针对性的修改。同时，我们引入了ADS-Edit，一个专门为ADS设计的多模态知识编辑数据集，其中包括各种真实世界场景、多种数据类型和全面的评估指标。我们进行了全面的实验并得出了一些有趣的结论。我们希望我们的工作将有助于知识编辑在自动驾驶领域应用的进一步发展。代码和数据可在https://github.com/zjunlp/EasyEdit/blob/main/examples/ADSEdit.md 获得。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [408] [NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty](https://arxiv.org/abs/2508.03294)
> *自然语言处理方法在评估问题难度方面可能优于教授*

*Leonidas Zotos, Ivo Pascal de Jong, Matias Valdenegro-Toro, Andreea Ioana Sburlea, Malvina Nissim, Hedderik van Rijn* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 问题难度估计, 考试评估, 监督学习, 自然语言处理

**Comment:** 10 pages, 2 figures, accepted at the 2nd International Workshop on AI
  in Society, Education and Educational Research (AISEER)

> **TL;DR:** 自然语言处理方法在预测考试问题难度方面优于教授。

**AI_Comments:** 这项研究创新性地将大型语言模型应用于教育评估领域，特别是问题难度估计，并提出了一个高效的监督学习框架。其重要性在于，它为提高考试质量和减轻教师负担提供了新的技术途径。仅用42个训练样本就达到优秀表现，显示出该方法的强大潜力和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 评估考试问题的难度对于开发高质量的考试至关重要，但教授并非总能很好地完成这项任务。

**Method:** 本研究比较了多种基于大型语言模型（LLM）的方法与三位教授在估计神经网络和机器学习领域的是非题学生正确率方面的能力。具体方法包括直接询问Gemini 2.5以及在监督学习设置下利用LLM解决问题的不确定性，其中监督学习仅使用了42个训练样本。

**Result:** 结果显示，教授区分简单和困难问题的能力有限，且表现不如直接询问Gemini 2.5。更进一步，使用LLM不确定性进行监督学习取得了甚至更好的结果。

**Conclusion:** 论文得出结论，结合大型语言模型不确定性的监督学习可以帮助教授更好地估计考试问题的难度，从而提高评估质量。

> **ai_Abstract:** 本研究旨在解决教授在评估考试问题难度方面存在的不足。通过比较大型语言模型（LLMs）方法与教授在预测是非题正确率上的表现，发现LLMs，特别是结合其不确定性进行监督学习的方法，在估计问题难度上显著优于教授，即使只使用少量训练数据也能取得良好效果。这表明LLM辅助的评估方法能有效提升考试质量。

> **摘要翻译:** 评估考试问题的难度对于开发高质量的考试至关重要，但教授并非总能很好地完成这项任务。我们比较了各种基于大型语言模型的方法与三位教授在估计神经网络和机器学习领域的是非题中学生正确回答的百分比方面的能力。我们的结果表明，教授区分简单和困难问题的能力有限，并且他们的表现不如直接要求Gemini 2.5解决这项任务。然而，我们使用LLM解决问题的不确定性在监督学习设置中获得了更好的结果，仅使用了42个训练样本。我们得出结论，使用LLM不确定性的监督学习可以帮助教授更好地估计考试问题的难度，从而提高评估质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [410] [GPT is Devastated and LLaMA is Content: Emotion Representation Alignment in LLMs for Keyword-based Generation](https://arxiv.org/abs/2503.11881)
> *GPT 崩溃，LLaMA 满足：LLM 中用于关键词生成的情感表征对齐*

*Shadab Choudhury, Asha Kumar, Lara J. Martin* | **Category: cs.CL** | **Updated: 2025-08-04**

**Keywords:** 情感表征对齐, 大型语言模型, 关键词生成, VAD, 人工评估

**Comment:** 

> **TL;DR:** 研究发现，在LLM中，人们在关键词引导的情感文本生成方面，对英语单词的理解比VAD量表更好。

**AI_Comments:** 这项研究创新性地引入了“表征对齐”的人工评估任务来量化LLM情感理解与人类期望之间的差距，并提供了关于不同情感表征（尤其是词汇与数值表示）在LLM中有效性的重要见解。其发现对于优化LLM在受控情感文本生成中的表现具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLM）的受控文本生成中，语言模型对概念的解释与人们的期望之间存在差距。

**Method:** 引入了“表征对齐”的人工评估任务来衡量LLM概念解释与人类期望的差距。选择了单词、以词汇和数字形式表达的效价-唤醒-主导度（VAD）维度以及表情符号四种情感表征。在GPT-4和LLaMA-3上，在关键词引导的句子生成背景下进行评估，并测量了生成句子的准确性和真实感。

**Result:** 研究发现，当以英语单词（例如“angry”）而非VAD量表为条件时，人们更认同LLM的生成方式，尤其在数字VAD与单词比较时差异显著。此外，生成的句子传达情感的感知取决于表征类型和具体情感。

**Conclusion:** 尽管VAD等表征将情感分解为易于计算的组件，但研究表明，对于关键词引导的情感生成，人类与LLM在基于英语单词的生成上的一致性更高，这表明简单的文本词汇在情感表征方面可能比复杂的数值维度更有效。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在关键词引导的情感文本生成中，其概念解释与人类期望之间的差距。通过引入“表征对齐”的人工评估任务，并比较单词、VAD维度和表情符号等四种情感表征，发现人们在基于英语单词（如“angry”）进行生成时与LLM的一致性更高，尤其与数字VAD相比。研究还表明，情感传达的感知受表征类型和具体情感的影响。

> **摘要翻译:** 在大型语言模型（LLM）的受控文本生成中，语言模型对概念的解释与人们的期望之间存在差距。我们引入了“表征对齐”的人工评估任务来衡量这种差距。我们选择了四种情感表征：单词、以词汇和数字形式表达的效价-唤醒-主导度（VAD）维度以及表情符号，并在GPT-4和LLaMA-3上，在关键词引导的句子生成背景下对它们进行了评估。除了表征对齐，我们还测量了人们对生成句子的准确性和真实感的判断。尽管VAD等表征将情感分解为易于计算的组件，但我们的发现表明，当以英语单词（例如“angry”）而非VAD量表为条件时，人们更认同LLM的生成方式。这种差异在数字VAD与单词比较时尤其明显。此外，我们发现生成的句子传达情感的感知取决于表征类型和具体情感。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [414] [Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models](https://arxiv.org/abs/2508.03199)
> *超越内容：语法性别如何影响文本到图像模型中的视觉表征*

*Muhammed Saeed, Shaina Raza, Ashmal Vayani, Muhammad Abdul-Mageed, Ali Emami, Shady Shehata* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 语法性别, 文本到图像模型, 偏见, 多语言, 视觉表征

**Comment:** 

> **TL;DR:** 文本到图像模型中的语法性别显著影响视觉输出，表明语言结构而非仅仅内容塑造了AI生成的图像。

**AI_Comments:** 这篇论文通过关注语法性别如何影响文本到图像模型的视觉输出，为AI偏见研究提供了一个新颖且重要的视角。其创新之处在于构建了一个独特的跨语言基准，专门针对语法性别与刻板印象性别矛盾的词汇，并揭示了语言深层结构对AI生成结果的系统性影响。这项工作强调了在开发和评估多语言、多模态AI系统时，不仅要考虑内容偏见，还要深入理解语言本身结构带来的潜在偏见，对AI公平性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于文本到图像（T2I）模型偏见的研究主要集中在人口统计学表征和刻板印象属性上，却忽视了一个基本问题：语法性别如何跨语言影响视觉表征。

**Method:** 研究引入了一个跨语言基准，检查了语法性别与刻板性别关联相矛盾的词汇。数据集涵盖五种有性别语言（法语、西班牙语、德语、意大利语、俄语）和两种无性别对照语言（英语、中文），包含800个独特提示，在三种最先进的T2I模型上生成了28,800张图像。

**Result:** 分析显示语法性别显著影响图像生成：阳性语法标记平均将男性表征增加到73%（相比中性英语的22%），而阴性语法标记将女性表征增加到38%（相比英语的28%）。这些影响系统地因语言资源可用性和模型架构而异，高资源语言显示出更强的影响。

**Conclusion:** 研究结果表明，语言结构本身，而不仅仅是内容，塑造了AI生成的视觉输出，为理解多语言、多模态系统中的偏见和公平性引入了一个新维度。

> **ai_Abstract:** 本研究探讨了文本到图像（T2I）模型中语法性别对视觉表征的影响，填补了现有偏见研究主要关注人口统计学属性的空白。通过构建一个涵盖七种语言（五种有性别，两种无性别）的跨语言基准数据集，并使用800个提示在三种SOTA T2I模型上生成了28,800张图像，研究发现语法性别显著影响图像生成。具体而言，阳性语法标记将男性表征平均提高到73%，而阴性语法标记将女性表征提高到38%。这些影响因语言资源和模型架构而异，在高资源语言中表现更强。研究最终指出，语言结构本身而非仅内容塑造了AI生成的视觉输出，为多语言、多模态系统中的偏见和公平性研究提供了新视角。

> **摘要翻译:** 对文本到图像（T2I）模型中偏见的研究主要集中在人口统计学表征和刻板印象属性上，忽略了一个基本问题：语法性别如何跨语言影响视觉表征？我们引入了一个跨语言基准，检查了语法性别与刻板性别关联相矛盾的词汇（例如，“une sentinelle”——法语中语法为阴性，但指代刻板印象中的男性概念“guard”）。我们的数据集涵盖五种有性别语言（法语、西班牙语、德语、意大利语、俄语）和两种无性别对照语言（英语、中文），包含800个独特提示，在三种最先进的T2I模型上生成了28,800张图像。我们的分析显示，语法性别显著影响图像生成：阳性语法标记平均将男性表征增加到73%（相比中性英语的22%），而阴性语法标记将女性表征增加到38%（相比英语的28%）。这些影响系统地因语言资源可用性和模型架构而异，高资源语言显示出更强的影响。我们的发现表明，语言结构本身，而不仅仅是内容，塑造了AI生成的视觉输出，为理解多语言、多模态系统中的偏见和公平性引入了一个新维度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [456] [Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP](https://arxiv.org/abs/2508.03204)
> *领域无关NLP中隐私保护文本预处理的现状*

*Abhirup Sinha, Pritilata Saha, Tithi Saha* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 隐私保护, 文本预处理, 领域无关NLP, 大型语言模型, 数据匿名化

**Comment:** To be published in the Proceedings of Die Studierendenkonferenz
  Informatik (SKILL) 2024

> **TL;DR:** 本报告探讨了在大型语言模型数据中保护隐私的文本预处理方法，因为私有信息可能从模型中被提取。

**AI_Comments:** 这篇论文似乎是一篇综述性文章，旨在梳理当前在保护NLP数据隐私方面的预处理技术。其创新性在于对现有方法的汇总和聚焦，重要性在于强调了数据隐私在AI时代的关键作用，并为未来研究指明方向。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型需要大量数据，其中常包含私人信息，且研究表明这些信息可能被提取。因此，匿名化这些私人和敏感信息至关重要。

**Method:** 本报告关注几种用于在文本数据中掩盖或假名化私人信息的预处理方法，特别是在领域无关的NLP任务中。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本报告讨论了在领域无关的自然语言处理任务中，如何通过文本预处理方法来保护数据隐私。鉴于大型语言模型训练数据中包含大量敏感信息且存在信息泄露风险，报告重点探讨了多种用于掩盖或假名化私人信息的预处理技术。

> **摘要翻译:** 隐私是一项基本人权。数据隐私受到不同法规的保护，例如GDPR。然而，现代大型语言模型需要大量数据来学习语言变异，而这些数据通常包含私人信息。研究表明，可以从这些语言模型中提取私人信息。因此，匿名化这些私人和敏感信息至关重要。虽然完全匿名化可能无法实现，但存在多种不同的预处理方法，用于在文本数据中掩盖或假名化私人信息。本报告重点介绍了几种适用于领域无关NLP任务的此类方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [457] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
> *弥合教育问答系统中大型语言模型与符号推理的鸿沟：来自IJCNN 2025 XAI挑战赛的启示*

*Long S. T. Nguyen, Khang H. N. Vo, Thu H. A. Nguyen, Tuan C. Bui, Duc Q. Nguyen, Thanh-Tung Tran, Anh D. Nguyen, Minh L. Nguyen, Fabien Baldacci, Thang H. Bui, Emanuel Di Nardo, Angelo Ciaramella, Son H. Le, Ihsan Ullah, Lorenzo Di Rocco, Tho T. Quan* | **Category: cs.CL, cs.AI, cs.LO** | **Updated: 2025-08-02**

**Keywords:** 可解释人工智能, 大型语言模型, 符号推理, 教育问答系统, 黑客马拉松

**Comment:** The XAI Challenge @ TRNS-AI Workshop, IJCNN 2025: Explainable AI for
  Educational Question Answering. Website:
  https://sites.google.com/view/trns-ai/challenge/

> **TL;DR:** 本文分析了XAI挑战赛2025，该挑战赛旨在构建可解释的教育问答系统，以弥合大型语言模型和符号推理之间的差距，并为未来的可解释人工智能教育系统提供见解。

**AI_Comments:** 本文通过介绍一个以XAI为核心的黑客马拉松式竞赛，创新性地探讨了LLMs与符号推理在教育问答系统中的结合，以提升透明度和可解释性。这种将理论研究与实践竞赛相结合的方式，不仅验证了技术的可行性，也为实际应用提供了宝贵的经验。特别是在数据集构建中引入逻辑验证和专家评审，确保了数据的质量和真实性，具有重要意义。该工作对于推动教育AI的可信赖发展具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在教育领域的日益融合，增强了对透明度和可解释性的需求。然而，很少有黑客马拉松直接解决教育领域真实世界的解释性人工智能（XAI）问题。

**Method:** 本文分析了2025年XAI挑战赛，这是一个由胡志明市理工大学和神经符号人工智能信任与可靠性国际研讨会（TRNS-AI）联合举办的黑客马拉松式竞赛。挑战赛要求参与者构建问答系统，能够回答学生关于大学政策的问题，并生成清晰、基于逻辑的自然语言解释。解决方案需要使用轻量级大型语言模型（LLMs）或混合LLM-符号系统。竞赛提供了一个高质量的数据集，该数据集通过基于逻辑的模板构建，并经过Z3验证和专家学生评审以确保与真实学术场景一致。文章描述了挑战赛的动机、结构、数据集构建和评估协议。

**Result:** 研究结果为未来以XAI为中心的教育系统和竞争性研究计划提供了可操作的见解。

**Conclusion:** 这项竞赛代表着一项新颖的尝试，旨在弥合大型语言模型和符号推理之间的鸿沟，以服务于可解释性，并为未来的XAI中心教育系统和竞争性研究计划提供了可操作的见解。

> **ai_Abstract:** 本文深入分析了2025年XAI挑战赛，该挑战赛旨在推动教育领域可解释AI（XAI）的发展。该比赛要求参赛者构建能够提供逻辑解释的教育问答系统，并鼓励使用轻量级大型语言模型或混合LLM-符号系统。文章详细介绍了挑战赛的结构、数据集构建和评估方法，并强调了其在弥合LLMs与符号推理之间差距以实现可解释性方面的创新性。研究结果为未来XAI教育系统和研究提供了宝贵见解。

> **摘要翻译:** 人工智能（AI）日益融入教育领域，使得对透明度和可解释性的需求日益增强。虽然黑客马拉松长期以来一直是快速AI原型开发的敏捷环境，但很少有直接解决真实教育环境中可解释AI（XAI）的问题。本文对2025年XAI挑战赛进行了全面分析，这是一项由胡志明市理工大学（HCMUT）和神经符号AI信任与可靠性国际研讨会（TRNS-AI）联合组织，作为国际神经网络联合会议（IJCNN 2025）一部分的黑客马拉松式竞赛。该挑战赛要求参与者构建问答（QA）系统，能够回答学生关于大学政策的查询，同时生成清晰、基于逻辑的自然语言解释。为了提高透明度和可信度，解决方案要求使用轻量级大型语言模型（LLMs）或混合LLM-符号系统。提供了一个高质量的数据集，该数据集通过基于逻辑的模板构建，并经过Z3验证，并通过专家学生评审进行完善，以确保与真实世界的学术场景保持一致。我们描述了挑战赛的动机、结构、数据集构建和评估协议。将这项竞赛置于AI黑客马拉松更广泛的演变背景中，我们认为它代表着一项新颖的努力，旨在弥合LLM和符号推理之间的鸿沟，以服务于可解释性。我们的研究结果为未来以XAI为中心的教育系统和竞争性研究计划提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [464] [Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling](https://arxiv.org/abs/2508.03296)
> *通过策略对齐推理和分层标注实现可信多模态内容审核*

*Anqi Li, Wenwei Jin, Jintao Tong, Pengda Qin, Weijia Li, Guo Lu* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 多模态审核, 策略对齐, 分层标注, 可信赖性, 内容安全

**Comment:** 

> **TL;DR:** 提出Hi-Guard框架，通过分层处理和策略对齐推理，提升多模态内容审核的准确性、可解释性和可信赖性。

**AI_Comments:** 该研究创新性地将策略对齐推理和分层标注引入多模态内容审核，解决了现有系统依赖噪声标签和决策不透明的痛点。其分层设计提高了效率，而策略对齐和GRPO优化则显著增强了模型的准确性、泛化能力和可解释性，对于大规模内容安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前社交平台内容审核系统依赖噪声标签，缺乏与审核规则对齐，导致决策不透明，阻碍人工审查，且难以大规模保证安全性和合规性。

**Method:** 提出Hi-Guard框架，包含两个核心“分层”设计：1) 分层审核流程：轻量级模型过滤安全内容，更强模型处理细粒度风险分类；2) 分层分类：第二阶段模型在粗到细粒度分层分类法上进行基于路径的分类。通过直接将规则定义融入模型提示，确保与政策对齐。引入多级软边距奖励并使用Group Relative Policy Optimization (GRPO) 进行优化，惩罚语义相邻的错误分类，提升解释质量。

**Result:** Hi-Guard在分类准确性、泛化能力和可解释性方面表现优异，并通过了大规模实验和实际部署验证。

**Conclusion:** Hi-Guard为可伸缩、透明和可信的内容安全系统铺平了道路。

> **ai_Abstract:** 本文提出Hi-Guard，一个多模态内容审核框架，旨在解决现有系统缺乏策略对齐和决策不透明的问题。Hi-Guard采用分层审核流程和分层分类法，并直接将审核规则整合到模型中，通过多级软边距奖励和GRPO优化，提升结构化预测和推理能力。实验和实际部署证明，Hi-Guard在准确性、泛化性和可解释性方面表现优越，为构建可信赖的内容安全系统提供了新途径。

> **摘要翻译:** 社交平台彻底改变了信息共享，但也加速了有害和违反政策内容的传播。为了大规模确保安全性和合规性，审核系统必须超越效率，提供准确性和可解释性。然而，当前方法主要依赖于嘈杂的、标签驱动的学习，缺乏与审核规则的对齐，并产生不透明的决策，阻碍了人工审查。因此，我们提出了分层卫士（Hi-Guard），一个多模态审核框架，引入了一种新的策略对齐决策范式。“分层”一词反映了我们系统设计的两个关键方面：（1）分层审核管道，其中一个轻量级二元模型首先过滤安全内容，一个更强的模型处理细粒度风险分类；（2）第二阶段的分层分类法，模型在从粗到细粒度的分层分类法上执行基于路径的分类。为了确保与不断演进的审核政策对齐，Hi-Guard直接将规则定义整合到模型提示中。为了进一步增强结构化预测和推理，我们引入了多级软边距奖励，并使用组相对策略优化（GRPO）进行优化，惩罚语义相邻的错误分类并提高解释质量。广泛的实验和实际部署表明，Hi-Guard实现了卓越的分类准确性、泛化能力和可解释性，为可扩展、透明和可信的内容安全系统铺平了道路。代码可在：https://github.com/lianqi1008/Hi-Guard 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [473] [Ensemble Learning for Large Language Models in Text and Code Generation: A Survey](https://arxiv.org/abs/2503.13505)
> *大型语言模型在文本和代码生成中的集成学习：一项综述*

*Mari Ashiga, Wei Jie, Fan Wu, Vardan Voskanyan, Fateme Dinmohammadi, Paul Brookes, Jingzhi Gong, Zheng Wang* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 集成学习, 文本生成, 代码生成, 综述

**Comment:** Under review by IEEE TAI

> **TL;DR:** 本文综述了大型语言模型（LLMs）在文本和代码生成中使用的集成学习方法，旨在解决LLMs输出不一致、偏差以及闭源限制等问题，并提升输出质量和应用灵活性。

**AI_Comments:** 这是一篇及时且重要的综述文章，它系统地梳理了LLM集成学习的现有方法，为解决当前单个LLM的局限性提供了方向。其创新之处在于对集成方法的细致分类和对关键优势的总结，这对于研究人员和实践者都具有很高的参考价值。未来，将这些集成策略扩展到多模态LLMs将是重要的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 单个大型语言模型（LLMs）在生成文本时常出现输出不一致和偏差，限制了其对多样化语言模式的表示。此外，许多强大的LLMs的闭源特性因数据隐私问题限制了其在工业中的应用。受文本生成成功的启发，LLM集成技术正越来越多地被探索用于代码生成。

**Method:** 本文综述了新兴的LLM集成方法，并将其分为七种主要方法：权重合并、知识融合、专家混合、奖励集成、输出集成、路由和级联。文章分析了这些方法的能力。

**Result:** 研究结果强调了LLM集成方法的关键优势，包括改进的多样性表示、增强的输出质量和更大的应用灵活性。这些见解有助于实际任务中的模型选择。

**Conclusion:** 本文为理解和促进LLM集成技术在文本和代码生成中的研究和实际应用奠定了基础，并为将集成策略扩展到多模态LLMs提供了指导。

> **ai_Abstract:** 本文对大型语言模型（LLMs）在文本和代码生成中的集成学习方法进行了全面综述。针对单个LLM存在的输出不一致、偏差以及闭源限制等问题，文章系统地分类并分析了权重合并、知识融合、专家混合、奖励集成、输出集成、路由和级联七种主要集成方法。研究强调了集成方法在提升多样性表示、改善输出质量和增加应用灵活性方面的显著优势，并为实际应用中的模型选择以及未来向多模态LLMs扩展提供了基础。

> **摘要翻译:** 生成式预训练Transformer (GPTs) 是文本生成的基础大型语言模型 (LLMs)。然而，单个LLMs通常会产生不一致的输出并表现出偏差，限制了它们对多样化语言模式的表示。许多强大LLMs的闭源性质进一步限制了其在工业应用中的使用，因为存在数据隐私问题。受文本生成成功的启发，LLM集成技术现在正越来越多地被探索用于代码生成。本文综述了这些新兴的集成方法，以增强理解、鼓励进一步研究并促进在文本和代码生成中的实际实施。我们将LLM集成分为七种主要方法——权重合并、知识融合、专家混合、奖励集成、输出集成、路由和级联——并分析了这些方法的能力。我们的发现突出了关键优势，例如改进的多样性表示、增强的输出质量和更大的应用灵活性。这些见解有助于实际任务中的模型选择，并且至关重要的是，为将集成策略扩展到多模态LLMs奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [492] [VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo](https://arxiv.org/abs/2508.02317)
> *VeOmni：使用以模型为中心的分布式配方库扩展任意模态模型训练*

*Qianli Ma, Yaowei Zheng, Zhelun Shi, Zhongkai Zhao, Bin Jia, Ziyue Huang, Zhiqi Lin, Youjie Li, Jiacheng Yang, Yanghua Peng, Zhi Zhang, Xin Liu* | **Category: cs.CL, cs.AI, cs.DC** | **Updated: 2025-08-05**

**Keywords:** 全模态LLM, 分布式训练, 3D并行, 模型中心, 深度学习框架

**Comment:** 

> **TL;DR:** VeOmni是一个模块化、高效的训练框架，通过解耦通信和计算，实现高效的3D并行，显著提高了全模态大型语言模型训练的效率和可扩展性。

**AI_Comments:** VeOmni的创新之处在于其“以模型为中心”的分布式配方，成功地将通信与计算解耦，这对于处理复杂且异构的全模态LLM架构至关重要。其3D并行能力和灵活的模态集成接口，使其成为一个通用且高效的训练解决方案，有望大幅降低全模态模型开发的门槛和成本。

<details>
  <summary>Details</summary>

**Motivation:** 训练全模态大型语言模型面临巨大挑战，因为需要处理多样化的模态，模型架构异构，且现有框架将模型定义与并行逻辑耦合，导致可扩展性有限和高昂的工程开销。

**Method:** 本文提出了VeOmni，一个模块化且高效的训练框架。VeOmni引入了以模型为中心的分布式配方，将通信与计算解耦，从而在全模态大型语言模型上实现高效的3D并行。它还具有灵活的配置接口，支持以最少的代码更改无缝集成新模态。

**Result:** 使用VeOmni，一个300亿参数的全模态混合专家（MoE）模型可以达到超过2,800 tokens/秒/GPU的吞吐量，并通过3D并行在128个GPU上扩展到160K上下文长度，展示了其在训练大型全模态LLM方面的卓越效率和可扩展性。

**Conclusion:** VeOmni通过其模块化设计、通信与计算解耦以及高效的3D并行能力，显著提升了全模态大型语言模型的训练效率和可扩展性，有效解决了现有框架的局限性。

> **ai_Abstract:** VeOmni是一个为全模态大型语言模型训练设计的模块化且高效的框架。它通过引入以模型为中心的分布式配方，将通信与计算解耦，从而实现了高效的3D并行。该框架解决了现有系统模型定义与并行逻辑耦合导致的可扩展性差和工程开销大的问题。实验表明，VeOmni能够以高吞吐量训练大型全模态MoE模型，并支持长上下文长度，显著提升了训练效率和可扩展性。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展推动了全模态理解和生成的显著进步。然而，由于处理多样化模态所需的异构模型架构，训练全模态LLM仍然是一个重大挑战，这需要复杂的系统设计来实现高效的大规模训练。现有框架通常将模型定义与并行逻辑纠缠在一起，导致端到端全模态训练的可扩展性有限和巨大的工程开销。我们提出了VeOmni，一个模块化且高效的训练框架，旨在加速全模态LLM的开发。VeOmni引入了以模型为中心的分布式配方，将通信与计算解耦，从而在全模态LLM上实现高效的3D并行。VeOmni还具有灵活的配置接口，支持以最少的代码更改无缝集成新模态。使用VeOmni，一个300亿参数的全模态混合专家（MoE）模型可以达到超过2,800 tokens/秒/GPU的吞吐量，并通过3D并行在128个GPU上扩展到160K上下文长度，展示了其在训练大型全模态LLM方面的卓越效率和可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [494] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
> *ReaGAN：节点即智能体推理图智能体网络*

*Minghao Guo, Xi Zhu, Jingyuan Huang, Kai Mei, Yongfeng Zhang* | **Category: cs.CL, cs.LG, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 图神经网络, 智能体, 检索增强生成, 节点级规划, 图学习

**Comment:** 17 pages, work in progress

> **TL;DR:** ReaGAN是一个基于智能体的图神经网络框架，通过节点级规划和检索增强生成来解决传统GNN的信息不平衡和局部性问题。

**AI_Comments:** ReaGAN的创新之处在于将“节点即智能体”的概念引入图神经网络，通过赋予节点自主决策和规划能力，以及结合检索增强生成（RAG）来解决传统GNN面临的信息不平衡和局部性限制。这种方法提升了模型捕获全局语义关系和自适应传播信息的能力，并且在不微调LLM骨干的情况下取得了良好性能，为图学习提供了一个新颖且有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统图神经网络（GNNs）在信息传播中存在两个主要限制：1) 无法处理节点信息丰富度不平衡的问题；2) 预定义的消息传递机制主要利用局部结构相似性，忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。

**Method:** 本文提出了检索增强图智能体网络（ReaGAN），一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为一个独立智能体，根据其内部记忆独立规划下一步动作，实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容并在图中建立全局关系。

**Result:** ReaGAN在少量样本的上下文设置下，使用冻结的LLM骨干模型无需微调即可获得具有竞争力的性能。

**Conclusion:** ReaGAN展示了智能体规划和局部-全局检索在图学习中的潜力。

> **ai_Abstract:** 本文提出了ReaGAN，一个新颖的基于智能体的图神经网络框架，旨在解决传统GNN在处理节点信息不平衡和捕获全局语义关系方面的局限性。ReaGAN赋予每个节点独立的决策能力，使其作为智能体进行节点级规划和自适应消息传播，并利用检索增强生成（RAG）机制来建立图中的全局语义联系。实验结果表明，ReaGAN在少量样本设置下，使用未微调的LLM骨干模型也能达到有竞争力的表现，突显了智能体规划和局部-全局检索在图学习中的潜力。

> **摘要翻译:** 图神经网络（GNNs）通过预定义聚合机制在邻居节点间传播信息，在基于图的学习中取得了显著成功。然而，这种固定的方案常常面临两个关键限制。首先，它们无法处理节点信息丰富度的不平衡——一些节点信息丰富，而另一些则稀疏。其次，预定义的消息传递主要利用局部结构相似性，同时忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。我们提出了检索增强图智能体网络（ReaGAN），一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为一个智能体，根据其内部记忆独立规划下一步动作，从而实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容并在图中建立全局关系。ReaGAN在少量样本的上下文设置下，使用冻结的LLM骨干模型无需微调即可获得具有竞争力的性能，展示了智能体规划和局部-全局检索在图学习中的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [501] [Listening to the Unspoken: Exploring "365" Aspects of Multimodal Interview Performance Assessment](https://arxiv.org/abs/2507.22676)
> *倾听未言之语：探索多模态面试表现评估的“365”维度*

*Jia Li, Yang Wang, Wenhao Qian, Jialong Hu, Zhenzhen Hu, Richang Hong, Meng Wang* | **Category: cs.CL, cs.MM** | **Updated: 2025-08-05**

**Keywords:** 多模态, 面试表现评估, 特征融合, 集成学习, 自动化评估

**Comment:** 8 pages, 4 figures, ACM MM 2025.
  github:https://github.com/MSA-LMC/365Aspects

> **TL;DR:** 本文提出一个新颖的多模态面试表现评估框架，通过整合视频、音频和文本等三种模态，以及每个候选人的六个回答和五个关键评估维度，实现了对面试表现的“365”方面探索。该框架在AVI Challenge 2025中获得第一名，证明了其在自动化和多模态面试评估中的有效性和鲁棒性。

**AI_Comments:** 该论文创新性地提出了“365”维度评估框架，融合了多种模态数据（视频、音频、文本），并通过先进的特征融合（共享压缩多层感知器）和两级集成学习策略提升了评估的全面性和鲁棒性。其在AVI Challenge 2025中取得第一名的成绩，证明了其在实际应用中的巨大潜力，有望推动自动化面试评估领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 面试表现评估对于确定候选人是否适合专业职位至关重要。为了确保全面和公正的评估，本文旨在提出一个新颖且全面的框架。

**Method:** 本文提出了一个新颖全面的框架，通过整合三种模态（视频、音频、文本）、每个候选人的六个回答和五个关键评估维度，探索面试表现的“365”个方面。该框架采用模态特定特征提取器编码异构数据流，并通过共享压缩多层感知器进行融合。为增强预测鲁棒性，还引入了两级集成学习策略：独立回归头预测每个回答的分数，然后使用均值池化机制聚合预测结果以生成五个目标维度的最终分数。

**Result:** 该框架实现了0.1824的多维度平均MSE，并在AVI Challenge 2025中获得第一名，证明了其在推进自动化多模态面试表现评估方面的有效性和鲁棒性。

**Conclusion:** 通过捕获多模态数据中的显式和隐式线索，本文提出的方法实现了全面和无偏见的评估，有效推进了自动化多模态面试表现评估。

> **ai_Abstract:** 本文提出了一种新颖的多模态面试表现评估框架，通过整合视频、音频和文本三种模态，以及对每个候选人六个回答的五个关键维度进行评估，探索了“365”个评估方面。该框架利用模态特定特征提取器和共享压缩多层感知器融合数据，并采用两级集成学习策略提高预测鲁棒性。实验结果显示，该框架在多维度平均MSE上达到0.1824，并在AVI Challenge 2025中荣获第一，展现了其在自动化和多模态面试评估中的卓越性能和鲁棒性。

> **摘要翻译:** 面试表现评估对于确定候选人是否适合专业职位至关重要。为了确保全面和公正的评估，我们提出了一个新颖且全面的框架，通过整合三种模态（视频、音频和文本）、每个候选人的六个回答和五个关键评估维度，探索面试表现的“365”个方面。该框架采用模态特定特征提取器编码异构数据流，随后通过共享压缩多层感知器进行融合。此模块将多模态嵌入压缩到统一的潜在空间中，从而促进高效的特征交互。为了增强预测鲁棒性，我们引入了两级集成学习策略：(1) 独立的回归头预测每个回答的分数，(2) 使用均值池化机制在回答之间聚合预测结果，以生成五个目标维度的最终分数。通过倾听未言之语，我们的方法从多模态数据中捕获显式和隐式线索，从而实现全面和无偏见的评估。我们的框架实现了0.1824的多维度平均MSE，并在AVI Challenge 2025中获得第一名，证明了其在推进自动化和多模态面试表现评估方面的有效性和鲁棒性。完整实现可在https://github.com/MSA-LMC/365Aspects获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [505] [Probing Syntax in Large Language Models: Successes and Remaining Challenges](https://arxiv.org/abs/2508.03211)
> *探测大型语言模型中的句法：成功与挑战*

*Pablo J. Diego-Simón, Emmanuel Chemla, Jean-Rémi King, Yair Lakretz* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 句法, 结构探针, 基准测试, 挑战

**Comment:** 

> **TL;DR:** 本文深入分析了结构探针在大型语言模型中表示句法结构的有效性。研究发现，结构探针受词语距离和深层句法结构挑战，但不受词语可预测性影响，揭示了当前结构探针的局限性。

**AI_Comments:** 本文通过引入受控基准，系统性地评估了结构探针在大型语言模型中探测句法结构的能力，弥补了以往研究中评估数据集不区分的不足。其创新之处在于揭示了结构探针的潜在偏见（如对距离的敏感性）和局限性（对深层句法的捕捉不足），为未来设计更鲁棒的探针提供了明确的方向。这项工作对于理解LLMs内部表示机制，特别是句法知识的编码方式，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）的激活可以揭示句法结构，但现有“结构探针”通常在不加区分的句子集上进行评估，导致不清楚结构和/或统计因素是否系统性地影响这些句法表示。

**Method:** 通过对三个受控基准进行结构探针的深入分析。

**Result:** 结果有三方面：1. 结构探针受表层属性（词语距离）偏向，距离越近越可能被认为是句法相关。2. 结构探针受语言属性挑战，对深层句法结构表示不佳，并受交互名词或非语法动词形式干扰。3. 结构探针似乎不受单个词语可预测性的影响。

**Conclusion:** 这项工作揭示了结构探针当前面临的挑战，并提供了一个由受控刺激组成的基准来更好地评估它们的性能。

> **ai_Abstract:** 本文深入探讨了大型语言模型中用于揭示句法结构的“结构探针”的有效性。通过在三个受控基准上进行分析，研究发现结构探针易受词语距离等表层特征的影响，难以准确捕捉深层句法结构，并受到特定语言现象的干扰。然而，词语的可预测性似乎不影响其表现。研究结果揭示了当前结构探针在探测LLM句法表示方面面临的挑战，并强调了使用受控基准进行评估的重要性。

> **摘要翻译:** 句子的句法结构可以很容易地从大型语言模型（LLMs）的激活中读取出来。然而，用于揭示这种现象的“结构探针”通常在不加区分的句子集上进行评估。因此，目前尚不清楚结构和/或统计因素是否系统地影响这些句法表示。为了解决这个问题，我们对三个受控基准上的结构探针进行了深入分析。我们的结果有三方面。首先，结构探针受到一个表层属性的偏向：句子中两个词语的距离越近，结构探针越可能认为它们在句法上相关。其次，结构探针受到语言属性的挑战：它们对深层句法结构的表示很差，并受到交互名词或非语法动词形式的干扰。第三，结构探针似乎不受单个词语可预测性的影响。总的来说，这项工作揭示了结构探针当前面临的挑战，并提供了一个由受控刺激组成的基准，以更好地评估它们的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [513] [CTTS: Collective Test-Time Scaling](https://arxiv.org/abs/2508.03333)
> *CTTS：集体测试时缩放*

*Zhende Song, Shengji Tang, Peng Ye, Jiayuan Fan, Tao Chen* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 测试时缩放, 集体智能体, 大语言模型, 多智能体协作, 多奖励模型

**Comment:** 

> **TL;DR:** 本文首次探索集体测试时缩放（CTTS），通过设计多智能体和多奖励模型协作的CTTS-MM框架，显著提升大语言模型的推理效果。

**AI_Comments:** 本文创新性地将“集体”概念引入测试时缩放领域，突破了传统单智能体方法的局限。通过系统地探索不同的协作范式并提出CTTS-MM框架，为提升大语言模型推理能力提供了一条新颖且高效的途径，尤其是在不进行额外训练的前提下。其提出的Agent Collaboration Search和Mixture of Reward Models机制具有通用性，有望启发未来在多模型协作方面的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测试时缩放（TTS）方法（如Best-of-N和Self-Consistency）主要依赖单智能体与奖励模型交互，受限于单智能体测试时缩放（STTS）范式的能力。然而，集体智能体方法已被证明可以突破单智能体系统的上限。

**Method:** 本文首次探索集体测试时缩放（CTTS），设计了三种主要范式（SA-MR, MA-SR, MA-MR）来寻找最优CTTS范式。基于MA-MR的最佳表现，提出了CTTS-MM框架，该框架有效利用多智能体和多奖励模型协作。具体地，对于多智能体协作，提出了智能体协作搜索（ACS）；对于多奖励模型协作，提出了奖励模型混合（MoR），包括一个精选问题池和通过成对奖励排名（PRR）指标选择最优奖励模型组合的先验奖励模型集成选择（PRES）。

**Result:** 实验表明，MA-MR范式始终表现最佳。所提出的CTTS-MM框架在七个主流基准测试中持续获得卓越性能。

**Conclusion:** 本文首次探索了集体测试时缩放（CTTS），并提出了CTTS-MM框架，通过有效结合多智能体和多奖励模型协作，显著提升了大语言模型的推理能力。

> **ai_Abstract:** 本文首次探索了集体测试时缩放（CTTS），旨在通过多智能体和多奖励模型协作来提升大语言模型的性能，而无需额外训练。研究设计并比较了不同的CTTS交互范式，发现多智能体到多奖励模型（MA-MR）的效果最佳。在此基础上，提出了CTTS-MM框架，该框架包含用于多智能体协作的智能体协作搜索（ACS）和用于多奖励模型协作的奖励模型混合（MoR），后者结合了精选问题池和先验奖励模型集成选择（PRES）。实验证明CTTS-MM在多个基准测试中表现优异。

> **摘要翻译:** 测试时缩放（TTS）已成为一个有前景的研究领域，旨在不额外训练的情况下增强大型语言模型（LLMs）的有效性。然而，大多数现有方法，例如Best-of-N和Self-Consistency，都依赖于单个智能体与奖励模型（SA-SR）交互，受限于单智能体测试时缩放（STTS）范式的有限能力。另一方面，最近的研究表明，集体智能体方法可以通过协调多样化的模型来突破单智能体系统的上限。因此，在本文中，我们首次探索集体测试时缩放（CTTS）。考虑到单个和多个模型的不同交互类型，我们设计了三种主要范式来研究CTTS的最佳范式：（1）单智能体到多奖励模型（SA-MR）；（2）多智能体到单奖励模型（MA-SR）；以及（3）多智能体到多奖励模型（MA-MR）。广泛的实验表明，MA-MR始终能取得最佳性能。在此基础上，我们提出了一种名为CTTS-MM的新颖框架，它有效地利用多智能体和多奖励模型协作来增强推理。具体而言，对于多智能体协作，我们提出了智能体协作搜索（ACS），它从大量的候选池中搜索最有效的LLM智能体组合；对于多奖励模型协作，我们提出了奖励模型混合（MoR），它由一个精选问题池和通过成对奖励排名（PRR）指标选择最优奖励模型组合的先验奖励模型集成选择（PRES）组成。在七个主流基准测试中的实验表明，所提出的CTTS-MM持续获得卓越性能。代码将发布在https://github.com/magent4aci/CTTS-MM。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [514] [Why do LLMs attend to the first token?](https://arxiv.org/abs/2504.02732)
> *为什么大型语言模型会关注第一个token？*

*Federico Barbero, Álvaro Arroyo, Xiangming Gu, Christos Perivolaropoulos, Michael Bronstein, Petar Veličković, Razvan Pascanu* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 注意力汇, 信息混合, Transformer, 注意力模式

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）倾向于严重关注序列中的第一个token（即注意力汇），本文从理论和经验上论证了这是一种避免过度混合的机制。

**AI_Comments:** 这项研究通过回答“为什么”LLMs会学习注意力汇这一核心问题，提供了对LLM内部机制的更深层次理解，具有重要的理论和实践意义。它将注意力汇与信息传播中的“过度混合”问题联系起来，为理解Transformer的注意力模式提供了新的视角。实验验证了理论，并探讨了实际因素的影响，有助于未来的模型设计和优化。

<details>
  <summary>Details</summary>

**Motivation:** 许多研究已经详细探讨了LLM中注意力汇现象，并提出了利用或缓解它的方法。注意力汇与量化困难、安全问题和流式注意力有关。然而，尽管许多工作提供了它们发生或不发生的条件，但一个关键问题仍未得到深入解答：为什么LLMs会学习这种模式以及它们是如何被使用的？本文旨在回答这个问题。

**Method:** 本文结合理论和经验方法。理论上，将注意力汇机制与信息如何在Transformer中传播的现有工作联系起来。经验上，通过实验验证了理论直觉，并展示了上下文长度、深度和数据打包等选择如何影响注意力汇行为。

**Result:** 研究表明，注意力汇提供了一种让LLMs避免过度混合的方法。

**Conclusion:** 这项研究为注意力汇在LLMs中为何有用提供了一个新的实用视角，有助于更好地理解训练过程中形成的注意力模式。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）中普遍存在的“注意力汇”现象，即LLMs倾向于高度关注序列的第一个token。针对“为什么LLMs会学习并使用这种模式”这一未解答的关键问题，研究从理论和经验两方面论证，注意力汇是LLMs避免信息过度混合的一种机制。通过实验，论文验证了其理论直觉，并分析了上下文长度、深度和数据打包等因素对注意力汇行为的影响，旨在提供一个关于注意力汇效用的新视角。

> **摘要翻译:** 大型语言模型（LLMs）倾向于严重关注序列中的第一个token——形成所谓的注意力汇。许多工作已经详细研究了这种现象，提出了各种利用或缓解它的方法。注意力汇与量化困难、安全问题和流式注意力有关。然而，尽管许多工作提供了它们发生或不发生的条件，但一个关键问题仍未得到深入解答：为什么LLMs会学习这种模式以及它们是如何被使用的？在这项工作中，我们从理论和经验上论证，这种机制为LLMs提供了一种避免过度混合的方法，并将其与现有研究Transformer中信息如何数学传播的系列工作联系起来。我们进行实验以验证我们的理论直觉，并展示了上下文长度、深度和数据打包等选择如何影响注意力汇行为。我们希望这项研究能为注意力汇在LLMs中为何有用提供一个新的实用视角，从而更好地理解训练过程中形成的注意力模式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [544] [Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs](https://arxiv.org/abs/2504.06219)
> *高性能LLM能否符合伦理？量化网络爬取选择退出的影响*

*Dongyang Fan, Vinko Sabolčec, Matin Ansaripour, Ayush Kumar Tarun, Martin Jaggi, Antoine Bosselut, Imanol Schlag* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 数据合规性, 网络爬取, 性能, 版权

**Comment:** COLM 2025 Camera Ready version

> **TL;DR:** 研究发现，截至2025年1月，遵守网络数据爬取选择退出并不会降低通用LLM的性能，但在生物医学等专业领域，排除主要出版商会导致性能下降。

**AI_Comments:** 这项研究通过引入“数据合规性差距”这一概念，首次量化了数据合规性对LLM性能的实际影响，具有创新性。它为AI伦理和数据使用政策提供了重要的实证依据，揭示了通用与专业领域模型在数据需求上的差异，对未来LLM的训练实践和政策制定具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着版权方越来越多地采用网络爬取选择退出，需要了解数据合规性如何影响大型语言模型（LLM）的性能，以及这些限制对模型能力的影响尚不明确。

**Method:** 提出了“数据合规性差距”（DCG）的概念，量化了遵守和不遵守网络爬取选择退出数据集训练的模型之间的性能差异。在从头预训练和从现有合规模型进行持续预训练两种设置下测量了DCG，并使用1.5B模型进行实验。

**Result:** 截至2025年1月，遵守网络数据选择退出对通用知识获取没有影响（DCG接近0%）。但在生物医学等专业领域，排除主要出版商会导致性能下降。

**Conclusion:** 通用LLM可以使用完全开放的数据进行训练并达到同等性能，但专业领域的性能可能受益于在训练后期访问高质量的受版权保护的数据源。这项研究为数据合规性与模型性能之间的权衡提供了实证见解。

> **ai_Abstract:** 本研究探讨了网络爬取选择退出对大型语言模型（LLM）性能的影响，引入了“数据合规性差距”（DCG）来量化合规性对模型能力的影响。实验表明，截至2025年1月，遵守数据退出规则对通用LLM的知识获取没有负面影响。然而，在生物医学等专业领域，排除主要出版商的数据会导致性能下降。研究结论是，通用LLM可以利用开放数据良好训练，但专业领域可能需要后期访问受版权保护的高质量数据。

> **摘要翻译:** 在线内容版权所有者越来越多地采用网络爬取选择退出，这引发了关于数据合规性对大型语言模型（LLM）性能影响的关键问题。然而，对于这些限制（以及由此导致的预训练数据集的过滤）如何影响使用这些语料库训练的模型的能力，人们知之甚少。在这项工作中，我们将这种影响概念化为“数据合规性差距”（DCG），它量化了在遵守网络爬取选择退出的数据集上训练的模型与不遵守的数据集上训练的模型之间的性能差异。我们在两种设置下测量了数据合规性差距：从头预训练模型和从现有合规模型进行持续预训练（模拟了在预训练后期可以整合受版权保护数据的情况）。我们对1.5B模型的实验表明，截至2025年1月，遵守网络数据选择退出不会降低通用知识获取（DCG接近0%）。然而，在生物医学等专业领域，排除主要出版商会导致性能下降。这些发现表明，虽然通用LLM可以使用完全开放的数据进行训练以达到同等性能，但专业领域的性能可能受益于在训练后期访问高质量的受版权保护的来源。我们的研究为数据合规性与下游模型性能之间长期争论的权衡提供了实证见解，为未来关于AI训练实践和政策决策的讨论提供了信息。我们的网站可在 https://data-compliance.github.io/ 访问。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [548] [Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature](https://arxiv.org/abs/2508.03358)
> *Taggus：一个从葡萄牙语小说中提取人物社交网络的自动化流程*

*Tiago G Canário, Catarina Duarte, Flávio L. Pinheiro, João L. M. Pereira* | **Category: cs.CL, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 人物社交网络, 葡萄牙语小说, 自动化流程, 自然语言处理, 词性标注

**Comment:** 24 pages, 5 Figures, 4 Tables

> **TL;DR:** Taggus是一个自动化流程，用于从葡萄牙语小说中提取人物及其社交网络，它结合了词性标注和启发式方法，在人物识别、共指消解和交互检测方面表现优于现有SOTA工具。

**AI_Comments:** Taggus的创新之处在于其针对低资源语言（葡萄牙语）的文学作品，结合词性标注和启发式方法来构建人物社交网络，而非单纯依赖难以获取的标注数据。其在F1分数上对现有SOTA工具的显著提升（50.7%和22.3%）证明了其方法的有效性。尽管存在测试样本大小和范围的局限性，但该工作的开源性对推动葡萄牙语文学NLP领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从小说中自动识别人物及其互动是一项复杂的任务，需要利用多种自然语言处理（NLP）方法，但现有方法（特别是对于低资源语言）由于缺乏手动标注数据而表现不佳。

**Method:** 本文提出了一个名为Taggus的自动化流程，用于从葡萄牙语文学作品中提取社交网络。该流程结合了词性标注（POS tagging）和一系列启发式方法，以识别人物并解决共指问题，以及检测人物间的互动。

**Result:** Taggus流程在人物识别和共指消解任务中达到了94.1%的平均F1分数，在交互检测中达到75.9%的F1分数。与现有的SOTA工具（现成NER工具和大型语言模型ChatGPT）相比，这些结果分别提高了50.7%和22.3%。

**Conclusion:** Taggus管道在从葡萄牙语小说中提取人物社交网络方面取得了令人满意的结果，并显著优于现有最先进的工具，为葡萄牙语在该领域的发展提供了新的解决方案。

> **ai_Abstract:** 本文提出了一种名为Taggus的自动化流程，旨在从葡萄牙语小说中提取人物社交网络。针对现有NLP方法在人物社交网络构建任务中表现不佳，尤其是在低资源语言中缺乏标注数据的问题，Taggus结合了词性标注和启发式方法。实验结果显示，Taggus在人物识别和共指消解方面取得了94.1%的F1分数，在交互检测方面取得了75.9%的F1分数，相比现有SOTA工具（如NER和ChatGPT）有显著提升。该流程已公开发布，以促进葡萄牙语在该领域的研究与发展。

> **摘要翻译:** 从小说中自动识别人物及其互动可以说是一项复杂的任务，它需要利用多种自然语言处理（NLP）方法，如命名实体识别（NER）和词性标注（POS tagging）。然而，这些方法并未针对构建人物社交网络这一任务进行优化。事实上，由于缺乏用于训练的手动标注数据，目前可用的方法往往表现不佳，尤其是在代表性不足的语言中。本文提出了一个名为Taggus的流程，用于从葡萄牙语文学作品中提取社交网络。我们的结果表明，与现有的最先进工具——现成NER工具和大型语言模型（ChatGPT）——相比，该流程（它使用了词性标注和一系列启发式方法的组合）在识别人物和解决共指问题上取得了94.1%的平均F1分数，在交互检测上取得了75.9%的F1分数，达到了令人满意的结果。这分别比现有最先进工具的结果提高了50.7%和22.3%。文中还概述了进一步改进结果的步骤，例如检测人物之间关系的解决方案。论文承认了测试样本大小和范围的局限性。Taggus流程已公开发布，以鼓励葡萄牙语在该领域的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [567] [The Multi-Round Diagnostic RAG Framework for Emulating Clinical Reasoning](https://arxiv.org/abs/2504.07724)
> *模拟临床推理的多轮诊断RAG框架*

*Penglei Sun, Yixiang Chen, Xiang Li, Xiaowen Chu* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 医疗诊断, RAG, 知识图谱, 大型语言模型, 临床推理

**Comment:** 

> **TL;DR:** 提出多轮诊断RAG框架（MRD-RAG）和知识图谱（DiagnosGraph），以弥合患者描述与医学知识之间的语义鸿沟，提高医疗LLM的诊断准确性。

**AI_Comments:** 本文的创新点在于同时从数据（构建DiagnosGraph）和方法（提出MRD-RAG框架）两个维度解决了医疗RAG领域的核心挑战——语义鸿沟问题。DiagnosGraph通过整合中西医知识和规范化病历，为RAG提供了高质量的知识基础；MRD-RAG通过模拟医生多轮问诊的临床推理过程，使得诊断更加精细和人性化。这对于提升医疗LLM的实际应用价值具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有医疗RAG在实际部署中面临挑战，即患者口语化描述与医学知识库专业术语之间的语义鸿沟，这阻碍了RAG在医疗诊断中的实际应用。

**Method:** 从数据和方法两方面解决问题。数据方面，构建了DiagnosGraph知识图谱，涵盖现代医学和中医药，并引入1908份规范化的病历来连接口语化叙述与学术医学知识。方法方面，提出了多轮诊断RAG（MRD-RAG）框架，通过多轮对话模拟医生临床推理过程，以细化诊断可能性。

**Result:** 在四个医学基准测试上进行实验，并由人类医生评估，结果表明MRD-RAG显著提升了LLM的诊断性能，使其更准确且更符合人类诊断习惯。

**Conclusion:** MRD-RAG框架通过模拟临床推理并结合通用知识图谱，有效弥合了医疗RAG中的语义鸿沟，提高了自动化诊断的准确性和人性化程度，具有巨大的应用潜力。

> **ai_Abstract:** 本文针对医疗RAG中患者口语描述与专业医学术语之间的语义鸿沟问题，提出了两项创新：一是构建了DiagnosGraph通用医学知识图谱，其中包含规范化的病历数据以弥合语言差距；二是引入了多轮诊断RAG（MRD-RAG）框架，通过模拟医生多轮对话的临床推理过程来细化诊断。实验证明MRD-RAG显著提升了LLM的诊断准确性和与人类诊断的一致性。

> **摘要翻译:** 近年来，准确快速地部署医学大型语言模型（LLM）已成为一种趋势。其中，检索增强生成（RAG）因其快速部署和隐私保护而受到关注。然而，阻碍RAG在医疗诊断中实际部署的挑战是：口语化的患者描述与医学知识库中的专业术语之间的语义鸿沟。我们试图从数据和方法角度解决这一挑战。首先，为了解决现有知识库中的语义鸿沟，我们构建了DiagnosGraph，一个涵盖现代医学和中医药的通用知识图谱。它包含876种常见疾病，图谱包含7,997个节点和37,201个三元组。为了弥合口语化患者叙述与学术医学知识之间的差距，DiagnosGraph还通过规范化患者主诉并提出医学诊断，引入了1,908份病历。其次，我们引入了多轮诊断RAG（MRD-RAG）框架。它利用多轮对话来细化诊断可能性，模拟医生的临床推理。在四个医学基准测试上进行实验，并由人类医生评估，结果表明MRD-RAG增强了LLM的诊断性能，突显了其使自动化诊断更准确、更符合人类习惯的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [583] [Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models](https://arxiv.org/abs/2508.03363)
> *思考与非思考校准：推理大型语言模型中一种新的上下文学习范式*

*Haotian Wu, Bo Xu, Yao Shu, Menglin Yang, Chengwei Qin* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 上下文学习, 推理大型语言模型, 思考与非思考校准, JointThinking, 推理准确性

**Comment:** 

> **TL;DR:** 提出一种名为JointThinking的新上下文学习范式，通过结合“思考”和“非思考”两种模式来提高推理大型语言模型的准确性和鲁棒性，且具有低延迟和良好扩展性。

**AI_Comments:** 该论文提出了一种新颖的上下文学习范式，通过引入“思考”和“非思考”两种模式进行校准，有效提升了推理大型语言模型的性能。其创新点在于利用模式间的结构化差异进行一致性检查和二次思考，尤其是在大多数情况下只进行一轮推理，保证了低延迟。此外，其在分布外任务上的优越表现和良好的可扩展性也凸显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注推理大型语言模型的训练和推理策略，而其在上下文学习（ICL）方面的潜力仍未被充分探索。

**Method:** 提出“思考与非思考校准”（JointThinking）这一新的上下文学习范式。该方法让模型并行生成两种模式（思考和非思考）的答案。仅当两种答案不一致时，才触发第二轮思考，利用包含原始问题和两个候选答案的单一提示进行。由于不一致情况发生频率低，多数情况下只需一轮推理，延迟开销小。

**Result:** JointThinking在多个推理基准测试中显著优于少样本思维链（CoT）和多数投票，并提升了答案的鲁棒性。其在分布内任务上表现与基于训练的SOTA方法相当，在分布外任务上则大幅超越。通过利用不同的推理模式，错误率持续降低，且随着模型规模增大，第二轮思考的性能差距缩小，表明该方法具有强大的可扩展性。

**Conclusion:** JointThinking是一种有效且可扩展的推理大型语言模型上下文学习新范式，通过结构化地利用不同推理模式显著提升了推理准确性和鲁棒性，并为未来的ICL研究提供了新方向。

> **ai_Abstract:** 本文提出了一种名为“思考与非思考校准”（JointThinking）的新型上下文学习（ICL）范式，旨在提升推理大型语言模型（RLLMs）的推理准确性。该方法通过并行生成“思考”和“非思考”两种模式的答案，并仅在两者不一致时触发第二轮思考进行校准。实验表明，JointThinking在多个推理基准上显著优于现有少样本方法，并展现出强大的鲁棒性、与SOTA训练方法相当的分布内性能，以及在分布外任务上的卓越表现。该方法具有低延迟和良好的可扩展性，并通过对校准机制的分析，强调了结构化思维多样性的价值。

> **摘要翻译:** 推理大型语言模型（RLLMs）最近通过结构化和多步推理展示了卓越的能力。虽然先前的研究主要集中于改进其训练和推理策略，但其上下文学习（ICL）的潜力在很大程度上仍未被充分探索。为了填补这一空白，我们提出了思考与非思考校准（JointThinking），这是一种新的ICL范式，它利用两种推理模式（即思考和非思考）之间的结构化差异来提高推理准确性。具体而言，我们的方法提示模型并行生成两个答案：一个在思考模式下，另一个在非思考模式下。只有当两个初始响应不一致时，才会触发第二轮思考，使用一个包含原始问题和两个候选答案的单一提示。由于这种不一致情况很少发生（例如，在GSM8K中仅为6%），我们的方法在大多数情况下只执行一轮推理，从而导致最小的延迟开销。在多个推理基准上进行的广泛实验表明，JointThinking显著优于少样本思维链（CoT）和多数投票，并提高了答案的鲁棒性。此外，它在分布内性能上与基于训练的SOTA方法相当，同时在分布外任务上表现出色。我们进一步对校准机制进行了系统分析，表明利用不同的推理模式持续降低了错误率，并突出了结构化思维多样性的价值。此外，我们观察到，随着模型规模的增加，第二轮思考中实际推理与理想推理之间的性能差距缩小，这表明了我们方法强大的可扩展性。最后，我们讨论了当前的局限性，并概述了未来RLLMs中ICL研究的有前景方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [598] [Reconstructing Sepsis Trajectories from Clinical Case Reports using LLMs: the Textual Time Series Corpus for Sepsis](https://arxiv.org/abs/2504.12326)
> *使用大型语言模型从临床病例报告中重建脓毒症轨迹：脓毒症文本时间序列语料库*

*Shahriar Noroozizadeh, Jeremy C. Weiss* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 脓毒症, 时间序列, 病例报告, 临床发现

**Comment:** 

> **TL;DR:** 使用大型语言模型（LLMs）从临床病例报告中提取脓毒症时间序列数据，并构建了一个新的开放获取语料库，以弥补现有临床数据的时间滞后和不完整性。

**AI_Comments:** 这项工作创新性地利用大型语言模型从非结构化临床文本中提取时间序列信息，为脓毒症研究提供了宝贵的数据集。其重要性在于弥补了现有临床数据在完整性和时间粒度上的不足，为训练更精确的临床模型奠定了基础。同时，研究也坦诚指出了LLMs在时间重建方面的当前局限性，并提出了多模态集成这一未来改进方向，这对于推动LLMs在医疗领域的应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 临床病例报告虽然完整但时间滞后，而结构化数据虽然及时却不完整。为了训练模型和算法使用更完整、时间粒度更细的数据，需要一种方法从病例报告中获取时间序列数据。

**Method:** 本研究构建了一个利用大型语言模型（LLMs）的管道，用于表型分类、提取和标注病例报告中的时间定位发现。该管道应用于Pubmed-开放获取（PMOA）子集中的2,139份病例报告，生成了Sepsis-3的开放获取文本时间序列语料库。为了验证系统，研究将其应用于PMOA和来自I2B2/MIMIC-IV的时间线标注，并将结果与医生专家标注进行比较。

**Result:** 系统显示出高临床发现恢复率（事件匹配率：O1-preview--0.755，Llama 3.3 70B Instruct--0.753）和强大的时间排序能力（一致性：O1-preview--0.932，Llama 3.3 70B Instruct--0.932）。

**Conclusion:** 该工作揭示了大型语言模型在文本中进行临床发现时间定位的能力，同时也说明了大型语言模型用于时间重建的局限性，并提出了通过多模态集成改进的几种潜在途径。

> **ai_Abstract:** 本研究旨在解决临床病例报告时间滞后和结构化数据不完整的问题，通过开发一个基于大型语言模型（LLMs）的管道，从2,139份脓毒症病例报告中提取并标注时间定位的临床发现，构建了一个名为“脓毒症文本时间序列语料库”的开放获取数据集。验证结果显示，该系统在临床发现恢复率和时间排序方面表现出色，并指出了LLMs在时间重建中的局限性及多模态集成的改进潜力。

> **摘要翻译:** 临床病例报告和出院总结可能是患者就诊最完整、最准确的总结，但它们是在就诊后才最终确定，即加盖时间戳。补充结构化数据流虽然更早可用，但存在不完整性。为了训练模型和算法使用更完整、时间粒度更细的数据，我们构建了一个流程，利用大型语言模型对病例报告中的时间定位发现进行表型分类、提取和标注。我们将此流程应用于生成一个开放获取的Sepsis-3文本时间序列语料库，该语料库包含来自Pubmed-开放获取（PMOA）子集的2,139份病例报告。为了验证我们的系统，我们将其应用于PMOA和来自I2B2/MIMIC-IV的时间线标注，并将结果与医生专家标注进行比较。我们展示了临床发现的高恢复率（事件匹配率：O1-preview--0.755，Llama 3.3 70B Instruct--0.753）和强大的时间排序能力（一致性：O1-preview--0.932，Llama 3.3 70B Instruct--0.932）。我们的工作揭示了大型语言模型在文本中时间定位临床发现的能力，说明了大型语言模型用于时间重建的局限性，并提供了通过多模态集成改进的几种潜在途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [612] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
> *大型语言模型对患者提出的医疗问题提供不安全的答案*

*Rachel L. Draelos, Samina Afreen, Barbara Blasko, Tiffany L. Brazile, Natasha Chase, Dimple Patel Desai, Jessica Evert, Heather L. Gardner, Lauren Herrmann, Aswathy Vaikom House, Stephanie Kass, Marianne Kavan, Kirshma Khemani, Amanda Koire, Lauren M. McDonald, Zahraa Rabeeah, Amy Shah* | **Category: cs.CL, cs.HC** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 医疗建议, 患者安全, 聊天机器人, 红队测试

**Comment:** 20 pages

> **TL;DR:** 大型语言模型聊天机器人对患者提出的医疗问题提供不安全的答案，存在严重患者安全隐患。

**AI_Comments:** 这项研究通过系统性的红队测试，首次量化了主流大型语言模型在医疗咨询方面的潜在风险，具有重要的临床和公共卫生意义。其创新之处在于构建了HealthAdvice数据集和评估框架，为后续LLM在医疗领域的安全研究提供了基础。研究结果警示了当前LLM在医疗应用中的局限性，并强调了在广泛部署前进行严格验证和改进的必要性，尤其是在涉及患者生命健康的关键领域。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于数百万患者已定期使用大型语言模型（LLM）聊天机器人寻求医疗建议，这引发了对患者安全的担忧。

**Method:** 这项由医生主导的红队研究，使用一个新的数据集HealthAdvice和一个评估框架，比较了四种公开可用的聊天机器人（Claude, Gemini, GPT-4o, Llama3-70B）的安全性。总共评估了222个患者提出的寻求建议的初级保健医疗问题（涵盖内科、妇科和儿科）的888个聊天机器人回复，进行定量和定性分析。

**Result:** 聊天机器人之间存在统计学上的显著差异。问题回复率从21.6%（Claude）到43.2%（Llama）不等，不安全回复率从5%（Claude）到13%（GPT-4o, Llama）不等。定性结果显示，聊天机器人的回复有可能导致严重的患者伤害。

**Conclusion:** 这项研究表明，数百万患者可能从公开可用的聊天机器人那里获得不安全的医疗建议，需要进一步的工作来提高这些强大工具的临床安全性。

> **ai_Abstract:** 本研究通过一项由医生主导的红队测试，评估了四种主流大型语言模型聊天机器人（Claude, Gemini, GPT-4o, Llama3-70B）在回答患者医疗问题时的安全性。研究使用了HealthAdvice数据集，对222个问题共888个回复进行了定量和定性分析。结果显示，各聊天机器人之间存在显著差异，问题回复率和不安全回复率较高，且定性分析揭示了可能导致严重患者伤害的回复。研究强调，数百万患者可能正在接收不安全的医疗建议，亟需提升这些工具的临床安全性。

> **摘要翻译:** 数百万患者已定期使用大型语言模型（LLM）聊天机器人寻求医疗建议，这引发了对患者安全的担忧。这项由医生主导的红队研究，使用一个新的数据集HealthAdvice和一个能够进行定量和定性分析的评估框架，比较了四种公开可用的聊天机器人——Anthropic的Claude、Google的Gemini、OpenAI的GPT-4o和Meta的Llama3-70B——的安全性。总共评估了222个患者提出的寻求建议的初级保健医疗问题（涵盖内科、妇科和儿科）的888个聊天机器人回复。我们发现聊天机器人之间存在统计学上的显著差异。问题回复率从21.6%（Claude）到43.2%（Llama）不等，不安全回复率从5%（Claude）到13%（GPT-4o、Llama）不等。定性结果显示，聊天机器人的回复有可能导致严重的患者伤害。这项研究表明，数百万患者可能从公开可用的聊天机器人那里获得不安全的医疗建议，需要进一步的工作来提高这些强大工具的临床安全性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [617] [ReDSM5: A Reddit Dataset for DSM-5 Depression Detection](https://arxiv.org/abs/2508.03399)
> *ReDSM5：一个用于DSM-5抑郁症检测的Reddit数据集*

*Eliseo Bao, Anxo Pérez, Javier Parapar* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 抑郁症检测, DSM-5, Reddit数据集, 心理健康, 可解释性

**Comment:** Accepted as a resource paper at CIKM 2025

> **TL;DR:** ReDSM5是一个Reddit数据集，包含1484个长篇帖子，由持证心理学家在句子层面针对DSM-5的九种抑郁症症状进行详尽标注，旨在促进开发可解释的抑郁症检测模型。

**AI_Comments:** ReDSM5数据集的创新之处在于其对社交媒体文本进行精细的句子级标注，并将其与DSM-5的九种具体抑郁症症状关联起来，同时提供专家临床理由。这显著提升了抑郁症检测模型的可解释性和临床相关性，弥补了现有方法仅进行粗粒度分类的不足。该数据集对于推动自然语言处理在心理健康领域的应用具有重要意义，尤其是在开发可信赖和透明的AI诊断辅助工具方面。

<details>
  <summary>Details</summary>

**Motivation:** 抑郁症是一种普遍的精神健康问题，许多病例因传统临床障碍和普遍存在的耻辱感而未被诊断。现有计算方法在检测抑郁症时，缺乏将语言与DSM-5特定标准联系起来，限制了临床相关性和可解释性。

**Method:** 研究引入了ReDSM5数据集，包含1484个Reddit长篇帖子，由持证心理学家在句子层面根据DSM-5的九种抑郁症症状进行详尽标注，并提供临床理由。研究对该集合进行了探索性分析，检查了词汇、句法和情感模式，并为多标签症状分类和解释生成建立了基线基准。

**Result:** ReDSM5独特地结合了症状特异性监督和专家解释，促进了能够检测抑郁症并生成人类可解释推理的模型的开发。研究为多标签症状分类和解释生成建立了基线基准。

**Conclusion:** ReDSM5数据集通过提供症状特异性标注和专家解释，为开发可解释的抑郁症检测模型提供了独特的资源，并为未来的研究提供了基线。

> **ai_Abstract:** 该论文介绍了ReDSM5，一个新颖的Reddit数据集，旨在解决现有抑郁症检测计算方法缺乏临床可解释性的问题。ReDSM5包含1484个Reddit长篇帖子，由持证心理学家在句子层面根据DSM-5的九种抑郁症症状进行详尽标注，并附有临床理由。该数据集通过结合症状特异性监督和专家解释，旨在促进开发能够检测抑郁症并提供可解释推理的模型。研究还对数据集进行了探索性分析，并为多标签症状分类和解释生成建立了基线基准，为未来的研究提供了参考。

> **摘要翻译:** 抑郁症是一种普遍的精神健康状况，影响着全球数亿人，但由于传统临床就医的障碍和普遍存在的耻辱感，许多病例仍未被诊断。社交媒体平台，尤其是Reddit，提供了丰富的用户生成叙述，可以揭示抑郁症症状的早期迹象。然而，现有的计算方法通常只是简单地将整个帖子标记为抑郁或非抑郁，而没有将语言与DSM-5（诊断抑郁症的标准临床框架）的特定标准联系起来。这限制了临床相关性和可解释性。为了解决这一空白，我们引入了ReDSM5，这是一个新颖的Reddit语料库，包含1484篇长篇帖子，每篇都由一位持证心理学家在句子层面针对DSM-5的九种抑郁症症状进行了详尽标注。对于每个标签，标注者还提供了基于DSM-5方法的简洁临床理由。我们对该集合进行了探索性分析，检查了社交媒体叙述中表征症状表达的词汇、句法和情感模式。与之前的资源相比，ReDSM5独特地结合了症状特异性监督和专家解释，促进了不仅能检测抑郁症还能生成人类可解释推理的模型的开发。我们为多标签症状分类和解释生成建立了基线基准，为未来关于检测和可解释性的研究提供了参考结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [632] [Energy-Based Reward Models for Robust Language Model Alignment](https://arxiv.org/abs/2504.13134)
> *基于能量的奖励模型用于鲁棒语言模型对齐*

*Anamika Lochab, Ruqi Zhang* | **Category: cs.CL, cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 奖励模型, 语言模型对齐, 鲁棒性, 泛化, 基于能量模型

**Comment:** Accepted by COLM 2025

> **TL;DR:** 引入了基于能量的奖励模型（EBRM），一个轻量级的后处理框架，旨在提高奖励模型（RMs）的鲁棒性和泛化能力，通过显式建模奖励分布、冲突感知数据过滤、标签噪声感知对比训练和混合初始化实现，无需重新训练。实验证明其在对齐任务中显著提升性能并延迟奖励破解。

**AI_Comments:** EBRM的创新之处在于其无需重新训练即可提升现有奖励模型的性能，这大大提高了其计算效率和应用灵活性。通过显式建模奖励分布和处理噪声数据，它有效解决了奖励模型在复杂偏好捕获和泛化方面的常见挑战。该方法对于LLM对齐领域具有重要意义，尤其是在需要高效且鲁棒的奖励模型时。

<details>
  <summary>Details</summary>

**Motivation:** 奖励模型（RMs）在对齐大型语言模型（LLMs）与人类偏好方面至关重要，但它们通常难以捕捉复杂的人类偏好并泛化到未见过的数据。

**Method:** 我们引入了基于能量的奖励模型（EBRM），一个轻量级的后处理改进框架，用于增强RM的鲁棒性和泛化能力。EBRM显式地建模奖励分布，捕捉人类偏好的不确定性，并减轻噪声或未对齐标注的影响。它通过冲突感知数据过滤、标签噪声感知对比训练和混合初始化来实现这一点。值得注意的是，EBRM无需重新训练即可增强RM。

**Result:** 在RM基准测试上的实证评估表明，在鲁棒性和泛化能力方面都有显著改进，与标准RM相比，在安全关键对齐任务中实现了高达5.97%的改进。此外，强化学习实验证实，我们改进的奖励增强了对齐质量，有效延迟了奖励破解。

**Conclusion:** 这些结果表明我们的方法是现有RM和对齐流水线的一种可扩展且有效的增强。

> **ai_Abstract:** 本文提出了一种名为能量奖励模型（EBRM）的轻量级后处理框架，旨在解决现有奖励模型在捕捉复杂人类偏好和泛化方面的不足。EBRM通过显式建模奖励分布、冲突感知数据过滤、标签噪声感知对比训练和混合初始化来提高奖励模型的鲁棒性和泛化能力，且无需重新训练。实验结果表明，EBRM在对齐任务中显著提升了性能，尤其是在安全关键任务中，并能有效延迟奖励破解，证明了其作为现有奖励模型和对齐流程的有效且可扩展的增强方案。

> **摘要翻译:** 奖励模型（RMs）对于将大型语言模型（LLMs）与人类偏好对齐至关重要。然而，它们常常难以捕捉复杂的人类偏好并泛化到未见过的数据。为了解决这些挑战，我们引入了基于能量的奖励模型（EBRM），一个轻量级的后处理改进框架，旨在提高RM的鲁棒性和泛化能力。EBRM显式地建模奖励分布，捕捉人类偏好的不确定性，并减轻噪声或未对齐标注的影响。它通过冲突感知数据过滤、标签噪声感知对比训练和混合初始化来实现这一点。值得注意的是，EBRM无需重新训练即可增强RM，这使得它在计算上高效且可适应不同的模型和任务。在RM基准测试上的实证评估表明，在鲁棒性和泛化能力方面都有显著改进，与标准RM相比，在安全关键对齐任务中实现了高达5.97%的改进。此外，强化学习实验证实，我们改进的奖励增强了对齐质量，有效延迟了奖励破解。这些结果表明我们的方法是现有RM和对齐流水线的一种可扩展且有效的增强。代码可在EBRM获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [654] [Science Hierarchography: Hierarchical Organization of Science Literature](https://arxiv.org/abs/2504.13834)
> *科学分层图谱：科学文献的层级组织*

*Muhan Gao, Jash Shah, Weiqi Wang, Daniel Khashabi* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 科学文献组织,层级结构,嵌入式聚类,大型语言模型,LLM代理

**Comment:** 

> **TL;DR:** 本研究提出了一种名为“科学分层图谱”的新方法，通过结合嵌入式聚类和大型语言模型（LLM）提示，将科学文献组织成一个多层次的层级结构，以更好地理解科学领域的发展情况，并提高了LLM导航和检索文献的能力。

**AI_Comments:** 该研究提出的“科学分层图谱”方法在解决科学文献组织和探索的挑战方面具有创新性。通过结合嵌入式聚类和LLM提示的混合方法，在效率和准确性之间取得了良好的平衡。该方法不仅有助于理解科学领域的发展，还为LLM在文献检索和分析方面的应用开辟了新的可能性。然而，对于该层级结构的具体构建细节和评估指标的深入分析，以及其在不同科学领域的可推广性，还有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 当前科学知识增长迅速，难以跟踪跨学科进展和高级概念联系。现有的工具（如引用网络和搜索引擎）缺乏足够的抽象能力来表示不同子领域活动密度和结构。

**Method:** 开发了一种结合嵌入式聚类和大型语言模型（LLM）提示的混合方法，以平衡可扩展性和语义精度，构建多层次的科学文献层级结构。

**Result:** 所提出的方法在质量-速度权衡方面优于仅使用LLM的方法，并且能够有效地帮助基于LLM的代理导航层级结构以定位目标论文，提高了可解释性，并提供了探索科学文献的新途径。

**Conclusion:** 科学分层图谱方法通过构建多层次的文献层级结构，能够提供对科学领域发展情况的洞察，并能有效地帮助LLM代理导航和定位文献，优于现有方法，为探索科学文献提供了新的可能。

> **ai_Abstract:** 本研究提出了一种名为“科学分层图谱”的新方法，旨在将科学文献组织成一个多层次的层级结构，以应对科学知识快速增长带来的挑战。该方法结合了嵌入式聚类和大型语言模型（LLM）提示，实现了可扩展性和语义精度的平衡，并优于纯LLM方法。实验表明，该层级结构能有效辅助LLM代理导航和定位文献，提高了可解释性，为探索科学文献提供了新途径。

> **摘要翻译:** 科学知识正在迅速增长，使得跟踪进展和跨广泛学科的高级概念联系变得困难。像引用网络和搜索引擎这样的工具虽然有助于检索相关论文，但它们缺乏捕获跨子领域活动密度和结构所需的抽象能力。
我们提出了“科学分层图谱”（SCIENCE HIERARCHOGRAPHY）的动机，其目标是将科学文献组织成一个高质量的层级结构，该结构跨越多个抽象级别——从广泛的领域到具体的研究。这种表示可以提供对哪些领域已被充分探索以及哪些领域尚未得到充分探索的见解。为了实现这一目标，我们开发了一种混合方法，该方法结合了高效的基于嵌入的聚类和基于 LLM 的提示，在可扩展性和语义精度之间取得了平衡。与迭代树构建等重 LLM 的方法相比，我们的方法实现了卓越的质量-速度权衡。我们的层级结构捕捉了研究贡献的不同维度，反映了现代科学的跨学科和多方面性质。我们通过衡量基于 LLM 的代理在多大程度上能够有效地导航层级结构来定位目标论文来评估其效用。结果表明，我们的方法提高了可解释性，并提供了超越传统搜索方法探索科学文献的替代途径。
代码、数据和演示可在以下网址获取：
https://github.com/JHU-CLSP/science-hierarchography

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [655] [Variety Is the Spice of Life: Detecting Misinformation with Dynamic Environmental Representations](https://arxiv.org/abs/2508.03420)
> *多样性是生活的调味品：利用动态环境表示检测虚假信息*

*Bing Wang, Ximing Li, Yiming Wang, Changchun Li, Jiaxu Cui, Renchu Guan, Bo Yang* | **Category: cs.CL, cs.SI** | **Updated: 2025-08-05**

**Keywords:** 虚假信息检测, 动态环境表示, 时间模型, LSTM, ODE

**Comment:** Accepted by CIKM 2025. 11 pages, 4 figures. Code:
  https://github.com/wangbing1416/MISDER

> **TL;DR:** 本文提出了一种名为MISDER的新框架，通过学习动态的社会环境表示来检测虚假信息，并证明其有效性。

**AI_Comments:** 这篇论文的创新点在于它认识到虚假信息检测中的动态性问题，并提出了一个能捕捉环境变化的框架。它打破了传统静态学习范式的局限性，通过引入动态环境表示和时间模型，更贴近现实世界中信息真实性波动的复杂性。这对于提高虚假信息检测的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虚假信息在社交媒体上泛滥并造成有害影响，自动检测虚假信息（MD）成为热门研究。然而，主流MD方法假设环境是静态的，这在真实世界中并不成立，因为新闻的真实性可能随动态演变的社会环境而波动。

**Method:** 提出了一种名为动态环境表示虚假信息检测（MISDER）的新框架。MISDER的核心思想是学习每个时期的社会环境表示，并使用时间模型来预测未来时期的表示。具体地，时间模型被指定为LSTM模型、连续动力学方程和预训练动力学系统，从而提出了MISDER的三种变体：MISDER-LSTM、MISDER-ODE和MISDER-PT。

**Result:** 在两个流行的数据集上，将MISDER与各种MD基线进行了比较，实验结果表明所提出的模型是有效的。

**Conclusion:** 所提出的MISDER模型能够有效应对虚假信息检测中动态环境的挑战，并优于现有的静态方法。

> **ai_Abstract:** 本文提出了一种名为MISDER的新颖框架，用于解决在动态变化的社会环境中检测虚假信息的问题。与将虚假信息检测视为静态学习任务的主流方法不同，MISDER通过学习每个时期的社会环境表示并利用时间模型（如LSTM、ODE或预训练动力学系统）预测未来表示，从而捕捉新闻真实性的动态变化。实验结果表明，该模型在两个广泛使用的数据集上优于现有基线方法，证明了其在动态虚假信息检测方面的有效性。

> **摘要翻译:** 虚假信息在各种社交媒体平台上的泛滥已引起学术界和工业界的广泛关注，因为它具有有害影响。因此，自动区分虚假信息，即虚假信息检测（MD），已成为一个日益活跃的研究课题。主流方法将MD视为一种静态学习范式，学习新闻文章的内容、链接和传播与相应人工真实性标签之间的映射。然而，静态假设经常被违反，因为在现实场景中，新闻文章的真实性可能会在动态演变的社会环境中波动。为了解决这个问题，我们提出了一种新颖的框架，即利用动态环境表示的虚假信息检测（MISDER）。MISDER的基本思想在于学习每个时期的社会环境表示，并采用时间模型来预测未来时期的表示。在这项工作中，我们将时间模型指定为LSTM模型、连续动力学方程和预训练动力学系统，从而提出了MISDER的三种变体，即MISDER-LSTM、MISDER-ODE和MISDER-PT。为了评估MISDER的性能，我们将其与两个流行数据集上的各种MD基线进行了比较，实验结果表明我们提出的模型是有效的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [694] [LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models](https://arxiv.org/abs/2508.03440)
> *大型语言模型（LLMs）拥有石头般的心：揭示大型推理模型的软思维能力*

*Junhong Wu, Jinliang Lu, Zixuan Ren, Ganqiang Hu, Zhi Wu, Dai Dai, Hua Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 软思维, 大型语言模型, 推理能力, 随机性, Gumbel-Softmax

**Comment:** 10 pages, 7 figures, working in progress

> **TL;DR:** 大型语言模型（LLMs）在处理抽象概念时，其“软思维”能力被高估了。尽管“软思维”旨在实现更灵活的推理，但模型倾向于依赖输入中最具影响力的部分，导致推理路径单一，类似于贪婪解码。通过引入 Dirichlet 重采样或 Gumbel-Softmax 等随机性策略，可以克服这一局限，释放“软思维”的潜力，其中 Gumbel-Softmax 在八个推理基准测试中表现尤为出色。

**AI_Comments:** 该研究揭示了LLMs在“软思维”方面的潜在局限性，即模型可能过度依赖输入中最具影响力的部分，而非充分利用软标记的优势。引入随机性策略，特别是Gumbel-Softmax，被证明是解决这一问题的有效方法。然而，对于“软思维”的“软性”和“随机性”之间的权衡，以及这种方法在更广泛的推理任务中的泛化能力，仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在处理抽象和流动的概念时能力有限，因为它们通常依赖于生成离散的标记。为了解决这个问题，研究旨在使LLMs能够生成软的、抽象的标记，以便在连续的概念空间中进行推理。

**Method:** 通过一系列探测技术，检查了LLMs的内部行为，以探索其“软思维”能力。为了解决“软思维”的局限性，研究人员探索了引入随机性的采样策略，如Dirichlet重采样和Gumbel-Softmax技巧。

**Result:** 研究发现，LLMs在“软思维”过程中，主要依赖于软输入中最具影响力的部分，而不是同时探索多种推理路径。这种依赖性限制了“软思维”的优势，使其类似于贪婪解码。然而，通过引入随机性，特别是使用Gumbel-Softmax技巧，可以缓解这些限制，并在八个推理基准测试中取得更好的性能。

**Conclusion:** 虽然“软思维”的初衷是通过软标记传递更多信息以实现更灵活的推理，但LLMs的实际行为表明它们倾向于选择最有影响力的输入部分，这限制了其推理能力。通过引入随机性，如Gumbel-Softmax技巧，可以克服这一限制，并有效利用“软思维”的潜力，在各种推理任务中取得更好的结果。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）的“软思维”能力，指出它们在处理抽象概念时，倾向于依赖输入中最具影响力的部分，而非广泛探索多种推理路径。研究通过引入随机性采样策略（如Gumbel-Softmax）来克服这一局限，实验证明该方法能有效提升LLMs在推理任务中的表现。

> **摘要翻译:** 人类认知自然地涉及抽象和流动的概念，而现有的推理模型通常依赖于生成离散的标记，这可能会限制它们表达能力。近期的进展旨在通过使大型语言模型（LLMs）能够生成软的、抽象的标记来解决这一限制，从而促进在连续概念空间中的推理。本文通过使用一套探测技术，检查模型内部行为，探讨了各种LLMs的“软思维”能力。与普遍认为“软思维”能够同时探索多种推理路径的观点相反，我们的研究结果表明，LLMs在后续的解码步骤中主要依赖于软输入中最具影响力的部分。这种依赖性阻碍了不同推理路径的探索，并将普通的“软思维”简化为一种贪婪解码的形式，模糊了通过软标记传递更多信息的好处。为了解决这个问题，我们探索了引入“随机性”的采样策略，采用了Dirichlet重采样和Gumbel-Softmax技巧等方法。我们的实验表明，引入随机性可以缓解普通方法的局限性，并释放“软思维”的潜力。值得注意的是，Gumbel-Softmax技巧提供了足够的随机性，并具有可控的平滑度，在八个推理基准测试中表现出优越的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [696] [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org/abs/2504.17720)
> *大型语言模型在教育领域的多语言性能偏差*

*Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型,教育,多语言性能,语言偏见,低资源语言

**Comment:** 

> **TL;DR:** 大型语言模型在教育领域的表现因语言而异，低资源语言的表现较差，建议部署前进行验证。

**AI_Comments:** 该研究强调了在教育领域部署多语言LLM时，评估语言偏见和性能差异的重要性。研究结果表明，低资源语言的LLM表现不佳，这可能加剧教育不平等。未来的研究可以探索如何改进LLM在低资源语言上的表现，以及开发更公平的评估方法。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）在教育领域的广泛应用，需要评估其在非英语语言环境下的表现，以确定其适用性。

**Method:** 评估了流行LLM在八种非英语语言（包括中文、印地语、阿拉伯语、德语、波斯语、泰卢固语、乌克兰语、捷克语）和英语上的四项教育任务（识别学生误解、提供针对性反馈、互动辅导、翻译评分）的表现。

**Result:** LLM在教育任务上的表现与训练数据中的语言代表量有一定相关性，低资源语言的表现较差。尽管模型在大多数语言上表现尚可，但与英语相比，性能下降明显。

**Conclusion:** 在教育领域部署LLM之前，应先验证其在目标语言和特定教育任务上的性能。

> **ai_Abstract:** 本研究评估了大型语言模型（LLM）在八种非英语语言及英语上的教育任务表现，发现模型性能与训练数据中的语言代表量相关，低资源语言表现较差。尽管在多数语言上表现尚可，但与英语相比存在显著性能下降。研究建议在教育领域部署LLM前，应先验证其在目标语言和具体任务上的表现。

> **摘要翻译:** 大型语言模型（LLM）正越来越多地被应用于教育领域。这些应用已超出了英语的范畴，尽管当前的LLM仍主要以英语为中心。在本研究中，我们旨在确定其在非英语语言教育环境中的使用是否合理。我们评估了流行LLM在八种语言（中文、印地语、阿拉伯语、德语、波斯语、泰卢固语、乌克兰语、捷克语）以及英语上的四项教育任务的表现：识别学生误解、提供针对性反馈、互动辅导和翻译评分。我们发现，在这些任务上的表现与训练数据中语言的代表量有一定程度的对应关系，低资源语言的任务表现较差。尽管模型在大多数语言上的表现尚可，但与英语相比，频繁出现的性能下降是显著的。因此，我们建议实践者在部署前，首先验证LLM在目标语言上针对其教育任务的运行效果是否良好。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [730] [RIVAL: Reinforcement Learning with Iterative and Adversarial Optimization for Machine Translation](https://arxiv.org/abs/2506.05070)
> *RIVAL：用于机器翻译的具有迭代和对抗性优化的强化学习*

*Tianjiao Li, Mengran Yu, Chenyu Shi, Yanjun Zhao, Xiaojing Liu, Qiang Zhang, Qi Zhang, Xuanjing Huang, Jiayin Wang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 机器翻译, 强化学习, 对抗性训练, 分布偏移, 人类反馈

**Comment:** 

> **TL;DR:** 将RLHF应用于字幕翻译任务时，由于离线奖励模型与在线LLM之间的分布偏移，导致性能不佳。提出了一种名为RIVAL的对抗性训练框架，通过将奖励模型和LLM之间的过程公式化为最小-最大博弈来解决此问题，其中奖励模型学会区分翻译质量，而LLM则学会缩小差距。通过结合定性和定量奖励以及参考免费的质量建模，RIVAL在翻译任务上显著优于基线。

**AI_Comments:** 该研究提出了一种新颖的对抗性训练框架（RIVAL），以解决在机器翻译（特别是字幕翻译）中使用RLHF时出现的分布偏移问题。通过将奖励模型和LLM之间的训练过程公式化为最小-最大博弈，并结合定性和定量奖励，该方法有效地提高了翻译质量。该研究的贡献在于识别并解决了RLHF在特定翻译任务中的局限性，并提供了一个更稳定、更通用的解决方案。然而，该方法在计算成本和实际部署方面的效率仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 将RLHF应用于字幕翻译任务时，发现其性能不佳，原因是离线奖励模型（RM）与在线LLM之间存在分布偏移，导致了不良的训练结果。

**Method:** 提出了一种名为RIVAL的对抗性训练框架，将奖励模型（RM）和大型语言模型（LLM）之间的过程公式化为最小-最大博弈。RM被训练来区分强弱翻译（定性偏好奖励），而LLM被训练来提高其翻译以缩小差距。为了稳定训练和提高泛化能力，还引入了定量偏好奖励（如BLEU）到RM中，实现了与人类评估一致的无参考质量建模。

**Result:** 通过广泛的实验证明，所提出的对抗性训练框架显著优于翻译基线。

**Conclusion:** RIVAL是一种有效的对抗性训练框架，通过解决离线奖励模型和在线LLM之间的分布偏移问题，显著提高了机器翻译，特别是在字幕翻译任务中。

> **ai_Abstract:** 该研究提出了一种名为RIVAL的对抗性训练框架，用于解决将RLHF应用于字幕翻译任务时出现的性能下降问题。该问题源于离线奖励模型与在线LLM之间的分布偏移。RIVAL通过最小-最大博弈来迭代地更新奖励模型和LLM，使奖励模型能够区分翻译质量，并使LLM能够提高其翻译以缩小差距。该框架还结合了定性和定量奖励，以提高训练稳定性和泛化能力，并在实验中证明其效果优于现有基线。

> **摘要翻译:** 大型语言模型（LLM）具有强大的多语言能力，将人类反馈强化学习（RLHF）与翻译任务相结合已显示出巨大潜力。然而，我们观察到该范式在应用于字幕翻译任务时表现出乎意料地差。在这项工作中，我们研究了这个问题，发现离线奖励模型（RM）由于分布偏移而逐渐偏离在线LLM，最终导致不良的训练结果。为了解决这个问题，我们提出了RIVAL，一个对抗性训练框架，将该过程公式化为RM和LLM之间的最小-最大博弈。RIVAL迭代地更新两个模型，其中RM被训练来区分强弱翻译（定性偏好奖励），而LLM被训练来增强其翻译以缩小这个差距。为了稳定训练和提高泛化能力，我们将定量偏好奖励（例如BLEU）也纳入RM，实现了与人类评估一致的无参考质量建模。通过广泛的实验，我们证明了所提出的对抗性训练框架显著优于翻译基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [735] [Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings](https://arxiv.org/abs/2508.03453)
> *裁剪优于随机丢弃作为训练自监督文本嵌入的增强策略*

*Rita González-Márquez, Philipp Berens, Dmitry Kobak* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 文本嵌入,自监督学习,数据增强,裁剪,对比学习

**Comment:** 

> **TL;DR:** 自监督学习通过数据增强来训练文本嵌入，其中裁剪是一种比随机丢弃更有效的策略，尤其是在特定领域的数据上。

**AI_Comments:** 这项研究在自监督文本嵌入领域做出了重要贡献，通过系统比较裁剪和随机丢弃两种增强策略，明确了裁剪的优越性。研究结果对于如何有效地利用自监督学习提升文本嵌入质量具有指导意义，尤其是在特定领域数据的应用场景下。然而，文中提到的“非常短的微调”和“有时仅边缘地低于”有监督SOTA模型，这些描述可以更具体化，例如给出具体的微调步数或性能差距的量化数据，以增强说服力。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言处理（NLP）应用中，文本嵌入至关重要，但目前主流方法依赖于有监督的微调。与在计算机视觉中取得成功的自监督学习相比，文本嵌入的自监督方法仍有提升空间。

**Method:** 本文系统地比较了两种用于文本嵌入对比学习的正样本生成增强策略：裁剪和基于随机丢弃的方法。通过在MTEB和其他领域特定评估中评估嵌入质量来验证。

**Result:** 裁剪增强方法在文本嵌入质量上显著优于基于随机丢弃的方法。尽管在跨领域数据上，自监督学习的嵌入质量略逊于有监督的最新模型（SOTA），但在特定领域数据上，自监督微调能在短时间内产生高质量的文本嵌入，其性能与有监督SOTA模型相近。此外，研究发现表示质量随Transformer层数的增加而提高，且仅微调最后几层即可达到相似的嵌入质量。

**Conclusion:** 裁剪作为一种数据增强策略，在自监督文本嵌入学习中比随机丢弃更有效。自监督微调在特定领域数据上能产生高质量的文本嵌入，并且仅微调最后几层Transformer层就足够了。

> **ai_Abstract:** 该研究比较了两种用于自监督文本嵌入学习的增强策略：裁剪和基于随机丢弃的方法。实验结果表明，裁剪在提高文本嵌入质量方面优于随机丢弃。特别是在特定领域的数据上，通过短时间的自监督微调可以获得高质量的文本嵌入，其性能接近于有监督的最新模型。研究还发现，最后几层的Transformer层对嵌入质量的提升贡献最大，仅微调这些层即可达到令人满意的效果。

> **摘要翻译:** 文本嵌入，即整个文本的向量表示，在许多NLP应用中起着重要作用，例如检索增强生成、情感分析、聚类或用于数据探索的文本集合可视化。目前，性能最佳的嵌入模型是通过使用经过精心挑选的文本对进行广泛的有监督微调，从预训练语言模型中获得的。这与计算机视觉形成了对比，在计算机视觉中，基于数据增强的自监督训练已显示出卓越的成功。在这里，我们系统地比较了两种最知名的用于文本嵌入对比学习的正样本生成增强策略。我们在MTEB和额外的领域内评估中评估嵌入质量，并表明裁剪增强在性能上大大优于基于随机丢弃的方法。我们发现，在跨领域数据上，所得嵌入的质量低于有监督的SOTA模型，但对于领域内数据，自监督微调在非常短的微调后就能产生高质量的文本嵌入，有时仅略低于有监督的SOTA。最后，我们表明表示质量随着最后几个Transformer层的增加而提高，这些层在微调过程中经历了最大的变化；并且仅微调这些最后几层就足以达到相似的嵌入质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [764] [ProRefine: Inference-Time Prompt Refinement with Textual Feedback](https://arxiv.org/abs/2506.05305)
> *ProRefine：具有文本反馈的推理时提示精炼*

*Deepak Pandita, Tharindu Cyril Weerasooriya, Ankit Parag Shah, Isabelle Diana May-Xin Ng, Christopher M. Homan, Wei Wei* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 提示优化, 代理工作流, 推理时改进, 文本反馈, LLM

**Comment:** 

> **TL;DR:** ProRefine是一种在推理时优化提示的方法，它使用LLM的代理循环来生成和应用文本反馈，以改进多步推理任务的提示，而无需额外的训练或真实标签。在五个数学推理数据集上的评估显示，ProRefine显著优于零样本思维链基线，并且可以使较小的模型接近较大模型的性能。

**AI_Comments:** 该研究提出了一种新颖的推理时提示优化方法ProRefine，通过利用LLM的代理循环来生成和应用文本反馈。该方法无需额外的训练或真实标签，即可动态改进多步推理任务的提示，并在数学推理任务上取得了显著的性能提升，优于现有的零样本思维链基线。此外，ProRefine还能提高小型模型的性能，使其接近大型模型的性能水平，这对于构建更具成本效益和更强大的混合人工智能系统具有重要意义。该方法的创新性在于其在推理时进行提示优化，以及利用文本反馈进行迭代改进的机制。然而，该方法在处理更广泛的推理任务或在更复杂的代理交互场景中的有效性仍有待进一步研究。此外，计算成本和潜在的反馈循环不稳定性也是未来研究可以关注的方面。

<details>
  <summary>Details</summary>

**Motivation:** 代理工作流在复杂的任务中起着重要作用，但其性能严重依赖于用于指导模型角色的提示。不完善的提示会导致次优性能，限制其可靠性和可扩展性。因此，需要一种在推理时优化提示的方法。

**Method:** ProRefine是一种创新的推理时优化方法，它利用LLM的代理循环来生成和应用文本反馈，以动态地改进多步推理任务的提示，而无需额外的训练或真实标签。

**Result:** 在五个数学推理数据集上的评估显示，ProRefine比零样本思维链基线高出3到37个百分点。此外，该方法使较小的模型能够接近较大模型的性能。

**Conclusion:** ProRefine通过在推理时使用文本反馈动态地改进提示，显著提高了多步推理任务的性能，并使较小的模型能够达到较大模型的性能水平，从而为构建更具成本效益和更强大的混合人工智能系统提供了潜力。

> **ai_Abstract:** ProRefine通过利用LLM的代理循环生成和应用文本反馈，在推理时动态地优化用于多步推理任务的提示，而无需额外的训练或真实标签。该方法在数学推理基准测试中显示出显著的性能提升，并能缩小小型和大型模型之间的性能差距。

> **摘要翻译:** 代理工作流，其中多个AI代理协作以完成诸如推理或规划之类的复杂任务，在许多尖端的商业应用中发挥着重要作用，并且由于其完成昂贵、复杂任务的潜力，这些任务直到最近只有人类才被信任来做，因此继续吸引着几乎所有领域的 शोधकर्ताओं。这些工作流的关键在于用于提供模型在这些工作流中扮演的角色。设计不佳的提示，即使在指导单个代理方面稍有不佳，也可能导致次优性能，这种性能可能会在代理系统中累积，从而限制其可靠性和可扩展性。为了解决推理时提示优化这个重要问题，我们引入了ProRefine，这是一种创新的推理时优化方法，它使用LLM的代理循环来生成和应用文本反馈。ProRefine能够动态地改进多步推理任务的提示，而无需额外的训练或真实标签。在五个数学推理数据集上进行的评估显示，ProRefine的性能显著优于零样本思维链基线3到37个百分点。这种方法不仅提高了准确性，还使较小的模型能够接近其较大对应模型的性能。这凸显了其在构建更具成本效益和更强大的混合人工智能系统方面的潜力，从而实现了高性能人工智能的普及。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [776] [fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval](https://arxiv.org/abs/2508.03475)
> *SemEval-2025 Task 7：多语言和跨语言事实核查声明检索*

*Pranshu Rastogi* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 事实核查声明检索, 多语言, 跨语言, 双编码器, 学习排序

**Comment:** 7 pages, 6 tables. Code available at
  https://github.com/pranshurastogi29/SemEval-2025-ACL-Multi-and-Crosslingual-Retrieval-using-Bi-encoders

> **TL;DR:** 一个基于双编码器模型的学习排序方法，用于多语言和跨语言的事实核查声明检索，在SemEval-2025任务7中取得了优异的性能。

**AI_Comments:** 该方法在处理多语言和跨语言信息检索方面具有创新性，通过利用预训练Transformer和学习排序技术，有效提高了事实核查声明检索的准确性。模型轻量化和在Kaggle GPU上的训练效率也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 解决多语言和跨语言场景下的事实核查声明检索问题。

**Method:** 将问题视为一个学习排序任务，使用经过预训练的Transformer进行微调的双编码器模型，并针对句子相似性进行优化。训练数据包含源语言及其英语翻译（用于多语言检索）和仅英语翻译（用于跨语言检索）。

**Result:** 在多语言检索中达到了92%的Success@10，在跨语言检索中达到了80%的Success@10，分别获得第5名和第10名。

**Conclusion:** 所提出的基于双编码器模型和学习排序的方法在多语言和跨语言事实核查声明检索任务中表现出色。

> **ai_Abstract:** 本文介绍了一种用于SemEval-2025 Task 7（多语言和跨语言事实核查声明检索）的方法。该方法将问题建模为学习排序任务，利用经过优化的双编码器模型，并通过多语言和跨语言训练策略来提高性能。实验结果表明，该方法在两个赛道中均取得了显著的成果。

> **摘要翻译:** SemEval-2025任务7：多语言和跨语言事实核查声明检索被视为一项学习排序任务，使用了从针对句子相似性优化的预训练Transformer微调的双编码器模型。训练数据同时使用了源语言及其英语翻译来进行多语言检索，以及仅使用英语翻译来进行跨语言检索。该方法使用了参数少于5亿的轻量级模型，并在Kaggle T4 GPU上进行训练，在多语言检索中取得了92%的Success@10，在跨语言检索中取得了80%的Success@10，分别在跨语言和多语言赛道中排名第5和第10。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [799] [What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study](https://arxiv.org/abs/2506.12537)
> *什么才是一个好的语音分词器，用于以大语言模型为中心的语音生成？一项系统性研究*

*Xiaoran Fan, Zhichao Sun, Yangfan Gao, Jingfei Xiong, Hang Yan, Yifei Cao, Jiajun Sun, Shuo Li, Zhihao Zhang, Zhiheng Xi, Yuhao Zhou, Senjie Jin, Changhao Jiang, Junjie Ye, Ming Zhang, Rui Zheng, Zhenhua Han, Yunke Zhang, Demei Yan, Shaokang Dong, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang* | **Category: cs.CL, cs.AI, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 语音分词器, 语音-语言模型, 解耦分词, 多令牌预测, 面向说话人的生成, RoleTriviaQA, 词错误率, 跨模态对齐, 语音合成, LLM-centric SLM, speech tokenizer, SLM, decoupled tokenization, MTP, speaker-aware generation, RoleTriviaQA, WER, cross-modal alignment, speech synthesis, LLM-centric SLM

**Comment:** 

> **TL;DR:** 该研究系统地研究了语音分词器设计对以大语言模型为中心的语音-语言模型（SLM）的影响，发现解耦分词器能显著提高跨模态对齐和语音合成质量。通过引入多令牌预测（MTP）解决了信息密度不匹配问题，从而加快了解码速度并降低了词错误率。此外，还提出了一种面向说话人的生成范式，并引入了一个新的大规模角色扮演问答数据集RoleTriviaQA，实验证明了所提方法在知识理解和说话人一致性方面的提升。

**AI_Comments:** 这项研究对于理解和改进以大语言模型为中心的语音生成系统具有重要意义。通过系统地比较不同的分词器设计，并提出多令牌预测和面向说话人的生成范式，该研究不仅提升了模型的性能，还通过引入新的数据集为未来的研究奠定了基础。研究的创新性在于其对分词器设计的深入分析以及解决信息密度不匹配问题的有效方法。然而，研究可能还可以进一步探讨不同分词器在特定语音任务（如语音翻译或语音编辑）上的具体表现，以及其在实际应用中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了统一语音和文本的理解与生成，研究了以大语言模型为中心的语音-语言模型（SLM）。然而，在实现有效的跨模态对齐和高质量语音生成方面仍存在挑战。因此，本研究旨在系统地研究语音分词器设计在LLM驱动的SLM中的作用，以应对这些挑战。

**Method:** 本研究通过一个公平的SLM框架，比较了耦合、半解耦和全解耦的语音分词器。为了解决语音和文本之间的信息密度不匹配问题，研究引入了多令牌预测（MTP）机制，允许每个隐藏状态解码多个语音令牌。此外，还提出了一种面向说话人的生成范式，并引入了一个名为RoleTriviaQA的大规模数据集，该数据集包含多样化的说话人身份，用于知识问答。

**Result:** 研究发现，解耦分词器显著提高了对齐和合成质量。通过引入MTP，解码速度提高了12倍，词错误率从6.07大幅降低至3.01。此外，面向说话人的生成范式和RoleTriviaQA数据集的实验证明，所提出的方法能够同时提升知识理解能力和说话人一致性。

**Conclusion:** 解耦的语音分词器设计对于提升LLM驱动的SLM中的跨模态对齐和语音合成质量至关重要。多令牌预测（MTP）是一种有效的解决信息密度不匹配问题的方法，可以显著加速解码并提高生成语音的准确性。面向说话人的生成范式和高质量的多说话人数据集对于提高模型的知识理解和说话人一致性同样重要。

> **ai_Abstract:** 本研究系统地探讨了语音分词器设计对基于大语言模型的语音-语言模型（SLM）性能的影响。研究发现，解耦分词器在提高跨模态对齐和语音合成质量方面表现更优。为解决语音与文本间的信息密度差异，研究引入了多令牌预测（MTP）技术，实现了高达12倍的解码加速和显著的词错误率降低。此外，研究还提出了一种面向说话人的生成范式，并发布了包含多样化说话人身份的角色扮演问答数据集RoleTriviaQA，实验结果表明该方法能有效提升模型的知识理解和说话人一致性。

> **摘要翻译:** 语音-语言模型（SLM）为统一语音和文本的理解与生成提供了一条有前景的道路。然而，在实现有效的跨模态对齐和高质量语音生成方面仍然存在挑战。在本研究中，我们系统地研究了语音分词器设计在以大语言模型为中心的SLM中的作用，并通过语音头和说话人建模进行了增强。我们在公平的SLM框架下比较了耦合、半解耦和全解耦的语音分词器，发现解耦分词器显著提高了对齐和合成质量。为了解决语音和文本之间的信息密度不匹配问题，我们将多令牌预测（MTP）引入SLM，使每个隐藏状态能够解码多个语音令牌。这使得解码速度提高了12倍，并且词错误率（从6.07降至3.01）也大幅下降。此外，我们提出了一种面向说话人的生成范式，并引入了RoleTriviaQA，这是一个大规模的角色扮演知识问答基准，具有多样化的说话人身份。实验证明，我们的方法同时提高了知识理解和说话人一致性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [819] [CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03489)
> *CF-RAG：一种使用检索增强生成技术的碳足迹问答数据集和方法*

*Kaiwen Zhao, Bharathan Balaji, Stephen Lee* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 碳足迹, 可持续性报告, PDF解析, 检索增强生成, LLM

**Comment:** 

> **TL;DR:** 该研究提出了一个名为CarbonPDF-QA的数据集和一种名为CarbonPDF的方法，用于解决从PDF格式的产品可持续性报告中提取和分析碳足迹信息时遇到的挑战，特别是由于PDF解析导致的非结构化和不一致性问题。研究发现现有模型（如GPT-4o）在处理数据不一致性方面存在困难，因此开发了CarbonPDF，一种基于Llama 3微调的LLM技术，并在实验中证明其性能优于现有技术。

**AI_Comments:** 该研究在处理非结构化和不一致的PDF报告数据方面取得了显著进展，并开发了一个有价值的数据集。然而，未来可以进一步探索更鲁棒的PDF解析技术，以及评估CarbonPDF在处理更大规模、更多样化数据集上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 产品可持续性报告包含重要的环境影响信息，但通常为PDF格式，且包含表格和文本，难以分析。报告缺乏标准化和格式不一致性加剧了信息提取和解读的难度。现有方法在处理PDF解析产生的非结构化和不一致文本方面存在挑战。

**Method:** 提出了CarbonPDF-QA数据集，包含1735份产品报告的问答对，并附有人工标注的答案。开发了CarbonPDF方法，一种基于LLM的技术，通过在训练数据上微调Llama 3来解决碳足迹问答问题，专门处理PDF解析带来的非结构化和不一致性。

**Result:** 所提出的CarbonPDF方法在处理包含数据不一致性的问题时，性能优于包括在表格和文本数据上微调的问答系统在内的现有最先进技术。

**Conclusion:** CarbonPDF-QA数据集和CarbonPDF方法能够有效解决从PDF格式的产品可持续性报告中提取和分析碳足迹信息时的挑战，特别是在处理非结构化和不一致文本方面，并且性能优于现有技术。

> **ai_Abstract:** 本研究提出了一种名为CF-RAG（Carbon Footprint Retrieval-Augmented Generation）的方法，并构建了一个名为CarbonPDF-QA的数据集，旨在解决从PDF格式的产品可持续性报告中提取碳足迹信息并回答相关问题的挑战。研究人员发现，PDF解析产生的非结构化和不一致文本是主要障碍，并且像GPT-4o这样的模型在处理数据不一致性时表现不佳。为了应对这些挑战，他们开发了CarbonPDF，一种基于Llama 3微调的LLM技术，该技术在处理此类数据集时表现优于现有最先进的方法。

> **摘要翻译:** 产品可持续性报告提供了关于产品环境影响的宝贵见解，通常以PDF格式分发。这些报告通常包含表格和文本的组合，使分析复杂化。缺乏标准化和报告格式的可变性进一步加剧了从大量文档中提取和解读相关信息的难度。在本研究中，我们着手解决回答可持续性报告中与碳足迹相关的问题的挑战，这些报告以PDF格式提供。与以往的方法不同，我们的重点是解决从PDF解析中提取的文本的非结构化和不一致性所带来的困难。为了促进这种分析，我们引入了CarbonPDF-QA，一个开源数据集，包含1735份产品报告文件的问答对，以及人工标注的答案。我们的分析表明，GPT-4o在回答数据不一致的问题时存在困难。为了解决这一限制，我们提出了CarbonPDF，一种专门用于回答此类数据集上的碳足迹问题的基于LLM的技术。我们通过在我们的训练数据上微调Llama 3来开发CarbonPDF。我们的结果表明，我们的技术在性能上优于包括在表格和文本数据上微调的问答系统在内的现有最先进技术。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [826] [Pre-trained Transformer-Based Approach for Arabic Question Answering : A Comparative Study](https://arxiv.org/abs/2111.05671)
> *基于预训练Transformer的阿拉伯语问答方法：一项比较研究*

*Kholoud Alsubhi, Amani Jamal, Areej Alhothali* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 阿拉伯语问答, Transformer, 预训练模型, 阅读理解, 迁移学习

**Comment:** Rewrite the paper

> **TL;DR:** 该研究评估了三种预训练Transformer模型（AraBERTv2-base、AraBERTv0.2-large和AraELECTRA）在阿拉伯语问答任务上的性能，使用了四个数据集，并分析了模型表现不佳的原因。

**AI_Comments:** 这项研究对于推动阿拉伯语NLP领域的发展具有重要意义，特别是针对阿拉伯语问答这一具有挑战性的任务。通过比较不同预训练模型的性能并分析其局限性，为研究人员提供了宝贵的见解。然而，研究中使用的具体数据集和评估指标可能影响结果的普适性，未来可以考虑更广泛的数据集和更全面的评估方法。

<details>
  <summary>Details</summary>

**Motivation:** 阿拉伯语问答研究进展缓慢，且缺乏大型基准数据集，而预训练语言模型在许多阿拉伯语NLP问题上表现优异，因此有必要评估这些模型在阿拉伯语问答任务上的性能。

**Method:** 对AraBERTv2-base、AraBERTv0.2-large和AraELECTRA这三种预训练Transformer模型进行微调，并在Arabic-SQuAD、ARCD、AQAD和TyDiQA-GoldP这四个阿拉伯语阅读理解数据集上评估它们的性能，最后分析了部分模型表现不佳的原因。

**Result:** 比较了三种预训练Transformer模型在四个阿拉伯语问答数据集上的性能，并对部分模型的低性能进行了分析。

**Conclusion:** 该研究评估了三种预训练Transformer模型在阿拉伯语问答任务上的性能，并分析了影响模型表现的因素，为未来的阿拉伯语问答研究提供了参考。

> **ai_Abstract:** 本研究旨在评估三种先进的预训练Transformer模型（AraBERTv2-base、AraBERTv0.2-large和AraELECTRA）在阿拉伯语问答任务上的性能。研究人员在四个公开的阿拉伯语阅读理解数据集（Arabic-SQuAD、ARCD、AQAD和TyDiQA-GoldP）上对这些模型进行了微调和比较，并对部分模型表现不佳的原因进行了深入分析，以期为未来阿拉伯语问答系统的发展提供指导。

> **摘要翻译:** 问答（QA）是自然语言处理（NLP）中最具挑战性但又得到广泛研究的问题之一。问答（QA）系统试图为给定的问题生成答案。这些答案可以从非结构化或结构化文本中生成。因此，QA被认为是一个重要的研究领域，可用于评估文本理解系统。大量的QA研究致力于英语语言，研究了最先进的技术并取得了最先进的成果。然而，由于阿拉伯语QA研究的稀缺以及大型基准数据集的缺乏，阿拉伯语问答的进展速度相当缓慢。最近，许多预训练语言模型在许多阿拉伯语NLP问题中都取得了很高的性能。在这项工作中，我们使用四个阅读理解数据集，即Arabic-SQuAD、ARCD、AQAD和TyDiQA-GoldP数据集，评估了阿拉伯语QA最先进的预训练Transformer模型。我们对AraBERTv2-base模型、AraBERTv0.2-large模型和AraELECTRA模型进行了微调和性能比较。最后，我们对一些模型获得的低性能进行了分析，以理解和解释。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [833] [AI4Research: A Survey of Artificial Intelligence for Scientific Research](https://arxiv.org/abs/2507.01903)
> *人工智能助力科学研究：一项调查*

*Qiguang Chen, Mingda Yang, Libo Qin, Jinhao Liu, Zheng Yan, Jiannan Guan, Dengyun Peng, Yiyan Ji, Hanjing Li, Mengkang Hu, Yimeng Zhang, Yihao Liang, Yuhang Zhou, Jiaqi Wang, Zhi Chen, Wanxiang Che* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 人工智能，科学研究，大型语言模型，自动化实验，survey

**Comment:** Preprint, Paper list is available at
  https://github.com/LightChen233/Awesome-AI4Research

> **TL;DR:** 本文对人工智能在科学研究中的应用进行了全面 survey，提出了分类方法，明确了研究空白和未来方向，并整理了相关资源，旨在促进该领域的进步。

**AI_Comments:** 该 survey 在 AI 快速发展的背景下，系统地梳理了 AI 在科学研究中的应用，为该领域的研究者提供了一个清晰的框架和宝贵的资源。其对未来方向的识别和对自动化实验的关注具有前瞻性。然而，abstract 中未提及具体的 AI 模型或技术细节，这可能限制了 survey 的深度。

<details>
  <summary>Details</summary>

**Motivation:** AI，特别是大型语言模型在复杂领域展现出强大能力，促使研究者探索其在科学研究创新过程中的应用，但目前缺乏全面的 survey 来指导和促进该领域的发展。

**Method:** 本文首先对AI4Research中的五个主流任务进行了系统分类，然后识别了关键的研究空白并指出了未来有前景的研究方向，最后汇集了相关的多学科应用、数据集和工具等资源。

**Result:** 本文提出了一个系统性的分类方法，识别了研究空白和未来方向，并整理了丰富的应用和资源，为研究社区提供了对AI4Research的统一视角和快速获取资源的途径。

**Conclusion:** 本文的 survey 为AI4Research领域的研究者提供了系统的分类、对未来方向的见解以及丰富的资源，有望加速该领域的创新和发展。

> **ai_Abstract:** 本 survey 全面梳理了人工智能在科学研究（AI4Research）中的应用，提出了一个系统性的任务分类框架，识别了当前研究的空白和未来的发展方向（如自动化实验的严谨性、可扩展性及社会影响），并整合了相关的应用案例、数据集和工具。该工作旨在为研究社区提供一个统一的视角和便捷的资源访问途径，以推动 AI 在科学研究领域的创新与发展。

> **摘要翻译:** 近期，人工智能（AI）取得了显著进展，尤其是在大型语言模型（LLM）如 OpenAI-o1 和 DeepSeek-R1 等方面，它们在逻辑推理和实验编码等复杂领域展现了卓越的能力。受这些进展的启发，众多研究开始探索 AI 在创新过程中的应用，特别是在科学研究领域。这些 AI 技术主要目标是开发能够自主进行广泛科学研究过程的系统。尽管取得了重大进展，但目前仍缺乏一项关于 AI 助力科学研究（AI4Research）的全面 survey，这阻碍了我们对该领域的理解和进一步发展。为了弥补这一不足，我们 प्रस्तुत 了一项全面的 survey，并对 AI4Research 提供了统一的视角。具体而言，我们工作的贡献包括：(1) 系统分类：我们首先引入一个系统分类法，对 AI4Research 中的五个主流任务进行分类。(2) 新前沿：接着，我们识别了关键的研究空白，并强调了未来有前景的研究方向，重点关注自动化实验的严谨性和可扩展性，以及其社会影响。(3) 丰富的应用和资源：最后，我们汇集了丰富的资源，包括相关的多学科应用、数据集和工具。我们希望我们的工作能为研究社区提供对这些资源的快速访问，并激发 AI4Research 领域的创新突破。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [853] [UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust Empathy Regression](https://arxiv.org/abs/2508.03520)
> *UPLME：用于鲁棒共情回归的不确定性感知概率语言模型*

*Md Rakibul Hasan, Md Zakir Hossain, Aneesh Krishna, Shafin Rahman, Tom Gedeon* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 共情回归, 标签噪声, 不确定性量化, 概率语言模型, 变分模型集成

**Comment:** Code available at https://github.com/hasan-rakibul/UPLME

> **TL;DR:** 该研究提出了UPLME，一个不确定性感知概率语言模型框架，用于处理共情回归中的标签噪声问题，并在两个基准测试中取得了最先进的性能。

**AI_Comments:** 该研究在共情回归领域提出了创新的UPLME框架，有效解决了标签噪声问题，并取得了显著的性能提升。其不确定性感知和概率建模的方法为处理回归任务中的噪声数据提供了新的思路。然而，模型的计算复杂性和对噪声类型敏感性的进一步研究可能是有益的。

<details>
  <summary>Details</summary>

**Motivation:** 监督学习在共情回归中面临自评共情分数不准确的挑战，而现有处理文本分类标签噪声的算法在回归问题上应用较少。

**Method:** 提出UPLME框架，包含一个预测共情分数和异方差不确定性的概率语言模型，并使用贝叶斯概念和变分模型集成进行训练。引入了两个新的损失函数：一个惩罚不确定性量化（UQ）的退化，另一个强制输入对之间的相似性。

**Result:** UPLME在包含标签噪声的两个公开基准测试中取得了最先进的性能（皮尔逊相关系数从0.558提高到0.580，从0.629提高到0.634）。通过注入合成标签噪声，证明了UPLME能根据预测的不确定性有效区分噪声和干净样本，并且在校准误差方面优于现有的基于变分模型集成的UQ方法（从0.571降低到0.376）。

**Conclusion:** UPLME框架能够有效地处理共情回归中的标签噪声问题，并通过不确定性感知提高了模型的鲁棒性和性能。

> **ai_Abstract:** 该研究提出了一种名为UPLME的不确定性感知概率语言模型框架，旨在解决共情回归任务中由自评分数不准确引起的标签噪声问题。UPLME通过预测共情分数和异方差不确定性，并结合贝叶斯概念和变分模型集成进行训练，同时引入了新的损失函数来处理不确定性量化和输入对相似性。实验结果表明，UPLME在两个包含标签噪声的公开基准测试中均取得了最先进的性能，并能有效区分噪声和干净样本，同时在校准误差方面也优于现有方法。

> **摘要翻译:** 监督学习在共情回归中面临自评共情分数不准确的挑战。尽管已经提出了许多用于处理文本分类问题中带噪声标签的算法，但针对回归问题的研究相对较少。我们提出了UPLME，一个不确定性感知概率语言模型框架，用于在共情检测的回归设置中捕捉标签噪声。UPLME包含一个概率语言模型，可以同时预测共情分数和异方差不确定性，并使用贝叶斯概念和变分模型集成进行训练。我们进一步引入了两个新颖的损失函数：一个惩罚退化的不确定性量化（UQ），另一个强制我们预测共情的输入对之间的相似性。UPLME在具有标签噪声的两个公开基准测试中取得了最先进的性能（皮尔逊相关系数：0.558→0.580和0.629→0.634），优于文献报道的性能。通过注入合成标签噪声，我们表明UPLME能够根据预测的不确定性有效地分离噪声样本和干净样本。UPLME在针对回归问题设计的近期基于变分模型集成的UQ方法方面也表现更优（校准误差：0.571→0.376）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [870] [STRUCTSENSE: A Task-Agnostic Agentic Framework for Structured Information Extraction with Human-In-The-Loop Evaluation and Benchmarking](https://arxiv.org/abs/2507.03674)
> *结构感知：一个用于结构化信息提取的、具有人类 in-the-loop 评估和基准测试的类代理框架*

*Tek Raj Chhetri, Yibei Chen, Puja Trivedi, Dorota Jarecka, Saif Haobsh, Patrick Ray, Lydia Ng, Satrajit S. Ghosh* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 结构化信息提取, 大型语言模型, 本体知识, 代理能力, 人类 in-the-loop

**Comment:** -

> **TL;DR:** StructSense是一个基于LLM的框架，利用本体和自我评估来提高结构化信息提取的准确性和可移植性，尤其是在专业领域。

**AI_Comments:** 该研究提出了一种名为StructSense的创新框架，通过结合本体知识、代理能力和人类反馈来改进结构化信息提取，特别是在专业领域。该框架的模块化和任务无关特性提高了其可扩展性和适应性。然而，该框架在处理高度复杂或模糊的非结构化数据时，其性能仍有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的方法在专业领域和跨任务的泛化能力方面存在局限性，需要更有效的结构化信息提取方法来加速科学发现和知识合成。

**Method:** StructSense是一个模块化、任务无关的开源框架，它利用LLM，并通过领域特定的本体知识来指导，结合了自我评估的代理能力和人类 in-the-loop 机制进行迭代优化和质量验证。

**Result:** StructSense克服了领域敏感性和跨任务泛化能力不足的限制，并在神经科学信息提取任务中得到了验证。

**Conclusion:** StructSense通过结合本体知识、代理能力和人类反馈，成功地解决了现有LLM在专业领域结构化信息提取中的局限性，并展示了其跨任务的泛化能力。

> **ai_Abstract:** StructSense是一个创新的、开源的、基于LLM的框架，旨在解决结构化信息提取在专业领域和跨任务泛化方面的挑战。该框架通过整合领域特定的本体知识、自我评估的代理能力以及人类反馈机制，实现了更准确、更具适应性的信息提取，并在神经科学领域得到了成功验证。

> **摘要翻译:** 从非结构化来源（如自由文本文档和科学文献）中提取结构化信息的能力对于加速科学发现和知识合成至关重要。大型语言模型（LLM）在包括结构化信息提取在内的各种自然语言处理任务中展现了卓越的能力。然而，它们在需要细致理解和专家领域知识的专业、领域特定环境中的有效性常常会降低。此外，现有的基于LLM的方法在任务和领域之间的可转移性方面常常表现不佳，限制了它们的可扩展性和适应性。为了应对这些挑战，我们引入了StructSense，一个基于LLM的、用于结构化信息提取的模块化、任务无关的开源框架。StructSense由本体中编码的领域特定符号知识指导，使其能够更有效地导航复杂的领域内容。它通过形成用于迭代改进的反馈循环的自我评估法官来进一步整合代理能力，并纳入了人类in-the-loop机制来确保质量和验证。我们证明了StructSense可以克服领域敏感性和跨任务泛化能力不足的限制，这通过其在多样化的神经科学信息提取任务中的应用得到了证明。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [889] [FilBench: Can LLMs Understand and Generate Filipino?](https://arxiv.org/abs/2508.03523)
> *FilBench：大型语言模型能理解和生成菲律宾语吗？*

*Lester James V. Miranda, Elyanah Aco, Conner Manuel, Jan Christian Blaise Cruz, Joseph Marvin Imperial* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** FilBench, 菲律宾语, 大型语言模型, 基准测试, 自然语言处理

**Comment:** 

> **TL;DR:** FilBench是一个评估大型语言模型在菲律宾语、他加禄语和宿务语任务中表现的基准，结果显示现有模型在该领域仍有很大提升空间，特别是GPT-4o得分72.23%，专门针对东南亚语言训练的模型表现更差。

**AI_Comments:** 这项研究通过引入FilBench填补了大型语言模型在菲律宾语处理能力评估方面的空白，突显了语言特定基准的重要性。然而，将模型在FilBench上的表现与在其他语言上的表现进行更详细的比较，将有助于更全面地理解其跨语言能力。此外，探索导致模型在菲律宾语上表现不佳的具体原因，例如数据偏差或模型架构限制，将为未来的改进提供有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在英语任务上表现出色，但它们在菲律宾语等特定语言上的能力却鲜为人知。

**Method:** 创建了一个名为FilBench的菲律宾语中心基准，包含文化知识、经典自然语言处理、阅读理解和生成等任务，并评估了27个最先进的大型语言模型。

**Result:** 大多数模型在阅读理解和翻译方面存在困难，最佳模型GPT-4o得分仅为72.23%。专门针对东南亚语言训练的模型表现更差，最佳模型SEA-LION v3 70B得分仅为61.07%。

**Conclusion:** FilBench的创建对于推动菲律宾自然语言处理的进步以及增加菲律宾语言在大型语言模型开发中的包容性具有重要价值。

> **ai_Abstract:** FilBench是一个新推出的、以菲律宾语为中心的基准测试，旨在评估大型语言模型（LLM）在菲律宾语、他加禄语和宿务语中的理解和生成能力。研究评估了27个先进的LLM，发现它们在阅读理解和翻译方面存在显著不足，即使是表现最好的GPT-4o得分也仅为72.23%。专门为东南亚语言训练的模型表现更差。该研究强调了创建特定语言基准对于推动菲律宾NLP发展和促进语言包容性的重要性。

> **摘要翻译:** 尽管大型语言模型在英语任务上表现出令人印象深刻的性能，但人们对其在菲律宾语等特定语言上的能力知之甚少。在这项工作中，我们通过引入FilBench来解决这一差距，FilBench是一个以菲律宾语为中心的基准，旨在评估大型语言模型在菲律宾语、他加禄语和宿务语中的各项任务和能力。我们精心策划了FilBench中的任务，以反映菲律宾自然语言处理研究的优先事项和趋势，例如文化知识、经典自然语言处理、阅读理解和生成。通过在FilBench上评估27个最先进的大型语言模型，我们发现一些模型在阅读理解和翻译能力方面存在不足。我们的结果表明FilBench具有挑战性，最佳模型GPT-4o的得分仅为72.23%。此外，我们还发现专门为东南亚语言训练的模型在FilBench上的表现不佳，表现最好的模型SEA-LION v3 70B的得分仅为61.07%。我们的工作证明了策划特定语言的大型语言模型基准在推动菲律宾自然语言处理的进步和增加菲律宾语言在大型语言模型开发中的包容性方面的价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [895] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
> *临床依据的基于代理的报告评估：一种可解释的放射学报告生成指标*

*Radhika Dua, Young Joon, Kwon, Siddhant Dogra, Daniel Freedman, Diana Ruan, Motaz Nashawaty, Danielle Rigau, Daniel Alexander Alber, Kang Zhang, Kyunghyun Cho, Eric Karl Oermann* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 放射学报告生成, 评估指标, 可解释性, 大型语言模型, 临床依据

**Comment:** 

> **TL;DR:** ICARE是一个结合了大型语言模型代理和动态多项选择问答的新型放射学报告生成评估框架，通过问题回答的一致性来衡量报告的临床准确性和召回率，并因其可解释性和与专家判断的高度一致性而优于现有指标。

**AI_Comments:** ICARE框架在放射学报告生成评估领域具有创新性，通过结合LLM代理和MCQA设计了一种新颖的可解释评估方法。其最大的亮点在于将评估过程与临床问题和答案的匹配度联系起来，提高了评估的透明度和可信度。然而，该方法对LLM代理的能力和问题的设计质量有较高依赖，可能存在潜在的偏见或局限性，这需要进一步的研究来探索和验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有放射学报告生成（RRG）的评估指标缺乏可解释性，并且通常依赖于表面相似性或表现得像黑箱，这阻碍了其在临床上的安全部署。

**Method:** ICARE框架利用大型语言模型代理和动态多项选择问答（MCQA）。两个代理分别持有真实报告和生成报告，它们相互生成临床相关问题并进行问答。答案的一致性被用作衡量临床精确度和召回率的可解释代理。

**Result:** ICARE与专家判断的对齐度显著高于现有指标。扰动分析证实了其对临床内容的敏感性和可重复性，模型比较揭示了可解释的错误模式。

**Conclusion:** ICARE提供了一种可解释的评估框架，通过链接分数到问答对，实现了透明和可解释的评估，并且在临床评估方面优于现有方法。

> **ai_Abstract:** ICARE是一个新颖的评估框架，用于放射学报告生成（RRG），它利用大型语言模型代理和动态多项选择问答（MCQA）来提供可解释的临床评估。该框架通过让两个代理（一个使用真实报告，一个使用生成报告）相互提问并回答，来衡量生成报告的临床准确性和召回率。ICARE的优势在于其可解释性，能够将分数与具体的问答对联系起来，并且临床研究表明它比现有指标更能与专家判断保持一致。

> **摘要翻译:** 放射学成像在诊断、治疗规划和临床决策中起着核心作用。视觉语言基础模型激发了对自动化放射学报告生成（RRG）的兴趣，但安全部署需要对生成报告进行可靠的临床评估。现有指标通常依赖于表面相似性或表现为黑箱，缺乏可解释性。我们引入了ICARE（可解释和临床依据的基于代理的报告评估），一个利用大型语言模型代理和动态多项选择问答（MCQA）的可解释评估框架。两个代理，每个代理拥有真实报告或生成的报告，生成临床上有意义的问题并相互提问。答案的一致性捕捉了病变的保存和一致性，作为临床精确度和召回率的可解释代理。通过将分数链接到问答对，ICARE实现了透明和可解释的评估。临床研究表明，ICARE与专家判断的对齐度显著高于以往的指标。扰动分析证实了其对临床内容的敏感性和可重复性，而模型比较揭示了可解释的错误模式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [896] [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960)
> *中文有害内容检测基准：ChineseHarm-Bench*

*Kangwei Liu, Siyuan Cheng, Bozhong Tian, Xiaozhuan Liang, Yuyang Yin, Meng Han, Ningyu Zhang, Bryan Hooi, Xi Chen, Shumin Deng* | **Category: cs.CL, cs.AI, cs.CR, cs.IR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 中文有害内容检测,基准数据集,知识增强,大型语言模型,内容审核

**Comment:** Work in progress

> **TL;DR:** 该研究提出了一个名为ChineseHarm-Bench的中文有害内容检测基准，包含六个类别的真实世界数据，并开发了一个结合知识规则和LLM隐式知识的基准模型，使小型模型也能达到先进LLM的性能。

**AI_Comments:** 该研究填补了中文有害内容检测领域的数据集空白，并提出了一种新颖的知识增强方法，具有重要的理论和实践意义。然而，基准的规模和多样性仍有待进一步扩展，以应对更复杂的有害内容场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有有害内容检测资源主要集中在英语，中文数据集稀缺且范围有限，因此需要一个全面的中文有害内容检测基准。

**Method:** 构建了一个包含六个类别的、完全来自真实世界数据的、经过专业注释的中文内容有害检测基准。通过注释过程还生成了一个知识规则库，用于辅助LLM进行中文有害内容检测。此外，还提出了一个知识增强基线模型，该模型结合了人工注释的知识规则和LLM的隐式知识。

**Result:** 所提出的知识增强基线模型使小型模型在中文有害内容检测任务上取得了与最先进LLM相当的性能。

**Conclusion:** ChineseHarm-Bench为中文有害内容检测提供了一个全面的、基于真实世界数据的基准，并且提出的知识增强方法能够有效提升小型模型在该任务上的性能。

> **ai_Abstract:** 本研究介绍了ChineseHarm-Bench，一个针对中文有害内容检测的基准数据集，该数据集基于真实世界数据并包含六个类别。研究人员还开发了一种知识增强方法，结合了人工规则和LLM知识，使得小型模型在该任务上的表现能够媲美大型模型。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地应用于自动化有害内容检测任务，协助审核员识别策略违规行为，并提高内容审核的整体效率和准确性。然而，现有的有害内容检测资源主要集中在英语，中文数据集仍然稀缺且范围有限。我们提出了一个全面的、经过专业注释的中文内容有害检测基准，涵盖六个代表性类别，并且完全由真实世界数据构建。我们的注释过程还产生了一个知识规则库，为LLM提供显式的专家知识，以辅助中文有害内容检测。此外，我们提出了一个知识增强的基线模型，该模型整合了人工注释的知识规则和来自大型语言模型的隐式知识，使小型模型能够达到与最先进LLM相当的性能。代码和数据可在https://github.com/zjunlp/ChineseHarm-bench获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [898] [MemOS: A Memory OS for AI System](https://arxiv.org/abs/2507.03724)
> *MemOS：人工智能系统的内存操作系统*

*Zhiyu Li, Shichao Song, Chenyang Xi, Hanyu Wang, Chen Tang, Simin Niu, Ding Chen, Jiawei Yang, Chunyu Li, Qingchen Yu, Jihao Zhao, Yezhaohui Wang, Peng Liu, Zehao Lin, Pengyuan Wang, Jiahao Huo, Tianyi Chen, Kai Chen, Kehang Li, Zhen Tao, Huayi Lai, Hao Wu, Bo Tang, Zhenren Wang, Zhaoxin Fan, Ningyu Zhang, Linfeng Zhang, Junchi Yan, Mingchuan Yang, Tong Xu, Wei Xu, Huajun Chen, Haofen Wang, Hongkang Yang, Wentao Zhang, Zhi-Qin John Xu, Siheng Chen, Feiyu Xiong* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** LLMs,内存管理,MemOS,内存操作系统,持续学习

**Comment:** 36 pages, 10 figures, 5 tables

> **TL;DR:** MemOS是一个内存操作系统，它将内存视为可管理的系统资源，统一了文本、激活和参数级内存的表示、调度和演变，以实现高效存储和检索。它通过MemCube封装内存内容和元数据，支持组合、迁移和融合，从而为LLM带来可控性、可塑性和可演化性，为持续学习和个性化建模奠定基础。

**AI_Comments:** 该研究提出了一种新颖的内存操作系统（MemOS），旨在解决大型语言模型（LLMs）在内存管理方面的核心挑战。通过将内存视为可管理的系统资源，并引入MemCube的概念来统一和管理不同类型的内存（文本、激活、参数），MemOS有望显著提升LLMs在长上下文理解、持续学习和个性化方面的能力。该方法通过提供可控性、可塑性和可演化性，为构建更强大、更适应性强的AI系统奠定了基础。其创新之处在于将操作系统中的内存管理思想应用于LLMs，并提出了具体的实现单元MemCube。然而，MemOS的实际部署效果、与其他现有技术的集成效率以及在不同应用场景下的性能表现仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）缺乏明确的内存管理系统，限制了它们在长上下文推理、持续个性化和知识一致性方面的能力。它们主要依赖静态参数和短暂的上下文状态，无法有效跟踪用户偏好或更新知识。检索增强生成（RAG）虽然引入了外部知识，但缺乏生命周期控制和持久化表示集成。LLMs还面临信息在时间和上下文分布方面的挑战，需要能够管理不同时间尺度和来源的异构知识的系统。

**Method:** 提出MemOS，一个内存操作系统，将内存视为可管理的系统资源。它统一了明文、基于激活和参数级内存的表示、调度和演变，实现了成本效益的存储和检索。MemOS使用MemCube作为基本单元，封装内存内容和元数据（如来源和版本），并支持MemCube的组合、迁移和融合，从而实现内存类型之间的灵活转换，并将检索与基于参数的学习相结合。

**Result:** MemOS建立了以内存为中心的系统框架，为LLMs带来了可控性、可塑性和可演化性，为持续学习和个性化建模奠定了基础。

**Conclusion:** MemOS通过将内存作为可管理的系统资源，统一了不同类型内存的表示、调度和演化，解决了LLMs在内存管理方面的挑战，为实现LLMs的可控性、可塑性和可演化性提供了基础，从而支持持续学习和个性化建模。

> **ai_Abstract:** 该论文提出MemOS，一个内存操作系统，旨在解决大型语言模型（LLMs）在内存管理方面的不足。MemOS将内存视为系统资源，统一了文本、激活和参数级内存的表示、调度和演变，并通过MemCube实现高效存储和检索。该框架旨在为LLMs带来可控性、可塑性和可演化性，以支持持续学习和个性化。

> **摘要翻译:** 大型语言模型（LLMs）已成为通用人工智能（AGI）的关键基础设施，但其缺乏明确的内存管理系统阻碍了长上下文推理、持续个性化和知识一致性的发展。现有模型主要依赖静态参数和短暂的上下文状态，限制了它们跟踪用户偏好或在长时间内更新知识的能力。检索增强生成（RAG）虽然引入了纯文本形式的外部知识，但仍然是一种无状态的变通方法，缺乏生命周期控制或与持久化表示的集成。最近的工作从内存层次结构的角度对LLMs的训练和推理成本进行了建模，表明在参数内存和外部检索之间引入显式内存层可以通过外部化特定知识来大幅降低这些成本。除了计算效率，LLMs还面临信息在时间和上下文中分布方式带来的更广泛挑战，这需要能够管理跨越不同时间尺度和来源的异构知识的系统。为了应对这一挑战，我们提出了MemOS，一个内存操作系统，它将内存视为一个可管理的系统资源。它统一了明文、基于激活和参数级内存的表示、调度和演化，实现了成本效益的存储和检索。作为基本单元，MemCube封装了内存内容以及来源和版本等元数据。MemCubes可以随着时间的推移进行组合、迁移和融合，从而实现内存类型之间的灵活转换，并弥合检索与基于参数的学习之间的差距。MemOS建立了一个以内存为中心的系统框架，为LLMs带来了可控性、可塑性和可演化性，为持续学习和个性化建模奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [910] [Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions](https://arxiv.org/abs/2408.06787)
> *连接大语言模型和知识图谱而不进行微调：中间探测遇上子图感知实体描述*

*Bo Xue, Yi Xu, Yunchong Song, Jiaxin Ding, Luoyi Fu, Xinbing Wang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 知识图谱补全, 大型语言模型, 无需微调, 中间探测, 子图感知实体描述

**Comment:** 

> **TL;DR:** 该研究提出了一种结合大语言模型（LLM）和知识图谱（KG）的方法，用于知识图谱补全（KGC）。该方法不依赖LLM的微调，而是利用LLM中间层的隐藏状态来捕捉三元组的语义和关系信息，并结合子图采样生成的实体描述来训练一个高效的分类器。实验结果表明，该方法在效率和性能上均优于现有方法，特别是与微调LLM的方法相比，在提高GPU内存效率和加速训练/推理方面表现突出。

**AI_Comments:** 该研究提出了一种创新的方法，成功地在不进行LLM微调的情况下，实现了LLM与知识图谱的有效融合，以解决KGC问题。其核心亮点在于利用LLM的中间层信息和子图感知的实体描述，这在理论上和实践中都具有重要意义。该方法不仅解决了LLM微调带来的高昂成本问题，还在效率和性能上取得了突破性进展，尤其是在GPU内存使用和训练/推理速度方面。然而，对于“中间探测”的具体机制以及“子图采样”的策略对性能的影响程度，摘要中未详细说明，这可能是未来研究可以深入探讨的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的知识图谱补全（KGC）方法仅依赖结构信息，在处理稀疏的知识图谱（KG）时存在困难。虽然大语言模型（LLM）拥有丰富的世界知识和强大的上下文建模能力，但直接微调LLM进行KGC会带来高昂的计算和内存开销，而不微调LLM则性能不佳。因此，需要一种能够有效且高效地结合LLM和KG的方法来解决KGC问题。

**Method:** 提取LLM中间层的知识三元组的上下文感知隐藏状态，以捕捉丰富的语义和关系细微差别。然后，利用这些表示来训练一个针对KGC任务量身定制的数据高效分类器。为了弥合LLM和KG之间的语义差距，采用子图采样生成模型友好的实体描述。使用切片互信息（SMI）作为原则性度量来量化这些表示中编码的任务特定信息。

**Result:** 在标准基准测试上的广泛实验验证了该方法的效率和有效性。与先前基于未微调LLM的方法相比，实现了47%的相对改进。在GPU内存效率方面提高了188倍，并加速了26.11倍的训练和推理，实现了与微调LLM相当的分类性能。

**Conclusion:** 该研究提出的框架成功地将LLM的优势与强大的知识表示相结合，实现了有效且高效的知识图谱补全。该方法通过利用中间探测和子图感知实体描述，避免了LLM微调带来的高昂成本，并在性能和效率上取得了显著的改进，达到了与微调LLM相当的水平。

> **ai_Abstract:** 本研究提出了一种新颖的框架，旨在无需微调即可实现大型语言模型（LLM）与知识图谱（KG）的有效结合，以解决知识图谱补全（KGC）问题。该方法通过提取LLM中间层的隐藏状态来捕捉知识三元组的丰富语义信息，并结合从KG子图中生成的实体描述来训练一个高效的分类器。实验结果表明，该方法在保持高GPU内存效率（提高188倍）和加速训练推理（提高26.11倍）的同时，实现了与微调LLM相当的性能，并显著优于其他未微调LLM的方法。

> **摘要翻译:** 传统的知识图谱补全（KGC）方法仅依赖结构信息，在处理知识图谱（KG）固有的稀疏性方面存在困难。相比之下，大型语言模型（LLM）封装了广泛的世界知识，并展现出强大的上下文建模能力，这使其有望缓解传统方法的局限性。然而，尽管直接微调LLM进行KGC是有效的，但它带来了巨大的计算和内存开销，而利用未经微调的LLM虽然高效，但性能不佳。在本研究中，我们提出了一种新颖的框架，将LLM的优势与强大的知识表示相结合，以实现有效且高效的KGC。我们提取了LLM中间层的知识三元组的上下文感知隐藏状态，从而捕捉了丰富的语义和关系细微差别。然后，利用这些表示来训练一个针对KGC任务量身定制的数据高效分类器。为了弥合LLM和KG之间的语义差距，我们采用了子图采样技术在KG上生成模型友好的实体描述。我们进一步采用切片互信息（SMI）作为原则性度量来量化这些表示中编码的任务特定信息。在标准基准测试上的广泛实验验证了我们方法的效率和有效性。我们实现了比先前基于未经微调LLM的方法高47%的相对改进，并且据我们所知，是我们首次在实现与微调LLM相当的分类性能的同时，将GPU内存效率提高了188倍，并将训练和推理速度提高了26.11倍。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [918] [Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data](https://arxiv.org/abs/2409.16647)
> *时间序列数据的领域无关的描述性文本自动生成*

*Kota Dohi, Aoi Ito, Harsh Purohit, Tomoya Nishida, Takashi Endo, Yohei Kawaguchi* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 时间序列数据,描述性文本生成,领域无关,对比学习,TACO数据集

**Comment:** 

> **TL;DR:** 提出了一种系统地从时间序列数据生成领域无关的描述性文本的方法，通过前向和后向方法创建时间序列数据和描述性文本对，并利用新颖的后向方法创建了TACO数据集，该数据集可用于训练对比学习模型，以生成新领域时间序列数据的描述性文本。

**AI_Comments:** 该研究通过提出新颖的后向方法和创建TACO数据集，解决了时间序列数据描述性文本生成的挑战，并验证了其在新领域生成文本的有效性，具有一定的创新性和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于带有描述性文本的时间序列数据稀缺，因此训练模型生成描述性文本具有挑战性。

**Method:** 提出了一种系统地从时间序列数据生成领域无关的描述性文本的方法，包括前向方法和后向方法，并利用后向方法创建了TACO数据集。

**Result:** 使用TACO数据集训练的基于对比学习的模型能够为新领域的时间序列数据生成描述性文本。

**Conclusion:** 所提出的方法和TACO数据集能够有效地解决时间序列数据描述性文本生成的挑战，并为新领域生成描述性文本。

> **ai_Abstract:** 本研究提出了一种从时间序列数据生成领域无关的描述性文本的方法，通过前向和后向两种方法创建数据与文本对。研究者实现了后向方法，并创建了TACO数据集，实验证明使用该数据集训练的对比学习模型能够为新领域的时间序列数据生成描述性文本。

> **摘要翻译:** 由于缺少带描述性文本的时间序列数据，训练一个生成时间序列数据描述性文本的模型是具有挑战性的。在本研究中，我们提出了一种从时间序列数据系统地生成领域无关的描述性文本的方法。我们确定了两种创建时间序列数据和描述性文本对的不同方法：前向方法和后向方法。通过实现新颖的后向方法，我们创建了用于观测的Temporal Automated Captions（TACO）数据集。实验结果表明，使用TACO数据集训练的基于对比学习的模型能够为新领域的时间序列数据生成描述性文本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [923] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
> *人口感知专家与合成视角下的标注者异议建模*

*Yinuo Xu, Veronica Derricks, Allison Earl, David Jurgens* | **Category: cs.CL** | **Updated: 2025-08-04**

**Keywords:** 标注者异议,人口感知专家混合模型,合成数据,数据插补,多样化视角

**Comment:** 28 pages, 17 figures

> **TL;DR:** 本研究提出了一种名为DEM-MoE的模型，通过结合架构和数据方面的创新来模拟NLP任务中的标注者异议。该模型能根据标注者的人口统计信息将输入路由到专家子网络，从而更好地表示结构化的、群体层面的变异性。此外，研究还探讨了使用大型语言模型生成合成标注数据进行数据插补的方法，并提出了混合真实和合成数据的策略，以期丰富训练数据并提升模型在多样化视角下的表现。

**AI_Comments:** 该研究在标注者异议建模方面提出了新颖的DEM-MoE架构，并结合了数据驱动的方法，如利用LLM生成合成数据，这为处理主观性强的NLP任务提供了有价值的见解。模型能够根据人口统计信息区分不同群体，这在公平性和鲁棒性方面具有重要意义。然而，合成数据的“中等程度”一致性以及混合策略的依赖性表明，在实际应用中仍需谨慎评估和调整。

<details>
  <summary>Details</summary>

**Motivation:** 在主观自然语言处理任务中，标注者之间存在异议，这给模型训练带来了挑战。本研究旨在通过一种新的模型来更好地模拟和理解这种标注者异议，特别是考虑到人口统计学因素对异议的影响，并探索利用合成数据来增强模型能力。

**Method:** 本研究提出了一种名为DEM-MoE（人口感知专家混合模型）的架构。该模型通过人口统计信息将输入路由到不同的专家子网络，以捕捉标注者群体间的变异性。此外，研究还利用大型语言模型通过零样本提示生成合成标注数据，并测试了混合真实和合成数据的策略，以应对人口统计信息覆盖稀疏的问题。

**Result:** DEM-MoE模型在不同人口统计群体中表现出具有竞争力的性能，特别是在标注者异议较高的的数据集上表现尤为出色。研究还表明，大型语言模型生成的合成标注数据与人类标注数据具有中等程度的一致性，并为数据插补提供了一种可扩展的方法。混合真实和合成数据的最佳策略取决于数据集的结构。

**Conclusion:** 本研究提出的DEM-MoE模型及其结合合成数据的策略，能够有效地模拟标注者异议，并提升模型在处理多样化视角下的表现。研究结果表明，考虑人口统计信息和利用合成数据是改进主观NLP任务标注者异议建模的重要途径。

> **ai_Abstract:** 本研究提出了一种名为DEM-MoE的模型，通过人口统计信息将输入路由到专家子网络，以模拟主观NLP任务中的标注者异议。研究还探索了使用LLM生成的合成数据进行数据插补和丰富训练数据的方法，并提出了混合真实和合成数据的策略。结果表明，DEM-MoE在不同群体中表现良好，合成数据具有一定的可用性，混合策略的有效性取决于数据集结构，共同提升了对多样化视角的表征能力。

> **摘要翻译:** 我们提出了一种通过架构和数据中心创新来模拟主观NLP任务中标注者异议的方法。我们的模型DEM-MoE（人口感知专家混合模型）根据标注者的人口统计信息将输入路由到专家子网络，使其能够比先前模型更好地表示结构化的、群体层面的变异性。DEM-MoE在不同人口统计群体中始终表现出具有竞争力的性能，并在具有高标注者异议的数据集上显示出特别强劲的结果。为了解决人口统计覆盖稀疏的问题，我们测试了通过零样本提示生成的大型语言模型（LLM）合成标注是否可用于数据插补。我们表明，这些合成判断在我们的数据上与人类标注具有中等程度的一致性，并提供了一种可扩展的方法来潜在地丰富训练数据。然后，我们提出并评估了使用针对数据集结构量身定制的策略来混合真实和合成数据的方法。我们发现最佳策略取决于数据集的结构。总而言之，这些贡献改进了对不同视角的表征。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [924] [Marito: Structuring and Building Open Multilingual Terminologies for South African NLP](https://arxiv.org/abs/2508.03529)
> *Marito：为南非自然语言处理构建和建立开放的多语言术语库*

*Vukosi Marivate, Isheanesu Dzingirai, Fiskani Banda, Richard Lastrucci, Thapelo Sindane, Keabetswe Madumo, Kayode Olaleye, Abiodun Modupe, Unarine Netshifhefhe, Herkulaas Combrink, Mohlatlego Nakeng, Matome Ledwaba* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** Marito, 多语言NLP, 术语数据, RAG, 南非语言

**Comment:** Under Review

> **TL;DR:** 该研究介绍了Marito项目，旨在解决南非多语言NLP领域缺乏结构化术语数据的问题。通过整合、清理和标准化现有的零散术语资源，Marito创建了开放、可互操作的数据集，并基于NOODL框架发布。将Marito术语集成到RAG管道中，可显著提高英语到Tshivenda机器翻译的准确性和领域特定一致性。

**AI_Comments:** 该研究有效地解决了南非NLP领域面临的关键挑战，即缺乏标准化、可访问的术语数据。Marito项目通过系统化的方法创建开放数据集，并展示了其在实际应用中的有效性（通过RAG管道和机器翻译评估），这对于推动非洲语言的NLP发展具有重要意义。NOODL框架的引入也体现了对公平和本地化解决方案的关注。未来的工作可以进一步扩展支持的语言范围，并探索更多NLP应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 南非多语言NLP领域缺乏结构化的术语数据，现有的政府和学术术语列表分散且格式不兼容，阻碍了计算研究和开发。

**Method:** Marito系统性地整合、清理和标准化分散的术语资源，创建开放、可互操作的数据集。将这些术语集成到检索增强生成（RAG）管道中进行评估。

**Result:** 在英语到Tshivenda的机器翻译任务中，集成Marito术语的RAG管道显著提高了大型语言模型的准确性和领域特定一致性。

**Conclusion:** Marito为开发稳健且公平的NLP技术提供了可扩展的基础，确保南非丰富的语言多样性在数字时代得到体现。

> **ai_Abstract:** Marito项目通过整合、标准化南非分散的术语资源，创建了开放、可互操作的数据集，解决了多语言NLP领域缺乏结构化术语数据的问题。该项目发布的Marito数据集基于NOODL框架，并成功应用于英语到Tshivenda机器翻译的RAG管道，显著提升了模型性能，为南非语言多样性的数字化发展奠定了基础。

> **摘要翻译:** 南非官方语言的结构化术语数据严重缺乏，尽管存在许多政府和学术术语列表，但多语言自然语言处理（NLP）的进展仍然受到阻碍。这些宝贵的资产仍然分散且以不可机器读取的格式存在，使其无法用于计算研究和开发。

Marito通过系统地聚合、清理和标准化这些分散的资源，将其转化为开放、可互操作的数据集，从而应对这一挑战。

我们引入了基础的Marito数据集，该数据集在公平、以非洲为中心的NOODL框架下发布。

为了展示其即时效用，我们将术语集成到检索增强生成（RAG）管道中。

实验表明，在大型语言模型的英语到Tshivenda机器翻译方面，准确性和领域特定一致性得到了显著改善。

Marito为开发稳健且公平的NLP技术提供了可扩展的基础，确保南非丰富的语言多样性在数字时代得到体现。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [926] [CLARIFID: Improving Radiology Report Generation by Reinforcing Clinically Accurate Impressions and Enforcing Detailed Findings](https://arxiv.org/abs/2507.17234)
> *CLARIFID：通过加强临床准确印象和强制详细发现来改进放射学报告生成*

*Kyeongkyu Lee, Seonghwan Yoon, Hongki Lim* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 放射学报告生成, 临床准确性, CLARIFID, 强化学习, 多视图编码

**Comment:** 

> **TL;DR:** CLARIFID 是一个新框架，通过模仿专家工作流程来优化放射学报告的准确性，它结合了分节感知预训练、基于 CheXbert F1 分数的强化学习以及多视图编码，从而比现有方法在临床效用和标准指标上表现更好。

**AI_Comments:** 该研究提出了一种名为 CLARIFID 的新颖框架，用于改进放射学报告的自动生成。该方法通过模仿专家工作流程，并结合分节感知预训练、强化学习（以 CheXbert F1 分数作为奖励）以及多视图融合等技术，有效地解决了现有方法在临床准确性和全面性方面的不足。实验结果令人鼓舞，表明该方法在标准 NLG 指标和临床感知指标上均优于现有基线。该研究的创新性在于直接优化诊断的准确性，并强制执行“发现”先于“印象”的生成顺序，这对于生成可靠的放射学报告至关重要。未来的工作可以进一步探索该方法在不同类型医学影像和报告生成任务上的应用。

<details>
  <summary>Details</summary>

**Motivation:** 当前的放射学报告自动生成方法在确保报告的临床准确性和可靠性方面存在不足，并且通常仅依赖单视图图像，限制了诊断的全面性。

**Method:** CLARIFID 框架通过以下方式优化诊断准确性：1. 学习“发现”到“印象”的逻辑流程，通过分节感知预训练实现；2. 使用 CheXbert F1 分数作为奖励，通过近端策略优化进行微调；3. 强制执行“发现”先于“印象”的推理感知解码；4. 通过基于 Vision Transformer 的多视图编码器融合多个胸部 X 射线视图。在推理过程中，采用推理感知下一个标记强制策略，然后进行报告级重新排序。

**Result:** 在 MIMIC-CXR 数据集上的实验结果表明，该方法在临床效用方面表现更优，并在标准 NLG 指标和临床感知分数上均优于现有基线。

**Conclusion:** CLARIFID 通过模仿专家工作流程，并结合分节感知预训练、基于 CheXbert F1 分数的强化学习以及多视图融合，显著提高了放射学报告的临床准确性和全面性，优于现有方法。

> **ai_Abstract:** CLARIFID 是一个旨在提高放射学报告自动生成质量的新框架。它通过模仿放射科医生从“发现”到“印象”的两步工作流程来优化报告的临床准确性。该框架利用分节感知预训练、基于 CheXbert F1 分数的强化学习以及多视图编码技术，以确保报告的准确性和全面性。实验结果表明，CLARIFID 在 MIMIC-CXR 数据集上取得了优于现有方法的性能。

> **摘要翻译:** 自动生成放射学报告有潜力减轻放射科医生的巨大工作量，但目前的方法在提供临床上可靠的结论方面存在困难。特别是，大多数先前的方法侧重于生成流畅的文本，而没有有效确保报告的事实正确性，并且通常依赖单视图图像，限制了诊断的全面性。我们提出了 CLARIFID，一个新颖的框架，通过模仿专家的两步工作流程直接优化诊断的准确性。具体来说，CLARIFID (1) 通过分节感知预训练学习从“发现”到“印象”的逻辑流程，(2) 使用近端策略优化进行微调，其中 Impression 部分的 CheXbert F1 分数作为奖励，(3) 强制执行推理感知解码，该解码在合成“印象”之前完成“发现”，并且 (4) 通过基于 Vision Transformer 的多视图编码器融合多个胸部 X 射线视图。在推理过程中，我们应用推理感知下一个标记强制策略，然后进行报告级重新排序，确保模型在合成印象之前首先生成全面的“发现”部分，从而保持连贯的临床推理。在 MIMIC-CXR 数据集上的实验结果表明，我们的方法实现了卓越的临床疗效，并在标准 NLG 指标和临床感知分数上均优于现有基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [944] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
> *高亮与总结：无需越狱的检索增强生成*

*Giovanni Cherubin, Andrew Paverd* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 检索增强生成, 模型安全, 越狱防御, 高亮与总结, 大型语言模型

**Comment:** 

> **TL;DR:** 该论文提出了一种名为“高亮与总结”（H&S）的新型检索增强生成（RAG）设计模式，通过将用户问题隐藏在生成式语言模型（LLM）之外，来防止模型被恶意利用。实验表明，基于LLM的高亮器生成的H&S响应在质量上优于标准的RAG方法。

**AI_Comments:** 该研究提出了一种创新的RAG设计模式，通过将用户问题与LLM隔离来解决越狱和模型劫持问题，这是一种有前景的安全策略。然而，仅使用LLM作为高亮器可能会引入新的漏洞或性能瓶颈，需要进一步研究其鲁棒性和效率。此外，评估仅限于“正确性、相关性和响应质量”，可能需要更全面的安全评估指标。

<details>
  <summary>Details</summary>

**Motivation:** 防止大型语言模型（LLM）被越狱和模型劫持是一个重要且具有挑战性的任务，因为恶意用户可以通过精心设计的提示来诱导LLM生成不希望出现的内容或执行非预期任务。现有的缓解措施，如强化系统提示或使用内容分类器，容易被绕过。

**Method:** 提出了一种名为“高亮与总结”（H&S）的设计模式，用于检索增强生成（RAG）系统。该模式将RAG流程分为两个组件：1. 高亮器：提取检索到的文档中的相关段落（“高亮”），但不向生成式LLM透露用户的问题。2. 总结器：根据提取的高亮段落生成最终答案。论文中描述了几种可能的H&S实现方式，并从正确性、相关性和响应质量方面对生成的响应进行了评估。

**Result:** 当使用基于LLM的高亮器时，大多数H&S响应在质量上优于标准的RAG流程。

**Conclusion:** “高亮与总结”（H&S）作为一种新的RAG设计模式，能够通过在设计上就隐藏用户问题来有效防止LLM被越狱和模型劫持，并且在实验中表现出优于标准RAG方法的响应质量。

> **ai_Abstract:** 本研究提出了一种名为“高亮与总结”（H&S）的新型检索增强生成（RAG）方法，旨在通过在不向生成式语言模型（LLM）透露用户原始问题的情况下提取和总结相关信息来防御越狱和模型劫持攻击。该方法将RAG流程分解为“高亮器”和“总结器”两个阶段。“高亮器”负责从检索到的文档中识别关键信息片段，而“总结器”则基于这些片段生成最终答案。实验结果表明，采用基于LLM的“高亮器”的H&S方法在响应的正确性、相关性和整体质量方面均优于传统的RAG方法。

> **摘要翻译:** 防止大型语言模型（LLM）被越狱和模型劫持是一项重要但艰巨的任务。例如，在与聊天机器人交互时，恶意用户可以输入精心设计的提示，导致LLM生成不希望出现的内容或执行与其预期目的完全不同的任务。现有对此类攻击的缓解措施通常依赖于加强LLM的系统提示或使用旨在检测不希望出现的内容或偏离主题的对话的内容分类器。然而，由于可能输入的组合和不希望出现的输出的空间非常大，这些概率性方法相对容易被绕过。在本论文中，我们提出并评估了“高亮与总结”（H&S），一种用于检索增强生成（RAG）系统的新设计模式，该模式通过设计来防止这些攻击。核心思想是执行与标准RAG流程相同的任务（即，根据相关来源，对问题提供自然语言答案），而无需向生成式LLM透露用户的问题。这是通过将流程分为两个组件来实现的：一个高亮器，它接收用户的问题并从检索到的文档中提取相关段落（“高亮”），以及一个总结器，它接收高亮段落并将其总结为连贯的答案。我们描述了几种可能的H&S实现方式，并从正确性、相关性和响应质量方面评估了它们生成的响应。令人惊讶的是，在使用基于LLM的高亮器时，大多数H&S响应被认为优于标准的RAG流程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [952] [EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for Large Language Models](https://arxiv.org/abs/2508.03533)
> *EmbedGrad：基于梯度的大型语言模型嵌入空间提示优化*

*Xiaoming Hou, Jiquan Zhang, Zibin Lin, DaCheng Tao, Shengli Zhang* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** EmbedGrad, 提示优化, 嵌入空间, 梯度优化, 模型适应

**Comment:** 

> **TL;DR:** EmbedGrad是一种新的框架，通过梯度优化嵌入空间中的文本提示，以适应大型语言模型。它解决了离散提示工程的精度不足和基于参数的方法的复杂性问题。EmbedGrad在数学推理、情感分析和因果判断等任务中表现出色，尤其能显著提高小型模型在复杂问题上的准确性。

**AI_Comments:** EmbedGrad通过在嵌入空间中进行梯度优化来改进提示工程，这是一种新颖且有前景的方法。它有效地解决了离散提示工程的精度限制和参数调整方法的复杂性问题。该研究在不同模型规模和任务上都展示了其有效性，尤其是在提升小型模型处理复杂任务的能力方面。然而，该方法在计算成本、对特定任务的敏感性以及解释其在嵌入空间中进行优化的具体机制方面可能还有进一步研究的空间。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI部署挑战在于如何有效地将强大的预训练基础模型适应于各种任务。现有的方法，如离散提示工程和基于参数的连续适应，都存在局限性：前者缺乏精细调整的精度，后者则增加了复杂性并降低了可解释性。

**Method:** EmbedGrad框架通过梯度优化文本提示的嵌入。它将训练和部署分离开来：在优化过程中，使用标记示例进行精确的嵌入调整，同时保留语义；在推理过程中，仅将优化后的嵌入与用户查询结合。这种方法允许在嵌入空间中进行精细校准，例如改进“请逐步推理”这类提示的推理能力。

**Result:** 在数学推理、情感分析和因果判断任务的全面评估中，EmbedGrad被证明是有效的。例如，在Qwen2.5-Math-1.5B模型上优化“请逐步推理”提示，在数学问题上的准确率从14.74%提高到58.96%。在不同模型规模（0.5B-14B）和所有任务中都观察到了一致的改进，尤其是在处理因果判断等复杂问题的小型模型上取得了显著的提升。

**Conclusion:** EmbedGrad通过嵌入细化提供了一种新的任务适应范式，它在不改变模型架构的情况下，结合了提示工程和参数效率的优点，从而实现了比现有方法更优越的性能。

> **ai_Abstract:** EmbedGrad是一种创新的框架，它通过在嵌入空间中使用梯度优化文本提示来改进大型语言模型的任务适应性。该方法解决了传统提示工程精度不足和参数调整方法复杂度高的问题，通过在推理时仅集成优化后的嵌入，实现了精细的校准。实验证明，EmbedGrad在多种任务和模型规模上均能有效提升性能，尤其对小型模型在复杂任务上的表现有显著改善，为模型适应性提供了一种新的有效途径。

> **摘要翻译:** 有效调整强大的预训练基础模型以适应各种任务仍然是AI部署中的一个关键挑战。当前的方法主要遵循两种范式：通过提示工程对文本提示进行离散优化，或通过额外的可训练参数进行连续适应。两者都存在局限性——离散方法缺乏精细调整的精度，而基于参数的技术则增加了复杂性并降低了可解释性。为了解决这些限制，我们提出了EmbedGrad，一个通过梯度优化文本提示嵌入的新颖框架。我们的方法独特地将训练与部署分离开来：在优化过程中，标记示例指导精确的嵌入调整，同时保留语义含义；在推理过程中，只有优化后的嵌入与用户查询集成。这使得在文本空间中无法实现的精细校准成为可能，例如增强像“请逐步推理”这样的提示的推理能力。在数学推理、情感分析和因果判断任务上的全面评估证明了EmbedGrad的有效性：在Qwen2.5-Math-1.5B上优化此推理提示，在数学问题上的准确率从14.74%提高到58.96%。在模型规模（0.5B-14B）和所有任务中都观察到了一致的改进，尤其是在小型模型处理因果判断等复杂问题时，取得了显著的提升。通过在不进行架构更改的情况下弥合提示工程和参数效率，我们的工作将嵌入细化确立为任务适应的一种强大新范式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [961] [Post-Completion Learning for Language Models](https://arxiv.org/abs/2507.20252)
> *后完成学习语言模型*

*Xiang Fei, Siqi Wang, Shu Wei, Yuxiang Nie, Wei Shi, Hao Feng, Chao Feng, Can Huang* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 后完成学习,语言模型,强化学习,自我评估,推理能力

**Comment:** 

> **TL;DR:** 提出后完成学习（PCL）框架，利用模型输出完成后的序列空间，通过白盒强化学习优化推理和自我评估能力，实验证明其优于传统方法。

**AI_Comments:** 该研究提出了一种创新的语言模型训练方法，通过利用“后完成”阶段来提升模型性能，这在现有研究中较为少见。其白盒强化学习和双轨道SFT结合的方法具有一定的技术亮点，但需要进一步验证其在更广泛场景下的普适性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 当前语言模型训练方法在达到序列结束（<eos>）标记时终止，忽略了完成后的潜在学习机会。

**Method:** 设计了一种白盒强化学习方法，让模型根据奖励规则评估输出内容，然后计算得分并与奖励函数对齐进行监督。采用双轨道SFT优化推理和评估能力，并与RL训练混合实现多目标混合优化。

**Result:** 在不同数据集和模型上的实验结果表明，与传统的SFT和RL方法相比，该方法取得了一致的改进。

**Conclusion:** PCL提供了一种新的语言模型训练技术路径，在保持部署效率的同时提高了输出质量。

> **ai_Abstract:** 本文提出了一种名为后完成学习（PCL）的新型语言模型训练框架，该框架通过利用模型输出完成后的序列空间来提升推理和自我评估能力。PCL采用白盒强化学习方法，使模型能够进行自我评估和奖励预测，并通过双轨道SFT和RL混合优化实现多目标训练。实验结果表明，PCL在不同数据集和模型上均优于传统方法，为提高语言模型输出质量和部署效率提供了新的途径。

> **摘要翻译:** 当前的语言模型训练范式通常在达到序列结束（<eos>）标记时终止学习，而忽略了在完成后的序列空间中的潜在学习机会。我们提出了后完成学习（PCL），一种新颖的训练框架，系统地利用模型输出完成后的序列空间，以增强推理和自我评估能力。PCL使模型能够在训练期间继续生成自我评估和奖励预测，同时通过在完成点停止来保持高效推理。
为了充分利用这个后完成空间，我们设计了一种白盒强化学习方法：让模型根据奖励规则评估输出内容，然后计算得分并与奖励函数对齐进行监督。我们实现了双轨道SFT来优化推理和评估能力，并将其与RL训练混合以实现多目标混合优化。
在不同数据集和模型上的实验结果证明了与传统SFT和RL方法相比具有一致的改进。我们的方法为语言模型训练提供了一条新的技术路径，在保持部署效率的同时提高了输出质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [965] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
> *基于合并的句法由不同的神经认知机制介导：对九种语言中具有语言缺陷的 84,000 名个体的理解能力进行聚类分析*

*Elliot Murphy, Rohan Venkatesh, Edward Khokhlovich, Andrey Vyshedskiy* | **Category: cs.CL** | **Updated: 2025-08-04**

**Keywords:** 合并句法, 神经认知机制, 句法复杂性, 聚类分析, 语言缺陷

**Comment:** 

> **TL;DR:** 该研究通过聚类分析，在九种语言中对 84,000 名有语言缺陷的个体进行了句法理解能力的研究，发现存在三种不同的句法结构类型，可能与不同的发展阶段和选择性损伤有关，并提出合并句法可能由不同的认知机制支持。

**AI_Comments:** 这项研究规模庞大，涵盖了多种语言和大量个体，为理解句法处理的神经认知机制提供了有力的证据。研究结果支持了句法结构并非单一机制产物的观点，并为未来在发展和病理学研究中进一步探索这些差异提供了方向。然而，仅凭行为学数据可能难以完全区分认知机制的差异，未来的神经影像学研究或许能提供更直接的证据。

<details>
  <summary>Details</summary>

**Motivation:** 探究句法操作“合并”在神经认知层面的机制，以及不同类型的合并结构（简单指令、形容词-名词、名词-空间介词）是否由不同的认知机制支持。

**Method:** 对 84,000 名有语言缺陷的个体进行句法理解能力测试，并采用聚类分析来识别不同的句法结构类型。

**Result:** 聚类分析揭示了三种不同的句法结构类型，为合并句法可能由不同的认知机制支持提供了行为学证据。

**Conclusion:** 尽管合并句法可能在进化中突然出现，但不同的认知机制似乎支撑着各种合并结构的处理。

> **ai_Abstract:** 这项研究调查了句法操作“合并”的神经认知基础，通过对 84,000 名患有语言缺陷的个体进行句法理解能力分析，发现存在三种不同的句法结构类型，这表明合并句法可能由不同的认知机制支持，并可能在不同的发展阶段出现或易受选择性损伤的影响。

> **摘要翻译:** 在现代语言科学中，句法的核心计算操作“合并”被定义为一种将两个语言单位（例如，“棕色的”，“猫”）组合起来形成一个分类结构（“棕色的猫”，一个名词短语）的操作。然后，它可以根据这种分类信息与额外的语言单位进一步组合，并遵循非结合律，从而尊重抽象分组。一些语言学家认为，合并是一种基本的、不可分割的操作，是在单一次进化步骤中出现的。从神经认知的角度来看，合并构建的不同心智对象可能由不同的机制支持：（1）简单的指令结构（例如，“吃苹果”）；（2）形容词和名词的合并（“红色的船”）；以及（3）名词与空间介词的合并（“笔记本在沙发后面”）。在这里，我们系统地调查了参与者对具有不同句法复杂性水平的句子的理解能力。聚类分析揭示了三种不同结构类型的行为学证据，我们讨论这些结构可能在不同的发展阶段出现并受到选择性损伤的影响。尽管合并句法可能在进化过程中突然出现，导致了我们物种所采取的结构化符号转折，但不同的认知机制似乎支撑着各种合并结构的处理。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [967] [A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans](https://arxiv.org/abs/2412.01131)
> *预训练语言模型和人类语义关系知识的综合评估*

*Zhihan Cao, Hiroaki Yamada, Simone Teufel, Takenobu Tokunaga* | **Category: cs.CL** | **Updated: 2025-08-05**

**Keywords:** 语义关系, 预训练语言模型, 人类比较, 评估框架, 知识差距

**Comment:** 

> **TL;DR:** 该研究评估了预训练语言模型（PLMs）在理解五种语义关系（包括上位、下位、整体、部分、反义和同义）方面的知识，并将其与人类的表现进行比较。研究引入了一个包含五个新指标（健全性、完整性、对称性、原型性和可区分性）的评估框架。实验结果表明，在所有语义关系中，人类在理解能力上显著优于模型，并且因果语言模型并不总是比掩码语言模型表现更好，反义关系是所有模型表现相对较好的唯一例外。

**AI_Comments:** 该研究在评估预训练语言模型（PLMs）的语义关系知识方面做出了重要贡献，通过引入更广泛的关系和创新的评估指标，并首次将人类表现纳入同一基准进行比较，揭示了模型与人类之间存在的显著差距。研究方法严谨，实验设计全面，但未来的工作可以进一步探索导致这种差距的具体原因，并研究如何提升模型在这些语义关系上的理解能力。

<details>
  <summary>Details</summary>

**Motivation:** 先前对预训练语言模型（PLMs）语义关系知识的研究存在局限性，主要集中在上位关系上，且未将人类的表现纳入同一任务进行衡量，导致对模型能力的评估不完整。

**Method:** 提出一个包含五种语义关系（上位、下位、整体、部分、反义、同义）和五个新指标（健全性、完整性、对称性、原型性、可区分性）的综合评估框架，用于比较人类和六种预训练语言模型（包括四种掩码语言模型和两种因果语言模型）在理解语义关系方面的能力。

**Result:** 在所有测试的语义关系中，人类在理解能力上显著优于所有模型。因果语言模型并不总是比掩码语言模型表现更好。反义关系是唯一一个所有模型表现都相对较好的关系。

**Conclusion:** 预训练语言模型在理解语义关系方面与人类存在显著的知识差距。

> **ai_Abstract:** 本研究提出了一种全面的评估框架，用于衡量预训练语言模型（PLMs）在五种语义关系（下位、整体、部分、反义、同义）上的知识，并引入了五个新的评估指标（健全性、完整性、对称性、原型性、可区分性）。通过将PLMs与人类在同一任务上的表现进行比较，研究发现人类在所有语义关系上都表现出显著优于模型的能力，并且反义关系是模型表现相对较好的唯一例外。

> **摘要翻译:** 近期，大量研究致力于揭示预训练语言模型（PLMs）在语言不同方面的具体学习内容及其学习方式。其中一类研究旨在探究PLMs所拥有的关于语义关系方面的知识。然而，语义关系的许多方面仍未被充分探索。通常，只考虑了一种关系，即上位关系。此外，以往的研究并未衡量人类在与PLMs相同的任务上的表现。这意味着，在目前这个时间点，对这些模型语义关系知识的掌握程度的了解是不完整的。为了解决这一差距，我们引入了一个综合评估框架，涵盖了除上位关系之外的五种关系：下位关系、整体关系、部分关系、反义关系和同义关系。我们使用了五个指标（其中两个是新提出的）来衡量近期未被处理的语义关系知识的各个方面，即健全性、完整性、对称性、原型性和可区分性。利用这些指标，我们可以公平地比较人类和模型在同一任务上的表现。我们广泛的实验涉及六个PLMs，包括四种掩码语言模型和两种因果语言模型。结果表明，在所有语义关系上，人类与模型之间存在显著的知识差距。总的来说，尽管因果语言模型得到了广泛应用，但它们的表现并不总是显著优于掩码语言模型。反义关系是一个例外，所有模型在该关系上的表现都相当不错。评估材料可在https://github.com/hancules/ProbeResponses找到。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='cscr'></a>
## cs.CR 

### [13] [A Non-leveled and Reliable Approximate FHE Framework through Binarized Polynomial Rings](https://arxiv.org/abs/2508.02943)
> *通过二值化多项式环实现的非分层可靠近似全同态加密框架*

*Baigang Chen, Dongfang Zhao* | **Category: cs.CR** | **Updated: 2025-08-04**

**Keywords:** 全同态加密, CKKS, 二值化, 多项式环, 纠错码

**Comment:** 

> **TL;DR:** 本文提出了一个基于二值化多项式环的CKKS变体，解决了现有CKKS方案中噪声增长快、参数调整复杂和模切换成本高的问题，并通过集成BCH纠错码实现了可靠的无限深度计算。

**AI_Comments:** 该论文通过将CKKS方案二值化并集成BCH纠错码，创新性地解决了近似FHE中噪声控制和复杂参数调优的挑战。其“非分层”特性和对“无界深度计算”的支持是重要的突破，可能大大扩展FHE在实际应用中的可行性，尤其是在资源受限或需要高效率的场景。这是一个有前景的方向，有望推动FHE的实际部署。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CKKS全同态加密方案存在噪声增长迅速、参数调整复杂以及依赖昂贵的模切换操作等问题，限制了其在机器学习和数值计算工作负载中的应用。

**Method:** 本文提出了一种CKKS的二值变体，该变体完全在二值系数多项式环上操作，并用轻量级自举机制取代了重定标。为缓解二值编码引入的额外比特翻转错误，该框架集成了BCH纠错码以实现鲁棒解密。该开源实现基于HElib库。

**Result:** 经验评估表明，该框架在各种设置下都具有实用性和可扩展性，并且能够在小环维度下实现高效评估和无界深度计算。

**Conclusion:** 通过引入二值系数编码和轻量级自举机制，结合BCH纠错码，该框架实现了在近似全同态加密中可靠且高效的无界深度计算。

> **ai_Abstract:** 本文提出了一个非分层且可靠的近似全同态加密（FHE）框架，通过引入CKKS方案的二值化变体来解决其噪声增长快、参数调整复杂和模切换成本高的问题。该框架在二值系数多项式环上操作，并用轻量级自举机制取代了重定标，同时集成了BCH纠错码以提高解密鲁棒性。该开源实现基于HElib库，支持小环维度下的高效评估和无界深度计算，并通过实证评估验证了其实用性和可扩展性。

> **摘要翻译:** 同态加密（HE）实现了对加密数据的安全计算，保护了云计算、医疗保健和金融等领域的用户隐私。在全同态加密（FHE）方案中，CKKS因支持复数上的近似算术而著称，这是机器学习和数值工作负载的关键要求。然而，CKKS存在噪声增长迅速、参数调整复杂以及依赖昂贵的模切换等问题。我们提出了一种CKKS的二进制变体，它完全在二值系数多项式环上操作，并用轻量级自举机制取代了重定标。为了缓解二进制编码引入的额外比特翻转错误，我们集成了BCH纠错码以实现鲁棒解密。我们的开源实现基于HElib库构建，保留了CKKS的核心代数结构，同时引入了二值系数编码，从而能够在小环维度下进行高效评估并实现无界深度计算。经验评估证明了该框架在各种设置下的实用性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [42] [Lightweight Fault Detection Architecture for NTT on FPGA](https://arxiv.org/abs/2508.03062)
> *轻量级FPGA上NTT的故障检测架构*

*Rourab Paul, Paresh Baidya, Krishnendu Guha* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 后量子密码, 故障检测, NTT, FPGA, 侧信道攻击

**Comment:** 

> **TL;DR:** 本研究提出了一种用于FPGA上数论变换（NTT）的轻量级故障检测架构，通过重计算和内存规则检查实现了高故障覆盖率和低资源消耗，以应对后量子密码硬件实现中的故障注入攻击。

**AI_Comments:** 这篇论文的创新点在于提出了两种针对NTT不同组件（逻辑块和内存）的特定故障检测方法（REMO和Memory Rule Checkers），并且在FPGA上实现了极低的资源消耗和功耗，同时保持了高故障覆盖率。这对于后量子密码算法的硬件安全实现具有重要意义，尤其是在资源受限的环境中。其贡献在于提供了一个高效且轻量级的解决方案来应对日益增长的硬件故障注入攻击威胁。

<details>
  <summary>Details</summary>

**Motivation:** 后量子密码（PQC）算法在硬件实现中容易受到自然故障或故意故障注入（侧信道攻击）的敏感信息泄露，这降低了未来网络安全处理器中密码实现的可靠性。

**Method:** 本研究提出了一种基于重计算的轻量级高效故障检测模块，并在FPGA上实现了数论变换（NTT）。具体方法包括：1) 针对Cooley-Tukey蝶形单元（CT-BU）的逻辑块，使用蒙哥马利约减提出了一种名为“带模偏移的重计算（REMO）”的故障检测方法；2) 针对NTT中使用的内存组件，提出了“内存规则检查器”方法。

**Result:** 所提出的故障检测框架实现了高效率和显著低的实现成本：在Artix-7 FPGA上仅占用16个切片和一个DSP块，功耗仅为3mW。基于REMO的检测机制实现了87.2%至100%的故障覆盖率，可适应不同的字长、故障位数和故障注入模式。内存规则检查器也表现出稳健的性能，根据注入故障的性质，实现了50.7%至100%的故障检测。

**Conclusion:** 该论文提出的故障检测框架通过低实现成本和高效率为NTT的故障检测设定了新的基准。

> **ai_Abstract:** 本文针对后量子密码（PQC）算法在硬件实现中面临的故障注入威胁，提出了一种在FPGA上实现数论变换（NTT）的轻量级故障检测架构。该架构包含两种创新方法：针对Cooley-Tukey蝶形单元（CT-BU）逻辑块的“带模偏移的重计算（REMO）”和针对NTT内存组件的“内存规则检查器”。实验结果表明，该框架在Artix-7 FPGA上实现了极低的资源消耗（16个切片，1个DSP，3mW功耗）和高故障覆盖率（REMO达到87.2%-100%，内存检查器达到50.7%-100%），为PQC硬件的可靠性提供了高效解决方案。

> **摘要翻译:** 后量子密码（PQC）算法在数学上是安全的，并且能够抵抗量子攻击，但由于自然故障或故意故障注入，它们在硬件实现中仍然可能泄露敏感信息。侧信道攻击中的故意故障注入降低了未来网络安全处理器中密码实现的可靠性。在这方面，本研究提出了一种在现场可编程门阵列（FPGA）上实现数论变换（NTT）的轻量级、高效、基于重计算的故障检测模块。NTT主要由存储单元和Cooley-Tukey蝶形单元（CT-BU）组成，CT-BU是多项式乘法中必不可少的关键且计算密集型硬件组件。NTT和多项式乘法是许多PQC算法（包括Kyber、NTRU、Ring-LWE等）中的基本组成部分。在本文中，我们提出了一种针对CT-BU逻辑块的故障检测方法，称为：带模偏移的重计算（REMO），它使用蒙哥马利约减；以及另一种针对NTT内部使用的内存组件的方法，称为内存规则检查器。所提出的故障检测框架通过实现高效率和显著低的实现成本设定了新的基准。它在Artix-7 FPGA中仅占用16个切片和一个DSP块，功耗仅为3mW。基于REMO的检测机制实现了87.2%至100%的故障覆盖率，可适应各种字长、故障位数和故障注入模式。同样，内存规则检查器也表现出强大的性能，根据注入故障的性质，实现了50.7%至100%的故障检测。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [65] [Untraceable DeepFakes via Traceable Fingerprint Elimination](https://arxiv.org/abs/2508.03067)
> *通过可追溯指纹消除实现不可追溯的DeepFakes*

*Jiewei Lai, Lan Zhang, Chen Tang, Pengcheng Sun, Xinming Wang, Yunhao Wang* | **Category: cs.CR, cs.AI** | **Updated: 2025-08-05**

**Keywords:** DeepFakes, 不可追溯性, 归因模型, 乘法攻击, 生成模型

**Comment:** 

> **TL;DR:** 本文提出了一种乘法攻击方法，通过消除生成模型在DeepFakes中留下的痕迹，使其不可追溯，并能有效规避归因模型，即使在存在防御机制的情况下。

**AI_Comments:** 本文的创新之处在于提出了一种新型的乘法攻击，它能够从根本上消除生成模型的痕迹，而非仅仅是扰动，这与以往的规避攻击有本质区别。其黑盒、通用性设计使其具有广泛的适用性。这项工作揭示了DeepFakes归因技术面临的深层漏洞，对未来DeepFakes检测和防御机制的研发具有重要的警示意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管DeepFakes归因技术取得了显著进展，但现有规避攻击未能从根本上消除生成模型的痕迹，仍可被防御措施缓解。因此，需要一种更有效的方法来实现不可追溯的DeepFakes。

**Method:** 本文提出了一种乘法攻击，通过乘法运算从根本上消除生成模型的痕迹。该方法设计为一种通用的黑盒攻击，仅使用真实数据训练对抗模型，适用于多种生成模型且与归因模型无关。

**Result:** 该方法在针对9种生成模型生成的DeepFakes上，对6种先进归因模型实现了97.08%的平均攻击成功率。即使存在防御机制，攻击成功率仍保持在72.39%以上。

**Conclusion:** 乘法攻击带来了潜在的挑战，强调了开发更鲁棒的归因模型的必要性。

> **ai_Abstract:** 本文提出了一种通过乘法攻击实现不可追溯DeepFakes的新方法，旨在从根本上消除生成模型在图像中留下的可追溯痕迹，从而有效规避现有的归因模型，甚至包括那些部署了防御措施的模型。该方法是一种通用的黑盒攻击，仅使用真实数据进行训练，对各种生成模型和归因模型都具有普适性。实验结果表明，该攻击具有极高的成功率，平均攻击成功率高达97.08%，即使在防御机制下也能保持72.39%以上的成功率，这凸显了乘法攻击对DeepFakes归因技术构成的严峻挑战，并强调了开发更鲁棒的归因模型的紧迫性。

> **摘要翻译:** 近年来，DeepFakes归因技术的进步显著增强了取证能力，使得从图像中提取生成模型（GMs）留下的痕迹成为可能，从而使DeepFakes可以追溯到其源生成模型。与此同时，一些攻击试图规避归因模型（AMs）以探索其局限性，这呼吁更鲁棒的归因模型。然而，现有攻击未能消除生成模型的痕迹，因此可以被防御措施缓解。在本文中，我们发现通过乘法攻击可以实现不可追溯的DeepFakes，这种攻击可以从根本上消除生成模型的痕迹，从而规避即使增强了防御措施的归因模型。我们设计了一种通用且黑盒的攻击方法，该方法仅使用真实数据训练对抗模型，适用于各种生成模型且与归因模型无关。实验结果表明，我们的方法具有出色的攻击能力和普遍适用性，在针对由9个生成模型生成的DeepFakes上，对6个先进的归因模型实现了97.08%的平均攻击成功率（ASR）。即使在存在防御机制的情况下，我们的方法仍能保持超过72.39%的ASR。我们的工作强调了乘法攻击带来的潜在挑战，并突出了对更鲁棒的归因模型的需求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [89] [VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](https://arxiv.org/abs/2508.03097)
> *VFLAIR-LLM：一个用于LLM分割学习的综合框架与基准*

*Zixuan Gu, Qiufeng Fan, Long Sun, Yang Liu, Xiaojun Ye* | **Category: cs.CR, cs.AI, I.2.11** | **Updated: 2025-08-05**

**Keywords:** 分割学习, 大型语言模型, 隐私保护, 基准测试, VFLAIR-LLM

**Comment:** 12 pages, 10 figures, published in KDD2025

> **TL;DR:** 针对LLM在资源受限和隐私保护下的应用挑战，本文提出了VFLAIR-LLM框架，一个支持LLM分割学习的轻量级框架，并对其进行了攻击与防御的基准测试，提供了实践建议。

**AI_Comments:** VFLAIR-LLM的创新之处在于其作为首个专门针对LLM分割学习的综合框架和基准，解决了LLM在隐私和资源受限环境下的部署难题。其重要性在于提供了一个实用的解决方案和评估工具，促进了LLM在敏感数据场景下的应用。通过对攻击和防御的广泛基准测试，该工作为实践者提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的普及，用户面临数据隐私和私有部署计算资源限制的问题，这使得在受限本地资源下实现安全的LLM适应性成为挑战。

**Method:** 提出了VFLAIR-LLM框架，这是一个可扩展且轻量级的LLM分割学习框架，支持隐私保护的LLM推理和微调。该框架提供两种LLM分区设置，支持三种任务类型和18个数据集。此外，它还提供用于实现和评估攻击与防御的标准模块。

**Result:** 对5种攻击和9种防御在各种LLM分割学习（SL-LLM）设置下进行了基准测试。

**Conclusion:** 本研究为模型分区配置、防御策略和相关超参数的选择提供了具体的见解和建议，以供实际应用。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在数据隐私和计算资源受限环境下的应用挑战，提出了VFLAIR-LLM框架。VFLAIR-LLM是一个可扩展、轻量级的LLM分割学习框架，旨在实现隐私保护的LLM推理和微调。该框架支持多种分区设置、任务类型和数据集，并包含攻击与防御的评估模块。研究者对多种攻击和防御策略进行了基准测试，为LLM分割学习的实际应用提供了配置和策略建议。

> **摘要翻译:** 随着大型语言模型（LLMs）的进步，LLM应用已扩展到越来越多的领域。然而，关注数据隐私的用户在直接利用LLM API时面临限制，而私有部署则会产生显著的计算需求。这在受限的本地资源下，为实现安全的LLM适应性带来了巨大的挑战。为了解决这个问题，协同学习方法，如分割学习（SL），为将LLMs适应到私有领域提供了一种资源高效且隐私保护的解决方案。在本研究中，我们介绍了VFLAIR-LLM（可在https://github.com/FLAIR-THU/VFLAIR-LLM获取），一个可扩展且轻量级的LLM分割学习框架，能够在资源受限的环境中实现隐私保护的LLM推理和微调。我们的库提供了两种LLM分区设置，支持三种任务类型和18个数据集。此外，我们还提供了用于实现和评估攻击与防御的标准模块。我们对5种攻击和9种防御在各种LLM分割学习（SL-LLM）设置下进行了基准测试，为模型分区配置、防御策略和相关超参数的选择提供了具体的见解和建议，以供实际应用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [121] [Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](https://arxiv.org/abs/2508.03125)
> *攻击消息而非代理：一种针对LLM-MAS的多轮自适应隐蔽篡改框架*

*Bingyu Yan, Ziyi Zhou, Xiaoming Zhang, Chaozhuo Li, Ruilin Zeng, Yirui Qi, Tianbo Wang, Litian Zhang* | **Category: cs.CR, cs.AI, cs.MA** | **Updated: 2025-08-05**

**Keywords:** LLM-MAS, 攻击框架, 通信安全, 隐蔽性, 蒙特卡洛树搜索

**Comment:** 

> **TL;DR:** 提出MAST框架，通过篡改消息而非攻击代理，对LLM-MAS进行隐蔽且高效的多轮攻击。

**AI_Comments:** 这篇论文的创新点在于其“攻击消息而非代理”的视角，专注于利用LLM-MAS的通信漏洞。通过结合MCTS和DPO，MAST实现了自适应和多轮的攻击策略，同时通过双重相似性约束确保了攻击的隐蔽性，这对于现有攻击方法是一个显著的改进。其重要性在于揭示了LLM-MAS中通信层面存在的潜在安全风险，并为未来的安全防护提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型多智能体系统（LLM-MAS）通过智能体间通信完成复杂任务，但这种通信依赖性引入了严重的安全漏洞。现有针对LLM-MAS的攻击方法在有效性、适应性和隐蔽性方面存在局限。

**Method:** 本文提出MAST框架，旨在利用LLM-MAS内部的通信漏洞。MAST结合蒙特卡洛树搜索（MCTS）与直接偏好优化（DPO）来训练一个攻击策略模型，该模型能够自适应地生成有效的多轮篡改策略。为确保隐蔽性，MAST在篡改过程中施加了双重语义和嵌入相似性约束。

**Result:** 在不同任务、通信架构和大型语言模型上的综合实验表明，MAST能够持续实现高攻击成功率，并且与基线方法相比显著增强了攻击的隐蔽性。

**Conclusion:** 研究结果突出了MAST框架的有效性、隐蔽性和适应性，并强调了在LLM-MAS中建立强大通信安全防护的必要性。

> **ai_Abstract:** 本文提出MAST框架，一种针对大型语言模型多智能体系统（LLM-MAS）的、利用通信漏洞的多轮自适应隐蔽篡改方法。MAST结合蒙特卡洛树搜索和直接偏好优化来生成攻击策略，并通过语义和嵌入相似性约束确保攻击的隐蔽性。实验证明，MAST在多种场景下均能实现高攻击成功率和卓越的隐蔽性，揭示了LLM-MAS通信安全防护的必要性。

> **摘要翻译:** 大型语言模型多智能体系统（LLM-MAS）通过智能体间通信有效地完成复杂动态任务，但这种依赖性引入了严重的安全漏洞。现有针对LLM-MAS的攻击方法要么损害智能体内部，要么依赖直接和公开的劝说，这限制了它们的有效性、适应性和隐蔽性。在本文中，我们提出了MAST，一个多轮自适应隐蔽篡改框架，旨在利用系统内的通信漏洞。MAST将蒙特卡洛树搜索与直接偏好优化相结合，训练一个攻击策略模型，该模型自适应地生成有效的多轮篡改策略。此外，为了保持隐蔽性，我们在篡改过程中施加了双重语义和嵌入相似性约束。在不同任务、通信架构和LLM上的综合实验表明，与基线相比，MAST始终能实现高攻击成功率，同时显著增强隐蔽性。这些发现突出了MAST的有效性、隐蔽性和适应性，强调了LLM-MAS中需要强大的通信安全防护。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [161] [Protecting Small Organizations from AI Bots with Logrip: Hierarchical IP Hashing](https://arxiv.org/abs/2508.03130)
> *使用 Logrip 保护小型组织免受 AI 机器人侵害：分层 IP 哈希*

*Rama Carl Hoetzlein* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** AI 机器人, 分层 IP 哈希, 服务器安全, 流量管理, 小型组织

**Comment:** 11 pages, 4 figures

> **TL;DR:** Logrip 使用分层 IP 哈希和数据可视化来识别和管理小型组织服务器上的 AI 机器人流量，有效区分人类和机器人，并缓解性能下降。

**AI_Comments:** 这篇论文的创新点在于提出了“分层 IP 哈希”结合“数据可视化”来识别和管理日益增长的 AI 机器人流量，特别关注小型组织的痛点。其重要性在于提供了一种可能比传统限流方法更有效的解决方案，以应对现代机器人规避技术。通过真实世界数据揭示 AI 机器人流量的巨大占比，强调了该研究的实际需求和价值。

<details>
  <summary>Details</summary>

**Motivation:** 小型组织、初创公司和自托管服务器正面临日益增长的自动化网络爬虫和 AI 机器人的压力，这些机器人能够规避传统限制并导致服务器性能下降。

**Method:** 提出了一种新颖的安全方法，利用数据可视化和分层 IP 哈希来分析服务器事件日志，根据访问模式区分人类用户和自动化实体。通过聚合子网类别的 IP 活动并应用统计测量，该方法能够检测传统工具无法识别的协调机器人活动和分布式爬虫攻击。

**Result:** 通过一个真实世界的例子，估计 80% 到 95% 的流量源自 AI 爬虫，突显了改进过滤机制的必要性。

**Conclusion:** 该方法使小型组织能够有效调节自动化流量，在减轻性能下降的同时保持公共访问。

> **ai_Abstract:** 该论文提出了一种名为 Logrip 的新型安全方法，利用数据可视化和分层 IP 哈希技术分析服务器日志，以帮助小型组织抵御日益增长的 AI 机器人流量。该方法通过分析 IP 访问模式和聚合子网活动来区分人类用户和自动化实体，从而有效检测传统工具难以识别的协调性机器人攻击。研究表明，AI 爬虫占据了服务器流量的绝大部分，Logrip 能够有效调节此类流量，在保护服务器性能的同时维持正常公共访问。

> **摘要翻译:** 小型组织、初创公司和自托管服务器正面临自动化网络爬虫和 AI 机器人日益增长的压力，它们在过去几年中的在线存在显着增加。现代机器人能够规避传统的流量限制，即使行为良好，也能通过巨大的流量导致服务器性能下降。我们引入了一种新颖的安全方法，该方法利用数据可视化和分层 IP 哈希来分析服务器事件日志，根据访问模式区分人类用户和自动化实体。通过聚合子网类别的 IP 活动并应用统计测量，我们的方法能够检测传统工具无法识别的协调机器人活动和分布式爬虫攻击。通过一个真实世界的例子，我们估计 80% 到 95% 的流量源自 AI 爬虫，这突显了改进过滤机制的必要性。我们的方法使小型组织能够有效调节自动化流量，在减轻性能下降的同时保持公共访问。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [201] [WiFinger: Fingerprinting Noisy IoT Event Traffic Using Packet-level Sequence Matching](https://arxiv.org/abs/2508.03151)
> *WiFinger：使用数据包级序列匹配对嘈杂的物联网事件流量进行指纹识别*

*Ronghua Li, Shinan Liu, Haibo Hu, Qingqing Ye, Nick Feamster* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 物联网安全, 流量指纹识别, Wi-Fi, 隐私推断, 序列匹配

**Comment:** 

> **TL;DR:** WiFinger通过将流量模式分类转化为子序列匹配问题，有效识别嘈杂Wi-Fi流量中的多个物联网事件，性能优于现有方法。

**AI_Comments:** WiFinger的创新之处在于将流量模式分类转化为子序列匹配问题，并针对无线流量的噪声和丢包特性进行了优化，显著提升了在Wi-Fi环境下的物联网事件指纹识别准确性。其解决多事件同时跟踪的痛点，对物联网隐私保护领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私推断攻击方法在无线（尤其是Wi-Fi）流量上表现不佳，因为其噪声大、丢包严重，且难以同时跟踪多个物联网事件。

**Method:** 提出WiFinger，一种细粒度的多物联网事件指纹识别方法，针对嘈杂流量。它将流量模式分类任务转化为子序列匹配问题，并引入新技术来解决高时间复杂度的同时保持高准确性。

**Result:** 实验表明，WiFinger在Wi-Fi流量上优于现有方法，对各种物联网事件的平均召回率达到85%（现有方法为0.49%和0.46%），同时对大多数事件的误报率几乎为零。

**Conclusion:** WiFinger能有效且准确地对嘈杂Wi-Fi流量中的多个物联网事件进行指纹识别，显著优于现有技术，为物联网隐私保护提供了新的解决方案。

> **ai_Abstract:** 本文提出了WiFinger，一种针对嘈杂Wi-Fi流量的细粒度多物联网事件指纹识别方法，旨在应对现有方法在无线环境下性能差且无法同时跟踪多个事件的问题。WiFinger将流量模式分类视为子序列匹配问题，并通过创新技术解决了高时间复杂度。实验证明，WiFinger在召回率和误报率方面均显著优于现有方法。

> **摘要翻译:** 物联网环境（如智能家居）容易受到隐私推断攻击，攻击者可以分析加密网络流量的模式来推断设备状态甚至人员活动。虽然大多数现有攻击利用机器学习技术来发现此类流量模式，但由于无线嗅探的严重噪声和数据包丢失，它们在无线流量（尤其是Wi-Fi）上的性能不佳。此外，这些方法通常旨在区分分块的物联网事件流量样本，并且无法有效同时跟踪多个事件。在这项工作中，我们提出了WiFinger，一种针对嘈杂流量的细粒度多物联网事件指纹识别方法。WiFinger将流量模式分类任务转化为子序列匹配问题，并引入了新技术来解决高时间复杂度的同时保持高准确性。实验表明，我们的方法在Wi-Fi流量上优于现有方法，对各种物联网事件的平均召回率达到85%（现有方法为0.49%和0.46%），同时对大多数事件的误报率几乎为零。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [241] [BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03221)
> *BadBlocks：针对文生图扩散模型的低成本隐蔽后门攻击*

*Yu Pan, Jiahao Chen, Lin Wang, Bingrong Dai, Yi Du* | **Category: cs.CR, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 后门攻击, 文生图, 低成本, 隐蔽

**Comment:** 

> **TL;DR:** BadBlocks是一种新型、低成本且隐蔽的后门攻击，专门针对文生图扩散模型，它能以极低的资源消耗成功植入后门并规避当前最先进的防御机制。

**AI_Comments:** BadBlocks的创新之处在于其极低的资源消耗和对现有防御的规避能力。通过选择性地污染UNet架构的特定块，它实现了高效且隐蔽的攻击，同时保持了模型大部分功能的正常。这项工作的重要性在于揭示了扩散模型在后门攻击面前的新型脆弱性，特别是其能够规避先进的防御，并使得攻击成本大大降低，这对于未来的模型安全研究提出了新的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像生成领域取得了显著进展，但也容易受到后门攻击。尽管防御技术不断进步，能够识别和缓解大多数现有后门攻击，但仍缺乏针对更轻量级、更隐蔽攻击的防御方法。本文旨在识别并提出一种新型的威胁，以降低后门攻击的门槛并规避现有防御。

**Method:** 本文提出名为BadBlocks的新型后门攻击，通过选择性地污染扩散模型UNet架构中的特定块来实现。这种方法仅需传统后门攻击约30%的计算资源和20%的GPU时间，同时保持模型其余部分的正常功能。

**Result:** BadBlocks在极度受限的计算资源和GPU时间下，实现了高攻击成功率（ASR）和低感知质量损失（FID分数衡量）。它能够绕过现有的防御框架，特别是基于注意力的后门检测方法。消融研究表明，有效的后门注入无需微调整个网络，且某些神经网络层在后门映射中扮演关键角色。

**Conclusion:** BadBlocks显著降低了进行后门攻击的门槛，使得攻击者即使使用消费级GPU也能向大型扩散模型注入后门，这凸显了它作为一种新型且值得关注的威胁。

> **ai_Abstract:** 本文提出了一种名为BadBlocks的新型后门攻击，专门针对文生图扩散模型。与现有方法相比，BadBlocks更加轻量级且隐蔽，仅需极少的计算资源和GPU时间即可成功注入后门。它通过选择性地污染UNet架构中的特定块来实现攻击，并能有效规避最先进的防御框架。实验证明其具有高攻击成功率和低感知质量损失，并显著降低了后门攻击的门槛，甚至允许使用消费级GPU进行攻击。

> **摘要翻译:** 近年来，扩散模型在图像生成领域取得了显著进展。然而，最近的研究表明，扩散模型容易受到后门攻击，攻击者可以通过向训练数据集中注入特定的视觉模式或文本短语等隐蔽触发器来操纵输出。幸运的是，随着防御技术的不断进步，防御者越来越能够利用视觉检查和基于神经网络的检测方法来识别和缓解大多数后门攻击。然而，在本文中，我们发现了一种比现有方法更轻量级、更隐蔽的新型后门威胁，我们将其命名为BadBlocks，它仅需要之前后门攻击通常所需计算资源的约30%和GPU时间的20%，却能成功注入后门并规避最先进的防御框架。BadBlocks使攻击者能够选择性地污染扩散模型UNet架构内的特定块，同时保持其余组件的正常功能。实验结果表明，即使在计算资源和GPU时间极其受限的情况下，BadBlocks也能实现高攻击成功率（ASR）和低感知质量损失（通过FID分数衡量）。此外，BadBlocks能够绕过现有防御框架，特别是基于注意力的后门检测方法，这凸显了它作为一种新型且值得关注的威胁。消融研究进一步表明，有效的后门注入不需要对整个网络进行微调，并突出了某些神经网络层在后门映射中的关键作用。总的来说，BadBlocks显著降低了进行后门攻击的各个方面的门槛。它使攻击者即使使用消费级GPU也能向大型扩散模型注入后门。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [258] [Revisiting Privacy-Utility Trade-off for DP Training with Pre-existing Knowledge](https://arxiv.org/abs/2409.03344)
> *重新审视利用预存知识进行差分隐私训练的隐私-效用权衡*

*Yu Zheng, Wenchao Zhang, Yonggang Zhang, Yuxiang Peng, Wei Song, Kai Zhou, Xiaojiang Du, Bo Han* | **Category: cs.CR** | **Updated: 2025-08-04**

**Keywords:** 差分隐私, 隐私-效用权衡, 异构噪声, 预存知识, DP-SGD

**Comment:** 16 pages

> **TL;DR:** 本文提出了一种名为DP-Hero的差分隐私框架，通过引入异构噪声并利用预训练模型的知识来指导噪声分配，从而在保护隐私的同时显著提高深度学习模型的训练效用。

**AI_Comments:** 本文的创新点在于提出了异构噪声的概念，并巧妙地利用了“预存知识”（即先前训练模型中编码的信息）来指导噪声的分配，而非简单地均匀添加噪声。这提供了一个有前途的方向来缓解差分隐私训练中固有的隐私-效用冲突，对于实际部署差分隐私模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私随机梯度下降（DP-SGD）通过向梯度更新中添加同质高斯噪声来保护隐私，但这会导致效用损失，因为所有梯度元素都被污染，无论其重要性。现有方法未能充分优化隐私-效用权衡。

**Method:** 本文提出了一种通用的差分隐私框架——DP-Hero（Heterogeneous Noise），它通过定义异构随机机制来优化效用。DP-Hero的核心思想是利用先前训练模型中编码的知识来指导后续异构噪声的分配，从而实现统计扰动并提高效用。作者将DP-Hero实例化为异构版本的DP-SGD，并将其扩展到联邦学习。

**Result:** 实验结果验证了所提出的DP-Hero的有效性，与现有最先进的工作相比，它显著提高了训练准确性。

**Conclusion:** 本文通过学习预存泄漏知识中的噪声指导，改善了隐私-效用空间，提供了一个理解效用提升型差分隐私训练的新视角。

> **ai_Abstract:** 该论文旨在解决差分隐私（DP）训练中同质噪声导致的效用损失问题。作者提出了一种名为DP-Hero的通用差分隐私框架，通过引入异构噪声并利用预训练模型中的知识来指导噪声的差异化分配，从而优化隐私-效用权衡。DP-Hero通过实例化为异构DP-SGD并扩展到联邦学习，在实验中展示了相比现有技术更高的训练准确性，为提升DP训练效用提供了一个新颖的视角。

> **摘要翻译:** 差分隐私（DP）提供了一个可证明的框架，通过在隐私敏感数据集上定制随机机制来保护个体。深度学习模型已显示出模型暴露中的隐私风险，因为已建立的学习模型无意中记录了成员级别隐私泄露。差分隐私随机梯度下降（DP-SGD）已被提出，通过在反向传播中向梯度更新添加随机高斯噪声来保护训练个体。研究人员发现DP-SGD会导致效用损失，因为注入的同质噪声会改变每次迭代计算的梯度更新。也就是说，梯度中的所有元素都被污染，无论它们在更新模型参数中的重要性如何。在这项工作中，我们认为可以通过涉及注入噪声的异构性来优化效用。因此，我们提出了一种具有异构噪声的通用差分隐私框架（DP-Hero），通过定义异构随机机制来抽象其属性。DP-Hero的洞察力是利用先前训练模型中编码的知识来指导后续异构噪声的分配，从而利用统计扰动并实现增强的效用。在DP-Hero之上，我们实例化了一个异构版本的DP-SGD，并将其进一步扩展到联邦训练。我们进行了全面的实验来验证和解释所提出的DP-Hero的有效性，显示出与现有最先进工作相比，训练准确性有所提高。广义上，我们通过从先前训练模型中编码的预存泄漏知识中学习噪声指导，阐明了改进隐私-效用空间的方法，展示了理解效用提升型差分隐私训练的不同视角。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [281] [BDFirewall: Towards Effective and Expeditiously Black-Box Backdoor Defense in MLaaS](https://arxiv.org/abs/2508.03307)
> *BDFirewall：面向MLaaS中有效且快速的黑盒后门防御*

*Ye Li, Chengcheng Zhu, Yanchao Zhao, Jiale Zhang* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 后门防御, MLaaS, 黑盒, 触发器分类, 渐进式防御

**Comment:** 18 pages

> **TL;DR:** BDFirewall是一种针对MLaaS黑盒后门攻击的防御框架，它根据触发器可见性（HVT、SVT、LVT）进行分类，并采用渐进式方法进行移除，显著降低了攻击成功率，提高了中毒样本准确性，并加速了推理时间。

**AI_Comments:** 该论文的创新之处在于其对后门触发器进行了新颖的分类，并据此设计了一个渐进式、多策略的防御框架，能够针对不同类型的触发器进行有效防御。特别是在黑盒场景下无需模型访问的设定，以及实现显著推理速度提升（最高111倍）的成果，都显示出其重要的实际应用价值和技术突破性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决黑盒场景下后门攻击的防御挑战，从而增强MLaaS中推理的安全性。

**Method:** 首先，从对补丁区域影响的新视角，将后门触发器分为高可见性触发器（HVT）、半可见性触发器（SVT）和低可见性触发器（LVT）。在此分类基础上，提出了一种渐进式防御框架BDFirewall，无需模型访问即可从最明显到最细微地移除这些触发器。针对HVT，通过检测显著差异来识别和消除，并恢复补丁区域。针对SVT，将中毒输入建模为触发器与良性特征的混合，将良性特征视为“噪声”，通过去噪过程重建SVT，然后通过减去重建的触发器获得无SVT输入。针对LVT，引入轻量级噪声破坏触发器模式，然后应用DDPM恢复对干净特征的任何附带影响。

**Result:** 综合实验表明，该方法优于现有最先进的防御。与基线相比，BDFirewall平均将攻击成功率（ASR）降低了33.25%，将中毒样本准确率（PA）提高了29.64%，推理时间最高加速了111倍。

**Conclusion:** BDFirewall是一种有效且高效的黑盒后门防御框架，能够成功应对不同类型的后门触发器，显著提升MLaaS推理的安全性。

> **ai_Abstract:** BDFirewall是一种新颖的黑盒后门防御框架，专为MLaaS设计。它将后门触发器根据其可见性分为高、半和低三类，并采用渐进式防御策略。针对高可见性触发器，通过检测并消除局部语义扭曲；针对半可见性触发器，将良性特征视为“噪声”并通过去噪重建并移除触发器；针对低可见性触发器，则引入轻量级噪声结合DDPM进行处理。实验证明，BDFirewall在降低攻击成功率、提高中毒样本准确性以及显著提升推理速度方面，均优于现有先进方法。

> **摘要翻译:** 在本文中，我们致力于解决黑盒场景下后门攻击对策的挑战，从而增强MLaaS中推理的安全性。我们首先从一个新颖的角度，即它们对补丁区域的影响，对后门触发器进行分类，并将其分为：高可见性触发器（HVT）、半可见性触发器（SVT）和低可见性触发器（LVT）。基于此分类，我们提出了一个渐进式防御框架BDFirewall，该框架无需模型访问即可从最明显到最细微地移除这些触发器。首先，对于产生最显著局部语义扭曲的HVT，我们通过检测这些显著差异来识别并消除它们。然后，我们恢复补丁区域以减轻此类移除过程的不利影响。然而，为HVT设计的局部净化对SVT无效，SVT会全局扰动良性特征。因此，我们将SVT中毒输入建模为触发器和良性特征的混合，其中我们非常规地将良性特征视为“噪声”。这种公式允许我们通过应用去噪过程来重建SVT，该过程去除了这些良性“噪声”特征。然后通过减去重建的触发器获得无SVT输入。最后，为了中和几乎无法察觉但脆弱的LVT，我们引入轻量级噪声来破坏触发器模式，然后应用DDPM来恢复对干净特征的任何附带影响。综合实验表明，我们的方法优于现有最先进的防御。与基线相比，BDFirewall平均将攻击成功率（ASR）降低了33.25%，将中毒样本准确率（PA）提高了29.64%，推理时间最高加速了111倍。代码将在接受后公开提供。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [311] [From Legacy to Standard: LLM-Assisted Transformation of Cybersecurity Playbooks into CACAO Format](https://arxiv.org/abs/2508.03342)
> *从传统到标准：LLM辅助将网络安全剧本转换为CACAO格式*

*Mehdi Akbari Gurabi, Lasse Nitz, Radu-Mihai Castravet, Roman Matzutt, Avikarsha Mandal, Stefan Decker* | **Category: cs.CR, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 网络安全剧本, LLM, CACAO格式, 提示工程, 自动化

**Comment:** 20 pages, including appendices, 32 references, 4 tables, 7 main
  figures (some of them has sub-figures)

> **TL;DR:** 本文探讨了使用大型语言模型（LLM）和提示工程，将非机器可读的网络安全剧本自动转换为标准化的CACAO格式，并展示了其在提高准确性和减少错误方面的有效性。

**AI_Comments:** 这项工作在将非结构化网络安全剧本转换为机器可读格式方面具有重要意义，其创新性在于结合LLM、精心设计的提示工程和迭代细化机制来解决语法和语义挑战。这对于提高网络安全操作的自动化和互操作性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有网络安全剧本通常采用异构、非机器可读的格式，这限制了它们在安全编排、自动化和响应平台上的自动化和互操作性。

**Method:** 本文系统地研究了各种提示工程技术，并精心设计了旨在最大化语法准确性和语义保真度的提示。提出了一种模块化转换管道，该管道集成了语法检查器以确保语法正确性，并具有迭代细化机制以逐步减少语法错误。

**Result:** 结果表明，该方法显著提高了剧本转换的准确性，有效捕获了复杂的工作流结构，并大幅减少了错误。

**Conclusion:** 该研究突出了在自动化网络安全剧本转换任务中实际部署的潜力。

> **ai_Abstract:** 本文探讨了利用大型语言模型（LLM）和提示工程，将非机器可读的传统网络安全剧本自动转换为标准化的CACAO格式。研究设计了模块化转换管道，包含语法检查和迭代细化机制，以确保转换的准确性和语义保真度。在自定义数据集上的评估显示，该方法显著提升了转换准确性，有效处理复杂工作流，并大幅减少了错误，展现了其在自动化网络安全剧本转换中的实际应用潜力。

> **摘要翻译:** 现有的网络安全剧本通常以异构、非机器可读的格式编写，这限制了它们在安全编排、自动化和响应平台上的自动化和互操作性。本文探讨了大型语言模型结合提示工程在自动将传统事件响应剧本转换为标准化、机器可读的CACAO格式方面的适用性。我们系统地研究了各种提示工程技术，并精心设计了旨在最大化语法准确性和语义保真度以保留控制流的提示。我们的模块化转换管道集成了语法检查器以确保语法正确性，并具有迭代细化机制，可逐步减少语法错误。我们在一个包含多样化传统剧本和手动创建的CACAO参考的自定义生成数据集上评估了所提出的方法。结果表明，我们的方法显著提高了剧本转换的准确性，有效捕获了复杂的工作流结构，并大幅减少了错误。它突出了在自动化网络安全剧本转换任务中实际部署的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [316] [PrivDiffuser: Privacy-Guided Diffusion Model for Data Obfuscation in Sensor Networks](https://arxiv.org/abs/2412.14499)
> *PrivDiffuser：传感器网络中用于数据混淆的隐私引导扩散模型*

*Xin Yang, Omid Ardakanian* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 数据混淆, 扩散模型, 隐私保护, 传感器网络, 互信息

**Comment:** 

> **TL;DR:** PrivDiffuser是一种基于去噪扩散模型的新型数据混淆技术，通过有效引导和互信息正则化，在传感器网络中实现了数据效用和隐私之间的卓越权衡。

**AI_Comments:** PrivDiffuser的创新之处在于将去噪扩散模型应用于数据混淆领域，并通过引入隐私引导和互信息正则化来优化隐私-效用权衡。其允许用户在不重新训练模型的情况下调整隐私保护级别的能力，显著增强了其实用性和灵活性，对于处理敏感传感器数据的隐私保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 物联网 (IoT) 设备收集的传感器数据可能包含敏感个人信息，当与半信任服务提供商共享时，这些服务提供商可能会使用机器学习模型提取这些信息，从而引发严重的隐私问题。通过生成模型进行数据混淆是一种有前景的方法，可以生成合成数据，在保留原始数据中有用信息的同时模糊敏感信息。

**Method:** 本文提出了PrivDiffuser，一种基于去噪扩散模型的新型数据混淆技术。它通过结合有效的引导技术，实现了数据效用和隐私之间的卓越权衡。具体来说，该方法从传感器数据中提取包含公共和私有属性信息的潜在表示来引导扩散模型，并在学习潜在表示时施加基于互信息的正则化以减轻公共和私有属性的纠缠，从而提高引导的有效性。

**Result:** 在包含不同传感模式的三个真实世界数据集上的评估表明，PrivDiffuser比现有数据混淆技术提供了更好的隐私-效用权衡，效用损失降低高达1.81%，隐私损失降低高达3.42%。此外，与现有混淆方法相比，PrivDiffuser的独特优势在于允许具有不同隐私需求的用户在无需重新训练生成模型的情况下保护其隐私。

**Conclusion:** PrivDiffuser是一种创新的数据混淆技术，它利用去噪扩散模型和有效的引导机制，在保持数据效用的同时显著增强了隐私保护，并且能够灵活地适应不同的用户隐私需求而无需模型重训练。

> **ai_Abstract:** 本文提出了一种名为PrivDiffuser的新型数据混淆技术，旨在解决物联网传感器数据共享中的隐私问题。该方法基于去噪扩散模型，通过提取和引导公共与私有属性的潜在表示，并施加互信息正则化来减少属性纠缠，从而在数据效用和隐私之间实现卓越的权衡。实验结果表明，PrivDiffuser在多个真实世界数据集上优于现有技术，并提供了一项独特优势，即用户无需重新训练模型即可根据其不同的隐私需求进行保护。

> **摘要翻译:** 物联网 (IoT) 设备收集的传感器数据可以揭示个人的敏感个人信息，在与半信任服务提供商共享时会引发重大的隐私问题，因为他们可能使用机器学习模型提取这些信息。由生成模型赋能的数据混淆是一种有前景的方法，用于生成合成数据，从而在保留原始数据中有用信息的同时模糊敏感信息。然后，这些新生成的数据将与服务提供商共享，而不是原始传感器数据。在这项工作中，我们提出了PrivDiffuser，一种基于去噪扩散模型的新型数据混淆技术，通过结合有效的引导技术，实现了数据效用和隐私之间的卓越权衡。具体来说，我们从传感器数据中提取包含公共和私有属性信息的潜在表示来引导扩散模型，并在学习潜在表示时施加基于互信息的正则化以减轻公共和私有属性的纠缠，从而提高引导的有效性。在包含不同传感模式的三个真实世界数据集上的评估表明，PrivDiffuser比现有数据混淆技术提供了更好的隐私-效用权衡，效用损失降低高达1.81%，隐私损失降低高达3.42%。此外，与现有混淆方法相比，PrivDiffuser的独特优势在于允许具有不同隐私需求的用户在无需重新训练生成模型的情况下保护其隐私。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [351] [Smart Car Privacy: Survey of Attacks and Privacy Issues](https://arxiv.org/abs/2508.03413)
> *智能汽车隐私：攻击与隐私问题综述*

*Akshay Madhav Deshmukh* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 智能汽车隐私, VANETs, 安全攻击, 隐私问题, 防御机制

**Comment:** 13 pages, 16 figures

> **TL;DR:** 本文综述了智能汽车中车辆自组织网络（VANETs）的安全和隐私问题，包括各种攻击、防御机制以及隐私影响。

**AI_Comments:** 本文作为一篇综述性文章，系统地梳理了智能汽车和VANETs领域的安全与隐私挑战，对于理解该领域的现状和未来研究方向具有重要价值。其创新点在于全面分类了攻击类型和防御机制，为后续研究提供了扎实的基础。然而，作为一篇综述，它并未提出新的解决方案或实验结果。

<details>
  <summary>Details</summary>

**Motivation:** 现代汽车日益计算机化并提供无线连接，这使得它们容易受到攻击。车辆自组织网络（VANETs）作为智能交通系统的关键技术，其安全和隐私问题由于车辆的移动性而成为主要关注点。因此，设计安全机制以消除网络中的对手至关重要。

**Method:** 本文概述了各种车载网络架构、现代汽车安全演变、VANETs中的各种安全和隐私攻击及其防御机制（附示例并分类），并概述了车载网络可能带来的各种隐私影响。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究对智能汽车中的安全和隐私问题进行了全面综述，特别关注车辆自组织网络（VANETs）。论文探讨了现代汽车的脆弱性、VANETs作为智能交通系统组成部分的重要性，并详细介绍了VANETs中存在的各种安全和隐私攻击及其相应的防御机制，并对这些机制进行了分类。此外，它还讨论了车载网络带来的隐私影响。

> **摘要翻译:** 汽车在我们的日常生活中变得越来越重要。现代汽车高度计算机化，因此可能容易受到攻击。为车辆提供许多无线连接，在车辆与其外部环境之间建立了桥梁。这种联网汽车解决方案有望成为汽车革命的下一个前沿，也是向下一代智能交通系统发展的关键。车载自组织网络（VANETs）是一种新兴的移动自组织网络技术，它结合了用于车辆间数据通信的移动路由协议，以支持智能交通系统。因此，由于车辆的移动性，安全和隐私是VANETs中的主要关注点。因此，在VANETs中设计安全机制以消除网络中的对手显得尤为重要。
本文概述了各种车载网络架构。现代汽车安全的发展。VANETs中的各种安全和隐私攻击及其防御机制（附示例并对这些机制进行分类）。它还概述了车载网络可能带来的各种隐私影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [359] [FFCBA: Feature-based Full-target Clean-label Backdoor Attacks](https://arxiv.org/abs/2504.21054)
> *FFCBA：基于特征的全目标无标签后门攻击*

*Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Liantao Wu, Zhe Li, Weifeng Liu* | **Category: cs.CR, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 后门攻击, 无标签攻击, 多目标攻击, 基于特征, 自编码器

**Comment:** 

> **TL;DR:** 本文提出FFCBA，一种基于特征的全目标无标签后门攻击，通过FSBA和FMBA两种范式解决了现有无标签攻击性能不足和多目标攻击易被检测的问题，并在实验中展现了出色的攻击性能和对先进防御的鲁棒性。

**AI_Comments:** FFCBA的创新点在于其提出了基于特征的无标签全目标后门攻击，通过FSBA和FMBA两种范式，有效解决了传统无标签攻击性能不足和多目标攻击隐蔽性差的问题。它利用类别条件自编码器生成精细的触发器，同时兼顾了攻击效率和跨模型泛化能力，这对于提升后门攻击的隐蔽性和有效性，以及未来后门防御的研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多目标后门攻击遵循脏标签范式，中毒样本被错误标记且通常需要极高的中毒率，易被手动检测。而无标签攻击虽更隐蔽，但通常难以实现稳定和令人满意的攻击性能，并且难以有效扩展到多目标攻击。

**Method:** 本文提出了基于特征的全目标无标签后门攻击（FFCBA），包含两种范式：特征跨越后门攻击（FSBA）和特征迁移后门攻击（FMBA）。FSBA利用类别条件自编码器生成噪声触发器，使受扰动的同类样本与原始类别特征对齐，确保触发器的有效性、类内一致性、类间特异性和自然特征相关性。FMBA采用两阶段类别条件自编码器训练过程，交替使用类外和类内样本，以生成具有强目标类别特征的触发器，使其对跨模型攻击非常有效。

**Result:** 实验在多个数据集和模型上进行，结果表明FFCBA实现了出色的攻击性能，并对最先进的后门防御保持了理想的鲁棒性。

**Conclusion:** FFCBA有效地解决了现有无标签和多目标后门攻击的局限性，提供了一种隐蔽、稳定且可扩展的解决方案，具有强大的攻击性能和对防御的鲁棒性。

> **ai_Abstract:** 本文提出了一种名为FFCBA（基于特征的全目标无标签后门攻击）的新型方法，旨在克服现有无标签攻击性能不稳定以及多目标脏标签攻击易被检测的缺点。FFCBA包含两种核心范式：FSBA（特征跨越后门攻击）和FMBA（特征迁移后门攻击）。FSBA利用类别条件自编码器生成与原始特征对齐的噪声触发器，实现高效且隐蔽的攻击。FMBA则通过两阶段训练，生成具有强目标类特征的触发器，增强了跨模型攻击能力。实验证明，FFCBA在攻击效果和对主流后门防御的鲁棒性方面均表现出色。

> **摘要翻译:** 后门攻击对深度神经网络构成重大威胁，因为被后门攻击的模型会将带有特定触发器的中毒样本错误分类到目标类别，同时保持在干净样本上的正常性能。其中，多目标后门攻击可以同时针对多个类别。然而，现有的多目标后门攻击都遵循脏标签范式，其中中毒样本被错误标记，并且大多数需要极高的中毒率。这使得它们很容易通过人工检查检测出来。相比之下，无标签攻击更隐蔽，因为它们避免修改中毒样本的标签。然而，它们通常难以实现稳定和令人满意的攻击性能，并且往往无法有效地扩展到多目标攻击。为了解决这个问题，我们提出了基于特征的全目标无标签后门攻击（FFCBA），它包含两种范式：特征跨越后门攻击（FSBA）和特征迁移后门攻击（FMBA）。FSBA利用类别条件自编码器生成噪声触发器，使受扰动的同类样本与原始类别的特征对齐，确保触发器的有效性、类内一致性、类间特异性和自然特征相关性。虽然FSBA支持快速高效的攻击，但其跨模型攻击能力相对较弱。FMBA采用两阶段类别条件自编码器训练过程，交替使用类外样本和类内样本。这使得FMBA能够生成具有强目标类别特征的触发器，使其对跨模型攻击非常有效。我们在多个数据集和模型上进行了实验，结果表明FFCBA实现了出色的攻击性能，并对最先进的后门防御保持了理想的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [380] [Unravelling the Probabilistic Forest: Arbitrage in Prediction Markets](https://arxiv.org/abs/2508.03474)
> *揭示概率森林：预测市场中的套利*

*Oriol Saguillo, Vahid Ghafouri, Lucianna Kiffer, Guillermo Suarez-Tangil* | **Category: cs.CR, q-fin.TR** | **Updated: 2025-08-05**

**Keywords:** 预测市场, 套利, Polymarket, 定价错误, 链上数据

**Comment:** 

> **TL;DR:** 本文对预测市场平台 Polymarket 上的套利现象进行了实证分析，揭示了两种套利形式，并发现用户已利用这些机会提取了约4000万美元的利润。

**AI_Comments:** 这篇论文的创新之处在于它首次对预测市场中的套利现象进行了大规模的实证分析，并揭示了两种具体的套利形式。其解决大规模数据比较挑战的启发式归约策略也值得关注。研究结果量化了预测市场中因定价不一致而产生的巨大套利利润，这对于理解此类市场的效率和参与者行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管预测市场平台 Polymarket 的设计要求相关结果的总价格应为1美元（代表总概率为1），但其平台上出现了相关资产定价错误的情况，从而产生了套利机会，允许用户通过买卖特定结果来保证获利。本文旨在探究这些套利机会的产生条件、是否真实发生以及是否已被利用。

**Method:** 作者对 Polymarket 数据进行了实证套利分析。为克服分析相关市场间套利的比较规模挑战（朴素分析需要 $O(2^{n+m})$ 次比较），他们采用了一种基于时效性、主题相似性和组合关系启发式驱动的归约策略，并通过专家输入进行了验证。研究使用了链上历史订单簿数据来分析套利机会的存在和执行情况。

**Result:** 研究揭示了 Polymarket 上两种不同形式的套利：市场再平衡套利（Market Rebalancing Arbitrage），发生在单一市场或条件内；以及组合套利（Combinatorial Arbitrage），跨越多个市场。通过分析链上历史订单簿数据，发现用户已通过这些套利机会提取了约4000万美元的估计利润。

**Conclusion:** 预测市场平台 Polymarket 上存在显著的套利机会，且这些机会已被用户成功利用，产生了巨大的利润。

> **ai_Abstract:** 本文对预测市场平台 Polymarket 上的套利现象进行了深入的实证分析。尽管平台设计旨在避免定价错误，但研究发现存在两种主要形式的套利机会：市场内部的“市场再平衡套利”和跨市场的“组合套利”。为应对大数据分析挑战，作者开发了一种启发式归约策略。通过分析链上历史订单簿数据，研究证实了这些套利机会的真实存在，并揭示用户已通过利用这些不一致性获得了高达4000万美元的估计利润。

> **摘要翻译:** Polymarket 是一个预测市场平台，用户可以通过交易与特定结果（称为条件）相关的份额来推测未来事件。每个市场都与一组一个或多个此类条件相关联。为确保市场正确结算，条件集必须是详尽的——共同涵盖所有可能的结果——并且是互斥的——只有一个条件可能解析为真。因此，所有相关结果的总价格应为1美元，代表任何结果的总概率为1。尽管有此设计，Polymarket 仍存在相关资产定价错误的情况，允许以低于（或高于）1美元的价格购买（或出售）某个确定结果，从而保证获利。这种被称为套利的现象，可能使老练的参与者利用这些不一致性。

  在本文中，我们对 Polymarket 数据进行了实证套利分析，以回答三个关键问题：（Q1）什么条件会引起套利？（Q2）Polymarket 上是否真的发生套利？以及（Q3）是否有人利用了这些机会？分析相关市场之间套利的一个主要挑战在于大量市场和条件之间的比较可扩展性，朴素分析需要 $O(2^{n+m})$ 次比较。为了克服这一点，我们采用了一种基于时效性、主题相似性和组合关系的启发式驱动归约策略，并通过专家输入进一步验证。

  我们的研究揭示了 Polymarket 上两种不同形式的套利：市场再平衡套利（Market Rebalancing Arbitrage），发生在单一市场或条件内；以及组合套利（Combinatorial Arbitrage），跨越多个市场。我们使用链上历史订单簿数据来分析这些类型的套利机会何时存在以及何时被用户执行。我们发现已提取的实际利润估计为4000万美元。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [415] [LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning](https://arxiv.org/abs/2506.06742)
> *LADSG：垂直联邦学习中用于标签隐私的标签匿名蒸馏和相似梯度替换*

*Zeyu Yan, Yifei Yao, Xuanbing Wen, Shixiong Zhang, Juli Zhang, Kai Fan* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 垂直联邦学习, 标签隐私, 标签推断攻击, 梯度替换, 软蒸馏

**Comment:** Under review

> **TL;DR:** 提出LADSG，一种垂直联邦学习的轻量级防御框架，通过标签匿名和梯度替换有效抵御标签推断攻击。

**AI_Comments:** LADSG的创新点在于其统一的防御框架，能够同时应对多种类型的标签推断攻击，并通过标签匿名化和梯度替换提供了多层保护。其轻量级和与标准VFL管道的兼容性使其在实际VFL部署中具有较高的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 垂直联邦学习（VFL）面临内部攻击者进行标签推断攻击的风险，现有防御措施通常只针对孤立的泄露向量或特定类型的攻击，对于新兴的利用多个途径的混合攻击仍然脆弱。

**Method:** LADSG（Label-Anonymized Defense with Substitution Gradient）是一个统一且轻量级的VFL防御框架。它首先通过软蒸馏匿名化真实标签以减少语义暴露，然后生成语义对齐的替代梯度以扰乱基于梯度的泄露，最后通过梯度范数检测过滤异常更新。

**Result:** 在六个真实世界数据集上的广泛实验表明，LADSG将所有三种标签推断攻击的成功率降低了30-60%，且计算开销极小。

**Conclusion:** LADSG是一种有效且实用的统一轻量级防御框架，能够显著提高垂直联邦学习中的标签隐私性，抵御多种标签推断攻击。

> **ai_Abstract:** 本文提出了LADSG，一个针对垂直联邦学习（VFL）中标签隐私的统一轻量级防御框架。针对现有防御措施无法有效抵御混合标签推断攻击的问题，LADSG通过软蒸馏匿名化真实标签以减少语义暴露，生成语义对齐的替代梯度以扰乱梯度泄露，并通过梯度范数检测过滤异常更新。实验结果表明，LADSG在六个真实世界数据集上能将所有三类标签推断攻击的成功率降低30-60%，同时计算开销极小，证明了其在VFL中保护标签隐私的实用性和有效性。

> **摘要翻译:** 垂直联邦学习（VFL）已成为跨分布式特征空间进行协作模型训练的一种有前景的范式，它实现了在不共享原始数据的情况下保护隐私的学习。然而，最近的研究证实了内部攻击者进行标签推断攻击的可行性。通过战略性地利用梯度向量和语义嵌入，攻击者——通过被动、主动或直接攻击——可以准确地重建私有标签，导致灾难性的数据泄露。现有的防御措施通常只针对孤立的泄露向量或专为特定类型的攻击设计，对于同时利用多个途径的新兴混合攻击仍然脆弱。为了弥补这一差距，我们提出了LADSG（Label-Anonymized Defense with Substitution Gradient），一个统一且轻量级的VFL防御框架。LADSG首先通过软蒸馏匿名化真实标签以减少语义暴露，然后生成语义对齐的替代梯度以扰乱基于梯度的泄露，最后通过梯度范数检测过滤异常更新。它具有可扩展性，并与标准VFL管道兼容。在六个真实世界数据集上进行的广泛实验表明，LADSG将所有三种标签推断攻击的成功率降低了30-60%，且计算开销极小，证明了其实际有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [421] [Intrusion Detection in Heterogeneous Networks with Domain-Adaptive Multi-Modal Learning](https://arxiv.org/abs/2508.03517)
> *异构网络中基于域适应多模态学习的入侵检测*

*Mabin Umman Varghese, Zahra Taghiyarrenani* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** 网络入侵检测, 深度学习, 多模态学习, 域适应, 异构网络

**Comment:** 

> **TL;DR:** 本文提出一个结合多模态学习和域适应的深度神经网络模型，用于异构网络入侵检测，解决了传统模型对大量标注数据和数据异构性的依赖，并在实验中表现出优越的泛化能力。

**AI_Comments:** 这篇论文的创新点在于将多模态学习与域适应技术相结合，解决了网络入侵检测中常见的跨域数据异构性和标注数据稀缺问题。通过顺序循环处理数据，模型能够更好地从多样化数据集中学习和泛化，这对于应对不断演变的网络威胁具有重要意义。该方法提高了模型在现实复杂网络环境中的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统深度神经网络模型在网络入侵检测中受限于对大量标注数据集的需求以及不同网络域之间数据和特征异构性带来的挑战。

**Method:** 提出了一种深度神经网络模型，该模型将多模态学习与域适应技术相结合进行分类。它以顺序循环的方式处理来自不同来源的数据，从而能够从多个数据集中学习并适应不同的特征空间。

**Result:** 实验结果表明，该模型在网络入侵分类方面显著优于基线神经网络模型，尤其是在样本可用性和概率分布变化的情况下。该模型能够泛化到异构数据集。

**Conclusion:** 该模型能够泛化到异构数据集，使其成为现实世界网络入侵检测的有效解决方案。

> **ai_Abstract:** 本文针对传统深度学习网络入侵检测系统在处理异构数据和缺乏标注数据方面的局限性，提出了一种结合多模态学习和域适应的深度神经网络模型。该模型能够顺序循环处理来自不同来源的数据，有效学习并适应不同的特征空间。实验证明，该模型在网络入侵分类任务中显著优于现有基线模型，尤其在数据分布不均时表现出强大的泛化能力，为现实世界异构网络环境下的入侵检测提供了一种高效解决方案。

> **摘要翻译:** 网络入侵检测系统（NIDS）在保护网络基础设施免受网络攻击方面发挥着关键作用。随着这些攻击的普遍性和复杂性增加，机器学习和深度神经网络方法已成为增强NIDS检测恶意活动能力的有效工具。然而，传统深度神经网络模型的有效性常常受限于需要大量的标注数据集以及不同网络域之间数据和特征异构性带来的挑战。为了解决这些限制，我们开发了一种深度神经网络模型，该模型集成了多模态学习和域适应技术进行分类。我们的模型以顺序循环的方式处理来自不同来源的数据，使其能够从多个数据集中学习并适应不同的特征空间。实验结果表明，我们提出的模型在网络入侵分类方面显著优于基线神经网络模型，尤其是在样本可用性和概率分布变化的情况下。该模型的性能突出了其在异构数据集上泛化的能力，使其成为现实世界网络入侵检测的有效解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [463] [MalFlows: Context-aware Fusion of Heterogeneous Flow Semantics for Android Malware Detection](https://arxiv.org/abs/2508.03588)
> *MalFlows: 面向安卓恶意软件检测的异构流语义上下文感知融合*

*Zhaoyi Meng, Fenglei Xu, Wenxiang Zhao, Wansen Wang, Wenchao Huang, Jie Cui, Hong Zhong, Yan Xiong* | **Category: cs.CR, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 安卓恶意软件检测, 异构流语义, 上下文感知, 异构信息网络, flow2vec

**Comment:** Submitted to TDSC

> **TL;DR:** MalFlows 是一种新颖的安卓恶意软件检测技术，它通过上下文感知的方式融合了异构流语义，并利用异构信息网络和新的嵌入技术提高了检测精度。

**AI_Comments:** MalFlows 的创新之处在于首次实现了对安卓应用中异构流（控制流、数据流、ICC）的上下文感知融合，并通过引入异构信息网络（HIN）和定制的 flow2vec 嵌入技术，有效解决了现有静态分析方法中语义互补性利用不足和上下文不敏感的问题。其结合深度学习进行分类也增强了模型的判别能力。这项研究对于提升安卓恶意软件检测的精度和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的安卓恶意软件检测方法难以有效利用不同类型流（控制流、数据流、组件间通信）之间的语义互补性来表示程序行为，且其上下文不敏感的特性阻碍了跨流语义集成的准确性。

**Method:** 本文提出了 MalFlows，一种上下文感知融合异构流语义的安卓恶意软件检测技术。它采用异构信息网络（HIN）对程序流中的丰富语义进行建模，并进一步提出了 flow2vec，一种上下文感知的 HIN 嵌入技术，能够根据跨流的上下文约束区分 HIN 实体的语义，并通过联合使用多个元路径学习准确的应用程序表示。这些表示最终输入到基于通道注意力的深度神经网络进行恶意软件分类。

**Result:** MalFlows 在包含超过 31,000 个真实应用程序中提取的 2000 多万个流实例的大规模数据集上进行了评估。实验结果表明，MalFlows 在安卓恶意软件检测方面优于代表性基线，同时验证了 flow2vec 在从异构流构建的 HIN 中准确学习应用程序表示的有效性。

**Conclusion:** MalFlows 通过上下文感知融合异构流语义，显著提高了安卓恶意软件检测的准确性，并且首次全面聚合了多样化的流相关信息来评估应用程序的恶意性。

> **ai_Abstract:** MalFlows 是一种用于安卓恶意软件检测的新型技术，它解决了现有方法在融合异构流语义和上下文感知方面的不足。该方法利用异构信息网络（HIN）对控制流、数据流和组件间通信的语义进行建模，并提出了上下文感知的 flow2vec 嵌入技术来学习准确的应用程序表示。这些表示随后被输入到基于通道注意力的深度神经网络进行分类。实验证明，MalFlows 在大规模数据集上优于现有基线，并有效提升了恶意软件检测的准确性。

> **摘要翻译:** 静态分析是安卓应用检查中的一项基本技术，能够提取控制流、数据流和组件间通信（ICC），所有这些对于恶意软件检测都至关重要。然而，现有方法难以利用不同类型流之间的语义互补性来表示程序行为，并且其上下文不敏感的特性进一步阻碍了跨流语义集成的准确性。我们提出并实现了 MalFlows，这是一种新颖的技术，旨在实现异构流语义的上下文感知融合，用于安卓恶意软件检测。我们的目标是利用三种类型流相关信息的互补优势进行精确的应用画像。我们采用异构信息网络（HIN）对这些程序流中的丰富语义进行建模。我们进一步提出了 flow2vec，这是一种上下文感知的 HIN 嵌入技术，它根据不同流之间的上下文约束按需区分 HIN 实体的语义，并通过联合使用多个元路径学习准确的应用程序表示。这些表示最终输入到一个基于通道注意力的深度神经网络进行恶意软件分类。据我们所知，这是首次全面聚合多样化的流相关信息来评估应用程序内部恶意性的研究。我们在一个包含从超过 31,000 个真实世界应用程序中提取的 2000 多万个流实例的大规模数据集上评估了 MalFlows。实验结果表明，MalFlows 在安卓恶意软件检测方面优于代表性基线，同时验证了 flow2vec 在从异构流构建的 HIN 中准确学习应用程序表示的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [471] [ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space](https://arxiv.org/abs/2506.10323)
> *ELFuzz：通过LLM驱动的模糊器空间合成实现高效输入生成*

*Chuyang Chen, Brendan Dolan-Gavitt, Zhiqiang Lin* | **Category: cs.CR, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 模糊测试, LLM, 输入生成, 自动化, 零日漏洞

**Comment:** Accepted by USENIX Security'25 Cycle 2

> **TL;DR:** ELFuzz 是一种新的模糊测试方法，它利用大型语言模型（LLM）自动合成模糊器，显著减少了手动工作量，并在大规模真实世界系统中提高了覆盖率并发现了更多错误，包括零日漏洞。

**AI_Comments:** ELFuzz 的创新之处在于将大型语言模型应用于模糊器合成，实现了模糊测试过程的高度自动化，显著减少了传统方法所需的手动工作量。其通过LLM驱动的演化和模糊器空间模型，能够生成高效且人类可理解的模糊器，并在大规模真实世界系统中展现出卓越的性能，甚至发现了零日漏洞，这凸显了其在软件测试和安全领域的巨大价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于生成的模糊测试需要大量手动工作来构建输入语法和语义约束的规范。该论文旨在解决这一手动工作量大的问题。

**Method:** ELFuzz 提出了一种通过LLM驱动的合成方法，在模糊器空间上自动合成针对特定测试系统（SUT）的基于生成的模糊器。它从最小的种子模糊器开始，通过LLM驱动的自动化演化和覆盖率指导来推动合成。其关键组成部分是模糊器空间模型。

**Result:** ELFuzz 与手动编写的规范和现有先进方法相比，实现了高达434.8%的覆盖率提升，并触发了多达174.0%的人工注入错误。它成功应用于高达1,791,104行代码的真实世界SUT。在一项针对最新版cvc5的14天模糊测试活动中，ELFuzz 发现了五个零日漏洞（其中三个可被利用）。消融研究显示，模糊器空间模型对ELFuzz的有效性贡献最大（高达62.5%）。ELFuzz 合成的模糊器能够以人类可理解的方式捕获有趣的语法结构和语义约束。

**Conclusion:** ELFuzz 展示了在模糊测试中实现更自动化、高效和可扩展的输入生成的巨大潜力。

> **ai_Abstract:** ELFuzz 提出了一种基于大型语言模型（LLM）驱动合成的新型模糊测试方法，旨在解决传统生成式模糊测试中手动构建输入规范的痛点。该方法通过LLM驱动的演化和覆盖率指导，自动合成高效且人类可理解的模糊器。实验证明，ELFuzz 在处理大规模真实系统时表现出色，显著提高了代码覆盖率，发现了更多注入错误，并成功发现了真实世界软件中的零日漏洞。其核心的模糊器空间模型对性能提升贡献显著，展现了自动化、高效和可扩展模糊测试的巨大潜力。

> **摘要翻译:** 基于生成的模糊测试根据输入语法和语义约束的规范生成适当的测试用例来测试系统和软件。然而，这些规范的构建需要大量的手动工作。本文提出了一种新方法ELFuzz（通过大型语言模型进行模糊测试的演化），它通过LLM驱动的模糊器空间合成，自动合成针对被测系统（SUT）的基于生成的模糊器。从高层次来看，它从最小的种子模糊器开始，并通过LLM驱动的、有覆盖率指导的全自动化演化来推动合成。与以前的方法相比，ELFuzz 可以1）无缝扩展到真实世界规模的SUT——在我们的评估中，代码行数高达1,791,104行——以及2）合成能够以人类可理解的方式捕获有趣的语法结构和语义约束的高效模糊器。我们的评估将ELFuzz 与领域专家手动编写的规范以及最先进方法合成的规范进行了比较。结果表明，ELFuzz 实现了高达434.8%的覆盖率提升，并触发了多达174.0%的人工注入错误。我们还使用ELFuzz 对最新版本的cvc5进行了为期14天的真实世界模糊测试，令人鼓舞的是，它发现了五个零日漏洞（其中三个可被利用）。此外，我们进行了一项消融研究，结果表明，模糊器空间模型作为ELFuzz的关键组成部分，对其有效性的贡献最大（高达62.5%）。对ELFuzz 合成的模糊器进行的进一步分析证实，它们能够以人类可理解的方式捕获有趣的语法结构和语义约束。这些结果展示了ELFuzz 在模糊测试中实现更自动化、高效和可扩展的输入生成方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [518] [CyGym: A Simulation-Based Game-Theoretic Analysis Framework for Cybersecurity](https://arxiv.org/abs/2506.21688)
> *CyGym：一个基于仿真的网络安全博弈论分析框架*

*Michael Lanier, Yevgeniy Vorobeychik* | **Category: cs.CR, cs.GT** | **Updated: 2025-08-05**

**Keywords:** 网络安全, 博弈论, 模拟器, APT, 零日攻击

**Comment:** 

> **TL;DR:** 本文介绍了CyGym，一个基于OpenAI Gym的模拟器和博弈论框架，用于分析网络防御者与攻击者之间的网络安全对抗，并成功应用于分析Volt Typhoon APT，展示了博弈论策略在理解网络弹性方面的有效性。

**AI_Comments:** CyGym的创新之处在于其将现实世界网络安全特征与博弈论分析相结合的模拟器设计，特别是在零日攻击建模和采用PSRO风格方法计算均衡方面。这为网络安全领域的策略分析提供了一个强大的工具，有助于更好地理解复杂威胁并制定更有效的防御策略。其重要性体现在能够为防御者提供关于最优防御姿态和威胁缓解的量化洞察，尤其是在面对如APT等高级威胁时。

<details>
  <summary>Details</summary>

**Motivation:** 为了促进网络安全领域的博弈论建模和分析，同时保持对现实网络防御重要特征的模拟，本文旨在引入一个新颖的网络安全对抗模拟器。

**Method:** 本文引入了一个名为CyGym的新型网络安全对抗模拟器，该模拟器构建于OpenAI Gym框架内，并融入了真实的网络拓扑、漏洞、攻击（包括零日攻击）和防御机制。此外，本文提出了一个基于该模拟器的形式化仿真博弈论网络防御模型，该模型包含一种新颖的零日攻击建模方法，并采用PSRO风格的方法近似计算博弈中的均衡。该模拟器和框架被用于分析Volt Typhoon高级持续性威胁（APT）。

**Result:** 实验结果表明，博弈论策略在理解网络针对APT和零日攻击（如Volt Typhoon）的弹性方面是有效的。

**Conclusion:** 博弈论策略能够为理解网络弹性提供有价值的见解，并为优化防御姿态和主动威胁缓解提供指导。

> **ai_Abstract:** 本文提出了CyGym，一个基于OpenAI Gym框架的新型网络安全对抗模拟器，旨在促进网络防御者与攻击者之间的博弈论建模与分析，同时保留现实网络防御的关键特性。该模拟器集成了真实的网络环境要素，并结合了新颖的零日攻击建模和PSRO风格的均衡计算方法，构建了一个形式化的博弈论模型。通过对Volt Typhoon高级持续性威胁的分析，研究结果验证了博弈论策略在评估网络对APT和零日攻击弹性的有效性，为优化防御策略和主动威胁缓解提供了重要洞察。

> **摘要翻译:** 我们引入了一个新颖的网络安全对抗模拟器，用于网络防御者和攻击者之间，旨在促进博弈论建模和分析，同时保持真实网络防御的许多重要特征。我们的模拟器构建于OpenAI Gym框架内，整合了真实的网络拓扑、漏洞、攻击（包括零日攻击）和防御机制。此外，我们利用该模拟器提供了一个形式化的基于仿真的网络防御博弈论模型，该模型采用了一种新颖的零日攻击建模方法，以及一种PSRO风格的方法来近似计算该博弈中的均衡。我们使用我们的模拟器和相关的博弈论框架来分析Volt Typhoon高级持续性威胁（APT）。Volt Typhoon代表了一种由国家支持的行动者所采用的复杂网络攻击策略，其特点是隐秘的、长时间的渗透和网络漏洞的利用。我们的实验结果证明了博弈论策略在理解网络针对APT和零日攻击（如Volt Typhoon）的弹性方面的有效性，为最优防御姿态和主动威胁缓解提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [554] [LeakyCLIP: Extracting Training Data from CLIP](https://arxiv.org/abs/2508.00756)
> *LeakyCLIP：从CLIP中提取训练数据*

*Yunhao Chen, Shujie Wang, Xin Wang, Xingjun Ma* | **Category: cs.CR** | **Updated: 2025-08-05**

**Keywords:** CLIP, 数据提取, 隐私泄露, 图像重建, 多模态模型

**Comment:** 

> **TL;DR:** LeakyCLIP是一种新的攻击框架，能够从CLIP模型中高精度地重建训练图像，揭示了多模态模型中普遍存在的隐私泄露风险。

**AI_Comments:** LeakyCLIP提供了一种新颖且实用的方法来探测CLIP模型的数据隐私风险，其创新性在于结合了对抗性微调、嵌入对齐和Stable Diffusion细化等多种技术来克服CLIP反演的挑战，并显著提高了重建质量。这项工作对于理解和缓解多模态模型中的隐私泄露问题具有重要意义，尤其是在当前多模态AI模型广泛应用的背景下，其发现对于模型安全性和负责任的AI开发具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 理解对比语言-图像预训练（CLIP）中的记忆化和隐私泄露风险对于确保多模态模型的安全性至关重要。鉴于最近研究表明扩散模型存在提取敏感训练数据的可能性，本工作旨在深入调查CLIP中的数据记忆和提取风险。

**Method:** 本研究引入了LeakyCLIP，一个新颖的攻击框架，旨在通过CLIP反演过程（即从文本提示中重建训练图像）实现高质量、语义准确的图像重建。为了解决CLIP反演中存在的非鲁棒特征、文本嵌入中有限的视觉语义以及低重建保真度这三个关键挑战，LeakyCLIP采用了以下策略：1) 对抗性微调以增强优化平滑度；2) 基于线性变换的嵌入对齐；3) 基于Stable Diffusion的细化以提高重建保真度。

**Result:** 实证结果表明LeakyCLIP表现优越，与LAION-2B子集上基线方法相比，对于ViT-B-16的结构相似性指数（SSIM）提高了358%以上。此外，研究揭示了普遍存在的泄露风险，即使从低保真重建的指标中也能成功推断出训练数据的成员身份。

**Conclusion:** 本工作引入了一种实用的CLIP反演方法，同时为多模态模型中隐私风险的性质和范围提供了新颖的见解。

> **ai_Abstract:** LeakyCLIP是一个新颖的攻击框架，旨在通过CLIP反演从文本提示中重建高质量、语义准确的训练图像，从而深入研究CLIP模型中的数据记忆和隐私泄露风险。该框架通过对抗性微调、线性变换嵌入对齐和基于Stable Diffusion的细化，有效解决了CLIP反演中非鲁棒特征、有限视觉语义和低重建保真度等关键挑战。实验结果表明，LeakyCLIP在图像重建质量上显著优于现有方法，并揭示了多模态模型中普遍存在的训练数据泄露风险，即使是低保真重建也能推断出训练数据成员身份。这项工作为理解和缓解多模态模型的隐私问题提供了新的视角和实用方法。

> **摘要翻译:** 理解对比语言-图像预训练（CLIP）中的记忆化和隐私泄露风险对于确保多模态模型的安全性至关重要。最近的研究表明从扩散模型中提取敏感训练示例是可行的，其中条件扩散模型表现出更强的记忆和泄露信息倾向。在本工作中，我们通过CLIP反演（一个旨在从文本提示中重建训练图像的过程）的视角，调查了CLIP中的数据记忆和提取风险。为此，我们引入了\textbf{LeakyCLIP}，一个新颖的攻击框架，旨在从CLIP嵌入中实现高质量、语义准确的图像重建。我们确定了CLIP反演中的三个关键挑战：1）非鲁棒特征，2）文本嵌入中有限的视觉语义，以及3）低重建保真度。为了解决这些挑战，LeakyCLIP采用了1）对抗性微调以增强优化平滑度，2）基于线性变换的嵌入对齐，以及3）基于Stable Diffusion的细化以提高保真度。实证结果表明LeakyCLIP的优越性，与LAION-2B子集上的基线方法相比，对于ViT-B-16的结构相似性指数（SSIM）提高了358%以上。此外，我们揭示了普遍存在的泄露风险，表明即使从低保真重建的指标中也能成功推断出训练数据的成员身份。我们的工作引入了一种实用的CLIP反演方法，同时为多模态模型中隐私风险的性质和范围提供了新颖的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [588] [Quantum-Resistant RSA Modulus Decomposition via Adaptive Rényi Entropy Optimization](https://arxiv.org/abs/2508.00840)
> *通过自适应Rényi熵优化实现抗量子RSA模数分解*

*Ruopengyu Xu, Chenglian Liu* | **Category: cs.CR, math.NT, quant-ph, 94A60, 11Y05, 11T71, 81P94, 68Q12, E.3; F.2.1; G.3; K.6.5; C.1.m** | **Updated: 2025-08-05**

**Keywords:** RSA, 量子抗性, Rényi熵, 素数选择, Shor算法

**Comment:** 11 pages , 2 tables

> **TL;DR:** 本文通过优化素数选择并施加Rényi熵约束，探索了一种增强RSA抗量子攻击能力的理论方法，旨在提高Shor算法的复杂度，同时保持经典安全性。

**AI_Comments:** 本文提出了一种创新的方法，将数论（Maynard素数间隔定理）与量子信息理论（Rényi熵）相结合，以增强经典加密算法的抗量子能力。其创新之处在于通过优化素数选择的内在特性来提高量子攻击的难度，而非仅仅依赖于更大的密钥长度。这为构建后量子密码学提供了一个新的理论视角，但其实用性和在实际系统中的部署仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过优化素数选择并施加Rényi熵约束，增强RSA对量子攻击的抵抗力。

**Method:** 本文开发了一个框架，通过控制素数接近度（$|p-q| < \gamma\sqrt{pq}$）来生成素数，以最小化量子周期查找算子的碰撞熵$\mathscr{H}_2$。主要贡献包括：建立素数分布性质与量子攻击复杂性之间的联系（通过Maynard素数间隔定理），提供熵约束下素数存在的建设性证明，以及在量子随机预言模型下证明了安全性可归约为理想格问题。

**Result:** 理论分析表明，对于具有$\gamma < k^{-1/2+\epsilon}$的k比特模数，Shor算法需要$\Omega(\gamma^{-1}k^{3/2})$次量子操作，同时保持与标准RSA等效的经典安全性。关键增强包括：通过Maynard定理证明素数存在性，将SVP归约嵌入理想格，量子Fano界用于信息论分析，以及多素数RSA扩展。

**Conclusion:** 通过对RSA模数分解的素数选择进行Rényi熵优化，可以显著提高Shor算法的量子操作复杂度，同时不影响其经典安全性，从而增强RSA的抗量子能力。

> **ai_Abstract:** 本文提出了一种通过Rényi熵优化素数选择来增强RSA抗量子攻击能力的新颖理论方法。通过控制素数接近度以最小化量子周期查找算子的碰撞熵，该研究利用Maynard素数间隔定理建立了素数分布与量子攻击复杂性之间的联系，并提供了熵约束下素数存在的证明。理论分析显示，这种方法能显著增加Shor算法所需的量子操作次数，同时维持标准的经典安全性，并通过理想格嵌入和量子Fano界等技术进一步强化。

> **摘要翻译:** 本文探讨了一种通过Rényi熵约束优化素数选择来增强RSA抗量子攻击能力的理论方法。我们开发了一个框架，在该框架中，通过控制素数接近度（$|p-q| < \gamma\sqrt{pq}$）来生成素数，以最小化量子周期查找算子的碰撞熵$\mathscr{H}_2$。
主要贡献包括：（1）通过Maynard素数间隔定理建立了素数分布性质与量子攻击复杂性之间的联系；（2）提供了熵约束下素数存在的建设性证明；（3）在量子随机预言模型下证明了安全性可归约为理想格问题。
理论分析表明，对于具有$\gamma < k^{-1/2+\epsilon}$的k比特模数，Shor算法需要$\Omega(\gamma^{-1}k^{3/2})$次量子操作，同时保持与标准RSA等效的经典安全性。关键增强包括：（1）通过Maynard定理（定理3.1）证明素数存在性；（2）用于SVP归约的理想格嵌入（定理5.3）；（3）用于信息论分析的量子Fano界（定理6.3）；（4）多素数RSA扩展（7.3节）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [623] [BlockA2A: Towards Secure and Verifiable Agent-to-Agent Interoperability](https://arxiv.org/abs/2508.01332)
> *BlockA2A：迈向安全可验证的智能体间互操作性*

*Zhenhua Zou, Zhuotao Liu, Lepeng Zhao, Qiuyang Zhan* | **Category: cs.CR, cs.AI, 68T42 (Primary), 94A60 (Secondary), I.2.11; E.3** | **Updated: 2025-08-05**

**Keywords:** 多智能体系统安全, 智能体互操作性, 去中心化标识符, 区块链, 大型语言模型

**Comment:** 43 pages

> **TL;DR:** BlockA2A提出了一种统一的多智能体信任框架，利用去中心化标识符、区块链和智能合约来解决LLM驱动的多智能体系统中的安全漏洞，并引入防御编排引擎以实时中和攻击。

**AI_Comments:** 本文创新性地将去中心化技术（DIDs、区块链、智能合约）引入到LLM驱动的多智能体系统的安全框架中，解决了传统安全策略的不足。其提出的BlockA2A和防御编排引擎（DOE）为未来AI智能体系统的安全和可信赖性提供了重要的解决方案，并且通过实际实现和性能评估验证了其可行性。

<details>
  <summary>Details</summary>

**Motivation:** LLM驱动的多智能体系统在企业生态系统中得到快速应用，但存在身份框架碎片化、通信渠道不安全以及对拜占庭智能体或对抗性提示防御不足等关键安全漏洞。现有的安全策略无法有效解决这些新兴风险。

**Method:** 本文提出了BlockA2A，一个统一的多智能体信任框架。它采用去中心化标识符（DIDs）实现细粒度跨域智能体认证，区块链锚定的账本实现不可篡改的审计性，以及智能合约动态执行上下文感知访问控制策略。此外，提出了防御编排引擎（DOE）通过实时机制（包括拜占庭智能体标记、响应式执行停止和即时权限撤销）主动中和攻击。

**Result:** 经验评估表明BlockA2A在中和基于提示、基于通信、行为和系统性的MAS攻击方面是有效的。实验证实BlockA2A和DOE的开销在亚秒级，支持在生产LLM多智能体环境中可扩展部署。

**Conclusion:** BlockA2A通过消除中心化信任瓶颈、确保消息真实性和执行完整性以及保证智能体交互的可追溯性，为LLM驱动的多智能体系统提供了安全、可验证的智能体间互操作性。

> **ai_Abstract:** 本文针对LLM驱动的多智能体系统（MASes）面临的安全挑战，如身份碎片化、通信不安全和对抗性攻击防御不足，提出了BlockA2A框架。BlockA2A利用去中心化标识符（DIDs）、区块链和智能合约构建统一的多智能体信任机制，以实现安全可验证的智能体间互操作性。此外，引入防御编排引擎（DOE）进行实时攻击中和。实验证明了BlockA2A在应对多种MAS攻击方面的有效性，并且具有低开销，适用于生产环境部署。

> **摘要翻译:** 由大型语言模型（LLM）驱动的智能AI的快速采用，正在通过执行复杂工作流的自主智能体改变企业生态系统。然而，我们观察到LLM驱动的多智能体系统（MASes）中存在几个关键的安全漏洞：碎片化的身份框架、不安全的通信渠道以及对拜占庭智能体或对抗性提示的防御不足。在本文中，我们首次系统分析了这些新兴的多智能体风险，并解释了为什么传统的安全策略无法有效解决这些风险。随后，我们提出了BlockA2A，这是第一个统一的多智能体信任框架，它实现了安全可验证的智能体间互操作性。从高层次来看，BlockA2A采用去中心化标识符（DIDs）实现细粒度跨域智能体认证，区块链锚定的账本实现不可篡改的审计性，以及智能合约动态执行上下文感知访问控制策略。BlockA2A消除了中心化信任瓶颈，确保消息真实性和执行完整性，并保证智能体交互的可追溯性。此外，我们提出了一个防御编排引擎（DOE），通过实时机制（包括拜占庭智能体标记、响应式执行停止和即时权限撤销）主动中和攻击。经验评估证明了BlockA2A在中和基于提示、基于通信、行为和系统性MAS攻击方面的有效性。我们将其集成到现有MAS中的方式进行了形式化，并展示了Google A2A协议的实际实现。实验证实BlockA2A和DOE以亚秒级的开销运行，使得在生产LLM多智能体环境中能够进行可扩展部署。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [667] [ConfGuard: A Simple and Effective Backdoor Detection for Large Language Models](https://arxiv.org/abs/2508.01365)
> *ConfGuard：一种简单有效的LLM后门检测方法*

*Zihan Wang, Rui Zhang, Hongwei Li, Wenshu Fan, Wenbo Jiang, Qingchuan Zhao, Guowen Xu* | **Category: cs.CR, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 后门检测, 大型语言模型, 序列锁定, 置信度, 实时检测

**Comment:** Under review

> **TL;DR:** ConfGuard通过监控LLM输出的置信度来实时检测后门攻击，效果显著。

**AI_Comments:** 该论文的创新点在于发现了LLM后门攻击中“序列锁定”这一行为差异，并基于此设计了轻量级且高效的检测方法ConfGuard。其重要性在于提供了一种实用的、低延迟的LLM后门防御方案，解决了现有方法在LLM场景下的局限性，对于LLM的安全部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对大型语言模型（LLM）后门攻击的防御方法主要为分类任务设计，对LLM的自回归特性和巨大的输出空间无效，导致性能差和延迟高，因此需要一种更有效的方法来解决这些限制。

**Method:** 本文研究了良性LLM和后门LLM在输出空间的行为差异，发现了一个关键现象——“序列锁定”：后门模型在生成目标序列时具有异常高且一致的置信度。基于此，提出了ConfGuard，这是一种轻量级且有效的检测方法，通过监控令牌置信度的滑动窗口来识别序列锁定。

**Result:** 广泛的实验表明，ConfGuard在绝大多数情况下实现了接近100%的真阳性率（TPR）和可忽略不计的假阳性率（FPR）。

**Conclusion:** ConfGuard几乎不增加额外延迟即可实现实时检测，使其成为实际LLM部署中实用的后门防御方法。

> **ai_Abstract:** 本文提出了ConfGuard，一种针对大型语言模型（LLM）后门攻击的轻量级实时检测方法。该方法基于对良性与后门LLM行为差异的研究，特别是发现后门模型在生成目标序列时表现出异常高的“序列锁定”置信度。ConfGuard通过监控滑动窗口中的token置信度来识别这一现象。实验证明，ConfGuard在检测后门攻击方面具有极高的准确率和极低的误报率，且几乎不引入额外延迟，使其适用于实际LLM部署。

> **摘要翻译:** 后门攻击对大型语言模型（LLM）构成了重大威胁，攻击者可以嵌入隐藏的触发器来操纵LLM的输出。大多数现有防御方法主要为分类任务设计，对LLM的自回归特性和巨大的输出空间无效，因此性能不佳且延迟高。为了解决这些限制，我们研究了良性LLM和后门LLM在输出空间的行为差异。我们发现了一个关键现象，称之为“序列锁定”：与良性生成相比，后门模型在生成目标序列时具有异常高且一致的置信度。基于这一见解，我们提出了ConfGuard，一种轻量级且有效的检测方法，它通过监控令牌置信度的滑动窗口来识别序列锁定。广泛的实验表明，ConfGuard在绝大多数情况下实现了接近100%的真阳性率（TPR）和可忽略不计的假阳性率（FPR）。至关重要的是，ConfGuard几乎不增加额外延迟即可实现实时检测，使其成为实际LLM部署中实用的后门防御。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [902] [Real-World Evaluation of Protocol-Compliant Denial-of-Service Attacks on C-V2X-based Forward Collision Warning Systems](https://arxiv.org/abs/2508.02805)
> *基于蜂窝车联网（C-V2X）的前向碰撞预警系统的协议合规拒绝服务攻击的现实世界评估*

*Jean Michel Tine, Mohammed Aldeen, Abyad Enan, M Sabbir Salek, Long Cheng, Mashrur Chowdhury* | **Category: cs.CR** | **Updated: 2025-08-04**

**Keywords:** C-V2X, 前向碰撞预警, 拒绝服务攻击, 协议合规, 基本安全消息

**Comment:** This paper was submitted to the Transportation Research Board (TRB)
  2026 and is under review

> **TL;DR:** 该研究评估了在C-V2X前向碰撞预警（FCW）系统中，利用UDP泛洪和超大基本安全消息（BSM）的协议合规拒绝服务（DoS）攻击的实际效果。研究表明，这些攻击能够严重损害FCW系统的性能，导致通信失败，从而无法发出预警。

**AI_Comments:** 该研究具有重要的现实意义，因为它揭示了即使通信协议得到遵守，C-V2X系统仍然容易受到可能危及安全的攻击。研究方法采用了实际测试平台，增加了结果的可信度。然而，研究可能未涵盖所有类型的DoS攻击或所有C-V2X安全应用场景，未来的研究可以扩展到更广泛的攻击向量和应用。

<details>
  <summary>Details</summary>

**Motivation:** 评估C-V2X技术在实际应用中，特别是前向碰撞预警系统（FCW）中，是否存在协议合规的拒绝服务（DoS）攻击的风险，以及这些攻击对系统性能的影响。

**Method:** 研究人员构建了一个实际的联网车辆测试平台，使用了市售的车载单元（OBUs），并模拟了两种协议合规的DoS攻击：使用用户数据报协议（UDP）泛洪和超大尺寸的基本安全消息（BSM）。这些攻击严格遵守3GPP和SAE J2735规范，但在异常高的速率和超大载荷下发送。

**Result:** UDP泛洪攻击单独使用时，可将数据包递送率降低高达87%，并将延迟增加到400毫秒以上。超大尺寸的BSM泛洪攻击会使接收器处理资源过载，导致FCW警报延迟或完全被抑制。当两种攻击同时进行时，会导致近乎完全的通信失败， FCW预警功能完全失效。

**Conclusion:** 研究结果表明，即使通信符合协议规定，也不能保证基于C-V2X的安全应用（如FCW系统）能够安全可靠地运行。协议合规性本身并不能防御精心设计的DoS攻击。

> **ai_Abstract:** 本研究评估了在C-V2X网络中，通过UDP泛洪和超大BSM消息的协议合规拒绝服务（DoS）攻击对前向碰撞预警（FCW）系统的实际影响。研究在真实测试环境中进行，结果表明这些攻击能够显著降低数据包递送率、增加延迟，甚至完全阻止FCW预警，证明了协议合规性并不足以保证C-V2X安全应用的可靠性。

> **摘要翻译:** 蜂窝车联网（C-V2X）技术能够实现低延迟、高可靠性的通信，这对于前向碰撞预警（FCW）系统等安全应用至关重要。C-V2X的部署严格遵循第三代合作伙伴项目（3GPP）和汽车工程师学会标准（SAE）J2735规范，以确保互操作性。本文展示了对协议合规的拒绝服务（DoS）攻击的真实世界测试平台评估，这些攻击利用了用户数据报协议（UDP）泛洪和超大尺寸的基本安全消息（BSM），利用了C-V2X中传输层和应用层的漏洞。本研究提出的攻击通过标准的PC5侧行链路传输有效报文，完全符合3GPP和SAE J2735规范，但其速率异常高且载荷超大，在不违反IEEE 1609等任何协议规则的情况下，使接收器资源过载。我们使用配备商用车载单元（OBUs）的真实联网车辆测试平台，证明了高速率的UDP泛洪和超大载荷的BSM泛洪会严重损害FCW性能。结果表明，单独的UDP泛洪攻击使数据包递送率降低高达87%，并将延迟增加到400毫秒以上，而超大尺寸的BSM泛洪则使接收器处理资源过载，导致FCW警报延迟或完全被抑制。当UDP和BSM攻击同时进行时，它们会导致近乎完全的通信失败，完全阻止FCW预警。这些发现揭示了，协议合规的通信并不一定能保证基于C-V2X的安全应用的运行安全或可靠性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [930] [Thermal-Aware 3D Design for Side-Channel Information Leakage](https://arxiv.org/abs/2508.02816)
> *面向侧信道信息泄露的热感知3D设计*

*Dylan Stow, Russell Barnes, Eren Kurshan, Yuan Xie* | **Category: cs.CR, cs.ET** | **Updated: 2025-07-24**

**Keywords:** 热侧信道攻击,3D集成,侧信道信息泄露,活动模式,芯片安全

**Comment:** 

> **TL;DR:** 该论文提出了一种利用3D集成技术和动态活动模式来隐藏关键活动，以应对热侧信道攻击的方法，实验证明该方法能有效降低侧信道漏洞因子和空间热侧信道因子。

**AI_Comments:** 该研究在侧信道攻击防御领域具有重要意义，特别是针对热侧信道攻击提出了创新的3D设计方法。利用3D集成技术的空间特性来隐藏信息流是一个有前景的方向。然而，动态生成活动模式的计算开销和对芯片整体性能的影响可能需要进一步的评估。

<details>
  <summary>Details</summary>

**Motivation:** 侧信道攻击是重要的安全挑战，特别是热侧信道攻击能够泄露芯片活动信息，甚至加密密钥。因此，需要一种方法来主动隐藏关键活动，同时最小化功耗。

**Method:** (i) 利用3D集成技术的固有特性来防御侧信道攻击；(ii) 动态生成自定义活动模式，以匹配功能层中需要隐藏的活动。

**Result:** 3D技术结合提出的运行时算法能有效将侧信道漏洞因子（SVF）降低到0.05以下，空间热侧信道因子（STSF）降低到0.59以下。

**Conclusion:** 3D集成技术和动态活动模式相结合，能够有效地降低热侧信道攻击的风险。

> **ai_Abstract:** 该研究提出了一种创新的热感知3D设计方法，旨在解决侧信道攻击中的热侧信道信息泄露问题。该方法利用3D集成技术的优势，结合动态生成的自定义活动模式，以隐藏芯片关键功能层的活动，同时有效控制功耗。实验结果表明，该方法能够显著降低侧信道漏洞因子（SVF）和空间热侧信道因子（STSF），为芯片安全提供了有效的解决方案。

> **摘要翻译:** 侧信道攻击是重要的安全挑战，因为它们会泄露关于芯片活动的敏感信息。在这些攻击中，热侧信道已被证明可以揭示关键功能块的活动，甚至加密密钥。本文提出了一种新颖的方法，通过（i）利用3D集成的固有特性来防御侧信道攻击，以及（ii）动态生成自定义活动模式来匹配功能层中需要隐藏的活动，从而主动隐藏关键活动，同时最小化功耗。实验分析表明，3D技术结合所提出的运行时算法能够有效地将侧信道漏洞因子（SVF）降低到0.05以下，并将空间热侧信道因子（STSF）降低到0.59以下。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [951] [Agentic Privacy-Preserving Machine Learning](https://arxiv.org/abs/2508.02836)
> *Agentic隐私保护机器学习*

*Mengyu Zhang, Zhuotao Liu, Jingwen Huang, Xuanqi Liu* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 隐私保护机器学习,大型语言模型,Agentic-PPML,加密推理,意图理解

**Comment:** 

> **TL;DR:** 该论文提出了一种名为Agentic-PPML的新框架，通过将LLM的意图理解与专门模型的加密推理分离，解决了现有隐私保护机器学习（PPML）在处理大型语言模型（LLMs）时效率低下（比明文推理慢10000倍以上）的问题，从而实现实用的隐私保护LLM服务。

**AI_Comments:** 该论文提出了一种创新的方法来解决LLM隐私保护中的效率瓶颈，通过模块化设计将不同计算任务分配给最适合的模型。这种方法具有重要的实际意义，但其在不同领域和模型上的通用性以及实际部署的复杂性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有隐私保护机器学习（PPML）方案在处理数十亿参数的大型语言模型（LLMs）时效率低下，与明文推理相比慢至少10000倍，并且随着上下文长度的增加，性能差距会更大，这阻碍了LLMs在AI中的实际应用。

**Method:** 提出了一种名为Agentic-PPML的新框架，该框架利用通用的LLM进行意图理解，并将加密安全推理委托给在垂直领域训练的专用模型。通过将通常不涉及敏感信息的语言意图解析与隐私关键计算模块化地分离，避免了LLM处理加密提示的需求。

**Result:** Agentic-PPML框架通过将意图解析与加密推理分离，避免了LLM处理加密提示，从而实现了实用的隐私保护LLM部署。

**Conclusion:** Agentic-PPML框架通过模块化设计，有效解决了现有PPML在LLMs上面临的效率瓶颈，为部署隐私保护的LLM服务提供了可行的解决方案。

> **ai_Abstract:** 该论文提出了一种名为Agentic-PPML的新框架，旨在解决现有隐私保护机器学习（PPML）在处理大型语言模型（LLMs）时效率低下的问题。通过将LLM的意图理解与专门模型的加密推理分离，Agentic-PPML避免了LLM处理加密提示，从而实现了更实用的隐私保护LLM服务。

> **摘要翻译:** 隐私保护机器学习（PPML）对于确保AI中的数据隐私至关重要。在过去的几年里，社区提出了各种基于各种密码学原语的可证明安全的PPML方案。然而，当涉及到拥有数十亿参数的大型语言模型（LLMs）时，PPML的效率是不可接受的。例如，目前最先进的机密LLM推理解决方案比明文推理慢至少10000倍。当上下文长度增加时，性能差距甚至更大。在本篇立场文件中，我们提出了一个名为Agentic-PPML的新颖框架，以使LLM中的PPML变得实用。我们的关键见解是利用通用的LLM进行意图理解，并将加密安全推理委托给在垂直领域训练的专用模型。通过将通常涉及很少或不涉及敏感信息的语言意图解析与隐私关键计算进行模块化分离，Agentic-PPML完全消除了LLM处理加密提示的需求，从而能够实用部署以LLM为中心的隐私保护服务。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [973] [LMDG: Advancing Lateral Movement Detection Through High-Fidelity Dataset Generation](https://arxiv.org/abs/2508.02942)
> *LMDG：通过高保真数据集生成推进横向移动检测*

*Anas Mabrouk, Mohamed Hatem, Mohammad Mamun, Sherif Saad* | **Category: cs.CR** | **Updated: 2025-08-04**

**Keywords:** 横向移动检测, 数据集生成, 进程树标签, MITRE ATT&CK, 网络安全

**Comment:** 

> **TL;DR:** 该研究提出了LMDG框架，用于生成高保真度的横向移动攻击数据集，解决了现有数据集的不足，并通过进程树标签技术实现了精细化的攻击步骤和TTPs关联。

**AI_Comments:** 该研究通过LMDG框架和进程树标签技术，解决了横向移动攻击数据集稀缺的问题，并实现了对攻击过程的精细化标注，具有重要的实际意义和研究价值。其生成的数据集规模大、真实性高，为相关检测技术的评估提供了有力支撑。然而，该方法在不同规模和复杂度的企业环境中的通用性和可扩展性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有横向移动检测系统的开发和评估受到缺乏真实、标注良好数据集的阻碍。

**Method:** 提出LMDG框架，通过自动化良性活动生成、多阶段攻击执行和系统/网络日志的全面标注来生成高保真度横向移动数据集。该框架的核心是进程树标签技术，这是一种基于代理的技术，能够高精度地追踪所有恶意活动到其源头，并实现对恶意日志条目的精确、分步标注，将其与特定的攻击步骤和MITRE ATT&CK TTPs相关联。

**Result:** 使用LMDG在一个包含22个用户账户的25虚拟机企业环境中生成了一个为期25天的数据集。该数据集包含944 GB的主机和网络日志，嵌入了35次多阶段横向移动攻击，恶意事件占比低于1%，真实地反映了用于评估检测系统的良性与恶意活动比例。LMDG生成的数据集在攻击多样性、攻击模式时效性、攻击时间跨度、数据源全面性、网络架构真实性以及标注准确性方面优于现有数据集。

**Conclusion:** LMDG框架能够生成高质量、精细标注的横向移动数据集，为开发和评估更有效的检测系统提供了关键支持，特别是其进程树标签技术为理解和检测多步骤攻击提供了前所未有的细粒度上下文。

> **ai_Abstract:** LMDG是一个用于生成高保真横向移动攻击数据集的框架，解决了现有数据集的不足。它通过自动化流程和创新的进程树标签技术，实现了对多阶段攻击的精细化标注，并生成了一个包含真实网络环境和攻击模式的大规模数据集，为开发更有效的检测系统提供了支持。

> **摘要翻译:** 横向移动（LM）攻击持续对企业安全构成重大威胁，使攻击者能够隐秘地攻陷关键资产。然而，缺乏真实、标注良好的数据集阻碍了LM检测系统的开发和评估。为了解决这一差距，我们提出了LMDG，一个用于生成高保真度LM数据集的可重现和可扩展框架。LMDG自动化了良性活动生成、多阶段攻击执行以及系统和网络日志的全面标注，大大减少了手动工作量，并实现了可扩展的数据集创建。LMDG的一个核心贡献是进程树标签，一种新颖的基于代理的技术，能够高精度地追踪所有恶意活动到其源头。与诸如注入时序或行为画像等先前方法不同，进程树标签能够对恶意日志条目进行准确、分步的标注，将其与特定的攻击步骤和MITRE ATT&CK TTPs相关联。据我们所知，这是第一个支持多步骤攻击的细粒度标注的方法，为诸如攻击路径重建等检测模型提供了关键的上下文。我们使用LMDG在一个包含22个用户账户的25虚拟机企业环境中生成了一个为期25天的数据集。该数据集包含944 GB的主机和网络日志，并嵌入了35次多阶段LM攻击，恶意事件占总活动的不到1%的比例，反映了用于评估检测系统的真实的良性与恶意比例。LMDG生成的数据集在提供多样化的LM攻击、最新的攻击模式、更长的攻击时间框架、全面的数据源、真实的网络架构以及更准确的标注方面优于现有数据集。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [7] [MetaScope: Optics-Driven Neural Network for Ultra-Micro Metalens Endoscopy](https://arxiv.org/abs/2508.03596)
> *MetaScope：光学驱动的超微型超透镜内窥镜神经网络*

*Wuyang Li, Wentao Pan, Xiaoyuan Liu, Zhendong Luo, Chenxin Li, Hengyu Liu, Din Ping Tsai, Mu Ku Chen, Yixuan Yuan* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 超透镜内窥镜, 光学驱动神经网络, 强度衰减, 色差校正, MetaScope

**Comment:** ICCV 2025 (Highlight); Project Page:
  https://cuhk-aim-group.github.io/MetaScope/

> **TL;DR:** MetaScope是一个光学驱动的神经网络，通过解决强度衰减和色差问题，显著提升了超微型超透镜内窥镜的图像分割和恢复性能，并在真实生物医学场景中展现出良好的泛化能力。

**AI_Comments:** MetaScope的创新之处在于其将物理光学原理与深度学习相结合，特别设计了OIA和OCC模块来解决超透镜特有的成像问题，这在超微型内窥镜领域具有重要意义。通过建立专门的数据集并进行光学模拟，该研究系统性地弥补了超透镜成像在算法和数据方面的不足。其在真实生物医学场景中的良好泛化能力，预示着其在实际临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有内窥镜受限于凸透镜的毫米级厚度，难以应用于微米级临床场景。超透镜作为一种有前景的微米级解决方案，但在数据采集和算法研究方面存在空白，尤其面临强度衰减和色差等光学问题。

**Method:** 本文首先建立了超透镜内窥镜数据集并进行了光学模拟，识别出两个主要光学问题。其次，提出了MetaScope，一个新型的光学驱动神经网络。MetaScope包含两个核心设计：光学信息强度调整（OIA）通过学习光学嵌入纠正强度衰减；光学信息色差校正（OCC）通过学习点扩散函数（PSF）分布指导的空间变形来减轻色差。为增强联合学习，还采用了梯度引导蒸馏技术，自适应地从基础模型中迁移知识。

**Result:** MetaScope在超透镜分割和恢复方面均优于现有最先进的方法，并在真实的生物医学场景中表现出令人印象深刻的泛化能力。

**Conclusion:** MetaScope成功弥补了超透镜内窥镜在数据和算法上的空白，通过创新的光学驱动神经网络设计，有效解决了图像质量问题，并在临床应用中展现出优越的性能和泛化能力。

> **ai_Abstract:** 本文针对传统内窥镜厚度限制和超透镜内窥镜在数据与算法上的空白，提出了MetaScope，一个光学驱动的神经网络框架。该框架通过光学信息强度调整（OIA）和光学信息色差校正（OCC）两大创新模块，分别解决超透镜成像中的强度衰减和色差问题。此外，引入梯度引导蒸馏以增强联合学习。实验证明，MetaScope在超透镜图像分割和恢复任务上超越了现有技术，并在真实生物医学场景中展现出强大的泛化能力，为超微型内窥镜提供了有效解决方案。

> **摘要翻译:** 微型内窥镜技术已推动了人体内部精确视觉感知的进步。然而，目前的研究仍局限于采用凸透镜的传统相机，其毫米级厚度的物理限制严重阻碍了微观层面的临床应用。近年来，随着超表面光学器件的兴起，基于超透镜（微米级）的超微成像受到了广泛关注，被视为一种有前景的解决方案。然而，由于超透镜的物理特性差异，在数据采集和算法研究方面存在巨大空白。鉴于此，我们旨在弥合这一未被探索的空白，推动新型超透镜内窥镜技术的发展。首先，我们建立了超透镜内窥镜数据集并进行了初步光学模拟，识别出两个物理上符合强光学先验的衍生光学问题。其次，我们提出了MetaScope，一个专为超透镜内窥镜量身定制的、由物理光学驱动的新型光学驱动神经网络。MetaScope包含两项新颖设计：光学信息强度调整（OIA），通过学习光学嵌入来纠正强度衰减；以及光学信息色差校正（OCC），通过学习由点扩散函数（PSF）分布指导的空间变形来减轻色差。为了增强联合学习，我们进一步部署了梯度引导蒸馏技术，以自适应地从基础模型中迁移知识。大量实验表明，MetaScope不仅在超透镜分割和恢复方面均优于现有最先进的方法，而且在真实的生物医学场景中也取得了令人印象深刻的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [16] [GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing](https://arxiv.org/abs/2508.02831)
> *GENIE：用于神经辐射场交互式编辑的高斯编码*

*Mikołaj Zieliński, Krzysztof Byrski, Tomasz Szczepanik, Przemysław Spurek* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 神经辐射场, 高斯泼溅, 交互式编辑, 实时渲染, 3D场景表示

**Comment:** 

> **TL;DR:** GENIE结合了NeRF的光照真实感和高斯泼溅的编辑能力，通过高斯编码和高效的最近高斯搜索实现实时、局部感知的3D场景编辑。

**AI_Comments:** GENIE的创新之处在于其混合方法，成功结合了NeRF的渲染质量和高斯泼溅的编辑优势。通过引入高斯编码和RT-GPS，它解决了NeRF在交互性方面的局限性，同时保持了视觉质量。这种方法对于需要实时反馈和物理交互的3D应用具有重要意义，是神经渲染领域的一个重要进步。

<details>
  <summary>Details</summary>

**Motivation:** NeRF在高保真新视角合成方面表现出色，但其隐式编码使得编辑和物理交互困难。高斯泼溅(GS)虽然支持实时渲染和直观操作，但本文旨在结合两者的优势，实现既有NeRF渲染质量又具备GS可编辑性的模型。

**Method:** 本文引入了GENIE模型，它将高斯泼溅的显式结构与NeRF的渲染质量相结合。GENIE为每个高斯分配一个可训练的特征嵌入，并使用这些嵌入来条件化一个NeRF网络。为了高效地实现这一条件化，引入了Ray-Traced Gaussian Proximity Search (RT-GPS)进行快速最近高斯搜索。同时，集成了多分辨率哈希网格来初始化和更新高斯特征。

**Result:** GENIE实现了实时、局部感知的编辑功能，当高斯基元被重新定位或修改时，其插值影响会立即反映在渲染输出中。这使得直观的场景操作、动态交互以及与物理模拟的兼容性成为可能。

**Conclusion:** GENIE通过结合隐式和显式表示的优点，弥合了几何编辑和神经渲染之间的鸿沟，支持直观的场景操作、动态交互和物理模拟兼容性。

> **ai_Abstract:** 本文提出了GENIE，一个结合NeRF和高斯泼溅优点的混合模型，旨在实现高保真渲染质量下的可编辑3D场景表示。GENIE通过为每个高斯分配可训练的特征嵌入来条件化NeRF网络，并引入了RT-GPS进行高效的最近高斯搜索。此外，利用多分辨率哈希网格初始化和更新高斯特征。该方法实现了实时、局部感知的编辑，使用户能够直观地操作场景并支持物理模拟，从而弥合了几何编辑与神经渲染之间的差距。

> **摘要翻译:** 神经辐射场（NeRF）和高斯泼溅（GS）最近彻底改变了3D场景表示和渲染。NeRF通过神经网络学习体积表示，实现了高保真新视角合成，但其隐式编码使得编辑和物理交互充满挑战。相比之下，GS将场景表示为高斯基元的显式集合，实现了实时渲染、更快的训练和更直观的操作。这种显式结构使得GS特别适合交互式编辑和与基于物理的模拟集成。在本文中，我们引入了GENIE（用于神经辐射场交互式编辑的高斯编码），这是一种混合模型，结合了NeRF的逼真渲染质量和GS的可编辑、结构化表示。我们不使用球谐函数进行外观建模，而是为每个高斯分配一个可训练的特征嵌入。这些嵌入用于根据每个查询点最近的k个高斯来条件化NeRF网络。为了使这种条件化高效，我们引入了Ray-Traced Gaussian Proximity Search (RT-GPS)，这是一种基于修改后的光线追踪管道的快速最近高斯搜索。我们还集成了一个多分辨率哈希网格来初始化和更新高斯特征。这些组件共同实现了实时、局部感知的编辑：当高斯基元被重新定位或修改时，它们的插值影响会立即反映在渲染输出中。通过结合隐式和显式表示的优点，GENIE支持直观的场景操作、动态交互以及与物理模拟的兼容性，弥合了几何编辑和神经渲染之间的鸿沟。代码可以在（https://github.com/MikolajZielinski/genie）找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [17] [Advancing Precision in Multi-Point Cloud Fusion Environments](https://arxiv.org/abs/2508.03179)
> *多点云融合环境中精度提升*

*Ulugbek Alibekov, Vanessa Staderini, Philipp Schneider, Doris Antensteiner* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-05**

**Keywords:** 多点云融合, 工业检测, 点云配准, CloudCompare插件, 表面缺陷

**Comment:** Accpeted for publication in Communications in Computer and
  Information Science, Springer

> **TL;DR:** 本研究通过引入合成数据集、距离度量和CloudCompare插件，旨在提高多点云融合在视觉工业检测中的精度和效率。

**AI_Comments:** 该论文的创新之处在于结合了新的合成数据集、距离度量以及一个实用的CloudCompare插件，直接解决了工业检测中精度和效率的问题，具有较高的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过评估点云和多点云匹配方法，提高视觉工业检测的精度。

**Method:** 本研究引入了一个用于配准方法定量评估的合成数据集和用于点云比较的各种距离度量。此外，还提出了一个新颖的CloudCompare插件，用于合并多个点云和可视化表面缺陷。

**Result:** 通过引入的合成数据集、距离度量和CloudCompare插件，提高了自动化检测系统的准确性和效率。

**Conclusion:** 本研究提出的方法和工具显著提升了自动化检测系统的准确性和效率。

> **ai_Abstract:** 本研究致力于提升多点云融合环境下的视觉工业检测精度。通过评估点云和多点云匹配方法，并引入了一个用于配准方法定量评估的合成数据集、多种点云比较距离度量，以及一个用于合并多点云和可视化表面缺陷的CloudCompare插件，该研究旨在提高自动化检测系统的准确性和效率。

> **摘要翻译:** 本研究侧重于通过评估点云和多点云匹配方法来进行视觉工业检测。我们还引入了一个合成数据集，用于定量评估配准方法和各种点云比较距离度量。此外，我们提出了一个新颖的CloudCompare插件，用于合并多个点云和可视化表面缺陷，从而提高自动化检测系统的准确性和效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [20] [Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation](https://arxiv.org/abs/2508.03055)
> *不确定性引导的人脸抠图用于遮挡感知的人脸变换*

*Hyebin Cho, Jaehyup Lee* | **Category: cs.CV, cs.AI, I.4.8** | **Updated: 2025-08-05**

**Keywords:** 人脸抠图, 遮挡感知, 不确定性引导, 知识蒸馏, CelebAMat

**Comment:** Accepted to ACM MM 2025. 9 pages, 8 figures, 6 tables

> **TL;DR:** 本文提出了FaceMat，一个无需Trimap、不确定性感知的人脸抠图框架，用于在复杂遮挡下生成高质量的alpha蒙版，并引入了CelebAMat数据集，显著提升了人脸滤镜在真实视频场景中的表现。

**AI_Comments:** FaceMat的创新点在于引入了不确定性引导的人脸抠图，并提出了一个无需Trimap的端到端框架，这对于实时应用至关重要。其两阶段训练结合不确定性感知知识蒸馏，有效地解决了复杂遮挡下人脸抠图的挑战。此外，专门构建的CelebAMat数据集为该领域的研究提供了宝贵的资源。该工作对于提升人脸滤镜在真实复杂场景中的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸滤镜在存在遮挡（如手、头发、配饰）的情况下性能会下降，这限制了其在短视频内容中的应用。为了解决这一局限性，本文引入了人脸抠图任务，旨在将遮挡元素与面部区域分离。

**Method:** 本文提出了FaceMat框架，一个无需Trimap、不确定性感知的人脸抠图方法。它采用两阶段训练流程：首先，一个教师模型通过负对数似然（NLL）损失共同估计alpha蒙版和每像素不确定性；然后，这种不确定性通过空间自适应知识蒸馏来指导学生模型，使学生模型专注于模糊或被遮挡的区域。此外，该方法将皮肤明确视为前景，遮挡视为背景，并构建了大规模合成数据集CelebAMat。

**Result:** FaceMat在多个基准测试中优于现有最先进的方法，显著提高了人脸滤镜在真实、无约束视频场景中的视觉质量和鲁棒性。

**Conclusion:** FaceMat通过引入不确定性引导的人脸抠图，并在复杂遮挡下实现高质量的alpha蒙版预测，有效解决了人脸滤镜在遮挡情况下的性能下降问题，为实时人脸转换应用提供了更鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的人脸抠图任务，旨在解决人脸滤镜在存在遮挡时的性能下降问题。研究人员开发了FaceMat，一个无需Trimap、不确定性感知的人脸抠图框架，它通过两阶段训练（教师模型估计不确定性，学生模型通过知识蒸馏学习）来生成高质量的alpha蒙版，尤其擅长处理复杂遮挡。FaceMat将皮肤视为前景、遮挡视为背景，且无需辅助输入，适用于实时应用。为支持此任务，研究团队还构建了大规模合成数据集CelebAMat。实验证明FaceMat在多个基准测试中优于现有SOTA方法，显著提升了人脸滤镜的视觉质量和鲁棒性。

> **摘要翻译:** 人脸滤镜已成为短视频内容的关键要素，可实现风格化和人脸替换等多种视觉效果。然而，在存在遮挡（如手、头发或配饰遮挡面部）的情况下，其性能通常会下降。为了解决这一局限性，我们引入了人脸抠图的新任务，该任务估计细粒度的alpha蒙版，以将遮挡元素与面部区域分离。我们进一步提出了FaceMat，一个无需Trimap、不确定性感知的框架，可在复杂遮挡下预测高质量的alpha蒙版。我们的方法利用两阶段训练流程：首先训练一个教师模型，使用负对数似然（NLL）损失共同估计alpha蒙版和每像素不确定性，然后利用这种不确定性通过空间自适应知识蒸馏来指导学生模型。这种公式使学生模型能够专注于模糊或被遮挡的区域，从而提高泛化能力并保持语义一致性。与依赖Trimap或分割蒙版的前期方法不同，我们的框架不需要辅助输入，使其非常适合实时应用。此外，我们通过明确将皮肤视为前景并将遮挡视为背景来重新制定抠图目标，从而实现更清晰的合成策略。为了支持这项任务，我们新构建了CelebAMat，一个专门为遮挡感知人脸抠图设计的大规模合成数据集。大量实验表明，FaceMat在多个基准测试中优于现有最先进的方法，增强了真实世界、无约束视频场景中人脸滤镜的视觉质量和鲁棒性。源代码和CelebAMat数据集可在https://github.com/hyebin-c/FaceMat.git获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [22] [LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences](https://arxiv.org/abs/2508.03692)
> *LiDARCrafter：基于激光雷达序列的动态4D世界建模*

*Ao Liang, Youquan Liu, Yu Yang, Dongyue Lu, Linfeng Li, Lingdong Kong, Huaici Zhao, Wei Tsang Ooi* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 激光雷达生成, 4D世界建模, 扩散模型, 自动驾驶, 数据增强

**Comment:** Preprint; 28 pages, 18 figures, 12 tables; Project Page at
  https://lidarcrafter.github.io

> **TL;DR:** LiDARCrafter是一个统一的框架，用于从激光雷达序列生成和编辑动态4D世界，通过自然语言输入和扩散网络实现高保真、可控和时间一致的生成，并为自动驾驶数据增强和仿真提供支持。

**AI_Comments:** LiDARCrafter的创新之处在于其将自然语言处理与扩散模型相结合，实现了对4D激光雷达序列的精细化控制和生成。它解决了现有世界模型在处理激光雷达数据时的局限性，特别是在可控性和时间连贯性方面。该研究不仅提出了一个强大的生成框架，还建立了标准化的评估基准，这对于推动自动驾驶领域的数据生成和仿真技术发展具有重要意义。代码和基准的发布也体现了其对社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成式世界模型主要关注视频或占用网格，忽视了激光雷达的独特属性。将激光雷达生成扩展到动态4D世界建模在可控性、时间连贯性和评估标准化方面面临挑战。

**Method:** LiDARCrafter是一个统一的4D激光雷达生成和编辑框架。它将自由形式的自然语言输入解析为以自我为中心的场景图，这些场景图调节一个三分支扩散网络来生成对象结构、运动轨迹和几何形状。此外，一个自回归模块生成时间上连贯的4D激光雷达序列。为了支持标准化评估，该研究还建立了一个包含场景、对象和序列级别指标的综合基准。

**Result:** 在nuScenes数据集上使用所建立的基准进行实验表明，LiDARCrafter在保真度、可控性和时间一致性方面均达到了最先进的性能。

**Conclusion:** LiDARCrafter在4D激光雷达生成和编辑方面取得了最先进的性能，为自动驾驶领域的数据增强和仿真铺平了道路。

> **ai_Abstract:** LiDARCrafter是一个新颖的统一框架，专注于从激光雷达序列进行动态4D世界建模。它通过将自然语言输入转换为场景图来条件化一个三分支扩散网络，以生成对象结构、运动轨迹和几何形状，从而实现可控和细粒度的场景编辑。此外，一个自回归模块确保了生成序列的时间连贯性。该工作还建立了一个全面的评估基准。实验结果表明，LiDARCrafter在保真度、可控性和时间一致性方面均达到了最先进的性能，为自动驾驶的数据增强和仿真提供了强大支持。

> **摘要翻译:** 生成式世界模型已成为自动驾驶不可或缺的数据引擎，然而现有的大多数工作都集中在视频或占用网格上，忽略了激光雷达的独特属性。将激光雷达生成扩展到动态4D世界建模在可控性、时间连贯性和评估标准化方面带来了挑战。为此，我们提出了LiDARCrafter，一个用于4D激光雷达生成和编辑的统一框架。给定自由形式的自然语言输入，我们将其指令解析为以自我为中心的场景图，这些场景图调节一个三分支扩散网络来生成对象结构、运动轨迹和几何形状。这些结构化条件支持多样化和细粒度的场景编辑。此外，一个自回归模块生成具有平滑过渡的时间连贯的4D激光雷达序列。为了支持标准化评估，我们建立了一个包含场景、对象和序列级别指标的综合基准。在nuScenes数据集上使用该基准进行的实验表明，LiDARCrafter在所有级别的保真度、可控性和时间一致性方面均达到了最先进的性能，为数据增强和仿真铺平了道路。代码和基准已向社区发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [29] [Sparsity and Total Variation Constrained Multilayer Linear Unmixing for Hyperspectral Imagery](https://arxiv.org/abs/2508.03403)
> *稀疏性和全变分约束的多层线性高光谱图像解混*

*Gang Yang* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-05**

**Keywords:** 高光谱解混, 稀疏性, 全变分, 多层线性解混, ADMM

**Comment:** 

> **TL;DR:** 提出了一种结合稀疏性和全变分约束的新型多层线性解混方法STVMLU，用于提高高光谱图像解混精度。

**AI_Comments:** 该论文的创新点在于将多层矩阵分解模型与全变分约束和L1/2范数稀疏约束相结合，以解决高光谱图像解混中的精度问题。全变分约束利用了空间信息，而稀疏约束则捕捉了丰度矩阵的特性。采用ADMM优化方法也是一个有效的策略。这项工作对于提高高光谱图像分析的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱解混是高光谱图像应用中的关键预处理步骤，旨在估计材料特征和丰度。本研究的动机是开发一种新方法来提高解混的准确性。

**Method:** 提出了一种名为STVMLU（稀疏性和全变分约束的多层线性解混）的新方法。该方法基于多层矩阵分解模型，并通过引入全变分（TV）约束来考虑相邻空间相似性以提高解混精度。此外，采用L1/2范数稀疏约束来有效表征丰度矩阵的稀疏性。模型优化采用交替方向乘子法（ADMM），实现端元和丰度矩阵的同时提取。

**Result:** 实验结果表明，所提出的STVMLU方法相比其他算法具有增强的性能。

**Conclusion:** 所提出的STVMLU方法能够有效提高高光谱图像解混的精度和性能。

> **ai_Abstract:** 本文提出了一种新颖的高光谱图像解混方法STVMLU，该方法结合了稀疏性和全变分约束。STVMLU基于多层矩阵分解模型，通过引入全变分约束利用空间相似性，并采用L1/2范数稀疏约束表征丰度矩阵的稀疏性，以提高解混精度。模型通过交替方向乘子法进行优化。实验结果验证了STVMLU优于其他算法的性能。

> **摘要翻译:** 高光谱解混旨在估计材料特征（称为端元）和相应的比例（称为丰度），这是各种高光谱图像应用中的关键预处理步骤。本研究开发了一种名为稀疏性和全变分（TV）约束的多层线性解混（STVMLU）的新方法，用于高光谱图像。具体来说，基于多层矩阵分解模型，为了提高解混的准确性，引入了TV约束以考虑相邻空间相似性。此外，采用了L1/2范数稀疏约束来有效表征丰度矩阵的稀疏性。为了优化STVMLU模型，采用了交替方向乘子法（ADMM），该方法允许同时提取端元及其相应的丰度矩阵。实验结果表明，所提出的STVMLU在与其他算法比较时表现出增强的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [39] [MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention](https://arxiv.org/abs/2507.22805)
> *MoCHA：采用MoE连接器和分层组注意力的高级视觉-语言推理*

*Yuqi Pang, Bowen Yang, Yun Cao, Rong Fan, Xiaoyu Li, Chen He* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视觉-语言推理, 专家混合连接器, 分层组注意力, 视觉大语言模型, 稀疏专家

**Comment:** 

> **TL;DR:** MoCHA是一个新的视觉框架，通过集成多视觉骨干、稀疏专家混合连接器（MoECs）和分层组注意力（HGA），解决了现有视觉大语言模型（VLLMs）在处理复杂视觉信息时的高成本和细节提取挑战，并在多项基准测试中超越了现有先进模型。

**AI_Comments:** MoCHA的创新之处在于其对VLLM中视觉特征处理的优化，特别是引入了稀疏专家混合连接器（MoECs）实现动态、高效的特征选择，以及分层组注意力（HGA）来精细化视觉信息的利用。这种组合有效地解决了传统VLLM在高成本和细节提取上的痛点。其在缓解幻觉和提升指令遵循方面的显著改进，表明了该方法在实际应用中的巨大潜力。该研究为未来VLLM的设计提供了新的思路，强调了高效和细粒度视觉特征处理的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉大语言模型（VLLMs）在处理复杂和细粒度视觉信息时，面临高昂的训练和推理成本，以及在提取视觉细节和有效桥接跨模态方面的挑战。

**Method:** 本文提出了一个新的视觉框架MoCHA，它集成了四种视觉骨干（CLIP、SigLIP、DINOv2和ConvNeXt）以提取互补的视觉特征。该框架配备了稀疏专家混合连接器（MoECs）模块，用于动态选择适合不同视觉维度的专家。为了减少MoECs模块编码的视觉信息的冗余或不足使用，MoCHA进一步设计了分层组注意力（HGA），包含组内和组间操作以及自适应门控策略。MoCHA在Phi2-2.7B和Vicuna-7B两个主流LLM上进行了训练。

**Result:** MoCHA在各种任务中超越了最先进的开源模型。例如，与CuMo (Mistral-7B)相比，MoCHA (Phi2-2.7B)在POPE上提高了3.25%以减轻幻觉，并在MME上提高了153分以更好地遵循视觉指令。消融研究进一步证实了所提出的MoECs和HGA在提高MoCHA整体性能方面的有效性和鲁棒性。

**Conclusion:** MoECs和HGA模块的引入，显著提升了MoCHA的整体性能，使其在视觉-语言推理任务中表现出卓越的能力，尤其是在缓解幻觉和遵循视觉指令方面。

> **ai_Abstract:** MoCHA是一个针对视觉大语言模型（VLLMs）提出的新型视觉框架，旨在解决现有方法在处理复杂视觉信息时面临的高成本和细节提取挑战。该框架通过集成CLIP、SigLIP、DINOv2和ConvNeXt四种视觉骨干以获取互补特征，并引入稀疏专家混合连接器（MoECs）进行动态专家选择。为优化视觉信息利用，MoCHA还设计了分层组注意力（HGA），包含组内、组间操作和自适应门控策略。在Phi2-2.7B和Vicuna-7B模型上的训练和评估表明，MoCHA在多项任务上超越了现有先进模型，显著缓解了幻觉并提升了视觉指令遵循能力，其核心模块MoECs和HGA的有效性也得到了消融研究的证实。

> **摘要翻译:** 视觉大语言模型（VLLMs）主要通过整合先进的视觉编码器和扩展视觉模型来处理复杂和细粒度的视觉信息。然而，这些方法面临高昂的训练和推理成本，以及在提取视觉细节、有效桥接跨模态方面的挑战。在这项工作中，我们提出了一个新颖的视觉框架MoCHA来解决这些问题。我们的框架集成了四种视觉骨干（即CLIP、SigLIP、DINOv2和ConvNeXt）来提取互补的视觉特征，并配备了稀疏专家混合连接器（MoECs）模块，以动态选择适合不同视觉维度的专家。为了缓解MoECs模块编码的视觉信息冗余或不足使用的问题，我们进一步设计了分层组注意力（HGA），包含组内和组间操作以及自适应门控策略，用于编码的视觉特征。我们在两个主流LLM（如Phi2-2.7B和Vicuna-7B）上训练了MoCHA，并评估了它们在各种基准测试中的性能。值得注意的是，MoCHA在各种任务中超越了最先进的开源模型。例如，与CuMo（Mistral-7B）相比，我们的MoCHA（Phi2-2.7B）通过在POPE上提高3.25%来减轻幻觉，并通过在MME上提高153分来遵循视觉指令，展现出卓越的能力。最后，消融研究进一步证实了所提出的MoECs和HGA在提高MoCHA整体性能方面的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [43] [CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation](https://arxiv.org/abs/2508.03060)
> *CHARM：任意模态协同协调用于模态无关语义分割*

*Lekang Wen, Jing Xiao, Liang Liao, Jiajun Chen, Mi Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 模态无关语义分割, 协同协调, 互补学习, 跨模态交互, 双路径优化

**Comment:** 

> **TL;DR:** 提出CHARM框架，通过隐式对齐和双路径优化，在模态无关语义分割中实现模态协同协调而非同质化，提高性能。

**AI_Comments:** CHARM的创新点在于提出了“协同协调而非同质化”的理念，通过隐式对齐和双路径优化策略，有效利用了模态间的互补性，同时保留了各模态的独特性。这对于提升模态无关语义分割在复杂、多模态场景下的鲁棒性具有重要意义，特别是对“脆弱模态”的性能提升显示了其强大的泛化能力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有模态无关语义分割方法依赖显式特征对齐导致模态同质化，削弱了各模态的独特性和互补性。

**Method:** 提出CHARM框架，包含两个组件：1) 互感知单元（MPU），通过基于窗口的跨模态交互实现隐式对齐；2) 双路径优化策略，将训练解耦为协作学习策略（CoL）和个体增强策略（InE）。

**Result:** CHARM在多个数据集和骨干网络上持续优于基线，尤其在“脆弱模态”上表现显著提升。

**Conclusion:** 该工作将重点从模型同质化转向协调，实现了跨模态互补性，以实现多样性中的真正和谐。

> **ai_Abstract:** 本文针对模态无关语义分割（MaSS）中现有方法因显式特征对齐导致模态同质化、损害各模态独特性和互补性的问题，提出了CHARM框架。CHARM通过互感知单元（MPU）进行隐式跨模态交互对齐，并采用双路径优化策略（协作学习与个体增强）来保留模态特有优势。实验结果表明，CHARM在多个数据集和骨干网络上均优于现有基线，尤其提升了对脆弱模态的性能，实现了从模态同质化到协同协调的范式转变。

> **摘要翻译:** 模态无关语义分割（MaSS）旨在实现跨任意输入模态组合的鲁棒场景理解。现有方法通常依赖显式特征对齐来实现模态同质化，这稀释了每种模态的独特优势并破坏了它们固有的互补性。为了实现合作协调而非同质化，我们提出了CHARM，一个新颖的互补学习框架，旨在通过两个组件隐式对齐内容，同时保留模态特有优势：(1) 互感知单元（MPU），通过基于窗口的跨模态交互实现隐式对齐，其中模态作为彼此的查询和上下文来发现模态交互对应关系；(2) 双路径优化策略，将训练解耦为用于互补融合学习的协作学习策略（CoL）和用于受保护的模态特定优化的个体增强策略（InE）。跨多个数据集和骨干网络的实验表明，CHARM持续优于基线，在脆弱模态上取得了显著的增益。这项工作将重点从模型同质化转向协调，实现了跨模态互补性，以实现多样性中的真正和谐。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [46] [A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness](https://arxiv.org/abs/2503.02797)
> *图像质量指标与深度神经网络鲁棒性对齐的因果框架*

*Nathan Drenkow, Mathias Unberath* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 图像质量评估, 深度神经网络, 鲁棒性, 因果框架, DNN性能

**Comment:** 

> **TL;DR:** 传统图像质量指标无法有效预测深度神经网络性能，本文提出一个因果框架来开发与DNN性能高度相关的指标。

**AI_Comments:** 该论文通过引入一个因果框架，创新性地解决了图像质量评估与深度神经网络鲁棒性之间的对齐问题，超越了以人类感知为中心的传统质量评估方法。这对于开发在实际成像条件下更鲁棒的AI系统具有重要意义，其创新点在于使用因果方法来使指标与DNN的敏感性保持一致。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）对成像条件的变化非常敏感，而传统的图像质量评估（IQA）指标主要针对人类感知，与DNN的敏感性不匹配。因此，需要一种既对成像条件敏感又与DNN性能良好对齐的指标。

**Method:** 首先，从理论和经验上研究了传统IQA指标是否能有效预测DNN性能。然后，利用一个因果框架开发了与DNN性能强相关的新指标。

**Result:** 理论和经验表明，传统IQA指标对图像分类的DNN性能预测能力较弱。通过提出的因果框架开发的新指标与DNN性能表现出强相关性。

**Conclusion:** 本文提出的因果框架能够开发出与深度神经网络性能高度相关的图像质量指标，从而有效估计大型图像数据集相对于目标视觉任务的质量分布。

> **ai_Abstract:** 本文探讨了传统图像质量评估（IQA）指标与深度神经网络（DNN）性能之间存在的脱节问题，指出传统IQA指标对DNN性能的预测能力较弱。为解决此问题，论文提出了一个因果框架，用于开发与DNN性能高度相关的新型图像质量指标，从而能够更有效地评估大型图像数据集在特定视觉任务下的质量分布。

> **摘要翻译:** 图像质量在深度神经网络（DNN）的性能中扮演着重要角色，而DNN已被广泛证明对成像条件的变化表现出敏感性。传统的图像质量评估（IQA）旨在衡量和调整相对于人类感知判断的质量，但我们通常需要一种不仅对成像条件敏感，而且与DNN敏感性良好对齐的指标。我们首先探讨传统IQA指标是否也能提供关于DNN性能的信息。我们从理论和经验上表明，传统IQA指标对于图像分类的DNN性能预测能力较弱。然后，我们使用我们的因果框架开发了与DNN性能表现出强相关性的指标，从而使我们能够有效估计大型图像数据集相对于目标视觉任务的质量分布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [47] [RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm](https://arxiv.org/abs/2502.12513)
> *RealSyn：一种有效且可扩展的多模态交错文档转换范式*

*Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态学习, 对比学习, 视觉-语言预训练, 数据集构建, RealSyn

**Comment:** 15 pages, 12 figures, Accepted by ACM MM2025, Webpage:
  https://garygutc.github.io/RealSyn

> **TL;DR:** 本文提出了RealSyn，一个结合真实和合成文本的多模态数据集，旨在充分利用未被利用的交错文档进行对比视觉-语言表示学习。通过数据提取、分层检索、图像语义增强生成和语义平衡采样策略，RealSyn数据集在各种下游任务上使预训练模型达到最先进的性能，并展现出强大的可扩展性。

**AI_Comments:** 本文创新性地提出了一种利用未充分利用的多模态交错文档进行对比视觉-语言表示学习的范式。其亮点在于结合了真实数据提取、分层检索、合成文本生成和语义平衡采样等多种策略，有效构建了大规模高质量数据集RealSyn。通过引入合成文本，增强了细粒度视觉信息，同时语义平衡采样解决了长尾概念学习问题。该工作为视觉-语言预训练提供了新的数据范式，并显著提升了模型性能和可扩展性，对未来的多模态研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管CLIP在图像-文本对预训练方面表现出色，但大量多模态交错文档在对比视觉-语言表示学习中仍未得到充分利用。现有方法未能有效利用这些非配对文档，导致潜在的信息损失。

**Method:** 1. 建立Real-World Data Extraction管道提取高质量图像和文本。
2. 设计分层检索方法将图像与多个语义相关的真实文本关联起来。
3. 提出图像语义增强生成模块用于合成文本生产，以增强细粒度视觉信息。
4. 采用语义平衡采样策略提高数据集多样性，以更好地学习长尾概念。
5. 构建了RealSyn数据集，结合真实和合成文本，并提供15M、30M和100M三种规模。

**Result:** 1. RealSyn数据集构建完成，包含真实和合成文本，规模分别为15M、30M和100M。
2. 在RealSyn上预训练的模型在各种下游任务（包括线性探测、零样本迁移、零样本鲁棒性和零样本检索）中始终实现最先进的性能。
3. 实验证实RealSyn显著增强了对比视觉-语言表示学习。
4. RealSyn展现出强大的可扩展性。

**Conclusion:** RealSyn通过有效利用未充分利用的多模态交错文档，显著提升了对比视觉-语言表示学习的性能，并在多个下游任务中达到了最先进水平，证明了其有效性和强大的可扩展性。

> **ai_Abstract:** 本文提出RealSyn，一个用于对比视觉-语言表示学习的有效且可扩展的多模态交错文档转换范式。针对现有方法未能充分利用大量未配对多模态交错文档的问题，RealSyn通过建立数据提取管道、设计分层检索方法、提出图像语义增强生成模块以及采用语义平衡采样策略来构建高质量的真实与合成文本结合的数据集。实验结果表明，在RealSyn上预训练的模型在多项下游任务中均达到最先进性能，显著提升了对比视觉-语言表示学习能力并展现出卓越的可扩展性。

> **摘要翻译:** 在对大量图像-文本对进行预训练后，对比语言-图像预训练（CLIP）在各种基准测试中展现出令人期待的性能。然而，大量多模态交错文档在对比视觉-语言表示学习中仍未得到充分利用。为了充分利用这些非配对文档，我们首先建立了一个真实世界数据提取管道来提取高质量的图像和文本。然后，我们设计了一种分层检索方法，以有效地将每张图像与多个语义相关的真实文本关联起来。为了进一步增强细粒度视觉信息，我们提出了一个图像语义增强生成模块，用于生成合成文本。此外，我们采用了一种语义平衡采样策略来提高数据集多样性，从而更好地学习长尾概念。基于这些创新，我们构建了RealSyn，一个结合了真实和合成文本的数据集，提供15M、30M和100M三种规模。我们将我们的数据集与用于CLIP训练的其他广泛使用的同等规模数据集进行了比较。在RealSyn上预训练的模型在各种下游任务中始终实现最先进的性能，包括线性探测、零样本迁移、零样本鲁棒性和零样本检索。此外，大量实验证实RealSyn显著增强了对比视觉-语言表示学习，并展现出强大的可扩展性。为了促进未来的研究，RealSyn数据集和预训练模型权重已在https://github.com/deepglint/RealSyn发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [51] [Learning Latent Representations for Image Translation using Frequency Distributed CycleGAN](https://arxiv.org/abs/2508.03415)
> *使用频率分布CycleGAN学习图像翻译的潜在表示*

*Shivangi Nigam, Adarsh Prasad Behera, Shekhar Verma, P. Nagabhushan* | **Category: cs.CV, cs.AI, cs.GR** | **Updated: 2025-08-05**

**Keywords:** 图像翻译, CycleGAN, 频率分布, 潜在表示, 生成对抗网络

**Comment:** This paper is currently under review for publication in an IEEE
  Transactions. If accepted, the copyright will be transferred to IEEE

> **TL;DR:** Fd-CycleGAN通过结合局部邻域编码和频率感知监督，以及分布损失度量，改进了CycleGAN的图像翻译性能，实现了更好的感知质量、更快的收敛和模式多样性，尤其是在数据量不足的情况下。

**AI_Comments:** Fd-CycleGAN的创新点在于将频率感知监督和局部邻域编码融入CycleGAN框架，以更精细地捕捉图像的局部和全局特征，从而提升翻译质量。其在低数据量下的优越表现以及与扩散模型在效率上的对比优势，突显了其在实际应用中的潜力和实用性。该方法为图像翻译任务中潜在表示学习提供了一个有效的新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像到图像翻译方法在学习潜在表示以近似真实数据分布方面存在不足，尤其是在捕获细粒度局部像素语义和保持结构连贯性方面。

**Method:** 本文提出了Fd-CycleGAN，一个基于CycleGAN的图像到图像翻译框架。它集成了局部邻域编码（LNE）和频率感知监督，以捕获细粒度局部像素语义并保持源域的结构连贯性。该方法采用基于分布的损失度量，包括KL/JS散度和基于对数的相似性度量，以量化真实图像和生成图像在空间域和频率域的分布对齐情况。

**Result:** Fd-CycleGAN在Horse2Zebra、Monet2Photo和合成增强的Strike-off数据集上进行了实验验证。与基线CycleGAN及其他SOTA方法相比，Fd-CycleGAN展示出卓越的感知质量、更快的收敛速度和改进的模式多样性，尤其是在低数据量情况下。通过有效捕获局部和全局分布特征，Fd-CycleGAN实现了视觉上更连贯、语义上更一致的翻译。

**Conclusion:** 频率引导的潜在学习显著提高了图像翻译任务的泛化能力，在文档修复、艺术风格迁移和医学图像合成等领域具有应用前景。与基于扩散的生成模型相比，Fd-CycleGAN作为轻量级对抗方法在训练效率和定性输出方面具有优势。

> **ai_Abstract:** Fd-CycleGAN是一个改进的图像到图像翻译框架，它在CycleGAN的基础上引入了局部邻域编码和频率感知监督，以更好地学习图像的潜在表示。该方法利用分布损失度量来精确对齐生成图像与真实图像的分布。实验证明，Fd-CycleGAN在感知质量、收敛速度和模式多样性方面优于现有方法，尤其在数据稀缺时表现更佳，并展现了在多个图像翻译应用中的潜力，同时在效率上优于扩散模型。

> **摘要翻译:** 本文提出了Fd-CycleGAN，一个图像到图像（I2I）翻译框架，旨在增强潜在表示学习以近似真实数据分布。在CycleGAN的基础上，我们的方法集成了局部邻域编码（LNE）和频率感知监督，以捕获细粒度局部像素语义，同时保留源域的结构连贯性。我们采用基于分布的损失度量，包括KL/JS散度和基于对数的相似性度量，以明确量化真实和生成图像分布在空间域和频率域的对齐情况。为了验证Fd-CycleGAN的有效性，我们在各种数据集——Horse2Zebra、Monet2Photo和合成增强的Strike-off数据集——上进行了实验。与基线CycleGAN和其他最先进的方法相比，我们的方法展示出卓越的感知质量、更快的收敛速度和改进的模式多样性，尤其是在数据量不足的情况下。通过有效捕获局部和全局分布特征，Fd-CycleGAN实现了视觉上更连贯和语义上更一致的翻译。我们的结果表明，频率引导的潜在学习显著提高了图像翻译任务的泛化能力，在文档修复、艺术风格迁移和医学图像合成方面具有广阔的应用前景。我们还提供了与基于扩散的生成模型的比较见解，强调了我们轻量级对抗方法在训练效率和定性输出方面的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [52] [Zero-shot Shape Classification of Nanoparticles in SEM Images using Vision Foundation Models](https://arxiv.org/abs/2508.03235)
> *使用视觉基础模型对扫描电镜图像中的纳米粒子进行零样本形状分类*

*Freida Barnatan, Emunah Goldstein, Einav Kalimian, Orchen Madar, Avi Huri, David Zitoun, Ya'akov Mandelbaum, Moshe Amitay* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 零样本分类, 纳米粒子, 扫描电镜图像, 视觉基础模型, SAM, DINOv2

**Comment:** 

> **TL;DR:** 本研究提出了一种零样本分类流程，利用视觉基础模型（SAM和DINOv2）对扫描电镜图像中的纳米粒子进行高效、高精度的形状分类，无需大量标注数据和微调，且性能优于传统方法。

**AI_Comments:** 该论文的创新点在于将两个强大的视觉基础模型（SAM和DINOv2）整合到一个零样本分类流程中，解决了传统深度学习方法在纳米粒子形态分类中对大量标注数据和计算资源的需求。这种无需大量微调即可实现高精度和鲁棒性的能力，极大地提高了该技术的实用性和可及性，特别是在数据稀缺或领域转移的科学成像场景中。它为自动化显微镜图像分析提供了一个有前景的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 纳米粒子形态表征对确保纳米材料产品质量和加速开发至关重要。然而，传统的深度学习方法需要大量标注数据集和计算密集型训练，限制了其在研究和工业环境中对普通纳米粒子研究人员的可用性。

**Method:** 本研究引入了一种零样本分类流程，该流程利用两个视觉基础模型：用于目标分割的Segment Anything Model (SAM) 和用于特征嵌入的DINOv2。通过将这些模型与一个轻量级分类器结合，实现了高精度的形状分类。

**Result:** 该方法在三个形态多样的纳米粒子数据集上实现了高精度形状分类，且无需大量参数微调。其性能优于微调后的YOLOv11和ChatGPT o4-mini-high基线，并对小数据集、细微形态变化以及从自然图像到科学图像的领域漂移表现出鲁棒性。对DINOv2特征的PCA图上的定量聚类指标也用于评估化学合成的进展。

**Conclusion:** 这项工作突出了基础模型在推动自动化显微镜图像分析方面的潜力，为纳米粒子研究中的传统深度学习流程提供了一种更高效、更易于用户使用的替代方案。

> **ai_Abstract:** 本研究提出了一种新颖的零样本分类流程，用于在扫描电镜图像中对纳米粒子进行形状分类。该方法利用Segment Anything Model (SAM) 进行目标分割，并结合DINOv2进行特征嵌入，再通过一个轻量级分类器实现高精度分类。与传统深度学习方法相比，该流程无需大量标注数据和参数微调，且在多个纳米粒子数据集上表现出卓越性能和鲁棒性，优于现有基线。这项工作展示了视觉基础模型在自动化显微镜图像分析中的巨大潜力，为纳米粒子研究提供了一种更高效、更易于访问的解决方案。

> **摘要翻译:** 扫描电子显微镜（SEM）图像中纳米粒子形态的准确高效表征对于确保纳米材料合成中的产品质量和加速开发至关重要。然而，用于形状分类的传统深度学习方法需要大量的标记数据集和计算密集型训练，这限制了它们在研究和工业环境中对普通纳米粒子从业者的可及性。在这项研究中，我们引入了一种零样本分类流程，该流程利用了两个视觉基础模型：用于目标分割的Segment Anything Model (SAM) 和用于特征嵌入的DINOv2。通过将这些模型与一个轻量级分类器结合，我们在三个形态多样的纳米粒子数据集上实现了高精度形状分类——而无需大量的参数微调。我们的方法优于经过微调的YOLOv11和ChatGPT o4-mini-high基线，证明了其对小数据集、细微形态变化以及从自然图像到科学成像的领域转移的鲁棒性。讨论了DINOv2特征的PCA图上的定量聚类指标，作为评估化学合成进展的一种手段。这项工作突出了基础模型在推动自动化显微镜图像分析方面的潜力，为纳米粒子研究中的传统深度学习流程提供了一种更高效、更易于用户使用的替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [54] [LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation](https://arxiv.org/abs/2508.03694)
> *LongVie: 多模态引导的可控超长视频生成*

*Jianxiong Gao, Zhaoxi Chen, Xian Liu, Jianfeng Feng, Chenyang Si, Yanwei Fu, Yu Qiao, Ziwei Liu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 超长视频生成, 可控视频生成, 多模态控制, 时间一致性, 视觉退化

**Comment:** Project page: https://vchitect.github.io/LongVie-project/

> **TL;DR:** LongVie是一个端到端自回归框架，通过统一噪声初始化、全局控制信号归一化、多模态控制和降级感知训练，解决了现有方法在超长视频生成中遇到的时间不一致和视觉退化问题，并实现了最先进的性能。

**AI_Comments:** LongVie通过其创新的多模态控制和降级感知训练策略，有效解决了超长视频生成中的核心挑战，即时间一致性和视觉退化。引入新的基准LongVGenBench也对该领域的研究具有重要意义，有助于推动未来研究的进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在生成超长视频时存在时间不一致和视觉退化问题，难以扩展。此外，单独的噪声初始化、独立的控制信号归一化以及单模态引导的局限性也是挑战。

**Method:** LongVie是一个端到端自回归框架，引入了四项核心设计：1) 统一的噪声初始化策略；2) 全局控制信号归一化；3) 整合密集和稀疏控制信号的多模态控制框架；4) 降级感知训练策略。同时，本文还引入了LongVGenBench基准数据集。

**Result:** LongVie在长距离可控性、一致性和质量方面达到了最先进的性能。引入了包含100个高分辨率超长视频的LongVGenBench综合基准。

**Conclusion:** LongVie框架有效解决了可控超长视频生成中的时间一致性和视觉退化问题，达到了最先进的性能，并为该领域提供了新的基准。

> **ai_Abstract:** 本文提出了LongVie，一个端到端自回归框架，旨在解决超长视频生成中的时间不一致和视觉退化挑战。LongVie通过统一噪声初始化、全局控制信号归一化、多模态控制框架以及降级感知训练策略来确保生成视频的连贯性和高质量。研究还引入了LongVGenBench，一个包含100个高分辨率长视频的综合基准。实验证明LongVie在长距离可控性、一致性和质量方面均达到了最先进的水平。

> **摘要翻译:** 可控的超长视频生成是一项基础但具有挑战性的任务。尽管现有方法对短视频片段有效，但由于时间不一致和视觉退化等问题，它们难以扩展。在本文中，我们初步研究并确定了三个关键因素：单独的噪声初始化、独立的控制信号归一化以及单模态引导的局限性。为了解决这些问题，我们提出了LongVie，一个用于可控长视频生成的端到端自回归框架。LongVie引入了两个核心设计来确保时间一致性：1）统一的噪声初始化策略，可在视频片段之间保持一致的生成；2）全局控制信号归一化，可在整个视频的控制空间中强制对齐。为了减轻视觉退化，LongVie采用了3）一个多模态控制框架，该框架集成了密集（例如，深度图）和稀疏（例如，关键点）控制信号，并辅以4）一种降级感知训练策略，该策略随着时间的推移自适应地平衡模态贡献以保持视觉质量。我们还引入了LongVGenBench，一个包含100个高分辨率视频的综合基准，涵盖了不同的真实世界和合成环境，每个视频持续一分钟以上。大量实验表明，LongVie在长距离可控性、一致性和质量方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [69] [MedCAL-Bench: A Comprehensive Benchmark on Cold-Start Active Learning with Foundation Models for Medical Image Analysis](https://arxiv.org/abs/2508.03441)
> *MedCAL-Bench：一个关于医学图像分析中基于基础模型的冷启动主动学习的综合基准*

*Ning Zhu, Xiaochuan Ma, Shaoting Zhang, Guotai Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 冷启动主动学习, 基础模型, 医学图像分析, 基准测试, 特征提取

**Comment:** 23 pages, 6 figures, 10 tables

> **TL;DR:** MedCAL-Bench是首个针对医学图像分析中基于基础模型的冷启动主动学习（CSAL）的基准测试，评估了不同基础模型和CSAL策略，发现基础模型在CSAL中有效，但性能和最佳策略因任务而异。

**AI_Comments:** MedCAL-Bench的创新之处在于它是首个系统性地将基础模型引入冷启动主动学习并进行全面基准测试的研究，特别是在医学图像分析领域。它不仅评估了基础模型作为特征提取器的能力，还同时考察了样本选择策略，弥补了现有研究的空白。这项工作的重要性在于为研究人员和开发者提供了宝贵的指导，揭示了基础模型在CSAL中的潜力以及在不同任务中选择最佳模型和策略的复杂性，有助于推动高效医学图像标注和模型开发。

<details>
  <summary>Details</summary>

**Motivation:** 在有限的标注预算下，冷启动主动学习（CSAL）对于提高医学图像分析中的标注效率和模型性能至关重要。现有的大多数CSAL方法依赖于目标数据集上的自监督学习进行特征提取，但这种方法效率低下且特征表示能力有限。最近预训练的基础模型（FMs）展现出强大的特征提取能力，有望改善CSAL，但这一范式研究较少，且缺乏用于比较FMs在CSAL任务中的基准。

**Method:** 我们提出了MedCAL-Bench，这是首个系统性的基于基础模型的医学图像分析CSAL基准。我们评估了14个基础模型和7种CSAL策略，涵盖7个数据集，涉及分类和分割任务，并来自不同的医学模态。这是第一个同时评估特征提取和样本选择阶段的CSAL基准。

**Result:** 实验结果显示：1）大多数基础模型是CSAL有效的特征提取器，其中DINO系列在分割任务中表现最佳；2）这些基础模型在分割任务中的性能差异很大，而在分类任务中差异较小；3）在不同数据集上的CSAL中，应考虑不同的样本选择策略，其中ALPS在分割任务中表现最佳，而RepDiv在分类任务中表现领先。

**Conclusion:** 基础模型是冷启动主动学习中有效的特征提取器，但在医学图像分析中，基础模型的选择和样本选择策略应根据具体任务（分类或分割）和数据集进行调整，以达到最佳性能。

> **ai_Abstract:** 本研究提出了MedCAL-Bench，这是首个针对医学图像分析中基于基础模型的冷启动主动学习（CSAL）的综合基准。鉴于现有CSAL方法在特征提取方面的局限性以及基础模型在特征提取方面的潜力，该基准系统地评估了14个基础模型和7种CSAL策略，涵盖7个医学数据集的分类和分割任务。研究发现，基础模型是CSAL的有效特征提取器，但其性能差异在分割任务中显著，在分类任务中较小。此外，最佳的样本选择策略因任务和数据集而异，例如DINO系列和ALPS在分割中表现优异，而RepDiv在分类中领先。

> **摘要翻译:** 冷启动主动学习（CSAL）旨在无需先验知识的情况下选择信息量大的样本进行标注，这对于在有限的标注预算下提高医学图像分析中的标注效率和模型性能至关重要。大多数现有的CSAL方法依赖于目标数据集上的自监督学习（SSL）进行特征提取，但这种方法效率低下且受限于不充分的特征表示。最近，预训练的基础模型（FMs）展现出强大的特征提取能力，有望更好地应用于CSAL。然而，这种范式很少被研究，并且缺乏用于比较FMs在CSAL任务中的基准。为此，我们提出了MedCAL-Bench，这是首个系统性的基于基础模型的医学图像分析CSAL基准。我们评估了14个基础模型和7种CSAL策略，涵盖7个数据集，在不同的标注预算下，覆盖了来自不同医学模态的分类和分割任务。这也是第一个同时评估特征提取和样本选择阶段的CSAL基准。我们的实验结果表明：1）大多数基础模型是CSAL有效的特征提取器，其中DINO系列在分割任务中表现最佳；2）这些基础模型在分割任务中的性能差异很大，而在分类任务中差异较小；3）在不同数据集上的CSAL中，应考虑不同的样本选择策略，其中通过处理惊奇度进行主动学习（ALPS）在分割任务中表现最佳，而RepDiv在分类任务中表现领先。代码可在https://github.com/HiLab-git/MedCAL-Bench获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [74] [RefineSeg: Dual Coarse-to-Fine Learning for Medical Image Segmentation](https://arxiv.org/abs/2508.02844)
> *RefineSeg：医学图像分割的双粗到细学习*

*Anghong Du, Nay Aung, Theodoros N. Arvanitis, Stefan K. Piechnik, Joao A C Lima, Steffen E. Petersen, Le Zhang* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 医学图像分割, 粗到细学习, 弱监督, 标注, 转换矩阵

**Comment:** 

> **TL;DR:** RefineSeg提出了一种基于粗略标注的双粗到细学习框架，用于医学图像分割，其性能超越了弱监督方法并接近全监督方法。

**AI_Comments:** RefineSeg的创新点在于其利用粗略、有噪声的标注进行高精度医学图像分割，并通过“转换矩阵”有效建模标注的不确定性。这大大降低了对昂贵且专业的像素级标注的依赖，为医学图像分析领域提供了一个实用且高效的解决方案，有望推动弱监督学习在临床应用中的发展。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像的高质量像素级标注成本高昂且需要专业知识，这限制了监督分割任务的应用。本文旨在解决在仅依赖粗略标注的情况下进行有效分割的挑战。

**Method:** 本文提出了一种新颖的粗到细分割框架，该框架完全依赖于粗略级别的标注（包括目标和补充绘图），即使它们存在固有噪声。该框架通过引入转换矩阵来建模粗略标注中不准确和不完整的区域。通过在多组粗略标注上联合训练，它逐步细化网络输出，并通过基于矩阵的建模推断出真实的分割分布，从而实现了对精确标签的鲁棒近似。

**Result:** 所提出的方法在两个公共心脏成像数据集ACDC和MSCMRseg上展示了其灵活性和有效性，并在UK Biobank数据集上进一步评估了其性能。实验结果表明，该方法超越了最先进的弱监督方法，并与全监督方法的效果非常接近。

**Conclusion:** 本文提出的RefineSeg框架通过利用粗略标注和转换矩阵建模，成功解决了医学图像分割中高质量标注获取困难的问题，并在性能上达到了与全监督方法相媲美的水平，证明了其在实际应用中的潜力和有效性。

> **ai_Abstract:** RefineSeg提出了一种用于医学图像分割的双粗到细学习框架，旨在解决高质量像素级标注获取困难的问题。该方法仅依赖于粗略标注，并通过引入转换矩阵来建模标注中的不准确和不完整区域。通过在多组粗略标注上联合训练，RefineSeg逐步优化网络输出以近似真实的分割分布。在多个心脏成像数据集上的实验证明，该方法性能优于现有弱监督方法，并可与全监督方法相媲美。

> **摘要翻译:** 高质量的医学图像像素级标注对于监督分割任务至关重要，但获取此类标注成本高昂且需要医学专业知识。为了解决这一挑战，我们提出了一种新颖的粗到细分割框架，该框架完全依赖于粗略级别的标注，包括目标和补充绘图，尽管它们存在固有噪声。该框架通过引入转换矩阵来建模粗略标注中不准确和不完整的区域。通过在多组粗略标注上联合训练，它逐步细化网络输出并推断出真实的分割分布，通过基于矩阵的建模实现对精确标签的鲁棒近似。为了验证所提出方法的灵活性和有效性，我们在两个公共心脏成像数据集ACDC和MSCMRseg上展示了结果，并进一步评估了其在UK Biobank数据集上的性能。实验结果表明，我们的方法超越了最先进的弱监督方法，并与全监督方法的效果非常接近。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [75] [CORE-ReID: Comprehensive Optimization and Refinement through Ensemble fusion in Domain Adaptation for person re-identification](https://arxiv.org/abs/2508.03064)
> *CORE-ReID：通过集成融合在领域自适应中进行全面优化和细化以实现行人重识别*

*Trinh Quoc Nguyen, Oky Dicky Ardiansyah Prima, Katsuyoshi Hotta* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 行人重识别, 无监督领域自适应, 集成融合, 伪标签, 领域适应

**Comment:** 

> **TL;DR:** CORE-ReID是一个用于行人重识别无监督领域自适应的新框架，它利用CycleGAN生成数据，结合教师-学生网络进行多级聚类以生成伪标签，并引入可学习的集成融合组件来增强学习并避免歧义，在多个UDA基准测试中取得了最先进的性能。

**AI_Comments:** CORE-ReID的创新之处在于其综合性的方法，结合了CycleGAN进行数据生成、教师-学生网络与多级聚类生成伪标签，以及最关键的可学习集成融合组件。该融合组件专注于细粒度局部信息，有效解决了多伪标签带来的歧义问题，这是其优于现有方法的重要原因。此外，引入高效通道注意力块和双向均值特征归一化等额外增强功能，进一步提升了模型的鲁棒性和性能。论文不仅提出了理论框架，还通过实验证明了其在多个UDA基准测试上的最先进性能，并提供了开源代码，极大地促进了该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决行人重识别（ReID）中的无监督领域自适应（UDA）问题。

**Method:** 该框架名为CORE-ReID，在预训练阶段利用CycleGAN生成多样化数据以协调不同相机源的图像特性。在微调阶段，基于教师-学生网络对，它整合多视角特征进行多级聚类以生成多样化的伪标签。此外，引入了一个可学习的集成融合组件，该组件专注于全局特征中的细粒度局部信息，以增强学习全面性并避免与多个伪标签相关的歧义。框架还通过高效通道注意力块和双向均值特征归一化等增强功能，减轻偏差效应并自适应融合全局和局部特征。

**Result:** 在行人重识别的三个常见UDA数据集上进行的实验结果表明，CORE-ReID比现有最先进的方法取得了显著的性能提升。它在平均精度均值（Mean Average Precision）、Top-1、Top-5和Top-10方面实现了高准确性。

**Conclusion:** CORE-ReID框架确保了融合特征的清晰性，避免了歧义，并在无监督领域自适应行人重识别中实现了高准确性，证明了其作为一种先进有效解决方案的地位。

> **ai_Abstract:** 本研究提出了CORE-ReID框架，旨在解决行人重识别的无监督领域自适应问题。该框架通过CycleGAN在预训练阶段进行数据多样化，并在微调阶段利用教师-学生网络和多级聚类生成伪标签。核心创新在于引入了可学习的集成融合组件，用于处理细粒度局部信息并避免伪标签歧义。实验证明，CORE-ReID在多个UDA基准测试上显著超越了现有技术，并通过附加的注意力机制和特征归一化进一步增强了性能，实现了高精度。

> **摘要翻译:** 本研究引入了一个新颖的框架，“通过集成融合在领域自适应中进行全面优化和细化以实现行人重识别（CORE-ReID）”，旨在解决行人重识别（ReID）中的无监督领域自适应（UDA）问题。该框架在预训练阶段利用CycleGAN生成多样化数据，以协调来自不同相机源的图像特性差异。在微调阶段，基于一对教师-学生网络，该框架整合多视角特征进行多级聚类，以导出多样化的伪标签。引入了一个可学习的集成融合组件，该组件专注于全局特征中的细粒度局部信息，以增强学习的全面性并避免与多个伪标签相关的歧义。在行人重识别的三个常见UDA数据集上进行的实验结果表明，该方法比现有最先进的方法取得了显著的性能提升。额外的增强功能，例如高效通道注意力块和双向均值特征归一化，进一步减轻了偏差效应，并使用基于ResNet的模型自适应融合了全局和局部特征，从而进一步增强了该框架。所提出的框架确保了融合特征的清晰性，避免了歧义，并在平均精度均值、Top-1、Top-5和Top-10方面实现了高准确性，使其成为行人重识别UDA领域的一种先进且有效的解决方案。我们的代码和模型可在https://github.com/TrinhQuocNguyen/CORE-ReID 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [86] [Trokens: Semantic-Aware Relational Trajectory Tokens for Few-Shot Action Recognition](https://arxiv.org/abs/2508.03695)
> *Trokens：面向少样本动作识别的语义感知关系轨迹令牌*

*Pulkit Kumar, Shuaiyi Huang, Matthew Walmer, Sai Saketh Rambhatla, Abhinav Shrivastava* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** Trokens, 少样本动作识别, 轨迹令牌, 语义感知, 运动建模

**Comment:** Accepted at ICCV 2025; First two authors contributed equally

> **TL;DR:** Trokens将轨迹点转换为语义感知关系令牌，通过解决信息点选择和运动模式建模的挑战，显著提升了少样本动作识别的性能，并在多个基准测试中达到了最先进水平。

**AI_Comments:** Trokens的创新之处在于其将轨迹点转化为语义感知关系令牌的独特思路，以及针对少样本动作识别中点选择和运动模式建模两大挑战提出的具体解决方案。语义感知采样策略和结合HoD与轨迹间关系的运动建模框架是其核心创新点。该方法的重要性体现在其在多个基准测试中达到最先进的性能，表明其在提升视频理解能力方面的巨大潜力。抽象中未提及具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 视频理解，特别是少样本动作识别，需要有效建模运动和外观信息。当前的点跟踪方法在选择有信息量的跟踪点和有效建模其运动模式方面面临两大基本挑战。

**Method:** 本文提出了Trokens，一种将轨迹点转化为语义感知关系令牌的新方法。它包含：1) 一种语义感知采样策略，根据对象尺度和语义相关性自适应地分布跟踪点；2) 一个运动建模框架，通过定向位移直方图（HoD）捕获轨迹内动力学，并通过轨迹间关系建模复杂的动作模式。该方法将这些轨迹令牌与语义特征相结合，以运动信息增强外观特征。

**Result:** Trokens在六个不同的少样本动作识别基准测试（Something-Something-V2全量和小型分割、Kinetics、UCF101、HMDB51和FineGym）上实现了最先进的性能。

**Conclusion:** Trokens通过引入语义感知采样策略和综合运动建模框架，成功地将轨迹点转化为语义感知关系令牌，有效解决了少样本动作识别中的关键挑战，并在多个主流基准测试中取得了显著的性能提升，证明了其在视频理解领域的有效性和潜力。

> **ai_Abstract:** Trokens是一种新颖的少样本动作识别方法，通过将轨迹点转化为语义感知关系令牌来解决现有挑战。它引入了语义感知采样策略以优化点选择，并开发了结合轨迹内（HoD）和轨迹间关系的运动建模框架。该方法有效地融合了轨迹令牌和语义特征，显著提升了外观特征的运动信息，并在六个主流少样本动作识别基准测试中取得了最先进的性能。

> **摘要翻译:** 视频理解需要有效建模运动和外观信息，特别是对于少样本动作识别。虽然点跟踪的最新进展已被证明可以改善少样本动作识别，但仍存在两个基本挑战：选择有信息量的点进行跟踪和有效建模其运动模式。我们提出了Trokens，一种将轨迹点转化为语义感知关系令牌用于动作识别的新方法。首先，我们引入了一种语义感知采样策略，根据对象尺度和语义相关性自适应地分布跟踪点。其次，我们开发了一个运动建模框架，通过定向位移直方图（HoD）捕获轨迹内动力学，并通过轨迹间关系建模复杂的动作模式。我们的方法有效地将这些轨迹令牌与语义特征结合，以运动信息增强外观特征，在六个不同的少样本动作识别基准测试（Something-Something-V2（全量和小型分割）、Kinetics、UCF101、HMDB51和FineGym）上实现了最先进的性能。项目页面请见https://trokens-iccv25.github.io

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [88] [Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints](https://arxiv.org/abs/2507.23064)
> *实时自动驾驶中的视觉-语言融合：相机、高精地图和路径点的目标中心交叉注意力*

*Santosh Patapati, Trisanth Srinivasan, Murari Ambati* | **Category: cs.CV, cs.AI, cs.LG, cs.RO, I.4.8; I.2.10; I.2.6; C.3.3; I.4.9** | **Updated: 2025-08-05**

**Keywords:** 视觉-语言融合, 自动驾驶, 交叉注意力, 高精地图, 路径点

**Comment:** 5 pages

> **TL;DR:** 该论文提出了XYZ-Drive，一个融合视觉、语言和地图信息，并使用目标中心交叉注意力进行实时自动驾驶的单分支模型，在基准测试中表现出色。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的视觉-语言模型XYZ-Drive，通过目标中心交叉注意力层实现了相机图像、高精地图和路径点之间的高效信息融合，解决了传统自动驾驶堆栈中几何和语义信息分离处理的问题。其采用LLaMA模型进行部分微调，并实现单分支输出，显著提升了效率和性能。消融实验充分验证了各模态和融合策略的重要性，为未来多模态自动驾驶系统的设计提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车需要几何精度和语义理解才能在复杂的环境中导航，但大多数现有系统将这两者分开处理。

**Method:** 论文提出了XYZ-Drive，一个单一的视觉-语言模型。它读取前置摄像头图像、25m x 25m的俯视图地图和下一个路径点，然后输出转向和速度。模型使用一个轻量级的目标中心交叉注意力层，让路径点令牌突出相关的图像和地图块，融合后的令牌进入部分微调的LLaMA-3.2 11B模型。

**Result:** 在MD-NEX室外驾驶基准测试中，XYZ-Drive达到了95%的成功率和0.80的路径长度加权成功率（SPL），比PhysNav-DG高出15%，并将碰撞次数减半，同时通过使用单一分支显著提高了效率。消融实验表明，移除任何模态（视觉、路径点、地图）都会使成功率下降高达11%；用简单拼接替换目标中心注意力会使性能下降3%；保持Transformer冻结会损失5%；将地图分辨率从10厘米粗化到40厘米会增加碰撞率。

**Conclusion:** 早期、令牌级别的意图和地图布局融合能够实现准确、透明、实时的驾驶。

> **ai_Abstract:** 该论文提出了XYZ-Drive，一个创新的单分支视觉-语言模型，旨在解决自动驾驶中几何精度和语义理解分离处理的问题。XYZ-Drive通过一个轻量级的目标中心交叉注意力层，融合了来自摄像头、高精地图和路径点的信息，并利用部分微调的LLaMA-3.2 11B模型输出转向和速度。在MD-NEX室外驾驶基准测试中，XYZ-Drive取得了95%的成功率和0.80的SPL，显著超越了现有方法，并通过消融实验证明了多模态融合和目标中心注意力的有效性，最终实现了准确、透明、实时的自动驾驶。

> **摘要翻译:** 自动驾驶汽车需要几何精度和语义理解才能在复杂的环境中导航，然而大多数现有堆栈将它们分开处理。我们提出了XYZ-Drive，一个单一的视觉-语言模型，它读取一个前置摄像头帧、一个25米×25米的高空地图以及下一个路径点，然后输出转向和速度。一个轻量级的目标中心交叉注意力层允许路径点令牌突出显示相关的图像和地图补丁，在融合后的令牌进入部分微调的LLaMA-3.2 11B模型之前，支持动作和文本解释。
在MD-NEX室外驾驶基准测试中，XYZ-Drive取得了95%的成功率和0.80的路径长度加权成功率（SPL），比PhysNav-DG高出15%，并将碰撞次数减半，同时通过仅使用单一分支显著提高了效率。十六项消融实验解释了这些增益。移除任何模态（视觉、路径点、地图）都会使成功率下降高达11%，证实了它们互补的角色和丰富的连接。用简单拼接替换目标中心注意力会使性能下降3%，表明基于查询的融合更有效地注入了地图知识。保持Transformer冻结会损失5%，表明在将VLM应用于自动驾驶等特定任务时微调的重要性。将地图分辨率从10厘米粗化到40厘米会模糊车道边缘并提高碰撞率。
总的来说，这些结果表明，意图和地图布局的早期、令牌级融合能够实现准确、透明、实时的驾驶。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [93] [AttZoom: Attention Zoom for Better Visual Features](https://arxiv.org/abs/2508.03625)
> *AttZoom：用于更好视觉特征的注意力缩放*

*Daniel DeAlcala, Aythami Morales, Julian Fierrez, Ruben Tolosana* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 注意力机制, 卷积神经网络, 特征提取, 空间注意力, 模型无关

**Comment:** Accepted at ICCVw HiCV

> **TL;DR:** AttZoom是一种模块化、模型无关的空间注意力机制，通过强调输入中的高重要性区域来改进CNN的特征提取，在多个CNN骨干网络上实现了分类准确率的提高。

**AI_Comments:** 这项研究的创新之处在于提出了一种模块化且模型无关的空间注意力机制AttZoom，它作为一个独立的层，避免了传统方法对特定架构的依赖，从而提高了CNN的特征提取能力。其重要性在于提供了一种通用且易于集成的方法来提升现有CNN模型的性能，且开销极小。

<details>
  <summary>Details</summary>

**Motivation:** 传统的注意力方法需要特定于架构的集成，而本文旨在提出一种独立的、模块化的空间注意力机制，以改进卷积神经网络（CNN）中的特征提取。

**Method:** 本文提出了一种名为Attention Zoom的模块化、模型无关的空间注意力机制。它引入了一个独立的层，用于在空间上强调输入中的高重要性区域，以改进CNN的特征提取。

**Result:** 在CIFAR-100和TinyImageNet数据集上，使用多个CNN骨干网络进行评估，Attention Zoom持续提高了Top-1和Top-5分类准确率。通过Grad-CAM和空间扭曲的视觉分析表明，该方法促进了细粒度和多样化的注意力模式。

**Conclusion:** Attention Zoom是一种有效且通用的层，能够以最小的架构开销改进卷积神经网络的性能。

> **ai_Abstract:** 本文提出了一种名为Attention Zoom的模块化、模型无关的空间注意力机制，旨在通过一个独立的层来空间强调输入中的高重要性区域，从而改进CNN的特征提取。该方法在CIFAR-100和TinyImageNet数据集上的多个CNN骨干网络上进行了评估，结果显示分类准确率有显著提升，并且视觉分析证实其能产生细粒度和多样化的注意力模式，证明了其有效性和通用性。

> **摘要翻译:** 我们提出了Attention Zoom，一种模块化且与模型无关的空间注意力机制，旨在改进卷积神经网络（CNN）中的特征提取。与需要架构特定集成的传统注意力方法不同，我们的方法引入了一个独立的层，该层在空间上强调输入中的高重要性区域。我们在CIFAR-100和TinyImageNet上使用多个CNN骨干网络评估了Attention Zoom，显示出Top-1和Top-5分类准确率的持续提高。使用Grad-CAM和空间扭曲的视觉分析表明，我们的方法鼓励细粒度和多样化的注意力模式。我们的结果证实了所提出层在以最小架构开销改进CNN方面的有效性和通用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [Information Bottleneck-Guided Heterogeneous Graph Learning for Interpretable Neurodevelopmental Disorder Diagnosis](https://arxiv.org/abs/2502.20769)
> *信息瓶颈引导的异构图学习用于可解释的神经发育障碍诊断*

*Yueyang Li, Lei Chen, Wenhao Dong, Shengyu Gong, Zijian Kang, Boyang Wei, Weiming Zeng, Hongjie Yan, Lingbin Bian, Zhiguo Zhang, Wai Ting Siok, Nizhuan Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 神经发育障碍, 可解释人工智能, 信息瓶颈, 异构图神经网络, 生物标志物识别

**Comment:** 

> **TL;DR:** 本文提出了I2B-HGNN，一个新颖的可解释模型，利用信息瓶颈和异构图学习，通过整合多模态数据和识别生物标志物来诊断神经发育障碍。

**AI_Comments:** 该论文创新性地应用信息瓶颈原理来指导脑连接建模和跨模态特征整合，为可解释的神经发育障碍诊断提供了一个统一的框架。将基于Transformer的全局注意力与图神经网络相结合，并利用异构图学习与结构一致性约束，是提升复杂神经疾病多模态数据处理和可解释性方面的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习方法在神经发育障碍（NDDs）诊断中存在解释性不足的问题，难以从fMRI数据中提取有意义的生物标志物，也难以建立影像特征与人口统计学特征的清晰关系。此外，当前的图神经网络方法在捕获局部和全局功能连接模式以及实现理论上合理的多模态数据融合方面也存在局限性。

**Method:** 本文提出了可解释信息瓶颈异构图神经网络（I2B-HGNN），一个统一的框架，应用信息瓶颈原理来指导脑连接建模和跨模态特征整合。该框架包含两个互补组件：信息瓶颈图Transformer（IBGraphFormer），它结合了基于Transformer的全局注意力机制和图神经网络，通过信息瓶颈引导的池化来识别生物标志物；以及信息瓶颈异构图注意力网络（IB-HGAN），它采用基于元路径的异构图学习和结构一致性约束来实现神经影像和人口统计学数据的可解释融合。

**Result:** 实验结果表明，I2B-HGNN在诊断NDDs方面取得了卓越的性能，表现出高分类准确性，并能提供可解释的生物标志物识别，同时有效分析非影像数据。

**Conclusion:** I2B-HGNN框架通过有效整合多模态数据和识别生物标志物，以高准确性和可解释性成功解决了可解释神经发育障碍诊断的挑战。

> **ai_Abstract:** 本文提出了一种名为I2B-HGNN的新型可解释框架，用于神经发育障碍（NDD）诊断。该框架旨在解决整合多模态神经影像和人口统计学数据、提取有意义生物标志物以及提高模型可解释性的挑战。I2B-HGNN利用信息瓶颈原理，包含两个核心组件：IBGraphFormer通过全局注意力和图池化识别生物标志物；IB-HGAN则通过异构图学习实现多源数据的可解释融合。实验结果表明，I2B-HGNN在NDD诊断中表现出卓越的性能，具有高分类准确性和可解释的生物标志物识别能力。

> **摘要翻译:** 为神经发育障碍（NDDs）诊断开发可解释模型在有效编码、解码和整合多模态神经影像数据方面面临重大挑战。尽管许多现有机器学习方法在脑网络分析中显示出前景，但它们通常解释性有限，特别是在从功能性磁共振成像（fMRI）数据中提取有意义的生物标志物以及建立影像特征与人口统计学特征之间的清晰关系方面。此外，当前的图神经网络方法在捕获局部和全局功能连接模式的同时实现理论上合理的多模态数据融合方面也面临局限性。
为了解决这些挑战，我们提出了可解释信息瓶颈异构图神经网络（I2B-HGNN），这是一个统一的框架，应用信息瓶颈原理来指导脑连接建模和跨模态特征整合。该框架包含两个互补的组件。第一个是信息瓶颈图Transformer（IBGraphFormer），它将基于Transformer的全局注意力机制与图神经网络通过信息瓶颈引导的池化相结合，以识别足够的生物标志物。第二个是信息瓶颈异构图注意力网络（IB-HGAN），它采用基于元路径的异构图学习和结构一致性约束，以实现神经影像和人口统计学数据的可解释融合。实验结果表明，I2B-HGNN在诊断NDDs方面取得了卓越的性能，表现出高分类准确性，并能提供可解释的生物标志物识别，同时有效分析非影像数据。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [111] [SSFMamba: Symmetry-driven Spatial-Frequency Feature Fusion for 3D Medical Image Segmentation](https://arxiv.org/abs/2508.03069)
> *SSFMamba：对称驱动的空间-频率特征融合用于3D医学图像分割*

*Bo Zhang, Yifan Zhang, Shuo Yan, Yu Bai, Zheng Zhang, Wu Liu, Xiuzhuang Zhou, Wendong Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D医学图像分割, 空间-频率融合, Mamba, 对称性, 全局上下文

**Comment:** 

> **TL;DR:** SSFMamba提出了一种基于Mamba的双分支网络，通过对称驱动的空间-频率特征融合，解决了3D医学图像分割中空间域全局上下文建模受限以及频率域特征利用不足的问题，并在BraTS数据集上取得了最先进的性能。

**AI_Comments:** SSFMamba的创新之处在于其对称驱动的空间-频率特征融合策略，有效地结合了空间域的局部细节和频率域的全局上下文信息，并特别关注了频率域的共轭对称性。引入Mamba块来处理异构特征融合，并利用其在频率域的全局建模能力是另一个亮点。此外，3D多方向扫描机制的设计也增强了局部与全局线索的融合。该方法在解决3D医学图像分割中全局上下文建模和频率域特征有效利用方面显示出重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D医学图像分割方法中，空间域在建模全局上下文方面能力有限。同时，新兴的频率域方法在特征提取时忽视了频率域信息的独特属性（如共轭对称性），也未考虑空间域和频率域之间数据分布的根本差异，这导致频率域的互补优势被稀释或掩盖。

**Method:** 本文提出了SSFMamba，一个基于Mamba的对称驱动空间-频率特征融合网络。SSFMamba采用互补的双分支架构，分别从空间域和频率域提取特征，并利用Mamba块融合这些异构特征，以保留全局上下文并增强局部细节。在频率域分支中，结合Mamba的全局上下文提取能力和频率域特征的协同效应来增强全局建模。此外，设计了一种3D多方向扫描机制来加强局部和全局线索的融合。

**Result:** 在BraTS2020和BraTS2023数据集上进行的大量实验表明，SSFMamba在各种评估指标上持续优于最先进的方法。

**Conclusion:** SSFMamba通过其对称驱动的空间-频率特征融合和Mamba块的应用，有效解决了3D医学图像分割中的挑战，并在基准数据集上取得了卓越的性能，证明了其方法的有效性和优越性。

> **ai_Abstract:** SSFMamba提出了一种新颖的基于Mamba的双分支网络，用于3D医学图像分割。该网络旨在克服传统空间域方法在全局上下文建模上的局限性，并解决现有频率域方法在处理频率域特有属性（如共轭对称性）和跨域数据分布差异时的不足。SSFMamba通过一个对称驱动的空间-频率特征融合机制，结合Mamba块的强大建模能力，从空间和频率域提取并融合特征，以同时保留全局上下文和增强局部细节。特别地，它利用Mamba在频率域增强全局建模，并引入3D多方向扫描机制。实验证明，SSFMamba在BraTS2020和BraTS2023数据集上表现优于现有最先进的方法。

> **摘要翻译:** 鉴于3D医学图像分割中空间域在建模全局上下文方面的能力有限，新兴方法已开始引入频域表示。然而，简单的特征提取策略往往忽视频域信息的独特属性，例如共轭对称性。它们也未能考虑空间域和频域之间数据分布的根本差异，这最终可能稀释或掩盖基于频域表示所提供的互补优势。本文提出SSFMamba，一个基于Mamba的对称驱动空间-频率特征融合网络，用于3D医学图像分割。SSFMamba采用互补的双分支架构，从空间域和频域提取特征，并利用Mamba块融合这些异构特征，以在保留全局上下文的同时增强局部细节。在频域分支中，我们利用Mamba卓越的全局上下文信息提取能力，结合频域特征的协同效应，进一步增强全局建模。此外，我们设计了一种3D多方向扫描机制，以加强局部和全局线索的融合。在BraTS2020和BraTS2023数据集上进行的大量实验表明，我们的方法在各种评估指标上持续优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [114] [FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles](https://arxiv.org/abs/2508.03241)
> *FFHQ-Makeup：具有多风格面部一致性的配对合成彩妆数据集*

*Xingchao Yang, Shiori Ueda, Yuantian Huang, Tomoya Akiyama, Takafumi Taketomi* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 合成彩妆数据集, 面部一致性, 彩妆迁移, FFHQ, 图像生成

**Comment:** Project: https://yangxingchao.github.io/FFHQ-Makeup-page, Datasets:
  https://huggingface.co/datasets/cyberagent/FFHQ-Makeup

> **TL;DR:** 提出了FFHQ-Makeup，一个高质量的合成彩妆数据集，包含9万对裸妆-彩妆图像对，解决了现有数据集缺乏高真实感和面部一致性的问题。

**AI_Comments:** 这项工作通过创建大规模、高质量且保持面部一致性的合成彩妆数据集，解决了美容领域一个长期存在的痛点。其创新之处在于改进的彩妆迁移方法能够解耦身份和彩妆，有效避免了传统合成方法中常见的面部扭曲或身份改变问题。该数据集有望成为推动虚拟试妆、面部美学分析等研究的重要基础资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有配对裸妆-彩妆数据集的收集面临挑战，真实世界数据难以大规模获取，而现有合成方法存在真实感不足或裸妆与彩妆图像之间不一致的问题（如面部几何变形或身份表情改变）。

**Method:** 该工作提出了FFHQ-Makeup数据集。它基于FFHQ数据集，通过引入一种改进的彩妆迁移方法，将真实世界的彩妆风格从现有数据集中迁移到1.8万个身份上，该方法能够解耦身份和彩妆。每个身份与5种不同的彩妆风格配对。

**Result:** 成功构建了FFHQ-Makeup数据集，包含9万张高质量的裸妆-彩妆图像对。该数据集在身份和表情上保持了面部一致性。

**Conclusion:** FFHQ-Makeup是第一个专门构建彩妆数据集的工作，旨在填补高质量裸妆-彩妆配对数据集的空白，并为未来美容相关任务的研究提供宝贵资源。

> **ai_Abstract:** 这篇论文介绍了FFHQ-Makeup，一个合成的高质量配对彩妆数据集。针对现有真实数据集收集困难和合成数据集真实感及一致性不足的问题，作者基于FFHQ数据集，开发了一种解耦身份和彩妆的改进迁移方法，将真实彩妆风格应用到1.8万个身份上，为每个身份生成5种不同彩妆风格，共计9万对图像。该数据集旨在保持面部身份和表情的一致性，以促进虚拟试妆、面部隐私保护等美容相关研究。

> **摘要翻译:** 配对的裸妆-彩妆面部图像对于广泛的美容相关任务至关重要，例如虚拟试妆、面部隐私保护和面部美学分析。然而，收集高质量的配对彩妆数据集仍然是一个重大挑战。真实世界数据采集受到难以收集大规模配对图像的限制，而现有合成方法通常存在真实感有限或裸妆与彩妆图像之间不一致的问题。当前的合成方法通常分为两类：基于变形的变换，这通常会扭曲面部几何形状并损害彩妆的精度；以及文本到图像生成，这倾向于改变面部身份和表情，从而破坏一致性。在这项工作中，我们提出了FFHQ-Makeup，一个高质量的合成彩妆数据集，它将每个身份与多种彩妆风格配对，同时在身份和表情上保持面部一致性。我们的管道基于多样化的FFHQ数据集，通过引入一种改进的彩妆迁移方法，将真实世界的彩妆风格从现有数据集中迁移到1.8万个身份上，该方法能够解耦身份和彩妆。每个身份与5种不同的彩妆风格配对，总共生成了9万张高质量的裸妆-彩妆图像对。据我们所知，这是第一个专门致力于构建彩妆数据集的工作。我们希望FFHQ-Makeup能够填补高质量裸妆-彩妆配对数据集的空白，并成为未来美容相关任务研究的宝贵资源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [116] [RAAG: Ratio Aware Adaptive Guidance](https://arxiv.org/abs/2508.03442)
> *RAAG: 比例感知自适应引导*

*Shangwen Zhu, Qianyu Peng, Yuting Hu, Zhantao Yang, Han Zhang, Zhao Pu, Ruili Feng, Fan Cheng* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 流式生成模型, 分类器无关引导, 自适应引导, 采样加速, RATIO

**Comment:** 

> **TL;DR:** 本文揭示了流式生成模型中分类器无关引导在早期采样步骤中的不稳定性，并提出了一种基于比例感知的自适应引导策略，可在保持或提高生成质量的同时实现高达3倍的加速采样。

**AI_Comments:** 该论文揭示了流式生成模型中一个重要的、先前未被充分理解的引导不稳定性问题，即早期采样步骤中RATIO峰值导致的敏感性。其提出的RAAG自适应引导方法理论扎实且实用，通过简单的指数衰减策略有效解决了这一问题，并在不增加推理开销的情况下显著提升了生成速度和质量。这项工作对于优化快速流式生成模型的性能具有重要意义，其发现的RATIO特性也为未来相关研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 流式生成模型在图像和视频合成方面取得了显著进展，但关于引导如何与采样过程的不同阶段互动（尤其是在快速、低步长的情况下）知之甚少。本文揭示了一个根本性不稳定性：最早的反向步骤对引导尺度极其敏感，这是因为条件预测与无条件预测的相对强度（RATIO）出现显著峰值。

**Method:** 为了解决早期采样步骤中引导尺度敏感性导致的不稳定性，我们提出了一种简单、有理论基础的、比例感知的自适应引导调度方案。该方案利用封闭形式的指数衰减，根据不断变化的RATIO自动抑制早期步骤的引导尺度。

**Result:** 我们的方法轻量级，无需额外推理开销，并与标准流框架兼容。在最先进的图像（SD3.5、Lumina）和视频（WAN2.1）模型上的实验表明，我们的方法在保持或提高生成质量、鲁棒性和语义对齐的同时，可实现高达3倍的采样速度提升。广泛的消融研究进一步证实了我们调度方案在模型、数据集和超参数上的通用性和稳定性。

**Conclusion:** 我们的研究结果强调了逐步引导适应在释放快速流式生成模型全部潜力方面的关键作用。

> **ai_Abstract:** 本文研究了流式生成模型中分类器无关引导（CFG）在快速采样阶段的相互作用。研究发现，在早期反向采样步骤中，条件预测与无条件预测的相对强度（RATIO）会出现显著峰值，导致引导尺度敏感性和指数级错误放大。为解决此问题，论文提出了一种名为RAAG的比例感知自适应引导调度方案，该方案在早期步骤根据RATIO自动衰减引导尺度。该方法无需额外开销，兼容性强，并能在不牺牲质量的前提下显著加速图像和视频生成，最高可达3倍。

> **摘要翻译:** 流式生成模型最近在图像和视频合成方面取得了显著进展，其中分类器无关引导（CFG）已成为高保真、可控生成的标准工具。然而，尽管它们取得了实际成功，但关于引导如何与采样过程的不同阶段互动——尤其是在现代流式管道典型的快速、低步长情况下——知之甚少。在这项工作中，我们发现并分析了一个根本性不稳定性：最早的反向步骤对引导尺度极其敏感，这是因为条件预测与无条件预测的相对强度（RATIO）出现显著峰值。通过严格的理论分析和经验验证，我们表明这种RATIO峰值是数据分布固有的，与模型架构无关，并且在与强引导结合时会导致指数级错误放大。为了解决这个问题，我们提出了一种简单、有理论基础的、比例感知的自适应引导调度方案，该方案利用封闭形式的指数衰减，根据不断变化的RATIO自动抑制早期步骤的引导尺度。我们的方法轻量级，无需额外推理开销，并与标准流框架兼容。在最先进的图像（SD3.5、Lumina）和视频（WAN2.1）模型上的实验表明，我们的方法在保持或提高生成质量、鲁棒性和语义对齐的同时，可实现高达3倍的采样速度提升。广泛的消融研究进一步证实了我们调度方案在模型、数据集和超参数上的通用性和稳定性。我们的发现强调了逐步引导适应在释放快速流式生成模型全部潜力方面的关键作用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [122] [MIDAR: Mimicking LiDAR Detection for Traffic Applications with a Lightweight Plug-and-Play Model](https://arxiv.org/abs/2508.02858)
> *MIDAR：用于交通应用的轻量级即插即用模型，模仿激光雷达检测*

*Tianheng Zhu, Yiheng Feng* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 激光雷达检测, 交通模拟, 合作感知, 自动驾驶, MIDAR

**Comment:** 18 pages, 9 figures

> **TL;DR:** MIDAR是一个轻量级模型，用于在交通模拟器中模拟激光雷达检测，弥补了高保真传感器模拟器与高效交通模拟器之间的差距。

**AI_Comments:** MIDAR的创新点在于它提供了一个轻量级且即插即用的解决方案，能够在不牺牲交通模拟器可扩展性的前提下，生成逼真的激光雷达检测结果。这对于大规模合作感知研究和交通应用具有重要意义，因为它允许研究人员在模拟环境中获得更接近真实世界的感知数据。

<details>
  <summary>Details</summary>

**Motivation:** 现有游戏引擎模拟器在多自动驾驶车辆场景中面临可扩展性挑战，而微观交通模拟器缺乏感知建模能力，导致在合作感知研究中难以获得逼真的检测结果。

**Method:** 本文提出了MIDAR模型，一个激光雷达检测模仿模型，它利用微观交通模拟器中可用的车辆级特征来近似逼真的激光雷达检测。具体而言，MIDAR基于周围车辆的空间布局和尺寸，预测理想激光雷达检测结果中的真阳性（TPs）和假阴性（FNs）。通过构建一个改进的多跳视线（RM-LoS）图来编码车辆间的遮挡关系，MIDAR采用GRU增强的APPNP架构来传播特征。

**Result:** MIDAR在nuScenes AD数据集上，在近似主流3D激光雷达检测模型CenterPoint的检测结果方面，AUC达到了0.909。两项基于合作感知的交通应用进一步验证了这种逼真检测建模的必要性。

**Conclusion:** MIDAR可以无缝集成到交通模拟器和轨迹数据集中，为需要精确个体车辆观测（如位置、速度、车道索引）的交通应用提供逼真的检测建模能力。

> **ai_Abstract:** 本文提出了MIDAR，一个轻量级的即插即用模型，旨在弥补高保真传感器模拟器（如CARLA）在多自动驾驶车辆场景中的可扩展性挑战与微观交通模拟器（如SUMO）缺乏感知建模能力之间的鸿沟。MIDAR通过利用交通模拟器中现有的车辆级特征来模仿逼真的激光雷达检测，预测真阳性（TPs）和假阴性（FNs），并利用一个改进的多跳视线（RM-LoS）图和GRU增强的APPNP架构来处理遮挡关系。实验表明，MIDAR在近似主流3D激光雷达检测模型CenterPoint的结果上表现出色，AUC达到0.909，并被证明对于需要精确车辆观测的交通应用至关重要。

> **摘要翻译:** 随着自动驾驶（AD）技术的发展，越来越多的研究致力于利用从多个自动驾驶车辆（AVs）收集的协同感知（CP）数据来增强交通应用。由于大规模真实世界自动驾驶车辆部署的不切实际性，模拟已成为大多数研究的主要方法。虽然像CARLA这样的基于游戏引擎的模拟器能够生成高保真原始传感器数据（例如激光雷达点云），并可用于产生逼真的检测输出，但它们在多自动驾驶车辆场景中面临可扩展性挑战。相比之下，像SUMO这样的微观交通模拟器能够高效扩展，但缺乏感知建模能力。为了弥补这一差距，我们提出了MIDAR，一个激光雷达检测模仿模型，它利用微观交通模拟器中易于获得的车辆级特征来近似逼真的激光雷达检测。具体而言，MIDAR基于周围车辆的空间布局和尺寸，从理想的激光雷达检测结果中预测真阳性（TPs）和假阴性（FNs）。构建了一个改进的多跳视线（RM-LoS）图来编码车辆间的遮挡关系，MIDAR在此基础上采用GRU增强的APPNP架构，将来自自我自动驾驶车辆和遮挡车辆的特征传播到预测目标。MIDAR在nuScenes AD数据集上，在近似主流3D激光雷达检测模型CenterPoint生成的检测结果方面，AUC达到了0.909。两项基于协同感知的交通应用进一步验证了这种逼真检测建模的必要性，特别是对于需要精确个体车辆观测（例如位置、速度、车道索引）的任务。正如应用所示，MIDAR可以无缝集成到交通模拟器和轨迹数据集中，并将在发布后开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [127] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
> *D3：使用二阶特征的免训练AI生成视频检测*

*Chende Zheng, Ruiqi suo, Chenhao Lin, Zhengyu Zhao, Le Yang, Shuai Liu, Minghui Yang, Cong Wang, Chao Shen* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** AI生成视频检测, 免训练, 二阶特征, 时间伪影, D3

**Comment:** 8 pages, 4 figures

> **TL;DR:** D3提出了一种免训练的AI生成视频检测方法，通过分析真实视频和AI生成视频在二阶特征分布上的差异，在多个数据集上表现出卓越的性能和计算效率。

**AI_Comments:** D3的创新之处在于其免训练的特性以及对视频二阶时间特征的深入挖掘，这使其在面对不断进化的AI生成技术时可能具有更强的适应性。通过建立理论框架并验证二阶特征的差异性，该方法提供了一个新颖且高效的检测范式，避免了传统深度学习方法对大量训练数据的依赖。其出色的性能和计算效率使其在实际应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 视频生成技术（如Sora）的快速发展使得高保真AI生成视频的制作变得越来越容易，引起了公众对合成内容传播的担忧。现有检测方法在探索合成视频中的时间伪影方面存在不足。

**Method:** 该研究基于牛顿力学建立了二阶动力学分析的理论框架，并扩展了用于时间伪影检测的二阶中心差分特征。在此基础上，提出了名为D3（Detection by Difference of Differences）的免训练检测方法，利用真实视频和AI生成视频之间在二阶特征分布上的根本差异进行检测。

**Result:** D3在4个开源数据集（Gen-Video, VideoPhy, EvalCrafter, VidProM）共40个子集上验证了其优越性。例如，在GenVideo数据集上，D3的平均精度比之前最好的方法提高了10.39%（绝对值）。额外实验表明D3具有出色的计算效率和强大的鲁棒性能。

**Conclusion:** D3通过利用真实视频和AI生成视频之间在二阶特征分布上的差异，提出了一种有效的免训练检测方法，并在多个数据集上取得了显著的性能提升，同时表现出高效率和鲁棒性。

> **ai_Abstract:** 本研究提出了一种名为D3的免训练AI生成视频检测方法，旨在解决现有方法对合成视频时间伪影探索不足的问题。D3基于牛顿力学下的二阶动力学分析，揭示了真实视频与AI生成视频在二阶特征分布上的根本差异，并利用这些差异进行检测。实验结果表明，D3在多个数据集上显著优于现有最佳方法，例如在GenVideo上平均精度提升10.39%，同时展现出卓越的计算效率和鲁棒性。

> **摘要翻译:** 视频生成技术（如Sora）的演进使得制作高保真AI生成视频变得越来越容易，引发了公众对合成内容传播的担忧。然而，现有检测方法受限于对合成视频中时间伪影的探索不足。为了弥补这一空白，我们通过牛顿力学下的二阶动力学分析建立了一个理论框架，随后扩展了专为时间伪影检测而设计的二阶中心差分特征。在此理论基础上，我们揭示了真实视频和AI生成视频在二阶特征分布上的根本差异。具体而言，我们提出了一种新颖的免训练检测方法——差异之差检测（D3），该方法利用了上述二阶时间差异。我们在4个开源数据集（Gen-Video、VideoPhy、EvalCrafter、VidProM）共40个子集上验证了D3的优越性。例如，在GenVideo上，D3的平均精度比之前最好的方法提高了10.39%（绝对值）。关于时间成本和后处理操作的额外实验证明了D3卓越的计算效率和强大的鲁棒性能。我们的代码可在https://github.com/Zig-HS/D3获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [135] [Long-tailed Adversarial Training with Self-Distillation](https://arxiv.org/abs/2503.06461)
> *长尾对抗训练与自蒸馏*

*Seungju Cho, Hongsin Lee, Changick Kim* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 长尾分布, 对抗训练, 自蒸馏, 对抗鲁棒性, 尾部类别

**Comment:** ICLR 2025. See OpenReview and code (in Supplementary Material) at
  https://openreview.net/forum?id=vM94dZiqx4

> **TL;DR:** 本文提出了一种新颖的自蒸馏技术，通过利用从原始长尾数据集中采样的平衡自教师模型，显著提高了长尾分布下对抗鲁棒性，尤其是在尾部类别的性能上达到了最先进水平。

**AI_Comments:** 本文提出了一种简单而有效的自蒸馏方法来解决长尾分布下的对抗鲁棒性问题，其创新点在于利用平衡的自教师模型来指导学习，有效缓解了尾部数据稀缺带来的挑战。该方法在多个数据集上取得了显著的性能提升，尤其是在尾部类别的鲁棒性上表现出色，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 对抗训练虽然能显著增强对抗鲁棒性，但在平衡数据集上表现更优。在不平衡或长尾分布下解决对抗鲁棒性问题更具挑战性，主要是因为尾部数据实例稀缺，导致对抗训练难以在尾部类别上实现高性能。

**Method:** 本文提出了一种通过新颖的自蒸馏技术来提升长尾分布上对抗鲁棒性的方法。具体来说，该方法利用一个平衡的自教师模型，该模型使用从原始长尾数据集中采样的平衡数据集进行训练。

**Result:** 在长尾对抗鲁棒性方面，本文方法在干净和鲁棒准确性方面均取得了最先进的性能，并在各种数据集上显著提高了尾部类别的性能。针对PGD攻击，该方法在CIFAR-10、CIFAR-100和Tiny-ImageNet上分别将尾部类别的准确率提高了20.3、7.1和3.8个百分点，同时实现了最高的鲁棒准确性。

**Conclusion:** 本文提出的基于自蒸馏的长尾对抗训练方法有效解决了长尾分布下对抗鲁棒性差的问题，尤其显著提升了尾部类别的性能，达到了最先进水平。

> **ai_Abstract:** 本文针对长尾分布下对抗训练在尾部类别性能不佳的挑战，提出了一种基于自蒸馏的新颖方法。该方法通过训练一个使用平衡数据集的自教师模型，显著提升了长尾对抗鲁棒性。实验证明，该方法在干净和鲁棒准确性方面均达到最先进水平，尤其在尾部类别性能上取得了显著提升，例如在CIFAR-10、CIFAR-100和Tiny-ImageNet上分别提高了20.3、7.1和3.8个百分点的对抗准确率。

> **摘要翻译:** 对抗训练显著增强了对抗鲁棒性，然而，优越的性能主要在平衡数据集上实现。在不平衡或长尾分布背景下解决对抗鲁棒性问题更具挑战性，这主要是由于尾部数据实例的稀缺性。先前关于长尾分布中对抗鲁棒性的研究主要集中于将传统的长尾自然训练与现有对抗鲁棒性方法相结合。在本研究中，我们深入分析了对抗训练难以在长尾分布的尾部类别上实现高性能的挑战。此外，我们通过一种新颖的自蒸馏技术，提出了一种简单而有效的解决方案，以提升长尾分布上的对抗鲁棒性。具体来说，这种方法利用了一个平衡的自教师模型，该模型使用从原始长尾数据集中采样的平衡数据集进行训练。我们广泛的实验证明，在长尾对抗鲁棒性方面，无论是在干净准确性还是鲁棒准确性方面，都达到了最先进的性能，并在各种数据集上显著提高了尾部类别的性能。我们分别在CIFAR-10、CIFAR-100和Tiny-ImageNet上将尾部类别对抗PGD攻击的准确率提高了20.3、7.1和3.8个百分点，同时实现了最高的鲁棒准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [139] [RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions](https://arxiv.org/abs/2508.03077)
> *RobustGS：低质量条件下前馈3D高斯泼溅的统一增强*

*Anran Wu, Long Peng, Xin Di, Xueyuan Dai, Chen Wu, Yang Wang, Xueyang Fu, Yang Cao, Zheng-Jun Zha* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D高斯泼溅, 鲁棒性, 特征增强, 低质量图像, 多视图重建

**Comment:** 

> **TL;DR:** 提出RobustGS模块，显著增强前馈3DGS在噪声、低光、雨等低质量输入条件下的鲁棒性，实现高质量3D重建。

**AI_Comments:** RobustGS的创新之处在于其通用且高效的多视图特征增强模块设计，特别是广义退化学习器和语义感知状态空间模型的结合，使其能够有效处理真实世界中复杂的低质量输入。其即插即用的特性也大大增强了其实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有前馈3D高斯泼溅（3DGS）方法在处理真实世界中受噪声、低光或雨等挑战性条件影响的低质量多视图图像时，会导致几何不准确和3D重建质量下降。

**Method:** 提出通用且高效的多视图特征增强模块RobustGS，可即插即用集成到现有前馈3DGS管道中。该模块包含两个核心组件：1) 广义退化学习器（Generalized Degradation Learner），用于从多视图输入中提取多种退化的通用表示和分布，以增强退化感知。2) 语义感知状态空间模型，首先利用退化表示增强特征空间中的受损输入，然后采用语义感知策略聚合不同视图间语义相似的信息，以提取细粒度的跨视图对应关系，从而提高3D表示质量。

**Result:** 实验证明，RobustGS以即插即用的方式集成到现有方法中时，在各种类型的退化条件下始终实现最先进的重建质量。

**Conclusion:** RobustGS通过其创新的模块设计，有效解决了前馈3DGS在低质量输入条件下的鲁棒性问题，显著提升了3D重建质量，并展现了其普适性和优越性。

> **ai_Abstract:** 本文提出了RobustGS，一个通用且高效的多视图特征增强模块，旨在解决前馈3D高斯泼溅（3DGS）在低质量输入图像（如噪声、低光、雨）下重建质量下降的问题。RobustGS包含一个广义退化学习器用于提取多重退化表示，以及一个语义感知状态空间模型用于在特征空间中增强受损输入并聚合跨视图语义信息。该模块可即插即用，实验证明其在各种退化条件下能显著提高3D重建的鲁棒性和质量，达到最先进水平。

> **摘要翻译:** 前馈3D高斯泼溅（3DGS）通过实现快速高质量重建而无需逐场景优化，克服了基于优化的3DGS的局限性。然而，现有前馈方法通常假设输入多视图图像是干净和高质量的。在真实世界场景中，图像常在噪声、低光或雨等挑战性条件下捕获，导致几何不准确和3D重建质量下降。为了解决这些挑战，我们提出了一种通用且高效的多视图特征增强模块RobustGS，它能显著提高前馈3DGS方法在各种不利成像条件下的鲁棒性，实现高质量3D重建。RobustGS模块可以无缝地以即插即用的方式集成到现有预训练管道中，以增强重建鲁棒性。具体而言，我们引入了一个新颖的组件——广义退化学习器，旨在从多视图输入中提取多种退化的通用表示和分布，从而增强对退化的感知并提高3D重建的整体质量。此外，我们提出了一种新颖的语义感知状态空间模型。它首先利用提取的退化表示来增强特征空间中的受损输入。然后，它采用语义感知策略聚合不同视图间语义相似的信息，从而提取细粒度的跨视图对应关系，进一步提高3D表示的质量。大量实验表明，我们的方法以即插即用的方式集成到现有方法中时，在各种类型的退化条件下始终实现最先进的重建质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [CoPS: Conditional Prompt Synthesis for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2508.03447)
> *CoPS：面向零样本异常检测的条件提示合成*

*Qiyu Chen, Zhen Qu, Wei Luo, Haiming Yao, Yunkang Cao, Yuxin Jiang, Yinan Duan, Huiyuan Luo, Chengkan Lv, Zhengtao Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 零样本异常检测, 提示合成, 视觉语言模型, 异常检测, 动态提示

**Comment:** 19 pages, 33 figures, 14 tables

> **TL;DR:** CoPS通过合成动态提示并注入视觉特征，解决了现有零样本异常检测中提示学习的泛化性和过拟合问题，在工业和医学数据集上显著超越了SOTA方法。

**AI_Comments:** CoPS的创新之处在于其动态提示合成机制，通过将视觉特征（正常/异常原型、语义图像特征）注入到提示中，有效克服了传统提示学习中静态token和稀疏标签的局限性。这种方法提高了模型对未见类别的泛化能力，并在实际应用中展现出显著的性能提升，对于零样本异常检测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前零样本异常检测中，提示学习面临两大挑战：(i) 静态可学习的token难以捕捉正常和异常状态的连续多样模式，限制了对未见类别的泛化能力；(ii) 固定文本标签提供过于稀疏的类别信息，使模型容易过拟合到特定语义子空间。

**Method:** 本文提出了条件提示合成（CoPS）框架，通过以下方式合成基于视觉特征的动态提示：1. 从细粒度补丁特征中提取代表性的正常和异常原型并显式注入到提示中，实现自适应状态建模。2. 利用变分自编码器对语义图像特征进行建模，并将多样的类别token隐式融合到提示中。3. 结合空间感知对齐机制。

**Result:** CoPS在13个工业和医学数据集的分类和分割任务中，AUROC指标均超越了现有最先进方法2.5%。

**Conclusion:** CoPS框架通过动态提示合成和视觉特征注入，有效解决了零样本异常检测中提示学习的泛化性和过拟合问题，显著提升了跨类别异常检测的性能。

> **ai_Abstract:** CoPS是一种新颖的零样本异常检测框架，旨在解决现有提示学习中静态token和稀疏标签导致的泛化性差和过拟合问题。CoPS通过从视觉特征中合成动态提示，显式注入正常和异常原型，并隐式融合多样化类别token，从而实现自适应状态建模。结合空间感知对齐机制，CoPS在多个工业和医学数据集上显著提升了异常检测的分类和分割性能。

> **摘要翻译:** 最近，大型预训练视觉-语言模型在零样本异常检测（ZSAD）中展现出卓越的性能。通过在单个辅助数据集上进行微调，该模型能够在涵盖工业缺陷和医疗病变的各种数据集上实现跨类别异常检测。与手动设计的提示相比，提示学习消除了对专家知识和反复试验的需求。然而，它仍然面临以下挑战：(i) 静态可学习的token难以捕捉正常和异常状态的连续和多样模式，限制了对未见类别的泛化能力；(ii) 固定文本标签提供过于稀疏的类别信息，使得模型容易过拟合到特定语义子空间。为了解决这些问题，我们提出了条件提示合成（CoPS），这是一种新颖的框架，它根据视觉特征合成动态提示以增强ZSAD性能。具体来说，我们从细粒度补丁特征中提取代表性的正常和异常原型，并将其显式注入到提示中，从而实现自适应状态建模。鉴于类别标签的稀疏性，我们利用变分自编码器对语义图像特征进行建模，并将各种类别token隐式融合到提示中。此外，结合我们的空间感知对齐机制，广泛的实验表明CoPS在13个工业和医学数据集的分类和分割任务中，AUROC均超越了最先进方法2.5%。代码将在https://github.com/cqylunlun/CoPS提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [158] [Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model](https://arxiv.org/abs/2503.23502)
> *利用预训练深度基础模型提升全向立体匹配*

*Jannik Endres, Oliver Hahn, Charles Corbière, Simone Schaub-Meyer, Stefan Roth, Alexandre Alahi* | **Category: cs.CV, cs.AI, cs.LG, cs.RO** | **Updated: 2025-08-04**

**Keywords:** 全向立体匹配, 深度基础模型, 单目深度估计, 机器人, 深度感知

**Comment:** Accepted at IROS 2025. Project page:
  https://vita-epfl.github.io/DFI-OmniStereo-website/

> **TL;DR:** DFI-OmniStereo提出了一种新颖的全向立体匹配方法，利用预训练的单目深度基础模型，并在Helvipd数据集上将视差MAE降低了约16%，解决了现有方法在复杂环境下精度有限的问题。

**AI_Comments:** 该论文的创新点在于将预训练的深度基础模型引入全向立体匹配任务，有效解决了真实世界数据稀缺导致精度受限的问题。通过利用大型模型的泛化能力和提出的两阶段训练策略，实现了显著的性能提升，对于移动机器人等需要高精度全向深度感知的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全向深度感知对于移动机器人应用至关重要，但现有的全向立体匹配方法由于缺乏真实世界数据，在不同环境、深度范围和光照条件下深度精度有限。

**Method:** 本文提出DFI-OmniStereo，一种利用大型预训练基础模型进行相对单目深度估计的全向立体匹配方法。该方法采用迭代优化立体匹配架构，并引入了两阶段训练策略，在尺度不变微调之前利用相对单目深度特征。

**Result:** DFI-OmniStereo在真实世界的Helvipad数据集上实现了最先进的结果，与之前最好的全向立体方法相比，视差MAE降低了约16%。

**Conclusion:** DFI-OmniStereo通过结合预训练深度基础模型和创新的训练策略，显著提升了全向立体匹配的精度，为移动机器人应用提供了更可靠的深度感知能力。

> **ai_Abstract:** 本文提出了一种名为DFI-OmniStereo的新型全向立体匹配方法，旨在解决现有方法在复杂环境下深度精度不足的问题。该方法创新性地将大型预训练的单目深度基础模型整合到迭代优化立体匹配框架中，并通过两阶段训练策略有效利用其特征。实验结果表明，DFI-OmniStereo在Helvipad数据集上显著提升了性能，将视差平均绝对误差降低了约16%，达到了当前最佳水平。

> **摘要翻译:** 全向深度感知对于需要360度全方位场景理解的移动机器人应用至关重要。基于摄像头的设置通过使用立体深度估计来生成密集、高分辨率的深度图，而无需依赖昂贵的有源传感，从而提供了一种经济高效的选择。然而，由于真实世界数据的稀缺性，现有的全向立体匹配方法在不同的环境、深度范围和光照条件下只能实现有限的深度精度。我们提出了DFI-OmniStereo，这是一种新颖的全向立体匹配方法，它利用一个大型预训练的基础模型进行迭代优化立体匹配架构中的相对单目深度估计。我们引入了一种专门的两阶段训练策略，在尺度不变微调之前利用相对单目深度特征进行全向立体匹配。DFI-OmniStereo在真实世界的Helvipad数据集上取得了最先进的结果，与之前最好的全向立体方法相比，视差MAE降低了约16%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [170] [Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets](https://arxiv.org/abs/2508.02871)
> *深度神经变换器和卷积神经网络在现代遥感数据集上的评估与分析*

*J. Alex Hurt, Trevor M. Bajkowski, Grant J. Scott, Curt H. Davis* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 深度学习, 变换器, 卷积神经网络, 遥感, 目标检测

**Comment:** 

> **TL;DR:** 本文比较了深度神经变换器和卷积神经网络在遥感图像目标检测中的性能，特别是在高分辨率卫星图像上，并对33个模型进行了大规模评估和分析。

**AI_Comments:** 本文对深度学习领域中两种主流架构——变换器和卷积神经网络在遥感图像分析这一特定应用场景下的性能进行了大规模且系统的比较。其创新之处在于首次在大规模现代遥感数据集上对变换器进行了广泛评估，填补了该领域的空白。研究通过对比多种先进模型，为遥感图像处理选择合适的深度学习模型提供了重要的实证依据，对于推动遥感领域的计算机视觉应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 卷积神经网络（DCNNs）在计算机视觉领域取得了巨大成功，但随着视觉变换器（Visual Transformers）的兴起，有必要在大规模遥感数据上比较不同变换器基神经网络的性能，因为它们尚未在此类数据上进行广泛比较。

**Method:** 本研究探索了基于变换器的神经网络在高分辨率电光卫星图像中进行目标检测的应用。研究比较了11种不同的边界框检测和定位算法（其中7种发表于2020年之后，所有11种发表于2015年之后）。具体地，在三种最先进的开源高分辨率遥感图像数据集上，比较了5种基于变换器的架构与6种卷积网络的性能。共训练和评估了33个深度神经模型，并对模型性能进行了讨论和分析。

**Result:** 研究展示了变换器基神经网络在多种公开基准数据集上实现了最先进的性能。通过对五种变换器架构和六种卷积网络在三种遥感数据集上的性能进行比较，并对33个深度神经模型的表现进行了讨论和分析。

**Conclusion:** 论文通过对多种特征提取方法和检测算法下模型性能的讨论和分析，提供了关于深度神经变换器和卷积神经网络在现代遥感数据集上表现的见解。

> **ai_Abstract:** 本文评估并分析了深度神经变换器和卷积神经网络在现代遥感数据集上的性能。研究指出，尽管变换器在其他CV领域表现出色，但其在遥感领域的规模化比较仍不足。为此，作者在高分辨率电光卫星图像的目标检测任务上，比较了5种基于变换器的架构和6种卷积网络，总计33个深度模型在三种先进的开源遥感数据集上的表现。研究展示了变换器基模型在遥感目标检测中的最先进性能，并对不同特征提取和检测算法下的模型表现进行了深入讨论和分析。

> **摘要翻译:** 2012年，AlexNet确立了深度卷积神经网络（DCNNs）在计算机视觉领域的领先地位，这些网络很快在包括遥感在内的许多领域的视觉任务中取得了领先。随着视觉变换器（Visual Transformers）的发布，我们正在见证计算视觉领域的第二次现代飞跃，因此，理解各种基于变换器的神经网络在卫星图像上的表现至关重要。尽管变换器在自然语言处理和计算机视觉应用中表现出高水平的性能，但它们尚未在大规模现代遥感数据上进行比较。在本文中，我们探讨了在高清电光卫星图像中使用基于变换器的神经网络进行目标检测的应用，并在各种公开基准数据集上展示了最先进的性能。在本研究中，我们比较了11种不同的边界框检测和定位算法，其中7种自2020年以来发布，所有11种自2015年以来发布。将五种基于变换器的架构与六种卷积网络在三种最先进的开源高分辨率遥感图像数据集上进行了性能比较，这些数据集在大小和复杂性上各不相同。在训练和评估了33个深度神经模型之后，我们随后讨论并分析了各种特征提取方法和检测算法下的模型性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [175] [FEB-Cache: Frequency-Guided Exposure Bias Reduction for Enhancing Diffusion Transformer Caching](https://arxiv.org/abs/2503.07120)
> *FEB-Cache：频率引导的曝光偏差减少以增强扩散Transformer缓存*

*Zhen Zou, Feng Zhao* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 扩散Transformer, 缓存, 曝光偏差, 频率引导, FEB-Cache

**Comment:** 

> **TL;DR:** FEB-Cache通过频率引导的缓存策略减少扩散Transformer中缓存引起的曝光偏差，从而提高性能并加速生成过程。

**AI_Comments:** 这篇论文通过深入分析缓存对扩散Transformer生成质量损害的原因（曝光偏差放大），并发现其与 Attention 和 MLP 的频率响应特性不匹配，提供了一个新颖的视角。通过引入频率引导的缓存策略 FEB-Cache，分离处理 Attention 和 MLP，有效解决了这一问题。其创新点在于从频率响应特性入手，提供了对缓存机制更深层次的理解和优化方法，对加速DiT并提升生成质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer (DiT) 具有高计算复杂性，而现有的特征缓存方法在加速的同时会损害生成质量，因为它们没有分析缓存损害生成过程的原因。本文旨在解决缓存放大曝光偏差导致生成质量下降的问题。

**Method:** 本文首先确认缓存会放大曝光偏差。然后，发现此问题源于 Attention 和 MLP 的频率响应特性与简单缓存之间的不匹配。基于 Attention 和 MLP 对频率信号的独特偏好，提出了一种分离 Attention 和 MLP 的缓存策略，并引入了 FEB-Cache。FEB-Cache 是一种联合缓存策略，它基于频率引导的缓存表来缓存 Attention 和 MLP，以实现与非曝光偏差扩散过程的对齐，从而增强曝光偏差的拟合并减少它。

**Result:** 经验结果表明，FEB-Cache 在优化模型性能的同时促进了加速。

**Conclusion:** FEB-Cache 提供了一种结合对缓存机制的全面理解的新视角，通过频率引导的 Attention 和 MLP 分离缓存策略，成功解决了扩散Transformer中缓存导致的曝光偏差问题，从而提升了性能并加速了扩散过程。

> **ai_Abstract:** 本文针对扩散Transformer (DiT) 高计算复杂性中缓存导致的生成质量下降问题，指出其根源在于缓存放大了曝光偏差，且 Attention 和 MLP 的频率响应特性与简单缓存不匹配。为此，作者提出了 FEB-Cache，这是一种频率引导的联合缓存策略，通过分离 Attention 和 MLP 的缓存，使其与非曝光偏差扩散过程对齐，从而有效减少曝光偏差。实验结果验证了 FEB-Cache 在提升模型性能的同时实现了加速。

> **摘要翻译:** 扩散Transformer (DiT) 展示了令人印象深刻的生成能力，但由于其高计算复杂性而面临巨大挑战。为了解决这个问题，引入了各种方法，特别是特征缓存。然而，这些方法侧重于对齐非缓存扩散，而没有分析为什么缓存会损害生成过程。在本文中，我们首先证实缓存大大放大了曝光偏差，导致生成质量下降。然而，由于曝光偏差的非平滑性，直接应用噪声缩放来解决这个问题是具有挑战性的。我们发现这种现象源于其频率响应特性与 Attention 和 MLP 的简单缓存之间的不匹配。由于这两个组件对频率信号表现出独特的偏好，这为我们提供了一种缓存策略，可以分离 Attention 和 MLP，以实现曝光偏差的增强拟合并减少它。在此基础上，我们引入了 FEB-Cache，这是一种联合缓存策略，它基于频率引导的缓存表，与非曝光偏差扩散过程（这为我们提供了更高的性能上限）的 Attention 和 MLP 缓存对齐。我们的方法结合了对缓存机制的全面理解，并提供了一个利用缓存加速扩散过程的新视角。经验结果表明，FEB-Cache 在优化模型性能的同时促进了加速。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [179] [Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models](https://arxiv.org/abs/2508.03079)
> *探索大型视觉-语言模型中细粒度属性的公平性*

*Zaiying Zhao, Toshihiko Yamasaki* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 大型视觉-语言模型, 公平性, 细粒度属性, 偏见, 知识库

**Comment:** Accepted to the Responsible Generative AI (ReGenAI) Workshop, CVPR
  2025

> **TL;DR:** 本研究发现大型视觉-语言模型在细粒度属性上存在偏见，且文化、环境和行为因素对其决策影响大于传统人口统计学属性。

**AI_Comments:** 本文创新性地将公平性研究扩展到更细粒度的属性，并指出文化、环境、行为等非传统人口统计学因素对LVLM公平性有更显著影响，为未来LVLM偏见缓解提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注大型视觉-语言模型在人口统计学属性上的公平性，但对更广泛的细粒度属性的公平性探索不足，而LVLM的应用快速增长，其公平性问题日益凸显。

**Method:** 本研究利用大型语言模型（LLMs）构建了一个开放集偏见属性知识库，并评估了大型视觉-语言模型（LVLMs）在更细粒度属性上的公平性。

**Result:** 实验结果表明，LVLMs在多样化的属性集上表现出有偏见的输出；文化、环境和行为因素对LVLMs决策的影响比传统人口统计学属性更显著。

**Conclusion:** 大型视觉-语言模型在细粒度属性上存在显著偏见，且非传统人口统计学因素（如文化、环境、行为）对其公平性的影响更为重要。

> **ai_Abstract:** 本研究旨在探索大型视觉-语言模型（LVLMs）在细粒度属性上的公平性，超越了现有研究主要关注的人口统计学属性。通过构建一个基于LLMs的开放集偏见属性知识库，研究发现LVLMs在多样化属性上存在偏见，且文化、环境和行为因素对模型决策的影响远大于传统人口统计学属性。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）如GPT-4o的应用迅速扩展，引发了对其公平性的重大担忧。虽然现有研究主要关注种族和性别等人口统计学属性，但对更广泛属性的公平性在很大程度上仍未被探索。在本研究中，我们利用大型语言模型（LLMs）构建了一个开放集偏见属性知识库，并评估了LVLMs在更细粒度属性上的公平性。我们的实验结果表明，LVLMs在各种属性上都表现出有偏见的输出，并进一步证明文化、环境和行为因素对LVLM决策的影响比传统人口统计学属性更为显著。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [180] [MVTOP: Multi-View Transformer-based Object Pose-Estimation](https://arxiv.org/abs/2508.03243)
> *MVTOP：基于多视图Transformer的目标姿态估计*

*Lukas Ranftl, Felix Brendel, Bertram Drost, Carsten Steger* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多视图姿态估计, Transformer, 姿态模糊, 早期融合, 刚体目标

**Comment:** 9 pages, 7 figures

> **TL;DR:** MVTOP是一种新型的基于Transformer的多视图刚体目标姿态估计算法，通过早期融合视图特征和利用视线解决单视图或后处理无法解决的姿态模糊问题。

**AI_Comments:** MVTOP的创新之处在于其采用早期融合和利用视线来解决多视图姿态估计中的姿态模糊问题，这是现有方法难以处理的。其端到端可训练且不依赖深度数据的特性增加了其实用性。该方法通过构建一个专门的合成数据集来验证其解决复杂姿态模糊的能力，显示了其在该领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有单视图或对单视图姿态进行后处理的方法无法可靠解决多视图刚体目标姿态估计中的姿态模糊问题。据作者所知，缺乏能够可靠解决此类姿态模糊问题的整体多视图方法。

**Method:** MVTOP是一种基于Transformer的多视图刚体目标姿态估计算法。它通过早期融合视图特定特征来解决姿态模糊问题。该方法通过从相应相机中心发出的视线来建模多视图几何，尽管相机内部参数和相对方向已知，但它们可以随每次推理而变化，使其具有通用性。该模型是端到端可训练的，且不需要额外数据如深度信息。

**Result:** 在作者提供的合成数据集上，MVTOP优于单视图和所有现有多视图方法。在YCB-V数据集上取得了有竞争力的结果。作者指出，据他们所知，没有其他整体多视图方法能够可靠地解决此类姿态模糊问题。

**Conclusion:** MVTOP通过早期融合视图特定特征和利用视线，成功解决了多视图刚体目标姿态估计中的姿态模糊问题。它提供了一种通用、端到端可训练且无需额外数据的解决方案，并在处理复杂姿态模糊方面表现出色，填补了该领域的空白。

> **ai_Abstract:** 本文提出MVTOP，一种基于Transformer的新型多视图刚体目标姿态估计算法。它通过早期融合视图特征并利用相机视线来解决传统单视图或后处理方法无法解决的姿态模糊问题。MVTOP具有通用性、端到端可训练，且无需额外深度数据。实验证明，MVTOP在处理姿态模糊的合成数据集上显著优于现有方法，并在YCB-V数据集上表现出竞争力，填补了可靠解决此类问题的整体多视图方法空白。

> **摘要翻译:** 我们提出了MVTOP，一种新颖的基于Transformer的多视图刚体目标姿态估计方法。通过对视图特定特征的早期融合，我们的方法可以解决单视图或对单视图姿态进行后处理无法解决的姿态模糊问题。MVTOP通过从相应相机中心发出的视线来建模多视图几何。虽然该方法假设特定场景的相机内部参数和相对方向是已知的，但它们可以随每次推理而变化。这使得该方法具有通用性。视线的使用使得MVTOP能够利用合并的多视图信息正确预测正确的姿态。为了展示模型的性能，我们提供了一个只能通过这种整体多视图方法解决的合成数据集，因为数据集中的姿态无法仅通过一个视图解决。我们的方法在我们的数据集上优于单视图和所有现有多视图方法，并在YCB-V数据集上取得了有竞争力的结果。据我们所知，目前还没有能够可靠解决此类姿态模糊问题的整体多视图方法。我们的模型是端到端可训练的，不需要任何额外数据，例如深度信息。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [183] [Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation](https://arxiv.org/abs/2507.04049)
> *打破模仿瓶颈：强化扩散驱动多样化轨迹生成*

*Ziying Song, Lin Liu, Hongyu Pan, Bencheng Liao, Mingzhe Guo, Lei Yang, Yongchang Zhang, Shaoqing Xu, Caiyan Jia, Yadan Luo* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 模仿学习, 强化学习, 扩散模型, 轨迹生成, 自动驾驶, 模式崩溃

**Comment:** 16 pages, 6 figures

> **TL;DR:** DIVER是一个结合强化学习和扩散模型的自动驾驶框架，旨在生成多样化且可行的轨迹，解决模仿学习中行为保守和模式崩溃的问题。

**AI_Comments:** DIVER的创新之处在于将强化学习与扩散模型相结合，解决了模仿学习在自动驾驶中生成保守和同质化轨迹的瓶颈。通过生成多样化轨迹并引入新的多样性评估指标，该工作在提高自动驾驶系统在复杂环境下的泛化能力和鲁棒性方面迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 大多数端到端自动驾驶方法依赖单一专家演示的模仿学习，导致行为保守、同质化，限制了在复杂真实场景中的泛化能力。

**Method:** 本文提出了DIVER，一个结合强化学习与扩散生成模型的端到端驾驶框架。首先，模型根据地图元素和周围智能体，从单一真实轨迹生成多个参考轨迹，以克服模仿学习的局限性。其次，利用强化学习引导扩散过程，通过奖励监督强制执行轨迹的安全性和多样性约束。此外，为解决L2基准开环度量在捕获轨迹多样性方面的局限性，提出了一种新颖的多样性度量来评估多模态预测的多样性。

**Result:** 在闭环NAVSIM和Bench2Drive基准测试以及开环nuScenes数据集上的大量实验表明，DIVER显著提高了轨迹多样性，有效解决了模仿学习固有的模式崩溃问题。

**Conclusion:** DIVER通过结合强化学习和扩散模型，成功地生成了多样化且可行的自动驾驶轨迹，有效解决了模仿学习中的模式崩溃问题，并提高了轨迹的实用性和泛化能力。

> **ai_Abstract:** DIVER是一个创新的端到端自动驾驶框架，它通过结合强化学习和扩散模型来克服传统模仿学习的局限性。该框架能够从单一专家演示中生成多样化的轨迹，并通过强化学习来确保轨迹的安全性和多样性。为准确评估多模态预测，DIVER还引入了一种新的多样性度量。实验证明，DIVER显著提升了轨迹多样性，有效解决了模仿学习中的模式崩溃问题。

> **摘要翻译:** 大多数端到端自动驾驶方法依赖于单一专家演示的模仿学习，通常导致保守和同质化的行为，从而限制了在复杂现实场景中的泛化能力。在这项工作中，我们提出了DIVER，一个将强化学习与基于扩散的生成相结合的端到端驾驶框架，以生成多样化且可行的轨迹。DIVER的核心在于一种强化的基于扩散的生成机制。首先，模型根据地图元素和周围智能体，从单一真实轨迹生成多个参考轨迹，从而缓解了仅依赖单一专家演示所产生的模仿学习局限性。其次，采用强化学习来引导扩散过程，其中基于奖励的监督对生成的轨迹强制执行安全性和多样性约束，从而增强了它们的实用性和泛化能力。此外，为了解决基于L2的开环度量在捕获轨迹多样性方面的局限性，我们提出了一种新颖的多样性度量来评估多模态预测的多样性。在闭环NAVSIM和Bench2Drive基准测试以及开环nuScenes数据集上的大量实验表明，DIVER显著提高了轨迹多样性，有效解决了模仿学习固有的模式崩溃问题。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [187] [4D Scaffold Gaussian Splatting with Dynamic-Aware Anchor Growing for Efficient and High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2411.17044)
> *具有动态感知锚点增长的4D支架高斯溅射：用于高效、高保真动态场景重建*

*Woong Oh Cho, In Cho, Seoha Kim, Jeongmin Bae, Youngjung Uh, Seon Joo Kim* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-05**

**Keywords:** 4D高斯溅射, 动态场景重建, 锚点框架, 存储效率, 神经4D高斯

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于4D锚点的高斯溅射框架，结合动态感知锚点增长策略，旨在高效、高保真地重建动态场景，同时解决存储开销问题并确保动态区域的质量。

**AI_Comments:** 该论文为动态场景的4D高斯溅射提供了一种创新方法，巧妙地平衡了存储效率和重建质量。它摒弃了简单减少高斯数量的策略，转而采用基于锚点的压缩机制和自适应增长策略，这相对于以往为效率牺牲质量的方法是一个显著进步，尤其是在复杂的动态区域。其中，“动态感知锚点增长”策略因其对目标区域的精准改进而尤为值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 通过4D高斯建模动态场景虽然能提供高视觉保真度和快速渲染速度，但存在显著的存储开销。现有方法通过减少高斯数量来降低成本，但这不可避免地损害了动态区域的渲染质量。本文旨在从不同角度解决存储成本问题，同时避免牺牲动态区域的重建质量。

**Method:** 本文引入了一种新颖的基于4D锚点的框架。该方法不减少高斯数量，而是保留足够的数量来精确建模动态内容，并将其压缩成紧凑的、网格对齐的4D锚点特征。每个锚点通过一个MLP生成一组神经4D高斯，这些高斯以最小参数捕获时间变化。此外，引入了动态感知锚点增长策略，通过调整高斯时间覆盖的累积梯度，有效地将额外锚点分配给重建不足的动态区域。

**Result:** 实验结果表明，该方法在动态区域实现了最先进的视觉质量，以实用的存储成本大幅超越了所有基线。

**Conclusion:** 本文提出的基于4D锚点的框架结合动态感知锚点增长策略，有效解决了4D高斯溅射的存储开销问题，同时在动态区域保持了高保真的重建质量。

> **ai_Abstract:** 本文提出了一种名为“4D支架高斯溅射”的新型框架，用于高效、高保真地重建动态场景。该方法通过将高斯压缩为紧凑的、网格对齐的4D锚点特征来解决4D高斯建模的存储开销问题，并利用MLP从这些锚点生成神经4D高斯。为提升动态区域的重建质量，论文还引入了一种动态感知锚点增长策略，智能地为这些区域分配额外锚点。实验结果表明，该方法在保持实用存储成本的同时，在动态区域实现了最先进的视觉质量。

> **摘要翻译:** 通过4D高斯建模动态场景具有高视觉保真度和快速渲染速度，但带来了显著的存储开销。最近的方法通过积极减少高斯数量来缓解这一成本。然而，这不可避免地移除了高质量渲染所需的高斯，导致动态区域的严重退化。在本文中，我们引入了一种新颖的基于4D锚点的框架，从不同角度解决存储成本问题。我们的方法没有减少高斯数量，而是保留了足够的数量来准确建模动态内容，同时将它们压缩成紧凑的、网格对齐的4D锚点特征。每个锚点都由一个MLP处理，以生成一组神经4D高斯，这些高斯代表一个局部时空区域。我们设计这些神经4D高斯以最小的参数捕获时间变化，使其非常适合基于MLP的生成。此外，我们引入了一种动态感知锚点增长策略，以有效地将额外的锚点分配给重建不足的动态区域。我们的方法通过高斯的时间覆盖来调整累积梯度，显著提高了动态区域的重建质量。实验结果表明，我们的方法在动态区域实现了最先进的视觉质量，以实用的存储成本大幅超越了所有基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [189] [Video Demoireing using Focused-Defocused Dual-Camera System](https://arxiv.org/abs/2508.03449)
> *使用聚焦-散焦双摄像头系统的视频去摩尔纹*

*Xuan Dong, Xiangyuan Sun, Xia Wang, Jian Song, Ya Li, Weixin Li* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 去摩尔纹, 双摄像头系统, 聚焦-散焦, 视频处理, 摩尔纹

**Comment:** 

> **TL;DR:** 提出了一种基于聚焦-散焦双摄像头系统的新型视频去摩尔纹方法，有效解决了现有方法的挑战并提高了性能。

**AI_Comments:** 这项工作的创新之处在于引入了双摄像头系统来解决去摩尔纹中的固有模糊性，即区分摩尔纹和真实纹理。通过利用散焦图像作为辅助信息，它提供了一种更鲁棒的解决方案。其重要性在于提升了视频去摩尔纹的质量，尤其是在保持时间连贯性和纹理细节方面，对于专业视频制作和消费级设备都有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单摄像头去摩尔纹方法面临两大挑战：1) 区分摩尔纹与真实纹理；2) 在去除摩尔纹的同时保持色调一致性和时间连贯性。

**Method:** 提出了一种双摄像头框架，同步捕获聚焦视频（可能含摩尔纹）和散焦视频（摩尔纹显著减少但纹理模糊）。利用散焦视频帮助区分摩尔纹与真实纹理，以指导聚焦视频的去摩尔纹。具体流程包括：基于光流的对齐步骤处理两路视频的位移和遮挡差异；然后，使用多尺度CNN和多维训练损失，利用对齐后的散焦帧引导聚焦帧的去摩尔纹；最后，通过联合双边滤波器利用CNN去摩尔纹结果作为引导来过滤输入聚焦帧，以保持色调和时间一致性。

**Result:** 实验结果表明，所提出的框架在很大程度上优于最先进的图像和视频去摩尔纹方法。

**Conclusion:** 该研究成功开发了一种创新的双摄像头去摩尔纹系统，有效解决了单摄像头方法的局限性，并实现了卓越的去摩尔纹性能，同时保持了图像质量和时间一致性。

> **ai_Abstract:** 本论文提出了一种新颖的基于聚焦-散焦双摄像头系统进行视频去摩尔纹的方法。针对现有单摄像头方法在区分摩尔纹与真实纹理以及保持色调和时间一致性方面的挑战，该系统通过同步捕获同一场景的聚焦和散焦视频，并利用散焦视频指导聚焦视频的去摩尔纹。其核心是逐帧处理流程，包括光流对齐、基于多尺度CNN和多维损失的引导去摩尔纹，以及用于保持一致性的联合双边滤波。实验证明，该方法显著优于现有技术。

> **摘要翻译:** 摩尔纹，图像和视频中不需要的颜色伪影，产生于空间高频场景内容与数码相机空间离散采样之间的干扰。现有的去摩尔纹方法主要依赖于单摄像头图像/视频处理，这面临两个关键挑战：1) 区分摩尔纹与视觉上相似的真实纹理，以及 2) 在去除摩尔纹伪影的同时保持色调一致性和时间连贯性。为了解决这些问题，我们提出了一种双摄像头框架，该框架捕获同一场景的同步视频：一个聚焦（保留高质量纹理但可能出现摩尔纹），一个散焦（摩尔纹显著减少但纹理模糊）。我们使用散焦视频帮助区分摩尔纹与真实纹理，从而指导聚焦视频的去摩尔纹。我们提出了一种逐帧去摩尔纹流水线，该流水线首先通过基于光流的对齐步骤来解决聚焦帧和散焦帧之间在位移和遮挡上的任何差异。然后，我们利用对齐后的散焦帧，使用多尺度CNN和多维训练损失来指导聚焦帧的去摩尔纹。为了保持色调和时间一致性，我们的最后一步涉及一个联合双边滤波器，利用CNN的去摩尔纹结果作为引导来过滤输入聚焦帧，以获得最终输出。实验结果表明，我们提出的框架在很大程度上优于最先进的图像和视频去摩尔纹方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [215] [NAMI: Efficient Image Generation via Bridged Progressive Rectified Flow Transformers](https://arxiv.org/abs/2503.09242)
> *NAMI：通过桥接渐进式修正流变换器实现高效图像生成*

*Yuhang Ma, Bo Cheng, Shanyuan Liu, Hongyi Zhou, Liebucha Wu, Xiaoyu Wu, Dawei Leng, Yuhui Yin* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像生成, 修正流, Transformer, 效率, 多分辨率训练

**Comment:** 

> **TL;DR:** NAMI提出了一种桥接渐进式修正流变换器，通过多分辨率训练和分段流生成，显著提高了图像生成效率并保持了高质量。

**AI_Comments:** NAMI的创新点在于其分解生成过程的策略，特别是在不同分辨率阶段使用不同数量的Transformer层以及引入BridgeFlow模块来连接这些阶段，这有效地平衡了效率和质量。其提出的NAMI-1K基准对于未来图像生成模型的评估也具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流基Transformer模型在图像生成方面性能卓越，但由于其庞大的参数量，通常会面临高推理延迟和计算成本。

**Method:** 本文提出了NAMI（Bridged Progressive Rectified Flow Transformers），通过在时间、空间和架构维度上分解图像生成过程。它将修正流根据分辨率划分为不同的阶段，并引入BridgeFlow模块来连接这些阶段。在低分辨率阶段使用较少Transformer层来生成图像布局和概念轮廓，并随着分辨率的增加逐步添加更多的层。NAMI还利用分段流和Diffusion Transformer (DiT) 的空间级联来加速图像生成。

**Result:** 实验表明，NAMI实现了快速收敛，并显著减少了推理时间（例如，生成1024分辨率图像的时间减少了64%），同时确保了高质量的生成效果。其模型性能与最先进的模型具有竞争力。此外，本文还提出了NAMI-1K基准来评估人类偏好性能，旨在减轻分布偏差并全面评估模型有效性。

**Conclusion:** NAMI通过创新的多分辨率训练和桥接流设计，成功解决了流基Transformer模型在图像生成中效率低下的问题，在保持高质量的同时大幅提升了图像生成速度。同时，提出的NAMI-1K基准对未来图像生成模型的评估具有重要意义。

> **ai_Abstract:** 本文提出了NAMI（Bridged Progressive Rectified Flow Transformers），旨在解决现有流基Transformer模型在图像生成中效率低下的问题。NAMI通过多分辨率训练、分阶段生成以及引入BridgeFlow模块来连接不同分辨率阶段的流，从而加速模型收敛并大幅减少推理时间（如1024分辨率图像生成时间减少64%），同时保持了高质量的生成效果。此外，文章还提出了NAMI-1K基准用于评估模型性能。实验证明NAMI与最先进模型具有竞争力。

> **摘要翻译:** 基于流的Transformer模型在图像生成方面取得了最先进的性能，但由于其庞大的参数量，通常会面临高推理延迟和计算成本。为了在不牺牲质量的情况下提高推理效率，我们提出了桥接渐进式修正流变换器（NAMI），它在时间、空间和架构维度上分解了生成过程。我们将修正流根据分辨率划分为不同的阶段，并使用BridgeFlow模块将它们连接起来。在低分辨率阶段使用较少的Transformer层来生成图像布局和概念轮廓，随着分辨率的增加逐渐添加更多的层。实验表明，我们的方法实现了快速收敛并减少了推理时间，同时确保了生成质量。本文的主要贡献总结如下：（1）我们引入了桥接渐进式修正流变换器，实现了多分辨率训练，加速了模型收敛；（2）NAMI利用分段流和Diffusion Transformer（DiT）的空间级联来快速生成图像，将1024分辨率图像的生成时间减少了64%；（3）我们提出了BridgeFlow模块来对齐不同阶段之间的流；（4）我们提出了NAMI-1K基准来评估人类偏好性能，旨在减轻分布偏差并全面评估模型有效性。结果表明我们的模型与最先进的模型具有竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [218] [VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction](https://arxiv.org/abs/2508.02890)
> *VisuCraft：通过结构化信息提取增强大型视觉语言模型用于复杂视觉引导创意内容生成*

*Rongxin Jiang, Robert Long, Chenghao Gu, Mingrui Yan* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-04**

**Keywords:** 大型视觉语言模型, 创意内容生成, 结构化信息提取, 动态提示, 视觉引导

**Comment:** 

> **TL;DR:** VisuCraft通过结构化信息提取和动态提示生成，显著提升了大型视觉语言模型在复杂视觉引导创意内容生成方面的能力，尤其在创造力和指令依从性方面表现出色。

**AI_Comments:** VisuCraft通过其独特的结构化信息提取和动态提示生成机制，有效解决了现有LVLMs在视觉保真度、创造力和指令依从性方面的不足。这种方法提供了一种提升LVLMs生成长篇创意文本质量的有效途径，对于推动视觉引导的AI内容创作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LVLMs在生成长篇文本时，难以保持高视觉保真度、真正的创造力以及精确遵循细微的用户指令。

**Method:** VisuCraft集成了一个多模态结构化信息提取器（E）和一个动态提示生成模块（G）。提取器将输入图像中的细粒度视觉属性提炼成丰富的结构化表示，然后动态提示模块将其与用户指令结合，为底层LVLMs（如LLaVA, InstructBLIP）创建高度优化的提示。

**Result:** VisuCraft在自建的ImageStoryGen-500K数据集上，使用VisuGen Metrics（视觉接地、创造力和指令依从性）进行评估，在故事生成和诗歌创作等任务中始终优于基线LVLMs，特别是在创造力和指令依从性方面取得了显著改进。

**Conclusion:** VisuCraft有效地生成了富有想象力、视觉接地且与用户对齐的长篇创意文本，为LVLMs在复杂的创意AI应用中解锁了新潜力。

> **ai_Abstract:** VisuCraft是一个新颖的框架，旨在通过引入多模态结构化信息提取器和动态提示生成模块，提升大型视觉语言模型在复杂视觉引导创意内容生成方面的能力。它能将图像中的细粒度视觉属性转化为结构化表示，并结合用户指令生成优化提示，从而使LVLMs在故事生成和诗歌创作等任务中，尤其在创造力和指令依从性方面，显著优于现有基线模型。

> **摘要翻译:** 本文介绍了VisuCraft，一个旨在显著增强大型视觉语言模型（LVLMs）在复杂视觉引导创意内容生成方面能力的新颖框架。现有的LVLMs在生成长篇文本时，往往在保持高视觉保真度、真正的创造力以及精确遵循细微的用户指令方面表现出局限性。VisuCraft通过集成多模态结构化信息提取器（E）和动态提示生成模块（G）来解决这些挑战。该提取器将输入图像中的细粒度视觉属性提炼成丰富的结构化表示，然后动态提示模块将其与用户指令结合，为底层LVLMs（例如LLaVA、InstructBLIP）创建高度优化的提示。在自建的ImageStoryGen-500K数据集上，使用VisuGen指标（视觉接地、创造力和指令依从性）进行评估，VisuCraft在故事生成和诗歌创作等任务中始终优于基线LVLMs。我们的结果表明，特别是在创造力和指令依从性方面有显著改进，验证了VisuCraft在生成富有想象力、视觉接地且与用户对齐的长篇创意文本方面的有效性。这项工作为LVLMs在复杂的创意AI应用中开启了新潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [219] [Contrastive Cross-Bag Augmentation for Multiple Instance Learning-based Whole Slide Image Classification](https://arxiv.org/abs/2508.03081)
> *用于多实例学习全玻片图像分类的对比跨包增强*

*Bo Zhang, Xu Xinan, Shuo Yan, Yu Bai, Zheng Zhang, Wufan Wang, Wendong Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多实例学习, 全玻片图像, 对比学习, 数据增强, 图像分类

**Comment:** 

> **TL;DR:** 本文提出了一种名为$C^2Aug$的对比跨包增强方法，以解决多实例学习（MIL）中伪包多样性受限的问题，并通过引入包级和组级对比学习框架来提高模型性能，在全玻片图像分类任务中优于现有SOTA方法。

**AI_Comments:** 该论文通过引入跨包增强和对比学习框架，有效解决了MIL在WSI分类中面临的关键挑战，即伪包多样性不足和关键实例分布不均导致的性能瓶颈。其创新点在于从多个包中采样实例以增加多样性，并利用对比学习提升特征判别力，这对于提高病理图像分析的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多实例学习（MIL）伪包增强方法从有限数量的包中采样实例，导致多样性受限。此外，引入新实例会增加伪包中关键实例（如肿瘤实例）的数量，从而减少包含少量关键实例的伪包的出现，限制了模型性能，尤其是在肿瘤区域较小的测试玻片上。

**Method:** 本文提出了对比跨包增强（$C^2Aug$），通过从所有具有相同类别的包中采样实例来增加伪包的多样性。为了解决关键实例增加导致性能下降的问题，研究者引入了一个包级和组级对比学习框架，以增强具有不同语义特征的判别能力，从而提高模型性能。

**Result:** 实验结果表明，$C^2Aug$在多个评估指标上始终优于最先进的方法。

**Conclusion:** 本文提出的对比跨包增强（$C^2Aug$）结合对比学习框架，有效解决了MIL中伪包多样性不足和关键实例过多导致性能受限的问题，显著提升了全玻片图像分类的性能。

> **ai_Abstract:** 本文提出了一种新颖的对比跨包增强（$C^2Aug$）方法，用于解决基于多实例学习（MIL）的全玻片图像（WSI）分类中伪包多样性不足的问题。$C^2Aug$通过从所有同类别的包中采样实例来增加伪包的多样性。针对新实例引入可能导致关键实例过多，从而限制模型性能（尤其是在小肿瘤区域）的问题，研究引入了一个包级和组级对比学习框架，以增强不同语义特征的判别力。实验证明，$C^2Aug$在多项评估指标上均超越了现有最先进的方法。

> **摘要翻译:** 最近用于多实例学习（MIL）全玻片图像（WSI）分类的伪包增强方法从有限数量的包中采样实例，导致多样性受限。为了解决这个问题，我们提出了对比跨包增强（$C^2Aug$），从所有同类别的包中采样实例，以增加伪包的多样性。然而，向伪包中引入新的实例会增加关键实例（例如肿瘤实例）的数量。这种增加导致包含少量关键实例的伪包出现频率降低，从而限制了模型性能，尤其是在肿瘤区域较小的测试玻片上。为了解决这个问题，我们引入了一个包级和组级对比学习框架，以增强具有不同语义特征的判别能力，从而提高模型性能。实验结果表明，$C^2Aug$在多个评估指标上始终优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [223] [3DRot: 3D Rotation Augmentation for RGB-Based 3D Tasks](https://arxiv.org/abs/2508.01423)
> *3DRot: 用于RGB-Based 3D任务的3D旋转增强*

*Shitian Yang, Deyu Li, Xiaoke Jiang, Lei Zhang* | **Category: cs.CV, cs.LG, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 3D旋转, 数据增强, RGB-based 3D任务, 单目3D检测, 几何一致性

**Comment:** 

> **TL;DR:** 3DRot是一个即插即用的数据增强方法，通过在相机空间进行几何一致的旋转和镜像变换，提升RGB-based 3D任务的性能，尤其在单目3D检测上表现出色。

**AI_Comments:** 3DRot的创新之处在于其“几何一致”的旋转和镜像增强，克服了传统图像变换破坏3D几何一致性的问题。其“即插即用”的特性和不依赖场景深度的优势使其具有很高的实用性和普适性，对于数据稀缺且标注昂贵的RGB-based 3D任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** RGB-based 3D任务（如3D检测、深度估计、3D关键点估计）面临数据稀缺、标注昂贵以及现有图像变换（如缩放、旋转）破坏几何一致性的问题。

**Method:** 本文引入了3DRot，一种即插即用的数据增强方法。它围绕相机光学中心旋转和镜像图像，同时同步更新RGB图像、相机内参、物体姿态和3D标注，以保持投影几何一致性，实现在不依赖任何场景深度的情况下进行几何一致的旋转和反射。它纯粹通过相机空间变换操作。

**Result:** 在SUN RGB-D数据集上，3DRot将单目3D检测的$IoU_{3D}$从43.21提高到44.51，将旋转误差(ROT)从22.91$^	ext{o}$降低到20.93$^	ext{o}$，并将$mAP_{0.5}$从35.70提高到38.11。与Cube R-CNN相比，3DRot在$IoU_{3D}$和$mAP_{0.5}$上的提升更显著。

**Conclusion:** 3DRot通过相机空间变换操作，易于迁移到其他3D任务。

> **ai_Abstract:** 本文提出了3DRot，一种用于RGB-based 3D任务的即插即用数据增强方法。该方法通过在相机空间对图像进行几何一致的旋转和镜像变换，并同步更新相关参数和标注，从而在不依赖深度信息的情况下保持投影几何一致性。实验证明，3DRot在单目3D检测任务中显著提升了性能，例如在SUN RGB-D数据集上提高了$IoU_{3D}$、降低了旋转误差并提升了$mAP_{0.5}$，且易于推广到其他3D任务。

> **摘要翻译:** RGB-based 3D任务，例如3D检测、深度估计、3D关键点估计，仍然面临数据稀缺、标注昂贵以及增强工具箱薄弱的问题，因为大多数图像变换，包括缩放和旋转，都会破坏几何一致性。在本文中，我们引入了3DRot，一种即插即用的增强方法，它围绕相机光学中心旋转和镜像图像，同时同步更新RGB图像、相机内参、物体姿态和3D标注，以保持投影几何一致性——实现在不依赖任何场景深度的情况下进行几何一致的旋转和反射。我们通过一个经典的3D任务——单目3D检测来验证3DRot。在SUN RGB-D数据集上，3DRot将$IoU_{3D}$从43.21提高到44.51，将旋转误差(ROT)从22.91$^	ext{o}$降低到20.93$^	ext{o}$，并将$mAP_{0.5}$从35.70提高到38.11。作为比较，Cube R-CNN结合SUN RGB-D以及其他3个数据集进行单目3D估计，采用类似的机制和测试数据集，将$IoU_{3D}$从36.2提高到37.8，将$mAP_{0.5}$从34.7提高到35.4。由于它纯粹通过相机空间变换操作，3DRot易于转移到其他3D任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness](https://arxiv.org/abs/2503.10624)
> *ETCH：通过等变紧密度将人体拟合推广到穿着衣物的人体*

*Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu* | **Category: cs.CV, cs.AI, cs.GR** | **Updated: 2025-08-04**

**Keywords:** 身体拟合, 穿着衣物人体, 等变性, 紧密度, 点云

**Comment:** Page: https://boqian-li.github.io/ETCH/, Code:
  https://github.com/boqian-li/ETCH

> **TL;DR:** ETCH是一种新方法，通过等变紧密度和内体标记拟合，显著提高了对穿着衣物人体进行身体拟合的准确性和泛化能力，尤其是在松散衣物和零样本设置下。

**AI_Comments:** 这篇论文的创新点在于提出了“等变紧密度”的概念，并将其巧妙地整合到身体拟合流程中，通过SE(3)等变性来处理布料与身体的复杂关系，并将其简化为内体标记拟合任务。这种方法有效地解决了传统方法对初始化敏感和学习方法泛化能力差的问题，尤其是在处理松散衣物和应对分布外数据时的优异表现，显示了其重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在对3D穿着衣物人体点云进行身体拟合时存在挑战：传统的优化方法对姿态初始化敏感，而最近基于学习的方法在不同姿态和服装类型上的泛化能力较差。

**Method:** 提出ETCH（Equivariant Tightness Fitting for Clothed Humans），一个新颖的流程。它通过局部近似SE(3)等变性估计布料到身体的表面映射，将紧密度编码为从布料表面到底层身体的位移向量。在此映射之后，姿态不变的身体特征回归稀疏身体标记，从而将穿着衣物的人体拟合简化为内体标记拟合任务。

**Result:** 在CAPE和4D-Dress数据集上，ETCH显著优于现有SOTA方法。在松散衣物上的身体拟合精度提高16.7% ~ 69.5%，形状精度平均提高49.9%。在一次性（或分布外）设置（约1%数据）下，等变紧密度设计可将方向误差降低67.2% ~ 89.8%。定性结果表明ETCH在具有挑战性的姿态、未见形状、宽松衣物和非刚性动态方面具有强大的泛化能力。

**Conclusion:** ETCH通过引入等变紧密度设计和将拟合任务简化为内体标记拟合，显著提高了对穿着衣物人体进行身体拟合的准确性和泛化能力，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出ETCH，一种新颖的穿着衣物人体身体拟合方法，通过引入局部近似SE(3)等变性来建模布料与身体之间的紧密度，并将其转化为位移向量。该方法将复杂的身体拟合任务简化为内体标记拟合，利用姿态不变的身体特征回归稀疏标记。实验结果表明，ETCH在身体拟合精度和形状精度上显著超越现有方法，尤其在处理松散衣物和零样本泛化方面表现出色，展现了其强大的泛化能力。

> **摘要翻译:** 将身体拟合到3D穿着衣物的人体点云是一项常见但具有挑战性的任务。传统的基于优化的方法使用多阶段流程，对姿态初始化敏感，而最近基于学习的方法通常难以在不同姿态和服装类型之间泛化。我们提出了一种新颖的流程，名为ETCH（Equivariant Tightness Fitting for Clothed Humans），它通过局部近似SE(3)等变性估计布料到身体的表面映射，将紧密度编码为从布料表面到底层身体的位移向量。在此映射之后，姿态不变的身体特征回归稀疏身体标记，从而将穿着衣物的人体拟合简化为内体标记拟合任务。在CAPE和4D-Dress上的大量实验表明，ETCH在松散衣物上的身体拟合精度（16.7% ~ 69.5%）和形状精度（平均49.9%）方面显著优于最先进的方法——无论是紧密度无关还是紧密度感知的。我们的等变紧密度设计甚至可以在一次性（或分布外）设置（约1%数据）中将方向误差减少（67.2% ~ 89.8%）。定性结果表明ETCH具有强大的泛化能力，无论面对挑战性姿态、未见形状、宽松衣物和非刚性动态。我们很快将在https://boqian-li.github.io/ETCH/发布代码和模型以供研究使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [230] [Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging](https://arxiv.org/abs/2504.02480)
> *图注意力驱动的贝叶斯深度展开用于双峰单光子激光雷达成像*

*Kyungmin Choi, JaKeoung Koo, Stephen McLaughlin, Abderrahim Halimi* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 单光子激光雷达, 深度展开, 贝叶斯模型, 双峰成像, 几何深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种用于双峰单光子激光雷达成像的深度展开算法，结合了统计方法和深度学习方法的优点，以应对多目标和噪声环境下的挑战，并在合成和真实数据上表现出竞争力，同时提供不确定性信息。

**AI_Comments:** 该论文的创新点在于将深度展开网络与层次贝叶斯模型相结合，并引入图注意力机制处理多目标和双峰数据，从而在保证高精度的同时，提供了传统深度学习方法所缺乏的不确定性量化能力。这对于单光子激光雷达在复杂场景下的应用具有重要意义，因为它解决了现有方法在解释性和多目标处理上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 单光子激光雷达成像在高分辨率和长距离方面具有显著优势，但在噪声环境和每像素多目标场景中应用面临挑战。现有统计方法解释性强但处理复杂场景能力有限，深度学习方法精度高但缺乏解释性或仅限于每像素单峰。

**Method:** 本文提出了一种用于双峰单光子激光雷达成像的深度展开算法。引入了一个用于多目标的层次贝叶斯模型，并提出了一个展开底层统计方法的神经网络。为支持多目标，采用了双深度图表示，并利用几何深度学习从点云中提取特征。

**Result:** 实验结果表明，与现有方法相比，所提出的方法在合成和真实数据上均表现出竞争力，同时还提供了不确定性信息。

**Conclusion:** 本文提出的方法结合了统计方法和学习方法的优点，在准确性和量化不确定性方面表现出色，有效解决了单光子激光雷达在多目标和噪声环境下的成像挑战。

> **ai_Abstract:** 本文提出了一种图注意力驱动的贝叶斯深度展开算法，专门用于解决双峰单光子激光雷达在噪声和多目标环境下的成像挑战。该方法通过引入一个层次贝叶斯模型和一个展开统计方法的神经网络，并结合双深度图表示和几何深度学习，有效融合了统计方法的可解释性和深度学习的优异性能，能够同时提供高精度成像和不确定性量化。实验证明其在合成和真实数据上均优于现有方法。

> **摘要翻译:** 单光子激光雷达成像由于其高分辨率和远距离能力，在3D成像中具有显著优势，但在每像素多个目标的噪声环境中应用具有挑战性。为了应对这些挑战，已经提出了几种方法。统计方法在推断参数方面表现出可解释性，但它们在处理复杂场景的能力方面往往受到限制。基于深度学习的方法在准确性和鲁棒性方面表现出卓越的性能，但它们缺乏可解释性或仅限于每像素单峰。在本文中，我们提出了一种用于双峰单光子激光雷达成像的深度展开算法。我们引入了一个用于多目标的层次贝叶斯模型，并提出了一个展开底层统计方法的神经网络。为了支持多个目标，我们采用了双深度图表示并利用几何深度学习从点云中提取特征。所提出的方法在准确性和量化不确定性方面充分利用了统计方法和基于学习方法的优势。在合成和真实数据上的实验结果表明，与现有方法相比，该方法具有竞争力，同时还提供了不确定性信息。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [244] [Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution](https://arxiv.org/abs/2508.03244)
> *超轻型极性分离神经形态SNN用于事件流超分辨率*

*Chuanzhi Xu, Haoxian Zhou, Langyi Chen, Yuk Ying Chung, Qiang Qu* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 事件相机, 超分辨率, 脉冲神经网络（SNNs）, 轻量级, 实时

**Comment:** 

> **TL;DR:** 提出一种基于SNN的超轻量级事件流超分辨率方法，适用于资源受限设备。

**AI_Comments:** 该论文的创新之处在于将脉冲神经网络（SNNs）应用于事件流超分辨率，并引入了新颖的极性分离编码和可学习的损失函数。其超轻量级设计对于在边缘设备上实现实时部署以及作为高效的预处理步骤至关重要，有效解决了事件相机的一个关键局限性。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机虽然具有高时间分辨率、低延迟和高动态范围的优势，但其有限的空间分辨率对细粒度感知任务构成了挑战。

**Method:** 本文提出了一种基于脉冲神经网络（SNNs）的超轻量级、基于流的事件到事件超分辨率方法。为减小模型尺寸，引入了新颖的双前向极性分离事件编码策略，通过共享SNN将正负事件解耦到单独的前向路径。此外，还提出了一种可学习的时空极性感知损失（LearnSTPLoss），利用可学习的基于不确定性的权重自适应平衡时间、空间和极性一致性。

**Result:** 实验结果表明，该方法在多个数据集上实现了有竞争力的超分辨率性能，同时显著减小了模型尺寸和推理时间。

**Conclusion:** 该方法的轻量化设计使其能够嵌入到事件相机中，或作为下游视觉任务的有效前端预处理。

> **ai_Abstract:** 本文提出了一种基于脉冲神经网络（SNNs）的超轻量级事件到事件超分辨率方法，旨在解决事件相机空间分辨率有限的问题。为实现实时部署于资源受限设备，该方法引入了双前向极性分离事件编码策略和可学习的时空极性感知损失（LearnSTPLoss）。实验证明，该方法在保持竞争性超分辨率性能的同时，显著减小了模型尺寸和推理时间，使其适用于事件相机内嵌或作为下游视觉任务的有效预处理。

> **摘要翻译:** 事件相机具有高时间分辨率、低延迟和高动态范围等无与伦比的优势。然而，其有限的空间分辨率对细粒度感知任务提出了挑战。在这项工作中，我们提出了一种基于脉冲神经网络（SNNs）的超轻量级、基于流的事件到事件超分辨率方法，旨在实时部署在资源受限设备上。为了进一步减小模型尺寸，我们引入了一种新颖的双前向极性分离事件编码策略，该策略通过共享SNN将正负事件解耦到单独的前向路径中。此外，我们提出了一种可学习的时空极性感知损失（LearnSTPLoss），该损失使用可学习的基于不确定性的权重自适应地平衡时间、空间和极性一致性。实验结果表明，我们的方法在多个数据集上实现了有竞争力的超分辨率性能，同时显著减小了模型尺寸和推理时间。其轻量化设计使得该模块能够嵌入到事件相机中，或作为下游视觉任务的有效前端预处理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [Forecasting When to Forecast: Accelerating Diffusion Models with Confidence-Gated Taylor](https://arxiv.org/abs/2508.02240)
> *预测何时预测：使用置信度门控泰勒加速扩散模型*

*Xiaoliu Guan, Lielin Jiang, Hanqi Chen, Xu Zhang, Jiaxing Yan, Guanzhong Wang, Yi Liu, Zetao Zhang, Yu Wu* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 加速, 泰勒展开, 动态缓存, 推理速度

**Comment:** 15 pages, 4 figures

> **TL;DR:** 本文提出了一种新的置信度门控泰勒方法来加速扩散模型，通过动态缓存和减少缓存特征来提高推理速度并保持生成质量。

**AI_Comments:** 本文的创新点在于优化了基于泰勒展开的扩散模型加速方法，通过将预测目标从模块级别提升到块级别，并引入了基于置信度的动态缓存机制。这种方法有效地解决了现有泰勒加速方案中内存开销大和固定缓存策略导致质量下降的问题，使得扩散模型在资源受限的环境下更具实用性。利用早期块的误差来判断后期块预测的可靠性是一个巧妙的设计。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer（DiTs）在视觉生成任务中表现出色，但其推理速度慢，限制了在低资源应用中的部署。现有的基于泰勒展开的加速方法（如TaylorSeer）存在模块级预测导致的内存和计算开销大、以及固定缓存策略不考虑预测准确性变化导致质量下降的问题。

**Method:** 我们提出了一种新的方法来更好地利用基于泰勒的加速。首先，将泰勒预测目标从模块级别转移到最后一个块级别，显著减少了缓存特征的数量。其次，观察到Transformer块之间存在强烈的序列依赖性，我们提出使用第一个块的泰勒估计输出与实际输出之间的误差作为预测可靠性的指标。如果误差很小，则信任最后一个块的泰勒预测；否则，退回到完全计算，从而实现了动态缓存机制。

**Result:** 我们的方法在FLUX上实现了3.17倍的加速，在DiT上实现了2.36倍的加速，在Wan Video上实现了4.14倍的加速，同时质量下降可以忽略不计。

**Conclusion:** 我们提出的方法在速度和质量之间取得了更好的平衡，有效地加速了扩散模型的推理过程。

> **ai_Abstract:** 本文针对扩散Transformer（DiTs）在视觉生成中推理速度慢的问题，提出了一种名为“置信度门控泰勒”的新型加速方法。该方法优化了基于泰勒展开的加速技术，将预测目标从细粒度的模块级别转移到最后一个块级别，从而显著减少了缓存特征和计算开销。此外，通过利用Transformer块之间的序列依赖性，作者引入了一个动态缓存机制：使用第一个块的泰勒预测误差作为可靠性指标，当误差小时信任泰勒预测，否则回退到完全计算。实验结果表明，该方法在保持图像生成质量的同时，实现了显著的推理加速，例如在FLUX上加速3.17倍，在DiT上加速2.36倍，在Wan Video上加速4.14倍。

> **摘要翻译:** 扩散Transformer（DiTs）在视觉生成任务中表现出卓越的性能。然而，其较低的推理速度限制了它们在低资源应用中的部署。最近的免训练方法通过缓存和重用过去表示来利用时间步长之间特征的冗余性以加速推理。在此基础上，TaylorSeer反过来通过泰勒展开利用缓存特征来预测未来的特征。然而，它在所有Transformer块（例如，注意力或前馈模块）上的模块级预测需要存储细粒度的中间特征，导致显著的内存和计算开销。此外，它采用固定的缓存策略，没有考虑不同时间步长预测的准确性变化，这可能在预测失败时导致输出质量下降。为了解决这些限制，我们提出了一种新的方法来更好地利用基于泰勒的加速。首先，我们将泰勒预测目标从模块级别转移到最后一个块级别，显著减少了缓存特征的数量。此外，观察到Transformer块之间存在强烈的序列依赖性，我们提出使用第一个块的泰勒估计输出与实际输出之间的误差作为预测可靠性的指标。如果误差很小，我们信任最后一个块的泰勒预测；否则，我们退回到完全计算，从而实现了动态缓存机制。经验结果表明，我们的方法在速度和质量之间取得了更好的平衡，在FLUX上实现了3.17倍的加速，在DiT上实现了2.36倍的加速，在Wan Video上实现了4.14倍的加速，同时质量下降可以忽略不计。项目页面在这里：\href{https://cg-taylor-acce.github.io/CG-Taylor/}{这里。}

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [Decouple and Track: Benchmarking and Improving Video Diffusion Transformers for Motion Transfer](https://arxiv.org/abs/2503.17350)
> *解耦与跟踪：视频扩散变换器在动作迁移中的基准测试与改进*

*Qingyu Shi, Jianzong Wu, Jinbin Bai, Jiangning Zhang, Lu Qi, Yunhai Tong, Xiangtai Li* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 动作迁移, 视频扩散变换器, 运动解耦, 时间核, 基准测试

**Comment:** ICCV 2025

> **TL;DR:** 本文提出DeT方法改进视频扩散变换器（DiT）的动作迁移能力，通过时间核和轨迹监督实现运动与外观解耦，并引入MTBench基准和混合运动保真度指标进行更全面的评估。

**AI_Comments:** 这篇论文通过引入特定的时间处理模块和显式运动监督，巧妙地解决了视频扩散变换器在动作迁移中运动与外观解耦的难题。同时，提出新的基准和评估指标，对于推动该领域的研究和提供更严谨的评估框架具有重要意义。其创新点在于对DiT模型的针对性改进和全面的评估体系构建。

<details>
  <summary>Details</summary>

**Motivation:** 动作迁移任务需要模型解耦运动与外观。现有的视频扩散变换器（DiT）模型使用3D全注意力，不明确分离时空信息，导致运动与外观解耦更具挑战性。

**Method:** 提出DeT方法，通过引入一个简单有效的时间核来平滑DiT特征的时间维度，促进前景运动与背景外观的解耦，并捕获运动相关的时间变化。此外，在潜在特征空间中引入沿密集轨迹的显式监督以增强运动一致性。同时，提出MTBench作为动作迁移的通用且具有挑战性的基准，并引入考虑全局和局部运动相似性的混合运动保真度指标。

**Result:** 在MTBench上的大量实验表明，DeT在运动保真度和编辑保真度之间实现了最佳权衡。

**Conclusion:** DeT方法有效提高了视频扩散变换器在动作迁移任务中的表现，并提供了更全面的评估基准和指标，为该领域的研究提供了新方向。

> **ai_Abstract:** 本文针对视频扩散变换器（DiT）在动作迁移任务中难以解耦运动与外观的问题，提出了DeT方法。DeT通过引入时间核来平滑DiT特征并捕获时间变化，以及在潜在空间中进行密集轨迹监督，以增强运动一致性并促进运动与外观的解耦。为全面评估，作者还构建了MTBench基准和一个混合运动保真度指标。实验证明DeT在运动和编辑保真度之间取得了最佳平衡。

> **摘要翻译:** 动作迁移任务旨在将运动从源视频转移到新生成的视频中，这要求模型将运动与外观解耦。以前基于扩散的方法主要依赖于3D U-Net中独立的空间和时间注意力机制。相比之下，最先进的视频扩散变换器（DiT）模型使用3D全注意力，其不明确分离时间和空间信息。因此，空间和时间维度之间的相互作用使得DiT模型解耦运动和外观更具挑战性。在本文中，我们提出了DeT，一种适应DiT模型以提高动作迁移能力的方法。我们的方法引入了一个简单而有效的时间核，用于沿时间维度平滑DiT特征，从而促进前景运动与背景外观的解耦。同时，时间核有效地捕获了DiT特征中的时间变化，这些变化与运动密切相关。此外，我们在潜在特征空间中引入沿密集轨迹的显式监督，以进一步增强运动一致性。此外，我们提出了MTBench，一个通用且具有挑战性的动作迁移基准。我们还引入了一种混合运动保真度指标，该指标同时考虑了全局和局部运动相似性。因此，我们的工作提供了比以前工作更全面的评估。MTBench上的大量实验表明，DeT在运动保真度和编辑保真度之间实现了最佳权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [259] [Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts](https://arxiv.org/abs/2508.03094)
> *利用LLM生成的视觉概念增强疾病的持续学习*

*Jiantao Tan, Peixian Ma, Kanghao Chen, Zhiming Dai, Ruixuan Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 持续学习, 大型语言模型, 视觉概念, 医疗图像分类, 跨模态注意力

**Comment:** 

> **TL;DR:** 该研究提出一种新框架，利用大型语言模型（LLM）生成的视觉概念作为语义指导，通过跨模态注意力机制增强医疗图像分类系统的持续学习能力，并取得了最先进的性能。

**AI_Comments:** 该研究的创新点在于将LLM生成的丰富视觉概念引入持续学习，弥补了现有方法在语义利用上的不足。通过动态概念池和跨模态注意力机制，有效提升了模型在动态环境下的适应性和分类性能，对于医疗图像诊断等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医疗图像分类系统需要持续学习以适应动态变化的临床环境。现有方法虽然利用文本模态信息，但仅依赖简单的类别名称模板，忽略了更丰富的语义信息，限制了多模态信息在持续学习中的潜力。

**Method:** 提出一个新颖的框架，利用大型语言模型（LLM）生成的视觉概念作为判别性语义指导。该方法动态构建一个视觉概念池，并通过基于相似度的过滤机制防止冗余。随后，采用一个跨模态图像-概念注意力模块，并结合注意力损失，将概念整合到持续学习过程中，从而利用相关视觉概念的语义知识生成具有类别代表性的融合特征进行分类。

**Result:** 在医学和自然图像数据集上的实验表明，该方法取得了最先进的性能。

**Conclusion:** 该研究提出的利用LLM生成视觉概念增强持续学习的方法有效且优越，显著提升了医疗图像分类系统的适应性和性能。

> **ai_Abstract:** 本文提出一个新颖的框架，旨在通过利用大型语言模型（LLM）生成的视觉概念来增强医疗图像分类系统的持续学习能力。针对现有方法在利用多模态信息时忽略丰富语义的不足，该框架动态构建视觉概念池并采用跨模态图像-概念注意力模块，以整合语义知识并生成有代表性的特征。实验证明，该方法在医学和自然图像数据集上均达到了最先进的性能。

> **摘要翻译:** 持续学习对于医疗图像分类系统适应动态变化的临床环境至关重要。多模态信息的整合可以显著增强图像类别的持续学习。然而，现有方法虽然确实利用文本模态信息，但它们仅依赖于带有类别名称的简单模板，从而忽略了更丰富的语义信息。为了解决这些限制，我们提出了一种新颖的框架，该框架利用大型语言模型（LLM）生成的视觉概念作为判别性语义指导。我们的方法通过基于相似度的过滤机制动态构建一个视觉概念池，以防止冗余。然后，为了将这些概念整合到持续学习过程中，我们采用了一个跨模态图像-概念注意力模块，并辅以注意力损失。通过注意力机制，该模块可以利用来自相关视觉概念的语义知识，并生成具有类别代表性的融合特征进行分类。在医学和自然图像数据集上的实验表明，我们的方法取得了最先进的性能，证明了我们方法的有效性和优越性。我们将公开发布代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [269] [AVPDN: Learning Motion-Robust and Scale-Adaptive Representations for Video-Based Polyp Detection](https://arxiv.org/abs/2508.03458)
> *AVPDN: 学习运动鲁棒和尺度自适应的表示用于基于视频的息肉检测*

*Zilin Chen, Shengnan Lu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视频息肉检测, 运动鲁棒性, 尺度自适应, 深度学习, 结肠镜视频

**Comment:** 

> **TL;DR:** AVPDN是一种针对结肠镜视频中息肉检测的鲁棒框架，它通过自适应特征交互与增强和尺度感知上下文集成模块来处理快速相机运动和多尺度特征集成问题。

**AI_Comments:** AVPDN通过其创新的双模块设计，即AFIA和SACI，有效地解决了视频息肉检测中运动鲁棒性和尺度自适应性的关键挑战。AFIA结合了密集和稀疏自注意力以及通道混洗，旨在优化特征表示和信息交流，而SACI则通过多尺度空洞卷积提升了上下文感知和去噪能力。这种方法对于提高结肠镜视频诊断的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 结直肠癌的早期和中期诊断中，准确检测息肉至关重要。与静态图像相比，动态结肠镜视频提供更全面的视觉信息，但快速的相机运动引入大量背景噪声，扰乱场景结构完整性并增加假阳性风险。为解决这些挑战，本文提出了AVPDN。

**Method:** 本文提出了自适应视频息肉检测网络（AVPDN），一个用于结肠镜视频中多尺度息肉检测的鲁棒框架。AVPDN包含两个关键组件：自适应特征交互与增强（AFIA）模块和尺度感知上下文集成（SACI）模块。AFIA模块采用三分支架构，通过密集自注意力进行全局上下文建模，稀疏自注意力减少低查询-键相似性影响，以及通道混洗操作促进分支间信息交换。SACI模块利用具有不同感受野的空洞卷积，在多个空间尺度捕获上下文信息，以增强多尺度特征集成和模型去噪能力。

**Result:** 在几个具有挑战性的公共基准上进行的实验表明，所提出的方法在基于视频的息肉检测任务中表现出有效性和泛化能力，并取得了有竞争力的性能。

**Conclusion:** 本文提出的AVPDN通过其特有的AFIA和SACI模块，有效解决了结肠镜视频中快速相机运动导致的噪声和多尺度息肉检测的挑战，并在公共基准上取得了有竞争力的性能，证明了其有效性和泛化能力。

> **ai_Abstract:** 本文提出了一种名为AVPDN的自适应视频息肉检测网络，旨在解决结肠镜视频中因快速相机运动导致的背景噪声和多尺度息肉检测的挑战。AVPDN包含两个核心模块：AFIA用于增强特征表示和处理上下文建模，SACI用于加强多尺度特征集成和提高去噪能力。实验结果表明，该方法在公共基准上表现出良好的有效性和泛化能力。

> **摘要翻译:** 准确检测息肉对于结直肠癌的早期和中期诊断至关重要。与静态图像相比，动态结肠镜视频提供了更全面的视觉信息，这有助于制定有效的治疗方案。然而，与固定摄像机录像不同，结肠镜视频通常表现出快速的摄像机移动，引入大量背景噪声，扰乱了场景的结构完整性并增加了假阳性的风险。为了应对这些挑战，我们提出了自适应视频息肉检测网络（AVPDN），这是一个用于结肠镜视频中多尺度息肉检测的鲁棒框架。AVPDN包含两个关键组件：自适应特征交互与增强（AFIA）模块和尺度感知上下文集成（SACI）模块。AFIA模块采用三分支架构以增强特征表示。它采用密集自注意力进行全局上下文建模，稀疏自注意力以减轻特征聚合中低查询-键相似性的影响，以及通道混洗操作以促进分支间的信息交换。同时，SACI模块旨在加强多尺度特征集成。它利用具有不同感受野的空洞卷积来捕获多个空间尺度的上下文信息，从而提高模型的去噪能力。在几个具有挑战性的公共基准上进行的实验证明了所提出方法的有效性和泛化能力，在基于视频的息肉检测任务中取得了有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation](https://arxiv.org/abs/2508.02903)
> *RDDPM：用于无监督异常分割的鲁棒去噪扩散概率模型*

*Mehrdad Moradi, Kamran Paynabar* | **Category: cs.CV, 68T07, I.4.9; I.2.10** | **Updated: 2025-08-04**

**Keywords:** 鲁棒扩散模型, 异常分割, 无监督学习, 受污染数据, 去噪扩散概率模型

**Comment:** 10 pages, 5 figures. Accepted to the ICCV 2025 Workshop on
  Vision-based Industrial InspectiON (VISION)

> **TL;DR:** 提出RDDPM，一种鲁棒的去噪扩散模型，用于在仅有受污染（正常和异常混合）数据的情况下进行无监督异常分割，性能优于现有SOTA。

**AI_Comments:** 该论文的创新点在于提出了RDDPM，解决了扩散模型在无监督异常分割中对纯净训练数据的依赖问题，使其在实际应用中更具可行性。通过将最大似然估计重新解释为鲁棒回归问题，为扩散模型的鲁棒性提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型在无监督异常分割中表现出色，但它们通常需要纯净的正常数据进行训练，这限制了它们在实际应用中的可行性。

**Method:** 提出RDDPM，通过将数据最大似然估计转化为非线性回归问题，并利用鲁棒回归方法，重新解释并推导出鲁棒的去噪扩散概率模型，使其能够在只有受污染的未标记数据的情况下进行训练。

**Result:** 该方法在仅有受污染数据时，在无监督异常分割方面优于当前最先进的扩散模型，在MVTec数据集上，AUROC提高了8.08%，AUPRC提高了10.37%。

**Conclusion:** RDDPM成功解决了扩散模型在训练数据受污染时的局限性，并在无监督异常分割任务中取得了显著的性能提升。

> **ai_Abstract:** 本文提出了RDDPM，一种鲁棒去噪扩散概率模型，旨在解决现有扩散模型在无监督异常分割中需要纯净正常数据训练的局限性。RDDPM通过将数据最大似然估计重新解释为非线性回归问题，并结合鲁棒回归，使其能够在仅有受污染（正常与异常混合）的未标记数据环境下进行训练。实验结果表明，RDDPM在受污染数据场景下的无监督异常分割性能显著优于现有SOTA扩散模型，在MVTec数据集上AUROC和AUPRC分别提高了8.08%和10.37%。

> **摘要翻译:** 去噪扩散模型在无监督异常分割方面取得了显著成功。对于异常分割，这些模型首先在正常数据上进行训练；然后，异常图像被噪声化到一个中间步骤，并通过反向扩散重建正常图像。与传统统计方法不同，扩散模型不依赖于数据或目标异常的特定假设，使其适用于不同领域。然而，扩散模型通常假设可以获取正常数据进行训练，这限制了它们在实际场景中的适用性。在本文中，我们提出了一种新颖的鲁棒去噪扩散模型，用于仅有受污染（即正常和异常混合）未标记数据可用的情况。通过将数据最大似然估计转化为非线性回归问题，我们通过回归视角重新解释了去噪扩散概率模型。利用鲁棒回归，我们推导出了去噪扩散概率模型的鲁棒版本。我们新颖的框架为构建各种鲁棒扩散模型提供了灵活性。我们的实验表明，当只有受污染数据可用时，我们的方法在无监督异常分割方面优于当前最先进的扩散模型。我们的方法优于现有的基于扩散的方法，在MVTec数据集上，AUROC提高了8.08%，AUPRC提高了10.37%。实现代码可在以下网址获取：https://github.com/mehrdadmoradi124/RDDPM。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning](https://arxiv.org/abs/2503.21055)
> *什么改变了，什么可能改变？面向过程感知视频表征学习的状态变化反事实*

*Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 过程感知视频, 状态变化, 反事实, 大型语言模型, 视频表征学习

**Comment:** 16 pages, 4 figures

> **TL;DR:** 该论文通过整合大型语言模型生成的状态变化描述和状态变化反事实，改进了面向过程的视频表征学习，并在多项任务上取得了显著提升。

**AI_Comments:** 该论文的创新点在于首次将LLMs引入到过程感知视频理解领域，利用其生成状态变化描述和反事实来作为监督信号。特别是引入“状态变化反事实”来模拟假设的失败场景，使得模型能够学习因果关系和“如果...会怎样”的推理能力，这对于提升模型对复杂程序性活动的理解具有重要意义。该方法在多项任务上的显著改进也证明了其有效性和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作在过程感知视频表征学习中主要关注动作的时间顺序，但未能明确学习场景变换（即状态变化）。为了更深入地理解程序性活动，需要模型化动作步骤如何改变场景以及场景变化如何影响动作序列，包括偶然或错误的动作。

**Method:** 本研究通过将大型语言模型（LLMs）生成的状态变化描述作为视频编码器的监督信号，来学习过程感知的视频表征。此外，通过生成模拟假设失败结果的状态变化反事实，让模型通过想象未见的“如果...会怎样”场景进行学习，这种反事实推理有助于模型理解活动中每一步的因果关系。

**Result:** 在时间动作分割、错误检测、动作阶段分类、帧检索、多实例检索和动作识别等过程感知任务上进行了广泛实验。结果表明，所提出的状态变化描述及其反事实是有效的，并在多项任务上取得了显著改进。

**Conclusion:** 通过整合LLM生成的状态变化描述和状态变化反事实，可以有效提升模型对过程感知视频的理解能力，并在多种相关任务上取得显著性能提升。

> **ai_Abstract:** 该研究旨在通过引入大型语言模型（LLMs）生成的状态变化描述和状态变化反事实，改进过程感知视频表征学习。与以往仅关注动作时间顺序的方法不同，本文方法明确学习场景变换及其因果关系。实验结果表明，该方法在多种过程感知任务上均取得了显著提升，验证了状态变化描述和反事实的有效性。

> **摘要翻译:** 理解一项程序性活动需要对动作步骤如何改变场景进行建模，以及不断演变的场景变化如何影响动作步骤序列，即使是偶然或错误的步骤。现有工作通过建模动作的时间顺序来研究过程感知视频表征，但尚未明确学习状态变化（场景转换）。在本工作中，我们通过将大型语言模型（LLMs）生成的状态变化描述作为视频编码器的监督信号，来研究过程感知视频表征学习。此外，我们生成了模拟假设失败结果的状态变化反事实，允许模型通过想象未见的“如果...会怎样”场景进行学习。这种反事实推理有助于模型理解活动中每一步的因果关系。我们在过程感知任务上进行了广泛实验，包括时间动作分割、错误检测、动作阶段分类、帧检索、多实例检索和动作识别。我们的结果证明了所提出的状态变化描述及其反事实的有效性，并在多项任务上取得了显著改进。代码可在https://github.com/HCIS-Lab/counterfactual-video-pretrain 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [284] [DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition](https://arxiv.org/abs/2508.03397)
> *DepthGait：RGB导出的深度和轮廓序列的多尺度跨层次特征融合，实现鲁棒步态识别*

*Xinzhu Li, Juepeng Zheng, Yikun Chen, Xudong Mao, Guanghui Yue, Wei Zhou, Chenlei Lv, Ruomei Wang, Fan Zhou, Baoquan Zhao* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-05**

**Keywords:** 步态识别, 深度图, 轮廓, 特征融合, RGB

**Comment:** 

> **TL;DR:** DepthGait框架通过融合RGB导出的深度图和轮廓序列，并采用多尺度跨层次特征融合方案，显著提升了步态识别的鲁棒性和准确性。

**AI_Comments:** 该论文的创新点在于引入了RGB导出的深度图作为步态识别的新模态，有效弥补了传统2D轮廓和骨架在捕捉三维信息和细节方面的不足。同时，提出的多尺度跨层次特征融合方案有效地融合了不同模态的特征，提升了识别的鲁棒性。这对于在复杂环境中实现更准确的步态识别具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的步态识别方法主要依赖于二进制轮廓和骨架等2D表示，但这些表示不足以捕获处理视角变化所需的足够线索，也无法捕捉步态的更精细和有意义的细节，导致鲁棒性不足。

**Method:** 本文提出了一种名为DepthGait的新颖框架，它结合了RGB图像序列导出的深度图和轮廓序列进行步态识别。该方法不仅使用2D轮廓表示，还显式地从RGB图像序列估计深度图作为新的模态，以捕获人体运动中固有的判别性特征。此外，还开发了一种新颖的多尺度和跨层次融合方案，以弥合深度图和轮廓之间的模态差异。

**Result:** 在标准基准测试上进行了大量实验，结果表明所提出的DepthGait框架与同类方法相比，实现了最先进的性能，并在具有挑战性的数据集上获得了令人印象深刻的平均Rank-1准确率。

**Conclusion:** DepthGait框架通过有效利用RGB导出的深度信息和轮廓序列，并结合创新的多尺度跨层次特征融合方案，成功克服了传统2D表示的局限性，显著提升了步态识别的鲁棒性和准确性，达到了最先进的水平。

> **ai_Abstract:** 本研究提出了一种名为DepthGait的新型步态识别框架，旨在解决传统2D表示（如轮廓和骨架）在处理视角变化和捕捉精细步态细节方面的不足。DepthGait通过从RGB图像序列中估计并整合深度图作为新的模态，并结合原有的轮廓信息，以捕获更具判别力的特征。此外，该框架还引入了独特的多尺度和跨层次融合方案来有效融合不同模态的数据。实验证明，DepthGait在多个标准基准数据集上取得了最先进的性能和高准确率。

> **摘要翻译:** 鲁棒的步态识别需要高度判别性的表示，这与输入模态密切相关。尽管二进制轮廓和骨架在近期文献中占据主导地位，但这些2D表示未能捕获足够的线索来处理视角变化，也无法捕捉步态的更精细和有意义的细节。在本文中，我们引入了一个新颖的框架，称为DepthGait，它结合了RGB导出的深度图和轮廓序列，以增强步态识别。具体而言，除了人体的2D轮廓表示外，所提出的管道明确地从给定的RGB图像序列估计深度图，并将其用作一种新的模态，以捕获人体运动中固有的判别性特征。此外，还开发了一种新颖的多尺度和跨层次融合方案，以弥合深度图和轮廓之间的模态差异。在标准基准测试上进行的广泛实验表明，所提出的DepthGait与同类方法相比，实现了最先进的性能，并在具有挑战性的数据集上获得了令人印象深刻的平均Rank-1准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [289] [AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video](https://arxiv.org/abs/2508.03100)
> *AVATAR：强化学习在视频中实现视觉、听觉和推理*

*Yogesh Kulkarni, Pooyan Fazli* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 多模态推理, 视频理解, 离策略学习, 信用分配

**Comment:** 

> **TL;DR:** AVATAR是一个新的强化学习框架，通过离策略训练和时间优势塑造，解决了现有方法在长视频多模态推理中的数据效率低下和奖励分配不均问题，显著提升了性能和样本效率。

**AI_Comments:** AVATAR的创新之处在于其结合了离策略训练和新颖的时间优势塑造策略，有效解决了长视频多模态推理中长期存在的数据效率和信用分配难题。离策略训练显著提升了样本效率，而TAS则确保了学习信号能更准确地指导模型关注关键推理步骤，这对于复杂的多模态任务至关重要。其在多个基准上的显著性能提升和更高的样本效率，表明了该方法在推动多模态AI发展方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法如GRPO在长视频多模态推理中存在三个主要限制：1) 在线策略设计导致数据效率低下；2) 组内相同或近似相同的奖励导致优势消失，学习信号丧失；3) 统一的信用分配未能突出关键推理步骤。

**Method:** 本文提出了AVATAR（Audio-Video Agent for Alignment and Reasoning）框架，通过两个核心组件解决上述限制：1) 离策略训练架构，通过重用具有更大奖励多样性的过去经验，提高样本效率并解决优势消失问题；2) 时间优势塑造（Temporal Advantage Shaping, TAS），一种新颖的信用分配策略，在学习过程中提升关键推理阶段的权重。

**Result:** AVATAR在多个基准测试中表现出色，在MMVU上比Qwen2.5-Omni基线高出+5.4，在OmniBench上高出+4.9，在Video-Holmes上高出+4.5，同时样本效率提高了35%以上。

**Conclusion:** AVATAR通过其创新的离策略训练和时间优势塑造策略，有效解决了长视频多模态推理中的关键挑战，实现了显著的性能提升和更高的样本效率，证明了其在这一领域的可行性和优越性。

> **ai_Abstract:** 本文介绍了AVATAR（Audio-Video Agent for Alignment and Reasoning），一个针对长视频多模态推理的强化学习框架。该框架旨在解决现有方法（如GRPO）面临的数据效率低下、优势消失和信用分配不均等问题。AVATAR通过采用离策略训练架构来提高样本效率和奖励多样性，并引入时间优势塑造（TAS）策略以更合理地分配信用。实验结果表明，AVATAR在多个基准测试中显著优于现有基线，并展现出更高的样本效率。

> **摘要翻译:** 长视频上的多模态推理具有挑战性，因为它需要跨模态的精确时空融合和对齐。虽然最近的方法，如组相对策略优化（GRPO），在该领域显示出前景，但它们存在三个关键限制：(1) 其在线策略设计导致的数据效率低下，(2) 优势消失问题，即组内相同或近似相同的奖励通过产生零值优势来消除学习信号，以及 (3) 未能强调关键推理步骤的统一信用分配。我们引入了AVATAR（Audio-Video Agent for Alignment and Reasoning），一个通过两个核心组件解决这些限制的框架：(1) 一个离策略训练架构，通过重用具有更大奖励多样性的过去经验来提高样本效率并解决优势消失问题，以及 (2) 时间优势塑造（TAS），一种新颖的信用分配策略，在学习过程中提升关键推理阶段的权重。AVATAR在各种基准测试中取得了强大的性能，在MMVU上比Qwen2.5-Omni基线高出+5.4，在OmniBench上高出+4.9，在Video-Holmes上高出+4.5，同时样本效率提高了35%以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [IKOD: Mitigating Visual Attention Degradation in Large Vision-Language Models](https://arxiv.org/abs/2508.03469)
> *IKOD：缓解大型视觉-语言模型中的视觉注意力退化*

*Jiabing Yang, Chenhang Cui, Yiyang Zhou, Yixiang Chen, Peng Xia, Ying Wei, Tao Yu, Yan Huang, Liang Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 大型视觉-语言模型, 视觉注意力, 幻觉, 协作解码, IKOD

**Comment:** 

> **TL;DR:** IKOD是一种协作解码策略，通过键值合并和原始解码结合来缓解大型视觉-语言模型中视觉注意力随序列增长而下降的问题，从而有效减少幻觉。

**AI_Comments:** IKOD的创新点在于识别并解决了LVLMs中视觉注意力随序列长度增加而退化这一核心问题，这直接导致了幻觉。其方法巧妙地利用了键值合并，将高注意力短序列的信息融入长序列解码中，实现了高效且无需训练的性能提升，具有很高的实用价值和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在集成视觉和语言进行协作推理时面临“幻觉”问题，即输出与图像不符。现有方法计算成本高或需要昂贵的标注。研究表明，LVLMs的幻觉随序列长度增长而增加，且视觉注意力会随生成序列增长而减弱，这被认为是导致幻觉的关键因素。

**Method:** 基于视觉注意力随生成序列增长而减弱的发现，本文提出了IKOD（Image attention-guided Key-value merging cOllaborative Decoding）。该方法通过键值合并从具有更高图像注意力的较短序列中获取logits，并将其与原始解码的logits结合，以缓解注意力退化和抑制幻觉。

**Result:** 在幻觉和综合基准测试上的大量实验表明，IKOD在缓解幻觉和提高LVLMs的综合能力方面具有卓越的有效性。它无需额外的训练或外部工具，是一种轻量级且高效的框架。

**Conclusion:** IKOD通过解决视觉注意力退化问题，显著缓解了大型视觉-语言模型中的幻觉，并提升了模型的综合能力，且无需额外训练。

> **ai_Abstract:** 本文提出IKOD，一种针对大型视觉-语言模型（LVLMs）的协作解码策略，旨在缓解模型生成序列时视觉注意力下降导致幻觉增加的问题。通过分析发现LVLMs的视觉注意力随序列增长而减弱，IKOD通过键值合并将高图像注意力的短序列logits与原始解码结合，有效抑制幻觉并提高模型能力，且无需额外训练，计算成本低。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）的最新进展在多个领域取得了显著进展。然而，这些模型在整合视觉和语言进行协作推理时仍面临固有的挑战，这通常会导致“幻觉”，即输出与相应的图像不符。许多努力已经尝试解决这些问题，但每种方法都有其局限性，例如高计算成本或昂贵的数据集标注。最近的研究表明，LVLMs表现出一种长期偏差，即幻觉随着序列长度的增长而增加，但其根本原因仍知之甚少。基于对LVLMs中注意力机制的广泛研究，我们分析了这种长期偏差与视觉注意力之间的关系。在我们的研究中，我们发现当前LVLMs中存在一个一致的现象：模型的视觉输入注意力随着生成序列的增长而减弱，我们假设这是导致观察到的幻觉增加的关键因素。基于这些见解，我们提出了图像注意力引导的键值合并协作解码（IKOD），这是一种生成更注重图像序列的协作解码策略。该方法通过键值合并从具有更高图像注意力的较短序列中获取logits，并将其与原始解码的logits结合，有效缓解了注意力退化并抑制了幻觉，同时不会带来太多的推理成本。在幻觉和综合基准测试上的大量实验证明了IKOD在缓解幻觉和提高LVLMs综合能力方面的卓越有效性。重要的是，IKOD不需要额外的训练或外部工具，使其成为一个适用于各种模型的轻量级高效框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion](https://arxiv.org/abs/2508.03252)
> *鲁棒的单阶段全稀疏3D目标检测，通过可分离的潜在扩散*

*Wentao Qu, Guofeng Mei, Jing Wang, Yujiao Wu, Xiaoshui Huang, Liang Xiao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D目标检测, 稀疏表示, 扩散模型, 单阶段, 鲁棒性

**Comment:** 

> **TL;DR:** RSDNet提出了一种基于可分离潜在扩散框架的单阶段全稀疏3D目标检测网络，解决了现有DDPM方法推理效率低的问题，实现了鲁棒高效的SOTA性能。

**AI_Comments:** RSDNet的创新点在于其可分离潜在扩散框架（DLF），它不仅解决了DDPMs在3D目标检测中推理效率低的问题，还通过重新设计去噪机制和引入语义几何引导，提升了模型对多重扰动的鲁棒性以及在全稀疏表示下的检测能力。单步推理的实现是其效率提升的关键，使其在实际应用中更具潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于DDPMs的3D目标检测方法通常依赖于3D框的得分匹配或预训练的扩散先验，但它们在推理时需要多步迭代，这限制了效率。

**Method:** 提出RSDNet，一个带有可分离潜在框架（DLF）的鲁棒单阶段全稀疏3D目标检测网络。RSDNet通过多级去噪自编码器（DAEs）在潜在特征空间学习去噪过程，以理解多级扰动下的场景分布。它重新制定了DDPM的加噪和去噪机制，使DLF能够构建多类型、多级噪声样本和目标，增强对多重扰动的鲁棒性。此外，引入了语义几何条件引导来感知物体边界和形状，解决稀疏表示中的中心特征缺失问题，实现全稀疏检测。DLF的可分离去噪网络设计使得RSDNet能够进行单步推理，提高检测效率。

**Result:** 在公共基准测试上进行的广泛实验表明，RSDNet能够超越现有方法，实现最先进的检测性能。

**Conclusion:** RSDNet通过引入可分离的潜在扩散框架，成功解决了现有DDPMs在3D目标检测中效率低下的问题，并在鲁棒性、稀疏表示和推理效率方面取得了显著提升，达到了最先进的性能。

> **ai_Abstract:** 本文提出了RSDNet，一个鲁棒的单阶段全稀疏3D目标检测网络，旨在解决现有基于DDPMs方法在推理效率上的不足。RSDNet通过其可分离潜在框架（DLF），在潜在特征空间利用DAEs进行去噪，并重新设计DDPMs的加噪去噪机制以增强对多级扰动的鲁棒性。此外，引入语义几何条件引导来处理稀疏表示中的特征缺失。DLF的可分离设计允许RSDNet实现单步推理，显著提高了效率。实验证明RSDNet在性能上超越了现有方法，达到了最先进水平。

> **摘要翻译:** 去噪扩散概率模型（DDPMs）在鲁棒3D目标检测任务中取得了成功。现有方法通常依赖于3D框的得分匹配或预训练的扩散先验。然而，它们在推理时通常需要多步迭代，这限制了效率。为了解决这个问题，我们提出了一种鲁棒的单阶段全稀疏3D目标检测网络，该网络具有DDPMs的可分离潜在框架（DLF），命名为RSDNet。具体而言，RSDNet通过多级去噪自编码器（DAEs）等轻量级去噪网络在潜在特征空间中学习去噪过程。这使得RSDNet能够有效地理解多级扰动下的场景分布，实现鲁棒可靠的检测。同时，我们重新制定了DDPM的加噪和去噪机制，使DLF能够构建多类型和多级噪声样本和目标，增强RSDNet对多种扰动的鲁棒性。此外，引入了语义几何条件引导来感知物体边界和形状，缓解了稀疏表示中的中心特征缺失问题，使RSDNet能够在全稀疏检测管道中执行。此外，DLF的可分离去噪网络设计使RSDNet能够在推理中执行单步检测，进一步提高了检测效率。在公共基准测试上进行的广泛实验表明，RSDNet能够超越现有方法，实现最先进的检测。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes](https://arxiv.org/abs/2503.23461)
> *TextCrafter：在复杂视觉场景中准确渲染多个文本*

*Nikai Du, Zhennan Chen, Shan Gao, Zhizhou Chen, Xi Chen, Zhengkai Jiang, Jian Yang, Ying Tai* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 复杂视觉文本生成, TextCrafter, 文本渲染, 渐进式策略, CVTG-2K

**Comment:** 

> **TL;DR:** TextCrafter提出了一种新颖的多视觉文本渲染方法，以解决复杂视觉文本生成（CVTG）中文本失真、模糊和遗漏的问题，并引入了新的基准数据集。

**AI_Comments:** TextCrafter的创新之处在于其针对复杂视觉文本生成任务中常见问题的特定解决方案，即通过渐进式策略和令牌焦点增强机制来确保文本内容的准确渲染和与视觉载体的良好对齐。引入新的CVTG-2K基准数据集对于推动该领域的研究和评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂视觉文本生成（CVTG）任务中，图像生成模型经常渲染出失真、模糊或遗漏的视觉文本。

**Method:** 本文提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter采用渐进式策略分解复杂的视觉文本并确保文本内容与其视觉载体之间有强大的对齐。此外，它还结合了令牌焦点增强机制以提高生成过程中视觉文本的显著性。本文还提出了一个新的基准数据集CVTG-2K。

**Result:** TextCrafter有效解决了CVTG任务中的文本混淆、遗漏和模糊等关键挑战。广泛的实验表明，我们的方法超越了最先进的方法。

**Conclusion:** TextCrafter通过其渐进式策略和令牌焦点增强机制，成功地提高了复杂视觉文本生成的质量，解决了现有方法的局限性，并为该领域提供了一个新的评估基准。

> **ai_Abstract:** 本文针对复杂视觉文本生成（CVTG）中现有模型渲染文本失真、模糊和遗漏的问题，提出了一种名为TextCrafter的新型多视觉文本渲染方法。TextCrafter采用渐进式分解策略和令牌焦点增强机制，有效提升了文本渲染的准确性和清晰度。此外，研究还引入了CVTG-2K基准数据集以促进该领域的评估。实验结果表明，TextCrafter优于现有技术。

> **摘要翻译:** 本文探讨了复杂视觉文本生成（CVTG）任务，该任务的重点是在视觉图像中不同区域生成复杂的文本内容。在CVTG中，图像生成模型通常会渲染出扭曲和模糊的视觉文本，或者遗漏一些视觉文本。为了解决这些挑战，我们提出了TextCrafter，一种新颖的多视觉文本渲染方法。TextCrafter采用渐进式策略来分解复杂的视觉文本，同时确保文本内容与其视觉载体之间有强大的对齐。此外，它还结合了令牌焦点增强机制，以在生成过程中放大视觉文本的显著性。TextCrafter有效解决了CVTG任务中的关键挑战，例如文本混淆、遗漏和模糊。此外，我们提出了一个新的基准数据集CVTG-2K，旨在严格评估生成模型在CVTG任务上的性能。大量的实验表明，我们的方法超越了最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [315] [Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning](https://arxiv.org/abs/2508.03102)
> *因果解缠与跨模态对齐增强小样本学习*

*Tianjiao Jiang, Zhen Zhang, Yuhang Liu, Javen Qinfeng Shi* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 小样本学习, 因果解缠, 跨模态对齐, CLIP, ICA

**Comment:** 

> **TL;DR:** 本文提出了因果CLIP适配器 (CCA)，通过无监督ICA显式解缠CLIP视觉特征，并结合单向微调和双向交叉注意力机制增强跨模态对齐，从而在小样本学习任务中取得了最先进的性能和鲁棒性。

**AI_Comments:** 本文的创新点在于将因果解缠（通过ICA）与CLIP的跨模态对齐能力相结合，有效解决了小样本学习中表示纠缠和过拟合的问题。通过显式解缠和多层次的对齐增强，CCA在有限数据条件下展现出卓越的性能和鲁棒性，为小样本学习提供了一个高效且有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的小样本学习方法依赖于纠缠的表示，需要模型从有限的监督中隐式恢复解缠过程，这阻碍了有效的模型适应。

**Method:** 本文提出了因果CLIP适配器 (CCA)，它通过无监督独立分量分析 (ICA) 显式解缠从CLIP中提取的视觉特征，减少了可训练参数并减轻了过拟合。为了应对ICA可能破坏CLIP对齐的问题，CCA通过微调基于CLIP的文本分类器进行单向增强，并通过交叉注意力机制进行双向增强，以丰富视觉和文本表示。最终，单模态和跨模态分类输出可以线性结合以提高分类精度。

**Result:** 在11个基准数据集上的大量实验表明，该方法在小样本性能和对分布变化的鲁棒性方面始终优于最先进的方法，同时保持了计算效率。

**Conclusion:** CCA通过结合因果解缠和跨模态对齐，显著提升了小样本学习的性能和鲁棒性，并在多个基准数据集上超越了现有方法。

> **ai_Abstract:** 本文提出了因果CLIP适配器 (CCA)，一个用于增强小样本学习的新框架。CCA利用无监督独立分量分析 (ICA) 对CLIP提取的视觉特征进行显式解缠，以减少过拟合。为了弥补ICA可能造成的CLIP跨模态对齐破坏，CCA通过微调CLIP文本分类器和引入交叉注意力机制来增强对齐。该方法在11个基准数据集上显著优于现有的小样本学习方法，并在性能和鲁棒性方面达到了最先进水平。

> **摘要翻译:** 小样本学习 (FSL) 通常需要使用有限的标注数据来有效地适应模型。然而，大多数现有的小样本学习方法依赖于纠缠的表示，要求模型仅使用有限的监督隐式恢复解缠过程以获得解缠表示，这阻碍了有效的适应。最近的理论研究表明，多模态对比学习方法，如CLIP，可以解缠潜在表示，直至线性变换。鉴于此，我们提出了因果CLIP适配器 (CCA)，这是一个新颖的框架，它使用无监督独立分量分析 (ICA) 显式解缠从CLIP中提取的视觉特征。这消除了从标注数据中学习解缠过程的需要，从而减少了可训练参数的数量并减轻了过拟合。更进一步，虽然ICA可以获得视觉解缠表示，但它也可能破坏CLIP的模态内和模态间对齐。为了抵消这一点，CCA通过两种方式进一步利用CLIP固有的跨模态对齐：单向地，通过微调基于CLIP的文本分类器；双向地，通过一个交叉注意力机制，该机制通过相互作用丰富视觉和文本表示。单模态和跨模态分类输出都可以有效地线性组合以提高分类精度。在11个基准数据集上的大量实验表明，我们的方法在小样本性能和对分布变化的鲁棒性方面始终优于最先进的方法，同时保持了计算效率。代码将在 https://github.com/tianjiao-j/CCA 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [324] [How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes](https://arxiv.org/abs/2508.02905)
> *声音会如何变化？室内场景中材料控制的多模态声学特征生成*

*Mahnoor Fatima Saad, Ziad Al-Halah* | **Category: cs.CV, cs.SD, eess.AS** | **Updated: 2025-08-04**

**Keywords:** 声学特征生成, 房间脉冲响应, 材料控制, 多模态, 室内场景

**Comment:** Accepted to ICCV 2025. Project Page:
  https://mahnoor-fatima-saad.github.io/m-capa.html

> **TL;DR:** 该研究引入了材料控制的声学特征生成任务，并提出了一个编码器-解码器模型，可根据用户定义的材料配置为室内场景生成高保真房间脉冲响应（RIR）。

**AI_Comments:** 该论文的创新点在于提出了“材料控制的声学特征生成”这一新颖任务，并开发了一个能够动态响应用户材料配置的生成模型。创建Acoustic Wonderland数据集填补了该领域的数据空白，对未来的研究具有重要意义。该方法为虚拟声学设计和模拟提供了强大的工具，具有实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有技术无法根据用户定义的材料配置动态生成室内场景的声学特征，例如预测工作室铺设地毯和墙壁安装吸音板后声音会如何变化。

**Method:** 提出了一种新颖的编码器-解码器方法，该方法从视听观察中编码场景的关键属性，并根据用户提供的材料规格生成目标房间脉冲响应（RIR）。为了支持这项任务，还创建了一个新的基准数据集——Acoustic Wonderland Dataset。

**Result:** 所提出的模型能够有效编码材料信息并生成高保真RIR，其性能优于多个基线和最先进的方法。模型支持在推理时根据各种动态定义的材料配置生成多样化的RIR。

**Conclusion:** 该研究成功解决了材料控制的声学特征生成任务，并开发了一个能够根据用户定义的材料配置生成高保真RIR的模型，为室内声学模拟提供了有效工具。

> **ai_Abstract:** 该论文介绍了一项新的任务：材料控制的室内场景声学特征生成。作者提出了一种新颖的编码器-解码器模型，该模型能够根据场景的视听特征和用户指定的材料配置，动态生成高保真的房间脉冲响应（RIR）。为支持此任务，论文还构建了Acoustic Wonderland数据集。实验证明，该模型在生成高质量RIR方面优于现有方法。

> **摘要翻译:** 一个工作室在铺设地毯和墙壁安装吸音板后，声音会如何变化？我们引入了材料控制的声学特征生成任务，其目标是在给定具有特定视听特征的室内场景的情况下，根据用户在推理时定义的材料配置生成目标声学特征。我们通过一种新颖的编码器-解码器方法解决了这项任务，该方法从视听观察中编码场景的关键属性，并根据用户提供的材料规格生成目标房间脉冲响应（RIR）。我们的模型能够根据在推理时动态定义的各种材料配置生成多样化的RIR。为了支持这项任务，我们创建了一个新的基准数据集——Acoustic Wonderland Dataset，该数据集旨在开发和评估在多样化和具有挑战性的设置下材料感知的RIR预测方法。我们的结果表明，所提出的模型有效地编码了材料信息并生成了高保真RIR，其性能优于多个基线和最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [335] [JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers](https://arxiv.org/abs/2505.00482)
> *JointDiT：使用扩散Transformer增强RGB-深度联合建模*

*Kwon Byung-Ki, Qi Dai, Lee Hyoseok, Chong Luo, Tae-Hyun Oh* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 扩散Transformer, 联合建模, RGB-深度, 图像生成, 深度估计

**Comment:** Accepted to IEEE/CVF International Conference on Computer Vision
  (ICCV) 2025. Project page: https://byungki-k.github.io/JointDiT/ Code:
  https://github.com/kaist-ami/JointDiT

> **TL;DR:** JointDiT是一种扩散Transformer，通过自适应调度权重和不平衡时间步采样策略，实现RGB和深度图像的高质量联合生成、深度估计和深度条件图像生成。

**AI_Comments:** JointDiT的创新之处在于将扩散Transformer应用于RGB和深度数据的联合建模，并提出了两种有效的技术（自适应调度权重和不平衡时间步采样策略）来优化这一过程。这使得模型能够同时生成高保真图像和几何准确的深度图，并灵活地处理多种生成任务。该研究的重要性在于提出了一种新的、可能更通用的方法来替代传统的条件生成，为多模态图像生成领域开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法可能难以同时生成高保真图像和几何上合理准确的深度图，或者在联合分布建模方面存在不足。本文旨在通过利用扩散Transformer的架构优势和图像先验，实现RGB和深度图像的稳健联合分布建模，从而能够生成高质量图像和准确的深度图，并处理多种组合生成任务。

**Method:** 本文提出了JointDiT，一个扩散Transformer模型，用于建模RGB和深度的联合分布。通过引入两种简单而有效的技术：依赖于每种模态噪声水平的自适应调度权重（adaptive scheduling weights）和不平衡时间步采样策略（unbalanced timestep sampling strategy），实现了稳健的联合分布建模。这些技术使得模型能够针对每种模态在所有噪声水平下进行训练，并通过控制每个分支的时间步来自然处理联合生成、深度估计和深度条件图像生成等各种组合生成任务。

**Result:** JointDiT不仅能够生成高保真图像，还能生成几何上合理且准确的深度图。它在联合生成任务中表现出卓越的性能。此外，在深度估计和深度条件图像生成方面也取得了可比较的结果。

**Conclusion:** 联合分布建模可以作为条件生成的一种可行替代方案。

> **ai_Abstract:** 本文介绍了JointDiT，一种基于扩散Transformer的模型，专注于RGB图像和深度图的联合分布建模。该模型通过引入自适应调度权重和不平衡时间步采样策略，实现了高质量的图像生成和准确的深度图预测。JointDiT能够处理多种组合生成任务，包括联合生成、深度估计和深度条件图像生成，并在这些任务中表现出色，表明联合分布建模是条件生成的一种有效替代方案。

> **摘要翻译:** 我们提出了JointDiT，一种扩散Transformer，用于建模RGB和深度的联合分布。通过利用最先进的扩散Transformer的架构优势和出色的图像先验，JointDiT不仅能够生成高保真图像，还能生成几何上合理且准确的深度图。这种稳健的联合分布建模是通过我们提出的两种简单而有效的技术实现的，即依赖于每种模态噪声水平的自适应调度权重和不平衡时间步采样策略。通过这些技术，我们针对每种模态在所有噪声水平下训练我们的模型，使JointDiT能够通过简单控制每个分支的时间步来自然处理各种组合生成任务，包括联合生成、深度估计和深度条件图像生成。JointDiT展示了卓越的联合生成性能。此外，它在深度估计和深度条件图像生成方面也取得了可比较的结果，这表明联合分布建模可以作为条件生成的一种可行替代方案。项目页面可在https://byungki-k.github.io/JointDiT/查看。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [336] [FlowR: Flowing from Sparse to Dense 3D Reconstructions](https://arxiv.org/abs/2504.01647)
> *FlowR：从稀疏到密集的3D重建*

*Tobias Fischer, Samuel Rota Bulò, Yung-Hsu Yang, Nikhil Keetha, Lorenzo Porzi, Norman Müller, Katja Schwarz, Jonathon Luiten, Marc Pollefeys, Peter Kontschieder* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 3D重建, 新颖视图合成, 流匹配, 高斯泼溅, 稀疏视图

**Comment:** ICCV 2025 Highlight. Project page is available at
  https://tobiasfshr.github.io/pub/flowr

> **TL;DR:** FlowR提出了一种多视图流匹配模型，通过生成一致的视图来改善稀疏和密集视图场景下的新颖视图合成（NVS）和3D重建质量，优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了一个多视图流匹配模型，直接学习从稀疏到密集视图渲染的流，从而生成一致的中间视图，有效解决了3D高斯泼溅在稀疏数据下的质量退化问题。与现有依赖2D生成模型的方法相比，FlowR通过多视图一致性避免了幻觉和伪影，这对于虚拟现实等需要高质量3D重建的应用具有重要意义。其大规模数据集训练和在H100上的高效处理能力也显示了其潜在的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅在新颖视图合成(NVS)方面表现出色，但在稀疏训练视图下质量急剧下降，而获取密集的捕获数据既费力又昂贵。现有使用2D生成模型的方法（如通过蒸馏或生成额外训练视图）常导致幻觉、不一致的生成结果和重建伪影。

**Method:** 我们提出了一种多视图流匹配模型，该模型学习一种流，直接将稀疏重建的新颖视图渲染与密集重建的预期渲染连接起来。这使得能够通过一致的生成视图来增强场景捕获，从而提高重建质量。该模型在一个包含360万图像对的新数据集上进行训练。

**Result:** 我们的模型在单个H100 GPU上单次前向传递中可处理多达45个540x960分辨率的视图（91K令牌）。我们的管道在稀疏和密集视图场景下均持续改善NVS，并在多个广泛使用的新颖视图合成基准上实现了比现有工作更高质量的重建。

**Conclusion:** 本文提出了一种新颖的多视图流匹配模型FlowR，通过生成一致的视图来有效解决稀疏视图下3D重建质量下降的问题，并在新颖视图合成方面取得了显著的性能提升，超越了现有技术。

> **ai_Abstract:** 本文提出FlowR，一种新颖的多视图流匹配模型，旨在解决3D高斯泼溅在稀疏视图下NVS质量下降的问题。针对现有2D生成模型存在的幻觉和不一致性，FlowR通过学习一个流，将稀疏重建的渲染与密集重建的预期渲染直接连接，从而生成一致的辅助视图。该模型在一个包含360万图像对的数据集上训练，并在稀疏和密集视图场景下均显著提升了NVS和3D重建的质量，在多个主流基准测试中表现优于现有方法。

> **摘要翻译:** 3D高斯泼溅技术能够以实时帧率实现高质量的新颖视图合成（NVS）。然而，当偏离训练视图时，其质量会急剧下降。因此，为了满足虚拟现实（VR）等应用的高质量期望，需要密集的捕获。然而，获取此类密集捕获非常费力且昂贵。现有工作已经探索使用2D生成模型通过蒸馏或生成额外的训练视图来缓解这一要求。这些模型通常依赖于仅以少量参考输入视图为条件的从噪声到数据的生成过程，导致幻觉、不一致的生成结果以及随后的重建伪影。相反，我们提出了一种多视图流匹配模型，该模型学习一种流，直接将可能来自稀疏重建的新颖视图渲染连接到我们期望从密集重建中获得的渲染。这使得能够通过一致的生成视图来增强场景捕获，从而提高重建质量。我们的模型在一个包含360万图像对的新数据集上进行训练，并且可以在单个H100 GPU上单次前向传递中处理多达45个540x960分辨率的视图（91K令牌）。我们的管道在稀疏和密集视图场景下均持续改善NVS，并在多个广泛使用的新颖视图合成基准上实现了比现有工作更高质量的重建。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [339] [H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction](https://arxiv.org/abs/2508.03118)
> *H3R：用于通用三维重建的混合多视角对应*

*Heng Jia, Linchao Zhu, Na Zhao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D重建, 多视角对应, 混合框架, 普吕克坐标, 基础模型

**Comment:** ICCV 2025

> **TL;DR:** H3R是一个混合框架，通过结合体素潜在融合和注意力特征聚合，解决了通用三维重建中多视角对应建模的挑战，实现了更快的收敛和最先进的性能。

**AI_Comments:** 这篇论文通过提出一个混合框架H3R，创新性地解决了通用三维重建中多视角对应建模的难题。其核心创新在于结合了显式和隐式方法的优点，通过高效的潜在体素和相机感知Transformer实现了几何一致性和鲁棒性。此外，发现空间对齐的基础模型在三维重建中的优势，也为该领域提供了新的见解。该方法在收敛速度和性能上的显著提升，以及对可变输入的支持和跨数据集泛化能力，都表明其具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管前馈3D高斯泼溅技术取得了进展，但通用三维重建仍然具有挑战性，特别是在多视角对应建模方面。现有方法面临一个根本性的权衡：显式方法几何精度高但难以处理模糊区域，而隐式方法鲁棒性强但收敛缓慢。

**Method:** 本文提出了H3R，一个混合框架，通过整合体素潜在融合与基于注意力的特征聚合来解决现有方法的局限性。该框架包含两个互补组件：一个通过极线约束强制执行几何一致性的高效潜在体素，以及一个利用普吕克坐标进行自适应对应细化的相机感知Transformer。此外，研究发现空间对齐的基础模型（如SD-VAE）在空间重建要求上显著优于语义对齐模型（如DINOv2）。该方法支持可变数量和高分辨率输入视图，并展示了鲁棒的跨数据集泛化能力。

**Result:** H3R方法实现了最先进的性能，在RealEstate10K、ACID和DTU数据集上分别取得了0.59 dB、1.06 dB和0.22 dB的显著PSNR改进。该方法比现有方法收敛速度快2倍，并支持可变数量和高分辨率输入视图，同时展示了鲁棒的跨数据集泛化能力。

**Conclusion:** H3R通过结合高效的潜在体素和相机感知Transformer的混合方法，有效解决了通用三维重建中多视角对应建模的挑战，实现了卓越的泛化能力、更快的收敛速度和最先进的性能。

> **ai_Abstract:** 本文提出了H3R，一个用于通用三维重建的混合框架，旨在解决现有方法在多视角对应建模中几何精度与收敛速度之间的权衡。H3R结合了高效的潜在体素和相机感知Transformer，通过强制几何一致性和自适应对应细化来提高泛化能力并加速收敛。研究还发现空间对齐的基础模型更适合空间重建。H3R在多个数据集上实现了最先进的性能，并支持灵活的输入视图数量和分辨率。

> **摘要翻译:** 尽管前馈3D高斯泼溅技术最近取得了进展，但通用三维重建仍然具有挑战性，特别是在多视角对应建模方面。现有方法面临一个根本性的权衡：显式方法几何精度高但难以处理模糊区域，而隐式方法鲁棒性强但收敛缓慢。我们提出了H3R，一个通过整合体素潜在融合与基于注意力的特征聚合来解决这一局限性的混合框架。我们的框架由两个互补的组件组成：一个通过极线约束强制执行几何一致性的高效潜在体素，以及一个利用普吕克坐标进行自适应对应细化的相机感知Transformer。通过整合这两种范式，我们的方法增强了泛化能力，同时比现有方法收敛速度快2倍。此外，我们表明空间对齐的基础模型（例如SD-VAE）显著优于语义对齐模型（例如DINOv2），解决了语义表示和空间重建要求之间的不匹配问题。我们的方法支持可变数量和高分辨率输入视图，同时展示了鲁棒的跨数据集泛化能力。大量的实验表明，我们的方法在多个基准测试中取得了最先进的性能，在RealEstate10K、ACID和DTU数据集上分别取得了0.59 dB、1.06 dB和0.22 dB的显著PSNR改进。代码可在https://github.com/JiaHeng-DLUT/H3R 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [341] [Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation](https://arxiv.org/abs/2411.19331)
> *与 DINO 对话：弥合自监督视觉骨干与语言模型，实现开放词汇分割*

*Luca Barsellotti, Lorenzo Bianchi, Nicola Messina, Fabio Carrara, Marcella Cornia, Lorenzo Baraldi, Fabrizio Falchi, Rita Cucchiara* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 开放词汇分割, 自监督学习, 视觉-语言模型, DINOv2, CLIP

**Comment:** 

> **TL;DR:** 本文提出了 Talk2DINO，一种结合 DINOv2 空间精度和 CLIP 语言理解的新方法，用于开放词汇分割，无需微调骨干网络，并在无监督 OVS 基准测试中达到 SOTA 性能。

**AI_Comments:** 这篇论文的创新点在于提出了一种无需微调骨干网络就能有效结合自监督视觉模型和视觉-语言模型的方法，解决了现有方法在开放词汇分割中空间定位和语言集成方面的不足。其利用 DINOv2 的注意力图进行局部对齐的策略是关键，显著提升了分割质量和前景背景区分能力，为开放词汇分割领域提供了一个高效且性能卓越的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型（如 CLIP）在开放词汇分割中空间定位能力不足，而自监督视觉模型（如 DINO）虽然视觉编码精细但缺乏语言集成。本文旨在弥合 DINOv2 的空间精度与 CLIP 的语言理解之间的鸿沟。

**Method:** 提出了 Talk2DINO 混合方法，通过学习到的映射函数，将 CLIP 的文本嵌入与 DINOv2 的补丁级特征对齐，且无需微调底层骨干网络。训练时利用 DINOv2 的注意力图选择性地将局部视觉补丁与文本嵌入对齐。

**Result:** Talk2DINO 增强了分割过程，生成更自然、噪声更少的分割结果，并能有效区分前景物体和背景。在多个无监督开放词汇分割基准测试中，Talk2DINO 取得了最先进的性能。

**Conclusion:** Talk2DINO 有效地将 DINOv2 的空间准确性与 CLIP 的语言理解能力相结合，为开放词汇分割提供了一种强大的解决方案，并在无监督 OVS 任务上达到了 SOTA 表现。

> **ai_Abstract:** 本文介绍了 Talk2DINO，一种用于开放词汇分割的新型混合方法，旨在结合自监督视觉模型 DINOv2 的精细空间编码能力与视觉-语言模型 CLIP 的语言理解能力。通过一个学习到的映射函数，Talk2DINO 将 CLIP 的文本嵌入与 DINOv2 的补丁级特征对齐，并利用 DINOv2 的注意力图进行局部对齐，无需对骨干网络进行微调。实验证明，Talk2DINO 能够生成更自然、噪声更低的分割结果，有效区分前景与背景，并在多个无监督 OVS 基准测试中达到了最先进的性能。

> **摘要翻译:** 开放词汇分割（OVS）旨在通过自由形式的文本概念对图像进行分割，而无需预定义的训练类别。尽管现有的视觉-语言模型（如 CLIP）可以通过利用 Vision Transformers 的粗略空间信息生成分割掩码，但由于其图像和文本特征的全局对齐，它们在空间定位方面面临挑战。相反，DINO 等自监督视觉模型在细粒度视觉编码方面表现出色，但缺乏与语言的集成。为了弥合这一差距，我们提出了 Talk2DINO，一种新颖的混合方法，它结合了 DINOv2 的空间准确性与 CLIP 的语言理解能力。我们的方法通过一个学习到的映射函数，将 CLIP 的文本嵌入与 DINOv2 的补丁级特征对齐，而无需微调底层骨干网络。在训练时，我们利用 DINOv2 的注意力图选择性地将局部视觉补丁与文本嵌入对齐。我们展示了 Talk2DINO 强大的语义和定位能力可以增强分割过程，从而产生更自然、噪声更少的分割结果，并且我们的方法还可以有效地区分前景物体和背景。实验结果表明，Talk2DINO 在多个无监督 OVS 基准测试中取得了最先进的性能。源代码和模型可在 https://lorebianchi98.github.io/Talk2DINO/ 公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Text-to-Image Generation](https://arxiv.org/abs/2508.03485)
> *LRQ-DiT：用于文本到图像生成的扩散Transformer的对数旋转后训练量化*

*Lianwei Yang, Haokun Lin, Tianchen Zhao, Yichen Wu, Hongyu Zhu, Ruiqi Xie, Zhenan Sun, Yu Wang, Qingyi Gu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 扩散Transformer, 后训练量化, 低比特, 对数旋转, 文本到图像生成

**Comment:** 

> **TL;DR:** LRQ-DiT提出了一种新的后训练量化方法，通过对数量化和自适应旋转方案，解决了扩散Transformer在低比特量化中遇到的权重长尾分布和激活异常值问题，显著降低了计算成本并保持了图像质量。

**AI_Comments:** LRQ-DiT的创新之处在于其针对扩散Transformer量化中的具体挑战（权重长尾分布和激活异常值）提出了针对性解决方案。特别是对数量化和自适应旋转方案，这对于在资源受限设备上部署大型生成模型具有重要意义。该工作有效地提高了DiT模型在实际应用中的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer (DiTs) 在文本到图像生成方面表现出色，但其高计算成本和大参数量限制了其在资源受限场景中的应用。现有后训练量化 (PTQ) 方法在极端低比特设置下性能严重下降。主要障碍是模型权重呈长尾高斯分布导致均匀量化误差大，以及两种激活异常值（轻微异常值和显著异常值）干扰量化。

**Method:** 提出LRQ-DiT，一个高效准确的PTQ框架。引入Twin-Log Quantization (TLQ)，一种基于对数的量化方法，用于解决权重分布问题，减少量化误差。提出Adaptive Rotation Scheme (ARS)，根据激活波动动态应用Hadamard或异常值感知旋转，以有效减轻两种激活异常值的影响。

**Result:** LRQ-DiT在PixArt和FLUX模型上，以及COCO、MJHQ和sDCI数据集上进行了不同比特宽度设置下的评估。结果表明，LRQ-DiT实现了DiT模型的低比特量化，同时保持了图像质量，并且优于现有PTQ基线。

**Conclusion:** LRQ-DiT成功解决了扩散Transformer在低比特后训练量化中的挑战，通过创新的对数量化和自适应旋转方案，在保持高性能的同时显著降低了计算资源需求，使得DiT模型在资源受限场景下更具可用性。

> **ai_Abstract:** 本文提出了LRQ-DiT，一个高效且准确的扩散Transformer后训练量化框架，旨在解决DiT模型在文本到图像生成中面临的高计算成本和低比特量化性能下降问题。LRQ-DiT通过引入Twin-Log Quantization (TLQ) 来处理权重的长尾高斯分布，并设计了Adaptive Rotation Scheme (ARS) 来缓解激活异常值的影响。实验证明，LRQ-DiT在多个数据集和模型上实现了低比特量化，同时保持了图像质量，并超越了现有基线方法。

> **摘要翻译:** 扩散Transformer（DiTs）在文本到图像生成方面取得了令人印象深刻的性能。然而，其高计算成本和庞大的参数量对在资源受限场景中的使用构成了重大挑战。后训练量化（PTQ）是减少内存使用和加速推理的一种有前景的解决方案，但现有PTQ方法在极端低比特设置下会遭受严重的性能下降。我们确定了DiT模型低比特后训练量化的两个主要障碍：（1）模型权重遵循带有长尾的高斯状分布，导致均匀量化无法很好地分配区间并导致显著误差；（2）两种类型的激活异常值：(i) 值略微升高的轻微异常值，以及(ii) 集中在特定通道中具有大值的显著异常值，它们都会扰乱激活量化。为了解决这些问题，我们提出了LRQ-DiT，一个高效且准确的PTQ框架。我们引入了Twin-Log Quantization (TLQ)，一种基于对数的方法，与权重分布良好对齐并减少量化误差。我们还提出了一种自适应旋转方案（ARS），根据激活波动动态应用Hadamard或异常值感知旋转，有效减轻了两种异常值的影响。我们在PixArt和FLUX上在各种比特宽度设置下评估了LRQ-DiT，并在COCO、MJHQ和sDCI数据集上验证了性能。LRQ-DiT实现了DiT模型的低比特量化，同时保持了图像质量，优于现有PTQ基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [356] [Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation](https://arxiv.org/abs/2504.04841)
> *Prior2Former——用于无假设开放世界全景分割的掩码Transformer证据建模*

*Sebastian Schmidt, Julius Körner, Dominik Fuchsgruber, Stefano Gasperini, Federico Tombari, Stephan Günnemann* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 全景分割, 证据学习, 不确定性估计, 开放世界, 掩码Transformer

**Comment:** 

> **TL;DR:** Prior2Former (P2F) 是一种基于证据学习的掩码Transformer，用于全景分割，解决了现有方法在处理新类别和分布外(OOD)数据时的局限性，实现了无需OOD数据或对比训练的SOTA性能。

**AI_Comments:** 这篇论文的创新点在于首次将证据学习引入分割视觉Transformer，并通过Beta先验实现了高质量的不确定性估计，从而有效处理开放世界中的新颖和OOD对象。其重要性在于解决了传统全景分割方法在现实世界应用中对未知类别泛化能力不足的问题，尤其是在无需OOD数据训练的情况下，大大提升了模型的实用性和可靠性。这对于自动驾驶等安全关键领域具有显著价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的全景分割方法依赖于预定义的类别，在处理新颖类别和分布外(OOD)数据时表现不佳，这在自动驾驶等安全关键应用中尤其成问题，因为在这些应用中，未见场景的可靠性至关重要。

**Method:** 本文提出了Prior2Former (P2F)，这是首个基于证据学习的分割视觉Transformer方法。P2F通过引入Beta先验来计算像素级二值掩码分配中的模型不确定性，从而扩展了掩码视觉Transformer架构。它无需访问OOD数据样本或对空（即未标记）类别进行对比训练。

**Result:** P2F实现了高质量的不确定性估计，能有效检测新颖和OOD对象，并在异常实例分割和开放世界全景分割方面达到了最先进的水平。在Cityscapes、COCO、SegmentMeIfYouCan和OoDIS数据集上的综合实验表明，P2F在各个方面都展现了最先进的性能。

**Conclusion:** Prior2Former (P2F) 通过将证据学习引入掩码视觉Transformer，解决了全景分割中对新颖和OOD类别的鲁棒性问题，实现了无需OOD数据或对比训练的高可靠性分割，弥补了基准性能与实际可靠性之间的差距。

> **ai_Abstract:** Prior2Former (P2F) 是一种创新的全景分割方法，它将证据学习集成到掩码视觉Transformer架构中。该模型通过引入Beta先验来估计像素级不确定性，从而有效地检测新颖和分布外(OOD)对象，克服了现有方法对预定义类别的依赖。P2F的独特之处在于它无需OOD数据或对比训练，使其在现实世界应用中具有高度实用性。实验证明，P2F在开放世界全景分割和异常实例分割方面均达到了最先进的性能。

> **摘要翻译:** 在全景分割中，必须在语义类别内分离单个实例。由于最先进的方法依赖于预定义的一组类别，它们难以处理新颖类别和分布外(OOD)数据。这在自动驾驶等安全关键应用中尤其成问题，因为在这些应用中，未见场景的可靠性至关重要。我们通过提出Prior2Former (P2F) 来弥补卓越基准性能与可靠性之间的差距，这是首个基于证据学习的分割视觉Transformer方法。P2F通过引入Beta先验来计算像素级二值掩码分配中的模型不确定性，从而扩展了掩码视觉Transformer架构。这种设计实现了高质量的不确定性估计，有效检测新颖和OOD对象，从而实现了最先进的异常实例分割和开放世界全景分割。与大多数解决未知类别的分割模型不同，P2F在没有访问OOD数据样本或对空（即未标记）类别进行对比训练的情况下运行，这使得它在无法获得此类先验信息的实际场景中具有高度适用性。此外，P2F可以灵活应用于异常实例和全景分割。通过在Cityscapes、COCO、SegmentMeIfYouCan和OoDIS数据集上的综合实验，P2F在各个方面都展现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [361] [V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models](https://arxiv.org/abs/2508.03254)
> *V.I.P.：用于高效视频扩散模型的迭代在线偏好蒸馏*

*Jisoo Kim, Wooseok Seo, Junwan Kim, Seungho Park, Sooyeon Park, Youngjae Yu* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视频扩散模型, 模型蒸馏, 偏好优化, 文本到视频, 效率

**Comment:** ICCV2025 accepted

> **TL;DR:** 本文提出了一种名为 ReDPO 的有效蒸馏方法，结合 DPO 和 SFT，并引入 V.I.P. 框架来降低文本到视频（T2V）模型的计算成本，同时保持或超越性能。

**AI_Comments:** 这篇论文的创新点在于结合了DPO和SFT进行模型蒸馏，以解决传统SFT在模型剪枝后易导致模式崩溃的问题。通过引入DPO，学生模型能够有选择性地学习教师模型的关键特性，而非盲目模仿，这对于在资源受限环境下部署高性能T2V模型具有重要意义。V.I.P.框架的数据筛选和在线训练机制也提高了蒸馏过程的效率和质量。该研究为视频生成模型的轻量化提供了有效的解决方案，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限环境中部署文本到视频（T2V）模型时，其高计算成本是一个关键挑战。现有的蒸馏方法主要依赖于监督微调（SFT），这常导致模式崩溃和质量下降，因为剪枝后的模型难以直接匹配教师模型的输出。

**Method:** 本文提出了一种名为 ReDPO 的有效蒸馏方法，它集成了 DPO（偏好优化）和 SFT（监督微调）。ReDPO 利用 DPO 引导学生模型专注于恢复目标属性而非被动模仿教师模型，同时利用 SFT 提升整体性能。此外，还提出了 V.I.P. 框架，用于过滤和筛选高质量的配对数据集，并采用逐步在线方法进行校准训练。

**Result:** 该方法在 VideoCrafter2 和 AnimateDiff 两种领先的 T2V 模型上进行了验证，分别实现了 36.2% 和 67.5% 的参数缩减，同时保持甚至超越了完整模型的性能。进一步的实验证明了 ReDPO 和 V.I.P. 框架在实现高效高质量视频生成方面的有效性。

**Conclusion:** 本文提出的 ReDPO 蒸馏方法和 V.I.P. 框架能够显著降低文本到视频模型的计算成本，同时保持或提升生成质量，有效解决了现有蒸馏方法中模式崩溃和性能下降的问题。

> **ai_Abstract:** 本文针对文本到视频（T2V）模型在资源受限环境中的部署挑战，提出了一种名为 ReDPO 的新型蒸馏方法，该方法结合了偏好优化（DPO）和监督微调（SFT），旨在克服传统监督微调导致的模式崩溃和质量下降问题。ReDPO 引导学生模型关注特定属性恢复，而非简单模仿教师模型，并通过 SFT 提升整体性能。此外，论文还引入了 V.I.P. 框架，用于构建高质量数据集和实现校准训练。实验结果表明，该方法在 VideoCrafter2 和 AnimateDiff 模型上显著减少了参数量，同时保持或超越了原始模型的性能，有效实现了高效高质量的视频生成。

> **摘要翻译:** 随着在资源受限环境中部署文本到视频（T2V）模型的兴趣日益增长，降低其高计算成本已变得至关重要，这促使人们在保持性能的同时，对剪枝和知识蒸馏方法进行了广泛研究。然而，现有的蒸馏方法主要依赖于监督微调（SFT），这常导致模式崩溃，因为容量减小的剪枝模型无法直接匹配教师模型的输出，最终导致质量下降。为了解决这一挑战，我们提出了一种有效的蒸馏方法 ReDPO，它集成了 DPO 和 SFT。我们的方法利用 DPO 引导学生模型专注于恢复目标属性，而不是被动模仿教师模型，同时还利用 SFT 提升整体性能。我们额外提出了 V.I.P.，一个用于过滤和筛选高质量配对数据集的新颖框架，以及一种用于校准训练的逐步在线方法。我们在两种领先的 T2V 模型 VideoCrafter2 和 AnimateDiff 上验证了我们的方法，分别实现了 36.2% 和 67.5% 的参数缩减，同时保持甚至超越了完整模型的性能。进一步的实验证明了 ReDPO 和 V.I.P. 框架在实现高效高质量视频生成方面的有效性。我们的代码和视频可在 https://jiiiisoo.github.io/VIP.github.io/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery](https://arxiv.org/abs/2508.03127)
> *Landsat30-AU：一个用于澳大利亚Landsat图像的视觉-语言数据集*

*Sai Ma, Zhuang Li, John A Taylor* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视觉语言数据集, Landsat, 遥感, 地球观测, VQA

**Comment:** 

> **TL;DR:** Landsat30-AU是一个大型视觉-语言数据集，包含来自36年以上澳大利亚Landsat卫星图像的图像-字幕对和视觉问答样本，旨在弥补现有数据集在低分辨率、多卫星、长期地球观测数据方面的不足，并展示了在这些数据上微调可以显著提升模型性能。

**AI_Comments:** 该论文的创新点在于构建了一个大规模、长期、多卫星、低分辨率的视觉-语言数据集，填补了现有遥感VLM数据集的空白。其重要性在于，该数据集有望促进更经济、更鲁棒的全球监测，并使地球观测数据对更广泛的用户可及。同时，论文通过实验证明了现有通用VLM在处理此类专业数据时的局限性，并强调了领域特定数据微调的必要性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型(VLM)数据集主要关注短期、高分辨率图像，忽略了对经济且鲁棒的全球监测至关重要的低分辨率、多卫星、长期档案（如Landsat）。这限制了卫星图像的自然语言交互，阻碍了地球观测的民主化、专家工作流程的加速、非专业人士的数据可及性以及行星级自动化。

**Method:** 本研究通过构建Landsat30-AU数据集来解决上述问题。该数据集包含来自澳大利亚36年以上Landsat 5、7、8、9卫星的30米分辨率图像。数据集分为两部分：Landsat30-AU-Cap（196,262个图像-字幕对）和Landsat30-AU-VQA（17,725个人工验证的视觉问答样本，涵盖八个遥感领域）。数据集的整理通过一个自举管道进行，该管道利用通用VLM进行迭代细化和人工验证以确保质量。

**Result:** 对八个VLM在Landsat30-AU基准上的评估显示，现成的模型难以理解卫星图像。开源遥感VLM EarthDial在字幕任务中SPIDEr得分仅为0.07，VQA准确率仅为0.48。然而，在Landsat30-AU上对Qwen2.5-VL-7B进行轻量级微调，字幕性能从0.11 SPIDEr提高到0.31，VQA准确率从0.74提升到0.87。

**Conclusion:** 现有的通用视觉语言模型在处理低分辨率、长期卫星图像方面存在显著局限性。而通过在Landsat30-AU等专门的、大规模、长期数据集上进行微调，可以显著提升模型在卫星图像理解（如图像字幕和视觉问答）方面的性能，这表明此类数据集对于推动地球观测的民主化和自动化至关重要。

> **ai_Abstract:** 本研究介绍了Landsat30-AU，一个大规模的视觉-语言数据集，用于解决现有数据集在低分辨率、多卫星、长期地球观测图像方面的不足。该数据集包含来自澳大利亚36年以上Landsat卫星图像的19万余个图像-字幕对和近1.8万个视觉问答样本，通过自举管道和人工验证构建。评估结果表明，通用VLM在卫星图像理解方面表现不佳，但通过在Landsat30-AU上进行轻量级微调，模型性能（如Qwen2.5-VL-7B）可以显著提升，验证了该数据集对于推动遥感领域VLM发展的重要性。

> **摘要翻译:** 视觉语言模型（VLM）通过实现与卫星图像的自然语言交互，可以加速专家工作流程、使非专业人士能够访问数据并实现行星级自动化，从而使地球观测民主化。然而，现有数据集主要关注短期、高分辨率图像，且来源卫星数量有限，忽视了对经济且鲁棒的全球监测至关重要的低分辨率、多卫星、长期档案，例如Landsat。我们通过Landsat30-AU解决了这一空白，这是一个大规模的视觉语言数据集，由Landsat 5、7、8和9四颗Landsat卫星在澳大利亚上空收集的30米分辨率图像构建，时间跨度超过36年。该数据集包含两个组件：Landsat30-AU-Cap，包含196,262个图像-字幕对；以及Landsat30-AU-VQA，包含17,725个人工验证的视觉问答（VQA）样本，涵盖八个遥感领域。这两个数据集都是通过一个自举管道精心策划的，该管道利用通用VLM进行迭代细化和人工验证以确保质量。我们对八个VLM在我们的基准上进行的评估表明，现成的模型难以理解卫星图像。开源遥感VLM EarthDial在字幕任务中仅获得0.07的SPIDEr分数，VQA准确率为0.48，这凸显了当前方法的局限性。令人鼓舞的是，在Landsat30-AU上对Qwen2.5-VL-7B进行轻量级微调，字幕性能从0.11 SPIDEr提高到0.31，VQA准确率从0.74提升到0.87。代码和数据可在https://github.com/papersubmit1/landsat30-au获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [369] [WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image](https://arxiv.org/abs/2412.02141)
> *WSI-LLaVA：一种用于全玻片图像的多模态大型语言模型*

*Yuci Liang, Xinheng Lyu, Meidan Ding, Wenting Chen, Jipeng Zhang, Yuexiang Ren, Xiangjian He, Song Wu, Sen Yang, Xiyue Wang, Xiaohan Xing, Linlin Shen* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 全玻片图像, 多模态大型语言模型, 计算病理学, 形态分析, 诊断准确性

**Comment:** ICCV 2025, 38 pages, 22 figures, 35 tables

> **TL;DR:** 现有病理学MLLM无法全面分析全玻片图像并忽略关键形态特征，本文提出WSI-Bench基准和WSI-LLaVA框架，通过三阶段训练和新指标显著提升全玻片图像理解和诊断准确性。

**AI_Comments:** 这篇论文通过引入大规模形态感知基准WSI-Bench和创新的WSI-LLaVA框架，解决了现有MLLMs在全玻片图像分析中形态特征理解不足的痛点。其三阶段训练方法和专门的WSI指标设计，对于提升计算病理学模型的诊断准确性具有重要意义，是该领域的一大进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的patch-level多模态大型语言模型（MLLMs）在计算病理学中存在局限性，它们无法全面分析全玻片图像（WSIs），并且倾向于绕过病理学家诊断所依赖的关键形态特征。

**Method:** 本文首先引入了WSI-Bench，一个包含18万个VQA对的大规模形态感知基准，用于评估MLLMs对形态特征的理解。在此基础上，提出了WSI-LLaVA，一个用于千兆像素WSI理解的新颖框架，采用三阶段训练方法：WSI-文本对齐、特征空间对齐和任务特定指令微调。同时，开发了WSI-Precision和WSI-Relevance两种专门的WSI指标来评估模型性能。

**Result:** 实验结果表明，WSI-LLaVA在所有能力维度上均优于现有模型，尤其在形态分析方面有显著改进，并建立了形态理解与诊断准确性之间的明确关联。

**Conclusion:** WSI-LLaVA通过其新颖的框架和训练方法，显著提升了多模态大型语言模型在全玻片图像分析中的形态理解能力和诊断准确性，为计算病理学带来了突破。

> **ai_Abstract:** 本文针对现有计算病理学中多模态大型语言模型无法全面分析全玻片图像并忽略关键形态特征的局限性，提出了WSI-Bench基准数据集和WSI-LLaVA框架。WSI-LLaVA采用WSI-文本对齐、特征空间对齐和任务特定指令微调的三阶段训练方法，并引入WSI-Precision和WSI-Relevance两种新指标。实验证明WSI-LLaVA在全玻片图像理解和形态分析上显著优于现有模型，有效提升了诊断准确性。

> **摘要翻译:** 计算病理学领域的最新进展已经产生了补丁级多模态大型语言模型（MLLMs），但这些模型受到其无法全面分析全玻片图像（WSIs）以及倾向于绕过病理学家诊断所依赖的关键形态特征的限制。为了解决这些挑战，我们首先引入了WSI-Bench，一个大规模的形态感知基准，包含来自30种癌症类型的9,850个WSI的18万个VQA对，旨在评估MLLMs对诊断准确性至关重要的形态特征的理解。在此基准之上，我们提出了WSI-LLaVA，一个用于千兆像素WSI理解的新颖框架，它采用三阶段训练方法：WSI-文本对齐、特征空间对齐和任务特定指令微调。为了更好地评估病理学背景下的模型性能，我们开发了两种专门的WSI指标：WSI-Precision和WSI-Relevance。实验结果表明，WSI-LLaVA在所有能力维度上均优于现有模型，在形态分析方面有显著改进，建立了形态理解与诊断准确性之间的明确关联。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [373] [Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces](https://arxiv.org/abs/2508.02917)
> *使用大型视觉-语言模型遵循路线指令：低级和全景动作空间的比较*

*Vebjørn Haug Kåsene, Pierre Lison* | **Category: cs.CV, cs.AI, cs.CL, cs.RO** | **Updated: 2025-08-04**

**Keywords:** 视觉-语言导航, 大型视觉-语言模型, 动作空间, 通用模型, Qwen2.5-VL

**Comment:** This paper has been accepted to ICNSLP 2025

> **TL;DR:** 研究表明，通用大型视觉-语言模型（LVLMs）可以进行视觉-语言导航（VLN），但性能仍落后于专门设计的模型，同时支持低级和全景动作空间。

**AI_Comments:** 本文的创新点在于首次系统地探究了通用大型视觉-语言模型在视觉-语言导航任务中的适用性，并对比了其在不同动作空间下的性能。其重要性在于为未来基于通用LVLMs进行VLN研究提供了基线和方向，指出了通用模型虽然有潜力但仍需进一步优化的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言导航（VLN）系统多依赖于专门为导航设计的模型，而通用大型视觉-语言模型（LVLMs）的潜力尚未充分探索。此外，VLN研究中关于低级和全景动作空间哪种更适合通用模型的支持也缺乏深入比较。

**Method:** 本文通过在Room-to-Room (R2R) 数据集上微调开源模型Qwen2.5-VL-3B-Instruct，并评估其在低级和全景动作空间下的性能，来探究通用LVLM是否能有效支持VLN任务以及同时支持两种动作范式。

**Result:** 在R2R测试集上，表现最佳的模型取得了41%的成功率。

**Conclusion:** 研究表明，通用的大型视觉-语言模型可以学习执行视觉-语言导航任务，但其性能仍然落后于专门为该任务设计的模型。同时，这些模型能够支持低级和全景两种动作范式。

> **ai_Abstract:** 本文探讨了通用大型视觉-语言模型（LVLMs）在视觉-语言导航（VLN）任务中的应用潜力，并比较了其在低级和全景动作空间下的表现。研究通过在R2R数据集上微调Qwen2.5-VL-3B-Instruct模型，发现通用LVLMs能学习执行VLN任务并支持两种动作范式，但其性能（在R2R测试集上成功率为41%）仍不及专门为导航优化的模型。

> **摘要翻译:** 视觉-语言导航（VLN）是指使自主机器人通过遵循自然语言指令在陌生环境中导航的任务。尽管近期大型视觉-语言模型（LVLMs）在该任务中展现出潜力，但目前大多数VLM系统依赖于专门为导航设计和优化的模型，这使得通用LVLMs的潜力尚未得到充分探索。此外，虽然较早的VLN方法使用带有自我中心视角和原子动作（如“左转”或“向前移动”）的低级动作空间，但较新的模型倾向于使用具有离散可导航视点的全景动作空间。本文研究了（1）通用LVLMs（未经架构修改或基于模拟器训练的微调）是否能有效支持VLN任务，以及（2）此类模型是否能同时支持低级和全景动作范式。为此，我们对开源模型Qwen2.5-VL-3B-Instruct在Room-to-Room（R2R）数据集上进行了微调，并评估了其在低级和全景动作空间下的实证性能。最终表现最佳的模型在R2R测试集上取得了41%的成功率，这表明通用LVLMs虽然可以学习执行视觉-语言导航，但仍落后于专门为该任务设计的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [376] [ParticleSAM: Small Particle Segmentation for Material Quality Monitoring in Recycling Processes](https://arxiv.org/abs/2508.03490)
> *ParticleSAM：回收过程中材料质量监测的小颗粒分割*

*Yu Zhou, Pelle Thielmann, Ayush Chamoli, Bruno Mirbach, Didier Stricker, Jason Rambach* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** ParticleSAM, 小颗粒分割, 材料质量监测, 回收过程, 建筑材料

**Comment:** 12 pages, 4 figures. Accepted for presentation at EUSIPCO 2025,
  September 8-12, 2025. List of accepted papers available at
  http://cmsworkshops.com/EUSIPCO2025/papers/accepted_papers.php

> **TL;DR:** ParticleSAM 是一种改进的分割基础模型，用于在回收过程中对建筑材料中的小颗粒进行有效分割，并通过新数据集进行验证。

**AI_Comments:** ParticleSAM 的创新之处在于将现有的分割基础模型 SAM 进行了针对性地优化，使其能够有效处理密集小颗粒图像，解决了现有方法在建筑材料回收领域应用中的局限性。同时，通过自动化流程生成新的密集多颗粒数据集，不仅为该领域提供了宝贵的基准，也为后续研究奠定了基础，具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 建筑行业资源消耗巨大，回收建筑材料潜力高，但质量监测仍依赖人工方法。现有视觉机器学习方法不适用于包含数百个小颗粒的图像，因此需要更快、更高效的解决方案。

**Method:** 本文提出了 ParticleSAM，它是对分割基础模型的改进，适用于建筑材料颗粒中常见的小而密集的物体图像。此外，还创建了一个新的密集多颗粒数据集，该数据集通过自动化数据生成和标注流程，从孤立的颗粒图像中模拟生成。

**Result:** 实验结果通过定量和定性实验与原始 SAM 方法进行比较，验证了 ParticleSAM 方法的优势。

**Conclusion:** ParticleSAM 及其创建的新数据集为视觉材料质量控制自动化提供了基准，并且该分割方法在需要小颗粒分割的应用领域（不仅限于建筑业）具有潜在价值。

> **ai_Abstract:** 针对回收过程中建筑材料质量监测中传统人工方法效率低、现有分割模型不适用于密集小颗粒图像的问题，本文提出了 ParticleSAM。该方法是对分割基础模型的改进，能有效处理图像中密集的小颗粒。同时，研究团队通过自动化数据生成和标注流程，创建了一个新的密集多颗粒数据集，为视觉材料质量控制自动化提供了基准。实验结果表明，ParticleSAM 在小颗粒分割方面优于原始 SAM 方法，在建筑及其他需要小颗粒分割的领域具有广泛应用潜力。

> **摘要翻译:** 建筑行业是资源消耗的主要部门。回收建筑材料具有很高的再利用潜力，但骨料的质量监测通常仍采用人工方法。基于视觉的机器学习方法可以为这个问题提供更快、更高效的解决方案，但现有分割方法在设计上不直接适用于包含数百个小颗粒的图像。在本文中，我们提出了 ParticleSAM，它是对分割基础模型的改进，适用于小而密集物体（如建筑材料颗粒中常见物体）的图像。此外，我们借助自动化数据生成和标注流程，从孤立的颗粒图像中模拟创建了一个新的密集多颗粒数据集。该数据集可作为视觉材料质量控制自动化的基准，而我们的分割方法在建筑业之外需要小颗粒分割的应用领域也具有潜在价值。我们的实验结果通过定量和定性实验与原始 SAM 方法进行比较，验证了我们方法的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [378] [How Can Objects Help Video-Language Understanding?](https://arxiv.org/abs/2504.07454)
> *物体如何帮助视频-语言理解？*

*Zitian Tang, Shijie Wang, Junho Cho, Jaewook Yoo, Chen Sun* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态大语言模型, 物体表示, 视频问答, ObjectMLLM, 视觉感知

**Comment:** 

> **TL;DR:** 本文通过引入ObjectMLLM框架，并在六个视频问答基准上进行评估，证实了在多模态大语言模型（MLLMs）中显式集成以物体为中心的表示仍然是必要的，并且将连续的结构化物体信息量化为纯文本是一种有效且数据高效的方法。

**AI_Comments:** 本文的创新点在于提出了ObjectMLLM框架，并验证了在MLLMs中显式集成物体表示的必要性。更重要的是，它发现了一种简单而高效的方法——将结构化物体信息量化为纯文本，这提供了一个将CV模块集成到MLLM的新视角，具有重要的实践价值和启发性。

<details>
  <summary>Details</summary>

**Motivation:** 在多模态大语言模型（MLLMs）中，是否仍然需要显式地表示物体？现有的方法要么隐式建模物体和时空关系，要么仅依赖图像标题而缺少细粒度时空信息。本文旨在回答这个问题。

**Method:** 本文引入了ObjectMLLM框架，该框架能够利用任意计算机视觉算法来提取和集成结构化的视觉表示。研究发现，将连续的、结构化的物体信息量化并表示为纯文本的简单方法表现最佳。

**Result:** 通过在六个视频问答基准上的广泛评估，证实了显式集成以物体为中心的表示仍然是必要的。令人惊讶的是，将连续的结构化物体信息量化并表示为纯文本的简单方法表现最佳，提供了一种数据高效的方法来将其他视觉感知模块集成到MLLM设计中。

**Conclusion:** 在多模态大语言模型中，显式集成以物体为中心的表示是必要的，并且将物体信息量化为纯文本是一种有效且数据高效的集成方式。

> **ai_Abstract:** 本文探讨了在多模态大语言模型（MLLMs）中显式表示物体的重要性。研究人员提出了ObjectMLLM框架，该框架能够集成结构化的视觉表示。通过在六个视频问答基准上的评估，结果表明显式集成以物体为中心的表示是必要的。令人惊讶的是，将连续的物体信息量化为纯文本的简单方法被证明是最有效的，为将其他视觉感知模块集成到MLLM设计中提供了一种数据高效的途径。

> **摘要翻译:** 我们是否仍然需要在多模态大语言模型（MLLMs）中显式地表示物体？一个极端是，预训练编码器将图像转换为视觉标记，通过这些标记可以隐式地建模物体和时空关系。另一个极端是，尽管缺少细粒度的时空信息，但图像标题本身在理解任务中提供了强大的经验性能。为了回答这个问题，我们引入了ObjectMLLM，一个能够利用任意计算机视觉算法提取和整合结构化视觉表示的框架。通过在六个视频问答基准上的广泛评估，我们确认显式集成以物体为中心的表示仍然是必要的。令人惊讶的是，我们观察到将连续的、结构化的物体信息量化并将其表示为纯文本的简单方法表现最佳，提供了一种数据高效的方法来将其他视觉感知模块集成到MLLM设计中。我们的代码和模型已在https://github.com/brown-palm/ObjectMLLM发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [ChartCap: Mitigating Hallucination of Dense Chart Captioning](https://arxiv.org/abs/2508.03164)
> *ChartCap：缓解密集图表字幕中的幻觉现象*

*Junyoung Lim, Jaewoo Ahn, Gunhee Kim* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 图表字幕, 幻觉缓解, 大规模数据集, 视觉一致性分数, 视觉语言模型

**Comment:** ICCV 2025 (Highlight)

> **TL;DR:** ChartCap引入了一个大规模的高质量真实世界图表数据集，并通过新的指标和构建流程，显著减少了图表字幕生成中的幻觉问题。

**AI_Comments:** ChartCap的创新之处在于其大规模、高质量的图表数据集，通过精心的构建管道排除了冗余信息并强调了图表的核心洞察。提出的视觉一致性分数是一个新颖的、不依赖于参考字幕的评估方法，对于衡量图表字幕的质量具有重要意义。这项工作为图表字幕领域提供了宝贵资源和评估工具，有望推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言模型在生成准确、信息丰富且无幻觉的图表字幕方面面临挑战，主要原因在于缺乏大规模、高质量的真实世界图表数据集。现有数据集存在包含图表外信息和未能充分捕捉结构元素及关键洞察的问题。

**Method:** 我们引入了ChartCap，一个包含56.5万张真实世界图表图像和类型特定、密集字幕的大规模数据集。构建ChartCap采用了一个四阶段管道，仅使用图表中的可识别数据生成字幕，并采用基于循环一致性的人工验证来加速质量控制。此外，我们提出了一种新的度量标准——视觉一致性分数（Visual Consistency Score），通过测量从字幕重建的图表与原始图表之间的相似性来评估字幕质量，且独立于参考字幕。

**Result:** 在ChartCap上微调的模型能够持续生成更准确、信息量更大且幻觉更少的字幕，超越了开源模型、专有模型甚至人工标注的字幕。

**Conclusion:** ChartCap数据集和提出的方法有效缓解了图表字幕生成中的幻觉问题，并显著提升了字幕的准确性和信息量。

> **ai_Abstract:** 本文介绍了ChartCap，一个包含56.5万张真实世界图表图像的大规模数据集，旨在解决视觉语言模型在生成无幻觉、准确且信息丰富的图表字幕方面的挑战。ChartCap数据集通过一个四阶段的管道构建，该管道专注于从图表本身提取信息，并采用循环一致性验证来确保质量。此外，论文还提出了一种新的评估指标——视觉一致性分数，用于独立评估字幕质量。实验结果表明，在ChartCap上训练的模型能够显著减少字幕中的幻觉，并生成更优质的字幕，超越了现有模型和人工标注的水平。

> **摘要翻译:** 为图表生成准确、信息丰富且无幻觉的字幕对于视觉语言模型来说仍然具有挑战性，这主要是由于缺乏大规模、高质量的真实世界图表数据集。然而，现有真实世界图表数据集存在包含无法从图表中推断出的无关信息，以及未能充分捕捉结构元素和关键洞察的问题。因此，我们引入了ChartCap，一个包含56.5万张真实世界图表图像的大规模数据集，并配有类型特定、密集的字幕，这些字幕排除了无关信息，并详细突出了结构元素和关键洞察。为了构建ChartCap，我们设计了一个四阶段的管道，该管道仅使用图表中可识别的数据生成字幕，并采用基于循环一致性的人工验证，这在不牺牲准确性的情况下加速了质量控制。此外，我们提出了一种新颖的度量标准——视觉一致性分数（Visual Consistency Score），该分数通过测量从字幕重建的图表与原始图表之间的相似性来评估字幕质量，且独立于参考字幕。大量的实验证实，在ChartCap上微调的模型能够持续生成更准确、信息量更大且幻觉更少的字幕，超越了开源模型、专有模型甚至人工标注的字幕。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [392] [Knowledge Distillation for Underwater Feature Extraction and Matching via GAN-synthesized Images](https://arxiv.org/abs/2504.08253)
> *知识蒸馏用于水下特征提取与匹配通过GAN合成图像*

*Jinghe Yang, Mingming Gong, Ye Pu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 知识蒸馏, 水下特征提取, GAN合成图像, 跨模态学习, VSLAM

**Comment:** 

> **TL;DR:** 通过GAN合成图像，利用跨模态知识蒸馏提高水下特征提取和匹配的鲁棒性。

**AI_Comments:** 本文创新性地结合了GAN合成技术和跨模态知识蒸馏，解决了水下图像质量差导致的特征提取和匹配困难问题。特别是提出了自适应GAN合成方法来模拟水下环境噪声和散射，增强了合成图像的真实性，并有效提升了水下视觉定位和建图的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 水下环境因衰减、散射和“海洋雪”干扰导致图像模糊和噪声，严重影响水下视觉特征提取和匹配的鲁棒性，而AUV在水下探索中依赖视觉方法进行定位和建图。

**Method:** 提出一种自适应GAN合成方法来估计水体参数和噪声分布，生成环境特定的合成水下图像。然后引入一个通用的知识蒸馏框架，将空中特征提取和匹配模型迁移到水下设置。

**Result:** GAN合成方法的评估突出了新组件（GAN合成噪声和前向散射）的重要性。在真实水下序列上，通过VSLAM验证了迁移模型的有效性。

**Conclusion:** 提出的跨模态知识蒸馏方法能有效提高水下浑浊环境中特征提取和匹配的鲁棒性。

> **ai_Abstract:** 本文提出一种通过跨模态知识蒸馏提高水下浑浊环境中特征提取和匹配鲁棒性的方法。通过新颖的自适应GAN合成技术生成环境特定的水下图像，并利用这些图像作为媒介，将空中训练的模型知识迁移到水下应用。实验验证了GAN合成新组件的重要性以及迁移模型在真实水下VSLAM任务中的有效性。

> **摘要翻译:** 水下自主航行器（AUVs）在水下探索中扮演着关键角色。在没有GPS和LiDAR等传统传感器的情况下，基于视觉的方法为定位和建图提供了经济有效的解决方案。然而，由于衰减、散射和“海洋雪”的干扰导致图像模糊和噪声，水下环境对特征提取和匹配提出了严峻挑战。在本文中，我们旨在通过跨模态知识蒸馏方法，利用合成水下图像作为媒介，将空中特征提取和匹配模型迁移到水下环境，从而提高浑浊水下环境中特征提取和匹配的鲁棒性。我们首先提出一种新颖的自适应GAN合成方法，用于估计水体参数和水下噪声分布，以生成特定于环境的合成水下图像。然后，我们引入了一个与不同教师模型兼容的通用知识蒸馏框架。基于GAN的合成评估突出了所提出模型中新组件（即GAN合成噪声和前向散射）的重要性。此外，作为特征提取和匹配的代表性下游应用，VSLAM被用于真实水下序列，以验证迁移模型的有效性。项目页面：https://github.com/Jinghe-mel/UFEN-GAN。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [PyCAT4: A Hierarchical Vision Transformer-based Framework for 3D Human Pose Estimation](https://arxiv.org/abs/2508.02806)
> *PyCAT4: 一种基于分层视觉Transformer的3D人体姿态估计框架*

*Zongyou Yang, Jonathan Loo* | **Category: cs.CV, cs.LG, I.2.10; I.4.8; I.5.4** | **Updated: 2025-08-04**

**Keywords:** 3D人体姿态估计, Transformer, 特征融合, PyCAT4, 深度学习

**Comment:** 10 pages, 20 figures

> **TL;DR:** PyCAT4提出了一种基于Transformer和多尺度特征融合的改进型Pymaf网络，显著提升了3D人体姿态估计的性能。

**AI_Comments:** 该论文通过整合Transformer的自注意力机制和时间融合技术，以及空间金字塔结构，对现有Pymaf网络进行了多方面的优化。其创新点在于将这些先进技术系统地应用于3D人体姿态估计，特别是在特征提取、时间序列处理和多尺度特征融合方面进行了改进。这对于提升复杂场景下人体姿态估计的准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于卷积神经网络结合金字塔网格对齐反馈循环以及基于Transformer的时间分析架构在3D人体姿态估计领域取得的显著进展，本研究旨在深入优化和改进现有的Pymaf网络架构。

**Method:** 本研究提出了PyCAT4模型，主要创新点包括：引入基于自注意力机制的Transformer特征提取网络层以增强低级特征捕获；通过特征时间融合技术增强视频序列中时间信号的理解和捕获；实现空间金字塔结构以进行多尺度特征融合。该模型在COCO和3DPW数据集上进行了验证。

**Result:** 实验结果表明，所提出的改进策略显著增强了网络在人体姿态估计中的检测能力。

**Conclusion:** 所提出的改进策略显著增强了网络在人体姿态估计中的检测能力，进一步推动了人体姿态估计技术的发展。

> **ai_Abstract:** 本研究提出了一种名为PyCAT4的3D人体姿态估计算法，旨在优化和改进现有的Pymaf网络。PyCAT4引入了基于自注意力机制的Transformer特征提取层以捕获低级特征，利用特征时间融合技术处理视频序列中的时间信号，并采用空间金字塔结构实现多尺度特征融合。在COCO和3DPW数据集上的实验验证表明，PyCAT4显著提升了人体姿态估计的检测能力。

> **摘要翻译:** 最近，通过将卷积神经网络（CNN）与金字塔网格对齐反馈循环相结合，3D人体姿态估计的准确性得到了显著提高。此外，通过采用基于Transformer的时间分析架构，计算机视觉领域也取得了创新性突破。鉴于这些进展，本研究旨在深入优化和改进现有的Pymaf网络架构。本文的主要创新包括：(1) 引入基于自注意力机制的Transformer特征提取网络层，以增强低级特征的捕获；(2) 通过特征时间融合技术增强对视频序列中时间信号的理解和捕获；(3) 实现空间金字塔结构，以实现多尺度特征融合，有效平衡不同尺度之间的特征表示差异。本研究获得的PyCAT4新模型在COCO和3DPW数据集上通过实验验证。结果表明，所提出的改进策略显著增强了网络在人体姿态估计中的检测能力，进一步推动了人体姿态估计技术的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [396] [COFFEE: A Shadow-Resilient Real-Time Pose Estimator for Unknown Tumbling Asteroids using Sparse Neural Networks](https://arxiv.org/abs/2508.03132)
> *COFFEE：一种使用稀疏神经网络的未知翻滚小行星抗阴影实时姿态估计器*

*Arion Zimmermann, Soon-Jo Chung, Fred Hadaegh* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 姿态估计, 稀疏神经网络, 抗阴影, 小行星, 实时

**Comment:** in Proc. 75th Int. Astronautical Congress (IAC-24), Milan, Italy,
  Oct. 2024

> **TL;DR:** COFFEE是一种用于未知翻滚小行星的抗阴影实时姿态估计器，它利用稀疏神经网络和对太阳相位角的先验信息，实现了比现有方法更准确、无偏差且更快的姿态估计。

**AI_Comments:** COFFEE的创新之处在于其对阴影鲁棒性的处理，通过利用太阳相位角先验信息和关联轮廓与阴影来提取对阴影运动不变的特征，这对于空间目标姿态估计是一个重要的突破。结合稀疏神经网络和图神经网络的设计，在保证高精度的同时显著提升了计算效率，使其更适用于资源受限的空间硬件。该方法对于空间碎片跟踪、小行星探测等任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在空间中准确估计未知物体的状态是一个关键挑战，应用于空间碎片跟踪和小行星形状估计。现有方法（如SIFT、ORB、AKAZE）实时但姿态估计不准确；现代深度学习方法质量更高但计算资源需求大，不适用于空间硬件。此外，经典和数据驱动方法都不抗物体自身的高度不透明阴影，这些阴影会导致姿态估计出现大偏差，从而可能导致任务失败，尤其是在物体进行混沌翻滚运动时。

**Method:** 本文提出了COFFEE（Celestial Occlusion Fast FEature Extractor），一种利用航天器上常见的太阳跟踪传感器提供的太阳相位角先验信息的实时小行星姿态估计框架。它通过将显著轮廓与其投影阴影关联起来，检测到一组稀疏特征，这些特征对阴影运动不变。然后，联合训练一个稀疏神经网络和一个基于注意力的图神经网络特征匹配模型，以提供连续帧之间的对应关系。

**Result:** COFFEE姿态估计管道被发现是无偏差的，比经典姿态估计管道更准确，并且在合成数据以及翻滚小行星Apophis的渲染图上比其他最先进的深度学习管道快一个数量级。

**Conclusion:** COFFEE成功解决了未知翻滚小行星在阴影存在下的实时姿态估计挑战，提供了无偏差、高精度且计算效率高的解决方案，优于现有的经典和深度学习方法。

> **ai_Abstract:** 本文介绍了COFFEE，一种针对未知翻滚小行星的实时抗阴影姿态估计框架。针对现有方法在精度、计算资源和阴影鲁棒性方面的局限性，COFFEE利用太阳相位角先验信息，通过关联轮廓与阴影来检测稀疏特征，并结合稀疏神经网络和图神经网络进行特征匹配。实验结果表明，COFFEE在合成数据和Apophis渲染图上实现了无偏差、更高精度且计算速度远超现有深度学习方法的姿态估计。

> **摘要翻译:** 在空间中准确估计未知物体的状态是一个关键挑战，其应用范围从空间碎片跟踪到小天体形状估计。实现这一能力的一个必要前提是能够在连续图像流上找到并跟踪特征。现有方法，例如SIFT、ORB和AKAZE，实现了实时但不够准确的姿态估计，而现代深度学习方法则以更高的计算资源需求为代价，产生更高质量的特征，这些资源可能在空间合格硬件上不可用。此外，经典和数据驱动方法都对物体自身高度不透明的阴影不鲁棒。我们发现，随着目标物体的旋转，这些阴影可能导致所得姿态估计出现大的偏差。对于这些物体，实时姿态估计算法中的偏差可能会误导航天器的状态估计器，并导致任务失败，特别是当物体经历混沌翻滚运动时。我们提出了COFFEE，即天体遮挡快速特征提取器（Celestial Occlusion Fast FEature Extractor），一个用于小行星的实时姿态估计框架，旨在利用航天器上普遍可用的太阳跟踪传感器提供的太阳相位角先验信息。通过将显著轮廓与其投影阴影关联，检测到一组稀疏特征，这些特征对阴影的运动是不变的。然后，联合训练一个稀疏神经网络和一个基于注意力的图神经网络特征匹配模型，以提供连续帧之间的对应关系。结果发现，该姿态估计管道是无偏差的，比经典姿态估计管道更准确，并且在合成数据以及翻滚小行星Apophis的渲染图上比其他最先进的深度学习管道快一个数量级。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [397] [CutPaste&Find: Efficient Multimodal Hallucination Detector with Visual-aid Knowledge Base](https://arxiv.org/abs/2502.12591)
> *CutPaste&Find：基于视觉辅助知识库的高效多模态幻觉检测器*

*Cong-Duy Nguyen, Xiaobao Wu, Duc Anh Vu, Shuai Zhao, Thong Nguyen, Anh Tuan Luu* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型视觉-语言模型, 幻觉检测, 视觉辅助知识库, 效率, 多模态

**Comment:** 

> **TL;DR:** 提出CutPaste&Find，一个轻量级、免训练的LVLM幻觉检测框架，通过视觉辅助知识库实现高效且经济的检测，无需昂贵的LVLM推理。

**AI_Comments:** 这项工作通过提出一个轻量级、免训练且不依赖昂贵LVLM推理的框架，有效解决了LVLM幻觉检测的实用性问题。其创新点在于引入了视觉辅助知识库和相似度分数优化，显著提高了检测效率和成本效益，对于大规模和离线应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）易产生幻觉（如物体幻觉），而现有检测方法依赖昂贵的API调用和迭代LVLM验证，不适用于大规模或离线使用。

**Method:** 提出CutPaste&Find框架，其轻量级且免训练。该方法利用现成的视觉和语言模块进行多步验证，无需LVLM推理。核心是一个视觉辅助知识库，编码实体-属性关系和图像表示。引入缩放因子以优化相似度分数。

**Result:** 在POPE和R-Bench等基准数据集上，CutPaste&Find实现了有竞争力的幻觉检测性能，并且比现有方法更高效、更具成本效益。

**Conclusion:** CutPaste&Find提供了一种有效且高效的解决方案，用于检测LVLM生成的幻觉，克服了现有方法的局限性。

> **ai_Abstract:** 本文提出了CutPaste&Find，一个轻量级、免训练的框架，旨在高效检测大型视觉-语言模型（LVLMs）中的多模态幻觉。该框架通过利用现成的视觉和语言模块以及一个核心的视觉辅助知识库进行多步验证，避免了昂贵的LVLM推理和API调用。实验证明，CutPaste&Find在保持竞争性检测性能的同时，显著提高了效率和成本效益，解决了现有幻觉检测方法的实用性问题。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）展示了令人印象深刻的多模态推理能力，但它们仍然容易产生幻觉，特别是物体幻觉，即在生成的描述中捏造不存在的物体或错误的属性。现有的检测方法取得了强大的性能，但它们严重依赖昂贵的API调用和基于LVLM的迭代验证，这使得它们不适用于大规模或离线使用。为了解决这些限制，我们提出了CutPaste&Find，一个轻量级且免训练的框架，用于检测LVLM生成输出中的幻觉。我们的方法利用现成的视觉和语言模块，无需LVLM推理即可高效地执行多步验证。我们框架的核心是一个视觉辅助知识库，它编码了丰富的实体-属性关系和相关的图像表示。我们引入了一个缩放因子来优化相似度分数，即使对于真实图像-文本对也能缓解次优对齐值的问题。在包括POPE和R-Bench在内的基准数据集上的全面评估表明，CutPaste&Find在实现有竞争力的幻觉检测性能的同时，比以前的方法显著更高效且更具成本效益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [401] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
> *FastInit：用于时间一致性视频生成的快速噪声初始化*

*Chengyu Bai, Yuming Li, Zhongyu Zhao, Jintao Chen, Peidong Jia, Qi She, Ming Lu, Shanghang Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-06-19**

**Keywords:** 视频生成, 扩散模型, 时间一致性, 噪声初始化, VNPNet

**Comment:** 

> **TL;DR:** FastInit提出了一种快速噪声初始化方法，通过学习一个视频噪声预测网络（VNPNet），在单次前向传播中生成精炼噪声，从而在提高视频生成效率的同时实现高时间一致性，避免了传统迭代细化方法的计算开销。

**AI_Comments:** FastInit的创新之处在于通过引入VNPNet将耗时的迭代噪声细化过程转化为高效的单次前向传播，从而显著提升了视频生成的时间一致性和效率。这提供了一个实用的解决方案，可直接应用于现有文本到视频模型，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在视频生成方面取得了显著进展，但实现高时间一致性仍是一个挑战。现有的迭代细化初始噪声的方法（如FreeInit）虽然能提高一致性，但会显著增加计算成本。

**Method:** 本文提出了FastInit，一种快速噪声初始化方法，无需迭代细化。FastInit学习了一个视频噪声预测网络（VNPNet），该网络以随机噪声和文本提示作为输入，通过单次前向传播生成精炼噪声。为了训练VNPNet，研究人员创建了一个包含文本提示、随机噪声和精炼噪声对的大规模数据集。

**Result:** FastInit大大提高了视频生成的效率，同时实现了帧间的高时间一致性。对各种文本到视频模型的广泛实验表明，该方法持续提高了生成视频的质量和时间一致性。

**Conclusion:** FastInit不仅在视频生成方面提供了实质性改进，还提供了一个可在推理过程中直接应用的实用解决方案。

> **ai_Abstract:** 本文提出了FastInit，一种快速噪声初始化方法，旨在解决扩散模型视频生成中时间一致性差和现有迭代方法计算成本高的问题。FastInit通过训练一个视频噪声预测网络（VNPNet），实现在单次前向传播中从随机噪声和文本提示生成精炼噪声，从而避免了耗时的迭代细化。实验证明，FastInit显著提高了视频生成的效率、质量和时间一致性，并能直接应用于推理过程。

> **摘要翻译:** 视频生成随着扩散模型的发展取得了显著进展；然而，实现高时间一致性仍然是一项具有挑战性的任务。最近，FreeInit发现了一个训练-推理差距，并引入了一种在推理过程中迭代细化初始噪声的方法。然而，迭代细化显著增加了视频生成相关的计算成本。在本文中，我们介绍了FastInit，一种快速噪声初始化方法，它消除了迭代细化的需要。FastInit学习了一个视频噪声预测网络（VNPNet），该网络以随机噪声和文本提示作为输入，通过单次前向传播生成精炼的噪声。因此，FastInit大大提高了视频生成的效率，同时实现了帧间的高时间一致性。为了训练VNPNet，我们创建了一个包含文本提示、随机噪声和精炼噪声对的大规模数据集。对各种文本到视频模型的广泛实验表明，我们的方法持续提高了生成视频的质量和时间一致性。FastInit不仅在视频生成方面提供了实质性改进，还提供了一个可在推理过程中直接应用的实用解决方案。代码和数据集将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [404] [Quality Versus Sparsity in Image Recovery by Dictionary Learning Using Iterative Shrinkage](https://arxiv.org/abs/2508.03492)
> *使用迭代收缩的字典学习在图像恢复中的质量与稀疏性权衡*

*Mohammadsadegh Khoshghiaferezaee, Moritz Krauth, Shima Shabani, Michael Breuß* | **Category: cs.CV, 65K05, 68T30, I.4.5; I.2.6** | **Updated: 2025-08-05**

**Keywords:** 稀疏字典学习, 图像恢复, 迭代收缩, 稀疏性, 恢复质量

**Comment:** 6 pages, 4 figures, 3 tables, IEEE-IPTA,2025

> **TL;DR:** 本研究探讨了稀疏字典学习中稀疏度对图像恢复质量的影响，发现高稀疏度通常不会损害恢复质量，并且不同的优化方法会导致不同的稀疏度方案。

**AI_Comments:** 这篇论文解决了稀疏字典学习中一个关键的实际问题：稀疏度与恢复质量之间的权衡。其创新之处在于通过实验证明了高稀疏度在不牺牲恢复质量的情况下是可行的，这对于需要高效存储和处理的应用具有重要意义。同时，文章也指出了不同优化方法会导致不同的稀疏度方案，为后续研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏字典学习（SDL）在图像处理中很重要，但存在一个问题：在SDL中应该强制执行多大程度的稀疏性才不会损害恢复质量，因为稀疏性对于高效处理和存储至关重要。

**Method:** 论文关注通过多种优化方法获得的解的稀疏性，并利用迭代收缩方法作为一类强大的算法进行研究。

**Result:** 研究发现，不同的优化方法会产生不同的稀疏度方案。此外，结果表明，高稀疏度通常不会损害恢复质量，即使恢复的图像与学习数据库大相径庭。

**Conclusion:** 本研究得出结论，在稀疏字典学习的图像恢复中，高稀疏度通常不会损害恢复质量，并且稀疏度方案取决于所使用的优化方法。

> **ai_Abstract:** 本研究探讨了稀疏字典学习（SDL）在图像恢复中的应用，特别关注稀疏度与恢复质量之间的关系。文章指出，SDL可视为非光滑优化问题，并利用迭代收缩等多种优化方法分析了所得解的稀疏性。研究发现，不同的优化方法会导致不同的稀疏度方案。最重要的是，论文证明了高稀疏度通常不会损害图像恢复质量，即使恢复图像与原始学习数据库有较大差异。

> **摘要翻译:** 稀疏字典学习（SDL）是一种基本技术，对许多图像处理任务都很有用。我们以图像恢复为例，其中SDL可以看作是一个非光滑优化问题。对于这类问题，迭代收缩方法代表了一类强大的算法，是当前研究的热点。稀疏性是学习到的解的一个重要特性，因为正是稀疏性使得后续处理或存储变得高效。稀疏性意味着恢复的图像是由尽可能少的字典元素组合而成的。因此，问题出现了，在SDL中应该强制执行多大程度的稀疏性才不会损害恢复质量。在本文中，我们关注使用各种优化方法可以获得的解的稀疏性。结果表明，根据所使用的方法，存在不同的稀疏度方案。此外，我们说明了高稀疏度通常不会损害恢复质量，即使恢复的图像与学习数据库大相径庭。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [406] [Gradient as Conditions: Rethinking HOG for All-in-one Image Restoration](https://arxiv.org/abs/2504.09377)
> *梯度作为条件：重新思考HOG用于一体化图像恢复*

*Jiawei Wu, Zhifei Yang, Zhe Wang, Zhi Jin* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像恢复, HOG, Transformer, 一体化图像恢复, 梯度

**Comment:** 

> **TL;DR:** 提出HOGformer，一个基于Transformer的模型，利用HOG特征进行一体化图像恢复，实现SOTA性能。

**AI_Comments:** 本文的创新点在于将经典的HOG特征作为一种显式且可解释的先验引入到一体化图像恢复任务中，而非依赖隐式学习。这种方法不仅提升了模型在复杂和未见场景下的泛化能力，也为图像恢复任务提供了一种新的、可解释的条件指导范式。HOG损失的引入也进一步强调了对结构和边缘细节的关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的一体化图像恢复（AIR）方法依赖隐式学习的先验，可能导致特征表示纠缠，并在复杂或未见场景中性能受阻。本文观察到HOG作为经典梯度表示，在不同退化之间具有强大的判别能力，可作为AIR的有力且可解释的先验。

**Method:** 提出HOGformer，一个基于Transformer的模型，集成了可学习的HOG特征用于退化感知恢复。核心是动态HOG感知自注意力（DHOGSA）机制，它根据HOG描述符编码的退化特定线索自适应地建模长距离空间依赖。为适应一体化图像恢复中退化的异质性，提出动态交互前馈（DIFF）模块，促进通道-空间交互。此外，提出HOG损失以显式增强结构保真度和边缘锐度。

**Result:** 在包括恶劣天气和自然退化在内的各种基准测试中，HOGformer实现了最先进的性能，并很好地推广到复杂的真实世界场景。

**Conclusion:** HOG作为一种可解释的梯度先验，能够有效指导一体化图像恢复。HOGformer通过集成HOG特征和设计特定的模块，在多种退化场景下取得了优异的恢复效果。

> **ai_Abstract:** 本文提出HOGformer，一个将HOG特征作为显式退化条件的Transformer模型，用于一体化图像恢复。针对现有方法隐式先验的局限性，HOGformer通过动态HOG感知自注意力机制和动态交互前馈模块，有效利用HOG的判别能力来指导恢复过程，并引入HOG损失以提升细节。实验证明HOGformer在多种退化场景下均达到SOTA性能。

> **摘要翻译:** 一体化图像恢复（AIR）旨在通过利用信息丰富的退化条件来指导恢复过程，从而在统一模型中解决各种退化问题。然而，现有方法通常依赖隐式学习的先验，这可能导致特征表示纠缠，并在复杂或未见场景中阻碍性能。作为一种经典的梯度表示，我们观察到定向梯度直方图（HOG）在各种退化中具有强大的判别能力，使其成为AIR的强大且可解释的先验。基于这一见解，我们提出了HOGformer，一个基于Transformer的模型，它集成了可学习的HOG特征用于退化感知恢复。HOGformer的核心是动态HOG感知自注意力（DHOGSA）机制，该机制根据HOG描述符编码的退化特定线索自适应地建模长距离空间依赖。为了进一步适应AIR中退化的异质性，我们提出了一个动态交互前馈（DIFF）模块，该模块促进通道-空间交互，从而在各种退化下实现鲁棒的特征变换。此外，我们提出了HOG损失以明确增强结构保真度和边缘锐度。在包括恶劣天气和自然退化在内的各种基准测试上进行的广泛实验表明，HOGformer实现了最先进的性能，并很好地推广到复杂的真实世界场景。代码可在https://github.com/Fire-friend/HOGformer 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [KAN or MLP? Point Cloud Shows the Way Forward](https://arxiv.org/abs/2504.13593)
> *KAN还是MLP？点云指明方向*

*Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 点云分析, Kolmogorov-Arnold网络, KANs, MLP, 3D视觉

**Comment:** 

> **TL;DR:** 本文提出了PointKAN，将Kolmogorov-Arnold网络（KANs）应用于点云分析，通过引入几何仿射模块和高效KANs，解决了传统MLP在点云处理中的局限性，并在多个基准数据集上超越了PointMLP，同时显著降低了参数量和计算复杂度。

**AI_Comments:** 这项工作创新性地将新兴的Kolmogorov-Arnold网络（KANs）引入到三维点云分析领域，解决了传统MLP在特征捕获和效率上的痛点。通过引入几何仿射模块和高效KANs的变体，该模型不仅提升了性能，还显著优化了资源消耗，为点云理解和3D视觉研究开辟了新的方向。其在少样本学习上的出色表现也预示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多层感知机（MLPs）在点云分析中作为基本架构组件，但在处理复杂几何结构时，其固定的激活函数难以有效捕获局部几何特征，且存在参数效率低下和模型冗余高的问题。

**Method:** 本文提出了PointKAN，将Kolmogorov-Arnold网络（KANs）应用于点云分析。PointKAN首先引入几何仿射模块（GAM）来转换局部特征，增强对几何变化的鲁棒性。接着，在局部特征处理（LFP）中，使用并行结构提取组级特征和全局上下文。这些特征在全局特征处理（GFP）中组合并处理，通过重复操作逐步扩展感受野。为解决标准KANs参数量大和计算效率低的问题，PointKAN-elite变体开发了高效KANs（Efficient-KANs）。

**Result:** 实验结果表明，PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上均优于PointMLP，尤其在少样本学习任务中表现出色。此外，PointKAN显著降低了参数量和计算复杂度（FLOPs）。

**Conclusion:** 本文突出了基于KANs的架构在3D视觉中的潜力，并为点云理解研究开辟了新途径。

> **ai_Abstract:** 本文提出了PointKAN，一种将Kolmogorov-Arnold网络（KANs）应用于点云分析的新型架构，旨在克服传统MLP在处理复杂几何结构时的局限性。PointKAN通过引入几何仿射模块（GAM）增强鲁棒性，并采用并行结构在局部特征处理（LFP）中捕获多尺度特征。为提高效率，PointKAN-elite版本集成了高效KANs。实验证明，PointKAN在多个点云基准数据集上性能优于PointMLP，尤其在少样本学习中表现突出，并显著降低了模型参数和计算成本，展示了KANs在3D视觉领域的巨大潜力。

> **摘要翻译:** 多层感知机（MLPs）因其有效的特征学习机制，已成为点云分析中基本的架构组件之一。然而，在处理点云中复杂的几何结构时，MLPs固定的激活函数难以有效捕获局部几何特征，同时存在参数效率低下和模型冗余高的问题。在本文中，我们提出了PointKAN，将Kolmogorov-Arnold网络（KANs）应用于点云分析任务，以研究其在分层特征表示中的有效性。首先，我们引入了一个几何仿射模块（GAM）来转换局部特征，提高了模型对几何变化的鲁棒性。其次，在局部特征处理（LFP）中，一个并行结构同时提取组级特征和全局上下文，为精细细节和整体结构提供了丰富的表示。最后，这些特征在全局特征处理（GFP）中组合并处理。通过重复这些操作，感受野逐渐扩展，使模型能够捕获点云的完整几何信息。为了克服标准KANs高参数量和计算效率低的问题，我们在PointKAN-elite变体中开发了高效KANs，这显著减少了参数量，同时保持了准确性。实验结果表明，PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上均优于PointMLP，尤其在少样本学习任务中表现出色。此外，PointKAN显著降低了参数量和计算复杂度（FLOPs）。这项工作突出了基于KANs的架构在3D视觉中的潜力，并为点云理解研究开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [Beyond Isolated Words: Diffusion Brush for Handwritten Text-Line Generation](https://arxiv.org/abs/2508.03256)
> *超越孤立词：用于手写文本行生成的扩散画笔*

*Gang Dai, Yifan Zhang, Yutao Qin, Qiangya Guo, Shuangping Huang, Shuicheng Yan* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 手写文本生成, 扩散模型, 文本行生成, 风格学习, 内容准确性

**Comment:** To appear in ICCV2025

> **TL;DR:** DiffBrush是一种新的扩散模型，通过解耦风格学习和多尺度内容学习，解决了现有手写文本生成方法仅关注孤立词的问题，实现了高质量的手写文本行生成。

**AI_Comments:** 这项工作通过引入扩散模型和独特的内容解耦及多尺度学习策略，有效地解决了手写文本行生成中风格连贯性和内容准确性的关键挑战，超越了传统孤立词生成方法的局限性，在手写文本合成领域具有重要的创新意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有手写文本生成方法主要关注孤立词，但真实手写文本不仅需要关注单个词，还需要关注词之间的关系（如垂直对齐和水平间距）。因此，生成整个文本行是一项更具前景和全面的任务，但面临建模复杂风格模式和保持内容准确性的挑战。

**Method:** 提出了一种名为DiffBrush的新型扩散模型，用于手写文本行生成。它通过两种关键策略在风格模仿和内容准确性方面表现出色：1) 内容解耦风格学习，通过使用列向和行向掩码将风格与内容解耦，以更好地捕捉词内和词间风格模式；2) 多尺度内容学习，采用行和词判别器来确保文本内容的全局连贯性和局部准确性。

**Result:** 大量实验表明，DiffBrush在生成高质量文本行方面表现出色，特别是在风格再现和内容保持方面。

**Conclusion:** DiffBrush通过其独特的内容解耦风格学习和多尺度内容学习策略，有效解决了手写文本行生成的挑战，实现了高质量的文本行生成，并在风格再现和内容保持方面优于现有方法。

> **ai_Abstract:** 本文提出了一种名为DiffBrush的新型扩散模型，用于解决现有手写文本生成方法无法有效处理整个文本行的问题。DiffBrush通过内容解耦风格学习和多尺度内容学习两种策略，能够准确建模复杂的词内和词间风格模式，并保持内容的高度准确性。实验证明，该模型在生成高质量手写文本行方面，尤其是在风格再现和内容保持方面，表现出卓越的性能。

> **摘要翻译:** 现有手写文本生成方法主要关注孤立词。然而，真实手写文本不仅需要关注单个词，还需要关注它们之间的关系，例如垂直对齐和水平间距。因此，生成整个文本行成为一项更具前景和全面的任务。然而，这项任务带来了严峻的挑战，包括准确建模包含词内和词间关系的复杂风格模式，以及在众多字符中保持内容准确性。为了应对这些挑战，我们提出了DiffBrush，一种新颖的基于扩散模型的手写文本行生成模型。与现有方法不同，DiffBrush通过两种关键策略在风格模仿和内容准确性方面表现出色：(1) 内容解耦风格学习，它将风格与内容解耦，通过使用列向和行向掩码更好地捕捉词内和词间风格模式；以及 (2) 多尺度内容学习，它采用行和词判别器来确保文本内容的全局连贯性和局部准确性。大量实验表明，DiffBrush在生成高质量文本行方面表现出色，特别是在风格再现和内容保持方面。代码可在 https://github.com/dailenson/DiffBrush 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org/abs/2504.17432)
> *打破模态壁垒：基于多模态大语言模型的通用嵌入学习*

*Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态嵌入学习, MLLM, 知识蒸馏, 硬负样本, 判别性表示

**Comment:** 13 pages, 8 figures, Accepted by ACM MM2025, Project page:
  https://garygutc.github.io/UniME

> **TL;DR:** UniME是一个两阶段框架，利用MLLM学习通用判别性多模态嵌入，通过知识蒸馏和硬负样本增强指令微调，在多项任务上表现优异。

**AI_Comments:** UniME的创新之处在于其结合了LLM的知识蒸馏和硬负样本增强的指令微调，有效提升了MLLM在多模态表示学习中的判别性和组合性，打破了传统CLIP的局限，为通用多模态嵌入学习提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** CLIP框架在多模态表示学习中存在文本标记截断、图像-文本编码孤立和组合性不足的局限性。尽管MLLM在视觉-语言理解方面有进展，但其可迁移多模态表示学习的潜力尚未充分挖掘。

**Method:** 本文提出了UniME（通用多模态嵌入）框架，分为两个阶段：第一阶段，从强大的LLM教师模型进行文本判别知识蒸馏，增强MLLM语言组件的嵌入能力。第二阶段，引入硬负样本增强指令微调，通过缓解假负样本污染并采样多个硬负样本，提升判别能力和指令遵循能力。

**Result:** UniME在MMEB基准和多个检索任务（包括短文本、长文本和组合检索）上均取得了持续的性能提升，展现出卓越的判别和组合能力。

**Conclusion:** UniME框架有效地克服了现有方法的局限性，实现了通用的、高性能的多模态嵌入学习，并在多项任务上表现出优越的判别和组合能力。

> **ai_Abstract:** 本文提出了UniME，一个两阶段框架，利用多模态大语言模型（MLLMs）学习通用的、判别性的多模态嵌入，以解决CLIP框架的局限性（如文本截断和组合性不足）以及MLLM在可迁移表示学习方面的潜力未充分挖掘的问题。UniME通过LLM的知识蒸馏增强MLLM的语言组件，并通过硬负样本增强指令微调提升判别能力和指令遵循能力。实验证明UniME在多项检索任务和MMEB基准上均表现出优越的性能，尤其在判别和组合能力方面。

> **摘要翻译:** 对比语言-图像预训练（CLIP）框架已成为多模态表示学习中广泛使用的方法，特别是在图像-文本检索和聚类方面。然而，其效率受到三个关键限制的制约：（1）文本标记截断，（2）孤立的图像-文本编码，以及（3）由于词袋行为导致的组合性不足。尽管最近的多模态大型语言模型（MLLMs）在广义视觉-语言理解方面取得了显著进展，但它们学习可迁移多模态表示的潜力仍未得到充分探索。在这项工作中，我们提出了UniME（通用多模态嵌入），一个新颖的两阶段框架，利用MLLMs学习用于各种下游任务的判别性表示。在第一阶段，我们从一个强大的基于LLM的教师模型进行文本判别知识蒸馏，以增强MLLM语言组件的嵌入能力。在第二阶段，我们引入了硬负样本增强指令微调，以进一步推进判别性表示学习。具体来说，我们首先减轻假负样本污染，然后在一个批次中为每个实例采样多个硬负样本，强制模型关注有挑战性的样本。这种方法不仅提高了判别能力，还增强了下游任务中的指令遵循能力。我们在MMEB基准和多个检索任务（包括短文本和长文本检索和组合检索）上进行了广泛的实验。结果表明，UniME在所有任务上都取得了持续的性能提升，展示出卓越的判别和组合能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [Uint: Building Uint Detection Dataset](https://arxiv.org/abs/2508.03139)
> *Uint：构建建筑单元检测数据集*

*Haozhou Zhai, Yanzhe Gao, Tianjiang Hu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 火灾检测, 建筑单元, 合成数据, 无人机, 数据集

**Comment:** 

> **TL;DR:** 本文介绍了一个名为Uint的合成数据集，用于解决火灾场景中建筑单元检测标注数据稀缺的问题，以提升火灾预警和应急救援的计算机视觉模型性能。

**AI_Comments:** 该论文通过合成数据解决了火灾检测领域一个实际且关键的数据稀缺问题。利用多种增强技术和大型模型生成火灾效果，展示了创建逼真多样化数据集的创新方法。这种方法对于降低真实世界数据收集的危险性和成本具有重要意义，是对应急响应计算机视觉领域的一个宝贵贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有火灾相关数据中，专门针对建筑单元的标注数据严重不足，而这类数据对于训练鲁棒的计算机视觉模型（特别是火灾预警和应急救援任务）至关重要。

**Method:** 研究人员引入了一个由无人机捕获的建筑单元标注数据集。该数据集通过使用真实多层场景构建背景，结合运动模糊和亮度调整以增强图像真实性，模拟无人机在各种情况下的拍摄条件，并利用大型模型在不同位置生成火灾效果等多种增强技术构建而成。

**Result:** 通过该方法生成了一个包含1,978张图像的合成数据集，涵盖了广泛的建筑场景。该数据集能够有效提高火灾单元检测的泛化能力，提供多场景和可扩展的数据，并降低收集真实火灾数据相关的风险和成本。

**Conclusion:** 该合成数据集解决了火灾场景中建筑单元检测数据稀缺的问题，为提升火灾单元检测模型的性能和效率提供了宝贵资源。

> **ai_Abstract:** 本文针对火灾检测中建筑单元标注数据稀缺的问题，提出了一个名为Uint的合成数据集。该数据集通过无人机捕获的图像，结合真实多层背景、运动模糊、亮度调整、模拟无人机拍摄条件以及大型模型生成的火灾效果等多种增强技术构建。该合成数据集包含1,978张图像，旨在提高火灾单元检测模型的泛化能力，提供多场景和可扩展的数据，同时降低收集真实火灾数据的风险和成本。

> **摘要翻译:** 火灾场景数据集对于训练鲁棒的计算机视觉模型至关重要，尤其是在火灾预警和应急救援等任务中。然而，在目前可用的火灾相关数据中，专门针对建筑单元的标注数据严重不足。为了解决这个问题，我们引入了一个由无人机捕获的建筑单元标注数据集，该数据集结合了多种增强技术。我们使用真实的多层场景构建背景，结合运动模糊和亮度调整以增强捕获图像的真实性，模拟无人机在各种情况下的拍摄条件，并利用大型模型在不同位置生成火灾效果。通过这种方法生成的合成数据集涵盖了广泛的建筑场景，总计1,978张图像。该数据集可以有效提高火灾单元检测的泛化能力，提供多场景和可扩展的数据，同时降低收集真实火灾数据相关的风险和成本。该数据集可在 https://github.com/boilermakerr/FireUnitData 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [LMME3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs](https://arxiv.org/abs/2504.20466)
> *LMME3DHF：基于LMM的多模态3D人脸生成基准测试与评估*

*Woo Yi Yang, Jiarui Wang, Sijing Wu, Huiyu Duan, Yuxin Zhu, Liu Yang, Kang Fu, Guangtao Zhai, Xiongkuo Min* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D人脸生成, 质量评估, 大型多模态模型, 基准测试, LMME3DHF

**Comment:** 

> **TL;DR:** 本文介绍了LMME3DHF，一个基于大型多模态模型（LMM）的3D人脸评估指标，通过构建大型基准数据集Gen3DHF，实现了对AI生成3D人脸质量和真实感的准确预测、失真感知问答和显著性预测，并达到了最先进的性能。

**AI_Comments:** 本文通过构建大规模基准数据集Gen3DHF和提出基于LMM的评估指标LMME3DHF，为AI生成3D人脸的质量评估提供了一个创新且有效的解决方案。其创新点在于结合了大规模多模态数据和先进的LMM技术，以克服传统评估方法的主观性限制。该研究对于推动3D人脸生成技术在多媒体、VR等领域的应用具有重要意义，尤其是在确保生成内容质量和真实感方面。

<details>
  <summary>Details</summary>

**Motivation:** 由于人类感知的主观性和对面部特征固有的感知敏感性，评估AI生成3D人脸的质量和真实感仍然是一个重大挑战。

**Method:** 本文首先引入了Gen3DHF，一个包含2,000个AI生成3D人脸视频以及4,000个平均意见得分（MOS）、2,000个失真感知显著图和失真描述的大规模基准数据集。在此基础上，提出了LMME3DHF，一个基于大型多模态模型（LMM）的3D人脸评估指标，能够进行质量和真实感分数预测、失真感知视觉问答和失真感知显著性预测。

**Result:** 实验结果表明，LMME3DHF在准确预测AI生成3D人脸质量分数以及有效识别失真感知显著区域和失真类型方面，均超越了现有方法，达到了最先进的性能，并与人类感知判断保持高度一致。

**Conclusion:** LMME3DHF作为一种基于LMM的3D人脸评估指标，结合了大规模基准数据集Gen3DHF，有效解决了AI生成3D人脸质量评估的挑战，并在多项任务上取得了显著的SOTA性能，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文针对AI生成3D人脸的质量评估挑战，提出了LMME3DHF，一个基于大型多模态模型（LMM）的评估指标。研究首先构建了大规模基准数据集Gen3DHF，包含了AI生成3D人脸视频及其感知质量评分和失真信息。基于Gen3DHF，LMME3DHF能够准确预测3D人脸的质量和真实感分数，并进行失真感知视觉问答和显著性预测。实验证明，LMME3DHF在性能上超越了现有方法，与人类感知判断高度一致，达到了最先进水平。

> **摘要翻译:** 生成式人工智能的快速发展使得3D人脸（HFs）的创建成为可能，应用于媒体制作、虚拟现实、安全、医疗保健和游戏开发等领域。然而，由于人类感知的主观性以及对面部特征固有的感知敏感性，评估这些AI生成3D人脸的质量和真实感仍然是一个重大挑战。为此，我们对AI生成3D人脸的质量评估进行了全面研究。我们首先引入了Gen3DHF，一个大规模基准数据集，包含2,000个AI生成3D人脸视频，以及在质量和真实性两个维度上收集的4,000个平均意见得分（MOS）、2,000个失真感知显著图和失真描述。基于Gen3DHF，我们提出了LMME3DHF，一个基于大型多模态模型（LMM）的3D人脸评估指标，能够进行质量和真实性分数预测、失真感知视觉问答和失真感知显著性预测。实验结果表明，LMME3DHF达到了最先进的性能，在准确预测AI生成3D人脸的质量分数以及有效识别失真感知显著区域和失真类型方面，均超越了现有方法，同时与人类感知判断保持高度一致。Gen3DHF数据库和LMME3DHF都将在论文发表后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [429] [How Diffusion Prior Landscapes Shape the Posterior in Blind Deconvolution](https://arxiv.org/abs/2508.02923)
> *扩散先验景观如何影响盲反卷积中的后验分布*

*Minh-Hai Nguyen, Edouard Pauwels, Pierre Weiss* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 盲反卷积, 扩散先验, 最大后验估计, 后验景观, 局部最小值

**Comment:** 

> **TL;DR:** 在盲反卷积中，最大后验（MAP）估计与扩散先验结合时，倾向于产生模糊解；本研究发现，通过良好的局部初始化以找到后验分布的局部最小值，可以有效获得清晰的自然图像。

**AI_Comments:** 这篇论文深入探讨了扩散先验在盲反卷积中MAP估计局限性的根源，并提出了通过局部初始化到后验局部最小值来克服这一问题的新视角。其创新之处在于结合了扩散模型和对后验景观的细致分析，为设计更有效的图像先验和优化策略提供了理论依据和实践指导，对于图像去模糊领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的最大后验（MAP）估计在盲反卷积中与稀疏性促进图像先验结合时，倾向于产生模糊的解决方案，从而限制了其有效性。

**Method:** 本文使用基于扩散的先验重新审视了盲反卷积中的MAP估计问题。通过对先验似然景观进行实证检验，并在此基础上对盲去模糊后验进行了理论分析。研究发现通过梯度下降法可以找到后验的局部最小值，并通过数值实验验证了这些分析和发现。

**Result:** 扩散先验的似然景观显示，模糊图像往往具有更高的似然，并且景观中包含许多对应自然图像的局部极小值。理论分析表明，MAP估计器倾向于产生锐利滤波器（接近狄拉克delta函数）和模糊解。然而，通过梯度下降获得的后验局部极小值对应于真实的自然图像，能够有效解决盲反卷积问题。

**Conclusion:** 克服MAP估计在盲反卷积中产生模糊解的局限性，需要对后验景观中的局部最小值进行良好的局部初始化。

> **ai_Abstract:** 本文研究了扩散先验景观如何影响盲反卷积中的最大后验（MAP）估计。研究发现，传统的MAP估计结合稀疏先验时易产生模糊结果。作者通过实证和理论分析，揭示了扩散先验的似然景观特性，即模糊图像具有高似然且存在对应自然图像的局部极小值。虽然MAP估计倾向于模糊解，但通过梯度下降获得的后验局部最小值能够产生清晰真实的图像。研究强调了良好的局部初始化对于克服MAP局限性的重要性，并通过数值实验验证了这些发现。

> **摘要翻译:** 最大后验 (MAP) 估计是盲反卷积中广泛使用的框架，用于从模糊观测中恢复清晰图像。估计的图像和模糊滤波器被定义为后验分布的最大值。然而，当与促进稀疏性的图像先验结合时，MAP 估计已被证明倾向于模糊解，从而限制了其有效性。在本文中，我们使用基于扩散的先验（一类捕获真实图像分布的模型）重新审视了这一结果。通过对先验似然景观的实证检验，我们揭示了两个关键属性：首先，模糊图像倾向于具有更高的似然；其次，景观包含许多对应于自然图像的局部极小值。基于这些见解，我们对盲去模糊后验进行了理论分析。这表明 MAP 估计器倾向于产生锐利滤波器（接近狄拉克 delta 函数）和模糊解。然而，后验的局部极小值（可以通过梯度下降获得）对应于真实的自然图像，有效地解决了盲反卷积问题。我们的发现表明，克服 MAP 的局限性需要对后验景观中的局部极小值进行良好的局部初始化。我们通过数值实验验证了我们的分析，证明了我们的见解在设计改进的先验和优化技术方面的实际意义。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [432] [Prototype-Enhanced Confidence Modeling for Cross-Modal Medical Image-Report Retrieval](https://arxiv.org/abs/2508.03494)
> *跨模态医学图像-报告检索中的原型增强置信度建模*

*Shreyank N Gowda, Xiaobo Jin, Christian Wagner* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 跨模态检索, 医学图像, 原型学习, 置信度建模, 语义对齐

**Comment:** 

> **TL;DR:** 提出PECM框架，通过原型增强和置信度建模，显著提升了跨模态医学图像-报告检索的精度和可靠性，实现了SOTA。

**AI_Comments:** 该论文的创新点在于提出了PECM框架，通过引入多级原型和双流置信度估计来解决医学图像-报告跨模态检索中的数据模糊性和语义关系捕获难题。其核心贡献在于利用原型来增强语义表示的鲁棒性，并通过置信度建模来有效处理不确定性数据。这对于提高临床场景中医学数据检索的可靠性具有重要意义，并成功建立了新的SOTA。

<details>
  <summary>Details</summary>

**Motivation:** 在跨模态医学图像-报告检索任务中，由于医学数据固有的模糊性和变异性，准确对齐图像和报告具有挑战性；现有模型难以捕获细微的多级语义关系，导致检索结果不可靠。

**Method:** 本文提出原型增强置信度建模（PECM）框架。该框架为每种模态引入多级原型，以更好地捕获语义变异性并增强检索鲁棒性。PECM采用双流置信度估计，利用原型相似性分布和自适应加权机制来控制高不确定性数据对检索排名的影响。

**Result:** 在放射学图像-报告数据集上，该方法显著提高了检索精度和一致性，有效处理了数据模糊性，并提升了复杂临床场景中的可靠性。在多个不同数据集和任务（包括全监督和零样本检索）上，获得了高达10.17%的性能提升，建立了新的最先进水平。

**Conclusion:** PECM框架通过原型增强和置信度建模，有效解决了跨模态医学图像-报告检索中的挑战，显著提升了检索的精度、一致性和可靠性，达到了新的最先进水平。

> **ai_Abstract:** 本文提出了一种原型增强置信度建模（PECM）框架，旨在解决跨模态医学图像-报告检索中因数据模糊性和语义关系捕获不足导致的可靠性问题。PECM通过引入多级原型和双流置信度估计机制，有效捕获语义变异性并控制不确定性数据的影响。实验结果表明，PECM在医学图像-报告检索任务中显著提升了精度和一致性，并在多个数据集和任务上达到了最先进的性能。

> **摘要翻译:** 在跨模态检索任务中，例如图像到报告和报告到图像的检索，准确地将医学图像与相关文本报告对齐至关重要，但由于医学数据固有的模糊性和变异性而充满挑战。现有模型通常难以捕获放射学数据中细微的多级语义关系，导致检索结果不可靠。为了解决这些问题，我们提出了原型增强置信度建模（PECM）框架，该框架为每种模态引入多级原型，以更好地捕获语义变异性并增强检索鲁棒性。PECM采用双流置信度估计，利用原型相似性分布和自适应加权机制来控制高不确定性数据对检索排名的影响。应用于放射学图像-报告数据集，我们的方法在检索精度和一致性方面取得了显著改进，有效处理了数据模糊性并提高了复杂临床场景中的可靠性。我们在多个不同数据集和任务（包括全监督和零样本检索）上报告了结果，获得了高达10.17%的性能提升，建立了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [433] [Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI](https://arxiv.org/abs/2505.05895)
> *利用视觉-语言模型进行汽车UI的视觉定位与分析*

*Benjamin Raphael Ernhofer, Daniil Prokhorov, Jannica Langner, Dominik Bollmann* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 汽车UI, 视觉-语言模型, 视觉定位, 数据集, 跨领域泛化

**Comment:** 

> **TL;DR:** 该研究引入了一个视觉-语言框架和数据集，用于理解和交互汽车UI，并通过微调模型实现了跨领域的高性能表现。

**AI_Comments:** 这项研究的创新之处在于将视觉-语言模型应用于复杂的汽车UI分析领域，并解决了UI更新和设计多样性带来的挑战。通过发布AutomotiveUI-Bench-4K数据集，为该领域的研究提供了宝贵的资源。模型在跨领域泛化上的出色表现，以及其成本效益和易于部署的特点，预示着该技术在实际汽车信息娱乐系统中的巨大应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代汽车信息娱乐系统需要智能和自适应的解决方案来管理频繁的用户界面（UI）更新和多样化的设计变体。因此，需要一个框架来促进对汽车UI的理解和交互。

**Method:** 该研究引入了一个视觉-语言框架。发布了开源数据集AutomotiveUI-Bench-4K（包含998张图像和4,208个标注）。提出了一个用于生成训练数据的数据管道。使用低秩适应（LoRa）对基于Molmo-7B的模型进行微调，整合了生成的推理以及视觉定位和评估能力，从而开发出微调后的评估性大型动作模型（ELAM）。

**Result:** ELAM在AutomotiveUI-Bench-4K上取得了强大的性能。在ScreenSpot上比基线模型提高了+5.6%，并实现了80.8%的平均准确率，其性能与桌面、移动和网络领域的专用模型接近或超越，尽管主要在汽车领域进行训练。该方法展示了强大的跨领域泛化能力，且成本效益高，微调模型可在消费级GPU上部署。

**Conclusion:** 数据收集和随后的微调可以推动AI在汽车UI理解和交互方面的进展，且所提出的方法具有成本效益，并且微调后的模型可以在消费级GPU上部署。

> **ai_Abstract:** 该论文提出了一个利用视觉-语言模型理解和交互汽车用户界面的框架。为支持相关研究，作者发布了AutomotiveUI-Bench-4K数据集，并开发了一个数据生成管道。通过使用LoRa对基于Molmo-7B的模型进行微调，得到了评估性大型动作模型（ELAM），该模型在所提出的数据集上表现出色，并在跨领域泛化方面显示出强大能力，尤其是在ScreenSpot上取得了80.8%的准确率，超越或媲美现有专用模型。研究表明，通过高效的数据收集和微调，可以实现汽车UI理解的AI驱动进步，且该方法成本低廉，易于部署。

> **摘要翻译:** 现代汽车信息娱乐系统需要智能和自适应的解决方案来管理频繁的用户界面（UI）更新和多样化的设计变体。本研究引入了一个视觉-语言框架，以促进对汽车UI的理解和交互，从而实现不同UI设计之间的无缝适应。为了支持该领域的研究，还发布了AutomotiveUI-Bench-4K，一个包含998张图像和4,208个标注的开源数据集。此外，还提出了一个用于生成训练数据的数据管道。一个基于Molmo-7B的模型通过低秩适应（LoRa）进行微调，整合了生成的推理以及视觉定位和评估能力。微调后的评估性大型动作模型（ELAM）在AutomotiveUI-Bench-4K上取得了强大的性能（模型和数据集可在Hugging Face上获取）。该方法展示了强大的跨领域泛化能力，包括在ScreenSpot上比基线模型提高了+5.6%。在ScreenSpot上实现了80.8%的平均准确率，尽管主要在汽车领域进行训练，但其性能与桌面、移动和网络领域的专用模型接近或超越。这项研究探讨了数据收集和随后的微调如何能够推动汽车UI理解和交互领域的AI驱动进展。所应用的方法具有成本效益，并且微调后的模型可以在消费级GPU上部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [434] [FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing](https://arxiv.org/abs/2505.03329)
> *FLUX-Text：一种简单先进的场景文本编辑扩散Transformer基线*

*Rui Lan, Yancheng Bai, Xu Duan, Mingxing Li, Dongyang Jin, Ryan Xu, Lei Sun, Xiangxiang Chu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 场景文本编辑, 扩散Transformer, 多语言文本, 字形理解, 文本感知损失

**Comment:** 10 pages, 5 figures

> **TL;DR:** FLUX-Text是一种基于扩散Transformer的场景文本编辑方法，通过轻量级嵌入模块和区域文本感知损失，解决了复杂字形（特别是中文、韩文、日文）编辑问题，显著减少了训练数据需求，并在视觉质量和文本保真度上超越现有方法。

**AI_Comments:** FLUX-Text的创新点在于将Diffusion Transformer（DiT）架构应用于场景文本编辑，这使其能够以极少的训练数据（仅0.1M）取得优异表现，大幅降低了数据依赖性。同时，其轻量级嵌入模块和专门的区域文本感知损失有效地提升了对复杂多语言字形的处理能力，解决了现有方法在非拉丁语系文本上的痛点，具有重要的实际应用价值和研究潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的场景文本编辑方法主要基于UNet扩散模型，在处理复杂字形结构（特别是中文、韩文、日文等非拉丁语系）时仍面临挑战，难以保证文本保真度和整体视觉质量与背景一致。

**Method:** 本文提出了FLUX-Text，一种简单先进的多语言场景文本编辑DiT（Diffusion Transformer）方法。它通过轻量级的视觉和文本嵌入模块增强字形理解和生成能力，同时保留了FLUX原有的生成能力。此外，还提出了针对文本区域的区域文本感知损失（Regional Text Perceptual Loss），并配合两阶段训练策略，以更好地平衡文本编辑和整体图像质量。FLUX-Text基于DiT架构和轻量级特征注入模块，仅需0.1M训练样本即可训练，比流行方法所需的2.9M减少了97%。

**Result:** 在多个公共数据集（包括英文和中文基准）上进行的广泛实验表明，FLUX-Text在视觉质量和文本保真度方面均超越了其他方法。

**Conclusion:** FLUX-Text通过其创新的DiT架构、轻量级嵌入模块和专门的损失函数，有效解决了复杂多语言场景文本编辑的挑战，显著提升了编辑效果并大幅降低了数据需求，展现了卓越的性能。

> **ai_Abstract:** FLUX-Text提出了一种基于扩散Transformer的场景文本编辑方法，旨在解决现有UNet扩散模型在处理复杂多语言字形时的不足。该方法通过引入轻量级视觉和文本嵌入模块增强字形理解，并设计了区域文本感知损失和两阶段训练策略以优化编辑效果。FLUX-Text的DiT架构使其能在极少数据下训练，并在实验中展现出超越现有方法的视觉质量和文本保真度。

> **摘要翻译:** 场景文本编辑旨在修改或添加图像上的文本，同时确保文本保真度以及与背景一致的整体视觉质量。最近的方法主要基于UNet扩散模型，这些模型改善了场景文本编辑结果，但在处理复杂字形结构（特别是中文、韩文、日文等非拉丁语系）时仍面临挑战。为了解决这些问题，我们提出了FLUX-Text，一种简单先进的多语言场景文本编辑DiT方法。具体来说，我们的FLUX-Text通过轻量级的视觉和文本嵌入模块增强了字形理解和生成能力，同时保留了FLUX原有的生成能力。我们进一步提出了一种为文本区域量身定制的区域文本感知损失，并配合匹配的两阶段训练策略，以更好地平衡文本编辑和整体图像质量。得益于基于DiT的架构和轻量级特征注入模块，FLUX-Text仅需0.1M训练样本即可训练，与流行方法所需的2.9M相比，减少了97%。在多个公共数据集（包括英文和中文基准）上进行的广泛实验表明，我们的方法在视觉质量和文本保真度方面均超越了其他方法。所有代码均可在https://github.com/AMAP-ML/FluxText获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework](https://arxiv.org/abs/2508.02807)
> *DreamVVT：通过分阶段扩散Transformer框架掌握野外真实视频虚拟试穿*

*Tongchun Zuo, Zaiyu Huang, Shuliang Ning, Ente Lin, Chao Liang, Zerong Zheng, Jianwen Jiang, Yuan Zhang, Mingyuan Gao, Xin Dong* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 视频虚拟试穿, 扩散Transformer, 时间一致性, 服装细节, 图像生成

**Comment:** 18 pages, 12 figures

> **TL;DR:** DreamVVT是一个两阶段扩散Transformer框架，用于在野外实现逼真的视频虚拟试穿，解决了现有方法在细节保留和时间一致性方面的挑战。

**AI_Comments:** DreamVVT的创新之处在于其两阶段扩散Transformer框架，特别是结合了VLM和LoRA适配器来利用多样化的非配对数据和预训练模型先验知识，有效解决了视频虚拟试穿中的细节保留和时间一致性难题。这对于电商和娱乐应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端视频虚拟试穿 (VVT) 方法过度依赖稀缺的配对服装数据集，未能有效利用先进视觉模型和测试时输入的先验知识，导致在非受限场景中难以准确保留精细服装细节和维持时间一致性。

**Method:** 提出DreamVVT，一个基于扩散Transformer (DiTs) 的两阶段框架。第一阶段，从输入视频中采样代表性帧，利用集成视觉语言模型 (VLM) 的多帧试穿模型合成高保真、语义一致的关键帧试穿图像，作为后续视频生成的补充外观指导。第二阶段，从输入内容中提取骨骼图以及精细动作和外观描述，连同关键帧试穿图像一起输入到通过LoRA适配器增强的预训练视频生成模型中，以确保未见区域的长期时间连贯性并实现高度逼真的动态动作。

**Result:** 广泛的定量和定性实验表明，DreamVVT在真实场景中在保留详细服装内容和时间稳定性方面超越了现有方法。

**Conclusion:** DreamVVT通过其分阶段框架和对先验知识的有效利用，成功解决了现有VVT方法在细节保留和时间一致性方面的挑战，实现了更逼真的野外视频虚拟试穿。

> **ai_Abstract:** DreamVVT是一个新颖的两阶段扩散Transformer框架，旨在解决现有视频虚拟试穿 (VVT) 方法在野外场景中面临的服装细节保留和时间一致性挑战。它通过在第一阶段利用多帧试穿模型和VLM生成高保真关键帧图像，并在第二阶段将这些图像与骨骼图及运动描述结合，输入到经过LoRA增强的预训练视频生成模型中，从而实现逼真的动态动作和长期时间连贯性。实验证明DreamVVT在真实世界场景中优于现有方法。

> **摘要翻译:** 视频虚拟试穿 (VVT) 技术因其在电子商务广告和娱乐领域的应用前景而引起了广泛的学术兴趣。然而，大多数现有的端到端方法过度依赖稀缺的配对服装中心数据集，并且未能有效利用先进视觉模型和测试时输入的先验知识，这使得在不受约束的场景中准确保留精细服装细节和保持时间一致性变得具有挑战性。为了解决这些挑战，我们提出了DreamVVT，一个基于扩散Transformer (DiTs) 精心设计的两阶段框架，其本质上能够利用多样化的非配对以人为中心的数据来增强在真实世界场景中的适应性。为了进一步利用预训练模型和测试时输入的先验知识，在第一阶段，我们从输入视频中采样代表性帧，并利用集成了视觉语言模型 (VLM) 的多帧试穿模型，合成高保真和语义一致的关键帧试穿图像。这些图像作为后续视频生成的补充外观指导。在第二阶段，从输入内容中提取骨骼图以及精细动作和外观描述，这些连同关键帧试穿图像一起被输入到通过LoRA适配器增强的预训练视频生成模型中。这确保了未见区域的长期时间连贯性，并实现了高度逼真的动态动作。广泛的定量和定性实验表明，DreamVVT在真实场景中在保留详细服装内容和时间稳定性方面超越了现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [441] [PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining](https://arxiv.org/abs/2505.05307)
> *PRE-Mamba：一种用于超高频事件相机去雨的4D状态空间模型*

*Ciyu Ruan, Ruishan Guo, Zihang Gong, Jingao Xu, Wenhan Yang, Xinlei Chen* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 事件相机, 去雨, 4D状态空间模型, PRE-Mamba, 时空特性

**Comment:** This version is the camera-ready version accepted at ICCV 2025

> **TL;DR:** PRE-Mamba是一种新颖的基于点的事件相机去雨框架，通过利用4D事件云表示、时空解耦融合模块和多尺度状态空间模型，在保持高时间精度的同时，以线性计算复杂度实现了卓越的去雨性能和泛化能力。

**AI_Comments:** PRE-Mamba的创新之处在于其将4D事件云表示与时空解耦融合以及多尺度状态空间模型相结合，有效处理了事件数据固有的时空特性，并实现了线性计算复杂度。这对于处理超高频事件数据至关重要。其在EventRain-27K数据集上的优异表现和泛化能力证明了其重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机在高时间分辨率和动态范围方面表现出色，但在雨天条件下会受到密集噪声的影响。现有的事件去雨方法在时间精度、去雨效果和计算效率之间面临权衡。

**Method:** 本文提出了PRE-Mamba，一种新颖的基于点的事件相机去雨框架。该框架引入了整合双时间尺度的4D事件云表示以保持高时间精度，一个时空解耦融合模块（STDF）通过浅层解耦和时空信息交互来增强去雨能力，以及一个多尺度状态空间模型（MS3M），以线性计算复杂度在双时间尺度和多空间尺度上捕获更深层的雨动态。该方法还通过频域正则化得到增强。

**Result:** PRE-Mamba在EventRain-27K数据集上实现了卓越的性能（0.95 SR，0.91 NR和0.4s/M事件），且仅有0.26M参数。此外，该方法在不同降雨强度、视角甚至雪天条件下都表现出良好的泛化能力。

**Conclusion:** PRE-Mamba通过其创新的架构和对事件相机时空特性的充分利用，有效解决了雨天条件下事件相机的去噪问题，并展现出优异的性能和泛化能力，为超高频事件相机去雨提供了一个高效的解决方案。

> **ai_Abstract:** PRE-Mamba提出了一种新颖的4D状态空间模型，用于解决事件相机在雨天条件下的密集噪声问题。该框架利用4D事件云表示、时空解耦融合模块（STDF）和多尺度状态空间模型（MS3M），有效捕捉雨滴的时空动态，并在保持高时间精度的同时，以线性计算复杂度实现高效去雨。实验结果表明，PRE-Mamba在EventRain-27K数据集上表现出卓越的性能和泛化能力，即使在不同雨强、视角和雪天条件下也表现良好。

> **摘要翻译:** 事件相机在高时间分辨率和动态范围方面表现出色，但在雨天条件下会受到密集噪声的影响。现有的事件去雨方法在时间精度、去雨效果和计算效率之间面临权衡。在本文中，我们提出了PRE-Mamba，一种新颖的基于点的事件相机去雨框架，它充分利用了原始事件和雨的时空特性。我们的框架引入了一种整合双时间尺度的4D事件云表示以保持高时间精度，一个时空解耦融合模块（STDF）通过浅层解耦和时空信息交互来增强去雨能力，以及一个多尺度状态空间模型（MS3M），它以线性计算复杂度在双时间尺度和多空间尺度上捕获更深层的雨动态。通过频域正则化增强，PRE-Mamba在EventRain-27K这个包含标记合成和真实世界序列的综合数据集上，以仅0.26M的参数实现了卓越的性能（0.95 SR，0.91 NR和0.4s/M事件）。此外，我们的方法在不同降雨强度、视角甚至雪天条件下都表现出良好的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [448] [Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image](https://arxiv.org/abs/2505.14537)
> *个性化你的高斯：从单张图像实现一致的3D场景个性化*

*Yuxuan Wang, Xuanyu Yi, Qingshan Xu, Yuan Zhou, Long Chen, Hanwang Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D场景个性化, 单图像, 3D高斯泼溅, 视图一致性, LoRA微调

**Comment:** 18 pages

> **TL;DR:** CP-GS是一个从单张图像实现一致3D场景个性化的框架，它通过传播单视图参考外观并结合预训练图像到3D生成和LoRA微调，有效缓解了视角偏差，生成高质量的个性化结果。

**AI_Comments:** 该论文的创新点在于提出了CP-GS框架，有效解决了从单张图像进行3D场景个性化时的视角偏差问题，这是现有方法的一个主要局限。通过结合预训练的图像到3D生成和迭代LoRA微调，该方法能够一致地扩展单视图信息，从而实现高质量的多视图一致性个性化，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 从单张参考图像个性化3D场景需要实现多视图一致性和与输入图像的参考一致性。然而，由于单张图像提供的有限视角导致的视图偏差，现有方法难以产生一致结果，缺乏有效扩展参考信息的机制。

**Method:** 本文提出了Consistent Personalization for 3D Gaussian Splatting (CP-GS) 框架。CP-GS逐步将单视图参考外观传播到新视角，整合了预训练的图像到3D生成和迭代LoRA微调来提取和扩展参考外观，并通过几何线索引导的视图一致生成过程，最终生成忠实的多视图指导图像和个性化的3DGS输出。

**Result:** 在真实世界场景进行的广泛实验表明，CP-GS有效缓解了视角偏差，实现了高质量的个性化，显著优于现有方法。

**Conclusion:** CP-GS框架通过其独特的单视图参考外观传播机制和视图一致生成过程，成功解决了从单张图像进行3D场景个性化时存在的视角偏差问题，并取得了超越现有方法的卓越性能。

> **ai_Abstract:** 本文提出了CP-GS框架，旨在解决从单张图像进行3D场景个性化时遇到的视图偏差和一致性问题。通过将单视图参考外观逐步传播到新视角，并结合预训练图像到3D生成和迭代LoRA微调，CP-GS能够生成视图一致的指导图像和高质量的个性化3DGS输出。实验证明，CP-GS在真实场景中有效减轻了视图偏差，并显著优于现有方法。

> **摘要翻译:** 从单张参考图像个性化3D场景可以实现直观的用户引导编辑，这需要实现跨视点的多视图一致性以及与输入图像的参考一致性。然而，由于单张图像提供的有限视角导致的视图偏差，这些目标尤其具有挑战性。现有图像条件下的3DGS个性化方法由于缺乏有效扩展原始视图之外参考信息的机制，常常受到这种视图偏差的影响，难以产生一致的结果。因此，在本文中，我们提出了用于3D高斯泼溅的一致个性化（CP-GS）框架，该框架逐步将单视图参考外观传播到新视角。特别是，CP-GS集成了预训练的图像到3D生成和迭代LoRA微调，以提取和扩展参考外观，并通过几何线索引导的视图一致生成过程，最终生成忠实的多视图指导图像和个性化的3DGS输出。在真实世界场景进行的广泛实验表明，我们的CP-GS有效缓解了视角偏差，实现了高质量的个性化，显著优于现有方法。代码将在https://github.com/Yuxuan-W/CP-GS发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [451] [T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates](https://arxiv.org/abs/2507.07633)
> *T-GVC：超低比特率下的轨迹引导生成式视频编码*

*Zhitao Wang, Hengyu Man, Wenrui Li, Xingtao Wang, Xiaopeng Fan, Debin Zhao* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-05**

**Keywords:** 生成式视频编码, 超低比特率, 轨迹引导, 运动跟踪, 扩散模型

**Comment:** 

> **TL;DR:** T-GVC 是一种新的生成式视频编码框架，通过结合低级运动跟踪和高级语义理解，在超低比特率下实现高质量视频重建，解决了现有方法在捕捉精细运动细节方面的不足。

**AI_Comments:** T-GVC 的创新之处在于将低级运动跟踪与高级语义理解相结合，并通过稀疏轨迹点和无训练的轨迹对齐引导机制，解决了现有生成式视频编码在精细运动捕捉和泛化性上的局限性，为超低比特率视频编码提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成式视频编码方法受限于领域特异性（如面部或人类视频）或过度依赖高级文本指导，导致无法充分捕捉精细运动细节，重建视频不真实或不连贯。

**Method:** 本文提出了轨迹引导生成式视频编码（T-GVC），一个结合低级运动跟踪和高级语义理解的新框架。T-GVC 包含一个语义感知的稀疏运动采样流程，根据像素的语义重要性提取像素级运动作为稀疏轨迹点，从而显著降低比特率并保留关键时间语义信息。此外，通过将轨迹对齐的损失约束集成到扩散过程中，在潜在空间中引入了一种无需训练的引导机制，以确保物理上合理的运动模式。

**Result:** 实验结果表明，在超低比特率条件下，T-GVC 优于传统和神经视频编解码器。额外的实验证实，该框架比现有的文本引导方法实现了更精确的运动控制。

**Conclusion:** T-GVC 提出了一种新的生成式视频编码方向，通过几何运动建模进行引导，解决了现有方法在精细运动细节捕捉上的不足，并在超低比特率下表现出色。

> **ai_Abstract:** T-GVC 是一种新型的生成式视频编码框架，旨在解决现有方法在超低比特率下捕捉精细运动细节的不足。它通过语义感知的稀疏运动采样来降低比特率，并引入轨迹对齐的损失约束在扩散过程中进行无训练引导，以确保运动的物理合理性。实验证明，T-GVC 在超低比特率条件下优于传统和神经编解码器，并提供比文本引导方法更精确的运动控制。

> **摘要翻译:** 视频生成技术的最新进展催生了一种新兴的生成式视频编码范式，通过利用强大的生成先验，用于超低比特率（ULB）场景。然而，大多数现有方法受限于领域特异性（例如，面部或人类视频）或过度依赖高级文本指导，这往往无法充分捕捉精细的运动细节，导致不真实或不连贯的重建。为了解决这些挑战，我们提出了轨迹引导生成式视频编码（简称 T-GVC），这是一种将低级运动跟踪与高级语义理解相结合的新颖框架。T-GVC 具有一个语义感知的稀疏运动采样流程，该流程根据像素的语义重要性将像素级运动提取为稀疏轨迹点，从而显著降低比特率，同时保留关键的时间语义信息。此外，通过将轨迹对齐的损失约束集成到扩散过程中，我们在潜在空间中引入了一种无需训练的引导机制，以确保物理上合理的运动模式，而不会牺牲生成模型的固有能力。实验结果表明，T-GVC 在 ULB 条件下优于传统和神经视频编解码器。此外，额外的实验证实，我们的框架比现有文本引导方法实现了更精确的运动控制，为几何运动建模引导的生成式视频编码开辟了新方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [452] [UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying](https://arxiv.org/abs/2508.03142)
> *UniEdit-I：通过迭代理解、编辑和验证实现统一VLM的免训练图像编辑*

*Chengyu Bai, Jintao Chen, Xiang Bai, Yilong Chen, Qi She, Ming Lu, Shanghang Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 统一VLM,图像编辑,免训练,迭代,UniEdit-I

**Comment:** 

> **TL;DR:** UniEdit-I是一个免训练框架，通过迭代理解、编辑和验证，为统一视觉语言模型（VLM）提供图像编辑能力，并在基准测试中达到了SOTA性能。

**AI_Comments:** UniEdit-I的创新之处在于其“免训练”特性和迭代的“理解、编辑、验证”循环，这极大地降低了实现VLM图像编辑的门槛，并提高了编辑的精度和一致性。该方法充分利用了现有VLM的理解能力，并通过巧妙的迭代反馈机制实现了精确控制，为未来统一VLM在更广泛应用中的落地提供了新的思路和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管统一视觉语言模型（VLM）在视觉理解和生成方面取得了快速进展，并且存在一个有前景的生成管道，但如何轻松实现图像编辑能力仍未被探索。本文旨在解决这一空白，为统一VLM提供免训练的图像编辑能力。

**Method:** 本文提出了一个名为UniEdit-I的免训练框架，通过三个迭代步骤实现图像编辑：1. 理解：分析源图像生成源提示，并根据编辑指令对目标提示进行最小化词语替换。2. 编辑：引入时间自适应偏移，在去噪过程中实现从粗到细的连贯编辑。3. 验证：检查目标提示与中间编辑图像的对齐情况，提供自动一致性得分和纠正反馈，并决定是否提前停止或继续编辑循环。此循环迭代进行直至收敛，以实现高保真编辑。

**Result:** 该方法基于最新的BLIP3-o实现，并在GEdit-Bench基准测试中取得了最先进（SOTA）的性能。

**Conclusion:** UniEdit-I框架成功地为统一视觉语言模型提供了免训练的图像编辑能力，并通过迭代的理解、编辑和验证过程实现了高保真编辑，在相关基准测试中表现出色。

> **ai_Abstract:** 本文提出了UniEdit-I，一个新颖的免训练框架，旨在为统一视觉语言模型（VLM）提供图像编辑能力。该框架通过迭代的理解、编辑和验证三个核心步骤实现高保真编辑。理解步骤生成和调整提示，编辑步骤通过时间自适应偏移进行图像修改，验证步骤则检查一致性并提供反馈。UniEdit-I基于BLIP3-o实现，并在GEdit-Bench基准测试中达到了最先进的性能，解决了统一VLM图像编辑能力的空白。

> **摘要翻译:** 近年来，统一视觉语言模型（VLM）迅速发展，有效地在一个单一设计中处理视觉理解和生成任务。尽管许多统一VLM探索了各种设计选择，但OpenAI GPT-4o最近的假设提出了一种有前景的生成管道：理解VLM->视觉特征->投影器->扩散模型->图像。理解VLM是冻结的，只有与生成相关的模块被训练。这种管道保持了理解VLM的强大能力，同时使统一VLM具备图像生成能力。尽管这种管道在统一VLM的未来发展中显示出非常有前景的潜力，但如何轻松实现图像编辑能力仍未被探索。在本文中，我们引入了一个名为UniEdit-I的新颖的免训练框架，通过三个迭代步骤：理解、编辑和验证，使统一VLM具备图像编辑能力。1. 理解步骤通过结构化语义分析分析源图像以创建源提示，并根据编辑指令进行最小的词语替换以形成目标提示。2. 编辑步骤引入了时间自适应偏移，允许在整个去噪过程中进行从粗到细的连贯编辑。3. 验证步骤检查目标提示与中间编辑图像之间的一致性，提供自动一致性得分和纠正反馈，并决定是否提前停止或继续编辑循环。这种理解、编辑和验证循环迭代进行直至收敛，以免训练的方式提供高保真编辑。我们基于最新的BLIP3-o实现了我们的方法，并在GEdit-Bench基准测试中取得了最先进（SOTA）的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [455] [GOBench: Benchmarking Geometric Optics Generation and Understanding of MLLMs](https://arxiv.org/abs/2506.00991)
> *GOBench：基准测试多模态大语言模型在几何光学生成与理解方面的能力*

*Xiaorong Zhu, Ziheng Jia, Jiarui Wang, Xiangyu Zhao, Haodong Duan, Xiongkuo Min, Jia Wang, Zicheng Zhang, Guangtao Zhai* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态大语言模型, 几何光学, 基准测试, 图像生成, 光学理解

**Comment:** 8 pages, 5 figures

> **TL;DR:** GOBench是首个评估多模态大语言模型在几何光学生成和理解方面能力的基准测试，结果显示当前模型在这两方面都面临显著挑战。

**AI_Comments:** 这项工作具有创新性，因为它首次系统地评估了多模态大语言模型在几何光学这一特定物理领域的能力。其重要性在于揭示了当前MLLMs在生成和理解光学原理方面的显著局限性，为未来模型改进指明了方向。通过提供公开的基准数据集和代码，它为研究社区提供了一个宝贵的工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）在视觉理解和生成方面取得了显著进展，但对其在几何光学等精细物理原理方面的能力评估仍未得到充分探索。本文旨在弥补这一空白。

**Method:** 研究引入了GOBench，这是第一个系统评估MLLMs在两个任务（生成光学真实图像和理解底层光学现象）能力的基准。研究策划了几何光学场景的高质量提示，并使用MLLMs构建了GOBench-Gen-1k数据集。通过主观实验评估生成图像的光学真实性、美学质量和指令忠实度。对于理解任务，应用精心设计的评估指令测试了十一个知名MLLMs的光学理解能力。

**Result:** 实验结果表明，当前模型在光学生成和理解方面都面临显著挑战。顶级的生成模型GPT-4o-Image无法完美完成所有生成任务，而表现最佳的MLLM模型Gemini-2.5Pro在光学理解方面的准确率仅为37.35%。

**Conclusion:** 当前的多模态大语言模型在几何光学图像生成和光学现象理解方面表现出显著的局限性，仍需进一步改进以达到更高的准确性和真实性。

> **ai_Abstract:** 本文介绍了GOBench，这是首个用于系统评估多模态大语言模型（MLLMs）在几何光学图像生成和光学现象理解方面能力的基准测试。研究构建了高质量的几何光学场景数据集，并通过主观评估和指令测试，揭示了当前MLLMs在生成光学真实图像和理解光学原理方面的显著缺陷和局限性，指出现有模型在此领域的表现远未达到理想水平。

> **摘要翻译:** 多模态大语言模型（MLLMs）的快速发展正在推动视觉理解和生成方面的重大进步。然而，对其能力（尤其是几何光学中精细的物理原理）的全面评估仍未得到充分探索。为了弥补这一空白，我们引入了GOBench，这是第一个系统评估MLLMs在两个任务中能力的基准：1）生成光学真实图像和2）理解底层光学现象。我们策划了几何光学场景的高质量提示，并使用MLLMs构建了GOBench-Gen-1k数据集。然后，我们组织了主观实验，根据光学真实性、美学质量和指令忠实度评估生成的图像，揭示了MLLMs违反光学原理的生成缺陷。对于理解任务，我们应用精心设计的评估指令来测试十一个知名MLLMs的光学理解能力。实验结果表明，当前模型在光学生成和理解方面都面临显著挑战。表现最佳的生成模型GPT-4o-Image无法完美完成所有生成任务，而表现最佳的MLLM模型Gemini-2.5Pro在光学理解方面的准确率仅为37.35%。数据库和代码可在https://github.com/aiben-ch/GOBench公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [460] [EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation](https://arxiv.org/abs/2508.03497)
> *EditGarment：一个基于指令的服装编辑数据集，通过自动化MLLM合成和语义感知评估构建*

*Deqiang Yin, Junyi Guo, Huanda Lu, Fangyu Wu, Dongming Lu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 服装编辑, 基于指令, 数据集, MLLM, 语义感知评估

**Comment:** 

> **TL;DR:** 该论文介绍了EditGarment，这是第一个基于指令的服装编辑数据集，通过自动化多模态大语言模型（MLLM）合成和新的语义感知评估指标构建，以解决数据稀缺问题。

**AI_Comments:** 该论文通过提出一种自动化且可扩展的解决方案来生成高质量的基于指令的服装编辑数据，具有创新性，此前这项任务受限于高昂的手动标注成本。引入“时尚编辑分数”是一个重要贡献，为该任务提供了对时尚特定语义至关重要的评估方法。该数据集有望显著推动时尚领域基于指令的图像编辑研究。

<details>
  <summary>Details</summary>

**Motivation:** 基于指令的服装编辑因高质量指令-图像对的稀缺而进展受限，手动标注成本高且难以扩展。现有MLLM在自动化数据合成方面的应用受到指令建模不精确和缺乏时尚特定监督信号的限制。

**Method:** 本文提出了一个自动化流程来构建服装编辑数据集。首先，定义了六种与真实时尚工作流程对齐的编辑指令类别，以指导生成平衡且多样化的指令-图像三元组。其次，引入了“时尚编辑分数”（Fashion Edit Score），这是一种语义感知评估指标，用于捕捉服装属性间的语义依赖并提供可靠监督。

**Result:** 通过所提出的流程，总共构建了52,257个候选三元组，并保留了20,596个高质量三元组，从而构建了EditGarment，这是第一个专为独立服装编辑量身定制的基于指令的数据集。

**Conclusion:** 该论文通过提出一个自动化流程和新的评估指标，成功解决了基于指令的服装编辑中数据稀缺的问题，并构建了高质量的EditGarment数据集。

> **ai_Abstract:** 该论文介绍了EditGarment，这是一个专为独立服装编辑设计的首个基于指令的数据集。为解决数据稀缺问题，作者提出了一个自动化数据集构建流程，该流程定义了六种服装编辑指令类别，并引入了“时尚编辑分数”这一语义感知评估指标，以指导和监督高质量指令-图像三元组的生成。最终构建的EditGarment数据集包含20,596个高质量三元组。

> **摘要翻译:** 基于指令的服装编辑通过自然语言实现精确的图像修改，在时尚设计和个性化定制方面具有广泛应用。与通用编辑任务不同，它需要理解服装特定的语义和属性依赖关系。然而，高质量指令-图像对的稀缺限制了进展，因为手动标注成本高昂且难以扩展。尽管MLLM在自动化数据合成方面表现出潜力，但其在服装编辑中的应用受到指令建模不精确和缺乏时尚特定监督信号的限制。为了应对这些挑战，我们提出了一个用于构建服装编辑数据集的自动化流程。我们首先定义了六种与真实时尚工作流程对齐的编辑指令类别，以指导生成平衡且多样化的指令-图像三元组。其次，我们引入了时尚编辑分数（Fashion Edit Score），这是一种语义感知评估指标，能够捕捉服装属性之间的语义依赖关系，并在构建过程中提供可靠的监督。利用这个流程，我们总共构建了52,257个候选三元组，并保留了20,596个高质量三元组，以构建EditGarment，这是第一个专为独立服装编辑量身定制的基于指令的数据集。项目页面是https://yindq99.github.io/EditGarment-project/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [462] [Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting](https://arxiv.org/abs/2506.05280)
> *统一外观编码和双边网格用于驾驶场景高斯泼溅*

*Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu, Saining Zhang, Ziyang Yan, Pierre Merriaux, Lei Lei, Tianfan Xue, Hao Zhao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 高斯泼溅, 外观编码, 双边网格, 自动驾驶, 几何重建

**Comment:** Project page: https://bigcileng.github.io/bilateral-driving ; Code:
  https://github.com/BigCiLeng/bilateral-driving

> **TL;DR:** 本文提出了一种新颖的多尺度双边网格，该网格统一了外观编码和双边网格，显著提高了动态、解耦自动驾驶场景重建的几何精度，解决了光度不一致导致的问题。

**AI_Comments:** 该论文的创新点在于提出了统一外观编码和双边网格的多尺度双边网格方法，有效解决了神经渲染在复杂真实场景中光度不一致导致的几何精度问题。其重要性体现在对自动驾驶领域高精度几何重建的贡献，通过减少浮点物显著提升了模型的鲁棒性和实用性。这种统一多种渲染策略的思路也为未来的神经渲染研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在真实世界场景中，很难保证图像中完美的光度一致性。现有的外观编码模型能力有限，因为单个编码应用于整个图像；而双边网格虽然可以进行像素级颜色映射，但难以有效优化和约束。

**Method:** 本文提出了一种新颖的多尺度双边网格，它统一了外观编码和双边网格的优点。

**Result:** 该方法显著提高了动态、解耦自动驾驶场景重建的几何精度，优于单独的外观编码和双边网格。在Waymo、NuScenes、Argoverse和PandaSet四个数据集上均显示出良好结果。几何精度的提高是由多尺度双边网格有效减少光度不一致引起的浮点物驱动的。

**Conclusion:** 统一外观编码和双边网格的多尺度双边网格方法，能有效解决光度不一致问题，显著提升自动驾驶场景重建的几何精度，对障碍物规避和控制至关重要。

> **ai_Abstract:** 本文针对神经渲染技术在真实世界场景中光度一致性难以保证的问题，提出了一种新颖的多尺度双边网格方法。该方法将传统的外观编码和双边网格进行统一，有效解决了现有方法的局限性。实验结果表明，该方法在动态、解耦自动驾驶场景重建中显著提升了几何精度，并在多个主流自动驾驶数据集上表现出色，对于自动驾驶中的障碍物规避和控制具有重要意义。

> **摘要翻译:** 神经渲染技术，包括NeRF和高斯泼溅（GS），依赖光度一致性来产生高质量的重建。然而，在真实世界场景中，很难保证获取图像中完美的光度一致性。外观编码已被广泛用于解决这个问题，但其建模能力有限，因为单个编码应用于整个图像。最近，引入了双边网格来执行像素级颜色映射，但它难以有效优化和约束。在本文中，我们提出了一种新颖的多尺度双边网格，它统一了外观编码和双边网格。我们证明了这种方法显著提高了动态、解耦自动驾驶场景重建的几何精度，优于单独的外观编码和双边网格。这对于自动驾驶至关重要，因为精确的几何形状对于避障和控制非常重要。我们的方法在四个数据集上显示出强大的结果：Waymo、NuScenes、Argoverse和PandaSet。我们进一步证明，几何形状的改进是由多尺度双边网格驱动的，它有效地减少了光度不一致引起的浮点物。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [BaroPoser: Real-time Human Motion Tracking from IMUs and Barometers in Everyday Devices](https://arxiv.org/abs/2508.03313)
> *BaroPoser：利用日常设备中的IMU和气压计进行实时人体运动追踪*

*Libo Zhang, Xinyu Yi, Feng Xu* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 人体运动追踪, IMU, 气压计, 姿态估计, 实时

**Comment:** 9 pages, 10 figures

> **TL;DR:** BaroPoser是首个结合IMU和气压计数据，利用智能手机和智能手表实时估计人体姿态和全局位移的方法，解决了现有IMU方法在不平坦地形上姿态估计精度低和受限的问题，并表现出优于SOTA的性能。

**AI_Comments:** BaroPoser的创新之处在于首次将气压计数据与IMU数据结合用于人体运动追踪，有效解决了在非平坦地形上姿态估计和全局位移预测的挑战。其提出的局部大腿坐标系也为姿态表示学习提供了新思路。该研究对于扩展日常设备在复杂环境中人体运动追踪的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有利用日常设备（如智能手机、智能手表）中IMU进行人体运动追踪的方法，由于传感器测量稀疏和缺乏非平坦地形数据集，导致姿态估计精度不足，且通常仅限于在平坦地形上恢复运动。

**Method:** 提出了BaroPoser，首次结合智能手机和智能手表记录的IMU和气压数据，实时估计人体姿态和全局位移。通过利用气压读数估计传感器高度变化，为提高姿态估计精度和预测非平坦地形上的全局位移提供了有价值的线索。此外，还提出了一个局部大腿坐标系来解耦局部和全局运动输入，以实现更好的姿态表示学习。

**Result:** 在公共基准数据集和真实世界记录上进行了评估。定量和定性结果表明，在相同的硬件配置下，该方法优于仅使用IMU的现有最先进（SOTA）方法。

**Conclusion:** BaroPoser通过结合IMU和气压计数据，成功实现了在不平坦地形上的实时人体姿态估计和全局位移预测，显著提升了运动追踪的精度和适用性。

> **ai_Abstract:** BaroPoser是一种新颖的实时人体运动追踪方法，它创新性地结合了来自智能手机和智能手表的IMU和气压计数据，以解决现有IMU方法在非平坦地形上姿态估计精度低和全局位移预测受限的问题。该方法利用气压数据估计高度变化，并引入局部大腿坐标系来优化姿态表示学习。实验结果表明，BaroPoser在相同硬件配置下，性能优于仅使用IMU的最先进方法，为人体运动追踪在复杂环境中的应用提供了有效解决方案。

> **摘要翻译:** 近年来，利用智能手机和智能手表等日常设备中的惯性测量单元（IMU）追踪人体运动越来越受欢迎。然而，由于传感器测量稀疏以及缺乏捕获不平坦地形上人体运动的数据集，现有方法通常在姿态估计精度方面存在困难，并且通常仅限于在平坦地形上恢复运动。为此，我们提出了BaroPoser，这是第一个结合智能手机和智能手表记录的IMU和气压数据，以实时估计人体姿态和全局位移的方法。通过利用气压读数，我们估计了传感器高度变化，这为提高人体姿态估计的准确性以及预测非平坦地形上的全局位移提供了宝贵的线索。此外，我们提出了一个局部大腿坐标系，以解耦局部和全局运动输入，从而实现更好的姿态表示学习。我们在公共基准数据集和真实世界记录上评估了我们的方法。定量和定性结果表明，在相同的硬件配置下，我们的方法优于仅使用IMU的最先进（SOTA）方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [468] [Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind](https://arxiv.org/abs/2505.12207)
> *大型多模态模型能否理解农业场景？使用 AgroMind 进行基准测试*

*Qingmei Li, Yang Zhang, Zurong Mai, Yuhang Chen, Shuohong Lou, Henglian Huang, Jiarui Zhang, Zhiwei Zhang, Yibin Wen, Weijia Li, Haohuan Fu, Jianxi Huang, Juepeng Zheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 大型多模态模型, 农业遥感, 基准测试, AgroMind, 场景理解

**Comment:** 

> **TL;DR:** 引入AgroMind，一个全面的农业遥感基准，以评估和揭示大型多模态模型在农业场景理解方面的局限性。

**AI_Comments:** AgroMind的创新之处在于其对农业遥感场景理解的全面性和细致性，填补了现有基准的空白。它不仅覆盖了多样的任务维度，还整合了丰富的图像和问答数据，为LMMs在农业领域的应用提供了坚实的评估基础。其发现LMMs在某些方面已超越人类表现，但仍存在特定领域知识的局限性，这为未来AI在农业智能发展提供了重要的洞察和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有农业遥感基准在数据集场景多样性和任务设计方面存在显著局限性，导致大型多模态模型在该领域的能力评估不足。

**Method:** 引入AgroMind，一个涵盖空间感知、物体理解、场景理解和场景推理四个任务维度（共13种任务类型）的农业遥感基准。该基准集成了8个公共数据集和1个私人农田数据集，包含27,247个问答对和19,615张图像。通过多源数据预处理、系统性任务定义生成农业相关问题，并使用大型多模态模型进行推理和评估。评估了20个开源LMMs和4个闭源模型。

**Result:** 实验揭示了大型多模态模型在空间推理和细粒度识别方面存在显著的性能差距。值得注意的是，人类表现落后于几个领先的LMMs。

**Conclusion:** AgroMind建立了一个农业遥感的标准化评估框架，揭示了大型多模态模型在领域知识方面的局限性，并强调了未来工作中的关键挑战。

> **ai_Abstract:** 该论文提出了AgroMind，一个用于评估大型多模态模型（LMMs）在农业遥感领域能力的综合基准。鉴于现有农业遥感基准的不足，AgroMind涵盖了空间感知、物体理解、场景理解和场景推理等13种任务类型，并整合了多个数据集构建了包含27,247个问答对和19,615张图像的高质量评估集。通过对24个LMMs的评估，研究发现LMMs在农业场景理解，特别是空间推理和细粒度识别方面存在显著差距，同时也发现部分LMMs性能超越人类。AgroMind为农业遥感领域LMMs的评估提供了一个标准化框架，并揭示了模型在特定领域知识方面的局限性，为未来研究指明了方向。

> **摘要翻译:** 大型多模态模型（LMMs）已在各个领域展现出能力，但针对农业遥感（RS）的综合基准仍然稀缺。现有为农业遥感场景设计的基准存在显著局限性，主要体现在数据集场景多样性不足和任务设计过于简化。为了弥补这一空白，我们引入了AgroMind，一个全面的农业遥感基准，涵盖空间感知、物体理解、场景理解和场景推理四个任务维度，共有13种任务类型，从作物识别和健康监测到环境分析。我们通过整合八个公共数据集和一个私人农田地块数据集，策划了一个高质量的评估集，其中包含27,247个问答对和19,615张图像。流程始于多源数据预处理，包括收集、格式标准化和注释细化。然后，我们通过系统地定义任务，生成多样化的农业相关问题。最后，我们利用LMMs进行推理，生成响应，并进行详细检查。我们在AgroMind上评估了20个开源LMMs和4个闭源模型。实验揭示了显著的性能差距，尤其是在空间推理和细粒度识别方面，值得注意的是，人类表现落后于几个领先的LMMs。通过建立农业遥感的标准化评估框架，AgroMind揭示了LMMs在领域知识方面的局限性，并强调了未来工作的关键挑战。数据和代码可在 https://rssysu.github.io/AgroMind/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [EASG-Bench: Video Q&A Benchmark with Egocentric Action Scene Graphs](https://arxiv.org/abs/2506.05787)
> *EASG-Bench：基于自我中心动作场景图的视频问答基准*

*Ivan Rodin, Tz-Ying Wu, Kyle Min, Sharath Nittur Sridhar, Antonino Furnari, Subarna Tripathi, Giovanni Maria Farinella* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 视频问答, 自我中心视频, 场景图, 基准测试, 视频大型语言模型

**Comment:** Accepted to SAUAFG Workshop at ICCV 2025

> **TL;DR:** EASG-Bench是一个针对自我中心视频的问答基准，其问题/答案对来源于时空接地的动态场景图。研究人员提出了一个评估框架，并发现现有模型在时间排序问题上存在性能差距，揭示了长上下文视频理解领域的研究空白。

**AI_Comments:** EASG-Bench的创新之处在于其专注于自我中心视频，并利用动态场景图来构建更细致、更具挑战性的问答对，尤其强调了时间排序问题。这对于推动视频理解，特别是长上下文和复杂交互理解领域的研究具有重要意义。通过识别现有模型在时间推理上的不足，该工作为未来的模型开发指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决现有视频问答数据集的不足，尤其是在捕捉自我中心视频中演员、动作和物体之间复杂关系方面的缺陷，并识别长上下文视频理解领域的研究空白。

**Method:** 引入了EASG-Bench，一个基于自我中心视频的问答基准，其问答对来源于时空接地的动态场景图。提出了一个系统的评估框架，并使用该基准评估了多种纯语言模型和视频大型语言模型。

**Result:** 观察到纯语言模型和视频大型语言模型之间存在性能差距，尤其是在关注时间排序的问题上。这识别了长上下文视频理解领域的一个研究空白。

**Conclusion:** EASG-Bench作为一个新的问答基准，成功揭示了现有模型在长上下文视频理解，特别是时间排序方面的不足，为未来的研究指明了方向。该基准和代码的公开将促进研究的再现性和进一步发展。

> **ai_Abstract:** 本论文介绍了EASG-Bench，一个专为自我中心视频设计的问答基准。该基准的问答对通过时空接地的动态场景图生成，这些图能够捕捉演员、动作和物体间的复杂关系。作者提出了一套系统评估框架，并用其测试了多种语言模型和视频大型语言模型。研究结果显示，在处理时间排序相关问题时，现有模型表现出明显的性能差距，这指出了长上下文视频理解领域的一个重要研究空白。为促进研究的再现性和后续发展，该基准及其配套代码已公开发布。

> **摘要翻译:** 我们引入了EASG-Bench，一个针对自我中心视频的问答基准，其问答对来源于时空接地的动态场景图，这些图捕获了演员、动作和物体之间复杂的相互关系。我们提出了一个系统的评估框架，并使用该基准评估了几种纯语言模型和视频大型语言模型（video-LLMs）。我们观察到纯语言模型和视频大型语言模型之间存在性能差距，尤其是在关注时间排序的问题上，从而识别了长上下文视频理解领域的一个研究空白。为了促进我们发现的再现性并促进进一步研究，该基准和配套代码可在以下GitHub页面获取：https://github.com/fpv-iplab/EASG-bench。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [476] [UniDet-D: A Unified Dynamic Spectral Attention Model for Object Detection under Adverse Weathers](https://arxiv.org/abs/2506.12324)
> *UniDet-D：一种统一的动态光谱注意力模型，用于恶劣天气下的目标检测*

*Wei Zhang, Yuantao Wang, Haowei Yang, Yin Zhuang, Shijian Lu, Xuerui Mao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 目标检测, 恶劣天气, 动态光谱注意力, 图像恢复, 统一框架

**Comment:** 

> **TL;DR:** UniDet-D是一个统一框架，通过动态光谱注意力机制，在单个网络中同时实现恶劣天气下的目标检测和图像恢复，提高了检测精度和泛化能力。

**AI_Comments:** 这篇论文通过引入一个统一的框架UniDet-D及其动态光谱注意力机制，创新性地解决了恶劣天气下目标检测的泛化性问题。其将图像恢复和目标检测整合到单一网络中，并能自适应地处理不同类型的图像退化，显著提升了模型在复杂真实环境中的鲁棒性和实用性。对未见天气条件的良好泛化能力是其重要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中的目标检测面临恶劣天气（如雨、雾、雪、低光照等）导致的图像退化挑战。现有方法通常针对特定天气设计，泛化性差，且未能充分利用视觉特征来处理各种图像退化问题。

**Method:** UniDet-D是一个统一框架，通过理论分析关键视觉细节在恶劣天气图像中的丢失方式，在一个网络中实现目标检测和图像恢复。它引入了动态光谱注意力机制，自适应地强调信息丰富的光谱分量并抑制不相关的分量，以实现更鲁棒和有区分度的特征表示。

**Result:** UniDet-D在不同类型的恶劣天气退化下均表现出卓越的检测精度。此外，UniDet-D对沙尘暴和雨雾混合等未见过的恶劣天气条件表现出优异的泛化能力。

**Conclusion:** UniDet-D通过其统一框架和动态光谱注意力机制，有效解决了恶劣天气下的目标检测问题，展现出优异的性能和泛化能力，具有巨大的实际部署潜力。

> **ai_Abstract:** UniDet-D是一种创新的统一框架，旨在解决恶劣天气下的目标检测挑战。该模型通过理论分析图像退化机制，设计了动态光谱注意力机制，使得在单个网络中能够同时进行目标检测和图像恢复。实验证明，UniDet-D在多种恶劣天气条件下均展现出卓越的检测精度和对未知天气的强大泛化能力，预示着其在实际应用中的巨大潜力。

> **摘要翻译:** 现实世界中的目标检测是一项具有挑战性的任务，因为捕获的图像/视频经常因雨、雾、雪、低光照等各种恶劣天气条件而遭受复杂的退化。尽管之前付出了大量的努力，但大多数现有方法都是针对一种特定类型的恶劣天气设计的，存在泛化性差、在处理各种图像退化时视觉特征利用不足的限制。我们利用对恶劣天气图像中关键视觉细节如何丢失的理论分析，设计了UniDet-D，这是一个统一的框架，解决了在各种恶劣天气条件下进行目标检测的挑战，并在一个网络中实现了目标检测和图像恢复。具体来说，所提出的UniDet-D结合了动态光谱注意力机制，该机制自适应地强调信息丰富的光谱分量，同时抑制不相关的分量，从而在各种退化类型中实现更鲁棒和有区分度的特征表示。广泛的实验表明，UniDet-D在不同类型的恶劣天气退化下均实现了卓越的检测精度。此外，UniDet-D对沙尘暴和雨雾混合等未见过的恶劣天气条件表现出优异的泛化能力，突显了其在实际部署中的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [477] [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
> *阐明特征归一化在IJEPA中的作用*

*Adam Colton* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 特征归一化, IJEPA, DynTanh, 视觉表示学习, token能量

**Comment:** 

> **TL;DR:** 本文提出特征归一化（如LN）在IJEPA中会破坏视觉token的自然能量层级，导致模型无法优先处理语义重要区域，并引入了棋盘格伪影。作者建议用DynTanh激活函数替代LN，以保留token能量，从而显著提升了ImageNet线性探针准确率并减少了深度估计的RMSE。

**AI_Comments:** 本文通过对IJEPA中特征归一化的深入分析，揭示了LN可能带来的负面影响，即破坏了语义信息与特征能量之间的自然对应关系。提出使用DynTanh替代LN是一个简洁而有效的创新点，它通过更好地保留特征的自然能量分布，使得模型能够更有效地利用语义信息，从而在多个下游任务上取得了性能提升。这对于自监督学习领域中特征表示的理解和优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在标准IJEPA中，教师编码器输出的特征会进行层归一化（LN），这被认为破坏了视觉token的自然能量层级，使得高能量（语义重要）token无法得到优先处理，并导致损失图出现棋盘格状伪影。

**Method:** 提出用DynTanh激活函数替代IJEPA中的特征层归一化（LN）。DynTanh能更好地保留token能量，允许高能量token对预测损失做出更大贡献。

**Result:** 使用DynTanh的IJEPA模型展现出更长的损失分布尾部，并修复了损失图中的棋盘格伪影。经验结果显示，对于ViT-Small，ImageNet线性探针准确率从38%提高到42.7%，并且在NYU Depth V2单目深度估计上RMSE降低了0.08。

**Conclusion:** 保留自然的token能量对于有效的自监督视觉表示学习至关重要。

> **ai_Abstract:** 本文研究了IJEPA中特征归一化的作用，指出标准LN会破坏视觉token的能量层级，导致模型无法识别语义重要区域并产生伪影。为解决此问题，作者提出用DynTanh替代LN，以更好地保留token能量，从而使高能量token能更大程度地影响预测损失。实验证明，这一改进不仅消除了损失图中的伪影，还显著提升了ImageNet线性探针准确率和深度估计性能，强调了保留自然token能量对自监督视觉学习的重要性。

> **摘要翻译:** 在标准的图像联合嵌入预测架构（IJEPA）中，教师编码器输出的特征在作为学生编码器和预测器的蒸馏目标之前会进行层归一化（LN）。我们提出这种特征归一化破坏了视觉token的自然能量层级，其中高能量token（L2范数较大的token）编码了语义上重要的图像区域。LN强制所有特征具有相同的L2范数，有效地均衡了它们的能量，并阻止模型优先处理语义丰富的区域。我们发现使用特征LN训练的IJEPA模型在损失图中表现出显著的棋盘格状伪影。我们提出用DynTanh激活函数替代特征LN，因为后者能更好地保留token能量，并允许高能量token对预测损失做出更大的贡献。我们展示了使用特征DynTanh训练的IJEPA展现出更长的损失分布尾部，并修复了损失图中的棋盘格伪影。我们的经验结果表明，我们简单的修改将ViT-Small在ImageNet线性探针上的准确率从38%提高到42.7%，并在NYU Depth V2单目深度估计上将RMSE降低了0.08。这些结果表明，保留自然的token能量对于有效的自监督视觉表示学习至关重要。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [Beyond Images: Adaptive Fusion of Visual and Textual Data for Food Classification](https://arxiv.org/abs/2308.02562)
> *图像之外：视觉与文本数据自适应融合用于食物分类*

*Prateek Mittal, Puneet Goyal, Joohi Chauhan* | **Category: cs.CV, cs.AI, cs.CY, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 食物分类, 多模态融合, 视觉数据, 文本数据, 自适应融合

**Comment:** 

> **TL;DR:** 本研究提出了一种新颖的多模态食物识别框架，通过自适应融合视觉和文本数据，显著提高了食物分类的准确性和鲁棒性，并在UPMC Food-101数据集上达到了97.84%的准确率。

**AI_Comments:** 这篇论文的创新点在于提出了一个动态自适应的多模态融合策略，能够有效结合视觉和文本数据，并且能够缓解数据缺失或不一致带来的负面影响。其在UPMC Food-101数据集上实现的97.84%的准确率显著优于单一模态和现有SOTA方法，证明了其方法的有效性和实用性。这种方法对于需要整合多种数据源的实际应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过有效结合视觉和文本模态来增强食物分类的准确性和鲁棒性，并解决数据缺失或不一致的问题。

**Method:** 本研究提出了一种新颖的多模态食物识别框架，采用动态多模态融合策略，自适应整合来自单模态视觉输入和互补文本元数据的特征。该融合机制旨在最大化信息内容利用，同时减轻缺失或不一致模态数据的不利影响。

**Result:** 在UPMC Food-101数据集上，单一模态分类准确率：图像73.60%，文本88.84%。融合两种模态后，模型准确率达到97.84%，优于现有多个最先进方法。实验分析证明了所提设置的鲁棒性、适应性和计算效率。

**Conclusion:** 所提出的多模态食物识别框架通过自适应融合视觉和文本数据，显著提升了食物分类的准确性和鲁棒性，并在实际应用场景中展现出实用性。

> **ai_Abstract:** 本文提出了一种创新的多模态食物识别框架，通过动态自适应融合视觉图像和文本元数据来提高食物分类的准确性和鲁棒性。该框架旨在有效利用多源信息并应对数据缺失或不一致问题。在UPMC Food-101数据集上的评估显示，单模态图像和文本的准确率分别为73.60%和88.84%，而融合后准确率高达97.84%，显著超越了现有技术，并展现出良好的鲁棒性、适应性和计算效率，适用于实际多模态食物识别应用。

> **摘要翻译:** 本研究引入了一种新颖的多模态食物识别框架，该框架有效结合了视觉和文本模态，以提高分类准确性和鲁棒性。所提出的方法采用动态多模态融合策略，自适应地整合来自单模态视觉输入和互补文本元数据的特征。这种融合机制旨在最大限度地利用信息内容，同时减轻缺失或不一致模态数据的不利影响。该框架在UPMC Food-101数据集上进行了严格评估，图像的单模态分类准确率为73.60%，文本为88.84%。当两种模态融合时，模型达到了97.84%的准确率，优于多种最先进的方法。广泛的实验分析证明了所提出设置的鲁棒性、适应性和计算效率，突出了其在真实世界多模态食物识别场景中的实际适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [479] [VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation](https://arxiv.org/abs/2508.03351)
> *VLMQ：通过海森增强对大型视觉语言模型进行高效训练后量化*

*Yufei Xue, Yushi Huang, Jiawei Shao, Jun Zhang* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 训练后量化, 视觉语言模型, 海森增强, 令牌重要性, 模型压缩

**Comment:** 13 pages, 5 figures

> **TL;DR:** 提出VLMQ，一种针对视觉语言模型（VLM）的训练后量化（PTQ）方法，通过引入令牌级重要性因子解决视觉令牌冗余问题，在低比特设置下实现了最先进的性能。

**AI_Comments:** VLMQ的创新点在于其提出了一个重要性感知的PTQ框架，专门解决了视觉语言模型中视觉令牌冗余导致的量化性能下降问题。通过引入令牌级重要性因子并高效计算，它弥补了现有LLM-centric PTQ方法在VLM领域的不足，对于推动大型VLM在资源受限环境下的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Hessian的LLM训练后量化（PTQ）方法在应用于视觉语言模型（VLM）时，由于未能处理VLM中存在的模态差异（即视觉令牌过多和冗余），导致性能严重下降。因此，需要一种针对VLM特点的PTQ框架。

**Method:** 本文提出了VLMQ，一个新颖的重要性感知训练后量化框架，专为视觉语言模型（VLM）设计。VLMQ通过优化一个重要性感知目标来增强Hessian矩阵，该目标引入了令牌级重要性因子，同时保持与并行权重更新的兼容性。为了确保效率和有效性，这些因子通过一次轻量级的块级反向传播计算，并由与令牌级扰动的理论联系指导。

**Result:** 在0.5B到32B的8个视觉语言模型基准测试中，VLMQ展示了最先进的（SOTA）性能，尤其是在低比特设置下。例如，在2比特量化下，VLMQ在MME-RealWorld上实现了16.45%的显著提升。

**Conclusion:** VLMQ通过解决视觉语言模型中的模态差异和视觉令牌冗余问题，显著提升了训练后量化在大型视觉语言模型上的性能，尤其是在低比特设置下，达到了最先进的水平。

> **ai_Abstract:** 本文提出了VLMQ，一种专门针对大型视觉语言模型的训练后量化（PTQ）框架。针对现有PTQ方法在VLM上因未考虑视觉令牌冗余导致的性能下降问题，VLMQ通过优化包含令牌级重要性因子的Hessian矩阵并高效计算这些因子，实现了重要性感知量化。实验证明，VLMQ在多个VLM基准测试中，尤其是在低比特量化下，取得了显著的性能提升，达到了最先进水平。

> **摘要翻译:** 训练后量化（PTQ）已成为一种有效的压缩大型模型并加速其推理而无需重新训练的方法。虽然PTQ在大型语言模型（LLM）的背景下得到了广泛研究，但其在视觉语言模型（VLM）中的适用性仍未得到充分探索。在本文中，我们发现了VLM的模态差异（即文本令牌有限与视觉令牌过多和冗余）。然而，现有的基于Hessian的LLM PTQ方法在量化过程中对所有令牌一视同仁，导致应用于VLM时性能严重下降。受此观察启发，我们提出了一种专为VLM量身定制的新颖的重要性感知PTQ框架，名为VLMQ。具体来说，为了解决视觉令牌冗余问题，VLMQ 1）优化了一个重要性感知目标，该目标产生了一个增强的Hessian矩阵，其中包含令牌级重要性因子，同时保持与并行权重更新的兼容性；2）通过一次轻量级的块级反向传播计算这些因子，并由与令牌级扰动的理论联系指导，从而确保效率和有效性。在0.5B至32B VLM上的8个基准测试中的广泛评估表明，我们的VLMQ具有最先进（SOTA）的性能，尤其是在低比特设置下。例如，在2比特量化下，它在MME-RealWorld上实现了16.45%的显著提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [481] [EgoPrompt: Prompt Pool Learning for Egocentric Action Recognition](https://arxiv.org/abs/2508.03266)
> *EgoPrompt：用于第一人称动作识别的提示池学习*

*Huaihai Lyu, Chaofan Chen, Yuheng Ji, Changsheng Xu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 第一人称动作识别, 提示学习, 提示池, 动词-名词交互, 泛化

**Comment:** 

> **TL;DR:** EgoPrompt提出了一种基于提示学习的框架，通过构建统一提示池并引入多样化池准则，有效整合动词和名词组件，显著提升了第一人称动作识别的泛化能力。

**AI_Comments:** EgoPrompt的创新点在于其巧妙地利用提示学习来显式建模第一人称动作识别中动词和名词组件之间的内在语义和上下文关系，这克服了以往方法独立处理两者的局限性。统一提示池和多样化池准则的设计是其核心贡献，特别是在提升模型泛化能力方面表现出色。该方法对于增强现实和虚拟现实领域中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有第一人称动作识别方法将动词和名词组件视为独立的分类任务，忽略了它们固有的语义和上下文关系，导致表征碎片化和泛化能力欠佳。

**Method:** 本文提出了一个名为EgoPrompt的基于提示学习的框架。该框架在现有提示策略的基础上，构建了一个统一提示池空间来建立两种组件表征之间的交互。具体来说，动词和名词的组件表征首先被分解为提示对形式的细粒度模式，然后通过基于注意力的机制融合这些模式级表征，以促进跨组件交互。为确保提示池的信息量，还引入了新颖的训练目标——多样化池准则，通过提示选择频率正则化和提示知识正交化两个方面实现目标。

**Result:** EgoPrompt在Ego4D、EPIC-Kitchens和EGTEA数据集上进行了广泛实验，结果一致表明其在数据集内、跨数据集和从基类到新类的泛化基准上均达到了最先进的性能。

**Conclusion:** 通过提出EgoPrompt框架，有效解决了第一人称动作识别中动词和名词组件独立处理的问题，通过提示池学习和跨组件交互显著提升了模型的泛化能力，达到了最先进的性能。

> **ai_Abstract:** 本文针对第一人称动作识别中动词和名词组件独立处理导致泛化能力差的问题，提出了一种基于提示学习的EgoPrompt框架。该框架通过构建统一提示池空间，将动词和名词表征分解为细粒度提示对模式，并通过注意力机制融合以促进跨组件交互。为确保提示池的信息量，EgoPrompt还引入了多样化池准则（包括提示选择频率正则化和提示知识正交化）。在Ego4D、EPIC-Kitchens和EGTEA等数据集上的广泛实验表明，EgoPrompt在多种泛化基准上均达到了最先进的性能。

> **摘要翻译:** 在增强现实和虚拟现实应用需求日益增长的推动下，第一人称动作识别已成为一个突出的研究领域。它通常分为两个子任务：识别所执行的行为（即动词成分）和识别被作用的物体（即名词成分）。然而，大多数现有方法将这两个成分视为独立的分类任务，侧重于提取特定于成分的知识，同时忽略了它们固有的语义和上下文关系，导致表征碎片化和次优的泛化能力。为了解决这些挑战，我们提出了一种基于提示学习的框架EgoPrompt来执行第一人称动作识别任务。在现有捕获特定成分知识的提示策略基础上，我们构建了一个统一提示池空间，以建立两种成分表征之间的交互。具体而言，成分表征（来自动词和名词）首先以提示对形式分解为细粒度模式。然后，这些模式级表征通过基于注意力的机制进行融合，以促进跨成分交互。为了确保提示池的信息量，我们进一步引入了一个新颖的训练目标——多样化池准则。该目标从两个角度实现了我们的目标：提示选择频率正则化和提示知识正交化。在Ego4D、EPIC-Kitchens和EGTEA数据集上进行了广泛实验。结果一致表明EgoPrompt在数据集内、跨数据集和从基类到新类的泛化基准上均实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [Understanding and Benchmarking the Trustworthiness in Multimodal LLMs for Video Understanding](https://arxiv.org/abs/2506.12336)
> *理解和评估多模态大语言模型在视频理解中的可信度*

*Youze Wang, Zijun Chen, Ruoyu Chen, Shishen Gu, Wenbo Hu, Jiayang Liu, Yinpeng Dong, Hang Su, Jun Zhu, Meng Wang, Richang Hong* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态大语言模型, 视频理解, 可信度, 基准测试, 鲁棒性

**Comment:** 

> **TL;DR:** 本研究引入了Trust-videoLLMs，一个全面的基准测试，用于评估23个视频LLMs在真实性、鲁棒性、安全性、公平性和隐私性五个关键维度的可信度，揭示了当前模型在动态场景理解、跨模态扰动弹性和风险缓解方面的局限性。

**AI_Comments:** 这项研究的创新之处在于首次全面构建了一个评估多模态大语言模型在视频理解中可信度的基准，超越了传统的准确性评估，涵盖了鲁棒性、安全性、公平性和隐私等关键维度。其重要性在于揭示了当前videoLLMs在实际应用中面临的挑战，并为未来模型开发指明了方向，即需要关注数据多样性和多模态对齐。该基准工具的公开可用性也为社区提供了标准化的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视频理解中的多模态大语言模型（videoLLMs）取得了进展，但它们在事实不准确性、有害内容、偏见、幻觉和隐私风险等方面的挑战，损害了其可靠性。

**Method:** 研究引入了Trust-videoLLMs，一个综合性基准，评估了23个最先进的videoLLMs（5个商业模型，18个开源模型）。该基准涵盖了真实性、鲁棒性、安全性、公平性和隐私性五个关键维度，包含30项任务，使用改编、合成和标注的视频来评估时空风险、时间一致性和跨模态影响。

**Result:** 结果显示，模型在动态场景理解、跨模态扰动弹性和现实世界风险缓解方面存在显著局限性。虽然开源模型偶尔表现优异，但专有模型通常展现出更高的可信度，且模型规模并非总能带来性能提升。

**Conclusion:** 研究结果强调了增强训练数据多样性和鲁棒多模态对齐的必要性。Trust-videoLLMs提供了一个公开可用的、可扩展的工具包，用于标准化可信度评估，填补了以准确性为重点的基准与对鲁棒性、安全性、公平性和隐私性的需求之间的关键空白。

> **ai_Abstract:** 本研究针对视频理解中多模态大语言模型（videoLLMs）面临的可靠性挑战，提出了名为Trust-videoLLMs的综合性基准测试。该基准评估了23个主流videoLLMs在真实性、鲁棒性、安全性、公平性和隐私性五个维度的表现，通过30项任务和多种视频类型评估时空风险。研究发现当前模型在动态场景理解、跨模态扰动和实际风险缓解方面存在显著不足。虽然专有模型通常更可信，但模型规模并非性能提升的决定因素。研究强调需改进训练数据多样性和多模态对齐，并提供Trust-videoLLMs作为标准化可信度评估的开源工具。

> **摘要翻译:** 视频理解中的多模态大语言模型（videoLLMs）的最新进展增强了它们处理复杂时空数据的能力。然而，事实不准确性、有害内容、偏见、幻觉和隐私风险等挑战损害了它们的可靠性。本研究引入了Trust-videoLLMs，这是一个首次全面的基准测试，用于评估23个最先进的videoLLMs（5个商业模型，18个开源模型）在五个关键维度上的可信度：真实性、鲁棒性、安全性、公平性和隐私性。该框架包含30项任务，使用改编、合成和标注的视频，评估时空风险、时间一致性和跨模态影响。结果揭示了在动态场景理解、跨模态扰动弹性和现实世界风险缓解方面的显著局限性。虽然开源模型偶尔表现出色，但专有模型通常表现出更高的可信度，尽管规模并不总能持续改进性能。这些发现强调了增强训练数据多样性和鲁棒多模态对齐的必要性。Trust-videoLLMs提供了一个公开可用的、可扩展的工具包，用于标准化可信度评估，解决了以准确性为中心的基准与对鲁棒性、安全性、公平性和隐私性的需求之间的关键差距。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?](https://arxiv.org/abs/2508.02927)
> *使用超小型卷积神经网络的红外目标检测：ImageNet预训练仍然有用吗？*

*Srikanth Muralidharan, Heitor R. Medeiros, Masih Aminbeidokhti, Eric Granger, Marco Pedersoli* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 红外目标检测, 超小型卷积神经网络, ImageNet预训练, 鲁棒性, 边缘计算

**Comment:** 

> **TL;DR:** 研究发现，对于红外目标检测中的超小型模型，ImageNet预训练仍然有用，但在一定容量阈值后，其对域外检测鲁棒性的提升效果会递减。

**AI_Comments:** 该论文解决了在资源受限设备上部署AI模型的重要实际问题，特别是关于预训练对超小型模型影响的未明确性。其创新点在于系统地研究了ImageNet预训练对超小型ConvNets在红外目标检测中域外鲁棒性的影响，并提出了关于模型容量与预训练收益递减的发现。这对边缘计算和嵌入式AI领域的模型部署具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多实际应用需要模型在有限硬件的小型嵌入式设备上运行，同时对不同操作条件和模态保持鲁棒性。对于小型模型，预训练的效果尚不明确，尤其是在红外视觉模态的下游目标检测任务中。

**Method:** 本研究调查了ImageNet预训练对参数小于1M的超小型骨干网络架构的影响，重点关注其在红外视觉模态下游目标检测任务中的鲁棒性。研究人员根据标准目标识别架构的缩放定律构建了两个超小型骨干网络家族，并系统地研究了它们的性能。实验在三个不同的数据集上进行。

**Result:** 实验结果表明，ImageNet预训练仍然有用，但超出一定的容量阈值后，它在域外检测鲁棒性方面的收益会递减。

**Conclusion:** 作者建议从业者仍应使用预训练，并且在可能的情况下避免使用过小的模型，因为虽然它们可能在域内问题上表现良好，但在工作条件不同时会变得脆弱。

> **ai_Abstract:** 本研究探讨了ImageNet预训练对红外目标检测中超小型卷积神经网络（参数小于1M）鲁棒性的影响。通过构建和测试两类超小型骨干网络，研究发现ImageNet预训练对这类模型仍然有益，但在模型容量达到一定阈值后，其对域外检测鲁棒性的提升效果会递减。作者建议在实际应用中继续采用预训练，并谨慎选择模型大小，以确保在不同工况下的鲁棒性。

> **摘要翻译:** 许多实际应用需要识别模型能够对不同的操作条件和模态保持鲁棒性，同时在硬件受限的小型嵌入式设备上运行。虽然对于正常大小的模型，预训练在准确性和鲁棒性方面被认为是非常有益的，但对于可用于嵌入式和边缘设备的小型模型，其效果尚不清楚。在这项工作中，我们研究了ImageNet预训练对越来越小的骨干网络架构（参数小于1M的超小型模型）在红外视觉模态下游目标检测任务中鲁棒性的影响。我们使用从标准目标识别架构导出的缩放定律，构建了两个超小型骨干网络家族并系统地研究了它们的性能。我们在三个不同数据集上的实验表明，ImageNet预训练仍然有用，但超过一定的容量阈值后，它在域外检测鲁棒性方面的收益会递减。因此，我们建议从业者仍然使用预训练，并在可能的情况下避免使用过小的模型，因为虽然它们可能在域内问题上表现良好，但在工作条件不同时，它们会变得脆弱。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [486] [SARD: Segmentation-Aware Anomaly Synthesis via Region-Constrained Diffusion with Discriminative Mask Guidance](https://arxiv.org/abs/2508.03143)
> *SARD：基于区域约束扩散和判别性掩码引导的分割感知异常合成*

*Yanshu Wang, Xichen Xu, Xiaoning Lei, Guoyang Xie* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 异常合成, 扩散模型, 区域约束, 判别性掩码引导, 工业异常检测

**Comment:** Accepted by The 2025 International Conference on Machine Intelligence
  and Nature-InspireD Computing (MIND)

> **TL;DR:** SARD是一种新的扩散模型，通过区域约束和判别性掩码引导，解决了现有方法在工业异常合成中空间控制和区域保真度不足的问题，实现了像素级异常合成的SOTA。

**AI_Comments:** SARD的创新点在于结合了区域约束扩散和判别性掩码引导，有效解决了扩散模型在生成特定区域（异常）时难以保持背景完整性和区域精度的挑战。这种方法对于工业异常检测领域具有重要意义，因为它能生成高质量的训练数据，从而提升检测系统的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高工业异常检测系统的鲁棒性，需要合成逼真且空间精确的异常。现有的基于扩散的方法在建模复杂缺陷模式方面表现出色，但在空间可控性和保持细粒度区域保真度方面存在不足，导致背景伪影。

**Method:** 提出SARD框架，包含两个核心组件：1. 区域约束扩散（RCD）过程：在反向去噪阶段冻结背景，仅选择性地更新前景异常区域，从而有效减少背景伪影。2. 判别性掩码引导（DMG）模块：集成到判别器中，通过像素级掩码引导，同时评估全局真实性和局部异常保真度。

**Result:** 在MVTec-AD和BTAD数据集上的广泛实验表明，SARD在分割精度和视觉质量方面超越了现有方法，在像素级异常合成方面达到了新的最先进水平。

**Conclusion:** SARD通过其新颖的区域约束扩散和判别性掩码引导机制，有效解决了现有扩散模型在异常合成中空间控制和区域保真度不足的问题，成功实现了逼真且空间精确的异常合成，并达到了像素级异常合成的最新技术水平。

> **ai_Abstract:** 本文提出SARD框架，旨在解决现有扩散模型在工业异常合成中空间控制和区域保真度不足的问题。SARD通过引入区域约束扩散（RCD）过程来保护背景并仅更新异常区域，并结合判别性掩码引导（DMG）模块，实现对全局真实性和局部异常保真度的联合评估。实验证明，SARD在分割精度和视觉质量方面优于现有方法，达到了像素级异常合成的最新水平。

> **摘要翻译:** 综合分析：合成逼真且空间精确的异常对于提高工业异常检测系统的鲁棒性至关重要。虽然最近基于扩散的方法在建模复杂缺陷模式方面表现出强大的能力，但它们在空间可控性方面常常遇到困难，并且未能保持细粒度的区域保真度。为了克服这些限制，我们提出了SARD（基于区域约束扩散和判别性掩码引导的分割感知异常合成），一个专门为异常生成设计的新型基于扩散的框架。我们的方法引入了一个区域约束扩散（RCD）过程，通过在反向去噪阶段冻结背景并选择性地仅更新前景异常区域来保留背景，从而有效减少背景伪影。此外，我们将判别性掩码引导（DMG）模块集成到判别器中，通过像素级掩码引导，实现对全局真实性和局部异常保真度的联合评估。在MVTec-AD和BTAD数据集上进行的广泛实验表明，SARD在分割精度和视觉质量方面超越了现有方法，为像素级异常合成树立了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [488] [MAUP: Training-free Multi-center Adaptive Uncertainty-aware Prompting for Cross-domain Few-shot Medical Image Segmentation](https://arxiv.org/abs/2508.03511)
> *MAUP：面向跨域小样本医学图像分割的免训练多中心自适应不确定性感知提示*

*Yazhou Zhu, Haofeng Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学图像分割, 小样本学习, 免训练, 提示学习, SAM

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** MAUP是一种免训练的跨域小样本医学图像分割方法，通过自适应提示将SAM应用于医学图像分割，解决了传统方法对大量训练的依赖。

**AI_Comments:** 该论文提出了一种创新的免训练方法，将大型自然图像模型（如SAM）应用于医学图像分割，解决了现有CD-FSMIS方法训练成本高、部署困难的问题。其核心创新在于MAUP策略，通过智能地生成和优化提示，实现了对医学图像的有效分割。这项工作对于使基础模型更易于在医学图像等专业领域应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前跨域小样本医学图像分割 (CD-FSMIS) 模型依赖于大量的训练过程，这限制了模型的通用性和部署便捷性。本研究旨在提出一种免训练的解决方案，以利用大型视觉模型（如SAM）来解决这一问题。

**Method:** 本研究提出了免训练的MAUP（Multi-center Adaptive Uncertainty-aware Prompting）策略，用于将基于自然图像训练的基础模型Segment Anything Model (SAM) 适应到CD-FSMIS任务中。MAUP包含三项关键创新：1) 基于K-means聚类的多中心提示生成，以实现全面的空间覆盖；2) 不确定性感知提示选择，重点关注挑战区域；3) 自适应提示优化，根据目标区域复杂性动态调整。该方法结合了预训练的DINOv2特征编码器。

**Result:** MAUP在三个医学数据集上实现了精确的分割结果，并且无需任何额外训练。与几种传统的CD-FSMIS模型和免训练FSMIS模型相比，MAUP表现出优越的性能。

**Conclusion:** MAUP成功地将大型视觉基础模型（如SAM）以免训练的方式应用于跨域小样本医学图像分割任务，有效解决了现有方法对大量训练的依赖，并取得了精确的分割结果。

> **ai_Abstract:** 本论文提出了一种名为MAUP的免训练方法，用于跨域小样本医学图像分割 (CD-FSMIS)。MAUP通过K-means聚类生成多中心提示，选择不确定性感知提示关注挑战区域，并自适应优化提示以适应目标区域复杂性，从而将Segment Anything Model (SAM) 适应到医学图像分割任务中。结合DINOv2特征编码器，MAUP在三个医学数据集上实现了精确分割，且无需额外训练，优于现有方法。

> **摘要翻译:** 跨域小样本医学图像分割 (CD-FSMIS) 是一种利用其他领域知识对有限标注的医学图像进行分割的潜在解决方案。当前 CD-FSMIS 模型的显著性能依赖于对其他源医学领域的大量训练过程，这降低了模型的通用性和部署便捷性。随着自然图像大型视觉模型的发展，我们提出了一种免训练的 CD-FSMIS 模型，该模型引入了多中心自适应不确定性感知提示 (MAUP) 策略，用于将基于自然图像训练的基础模型 Segment Anything Model (SAM) 适应到 CD-FSMIS 任务中。具体来说，MAUP 包含三项关键创新：(1) 基于 K-means 聚类的多中心提示生成，实现全面的空间覆盖；(2) 不确定性感知提示选择，关注挑战区域；(3) 自适应提示优化，可根据目标区域复杂性动态调整。结合预训练的 DINOv2 特征编码器，MAUP 在三个医学数据集上实现了精确的分割结果，与几种传统的 CD-FSMIS 模型和免训练 FSMIS 模型相比，无需任何额外训练。源代码可在：https://github.com/YazhouZhu19/MAUP 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement](https://arxiv.org/abs/2506.18346)
> *BSMamba：低光照图像增强中的亮度与语义建模长程交互*

*Tongshun Zhang, Pingping Liu, Mengen Cai, Zijian Zhang, Yubing Lu, Qiuzhan Zhou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 低光照图像增强, Mamba, 状态空间模型, 亮度建模, 语义建模

**Comment:** 

> **TL;DR:** BSMamba提出了一种新的视觉Mamba架构，通过亮度Mamba和语义Mamba分别处理图像亮度和语义一致性，在低光照图像增强中实现了SOTA性能并保持了语义一致性。

**AI_Comments:** BSMamba的创新之处在于其双Mamba结构，即亮度Mamba和语义Mamba，通过智能地基于图像内容（亮度、语义）而非固定的扫描模式来处理长程依赖，有效解决了现有视觉Mamba在图像恢复中面临的局限性。这种方法不仅提升了低光照图像增强的性能，也为未来基于状态空间模型的图像处理提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前的低光照图像增强(LLIE)方法在提高亮度的同时，难以兼顾语义一致性、细节保持和计算效率。此外，现有的视觉Mamba模型将2D图像展平为1D序列，限制了远距离token之间的交互和长程依赖的捕获能力。

**Method:** 提出了一种名为BSMamba的新型视觉Mamba架构，包含两个专门设计的组件：亮度Mamba和语义Mamba。亮度Mamba通过亮度引导的选择性注意力，优先连接亮度相似的远距离token，解决亮度恢复问题。语义Mamba则优先连接语义相似的token，以保持图像增强过程中的上下文一致性和语义的层次结构。BSMamba通过基于亮度与语义相似性而非任意扫描模式来建模token。

**Result:** 大量实验表明，BSMamba在低光照图像增强任务中实现了最先进的性能，同时有效保持了语义一致性。

**Conclusion:** BSMamba通过创新的亮度与语义建模，成功解决了低光照图像增强中亮度提升与语义保持的难题，并在性能上超越现有方法。

> **ai_Abstract:** 本文提出了BSMamba，一种新颖的视觉Mamba架构，旨在解决低光照图像增强（LLIE）中亮度提升与语义一致性保持的挑战，并改进现有Mamba模型在处理长程依赖时的局限性。BSMamba包含亮度Mamba和语义Mamba两个核心组件，分别通过亮度引导和语义相似性优先连接远距离token，从而实现更有效的亮度恢复和语义保持。实验证明BSMamba在LLIE任务上达到了SOTA性能。

> **摘要翻译:** 当前的低光照图像增强（LLIE）方法在同时提高亮度和保持语义一致性、精细细节以及计算效率方面面临显著限制。随着状态空间模型，特别是Mamba的出现，图像恢复取得了显著性能，然而现有的视觉Mamba方法通过固定的扫描规则将2D图像展平为1D token序列，这严重限制了具有因果关系的远距离token之间的交互，并限制了它们捕获有意义的长程依赖的能力。为了解决这些基本限制，我们提出了BSMamba，一种新颖的视觉Mamba架构，它包含两个专门设计的组件：亮度Mamba和语义Mamba。亮度Mamba通过优先连接具有相似亮度水平的远距离token来彻底改变token交互模式，通过亮度引导的选择性注意力有效解决了LLIE任务中亮度恢复的挑战。作为补充，语义Mamba在共享相似语义含义的token之间建立优先交互，允许模型通过连接图像中语义相关的区域来保持上下文一致性，从而在增强过程中保留图像语义的层次结构。通过基于亮度相似性和语义相似性而非任意扫描模式智能地建模token，BSMamba超越了传统token序列化的限制，同时遵循因果建模的原则。大量实验表明，BSMamba在LLIE中实现了最先进的性能，同时保持了语义一致性。代码可在https://github.com/bywlzts/BSMamba 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [510] [LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration](https://arxiv.org/abs/2310.03669)
> *LumiNet：感知驱动的知识蒸馏通过统计Logit校准*

*Md. Ismail Hossain, M M Lutfe Elahi, Sameera Ramasinghe, Ali Cheraghian, Fuad Rahman, Nabeel Mohammed, Shafin Rahman* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 知识蒸馏, Logit校准, 感知驱动, 深度学习, 模型压缩

**Comment:** Accepted at Transactions on Machine Learning Research (TMLR), August
  2025

> **TL;DR:** LumiNet通过引入“感知”概念和统计Logit校准，显著提升了基于Logit的知识蒸馏性能，甚至超越了领先的基于特征的方法。

**AI_Comments:** 这篇论文的创新点在于提出了“感知”概念和统计Logit校准，成功弥补了基于Logit的知识蒸馏与基于特征方法之间的性能差距，甚至超越了后者。这为Logit蒸馏研究提供了新的方向，并可能推动其在实际应用中的进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Logit的知识蒸馏方法通常表现不如基于特征的方法，存在性能差距。本文旨在弥补这一差距，提升基于Logit的蒸馏效果，并解决Logit蒸馏中的过度自信问题。

**Method:** 提出了LumiNet，一种新颖的知识蒸馏算法，旨在增强基于Logit的蒸馏。引入了“感知”的概念，旨在根据模型的表示能力校准Logits。通过考虑批次中样本与其他样本的关系来重建样本的Logits。

**Result:** LumiNet在CIFAR-100、ImageNet和MSCOCO等基准测试中表现出色，超越了领先的基于特征的方法。例如，在ImageNet上，与使用ResNet18和MobileNetV2的KD相比，分别提高了1.5%和2.05%。

**Conclusion:** LumiNet通过感知驱动的统计Logit校准，成功提升了基于Logit的知识蒸馏性能，使其超越了传统的基于特征的方法。

> **ai_Abstract:** 本文提出了LumiNet，一种创新的知识蒸馏算法，专门用于提升基于Logit的蒸馏性能。通过引入“感知”概念并进行统计Logit校准，LumiNet有效解决了Logit蒸馏中的过度自信问题，并能通过考虑批次内样本关系来重建Logits。实验证明，LumiNet在多个基准测试中优于现有的基于特征的知识蒸馏方法，显著提升了蒸馏效果。

> **摘要翻译:** 在知识蒸馏文献中，基于特征的方法由于能够有效利用大型教师模型而占据主导地位。相比之下，旨在从教师模型中提取“暗知识”的基于Logit的方法通常表现不如基于特征的方法。为了弥合这一差距，我们提出了LumiNet，一种新颖的知识蒸馏算法，旨在增强基于Logit的蒸馏。我们引入了“感知”的概念，旨在根据模型的表示能力校准Logits。这个概念解决了基于Logit的蒸馏方法中的过度自信问题，同时还引入了一种从教师模型中蒸馏知识的新方法。它通过考虑批次中样本与其他样本的关系来重建样本的Logits。LumiNet在CIFAR-100、ImageNet和MSCOCO等基准测试中表现出色，超越了领先的基于特征的方法，例如，与ImageNet上使用ResNet18和MobileNetV2的KD相比，它分别显示出1.5%和2.05%的改进。代码可在https://github.com/ismail31416/LumiNet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [511] [MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention](https://arxiv.org/abs/2507.02488)
> *MedFormer：具有内容感知双稀疏选择注意的分层医学视觉Transformer*

*Zunhui Xia, Hongxing Li, Libin Lan* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学图像识别, 视觉Transformer, 稀疏注意力, 分层结构, MedFormer

**Comment:** 13 pages, 9 figures, 10 tables; The code is available at
  https://github.com/XiaZunhui/MedFormer

> **TL;DR:** MedFormer是一种高效且通用的医学视觉Transformer，通过分层结构和内容感知双稀疏选择注意力解决了现有方法的通用性和计算效率问题。

**AI_Comments:** MedFormer的创新之处在于其结合了分层金字塔结构和内容感知稀疏注意力机制，有效解决了医学图像识别中视觉Transformer的通用性和计算效率瓶颈。DSSA的设计特别是其内容感知能力，有望提升模型在复杂医学图像中的特征提取能力和鲁棒性，具有重要的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学图像识别中的视觉Transformer方法面临两大挑战：一是任务特定和架构定制，通用性受限；二是全注意力计算成本高，或手工稀疏注意力性能不佳。

**Method:** 本文提出了MedFormer，一种高效的医学视觉Transformer。它采用金字塔缩放结构作为通用骨干网络，适用于图像分类和密集预测（如语义分割、病灶检测）等多种任务，以实现分层特征表示并降低计算负荷。同时，引入了新颖的具有内容感知能力的双稀疏选择注意力（DSSA），旨在明确关注最相关内容，从而提高计算效率、抗噪声鲁棒性并保持高性能。

**Result:** 理论分析表明MedFormer在通用性和效率方面优于现有医学视觉Transformer。在各种成像模态数据集上的广泛实验证明，MedFormer在图像分类、语义分割和病灶检测这三种医学图像识别任务中均持续提升了性能。

**Conclusion:** MedFormer为医学图像识别提供了一个高效且通用的解决方案，具有强大的临床应用潜力。

> **ai_Abstract:** MedFormer是一种新型的医学视觉Transformer，旨在解决现有方法在通用性和计算效率上的不足。它通过采用金字塔缩放结构作为多任务通用骨干网络，并引入内容感知双稀疏选择注意力（DSSA）来优化性能和效率。实验证明MedFormer在多种医学图像识别任务中表现出更高的通用性和效率，具有潜在的临床应用价值。

> **摘要翻译:** 医学图像识别是辅助临床诊断的关键方式，能够更准确、及时地识别疾病和异常。基于视觉Transformer的方法已被证明在处理各种医学识别任务中有效。然而，这些方法面临两个主要挑战。首先，它们通常是任务特定和架构定制的，限制了其通用性。其次，它们通常要么采用全注意力来建模长程依赖关系，导致高计算成本，要么依赖手工设计的稀疏注意力，可能导致次优性能。为了解决这些问题，我们提出了MedFormer，一种高效的医学视觉Transformer，具有两个关键思想。首先，它采用金字塔缩放结构作为各种医学图像识别任务（包括图像分类和语义分割、病灶检测等密集预测任务）的通用骨干网络。这种结构有助于分层特征表示，同时降低特征图的计算负荷，这对于提升性能非常有益。其次，它引入了一种新颖的具有内容感知能力的双稀疏选择注意力（DSSA），以提高计算效率和抗噪声鲁棒性，同时保持高性能。作为MedFormer的核心构建技术，DSSA旨在明确关注最相关的内容。理论分析表明，MedFormer在通用性和效率方面优于现有医学视觉Transformer。在各种成像模态数据集上的大量实验表明，MedFormer在上述所有三种医学图像识别任务中始终提高了性能。MedFormer为医学图像识别提供了一个高效且通用的解决方案，具有强大的临床应用潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [Draw Your Mind: Personalized Generation via Condition-Level Modeling in Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03481)
> *画出你的想法：通过条件级建模在文本到图像扩散模型中实现个性化生成*

*Hyungjin Kim, Seokho Ahn, Young-Duk Seo* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 个性化生成, 文本到图像扩散模型, 条件级建模, DrUM, 用户画像

**Comment:** Accepted at ICCV 2025

> **TL;DR:** DrUM通过条件级建模而非提示级建模，解决了文本到图像扩散模型中个性化生成不准确的问题，实现了无需微调的兼容性。

**AI_Comments:** DrUM的创新之处在于将个性化生成从提示级建模转移到条件级建模，解决了现有方法中输入标记容量的限制。其与开源文本编码器的无缝集成以及无需额外微调的兼容性，极大地提升了其在实际应用中的潜力和易用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像（T2I）扩散模型中的个性化生成主要依赖于提示级建模，但由于T2I扩散模型的输入标记容量有限，导致个性化不准确。

**Method:** 我们提出了DrUM，一种新颖的方法，它将用户画像与基于Transformer的适配器相结合，通过在潜在空间中进行条件级建模来实现个性化生成。

**Result:** DrUM在大型数据集上表现出强大的性能，并且可以与开源文本编码器无缝集成，使其与广泛使用的基础T2I模型兼容，而无需额外的微调。

**Conclusion:** DrUM通过条件级建模有效解决了现有T2I扩散模型在个性化生成方面因输入标记容量限制而导致的不准确问题，实现了高性能和广泛兼容性。

> **ai_Abstract:** 本研究提出了一种名为DrUM的新方法，旨在解决现有文本到图像（T2I）扩散模型中个性化生成不准确的问题。与现有依赖提示级建模的方法不同，DrUM通过将用户画像与基于Transformer的适配器相结合，在潜在空间中进行条件级建模，从而实现个性化生成。该方法在大型数据集上表现出色，并能与现有T2I模型无缝集成且无需额外微调。

> **摘要翻译:** 文本到图像（T2I）扩散模型中的个性化生成旨在以最少的用户干预，将用户的个性化偏好自然地融入生成过程。然而，现有研究主要依赖于大规模模型中的提示级建模，由于T2I扩散模型的输入标记容量有限，这通常会导致不准确的个性化。为了解决这些限制，我们提出了DrUM，一种新颖的方法，它将用户画像与基于Transformer的适配器相结合，通过在潜在空间中进行条件级建模来实现个性化生成。DrUM在大型数据集上表现出强大的性能，并且可以与开源文本编码器无缝集成，使其与广泛使用的基础T2I模型兼容，而无需额外的微调。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [515] [Distribution-aware Knowledge Unification and Association for Non-exemplar Lifelong Person Re-identification](https://arxiv.org/abs/2508.03516)
> *非示例终身行人重识别中的分布感知知识统一与关联*

*Shiben Liu, Mingyue Xu, Huijie Fan, Qiang Wang, Yandong Tang, Zhi Han* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 终身行人重识别, 知识统一, 分布感知, 知识关联, 非示例学习

**Comment:** 9 papges, 6 figures

> **TL;DR:** 本文提出了一个名为DKUA的新框架，用于终身行人重识别（LReID），以通过分布感知建模和统一知识关联来解决遗忘和泛化挑战，在不存储旧样本的情况下，在反遗忘和泛化能力方面显著优于现有方法。

**AI_Comments:** 该论文通过提出DKUA框架，在非示例终身行人重识别领域做出了重要贡献。其创新点在于引入了分布感知和跨域统一知识学习，有效解决了现有方法中忽视的关键问题。通过域风格建模、自适应知识整合、统一知识关联和基于分布的知识迁移等多个模块的协同作用，该方法在知识保留和新知识适应之间取得了更好的平衡，显著提升了LReID的性能。特别是在不存储旧样本的情况下实现性能提升，这一点对于实际应用具有重要意义。该研究为LReID领域提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 终身行人重识别（LReID）面临着一个关键挑战：平衡旧知识的保留与新信息的适应。现有的LReID方法通常采用知识蒸馏来强制表示对齐，但它们忽略了特定的分布感知和跨域统一知识学习，而这两者对于解决该挑战至关重要。

**Method:** 我们提出了一个新颖的分布感知知识统一和关联（DKUA）框架。该框架对每个实例进行域风格建模，以传播域特定表示，从而增强抗遗忘和泛化能力。具体来说，我们设计了一个分布感知模型，将当前域的实例级表示转换为具有不同域风格的域特定表示，从而在不存储旧样本的情况下保留学习到的知识。接着，我们提出了自适应知识整合（AKC）来动态生成统一表示作为跨域表示中心。为了进一步减轻遗忘，我们开发了统一知识关联（UKA）机制，该机制探索统一表示作为桥梁，明确地建模域间关联，减少域间差距。最后，提出了基于分布的知识迁移（DKT）来防止当前域分布偏离跨域分布中心，从而提高适应能力。

**Result:** 实验结果表明，我们的DKUA在反遗忘和泛化能力方面，平均mAP/R@1分别比现有方法提高了7.6%/5.3%。

**Conclusion:** 本文提出的分布感知知识统一和关联（DKUA）框架通过有效的知识保留和适应机制，显著提升了终身行人重识别的性能，尤其在反遗忘和泛化能力方面表现出色。

> **ai_Abstract:** 本文针对终身行人重识别（LReID）中旧知识保留与新信息适应的平衡挑战，提出了一个新颖的分布感知知识统一和关联（DKUA）框架。该框架通过分布感知模型实现域特定表示的传播，结合自适应知识整合（AKC）动态生成统一的跨域表示中心，并利用统一知识关联（UKA）机制显式建模域间关联。此外，还引入了基于分布的知识迁移（DKT）以防止当前域分布偏离中心。实验证明，DKUA在不存储旧样本的情况下，在反遗忘和泛化能力方面均显著优于现有方法。

> **摘要翻译:** 终身行人重识别（LReID）面临一个关键挑战：平衡旧知识的保留与新信息的适应。现有的LReID方法通常采用知识蒸馏来强制表示对齐。然而，这些方法忽略了两个关键方面：特定的分布感知和跨域统一知识学习，而这两者对于解决这一挑战都至关重要。为了克服这些限制，我们提出了一个新颖的分布感知知识统一和关联（DKUA）框架，其中对每个实例进行域风格建模以传播域特定表示，从而增强抗遗忘和泛化能力。具体来说，我们设计了一个分布感知模型，将当前域的实例级表示转换为具有不同域风格的域特定表示，在不存储旧样本的情况下保留学习到的知识。接下来，我们提出了自适应知识整合（AKC）来动态生成统一表示作为跨域表示中心。为了进一步减轻遗忘，我们开发了统一知识关联（UKA）机制，该机制探索统一表示作为桥梁，明确地建模域间关联，减少域间差距。最后，提出了基于分布的知识迁移（DKT）来防止当前域分布偏离跨域分布中心，从而提高适应能力。实验结果表明，我们的DKUA在反遗忘和泛化能力方面，平均mAP/R@1分别比现有方法提高了7.6%/5.3%。我们的代码将公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [519] [LORE: Latent Optimization for Precise Semantic Control in Rectified Flow-based Image Editing](https://arxiv.org/abs/2508.03144)
> *LORE：基于整流流的图像编辑中用于精确语义控制的潜在优化*

*Liangyang Ouyang, Jiafeng Mao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像编辑, 文本驱动, 潜在优化, 整流流, 语义控制

**Comment:** We will make our implementation available soon

> **TL;DR:** LORE通过直接优化倒置噪声解决了基于整流流的图像编辑中语义偏差导致的问题，实现了稳定、可控和通用的概念替换。

**AI_Comments:** LORE的创新之处在于其无需训练的特性以及直接优化潜在空间中的倒置噪声来解决语义偏差问题，这提供了一种高效且通用性强的图像编辑方案。其在不修改模型架构的前提下，显著提升了编辑的精确控制能力和泛化性，对于文本驱动图像编辑领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于整流流模型的反演图像编辑方法存在结构性限制，即源概念的语义偏差会抑制对目标概念的注意力，导致在源和目标语义不相似时编辑失败或产生非目标区域的意外修改。

**Method:** 本文提出LORE，一种无需训练且高效的图像编辑方法。LORE直接优化了倒置噪声，解决了现有方法在泛化性和可控性方面的核心限制，无需修改架构或微调模型，即可实现稳定、可控和通用的概念替换。

**Result:** LORE在PIEBench、SmartEdit和GapEdit三个基准测试中，在语义对齐、图像质量和背景保真度方面显著优于现有基线方法。

**Conclusion:** 潜在空间优化对于通用图像编辑是有效且可扩展的。

> **ai_Abstract:** 本文提出了LORE，一种无需训练的图像编辑方法，旨在解决现有基于整流流模型的反演编辑方法中存在的语义偏差问题。该偏差导致源概念对目标概念的注意力抑制，特别是在语义差异大时，影响编辑效果。LORE通过直接优化反演噪声，实现了稳定、可控且通用的概念替换，无需模型微调。实验证明，LORE在语义对齐、图像质量和背景保真度方面均优于现有方法，验证了其在通用图像编辑中的有效性和可扩展性。

> **摘要翻译:** 文本驱动的图像编辑使用户能够通过自然语言指令灵活修改视觉内容，并广泛应用于语义对象替换、插入和删除等任务。尽管最近使用整流流模型的基于反演的编辑方法在图像质量方面取得了可喜的成果，但我们发现其编辑行为存在结构性限制：编码在反演噪声中的源概念的语义偏差往往会抑制对目标概念的注意力。当源和目标语义不相似时，这个问题变得尤为关键，此时注意力机制固有地会导致编辑失败或在非目标区域产生意外修改。在本文中，我们系统地分析并验证了这一结构性缺陷，并引入了LORE，一种无需训练且高效的图像编辑方法。LORE直接优化了反演噪声，解决了现有方法在泛化性和可控性方面的核心限制，无需架构修改或模型微调即可实现稳定、可控和通用的概念替换。我们在三个具有挑战性的基准测试：PIEBench、SmartEdit和GapEdit上进行了全面的评估。实验结果表明，LORE在语义对齐、图像质量和背景保真度方面显著优于强大的基线，证明了潜在空间优化对于通用图像编辑的有效性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [521] [Efficient Multi-Slide Visual-Language Feature Fusion for Placental Disease Classification](https://arxiv.org/abs/2508.03277)
> *高效多幻灯片视觉-语言特征融合用于胎盘疾病分类*

*Hang Guo, Qing Zhang, Zixuan Gao, Siyuan Yang, Shulin Peng, Xiang Tao, Ting Yu, Yan Wang, Qingli Li* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 胎盘疾病分类, 全玻片图像, 多模态融合, 深度学习, 病理诊断

**Comment:** Accepted by ACMMM'25

> **TL;DR:** 本研究提出EmmPD框架，通过两阶段补丁选择和混合多模态融合，有效解决全玻片图像分析中的计算挑战和全局上下文丢失问题，在胎盘疾病诊断上实现最先进性能。

**AI_Comments:** 该论文通过提出创新的两阶段补丁选择和多模态融合策略，有效地解决了全玻片图像分析中的计算效率和全局上下文丢失两大核心挑战，对于胎盘疾病的精准诊断具有重要意义。其结合视觉和文本信息的方法，提升了诊断的全面性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有全玻片图像（WSI）分类方法存在两大局限性：一是补丁选择策略不当，要么影响性能，要么未能充分降低计算需求；二是补丁级处理导致全局组织学上下文信息丢失。准确预测胎盘疾病对于预防严重的母胎并发症至关重要，但WSI分析面临巨大的计算挑战。

**Method:** 本研究提出了一种名为EmmPD的高效多模态患者级胎盘疾病诊断框架。该方法引入了一个两阶段补丁选择模块，结合了无参数和可学习的压缩策略，以优化计算效率和关键特征保留。此外，开发了一个混合多模态融合模块，利用自适应图学习增强病理特征表示，并整合文本医学报告以丰富全局上下文理解。

**Result:** 在自建的患者级胎盘数据集和两个公共数据集上进行的广泛实验表明，所提出的方法实现了最先进的诊断性能。

**Conclusion:** EmmPD框架通过其创新的两阶段补丁选择和混合多模态融合策略，有效克服了全玻片图像分析中的计算挑战和上下文丢失问题，显著提升了胎盘疾病的诊断准确性。

> **ai_Abstract:** 本论文提出了一种名为EmmPD的高效多模态框架，用于患者级胎盘疾病诊断。该框架旨在解决全玻片图像（WSI）分析中存在的计算量大、补丁选择效率低以及全局组织学上下文丢失等问题。EmmPD引入了一个结合无参数和可学习压缩的两阶段补丁选择模块，以平衡计算效率和特征保留。同时，它开发了一个混合多模态融合模块，该模块利用自适应图学习来增强病理特征表示，并整合文本医学报告以丰富全局上下文理解。实验结果表明，EmmPD在多个数据集上均取得了最先进的诊断性能。

> **摘要翻译:** 通过全玻片图像（WSI）准确预测胎盘疾病对于预防严重的母胎并发症至关重要。然而，由于数据量巨大，WSI分析带来了显著的计算挑战。现有的WSI分类方法遇到了关键限制：（1）补丁选择策略不足，要么损害性能，要么未能充分降低计算需求；（2）补丁级处理方法导致全局组织学上下文丢失。为了应对这些挑战，我们提出了一种用于患者级胎盘疾病诊断的高效多模态框架，名为EmmPD。我们的方法引入了一个两阶段补丁选择模块，结合了无参数和可学习的压缩策略，最佳地平衡了计算效率和关键特征保留。此外，我们开发了一个混合多模态融合模块，该模块利用自适应图学习来增强病理特征表示，并结合文本医学报告以丰富全局上下文理解。在自建的患者级胎盘数据集和两个公共数据集上进行的广泛实验表明，我们的方法实现了最先进的诊断性能。代码可在https://github.com/ECNU-MultiDimLab/EmmPD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [523] [Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation](https://arxiv.org/abs/2507.08343)
> *迈向不可感知JPEG图像隐藏：多范围表示驱动的对抗性隐写生成*

*Junxue Yang, Xin Liao, Weixuan Tang, Jianhua Yang, Zheng Qin* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** JPEG图像隐藏, 对抗性隐写, 多范围表示, 不可感知性, 隐写分析

**Comment:** 

> **TL;DR:** 本文提出了一种名为MRAG的多范围表示驱动对抗性隐写生成框架，用于JPEG图像隐藏，通过结合局部和全局特征以及设计新的损失函数，实现了视觉和隐写分析上的不可感知性，并达到了最先进的性能。

**AI_Comments:** 该论文通过引入多范围表示（结合局部卷积特征和全局Transformer特征）以及创新的特征角度-范数解耦损失，有效地提升了JPEG图像隐藏的不可感知性，解决了现有方案易被检测的痛点。其核心创新在于模拟隐写分析器的检测机制，并通过对抗性学习生成难以察觉的隐写图像，具有重要的实用价值和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像隐藏方案由于局限于空间域、单一范围的特征提取和攻击以及不足的损失约束，容易被肉眼或隐写分析器检测到。

**Method:** 本文提出了一种名为MRAG的多范围表示驱动对抗性隐写生成框架，用于JPEG图像隐藏。MRAG集成了卷积的局部范围特性和Transformer的全局范围建模能力。同时，设计了一种特征角度-范数解耦损失，用于发起多范围表示驱动的特征级对抗性攻击，该损失基于替代隐写分析器的分类特征（即在最后一个全连接层之前的特征）计算封面图像和隐写图像之间的对抗性损失。此外，还设计了粗粒度和细粒度频率分解操作来转换输入，引入多粒度信息。

**Result:** MRAG能够在特征角度和范数的双重约束下，将封面和秘密信息的连接编码为与隐写分析相关的局部和全局范围的细微对抗性扰动。因此，生成的隐写图像可以实现视觉和隐写分析上的不可感知性。广泛的实验表明，MRAG可以达到最先进的性能。

**Conclusion:** 本文提出的MRAG框架通过整合多范围表示和设计特定的损失函数，成功解决了现有图像隐藏方案易被检测的问题，实现了视觉和隐写分析上的不可感知性，并达到了当前领域的最佳性能。

> **ai_Abstract:** 本文提出了一种名为MRAG的JPEG图像隐藏框架，旨在解决现有方案易被检测的问题。MRAG通过结合卷积的局部特征和Transformer的全局建模能力，并设计一种新的特征角度-范数解耦损失，实现了多范围表示驱动的特征级对抗性攻击。该方法能够将秘密信息编码为细微的对抗性扰动，从而使生成的隐写图像在视觉和隐写分析上均不可感知。实验结果表明，MRAG达到了最先进的性能。

> **摘要翻译:** 图像隐藏充分挖掘了基于深度学习模型的隐藏潜力，旨在将图像级消息隐藏在封面图像中，并从隐写图像中揭示出来以实现秘密通信。现有隐藏方案由于封面类型局限于空间域、单一范围特征提取和攻击以及损失约束不足，容易被肉眼或隐写分析器检测到。为了解决这些问题，我们提出了一种名为MRAG的多范围表示驱动对抗性隐写生成框架，用于JPEG图像隐藏。该设计源于隐写分析器通常结合局部和全局范围信息以更好地捕获隐藏痕迹的事实。具体而言，MRAG整合了卷积的局部范围特性和Transformer的全局范围建模能力。同时，设计了一种特征角度-范数解耦损失，用于发起多范围表示驱动的特征级对抗性攻击。它根据替代隐写分析器的分类特征（即最后一个全连接层之前的特征）计算封面和隐写图像之间的对抗性损失。在特征角度和范数的双重约束下，MRAG可以将封面和秘密信息的连接巧妙地编码为与隐写分析相关的局部和全局范围的细微对抗性扰动。因此，生成的隐写图像可以实现视觉和隐写分析上的不可感知性。此外，还设计了粗粒度和细粒度频率分解操作来转换输入，引入多粒度信息。广泛的实验表明，MRAG可以达到最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion](https://arxiv.org/abs/2507.08344)
> *MM-Gesture: 基于多模态融合的精确微手势识别*

*Jihao Gu, Fei Wang, Kun Li, Yanyan Wei, Zhiliang Wu, Dan Guo* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 微手势识别, 多模态融合, MiGA挑战赛, PoseConv3D, Video Swin Transformer

**Comment:** 1st Place in Micro-gesture Classification sub-challenge in 3rd MiGA
  at IJCAI 2025

> **TL;DR:** MM-Gesture在第三届MiGA挑战赛微手势分类赛道中排名第一，通过多模态融合和新颖的集成策略，实现了对微手势的精确识别，并超越了现有SOTA方法。

**AI_Comments:** MM-Gesture的创新性体现在其多模态融合策略，结合了多种互补信息源以捕捉微手势的细微特征。该方法在国际挑战赛中取得第一名的成绩，充分证明了其在微手势识别领域的领先地位和实用价值。此外，采用迁移学习和模态加权集成策略也增强了其性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决微手势（MGs）识别的挑战，特别是识别细微且持续时间短的微手势。

**Method:** MM-Gesture是一个多模态融合框架，整合了关节、肢体、RGB视频、泰勒级数视频、光流视频和深度视频模态的互补信息。它利用PoseConv3D和Video Swin Transformer架构，并采用了一种新颖的模态加权集成策略。此外，通过在更大的MA-52数据集上进行迁移学习预训练，进一步增强了RGB模态的性能。

**Result:** MM-Gesture在第三届MiGA挑战赛微手势分类赛道中排名第一，性能优于先前的最先进方法。在iMiGUE基准测试中，实现了73.213%的top-1准确率。

**Conclusion:** 该论文提出的MM-Gesture方法通过多模态融合和先进的网络架构，有效提高了微手势识别的准确性，并在国际挑战赛中取得了领先地位，证明了其方法的有效性和优越性。

> **ai_Abstract:** MM-Gesture是一种多模态融合框架，专为精确识别细微的微手势而设计。该方法整合了多种视频和姿态模态数据，并结合PoseConv3D和Video Swin Transformer架构以及创新的模态加权集成策略。通过在MA-52数据集上的迁移学习，进一步提升了RGB模态的性能。MM-Gesture在第三届MiGA挑战赛中获得第一名，并在iMiGUE基准测试中取得了73.213%的top-1准确率，证明了其超越现有SOTA方法的卓越性能和有效性。

> **摘要翻译:** 在本文中，我们介绍了MM-Gesture，这是我们HFUT-VUT团队开发的解决方案，在第三届IJCAI 2025 MiGA挑战赛的微手势分类赛道中排名第一，与之前的最先进方法相比，取得了卓越的性能。MM-Gesture是一个专门为识别细微和短时微手势（MGs）而设计的多模态融合框架，它整合了来自关节、肢体、RGB视频、泰勒级数视频、光流视频和深度视频模态的互补线索。我们的方法利用PoseConv3D和Video Swin Transformer架构，并采用了一种新颖的模态加权集成策略，通过在更大的MA-52数据集上进行迁移学习预训练，进一步增强了RGB模态的性能。在iMiGUE基准测试上进行的广泛实验，包括不同模态的消融研究，验证了我们所提出方法的有效性，实现了73.213%的top-1准确率。代码可在以下网址获取：https://github.com/momiji-bit/MM-Gesture。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [530] [X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio](https://arxiv.org/abs/2508.02944)
> *X-Actor：基于音频的情感丰富、长程肖像表演*

*Chenxu Zhang, Zenan Li, Hongyi Xu, You Xie, Xiaochen Zhao, Tianpei Gu, Guoxian Song, Xin Chen, Chao Liang, Jianwen Jiang, Linjie Luo* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 音频驱动动画, 肖像表演, 扩散模型, 情感表达, 说话人视频

**Comment:** Project Page at https://byteaigc.github.io/X-Actor/

> **TL;DR:** X-Actor是一个新颖的音频驱动肖像动画框架，能从单一参考图像和音频生成逼真、情感丰富的说话人视频，超越了传统对口型方法，实现了长程、电影风格的表演。

**AI_Comments:** 该论文提出的X-Actor框架在音频驱动肖像动画领域具有显著创新。其核心贡献在于突破了传统方法对短程唇部同步的限制，转而关注长程、情感丰富的面部表演。两阶段解耦生成管道，特别是利用自回归扩散模型在解耦的潜在空间中捕捉长程关联，是其技术亮点，有效解决了误差累积问题并实现了无限长度的运动预测。这使得生成的动画更具表现力和电影感，为虚拟形象、内容创作等领域带来了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法主要侧重于受限说话场景下的唇部同步和短程视觉保真度，无法捕捉细微、动态演变的情感以及与语音节奏和内容连贯的长程表演。因此，需要一个能够生成演员级、长程肖像表演的框架。

**Method:** X-Actor采用两阶段解耦生成流程：首先，一个音频条件自回归扩散模型在长时序上下文窗口内预测富有表现力但与身份无关的面部运动潜在令牌；其次，一个基于扩散的视频合成模块将这些运动转化为高保真视频动画。通过在与视觉和身份线索解耦的紧凑面部运动潜在空间中操作，该自回归扩散模型通过扩散强制训练范式有效捕捉音频与面部动态之间的长程关联，实现无限长、情感丰富的运动预测而无误差累积。

**Result:** X-Actor生成了引人注目、电影风格的表演，超越了标准的说话人动画，并在长程、音频驱动的情感肖像表演中取得了最先进的结果。

**Conclusion:** X-Actor通过其创新的两阶段解耦生成管道和在紧凑面部运动潜在空间中的操作，成功解决了现有方法的局限性，实现了逼真、情感丰富且连贯的音频驱动长程肖像动画，达到了行业领先水平。

> **ai_Abstract:** X-Actor是一个创新的音频驱动肖像动画框架，旨在从单一图像和音频生成逼真且情感丰富的说话人视频。它解决了现有方法在长程情感表达和连贯性方面的不足，通过一个两阶段解耦生成管道实现：首先使用音频条件自回归扩散模型预测与身份无关的面部运动潜在令牌，然后通过扩散模型合成高保真视频。该方法在紧凑的潜在空间中操作，有效捕捉音频与面部动态的长程关联，从而实现无限长、无误差累积的情感丰富运动预测。实验证明，X-Actor在长程、音频驱动的情感肖像表演中达到了最先进水平，生成了电影级的表演效果。

> **摘要翻译:** 我们提出了X-Actor，一个新颖的音频驱动肖像动画框架，能够从单一参考图像和输入音频剪辑生成栩栩如生、情感丰富的说话人视频。与以往强调受限说话场景下唇部同步和短程视觉保真度的方法不同，X-Actor实现了演员级的长程肖像表演，捕捉了与语音节奏和内容连贯的细微、动态演变的情感。我们方法的核心是一个两阶段解耦生成管道：首先是一个音频条件自回归扩散模型，它在长时序上下文窗口内预测富有表现力但与身份无关的面部运动潜在令牌；其次是一个基于扩散的视频合成模块，将这些运动转化为高保真视频动画。通过在与视觉和身份线索解耦的紧凑面部运动潜在空间中操作，我们的自回归扩散模型通过扩散强制训练范式有效捕捉音频与面部动态之间的长程关联，实现了无限长、情感丰富的运动预测而无误差累积。大量实验表明，X-Actor生成了引人注目、电影风格的表演，超越了标准的说话人动画，并在长程、音频驱动的情感肖像表演中取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [537] [Semantic Mosaicing of Histo-Pathology Image Fragments using Visual Foundation Models](https://arxiv.org/abs/2508.03524)
> *使用视觉基础模型对组织病理学图像碎片进行语义拼接*

*Stefan Brandstätter, Maximilian Köller, Philipp Seeböck, Alissa Blessing, Felicitas Oberndorfer, Svitlana Pochepnia, Helmut Prosch, Georg Langs* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 组织病理学, 图像拼接, 视觉基础模型, 语义匹配, 全切片图像

**Comment:** 

> **TL;DR:** 该论文提出了一种名为SemanticStitcher的新方法，利用视觉病理学基础模型的语义特征来克服传统拼接方法在组织病理学图像中遇到的挑战，并实现了鲁棒且优于现有技术的全切片图像（WMS）拼接。

**AI_Comments:** 该论文的创新点在于将视觉基础模型引入到组织病理学图像拼接领域，通过利用语义特征而非传统的几何边界匹配，有效解决了组织样本在制备过程中可能出现的各种复杂问题，如组织缺失和形态变形。这对于大规模病理分析的自动化和标准化具有重要意义，克服了现有技术的局限性，为数字病理学的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在组织病理学中，组织样本通常大于标准显微镜载玻片，需要将多个碎片拼接起来才能处理肿瘤等完整结构。自动化拼接是扩展分析的先决条件，但由于制备过程中的组织丢失、不均匀的形态变形、染色不一致、载玻片错位导致的区域缺失或组织边缘磨损等问题，传统方法（基于边界形状匹配）面临挑战，限制了其重建人工全切片（WMS）的能力。

**Method:** 本文引入了SemanticStitcher，它利用从视觉组织病理学基础模型中提取的潜在特征表示来识别不同碎片中的相邻区域。基于大量语义匹配候选点的鲁棒姿态估计被用来将多个碎片拼接成全切片（WMS）。

**Result:** 在三个不同的组织病理学数据集上进行的实验表明，SemanticStitcher 能够实现鲁棒的全切片（WMS）拼接，并且在正确的边界匹配方面始终优于现有技术。

**Conclusion:** SemanticStitcher通过利用视觉基础模型的语义特征，有效解决了组织病理学图像碎片拼接的挑战，并在全切片图像重建方面取得了优于现有技术的性能。

> **ai_Abstract:** 本论文提出SemanticStitcher，一种新颖的组织病理学图像拼接方法。针对传统方法在处理组织丢失、变形、染色不一致等挑战时的局限性，SemanticStitcher利用视觉病理学基础模型提取的潜在语义特征来识别图像碎片间的相邻区域，并通过鲁棒的姿态估计完成全切片图像（WMS）的拼接。实验证明，该方法在多个数据集上均能实现稳定且优于现有技术的边界匹配和图像拼接效果。

> **摘要翻译:** 在组织病理学中，组织样本通常大于标准显微镜载玻片，因此需要拼接多个碎片才能处理肿瘤等完整结构。自动化拼接是扩展分析的先决条件，但由于制备过程中的组织丢失、不均匀的形态变形、染色不一致、载玻片错位导致的区域缺失或组织边缘磨损等问题，这具有挑战性。这限制了使用边界形状匹配算法的现有拼接方法重建人工全切片（WMS）的能力。在此，我们引入了SemanticStitcher，它利用从视觉组织病理学基础模型中提取的潜在特征表示来识别不同碎片中的相邻区域。基于大量语义匹配候选点的鲁棒姿态估计被用来将多个碎片拼接成全切片（WMS）。在三个不同的组织病理学数据集上进行的实验表明，SemanticStitcher 能够实现鲁棒的全切片（WMS）拼接，并且在正确的边界匹配方面始终优于现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [538] [Causally Steered Diffusion for Automated Video Counterfactual Generation](https://arxiv.org/abs/2506.14404)
> *因果引导扩散用于自动化视频反事实生成*

*Nikos Spyrou, Athanasios Vlontzos, Paraskevas Pegios, Thomas Melistas, Nefeli Gkouti, Yannis Panagakis, Giorgos Papanastasiou, Sotirios A. Tsaftaris* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视频反事实生成, 因果推断, 潜在扩散模型, 视频编辑, 视觉-语言模型

**Comment:** 

> **TL;DR:** CSVC是一个利用文本提示中嵌入的因果知识来引导扩散模型生成逼真视频反事实的框架，解决了视频编辑中因果关系难以维持的问题。

**AI_Comments:** 这篇论文提出了一种创新方法，解决了当前扩散模型在视频编辑中一个关键的局限性：保持因果一致性。通过将其表述为OOD预测问题，并利用基于提示的因果引导和基于VLM的损失，该方法提供了一个多功能、兼容黑盒的解决方案。其生成具有因果忠实性的逼真“如果”场景的能力是一个重大进步，为数字媒体和医疗保健领域的应用打开了大门。

<details>
  <summary>Details</summary>

**Motivation:** 将文本到图像（T2I）潜在扩散模型（LDMs）应用于视频编辑时，难以保持视频数据生成过程中固有的因果关系，如果忽略这些关系，编辑可能会产生不真实或误导性的结果。

**Method:** 本文引入了CSVC，一个用于反事实视频生成的因果忠实框架，将其表述为一个分布外（OOD）预测问题。该方法通过将因果图中指定的因果关系编码到文本提示中来嵌入先验因果知识，并通过使用基于视觉-语言模型（VLM）的文本损失来优化这些提示，从而引导生成过程。这种损失鼓励LDMs的潜在空间捕捉以反事实形式存在的OOD变异，有效地将生成引导到具有因果意义的替代方案。所提出的CSVC框架与底层视频编辑系统无关，不需要访问其内部机制或进行微调。

**Result:** 实验结果表明，CSVC通过基于提示的因果引导，在LDM分布内生成了因果忠实的视频反事实，在不损害时间一致性或视觉质量的情况下，在真实世界的人脸视频上实现了最先进的因果有效性。该方法使用标准视频质量指标和反事实特定标准（如因果有效性和最小性）进行了评估。

**Conclusion:** 所提出的CSVC框架能够有效生成逼真的“如果”假设视频场景，并通过保持因果忠实性，其与任何黑盒视频编辑系统的兼容性使其在数字媒体和医疗保健等多个领域具有巨大潜力。

> **ai_Abstract:** 本文介绍了CSVC，一个用于自动化视频反事实生成的创新框架，它通过因果引导扩散模型实现。为了解决潜在扩散模型（LDMs）在视频编辑中难以保持因果关系的问题，CSVC将因果图中的知识嵌入到文本提示中。它通过使用基于视觉-语言模型（VLM）的文本损失来优化这些提示，从而引导生成过程，有效地将LDMs引导至生成因果忠实的“如果”场景，这被视为一个分布外预测问题。CSVC是系统无关的，并在真实世界视频上实现了最先进的因果有效性和视觉质量，显示出在多种应用中的潜力。

> **摘要翻译:** 将文本到图像（T2I）潜在扩散模型（LDMs）应用于视频编辑已显示出强大的视觉保真度和可控性，但仍面临保持视频数据生成过程中固有因果关系的挑战。如果忽略这些关系，影响因果依赖属性的编辑通常会产生不真实或误导性的结果。在这项工作中，我们引入了一个因果忠实的视频反事实生成框架，将其表述为一个分布外（OOD）预测问题。我们通过将因果图中指定的因果关系编码到文本提示中来嵌入先验因果知识，并通过使用基于视觉-语言模型（VLM）的文本损失来优化这些提示，从而引导生成过程。这种损失鼓励LDMs的潜在空间捕捉以反事实形式存在的OOD变异，有效地将生成引导到具有因果意义的替代方案。所提出的框架名为CSVC，与底层视频编辑系统无关，不需要访问其内部机制或进行微调。我们使用标准视频质量指标和反事实特定标准（如因果有效性和最小性）评估了我们的方法。实验结果表明，CSVC通过基于提示的因果引导，在LDM分布内生成了因果忠实的视频反事实，在不损害时间一致性或视觉质量的情况下，在真实世界的人脸视频上实现了最先进的因果有效性。由于其与任何黑盒视频编辑系统的兼容性，我们的框架在数字媒体和医疗保健等不同领域生成逼真的“如果”假设视频场景方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [539] [Learning Interpretable Queries for Explainable Image Classification with Information Pursuit](https://arxiv.org/abs/2312.11548)
> *为可解释图像分类学习可解释查询与信息追踪*

*Stefan Kolek, Aditya Chattopadhyay, Kwan Ho Ryan Chan, Hector Andrade-Loarca, Gitta Kutyniok, Réne Vidal* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 信息追踪, 可解释AI, 图像分类, 查询学习, 字典学习

**Comment:** Published at ICCV 2025

> **TL;DR:** 本文提出一种直接从数据集中学习可解释查询字典的新方法，显著优于手工制作的字典，用于可解释图像分类。

**AI_Comments:** 这篇论文的创新点在于提出了直接从数据中学习可解释查询字典的方法，克服了传统手工制作字典受限于领域专家知识和提示工程启发式方法的局限性。通过将字典学习问题化为优化问题并利用大型视觉语言模型的潜在空间，为可解释AI领域提供了一条新的路径，有望提高可解释性预测算法的效率和泛化能力，对可解释图像分类具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信息追踪(IP)算法依赖于手工制作的查询字典，这些字典受限于领域专家的专业知识和提示工程的启发式方法，导致实用性受限。

**Method:** 本文提出一种直接从数据集中学习可解释查询字典的新方法。该方法将查询字典学习问题表述为一个优化问题，通过增强信息追踪（IP）的变分公式并引入可学习的字典参数。为了构建可学习和可解释的查询，该研究利用了大型视觉和语言模型（如CLIP）的潜在空间。为解决优化问题，提出了一种受经典稀疏字典学习启发的新的查询字典学习算法。

**Result:** 实验表明，学习到的字典显著优于使用大型语言模型生成的手工制作的字典。

**Conclusion:** 通过直接从数据集中学习可解释查询字典，可以显著提高可解释预测算法（如信息追踪）的性能，克服了传统手工制作字典在专业知识和提示工程方面的局限性。

> **ai_Abstract:** 本文针对信息追踪（IP）算法中手工制作查询字典的局限性，提出一种新颖的方法：直接从数据集中学习可解释查询字典。该方法将字典学习表述为一个优化问题，通过增强IP的变分公式并引入可学习参数，同时利用大型视觉和语言模型（如CLIP）的潜在空间来构建可解释查询。研究还提出了一种新的字典学习算法来解决此优化问题。实验结果表明，学习到的字典在性能上显著优于手工制作的字典。

> **摘要翻译:** 信息追踪（IP）是一种可解释的预测算法，它贪婪地按信息增益的顺序选择一系列关于数据的可解释查询，并在每一步根据观察到的查询-答案对更新其后验。标准范式使用领域专家或大型语言模型在人工提示后整理的手工制作的潜在数据查询字典。然而，在实践中，手工制作的字典受限于整理者的专业知识和提示工程的启发式方法。本文介绍了一种新颖的方法：直接从数据集中学习可解释查询字典。我们的查询字典学习问题通过增强IP的变分公式并加入可学习的字典参数，被表述为一个优化问题。为了制定可学习和可解释的查询，我们利用了CLIP等大型视觉和语言模型的潜在空间。为了解决优化问题，我们提出了一种受经典稀疏字典学习启发的新的查询字典学习算法。我们的实验表明，学习到的字典显著优于使用大型语言模型生成的手工制作的字典。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [547] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
> *传统艺术中不同LoRA模块的风格组合*

*Jaehyun Lee, Wonhark Park, Wonsik Shin, Hyunho Lee, Hyoung Min Na, Nojun Kwak* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 风格组合, 扩散模型, 零样本, 区域风格控制, LoRA

**Comment:** Accepted to ICCV 2025 Workshop(WCCA)

> **TL;DR:** 提出了一种零样本扩散管道，通过在去噪潜在空间中融合来自不同风格专业化模型的风格信息，实现了对图像区域特定风格的精确控制，解决了现有扩散模型难以控制地应用多个艺术风格的问题。

**AI_Comments:** 该论文的创新点在于提出了在去噪潜在空间进行风格组合的零样本扩散管道，并利用了潜在空间中噪声水平与风格信息强度的关系。通过结合空间掩码和ControlNet的深度图条件，实现了对图像区域特定风格的精细控制，有效解决了传统扩散模型在多风格融合中风格难以受控地应用和相互干扰的问题，对于传统艺术领域的风格迁移和创作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散的文本到图像模型在合成图像和捕捉特定艺术风格方面表现出色，但其纠缠的潜在空间和缺乏平滑插值使得难以在受控、区域化的方式下应用不同的绘画技术，常常导致一种风格占据主导地位。

**Method:** 提出了一种零样本扩散管道，通过在单独训练的、风格专业化模型的流匹配去噪过程中，对预测的去噪潜在空间进行风格组合，自然地融合多种风格。该方法利用较低噪声的潜在空间携带更强的风格信息，并使用空间掩码在异构扩散管道中融合它们，实现精确的区域特定风格控制。此外，通过ControlNet引入深度图条件，以确保不同模型间的结构一致性。

**Result:** 定性和定量实验表明，该方法根据给定的掩码成功实现了区域特定的风格混合。该机制在允许用户引导混合的同时，保留了每种独立风格的保真度。

**Conclusion:** 该研究成功地提出了一种零样本扩散管道，通过在去噪潜在空间中进行风格组合，实现了对传统艺术中图像区域特定风格的精确、受控混合，解决了现有扩散模型在多风格应用中的局限性。

> **ai_Abstract:** 该论文提出了一种零样本扩散管道，旨在解决现有扩散模型在应用多种艺术风格时难以进行区域控制的问题。该方法通过在去噪潜在空间中融合来自不同风格专业化模型的风格信息，并利用空间掩码实现区域特定风格控制。此外，结合ControlNet的深度图条件确保了结构一致性。实验证明，该方法能成功实现图像区域的精确风格混合。

> **摘要翻译:** 基于扩散的文本到图像模型在从文本提示合成多样化图像方面取得了显著成果，并且可以通过风格个性化捕捉特定的艺术风格。然而，它们纠缠的潜在空间和缺乏平滑插值使得难以在受控、区域化的方式下应用不同的绘画技术，常常导致一种风格占据主导。为了克服这个问题，我们提出了一种零样本扩散管道，通过在单独训练的、风格专业化模型的流匹配去噪过程中，对预测的去噪潜在空间进行风格组合，自然地融合多种风格。我们利用较低噪声的潜在空间携带更强的风格信息这一事实，并使用空间掩码在异构扩散管道中融合它们，从而实现精确的区域特定风格控制。这种机制在允许用户引导混合的同时，保留了每种独立风格的保真度。此外，为了确保不同模型间的结构一致性，我们将通过ControlNet进行的深度图条件引入到扩散框架中。定性和定量实验表明，我们的方法根据给定的掩码成功实现了区域特定的风格混合。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [549] [SAVER: Mitigating Hallucinations in Large Vision-Language Models via Style-Aware Visual Early Revision](https://arxiv.org/abs/2508.03177)
> *SAVER：通过风格感知视觉早期修正缓解大型视觉-语言模型中的幻觉*

*Zhaoxu Li, Chenqi Kong, Yi Yu, Qiangqiang Wu, Xinghao Jiang, Ngai-Man Cheung, Bihan Wen, Alex Kot, Xudong Jiang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 大型视觉-语言模型, 幻觉缓解, 风格化图像, 视觉注意力, SAVER

**Comment:** 

> **TL;DR:** 本文提出了SAVER，一种新的机制，通过利用早期层反馈，根据token级别的视觉注意力模式动态调整LVLM的最终输出，以缓解风格化图像引起的幻觉，并在各种模型、数据集和任务上实现了最先进的幻觉缓解性能。

**AI_Comments:** 该论文的创新点在于首次系统地关注了大型视觉-语言模型在处理风格化图像时产生的幻觉问题，并构建了专门的数据集进行研究。SAVER机制通过利用早期层反馈和视觉注意力模式进行动态调整，提供了一种新颖有效的幻觉缓解策略，对LVLM的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在理解复杂的视觉-文本上下文方面取得了显著突破，但幻觉问题仍然限制了它们的实际应用。现有方法主要关注摄影图像，而忽略了风格化图像带来的潜在风险，这在游戏场景理解、艺术教育和医疗分析等关键场景中至关重要。

**Method:** 首先构建了一个包含摄影图像及其对应风格化版本的带标注数据集。然后，通过在收集的数据集上对13个先进的LVLM进行基准测试，在判别和生成任务上进行了直接比较。最后，提出了风格感知视觉早期修正（SAVER）机制，该机制基于token级别的视觉注意力模式，利用早期层反馈动态调整LVLM的最终输出，以缓解风格化图像引起的幻觉。

**Result:** 研究发现，风格化图像比摄影图像更容易引起幻觉。SAVER在各种模型、数据集和任务中，在幻觉缓解方面取得了最先进的性能。

**Conclusion:** SAVER有效缓解了大型视觉-语言模型在处理风格化图像时产生的幻觉问题，并通过早期层反馈和视觉注意力模式调整实现了卓越的性能。

> **ai_Abstract:** 本文关注大型视觉-语言模型（LVLMs）在处理风格化图像时产生的幻觉问题。研究人员首先构建了一个包含摄影图像和风格化图像的新数据集，并对13个LVLM进行了基准测试，发现风格化图像更容易导致幻觉。为了解决这一问题，论文提出了SAVER（Style-Aware Visual Early Revision）机制，该机制通过利用早期层反馈和token级别的视觉注意力模式，动态调整LVLM的输出以减轻幻觉。实验证明SAVER在多种模型、数据集和任务上均达到了最先进的幻觉缓解效果。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）最近在理解复杂的视觉-文本上下文方面取得了重大突破。然而，幻觉问题仍然限制了它们的实际应用。尽管以前的缓解方法有效地减少了摄影图像中的幻觉，但它们在很大程度上忽视了风格化图像带来的潜在风险，而风格化图像在游戏场景理解、艺术教育和医疗分析等关键场景中发挥着至关重要的作用。在这项工作中，我们首先构建了一个包含摄影图像及其相应风格化版本并带有仔细标注标题的数据集。然后，我们通过在收集的数据集上对13个先进的LVLM进行基准测试，在判别和生成任务上进行了直接比较。我们的研究结果表明，风格化图像比其摄影对应物更容易引起显著更多的幻觉。为了解决这个问题，我们提出了风格感知视觉早期修正（SAVER），这是一种新颖的机制，它根据token级别的视觉注意力模式动态调整LVLM的最终输出，利用早期层反馈来缓解风格化图像引起的幻觉。大量的实验表明，SAVER在各种模型、数据集和任务中，在幻觉缓解方面取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [550] [Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation](https://arxiv.org/abs/2508.03300)
> *零样本域适应语义分割通过合成数据生成和渐进式适应*

*Jun Luo, Zijing Zhao, Yang Liu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 零样本域适应, 语义分割, 合成数据生成, 文本到图像扩散模型, 渐进式适应

**Comment:** Accepted to IROS 2025

> **TL;DR:** SDGPA是一种新颖的方法，通过利用文本到图像扩散模型生成合成数据并采用渐进式适应策略来解决零样本域适应语义分割问题，实现了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于将文本到图像扩散模型应用于零样本域适应语义分割任务，通过文本描述生成目标域风格的合成数据。同时，提出的分块编辑和合并策略有效解决了合成数据中布局不精确的问题，而增强中间域和渐进式适应策略则进一步提高了模型适应的稳定性和鲁棒性，这些都是对现有域适应方法的有益补充和改进。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习语义分割模型在处理训练和测试数据之间的分布偏移时存在局限性，特别是在零样本域适应场景中，目标域图像不可用，只有文本描述。

**Method:** 本文提出了SDGPA（合成数据生成和渐进式适应）方法，用于零样本域适应语义分割。它利用预训练的文本到图像扩散模型，通过将源域图像转换为目标风格来生成训练图像。为了解决合成数据中不准确的布局问题，该方法提出裁剪源图像，单独编辑小补丁，然后将它们合并回去。此外，SDGPA构建了一个增强的中间域，并设计了一种渐进式适应策略，以实现更稳定的模型适应和减轻合成数据噪声的影响。

**Result:** 我们的方法在零样本语义分割方面实现了最先进的性能。

**Conclusion:** 本文提出的SDGPA方法通过创新的合成数据生成和渐进式适应策略，有效解决了零样本域适应语义分割的挑战，并取得了最先进的成果。

> **ai_Abstract:** 本文提出了SDGPA，一种用于零样本域适应语义分割的新方法。面对目标域数据缺失的问题，SDGPA利用文本到图像扩散模型生成具有目标风格的合成训练数据。为解决合成数据中布局不精确的问题，该方法采用分块编辑并合并的策略。同时，为应对大的域差距和合成数据噪声，SDGPA引入了增强中间域和渐进式适应策略。实验证明，该方法在零样本语义分割任务上取得了最先进的性能。

> **摘要翻译:** 基于深度学习的语义分割模型取得了令人印象深刻的成果，但在处理训练和测试数据之间的分布偏移时仍然存在局限性。在本文中，我们提出了SDGPA（合成数据生成和渐进式适应），一种解决零样本域适应语义分割的新颖方法，其中没有目标图像可用，只提供了目标域风格的文本描述。为了弥补目标域训练数据的不足，我们利用一个预训练的现成文本到图像扩散模型，通过将源域图像转换为目标风格来生成训练图像。直接编辑源域图像会引入噪声，因为源图像的布局无法精确保持，从而损害分割效果。为了解决合成数据中不准确的布局问题，我们提出了一种方法，该方法裁剪源图像，单独编辑小块，然后将它们合并回去，这有助于提高空间精度。认识到巨大的域差距，SDGPA构建了一个增强的中间域，利用更容易的适应子任务，使模型能够更稳定地适应目标域。此外，为了减轻合成数据中噪声的影响，我们设计了一种渐进式适应策略，确保在整个训练过程中进行鲁棒学习。广泛的实验表明，我们的方法在零样本语义分割中实现了最先进的性能。代码可在https://github.com/ROUJINN/SDGPA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [562] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
> *AD-GS：面向自动驾驶的自监督物体感知B样条高斯泼溅*

*Jiawei Xu, Kai Deng, Zexin Fan, Shenlong Wang, Jin Xie, Jian Yang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 自监督学习, 高斯泼溅, 自动驾驶, 动态场景渲染, B样条

**Comment:** Accepted by ICCV 2025

> **TL;DR:** AD-GS是一个自监督框架，利用B样条高斯泼溅技术，实现高质量的动态城市场景渲染，无需手动标注。

**AI_Comments:** AD-GS的创新之处在于其无需手动标注即可实现高质量动态场景渲染，这对于自动驾驶模拟领域具有重要意义。其结合B样条曲线和三角函数的运动模型，以及自动场景分割和可见性推理，有效提升了自监督方法的性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 当前高质量的动态城市场景建模和渲染方法通常依赖于昂贵的手动对象轨迹标注，而现有的自监督方法在准确捕捉动态对象运动和正确分解场景方面表现不佳，导致渲染伪影。

**Method:** AD-GS引入了一种新颖的自监督框架，用于从单个日志中高质量自由视点渲染驾驶场景。其核心是一个可学习的运动模型，该模型将局部感知B样条曲线与全局感知三角函数相结合，实现灵活而精确的动态对象建模。AD-GS通过简化的伪2D分割自动将场景分割为对象和背景，使用动态高斯和双向时间可见性掩码表示对象。此外，该模型还结合了可见性推理和物理刚性正则化以增强鲁棒性。

**Result:** 广泛的评估表明，AD-GS这一无需标注的模型显著优于当前最先进的无标注方法，并且与依赖标注的方法具有竞争力。

**Conclusion:** AD-GS成功地提供了一种无需手动标注的自监督方法，用于高质量地建模和渲染动态城市驾驶场景，解决了现有方法的局限性并达到了与标注依赖方法相媲美的性能。

> **ai_Abstract:** AD-GS是一种新颖的自监督框架，旨在解决自动驾驶场景中动态城市环境的高质量渲染问题，尤其是在缺乏手动标注的情况下。它通过结合局部感知B样条曲线和全局感知三角函数的可学习运动模型，以及自动对象分割和动态高斯表示，实现了对动态对象的精确建模。该方法无需传统昂贵的标注，并在性能上超越了现有无标注方法，同时与依赖标注的方法具有竞争力。

> **摘要翻译:** 建模和渲染动态城市驾驶场景对于自动驾驶模拟至关重要。当前高质量的方法通常依赖于昂贵的手动对象轨迹标注，而自监督方法未能准确捕捉动态对象运动并正确分解场景，导致渲染伪影。我们引入了AD-GS，一个新颖的自监督框架，用于从单个日志中高质量自由视点渲染驾驶场景。其核心是一个新颖的可学习运动模型，该模型将局部感知B样条曲线与全局感知三角函数相结合，实现灵活而精确的动态对象建模。AD-GS无需全面的语义标注，通过简化的伪2D分割自动将场景分割为对象和背景，使用动态高斯和双向时间可见性掩码表示对象。此外，我们的模型结合了可见性推理和物理刚性正则化以增强鲁棒性。广泛的评估表明，我们的无需标注模型显著优于当前最先进的无标注方法，并且与依赖标注的方法具有竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [Towards Robust Image Denoising with Scale Equivariance](https://arxiv.org/abs/2508.02967)
> *迈向具有尺度等变性的鲁棒图像去噪*

*Dawei Zhang, Xiaojie Guo* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像去噪, 尺度等变性, 分布外鲁棒性, 空间变异噪声, 盲去噪

**Comment:** 

> **TL;DR:** 本文提出了一种具有尺度等变性的鲁棒盲去噪框架（包含HNM和IGM），旨在提高模型对空间变异噪声的鲁棒性，并在性能上超越了现有SOTA方法。

**AI_Comments:** 本文引入了尺度等变性作为图像去噪的一个新颖归纳偏差，创新性地解决了模型在处理分布外空间变异噪声时的泛化难题。所提出的HNM和IGM模块设计巧妙，有效利用了这一偏差，显著提升了去噪性能。这项工作对于开发更鲁棒、更实用的去噪解决方案具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管图像去噪取得了进展，但现有模型难以泛化到分布外（OOD）的空间变异噪声，这导致了泛化差距，是一个基本但未被充分探索的挑战。

**Method:** 本文研究了尺度等变性作为改善OOD鲁棒性的核心归纳偏差。基于此，提出了一个鲁棒的盲去噪框架，包含两个关键组件：异构归一化模块（HNM）用于稳定特征分布并在不同噪声强度下动态校正特征；交互门控模块（IGM）通过信号和特征路径之间的门控交互促进有效的信息调制。

**Result:** 模型在合成和真实世界基准测试中始终优于最先进的方法，尤其是在空间异构噪声条件下表现突出。

**Conclusion:** 通过引入尺度等变性并设计HNM和IGM模块，本文显著提高了图像去噪模型对空间变异噪声的鲁棒性和泛化能力。

> **ai_Abstract:** 本文旨在解决图像去噪模型在处理分布外空间变异噪声时的泛化难题。研究将尺度等变性作为核心归纳偏差以提升OOD鲁棒性，并提出了一种新颖的鲁棒盲去噪框架。该框架包含异构归一化模块（HNM），用于稳定特征分布和动态校正噪声强度下的特征；以及交互门控模块（IGM），通过门控交互实现信号与特征路径间的信息有效调制。实验结果表明，该模型在合成和真实世界的基准测试中，尤其在空间异构噪声下，性能显著优于现有最先进方法。

> **摘要翻译:** 尽管图像去噪取得了显著进展，但现有模型在泛化超出分布内噪声模式方面常常面临困难，尤其是在面对以空间变异噪声为特征的分布外（OOD）条件时。这种泛化差距仍然是一个基本但未被充分探索的挑战。在这项工作中，我们研究了尺度等变性作为改善OOD鲁棒性的核心归纳偏差。我们认为，结合尺度等变结构使模型能够更好地从对空间均匀噪声的训练适应到对空间非均匀退化的推理。基于这一见解，我们提出了一个鲁棒的盲去噪框架，该框架配备了两个关键组件：异构归一化模块（HNM）和交互门控模块（IGM）。HNM在不同噪声强度下稳定特征分布并动态校正特征，而IGM通过信号和特征路径之间的门控交互促进有效的信息调制。广泛的评估表明，我们的模型在合成和真实世界基准测试中始终优于最先进的方法，特别是在空间异构噪声下。代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [569] [CoEmoGen: Towards Semantically-Coherent and Scalable Emotional Image Content Generation](https://arxiv.org/abs/2508.03535)
> *CoEmoGen：迈向语义连贯且可扩展的情绪图像内容生成*

*Kaishen Yuan, Yuting Zhang, Shang Gao, Yijie Zhu, Wenshuo Chen, Yutao Yue* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 情绪图像生成, 语义连贯性, 可扩展性, 多模态大语言模型, 分层低秩适应

**Comment:** 10 pages, 9 figures

> **TL;DR:** CoEmoGen通过多模态大语言模型和分层低秩适应模块，生成语义连贯且可扩展的情绪图像，并引入了一个大型情绪艺术数据集。

**AI_Comments:** CoEmoGen的创新之处在于结合了MLLMs进行高级语义指导和HiLoRA模块进行分层情绪特征建模，有效解决了现有EICG方法在抽象情绪处理和可扩展性方面的不足。其提出的EmoArt数据集也为该领域提供了宝贵的资源，对情绪驱动的艺术创作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像扩散模型难以处理抽象情绪，而专门的情绪图像内容生成（EICG）方法过度依赖词级属性标签，导致语义不连贯、模糊且可扩展性有限。

**Method:** 本文提出了CoEmoGen，一个新型的流水线，它利用多模态大语言模型（MLLMs）构建高质量的、专注于情绪触发内容的字幕，以提供上下文丰富的语义指导。此外，受心理学见解的启发，CoEmoGen设计了一个分层低秩适应（HiLoRA）模块，以协同建模极性共享的低级特征和情绪特定的高级语义。为展示可扩展性，还策划了大规模情绪艺术图像数据集EmoArt。

**Result:** 广泛的实验从定量、定性和用户研究的角度证明了CoEmoGen在情感忠实度和语义连贯性方面的优越性。此外，通过策划大规模情绪艺术图像数据集EmoArt，直观地展示了其可扩展性。

**Conclusion:** CoEmoGen有效解决了情绪图像内容生成中语义不连贯和可扩展性受限的问题，通过结合MLLMs和HiLoRA模块实现了语义连贯和高可扩展的情绪图像生成，并为情绪驱动的艺术创作提供了新的资源。

> **ai_Abstract:** 本文提出了CoEmoGen，一个解决情绪图像内容生成（EICG）中语义不连贯和可扩展性挑战的新框架。CoEmoGen利用多模态大语言模型生成高质量情绪触发字幕进行语义指导，并引入分层低秩适应（HiLoRA）模块以有效建模情绪特征。实验证明CoEmoGen在情感忠实度和语义连贯性方面表现优越。此外，研究团队还发布了大规模情绪艺术数据集EmoArt，以展示其可扩展性并促进情绪驱动的艺术创作。

> **摘要翻译:** 情绪图像内容生成（EICG）旨在根据给定的情感类别生成语义清晰且情感忠实的图像，具有广阔的应用前景。虽然最近的文本到图像扩散模型在生成具体概念方面表现出色，但它们在处理抽象情绪的复杂性方面遇到了困难。也有专门为EICG设计的方法出现，但它们过度依赖词级属性标签进行指导，导致语义不连贯、模糊和可扩展性有限。为了解决这些挑战，我们提出了CoEmoGen，一个以语义连贯性和高可扩展性著称的新型流水线。具体来说，我们利用多模态大语言模型（MLLMs）构建高质量的、专注于情绪触发内容的字幕，以提供上下文丰富的语义指导。此外，受心理学见解的启发，我们设计了一个分层低秩适应（HiLoRA）模块，以协同建模极性共享的低级特征和情绪特定的高级语义。广泛的实验从定量、定性和用户研究的角度证明了CoEmoGen在情感忠实度和语义连贯性方面的优越性。为了直观地展示可扩展性，我们策划了EmoArt，一个大规模的情绪唤起艺术图像数据集，为情绪驱动的艺术创作提供了无限的灵感。数据集和代码可在https://github.com/yuankaishen2001/CoEmoGen 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [571] [Uncertainty-aware Medical Diagnostic Phrase Identification and Grounding](https://arxiv.org/abs/2404.06798)
> *不确定性感知医学诊断短语识别与定位*

*Ke Zou, Yang Bai, Zhihao Chen, Yang Zhou, Yidi Chen, Kai Ren, Meng Wang, Xuedong Yuan, Xiaojing Shen, Xiaochun Cao, Yih Chung Tham, Huazhu Fu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学报告定位, 不确定性感知, 多模态大型语言模型, 诊断短语识别, 图像定位

**Comment:** 17 pages, 6 figures

> **TL;DR:** 本文提出uMedGround框架，首次端到端地从医学报告中识别诊断短语并定位对应区域，解决了现有方法效率低、缺乏置信度估计的问题，并通过引入不确定性感知预测模型提高了鲁棒性和可靠性。

**AI_Comments:** 本文的创新点在于首次提出了医学报告定位（MRG）这一新任务，并设计了端到端解决方案uMedGround。其重要性体现在解决了当前医学影像诊断中手动提取短语效率低以及模型缺乏置信度的问题，通过引入不确定性感知预测模型，显著提高了临床应用的可靠性。此外，其多模态LLM的运用以及在视觉问答等下游任务中的拓展性也增强了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医学短语定位方法依赖手动从医学报告中提取关键短语，降低了效率并增加了临床医生工作量。此外，模型缺乏置信度估计限制了临床信任和可用性。

**Method:** 本文引入了医学报告定位（MRG）新任务，旨在直接从医学报告中端到端地识别诊断短语及其对应的定位框。为此，提出了uMedGround框架，该框架利用多模态大型语言模型，通过在词汇表中嵌入一个独特的<BOX>标记来预测诊断短语，以增强检测能力。一个视觉编码器-解码器处理嵌入的标记和输入图像以生成定位框。关键是，uMedGround整合了一个不确定性感知预测模型，显著提高了定位预测的鲁棒性和可靠性。

**Result:** 实验结果表明，uMedGround优于最先进的医学短语定位方法和微调过的大型视觉-语言模型，验证了其有效性和可靠性。此外，本文还展示了uMedGround在医学视觉问答和基于类的定位任务中的适用性。

**Conclusion:** 本文首次探索了医学报告定位（MRG）任务，并提出了uMedGround框架，通过不确定性感知预测提高了医学诊断短语识别和定位的鲁棒性和可靠性，为临床医生提供了更有力的支持。

> **ai_Abstract:** 本文提出了一项名为医学报告定位（MRG）的新任务，旨在解决当前医学短语定位方法效率低下和缺乏模型置信度的问题。为此，论文引入了uMedGround框架，该框架是一个基于多模态大型语言模型的端到端系统，能够直接从医学报告中识别诊断短语并生成对应的图像定位框。uMedGround通过嵌入特殊标记和整合不确定性感知预测模型，显著提升了定位的鲁棒性和可靠性。实验证明，uMedGround在性能上超越了现有先进方法，并在医学视觉问答和基于类的定位任务中展现了良好的应用潜力，为临床诊断提供了更可靠的支持。

> **摘要翻译:** 医学短语定位对于根据短语查询识别医学图像中的相关区域至关重要，有助于准确的图像分析和诊断。然而，当前的方法依赖于从医学报告中手动提取关键短语，降低了效率并增加了临床医生工作量。此外，模型缺乏置信度估计限制了临床信任和可用性。在本文中，我们引入了一项名为医学报告定位（MRG）的新任务，旨在以端到端的方式直接从医学报告中识别诊断短语及其对应的定位框。为了应对这一挑战，我们提出了uMedGround，一个鲁棒且可靠的框架，它利用多模态大型语言模型，通过在词汇表中嵌入一个独特的<BOX>标记来预测诊断短语，以增强检测能力。一个视觉编码器-解码器处理嵌入的标记和输入图像以生成定位框。关键是，uMedGround整合了一个不确定性感知预测模型，显著提高了定位预测的鲁棒性和可靠性。实验结果表明，uMedGround优于最先进的医学短语定位方法和微调过的大型视觉-语言模型，验证了其有效性和可靠性。这项研究代表了MRG任务的开创性探索，标志着该领域的首次尝试。此外，我们还展示了uMedGround在医学视觉问答和基于类的定位任务中的适用性，它突出了与关键诊断短语对齐的视觉证据，支持临床医生解释各种类型的文本输入，包括自由文本报告、视觉问答查询和类别标签。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [572] [Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark](https://arxiv.org/abs/2507.15882)
> *文档干草堆：一个长上下文多模态图像/文档理解视觉LLM基准*

*Goeric Huybrechts, Srikanth Ronanki, Sai Muralidhar Jayanthi, Jack Fitzgerald, Srinivasan Veeravanallur* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 长上下文, 多模态, 基准, 视觉语言模型, 文档理解

**Comment:** 

> **TL;DR:** 引入了Document Haystack，一个用于评估视觉语言模型在长、视觉复杂文档上性能的基准，以解决缺乏此类基准的问题。

**AI_Comments:** 这项工作具有重要意义，因为它解决了多模态LLM在处理长文档时面临的关键挑战——缺乏合适的评估工具。Document Haystack的创新之处在于其大规模、多样化的文档范围（5-200页）以及引入“针”式检索任务，这能有效测试VLM在复杂长上下文中的信息检索能力。其自动化评估框架也大大提高了评估效率和客观性。该基准的发布有望推动长文档理解领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型在分析和理解复杂数据输入方面取得了显著进展，但对长文档的处理仍未得到充分探索，这主要是由于缺乏合适的基准。

**Method:** 我们引入了Document Haystack，这是一个全面的基准，旨在评估视觉语言模型（VLMs）在长、视觉复杂文档上的性能。该基准包含5到200页的文档，并策略性地在文档的不同深度插入纯文本或多模态文本+图像的“针”，以挑战VLMs的检索能力。它包括400个文档变体和总共8,250个问题，并由一个客观、自动化的评估框架支持。

**Result:** 我们详细介绍了Document Haystack数据集的构建和特性，并展示了知名VLM在该基准上的结果。

**Conclusion:** 该研究通过引入Document Haystack基准，解决了长文档处理中缺乏评估工具的问题，并讨论了该领域潜在的研究方向，为未来VLM在长文档理解方面的研究提供了基础和方向。

> **ai_Abstract:** 本文介绍了Document Haystack，一个旨在评估视觉语言模型（VLMs）在长、视觉复杂文档上理解和检索能力的综合基准。该基准通过在长达200页的文档中嵌入文本或图文“针”来测试VLMs的检索能力，包含400种文档变体和8,250个问题，并配备自动化评估框架。研究旨在弥补当前缺乏长文档处理基准的空白，并为未来VLMs在该领域的研究提供支持。

> **摘要翻译:** 多模态大型语言模型的普及显著提升了分析和理解不同模态复杂数据输入的能力。然而，对长文档的处理仍未得到充分探索，这主要是由于缺乏合适的基准。为了解决这个问题，我们引入了Document Haystack，这是一个全面的基准，旨在评估视觉语言模型（VLMs）在长、视觉复杂文档上的性能。Document Haystack的文档长度从5页到200页不等，并策略性地在文档的不同深度插入纯文本或多模态文本+图像的“针”，以挑战VLMs的检索能力。它包括400个文档变体和总共8,250个问题，并由一个客观、自动化的评估框架支持。我们详细介绍了Document Haystack数据集的构建和特性，展示了知名VLM的结果，并讨论了该领域潜在的研究方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [573] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
> *PositionIC：图像定制中统一的位置与身份一致性*

*Junjie Hu, Tianyang Han, Kai Ma, Jialin Gao, Hao Dou, Song Yang, Xianhua He, Jianhui Zhang, Junfeng Luo, Xiaoming Wei, Wenqiang Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像定制, 位置一致性, 身份一致性, 多主体, 空间控制

**Comment:** 

> **TL;DR:** PositionIC是一个统一框架，通过引入可扩展的合成管道和轻量级位置调制操作，解决了图像定制中多主体精细空间控制的挑战，实现了高一致性和精确的空间控制。

**AI_Comments:** 本文提出的PositionIC框架通过其创新的双向生成合成管道和轻量级位置调制操作，有效地解决了图像定制领域中多主体精细空间控制的挑战。其核心贡献在于统一了位置和身份的一致性，这对于实现更广泛的实际应用至关重要。该方法通过解耦空间嵌入，允许独立的主体放置，同时保持高保真度，极大地提升了定制图像的实用性。未来该框架的发布将有助于推动相关领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有主体驱动的图像定制方法在保真度方面取得了显著进展，但精细的实例级空间控制仍然难以实现，阻碍了更广泛的实际应用。这主要是因为缺乏将身份与精确位置线索结合的可扩展数据集。

**Method:** 本文提出了PositionIC，一个统一的框架，用于强制执行多主体定制中的位置和身份一致性。该方法构建了一个可扩展的合成管道，采用双向生成范式来消除主体漂移并保持语义连贯性。在此基础上，设计了一种轻量级的位置调制操作，该操作解耦了主体间的空间嵌入，从而实现了独立、精确的放置，同时保留了视觉保真度。

**Result:** 广泛的实验表明，PositionIC方法可以在图像定制任务中实现精确的空间控制，同时保持高一致性。

**Conclusion:** PositionIC为开放世界、多实体场景中的可控、高保真图像定制铺平了道路。

> **ai_Abstract:** PositionIC是一个解决图像定制中精细实例级空间控制难题的统一框架。针对现有方法缺乏将身份与精确位置线索结合的可扩展数据集的问题，PositionIC通过构建一个可扩展的双向生成合成管道来消除主体漂移并保持语义连贯性。此外，它设计了一种轻量级的位置调制操作，以解耦主体空间嵌入，实现独立、精确的放置并保持视觉保真度。实验证明，PositionIC在图像定制任务中实现了精确的空间控制和高一致性，为多实体场景下的可控、高保真图像定制提供了新途径。

> **摘要翻译:** 最近主体驱动的图像定制在保真度方面取得了显著进展，但精细的实例级空间控制仍然难以实现，阻碍了更广泛的实际应用。这一限制主要归因于缺乏将身份与精确位置线索绑定在一起的可扩展数据集。为此，我们引入了PositionIC，一个统一的框架，用于强制执行多主体定制中的位置和身份一致性。我们构建了一个可扩展的合成管道，采用双向生成范式来消除主体漂移并保持语义连贯性。在此数据之上，我们设计了一种轻量级的位置调制操作，该操作解耦了主体间的空间嵌入，从而实现了独立、精确的放置，同时保留了视觉保真度。广泛的实验表明，我们的方法可以在图像定制任务中实现精确的空间控制，同时保持高一致性。PositionIC为开放世界、多实体场景中的可控、高保真图像定制铺平了道路，并将发布以促进进一步研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [577] [Architectural Insights into Knowledge Distillation for Object Detection: A Comprehensive Review](https://arxiv.org/abs/2508.03317)
> *目标检测知识蒸馏的架构洞察：一项全面综述*

*Mahdi Golizadeh, Nassibeh Golizadeh, Mohammad Ali Keyvanrad, Hossein Shirazi* | **Category: cs.CV, 68T07, I.4.8** | **Updated: 2025-08-05**

**Keywords:** 知识蒸馏, 目标检测, 架构分类, CNN, Transformer

**Comment:** 20 pages, 11 figures, This paper was submitted to IEEE Transactions
  on Neural Networks and Learning Systems

> **TL;DR:** 这篇综述提出了一个以架构为中心的知识蒸馏（KD）分类法，用于目标检测，涵盖了基于CNN和Transformer的检测器，并评估了代表性方法，旨在澄清该领域并指导未来的研究。

**AI_Comments:** 该论文的创新之处在于提出了一个新颖的、以架构为中心的知识蒸馏分类法，这对于理解和组织目标检测领域复杂的KD方法具有重要意义。它不仅回顾了现有技术，还指出了未来的研究方向和挑战，对该领域的发展具有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在目标检测中取得了显著的准确性，但计算成本高昂，限制了在资源受限设备上的部署。知识蒸馏（KD）提供了一种解决方案，但将其应用于目标检测面临独特挑战，如分类和定位的双重目标、前景-背景不平衡以及多尺度特征表示。

**Method:** 本综述引入了一种新颖的、以架构为中心的知识蒸馏方法分类法，区分了基于CNN的检测器（涵盖骨干网络、颈部、头部和RPN/RoI级别的蒸馏）和基于Transformer的检测器（包括查询级别、特征级别和logit级别的蒸馏）。此外，还使用MS COCO和PASCAL VOC数据集，以mAP@0.5作为性能指标，评估了代表性方法，并进行了比较分析。

**Result:** 该综述对代表性方法进行了比较分析，评估了它们在MS COCO和PASCAL VOC数据集上使用mAP@0.5作为性能指标的有效性。

**Conclusion:** 所提出的分类法和分析旨在阐明目标检测中知识蒸馏不断发展的格局，突出当前挑战，并指导未来研究，以实现高效和可扩展的检测系统。

> **ai_Abstract:** 本综述全面回顾了目标检测领域的知识蒸馏（KD），旨在解决深度学习模型计算成本高的问题。文章提出了一种新颖的、以架构为中心的KD分类法，涵盖了基于CNN和Transformer的检测器中的不同蒸馏级别。通过对代表性方法在MS COCO和PASCAL VOC数据集上的评估和比较分析，本综述旨在澄清KD在目标检测中的应用现状，识别现有挑战，并为未来高效和可扩展检测系统的研究提供指导。

> **摘要翻译:** 目标检测通过深度学习取得了显著的准确性，但这些改进通常伴随着计算成本的增加，限制了在资源受限设备上的部署。知识蒸馏（KD）通过使紧凑的学生模型能够从大型教师模型中学习，提供了一种有效的解决方案。然而，将KD应用于目标检测带来了独特的挑战，这归因于其双重目标——分类和定位——以及前景-背景不平衡和多尺度特征表示。本综述引入了一种新颖的、以架构为中心的KD方法分类法，区分了基于CNN的检测器（涵盖骨干网络级别、颈部级别、头部级别和RPN/RoI级别蒸馏）和基于Transformer的检测器（包括查询级别、特征级别和logit级别蒸馏）。我们进一步使用MS COCO和PASCAL VOC数据集，以mAP@0.5作为性能指标，评估了代表性方法，提供了它们的有效性比较分析。所提出的分类法和分析旨在阐明目标检测中KD不断发展的格局，突出当前挑战，并指导未来研究，以实现高效和可扩展的检测系统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [582] [Duplex-GS: Proxy-Guided Weighted Blending for Real-Time Order-Independent Gaussian Splatting](https://arxiv.org/abs/2508.03180)
> *Duplex-GS：代理引导加权混合实现实时无关顺序高斯泼溅*

*Weihang Liu, Yuke Li, Yuxuan Li, Jingyi Yu, Xin Lou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 高斯泼溅, 无关顺序渲染, 实时渲染, 代理表示, 加权混合

**Comment:** 

> **TL;DR:** Duplex-GS是一个双层级框架，结合代理高斯表示和无关顺序渲染技术，在保持实时性能的同时实现逼真的渲染效果，并显著提升了速度和效率。

**AI_Comments:** Duplex-GS的创新之处在于其双层级框架设计，特别是引入了代理高斯表示和单元代理，有效解决了3DGS中视图自适应基数排序的计算瓶颈。通过与OIT的结合，实现了物理启发式的加权求和渲染，不仅提升了效率，还解决了常见的渲染伪影问题，对实时高斯泼溅渲染领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的3D高斯泼溅(3DGS)方法依赖于计算成本高的顺序alpha混合操作，导致显著的开销，尤其是在资源受限的平台上。

**Method:** Duplex-GS提出了一个双层级框架，集成了代理高斯表示和无关顺序渲染技术。为减轻视图自适应基数排序的开销，引入了用于局部高斯管理的单元代理，并提出了单元搜索光栅化以进一步加速。通过与无关顺序透明度(OIT)无缝结合，开发了一种物理启发式加权求和渲染技术，同时消除了“弹出”和“透明度”伪影。

**Result:** 在各种真实世界数据集上的广泛实验表明，该方法在多尺度训练视图和大规模环境等多种场景中具有鲁棒性。与现有基于OIT的高斯泼溅方法相比，实现了1.5到4倍的速度提升，并将基数排序开销降低了52.2%到86.9%，且没有质量下降。

**Conclusion:** 该研究验证了OIT渲染范式在高斯泼溅中的优势，实现了高质量渲染，并显著提升了效率。

> **ai_Abstract:** Duplex-GS是一个创新的双层级框架，旨在解决现有3D高斯泼溅方法中顺序alpha混合带来的高计算开销问题。它通过引入代理高斯表示、单元代理和单元搜索光栅化来优化局部高斯管理和加速渲染过程。该框架与无关顺序透明度(OIT)技术相结合，开发了一种物理启发式加权求和渲染技术，有效消除了渲染伪影。实验结果表明，Duplex-GS在保持高质量渲染的同时，显著提升了渲染速度和效率，尤其是在减少基数排序开销方面表现突出。

> **摘要翻译:** 最近3D高斯泼溅(3DGS)的进展展示了卓越的渲染保真度和效率。然而，这些方法仍然依赖于计算成本高的顺序alpha混合操作，导致显著的开销，尤其是在资源受限的平台上。在本文中，我们提出了Duplex-GS，一个双层级框架，它将代理高斯表示与无关顺序渲染技术相结合，以在保持实时性能的同时实现逼真的结果。为了减轻视图自适应基数排序造成的开销，我们引入了用于局部高斯管理的单元代理，并提出了单元搜索光栅化以进一步加速。通过将我们的框架与无关顺序透明度(OIT)无缝结合，我们开发了一种物理启发式加权求和渲染技术，同时消除了“弹出”和“透明度”伪影，从而在准确性和效率方面都取得了实质性改进。在各种真实世界数据集上的广泛实验证明了我们方法在包括多尺度训练视图和大规模环境在内的各种场景中的鲁棒性。我们的结果验证了OIT渲染范式在高斯泼溅中的优势，实现了高质量渲染，与现有基于OIT的高斯泼溅方法相比，速度提升了1.5到4倍，并将基数排序开销降低了52.2%到86.9%，且没有质量下降。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [587] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
> *Franca：用于可扩展视觉表示学习的嵌套玩偶聚类*

*Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉基础模型, 嵌套玩偶聚类, SSL聚类, 位置解耦, 开源模型

**Comment:** 

> **TL;DR:** Franca是一个开源的视觉基础模型，性能可与最先进的专有模型相媲美，它通过嵌套玩偶表示的多头聚类投影仪解决了SSL聚类方法的局限性，并采用位置解耦策略来提高语义内容编码，从而在各项下游基准测试中取得了持续的改进。

**AI_Comments:** 该研究提出了Franca，一个开源的视觉基础模型，在性能上可与专有模型媲美。其创新之处在于嵌套玩偶聚类方法，解决了现有SSL聚类方法的模糊性问题，实现了性能与内存效率的平衡。同时，位置解耦策略的引入也提升了模型的语义理解能力。该模型为构建更透明、可复现和通用的基础模型提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现代SSL聚类方法在处理聚类语义的固有模糊性方面存在不足，并且在不增加模型尺寸的情况下实现性能和内存效率是一个挑战。

**Method:** Franca采用了一种基于嵌套玩偶表示的参数高效、多头聚类投影仪，该投影仪能够逐步将特征细化为越来越精细的聚类，同时不增加模型大小。此外，还提出了一种新颖的位置解耦策略，以消除密集表示中的位置偏差。

**Result:** Franca在各项下游基准测试中实现了持续的改进，证明了更清洁的特征空间的效用。

**Conclusion:** Franca树立了透明、高性能视觉模型的新标准，并为AI社区更具可复现性和通用性的基础模型开辟了道路。

> **ai_Abstract:** Franca是一个开源的视觉基础模型，它通过一种新颖的嵌套玩偶聚类方法解决了现有SSL聚类方法的局限性，该方法能够实现性能和内存效率的提升。此外，还通过位置解耦策略改善了语义内容的编码，并在下游任务中取得了优于现有模型的性能。

> **摘要翻译:** 我们提出了Franca（发音为Fran-ka：自由一个）：第一个完全开源（数据、代码、权重）的视觉基础模型，其性能在许多情况下都与最先进的专有模型相匹配甚至超越，例如DINOv2、CLIP、SigLIPv2等。我们的方法基于受Web-SSL启发的透明训练流程，并使用公开可用的数据：ImageNet-21K和ReLAION-2B的一个子集。除了模型发布，我们还解决了SSL聚类方法中的关键局限性。虽然现代模型依赖于通过Sinkhorn-Knopp等聚类算法将图像特征分配给大型码本，但它们未能考虑到聚类语义中固有的模糊性。为了解决这个问题，我们引入了一种基于嵌套玩偶表示的参数高效、多头聚类投影仪。该设计能够逐步将特征细化为越来越精细的聚类，而不会增加模型大小，从而实现性能和内存效率。此外，我们提出了一种新颖的位置解耦策略，该策略明确地从密集表示中消除了位置偏差，从而提高了语义内容的编码。这在几项下游基准测试中带来了持续的收益，证明了更清洁的特征空间的效用。我们的贡献为透明、高性能的视觉模型树立了新的标准，并为更具可复现性和通用性的基础模型为更广泛的AI社区开辟了道路。代码和模型检查点可在https://github.com/valeoai/Franca获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [591] [SCFlow: Implicitly Learning Style and Content Disentanglement with Flow Models](https://arxiv.org/abs/2508.03402)
> *SCFlow：使用流模型隐式学习风格与内容解耦*

*Pingchuan Ma, Xiaopei Yang, Yusong Li, Ming Gui, Felix Krause, Johannes Schusterbauer, Björn Ommer* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 风格解耦, 内容解耦, 流模型, 流匹配, 隐式学习

**Comment:** ICCV 2025, Project Page: https://compvis.github.io/SCFlow/

> **TL;DR:** 提出SCFlow，一个流匹配框架，通过可逆地合并风格和内容来隐式实现风格与内容的解耦，无需显式监督。

**AI_Comments:** SCFlow提出了一种新颖的、非显式解耦风格和内容的方法，通过可逆合并来绕过传统方法的挑战。其利用流匹配的灵活性和大规模合成数据集的构建是重要的创新点，为图像生成和表示学习领域提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 视觉模型中显式解耦风格和内容因语义重叠和人类感知的主观性而具有挑战性，现有方法也面临概念交织的固有模糊性。

**Method:** 提出SCFlow，一个流匹配框架，学习纠缠和解耦表示之间的双向映射。其基于三个关键洞察：1) 仅训练合并风格和内容，以实现可逆解耦而无需显式监督；2) 流匹配可在任意分布上进行，避免了扩散模型和归一化流的限制性高斯先验；3) 构建了一个包含51万个样本的合成数据集来模拟解耦。

**Result:** SCFlow在可控生成任务之外，还能在零样本设置下泛化到ImageNet-1k和WikiArt数据集，并取得了有竞争力的性能。

**Conclusion:** 解耦自然地从可逆的合并过程中出现。

> **ai_Abstract:** 本文提出SCFlow，一个基于流匹配的框架，旨在通过学习风格和内容的可逆合并来隐式实现解耦，从而避免了显式解耦的挑战。SCFlow通过训练合并而非分离来学习纠缠和解耦表示间的双向映射，利用流匹配处理任意分布，并构建了大规模合成数据集进行训练。实验证明，SCFlow不仅适用于可控生成，还能在零样本设置下泛化到真实数据集并取得良好性能，表明解耦可从可逆合并中自然涌现。

> **摘要翻译:** 在视觉模型中显式地解耦风格和内容仍然具有挑战性，因为它们存在语义重叠以及人类感知的主观性。现有方法通过生成或判别目标来提议分离，但它们仍然面临解耦交织概念的固有模糊性。相反，我们提出一个问题：我们能否通过学习可逆地合并风格和内容，从而让分离自然地出现，以此绕过显式解耦？我们提出了SCFlow，一个流匹配框架，它学习纠缠和解耦表示之间的双向映射。我们的方法建立在三个关键洞察之上：1）仅训练合并风格和内容（一个定义明确的任务）可以实现可逆解耦，而无需显式监督；2）流匹配可以在任意分布上进行桥接，避免了扩散模型和归一化流的限制性高斯先验；3）我们策划了一个包含51万个样本（51种风格 × 10,000个内容样本）的合成数据集，通过系统性的风格-内容配对来模拟解耦。除了可控生成任务，我们证明SCFlow在零样本设置下泛化到ImageNet-1k和WikiArt，并取得了有竞争力的性能，这突出表明解耦自然地从可逆的合并过程中出现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [596] [Diffusion Models with Adaptive Negative Sampling Without External Resources](https://arxiv.org/abs/2508.02973)
> *具有自适应负采样且无需外部资源的扩散模型*

*Alakh Desai, Nuno Vasconcelos* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 负采样, 无分类器引导, 提示依从性, 图像生成

**Comment:** 

> **TL;DR:** 本文提出了一种名为ANSWER的训练无关技术，它通过利用扩散模型对否定的内部理解，在不使用显式负提示的情况下，显著提高了图像生成对提示的依从性。

**AI_Comments:** 这篇论文的创新点在于提出了ANSWER，一种无需外部资源和额外训练即可提升扩散模型生成质量和提示依从性的方法。它巧妙地利用了模型对“否定”的内在理解，避免了传统负提示的局限性（耗损和不完整）。其普适性（适用于任何支持CFG的模型）和显著的实验效果（人类偏好度提高2倍）表明了其潜在的广泛应用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像生成方面表现出色，但在提示依从性和质量上仍有显著差异。现有的负提示方法虽能改善依从性，但显式负提示是耗损且不完整的。研究旨在开发一种无需外部资源且能同时处理正负条件的新采样方法。

**Method:** 本文探索了负提示与无分类器引导（CFG）之间的关系，提出了一种名为“自适应负采样无需外部资源”（ANSWER）的采样过程。ANSWER利用扩散模型对否定的内部理解，从单个提示中同时考虑正负条件，从而提高生成图像与提示的一致性。该技术无需训练，适用于任何支持CFG的模型，并且无需显式负提示即可实现图像概念的负向接地。

**Result:** 实验表明，将ANSWER应用于现有扩散模型，在多个基准测试中均优于基线方法，并且人类用户对ANSWER生成图像的偏好度是其他方法的两倍。

**Conclusion:** ANSWER是一种有效的、训练无关的采样技术，它通过利用扩散模型内部对否定的理解，在不依赖外部资源或显式负提示的情况下，显著提升了扩散模型生成图像的提示依从性和质量。

> **ai_Abstract:** 本文提出了一种名为ANSWER（自适应负采样无需外部资源）的新型采样技术，旨在提高扩散模型生成图像的提示依从性和质量。ANSWER通过探索负提示与无分类器引导（CFG）的关系，利用扩散模型对否定的内部理解，从单个提示中同时处理正负条件，从而避免了传统显式负提示的局限性。该方法无需训练，可应用于任何支持CFG的模型，并在实验中展现出优于现有基线模型的性能，并获得人类用户更高的偏好。

> **摘要翻译:** 扩散模型（DMs）在根据文本提示创建多样化和高保真图像方面展现出无与伦比的能力。然而，众所周知，它们在提示依从性和质量方面存在显著差异。引入负提示是为了通过指定图像不得包含的内容来提高提示依从性。以往的工作表明存在一个理想的负提示，可以最大限度地提高正提示的成功率。在这项工作中，我们探索了负提示与无分类器引导（CFG）之间的关系，以开发一种名为“自适应负采样无需外部资源”（ANSWER）的采样程序，该程序能够从单个提示中同时考虑正负条件。这利用了扩散模型对否定的内部理解，以增加生成忠实于提示的图像的几率。ANSWER是一种无需训练的技术，适用于任何支持CFG的模型，并且无需显式负提示即可实现图像概念的负向接地，而显式负提示是耗损且不完整的。实验表明，将ANSWER添加到现有扩散模型中，在多个基准测试中均优于基线方法，并且人类对其的偏好度是其他方法的两倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [600] [Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation](https://arxiv.org/abs/2506.17213)
> *长期交通模拟：交错自回归运动与场景生成*

*Xiuyu Yang, Shuhan Tan, Philipp Krähenbühl* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 交通模拟, 长期模拟, 自回归运动, 场景生成, 自动驾驶

**Comment:** ICCV 2025. Project page: https://orangesodahub.github.io/InfGen Code:
  https://github.com/OrangeSodahub/infgen

> **TL;DR:** InfGen是一个统一的下一令牌预测模型，通过交错的闭环运动模拟和场景生成，实现了长期的稳定交通模拟，并在短期和长期模拟中均表现出色。

**AI_Comments:** InfGen的创新之处在于其统一的下一令牌预测模型，能够交错进行运动模拟和场景生成，解决了长期交通模拟中代理进出场景的挑战，这对于自动驾驶系统的实际部署具有重要意义。其在长期模拟中的显著性能提升表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的交通模拟模型和基准主要关注场景中初始代理的闭环运动模拟，这对于需要代理进出场景的长期（点对点）交通模拟来说存在问题。

**Method:** 本文提出了InfGen，一个统一的下一令牌预测模型，它能自动在闭环运动模拟和场景生成模式之间切换，从而实现交错的闭环运动模拟和场景生成。

**Result:** InfGen在短期（9秒）交通模拟中达到了最先进水平，并在长期（30秒）模拟中显著优于所有其他方法。

**Conclusion:** InfGen通过其独特的交错运动模拟和场景生成机制，成功解决了长期交通模拟中的挑战，并提供了卓越的性能和稳定性。

> **ai_Abstract:** 本文提出了InfGen，一个统一的下一令牌预测模型，旨在解决现有交通模拟器在长期模拟中因代理进出场景而面临的问题。InfGen通过交错的闭环运动模拟和场景生成，实现了稳定的长期推演。实验结果表明，InfGen在短期交通模拟中达到最先进水平，并在长期模拟中显著超越其他方法。

> **摘要翻译:** 一个理想的交通模拟器能够复制自动驾驶系统在部署过程中所经历的真实长期点对点行程。先前的模型和基准专注于场景中初始代理的闭环运动模拟。这对于长期模拟来说是有问题的。随着自动驾驶车辆进入新区域，代理会进出场景。我们提出了 InfGen，一个统一的下一令牌预测模型，它执行交错的闭环运动模拟和场景生成。InfGen 自动在闭环运动模拟和场景生成模式之间切换。它实现了稳定的长期推演模拟。InfGen 在短期（9秒）交通模拟中表现达到最先进水平，并在长期（30秒）模拟中显著优于所有其他方法。InfGen 的代码和模型将在 https://orangesodahub.github.io/InfGen 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [601] [Negation-Aware Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2507.19064)
> *视觉-语言模型中感知否定的测试时间适应*

*Haochen Han, Alex Jinpeng Wang, Fangming Liu, Jun Zhu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉-语言模型, 否定理解, 测试时间适应, 分布偏移, 低碳

**Comment:** This paper will be submitted to the IEEE for possible publication

> **TL;DR:** 本文提出了一种名为NEAT的测试时间适应方法，用于解决视觉-语言模型在理解否定方面的不足，该方法通过高效调整分布相关参数，以低碳方式实现了与现有先进方法相当或更优的性能。

**AI_Comments:** 本文提出了一种新颖且高效的方法来解决视觉-语言模型中一个重要但被忽视的问题——否定理解。其创新之处在于识别出否定理解的瓶颈在于肯定和否定分布之间的双概念偏移，并提出了一种测试时间适应（NEAT）策略，而非依赖于大规模数据增强或模型微调。这种“低碳”方法在参数效率方面表现出色（不到0.01%的可训练参数），同时实现了与现有先进方法相当或更优的性能，这对于资源受限的实际部署具有重要意义。该研究为未来VLMs的鲁棒性和泛化性提供了一个新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）在处理否定理解方面存在严重局限性，尽管它们具有出色的可迁移性。在许多实际应用中，模型需要明确识别错误或不存在的信息（例如，放射科医生搜索排除特定条件的图像），但VLMs无法有效处理否定。现有方法通过大量否定数据微调模型来解决，但这需要大量的计算资源和数据，限制了其可持续的广泛应用。

**Method:** 作者观察到，处理否定的关键障碍在于肯定和否定分布之间的双概念偏移。因此，提出了一种“感知否定测试时间适应”（Negation-Aware Test-Time Adaptation, NEAT）方法。该方法在推理过程中高效调整与分布相关的参数，旨在减少一致语义中的分布偏移，同时消除不相关语义中的错误分布一致性。这是一种“低碳”的解决方案。

**Result:** 在各种否定理解任务上的广泛实验验证了所提出方法的有效性。值得注意的是，NEAT仅用不到0.01%的可训练参数，就取得了与最先进的后训练方法相当或更优的性能。

**Conclusion:** NEAT通过解决肯定和否定分布之间的双概念偏移，为视觉-语言模型提供了高效且低碳的否定理解能力，并在资源受限的情况下取得了显著的性能提升。

> **ai_Abstract:** 本文解决了视觉-语言模型（VLMs）在否定理解方面的不足，这是一个在实际应用中非常重要但被忽视的问题。现有方法依赖于大量数据微调，但作者发现核心问题在于肯定和否定分布之间的概念偏移。为此，论文提出了一种名为“感知否定测试时间适应”（NEAT）的新方法。NEAT在推理时高效调整分布相关参数，以减少语义一致性中的分布偏移，并消除不相关语义中的虚假一致性。实验表明，NEAT在各种否定理解任务上表现出色，仅用极少量可训练参数（<0.01%）即可达到或超越现有最先进的后训练方法，提供了一种“低碳”且高效的解决方案。

> **摘要翻译:** 在本文中，我们研究了视觉-语言模型（VLMs）中一个实际但较少触及的问题，即否定理解。具体来说，许多现实世界的应用要求模型明确识别什么是错误的或不存在的，例如，放射科医生可能需要搜索排除特定条件的图像。尽管VLMs通过大规模训练展现出令人印象深刻的可迁移性，但它们在处理否定方面存在一个关键的局限性。为了应对这一挑战，现有方法将其根源归因于否定训练数据的稀缺性，并提出在包含明确否定的大规模数据上微调VLMs。毫无疑问，这种以数据为中心的解决方案需要大量的计算资源和数据，限制了它们的可持续广泛采用。为了以低碳方式处理否定，我们凭经验观察到，关键障碍在于肯定和否定分布之间的双概念偏移。因此，我们提出了一种感知否定的测试时间适应（NEAT）方法，以在推理过程中高效调整与分布相关的参数。简而言之，NEAT可以减少一致语义中的分布偏移，同时消除不相关语义中的错误分布一致性。在各种否定理解任务上的广泛实验验证了所提出方法的有效性。值得注意的是，NEAT仅用不到0.01%的可训练参数，就取得了与最先进的后训练方法相当或更优的性能。我们的代码可在https://github.com/hhc1997/NEAT获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [605] [Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation](https://arxiv.org/abs/2508.03320)
> *Skywork UniPic：面向视觉理解与生成的统一自回归建模*

*Peiyu Wang, Yi Peng, Yimeng Gan, Liang Hu, Tianyidan Xie, Xiaokun Wang, Yichen Wei, Chuanxin Tang, Bo Zhu, Changshi Li, Hongyang Wei, Eric Li, Xuchen Song, Yang Liu, Yahui Zhou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 统一模型, 自回归, 视觉理解, 图像生成, 图像编辑

**Comment:** 

> **TL;DR:** Skywork UniPic是一个1.5亿参数的统一自回归模型，能够在单一架构中实现图像理解、文本到图像生成和图像编辑，并在商品硬件上达到了SOTA性能，证明了紧凑型多模态系统的可行性。

**AI_Comments:** Skywork UniPic的创新之处在于其统一的自回归架构，能够处理多种视觉任务而无需复杂的适配器，这简化了多模态系统的设计和部署。其在商品硬件上实现SOTA性能的能力，特别是低内存占用，使其具有很高的实用价值和部署潜力。结合其精心策划的大规模数据集和奖励模型，该研究为高效、高保真多模态AI的发展提供了一个重要的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态系统通常需要任务特定的适配器或模块间连接器，增加了复杂性和资源需求。本文旨在开发一个统一的自回归模型，以消除这些需求，并在商品硬件上实现高性能，从而建立一个实用的、可部署的高保真多模态AI范式。

**Method:** Skywork UniPic是一个1.5亿参数的自回归模型，其方法包括：(1) 解耦编码策略，利用掩码自回归编码器进行合成，SigLIP2编码器进行理解，并将两者都输入共享的自回归解码器；(2) 渐进式、分辨率感知的训练计划，从256x256扩展到1024x1024，同时动态解冻参数以平衡容量和稳定性；(3) 精心策划的亿级规模数据集，并辅以任务特定的奖励模型来优化生成和编辑目标。

**Result:** Skywork UniPic在GenEval得分0.86，超过了大多数现有统一模型；在DPG-Bench复杂生成任务上创下85.5的新纪录；在GEditBench-EN上图像编辑得分5.83，在ImgEdit-Bench上得分3.49；生成1024x1024图像时GPU内存使用低于15 GB（如RTX 4090）。

**Conclusion:** Skywork UniPic通过证明高保真多模态集成无需承担过高的资源需求，为可部署的高保真多模态AI建立了一个实用的范式。

> **ai_Abstract:** Skywork UniPic是一个1.5亿参数的统一自回归模型，旨在通过单一架构整合图像理解、文本到图像生成和图像编辑，从而消除对任务特定适配器的需求。该模型采用解耦编码策略、渐进式分辨率感知训练计划和亿级规模的精选数据集，并在商品硬件上实现了最先进的性能，包括在GenEval、DPG-Bench和图像编辑基准测试中取得高分，同时显著降低了GPU内存消耗，为可部署的高保真多模态AI提供了实用范式。

> **摘要翻译:** 我们推出了Skywork UniPic，一个1.5亿参数的自回归模型，它在单一架构中统一了图像理解、文本到图像生成和图像编辑——无需任务特定的适配器或模块间连接器——并证明了紧凑型多模态系统可以在商品硬件上实现最先进的性能。Skywork UniPic在GenEval得分0.86，超越了大多数现有统一模型；在DPG-Bench复杂生成任务上创下85.5的新纪录；在GEditBench-EN上图像编辑得分5.83，在ImgEdit-Bench上得分3.49；生成1024 x 1024图像时GPU内存使用低于15 GB（例如，RTX 4090）。(1) 采用解耦编码策略，利用掩码自回归编码器进行合成，SigLIP2编码器进行理解，所有这些都馈入共享的自回归解码器；(2) 渐进式、分辨率感知的训练计划，从256 x 256扩展到1024 x 1024，同时动态解冻参数以平衡容量和稳定性；(3) 精心策划的亿级规模数据集，辅以任务特定的奖励模型以优化生成和编辑目标。通过证明高保真多模态集成无需承担过高的资源需求，Skywork UniPic为可部署、高保真多模态AI建立了一个实用的范式。代码和权重已在https://huggingface.co/Skywork/Skywork-UniPic-1.5B公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [606] [Quality-Aware Language-Conditioned Local Auto-Regressive Anomaly Synthesis and Detection](https://arxiv.org/abs/2508.03539)
> *质量感知语言条件局部自回归异常合成与检测*

*Long Qian, Bingke Zhu, Yingying Chen, Ming Tang, Jinqiao Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 异常合成, 语言条件, 自回归, 异常检测, 质量感知

**Comment:** 

> **TL;DR:** 该论文提出ARAS，一种语言条件自回归异常合成方法，通过token锚定潜在编辑精确注入局部文本指定缺陷。结合QARAD框架和动态加权策略，ARAS在三个基准数据集上超越SOTA方法，在异常检测任务中实现更高的准确性、鲁棒性，并提供5倍的合成速度提升。

**AI_Comments:** 该论文的创新点在于提出了语言条件自回归异常合成方法ARAS，通过精确的局部缺陷注入和语义控制，解决了现有扩散模型在异常合成中存在的结构缺陷和效率问题。结合质量感知的QARAD框架，通过动态加权策略进一步优化了异常检测性能。其显著的性能提升和合成速度优势，对工业缺陷检测和医疗图像分析等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型和粗糙修复管道在异常合成方面存在结构缺陷，如微结构不连续、语义可控性有限和生成效率低下。

**Method:** 提出ARAS（语言条件自回归异常合成方法），通过token锚定潜在编辑将局部文本指定缺陷精确注入图像。利用硬门控自回归操作符和无训练、上下文保留的掩码采样核。进一步在QARAD（质量感知重加权异常检测）框架中引入动态加权策略，通过双编码器模型计算图像-文本相似性得分来强调高质量合成样本。

**Result:** 在MVTec AD、VisA和BTAD三个基准数据集上，QARAD在图像级和像素级异常检测任务中均优于SOTA方法，实现了更高的准确性、鲁棒性，并且合成速度比基于扩散的方法快5倍。

**Conclusion:** ARAS结合QARAD框架显著提升了异常合成的质量和效率，并在异常检测任务中取得了领先的性能，解决了现有方法的局限性。

> **ai_Abstract:** 该论文提出了ARAS，一种语言条件自回归异常合成方法，旨在克服现有扩散模型和修复方法在结构缺陷、语义控制和生成效率方面的限制。ARAS通过token锚定潜在编辑将文本指定的局部缺陷精确注入图像，并结合硬门控自回归操作和上下文保留采样核，显著提升缺陷真实感和纹理保留。此外，论文还引入了QARAD框架，利用动态加权策略基于图像-文本相似性强调高质量合成样本。实验结果表明，QARAD在多个基准数据集上优于现有SOTA方法，在异常检测准确性、鲁棒性方面表现更佳，且合成速度提升5倍。

> **摘要翻译:** 尽管异常合成方法取得了实质性进展，但现有的基于扩散和粗糙修复管道普遍存在结构缺陷，例如微观结构不连续性、有限的语义可控性和低效的生成。为了克服这些限制，我们引入了ARAS，这是一种语言条件的自回归异常合成方法，通过标记锚定的潜在编辑将局部、文本指定的缺陷精确地注入正常图像中。利用硬门控自回归操作符和无训练、上下文保留的掩码采样核，ARAS显著增强了缺陷的真实感，保留了细粒度材料纹理，并提供了对合成异常的连续语义控制。集成到我们的质量感知重加权异常检测（QARAD）框架中，我们进一步提出了一种动态加权策略，通过使用双编码器模型计算图像-文本相似性得分来强调高质量的合成样本。在MVTec AD、VisA和BTAD三个基准数据集上进行的大量实验表明，我们的QARAD在图像级和像素级异常检测任务中均优于SOTA方法，实现了更高的准确性、鲁棒性，并且与基于扩散的替代方案相比，合成速度提高了5倍。我们的完整代码和合成数据集将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [607] [Generalized Compressed Sensing for Image Reconstruction with Diffusion Probabilistic Models](https://arxiv.org/abs/2405.17456)
> *扩散概率模型用于图像重建的广义压缩感知*

*Ling-Qi Zhang, Zahra Kadkhodaie, Eero P. Simoncelli, David H. Brainard* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-04**

**Keywords:** 压缩感知, 图像重建, 扩散模型, 线性测量, 信号处理

**Comment:** Transactions on Machine Learning Research (2025)

> **TL;DR:** 本文提出一种利用扩散模型优化的线性测量方法，用于高效图像重建，显著优于传统方法。

**AI_Comments:** 本文的创新之处在于将扩散概率模型引入到广义压缩感知框架中，利用其强大的生成能力来学习和捕捉自然图像的复杂统计结构，从而优化线性测量。这为高维信号（特别是图像）的稀疏采样和高效重建提供了一个新颖且有效的方法，突破了传统方法对简单统计模型的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像重建的线性测量方法（如PCA、ICA和CS）依赖于轴对齐或子空间对齐的统计特征，未能充分利用自然信号（如摄影图像）中更丰富的统计结构。

**Method:** 引入一种通用方法，通过利用在去噪（扩散模型）中训练的神经网络中隐含的先验知识来表达信号统计，从而获得一组优化的线性测量值，用于高效图像重建。

**Result:** 1. 为两个自然图像数据集导出的最优测量值不同于PCA、ICA或CS，并导致显著更低的均方重建误差。2. 测量值的边际分布是不对称的（偏斜），比以前的方法更显著。3. 针对感知损失（SSIM）进行优化会导致与针对MSE优化时不同的测量值。

**Conclusion:** 结果强调了在设计有效的线性测量时，结合自然信号的特定统计规律的重要性。

> **ai_Abstract:** 本文提出一种利用扩散概率模型捕获图像丰富统计结构的新型广义压缩感知方法，用于优化线性测量以实现高效图像重建。该方法通过在扩散模型中隐含的先验来表达信号统计，实验证明其在均方误差上显著优于传统PCA、ICA和随机投影CS方法，并揭示了优化测量值的独特统计特性，强调了利用信号特定统计规律的重要性。

> **摘要翻译:** 我们研究了为重建高维信号选择少量线性测量的问题。优化此类测量的成熟方法包括主成分分析（PCA）、独立成分分析（ICA）和基于随机投影的压缩感知（CS），所有这些都依赖于信号源的轴对齐或子空间对齐的统计特征。然而，许多自然发生的信号，包括摄影图像，包含更丰富的统计结构。为了利用这种结构，我们引入了一种获取优化线性测量集的通用方法，用于高效图像重建，其中信号统计通过训练用于去噪的神经网络（称为“扩散模型”）中隐含的先验来表达。我们证明了为两个自然图像数据集导出的最优测量值不同于PCA、ICA或CS，并导致显著更低的均方重建误差。有趣的是，测量值的边际分布是不对称的（偏斜），比以前的方法更显著。我们还发现，针对感知损失（通过结构相似性（SSIM）量化）进行优化会导致与针对MSE优化时不同的测量值。我们的结果强调了在设计有效的线性测量时，结合自然信号的特定统计规律的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [615] [Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback](https://arxiv.org/abs/2507.20766)
> *仅通过图像学习：结合推理、渲染和视觉反馈的视觉强化学习*

*Yang Chen, Yufan Shen, Wenxuan Huang, Sheng Zhou, Qunshu Lin, Xinyu Cai, Zhi Yu, Jiajun Bu, Botian Shi, Yu Qiao* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉强化学习, 多模态大型语言模型, 视觉推理, 图像到代码生成, 视觉反馈

**Comment:** 

> **TL;DR:** 提出RRVF框架，使多模态大型语言模型（MLLMs）仅通过原始图像进行视觉强化学习，解决对图像-文本监督的依赖，并在图像到代码生成任务上取得优异表现。

**AI_Comments:** RRVF框架的创新之处在于利用“验证不对称性”原则，将视觉反馈作为强化学习的奖励信号，从而有效解决了多模态大型语言模型对大量人工标注图像-文本监督的依赖。这为MLLMs实现更自主、更深入的视觉推理提供了一条有前景的路径，尤其是在数据稀缺或标注成本高昂的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在深度视觉推理方面存在关键瓶颈，即它们严重依赖人工标注的图像-文本监督。

**Method:** 本文引入了一种名为“推理-渲染-视觉反馈”（Reasoning-Rendering-Visual-Feedback, RRVF）的新型框架，使MLLMs仅通过原始图像学习复杂的视觉推理。该框架基于“验证不对称性”原则，即验证渲染输出比执行深度视觉推理以生成忠实的、结构化表示（如代码）更容易。这种相对容易性被用作强化学习（RL）的理想奖励信号，从而减少对图像-文本监督的依赖。RRVF实现了一个闭环迭代过程，包含推理、渲染和视觉反馈组件，并通过GRPO算法进行端到端优化，支持通过多轮交互进行自我修正。

**Result:** 在数据图表和网络界面两个不同领域的图像到代码生成任务上，RRVF训练的模型不仅优于现有同等大小的开源MLLMs和监督微调基线，而且表现出卓越的泛化能力。值得注意的是，该模型甚至超越了训练期间用于生成视觉反馈的更先进的MLLM。

**Conclusion:** RRVF框架通过仅使用图像进行视觉强化学习，有效解决了MLLMs对图像-文本监督的依赖，并在复杂视觉推理和图像到代码生成任务上显著提升了性能和泛化能力。

> **ai_Abstract:** 本文针对多模态大型语言模型（MLLMs）在深度视觉推理中对图像-文本监督的过度依赖问题，提出了一种名为“推理-渲染-视觉反馈”（RRVF）的新型视觉强化学习框架。RRVF利用“验证不对称性”原则，将渲染输出与源图像的比较作为强化学习的奖励信号，从而使MLLMs能够仅通过原始图像进行学习。该框架通过闭环迭代过程实现推理、渲染和视觉反馈的整合，并通过GRPO算法进行端到端优化。实验证明，RRVF在图像到代码生成任务上显著优于现有基线模型，并展现出更强的泛化能力。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在各种视觉任务中表现出色。随后对其视觉推理能力的增强研究显著扩展了它们的性能范围。然而，MLLMs在向深度视觉推理发展中的一个关键瓶颈是它们严重依赖人工标注的图像-文本监督。为了解决这个问题，我们引入了一种新颖的框架，“推理-渲染-视觉反馈”（RRVF），该框架使MLLMs能够仅从原始图像中学习复杂的视觉推理。该框架建立在“验证不对称性”原则之上，即验证渲染输出与源图像的一致性比执行深度视觉推理以生成忠实的、结构化表示（如代码）要容易得多。我们证明了这种相对容易性为通过强化学习（RL）进行优化提供了理想的奖励信号，从而减少了对图像-文本监督的依赖。RRVF实现了包含推理、渲染和视觉反馈组件的闭环迭代过程，使模型能够执行复杂的推理，包括通过多轮交互进行自我修正。这个过程使用GRPO算法进行端到端优化。在数据图表和网络界面两个不同领域的图像到代码生成任务上进行了广泛评估。RRVF训练的模型不仅优于现有同等大小的开源MLLMs和监督微调基线，而且表现出卓越的泛化能力。值得注意的是，该模型超越了训练期间用于生成视觉反馈的更先进的MLLM。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [624] [Monocular Depth Estimation with Global-Aware Discretization and Local Context Modeling](https://arxiv.org/abs/2508.03186)
> *结合全局感知离散化和局部上下文建模的单目深度估计*

*Heng Wu, Qian Zhang, Guixu Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 单目深度估计, 全局感知, 局部上下文, GLKAM, GBPM

**Comment:** 

> **TL;DR:** 本文提出了一种新的单目深度估计算法，通过结合局部和全局线索来提高精度，引入了GLKAM捕获局部信息和GBPM估计全局深度分布。在NYU-V2和KITTI数据集上表现出竞争力和优越性。

**AI_Comments:** 本文的创新点在于通过GLKAM和GBPM两个模块巧妙地结合了局部和全局信息，有效解决了单目深度估计中的固有模糊性问题。这种结合局部细节和全局结构指导的方法对于提高深度估计精度非常重要。其在主流数据集上的优越表现也证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 准确的单目深度估计是一个具有挑战性的问题，因为它从单一视角恢复三维结构本质上是一个病态问题，存在固有的模糊性，即多种深度配置可以产生相同的二维投影。

**Method:** 本文提出了一种结合局部和全局线索的新型深度估计方法。具体来说，引入了门控大核注意力模块（GLKAM）以利用大核卷积和门控机制捕获多尺度局部结构信息。为了增强网络的全局感知能力，引入了全局深度区间预测模块（GBPM），用于估计深度区间的全局分布并为深度回归提供结构指导。

**Result:** 在NYU-V2和KITTI数据集上的大量实验表明，该方法取得了有竞争力的性能，并优于现有方法。

**Conclusion:** 实验验证了所提出的每个组件（GLKAM和GBPM）的有效性。

> **ai_Abstract:** 本文针对单目深度估计的固有模糊性挑战，提出了一种结合局部和全局线索的新方法。该方法引入了门控大核注意力模块（GLKAM）以捕获多尺度局部结构信息，并设计了全局深度区间预测模块（GBPM）来估计深度区间的全局分布并提供结构指导。在NYU-V2和KITTI数据集上的广泛实验证明，该方法性能具有竞争力并优于现有方法，验证了其所提组件的有效性。

> **摘要翻译:** 准确的单目深度估计仍然是一个具有挑战性的问题，原因在于从单一视角恢复三维结构本质上是一个病态问题，存在固有的模糊性，即多种合理的深度配置可以产生相同的二维投影。在本文中，我们提出了一种新颖的深度估计方法，该方法结合了局部和全局线索以提高预测精度。具体来说，我们提出了门控大核注意力模块（GLKAM），通过利用大核卷积和门控机制，有效捕获多尺度局部结构信息。为了进一步增强网络的全局感知能力，我们引入了全局深度区间预测模块（GBPM），该模块估计深度区间的全局分布，并为深度回归提供结构指导。在NYU-V2和KITTI数据集上进行的大量实验表明，我们的方法取得了有竞争力的性能，并优于现有方法，验证了每个所提组件的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [625] [Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling](https://arxiv.org/abs/2508.03404)
> *视觉文档理解与问答：一种具有测试时缩放功能的多智能体协作框架*

*Xinlei Yu, Zhangquan Chen, Yudong Zhang, Shilin Lu, Ruolin Shen, Jiangning Zhang, Xiaobin Hu, Yanwei Fu, Shuicheng Yan* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视觉文档理解, 视觉问答, 多智能体系统, 测试时缩放, 自校正

**Comment:** 

> **TL;DR:** 提出MACT多智能体协作框架，通过小规模智能体和测试时缩放，显著提升视觉文档理解和问答性能，尤其在长视觉上下文和复杂推理任务上表现优异。

**AI_Comments:** MACT通过其模块化的多智能体设计和创新的判断智能体自校正机制，有效解决了现有VLM在处理复杂文档理解任务时的局限性。测试时缩放和混合奖励建模进一步提升了其效率和性能，使其在保持小参数规模的同时，在长视觉上下文和复杂推理任务中展现出卓越的泛化能力和鲁棒性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型（VLMs）受限于参数规模、缺乏鲁棒的自校正能力，在长视觉上下文和复杂推理任务上表现不佳，导致文档相关任务的性能次优。

**Method:** 提出MACT框架，包含规划、执行、判断和回答四个小型智能体，具有明确角色和有效协作。判断智能体负责验证和重定向以进行修订。引入混合奖励建模和智能体级混合测试时缩放策略，以平衡智能体能力和全局协作，并定制缩放策略。

**Result:** MACT在文档和非文档基准测试中表现出色，参数规模更小，且不牺牲通用和数学任务能力。在涉及长视觉上下文和复杂推理的基准测试中表现突出。MACT的三个变体在15个基准测试中领先13个，平均得分位居前三。

**Conclusion:** MACT框架通过其多智能体协作和测试时缩放策略，有效解决了现有VLM在文档理解和VQA任务中的局限性，实现了卓越的性能。

> **ai_Abstract:** 本文提出MACT，一个用于视觉文档理解和问答的多智能体协作框架。MACT包含规划、执行、判断和回答四个小型智能体，通过独特的判断智能体进行自校正，并引入混合奖励建模和测试时缩放策略。实验结果表明，MACT在多种基准测试中表现优异，尤其擅长处理长视觉上下文和复杂推理任务，且参数规模更小。

> **摘要翻译:** 现有视觉-语言模型（VLMs），无论是通用型还是专业型，仍受限于其参数规模，缺乏鲁棒的自校正能力，并且在涉及长视觉上下文和复杂推理的任务中表现不佳，导致文档相关任务的性能不理想。为解决此问题，我们提出了MACT，一个具有测试时缩放功能的多智能体协作框架，专为视觉文档理解和视觉问答（VQA）量身定制。它包含四个不同的小规模智能体，即规划、执行、判断和回答智能体，它们具有明确定义的角色和有效的协作。值得注意的是，判断智能体专门负责验证正确性并重定向到先前的智能体进行修订，其性能优于传统的校正策略。为了进一步扩展该框架的能力边界，我们提出了平衡智能体特定能力和全局协作的混合奖励建模，以及根据其功能为每个智能体定制不同缩放策略的智能体级混合测试时缩放。在涵盖文档和非文档设置的基准测试中进行评估，我们的MACT在参数规模更小的情况下表现出卓越的性能，同时不牺牲通用和数学任务的能力。特别是，它在涉及长视觉上下文和复杂推理的基准测试中脱颖而出。MACT的三个变体在平均得分上始终占据前三名，并在15个基准测试中领先13个。代码将在此处提供：https://github.com/YU-deep/MACT.git。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [628] [Aether Weaver: Multimodal Affective Narrative Co-Generation with Dynamic Scene Graphs](https://arxiv.org/abs/2507.21893)
> *Aether Weaver: 基于动态场景图的多模态情感叙事协同生成*

*Saeed Ghorbani* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态协同生成, 动态场景图, 情感叙事, 大型语言模型, Aether Weaver

**Comment:** 

> **TL;DR:** Aether Weaver是一个新颖的集成框架，通过协同生成机制，同时合成文本叙事、动态场景图、视觉场景和情感音景，克服了传统文本到视觉管道的局限性，显著增强了叙事深度、视觉保真度和情感共鸣。

**AI_Comments:** Aether Weaver的创新之处在于其集成和协同生成机制，而非传统的顺序管道，这使得它能同时处理文本、视觉和音频，并在多个模态之间保持情感和结构的一致性。其引入的Director和Affective Tone Mapper等组件，有效解决了多模态内容生成中一致性难以保持的关键挑战。该框架对于沉浸式故事讲述和创意内容产业具有重要意义，有望提升用户体验和内容创作效率。

<details>
  <summary>Details</summary>

**Motivation:** 克服了现有顺序文本到视觉管道的局限性，旨在实现多模态叙事的协同生成。

**Method:** Aether Weaver是一个集成的框架，其核心包括：1. Narrator（叙述者）：一个大型语言模型，负责生成叙事文本和多模态提示。2. Director（导演）：作为动态场景图管理器，分析文本以构建和维护故事世界的结构化表示，确保视觉渲染和后续叙事生成的时空和关系一致性。3. Narrative Arc Controller（叙事弧控制器）：引导高层故事结构，影响多模态情感一致性。4. Affective Tone Mapper（情感色调映射器）：确保所有模态间的情感表达一致。该系统通过紧密集成的协同生成机制，同时合成文本叙事、动态场景图表示、视觉场景和情感音景。

**Result:** 通过对涵盖各种流派的多元叙事提示进行定性评估，Aether Weaver与级联基线方法相比，显著增强了叙事深度、视觉保真度和情感共鸣。

**Conclusion:** Aether Weaver集成框架为快速创意原型设计和沉浸式故事讲述体验提供了一个强大的平台。

> **ai_Abstract:** Aether Weaver是一个创新的多模态叙事协同生成框架，旨在克服传统文本到视觉流程的限制。该系统通过大型语言模型（Narrator）生成叙事文本和提示，并利用动态场景图管理器（Director）维护故事的时空一致性。此外，Narrative Arc Controller和Affective Tone Mapper确保了高层故事结构和跨模态情感表达的一致性。定性评估表明，Aether Weaver在叙事深度、视觉保真度和情感共鸣方面优于传统方法，为创意原型和沉浸式故事讲述提供了强大的平台。

> **摘要翻译:** 我们引入Aether Weaver，一个新颖的、集成的多模态叙事协同生成框架，它克服了顺序文本到视觉管道的局限性。我们的系统由紧密集成的协同生成机制驱动，同时合成文本叙事、动态场景图表示、视觉场景和情感音景。其核心是Narrator，一个大型语言模型，负责生成叙事文本和多模态提示；而Director则充当动态场景图管理器，分析文本以构建和维护故事世界的结构化表示，确保视觉渲染和后续叙事生成的时空和关系一致性。此外，一个Narrative Arc Controller引导高层故事结构，影响多模态情感一致性，并由一个Affective Tone Mapper进一步补充，确保所有模态间的情感表达一致。通过对涵盖各种流派的多元叙事提示进行定性评估，我们证明Aether Weaver与级联基线方法相比，显著增强了叙事深度、视觉保真度和情感共鸣。这个集成框架为快速创意原型设计和沉浸式故事讲述体验提供了一个强大的平台。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [630] [Separating Shared and Domain-Specific LoRAs for Multi-Domain Learning](https://arxiv.org/abs/2508.02978)
> *分离共享和领域特定LoRA以实现多领域学习*

*Yusaku Takama, Ning Ding, Tatsuya Yokota, Toru Tamaki* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多领域学习, LoRA, 领域特定信息, 子空间, 动作识别

**Comment:** 9 pages

> **TL;DR:** 本文提出了一种方法，确保共享LoRA和领域特定LoRA存在于不同的子空间中，以提高多领域学习中领域特定信息的捕获能力。

**AI_Comments:** 本文的创新点在于提出了将共享LoRA和领域特定LoRA分离到不同正交子空间的方法，这有助于更清晰地区分和捕获领域特定信息。这种方法为多领域学习中的适配器设计提供了新的思路，可能有助于提高模型在多领域任务上的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有多领域学习架构中共享LoRA和领域特定LoRA的结构是否能有效捕获领域特定信息尚不明确。

**Method:** 本文提出了一种方法，确保共享LoRA和领域特定LoRA存在于不同的子空间中，具体来说是预训练权重的列空间和左零空间。

**Result:** 将所提出的方法应用于动作识别，并在一些情况下证明了其有效性，同时分析了LoRA权重的维度。

**Conclusion:** 通过将共享和领域特定LoRA放置在不同的子空间中，可以有效提高多领域学习中领域特定信息的捕获能力。

> **ai_Abstract:** 本文针对多领域学习中现有共享LoRA和领域特定LoRA结构在捕获领域特定信息方面的不足，提出了一种新方法。该方法通过确保共享LoRA和领域特定LoRA分别存在于预训练权重的列空间和左零空间中，从而在不同子空间中实现分离。实验在动作识别任务的UCF101、Kinetics400和HMDB51数据集上验证了该方法的有效性，并对LoRA权重的维度进行了分析。

> **摘要翻译:** 现有多领域学习架构有两种类型的适配器：所有领域共享的LoRA和每个特定领域的领域特定LoRA。然而，这种结构是否能有效捕获领域特定信息仍不清楚。在本文中，我们提出了一种方法，确保共享LoRA和领域特定LoRA存在于不同的子空间中；具体来说是预训练权重的列空间和左零空间。我们将所提出的方法应用于动作识别，使用了三个数据集（UCF101、Kinetics400和HMDB51），并在一些情况下证明了其有效性，同时分析了LoRA权重的维度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [639] [LRDDv2: Enhanced Long-Range Drone Detection Dataset with Range Information and Comprehensive Real-World Challenges](https://arxiv.org/abs/2508.03331)
> *LRDDv2：增强型远程无人机检测数据集，包含距离信息和全面的现实世界挑战*

*Amirreza Rouhi, Sneh Patel, Noah McCarthy, Siddiqa Khan, Hadi Khorsand, Kaleb Lefkowitz, David K. Han* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 无人机检测, 远程检测, 数据集, 距离估计, 小目标检测

**Comment:** Accepted and presented at ISRR 2024

> **TL;DR:** LRDDv2是一个包含39,516张图像的增强型远程无人机检测数据集，其独特之处在于包含距离信息，旨在解决现有数据集在远程检测方面的不足。

**AI_Comments:** LRDDv2数据集的创新之处在于其对远程无人机检测的明确关注，特别是通过包含目标距离信息，这为开发新的无人机距离估计算法提供了独特的机会。该数据集的发布对于推动小目标检测和远程监控领域的研究具有重要意义，因为它解决了现有数据集在多样性和特定场景（如远距离和低分辨率目标）方面存在的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于无人机使用量的指数级增长，尤其是在人口密集区域，确保安全操作的关键在于能够在更远的距离检测到它们。尽管深度学习在计算机视觉方面取得了巨大进步，但检测小型空中物体仍然是一项艰巨的挑战。现有无人机检测数据集缺乏广泛性和多样性，尤其是在不同环境条件下进行远程检测方面。

**Method:** 本文引入了LRDDv2数据集，它是LRDD数据集的第二个版本，包含39,516张精心标注的图像。LRDDv2通过纳入更多种类的图像来增强LRDDv1，提供了更丰富和全面的无人机检测研究资源。其独特之处在于包含了超过8,000张图像的目标距离信息，从而可以开发无人机距离估计算法。

**Result:** LRDDv2数据集包含39,516张精心标注的图像，比LRDDv1具有更大的多样性和全面性。该数据集的显著特点是为超过8,000张图像提供了目标距离信息，使得开发无人机距离估计算法成为可能。为适应远程空中目标检测，LRDDv2数据集的大部分图像在1080p分辨率下捕捉的无人机像素数都在50或更少。

**Conclusion:** LRDDv2数据集的发布为远程无人机检测研究提供了一个更广泛、更多样化且包含距离信息的资源，有助于推动该领域算法的开发，特别是无人机距离估计。

> **ai_Abstract:** 本文介绍了LRDDv2数据集，一个包含39,516张精心标注图像的增强型远程无人机检测数据集。作为LRDDv1的升级版，LRDDv2旨在通过提供更广泛、更多样化的图像集合来解决现有数据集在远程无人机检测方面的不足。该数据集的显著特点是为超过8,000张图像提供了目标距离信息，这使得开发无人机距离估计算法成为可能。LRDDv2专注于远程检测，其大部分图像中的无人机在1080p分辨率下仅占50或更少像素。

> **摘要翻译:** 无人机（UAV）使用的指数级增长凸显了在更远距离检测它们以确保安全操作的关键需求，尤其是在人口稠密地区。尽管计算机视觉通过深度学习取得了巨大进步，但检测这些小型空中物体仍然是一项艰巨的挑战。虽然已经开发了几个专门用于无人机检测的数据集，但对更广泛、更多样化的无人机图像数据集合的需求依然存在，特别是用于在不同环境条件下进行远程检测。我们在此介绍远程无人机检测（LRDD）第2版数据集，它包含39,516张精心标注的图像，作为先前发布的LRDD数据集的第二个版本。LRDDv2数据集通过纳入更多种类的图像来增强LRDDv1，为无人机检测研究提供了更丰富和全面的资源。LRDDv2的独特之处在于它包含了超过8,000张图像的目标距离信息，使得开发无人机距离估计算法成为可能。为适应远程空中目标检测，LRDDv2数据集的大部分图像在1080p分辨率下捕捉的无人机像素数都在50或更少。如需访问完整的远程无人机检测数据集（LRDD）v2，请访问https://research.coe.drexel.edu/ece/imaple/lrddv2/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [641] [Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences](https://arxiv.org/abs/2508.03542)
> *语音转LaTeX：用于转换口述方程和句子新模型和数据集*

*Dmitrii Korzh, Dmitrii Tarasov, Artyom Iudin, Elvir Karimov, Matvey Skripkin, Nikita Kuzmin, Andrey Kuznetsov, Oleg Y. Rogov, Ivan Oseledets* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 语音转LaTeX, 数学表达式, 数据集, 音频语言模型, 多模态AI

**Comment:** 

> **TL;DR:** 本文介绍了用于将口述数学方程和句子转换为LaTeX的新模型和首个大规模开源数据集，并显著优于现有方法。

**AI_Comments:** 本文最大的创新在于构建并开源了首个大规模（66,000+样本）、多语言（英俄）的Speech-to-LaTeX数据集，同时涵盖了数学方程和句子，极大地推动了该领域的研究。此外，通过引入新的基准测试（S2L-equations和S2L-sentences）和应用音频语言模型，显著提升了转换性能。其重要性在于直接解决了教育和研究中口述数学转录的实际需求。尽管在S2L-sentences上的CER为40%仍有提升空间，但这项工作为未来多模态AI在数学内容识别方面的发展奠定了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 口述数学表达式转换为LaTeX是一项具有挑战性的任务，存在歧义且未被充分探索。现有工作存在多项限制，如需要两次转录、仅关注孤立方程、测试集有限且缺乏训练数据和多语言支持。这项任务在教育和研究领域（如讲座转录和笔记创建）具有直接应用价值。

**Method:** 提出了第一个完全开源的大规模数据集，包含超过66,000个来自不同科学领域的英语和俄语数学方程和句子的人工标注音频样本。除了ASR后校正模型和少量样本提示，还应用了音频语言模型。建立了首个数学句子识别基准（S2L-sentences）。

**Result:** 在MathSpeech基准测试中，方程转换的字符错误率（CER）结果具有可比性（28% 对 30%）。在提出的S2L-equations基准测试中，模型表现显著优于MathSpeech模型，领先超过40个百分点（27% 对 64%）。在S2L-sentences基准测试中，实现了40%的方程CER。

**Conclusion:** 这项工作为多模态AI的未来发展奠定了基础，特别关注数学内容识别。

> **ai_Abstract:** 本文针对口述数学表达式转换为LaTeX的挑战性任务，提出了新模型和首个大规模、完全开源的数据集。该数据集包含超过66,000个英语和俄语的数学方程和句子的人工标注音频样本，弥补了现有工作缺乏训练数据和多语言支持的不足。研究团队除了采用ASR后校正和少量样本提示，还应用了音频语言模型。结果显示，在现有基准测试上性能可比，而在新提出的S2L-equations基准测试上，模型表现显著优于现有方法，并建立了首个S2L-sentences数学句子识别基准。这项工作为多模态AI在数学内容识别领域的发展奠定了基础。

> **摘要翻译:** 口述数学表达式的转换是一项具有挑战性的任务，它涉及将语音转录为严格结构化的符号表示，同时解决方程发音中固有的歧义。尽管自动语音识别（ASR）和语言模型（LM）已取得显著进展，但将口述数学转换为LaTeX的问题仍未得到充分探索。这项任务直接应用于教育和研究领域，例如讲座转录或笔记创建。基于ASR后校正，先前的工作需要两次转录，仅关注孤立的方程，测试集有限，并且既不提供训练数据也不支持多语言覆盖。为了解决这些问题，我们提出了第一个完全开源的大规模数据集，包含来自不同科学领域的66,000多个英语和俄语数学方程和句子的人工标注音频样本。除了ASR后校正模型和少量样本提示外，我们还应用了音频语言模型，在MathSpeech基准测试中，方程转换的字符错误率（CER）结果具有可比性（28% 对 30%）。相比之下，在提出的S2L-equations基准测试中，即使考虑了LaTeX格式伪影，我们的模型也以超过40个百分点的显著优势超越了MathSpeech模型（27% 对 64%）。我们建立了第一个数学句子识别基准（S2L-sentences），并实现了40%的方程CER。这项工作为多模态AI的未来发展奠定了基础，特别关注数学内容识别。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [642] [Towards Optimal Aggregation of Varying Range Dependencies in Haze Removal](https://arxiv.org/abs/2408.12317)
> *去雾中不同范围依赖关系的最优聚合*

*Xiaozhe Zhang, Fengying Xie, Haidong Ding, Linpeng Pan, Zhenwei Shi* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 去雾, 双流网络, 依赖聚合, CLIP增强, 语义信息

**Comment:** 11 pages, 8 figures

> **TL;DR:** 本文提出了DehazeMatic，一个通过双流设计和CLIP增强聚合器，有效整合短程与长程依赖进行去雾的方法，并在多个基准测试中超越了现有最先进的方法。

**AI_Comments:** 该论文的创新之处在于其明确地整合并优化聚合了短程和长程依赖，并且首次利用细粒度的雾霾密度图和语义信息来指导这一聚合过程。这种结合了图像内容理解（通过语义信息）和物理特性（通过雾霾密度）的方法，为去雾领域提供了一个更全面和有效的新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有去雾方法专注于短程或长程依赖，未能有效整合两者的互补优势。本研究旨在在一个统一框架内明确整合并合理聚合不同范围的依赖关系，以实现更优的去雾效果。

**Method:** 本文提出了DehazeMatic，它采用双流设计同时捕获短程和长程依赖。为了优化不同范围依赖的贡献，作者引入了CLIP增强双路径聚合器，该聚合器首次生成细粒度雾霾密度图，并在共享骨干网络中生成语义图，然后利用两者共同指导聚合过程。

**Result:** DehazeMatic在多个基准测试中表现优于现有最先进的去雾方法。

**Conclusion:** 通过提出DehazeMatic，并采用雾霾密度和语义信息联合指导的CLIP增强双路径聚合器，该研究成功地优化了不同范围依赖关系的聚合，从而实现了卓越的去雾性能。

> **ai_Abstract:** 本文提出了一种名为DehazeMatic的新型去雾方法，旨在解决现有方法未能有效整合短程和长程依赖的问题。DehazeMatic采用双流设计来同时捕获这两种依赖关系。其核心创新在于引入了CLIP增强双路径聚合器，该聚合器能够首次生成细粒度雾霾密度图，并结合语义信息来指导不同范围依赖的最佳聚合。实验结果表明，DehazeMatic在多个基准测试中均超越了当前的先进方法。

> **摘要翻译:** 去雾旨在从有雾输入中恢复清晰图像。现有方法通过专注于短程依赖以保留局部细节或专注于长程依赖以捕获全局上下文，取得了显著成功。鉴于两者的互补优势，一个自然的发展是在统一框架内明确整合它们并实现其合理聚合。然而，这种整合仍未得到充分探索。在本文中，我们提出了DehazeMatic，它通过双流设计同时明确捕获短程和长程依赖。为了优化不同范围依赖的贡献，我们进行了大量实验以识别关键影响因素，并发现有效的聚合机制应由雾霾密度和语义信息的联合考虑来指导。基于这些见解，我们引入了CLIP增强双路径聚合器，它不仅首次实现了细粒度雾霾密度图的生成，还在共享骨干网络中生成语义图，最终利用两者来指导聚合过程。大量实验表明，DehazeMatic在多个基准测试中优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [643] [Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition](https://arxiv.org/abs/2507.21977)
> *运动很重要：基于骨骼的微动作识别中的运动引导调制网络*

*Jihao Gu, Kun Li, Fei Wang, Yanyan Wei, Zhiliang Wu, Hehe Fan, Meng Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 微动作识别, 运动引导调制网络, 骨骼动作, 细微运动, 时空表示学习

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出了一种运动引导调制网络（MMN），通过捕捉和调制细微的运动线索，显著提升了基于骨骼的微动作识别的性能。

**AI_Comments:** 该论文的创新点在于提出了一个专门用于捕捉和调制微动作中细微运动线索的网络架构。通过引入骨骼和帧层面的调制模块，有效地解决了现有方法难以区分细微动作的问题。其强调运动线索的重要性，并验证了其在微动作识别领域的有效性，为未来的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有微动作识别方法常忽略微动作中固有的细微变化，限制了区分这些动作的准确性。微动作在人类情感分析等社会互动中具有潜在应用，但识别准确性不足。

**Method:** 本文提出了一种新颖的运动引导调制网络（MMN），用于隐式捕捉和调制细微运动线索以增强时空表示学习。具体来说，引入了运动引导骨骼调制模块（MSM）在骨骼层面注入运动线索以引导空间表示建模；并行设计了运动引导时间调制模块（MTM）在帧层面整合运动信息以促进微动作整体运动模式建模。最后，提出了一种运动一致性学习策略来聚合多尺度特征的运动线索进行微动作分类。

**Result:** 在Micro-Action 52和iMiGUE数据集上的实验结果表明，MMN在基于骨骼的微动作识别中实现了最先进的性能。

**Conclusion:** 实验结果强调了显式建模细微运动线索对于微动作识别的重要性。

> **ai_Abstract:** 本文提出了一种名为运动引导调制网络（MMN）的新颖方法，旨在解决现有微动作识别方法未能有效捕捉细微运动变化的问题。MMN通过引入运动引导骨骼调制模块（MSM）和运动引导时间调制模块（MTM），分别在骨骼和帧层面注入并调制运动线索，以增强时空表示学习。此外，还采用了一种运动一致性学习策略来整合多尺度特征。实验结果表明，MMN在Micro-Action 52和iMiGUE数据集上达到了当前最佳性能，证明了细致建模细微运动线索对于微动作识别的关键作用。

> **摘要翻译:** 微动作（MAs）是社会互动中一种重要的非语言交流形式，在人类情感分析中具有潜在应用。然而，现有的微动作识别方法常常忽略微动作中固有的细微变化，这限制了区分具有细微变化的微动作的准确性。为了解决这个问题，我们提出了一种新颖的运动引导调制网络（MMN），该网络隐式捕捉和调制细微运动线索，以增强时空表示学习。具体来说，我们引入了一个运动引导骨骼调制模块（MSM）以在骨骼层面注入运动线索，作为控制信号来引导空间表示建模。同时，我们设计了一个运动引导时间调制模块（MTM）以在帧层面整合运动信息，促进微动作中整体运动模式的建模。最后，我们提出了一种运动一致性学习策略，以聚合多尺度特征中的运动线索进行微动作分类。在Micro-Action 52和iMiGUE数据集上的实验结果表明，MMN在基于骨骼的微动作识别中实现了最先进的性能，强调了显式建模细微运动线索的重要性。代码将在https://github.com/momiji-bit/MMN提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [657] [SlotMatch: Distilling Temporally Consistent Object-Centric Representations for Unsupervised Video Segmentation](https://arxiv.org/abs/2508.03411)
> *SlotMatch：用于无监督视频分割的时间一致性以物体为中心的表征蒸馏*

*Diana-Nicoleta Grigore, Neelu Madan, Andreas Mogelmose, Thomas B. Moeslund, Radu Tudor Ionescu* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 无监督视频分割, 知识蒸馏, 物体中心表征, Slot attention, 模型效率

**Comment:** 

> **TL;DR:** SlotMatch通过知识蒸馏将物体中心表征转移到轻量级模型，实现了优于SOTA的无监督视频分割，同时显著减少了参数和提高了速度。

**AI_Comments:** SlotMatch的创新点在于其极简的知识蒸馏方法，仅通过余弦相似度对齐就实现了复杂的物体中心表征的有效迁移，并证明了额外损失的冗余性。这对于在资源受限环境下部署无监督视频分割模型具有重要意义，因为它显著提高了效率而不牺牲性能，甚至有所提升。

<details>
  <summary>Details</summary>

**Motivation:** 无监督视频分割因缺乏监督信号和视觉场景复杂性而具有挑战性。现有基于slot attention的最先进模型通常需要大型且计算成本高的神经网络架构。

**Method:** 提出了一种名为SlotMatch的简单知识蒸馏框架，通过余弦相似度对相应的教师和学生slot进行对齐，将以物体为中心的表征有效转移到轻量级学生模型。该方法不需要额外的蒸馏目标或辅助监督。

**Result:** 在两个数据集上的实验表明，基于SlotMatch的学生模型在性能上与最先进的教师模型SlotContrast相当甚至超越，同时参数减少3.6倍，运行速度快1.9倍。此外，该学生模型超越了以前的无监督视频分割模型。

**Conclusion:** SlotMatch通过简单的知识蒸馏，成功地将复杂的物体中心表征转移到轻量级模型，在无监督视频分割任务中实现了卓越的性能和效率提升，并证明了额外损失的冗余性。

> **ai_Abstract:** 本文提出了SlotMatch，一个用于无监督视频分割的知识蒸馏框架。它通过简单的余弦相似度对齐，将复杂的以物体为中心的表征从大型教师模型蒸馏到轻量级学生模型，无需额外监督。实验证明，SlotMatch学生模型在保持甚至超越SOTA性能的同时，显著降低了模型大小和提高了运行速度，验证了其有效性和简洁性。

> **摘要翻译:** 无监督视频分割是一项具有挑战性的计算机视觉任务，特别是由于缺乏监督信号以及视觉场景的复杂性。为了克服这一挑战，基于slot attention的最先进模型通常不得不依赖大型且计算成本高的神经网络架构。为此，我们提出了一种简单的知识蒸馏框架，可以有效地将以物体为中心的表征转移到轻量级学生模型。所提出的框架名为SlotMatch，通过余弦相似度对相应的教师和学生slot进行对齐，不需要额外的蒸馏目标或辅助监督。SlotMatch的简单性通过理论和经验证据得到证实，两者都表明集成额外的损失是冗余的。我们在两个数据集上进行了实验，将最先进的教师模型SlotContrast与我们蒸馏出的学生模型进行比较。结果表明，我们基于SlotMatch的学生模型与教师模型相当甚至超越，同时使用的参数减少了3.6倍，运行速度快了1.9倍。此外，我们的学生模型超越了以前的无监督视频分割模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [663] [MoExDA: Domain Adaptation for Edge-based Action Recognition](https://arxiv.org/abs/2508.02981)
> *MoExDA：面向边缘的动作识别域自适应*

*Takuya Sugimoto, Ning Ding, Toru Tamaki* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 动作识别, 域自适应, 边缘信息, 静态偏差, 轻量级

**Comment:** 7 pages

> **TL;DR:** 本研究提出了一种名为MoExDA的轻量级域自适应方法，通过结合RGB信息和边缘帧信息来解决动作识别中的静态偏差问题，实验证明该方法能有效抑制静态偏差，降低计算成本，并提高动作识别的鲁棒性。

**AI_Comments:** 该研究提出了一种新颖的轻量级域自适应方法MoExDA，通过引入边缘帧来解决动作识别中的静态偏差问题，这在计算效率和性能提升方面具有潜力。然而，其具体在不同数据集和复杂场景下的泛化能力和局限性有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现代动作识别模型存在静态偏差问题，导致泛化性能下降。

**Method:** 提出了一种名为MoExDA的轻量级域自适应方法，该方法结合RGB帧和边缘帧信息，利用边缘帧来对抗静态偏差。

**Result:** 所提出的方法能有效抑制静态偏差，计算成本更低，从而实现比以往方法更鲁棒的动作识别。

**Conclusion:** MoExDA是一种有效的轻量级域自适应方法，能够通过结合RGB和边缘信息来解决动作识别中的静态偏差问题，提高模型性能。

> **ai_Abstract:** 本研究提出MoExDA，一种用于动作识别的轻量级域自适应方法，结合RGB和边缘信息以解决静态偏差问题，并在实验中证明其能有效抑制偏差、降低计算成本并提高鲁棒性。

> **摘要翻译:** 现代动作识别模型存在静态偏差，导致泛化性能下降。在本文中，我们提出了一种名为MoExDA的轻量级域自适应方法，该方法通过在RGB帧之外额外使用边缘帧，并结合RGB和边缘信息，来对抗静态偏差问题。实验证明，所提出的方法能够以更低的计算成本有效抑制静态偏差，从而实现比以往方法更鲁棒的动作识别。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [664] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
> *多模态指代分割：一项综述*

*Henghui Ding, Song Tang, Shuting He, Chang Liu, Zuxuan Wu, Yu-Gang Jiang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态指代分割, 图像分割, 视频分割, 3D场景分割, 综述

**Comment:** Project Page:
  https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation

> **TL;DR:** 这篇综述全面回顾了多模态指代分割领域，涵盖了背景、统一架构、图像/视频/3D场景的方法、广义指代表达、相关任务和应用，并提供了性能比较。

**AI_Comments:** 这篇综述对于多模态指代分割领域具有重要价值，因为它系统地整理了该领域的最新进展，提供了一个统一的视角来理解不同场景下的方法，并指出了未来研究的方向。它不仅总结了现有技术，还讨论了应对现实世界挑战的方法，并提供了性能基准，对于研究人员和工程师来说是一个宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 多模态指代分割在需要基于用户指令进行精确物体感知的实际应用中至关重要。随着卷积神经网络、Transformer和大型语言模型的发展，该领域在过去十年中获得了显著关注，因此有必要对其进行全面综述。

**Method:** 这篇综述首先介绍了多模态指代分割的背景、问题定义和常用数据集。接着，它总结了一个统一的元架构，并回顾了图像、视频和3D场景三种主要视觉场景中的代表性方法。此外，还讨论了广义指代表达（GREx）方法以应对现实世界复杂性，以及相关任务和实际应用。文中还提供了标准基准上的广泛性能比较。

**Result:** 这篇综述提供了一个统一的元架构总结，回顾了多模态指代分割在图像、视频和3D场景中的代表性方法，讨论了广义指代表达方法、相关任务和实际应用，并提供了广泛的性能比较。

**Conclusion:** 这篇综述全面概述了多模态指代分割的进展和挑战，为研究人员提供了该领域的背景、方法分类、应用和性能基准的宝贵资源。

> **ai_Abstract:** 本文对多模态指代分割领域进行了全面综述。它首先定义了该任务，阐述了其在实际应用中的重要性，并介绍了背景信息和数据集。随后，文章总结了一个统一的元架构，并详细回顾了在图像、视频和3D场景中实现的代表性方法。此外，综述还探讨了应对复杂现实世界的广义指代表达方法、相关任务和实际应用，并提供了详尽的性能比较。

> **摘要翻译:** 多模态指代分割旨在根据文本或音频格式的指代表达，在视觉场景（如图像、视频和3D场景）中分割目标对象。这项任务在需要基于用户指令进行精确物体感知的实际应用中发挥着关键作用。在过去十年中，随着卷积神经网络、Transformer和大型语言模型的发展，所有这些都极大地提升了多模态感知能力，该任务在多模态社区中获得了显著关注。本文对多模态指代分割进行了全面综述。我们首先介绍该领域的背景，包括问题定义和常用数据集。接下来，我们总结了一个用于指代分割的统一元架构，并回顾了图像、视频和3D场景三种主要视觉场景中的代表性方法。我们进一步讨论了广义指代表达（GREx）方法，以解决现实世界的复杂性挑战，以及相关任务和实际应用。文中还提供了标准基准上的广泛性能比较。我们持续在https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation跟踪相关工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [666] [Unifying Locality of KANs and Feature Drift Compensation for Data-free Continual Face Forgery Detection](https://arxiv.org/abs/2508.03189)
> *KANs 的局部性统一与无数据特征漂移补偿用于持续人脸伪造检测*

*Tianshuo Zhang, Siran Peng, Li Gao, Haoyuan Zhang, Xiangyu Zhu, Zhen Lei* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 持续学习,人脸伪造检测,Kolmogorov-Arnold 网络,灾难性遗忘,特征漂移

**Comment:** 

> **TL;DR:** 该研究提出了一种名为 KAN-CFD 的新框架，用于解决人脸伪造检测中的灾难性遗忘问题，通过改进的 KANs 和无数据重放策略来提高检测性能并减少遗忘。

**AI_Comments:** 该研究巧妙地将 KANs 的局部可塑性特性应用于持续学习场景，解决了人脸伪造检测中的关键挑战。通过 DG-KD 和 FS-KDCP 的设计，不仅克服了 KANs 在图像处理上的局限性，还创新性地实现了无数据重放的特征分离，这在数据隐私和存储受限的场景下具有重要意义。实验结果的验证也增强了该方法的实用性。未来可进一步探索 KANs 在其他持续学习任务中的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 人脸伪造技术快速发展，需要检测器持续适应新伪造方法，但现有检测器在学习新类型时会遗忘旧类型（灾难性遗忘）。KANs 因其局部可塑性激活函数适合解决此问题，但其样条在图像处理中效果不佳，且不同域特征易重叠导致冲突。

**Method:** 提出 KAN-CFD 框架，包括：1. 域分组 KAN 检测器 (DG-KD)，使 KANs 能处理高维图像输入并保持局部性；2. 无数据重放特征分离策略，通过 KAN 漂移补偿投影 (FS-KDCP) 避免 KAN 输入空间重叠。

**Result:** 实验结果表明，所提出的方法在提高性能的同时显著减少了遗忘。

**Conclusion:** KAN-CFD 框架通过 DG-KD 和 FS-KDCP 策略，成功地将 KANs 应用于持续人脸伪造检测，有效解决了局部性问题和特征重叠问题，提高了检测性能并减轻了灾难性遗忘。

> **ai_Abstract:** 该研究提出了一种名为 KAN-CFD 的新框架，旨在解决持续人脸伪造检测中的灾难性遗忘问题。通过域分组 KAN 检测器（DG-KD）来处理高维图像并保持 KANs 的局部性，以及利用无数据重放的特征分离策略（FS-KDCP）来补偿特征漂移和避免域冲突，该方法在实验中展现出优越的性能和更低的遗忘率。

> **摘要翻译:** 人脸伪造技术的快速发展使得检测器需要持续适应新的伪造方法，从而将人脸伪造检测置于持续学习范式中。然而，当检测器学习新的伪造类型时，其对先前类型的性能往往会迅速下降，这种现象被称为灾难性遗忘。Kolmogorov-Arnold 网络（KANs）利用局部可塑样条作为其激活函数，使得它们能够通过仅修改函数的局部区域而不影响其他区域来学习新任务。因此，它们自然适合解决灾难性遗忘问题。然而，KANs 有两个显著的局限性：1）样条对于对高维图像建模无效，而适合图像的替代激活函数缺乏局部性的基本属性；2）在持续学习中，当不同域的特征重叠时，由于相同区域的重复修改，不同域到不同曲线区域的映射总是会崩溃。在本文中，我们提出了一种基于 KAN 的持续人脸伪造检测（KAN-CFD）框架，该框架包括一个域分组 KAN 检测器（DG-KD）和一个通过 KAN 漂移补偿投影（FS-KDCP）实现的无数据重放特征分离策略。DG-KD 使 KANs 能够拟合高维图像输入，同时保持局部性和局部可塑性。FS-KDCP 在不使用先前任务数据的情况下，避免了 KAN 输入空间的重叠。实验结果表明，所提出的方法在实现卓越性能的同时，显著减少了遗忘。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [668] [Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation](https://arxiv.org/abs/2508.03334)
> *宏观微观规划用于高质量和并行化自回归长视频生成*

*Xunzhi Xiang, Yabo Chen, Guiyu Zhang, Zhongyu Wang, Zhe Gao, Quanming Xiang, Gonghu Shang, Junqi Liu, Haibin Huang, Yang Gao, Chi Zhang, Qi Fan, Xuelong Li* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 长视频生成,自回归模型,宏观微观规划,并行化,扩散模型

**Comment:** 

> **TL;DR:** 现有的自回归扩散模型在视频生成方面表现出色，但通常仅限于较短的时间长度。为了解决这个问题，我们提出了一种名为“宏观微观规划”（MMPL）的新型规划后填充框架，用于长视频生成。MMPL通过两个层次的阶段（微观规划和宏观规划）来勾画整个视频的全局故事情节。微观规划预测每个短视频片段中的未来关键帧，为生成高质量视频片段提供运动和外观先验。宏观规划通过微观规划的自回归链将关键帧规划扩展到整个视频，确保视频片段之间的长期一致性。随后，基于MMPL的内容填充并行生成片段中的所有中间帧，实现了自回归生成的有效并行化。通过自适应工作负载调度进一步优化了并行化，以平衡GPU执行和加速自回归视频生成。实验证明，我们的方法在质量和稳定性方面优于现有的长视频生成模型。

**AI_Comments:** 该研究提出了一种创新的“宏观微观规划”框架，有效地解决了长视频生成中的关键挑战，如时间漂移和并行化困难。通过将长视频生成分解为层次化的规划和并行填充任务，该方法在质量和效率上都取得了显著的提升。未来的工作可以进一步探索更复杂的场景和内容，以及更精细的规划策略。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自回归扩散模型在视频生成方面存在时间长度限制，并且由于误差累积导致的 temporal drift 和自回归生成难以并行化的问题。

**Method:** 提出了一种名为“宏观微观规划”（MMPL）的新型规划后填充框架，用于长视频生成。该框架包含两个层次的规划阶段：微观规划（预测短视频片段内的未来关键帧）和宏观规划（通过自回归链将关键帧规划扩展到整个视频），以及基于MMPL的内容填充（并行生成中间帧）和自适应工作负载调度（优化并行化）。

**Result:** 实验表明，所提出的MMPL方法在视频生成质量和稳定性方面优于现有的长视频生成模型。

**Conclusion:** 所提出的MMPL框架通过宏观-微观规划和并行填充有效地解决了现有自回归扩散模型在长视频生成中的局限性，显著提高了生成视频的质量和稳定性。

> **ai_Abstract:** 本研究提出了一种用于长视频生成的“宏观微观规划”（MMPL）框架，以解决现有自回归扩散模型在时间长度和并行化方面的限制。MMPL通过分层规划（微观规划预测片段关键帧，宏观规划确保跨片段一致性）和并行内容填充，实现了高质量、长时序且高效的视频生成。

> **摘要翻译:** 当前的自回归扩散模型在视频生成方面表现出色，但通常仅限于较短的时间长度。我们的理论分析表明，自回归建模通常会因误差累积而导致时间漂移，并阻碍长视频合成的并行化。为了解决这些局限性，我们提出了一种以宏观微观规划（MMPL）为中心的、用于长视频生成的新型规划后填充框架。MMPL通过两个层次的阶段：微观规划和宏观规划，来勾画整个视频的全局故事情节。具体来说，微观规划预测每个短视频片段内的稀疏未来关键帧，为生成高质量视频片段提供运动和外观先验。宏观规划通过微观规划的自回归链将片段内的关键帧规划扩展到整个视频，确保视频片段之间的长期一致性。随后，基于MMPL的内容填充并行生成跨片段的所有中间帧，实现了自回归生成的有效并行化。通过自适应工作负载调度进一步优化了并行化，以平衡GPU执行和加速自回归视频生成。广泛的实验证实，我们的方法在质量和稳定性方面优于现有的长视频生成模型。生成的视频和比较结果可在我们的项目页面中找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [671] [The Promise of RL for Autoregressive Image Editing](https://arxiv.org/abs/2508.01119)
> *强化学习在自回归图像编辑中的应用前景*

*Saba Ahmadi, Rabiul Awal, Ankur Sikarwar, Amirhossein Kazemnejad, Ge Ya Luo, Juan A. Rodriguez, Sai Rajeswar, Siva Reddy, Christopher Pal, Benno Krojer, Aishwarya Agrawal* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 图像编辑, 自回归模型, 多模态模型, 链式思考

**Comment:** 

> **TL;DR:** 本研究提出了一种名为EARL的基于强化学习（RL）的图像编辑模型，该模型结合了大型多模态语言模型（LLM）验证器，在多种图像编辑任务上表现出色，并且训练数据量较少。

**AI_Comments:** 该研究提出了一种新颖的基于强化学习的图像编辑模型EARL，该模型通过结合大型多模态语言模型验证器，在图像编辑任务上取得了优于监督微调和链式思考等其他策略的性能。EARL模型在训练数据量较少的情况下仍能保持竞争力，这表明其在提高模型效率和性能方面具有重要潜力。该研究的创新性在于将RL应用于自回归多模态模型进行图像编辑，并取得了显著的成果。未来可以进一步探索RL在更复杂的图像编辑任务中的应用，以及优化模型结构以进一步提升性能。

<details>
  <summary>Details</summary>

**Motivation:** 探索提高图像编辑任务性能的策略，特别是监督微调（SFT）、强化学习（RL）和链式思考（CoT）推理。

**Method:** 采用一个统一处理文本和视觉标记的自回归多模态模型框架，并探索了SFT、RL和CoT三种策略，重点研究了RL与大型多模态LLM验证器的结合。

**Result:** RL结合大型多模态LLM验证器是三种策略中最有效的。EARL模型在多样化的编辑任务上表现具有竞争力，且训练数据量更少。

**Conclusion:** EARL模型是基于RL的图像编辑模型的有力代表，推动了自回归多模态模型在图像编辑领域的应用。

> **ai_Abstract:** 该研究提出了一种名为EARL的图像编辑模型，利用自回归多模态框架，探索了SFT、RL和CoT等策略。研究发现，RL结合大型多模态LLM验证器效果最佳。EARL模型在多种图像编辑任务上表现出色，训练数据需求少，推动了该领域的发展。

> **摘要翻译:** 我们探索了三种策略以提高在一系列图像编辑任务上的性能：监督微调（SFT）、强化学习（RL）和链式思考（CoT）推理。为了在一个一致的框架中研究所有这些组件，我们采用了一个自回归多模态模型，该模型以统一的方式处理文本和视觉标记。我们发现，将RL与大型多模态LLM验证器相结合是这些策略中最有效的。因此，我们发布了EARL：Editing with Autoregression and RL，这是一个强大的基于RL的图像编辑模型，尽管使用的训练数据量少得多，但在各种编辑任务上的表现与强大的基线模型相比仍具有竞争力。因此，EARL推动了自回归多模态模型在图像编辑方面的应用。我们在https://github.com/mair-lab/EARL发布了我们的代码、训练数据和训练好的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [676] [Advancing Wildlife Monitoring: Drone-Based Sampling for Roe Deer Density Estimation](https://arxiv.org/abs/2508.03545)
> *推进野生动物监测：基于无人机的 Roe 鹿密度估算*

*Stephanie Wohlfahrt, Christoph Praschl, Horst Leitner, Wolfram Jantsch, Julia Konic, Silvio Schueler, Andreas Stöckl, David C. Schedl* | **Category: cs.CV, q-bio.QM, 62P10, I.4.8** | **Updated: 2025-08-05**

**Keywords:** 无人机, Roe 鹿, 密度估算, 热成像, 相机陷阱

**Comment:** 6 pages, 1 figure, 1 table, International Wildlife Congress 2025

> **TL;DR:** 该研究使用无人机结合热成像和RGB影像，在奥地利东南部估算 Roe 鹿密度，并与相机陷阱数据进行比较。研究发现无人机方法高效且具有可扩展性，但估算结果可能反映的是日间活动，而相机陷阱方法估算的是较长时间段内的平均活动。

**AI_Comments:** 该研究有效地展示了无人机技术在野生动物监测中的潜力，特别是在密度估算方面。通过结合热成像和RGB影像，并与传统相机陷阱方法进行比较，为该领域提供了有价值的见解。研究中提到的不同外推方法及其对结果的影响值得进一步探讨。此外，无人机活动对野生动物行为的潜在影响以及如何最小化这种影响也是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统野生动物密度估算方法（如捕获-标记-重捕、距离取样、相机陷阱）劳动密集且空间受限，因此需要更高效、可扩展的方法。

**Method:** 使用搭载热成像（IR）和RGB传感器的无人机，在奥地利东南部进行了两次（10月和11月）单日调查。无人机沿预设网格和随机化路径飞行，在60米高度进行拍摄，以避免惊扰鹿群。对拍摄到的影像进行手动标注，并应用三种外推方法（朴素面积外推、自助法、零膨胀负二项模型）计算密度。同时，使用相机陷阱数据和随机遭遇模型（REM）作为对比。

**Result:** 基于无人机的估算方法结果相似，通常比REM方法估算出的密度更高，但在10月的一个区域例外。研究推测无人机方法反映的是日间活动，而REM方法反映的是较长时间段内的平均活动。

**Conclusion:** 无人机是一种有前景的、可扩展的野生动物密度估算方法，尽管它提供的密度估算可能与传统方法（如REM）反映的活动模式有所不同。

> **ai_Abstract:** 本研究利用无人机结合热成像和RGB影像技术，在奥地利东南部对Roe 鹿的密度进行了估算，并与相机陷阱数据进行了对比。研究方法包括使用无人机进行高效、非侵入性的动物计数，并应用了三种不同的外推方法来计算密度。结果显示，无人机方法与相机陷阱方法（REM）在密度估算上存在差异，可能反映了不同时间尺度上的动物活动模式。研究结论认为，无人机是一种有前景的、可扩展的野生动物密度监测工具。

> **摘要翻译:** 我们使用无人机估算奥地利东南部野生动物密度，并将这些估算与相机陷阱数据进行比较。传统的捕获-标记-重捕、距离取样或相机陷阱等方法已经确立，但劳动密集或空间受限。使用热成像（IR）和RGB影像，无人机能够进行高效、非侵入性的动物计数。我们的调查在10月和11月（无叶期）的三个亚伊利里亚丘陵和台地景观区域进行了单日调查。飞行航线基于预设的发射点，采用350米网格，并通过算法定义系统随机化航线的方向。这种设置允许使用多架无人机在一天内调查大片区域，并最大限度地减少重复计数。飞行高度设定为60米，以避免干扰 Roe 鹿（Capreolus capreolus）但又能确保探测。在记录的影像中手动标注动物，并推断出每平方公里的密度。我们应用了三种外推方法，其复杂性逐渐增加：朴素的基于面积的外推、自助法和零膨胀负二项模型。作为比较，我们使用飞行期间的相机陷阱数据计算了随机遭遇模型（REM）的估算值。基于无人机的方法得出了相似的结果，通常比REM估算出的密度更高，除了10月的一个区域。我们假设基于无人机的密度反映了开阔和林地区域的日间活动，而REM估算值反映了林区内更长时间段的平均活动。尽管两种方法都估算密度，但它们提供了对野生动物存在的不同视角。我们的结果表明，无人机为野生动物密度估算提供了一种有前景的、可扩展的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [Dynamic 2D Gaussians: Geometrically Accurate Radiance Fields for Dynamic Objects](https://arxiv.org/abs/2409.14072)
> *动态二维高斯：动态对象的几何精度辐射场*

*Shuai Zhang, Guanjun Wu, Zhoufeng Xie, Xinggang Wang, Bin Feng, Wenyu Liu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 动态二维高斯, 几何精度, 网格重建, 动态对象, 稀疏输入

**Comment:** Accepted by ACMMM 2025

> **TL;DR:** 该研究提出了一种名为动态二维高斯（D-2DGS）的新型表示方法，使用二维高斯和稀疏控制点来表示动态对象的几何形状，能够从稀疏图像输入中重建高质量网格，并能有效去除重建过程中产生的浮动点，实验证明其在重建细节丰富、平滑的高质量网格方面表现优异。

**AI_Comments:** 该研究在动态对象网格重建领域提出了创新的D-2DGS方法，解决了现有技术在几何精度上的不足，并能处理稀疏输入，具有重要的实际应用价值。其通过掩码技术去除伪影的思路也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的4D表示方法虽然能渲染动态对象的优质新视角，但由于其隐式或几何不准确的表示，无法重建高质量的网格。

**Method:** 提出了一种名为动态二维高斯（D-2DGS）的新型表示方法，采用二维高斯作为基础几何表示，并使用稀疏控制点捕捉二维高斯的变形。通过提取渲染的高质量图像中的对象掩码并对渲染的深度图进行掩码处理，去除重建过程中易产生的浮动点，从而提取动态对象的优质动态网格序列。

**Result:** 实验表明，D-2DGS在从稀疏输入重建细节丰富、平滑的高质量网格方面表现出色。

**Conclusion:** D-2DGS是一种能够从稀疏图像输入中重建准确网格的新型表示方法，特别擅长处理动态对象，能够生成高质量、细节丰富且平滑的网格。

> **ai_Abstract:** 该研究提出了一种名为动态二维高斯（D-2DGS）的新型表示方法，用于从稀疏图像输入中重建动态对象的几何精度网格。D-2DGS利用二维高斯和稀疏控制点来捕捉几何变形，并通过掩码技术去除伪影，实现了高质量的动态网格序列重建。

> **摘要翻译:** 重建物体和提取高质量表面在现实世界中起着至关重要的作用。目前的4D表示方法展示了渲染动态对象高质量新视角的能力，但由于其隐式或几何不准确的表示，无法重建高质量网格。在本研究中，我们提出了一种能够从稀疏图像输入重建准确网格的新型表示，命名为动态二维高斯（D-2DGS）。我们采用二维高斯作为基础几何表示，并使用稀疏控制点来捕捉二维高斯的变形。通过从渲染的高质量图像中提取对象掩码并对渲染的深度图进行掩码处理，我们可以去除重建过程中易产生的浮动点，并能够提取动态对象的优质动态网格序列。实验证明，我们的D-2DGS在从稀疏输入重建细节丰富、平滑的高质量网格方面表现出色。代码可在https://github.com/hustvl/Dynamic-2DGS获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [685] [Zero-shot Segmentation of Skin Conditions: Erythema with Edit-Friendly Inversion](https://arxiv.org/abs/2508.01334)
> *皮肤病变（红斑）的零样本分割：一种易于编辑的逆转方法*

*Konstantinos Moutselos, Ilias Maglogiannis* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 零样本分割, 红斑检测, 扩散模型, 图像编辑, 计算机辅助皮肤病学

**Comment:** 

> **TL;DR:** 本研究提出了一种利用扩散模型中的易于编辑的逆转方法，通过生成编辑来合成无红斑的参考图像，并将其与原始图像对齐，从而实现红斑的零样本分割，并取得了比基线方法更好的效果。

**AI_Comments:** 该研究在零样本分割领域提出了一个创新的方法，特别是在皮肤病学应用方面。通过结合扩散模型的生成能力和颜色空间分析，成功地解决了对标注数据依赖的问题。易于编辑的逆转概念是一个亮点，为未来的研究开辟了道路。然而，实验仅限于定性评估，未来的工作可以考虑进行更广泛的定量分析和在不同皮肤病变上的应用。

<details>
  <summary>Details</summary>

**Motivation:** 减少对标记皮肤病学数据集的依赖，为计算机辅助皮肤病学提供一种可扩展、灵活且无需注释训练掩码的诊断支持工具。

**Method:** 利用扩散模型中的易于编辑的逆转方法，通过生成编辑合成无红斑的参考图像，然后将参考图像与原始图像对齐。最后，通过颜色空间分析来识别红斑区域。

**Result:** 在初步的定性实验中，该流程成功地分离了各种病例的面部红斑，并在性能上优于基于阈值的基线技术。

**Conclusion:** 将生成扩散模型与统计颜色分割相结合，为计算机辅助皮肤病学提供了一种有效且无需预先训练数据即可检测红斑的潜力。

> **ai_Abstract:** 本研究提出了一种新颖的零样本皮肤病变分割框架，专注于红斑的检测。该方法利用扩散模型的编辑逆转功能，为患者生成不含红斑的参考图像，并将其与原始图像精确对齐。通过简化的颜色空间分析，该技术能够识别红斑区域，有效减少了对大量标注数据的需求。实验结果表明，该方法在处理不同病例的面部红斑时表现出色，优于传统的基于阈值的方法，为计算机辅助皮肤病学提供了一种高效且无需训练数据的解决方案。

> **摘要翻译:** 本研究提出了一种利用扩散模型中的易于编辑的逆转方法，通过生成编辑来合成无红斑的参考图像，并将其与原始图像对齐，从而实现红斑的零样本分割。颜色空间分析只需最少的用户干预即可识别红斑区域。该方法显著减少了对标记皮肤病学数据集的依赖，并通过避免对任何注释训练掩码的需求，提供了一个可扩展且灵活的诊断支持工具。在我们初步的定性实验中，该流程成功地分离了各种病例的面部红斑，展示了比基于阈值技术更好的性能。这些结果凸显了结合生成扩散模型和统计颜色分割在计算机辅助皮肤病学方面的潜力，能够高效地检测红斑，而无需预先的训练数据。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [689] [R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation](https://arxiv.org/abs/2508.03426)
> *基于LLM的放射报告生成的分层多模态知识图谱*

*Futian Wang, Yuhan Qiao, Xiao Wang, Fuling Wang, Yuxiang Zhang, Dengdi Sun* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 放射报告生成, 知识图谱, 大语言模型, 多模态学习, 医疗人工智能

**Comment:** 

> **TL;DR:** 该研究提出了一种名为R2GenKG的新框架，利用多模态知识图谱来改进基于大语言模型（LLM）的放射报告生成，解决了幻觉和诊断能力弱的问题。框架包含构建M3KG知识图谱、使用R-GCN和Swin-Transformer提取特征，并通过交叉注意力机制整合视觉和知识信息，最终生成放射报告。

**AI_Comments:** 该研究提出了一个创新的方法，通过构建多模态知识图谱来增强LLM在放射报告生成中的能力，特别是在解决幻觉和提高诊断准确性方面。M3KG的构建和R-GCN、Swin-Transformer以及交叉注意力的结合展示了多模态信息融合的潜力。然而，知识图谱的规模和构建过程的计算成本可能是潜在的限制因素，未来可以进一步探索更高效的知识图谱构建和利用方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于大语言模型的医学影像报告生成技术存在幻觉和疾病诊断能力不足的问题。

**Method:** 1. 构建大规模多模态医学知识图谱M3KG（包含2477个实体，3种关系，37424个三元组，6943个疾病感知视觉标记）。2. 使用R-GCN编码器提取多粒度语义图谱特征。3. 使用Swin-Transformer提取X光图像的视觉特征。4. 通过交叉注意力机制整合视觉特征和知识信息。5. 使用Q-former和交叉注意力检索疾病感知视觉标记。6. 利用大语言模型将语义知识图谱、X光图像和疾病感知视觉标记映射为语言描述。

**Result:** 在多个数据集上的广泛实验验证了所提出的知识图谱和X光报告生成框架的有效性。

**Conclusion:** 所提出的R2GenKG框架通过整合多模态知识图谱，有效提升了基于LLM的放射报告生成质量，解决了现有技术中的挑战。

> **ai_Abstract:** 本研究提出了一种名为R2GenKG的框架，用于改进基于大语言模型（LLM）的放射报告生成。该框架通过构建一个大规模多模态医学知识图谱（M3KG），并结合R-GCN和Swin-Transformer等技术来提取和整合视觉与知识信息，以解决现有模型中存在的幻觉和诊断能力弱的问题。实验结果表明，该框架在多个数据集上表现出优越的性能。

> **摘要翻译:** X光医学报告生成是医疗领域人工智能的重要应用之一。在大语言模型（LLM）的支持下，医学报告生成的质量得到了显著提升。然而，诸如幻觉和疾病诊断能力弱等挑战仍然存在。在本研究中，我们首先利用GPT-4o基于基础医学报告构建了一个大规模多模态医学知识图谱（M3KG），其中包含CheXpert Plus数据集的2477个实体、3种关系、37424个三元组以及6943个疾病感知视觉标记。然后，我们对其进行采样以获得多粒度语义图谱，并使用R-GCN编码器进行特征提取。对于输入的X光图像，我们采用Swin-Transformer提取视觉特征并与知识进行交叉注意力交互。视觉标记被输入Q-former，并通过另一个交叉注意力机制检索疾病感知视觉标记。最后，我们采用大语言模型将语义知识图谱、输入X光图像和疾病感知视觉标记映射为语言描述。在多个数据集上的广泛实验充分验证了我们提出的知识图谱和X光报告生成框架的有效性。本文的源代码将在https://github.com/Event-AHU/Medical_Image_Analysis发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [699] [Open-Attribute Recognition for Person Retrieval: Finding People Through Distinctive and Novel Attributes](https://arxiv.org/abs/2508.01389)
> *开放属性识别在行人检索中的应用：通过区分性和新颖性属性寻找行人*

*Minjeong Park, Hongbeen Park, Sangwon Lee, Yoonha Jang, Jinkyu Kim* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 行人检索, 属性识别, 开放集识别, 身体部位表示, 开放属性识别

**Comment:** 

> **TL;DR:** 该研究提出了开放属性识别（OAPR）任务，以解决现有行人属性识别（PAR）方法在现实场景中无法处理新属性以及通用属性区分度低的问题。研究者们设计了一个新颖的框架来学习可泛化的身体部位表示，并重建了四个常用数据集以支持开放属性识别。实验证明了OAPR任务的必要性和所提出框架的有效性。

**AI_Comments:** 这项研究解决了行人检索领域的一个重要实际问题，即如何处理现实世界中不断出现的新属性以及如何提高现有属性的区分度。所提出的OAPR任务和框架具有创新性，并且通过重建数据集来支持该任务也体现了研究的严谨性。然而，框架在处理大量新颖属性时的可扩展性和鲁棒性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于属性的行人检索方法存在两个主要问题：1. 它们通常假设在训练和推理过程中所有属性类别都可用（闭集假设），这限制了它们在现实世界中的应用，因为新属性可能会出现。2. 基准数据集中的预定义属性通常是通用的，并且在个体之间共享，这使得它们在检索目标行人时区分度较低。

**Method:** 提出开放属性识别（OAPR）任务，旨在无论属性是否在训练期间见过，都能基于属性线索检索行人。为此，研究者们引入了一个新颖的框架，用于学习能够覆盖广泛属性类别的一般化身体部位表示。此外，他们还重建了四个广泛使用的基准数据集，以适应开放属性识别的需求。

**Result:** 在重建的四个数据集上的综合实验表明，OAPR任务是必要的，并且所提出的框架是有效的。

**Conclusion:** 该研究提出的开放属性识别（OAPR）任务以及相应框架能够有效解决现有行人属性识别方法在处理新颖属性和提高属性区分度方面的局限性，为行人检索提供了新的解决方案。

> **ai_Abstract:** 本研究提出了开放属性识别（OAPR）任务，以解决行人检索中现有方法在处理新属性和提高属性区分度方面的不足。研究者们设计了一个新颖的框架来学习通用的身体部位表示，并重建了数据集以支持此任务。实验结果证明了该方法的有效性。

> **摘要翻译:** 行人属性识别（PAR）在行人检索和识别等多种视觉任务中起着至关重要的作用。大多数现有的基于属性的检索方法在闭集假设下运行，即所有属性类别在训练和推理过程中都可用。然而，这种假设限制了它们在现实场景中的应用，因为新属性可能会出现。此外，基准数据集中的预定义属性通常是通用的，并且在个体之间共享，这使得它们在检索目标行人时区分度较低。为了应对这些挑战，我们提出了开放属性识别行人检索（OAPR）任务，旨在无论这些属性在训练期间是否见过，都能基于属性线索检索行人。为了支持这项任务，我们引入了一个新颖的框架，旨在学习能够覆盖广泛属性类别的一般化身体部位表示。此外，我们重建了四个广泛使用的基准数据集以用于开放属性识别。在这些数据集上的综合实验证明了OAPR任务的必要性以及我们框架的有效性。源代码和预训练模型将在发布后公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [702] [Beyond Meme Templates: Limitations of Visual Similarity Measures in Meme Matching](https://arxiv.org/abs/2508.03562)
> *超越表情包模板：视觉相似性度量在表情包匹配中的局限性*

*Muzhaffar Hazman, Susan McKeever, Josephine Griffith* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 表情包匹配, 模板匹配, 视觉相似性, 非模板化表情包, 多模态大语言模型

**Comment:** Accepted for publication at IEEE International Conference on Image
  Processing Theory, Tools and Applications (IPTA) 2025

> **TL;DR:** 现有表情包匹配方法主要依赖模板匹配，无法有效处理非模板化表情包。本文提出了一种超越模板匹配的更广泛的表情包匹配方法，并探索了基于多模态大语言模型的匹配方法，但发现准确匹配表情包仍然是一个挑战。

**AI_Comments:** 该研究指出了现有表情包匹配方法的局限性，并提出了超越模板匹配的解决方案，具有一定的理论和实践意义。然而，研究结果也表明，表情包匹配的准确性仍有待提高，需要进一步探索更先进的技术。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于模板匹配的表情包匹配方法无法有效处理非模板化表情包，限制了自动表情包分析和与在线表情包词典的链接。

**Method:** 提出了一种超越模板匹配的更广泛的表情包匹配方法，并引入了相似度度量的分段式计算方法，同时探索了使用预训练的多模态大语言模型进行提示式匹配。

**Result:** 分段式计算方法在匹配非模板化表情包方面优于整图度量，但传统的相似度度量在匹配模板化表情包方面表现良好。基于提示的方法也显示出潜力，但准确匹配表情包仍具挑战。

**Conclusion:** 准确地通过共享视觉元素（而不仅仅是背景模板）匹配表情包仍然是一个需要更复杂匹配技术的开放性挑战。

> **ai_Abstract:** 本研究旨在解决当前表情包匹配方法主要依赖模板匹配，而忽略非模板化表情包的问题。研究人员提出了一种更广泛的匹配框架，并通过分段式计算和多模态大语言模型探索了新的匹配技术。实验结果表明，虽然分段式计算在处理非模板化表情包方面有所改进，但准确匹配表情包仍然是一个挑战。

> **摘要翻译:** 互联网表情包是数字传播的主食，在用户参与在线社区和研究人员深入了解当代数字文化方面发挥着关键作用。这些引人入胜的用户生成内容以其视觉元素的重用为特征，这些视觉元素也存在于其他表情包中。通过这些共享视觉元素匹配表情包实例，称为表情包匹配，是多种表情包分析方法的基础。然而，大多数现有方法假设每个表情包都包含一个共享的视觉背景（称为模板）以及一些叠加的文本，从而将表情包匹配限制在仅比较背景图像上。当前的方法排除了许多非模板化表情包，并限制了自动表情包分析的有效性，也无法有效地将表情包与当代基于网络的表情包词典联系起来。在这项工作中，我们引入了一种超越模板匹配的更广泛的表情包匹配方法。我们表明，传统的相似度度量（包括新颖的分段式计算相似度度量）在匹配模板化表情包方面表现出色，但在应用于非模板化表情包格式时则表现不佳。然而，人们发现分段式方法在匹配非模板化表情包方面始终优于整图度量。最后，我们探索了一种使用预训练的多模态大语言模型的基于提示的方法来进行表情包匹配。我们的结果强调，通过共享视觉元素（而不仅仅是背景模板）准确匹配表情包仍然是一个开放性挑战，需要更复杂的匹配技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [703] [Beyond Illumination: Fine-Grained Detail Preservation in Extreme Dark Image Restoration](https://arxiv.org/abs/2508.03336)
> *超越照明：极端暗图像中的细粒度细节保留*

*Tongshun Zhang, Pingping Liu, Zixuan Zhong, Zijian Zhang, Qiuzhan Zhou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 暗图像恢复, 细节保留, 傅里叶变换, Mamba, 图像增强

**Comment:** 

> **TL;DR:** 提出一种高效的双阶段方法，利用傅里叶变换和Mamba模块来恢复极端暗图像中的细节和边缘。

**AI_Comments:** 该研究提出了一种创新的双阶段方法，通过利用傅里叶变换和Mamba模块来解决暗图像恢复中的关键挑战——细粒度细节的保留。RFGM在频域处理光照恢复的思路很有前景，而Patch Mamba和Grad Mamba在纹理和边缘细节上的侧重则进一步增强了方法的有效性。该方法不仅在性能上有所提升，而且强调了模块的轻量级和易集成性，这对于实际应用具有重要意义。然而，文章未提及该方法在计算复杂度或处理速度方面的具体量化评估，这可能是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在恢复极端暗图像的细节和边缘方面存在不足，影响下游应用。

**Method:** 提出一种双阶段方法：第一阶段使用残差傅里叶引导模块（RFGM）在频域恢复全局光照，第二阶段使用补丁Mamba和梯度Mamba模块来细化纹理结构和高梯度区域。

**Result:** 实验表明，该方法显著提高了细节恢复性能，同时保持了效率，并且所提出的模块轻量级，可轻松集成到现有基于傅里叶的框架中。

**Conclusion:** 所提出的方法在恢复极端暗图像的细节方面表现出色，并且具有高效性和易集成性。

> **ai_Abstract:** 本研究提出了一种新颖的双阶段方法，用于恢复极端暗图像中的细粒度细节。该方法结合了残差傅里叶引导模块（RFGM）以在频域中恢复光照，以及专门设计的Mamba模块（Patch Mamba和Grad Mamba）来细化纹理和边缘。实验证明，该方法在提高细节恢复能力和效率方面均优于现有技术，并且易于集成。

> **摘要翻译:** 恢复极其黑暗的图像中的细粒度细节仍然是一个挑战，因为结构信息丢失严重且噪声腐蚀。现有的增强方法通常无法保留复杂的细节和清晰的边缘，限制了它们在文本和边缘检测等下游应用中的有效性。为了解决这些不足，我们提出了一种以暗图像细节恢复为中心的有效双阶段方法。在第一阶段，我们引入了一个残差傅里叶引导模块（RFGM），它在频域中有效地恢复了全局光照。RFGM通过残差连接捕获了阶段间和通道间的依赖关系，为高保真频率处理提供了强大的先验知识，同时减轻了来自不可靠先验的误差累积风险。第二阶段采用专门为纹理结构细化设计的互补Mamba模块：（1）Patch Mamba在通道连接的非下采样块上操作，仔细地对像素级相关性进行建模，以在不损失分辨率的情况下增强细粒度细节。（2）Grad Mamba显式地关注高梯度区域，缓解了状态空间模型中的状态衰减，并优先重建清晰的边缘和边界。在多个基准数据集和下游应用上的广泛实验表明，我们的方法在保持效率的同时显著提高了细节恢复性能。至关重要的是，所提出的模块是轻量级的，并且可以以最小的计算开销无缝集成到现有的基于傅里叶的框架中。代码可在https://github.com/bywlzts/RFGM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [708] [Adversarial Attention Perturbations for Large Object Detection Transformers](https://arxiv.org/abs/2508.02987)
> *面向大型对象检测 Transformer 的对抗性注意力扰动*

*Zachary Yahn, Selim Furkan Tekin, Fatih Ilhan, Sihao Hu, Tiansheng Huang, Yichang Xu, Margaret Loper, Ling Liu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 对抗性攻击, Transformer, 目标检测, 注意力机制, AFOG

**Comment:** ICCV 2025

> **TL;DR:** 提出了一种名为 AFOG 的新型对抗性攻击方法，该方法通过扰动注意力机制来攻击基于 Transformer 的目标检测器，并且对 CNN 检测器也有效，在实验中表现出优越的性能和效率。

**AI_Comments:** 该研究提出了一种新颖的对抗性攻击方法 AFOG，专注于 Transformer 检测器的注意力机制，解决了现有方法在 Transformer 检测器上的局限性。AFOG 的架构无关性和统一框架使其具有广泛的应用潜力。该方法通过可学习的注意力机制和有效的损失函数设计，在性能和效率上均取得了显著提升，并得到了大量实验验证，具有较高的学术和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对目标检测的对抗性扰动方法要么局限于攻击基于 CNN 的检测器，要么对基于 Transformer 的检测器效果较弱。

**Method:** 提出了一种名为 AFOG（Attention-Focused Offensive Gradient）的攻击方法，该方法利用可学习的注意力机制将扰动集中在图像的脆弱区域，并通过整合两种特征损失来制定攻击损失，同时进行迭代扰动注入。

**Result:** AFOG 在 COCO 数据集上针对十二种大型检测 Transformer 进行了广泛实验，结果表明该方法比现有攻击方法在 Transformer 和 CNN 检测器上性能提升高达 83%，并且具有更快的速度和更好的不可感知性。

**Conclusion:** AFOG 是一种有效、高效且隐蔽的对抗性扰动方法，能够成功攻击大型目标检测 Transformer，并在实验中证明了其优越性。

> **ai_Abstract:** 本文提出了一种名为 AFOG 的新型对抗性攻击方法，专门用于攻击基于 Transformer 的目标检测器。AFOG 利用可学习的注意力机制，将扰动集中在图像的关键区域，从而有效降低检测器的性能。该方法不仅对 Transformer 检测器有效，也能攻击 CNN 检测器。实验结果表明，AFOG 在 COCO 数据集上取得了比现有方法更高的攻击成功率和效率，同时保持了扰动的视觉不可感知性。

> **摘要翻译:** 对抗性扰动是揭示神经网络漏洞的有用工具。现有的针对目标检测的对抗性扰动方法要么局限于攻击基于卷积神经网络（CNN）的检测器，要么对基于 Transformer 的检测器效果较弱。本文提出了一种针对目标检测 Transformer 的注意力聚焦攻击梯度（AFOG）攻击。AFOG 在设计上与神经网络架构无关，并且可以通过统一的对抗性注意力框架有效攻击大型的基于 Transformer 的目标检测器和传统的基于 CNN 的检测器。本文做出了三项原创性贡献。首先，AFOG 利用一种可学习的注意力机制，将扰动集中在多框检测任务中的脆弱图像区域，与非注意力基线相比，性能提高了 30.6%。其次，AFOG 的攻击损失是通过在迭代注入对抗性扰动的同时，通过可学习的注意力更新整合两种特征损失来制定的。最后，AFOG 是一种高效且隐蔽的对抗性扰动方法。它通过添加策略性生成且视觉上不可察觉的扰动来探测检测 Transformer 的薄弱环节，从而导致经过良好训练的目标检测模型失效。在 COCO 数据集上对十二种大型检测 Transformer 进行的广泛实验证明了 AFOG 的有效性。我们的实证结果还表明，AFOG 在 Transformer 和 CNN 检测器上的表现优于现有攻击方法，性能提升高达 83%，并且具有卓越的速度和不可感知性。代码可在 https://github.com/zacharyyahn/AFOG 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [709] [Neovascularization Segmentation via a Multilateral Interaction-Enhanced Graph Convolutional Network](https://arxiv.org/abs/2508.03197)
> *通过多边交互增强图卷积网络的血管新生分割*

*Tao Chen, Dan Zhang, Da Chen, Huazhu Fu, Kai Jin, Shanshan Wang, Laurent D. Cohen, Yitian Zhao, Quanyong Yi, Jiong Zhang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 脉络膜新生血管, 图卷积网络, OCTA图像分割, 多任务学习, 计算机视觉

**Comment:** 

> **TL;DR:** 本研究提出了MTG-Net，一种用于OCTA图像中脉络膜新生血管（CNV）分割的新型图卷积网络。该网络通过多任务框架和两个图推理模块（MIGR和MRGR）整合区域和血管形态信息，并利用不确定性加权损失处理伪影和噪声。实验证明，MTG-Net在CNV区域和血管分割方面优于现有方法，Dice分数分别为87.21%和88.12%。此外，研究构建了首个公开可用的CNV数据集CNVSeg。

**AI_Comments:** 该研究在CNV分割领域取得了重要进展，不仅提出了创新的MTG-Net模型，解决了现有方法的局限性，还构建了首个公开数据集，为该领域的研究提供了有力支持。模型通过整合多模态信息和利用图推理机制来提升分割精度，尤其是在处理不规则形状和图像伪影方面显示出潜力。然而，未来可以进一步探索模型在不同类型OCTA设备和不同病变阶段的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 脉络膜新生血管（CNV）是湿性年龄相关性黄斑变性（wet AMD）的关键特征，也是导致失明的主要原因。准确分割OCTA图像中的CNV区域和血管对于临床评估至关重要。然而，CNV形状不规则、成像伪影、噪声和边界模糊等挑战限制了分割精度，并且缺乏公开数据集。因此，本研究旨在解决这些挑战，提高CNV分割的准确性。

**Method:** 本研究提出了一个名为MTG-Net的多边交互增强图卷积网络，用于CNV分割。MTG-Net包含一个多任务框架，该框架将图像分解为三个特定任务的特征图，以编码丰富的几何特征。此外，还设计了两个基于图的跨任务模块：多边交互图推理（MIGR）和多边强化图推理（MRGR）。这两个模块通过图机制迭代地推理任务之间的高阶关系，实现任务目标的互补优化。同时，提出了一种不确定性加权损失函数来减轻伪影和噪声对分割精度的影响。研究还构建了首个公开的CNV数据集CNVSeg。

**Result:** 实验结果表明，MTG-Net在CNV分割任务上优于现有方法。具体而言，MTG-Net在区域分割任务上达到了87.21%的Dice分数，在血管分割任务上达到了88.12%的Dice分数。

**Conclusion:** 本研究提出了MTG-Net，一种创新的图卷积网络，通过整合区域和血管形态信息以及利用图机制进行跨任务推理，有效解决了OCTA图像中CNV分割的挑战。所提出的方法在分割精度上优于现有技术，并且构建的CNVSeg数据集为未来的CNV研究提供了宝贵的资源。

> **ai_Abstract:** 本研究针对湿性年龄相关性黄斑变性（wet AMD）中的脉络膜新生血管（CNV）分割问题，提出了一种名为MTG-Net的新型图卷积网络。该网络创新性地结合了区域和血管的形态信息，并通过多任务框架以及多边交互图推理（MIGR）和多边强化图推理（MRGR）两个图模块来增强特征表示和任务间的互补优化。此外，研究还引入了不确定性加权损失函数以提高模型对伪影和噪声的鲁棒性。为推动CNV研究，本研究还构建了首个公开的CNV数据集CNVSeg。实验结果表明，MTG-Net在CNV区域和血管分割方面均取得了优于现有方法的性能。

> **摘要翻译:** 脉络膜新生血管（CNV）是湿性年龄相关性黄斑变性（wet AMD）的一个主要特征，代表着全球失明的首要原因。在临床实践中，由于其微米级分辨率和非侵入性，光学相干断层扫描血管造影（OCTA）常用于研究CNV相关的病理变化。因此，准确分割OCTA图像中的CNV区域和血管对于湿性AMD的临床评估至关重要。然而，由于CNV形状不规则以及投影伪影、噪声和边界模糊等成像限制，存在分割挑战。此外，公开可用数据集的缺乏也限制了CNV的分析。为了应对这些挑战，本文构建了首个公开可用的CNV数据集（CNVSeg），并提出了一种新颖的多边图卷积交互增强CNV分割网络（MTG-Net）。该网络整合了区域和血管的形态信息，并在图域内探索了语义和几何的对偶约束。具体而言，MTG-Net由一个多任务框架和两个基于图的跨任务模块组成：多边交互图推理（MIGR）和多边强化图推理（MRGR）。多任务框架编码了丰富的病灶形状和表面几何特征，将图像解耦为三个特定任务的特征图。MIGR和MRGR通过图机制迭代地推理任务之间的高阶关系，从而实现任务特定目标的互补优化。此外，还提出了一种不确定性加权损失来减轻伪影和噪声对分割精度的影响。实验结果表明，MTG-Net的性能优于现有方法，在区域分割方面达到了87.21%的Dice分数，在血管分割方面达到了88.12%的Dice分数。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [711] [A Scalable Machine Learning Pipeline for Building Footprint Detection in Historical Maps](https://arxiv.org/abs/2508.03564)
> *用于检测历史地图建筑足迹的可扩展机器学习管道*

*Annemarie McCarthy* | **Category: cs.CV, I.4** | **Updated: 2025-08-05**

**Keywords:** 机器学习, 建筑足迹检测, 历史地图, 农村地区, CNN

**Comment:** 15 pages, 11 figures

> **TL;DR:** 该研究提出了一个可扩展且高效的机器学习管道，用于从历史地图中提取农村地区的建筑足迹，通过分层方法解决了传统方法的计算密集型问题，并在实际应用中取得了良好效果。

**AI_Comments:** 该研究在解决历史地图建筑足迹检测的实际问题上取得了显著进展，特别是在处理计算密集型和农村地区数据方面。分层方法的设计有效地提高了效率。然而，对于不同地图投影、质量和年代的鲁棒性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统从历史地图提取建筑足迹的机器学习方法计算密集且主要关注城市地区，难以应用于需要分析广大农村地区的研究，如验证历史人口普查数据或定位废弃定居点。

**Method:** 该研究提出了一种分层机器学习方法：首先使用卷积神经网络（CNN）分类器逐步筛选掉不太可能包含建筑物的地图区域，然后对剩余高概率区域使用CNN分割算法提取建筑特征。

**Result:** 该管道在爱尔兰 Ordnance Survey 历史 25 英寸和 6 英寸地图系列测试区域上进行了验证，证明了其高性能和比传统仅分割方法更高的效率，并成功识别了一个在 1839 年的地图中存在但在 1899 年的地图中消失的定居点。

**Conclusion:** 该研究提出的可扩展机器学习管道能够高效地从历史地图中提取农村地区的建筑足迹，并在历史和考古研究中具有应用潜力。

> **ai_Abstract:** 本研究提出了一种新颖的、可扩展且高效的机器学习管道，用于从历史地图中检测农村地区的建筑足迹。该方法采用分层处理策略，首先利用 CNN 分类器过滤掉非建筑区域，然后利用 CNN 分割算法提取建筑特征，有效解决了传统方法计算量大和难以应用于农村地区的问题。实验结果表明，该管道在性能和效率上均优于传统方法，并成功应用于历史和考古研究，例如识别出可能因大饥荒而被废弃的定居点。

> **摘要翻译:** 历史地图为研究过去的地貌和聚落格局提供了宝贵的视角。尽管以往的研究利用了基于机器学习的技术从历史地图中提取建筑足迹，但这类方法主要集中在城市地区，并且计算量往往很大。这给需要跨越广阔农村地区进行分析的研究问题带来了挑战，例如验证历史人口普查数据或定位废弃的聚落。本文解决了这一局限性，提出了一种可扩展且高效的管道，专门针对建筑分布稀疏的农村地图。所描述的方法采用了一种分层机器学习方法：首先使用卷积神经网络（CNN）分类器逐步滤除不太可能包含建筑物的地图部分，从而显著减少了需要详细分析的区域。然后，对剩余的高概率部分采用CNN分割算法来提取建筑特征。该管道使用 Ordnance Survey Ireland 历史 25 英寸地图系列和 6 英寸地图系列的测试部分进行了验证，证明了其高性能和相比于传统仅分割方法的效率提升。将该技术应用于覆盖同一地理区域的两个地图系列，凸显了其在历史和考古发现方面的潜力。值得注意的是，该管道识别出了一个约有 22 处建筑的定居点，位于 Co. Galway 的 Tully，该定居点出现在 1839 年生产的 6 英寸地图中，但在 1899 年生产的 25 英寸地图中已不存在，这表明它可能在大饥荒时期被废弃。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [712] [TextMaster: A Unified Framework for Realistic Text Editing via Glyph-Style Dual-Control](https://arxiv.org/abs/2410.09879)
> *TextMaster：一种通过字形-风格双重控制实现真实文本编辑的统一框架*

*Zhenyu Yan, Jian Wang, Aoqiang Wang, Yuhan Li, Wenxiang Shang, Ran Lin* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 文本编辑, 字形控制, 风格迁移, 注意力机制, 图像编辑

**Comment:** Accepted to ICCV 2025

> **TL;DR:** TextMaster是一个统一框架，通过结合高分辨率字形信息和注意力机制，实现了高精度、可控风格的文本编辑，解决了现有方法在复杂文本描画准确性和风格可控性方面的不足。

**AI_Comments:** 该研究提出了一种名为TextMaster的统一框架，旨在解决图像编辑中现有文本编辑方法的局限性。通过结合高分辨率字形信息、感知损失、注意力机制和风格注入技术，TextMaster在文本渲染的准确性、布局控制和风格可控性方面取得了显著进展。该方法在处理复杂文本和实现可控风格迁移方面具有创新性，为文本编辑领域带来了重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本编辑方法在复杂文本的描画准确性和生成文本风格的可控性方面存在显著局限，导致人力和物力资源成本高昂。

**Method:** TextMaster通过整合高分辨率标准字形信息和在文本编辑区域应用感知损失来提高文本渲染的准确性和保真度。利用注意力机制计算中间层边界框回归损失，以学习跨不同上下文的文本布局。提出了一种新颖的风格注入技术，实现了可控的风格迁移。

**Result:** TextMaster在文本编辑方面达到了最先进的性能，能够准确编辑不同场景和图像区域的文本，同时保持正确的布局和可控的文本风格。

**Conclusion:** TextMaster通过整合字形信息、感知损失、注意力机制和风格注入技术，有效解决了现有文本编辑方法的局限性，实现了高精度、高保真度且风格可控的文本编辑。

> **ai_Abstract:** TextMaster是一个创新的统一框架，专注于解决图像编辑中的文本编辑难题。该框架通过整合高分辨率字形信息和应用感知损失来提升文本渲染的精度与保真度，同时利用注意力机制优化文本布局，并通过新颖的风格注入技术实现风格的精确控制。实验证明，TextMaster在准确性、布局和风格可控性方面均优于现有方法，为高质量文本编辑提供了有效的解决方案。

> **摘要翻译:** 在图像编辑任务中，高质量的文本编辑能力可以显著降低人力和物力资源的成本。然而，现有方法在处理复杂文本的描画准确性和生成文本风格的可控性方面存在显著局限。为了应对这些挑战，我们提出了TextMaster，一种能够跨不同场景和图像区域准确编辑文本，同时确保正确布局和可控文本风格的解决方案。我们的方法通过整合高分辨率标准字形信息和在文本编辑区域应用感知损失来提高文本渲染的准确性和保真度。此外，我们利用注意力机制计算每个字符的中间层边界框回归损失，使模型能够学习跨不同上下文的文本布局。更进一步，我们提出了一种新颖的风格注入技术，实现了注入文本的可控风格迁移。通过全面的实验，我们证明了我们的方法达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [713] [VPN: Visual Prompt Navigation](https://arxiv.org/abs/2508.01766)
> *视觉提示导航：VPN*

*Shuo Feng, Zihan Wang, Yuchen Li, Rui Kong, Hengyi Cai, Shuaiqiang Wang, Gim Hee Lee, Piji Li, Shuqiang Jiang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉提示导航, 具身代理, 导航范式, 数据集, VPNet

**Comment:** 

> **TL;DR:** 提出视觉提示导航（VPN）范式，使用2D俯视地图上的视觉提示轨迹代替自然语言来指导具身代理导航，减少歧义并提高效率。构建了R2R-VP和R2R-CE-VP数据集，并提出了VPNet模型及数据增强策略。

**AI_Comments:** 该研究提出了一种创新的导航范式，通过视觉提示替代自然语言，解决了现有方法的痛点。数据集和模型的构建为该领域的研究提供了基础。然而，该方法在复杂三维环境中的泛化能力和鲁棒性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言在指导具身代理导航时存在歧义和冗余问题，影响了在复杂环境中的导航效率。

**Method:** 提出视觉提示导航（VPN）范式，使用用户在2D俯视地图上标记的视觉导航轨迹来指导代理导航。构建了R2R-VP和R2R-CE-VP数据集，并提出了用于处理VPN任务的VPNet模型，结合了视图级和轨迹级数据增强策略。

**Result:** 实验评估了视觉提示形式、俯视地图格式和数据增强策略对视觉提示导航性能的影响。

**Conclusion:** 视觉提示导航（VPN）范式能够有效克服自然语言指导的局限性，通过直观、空间定位明确的视觉提示，提高具身代理在复杂环境中的导航效率和用户友好性。

> **ai_Abstract:** 本研究提出了一种名为视觉提示导航（VPN）的新范式，旨在解决自然语言在指导具身代理导航时存在的歧义和冗长问题。VPN利用用户在2D俯视地图上标记的视觉轨迹作为导航指令，提供更直观、空间定位更明确的引导。研究人员构建了新的R2R-VP和R2R-CE-VP数据集，并提出了名为VPNet的基线模型，结合了视图级和轨迹级数据增强技术，以提升导航性能。实验结果表明，VPN在提高导航效率和用户友好性方面具有潜力。

> **摘要翻译:** 虽然自然语言常被用来指导具身代理，但语言固有的歧义性和冗长性常常阻碍语言引导导航在复杂环境中的有效性。为此，我们提出了视觉提示导航（VPN），一种新颖的范式，仅使用用户在2D俯视地图中提供的视觉提示来指导代理导航。该视觉提示主要侧重于在场景的俯视图中标记视觉导航轨迹，提供直观且空间定位明确的指导，而无需依赖语言指令。它对非专业用户更友好，并减少了解释性歧义。我们在离散和连续导航设置中都构建了VPN任务，通过扩展现有的R2R和R2R-CE片段，并加入相应的视觉提示，构建了两个新的数据集R2R-VP和R2R-CE-VP。此外，我们引入了VPNet，一个专门用于处理VPN任务的基线网络，并采用了两种数据增强策略：视图级增强（改变初始航向和提示方向）和轨迹级增强（纳入大规模3D场景的多样化轨迹），以提高导航性能。广泛的实验评估了视觉提示形式、俯视地图格式和数据增强策略如何影响视觉提示导航的性能。代码可在https://github.com/farlit/VPN获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [Live Demonstration: Neuromorphic Radar for Gesture Recognition](https://arxiv.org/abs/2508.03324)
> *现场演示：用于手势识别的神经形态雷达*

*Satyapreet Singh Yadav, Chandra Sekhar Seelamantula, Chetan Singh Thakur* | **Category: cs.CV, cs.ET, cs.NE, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 神经形态雷达,手势识别,事件驱动,低功耗,异步sigma-delta编码

**Comment:** Neuromorphic Radar, Hand Gesture Recognition, Event-Driven,
  Sigma-Delta Encoding, Sparse Representation. Presented in ICASSP 2025 at
  Hyderabad, India

> **TL;DR:** 该研究提出了一种基于事件驱动的神经形态雷达框架，用于实时、低功耗的手势识别。该系统使用24 GHz多普勒雷达和神经形态采样器，将雷达信号转换为稀疏的事件表示，并直接由微控制器上的轻量级神经网络处理，实现了低延迟推理。与传统方法不同，该系统仅在检测到有意义的运动时激活，从而显著降低了功耗和计算开销。在包含五种手势的数据集上，该系统实现了超过85%的实时准确率，并且是首个将生物启发的异步sigma-delta编码和事件驱动处理框架应用于雷达手势识别的研究。

**AI_Comments:** 这项工作在雷达手势识别领域具有重要意义，因为它引入了一种受生物启发的、事件驱动的方法，显著提高了能源效率和实时性能。该研究首次将异步sigma-delta编码和脉冲序列处理相结合应用于雷达手势识别，为低功耗嵌入式系统中的新兴传感技术开辟了新的途径。然而，该系统在不同环境条件下的鲁棒性以及对更复杂手势集和交互的扩展性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统雷达手势识别方法需要持续采样和处理数据，导致内存、功耗和计算开销较高。本研究旨在开发一种更高效的系统，通过模仿生物传感机制，仅在检测到有意义的运动时激活，从而降低资源消耗。

**Method:** 本研究提出了一种神经形态雷达框架，该框架包含一个24 GHz多普勒雷达前端和一个定制的神经形态采样器。该采样器采用异步sigma-delta编码，将中频（IF）信号转换为稀疏的脉冲序列表示。这些脉冲序列随后被直接输入到部署在Cortex-M0微控制器上的轻量级神经网络中进行处理，无需进行频谱图重建。

**Result:** 在包含七个用户收集的五种手势的数据集上，该系统实现了超过85%的实时准确率。

**Conclusion:** 本研究成功开发了一种基于事件驱动的神经形态雷达框架，用于实时、低功耗的手势识别。该方法通过模仿生物传感机制，显著降低了功耗和计算开销，并达到了很高的准确率，是雷达手势识别领域的创新性工作。

> **ai_Abstract:** 本研究提出了一种新颖的神经形态雷达框架，用于实现低功耗、实时的手势识别。该系统利用24 GHz多普勒雷达和事件驱动的神经形态采样器，将雷达信号转换为稀疏的脉冲序列，并由微控制器上的轻量级神经网络直接处理，从而无需频谱图重建即可实现低延迟推理。与传统方法相比，该系统仅在检测到运动时激活，大大降低了功耗和计算需求，并在实验中达到了超过85%的准确率。

> **摘要翻译:** 我们提出了一种神经形态雷达框架，用于通过受生物传感启发的事件驱动架构进行实时、低功耗的手势识别（HGR）。我们的系统包含一个24 GHz的多普勒雷达前端和一个定制的神经形态采样器，该采样器通过异步sigma-delta编码将中频（IF）信号转换为稀疏的脉冲序列表示。这些事件直接由部署在Cortex-M0微控制器上的轻量级神经网络处理，无需频谱图重建即可实现低延迟推理。与传统的雷达HGR流程不同，我们的架构仅在检测到有意义的运动时激活，从而显著降低了内存、功耗和计算开销。在从七个用户收集的五种手势的数据集上进行评估，我们的系统实现了>85%的实时准确率。据我们所知，这是首次将生物启发的异步sigma-delta编码和事件驱动处理框架应用于雷达HGR的研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [723] [Spatial Imputation Drives Cross-Domain Alignment for EEG Classification](https://arxiv.org/abs/2508.03437)
> *空间插补驱动跨域对齐以实现脑电图分类*

*Hongjun Liu, Chao Yao, Yalan Zhang, Xiaokun wang, Xiaojuan Ban* | **Category: cs.CV, cs.AI, 62M10, I.5.1; J.3** | **Updated: 2025-08-05**

**Keywords:** 脑电图分类, 跨域对齐, 空间插补, 自监督学习, 数据分布偏移

**Comment:** ACMMM 2025 poster

> **TL;DR:** 该研究提出了一种名为IMAC的框架，通过空间时间序列插补来解决跨域脑电图（EEG）分类中的数据分布偏移问题。IMAC通过统一电极布局、引入通道依赖掩码和重建任务来对齐跨域EEG数据，并在推理时利用插补器实现稳健的信号对齐。该框架还分别处理EEG信号的时空信息，降低了计算复杂度。实验结果表明，IMAC在各种跨域场景下均表现优越，准确率达到最先进水平，并且在模拟和真实分布偏移下表现出很强的鲁棒性。

**AI_Comments:** 该研究提出的IMAC框架在解决跨域EEG分类中的数据分布偏移问题上具有创新性，通过将对齐问题转化为空间插补任务，并引入通道依赖掩码和解耦的时空信息建模，取得了优越的性能和鲁棒性。然而，需要进一步研究其在处理更复杂或极端分布偏移情况下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 脑电图（EEG）信号分类面临数据分布偏移的挑战，这源于不同领域之间异构的电极配置、采集协议和硬件差异。

**Method:** 提出了一种名为IMAC的新型通道依赖掩码和插补自监督框架。该框架将跨域EEG数据对齐的挑战转化为空间时间序列插补任务。具体方法包括：1. 使用3D到2D位置统一映射策略标准化不同电极布局，建立统一的空间表示。2. 引入了通道依赖掩码和重建任务，将其构建为低到高分辨率的EEG空间插补问题，模拟通道缺失和时间不稳定性等跨域变异。3. 采用解耦结构分别建模EEG信号的时空信息。

**Result:** 在10个公开的EEG数据集上的综合评估表明，IMAC在跨主体和跨中心验证场景中均取得了最先进的分类准确率。IMAC在模拟和真实世界的分布偏移下表现出很强的鲁棒性，在完整性评分方面超越基线方法高达35%，同时保持了稳定的分类准确率。

**Conclusion:** IMAC框架通过空间插补实现了有效的跨域EEG数据对齐，解决了数据分布偏移问题，并在各种评估场景中展现了优越的性能和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为IMAC的自监督框架，用于解决脑电图（EEG）分类中的跨域数据分布偏移问题。IMAC通过空间时间序列插补方法，利用通道依赖掩码和重建任务来对齐不同域的EEG数据，并采用解耦结构分别处理时空信息。实验证明，IMAC在多个数据集上实现了最先进的分类性能，并对模拟和实际的分布偏移具有良好的鲁棒性。

> **摘要翻译:** 脑电图（EEG）信号分类由于领域间异构的电极配置、采集协议和硬件差异导致的数据分布偏移而面临严峻挑战。本文介绍了一种新颖的通道依赖掩码和插补自监督框架IMAC，它将跨域EEG数据偏移的对齐问题构建为空间时间序列插补任务。为了解决跨域场景中的异构电极配置，IMAC首先使用3D到2D位置统一映射策略来标准化不同的电极布局，建立统一的空间表示。与以往基于掩码的自监督表示学习方法不同，IMAC引入了时空信号对齐。这包括构建一个通道依赖掩码和重建任务，该任务被构建为低到高分辨率的EEG空间插补问题。因此，该方法模拟了通道缺失和时间不稳定性等跨域变异，从而使模型能够在推理过程中利用所提出的插补器来实现稳健的信号对齐。此外，IMAC采用了一种解耦结构，分别对EEG信号的时空信息进行建模，降低了计算复杂度，同时提高了灵活性和适应性。在10个公开可用的EEG数据集上的综合评估表明，IMAC在跨主体和跨中心验证场景中均取得了优越的性能，取得了最先进的分类准确率。值得注意的是，IMAC在模拟和真实世界分布偏移下均表现出很强的鲁棒性，在完整性评分方面超越基线方法高达35%，同时保持了稳定的分类准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [726] [After the Party: Navigating the Mapping From Color to Ambient Lighting](https://arxiv.org/abs/2508.02168)
> *派对之后：导航从颜色到环境光照的映射*

*Florin-Alexandru Vasluianu, Tim Seizinger, Zongwei Wu, Radu Timofte* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 图像恢复, 彩色光照, 环境归一化, Retinex, CL3AN

**Comment:** an 8-pages manuscript, 9 figures, 3 tables

> **TL;DR:** 该研究提出了CL3AN数据集和一种新的学习框架，用于在多色光源下恢复图像到环境归一化状态，解决了现有方法在处理复杂光照问题上的不足。

**AI_Comments:** 该研究在处理复杂光照条件下的图像恢复方面取得了重要进展，通过引入大规模数据集和创新的学习框架，有效解决了现有方法的局限性。其借鉴Retinex模型的思路具有启发性，并且在实际应用中展现了良好的鲁棒性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理复杂光照（如彩色光源、遮挡、多材质交互）时过于简化，通常假设单一光源或均匀白光，未能解决这些复杂性。

**Method:** 提出了一种新的学习框架，利用显式的色度-亮度分量引导，借鉴Retinex模型的原理，以实现光照与反射率的分解。

**Result:** 在现有基准和新数据集上的广泛评估表明，该方法在非均匀彩色光照和特定材质反射率变化下具有增强的鲁棒性，同时保持了高度竞争力的计算成本。现有方法在处理复杂光照时会产生光照不一致、纹理泄露和颜色失真等瑕疵。

**Conclusion:** 所提出的方法通过显式的色度-亮度分量引导，有效地解决了在多色光源下图像恢复的问题，并在复杂光照条件下表现出优越的性能。

> **ai_Abstract:** 本研究介绍了CL3AN，一个用于处理多色光源下图像恢复问题的大规模数据集，并提出了一种新颖的学习框架。该框架受Retinex模型启发，利用色度-亮度分量引导来分解光照和反射率，解决了现有方法在复杂光照条件下产生的瑕疵问题，并在各种挑战性场景中展示了优越的鲁棒性和效率。

> **摘要翻译:** 实际场景中的光照inherently复杂，涉及彩色光源、遮挡以及产生复杂反射率和阴影效果的各种材质交互。然而，现有方法通常通过假设单一光源或均匀、白平衡的光照来过度简化这一挑战，使得许多复杂性未得到解决。在本研究中，我们引入了CL3AN，这是同类首个大规模、高分辨率的数据集，旨在促进从多色光源捕获的图像恢复到其环境归一化对应物。通过基准测试，我们发现领先的方法由于其精确分离光照与反射率的能力有限，常常会产生瑕疵，例如光照不一致、纹理泄露和颜色失真。基于这一见解，我们通过一种新颖的学习框架实现了这种期望的分解，该框架利用显式的色度-亮度分量引导，借鉴了Retinex模型的原理。在现有基准和我们数据集上的广泛评估表明了我们方法的有效性，展示了在非均匀彩色光照和材质特定反射率变化下的增强鲁棒性，同时保持了高度竞争力的计算成本。基准、代码和模型可在www.github.com/fvasluianu97/RLN2获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [737] [Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration](https://arxiv.org/abs/2508.03337)
> *更少即是更多：通过自适应帧剪枝和语义图集成实现的高效视频问答*

*Shaoguang Wang, Jianxiang He, Yijie Xu, Ziyang Chen, Weiyu Guo, Hui Xiong* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视频问答, 自适应帧剪枝, 令牌效率, 语义图, 多模态大语言模型

**Comment:** Corresponding authors: Weiyu Guo, Hui Xiong

> **TL;DR:** 该研究提出了一种名为自适应帧剪枝（AFP）的新方法，用于解决视频问答（Video-QA）中处理大量视频帧导致的高令牌成本问题。AFP通过聚类算法去除冗余帧，并引入轻量级语义图来弥补信息损失。实验表明，该方法能显著减少所需帧数和令牌数量，同时提高准确性。

**AI_Comments:** 这项研究通过引入自适应帧剪枝（AFP）和语义图集成，有效地解决了视频问答中因处理大量视频帧而带来的高令牌成本和性能下降问题，展示了“少即是多”的优化潜力。其创新性在于利用聚类算法去除冗余信息，并通过轻量级语义图补充关键上下文，实现了效率和准确性的显著提升。该方法在多个基准测试上的优异表现证明了其有效性和广泛适用性。

<details>
  <summary>Details</summary>

**Motivation:** 视频问答（Video-QA）应用受限于处理视频帧的高令牌成本，而现有关键帧选择方法仍存在时间冗余（视觉回声），过多的帧可能导致性能下降。

**Method:** 提出自适应帧剪枝（AFP）方法，在ResNet-50和CLIP特征空间上使用自适应分层聚类算法识别并合并视觉回声。为弥补信息损失，引入基于文本的语义图提供关键上下文。

**Result:** 在LongVideoBench和VideoMME基准测试中，该方法将所需帧数减少高达86.9%，总输入令牌减少高达83.2%，并且在提供简洁高质量帧的同时，准确性也常优于使用更多帧的基线。

**Conclusion:** 自适应帧剪枝（AFP）结合语义图能够有效解决视频问答中的高令牌成本和冗余帧问题，实现效率和准确性的双重提升。

> **ai_Abstract:** 该研究提出了一种名为自适应帧剪枝（AFP）的新颖后处理方法，用于解决视频问答（Video-QA）中的高令牌成本问题。AFP通过在融合的ResNet-50和CLIP特征空间上应用自适应分层聚类来识别和合并冗余帧（“视觉回声”），从而智能地剪枝关键帧。为了弥补信息损失，该方法还引入了一个轻量级的文本语义图来提供必要的上下文。在LongVideoBench和VideoMME基准测试上的实验表明，该方法能大幅减少所需帧数（高达86.9%）和令牌数量（高达83.2%），同时提高准确性，解决了上下文稀释和时间冗余问题。

> **摘要翻译:** 多模态大语言模型（MLLM）在视频问答（Video-QA）中的实际应用受到处理大量视频帧的高令牌成本的严重阻碍。虽然增加采样帧数是一种常用策略，但我们观察到一种“少即是多”的现象，即过多的帧由于上下文稀释而可能适得其反地降低性能。同时，最先进的关键帧选择方法虽然有效，但仍然产生显著的时间冗余，我们称之为“视觉回声”。为了应对这些双重挑战，我们提出了自适应帧剪枝（AFP），一种智能地剪枝所选关键帧的新型后处理方法。AFP在融合的ResNet-50和CLIP特征空间上采用自适应分层聚类算法，以识别和合并这些回声成单一代表。为了弥补信息损失，我们引入了一个轻量级的、基于文本的语义图，以最小的令牌开销提供关键上下文。我们在LongVideoBench和VideoMME基准测试中，跨多个领先的MLLM进行了广泛的实验，我们的完整方法展示了所需帧数高达86.9%和总输入令牌高达83.2%的急剧减少。至关重要的是，通过提供一组简洁、高质量的帧，我们的方法不仅提高了效率，而且在准确性方面通常优于使用更多帧的基线。代码将在发表后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [740] [CMIC: Content-Adaptive Mamba for Learned Image Compression](https://arxiv.org/abs/2508.02192)
> *CMIC：用于学习图像压缩的内容自适应 Mamba*

*Yunuo Chen, Zezheng Lyu, Bing He, Hongwei Hu, Qi Wang, Yuan Tian, Li Song, Wenjun Zhang, Guo Lu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 学习图像压缩, Mamba, 内容自适应, 率失真性能, 状态空间模型

**Comment:** 

> **TL;DR:** CMIC是一种改进的Mamba模型，通过内容感知重新组织和全局先验来提高图像压缩的效率和性能。

**AI_Comments:** 该研究提出了一种新颖的内容自适应 Mamba 架构（CAM），并成功将其应用于学习图像压缩（LIC）领域。通过解决 Mamba 模型在内容依赖性捕捉方面的局限性，CMIC 模型在率失真性能上取得了显著的提升，显示了该方法在图像压缩领域的潜力和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Mamba模型在学习图像压缩时是内容无关的，其固定的选择性扫描限制了其利用内容依赖性的能力。

**Method:** 提出内容自适应Mamba (CAM)，它通过内容感知标记重组（基于内容相似性聚类和重新排序标记）和全局先验（通过提示词典整合到SSM）来解决Mamba的局限性。CMIC模型利用CAM实现了高性能。

**Result:** CMIC模型在Kodak、Tecnick和CLIC基准测试上，BD率分别优于VTM-21.0的-15.91%、-21.34%和-17.58%，达到了最先进的率失真性能。

**Conclusion:** CMIC通过内容自适应Mamba在率失真性能上取得了最先进的成果，证明了其在学习图像压缩方面的有效性。

> **ai_Abstract:** CMIC（Content-Adaptive Mamba for Learned Image Compression）是一种新的学习图像压缩模型，它引入了内容自适应 Mamba（CAM）。CAM 通过内容感知标记重组和全局先验整合，解决了标准 Mamba 模型在处理图像内容依赖性方面的不足，实现了更优的率失真性能，并在多个基准测试中超越了现有技术。

> **摘要翻译:** 最近的学习图像压缩（LIC）利用了 Mamba 风格的状态空间模型（SSM），以线性的复杂度实现了全局感受野。然而，标准的 Mamba 是内容无关的，依赖于固定的、预定义的选择性扫描，这限制了它动态地充分利用内容依赖性的能力。我们引入了内容自适应 Mamba（CAM），一种动态 SSM，解决了两个关键限制。首先，它采用了内容感知标记重组，根据内容相似性对标记进行聚类和重新排序，优先考虑特征空间中的邻近性而非欧几里得空间。其次，它通过提示词典将全局先验整合到 SSM 中，有效缓解了 Mamba 标记交互中的严格因果关系和长程衰减。这些创新使 CAM 能够在保持计算效率的同时更好地捕捉全局依赖性。利用 CAM，我们的基于内容自适应 Mamba 的 LIC 模型（CMIC）实现了最先进的率失真性能，在 Kodak、Tecnick 和 CLIC 基准测试上分别比 VTM-21.0 提高了 -15.91%、-21.34% 和 -17.58% 的 BD 率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [742] [Attack Anything: Blind DNNs via Universal Background Adversarial Attack](https://arxiv.org/abs/2409.00029)
> *攻击一切：通过通用背景对抗性攻击实现盲DNN*

*Jiawei Lian, Shaohui Mei, Xiaofei Wang, Yi Wang, Lefan Wang, Yingjie Lu, Mingyang Ma, Lap-Pui Chau* | **Category: cs.CV, cs.CR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 背景对抗性攻击, 深度神经网络, 通用攻击, 数字攻击, 物理攻击

**Comment:** 

> **TL;DR:** 该研究提出了一种创新的背景对抗性攻击框架，可以在数字和物理领域攻击任何目标，无需改变目标本身。该方法通过迭代优化解决问题，并提供理论收敛性证明。通过集成策略和改进的平滑约束，增强了攻击效果和迁移性。实验证明了该方法的有效性，并揭示了背景变化对DNN鲁棒性的重要影响。

**AI_Comments:** 这项研究提出了一个新颖的攻击范式，将注意力从目标对象转移到背景，这对于理解和防御DNN的鲁棒性具有重要意义。其“攻击任何东西”的通用性和跨域（数字/物理）能力是该研究的主要亮点。然而，该方法在实际应用中的可行性和潜在的伦理影响需要进一步探讨。理论证明的“温和但充分的条件”也值得深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注对目标对象或图像本身的扰动攻击，而本研究旨在探索一种新的攻击方式——背景对抗性攻击，即在不干扰目标对象的情况下，通过改变背景来攻击深度神经网络（DNN），并验证其在数字和物理域的有效性和泛化能力。

**Method:** 将背景对抗性攻击视为一个迭代优化问题，类似于DNN的学习过程，并提供了理论上的收敛性证明。此外，提出了一种新的集成策略来增强攻击效果和迁移性，并引入了一种改进的平滑约束，以无缝集成扰动。

**Result:** 在数字和物理领域进行了广泛而严格的实验，涵盖了各种对象、模型和任务，证明了所提出方法的“攻击一切”的有效性。研究结果表明，背景变化在DNN的鲁棒性和可靠性方面起着比以往认识到的更重要的作用，突显了人类视觉和机器视觉在理解背景变化方面的显著差异。

**Conclusion:** 该研究提出的背景对抗性攻击框架在数字和物理领域均表现出有效性，能够攻击各种目标、模型和任务。研究结果强调了背景变化对DNN性能的重要性，并对DNN的鲁棒性和可靠性提出了重新评估的必要性。

> **ai_Abstract:** 本研究提出了一种名为“攻击任何东西”的通用背景对抗性攻击框架，该框架能在数字和物理领域通过改变背景来攻击DNN，而无需干扰目标对象。该方法将攻击视为迭代优化问题，并提供理论收敛性证明，同时通过集成策略和改进的平滑约束增强攻击效果和迁移性。实验证明了该方法的有效性，并揭示了背景变化对DNN鲁棒性的重要影响。

> **摘要翻译:** 众所周知，深度神经网络（DNN）容易受到对抗性扰动的攻击。现有研究主要集中在通过破坏目标对象（物理攻击）或图像（数字攻击）来进行攻击，这在攻击有效性方面是直观上可接受和可理解的。相比之下，我们的重点是在数字和物理领域进行背景对抗性攻击，而不会对目标对象本身造成任何干扰。具体来说，我们提出了一种有效的背景对抗性攻击框架，可以“攻击任何东西”，从而使攻击效果能够很好地泛化到各种对象、模型和任务。在技术上，我们将背景对抗性攻击视为一个迭代优化问题，类似于DNN的学习过程。此外，我们在满足一组温和但充分的条件下，对其收敛性进行了理论证明。为了增强攻击效果和迁移性，我们提出了一种针对对抗性扰动量身定制的新型集成策略，并引入了一种改进的平滑约束，用于集成扰动的无缝连接。我们在数字和物理领域进行了广泛而严格的实验，涵盖了各种对象、模型和任务，证明了所提出方法“攻击任何东西”的有效性。研究结果证实了人类视觉和机器视觉在背景变化价值上的显著差异，这些背景变化的作用远比以前认识到的更重要，因此有必要重新评估DNN的鲁棒性和可靠性。代码将在https://github.com/JiaweiLian/Attack_Anything 公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [744] [SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks](https://arxiv.org/abs/2508.03566)
> *SAM2-UNeXT：改进高分辨率基线以适应基础模型到下游分割任务*

*Xinyu Xiong, Zihuang Wu, Lei Zhang, Lei Lu, Ming Li, Guanbin Li* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** SAM2-UNeXT, 分割, 基础模型, DINOv2, 图像分割

**Comment:** Technical Report

> **TL;DR:** SAM2-UNeXT 是一个改进的框架，通过集成 DINOv2 编码器来增强 SAM2 的表示能力，并采用双分辨率策略和密集连接层，无需复杂的解码器即可实现更准确的分割。

**AI_Comments:** 该研究提出了一种新颖的 SAM2-UNeXT 框架，通过集成 DINOv2 编码器和采用双分辨率策略，有效提升了 SAM 模型在下游分割任务中的性能。其创新之处在于无需复杂的解码器设计即可实现高精度分割，并验证了其在多种分割任务上的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究强调了 SAM 模型在下游任务中的应用潜力，但构建更强大、更通用的编码器以进一步提升性能仍是一个开放性挑战。

**Method:** 提出 SAM2-UNeXT 框架，该框架基于 SAM2-UNeT 的核心思想，通过集成辅助 DINOv2 编码器来扩展 SAM2 的表示能力，并采用双分辨率策略和密集连接层。

**Result:** 在四个基准测试（二值图像分割、伪装目标检测、海洋生物分割和遥感显着性检测）上进行了广泛的实验，结果表明 SAM2-UNeXT 的性能优于现有方法。

**Conclusion:** SAM2-UNeXT 通过集成 DINOv2 编码器、双分辨率策略和密集连接层，在不依赖复杂解码器设计的情况下，实现了更准确的分割，并在多个分割任务上取得了优越的性能。

> **ai_Abstract:** SAM2-UNeXT 是一个新颖的框架，通过结合 SAM2-UNeT 的原理和 DINOv2 编码器，提升了基础模型在下游分割任务中的性能。该框架采用双分辨率和密集连接层，简化了模型结构，提高了分割精度，并在多个基准测试中表现出色。

> **摘要翻译:** 近期研究强调了适应分割任何模型（SAM）在各种下游任务中的潜力。然而，构建更强大、更通用的编码器以进一步提升性能仍然是一个开放的挑战。在这项工作中，我们提出了 SAM2-UNeXT，一个先进的框架，它建立在 SAM2-UNeT 的核心原理之上，通过集成辅助 DINOv2 编码器来扩展 SAM2 的表示能力。通过采用双分辨率策略和密集连接层，我们的方法能够以简单的架构实现更准确的分割，从而放宽了对复杂解码器设计的需求。在四个基准测试上进行的广泛实验，包括二值图像分割、伪装目标检测、海洋生物分割和遥感显着性检测，证明了我们提出的方法的优越性能。代码可在 https://github.com/WZH0120/SAM2-UNeXT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [748] [Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models](https://arxiv.org/abs/2508.03006)
> *预见其未发：基于扩散的文本到图像模型的生成中不安全内容检测*

*Fan Yang, Yihao Huang, Jiayi Zhu, Ling Shi, Geguang Pu, Jin Song Dong, Kailong Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 文本到图像, NSFW检测, 生成中检测, 预测噪声

**Comment:** 8 pages

> **TL;DR:** 该研究提出了一种名为IGD的新方法，利用扩散过程中预测的噪声来检测不安全内容，在七个类别上平均准确率达到91.32%，优于基线方法。

**AI_Comments:** 该研究提出了一种创新的NSFW内容检测方法，将检测点从生成前/后移至生成中，利用了扩散模型内部的预测噪声信号，这是一种新颖且有潜力的研究方向。其准确率较高，并优于多种基线方法，显示了其实用性。然而，该方法对计算资源的要求以及在不同扩散模型上的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法侧重于生成前过滤提示或生成后审核图像，而忽略了扩散模型的生成中阶段，而该阶段可能产生不安全内容。

**Method:** 提出了一种名为In-Generation Detection (IGD) 的方法，该方法利用扩散过程中预测的噪声作为内部信号来识别不安全内容。

**Result:** IGD方法在七个不安全内容类别上实现了91.32%的平均检测准确率，优于七种基线方法。

**Conclusion:** IGD是一种简单有效的方法，可以利用扩散过程中的预测噪声来检测不安全内容，为解决扩散模型滥用问题提供了新的途径。

> **ai_Abstract:** 本研究提出了一种名为“生成中检测”（IGD）的新方法，用于检测扩散文本到图像模型在生成过程中产生的不安全内容（NSFW）。IGD利用扩散过程中预测的噪声作为信号，能够区分NSFW和良性提示，即使在对抗性提示下也能有效工作。实验证明，IGD在七个NSFW类别上的平均检测准确率为91.32%，优于现有方法。

> **摘要翻译:** 基于扩散的文本到图像（T2I）模型能够生成高质量的图像，但也带来了重大的滥用风险，特别是在生成不安全内容（NSFW）方面。虽然先前的检测方法侧重于在生成前过滤提示或在生成后审核图像，但扩散模型的生成中阶段在NSFW检测方面仍未得到充分探索。在本研究中，我们提出了一种简单而有效的方法——生成中检测（IGD），该方法利用扩散过程中预测的噪声作为内部信号来识别NSFW内容。这种方法的动机是初步研究表明，即使在提示经过对抗性设计的情况下，预测的噪声也可能捕捉到区分NSFW和良性提示的语义线索。在七个NSFW类别上进行的实验表明，IGD在处理朴素和对抗性NSFW提示时，平均检测准确率达到了91.32%，优于七种基线方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [749] [AlignCAT: Visual-Linguistic Alignment of Category and Attributefor Weakly Supervised Visual Grounding](https://arxiv.org/abs/2508.03201)
> *AlignCAT：类别和属性的视觉语言对齐用于弱监督视觉基础*

*Yidan Wang, Chenyi Zhuang, Wutao Liu, Pan Gao, Nicu Sebe* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉基础, 弱监督学习, 跨模态推理, 类别对齐, 属性对齐

**Comment:** 

> **TL;DR:** AlignCAT是一种新的查询式语义匹配框架，用于解决弱监督视觉基础中的类别和属性歧义问题，通过粗粒度和细粒度对齐模块来提高视觉语言一致性，并在三个基准测试中优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的框架AlignCAT，通过引入粗粒度和细粒度对齐模块来解决弱监督视觉基础中的关键挑战，即类别和属性的歧义性。该方法通过增强跨模态推理和利用语言线索，有效地提高了视觉语言对齐的准确性。实验结果表明，AlignCAT在多个标准数据集上表现出色，优于现有方法，证明了其有效性和实用性。代码的开源也为后续研究提供了便利。

<details>
  <summary>Details</summary>

**Motivation:** 现有弱监督视觉基础方法缺乏强大的跨模态推理能力，难以区分文本表达中的细微语义差异，这源于类别和属性的歧义性。

**Method:** 提出了一种名为AlignCAT的新型查询式语义匹配框架，包含一个粗粒度对齐模块（利用类别信息和全局上下文）和一个细粒度对齐模块（利用描述信息和词级文本特征），以增强视觉语言对齐和属性一致性，并通过对比学习逐步过滤错误的视觉查询。

**Result:** 在RefCOCO、RefCOCO+和RefCOCOg三个数据集上进行了广泛的实验，结果表明AlignCAT在两个视觉基础任务上优于现有的弱监督方法。

**Conclusion:** AlignCAT通过利用语言线索，逐步过滤错误的视觉查询并提高对比学习效率，有效解决了弱监督视觉基础中的类别和属性歧义问题，并在多个基准测试中取得了优越的性能。

> **ai_Abstract:** AlignCAT是一种用于弱监督视觉基础的新型框架，通过粗粒度（类别和全局上下文）和细粒度（属性和词级特征）的对齐模块来解决类别和属性歧义问题，从而增强视觉语言对齐，并在多个基准测试中取得了优越的性能。

> **摘要翻译:** 弱监督视觉基础（VG）旨在根据文本描述定位图像中的对象。尽管取得了显著进展，但现有方法缺乏强大的跨模态推理能力，难以区分文本表达中的细微语义差异，这源于类别和属性的歧义性。为了解决这些挑战，我们引入了AlignCAT，这是一种用于弱监督VG的新型查询式语义匹配框架。为了增强视觉语言对齐，我们提出了一个粗粒度对齐模块，它利用类别信息和全局上下文，有效地减轻了类别不一致对象带来的干扰。随后，一个细粒度对齐模块利用描述信息并捕获词级文本特征，以实现属性一致性。通过充分利用语言线索，我们提出的AlignCAT逐步过滤掉错误的视觉查询，并提高了对比学习的效率。在三个VG基准测试，即RefCOCO、RefCOCO+和RefCOCOg上进行的广泛实验，验证了AlignCAT在两个VG任务上优于现有弱监督方法的性能。我们的代码可在：https://github.com/I2-Multimedia-Lab/AlignCAT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [752] [Adaptive Augmentation Policy Optimization with LLM Feedback](https://arxiv.org/abs/2410.13453)
> *自适应增强策略优化与大语言模型反馈*

*Ant Duru, Alptekin Temizel* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 数据增强,大语言模型,策略优化,自适应学习,深度学习

**Comment:** 9 pages, 2 algorithms, 2 tables, submitted for consideration to 2025
  International Conference on Machine Vision

> **TL;DR:** 本研究提出了一种使用大语言模型（LLM）反馈来优化数据增强策略的方法，通过迭代调整和自适应策略，在不完全重新训练模型的情况下提高性能，并在图像分类任务中取得了优于传统方法的准确性提升。

**AI_Comments:** 该研究将LLM的强大上下文理解和推理能力应用于数据增强策略的优化，解决了传统方法计算成本高和泛化性差的问题。通过在训练过程中进行自适应调整，该方法有望在实际应用中显著提升模型的性能和效率。然而，LLM的引入可能带来额外的计算开销和对LLM本身的依赖性，这可能是未来研究需要考虑的方面。

<details>
  <summary>Details</summary>

**Motivation:** 传统的数据增强策略依赖手动设计、随机采样或自动化搜索，但这些方法计算成本高且针对特定数据集。本研究旨在提出一种更有效、计算成本更低的数据增强优化策略。

**Method:** 提出了一种利用大语言模型（LLM）反馈来优化数据增强策略的方法，包括（1）LLM引导的增强策略优化，迭代地优化LLM选择的增强策略；（2）自适应LLM引导的增强策略优化，在每次迭代中根据性能指标调整策略。该方法利用LLM的上下文知识，根据数据集特性、模型架构和训练性能动态选择增强变换。

**Result:** 在特定领域的图像分类数据集上，与传统方法相比，该方法一致地提高了准确性。

**Conclusion:** 本研究提出了一种新颖的、基于LLM反馈的自适应数据增强优化策略，该策略能够根据模型性能和数据集特性动态调整增强策略，从而在降低计算成本的同时提高模型性能，并在图像分类任务中展现出优越性。

> **ai_Abstract:** 本研究提出了一种新颖的、基于大语言模型（LLM）反馈的自适应数据增强策略优化方法。该方法能够根据数据集特性、模型架构和训练性能动态选择和调整增强变换，无需完全重新训练模型即可减少计算成本并提高性能。实验结果表明，该方法在特定领域的图像分类任务上优于传统方法。

> **摘要翻译:** 数据增强是深度学习流水线的一个关键组成部分，通过增加数据集的多样性来增强模型的泛化能力。传统的数据增强策略依赖于手动设计的变换、随机采样或基于搜索的自动化方法。尽管自动化方法可以提高性能，但它们通常需要大量的计算资源，并且是为特定数据集设计的。在本工作中，我们提出了一种由大型语言模型（LLM）引导的增强优化策略，该策略根据模型性能反馈来优化增强策略。我们提出了两种方法：（1）LLM引导的增强策略优化，其中LLM选择的增强策略在训练周期中进行迭代优化，以及（2）自适应LLM引导的增强策略优化，该方法在每次迭代中根据性能指标调整策略。这种在训练中进行的方法无需在获得LLM反馈前进行完全的模型重新训练，从而降低了计算成本，同时提高了性能。我们的方法采用LLM根据数据集特性、模型架构和先前的训练性能动态选择增强变换。利用LLM的上下文知识，尤其是在医学成像等特定领域任务中，我们的方法选择了针对数据集特性和模型性能量身定制的增强方法。在特定领域的图像分类数据集上进行的实验表明，与传统方法相比，准确性得到了一致的提高。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [753] [Glioblastoma Overall Survival Prediction With Vision Transformers](https://arxiv.org/abs/2508.02439)
> *胶质母细胞瘤的整体生存期预测：使用视觉变换器*

*Yin Lin, Riccardo Barbieri, Domenico Aquino, Giuseppe Lauria, Marina Grisoli, Elena De Momi, Alberto Redaelli, Simona Ferrante* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 胶质母细胞瘤, 总生存期预测, 视觉变换器, MRI, 深度学习

**Comment:** 4 pages, 4 figures, EMBC2025

> **TL;DR:** 该研究提出了一种新颖的AI方法，利用视觉变换器（ViTs）直接从MRI图像中提取特征，以预测胶质母细胞瘤患者的总生存期（OS），无需肿瘤分割，简化了工作流程并降低了计算资源需求。在BRATS数据集上，该模型达到了62.5%的测试集准确率，并在精确率、召回率和F1分数方面表现优于现有最佳模型。尽管数据集大小限制了ViT的泛化能力，但该研究证明了ViTs在降采样医学成像任务中的适用性，并为构建计算高效且无需分割的OS预测模型奠定了基础。

**AI_Comments:** 该研究展示了ViTs在医学成像分析中的潜力，特别是在无需预处理（如肿瘤分割）的情况下直接从图像中提取信息。然而，模型在泛化能力方面的局限性，尤其是在数据集较小的情况下，是未来研究需要关注的关键点。提升数据集规模或采用更先进的ViT变体可能有助于克服这一挑战。

<details>
  <summary>Details</summary>

**Motivation:** 预测胶质母细胞瘤患者的总生存期（OS）对于个性化治疗策略和使临床决策与患者结果保持一致至关重要。

**Method:** 利用视觉变换器（ViTs）直接从MRI图像中提取隐藏特征，以预测OS，无需肿瘤分割。

**Result:** 在BRATS数据集上，该模型达到了62.5%的测试集准确率，并且在精确率、召回率和F1分数方面表现优于现有最佳模型。然而，由于数据集规模的限制，ViT的泛化能力受到影响。

**Conclusion:** 该研究证明了视觉变换器（ViTs）在降采样医学成像任务中的适用性，并为构建计算高效且无需分割的OS预测模型奠定了基础。

> **ai_Abstract:** 本研究提出了一种利用视觉变换器（ViTs）直接从MRI图像预测胶质母细胞瘤（GBM）患者总生存期（OS）的新方法，无需肿瘤分割，从而简化了流程并降低了计算需求。该模型在BRATS数据集上取得了62.5%的准确率，并在精确率、召回率和F1分数方面优于现有最佳方法，证明了ViTs在医学成像任务中的潜力。

> **摘要翻译:** 胶质母细胞瘤是一种最常见且最具侵袭性的脑肿瘤，中位生存期为10-15个月。预测总生存期（OS）对于个性化治疗策略和使临床决策与患者结果保持一致至关重要。在本研究中，我们提出了一种新颖的人工智能（AI）方法，利用磁共振成像（MRI）图像进行OS预测，利用视觉变换器（ViTs）直接从MRI图像中提取隐藏特征，无需肿瘤分割。与传统方法不同，我们的方法简化了工作流程并减少了计算资源需求。
该模型在BRATS数据集上进行了评估，在测试集上达到了62.5%的准确率，与性能最佳的方法相当。此外，它在精确率、召回率和F1分数方面表现出均衡的性能，在这些指标上超过了最佳模型。数据集的大小限制了ViT的泛化能力，而ViT通常比卷积神经网络需要更大的数据集。这种泛化能力限制在所有引用的研究中都存在。这项工作突显了ViTs在降采样医学成像任务中的适用性，并为计算高效且不依赖分割的OS预测模型奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [757] [VideoGuard: Protecting Video Content from Unauthorized Editing](https://arxiv.org/abs/2508.03480)
> *视频卫士：保护视频内容免受未经授权的编辑*

*Junjie Cao, Kaizhou Li, Xinchun Yu, Hongxiang Li, Xiaoping Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视频保护, 生成式AI, 视频编辑, 扩散模型, 内容安全

**Comment:** ai security, 10pages, 5 figures

> **TL;DR:** 本研究提出了一种名为VideoGuard的视频内容保护方法，通过引入人眼难以察觉的扰动来阻止恶意编辑，并取得了优于基线方法的保护效果。

**AI_Comments:** 该研究有效地解决了视频内容在生成式AI时代面临的独特安全挑战。通过引入联合帧优化和运动信息融合等创新技术，VideoGuard在保护视频免受篡改方面取得了显著进展，为数字内容安全领域提供了有价值的贡献。然而，该方法在实际应用中的计算复杂度和对不同类型视频的泛化能力仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 生成式技术的发展带来了视频内容被恶意编辑的风险，但现有研究在保护视频方面存在不足。

**Method:** VideoGuard通过联合优化所有视频帧并融合视频运动信息，引入人眼难以察觉的扰动，干扰生成式扩散模型的功能，从而导致模型输出不合理和不一致的结果。

**Result:** 与基线方法相比，VideoGuard在保护视频免受未经授权编辑方面表现出优越的性能。

**Conclusion:** VideoGuard是一种有效保护视频内容免受恶意编辑的方法，通过联合帧优化和运动信息融合实现了对生成式模型的干扰。

> **ai_Abstract:** 本研究提出了一种名为VideoGuard的视频内容保护方法，旨在应对生成式技术发展带来的视频被恶意编辑的风险。与仅处理单帧图像的方法不同，VideoGuard采用联合帧优化策略，将视频所有帧作为一个整体进行优化，并融入视频运动信息，以干扰生成式扩散模型。这种方法通过引入人眼难以察觉的扰动，使得模型生成的输出不合理且不一致，从而有效阻止未经授权的编辑。实验结果表明，VideoGuard的保护性能优于现有的基线方法。

> **摘要翻译:** 随着生成式技术的飞速发展，当前的生成模型能够以可控的方式生成高保真度的数字内容并对其进行编辑。然而，恶意个人有可能滥用这些能力进行误导性活动。尽管现有研究已尝试保护照片图像免受生成模型的操纵，但视频内容编辑所获得的保护仍然存在显著的差距。为了弥合这一差距，我们提出了一种名为VideoGuard的保护方法，该方法能够有效地保护视频免受未经授权的恶意编辑。这种保护是通过微妙地引入几乎无法察觉的扰动来实现的，这些扰动会干扰目标生成扩散模型的功能。由于视频帧之间的冗余以及视频扩散模型中的帧间注意力机制，仅仅将基于图像的保护方法分别应用于每个视频帧并不能保护视频免受未经授权的编辑。为了应对这一挑战，我们采用了联合帧优化，将所有视频帧视为一个优化实体。此外，我们提取视频运动信息并将其融合到优化目标中。因此，这些改动可以有效地迫使模型产生不合理和不一致的输出。我们提供了一个优化此扰动的流程。最后，我们使用客观指标和主观指标来证明我们方法的有效性，结果表明VideoGuard的保护性能优于所有基线方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [758] [RadProPoser: A Framework for Human Pose Estimation with Uncertainty Quantification from Raw Radar Data](https://arxiv.org/abs/2508.03578)
> *雷达姿态 প্রস্তাব者：基于原始雷达数据进行不确定性量化的人体姿态估计框架*

*Jonas Leo Mueller, Lukas Engel, Eva Dorschky, Daniel Krauss, Ingrid Ullmann, Martin Vossiek, Bjoern M. Eskofier* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 人体姿态估计, 雷达传感, 不确定性量化, 概率模型, 变分推理

**Comment:** 

> **TL;DR:** RadProPoser是一个新框架，使用原始雷达数据进行人体姿态估计，并量化不确定性。

**AI_Comments:** 该研究首次提出了端到端基于原始雷达张量数据的人体姿态估计方法，并显式地量化了每关节的不确定性，这对于提高雷达应用的可解释性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 雷达人体姿态估计（HPE）具有隐私保护和光照不变性，但面临噪声和多径干扰的挑战。

**Method:** RadProPoser是一个概率编码器-解码器架构，处理MIMO雷达的复值雷达张量，并通过变分推理进行关键点回归，同时预测26个3D关节位置及其不确定性。

**Result:** RadProPoser在新的数据集上实现了6.425厘米的平均每关节位置误差（MPJPE），并且学习到的不确定性与实际姿态误差高度相关。此外，通过数据增强，下游活动分类任务的F1分数达到了0.870。

**Conclusion:** RadProPoser是首个端到端基于雷达张量的人体姿态估计系统，能够显式地从原始雷达张量数据中建模和量化每关节的不确定性，为雷达应用中可解释和可靠的人体运动分析奠定了基础。

> **ai_Abstract:** RadProPoser是一个新颖的框架，用于处理嘈杂的雷达数据以进行人体姿态估计。它采用概率编码器-解码器架构，结合变分推理来预测关节位置和量化不确定性。该方法在新的数据集上取得了优异的性能，并且学习到的不确定性对于可靠的预测至关重要。此外，它还可以用于数据增强，以提高下游任务的性能。

> **摘要翻译:** 基于雷达的人体姿态估计（HPE）提供了一种隐私保护、光照不变的传感方式，但面临着噪声大、受多径影响的测量挑战。我们引入了RadProPoser，一种概率编码器-解码器架构，用于处理来自紧凑型3发射器、4接收器MIMO雷达的复值雷达张量。通过将变分推理纳入关键点回归，RadProPoser能够同时预测26个三维关节位置以及异方差的偶然不确定性，并且可以通过重新校准来预测总不确定性。我们探索了使用高斯和拉普拉斯分布作为潜在先验和似然的各种概率公式。在我们新发布的包含光学运动捕捉地面真实数据的数据集上，RadProPoser实现了6.425厘米的总体平均每关节位置误差（MPJPE），在45度视角下为5.678厘米。学习到的不确定性与实际姿态误差表现出很强的一致性，并且可以通过校准生成可靠的预测区间，我们最好的配置实现了0.021的预期校准误差。作为额外的演示，从这些潜在分布中采样能够有效地进行下游活动分类的数据增强，取得了0.870的F1分数。据我们所知，这是首个端到端基于雷达张量的人体姿态估计系统，能够从原始雷达张量数据中显式地建模和量化每关节的不确定性，为雷达应用中可解释和可靠的人体运动分析奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [767] [Low-Frequency First: Eliminating Floating Artifacts in 3D Gaussian Splatting](https://arxiv.org/abs/2508.02493)
> *低频优先：消除三维高斯泼溅中的浮动伪影*

*Jianchao Wang, Peng Zhou, Cen Li, Rong Quan, Jie Qin* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D高斯泼溅, 浮动伪影, 低频学习, 频域分析, EFA-GS

**Comment:** Project Website: https://jcwang-gh.github.io/EFA-GS

> **TL;DR:** 该研究提出了一种名为EFA-GS的新方法，通过分析低频初始化中的浮动伪影来源，选择性地扩展优化不足的高斯核，并结合基于深度和尺度的策略来优化高斯核的扩展，从而有效减少了浮动伪影并保留了高频细节，在PSNR方面比基线方法提高了1.68 dB。

**AI_Comments:** 该研究从频域角度深入分析了3D高斯泼溅中的浮动伪影问题，并提出了创新的EFA-GS方法，通过优先低频学习和动态扩展策略有效解决了该问题。实验结果表明该方法在减少伪影和保留细节方面表现优异，并验证了其在实际应用中的潜力。然而，对于“低质量初始化”的具体定义和不同场景下的泛化能力仍需进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅（3DGS）在三维重建方面表现出色，但常产生浮动伪影，尤其是在低质量初始化时，其产生机制尚未得到充分研究。

**Method:** 从频域角度分析浮动伪影的成因，发现优化不足的高斯核是主要来源。提出EFA-GS方法，选择性扩展优化不足的高斯核，优先学习低频信息。同时引入基于深度和尺度的策略动态优化高斯核扩展，以减少细节丢失。

**Result:** EFA-GS方法显著减少了浮动伪影，同时保留了高频细节。在RWLQ数据集上，PSNR比基线方法提高了1.68 dB。该方法在下游三维编辑任务中也验证了其有效性。

**Conclusion:** EFA-GS通过优先低频学习和动态调整高斯核扩展，有效解决了3D高斯泼溅中的浮动伪影问题，并在视觉保真度和细节保留方面取得了显著提升。

> **ai_Abstract:** 该研究提出了一种名为EFA-GS的新方法，旨在解决3D高斯泼溅（3DGS）中的浮动伪影问题。研究人员通过频域分析发现，优化不足的高斯核是导致这些伪影的主要原因。EFA-GS通过优先扩展优化不足的高斯核以学习低频信息，并结合深度和尺度策略动态优化高斯核扩展，有效减少了伪影并保留了高频细节，在PSNR指标上取得了显著提升。

> **摘要翻译:** 三维高斯泼溅（3DGS）是一种强大且计算高效的三维重建表示。尽管其优点突出，但3DGS常会产生浮动伪影，这些伪影是与实际几何体分离的错误结构，会严重降低视觉保真度。导致这些伪影的潜在机制，尤其是在低质量初始化场景下，尚未得到充分探索。在本研究中，我们从频域的角度探讨了浮动伪影的起源，并确定优化不足的高斯核是主要来源。基于我们的分析，我们提出了消除浮动伪影的高斯泼溅（EFA-GS），它选择性地扩展优化不足的高斯核，以优先学习准确的低频信息。此外，我们引入了基于深度和基于尺度的互补策略，以动态地优化高斯核的扩展，从而有效缓解细节侵蚀。在合成和真实世界数据集上的广泛实验表明，EFA-GS在保留高频细节的同时，显著减少了浮动伪影，在我们提出的RWLQ数据集上，PSNR比基线方法提高了1.68 dB。此外，我们验证了我们方法在下游三维编辑任务中的有效性。我们在https://jcwang-gh.github.io/EFA-GS提供了我们的实现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [771] [IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves](https://arxiv.org/abs/2411.00827)
> *IDEATOR：使用大型视觉语言模型自身来进行越狱和基准测试*

*Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma, Yu-Gang Jiang* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 越狱攻击, 视觉语言模型, 多模态安全, IDEATOR, VLJailbreakBench

**Comment:** 

> **TL;DR:** 本研究提出了一种名为IDEATOR的新方法，利用大型视觉语言模型（VLMs）自身来生成用于黑盒越狱攻击的多模态提示。IDEATOR结合了VLM生成的文本和扩散模型生成的图像，在MiniGPT-4上实现了94%的攻击成功率，并在LLaVA、InstructBLIP和Chameleon上表现出良好的可迁移性。基于此方法，研究者构建了一个包含3654个样本的VLJailbreakBench基准测试集，揭示了当前VLMs在安全对齐方面存在的显著差距，并强调了加强防御的必要性。

**AI_Comments:** 该研究提出了一种创新的方法，利用模型自身来发现和利用其安全漏洞，这是一种“以毒攻毒”的思路。IDEATOR的自动化和高迁移性使其成为评估和改进VLM安全性的有力工具。VLJailbreakBench的构建为后续VLM安全研究提供了宝贵的资源。然而，该方法对计算资源的要求以及潜在的滥用风险也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型视觉语言模型（VLMs）在安全部署方面面临挑战，现有的越狱方法由于多模态数据有限，主要依赖于手动制作的图像和文本，效果和多样性不足。因此，需要一种更有效、更多样化的方法来评估和提升VLMs的安全性。

**Method:** IDEATOR方法利用一个VLM来生成目标越狱文本，并将其与由先进的扩散模型生成的越狱图像配对，以对其他VLMs进行黑盒越狱攻击。该方法旨在利用VLMs自身的能力来生成攻击所需的恶意多模态提示。

**Result:** IDEATOR在MiniGPT-4上实现了94%的攻击成功率（ASR），平均仅需5.34次查询。该方法在迁移到LLaVA、InstructBLIP和Chameleon时，分别取得了82%、88%和75%的高ASR。研究者还创建了VLJailbreakBench基准测试集，包含3654个多模态越狱样本，并在11个VLMs上进行了测试，发现GPT-4o的ASR为46.31%，Claude-3.5-Sonnet的ASR为19.65%，表明当前VLMs在安全对齐方面存在显著不足。

**Conclusion:** IDEATOR是一种有效且可迁移的利用VLM自身生成多模态越狱提示的方法，能够显著提升越狱攻击的效率和多样性。研究提出的VLJailbreakBench基准测试揭示了当前VLMs在安全对齐方面存在的普遍性问题，凸显了开发更强大防御机制的紧迫性。

> **ai_Abstract:** 本研究提出了一种名为IDEATOR的新型越狱方法，该方法利用大型视觉语言模型（VLMs）自身来生成恶意图像-文本对，用于对其他VLMs进行黑盒越狱攻击。IDEATOR通过结合VLM生成的文本和扩散模型生成的图像，在MiniGPT-4上实现了94%的攻击成功率，并表现出良好的跨模型可迁移性。基于此方法，研究者构建了一个名为VLJailbreakBench的多模态安全基准测试集，并通过在多个知名VLMs上的测试，揭示了当前模型在安全对齐方面存在的普遍性问题，强调了开发更强安全防御机制的必要性。

> **摘要翻译:** 随着大型视觉语言模型（VLMs）日益普及，确保其安全部署已变得至关重要。近期研究探索了VLM在面对越狱攻击时的鲁棒性——即利用模型漏洞诱导有害输出的技术。然而，多模态数据的多样性有限，导致当前方法严重依赖于源自有害文本数据集的对抗性或手动制作的图像，这些图像在不同情境下的有效性和多样性往往不足。在本论文中，我们提出了IDEATOR，一种新颖的越狱方法，它能自主生成恶意的图像-文本对，用于黑盒越狱攻击。IDEATOR基于一个见解，即VLMs本身可以作为强大的红队模型，用于生成多模态越狱提示。具体来说，IDEATOR利用一个VLM来创建目标越狱文本，并将其与由最先进的扩散模型生成的越狱图像配对。大量的实验证明了IDEATOR的高效性和可迁移性，在越狱MiniGPT-4时取得了94%的攻击成功率（ASR），平均仅需5.34次查询，并且在迁移到LLaVA、InstructBLIP和Chameleon时，分别取得了82%、88%和75%的高ASR。基于IDEATOR强大的可迁移性和自动化流程，我们引入了VLJailbreakBench，一个包含3654个多模态越狱样本的安全基准测试。我们在11个近期发布的VLM上进行的基准测试结果揭示了安全对齐方面存在的显著差距。例如，我们的挑战集在GPT-4o上的ASR为46.31%，在Claude-3.5-Sonnet上的ASR为19.65%，这凸显了对更强防御措施的迫切需求。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [780] [DyCAF-Net: Dynamic Class-Aware Fusion Network](https://arxiv.org/abs/2508.03598)
> *动态类别感知融合网络：DyCAF-Net*

*Md Abrar Jahin, Shahriar Soudeep, M. F. Mridha, Nafiz Fahad, Md. Jakir Hossen* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 物体检测, 动态场景, 类别感知, 注意力机制, 多尺度融合

**Comment:** Accepted to IEEE DSAA 2025 (10 pages, 5 figures)

> **TL;DR:** DyCAF-Net 通过输入条件平衡颈部、双动态注意力机制和类别感知特征适应性，改进了物体检测的性能，尤其是在遮挡、杂乱和类别不平衡的动态场景中。

**AI_Comments:** 该研究提出了一种名为 DyCAF-Net 的新颖物体检测网络，通过引入动态类别感知融合机制，有效解决了传统方法在处理动态场景（如遮挡、杂乱和类别不平衡）时存在的局限性。其创新的三点设计（平衡颈部、双动态注意力、类别感知特征适应）展示了在提升检测精度和鲁棒性方面的潜力。该方法在多个基准测试中取得了优异的性能，并保持了良好的计算效率，预示着其在医学成像、监控和自动驾驶等领域的广泛应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 静态融合启发式和类别不可知注意力限制了动态场景中具有遮挡、杂乱和类别不平衡的物体检测性能。

**Method:** DyCAF-Net 包含三个创新：1）输入条件平衡颈部，通过隐式不动点建模迭代地优化多尺度特征；2）双动态注意力机制，使用输入和类别依赖线索自适应地重新校准通道和空间响应；3）类别感知特征适应，调节特征以优先考虑稀有类别的区分性区域。

**Result:** DyCAF-Net 在精度、mAP@50 和 mAP@50-95 方面取得了显著的改进，在 13 个不同的基准测试中，包括遮挡严重和长尾数据集，与 YOLOv8 和相关架构进行了全面的消融研究，并与九个最先进的基线进行了比较。

**Conclusion:** DyCAF-Net 是一种强大的解决方案，适用于医学成像、监控和自主系统中的现实世界检测任务，因为它在保持计算效率和有竞争力的推理速度的同时，具有对尺度方差、语义重叠和类别不平衡的适应性。

> **ai_Abstract:** DyCAF-Net 是一项物体检测的进步，它通过动态类别感知融合网络解决了动态场景中的挑战。该网络采用输入条件平衡颈部进行特征优化，双动态注意力机制进行自适应校准，以及类别感知特征适应来处理稀有类别。实验证明，DyCAF-Net 在各种数据集上均能显著提高性能，同时保持计算效率和推理速度，适用于各种实际应用。

> **摘要翻译:** 物体检测的最新进展依赖于具有多尺度融合和注意力机制的模块化架构。然而，静态融合启发式和类别不可知注意力在具有遮挡、杂乱和类别不平衡的动态场景中限制了性能。我们引入了动态类别感知融合网络（DyCAF-Net），它通过三项创新解决了这些挑战：(1) 一个输入条件平衡颈部，通过隐式不动点建模迭代地优化多尺度特征，(2) 一个双动态注意力机制，使用输入和类别依赖线索自适应地重新校准通道和空间响应，以及 (3) 类别感知特征适应，调节特征以优先考虑稀有类别的区分性区域。通过与 YOLOv8 和相关架构进行全面的消融研究，以及与九个最先进的基线进行基准测试，DyCAF-Net 在 13 个不同的基准测试中，包括遮挡严重和长尾数据集，在精度、mAP@50 和 mAP@50-95 方面取得了显著的改进。该框架保持了计算效率（~1110 万个参数）和有竞争力的推理速度，同时其对尺度方差、语义重叠和类别不平衡的适应性使其成为医学成像、监控和自主系统中现实世界检测任务的强大解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [783] [Differentially Private Adaptation of Diffusion Models via Noisy Aggregated Embeddings](https://arxiv.org/abs/2411.14639)
> *差分隐私适应扩散模型通过噪声聚合嵌入*

*Pura Peetathawatchai, Wei-Ning Chen, Berivan Isik, Sanmi Koyejo, Albert No* | **Category: cs.CV, cs.CR, cs.LG, Computer Vision (cs.CV), Machine Learning (cs.LG), Machine Learning
  (stat.ML)** | **Updated: 2025-08-05**

**Keywords:** 差分隐私,扩散模型,文本反演,嵌入聚合,个性化

**Comment:** 

> **TL;DR:** 该研究提出了一种名为DPAgg-TI的新方法，通过对文本反演学习到的嵌入向量进行噪声聚合，在差分隐私约束下实现对大型扩散模型的个性化调整，解决了DP-SGD在小数据集上效用严重下降的问题，并在风格迁移任务上取得了优于DP-SGD的性能。

**AI_Comments:** 该研究提出了一种新颖的差分隐私适配扩散模型的方法，通过利用文本反演和噪声聚合嵌入，有效解决了现有DP-SGD方法在小数据集上效用严重下降的问题，并在实验中取得了优于DP-SGD的成果，具有重要的理论和实践意义。然而，其在不同类型数据和不同隐私预算下的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 对大型扩散模型进行个性化调整，尤其是在使用小规模、敏感数据集时，会带来严重隐私风险。常用的DP-SGD方法在小数据量下由于需要高噪声以保证隐私，会导致效用严重下降。

**Method:** 提出了一种名为DPAgg-TI的新方法，该方法利用文本反演（TI）学习图像的嵌入向量，并在差分隐私（DP）约束下进行适配。具体做法是对每个图像的嵌入向量进行聚合，并加入经过校准的噪声，以确保形式化的DP保证并保持高输出保真度。

**Result:** DPAgg-TI在相同的隐私预算下，在效用和鲁棒性方面均优于DP-SGD微调，其在风格迁移任务上的表现与非私有基线模型非常接近。相比之下，DP-SGD在该场景下无法生成有意义的输出。

**Conclusion:** DPAgg-TI通过对文本反演学习到的嵌入向量进行噪声聚合，为在差分隐私约束下适配大型扩散模型提供了一种有效的方法，相比DP-SGD，在保持隐私的同时能更好地保留模型效用和鲁棒性。

> **ai_Abstract:** 本研究提出了一种名为DPAgg-TI的新方法，用于在差分隐私下个性化大型扩散模型。该方法通过对文本反演学习到的嵌入向量进行噪声聚合，解决了现有DP-SGD方法在小数据集上效用严重下降的问题，并在实验中证明了其在效用和鲁棒性方面优于DP-SGD，能够接近非私有基线。

> **摘要翻译:** 个性化大型扩散模型会带来严重的隐私风险，尤其是在适应小型、敏感数据集时。一种常见的方法是使用差分私有随机梯度下降（DP-SGD）进行微调，但这由于在隐私保护所需的高噪声下会导致严重的效用下降，尤其是在小数据量的情况下。我们提出了另一种方法，该方法利用文本反演（TI），它为图像或图像集学习一个嵌入向量，以便在差分隐私（DP）约束下进行适配。我们的方法，通过文本反演进行差分私有聚合（DPAgg-TI），将校准后的噪声添加到每个图像嵌入的聚合中，以确保正式的DP保证，同时保持高输出保真度。我们证明，在相同的隐私预算下，DPAgg-TI在效用和鲁棒性方面均优于DP-SGD微调，在私有艺术品和巴黎2024奥运会图标的风格迁移任务上，其结果与非私有基线非常接近。相比之下，DP-SGD在此场景下无法生成有意义的输出。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [790] [Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.03007)
> *通过VFM进行多粒度特征校准以实现领域泛化语义分割*

*Xinhui Li, Xiaojie Guo* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 领域泛化语义分割, 视觉基础模型, 多粒度特征校准, 层次化适应, 鲁棒性

**Comment:** 

> **TL;DR:** 该研究提出了一种名为MGFC的新框架，通过多粒度特征校准来提高领域泛化语义分割（DGSS）模型的泛化能力，实现了优于现有方法的性能。

**AI_Comments:** 这项研究提出了一种新颖的多粒度特征校准（MGFC）框架，用于解决领域泛化语义分割（DGSS）中的关键挑战。通过对视觉基础模型（VFM）的特征进行从粗到细的层次化适应，该方法有效地解决了现有技术中对全局特征的过度关注。MGFC通过分别处理全局上下文、类别判别力和空间细节，展示了多粒度适应的潜力。该研究的贡献在于提供了一种更全面的特征校准方法，提高了模型在不同领域之间的泛化能力。然而，该方法在计算成本和不同粒度级别之间的交互作用方面可能存在一些局限性，这需要进一步的研究来探讨。

<details>
  <summary>Details</summary>

**Motivation:** 现有领域泛化语义分割（DGSS）方法主要关注全局特征微调，忽略了跨特征层级的层次化适应，而这对于精确的密集预测至关重要。

**Method:** 提出了一种名为多粒度特征校准（MGFC）的新框架，通过粗到细的对齐来校准VFM特征，首先校准粗粒度特征以捕捉全局上下文语义和场景结构，然后通过提高类别级特征判别力来细化中粒度特征，最后通过增强高频空间细节来校准细粒度特征。

**Result:** 在基准数据集上的广泛实验表明，所提出的MGFC方法优于最先进的DGSS方法，证明了多粒度适应对于领域泛化任务的有效性。

**Conclusion:** 多粒度适应对于语义分割的领域泛化任务是有效的，MGFC框架通过多粒度特征校准提高了模型的泛化能力。

> **ai_Abstract:** 本研究提出了一种名为多粒度特征校准（MGFC）的新框架，用于领域泛化语义分割（DGSS）。与现有方法侧重于全局特征不同，MGFC通过粗到细的校准策略，在不同粒度级别上对视觉基础模型（VFM）的特征进行层次化适应。该方法首先捕捉全局上下文，然后提高类别判别力，最后增强空间细节，从而提高模型在未见域上的鲁棒性。实验证明，MGFC在DGSS任务上优于最先进的方法。

> **摘要翻译:** 领域泛化语义分割（DGSS）旨在提高模型在未见过的域上的泛化能力，而无需在训练期间访问目标数据。DGSS的最新进展越来越多地通过参数高效的微调策略利用视觉基础模型（VFM）。然而，现有的大多数方法都集中在全局特征微调，而忽略了跨特征层级的层次化适应，而这对于精确的密集预测至关重要。在本研究中，我们提出了多粒度特征校准（MGFC），一个新颖的框架，它执行VFM特征的粗到细对齐，以增强在域偏移下的鲁棒性。具体来说，MGFC首先校准粗粒度特征以捕捉全局上下文语义和场景结构。然后，它通过提高类别级特征的判别力来细化中粒度特征。最后，通过增强高频空间细节来校准细粒度特征。通过执行层次化和粒度感知的校准，MGFC有效地将VFM的泛化优势转移到DGSS这一特定领域的任务中。在基准数据集上的广泛实验表明，我们的方法优于最先进的DGSS方法，突显了多粒度适应对于领域泛化任务的语义分割的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [791] [Open-Vocabulary HOI Detection with Interaction-aware Prompt and Concept Calibration](https://arxiv.org/abs/2508.03207)
> *开放词汇的人体-物体交互检测：交互感知提示与概念校准*

*Ting Lei, Shaofeng Yin, Qingchao Chen, Yuxin Peng, Yang Liu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 开放词汇HOI检测, 交互感知提示, 概念校准, 视觉语言模型, 细粒度检测

**Comment:** 

> **TL;DR:** 提出INP-CC模型，通过交互感知提示和概念校准，解决了现有开放词汇HOI检测中图像编码器不匹配和文本描述编码困难的问题，在SWIG-HOI和HICO-DET数据集上表现优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的INP-CC框架，通过交互感知提示和概念校准来改进开放词汇HOI检测。其亮点在于动态生成提示以聚焦关键交互模式，并通过语言模型校准来区分相似概念，这在解决现有方法的局限性方面具有潜力。然而，其计算效率和在更复杂、多样化场景下的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有开放词汇HOI检测方法依赖VLMs，但存在图像编码器不匹配（图像级预训练不适用于细粒度区域级交互检测）和文本描述编码困难（难以捕捉详细HOI关系）的问题。

**Method:** 提出INP-CC，一个端到端的开放词汇HOI检测器，包含交互感知提示生成器（动态生成提示，选择性共享相似交互）和概念校准（通过语言模型校准HOI概念表示，区分相似类别）以及负采样策略。

**Result:** INP-CC在SWIG-HOI和HICO-DET数据集上显著优于现有最先进模型。

**Conclusion:** INP-CC通过交互感知提示和概念校准，有效解决了开放词汇HOI检测中的关键挑战，并在标准数据集上取得了领先性能。

> **ai_Abstract:** 本文提出了一种名为INP-CC的开放词汇人体-物体交互（HOI）检测新方法，以解决现有方法中图像编码器不匹配和文本描述编码困难的问题。INP-CC通过交互感知提示生成器动态生成针对场景的提示，并利用语言模型引导的概念校准来优化HOI概念表示，从而提高对细粒度交互的检测能力。实验证明，INP-CC在SWIG-HOI和HICO-DET数据集上取得了优于现有方法的性能。

> **摘要翻译:** 开放词汇人体-物体交互（HOI）检测旨在检测人与物体之间的交互，并能泛化到训练集之外的新颖交互类别。现有方法通常依赖视觉语言模型（VLMs），但面临着由于次优图像编码器带来的挑战，因为图像级预训练与HOI所需的细粒度区域级交互检测不匹配。此外，有效编码视觉外观的文本描述仍然很困难，限制了模型捕捉详细HOI关系的能力。为了解决这些问题，我们提出了交互感知提示与概念校准（INP-CC），一种端到端的开放词汇HOI检测器，集成了交互感知提示和概念校准。具体来说，我们提出了一个交互感知提示生成器，该生成器根据输入场景动态生成一组紧凑的提示，并能在相似交互之间进行选择性共享。这种方法将模型的注意力引导至关键的交互模式，而不是通用的图像级语义，从而增强了HOI检测。此外，我们通过语言模型引导的校准来优化HOI概念表示，这有助于通过研究类别间的视觉相似性来区分不同的HOI概念。还采用了负采样策略来优化跨模态相似性建模，使模型能够更好地区分视觉上相似但语义上不同的动作。大量的实验结果表明，INP-CC在SWIG-HOI和HICO-DET数据集上的表现显著优于最先进的模型。代码可在https://github.com/ltttpku/INP-CC获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [792] [When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models](https://arxiv.org/abs/2508.03483)
> *当汽车带有刻板印象时：对文本到图像模型中对象的人口统计学偏见进行审计*

*Dasol Choi Jihwan Lee, Minjae Lee, Minsuk Kahng* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 文本到图像模型,人口统计学偏见,刻板印象,对象生成,SODA审计

**Comment:** 

> **TL;DR:** 该研究提出了SODA框架，用于审计文本到图像模型中生成的对象（如汽车）与特定人群关联时存在的人口统计学偏见，发现模型会生成与性别或种族提示相关的特定颜色模式，放大了视觉差异，并强调了负责任AI发展的重要性。

**AI_Comments:** 这项研究开创性地将对生成模型偏见的审计扩展到了对象层面，而不仅仅是人物描绘。SODA框架的提出为量化和揭示这些微妙但普遍存在的偏见提供了一个实用的工具。研究结果强调了在AI开发中解决刻板印象和促进公平性的重要性。然而，未来的研究可以进一步探索这些偏见产生的具体机制，并开发减轻这些偏见的具体技术。

<details>
  <summary>Details</summary>

**Motivation:** 先前研究主要关注文本到图像生成中的人类描绘偏见，而本研究则关注一个更微妙但普遍存在的现象：生成对象（如汽车）中的人口统计学偏见。

**Method:** 提出SODA（Stereotyped Object Diagnostic Audit）框架，系统地衡量生成对象的人口统计学偏见。该方法比较了带有示范性线索（如“适合年轻人”）的提示与中性提示下生成的对象在视觉属性上的差异，分析了三个先进模型（GPT Image-1、Imagen 4和Stable Diffusion）在五个对象类别中的2700张图像。

**Result:** 发现特定人群与视觉属性之间存在强烈的关联，例如由性别或种族提示引起的重复颜色模式。这些模式反映并强化了已知的刻板印象以及更微妙、不直观的偏见。一些模型生成的输出多样性较低，与中性提示相比，放大了视觉差异。

**Conclusion:** 提出的审计框架为测试提供了一种实用的方法，揭示了当今生成模型中仍然存在刻板印象。这是朝着更系统、更负责任的AI发展迈出的重要一步。

> **ai_Abstract:** 本研究引入了SODA审计框架，用于检测文本到图像模型在生成对象时可能存在的基于人口统计学信息的偏见。通过分析模型在不同提示下的图像输出，研究发现模型会将特定人群与特定的视觉属性（如颜色）关联起来，从而强化甚至创造新的刻板印象，并指出模型多样性不足会加剧这些偏见。

> **摘要翻译:** 虽然先前对文本到图像生成的研究主要集中在人类描绘中的偏见，但我们调查了一个更微妙但普遍存在的现象：生成对象（例如汽车）中的人口统计学偏见。我们引入了SODA（刻板印象对象诊断审计），一个用于系统衡量此类偏见的创新框架。我们的方法将带有示范性线索（例如，“适合年轻人”）的提示生成的对象与中性提示生成的对象在视觉属性上的差异进行了比较，分析了三个最先进的模型（GPT Image-1、Imagen 4和Stable Diffusion）在五个对象类别中的2700张图像。通过全面的分析，我们发现特定人群与视觉属性之间存在强烈的关联，例如由性别或种族提示引起的重复颜色模式。这些模式反映并强化了不仅是众所周知的刻板印象，而且是更微妙和不直观的偏见。我们还观察到一些模型生成的输出多样性较低，这反过来又放大了与中性提示相比的视觉差异。我们提出的审计框架为测试提供了一种实用的方法，揭示了刻板印象仍然嵌入在当今的生成模型中。我们认为这是朝着更系统和负责任的AI发展迈出的重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [794] [CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM](https://arxiv.org/abs/2411.04954)
> *CAD-MLLM：利用多模态大型语言模型统一多模态条件下的CAD生成*

*Jingwei Xu, Chenyu Wang, Zibo Zhao, Wen Liu, Yi Ma, Shenghua Gao* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** CAD生成, 多模态学习, 大型语言模型, 参数化建模, Omni-CAD

**Comment:** Project page: https://cad-mllm.github.io/

> **TL;DR:** 本研究提出了CAD-MLLM，一个能够根据文本、图像、点云或其组合生成参数化CAD模型的系统。它利用LLM对齐多模态数据和CAD模型向量表示，并引入了包含约450K实例及其CAD构建序列的Omni-CAD数据集。该系统在生成CAD模型方面表现优于现有方法，并引入了评估拓扑质量和曲面封闭性的新指标。

**AI_Comments:** 该研究在CAD生成领域取得了重要进展，通过引入CAD-MLLM和Omni-CAD数据集，实现了多模态输入的统一处理。然而，未来可以进一步探索更复杂的几何约束和交互式编辑功能。

<details>
  <summary>Details</summary>

**Motivation:** 设计一个能够根据文本、图像、点云或其组合等用户输入轻松生成CAD模型的统一计算机辅助设计（CAD）生成系统。

**Method:** 利用CAD模型的命令序列，并采用先进的大型语言模型（LLMs）来对齐跨越不同多模态数据和CAD模型向量表示的特征空间。为模型训练设计了一个全面的数据构建和标注流程，为每个CAD模型配备了相应的多模态数据。引入了评估拓扑质量和曲面封闭性的额外指标。

**Result:** CAD-MLLM在生成参数化CAD模型方面表现优于现有的条件生成方法，并且对噪声和缺失点具有高度鲁棒性。

**Conclusion:** CAD-MLLM是首个能够根据多模态输入生成参数化CAD模型的系统，它通过利用LLM对齐多模态数据和CAD模型向量表示，并引入新的评估指标，在CAD生成任务上取得了显著的进展。

> **ai_Abstract:** 本研究提出了CAD-MLLM，一个创新的统一系统，能够根据文本、图像、点云或其组合生成参数化CAD模型。该系统利用大型语言模型（LLM）对齐多模态数据和CAD模型向量表示，并通过一个包含约450K实例及其CAD构建序列的名为Omni-CAD的新型多模态CAD数据集进行训练。CAD-MLLM在评估拓扑质量和曲面封闭性方面超越了传统指标，并通过实验证明其在生成CAD模型方面优于现有方法，并对噪声和缺失点具有鲁棒性。

> **摘要翻译:** 本篇论文旨在设计一个统一的计算机辅助设计（CAD）生成系统，该系统能够根据用户以文本描述、图像、点云或它们的组合形式的输入轻松生成CAD模型。为此，我们引入了CAD-MLLM，这是第一个能够根据多模态输入生成参数化CAD模型的系统。具体来说，在CAD-MLLM框架内，我们利用CAD模型的命令序列，然后采用先进的大型语言模型（LLMs）来对齐跨越这些不同多模态数据和CAD模型向量表示的特征空间。为了便于模型训练，我们设计了一个全面的数据构建和标注流程，为每个CAD模型配备了相应的多模态数据。我们由此产生的、名为Omni-CAD的数据集是第一个包含每个CAD模型的文本描述、多视图图像、点云和命令序列的多模态CAD数据集。它包含大约450K个实例及其CAD构建序列。为了彻底评估我们生成的CAD模型的质量，我们超越了当前侧重于重建质量的评估指标，引入了评估拓扑质量和曲面封闭性的额外指标。广泛的实验结果表明，CAD-MLLM的性能显著优于现有的条件生成方法，并且对噪声和缺失点保持高度鲁棒性。项目页面和更多可视化可以在：https://cad-mllm.github.io/找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [800] [Video Is Worth a Thousand Images: Exploring the Latest Trends in Long Video Generation](https://arxiv.org/abs/2412.18688)
> *视频的价值等于一千张图像：探索长视频生成的最新趋势*

*Faraz Waseem, Muhammad Shahzad* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 长视频生成, 多模态大语言模型, 时空一致性, 分而治之, 生成式人工智能

**Comment:** 35 pages, 18 figures, Manuscript submitted to ACM

> **TL;DR:** 尽管多模态大语言模型取得了进展，但生成一分钟以上的长视频仍然是一个挑战，因为这需要规划、故事发展和时空一致性等方面的考虑。本篇综述探讨了长视频生成的现状，包括基础技术、策略、数据集、评估指标以及未来的研究方向。

**AI_Comments:** 该综述为长视频生成领域提供了一个全面的概述，强调了当前的技术限制和未来的研究方向。它有效地组织了信息，涵盖了从基础技术到评估指标的广泛主题，为研究人员提供了一个有价值的资源。

<details>
  <summary>Details</summary>

**Motivation:** 生成长视频（超过一分钟）仍然是一个巨大的挑战，需要超越简单的密度函数近似，还需要考虑规划、故事发展和时空一致性等问题。

**Method:** 本综述检查了长视频生成的当前状况，包括基础技术（如 GANs 和扩散模型）、视频生成策略、大规模训练数据集、长视频的质量指标以及解决现有视频生成能力局限性的未来研究领域。

**Result:** Not mentioned in abstract

**Conclusion:** 本综述旨在为长视频生成领域提供一个全面的基础，为未来的进步和研究提供指导。

> **ai_Abstract:** 本综述旨在应对长视频生成这一复杂挑战，该挑战超越了仅生成一分钟的视频。它深入探讨了该领域，涵盖了从 GANs 和扩散模型等基础技术到视频生成策略、大规模数据集和评估指标的各个方面。此外，它还指出了需要解决的局限性，并为未来的研究方向提供了见解，以期推动长视频生成能力的进步。

> **摘要翻译:** 一张图像可以传达千言万语，但由数百甚至数千帧图像组成的视频则能讲述一个更复杂的故事。尽管在多模态大语言模型（MLLM）方面取得了重大进展，但生成长视频仍然是一个艰巨的挑战。在撰写本文时，OpenAI 的 Sora，即当前最先进的系统，仍然仅限于生成长达一分钟的视频。这一限制源于长视频生成的复杂性，它不仅需要生成式人工智能技术来近似密度函数，还需要规划、故事发展以及保持空间和时间一致性等关键方面，这些都带来了额外的挑战。将生成式人工智能与分而治之的方法相结合，可以在提供更大控制能力的同时，提高长视频的可扩展性。在本综述中，我们探讨了长视频生成的当前状况，涵盖了像 GANs 和扩散模型这样的基础技术、视频生成策略、大规模训练数据集、用于评估长视频的质量指标以及解决现有视频生成能力局限性的未来研究领域。我们相信，这将为该领域提供一个全面的基础，为长视频生成的未来进步和研究提供广泛的信息。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [806] [CIVQLLIE: Causal Intervention with Vector Quantization for Low-Light Image Enhancement](https://arxiv.org/abs/2508.03338)
> *CIVQLLIE：因果干预与向量量化用于低光图像增强*

*Tongshun Zhang, Pingping Liu, Zhe Zhang, Qiuzhan Zhou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 低光图像增强, 向量量化, 因果干预, 离散表示学习, 图像重建

**Comment:** 

> **TL;DR:** 该研究提出了一种名为CIVQLLIE的新框架，通过向量量化（VQ）和多层次因果干预来解决低光图像增强（LLIE）中的挑战。它利用离散表示学习和因果推理，通过像素级和特征级干预来校正数据分布偏移，并利用匹配的码本表示重建细节。

**AI_Comments:** 该研究提出的CIVQLLIE框架在低光图像增强领域具有创新性，它结合了离散表示学习（VQ）和因果推理，有效解决了传统方法在极暗条件下存在的局限性。通过多层次的因果干预，该方法能够处理数据分布偏移问题，并在细节重建方面表现出色。然而，该方法在实际应用中的计算复杂度和对大规模高质量图像数据集的依赖性可能是其潜在的限制。

<details>
  <summary>Details</summary>

**Motivation:** 现有低光图像增强方法在极暗条件下效果不佳，要么缺乏可解释性，要么依赖不可靠的先验知识，要么基于简化的物理假设。CIVQLLIE旨在通过离散表示学习和因果推理来克服这些局限性。

**Method:** CIVQLLIE框架利用向量量化（VQ）将连续图像特征映射到离散码本，并提出多层次因果干预来校正分布偏移。具体包括：1. 像素级因果干预（PCI）模块对齐低级特征；2. 特征感知因果干预（FCI）机制结合低频选择性注意力门控（LSAG）来增强受照度退化影响的通道；3. 高频细节重建模块（HDRM）利用码本表示和可变形卷积重建细节。

**Result:** 该研究提出了一种名为CIVQLLIE的新框架，通过向量量化（VQ）和多层次因果干预来解决低光图像增强（LLIE）中的挑战。它利用离散表示学习和因果推理，通过像素级和特征级干预来校正数据分布偏移，并利用匹配的码本表示重建细节。

**Conclusion:** CIVQLLIE框架通过结合向量量化和多层次因果干预，有效地解决了低光图像增强中的挑战，提高了图像的亮度和细节清晰度。

> **ai_Abstract:** CIVQLLIE是一个新颖的低光图像增强框架，它利用向量量化（VQ）学习离散视觉标记，并通过像素级因果干预（PCI）、特征感知因果干预（FCI）和低频选择性注意门控（LSAG）来解决数据分布偏移问题，最后利用高频细节重建模块（HDRM）和可变形卷积重建图像细节。

> **摘要翻译:** 在夜间场景中拍摄的图像可见性大大降低，阻碍了有效的内容感知。目前的低光图像增强（LLIE）方法面临严峻的挑战：数据驱动的端到端映射网络缺乏可解释性或依赖不可靠的先验指导，在极暗条件下表现不佳，而基于物理的方法则依赖于通常在复杂的现实场景中失效的简化假设。为了解决这些局限性，我们提出了CIVQLLIE，一个利用因果推理的离散表示学习的强大功能的创新框架。我们通过向量量化（VQ）实现这一点，它将连续图像特征映射到从大规模高质量图像中学到的视觉标记的离散码本。该码本作为可靠的先验，编码独立于退化的标准化亮度和颜色模式。然而，由于退化输入和学习到的码本之间的分布偏移，直接将VQ应用于低光图像会失败。因此，我们提出了一种多层次因果干预方法来系统地校正这些偏移。首先，在编码过程中，我们的像素级因果干预（PCI）模块进行干预，以将低级特征与码本预期的亮度和颜色分布对齐。其次，具有低频选择性注意门控（LSAG）的特征感知因果干预（FCI）机制识别并增强受照度退化影响最大的通道，从而在通过灵活的特征级干预增强编码器的泛化性能的同时，促进准确的码本标记匹配。最后，在解码过程中，高频细节重建模块（HDRM）利用匹配的码本表示中保留的结构信息，使用可变形卷积技术重建精细细节。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [807] [WaMo: Wavelet-Enhanced Multi-Frequency Trajectory Analysis for Fine-Grained Text-Motion Retrieval](https://arxiv.org/abs/2508.03343)
> *小波增强多频轨迹分析用于细粒度文本-动作检索*

*Junlong Ren, Gangjian Zhang, Honghao Fu, Pengcheng Wu, Hao Wang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 文本-动作检索, 小波变换, 多频特征, 细粒度对齐, 3D运动

**Comment:** 

> **TL;DR:** WaMo是一种新颖的小波增强多频特征提取框架，用于细粒度文本-动作检索。它通过分解、重建和重排运动信号来捕捉特定部位和随时间变化的运动细节，从而优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的小波增强多频特征提取框架（WaMo），用于解决文本-动作检索（TMR）中的关键挑战，即精确对齐文本描述和3D运动序列。通过其独特的三部分方法（小波分解、小波重建和无序序列预测），WaMo能够捕捉到传统方法忽略的细粒度运动细节，从而在两个标准数据集上取得了显著的性能提升。这项工作在人体运动理解和检索领域具有重要意义，为处理复杂时空数据提供了一种有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本-动作检索（TMR）方法难以精确匹配3D动作和文本，因为它们忽略了人体结构和时空动态的复杂性，并且未能区分身体部位及其动态，限制了精确的语义对齐。

**Method:** WaMo框架包含三个主要部分：1）轨迹小波分解，将运动信号分解为保留局部运动学细节和全局运动语义的频率分量。2）轨迹小波重建，使用可学习的反小波变换从提取的特征重建原始关节轨迹。3）无序运动序列预测，重新排序打乱的运动序列以学习固有的时间连贯性。

**Result:** WaMo在HumanML3D和KIT-ML数据集上分别实现了17.0%和18.2%的Rsum提升，优于现有最先进的方法。

**Conclusion:** WaMo通过其小波增强的多频特征提取框架，在细粒度文本-动作检索方面取得了显著的改进，能够精确捕捉运动细节并与文本进行语义对齐。

> **ai_Abstract:** WaMo是一种用于细粒度文本-动作检索的新型框架，通过小波变换分解和重建运动信号，捕捉精细的身体部位和时间动态，实现了比现有方法更好的性能。

> **摘要翻译:** 文本-动作检索（TMR）旨在检索在语义上与文本描述相关的3D运动序列。然而，将3D动作与文本进行匹配仍然极具挑战性，这主要是由于人体结构的复杂性及其时空动态。现有方法常常忽略这些复杂性，依赖于无法区分不同身体部位及其动态的一般编码方法，从而限制了精确的语义对齐。为解决此问题，我们提出了WaMo，一种新颖的小波增强多频特征提取框架。它充分捕捉多分辨率下身体关节上特定部位和随时间变化的运动细节，提取区分性运动特征以实现与文本的细粒度对齐。WaMo包含三个关键组成部分：1）轨迹小波分解将运动信号分解为保留局部运动学细节和全局运动语义的频率分量。2）轨迹小波重建使用可学习的反小波变换从提取的特征重建原始关节轨迹，确保保留重要的时空信息。3）无序运动序列预测重新排序打乱的运动序列以提高对固有时间连贯性的学习，增强动作-文本对齐。大量实验证明了WaMo的优越性，在HumanML3D和KIT-ML数据集上分别实现了17.0%和18.2%的Rsum提升，优于现有最先进（SOTA）的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [808] [CloudBreaker: Breaking the Cloud Covers of Sentinel-2 Images using Multi-Stage Trained Conditional Flow Matching on Sentinel-1](https://arxiv.org/abs/2508.03608)
> *CloudBreaker：利用Sentinel-1上的多阶段训练条件流匹配打破Sentinel-2图像的云覆盖*

*Saleh Sakib Ahmed, Sara Nowreen, M. Sohel Rahman* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-05**

**Keywords:** CloudBreaker, Sentinel-1, Sentinel-2, 流匹配, 遥感

**Comment:** 

> **TL;DR:** CloudBreaker框架利用Sentinel-1雷达数据生成高质量的多光谱Sentinel-2信号（包括RGB图像、NDVI和NDWI），解决了卫星图像在云层覆盖和夜间条件下的限制。该框架采用新颖的多阶段条件潜在流匹配训练方法，并结合了余弦调度，在FID、SSIM（NDWI和NDVI）方面表现出色。

**AI_Comments:** 该研究提出了一种创新的方法，利用Sentinel-1雷达数据克服Sentinel-2光学数据的限制，在遥感领域具有重要意义。将余弦调度与流匹配相结合是该领域的首创。然而，生成图像的SSIM分数表明在结构相似性方面仍有改进的空间。

<details>
  <summary>Details</summary>

**Motivation:** 卫星遥感受到云层覆盖和夜间条件的限制，影响了多光谱图像的可用性和可用性。Sentinel-1雷达图像不受这些因素影响，可提供一致的数据。为了克服这些限制，需要一种从Sentinel-1数据生成Sentinel-2信号的框架。

**Method:** 提出了一种名为CloudBreaker的新颖框架，该框架利用Sentinel-1数据生成多光谱Sentinel-2信号。该方法采用新颖的多阶段训练方法，基于条件潜在流匹配，并首次将余弦调度与流匹配相结合。

**Result:** CloudBreaker在FID方面取得了0.7432的得分，表明生成的 सत光学图像具有高度保真度和真实感。在NDWI方面，SSIM得分为0.6156，在NDVI方面，SSIM得分为0.6874，表明了高度的结构相似性。

**Conclusion:** CloudBreaker是一个有前途的解决方案，可用于通常无法或不可靠的多光谱数据的各种遥感应用。

> **ai_Abstract:** CloudBreaker是一个创新的框架，它利用Sentinel-1雷达数据生成高质量的多光谱Sentinel-2信号，包括RGB图像和植被/水指数（如NDVI、NDWI）。该方法通过多阶段条件潜在流匹配和余弦调度解决了卫星遥感中由云层覆盖和夜间条件引起的数据可用性问题，并在FID和SSIM指标上取得了优异的性能。

> **摘要翻译:** 云层覆盖和夜间条件仍然是卫星遥感的重要限制，常常限制了多光谱图像的可用性和可用性。相比之下，Sentinel-1雷达图像不受云层覆盖的影响，并且可以在任何天气或光照条件下提供一致的数据。为了应对有限的卫星图像的挑战，我们提出了CloudBreaker，一个从Sentinel-1数据生成高质量多光谱Sentinel-2信号的新颖框架。这包括重建光学（RGB）图像以及关键的植被和水指数，如NDVI和NDWI。我们采用了一种基于条件潜在流匹配的新颖多阶段训练方法，并且据我们所知，我们是第一个将余弦调度与流匹配相结合的人。CloudBreaker表现出强大的性能，在Frechet Inception Distance（FID）方面取得了0.7432的得分，表明生成的 सत光学图像具有高度保真度和真实感。该模型在NDWI的结构相似性指数（SSIM）方面也取得了0.6156的得分，在NDVI方面取得了0.6874的得分，表明了高度的结构相似性。这使得CloudBreaker成为多光谱数据通常不可用或不可靠的各种遥感应用的有前途的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [828] [evTransFER: A Transfer Learning Framework for Event-based Facial Expression Recognition](https://arxiv.org/abs/2508.03609)
> *事件驱动的表情识别迁移学习框架*

*Rodrigo Verschae, Ignacio Bugueno-Cordova* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 事件相机,人脸表情识别,迁移学习,时空动态,LSTM

**Comment:** 

> **TL;DR:** 提出了一种名为evTransFER的基于迁移学习的框架，用于事件相机的人脸表情识别。该框架通过在面部重建任务上训练的对抗生成方法提取时空特征，并结合LSTM和TIE表示来捕获长期动态，显著提高了识别精度。

**AI_Comments:** 该研究在事件相机人脸表情识别领域提出了创新的迁移学习框架，通过利用面部重建任务的预训练模型来提升特征提取能力，并结合LSTM和TIE表示来增强对时空动态的捕捉。实验结果表明该方法具有显著的性能优势，为事件相机在情感计算领域的应用提供了有价值的解决方案。然而，未来研究可以进一步探索不同预训练任务对性能的影响，以及该框架在更复杂或多样化的事件数据集上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机具有高时间分辨率和高动态范围，能捕捉有价值的时空动态信息，但其在人脸表情识别方面的应用仍需改进。现有方法在利用事件相机数据进行表情识别时，可能无法充分捕捉人脸的时空动态信息。

**Method:** 提出了一种名为evTransFER的迁移学习框架。该框架的核心是一个特征提取器，通过在面部重建任务上训练对抗生成方法来学习时空动态，然后将训练好的编码器权重转移到表情识别任务中。此外，还设计了一个包含LSTM的架构来捕捉长期表情动态，并引入了一种新的事件表示TIE。

**Result:** 在e-CK+数据库上，evTransFER达到了93.6%的识别率，相比现有最先进的方法，准确率提高了25.9%或更多。这表明该迁移学习方法显著优于从头开始训练网络的方法。

**Conclusion:** evTransFER框架通过迁移学习、LSTM和TIE表示的结合，成功提高了事件相机人脸表情识别的准确性，证明了其在处理这类数据方面的有效性。

> **ai_Abstract:** 本文提出了一种名为evTransFER的迁移学习框架，用于事件相机的人脸表情识别。该框架通过在面部重建任务上预训练特征提取器，然后将其应用于表情识别，有效编码了人脸的时空动态。结合LSTM和TIE表示，evTransFER在e-CK+数据库上取得了93.6%的识别率，显著优于现有方法。

> **摘要翻译:** 事件相机是受生物启发的视觉传感器，能够以微秒级的延迟、高时间分辨率和高动态范围异步捕获像素强度变化，提供了关于场景时空动态的宝贵信息。在本研究中，我们提出了一种基于迁移学习的框架和架构evTransFER，用于使用事件相机进行人脸表情识别。主要贡献是设计了一个用于编码人脸时空动态的特征提取器，该提取器通过在不同问题（面部重建）上训练对抗生成方法，然后将训练好的编码器权重转移到人脸表情识别系统。我们表明，与从头开始训练网络相比，这种提出的迁移学习方法大大提高了识别面部表情的能力。此外，我们提出了一种包含LSTM以捕获更长期的面部表情动态的架构，并引入了一种新的事件表示，称为TIE，这两者都进一步提高了结果。我们在事件相机人脸表情数据库e-CK+上评估了提出的框架，并将其与最先进的方法进行了比较。结果表明，提出的框架evTransFER在e-CK+数据库上实现了93.6%的识别率，与最先进的性能相比，准确率显著提高了25.9%或更多。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [829] [SemiSegECG: A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
> *半监督心电图分割：用于心电图描绘的多种数据集基准*

*Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo* | **Category: cs.CV, cs.AI, cs.LG, eess.SP** | **Updated: 2025-08-05**

**Keywords:** 心电图描绘,半监督学习,语义分割,数据集基准,Transformer

**Comment:** Accepted by CIKM 2025. The code is available at
  https://github.com/bakqui/semi-seg-ecg

> **TL;DR:** 该研究提出了SemiSegECG，一个用于半监督心电图描绘的基准，整合了多个数据集，并评估了五种半监督算法在卷积网络和Transformer架构上的表现，提出了ECG特定的训练和增强策略，结果显示Transformer优于卷积网络。

**AI_Comments:** 这项研究的创新性在于提出了一个专门针对心电图描绘的半监督语义分割基准（SemiSegECG），解决了该领域公共标注数据集稀缺的问题。通过整合多个数据集和评估多种算法及架构，该研究为后续研究提供了坚实的基础。提出的ECG特定训练配置和数据增强策略也具有重要的实际意义。然而，该研究的局限性可能在于数据集的统一和预处理过程的细节并未详述，以及跨域评估的普适性仍需进一步验证。总的来说，这项工作对于推动心电图分析的自动化和智能化具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在心电图描绘方面取得了进展，但公共标注数据集的稀缺限制了其发展。半监督学习可以通过利用大量未标记的心电图数据来解决这个问题。

**Method:** 该研究整合了多个公共心电图数据集，并采用了五种代表性的半监督学习算法，在卷积网络和Transformer两种架构上进行了评估，同时还提出了针对心电图的训练配置和数据增强策略，并建立了一个标准化的评估框架。

**Result:** 在半监督心电图描绘方面，Transformer架构的表现优于卷积网络。

**Conclusion:** SemiSegECG基准将为推进半监督心电图描绘方法奠定基础，并促进该领域的进一步研究。

> **ai_Abstract:** 该研究提出了SemiSegECG，这是首个用于心电图描绘半监督语义分割的系统性基准。该基准整合了多个公共数据集，评估了五种半监督学习算法在卷积网络和Transformer架构上的表现，并提出了ECG特定的训练配置和数据增强策略。研究结果表明，Transformer在半监督心电图描绘方面优于卷积网络，该基准有望推动该领域的研究。

> **摘要翻译:** 心电图（ECG）描绘，即有意义的波形特征分割，对于临床诊断至关重要。尽管深度学习取得了最新进展，但由于公开标注数据集的稀缺，进展有限。半监督学习通过利用丰富的未标注心电图数据，提供了一个有前途的解决方案。在本研究中，我们提出了SemiSegECG，这是第一个用于心电图描绘半监督语义分割（SemiSeg）的系统性基准。我们整理并统一了多个公共数据集，包括以前未充分利用的来源，以支持稳健和多样化的评估。我们采用了五种代表性的SemiSeg算法，将它们应用于两种不同的架构：卷积网络和Transformer，并在两种不同的设置下进行了评估：域内和跨域。此外，我们提出了ECG特定的训练配置和数据增强策略，并引入了一个标准化的评估框架。我们的结果表明，Transformer在半监督ECG描绘方面优于卷积网络。我们预期SemiSegECG将为推进半监督ECG描绘方法奠定基础，并促进该领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [831] [Enhancing Long Video Question Answering with Scene-Localized Frame Grouping](https://arxiv.org/abs/2508.03009)
> *增强长视频问答的场景定位帧分组*

*Xuyi Yang, Wenhao Zhang, Hongbo Jin, Lin Liu, Hongbo Xu, Yongwei Nie, Fei Yu, Fei Ma* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 长视频问答,多模态大语言模型,场景理解,帧分组,LVSQA数据集

**Comment:** 

> **TL;DR:** 该研究提出了一种名为SLFG的新方法，通过将视频帧组合成语义连贯的场景帧来提高多模态大语言模型在长视频理解方面的能力，并发布了用于评估场景感知能力的新数据集SceneQA和LVSQA。

**AI_Comments:** 这项研究提出的SLFG方法在解决长视频理解的挑战方面具有创新性，通过将帧分组为场景，有效地解决了信息过载和相关性提取的问题。新提出的SceneQA任务和LVSQA数据集为该领域的研究提供了宝贵的资源，有助于更准确地评估模型能力。该方法即插即用的特性使其易于集成到现有系统中，具有很高的实用价值。未来的工作可以进一步探索不同场景分组策略和更精细的推理机制。

<details>
  <summary>Details</summary>

**Motivation:** 现有长视频理解方法在处理大量帧时面临资源限制，且现有评估任务未能满足实际应用中对场景细节感知和推理的需求。

**Method:** 提出了一种名为SLFG的新方法，该方法结合了场景定位方法和动态帧重组机制，将单个视频帧组合成语义连贯的场景帧，以增强长视频理解能力。同时，还提出了SceneQA新任务和LVSQA数据集，用于支持和评估该方法。

**Result:** SLFG方法在多项长视频基准测试中表现出色，显著增强了现有模型在长视频中的理解能力。

**Conclusion:** 所提出的SLFG方法通过场景定位和动态帧重组，有效解决了多模态大语言模型在长视频理解中的挑战，并证明了其在提升模型性能方面的有效性。新提出的SceneQA任务和LVSQA数据集为评估长视频场景感知能力提供了新的标准。

> **ai_Abstract:** 该论文针对多模态大语言模型在长视频理解方面存在的资源限制和信息提取挑战，提出了新的场景问答（SceneQA）任务和LVSQA数据集，以更公平地评估模型在长视频中的场景感知能力。研究引入了一种名为SLFG的新方法，该方法通过场景定位和动态帧重组将单个帧组合成语义连贯的场景帧，从而增强现有模型的长视频理解能力。SLFG具有即插即用性，无需修改模型架构，并在多项长视频基准测试中取得了优异的实验结果。

> **摘要翻译:** 当前多模态大语言模型（MLLMs）在长视频理解方面表现不佳，这主要是由于资源限制导致它们无法处理所有视频帧及其相关信息。高效地提取相关信息已成为一项艰巨的任务。现有的框架和评估任务侧重于从大量无关帧中识别包含核心对象的特定帧，这并不符合现实世界应用的实际需求。为了解决这个问题，我们提出了视频问答任务下的一个新场景，即SceneQA，它强调基于场景的细节感知和推理能力。我们开发了LVSQA数据集来支持SceneQA任务，该数据集基于精心挑选的LVBench视频，并包含新收集的问答对，以促进对MLLMs在长视频场景感知能力进行更公平的评估。受人类认知启发，我们引入了一种名为SLFG的新颖方法。SLFG的核心思想是将单个帧组合成语义连贯的场景帧。通过利用场景定位方法和动态帧重组机制，SLFG显著增强了现有MLLMs在长视频中的理解能力。SLFG无需修改原始模型架构，并具有出色的即插即用性。实验结果表明，该方法在多项长视频基准测试中表现出色。代码和数据集将在http://www.slfg.pkuzwh.cn发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [832] [GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations](https://arxiv.org/abs/2508.03209)
> *GeoShield：通过对抗性扰动保护地理位置隐私免受视觉语言模型的侵害*

*Xinwei Liu, Xiaojun Jia, Yuan Xun, Simeng Qin, Xiaochun Cao* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 地理位置隐私, 视觉语言模型, 对抗性扰动, GeoShield, 隐私保护

**Comment:** 

> **TL;DR:** GeoShield是一个新的框架，通过在图像中添加微小的、不易察觉的扰动来保护用户的地理位置隐私，防止其被视觉语言模型（VLMs）泄露，同时保持图像的视觉和语义质量。

**AI_Comments:** 该研究首次提出使用对抗性扰动来防御先进VLMs的地理位置推断，解决了现有方法的局限性，并在实际应用中展示了其有效性。GeoShield框架的设计具有创新性，能够有效分离地理信息并适应不同分辨率，为保护用户隐私提供了重要的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 随着视觉语言模型（VLMs）能够从图像中推断用户位置，用户的地理位置隐私面临风险。现有的对抗性扰动方法在处理高分辨率图像和低扰动预算时效果不佳，并且可能引入不相关的语义内容。

**Method:** GeoShield框架包含三个模块：1. 特征解耦模块：分离地理信息和非地理信息。2. 暴露元素识别模块：精确定位图像中泄露地理信息的区域。3. 尺度自适应增强模块：同时优化全局和局部扰动，以适应不同分辨率。

**Result:** 实验表明，GeoShield在黑盒设置下持续优于现有方法，在最小化视觉和语义影响的同时，实现了强大的隐私保护。

**Conclusion:** GeoShield是首个用于防御先进VLMs地理位置推断的对抗性扰动方法，为日益增长的隐私问题提供了一个实用且有效的解决方案。

> **ai_Abstract:** GeoShield是一个创新的框架，旨在解决视觉语言模型（VLMs）从图像中推断用户地理位置所带来的隐私风险。它通过引入特征解耦、暴露元素识别和尺度自适应增强等模块，有效地分离地理信息，精确定位泄露信息的区域，并优化扰动以适应不同分辨率，从而在保护地理隐私的同时，最大限度地减少对图像视觉和语义质量的影响。

> **摘要翻译:** 视觉语言模型（VLMs），如GPT-4o，现在能够从公开分享的图像中推断出用户的地理位置，对地理隐私构成重大风险。尽管对抗性扰动提供了一种潜在的防御手段，但现有方法在这种情况下并不适用：它们在高分辨率图像和低扰动预算下表现不佳，并且可能会引入不相关的语义内容。为了解决这些局限性，我们提出了GeoShield，一个新颖的对抗性框架，旨在为现实场景中的鲁棒地理隐私保护。GeoShield包含三个关键模块：一个分离地理和非地理信息的特征解耦模块，一个精确定位图像中泄露地理信息的暴露元素识别模块，以及一个联合优化全局和局部扰动的尺度自适应增强模块，以确保在不同分辨率下的有效性。在具有挑战性基准上的广泛实验表明，GeoShield在黑盒设置下持续优于现有方法，在最小化视觉或语义质量影响的同时实现了强大的隐私保护。据我们所知，这项工作首次探索了使用对抗性扰动来防御来自先进VLMs的地理位置推断，为日益增长的隐私问题提供了一个实用且有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [835] [Neuro-3D: Towards 3D Visual Decoding from EEG Signals](https://arxiv.org/abs/2411.12248)
> *神经三维：面向从脑电信号进行三维视觉解码*

*Zhanqiang Guo, Jiamin Wu, Yonghao Song, Jiahui Bu, Weijian Mai, Qihao Zheng, Wanli Ouyang, Chunfeng Song* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 脑电信号, 三维视觉解码, Neuro-3D, EEG-3D, 神经表征

**Comment:** 

> **TL;DR:** 本研究首次探索了基于脑电信号的三维视觉解码，提出了Neuro-3D框架和EEG-3D数据集，能够高保真地重建三维物体的形状和颜色，并进行有效的脑区分析。

**AI_Comments:** 该研究在三维视觉解码领域具有开创性，首次利用脑电信号实现了对三维物体形状和颜色的解码，并提供了EEG-3D数据集作为基准。其提出的Neuro-3D框架能够有效整合不同刺激类型的脑电特征，并具有进行脑区分析的潜力，为理解大脑视觉感知机制提供了新的工具和视角。然而，仅从脑电信号解码复杂的三维视觉信息仍面临挑战，未来研究可进一步探索更精细的解码精度和更广泛的视觉场景。

<details>
  <summary>Details</summary>

**Motivation:** 理解大脑如何感知和处理现实世界中的三维视觉刺激是神经科学中的一个长期目标。

**Method:** 提出了一种基于脑电信号的三维视觉解码框架Neuro-3D，该框架自适应地整合了来自静态和动态刺激的脑电特征，并使用基于扩散的彩色点云解码器来恢复三维物体的形状和颜色。同时，构建了一个包含多模态分析数据和大规模脑电记录的EEG-3D数据集。

**Result:** Neuro-3D能够高保真地重建彩色三维物体，并且学习到的神经表征能够进行有意义的脑区分析。

**Conclusion:** Neuro-3D框架在基于脑电信号的三维视觉解码任务上取得了成功，为理解大脑三维视觉感知提供了新的途径。

> **ai_Abstract:** 本研究旨在解码大脑对三维视觉刺激的感知过程，并提出了名为Neuro-3D的框架以及EEG-3D数据集。Neuro-3D利用脑电信号，通过整合静态和动态刺激的特征，并结合扩散模型解码器，成功地重建了三维物体的形状和颜色，同时还能进行脑区分析。该研究是首次在脑电信号基础上进行三维视觉解码的探索。

> **摘要翻译:** 人类对视觉世界的感知是由三维信息的立体处理所塑造的。理解大脑如何在现实世界中感知和处理三维视觉刺激一直是神经科学中的一项长期努力。为了实现这一目标，我们引入了一项新的神经科学任务：从脑电信号（一种能够实时监测神经动力学并富含复杂视觉线索的神经成像技术）解码三维视觉感知。为了提供关键的基准，我们首先提出了EEG-3D，这是一个开创性的数据集，包含多模态分析数据和来自12名受试者观看72类三维物体（以视频和图像形式呈现）的大规模脑电记录。此外，我们提出了Neuro-3D，一个基于脑电信号的三维视觉解码框架。该框架自适应地整合了从静态和动态刺激中提取的脑电特征，以学习互补且鲁棒的神经表征，随后利用这些表征通过提出的基于扩散的彩色点云解码器来恢复三维物体的形状和颜色。据我们所知，我们是第一个探索基于脑电信号的三维视觉解码的研究。实验表明，Neuro-3D不仅能高保真地重建彩色三维物体，还能学习到有效的神经表征，从而能够进行有洞察力的脑区分析。该数据集及相关代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [840] [FedPromo: Federated Lightweight Proxy Models at the Edge Bring New Domains to Foundation Models](https://arxiv.org/abs/2508.03356)
> *FedPromo：边缘的联邦轻量级代理模型为基础模型带来新领域*

*Matteo Caligiuri, Francesco Barbato, Donald Shenaj, Umberto Michieli, Pietro Zanuttigh* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 联邦学习, 轻量级代理模型, 知识蒸馏, 边缘计算, 基础模型

**Comment:** 7 pages (main document) + 12 pages (appendix), 3 figures (main) + 12
  figures (appendix), 5 tables (main) + 6 tables (appendix), submitted to AAAI
  2026

> **TL;DR:** FedPromo是一个联邦学习框架，通过在客户端优化轻量级代理模型来适应新的领域，从而降低计算开销并保护隐私，在有限资源的客户端上表现优于现有方法。

**AI_Comments:** FedPromo在联邦学习领域提出了一个有前景的解决方案，特别是在处理资源受限的边缘设备时。其通过知识蒸馏和轻量级代理模型的设计，有效地平衡了模型性能、隐私保护和计算效率。然而，该方法在不同领域和模型架构上的泛化能力以及实际部署中的可扩展性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦学习方法在处理大型模型时需要大量客户端计算资源，这对于资源受限的设备来说是不可行的。

**Method:** FedPromo采用两阶段方法：首先，服务器端知识蒸馏将大型基础模型（如Transformer）的表示与紧凑型模型（如CNN）的表示对齐；然后，将紧凑型模型的编码器部署到客户端设备，在本地训练可训练的分类器；最后，聚合这些分类器并将其转移回基础模型，实现个性化适应。

**Result:** FedPromo在五个图像分类基准测试中表现优于现有方法，同时考虑了资源受限的客户端。

**Conclusion:** FedPromo框架通过轻量级代理模型实现了在资源受限的客户端上的高效、隐私保护的个性化适应，并在多领域学习方面取得了良好的平衡。

> **ai_Abstract:** FedPromo是一个创新的联邦学习框架，旨在解决在资源受限的客户端设备上适应大型基础模型的问题。该框架通过在客户端训练轻量级代理模型，并在服务器端进行知识蒸馏和聚合，有效降低了计算开销并保护了用户隐私。实验结果表明，FedPromo在多领域学习任务中表现出色，优于现有方法。

> **摘要翻译:** 联邦学习（FL）是在分散式数据上训练深度学习模型的既定范例。然而，随着模型尺寸的增大，传统的FL方法通常需要在客户端设备上占用大量的计算资源，这可能并不可行。我们提出了FedPromo，一个新颖的框架，能够将存储在中央服务器上的大规模基础模型高效地适应到仅由远程客户端遇到的新领域。FedPromo不直接在客户端设备上训练大型模型，而是通过FL优化轻量级代理模型，在保持隐私的同时显著降低了计算开销。我们的方法遵循一个两阶段过程：首先，服务器端知识蒸馏将大规模基础模型（例如Transformer）的表示与紧凑型模型（例如CNN）的表示对齐。然后，将紧凑型模型的编码器部署到客户端设备，在本地学习可训练的分类器。随后，这些分类器被聚合起来，并无缝地转移回基础模型，从而在不直接访问用户数据的情况下实现个性化适应。通过新颖的正则化策略，我们的框架实现了分散式的多领域学习，平衡了性能、隐私和资源效率。在五个图像分类基准测试上进行的广泛实验表明，FedPromo在假设客户端资源有限的情况下，其性能优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [841] [CHIRP: A Fine-Grained Benchmark for Open-Ended Response Evaluation in Vision-Language Models](https://arxiv.org/abs/2501.09672)
> *CHIRP：视觉语言模型开放式响应评估的细粒度基准*

*Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony, Edwin Fennell, Irina Rish* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视觉语言模型, VLM评估, CHIRP基准, Robin VLM套件, 开放式响应

**Comment:** 

> **TL;DR:** 该论文提出了CHIRP，一个用于评估视觉语言模型（VLMs）开放式响应的新基准，并介绍了Robin VLM套件，用于识别现有评估方法的不足。

**AI_Comments:** 该研究在VLM评估领域提出了一个重要的贡献，即CHIRP基准。通过结合Robin VLM套件的开发和现有评估方法的分析，该研究为解决VLM评估的挑战提供了一个新的视角和工具。开放获取的策略也值得称赞，有助于推动整个领域的进步。

<details>
  <summary>Details</summary>

**Motivation:** 随着视觉语言模型（VLMs）的广泛应用，需要对其进行严格和全面的评估。现有的评估方法存在不足。

**Method:** 分析了现有的VLM评估技术，包括自动化指标、基于AI的评估和人类评估。开发了Robin VLM套件，并在此基础上提出了CHIRP基准。

**Result:** 识别出现有VLM评估方法的局限性，并提出了CHIRP作为一种更鲁棒、更完整的VLM评估方法。

**Conclusion:** CHIRP是一个新的长回复基准，可以更全面地评估VLMs。Robin VLM套件和CHIRP基准的开放获取将促进VLM研究。

> **ai_Abstract:** 该研究针对视觉语言模型（VLMs）的评估问题，首先分析了现有评估方法的局限性，然后介绍了名为Robin的VLM套件，并在此基础上提出了CHIRP基准。CHIRP是一个新的长回复基准，旨在提供更全面、更鲁棒的VLM评估。研究团队已开放Robin的训练代码、模型套件和CHIRP基准，以促进相关研究。

> **摘要翻译:** 近年来，视觉语言模型（VLMs）的激增，要求对其进行严格和全面的评估方法和基准。这项工作分析了现有的VLM评估技术，包括自动化指标、基于AI的评估和跨不同任务的人类评估。我们首先介绍了Robin——我们通过在多个尺度上结合大型语言模型（LLMs）和视觉编码器（VEs）构建的一个新颖的VLM套件，并利用Robin识别现有评估方法在不同尺度上的不足。接下来，为了克服已识别的局限性，我们提出了CHIRP——一个我们为更鲁棒和完整的VLM评估而开发的新长回复基准。我们开放获取Robin训练代码、模型套件和CHIRP基准，以促进可重复性并推进VLM研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [848] [FPG-NAS: FLOPs-Aware Gated Differentiable Neural Architecture Search for Efficient 6DoF Pose Estimation](https://arxiv.org/abs/2508.03618)
> *面向高效6DoF位姿估计的感知门控可微分神经架构搜索*

*Nassim Ali Ousalah, Peyman Rostami, Anis Kacem, Enjie Ghorbel, Emmanuel Koumandakis, Djamila Aouada* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 6DoF位姿估计, 可微分神经架构搜索, FLOPs感知, 门控机制, 高效推理

**Comment:** Accepted to the 27th IEEE International Workshop on Multimedia Signal
  Processing (MMSP) 2025

> **TL;DR:** FPG-NAS是一种新颖的感知门控可微分神经架构搜索框架，专门用于高效的6DoF位姿估计，通过特定的搜索空间和门控机制提升了架构多样性，并利用FLOPs正则化在准确性和效率之间取得了平衡，在LINEMOD和SPEED+数据集上表现优于现有方法。

**AI_Comments:** 该研究是首个将可微分神经架构搜索（NAS）应用于6DoF位姿估计领域的开创性工作，其提出的感知门控机制和FLOPs正则化策略有效地解决了现有方法在计算效率方面的瓶颈。然而，对于其搜索空间的设计和门控机制的普适性，可能还需要进一步的探究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 从单张图像估计3D旋转和平移（6DoF位姿估计）虽然被广泛研究，但计算成本高昂，限制了其在资源受限场景下的应用。

**Method:** 提出了一种专门针对6DoF位姿估计的可微分神经架构搜索（NAS）方法，该方法包含一个任务特定的搜索空间和一个可微分的门控机制，用于离散的多候选操作符选择，并引入了FLOPs正则化项以平衡准确性和效率。该框架探索了大约10^92种可能的架构。

**Result:** 在LINEMOD和SPEED+数据集上的实验表明，FPG-NAS导出的模型在严格的FLOPs约束下优于先前的方法。

**Conclusion:** FPG-NAS是首个专门为6DoF位姿估计设计的可微分神经架构搜索框架，能够生成在效率和准确性之间取得良好平衡的模型。

> **ai_Abstract:** FPG-NAS是一种新颖的神经架构搜索（NAS）框架，专门用于解决6DoF位姿估计中的计算效率问题。它通过引入任务特定的搜索空间、可微分门控机制和FLOPs正则化，实现了在准确性和计算成本之间的优化权衡。实验结果表明，FPG-NAS在资源受限的条件下优于现有方法。

> **摘要翻译:** 我们引入了FPG-NAS，一个用于高效6DoF物体位姿估计的感知门控可微分神经架构搜索框架。从单张图像估计3D旋转和平移（6DoF位姿估计）虽然被广泛研究，但计算成本高昂，限制了其在资源受限场景下的应用。FPG-NAS通过提出一种专门针对6DoF位姿估计的可微分NAS方法来解决这个问题，该方法具有一个任务特定的搜索空间和一个可微分的门控机制，能够实现离散的多候选操作符选择，从而提高架构多样性。此外，一个FLOPs正则化项确保了准确性和效率之间的平衡。该框架探索了大约10^92种可能的架构。在LINEMOD和SPEED+数据集上的实验表明，FPG-NAS导出的模型在严格的FLOPs约束下优于先前的方法。据我们所知，FPG-NAS是首个专门为6DoF物体位姿估计设计的可微分NAS框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [864] [Retinal Lipidomics Associations as Candidate Biomarkers for Cardiovascular Health](https://arxiv.org/abs/2508.03538)
> *视网膜脂质组学关联作为心血管健康的候选生物标志物*

*Inamullah, Imran Razzak, Shoaib Jameel* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 脂质组学, 视网膜微血管, 生物标志物, 代谢健康, 深度学习

**Comment:** 

> **TL;DR:** 该研究首次将深度学习衍生的视网膜特征与脂质组学特征相结合，发现不同的血脂亚类与视网膜微血管特征相关，支持其作为系统代谢健康的无创标志物。

**AI_Comments:** 这项研究通过结合先进的脂质组学分析和深度学习驱动的视网膜成像技术，为理解脂质代谢与微血管健康之间的联系提供了有价值的见解。研究的优势在于使用了大型人群队列，并排除了疾病和治疗的影响，这使得研究结果更具普遍性和可靠性。然而，研究可能未充分探讨脂质亚类与视网膜特征之间潜在的因果关系，以及这些发现转化为临床实践的具体途径。未来的研究可以进一步探索这些关联的机制，并开发相应的诊断或治疗策略。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视网膜微血管成像可用于评估全身血管和代谢健康，但脂质组学与视网膜血管之间的关联尚不充分。

**Method:** 使用 Spearman 相关分析和 Benjamini-Hochberg 错误发现率（BH-FDR）调整，研究了血清脂质亚类（游离脂肪酸、二酰甘油、三酰甘油、胆固醇酯）与十种视网膜微血管特征之间的关系。

**Result:** 结果显示，游离脂肪酸与视网膜血管扭曲度相关；胆固醇酯与动脉和静脉的平均宽度相关；二酰甘油和三酰甘油与小动脉和小静脉的宽度和复杂性呈负相关。

**Conclusion:** 视网膜血管结构反映了不同的循环脂质特征，支持其作为系统代谢健康的无创标志物。

> **ai_Abstract:** 本研究旨在探索血清脂质亚类与视网膜微血管特征之间的关系，以评估视网膜作为代谢健康标志物的潜力。研究发现，不同的脂质亚类（如 FA、CE、DAG、TAG）与视网膜血管的宽度、扭曲度和复杂性等特征相关。这项工作首次结合了深度学习衍生的视网膜特征和脂质组学数据，为理解微血管结构变化提供了新视角。

> **摘要翻译:** 视网膜微血管成像越来越多地被认为是评估全身血管和代谢健康的非侵入性方法。然而，脂质组学与视网膜血管之间的关联仍然不足。本研究在一个大型人群队列中调查了血清脂质亚类、游离脂肪酸（FA）、二酰甘油（DAG）、三酰甘油（TAG）和胆固醇酯（CE）与视网膜微血管特征之间的关系。我们使用 Spearman 相关分析，并通过 Benjamini-Hochberg 错误发现率（BH-FDR）调整来检验脂质亚类与十种视网膜微血管特征之间的相互联系。结果表明，FA 与视网膜血管扭曲度有关，而 CE 与动脉和静脉的平均宽度相关。相反，DAG 和 TAG 与小动脉和小静脉的宽度和复杂性呈负相关。这些发现表明，视网膜血管结构反映了不同的循环脂质特征，支持其作为系统代谢健康的无创标志物。本研究首次将深度学习（DL）衍生的视网膜特征与脂质组学亚类整合到一个健康队列中，从而在没有疾病状态或治疗效果影响的情况下，为微血管结构变化提供了见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [869] [SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting](https://arxiv.org/abs/2508.03017)
> *3D高斯泼溅的自适应压缩方法*

*Liheng Zhang, Weihao Yu, Zubo Lu, Haozhi Gu, Jin Huang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D高斯泼溅, 压缩, 重要性分数, 码本修复, 渲染质量, SA-3DGS

**Comment:** 9 pages, 7 figures. Under review at AAAI 2026

> **TL;DR:** 该方法通过学习重要性分数来识别并移除不重要的3D高斯点，然后进行压缩和修复，以减小存储需求并保持渲染质量。

**AI_Comments:** 该方法在解决3D高斯泼溅的存储瓶颈方面取得了显著进展，通过引入“重要性分数”和创新的压缩与修复机制，实现了高效压缩和高质量渲染的平衡。其对其他方法的改进和良好的泛化能力也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅方法需要大量高斯点，导致存储需求高，限制了实际应用。现有压缩方法难以识别真正不重要的点，影响了剪枝、压缩质量和渲染性能。

**Method:** 提出SA-3DGS方法，通过学习重要性分数自动识别不显著的高斯点以进行剪枝和冗余减少；然后使用重要性感知聚类模块将高斯点属性压缩到码本中以提高表达能力并减小模型尺寸；最后，利用上下文场景信息修复码本，恢复原始高斯点属性，减轻信息丢失导致的渲染质量下降。

**Result:** 在多个基准数据集上实现了高达66倍的压缩率，同时保持甚至提高了渲染质量。该方法还可以改进其他基于剪枝的方法（如LightGaussian），表现出优异的性能和泛化能力。

**Conclusion:** SA-3DGS通过学习重要性分数、重要性感知聚类和码本修复，有效降低了3D高斯泼溅的存储成本，同时保持了渲染质量，并能提升其他压缩方法。

> **ai_Abstract:** SA-3DGS是一种创新的3D高斯泼溅压缩方法，通过学习高斯点的重要性分数来识别和移除不显著的点，随后利用重要性感知聚类和码本修复技术，在大幅降低存储占用的同时，有效保持甚至提升了渲染质量。

> **摘要翻译:** 近期3D高斯泼溅的进展增强了高效、高质量的新视点合成。然而，场景的表示需要大量的高斯点，导致高存储需求并限制了实际部署。最新的方法促进了高斯模型的压缩，但难以识别场景中真正不重要的“高斯点”，从而导致后续的高斯剪枝、压缩质量和渲染性能下降。为了解决这个问题，我们提出了SA-3DGS，一种在保持渲染质量的同时显著降低存储成本的方法。SA-3DGS学习一个重要性分数，以自动识别场景重建中最不显著的高斯点，从而实现有效的剪枝和冗余减少。接下来，重要性感知聚类模块将高斯属性更准确地压缩到码本中，提高了码本的表达能力，同时减小了模型尺寸。最后，码本修复模块利用上下文场景信息来修复码本，从而恢复原始高斯点属性，并减轻了因信息丢失而导致的渲染质量下降。在多个基准数据集上的实验结果表明，我们的方法实现了高达66倍的压缩率，同时保持甚至提高了渲染质量。所提出的高斯剪枝方法不仅适用于其他基于剪枝的方法（例如LightGaussian），而且还能改进它们，展示了优异的性能和强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [876] [The Power of Many: Synergistic Unification of Diverse Augmentations for Efficient Adversarial Robustness](https://arxiv.org/abs/2508.03213)
> *众多力量的融合：协同统一多样化增强以实现高效对抗鲁棒性*

*Wang Yu-Hang, Shiwei Li, Jianxiang Liao, Li Bohan, Jian Liu, Wenfei Yin* | **Category: cs.CV, cs.AI, C.1.2** | **Updated: 2025-08-05**

**Keywords:** 对抗鲁棒性, 数据增强, 协同作用, 通用对抗增强器, 效率

**Comment:** 13 pages,2 figures,6 tables

> **TL;DR:** 该研究提出了一种名为通用对抗增强器（UAA）的框架，通过预先计算通用变换并离线生成对抗性扰动，解决了现有对抗训练计算成本高和标准性能下降的问题。UAA具有即插即用和训练高效的特点，并在多个基准测试中验证了其有效性，成为数据增强对抗防御策略的新 SOTA。

**AI_Comments:** 该研究提出的UAA框架通过离线预计算通用变换来解决对抗训练的效率问题，这是一个有价值的创新。然而，该方法在面对不同类型的对抗性攻击时，其泛化能力和鲁棒性的具体表现仍需进一步探索。此外，虽然提到了协同作用的重要性，但具体如何最优地组合和平衡不同的增强策略是未来研究的一个重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 对抗性扰动威胁深度学习模型，现有的对抗训练（AT）方法计算成本高且会降低标准性能。数据增强是另一种方法，但现有技术鲁棒性增益有限或训练开销大。因此，开发一种高效且鲁棒的防御机制至关重要。

**Method:** 该研究提出了一种名为通用对抗增强器（UAA）的框架，该框架具有即插即用和训练高效的特点。UAA通过离线预计算一个通用变换，将昂贵的扰动生成过程与模型训练分离，然后在训练期间为每个样本高效地生成独特的对抗性扰动。

**Result:** 在多个基准测试上的广泛实验证明了UAA的有效性。结果表明，UAA在数据增强的对抗防御策略方面达到了新的 state-of-the-art (SOTA)，并且不需要在训练期间在线生成对抗性样本。

**Conclusion:** UAA框架通过协同统一多样化的数据增强技术，提供了一种高效且强大的对抗鲁棒性解决方案，为构建鲁棒模型提供了一条实用且高效的途径。

> **ai_Abstract:** 本研究提出了一种名为通用对抗增强器（UAA）的框架，旨在解决深度学习模型在对抗性攻击下的鲁棒性问题。通过系统分析发现，多样化数据增强策略的协同作用对提升鲁棒性至关重要。UAA通过将昂贵的扰动生成过程离线化，实现了高效且即插即用的对抗训练，无需在线生成对抗样本，并在多个基准测试中取得了领先的性能。

> **摘要翻译:** 对抗性扰动对深度学习模型构成了重大威胁。对抗性训练（AT）是主要的防御方法，但面临计算成本高和标准性能下降的挑战。虽然数据增强提供了一条替代途径，但现有技术要么鲁棒性增益有限，要么训练开销巨大。因此，开发一种既高效又鲁棒的防御机制至关重要。在本研究中，我们首先对现有的增强技术进行了系统的分析，揭示了增强鲁棒性关键在于多样化策略之间的协同作用，而非单一方法。基于这一见解，我们提出了通用对抗增强器（UAA）框架，其特点是即插即用和训练高效。UAA通过离线预计算一个通用变换，将昂贵的扰动生成过程与模型训练分离开来，然后在训练期间高效地为每个样本生成独特的对抗性扰动。在多个基准测试上进行的广泛实验验证了UAA的有效性。结果表明，UAA在基于数据增强的对抗防御策略方面达到了新的 state-of-the-art (SOTA)，并且不需要在训练期间在线生成对抗性样本。该框架为构建鲁棒模型提供了一条实用且高效的途径。我们的代码可在补充材料中找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [877] [Diffusion Once and Done: Degradation-Aware LoRA for Efficient All-in-One Image Restoration](https://arxiv.org/abs/2508.03373)
> *一次性完成的扩散：用于高效一体化图像恢复的退化感知LoRA*

*Ni Tang, Xiaotong Luo, Zihan Cheng, Liangtai Zhou, Dongxiao Zhang, Yanyun Qu* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 一体化图像恢复, 扩散模型, 低秩适应, 特征调制, 高效推理

**Comment:** 

> **TL;DR:** 提出了一种名为DOD的高效一体化图像恢复方法，它使用Stable Diffusion模型进行单步采样，并通过特征调制和低秩适应来处理多种退化，同时增强细节，实现了优于现有方法的视觉质量和推理效率。

**AI_Comments:** 该方法通过创新的特征调制和低秩适应技术，显著提高了扩散模型在图像恢复任务中的效率和适应性，特别是在单步采样下实现了高性能，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的一体化图像恢复（AiOIR）方法要么需要重新训练扩散模型，要么需要额外的条件引导来微调预训练模型，这导致高推理成本和对不同退化类型的适应性有限。

**Method:** 提出了一种名为DOD的高效AiOIR方法，该方法使用Stable Diffusion（SD）模型进行单步采样。具体而言，首先引入多退化特征调制来捕获不同的退化提示，然后参数高效的条件低秩适应（LoRA）集成这些提示以适应不同退化类型。此外，在SD的解码器中集成了高保真细节增强模块以改善结构和纹理细节。

**Result:** 实验表明，所提出的方法在视觉质量和推理效率方面均优于现有的基于扩散的恢复方法。

**Conclusion:** DOD方法通过单步采样、多退化特征调制和低秩适应，实现了高效且适应性强的一体化图像恢复，并在视觉质量和推理效率上超越了现有方法。

> **ai_Abstract:** 本文提出了一种名为DOD的高效一体化图像恢复（AiOIR）方法，该方法利用Stable Diffusion（SD）模型的单步采样，并通过多退化特征调制和参数高效的条件低秩适应（LoRA）来处理不同退化类型。此外，还集成了一个高保真细节增强模块来提升恢复图像的质量。实验证明，DOD在视觉质量和推理效率上均优于现有的基于扩散的恢复方法。

> **摘要翻译:** 扩散模型在处理各种退化类型的一体化图像恢复（AiOIR）方面展现了强大的潜力，能够生成丰富的纹理细节。现有的AiOIR方法通常需要重新训练扩散模型或使用额外的条件引导来微调预训练的扩散模型。然而，这些方法往往存在推理成本高和对不同退化类型的适应性有限的问题。在本文中，我们提出了一种高效的AiOIR方法，名为“一次性完成的扩散”（DOD），旨在通过Stable Diffusion（SD）模型的单步采样来实现卓越的恢复性能。具体而言，我们首先引入多退化特征调制来捕获不同的退化提示，并利用预训练的扩散模型。然后，参数高效的条件低秩适应（LoRA）集成这些提示，以实现SD模型的微调，从而适应不同的退化类型。此外，我们还将一个高保真细节增强模块集成到SD的解码器中，以改善结构和纹理细节。实验结果表明，我们的方法在视觉质量和推理效率方面均优于现有的基于扩散的恢复方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [878] [Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images](https://arxiv.org/abs/2508.03643)
> *Uni3R：从无姿态多视图图像通过可泛化高斯飞溅进行统一的3D重建和语义理解*

*Xiangyu Sun, Haoyi jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie wang, Wei Sui, Zhizhong Su, Wenyu Liu, Xinggang Wang, Eunbyung Park* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 3D重建, 语义理解, 高斯飞溅, 跨视图Transformer, 开放词汇

**Comment:** The code is available at https://github.com/HorizonRobotics/Uni3R

> **TL;DR:** Uni3R是一个创新的前馈框架，可以直接从无姿态多视图图像中进行3D重建和语义理解，无需对每个场景进行优化。

**AI_Comments:** 该研究提出了一种新颖的Uni3R框架，能够同时处理3D重建和语义理解任务，解决了传统方法的局限性。其利用跨视图Transformer和3D高斯基元的方法具有创新性，并在多个基准测试中取得了优异的性能，展示了其在通用3D场景处理方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 从稀疏的2D视图中重建和语义理解3D场景是一个基本挑战，传统方法通常将语义理解与重建分离，或者需要昂贵的每场景优化，这限制了它们的可扩展性和泛化性。

**Method:** Uni3R利用跨视图Transformer整合多视图信息，然后回归具有语义特征场的3D高斯基元，实现了高保真新视图合成、开放词汇3D语义分割和深度预测。

**Result:** Uni3R在RE10K上实现了25.07 PSNR，在ScanNet上实现了55.84 mIoU，在多个基准测试中取得了新的最先进成果。

**Conclusion:** Uni3R代表了可泛化的、统一的3D场景重建和理解的新范式。

> **ai_Abstract:** Uni3R是一个创新的前馈框架，能够直接从无姿态的多视图图像中同时进行3D重建和开放词汇语义理解。它利用跨视图Transformer整合信息，并回归具有语义特征场的3D高斯基元，从而实现高保真的新视图合成、3D语义分割和深度预测，在多个基准测试中取得了最先进的成果。

> **摘要翻译:** 从稀疏的2D视图重建和语义解释3D场景是计算机视觉中的一个基本挑战。传统方法通常将语义理解与重建分离，或者需要昂贵的每场景优化，从而限制了它们的可扩展性和泛化性。在本文中，我们介绍了Uni3R，一个新颖的前馈框架，可以直接从无姿态的多视图图像中重建一个统一的3D场景表示，并用开放词汇语义进行丰富。我们的方法利用跨视图Transformer来稳健地整合跨任意多视图输入的信​​息，然后回归一组具有语义特征场的3D高斯基元。这种统一的表示在一次前馈传递中实现了高保真的新视图合成、开放词汇3D语义分割和深度预测。大量实验表明，Uni3R在多个基准测试中取得了新的最先进成果，包括在RE10K上实现了25.07 PSNR和在ScanNet上实现了55.84 mIoU。我们的工作标志着可泛化的、统一的3D场景重建和理解的新范式。代码可在https://github.com/HorizonRobotics/Uni3R找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [879] [Individual Content and Motion Dynamics Preserved Pruning for Video Diffusion Models](https://arxiv.org/abs/2411.18375)
> *视频扩散模型的个体内容和运动动态保留剪枝*

*Yiming Wu, Zhenghao Chen, Huan Wang, Dong Xu* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-05**

**Keywords:** 视频扩散模型, 模型压缩, 剪枝, 个体内容, 运动动态, 一致性损失

**Comment:** ACM MM 2025

> **TL;DR:** 通过个体内容和运动动态保留剪枝以及一致性损失，提出了一种压缩视频扩散模型的新方法VDMini，该方法在保持高质量视频生成的同时显著加快了推理速度。

**AI_Comments:** 该研究有效地解决了视频扩散模型在实际应用中的性能瓶颈。通过对模型层级进行精细化分析，并结合创新的损失函数设计，实现了推理速度和生成质量的良好平衡，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 视频扩散模型（VDMs）计算成本高且推理速度慢，阻碍了其部署。

**Method:** 提出了一种基于个体内容和运动动态保留剪枝及一致性损失的视频扩散模型压缩方法。该方法根据层级对模型进行剪枝，浅层关注个体内容，深层关注运动动态。同时，引入了包括个体内容蒸馏（ICD）损失和多帧内容对抗（MCA）损失在内的一致性损失，以保持生成性能。

**Result:** VDMini显著加速了推理时间，同时保持了高质量的视频生成。在文本到视频（T2V）和图像到视频（I2V）任务上，VDMini分别实现了2.5倍、1.4倍和1.25倍的加速，并且在UCF101、VBench-T2V和VBench-I2V等基准测试中保持了生成质量。

**Conclusion:** 所提出的VDMini方法通过个体内容和运动动态保留剪枝及一致性损失，成功解决了视频扩散模型计算成本高和推理速度慢的问题，实现了推理加速和高质量视频生成。

> **ai_Abstract:** 本研究提出了一种名为VDMini的视频扩散模型压缩方法，通过区分不同层级对内容和运动动态的重要性，对模型进行剪枝，并结合个体内容蒸馏（ICD）和多帧内容对抗（MCA）损失，以在加速推理的同时保持视频生成质量。

> **摘要翻译:** 视频扩散模型（VDMs）高昂的计算成本和缓慢的推理时间是部署它们的主要障碍。为此，我们引入了一种新的视频扩散模型压缩方法，该方法采用个体内容和运动动态保留剪枝以及一致性损失。首先，我们通过实验观察到，VDM的更深层对于保持“运动动态”（例如，整个视频的一致性）至关重要，而较浅层更侧重于“个体内容”（例如，单个帧）。因此，我们在较浅层修剪冗余块，同时保留更多较深层，从而得到一个名为VDMini的轻量级VDM变体。此外，我们提出了一种“个体内容和运动动态”（ICMD）一致性损失，以获得与大型VDM相当的生成性能。具体来说，我们首先使用个体内容蒸馏（ICD）损失来保持教师模型和学生模型之间每帧特征的一致性。接下来，我们引入多帧内容对抗（MCA）损失来增强生成视频整体的运动动态。该方法在保持高质量视频生成的同时，显著加快了推理时间。广泛的实验证明了我们在两个重要的视频生成任务——文本到视频（T2V）和图像到视频（I2V）上VDMini的有效性，我们分别实现了I2V方法SF-V、T2V方法T2V-Turbo-v2和T2V方法HunyuanVideo的平均2.5倍、1.4倍和1.25倍的加速，同时在UCF101、VBench-T2V和VBench-I2V等多个基准上保持了生成视频的质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [900] [IntroStyle: Training-Free Introspective Style Attribution using Diffusion Features](https://arxiv.org/abs/2412.14432)
> *训练免费内省风格归因使用扩散特征*

*Anand Kumar, Jiteng Mu, Nuno Vasconcelos* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-05**

**Keywords:** 风格归因, 扩散模型, 无需训练, 艺术风格, IntroStyle

**Comment:** 17 pages, 16 figures

> **TL;DR:** 本研究提出了一种名为IntroStyle的创新的、无需训练的框架，利用扩散模型的特征来解决风格归因问题，无需外部模块或重新训练。该方法在WikiArt和DomainNet数据集上表现优于现有方法，并且在Artistic Style Split（ArtSplit）数据集上进行了评估。

**AI_Comments:** 该研究提出了一种新颖的、无需训练的风格归因方法，利用扩散模型的内在特征，解决了现有方法在资源消耗和实时性方面的局限性。其创新性在于无需额外的数据集或模型训练即可实现高性能的风格归因。引入ArtSplit数据集用于细粒度评估也是一个亮点。然而，文中提到的\[\]符号指代不明，可能需要进一步澄清。

<details>
  <summary>Details</summary>

**Motivation:** 现有风格提取方法需要收集自定义数据集和训练专用模型，成本高昂且不适用于实时应用。因此，需要一种无需训练即可解决风格归因问题的有效方法。

**Method:** 提出了一种名为IntroStyle的无需训练的框架，仅使用扩散模型生成的特征来解决风格归因问题，无需任何外部模块或重新训练。

**Result:** 在WikiArt和DomainNet数据集上的实验结果表明，IntroStyle能够有效应对艺术风格的动态性，并且在风格归因方面优于现有方法。

**Conclusion:** IntroStyle是一个创新的、无需训练的框架，仅利用扩散模型的特征即可解决风格归因问题，并且在性能上优于现有方法。

> **ai_Abstract:** 本研究提出了一种名为IntroStyle的创新性、无需训练的框架，利用扩散模型的特征来解决风格归因问题，无需外部模块或重新训练。该方法在WikiArt和DomainNet数据集上表现优于现有方法，并且在Artistic Style Split（ArtSplit）数据集上进行了评估。

> **摘要翻译:** 文本到图像（T2I）模型最近被广泛采用。这引发了对保护知识产权的担忧，以及对防止生成特定艺术风格的机制的需求日益增长。现有的风格提取方法通常需要收集自定义数据集和训练专用模型。然而，这成本高昂、耗时，并且通常不适用于实时应用。我们提出了一种新颖的、无需训练的框架来解决风格归因问题，仅使用扩散模型产生的特征，而无需任何外部模块或重新训练。这被称为内省风格归因（IntroStyle），并且在风格归因方面优于最先进的模型。我们还引入了一个名为艺术风格分离（ArtSplit）的合成数据集来分离艺术风格并评估细粒度风格归因性能。我们在WikiArt和DomainNet数据集上的实验结果表明，\[\]对艺术风格的动态性具有鲁棒性，并且在性能上优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [904] [MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention](https://arxiv.org/abs/2508.03034)
> *MoCA：通过交叉注意力混合实现身份保持的文本到视频生成*

*Qi Xie, Yongjia Ma, Donglin Di, Xuehao Gao, Xun Yang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 文本到视频生成, 身份保持, 交叉注意力混合, 扩散Transformer, 时序建模

**Comment:** 

> **TL;DR:** MoCA是一种新的文本到视频生成模型，它通过交叉注意力混合来保持身份一致性，并在CelebIPVid数据集上取得了超过5%的面部相似性提升。

**AI_Comments:** 这项研究提出了一种名为MoCA的新型文本到视频生成模型，它通过引入交叉注意力混合机制来解决现有模型在身份保持方面的挑战。该模型在Diffusion Transformer骨干上进行了构建，并结合了分层时间池化和时序感知交叉注意力专家，以提高帧间身份一致性和捕捉时空关系。此外，还使用了潜在视频感知损失来增强细节。为了支持模型的训练和评估，研究人员创建了一个新的数据集CelebIPVid。实验结果表明，MoCA在面部相似性方面取得了显著的性能提升，超过了现有的T2V方法。这项工作对于需要精确身份保持的视频生成任务具有重要意义，但可能在计算复杂性和模型可解释性方面存在一些局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到视频生成模型在捕捉细微的面部动态和保持时间身份一致性方面存在挑战。

**Method:** MoCA模型基于Diffusion Transformer (DiT)骨干，并引入了交叉注意力混合机制。该机制通过在每个DiT块中嵌入MoCA层，利用分层时间池化捕捉不同时间尺度的身份特征，并通过时序感知交叉注意力专家动态建模时空关系。此外，还采用了潜在视频感知损失来增强身份一致性和帧间细节。

**Result:** 在CelebIPVid数据集上的实验表明，MoCA在面部相似性方面比现有的文本到视频生成方法提高了5%以上。

**Conclusion:** MoCA通过其创新的交叉注意力混合机制和时序建模方法，成功解决了现有文本到视频生成模型在身份保持方面的挑战，并在实验中取得了显著的性能提升。

> **ai_Abstract:** MoCA是一种新颖的文本到视频生成模型，它利用交叉注意力混合机制和分层时间池化来解决现有模型在保持身份一致性和捕捉面部动态方面的不足。通过在DiT骨干中集成这些技术，并结合潜在视频感知损失，MoCA能够实现更优的帧间身份一致性。此外，研究人员构建了一个名为CelebIPVid的大型数据集，用于训练和评估模型，实验结果显示MoCA在面部相似性方面表现优于现有方法。

> **摘要翻译:** 尽管基于扩散的模型取得了最新进展，但实现ID保持的文本到视频（T2V）生成仍然具有挑战性。现有方法通常无法捕捉细粒度的面部动态或保持时间身份一致性。为了解决这些局限性，我们提出MoCA，一种基于扩散Transformer（DiT）骨干的新型视频扩散模型，它采用了受专家混合范例启发的交叉注意力混合机制。我们的框架通过将MoCA层嵌入每个DiT块来提高帧间身份一致性，其中分层时间池化跨越不同时间尺度捕捉身份特征，而时序感知交叉注意力专家动态地对时空关系进行建模。我们进一步结合了潜在视频感知损失，以增强视频帧的身份一致性和细粒度细节。为了训练该模型，我们收集了CelebIPVid，一个包含10,000个来自1,000个不同个体的ВЫСОКОРЕЗОЛЮТНЫХ视频的数据集，以促进跨种族泛化。在CelebIPVid上的广泛实验表明，MoCA在面部相似性方面比现有的T2V方法提高了5%以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [908] [GRASPing Anatomy to Improve Pathology Segmentation](https://arxiv.org/abs/2508.03374)
> *GRASP: 利用解剖学改进病理分割*

*Keyi Li, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 病理分割, 解剖学, GRASP, 深度学习, PET/CT

**Comment:** Accepted at 16th MICCAI Workshop on Machine Learning in Medical
  Imaging (MLMI2025)

> **TL;DR:** GRASP是一个即插即用的框架，通过整合伪标签和特征对齐来利用现有的解剖分割模型，从而增强病理分割模型的性能，而无需重新训练解剖组件。

**AI_Comments:** 该研究提出了一种创新的GRASP框架，用于病理分割，通过整合解剖学知识来弥补当前深度学习方法的不足。其模块化和即插即用的特性，以及无需重新训练解剖组件的优势，使其具有广泛的应用潜力。然而，其在不同模态和复杂病理类型上的泛化能力仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 当前深度学习方法在病理分割中主要依赖纯粹的模式识别，忽略了病理发生的解剖学背景，这与放射科医生依赖解剖学理解进行精确病理描绘的实践存在差距。

**Method:** GRASP框架通过伪标签集成和特征对齐，利用现有的解剖分割模型来增强病理分割模型。它将解剖学伪标签作为输入通道，并通过Transformer引导的解剖特征融合来整合解剖学背景，并且可以集成到标准的病理优化流程中，无需重新训练解剖组件。

**Result:** GRASP在两个PET/CT数据集上表现稳定，在多个评估指标和多种架构中均获得优异排名。其结合伪标签和特征融合的双重解剖学注入策略能有效整合解剖学背景。

**Conclusion:** GRASP框架通过集成伪标签和特征对齐，成功地将解剖学知识融入病理分割模型，提高了分割性能，为病理分割任务提供了一种无需重新训练解剖组件的有效方法。

> **ai_Abstract:** GRASP是一种新颖的框架，通过集成伪标签和特征对齐来利用现有的解剖分割模型，从而在病理分割任务中引入解剖学知识。该方法无需重新训练解剖组件，即可提升分割性能，并在多个数据集和架构上得到了验证。

> **摘要翻译:** 放射科医生依靠解剖学理解来精确描绘病变，但目前大多数深度学习方法仅依赖模式识别，忽略了病变发生的解剖学背景。为了缩小这一差距，我们引入了GRASP（用于病理分割的引导表示对齐），一个模块化的即插即用框架，通过集成伪标签和特征对齐来利用现有的解剖分割模型，从而增强病理分割模型。与先前通过辅助训练获得解剖学知识的方法不同，GRASP可以集成到标准的病理优化方案中，而无需重新训练解剖学组件。我们在两个PET/CT数据集上评估了GRASP，进行了系统的消融研究，并研究了该框架的内部工作原理。我们发现GRASP在多个评估指标和多种架构中始终获得最高排名。该框架的双重解剖学注入策略，结合了作为输入通道的解剖学伪标签和通过Transformer引导的解剖学特征融合，有效地整合了解剖学背景。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [909] [OmniShape: Zero-Shot Multi-Hypothesis Shape and Pose Estimation in the Real World](https://arxiv.org/abs/2508.03669)
> *全方位形状：真实世界中的零样本多假设形状与姿态估计*

*Katherine Liu, Sergey Zakharov, Dian Chen, Takuya Ikeda, Greg Shakhnarovich, Adrien Gaidon, Rares Ambrus* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 形状估计, 姿态估计, 零样本学习, 扩散模型, 三平面神经网络场

**Comment:** 8 pages, 5 figures. This version has typo fixes on top of the version
  published at ICRA 2025

> **TL;DR:** OmniShape是一个创新的方法，能够从单张图像估计物体的姿态和完整形状，无需预先知道3D模型或物体类别。它通过将形状补全分解为两个多模态分布（测量值到归一化物体参考系的投影，以及物体几何的先验知识），并利用条件扩散模型进行训练，从而能够从联合姿态和形状分布中采样多个假设，在真实世界数据集上表现出色。

**AI_Comments:** 该研究提出了一种在真实世界场景中进行零样本、多假设的形状和姿态估计的创新方法。通过将形状补全分解为两个独立的条件扩散模型，OmniShape能够处理未知物体类别和缺乏3D模型信息的情况，这在实际应用中具有重要意义。然而，其在不同光照条件、遮挡和复杂背景下的鲁棒性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在不知道3D模型或物体类别的情况下，从单个观测中估计物体的姿态和完整形状。

**Method:** OmniShape将形状补全分解为两个多模态分布：1）测量值如何投影到由数据集定义的归一化物体参考系，2）对物体几何的先验建模，表示为三平面神经网络场。通过训练这两个分布的独立条件扩散模型，可以从联合姿态和形状分布中采样多个假设。

**Result:** OmniShape在具有挑战性的真实世界数据集上展现出引人注目的性能。

**Conclusion:** OmniShape是首个能够进行概率姿态和形状估计的方法，它通过解耦形状补全过程并利用条件扩散模型，实现了零样本、多假设的形状和姿态估计，并在真实世界场景中取得了优异的表现。

> **ai_Abstract:** OmniShape是一种新颖的零样本方法，用于从单个图像估计物体的姿态和形状，无需预先了解3D模型或类别。该方法将形状补全分解为测量值到参考系的投影和物体几何的先验知识，并使用条件扩散模型生成多个可能的姿态和形状假设，在真实世界数据上表现优异。

> **摘要翻译:** 我们希望从单个观测中估计物体的姿态和完整形状，而不假设已知的3D模型或类别。在这项工作中，我们提出了OmniShape，这是同类方法中的第一个，能够进行概率姿态和形状估计。OmniShape基于一个关键的见解，即形状补全可以分解为两个多模态分布：一个捕捉测量值如何投影到由数据集定义的归一化物体参考系，另一个对物体几何进行建模，表示为三平面神经网络场。通过为这两个分布训练单独的条件扩散模型，我们能够从联合姿态和形状分布中进行采样，从而得到多个假设。OmniShape在具有挑战性的真实世界数据集上展现出引人注目的性能。项目网站：https://tri-ml.github.io/omnishape

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [925] [ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow](https://arxiv.org/abs/2508.03218)
> *ActionSink：通过动作流的动态集成实现精确机器人操作*

*Shanshan Guo, Xiwen Liang, Junfan Lin, Yuzheng Zhuang, Liang Lin, Xiaodan Liang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 机器人操纵,动作流,自监督学习,动作估计,精确控制

**Comment:** 

> **TL;DR:** ActionSink 通过将机器人动作重新构建为自监督的“动作流”（源自视频的光流），并利用粗到精匹配器和动态集成器来提高低级动作估计的精度，从而在机器人操纵任务中取得了最先进的性能。

**AI_Comments:** ActionSink 框架在解决机器人操纵中的低级动作估计精度问题方面具有创新性。通过将动作定义为动作流并采用精细的匹配和集成策略，该方法展示了显著的性能提升。然而，该方法对视频数据的依赖性以及在不同环境下的泛化能力仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 低级动作估计的低精度是基于学习的机器人操纵性能的关键限制因素。

**Method:** ActionSink 框架将机器人动作重新构建为源自视频的光流（称为“动作流”），并以自监督的方式进行。它包含一个粗到精的动作流匹配器，通过迭代检索和去噪过程不断提高动作流的准确性；以及一个动态动作流集成器，它使用工作内存池来动态高效地管理用于增强当前动作估计的历史动作流。

**Result:** ActionSink 在 LIBERO 基准测试上的成功率比之前的最先进方法提高了 7.9%，在 LIBERO-Long 的挑战性长视野视觉任务上准确率提高了近 8%。

**Conclusion:** ActionSink 通过将机器人动作重新构建为动作流，并利用其动态集成来提高低级动作估计的精度，从而在机器人操纵任务中取得了最先进的性能。

> **ai_Abstract:** ActionSink 是一种新颖的机器人操纵框架，旨在通过精确估计低级动作来提高机器人操纵性能。它通过将机器人动作重新构建为自监督的“动作流”（源自视频的光流），并利用粗到精匹配器和动态集成器来提高精度。该框架在 LIBERO 和 LIBERO-Long 基准测试上均取得了最先进的性能。

> **摘要翻译:** 语言指导的机器人操作由于从收集的数据中学习的潜力而引起了极大的兴趣。虽然高级感知和规划的挑战随着通用大型预训练模型的进展而不断得到解决，但低级动作估计的低精度已成为操纵性能的关键限制因素。为此，本文介绍了一种新颖的机器人操纵框架，即 ActionSink，旨在为基于学习的机器人操纵领域的精确动作估计铺平道路。顾名思义，ActionSink 以自监督的方式将机器人动作重新构建为来自视频的光流，称为“动作流”，然后用于检索和集成以增强动作估计。具体来说，ActionSink 包含两个主要模块。第一个模块是粗到精的动作流匹配器，它通过迭代检索和去噪过程不断地提高动作流的准确性。第二个模块是动态动作流集成器，它采用工作内存池，动态高效地管理应使用历史动作流来增强当前动作估计。在此模块中，提出了一种多层融合模块，用于融合来自当前和工作内存的直接估计和动作流，通过一系列估计-集成过程实现高精度的动作估计。我们的 ActionSink 框架在 LIBERO 基准测试上的成功率比之前的最先进方法提高了 7.9%，在具有挑战性的长视野视觉任务 LIBERO-Long 上准确率提高了近 8%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [928] [EvRT-DETR: Latent Space Adaptation of Image Detectors for Event-based Vision](https://arxiv.org/abs/2412.02890)
> *事件驱动的实时检测器：用于事件视觉的图像检测器潜在空间自适应*

*Dmitrii Torbunov, Yihui Ren, Animesh Ghose, Odera Dim, Yonggang Cui* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 事件相机, 物体检测, 潜在空间适配, RT-DETR, 计算机视觉

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 该研究提出了一种名为EvRT-DETR的新框架，通过修改冻结的潜在表示空间，将主流图像检测器（如RT-DETR）适配到事件相机数据上，实现了最先进的物体检测性能。

**AI_Comments:** 该研究提出了一种新颖的框架，通过潜在空间适配将成熟的图像检测器（如RT-DETR）应用于事件相机数据，克服了事件数据稀疏和异步的挑战。这种方法比依赖复杂数据表示和专用架构的传统方法更有效率，并在基准测试中取得了最先进的成果，展示了其潜力和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机（EBCs）数据稀疏且异步，难以进行图像分析，现有方法依赖复杂的数据表示和专用架构。本研究旨在解决EBCs的物体检测问题，并提出一种更有效的方法。

**Method:** 提出I2EvDet（Image-to-Event Detection）框架，将主流物体检测器（RT-DETR）适配到事件数据。通过修改冻结的潜在表示空间，将图像检测器转化为事件检测模型，并进行了最小的架构修改。

**Result:** 在Gen1 (mAP +2.3) 和 1Mpx/Gen4 (mAP +1.4) 标准基准数据集上达到了最先进的性能。

**Conclusion:** 通过原则性地适配主流架构，为EBCs物体检测提供了一种新的、高效的方法，并可能应用于其他时间视觉领域。

> **ai_Abstract:** 本研究提出EvRT-DETR框架，通过适配主流图像检测器RT-DETR到事件相机数据，解决了事件视觉中的物体检测问题。该方法通过修改检测器的潜在空间，实现了与专用方法相当甚至更优的性能，并在标准数据集上达到SOTA。

> **摘要翻译:** 事件相机（EBCs）作为一种受生物启发的替代传统相机的方法，在功耗效率、时间分辨率和高动态范围方面具有优势。然而，由于数据稀疏和异步的性质，为EBCs开发图像分析方法具有挑战性。本研究解决了EBC相机物体检测的问题。目前EBC物体检测的方法侧重于构建复杂的数据表示，并依赖于专用架构。我们引入了I2EvDet（Image-to-Event Detection），一个创新的适配框架，将主流物体检测与时间事件数据处理相结合。首先，我们证明了在EBC数据的一种简单的类似图像的表示上训练的实时检测转换器（RT-DETR），一种最先进的自然图像检测器，其性能与专用的EBC方法相当。接下来，作为我们框架的一部分，我们开发了一种有效的适配技术，通过对它们的冻结潜在表示空间进行最小的架构修改，将基于图像的检测器转化为基于事件的检测模型。由此产生的EvRT-DETR模型在标准的Gen1 (mAP +2.3) 和 1Mpx/Gen4 (mAP +1.4) 基准数据集上达到了最先进的性能。这些结果通过对主流架构进行原则性适配，展示了一种全新的EBC物体检测方法，提供了一种高效的替代方案，并有可能应用于其他时间视觉领域。代码可在以下网址获得：https://github.com/realtime-intelligence/evrt-detr

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [933] [GaitAdapt: Continual Learning for Evolving Gait Recognition](https://arxiv.org/abs/2508.03375)
> *GaitAdapt：持续学习以适应不断变化的步态识别*

*Jingjie Wang, Shunli Zhang, Xiang Wei, Senmao Tian* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 步态识别,持续学习,知识保留,图神经网络,特征可区分性

**Comment:** 

> **TL;DR:** 该论文提出了一种名为GaitAdapt的持续学习方法，用于改进步态识别技术，解决了现有方法在面对新数据集时需要重新训练且难以保留旧知识的问题。GaitAdapter通过GPAK模块整合当前数据和历史数据中的共同步态模式，并利用EDSN方法保持不同任务中步态特征的相对空间分布，从而有效提升了步态识别的鉴别能力，并优于其他现有方法。

**AI_Comments:** 该研究提出了一种创新的持续学习方法GaitAdapter来解决步态识别领域的关键挑战，即在数据不断更新时保持模型性能。通过GPAK和EDSN模块的设计，该方法在整合新旧知识和维持特征区分度方面取得了显著进展。然而，其在不同类型步态数据（如不同视角、传感器）上的泛化能力以及计算效率仍有待进一步探索。该工作对于需要适应动态环境的识别系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前步态识别方法在遇到新数据集时通常需要重新训练，但重新训练的模型往往难以保留先前数据集的知识，导致在早期测试集上的性能显著下降。

**Method:** 提出了一种名为GaitAdapt的持续学习任务，并提出了一种名为GaitAdapter的非重放持续学习方法。该方法集成了GPAK模块，利用图神经网络聚合当前数据的共同步态模式到由图向量构成的存储库中，并利用EDSN方法确保新添加的步态样本在不同任务间保持相似的相对空间分布。

**Result:** GaitAdapter能够有效保留从不同任务中获得的步态知识，并展现出比其他方法明显更优的鉴别能力。

**Conclusion:** GaitAdapter是一种有效的持续学习方法，能够解决步态识别中的知识遗忘问题，并在保留和提升步态识别能力方面优于现有方法。

> **ai_Abstract:** 本研究提出了一种名为GaitAdapt的持续学习框架和GaitAdapter方法，旨在解决步态识别中因数据更新而导致的知识遗忘问题。GaitAdapter通过GPAK模块整合不同任务的步态特征，并利用EDSN方法维持特征的区分度，实现了步态识别能力的持续提升和知识的有效保留，实验结果表明其性能优于现有方法。

> **摘要翻译:** 当前的步态识别方法通常需要重新训练，当遇到新的数据集时。然而，重新训练的模型经常在保留先前数据集的知识方面遇到困难，导致在早期测试集上的性能显著下降。为了解决这些挑战，我们提出了一项持续步态识别任务，称为GaitAdapt，它支持步态识别能力随时间的累积增强，并根据各种评估场景进行了系统分类。此外，我们提出了一种用于步态识别的非重放持续学习方法GaitAdapter。该方法集成了GaitPartition自适应知识（GPAK）模块，利用图神经网络将当前数据的共同步态模式聚合到一个由图向量构成的存储库中。随后，该存储库用于提高新任务中步态特征的可区分性，从而增强模型有效识别步态模式的能力。我们还基于负样本对引入了一种基于欧几里得距离稳定性（EDSN）的方法，该方法确保了来自不同类别的、新添加的步态样本在先前和当前步态任务中保持相似的相对空间分布，从而减轻了任务变化对原始域特征可区分性的影响。广泛的评估表明，GaitAdapter能够有效地保留从不同任务中获得的步态知识，并展现出比其他方法明显更优的可区分能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [934] [Veila: Panoramic LiDAR Generation from a Monocular RGB Image](https://arxiv.org/abs/2508.03690)
> *单目RGB图像的全景激光雷达生成*

*Youquan Liu, Lingdong Kong, Weidong Yang, Ao Liang, Jianxiong Gao, Yang Wu, Xiang Xu, Xin Li, Linfeng Li, Runnan Chen, Ben Fei* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 全景激光雷达生成, 条件扩散模型, RGB-LiDAR对齐, 跨模态一致性, 空间控制

**Comment:** Preprint; 10 pages, 6 figures, 7 tables

> **TL;DR:** 本研究提出了一种名为Veila的条件扩散框架，利用单目RGB图像生成全景激光雷达数据，解决了现有方法在可控性和空间控制方面的不足。Veila通过置信度感知条件机制（CACM）、几何跨模态对齐（GCMA）和全景特征一致性（PFC）来克服RGB到LiDAR转换中的挑战，并在多个基准测试中取得了最先进的性能，同时证明了其在下游任务中的有效性。

**AI_Comments:** 该研究提出了一种新颖的框架Veila，用于从单目RGB图像生成全景LiDAR数据，解决了现有技术在可控性和空间精度方面的局限性。通过引入CACM、GCMA和PFC等创新机制，Veila有效地处理了RGB与LiDAR数据之间的模态差异和结构一致性问题。新提出的评估指标也为该领域的研究提供了有价值的工具。然而，框架在处理极端天气或复杂场景下的鲁棒性仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 可扩展的自动驾驶和机器人三维感知需要真实且可控的全景激光雷达数据生成。现有方法要么生成不可控，要么依赖文本引导但缺乏精细的空间控制。利用单目RGB图像作为空间控制信号是一种低成本、可扩展的替代方案，但面临着空间变化的语义和深度线索、RGB外观与LiDAR几何之间的模态差异以及保持单目RGB与全景LiDAR之间结构一致性等挑战。

**Method:** 提出了一种名为Veila的条件扩散框架，包含三个关键组件：1. 置信度感知条件机制（CACM），通过自适应地平衡局部可靠的语义和深度线索来增强RGB条件；2. 几何跨模态对齐（GCMA），用于在噪声扩散下实现鲁棒的RGB-LiDAR对齐；3. 全景特征一致性（PFC），用于强制单目RGB和全景LiDAR之间的全局结构一致性。此外，还引入了跨模态语义一致性和跨模态深度一致性两个指标来评估模态间的对齐质量。

**Result:** Veila在nuScenes、SemanticKITTI以及提出的KITTI-Weather基准测试中，实现了最先进的生成保真度和跨模态一致性。通过生成性数据增强，Veila能够提升下游激光雷达语义分割任务的性能。

**Conclusion:** Veila框架成功地解决了利用单目RGB图像生成全景LiDAR数据的挑战，通过其创新的条件机制、对齐方法和一致性约束，实现了高质量、可控的数据生成，并在实际应用中展现出提升下游任务性能的潜力。

> **ai_Abstract:** 本研究提出Veila框架，利用单目RGB图像生成全景LiDAR数据。该框架通过置信度感知条件机制、几何跨模态对齐和全景特征一致性，解决了生成过程中的关键挑战，实现了高质量、可控的数据生成，并提升了下游任务的性能。

> **摘要翻译:** 现实且可控的全景激光雷达数据生成对于自动驾驶和机器人技术中的可扩展三维感知至关重要。现有方法要么进行不可控生成，要么采用文本引导合成，但缺乏精细的空间控制。利用单目RGB图像作为空间控制信号提供了一种可扩展且低成本的替代方案，但这仍然是一个开放性问题。然而，它面临三个核心挑战：(i)来自RGB的语义和深度线索在空间上是变化的，这使得可靠的条件生成复杂化；(ii)RGB外观和LiDAR几何之间的模态差异在噪声扩散下放大了对齐误差；(iii)在图像和LiDAR之间的非重叠区域，保持单目RGB和全景LiDAR之间的结构一致性是具有挑战性的。为了解决这些挑战，我们提出了Veila，一种新颖的条件扩散框架，它集成了：一个置信度感知条件机制（CACM），通过根据其局部可靠性自适应地平衡语义和深度线索来加强RGB条件；一个几何跨模态对齐（GCMA），用于在噪声扩散下实现鲁棒的RGB-LiDAR对齐；以及一个全景特征一致性（PFC），用于强制单目RGB和全景LiDAR之间的全局结构一致性。此外，我们还引入了两个指标，跨模态语义一致性和跨模态深度一致性，来评估跨模态的对齐质量。在nuScenes、SemanticKITTI和我们提出的KITTI-Weather基准测试上的实验表明，Veila实现了最先进的生成保真度和跨模态一致性，同时实现了能够改进下游激光雷达语义分割的生成性数据增强。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [938] [VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering](https://arxiv.org/abs/2508.03039)
> *视频森林：跨视频问答的以人物为中心的层次推理*

*Yiran Meng, Junhong Ye, Wei Zhou, Guanghui Yue, Xudong Mao, Ruomei Wang, Baoquan Zhao* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-05**

**Keywords:** 跨视频问答, 以人物为中心的推理, 层次结构, 多智能体系统, VideoForest, CrossVideoQA

**Comment:** 

> **TL;DR:** VideoForest是一个新框架，通过以人物为中心的层次推理来解决跨视频问答的挑战，利用人物特征连接视频，并使用多粒度生成树结构和多智能体推理来回答复杂问题。它在新的CrossVideoQA基准测试中表现优于现有方法。

**AI_Comments:** 该研究提出了一种创新的方法来解决跨视频问答的挑战，通过以人物为中心的层次推理来有效地连接和理解来自多个视频的信息。该方法在提取人物特征、构建分层结构和进行推理方面具有新颖性。引入的CrossVideoQA数据集为该领域的研究提供了重要的资源。然而，该方法在ReID和跟踪算法的鲁棒性以及多智能体推理的效率和可扩展性方面可能面临挑战。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单视频理解方法在处理跨视频问答时面临挑战，尤其是在建立视频流之间的连接和管理多源信息检索的复杂性方面。

**Method:** VideoForest框架采用以人物为中心的层次推理，包括：1) 使用ReID和跟踪算法提取以人物为中心的特征，建立跨视频的时空关系；2) 构建多粒度生成树结构，围绕人物轨迹分层组织视觉内容；3) 采用多智能体推理框架遍历该结构来回答跨视频查询。

**Result:** VideoForest在跨视频推理任务中表现出优越性能，在人物识别方面达到71.93%的准确率，在行为分析方面达到83.75%，在摘要和推理方面达到51.67%，显著优于现有方法。

**Conclusion:** VideoForest通过以人物为中心的特征统一多个视频流，为跨视频理解开创了新范式，能够在保持计算效率的同时，实现跨分布式视觉信息的复杂推理。

> **ai_Abstract:** VideoForest是一个新颖的跨视频问答框架，通过以人物为中心的层次推理来解决信息连接和多源检索的复杂性。该框架利用人物特征作为视频间的桥梁，通过以人物为中心的特征提取、多粒度生成树结构和多智能体推理来组织和处理信息。框架还引入了专门用于人物中心跨视频分析的CrossVideoQA数据集，并在实验中证明了其优于现有方法的性能。

> **摘要翻译:** 跨视频问答在传统单视频理解的基础上带来了更大的挑战，特别是在建立跨视频流的有意义连接和管理多源信息检索的复杂性方面。我们引入了VideoForest，一个通过以人物为中心的层次推理来应对这些挑战的新颖框架。我们的方法利用人物级别的特征作为视频之间的自然连接点，能够在无需端到端训练的情况下实现有效的跨视频理解。VideoForest集成了三项关键创新：1) 一个以人物为中心的特征提取机制，采用ReID和跟踪算法来建立跨越多个视频源的鲁棒时空关系；2) 一个多粒度生成树结构，围绕人物级别的轨迹分层组织视觉内容；3) 一个多智能体推理框架，有效地遍历该分层结构来回答复杂的跨视频查询。为了评估我们的方法，我们开发了CrossVideoQA，一个专为以人物为中心的跨视频分析设计的全面基准数据集。实验结果证明了VideoForest在跨视频推理任务中的卓越性能，在人物识别方面达到了71.93%的准确率，在行为分析方面达到了83.75%，在摘要和推理方面达到了51.67%，显著优于现有方法。我们的工作通过人物级别的特征统一多个视频流，为跨视频理解开创了新范式，能够在保持计算效率的同时，实现跨分布式视觉信息的复杂推理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [959] [Multi-human Interactive Talking Dataset](https://arxiv.org/abs/2508.03050)
> *多人互动说话数据集*

*Zeyu Zhu, Weijia Wu, Mike Zheng Shou* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多人互动, 说话视频生成, 数据集, 身体姿态, 语音交互

**Comment:** 9 pages, 4 figures, 4 tables

> **TL;DR:** 本研究提出了MIT数据集，一个包含12小时、2-4人对话的高分辨率视频数据集，并附带身体姿势和语音交互的精细标注，旨在解决现有研究在单人或孤立面部动画方面的局限性，以促进多人互动视频生成的研究。同时，研究提出了一个名为CovOG的基线模型，该模型包含多人类姿态编码器（MPE）和交互式音频驱动器（IAD），以处理不同数量的说话者并根据特定音频特征调节头部动态，证明了生成逼真多人说话视频的可行性与挑战。

**AI_Comments:** 该研究成功构建了一个针对多人互动说话视频生成的大规模数据集MIT，并提出了相应的基线模型CovOG。数据集的规模和标注的详细程度对于推动该领域的研究具有重要意义。然而，模型在处理复杂互动和保持长时间连贯性方面仍面临挑战，未来的研究可以进一步探索更先进的生成技术和更丰富的交互标注。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要集中在单人独白或孤立的面部动画生成，这限制了其在真实多人互动场景中的应用。本研究旨在弥合这一差距，为多人互动对话视频生成提供一个专门的数据集和基线模型。

**Method:** 研究引入了一个自动化的数据采集和标注流程，以创建MIT数据集。该数据集包含12小时的高分辨率视频，记录了2到4名说话者的自然对话，并提供了详细的身体姿态和语音交互标注。此外，研究提出了CovOG基线模型，该模型结合了多人类姿态编码器（MPE）来聚合个体姿态嵌入，以及交互式音频驱动器（IAD）来根据说话者特定的音频特征调节头部动态。

**Result:** 研究成功创建了一个大规模的多人互动说话视频数据集（MIT），该数据集包含12小时的高分辨率视频，记录了2-4人的自然对话，并带有精细的身体姿态和语音交互标注。提出的CovOG基线模型展示了处理多人对话和生成互动式头部动画的可行性，并揭示了该领域的挑战。

**Conclusion:** MIT数据集为多人互动说话视频生成提供了一个宝贵的资源和基准，而CovOG模型则展示了解决这一新颖任务的可行性与挑战，为未来的相关研究奠定了基础。

> **ai_Abstract:** 本研究介绍了MIT数据集，一个专为多人说话视频生成设计的大规模数据集，包含12小时的高分辨率视频，记录了2-4人的自然对话，并附有身体姿势和语音交互的详细标注。研究还提出了CovOG基线模型，该模型利用多人类姿态编码器和交互式音频驱动器来处理多人互动和生成动态头部动画，旨在推动多人互动视频生成领域的研究。

> **摘要翻译:** 现有关于说话视频生成的研究主要集中在单人独白或孤立的面部动画，这限制了它们在真实多人互动中的应用。为了弥合这一差距，我们引入了MIT，一个专门为多人说话视频生成设计的大规模数据集。为此，我们开发了一个自动化的流程来收集和标注多人对话视频。所得数据集包含12小时的高分辨率视频片段，每个片段包含2到4名说话者，并带有身体姿势和语音交互的精细标注。它捕捉了多说话者场景中自然的对话动态，为研究互动视觉行为提供了丰富的资源。为了展示MIT的潜力，我们进一步提出了CovOG，一个针对这一新颖任务的基线模型。它集成了多人类姿态编码器（MPE）通过聚合个体姿态嵌入来处理不同数量的说话者，以及交互式音频驱动器（IAD）来根据说话者特定的音频特征调节头部动态。这些组件共同展示了生成逼真多人说话视频的可行性与挑战，使MIT成为未来研究的一个有价值的基准。代码可在：https://github.com/showlab/Multi-human-Talking-Video-Dataset 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [962] [La La LiDAR: Large-Scale Layout Generation from LiDAR Data](https://arxiv.org/abs/2508.03691)
> *La La LiDAR：基于LiDAR数据的大规模布局生成*

*Youquan Liu, Lingdong Kong, Weidong Yang, Xin Li, Ao Liang, Runnan Chen, Ben Fei, Tongliang Liu* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-05**

**Keywords:** LiDAR场景生成, 布局引导, 场景图扩散, 可控生成, 自动驾驶

**Comment:** Preprint; 10 pages, 6 figures, 7 tables

> **TL;DR:** La La LiDAR是一个创新的框架，通过语义增强的场景图扩散和关系感知上下文条件，实现了大规模、可控的LiDAR场景生成，并能注入前景对象，解决了现有模型在前景对象控制和空间关系方面的局限性，同时引入了新的数据集和评估指标，在LiDAR生成和下游感知任务上均达到最先进的性能。

**AI_Comments:** 该研究提出了一种名为La La LiDAR的新型框架，用于大规模、可控的LiDAR场景生成。其主要创新点在于引入了语义增强的场景图扩散和关系感知上下文条件，解决了现有方法在前景对象控制和空间关系方面的局限性。通过Shi-Zeng Li等人的研究，该方法能够实现对对象放置的定制化控制，同时保持空间和语义的一致性。此外，该研究还发布了两个新的大规模LiDAR场景图数据集（Waymo-SG和nuScenes-SG）以及新的评估指标，为该领域的研究提供了重要支持。实验结果表明，La La LiDAR在LiDAR生成和下游感知任务上均达到了最先进的水平，为自动驾驶和机器人领域的场景模拟和安全验证提供了强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于扩散的模型在LiDAR场景生成方面虽然保真度高，但在前景对象控制和空间关系方面存在不足，限制了其在自动驾驶和机器人领域的应用，特别是在场景模拟和安全验证方面。

**Method:** 提出了一种名为“La La LiDAR”的新型布局引导生成框架，该框架采用语义增强的场景图扩散（semantic-enhanced scene graph diffusion）和关系感知上下文条件（relation-aware contextual conditioning）来实现结构化的LiDAR布局生成，并结合了前景感知控制注入（foreground-aware control injection）来完成整个场景的生成。此外，还引入了Waymo-SG和nuScenes-SG两个大规模LiDAR场景图数据集以及新的布局合成评估指标。

**Result:** La La LiDAR在LiDAR生成和下游感知任务上均取得了最先进的性能，为可控的3D场景生成树立了新的标杆。

**Conclusion:** La La LiDAR通过其新颖的框架和数据集，成功实现了大规模、可控的LiDAR场景生成，解决了现有方法的局限性，并在多个评估指标上展现出优越的性能。

> **ai_Abstract:** La La LiDAR是一个新颖的框架，通过结合语义增强的场景图扩散和关系感知上下文条件，实现了大规模、可控的LiDAR场景生成。该方法解决了现有模型在前景对象控制和空间关系方面的不足，并通过引入新的数据集和评估指标，在LiDAR生成和下游感知任务方面取得了最先进的性能。

> **摘要翻译:** 可控的真实LiDAR场景生成对于自动驾驶和机器人等应用至关重要。尽管最近的扩散模型在LiDAR生成方面实现了高保真度，但它们缺乏对前景对象和空间关系的显式控制，限制了它们在场景模拟和安全验证方面的用途。为了解决这些局限性，我们提出了大规模布局引导LiDAR生成模型（“La La LiDAR”），这是一个新颖的布局引导生成框架，它引入了用于结构化LiDAR布局生成的语义增强场景图扩散和关系感知上下文条件，然后进行前景感知控制注入以完成场景生成。这使得在确保空间和语义一致性的同时，能够自定义对象放置。为了支持我们的结构化LiDAR生成，我们引入了Waymo-SG和nuScenes-SG，两个大规模LiDAR场景图数据集，以及用于布局合成的新评估指标。大量实验表明，La La LiDAR在LiDAR生成和下游感知任务方面均取得了最先进的性能，为可控的3D场景生成树立了新的标杆。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [968] [Neutralizing Token Aggregation via Information Augmentation for Efficient Test-Time Adaptation](https://arxiv.org/abs/2508.03388)
> *通过信息增强中和令牌聚合以实现高效的测试时适应*

*Yizhe Xiong, Zihan Zhou, Yiwen Liang, Hui Chen, Zijia Lin, Tianxiang Hao, Fan Zhang, Jungong Han, Guiguang Ding* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 测试时自适应, 视觉 Transformer, 令牌聚合, 信息增强, 推理效率

**Comment:** 9 pages, 7 figures

> **TL;DR:** 该研究提出了一种名为NAVIA的新方法，通过增强[CLS]令牌嵌入和引入自适应偏差来解决测试时自适应（TTA）中的计算开销问题，该方法在提高适应能力的同时，将推理延迟降低了20%以上，性能提升了2.5%。

**AI_Comments:** 该研究提供了一个新颖的视角来解决TTA中的效率问题，通过信息论的角度分析了令牌聚合的局限性，并提出了有针对性的解决方案。NAVIA方法的提出及其在实验中的优异表现，为未来高效的TTA研究提供了有价值的参考。然而，其理论分析的普适性和在更广泛模型架构上的有效性有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测试时自适应（TTA）方法计算开销大，限制了其在资源受限场景下的应用。令牌聚合方法虽然能降低推理成本，但会导致性能显著下降。本研究旨在解决高效测试时自适应（ETTA）问题，即在降低推理延迟的同时保持TTA的适应能力。

**Method:** 提出了一种名为NAVIA（Neutralizing Token Aggregation via Information Augmentation）的方法。该方法通过直接增强[CLS]令牌嵌入，并在ViT的浅层中引入自适应偏差到[CLS]令牌。这些增强措施通过熵最小化进行优化，以恢复因令牌聚合而丢失的信息。

**Result:** NAVIA在各种分布外基准测试中的表现显著优于现有最先进的方法（超过2.5%），同时将推理延迟降低了20%以上。

**Conclusion:** NAVIA通过信息增强有效解决了高效测试时自适应（ETTA）的挑战，在降低推理成本的同时保持甚至提高了模型的适应能力。

> **ai_Abstract:** 本研究针对测试时自适应（TTA）中的计算开销问题，提出了NAVIA方法。NAVIA通过增强[CLS]令牌和引入自适应偏差来补偿令牌聚合带来的信息损失，从而在降低推理延迟的同时保持模型的适应能力。实验结果表明，NAVIA在性能和效率上均优于现有方法。

> **摘要翻译:** 测试时自适应（TTA）已成为一种有效的解决方案，可在没有额外训练数据的情况下将视觉 Transformer（ViT）适应于分布变化。然而，现有的 TTA 方法通常会产生显著的计算开销，限制了它们在资源受限的实际场景中的应用。为了降低推理成本，即插即用的令牌聚合方法会合并 ViT 中冗余的令牌以减少处理的总令牌数。尽管效率高，但在直接与现有的 TTA 方法集成时，它会导致性能严重下降。我们将此问题形式化为高效测试时自适应（ETTA），旨在在降低推理延迟的同时保留 TTA 的适应能力。在本研究中，我们首先从新颖的互信息角度提供了理论分析，表明令牌聚合固有地会导致信息丢失，而传统的基于范数调整的 TTA 方法无法完全缓解这种信息丢失。根据这一见解，我们提出通过信息增强来中和令牌聚合（NAVIA）。具体来说，我们直接增强 [CLS] 令牌嵌入，并将自适应偏差合并到 ViT 浅层的 [CLS] 令牌中。我们从理论上证明，通过熵最小化进行优化的这些增强措施可以恢复因令牌聚合而丢失的信息。在各种分布外基准测试中的广泛实验表明，NAVIA 的性能比最先进的方法显著提高了 2.5% 以上，同时将推理延迟降低了 20% 以上，有效地解决了 ETTA 的挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [971] [Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation](https://arxiv.org/abs/2507.21455)
> *通过参数化、预定义增强和近似来增强自监督数据集蒸馏*

*Sheng-Feng Yu, Jia-Jiun Yao, Wei-Chen Chiu* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 数据集蒸馏,自监督学习,参数化,数据增强,迁移学习

**Comment:** To appear in the Proceedings of the International Conference on
  Learning Representations (ICLR 2025)

> **TL;DR:** 该研究提出了一种名为自监督数据集蒸馏的技术，通过参数化、预定义增强和近似来压缩数据集，以降低训练成本并保持模型性能。

**AI_Comments:** 该研究在数据集蒸馏领域取得了显著进展，特别是在自监督学习方面。通过引入参数化、预定义增强和近似技术，有效解决了自监督数据集蒸馏中的关键挑战，并在多个方面展现出优越性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型数据集的训练成本高昂，促使研究人员开发数据集蒸馏技术来压缩数据集。

**Method:** 提出了一种新的自监督数据集蒸馏方法，包含三个关键技术：1. 使用低维基进行参数化；2. 使用预定义的数据增强来解决不稳定性问题；3. 利用轻量级网络对数据增强视图之间的联系进行建模。

**Result:** 所提出的方法在蒸馏效率、跨架构泛化能力和迁移学习性能方面优于现有方法，并在各种数据集上进行了验证。

**Conclusion:** 通过参数化、预定义增强和近似技术，可以有效地进行自监督数据集蒸馏，从而在降低数据集大小的同时保持模型性能。

> **ai_Abstract:** 本研究提出了一种名为自监督数据集蒸馏的新方法，旨在解决大型数据集训练成本高昂的问题。该方法通过引入参数化、预定义增强和近似技术，将图像及其自监督表示压缩到一个更小的蒸馏集中。实验证明，该方法在蒸馏效率、跨架构泛化能力和迁移学习性能方面均优于现有技术。

> **摘要翻译:** 虽然更大的数据集对于训练大型深度模型至关重要，但数据集大小的快速增长带来了成本高昂的训练时间的重大挑战，甚至导致了高昂的计算费用。数据集蒸馏最近成为一种流行的技术，通过学习一组高度紧凑的代表性样本来减小数据集的大小，其中使用这些样本训练的模型理想情况下应具有与使用完整数据集训练的模型相当的性能。虽然现有的大多数数据集蒸馏工作都集中在监督数据集上，但我们旨在将图像及其自监督训练的表示蒸馏到一个蒸馏集中。这个过程，称为自监督数据集蒸馏，有效地从真实数据集中提取丰富的信息，从而产生具有增强的跨架构泛化能力的蒸馏集。特别是，为了更忠实、更紧凑地保留原始数据集的关键特征，我们提出了一些新技术：1）我们通过不同的低维基引入了对图像和表示的创新参数化，其中参数化的基选择被实验证明起着至关重要的作用；2）我们通过利用预定义的数据增强来解决由数据增强的随机性引起的不稳定性——数据增强是自监督学习的一个关键组成部分，但在先前的自监督数据集蒸馏工作中被低估了——；3）我们进一步利用一个轻量级网络来模拟同一图像的增强视图表示之间的联系，从而实现更紧凑的蒸馏对。在各种数据集上进行的广泛实验验证了我们的方法在蒸馏效率、跨架构泛化能力和迁移学习性能方面的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [976] [Trace3D: Consistent Segmentation Lifting via Gaussian Instance Tracing](https://arxiv.org/abs/2508.03227)
> *Trace3D：通过高斯实例追踪实现一致的分割提升*

*Hongyu Shen, Junfeng Ni, Yixin Chen, Weishuo Li, Mingtao Pei, Siyuan Huang* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 高斯溅射, 3D分割, 实例追踪, 自适应密度控制, 语义线索

**Comment:** 

> **TL;DR:** Trace3D是一种新的方法，通过高斯实例追踪（GIT）来解决高斯溅射中的2D到3D分割问题，通过实例权重矩阵纠正2D分割不一致性，并使用自适应密度控制来改进分割边界，从而实现更清晰、更一致的3D分割。

**AI_Comments:** 该方法在解决高斯溅射中的3D分割一致性问题上具有创新性，通过引入实例追踪和自适应密度控制来改进分割质量。然而，计算成本和在大规模场景下的可扩展性可能需要进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在将2D视觉分割提升到3D高斯溅射时，存在跨视点2D掩码不一致和分割边界噪声的问题，因为它们忽略了用于精炼高斯体的语义线索。

**Method:** 提出高斯实例追踪（GIT）方法，通过实例权重矩阵增强高斯表示，以识别和纠正2D分割不一致性；提出GIT引导的自适应密度控制机制，在训练过程中分割和修剪模糊的高斯体，以获得更清晰、更一致的2D和3D分割边界。

**Result:** Trace3D能够提取干净的3D资产，并在在线（如自提示）和离线（如对比提升）设置中持续改进3D分割，支持分层分割、对象提取和场景编辑等应用。

**Conclusion:** Trace3D通过引入高斯实例追踪（GIT）和自适应密度控制，有效地解决了高斯溅射中2D到3D分割的挑战，实现了更一致、更清晰的3D分割，并为下游应用提供了支持。

> **ai_Abstract:** Trace3D提出了一种名为高斯实例追踪（GIT）的新方法，用于解决高斯溅射中的2D到3D分割问题。该方法通过引入实例权重矩阵来处理2D分割的不一致性，并利用自适应密度控制来优化高斯体的表示，从而生成更清晰、更一致的3D分割结果，并支持多种下游应用。

> **摘要翻译:** 我们解决了将2D视觉分割提升到3D高斯溅射的挑战。现有方法通常在跨视点的2D掩码不一致以及产生嘈杂的分割边界方面存在问题，因为它们忽略了用于精炼学习到的高斯体的语义线索。为了克服这些问题，我们引入了高斯实例追踪（GIT），它通过跨输入视图的实例权重矩阵来增强标准高斯表示。利用高斯体在3D中的固有一致性，我们使用该矩阵来识别和纠正2D分割不一致性。此外，由于每个高斯体理想上对应于一个单一对象，我们提出了一种GIT引导的自适应密度控制机制，在训练过程中分割和修剪模糊的高斯体，从而产生更清晰、更连贯的2D和3D分割边界。实验结果表明，我们的方法能够提取干净的3D资产，并在在线（例如，自提示）和离线（例如，对比提升）设置中持续改进3D分割，从而能够进行分层分割、对象提取和场景编辑等应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [977] [UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation](https://arxiv.org/abs/2506.04134)
> *中文顺语：中文顺语视频到语音生成的统一识别和生成框架*

*Jinting Wang, Shan Yang, Chenxing Li, Dong Yu, Li Liu* | **Category: cs.CV, cs.SD, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 中文顺语, 视频到语音生成, 统一框架, 顺语识别, 视觉语音转换

**Comment:** 8 pages, 5 figures

> **TL;DR:** 该研究提出了UniCUE，一个创新的统一框架，可以直接从中文顺语视频生成语音，无需中间文本表示，解决了现有方法的误差传播和时间失配问题。该框架整合了顺语识别（CSR）以提供视觉语义线索，并包含一个姿势感知视觉处理器、一个语义对齐池和一个视觉语音适配器。研究人员还构建了一个名为UniCUE-HI的大规模数据集，包含11282个视频，并证明了UniCUE在多个评估指标上达到了最先进的性能。

**AI_Comments:** 该研究提出了一个创新的统一框架UniCUE，用于中文顺语视频到语音的生成，直接解决了现有流水线方法的局限性。框架的核心在于将理解任务（CSR）与生成任务相结合，并通过专门设计的组件（姿势感知视觉处理器、语义对齐池、视觉语音适配器）实现了有效的视觉-语音映射。UniCUE-HI数据集的构建为该领域的研究提供了重要资源。该方法的创新性在于其端到端的直接生成能力，避免了中间文本的潜在问题，并在实验中取得了领先的性能，显示了其潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有中文顺语视频到语音（CSV2S）的方法通常采用“顺语识别（CSR）+ 文本到语音（TTS）”的流水线，这种方法依赖于文本作为中间媒介，可能导致误差传播和语音与顺语视频动态之间的时间失配。直接从顺语视频生成语音的方法则面临多模态复杂性和顺语数据有限的挑战。

**Method:** 提出UniCUE，首个统一的CSV2S框架，直接从顺语视频生成语音，不依赖中间文本。该框架的关键在于整合了提供细粒度视觉语义线索的理解任务（CSR），具体包括一个姿势感知视觉处理器、一个实现精确视觉语义映射的语义对齐池，以及一个在统一架构中连接理解和生成任务的视觉语音适配器。同时，构建了UniCUE-HI数据集，包含11282个视频。

**Result:** 在UniCUE-HI数据集上的大量实验表明，UniCUE在多个评估指标上实现了最先进的性能。

**Conclusion:** UniCUE框架成功地解决了从顺语视频直接生成语音的挑战，通过整合理解和生成任务，并利用大规模数据集进行了验证，取得了优于现有方法的性能。

> **ai_Abstract:** UniCUE是一个新颖的统一框架，旨在直接从中文顺语（CS）视频生成语音，解决了现有方法中因依赖中间文本而产生的误差传播和时间失配问题。该框架通过整合一个顺语识别（CSR）模块来提供视觉语义线索，并包含姿势感知视觉处理、语义对齐和视觉语音适配等关键组件。研究人员还发布了一个大规模数据集UniCUE-HI，并证明了UniCUE在性能上的优越性。

> **摘要翻译:** 顺语（CS）通过手部编码增强唇读，提供视觉语音线索，从而支持听障人士精确感知语音。CS视频到语音生成（CSV2S）任务旨在将CS视频转换为可理解的语音信号。大多数现有研究集中于CS识别（CSR），将视频内容转录为文本。因此，CSV2S的一个常见解决方案是将CSR与文本到语音（TTS）系统集成。然而，这种流水线依赖文本作为中间媒介，可能导致误差传播以及语音和CS视频动态之间的时间失配。相比之下，直接从CS视频生成音频语音（直接CSV2S）通常会受到固有的多模态复杂性和CS数据有限性的影响。为了应对这些挑战，我们提出了UniCUE，这是首个用于CSV2S的统一框架，可以直接从CS视频生成语音，而无需依赖中间文本。UniCUE的核心创新在于整合了一个理解任务（CSR），该任务提供细粒度的CS视觉语义线索来指导语音生成。具体来说，UniCUE包含一个姿势感知视觉处理器、一个实现精确视觉语义映射的语义对齐池，以及一个在统一架构中连接理解和生成任务的视觉语音适配器。为了支持该框架，我们构建了UniCUE-HI，一个大规模普通话CS数据集，包含来自14个发音者的11282个视频，包括听障和正常听力人士。在该数据集上的广泛实验表明，UniCUE在多个评估指标上取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [978] [FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2501.07378)
> *联邦半监督域泛化医学图像分割*

*Zhipeng Deng, Zhe Xu, Tsuyoshi Isshiki, Yefeng Zheng* | **Category: cs.CV** | **Updated: 2025-08-05**

**Keywords:** 联邦半监督学习, 域泛化, 医学图像分割, 域转移, 伪标签

**Comment:** 21 pages

> **TL;DR:** 该研究提出了FedSemiDG框架，通过一种名为FGASL的新方法，解决了联邦半监督学习中的域转移问题，以提高在未见域上的医学图像分割性能。

**AI_Comments:** 该研究解决了联邦半监督学习中的一个重要但被忽视的问题——域转移，并提出了一个名为FedSemiDG的全面框架。FGASL框架中的GAA、DR和PIA策略具有创新性，能够同时处理全局聚合和局部特征学习，以提升模型在未见域上的泛化能力。实验结果令人信服，证明了该方法在实际医学图像分割任务中的有效性。然而，计算成本和模型复杂度可能是未来研究需要考虑的方面。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割因图像多样性和标注数据缺乏而面临挑战，联邦半监督学习（FSSL）旨在利用多中心未标记数据进行模型训练。然而，FSSL在域转移问题上的研究不足，可能导致模型聚合不佳和未标记数据利用效果差，最终影响在未见域上的性能。

**Method:** 提出了一种名为FGASL的新框架，用于解决FedSemiDG问题。该框架在全球层面引入了“泛化感知聚合”（GAA），根据模型泛化性能自适应地分配权重；在局部层面，采用“双教师自适应伪标签精炼”（DR）策略结合全局和特定域知识生成更可靠的伪标签；此外，通过“扰动不变对齐”（PIA）强制特征在扰动下保持一致性，促进域不变学习。

**Result:** 在四个医学分割任务（心脏MRI、脊柱MRI、膀胱癌MRI和结直肠息肉）上的广泛实验表明，该方法显著优于最先进的FSSL和域泛化方法，在未见域上实现了稳健的泛化。

**Conclusion:** 所提出的FedSemiDG方法，特别是FGASL框架，通过GAA、DR和PIA等机制，有效地解决了联邦半监督学习中的域转移问题，在医学图像分割任务中展现出优越的泛化能力。

> **ai_Abstract:** 本研究提出了FedSemiDG框架，旨在解决联邦半监督学习（FSSL）中的域转移问题，以提高在未见域上的医学图像分割性能。通过FGASL框架，结合了全局的泛化感知聚合（GAA）和局部的双教师自适应伪标签精炼（DR）与扰动不变对齐（PIA）策略，该方法在多个医学图像分割任务中取得了优于现有技术的性能。

> **摘要翻译:** 医学图像分割因医学图像的多样性和标注数据的缺乏而充满挑战，这促使了近期在联邦半监督学习（FSSL）方面的发展，旨在利用来自多个中心的大量未标记数据进行模型训练，而无需共享原始数据。然而，在FSSL中尚未充分探索的是域转移问题，这可能导致模型聚合不佳以及未标记数据的利用效果不佳，最终导致在未见域上的性能不令人满意。在本研究中，我们探索了这个先前被忽视的场景，即域泛化联邦半监督学习（FedSemiDG），其目标是以分布式方式从具有有限标记数据和大量未标记数据的多个域中学习一个模型，以便该模型能够很好地泛化到未见域。我们提出了一个新颖的框架，即联邦泛化感知半监督学习（FGASL），通过有效解决全局和局部层面的关键问题来应对FedSemiDG中的挑战。在全球层面，我们引入了泛化感知聚合（GAA），根据局部模型的泛化性能为其分配自适应权重。在局部层面，我们使用双教师自适应伪标签精炼（DR）策略来结合全局和特定域的知识，生成更可靠的伪标签。此外，扰动不变对齐（PIA）强制特征在扰动下保持一致性，促进域不变学习。在四个医学分割任务（心脏MRI、脊柱MRI、膀胱癌MRI和结直肠息肉）上的广泛实验表明，我们的方法显著优于最先进的FSSL和域泛化方法，在未见域上实现了稳健的泛化。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [97] [Teaching at Scale: Leveraging AI to Evaluate and Elevate Engineering Education](https://arxiv.org/abs/2508.02731)
> *大规模教学：利用人工智能评估和提升工程教育*

*Jean-Francois Chamberland, Martin C. Carlisle, Arul Jayaraman, Krishna R. Narayanan, Sunay Palsole, Karan Watson* | **Category: cs.CY, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** AI教育应用, 大型语言模型, 教学评估, 工程教育, 学生反馈

**Comment:** 

> **TL;DR:** 该论文提出了一个AI驱动的框架，利用大型语言模型（LLMs）对大规模工程项目中的学生反馈进行可扩展、道德的分析，以提升教学质量。

**AI_Comments:** 该论文具有创新性，因为它通过提出一个AI驱动的解决方案，解决了大规模教育评估中的一个重大挑战。其对道德保障（匿名化、异常处理）以及不自动化人事决策的关注对于实际应用至关重要。成功的部署和初步验证为LLM在教育评估中的效用提供了有力证据，突出了AI在提高教学质量方面的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 大规模评估教学效果对于大型大学，特别是招收数万名学生的工程项目来说，是一个持续的挑战。传统的人工审查方法不切实际，导致见解被忽视和数据使用不一致。

**Method:** 本文提出了一种可扩展的、人工智能支持的框架，利用大型语言模型（LLMs）综合定性学生反馈。该系统采用分层摘要、匿名化和异常处理来提取可操作的主题，同时维护道德保障。此外，它还使用视觉分析通过基于百分位的比较、历史趋势和教学负荷来情境化数值分数。该方法整合了学生、同行和自我反思的输入。

**Result:** 该系统已成功部署在一个大型工程学院。通过与人工评审员的比较、教师反馈和纵向分析进行的初步验证表明，LLM生成的摘要可以可靠地支持形成性评估和专业发展。

**Conclusion:** 当人工智能系统在设计时具有透明度和共享治理时，它们可以促进学术机构的大规模教学卓越和持续改进。

> **ai_Abstract:** 本文介绍了一个可扩展的、人工智能支持的框架，该框架利用大型语言模型分析大规模工程项目中学生的定性反馈。该系统采用分层摘要、匿名化和视觉分析来提取可操作的见解并情境化表现，旨在克服传统评估方法的局限性。该系统已成功部署在一个大型工程学院，初步验证表明，由LLM生成的摘要能够可靠地支持形成性评估和专业发展，证明了AI在适当设计下提升大规模教学卓越的潜力。

> **摘要翻译:** 大规模评估教学效果对于大型大学来说仍然是一个持续的挑战，特别是在招收数万名学生的工程项目中。传统方法，如人工审查学生评估，往往不切实际，导致见解被忽视和数据使用不一致。本文提出了一种可扩展的、人工智能支持的框架，利用大型语言模型综合定性学生反馈。该系统采用分层摘要、匿名化和异常处理，从开放式评论中提取可操作的主题，同时维护道德保障。视觉分析通过基于百分位的比较、历史趋势和教学负荷来情境化数值分数。该方法支持有意义的评估，并与定性分析和教育评估的最佳实践相符，整合了学生、同行和自我反思的输入，而无需自动化人事决策。我们报告了它在大型工程学院的成功部署。通过与人工评审员的比较、教师反馈和纵向分析进行的初步验证表明，LLM生成的摘要可以可靠地支持形成性评估和专业发展。这项工作表明，人工智能系统在设计时如果具有透明度和共享治理，可以促进学术机构的大规模教学卓越和持续改进。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [129] [Advancing Science- and Evidence-based AI Policy](https://arxiv.org/abs/2508.02748)
> *推进科学和循证的AI政策*

*Rishi Bommasani, Sanjeev Arora, Jennifer Chayes, Yejin Choi, Mariano-Florentino Cuéllar, Li Fei-Fei, Daniel E. Ho, Dan Jurafsky, Sanmi Koyejo, Hima Lakkaraju, Arvind Narayanan, Alondra Nelson, Emma Pierson, Joelle Pineau, Scott Singer, Gaël Varoquaux, Suresh Venkatasubramanian, Ion Stoica, Percy Liang, Dawn Song* | **Category: cs.CY** | **Updated: 2025-08-02**

**Keywords:** AI政策, 证据, 政策制定, 人工智能, 治理

**Comment:** This is the author's version of the work. It is posted here by
  permission of the AAAS for personal use, not for redistribution. The
  definitive version was published in Science on July 31, 2025

> **TL;DR:** 本文旨在解决如何优化人工智能政策中证据与政策的关系，以应对日益强大的AI带来的机遇和挑战。

**AI_Comments:** 本文的创新之处在于其明确聚焦于优化AI政策制定中的证据与政策关系，而非仅仅识别风险或倡导现有政策。这对于构建更有效、更负责任的AI治理框架至关重要。其重要性在于强调了科学和证据在复杂AI政策环境中的核心作用，有助于避免基于炒作的决策。

<details>
  <summary>Details</summary>

**Motivation:** AI政策应以证据为基础，确保其潜在益处得到负责任的实现和广泛共享。然而，AI政策制定面临制度限制、政治动态、利益相关者、媒体环境、经济考量、文化背景和领导力视角等多重复杂因素，且证据与政策可能因AI的广泛性而脱节。本文旨在解决如何优化证据与政策的关系这一难题。

**Method:** 本文旨在探讨并优化证据与政策的关系，以应对日益强大的AI带来的机遇和挑战。

**Result:** Not mentioned in abstract

**Conclusion:** 本文旨在优化证据与政策的关系，以应对日益强大的AI带来的机遇和挑战。

> **ai_Abstract:** AI政策应以科学和证据为基础，以负责任地实现和共享AI的益处。然而，AI政策制定面临制度、政治等复杂因素，且证据与政策可能因AI的广泛性而脱节。现有努力主要集中于研究AI风险或倡导政策应对。本文旨在探讨并优化证据与政策之间的关系，以应对日益强大的AI所带来的机遇和挑战。

> **摘要翻译:** AI政策应通过确保其潜在益处得到负责任的实现和广泛共享来促进AI创新。为实现此目标，AI政策制定应高度重视证据：科学理解和系统分析应为政策提供信息，政策应加速证据的生成。但政策结果反映出制度限制、政治动态、选举压力、利益相关者利益、媒体环境、经济考量、文化背景和领导力视角。AI广泛的影响力可能导致证据与政策脱节，进一步增加了这种复杂性：尽管有些证据和政策直接针对AI，但更多是部分与AI交叉。精心设计的政策应整合反映科学理解而非炒作的证据。越来越多的努力通过以下两种方式解决这个问题：(i) 贡献有关AI风险及其有效缓解的研究，或(ii) 倡导政策以解决这些风险。本文旨在解决如何优化证据与政策的关系这一难题，以应对日益强大的AI带来的机遇和挑战。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [169] [Towards a Manifesto for Cyber Humanities: Paradigms, Ethics, and Prospects](https://arxiv.org/abs/2508.02760)
> *走向网络人文学宣言：范式、伦理与前景*

*Giovanni Adorni, Emanuele Bellini* | **Category: cs.CY, cs.AI, cs.DL, I.2.0; K.3.m; K.4.0** | **Updated: 2025-08-03**

**Keywords:** 网络人文学, 数字人文学, 跨学科认识论, 算法反思, 以人为中心的人工智能

**Comment:** 18 pages, 1 table, 48 references, to appear in: 1st. IEEE Int. Conf.
  on "Cyber Humanities"

> **TL;DR:** 本文提出了“网络人文学”的概念，旨在为后数字时代的人文学研究提供一个批判性的重新配置，并倡导整合伦理设计、可持续数字实践和以人为中心的知识系统。

**AI_Comments:** 本文提出了一个前瞻性的“网络人文学”概念，超越了传统的数字人文学，强调了在算法主导的时代中，伦理、可持续性和以人为中心的重要性。其创新之处在于将人文学研究提升到“基础范式”的高度，并提供了具体的“十诫”原则，这对于指导未来人文学与数字技术的融合具有重要意义。该宣言为跨学科合作和批判性思维提供了一个强大的框架。

<details>
  <summary>Details</summary>

**Motivation:** 数字基础设施和算法系统的快速发展正在重塑人文学科与知识和文化互动的方式。本文旨在提出一个“网络人文学”的概念，作为后数字时代人文学探究的批判性重构，并为这种新的范式建立一个灵活的框架和基本原则。

**Method:** 本文提出了一个灵活的框架，该框架整合了伦理设计、可持续数字实践和根植于以人为中心方法的参与式知识系统。通过“十诫”式的基本原则，宣言邀请科学界批判性地审视和重新构想影响文化、创造力和集体记忆的算法基础设施。

**Result:** 本文提出了一个“网络人文学”的宣言，包含一个灵活的框架和一套基本原则（十诫），旨在指导在计算介导世界中的人文学探究。

**Conclusion:** “网络人文学”不应被视为现有实践的简单延伸，而应被理解为计算介导世界中人文学探究的基础范式。

> **ai_Abstract:** 本文提出了“网络人文学”的概念，旨在作为计算介导世界中人文学探究的基础范式。该宣言建立在一个灵活的框架之上，整合了伦理设计、可持续数字实践和以人为中心的知识系统，并通过一套基本原则，呼吁重新审视和构想影响文化、创造力和集体记忆的算法基础设施，以应对数字时代对人文学科的重塑。

> **摘要翻译:** 数字基础设施和算法系统的加速演变正在重塑人文学科与知识和文化的互动方式。根植于数字人文学和数字人文主义的传统，“网络人文学”的概念提出了对后数字时代人文学探究的批判性重新配置。本宣言引入了一个灵活的框架，该框架整合了伦理设计、可持续数字实践以及根植于以人为中心方法的参与式知识系统。通过一套基础原则（十诫），本宣言邀请科学界批判性地审视和重新构想影响文化、创造力和集体记忆的算法基础设施。
“网络人文学”不应被视为现有实践的简单延伸，而应被理解为计算介导世界中人文学探究的基础范式。
关键词：网络人文学，数字人文学，跨学科认识论，算法反思，以人为中心的人工智能，设计伦理，知识生态系统，数字主权，认知基础设施

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [209] [The Architecture of Trust: A Framework for AI-Augmented Real Estate Valuation in the Era of Structured Data](https://arxiv.org/abs/2508.02765)
> *信任的架构：结构化数据时代下人工智能增强型房地产估价的框架*

*Petteri Teikari, Mike Jarrell, Maryam Azh, Harri Pesola* | **Category: cs.CY, cs.AI, cs.CV, I.2.1; H.4.2; K.5.2; I.2.10; I.4.8; K.4.1; J.1** | **Updated: 2025-08-04**

**Keywords:** AI增强估价, 房地产, 结构化数据, 信任框架, 人机协作

**Comment:** 46 pages, 6 figures

> **TL;DR:** 本文提出了一个用于人工智能增强型房地产估价的框架，旨在应对向结构化数据过渡的监管变革，并强调人机协作，同时解决信任和偏见问题。

**AI_Comments:** 本文的创新之处在于其将“信任”这一关键概念引入到人工智能增强的金融应用中，尤其是在房地产估价这一重要监管变革背景下。论文强调人机协作而非完全自动化，并明确考虑算法公平性和偏差问题，这对于高风险领域的实际部署和采纳至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 2026年UAD 3.6的强制实施将房地产估价报告从叙述性转变为结构化、机器可读的格式。本文旨在首次全面分析这一监管转变与同期AI进展（计算机视觉、自然语言处理、自主系统）的结合，并开发一个框架来解决现有机构失误（如评估师间差异和系统性偏差）和机构信任要求，以提高估价的可靠性和效率。

**Method:** 本文开发了一个三层人工智能增强型估价框架，涵盖物理数据采集、语义理解和认知推理。该框架旨在整合新兴技术，同时保持专业监督，并解决高风险金融应用中的信任要求，包括监管合规性、算法公平性和不确定性量化。此外，论文还提出了超越通用AI基准的领域特定评估方法。

**Result:** 分析表明，监管标准化与AI能力的融合能够实现根本性的市场重组。该框架在整合新兴技术的同时，能有效保持专业监督。研究结果强调，成功的转型不仅需要技术复杂性，更需要细致的人机协作，以增强而非取代专业专业知识，并解决房地产市场中历史偏差和信息不对称问题。

**Conclusion:** 成功的房地产估价AI转型不仅需要技术上的先进性，更需要细致的人机协作，以增强专业知识，并解决历史偏见和信息不对称问题。

> **ai_Abstract:** 本文分析了UAD 3.6监管转变对房地产估价向结构化数据发展的影响，并结合AI进展提出了一个名为“信任的架构”的三层框架。该框架旨在实现人工智能增强型估价，解决技术实施、机构信任和现有偏差等问题。研究强调，成功的转型需要人机协作，以增强专业知识并重塑市场，同时提供监管合规性、公平性和不确定性量化的解决方案。

> **摘要翻译:** 统一评估数据集 (UAD) 3.6 于 2026 年强制实施，将住宅物业估价从叙述性报告转变为结构化、机器可读的格式。本文首次对这一监管转变以及计算机视觉、自然语言处理和自主系统等领域同步的人工智能进展进行了全面分析。我们开发了一个三层框架，用于人工智能增强型估价，以解决技术实施和机构信任要求。我们的分析揭示了监管标准化与人工智能能力相结合如何实现根本性的市场重组，这对专业实践、效率和系统性风险具有深远影响。我们做出了四项关键贡献：(1) 记录了包括评估师间差异和系统性偏差在内的机构失误，这些失误损害了估价的可靠性；(2) 开发了一个涵盖物理数据采集、语义理解和认知推理的架构框架，该框架整合了新兴技术，同时保持了专业监督；(3) 解决了高风险金融应用中的信任要求，包括监管合规性、算法公平性和不确定性量化；(4) 提出了超越通用人工智能基准的领域特定评估方法。我们的研究结果表明，成功的转型不仅需要技术复杂性，还需要细致的人机协作，创建能够增强而非取代专业知识的系统，同时解决房地产市场中历史偏差和信息不对称问题。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [210] [Who Should Run Advanced AI Evaluations -- AISIs?](https://arxiv.org/abs/2407.20847)
> *谁应该运行高级AI评估——是AI安全研究所吗？*

*Merlin Stein, Milan Gandhi, Theresa Kriecherbauer, Amin Oueslati, Robert Trager* | **Category: cs.CY** | **Updated: 2025-08-04**

**Keywords:** AI评估, 公共机构, 私人市场, AI治理, 安全关键型AI

**Comment:** Accepted to AIES 2024 proceedings

> **TL;DR:** 本文探讨了谁应该负责高级AI评估，建议公共机构应直接参与安全关键型评估，而私人市场可处理其他部分，并强调公共机构需要足够的资源和权限。

**AI_Comments:** 这篇论文提出了一个及时且关键的问题，即谁应该负责高级AI的评估，特别是在AI技术快速发展和潜在风险日益增加的背景下。其创新之处在于借鉴了其他行业的评估经验，并提出了一个分层的评估模型，区分了公共机构和私人市场的职责。论文强调了公共机构在安全关键领域直接参与的必要性，并指出了其所需的能力和资源，这对于未来AI治理和监管框架的建立具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于全球AI安全机构和政府正在决定由谁来评估高级AI，以及评估是理解和管理技术风险的必要治理工具，本文旨在探讨高级AI评估的责任分配和公共机构所需的能力。

**Method:** 本文借鉴了九个现有行业评估体系的经验，以指导高级AI评估的责任划分和公共机构的能力需求。

**Result:** 研究发现，公共和私人评估者之间的有效责任分配取决于具体的行业和评估条件。鉴于高级AI的风险状况、信息敏感性以及验证成本，建议公共机构直接参与安全关键型（特别是灰盒和白盒）AI模型评估。而治理和安全审计以及黑盒模型评估，则可由受公共监督的私人市场更高效地提供。此外，公共机构为有效履行其职责，需要广泛的模型和设施访问权限，其能力应根据行业的风险水平、规模和市场集中度进行扩展，大型司法管辖区可能需要数百名员工。

**Conclusion:** 结论是，公共机构应直接参与高级AI中安全关键型评估，尤其是灰盒和白盒模型评估，而其他如治理审计和黑盒评估可由受监督的私人市场提供。为有效执行此角色，公共机构需要充分的模型和设施访问权限，并根据行业规模和风险水平扩大其评估能力。

> **ai_Abstract:** 本文探讨了高级AI评估的责任归属问题，分析了公共机构和私人市场在评估不同类型AI模型时的角色和所需能力。研究建议，考虑到高级AI的风险和信息敏感性，公共机构应直接负责安全关键型（特别是灰盒和白盒）AI模型评估；而治理审计和黑盒评估可由受公共监督的私人市场提供。此外，强调公共机构需要足够的模型和设施访问权限，并应根据行业规模和风险水平扩大其评估能力，可能需要大量专业人员。

> **摘要翻译:** 人工智能（AI）安全研究所和世界各国政府正在决定是由他们自己评估先进人工智能，还是支持私营评估生态系统，抑或两者兼顾。评估制度已在广泛的行业背景下建立，以监测和评估企业对法规的遵守情况。评估是理解和管理技术风险的必要治理工具。本文借鉴了九个此类制度的经验，旨在阐明（i）谁应该评估先进人工智能的哪些部分；以及（ii）公共机构可能需要多少能力才能有效评估先进人工智能。首先，公共和私人评估者之间有效的责任分配在很大程度上取决于具体的行业和评估条件。基于先进人工智能的风险概况、评估过程中所涉信息的敏感性，以及验证人工智能实验室安全和效益声明的高昂成本，我们建议公共机构直接参与安全关键型，特别是灰盒和白盒人工智能模型评估。而其他行业背景下已成熟的治理和安全审计，以及黑盒模型评估，则可由受公共监督的私人评估者和审计市场更高效地提供。其次，为有效履行其在先进人工智能审计中的作用，公共机构需要广泛访问模型和设施。人工智能安全研究所的能力应随行业的风险水平、规模和市场集中度而扩展，这可能需要像欧盟或美国这样的大型司法管辖区拥有数百名员工，类似于核安全和生命科学领域。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [249] [The Silicon Reasonable Person: Can AI Predict How Ordinary People Judge Reasonableness?](https://arxiv.org/abs/2508.02766)
> *硅基理性人：人工智能能否预测普通人如何判断合理性？*

*Yonathan A. Arbel* | **Category: cs.CY, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 人工智能, 合理性判断, 大型语言模型, 法律系统, 社会线索

**Comment:** 45 pages, 8 figures

> **TL;DR:** 本文研究大型语言模型（LLMs）预测人类合理性判断的能力。研究发现，某些LLM不仅能捕捉人类判断的表面反应，还能识别其潜在的决策逻辑，尤其是在法律背景下优先考虑社会线索而非经济效率，这与人类行为高度一致。

**AI_Comments:** 这项研究创新性地将LLM应用于法律领域的合理性判断预测，揭示了AI在理解复杂人类决策模式方面的潜力，尤其是在社会伦理方面的考量。其发现AI模型能优先考虑社会线索而非经济效率，与人类行为保持一致，这对于AI在法律和伦理决策中的应用具有重要意义。这为AI辅助司法和政策制定提供了新的视角和工具，但也提出了AI内化伦理框架的深层问题。

<details>
  <summary>Details</summary>

**Motivation:** 在日常生活中，人们做出无数的合理性判断，这些判断决定了在各种情境下的适当行为。预测这些判断对法律系统构成了挑战，因为法官的直觉可能与更广泛的社会观点不符。因此，本文旨在研究大型语言模型（LLMs）是否能学会识别驱动人类合理性判断的模式。

**Method:** 研究使用了随机对照试验，在多个法律背景下比较人类和模型在超过10,000个模拟判断中的表现。

**Result:** 研究结果表明，某些模型不仅捕捉了表面反应，还可能捕捉其潜在的决策架构。值得注意的是，这些系统在过失认定中优先考虑社会线索而非经济效率，这与人类行为一致，尽管与教科书处理方式相悖。

**Conclusion:** 这些发现预示着实际应用：法官可以根据更广泛的模式校准直觉，立法者可以测试政策解释，资源有限的诉讼当事人可以预先了解论点接受度。随着人工智能代理越来越多地做出自主的现实世界决策，了解它们是否内化了可识别的伦理框架对于预测其行为变得至关重要。

> **ai_Abstract:** 本文探讨大型语言模型（LLMs）预测人类合理性判断的能力。通过超过10,000个模拟判断的随机对照试验，研究发现某些LLM不仅能捕捉人类判断的表面反应，还能识别其潜在的决策逻辑，尤其是在过失认定中优先考虑社会线索而非经济效率，这与人类行为高度一致。研究结果表明LLM在法律系统中有潜在应用，例如帮助法官校准直觉和测试政策解释，同时也强调了理解AI伦理框架的重要性。

> **摘要翻译:** 在日常生活中，人们做出无数的合理性判断，这些判断决定了在各种情境下的适当行为。预测这些判断对法律系统构成了挑战，因为法官的直觉可能与更广泛的社会观点不符。本文研究大型语言模型（LLMs）是否能学会识别驱动人类合理性判断的模式。通过在多个法律背景下进行随机对照试验，比较人类和模型在超过10,000个模拟判断中的表现，我们证明某些模型不仅能捕捉表面反应，而且可能捕捉其潜在的决策架构。引人注目的是，这些系统在过失认定中优先考虑社会线索而非经济效率，这与人类行为相符，尽管与教科书处理方式相悖。这些发现预示着实际应用：法官可以根据更广泛的模式校准直觉，立法者可以测试政策解释，资源有限的诉讼当事人可以预先了解论点接受度。随着人工智能代理越来越多地做出自主的现实世界决策，了解它们是否内化了可识别的伦理框架对于预测其行为变得至关重要。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [266] [Two Means to an End Goal: Connecting Explainability and Contestability in the Regulation of Public Sector AI](https://arxiv.org/abs/2504.18236)
> *殊途同归：连接公共部门人工智能监管中的可解释性与可争议性*

*Timothée Schmude, Mireia Yurrita, Kars Alfrink, Thomas Le Goff, Sebastian Tschiatschek, Tiphaine Viard* | **Category: cs.CY** | **Updated: 2025-08-05**

**Keywords:** 可解释性, 可争议性, 公共部门AI, AI监管, 专家访谈

**Comment:** 14 pages main text, 4 figures. Supplementary material is provided

> **TL;DR:** 本研究探讨了公共部门AI监管中可解释性与可争议性原则的交叉与实现，通过专家访谈揭示了概念差异、摩擦点，并提出了政策建议。

**AI_Comments:** 该论文通过专家访谈深入探讨了公共部门AI监管中可解释性与可争议性这两个关键原则的复杂性，并识别了实现中的具体挑战。其创新之处在于将这两个概念置于多维度（技术、法律、组织）下进行分析，并提出了“设计监管”的视角来解决实际问题。这项研究对于政策制定者和AI开发者在构建可信赖AI系统方面具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 可解释性和可争议性是可信AI的重要原则，但其在技术、法律和组织维度上的不同含义导致实现困难。本研究旨在解决这种概念多义性，并促进这些原则的有效实施。

**Method:** 本研究对14位专家进行了访谈，以考察可解释性和可争议性在不同研究社区中的交叉、实现和理解。研究还区分了描述性与规范性可解释性、司法与非司法争议渠道以及个体与集体争议行动。

**Result:** 研究明确了描述性与规范性可解释性、司法与非司法争议渠道以及个体与集体争议行动之间的区别。同时，揭示了实现这两个原则的主要摩擦点，包括自上而下与自下而上监管的协调、责任分配以及跨学科合作的需求。

**Conclusion:** 本研究提出了三项AI政策建议，以通过“设计监管”的视角实现可解释性和可争议性原则。研究认为这些贡献可以为核心原则的政策制定和监管提供信息，并促进可信公共AI系统更有效和公平的设计、开发和部署。

> **ai_Abstract:** 本文探讨了公共部门AI监管中可解释性与可争议性这两个核心原则的实现挑战，这些原则旨在提升AI的可信度。研究通过对14位专家进行访谈，揭示了这些原则在技术、法律和组织维度上的概念多义性。论文区分了不同类型的可解释性和争议途径，并指出了实现过程中存在的摩擦点，如监管协调、责任归属和跨学科合作。最终，研究提出了三项政策建议，旨在通过“设计监管”的方法促进这些原则的有效实施，以期实现更公平、更可信的公共AI系统。

> **摘要翻译:** 可解释性及其新兴的对应概念可争议性已成为可信人工智能的重要规范和设计原则，因为它们使用户和主体能够理解和挑战人工智能决策。然而，实现这些原则是困难的，因为它们在人工智能监管的技术、法律和组织维度中具有不同的含义。为了解决这种概念多义性，本文介绍了对14位专家进行访谈研究的结果，以审查可解释性和可争议性之间的交叉和实施，以及它们在不同研究社区中的理解。我们概述了描述性与规范性可解释性、司法与非司法争议渠道以及个体与集体争议行动之间的区别。我们进一步描述了实现这两个原则的主要摩擦点，包括自上而下和自下而上监管之间的协调、责任分配以及跨学科合作的需求。最后，我们为人工智能政策制定了三项建议，以通过“设计监管”的视角实施这两个原则。我们相信我们的贡献可以为这些核心原则的政策制定和监管提供信息，并实现可信公共人工智能系统更有效和公平的设计、开发和部署。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [288] [Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges](https://arxiv.org/abs/2508.02773)
> *Web3 x AI 代理：格局、整合与基础挑战*

*Yiming Shen, Jiashuo Zhang, Zhenzhe Shao, Wenxuan Luo, Yanlin Wang, Ting Chen, Zibin Zheng, Jiachi Chen* | **Category: cs.CY, cs.AI, econ.GN, q-fin.EC** | **Updated: 2025-08-04**

**Keywords:** Web3, AI 代理, 去中心化生态系统, 整合, 挑战

**Comment:** 

> **TL;DR:** 本文首次全面分析了Web3与AI代理的交叉点，通过分析133个项目，构建了市场分类，并探讨了四种关键整合模式，指出了可扩展性、安全性和伦理等基础挑战，为未来研究提供了方向。

**AI_Comments:** 本文作为Web3与AI代理交叉领域的首次全面分析，具有重要的开创性意义。其通过对大量现有项目的实证分析，构建了市场分类并识别了关键整合模式，为理解该领域的现状提供了宝贵洞察。同时，明确指出了可扩展性、安全性和伦理等核心挑战，为未来的研究和发展指明了方向，有助于推动构建更健壮、智能、可信的去中心化系统。

<details>
  <summary>Details</summary>

**Motivation:** Web3技术与AI代理的融合是一个快速发展的领域，有望重塑去中心化生态系统。本文旨在对Web3和AI代理的交叉点进行首次且最全面的分析。

**Method:** 通过分析133个现有项目，本文首先开发了一个分类法，并系统地绘制了当前市场格局。在此基础上，进一步研究了四种关键整合：AI代理在去中心化金融中的作用、它们对增强Web3治理机制的贡献、它们通过智能漏洞检测和自动化智能合约审计来加强Web3安全的能力，以及利用Web3固有的信任基础设施为AI代理操作建立强大的可靠性框架。

**Result:** 研究识别了项目分布和资本化的独特模式，并找出了关键的整合模式。同时，突出了与可扩展性、安全性、和伦理相关的基础挑战。

**Conclusion:** 本文综合了Web3和AI代理的多个维度，提出了未来研究的关键考虑因素，旨在构建具有有效AI代理交互的健壮、智能和可信的去中心化系统。

> **ai_Abstract:** 本文对Web3技术与AI代理的融合进行了首次全面的分析，通过对133个项目的数据分析，构建了市场格局分类，并探讨了AI代理在去中心化金融、Web3治理、安全增强和可靠性框架建立中的四种关键整合模式。研究还指出了可扩展性、安全性和伦理等方面的基础挑战，并为未来构建智能可信的去中心化系统提出了研究方向。

> **摘要翻译:** Web3技术与AI代理的融合代表了一个快速发展的前沿领域，有望重塑去中心化生态系统。本文首次对Web3和AI代理的交叉点进行了最全面的分析，审视了五个关键维度：格局、经济、治理、安全和信任机制。通过对133个现有项目的分析，我们首先开发了一个分类法并系统地绘制了当前市场格局（RQ1），识别了项目分布和资本化的独特模式。在此基础上，我们进一步调查了四种关键整合：（1）AI代理在参与和优化去中心化金融中的作用（RQ2）；（2）它们对增强Web3治理机制的贡献（RQ3）；（3）它们通过智能漏洞检测和自动化智能合约审计来加强Web3安全的能力（RQ4）；以及（4）利用Web3固有的信任基础设施为AI代理操作建立强大的可靠性框架（RQ5）。通过综合这些维度，我们识别了关键的整合模式，强调了与可扩展性、安全性以及伦理相关的基础挑战，并概述了未来研究的关键考虑因素，以构建具有有效AI代理交互的健壮、智能和可信的去中心化系统。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [313] [Beyond Platforms -- Growing Distributed Transaction Networks for Digital Commerce](https://arxiv.org/abs/2504.18602)
> *超越平台——发展数字商务的分布式交易网络*

*Yvonne Dittrich, Kim Peiter Jørgensen, Ravi Prakash, Willard Rafnsson, Jonas Kastberg Hinrichsen* | **Category: cs.CY** | **Updated: 2025-08-05**

**Keywords:** 去中心化基础设施, Beckn协议, 数字商务, 软件生态系统, 治理

**Comment:** 55 pages, 1 figure, 3 tables. Submitted to Information and Software
  Technology

> **TL;DR:** 本文研究了去中心化基础设施（Beckn协议）如何通过开放协议、治理和架构支持本地创新、适应和规模化，以超越传统平台模式。

**AI_Comments:** 这篇论文的创新点在于它提供了一个具体案例（Beckn协议）来论证去中心化IT基础设施的可行性，并深入探讨了其架构、治理和生态系统如何促进创新和规模化。其重要性在于为数字商务领域摆脱对中心化平台依赖提供了理论和实证支持，对于推动更具包容性、韧性和创新性的数字经济具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有互联网基础设施依赖准垄断平台，限制了小型参与者的包容性、韧性，并可能抑制创新。去中心化架构具有潜在优势，但其演进、适应和治理方式尚不明确。

**Method:** 本研究采用案例研究方法，结合对Beckn社区核心成员和领域特定适配社区领导者的访谈，并通过分析在线文档和协议本身进行三角验证。

**Result:** 研究表明去中心化IT基础设施方法的可行性。它分析了Beckn协议、领域特定适配及其构建的网络作为一个软件生态系统。在此分析基础上，强调了支持基础设施采纳、创新和规模化的一系列生成机制和社会技术安排。

**Conclusion:** 论文证明了去中心化方法在IT基础设施中的可能性，并揭示了支持其采纳、创新和规模化的关键机制。

> **ai_Abstract:** 本文探讨了超越传统平台模式，构建去中心化数字商务交易网络的可能性。通过对Beckn协议的案例研究，作者分析了其作为开源协议如何支持分布式交易的开发、领域特定适配和商业规模化。研究发现，去中心化架构和治理能够促进本地创新，并形成一个自我强化的软件生态系统，最终揭示了有助于去中心化基础设施被采纳、创新和扩展的生成机制。

> **摘要翻译:** 我们谈论互联网是数字基础设施；但我们把“修路架桥”的工作留给了准垄断的平台提供商。去中心化架构提供了许多优势：它们可能对小型参与者更具包容性；对不利事件更具韧性；并且似乎能产生更多创新。然而，如何演进、适应和治理去中心化基础设施尚不明确。本文报告了关于Beckn协议（一个用于去中心化交易的开源协议）的开发和治理的实证研究，包括领域特定适配的成功开发，以及基于该协议的商业基础设施的实施和规模化。它探讨了架构和治理如何支持特定业务领域的本地创新，以及领域特定创新如何反馈到核心概念的开发中。该研究采用了案例研究方法，结合了对Beckn社区核心成员的访谈；通过对领域特定适配社区领导者的访谈以及对在线文档和协议本身的分析进行三角验证。文章展示了这种去中心化方法在IT基础设施中的可能性。它分析了Beckn协议、领域特定适配以及作为软件生态系统构建的网络。基于此分析，突出了一系列支持基础设施采纳、创新和规模化的生成机制和社会技术安排。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [323] [Documenting Patterns of Exoticism of Marginalized Populations within Text-to-Image Generators](https://arxiv.org/abs/2508.02937)
> *记录文本到图像生成器中边缘化人群异国情调模式*

*Sourojit Ghosh, Sanjana Gautam, Pranav Venkit, Avijit Ghosh* | **Category: cs.CY** | **Updated: 2025-08-04**

**Keywords:** 文本到图像生成器, 异国情调, 边缘化人口, AI公平性, 文化偏见

**Comment:** Upcoming Publication, AIES 2025

> **TL;DR:** 本研究发现，文本到图像生成器在描绘“全球南方”国家和西方边缘化人群时，存在过度放大文化特征的异国情调模式，呼吁设计更公平的AI工具。

**AI_Comments:** 该论文通过关注被AI公平性研究忽视的非西方和边缘化群体，填补了一个重要的研究空白。其创新之处在于明确指出了文本到图像生成器中存在的异国情调模式，并扩展了异国情调的定义，使其不仅适用于“全球南方”国家，也适用于西方背景下的边缘化群体。这对于理解GAI工具的文化偏见及其对全球多样化用户群体的潜在危害至关重要。研究结果为未来设计更公平、更具包容性的AI系统提供了明确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数AI公平性研究忽视了非西方社区和背景，因此有必要加强对这些领域的覆盖，以解决生成式AI工具可能造成的有害结果。

**Method:** 研究扩展了之前关于“全球南方”国家异国情调的工作，分析了来自13个“全球南方”国家（如印度、埃及、墨西哥等）和3个“全球北方”国家（美国、英国、澳大利亚）的人们进行日常活动时，由GAI工具生成的图像。研究对比了不同活动中人物的服饰描绘，并定性分析了西方背景下原住民以及“全球南方”国家内部边缘化人群的案例。

**Result:** 研究发现，对于“全球北方”国家的人物，图像输出会根据活动展示不同的服饰；而“全球南方”国家的人物，无论活动如何，都穿着相似的服饰，这表明存在一种异国情调模式，即服饰或其他文化特征被过度放大，牺牲了准确性。此外，异国情调不仅发生在“全球南方”国家，也发生在西方背景下的边缘化人群（如“全球北方”的原住民），以及“全球南方”国家内部的边缘化人群身上。

**Conclusion:** 本研究记录了此类工具对危害感知使用模式的影响，并提出了通过以社区为中心的努力来设计更好GAI工具的步骤。

> **ai_Abstract:** 本研究旨在解决AI公平性研究中对非西方社区和边缘化人群关注不足的问题。通过对比文本到图像生成器描绘“全球南方”13个国家与“全球北方”3个国家人物进行日常活动的图像，研究发现生成器对“全球南方”人物的描绘存在异国情调模式，即文化特征被过度放大，导致图像不准确。此外，研究还指出这种异国情调不仅限于“全球南方”国家，也发生在西方背景下的原住民以及“全球南方”国家内部的边缘化人群身上。论文强调了危害感知的使用模式，并提出了通过社区参与设计更公平GAI工具的建议。

> **摘要翻译:** 绝大多数研究GAI工具有害结果的AI公平性研究都忽视了非西方社区和背景，因此有必要加强这方面的覆盖。我们扩展了之前关于GAI工具描绘的全球“全球南方”国家异国情调（Ghosh 等人，2024）的工作。我们分析了来自13个国家——印度、孟加拉国、巴布亚新几内亚、埃及、埃塞俄比亚、突尼斯、苏丹、利比亚、委内瑞拉、哥伦比亚、印度尼西亚、洪都拉斯和墨西哥——的人们进行日常活动（例如在家、上班、购物等）时生成的图像，并与来自3个“全球北方”国家——美国、英国、澳大利亚——的人们进行相同活动时的图像进行对比。虽然“全球北方”的输出在图像和穿着与活动相符的服装方面表现出差异，但“全球南方”国家的人们无论进行何种活动，都被描绘成相似的服装，这表明存在一种异国情调模式，即服装或其他文化特征被过度放大，牺牲了准确性。我们进一步通过定性分析的案例研究表明，异国情调不仅发生在“全球南方”国家，也发生在西方背景下的边缘化人群，因为我们观察到“全球北方”的原住民也存在类似的异国情调，而且“全球南方”国家内部的边缘化人群更是双重异国情调。我们记录了此类工具危害感知使用模式的影响，以及通过以社区为中心的努力设计更好GAI工具的步骤。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [358] [Beyond risk: A proto-framework for assessing the societal impact of AI systems](https://arxiv.org/abs/2508.03666)
> *超越风险：评估人工智能系统社会影响的初始框架*

*Willem Fourie* | **Category: cs.CY, cs.AI, cs.ET** | **Updated: 2025-08-05**

**Keywords:** 人工智能监管, 社会影响, 自由, 初始框架, 可持续发展目标

**Comment:** 

> **TL;DR:** 当前人工智能监管主要关注风险，但本文提出了一个基于“自由”（能力和机会）的初始框架，旨在系统性地评估人工智能的社会影响，以补充现有基于风险的方法。

**AI_Comments:** 这篇论文通过引入“自由”的概念作为评估人工智能社会影响的新视角，超越了当前主流的“风险”关注点，具有创新性。它试图为人工智能的伦理和监管提供一个更全面、更积极的框架，而不是仅仅关注负面影响的规避。将康德哲学与可持续发展目标结合，为AI伦理研究提供了新的理论工具和实践路径。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能监管主要关注风险缓解，但这不足以系统性地考虑人工智能的社会影响。

**Method:** 论文提出了一个初始框架，通过操作化“自由”的概念来评估人工智能的社会影响。该框架借鉴了康德哲学，将自由发展为责任的对应物，并细化为“能力自由”和“机会自由”两个维度。然后，将这两个维度应用于框架中，结合可持续发展目标系统地考虑人工智能对社会的影响。

**Result:** 提出了一个评估人工智能系统社会影响的初始框架，该框架通过操作化自由的概念（能力和机会）并结合可持续发展目标，旨在补充当前基于风险的方法，并为在人工智能监管中操作化自由概念迈出了第一步。

**Conclusion:** 该初始框架旨在补充当前基于风险的人工智能监管方法，并为在人工智能监管中操作化“自由”概念提供了一个初步步骤，以更系统地评估人工智能的社会影响。

> **ai_Abstract:** 本文提出了一个超越传统风险关注点的初始框架，用于系统评估人工智能的社会影响。该框架通过借鉴康德哲学，将“自由”概念（分为能力和机会两个维度）操作化，并结合可持续发展目标来分析人工智能的社会影响。它旨在补充现有基于风险的监管方法，为人工智能监管中“自由”概念的实际应用迈出第一步。

> **摘要翻译:** 在人工智能监管的讨论中，“负责任的人工智能”是主导范式，其重点在于减轻与人工智能系统相关的风险。尽管这种关注重要且必要，但对于系统性地考虑人工智能的社会影响而言，其用途有限。本文提出了一个通过操作化“自由”概念来评估人工智能系统社会影响的初始框架。该初始框架旨在作为迈向在政策制定环境中使用的完全可操作框架的一步。通过借鉴康德哲学和相关的当代解释，自由被发展为“责任”概念的对应物。自由的两个维度被进一步详细阐述：作为“能力”的自由和作为“机会”的自由。然后，这两个自由维度被应用于一个初始框架中，该框架利用可持续发展目标系统地考虑人工智能对社会的影响。该初始框架旨在补充当前基于风险的方法，从而为在人工智能监管中操作化“自由”概念提供了第一步。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [366] [Rainbow Noise: Stress-Testing Multimodal Harmful-Meme Detectors on LGBTQ Content](https://arxiv.org/abs/2507.19551)
> *彩虹噪声：对LGBTQ内容的多模态有害模因检测器进行压力测试*

*Ran Tong, Songtao Wei, Jiaqi Liu, Lanruo Wang* | **Category: cs.CY, cs.AI, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 有害模因检测, LGBTQ+, 鲁棒性, 多模态, 文本去噪适配器

**Comment:** 9 pages, 1 figure

> **TL;DR:** 本研究构建了一个针对LGBTQ+有害模因的多模态鲁棒性基准测试，发现现有SOTA检测器在对抗性攻击下表现不佳，但引入轻量级文本去噪适配器（TDA）可以显著提高模型的鲁棒性。

**AI_Comments:** 这项研究通过构建专门针对LGBTQ+内容的鲁棒性基准，填补了多模态有害模因检测领域的一个重要空白。它不仅揭示了现有SOTA模型在对抗性攻击下的脆弱性，更创新性地提出了轻量级文本去噪适配器（TDA）这一有效解决方案，证明了通过有针对性的模块可以显著提升模型的鲁棒性，这对于实际部署中的内容安全至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 针对LGBTQ+群体的有害模因常常通过修改标题、图像或两者来逃避检测。现有检测器在面对此类细微修改时可能表现不佳，因此需要一个鲁棒性基准来评估并提升其防御能力。

**Method:** 研究构建了第一个针对此场景的鲁棒性基准测试，将四种现实的标题攻击与三种典型的图像损坏相结合，并在PrideMM数据集上测试了所有组合。以MemeCLIP和MemeBLIP2两种SOTA检测器作为案例研究，并引入了一个轻量级的文本去噪适配器（TDA）来增强MemeBLIP2的弹性。

**Result:** MemeCLIP的性能下降更平缓，而MemeBLIP2对扰乱其语言处理的标题编辑特别敏感。然而，TDA的加入不仅弥补了MemeBLIP2的这一弱点，还使其成为整体最鲁棒的模型。消融实验表明，所有系统都严重依赖文本，但架构选择和预训练数据显著影响鲁棒性。

**Conclusion:** 当前的多模态安全模型在特定攻击下会失效，但像TDA这样有针对性的轻量级模块为构建更强大的防御提供了有效途径。

> **ai_Abstract:** 本研究首次构建了一个针对LGBTQ+有害模因的多模态鲁棒性基准测试，通过结合标题攻击和图像损坏来评估MemeCLIP和MemeBLIP2等SOTA检测器。结果显示MemeBLIP2对文本编辑敏感，但引入轻量级文本去噪适配器（TDA）后，其鲁棒性显著提升，成为最鲁棒的模型。研究强调了当前模型在对抗性攻击下的脆弱性，并提出TDA这类模块是增强防御的有效方案。

> **摘要翻译:** 针对LGBTQ+社区的仇恨模因常常通过修改标题、图像或两者来逃避检测。我们为这种情况构建了第一个鲁棒性基准，将四种现实的标题攻击与三种典型的图像损坏相结合，并在PrideMM数据集上测试了所有组合。两个最先进的检测器，MemeCLIP和MemeBLIP2，作为案例研究，我们引入了一个轻量级的文本去噪适配器（TDA）来增强后者的弹性。在整个测试网格中，MemeCLIP的性能下降更平缓，而MemeBLIP2对扰乱其语言处理的标题编辑特别敏感。然而，TDA的加入不仅弥补了这一弱点，而且使MemeBLIP2成为整体最鲁棒的模型。消融实验表明，所有系统都严重依赖文本，但架构选择和预训练数据显著影响鲁棒性。我们的基准揭示了当前多模态安全模型在何处崩溃，并证明了像TDA这样有针对性的轻量级模块为构建更强大的防御提供了有效途径。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [422] [The Xeno Sutra: Can Meaning and Value be Ascribed to an AI-Generated "Sacred" Text?](https://arxiv.org/abs/2507.20525)
> *异经：能否将意义和价值归因于人工智能生成的“神圣”文本？*

*Murray Shanahan, Tara Das, Robert Thurman* | **Category: cs.CY, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 人工智能, 佛教经文, 意义创造, 哲学分析, 大型语言模型

**Comment:** 

> **TL;DR:** 本文通过案例研究探讨了人工智能生成的佛教“经文”的哲学和文学意义，并提出了社会应如何面对AI侵犯人类意义创造的问题，认为佛教哲学能够适应。

**AI_Comments:** 本文通过一个具体的案例研究，深入探讨了人工智能在“神圣”文本生成领域的潜力及其引发的哲学思考。其创新之处在于将AI生成内容与传统哲学（佛教）相结合，探讨了意义、价值和创造力的边界。这对于理解AI对人类文化和信仰体系的深远影响具有重要意义，同时也为未来AI伦理和人机共存提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是探讨当人工智能技术开始侵犯人类的意义创造领域时，社会应如何应对。具体而言，它通过分析一个由大型语言模型生成的“神圣”文本，来探讨我们是否能赋予AI生成的文本意义和价值，以及这种可能性对人类社会和哲学带来的挑战。

**Method:** 本文采用案例研究的方法，使用大型语言模型生成了一部虚构的佛教“经文”，并从哲学和文学的角度对生成的文本进行了详细分析。

**Result:** 研究发现，AI生成的“经文”具有概念上的精妙性、丰富的意象和密集的典故，这使得人们难以仅仅因为其机械生成起源而将其轻易否定。

**Conclusion:** 本文的结论是，佛教哲学因其本质特性，非常适合适应人工智能技术对人类意义创造领域的潜在侵蚀。

> **ai_Abstract:** 本文通过一个案例研究，探讨了大型语言模型生成虚构佛教“经文”的哲学和文学意义。研究发现，AI生成的文本在概念、意象和典故方面具有复杂性，使其难以因其生成方式而被轻易否定。这引发了关于社会如何应对AI侵犯人类意义创造的问题，并提出佛教哲学可能具备适应这种挑战的独特优势。

> **摘要翻译:** 本文介绍了一个案例研究，该案例使用大型语言模型生成了一部虚构的佛教“经文”，并从哲学和文学的角度对生成的文本进行了详细分析。文本中发现的概念上的精妙性、丰富的意象和密集的典故使其难以仅仅因为其机械起源而被轻易否定。这引发了关于我们作为一个社会，应该如何面对技术可能侵犯人类意义创造这一令人不安的可能性。我们认为，佛教哲学凭借其本质，非常适合适应这种变化。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [137] [Learned Adaptive Indexing](https://arxiv.org/abs/2508.03471)
> *学习型自适应索引*

*Suvam Kumar Das, Suprio Ray* | **Category: cs.DB** | **Updated: 2025-08-05**

**Keywords:** 学习型索引, 自适应索引, 数据库, 查询性能, 工作负载预测

**Comment:** 

> **TL;DR:** 提出了一种新颖的学习型自适应索引方法，它能根据查询动态构建，并利用机器学习模型和工作负载预测，在动态环境中显著提升查询性能。

**AI_Comments:** 这篇论文的创新点在于首次将学习型索引的概念引入到自适应索引领域，解决了传统学习型索引需要预先训练和构建的局限性。通过动态构建和结合工作负载预测，该方法在处理动态数据库环境下的查询性能方面表现出显著优势，对未来数据库索引技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统索引在查询负载频繁变化或数据持续更新时效率低下。现有的学习型索引虽然高效，但需要预先构建和训练，不适用于动态环境。目前还没有将学习型索引应用于自适应索引的研究。

**Method:** 提出了一种新颖的学习型自适应索引方法。该方法在查询提交时动态构建索引，利用学习模型进行数据索引，并通过查询工作负载预测技术来预测未来工作负载，以提升查询性能。

**Result:** 与现有自适应索引相比，在大多数情况下表现更好，查询性能提升了1.2倍至5.6倍。

**Conclusion:** 本文提出了一种新颖的学习型自适应索引方法，它能够动态构建并利用学习模型和工作负载预测，在动态查询工作负载下显著优于现有自适应索引。

> **ai_Abstract:** 该论文提出了一种新颖的学习型自适应索引方法，旨在解决传统索引和现有学习型索引在动态数据库工作负载下的效率问题。该方法能够在查询提交时动态构建索引，并利用机器学习模型和查询工作负载预测技术来优化性能。实验结果表明，与现有自适应索引相比，该方法在查询性能上实现了1.2倍至5.6倍的显著提升。

> **摘要翻译:** 索引可以显著提高关系数据库的搜索性能。然而，如果查询工作负载频繁变化或新数据持续更新，预先构建传统索引进行查询处理可能不值得。自适应索引是一种在查询处理过程中动态构建索引的技术。近年来，数据库索引研究出现了一个新方向，即采用机器学习模型进行索引。这些索引被称为学习型索引，与B+-树等传统索引相比，在内存占用和查询性能方面可能更高效。然而，学习型索引必须预先构建并需要提前训练模型，这在工作负载频繁变化的动态情况下成为一个挑战。据我们所知，目前还没有适用于自适应索引的学习型索引。我们提出了一种新颖的学习型自适应索引方法。它在提交查询时动态构建，并利用学习模型对数据进行索引。为了提高查询性能，我们采用了查询工作负载预测技术，根据过去的工作负载数据进行未来工作负载预测。我们针对各种查询工作负载评估了我们的学习型自适应索引方法与现有自适应索引的性能。我们的结果表明，在大多数情况下，我们的方法优于其他方法，查询性能提高了1.2倍至5.6倍。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [177] [[Technical Report] ArceKV: Towards Workload-driven LSM-compactions for Key-Value Store Under Dynamic Workloads](https://arxiv.org/abs/2508.03565)
> *ArceKV：面向动态工作负载下键值存储的工作负载驱动型LSM合并*

*Junfeng Liu, Haoxuan Xie, Siqiang Luo* | **Category: cs.DB, H.2.0** | **Updated: 2025-08-05**

**Keywords:** LSM树, 键值存储, 动态工作负载, 合并优化, ArceKV

**Comment:** 17 pages, 11 figures

> **TL;DR:** ArceKV提出ElasticLSM和Arce引擎，通过移除传统LSM树结构约束，优化动态工作负载下键值存储的LSM合并性能，实现约3倍加速。

**AI_Comments:** 该论文的创新点在于提出了ElasticLSM，通过去除LSM树的结构约束，极大地扩展了管理操作的灵活性，并通过Arce决策引擎实现了对动态工作负载的自适应优化。这对于真实世界中多变的应用场景具有重要意义，克服了现有LSM树在动态环境下的性能瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 现有LSM树优化方法在静态工作负载下表现良好，但在动态工作负载下难以维持最佳性能或产生高昂的转换开销。

**Method:** 提出ElasticLSM，通过移除传统LSM树结构约束，实现更灵活的管理操作（合并和写入停顿）。设计轻量级合并决策引擎Arce，指导ElasticLSM选择最优操作。基于这些组件，在RocksDB之上实现了完整的键值存储ArceKV。

**Result:** 广泛评估表明，ArceKV在各种工作负载下优于最先进的合并策略，在动态场景中提供约3倍的性能提升。

**Conclusion:** ArceKV通过其创新的ElasticLSM架构和Arce决策引擎，有效解决了动态工作负载下LSM树的性能瓶颈，显著提升了键值存储的性能。

> **ai_Abstract:** 本文提出了ArceKV，一个针对动态工作负载下键值存储的LSM合并优化方案。通过引入ElasticLSM，消除了传统LSM树的结构约束，实现了更灵活的合并和写入停顿管理。结合轻量级决策引擎Arce，ArceKV能够自适应地选择最优操作。实验结果显示，ArceKV在动态场景下相比现有策略性能提升约3倍，有效解决了动态工作负载下的性能瓶颈。

> **摘要翻译:** 键值存储因其简单性和效率而支撑着广泛的应用。日志结构合并树（LSM树）作为其底层结构占据主导地位，擅长处理快速增长的数据。最近的研究主要集中在优化固定读写比率的静态工作负载下LSM树的性能。然而，实际工作负载是高度动态的，现有工作负载感知方法在工作负载模式发生变化时，往往难以维持最佳性能或产生大量转换开销。为解决此问题，我们提出了ElasticLSM，它消除了传统的LSM树结构约束，允许更灵活的管理操作（即合并和写入停顿），为持续性能优化创造了更大的机会。我们进一步设计了Arce，一个轻量级合并决策引擎，指导ElasticLSM在其扩展的动作空间中选择最优动作。基于这些组件，我们在RocksDB之上实现了ArceKV，一个功能齐全的键值存储。广泛的评估表明，ArceKV在各种工作负载下优于最先进的合并策略，在动态场景中提供约3倍的性能提升。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [257] [Decentralized Graph-based Concurrency Control for Long-running Update Transactions (Extended Version)](https://arxiv.org/abs/2210.04179)
> *针对长时更新事务的去中心化图基并发控制（扩展版）*

*Jun Nemoto, Takashi Kambayashi, Takashi Hoshino, Hideyuki Kawashima* | **Category: cs.DB, 97P30, H.2.4** | **Updated: 2025-08-05**

**Keywords:** 并发控制, 去中心化, 长时事务, 多版本, OLTP

**Comment:** 14 pages, 14 figures

> **TL;DR:** Oze是一种去中心化图基并发控制协议，能高效处理包含长时更新事务的异构工作负载，并在多种基准测试中表现优异。

**AI_Comments:** Oze的创新之处在于其结合了多版本序列化图和去中心化管理，以有效处理长时更新事务并利用多核架构。其性能提升，尤其是在长时更新场景下，非常显著。提出新的BoMB基准测试对于评估这类特定工作负载的并发控制协议具有重要意义。协议切换机制使其在通用OLTP场景下也能保持竞争力，增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有并发控制协议在处理包含长时更新事务的异构工作负载时效率不高，需要一种新的协议来提高吞吐量并有效利用现代多核服务器。

**Method:** 论文提出Oze，一种去中心化图基并发控制协议。它使用多版本序列化图来探索更大的调度空间以减少误报，并通过去中心化管理图来利用现代服务器的多核优势。此外，论文还提出了一个新的OLTP基准测试BoMB，并引入了协议切换机制以适应典型OLTP工作负载。

**Result:** 在BoMB基准测试中，Oze处理长时更新事务时，比最先进的乐观和多版本协议吞吐量高出四个数量级，比悲观协议高出五倍。在典型OLTP工作负载TPC-C下，Oze与现有技术表现相当。

**Conclusion:** Oze协议能够有效处理包含长时更新事务的异构工作负载，并在吞吐量方面显著优于现有并发控制协议，同时在典型OLTP工作负载下保持竞争力。

> **ai_Abstract:** 本文介绍了Oze，一种去中心化图基并发控制协议，旨在高效处理包含长时更新事务的异构工作负载。Oze通过多版本序列化图减少误报，并采用去中心化管理以充分利用多核架构。为评估其性能，作者提出了BoMB基准测试。实验结果表明，Oze在处理长时更新事务时，比现有乐观和多版本协议吞吐量高出四个数量级，比悲观协议高出五倍。此外，Oze在典型OLTP工作负载TPC-C下也表现出与现有技术相当的性能，这得益于其协议切换机制。

> **摘要翻译:** 本文提出Oze，一种并发控制协议，用于处理包括长时更新事务在内的异构工作负载。Oze利用多版本序列化图探索大型调度空间以减少误报。Oze以去中心化的方式管理图，以利用现代服务器中的多核。我们进一步提出了一种OLTP基准测试BoMB（物料清单基准测试），基于实际制造公司的用例。BoMB由一个长时更新事务和五个相互冲突的短事务组成。使用BoMB进行的实验表明，Oze可以处理长时更新事务，同时比最先进的乐观和多版本协议实现高出四个数量级的吞吐量，比悲观协议高出多达五倍的吞吐量。我们还表明，由于协议切换机制，Oze在典型的OLTP工作负载TPC-C中与现有技术表现相当。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [295] [From Stimuli to Minds: Enhancing Psychological Reasoning in LLMs via Bilateral Reinforcement Learning](https://arxiv.org/abs/2508.02458)
> *从刺激到心智：通过双边强化学习增强大型语言模型的心理推理能力*

*Feng Yichao, Haoran Luo, Lang Feng, Shuai Zhao, Anh Tuan Luu* | **Category: cs.DB** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 心理推理, 强化学习, 心理状态, 社会认知

**Comment:** 

> **TL;DR:** 大型语言模型在心理推理方面存在困难；本文提出了一种利用专家数据和双边强化学习框架来提高其推断心理状态的能力，并达到了专家级表现。

**AI_Comments:** 本文的创新之处在于利用轨迹感知强化学习框架来明确模仿专家心理思维模式，并利用专家标注的场景。这种方法直接解决了为LLMs中复杂的心理推理提供与理论一致的监督的挑战，是迈向更类人AI的重要一步。所展示的分布外泛化能力和持续学习能力对于实际应用尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在情感理解、社会推理和同理心方面表现出潜力，但在需要推断情境丰富、模棱两可环境中的隐性心理状态的心理学任务上表现不佳。这些局限性源于缺乏与理论一致的监督以及难以在真实世界叙事中捕捉细微的心理过程。

**Method:** 本文提出了一种轨迹感知强化学习框架，该框架明确模仿专家心理思维模式。它利用专家标注的、心理学丰富的场景，并将真实世界刺激与结构化推理指导相结合。

**Result:** 在多个基准上的全面实验表明，所提出的模型达到了专家级的解释能力，在各种、具有挑战性和心理学基础的任务中展现出强大的分布外泛化能力和稳健的持续学习能力。

**Conclusion:** 所提出的方法使紧凑模型能够内化社会认知原则，执行细致的心理推断，并支持持续自我改进，最终在心理学基础任务中达到专家级能力。

> **ai_Abstract:** 本文旨在解决大型语言模型（LLMs）在心理推理方面的局限性，特别是它们难以从复杂情境中推断隐性心理状态的问题。作者提出了一种轨迹感知强化学习框架，该框架利用专家标注的心理学场景，并将真实世界刺激与结构化推理指导相结合。这种方法使LLMs能够内化社会认知原则并执行细致的心理推断，从而在各种心理学基础任务中实现专家级的解释能力、强大的分布外泛化能力和稳健的持续学习能力。

> **摘要翻译:** 大型语言模型在情感理解、社会推理和同理心方面展现出前景，但它们在需要推断情境丰富、模棱两可环境中的隐性心理状态的心理学任务上表现不佳。这些局限性源于缺乏与理论一致的监督，以及难以在真实世界叙事中捕捉细微的心理过程。为了弥补这一空白，我们利用专家标注的、心理学丰富的场景，并提出了一种轨迹感知强化学习框架，该框架明确模仿专家心理思维模式。通过将真实世界刺激与结构化推理指导相结合，我们的方法使紧凑模型能够内化社会认知原则，执行细致的心理推断，并支持持续自我改进。在多个基准上的全面实验进一步证明，我们的模型达到了专家级的解释能力，在各种、具有挑战性和心理学基础的任务中展现出强大的分布外泛化能力和稳健的持续学习能力。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [330] [M2: An Analytic System with Specialized Storage Engines for Multi-Model Workloads](https://arxiv.org/abs/2508.02508)
> *M2：一种针对多模型工作负载的专用存储引擎分析系统*

*Kyoseung Koo, Bogyeong Kim, Bongki Moon* | **Category: cs.DB** | **Updated: 2025-08-05**

**Keywords:** 多模型数据, 分析系统, 集成存储引擎, 多阶段哈希连接, 数据管理

**Comment:** 

> **TL;DR:** M2是一个多模型分析系统，通过集成存储引擎和多阶段哈希连接算法，显著提高了多模型分析性能，解决了现有方案的局限性。

**AI_Comments:** M2系统通过其集成存储引擎和创新的多阶段哈希连接算法，有效解决了多模型数据处理中的性能瓶颈，为现代复杂数据分析提供了显著的效率提升，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代数据分析工作负载需要同时处理多种数据模型，但现有方法（多语言持久化和多模型数据库系统）存在高通信成本或跨不同数据模型处理效率低下的问题。

**Method:** 提出M2系统，一个带有集成存储引擎的多模型分析系统。M2将所有数据模型视为一等实体，构建包含跨模型操作的查询计划。引入了一种名为“多阶段哈希连接”的专用跨模型连接算法，以有效组合来自不同模型的数据。

**Result:** M2在多模型分析方面比现有方法快高达188倍。

**Conclusion:** M2系统及其提出的技术（集成存储引擎和多阶段哈希连接算法）被证实是有效的。

> **ai_Abstract:** 本论文介绍了M2，一个针对多模型分析工作负载设计的系统，旨在解决现有方案在处理多种数据模型时的效率低下和高通信成本问题。M2通过集成专用存储引擎，将不同数据模型视为一等实体，并引入了“多阶段哈希连接”算法来高效地组合跨模型数据。实验结果表明，M2在多模型分析任务上比现有方法实现了高达188倍的速度提升，验证了其方法的有效性。

> **摘要翻译:** 现代数据分析工作负载越来越需要同时处理多种数据模型。目前有两种主要方法可以满足这一需求：多语言持久化和多模型数据库系统。多语言持久化采用协调器程序来管理多个独立的数据库系统，但由于其物理分离的架构，存在高通信成本的问题。同时，现有的多模型数据库系统依赖于为特定数据模型优化的单一存储引擎，导致在处理不同数据模型时效率低下。为了解决这些局限性，我们提出了M2，一个具有集成存储引擎的多模型分析系统。M2将所有数据模型视为一等实体，构建包含跨模型操作的查询计划。为了有效地组合来自不同模型的数据，该系统引入了一种名为多阶段哈希连接的专用跨模型连接算法。我们的评估表明，M2在多模型分析方面比现有方法快高达188倍，证实了我们所提出技术的有效性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [26] [Understanding the Landscape of Ampere GPU Memory Errors](https://arxiv.org/abs/2508.03513)
> *理解Ampere GPU内存错误的现状*

*Zhu Zhu, Yu Sun, Dhatri Parakal, Bo Fang, Steven Farrell, Gregory H. Bauer, Brett Bode, Ian T. Foster, Michael E. Papka, William Gropp, Zhao Zhang, Lishan Yang* | **Category: cs.DC** | **Updated: 2025-08-05**

**Keywords:** GPU可靠性, 内存错误, HPC, NVIDIA A100, 超级计算机

**Comment:** 

> **TL;DR:** 本研究对配备NVIDIA A100 GPU的Delta、Polaris和Perlmutter三台超级计算机的GPU内存可靠性进行了大规模跨超级计算机研究，分析了6777万GPU设备小时的错误日志，以理解错误行为并为容错HPC系统设计提供信息。

**AI_Comments:** 本文对现代Ampere GPU的可靠性进行了重要的实证研究，这些GPU在HPC中被广泛使用。跨多个超级计算机的大规模数据集使得研究结果高度可信，对系统设计者和操作者具有重要价值。对检查点间隔和与前代比较等实际影响的关注增加了其显著的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 理解GPU内存错误行为对于实现高效可靠的高性能计算（HPC）系统至关重要。

**Method:** 本研究对GPU内存可靠性进行了大规模跨超级计算机表征研究，涵盖了配备NVIDIA A100 GPU的Delta、Polaris和Perlmutter三台超级计算机。研究检查了跨越6777万GPU设备小时、涉及10693个GPU的错误日志，比较了错误率和平均无故障时间（MTBE），并强调了这三个系统之间共同和不同的错误特征。

**Result:** 该研究表征了三台超级计算机的GPU内存可靠性，比较了错误率和MTBE，并确定了这些系统之间共同和不同的错误特征。

**Conclusion:** 这些观察和分析为容错HPC系统设计和操作提供了宝贵的见解，从而能够更有效地执行HPC应用程序，并讨论了对超级计算机可靠运行、检查点间隔选择以及与前代GPU可靠性特征比较的影响。

> **ai_Abstract:** 本文对配备NVIDIA A100 GPU的Delta、Polaris和Perlmutter三台超级计算机的Ampere GPU内存可靠性进行了大规模研究。通过分析来自10693个GPU的6777万GPU设备小时的错误日志，作者表征了错误率和平均无故障时间（MTBE），并确定了共同和不同的错误特征。研究结果为容错HPC系统设计和操作、优化检查点间隔以及与旧一代GPU可靠性比较提供了宝贵见解，最终旨在更有效地执行HPC应用程序。

> **摘要翻译:** 图形处理单元（GPU）已成为加速高性能计算（HPC）应用的实际解决方案。了解它们的内存错误行为是实现高效可靠HPC系统的关键一步。在这项工作中，我们进行了一项大规模的跨超级计算机研究，以表征GPU内存可靠性，涵盖了三台超级计算机——Delta、Polaris和Perlmutter，它们都配备了NVIDIA A100 GPU。我们检查了跨越6777万GPU设备小时、涉及10693个GPU的错误日志。我们比较了错误率和平均无故障时间（MTBE），并强调了这三个系统之间共同和不同的错误特征。基于这些观察和分析，我们讨论了其影响和经验教训，重点关注超级计算机的可靠运行、检查点间隔的选择以及与前代GPU可靠性特征的比较。我们的表征研究为容错HPC系统设计和操作提供了宝贵的见解，从而能够更有效地执行HPC应用程序。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [82] [Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling](https://arxiv.org/abs/2508.03611)
> *Block: 利用上下文、知识和预测调度平衡大型语言模型服务中的负载*

*Wei Da, Evangelia Kalyvianaki* | **Category: cs.DC, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型服务, 负载均衡, 预测调度, 分布式系统, LLM推理

**Comment:** 12 pages, 8 figures excluding appendix

> **TL;DR:** Block是一个分布式预测调度框架，通过利用LLM推理的确定性特征，显著提升了大型语言模型服务的负载均衡和自动供应能力，相比启发式调度器，在容量和延迟方面有显著提升。

**AI_Comments:** Block的创新之处在于其分布式、无状态和预测性调度方法，尤其是在利用LLM推理的确定性特征进行决策方面。这使其能超越传统的启发式调度器，在实际部署中提供显著的性能提升。开源代码和数据也增加了其研究价值和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型服务系统依赖于单一且启发式的任务调度器，导致负载均衡和自动供应效率不高。本文旨在通过利用上下文信息和LLM推理的确定性特征来优化这些问题。

**Method:** Block是一个完全分布式、无状态且预测性的调度系统。它利用大型语言模型推理的确定性和可预测特性，如主机配置、响应长度和硬件性能，来准确预测指标并做出调度决策。

**Result:** 在12个GPU集群上的评估显示，Block比启发式调度器显著更优，服务容量提升高达16.7%，P99尾延迟降低高达49.5%。这些性能提升在不同模型、工作负载和配置下保持一致。

**Conclusion:** Block通过其分布式和预测性调度方法，成功优化了大型语言模型服务的负载均衡和自动供应，显著提高了服务容量并降低了延迟，证明了其在实际应用中的优越性。

> **ai_Abstract:** Block是一个创新的分布式调度框架，专为优化大型语言模型服务的负载均衡和资源自动供应而设计。它通过利用请求的上下文信息以及LLM推理的确定性特征进行预测性调度，克服了传统启发式调度器的局限性。实验证明，Block显著提升了服务容量并降低了尾延迟，展现了其在提高LLM服务效率和可靠性方面的巨大潜力。

> **摘要翻译:** 本文介绍了Block，一个分布式调度框架，旨在通过利用传入请求的上下文信息，优化大型语言模型服务框架中实例间的负载均衡和自动供应。与依赖单一和启发式任务调度器的流行模型服务系统不同，Block作为一个完全分布式、无状态和预测性调度系统运行，以实现低开销、可靠性和可扩展性。它利用LLM推理的确定性和可预测特性，如主机配置、响应长度和硬件性能，根据准确预测的指标做出调度决策。在12个GPU集群上的评估显示，Block显著优于启发式调度器，将服务容量提升高达16.7%，并将P99尾延迟降低高达49.5%。这些性能提升在不同模型、工作负载和配置下保持一致。代码和数据已开源。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [217] [PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows](https://arxiv.org/abs/2508.02866)
> *PROV-AGENT：用于跟踪智能体工作流中AI智能体交互的统一溯源*

*Renan Souza, Amal Gueroudji, Stephen DeWitt, Daniel Rosendo, Tirthankar Ghosal, Robert Ross, Prasanna Balaprakash, Rafael Ferreira da Silva* | **Category: cs.DC, cs.DB, 68T42, 68T30, 68P20, 68Q85, 68M14,, D.2.12; H.2.4; I.2.11; C.2.4; H.3.4** | **Updated: 2025-08-04**

**Keywords:** 溯源, AI智能体, 工作流, LLMs, 可追溯性

**Comment:** Paper under peer-reviewed evaluation

> **TL;DR:** PROV-AGENT是一个新的溯源模型和系统，扩展了W3C PROV，用于在复杂工作流中跟踪AI智能体（如LLM）的交互，从而提高透明度、可追溯性和可靠性。

**AI_Comments:** PROV-AGENT的创新之处在于其将以智能体为中心的元数据与传统工作流溯源相结合的能力，解决了AI智能体在复杂环境中可能导致的错误传播和缺乏透明度的问题。其开源系统和跨设施评估进一步增强了其实用性和影响力，对于提高AI智能体工作流的可靠性和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）作为AI智能体的核心组件在复杂的、大规模的工作流中日益普及。然而，AI智能体可能产生幻觉或错误推理，其决策可能在工作流中传播错误，尤其是一个智能体的输出作为另一个智能体的输入时。虽然现有溯源技术支持可重复性和工作流数据理解，但它们未能捕获和关联以智能体为中心的元数据（提示、响应和决策）与工作流的其余部分，因此需要细粒度的溯源。

**Method:** 本文引入了PROV-AGENT，一个溯源模型，它扩展了W3C PROV并利用模型上下文协议（MCP）将智能体交互集成到端到端的工作流溯源中。该方法包括开发一个针对智能体工作流量身定制的溯源模型，以及一个用于捕获智能体溯源的近实时、开源系统。

**Result:** 本文的贡献包括：(1) 一个为智能体工作流量身定制的溯源模型；(2) 一个用于捕获智能体溯源的近实时、开源系统；(3) 跨边缘、云和高性能计算（HPC）环境的跨设施评估，证明了对关键溯源查询和智能体可靠性分析的支持。

**Conclusion:** PROV-AGENT通过提供统一的、细粒度的溯源能力，解决了在智能体工作流中跟踪AI智能体交互的挑战，显著提高了复杂多智能体系统中的透明度、可追溯性和可靠性。

> **ai_Abstract:** 本文提出了PROV-AGENT，一个创新的溯源模型和系统，旨在解决AI智能体在复杂工作流中缺乏透明度、可追溯性、可重复性和可靠性的问题。通过扩展W3C PROV并利用模型上下文协议（MCP），PROV-AGENT能够将智能体交互（包括提示、响应和决策）与整个工作流的溯源信息整合起来。该研究提供了一个专门针对智能体工作流的溯源模型，一个用于捕获智能体溯源的近实时开源系统，并通过跨多种计算环境的评估，展示了其在支持关键溯源查询和智能体可靠性分析方面的有效性。

> **摘要翻译:** 基础模型，如大型语言模型（LLMs），正日益成为跨联邦和异构环境的复杂、大规模工作流中AI智能体的核心组件。在智能体工作流中，自主智能体规划任务，与人类和同行交互，并影响科学成果。这使得透明度、可追溯性、可重复性和可靠性变得至关重要。然而，基于AI的智能体可能会产生幻觉或错误推理，它们的决策可能会在工作流中传播错误，尤其是一个智能体的输出作为另一个智能体的输入时。因此，细粒度的溯源对于连接智能体决策、其端到端上下文以及下游影响至关重要。虽然溯源技术长期以来支持可重复性和工作流数据理解，但它们未能捕获和关联以智能体为中心的元数据（提示、响应和决策）与工作流的其余部分。在本文中，我们引入了PROV-AGENT，一个溯源模型，它扩展了W3C PROV并利用模型上下文协议（MCP）将智能体交互集成到端到端的工作流溯源中。我们的贡献包括：(1) 一个为智能体工作流量身定制的溯源模型；(2) 一个用于捕获智能体溯源的近实时、开源系统；(3) 跨边缘、云和高性能计算（HPC）环境的跨设施评估，证明了对关键溯源查询和智能体可靠性分析的支持。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [226] [ZenFlow: Enabling Stall-Free Offloading Training via Asynchronous Updates](https://arxiv.org/abs/2505.12242)
> *ZenFlow：通过异步更新实现无停顿卸载训练*

*Tingfeng Lan, Yusen Wu, Bin Ma, Zhaoyuan Su, Rui Yang, Tekin Bicer, Masahiro Tanaka, Olatunji Ruwase, Dong Li, Yue Cheng* | **Category: cs.DC, cs.LG, C.1.4; D.4.7** | **Updated: 2025-08-04**

**Keywords:** 卸载训练, GPU停顿, 异步更新, 大型语言模型, 梯度选择

**Comment:** 13 pages, 16 figures

> **TL;DR:** ZenFlow是一个新的卸载训练框架，通过优先处理重要参数和异步更新，显著减少GPU停顿，提高LLM微调速度。

**AI_Comments:** 这篇论文的创新点在于其独特的参数优先级策略和GPU-CPU异步更新机制，有效解决了现有卸载训练框架中严重的GPU停顿问题。通过将重要梯度留在GPU上并异步处理不重要梯度，ZenFlow最大化了GPU的利用率，显著提升了LLM微调的效率。其提出的轻量级梯度选择方法也有效地支持了多GPU扩展，避免了昂贵的同步开销，展示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLMs）微调框架在将模型状态卸载到CPU内存时，将所有参数一视同仁并在CPU上更新整个模型，导致严重的GPU停顿，因为GPU需等待慢速CPU更新和有限带宽的PCIe传输。

**Method:** ZenFlow优先处理重要参数，并解耦GPU和CPU之间的更新。它在GPU上就地更新重要梯度，同时异步地将不那么重要的梯度卸载到CPU并进行累积，使CPU工作与GPU计算完全重叠。为了跨GPU扩展，ZenFlow引入了一种轻量级梯度选择方法，利用重要梯度的时空局部性特性，避免昂贵的全局同步。

**Result:** ZenFlow实现了高达5倍的端到端加速，降低了2倍的PCIe流量，并将GPU停顿减少了85%以上，同时保持了精度。

**Conclusion:** ZenFlow通过其创新的参数优先级和异步更新机制，成功解决了现有卸载训练框架中GPU停顿的问题，显著提高了大语言模型微调的效率和性能。

> **ai_Abstract:** ZenFlow是一个旨在解决大型语言模型微调中GPU停顿问题的新型卸载训练框架。它通过优先处理重要参数并在GPU上就地更新，同时将不重要的参数异步卸载到CPU进行更新，从而实现CPU和GPU工作的完全重叠。此外，ZenFlow引入了一种轻量级梯度选择方法以实现跨GPU扩展。实验结果表明，ZenFlow在保持精度的前提下，显著提升了训练速度，减少了PCIe流量和GPU停顿。

> **摘要翻译:** 标题：ZenFlow：通过异步更新实现无停顿卸载训练
摘要：微调大型语言模型（LLMs）通常会超出GPU内存限制，促使系统将模型状态卸载到CPU内存。然而，现有的卸载训练框架，如ZeRO-Offload，对所有参数一视同仁，并在CPU上更新整个模型，导致严重的GPU停顿，即快速、昂贵的GPU空闲等待慢速CPU更新和有限带宽的PCIe传输。我们提出了ZenFlow，一个新型的卸载框架，它优先处理重要参数并解耦GPU和CPU之间的更新。ZenFlow在GPU上就地更新重要梯度，同时异步地将不那么重要的梯度卸载到CPU并进行累积，使CPU工作与GPU计算完全重叠。为了跨GPU扩展，ZenFlow引入了一种轻量级梯度选择方法，该方法利用了重要梯度的新颖时空局部性特性，避免了昂贵的全局同步。ZenFlow实现了高达5倍的端到端加速，降低了2倍的PCIe流量，并将GPU停顿减少了85%以上，同时保持了精度。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [282] [xDeepServe: Model-as-a-Service on Huawei CloudMatrix384](https://arxiv.org/abs/2508.02520)
> *xDeepServe：华为CloudMatrix384上的模型即服务*

*Ao Xiao, Bangzheng He, Baoquan Zhang, Baoxing Huai, Bingji Wang, Bo Wang, Bo Xu, Boyi Hou, Chan Yang, Changhong Liu, Cheng Cui, Chenyu Zhu, Cong Feng, Daohui Wang, Dayun Lin, Duo Zhao, Fengshao Zou, Fu Wang, Gangqiang Zhang, Gengyuan Dan, Guanjie Chen, Guodong Guan, Guodong Yang, Haifeng Li, Haipei Zhu, Hao Feng, Hao Huang, Hao Xu, Hengrui Ma, Hengtao Fan, Hui Liu, Jia Li, Jiang Liu, Jiang Xu, Jie Meng, Jinhan Xin, Junhao Hu, Juwei Chen, Lan Yu, Lanxin Miao, Liang Liu, Linan Jing, Lu Zhou, Meina Han, Mingkun Deng, Mingyu Deng, Naitian Deng, Nizhong Lin, Peihan Zhao, Peng Pan, Pengfei Shen, Ping Li, Qi Zhang, Qin Zhang, Qingrong Xia, Qingyi Zhang, Qunchao Fu, Ren Guo, Ruimin Gao, Shaochun Li, Sheng Long, Shentian Li, Shining Wan, Shuai Shen, Shuangfu Zeng, Shuming Jing, Siqi Yang, Song Zhang, Tao Xu, Tianlin Du, Ting Chen, Wanxu Wu, Wei Jiang, Weinan Tong, Weiwei Chen, Wen Peng, Wenli Zhou, Wenquan Yang, Wenxin Liang, Xiang Liu, Xiaoli Zhou, Xin Jin, Xinyu Duan, Xu Li, Xu Zhang, Xusheng Chen, Yalong Shan, Yang Gan, Yao Lu, Yi Deng, Yi Zheng, Yingfei Zheng, Yiyun Zheng, Yizhou Shan, Yong Gao, Yongqiang Yang, Yuanjin Gong, Yue Yu, Yuetao Chen, Yukun Zhu, Yulong He, Yusu Zhao, Yuyan Wu, Zenan Zhang, Zhaojin Zhuo, Zhaoyang Ji, Zhefeng Wang, Zheng Wang, Zhenhua Yang, Zhenli Sheng, Zhibin Yu, Zhigang Ji, Zhihao Ren, Zhipeng Bian, Zhixia Liu, Zhiyu Dong, Zhonghua Li, Zhou Yu, Zhuoming Shen, Zhuwei Peng, Zi Ye, Zihao Xiang, Zimin Fu, Zixuan Zhang* | **Category: cs.DC** | **Updated: 2025-08-05**

**Keywords:** xDeepServe, LLM服务, MoE模型, 解耦架构, CloudMatrix384

**Comment:** 

> **TL;DR:** xDeepServe是华为云针对超大规模LLM推理系统，在CloudMatrix384 SuperPod上实现了Transformerless解耦架构，以应对MoE模型在大规模硬件上的挑战，并通过XCCL和FlowServe实现高效可扩展的服务。

**AI_Comments:** 该论文的创新点在于提出了Transformerless解耦架构，将Transformer模型的核心组件（如注意力、前馈和MoE）解耦，使其能够在分布式环境中独立扩展和执行，这对于处理日益增长的MoE LLM模型非常重要。结合华为CloudMatrix384 SuperPod的硬件优势（如高速互连和全局共享内存），并通过定制的通信库XCCL和扩展的服务引擎FlowServe，xDeepServe提供了一个针对超大规模LLM推理的完整解决方案。其重要性在于为未来超大规模AI基础设施上LLM的部署和高效运行提供了可行的路径。

<details>
  <summary>Details</summary>

**Motivation:** 大规模LLM（特别是MoE模型）的兴起与华为CloudMatrix384 SuperPod等超大规模AI硬件的出现，带来了在SuperPod级硬件上运行大型MoE模型的新挑战，包括需要新的执行模型、可伸缩调度、高效专家负载均衡以及消除单点故障。

**Method:** 本文提出了xDeepServe，华为云专为SuperPod级基础设施设计的LLM服务系统。其核心是Transformerless，一种解耦架构，将Transformer模型分解为模块化单元（注意力、前馈和MoE），这些单元通过高速网络在NPU上独立执行。该设计以两种形式实现：解耦的预填充-解码和解耦的MoE-注意力。为了支持这种架构，提出了XCCL通信库，利用CloudMatrix384的全局共享内存实现高效的点对点和全对全通信。此外，还扩展了其服务引擎FlowServe，通过系统级技术实现数百个NPU上的可伸缩推理。

**Result:** 这种完全解耦的设置可以在不牺牲性能的情况下实现计算和内存的独立扩展，并能够实现跨数百个NPU的可伸缩推理。

**Conclusion:** xDeepServe通过其Transformerless解耦架构和优化的通信库，成功解决了在超大规模硬件上部署和运行MoE LLM所面临的挑战，实现了计算和内存的独立扩展及数百个NPU上的可伸缩推理。

> **ai_Abstract:** 本文介绍了xDeepServe，一个华为云为超大规模LLM推理设计的服务系统，专为CloudMatrix384 SuperPod优化。针对MoE模型在大规模硬件上的挑战，xDeepServe提出了Transformerless解耦架构，将Transformer模型拆分为独立执行的模块化单元，并实现了计算和内存的独立扩展。该系统通过XCCL通信库利用全局共享内存，并扩展FlowServe引擎以支持数百个NPU上的可伸缩推理。

> **摘要翻译:** 大规模LLM和大规模SuperPod的兴起标志着大规模AI基础设施的新时代。LLM通过MoE不断扩展，如DeepSeek、Kimi和Qwen等最新模型所示。与此同时，AI硬件也在不断升级，华为的CloudMatrix384 SuperPod提供了数百GB/s的高速互连。在SuperPod规模的硬件上运行大型MoE模型带来了新的挑战。它需要新的执行模型、可伸缩调度、高效的专家负载均衡以及消除单点故障。本文介绍了xDeepServe，华为云专为SuperPod级基础设施设计的LLM服务系统。其核心是Transformerless，一种解耦架构，将Transformer模型分解为模块化单元——注意力、前馈和MoE——通过高速结构在NPU上独立执行。我们将这种设计以两种形式实现：解耦的预填充-解码和解耦的MoE-注意力。这种完全解耦的设置可以在不牺牲性能的情况下实现计算和内存的独立扩展。为了支持这种架构，我们提出了XCCL，一个通信库，它利用CloudMatrix384的全局共享内存来实现高效的点对点和全对全原语。我们还通过系统级技术扩展了我们的服务引擎FlowServe，从而实现了跨数百个NPU的可伸缩推理。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [400] [Low-Communication Resilient Distributed Estimation Algorithm Based on Memory Mechanism](https://arxiv.org/abs/2508.02705)
> *基于记忆机制的低通信弹性分布式估计算法*

*Wei Li, Limei Hu, Feng Chen, Ye Yao* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 分布式估计, 弹性, 低通信, 记忆机制, W-SVDD

**Comment:** 

> **TL;DR:** 本文提出了一种基于信誉节点选择和加权支持向量数据描述（W-SVDD）模型的低通信弹性分布式估计算法，以应对多任务对抗网络中受攻击节点或链路导致的参数估计问题。

**AI_Comments:** 该论文提出了一种创新的方法来提高分布式估计算法在对抗环境下的鲁棒性，特别是通过结合信誉机制、W-SVDD模型和事件触发机制来解决通信效率和抗攻击性问题。其亮点在于对记忆机制的利用以及对通信成本的优化，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多任务对抗网络中，受攻击的节点或链路会阻碍分布式算法中未知参数的准确估计。

**Method:** 首先，引入了一种基于信誉的节点选择策略，使节点能够与更可靠的邻居子集进行通信。其次，采用加权支持向量数据描述（W-SVDD）模型训练记忆数据，以识别可信的中间估计。此外，引入了事件触发机制以最小化W-SVDD模型的无效更新，并推导出了合适的阈值。

**Result:** 仿真结果表明，所提出的算法与其他算法相比，以更低的通信成本实现了更优越的性能。

**Conclusion:** 本文提出的基于信誉节点选择、W-SVDD模型和事件触发机制的低通信弹性分布式估计算法，能够有效提高分布式估计过程对受攻击节点或链路的抵抗力，并降低通信成本。

> **ai_Abstract:** 本文提出了一种低通信弹性分布式估计算法，旨在解决多任务对抗网络中受攻击节点或链路导致的参数估计不准确问题。该算法通过引入基于信誉的节点选择策略和利用加权支持向量数据描述（W-SVDD）模型训练记忆数据来识别可信估计，从而增强了对攻击的抵抗力。此外，还采用事件触发机制优化了W-SVDD模型的更新效率。仿真结果验证了该算法在降低通信成本的同时，取得了优越的性能。

> **摘要翻译:** 在多任务对抗网络中，受攻击的节点或链路会阻碍分布式算法中未知参数的准确估计。为了解决这一挑战，本文提出了一种低通信弹性分布式估计算法。首先，引入了一种基于信誉的节点选择策略，允许节点与更可靠的邻居子集进行通信。随后，为了识别可信的中间估计，采用了加权支持向量数据描述（W-SVDD）模型来训练记忆数据。这个训练好的模型有助于增强分布式估计过程对受攻击节点或链路影响的弹性。此外，引入了事件触发机制以最小化W-SVDD模型的无效更新，并基于假设推导出了合适的阈值。本文分析了算法的收敛性。最后，仿真结果表明，所提出的算法与其他算法相比，以更低的通信成本实现了更优越的性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [442] [A DataOps Toolbox Enabling Continuous Semantic Integration of Devices for Edge-Cloud AI Applications](https://arxiv.org/abs/2508.02708)
> *赋能边缘-云AI应用的设备持续语义集成的数据运维工具箱*

*Mario Scrocca, Marco Grassi, Alessio Carenini, Jean-Paul Calbimonte, Darko Anicic, Irene Celino* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** DataOps, 语义集成, 边缘计算, 云计算, AI应用

**Comment:** This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this contribution will
  be published in The Semantic Web - ISWC 2025

> **TL;DR:** 该研究提出了一个DataOps工具箱，利用语义Web技术和低代码机制，解决边缘-云AI应用中设备异构数据互操作性的挑战。

**AI_Comments:** 这篇论文的创新点在于将DataOps理念与语义Web技术和低代码机制相结合，为边缘-云AI应用中的异构设备集成提供了一个系统化的解决方案。其提出的持续语义集成方法对于处理复杂多变的环境数据具有重要意义，尤其是在工业物联网、智慧城市和医疗健康等领域。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂环境中实现基于AI的应用需要边缘到云的多个设备协作，但识别和配置这些设备以实现协作是一个挑战，尤其是在工业车间、道路基础设施和医疗治疗等不同场景中。

**Method:** 论文设计并实现了一个DataOps工具箱，该工具箱利用语义Web技术和低代码机制，支持持续语义集成方法，以处理不同类型的设备、数据格式、语义以及通信接口，从而解决异构数据互操作性问题。

**Result:** 该工具箱成功应用于三个不同领域的用例，展示了其实现的DataOps管道如何保证静态节点信息和运行时数据交换的互操作性。论文还讨论了用例试点活动的结果。

**Conclusion:** 论文讨论了在用例试点活动中取得的结果以及所获得的经验教训，证明了所提出的DataOps工具箱在解决边缘-云AI应用中设备异构数据互操作性方面的有效性。

> **ai_Abstract:** 本文提出并实现了一个DataOps工具箱，旨在解决边缘到云AI应用中设备间异构数据互操作性的挑战。该工具箱利用语义Web技术和低代码机制，支持设备、数据格式、语义和通信接口的持续语义集成。通过在三个不同领域的用例中应用，验证了该工具箱在保证静态信息和运行时数据交换互操作性方面的有效性，并分享了试点经验。

> **摘要翻译:** 复杂环境中AI应用的实施通常需要边缘到云的多个设备协作。识别所需设备并将其配置为协作是一个挑战，这与工业车间、道路基础设施和医疗治疗等不同场景相关。我们讨论了一个DataOps工具箱的设计和实现，该工具箱利用语义Web技术和低代码机制来解决此类应用程序开发中异构数据互操作性的要求。该工具箱支持持续语义集成方法，以处理各种类型的设备、数据格式和语义以及不同的通信接口。论文介绍了该工具箱在三个不同领域的用例中的应用、所实现的DataOps管道以及它们如何保证静态节点信息和运行时数据交换的互操作性。最后，我们讨论了用例试点活动的结果和经验教训。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [484] [Optimal Simultaneous Byzantine Agreement, Common Knowledge and Limited Information Exchange](https://arxiv.org/abs/2508.03418)
> *最优同步拜占庭协议、共同知识和有限信息交换*

*Ron van der Meyden* | **Category: cs.DC, cs.LO, 68W15, 03B42, 03B70, 68Q60, 68Q85, 68M15** | **Updated: 2025-08-05**

**Keywords:** 同步拜占庭协议, 认知逻辑, 有限信息交换, 分布式算法, 最优性

**Comment:** 

> **TL;DR:** 本文重新审视了同步拜占庭协议的认知分析，并提出了一个基于知识的程序，该程序在有限信息交换下能够实现最优协议，但并非在所有情况下都最优。

**AI_Comments:** 本文的创新之处在于将认知逻辑分析应用于更实用的有限信息交换场景，而非传统的全信息协议，这对于提高分布式算法的效率具有重要意义。它不仅解决了理论上的概念模糊问题，还提出了一个在特定条件下具有最优性的解决方案。然而，其最优性并非普遍适用，这提示了未来研究可以探索在更广泛场景下实现鲁棒最优性的方法。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发能尽快执行动作的解决方案，分布式算法的认知逻辑分析通常集中于“全信息协议”，但这可能导致空间和计算时间上的低效率。本文的动机是重新考虑在更弱但更实用的信息交换条件下，对同步拜占庭协议问题进行认知分析。

**Method:** 本文首先澄清了同步拜占庭协议问题规范及其解决方案中基于知识的程序的一些问题，特别是关于“无故障”和“尚未失效”概念的区别。然后，研究表明，在给定故障模型和满足特定条件的信息交换协议下，这种基于知识的程序能够产生一个相对于使用相同信息交换的解决方案而言是最优的协议。

**Result:** 研究表明，当相对于给定的故障模型和满足特定条件的信息交换协议实现时，所提出的基于知识的程序能够产生一个相对于使用相同信息交换的解决方案而言是最优的协议。论文还确定了在这种实现下也是最优的条件，但同时提供了一个例子表明这并非普遍适用。

**Conclusion:** 本文得出的结论是，在弱但更实用的信息交换条件下，通过重新审视同步拜占庭协议的认知分析，可以设计出在特定条件下最优的基于知识的协议。然而，这种最优性并不总是普遍成立的，这表明在实用性和普适性之间存在权衡。

> **ai_Abstract:** 本文针对分布式算法中全信息协议的低效率问题，重新审视了同步拜占庭协议在有限信息交换下的认知分析。研究澄清了相关概念，并提出了一种基于知识的程序。该程序在特定故障模型和信息交换协议下，能够实现相对于同类信息交换的最优协议，但这种最优性并非在所有情况下都普遍成立。

> **摘要翻译:** 为了开发能够尽快执行动作的解决方案，使用认知逻辑分析的分布式算法通常集中于“全信息协议”，这可能在空间和计算时间方面效率低下。本文重新审视了同步拜占庭协议问题的认知分析，关注更弱但更实用的信息交换。论文首先澄清了关于该问题规范及其解决方案中基于知识程序的某些问题，涉及“无故障”和“尚未失效”概念之间的区别，文献中对此存在差异。然后，研究表明，当相对于给定的故障模型和满足某些条件的信息交换协议实现时，这种基于知识的程序能够产生一个相对于使用相同信息交换的解决方案而言是最优的协议。论文还确定了在此实现下也是最优的条件，但提供了一个例子表明这并非普遍适用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [860] [In-Memory Non-Binary LDPC Decoding](https://arxiv.org/abs/2508.03567)
> *内存中非二元LDPC解码*

*Oscar Ferraz, Vitor Silva, Gabriel Falcao* | **Category: cs.DC, cs.CE** | **Updated: 2025-08-05**

**Keywords:** LDPC码,处理在内存,非二元解码,UPMEM,吞吐量

**Comment:** 23 pages, 10 figures, and 4 tables

> **TL;DR:** 该论文提出了一种新颖高效的近内存非二元LDPC解码器，是首个在UPMEM系统上实现的基于处理内存（PiM）的非二元LDPC解码器，其解码吞吐量高达76 Mbit/s，甚至可与低功耗GPU的实现相媲美。

**AI_Comments:** 该研究在解决内存瓶颈和提高LDPC解码效率方面取得了重要进展，提出的PiM解决方案在能效和性能上具有潜力。然而，该研究的局限性在于仅在UPMEM系统上进行了测试，其在不同硬件平台上的通用性和可扩展性仍需进一步验证。未来的研究可以探索更广泛的PiM架构和更复杂的LDPC编码方案。

<details>
  <summary>Details</summary>

**Motivation:** 内存技术发展滞后于计算技术，导致数据移动瓶颈，影响并行处理系统性能。处理在内存（PiM）范式通过在数据存储处设计计算单元来缓解此瓶颈。

**Method:** 提出了一种新颖高效的近内存非二元LDPC解码器，并在UPMEM系统上实现了首个基于PiM的非二元LDPC解码器。

**Result:** 在UPMEM系统上实现的PiM-based非二元LDPC解码器可以达到76 Mbit/s的解码吞吐量，与高度优化的低功耗GPU并行解决方案相比具有竞争力。

**Conclusion:** 提出的PiM-based非二元LDPC解码器在UPMEM系统上实现了具有竞争力的性能，证明了PiM范式在LDPC解码领域的潜力。

> **ai_Abstract:** 该论文介绍了一种用于UPMEM系统的新型近内存非二元LDPC解码器。该解码器利用处理在内存（PiM）范式，通过在数据存储处集成计算单元来克服内存瓶颈。实验结果表明，该解码器实现了76 Mbit/s的解码吞吐量，性能可与低功耗GPU相媲美，是首个在硬件上实现的PiM-based非二元LDPC解码器。

> **摘要翻译:** 低密度奇偶校验（LDPC）码是几个通信和存储应用的重要特征，它提供了一种灵活有效的方法来进行错误纠正。这些码在计算上很复杂，需要利用并行处理来满足实时约束。随着算术和逻辑单元技术的发展提高了计算系统的性能，内存技术却没有跟上相同的发展步伐，造成了数据移动瓶颈，并对并行处理系统产生了更严重的影响。为了缓解此瓶颈的严重性，已经提出了几种解决方案，即处理在内存（PiM）范式，该范式涉及设计计算单元到数据存储的位置（或附近），利用数千个低复杂度处理单元来执行按位和简单的算术运算。本文提出了一种在UPMEM系统上用于近内存非二元LDPC解码器的新颖高效解决方案，据我们所知，这是首个基于PiM的非二元LDPC解码器硬件，并与针对吞吐量性能高度优化的低功耗GPU并行解决方案进行了基准测试。基于PiM的非二元LDPC解码器可以实现76 Mbit/s的解码吞吐量，与在边缘GPU上运行的实现相比甚至具有竞争力。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [34] [A Foundational Schema.org Mapping for a Legal Knowledge Graph: Representing Brazilian Legal Norms as FRBR Works](https://arxiv.org/abs/2508.00827)
> *法律知识图谱的基础Schema.org映射：将巴西法律规范表示为FRBR作品*

*Hudson de Martim* | **Category: cs.DL, cs.AI, cs.CY, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 法律知识图谱, Schema.org, FRBR, 法律规范, JSON-LD

**Comment:** Substantial revision. Now grounded in the FRBR model, mapping the
  legal norm as an abstract Work. Scope narrowed to the Work -> sdo:Legislation
  mapping (LegislationObject section removed). Emphasizes creating a
  deterministic 'ground truth' for Legal AI and Graph RAG

> **TL;DR:** 该论文提出了一种基于FRBR模型将法律规范映射到schema.org/Legislation词汇的基础方法，并通过巴西Normas.leg.br门户的案例研究，演示了如何使用JSON-LD描述法律作品，旨在为法律AI应用创建确定性、可验证的知识图谱。

**AI_Comments:** 该论文的创新之处在于将成熟的FRBR模型与Schema.org/Legislation词汇相结合，为法律规范的结构化表示提供了基础性映射。其重要性在于为构建确定性、可验证的法律知识图谱奠定了基础，这对于提升法律AI应用的准确性和可靠性至关重要，克服了当前纯概率模型的不足。

<details>
  <summary>Details</summary>

**Motivation:** 构建先进的AI和信息检索系统（如法律知识图谱LKG）需要将法律规范结构化以实现机器可读性，以克服纯概率模型的局限性。

**Method:** 该论文基于文献记录功能需求（FRBR）模型，提出了一种将抽象法律作品（在法律图谱RAG框架中体现为规范节点）映射到可互操作的schema.org/Legislation词汇的基础方法。通过Normas.leg.br门户作为案例研究，演示了如何使用JSON-LD描述法律作品实体，并考虑了稳定的URN标识符、规范间关系和生命周期属性。

**Result:** 该研究演示了如何通过JSON-LD描述法律作品实体，考虑了稳定的URN标识符、规范间关系和生命周期属性，为创建确定性、可验证的知识图谱提供了基础步骤。

**Conclusion:** 这种结构化、形式化的方法是创建确定性、可验证知识图谱的必要第一步，该知识图谱可以作为法律AI应用的规范化“事实依据”，克服纯概率模型的局限性。

> **ai_Abstract:** 本论文提出了一种将法律规范结构化为机器可读格式的方法，以支持法律知识图谱（LKG）的构建。研究基于FRBR模型，将抽象法律作品映射到schema.org/Legislation词汇，并通过巴西Normas.leg.br门户的案例研究，演示了如何使用JSON-LD描述法律作品实体，包括URN标识符、规范间关系和生命周期属性。这一方法旨在为法律AI应用提供一个确定且可验证的知识图谱“事实依据”，从而克服现有概率模型的局限性。

> **摘要翻译:** 将法律规范结构化以实现机器可读性是构建先进AI和信息检索系统（如法律知识图谱LKG）的关键先决条件。本论文以文献记录功能需求（FRBR）模型为基础，提出了一种将抽象法律作品（在我们的法律图谱RAG框架中体现为规范节点）映射到可互操作的schema.org/Legislation词汇的基础映射。我们以Normas.leg.br门户网站作为实际案例研究，演示了如何通过JSON-LD描述此作品实体，同时考虑了稳定的URN标识符、规范间关系和生命周期属性。这种结构化、形式化的方法为创建确定性且可验证的知识图谱提供了必要的第一个步骤，该知识图谱可以作为法律AI应用的规范化“事实依据”，克服纯概率模型的局限性。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [386] [Who Gets Cited? Gender- and Majority-Bias in LLM-Driven Reference Selection](https://arxiv.org/abs/2508.02740)
> *谁被引用？LLM驱动的参考文献选择中的性别和多数偏见*

*Jiangen He* | **Category: cs.DL, cs.AI, cs.CY** | **Updated: 2025-08-02**

**Keywords:** LLM偏见, 性别偏见, 参考文献选择, 引文分析, 学术公平

**Comment:** 

> **TL;DR:** 本研究系统地调查了大型语言模型（LLMs）在参考文献选择中存在的性别偏见和多数偏见。结果显示，LLMs倾向于选择男性作者的参考文献，并偏向候选池中占多数的性别，这可能会加剧学术认可中的性别不平衡。

**AI_Comments:** 这项研究创新性地揭示了LLMs在学术引用中引入的潜在性别偏见和多数偏见，其重要性在于提醒学术界在广泛采用LLMs辅助研究时，需警惕并解决其可能加剧现有不公平现象的风险。研究方法严谨，通过受控实验和多模型评估增强了结果的说服力。其局限性可能在于未能深入探讨偏见产生的具体机制，以及所提出的缓解策略效果有限。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正被迅速采纳为研究助手，尤其是在文献综述和参考文献推荐方面，但目前对其是否会在引文工作流程中引入人口统计学偏见知之甚少。

**Method:** 本研究采用假名作者进行受控实验，系统地调查了LLM驱动的参考文献选择中的性别偏见。研究评估了GPT-4o、GPT-4o-mini、Claude Sonnet和Claude Haiku等多种LLM，通过改变候选参考文献池中的性别构成并分析跨领域的选择模式。

**Result:** 研究结果揭示了两种形式的偏见：对男性作者参考文献的持续偏好，以及偏向候选池中占多数性别的多数群体偏见。这些偏见在更大的候选池中被放大，并且仅通过基于提示的缓解策略得到适度减弱。领域层面的分析表明，偏见程度在不同科学领域之间存在差异，其中社会科学的偏见最小。

**Conclusion:** LLMs可能会强化或加剧学术认可中现有的性别不平衡。在将LLMs整合到高风险学术工作流程之前，需要有效的缓解策略，以避免延续科学引文实践中现有的性别差异。

> **ai_Abstract:** 本研究系统探讨了大型语言模型（LLMs）在参考文献选择中存在的性别偏见。通过对多款LLM进行受控实验，发现LLMs普遍存在对男性作者的偏好以及对候选池中多数性别的偏好。这些偏见在大型候选池中更为显著，且难以通过提示有效缓解。研究强调，LLMs可能加剧学术界现有的性别不平衡，呼吁在将LLMs应用于高风险学术流程前，必须制定有效的偏见缓解策略。

> **摘要翻译:** 大型语言模型（LLMs）正被迅速采纳为研究助手，尤其是在文献综述和参考文献推荐方面，但目前对其是否会在引文工作流程中引入人口统计学偏见知之甚少。本研究采用假名作者进行受控实验，系统地调查了LLM驱动的参考文献选择中的性别偏见。我们评估了GPT-4o、GPT-4o-mini、Claude Sonnet和Claude Haiku等多种LLM，通过改变候选参考文献池中的性别构成并分析跨领域的选择模式。我们的结果揭示了两种形式的偏见：对男性作者参考文献的持续偏好，以及偏向候选池中占多数性别的多数群体偏见。这些偏见在更大的候选池中被放大，并且仅通过基于提示的缓解策略得到适度减弱。领域层面的分析表明，偏见程度在不同科学领域之间存在差异，其中社会科学的偏见最小。我们的发现表明，LLMs可能会强化或加剧学术认可中现有的性别不平衡。在将LLMs整合到高风险学术工作流程之前，需要有效的缓解策略，以避免延续科学引文实践中现有的性别差异。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [491] [Arab Spring's Impact on Science through the Lens of Scholarly Attention, Funding, and Migration](https://arxiv.org/abs/2503.13238)
> *阿拉伯之春对科学的影响：通过学术关注、资金和移民的视角*

*Yasaman Asgari, Hongyu Zhou, Ozgur Kadir Ozer, Rezvaneh Rezapour, Mary Ellen Sloane, Alexandre Bovet* | **Category: cs.DL, cs.SI** | **Updated: 2025-08-05**

**Keywords:** 阿拉伯之春, 科学影响, 学术关注, 研究资金, 人才迁移

**Comment:** 

> **TL;DR:** 阿拉伯之春通过改变研究资金和研究者移民，显著重塑了对中东和北非地区（MENA）的学术关注，尤其是在沙特阿拉伯成为研究中心后。

**AI_Comments:** 该论文的创新之处在于量化了政治事件对科学研究格局的具体影响，通过学术关注度、资金流向和人才迁移三个维度，揭示了政治动荡如何重塑全球知识生产和流动。其重要性在于提供了实证证据，说明了非科学因素（政治）对科学发展轨迹的深远影响，对于理解科学地理学和国际合作具有重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 探讨2010-2011年阿拉伯之春如何超越政治领域，重塑了对中东和北非地区（MENA）的研究方式。

**Method:** 分析了2002年至2019年间370万篇Scopus索引的文章，以量化阿拉伯国家在标题或摘要中被提及的频率。

**Result:** 2011年后，十个阿拉伯国家在文章标题或摘要中被提及的频率相对于全球基线显著增加，其中埃及受到的关注最多；这种关注的激增与对MENA地区研究资金的增加以及研究人员移民后继续发表关于其原籍国的文章这两个机制相关；沙特阿拉伯已成为研究受影响国家的区域中心，吸引了资金和学者。

**Conclusion:** 政治动荡可以通过改变研究主体、使用的资源以及涉及的学科来重塑全球知识流动。

> **ai_Abstract:** 本研究分析了2010-2011年阿拉伯之春如何影响对中东和北非地区的科学关注。通过对370万篇Scopus文章的分析，发现阿拉伯国家在学术文献中的提及率在2011年后显著上升，尤其是在埃及。这种增长归因于研究资金的增加和研究人员的移民。研究还指出，沙特阿拉伯已成为该区域研究的中心，吸引了资金和学者，从而重塑了区域科学叙事。论文强调政治动荡对全球知识流动具有深远影响。

> **摘要翻译:** 2010-2011年的阿拉伯之春的影响远远超出了政治领域，重塑了中东和北非地区（MENA）的研究方式。通过分析2002年至2019年间发表的370万篇Scopus索引文章，我们发现，2011年后，这十个国家在文章标题或摘要中被提及的次数相对于全球基线显著增加，其中埃及在该地区获得了最多的关注。我们将这种激增与两个相互关联的机制联系起来：对MENA地区研究资金的增加，以及研究人员移民后继续发表关于其原籍国的文章。我们的分析显示，沙特阿拉伯已成为研究受影响国家的区域中心，吸引了资金和学者，从而在塑造该地区的科学叙事方面发挥了重要作用。这些发现表明，政治动荡可以通过改变研究主体、使用的资源以及涉及的学科来重塑全球知识流动。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [235] [Temporal Exploration of Random Spanning Tree Models](https://arxiv.org/abs/2508.03361)
> *随机生成树模型的时间探索*

*Samuel Baguley, Andreas Göbel, Nicolas Klodt, George Skretas, John Sylvester, Viktor Zamaraev* | **Category: cs.DM, math.CO, math.PR, 05C80, 68R10, 05C38** | **Updated: 2025-08-05**

**Keywords:** 时间图探索, 随机生成树模型, 随机时间图, 探索时间, 紧密界限

**Comment:** 42 pages, 8 Figures

> **TL;DR:** 本文在随机设置下研究了时间图探索问题（TEXP），引入了随机生成树（RST）模型，并建立了探索时间的紧密界限，揭示了随机设置与对抗性设置之间的根本区别。

**AI_Comments:** 这项工作通过将时间图探索问题置于随机设置中，为理解其复杂性提供了新的视角。引入随机生成树模型是一个新颖的方法，有助于克服传统对抗性设置中的限制。所建立的紧密界限，特别是$O(n^{3/2})$和$O(m)$，显著改进了对随机时间图探索效率的认识，并突出了随机性和对抗性情景之间的关键差异。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对时间图探索问题的理解有限，对于某些基本图类，已知界限之间存在巨大差距，且不清楚哪些属性使时间图难以探索。鉴于时间图探索问题在时间图理论中的核心作用，作者在随机设置中研究了该问题。

**Method:** 引入了随机生成树（RST）模型，该模型由一组n个顶点的树和该集合上的任意概率分布μ组成。通过从μ中独立抽取样本序列生成随机时间图。在此类随机时间图中系统地研究了时间图探索问题。

**Result:** 1. 任何RST模型都可以以高概率（w.h.p.）在$O(n^{3/2})$时间内探索，且该界限在常数因子内是紧密的，这表明对抗性设置和随机设置之间存在根本区别。 2. 如果RST的所有树都是具有m条边的固定图的子图，那么w.h.p.，它可以在$O(m)$时间内探索。

**Conclusion:** 论文在随机设置中对时间图探索问题进行了系统研究，引入了随机生成树模型，并建立了紧密的探索时间界限，揭示了随机设置下探索效率显著优于对抗性设置。

> **ai_Abstract:** 本文在随机设置下研究了时间图探索问题（TEXP），以解决现有研究中对该问题理解的局限性以及已知界限之间的巨大差距。作者引入了随机生成树（RST）模型，通过从一组树中独立抽样来生成随机时间图。研究建立了在RST模型下进行时间图探索的紧密界限，证明了在$O(n^{3/2})$时间内可以高概率地探索任何RST模型，并指出该界限是紧密的。此外，对于RST中所有树都是固定图子图的情况，探索时间可达$O(m)$。这些结果揭示了随机设置与对抗性设置在探索效率上的根本差异。

> **摘要翻译:** 时间图探索问题（TEXP）的输入是一个时间图，即在相同顶点集上的一系列图$(G_i)_{i\in \mathbb{N}}$，并要求找到访问所有顶点的最短长度路径，其中第i步使用来自$G_i$的边。如果每个$G_i$都是连通的，则存在长度为$n^2$的探索，并且已知这是在常数因子内可能达到的最佳结果。对于受限制的时间图类，已经获得了更细粒度的下限和上限，然而，对于几个基本类，已知界限之间存在巨大差距，并且仍然不清楚时间图的哪些属性使其本质上难以探索。
受限于这种有限的理解以及时间图探索问题在时间图理论中的核心作用，我们在随机设置中研究了这个问题。我们引入了随机生成树（RST）模型，该模型由一组n个顶点的树和该集合上的任意概率分布$\mu$组成。由RST模型生成的随机时间图是独立地从$\mu$中抽取的样本序列。
我们首次系统地研究了此类随机时间图中的时间图探索问题，并建立了探索时间的紧密通用界限。我们的第一个主要结果证明，任何RST模型都可以在高概率（w.h.p.）下在$O(n^{3/2})$时间内探索，并且我们证明这个界限在常数因子内是紧密的。这表明对抗性设置和随机设置之间存在根本区别。我们的第二个主要结果表明，如果RST的所有树都是具有m条边的固定图的子图，那么w.h.p.，它可以在$O(m)$时间内探索。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [290] [Adjacent vertex distinguishing total coloring of 3-degenerate graphs](https://arxiv.org/abs/2508.03549)
> *3-退化图的邻点可区别全染色*

*Diptimaya Behera, Mathew C. Francis, Sreejith K. Pallathumadam* | **Category: cs.DM, math.CO, 05C15, 68R10, G.2.1; G.2.2** | **Updated: 2025-08-05**

**Keywords:** 全染色, 邻点可区别, 3-退化图, 图染色猜想

**Comment:** 

> **TL;DR:** 本文验证了邻点可区别全染色猜想对3-退化图成立。

**AI_Comments:** 这项工作通过将邻点可区别全染色猜想的验证范围从2-退化图扩展到3-退化图，对图染色理论做出了贡献。它在解决一个重要的图论猜想方面迈出了新的一步。

<details>
  <summary>Details</summary>

**Motivation:** 邻点可区别全染色猜想（AVD Total Coloring Conjecture）提出每个图G都有一个最多使用Δ(G)+3种颜色的AVD全染色。之前的研究已经证明该猜想对2-退化图成立，因此本文旨在验证其对3-退化图的有效性。

**Method:** 摘要中未提及。

**Result:** 本文验证了邻点可区别全染色猜想对3-退化图成立。

**Conclusion:** 邻点可区别全染色猜想对3-退化图成立。

> **ai_Abstract:** 本文研究了邻点可区别全染色（AVD Total Coloring）问题，该问题由张等人于2005年提出，猜想每个图G都有一个最多使用Δ(G)+3种颜色的AVD全染色。鉴于此前苗等人已证明该猜想对2-退化图成立，本研究在此基础上，进一步验证并证明了该猜想对3-退化图同样成立。

> **摘要翻译:** 一个简单无向图G的全染色是对其顶点和边进行颜色赋值，使得赋予顶点的颜色构成一个正常顶点染色，赋予边的颜色构成一个正常边染色，并且每条边的颜色不同于其两个端点的颜色。也就是说，如果对于所有uv∈E(G)，都有φ(u)≠φ(v)且φ(uv)≠φ(u)，并且对于任意u∈V(G)和不同的v,w∈N(u)，都有φ(uv)≠φ(uw)（其中N(u)表示u的邻居集合），则φ:V(G)∪E(G)→N是G的一个全染色。如果对于所有uv∈E(G)，我们有φ({u}∪{uw:w∈N(u)})≠φ({v}∪{vw:w∈N(v)})，则图G的全染色φ被称为“邻点可区别”（简称AVD）。张，陈，李，姚，陆和王（中国科学A辑：数学，48(3):289--299, 2005）提出的AVD全染色猜想指出，每个图G都有一个最多使用Δ(G)+3种颜色的AVD全染色，其中Δ(G)表示G的最大度。对于某个s∈N，如果G的每个子图的最小度至多为s，则称图G是s-退化的。苗，施，胡和罗（离散数学，339(10):2446--2449, 2016）表明AVD全染色猜想对2-退化图是成立的。我们验证了该猜想对3-退化图的有效性。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [379] [Fast algorithms for Vizing's theorem on bounded degree graphs](https://arxiv.org/abs/2303.05408)
> *有界度图上Vizing定理的快速算法*

*Anton Bernshteyn, Abhishek Dhawan* | **Category: cs.DS, cs.DC, cs.DM, math.CO** | **Updated: 2025-08-04**

**Keywords:** Vizing定理, 边着色, 线性时间算法, 有界度图, 熵压缩

**Comment:** 45 pages, 15 figures

> **TL;DR:** 本文提出了针对有界度图的Vizing定理的线性时间边着色算法，并改进了分布式计算模型下的算法，关键在于熵压缩方法的应用。

**AI_Comments:** 本文的主要创新在于首次为$\Delta \geq 4$的有界度图提供了线性时间$(\Delta+1)$-边着色算法，这是一个显著的理论突破。引入熵压缩方法作为关键技术，证明了其在图算法中的强大潜力。此外，在分布式计算模型下的改进算法也具有重要的实践意义。这项工作为图着色问题的研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对有界度图的Vizing定理的边着色算法在$\\Delta = O(1)$时运行时间为$O(n \log n)$，而Sinnamon的算法为$O(n^{3/2})$，这并非最优。本文旨在开发更快的算法，特别是达到线性时间。

**Method:** 本文提出了一种新的算法，其关键新颖之处在于应用了熵压缩方法。此外，还利用了相同的思想开发了针对分布式计算模型（LOCAL模型）的新算法。

**Result:** 在$\\Delta$为常数时，本文提出了一种边着色算法，其运行时间为$O(n)$，这是目前已知最快的。在$\\Delta \geq 4$的情况下，这是首个线性时间$(\Delta+1)$-边着色算法。对于分布式LOCAL模型，当$\\Delta$为常数时，设计了一个确定性LOCAL算法，运行时间为$\\tilde{O}(\log^5 n)$；以及一个随机LOCAL算法，运行时间为$O(\\log^2 n)$。这些结果对于$\\Delta$高达$\\log^{o(1)} n$的情况也具有意义。

**Conclusion:** 本文为有界度图的Vizing定理提供了线性时间边着色算法，并在分布式计算模型下取得了显著改进，填补了线性时间算法的空白，证明了熵压缩方法在图算法中的有效性。

> **ai_Abstract:** 本文针对Vizing定理在有界度图上的边着色问题，提出了一个运行时间为$O(n)$的线性时间算法，显著优于现有算法。这是首次在$\Delta \ge 4$时达到线性时间的$(\Delta+1)$-边着色算法。此外，论文还利用相同的思想，为分布式LOCAL模型开发了更快的确定性和随机算法。这些算法的关键创新在于应用了熵压缩方法，并且其结果对$\Delta$高达$\log^{o(1)} n$的情况也保持有效。

> **摘要翻译:** Vizing定理指出，每个最大度为$\\Delta$的图$G$都可以使用$\\Delta + 1$种颜色进行正常边着色。目前已知最快的通用图$(\Delta+1)$-边着色算法是Sinnamon提出的，运行时间为$O(m\sqrt{n})$，其中$n :=|V(G)|$，$m :=|E(G)|$。我们研究了$\\Delta$为常数的情况，即$\\Delta = O(1)$。在这种情况下，Sinnamon算法的运行时间为$O(n^{3/2})$，而Gabow、Nishizeki、Kariv、Leven和Terada的研究表明可以改进到$O(n \log n)$。本文提出了一种算法，其运行时间仅为$O(n)$，这显然是最佳的。在此工作之前，对于任何$\\Delta \geq 4$，都没有已知的线性时间$(\Delta+1)$-边着色算法。利用一些相同的思想，我们还开发了在分布式计算的$\\mathsf{LOCAL}$模型中进行$(\Delta+1)$-边着色的新算法。具体来说，当$\\Delta$为常数时，我们设计了一个确定性$\\mathsf{LOCAL}$算法，运行时间为$\\tilde{O}(\log^5 n)$；以及一个随机$\\mathsf{LOCAL}$算法，运行时间为$O(\\log ^2 n)$。尽管我们的重点是常数$\\Delta$的情况，但由于其运行时间对$\\Delta$的依赖是多项式的，我们的结果对于$\\Delta$高达$\\log^{o(1)} n$的情况仍然很有趣。我们算法中的关键新颖之处是熵压缩方法的新颖应用。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [394] [Finding Colorings in One-Sided Expanders](https://arxiv.org/abs/2508.02825)
> *在单侧扩展图中寻找着色*

*Rares-Darius Buhai, Yiding Hua, David Steurer, Andor Vári-Kakas* | **Category: cs.DS** | **Updated: 2025-08-04**

**Keywords:** 单侧扩展图, 图着色, 独立集, 顶点覆盖, 近似算法, 硬度结果, 图谱

**Comment:** 62 pages, the arxiv landing page contains a shortened abstract

> **TL;DR:** 该论文为单侧扩展图上的着色和独立集问题提供了新的算法保证和硬度结果，改进了先前的近似算法，并引入了一种新的k-着色分层方法。

**AI_Comments:** 该论文显著推进了单侧扩展图算法问题的最新技术水平，特别是通过提供改进的近似比率和对k-着色问题的明确复杂性分类。引入基于矩阵性质的k-着色新分层方法是创新的，而发现新的图谱性质则提供了基础性的见解。硬度结果对于理解这类图中高效算法的局限性也至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在改进单侧扩展图中着色和独立集问题的算法保证，并在现有工作的基础上进行改进。具体来说，它寻求为独立集和顶点覆盖找到更好的近似算法，并理解这些图中k-着色问题的复杂性。

**Method:** 开发了针对单侧扩展图中着色和独立集问题的新算法保证。提出了一种基于k乘k矩阵的k-着色新分层方法。展示了一个关于图谱负特征值和正特征值之间关系的新性质。

**Result:** 对于一个3-可着色的正则单侧扩展图，在多项式时间内计算出相对大小至少为1/2-o(1)的独立集，或者除o(1)比例的顶点外其余顶点的正确3-着色，改进了现有工作。在足够强的正则单侧扩展图中，获得了顶点覆盖问题的有效1.6667因子近似算法，改进了之前(2-ε)因子近似。证明了如果k-着色分层中的k乘k矩阵有重复行，则在唯一博弈猜想下，单侧扩展图的相应着色问题是NP难的。证明了如果k乘k矩阵没有重复行，则相应着色问题可以在多项式时间内解决。展示了一个新的图谱性质：小于-τ的负特征值的数量至多是大于τ^2/2的特征值数量的O(1/τ^2)倍。

**Conclusion:** 该论文为单侧扩展图上的着色和独立集问题建立了新的算法保证和匹配的硬度结果，展示了改进的近似比，并根据新颖的矩阵分层明确区分了多项式时间可解和NP难的k-着色问题。

> **ai_Abstract:** 该论文为单侧扩展图中的着色和独立集问题提供了新的算法保证和硬度结果。主要贡献包括在3-可着色正则单侧扩展图中找到大型独立集或3-着色的多项式时间算法，顶点覆盖的1.6667因子近似改进，以及使用k乘k矩阵对k-着色进行的新分层，区分了NP难和多项式时间可解的情况。该工作还揭示了一个以前未观察到的关于图谱负特征值和正特征值之间关系的新性质。

> **摘要翻译:** 我们为单侧扩展图及相关图类的着色和独立集问题建立了新的算法保证和匹配的硬度结果。例如，给定一个3-可着色的正则单侧扩展图，我们可以在多项式时间内计算出相对大小至少为1/2-o(1)的独立集，或者除o(1)比例的顶点外其余顶点的正确3-着色，其中o(1)表示一个函数，其值随着归一化邻接矩阵的第二大特征值趋于0。这项结果改进了Bafna、Hsieh和Kothari（STOC 2025）最近的开创性工作，他们开发了一种算法，可以有效地在此类图中找到相对大小至少为0.01的独立集。我们还在足够强的正则单侧扩展图中获得了顶点覆盖问题的有效1.6667因子近似算法，改进了之前在此类图中未指定常数ε>0的(2-ε)因子近似。我们提出了k-着色问题的一种新的分层方法，其依据是类似于约束满足问题的谓词集的k乘k矩阵。我们证明，只要这个矩阵有重复的行，在唯一博弈猜想下，单侧扩展图的相应着色问题就是NP难的。另一方面，如果这个矩阵没有重复的行，我们的算法可以在多项式时间内解决单侧扩展图上的相应着色问题。作为我们算法结果的出发点，我们展示了一个图谱性质，据我所知，这是以前从未观察到的：小于-τ的负特征值的数量至多是大于τ^2/2的特征值数量的O(1/τ^2)倍。虽然这个结果允许我们限制单侧谱扩展图中远离0的特征值的数量，但仅凭此性质不足以支持我们的算法结果。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [450] [Coloring 3-Colorable Graphs with Low Threshold Rank](https://arxiv.org/abs/2508.03093)
> *低阈值秩的三可染色图着色*

*Jun-Ting Hsieh* | **Category: cs.DS** | **Updated: 2025-08-05**

**Keywords:** 3可染色图, 阈值秩, 独立集, 图着色, 近似算法

**Comment:** 

> **TL;DR:** 一种新算法，用于在具有低阈值秩的三可染色图中找到大的独立集，实现了接近最优的结果并证明了其紧密性。

**AI_Comments:** 该论文的创新之处在于提出了一种新算法，该算法在对特定类型的图进行3着色方面取得了接近最优的结果，并且重要的是，证明了其结果的紧密性。基于对3着色相关性性质的新颖观察，证明的简洁性也是一个值得注意的方面。这项工作推进了对图着色复杂性的理解，特别是与图谱性质相关的方面。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为具有小单侧阈值秩的三可染色图寻找大的独立集，以扩展和改进Bafna、Hsieh和Kothari先前关于单侧扩展图的工作，并探讨此类结果的紧密性。

**Method:** 提出了一种新算法。该算法基于一个观察：对于任何正确的3着色分布，如果端点的边缘分布不集中在任何单一颜色上，那么跨边的相关性必须很大。

**Result:** 对于一个$n$顶点3可染色图，其均匀随机游走矩阵最多有$r$个大于$\varepsilon$的特征值，算法在$n^{O(r/\varepsilon^2)}$时间内找到至少$(\frac{1}{2}-O(\varepsilon))n$个顶点的正确3着色。该结果被证明是紧密的。

**Conclusion:** 该论文为具有低阈值秩的三可染色图的很大一部分顶点提供了3着色的紧密结果。其关键洞察在于3着色特有的相关性性质，该性质对4着色不成立，这与已知的困难性结果一致。

> **ai_Abstract:** 本文提出了一种新颖的算法，用于对具有低单侧阈值秩的三可染色图的大部分顶点进行3着色。该算法实现了接近最优的结果，能够在多项式时间内对至少$(\frac{1}{2}-O(\varepsilon))n$个顶点进行着色。该证明简短且基于3着色特有的相关性性质，这突出了其与4着色的区别，并与已知的困难性结果相符。

> **摘要翻译:** 我们提出了一种新算法，用于在具有小单侧阈值秩的3可染色图中寻找大的独立集。具体来说，给定一个$n$顶点3可染色图，其均匀随机游走矩阵最多有$r$个大于$\varepsilon$的特征值，我们的算法在$n^{O(r/\varepsilon^2)}$时间内找到至少$(\frac{1}{2}-O(\varepsilon))n$个顶点的正确3着色。这扩展并改进了Bafna、Hsieh和Kothari关于单侧扩展图的结果。此外，Buhai、Hua、Steurer和V\'ari-Kakas的一项独立工作表明，正确3着色超过$(\frac{1}{2}+\varepsilon)n$个顶点是UG-hard的，从而确立了我们结果的紧密性。
我们的证明简短而简单，依赖于这样一个观察：对于任何正确的3着色分布，如果端点的边缘分布不集中在任何单一颜色上，那么跨边的相关性必须很大。值得注意的是，该性质对4着色不成立，这与[BHK25]关于4可染色单侧扩展图的困难性结果一致。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [499] [When is String Reconstruction using de Bruijn Graphs Hard?](https://arxiv.org/abs/2508.03433)
> *de Bruijn图上的字符串重建何时变得困难？*

*Ben Bals, Sebastiaan van Krieken, Solon P. Pissis, Leen Stougie, Hilde Verbeek* | **Category: cs.DS** | **Updated: 2025-08-05**

**Keywords:** de Bruijn图, 字符串重建, 欧拉路径, 参数化复杂度, 基因组组装

**Comment:** ESA 2025 (abstract abridged to satisfy arXiv requirements)

> **TL;DR:** 本文探讨了在给定领域知识函数的情况下，从de Bruijn图重建最佳字符串的难度。它研究了带约束的欧拉路径问题，并提出了在特定参数下改进的算法，特别是在位置范围相对于k较小时。

**AI_Comments:** 这篇论文解决了基因组组装和数据隐私等领域中一个重要的NP完全问题。其创新之处在于引入了新的参数化方法，并提供了组合学见解，从而在特定条件下（当位置范围相对于k较小时）实现了指数级的时间复杂度改进。这对于实际应用中处理带约束的字符串重建问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基因组组装中，将片段组装问题简化为欧拉路径问题，极大地推动了基因组组装的进展。de Bruijn图被用于此简化。在数据隐私领域，Bernardini等人也引入了基于z-匿名性的互补思想。核心问题是：给定一个建模领域知识的函数（将长度为k的字符串映射到其在重建字符串中可能出现的位置区间），从de Bruijn图中重建最佳字符串有多困难？这个问题转化为在图中寻找遵守边约束的欧拉路径。

**Method:** 本文关注于参数化，旨在将领域知识的质量纳入复杂性考量。Ben-Dor等人开发了一个算法来解决de Bruijn图上的问题，时间复杂度为$O(m \cdot w^{1.5} 4^{w})$，其中$m=|E|$，$w$是所有边的最大区间长度。本文提供了组合学见解，从而在现有技术水平上实现了指数级的改进。对于重要的de Bruijn图类别，本文开发了一个由$w (\log w+1) /(k-1)$参数化的改进算法。

**Result:** 本文提出了改进的算法，相对于现有技术实现了指数级的时间复杂度改进。对于de Bruijn图，新的算法由$w (\log w+1) /(k-1)$参数化。改进的算法表明，当位置范围相对于$k$较小时，这种方法是足够的。

**Conclusion:** 从de Bruijn图重建字符串的问题，在给定领域知识函数的情况下，是NP完全的。本文通过引入新的参数化算法，证明了当位置范围相对于k较小时，可以有效解决这个问题，并提供了比现有技术指数级提升的性能。

> **ai_Abstract:** 本文研究了在de Bruijn图上，给定领域知识函数约束下的字符串重建问题，该问题可归结为寻找带约束的欧拉路径。尽管该问题已知是NP完全的，但本文通过参数化方法，提出了新的组合学见解，并开发了一个改进的算法。该算法由$w (\log w+1) /(k-1)$参数化，并在位置范围$w$相对于$k$较小时，实现了比现有技术指数级的性能提升。

> **摘要翻译:** 片段组装问题简化为经典欧拉路径问题（及其变体）[Pevzner et al., PNAS 2001] 极大地推动了基因组组装的进展。这种简化采用了字母表Σ上k阶de Bruijn图G=(V,E)的概念。G中的单一欧拉路径代表一个候选基因组重建。Bernardini et al. 还在数据隐私领域引入了基于z-匿名性的互补思想 [ALENEX 2020]。
  紧迫的问题是：给定一个建模领域知识的函数，从de Bruijn图重建最佳字符串有多困难？该函数将每个长度为k的字符串映射到其在重建字符串中可能出现的位置区间。通过上述简化为de Bruijn图，后者函数转换为一个函数c，将每条边映射到其在欧拉路径中可能出现的位置区间。这在图上引出了以下基本问题：给定实例(G,c)，我们能否有效地计算出一条遵守c的欧拉路径？Hannenhalli et al. [CABIOS 1996] 正式化了这个问题并表明它是NP完全的。
  我们关注参数化，旨在将领域知识的质量纳入复杂性考量。Ben-Dor et al. 开发了一个算法来解决de Bruijn图上的问题，时间复杂度为O(m · w^1.5 4^w)，其中m=|E|，w是所有边的最大区间长度。Bumpus和Meeks [Algorithmica 2023] 在时间图上重新发现了相同的算法，突出了这个问题在其他背景下的相关性。我们给出了组合学见解，从而在现有技术水平上实现了指数级的时间复杂度改进。对于重要的de Bruijn图类别，我们开发了一个由w (log w+1) /(k-1)参数化的算法。我们改进的算法表明，当位置范围相对于k较小时，这种方法是足够的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [777] [Optimality of Frequency Moment Estimation](https://arxiv.org/abs/2411.02148)
> *频率矩估计的最优性*

*Mark Braverman, Or Zamir* | **Category: cs.DS, cs.CC, cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 频率矩估计, 空间复杂度, 下界, 改进算法, 流数据

**Comment:** This version retracts a previously included sketch claiming that the
  lower bound should extend to non-integral frequency moments F_p for p in
  (1,2)

> **TL;DR:** 该研究在估计流数据的第二频率矩方面，对小epsilon值（epsilon=Omega(1/sqrt(n))）给出了最优空间复杂度下界Omega(log(n*epsilon^2)/epsilon^2)，并提出了匹配该下界的改进算法。

**AI_Comments:** 该研究在理论和实践上都具有重要意义。理论上，它确定了在特定条件下第二频率矩估计的最优空间复杂度，填补了现有研究的空白。实践上，提出的改进算法能够更有效地处理小epsilon值的情况，这在许多实际应用中非常有用。然而，对于epsilon大于n^{-1/2+c}的情况，其下界与经典AMS上界一致，这表明在这些情况下，现有算法已经接近最优，改进空间可能有限。

<details>
  <summary>Details</summary>

**Motivation:** 为了确定估计流数据的第二频率矩所需的最小空间，并改进现有算法在小epsilon值下的性能。

**Method:** 通过证明最优下界和提出匹配该下界的改进算法。

**Result:** 证明了在epsilon = Omega(1/sqrt(n))时，第二频率矩估计的空间复杂度下界为Omega(log(n*epsilon^2)/epsilon^2)，并提出了一个改进的算法。

**Conclusion:** 该研究在小epsilon值下确定了第二频率矩估计的最优空间复杂度，并提出了匹配该最优下界的改进算法，解决了现有算法在这些情况下的性能问题。

> **ai_Abstract:** 本研究探讨了流数据第二频率矩估计的最优空间复杂度。在epsilon = Omega(1/sqrt(n))的条件下，证明了Omega(log(n*epsilon^2)/epsilon^2)的最优下界，并提出了一个改进算法，该算法在小epsilon值下优于经典的AMS算法，并匹配了新的下界。

> **摘要翻译:** 估计流数据的第二频率矩，最多需要 $(1ho	au	heta)$ 的乘法误差，空间复杂度最多为 $O(ho	au	heta / 	au^2)$ 位，这是 Alon、Matias 和 Szegedy 的开创性结果。众所周知，至少需要 $ho	au	heta + 1/	au^2$ 的空间。我们证明了对于所有 $	au = ho	au	heta/ho	au	heta^{1/2}$，最优下界为 $ho	au	heta(ho	au	heta 	au^2) / 	au^2$。请注意，当 $	au>ho	au	heta^{-1/2 + c}$，其中 $c>0$ 时，我们的下界与 AMS 的经典上界相匹配。对于较小的 $	au$ 值，我们还引入了一种改进的算法，该算法改进了经典的 AMS 边界并匹配了我们的下界。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [109] [Understanding Demand for Shared Autonomous Micro-Mobility](https://arxiv.org/abs/2508.03521)
> *理解共享自动微出行的需求*

*Naroa Coretti Sanchez, Kent Larson* | **Category: cs.ET, cs.CY** | **Updated: 2025-08-05**

**Keywords:** 共享自动微出行, 需求, 离散选择模型, 行为影响, 环境影响

**Comment:** 

> **TL;DR:** 本研究探讨了共享自动微出行系统（特别是自动自行车）的行为和环境影响，发现服务设计、人口特征、城市类型等因素显著影响采纳率和环境效益。

**AI_Comments:** 这项研究通过结合真实世界行程数据和混合离散选择模型（包含潜在态度），深入分析了共享自动微出行的用户行为和环境影响，弥补了现有研究在用户需求理解上的不足。其创新之处在于将行为因素与环境影响相结合，为政策制定者提供了更全面的视角。研究强调了服务设计在平衡采纳率和环境可持续性之间的重要性，对于未来智慧城市交通规划具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注共享自动微出行系统的运营和生命周期方面，但在理解这些服务可能替代哪些出行方式、哪些人更倾向于采纳以及服务属性如何影响用户决策方面存在关键空白。

**Method:** 研究设计了一项基于真实行程的情境感知陈述偏好调查，并估计了离散选择模型，包括一个包含潜在态度的混合模型。

**Result:** 研究结果表明，采纳率、出行方式转换和环境影响对服务设计高度敏感。等待时间短、成本低的场景会带来高采纳率但增加排放，而适度的等待时间则更有可能减少影响。采纳可能性随人口特征而变化，结果取决于城市类型、背景和基础设施假设。

**Conclusion:** 这些研究洞察可以为开发更可持续和公平的出行系统提供信息。

> **ai_Abstract:** 本研究通过情境感知调查和离散选择模型，探讨了共享自动微出行（特别是自动自行车）的行为和环境影响。研究发现，服务设计（如等待时间、成本）、人口特征和城市环境对系统采纳率、出行方式转换及环境影响至关重要。结果表明，高采纳率不一定带来环境效益，需要权衡设计以实现可持续发展。

> **摘要翻译:** 本研究考察了共享自动微出行系统的行为和环境影响，重点关注自动自行车及其在美国公共交通中的整合。尽管先前的研究已经涉及运营和生命周期方面，但在理解这些服务可能替代哪些模式、哪些人最倾向于采纳它们以及服务属性如何影响用户决策方面仍存在关键空白。我们设计了一项基于真实行程的情境感知陈述偏好调查，并估计了离散选择模型，包括一个包含潜在态度的混合模型。研究结果表明，采纳率、出行方式转换和环境影响对服务设计高度敏感。等待时间短、成本低的场景会带来高采纳率但增加排放，而适度的等待时间则更有可能减少影响。采纳可能性随人口特征而变化，结果取决于城市类型、背景和基础设施假设。这些洞察可以为开发更可持续和公平的出行系统提供信息。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [838] [Managing Escalation in Off-the-Shelf Large Language Models](https://arxiv.org/abs/2508.01056)
> *管理现成大型语言模型的升级*

*Sebastian Elbaum, Jonathan Panter* | **Category: cs.ET, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 国家安全, 升级管理, 战争游戏, 干预措施

**Comment:** 

> **TL;DR:** 研究表明，现成的LLM在面对地缘政治场景时，经常会提出升级行动。本研究提出了两种非技术性干预措施，并在实验性战争游戏中成功减少了升级情况，表明LLM可以被引导以符合国家安全目标，而不是禁止。

**AI_Comments:** 这项研究具有重要的现实意义，因为它直接解决了在国家安全领域应用LLM所面临的关键挑战之一：升级风险。研究提出的非技术性干预措施简单且易于实施，为实际应用提供了可行的解决方案。研究结论有力地反驳了完全禁止LLM在国家安全领域应用的观点，并强调了通过适当的管理来利用其潜力的重要性。未来的研究可以进一步探索这些干预措施在更复杂的场景和不同类型的LLM上的有效性，并量化其对决策过程的具体影响。

<details>
  <summary>Details</summary>

**Motivation:** 美国国家安全部门开始使用现成的LLM，但这些模型在面对地缘政治场景时，经常会建议采取升级行动。因此，需要研究如何控制这种倾向，以符合国家安全目标。

**Method:** 本研究提出了两种简单、非技术性的干预措施，并将其应用于最近的一项研究设计中，以控制LLM在面对地缘政治场景时的升级倾向。

**Result:** 通过在实验性战争游戏中引入这两种干预措施，研究显著减少了整个游戏过程中的升级情况。

**Conclusion:** 禁止在国家安全应用中使用LLM的警告为时过早。美国政府已经在并将继续使用LLM进行场景规划和行动建议。本研究提供的可操作措施可以使LLM与国家安全目标保持一致，包括升级管理。

> **ai_Abstract:** 本研究探讨了在国家安全领域使用现成的大型语言模型（LLM）时如何管理升级问题。研究发现，LLM在面对地缘政治场景时倾向于建议升级行动。为了解决这个问题，研究提出了两种非技术性的干预措施，并在实验性战争游戏中成功地减少了升级情况。研究认为，不应禁止在国家安全应用中使用LLM，而应采取措施来引导它们符合国家安全目标，特别是升级管理。

> **摘要翻译:** 美国国家安全客户已开始利用大型语言模型，包括公众熟悉的“现成”模型（例如 ChatGPT）的企业版。这种采用可能会加速。然而，最近的研究表明，现成的语言模型在被提示地缘政治或战略场景时，经常会建议采取升级行动。我们演示了两种简单、非技术性的干预措施来控制这些倾向。将这些干预措施引入最近一项研究的实验性战争游戏设计中，我们大大减少了整个游戏过程中的升级。因此，呼吁限制在国家安全应用中使用大型语言模型的说法为时过早。美国政府已经并将继续使用大型语言模型进行场景规划和提出行动方案。本研究不警告此类应用，而是承认大型语言模型的即时采用，并提供可操作的措施，使其与国家安全目标保持一致，包括升级管理。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [528] [A Myhill-Nerode Theorem for Generalized Automata, with Applications to Pattern Matching and Compression](https://arxiv.org/abs/2302.06506)
> *广义自动机的Myhill-Nerode定理及其在模式匹配和压缩中的应用*

*Nicola Cotumaccio* | **Category: cs.FL, cs.DS, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 广义自动机, Myhill-Nerode定理, 模式匹配, 数据压缩, 正则语言

**Comment:** 

> **TL;DR:** 本文为广义自动机首次推导出了一个完整的Myhill-Nerode定理，通过引入集合$\mathcal{W(A)}$解释了最小广义确定性自动机缺乏唯一性的问题，并展示了其在模式匹配和数据压缩中的应用。

**AI_Comments:** 本文的创新点在于首次为广义自动机推导出了完整的Myhill-Nerode定理，并通过引入集合$\mathcal{W(A)}$解决了该模型中长期存在的最小确定性自动机唯一性缺失问题。这一理论突破不仅完善了广义自动机的理论基础，还为模式匹配和数据压缩提供了新的高效算法和数据结构，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 广义自动机比传统自动机能更简洁地表示正则语言，但其最小广义确定性自动机失去了唯一性。本文的动机是解释这种唯一性的缺失，并为此类自动机推导出Myhill-Nerode定理，同时探索其应用。

**Method:** 研究分两部分进行：首先，通过引入一个与广义自动机$\mathcal{A}$相关的集合$\mathcal{W(A)}$，解释了最小广义确定性自动机缺乏唯一性的原因，并首次推导出了一个完整的Myhill-Nerode定理。其次，展示了集合$\mathcal{W(A)}$在模式匹配和数据压缩中的应用，并给出了具体的复杂度分析。

**Result:** 推导出了一个完整的Myhill-Nerode定理，该定理包含传统自动机的Myhill-Nerode定理作为退化情况。此外，研究表明，使用$\mathfrak{e} \log \sigma (1 + o(1)) + O(e)$比特可以存储惠勒广义自动机，从而模式匹配查询可以在$O(m \log \log \sigma)$时间内解决。

**Conclusion:** 本文成功为广义自动机推导出了一个完整的Myhill-Nerode定理，并通过引入集合$\mathcal{W(A)}$解释了其最小确定性形式的唯一性缺失问题。此外，该工作还展示了这些理论成果在模式匹配和数据压缩方面的实际应用潜力。

> **ai_Abstract:** 本论文深入探讨了广义自动机，一种比传统自动机更简洁的正则语言表示模型。针对其最小确定性形式缺乏唯一性的问题，研究引入了一个新的集合$\mathcal{W(A)}$，并在此基础上首次成功推导出了一个包含传统自动机Myhill-Nerode定理的完整Myhill-Nerode定理。此外，论文还展示了$\mathcal{W(A)}$集合在模式匹配和数据压缩领域的应用，提出了具体的存储和查询时间复杂度优化方案。

> **摘要翻译:** Eilenberg于1974年引入的广义自动机模型，通过允许边不仅用字符标记，还可以用字符串标记，从而比传统自动机更简洁地表示正则语言。Giammaresi和Montalbano在1995年的STACS会议上为广义自动机引入了确定性概念。虽然广义确定性自动机保留了传统确定性自动机的许多性质，但最小广义确定性自动机的唯一性却丧失了。
本文的第一部分，我们展示了这种缺乏唯一性可以通过引入一个与广义自动机$\mathcal{A}$相关的集合$\mathcal{W(A)}$来解释。通过这种方式，我们首次为广义自动机推导出了一个完整的Myhill-Nerode定理，其中包含教科书中传统自动机的Myhill-Nerode定理作为退化情况。在本文的第二部分，我们展示了集合$\mathcal{W(A)}$在模式匹配和数据压缩中的应用。我们展示了惠勒广义自动机可以使用$\mathfrak{e} \log \sigma (1 + o(1)) + O(e)$比特存储，从而模式匹配查询可以在$O(m \log \log \sigma)$时间内解决，其中$\mathfrak{e}$是所有边标签的总长度，$e$是边的数量，$\sigma$是字母表的大小，$m$是模式的长度。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [680] [Learning Event-recording Automata Passively](https://arxiv.org/abs/2508.03627)
> *被动学习事件记录自动机*

*Anirban Majumdar, Sayan Mukherjee, Jean-François Raskin* | **Category: cs.FL** | **Updated: 2025-08-05**

**Keywords:** 事件记录自动机, 时序语言学习, 状态合并, SMT, 被动学习

**Comment:** Shorter version of this article has been accepted at ATVA 2025

> **TL;DR:** 该论文提出了一种名为LEAP的算法，用于从符号时间词的样本中学习事件记录自动机（ERA），该算法基于状态合并技术，并使用SMT解决NP完全问题，实验证明了其有效性。

**AI_Comments:** 该研究提出了一种创新的被动学习方法，用于从符号时间词中学习事件记录自动机（ERA），解决了关键的NP完全问题，并通过SMT技术提供了实用的解决方案，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 从符号时间词的样本（包括正样本和负样本）中学习可由事件记录自动机（ERA）定义的时序语言。

**Method:** 提出了一种状态合并算法（LEAP），该算法可以从正负样本（符号时间词）中构建可能非确定性的ERA。该算法基于状态合并技术，并使用SMT来解决状态合并过程中的NP完全问题。

**Result:** 证明了确定两个ERA状态是否可以合并以保持样本一致性是一个NP完全问题，并提出了基于SMT的解决方案。实现表明该算法的有效性。

**Conclusion:** 所提出的LEAP算法能够从给定的样本中学习ERA，并且对于每个ERA可定义的语言，只要有合适的样本，该算法都可以进行推理。

> **ai_Abstract:** 本文介绍了一种名为LEAP的被动学习算法，用于从符号时间词的正负样本中学习事件记录自动机（ERA）。该算法采用状态合并技术，并利用SMT解决NP完全问题，实现了ERA的学习和推理。

> **摘要翻译:** 本文提出了一种从正负样本（符号时间词形式）中学习事件记录自动机（ERA）定义的时间语言的状态合并算法。我们的算法LEAP（被动学习事件记录自动机）基于合并技术，从这些样本构建可能非确定性的ERA。我们证明了确定两个ERA状态是否可以合并同时保持样本一致性是一个NP完全问题，并用一个实用的基于SMT的解决方案来解决这个问题。我们的实现通过实例证明了该算法的有效性。我们还表明，使用我们的算法和合适的样本，可以推理出每个ERA可定义的语言。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [721] [Design Support for Multitape Turing Machines](https://arxiv.org/abs/2508.03638)
> *多带图灵机的设计支持*

*Marco T. Morazán, Oliwia Kempinski, Andrés M. Garced* | **Category: cs.FL, cs.HC, cs.PL, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 多带图灵机,可视化工具,形式语言,自动机理论,教学支持

**Comment:** In Proceedings TFPiE 2025, arXiv:2508.02305

> **TL;DR:** 本研究介绍了一种用于多带图灵机教学的可视化工具集，包括动态模拟和静态图表渲染，旨在帮助学生理解其运行机制和设计过程，并提供了实证数据支持其有效性。

**AI_Comments:** 该研究通过开发可视化工具来解决形式语言教学中的一个实际问题，即学生对多带图灵机的理解困难。这种结合理论与实践的方法很有价值。然而，文中提到的“实证数据”并未详细展示，这限制了对其有效性的全面评估。未来的研究可以更深入地探讨这些工具在不同学习环境和学生群体中的具体应用效果和潜在的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多带图灵机教学方法对学生来说仍然具有挑战性，现有的FSM编程语言在帮助学生理解其操作语义和接受/拒绝原因方面存在不足。

**Method:** 开发了三个可视化工具：一个动态可视化工具用于模拟机器执行，一个静态可视化工具用于渲染转移图，另一个静态可视化工具用于渲染计算图。文章介绍了这些工具及其应用，并通过实证数据评估了学生的使用反馈。

**Result:** 学生普遍认为这些可视化工具易于接受且有用，有助于他们设计和实现多带图灵机。

**Conclusion:** 所开发的可视化工具集能够有效帮助学生理解和设计多带图灵机，实证数据表明它们在教学中是受欢迎且有效的。

> **ai_Abstract:** 本研究提出了一套用于多带图灵机教学的可视化工具，旨在解决学生在理解其操作语义和设计过程中的困难。该工具集包括一个动态模拟工具和两个静态渲染工具（用于转移图和计算图）。通过这些工具，学生能够更好地掌握多带图灵机的设计与实现。实证数据显示，这些工具受到了学生的欢迎并被认为具有较高的实用价值。

> **摘要翻译:** 许多形式语言与自动机理论课程都向学生介绍了图灵机的扩展。最广泛使用的扩展之一是赋予图灵机多个磁带。尽管多带图灵机是为了简化图灵机设计而进行的一种抽象，但学生们发现它们同样具有挑战性。为了帮助学生理解这些机器，FSM编程语言为其定义和执行提供了支持。然而，事实证明这对于许多学生理解这些机器的操作语义以及理解它们为什么接受或拒绝一个词来说仍然不够。为了解决这个问题，已经开发了三个可视化工具。第一个是模拟机器执行的动态可视化工具。第二个是自动渲染多带图灵机转移图的图形的静态可视化工具。第三个是自动渲染多带图灵机计算图的静态可视化工具。本文介绍了这些工具，并说明了如何使用它们来帮助学生设计和实现多带图灵机。此外，还提供了实证数据，表明学生普遍接受并发现这些工具有用。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [762] [A Design Recipe and Recipe-Based Errors for Regular Expressions](https://arxiv.org/abs/2508.03639)
> *正则表达式的设计配方和基于配方的错误*

*Marco T. Morazán, Shamil Dzhatdoyev, Josephine Des Rosiers, Tijana Minić, Andrés M. Garced, David Anthony K. Fields* | **Category: cs.FL, cs.HC, cs.PL, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 正则表达式,设计配方,错误消息,形式语言,自动机理论

**Comment:** In Proceedings TFPiE 2025, arXiv:2508.02305

> **TL;DR:** 该论文提出了一个用于形式语言和自动机理论学生设计正则表达式的框架，包括一个设计配方和一个基于配方定制的错误消息系统，旨在提供设计支持和改进错误反馈。

**AI_Comments:** 该研究通过提供结构化的设计方法和具体的错误反馈，解决了在正则表达式学习中的常见挑战，具有较高的教学和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 为形式语言和自动机理论学生在开发正则表达式时提供设计支持。

**Method:** 提出一个包含设计配方和定制错误消息系统的框架。错误消息系统会生成基于配方步骤的错误信息，并描述了一种用于编写单元测试的简短语法。此外，还展示了设计配方在课堂上的使用、两次调试会话以及错误消息系统的实现。

**Result:** 开发了一个包含设计配方和基于配方错误消息系统的框架，用于支持正则表达式的设计和调试。

**Conclusion:** 该框架为正则表达式的设计提供了支持，并通过基于配方定制的错误消息系统改进了错误反馈，有助于学生学习和理解。

> **ai_Abstract:** 本文介绍了一个为形式语言和自动机理论学生设计的框架，旨在帮助他们创建正则表达式。该框架包含一个详细的设计配方和一个创新的错误消息系统，该系统能提供基于设计过程中具体步骤的错误反馈。此外，还提供了一种简化的语法用于编写单元测试。

> **摘要翻译:** 本文提出了一个新颖的框架，为形式语言和自动机理论学生提供正则表达式开发的辅助设计。该框架包括一个正则表达式设计配方和一个定制的错误消息系统。该错误消息系统会生成基于配方步骤的错误信息，其中包含设计配方中未成功完成的步骤。此外，错误消息遵循简洁、扼要、无术语和非指令性的既定实践。另外，还描述了一种用于编写单元测试的简短语法。文章展示了该设计配方在课堂上的使用，讨论了使用所述系统的两次调试会话，并简要概述了错误消息系统的实现。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [804] [Visual Execution and Validation of Finite-State Machines and Pushdown Automata](https://arxiv.org/abs/2508.03641)
> *有限状态机和下推自动机的可视化执行与验证*

*Marco T. Morazán, David Anthony K. Fields, Andrés M. Garced, Tijana Minić* | **Category: cs.FL, cs.HC, cs.PL, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 有限状态机,下推自动机,可视化工具,形式语言,自动机理论

**Comment:** In Proceedings TFPiE 2025, arXiv:2508.02305

> **TL;DR:** 本研究提出两种新的动态可视化工具，用于帮助学生理解和验证非确定性有限状态机和下推自动机，解决了学生在理解这些模型的操作语义和栈推理方面遇到的困难。

**AI_Comments:** 该研究提出的可视化工具具有创新性，解决了自动机理论教学中的一个关键痛点。然而，该研究的局限性在于仅关注了FSM和PDA，并且其有效性仍需通过实际的教学评估来进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 学生在理解形式语言与自动机理论中的非确定性有限状态机和下推自动机时存在困难，尤其是在理解其操作语义、接受/拒绝单词的原因以及推理栈方面。现有教学方法未能有效解决这些挑战。

**Method:** 提出两种新的动态可视化工具，使用领域特定语言来支持自动机理论课堂上的机器设计。这两种工具分别可视化非确定性有限状态机和下推自动机的所有可能计算过程，并支持用户逐步验证状态属性。

**Result:** 这两种可视化工具能够逐步展示非确定性有限状态机和下推自动机的计算过程，帮助用户理解其操作语义，并允许用户直观地验证状态属性，从而辅助机器验证过程。

**Conclusion:** 本研究提出的可视化工具能够有效帮助学生克服在理解非确定性有限状态机和下推自动机方面遇到的困难，提高他们对自动机理论的掌握程度。

> **ai_Abstract:** 本研究旨在通过提供两种新颖的动态可视化工具来解决学生在形式语言和自动机理论课程中理解非确定性有限状态机（FSM）和下推自动机（PDA）的困难。这些工具使用一种领域特定语言，允许用户设计FSM，并以逐步方式可视化所有可能的计算过程。此外，它们还通过允许用户验证状态属性来辅助机器验证。这有助于学生更好地理解这些自动机的操作语义，特别是与栈推理相关的复杂性。

> **摘要翻译:** 在形式语言与自动机理论课程中，学生发现理解非确定性有限状态机和下推自动机非常困难。在许多情况下，这意味着他们难以理解这些机器的操作语义，因此，难以确定一个单词为何被接受或拒绝。这并非完全令人惊讶，因为学生主要接受设计和实现确定性程序的训练。对下推自动机的理解进一步复杂化，因为有必要推理栈。学生面临的一个常见困难是理解两个不同计算在处理相同单词时可能以不同的栈值达到相同状态。为了帮助学生理解，我们提出了两种新的动态可视化工具，用于有限状态机——自动机理论课堂的领域特定编程语言——以支持此类机器的设计。这两种工具分别以逐步方式可视化非确定性有限状态机或下推自动机可能执行的所有计算。此外，这些工具通过允许用户直观地验证状态代表的属性在机器转换到该状态时是否成立，来辅助机器验证过程。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [83] [Diffuse-CLoC: Guided Diffusion for Physics-based Character Look-ahead Control](https://arxiv.org/abs/2503.11801)
> *Diffuse-CLoC：基于物理的角色前瞻控制引导扩散框架*

*Xiaoyu Huang, Takara Truong, Yunbo Zhang, Fangzhou Yu, Jean Pierre Sleiman, Jessica Hodgins, Koushil Sreenath, Farbod Farshidian* | **Category: cs.GR, cs.LG, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 引导扩散, 物理基础控制, 运动生成, 角色控制, 联合分布建模

**Comment:** 

> **TL;DR:** Diffuse-CLoC是一个引导扩散框架，通过在单个扩散模型中建模状态和动作的联合分布，实现了直观、可控且物理真实的基于物理的前瞻运动生成，无需高层规划器即可处理多样化的任务。

**AI_Comments:** Diffuse-CLoC的创新点在于其将状态和动作的联合分布建模在一个单一扩散模型中，有效解决了传统方法中可控性和物理真实性难以兼顾的问题。这种方法避免了对高层规划器的依赖，简化了复杂的运动控制流程，并展现出处理多样化、长期任务的强大泛化能力，对物理仿真和角色动画领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有运动生成方法存在局限性：使用扩散模型的运动学运动生成虽然直观可控，但常无法产生物理可行的运动；而基于扩散的控制策略虽能生成物理真实的运动序列，但缺乏运动学预测限制了其可控性。

**Method:** Diffuse-CLoC通过关键洞察来解决这些挑战：在单个扩散模型中建模状态和动作的联合分布，通过对预测状态进行条件化来使动作生成具有可控性。这种方法利用了运动学运动生成中已有的条件化技术，同时生成物理真实的运动。

**Result:** 该方法无需高层规划器即可实现规划能力。一个预训练模型能处理多样化的、未见的长期下游任务，包括静态和动态障碍物避让、动作中间插入和任务空间控制。实验结果表明，该方法显著优于传统的高层运动扩散和低层跟踪的分层框架。

**Conclusion:** Diffuse-CLoC通过创新的联合分布建模方法，成功地将运动学预测的可控性与物理真实性相结合，为物理基础的角色运动生成提供了一个有效且高效的解决方案，并在多样化任务中表现出色。

> **ai_Abstract:** Diffuse-CLoC是一个创新的引导扩散框架，旨在解决物理基础角色运动生成中的可控性与物理真实性之间的矛盾。它通过在单个扩散模型中建模状态和动作的联合分布，实现了直观、可控且物理真实的运动，并通过对预测状态进行条件化来引导动作生成。该方法无需高层规划器即可执行规划任务，并能处理各种未见的长期挑战，如障碍物避让和任务空间控制。实验证明，Diffuse-CLoC显著优于传统的分层运动控制框架。

> **摘要翻译:** 我们提出了Diffuse-CLoC，一个用于基于物理的前瞻控制的引导扩散框架，它能够实现直观、可控且物理真实的运动生成。虽然现有使用扩散模型的运动学运动生成提供了直观的控制能力和推理时条件化，但它们通常无法产生物理可行的运动。相比之下，最近基于扩散的控制策略在生成物理可实现运动序列方面显示出前景，但缺乏运动学预测限制了它们的可控性。Diffuse-CLoC通过一个关键的洞察解决了这些挑战：在单个扩散模型中建模状态和动作的联合分布，通过对其预测状态进行条件化来使动作生成具有可控性。这种方法使我们能够利用运动学运动生成中已建立的条件化技术，同时产生物理真实的运动。因此，我们无需高层规划器即可实现规划能力。我们的方法通过一个预训练模型处理一系列未见的长期下游任务，包括静态和动态障碍物避让、动作中间插入和任务空间控制。实验结果表明，我们的方法显著优于传统的高层运动扩散和低层跟踪的分层框架。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [112] [Taking Language Embedded 3D Gaussian Splatting into the Wild](https://arxiv.org/abs/2507.19830)
> *将语言嵌入式3D高斯泼溅引入野外*

*Yuze Wang, Yue Qi* | **Category: cs.GR, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 语言嵌入式3D高斯泼溅, 开放词汇场景理解, 建筑结构理解, 无约束照片集, PT-OVS

**Comment:** Visit our project page at
  https://yuzewang1998.github.io/takinglangsplatw/

> **TL;DR:** 该论文提出了一种新的框架，通过扩展语言嵌入式3D高斯泼溅技术，实现了从无约束照片集中进行开放词汇场景理解，并引入了一个新的基准数据集PT-OVS，实验证明其在开放词汇分割方面优于现有方法，并支持多种沉浸式应用。

**AI_Comments:** 本文的创新点在于将语言嵌入式3D高斯泼溅技术应用于无约束照片集，以实现开放词汇的3D场景理解，尤其是在建筑风格和结构方面。通过引入多外观特征和不确定性图指导优化，以及独特的数据处理策略，该方法有效地弥补了现有3D重建在语义理解上的不足。PT-OVS数据集的引入也为该领域提供了重要的评估工具。其在交互式漫游、建筑风格识别和3D场景编辑方面的应用潜力巨大，为沉浸式体验和文化遗产保护提供了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于大规模互联网照片集的3D重建技术主要用于地标和历史遗迹的虚拟探索，但对建筑风格和结构知识的沉浸式理解关注甚少，仍局限于浏览静态的文本-图像对。因此，本文旨在探索是否能借鉴野外3D重建技术，利用无约束照片集创建一种沉浸式方法来理解建筑构件的3D结构。

**Method:** 本文扩展了语言嵌入式3D高斯泼溅（3DGS），提出了一种从无约束照片集进行开放词汇场景理解的新颖框架。具体来说，首先从与无约束图像相同的视角渲染多个外观图像，并结合重建的辐射场；然后提取多外观CLIP特征以及两种语言特征不确定性图（瞬态和外观不确定性）来指导优化过程。接着，提出了一种瞬态不确定性感知自动编码器、一种多外观语言场3DGS表示和一种后集成策略，以有效压缩、学习和融合来自多个外观的语言特征。

**Result:** 本文引入了PT-OVS，这是一个新的基准数据集，用于评估无约束照片集上的开放词汇分割性能。实验结果表明，本文方法优于现有方法，能够实现准确的开放词汇分割，并支持诸如带开放词汇查询的交互式漫游、建筑风格模式识别和3D场景编辑等应用。

**Conclusion:** 本文提出的方法通过扩展语言嵌入式3D高斯泼溅，实现了从无约束照片集进行准确的开放词汇场景理解，并能够支持交互式漫游、建筑风格识别和3D场景编辑等多种沉浸式应用，有效解决了现有技术在建筑结构沉浸式理解方面的不足。

> **ai_Abstract:** 该论文提出了一种创新的框架，通过扩展语言嵌入式3D高斯泼溅（3DGS）技术，旨在解决从无约束照片集中沉浸式理解建筑结构和风格的挑战。研究通过渲染多外观图像、提取多外观CLIP特征及语言特征不确定性图来指导优化，并引入了瞬态不确定性感知自动编码器、多外观语言场3DGS表示和后集成策略来处理和融合语言特征。为评估方法，作者构建了新的PT-OVS基准数据集。实验证明，该方法在开放词汇分割上优于现有技术，并支持交互式漫游、建筑风格识别和3D场景编辑等实际应用，极大地提升了3D场景的语义理解能力。

> **摘要翻译:** 最近，利用大规模互联网照片集进行3D重建的进展已经使得全球地标和历史遗迹的沉浸式虚拟探索成为可能。然而，对于建筑风格和结构知识的沉浸式理解却鲜有关注，这在很大程度上仍局限于浏览静态的文本-图像对。因此，我们能否从野外3D重建技术中汲取灵感，并利用无约束的照片集来创建一种沉浸式方法，以理解建筑构件的3D结构？为此，我们扩展了语言嵌入式3D高斯泼溅（3DGS），并提出了一种从无约束照片集进行开放词汇场景理解的新颖框架。具体来说，我们首先从与无约束图像相同的视角，使用重建的辐射场渲染多个外观图像，然后提取多外观CLIP特征和两种类型的语言特征不确定性图——瞬态和外观不确定性，它们源自多外观特征，用于指导后续的优化过程。接下来，我们提出了一种瞬态不确定性感知自动编码器、一种多外观语言场3DGS表示，以及一种后集成策略，以有效地压缩、学习和融合来自多个外观的语言特征。最后，为了定量评估我们的方法，我们引入了PT-OVS，这是一个新的基准数据集，用于评估无约束照片集上的开放词汇分割性能。实验结果表明，我们的方法优于现有方法，提供了准确的开放词汇分割，并支持诸如带开放词汇查询的交互式漫游、建筑风格模式识别和3D场景编辑等应用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [147] [MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh](https://arxiv.org/abs/2508.01242)
> *MeshLLM：赋能大型语言模型逐步理解和生成3D网格*

*Shuangkang Fang, I-Chao Shen, Yufeng Wang, Yi-Hsuan Tsai, Yi Yang, Shuchang Zhou, Wenrui Ding, Takeo Igarashi, Ming-Hsuan Yang* | **Category: cs.GR, cs.CV** | **Updated: 2025-08-05**

**Keywords:** MeshLLM, 大型语言模型, 3D网格, 文本序列化, 原始网格分解

**Comment:** Accepted by ICCV. Project Website: https://sk-fun.fun/MeshLLM

> **TL;DR:** MeshLLM是一个新颖的框架，利用大型语言模型（LLM）来理解和生成文本序列化的3D网格，解决了现有方法的数据集规模限制和3D结构信息丢失问题。

**AI_Comments:** MeshLLM的创新之处在于其通过原始网格分解策略，有效解决了大型语言模型在处理3D网格时面临的数据集规模不足和3D结构信息丢失的核心问题。该方法创建了前所未有的大规模数据集，并引入了增强LLM理解网格拓扑的训练策略，这对于推动LLM在3D领域应用具有重要意义和巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理文本序列化3D网格时存在局限性，包括：1) 数据集规模有限，无法满足LLM的token长度需求；2) 网格序列化过程中3D结构信息丢失。

**Method:** 本文提出了MeshLLM框架，核心在于引入了原始网格分解策略（Primitive-Mesh decomposition），将3D网格分解为结构上有意义的子单元。这使得构建一个包含1500k+样本的大规模数据集成为可能，比现有方法大近50倍，更符合LLM的扩展定律。此外，还提出了从顶点推断面连接性和局部网格组装训练策略，显著增强了LLM捕获网格拓扑和空间结构的能力。

**Result:** 实验结果表明，MeshLLM在网格生成质量和形状理解方面均优于现有最先进的LLaMA-Mesh。

**Conclusion:** MeshLLM在处理文本序列化3D网格方面展现出巨大潜力，通过解决数据规模和结构信息丢失的关键限制，显著提升了LLM对3D网格的理解和生成能力。

> **ai_Abstract:** MeshLLM是一个利用大型语言模型（LLM）理解和生成文本序列化3D网格的新框架。为解决现有方法的局限性，MeshLLM提出了原始网格分解策略，构建了一个比现有方法大50倍的1500k+样本的大规模数据集。同时，通过推断面连接性和局部网格组装训练策略，增强了LLM对3D网格拓扑和空间结构的捕获能力。实验证明，MeshLLM在网格生成质量和形状理解上均优于LLaMA-Mesh，展现了其在处理文本序列化3D网格方面的巨大潜力。

> **摘要翻译:** 我们提出了MeshLLM，一个新颖的框架，利用大型语言模型（LLMs）来理解和生成文本序列化的3D网格。我们的方法解决了现有方法中的关键局限性，包括在满足LLMs的token长度时数据集规模有限，以及网格序列化过程中3D结构信息的丢失。我们引入了一种原始网格分解策略，将3D网格分解为结构上有意义的子单元。这使得能够创建一个包含1500k+样本的大规模数据集，比以前的方法大近50倍，更符合LLM的扩展定律原则。此外，我们提出了从顶点推断面连接性和局部网格组装训练策略，显著增强了LLMs捕获网格拓扑和空间结构的能力。实验表明，MeshLLM在网格生成质量和形状理解方面均优于现有最先进的LLaMA-Mesh，突出了其在处理文本序列化3D网格方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [229] [READ: Real-time and Efficient Asynchronous Diffusion for Audio-driven Talking Head Generation](https://arxiv.org/abs/2508.03457)
> *READ：用于音频驱动的说话人头像生成的实时高效异步扩散模型*

*Haotian Wang, Yuzhe Weng, Jun Du, Haoran Xu, Xiaoyan Wu, Shan He, Bing Yin, Cong Liu, Jianqing Gao, Qingfeng Liu* | **Category: cs.GR, cs.CV, cs.SD, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 说话人头像生成, 扩散模型, 实时生成, 异步噪声调度器, 潜在空间

**Comment:** 9 pages

> **TL;DR:** 提出READ，首个实时扩散-Transformer模型，通过压缩潜在空间和异步调度器，大幅提升音频驱动说话人头像生成的效率和质量。

**AI_Comments:** 这篇论文的创新点在于首次提出了一个实时的扩散-Transformer框架用于音频驱动的说话人头像生成，解决了扩散模型推理速度慢这一关键瓶颈。通过引入高度压缩的潜在空间和新颖的异步噪声调度器（ANS），READ在保证生成质量的同时，大幅提升了生成效率和时间一致性，为该领域的实际应用开辟了新路径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型在音频驱动的说话人头像生成领域取得了显著进展，但其极慢的推理速度严重限制了实际应用。

**Method:** 本文提出了READ框架，这是首个实时扩散-Transformer说话人头像生成框架。该方法首先通过时间VAE学习时空高度压缩的视频潜在空间，以减少token数量并加速生成。为实现压缩潜在空间内的音视频对齐，引入预训练的Speech Autoencoder (SpeechAE) 生成对应的时序压缩语音潜在编码。这些潜在表示随后由精心设计的Audio-to-Video Diffusion Transformer (A2V-DiT) 主干网络进行建模。此外，为确保长时间生成中的时间一致性和加速推理，提出了一种新颖的异步噪声调度器 (ANS)，其在潜在空间中利用异步加噪和异步运动引导生成。

**Result:** 实验结果表明，READ在生成具有竞争力的说话人头像视频的同时，显著减少了运行时间，超越了现有最先进的方法。它在质量和速度之间实现了最佳平衡，并在长时间生成中保持了鲁棒的度量稳定性。

**Conclusion:** READ是首个实现实时、高效、高质量音频驱动说话人头像生成的扩散-Transformer框架，有效解决了现有扩散模型推理速度慢的问题。

> **ai_Abstract:** 本文提出了READ，一个创新的实时扩散-Transformer框架，用于音频驱动的说话人头像生成，旨在解决现有扩散模型推理速度慢的问题。READ通过引入时间VAE创建高度压缩的视频潜在空间，并结合SpeechAE生成对应的语音潜在编码，显著减少了计算量。核心是Audio-to-Video Diffusion Transformer (A2V-DiT) 进行高效合成。此外，新颖的异步噪声调度器 (ANS) 确保了长时间生成的时间一致性和加速推理。实验证明READ在速度和质量上均超越现有SOTA方法。

> **摘要翻译:** 标题：READ：用于音频驱动的说话人头像生成的实时高效异步扩散模型

摘要：扩散模型的引入为音频驱动的说话人头像生成领域带来了显著进步。然而，其极慢的推理速度严重限制了基于扩散的说话人头像生成模型的实际应用。在本研究中，我们提出了READ，这是首个基于扩散-Transformer的实时说话人头像生成框架。我们的方法首先通过时间VAE学习时空高度压缩的视频潜在空间，显著减少了token数量以加速生成。为了在这个压缩的潜在空间中实现更好的视听对齐，我们提出了一种预训练的语音自编码器（SpeechAE），用于生成与视频潜在空间对应的时序压缩语音潜在编码。然后，这些潜在表示通过精心设计的音频到视频扩散Transformer（A2V-DiT）主干网络进行建模，以实现高效的说话人头像合成。此外，为了确保在扩展生成中的时间一致性和加速推理，我们为框架的训练和推理过程提出了一种新颖的异步噪声调度器（ANS）。ANS利用潜在空间中的异步加噪和异步运动引导生成，确保了生成视频片段的一致性。实验结果表明，READ通过生成具有竞争力的说话人头像视频，同时显著减少了运行时间，超越了现有最先进的方法，实现了质量和速度之间的最佳平衡，并在长时间生成中保持了鲁棒的度量稳定性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [966] [Neighborhood-Preserving Voronoi Treemaps](https://arxiv.org/abs/2508.03445)
> *保留邻域的Voronoi树图*

*Patrick Paetzold, Rebecca Kehlbeck, Yumeng Xue, Bin Chen, Yunhai Wang, Oliver Deussen* | **Category: cs.GR** | **Updated: 2025-08-05**

**Keywords:** Voronoi树图, 邻域保持, 数据相似性, Kuhn-Munkres匹配, 可视化

**Comment:** 

> **TL;DR:** 该研究提出了一种新的Voronoi树图算法，该算法通过考虑数据相似性来生成保留邻域的树图，通过优化单元格大小和邻域关系来提高可视化效果。

**AI_Comments:** 该研究在Voronoi树图领域取得了重要进展，通过引入邻域保持机制，解决了传统方法忽略数据相似性的问题，为复杂数据的可视化提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Voronoi树图仅能同时展示节点及其层级关系，但忽略了地理邻近性或语义相似性等数据属性。

**Method:** 该算法首先通过考虑相似性来扩展树图布局流程，然后使用Kuhn-Munkres匹配将相似性与质心Voronoi单元（CVT）进行匹配，以创建具有相同单元格大小的初始Voronoi图。通过贪婪交换来进一步优化邻域，并在保持现有邻域的同时迭代调整单元格面积。

**Result:** 通过信息图和语言学中的多个真实世界示例证明了该方法的实用性，并通过树图指标和邻域保持度量来量化评估。

**Conclusion:** 该研究提出了一种新的Voronoi树图算法，该算法能够通过考虑数据相似性来生成保留邻域的树图，从而在可视化中同时展现层级关系和数据属性，并在多个真实世界案例中得到了验证。

> **ai_Abstract:** 本研究提出了一种名为“保留邻域的Voronoi树图”的新算法，该算法通过整合数据相似性信息来改进传统的Voronoi树图。通过利用Kuhn-Munkres匹配和贪婪交换等技术，该算法能够生成同时保留数据层级结构和相似性邻域的可视化。研究人员通过实际案例和量化指标证明了该方法的有效性。

> **摘要翻译:** Voronoi树图用于同时描绘节点及其层次关系。然而，除了层次结构之外，数据属性，例如共同出现的特征或相似性，也经常存在。例如，地理属性，如国家之间的共享边界，或语境化的语义信息，如从大型语言模型派生的嵌入向量。在这项工作中，我们提出了一种利用数据相似性生成保留邻域的Voronoi树图的算法。首先，我们扩展了树图布局流程，在数据预处理过程中考虑相似性。然后，我们使用Kuhn-Munkres匹配将相似性与质心Voronoi图（CVT）单元进行匹配，为每个层级创建具有相等单元格大小的初始Voronoi图。通过贪婪交换来改进单元格的邻域，以进一步匹配数据的相似性。在优化过程中，单元格面积在保持现有邻域的同时被迭代地调整为其各自的大小。我们通过信息图和语言学中的多个真实世界示例证明了我们方法的实用性。为了定量评估生成的树图，我们采用了树图指标并测量了邻域保持度。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [155] [Approximate Proportionality in Online Fair Division](https://arxiv.org/abs/2508.03253)
> *在线公平分配中的近似比例性*

*Davin Choo, Winston Fu, Derek Khu, Tzeh Yuan Neoh, Tze-Yang Poon, Nicholas Teh* | **Category: cs.GT, cs.AI, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 在线公平分配, 比例性, PROP1, 贪婪算法, 近似算法

**Comment:** 

> **TL;DR:** 本文研究在线公平分配中“至多一件物品的比例性”（PROP1）的近似性。发现传统的贪婪算法在自适应对抗下无法保证PROP1的近似。然而，在非自适应对抗下，简单的随机分配可以实现PROP1近似；引入最大物品价值（MIV）预测的算法也能获得鲁棒的近似比。同时指出，更强的公平概念即使有完美预测也难以近似。

**AI_Comments:** 这篇论文在在线公平分配领域具有重要意义，尤其是在处理不可近似的经典公平概念后，转而关注PROP1这一更具可行性的松弛概念。其创新点在于揭示了贪婪算法在自适应对抗下的局限性，并成功地在非自适应对抗和引入辅助信息（如MIV预测）的条件下找到了实现PROP1近似的有效策略。这对于实际系统设计中平衡公平性和可行性提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 在在线公平分配问题中，经典的公平概念（如无嫉妒和最大最小份额公平）已被证明难以近似。本文关注的是“至多一件物品的比例性”（PROP1），其近似性尚未被充分研究。由于常用的贪婪算法在一般情况下无法保证PROP1的近似性，这促使研究者探索在非自适应对抗下或利用辅助信息来解决这一挑战。

**Method:** 本文首先分析了三种自然贪婪算法在面对自适应对抗时对PROP1的近似性能，并发现它们无法保证任何正近似。随后，针对非自适应对抗情况，研究了简单的均匀随机分配方法，并证明其能以高概率实现有意义的PROP1近似。此外，论文还提出了一种算法，该算法在给定最大物品价值（MIV）预测时，能够获得针对PROP1的鲁棒近似比。最后，论文也探讨了更强的公平概念（如EF1、MMS和PROPX）在有完美MIV预测下的近似性。

**Result:** 研究表明，在自适应对抗下，三种自然的贪婪算法无法保证对PROP1的任何正近似。然而，在非自适应对抗下，简单的均匀随机分配可以以高概率实现有意义的PROP1近似。在给定最大物品价值（MIV）预测时，本文提出的算法能够获得针对PROP1的鲁棒近似比。此外，即使有完美的MIV预测，EF1、MMS和PROPX等更强的公平概念仍然不可近似。

**Conclusion:** 在在线公平分配问题中，实现“至多一件物品的比例性”（PROP1）的近似是具有挑战性的。虽然传统的贪婪算法在面对自适应对抗时表现不佳，但在非自适应对抗情境下，简单的随机分配或利用辅助信息（如最大物品价值预测）可以有效地实现PROP1的近似。然而，对于更强的公平概念，即使在理想的信息条件下，近似仍然是困难的。

> **ai_Abstract:** 本文深入探讨了在线公平分配中“至多一件物品的比例性”（PROP1）的近似问题。研究发现，在面对自适应对抗时，传统的贪婪算法无法保证PROP1的近似。为克服这一难题，论文转而研究非自适应对抗情境，并提出简单的均匀随机分配方法可实现PROP1的近似。此外，本文还设计了一种算法，通过利用最大物品价值（MIV）预测，能够获得鲁棒的PROP1近似比。然而，论文也指出，即使在有完美MIV预测的情况下，更强的公平概念（如EF1、MMS、PROPX）仍然难以近似。

> **摘要翻译:** 我们研究在线公平分配问题，其中不可分割的物品按顺序到达，并且必须立即、不可撤销地分配给代理人。先前的研究已经确定了在这种情况下近似经典公平概念（例如无嫉妒和最大最小份额公平）的强大不可能结果。相比之下，我们关注的是“至多一件物品的比例性”（PROP1），这是一种自然的比例性松弛，其可近似性仍未解决。我们首先表明，在面对自适应对抗时，三种自然的贪婪算法通常无法保证对PROP1的任何正近似。这令人惊讶，因为贪婪算法在公平分配中很常用，并且已知在额外信息假设下，一种自然的贪婪算法能够实现PROP1。这一困难结果促使我们研究非自适应对抗以及利用辅助信息，这与学习增强算法的精神一致。对于非自适应对抗，我们表明简单的均匀随机分配可以以高概率实现有意义的PROP1近似。同时，我们提出了一种算法，在给定最大物品价值（MIV）预测时，能够获得针对PROP1的鲁棒近似比。有趣的是，我们还表明，即使有完美的MIV预测，EF1、MMS和PROPX等更强的公平概念仍然不可近似。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [234] [On the Parallelizability of Approval-Based Committee Rules](https://arxiv.org/abs/2501.15006)
> *基于赞同的委员会规则的可并行性*

*Zack Fitzsimmons, Zohair Raza Hassan, Edith Hemaspaandra* | **Category: cs.GT** | **Updated: 2025-08-04**

**Keywords:** 基于赞同的委员会规则, 并行性, P-hard, 均等份额法, Chamberlin-Courant

**Comment:** A version of this paper will appear in the proceedings of ECAI 2025

> **TL;DR:** 本文研究了基于赞同的委员会规则的可并行性。结果表明，许多多项式时间可计算的规则（包括均等份额法）是P-hard，因此不可并行化。然而，对于Chamberlin-Courant规则，当投票为单峰或单交叉时，可以并行化。

**AI_Comments:** 该论文的创新之处在于，它深入探讨了基于赞同的委员会规则在并行计算方面的复杂性。通过证明许多常用多项式时间算法的P-hardness，它揭示了这些规则在处理大规模数据时的内在限制。同时，识别出Chamberlin-Courant规则在特定投票结构下（单峰或单交叉）的可并行性，为未来的算法设计和实际应用提供了宝贵的指导。这对于理解和优化大规模选举中的委员会选择算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管许多基于赞同的委员会（ABC）规则在多项式时间内可计算，但对于非常大的选举而言，多项式时间仍不足够，需要并行化。因此，研究这些规则的可并行性变得必要。

**Method:** 本文通过证明这些多项式时间ABC规则（包括均等份额法）的计算是P-hard，从而证明它们无法并行化。同时，对于Chamberlin-Courant规则，通过分析在单峰或单交叉投票情况下的特性，证明了其可并行性。

**Result:** 计算赢取委员会的许多多项式时间ABC规则（包括均等份额法）是P-hard，表明它们不能并行化。相反，对于重要的ABC规则Chamberlin-Courant，当投票是单峰或单交叉时，找到赢取委员会可以并行化。

**Conclusion:** 本文得出结论，尽管许多基于赞同的委员会规则在多项式时间内可计算，但它们是P-hard，因此无法并行化。然而，对于特定的规则（如Chamberlin-Courant）和特定的投票结构（单峰或单交叉），并行化是可能的。

> **ai_Abstract:** 本文探讨了基于赞同的委员会（ABC）规则的可并行性。研究发现，尽管许多ABC规则具有多项式时间算法，但包括均等份额法在内的这些规则的赢取委员会计算是P-hard，这意味着它们无法实现并行化。然而，对于Chamberlin-Courant规则，在单峰或单交叉的投票情境下，赢取委员会的计算可以并行化。这对于处理大规模选举中的委员会选择问题具有重要意义。

> **摘要翻译:** 基于赞同的委员会（ABC）规则是当给定一组选民的偏好时，选择一组公平候选人的重要工具。尽管许多ABC规则的获胜委员会是NP-hard问题，但这些规则的自然变体存在多项式时间算法。最近引入的均等份额法（Method of Equal Shares）是一种具有理想属性的重要ABC规则，它也可以在多项式时间内计算。然而，当处理非常大的选举时，多项式时间是不够的，可能需要并行化。我们证明，使用这些多项式时间ABC规则（包括均等份额法）计算获胜委员会是P-hard，从而表明它们无法并行化。相反，我们证明，当投票对于重要的ABC规则Chamberlin-Courant是单峰或单交叉时，找到获胜委员会可以并行化。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [6] [Embracing Transparency: A Study of Open Science Practices Among Early Career HCI Researchers](https://arxiv.org/abs/2410.04286)
> *拥抱透明：一项关于HCI领域早期职业研究人员开放科学实践的研究*

*Tatiana Chakravorti, Sanjana Gautam, Sarah M. Rajtmajer* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 开放科学, HCI, 早期职业研究人员, 透明度, 可再现性

**Comment:** 

> **TL;DR:** 本研究通过对早期职业HCI研究人员的访谈，调查了他们在开放科学实践中的看法和参与度，并指出了推广透明度和开放性所面临的关键障碍和改进建议。

**AI_Comments:** 该研究通过访谈深入探讨了HCI领域开放科学实践的现状和障碍，特别是从早期职业研究人员的视角。其价值在于明确指出了推广开放科学的具体挑战，并提出了针对性的建议，对政策制定和社区规范的引导具有指导意义。然而，研究的局限性在于其地理范围仅限于美国，且数据为自我报告，可能存在偏倚，这限制了结论的普适性。未来的研究可以考虑扩大样本的多样性，以增强研究结果的普遍适用性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于已发表研究结果的可再现性和可复制性问题日益受到关注，包括人机交互（HCI）在内的许多科学领域都加强了反思。近年来，HCI社区致力于实施政策改革和普及开放科学实践，因此本研究旨在调查早期职业HCI研究人员对开放科学的看法及其在最佳实践中的参与度。

**Method:** 本研究通过对18位早期职业HCI研究人员进行半结构化访谈，调查了他们对开放科学的看法和参与最佳实践的情况。

**Result:** 研究结果揭示了数据和材料共享以及预注册广泛采用的关键障碍，包括：缺乏明确的激励机制；文化抵制；培训不足；时间限制；对知识产权的担忧；以及数据隐私问题。研究还观察到，CHI等主要会议的小幅改变可以显著影响社区规范。

**Conclusion:** 本研究为解决开放科学实践的障碍并促进HCI领域的透明度和开放性提供了建议。尽管这些发现提供了关于早期职业HCI研究人员开放科学实践的宝贵见解，但其适用性仅限于美国。未来的研究将扩大范围，纳入不同经验水平和不同国家的HCI研究人员，以提供更具说服力的例子。

> **ai_Abstract:** 本研究通过对18位早期职业HCI研究人员的半结构化访谈，探讨了他们在开放科学实践中的看法和参与度。研究发现了数据和材料共享以及预注册普及的主要障碍，包括激励不足、文化阻力、培训缺乏、时间限制、知识产权和数据隐私问题。论文提出，CHI等大型会议的微小改变能有效影响社区规范，并针对这些障碍提出了促进HCI透明度和开放性的建议。研究局限于美国样本和自我报告数据，未来工作将拓展研究范围。

> **摘要翻译:** 包括人机交互（HCI）在内的许多科学领域，在对已发表研究结果的可再现性和可复制性担忧之后，加强了自我反省。值得注意的是，近年来HCI社区致力于实施政策改革和普及开放科学实践。我们的工作通过18次半结构化访谈，调查了早期职业HCI研究人员对开放科学的看法以及他们对最佳实践的参与。我们的发现强调了数据和材料共享以及预注册广泛采用的关键障碍，即：缺乏明确的激励机制；文化抵制；培训不足；时间限制；对知识产权的担忧；以及数据隐私问题。我们观察到，CHI等主要会议的小幅改变可以显著影响社区规范。我们提出了解决这些障碍并促进HCI领域透明度和开放性的建议。尽管这些发现提供了关于早期职业HCI研究人员开放科学实践的宝贵而有趣的见解，但其适用性仅限于美国。访谈研究依赖于自我报告数据；因此，它可能受到召回偏倚等偏差的影响。未来的研究将扩大范围，纳入不同经验水平和不同国家的HCI研究人员，以提供更具说服力的例子。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [59] [The Impostor is Among Us: Can Large Language Models Capture the Complexity of Human Personas?](https://arxiv.org/abs/2501.04543)
> *冒名顶替者在我们中间：大型语言模型能否捕捉人类角色的复杂性？*

*Christopher Lazik, Christopher Katins, Charlotte Kauter, Jonas Jakob, Caroline Jay, Lars Grunske, Thomas Kosch* | **Category: cs.HC** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 用户角色, 人机交互, 设计可信度, 刻板印象

**Comment:** 

> **TL;DR:** 本研究探讨了用户如何看待LLM生成的角色与人类创建的角色在设计可信度方面的差异。结果显示，LLM生成的角色被认为信息更丰富、更一致，但也更刻板。

**AI_Comments:** 这项研究揭示了LLM在生成用户角色方面的潜力和局限性。其创新之处在于通过用户感知对比，量化了LLM生成角色与人类创建角色的差异。重要性在于其指出了LLM在角色创建中可能引入的刻板印象问题，为未来LLM辅助设计工具的开发提供了关键指导，即需要加强多样性和真实性。

<details>
  <summary>Details</summary>

**Motivation:** AI生成的角色可能无法准确代表真实用户体验，可能缺失上下文和情感洞察，这可能影响设计质量，尤其是对新手而言。因此，本文旨在比较用户对LLM生成角色和人类创建角色的感知差异。

**Method:** 研究收集了十个由HCI专家根据相关属性创建的人类角色，并系统地使用LLM生成了十个角色。随后，通过一项调查比较了这两类角色。

**Result:** 参与者能够区分人类创建和AI生成的角色。AI生成的角色被认为信息更丰富、更一致。然而，参与者也指出AI生成的角色倾向于遵循刻板印象。

**Conclusion:** 虽然LLM生成的角色在信息量和一致性方面表现良好，但在创建角色时需要更强调多样性，以避免刻板印象，从而更好地捕捉人类角色的复杂性。

> **ai_Abstract:** 本研究调查了大型语言模型（LLM）在生成用户角色方面的能力及其与人类创建角色的对比。研究发现，尽管LLM生成的角色在信息量和一致性方面表现出色，但它们也存在遵循刻板印象的倾向。这表明在利用LLM进行角色创建时，需要特别关注多样性，以确保其能准确捕捉真实用户体验的复杂性。

> **摘要翻译:** 大型语言模型（LLM）为生成角色创造了新的机会，有望简化和加速以人为中心的设计过程。然而，AI生成的角色可能无法准确代表实际用户体验，因为它们可能缺少理解真实用户需求和行为至关重要的上下文和情感洞察。这给质量带来了潜在威胁，特别是对于新手而言。本文研究了用户在设计可信度方面对LLM创建的角色与人类创建的角色的感知差异。我们收集了由HCI专家根据相关工作中确立的属性开发的十个由人类创建的角色。然后，我们系统地用LLM生成了十个角色，并在调查中将它们与人类创建的角色进行了比较。结果显示，参与者区分了人类创建和AI生成的角色，后者被认为信息更丰富、更一致。然而，参与者指出AI生成的角色倾向于遵循刻板印象，这突出表明在使用LLM创建角色时需要更加强调多样性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [124] ["It was Mentally Painful to Try and Stop": Design Opportunities for Just-in-Time Interventions for People with Obsessive-Compulsive Disorder in the Real World](https://arxiv.org/abs/2501.13308)
> *“尝试停止是精神上的痛苦”：为现实世界中强迫症患者提供即时干预的设计机会*

*Ru Wang, Kexin Zhang, Yuqing Wang, Keri Brown, Yuhang Zhao* | **Category: cs.HC, H.5.0** | **Updated: 2025-08-05**

**Keywords:** 强迫症, 即时干预, 自我管理, 设计机会, 访谈研究

**Comment:** 

> **TL;DR:** 本研究通过访谈调查了强迫症患者自我管理中的挑战和需求，并提出了针对强迫症的即时干预技术设计机会。

**AI_Comments:** 这项研究通过访谈深入了解了强迫症患者的真实需求和挑战，其创新之处在于将这些见解转化为具体的即时干预技术设计机会。这对于开发更贴合患者需求的数字健康工具具有重要指导意义，有助于弥补现有治疗与日常自我管理之间的差距。

<details>
  <summary>Details</summary>

**Motivation:** 尽管暴露与反应预防等循证疗法对强迫症有效，但由于恐惧对抗和缺乏适当支持，在日常生活中管理强迫症症状仍然充满挑战。本研究旨在更好地理解强迫症自我管理中的挑战和需求。

**Method:** 研究人员对10名患有不同强迫症的参与者和7名专门治疗强迫症的治疗师进行了访谈。通过访谈，他们探讨了参与者触发因素的特征、这些因素如何影响他们的强迫行为，并发现了在强迫症发作不同阶段的关键应对策略。

**Result:** 研究结果强调了强迫症自我管理需求与当前可用支持之间的关键差距。基于这些见解，研究提出了针对强迫症的即时自我管理技术的设计机会，包括个性化症状追踪、即时干预以及对强迫症特有隐私和社会需求的支持。

**Conclusion:** 本研究揭示了强迫症患者自我管理中的挑战和需求，并基于此提出了具体的技术设计机会，以期通过技术及其他方式提供更好的支持。

> **ai_Abstract:** 本研究旨在探讨强迫症患者在日常自我管理中面临的挑战和需求。通过对强迫症患者和治疗师的访谈，研究揭示了触发因素、强迫行为模式以及应对策略，并指出了现有支持的不足。在此基础上，文章提出了针对强迫症的即时自我管理技术的设计方向，包括个性化症状追踪、即时干预以及对隐私和社会需求的关注，以期改善患者的自我管理。

> **摘要翻译:** 强迫症 (OCD) 是一种严重影响人们生活质量的精神疾病。虽然暴露与反应预防 (ERP) 等循证疗法可能有效，但在日常生活中管理强迫症症状——作为治疗和独立生活的重要组成部分——仍然具有挑战性，这归因于对恐惧的对抗和缺乏适当的支持。为了更好地理解强迫症自我管理中的挑战和需求，我们对10名患有不同强迫症的参与者和7名专门从事强迫症治疗的治疗师进行了访谈。通过这些访谈，我们探讨了参与者触发因素的特征以及它们如何塑造他们的强迫行为，并揭示了强迫症发作不同阶段的关键应对策略。我们的研究结果强调了强迫症自我管理需求与当前可用支持之间的关键差距。基于这些见解，我们提出了针对强迫症的即时自我管理技术的设计机会，包括个性化症状追踪、即时干预以及对强迫症特定隐私和社会需求的支持——通过技术及其他方式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [162] [Classifying Epistemic Relationships in Human-AI Interaction: An Exploratory Approach](https://arxiv.org/abs/2508.03673)
> *人机交互中认知关系分类：一种探索性方法*

*Shengnan Yang, Rongqian Ma* | **Category: cs.HC, cs.AI, cs.CY** | **Updated: 2025-08-02**

**Keywords:** 人机交互, 认知关系, AI角色, 知识共建, HCI

**Comment:** 

> **TL;DR:** 本研究通过对31位学者的访谈，识别并分类了人类与AI之间五种认知关系类型，强调认知角色是动态且情境依赖的，并呼吁建立更细致的框架来理解人机如何共同构建知识。

**AI_Comments:** 本研究的创新点在于其通过实证访谈深入探讨了人类与AI之间复杂的认知关系，并首次提出了一个分类框架。它超越了传统对AI功能和角色的关注，转而审视AI如何影响甚至重塑人类作为知识贡献者的角色。研究强调了认知角色的动态性和情境依赖性，对于理解未来人机协作模式具有重要意义，并为HCI领域提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI系统在知识密集型工作中变得不可或缺，关于其功能和在人机交互中认知角色的问题随之出现。现有的人机交互研究虽然提出了各种AI角色类型，但常忽略AI如何重塑用户作为知识贡献者的角色，这促使本研究探讨用户如何与AI形成认知关系。

**Method:** 本研究基于对跨学科31位学者的访谈，开发了一个包含五部分的编码簿，并据此识别了五种认知关系类型。

**Result:** 研究识别出五种认知关系类型：工具性依赖、权变委托、协同共事、权威取代和认知回避。这些类型反映了信任、评估模式、任务和人类认知地位的差异。研究发现认知角色是动态且情境依赖的。

**Conclusion:** 研究认为应超越AI的静态隐喻，转向一个更细致的框架，以捕捉人类和AI如何共同构建知识，从而丰富人机交互对AI使用中关系和规范维度的理解。

> **ai_Abstract:** 本研究旨在探索人类与AI在知识密集型工作中的认知关系。通过对31位学者的访谈，研究识别并分类了五种认知关系类型，包括工具性依赖、权变委托、协同共事、权威取代和认知回避。研究结果表明，这些认知角色是动态且情境依赖的，并呼吁建立一个更细致的框架来理解人机如何共同构建知识，以深化人机交互领域对AI使用关系和规范维度的理解。

> **摘要翻译:** 随着人工智能系统在知识密集型工作中变得不可或缺，不仅其功能，而且其在人机交互中的认知角色也引发了问题。虽然人机交互研究提出了各种人工智能角色类型，但它常常忽视人工智能如何重塑用户作为知识贡献者的角色。本研究探讨了用户如何与人工智能形成认知关系——他们在研究和教学情境中如何评估、信任和与人工智能协作。基于对跨学科31位学者的访谈，我们开发了一个包含五部分的编码簿，并识别了五种关系类型：工具性依赖、权变委托、协同共事、权威取代和认知回避。这些反映了信任、评估模式、任务和人类认知地位的差异。我们的发现表明，认知角色是动态且情境依赖的。我们主张超越人工智能的静态隐喻，转向一个更细致的框架，以捕捉人类和人工智能如何共同构建知识，从而丰富人机交互对人工智能使用中关系和规范维度的理解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [188] [Characterizing Visual Intents for People with Low Vision through Eye Tracking](https://arxiv.org/abs/2501.14327)
> *通过眼动追踪表征低视力人群的视觉意图*

*Ru Wang, Ruijia Chen, Anqiao Erica Cai, Zhiyuan Li, Sanbrita Mondal, Yuhang Zhao* | **Category: cs.HC, H.5.0** | **Updated: 2025-08-05**

**Keywords:** 低视力, 眼动追踪, 视觉意图, 注视模式, 辅助技术

**Comment:** 

> **TL;DR:** 本研究通过眼动追踪和回顾性思考研究，深入理解低视力人群在图像观看任务中的注视行为，并建立了视觉意图分类法，为开发意图感知的辅助技术奠定基础。

**AI_Comments:** 这项研究的创新之处在于通过眼动追踪和回顾性思考相结合的方法，首次系统地表征了低视力人群的视觉意图，并构建了相应的分类法。这对于理解低视力人群的视觉挑战和需求具有重要意义，为未来开发更智能、更个性化的辅助技术提供了坚实的基础。其局限性可能在于参与者数量相对较少，以及研究结果的普适性可能受限于特定类型的图像观看任务。

<details>
  <summary>Details</summary>

**Motivation:** 低视力人群获取视觉信息至关重要但充满挑战，他们偏好使用残余视力完成日常任务。注视模式是揭示其视觉挑战和意图的重要指标，有助于启发更具适应性的视觉支持。

**Method:** 本研究采用眼动追踪和回顾性思考研究，招募了20名低视力参与者和20名视力正常对照组。参与者完成各种图像观看任务，并回放注视轨迹以反思其视觉体验。

**Result:** 研究推导出了一个包含五种视觉意图的视觉意图分类法，这些意图由参与者的注视行为表征。研究还展示了低视力与视力正常参与者之间注视行为的差异，以及视觉能力如何影响低视力参与者在不同视觉意图下的注视模式。

**Conclusion:** 研究结果强调了结合视觉能力信息、视觉上下文和眼动追踪数据在视觉意图识别中的重要性，为低视力人群开发意图感知的辅助技术奠定了基础。

> **ai_Abstract:** 本研究旨在深入理解低视力人群在图像观看任务中的视觉意图和注视行为。通过对20名低视力参与者和20名视力正常对照组进行眼动追踪和回顾性思考研究，研究者推导出了一个包含五种视觉意图的分类法，并揭示了低视力人群与视力正常人群在注视行为上的差异，以及视觉能力对注视模式的影响。研究强调了结合视觉能力、视觉上下文和眼动追踪数据进行视觉意图识别的重要性，为开发针对低视力人群的意图感知辅助技术奠定了基础。

> **摘要翻译:** 获取视觉信息对低视力人群至关重要，但由于视力低下和视野受限等视觉状况而充满挑战。然而，与盲人不同，低视力人群拥有并倾向于在日常任务中使用其功能性视力。因此，注视模式成为揭示其视觉挑战和意图的重要指标，从而激发更具适应性的视觉支持。我们旨在深入理解低视力用户在不同图像观看任务中的注视行为，表征典型的视觉意图以及不同低视力状况人群所展现的独特注视模式。我们对20名低视力参与者和20名视力正常对照组进行了使用眼动追踪的回顾性思考研究。参与者完成了各种图像观看任务，并观看其注视轨迹的回放以反思其视觉体验。基于这项研究，我们推导出了一个包含五种视觉意图的视觉意图分类法，这些意图由参与者的注视行为表征。我们展示了低视力与视力正常参与者之间注视行为的差异，以及视觉能力如何影响低视力参与者在不同视觉意图下的注视模式。我们的发现强调了将视觉能力信息、视觉上下文和眼动追踪数据相结合在视觉意图识别中的重要性，为低视力人群开发意图感知的辅助技术奠定了基础。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [252] [Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health](https://arxiv.org/abs/2502.13920)
> *探索数据驱动、理论指导型大型语言模型在个性化健康支持中的应用：以睡眠健康为例*

*Xingbo Wang, Janessa Griffith, Daniel A. Adler, Joey Castillo, Tanzeem Choudhury, Fei Wang* | **Category: cs.HC, cs.CL** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 睡眠健康, 个性化支持, 行为改变, 聊天机器人

**Comment:** Accepted to CHI Conference on Human Factors in Computing Systems (CHI
  2025). Code is available at https://github.com/xingbow/sleephealthLLM

> **TL;DR:** HealthGuru是一款由大型语言模型驱动的聊天机器人，通过数据驱动、理论指导和自适应推荐来改善睡眠健康，并在实际部署研究中显示出积极效果。

**AI_Comments:** HealthGuru的创新之处在于其结合了数据驱动、理论指导和多智能体框架，为个性化健康支持提供了新的范式。其在睡眠健康领域的应用展示了LLM在行为改变支持方面的巨大潜力，特别是在将复杂数据转化为可操作建议方面。该研究通过实际部署验证了系统的有效性，但未来需要更大规模的研究来进一步验证其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管睡眠追踪设备普及，但许多人难以将数据转化为可操作的睡眠健康改善。现有方法提供的建议往往不切实际或无法适应个体情况。

**Method:** 本文提出了HealthGuru，一个由大型语言模型驱动的聊天机器人，旨在通过数据驱动、理论指导和自适应推荐以及对话式行为改变支持来改善睡眠健康。其多智能体框架整合了可穿戴设备数据、上下文信息和一个上下文多臂老虎机模型，以提供量身定制的睡眠增强活动。通过一项为期八周、有16名参与者的实地部署研究，将HealthGuru与基线聊天机器人进行了比较。

**Result:** 研究结果显示，使用HealthGuru后，睡眠时长和活动得分等指标有所改善，响应质量更高，用户行为改变的积极性也更高。

**Conclusion:** HealthGuru在改善睡眠健康方面表现出积极效果，并且研究还指出了健康聊天机器人个性化和用户参与度方面的挑战和设计考虑。

> **ai_Abstract:** 本文介绍了HealthGuru，一个由大型语言模型驱动的聊天机器人，旨在解决用户难以将睡眠追踪数据转化为实际行动的问题。HealthGuru通过整合可穿戴设备数据、上下文信息和上下文多臂老虎机模型，提供数据驱动、理论指导和自适应的个性化睡眠健康建议。一项为期八周的实地研究表明，与基线系统相比，HealthGuru能有效改善睡眠指标、提高响应质量并增强用户改变行为的动机。

> **摘要翻译:** 尽管睡眠追踪设备普及，但许多人难以将数据转化为可操作的睡眠健康改善。现有方法通常提供数据驱动的建议，但可能不切实际，也无法适应现实生活中的限制和个体情况。我们提出了HealthGuru，一个新颖的由大型语言模型驱动的聊天机器人，旨在通过数据驱动、理论指导和自适应推荐以及对话式行为改变支持来增强睡眠健康。HealthGuru的多智能体框架整合了可穿戴设备数据、上下文信息和一个上下文多臂老虎机模型，以建议量身定制的睡眠增强活动。该系统在促进自然对话的同时，融入了数据驱动的洞察和理论行为改变技术。我们对16名参与者进行了为期八周的实地部署研究，将HealthGuru与基线聊天机器人进行了比较。结果显示，使用HealthGuru后，睡眠时长和活动得分等指标有所改善，响应质量更高，用户行为改变的积极性也更高。我们还指出了健康聊天机器人个性化和用户参与度方面的挑战和设计考虑。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [318] [NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://arxiv.org/abs/2508.02823)
> *NeuroSync：通过直接修改LLM理解实现意图感知的基于代码的问题解决*

*Wenshuo Zhang, Leixian Shen, Shuchang Xu, Jindu Wang, Jian Zhao, Huamin Qu, Linping Yuan* | **Category: cs.HC, cs.AI, cs.CL, cs.SE** | **Updated: 2025-08-05**

**Keywords:** LLM, 代码生成, 意图对齐, 人机交互, NeuroSync

**Comment:** Accepted in UIST 2025

> **TL;DR:** NeuroSync提出了一种新的LLM人机交互范式，通过可视化和编辑LLM对用户意图和编码任务的理解，解决用户意图与生成代码之间的错位问题，从而提高代码生成效率和用户体验。

**AI_Comments:** 这项工作具有重要的创新性，它直接解决了LLM在代码生成中“黑箱”理解的痛点，通过外部化和可视化LLM的内部意图-任务映射，显著提升了人机协作的透明度和控制力。这种直接修改LLM理解的范式为未来更高效、更精准的LLM辅助编程工具奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前对话式LLM在帮助编程经验有限的用户解决领域问题时，常出现用户意图与生成代码不匹配的问题，导致用户沮丧并需要反复澄清。这种错位源于用户意图和编码任务都是非线性的，但必须通过线性的提示和代码序列来表达和解释，存在双向模糊性。

**Method:** 提出了一种新的“直接意图-任务匹配”人机交互范式，外部化并允许直接操作LLM在代码生成前推断出的编码任务及其关系。作为概念验证，该范式在NeuroSync中实现。NeuroSync采用知识蒸馏管道来提取LLM理解、用户意图及其映射，并通过可视化方式让用户直观地检查和编辑这些信息，从而增强对齐。

**Result:** 技术实验和用户研究（N=12）结果表明，NeuroSync增强了意图-任务对齐，降低了认知负荷，并提高了编码效率。

**Conclusion:** NeuroSync通过引入直接意图-任务匹配范式，有效解决了用户意图与LLM生成代码之间的错位问题，显著提升了用户体验和编码效率。

> **ai_Abstract:** NeuroSync提出了一种新的LLM人机交互范式，旨在解决用户意图与LLM生成代码之间的错位问题。该研究首先指出问题根源在于用户意图和编码任务的非线性与线性表达之间的双向模糊性。为解决此问题，NeuroSync引入“直接意图-任务匹配”机制，通过知识蒸馏提取LLM对编码任务和用户意图的理解，并允许用户通过可视化界面直接检查和编辑这些内部理解。实验证明，该方法能有效提升意图-任务对齐度，降低用户认知负担，并提高编程效率。

> **摘要翻译:** 对话式大型语言模型（LLMs）已被编程经验有限的领域用户广泛采用来解决领域问题。然而，这些用户经常面临其意图与生成代码之间的错位，导致沮丧和反复澄清。这项工作首先调查了这种错位的原因，其归因于双向模糊性：用户意图和编码任务本质上都是非线性的，但必须通过线性的提示和代码序列来表达和解释。为了解决这个问题，我们提出了直接意图-任务匹配，这是一种新的人机LLM交互范式，它将LLM的理解（即LLM在代码生成之前推断出的编码任务及其关系）外部化并允许直接操作。作为概念验证，该范式随后在NeuroSync中实现，该系统采用知识蒸馏管道来提取LLM理解、用户意图及其映射，并通过可视化方式让用户直观地检查和编辑它们，从而增强对齐。我们通过技术实验评估了NeuroSync的算法组件，并通过用户研究（N=12）评估了其整体可用性和有效性。结果表明，它增强了意图-任务对齐，降低了认知负荷，并提高了编码效率。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [321] [MERba: Multi-Receptive Field MambaVision for Micro-Expression Recognition](https://arxiv.org/abs/2506.14468)
> *MERba：用于微表情识别的多感受野MambaVision*

*Xinglong Mao, Shifeng Liu, Sirui Zhao, Tong Xu, Hanchao Wang, Baozhi Jia, Enhong Chen* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 微表情识别, MambaVision, 多感受野, 局部-全局特征整合, 双粒度分类

**Comment:** 

> **TL;DR:** MERba提出了一种分层多感受野MambaVision架构，通过局部-全局特征整合和双粒度分类模块，显著提高了微表情识别的性能。

**AI_Comments:** 该论文的创新点在于结合了MambaVision与多感受野架构，并通过独特的局部-全局特征整合策略来同时捕捉微表情的局部细节和全局上下文。双粒度分类模块的引入有效地解决了负面微表情高类间相似性的难题，显示了其在处理细微情感线索方面的强大潜力。这对于心理学、安全等领域具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的微表情识别（MER）方法难以同时捕获局部肌肉激活和全局面部依赖性，而这两者对于解码细微情绪线索至关重要。微表情作为短暂、非自主的面部动作，揭示真实情感，对心理评估和刑事调查具有重要价值。

**Method:** 本文提出了MERba，一种专为微表情识别设计的分层多感受野架构。它包含一系列局部-全局特征整合阶段。在每个阶段中，MERba局部提取器利用MambaVision Mixer和定制的非对称多扫描策略来捕获详细的窗口内运动模式，以增强局部空间敏感性。这些局部特征通过轻量级自注意力层聚合，明确建模窗口间关系，从而有效构建全局上下文。此外，为减轻负面微表情之间高类间相似性的挑战，引入了双粒度分类模块，将识别任务分解为粗到细的范式。

**Result:** 在三个基准数据集上的大量实验表明，MERba持续优于现有方法，并且消融研究证实了每个提出组件的有效性。

**Conclusion:** MERba通过其多感受野架构、局部-全局特征整合以及双粒度分类模块，有效解决了微表情识别中的挑战，并取得了优异的性能。

> **ai_Abstract:** 本文提出了MERba，一种用于微表情识别的分层多感受野架构。该模型通过局部-全局特征整合阶段，利用MambaVision Mixers增强局部空间敏感性，并通过自注意力层构建全局上下文。为应对负面微表情的类间相似性问题，引入了双粒度分类模块。实验证明MERba在多个基准数据集上均优于现有方法。

> **摘要翻译:** 微表情（MEs）是短暂、非自主的面部动作，能揭示真实情感，为心理评估和刑事调查提供有价值的见解。尽管自动微表情识别（MER）取得了显著进展，但现有方法仍然难以同时捕获局部肌肉激活和全局面部依赖性，而这两者对于解码细微情绪线索都至关重要。为了解决这一挑战，我们提出了MERba，一种专为MER设计的分层多感受野架构，它集成了一系列局部-全局特征整合阶段。在每个阶段中，MERba局部提取器通过集成MambaVision Mixer和定制的非对称多扫描策略来捕获详细的窗口内运动模式，以增强局部空间敏感性。这些局部特征随后通过轻量级自注意力层进行聚合，明确建模窗口间关系，从而有效构建全局上下文。此外，为了减轻负面微表情之间高类间相似性的挑战，我们引入了一个双粒度分类模块，将识别任务分解为粗到细的范式。在三个基准数据集上的大量实验表明，MERba持续优于现有方法，并且消融研究证实了每个提出组件的有效性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [346] [LLM Agent-Based Simulation of Student Activities and Mental Health Using Smartphone Sensing Data](https://arxiv.org/abs/2508.02679)
> *基于大型语言模型智能体模拟学生活动与心理健康：利用智能手机感知数据*

*Wayupuk Sommuang, Kun Kerdthaisong, Pasin Buakhaw, Aslan B. Wong, Nutchanon Yongsatianchot* | **Category: cs.HC** | **Updated: 2025-07-17**

**Keywords:** LLM agent, simulation, student mental health, smartphone sensing data, behavioral modeling

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于大型语言模型智能体的框架，利用智能手机感知数据模拟学生活动和心理健康，以探索新情景并进行干预研究。

**AI_Comments:** 这篇论文通过将大型语言模型智能体与真实世界智能手机感知数据相结合，提出了一种创新的方法来模拟复杂的人类行为和心理状态。其新颖之处在于超越了简单的数据复制，能够探索假设情景和干预策略，这是迈向主动心理健康支持的重要一步。能够进行“假设”情景分析和与智能体进行假设性访谈，为行为科学和公共卫生提供了强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 学生心理健康对学业成功至关重要，而日常活动对其有影响。现有移动感知数据通过统计和机器学习分析揭示了这种复杂联系，但可能无法探索新情景或进行干预研究。

**Method:** 本文提出了一种新颖的基于大型语言模型（LLM）智能体的模拟框架，利用StudentLife数据集模拟学生活动和心理健康。每个LLM智能体都通过个性问卷初始化，并在模拟学期中由智能手机感知数据引导。智能体能够预测个体行为，通过生态瞬时评估（EMA）提供自我报告的心理健康数据，并完成后续个性问卷。为确保准确性，研究探索了多种提示技术、记忆系统和基于活动的心理状态管理策略，这些策略能根据智能体的日常活动动态更新其心理状态。

**Result:** 该模拟超越了简单地复制现有数据，能够探索原始数据集中不存在的新情景，例如通过智能体间互动模拟同伴影响以及社交媒体的影响。此外，研究可以通过操纵感知信号的活动模式和问卷响应的个性特征来进行干预研究，从而为改善学生福祉的行为改变提供宝贵见解。该框架还支持对LLM智能体进行假设性访谈，以深入了解其心理健康。

**Conclusion:** 这项研究展示了LLM驱动的行为建模结合感知数据的强大能力，为理解和支持学生心理健康开辟了新途径。

> **ai_Abstract:** 本文提出了一种基于大型语言模型（LLM）智能体的模拟框架，利用智能手机感知数据和StudentLife数据集来建模学生活动和心理健康。智能体通过个性数据初始化并由感知数据引导，能够预测行为，通过生态瞬时评估报告心理健康，并根据活动动态调整其心理状态。该框架能够探索原始数据集中不存在的新情景（如同伴影响和社交媒体影响），通过操纵活动模式进行干预研究，以及对LLM智能体进行假设性访谈。这项研究展示了LLM驱动的行为建模结合感知数据在理解和支持学生心理健康方面的强大潜力。

> **摘要翻译:** 学生心理健康对学业成功至关重要，学习、社交和睡眠等活动在其中发挥着作用。当前的移动感知数据通过统计和机器学习分析，突出了这种错综复杂的联系。我们提出了一个新颖的基于大型语言模型（LLM）智能体的模拟框架，利用StudentLife数据集来建模学生活动和心理健康。每个LLM智能体都通过个性问卷初始化，并在整个模拟学期中由智能手机感知数据引导。这些智能体能够预测个体行为，通过生态瞬时评估（EMA）提供自我报告的心理健康数据，并完成后续个性问卷。为了确保准确性，我们研究了各种提示技术、记忆系统以及基于活动的心理状态管理策略，这些策略能够根据智能体的日常活动动态更新其心理状态。这项模拟超越了简单地复制现有数据。它使我们能够探索原始数据集中不存在的新情景，例如通过智能体间互动模拟同伴影响以及社交媒体的影响。此外，我们还可以通过感知信号操纵活动模式和利用问卷响应操纵个性特征来进行干预研究。这为可能增强学生福祉的行为改变提供了宝贵的见解。该框架还促进了对LLM智能体的假设性访谈，从而更深入地了解其心理健康。这项研究展示了LLM驱动的行为建模结合感知数据的强大能力，为理解和支持学生心理健康开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [368] ["It looks sexy but it's wrong." Tensions in creativity and accuracy using genAI for biomedical visualization](https://arxiv.org/abs/2507.14494)
> *“看起来很性感，但却是错的。”生成式AI用于生物医学可视化中创造性与准确性之间的张力*

*Roxanne Ziman, Shehryar Saharan, Gaël McGill, Laura Garrison* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 生成式AI, 生物医学可视化, 准确性, 创造性, 人工干预

**Comment:** 11 pages, 3 figures. Accepted to IEEE VIS 2025 Conference

> **TL;DR:** 本文深入分析了生成式AI在生物医学可视化中的应用所带来的工作流程和张力，发现尽管生成式AI能产生美观的视觉效果，但其固有限制导致信息不准确。通过对17位专家的访谈，研究揭示了专家们对生成式AI的态度各异，并强调了在科学传播中人工干预以确保准确性的必要性。

**AI_Comments:** 本文创新性地探讨了生成式AI在生物医学可视化领域中的应用，揭示了其在美学表现和科学准确性之间存在的固有张力。研究通过定性访谈提供了丰富的实证数据，深入分析了从业者的实际工作流程和态度，这对于理解生成式AI在专业领域的落地具有重要意义。其重要性在于，在生成式AI技术快速发展并被广泛应用的当下，本文提醒了科学传播和可视化领域应警惕盲目追求“性感”视觉效果而牺牲“正确性”的风险，强调了人类专家在保障信息准确性和可信度方面的不可替代性。研究的局限性可能在于其定性研究的性质，样本量相对较小，可能无法完全代表所有生物医学可视化从业者的观点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI能够便捷地生成生物医学内容的美学视觉效果，但这些工具的架构从根本上限制了所描绘信息的准确性和可信度。在当前公众对科学的信任面临危机之际，研究旨在深入分析生成式AI在生物医学可视化中的应用所产生的工作流程和张力。

**Method:** 研究通过对17位来自不同背景的生物医学可视化从业者和研究人员进行访谈，定性分析了驱动生成式AI在空间导向生物医学数据视觉表示中（不）使用的担忧和价值观。

**Result:** 研究发现，生物医学可视化专家（包括开发者和设计师）在日常工作流程的不同阶段使用生成式AI工具，并且对生成式AI的态度从热情的采纳者到怀疑的规避者不等。研究对比了当前观察到的生成式AI使用情况和先前工作中对可视化管道中生成式AI的预测。

**Conclusion:** 研究结果重申了在生物医学可视化乃至更广泛的科学传播中，人工干预对于实现共情设计和评估准确科学视觉效果的必要性。在科学信任受损的时代，提醒我们首先要做到“不伤害”。

> **ai_Abstract:** 本文深入探讨了生成式AI在生物医学可视化中的应用所带来的挑战，特别关注其在创造美观视觉效果的同时，可能导致信息不准确和不可信的问题。通过对17位专家的访谈，研究揭示了生物医学可视化专家对生成式AI的态度多样，从积极采用到谨慎规避。研究强调了在科学传播中，尤其是在生物医学可视化领域，人工干预对于确保科学视觉内容准确性和可信度的重要性。

> **摘要翻译:** 我们深入分析了生成式AI（genAI）在生物医学可视化（BioMedVis）中使用所产生的工作流程和张力。尽管生成式AI能够便捷地生成生物学和医学内容的美学视觉效果，但这些工具的架构从根本上限制了所描绘信息的准确性和可信度，从想象的（或奇特的）分子到异形解剖结构。通过对17位不同背景的从业者和研究人员进行访谈，我们定性分析了驱动生成式AI在空间导向生物医学数据视觉表示中（不）使用的担忧和价值观。我们发现，生物医学可视化专家，无论是作为开发者还是设计师，在日常工作流程的不同阶段使用生成式AI工具，并且对生成式AI的态度从热情的采纳者到怀疑的规避者不等。通过对比我们研究中观察到的生成式AI当前使用情况和观点与先前工作中对可视化管道中生成式AI的预测，我们将关于生成式AI对可视化项目影响的讨论重新聚焦于当下及其对未来可视化研究的机遇和陷阱。在公众对科学的信任面临危机之际，我们被提醒首先要做到“不伤害”，这不仅适用于生物医学可视化，也适用于更广泛的科学传播。我们的观察重申了人工干预对于实现共情设计和评估准确科学视觉效果的必要性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [374] [VRSight: An AI-Driven Scene Description System to Improve Virtual Reality Accessibility for Blind People](https://arxiv.org/abs/2508.02958)
> *VRSight：一个由AI驱动的场景描述系统，旨在改善盲人使用虚拟现实的无障碍性*

*Daniel Killough, Justin Feng, Zheng Xue "ZX" Ching, Daniel Wang, Rithvik Dyava, Yapeng Tian, Yuhang Zhao* | **Category: cs.HC** | **Updated: 2025-08-04**

**Keywords:** 虚拟现实可访问性, AI驱动系统, 盲人, 场景描述, 空间音频

**Comment:** 17 pages, 10 figures, 2 tables, LaTeX; To be published in ACM's 2025
  Symposium on User Interface Software and Technology (UIST 2025)

> **TL;DR:** VRSight是一个AI驱动的端到端系统，通过识别VR场景并生成空间音频反馈，使盲人用户无需开发者干预即可在VR中进行交互。

**AI_Comments:** 该论文的创新之处在于提出了一个端到端的AI驱动系统VRSight，它无需开发者额外介入即可为盲人提供VR场景描述。通过结合多种AI技术和创建专门的VR数据集DISCOVR，该研究有效解决了现有VR无障碍方案需要大量开发者投入的痛点，为改善VR对残障人士的可访问性提供了重要的实践路径。其无需开发者干预的特性对于推广VR无障碍应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实（VR）对盲人来说是无法访问的。尽管现有研究探索了许多增强VR可访问性的技术，但它们通常需要额外的开发者投入才能集成，导致大多数主流VR应用由于行业对可访问性重视不足而依然无法使用。

**Method:** 论文提出了VRSight，一个端到端系统，通过一系列AI模型（如目标检测、深度估计、基于LLM的氛围解释）事后识别VR场景，并生成基于音调的空间音频反馈，从而使盲人用户无需开发者干预即可在VR中交互。为了实现虚拟元素检测，该研究还贡献了DISCOVR数据集，一个包含来自17个社交VR应用的30种虚拟对象类别的VR数据集，以替代不适用于VR上下文的真实世界数据集。

**Result:** 九名参与者使用VRSight探索了一个现成的VR应用（Rec Room），结果表明该系统在促进社交任务（如头像感知和可用座位识别）方面是有效的。

**Conclusion:** VRSight通过AI驱动的场景描述和空间音频反馈，显著提高了盲人用户对VR的无障碍访问，且无需额外的开发者投入，证明了其在改善VR可访问性方面的有效性。

> **ai_Abstract:** 本文介绍了VRSight，一个端到端的AI驱动系统，旨在解决盲人使用虚拟现实（VR）的无障碍性问题。该系统利用目标检测、深度估计和大型语言模型等AI模型识别VR场景，并生成基于音调的空间音频反馈，从而使盲人用户无需开发者干预即可在VR中进行交互。为支持虚拟元素检测，研究还构建了DISCOVR数据集。用户研究表明，VRSight能有效帮助盲人用户在VR社交应用中完成如头像识别和座位查找等任务。

> **摘要翻译:** 虚拟现实（VR）对盲人来说是无法访问的。尽管研究已经调查了许多增强VR可访问性的技术，但它们需要额外的开发者投入才能集成。因此，由于行业对可访问性重视不足，大多数主流VR应用仍然无法访问。我们提出了VRSight，一个端到端系统，它通过一套AI模型（例如，目标检测、深度估计、基于LLM的氛围解释）事后识别VR场景，并生成基于音调的空间音频反馈，使盲人用户无需开发者干预即可在VR中进行交互。为了实现虚拟元素检测，我们进一步贡献了DISCOVR，一个VR数据集，包含来自17个社交VR应用的30个虚拟对象类别，取代了不适用于VR上下文的真实世界数据集。九名参与者使用VRSight探索了一个现成的VR应用（Rec Room），展示了其在促进社交任务（如头像感知和可用座位识别）方面的有效性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [402] [Survey of Large Language Models in Extended Reality: Technical Paradigms and Application Frontiers](https://arxiv.org/abs/2508.03014)
> *扩展现实中大型语言模型的综述：技术范式与应用前沿*

*Jingyan Wang, Yang Zhao, Haotian Mao, Xubo Yang* | **Category: cs.HC, I.2, H.5** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 扩展现实, 技术范式, 应用前沿, 综述

**Comment:** 29 pages, 5 tables

> **TL;DR:** 本综述全面回顾了大型语言模型（LLMs）与扩展现实（XR）的交叉领域，提出了LLM增强XR系统的技术范式分类，并探讨了LLM驱动技术在XR应用中的支持作用，旨在为研究人员提供指导。

**AI_Comments:** 这是一篇重要的综述文章，它系统地梳理了大型语言模型在扩展现实领域的应用现状和未来方向。其创新之处在于提出了一个清晰的技术范式分类，并将其与实际应用场景相结合，为该交叉领域的研究和开发提供了宝贵的路线图。对于新兴的LLM-XR领域，这种全面的梳理工作具有重要的指导意义和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言理解和生成方面展现出卓越能力，其与扩展现实（XR）的结合有望改变用户与沉浸式环境的交互方式。本综述旨在全面回顾LLMs与XR交叉领域的最新进展，并为研究人员和从业者提供指导，以推进智能XR体验的最新技术水平。

**Method:** 本综述对LLMs与XR交叉领域的最新发展进行了全面审查。它沿着技术和应用维度对研究进行了结构化组织。论文提出了一种以关键技术范式（如交互式智能体控制、XR开发工具包和生成式场景合成）为中心的LLM增强XR系统分类法，并探讨了这些范式如何实现XR中的新能力。同时，它研究了LLM驱动技术如何支持沉浸式教育、临床医疗保健和工业制造等不同领域的实际XR应用。

**Result:** 本综述提出了LLM增强XR系统的技术范式分类，包括交互式智能体控制、XR开发工具包和生成式场景合成。它还探讨了LLM驱动技术在沉浸式教育、临床医疗保健和工业制造等领域对实际XR应用的支持。通过连接这些技术范式与应用前沿，本综述强调了当前趋势，描绘了设计考量，并指出了构建LLM增强XR系统中的开放挑战。

**Conclusion:** 本工作提供了见解，可以指导研究人员和从业者推进智能XR体验的最新技术水平。

> **ai_Abstract:** 本综述探讨了大型语言模型（LLMs）与扩展现实（XR）的融合，旨在改变用户与沉浸式环境的交互方式。论文提出了LLM增强XR系统的技术范式分类，涵盖交互式智能体控制、XR开发工具包和生成式场景合成，并阐述了这些范式如何赋能XR新能力。此外，综述分析了LLM驱动技术在沉浸式教育、医疗保健和工业制造等XR应用领域的支持作用。通过连接技术范式与应用前沿，本综述揭示了当前趋势、设计考量及未来挑战，为智能XR体验的研究与实践提供了指导。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言理解和生成方面展现出卓越能力，其与扩展现实（XR）的结合有望改变用户与沉浸式环境的交互方式。本综述全面回顾了LLMs与XR交叉领域的最新进展，并沿着技术和应用维度提供了结构化的研究组织。我们提出了一种以关键技术范式——如交互式智能体控制、XR开发工具包和生成式场景合成——为中心的LLM增强XR系统分类法，并讨论了这些范式如何实现XR中的新能力。同时，我们研究了LLM驱动技术如何支持沉浸式教育、临床医疗保健和工业制造等不同领域的实际XR应用。通过连接这些技术范式与应用前沿，本综述强调了当前趋势，描绘了设计考量，并指出了构建LLM增强XR系统中的开放挑战。本工作提供了见解，可以指导研究人员和从业者推进智能XR体验的最新技术水平。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [424] [Using Tactile Charts to Support Comprehension and Learning of Complex Visualizations for Blind and Low-Vision Individuals](https://arxiv.org/abs/2507.21462)
> *使用触觉图表支持盲人和低视力个体理解和学习复杂可视化*

*Tingying He, Maggie McCracken, Daniel Hajas, Sarah Creem-Regehr, Alexander Lex* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 触觉图表, 盲人和低视力, 复杂可视化, 心智模型, 数据可访问性

**Comment:** 

> **TL;DR:** 本研究探讨触觉图表是否能帮助盲人和低视力个体理解和学习复杂可视化，并发现触觉模型能有效支持图表类型理解，是他们偏好的学习方法。

**AI_Comments:** 这项研究的创新在于将触觉图表应用于更复杂的科学可视化类型，而非仅限于简单图表，这对于扩大BLV个体获取高级数据信息的能力至关重要。其重要性体现在为BLV教育和辅助技术提供了实证支持，证明了触觉学习的有效性。研究方法严谨，结合了设计实践和用户研究，但由于访谈研究的性质，样本量相对较小，可能需要进一步的大规模研究来验证其普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 盲人和低视力（BLV）个体主要依赖替代文本获取数据可视化信息，但他们缺乏建立图表类型心智模型的方法，这对于解释描述至关重要。现有研究多集中于简单图表，不清楚触觉表示是否适用于科学出版物中更复杂的图表。

**Method:** 研究设计了四种3D打印的触觉模板图表（UpSet图、小提琴图、聚类热图和分面折线图），并与两名BLV研究人员合作。随后，对12名BLV参与者进行了一项访谈研究，比较使用触觉模板是否能改善图表的心智模型和理解，以及这种理解是否能转化为通过替代文本体验的新数据集。

**Result:** 主题分析表明，触觉模型支持图表类型理解，并且是BLV个体偏好的学习方法。研究还报告了参与者对触觉图表设计及其在BLV教育中作用的看法。

**Conclusion:** 触觉图表能够有效支持盲人和低视力个体理解和学习复杂可视化，帮助他们建立图表类型的心智模型。

> **ai_Abstract:** 本研究旨在探究触觉图表如何帮助盲人和低视力（BLV）个体理解和学习复杂的科学可视化。针对BLV个体难以建立复杂图表心智模型的问题，研究设计了四种3D打印的触觉模板图表，并对12名BLV参与者进行了访谈研究。结果表明，触觉模型能有效支持BLV个体对图表类型的理解，并成为他们偏好的学习方法。该研究还收集了参与者对触觉图表设计及其在BLV教育中作用的反馈，强调了触觉图表在弥合BLV个体访问复杂数据可视化方面的潜力。

> **摘要翻译:** 我们研究了触觉图表是否支持盲人和低视力（BLV）个体理解和学习复杂可视化，并贡献了四种触觉图表设计和一项访谈研究。可视化是传递数据的强大工具，但BLV个体通常只能依赖辅助技术——主要是替代文本——来获取这些信息。先前的研究表明，图表类型的心智模型对于解释这些描述非常重要，但BLV个体无法通过可视化图像建立这样的心智模型。触觉图表有望弥补这一空白，支持心智模型的构建过程。然而，关于触觉数据表示的研究大多集中于简单的图表类型，目前尚不清楚它们是否也适用于科学出版物中可能出现的更复杂的图表。我们与两名BLV研究人员合作，为四种高级图表类型（UpSet图、小提琴图、聚类热图和分面折线图）设计了带有探索说明的3D打印触觉模板图表。然后，我们对12名BLV参与者进行了一项访谈研究，比较使用我们的触觉模板是否能改善图表的心智模型和理解，以及这种理解是否能转化为通过替代文本体验的新数据集。主题分析表明，触觉模型支持图表类型理解，并且是BLV个体偏好的学习方法。我们还报告了参与者对触觉图表设计及其在BLV教育中作用的看法。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [428] [Real-World Receptivity to Adaptive Mental Health Interventions: Findings from an In-the-Wild Study](https://arxiv.org/abs/2508.02817)
> *现实世界中对自适应心理健康干预的接受度：一项“野外”研究的发现*

*Nilesh Kumar Sahu, Aditya Sneh, Snehil Gupta, Haroon R Lone* | **Category: cs.HC, cs.AI, cs.CY, eess.SP** | **Updated: 2025-07-10**

**Keywords:** 自适应干预, 心理健康, 接受度, 移动健康, 强化学习

**Comment:** 

> **TL;DR:** 本研究通过一项为期两周的“野外”研究，调查了用户对自适应心理健康干预的接受度，发现被动感知数据显著影响用户接受度，并为设计情境感知、可操作的干预措施提供了见解。

**AI_Comments:** 这项研究的创新之处在于其“野外”研究设计，这使得研究结果更具现实世界适用性。它填补了现有研究在理解用户对实际心理健康干预的“接受度”方面的空白，而不仅仅是关注干预时机。采用强化学习算法（汤普森采样）来优化干预交付，也体现了技术应用的前瞻性。研究强调了被动感知数据在预测用户接受度方面的重要性，这对于未来开发更智能、更个性化的mHealth工具具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的研究已经探讨了情境如何影响用户对通用通知和mHealth消息的反应，但很少有工作探索其对实际心理健康干预参与的影响。此外，现有研究多关注何时用户可能受益于干预，而较少关注理解接受度（即用户参与和执行干预的意愿和能力）。

**Method:** 本研究通过一项为期两周的“野外”研究，招募了70名学生，使用定制的Android应用程序LogMe。该应用程序收集被动传感器数据和主动情境报告，以触发心理健康干预。自适应干预模块采用汤普森采样（一种强化学习算法）构建。研究探讨了智能手机特征和自报告情境与接受度和可行性之间的关系，并检验了自适应强化学习方法是否能通过最大化组合接受度奖励来优化干预交付。

**Result:** 结果显示，几种类型的被动感知数据显著影响了用户对干预的接受度。

**Conclusion:** 本研究的发现为设计在现实世界环境中不仅及时而且可操作的情境感知、自适应干预提供了见解。

> **ai_Abstract:** 本研究旨在探讨在现实世界中用户对自适应心理健康干预的接受度。通过一项为期两周、涉及70名学生的“野外”研究，研究团队使用定制的Android应用LogMe收集被动感知数据和主动情境报告，并利用汤普森采样构建自适应干预模块。研究聚焦于智能手机特征和自报告情境如何影响用户的“接受”（参与提示）和“可行性”（采取行动的能力）。结果表明，多种被动感知数据显著影响了用户对干预的接受度，为设计更具情境感知和可操作性的自适应心理健康干预提供了重要见解。

> **摘要翻译:** 移动健康（mHealth）技术的兴起使得利用被动感知的智能手机数据对心理健康状况进行实时监测和干预成为可能。基于这些能力，即时自适应干预（JITAIs）旨在在适当的时机提供个性化支持，以适应用户不断变化的情境和需求。尽管先前的研究已经探讨了情境如何影响用户对通用通知和一般mHealth消息的反应，但相对较少的工作探索了其对实际心理健康干预参与的影响。此外，虽然现有研究大多关注于检测用户何时可能从干预中受益，但较少关注理解接受度，即用户参与和执行干预的意愿和能力。
在本研究中，我们通过两个组成部分调查了用户接受度：接受（承认或参与提示）和可行性（在情境限制下采取行动的能力）。我们对70名学生进行了一项为期两周的“野外”研究，使用了定制的Android应用程序LogMe，该程序收集被动传感器数据和主动情境报告以提示心理健康干预。自适应干预模块采用汤普森采样（一种强化学习算法）构建。我们解决了四个研究问题，这些问题涉及智能手机特征和自报告情境与接受度和可行性之间的关系，并检验了自适应强化学习方法是否能通过最大化组合接受度奖励来优化干预交付。我们的结果显示，几种类型的被动感知数据显著影响了用户对干预的接受度。我们的发现为设计在现实世界环境中不仅及时而且可操作的情境感知、自适应干预提供了见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [430] [Facilitating Visual Media Exploration for Blind and Low Vision Users through AI-Powered Interactive Storytelling](https://arxiv.org/abs/2508.03061)
> *通过人工智能驱动的交互式叙事促进盲人和低视力用户探索视觉媒体*

*Shuchang Xu* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 盲人和低视力用户, 视觉媒体探索, AI驱动叙事, 交互式叙事, 辅助技术

**Comment:** 

> **TL;DR:** AI驱动的交互式叙事帮助盲人和低视力用户无缝探索视觉媒体，提升其视觉媒体探索体验。

**AI_Comments:** 这篇论文的创新点在于提出了“AI驱动的交互式叙事”这一新颖范式，解决了盲人和低视力用户在探索视觉媒体时叙事中断和认知负荷过高的问题。通过整合探索与叙事，显著提升了用户体验和参与度，对于辅助技术领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有工具将视觉媒体探索与主叙事分离，这会打断叙事流程，增加认知负荷，并限制对视觉媒体的深度参与。为了解决这些挑战，本研究旨在引入一种新的范式，平衡用户自主性与叙事连贯性。

**Method:** 本研究引入了AI驱动的交互式叙事范式，利用AI生成交互式叙事，使盲人和低视力用户能够在连贯的叙事体验中探索视觉媒体。具体通过三种技术实现：1) 分层叙事，支持不同细节级别的照片集探索；2) 并行叙事，提供时间同步视频评论的无缝访问；3) 分支叙事，实现360度视频的沉浸式导航。

**Result:** 这些技术共同证明，AI驱动的交互式叙事可以在不同媒体格式中有效平衡用户自主性和叙事连贯性。

**Conclusion:** AI驱动的交互式叙事范式能够有效帮助盲人和低视力用户在保持叙事连贯性的同时，更好地探索视觉媒体。未来的工作将进一步实现更个性化和富有表现力的叙事体验。

> **ai_Abstract:** 本研究提出一种AI驱动的交互式叙事范式，旨在帮助盲人和低视力用户在不中断叙事流的情况下探索视觉媒体。通过分层叙事、并行叙事和分支叙事三种技术，该范式有效解决了现有工具的局限性，实现了用户自主性与叙事连贯性之间的平衡，从而提升了盲人和低视力用户对视觉内容的理解和参与度。

> **摘要翻译:** 赋能盲人和低视力（BLV）用户探索视觉媒体，可以提高内容理解、增强用户自主性并满足多样化的信息需求。然而，大多数现有工具将探索与主叙事分离，这会打断叙事流程，增加认知负荷，并限制对视觉媒体的深度参与。为了解决这些挑战，我的博士研究引入了人工智能驱动的交互式叙事范式，该范式利用人工智能生成交互式叙事，使BLV用户能够在连贯的叙事体验中探索视觉媒体。我通过三种技术实现了这一范式：（1）分层叙事，支持不同细节级别的照片集探索；（2）并行叙事，提供时间同步视频评论的无缝访问；（3）分支叙事，实现360度视频的沉浸式导航。总的来说，这些技术表明，人工智能驱动的交互式叙事可以在不同媒体格式中有效平衡用户自主性和叙事连贯性。我未来的工作将通过为BLV受众提供更个性化和富有表现力的叙事体验来推进这一范式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [458] [StoryEnsemble: Enabling Dynamic Exploration & Iteration in the Design Process with AI and Forward-Backward Propagation](https://arxiv.org/abs/2508.03182)
> *StoryEnsemble：利用AI和前向-后向传播在设计过程中实现动态探索与迭代*

*Sangho Suh, Michael Lai, Kevin Pu, Steven P. Dow, Tovi Grossman* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 设计过程, AI, 迭代, 探索, StoryEnsemble

**Comment:** 

> **TL;DR:** StoryEnsemble是一个结合AI和前向-后向传播的工具，旨在帮助设计师在受限条件下进行更动态、多方向的探索和迭代设计。

**AI_Comments:** 该论文通过引入一个结合AI和前向-后向传播的工具StoryEnsemble，创新性地解决了设计过程中迭代和探索的实际挑战。其重要性在于提供了一种新的交互范式，使设计过程更加动态和高效，有助于提升设计师的工作效率和设计质量。

<details>
  <summary>Details</summary>

**Motivation:** 设计过程中的时间与资源限制阻碍了设计师进行广泛探索、收集反馈和重新审视早期假设，导致难以实践核心设计原则。

**Method:** 研究者首先对15名UX从业者、学生和教师进行了形成性研究以理解挑战。基于研究发现，开发了StoryEnsemble工具，该工具将AI集成到节点-链接界面中，并利用前向和后向传播支持设计过程中的动态探索和迭代。

**Result:** 对10名参与者的用户研究表明，StoryEnsemble能够实现快速、多方向的迭代以及设计阶段间的灵活导航。

**Conclusion:** 这项工作通过引入新颖的交互方式，使探索和迭代更加流畅、可访问和引人入胜，从而增进了我们对AI如何促进更迭代设计实践的理解。

> **ai_Abstract:** 本文介绍了StoryEnsemble，一个结合AI和前向-后向传播的工具，旨在解决设计过程中因时间和资源限制导致的探索和迭代不足的问题。通过对UX从业者的形成性研究，该工具被开发出来，并在用户研究中展示了其在实现快速、多方向迭代和灵活导航方面的有效性，从而促进了更流畅、可访问和引人入胜的迭代设计实践。

> **摘要翻译:** 设计过程涉及探索、迭代以及在诸如角色创建、问题界定、解决方案构思和原型制作等相互关联的阶段之间的移动。然而，时间和资源的限制常常阻碍设计师进行广泛探索、收集反馈和重新审视早期假设——这使得在实践中难以坚持核心设计原则。为了更好地理解这些挑战，我们对15名参与者（包括用户体验从业者、学生和讲师）进行了一项形成性研究。基于研究结果，我们开发了StoryEnsemble，一个将人工智能集成到节点链接界面中并利用前向和后向传播来支持设计过程中动态探索和迭代的工具。一项对10名参与者的用户研究表明，StoryEnsemble能够实现快速、多方向的迭代以及设计阶段间的灵活导航。这项工作通过引入新颖的交互方式，使探索和迭代更加流畅、可访问和引人入胜，从而增进了我们对人工智能如何促进更迭代设计实践的理解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [470] [Critical Challenges in Content Moderation for People Who Use Drugs (PWUD): Insights into Online Harm Reduction Practices from Moderators](https://arxiv.org/abs/2508.02868)
> *药物使用者（PWUD）内容审核中的关键挑战：来自版主的在线减害实践洞察*

*Kaixuan Wang, Loraine Clarke, Carl-Cyril J Dreue, Guancheng Zhou, Jason T. Jacques* | **Category: cs.HC, cs.CY** | **Updated: 2025-08-04**

**Keywords:** 内容审核, 药物使用者, 减害, 在线社区, 社会技术系统

**Comment:** 22 pages

> **TL;DR:** 本文通过对Reddit上药物使用者论坛版主的采访，分析了在线社区内容审核对药物使用者安全的重要性及其面临的独特挑战，并提出了改进社会技术系统以支持版主工作的建议。

**AI_Comments:** 这篇论文揭示了在线社区内容审核在公共卫生领域的关键作用，特别是在支持药物使用者方面。其创新之处在于将内容审核视为一种公共卫生干预，并识别出其独特的挑战。论文强调了现有社会技术系统在支持版主方面的不足，并提出了具体的改进方向，如引入更智能的自动化工具和更灵活的规则编程方式。这对于平台设计者和政策制定者具有重要的实践指导意义，有助于改善弱势群体的在线支持和健康结果。论文的局限性可能在于其研究对象仅限于Reddit论坛，结果的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在线社区是药物使用者获取支持和减害信息的重要渠道。然而，现有社会技术系统对这些社区的版主支持不足，他们的工作涉及影响成员安全的重要决策。因此，研究旨在分析这项工作的独特性质，并指出现有系统在支持药物使用者社区方面的不足。

**Method:** 通过对Reddit上药物使用者论坛的经验丰富的版主进行访谈。

**Result:** 研究发现，药物使用者社区的内容审核工作是一种独特的公共卫生干预形式，面临三个挑战：需要专业的专家风险评估；时间紧迫的危机响应；以及平台政策与社区安全目标之间的结构性冲突。研究表明，当前的审核系统不足以支持药物使用者社区，例如，平台政策可能无意中促使版主实施限制性规则，从而限制了弱势群体在线分享潜在救生资源的能力。

**Conclusion:** 为了支持版主的工作，社会技术设计需要进行两次必要的转变：首先，转向支持人类在利益冲突情境中进行理解的自动化工具；其次，从要求版主执行低级规则编程的系统转向支持高级、基于示例指令的系统。此外，研究强调了在线空间中社会技术系统的设计如何影响旨在改善药物使用者社区健康结果的减害工作。

> **ai_Abstract:** 本研究探讨了药物使用者（PWUD）在线社区内容审核所面临的关键挑战，认为这项工作是一种独特的公共卫生干预。通过对Reddit版主的访谈，研究发现现有社会技术系统对版主支持不足，导致在专业风险评估、危机响应以及平台政策与社区安全目标冲突方面存在困难。文章指出，不当的平台政策可能限制了重要减害信息的传播。最后，研究建议通过开发支持人类理解的自动化工具和实现高层次、基于示例指令的系统来改进社会技术设计，以更好地支持版主工作并促进药物使用者社区的健康减害。

> **摘要翻译:** 在线社区是药物使用者（PWUD）重要的支持渠道，提供同伴支持和减害信息。这些社区的审核工作涉及影响成员安全的重要决策，但现有社会技术系统对版主的支持不足。通过对Reddit上药物使用者论坛经验丰富的版主进行访谈，我们分析了这项工作的独特性质。我们认为，这项工作构成了一种独特的公共卫生干预形式，其特点是面临三个审核挑战：需要专业的专家风险评估；时间紧迫的危机响应；以及平台政策与社区安全目标之间的结构性冲突。我们证明了当前的审核系统在支持药物使用者社区方面存在不足。例如，旨在最小化平台非法活动法律风险的政策，可能会无意中促使版主实施限制性规则以保护社区的存在，这可能限制了这一弱势群体在线分享潜在救生资源的能力。最后，我们提出了支持版主工作所需的两项社会技术设计转变：首先，转向支持人类在利益冲突情境中进行理解的自动化工具；其次，从要求版主执行低级规则编程的系统转向支持高级、基于示例指令的系统。此外，我们强调了在线空间中社会技术系统的设计如何影响旨在改善药物使用者社区健康结果的减害工作。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [487] [VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos](https://arxiv.org/abs/2507.21837)
> *VeasyGuide：针对演示视频中教师动作的低视力学习者个性化视觉引导*

*Yotam Sechayk, Ariel Shamir, Amy Pavel, Takeo Igarashi* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 低视力学习者, 视觉引导, 教师动作, 演示视频, 认知负荷

**Comment:** ASSETS '25, Denver, CO, USA

> **TL;DR:** VeasyGuide帮助低视力学习者更好地识别演示视频中教师的视觉动作，通过动态高亮和放大来减少认知负荷并提高检测率。

**AI_Comments:** VeasyGuide的创新之处在于利用运动检测技术为低视力学习者提供个性化的视觉辅助，解决了他们在在线学习中面临的具体挑战。其协同设计方法确保了用户需求被充分考虑。此外，该工具不仅对低视力人群有益，对正常视力人群也有积极作用，这增加了其普适性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 教育演示视频中教师的视觉动作（如指向、标记、绘画）常缺乏口头描述，导致低视力学习者难以找到视觉指示，或仅依赖音频，从而错过信息并增加认知负荷。

**Method:** 通过与三名低视力参与者的协同设计研究，开发了VeasyGuide工具。该工具利用运动检测来识别教师动作，并动态地高亮和放大这些动作，提供空间上下文、广泛的个性化设置以及实时视觉反馈。

**Result:** 对8名低视力参与者的评估显示，学习者在检测教师动作方面有显著改善，响应时间更快，认知负荷显著降低。对8名正常视力参与者的单独评估显示，VeasyGuide也增强了参与度和专注度。

**Conclusion:** VeasyGuide能有效帮助低视力学习者检测演示视频中的教师动作，降低认知负荷，并可能作为一种普适性工具提升所有学习者的参与度和专注度。

> **ai_Abstract:** 本文介绍了VeasyGuide，一个为低视力学习者设计的工具，旨在解决他们在教育演示视频中难以识别教师视觉动作的问题。VeasyGuide通过运动检测识别并动态高亮、放大教师动作，提供个性化的视觉引导。评估结果表明，该工具显著提高了低视力学习者检测教师动作的效率，降低了认知负荷，并对正常视力学习者也具有积极作用，展现了其普适性潜力。

> **摘要翻译:** 教师在教育演示视频中经常依靠指向、标记和绘画等视觉动作来传达信息。这些细微的视觉线索通常缺乏口头描述，迫使低视力（LV）学习者寻找视觉指示或完全依赖音频，这可能导致信息遗漏和认知负荷增加。为了解决这一挑战，我们与三名低视力参与者进行了一项协同设计研究，并开发了VeasyGuide，这是一种利用运动检测来识别教师动作并动态高亮和放大它们的工具。VeasyGuide产生熟悉的视觉高亮，传达空间上下文，并通过广泛的个性化和实时视觉反馈适应不同的学习者和内容。VeasyGuide通过澄清“看什么”和“看哪里”来减少视觉搜索工作。在对8名低视力参与者的评估中，学习者在检测教师动作方面表现出显著改善，响应时间更快，认知负荷显著降低。对8名正常视力参与者的单独评估显示，VeasyGuide也增强了参与度和专注度，表明其作为一种普适性工具的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [493] [Navigation Pixie: Implementation and Empirical Study Toward On-demand Navigation Agents in Commercial Metaverse](https://arxiv.org/abs/2508.03216)
> *导航小精灵：商业元宇宙中按需导航代理的实现与实证研究*

*Hikari Yanagawa, Yuichi Hiroi, Satomi Tokida, Yuji Hatada, Takefumi Hiraki* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 元宇宙, 导航代理, LLM, 虚拟现实, 交互设计

**Comment:** 11 pages + supplement 3 pages. To appear in IEEE ISMAR 2025

> **TL;DR:** Navigation Pixie是一种按需导航代理，通过结合结构化空间元数据和LLM自然语言处理，显著提高了商业元宇宙平台上的用户停留时间和自由探索。

**AI_Comments:** 本研究的创新点在于提出了一个松耦合的按需导航代理，成功地将LLM与结构化空间数据结合，并在商业元宇宙平台进行了大规模的跨平台实证研究。这对于VR交互设计和元宇宙的用户体验提升具有重要意义，尤其是在处理多样化用户生成内容和平台限制方面。其揭示的环境依赖性有效性也提供了宝贵的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 商业元宇宙平台缺乏能动态适应用户兴趣和意图的有效导航辅助。尽管已有研究在受控环境中探索了按需代理，但在多样世界配置和平台限制的商业环境中实现仍具挑战性。

**Method:** 本文提出了Navigation Pixie，一个按需导航代理，采用松耦合架构，将结构化空间元数据与基于LLM的自然语言处理相结合，同时最大限度地减少平台依赖性。这使得能够在商业元宇宙平台的大量用户基础上进行实验。

**Result:** 在商业元宇宙平台Cluster上，通过99名PC客户端和94名VR-HMD参与者的跨平台实验表明，与固定路线和无代理条件相比，Navigation Pixie显著增加了用户在PC和VR平台上的停留时间和自由探索。主观评估显示，PC环境中一致的按需偏好与VR-HMD中依赖上下文的社交感知优势并存。

**Conclusion:** 本研究通过对话式空间导航代理促进了VR交互设计，建立了揭示环境依赖有效性的跨平台评估方法，并展示了商业元宇宙平台的实证实验框架。

> **ai_Abstract:** 本研究提出了一种名为Navigation Pixie的按需导航代理，旨在解决商业元宇宙平台缺乏动态导航辅助的问题。该代理采用松耦合架构，结合结构化空间元数据和LLM驱动的自然语言处理，以最小化平台依赖。通过在商业元宇宙平台Cluster上进行PC和VR-HMD用户的跨平台实验，研究发现Navigation Pixie显著提高了用户停留时间和自由探索。此外，主观评估揭示了PC环境中的按需偏好和VR-HMD中的社交感知优势。该工作为VR交互设计、跨平台评估方法和商业元宇宙平台的实证研究框架做出了贡献。

> **摘要翻译:** 虽然商业元宇宙平台提供了多样化的用户生成内容，但它们缺乏能够动态适应用户兴趣和意图的有效导航辅助。尽管之前的研究在受控环境中调查了按需代理，但在具有多样化世界配置和平台限制的商业环境中实现仍然具有挑战性。
我们提出了Navigation Pixie，一个按需导航代理，它采用松耦合架构，将结构化空间元数据与基于LLM的自然语言处理相结合，同时最大限度地减少平台依赖性，这使得能够在商业元宇宙平台的广泛用户群上进行实验。我们在商业元宇宙平台Cluster上对99名PC客户端和94名VR-HMD参与者进行的跨平台实验表明，与固定路线和无代理条件相比，Navigation Pixie在两个平台上都显著增加了停留时间和自由探索。主观评估显示，在PC环境中存在一致的按需偏好，而在VR-HMD中存在依赖上下文的社交感知优势。这项研究通过对话式空间导航代理促进了VR交互设计，建立了揭示环境依赖有效性的跨平台评估方法，并展示了商业元宇宙平台的实证实验框架。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [506] [AnnoSense: A Framework for Physiological Emotion Data Collection in Everyday Settings for AI](https://arxiv.org/abs/2508.02680)
> *AnnoSense: 一种用于AI日常环境中生理情绪数据收集的框架*

*Pragya Singh, Ankush Gupta, Mohan Kumar, Pushpendra Singh* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 生理情绪数据, 日常环境, AI, 数据收集, AnnoSense

**Comment:** To be published in IMWUT, September 2025

> **TL;DR:** AnnoSense 是一个旨在解决日常环境中生理情绪数据收集和标注挑战的框架，为AI提供高质量数据。

**AI_Comments:** 该论文的创新之处在于其以用户为中心的方法，通过大量利益相关者（包括公众和心理健康专家）的反馈来指导情绪数据收集框架的设计，这有助于确保数据收集方法的真实性和可用性。其重要性在于为AI开发提供了高质量、真实世界情绪数据的潜在解决方案，克服了传统实验室环境数据收集的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能设备的普及，日常情绪监测机会增多，但AI算法需要高质量、准确标注的情绪数据。在真实世界环境中收集情绪数据以捕获更真实的情绪体验面临复杂挑战。

**Method:** 作者收集了75份问卷、32次公众访谈和3次与12位心理健康专业人士的焦点小组讨论，共计119位利益相关者的见解。基于这些见解，开发了 AnnoSense 框架。该框架随后由25位情绪AI专家评估了其清晰度、实用性和适应性。

**Result:** 从119位利益相关者获得的见解为 AnnoSense 框架的开发提供了信息。该框架被情绪AI专家评估为具有良好的清晰度、实用性和适应性。

**Conclusion:** AnnoSense 框架有潜力增强真实世界环境中情绪数据的收集和分析，对未来情绪AI研究具有重要意义。

> **ai_Abstract:** 本文提出了 AnnoSense 框架，旨在解决AI在日常环境中进行生理情绪数据收集和准确标注的挑战。研究通过对公众和心理健康专业人士进行问卷、访谈和焦点小组讨论，收集了119位利益相关者的见解，并基于此开发了 AnnoSense。该框架随后由情绪AI专家进行评估，结果显示其具有良好的清晰度、实用性和适应性。文章最后讨论了 AnnoSense 对未来情绪AI研究的潜在影响，强调其在真实世界情绪数据收集和分析中的价值。

> **摘要翻译:** 情绪和心理健康是生活质量的重要组成部分，随着智能手机、可穿戴设备和人工智能（AI）等智能设备的兴起，在日常环境中监测情绪的新机会随之出现。然而，为了使AI算法有效，它们需要高质量的数据和准确的标注。随着重心转向在真实世界环境中收集情绪数据以捕获更真实的情绪体验，情绪标注的收集过程变得日益复杂。这项工作从关键利益相关者的角度探讨了日常情绪数据收集的挑战。我们收集了75份问卷调查回复，对公众进行了32次访谈，并与12位心理健康专业人士进行了3次焦点小组讨论（FGDs）。从总共119位利益相关者获得的见解为我们框架 AnnoSense 的开发提供了信息，该框架旨在支持AI的日常情绪数据收集。该框架随后由25位情绪AI专家评估了其清晰度、实用性和适应性。最后，我们讨论了 AnnoSense 对未来情绪AI研究的潜在后续步骤和影响，强调了其在真实世界环境中增强情绪数据收集和分析的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [525] [Quo-Vadis Multi-Agent Automotive Research? Insights from a Participatory Workshop and Questionnaire](https://arxiv.org/abs/2508.03281)
> *多智能体汽车研究何去何从？来自参与式研讨会和问卷的见解*

*Pavlo Bazilinskyy, Francesco Walker, Debargha Dey, Tram Thi Minh Tran, Hyungchai Park, Hyochang Kim, Hyunmin Kang, Patrick Ebel* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 多智能体汽车研究, 混合交通, 参与式研讨会, 方法挑战, 模拟环境

**Comment:** 

> **TL;DR:** 该研究通过研讨会和问卷调查，探讨了多智能体汽车研究的现状，发现尽管其价值被广泛认可，但实践和技术障碍阻碍了实施，并强调需要更好的方法和工具。

**AI_Comments:** 本研究通过直接与领域专家互动，深入剖析了多智能体汽车研究的现状和面临的挑战，其创新之处在于采用参与式方法揭示了当前研究的局限性。其重要性在于明确指出了未来研究的方向，强调了跨学科合作和工具改进的必要性，这对于推动该领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在涉及自动驾驶车辆、手动驾驶车辆和弱势道路使用者的混合交通环境中，人类中心汽车研究面临新挑战，但大多数现有研究仅关注单智能体交互。

**Method:** 本研究报告了一项在AutomotiveUI '24会议期间进行的参与式研讨会（N = 15）和一份问卷调查（N = 19），以探讨多智能体汽车研究的现状。参与者讨论了在真实世界环境、模拟和计算建模中的方法挑战和机遇。

**Result:** 主要发现表明，尽管多智能体方法的价值被广泛认可，但实际和技术障碍阻碍了其实现。

**Conclusion:** 该研究强调需要跨学科方法、更好的工具和模拟环境，以支持可扩展、现实且符合伦理的多智能体研究。

> **ai_Abstract:** 本研究通过在AutomotiveUI '24会议期间进行的参与式研讨会和问卷调查，探讨了多智能体汽车研究的现状。尽管多智能体方法的价值在混合交通环境中得到广泛认可，但实际和技术障碍阻碍了其应用。研究结果强调了开发跨学科方法、改进工具和模拟环境以支持可扩展、现实和符合伦理的多智能体研究的必要性。

> **摘要翻译:** 向涉及自动驾驶车辆、手动驾驶车辆和弱势道路使用者的混合交通环境过渡，给以人为本的汽车研究带来了新的挑战。尽管如此，该领域的大多数研究都集中在单智能体交互上。本文报告了在AutomotiveUI '24会议期间进行的一项参与式研讨会（N = 15）和一份问卷调查（N = 19），旨在探索多智能体汽车研究的现状。参与者讨论了在真实世界环境、模拟和计算建模中的方法挑战和机遇。主要发现表明，尽管多智能体方法的价值被广泛认可，但实际和技术障碍阻碍了其实现。该研究强调需要跨学科方法、更好的工具和模拟环境，以支持可扩展、现实且符合伦理的多智能体研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [527] [Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable](https://arxiv.org/abs/2508.02639)
> *重构图案：一种复合视觉变量的综合方法*

*Tingying He, Jason Dykes, Petra Isenberg, Tobias Isenberg* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 图案, 视觉变量, 可视化, 纹理, 设计空间

**Comment:** 

> **TL;DR:** 本文提出了一种新的综合理论，用于解释、探索和使用图案作为可视化中的视觉变量，解决了现有概念和术语不一致的问题。

**AI_Comments:** 本文通过对“图案”作为视觉变量的重新定义和系统化，填补了可视化领域的一个重要空白。其创新之处在于提供了一个统一且全面的理论框架，解决了长期以来概念和术语混淆的问题。这不仅有助于更有效地使用图案进行数据编码，也为未来的可视化设计和研究提供了坚实的基础和广阔的探索空间，特别是通过引入三组变量来形式化图案，极大地扩展了其潜在应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管图案长期以来被用于数据编码并仍有价值，但其概念基础不稳定，研究文献和实践中使用的概念和术语不一致，这使得有效使用图案和进行相关研究变得困难。

**Method:** 研究人员进行了一项全面的跨学科文献综述，以澄清围绕“图案”和“纹理”使用的模糊性。

**Result:** 研究结果提出了一种将图案视为复合视觉变量的新一致处理方法，该变量由图形原语的结构化组组成，可以单独和集体地用作编码数据的标记。研究还提出了一个包含三组变量的新系统：原语的空间排列、原语之间的外观关系以及表征单个原语的视网膜视觉变量。

**Conclusion:** 这种新的、广泛适用的公式为视觉变量图案开辟了巨大的设计空间，并展示了与现有可视化理论的关系以及可视化设计的机会。该研究还探索了基于复杂空间排列的图案，展示了解释力，并将概念与地图和制图的更广泛理论联系起来。

> **ai_Abstract:** 本文提出了一种关于图案作为复合视觉变量的全面新理论，旨在解决现有可视化领域中图案概念和术语的不一致性。通过跨学科文献综述，作者澄清了“图案”和“纹理”的定义，并提出了一个将图案视为由图形原语组成的复合变量的新框架。该框架定义了一个包含空间排列、外观关系和视网膜变量的图案系统，从而为可视化设计开辟了广阔的设计空间，并与现有理论和制图学建立了联系。

> **摘要翻译:** 我们提出了一种新的综合理论，用于解释、探索和使用图案作为可视化中的视觉变量。尽管图案长期以来被用于数据编码并至今仍有价值，但其概念基础不稳定：研究文献和实践中使用的概念和术语不一致，这使得有效使用图案和进行研究以指导其使用变得具有挑战性。为了解决这个问题，我们进行了一项全面的跨学科文献综述，澄清了“图案”和“纹理”使用中的模糊性。因此，我们提出了一种将图案视为复合视觉变量的新一致处理方法，该变量由图形原语的结构化组组成，可以单独和集体地用作编码数据的标记。这种新的、广泛适用的公式为视觉变量图案开辟了巨大的设计空间，我们将其形式化为一个包含三组变量的新系统：原语的空间排列、原语之间的外观关系以及表征单个原语的视网膜视觉变量。我们展示了我们的图案系统如何与现有可视化理论相关联，并强调了可视化设计的机会。我们进一步探索了基于复杂空间排列的图案，展示了解释力，并将我们的概念化与地图和制图的更广泛理论联系起来。作者版本和附加材料可在OSF上获取：osf.io/z7ae2。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [555] [Enhancing Joint Human-AI Inference in Robot Missions: A Confidence-Based Approach](https://arxiv.org/abs/2508.03293)
> *增强机器人任务中的人机联合推理：一种基于置信度的方法*

*Duc-An Nguyen, Clara Colombatto, Steve Fleming, Ingmar Posner, Nick Hawes, Raunak Bhattacharyya* | **Category: cs.HC, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 人机联合推理, 机器人任务, 置信度方法, AI校准, 遥操作

**Comment:** 

> **TL;DR:** 本研究提出并验证了一种基于置信度选择更高置信度推理结果的人机联合推理方法，结果显示其能提高准确性，并强调了AI置信度校准的重要性。

**AI_Comments:** 该研究首次将最大置信度启发式方法应用于模拟机器人遥操作任务中的人机联合推理，具有创新性。它不仅提出了新的联合推理范式，还通过实证研究强调了AI置信度校准对人机协作性能的关键影响，指出了未来AI决策支持系统设计中需要关注的重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 在人机协作的机器人任务中，当前AI辅助模式下，人类操作员由于判断失误，难以有效接受或拒绝AI建议，导致人机互补性不足。

**Method:** 研究调查了一种人机联合推理方法，即选择置信度更高的一方所做的推理。通过一项N=100参与者的用户研究，在模拟机器人遥操作任务中（具体研究机器人控制延迟的推理），验证了该方法。

**Result:** a) 联合推理准确性更高，其程度受AI智能体置信度校准的影响；b) 人类会根据AI建议改变其推理，且这种改变的程度和方向也受AI智能体置信度校准的影响。研究还发现，将校准不良的AI决策支持系统与人类配对会损害团队绩效。

**Conclusion:** 人机联合推理，特别是基于置信度选择的方法，能够提高任务准确性。AI智能体的置信度校准至关重要，校准不佳的AI反而会损害人机团队的性能，因此需要具有良好元认知敏感性的AI决策支持系统。

> **ai_Abstract:** 本研究提出并评估了一种在机器人任务中增强人机联合推理的置信度方法。针对现有AI辅助模式下人类判断失误导致互补性不足的问题，该方法通过选择置信度更高的推理结果来提升性能。一项针对100名参与者的模拟机器人遥操作任务用户研究表明，这种联合推理方法提高了准确性，其有效性取决于AI的置信度校准。研究强调，AI的置信度校准对于人机团队的成功至关重要，校准不良的AI反而会损害团队绩效。

> **摘要翻译:** 人机联合推理在改善人类监督的机器人任务结果方面具有巨大潜力。当前的任务通常处于AI辅助设置中，人类操作员根据AI的建议做出最终推理。然而，由于人类在何时接受或拒绝AI建议方面的判断失误，很少能实现互补性。我们研究了人机联合推理，其中选择置信度更高的推理。通过一项N=100名参与者的用户研究，在一个有代表性的模拟机器人遥操作任务中，具体研究机器人控制延迟的推理，我们发现：a) 联合推理准确性更高，其程度受AI智能体置信度校准的调节；b) 人类会根据AI建议改变其推理，且这种改变的程度和方向也受AI智能体置信度校准的调节。有趣的是，我们的结果表明，将校准不良的AI决策支持系统与人类配对会损害性能，而不是帮助团队，这重申了对具有良好元认知敏感性的AI决策支持系统的需求。据我们所知，我们的研究首次将基于最大置信度的启发式方法应用于模拟机器人遥操作任务中的人机联合推理。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [590] [Remini: Leveraging Chatbot-Mediated Mutual Reminiscence for Promoting Positive Affect and Feeling of Connectedness among Loved Ones](https://arxiv.org/abs/2508.03355)
> *Remini：利用聊天机器人促进的共同回忆来提升亲密关系中的积极情绪和联结感*

*Zhuoqun Jiang, ShunYi Yeo, Wei Xuan Donovan Seow, Simon Perrault* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 共同回忆, 聊天机器人, 积极情绪, 联结感, 对话式AI

**Comment:** Camera-ready submission for PACM HCI, CSCW 2025

> **TL;DR:** Remini是一个聊天机器人，旨在通过引导共同回忆来增强亲密伴侣间的积极情绪和联结感，研究表明它显著提升了用户体验。

**AI_Comments:** Remini的创新之处在于其将聊天机器人技术应用于促进共同回忆，并引入了结构化的对话引导流程，有效解决了现有技术工具在互动性方面的不足。其基于SFAM框架的设计提升了交互的情感深度和有效性。该研究的重要性在于为利用AI技术增强人际关系提供了新的视角和实证支持，对于开发情感智能型对话系统具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的技术辅助回忆工具多侧重于个人反思或单向叙事，忽视了有意义的共同回忆所需的动态互动对话。为了解决这一局限性，本研究引入了Remini。

**Method:** 本研究介绍了Remini，一个基于“自传式记忆的社会功能（SFAM）”框架设计的聊天机器人，它通过五个叙事阶段（建立关系、记忆叙述、详述、反思和总结）引导情感丰富的交流。研究采用混合方法，通过一项N=48（24对）的被试间和被试内研究，将Remini与一个提供最少记忆触发提示的基线聊天机器人进行比较。

**Result:** 研究结果显示，Remini提供的结构化指导显著改善了积极情绪、联结感和参与度。它还促进了更详细的叙事共同构建和更大的相互自我披露。参与者反馈强调了聊天机器人辅助回忆的实用价值、感知益处和设计考量。

**Conclusion:** 本研究为通过共同回忆加强人际联系的对话代理提供了基于实证的设计启示。

> **ai_Abstract:** 本研究提出并评估了Remini，一个利用聊天机器人促进共同回忆的系统，旨在增强亲密伴侣间的积极情绪和联结感。与传统技术辅助回忆工具的单向性不同，Remini基于SFAM框架，通过引导式对话促进相互自我披露和情感交流。实验结果表明，Remini能显著提升用户的积极情绪、联结感和参与度，并促进更深层次的叙事构建和相互披露。研究为设计能加强人际关系的对话代理提供了实证指导。

> **摘要翻译:** 共同回忆，定义为通过相互自我披露重温共享的积极记忆，能够加强情感纽带，提升幸福感，并加深亲密关系。然而，大多数技术辅助的回忆工具都强调个人反思或单向叙事，这忽视了有意义的共同回忆所必需的动态互动对话。为了解决这一局限性，我们引入了Remini，一个旨在支持亲密伴侣（如情侣、朋友或家人）之间相互自我披露的聊天机器人。Remini以自传式记忆的社会功能（SFAM）框架为基础，利用对话式AI通过五个叙事阶段（建立关系、记忆叙述、详述、反思和总结）引导情感丰富的交流。在一项混合方法、被试间和被试内研究（N=48，24对）中，我们将Remini与一个提供最少记忆触发提示的基线聊天机器人进行了比较。我们的研究结果表明，Remini的结构化指导显著改善了积极情绪、联结感和参与度。它还促进了更详细的叙事共同构建和更大的相互自我披露。参与者反馈强调了聊天机器人辅助回忆的实用价值、感知益处和设计考量。我们为通过共同回忆加强人际联系的对话代理提供了基于实证的设计启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [631] [The Science Fiction Science Method](https://arxiv.org/abs/2508.03430)
> *科幻科学方法*

*Iyad Rahwan, Azim Shariff, Jean-François Bonnefon* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 科幻科学, 未来技术, 实验方法, 社会影响, 有效性

**Comment:** 

> **TL;DR:** 本文提出一种名为“科幻科学”的方法，通过实验模拟未来技术并量化其社会影响，旨在提前指导技术开发和监管。文章还探讨了该方法面临的有效性威胁以及如何推广应用。

**AI_Comments:** 这篇论文提出了一种创新且具有前瞻性的“科幻科学”研究方法，它试图将科幻的想象力与科学的严谨性相结合，为预测未来技术影响提供了新的视角。其重要性在于，它为社会和技术政策制定提供了早期、量化的洞察力。论文坦诚地指出了该方法在有效性方面面临的挑战，并积极探讨了解决方案，这对于推动该新兴领域的成熟和规范化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在未来技术的影响固化之前，预测其社会和行为影响，以便指导技术开发和监管。传统方法依赖定性叙事，但需要一种能提供定量测量的实验性方法。

**Method:** 本文提出“科幻科学”方法，该方法利用实验手段模拟未来技术，并收集参与者在未来不同受控情境下态度和行为的定量数据。

**Result:** Not mentioned in abstract

**Conclusion:** 论文探讨了科幻科学方法可能研究的技术类型、所需的非常规沉浸式方法，并提出如何解决其有效性威胁，以及如何使这些方法常态化，以促进科幻科学家多元社区参与有效性改进的良性循环。

> **ai_Abstract:** 本文提出了一种名为“科幻科学”的新颖方法，旨在通过实验模拟未来技术并定量分析其对社会和行为的影响，以便在技术发展初期进行干预和指导。文章指出，尽管该方法潜力巨大，但因其面临的有效性威胁而未被广泛采纳。为解决此问题，作者探讨了该方法适用的技术范围、所需的非常规沉浸式手段，并呼吁标准化这些方法，以促进科幻科学研究社区的参与和该领域有效性的持续改进。

> **摘要翻译:** 预测未来技术在实现之前的社会和行为影响，将使我们能够在这些影响根深蒂固之前指导其开发和监管。传统上，这种预测依赖于定性的叙事方法。本文描述了一种使用实验方法模拟未来技术，并收集分配给未来受控变化的参与者态度和行为的定量测量数据的方法。我们称这种方法为“科幻科学”。我们认为，尽管这种方法具有潜在的好处，但尚未被完全接受的原因是，实验科学家可能不愿从事面临科幻科学如此严重有效性威胁的工作。为了解决这些威胁，我们考虑了科幻科学可能研究的技术类型，以及科幻科学可能需要的非常规、沉浸式方法。我们旨在提供关于这种方法长期被边缘化的原因、如果能建立在强大但不同寻常的方法之上会带来什么好处，以及我们如何使这些方法常态化以帮助科幻科学家多元社区参与有效性改进的良性循环的视角。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [674] [Guided Reality: Generating Visually-Enriched AR Task Guidance with LLMs and Vision Models](https://arxiv.org/abs/2508.03547)
> *引导现实：使用大型语言模型和视觉模型生成富含视觉信息的增强现实任务指南*

*Ada Yi Zhao, Aditya Gunturu, Ellen Yi-Luen Do, Ryo Suzuki* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 增强现实, 大型语言模型, 视觉模型, 任务指导, 空间嵌入

**Comment:** To appear at UIST 2025

> **TL;DR:** 该研究提出了一种名为“引导现实”的全自动化增强现实（AR）系统，该系统利用大型语言模型（LLM）和视觉模型生成嵌入式、动态的视觉AR任务指导，以克服现有AR指导中视觉信息不足的问题。

**AI_Comments:** 该研究提出了一种创新的方法，将LLM和视觉模型结合起来，以生成更具信息量和空间感知的AR指导。与现有方法相比，该系统在视觉增强和空间嵌入方面取得了显著进展，有望在培训、维修等领域产生广泛影响。然而，对于不同复杂度的任务和不同类型的用户，其有效性的普适性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于LLM的AR指导缺乏丰富的视觉增强，难以有效地将指令融入空间语境，从而影响用户理解。

**Method:** 该系统整合了LLM和视觉模型，能够从用户查询生成多步指令，识别合适的视觉指导类型，提取关键交互点的空间信息，并将视觉指导嵌入物理空间以支持任务执行。研究人员从用户手册语料库中定义了五种视觉指导类别，并提出了一种基于当前步骤的识别策略。

**Result:** 通过包含16名用户参与的真实世界任务用户研究，以及对系统在实际环境中的探索，评估了该系统的有效性。此外，四位培训师也分享了关于如何将“引导现实”整合到其培训工作流程中的见解。

**Conclusion:** “引导现实”系统能够生成嵌入式和动态的视觉指导，有效解决了现有AR指导中视觉信息不足的问题，并通过用户研究和专家反馈证明了其在实际应用中的潜力。

> **ai_Abstract:** “引导现实”是一个创新的全自动化AR系统，它利用大型语言模型（LLM）和视觉模型来生成详细的、视觉丰富的AR任务指导。该系统能够根据用户指令生成分步说明，识别并提取关键空间信息，然后将视觉指导（如箭头、高亮显示等）动态地嵌入到现实世界的视图中，以提供更直观、更易于理解的任务引导。通过用户研究和专家访谈，该系统被证明能够有效提升用户在执行物理任务时的体验和效率。

> **摘要翻译:** 大型语言模型（LLM）使得为各种物理任务自动生成分步增强现实（AR）说明成为可能。然而，现有的基于LLM的AR指导通常缺乏丰富的视觉增强，难以有效地将指令嵌入空间语境以促进用户理解。我们提出了“引导现实”（Guided Reality），一个全自动化的AR系统，可以根据分步说明生成嵌入式和动态的视觉指导。我们的系统整合了LLM和视觉模型，以：1）从用户查询生成多步说明，2）识别合适的视觉指导类型，3）提取现实世界中关键交互点的空间信息，以及4）将视觉指导嵌入物理空间以支持任务执行。我们从用户手册语料库中定义了五种视觉指导类别，并提出了一种基于当前步骤的识别策略。我们通过一项用户研究（N=16）来评估该系统，用户完成了真实世界的任务，并在实际环境中探索了该系统。此外，四位指导者分享了关于“引导现实”如何整合到他们的培训工作流程中的见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [715] [SlideAudit: A Dataset and Taxonomy for Automated Evaluation of Presentation Slides](https://arxiv.org/abs/2508.03630)
> *幻灯片审计：用于演示幻灯片自动评估的数据集和分类法*

*Zhuohao Jerry Zhang, Ruiqi Chen, Mingyuan Zhong, Jacob O. Wobbrock* | **Category: cs.HC** | **Updated: 2025-08-05**

**Keywords:** 幻灯片评估, 数据集, 分类法, 大型语言模型, 设计缺陷

**Comment:** UIST 2025

> **TL;DR:** 该研究提出了SlideAudit数据集和分类法，用于自动评估演示幻灯片的设计缺陷。虽然大型语言模型在识别这些缺陷方面存在困难（F1分数在0.331到0.655之间），但利用该分类法的提示策略表现最佳。此外，该分类法在指导AI进行幻灯片修复方面也显示出其有效性。

**AI_Comments:** 该研究在幻灯片自动评估领域做出了重要贡献，提出了一个包含详细分类法和标注数据集的SlideAudit。研究方法严谨，通过对比不同模型和提示策略，清晰地展示了AI在这一任务上的潜力和局限性。修复研究的结果尤其令人鼓舞，表明该分类法在实际应用中具有指导意义。然而，未来可以进一步探索更先进的模型架构或训练方法来克服当前的性能瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 自动评估演示幻灯片等特定平面设计是一个开放性问题，目前缺乏有效的方法和数据集。

**Method:** 研究人员与设计专家合作，开发了一个详尽的幻灯片设计缺陷分类法。他们收集并合成了2400张幻灯片，其中一部分经过了特定的设计问题修改。然后，他们通过经过严格培训的众包（来自Prolific）使用该分类法对这些幻灯片进行了标注。为了评估AI识别设计缺陷的能力，研究人员比较了多种大型语言模型在不同提示策略下的表现，并与现有的设计评论流程进行了对比。此外，他们还进行了一项修复研究，以评估AI改进幻灯片设计的潜力。

**Result:** AI模型在准确识别幻灯片设计缺陷方面存在困难，F1分数在0.331到0.655之间。利用该研究提出的分类法的提示策略取得了最佳性能。在修复研究中，82.0%的幻灯片得到了显著改进，其中87.8%的改进效果优于未使用该分类法的模型，进一步证明了该分类法的实用性。

**Conclusion:** SlideAudit数据集和分类法为自动评估幻灯片设计缺陷提供了一个有价值的资源。虽然目前的AI模型在识别这些缺陷方面仍有局限性，但利用该分类法的提示策略可以提高其性能。该分类法在指导AI进行幻灯片修复方面也显示出巨大潜力。

> **ai_Abstract:** 本研究提出了SlideAudit，一个包含2400张标注幻灯片的数据集，旨在解决演示幻灯片自动评估的挑战。研究人员开发了一个详细的设计缺陷分类法，并使用该分类法对数据集进行了标注。通过实验评估了大型语言模型在识别幻灯片设计缺陷方面的能力，结果表明现有模型表现不佳，但利用该分类法的提示策略能显著提升性能。此外，研究还验证了该分类法在指导AI进行幻灯片修复方面的有效性。

> **摘要翻译:** 自动评估演示幻灯片等特定平面设计是一个开放性问题。我们提出了SlideAudit，一个用于自动幻灯片评估的数据集。我们与设计专家合作，开发了一个详尽的幻灯片设计缺陷分类法。我们的数据集包含从多个来源收集和合成的2400张幻灯片，其中包括一部分经过有意修改以包含特定设计问题的幻灯片。然后，我们通过Prolific上经过严格培训的众包对其进行了分类法的完整标注。为了评估AI识别设计缺陷的能力，我们比较了多种大型语言模型在不同提示策略下的表现，以及现有的设计评论流程。我们表明，AI模型在准确识别幻灯片设计缺陷方面存在困难，F1分数在0.331到0.655之间。值得注意的是，利用我们分类法的提示技术取得了最高的性能。我们进一步进行了一项修复研究，以评估AI改进幻灯片的潜力。在显示显著改进的82.0%的幻灯片中，有87.8%的幻灯片通过我们的分类法得到了更好的改进，进一步证明了其效用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [756] [Probing the Gaps in ChatGPT Live Video Chat for Real-World Assistance for People who are Blind or Visually Impaired](https://arxiv.org/abs/2508.03651)
> *探测ChatGPT视频聊天在为视障人士提供现实世界援助方面的差距*

*Ruei-Che Chang, Rosiana Natalie, Wenqian Xu, Jovan Zheng Feng Yap, Anhong Guo* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 视障人士, ChatGPT, 实时视频AI, 辅助技术, 人机交互

**Comment:** ACM ASSETS 2025

> **TL;DR:** 本研究评估了ChatGPT的实时视频功能在为视障人士提供现实世界援助方面的有效性，发现其在静态场景下表现良好，但在动态场景下存在不足，并指出了需要改进的领域。

**AI_Comments:** 该研究对当前AI在辅助视障人士方面的能力进行了有价值的探索，突出了技术在不同场景下的优势和局限性。研究结果对于未来开发更安全、更有效的AI辅助工具具有重要意义。然而，研究样本量较小，可能限制了结果的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型多模态模型在支持视障人士的现实世界辅助任务中的潜在益处和挑战。

**Method:** 进行了一项包含八名视障参与者的探索性研究，让他们在各种现实世界场景中使用ChatGPT的先进语音和视频功能。

**Result:** ChatGPT的视频功能在静态场景下能有效提供指导和答案，但在动态场景下的实时描述能力不足。尽管存在空间和距离信息不准确的问题，参与者仍能利用这些信息来辅助其移动策略。此外，该系统虽然因高质量的语音交互而具有人性化，但对用户视觉能力的假设、幻觉、通用性回答以及谄媚倾向，导致了混淆、不信任和潜在风险。

**Conclusion:** 目前的实时视频AI在为视障人士提供现实世界援助方面存在差距，尤其是在动态场景的描述能力上。未来的研究应侧重于增强传感能力、优化干预时机、解决生态和安全问题，以开发更有效的辅助视频AI代理。

> **ai_Abstract:** 本研究评估了ChatGPT的实时视频功能在支持视障人士的现实世界辅助任务中的表现。通过一项包含八名视障参与者的探索性研究，发现在静态场景下该技术能提供有效指导，但在动态场景下描述能力不足。研究还指出了该技术在空间感知、信息准确性、用户假设、幻觉和交互模式等方面存在的挑战，并对未来辅助视频AI代理的发展提出了建议。

> **摘要翻译:** 近期大型多模态模型的进展，使得视障（BVI）人士能够通过利用实时视频源的交互式系统，获得解读和与现实世界互动的新能力。然而，这类能力在支持多样化的现实世界辅助任务中的潜在益处和挑战仍然不明确。在本研究中，我们展示了一项包含八名视障参与者的探索性研究结果。参与者在各种现实世界场景中使用了ChatGPT的先进语音和视频功能——一种于2024年末发布的尖端实时视频AI，涵盖了从定位物体到识别视觉地标等任务，涉及不熟悉的室内和室外环境。我们的研究结果表明，当前的实时视频AI能够有效地为静态视觉场景提供指导和答案，但在提供动态情境下必需的实时描述方面则力不从心。尽管在空间和距离信息方面存在不准确之处，参与者仍能利用所提供的视觉信息来补充其移动策略。尽管该系统由于高质量的语音交互而被认为具有人性化，但它对用户视觉能力的假设、产生的幻觉、通用性的回答以及谄媚的倾向，给视障用户带来了困惑、不信任和潜在的风险。基于研究结果，我们讨论了对辅助视频AI代理的启示，包括为现实世界应用整合额外的传感能力、确定超越回合制交互的适当干预时机，以及解决生态和安全问题。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [932] [Aging Up AAC: An Introspection on Augmentative and Alternative Communication Applications for Autistic Adults](https://arxiv.org/abs/2404.17730)
> *衰老AAC：对自闭症成人辅助和替代沟通应用的内省*

*Lara J. Martin, Malathy Nagalakshmi* | **Category: cs.HC, cs.CL** | **Updated: 2025-08-04**

**Keywords:** 辅助和替代沟通, 自闭症成年人, 用户视角, AAC技术, 访谈研究

**Comment:** 

> **TL;DR:** 这项研究通过访谈12名自闭症成人，深入了解了他们在使用辅助和替代沟通（AAC）工具时遇到的问题，并提出了未来技术发展的建议。

**AI_Comments:** 这项研究具有重要意义，因为它关注了在技术设计中常常被忽视的特定用户群体——自闭症成年人。通过用户中心的方法，该研究为开发更有效、更易于使用的AAC工具提供了宝贵的见解。然而，访谈样本量相对较小，未来研究可以扩大样本并纳入更多样化的用户群体。

<details>
  <summary>Details</summary>

**Motivation:** 目前的辅助和替代沟通（AAC）技术在发展时，常常忽略了用户的视角，特别是自闭症成年人在这方面被忽视了。

**Method:** 通过对12名自闭症成年人进行深入访谈，收集他们在使用当前AAC工具时的痛点以及对未来技术改进的期望。

**Result:** 访谈结果归纳为8个主题类别：输入灵活性、输出灵活性、选择或调整AAC、AAC使用情境、益处、成人使用AAC的可及性、持续使用的障碍以及沟通控制。研究还将这些发现与现有文献进行了比较，并指出了新的研究方向。

**Conclusion:** 通过对自闭症成年人的访谈，本研究深入分析了当前AAC工具的不足之处，并提出了未来应关注的改进方向，以更好地满足自闭症成年人的沟通需求。

> **ai_Abstract:** 本研究旨在解决当前辅助和替代沟通（AAC）技术在设计中忽视用户视角，特别是自闭症成年人群体的问题。通过对12名自闭症成年人进行深入访谈，研究者识别了他们在现有AAC工具使用中的痛点，并探讨了他们对未来技术改进的期望。访谈结果被归纳为八个关键主题，涵盖了输入输出灵活性、工具选择与适应、使用情境、实际益处、成人可及性、持续使用障碍以及沟通控制等方面。研究不仅对比了这些发现与现有研究，还提出了新的研究方向，以期推动更符合用户需求的AAC技术发展。

> **摘要翻译:** 近年来，随着像ChatGPT这样的大型语言模型（LLMs）的广泛应用，高科技辅助和替代沟通（AAC）取得了快速发展，但许多这些技术的集成并未纳入用户的视角。自闭症成年人在AAC工具的设计中尤其被忽视。我们对12名自闭症成年人进行了深入访谈，以找出当前AAC的痛点，并确定他们可能认为有用的技术进步。我们从访谈中发现了8个不同的主题类别：输入灵活性、输出灵活性、选择或调整AAC、AAC使用情境、益处、成人使用AAC的可及性、持续使用的障碍以及沟通控制。在本论文中，我们将深入探讨这些类别——将每个类别与先前的工作进行比较——然后强调新的发现，以提出可能的研究方向。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [4] [Learning Multi-Aspect Item Palette: A Semantic Tokenization Framework for Generative Recommendation](https://arxiv.org/abs/2409.07276)
> *学习多维度物品调色板：一种用于生成式推荐的语义分词框架*

*Qijiong Liu, Jieming Zhu, Zhaocheng Du, Lu Fan, Zhou Zhao, Xiao-Ming Wu* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 语义分词, 生成式推荐, 物品调色板, 多维度嵌入, RQ-VAE

**Comment:** 

> **TL;DR:** LAMIA提出了一种新的多维度语义分词方法，通过学习“物品调色板”来克服现有RQ-VAE方法的局限性，并在推荐任务中取得了显著提升。

**AI_Comments:** LAMIA的创新之处在于引入了“物品调色板”的概念，通过学习多维度、独立的语义嵌入来更全面地捕获物品特征，克服了RQ-VAE单一嵌入的局限性。这种多方面表示方法对于提升生成式推荐模型在处理复杂物品信息和泛化能力方面具有重要意义。通过领域特定调优增强语义编码器也进一步提升了嵌入的代表性。

<details>
  <summary>Details</summary>

**Motivation:** 传统推荐模型依赖唯一的物品ID，难以利用物品内容信息并泛化到长尾或冷启动物品。尽管语义分词是解决方案，但现有方法（如RQ-VAE）存在嵌入提取、层次量化和训练稳定性等局限性。

**Method:** 我们提出了LAMIA，一种新颖的多维度语义分词方法。与RQ-VAE不同，LAMIA学习一个“物品调色板”，即一系列独立且语义并行的嵌入，以捕获物品的多个方面。此外，LAMIA通过使用基于文本的重建任务进行领域特定调优，增强了语义编码器，从而产生更具代表性的物品调色板嵌入。

**Result:** 在各种推荐任务和数据集上的广泛实验表明，LAMIA框架在推荐准确性方面比现有方法有显著改进。

**Conclusion:** LAMIA通过引入多维度物品调色板和领域特定调优，有效克服了现有语义分词方法的局限性，显著提高了生成式推荐的准确性。

> **ai_Abstract:** 该论文提出了一种名为LAMIA的新型语义分词框架，用于生成式推荐。针对传统推荐模型和现有语义分词方法（如RQ-VAE）在处理长尾/冷启动物品和其自身局限性（嵌入提取、量化、训练稳定性）方面的问题，LAMIA引入了“物品调色板”概念，学习多维度、独立的语义嵌入来捕获物品的多个方面。同时，通过文本重建任务对语义编码器进行领域特定调优。实验结果表明，LAMIA在推荐准确性上优于现有方法。

> **摘要翻译:** 传统推荐模型通常依赖唯一的物品标识符（ID）来区分物品，这会阻碍它们有效利用物品内容信息并泛化到长尾或冷启动物品的能力。最近，语义分词被提出作为一种有前景的解决方案，旨在将每个物品的语义表示分词为离散的序列。这些语义标记已成为训练生成式推荐模型的基础。然而，现有方法通常依赖于RQ-VAE（一种残差向量量化器）进行语义分词。这种依赖性带来了几个关键限制，包括嵌入提取、层次从粗到细量化以及训练稳定性方面的挑战。为了解决这些问题，我们引入了LAMIA，一种用于多维度语义分词的新方法。与使用单一嵌入的RQ-VAE不同，LAMIA学习一个“物品调色板”——一个由独立且语义并行的嵌入组成的集合，它们捕获物品的多个方面。此外，LAMIA通过使用基于文本的重建任务进行领域特定调优，增强了语义编码器，从而产生更具代表性的物品调色板嵌入。我们进行了广泛的实验，以验证LAMIA框架在各种推荐任务和数据集上的有效性。我们的结果表明，推荐准确性比现有方法有显著改进。为了促进可复现的研究，我们将发布源代码、数据和配置。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [68] [LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference](https://arxiv.org/abs/2505.12260)
> *LightRetriever：一种基于LLM的混合检索架构，查询推理速度提升1000倍*

*Guangyuan Ma, Yongliang Ma, Xuanrui Gou, Zhenpeng Su, Ming Zhou, Songlin Hu* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** LLM, 检索, 混合检索, 查询推理, 效率

**Comment:** 

> **TL;DR:** LightRetriever提出了一种基于LLM的混合检索架构，通过极轻量级的查询编码器，实现了查询推理速度1000倍的提升，同时保持了95%的检索性能。

**AI_Comments:** LightRetriever的核心创新在于其混合检索架构和极轻量级的查询编码器设计。它巧妙地解决了LLM在线检索部署中的效率瓶颈，通过将计算密集型任务（文档编码）离线化，并将实时查询处理简化到极致，实现了显著的速度提升，同时保持了高水平的检索性能。这对于实际应用中LLM的大规模部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在文本检索中显著提升了检索能力，但部署深度参数化的LLMs会导致查询推理吞吐量降低，并增加在线部署的资源需求。

**Method:** 本文提出了LightRetriever，一种新型的基于LLM的检索器，其查询编码器极其轻量。该方法保留了用于文档编码的全尺寸LLM，但将查询编码的工作量减少到仅需一次嵌入查找。

**Result:** 与在A800 GPU上运行完整LLM相比，LightRetriever在查询编码方面实现了超过1000倍的速度提升，在端到端检索吞吐量方面实现了超过10倍的增长。在大型检索基准上的广泛实验表明，LightRetriever在不同任务中表现良好，平均保持了95%的检索性能。

**Conclusion:** LightRetriever通过创新的轻量级查询编码器，显著提升了LLM基检索的效率和吞吐量，同时保持了高水平的检索性能，解决了LLM在线部署的资源和速度瓶颈。

> **ai_Abstract:** LightRetriever是一种创新的基于LLM的混合检索架构，旨在解决现有LLM检索系统中查询推理速度慢和资源消耗大的问题。它通过为文档编码保留一个全尺寸LLM，同时将查询编码简化为仅一次嵌入查找，从而实现了极轻量级的查询编码器。实验证明，LightRetriever在查询编码速度上比使用完整LLM快1000倍，端到端检索吞吐量提升10倍以上，并且在保持平均95%检索性能的同时，在多种任务上表现出良好的泛化能力。

> **摘要翻译:** 大型语言模型（LLMs）的文本检索基于向量相似性检索与搜索查询相关的文档。文档是离线预编码的，而查询是实时到达的，这需要一个高效的在线查询编码器。尽管LLMs显著增强了检索能力，但部署深度参数化的LLMs会降低查询推理吞吐量，并增加在线部署的资源需求。在本文中，我们提出了LightRetriever，一种新型的基于LLM的检索器，其查询编码器极其轻量。我们的方法保留了用于文档编码的全尺寸LLM，但将查询编码的工作量减少到仅需一次嵌入查找。与在A800 GPU上运行完整LLM相比，我们的方法在查询编码方面实现了超过1000倍的速度提升，在端到端检索吞吐量方面实现了超过10倍的增长。在大型检索基准上的广泛实验表明，LightRetriever在不同任务中表现良好，平均保持了95%的检索性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [444] [Reliable Evaluation Protocol for Low-Precision Retrieval](https://arxiv.org/abs/2508.03306)
> *低精度检索的可靠评估协议*

*Kisu Yang, Yoonna Jang, Hwanseok Jang, Kenneth Choi, Isabelle Augenstein, Heuiseok Lim* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 低精度检索, 评估协议, 分数平局, 高精度评分, 平局感知度量

**Comment:** 11 pages, 5 figures, submitted to ARR

> **TL;DR:** 低精度检索中的分数平局导致评估不可靠，本文提出高精度评分和平局感知度量来解决此问题。

**AI_Comments:** 这篇论文解决了低精度检索系统评估中一个实际且重要的问题，即分数平局导致的评估不稳定性。提出的HPS和TRM方法具有创新性，HPS以极小的额外开销解决了平局问题，而TRM则提供了对平局不确定性的量化，这对于理解和改进低精度模型至关重要。其贡献在于提供了一个更可靠的评估框架，有助于推动低精度检索技术的发展和实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 在低精度检索系统中，计算查询与文档之间的相关性分数时，由于粒度降低，会出现虚假平局。这导致结果因平局解决方式而产生高变异性，使得评估的可靠性降低。

**Method:** 提出了一种更鲁棒的检索评估协议，旨在减少分数变异。该协议包括：(1) 高精度评分（HPS），将最终评分步骤提升到更高精度以解决平局候选，计算成本极低；(2) 平局感知检索度量（TRM），报告预期分数、范围和偏差，以量化平局候选的排序不确定性。

**Result:** 实验测试了多种模型、三种评分函数和两个检索数据集，结果表明HPS显著降低了平局引起的不稳定性，TRM准确恢复了预期的度量值。

**Conclusion:** HPS和TRM的结合为低精度检索提供了一个更一致和可靠的评估系统。

> **ai_Abstract:** 本文针对低精度检索系统中因分数平局导致的评估不可靠问题，提出了一种名为“可靠评估协议”的新方法。该协议包含两部分：高精度评分（HPS）通过提升最终评分精度来解决平局，同时保持低计算成本；平局感知检索度量（TRM）则量化平局候选的排序不确定性。实验证明，该协议显著提高了低精度检索评估的一致性和可靠性。

> **摘要翻译:** 降低模型参数和计算的数值精度被广泛用于提高检索系统的效率。然而，在低精度下计算查询和文档之间的相关性分数时，我们观察到由于粒度降低而导致的虚假平局。这导致结果因平局解决方式而产生高变异性，使得评估的可靠性降低。为了解决这个问题，我们提出了一种更鲁棒的检索评估协议，旨在减少分数变异。它包括：(1) 高精度评分（HPS），将最终评分步骤提升到更高精度以解决平局候选，计算成本极低；(2) 平局感知检索度量（TRM），报告预期分数、范围和偏差，以量化平局候选的排序不确定性。我们的实验在两个检索数据集上测试了多种模型和三种评分函数，以证明HPS显著降低了平局引起的不稳定性，并且TRM准确恢复了预期的度量值。这种组合为低精度检索提供了一个更一致和可靠的评估系统。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [465] [Realizing Scaling Laws in Recommender Systems: A Foundation-Expert Paradigm for Hyperscale Model Deployment](https://arxiv.org/abs/2508.02929)
> *在推荐系统中实现扩展定律：一种用于超大规模模型部署的基础-专家范式*

*Dai Li, Kevin Course, Wei Li, Hongwei Li, Jie Hua, Yiqi Chen, Zhao Zhu, Rui Jian, Xuan Cao, Bi Xue, Yu Shi, Jing Qian, Kai Ren, Matt Ma, Qunshu Zhang, Rui Li* | **Category: cs.IR, cs.AI, cs.LG, 68T05, 68T07, 68T30, H.3.3; I.2.6** | **Updated: 2025-08-04**

**Keywords:** 推荐系统, 扩展定律, 基础-专家范式, 超大规模部署, HyperCast

**Comment:** 

> **TL;DR:** 提出并部署了基础-专家范式，以在推荐系统中实现超大规模模型的扩展定律，解决了部署挑战并取得了实际效果。

**AI_Comments:** 这项工作的创新之处在于将基础-专家范式成功应用于超大规模推荐系统，克服了该领域特有的挑战。其重要性在于提供了一个经过验证、计算高效且开发人员友好的部署蓝图，为未来推荐系统的大规模发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩展定律承诺推荐系统性能显著提升，但高效部署超大规模模型仍是未解决的重大挑战，因为推荐系统面临在线流数据、数据分布变化、不同推荐界面、严格延迟和计算限制等独特挑战。

**Method:** 提出“基础-专家范式”，其中一个中心基础模型（FM）通过终身、跨界面、多模态用户数据学习通用知识，然后通过目标感知嵌入高效地将知识转移到轻量级、特定界面的“专家”模型。为此，他们构建了生产级基础设施系统HyperCast。

**Result:** 该方法已在Meta部署，每天处理数百亿用户请求，相比之前的单阶段生产系统，在线指标有所改进，同时提高了开发人员速度并保持了基础设施效率。

**Conclusion:** 这项工作代表了首次成功部署大规模基础-专家范式，提供了一个经过验证、计算高效且开发人员友好的蓝图，以实现在推荐系统中扩展定律的承诺。

> **ai_Abstract:** 本文提出并实现了“基础-专家范式”来解决推荐系统中超大规模模型部署的挑战。该范式通过训练一个学习通用知识的基础模型，并将其高效转移到轻量级专家模型来适应特定任务。为支持此范式，他们构建了生产级系统HyperCast。该方法已在Meta部署，显著提升了在线指标、开发效率和基础设施效率，是首次成功大规模应用此范式。

> **摘要翻译:** 尽管扩展定律有望为推荐系统带来显著的性能提升，但高效部署超大规模模型仍然是一个尚未解决的重大挑战。与自然语言处理和计算机视觉等领域中基础模型（FMs）已广泛采用的情况不同，推荐系统的进展受到独特挑战的阻碍，包括需要在不断变化的数据分布下从在线流数据中学习、需要适应具有广泛下游任务和输入分布多样性的不同推荐界面，以及严格的延迟和计算限制。为了弥合这一差距，我们提出利用基础-专家范式：一个为开发和部署超大规模推荐基础模型而设计的框架。在我们的方法中，一个中心基础模型通过终身、跨界面、多模态用户数据进行训练，以学习通用知识。然后，这些知识通过目标感知嵌入高效地转移到各种轻量级、特定界面的“专家”模型中，使它们能够以最小的开销适应本地数据分布和优化目标。为了满足我们的训练、推理和开发需求，我们构建了HyperCast，一个生产级基础设施系统，它重新设计了训练、服务、日志记录和迭代，以支持这种解耦范式。我们的方法目前已在Meta部署，每天处理数百亿用户请求，与我们之前的单阶段生产系统相比，在线指标有所改进，同时提高了开发人员速度并保持了基础设施效率。据我们所知，这项工作代表了首次在此规模上成功部署基础-专家范式，提供了一个经过验证、计算高效且开发人员友好的蓝图，以实现在推荐系统中扩展定律的承诺。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [500] [LLM-based IR-system for Bank Supervisors](https://arxiv.org/abs/2508.02945)
> *面向银行监管者的基于LLM的信息检索系统*

*Ilias Aarab* | **Category: cs.IR, cs.AI, cs.LG, stat.AP, stat.CO, 68P20, 68T50, 68T05, 62P20, 91G80, H.3.3; I.2.6; I.2.7; J.1** | **Updated: 2025-08-04**

**Keywords:** LLM, 信息检索, 银行监管, 金融科技, Transformer

**Comment:** 

> **TL;DR:** 本文提出了一个基于LLM的信息检索系统，旨在帮助银行监管者通过检索相关的历史发现来起草一致的措施。

**AI_Comments:** 这项工作通过将多种匹配技术（词汇、语义、模糊集）与Transformer-based Denoising AutoEncoder相结合，为银行监管这一特定领域提供了一个创新且高效的解决方案。其在关键指标上的出色表现，特别是超越了现有基线模型，证明了其在实际应用中的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 银行监管者面临一项复杂的任务，即确保新措施与历史先例保持一致。为了解决这一挑战，本文引入了一个新颖的信息检索系统。

**Method:** 该系统接收现场调查结果，然后从综合数据库中检索最相关的历史发现及其相关措施。它利用词汇、语义和资本要求条例（CRR）模糊集匹配技术的结合。最终模型通过Transformer-based Denoising AutoEncoder进行微调，并通过蒙特卡洛方法验证了其性能。

**Result:** 该系统实现了0.83的平均精度均值（MAP@100）和0.92的平均倒数排名（MRR@100）。这些分数超过了独立的词汇模型（如BM25）和语义BERT类模型。

**Conclusion:** 本文提出的基于LLM的信息检索系统在协助银行监管者方面表现出强大的鲁棒性和准确性，并且其性能优于传统的词汇和语义模型。

> **ai_Abstract:** 本文介绍了一种新颖的基于LLM的信息检索（IR）系统，旨在帮助银行监管者起草一致且有效的措施。该系统能够摄取现场调查结果，并从数据库中检索相关的历史发现及其措施。它结合了词汇、语义和CRR模糊集匹配技术，并通过Transformer-based Denoising AutoEncoder进行微调。该系统在蒙特卡洛方法验证下表现出鲁棒性，并在部分标记数据场景中实现了0.83的MAP@100和0.92的MRR@100，优于BM25和BERT类模型。

> **摘要翻译:** 银行监管者面临一项复杂的任务，即确保新措施与历史先例保持一致。为了应对这一挑战，我们引入了一种新颖的信息检索（IR）系统，旨在协助监管者起草一致且有效的措施。该系统接收现场调查结果。然后，它从综合数据库中检索最相关的历史发现及其相关措施，为监管者针对新发现撰写充分知情的措施提供了坚实的基础。该IR系统利用词汇、语义和资本要求条例（CRR）模糊集匹配技术的结合，确保检索到的发现与当前案例紧密对齐。该系统的性能，特别是在部分标记数据的情况下，通过蒙特卡洛方法进行了验证，展示了其鲁棒性和准确性。通过基于Transformer的去噪自编码器进行微调，最终模型实现了0.83的平均精度均值（MAP@100）和0.92的平均倒数排名（MRR@100）。这些分数超过了独立的词汇模型（如BM25）和语义BERT类模型。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [531] [SustainableQA: A Comprehensive Question Answering Dataset for Corporate Sustainability and EU Taxonomy Reporting](https://arxiv.org/abs/2508.03000)
> *SustainableQA：一个针对企业可持续发展和欧盟分类报告的综合问答数据集*

*Mohammed Ali, Abdelrahman Abdallah, Adam Jatowt* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 可持续发展, 问答数据集, 欧盟分类, 大型语言模型, 数据提取

**Comment:** 

> **TL;DR:** 引入了SustainableQA，一个用于企业可持续发展报告的综合问答数据集和生成管道，以支持LLM和RAG系统进行数据提取和合规导航。

**AI_Comments:** 该论文通过引入一个大规模、领域特定的问答数据集SustainableQA，解决了企业可持续发展报告中数据提取的关键需求，尤其是在欧盟分类等新法规背景下。其创新之处在于结合了多种技术（语义分类、混合跨度提取、LLM细化和表格转换）来高效生成高质量数据。这对于推动LLM和RAG系统在企业可持续发展领域的应用具有重要意义，有助于提高数据透明度和合规性。

<details>
  <summary>Details</summary>

**Motivation:** 企业可持续发展透明度的需求日益增长，尤其是在欧盟分类等新法规下，需要从大量非结构化企业报告中精确提取数据。大型语言模型（LLMs）和检索增强生成（RAG）系统需要高质量、领域特定的问答（QA）数据集才能在特定领域表现出色。

**Method:** 引入了SustainableQA，一个新颖的数据集和可扩展的管道，用于从企业可持续发展报告和年度报告中生成综合问答数据集。其方法集成了语义块分类、结合了微调命名实体识别（NER）、基于规则的方法和LLM驱动的细化的混合跨度提取管道，以及专门的表格到段落转换。

**Result:** SustainableQA包含超过195,000个多样化的事实型和非事实型问答对。

**Conclusion:** SustainableQA是一个有效的资源，可用于开发和基准测试能够处理复杂可持续发展合规性的高级知识助手。

> **ai_Abstract:** 该论文介绍了SustainableQA，一个旨在解决企业可持续发展报告数据提取挑战的综合问答数据集。随着欧盟分类等新法规的出现，对精确数据提取的需求增加，而现有的LLM和RAG系统缺乏高质量、领域特定的QA数据集。SustainableQA通过一个可扩展的管道创建，该管道结合了语义块分类、混合跨度提取（NER、规则和LLM细化）以及表格到段落的转换。该数据集包含超过195,000个多样化的问答对，是开发和评估用于可持续发展合规性的知识助手的宝贵资源。

> **摘要翻译:** 对企业可持续发展透明度日益增长的需求，特别是在欧盟分类等新法规下，使得从大型非结构化企业报告中精确提取数据变得必要。大型语言模型（LLMs）和检索增强生成（RAG）系统需要高质量、领域特定的问答（QA）数据集才能在特定领域表现出色。为了解决这个问题，我们引入了SustainableQA，这是一个新颖的数据集和可扩展的管道，用于从企业可持续发展报告和年度报告中生成全面的问答数据集。我们的方法集成了语义块分类、结合了微调命名实体识别（NER）、基于规则的方法和LLM驱动的细化的混合跨度提取管道，以及专门的表格到段落转换。SustainableQA拥有超过195,000个多样化的事实型和非事实型问答对，是开发和基准测试能够处理复杂可持续发展合规性的高级知识助手的有效资源。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [568] [KBest: Efficient Vector Search on Kunpeng CPU](https://arxiv.org/abs/2508.03016)
> *KBest：鲲鹏CPU上的高效向量搜索*

*Kaihao MA, Meiling Wang, Senkevich Oleg, Zijian LI, Daihao Xue, Dmitriy Malyshev, Yangming Lv, Shihai Xiao, Xiao Yan, Radionov Alexander, Weidi Zeng, Yuanzhan Gao, Zhiyu Zou, Yao xin, Liu Lin, Junhao Wu, Yiding Liu, Yaoyao Fu, Gongyi Wang, Gong Zhang, Fei Yi, Yingfan Liu* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 向量搜索, 鲲鹏CPU, ARM架构, 硬件优化, KBest

**Comment:** 

> **TL;DR:** KBest是一个为华为鲲鹏920 CPU优化的向量搜索库，通过多种硬件感知和算法优化，实现了比x86 SOTA库更高的查询吞吐量。

**AI_Comments:** KBest的创新之处在于其针对特定硬件架构（鲲鹏ARM CPU）进行深度优化，而非通用优化。这对于充分利用特定硬件的计算能力至关重要，尤其是在当前异构计算日益普及的背景下。其强调硬件感知优化，并通过实际应用证明了其在吞吐量上的显著提升，显示了其重要的工程和商业价值。

<details>
  <summary>Details</summary>

**Motivation:** 向量搜索在许多应用中至关重要，但现有向量搜索库主要针对x86 CPU优化。华为鲲鹏CPU基于ARM架构且计算能力强劲，需要一个为其量身定制的高效向量搜索库。

**Method:** 提出了KBest，一个专为最新鲲鹏920 CPU设计的向量搜索库。KBest集成了广泛的硬件感知和算法优化，包括单指令多数据（SIMD）加速距离计算、数据预取、索引优化、提前终止和向量量化。

**Result:** 实验结果表明，KBest在鲲鹏CPU上运行优于x86 CPU上的SOTA向量搜索库，并且其优化可以将查询吞吐量提高2倍以上。

**Conclusion:** KBest是一个高效且实用的向量搜索库，专门为鲲鹏CPU优化，已成功应用于内部业务和外部企业客户，每天处理数千万次查询。

> **ai_Abstract:** 本文介绍了KBest，一个为华为鲲鹏920 CPU设计的向量搜索库。针对现有向量搜索库主要优化x86架构的问题，KBest通过SIMD加速距离计算、数据预取、索引优化、提前终止和向量量化等多种硬件感知和算法优化，显著提升了在ARM架构上的效率。实验证明，KBest的性能超越了x86上的SOTA库，查询吞吐量提升超过2倍，并已在实际业务中大规模应用。

> **摘要翻译:** 向量搜索，即从大型向量数据集中返回与给定查询向量最相似的向量，是搜索、推荐和大型语言模型等许多重要应用的基础。为了经济性，向量搜索需要高效以减少给定查询工作负载所需的资源。然而，现有向量搜索库（例如Faiss和DiskANN）针对x86 CPU架构（即英特尔和AMD CPU）进行了优化，而华为鲲鹏CPU基于ARM架构并在计算能力方面具有竞争力。在本文中，我们提出了KBest，一个专为最新鲲鹏920 CPU量身定制的向量搜索库。为了提高效率，KBest融合了广泛的硬件感知和算法优化，其中包括单指令多数据（SIMD）加速距离计算、数据预取、索引优化、提前终止和向量量化。实验结果表明，KBest在鲲鹏CPU上的性能优于在x86 CPU上运行的SOTA向量搜索库，并且我们的优化可以将查询吞吐量提高2倍以上。目前，KBest每天为我们内部业务和外部企业客户的应用程序提供服务，处理数千万次查询。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [597] [ADSeeker: A Knowledge-Infused Framework for Anomaly Detection and Reasoning](https://arxiv.org/abs/2508.03088)
> *ADSeeker：一个用于异常检测和推理的知识注入框架*

*Kai Zhang, Zekai Zhang, Xihe Sun, Jingmeng Nie, Qinghui Chen, Han Hao, Jianyuan Guo, Jinglin Zhang* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 异常检测, 知识注入, 多模态大语言模型, 零样本学习, 知识库

**Comment:** 

> **TL;DR:** ADSeeker是一个知识驱动的异常任务助手，通过构建视觉文档知识库SEEK-M&V、引入Q2K RAG框架、分层稀疏提示机制和最大的异常检测数据集MulA，显著提升了多模态大语言模型在工业异常检测中的零样本性能。

**AI_Comments:** ADSeeker的创新点在于其知识注入方法，通过构建结构化的视觉文档知识库（SEEK-M&V）和提出高效的知识检索框架（Q2K RAG），弥补了MLLMs在异常检测领域知识的不足。此外，引入大规模多类型异常数据集MulA对于解决工业AD数据稀缺问题具有重要意义，并推动了零样本异常检测的发展。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在自动视觉检测中表现出强大的语言理解能力，但其在异常检测（AD）任务中的表现远低于人类专家。主要挑战在于：(i) 预训练期间异常检测知识整合不足；(ii) 异常推理缺乏技术精确和上下文感知的语言生成。

**Method:** 提出ADSeeker，一个异常任务助手，通过知识驱动推理增强检测性能。它利用构建的视觉文档知识库SEEK-MVTec&VisA (SEEK-M&V)，该知识库包含语义丰富的描述和图像-文档对。为有效检索和利用知识，引入查询图像-知识检索增强生成（Q2K RAG）框架。为增强零样本异常检测（ZSAD）性能，ADSeeker利用分层稀疏提示机制和类型级特征来高效提取异常模式。此外，引入了最大的AD数据集Multi-type Anomaly (MulA)，包含26个类别72种多尺度缺陷类型。

**Result:** ADSeeker框架在多个基准数据集上实现了最先进的零样本性能。

**Conclusion:** ADSeeker通过整合领域知识、创新的知识检索机制和大规模数据集，有效提升了多模态大语言模型在工业异常检测任务中的性能，达到了最先进的零样本效果。

> **ai_Abstract:** 本文提出了ADSeeker，一个知识注入框架，旨在解决多模态大语言模型在工业异常检测中知识整合不足和推理语言生成不精确的问题。ADSeeker通过构建包含语义丰富描述的视觉文档知识库SEEK-M&V，并引入Q2K RAG框架进行知识检索。为了提升零样本异常检测性能，它还利用分层稀疏提示机制和类型级特征。同时，作者构建了迄今为止最大的异常检测数据集MulA。实验证明，ADSeeker在多个基准数据集上达到了最先进的零样本性能。

> **摘要翻译:** 自动视觉检测在工业检测中具有重要意义。尽管多模态大语言模型（MLLMs）表现出强大的语言理解能力，并有望胜任此任务，但其性能仍显著低于人类专家。在此背景下，我们确定了两个关键挑战：(i) 预训练期间异常检测（AD）知识整合不足；(ii) 异常推理缺乏技术精确和上下文感知的语言生成。为解决这些问题，我们提出了ADSeeker，一个异常任务助手，旨在通过知识驱动的推理来提升检测性能。ADSeeker利用我们构建的精选视觉文档知识库SEEK-MVTec&VisA (SEEK-M&V)，以解决现有仅依赖非结构化文本资源的局限性。SEEK-M&V包含语义丰富的描述和图像-文档对，从而实现更全面的异常理解。为有效检索和利用这些知识，我们引入了查询图像-知识检索增强生成（Q2K RAG）框架。为进一步提升零样本异常检测（ZSAD）的性能，ADSeeker利用分层稀疏提示机制和类型级特征来高效提取异常模式。此外，为应对工业异常检测（IAD）数据有限的挑战，我们引入了最大规模的AD数据集Multi-type Anomaly (MulA)，该数据集涵盖26个类别中72种多尺度缺陷类型。广泛的实验表明，我们的即插即用框架ADSeeker在多个基准数据集上实现了最先进的零样本性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [618] [MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation](https://arxiv.org/abs/2508.03553)
> *MultiRAG：一种知识引导的多源检索增强生成中缓解幻觉的框架*

*Wenlong Wu, Haofen Wang, Bohan Li, Peixuan Huang, Xinzhe Zhao, Lei Liang* | **Category: cs.IR, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 检索增强生成, 幻觉, 多源, 知识引导, MultiRAG

**Comment:** Accepted by ICDE 2025 Research Paper

> **TL;DR:** MultiRAG是一个知识引导的框架，通过构建知识图谱和多级置信度计算来缓解多源RAG中的幻觉问题，提高知识检索的可靠性和效率。

**AI_Comments:** 该论文提出了一种创新的知识引导框架MultiRAG，通过结合图结构来处理多源数据的逻辑关系和不一致性，有效缓解了RAG模型在多源场景下易产生的幻觉问题。其双模块设计，特别是多级置信度计算机制，为提升多源信息整合的可靠性提供了新的思路，具有较高的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管检索增强生成（RAG）有助于解决大型语言模型（LLMs）的幻觉问题，但整合多个检索源反而会加剧幻觉。这主要源于多源数据的稀疏分布（阻碍逻辑关系捕获）和不同源间固有的不一致性（导致信息冲突）。

**Method:** 我们提出了MultiRAG框架，通过知识引导的方法来缓解多源RAG中的幻觉。该框架包含两项核心创新：1) 一个知识构建模块，利用多源线图高效聚合不同知识源间的逻辑关系，从而解决数据稀疏分布问题；2) 一个复杂的检索模块，实现了多级置信度计算机制，进行图级和节点级评估，以识别并消除不可靠信息节点，从而减少源间不一致导致的幻觉。

**Result:** 在四个多领域查询数据集和两个多跳QA数据集上进行的广泛实验表明，MultiRAG显著增强了复杂多源场景下知识检索的可靠性和效率。

**Conclusion:** MultiRAG通过知识引导的方法，成功解决了多源检索增强生成中的幻觉问题，显著提高了知识检索的可靠性和效率。

> **ai_Abstract:** MultiRAG是一个新颖的知识引导框架，旨在解决多源检索增强生成（RAG）中由数据稀疏和源间不一致引起的幻觉问题。它通过引入知识构建模块（利用多源线图聚合逻辑关系）和检索模块（采用多级置信度计算机制识别并消除不可靠信息）来缓解这些挑战。实验证明，MultiRAG显著提升了复杂多源场景下知识检索的可靠性和效率。

> **摘要翻译:** 检索增强生成（RAG）已成为解决大型语言模型（LLMs）幻觉问题的一个有前景的解决方案。然而，整合多个检索源虽然可能提供更多信息，却引入了新的挑战，反而可能加剧幻觉问题。这些挑战主要体现在两个方面：多源数据的稀疏分布阻碍了逻辑关系的捕获，以及不同源之间固有的不一致性导致信息冲突。为了解决这些挑战，我们提出了MultiRAG，一个新颖的框架，旨在通过知识引导的方法缓解多源检索增强生成中的幻觉。我们的框架引入了两项关键创新：（1）一个知识构建模块，采用多源线图高效聚合不同知识源之间的逻辑关系，有效解决了数据稀疏分布问题；（2）一个复杂的检索模块，实现了多级置信度计算机制，执行图级和节点级评估，以识别并消除不可靠的信息节点，从而减少由源间不一致引起的幻觉。在四个多领域查询数据集和两个多跳QA数据集上进行的广泛实验表明，MultiRAG显著增强了复杂多源场景下知识检索的可靠性和效率。我们的代码可在https://github.com/wuwenlong123/MultiRAG获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [637] [Dual-disentangle Framework for Diversified Sequential Recommendation](https://arxiv.org/abs/2508.03172)
> *用于多样化序列推荐的双重解耦框架*

*Haoran Zhang, Jingtong Liu, Jiangzhou Deng, Junpeng Guo* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 序列推荐, 双重解耦, 多样性, 用户兴趣, 意图建模

**Comment:** 

> **TL;DR:** DDSRec是一个双重解耦框架，旨在通过解耦用户兴趣和意图来解决序列推荐中准确性和多样性之间的平衡问题。

**AI_Comments:** DDSRec的创新点在于其双重解耦框架，它解决了序列推荐中长期存在的准确性和多样性之间的权衡问题。通过在交互和表示层面进行解耦，该方法能够更精细地捕捉用户偏好，对于提升推荐系统的用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 序列推荐面临用户交互序列长度增长以及用户兴趣和意图复杂纠缠带来的多样性挑战。

**Method:** 提出了一种与模型无关的DDSRec（Dual-disentangle framework for Diversified Sequential Recommendation）框架。该框架通过在交互建模和表示学习中采用解耦视角，细化用户兴趣和意图建模。

**Result:** 在多个公共数据集上的大量实验证明了DDSRec在序列推荐的准确性和多样性方面的有效性和优越性。

**Conclusion:** DDSRec框架通过双重解耦方法，有效提升了序列推荐在准确性和多样性上的表现。

> **ai_Abstract:** 本文提出了DDSRec（Dual-disentangle framework for Diversified Sequential Recommendation）框架，旨在解决序列推荐中因用户兴趣和意图复杂纠缠导致的多样性挑战。DDSRec通过在交互建模和表示学习中采用双重解耦视角来细化用户兴趣和意图建模，从而在准确性和多样性之间取得平衡。实验结果表明，该框架在多个数据集上表现出优越的性能。

> **摘要翻译:** 序列推荐预测用户随时间变化的偏好，并取得了显著成功。然而，用户交互序列长度的增长以及不断演变的用户兴趣和意图的复杂纠缠，给多样性带来了重大挑战。为了解决这些问题，我们提出了一种与模型无关的用于多样化序列推荐的双重解耦框架（DDSRec）。该框架通过在交互建模和表示学习中采用解耦视角，细化用户兴趣和意图建模，从而平衡序列推荐中的准确性和多样性。在多个公共数据集上的大量实验证明了DDSRec在序列推荐的准确性和多样性方面的有效性和优越性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [652] [PyLate: Flexible Training and Retrieval for Late Interaction Models](https://arxiv.org/abs/2508.03555)
> *PyLate：Late Interaction模型的灵活训练与检索*

*Antoine Chaffin, Raphaël Sourty* | **Category: cs.IR, cs.CL** | **Updated: 2025-08-05**

**Keywords:** Late Interaction, Multi-vector models, PyLate, Information Retrieval, Sentence Transformers

**Comment:** 5 pages

> **TL;DR:** PyLate是一个基于Sentence Transformers的库，用于简化和加速Late Interaction模型（如ColBERT）的训练和检索，解决了现有工具的不足，并已成功应用于开发先进模型。

**AI_Comments:** PyLate库的推出解决了Late Interaction模型在实际应用中的一个关键瓶颈，即缺乏易用且高效的工具支持。该库的模块化设计和对现有框架（如Sentence Transformers）的兼容性，预示着它将极大地促进相关领域的研究和发展。其在支持先进模型开发方面的成功案例，也为其可靠性和有效性提供了有力证明。然而，未来可以关注其在处理更大规模数据集和更多样化检索任务时的性能表现及可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 单向量检索模型在处理域外、长上下文和推理密集型检索任务时存在性能瓶颈。多向量方法（如ColBERT）虽有理论和实践优势，但因缺乏易用、模块化的工具而普及度不高。PyLate旨在弥补这一差距，降低Late Interaction模型的应用门槛。

**Method:** PyLate是一个建立在Sentence Transformers之上的库，专门支持多向量架构。它提供了高效的训练、日志记录、模型卡片生成以及多向量特有的高效索引等功能，并要求用户仅需少量修改即可适应现有代码模板。

**Result:** PyLate已成功支持了GTE-ModernColBERT和Reason-ModernColBERT等先进模型的开发，展示了其在研究和生产环境中的实用性，并加速了Late Interaction模型在现代信息检索系统中的研究和应用。

**Conclusion:** PyLate通过提供一个易于使用、功能丰富的库，有效解决了Late Interaction模型在训练和检索方面的挑战，有望加速这些模型的广泛采用和发展。

> **ai_Abstract:** PyLate是一个新推出的库，旨在简化和加速Late Interaction模型（如ColBERT）的训练和检索过程。该库基于Sentence Transformers构建，提供了对多向量架构的原生支持，包括高效训练、日志记录、模型卡片生成以及专门的多向量索引。通过这些功能，PyLate解决了现有工具链的不足，降低了Late Interaction模型的应用门槛，并已成功应用于开发先进模型，如GTE-ModernColBERT和Reason-ModernColBERT，显示出其在研究和实际应用中的巨大潜力。

> **摘要翻译:** 神经检索已成为现代信息检索的基石。虽然单一向量搜索仍然是主导范式，但它存在将所有信息压缩到单个向量中的缺点。这种压缩会导致在域外、长上下文和推理密集型检索任务中出现明显的性能下降。ColBERT等开创的多向量方法旨在通过保留单个词嵌入并通过MaxSim算子计算相似性来解决这些限制。这种架构已显示出优越的实证优势，包括增强的域外泛化能力、长上下文处理能力以及在复杂检索场景中的性能。尽管有这些令人信服的实证结果和清晰的理论优势，但与单一向量模型相比，Late Interaction模型的实际采用和公开可用性仍然很低，这主要是由于缺乏用于训练和试验此类模型的易于访问和模块化的工具。为了弥合这一差距，我们引入了PyLate，一个建立在Sentence Transformers之上的简化库，用于原生支持多向量架构，继承了其高效的训练、先进的日志记录和自动化的模型卡片生成，同时仅需对用户熟悉的代码模板进行最少的代码更改。通过提供多向量特有的功能，如高效索引，PyLate旨在加速Late Interaction模型的研究和实际应用，从而释放它们在现代IR系统中的全部潜力。最后，PyLate已经支持了包括GTE-ModernColBERT和Reason-ModernColBERT在内的最先进模型的开发，证明了其在研究和生产环境中的实际效用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [681] [Parameter-Efficient Single Collaborative Branch for Recommendation](https://arxiv.org/abs/2508.03518)
> *面向推荐的参数高效单一协作分支*

*Marta Moscati, Shah Nawaz, Markus Schedl* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 推荐系统, 权重共享, 参数高效, 协作过滤, 神经网络

**Comment:** 5 pages

> **TL;DR:** 提出了一种名为CoBraR的新推荐系统框架，通过在用户和物品的神经网络模块之间共享权重，减少参数数量，并在不损害准确性的前提下改善了准确性以外的方面，适用于现实场景。

**AI_Comments:** 该研究提出了一种创新的参数共享方法（CoBraR），用于推荐系统中的用户和物品表示学习，有效地减少了模型参数并提高了效率，同时保持了准确性。其在现实场景中的应用潜力值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现代推荐系统依赖于联合嵌入空间中的用户和物品表示以及相似性度量来计算相关性得分。在多模态表示学习中，权重共享已被证明在减少同一物品的多个模态之间的距离方面是有效的。受这些方法的启发，我们提出了一种新颖的推荐系统，它利用用户和物品神经网络模块之间的权重共享来获取共享嵌入空间中的潜在表示。

**Method:** 提出了一种名为CoBraR（面向推荐的单一协作分支）的新型推荐系统框架，该框架通过在用于获取共享嵌入空间中潜在表示的用户和物品神经网络模块之间共享权重来实现。

**Result:** 通过在电子商务和电影推荐方面的定量实验评估，结果表明CoBraR通过减少参数数量和改善准确性以外的方面（如效率），同时不损害准确性，展现了其在现实场景中的应用和扩展潜力。

**Conclusion:** CoBraR通过参数共享有效减少了模型参数，并在不影响准确性的情况下提高了效率，具有在现实世界推荐场景中应用和扩展的潜力。

> **ai_Abstract:** 本研究提出了一种名为CoBraR的新型推荐系统框架，其核心在于用户和物品表示学习的神经网络模块之间采用权重共享机制。这种设计旨在减少模型参数数量，并提高效率，同时保持甚至超越现有方法的准确性。通过在电子商务和电影推荐任务上的实验验证，CoBraR显示出其在实际应用中的潜力和可扩展性。

> **摘要翻译:** 推荐系统（RS）通常依赖于联合嵌入空间中的用户和物品表示以及计算相关性得分的相似性度量。在现代推荐系统中，获取用户和物品表示的模块由两个独立的神经网络（NN）组成。在多模态表示学习中，权重共享已被证明在减少同一物品的多个模态之间的距离方面是有效的。受这些方法的启发，我们提出了一种新颖的推荐系统，它利用用户和物品神经网络模块之间的权重共享来获取共享嵌入空间中的潜在表示。我们提出的框架由一个单一的面向推荐的协作分支（CoBraR）组成。我们通过在电子商务和电影推荐方面的定量实验来评估CoBraR。我们的实验表明，通过减少参数数量和在不损害准确性的前提下改善超越准确性方面的性能，CoBraR有潜力应用于现实场景并进行扩展。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [722] [Demystifying Sequential Recommendations: Counterfactual Explanations via Genetic Algorithms](https://arxiv.org/abs/2508.03606)
> *揭秘序列推荐：通过遗传算法实现的对策性解释*

*Domiziano Scarcelli, Filippo Betello, Giuseppe Perelli, Fabrizio Silvestri, Gabriele Tolomei* | **Category: cs.IR** | **Updated: 2025-08-05**

**Keywords:** 序列推荐, 对策性解释, 遗传算法, 可解释性, NP-完全

**Comment:** 

> **TL;DR:** 该研究提出了首个针对序列推荐系统（SRS）的对策性解释技术，使用专门的遗传算法来寻找用户交互历史的最小改变，以获得不同推荐结果，并证明了该问题是NP-完全的。实验证明该方法能生成有意义且可解释的对策性解释，同时保持模型保真度。

**AI_Comments:** 这项研究在序列推荐系统的可解释性领域取得了重要进展，通过引入对策性解释来解决“黑箱”问题。使用遗传算法来解决这是一个创新的方法，并且证明该问题是NP-完全的也为未来的研究提供了理论基础。然而，在实际应用中，遗传算法的计算成本和解释的实际可操作性可能需要进一步的考虑。

<details>
  <summary>Details</summary>

**Motivation:** 序列推荐系统（SRS）作为“黑箱”模型，其可解释性不足，难以理解用户偏好的演变。

**Method:** 提出了一种专门针对离散序列的遗传算法，用于生成序列推荐系统的对策性解释，并证明了该问题的NP-完全性。

**Result:** 所提出的方法在四个实验设置、三个数据集和三个模型上进行了评估，成功生成了可解释的对策性解释，同时将模型保真度保持在接近1的水平。

**Conclusion:** 该研究为理解序列推荐决策提供了一个“假设”场景的框架，通过生成对策性解释来增强用户信任和系统透明度。

> **ai_Abstract:** 这项研究提出了一个新颖的对策性解释框架，专门用于解决序列推荐系统（SRS）的可解释性挑战。通过使用一种定制的遗传算法，该方法旨在识别用户互动历史中的最小更改，从而导致不同的推荐结果。研究人员证明了为序列数据生成此类解释是一个NP-完全问题，并通过在各种实验设置、数据集和模型上的评估，展示了其生成有意义且可解释的对策性解释的能力，同时保持高模型保真度。这项工作为增强用户信任和系统透明度通过“假设”分析来理解SRS决策铺平了道路。

> **摘要翻译:** 序列推荐系统（SRS）在捕捉用户不断发展的偏好方面表现出卓越的有效性。然而，它们作为“黑箱”模型的内在复杂性给可解释性带来了重大挑战。这项工作提出了第一个专门为SRS设计的对策性解释技术，在该领域引入了一种新颖的方法，解决了关键问题：用户互动历史的哪些最小变化会导致不同的推荐？为了实现这一点，我们引入了一种专门为离散序列设计的遗传算法，并表明为序列数据生成对策性解释是一个NP-完全问题。我们在四个实验设置中评估了这些方法，这些设置在目标-非目标和分类-非分类场景之间变化，以全面评估它们在生成有意义的解释方面的能力。使用三个不同的数据集和三个模型，我们能够证明我们的方法成功地生成了可解释的对策性解释，同时将模型保真度保持在接近1的水平。我们的研究结果通过提供一个框架来理解序列推荐决策，通过“假设”场景的视角，最终增强用户信任和系统透明度，为可解释人工智能的不断增长的领域做出了贡献。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [763] [LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay](https://arxiv.org/abs/2508.03628)
> *使用交叉编码器从LLM信号中提炼LLMDistill4Ads，用于eBay的广告商关键词推荐*

*Soumik Dey, Benjamin Braun, Naveen Ravipati, Hansi Wu, Binbin Li* | **Category: cs.IR, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** LLM蒸馏, 交叉编码器, 双编码器, 关键词推荐, eBay

**Comment:** 

> **TL;DR:** eBay使用LLM作为裁判来推荐广告商关键词，通过交叉编码器蒸馏LLM信号到双编码器学生模型，以提高检索相关关键词的性能。

**AI_Comments:** 这项研究有效地利用了LLM的判断能力来改进广告商关键词推荐，解决了大规模负面人类判断的获取难题。通过交叉编码器进行知识蒸馏，并结合多任务训练，显著提升了双编码器模型在检索相关关键词方面的性能，为在线广告平台提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** eBay的广告商需要推荐相关的关键词来提高广告效果，同时避免搜索系统拥挤和维持卖家声誉。然而，难以获得大规模的负面人类判断，因此使用LLM作为裁判来模仿卖家判断已成为一种常用方法。

**Method:** 提出了一种新颖的两步LLM蒸馏过程，使用交叉编码器作为助手，将LLM教师的信号提炼到一个双编码器学生模型中，并采用多任务训练方法，最终使用学生双编码器来检索相关的广告商关键词。

**Result:** 将来自LLM的知识蒸馏过程整合到多任务训练设置中，可以提高双编码器在eBay上检索相关广告商关键词的性能。

**Conclusion:** 通过LLM蒸馏和多任务训练，可以有效提升广告商关键词推荐的准确性。

> **ai_Abstract:** 该研究提出了一种名为LLMDistill4Ads的方法，利用大型语言模型（LLM）作为裁判，通过交叉编码器蒸馏其信号到双编码器学生模型，以改进eBay广告商关键词推荐系统的性能。该方法旨在解决大规模负面人类判断的获取难题，并通过多任务训练来优化学生模型的检索能力，最终实现更相关的关键词推荐。

> **摘要翻译:** eBay的卖家会收到关键词推荐，以提高其广告活动的表现。这些关键词的相关性对于避免搜索系统充斥不相关的商品和维持积极的卖家认知至关重要。关键词推荐必须同时符合卖家和搜索者对拍卖的判断。由于难以大规模获得负面人类判断，在多项研究中，使用LLM作为裁判来模仿卖家判断已成为常态。本研究引入了一种新颖的两步LLM蒸馏过程，该过程利用LLM裁判来消除我们基于嵌入的检索（EBR）模型中存在于点击数据中的各种偏差。我们通过交叉编码器助手从LLM教师进行蒸馏，采用多任务训练方法到一个双编码器学生，并最终使用学生双编码器来检索相关的广告商关键词。我们证明，在多任务训练设置中整合来自LLM的知识蒸馏过程，可以提高双编码器在eBay上检索相关广告商关键词的性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [805] [Personalized Recommendation of Dish and Restaurant Collections on iFood](https://arxiv.org/abs/2508.03670)
> *iFood平台上的菜肴和餐厅精选个性化推荐*

*Fernando F. Granado, Davi A. Bezerra, Iuri Queiroz, Nathan Oliveira, Pedro Fernandes, Bruno Schock* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 个性化推荐,食品集合,LightGBM,冷启动问题,A/B测试

**Comment:** Workshop on Two-sided Marketplace Optimization: Search, Discovery,
  Matching, Pricing & Growth in conjunction with KDD Conference (KDD 2025) in
  Toronto, Canada

> **TL;DR:** 该论文提出了一种名为RED的自动化推荐系统，用于iFood平台，通过LightGBM分类器对菜肴集合进行个性化推荐，解决了冷启动和数据稀疏性问题，并通过A/B测试证明了其在提高转化率方面的显著效果。

**AI_Comments:** 这项研究在解决大规模食品推荐平台的实际挑战方面取得了显著进展。RED系统通过结合多种特征和解决关键问题（如冷启动和数据偏差）来提供个性化推荐，这在商业环境中具有很高的价值。特别是，离线指标与在线性能的高度相关性，为未来推荐系统的开发和评估提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 食品配送平台需要帮助用户在海量餐厅和菜肴中找到他们喜欢的餐点，这是一个巨大的挑战。

**Method:** 使用LightGBM分类器，结合菜肴集合特征、用户-集合相似度和上下文信息来对集合进行评分。为了解决新集合的冷启动问题，采用了基于内容的表示和单调性约束。为了解决数据稀疏性问题，通过类别轮播交互进行引导。为了解决可见性偏差问题，在生产环境中进行了无偏样本的印象和购买采样。

**Result:** A/B测试结果显示，与基于流行度的基线相比，该系统将卡片转化率提高了97%，整体应用转化率提高了1.4%。离线准确性指标与在线性能高度相关。

**Conclusion:** RED系统在iFood平台上成功实现了大规模的个性化菜肴集合推荐，并通过A/B测试证明了其在提高用户转化率方面的显著效果，是首个在大规模商业环境中详细介绍精选食品集合推荐的工作。

> **ai_Abstract:** 该研究介绍了RED系统，一个为iFood平台设计的个性化推荐系统，用于向用户推荐精选的菜肴和餐厅集合。该系统利用LightGBM分类器，结合多种特征，并采用特定策略解决冷启动、数据稀疏性和可见性偏差问题。A/B测试结果表明，RED系统显著提高了用户转化率，并且其离线评估结果能有效预测在线表现。

> **摘要翻译:** 食品配送平台面临着帮助用户在海量餐厅和菜肴中找到他们真正喜欢的餐点的挑战。本文提出了RED，一个为拉丁美洲最大的按需食品配送平台iFood设计的自动化推荐系统，用于向数百万用户个性化推荐精选的食品集合。我们的方法采用LightGBM分类器，根据三个特征组对集合进行评分：集合特征、用户-集合相似度和上下文信息。为了解决新创建集合的冷启动问题，我们使用项目嵌入开发了基于内容的表示，并实施了单调性约束以提高泛化能力。我们通过从类别轮播交互中引导来解决数据稀疏性问题，并通过在生产环境中对印象和购买进行无偏采样来解决可见性偏差。该系统通过对iFood用户群的5-10%进行广泛的A/B测试，展示了显著的实际影响。我们的A/B测试在线结果与基于流行度的基线相比，卡片转化率提高了97%，整体应用转化率提高了1.4%。值得注意的是，我们的离线准确性指标与在线性能高度相关，能够在部署前可靠地预测效果。据我们所知，这是首次在动态商业环境中详细介绍大规模精选食品集合推荐的工作。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [939] [Heterophily-Aware Fair Recommendation using Graph Convolutional Networks](https://arxiv.org/abs/2402.03365)
> *异质性感知公平推荐使用图卷积网络*

*Nemat Gholinejad, Mostafa Haghir Chehreghani* | **Category: cs.IR, cs.LG, cs.SI** | **Updated: 2025-08-05**

**Keywords:** 图卷积网络,推荐系统,公平性,异质性,流行度偏差

**Comment:** 

> **TL;DR:** 提出了一种名为HetroFair的公平推荐系统，利用图卷积网络通过注意力机制和异质性特征加权来解决公平性和流行度偏差问题，并在实验中证明了其在提高物品侧公平性和用户侧准确性方面的有效性。

**AI_Comments:** 该研究提出了一种新颖的GNN推荐方法HetroFair，专注于解决推荐系统中的公平性和流行度偏差问题，这在当前研究中具有重要意义。其提出的公平感知注意力和异质性特征加权方法具有一定的创新性，并且通过多数据集实验验证了其有效性。然而，文章未深入探讨这两种机制在不同类型图结构或不同程度异质性数据上的泛化能力，以及在处理更复杂的多方公平性问题上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图神经网络（GNN）的推荐系统在提高准确性和性能的同时，也面临着公平性和流行度偏差的挑战，尤其是在用户、物品及其提供者目标不一致的情况下。

**Method:** 提出了一种名为HetroFair的公平GNN推荐系统，包含两个关键组件：1. 公平感知注意力机制，通过在GNN的归一化过程中引入点积来降低节点度的影响；2. 异质性特征加权，在聚合过程中为不同特征分配不同的权重。

**Result:** 实验结果表明，HetroFair能够有效缓解物品侧的公平性和流行度偏差，并在用户侧实现了更高的准确性。

**Conclusion:** HetroFair通过公平感知注意力和异质性特征加权，成功地解决了GNN推荐系统中的公平性和流行度偏差问题，同时提升了用户侧的推荐准确性。

> **ai_Abstract:** 本文提出了一种名为HetroFair的基于图卷积网络（GCN）的推荐系统，旨在解决推荐系统中的公平性和流行度偏差问题。HetroFair通过引入公平感知注意力机制来减少节点度对GCN归一化过程的影响，并通过异质性特征加权在聚合过程中为不同特征分配不同权重，以提升物品侧的公平性。实验证明，HetroFair在改善物品侧公平性、减少流行度偏差的同时，还能提高用户侧的推荐准确性。

> **摘要翻译:** 近年来，图神经网络（GNN）已成为改进推荐系统准确性和性能的流行工具。现代推荐系统不仅服务于最终用户，也使物品和物品提供者等其他参与者受益。这些参与者可能拥有不同或冲突的目标和利益，这增加了对公平性和流行度偏差的考量需求。基于GNN的推荐方法也面临着不公平和流行度偏差的挑战，并且它们的归一化和聚合过程也受到这些挑战的影响。在本文中，我们提出了一种名为HetroFair的公平GNN推荐系统，以改善物品侧的公平性。HetroFair使用两个独立的组件来生成公平性感知嵌入：i）公平性感知注意力，它在GNN的归一化过程中引入点积以减少节点度的影响；ii）异质性特征加权，在聚合过程中为不同特征分配不同的权重。为了评估HetroFair的有效性，我们在六个真实世界的数据集上进行了广泛的实验。我们的实验结果表明，HetroFair不仅缓解了物品侧的不公平和流行度偏差，而且在用户侧也实现了卓越的准确性。我们的实现可在https://github.com/NematGH/HetroFair公开获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [202] [What If, But Privately: Private Counterfactual Retrieval](https://arxiv.org/abs/2508.03681)
> *如果，但私密地：私密反事实检索*

*Shreya Meel, Mohamed Nomeir, Pasan Dissanayake, Sanghamitra Dutta, Sennur Ulukus* | **Category: cs.IT, cs.CR, cs.LG, cs.NI, eess.SP, math.IT** | **Updated: 2025-08-05**

**Keywords:** 私密反事实检索, 用户隐私, 可解释人工智能, 不可变特征, 信息论隐私

**Comment:** arXiv admin note: text overlap with arXiv:2410.13812,
  arXiv:2411.10429

> **TL;DR:** 本文提出了私密反事实检索（PCR）框架，允许用户在不泄露其特征向量的情况下，安全地获取反事实解释，同时实现完美的信息论用户隐私，并考虑了数据库隐私和不可变特征。

**AI_Comments:** 该论文在可解释人工智能领域中，创新性地将隐私保护融入到反事实解释的生成过程中，解决了用户在获取解释时可能面临的隐私泄露风险。其提出的信息论隐私保障为实际应用提供了坚实的基础，特别是在医疗、金融等高敏感数据场景下具有重要意义。同时，对不可变特征和用户偏好的考虑，也增强了方案的实用性和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 在关键应用中，黑盒机器学习模型的透明度和可解释性至关重要。提供反事实解释是满足这一需求的方式，但这可能对提供解释的机构和请求解释的用户构成隐私威胁。本文主要关注用户在不向机构透露其特征向量的情况下检索反事实实例时的隐私问题。

**Method:** 本文首先引入了私密反事实检索（PCR）问题，并提出了一个基线PCR方案，该方案使用户的特征向量对机构保持信息论上的隐私。在此基础上，提出了另外两种方案，与基线方案相比，它们减少了关于机构数据库泄露给用户的信息量。其次，放宽了所有特征都可变动的假设，并考虑了不可变PCR（I-PCR）的设置，用户可以在不改变其特征私有子集（构成不可变集）的情况下检索最近的反事实，同时保持其特征向量和不可变集对机构的隐私。为此，提出了两种方案，它们在信息论上保护用户隐私，但确保了不同程度的数据库隐私。第三，将PCR和I-PCR方案扩展，以纳入用户对属性转换的偏好，从而获得更具可操作性的解释。最后，通过数值结果支持理论发现，并比较了所提方案的数据库泄露情况。

**Result:** 数值结果支持了理论发现，并比较了所提出方案的数据库泄露情况。

**Conclusion:** 本文提出了私密反事实检索（PCR）框架，该框架允许用户在不泄露其特征向量的情况下，从数据库中检索精确的最近邻反事实解释，同时实现完美的信息论用户隐私。通过提出多种方案，考虑了不同程度的数据库隐私和不可变特征，并支持用户偏好，从而提供了更安全、更可操作的反事实解释。

> **ai_Abstract:** 本文提出了一种私密反事实检索（PCR）框架，旨在解决黑盒机器学习模型解释中存在的隐私问题。该框架允许用户在不泄露自身特征向量的前提下，从数据库中安全地检索精确的最近邻反事实解释，实现信息论上的用户隐私。研究引入了PCR问题及其基线方案，并进一步提出多种改进方案以减少数据库信息泄露。此外，论文还考虑了不可变特征（I-PCR）场景，并扩展了方案以支持用户对属性转换的偏好，最终通过数值实验验证了理论发现和方案的有效性。

> **摘要翻译:** 透明度和可解释性是在高风险应用中采用黑盒机器学习模型时需要考虑的两个重要方面。提供反事实解释是满足这一要求的一种方式。然而，这也对提供解释的机构以及请求解释的用户构成隐私威胁。在这项工作中，我们主要关注用户的隐私，用户希望在不向机构透露其特征向量的情况下检索反事实实例。我们的框架从已接受点的数据库中检索精确的最近邻反事实解释，同时为用户实现完美的信息论隐私。首先，我们介绍了私密反事实检索（PCR）问题，并提出了一个基线PCR方案，该方案使用户的特征向量对机构保持信息论上的隐私。在此基础上，我们提出了另外两种方案，与基线方案相比，它们减少了关于机构数据库泄露给用户的信息量。其次，我们放宽了所有特征都可变动的假设，并考虑了不可变PCR（I-PCR）的设置。在这里，用户在不改变其特征私有子集（构成不可变集）的情况下检索最近的反事实，同时保持其特征向量和不可变集对机构的隐私。为此，我们提出了两种方案，它们在信息论上保护用户隐私，但确保了不同程度的数据库隐私。第三，我们将PCR和I-PCR方案扩展，以纳入用户对属性转换的偏好，从而获得更具可操作性的解释。最后，我们提出了数值结果以支持我们的理论发现，并比较了所提方案的数据库泄露情况。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [203] [Optimal quantum locally recoverable codes from matrix-product construction](https://arxiv.org/abs/2310.15703)
> *基于矩阵乘积构造的最优量子局部可恢复码*

*Carlos Galindo, Fernando Hernando, Carlos Munuera, Diego Ruano* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 量子局部可恢复码, 矩阵乘积码, 最优码, 纠错码, 量子信息

**Comment:** This version introduces significant new results on quantum locally
  recoverable codes (quantum LRC) and appears under a new title

> **TL;DR:** 本文利用矩阵乘积码构造了最优量子局部可恢复码，并确定了其参数和局部性。

**AI_Comments:** 本文的创新点在于将矩阵乘积码应用于量子局部可恢复码的构造，这为设计具有最优参数的量子纠错码提供了一个新的有效途径。鉴于量子计算和存储的快速发展，此类研究对于构建鲁棒的量子信息系统具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 局部可恢复码（LRCs）广泛应用于大规模分布式和云存储系统。量子局部可恢复码（量子LRCs）是经典LRCs的量子对应物，它们允许通过对更大位置集合的qudit进行迹保持量子操作来纠正多个位置的擦除。满足Singleton类边界的量子LRCs被称为最优的，因此研究如何构造最优量子LRCs具有重要意义。

**Method:** 研究考虑了矩阵乘积码（MPCs）$\\mathcal{C}$，并给出了组成矩阵和组成码的条件，以使码$\\mathcal{C}$满足提供量子LRCs的条件。量子LRCs $\\mathcal{Q}(\\mathcal{C})$ 可以由经典Hermitian（或Euclidean）对偶包含码 $\\mathcal{C}$ 构建。

**Result:** 通过上述方法，本文能够提供量子LRCs $\\mathcal{Q}(\\mathcal{C})$ 的局部性和参数，并确定了由此派生的一系列最优量子LRCs。

**Conclusion:** 本文成功地利用矩阵乘积码构造了满足特定条件的量子局部可恢复码，并确定了多族最优量子局部可恢复码。

> **ai_Abstract:** 本文研究了量子局部可恢复码（量子LRCs）的构造，它是经典LRCs的量子对应物，用于纠正量子擦除。论文指出最优量子LRCs满足Singleton类界。通过使用矩阵乘积码（MPCs）作为基础，文章给出了构建此类代码的条件，并成功推导出了量子LRCs的局部性和参数，从而识别出了一系列最优的量子LRCs。

> **摘要翻译:** 局部可恢复码（LRCs）是广泛应用于大规模分布式和云存储系统的经典纠错码。量子局部可恢复码（量子LRCs）是经典LRCs的量子对应物。它们允许我们通过对更大位置集合的qudit进行迹保持量子操作来纠正多个位置的擦除。量子LRCs的参数和局部性满足一个类Singleton界；达到这个界的码被称为最优码。量子LRCs，$\mathcal{Q}(\mathcal{C})$，可以由经典Hermitian（或Euclidean）对偶包含码$\mathcal{C}$构建，它们的恢复能力受到这些码的Hermitian（或Euclidean）对偶的最小距离的上限限制。我们考虑矩阵乘积码（MPCs）$\mathcal{C}$，并给出了组成矩阵和组成码的条件，以使码$\mathcal{C}$满足提供量子LRCs的条件。因此，我们能够提供量子LRCs $\mathcal{Q}(\mathcal{C})$ 的局部性和参数，并确定了由此派生的一系列最优量子LRCs。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [260] [A New Construction of Non-Binary Deletion Correcting Codes and their Decoding](https://arxiv.org/abs/2501.13534)
> *非二进制删除纠错码的新构造及其解码*

*Michael Schaller, Beatrice Toesca, Van Khu Vu* | **Category: cs.IT, math.CO, math.IT** | **Updated: 2025-08-05**

**Keywords:** 非二进制码, 删除纠错码, 无重码, 解码, 码构造

**Comment:** 

> **TL;DR:** 本文提出了一种新的非二进制无重删除纠错码的构造方法，该方法在某些情况下比现有代码更大，并提供了一种解码算法。

**AI_Comments:** 本文的创新之处在于提出了一种基于集合码和置换码的新的显式构造无重码的方法，并在特定参数下实现了更大的码字尺寸，这对于删除纠错码的效率而言是一个重要的提升。

<details>
  <summary>Details</summary>

**Motivation:** 非二进制多重删除纠错码最近受到了广泛关注，本文致力于解决如何构造更优（更大、更高效）的这类码的问题。

**Method:** 本文提出了一种新的显式构造方法，基于集合码和置换码来构建无重码，并提供了一个相应的解码算法。

**Result:** 所构造的无重码能够纠正多重删除。在某些参数范围内，这些构造的码的尺寸比所有以前已知的非二进制多重删除纠错码都要大。同时提供了一个解码算法。

**Conclusion:** 本文成功构造了新的、更大的非二进制无重删除纠错码，并提供了相应的解码算法，在特定参数范围内优于现有工作。

> **ai_Abstract:** 本文针对非二进制多重删除纠错码的研究热点，提出了一种新的显式构造“无重码”的方法，这类码的特点是所有符号都不同。该构造方法基于集合码和置换码，并被证明能够有效纠正多重删除。此外，作者还提供了一个解码算法，并展示在特定参数范围内，他们新构造的码比所有先前已知的非二进制多重删除纠错码具有更大的尺寸。

> **摘要翻译:** 非二进制多重删除纠错码最近受到了广泛关注。在这项工作中，我们专注于无重码（multiplicity-free codes），这是一类所有符号都不同的非二进制码。我们的主要贡献是基于集合码和置换码对这类码进行了一种新的显式构造。我们表明，我们的无重码可以纠正多重删除，并提供了一种解码算法。我们还表明，在某些参数范围内，我们构造的码的尺寸比所有以前已知的非二进制多重删除纠错码都要大。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [317] [Low Complexity Artificial Noise Aided Beam Focusing Design in Near-Field Terahertz Communications](https://arxiv.org/abs/2502.08967)
> *近场太赫兹通信中低复杂度人工噪声辅助波束聚焦设计*

*Zhifeng Tang, Nan Yang, Xiangyun Zhou, Salman Durrani, Markku Juntti, Josep Miquel Jornet* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 人工噪声, 波束聚焦, 近场通信, 太赫兹通信, 保密速率

**Comment:** 

> **TL;DR:** 本文提出一种低复杂度人工噪声辅助的近场太赫兹窃听通信系统波束聚焦方案，通过优化波束聚焦和功率分配，显著提高了合法用户的保密速率。

**AI_Comments:** 该论文提出了一种低复杂度的人工噪声辅助波束聚焦方案，解决了近场太赫兹通信中的信息安全问题。其创新点在于将人工噪声与波束聚焦相结合，并通过优化方法提升保密速率。该研究对于未来太赫兹通信的安全传输具有重要意义，特别是在近场环境中，为对抗窃听提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 在近场太赫兹窃听通信系统中，基站向合法用户传输信号时需要减轻信息泄露给窃听者的问题。

**Method:** 提出了一种新颖的低复杂度人工噪声（AN）辅助波束聚焦方案。通过建立优化问题来最大化合法用户实现的保密速率，并通过设计最优波束聚焦和功率分配来解决该问题。

**Result:** 数值结果表明，所提出的AN辅助波束聚焦方案实现了显著的性能提升，尤其当窃听者比合法用户更靠近基站时。

**Conclusion:** 所提出的低复杂度人工噪声辅助波束聚焦方案能有效提升近场太赫兹通信系统的保密性能，特别是在窃听者靠近基站的情况下效果更佳。

> **ai_Abstract:** 本文针对近场太赫兹窃听通信系统，提出了一种新颖的低复杂度人工噪声（AN）辅助波束聚焦方案。该方案旨在最大化合法用户的保密速率，通过优化波束聚焦和功率分配来实现。数值结果验证了该方案能显著提升系统性能，尤其在窃听者距离基站较近时效果更佳。

> **摘要翻译:** 在本文中，我们开发了一种在近场太赫兹窃听通信系统中新颖的低复杂度人工噪声（AN）辅助波束聚焦方案。在该系统中，配备大规模阵列的基站（BS）向合法用户传输信号，同时减轻信息泄露给窃听者。我们提出了一个优化问题，旨在最大化合法用户实现的保密速率，并通过设计最优的波束聚焦和功率分配来解决该问题。数值结果表明，所提出的AN辅助波束聚焦方案实现了显著的性能提升，尤其当窃听者比合法用户更靠近基站时。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [375] [Self-orthogonal codes from plateaued functions and their applications in quantum codes and LCD codes](https://arxiv.org/abs/2502.11599)
> *自正交码：基于高原函数及其在量子码和LCD码中的应用*

*Yadi Wei, Jiaxin Wang, Fang-Wei Fu* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 自正交码, 高原函数, 量子码, LCD码, 线性码

**Comment:** 

> **TL;DR:** 本文利用高原函数构造了不含全1向量的自正交线性码，并确定了其权重分布。基于这些码，构建了新的近乎最优的量子码和最优的LCD码。

**AI_Comments:** 本文创新性地利用高原函数构造了不含全1向量的自正交码，这与以往通过增广技术构造包含全1向量的自正交码的方法不同。这一贡献不仅丰富了自正交码的构造理论，而且为构建高性能的量子码和LCD码提供了新的途径，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 自正交码因其在量子码、LCD码和格中的重要应用而受到广泛关注。现有的构造方法多包含全1向量，因此需要探索不含全1向量的新型自正交码。

**Method:** 本文利用高原函数构造了几类不含全1向量的线性码。研究了这些码的穿孔码，并明确确定了所构造码的权重分布。在特定条件下，证明了这些码是自正交的。此外，通过其对偶码获得了几类最优线性码。

**Result:** 构造了几类不含全1向量的线性码。明确确定了所构造码的权重分布。在特定条件下，这些码被证明是自正交的。从它们的对偶码中获得了一些最优线性码。利用自正交穿孔码，构造了几类至少是近乎最优的量子码和最优的LCD码。

**Conclusion:** 本文成功利用高原函数构造了不含全1向量的自正交线性码，并在此基础上得到了新的近乎最优的量子码和最优的LCD码，为编码理论提供了新的构造方法和实例。

> **ai_Abstract:** 本文利用高原函数构造了一类不包含全1向量的线性码，并对其穿孔码进行了研究。文中明确确定了所构造码的权重分布，并在特定条件下证明了这些码的自正交性。此外，通过这些码的对偶码获得了最优线性码，并利用自正交穿孔码构建了新的至少近乎最优的量子码和最优的LCD码。

> **摘要翻译:** 自正交码因其在量子码、LCD码和格中的重要应用而备受关注。最近，通过增广技术构造了几类包含全1向量的自正交码。在本文中，我们利用高原函数构造了一些不含全1向量的线性码。我们还研究了它们的穿孔码。所构造码的权重分布被明确确定。在某些条件下，这些码被证明是自正交的。此外，从它们的对偶码中获得了一些最优线性码。利用自正交穿孔码，我们还构造了几类至少是近乎最优的量子码和最优的LCD码。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [604] [Exponential convergence rate for Iterative Markovian Fitting](https://arxiv.org/abs/2508.02770)
> *迭代马尔可夫拟合的指数收敛速度*

*Kirill Sokolov, Alexander Korotin* | **Category: cs.IT, cs.LG, math.IT** | **Updated: 2025-08-04**

**Keywords:** 迭代马尔可夫拟合, 指数收敛, 薛定谔桥问题, Kullback-Leibler散度

**Comment:** 

> **TL;DR:** 本文首次证明了迭代马尔可夫拟合（IMF）算法在解决离散时间薛定谔桥问题时具有指数收敛速度。

**AI_Comments:** 本文的创新之处在于首次量化了迭代马尔可夫拟合（IMF）算法的收敛速度，证明了其指数收敛性，这对于理解和应用该算法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已知迭代马尔可夫拟合（IMF）算法在Kullback-Leibler散度上收敛到真实解，但其收敛速度尚未量化。

**Method:** 本文建立了IMF算法的指数收敛性，并给出了明确的收缩因子。

**Result:** 迭代马尔可夫拟合（IMF）算法表现出指数收敛，具有明确的收缩因子。

**Conclusion:** 本文首次证明了迭代马尔可夫拟合（IMF）算法在解决离散时间薛定谔桥问题时具有指数收敛速度。

> **ai_Abstract:** 本文研究了有限状态空间上的离散时间薛定谔桥问题中的迭代马尔可夫拟合（IMF）算法。此前，该算法的收敛性已知，但收敛速度未被量化。本工作首次证明了IMF算法具有指数收敛速度，并给出了明确的收缩因子。

> **摘要翻译:** 我们考虑有限状态空间上的离散时间薛定谔桥问题。尽管已知迭代马尔可夫拟合（IMF）算法在Kullback-Leibler散度上收敛到真实解，但其收敛速度尚未量化。在这项工作中，我们首次建立了IMF算法的指数收敛性，并给出了明确的收缩因子。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [646] [Distributed Source Coding for Compressing Vector-Linear Functions](https://arxiv.org/abs/2508.02996)
> *分布式信源编码用于压缩向量线性函数*

*Xuan Guang, Xiufang Sun, Ruze Zhang* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 分布式信源编码, 向量线性函数, 函数压缩容量, 网络函数计算, 容量下界

**Comment:** 49 pages, 22 figures

> **TL;DR:** 研究了一种分布式信源编码模型，用于压缩向量线性函数，并分析了其函数压缩容量。

**AI_Comments:** 该论文通过提出分布式信源编码模型来解决向量线性函数的压缩问题，其创新点在于引入了函数压缩容量的概念，并提出了一种新的上下界估计方法来精确刻画特定模型的容量。研究结果不仅提供了通用下界，还详细分析了其紧致性，并成功应用于网络函数计算领域，解决了一个开放问题，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 受移动卫星通信系统以及计算任务的重要和普遍应用的启发，本文考虑了一种用于压缩向量线性函数的分布式信源编码模型。

**Method:** 本文考虑了一个包含多个信源、多个编码器和一个解码器的分布式信源编码模型，旨在以零误差计算向量线性函数。研究关注函数压缩容量，首先提出了一个通用的下界。接着，针对只有三个信源且不超过三个编码器的非平凡模型，将$3\times2$列满秩矩阵$T$分为$T_1$和$T_2$两类。通过对编码函数图像集大小进行上下界估计的新方法，明确刻画了与$T_2$相关的两个最非平凡模型的函数压缩容量。

**Result:** 提出了一个适用于任意连接状态和向量线性函数的函数压缩容量的通用下界。证明了所有$3\times2$列满秩矩阵$T$可以分为$T_1$和$T_2$两种类型，同类型矩阵的函数压缩容量相同。明确刻画了与$T_2$相关的两个最非平凡模型的函数压缩容量，并发现所获得的下界并非总是紧的。然而，除了两个最非平凡模型外，该下界对于所有与$T_1$和$T_2$相关的模型都是紧的。将所获得的结果应用于网络函数计算，并回答了关于Guang等人（2019）提出的计算容量最佳已知上界是否普遍渐近紧的开放问题。

**Conclusion:** 本文完全刻画了特定分布式信源编码模型（除了两个最非平凡模型）的函数压缩容量，并证明了所提出的通用下界在多数情况下的紧致性。研究结果成功应用于网络函数计算，并解决了一个长期存在的开放问题。

> **ai_Abstract:** 该论文研究了一种用于压缩向量线性函数的分布式信源编码模型，该模型由多个信源、编码器和解码器组成，旨在以零误差计算信源信息的向量线性函数。文章关注系统的函数压缩容量，并提出了一个通用的容量下界。针对特定模型，论文将矩阵$T$分为两类$T_1$和$T_2$，并证明同类型矩阵容量相同。通过一种新的上下界估计方法，明确刻画了与$T_2$相关的两个最非平凡模型的容量，并发现通用下界并非总是紧的，但对于多数情况是紧的。最后，将结果应用于网络函数计算，并回答了一个关于计算容量上界的开放问题。

> **摘要翻译:** 受移动卫星通信系统以及计算任务的重要和普遍应用的启发，我们考虑了一个用于压缩向量线性函数的分布式信源编码模型，该模型由多个信源、多个编码器和一个连接所有编码器的解码器组成。每个编码器都可以访问信源的某个子集，并且解码器需要以零误差计算信源信息的向量线性函数，这对应于一个矩阵$T$。信源与编码器之间的连接状态以及向量线性函数都是任意的。在本文中，我们关注函数压缩容量以衡量系统使用效率。我们首先提出了一个适用于任意连接状态和向量线性函数的函数压缩容量的通用下界。接下来，我们限制在只有三个信源且不超过三个编码器的非平凡模型中，并证明所有$3\times2$列满秩矩阵$T$可以分为$T_1$和$T_2$两种类型，如果矩阵$T$属于同种类型，则其函数压缩容量相同。我们通过一种对编码函数图像集大小进行上下界估计的新方法，明确刻画了与$T_2$相关的两个最非平凡模型的函数压缩容量。这表明所获得的下界并非总是紧的。相反，通过完全刻画其容量，该下界对于所有与$T_1$相关的模型以及除了两个最非平凡模型之外的所有与$T_2$相关的模型都是紧的。我们最终将所获得的结果应用于网络函数计算，并回答了Guang等人（2019）证明的最佳已知计算容量上界是否普遍渐近紧的开放问题。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [688] [Multilevel inserting constructions for constant dimension subspace codes](https://arxiv.org/abs/2508.03196)
> *常维子空间码的多级插入构造*

*Gang Wang, Xuan Gao, Sihem Mesnager, Fang-Wei Fu* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 常维子空间码, 反双层多级构造, 秩度量码, 网络编码, 识别向量

**Comment:** 22 pages,1 table. Des.Codes Cryptogr. (2025)

> **TL;DR:** 该论文提出了一种新的常维子空间码（CDC）构造方法，通过引入反双层识别向量和反双层Ferrers图秩度量码，并将其插入到双层和双层构造中，从而得到有效的CDC构造。此外，还提供了一套新的双层识别向量，实现了另一种高效的CDC构造。与现有文献相比，这些新的CDC具有更大的规模，并且在某些情况下，新下界与已知上界的比率大于0.94548。

**AI_Comments:** 这项研究在常维子空间码（CDC）领域取得了显著进展，提出了一种新的构造方法，并实现了比现有文献更大的CDC规模。其理论分析和潜在应用价值值得肯定，特别是其在网络编码中的实用性。然而，对该方法在不同参数设置下的性能进行更广泛的评估，以及进一步探索其在其他编码理论问题中的应用，将有助于更全面地理解其贡献。

<details>
  <summary>Details</summary>

**Motivation:** 子空间码，特别是常维子空间码（CDC），在基础编码理论研究中具有重要意义，并在随机网络编码领域受到广泛关注。

**Method:** 通过引入反双层识别向量和反双层Ferrers图秩度量码，将反双层多级构造插入到双层构造和双层构造中，实现CDC的构造。此外，通过提供一组新的双层识别向量，实现了另一种CDC构造。

**Result:** 论文提出了一种新的CDC构造方法，所获得的CDC比现有文献中的CDC规模更大。对于某些CDC，新下界与已知上界的比率大于0.94548（对于任何素数幂q≥3）。

**Conclusion:** 该研究为常维子空间码（CDC）提供了有效的构造方法，并获得了比现有文献更大规模的CDC，为网络编码中的常维提升秩度量码提供了实际应用框架。

> **ai_Abstract:** 本研究提出了一种新颖的常维子空间码（CDC）构造方法，通过引入反双层识别向量和反双层Ferrers图秩度量码，并将其整合到现有的多级构造中，从而实现了更有效的CDC设计。此外，通过引入新的双层识别向量，进一步增强了CDC的构造能力。所提出的方法能够生成比现有文献中更大的CDC实例，并且在理论分析中，新下界与已知上界的比率表现优异，显示了其在网络编码等实际应用中的潜力。

> **摘要翻译:** 子空间码，特别是常维子空间码（CDCs），代表了一个有趣的领域，可用于进行基础编码理论研究。由于其在随机网络编码中的应用，它们受到了广泛关注。本文通过引入反双层识别向量和反双层Ferrers图秩度量码，提出了反双层多级构造。通过将反双层多级构造插入双层构造和双层构造中，提供了一种有效的CDC构造。此外，通过提供一组新的双层识别向量，我们给出了另一种有效的CDC构造。在本文中，展示了几种具有秩度量的CDC，其规模大于现有文献中已知的规模。从实际角度来看，我们的结果有助于常维提升秩度量码在网络编码应用中的实际框架。计算了某些CDC的新下界与已知上界的比率，对于任何素数幂q≥3，该比率大于0.94548。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [729] [Channel Coding for Unequal Error Protection in Digital Semantic Communication](https://arxiv.org/abs/2508.03381)
> *数字语义通信中的不均衡错误保护信道编码*

*Seonjung Kim, Yongjeong Oh, Yongjune Kim, Namyoon Lee, Yo-Seb Jeon* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-05**

**Keywords:** 语义通信, 不均衡错误保护, 信道编码, 比特翻转概率, 数字通信

**Comment:** 

> **TL;DR:** 该论文提出了一种针对数字语义通信的信道编码方法，以解决不均衡错误保护问题，即需要对语义重要性更高的比特提供更强的保护。研究提出了两种新颖的信道编码框架：基于比特级重复编码的框架和基于块级分组的现代信道编码框架，旨在最小化总码长并满足不均衡错误保护要求。仿真结果表明，所提出的框架在图像传输任务中显著优于传统方法，在任务性能和传输效率方面均有提升。

**AI_Comments:** 该研究在数字语义通信领域提出了创新的不均衡错误保护方法，通过结合比特级和块级编码策略，有效解决了语义信息传输中的关键挑战。研究提出的优化算法和框架具有实际应用价值，但对于不同类型的通信任务和信道条件下的性能表现仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 在数字语义通信中，需要为不同语义重要性的比特提供不同级别的错误保护（不均衡错误保护），即语义重要性越高的比特需要越强的保护。

**Method:** 1. 提出一种基于比特级重复编码的框架，优化每个比特的重复次数以满足其目标误比特率。
2. 提出一种基于块级分组的现代信道编码框架，将具有相似目标误比特率的语义比特分组，并提出一种基于有限码长容量分析的比特分组算法。

**Result:** 所提出的两种信道编码框架在图像传输任务中，相较于传统方法，在任务性能和传输效率方面均取得了显著的改进。

**Conclusion:** 该研究提出的两种信道编码框架能够有效地解决数字语义通信中的不均衡错误保护问题，通过优化比特级或块级的错误保护策略，实现了在满足不均衡错误保护要求的同时最小化总码长，从而提升了通信的整体性能。

> **ai_Abstract:** 本研究针对数字语义通信中的不均衡错误保护问题，提出了两种信道编码框架。第一个框架基于比特级重复编码，根据比特的重要性优化重复次数。第二个框架利用现代信道编码，通过聚类算法将相似重要性的比特分组以获得编码增益。两种方法均旨在最小化码长并满足保护要求。实验结果表明，所提出的框架在图像传输任务中显著优于传统方法，提高了任务性能和传输效率。

> **摘要翻译:** 语义通信是一种新兴的范例，它优先传输与任务相关的信息，而不是准确地传递原始数据比特。在本文中，我们解决了数字语义通信中的不均衡错误保护（UEP）问题，其中语义重要性更高的比特需要更强的保护。为了量化比特级别的importance，我们利用语义比特的比特翻转概率作为目标错误保护级别，这些级别与语义编码器和解码器一起被学习。我们提出了两种新颖的信道编码框架，旨在最小化总码长，同时满足UEP约束。首先，我们开发了一种基于重复编码的比特级UEP框架，其中每个比特的重复次数被优化以精确地满足其目标比特翻转概率。其次，我们引入了一种利用现代信道码的块级UEP框架，其中具有相似目标比特翻转概率的语义比特被分组，以利用编码增益。在此框架内，我们提出了一种由有限码长容量分析指导的比特分组算法。在图像传输任务上进行的仿真结果证实，所提出的框架显著优于传统方法，在任务性能和传输效率方面均取得了实质性的改进。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [770] [Dual Domain Expurgated Error Exponents for Source Coding with Side Information](https://arxiv.org/abs/2508.03467)
> *双域净化误差指数在具有侧信息的信源编码中的应用*

*Mehdi Dabirnia, Hamdi Joudeh, Albert Guillén i Fàbregas* | **Category: cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 信源编码, 侧信息, 净化误差指数, 双域方法, 随机编码

**Comment:** 

> **TL;DR:** 本研究提出了一种用于信源编码与侧信息的净化方法，实现了双域直接推导净化误差指数。与原始域优化不同，双域方法将优化问题转化为参数优化，允许更广泛的字母表和记忆。研究推导了两种净化误差指数，并证明其中一种与Csiszár-Körner指数一致。在无侧信息的情况下，净化指数与最优码的误差指数相同。

**AI_Comments:** 该研究在信源编码领域提出了一个重要的方法论创新，通过双域推导简化了复杂问题。其优点在于通用性强，能够处理更广泛的场景。然而，对于所提出的两种指数的数值差异的深入分析，以及在实际应用中的具体表现，还有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信源编码方法在处理具有侧信息的问题时，其优化过程通常涉及复杂的分布优化，限制了其在一般字母表和记忆情况下的应用。本研究旨在通过一种新的双域净化方法，简化优化过程，并扩展其适用范围。

**Method:** 提出了一种用于信源编码与侧信息的净化方法，实现了双域直接推导净化误差指数。研究推导了两种基于不同随机编码集合的净化误差指数，并通过与Csiszár-Körner指数的比较以及数值示例来说明其有效性。

**Result:** 推导了两种双域净化误差指数，并证明其中一种与Csiszár-Körner指数一致。数值示例表明，这两种指数存在差异，并且在无侧信息的情况下，净化指数与最优码的误差指数相同。

**Conclusion:** 所提出的双域净化方法能够直接推导净化误差指数，简化了优化过程，并适用于更一般的情况。其中一种推导出的指数与现有理论结果一致，为信源编码理论提供了新的视角和工具。

> **ai_Abstract:** 本研究提出了一种新颖的双域净化方法，用于信源编码中的侧信息问题，能够直接推导净化误差指数。该方法通过将复杂的分布优化简化为参数优化，克服了原始域方法的局限性，并能处理更一般的字母表和记忆情况。研究推导了两种净化误差指数，并证明其中一种与Csiszár-Körner指数等价，同时在无侧信息的情况下，该方法得到的指数与最优码的误差指数一致。

> **摘要翻译:** 我们提出了一种用于信源编码与侧信息的净化方法，该方法能够直接进行双域推导净化误差指数。
双域方法产生仅涉及少数参数的优化问题，任何次优选择都可以得到一个可实现的指数，这与涉及分布的原始域优化不同。
此外，双域方法自然地允许使用一般的字母表和/或记忆。
我们推导了两种不同的随机编码集合的双域净化误差指数。
我们证明了其中较优的指数通过图分解引理与Csiszár-Körner指数一致。
我们展示了一些数值示例，说明了两种指数之间的差异，并表明在没有侧信息的情况下，净化指数与信源最优码的误差指数一致。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [814] [Decoding Algorithms for Twisted GRS Codes](https://arxiv.org/abs/2508.03552)
> *扭曲GRS码的解码算法*

*Guanghui Zhang, Liren Lin, Bocong Chen* | **Category: cs.IT, math.IT, 94B05, 94B65** | **Updated: 2025-08-05**

**Keywords:** 扭曲GRS码, 解码算法, 高斯消元法, MDS码, 近MDS码

**Comment:** 17 pages

> **TL;DR:** 本文提出了一种基于高斯消元法的解码算法，用于纠正扭曲广义Reed-Solomon（TGRS）码中的错误，该算法适用于MDS TGRS码和近MDS TGRS码，纠错能力和计算复杂度与现有方法不同。

**AI_Comments:** 该研究提出了一个新的解码算法，采用高斯消元法，与现有基于欧几里得算法的方法不同，并解决了现有文献中未考虑的情况。算法的纠错能力和计算复杂度分析提供了有价值的见解，特别是其对近MDS TGRS码的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了扩展经典广义Reed-Solomon（GRS）码的代数能力，并用于构建新的非GRS最大距离可分（MDS）码和增强密码安全性。

**Method:** 采用高斯消元法提出新的解码算法，适用于参数为[n,k,n-k+1]的MDS TGRS码，并可推广到参数为[n, k, n-k]的近MDS TGRS码。

**Result:** 对于MDS TGRS码，当n-k为奇数时，可纠正$\lfloor \frac{n-k}{2}\rfloor$个错误；当n-k为偶数时，可纠正$\lfloor \frac{n-k}{2}\rfloor-1$个错误。计算复杂度为$O(n^3)$。对于近MDS TGRS码，可纠正$\\lfloor \frac{n-k-1}{2} \rfloor$个错误。

**Conclusion:** 本文提出的基于高斯消元法的解码算法为MDS TGRS码和近MDS TGRS码提供了新的解码方法，并在纠错能力和适用范围上有所扩展，计算复杂度为多项式时间。

> **ai_Abstract:** 本文提出了一种新颖的基于高斯消元法的解码算法，用于解决扭曲广义Reed-Solomon（TGRS）码的解码问题。该算法能够有效纠正MDS TGRS码和近MDS TGRS码中的错误，并提供了具体的纠错能力和计算复杂度分析。

> **摘要翻译:** 扭曲广义Reed-Solomon（TGRS）码被引入以扩展经典广义Reed-Solomon（GRS）码的代数能力。这种扩展有潜力构建新的非GRS最大距离可分（MDS）码并增强密码安全性。已知具有1次扭曲的TGRS码可以是MDS码或近MDS码。在本文中，我们采用高斯消元法提出新的解码算法，用于参数为[n,k,n-k+1]的MDS TGRS码。当n-k为奇数时，该算法可以纠正多达$\\lfloor \frac{n-k}{2}\rfloor$个错误；当n-k为偶数时，可以纠正$\\lfloor \frac{n-k}{2}\rfloor-1$个错误。两种情况下的计算复杂度均为$O(n^3)$。%，其中$\\omega\\approx 2.37286$是矩阵乘法指数。我们的方法与现有的基于欧几里得算法的方法不同，并解决了现有文献中未考虑的情况。
此外，该方法也适用于解码参数为[n, k, n-k]的近MDS TGRS码，可纠正多达$\\lfloor \frac{n-k-1}{2} \rfloor$个错误，同时保持在n上的多项式时间复杂度。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [2] [Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization](https://arxiv.org/abs/2508.02840)
> *资源高效的基于知识蒸馏和粒子群优化的软件漏洞自动评估*

*Chaoyang Gao, Xiang Chen, Jiyu Wang, Jibin Wang, Guang Yang* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-30**

**Keywords:** 软件漏洞评估, 知识蒸馏, 粒子群优化, 资源高效, 模型压缩

**Comment:** Accepted by Engineering Applications of Artificial Intelligence

> **TL;DR:** 提出一种结合知识蒸馏和粒子群优化的高效框架，用于自动软件漏洞评估，显著减小模型尺寸并保持高性能。

**AI_Comments:** 该论文的创新点在于将粒子群优化（用于模型架构搜索）与知识蒸馏（用于模型压缩）结合起来，以解决大型漏洞评估模型资源消耗高的问题。这种方法提供了一种实用的解决方案，使得复杂的漏洞评估模型能够在资源受限的环境中部署，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 软件系统日益复杂导致网络安全漏洞激增，需要高效可扩展的漏洞评估方案。然而，大型预训练模型因其高计算和存储需求而难以在实际场景中部署。

**Method:** 本文提出一个两阶段的资源高效框架：首先，利用粒子群优化（PSO）优化紧凑型学生模型的架构，以平衡计算效率和模型容量；其次，应用知识蒸馏（KD）将关键漏洞评估知识从大型教师模型转移到优化后的学生模型，从而显著减小模型尺寸并维持高性能。

**Result:** 在包含12,071个CVSS v3标注漏洞的增强型MegaVul数据集上进行实验。结果显示，模型尺寸减少99.4%，同时保留了原始模型89.3%的准确率。该方法在准确率方面比最先进的基线模型高出1.7%，参数减少60%。此外，训练时间减少72.1%，架构搜索时间比传统遗传算法减少34.88%。

**Conclusion:** 本文提出的框架通过结合知识蒸馏和粒子群优化，实现了资源高效的自动化软件漏洞评估，有效解决了大型模型部署的计算和存储限制，并在性能上超越了现有方法。

> **ai_Abstract:** 本文提出了一种新颖的资源高效框架，用于自动软件漏洞评估，该框架结合了知识蒸馏和粒子群优化。通过两阶段方法，首先利用粒子群优化优化紧凑型学生模型架构，然后通过知识蒸馏将大型教师模型的知识转移到学生模型。实验结果表明，该方法在大幅减小模型尺寸的同时保持了高准确率，并显著减少了训练和架构搜索时间，优于现有基线。

> **摘要翻译:** 软件系统日益复杂导致网络安全漏洞激增，需要高效可扩展的漏洞评估解决方案。然而，大型预训练模型的高计算和存储需求阻碍了它们在实际场景中的部署。为了解决这一挑战，我们提出了一种新颖的资源高效框架，该框架集成了知识蒸馏和粒子群优化，以实现自动化漏洞评估。我们的框架采用两阶段方法：首先，利用粒子群优化来优化紧凑型学生模型的架构，平衡计算效率和模型容量。其次，应用知识蒸馏将关键的漏洞评估知识从大型教师模型转移到优化后的学生模型。这一过程显著减小了模型尺寸，同时保持了高性能。在包含12,071个CVSS（通用漏洞评分系统）v3标注漏洞的增强型MegaVul数据集上的实验结果证明了我们方法的有效性。我们的方法在模型尺寸上实现了99.4%的缩减，同时保留了原始模型89.3%的准确率。此外，它在准确率方面比最先进的基线模型高出1.7%，且参数减少了60%。与传统遗传算法相比，该框架还将训练时间减少了72.1%，架构搜索时间减少了34.88%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [19] [Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach](https://arxiv.org/abs/2508.03158)
> *重新思考状态空间模型中的选择性：一种最小预测充分性方法*

*Yiyi Wang, Jian'an Zhang, Hongyi Duan, Haoyang Liu, Qingyang Li* | **Category: cs.LG, cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 状态空间模型, 选择性机制, 预测充分性, 信息压缩, 鲁棒性

**Comment:** Submitted to AAAI'26

> **TL;DR:** 本文提出了最小预测充分性原则，为状态空间模型（SSM）的选择机制提供了理论指导，并基于此设计了MPS-SSM，在多种任务上实现了SOTA性能和卓越鲁棒性。

**AI_Comments:** 这篇论文通过引入“预测充分性原则”，为状态空间模型（SSMs）中的选择机制提供了坚实的理论基础，解决了现有模型依赖启发式设计的问题。其创新点在于将信息论中的“最小充分统计量”概念应用于隐状态设计，旨在提升模型的鲁棒性和泛化能力。通过对历史信息进行高效压缩，MPS-SSM能够有效过滤非因果噪声和虚假模式，这对于实际应用中的数据质量问题至关重要。此外，该原则作为通用正则化框架的潜力，预示着它可能对更广泛的机器学习架构产生积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有选择性状态空间模型（如Mamba）的成功依赖于启发式设计的选择机制，缺乏严格的第一性原理推导，这引发了对其最优性和对抗虚假关联鲁棒性的质疑。

**Method:** 本文引入了“预测充分性原则”，该原则指出理想的隐状态应该是预测未来时对过去信息的最小充分统计量。基于此原则，提出了最小预测充分性状态空间模型（MPS-SSM），其选择机制通过优化从该原则导出的目标函数来指导，旨在最大程度地压缩历史信息同时不损失预测能力，从而学习忽略非因果噪声和虚假模式。此外，该原则还可以作为通用正则化框架来增强其他流行架构。

**Result:** MPS-SSM在广泛的基准数据集上实现了最先进的性能，在长期预测和噪声场景下显著优于现有模型，并展现出卓越的鲁棒性。

**Conclusion:** 最小预测充分性原则能够为状态空间模型的选择机制提供严格的理论指导，显著提升模型的性能和鲁棒性，并且该原则具有作为通用正则化框架的广泛潜力。

> **ai_Abstract:** 本文针对现有选择性状态空间模型选择机制缺乏理论基础的问题，提出了“预测充分性原则”，即理想隐状态应是预测未来时对过去信息的最小充分统计量。基于此，开发了最小预测充分性状态空间模型（MPS-SSM），其选择机制通过优化目标函数实现对历史信息的最大化压缩而不失预测力，从而提高模型抗噪声和虚假关联的能力。实验证明MPS-SSM在多种任务上达到SOTA性能，并在长期预测和噪声环境下展现出优越的鲁棒性。该原则还可作为通用正则化框架。

> **摘要翻译:** 状态空间模型（SSM），特别是最近的选择性变体如Mamba，已成为序列建模领域的主流架构，挑战了Transformer的主导地位。然而，这些最先进模型的成功在很大程度上依赖于启发式设计的选择机制，缺乏严格的第一性原理推导。这一理论空白引发了对其最优性和对抗虚假关联的鲁棒性的质疑。为了解决这个问题，我们引入了预测充分性原则，这是一种新颖的信息论准则，规定理想的隐状态应该是预测未来时对过去信息的最小充分统计量。基于这一原则，我们提出了最小预测充分性状态空间模型（MPS-SSM），这是一个新的框架，其中选择机制通过优化从我们原则中导出的目标函数来指导。这种方法鼓励模型在不损失预测能力的情况下最大程度地压缩历史信息，从而学习忽略非因果噪声和虚假模式。在广泛的基准数据集上进行的广泛实验表明，MPS-SSM不仅实现了最先进的性能，在长期预测和噪声场景下显著优于现有模型，而且表现出卓越的鲁棒性。此外，我们表明MPS原则可以作为一种通用正则化框架来增强其他流行的架构，突出了其广泛的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [36] [HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation](https://arxiv.org/abs/2508.03104)
> *HiTeC：基于文本属性超图的分层对比学习与语义感知增强*

*Mengting Pan, Fan Li, Xiaoyang Wang, Wenjie Zhang, Xuemin Lin* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 对比学习, 超图, 文本属性超图, 自监督学习, 语义感知增强

**Comment:** 12 pages, 18 figures

> **TL;DR:** HiTeC是一个两阶段的分层对比学习框架，针对文本属性超图（TAHGs）的自监督学习，通过结构感知预训练、语义感知数据增强和多尺度对比损失来解决现有方法在处理文本信息、数据增强和捕获长距离依赖方面的局限性，同时提高可扩展性。

**AI_Comments:** HiTeC的创新之处在于其两阶段的分层设计，有效地将文本编码器的结构感知预训练与超图对比学习解耦，显著提升了可扩展性。其次，引入的语义感知数据增强策略（提示增强文本增强和语义感知超边丢弃）克服了传统随机增强的局限性，生成了更具信息量的视图。最后，通过引入s-walk的子图级别对比，解决了现有方法难以捕获长距离依赖的问题，提升了表示学习的表达能力。该工作对于处理复杂多模态图数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有对比学习方法在处理具有丰富文本信息的超图时存在局限性：1) 图无关的文本编码器忽略文本内容与超图拓扑之间的关联；2) 随机数据增强引入噪声并削弱对比目标；3) 主要关注节点和超边级别的对比信号，限制了捕获长距离依赖的能力。此外，现有方法如HyperBERT存在可扩展性差的问题。

**Method:** 本文提出了HiTeC，一个两阶段的分层对比学习框架。第一阶段，使用结构感知对比目标预训练文本编码器，以克服传统方法的图无关性。第二阶段，引入两种语义感知增强策略：提示增强文本增强和语义感知超边丢弃，以生成信息丰富的视图。此外，提出了一个多尺度对比损失，通过基于s-walk的子图级别对比来捕获长距离依赖。通过解耦文本编码器预训练和超图对比学习，提高了可扩展性。

**Result:** 大量实验证实了HiTeC的有效性。

**Conclusion:** HiTeC通过其两阶段设计、语义感知增强和多尺度对比损失，有效地解决了文本属性超图自监督学习中的挑战，并在实验中展现出优异的性能和可扩展性。

> **ai_Abstract:** HiTeC是一个为文本属性超图（TAHGs）设计的两阶段分层对比学习框架。它旨在解决现有方法在整合文本信息、生成有效数据增强和捕获长距离依赖方面的不足，并提升可扩展性。第一阶段，HiTeC通过结构感知对比目标预训练文本编码器，使其能够感知超图拓扑。第二阶段，引入提示增强文本增强和语义感知超边丢弃两种语义感知增强策略，以创建高质量的对比视图。同时，提出了一个多尺度对比损失，通过结合子图级别的对比来捕获更长的依赖关系。该框架通过解耦预训练和对比学习过程，提高了整体的可扩展性。实验结果验证了HiTeC的有效性。

> **摘要翻译:** 对比学习（CL）已成为自监督超图学习的主导范式，无需昂贵的标签即可进行有效训练。然而，现实世界超图中的节点实体通常与丰富的文本信息相关联，这在以往的工作中被忽略了。直接将现有基于CL的方法应用于此类文本属性超图（TAHGs）会导致三个关键限制：(1) 图无关的文本编码器的普遍使用忽略了文本内容与超图拓扑之间的相关性，导致次优表示。(2) 它们对随机数据增强的依赖引入了噪声并削弱了对比目标。(3) 主要关注节点和超边级别的对比信号限制了捕获长距离依赖的能力，这对于表达性表示学习至关重要。尽管HyperBERT开创了TAHGs上的CL，但其协同训练范式存在可扩展性差的问题。为了填补研究空白，我们引入了HiTeC，一个两阶段的分层对比学习框架，具有语义感知增强，用于TAHGs上可扩展且有效的自监督学习。在第一阶段，我们使用结构感知对比目标预训练文本编码器，以克服传统方法的图无关性。在第二阶段，我们引入了两种语义感知增强策略，包括提示增强文本增强和语义感知超边丢弃，以促进信息丰富的视图生成。此外，我们提出了一种多尺度对比损失，通过基于s-walk的子图级别对比来扩展现有目标，以更好地捕获长距离依赖。通过将文本编码器预训练与超图对比学习解耦，这种两阶段设计在不损害表示质量的情况下增强了可扩展性。大量实验证实了HiTeC的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [45] [Heterogeneity-Oblivious Robust Federated Learning](https://arxiv.org/abs/2508.03579)
> *异构性无关的鲁棒联邦学习*

*Weiyao Zhang, Jinyang Li, Qi Song, Miao Wang, Chungang Lin, Haitong Luo, Xuying Meng, Yujun Zhang* | **Category: cs.LG, cs.NI** | **Updated: 2025-08-05**

**Keywords:** 联邦学习, 鲁棒性, 低秩适应, 投毒攻击, 异构性

**Comment:** Under review

> **TL;DR:** Horus是一个鲁棒的联邦学习框架，通过仅聚合低秩适应（LoRA）参数并利用LoRA-A的稳定性来检测中毒客户端，从而在高度异构环境下抵御投毒攻击并提高性能。

**AI_Comments:** Horus的创新点在于其利用LoRA进行参数聚合以减少攻击面，并发现LoRA-A在异构和投毒环境下的稳定性，从而有效识别并过滤中毒客户端。这种方法在应对真实世界的高度异构性挑战方面具有重要意义，因为它不仅提升了联邦学习的鲁棒性，也保持了模型的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）在数据分布、通信能力和模型架构高度异构的真实世界场景中，极易受到投毒攻击。这种异构性不仅削弱了聚合策略的有效性，还使攻击更难被检测。此外，高维模型增加了攻击面，因此需要一种新的方法来解决这些挑战。

**Method:** 本文提出了Horus，一个以低秩适应（LoRA）为核心的异构性无关鲁棒联邦学习框架。Horus不聚合完整的模型参数，而是将LoRA插入经验稳定的层中，并仅聚合LoRA以减少攻击面。研究发现，在异构性和投毒攻击下，输入投影（LoRA-A）比输出投影（LoRA-B）更稳定。利用这一观察，设计了一种使用LoRA-A特征的异构性无关投毒评分来过滤中毒客户端。对于剩余的良性客户端，提出了一种投影感知聚合机制，通过根据与全局方向的一致性重新加权客户端更新来保留协作信号并抑制漂移。

**Result:** 在各种数据集、模型架构和攻击类型上的大量实验表明，Horus在鲁棒性和准确性方面始终优于最先进的基线方法。

**Conclusion:** Horus通过创新的LoRA聚合和基于LoRA-A的投毒检测机制，成功地解决了联邦学习在高度异构环境下面临的投毒攻击挑战，显著提升了系统的鲁棒性和准确性。

> **ai_Abstract:** 本文提出Horus，一个鲁棒的联邦学习框架，旨在解决高度异构环境下联邦学习面临的投毒攻击问题。Horus通过聚合低秩适应（LoRA）参数而非完整模型来缩小攻击面，并利用LoRA-A（输入投影）在异构和投毒下的稳定性来设计投毒评分以过滤恶意客户端。对于良性客户端，Horus采用投影感知聚合机制来优化模型更新。实验结果表明，Horus在鲁棒性和准确性上均优于现有基线。

> **摘要翻译:** 联邦学习（FL）极易受到投毒攻击，尤其是在真实世界中高度异构的环境下，客户端在数据分布、通信能力和模型架构上存在显著差异。这种异构性不仅削弱了聚合策略的有效性，还使得攻击更难被检测。此外，高维模型扩大了攻击面。为了应对这些挑战，我们提出了Horus，一个以低秩适应（LoRA）为核心的异构性无关的鲁棒FL框架。Horus不聚合完整的模型参数，而是将LoRA插入经验稳定的层中，并仅聚合LoRA以减少攻击面。我们发现了一个关键的经验观察：在异构性和投毒攻击下，输入投影（LoRA-A）比输出投影（LoRA-B）明显更稳定。利用这一点，我们设计了一个使用LoRA-A特征的异构性无关投毒评分来过滤中毒客户端。对于剩余的良性客户端，我们提出了投影感知聚合机制，通过与全局方向的一致性重新加权客户端更新，以保留协作信号同时抑制漂移。在各种数据集、模型架构和攻击类型上进行的大量实验表明，Horus在鲁棒性和准确性方面始终优于最先进的基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [48] [PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty](https://arxiv.org/abs/2202.05063)
> *PCENet：用于学习不确定性的高维代理建模*

*Paz Fink Shustin, Shashanka Ubaru, Małgorzata J. Zimoń, Songtao Lu, Vasileios Kalantzis, Lior Horesh, Haim Avron* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-04**

**Keywords:** 不确定性量化, 代理建模, 降维, 变分自编码器, 多项式混沌展开

**Comment:** 

> **TL;DR:** PCENet提出了一种降维代理建模方法，结合变分自编码器和多项式混沌展开，以高效地在高维数据中进行不确定性量化和表示学习。

**AI_Comments:** 该论文提出了一种结合深度学习（变分自编码器）和传统不确定性量化方法（多项式混沌展开）的混合模型，这在处理高维不确定性问题上具有创新性。通过降维，它有效降低了不确定性量化的计算成本，并能够处理无先验假设的数据，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在科学计算和数据分析应用中，学习不确定性下的数据表示是一项重要任务。然而，不确定性量化技术计算成本高昂，对于高维数据而言更是难以承受。

**Method:** 该方法是一种两阶段学习过程：1) 使用变分自编码器学习输入数据分布的低维表示；2) 利用多项式混沌展开（PCE）将低维分布映射到输出目标。该模型能够高效地捕获系统动力学、在不确定性下学习数据表示和输入输出分布之间的映射、估计高维数据系统中的不确定性，并匹配输出分布的高阶矩，且无需任何先验统计假设。

**Result:** 数值结果展示了所提出方法的性能。

**Conclusion:** 该研究提出了一种名为PCENet的降维代理建模方法，能够有效解决高维数据下不确定性量化和表示学习的计算挑战，并在无先验统计假设下实现多项能力。

> **ai_Abstract:** PCENet提出了一种新颖的降维代理建模（DRSM）方法，用于解决高维数据中不确定性下表示学习和不确定性量化的计算挑战。该方法采用两阶段过程：首先利用变分自编码器学习数据的低维表示，然后通过多项式混沌展开将低维分布映射到输出目标。该模型能够在没有先验统计假设的情况下，高效地捕获系统动力学、学习数据表示、估计不确定性并匹配输出分布的高阶矩。数值结果验证了其性能。

> **摘要翻译:** 在不确定性下学习数据表示是一项重要的任务，出现在众多科学计算和数据分析应用中。然而，不确定性量化技术计算成本高昂，对于高维数据而言更是难以承受。在本研究中，我们引入了一种降维代理建模（DRSM）方法，用于表示学习和不确定性量化，旨在处理中高维数据。该方法包括一个两阶段学习过程：1) 采用变分自编码器学习输入数据分布的低维表示；2) 利用多项式混沌展开（PCE）公式将低维分布映射到输出目标。该模型使我们能够 (a) 在低维潜在空间中高效地捕获系统动力学，(b) 在不确定性下学习数据的表示以及输入和输出分布之间的映射，(c) 估计高维数据系统中的这种不确定性，以及 (d) 匹配输出分布的高阶矩；所有这些都无需对数据进行任何先验统计假设。本文提供了数值结果以说明所提出方法的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [53] [Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction](https://arxiv.org/abs/2508.03613)
> *Goedel-Prover-V2: 通过脚手架数据合成和自校正扩展形式化定理证明*

*Yong Lin, Shange Tang, Bohan Lyu, Ziran Yang, Jui-Hui Chung, Haoyu Zhao, Lai Jiang, Yihan Geng, Jiawei Ge, Jingruo Sun, Jiayun Wu, Jiri Gesi, Ximing Lu, David Acuna, Kaiyu Yang, Hongzhou Lin, Yejin Choi, Danqi Chen, Sanjeev Arora, Chi Jin* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 自动化定理证明, 语言模型, 数据合成, 自校正, Goedel-Prover-V2

**Comment:** 24 pages, 10 figures, 4 tables

> **TL;DR:** Goedel-Prover-V2 是一个开源语言模型系列，通过数据合成、自校正和模型平均，在自动化定理证明方面达到了新的SOTA，且模型更小、效率更高。

**AI_Comments:** 该论文通过引入脚手架数据合成、验证器引导的自校正和模型平均等创新机制，显著提升了自动化定理证明的性能，并实现了在更小模型规模下超越大型模型的能力，这在资源受限的场景下具有重要意义。其开源性质也促进了社区的进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过引入创新的训练方法，解决现有自动化定理证明模型在性能、可扩展性和效率方面的挑战，从而在形式化定理证明领域实现新的突破。

**Method:** 该方法基于标准的专家迭代和强化学习流程，并引入了三项关键创新：1) 脚手架数据合成：生成难度递增的合成任务来训练模型掌握复杂定理；2) 验证器引导的自校正：模型利用Lean编译器反馈迭代修正证明；3) 模型平均：合并模型检查点以缓解训练后期模型输出多样性下降的问题。

**Result:** 小型模型 Goedel-Prover-V2-8B 在 MiniF2F 上 pass@32 达到 84.6%，性能优于尺寸大80倍的 DeepSeek-Prover-V2-671B。旗舰模型 Goedel-Prover-V2-32B 在 MiniF2F 上 pass@32 标准模式下达到 88.1%，自校正模式下达到 90.4%，大幅超越此前SOTA。此外，该旗舰模型在 PutnamBench 上 pass@184 解决了 86 个问题，位列开源模型排行榜第一，显著超越 DeepSeek-Prover-V2-671B 的记录（47个问题，pass@1024），且模型尺寸和计算预算更小。发布时（2025年7-8月），Goedel-Prover-V2 在所有开源定理证明器中表现最佳，并在受限测试计算预算下跻身顶级模型之列。

**Conclusion:** Goedel-Prover-V2 通过其创新的训练方法，在自动化定理证明领域实现了显著的性能提升，尤其在开源模型中树立了新的标杆，并在效率上展现出巨大优势，证明了在更小模型尺寸下实现卓越性能的可能性。

> **ai_Abstract:** Goedel-Prover-V2 是一个开源语言模型系列，通过结合脚手架数据合成、验证器引导的自校正和模型平均等创新方法，在自动化定理证明领域取得了突破性进展。该系列模型在MiniF2F和PutnamBench等基准测试上均大幅超越现有最先进水平，尤其是在模型尺寸显著减小的情况下，性能表现优异，确立了开源定理证明器的新标杆。

> **摘要翻译:** 我们推出了 Goedel-Prover-V2，这是一系列开源语言模型，在自动化定理证明方面树立了新的最先进水平。我们的方法建立在标准的专家迭代和强化学习流程之上，并融入了三项关键创新：(1) 脚手架数据合成：我们生成难度递增的合成任务，以训练模型掌握日益复杂的定理；(2) 验证器引导的自校正：我们使模型能够通过利用 Lean 编译器的反馈迭代修改其证明；(3) 模型平均：我们合并模型检查点，以减轻训练后期模型输出多样性下降的问题。我们的小型模型 Goedel-Prover-V2-8B 在 MiniF2F 上 pass@32 达到 84.6%，尽管尺寸小 80 倍，但性能优于 DeepSeek-Prover-V2-671B。我们的旗舰模型 Goedel-Prover-V2-32B 在 MiniF2F 上 pass@32 标准模式下达到 88.1%，自校正模式下达到 90.4%，大幅超越了之前的 SOTA。此外，我们的旗舰模型在 PutnamBench 上 pass@184 解决了 86 个问题，在开源模型排行榜上名列第一，以显著更小的模型尺寸和计算预算，超越了 DeepSeek-Prover-V2-671B 解决 47 个问题的 pass@1024 记录。在发布时（2025 年 7 月至 8 月），Goedel-Prover-V2 在所有开源定理证明器中实现了最强的整体性能。在受限的测试时间计算预算下，它也位列表现最佳的模型之列——包括公开报告性能的闭源系统。我们的模型、代码和数据已在 https://github.com/Goedel-LM/Goedel-Prover-V2 发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [PPFL: A Personalized Federated Learning Framework for Heterogeneous Population](https://arxiv.org/abs/2310.14337)
> *PPFL: 一种针对异构群体的个性化联邦学习框架*

*Hao Di, Yi Yang, Haishan Ye, Xiangyu Chang* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 联邦学习, 个性化, 异构性, 隐私保护, 随机块坐标下降

**Comment:** 

> **TL;DR:** PPFL是一个新的联邦学习框架，通过“规范模型”和“成员向量”处理数据异构性，实现个性化且保护隐私，并优于现有方法。

**AI_Comments:** PPFL的创新点在于其通过“规范模型”和“成员向量”对异构性进行建模，提供了对客户端偏好的深入洞察，这是现有PFL方法所欠缺的。这种方法不仅实现了隐私保护下的个性化，还增强了模型的可解释性，对联邦学习领域具有重要意义。提出的随机块坐标下降算法也保证了其优化问题的可解性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的个性化方法是集中式的，可能在汇集个人信息时暴露原始数据。现有的个性化联邦学习（PFL）方法缺乏对客户端特征的深入洞察。

**Method:** PPFL（群体个性化联邦学习）利用“规范模型”捕获异构群体的基本特征，并使用“成员向量”揭示客户端偏好，从而将异构性建模为客户端对这些特征的不同偏好。为了解决PPFL的非凸优化问题，提出了一种新的随机块坐标下降算法，并建立了其收敛性。

**Result:** 实验结果验证了PPFL在病理和实际数据集上的有效性。

**Conclusion:** PPFL提供了一种灵活且可解释的个性化联邦学习框架，通过对客户端特征的深入洞察来有效处理异构性，并优于现有的PFL方法。

> **ai_Abstract:** 本文提出了PPFL（群体个性化联邦学习），一个在联邦学习范式下，考虑隐私的个性化框架。PPFL通过引入“规范模型”捕捉群体特征和“成员向量”表示客户端偏好来处理异构性，从而提供对客户端特征的深入理解。研究还探讨了PPFL与现有PFL方法的联系及其优势，并提出了一种随机块坐标下降算法来解决其非凸优化问题。实验结果验证了PPFL在不同数据集上的有效性。

> **摘要翻译:** 个性化旨在表征个体偏好，并广泛应用于许多领域。然而，传统的个性化方法以集中式方式运行，在汇集个人信息时可能暴露原始数据。在本文中，考虑到隐私问题，我们在联邦学习范式内开发了一个灵活且可解释的个性化框架，称为PPFL（群体个性化联邦学习）。通过利用“规范模型”捕获异构群体的基本特征，并采用“成员向量”揭示客户端偏好，PPFL将异构性建模为客户端对这些特征的不同偏好。这种方法为客户端特征提供了实质性见解，这是现有个性化联邦学习（PFL）方法所缺乏的。此外，我们探讨了PPFL与PFL方法的三大分支：聚类FL、多任务PFL和解耦PFL之间的关系，并展示了PPFL的优势。为了解决PPFL（一个带有线性约束的非凸优化问题），我们提出了一种新的随机块坐标下降算法，并建立了其收敛性。我们在病理和实际数据集上进行了实验，结果验证了PPFL的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [64] [Efficient Time Series Processing for Transformers and State-Space Models through Token Merging](https://arxiv.org/abs/2405.17951)
> *通过令牌合并实现Transformer和状态空间模型的高效时间序列处理*

*Leon Götz, Marcel Kollovieh, Stephan Günnemann, Leo Schwinn* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 令牌合并, 时间序列, Transformer, 状态空间模型, 局部合并

**Comment:** 21 pages in total, 20 figures

> **TL;DR:** 本文首次将令牌合并应用于时间序列的Transformer和状态空间模型，并引入了一种名为局部合并的新算法，该算法能够将计算复杂度从二次方降低到线性，并支持Transformer解码器中的因果合并，从而显著提高效率并保持精度，在Chronos模型上实现高达5400%的加速。

**AI_Comments:** 这项工作创新性地将计算机视觉领域的令牌合并技术引入到时间序列分析中，并针对时间序列的特点提出了“局部合并”这一新颖算法。其能够将计算复杂度从二次方降低到线性，以及支持Transformer解码器中的因果合并，是重要的技术突破。尤其是在Chronos基础模型上实现的巨大加速，突显了其在处理长序列数据方面的实际应用价值和潜力，对于未来大型时间序列模型的效率提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管次二次注意力机制或状态空间模型取得了进展，但处理长令牌序列仍然需要大量的计算资源。

**Method:** 本文首次将令牌合并技术应用于时间序列分析中的Transformer和状态空间模型。此外，论文引入了一种领域特定的令牌合并算法——局部合并，该算法选择性地合并局部邻域内的令牌。局部合并能够根据邻域大小将计算复杂度从二次方调整为线性，从而有效扩展到长序列；它也是第一个实现Transformer解码器中令牌合并的因果合并方案。研究还识别了输入数据的光谱特性，这些特性可以可靠地预测局部合并的潜在益处，而无需在下游任务上进行评估。

**Result:** 局部合并在保持最小精度影响的同时，提供了显著的效率提升，在最近提出的Chronos基础模型上实现了高达5400%的加速。

**Conclusion:** 通过引入局部合并算法，该研究成功地将令牌合并技术应用于时间序列的Transformer和状态空间模型，显著提高了长序列处理的计算效率，同时保持了高精度，并解决了Transformer解码器中的因果合并问题。

> **ai_Abstract:** 该研究首次将令牌合并技术应用于时间序列领域的Transformer和状态空间模型，以解决长序列处理中的高计算成本问题。论文提出了一种新的领域特定算法——局部合并，它通过选择性地合并局部令牌，实现了计算复杂度从二次方到线性的可调性，并首次支持Transformer解码器中的因果合并。实验结果表明，局部合并在保持高精度的同时，显著提升了效率，在Chronos模型上实现了高达5400%的加速。

> **摘要翻译:** 尽管次二次注意力机制或状态空间模型取得了最新进展，但处理长令牌序列仍然需要大量的计算资源。令牌合并已成为计算机视觉架构中提高计算效率的解决方案。在这项工作中，我们首次在时间序列分析中对Transformer和状态空间模型上的令牌合并进行了研究。我们进一步引入了局部合并，这是一种领域特定的令牌合并算法，它选择性地合并局部邻域内的令牌，实现了两大优势：a) 局部合并可以根据邻域大小将其计算复杂度从二次方调整为线性，从而有效地扩展到长序列；b) 局部合并是第一个支持Transformer解码器中令牌合并的因果合并方案。此外，我们确定了输入数据的光谱特性，这些特性可以可靠地预测局部合并的潜在益处，而无需在下游任务上进行评估。我们全面的实证评估表明，局部合并在对精度影响最小的情况下提供了显著的效率提升，在最近提出的Chronos基础模型上实现了高达5400%的加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [72] [Risk-averse learning with delayed feedback](https://arxiv.org/abs/2409.16866)
> *具有延迟反馈的风险规避学习*

*Siyi Wang, Zifan Wang, Karl Henrik Johansson, Sandra Hirche* | **Category: cs.LG, math.OC** | **Updated: 2025-08-04**

**Keywords:** 风险规避学习, 延迟反馈, CVaR, 零阶优化, 遗憾分析

**Comment:** 

> **TL;DR:** 本文研究了具有随机但有界延迟反馈的风险规避学习，开发了两种基于零阶优化的算法，并分析了它们的动态遗憾界，通过数值实验验证了性能。

**AI_Comments:** 本文的创新之处在于将零阶优化方法应用于具有延迟反馈的风险规避学习问题，这在实际应用中具有重要意义。对单点和两点算法的对比分析，以及理论遗憾界与实践性能的验证，提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界中，风险规避学习对于减轻潜在的不利结果非常重要。然而，延迟反馈使得有效评估和管理风险变得具有挑战性。

**Method:** 本文使用条件风险价值（CVaR）作为风险度量，研究了具有随机但有界延迟反馈的风险规避学习。开发了两种分别依赖于单点和两点零阶优化方法的风险规避学习算法。

**Result:** 算法的动态遗憾（dynamic regrets）根据累积延迟和总采样次数进行分析。在没有延迟的情况下，遗憾界与已建立的零阶随机梯度方法的风险规避学习界限相匹配。此外，两点风险规避学习算法通过实现更小的遗憾界而优于单点算法。在动态定价问题上的数值实验验证了算法的性能。

**Conclusion:** 本文成功开发并分析了在延迟反馈下进行风险规避学习的算法，并提供了理论保障和数值验证，表明其在实际应用中的潜力。

> **ai_Abstract:** 本文针对延迟反馈下风险规避学习的挑战，提出了两种基于零阶优化的风险规避学习算法，分别采用单点和两点方法，并以条件风险价值（CVaR）作为风险度量。研究分析了这些算法的动态遗憾界，结果表明在无延迟情况下，其性能与现有零阶随机梯度方法相当，且两点算法的遗憾界更小，性能更优。通过动态定价问题的数值实验验证了算法的有效性。

> **摘要翻译:** 在现实世界中，风险规避学习对于减轻潜在的不利结果非常重要。然而，延迟反馈使得有效评估和管理风险变得具有挑战性。在本文中，我们使用条件风险价值（CVaR）作为风险度量，并结合随机但有界延迟的反馈，研究了风险规避学习。我们开发了两种分别依赖于单点和两点零阶优化方法的风险规避学习算法。这些算法的动态遗憾根据累积延迟和总采样次数进行分析。在没有延迟的情况下，遗憾界与已建立的零阶随机梯度方法的风险规避学习界限相匹配。此外，两点风险规避学习算法通过实现更小的遗憾界而优于单点算法。我们提供了在动态定价问题上的数值实验，以证明算法的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [78] [Augmented Adversarial Trigger Learning](https://arxiv.org/abs/2503.12339)
> *增强对抗性触发器学习*

*Zhe Wang, Yanjun Qi* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 对抗性触发器学习, 大型语言模型越狱, 系统提示提取, 增强优化, ATLA

**Comment:** 

> **TL;DR:** ATLA通过增强优化目标，显著提升了对抗性触发器学习的效率和成功率，仅需少量查询即可越狱大型语言模型并提取系统提示。

**AI_Comments:** ATLA的创新之处在于其改进的优化目标（加权损失和辅助损失），这显著提高了对抗性触发器学习的效率（仅需一个查询）和攻击成功率。其高泛化性和对新LLM的迁移能力也突出了其方法的鲁棒性。这对于理解和防御LLM的对抗性攻击具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于梯度优化的对抗性攻击方法在学习对抗性触发器以生成越狱提示或泄露系统提示时，可能存在效率或效果上的局限性，特别是在查询次数方面。

**Method:** 本文提出了ATLA（Adversarial Trigger Learning with Augmented objectives）。ATLA通过将现有研究使用的负对数似然损失改进为加权损失公式，鼓励学习到的对抗性触发器更多地优化响应格式标记。这使得ATLA能够仅从一个查询-响应对中学习对抗性触发器，并且学习到的触发器能很好地泛化到其他类似查询。此外，还设计了一个变体，通过辅助损失来抑制回避性响应，从而增强触发器优化。

**Result:** ATLA在攻击成功率上持续优于现有最先进技术，实现近100%的攻击成功率，同时所需查询次数减少80%。ATLA学习到的越狱后缀对未见过的查询表现出高泛化性，并能很好地迁移到新的大型语言模型。

**Conclusion:** ATLA通过增强优化目标，显著提高了对抗性触发器学习的效率、成功率和泛化能力，为越狱大型语言模型和提取隐藏系统提示提供了一种更有效的方法。

> **ai_Abstract:** 本文提出了ATLA（Adversarial Trigger Learning with Augmented objectives），一种改进的对抗性触发器学习方法。ATLA通过引入加权损失和可选的辅助损失来增强优化目标，使其能够仅用一个查询-响应对学习越狱大型语言模型和提取系统提示的对抗性触发器。实验结果表明，ATLA在攻击成功率、查询效率和泛化能力方面均显著优于现有SOTA技术。

> **摘要翻译:** 梯度优化对抗性攻击方法自动化学习对抗性触发器，以生成越狱提示或泄露系统提示。在这项工作中，我们仔细研究了对抗性触发器学习的优化目标，并提出了ATLA：具有增强目标的对抗性触发器学习。ATLA将先前研究中使用的负对数似然损失改进为加权损失公式，鼓励学习到的对抗性触发器更多地优化响应格式标记。这使得ATLA能够仅从一个查询-响应对中学习对抗性触发器，并且学习到的触发器能够很好地泛化到其他类似查询。我们进一步设计了一个变体，通过辅助损失来增强触发器优化，以抑制回避性响应。我们展示了如何使用ATLA学习对抗性后缀来越狱大型语言模型并提取隐藏的系统提示。经验上，我们证明ATLA持续优于当前最先进的技术，在攻击中实现近100%的成功率，同时所需查询次数减少80%。ATLA学习到的越狱后缀对未见过的查询表现出高泛化性，并能很好地迁移到新的大型语言模型。我们发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [79] [Low-Bit Integerization of Vision Transformers using Operand Reordering for Efficient Hardware](https://arxiv.org/abs/2504.18547)
> *使用操作数重排序实现视觉Transformer的低位整数化以提高硬件效率*

*Ching-Yi Lin, Sahil Shah* | **Category: cs.LG, cs.CV, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 视觉Transformer, 量化, 整数化, 操作数重排序, 硬件效率

**Comment:** 4 pages + references, 5 figures, 2 tables in IEEE double column
  conference template

> **TL;DR:** 本文提出一种基于操作数重排序的整数化过程，通过延迟反量化操作，实现视觉Transformer在硬件上的高效低位推理，显著降低功耗。

**AI_Comments:** 该论文提出了一种新颖的整数化策略，通过改变计算顺序（操作数重排序）来避免量化模型在硬件推理中常见的反量化开销。这种方法直接在量化域进行计算，对于提高深度学习模型在边缘设备上的部署效率具有重要意义。其创新点在于对计算图的深入分析并提出了实用的优化方案，有效弥合了量化模型与高效硬件推理之间的差距。

<details>
  <summary>Details</summary>

**Motivation:** 预训练视觉Transformer在视觉任务中表现出色，但计算和内存成本高昂。模型量化虽然减少了内存使用，但由于矩阵操作前的反量化，仍存在显著的计算开销。

**Method:** 分析计算图并提出一种基于操作数重排序的整数化过程。具体而言，该过程将反量化延迟到矩阵操作之后，从而可以直接处理量化输入，实现整数化的矩阵乘法和线性模块。

**Result:** 在基于脉动阵列的硬件上合成ViT的自注意力模块进行验证。实验结果表明，所提出的低位推理减少了线性层和矩阵乘法的每个处理单元的功耗。

**Conclusion:** 通过延迟反量化操作实现操作数重排序的整数化过程，有效降低了视觉Transformer在硬件推理时的功耗，弥合了量化模型与高效推理之间的差距。

> **ai_Abstract:** 本文针对视觉Transformer计算和内存开销大的问题，提出了一种低位整数化方法。该方法通过分析计算图，引入操作数重排序，将反量化操作延迟到矩阵操作之后，从而可以直接对量化输入进行整数化矩阵乘法和线性模块处理。在脉动阵列硬件上验证ViT自注意力模块，实验结果显示该方法有效降低了线性层和矩阵乘法的功耗，提升了量化模型的硬件推理效率。

> **摘要翻译:** 预训练视觉Transformer在各种视觉任务中取得了卓越的性能，但其计算和内存成本高昂。虽然模型量化通过降低精度减少了内存使用，但由于矩阵操作前的反量化，这些模型仍然产生显著的计算开销。在这项工作中，我们分析了计算图并提出了一种基于操作数重排序的整数化过程。具体而言，该过程将反量化延迟到矩阵操作之后。这使得通过直接处理量化输入，可以实现整数化的矩阵乘法和线性模块。为了验证我们的方法，我们在基于脉动阵列的硬件上合成了ViT的自注意力模块。实验结果表明，我们的低位推理降低了线性层和矩阵乘法的每个处理单元的功耗，弥合了量化模型和高效推理之间的差距。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [80] [Clinicians' Voice: Fundamental Considerations for XAI in Healthcare](https://arxiv.org/abs/2411.04855)
> *临床医生的声音：医疗领域可解释人工智能的基本考量*

*T. E. Röber, R. Goedhart, S. İ. Birbil* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 可解释人工智能, 医疗保健, 临床医生, 用户研究, 工作流程

**Comment:** 

> **TL;DR:** 研究通过访谈临床医生，发现他们对医疗AI持积极态度但担忧工作流程和医患关系，强调医生培训和了解其需求对XAI成功至关重要。

**AI_Comments:** 本研究的创新之处在于直接采纳了最终用户——临床医生的声音，弥补了当前XAI研究中缺乏实际用户输入的不足。这对于确保XAI工具在医疗实践中的有效性和实用性至关重要。研究结果强调了工作流程整合、医患关系以及医生培训等关键因素，为未来医疗XAI的设计和部署提供了宝贵的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数可解释人工智能（XAI）研究缺乏最终用户（如临床医生）的输入，导致其实际价值有限。本研究旨在解决这一问题，获取临床医生的观点。

**Method:** 研究通过对临床医生进行半结构化访谈，讨论他们对开发和应用基于AI的工具的看法、期望和担忧。

**Result:** 样本中的临床医生普遍对开发医疗AI工具持积极态度，但担忧AI如何融入其工作流程以及对医患关系的影响。研究还发现AI培训对临床医生至关重要，并明确了临床医生在(X)AI工具中寻找的方面。

**Conclusion:** 临床医生对AI在医疗中的应用有积极态度，但其在工作流程和医患关系方面的担忧，以及对医生进行AI培训的需求，是确保XAI在医疗领域成功落地的关键考量。本研究采取了整体性和探索性视角，旨在识别医疗(X)AI产品的通用要求。

> **ai_Abstract:** 本研究旨在通过对临床医生进行半结构化访谈，解决当前可解释人工智能（XAI）研究缺乏最终用户输入的问题。结果显示，临床医生普遍支持医疗AI发展，但也关注其对工作流程和医患关系的影响，并强调了医生AI培训的重要性。研究识别了临床医生对(X)AI工具的具体需求，并采取整体探索性方法，为医疗XAI产品提出了通用要求。

> **摘要翻译:** 可解释人工智能（XAI）有望推动人工智能工具在实践中的实施和采用，尤其是在医疗等高风险环境中。然而，当前大多数研究缺乏来自最终用户的输入，因此其实际价值有限。为了解决这个问题，我们对临床医生进行了半结构化访谈，讨论了他们的想法、希望和担忧。我们样本中的临床医生普遍对开发用于临床实践的基于人工智能的工具持积极态度，但他们担心这些工具如何融入他们的工作流程以及如何影响医患关系。我们进一步将临床医生的人工智能培训确定为人工智能在医疗领域取得成功的关键因素，并强调了临床医生在（可解释）人工智能工具中正在寻找的方面。与其他研究不同的是，我们采取了一种整体性和探索性的视角，在测试特定工具之前，识别医疗领域（可解释）人工智能产品的通用要求。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [87] [Class Imbalance in Anomaly Detection: Learning from an Exactly Solvable Model](https://arxiv.org/abs/2501.11638)
> *类别不平衡在异常检测中的应用：从一个精确可解模型中学习*

*F. S. Pezzicoli, V. Ros, F. P. Landes, M. Baity-Jesi* | **Category: cs.LG, cond-mat.dis-nn, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 类别不平衡, 异常检测, 理论框架, 复制理论, 感知器模型

**Comment:** version accepted at AISTATS 2025

> **TL;DR:** 本文通过复制理论，基于教师-学生感知器模型，提供了一个理论框架来分析和解决机器学习中（特别是异常检测领域）长期存在的类别不平衡问题，并揭示了最优训练不平衡通常不同于50%，且依赖于内在不平衡、数据量和学习噪声。

**AI_Comments:** 本文的创新之处在于通过一个精确可解的模型（教师-学生感知器模型结合复制理论）为类别不平衡问题提供了一个坚实的理论基础，而非仅仅依赖经验性方法。它不仅解释了类别不平衡的多种来源，还推翻了最优训练不平衡为50%的传统认知，为实际应用提供了更精细的指导，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 类别不平衡（CI）是机器学习中一个长期存在的问题，它会减慢训练速度并降低性能。尽管存在经验性的补救措施，但由于缺乏一个全面的理论，通常不清楚哪种方法效果最好以及何时使用。

**Method:** 本文提供了一个理论框架来分析、解释和解决类别不平衡问题。该框架基于通过复制理论对教师-学生感知器模型的精确解。

**Result:** 在该框架内，可以区分几种类别不平衡的来源：内在不平衡、训练不平衡或测试不平衡。分析表明，最优训练不平衡通常与50%不同，并且对内在不平衡、数据量和学习中的噪声具有非平凡的依赖性。此外，在小噪声训练机制（结果与噪声水平无关）和高噪声机制（性能随噪声迅速下降）之间存在一个交叉点。

**Conclusion:** 本文的结果挑战了关于类别不平衡的一些传统观念，并提供了解决该问题的实用指导。

> **ai_Abstract:** 本文针对机器学习中，特别是异常检测领域的类别不平衡问题，提出了一个基于教师-学生感知器模型和复制理论的理论框架。该框架能够区分内在、训练和测试不平衡等多种来源，并揭示了最优训练不平衡并非固定在50%，而是复杂依赖于内在不平衡、数据量和学习噪声。研究还发现了小噪声与高噪声训练机制之间的性能交叉点，这些发现挑战了传统观念并提供了实用的指导。

> **摘要翻译:** 类别不平衡（CI）是机器学习中一个长期存在的问题，它会减慢训练速度并降低性能。尽管存在经验性的补救措施，但由于缺乏一个全面的理论，通常不清楚哪种方法效果最好以及何时使用。我们解决了不平衡的一个常见情况，即异常（或离群点）检测。我们提供了一个理论框架来分析、解释和解决类别不平衡。它基于通过复制理论对教师-学生感知器模型的精确解。在该框架内，可以区分几种类别不平衡的来源：内在不平衡、训练不平衡或测试不平衡。我们的分析表明，最优训练不平衡通常与50%不同，并且对内在不平衡、数据量和学习中的噪声具有非平凡的依赖性。此外，在小噪声训练机制（结果与噪声水平无关）和高噪声机制（性能随噪声迅速下降）之间存在一个交叉点。我们的结果挑战了关于类别不平衡的一些传统观念，并提供了解决该问题的实用指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [91] [Pulse Shape Discrimination Algorithms: Survey and Benchmark](https://arxiv.org/abs/2508.02750)
> *脉冲形状甄别算法：综述与基准测试*

*Haoran Liu, Yihan Zhan, Mingzhe Liu, Yanhua Liu, Peng Li, Zhuo Zuo, Bingqi Liu, Runxi Liu* | **Category: cs.LG, cs.AI, nucl-ex, physics.app-ph, physics.atom-ph** | **Updated: 2025-08-03**

**Keywords:** 脉冲形状甄别, 深度学习, 辐射探测, 算法基准, 开源工具箱

**Comment:** 

> **TL;DR:** 该论文对近六十种脉冲形状甄别（PSD）算法进行了全面的综述和基准测试，并发现深度学习模型在辐射探测中的表现优于传统方法，同时发布了开源工具箱和数据集以促进研究。

**AI_Comments:** 这项工作的重要性在于其对现有脉冲形状甄别（PSD）算法进行了全面且系统的基准测试，为研究人员提供了宝贵的比较数据。创新之处在于不仅评估了传统方法，还深入探讨了深度学习在PSD领域的应用潜力。尤其值得称赞的是，作者发布了开源工具箱和数据集，这对于推动该领域的研究进展和确保结果的可重复性具有里程碑意义。

<details>
  <summary>Details</summary>

**Motivation:** 对辐射探测中现有的脉冲形状甄别（PSD）算法进行全面的调查和基准测试，以评估它们的性能并识别最佳方法。

**Method:** 作者将近六十种脉冲形状甄别（PSD）方法分为统计学（时域、频域、神经网络）和先验知识（机器学习、深度学习）范式。他们将所有算法在两个标准化数据集（一个来自241Am-9Be源的未标记数据集和一个来自238Pu-9Be源的飞行时间标记数据集）上进行实现和评估，使用包括品质因数（FOM）、F1分数、ROC-AUC和方法间相关性等指标。

**Result:** 分析显示，深度学习模型，特别是多层感知器（MLPs）和结合统计特征与神经回归的混合方法，通常优于传统方法。论文还讨论了架构的适用性、FOM的局限性、替代评估指标以及在不同能量阈值下的性能。

**Conclusion:** 深度学习模型在脉冲形状甄别任务中表现出色，且该研究通过发布开源工具箱和数据集，极大地促进了PSD研究的可重复性和进展。

> **ai_Abstract:** 该论文全面综述并基准测试了近六十种辐射探测中的脉冲形状甄别（PSD）算法。研究将这些算法分为统计学和先验知识两大类，并在两个标准化数据集上使用多种指标进行了实现和评估。结果表明，深度学习模型，特别是MLPs和混合方法，表现优于传统方法。论文还探讨了架构、评估指标和性能限制，并发布了开源工具箱和数据集，以增强研究的可重复性和进展。

> **摘要翻译:** 这篇综述对用于辐射探测的脉冲形状甄别（PSD）算法进行了全面的调查和基准测试，将近六十种方法分为统计学（时域、频域、神经网络）和先验知识（机器学习、深度学习）范式。我们实现了所有算法，并在两个标准化数据集上进行了评估：一个来自241Am-9Be源的未标记数据集和一个来自238Pu-9Be源的飞行时间标记数据集，评估指标包括品质因数（FOM）、F1分数、ROC-AUC和方法间相关性。我们的分析表明，深度学习模型，特别是多层感知器（MLPs）和结合统计特征与神经回归的混合方法，通常优于传统方法。我们讨论了架构的适用性、FOM的局限性、替代评估指标以及在不同能量阈值下的性能。伴随这项工作，我们发布了一个Python和MATLAB的开源工具箱以及相关数据集，以促进可重复性和推进PSD研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [96] [A First-order Generative Bilevel Optimization Framework for Diffusion Models](https://arxiv.org/abs/2502.08808)
> *扩散模型的一阶生成式双层优化框架*

*Quan Xiao, Hui Yuan, A F M Saif, Gaowen Liu, Ramana Kompella, Mengdi Wang, Tianyi Chen* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 双层优化, 生成模型, 梯度估计, 微调

**Comment:** Cameral-ready version: added experiments using the HPSv2 reward,
  improved notation consistency for the diffusion model, and added related
  works

> **TL;DR:** 本文提出了一种一阶生成式双层优化框架，以解决扩散模型在下游任务优化中遇到的传统双层方法因高维概率空间和采样成本高昂而失效的问题。该框架针对微调和噪声调度优化两种场景，设计了计算上可行且高效的梯度估计器，并在实验中表现优于现有基线。

**AI_Comments:** 本文的创新点在于将扩散模型的优化问题成功地转化为一阶生成式双层优化框架，并设计出针对性的梯度估计器，有效解决了传统双层方法在处理高维概率空间和高昂采样成本时的局限性。这为扩散模型在实际应用中的微调和训练提供了更有效、更具理论支持的优化途径，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在高质量数据生成方面取得了成功，但其在下游任务（如微调或噪声调度优化）中的优化常涉及嵌套的双层结构。传统双层优化方法在处理扩散模型的无限维概率空间和高昂采样成本时面临挑战并失效。

**Method:** 作者将挑战形式化为生成式双层优化问题，并提出了一个一阶双层框架。具体方法包括：1) 对于微调预训练模型，采用仅推理的下层求解器，并为上层设计样本高效的梯度估计器。2) 对于从头训练扩散模型并优化噪声调度，通过重新参数化下层问题并设计计算上可行的梯度估计器来实现。

**Result:** 实验证明，所提出的方法在微调和超参数搜索方面优于现有基线。

**Conclusion:** 本文提出的生成式双层优化框架克服了传统双层方法与扩散过程的不兼容性，提供了理论基础和计算实用性，并在实验中展现出优越性能。

> **ai_Abstract:** 本文针对扩散模型在下游任务优化中遇到的传统双层优化方法失效的问题，提出了一个新颖的一阶生成式双层优化框架。该框架将问题形式化，并针对模型微调和噪声调度优化两种关键场景，设计了创新的梯度估计器，解决了无限维概率空间和高昂采样成本的挑战。实验结果表明，该方法在性能上超越了现有基线。

> **摘要翻译:** 扩散模型通过迭代去噪数据样本来合成高质量输出，已在多个领域取得经验性成功。然而，针对下游任务优化这些模型通常涉及嵌套的双层结构，例如为微调任务调整超参数或训练动态中的噪声调度，传统双层方法由于无限维概率空间和高昂的采样成本而失效。我们将这一挑战形式化为生成式双层优化问题，并解决了两个关键场景：(1) 通过将仅推理的下层求解器与样本高效的上层梯度估计器配对，对预训练模型进行微调；(2) 通过重新参数化下层问题并设计计算上可行的梯度估计器，从头开始训练扩散模型并优化噪声调度。我们的一阶双层框架克服了传统双层方法与扩散过程的不兼容性，提供了理论基础和计算实用性。实验表明，我们的方法优于现有的微调和超参数搜索基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [100] [Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2508.03108)
> *基于伪标签诱导子空间表示学习的鲁棒分布外检测*

*Tarhib Al Azad, Faizul Rakib Sayem, Shahana Ibrahim* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 分布外检测, 子空间表示学习, 伪标签, 鲁棒AI, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于伪标签诱导子空间表示的新型OOD检测框架，通过结合交叉熵分类损失和子空间距离正则化损失，在更宽松的假设下提升了ID-OOD样本的可分离性。

**AI_Comments:** 该论文的创新点在于提出了伪标签诱导子空间表示学习，并结合了新的学习准则，以解决现有OOD检测方法在特征空间假设上的限制。这种方法在更宽松的假设下提高了ID-OOD的可分离性，对鲁棒AI领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分布外（OOD）检测方法通常依赖于对特征空间施加的限制性假设，这限制了分布内（ID）和OOD样本之间的可分离性。

**Method:** 本文提出了一种基于伪标签诱导子空间表示的新型OOD检测框架。该框架在更宽松和自然的假设下工作，并引入了一个简单而有效的学习准则，该准则结合了基于交叉熵的ID分类损失和基于子空间距离的正则化损失，以增强ID-OOD的可分离性。

**Result:** 广泛的实验验证了所提框架的有效性。

**Conclusion:** 本文提出的基于伪标签诱导子空间表示的OOD检测框架，通过结合特定的学习准则，能够有效提升ID和OOD样本的可分离性，从而实现鲁棒的OOD检测。

> **ai_Abstract:** 本文提出了一种新颖的分布外（OOD）检测框架，其核心是伪标签诱导子空间表示学习。针对现有方法在特征空间假设上的局限性，该框架在更宽松的假设下工作，并通过结合基于交叉熵的ID分类损失和基于子空间距离的正则化损失，有效增强了分布内（ID）和OOD样本之间的可分离性。实验结果验证了该框架的有效性。

> **摘要翻译:** 分布外（OOD）检测是鲁棒人工智能（AI）的核心，旨在识别训练集之外的新分布样本。最近的方法利用特征表示作为OOD检测的区分性特征。然而，大多数现有方法依赖于对特征空间的限制性假设，这限制了分布内（ID）和OOD样本之间的可分离性。在这项工作中，我们提出了一种基于伪标签诱导子空间表示的新型OOD检测框架，与现有基于特征的技术相比，它在更宽松和自然的假设下工作。此外，我们引入了一个简单但有效的学习准则，该准则将基于交叉熵的ID分类损失与基于子空间距离的正则化损失相结合，以增强ID-OOD的可分离性。广泛的实验验证了我们框架的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [105] [Localization of Impacts on Thin-Walled Structures by Recurrent Neural Networks: End-to-end Learning from Real-World Data](https://arxiv.org/abs/2505.08362)
> *基于循环神经网络的薄壁结构冲击定位：从真实数据中进行端到端学习*

*Alexander Humer, Lukas Grasboeck, Ayech Benjeddou* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 冲击定位, 薄壁结构, 循环神经网络, 结构健康监测, 真实数据

**Comment:** XI ECCOMAS Thematic Conference on Smart Structures and Materials
  (SMART 2025)

> **TL;DR:** 本文提出使用循环神经网络（GRU）从真实传感器数据中端到端地定位薄壁结构上的冲击，实现了显著的定位精度。

**AI_Comments:** 本文的创新点在于结合了门控循环单元（GRU）处理长序列传感器数据，并通过自动化实验获取真实物理数据，有效避免了合成数据带来的“现实差距”。这对于结构健康监测领域的实际应用具有重要意义，尤其是在冲击定位这一复杂问题上。

<details>
  <summary>Details</summary>

**Motivation:** 冲击定位有助于评估结构完整性，但传统方法难以应对薄壁结构中兰姆波的色散特性，因此需要新的定位方法。

**Method:** 本文提出使用门控循环单元（GRU）构建的循环神经网络（RNNs）进行端到端冲击定位，直接从序列传感器数据中估计冲击位置。为获取真实世界数据，采用机器人将钢球投掷到配备压电传感器的铝板上进行自动化实验。

**Result:** 即使数据集相对较小，该方法在估计冲击位置方面也显示出显著的准确性。

**Conclusion:** 本文提出的基于GRU的循环神经网络方法能够有效地从真实传感器数据中准确地定位薄壁结构上的冲击。

> **ai_Abstract:** 本文提出了一种基于门控循环单元（GRU）的循环神经网络（RNN）方法，用于从真实传感器数据中端到端地定位薄壁结构上的冲击。针对传统方法难以处理兰姆波色散特性，研究人员通过自动化实验收集物理数据，并利用GRU处理长序列数据以避免梯度消失。实验结果表明，该方法在冲击定位方面表现出显著的准确性，即使在数据量相对较小的情况下也能取得良好效果。

> **摘要翻译:** 如今，机器学习无处不在，结构健康监测（SHM）也不例外。具体来说，我们解决了壳状结构上的冲击定位问题，其中冲击位置的知识有助于评估结构完整性。薄壁结构上的冲击会激发兰姆波，可以用压电传感器测量。它们的色散特性使得传统方法难以检测和定位冲击。在本文中，我们探索了使用神经网络进行冲击定位。特别是，我们建议使用循环神经网络（RNNs）进行端到端地估计冲击位置，即直接从顺序传感器数据中进行估计。我们处理了数千个样本的较长序列，因为需要高采样率才能准确捕获弹性波。因此，所提出的方法基于门控循环单元（GRUs），与传统RNNs相比，它们更不容易出现梯度消失问题。数据质量和数量在训练神经网络时至关重要。通常使用合成数据，这不可避免地引入了现实差距。与此相反，我们使用实验中的物理数据训练我们的网络，这需要自动化来处理所需的大量实验。为此，使用机器人将钢球投掷到配备压电陶瓷传感器的铝板上。我们的结果显示，即使数据集相对较小，在估计冲击位置方面也具有显著的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [107] [Aligning Constraint Generation with Design Intent in Parametric CAD](https://arxiv.org/abs/2504.13178)
> *参数化CAD中约束生成与设计意图的对齐*

*Evan Casey, Tianyu Zhang, Shu Ishida, William P. McCarthy, John Roger Thompson, Amir Khasahmadi, Joseph George Lambourne, Pradeep Kumar Jayaraman, Karl D. D. Willis* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** CAD约束生成, 设计意图, 对齐技术, 工程草图, 参数化设计

**Comment:** 

> **TL;DR:** 本文将大型语言模型（LLM）的对齐技术应用于CAD工程草图约束生成，通过约束求解器反馈，将草图完全约束率从8.9%提升到93%，显著提高了设计意图的对齐。

**AI_Comments:** 这篇论文通过将LLM的对齐技术引入CAD约束生成领域，提供了一种新颖且高效的方法来解决设计意图对齐的长期挑战。其主要创新在于利用约束求解器的反馈来指导模型训练，从而显著提高了草图的完全约束率，这对于CAD设计的可编辑性和鲁棒性至关重要。该方法的通用性也使其具有广泛的应用前景，为未来在语言和设计领域之间架设对齐策略的桥梁奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机辅助设计（CAD）中，工程草图的约束必须有效捕捉设计意图，以确保参数变化时几何图形能可预测地更新。然而，现有方法在将模型输出与设计意图对齐方面仍面临挑战，尤其是在生成能够完全约束所有几何图元且不过度约束或扭曲草图几何的约束方面。

**Method:** 本文将推理大型语言模型（LLM）中的对齐技术应用于计算机辅助设计（CAD）模型中的工程草图约束生成任务。具体地，研究人员利用对齐技术，并结合来自约束求解器的反馈，来训练一个现有的约束生成模型，以确保几何图元的完全约束。

**Result:** 采用该方法后，能够完全约束93%的草图，而使用朴素的监督微调（SFT）基线时仅为34%，不使用SFT时仅为8.9%。此外，该方法可以应用于任何现有的约束生成模型。

**Conclusion:** 本文通过将大型语言模型（LLM）的对齐策略引入CAD约束生成领域，显著提高了约束生成与设计意图的对齐程度，特别是草图的完全约束率。这项工作为连接语言和设计领域之间的对齐策略的进一步研究奠定了基础，并具有广泛的适用性。

> **ai_Abstract:** 本文将大型语言模型（LLM）中的对齐技术应用于计算机辅助设计（CAD）中的工程草图约束生成任务，旨在解决当前CAD模型输出与设计意图对齐的挑战（即“设计对齐”问题）。通过利用约束求解器的反馈来训练现有的约束生成模型，该方法显著提高了草图的完全约束率，从基线的8.9%（无SFT）和34%（SFT）提升至93%，同时避免了过度约束或几何扭曲。这项工作为将语言和设计领域的对齐策略结合起来的未来研究奠定了基础，并可应用于现有约束生成模型。

> **摘要翻译:** 我们借鉴推理大型语言模型（LLM）中的对齐技术，将其应用于计算机辅助设计（CAD）模型中工程草图约束的生成任务。工程草图由几何图元（例如点、线）通过约束（例如垂直、相切）连接而成，这些约束定义了它们之间的关系。为了使设计易于编辑，约束必须有效地捕捉设计意图，确保当参数改变时，几何图形能够可预测地更新。尽管当前的方法可以生成CAD设计，但将模型输出与设计意图对齐仍然是一个开放的挑战，我们将此问题标记为“设计对齐”。实现生成式CAD模型对齐的关键第一步是生成能够完全约束所有几何图元，同时不过度约束或扭曲草图几何的约束。通过使用对齐技术，并结合来自约束求解器的反馈来训练一个现有的约束生成模型，我们能够完全约束93%的草图，而使用朴素的监督微调（SFT）基线时仅为34%，没有SFT时仅为8.9%。我们的方法可以应用于任何现有的约束生成模型，并为进一步研究语言和设计领域之间的对齐策略奠定了基础。更多结果可在https://autodeskailab.github.io/aligning-constraint-generation/查看。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [117] [Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance](https://arxiv.org/abs/2503.14569)
> *势能分数匹配：利用势能引导对分子结构采样进行去偏*

*Liya Guo, Zun Wang, Chang Liu, Junzhe Li, Pipi Hu, Yi Zhu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 势能分数匹配, 分子构象采样, 扩散模型, 玻尔兹曼分布, 势能梯度

**Comment:** 

> **TL;DR:** 提出势能分数匹配（PSM），利用势能梯度指导生成模型，解决分子构象采样中数据偏差和计算成本高的问题，生成更接近玻尔兹曼分布的分子构象。

**AI_Comments:** 这篇论文的创新点在于将势能梯度引入到扩散模型中，以解决分子构象采样中的数据偏差问题，尤其是在不依赖精确能量函数的情况下实现去偏，这对于实际应用具有重要意义。它提高了分子模拟的效率和准确性，为药物发现和材料科学等领域提供了更可靠的工具。

<details>
  <summary>Details</summary>

**Motivation:** 分子构象的分布采样是物理和化学中的基本挑战，传统方法（分子动力学、蒙特卡罗）耗时且昂贵。扩散模型虽高效但获取无偏目标分布仍困难，需满足遍历性。

**Method:** 提出势能分数匹配（PSM），利用势能梯度指导生成模型。PSM不需要精确的能量函数，即使在有限和有偏数据上训练也能去偏样本分布。

**Result:** PSM在Lennard-Jones (LJ) 势能模型上优于现有最先进模型。在MD17和MD22数据集上的高维问题评估表明，PSM生成的分子分布比传统扩散模型更接近玻尔兹曼分布。

**Conclusion:** PSM能够有效且高效地生成更接近真实物理分布的分子构象，解决了传统方法和现有扩散模型在去偏采样方面的局限性。

> **ai_Abstract:** 本文提出了一种名为势能分数匹配（PSM）的新方法，旨在解决分子构象分布采样中的高成本和数据偏差问题。PSM利用势能梯度指导生成模型，即使在有限和有偏数据上也能有效去偏。实验证明，PSM在Lennard-Jones势能模型上优于现有模型，并且在MD17和MD22高维数据集上，其生成的分子分布比传统扩散模型更接近玻尔兹曼分布，为高效、准确的分子结构采样提供了新途径。

> **摘要翻译:** 分子物理性质的系综平均值与分子构象的分布密切相关，而对这种分布进行采样是物理和化学中的一个基本挑战。分子动力学（MD）模拟和马尔可夫链蒙特卡罗（MCMC）采样等传统方法虽然常用，但可能耗时且成本高昂。最近，扩散模型作为一种通过学习训练数据分布的有效替代方法而出现。然而，获得无偏的目标分布仍然是一项昂贵的任务，主要是因为它需要满足遍历性。为了应对这些挑战，我们提出了势能分数匹配（PSM），这是一种利用势能梯度来指导生成模型的方法。PSM不需要精确的能量函数，即使在有限和有偏数据上训练，也能对样本分布进行去偏。我们的方法在Lennard-Jones（LJ）势能（一种常用的玩具模型）上优于现有最先进（SOTA）模型。此外，我们使用MD17和MD22数据集将PSM的评估扩展到高维问题。结果表明，与传统扩散模型相比，PSM生成的分子分布更接近玻尔兹曼分布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [120] [Byte Pair Encoding for Efficient Time Series Forecasting](https://arxiv.org/abs/2505.14411)
> *用于高效时间序列预测的字节对编码*

*Leon Götz, Marcel Kollovieh, Stephan Günnemann, Leo Schwinn* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 时间序列预测, 字节对编码, 分词, 基序, 条件解码

**Comment:** 24 pages in total, 17 figures

> **TL;DR:** 本文提出了一种受字节对编码启发、以模式为中心的时间序列分词方案，显著提高了时间序列预测模型的效率和性能，并引入了条件解码优化。

**AI_Comments:** 该论文创新性地将字节对编码的概念应用于时间序列数据，解决了现有固定长度分词的局限性。其提出的以模式为中心的分词方法在效率和性能上带来了显著提升，特别是高达1990%的效率提升令人印象深刻。无梯度计算的条件解码作为后处理优化进一步增强了模型的表现，为时间序列分析领域提供了一个强大且高效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间序列分词方法通常将固定数量的样本编码为单个token，即使对于简单的模式也会生成过多的token，导致巨大的计算开销和效率低下。

**Method:** 提出了一种受字节对编码启发的、首个以模式为中心的时间序列分析分词方案。该方法基于频繁基序的离散词汇表，将具有潜在模式的样本合并为token，从而自适应地压缩时间序列。此外，还引入了条件解码作为一种轻量级且强大的后验优化方法，无需梯度计算且不增加计算开销。

**Result:** 在最近的时间序列基础模型上，基于基序的分词平均提高了预测性能36%，并提升了效率1990%。条件解码进一步将MSE降低了高达44%。该分词方法对不同的时间模式具有适应性，能泛化到未知数据，并捕获有意义的token表示，包括统计矩和趋势。

**Conclusion:** 本文提出的基于基序的分词方法和条件解码显著提升了时间序列预测的效率和性能，通过提供自适应、以模式为中心的token表示和轻量级优化方法，有效解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种新颖的、受字节对编码启发的以模式为中心的时间序列分词方法，通过将具有频繁基序的样本合并为token，自适应地压缩时间序列。同时，引入了一种轻量级的条件解码优化方法。该方法显著提高了时间序列基础模型的效率和预测性能，并展示了其适应性、泛化能力和有意义的token表示。

> **摘要翻译:** 现有时间序列分词方法主要将固定数量的样本编码为单个token。这种不灵活的方法即使对于扩展的常数值等简单模式，也可能生成过多的token，导致大量的计算开销。受字节对编码成功的启发，我们提出了第一个面向模式的时间序列分析分词方案。我们的方法基于频繁基序的离散词汇表，将具有潜在模式的样本合并为token，自适应地压缩时间序列。利用我们有限的基序集和时间序列的连续特性，我们进一步引入了条件解码作为一种轻量级但强大的后验优化方法，它不需要梯度计算，并且不增加计算开销。在最近的时间序列基础模型上，我们的基于基序的分词平均提高了预测性能36%，并提升了效率1990%。条件解码进一步将MSE降低了高达44%。在一项广泛的分析中，我们展示了我们的分词方法对不同时间模式的适应性、其对未知数据的泛化能力，以及其捕获不同时间序列特性（包括统计矩和趋势）的有意义的token表示。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [123] [SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference](https://arxiv.org/abs/2508.02751)
> *SmallKV：小模型辅助补偿KV缓存压缩以实现高效LLM推理*

*Yi Zhao, Yajuan Peng, Cam-Tu Nguyen, Zuchao Li, Xiaoliang Wang, Hai Zhao, Xiaoming Fu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-03**

**Keywords:** KV缓存压缩, LLM推理, 小模型辅助, 注意力机制, 吞吐量

**Comment:** 

> **TL;DR:** SmallKV提出一种小模型辅助的KV缓存压缩补偿方法，通过利用不同规模LLM间注意力矩阵的高相似性，解决了现有KV缓存驱逐方法中注意力模式适应性和边缘信息过度压缩的问题，显著提升了LLM推理的吞吐量和性能。

**AI_Comments:** SmallKV的创新点在于利用了不同规模LLM之间注意力矩阵的相似性来补偿KV缓存压缩，这是一种新颖且高效的思路。通过引入一个小模型来辅助大模型进行注意力感知和边缘信息近似，有效地解决了现有KV缓存驱逐策略的局限性，特别是在处理动态注意力模式和边缘信息保留方面。其在吞吐量上的显著提升也证明了该方法的实际应用价值，对于优化LLM在资源受限环境下的推理性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有KV缓存驱逐方法存在两个主要问题：1) 不可逆的驱逐策略无法适应解码过程中动态变化的注意力模式（显著性偏移问题）；2) 它们平等对待边缘重要和真正不重要的token，忽略了边缘token对模型性能的集体重要性（边缘信息过度压缩问题）。

**Method:** SmallKV设计了两种基于不同规模LLM之间注意力矩阵高相似度的补偿机制。它利用小模型辅助大模型感知注意力全局重要信息，并使用小模型的注意力分数来近似大模型中边缘token的注意力分数，从而补偿KV缓存压缩。

**Result:** 在GSM8K、BBH、MT-Bench和LongBench等基准测试上的大量实验证明了SmallKV的有效性。效率评估显示，SmallKV比基线方法实现了1.75-2.56倍更高的吞吐量。

**Conclusion:** SmallKV通过小模型辅助补偿KV缓存压缩，有效解决了现有方法的局限性，实现了资源受限环境下高效且高性能的LLM推理。

> **ai_Abstract:** 本论文提出了SmallKV，一种利用小模型辅助补偿KV缓存压缩的方法，旨在解决大型语言模型（LLMs）在长上下文场景中KV缓存驱逐的两个核心问题：动态注意力模式适应性不足和边缘信息过度压缩。SmallKV通过利用不同规模LLM之间注意力矩阵的高度相似性，设计了补偿机制，使大模型能更好地感知全局重要信息，并利用小模型近似边缘token的注意力分数。实验结果表明，SmallKV在多个基准测试上表现出有效性，并显著提高了LLM推理的吞吐量，展现了其在资源受限环境下实现高效高性能推理的潜力。

> **摘要翻译:** KV缓存驱逐已成为缓解LLM在长上下文场景中面临资源限制的有效解决方案。然而，现有的token级驱逐方法常常忽略两个关键方面：（1）它们不可逆的驱逐策略无法适应解码过程中动态变化的注意力模式（显著性偏移问题），以及（2）它们平等对待边缘重要和真正不重要的token，尽管边缘token对模型性能具有集体重要性（边缘信息过度压缩问题）。为了解决这些问题，我们基于不同规模LLM之间注意力矩阵的高度相似性设计了两种补偿机制。我们提出了SmallKV，一种小模型辅助的KV缓存压缩补偿方法。SmallKV可以保持不同规模LLM之间的注意力匹配，以：1）辅助较大模型感知注意力全局重要信息；2）使用较小模型的注意力分数来近似较大模型中边缘token的注意力分数。在包括GSM8K、BBH、MT-Bench和LongBench在内的基准测试上的大量实验证明了SmallKV的有效性。此外，效率评估显示SmallKV比基线方法实现了1.75-2.56倍更高的吞吐量，突显了其在资源受限环境中实现高效高性能LLM推理的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [128] [Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss](https://arxiv.org/abs/2505.15174)
> *通过块反射正交层和Logit退火损失增强认证鲁棒性*

*Bo-Han Lai, Pin-Han Huang, Bo-Han Kung, Shang-Tse Chen* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 认证鲁棒性, Lipschitz神经网络, 块反射正交层, Logit退火损失, BRONet

**Comment:** ICML 2025 Spotlight

> **TL;DR:** 提出了一种新的块反射正交（BRO）层和Logit退火损失函数，用于构建BRONet，以实现最先进的认证鲁棒性。

**AI_Comments:** 这篇论文的创新点在于提出了两种互补的技术：BRO层和Logit退火损失，共同提升了Lipschitz神经网络的性能。BRONet的提出为提高深度学习模型的认证鲁棒性提供了一种有效且简单的方案，其在多个数据集上达到SOTA的性能证明了方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 提升深度学习中Lipschitz神经网络的认证鲁棒性。

**Method:** 提出了块反射正交（BRO）层，以构建更具表达力的Lipschitz神经架构。引入了一种新的Logit退火损失函数，通过退火机制增加大多数数据点的裕度。结合BRO层和Logit退火损失，设计了BRONet。

**Result:** 在CIFAR-10/100、Tiny-ImageNet和ImageNet上的大量实验和实证分析表明，该方法优于现有基线，并实现了最先进的认证鲁棒性。

**Conclusion:** 通过结合新颖的块反射正交层和Logit退火损失函数，可以有效提升Lipschitz神经网络的认证鲁棒性，并达到最先进水平。

> **ai_Abstract:** 本文提出了一种新颖的块反射正交（BRO）层和Logit退火损失函数，旨在提升Lipschitz神经网络的认证鲁棒性。BRO层增强了网络表达能力，而Logit退火损失通过增加数据点裕度来提高鲁棒性。结合这两者，作者设计了BRONet，并在多个数据集上实现了最先进的认证鲁棒性，超越了现有方法。

> **摘要翻译:** Lipschitz神经网络因其在深度学习中提供认证鲁棒性而闻名。在本文中，我们提出了一种新颖、高效的块反射正交（BRO）层，该层增强了正交层构建更具表达力的Lipschitz神经架构的能力。此外，通过理论分析Lipschitz神经网络的本质，我们引入了一种新的损失函数，该函数采用退火机制来增加大多数数据点的裕度。这使得Lipschitz模型能够提供更好的认证鲁棒性。通过采用我们的BRO层和损失函数，我们设计了BRONet——一个简单而有效的Lipschitz神经网络，实现了最先进的认证鲁棒性。在CIFAR-10/100、Tiny-ImageNet和ImageNet上的大量实验和实证分析验证了我们的方法优于现有基线。该实现可在https://github.com/ntuaislab/BRONet获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [130] [Frontier: Simulating the Next Generation of LLM Inference Systems](https://arxiv.org/abs/2508.03148)
> *Frontier：模拟下一代大型语言模型推理系统*

*Yicheng Feng, Xin Tan, Kin Hang Sew, Yimin Jiang, Yibo Zhu, Hong Xu* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-08-05**

**Keywords:** LLM推理, MoE模型, 解耦架构, 系统模拟, Frontier

**Comment:** 

> **TL;DR:** Frontier是一个为下一代大型语言模型（LLM）推理系统设计的高保真模拟器，特别针对MoE模型和解耦架构的复杂性，弥补了现有模拟器的不足。

**AI_Comments:** Frontier通过提供一个专门用于复杂新兴架构的模拟器，填补了LLM系统设计中的关键空白。其统一的框架和对MoE以及解耦系统的支持具有创新性。这个工具对于优化下一代LLM推理的性能和可扩展性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有模拟器是为共置、密集模型设计的，无法捕捉MoE模型和解耦架构等新兴范式下大型语言模型推理的复杂系统动态。

**Method:** 本文提出了Frontier，一个从头开始设计的高保真模拟器。它引入了一个统一的框架来建模共置和解耦系统，原生支持带有专家并行性（EP）的MoE推理。它能够模拟复杂的流程，如跨集群专家路由和用于延迟隐藏的高级流水线策略。为了确保保真度和可用性，Frontier结合了改进的操作符模型以提高准确性。

**Result:** Frontier使社区能够设计和优化大规模LLM推理的未来。

**Conclusion:** Frontier是一个专门为模拟和优化下一代LLM推理系统（特别是MoE和解耦架构等复杂系统）而设计的高保真模拟器，解决了现有模拟器的局限性，旨在赋能社区进行未来LLM推理的设计与优化。

> **ai_Abstract:** Frontier是一个新颖的高保真模拟器，旨在解决现有模拟器在建模大型语言模型（LLM）推理日益增长的复杂性方面的局限性，特别是针对专家混合（MoE）模型和解耦架构。它提供了一个统一的框架，支持共置和解耦系统、原生MoE推理与专家并行性，以及高级工作流模拟，如跨集群专家路由和用于隐藏延迟的流水线策略，旨在促进未来大规模LLM推理的设计和优化。

> **摘要翻译:** 大型语言模型（LLM）推理随着专家混合（MoE）模型和解耦架构的兴起而变得日益复杂，这些架构将预填充/解码（PD）或注意力/前馈网络（AF）等组件解耦以实现异构扩展。现有为共置、密集模型设计的模拟器无法捕捉这些新兴范式的复杂系统动态。我们提出了Frontier，一个从头开始为这种新格局设计的高保真模拟器。Frontier引入了一个统一的框架来建模共置和解耦系统，提供了对带有专家并行性（EP）的MoE推理的原生支持。它能够模拟复杂的流程，如跨集群专家路由和用于延迟隐藏的高级流水线策略。为了确保保真度和可用性，Frontier结合了改进的操作符模型以提高准确性。Frontier使社区能够设计和优化大规模LLM推理的未来。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [133] [Cross-Model Semantics in Representation Learning](https://arxiv.org/abs/2508.03649)
> *表示学习中的跨模型语义*

*Saleh Nikooroo, Thomas Engel* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 表示学习, 跨模型语义, 结构约束, 归纳偏置, 特征互操作性

**Comment:** 

> **TL;DR:** 本文研究了结构约束如何影响不同深度学习架构之间内部表示的兼容性，并发现结构规律可以提高表示在架构变化下的稳定性，从而改善学习特征的互操作性。

**AI_Comments:** 本文的创新点在于系统地研究了结构约束对深度网络内部表示跨模型兼容性的影响，并提出了一个量化和分析表示对齐的框架。其重要性体现在揭示了特定归纳偏置不仅能提升模型内泛化能力，还能增强模型间特征的互操作性，这对于构建更稳定、可迁移和可组合的深度学习系统具有实际指导意义。此研究为模型蒸馏、模块化学习和鲁棒系统设计提供了新的视角和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 深度网络学习到的内部表示通常对架构选择敏感，这引发了关于学习结构在模型间稳定性、对齐性和可迁移性的问题。

**Method:** 本文构建了一个框架来测量和分析具有不同但相关架构先验的网络之间的表示对齐。通过理论洞察、实证探究和受控迁移实验相结合的方式进行研究。

**Result:** 结构规律诱导的表示几何在架构变化下更稳定。某些形式的归纳偏置不仅支持模型内的泛化，还提高了学习特征在模型间的互操作性。

**Conclusion:** 表示的可迁移性对于模型蒸馏、模块化学习和鲁棒学习系统的原理设计具有重要意义。

> **ai_Abstract:** 本文探讨了深度学习模型中内部表示的跨模型兼容性问题，该问题源于表示对架构选择的敏感性。研究通过引入结构约束（如线性整形算子和校正路径）来分析其对不同架构间表示对齐的影响。作者开发了一个测量和分析表示对齐的框架，并结合理论分析、实证实验和迁移实验证明，结构规律能使表示几何在架构变化下更稳定。这表明特定的归纳偏置不仅有助于模型内泛化，还能增强学习特征的跨模型互操作性。研究还讨论了表示可迁移性在模型蒸馏、模块化学习和鲁棒系统设计中的应用。

> **摘要翻译:** 深度网络学习到的内部表示通常对架构特定的选择很敏感，这引发了关于学习结构在模型间稳定性、对齐性和可迁移性的问题。在本文中，我们研究了结构约束——例如线性整形算子和校正路径——如何影响不同架构之间内部表示的兼容性。基于先前关于结构变换和收敛研究的见解，我们开发了一个框架，用于测量和分析具有不同但相关架构先验的网络之间的表示对齐。通过理论洞察、实证探究和受控迁移实验相结合的方式，我们证明了结构规律诱导的表示几何在架构变化下更稳定。这表明某些形式的归纳偏置不仅支持模型内的泛化，而且提高了学习特征在模型间的互操作性。最后，我们讨论了表示可迁移性对模型蒸馏、模块化学习和鲁棒学习系统的原理设计的影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [136] [NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation](https://arxiv.org/abs/2505.21020)
> *NeuralOM：用于次季节到季节模拟的神经海洋模型*

*Yuan Gao, Ruiqi Shu, Hao Wu, Fan Xu, Yanfei Xiang, Ruijian Gou, Qingsong Wen, Xian Wu, Kun Wang, Xiaomeng Huang* | **Category: cs.LG, physics.ao-ph** | **Updated: 2025-08-04**

**Keywords:** 神经海洋模型, 次季节到季节模拟, 误差校正, 物理引导, 图网络

**Comment:** 

> **TL;DR:** NeuralOM是一个新的神经算子框架，通过渐进残差校正和物理引导图网络，解决了长期、高精度模拟海洋等慢变物理系统中的误差累积问题，并在全球次季节到季节海洋模拟中表现出超越现有技术的准确性和稳定性。

**AI_Comments:** 该论文通过引入渐进残差校正和物理引导图网络，有效地解决了长期科学模拟中误差累积的难题，并提升了模型的物理一致性，具有重要的创新性和实用价值。其在海洋S2S模拟中的显著性能提升，预示着其在更广泛的地球系统模拟领域拥有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 长期、高精度模拟海洋和气候等慢变物理系统面临挑战，传统自回归机器学习模型因误差累积导致预测快速退化。

**Method:** 提出NeuralOM，一个通用的神经算子框架。核心创新包括：1) 渐进残差校正框架，将预测任务分解为一系列细粒度修正步骤，有效抑制长期误差累积；2) 物理引导图网络，其内置自适应消息机制明确建模多尺度物理相互作用，增强物理一致性并保持计算效率。

**Result:** NeuralOM在全球次季节到季节（S2S）海洋模拟中，不仅在预测精度和长期稳定性方面超越了现有最先进模型，还在模拟极端事件方面表现出色。例如，在60天提前期，其RMSE比最佳基线低13.3%。

**Conclusion:** NeuralOM为数据驱动的科学计算提供了一个稳定、高效且物理感知的新范式，有效解决了长期高精度海洋模拟的挑战。

> **ai_Abstract:** 本研究提出NeuralOM，一个用于模拟慢变物理系统（如海洋）的神经算子框架，以解决传统模型中误差累积导致的预测退化问题。NeuralOM包含渐进残差校正框架和物理引导图网络两大核心创新，前者抑制长期误差，后者增强物理一致性并提升效率。在全球次季节到季节海洋模拟任务中，NeuralOM在预测精度、长期稳定性及极端事件模拟方面均超越现有技术，为数据驱动的科学计算提供了高效且物理感知的解决方案。

> **摘要翻译:** 长期、高精度的慢变物理系统（如海洋和气候）模拟是科学计算中的一个根本性挑战。传统的自回归机器学习模型在此类任务中常常失败，因为微小误差会累积并导致预测能力快速下降。为了解决这个问题，我们提出了NeuralOM，一个通用的神经算子框架，旨在模拟复杂的慢变动力学。NeuralOM的核心包含两项关键创新：(1) 渐进残差校正框架，它将预测任务分解为一系列细粒度的修正步骤，有效抑制了长期误差累积；(2) 物理引导图网络，其内置的自适应消息机制明确建模了多尺度物理相互作用，如梯度驱动流和乘法耦合，从而在保持计算效率的同时增强了物理一致性。我们在全球次季节到季节（S2S）海洋模拟这一具有挑战性的任务上验证了NeuralOM。大量实验表明，NeuralOM不仅在预测精度和长期稳定性方面超越了现有最先进模型，而且在模拟极端事件方面也表现出色。例如，在60天提前期，NeuralOM的RMSE比表现最佳的基线低13.3%，为数据驱动的科学计算提供了一个稳定、高效且物理感知的范式。代码链接：https://github.com/YuanGao-YG/NeuralOM。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [140] [The alpha-beta divergence for real and complex data](https://arxiv.org/abs/2508.03272)
> *实数和复数数据的alpha-beta散度*

*Sergio Cruces* | **Category: cs.LG, cs.IT, math.IT, stat.ML** | **Updated: 2025-08-05**

**Keywords:** alpha-beta散度, 复数数据, 信号处理, 欧几里得距离, 马哈拉诺比斯距离

**Comment:** 

> **TL;DR:** 论文将alpha-beta散度扩展到复数数据，并展示了其与经典距离和散度的关系，以及在复数向量近似问题中的应用。

**AI_Comments:** 这项工作通过将alpha-beta散度推广到复数域，显著增强了其在信号处理领域的适用性，特别是考虑到许多实际数据固有的复数性质。其创新之处在于新颖的公式设计，能够通过简单设置超参数来还原为经典的距离度量，并提供可分离和不可分离的扩展。闭合形式的质心表达式也为理解超参数提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 散度是信号处理算法信息准则的基础。现有的alpha-beta散度主要针对非负数据，但许多信号处理领域的数据本质上是复数。因此，需要将alpha-beta散度扩展到复数数据以增强其适用性。

**Method:** 本文通过提出一种新的公式，将alpha-beta散度的定义扩展到复数数据，特别是当散度的参数是复数向量时。

**Result:** 新的复数alpha-beta散度公式在超参数设为单位时，可特化为欧几里得和马哈拉诺比斯平方距离。选择其他超参数可得到多种经典散度的可分离和不可分离扩展。在近似复数随机向量的问题中，通过优化alpha-beta平均失真获得的质心具有闭合形式表达式，这有助于理解散度超参数的不同作用。

**Conclusion:** 扩展后的alpha-beta散度及其性质在信号处理领域具有广泛的潜在应用，特别是在处理固有复数数据的场景中。

> **ai_Abstract:** 本文将针对非负数据的alpha-beta散度扩展到复数数据。提出的新公式在特定超参数设置下可简化为欧几里得和马哈拉诺比斯距离，并能生成多种经典散度的扩展。研究还发现，在复数向量近似问题中，优化alpha-beta平均失真得到的质心具有闭合形式，这有助于理解超参数的作用。该工作对于处理复杂信号处理领域中的复数数据具有重要意义。

> **摘要翻译:** 散度是支撑大多数信号处理算法的信息准则的基础。为非负数据设计的alpha-beta散度家族提供了一个多功能框架，该框架参数化并连续插值了现有文献中的几种可分离散度。这项工作扩展了alpha-beta散度的定义以适应复数数据，特别是当散度的参数是复数向量时。这种新颖的公式设计使得，通过将散度超参数设置为单位，它可以特化为众所周知的欧几里得和马哈拉诺比斯平方距离。超参数的其他选择产生了多种经典散度的实用可分离和不可分离扩展。在近似复数随机向量的问题背景下，通过优化alpha-beta平均失真获得的质心具有闭合形式表达式，其解释揭示了散度超参数的独特作用。这些贡献可能具有广泛的潜在适用性，因为有许多信号处理领域的基础数据本质上是复数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [143] [OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous Driving Framework](https://arxiv.org/abs/2411.07711)
> *OWLed：面向高效自动驾驶框架的异常值加权逐层剪枝*

*Jiaxi Li, Lu Yin, Xilu Wang* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-04**

**Keywords:** 模型剪枝, 自动驾驶, 大型语言模型, 计算效率, 稀疏性

**Comment:** IJCNN2025

> **TL;DR:** OWLed是一种异常值加权逐层剪枝框架，通过对不同层应用非均匀稀疏比来压缩LLM，从而在不降低性能的情况下显著降低自动驾驶系统的计算需求。

**AI_Comments:** OWLed的创新之处在于其异常值加权逐层剪枝策略，这使得模型压缩更加高效且无需微调。通过将驾驶环境数据纳入剪枝流程，确保了模型在自动驾驶任务中的适应性。研究发现编码器组件对剪枝更为敏感，为未来优化提供了方向。这项工作对于推动LLMs在资源受限的自动驾驶场景中的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将大型语言模型（LLMs）集成到自动驾驶系统中可以增强环境理解和决策能力，但LLMs在车载本地部署的巨大计算需求使其在实际汽车应用中不可行。

**Method:** 本文提出了OWLed（Outlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework），它利用异常值加权逐层稀疏性进行模型压缩。该方法根据异常特征的分布为不同层分配非均匀稀疏比，显著减小了模型大小，无需微调。为确保压缩模型良好适应自动驾驶任务，将驾驶环境数据纳入校准和剪枝过程。

**Result:** 经验研究表明，编码器组件比LLM对剪枝更敏感。实验结果表明，OWLed在感知、动作预测和语言理解方面优于现有方法，同时显著降低了计算要求。

**Conclusion:** 结合先进的剪枝技术与LLMs，有望开发出能够处理复杂场景的高效、鲁棒的自动驾驶系统。

> **ai_Abstract:** 本文提出OWLed，一种异常值加权逐层剪枝框架，旨在解决大型语言模型（LLMs）在自动驾驶系统本地部署时面临的巨大计算挑战。OWLed通过根据异常特征分布对不同层应用非均匀稀疏比来实现模型压缩，无需微调即可显著减小模型大小。该方法将驾驶环境数据整合到校准和剪枝过程中，确保压缩模型适应自动驾驶任务。实验证明，OWLed在感知、动作预测和语言理解方面优于现有方法，并显著降低了计算需求，显示了结合先进剪枝技术与LLMs开发高效自动驾驶系统的潜力。

> **摘要翻译:** 大型语言模型（LLMs）与自动驾驶系统的集成在环境理解和决策方面提供了有前景的增强。然而，在车辆本地部署LLMs的巨大计算需求使得这种方法在实际汽车应用中不可行。为了解决这一挑战，我们引入了OWLed，即面向高效自动驾驶框架的异常值加权逐层剪枝，它利用异常值加权逐层稀疏性进行模型压缩。我们的方法根据异常特征的分布为不同层分配非均匀稀疏比，显著减小了模型大小，无需微调。为了确保压缩模型良好适应自动驾驶任务，我们将驾驶环境数据纳入校准和剪枝过程。我们的经验研究表明，编码器组件比LLM对剪枝更敏感，突出了其在系统中的关键作用。实验结果表明，OWLed在感知、动作预测和语言理解方面优于现有方法，同时显著降低了计算要求。这些发现强调了将先进剪枝技术与LLMs结合起来开发能够处理复杂场景的高效、鲁棒自动驾驶系统的潜力。代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [144] [Comprehensive Attribute Encoding and Dynamic LSTM HyperModels for Outcome Oriented Predictive Business Process Monitoring](https://arxiv.org/abs/2506.03696)
> *面向结果的预测性业务流程监控的综合属性编码和动态LSTM超模型*

*Fang Wang, Paolo Ceravolo, Ernesto Damiani* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 预测性业务流程监控, 动态LSTM, 属性编码, 同步事件, 可解释性

**Comment:** 

> **TL;DR:** 本文提出了一套动态LSTM超模型，通过分层编码、字符分解和伪嵌入技术，以及专门的LSTM变体来改进预测性业务流程监控（PBPM），以解决现有方法在处理实时挑战（如同步事件、类别不平衡和多级属性）方面的局限性。

**AI_Comments:** 本文的创新点在于提出了动态LSTM超模型，通过综合属性编码（分层编码、字符分解、伪嵌入）和专门的LSTM变体来解决预测性业务流程监控中的多重现实挑战。其重要性体现在提升了模型对异构数据的处理能力和可解释性，使其更适用于实际复杂场景的部署，并对更广泛的AI领域中的时间结果预测和可解释性框架有所贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有预测性业务流程监控（PBPM）方法在处理真实世界挑战时缺乏灵活性，例如同步事件、类别不平衡和多级属性。此外，静态编码方案和固定LSTM架构难以支持自适应表示和跨异构数据集的泛化。

**Method:** 本文提出了一套动态LSTM超模型，该模型集成了事件和序列属性的两级分层编码、事件标签的基于字符的分解，以及用于持续时间和属性相关性的新型伪嵌入技术。此外，还引入了专门的LSTM变体，通过利用多维嵌入和时间差标志增强来建模同步事件。

**Result:** 在四个公共和真实世界数据集上的实验验证表明，在平衡数据集上准确率高达100%，在不平衡数据集上F1分数超过86%。

**Conclusion:** 本文提出的方法通过提供模块化和可解释的模型，更好地适应复杂环境中的部署，从而推进了预测性业务流程监控（PBPM）领域。它还通过改进时间结果预测、支持数据异构性和促进可解释的流程智能框架，为更广泛的AI社区做出了贡献。

> **ai_Abstract:** 本文针对预测性业务流程监控（PBPM）中现有方法在处理同步事件、类别不平衡和多级属性等挑战时的局限性，提出了一套动态LSTM超模型。该模型通过两级分层编码、字符分解以及伪嵌入技术处理事件和序列属性，并引入专门的LSTM变体来建模同步事件。实验结果表明，该方法在平衡数据集上实现了高准确率，在不平衡数据集上取得了优秀的F1分数，提升了模型的适应性、可解释性和在复杂环境中的部署能力。

> **摘要翻译:** 预测性业务流程监控（PBPM）旨在预测正在进行的业务流程的未来结果。然而，现有方法往往缺乏灵活性，无法处理真实世界的挑战，例如同步事件、类别不平衡和多级属性。尽管先前的工作探索了静态编码方案和固定的LSTM架构，但它们难以支持自适应表示和跨异构数据集的泛化。为了解决这些局限性，我们提出了一套动态LSTM超模型，该模型集成了事件和序列属性的两级分层编码、事件标签的基于字符的分解，以及用于持续时间和属性相关性的新型伪嵌入技术。我们进一步引入了专门的LSTM变体，用于同步事件建模，利用多维嵌入和时间差标志增强。在四个公共和真实世界数据集上的实验验证表明，在平衡数据集上准确率高达100%，在不平衡数据集上F1分数超过86%。我们的方法通过提供模块化和可解释的模型，更好地适应复杂环境中的部署，从而推进了PBPM。除了PBPM，它还通过改进时间结果预测、支持数据异构性以及促进可解释的流程智能框架，为更广泛的AI社区做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [152] [ProARD: progressive adversarial robustness distillation: provide wide range of robust students](https://arxiv.org/abs/2506.07666)
> *ProARD：渐进式对抗鲁棒性蒸馏：提供广泛的鲁棒学生网络*

*Seyedhamidreza Mousavi, Seyedali Mousavi, Masoud Daneshtalab* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 对抗鲁棒性蒸馏, 动态网络, 权重共享, 轻量级神经网络, 鲁棒性

**Comment:** 

> **TL;DR:** ProARD提出了一种高效的动态网络训练方法，通过一次训练即可支持多种鲁棒的轻量级学生网络，避免了重复训练的成本。

**AI_Comments:** ProARD的创新点在于提出了一个“一次训练，多学生网络”的动态蒸馏框架，有效解决了传统ARD在多设备部署场景下重复训练导致的计算资源浪费和碳排放问题。通过动态网络和权重共享机制，实现了鲁棒性蒸馏的效率提升。然而，论文也指出了随机采样学生网络的局限性，这可能意味着需要更复杂的采样策略来确保所有学生网络的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有对抗鲁棒性蒸馏（ARD）方法需要为满足不同边缘设备和资源限制而从头训练新的学生网络，导致巨大的计算成本和碳排放。

**Method:** 论文提出了ProARD。首先，构建一个基于动态层的动态深度神经网络，该网络在宽度、深度和扩展方面具有变化，以支持广泛的架构。然后，将最大尺寸的学生网络视为动态教师网络。ProARD通过权重共享机制训练这个动态网络，共同优化动态教师及其内部学生网络。为解决计算成本问题，需要采样机制选择学生子集。

**Result:** 论文指出，每次迭代中随机学生采样无法产生准确且鲁棒的学生网络。ProARD旨在实现一次高效训练，支持多种准确且鲁棒的学生网络，无需重复训练。

**Conclusion:** ProARD通过一次训练动态网络，旨在高效地提供广泛的准确和鲁棒的学生网络，从而避免重复训练的计算成本。

> **ai_Abstract:** 本论文提出了渐进式对抗鲁棒性蒸馏（ProARD），旨在解决现有对抗鲁棒性蒸馏（ARD）方法因设备多样性而需重复训练学生网络所导致的计算成本高昂问题。ProARD通过一次性高效训练一个动态深度神经网络来实现，该网络基于动态层构建，支持多种宽度、深度和扩展的架构。它将最大尺寸的学生网络作为动态教师，并利用权重共享机制共同优化动态教师及其内部学生网络。为应对高计算成本，ProARD采用采样机制选择学生子集，但研究发现随机采样无法生成准确鲁棒的学生。

> **摘要翻译:** 对抗鲁棒性蒸馏（ARD）已成为增强轻量级深度神经网络对抗性攻击鲁棒性的有效方法。当前的ARD方法利用大型鲁棒教师网络来训练一个鲁棒的轻量级学生网络。然而，由于边缘设备和资源限制的多样性，当前方法需要从头开始训练新的学生网络以满足特定的限制，这导致了大量的计算成本和增加的二氧化碳排放。本文提出了渐进式对抗鲁棒性蒸馏（ProARD），它能够高效地一次性训练一个动态网络，支持各种准确且鲁棒的学生网络，而无需重复训练。我们首先通过在每个设计阶段包含宽度、深度和扩展的变化，基于动态层构建一个动态深度神经网络，以支持广泛的架构。然后，我们将最大尺寸的学生网络视为动态教师网络。ProARD使用权重共享机制训练这个动态网络，以共同优化动态教师网络及其内部学生网络。然而，由于计算动态网络中所有学生的精确梯度成本很高，因此需要采样机制来选择学生的子集。我们发现，每次迭代中的随机学生采样无法产生准确且鲁棒的学生网络。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [156] [Online Robust Multi-Agent Reinforcement Learning under Model Uncertainties](https://arxiv.org/abs/2508.02948)
> *在模型不确定性下的在线鲁棒多智能体强化学习*

*Zain Ulabedeen Farhat, Debamita Ghosh, George K. Atia, Yue Wang* | **Category: cs.LG, cs.MA** | **Updated: 2025-08-04**

**Keywords:** 在线学习, 鲁棒强化学习, 多智能体系统, 模型不确定性, 分布鲁棒马尔可夫博弈

**Comment:** 

> **TL;DR:** 本文提出了RONAVI算法，首次实现了在没有预先数据的情况下，DRMGs的在线学习，并提供了理论保证，为构建鲁棒多智能体系统开辟了新路径。

**AI_Comments:** 本文的创新点在于首次将在线学习引入到DRMGs框架中，解决了传统DRMG方法对大量离线数据或模拟器的依赖问题。RONAVI算法的提出及其理论保证（低遗憾值和找到最优鲁棒策略）是重要的贡献，为在实际、不确定环境中部署多智能体系统提供了更实用的解决方案。这对于提高多智能体系统的可靠性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有训练良好的多智能体系统在实际部署时，由于训练与部署环境之间的模型不匹配（如噪声或对抗性攻击导致的环境不确定性），可能会失败。尽管DRMGs通过优化最坏情况性能来增强系统韧性，但现有方法依赖于模拟器或大量离线数据集，这些资源通常难以获得。

**Method:** 本文开创性地研究了DRMGs中的在线学习，即智能体直接从环境交互中学习而无需预先数据。为此，引入了“鲁棒乐观纳什值迭代（RONAVI）”算法，并首次为此设置提供了可证明的理论保证。

**Result:** 理论分析表明，RONAVI算法实现了低遗憾值，并能有效地找到针对总变差散度（Total Variation divergence）和 Kullback-Leibler 散度度量的不确定性集的最佳鲁棒策略。

**Conclusion:** 这些结果为开发真正鲁棒的多智能体系统建立了一条新的、实用的途径。

> **ai_Abstract:** 本文针对多智能体系统在不确定实际环境中部署时面临的鲁棒性问题，提出了DRMGs（分布鲁棒马尔可夫博弈）的在线学习框架。现有DRMG方法依赖离线数据，而本文引入了“鲁棒乐观纳什值迭代（RONAVI）”算法，允许智能体直接从在线交互中学习，无需预先数据。理论分析证明，RONAVI算法在总变差散度和Kullback-Leibler散度度量的不确定性下，能实现低遗憾值并找到最优鲁棒策略，为构建实用的鲁棒多智能体系统提供了新途径。

> **摘要翻译:** 训练有素的多智能体系统在实际环境中部署时可能会失败，原因在于训练环境和部署环境之间的模型不匹配，这由包括噪声或对抗性攻击在内的环境不确定性引起。分布鲁棒马尔可夫博弈（DRMGs）通过针对一组定义的环境不确定性优化最坏情况性能来增强系统弹性。然而，当前方法受限于对模拟器或大型离线数据集的依赖，而这些数据通常是不可用的。本文开创性地研究了DRMGs中的在线学习，其中智能体直接从环境交互中学习，无需预先数据。我们引入了“鲁棒乐观纳什值迭代（RONAVI）”算法，并首次为此设置提供了可证明的保证。我们的理论分析表明，该算法实现了低遗憾值，并能有效地找到针对总变差散度（Total Variation divergence）和Kullback-Leibler散度度量的不确定性集的最佳鲁棒策略。这些结果为开发真正鲁棒的多智能体系统建立了一条新的、实用的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [160] [Enhancing Spectral Graph Neural Networks with LLM-Predicted Homophily](https://arxiv.org/abs/2506.14220)
> *利用LLM预测的同质性增强谱图神经网络*

*Kangkang Lu, Yanhua Yu, Zhiyong Huang, Tat-Seng Chua* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 谱图神经网络, 大型语言模型, 图同质性, 节点分类, 结构先验

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的框架，利用大型语言模型（LLMs）估计图的同质性水平，并使用此全局结构先验来指导谱滤波器构建，从而在有限标签数据下提高谱图神经网络（SGNNs）的性能。

**AI_Comments:** 这项工作创新性地将大型语言模型（LLMs）引入到图神经网络（GNNs）领域，解决了SGNNs在有限标签数据和异质图上性能下降的问题。其“即插即用”和“成本可忽略”的特点使其具有很高的实用价值和应用潜力。通过LLM预测的全局结构先验来指导滤波器构建，避免了对图结构或任务特定训练的修改，提供了一种新颖且高效的增强GNNs性能的途径。

<details>
  <summary>Details</summary>

**Motivation:** 在标记数据有限的情况下，谱图神经网络（SGNNs）难以捕获最佳滤波器形状，导致性能下降，尤其是在异质图上。同时，大型语言模型（LLMs）的快速发展为在不修改图结构或不需要特定任务训练的情况下增强图学习提供了新的可能性。

**Method:** 我们设计了一个轻量级且即插即用的流程。将一小部分标记节点对格式化为自然语言提示，输入给大型语言模型（LLMs），LLMs预测图的同质性比率。这个估计值用于指导谱滤波器基的构建，使SGNNs能够更有效地适应同质和异质结构。

**Result:** 在多个基准数据集上的大量实验表明，我们LLM辅助的谱框架始终优于强大的SGNN基线。重要的是，这种增强带来的计算和经济成本可以忽略不计。

**Conclusion:** 通过利用LLM预测的图同质性作为先验知识来指导谱滤波器的构建，可以有效提升谱图神经网络在有限标签数据场景下的性能，且成本效益高，使其成为实际图应用的实用解决方案。

> **ai_Abstract:** 本文提出了一种创新的框架，旨在提升谱图神经网络（SGNNs）在有限标签数据下的性能。该方法利用大型语言模型（LLMs）预测图的同质性水平，并将这一全局结构先验知识融入到谱滤波器的构建中。通过将少量标记节点对转化为自然语言提示输入LLM，获取图的同质性比率，进而指导SGNNs的滤波器适应同质和异质结构。实验证明，该LLM辅助的谱框架显著优于现有SGNN基线，且计算和经济成本极低，为实际图应用提供了实用高效的解决方案。

> **摘要翻译:** 谱图神经网络（SGNNs）因其学习灵活滤波器的能力，在节点分类等任务中取得了卓越的性能。通常，这些滤波器是在下游任务的监督下学习的，使SGNNs能够适应不同的结构模式。然而，在标记数据有限的情况下，SGNNs往往难以捕获最佳滤波器形状，导致性能下降，尤其是在异质图上。与此同时，大型语言模型（LLMs）的快速发展为在不修改图结构或不需要特定任务训练的情况下增强图学习开辟了新的可能性。在这项工作中，我们提出了一个新颖的框架，利用LLMs估计图的同质性水平，并使用此全局结构先验来指导谱滤波器的构建。具体来说，我们设计了一个轻量级且即插即用的流程，其中一小部分标记节点对被格式化为LLM的自然语言提示，LLM随后预测图的同质性比率。这个估计值用于指导谱滤波器基的构建，使SGNNs能够更有效地适应同质和异质结构。在多个基准数据集上的大量实验表明，我们LLM辅助的谱框架始终优于强大的SGNN基线。重要的是，这种增强带来的计算和经济成本可以忽略不计，使其成为实际图应用的实用解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [163] [DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting](https://arxiv.org/abs/2508.02753)
> *DMSC: 动态多尺度协调框架用于时间序列预测*

*Haonan Yang, Jianchao Tang, Zhuo Li, Long Lan* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-03**

**Keywords:** 时间序列预测, 多尺度, 动态分解, 依赖建模, 自适应融合

**Comment:** 

> **TL;DR:** 本文提出了DMSC，一个用于时间序列预测的新框架，它比现有方法更好地处理多尺度时间依赖性，实现了最先进的性能和效率。

**AI_Comments:** 本文通过提出一个全面的框架，解决了时间序列预测中的关键挑战，包括静态分解、碎片化依赖建模和不灵活的融合机制。EMPD的动态性、TIB的整体依赖建模以及ASR-MoE的自适应融合似乎是其创新点。渐进式级联架构也可能是一个亮点。在多个基准上声称达到SOTA性能和卓越的计算效率表明其具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列预测（TSF）方法在建模复杂时序依赖关系方面面临挑战，具体表现为静态分解策略、碎片化依赖建模和不灵活的融合机制，这些限制了它们建模复杂时序依赖的能力。

**Method:** 本文提出了动态多尺度协调框架（DMSC），包含三个主要组件：多尺度块分解模块（EMPD）用于动态分段序列并自适应调整块；三元交互模块（TIB）用于共同建模块内、块间和跨变量依赖关系；以及自适应尺度路由MoE模块（ASR-MoE）用于动态融合多尺度预测。EMPD和TIB被整合到多层渐进级联架构中，其中粗粒度表示指导细粒度特征提取。

**Result:** DMSC在十三个真实世界基准上始终保持时间序列预测任务的最先进（SOTA）性能和卓越的计算效率。

**Conclusion:** DMSC通过使用动态分解、全面的依赖建模和自适应融合，有效解决了时间序列预测中复杂时序依赖建模的挑战，从而实现了最先进的性能和效率。

> **ai_Abstract:** 本文提出了DMSC（动态多尺度协调框架），旨在解决时间序列预测（TSF）中静态分解、碎片化依赖建模和不灵活融合的局限性。DMSC集成了多尺度块分解模块（EMPD）用于动态序列分段，三元交互模块（TIB）用于全面的依赖建模（块内、块间、跨变量），以及自适应尺度路由MoE模块（ASR-MoE）用于自适应多尺度预测融合。DMSC作为多层渐进级联架构实现，在十三个真实世界TSF基准上实现了最先进的性能和卓越的计算效率。

> **摘要翻译:** 时间序列预测（TSF）在建模不同尺度上复杂的时序依赖关系方面面临持续挑战。尽管最近在利用不同分解操作和基于CNN、MLP或Transformer的新颖架构方面取得了进展，但现有方法仍然存在静态分解策略、碎片化依赖建模和不灵活的融合机制等问题，限制了它们建模复杂时序依赖的能力。为了分别明确解决上述三个问题，我们提出了一种新颖的动态多尺度协调框架（DMSC），该框架包含多尺度块分解模块（EMPD）、三元交互模块（TIB）和自适应尺度路由MoE模块（ASR-MoE）。具体来说，EMPD被设计为一个内置组件，用于动态地将序列分割成具有指数级粒度的分层块，通过输入自适应的块调整来消除预定义的尺度限制。然后，TIB在每个层的分解表示中共同建模块内、块间和跨变量依赖关系。EMPD和TIB共同集成到层中，形成一个多层渐进级联架构，其中来自早期层的粗粒度表示通过门控路径自适应地指导后续层中的细粒度特征提取。ASR-MoE通过利用具有时序感知加权的专用全局和局部专家，动态融合多尺度预测。在十三个真实世界基准上的综合实验表明，DMSC在TSF任务中始终保持最先进（SOTA）的性能和卓越的计算效率。代码可在https://github.com/1327679995/DMSC 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [164] [GEDAN: Learning the Edit Costs for Graph Edit Distance](https://arxiv.org/abs/2508.03111)
> *GEDAN：学习图编辑距离的编辑成本*

*Francesco Leonardi, Markus Orsi, Jean-Louis Reymond, Kaspar Riesen* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 图编辑距离, 图神经网络, 编辑成本, 可解释性, 广义加性模型

**Comment:** 

> **TL;DR:** GEDAN是一个新的图神经网络框架，通过学习上下文感知的编辑成本来近似计算图编辑距离，提高了可解释性和适应性。

**AI_Comments:** 该论文的创新点在于提出了一个能够学习上下文感知编辑成本的图神经网络框架，解决了传统GED计算中编辑成本假设不切实际的问题。通过引入广义加性模型，显著提升了模型的可解释性，这对于理解复杂图结构至关重要，尤其是在科学领域。其在无监督设置下的优化能力也增加了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 图编辑距离（GED）是衡量图之间差异性的广泛采用指标，但其计算是NP难问题。现有的基于神经网络的近似方法大多假设单位成本编辑操作，这在现实应用中不切实际。

**Method:** 本文提出了一个新颖的图神经网络（GNN）框架GEDAN，通过监督和无监督训练来近似GED。在无监督设置下，它采用一种仅梯度自组织机制，无需真实距离即可优化。此外，其核心组件是集成了一个广义加性模型（GAM），允许灵活且可解释地学习上下文感知的编辑成本。

**Result:** 实验结果表明，所提出的方法取得了与最先进的参考方法相似的结果，但显著提高了适应性和可解释性。学习到的成本函数能够洞察复杂的图结构。

**Conclusion:** 该方法在分子分析和结构模式发现等领域特别有价值。

> **ai_Abstract:** 图编辑距离（GED）在衡量图相似性方面存在计算复杂度高和现有神经网络方法假设不实际的单位成本编辑操作的问题。本文提出了GEDAN，一个新颖的图神经网络框架，它结合监督和无监督训练来近似GED。该方法通过集成广义加性模型，能够灵活且可解释地学习上下文感知的编辑成本。GEDAN在保持与现有先进方法相似性能的同时，显著提升了模型的适应性和可解释性，为复杂图结构分析提供了新的视角，尤其适用于分子分析和结构模式发现。

> **摘要翻译:** 图编辑距离（GED）定义为将一个图转换为另一个图的最小成本转换，是衡量图之间差异性的广泛采用指标。GED的主要问题是其计算是NP难问题，这反过来导致了各种近似方法的发展，包括基于神经网络（NN）的方法。大多数这些基于NN的模型通过假设单位成本编辑操作来简化GED问题，这在现实世界应用中是一个相当不切实际的约束。在这项工作中，我们提出了一个新颖的图神经网络框架，该框架使用监督和无监督训练来近似GED。在无监督设置中，它采用了一种仅梯度自组织机制，无需真实距离即可进行优化。此外，我们架构的一个核心组件是集成了广义加性模型，它允许灵活且可解释地学习上下文感知的编辑成本。实验结果表明，所提出的方法取得了与最先进的参考方法相似的结果，但显著提高了适应性和可解释性。也就是说，学习到的成本函数提供了对复杂图结构的洞察，使其在分子分析和结构模式发现等领域特别有价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [167] [FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models](https://arxiv.org/abs/2508.01055)
> *FGBench：一个用于大型语言模型中官能团级别分子性质推理的数据集和基准*

*Xuan Liu, Siru Ouyang, Xianrui Zhong, Jiawei Han, Huimin Zhao* | **Category: cs.LG, cs.AI, q-bio.BM, q-bio.QM** | **Updated: 2025-08-05**

**Keywords:** 官能团, 大型语言模型, 分子性质推理, 数据集, 基准

**Comment:** 20 pages, 20 figures

> **TL;DR:** 现有LLM在官能团级别分子性质推理方面表现不佳，本文提出了FGBench数据集和基准来解决此问题。

**AI_Comments:** FGBench的创新之处在于其提供了迄今为止缺乏的、针对大型语言模型在化学领域进行官能团级别推理的精细数据集和基准。这解决了现有数据集仅关注分子级别预测的局限性，为构建更具解释性、结构感知的化学LLM奠定了基础。其重要性在于，通过揭示当前LLM在处理精细化学信息时的不足，FGBench指明了未来LLM在分子设计和药物发现等复杂化学任务中发展的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有化学领域的大型语言模型（LLM）数据集主要关注分子级别的性质预测，而忽略了精细的官能团（FG）信息。整合官能团级别的数据可以提供有价值的先验知识，连接分子结构与文本描述，从而构建更具解释性和结构感知的LLM，以用于分子相关任务的推理，并揭示官能团与分子性质之间的隐藏关系，进而推动分子设计和药物发现。

**Method:** 本文引入了FGBench，一个包含62.5万个分子性质推理问题的数据集，其中官能团信息被精确标注和定位，确保了数据集的互操作性，并促进多模态应用。FGBench包含了245种不同官能团的回归和分类任务，分为三类：单一官能团影响、多官能团相互作用和直接分子比较。作者还使用7K精选数据对最先进的LLM进行了基准测试。

**Result:** 基准测试结果表明，当前的LLM在官能团级别的性质推理方面表现不佳。

**Conclusion:** 本文强调了提高LLM在化学任务中推理能力的必要性，并预期FGBench构建数据集的方法将作为生成新问答对的基础框架，使LLM更好地理解精细的分子结构-性质关系。

> **ai_Abstract:** 本文介绍了FGBench数据集，旨在解决大型语言模型在化学领域缺乏官能团级别推理能力的问题。FGBench包含62.5万个带有详细官能团注释的问题，支持包括单一官能团影响、多官能团相互作用和直接分子比较等多种任务。对现有LLM的基准测试结果表明，它们在官能团级别的性质推理方面表现不佳，这突显了为分子设计和药物发现改进LLM推理能力的必要性。FGBench的方法论有望成为构建新的精细化分子结构-性质关系问答对的基础。

> **摘要翻译:** 大型语言模型（LLMs）在化学领域受到了广泛关注。然而，大多数现有数据集都集中在分子级别的性质预测，而忽略了精细的官能团（FG）信息的作用。整合官能团级别的数据可以提供有价值的先验知识，将分子结构与文本描述联系起来，从而用于构建更具解释性、结构感知的LLM，以进行分子相关任务的推理。此外，LLMs可以从这些精细信息中学习，揭示特定官能团与分子性质之间的隐藏关系，从而推动分子设计和药物发现。在此，我们引入了FGBench，一个包含62.5万个分子性质推理问题的数据集，其中官能团信息被精确标注和定位，这确保了数据集的互操作性，从而促进了进一步的多模态应用。FGBench包括245种不同官能团的回归和分类任务，涵盖分子性质推理的三类：(1) 单一官能团影响，(2) 多官能团相互作用，和 (3) 直接分子比较。在对7K精选数据上最先进LLMs的基准测试中，结果表明当前的LLMs在官能团级别的性质推理方面表现不佳，突出了增强LLMs在化学任务中推理能力的必要性。我们预计FGBench中构建官能团级别信息数据集的方法将作为生成新问答对的基础框架，使LLMs更好地理解精细的分子结构-性质关系。数据集和评估代码可在https://github.com/xuanliugit/FGBench获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [168] [Unraveling the Black-box Magic: An Analysis of Neural Networks' Dynamic Extrema](https://arxiv.org/abs/2507.03885)
> *揭示黑箱魔法：神经网络动态极值分析*

*Shengjian Chen* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 神经网络, 动态极值, 泛化能力, 线性方程组, 梯度消失

**Comment:** 19 pages, 8 figures, for understanding the principles of large
  language models

> **TL;DR:** 神经网络并非黑箱，其泛化能力源于将数据动态映射到模型函数的极值点。本文证明极值数量与参数量正相关，并提出一种通过解线性方程组来确定参数的新算法，可解释并处理梯度消失和过拟合等问题。

**AI_Comments:** 本文创新性地将神经网络的泛化能力与动态极值点联系起来，并提出了一种基于线性方程组的新参数求解算法，这与主流的反向传播方法截然不同。如果该方法能有效解决梯度消失和过拟合，将对神经网络的理论理解和实践应用产生重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 指出神经网络并非黑箱，并解释其泛化能力来源，同时解决梯度消失和过拟合等现有算法的困难。

**Method:** 证明神经网络的极值数量与参数数量正相关。提出了一种与反向传播算法显著不同的新算法，该算法主要通过求解线性方程组来获取参数值。

**Result:** 证明了神经网络中极值数量与参数数量呈正相关。提出的新算法能够有效解释并处理梯度消失和过拟合等困难情况。

**Conclusion:** 神经网络的泛化能力源于其动态映射数据到模型函数极值点的能力，并且通过求解线性方程组的新算法可以有效处理现有神经网络的挑战。

> **ai_Abstract:** 本文旨在揭示神经网络的“黑箱”本质，指出其泛化能力来源于将数据动态映射到模型函数极值点的能力。研究证明神经网络的极值数量与参数数量正相关。在此基础上，提出了一种有别于反向传播的新算法，通过求解线性方程组来确定参数，该方法能够有效解释并处理梯度消失和过拟合等常见问题。

> **摘要翻译:** 我们指出神经网络并非黑箱，它们的泛化能力源于将数据集动态映射到模型函数的极值点的能力。我们进一步证明，神经网络中极值的数量与其参数数量呈正相关。随后，我们提出了一种与反向传播算法显著不同的新算法，该算法主要通过求解线性方程组来获取参数值。在这种框架下，梯度消失和过拟合等一些困难情况可以得到合理解释和处理。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [173] [A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design](https://arxiv.org/abs/2508.03665)
> *一个受DbC启发的神经符号层，用于可信智能体设计*

*Claudiu Leoveanu-Condrei* | **Category: cs.LG, cs.AI, I.2.7; I.2.2; I.1.2; D.1.0** | **Updated: 2025-08-05**

**Keywords:** 契约式设计, 大型语言模型, 神经符号, 可信赖性, 语义验证

**Comment:** 3 pages, 1 figure

> **TL;DR:** 本文提出一个受契约式设计（DbC）启发的神经符号层，用于大型语言模型（LLM），以通过定义输入输出的语义和类型要求并结合概率修复来提高其可验证性和可靠性。

**AI_Comments:** 这项工作通过将传统的软件工程原则（如DbC）与现代的神经符号方法相结合，为提高大型语言模型的可信赖性提供了一个创新的框架。其“契约层”的概念为LLMs的输入输出提供了明确的规范和验证机制，有助于缓解其“幻觉”等不可控行为。提出的“功能等价”概念也为构建模块化和可互换的AI代理提供了理论基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽然能生成流畅的输出，但缺乏可验证的保证，这限制了它们在需要高可靠性的场景中的应用。

**Method:** 本文引入了一个受契约式设计（DbC）和类型理论原则启发的契约层，用于调解每次LLM调用。该层规定了输入和输出的语义和类型要求，并结合了概率修复机制以引导生成符合要求。语义验证通过程序员指定在良好类型数据结构上的条件操作性地定义。

**Result:** 契约满足是概率性的，语义验证通过程序员指定的条件操作性地定义。该层揭示了LLMs作为语义解析器和概率黑盒组件的双重视图。研究还提出，任何满足相同契约的两个智能体在这些契约方面是功能等价的。

**Conclusion:** 本文提出，任何满足相同契约的两个智能体在这些契约方面是功能等价的，这为构建可信赖的智能体提供了理论基础。

> **ai_Abstract:** 本文提出一个受契约式设计（DbC）和类型理论启发的神经符号契约层，旨在解决大型语言模型（LLMs）缺乏可验证保证的问题。该层通过对LLM的输入和输出施加语义及类型契约，并辅以概率修复机制，以确保生成内容的合规性。研究表明，契约满足是概率性的，且语义验证可操作性地定义。此外，本文提出了一个核心观点：任何满足相同契约的智能体在功能上是等价的，为设计更可信赖的智能体提供了新思路。

> **摘要翻译:** 生成模型，特别是大型语言模型（LLMs），能产生流畅的输出，但缺乏可验证的保证。我们借鉴契约式设计（DbC）和类型理论原则，引入了一个契约层来调解每一次LLM调用。契约规定了输入和输出的语义和类型要求，并结合概率修复以引导生成符合要求。该层揭示了LLMs作为语义解析器和概率黑盒组件的双重视图。契约满足是概率性的，语义验证通过程序员指定在良好类型数据结构上的条件操作性地定义。更广泛地说，这项工作提出，任何满足相同契约的两个智能体在这些契约方面是功能等价的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [176] [Leveraging Distribution Matching to Make Approximate Machine Unlearning Faster](https://arxiv.org/abs/2507.09786)
> *利用分布匹配加速近似机器遗忘*

*Junaid Iqbal Khan* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 机器遗忘, 数据集压缩, 分布匹配, 加速收敛, 模型隐私

**Comment:** 10 pages, 4 figures, 4 tables

> **TL;DR:** 本文提出了Blend和A-AMU两种方法，通过数据集压缩和加速损失函数，显著加快近似机器遗忘过程，同时保持模型效用和隐私。

**AI_Comments:** 本文的创新点在于首次系统性地结合了专门的数据集压缩技术（Blend）和加速损失函数（A-AMU）来解决近似机器遗忘的效率问题。Blend在数据集缩减方面表现出数量级的速度提升，而A-AMU则通过优化损失函数加速收敛。这种数据和损失双重优化的方法为提升AMU的实用性提供了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 近似机器遗忘（AMU）在处理大量保留数据集时计算开销大，且遗忘迭代次数难以减少，导致计算运行时长过长。

**Method:** 提出了两种互补方法：1. Blend：一种新颖的分布匹配数据集压缩（DC）方法，通过合并视觉相似图像来显著减小保留数据集大小，预处理开销小，比现有DC方法快数个数量级。2. Accelerated-AMU (A-AMU)：一种以损失为中心的方法，通过结合陡峭化的主要损失来加速遗忘，并使用可微分正则化器来匹配被遗忘数据和分布内未见数据的损失分布，从而加速收敛。

**Result:** 实验证明，这种数据和损失中心优化双重方法显著降低了单轮和多轮场景下的端到端遗忘延迟，同时保持了模型效用和隐私。

**Conclusion:** 通过联合设计专门的数据集压缩技术和专用的加速损失函数，本研究首次系统性地解决了机器遗忘效率问题。

> **ai_Abstract:** 本文提出了两种互补方法——Blend和Accelerated-AMU（A-AMU），以显著加速近似机器遗忘（AMU）过程。Blend是一种分布匹配数据集压缩技术，通过合并相似图像来减小保留数据集大小，其效率远超现有方法。A-AMU则是一种损失中心方法，通过结合陡峭化主损失和损失分布匹配正则化器来加速模型收敛。实验证明，这两种方法的结合显著降低了端到端遗忘延迟，同时保持了模型性能和隐私，为机器遗忘效率提供了新的解决方案。

> **摘要翻译:** 近似机器遗忘（AMU）通过在训练集的保留（和遗忘）子集上进行专门的微调，使模型能够“遗忘”特定的训练数据。然而，处理这个庞大的保留子集仍然占据了计算运行时长的主导地位，同时减少遗忘迭代次数也仍然是一个挑战。在本文中，我们提出了两种互补的方法来加速任意面向分类的AMU方法。首先，\textbf{Blend}，一种新颖的分布匹配数据集压缩（DC）方法，通过共享混合权重合并视觉相似的图像，显著减小了保留集的大小。它以最小的预处理开销运行，并且比最先进的DC方法快几个数量级。其次，我们以损失为中心的方法，\textbf{Accelerated-AMU (A-AMU)}，增强了AMU目标以加快收敛。A-AMU通过结合一个陡峭化的主要损失来加速遗忘，以及一个可微分正则化器来匹配被遗忘数据和分布内未见数据的损失分布，从而实现这一点。我们广泛的实验表明，这种数据和损失中心优化的双重方法在单轮和多轮场景中都极大地减少了端到端遗忘延迟，同时保持了模型效用和隐私。据我们所知，这是首次通过联合设计专门的数据集压缩技术和专用的加速损失函数来系统性地解决遗忘效率问题的研究。代码可在https://github.com/algebraicdianuj/DC_Unlearning 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [184] [AdaBrain-Bench: Benchmarking Brain Foundation Models for Brain-Computer Interface Applications](https://arxiv.org/abs/2507.09882)
> *AdaBrain-Bench：用于脑机接口应用的脑基础模型基准测试*

*Jiamin Wu, Zichen Ren, Junyu Wang, Pengyu Zhu, Yonghao Song, Mianxin Liu, Qihao Zheng, Lei Bai, Wanli Ouyang, Chunfeng Song* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 脑机接口, 脑基础模型, 基准测试, 脑电图, 迁移学习

**Comment:** 

> **TL;DR:** AdaBrain-Bench是一个大规模标准化基准，用于系统评估非侵入式脑机接口（BCI）任务中的脑基础模型，解决了当前领域缺乏全面基准的问题，并提供了评估和选择模型的见解。

**AI_Comments:** 该论文通过引入AdaBrain-Bench解决了当前脑机接口（BCI）领域的一个关键空白，即缺乏对脑基础模型进行系统评估的标准化基准。其创新之处在于提供了全面的数据集、任务适应管道和多维评估指标，这对于推动脑基础模型在BCI应用中的实际效用至关重要。该基准的发布将极大地促进可重现研究和该领域内更稳健、更通用神经解码解决方案的开发。

<details>
  <summary>Details</summary>

**Motivation:** 当前非侵入式脑机接口（BCI）领域缺乏全面、实用且可扩展的基准来评估公共脑基础模型在各种BCI任务中的效用，这阻碍了它们的广泛采用。

**Method:** 本文提出了AdaBrain-Bench，一个大规模标准化基准，用于系统评估广泛的非侵入式BCI任务中的脑基础模型。它包含跨7个关键应用的多种代表性BCI解码数据集，并引入了一个简化的任务适应管道，集成了多维评估指标和一套适应工具。该基准提供了一个评估脑基础模型在跨受试者、多受试者和少样本等关键迁移设置中泛化能力的框架。

**Result:** 利用AdaBrain-Bench评估了一系列公开可用的脑基础模型，并提供了在各种场景中选择合适模型的实践见解。

**Conclusion:** AdaBrain-Bench提供了一个可重现和可外部使用的基准管道，为促进稳健和通用神经解码解决方案的进展提供了一个持续发展的平台。

> **ai_Abstract:** AdaBrain-Bench是一个大规模标准化基准，旨在解决非侵入式脑机接口（BCI）领域缺乏全面基准来评估脑基础模型的问题。它整合了来自7个关键应用的多元BCI解码数据集，并引入了包含适应管道、多维评估指标和工具的框架，用于系统评估脑基础模型在跨受试者、多受试者和少样本等迁移设置中的泛化能力。该研究利用AdaBrain-Bench评估了现有模型，并提供了模型选择的实践指导，同时公开了其基准管道以促进可重现研究和该领域的持续发展。

> **摘要翻译:** 非侵入式脑机接口（BCI）提供了一种安全且易于访问的连接人脑与外部设备的方式，在家用和临床环境中具有广泛应用，以增强人类能力。然而，非侵入式信号中的高噪声水平和有限的任务特定数据限制了解码能力。最近，自监督预训练的采用正在改变非侵入式BCI研究的格局，使得脑基础模型能够从大规模未标记的脑电图（EEG）信号中捕获通用的神经表征，尽管存在大量噪声。然而，尽管取得了这些进展，该领域目前缺乏全面、实用且可扩展的基准来评估公共基础模型在各种BCI任务中的效用，这阻碍了它们的广泛采用。为了解决这一挑战，我们提出了AdaBrain-Bench，一个大规模标准化基准，用于系统评估广泛的非侵入式BCI任务中的脑基础模型。AdaBrain-Bench包含了一系列代表性的BCI解码数据集，涵盖7个关键应用。它引入了一个简化的任务适应管道，集成了多维评估指标和一套适应工具。该基准提供了一个包容性框架，用于评估脑基础模型在关键迁移设置中的泛化能力，包括跨受试者、多受试者和少样本场景。我们利用AdaBrain-Bench评估了一套公开可用的脑基础模型，并提供了在各种场景中选择合适模型的实践见解。我们公开了我们的基准管道，以实现可重现的研究和外部使用，提供一个持续发展的平台，以促进稳健和通用神经解码解决方案的进展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [190] [Scalable Graph Condensation with Evolving Capabilities](https://arxiv.org/abs/2502.17614)
> *可扩展的图凝聚与演化能力*

*Shengbo Gong, Mohammad Hashemi, Juntong Ni, Carl Yang, Wei Jin* | **Category: cs.LG, cs.SI, I.2** | **Updated: 2025-08-04**

**Keywords:** 图凝聚, 可扩展性, 动态图, 聚类, 演化能力

**Comment:** 19 pages, 8 figures

> **TL;DR:** GECC是一种可扩展的图凝聚方法，能够处理动态演化的图数据，通过继承先前结果实现演化能力，并提供显著的加速和更好的性能。

**AI_Comments:** 本文提出了一种创新的持续图凝聚框架GECC，解决了现有方法无法处理动态演化图数据的局限性。其通过继承聚类中心实现“演化能力”是关键创新点，显著提高了处理效率和可扩展性，尤其是在大规模动态图数据场景下具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有图凝聚方法假设训练集是静态的，这与现实世界图数据的动态演化特性不符，导致处理增长的数据集时效率低下，需要昂贵的再训练。

**Method:** 本文提出了GECC（Graph Evolving Clustering Condensation），一种可扩展的图凝聚方法，旨在处理大规模和演化的图数据。GECC通过对聚合特征进行逐类别聚类，并能在凝聚图扩展时将先前的凝聚结果作为聚类中心继承，从而获得演化能力。

**Result:** GECC在大型数据集上实现了约1000倍的速度提升，并且在性能上优于大多数最先进的图凝聚方法。该方法具有坚实的理论基础和卓越的经验性能。

**Conclusion:** GECC为处理大规模和不断演化的图数据提供了一种有效且高效的解决方案，克服了现有图凝聚方法在动态数据处理方面的限制，并展现出优越的性能和速度。

> **ai_Abstract:** 本文提出了一种名为GECC（Graph Evolving Clustering Condensation）的新型可扩展图凝聚方法，旨在解决现有方法在处理动态演化图数据时的局限性。GECC通过对聚合特征进行逐类别聚类，并能继承先前的凝聚结果作为聚类中心，从而实现持续的图凝聚和演化能力。实验证明，GECC在大型数据集上比现有最先进方法快约1000倍，并展现出更优越的性能。

> **摘要翻译:** 图数据的快速增长带来了显著的可扩展性挑战，因为大多数图算法的规模都与数据大小呈二次方关系。为了缓解这些问题，图凝聚（GC）方法被提出，旨在从较大的图中学习一个较小的图，从而加速下游任务。然而，现有方法关键地假设训练集是静态的，这与现实世界图数据固有的动态和演化性质相冲突。这项工作引入了一种新颖的持续图凝聚框架，能够高效地更新精炼图，处理数据流而无需昂贵的再训练。这一限制导致在凝聚增长的训练集时效率低下。在本文中，我们介绍了GECC（图演化聚类凝聚），一种可扩展的图凝聚方法，旨在处理大规模和演化的图数据。GECC通过对聚合特征进行逐类别聚类，采用了一种可追溯且高效的方法。此外，当凝聚图扩展时，它可以继承先前的凝聚结果作为聚类中心，从而获得演化能力。这种方法得到了坚实的理论基础支持，并展示了卓越的经验性能。包括真实世界场景在内的综合实验表明，GECC在大型数据集上实现了约1000倍的速度提升，同时性能优于大多数最先进的图凝聚方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [192] [A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18376)
> *智能农业中扩散模型的综合综述：进展、应用与挑战*

*Xing Hu, Haodong Chen, Qianqian Duan, Choon Ki Ahn, Huiliang Shang, Dawei Zhang Zhang* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 智能农业, 生成模型, 图像处理, 遥感

**Comment:** 

> **TL;DR:** 本文综述了扩散模型在智能农业中的最新进展、应用及其面临的挑战，指出扩散模型在处理农业图像、数据增强和遥感分析方面的巨大潜力。

**AI_Comments:** 本文作为一篇综述性论文，系统梳理了扩散模型在智能农业中的应用，填补了该领域内扩散模型应用的空白。其重要性在于，它不仅指出了扩散模型在解决农业图像数据挑战方面的优势，还展望了其在未来智能农业发展中的关键作用，为研究人员提供了宝贵的参考。创新性体现在对新兴扩散模型在特定应用领域的全面总结。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球人口增长和耕地资源日益有限，智能农业和精准农业成为可持续农业发展的关键方向。人工智能，特别是深度学习模型，已广泛应用于农业领域，而扩散模型作为一种新兴的生成模型，在解决农业场景中带注释数据集有限和样本分布不平衡等挑战方面展现出巨大潜力。

**Method:** 本文对扩散模型在农业领域的最新应用进展进行了综述，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的作用。

**Result:** 与传统的生成对抗网络（GANs）相比，扩散模型表现出更高的训练稳定性和卓越的图像生成质量。实证研究表明，扩散模型通过提高图像合成、增强和去噪任务的准确性、鲁棒性和泛化能力，显著提升了下游模型的性能。

**Conclusion:** 尽管扩散模型在计算效率和领域泛化方面仍面临挑战，但预计它们将在未来的智能农业中发挥越来越重要的作用，并有望解决粮食安全和环境可持续性等紧迫的全球问题。

> **ai_Abstract:** 本文全面综述了扩散模型在智能农业领域的应用进展、潜力及挑战。研究指出，扩散模型相较于GANs具有更高的训练稳定性和图像生成质量，能有效解决农业数据稀缺和不平衡问题。它们在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中发挥关键作用，显著提升了下游模型的性能。尽管仍面临计算效率和领域泛化等挑战，但扩散模型被认为对未来智能农业、粮食安全和环境可持续性具有重要意义。

> **摘要翻译:** 随着全球人口的增长和耕地资源的日益有限，智能和精准农业已成为可持续农业发展的重要方向。人工智能（AI），特别是深度学习模型，已广泛应用于作物监测、病虫害检测和产量预测等领域。在最近的生成模型中，扩散模型在农业图像处理、数据增强和遥感分析方面展现出巨大的潜力。与传统的生成对抗网络（GANs）相比，扩散模型表现出更高的训练稳定性和卓越的图像生成质量，有效解决了农业场景中带注释数据集有限和样本分布不平衡等挑战。本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的作用。实证研究表明，扩散模型通过在复杂环境条件下提高图像合成、增强和去噪任务的准确性、鲁棒性和泛化能力，显著提升了下游模型的性能。尽管在计算效率和领域泛化方面仍面临挑战，但扩散模型有望在未来的智能农业中发挥越来越重要的作用。随着技术的不断发展，它在解决粮食安全和环境可持续性等紧迫的全球问题方面具有巨大的前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [197] [Spectral Architecture Search for Neural Network Models](https://arxiv.org/abs/2504.00885)
> *神经网络模型的谱架构搜索*

*Gianluca Peri, Lorenzo Chicchi, Duccio Fanelli, Lorenzo Giambagli* | **Category: cs.LG, cond-mat.dis-nn, cond-mat.stat-mech, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 架构搜索, 神经网络, 谱属性, 梯度优化, 参数计数

**Comment:** 

> **TL;DR:** 本文提出了一种名为SPARCS的新型架构搜索协议，它利用层间传递矩阵的谱属性，通过连续可微流形进行探索，实现了基于梯度的优化，并在基准模型上展现出更少参数和恰当表达能力的自发架构。

**AI_Comments:** 该论文提出了一种新颖的架构搜索范式，通过引入谱属性和连续可微流形，为神经网络架构优化开辟了新的途径。其创新之处在于将离散的架构搜索问题转化为可梯度优化的连续问题，这可能大大提高搜索效率。减少参数数量和找到最小表达能力架构的成果，对于模型压缩和效率提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工神经网络的架构设计和优化是具有挑战性的问题。

**Method:** 本文提出了一种名为SPARCS（SPectral ARchiteCture Search）的新型架构搜索协议。该方法利用层间传递矩阵的谱属性，通过跨越连续可微流形来探索可能的架构空间，从而能够采用基于梯度的优化算法。

**Result:** 在简单的基准模型上，该方法能够生成一个自发架构，该架构具有处理给定任务所需的最小表达能力，并且与其他可行替代方案相比，参数数量有所减少。

**Conclusion:** 所提出的SPARCS方法能有效搜索出具有较少参数和适当表达能力的神经网络架构。

> **ai_Abstract:** 本文介绍了一种名为SPARCS的新型神经网络架构搜索方法。SPARCS利用层间传递矩阵的谱属性，通过在连续可微流形上进行探索，实现了基于梯度的优化。实验表明，该方法能够为基准任务找到一种自发形成的架构，该架构具有最小的表达能力和更少的参数。

> **摘要翻译:** 架构设计与优化是人工神经网络领域的挑战性问题。在此背景下，我们提出了一种名为SPARCS（SPectral ARchiteCture Search）的新型架构搜索协议，该协议利用层间传递矩阵的谱属性。SPARCS允许通过跨越连续可微流形来探索可能的架构空间，从而最终能够采用基于梯度的优化算法。参照简单的基准模型，我们展示了新提出的方法能够产生一个自发形成的架构，该架构具有处理所研究任务所需的最小表达能力，并且与其它可行替代方案相比，参数数量有所减少。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [200] [HGCN(O): A Self-Tuning GCN HyperModel Toolkit for Outcome Prediction in Event-Sequence Data](https://arxiv.org/abs/2507.22524)
> *HGCN(O)：一个用于事件序列数据结果预测的自调优GCN超模型工具包*

*Fang Wang, Paolo Ceravolo, Ernesto Damiani* | **Category: cs.LG, I.2.6** | **Updated: 2025-08-05**

**Keywords:** GCN, 事件序列预测, 自调优, 结果预测, 业务流程监控

**Comment:** 15 pages, 2 figures, preprint submitted to Knowledge-Base Systems

> **TL;DR:** HGCN(O)是一个自调优的GCN工具包，用于事件序列的结果预测。它结合了多种GCN架构和图表示，能优化平衡和非平衡数据集的预测准确性和稳定性，并被证实优于传统方法。

**AI_Comments:** 该论文的创新之处在于提出了一个“自调优”的GCN超模型工具包，能够整合多种GCN架构和图表示来处理事件序列数据。其特别关注并优化了在平衡和非平衡数据集上的预测准确性和稳定性，这在实际应用中非常重要。此外，明确指出其在预测性业务流程监控中的应用，突显了其在工业实践中的潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是开发一种能够优化事件序列数据预测准确性和稳定性的工具包，特别是针对平衡和非平衡数据集，并应用于预测性业务流程监控等领域。

**Method:** 该论文提出了HGCN(O)，一个使用图卷积网络（GCN）模型的自调优工具包，用于事件序列预测。它包含四种GCN架构（O-GCN、T-GCN、TP-GCN、TE-GCN），涵盖GCNConv和GraphConv层。该工具包通过选择不同的节点和图级属性以及通过边权重表示时间依赖性，整合了事件序列的多种图表示。

**Result:** 广泛的实验表明，GCNConv模型在非平衡数据上表现出色，而所有模型在平衡数据上表现一致。实验还证实，HGCN(O)的性能优于传统方法。

**Conclusion:** HGCN(O)是一个有效且性能优越的自调优GCN工具包，适用于事件序列数据的结果预测，尤其在处理非平衡数据集时表现突出，并且在预测性业务流程监控等应用中具有重要价值。

> **ai_Abstract:** HGCN(O)是一个创新的自调优GCN工具包，专门设计用于事件序列的结果预测。它集成了四种GCN架构（O-GCN、T-GCN、TP-GCN、TE-GCN）和多种图表示方法，通过优化节点级和图级属性以及时间依赖性来提高预测的准确性和稳定性。实验结果表明，HGCN(O)在处理平衡和非平衡数据集时均表现出色，尤其在非平衡数据上GCNConv模型性能突出，且整体表现优于传统方法。该工具包在预测性业务流程监控等领域具有重要的应用潜力。

> **摘要翻译:** 我们提出了HGCN(O)，一个使用图卷积网络（GCN）模型进行事件序列预测的自调优工具包。该工具包包含GCNConv和GraphConv层上的四种GCN架构（O-GCN、T-GCN、TP-GCN、TE-GCN），集成了事件序列的多种图表示，并具有不同的节点和图级属性选择以及通过边权重表示的时间依赖性，从而优化了平衡和非平衡数据集的预测准确性和稳定性。大量实验表明，GCNConv模型在非平衡数据上表现出色，而所有模型在平衡数据上表现一致。实验还证实了HGCN(O)的性能优于传统方法。应用包括预测性业务流程监控（PBPM），它根据事件日志预测业务流程的未来事件或状态。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [207] [SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy](https://arxiv.org/abs/2508.01188)
> *SpectrumWorld：光谱学人工智能基础*

*Zhuo Yang, Jiaqing Xie, Shuaike Shen, Daolang Wang, Yeyun Chen, Ben Gao, Shuzhou Sun, Biqing Qi, Dongzhan Zhou, Lei Bai, Linjiang Chen, Shufei Zhang, Jun Jiang, Tianfan Fu, Yuqiang Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 光谱学, 深度学习, 基准测试, SpectrumLab, 人工智能

**Comment:** 

> **TL;DR:** SpectrumLab是一个统一的平台，旨在标准化和加速光谱学领域的深度学习研究，它包含一个Python库、一个基准生成模块和多层基准测试套件，并揭示了现有方法的局限性。

**AI_Comments:** 该论文通过引入SpectrumLab平台，为光谱学领域的深度学习研究提供了急需的标准化和加速工具。其创新之处在于将数据处理、基准生成和多任务评估集成到一个统一框架中，特别是SpectrumAnnotator能够从有限数据生成高质量基准，以及SpectrumBench涵盖广泛的光谱任务和化学物质，这些都极大地推动了该领域的研究。揭示现有LLMs在光谱学应用的局限性也具有重要意义，指明了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在光谱学领域潜力巨大，但该领域的研究和评估缺乏标准化规范。

**Method:** 提出了SpectrumLab平台，包含三个核心组件：一个用于数据处理和评估的Python库和排行榜；一个创新的SpectrumAnnotator模块，能从有限的种子数据生成高质量基准；以及SpectrumBench，一个涵盖14种光谱任务、10多种光谱类型、包含120万种化学物质光谱的多层基准测试套件。

**Result:** 通过在SpectrumBench上对18个前沿多模态LLM进行实证研究，揭示了当前方法的关键局限性。

**Conclusion:** SpectrumLab有望成为推动深度学习驱动的光谱学领域未来发展的重要基础。

> **ai_Abstract:** 本研究提出了SpectrumLab，一个统一的平台，旨在解决光谱学深度学习研究中缺乏标准化的问题。该平台整合了Python库、基准生成模块SpectrumAnnotator和多任务基准测试套件SpectrumBench。通过对SpectrumBench上现有模型的实证研究，揭示了当前方法的局限性，并期望SpectrumLab能为光谱学深度学习的未来发展提供基础。

> **摘要翻译:** 深度学习在光谱学领域前景广阔，但该新兴领域的研究和评估往往缺乏标准化规范。为解决这一问题，我们推出了SpectrumLab，这是一个开创性的统一平台，旨在系统化和加速光谱学领域的深度学习研究。SpectrumLab集成了三个核心组件：一个全面的Python库，包含基本数据处理和评估工具以及排行榜；一个创新的SpectrumAnnotator模块，可以从有限的种子数据生成高质量的基准；以及SpectrumBench，一个多层基准测试套件，涵盖14种光谱任务和10多种光谱类型，其光谱数据来自超过120万种不同的化学物质。通过在SpectrumBench上对18个前沿多模态大型语言模型进行的全面实证研究，揭示了当前方法的关键局限性。我们希望SpectrumLab能为深度学习驱动的光谱学领域的未来发展奠定重要基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [208] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
> *锁相信噪比波段选择用于高光谱图像中弱矿物信号检测*

*Judy X Yang* | **Category: cs.LG, Cs** | **Updated: 2025-08-05**

**Keywords:** 高光谱成像, 矿物检测, 波段选择, 信噪比, 解混

**Comment:** 8 pages, 6 figures

> **TL;DR:** 本文提出了一种两阶段集成框架，通过锁相信噪比波段选择和解混来提高高光谱图像中弱矿物信号的检测性能。

**AI_Comments:** 该论文的创新点在于其提出的两阶段集成框架，特别是结合了锁相信噪比阈值进行波段选择，以及Savitzky-Golay滤波在波段选择和预处理中的双重作用。这为高光谱矿物测绘中弱信号检测这一常见挑战提供了一个实用且可复现的解决方案，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱成像为矿物测绘提供了详细的光谱信息，但弱矿物特征常被噪声和冗余波段掩盖，限制了检测性能。

**Method:** 本文提出一个两阶段集成框架。第一阶段，计算每个光谱波段的信噪比（SNR），并应用锁相阈值技术丢弃低信噪比波段，同时使用Savitzky-Golay滤波进行光谱平滑。第二阶段，将精炼后的高光谱数据重新引入模型，使用KMeans聚类提取末端元光谱，然后通过非负最小二乘法（NNLS）进行丰度解混。最终的末端元与实验室光谱通过余弦相似度和RMSE指标进行定量比较。

**Result:** 实验结果证实，所提出的流程提高了端元解混精度，并增强了对弱矿物区域的检测能力。

**Conclusion:** 这种两阶段策略为地质高光谱成像应用中的光谱降维和解混提供了一种实用且可复现的解决方案。

> **ai_Abstract:** 本文提出了一种用于高光谱图像中弱矿物信号检测的两阶段集成框架。第一阶段通过计算信噪比并应用锁相阈值技术进行波段选择，同时结合Savitzky-Golay滤波进行光谱平滑，以去除噪声和冗余。第二阶段利用KMeans聚类提取末端元，并通过非负最小二乘法进行丰度解混。实验证明，该方法能有效提高解混精度并增强弱矿物区域的检测能力，为地质高光谱应用提供了一种实用的光谱降维和解混方案。

> **摘要翻译:** 高光谱成像为矿物测绘提供了详细的光谱信息；然而，弱矿物特征常常被噪声和冗余波段掩盖，限制了检测性能。为了解决这个问题，我们提出了一个两阶段集成框架，用于增强Cuprite矿区的矿物检测。在第一阶段，我们计算每个光谱波段的信噪比（SNR），并应用锁相阈值技术丢弃低信噪比波段，有效去除冗余并抑制背景噪声。然后采用Savitzky-Golay滤波进行光谱平滑，它具有双重作用：首先在波段选择过程中稳定趋势，其次在预处理过程中保留细粒度的光谱特征。在第二阶段，将精炼后的高光谱数据重新引入模型，其中使用KMeans聚类提取12个末端元光谱（W1 custom），然后通过非负最小二乘法（NNLS）进行丰度解混。将得到的末端元与实验室光谱（W1 raw）使用余弦相似度和RMSE指标进行定量比较。实验结果证实，我们提出的流程提高了端元解混精度，并增强了对弱矿物区域的检测能力。这种两阶段策略为地质高光谱成像应用中的光谱降维和解混提供了一种实用且可复现的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [213] [Self-Questioning Language Models](https://arxiv.org/abs/2508.03682)
> *自我提问式语言模型*

*Lili Chen, Mihir Prabhudesai, Katerina Fragkiadaki, Hao Liu, Deepak Pathak* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 语言模型, 自我学习, 强化学习, 自博弈, 推理

**Comment:** 

> **TL;DR:** 大型语言模型可以通过生成自己的问题和答案，在没有外部数据的情况下提高推理能力，通过一个名为SQLM的非对称自博弈框架实现。

**AI_Comments:** 这项工作的创新之处在于提出了一种语言模型自我提升的新范式，即在没有外部人工标注数据的情况下，通过内部生成问题和答案来实现能力增长。其非对称自博弈框架和巧妙的奖励机制（特别是多数投票和单元测试作为正确性代理）是其亮点，为模型在资源受限或需要持续学习的场景下提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究大型语言模型是否能在不依赖外部数据的情况下，仅通过生成自己的问题和答案来提升能力。

**Method:** 提出了“自我提问式语言模型 (SQLM)”：一个非对称的自博弈框架。其中，提问者根据给定主题生成问题，解决者尝试回答。提问者和解决者都通过强化学习进行训练。提问者根据问题难度（非过易或过难）获得奖励，解决者根据多数投票（作为正确性的代理）获得奖励。对于编程任务，提问者生成单元测试进行验证。该框架在三位数乘法、代数问题（OMEGA基准）和编程问题（Codeforces）上进行了研究。

**Result:** 通过持续生成更有趣的问题并尝试解决它们，语言模型无需访问任何精选训练数据集即可在下游基准上得到改进。

**Conclusion:** 语言模型可以通过不断生成和解决问题，在没有外部数据的情况下提升自身能力。

> **ai_Abstract:** 本文提出了一种名为“自我提问式语言模型 (SQLM)”的新方法，使大型语言模型无需外部数据即可提升推理能力。SQLM是一个非对称自博弈框架，由一个生成问题的“提问者”和一个解决问题的“解决者”组成，两者均通过强化学习训练。提问者因生成难度适中的问题而获得奖励，解决者则通过多数投票机制获得奖励。该方法在数学和编程基准测试中展现出，语言模型通过内部生成并解决问题，能在不依赖额外数据集的情况下提高性能。

> **摘要翻译:** 大型语言模型能否在没有外部数据的情况下，通过生成自己的问题和答案来提高？我们假设一个预训练语言模型，在仅给定一个指定主题（例如代数应用题）并要求模型生成自己的问题的情况下，可以提高其推理能力。为此，我们提出了自我提问式语言模型（SQLM）：一个非对称的自博弈框架，其中提问者获得主题并为解决者生成问题，解决者尝试回答该问题。提问者和解决者都通过强化学习进行训练。如果问题不过于简单或过于困难，提问者将获得奖励；解决者则根据多数投票获得奖励，这在缺乏真实答案的情况下作为正确性的代理。对于编程任务，提问者可以生成单元测试用于验证。我们研究了在三个基准测试上的这种非对称自博弈框架：三位数乘法、OMEGA基准中的代数问题以及Codeforces中的编程问题。通过持续生成更有趣的问题并尝试解决它们，语言模型无需访问任何精选训练数据集即可在下游基准上得到改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [Stochastic Encodings for Active Feature Acquisition](https://arxiv.org/abs/2508.01957)
> *用于主动特征获取的随机编码*

*Alexander Norcliffe, Changhee Lee, Fergus Imrie, Mihaela van der Schaar, Pietro Lio* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 主动特征获取, 随机编码, 潜在变量模型, 监督学习, 动态特征选择

**Comment:** 31 pages, 15 figures, 17 tables, published at ICML 2025

> **TL;DR:** 本文提出了一种基于随机潜在变量模型的主动特征获取新方法，该方法通过在随机潜在空间中推理特征来克服现有强化学习方法训练困难和贪婪方法目光短浅的问题，并在广泛的数据集上表现优于现有基线。

**AI_Comments:** 本文的创新点在于引入了一个基于随机潜在变量模型的监督学习框架来解决主动特征获取问题，有效避免了强化学习的训练复杂性和贪婪方法的局部最优性。通过在潜在空间进行推理，该方法能够对未观测特征的多种可能性进行建模，从而做出更全局的决策，提高了特征获取的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的主动特征获取方法存在缺陷：强化学习方法面临训练困难，而贪婪地最大化标签和未观测特征的条件互信息会导致短视的获取。

**Method:** 本文引入了一种潜在变量模型，并以监督方式进行训练。通过在随机潜在空间中对许多可能的未观测实现中的特征进行推理，来完成特征获取。

**Result:** 在大量合成和真实数据集上的广泛评估表明，所提出的方法可靠地优于各种基线方法。

**Conclusion:** 本文提出的基于随机潜在变量模型的主动特征获取方法，有效解决了现有方法的局限性，并在性能上超越了多种基线，证明了其在动态特征选择问题上的优越性。

> **ai_Abstract:** 本文提出了一种新的主动特征获取（AFA）方法，旨在解决现有方法（如强化学习的训练困难和贪婪方法的短视性）的局限。该方法引入了一个以监督方式训练的潜在变量模型，通过在随机潜在空间中推理特征来进行获取决策。实验结果表明，该方法在多种合成和真实数据集上均显著优于现有基线。

> **摘要翻译:** 主动特征获取是一个实例级、序列化的决策问题。其目标是根据当前观测结果，独立地为每个测试实例动态选择要测量的特征。常见方法要么使用强化学习，但会遇到训练困难；要么贪婪地最大化标签和未观测特征的条件互信息，但这会导致短视的获取。为了解决这些缺点，我们引入了一个以监督方式训练的潜在变量模型。通过在随机潜在空间中对许多可能的未观测实现中的特征进行推理来完成特征获取。在大量合成和真实数据集上的广泛评估表明，我们的方法可靠地优于各种基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [A Compression Based Classification Framework Using Symbolic Dynamics of Chaotic Maps](https://arxiv.org/abs/2508.02330)
> *基于混沌映射符号动力学的压缩分类框架*

*Parth Naik, Harikrishnan N B* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 分类, 混沌映射, 符号动力学, 数据压缩, 机器学习

**Comment:** 4 figures, 3 tables

> **TL;DR:** 该研究提出了一种名为ChaosComp的新型分类框架，它利用混沌映射的符号动力学和数据压缩来对数据进行分类，通过比较不同类别的压缩表示长度来预测标签，并在多个数据集上取得了有竞争力的性能。

**AI_Comments:** 该研究的创新之处在于将动力系统、符号表示和基于压缩的学习概念融合，为分类问题提供了一个新颖的解释视角。这种跨学科的方法为机器学习领域带来了新的思路，尤其是在探索数据内在动态结构方面具有重要意义。尽管其目标并非达到最先进的性能，但其理论贡献和概念融合的价值不容忽视。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过动力系统和压缩的视角重新解释分类问题，这在学习理论和信息处理中是基础性视角，而不是追求最先进的性能。

**Method:** 该方法名为ChaosComp。核心思想是：1. 通过对阈值化的实值训练数据生成符号序列，然后通过一维混沌映射演化，为每个类别建模。2. 计算符号模式的转移概率并聚合形成类别特定的概率模型。3. 在测试阶段，测试数据被阈值化和符号化，然后使用类别符号统计通过反向迭代（一种动态重建技术）进行编码。4. 预测标签对应于产生最短压缩表示的类别，表示在其各自混沌模型下最有效的符号编码。

**Result:** 该方法在合成数据集和真实世界数据集上进行了评估，与传统机器学习算法相比，显示出有竞争力的性能。例如，在乳腺癌威斯康星数据集上的宏观F1分数达到0.9531，在Seeds数据集上为0.9475，在Iris数据集上为0.8469。

**Conclusion:** 该研究成功地通过动力系统和压缩的视角重新解释了分类问题，并提出了一种基于混沌映射符号动力学和数据压缩的新型分类框架，该框架在多个数据集上表现出有竞争力的性能。

> **ai_Abstract:** 该论文提出了一种名为ChaosComp的创新分类框架，它结合了混沌映射的符号动力学和数据压缩。该框架通过将训练数据转化为符号序列并利用混沌映射演化，为每个类别构建概率模型。在测试时，通过比较测试数据在不同类别模型下的压缩表示长度来预测标签。研究在合成和真实数据集上验证了ChaosComp的有效性，并强调其目标在于通过动力系统和压缩的视角重新诠释分类问题，而非追求最佳性能。

> **摘要翻译:** 我们提出了一种基于符号动力学和使用混沌映射的数据压缩的新型分类框架。其核心思想是通过对阈值化的实值训练数据生成符号序列，然后通过一维混沌映射演化来对每个类别进行建模。对于每个类别，我们计算符号模式（例如，第二返回映射的“00”、“01”、“10”和“11”）的转移概率，并聚合这些统计数据以形成一个类别特定的概率模型。在测试阶段，测试数据被阈值化和符号化，然后使用类别符号统计通过反向迭代（一种动态重建技术）进行编码。预测标签对应于产生最短压缩表示的类别，这表示在其各自混沌模型下最有效的符号编码。这种方法融合了动力系统、符号表示和基于压缩学习的概念。我们评估了所提出的方法：ChaosComp在合成数据集和真实世界数据集上的表现，与传统机器学习算法相比，显示出有竞争力的性能（例如，所提出方法在乳腺癌威斯康星数据集上的宏观F1分数=0.9531，在Seeds数据集上=0.9475，在Iris数据集上=0.8469等）。本研究的目标不是追求最先进的性能，而是通过动力系统和压缩的视角重新解释分类问题，这在学习理论和信息处理中是基础性的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [243] [Context-Adaptive Multi-Prompt LLM Embedding for Vision-Language Alignment](https://arxiv.org/abs/2508.02762)
> *上下文自适应多提示LLM嵌入用于视觉-语言对齐*

*Dahun Kim, Anelia Angelova* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-03**

**Keywords:** 视觉-语言对齐, 多提示嵌入, 对比学习, 语义表示, 自适应token

**Comment:** 

> **TL;DR:** 提出了一种上下文自适应多提示嵌入方法，通过引入多个结构化提示和自适应token来丰富视觉-语言对比学习中的语义表示，并在图像-文本和视频-文本检索基准上取得了持续改进。

**AI_Comments:** 该论文的创新点在于其提出的“上下文自适应多提示嵌入”方法，通过引入多个具有自适应token的结构化提示，有效地解决了传统视觉-语言模型中单一文本嵌入无法充分捕捉语义多样性的问题。这种多提示联合处理和融合的策略，结合多样性正则化和否定感知损失，显著提升了文本表示的丰富性和判别力，为视觉-语言对齐任务带来了新的思路和性能突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CLIP风格模型依赖于单一文本嵌入，限制了语义表示的丰富性，无法充分捕捉输入文本的多样语义方面。

**Method:** 提出上下文自适应多提示嵌入（Context-Adaptive Multi-Prompt Embedding）。该方法引入多个结构化提示，每个提示包含一个独特的自适应token，以捕获输入文本的不同语义方面。所有提示在一个前向传递中联合处理，生成的提示嵌入被组合成一个统一的文本表示，从而实现与视觉特征更丰富的对齐。为进一步促进语义多样性和表示质量，该方法还结合了多样性正则化损失和否定感知损失，以鼓励提示间的专业化并提高对比判别能力。

**Result:** 该方法在图像-文本和视频-文本检索基准上均取得了持续的改进。

**Conclusion:** 上下文自适应多提示嵌入方法通过丰富语义表示和增强对比判别能力，有效提升了视觉-语言对齐的效果，并在检索任务中展现出优越性。

> **ai_Abstract:** 该论文提出了一种名为“上下文自适应多提示嵌入”的新型方法，旨在增强视觉-语言对比学习中的语义表示。与传统单文本嵌入模型不同，该方法利用多个结构化提示，每个提示带有一个自适应token以捕捉文本的多样语义。这些提示嵌入被联合处理并组合成统一的文本表示，以实现更丰富的视觉对齐。此外，通过引入多样性正则化损失和否定感知损失，进一步提升了语义多样性和表示质量。实验结果表明，该方法在图像-文本和视频-文本检索任务上均实现了显著性能提升。

> **摘要翻译:** 我们提出了上下文自适应多提示嵌入，这是一种在视觉-语言对比学习中丰富语义表示的新方法。与依赖单一文本嵌入的标准CLIP风格模型不同，我们的方法引入了多个结构化提示，每个提示包含一个独特的自适应token，用于捕获输入文本的多种语义方面。我们在单个前向传递中联合处理所有提示。生成的提示嵌入被组合成一个统一的文本表示，从而实现与视觉特征更丰富的对齐。为了进一步促进语义多样性和表示质量，我们结合了多样性正则化损失和否定感知损失，鼓励提示间的专业化并提高对比判别能力。我们的方法在图像-文本和视频-文本检索基准上均取得了持续改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [262] [Efficient Generative Model Training via Embedded Representation Warmup](https://arxiv.org/abs/2504.10188)
> *通过嵌入表示预热实现高效生成模型训练*

*Deyuan Liu, Peng Sun, Xufeng Li, Tao Lin* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-02**

**Keywords:** 扩散模型, 生成模型, 训练加速, 表示学习, 嵌入表示预热 (ERW)谢

**Comment:** 

> **TL;DR:** 提出嵌入表示预热（ERW）框架，利用预训练高质量表示初始化扩散模型早期层，显著加速训练并提升性能，实现比SOTA快40倍的速度。

**AI_Comments:** 这篇论文通过识别扩散模型训练中的关键瓶颈——早期层表示学习效率低——并提出创新的嵌入表示预热（ERW）框架，有效地解决了训练效率和表示质量问题。其“即插即用”的特性增加了实用性，而40倍的训练加速是一个显著的进步，有望推动生成模型的发展和应用。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在生成高维数据方面表现出色，但在训练效率和表示质量方面不如自监督方法。主要瓶颈是训练过程中未能充分利用高质量、语义丰富的表示，这显著减缓了收敛速度。

**Method:** 提出嵌入表示预热（ERW）框架，该框架即插即用。在第一阶段，ERW模块作为预热，使用高质量的预训练表示初始化扩散模型的早期层。这减少了从头学习表示的负担。理论分析表明ERW的有效性取决于其在神经网络特定层（表示处理区域）的精确集成。

**Result:** 经验上，ERW方法在训练速度上比当前最先进的REPA方法快40倍。它不仅加速了训练收敛，还增强了表示质量。

**Conclusion:** ERW通过利用预训练表示预热扩散模型早期层，有效解决了扩散模型训练效率低和表示质量不足的问题，显著加速了训练并提升了性能。

> **ai_Abstract:** 本文提出嵌入表示预热（ERW）框架，旨在解决扩散模型训练效率低下和表示质量不高的问题。通过系统分析，作者发现早期层是表示学习的关键区域。ERW通过使用高质量的预训练表示初始化扩散模型的早期层，显著减少了从头学习的负担，从而加速了模型收敛并提升了性能。理论分析证实了ERW在特定神经网络层集成的有效性。实验结果表明，ERW在训练速度上比现有最佳方法REPA快40倍，并能提高表示质量。

> **摘要翻译:** 扩散模型在生成高维数据方面表现出色，但在训练效率和表示质量方面不如自监督方法。我们发现一个关键瓶颈：训练过程中未能充分利用高质量、语义丰富的表示，这显著减缓了收敛速度。我们的系统分析揭示了一个关键的表示处理区域——主要在早期层——在生成发生之前，语义和结构模式学习在此处进行。为了解决这个问题，我们提出了嵌入表示预热（ERW），一个即插即用的框架，其中在第一阶段，ERW模块作为预热，用高质量的预训练表示初始化扩散模型的早期层。这种预热最大限度地减少了从头学习表示的负担，从而加速了收敛并提升了性能。我们的理论分析表明，ERW的有效性取决于其精确集成到特定的神经网络层——被称为表示处理区域——模型主要在此处处理和转换特征表示以供后续生成。我们进一步证实，ERW不仅加速了训练收敛，还增强了表示质量：经验上，我们的方法比当前最先进的REPA方法实现了40倍的训练速度提升。代码可在https://github.com/LINs-lab/ERW获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [291] [Estimating Worst-Case Frontier Risks of Open-Weight LLMs](https://arxiv.org/abs/2508.03153)
> *评估开源大语言模型的最坏情况前沿风险*

*Eric Wallace, Olivia Watkins, Miles Wang, Kai Chen, Chris Koch* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 开源LLM, 前沿风险, 恶意微调, 生物风险, 网络安全

**Comment:** 

> **TL;DR:** 本文研究了开源大语言模型 gpt-oss 发布的最坏情况前沿风险。通过恶意微调（MFT）在生物学和网络安全领域最大化模型能力，并与现有模型进行比较。结果显示 MFT gpt-oss 表现不如顶尖闭源模型，对前沿能力的提升有限，支持了模型发布的决定。

**AI_Comments:** 该论文的创新点在于引入了“恶意微调（MFT）”这一新颖方法来主动评估开源大语言模型的潜在最坏情况风险，这对于AI安全领域是一个重要的贡献。通过模拟攻击场景来评估模型风险，为模型发布前的风险评估提供了实用的框架。其重要性在于为负责任的AI开发和部署提供了前瞻性的风险评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究开源大语言模型（gpt-oss）发布可能带来的最坏情况前沿风险，以指导模型发布决策并提供评估未来开源模型危害的方法。

**Method:** 引入恶意微调（MFT）方法，通过在生物学（威胁创建）和网络安全（CTF挑战）两个领域对 gpt-oss 进行微调，以最大化其潜在能力。在RL环境中使用网页浏览训练生物风险，在代理编码环境训练网络安全风险。将MFT模型与开源和闭源LLM进行前沿风险评估对比。

**Result:** 与前沿闭源模型（如OpenAI o3）相比，MFT gpt-oss 在生物风险和网络安全方面的表现不佳，未达到预备高能力水平。与开源模型相比，gpt-oss 可能略微增加了生物学能力，但并未实质性地推进前沿水平。

**Conclusion:** 研究结果支持了发布 gpt-oss 模型的决定。作者希望其恶意微调（MFT）方法能为评估未来开源模型发布可能造成的危害提供有用的指导。

> **ai_Abstract:** 本文通过引入恶意微调（MFT）方法，研究了开源大语言模型 gpt-oss 发布的最坏情况前沿风险。研究人员在生物学和网络安全领域对 gpt-oss 进行微调，以评估其潜在的恶意能力。结果显示，经过 MFT 的 gpt-oss 在这两个领域的表现均不如顶尖闭源模型，且对当前开源模型的前沿能力提升有限。这些发现支持了该模型的发布，并且该 MFT 方法有望为未来开源模型的风险评估提供指导。

> **摘要翻译:** 在本文中，我们研究了发布 gpt-oss 的最坏情况前沿风险。我们引入了恶意微调（MFT），我们试图通过在生物学和网络安全两个领域尽可能地微调 gpt-oss 来激发其最大能力。为了最大化生物风险（biorisk），我们策划了与威胁创建相关的任务，并在带有网页浏览的RL环境中训练 gpt-oss。为了最大化网络安全风险，我们在一个代理编码环境中训练 gpt-oss 来解决夺旗（CTF）挑战。我们将这些 MFT 模型与开放权重和闭源 LLM 在前沿风险评估上进行了比较。与前沿闭源模型相比，MFT gpt-oss 的表现不如 OpenAI o3，后者在生物风险和网络安全方面的能力低于“准备就绪高”水平。与开放权重模型相比，gpt-oss 可能会略微增加生物能力，但并未实质性地推进前沿。总而言之，这些结果促成了我们发布该模型的决定，我们希望我们的 MFT 方法可以作为评估未来开放权重版本危害的有用指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [299] [NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models](https://arxiv.org/abs/2504.14569)
> *NoWag：一个用于大型语言模型形状保持压缩的统一框架*

*Lawrence Liu, Inesh Chakrabarti, Yixiao Li, Mengdi Wang, Tuo Zhao, Lin F. Yang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 模型压缩, 零样本, 向量量化, 模型剪枝

**Comment:** 

> **TL;DR:** NoWag是一个统一的零样本形状保持压缩框架，用于大型语言模型。它在向量量化和非结构化/半结构化剪枝方面表现出色，优于或与现有技术竞争。

**AI_Comments:** NoWag框架的创新之处在于其作为统一的零样本形状保持压缩方法，适用于不同的压缩范式（如VQ和剪枝）。其重要性在于为大型语言模型在资源受限环境中的部署提供了高效的解决方案，并且其发现的压缩范式共性可能为未来的研究提供新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但计算和内存需求巨大，限制了它们在资源受限环境中的部署。

**Method:** 提出了NoWag（Normalized Weight and Activation Guided Compression），一个用于零样本形状保持压缩算法的统一框架。作者使用NoWag-VQ（用于向量量化）和NoWag-P（用于剪枝）两种流行的形状保持压缩形式，压缩了Llama-2 7B/13B/70B和Llama-3 8/70BB模型。

**Result:** NoWag-VQ显著优于最先进的零样本向量量化方法。NoWag-P与最先进的方法相比具有竞争力。

**Conclusion:** 这些结果表明这些压缩范式之间存在共性，这可以启发未来的工作。

> **ai_Abstract:** 本文提出了NoWag（Normalized Weight and Activation Guided Compression），一个统一的零样本形状保持压缩框架，旨在解决大型语言模型在资源受限环境中的部署问题。通过将NoWag应用于向量量化（NoWag-VQ）和剪枝（NoWag-P），并在Llama系列模型上进行测试，结果显示NoWag-VQ显著优于现有技术，NoWag-P也表现出竞争力，这揭示了不同压缩范式间的共通性。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但其巨大的计算和内存需求限制了它们在资源受限环境中的部署。为了解决这一挑战，我们提出了NoWag：（归一化权重和激活引导压缩），一个用于零样本形状保持压缩算法的统一框架。我们使用两种流行的形状保持压缩形式：向量量化NoWag-VQ（NoWag for Vector Quantization）和非结构化/半结构化剪枝NoWag-P（NoWag for Pruning），压缩了Llama-2 7B/13B/70B和Llama-3 8/70BB模型。我们发现NoWag-VQ显著优于最先进的零样本向量量化，而NoWag-P与最先进的方法相比具有竞争力。这些结果表明这些压缩范式之间存在共性，这可以启发未来的工作。我们的代码可在https://github.com/LawrenceRLiu/NoWag获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [331] [TAPAS: Fast and Automatic Derivation of Tensor Parallel Strategies for Large Neural Networks](https://arxiv.org/abs/2302.00247)
> *TAPAS：大型神经网络张量并行策略的快速自动推导*

*Ziji Shi, Le Jiang, Ang Wang, Jie Zhang, Chencan Wu, Yong Li, Xiaokui Xiao, Wei Lin, Jialin Li* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-08-05**

**Keywords:** 张量并行, 自动并行, 神经网络, 分布式训练, 搜索空间

**Comment:** Accepted by 54th International Conference on Parallel Processing
  (ICPP'25)

> **TL;DR:** TAPAS是一个用于大型神经网络的自动并行框架，它通过识别重复子结构来显著加速张量并行策略的搜索，其性能优于现有方法并媲美专家系统。

**AI_Comments:** TAPAS的创新之处在于其利用神经网络的重复子结构来优化张量并行策略的搜索过程，通过分治法显著缩小了搜索空间，从而实现了亚线性的复杂度。这极大地提升了自动并行系统的可扩展性和效率，对于大型神经网络的分布式训练具有重要意义，解决了现有方法在模型规模扩大时面临的瓶颈问题。

<details>
  <summary>Details</summary>

**Motivation:** 自动确定最优张量并行策略由于巨大的搜索空间（随模型大小和张量维度呈指数增长）而极具挑战性，这阻碍了自动并行系统在更大模型上的应用。

**Method:** TAPAS采用分治法，通过识别独特的子结构来消除冗余搜索工作，从而有效折叠搜索空间。

**Result:** TAPAS在各种模型上的搜索速度比最先进的自动并行框架快160倍，并且所推导策略的性能与专家设计的Megatron-LM库相比具有竞争力甚至更好。它以相对于模型大小的亚线性复杂度运行，使其成为训练大规模网络的可扩展解决方案。

**Conclusion:** TAPAS提供了一个可扩展且高效的解决方案，用于自动推导大型神经网络的张量并行策略，显著提升了搜索速度和策略性能。

> **ai_Abstract:** TAPAS是一个针对大型神经网络的自动并行框架，旨在解决张量并行策略搜索空间过大的问题。它利用神经网络中重复的子结构，通过分治法高效地折叠搜索空间，从而实现亚线性复杂度的运行。实验证明，TAPAS在搜索速度上显著优于现有框架，并且生成的策略性能可与专家级系统匹敌，为大规模神经网络的分布式训练提供了高效且可扩展的解决方案。

> **摘要翻译:** 张量并行是分布式训练大型神经网络的一项重要技术。然而，由于巨大的搜索空间（随模型大小和张量维度呈指数增长），自动确定最优张量并行策略极具挑战性。这阻碍了自动并行系统在更大模型上的应用。
我们观察到神经网络通常包含重复的子结构，并构建了一个名为TAPAS的自动并行框架，它消除了冗余的搜索工作。TAPAS采用分治法，通过识别独特的子结构来有效折叠搜索空间。因此，它以相对于模型大小的亚线性复杂度运行，使其成为训练大规模网络的可扩展解决方案。我们的评估表明，TAPAS在各种模型上的搜索速度比最先进的自动并行框架快160倍，并且所推导策略的性能与专家设计的Megatron-LM库相比具有竞争力甚至更好。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [350] [CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction](https://arxiv.org/abs/2508.03159)
> *CoTox：基于思维链的分子毒性推理与预测*

*Jueon Park, Yein Park, Minju Song, Soyon Park, Donghyeon Lee, Seungheun Baek, Jaewoo Kang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** CoTox, 分子毒性, 思维链, 大型语言模型, 药物开发

**Comment:** Under review

> **TL;DR:** CoTox是一个新颖的框架，它将大型语言模型（LLM）与思维链（CoT）推理相结合，用于多毒性预测。CoTox通过整合化学结构数据、生物通路和基因本体（GO）术语，生成可解释的毒性预测，并优于传统机器学习和深度学习模型，提高了药物开发的早期安全性评估。

**AI_Comments:** CoTox的创新之处在于将LLM的思维链推理能力与丰富的生物学背景知识（如生物通路和基因本体）相结合，显著提升了分子毒性预测的可解释性。通过引入IUPAC名称作为化学结构表示，CoTox有效地解决了LLM对SMILES理解的局限性，从而优化了模型的推理和预测性能。模拟细胞类型治疗并融入生物上下文进一步增强了模型预测结果的生理相关性。这项工作为早期药物开发中的毒性评估提供了一个更透明、更准确的工具，具有重要的实践意义，有望加速药物研发进程。

<details>
  <summary>Details</summary>

**Motivation:** 药物毒性是药物开发中的一个主要挑战。现有的机器学习模型在毒性预测方面有所改进，但它们对标注数据的依赖性以及缺乏可解释性限制了其适用性，尤其是在捕捉由复杂生物机制驱动的器官特异性毒性方面。虽然大型语言模型（LLM）通过逐步推理和文本数据整合提供了有前景的替代方案，但现有方法缺乏生物学背景和透明的推理过程。

**Method:** 我们提出了CoTox框架，它将大型语言模型（LLM）与思维链（CoT）推理相结合，用于多毒性预测。CoTox结合了化学结构数据、生物通路和基因本体（GO）术语，通过逐步推理生成可解释的毒性预测。研究发现，使用IUPAC名称表示化学结构比SMILES更能增强模型的推理能力和预测性能。为了演示其在药物开发中的实用性，我们模拟了相关细胞类型与药物的治疗，并将由此产生的生物学背景整合到CoTox框架中。

**Result:** 使用GPT-4o，CoTox在多毒性预测方面优于传统的机器学习和深度学习模型。研究还发现，使用IUPAC名称表示化学结构比SMILES更能增强LLM的推理能力并提高预测性能。通过模拟细胞类型治疗，CoTox能够生成与生理反应一致的毒性预测，并在案例研究中得到证实。

**Conclusion:** 基于LLM的框架在提高可解释性和支持早期药物安全评估方面具有巨大潜力。

> **ai_Abstract:** CoTox是一个新颖的框架，它将大型语言模型（LLM）与思维链（CoT）推理相结合，用于解决药物毒性预测中现有机器学习模型可解释性差和生物背景缺失的问题。该框架整合了化学结构、生物通路和基因本体（GO）术语，通过逐步推理生成可解释的多毒性预测。实验证明，CoTox（使用GPT-4o）在性能上超越了传统的机器学习和深度学习模型。研究还发现，使用IUPAC名称而非SMILES表示化学结构能显著提升LLM的推理和预测能力。通过模拟细胞处理并将生物背景融入框架，CoTox能生成与生理反应一致的毒性预测，展现了LLM在提高药物安全评估可解释性方面的巨大潜力。

> **摘要翻译:** 药物毒性仍然是药物开发中的一个主要挑战。最近的机器学习模型改进了计算机毒性预测，但它们对标注数据的依赖性和缺乏可解释性限制了其适用性。这限制了它们捕捉由复杂生物机制驱动的器官特异性毒性的能力。大型语言模型（LLM）通过逐步推理和文本数据整合提供了一种有前景的替代方案，但之前的方法缺乏生物学背景和透明的推理依据。
为了解决这个问题，我们提出了CoTox，一个将LLM与思维链（CoT）推理相结合的新颖框架，用于多毒性预测。CoTox结合了化学结构数据、生物通路和基因本体（GO）术语，通过逐步推理生成可解释的毒性预测。使用GPT-4o，我们表明CoTox优于传统的机器学习和深度学习模型。我们进一步检查了它在各种LLM上的性能，以确定CoTox在何处最有效。此外，我们发现用IUPAC名称表示化学结构（LLM比SMILES更容易理解）增强了模型的推理能力并提高了预测性能。为了证明其在药物开发中的实际效用，我们模拟了相关细胞类型与药物的治疗，并将由此产生的生物学背景整合到CoTox框架中。这种方法使CoTox能够生成与生理反应一致的毒性预测，如案例研究所示。这一结果突出了基于LLM的框架在提高可解释性和支持早期药物安全评估方面的潜力。本工作中使用的代码和提示可在https://github.com/dmis-lab/CoTox获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [360] [VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision](https://arxiv.org/abs/2508.03058)
> *VRPO：重新思考价值建模以实现噪声监督下鲁棒的强化学习训练*

*Dingwei Zhu, Shihan Dou, Zhiheng Xi, Senjie Jin, Guoqiang Zhang, Jiazheng Zhang, Junjie Ye, Mingxu Chai, Enyu Zhou, Ming Zhang, Caishuang Huang, Yunke Zhang, Yuran Wang, Tao Gui* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 人类反馈强化学习, 价值模型, 噪声监督, VRPO

**Comment:** 

> **TL;DR:** VRPO通过强化价值模型来提高噪声监督下RLHF的鲁棒性。

**AI_Comments:** 该论文的创新点在于重新审视并强调了价值模型在RLHF中对抗噪声监督的关键作用，而非仅仅关注奖励去噪。通过将价值模型从“被动预测器”转变为“主动调节器”，并引入具体的技术（辅助损失和变分信息瓶颈），VRPO提供了一个新颖且有效的解决方案，对提高RLHF在真实世界应用中的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习从人类反馈（RLHF）在真实世界设置中常受到噪声或不完美奖励监督的困扰，这损害了策略稳定性和泛化能力。这种噪声可能导致模型在优势估计时忽略关键词。现有工作侧重于奖励去噪或过滤不良数据，但往往忽视了价值模型在策略优化中的关键作用。

**Method:** 提出VRPO，一个以价值为中心的框架，用于在噪声监督下进行鲁棒的PPO训练。VRPO结合了两个核心设计：(1) 一个由冻结语言模型的熵和困惑度引导的辅助损失；(2) 一个变分信息瓶颈。这些机制增强了价值模型过滤噪声和在优势估计期间从上下文中捕获关键词的能力，将其从一个被动预测器转变为噪声的主动调节器。

**Result:** 在数学推理、科学问答和多轮对话任务上，在基于规则和基于模型的噪声奖励下，VRPO始终优于PPO和GRPO基线。

**Conclusion:** 研究结果强调了价值模型在RLHF中常被忽视的重要性，并为在噪声真实世界环境中进行鲁棒的策略优化提供了一种原则性且实用的方法。

> **ai_Abstract:** 该论文提出VRPO框架，旨在解决RLHF在噪声监督下策略不稳定和泛化能力差的问题。作者强调了强大价值模型在吸收不稳定信号和实现可靠优势估计中的关键作用。VRPO通过引入辅助损失（基于语言模型熵和困惑度）和变分信息瓶颈，增强价值模型过滤噪声和捕获关键信息的能力，使其成为噪声的主动调节器。实验证明，VRPO在多种任务和噪声奖励类型下均优于现有基线，突出了价值模型在RLHF中被忽视的重要性，并提供了一种在噪声环境中实现鲁棒策略优化的实用方法。

> **摘要翻译:** 人类反馈强化学习（RLHF）在真实世界环境中常受到噪声或不完美奖励监督的困扰，这损害了策略的稳定性和泛化能力。这种噪声可能导致模型在优势估计期间忽视关键词。虽然现有工作侧重于奖励去噪或过滤不良数据，但它们往往忽视了价值模型在策略优化中的关键作用。在这项工作中，我们表明一个强大的价值模型对于通过吸收不稳定信号和实现更可靠的优势估计来减轻噪声至关重要。我们提出了VRPO，一个以价值为中心的框架，用于在噪声监督下进行鲁棒的PPO训练。VRPO结合了两个核心设计：（1）一个由冻结语言模型的熵和困惑度引导的辅助损失，以及（2）一个变分信息瓶颈。这些机制增强了价值模型过滤噪声和在优势估计期间从上下文中捕获关键词的能力，将其从一个被动预测器转变为噪声的主动调节器。在数学推理、科学问答和多轮对话任务上，在基于规则和基于模型的噪声奖励下进行的实验表明，VRPO始终优于PPO和GRPO基线。我们的发现强调了价值模型在RLHF中常被忽视的重要性，并为在噪声真实世界环境中进行鲁棒的策略优化提供了一种原则性且实用的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [370] [GRILL: Gradient Signal Restoration in Ill-Conditioned Layers to Enhance Adversarial Attacks on Autoencoders](https://arxiv.org/abs/2505.03646)
> *GRILL：在病态层中恢复梯度信号以增强对自编码器的对抗性攻击*

*Chethan Krishnamurthy Ramanaik, Arjun Roy, Tobias Callies, Eirini Ntoutsi* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 对抗性攻击, 自编码器, 梯度消失, 鲁棒性, GRILL

**Comment:** 

> **TL;DR:** GRILL通过恢复自编码器病态层中的梯度信号，显著增强了对抗性攻击的有效性，从而更严格地评估自编码器的鲁棒性。

**AI_Comments:** GRILL的创新点在于识别并解决了自编码器对抗性攻击中梯度消失这一核心问题，通过局部梯度恢复，显著提升了攻击效果，为自编码器的鲁棒性评估提供了更强的工具，有助于推动该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有攻击算法在优化自编码器对抗性扰动时常停留在次优攻击，因为梯度在病态层中反向传播时会消失，导致梯度信号减弱。对抗性攻击对自编码器的鲁棒性研究相对不足。

**Method:** 本文引入了GRILL技术，该技术在自编码器的病态层中局部恢复梯度信号，从而实现更有效的范数有界对抗性攻击。

**Result:** 通过对不同架构的流行自编码器进行广泛实验，包括样本特定和通用攻击设置，以及标准和自适应攻击设置，结果表明GRILL显著增加了对抗性攻击的有效性。

**Conclusion:** GRILL通过解决自编码器病态层中梯度消失的问题，有效提升了对抗性攻击的效果，从而能够对自编码器的对抗性鲁棒性进行更严格、更准确的评估。

> **ai_Abstract:** 本文提出GRILL技术，旨在解决自编码器对抗性攻击中梯度在病态层消失的问题。通过局部恢复梯度信号，GRILL显著增强了范数有界对抗性攻击的有效性，从而能够对自编码器的对抗性鲁棒性进行更严格、更准确的评估。

> **摘要翻译:** 深度自编码器（AEs）的对抗性鲁棒性仍然相对未被探索，尽管其不可逆性质带来了独特的挑战。现有攻击算法在优化难以察觉的、范数有界的对抗性扰动以最大化AEs输出损伤时，往往停留在次优攻击。我们观察到，对抗性损失梯度在通过病态层反向传播时会消失。这个问题源于这些层雅可比矩阵中接近零的奇异值，这在优化过程中削弱了梯度信号。我们引入了GRILL，一种在病态层中局部恢复梯度信号的技术，从而实现更有效的范数有界攻击。通过对流行AEs的不同架构进行广泛实验，包括样本特定和通用攻击设置，以及标准和自适应攻击设置，我们表明我们的方法显著增加了我们对抗性攻击的有效性，从而能够更严格地评估AE鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [381] [Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization](https://arxiv.org/abs/2508.02834)
> *B细胞进化学习：基于在线优化的自适应多专家扩散模型用于抗体设计*

*Hanqi Feng, Peng Qiu, Mengchun Zhang, Yiran Tao, You Fan, Jingtao Xu, Barnabas Poczos* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 抗体设计, 扩散模型, B细胞进化, 在线优化, 多专家系统

**Comment:** 

> **TL;DR:** 受B细胞进化启发，提出一种新的自适应多专家扩散模型，通过在线优化为每个抗原定制抗体设计策略，显著提高抗体质量和泛化能力。

**AI_Comments:** 这项工作通过引入受B细胞进化启发的自适应多专家系统和在线优化，克服了现有扩散模型在抗体设计中缺乏特异性适应能力的局限。其创新之处在于将生物学原理与物理领域知识相结合，实现了对每个抗原的个性化抗体设计，显著提升了抗体的治疗潜力。该方法为迭代精炼和精确抗体设计开辟了新途径，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型在抗体设计中采用统一的生成策略，无法适应每个抗原的独特需求。

**Method:** 受B细胞亲和力成熟启发，提出了一个生物学驱动的框架，该框架在在线元学习系统中利用基于物理的领域知识。该方法采用多个专业专家（范德华力、分子识别、能量平衡和界面几何），其参数在生成过程中根据迭代反馈演化，模仿自然抗体精炼周期，从而为每个靶点发现个性化优化策略。

**Result:** 1) 无需预训练即可发现针对不同抗原类别的最佳SE(3)等变引导策略，在优化过程中保持分子对称性；2) 通过靶点特异性适应显著增强热点覆盖和界面质量，实现治疗性抗体特有的平衡多目标优化；3) 建立了迭代精炼范式，每个抗体-抗原系统通过在线评估学习其独特的优化配置文件；4) 有效泛化到从小表位到大蛋白界面的各种设计挑战，从而实现针对个体靶点的精确设计。

**Conclusion:** 该研究提出了一个新颖的、受生物学启发的抗体设计框架，通过在线优化和多专家自适应策略克服了现有扩散模型的局限性，实现了更高效、更精确的抗体设计，并为迭代精炼建立了新范式。

> **ai_Abstract:** 本研究提出了一种受B细胞进化启发的自适应多专家扩散模型，用于抗体设计。该模型通过在线元学习系统整合物理领域知识和多个专业专家，使生成策略能根据迭代反馈为每个抗原定制优化。实验证明，该方法无需预训练即可为不同抗原发现最佳SE(3)等变引导策略，显著提高抗体热点覆盖和界面质量，实现平衡多目标优化，并能有效泛化至多种设计挑战，为精确抗体设计提供了新范式。

> **摘要翻译:** 扩散模型在抗体设计方面展现出卓越潜力，然而现有方法采用统一的生成策略，无法适应每个抗原的独特需求。受B细胞亲和力成熟（抗体通过平衡亲和力、稳定性、自回避的多目标优化而进化）的启发，我们提出了第一个生物学驱动的框架，该框架在在线元学习系统中利用基于物理的领域知识。我们的方法采用多个专业专家（范德华力、分子识别、能量平衡和界面几何），其参数在生成过程中根据迭代反馈演化，模仿自然抗体精炼周期。这种自适应引导取代了固定协议，为每个靶点发现个性化优化策略。我们的实验表明，该方法：(1) 无需预训练即可发现针对不同抗原类别的最佳SE(3)等变引导策略，在优化过程中保持分子对称性；(2) 通过靶点特异性适应显著增强热点覆盖和界面质量，实现治疗性抗体特有的平衡多目标优化；(3) 建立了迭代精炼范式，每个抗体-抗原系统通过在线评估学习其独特的优化配置文件；(4) 有效泛化到从小表位到大蛋白界面的各种设计挑战，从而实现针对个体靶点的精确设计。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [416] [Understanding the Embedding Models on Hyper-relational Knowledge Graph](https://arxiv.org/abs/2508.03280)
> *理解超关系知识图谱上的嵌入模型*

*Yubo Wang, Shimin Di, Zhili Wang, Haoyang Li, Fei Teng, Hao Xin, Lei Chen* | **Category: cs.LG, cs.CL, cs.SI** | **Updated: 2025-08-05**

**Keywords:** 超关系知识图谱, 知识图谱嵌入, FormerGNN, 图神经网络, 信息整合

**Comment:** Accepted by CIKM 2025

> **TL;DR:** 本文研究超关系知识图谱（HKG）嵌入模型性能的来源，发现一些经典KGE模型表现相当，并揭示了现有方法的局限性。为解决这些问题，提出了新型FormerGNN框架，并在实验中取得了优异表现。

**AI_Comments:** 本文深入探讨了超关系知识图谱嵌入模型性能的内在机制，揭示了现有方法的局限性，如拓扑改变和信息压缩。其创新之处在于不仅分析了问题，还提出了一个新颖的FormerGNN框架，该框架通过独特的设计解决了现有模型在拓扑保留、长距离依赖捕获和信息整合方面的痛点。这对于推动HKGE领域的研究具有重要意义，为未来HKGE模型的设计提供了宝贵的见解和方向。

<details>
  <summary>Details</summary>

**Motivation:** 超关系知识图谱（HKG）嵌入模型（HKGE）的性能表现优异，但其性能究竟是来源于基础知识图谱嵌入（KGE）模型还是特殊设计的扩展模块尚不明确。此外，现有HKGE模型在捕获图的长距离依赖或整合主三元组与限定词信息时存在信息压缩问题或不足。

**Method:** 本文通过三种分解方法将超关系知识图谱（HKG）数据转换为传统知识图谱（KG）格式，并评估了多个经典KGE模型在HKG上的性能。在此基础上，提出了FormerGNN框架，该框架采用限定词整合器以保留原始HKG拓扑，使用基于GNN的图编码器捕获图的长距离依赖，并改进了主三元组和限定词信息的整合方法以缓解信息压缩问题。

**Result:** 研究结果表明，一些经典KGE模型可以达到与HKGE模型相当的性能。分解方法会改变原始HKG拓扑并未能完全保留HKG信息。现有HKGE模型在捕获图的长距离依赖方面存在不足，或因信息压缩问题难以整合主三元组和限定词信息。提出的FormerGNN框架在实验中优于现有HKGE模型。

**Conclusion:** 本研究表明，超关系知识图谱嵌入模型的性能来源复杂，经典KGE模型在特定条件下可表现良好，但现有HKGE模型在处理拓扑和信息整合方面仍有改进空间。提出的FormerGNN框架通过有效解决这些问题，为未来的HKGE研究提供了新的方向和更优的解决方案。

> **ai_Abstract:** 本文深入探究了超关系知识图谱（HKG）嵌入模型（HKGE）的性能来源。研究发现，通过将HKG分解为传统知识图谱（KG）格式并评估经典KGE模型，一些经典KGE模型能达到与HKGE模型相当的性能。进一步分析揭示，现有分解方法存在改变HKG拓扑和信息丢失的问题，且当前HKGE模型在捕获长距离依赖或整合主三元组与限定词信息方面表现不足。为解决这些局限性，本文提出了FormerGNN框架，该框架通过限定词整合器保留原始HKG拓扑，利用GNN编码器捕获长距离依赖，并优化信息整合以缓解压缩问题。实验证明FormerGNN优于现有HKGE模型。

> **摘要翻译:** 最近，超关系知识图谱（HKGs）被提出作为传统知识图谱（KGs）的扩展，以更好地表示带有额外限定词的真实世界事实。因此，研究人员试图通过设计额外的限定词处理模块来使经典的知识图谱嵌入（KGE）模型适应HKGs。然而，目前尚不清楚超关系KGE（HKGE）模型的卓越性能是源于其基础KGE模型还是特殊设计的扩展模块。因此，在本文中，我们数据层面地使用三种分解方法将HKGs转换为KG格式，然后评估了几个经典KGE模型在HKGs上的性能。我们的结果表明，一些KGE模型达到了与HKGE模型相当的性能。经过进一步分析，我们发现分解方法改变了原始HKG拓扑，并且未能完全保留HKG信息。此外，我们观察到当前的HKGE模型在捕获图的长距离依赖方面不足，或者由于信息压缩问题难以整合主三元组和限定词信息。为了进一步证明我们的发现并为未来的HKGE研究提供潜在方向，我们提出了FormerGNN框架。该框架采用限定词整合器来保留原始HKG拓扑，并使用基于GNN的图编码器来捕获图的长距离依赖，随后通过改进的方法整合主三元组和限定词信息以缓解压缩问题。我们的实验结果表明FormerGNN优于现有HKGE模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [425] [Out-of-Context Relational Reasoning in Large Language Models](https://arxiv.org/abs/2503.10408)
> *大型语言模型中的上下文外关系推理*

*Jonathan Shaki, Emanuele La Malfa, Michael Wooldridge, Sarit Kraus* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 上下文外推理, 二元关系, 表示学习, 推理能力

**Comment:** 

> **TL;DR:** 本研究探讨了大型语言模型在仅通过学习新引入的token表示来对二元关系进行上下文外推理的能力，发现LLMs表现优于随机，但仍远未达到完美，即使在相对简单的任务上。它们能编码有用信息并根据任务排列嵌入。

**AI_Comments:** 这项研究通过将二元关系推理任务从高阶复杂性中分离出来，为理解LLM的上下文外学习能力提供了一个更清晰的视角。其创新点在于专注于基础的二元关系和新token表示的学习，这有助于更细致地分析LLM的推理机制。虽然结果显示LLM仍有不足，但揭示了它们能编码有用信息，这对未来提升LLM的推理能力具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）基准测试大多侧重于高阶任务，这使得解释LLM在上下文外学习中的成功或失败变得困难。本研究旨在探究LLM在二元关系上进行上下文外推理的能力。

**Method:** 研究通过让大型语言模型仅学习新引入token的表示来考察其对二元关系进行上下文外推理的能力。实验聚焦于等式（=）、不等式（<）和包含（⊂）等二元关系，以及它们满足的性质，如自反性、对称性、传递性，并考虑逻辑复杂性（例如，推理“跳跃”的数量）。

**Result:** 实验结果显示，大型语言模型在二元关系推理任务上取得了优于随机的准确率，但即使在相对简单的任务上，其表现仍远未达到完美。分析学习到的表示表明，LLM能够直接编码有用信息，并根据任务排列嵌入。

**Conclusion:** 大型语言模型在二元关系上的上下文外推理能力虽优于随机，但仍有显著提升空间。LLMs能够有效地编码和组织任务相关的有用信息。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）在上下文外对二元关系进行推理的能力，这与现有关注高阶任务的研究不同。通过让LLM学习新token的表示，并在等式、不等式和包含等关系上进行实验，结果显示LLM的表现优于随机，但在简单任务上仍不完美。研究还发现LLM能够有效地编码和组织任务相关的有用信息。

> **摘要翻译:** 二元关系，例如等式，是基本的数学概念，它们隐式或显式地出现在大多数大型语言模型（LLM）的基准测试中。文献中最近的一个趋势是在上下文外学习中对LLM进行基准测试，其中数据并非在提示中呈现，而仅在模型训练期间出现。然而，现有工作大多侧重于高阶任务，这使得解释成功或失败变得困难。在这项工作中，我们研究了LLM通过仅学习新引入token的表示，在二元关系上进行上下文外推理的能力。我们的实验侧重于等式（=）、不等式（<）和包含（⊂）以及它们满足的性质，例如自反性、对称性、传递性，以及逻辑复杂性（例如，推理“跳跃”的数量）。我们表明，LLM实现了优于随机的准确率，但即使在涉及二元关系的相对简单的推理任务上，它们仍然远未达到完美。我们分析了学习到的表示，并表明LLM直接编码了有用信息，根据任务排列嵌入。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [436] [Beyond Least Squares: Robust Regression Transformer (R2T)](https://arxiv.org/abs/2508.02874)
> *超越最小二乘：鲁棒回归变换器 (R2T)*

*Roman Gutierrez, Tony Kai Tang, Isabel Gutierrez* | **Category: cs.LG, cs.AI, stat.ML, 68T30, 65D10, 62J02, 68T07, 62F35, 62J02, I.2.6; G.1.2; G.3** | **Updated: 2025-08-04**

**Keywords:** 鲁棒回归, 混合神经符号, Transformer, 非对称噪声, R2T

**Comment:** 10 pages, 4 figures, 1 table

> **TL;DR:** 针对非对称结构噪声，本文提出了一种混合神经符号架构（R2T），通过学习符号拟合显著提高了回归精度，超越了传统最小二乘和鲁棒回归方法。

**AI_Comments:** 该论文的创新点在于提出了一个混合神经符号架构，将深度学习的序列处理能力与符号回归的可解释性及鲁棒性相结合。这种方法特别适用于处理非对称结构噪声，弥补了传统回归方法的不足。其在合成数据上取得的显著性能提升表明了该架构的潜力，尤其是在可穿戴设备数据等噪声复杂的实际应用中。

<details>
  <summary>Details</summary>

**Motivation:** 传统的最小二乘优化在存在非对称结构噪声时表现不佳，而鲁棒回归技术也未能有效解决此问题。

**Method:** 本文提出了一种混合神经符号架构，其中一个Transformer编码器处理数值序列，一个压缩神经网络预测符号参数，一个固定的符号方程重构原始序列。训练目标是在添加非对称结构噪声后恢复原始序列，通过神经参数估计指导学习符号拟合。

**Result:** 该模型在合成可穿戴数据上实现了6e-6到3.5e-5的回归MSE中位数，比普通最小二乘拟合和Huber损失或SoftL1等鲁棒回归技术提高了10-300倍。

**Conclusion:** R2T模型在处理非对称结构噪声方面表现出卓越的鲁棒性，显著优于传统的最小二乘和现有的鲁棒回归技术。

> **ai_Abstract:** 本文提出了一种名为鲁棒回归变换器（R2T）的混合神经符号架构，旨在解决传统最小二乘和现有鲁棒回归方法在处理非对称结构噪声时的局限性。R2T结合了Transformer编码器、压缩神经网络和固定符号方程，通过学习由神经参数估计指导的符号拟合来恢复受噪声污染的序列。在合成可穿戴数据上的实验结果表明，R2T在回归MSE方面比现有技术有显著的10-300倍提升。

> **摘要翻译:** 鲁棒回归技术依赖于最小二乘优化，这种方法对于高斯噪声表现良好，但在存在非对称结构噪声时会失效。我们提出了一种混合神经符号架构，其中一个Transformer编码器处理数值序列，一个压缩神经网络预测符号参数，一个固定的符号方程重构原始序列。使用合成数据，训练目标是在添加非对称结构噪声后恢复原始序列，通过神经参数估计指导有效地学习符号拟合。我们的模型在合成可穿戴数据上实现了6e-6到3.5e-5的回归MSE中位数，与普通最小二乘拟合以及Huber损失或SoftL1等鲁棒回归技术相比，提高了10-300倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [P3SL: Personalized Privacy-Preserving Split Learning on Heterogeneous Edge Devices](https://arxiv.org/abs/2507.17228)
> *P3SL：异构边缘设备上的个性化隐私保护分层学习*

*Wei Fan, JinYi Yoon, Xiaochang Li, Huajie Shao, Bo Ji* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-08-05**

**Keywords:** 分层学习, 隐私保护, 异构边缘设备, 个性化, 双层优化

**Comment:** Accepted as invited paper in The 34th International Conference on
  Computer Communications and Networks (ICCCN 2025)

> **TL;DR:** P3SL是一个针对异构边缘设备的个性化隐私保护分层学习框架，通过个性化流水线和双层优化，允许客户端在不共享敏感信息的情况下确定最佳分割点，平衡能耗和隐私，同时保持高模型精度。

**AI_Comments:** P3SL的创新之处在于它首次将个性化隐私保护和本地模型定制引入分层学习，并通过双层优化技术，允许客户端在不泄露敏感信息的前提下自主决定最优分割点，有效解决了异构边缘设备环境下的挑战。这对于资源受限且对隐私有不同需求的设备参与分布式AI训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分层学习（SL）框架在异构边缘设备环境中面临挑战，特别是忽略了设备的个性化隐私需求和在不同环境条件下的本地模型定制，尽管它们优化了不同资源限制下的分割点。

**Method:** 本文提出了P3SL框架，其核心贡献有两方面：1) 设计个性化顺序分层学习流水线，允许每个客户端定制隐私保护并维护个性化本地模型；2) 采用双层优化技术，使客户端能够在不与服务器共享敏感信息的情况下，确定自己的最佳个性化分割点，从而平衡能耗和隐私泄露风险。

**Result:** P3SL在由4台Jetson Nano P3450、2台树莓派和1台笔记本电脑共7台设备组成的测试平台上进行了实现和评估，使用了多样化的模型架构和数据集，并在不同环境条件下进行了测试，旨在平衡能耗和隐私泄露风险，同时保持高模型精度。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了P3SL，一个针对异构边缘设备的个性化隐私保护分层学习框架，旨在解决现有分层学习在异构环境中忽视个性化隐私需求和本地模型定制的问题。P3SL通过设计个性化顺序分层学习流水线，允许客户端定制隐私保护和本地模型；并采用双层优化技术，使客户端无需共享敏感信息即可确定最佳分割点，从而平衡能耗和隐私泄露风险，同时保持高模型精度。该框架已在包含多种设备的测试平台上进行了实现和评估。

> **摘要翻译:** 分层学习（SL）是一种新兴的隐私保护机器学习技术，通过将模型划分为客户端和服务器端子模型，使资源受限的边缘设备能够参与模型训练。虽然SL减少了边缘设备的计算开销，但在计算资源、通信能力、环境条件和隐私要求各不相同的异构环境中，它面临着重大挑战。尽管最近的研究探索了针对不同资源限制优化分割点的异构SL框架，但它们往往忽略了在不同环境条件下的个性化隐私要求和本地模型定制。为了解决这些限制，我们提出了P3SL，一个专为异构、资源受限的边缘设备系统设计的个性化隐私保护分层学习框架。这项工作的关键贡献有两方面。首先，我们设计了一个个性化顺序分层学习流水线，允许每个客户端实现定制的隐私保护，并根据其计算资源、环境条件和隐私需求维护个性化的本地模型。其次，我们采用了一种双层优化技术，使客户端能够在不与服务器共享私有敏感信息（即计算资源、环境条件、隐私要求）的情况下，确定自己的最佳个性化分割点。这种方法在保持高模型精度的同时，平衡了能耗和隐私泄露风险。我们在一个由7台设备组成的测试平台上实现了P3SL并进行了评估，其中包括4台Jetson Nano P3450设备、2台树莓派和1台笔记本电脑，在不同的环境条件下使用了多样化的模型架构和数据集。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [439] [Neural Networks with Orthogonal Jacobian](https://arxiv.org/abs/2508.02882)
> *正交雅可比神经网络*

*Alex Massucco, Davide Murari, Carola-Bibiane Schönlieb* | **Category: cs.LG, cs.NA, math.NA** | **Updated: 2025-08-04**

**Keywords:** 神经网络, 正交雅可比, 梯度消失, 动态等距, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种统一的数学框架，用于构建输入到输出雅可比矩阵几乎处处正交的深度神经网络，有效解决了深度网络训练中的梯度消失/爆炸问题，并提供了新的网络设计，实现了稳定的训练和有竞争力的性能。

**AI_Comments:** 本文的创新之处在于提出了一个统一的数学框架，能够构建雅可比矩阵精确正交的深度神经网络，从而从根本上解决了梯度不稳定性问题。这一方法不仅涵盖了现有的一些有效策略，更重要的是，它开辟了新的网络设计路径，例如在不依赖传统残差连接的情况下实现与残差网络相当的训练稳定性，这对于未来深度学习架构的探索具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 非常深的神经网络通过提取丰富、分层的特征实现了最先进的性能，但其训练常受梯度消失或爆炸问题的阻碍。

**Method:** 本文提出了一个统一的数学框架，描述了一大类非线性前馈和残差网络，这些网络的输入到输出雅可比矩阵几乎处处精确正交。此外，还将分析扩展到雅可比矩阵表示部分等距的网络。

**Result:** 所提出的网络实现了完美的动态等距，即使非常深也能高效训练。该公式不仅包含了标准架构作为特例，还产生了不需要传统跳跃连接的新设计，且训练能力与残差网络相当。实验证明，初始化时的完美雅可比正交性足以稳定训练并获得有竞争力的性能。与通过正则化保持雅可比正交性的网络相比，结果具有可比性。广义模型也保持了良好的可训练性。

**Conclusion:** 通过引入雅可比矩阵几乎处处精确正交的神经网络，可以有效解决深度网络训练中的梯度消失/爆炸问题，实现稳定的训练和良好的性能，并为深度网络设计提供了新的思路。

> **ai_Abstract:** 本文提出了一种统一的数学框架，用于设计和分析具有精确正交雅可比矩阵的深度神经网络。该方法旨在解决深度网络训练中常见的梯度消失或爆炸问题，通过强制网络实现完美的动态等距，即使在很深的层数下也能保持高效和稳定的训练。研究不仅涵盖了现有架构，还引入了无需传统跳跃连接的新型网络设计，其训练能力与残差网络相当。实验结果验证了初始化时雅可比正交性对训练稳定性和性能的重要性，并表明该方法与正则化方法效果相当。此外，该框架还扩展到包含部分等距雅可比的广义模型，并证明其保持了良好的可训练性。

> **摘要翻译:** 非常深的神经网络通过提取丰富、分层的特征实现了最先进的性能。然而，通过反向传播训练它们常常受到梯度消失或爆炸的阻碍。现有的补救措施，如正交或方差保持初始化以及残差架构，允许更稳定的梯度传播和更深模型的训练。在这项工作中，我们引入了一个统一的数学框架，描述了一大类非线性前馈和残差网络，其输入到输出的雅可比矩阵几乎处处精确正交。这种约束迫使生成的网络实现完美的动态等距，并且尽管非常深也能高效训练。我们的公式不仅将标准架构作为特例恢复，而且还产生了新的设计，这些设计在不依赖传统跳跃连接的情况下，与残差网络的训练能力相匹配。我们提供了实验证据，表明初始化时的完美雅可比正交性足以稳定训练并实现有竞争力的性能。我们将这种策略与通过正则化保持雅可比正交性的网络进行比较，并获得了可比的结果。我们进一步将分析扩展到一类由具有正交雅可比的网络很好地近似的网络，并引入了雅可比表示部分等距的网络。这些广义模型随后被证明保持了有利的可训练性特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [CauKer: classification time series foundation models can be pretrained on synthetic data only](https://arxiv.org/abs/2508.02879)
> *CauKer：分类时间序列基础模型可仅在合成数据上进行预训练*

*Shifeng Xie, Vasilii Feofanov, Marius Alonso, Ambroise Odonnat, Jianfeng Zhang, Themis Palpanas, Ievgen Redko* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 时间序列基础模型, 合成数据, 预训练, CauKer, 扩展性

**Comment:** 

> **TL;DR:** CauKer提出了一种生成合成时间序列数据的方法，用于高效预训练时间序列基础模型，解决了真实数据预训练成本高的问题，并展示了在模型容量和数据集大小上的良好扩展性。

**AI_Comments:** 这项研究的创新之处在于提出了一种有效生成高质量合成时间序列数据的方法，从而解决了时间序列基础模型预训练中对昂贵真实数据依赖的问题。其重要性在于，通过使用合成数据进行预训练，可以显著降低计算成本和数据收集/标注的复杂性，并展示了更好的扩展性，这对于推动TSFMs的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列基础模型（TSFMs）的预训练通常需要大量且精心策划的真实世界序列数据，这导致计算成本高昂。为了实现TSFMs的样本高效预训练，本文提出了解决方案。

**Method:** 本文提出了CauKer算法，它结合了高斯过程（GP）核组合和结构因果模型（SCM），以生成多样化、因果一致的合成时间序列数据，这些数据具有真实的趋势、季节性和非线性交互。CauKer旨在为具有不同架构和预训练方法的分类TSFMs提供样本高效的预训练数据。

**Result:** 实验表明，使用CauKer生成的数据集在数据集大小（1万到1千万样本）和模型容量（100万到7.83亿参数）方面表现出清晰的扩展规律，这与真实世界数据集不规则的扩展行为形成对比。

**Conclusion:** CauKer证明了仅使用合成数据预训练时间序列基础模型是可行的，并且能够实现样本高效的预训练，同时在扩展性方面优于真实数据集。

> **ai_Abstract:** 本文提出了一种名为CauKer的新算法，旨在解决时间序列基础模型（TSFMs）预训练对大量真实数据依赖导致的高成本问题。CauKer通过结合高斯过程核组合和结构因果模型，生成多样化且因果一致的合成时间序列数据，这些数据具有真实的趋势、季节性和非线性交互。研究表明，使用CauKer生成的合成数据可以实现最先进分类TSFMs的样本高效预训练。此外，与真实数据集不同，CauKer生成的数据集在数据集大小和模型容量上表现出清晰的扩展规律。

> **摘要翻译:** 时间序列基础模型（TSFMs）由于其强大的零样本能力和广泛的实际应用，最近受到了广泛关注。此类模型通常需要在大规模、精心策划的真实世界序列集合上进行计算成本高昂的预训练。为了实现TSFMs的样本高效预训练，我们提出了CauKer，这是一种新颖的算法，旨在生成多样化、因果一致的合成时间序列，具有真实的趋势、季节性和非线性交互。CauKer结合了高斯过程（GP）核组合与结构因果模型（SCM），以生成数据，用于对具有不同架构和遵循不同预训练方法的最先进分类TSFMs进行样本高效的预训练。此外，我们的实验表明，CauKer生成的数据集在数据集大小（1万到1千万样本）和模型容量（100万到7.83亿参数）方面表现出清晰的扩展规律，这与真实世界数据集表现出的不规则扩展行为不同。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [Evaluating LLMs on Real-World Forecasting Against Expert Forecasters](https://arxiv.org/abs/2507.04562)
> *评估大型语言模型在真实世界预测中与专家预测员的表现*

*Janna Lu* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 预测, 专家预测员, 布里尔分数, Metaculus

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型在真实世界预测任务中的表现，发现它们虽然超越了普通人群，但仍显著低于专家预测员。

**AI_Comments:** 这篇论文评估了大型语言模型在真实世界预测中的实际能力，填补了该领域研究的空白。其重要性在于明确了当前LLMs在预测任务上的局限性，指出了LLMs在面对需要深刻理解和专业判断的复杂预测时，仍无法替代人类专家。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多种任务中表现出色，但它们预测未来事件的能力仍未得到充分研究。一年前，大型语言模型在准确性上远不及人类群体，因此有必要评估当前最先进的LLMs的预测能力。

**Method:** 研究评估了最先进的大型语言模型在来自Metaculus的464个预测问题上的表现，并将其性能与顶级预测员进行比较。

**Result:** 前沿模型获得了表面上超越人类群体的布里尔分数，但仍显著低于专家群体。

**Conclusion:** 大型语言模型在真实世界预测中虽然有所进步，但与顶级人类专家相比仍有显著差距。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在真实世界预测任务中的表现。通过在Metaculus的464个预测问题上测试最先进的LLMs，并将其结果与人类群体和专家预测员进行比较，研究发现LLMs的预测能力虽然优于普通人群，但与顶级专家相比仍有明显不足。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中都展现出卓越的能力，但它们预测未来事件的能力仍未得到充分研究。一年前，大型语言模型在准确性上难以接近人类群体的水平。我评估了最先进的LLMs在Metaculus的464个预测问题上的表现，并将其性能与顶级预测员进行了比较。前沿模型获得了表面上超越人类群体的布里尔分数，但仍显著低于专家群体。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [489] [Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling](https://arxiv.org/abs/2508.02749)
> *在路面劣化建模中考虑路网空间结构*

*Lu Gao, Ke Yu, Pan Lu* | **Category: cs.LG** | **Updated: 2025-08-02**

**Keywords:** 路面劣化建模, 空间结构, 图神经网络, 预测性能, 路网

**Comment:** 

> **TL;DR:** 本研究通过图神经网络（GNN）将路网的空间依赖性纳入路面劣化建模中，结果表明考虑空间关系可以提高路面劣化预测模型的性能。

**AI_Comments:** 本研究的创新之处在于将图神经网络（GNN）应用于路面劣化建模，以有效利用路网的空间结构信息。这为路面管理和维护决策提供了更准确的预测能力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 路面劣化建模对于提供路网未来状态信息和确定预防性维护或修复处理需求非常重要。使用图神经网络（GNN）的关键动机是其能够轻松直接地利用网络中丰富的结构信息，以探索考虑路网空间结构是否能提高劣化模型的预测性能。

**Method:** 本研究通过图神经网络（GNN）将路网的空间依赖性纳入路面劣化建模中。使用了来自德克萨斯州交通部维护的路面管理信息系统（PMIS）的超过五十万条观测数据的大型路面状况数据集。

**Result:** 有希望的比较结果表明，在考虑空间关系时，路面劣化预测模型表现更好。

**Conclusion:** 考虑路网的空间结构可以提高路面劣化模型的预测性能。

> **ai_Abstract:** 本研究旨在改进路面劣化建模，通过图神经网络（GNN）整合路网的空间结构信息。研究利用德克萨斯州交通部PMIS系统的大型数据集，评估了考虑空间关系对预测模型性能的影响。结果显示，纳入空间结构显著提升了路面劣化预测模型的准确性。

> **摘要翻译:** 路面劣化建模对于提供路网未来状态信息以及确定预防性维护或修复处理需求非常重要。本研究通过图神经网络（GNN）将路网的空间依赖性纳入路面劣化建模中。使用GNN进行路面性能建模的关键动机是其能够轻松直接地利用网络中丰富的结构信息。本文探讨了考虑路网空间结构是否会提高劣化模型的预测性能。本研究使用的数据集包含来自德克萨斯州交通部维护的路面管理信息系统（PMIS）的超过五十万条观测数据的大型路面状况数据集。有希望的比较结果表明，在考虑空间关系时，路面劣化预测模型表现更好。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [503] [Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning](https://arxiv.org/abs/2505.17988)
> *揭示小规模微调在R1风格强化学习中有效性的研究*

*Yutong Chen, Jiandong Gao, Ji Wu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** R1风格强化学习, 小规模微调, 再蒸馏, 大型语言模型, 效率提升

**Comment:** preprint

> **TL;DR:** 本文研究了R1风格强化学习中，小规模监督微调（SFT）对RL的显著影响，但效率低下。通过提出分析框架和再蒸馏（Re-distillation）技术，显著提升了小规模蒸馏的效率，使模型在更少样本和计算量下达到RL性能，并超越了现有模型。

**AI_Comments:** 本文通过提出“再蒸馏”这一创新技术，有效解决了R1风格强化学习中小规模监督微调效率低下的问题。其核心思想是通过从RL训练策略中采样进行再蒸馏，从而在保证性能的同时大幅减少了对样本和计算资源的需求，这对于大型语言模型的实际部署和应用具有重要意义。该研究不仅提供了理论分析框架，也通过实验验证了方法的有效性，对理解和优化R1风格RL机制具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管R1风格强化学习显著增强了大型语言模型的推理能力，但其基于规则的强化学习机制仍不清楚。研究发现小规模监督微调（SFT）对RL有显著影响但效率低下，因此需要解释这一现象并提高效率。

**Method:** 提出了一个分析框架来解释小规模SFT对RL的影响，并通过测量“样本效应”来比较SFT和RL的效率。在此分析指导下，提出了“再蒸馏（Re-distillation）”技术，该技术通过从RL训练的策略中采样来提高小规模蒸馏的有效性。

**Result:** 再蒸馏技术在三个数据集和Qwen、Llama模型上均显示出一致且惊人的效率：再蒸馏模型以远少于RL的样本量和计算量达到了RL的性能。在K&K数据集上，再蒸馏的Qwen-2.5-1.5B模型仅用1K SFT样本就超越了DeepSeek-V3-0324。

**Conclusion:** 研究解释了R1风格强化学习中的几个有趣现象，揭示了其经验成功背后的机制。再蒸馏技术可以有效地平衡强化学习中的多个目标，并显著提高小规模微调的效率。

> **ai_Abstract:** 本文深入探讨了R1风格强化学习（RL）中，小规模监督微调（SFT）对大型语言模型推理能力的影响。研究发现SFT虽然有显著影响但效率不高。为此，作者提出了一个分析框架来解释这一现象，并通过引入“再蒸馏（Re-distillation）”技术，显著提升了小规模蒸馏的效率。实验结果表明，再蒸馏模型能在显著减少样本量和计算量的情况下达到甚至超越RL的性能，例如在K&K数据集上，再蒸馏的Qwen-2.5-1.5B模型仅用1K SFT样本就超越了DeepSeek-V3-0324。这项工作不仅揭示了R1风格RL背后的机制，也为高效平衡RL中的多目标提供了新方法。

> **摘要翻译:** R1风格强化学习（RL）显著增强了大型语言模型的推理能力，但基于规则的RL机制仍不清楚。我们发现小规模监督微调（SFT）对RL有显著影响但效率低下。为了解释我们的观察结果，我们提出了一个分析框架，并通过测量“样本效应”来比较SFT和RL的效率。我们的假设分析表明SFT效率有提升的潜力。在我们的分析指导下，我们提出了“再蒸馏（Re-distillation）”技术，旨在通过从RL训练的策略中采样来提高小规模蒸馏的有效性。再蒸馏在三个数据集和Qwen、Llama模型上均显示出一致且惊人的效率：再蒸馏模型以远少于RL的样本量和计算量达到了RL的性能。结果，在K&K数据集上，我们再蒸馏的Qwen-2.5-1.5B模型仅用1K SFT样本就超越了DeepSeek-V3-0324。我们证明了再蒸馏可以有效地平衡RL中的多个目标。我们的工作解释了R1风格RL中的几个有趣现象，揭示了其经验成功背后的机制。代码可在以下网址获取：https://github.com/on1262/deep-reasoning。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [504] [Synthetic medical data generation: state of the art and application to trauma mechanism classification](https://arxiv.org/abs/2508.02771)
> *合成医疗数据生成：现状与创伤机制分类应用*

*Océane Doremus, Ariel Guerra-Adames, Marta Avalos-Fernandez, Vianney Jouhet, Cédric Gil-Jardiné, Emmanuel Lagarde* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 合成医疗数据, 机器学习, 创伤机制分类, 数据隐私, 文本数据

**Comment:** Accepted to CIBB 2025 as a short paper

> **TL;DR:** 本文概述了合成医疗数据生成的前沿机器学习方法，并提出了一种结合表格和非结构化文本数据生成高质量合成医疗记录的方法，旨在解决患者隐私和科学可重复性问题。

**AI_Comments:** 该论文通过关注合成医疗数据生成，解决了医疗健康领域机器学习研究中的关键挑战，即患者隐私保护和数据可重复性。其创新点在于提出了一种结合表格和非结构化文本数据的方法，这对于生成更全面、更真实的合成医疗记录具有重要意义，尤其是在处理复杂的临床数据时。这对于推动医疗AI研究在保护隐私的前提下进行具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 面对患者隐私保护和科学研究可重复性的挑战，健康领域的机器学习研究正转向合成医疗数据库的构建。

**Method:** 本文首先概述了用于生成合成表格和文本数据的最新机器学习方法，并重点关注其在创伤机制自动分类中的应用；随后提出了作者的方法，用于生成结合表格和非结构化文本数据的高质量合成医疗记录。

**Result:** 未在摘要中提及

**Conclusion:** 未在摘要中提及

> **ai_Abstract:** 该论文探讨了合成医疗数据生成的前沿技术及其在创伤机制分类中的应用。文章首先回顾了生成合成表格和文本数据的机器学习方法，然后提出了一种新的方法，旨在结合结构化表格数据和非结构化文本数据，以创建高质量的合成医疗记录，从而应对患者隐私和研究可重复性的挑战。

> **摘要翻译:** 面对患者保密性和科学可重复性的挑战，健康领域的机器学习研究正转向合成医疗数据库的构思。本文概述了用于生成合成表格和文本数据的最新机器学习方法，重点关注其在创伤机制自动分类中的应用，随后提出了我们生成结合表格和非结构化文本数据的高质量合成医疗记录的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Principled Foundations for Preference Optimization](https://arxiv.org/abs/2507.07855)
> *偏好优化的基本原理*

*Wenxuan Zhou, Shujian Zhang, Brice Magdalou, John Lambert, Ehsan Amid, Richard Nock, Andrew Hard* | **Category: cs.LG, cs.AI, cs.CL, I.2.6; I.2.7** | **Updated: 2025-08-05**

**Keywords:** 偏好优化, DPO, 损失函数, 随机选择, 机器学习

**Comment:** 

> **TL;DR:** 本文揭示了直接偏好优化（DPO）与机器学习中偏好学习的两个主要理论（损失函数和随机选择）之间的普遍联系，并强调了理解DPO原理的重要性。

**AI_Comments:** 本文的创新之处在于，它为当前热门的DPO算法提供了一个坚实的理论基础，将其置于更广泛的偏好学习理论框架中。通过揭示DPO与损失函数和随机选择的深层联系，文章不仅解释了DPO的有效性，还为其未来的扩展和改进指明了方向。其重要性在于，它为研究人员提供了理解DPO潜在局限性和开发更鲁棒、更通用算法的工具。对DPO广泛应用场景的强调，也凸显了这项基础研究的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解DPO从一般原理角度如何运作至关重要，原因在于模型应用场景的巨大和多样性、DPO当前的势头，以及许多最先进的DPO变体只占据了本文所覆盖图谱的一小部分。这也有助于理解偏离该图谱的陷阱并找到解决方案。

**Method:** 本文通过建立直接偏好优化（DPO）与机器学习中偏好学习的两个主要理论：损失函数（Savage）和随机选择（Doignon-Falmagne和Machina）之间的联系来展开研究。这种联系适用于Savage的所有损失。

**Result:** 所建立的通用联系包括：(i) 支持选择理论中的弃权，(ii) 支持机器学习中的非凸目标，(iii) 允许免费构建DPO设置的一些显著扩展，包括边际和长度校正。

**Conclusion:** 本文通过揭示DPO与损失函数和随机选择理论之间的普遍联系，为理解DPO的运作机制提供了一个通用的、有原则的视角，这对于DPO的广泛应用和未来发展至关重要。

> **ai_Abstract:** 本文深入探讨了直接偏好优化（DPO）的理论基础，揭示了它与机器学习中偏好学习的两个核心理论——损失函数（Savage）和随机选择（Doignon-Falmagne和Machina）——之间的普遍联系。研究表明，这种联系具有高度通用性，能够支持选择理论中的弃权、机器学习中的非凸目标，并自然地涵盖了DPO的多种扩展，如边际和长度校正。文章强调，从一般原理角度理解DPO对于其广泛应用、当前发展势头以及改进现有DPO变体至关重要，同时也有助于识别并规避潜在的理论陷阱。

> **摘要翻译:** 在本文中，我们展示了直接偏好优化（DPO）是机器学习中偏好学习的两个主要理论之间联系的一种非常具体的形式：损失函数（Savage）和随机选择（Doignon-Falmagne和Machina）。这种联系是针对Savage的所有损失建立的，在这种通用性水平上，(i) 它包括对选择理论中弃权的支持，(ii) 它包括对ML方面非凸目标的支持，(iii) 它允许免费构建DPO设置的一些显著扩展，包括边际和长度校正。从一个普遍的、有原则的视角来理解DPO如何运作是至关重要的，因为模型的应用前景巨大且多样，因为DPO当前势头强劲，但更重要的是——因为许多最先进的DPO变体确实占据了我们所覆盖图谱的一小部分区域。这也有助于理解偏离此图谱的陷阱，并找出解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [517] [Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation Models](https://arxiv.org/abs/2508.02812)
> *基于结构方程模型的分布鲁棒性强盗问题不确定性集*

*Katherine Avery, Chinmay Pendse, David Jensen* | **Category: cs.LG, I.2.4; I.2.6** | **Updated: 2025-08-04**

**Keywords:** 分布鲁棒性强盗, 结构方程模型, 不确定性集, 条件独立性, 策略学习

**Comment:** 10 pages main text, 28 pages total

> **TL;DR:** 当前分布鲁棒性方法过于保守；本文提出使用结构方程模型（SEM）为强盗问题创建不那么保守的不确定性集，从而实现更准确的评估和更低方差的策略。

**AI_Comments:** 该论文的创新之处在于利用结构方程模型（SEM）来定义不确定性集，这是一种解决现有分布鲁棒性方法保守性的新颖方法。这有望显著提高此类方法在实际应用中的实用性和性能，尤其是在分布偏移常见的情况下。在模型充分指定的情况下学习最优策略的能力提供了强大的理论保证。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于分布鲁棒性评估和学习的方法产生了过于保守的评估和策略。

**Method:** 提出了一种实用的强盗问题评估和学习算法，该算法使用受结构方程模型约束的数学规划来定制不确定性集。此外，展示了如何使用条件独立性检验来检测建模中发生变化的变量。

**Result:** 结构方程模型（SEM）方法比传统方法提供了更准确的评估，并学习到方差更低的策略，尤其是在大偏移量的情况下。

**Conclusion:** 假设模型充分指定，SEM方法可以学习到最优策略。

> **ai_Abstract:** 本文解决了当前分布鲁棒性强盗问题中评估和策略过于保守的问题。它提出了一种新颖的算法，利用结构方程模型（SEM）和数学规划来创建针对特定问题的不确定性集。与传统方法相比，所提出的SEM方法能够实现更准确的评估和更低方差的策略，尤其是在处理显著偏移时，并且在模型充分指定的情况下可以学习到最优策略。

> **摘要翻译:** 分布鲁棒性评估估计了在可能的协变量和奖励分布的不确定性集上的最坏情况预期回报，而分布鲁棒性学习则找到了一种策略，以最大化该不确定性集上的最坏情况回报。不幸的是，当前用于分布鲁棒性评估和学习的方法产生了过于保守的评估和策略。在这项工作中，我们提出了一种实用的强盗问题评估和学习算法，该算法使用受结构方程模型约束的数学规划，根据具体问题定制不确定性集。此外，我们展示了如何使用条件独立性检验来检测建模中发生变化的变量。我们发现，结构方程模型（SEM）方法比传统方法提供了更准确的评估，并学习到方差更低的策略，尤其是在大偏移量的情况下。此外，假设模型充分指定，SEM方法可以学习到最优策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [533] [GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics](https://arxiv.org/abs/2508.02926)
> *GrandJury：一种用于动态质量评估标准的协作机器学习模型评估协议*

*Arthur Cho* | **Category: cs.LG, cs.AI, cs.HC, I.2.6; I.2.7** | **Updated: 2025-08-04**

**Keywords:** 机器学习评估, 动态质量评估, 协作协议, 生成式AI, 大语言模型

**Comment:** 26 pages, 1 table. Open-source implementation available on PyPI
  (grandjury package) and GitHub. Dataset available on Hugging Face under
  CC-BY-4.0 license

> **TL;DR:** GrandJury 提出了一种新的协议，通过结合时间衰减聚合、可追溯性、动态任务评估标准归因和多人人工判断，来解决当前机器学习模型评估中缺乏对动态用户需求和演变现实的对齐问题。

**AI_Comments:** GrandJury的创新之处在于其对动态性和协作性的强调，这与传统静态基准测试形成了鲜明对比。它特别适用于生成式AI模型，这些模型的输出往往没有唯一的“正确”答案。通过引入时间衰减聚合和多方人工判断，该协议能够更好地反映用户需求和现实的演变，并提供更高的透明度和可追溯性。这对于提高AI系统的实际应用价值和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器学习模型评估方法依赖于静态的基准测试，这导致模型优化偏向排行榜得分而非与动态用户需求或不断演变的现实对齐。尤其是在生成式机器学习模型广泛应用的领域，可接受的响应是多元且高度依赖上下文的，而非绝对或静态。

**Method:** GrandJury 引入了一种正式的评估协议，该协议结合了时间衰减聚合、完整的可追溯性、对动态透明任务评估标准归因的支持以及多评估者的人工判断。

**Result:** GrandJury 能够实现多元化、负责任的评估，捕捉不断演变的共识并揭示分歧。它为AI从业者在没有绝对真实值的情况下评估机器学习输出提供了一个新范式。

**Conclusion:** GrandJury 提供了一个新的范式，用于在没有绝对真实值的情况下评估机器学习模型的输出，通过其协作协议实现了更动态和负责任的评估。

> **ai_Abstract:** GrandJury 提出了一种创新的机器学习模型评估协议，旨在解决现有静态评估方法无法适应生成式AI模型动态和上下文相关输出的局限性。该协议通过整合时间衰减聚合、完整的可追溯性、动态透明的任务评估标准归因以及多评估者的人工判断，实现了多元化、负责任的评估，从而更好地捕捉不断演变的共识和识别分歧。它为在缺乏绝对真实值的情况下评估AI模型输出提供了一个新的范式。

> **摘要翻译:** 生成式机器学习模型已成为现代系统的核心，为创意写作、摘要、多跳推理和上下文感知对话等应用提供支持。这些模型支撑着大规模人工智能助手、工作流自动化和自主决策。在这些领域中，可接受的响应很少是绝对或静态的，而是多元且高度依赖上下文的。然而，标准评估机制仍然依赖于静态的基准式测试，这激励了模型优化以追求排行榜分数，而非与动态用户需求或不断演变的现实对齐。GrandJury 引入了一种正式的评估协议，该协议结合了时间衰减聚合、完整的可追溯性、对动态透明任务评估标准归因的支持以及多评估者的人工判断。这些元素共同实现了多元化、负责任的评估，捕捉不断演变的共识并揭示分歧。我们提供了一个开源实现（GrandJury PyPI 包）和一个公共的大型语言模型（LLM）推理输出集合，以说明需求和方法。GrandJury 为AI从业者在没有绝对真实值的情况下评估机器学习输出提供了一个新范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [534] [Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination](https://arxiv.org/abs/2507.10532)
> *推理还是记忆？数据污染导致强化学习结果不可靠*

*Mingqi Wu, Zhihao Zhang, Qiaole Dong, Zhiheng Xi, Jun Zhao, Senjie Jin, Xiaoran Fan, Yuhao Zhou, Huijie Lv, Ming Zhang, Yanwei Fu, Qin Liu, Songyang Zhang, Qi Zhang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 数据污染, Qwen2.5, 基准测试, 数学推理

**Comment:** 33 pages

> **TL;DR:** 研究发现Qwen2.5系列模型在RL基准测试中的高性能可能源于数据污染而非真正的推理能力；通过引入无污染数据集，证明只有准确的奖励信号才能带来稳定改进。

**AI_Comments:** 该论文揭示了当前LLM在RL训练中可能存在的“记忆而非推理”问题，指出数据污染是导致模型在特定基准上表现优异但结果不可靠的关键因素。其创新之处在于提出并构建了一个“干净”的数学推理数据集RandomCalculation，为评估模型的真实推理能力提供了新的工具。论文强调了评估基准的纯净性对确保研究结论可靠性的重要性，对未来RL和LLM研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究发现强化学习在大型语言模型上取得了显著性能提升，甚至随机或不正确的奖励也能提高性能，但这些突破主要集中在Qwen2.5系列模型上，且很少推广到其他模型，这引发了对结果可靠性的质疑。

**Method:** 通过经验分析揭示Qwen2.5在常用基准测试中存在数据污染问题。为获得可靠的评估结果，引入了一个名为RandomCalculation的生成器，用于创建完全干净的算术问题数据集。使用该数据集，作者对比了准确、随机和不正确奖励信号对模型性能的影响，并进行了更细致的分析。

**Result:** Qwen2.5系列模型由于在大规模网络语料库上进行预训练，容易受到广泛使用的基准测试中的数据污染。因此，从受污染基准测试中得出的结论可能不可靠。在无泄漏数据集RandomCalculation上，只有准确的奖励信号才能使模型在数学推理方面获得稳定且超越基础模型性能界限的提升，而随机或不正确的奖励则不能。

**Conclusion:** 未来研究应在未受污染的基准上评估模型，并尽可能测试不同系列的模型，以确保关于强化学习及相关方法的结论是可靠的。

> **ai_Abstract:** 该研究调查了强化学习在大型语言模型中取得的性能提升，特别是Qwen2.5系列模型在数学基准测试上的突出表现。作者发现Qwen2.5的高性能可能源于其预训练数据中的数据污染，导致在受污染基准上的结果不可靠。为解决此问题，研究引入了名为RandomCalculation的无污染算术问题数据集。实验结果表明，只有准确的奖励信号才能在干净数据上带来稳定的性能提升，而随机或不正确的奖励则无效。论文强调了使用未受污染基准和测试多种模型系列对于获得可靠RL研究结论的重要性。

> **摘要翻译:** 大型语言模型中的推理能力长期以来一直是研究的重点，最近采用强化学习（RL）的研究引入了多种方法，在极少甚至没有外部监督的情况下取得了显著的性能提升。令人惊讶的是，一些研究甚至表明随机或不正确的奖励信号可以提高性能。然而，这些突破主要在数学能力强的Qwen2.5系列模型上观察到，例如在MATH-500、AMC和AIME等基准测试中，并且很少迁移到像Llama这样的模型上，这需要更深入的调查。在这项工作中，我们的经验分析表明，在大规模网络语料库上的预训练使得Qwen2.5容易受到广泛使用基准测试中的数据污染。因此，从Qwen2.5系列模型在受污染基准测试中得出的结论可能不可靠。为了获得可靠的评估结果，我们引入了一个生成器，可以创建任意长度和难度、完全干净的算术问题，命名为RandomCalculation。使用这个无泄漏数据集，我们表明只有准确的奖励信号才能在数学推理中产生稳定且超越基础模型性能边界的改进，而随机或不正确的奖励则不能。此外，我们进行了更细致的分析，以阐明在MATH-500和RandomCalculation基准测试中观察到的不同性能背后的因素。因此，我们建议未来的研究在未受污染的基准上评估模型，并在可行的情况下测试各种模型系列，以确保关于强化学习及相关方法的结论是可靠的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [535] [On the Theory and Practice of GRPO: A Trajectory-Corrected Approach with Fast Convergence](https://arxiv.org/abs/2508.02833)
> *GRPO的理论与实践：一种轨迹校正的快速收敛方法*

*Lei Pang, Ruinan Jin* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** GRPO, 强化学习, 大型语言模型, 策略梯度, 收敛性分析

**Comment:** 12 pages

> **TL;DR:** 本文分析了GRPO算法的梯度估计偏差，提出了一种新的轨迹级重要性校正算法TIC GRPO，并首次提供了GRPO类方法的收敛性分析。

**AI_Comments:** 本文对GRPO算法的内部机制进行了深入分析，揭示了其在梯度估计上的一个重要特性。通过提出TIC GRPO，不仅解决了原始GRPO的潜在偏差问题，还保持了其无批评者的优势。更重要的是，首次提供了GRPO类方法的理论收敛性分析，这对于理解和进一步发展这类针对LLM微调的RL算法具有重要意义，填补了理论空白。

<details>
  <summary>Details</summary>

**Motivation:** 抽象研究发现GRPO的更新规则实际上估计的是旧策略的梯度，而非当前策略的梯度，但由于旧策略频繁刷新，偏差影响有限。一项消融研究表明，即使完全移除重要性采样，使用固定旧策略梯度，性能仍与标准GRPO相当。这些发现促使作者提出了新的算法。

**Method:** 本文首先分析了GRPO算法，指出其更新规则估计的是旧策略的梯度。然后，通过一项消融研究验证了重要性采样的影响。基于这些发现，提出了一种新的算法：轨迹级重要性校正GRPO（TIC GRPO），该算法用单个轨迹级概率比替换了令牌级重要性比，从而获得了当前策略梯度的无偏估计，并保留了无批评者结构。此外，本文还首次对GRPO类方法（包括原始GRPO和TIC GRPO）进行了理论收敛性分析。

**Result:** 研究表明，GRPO的更新规则实际上估计的是旧策略的梯度。通过消融研究发现，即使完全移除重要性采样，更新使用固定旧策略的梯度，性能仍与标准GRPO相当。提出的TIC GRPO算法能够提供当前策略梯度的无偏估计。

**Conclusion:** 本文揭示了GRPO算法在梯度估计上的特性，并基于此提出了一种改进的、具有无偏梯度估计的TIC GRPO算法。同时，本文首次为GRPO类方法提供了理论收敛性分析，为这类算法的理解和发展奠定了基础。

> **ai_Abstract:** 本文深入分析了DeepSeek提出的GRPO算法，指出其更新规则在估计策略梯度时存在对旧策略的偏差，但这种偏差在实践中影响有限。通过消融实验验证了即使移除重要性采样，性能仍与GRPO相当。在此基础上，作者提出了一种新的算法——轨迹级重要性校正GRPO（TIC GRPO），该算法通过使用轨迹级概率比实现了当前策略梯度的无偏估计，并保持了无批评者结构。此外，本文首次为GRPO及其变体提供了理论收敛性分析。

> **摘要翻译:** DeepSeek 最近提出的组相对策略优化（GRPO）是一种用于微调大型语言模型的无评论家强化学习算法。它用组归一化奖励取代了近端策略优化（PPO）中的价值函数，同时保留了基于旧策略的PPO风格的令牌级重要性采样。我们发现GRPO的更新规则实际上估计的是旧策略的策略梯度，而非当前策略的。然而，由于旧策略每隔几步就会刷新，两者之间的差异仍然很小，从而限制了这种偏差在实践中的影响。我们通过一项消融研究验证了这一点，在该研究中，重要性采样被完全移除，取而代之的是在多个优化步骤中使用固定旧策略估计的梯度进行更新。值得注意的是，这种简化导致了与标准GRPO相当的性能。受这些发现的启发，我们提出了一种新算法：轨迹级重要性校正GRPO（TIC GRPO）。TIC GRPO用单个轨迹级概率比替换了令牌级重要性比，从而获得了当前策略梯度的无偏估计，同时保留了无评论家结构。此外，我们首次对GRPO类方法（包括原始GRPO和我们提出的变体）进行了理论收敛性分析。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [536] [Exploring Layer-wise Information Effectiveness for Post-Training Quantization in Small Language Models](https://arxiv.org/abs/2508.03332)
> *探索小语言模型中训练后量化的层级信息有效性*

*He Xiao, Qingyao Yang, Dirui Xie, Wendong Xu, Wenyong Zhou, Haobo Liu, Zhengwu Liu, Ngai Wong* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 量化, 小型语言模型, 训练后量化, 位宽分配, 边缘设备

**Comment:** low-bit quantization

> **TL;DR:** LieQ 是一种新的训练后量化框架，通过层级诊断实现自动位宽分配，在极低位宽下显著提高了小型语言模型的压缩精度，优于现有方法，并能大幅减少内存占用，为资源受限的边缘设备部署提供了新范式。

**AI_Comments:** LieQ的创新之处在于其无需梯度更新的层级诊断方法，这使得在极端低比特量化下也能保持高精度，显著优于现有SOTA方法。这对于在边缘设备上部署小型语言模型具有重要意义，有助于推动AI的普惠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（参数达数十亿）通常存在过度配置问题：许多层贡献的独特信息很少，但在推理过程中却占据了大量的内存和能耗。在极端低位压缩下，保持亚7B模型精度是一个关键挑战。

**Method:** 提出了LieQ，一个度量驱动的训练后量化框架。它引入了三种互补的层级诊断方法：困惑度下降（Perplexity Drop）、表征紧凑性（Representational Compactness）和Top-k能量增益（Top-k Energy Gain）。这些诊断揭示了层间的典型分工，从而无需梯度更新即可实现自动位宽分配。

**Result:** LieQ 在Qwen3-4B上实现了2.05比特量化，恢复了FP16基线性能的95.9%，在七项零样本推理任务上平均优于GPTQ 19.7%，优于AWQ 18.1%。在LLaMA3.2-3B上，LieQ 在2.07比特精度下保持了98.2%的基线精度，同时实现了4倍内存缩减。

**Conclusion:** LieQ 为在资源受限的边缘设备上部署小型语言模型建立了新的范式。

> **ai_Abstract:** 本文提出LieQ，一个针对小型语言模型的度量驱动训练后量化框架。通过引入困惑度下降、表征紧凑性和Top-k能量增益三种层级诊断，LieQ 能够自动分配位宽，无需梯度更新。实验表明，LieQ 在极低比特（2-3比特）精度下显著优于现有方法，如在Qwen3-4B和LLaMA3.2-3B上实现了高精度保持和大幅内存缩减，为资源受限设备上的模型部署提供了新方案。

> **摘要翻译:** 大型语言模型（参数达数十亿）通常存在过度配置问题：许多层贡献的独特信息很少，但在推理过程中却占据了大量的内存和能耗。我们提出了LieQ，一个度量驱动的训练后量化框架，旨在解决亚7B模型在极端低位压缩下保持精度的关键挑战。我们的方法引入了三种互补的层级诊断方法——困惑度下降、表征紧凑性和Top-k能量增益——这些诊断揭示了层间的典型分工，从而无需梯度更新即可实现自动位宽分配。与现有方法在2-3比特精度下遭受严重精度下降不同，LieQ 实现了最先进的压缩-精度权衡：在Qwen3-4B模型上，它在2.05比特量化下恢复了FP16基线性能的95.9%，在七项零样本推理任务上平均优于GPTQ 19.7%，优于AWQ 18.1%。应用于LLaMA3.2-3B模型时，LieQ 在2.07比特精度下保持了98.2%的基线精度，同时实现了4倍内存缩减，为在资源受限的边缘设备上部署小型语言模型建立了新的范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [541] [Comparative Evaluation of Kolmogorov-Arnold Autoencoders and Orthogonal Autoencoders for Fault Detection with Varying Training Set Sizes](https://arxiv.org/abs/2508.02860)
> *柯尔莫哥洛夫-阿诺德自动编码器和正交自动编码器在不同训练集大小下故障检测的比较评估*

*Enrique Luna Villagómez, Vladimir Mahalec* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 柯尔莫哥洛夫-阿诺德网络, 自动编码器, 故障检测, 数据效率, 无监督学习

**Comment:** 

> **TL;DR:** KAN-AEs，特别是WavKAN-AE和EfficientKAN-AE，在无监督故障检测中表现出比正交自动编码器更高的数据效率和更强的性能，即使在训练数据有限的情况下也是如此。

**AI_Comments:** 这篇论文探索了一种新颖的神经网络架构（KANs）在一个重要的无监督学习任务（故障检测）中的应用，这是一个创新的方向。研究结果表明KAN-AEs由于其数据效率和潜在的透明度，可能成为数据稀缺工业环境中的宝贵工具，解决了许多深度学习模型在实际应用中的一个限制。

<details>
  <summary>Details</summary>

**Motivation:** 柯尔莫哥洛夫-阿诺德网络（KANs）作为传统神经网络的一种灵活且参数高效的替代方案，在监督设置中显示出前景，但它们在无监督故障检测中的效用在很大程度上仍未被探索。

**Method:** 本研究对四种基于不同KAN实现的KAN-AE变体（EfficientKAN、FastKAN、FourierKAN和WavKAN）与正交自动编码器（OAE）在化工过程无监督故障检测中的性能进行了比较评估。模型在田纳西-伊士曼过程的13种训练集大小的正常操作数据上进行训练，并使用故障检测率（FDR）作为性能指标，在21种故障类型上进行评估。

**Result:** WavKAN-AE仅使用4,000个训练样本就达到了最高的总体FDR（≥92%），并保持最佳性能。EfficientKAN-AE仅用500个样本就达到了≥90%的FDR。FastKAN-AE在更大规模（≥50,000个样本）时变得有竞争力。FourierKAN-AE表现持续不佳。OAE基线逐渐改善，但需要大量更多的数据才能与顶级的KAN-AE性能相匹配。

**Conclusion:** KAN-AEs能够将数据效率与强大的故障检测性能相结合。它们使用结构化基函数表明了改进模型透明度的潜力，使其成为数据受限工业环境中部署的有前景的候选方案。

> **ai_Abstract:** 本研究评估了柯尔莫哥洛夫-阿诺德自动编码器（KAN-AEs）与正交自动编码器（OAEs）在化工过程无监督故障检测中的表现，尤其是在田纳西-伊士曼过程中。研究测试了四种KAN-AE变体在不同训练集大小和21种故障类型下的性能。结果表明，KAN-AEs，特别是WavKAN-AE和EfficientKAN-AE，与OAE相比，展现出卓越的数据效率和高故障检测率，使其成为数据受限工业应用中极具前景的候选方案。

> **摘要翻译:** 柯尔莫哥洛夫-阿诺德网络（KANs）最近作为传统神经网络的一种灵活且参数高效的替代方案而出现。与使用固定基于节点的激活的标准架构不同，KANs将可学习函数置于边上，由不同的函数族参数化。虽然它们在监督设置中显示出前景，但它们在无监督故障检测中的效用在很大程度上仍未被探索。本研究对基于KAN的自动编码器（KAN-AEs）在化工过程无监督故障检测中的应用进行了比较评估。我们调查了四种KAN-AE变体，每种都基于不同的KAN实现（EfficientKAN、FastKAN、FourierKAN和WavKAN），并在田纳西-伊士曼过程中与正交自动编码器（OAE）进行基准测试。模型在13种训练集大小的正常操作数据上进行训练，并使用故障检测率（FDR）作为性能指标，在21种故障类型上进行评估。WavKAN-AE仅使用4,000个训练样本就达到了最高的总体FDR（≥92%），即使其他变体在更大的数据集上进行训练，它仍然是表现最好的。EfficientKAN-AE仅用500个样本就达到了≥90%的FDR，显示出在低数据设置下的鲁棒性。FastKAN-AE在更大规模（≥50,000个样本）时变得具有竞争力，而FourierKAN-AE始终表现不佳。OAE基线逐渐改善，但需要大量更多的数据才能与顶级的KAN-AE性能相匹配。这些结果突出了KAN-AEs结合数据效率和强大故障检测性能的能力。它们使用结构化基函数表明了改进模型透明度的潜力，使其成为数据受限工业环境中部署的有前景的候选方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [542] [Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03501)
> *训练长上下文、多轮软件工程强化学习智能体*

*Alexander Golubev, Maria Trofimova, Sergei Polezhaev, Ibragim Badertdinov, Maksim Nekrashevich, Anton Shevtsov, Simon Karasik, Sergey Abramov, Andrei Andriushchenko, Filipp Fisin, Sergei Skvortsov, Boris Yangel* | **Category: cs.LG, cs.CL, cs.SE** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 大型语言模型, 软件工程, 多轮交互, 自主智能体

**Comment:** 

> **TL;DR:** 本文研究了如何使用强化学习训练长上下文、多轮软件工程智能体，通过修改后的DAPO算法，使基于Qwen2.5-72B-Instruct的智能体在SWE-bench Verified基准测试上的成功率从20%提升至39%，并在SWE-rebench上表现优于或持平于领先的开源模型。

**AI_Comments:** 该论文的创新点在于将强化学习成功应用于需要长上下文和多轮交互的软件工程领域，突破了当前RL-LLM研究主要关注单轮问题的局限性。其重要性在于证明了无需教师模型，通过RL也能有效提升LLM在复杂、有状态环境中的表现，为构建更强大的通用型自主智能体奠定了基础。这对于未来AI在软件开发自动化领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前强化学习在大型语言模型上的应用主要集中于单轮问题，而软件工程等实际领域需要丰富的多轮交互。本文旨在弥合这一差距，将强化学习成功应用于多轮、有状态环境的通用场景。

**Method:** 本文使用修改后的解耦优势策略优化（DAPO）算法，训练了一个基于Qwen2.5-72B-Instruct的智能体来解决真实世界的软件工程任务，且不依赖任何教师模型。

**Result:** 该方法将智能体在SWE-bench Verified基准测试上的成功率从20%的拒绝微调基线提高到39%。在SWE-rebench上，该智能体在使用相同脚手架的情况下，与DeepSeek-V3-0324和Qwen3-235B-A22B等领先的开源模型表现相当或更优。

**Conclusion:** 这项工作为基于开源模型构建更强大的自主智能体以解决复杂现实问题提供了一条可行的途径。

> **ai_Abstract:** 本文提出了一种使用强化学习训练长上下文、多轮软件工程智能体的方法。针对现有RL-LLM研究多集中于单轮问题的局限性，作者采用修改后的DAPO算法，训练了一个基于Qwen2.5-72B-Instruct的智能体，用于解决真实世界的软件工程任务。实验结果表明，该方法显著提升了智能体在SWE-bench Verified基准测试上的成功率（从20%提升至39%），且在SWE-rebench上与领先的开源模型表现相当或更优，为开发更强大的自主软件工程智能体提供了新路径。

> **摘要翻译:** 强化学习（RL）应用于大型语言模型（LLMs）的研究大多集中于单轮问题，例如数学推理或单次代码生成。虽然这些问题可以被视为令牌级别的多轮MDP，但这种观点对应于多轮交互的退化情况，即环境不提供反馈。这与许多真实世界领域（如软件工程（SWE））形成对比，后者需要与有状态环境进行丰富的多轮交互，该环境对每个动作都以非平凡的观察做出响应。
为了弥合这一差距，我们展示了RL在此通用机制上的成功应用。我们使用修改后的解耦优势策略优化（DAPO）算法，训练了一个基于Qwen2.5-72B-Instruct的智能体来解决真实世界的软件工程任务。我们的方法将智能体在SWE-bench Verified基准测试上的成功率从20%的拒绝微调基线提高到39%，并且不依赖任何教师模型。在SWE-rebench上，我们的智能体在使用相同脚手架的情况下，与DeepSeek-V3-0324和Qwen3-235B-A22B等领先的开源模型表现相当或更优，为基于开源模型构建更强大的自主智能体以解决复杂现实问题提供了一条可行的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [553] [Clus-UCB: A Near-Optimal Algorithm for Clustered Bandits](https://arxiv.org/abs/2508.02909)
> *Clus-UCB：一种用于聚类赌博机的近最优算法*

*Aakash Gore, Prasanna Chaporkar* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 聚类赌博机, Clus-UCB, 多臂赌博机, 后悔下界, 信息共享

**Comment:** 

> **TL;DR:** 研究了聚类多臂赌博机问题，提出了Clus-UCB算法，该算法利用聚类结构，渐近地接近新的后悔下界，并在模拟中表现良好。

**AI_Comments:** 这项工作的创新之处在于提出了Clus-UCB算法，该算法有效地利用了已知聚类结构来提高多臂赌博机问题的性能。通过引入共享信息的新指标，Clus-UCB在理论上和经验上都显示出优于传统方法的潜力。其重要性在于为在线广告和临床试验等实际应用提供了更高效的决策框架。

<details>
  <summary>Details</summary>

**Motivation:** 针对多臂赌博机问题，研究了手臂被划分为已知聚类且聚类内手臂平均奖励差异有已知阈值的情况。这种模型适用于在线广告、临床试验和无线通信等领域，其中结果取决于多个因素。

**Method:** 提出了Clus-UCB算法。该算法旨在利用聚类结构，引入了一种新的手臂评估指标，该指标依赖于聚类内的其他手臂，从而实现手臂间的信息共享。

**Result:** 推导出了比经典Lai & Robbins (1985)界限更优的渐近后悔下界。Clus-UCB算法能够渐近地接近这个新的下界。模拟结果显示，Clus-UCB的性能优于KL-UCB和其他已知处理相关手臂的赌博机算法。

**Conclusion:** 论文解决了聚类多臂赌博机问题，提出了近最优的Clus-UCB算法，并证明了其性能优势。文章也指出了当前工作的局限性并提出了未来的研究方向。

> **ai_Abstract:** 这篇论文研究了具有已知聚类结构的多臂赌博机问题，其中聚类内手臂的平均奖励差异有限。作者推导了新的渐近后悔下界，并提出了Clus-UCB算法。该算法通过引入依赖于聚类内其他手臂的新评估指标来利用聚类信息，从而实现信息共享。模拟结果表明，Clus-UCB在性能上优于现有算法，并能渐近地接近所推导的下界。

> **摘要翻译:** 我们研究了一种随机多臂赌博机设置，其中手臂被划分为已知聚类，使得聚类内手臂的平均奖励差异最多为已知阈值。虽然聚类结构是先验已知的，但手臂的平均值是未知的。该框架模拟了结果取决于多个因素——其中一些影响显著，另一些影响微小——的场景，例如在线广告、临床试验和无线通信。我们推导出了渐近后悔下界，该下界改进了Lai & Robbins (1985)的经典界限。然后，我们提出了Clus-UCB，一种高效的算法，它渐近地与这个下界紧密匹配。Clus-UCB旨在利用聚类结构，并引入了一个新的指标来评估手臂，该指标取决于聚类内的其他手臂。通过这种方式，手臂之间共享信息。我们展示了我们算法的模拟结果，并将其性能与KL-UCB和其他处理相关手臂的知名赌博机算法进行了比较。最后，我们讨论了这项工作的一些局限性，并以提及未来可能的研究方向作为结束。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [556] [Balancing Optimality and Diversity: Human-Centered Decision Making through Generative Curation](https://arxiv.org/abs/2409.11535)
> *平衡最优性与多样性：通过生成式策展实现以人为中心的决策*

*Michael Lingzhi Li, Shixiang Zhu* | **Category: cs.LG, cs.HC, math.OC** | **Updated: 2025-08-05**

**Keywords:** 生成式策证, 人机协作, 决策支持, 最优性, 多样性

**Comment:** 

> **TL;DR:** 提出一种“生成式策展”框架，为人类决策者提供兼顾最优性和多样性的推荐方案组合，以应对复杂决策中未观测因素。

**AI_Comments:** 这篇论文的创新点在于提出了“生成式策证”这一新颖框架，它突破了传统算法追求单一“最优解”的限制，转而关注如何生成一个多样化且高质量的推荐组合，以更好地适应人类决策中涉及的非量化、未建模因素。这种以人为中心的设计理念在实际应用中具有重要意义，尤其是在需要考虑复杂社会、政治和伦理因素的决策场景。其对“多样性”的量化和与“最优性”的权衡分析也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有算法推荐的解决方案往往只关注单一“最优”，但在医疗、物流、公共政策等领域，最终决策取决于人类对推荐组合中是否有满意选项，且受未观测定性因素影响。因此，需要一种能平衡量化质量和定性多样性的方法，以更好地配合人类判断。

**Method:** 提出“生成式策展”框架，该框架学习解决方案的分布，以最大化可管理组合中最佳选项的预期满意度。通过重新构建目标，形式化了量化质量与定性多样性之间的权衡，并引入了新的多样性指标。实现上采用生成对抗网络和顺序优化方法。

**Result:** 在合成和真实世界研究中，该框架与现有基准相比，持续降低了预期遗憾。

**Conclusion:** 该框架为决策者提供了一种设计算法的原则性方法，使其能够补充而非取代人类判断。通过生成多样化且高质量的选项组合，决策支持工具能够更好地适应未建模因素，从而实现大规模以人为中心的决策，确保算法推荐在目标不完整或演变时仍有用。

> **ai_Abstract:** 本文提出了“生成式策展”框架，旨在解决医疗、物流等领域中算法推荐与人类最终决策之间的差距。该框架通过学习解决方案的分布，生成兼顾量化质量和定性多样性的推荐组合，以最大化人类决策者从组合中选择最佳选项的预期满意度。它通过新的多样性指标形式化了质量与多样性的权衡，并利用生成网络和顺序优化实现。实验证明，该方法能有效降低决策遗憾，从而使算法更好地辅助而非替代人类判断，适应未建模的复杂因素，实现大规模以人为中心的决策。

> **摘要翻译:** 医疗保健、物流和公共政策领域的运营决策越来越多地涉及算法推荐候选解决方案，例如治疗方案、配送路线或政策选项，同时将最终选择权留给人类决策者。例如，学区使用算法设计校车路线，但管理者会根据社区反馈做出最终决定。在这些情况下，决策质量不取决于单一的算法“最优”，而是取决于推荐组合中是否包含人类最终认为可取的选项。我们提出了生成式策展，这是一个在满意度取决于可观测目标和未观测定性因素时，优化生成推荐集的框架。生成式策展不提供固定解决方案，而是学习解决方案的分布，旨在最大化可管理组合中最佳选项的预期满意度。我们的分析通过重新构建目标得出的新型多样性指标，形式化了量化质量与定性多样性之间的权衡。我们使用生成对抗网络和顺序优化方法实现了该框架，并在合成和真实世界研究中表明，与现有基准相比，它持续降低了预期遗憾。我们的框架为决策者提供了一种原则性方法，设计能够补充而非取代人类判断的算法。通过生成多样化但高质量的选项组合，决策支持工具可以更好地适应未建模因素，例如利益相关者偏好、政治可行性或社区接受度。更广泛地说，该框架使组织能够大规模地实现以人为中心的决策，确保即使目标不完整或不断演变，算法推荐仍然有用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [557] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
> *在资源受限下强化视觉语言模型使用工具进行详细视觉推理*

*Sunil Kumar, Bowen Zhao, Leo Dirac, Paulina Varshavskaya* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 视觉语言模型, 工具使用, 资源受限, 群组相对策略优化, 视觉推理

**Comment:** 

> **TL;DR:** 本研究提出了一种在资源受限下，通过使用群组相对策略优化（GRPO）训练小型视觉语言模型（VLMs）使用外部工具（如缩放）的方法，以提高其在详细视觉推理方面的性能。

**AI_Comments:** 本文提出了一种新颖且实用的方法，通过让小型VLMs学习使用外部工具来克服资源限制下的详细视觉推理挑战。其创新点在于结合了GRPO、简化的工具接口和针对性数据混合，为资源受限环境下的模型性能提升提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型模型推理能力取得了巨大进步，但视觉语言模型（VLMs）在详细视觉推理方面仍然面临挑战，尤其是在计算资源有限的情况下。

**Method:** 受Deepseek-1等方法的启发，本文通过群组相对策略优化（GRPO）训练小规模模型使用外部工具（如缩放）。该方法结合了GRPO学习、简单的奖励结构、简化的工具调用接口、为工具调用结果分配额外token以及包含更多视觉困难示例的训练数据混合。

**Result:** 与类似大小的基线模型相比，我们的方法在某些视觉问答（VQA）任务上取得了更好的性能，这得益于从外部工具收集到的详细视觉信息。

**Conclusion:** 通过结合GRPO、简化的工具接口和优化数据策略，本研究成功地强化了资源受限下的视觉语言模型，使其能够有效利用外部工具进行详细的视觉推理，从而在VQA任务上表现出优越的性能。

> **ai_Abstract:** 本论文旨在解决视觉语言模型（VLMs）在资源受限下进行详细视觉推理的困难。受Deepseek-r1的启发，研究人员使用群组相对策略优化（GRPO）训练小型VLMs以有效利用外部工具，如缩放功能。通过结合GRPO、简化的工具接口、优化的奖励机制和侧重于视觉困难样本的训练数据，该方法显著提高了模型在视觉问答（VQA）任务上的表现，证明了其在资源限制下增强VLM视觉推理能力的有效性。

> **摘要翻译:** 尽管大型模型推理能力最近取得了巨大进展，但视觉语言模型（VLMs）在详细视觉推理方面仍然面临挑战，尤其是在计算资源有限的情况下。为了解决这一挑战，我们从Deepseek-r1等适用于VLMs的方法中汲取灵感，并使用群组相对策略优化（GRPO）训练小规模模型使用外部工具，例如缩放。最大的益处来自于GRPO学习、简单的奖励结构、简化的工具调用接口、为工具调用结果分配额外token以及过度代表视觉困难示例的训练数据混合的组合。与类似大小的基线模型相比，我们的方法在某些视觉问答（VQA）任务上取得了更好的性能，这得益于从外部工具收集到的详细视觉信息。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [559] [BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling](https://arxiv.org/abs/2508.02924)
> *BoostTransformer：通过子网格选择和重要性采样增强Transformer模型*

*Biyi Fang, Jean Utke, Truong Vo, Diego Klabjan* | **Category: cs.LG, stat.ML, 68T07, 68Q32, I.2.6; I.5.1; F.1.1** | **Updated: 2025-08-04**

**Keywords:** Transformer, Boosting, 子网格选择, 重要性采样, 文本分类

**Comment:** 10 pages, 5 figures, submitted for review at a major machine learning
  conference. arXiv admin note: substantial text overlap with arXiv:2203.00761,
  arXiv:2507.22842

> **TL;DR:** BoostTransformer通过结合提升原理、子网格选择和重要性采样，显著提高了Transformer模型的训练效率和性能，超越了传统Transformer。

**AI_Comments:** 该论文通过将提升（boosting）原理与Transformer模型相结合，提出了一种新颖的方法，这在Transformer的效率和性能优化方面具有创新性。考虑到当前大型语言模型日益增长的复杂性，其专注于提高效率、性能并减少调优开销的努力具有高度相关性。子网格选择和重要性采样是其关键的创新组成部分。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Transformer架构在NLP领域虽然占据主导地位，但面临计算资源消耗巨大和超参数调优复杂的问题。

**Method:** BoostTransformer框架通过子网格令牌选择和重要性加权采样，将提升（boosting）原理融入Transformer模型。具体而言，它将一个最小二乘提升目标直接整合到Transformer的管道中。

**Result:** 在多个细粒度文本分类基准测试中，BoostTransformer展现了更快的收敛速度和更高的准确性，超越了标准Transformer，并显著减少了架构搜索开销。

**Conclusion:** BoostTransformer通过引入提升原理、子网格选择和重要性采样，有效地解决了传统Transformer在计算资源和调优上的挑战，实现了更高效的训练和更优异的性能。

> **ai_Abstract:** BoostTransformer是一个新颖的框架，旨在通过引入提升（boosting）原理、子网格令牌选择和重要性加权采样来增强Transformer模型。该方法将最小二乘提升目标直接整合到Transformer流程中，旨在解决标准Transformer计算资源消耗大和超参数调优复杂的问题。在多个细粒度文本分类基准测试中，BoostTransformer展现了更快的收敛速度和更高的准确性，超越了传统Transformer，并显著减少了架构搜索开销，实现了更高效的训练和性能提升。

> **摘要翻译:** Transformer架构在现代自然语言处理（NLP）中占据主导地位，但通常需要大量的计算资源和复杂的超参数调优。为了缓解这些挑战，我们提出了一个新颖的框架——BoostTransformer，它通过子网格令牌选择和重要性加权采样，利用提升（boosting）原理增强了Transformer。我们的方法将最小二乘提升目标直接整合到Transformer管道中，从而实现更高效的训练和改进的性能。在多个细粒度文本分类基准测试中，BoostTransformer展示了更快的收敛速度和更高的准确性，超越了标准Transformer，同时最大限度地减少了架构搜索开销。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [575] [A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models](https://arxiv.org/abs/2508.02711)
> *一种大型语言模型的贝叶斯混合参数高效微调方法*

*Yidong Chai, Yang Liu, Yonghang Zhou, Jiaheng Xie, Daniel Dajun Zeng* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 贝叶斯学习, 参数高效微调, 大型语言模型, 不确定性量化, 动态微调

**Comment:** 

> **TL;DR:** 提出了一种名为BH-PEFT的贝叶斯混合参数高效微调方法，它通过整合贝叶斯学习来解决现有混合PEFT方法在不确定性量化和动态适应性方面的挑战，并在业务任务中表现优异。

**AI_Comments:** 这项工作通过将贝叶斯学习引入混合PEFT方法，创新性地解决了LLM微调中不确定性量化和动态适应性的关键挑战。这对于需要高可靠性和实时适应性的商业应用具有重要意义。该方法结合了多种PEFT技术，并通过贝叶斯框架提供了不确定性估计，使其在实际部署中更具说服力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在特定领域微调时，现有混合参数高效微调（PEFT）方法面临两大挑战：一是缺乏不确定性量化能力，导致决策不可靠；二是难以动态适应新数据。这限制了它们在真实世界应用中的有效性。

**Method:** 本文提出贝叶斯混合参数高效微调（BH-PEFT）方法，将贝叶斯学习融入混合PEFT。BH-PEFT结合了Adapter、LoRA和Prefix-tuning来微调Transformer的馈线层和注意力层。通过将可学习参数建模为分布，BH-PEFT实现了不确定性量化。此外，还提出了贝叶斯动态微调方法，将上一轮的后验分布作为下一轮的先验，以有效适应新数据。

**Result:** BH-PEFT在情感分析、新闻分类和常识推理等业务任务上进行了评估。结果表明，该方法优于现有PEFT基线，能够实现不确定性量化以支持更可靠的决策，并提高了在动态场景中的适应性。

**Conclusion:** 本文提出了一种新颖的BH-PEFT方法和动态微调方法，支持在真实世界情境中进行不确定性感知和自适应决策。这项工作对业务分析和数据科学做出了贡献。

> **ai_Abstract:** 本文提出了一种新颖的贝叶斯混合参数高效微调（BH-PEFT）方法，旨在解决现有混合PEFT在大型语言模型微调中面临的不确定性量化不足和动态适应性差的问题。BH-PEFT将贝叶斯学习与Adapter、LoRA和Prefix-tuning相结合，通过将参数建模为分布来实现不确定性量化。同时，提出的贝叶斯动态微调方法利用前一轮的后验作为新数据的先验，增强了模型对动态数据的适应性。在情感分析、新闻分类和常识推理等业务任务上的实验结果表明，BH-PEFT优于现有基线，并能提供更可靠的决策和更好的动态适应性。

> **摘要翻译:** 大型语言模型（LLMs）展示了重塑世界的变革潜力。由于这些模型是在通用语料库上进行预训练的，它们通常需要领域特定的微调以优化在专业业务应用中的性能。由于其大规模特性，参数高效微调（PEFT）方法被广泛用于降低训练成本。其中，结合多种PEFT技术的混合PEFT方法取得了最佳性能。然而，现有混合PEFT方法在为专业应用微调LLMs时面临两大主要挑战：（1）依赖点估计，缺乏量化不确定性的能力以实现可靠决策；（2）难以动态适应新兴数据，缺乏适应真实世界情况的能力。我们提出了贝叶斯混合参数高效微调（BH-PEFT），这是一种将贝叶斯学习集成到混合PEFT中的新颖方法。BH-PEFT结合了Adapter、LoRA和Prefix-tuning来微调Transformer的馈线层和注意力层。通过将可学习参数建模为分布，BH-PEFT实现了不确定性量化。我们进一步提出了一种贝叶斯动态微调方法，其中上一轮的后验作为下一轮的先验，从而能够有效适应新数据。我们在情感分析、新闻分类和常识推理等业务任务上评估了BH-PEFT。结果表明，我们的方法优于现有PEFT基线，能够实现不确定性量化以支持更可靠的决策，并提高了在动态场景中的适应性。这项工作通过提出一种新颖的BH-PEFT方法和动态微调方法，支持在真实世界情境中进行不确定性感知和自适应决策，从而为业务分析和数据科学做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [576] [MoKA: Mixture of Kronecker Adapters](https://arxiv.org/abs/2508.03527)
> *MoKA：克罗内克适配器混合*

*Mohammadreza Sadeghi, Mahsa Ghazvini Nejad, MirHamed Jafarzadeh Asl, Yu Gu, Yuanhao Yu, Masoud Asgharian, Vahid Partovi Nia* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 参数高效微调, 克罗内克适配器, 大型语言模型, 门控机制, 秩灵活性

**Comment:** 

> **TL;DR:** MoKA是一种新的参数高效微调方法，通过混合克罗内克积提高表达能力并实现参数效率与性能的最佳权衡，在LLaMA模型上表现优异。

**AI_Comments:** MoKA的创新之处在于通过混合克罗内克积和引入门控机制，有效提升了PEFT方法的表达能力，同时通过秩灵活性和硬件优化解决了参数效率与性能之间的矛盾。这对于大型语言模型的实际部署和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的低秩适配器在参数高效微调（PEFT）中因秩约束导致表达能力有限，从而限制了它们在复杂任务上的性能。

**Method:** 提出MoKA，通过将权重更新建模为克罗内克积的混合来解决表达能力限制。它利用门控机制衡量每个克罗内克因子的重要性，并提供秩灵活性以平衡参数效率和准确性。为确保硬件效率，将克罗内克计算重构为标准矩阵操作。

**Result:** MoKA在指令微调和常识推理任务上，不仅优于PEFT基线，还将可训练参数数量减少高达27倍，实现了性能和参数效率之间的最先进权衡。

**Conclusion:** MoKA是一种有效且高效的新一代克罗内克适配器，它通过提高表达能力和优化硬件部署，为大型语言模型提供了卓越的参数高效微调解决方案。

> **ai_Abstract:** 本文提出MoKA（Mixture of Kronecker Adapters），一种新型参数高效微调方法，旨在克服现有低秩适配器表达能力受限的问题。MoKA通过将权重更新建模为克罗内克积的混合，并引入门控机制和秩灵活性来增强表达能力和优化参数效率。为确保硬件兼容性，其克罗内克计算被重构。实验证明，MoKA在指令微调和常识推理任务上，不仅超越了PEFT基线，还将可训练参数减少了高达27倍，实现了性能与参数效率的SOTA权衡。

> **摘要翻译:** 参数高效微调（PEFT）对于降低大型语言模型（LLM）的计算开销至关重要。低秩家族适配器常用于有效控制参数规模，同时保持LLM的生成能力。然而，由于秩约束导致的表达能力有限，常常限制了它们在复杂任务上的性能。我们提出了克罗内克适配器混合（MoKA），这是一种新一代克罗内克适配器，通过将权重更新建模为克罗内克积的混合来解决这一限制。我们提出的适配器利用门控机制来衡量每个克罗内克因子的重要性，从而实现更具表达力的自适应。此外，MoKA 实现了秩灵活性，在参数效率和准确性之间提供了更好的权衡。为了确保硬件效率，我们使用标准矩阵操作重新构建了克罗内克计算，允许在 GPU 优化硬件上无缝部署。我们使用 LLaMA2-7B 和 LLaMA3-8B 模型的低位量化版本，在指令微调和常识推理任务上进行了广泛实验。MoKA 不仅优于 PEFT 基线，而且将可训练参数数量减少高达 27 倍，实现了性能和参数效率之间的最先进权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [580] [PLoRA: Efficient LoRA Hyperparameter Tuning for Large Models](https://arxiv.org/abs/2508.02932)
> *PLoRA：大型模型高效LoRA超参数调优*

*Minghao Yan, Zhuang Wang, Zhen Jia, Shivaram Venkataraman, Yida Wang* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** LoRA, 超参数调优, 大型语言模型, 训练效率, 并发微调

**Comment:** 

> **TL;DR:** PLoRA通过并行化LoRA微调，显著提高了大型模型LoRA超参数调优的效率和吞吐量。

**AI_Comments:** PLoRA的创新在于从训练效率而非服务效率的角度优化LoRA，通过并行化和内核优化有效解决了LoRA超参数调优的高开销问题，对于大规模LLM的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有LoRA训练范式未能有效利用硬件资源，且获取高性能LoRA的开销高昂。

**Method:** 提出PLoRA系统，自动编排并发LoRA微调任务，并在给定硬件和模型约束下开发高性能内核以提高训练效率。

**Result:** PLoRA将超参数搜索空间的LoRA微调完工时间缩短高达7.52倍，并将训练吞吐量提高高达12.8倍。

**Conclusion:** PLoRA显著提高了LoRA微调的效率和资源利用率，解决了现有训练范式的瓶颈。

> **ai_Abstract:** 本文提出了PLoRA，一个旨在提高大型模型LoRA超参数调优效率的系统。PLoRA通过识别现有LoRA训练范式的资源利用率低下问题，引入了自动编排并发LoRA微调任务和开发高性能内核的方法。实验结果表明，PLoRA显著减少了微调完工时间并大幅提升了训练吞吐量。

> **摘要翻译:** 低秩适应（LoRA）因其低资源需求和良好性能，已成为大型语言模型（LLMs）的一种流行微调方法。尽管大量工作研究了通过并发服务多个LoRA来提高LoRA服务效率，但现有方法假设有大量LoRA适配器可供服务。在我们的工作中，我们进行了广泛的实证研究，发现当前的训练范式未能有效利用硬件资源，并且需要高昂的开销才能获得高性能的LoRA。利用这些见解，我们提出了PLoRA，它在给定的硬件和模型约束下自动编排并发的LoRA微调任务，并开发了高性能内核以提高训练效率。我们的实验研究表明，PLoRA将给定超参数搜索空间上的LoRA微调完工时间缩短了高达7.52倍，并在一系列最先进的LLM上将训练吞吐量提高了高达12.8倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [594] [Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver](https://arxiv.org/abs/2508.02964)
> *注入测量信息可实现快速且抗噪声的基于扩散的逆问题求解器*

*Jonathan Patsenker, Henry Li, Myeongseob Ko, Ruoxi Jia, Yuval Kluger* | **Category: cs.LG, stat.CO** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 逆问题, 测量信息, 条件后验均值, 噪声鲁棒性

**Comment:** 

> **TL;DR:** 通过估计条件后验均值，本研究提出了一种快速且抗噪声的扩散模型逆问题求解器，该求解器在处理测量信息时更有效。

**AI_Comments:** 该论文的关键创新在于将测量信息$\mathbf{y}$直接整合到扩散模型的后验均值估计中，而不是在采样过程的下游处理。这种“注入”方式显著提高了求解器的效率和对噪声的鲁棒性，解决了现有扩散模型在处理逆问题时的一个重要局限性。其提出的轻量级最大似然估计方法和噪声感知停止准则也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型逆问题求解器通常依赖Tweedie公式，但该方法未直接考虑测量信息y，需要后续集成，导致效率和鲁棒性不足。

**Method:** 本文提出估计条件后验均值 $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$，这可以被表述为一个轻量级、单参数最大似然估计问题的解。该预测可以集成到任何标准采样器中，从而实现快速且内存高效的逆问题求解器。此外，该优化器适用于一种抗测量噪声y的噪声感知、基于似然的停止准则。

**Result:** 该方法在多个数据集和任务上，与多种当代逆问题求解器相比，展示了相当或更优的性能。

**Conclusion:** 通过直接在扩散模型中整合测量信息，可以显著提高逆问题求解的速度、内存效率和对测量噪声的鲁棒性，从而提供一种高性能的解决方案。

> **ai_Abstract:** 本研究提出了一种改进的扩散模型逆问题求解器，通过直接估计条件后验均值$\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$来整合测量信息。与现有方法相比，该方法避免了测量信息在下游整合的需要，从而实现了更快速、内存高效的求解。该求解器还具有对测量噪声鲁棒的停止准则，并在多项任务中展现出与现有先进方法相当或更优的性能。

> **摘要翻译:** 扩散模型因其强大的图像先验和迭代采样算法，已被牢固确立为线性及非线性逆问题的零样本求解器。这些方法通常依赖Tweedie公式，该公式将扩散变量$\mathbf{x}_t$与后验均值$\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$联系起来，以估计最终去噪样本$\mathbf{x}_0$来引导扩散轨迹。然而，这并未考虑测量信息$\mathbf{y}$，后者必须在下游进行整合。在这项工作中，我们提出估计条件后验均值$\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$，这可以被表述为一个轻量级、单参数最大似然估计问题的解。由此产生的预测可以集成到任何标准采样器中，从而实现一个快速且内存高效的逆求解器。我们的优化器适用于一种噪声感知、基于似然的停止准则，该准则对$\mathbf{y}$中的测量噪声具有鲁棒性。我们证明了在多个数据集和任务上，与广泛选择的当代逆求解器相比，性能相当或有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [599] [R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning](https://arxiv.org/abs/2507.17307)
> *R-Stitch：高效推理的动态轨迹拼接*

*Zhuokun Chen, Zeren Chen, Jiahao He, Mingkui Tan, Jianfei Cai, Bohan Zhuang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 思维链推理, 混合解码, 语言模型加速, 推理效率, R-Stitch

**Comment:** 

> **TL;DR:** R-Stitch是一种混合解码框架，通过在推理过程中动态切换小型和大型语言模型来加速思维链（CoT）推理，显著降低了延迟，同时保持了准确性。

**AI_Comments:** R-Stitch的创新之处在于其令牌级的、基于置信度的混合解码策略，它有效地结合了小型模型的高效性和大型模型的准确性。这种动态切换机制避免了传统推测解码中全序列回滚的低效性，并且是模型无关和无需训练的，这大大降低了其应用门槛。其显著的延迟降低和可忽略的准确率损失，使其在实际应用中具有重要价值，尤其是在需要高效部署大型语言模型的场景。

<details>
  <summary>Details</summary>

**Motivation:** 思维链（CoT）推理虽然有效，但由于其在长序列上的自回归解码而引入了大量的计算开销。现有的加速策略存在局限性，例如推测解码在小型模型和大型模型之间一致性较低时提速有限，并且未能利用小型模型生成简洁中间推理的潜在优势。

**Method:** R-Stitch是一种基于令牌级别、置信度的混合解码框架。它通过在推理轨迹上在小型语言模型（SLM）和大型语言模型（LLM）之间切换来加速CoT推理。R-Stitch默认使用SLM生成令牌，仅当SLM的置信度低于阈值时才委托给LLM。这种设计避免了全序列回滚，并选择性地在不确定的步骤中调用LLM，从而在保持效率和答案质量的同时加速推理。

**Result:** 在数学推理基准测试中，R-Stitch将推理延迟降低了高达85%，而准确率下降可忽略不计。

**Conclusion:** R-Stitch在加速思维链（CoT）推理方面表现出实际有效性，显著降低了推理延迟，同时保持了答案质量，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文提出了R-Stitch，一个用于加速思维链（CoT）推理的令牌级、基于置信度的混合解码框架。针对CoT推理计算开销大的问题，R-Stitch通过在推理过程中动态地在小型语言模型（SLM）和大型语言模型（LLM）之间切换。它默认由SLM生成令牌，仅在SLM置信度不足时才调用LLM，从而避免了不必要的回滚并优化了LLM的使用。该方法模型无关、无需训练且兼容现有解码管道。实验结果表明，R-Stitch在数学推理任务上能将推理延迟降低高达85%，同时保持了几乎不变的准确率，展现了其在提高CoT推理效率方面的实用性。

> **摘要翻译:** 思维链（CoT）推理通过在推理过程中鼓励逐步的中间推理，增强了大型语言模型的解决问题能力。虽然有效，但CoT由于其对长令牌序列的自回归解码的依赖，引入了大量的计算开销。现有的加速策略要么通过提前停止或压缩奖励设计来减少序列长度，要么通过使用较小模型的推测解码来提高解码速度。然而，当小型模型和大型模型之间的一致性较低时，推测解码的加速效果有限，并且未能利用小型模型在产生简洁中间推理方面的潜在优势。在本文中，我们提出了R-Stitch，一个令牌级别、基于置信度的混合解码框架，它通过在推理轨迹上在小型语言模型（SLM）和大型语言模型（LLM）之间切换来加速CoT推理。R-Stitch默认使用SLM生成令牌，仅当SLM的置信度低于阈值时才委托给LLM。这种设计避免了全序列回滚，并选择性地在不确定的步骤中调用LLM，从而在保持效率和答案质量的同时加速推理。R-Stitch是模型无关的，无需训练，并且兼容标准的解码管道。在数学推理基准测试上的实验表明，R-Stitch将推理延迟降低了高达85%，而准确率下降可忽略不计，突出了其在加速CoT推理方面的实际有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [603] [Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)](https://arxiv.org/abs/2508.02737)
> *嵌入增强型铁电场效应晶体管 (FeFET) 概率建模*

*Tasnia Nobi Afee, Jack Hutchins, Md Mazharul Islam, Thomas Kampfe, Ahmedullah Aziz* | **Category: cs.LG, cs.ET** | **Updated: 2025-08-02**

**Keywords:** FeFETs, 概率建模, 混合密度网络, 变异性, 嵌入层

**Comment:** 15 pages, 6 figures, manuscript yet not submitted anywhere

> **TL;DR:** 提出一种基于MDN、C-infinity激活函数和嵌入层的增强型概率模型，用于准确捕获FeFET的随机性和变异性，实现高精度建模，R2达到0.92。

**AI_Comments:** 这项工作创新性地将C-infinity连续激活函数和设备特定嵌入层集成到基于MDN的概率建模框架中，有效地解决了FeFETs固有的随机性和变异性建模难题。其高精度（R2=0.92）证明了方法的有效性，为FeFET的可靠设计和电路仿真提供了关键支持，有望加速FeFET在下一代存储和逻辑技术中的应用。

<details>
  <summary>Details</summary>

**Motivation:** FeFETs在存储和逻辑技术中有巨大潜力，但其固有的随机性（操作循环和制造变异性）给准确可靠的建模带来挑战。现有模型无法充分捕获这种变异性或缺乏数学平滑性，导致电路级集成不稳定。

**Method:** 提出一个增强型概率建模框架，基于混合密度网络 (MDN)，整合C-infinity连续激活函数以实现平滑稳定的学习，并引入设备特定的嵌入层以捕获设备间的内在物理变异性。通过学习到的嵌入分布进行采样，可生成合成设备实例用于变异性感知仿真。

**Result:** 模型在捕获FeFET电流行为的变异性方面表现出高精度，R2值为0.92。

**Conclusion:** 该框架提供了一个可扩展、数据驱动的解决方案，用于建模FeFETs的完整随机行为，并为未来的紧凑模型开发和电路仿真集成奠定坚实基础。

> **ai_Abstract:** 本文提出一种增强型概率建模框架，用于解决铁电场效应晶体管 (FeFETs) 固有的随机性和变异性建模挑战。该框架基于混合密度网络 (MDN)，结合C-infinity连续激活函数和设备特定嵌入层，能够平滑且准确地捕获FeFET的物理变异性。模型在捕获FeFET电流行为变异性方面表现出高精度（R2=0.92），为FeFETs的全随机行为建模提供了一个可扩展、数据驱动的解决方案，并为未来的紧凑模型开发和电路仿真集成奠定基础。

> **摘要翻译:** 铁电场效应晶体管（FeFETs）在推动存储和逻辑技术方面具有巨大潜力，但其固有的随机性（源于操作循环和制造变异性）对准确可靠的建模构成了重大挑战。捕获这种变异性至关重要，因为它能使设计人员预测行为、优化性能并确保对制造和操作条件变化的可靠性和鲁棒性。现有的确定性模型和基于机器学习的紧凑模型往往未能充分捕获这种变异性，或缺乏稳定电路级集成所需的数学平滑性。在这项工作中，我们提出了一种增强型FeFET概率建模框架，以解决这些局限性。我们的方法以混合密度网络（MDN）为基础，集成了C-infinity连续激活函数以实现平滑、稳定的学习，并引入了设备特定的嵌入层以捕获设备间的内在物理变异性。从学习到的嵌入分布中进行采样，可以生成合成设备实例，用于变异性感知仿真。该模型在捕获FeFET电流行为的变异性方面表现出高精度，R2值为0.92。总而言之，该框架为建模FeFETs的完整随机行为提供了一个可扩展、数据驱动的解决方案，并为未来的紧凑模型开发和电路仿真集成提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [608] [Scalable Varied-Density Clustering via Graph Propagation](https://arxiv.org/abs/2508.02989)
> *可伸缩的变密度聚类通过图传播*

*Ninh Pham, Yingtao Zheng, Hugo Phibbs* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 变密度聚类, 图传播, 可伸缩性, 高维数据, 标签传播

**Comment:** 

> **TL;DR:** 该论文提出了一种新的、可伸缩的变密度聚类方法，通过将聚类问题转化为局部密度自适应邻域图上的标签传播过程，并结合随机投影和密度感知传播算法，实现了在大规模高维数据集上的高效聚类，同时保持了聚类质量和竞争力。

**AI_Comments:** 该论文的创新之处在于将变密度聚类问题重新概念化为图上的标签传播过程，并巧妙地结合了图传播技术和随机投影以实现可伸缩性。这种方法在处理大规模高维数据方面具有显著优势，特别是在计算效率方面。其将密度聚类与图论结合的视角也为未来研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是为了解决高维数据中变密度聚类的问题，并提出一种新的视角来处理这一挑战，将其视为图上的标签传播过程。

**Method:** 该方法将变密度聚类视为在适应局部密度变化的邻域图中的标签传播过程。它将基于密度的聚类与图连通性形式化地联系起来，并利用网络科学中开发的图传播技术。为确保可伸缩性，该方法引入了密度感知邻域传播算法，并利用先进的随机投影方法来构建近似邻域图。

**Result:** 该方法显著降低了计算成本，同时保持了聚类质量。在经验上，它能够在几分钟内扩展到包含数百万个点的数据集，并且与现有基线相比，实现了具有竞争力的准确性。

**Conclusion:** 该论文的结论是，所提出的通过图传播实现的可伸缩变密度聚类方法能够有效地处理大规模高维数据，在降低计算成本的同时保持聚类质量，并展现出优于现有方法的竞争力。

> **ai_Abstract:** 该论文提出了一种新颖的可伸缩变密度聚类方法，将高维数据聚类问题转化为局部密度自适应邻域图上的标签传播过程。通过将密度聚类与图连通性结合，并引入密度感知邻域传播算法及利用随机投影构建近似邻域图，该方法显著降低了计算成本并保持了聚类质量。实验证明，该方法能在大规模数据集上高效运行，并达到与现有方法相当的准确性。

> **摘要翻译:** 我们提出了一种针对高维数据变密度聚类的新颖视角，通过将其构建为在适应局部密度变化的邻域图中的标签传播过程。我们的方法将基于密度的聚类与图连通性正式连接起来，从而能够使用网络科学中开发的有效图传播技术。为了确保可伸缩性，我们引入了一种密度感知邻域传播算法，并利用先进的随机投影方法来构建近似邻域图。我们的方法显著降低了计算成本，同时保持了聚类质量。从经验上看，它能够在几分钟内扩展到包含数百万个点的数据集，并且与现有基线相比，实现了具有竞争力的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [621] [On the Fast Adaptation of Delayed Clients in Decentralized Federated Learning: A Centroid-Aligned Distillation Approach](https://arxiv.org/abs/2508.02993)
> *去中心化联邦学习中延迟客户端的快速适应：一种质心对齐蒸馏方法*

*Jiahui Bai, Hai Dong, A. K. Qin* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 去中心化联邦学习, 快速适应, 质心对齐蒸馏, 通信开销, 模型压缩

**Comment:** This paper is currently under peer review

> **TL;DR:** DFedCAD是一种新的去中心化联邦学习框架，通过质心对齐蒸馏技术，显著提高了延迟客户端的适应速度，同时大幅降低了通信开销。

**AI_Comments:** DFedCAD的创新之处在于结合了模型压缩（WCP）和基于质心对齐的知识蒸馏，有效解决了去中心化联邦学习中延迟客户端适应性和通信效率的关键挑战。其提出的结构距离和可微分k-means蒸馏模块是核心技术，实现了高效的知识转移。该方法在实际应用中具有显著潜力，因为它同时优化了性能和资源消耗。

<details>
  <summary>Details</summary>

**Motivation:** 去中心化联邦学习（DFL）在异步环境中面临延迟加入客户端适应缓慢和通信成本高昂的问题，这些限制严重阻碍了整体性能。

**Method:** 本文提出DFedCAD框架，通过加权簇剪枝（WCP）将模型压缩为代表性质心，以减少通信开销。然后，利用新颖的结构距离度量和可微分的k-means蒸馏模块，使延迟客户端能够智能地加权并与对等知识对齐，从而实现高效的端到端知识转移。

**Result:** 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的大量实验表明，DFedCAD始终达到最先进的性能，在所有评估设置中获得最高准确性，同时将通信开销降低了86%以上。

**Conclusion:** DFedCAD为动态、真实场景中的高效去中心化学习提供了一个可扩展且实用的解决方案。

> **ai_Abstract:** 本文提出了DFedCAD，一个用于去中心化联邦学习的新框架，旨在解决延迟客户端适应缓慢和高通信成本的问题。DFedCAD通过加权簇剪枝将模型压缩为质心以减少通信，并利用结构距离和可微分k-means蒸馏模块，使延迟客户端能快速高效地与对等知识对齐。实验证明，DFedCAD在多个数据集上实现了最先进的准确性，并将通信开销降低了86%以上，为动态环境下的高效去中心化学习提供了实用方案。

> **摘要翻译:** 去中心化联邦学习（DFL）在异步环境中面临延迟加入客户端适应缓慢和通信成本高昂的问题。这些限制严重阻碍了整体性能。为了解决这个问题，我们提出了DFedCAD，一种通过质心对齐蒸馏实现快速适应的新型框架。DFedCAD首先采用加权簇剪枝（WCP）将模型压缩为代表性质心，从而大大降低了通信开销。然后，它使延迟客户端能够利用新颖的结构距离度量和可微分的k-means蒸馏模块，智能地加权并与对等知识对齐，从而促进高效的端到端知识转移。在CIFAR-10、CIFAR-100和Tiny-ImageNet上的大量实验表明，DFedCAD始终达到最先进的性能，在所有评估设置中获得最高准确性，同时将通信开销降低了86%以上。我们的框架为动态、真实场景中的高效去中心化学习提供了一个可扩展且实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [634] [S2FGL: Spatial Spectral Federated Graph Learning](https://arxiv.org/abs/2507.02409)
> *S2FGL：空间谱联邦图学习*

*Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 联邦图学习, 图神经网络, 空间域, 谱域, 客户端漂移

**Comment:** 

> **TL;DR:** 本文提出了S2FGL框架，通过全局知识库解决空间语义知识退化问题，并通过频率对齐解决谱客户端漂移问题，显著提升了联邦图学习的性能。

**AI_Comments:** S2FGL的创新点在于从空间和谱两个独特视角审视并解决了联邦图学习中的核心挑战。通过引入全局知识库和频率对齐机制，它有效地缓解了数据孤岛和异质性带来的负面影响，为提升联邦图学习的性能和泛化能力提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦图学习（FGL）研究主要从结构角度处理子图联邦学习（subgraph-FL），忽视了图信号在空间域和谱域上的传播。具体而言，从空间角度看，子图联邦学习引入了客户端之间的边缘断开，导致标签信号中断和全局GNN语义知识的退化。从谱角度看，谱异质性导致子图间信号频率不一致，使得局部GNN过拟合本地信号传播方案，从而产生谱客户端漂移，损害全局泛化性。

**Method:** 本文提出了S2FGL框架，结合了空间和谱策略。具体方法包括：1. 引入一个全局知识库，以缓解由标签信号中断引起的语义知识不足的问题。2. 设计了频率对齐机制，以解决谱客户端漂移问题。

**Result:** 在多个数据集上进行了大量实验，结果表明S2FGL框架具有优越性。

**Conclusion:** S2FGL通过结合空间和谱策略，有效解决了联邦图学习中由于边缘断开导致的语义知识退化和谱异质性导致的谱客户端漂移问题，显著提升了模型性能和全局泛化性。

> **ai_Abstract:** 本文提出了S2FGL框架，旨在解决联邦图学习中因子图划分导致的图信号在空间域和谱域传播中遇到的挑战。S2FGL通过引入全局知识库来缓解空间视角下标签信号中断引起的语义知识退化，并通过设计频率对齐来解决谱视角下谱异质性导致的谱客户端漂移问题。实验结果表明，S2FGL在多个数据集上表现出优越性。

> **摘要翻译:** 联邦图学习（FGL）结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）强大的图建模能力。当前研究主要从结构角度处理子图联邦学习，却忽略了图信号在结构的空间域和谱域上的传播。从空间角度看，子图联邦学习引入了客户端之间的边缘断开，导致标签信号中断和全局GNN语义知识的退化。从谱角度看，谱异质性导致子图间信号频率不一致，使得局部GNN过拟合本地信号传播方案。结果，谱客户端漂移发生，损害了全局泛化性。为了解决这些挑战，我们提出了一个全局知识库来缓解由标签信号中断引起的语义知识不足的挑战。此外，我们设计了频率对齐来解决谱客户端漂移。空间和谱策略的结合形成了我们的S2FGL框架。在多个数据集上的大量实验证明了S2FGL的优越性。代码可在https://github.com/Wonder7racer/S2FGL.git获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [635] [Where and How to Enhance: Discovering Bit-Width Contribution for Mixed Precision Quantization](https://arxiv.org/abs/2508.03002)
> *在何处以及如何增强：发现混合精度量化中的位宽贡献*

*Haidong Kang, Lianbo Ma, Guo Yu, Shangce Gao* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 混合精度量化, 位宽贡献, Shapley值, 神经网络量化, 模型压缩

**Comment:** 

> **TL;DR:** 提出一种基于Shapley值的新型混合精度量化方法（SMPQ），它能直接衡量位宽贡献，并在主流基准上优于现有方法。

**AI_Comments:** 这篇论文的创新点在于它挑战了现有混合精度量化方法中关于位宽贡献的隐式假设，并首次引入了Shapley值来直接衡量位宽对性能的实际贡献。这种方法为理解和优化混合精度量化提供了新的视角，并可能在量化神经网络领域产生重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有混合精度量化（MPQ）方法在位宽选择时，隐式假设量化参数值反映了操作对精度提升的贡献，但本文认为量化参数的幅度不一定反映位宽对任务性能的实际贡献。

**Method:** 提出一种基于Shapley值的MPQ (SMPQ) 方法，直接衡量位宽操作对MPQ任务的贡献。为降低计算成本，提出一种基于蒙特卡洛采样的Shapley计算近似策略。

**Result:** 在主流基准上进行的广泛实验表明，SMPQ始终比基于梯度的竞争方法取得最先进的性能。

**Conclusion:** SMPQ通过直接衡量位宽贡献，克服了现有方法的局限性，实现了更好的混合精度量化性能。

> **ai_Abstract:** 本文研究了混合精度量化（MPQ）中位宽选择的问题，指出现有方法中量化参数的幅度不一定反映位宽对任务性能的实际贡献。为此，作者提出了一种基于Shapley值的新型MPQ方法（SMPQ），它能够直接衡量位宽操作的贡献。为了提高效率，SMPQ采用了基于蒙特卡洛采样的近似策略。实验结果表明，SMPQ在主流基准上达到了最先进的性能，优于基于梯度的现有方法。

> **摘要翻译:** 混合精度量化（MPQ）是一种有效的量化方法，通过为每个层的网络激活和权重分配不同的位宽，实现神经网络的精度-复杂度权衡。现有MPQ方法的典型方式是以梯度下降的方式优化量化策略（即位宽分配），这被称为可微分（DMPQ）。在搜索结束时，将选择与具有最大值的量化参数相关的位宽，以形成最终的混合精度量化策略，其隐含假设是量化参数的值反映了操作对精度改进的贡献。尽管关于MPQ改进的讨论很多，但位宽选择过程却很少受到关注。我们研究了这个问题，并认为量化参数的幅度不一定反映位宽对任务性能的实际贡献。然后，我们提出了一种基于Shapley的MPQ（SMPQ）方法，该方法衡量位宽操作对MPQ任务的直接贡献。为了降低计算成本，提出了一种基于蒙特卡洛采样的Shapley计算近似策略。在主流基准上进行的广泛实验表明，我们的SMPQ始终比基于梯度的竞争方法取得最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [645] [ZetA: A Riemann Zeta-Scaled Extension of Adam for Deep Learning](https://arxiv.org/abs/2508.02719)
> *ZetA：一种用于深度学习的黎曼Zeta尺度Adam扩展*

*Samiksha BC* | **Category: cs.LG, cs.AI, 68T07, 65K10, 68Q32, I.2.6; G.1.6; I.5.1** | **Updated: 2025-08-01**

**Keywords:** 深度学习优化器, Adam, 黎曼zeta函数, 梯度缩放, 泛化能力

**Comment:** 6 pages, 1 figure, 4 references. This paper introduces a hybrid
  optimizer combining Adam with Riemann zeta-based scaling

> **TL;DR:** ZetA是一种新的深度学习优化器，通过引入黎曼zeta函数的动态缩放来扩展Adam，并在多个数据集上显示出优于Adam的测试准确率。

**AI_Comments:** ZetA的创新点在于首次将黎曼zeta函数应用于深度学习优化器的梯度缩放中。这种独特的数学结合，加上其混合更新机制，使其在复杂和噪声环境下表现出优异的泛化能力和鲁棒性，为Adam等传统优化器提供了一个有前景的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 该工作旨在通过引入黎曼zeta函数动态缩放来改进Adam优化器，以提高深度学习模型的泛化能力和鲁棒性。

**Method:** ZetA是一种深度学习优化器，通过结合黎曼zeta函数进行动态梯度缩放来扩展Adam。它采用混合更新机制，该机制集成了自适应阻尼、基于余弦相似度的动量提升、熵正则化损失和类SAM扰动。

**Result:** 在SVHN、CIFAR10、CIFAR100、STL10和带噪声的CIFAR10上进行经验评估，ZetA始终显示出比Adam更高的测试准确率。实验表明ZetA是一种计算高效且鲁棒的Adam替代品，特别适用于噪声或高粒度分类任务。

**Conclusion:** ZetA是一种计算高效且鲁棒的Adam替代品，在深度学习优化中引入了基于zeta的梯度缩放，并在噪声或高粒度分类任务中表现出色。

> **ai_Abstract:** ZetA是一种新颖的深度学习优化器，它通过引入基于黎曼zeta函数的动态梯度缩放来改进Adam。该优化器采用混合更新机制，结合了自适应阻尼、余弦相似度动量提升、熵正则化损失和SAM式扰动，旨在提高模型的泛化能力和鲁棒性。实验结果表明，ZetA在多个图像分类数据集上均优于Adam，尤其在噪声或高粒度任务中表现出计算高效和鲁棒的特性。

> **摘要翻译:** 这项工作引入了ZetA，一种新颖的深度学习优化器，通过结合基于黎曼zeta函数的动态缩放来扩展Adam。据我们所知，ZetA是第一个在深度学习优化中应用基于zeta的梯度缩放的优化器。该方法通过混合更新机制提高了泛化能力和鲁棒性，该机制集成了自适应阻尼、基于余弦相似度的动量提升、熵正则化损失和锐度感知最小化（SAM）风格的扰动。在SVHN、CIFAR10、CIFAR100、STL10和带噪声的CIFAR10上的实证评估持续显示出比Adam更高的测试准确率。所有实验都采用轻量级全连接网络，在混合精度设置下训练五个epochs。结果表明，ZetA是Adam的一种计算高效且鲁棒的替代方案，特别适用于噪声或高粒度分类任务。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [650] [Urban In-Context Learning: Bridging Pretraining and Inference through Masked Diffusion for Urban Profiling](https://arxiv.org/abs/2508.03042)
> *城市情境学习：通过掩码扩散桥接预训练与推理实现城市画像*

*Ruixing Zhang, Bo Wang, Tongyu Zhu, Leilei Sun, Weifeng Lv* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 城市情境学习, 城市画像, 掩码扩散, 单阶段模型, 预训练推理统一

**Comment:** 

> **TL;DR:** 本文提出了城市情境学习（Urban In-Context Learning），一个通过掩码自编码过程统一预训练和推理的框架，用于城市画像预测，并引入了城市掩码扩散Transformer和城市表示对齐机制，实验表明其性能优于现有的两阶段方法。

**AI_Comments:** 该论文的创新点在于将GPT风格的单阶段学习范式引入到城市画像领域，并通过引入掩码扩散模型来解决城市数据与语言数据结构差异的挑战，实现了预测结果的分布化表示，而非单一确定值，这对于不确定性建模具有重要意义。同时，提出的表示对齐机制也有效稳定了训练过程。这项工作为城市数据分析提供了一个新的、更高效的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的城市画像方法通常采用两阶段范式（学习表示后进行下游预测），但GPT风格模型表明新的自监督预训练方案可以直接应用于下游任务，消除微调需求。然而，城市数据结构与语言不同，难以设计统一预训练和推理的单阶段模型。

**Method:** 本文提出了城市情境学习（Urban In-Context Learning）框架，通过对城市区域进行掩码自编码过程来统一预训练和推理。为了捕捉城市画像的分布，引入了城市掩码扩散Transformer（Urban Masked Diffusion Transformer），使每个区域的预测表示为分布而非确定值。此外，为了稳定扩散训练，提出了城市表示对齐机制（Urban Representation Alignment Mechanism），通过将模型中间特征与经典城市画像方法的特征对齐来正则化模型。

**Result:** 在两个城市的三个指标上进行了广泛实验，结果表明，本文提出的单阶段方法持续优于最先进的两阶段方法。消融研究和案例研究进一步验证了每个模块的有效性，特别是扩散建模的使用。

**Conclusion:** 本文成功提出了一个统一预训练和推理的单阶段城市画像框架，通过引入掩码扩散模型和表示对齐机制，有效解决了城市数据特性带来的挑战，并显著提升了预测性能。

> **ai_Abstract:** 本文提出了一种名为“城市情境学习”（Urban In-Context Learning）的新框架，旨在通过掩码自编码过程统一城市画像的预训练和推理阶段。针对城市数据的独特结构，该框架引入了城市掩码扩散Transformer来建模城市概况的分布，并采用城市表示对齐机制以稳定扩散训练。实验证明，该单阶段方法在多个城市画像任务上显著优于现有两阶段基线方法。

> **摘要翻译:** 城市画像旨在预测未知区域的城市概况，在经济和社会普查中发挥着关键作用。现有方法通常遵循两阶段范式：首先，学习城市区域的表示；其次，通过线性探测进行下游预测，这起源于BERT时代。受GPT风格模型发展的启发，最近的研究表明，新颖的自监督预训练方案可以赋予模型直接应用于下游任务的能力，从而无需针对特定任务进行微调。这主要是因为GPT通过下一词元预测统一了预训练和推理的形式。然而，城市数据表现出与语言根本不同的结构特征，这使得设计一个统一预训练和推理的单阶段模型变得具有挑战性。在这项工作中，我们提出了城市情境学习（Urban In-Context Learning），一个通过对城市区域进行掩码自编码过程来统一预训练和推理的框架。为了捕捉城市画像的分布，我们引入了城市掩码扩散Transformer，它使得每个区域的预测可以表示为分布而不是确定性值。此外，为了稳定扩散训练，我们提出了城市表示对齐机制，通过将模型的中间特征与经典城市画像方法的特征对齐来正则化模型。在两个城市的三个指标上进行的广泛实验表明，我们的单阶段方法始终优于最先进的两阶段方法。消融研究和案例研究进一步验证了每个提出的模块的有效性，特别是扩散建模的使用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [660] [A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning](https://arxiv.org/abs/2508.03046)
> *一种用于利用深度学习早期检测阿尔茨海默氏病的新型多模态框架*

*Tatwadarshi P Nagarhalli, Sanket Patil, Vishal Pande, Uday Aswalekar, Prafulla Patil* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 阿尔茨海默氏病, 早期检测, 多模态学习, 深度学习, MRI

**Comment:** Journal paper, 14 pages

> **TL;DR:** 该研究提出了一种结合MRI、认知评估和生物标志物数据的多模态深度学习框架，用于早期检测阿尔茨海默氏病，提高了诊断的准确性和可靠性。

**AI_Comments:** 该研究提出了一种利用多模态数据和深度学习进行阿尔茨海默氏病早期检测的新方法，具有重要的临床应用潜力。研究中提出的多模态融合策略，特别是在数据不完整情况下的处理能力，是该方法的关键创新点。然而，文章未详细说明加权平均的具体实现方式以及不同模态数据在融合过程中的权重分配依据，这可能影响结果的可复现性。未来的研究可以进一步探索更复杂的融合机制，并进行更大规模的临床验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统诊断方法依赖单一数据模式，未能捕捉阿尔茨海默氏病的复杂性，导致诊断延迟和治疗效果不佳。

**Method:** 提出了一种多模态框架，整合了MRI图像（使用CNN分析）、认知评估和生物标志物数据（使用LSTM分析），并通过加权平均等技术整合多模态结果，即使在数据不完整的情况下也能提高诊断准确性。

**Result:** 该多模态框架提高了诊断的准确性和可靠性，能够及早发现阿尔茨海默氏病，并且在数据不完整的情况下也能正常工作。

**Conclusion:** 该研究提出的多模态框架有潜力彻底改变阿尔茨海默氏病的早期检测，为更及时有效的治疗铺平道路。

> **ai_Abstract:** 本研究提出了一种创新的多模态深度学习框架，用于早期检测阿尔茨海默氏病（AD）。该框架整合了MRI成像、认知评估和生物标志物数据，并利用CNN和LSTM网络进行分析。通过先进的融合技术，即使在数据不完整的情况下，该框架也能提高诊断的准确性和可靠性，并能在出现临床症状前实现早期检测，为及时干预和改善患者预后提供了可能。

> **摘要翻译:** 阿尔茨海默氏病（AD）是一种进行性神经退行性疾病，其早期诊断面临重大挑战，常常导致治疗延迟和患者预后不良。传统的诊断方法通常依赖于单一数据模式，未能捕捉到该疾病的多方面性质。在本文中，我们提出了一种用于AD早期检测的新型多模态框架，整合了来自三个主要来源的数据：MRI成像、认知评估和生物标志物。该框架采用卷积神经网络（CNN）分析MRI图像，并采用长短期记忆（LSTM）网络处理认知和生物标志物数据。该系统通过使用加权平均等先进技术聚合来自这些不同模式的结果，即使在数据不完整的情况下也能提高诊断的准确性和可靠性。多模态方法不仅提高了检测过程的鲁棒性，而且能够在疾病的最早阶段识别AD，与传统方法相比具有显著优势。生物标志物和认知测试的整合尤为重要，因为它们可以在临床症状出现之前很久就能检测到阿尔茨海默氏症，从而促进早期干预，并有可能改变疾病的进程。本研究表明，所提出的框架有潜力彻底改变AD的早期检测，为更及时有效的治疗铺平道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [661] [Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems](https://arxiv.org/abs/2508.02887)
> *用于混合电力电子系统Sim2Real边缘数字孪生的物理嵌入式神经ODE*

*Jialin Zheng, Haoyu Wang, Yangbin Zeng, Di Mou, Xin Zhang, Hong Li, Sergio Vazquez, Leopoldo G. Franquelo* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 物理嵌入式神经ODE, 边缘数字孪生, 电力电子系统, 混合动态, Sim-to-Real

**Comment:** 

> **TL;DR:** 本文提出了一种物理嵌入式神经ODE（PENODE），通过嵌入事件自动机和注入已知ODE分量来解决电力电子系统边缘数字孪生中混合动态建模的挑战，实现了更高的准确性、更少的神经元和高效的边缘部署。

**AI_Comments:** 该论文的创新点在于将物理嵌入式神经ODE（PENODE）应用于电力电子系统的边缘数字孪生，通过结合事件自动机和神经ODE来有效处理连续演变的混合动态。这种方法不仅提高了Sim-to-Real的泛化能力，还在资源受限的边缘设备上实现了高效部署，同时保持了物理可解释性，对于工业物联网和实时控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有建模方法难以持续捕获电力电子系统（PES）固有的连续演变的混合动态，这会降低资源受限边缘设备上的Sim-to-Real泛化能力。为了解决这些挑战，本文提出了PENODE。

**Method:** 本文提出了一种物理嵌入式神经ODE（PENODE），该方法（i）将混合操作机制嵌入为事件自动机以明确控制离散切换，并且（ii）将已知的控制ODE分量直接注入到未建模动态的神经参数化中。这种统一设计产生了一个可微分的端到端可训练架构，该架构在保持物理可解释性的同时减少了冗余，并支持用于高效FPGA部署的云到边缘工具链。

**Result:** 实验结果表明，PENODE在白盒、灰盒和黑盒场景的基准测试中实现了显著更高的精度，同时神经元数量减少了75%。

**Conclusion:** 所提出的PENODE保持了物理可解释性、高效的边缘部署和实时控制增强。

> **ai_Abstract:** 本文针对电力电子系统（PES）边缘数字孪生（EDTs）中混合动态建模的挑战，提出了一种物理嵌入式神经ODE（PENODE）。PENODE通过将混合操作机制嵌入为事件自动机并直接注入已知ODE分量来解决现有方法的不足。该统一设计实现了可微分的端到端可训练架构，既保留了物理可解释性又减少了冗余，并支持高效的FPGA部署。实验证明，PENODE在不同场景下均显著提高了精度，同时大幅减少了神经元数量，验证了其在物理可解释性、边缘部署效率和实时控制增强方面的优势。

> **摘要翻译:** 边缘数字孪生（EDTs）对于电力电子系统（PES）的监测和控制至关重要。然而，现有建模方法难以持续捕获PES中固有的连续演变的混合动态，这会降低资源受限边缘设备上的Sim-to-Real泛化能力。为了解决这些挑战，本文提出了一种物理嵌入式神经ODE（PENODE），该方法（i）将混合操作机制嵌入为事件自动机以明确控制离散切换，并且（ii）将已知的控制ODE分量直接注入到未建模动态的神经参数化中。这种统一设计产生了一个可微分的端到端可训练架构，该架构在保持物理可解释性的同时减少了冗余，并支持用于高效FPGA部署的云到边缘工具链。实验结果表明，PENODE在白盒、灰盒和黑盒场景的基准测试中实现了显著更高的精度，同时神经元数量减少了75%，这验证了所提出的PENODE保持了物理可解释性、高效的边缘部署和实时控制增强。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [670] [Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs](https://arxiv.org/abs/2507.10595)
> *分而治之：一种面向属性缺失图的聚类驱动分层插值器*

*Yaowen Hu, Wenxuan Tu, Yue Liu, Miaomiao Li, Wenpeng Lu, Zhigang Luo, Xinwang Liu, Ping Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 深度图聚类, 属性缺失图, 分层插值, 聚类驱动, 图补全

**Comment:** 

> **TL;DR:** 提出了一种名为DTRGC的新方法，用于解决属性缺失图的深度图聚类问题。该方法通过分层插值和利用聚类信息来改进节点属性的填充，并在多个数据集上证明了其有效性。

**AI_Comments:** 该研究提出了一种新颖的分层插值方法来解决属性缺失图的深度图聚类问题，特别关注了邻域信息不足的节点。方法论（DCFP、HNAI、HRE）的结合以及利用聚类结构进行错误修正的思路具有创新性。实验结果令人信服，但对不同类型图结构和缺失模式的泛化能力仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的属性缺失图插值方法未能充分考虑节点邻域信息的可用性差异，导致结果不可靠，尤其是在邻域信息不足的节点上。

**Method:** 提出了一种名为DTRGC的新方法，该方法首先处理具有足够邻域信息的节点，然后利用聚类信息迭代地填充更难的节点。具体包括动态聚类感知特征传播（DCFP）、分层邻域感知插值（HNAI）以及逐跳表示增强（HRE）。

**Result:** DTRGC在六个广泛使用的图数据集上进行了实验，结果表明该方法在属性缺失图的深度图聚类任务上显著提高了多种DGC方法的性能。

**Conclusion:** DTRGC通过分层插值和利用聚类信息来处理属性缺失图，有效解决了现有方法的局限性，并在深度图聚类任务中取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为DTRGC的新方法，用于解决属性缺失图的深度图聚类问题。该方法通过动态聚类感知特征传播（DCFP）初始化节点属性，利用分层邻域感知插值（HNAI）优先处理邻域信息更完整的节点，并结合聚类结构进行错误修正，最后通过逐跳表示增强（HRE）提升节点表示。实验证明DTRGC在多个数据集上显著优于现有方法。

> **摘要翻译:** 深度图聚类（DGC）是一种针对属性缺失图的无监督任务，旨在将具有不完整属性的节点划分为不同的簇。解决这一具有挑战性的问题对于实际应用至关重要。然而，该领域的研究仍未得到充分探索。现有属性缺失图的插值方法往往未能充分考虑节点邻域信息可用量的差异，导致结果不可靠，尤其是在邻域信息不足的节点上。为了解决这个问题，我们提出了一种名为Divide-Then-Rule Graph Completion（DTRGC）的新方法。该方法首先处理具有足够邻域信息的节点，并将插值结果作为新知识来迭代地填充更具挑战性的节点，同时利用聚类信息来纠正插值错误。具体而言，动态聚类感知特征传播（DCFP）通过基于聚类结构调整传播权重来初始化缺失的节点属性。随后，分层邻域感知插值（HNAI）根据节点邻域属性的完整性，将属性缺失节点分为三类。插值是分层进行的，优先处理具有最多可用邻域信息的节点类别。然后，利用聚类结构来优化插值并纠正潜在的错误。最后，逐跳表示增强（HRE）整合了多跳信息，从而增强了节点表示的表达能力。在六个广泛使用的图数据集上的实验结果表明，DTRGC在属性缺失图的各种DGC方法方面显著提高了聚类性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [678] [Achieving Limited Adaptivity for Multinomial Logistic Bandits](https://arxiv.org/abs/2508.03072)
> *实现多项逻辑老虎机的有限适应性*

*Sukruta Prakash Midigeshi, Tanmay Goyal, Gaurav Sinha* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 多项逻辑老虎机, 有限适应性, 遗憾最小化, 分布最优设计, 批处理, 很少切换

**Comment:** Accepted to RLC 2025

> **TL;DR:** 该研究提出了两种多项逻辑老虎机算法（B-MNL-CB和RS-MNL），它们能在有限的策略更新次数下实现最优的遗憾界限，并在实验中表现出与需要每轮更新的现有算法相当甚至更好的性能。

**AI_Comments:** 该研究在多项逻辑老虎机领域取得了重要进展，特别是在有限适应性方面。提出的两种算法在理论上实现了最优遗憾界限，并在实践中表现出良好的性能。然而，算法的复杂性和在不同实际场景下的具体性能表现仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中的应用场景需要能够处理多个可能结果的问题，并且允许有限次数的策略更新，以提高算法的实用性。现有的多项逻辑老虎机算法虽然在遗憾和计算效率上表现优异，但缺乏在有限更新次数下的适应性。

**Method:** 研究提出了两种算法：B-MNL-CB，适用于批处理设置，通过将分布最优设计扩展到多项设置，在随机上下文生成的情况下，只需要对数对数T的更新轮次即可达到O(sqrt(T))的遗憾界限；RS-MNL，适用于很少切换的设置，在对抗性上下文生成的情况下，只需要O(log T)的策略更新即可达到O(sqrt(T))的遗憾界限。

**Result:** B-MNL-CB算法在随机上下文生成且更新轮次为log log T时，遗憾界限达到O(sqrt(T))。RS-MNL算法在对抗性上下文生成且策略更新为O(log T)时，遗憾界限也达到O(sqrt(T))。实验结果表明，与每轮都更新策略的现有算法相比，该研究提出的算法在固定策略更新次数的情况下具有竞争力，甚至更优。

**Conclusion:** 该研究成功提出了两种能在有限策略更新次数下实现最优遗憾界限的多项逻辑老虎机算法，并在实验中证明了其在实际应用中的有效性和竞争力。

> **ai_Abstract:** 本研究针对多项逻辑老虎机问题，提出了两种具有有限适应性的新算法：B-MNL-CB和RS-MNL。B-MNL-CB适用于批处理场景，通过扩展分布最优设计实现了对数对数T更新下的O(sqrt(T))遗憾界限。RS-MNL适用于很少切换的场景，在对抗性上下文下通过O(log T)更新实现了O(sqrt(T))遗憾界限。实验证明，这些算法在固定更新次数下性能优越，适用于实际应用。

> **摘要翻译:** 多项逻辑老虎机近来因其能够模拟具有多个结果的问题而备受关注。在此设定中，每个决策都与许多可能的、用多项logit函数建模的结果相关联。关于多项逻辑老虎机的几项近期工作同时实现了最优遗憾和计算效率。然而，受到现实世界挑战和实用性的驱动，有必要开发具有有限适应性的算法，即只允许进行M次策略更新。为了应对这些挑战，我们提出了两种算法，B-MNL-CB和RS-MNL，它们分别在批处理和很少切换的范式下运行。批处理设置涉及在算法开始时选择M次策略更新轮次，而很少切换的设置可以以自适应的方式选择这M次策略更新轮次。我们的第一种算法B-MNL-CB将分布最优设计的概念扩展到多项设置，并在给定Ω(log log T)更新轮次且上下文随机生成的情况下，实现了O(sqrt(T))的遗憾。我们的第二种算法RS-MNL适用于对抗性生成的上下文，并且在有O(log T)次策略更新的情况下可以实现O(sqrt(T))的遗憾。此外，我们进行的实验表明，我们的算法（具有固定次数的策略更新）与几种最先进的基线（它们每轮都更新其策略）相比具有极高的竞争力（并且通常更好），证明了我们的算法在各种实际场景中的适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [687] [ECGTwin: Personalized ECG Generation Using Controllable Diffusion Model](https://arxiv.org/abs/2508.02720)
> *ECGTwin：使用可控扩散模型生成个性化心电图*

*Yongfan Lai, Bo Liu, Xinyan Guan, Qinghao Zhao, Hongyan Li, Shenda Hong* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 个性化心电图, 数字孪生, 可控扩散模型, 对比学习, AdaX条件注入器

**Comment:** 

> **TL;DR:** ECGTwin是一个两阶段框架，利用对比学习提取个体特征，并通过AdaX条件注入器将目标心脏病症与扩散模型相结合，用于生成个性化心电图，可实现高保真度、多样性和精细控制，并有潜力改进ECG自动诊断。

**AI_Comments:** 该研究提出了一种名为ECGTwin的新框架，用于生成个性化心电图，解决了现有方法在提取个体特征和注入条件信息方面的挑战。利用对比学习和扩散模型相结合的方法具有创新性。然而，实际应用中的模型稳定性和对不同心脏病症的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 个性化心电图（ECG）生成旨在模拟患者特定的ECG数字孪生，以实现更准确的个体化医疗模式，但面临从无真实数据中提取个体特征以及在不混淆生成模型的情况下注入条件信息的挑战。

**Method:** ECGTwin采用两阶段框架：第一阶段通过对比学习训练的个体基础提取器提取参考ECG中的个人特征；第二阶段，提取的个人特征与目标心脏病症通过新颖的AdaX条件注入器集成到基于扩散模型的生成过程中，通过两个专用通道注入信号。

**Result:** ECGTwin能够生成高保真度、多样性并具有精细控制能力的心电图信号，同时保留个体特征。此外，ECGTwin在下游应用中显示出增强ECG自动诊断的潜力。

**Conclusion:** ECGTwin通过其两阶段框架和AdaX条件注入器，成功解决了个性化ECG生成中的关键挑战，证明了其在实现精确个性化医疗解决方案方面的能力，特别是在增强ECG自动诊断方面。

> **ai_Abstract:** ECGTwin是一个创新的两阶段框架，用于生成个性化心电图。它利用对比学习从参考ECG中提取个体特征，并通过新颖的AdaX条件注入器将这些特征与特定心脏病症相结合，以控制扩散模型进行生成。该模型在生成高保真度、多样化且具有个体特征保留能力的心电图方面表现出色，并有望改进ECG自动诊断，为个性化医疗铺平道路。

> **摘要翻译:** 个性化心电图（ECG）生成旨在模拟患者特定的ECG数字孪生，以适应特定条件。它有潜力将传统医疗转变为更准确的个体化范式，同时保留传统群体级ECG合成的关键优势。然而，这项有前途的任务带来了两个基本挑战：在没有真实数据的情况下提取个体特征，以及在不混淆生成模型的情况下注入各种类型的条件。在本文中，我们提出了ECGTwin，这是一个旨在解决这些挑战的两阶段框架。在第一阶段，通过对比学习训练的个体基础提取器能够从参考ECG中提取个人特征。在第二阶段，通过我们新颖的AdaX条件注入器将提取的个人特征与目标心脏病症集成到基于扩散模型的生成过程中，该注入器通过两个专用且专业的通道注入这些信号。定性和定量实验均表明，我们的模型不仅可以通过提供精细的生成可控性来生成高保真度和多样性的ECG信号，而且还能保留个体特征。此外，ECGTwin在增强下游应用中的ECG自动诊断方面显示出潜力，证实了精确个性化医疗解决方案的可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [692] [Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov-Based Analysis](https://arxiv.org/abs/2508.03105)
> *加速SGDM的学习率和批量大小调度：基于Lyapunov的分析*

*Yuichi Kondo, Hideaki Iiduka* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** SGDM, 学习率调度, 批量大小调度, Lyapunov函数, 收敛性

**Comment:** 

> **TL;DR:** 该研究提出了一种新的Lyapunov函数来分析具有动态学习率和批量大小调度的SGDM收敛性，发现增加批量大小（无论学习率如何）都能保证收敛，并且增加批量大小和增加学习率的组合收敛速度最快。

**AI_Comments:** 该研究在理论上为理解和优化SGDM的训练过程提供了新的视角，特别是通过Lyapunov函数分析动态调度策略的有效性。其研究结果具有重要的实践意义，为深度学习模型的训练提供了具体的指导。然而，研究中提到的预热调度在实验中表现最佳，但其理论分析并未在摘要中详细说明，这可能是未来研究的一个方向。

<details>
  <summary>Details</summary>

**Motivation:** 分析具有动态学习率和批量大小调度的随机梯度下降（SGDM）的收敛行为，并为设计高效稳定的深度学习训练过程提供理论基础和实践指导。

**Method:** 引入了一个新的、结构更简单的Lyapunov函数来分析SGDM在不同动态调度策略下的收敛性，包括恒定批量大小和衰减学习率、增加批量大小和衰减学习率、以及增加批量大小和增加学习率这三种策略。

**Result:** 研究表明，增加批量大小（策略ii和iii）可以保证期望梯度范数的收敛，而恒定批量大小（策略i）则不能。策略iii（增加批量大小和增加学习率）比策略i和ii具有更快的收敛速度。实验结果也证实了动态调度SGDM比固定超参数基线具有更快的收敛速度，并且预热调度在实验中表现最佳。

**Conclusion:** 该研究提出了一个统一的理论框架，为理解和设计动态学习率和批量大小调度在SGDM中的应用提供了理论基础和实践指导，证明了动态调度可以加速收敛并提高训练稳定性。

> **ai_Abstract:** 本研究提出了一种新的Lyapunov函数，用于分析具有动态学习率和批量大小调度的SGDM的收敛性。研究发现，增加批量大小的调度策略（包括增加批量大小与衰减学习率，以及增加批量大小与增加学习率）能够保证收敛，并且后者具有更快的收敛速度。实验结果也验证了动态调度策略的优越性，尤其是一种预热调度在实践中表现最佳。

> **摘要翻译:** 我们通过引入一个新的Lyapunov函数来分析随机梯度下降（SGDM）在动态学习率和批量大小调度下的收敛行为。这个Lyapunov函数与现有的相比结构更简单，有助于SGDM的收敛性分析，并能统一分析各种动态调度。具体来说，我们将理论框架扩展到涵盖深度学习中常用的三种实用调度策略：（i）恒定批量大小和衰减学习率，（ii）增加批量大小和衰减学习率，以及（iii）增加批量大小和增加学习率。我们的理论结果揭示了收敛行为的明确层次：虽然（i）不能保证期望梯度范数的收敛，但（ii）和（iii）都可以。此外，（iii）实现了比（i）和（ii）可证明更快的衰减率，即使在动量存在的情况下也实现了理论加速。实证结果验证了我们的理论，表明动态调度的SGDM在收敛速度上显著优于固定的超参数基线。我们还在实验中评估了一种预热调度，该调度在实验中表现优于所有其他策略的收敛行为。这些发现为设计现代深度学习中高效且稳定的训练过程提供了统一的理论基础和实践指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [701] [Set-Based Training for Neural Network Verification](https://arxiv.org/abs/2401.14961)
> *基于集合的神经网络验证训练*

*Lukas Koller, Tobias Ladner, Matthias Althoff* | **Category: cs.LG, cs.CR, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 神经网络验证,鲁棒性,对抗性攻击,集合训练,形式验证

**Comment:** published at Transactions on Machine Learning Research (TMLR)

> **TL;DR:** 通过计算输入和输出的集合以及梯度集合，减少输出包络，从而提高神经网络的鲁棒性并简化其形式验证。

**AI_Comments:** 该研究提出了一种新颖的基于集合的训练方法，解决了神经网络在安全关键应用中的鲁棒性和可验证性问题。通过引入梯度集合的概念来优化输出包络，为提高神经网络的可靠性提供了一种有前景的途径。该方法在简化形式验证方面具有重要意义，因为许多验证方法对输入集合的大小敏感。未来的工作可以探索该方法在不同网络架构和更复杂验证场景下的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了确保神经网络在安全关键环境中的安全性，必须对其鲁棒性进行形式验证，以抵抗输入扰动。提高神经网络的鲁棒性可以简化其形式验证过程。

**Method:** 提出了一种新颖的基于集合的训练程序，该程序计算给定输入集合的可能输出集合，并计算梯度集合，其中每个可能的输出都有不同的梯度。通过选择指向中心梯度的方向来减小输出包络的大小。

**Result:** 基于集合的训练能够生成具有竞争性性能的鲁棒神经网络，并且由于输出集减小，可以使用快速（多项式时间）验证算法对其进行验证。

**Conclusion:** 基于集合的训练方法可以生成鲁棒且易于验证的神经网络，从而在安全关键应用中具有实际意义。

> **ai_Abstract:** 本研究提出了一种基于集合的训练方法，通过计算输入和输出的集合以及梯度集合，有效减小了神经网络的输出包络。这种方法不仅提高了神经网络对输入扰动的鲁棒性，还显著简化了其形式验证过程，使得使用高效的验证算法成为可能。实验结果表明，该方法生成的神经网络在保持性能的同时，鲁棒性和可验证性均得到提升。

> **摘要翻译:** 神经网络容易受到对抗性攻击，即微小的输入扰动会显著影响神经网络的输出。因此，为了确保神经网络在安全关键环境中的安全性，必须对其鲁棒性进行形式验证，以抵抗输入扰动，例如来自噪声传感器的扰动。为了提高神经网络的鲁棒性，从而简化形式验证，我们提出了一种新颖的基于集合的训练程序，在该程序中，我们计算给定输入集合的可能输出集合，并首次计算梯度集合，即每个可能的输出都有不同的梯度。因此，我们可以通过选择指向其中心的梯度来直接减小输出包络的大小。小的输出包络可以提高神经网络的鲁棒性，同时简化其形式验证。后者的好处是，传播集合的大小越大，大多数验证方法的保守性就越大。我们广泛的评估表明，基于集合的训练能够生成具有竞争性性能的鲁棒神经网络，并且由于输出集减小，可以使用快速（多项式时间）验证算法对其进行验证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [704] [Filtering with Self-Attention and Storing with MLP: One-Layer Transformers Can Provably Acquire and Extract Knowledge](https://arxiv.org/abs/2508.00901)
> *使用自注意力进行过滤和使用MLP进行存储：单层Transformer可被证明获得和提取知识*

*Ruichen Xu, Kexin Chen* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-05**

**Keywords:** Transformer, 知识获取, 知识提取, MLP, 自注意力

**Comment:** 

> **TL;DR:** 该研究提出了一个单层Transformer框架，结合了自注意力和MLP模块，并从理论上证明了其在知识获取和提取方面的能力，同时分析了不同微调策略的影响，并通过实验验证了其有效性。

**AI_Comments:** 该研究在理论上为理解Transformer的知识处理机制提供了重要见解，特别是在整合MLP模块方面。然而，模型仅限于单层，这与实际应用中的多层Transformer存在差距，其理论结果在更复杂的架构上的普适性有待进一步验证。此外，对“数据多重性条件”的界定和影响的深入分析将有助于更好地指导实践。

<details>
  <summary>Details</summary>

**Motivation:** 理解Transformer在预训练中如何获取和存储知识，以及在微调推理中如何提取知识，这在理论上仍然不清楚。现有理论工作仅限于单层、仅注意力架构，而MLP被认为是知识存储的关键。然而，简化的模型可能无法获取或提取事实知识。

**Method:** 提出一个包含自注意力和MLP模块的单层Transformer框架，并通过追踪其梯度动态来建立收敛性和泛化性保证，从而阐明知识的获取和提取能力。分析了全参数微调和低秩微调。

**Result:** 1) Transformer在预训练中可实现接近最优的训练损失，表明知识获取有效；2) 在满足特定数据条件和大量微调数据集的情况下，Transformer在仅在预训练中学到但未在微调中加强的事实知识上可实现低泛化误差，表明知识提取成功；3) 当条件不满足时，Transformer表现出高泛化损失，导致幻觉。分析还为学习率调度等现象提供了理论见解。

**Conclusion:** 单层Transformer框架通过结合自注意力和MLP模块，能够有效地获取和提取知识，并且其性能受微调策略和数据条件的影响，这为理解和改进大型语言模型提供了理论基础。

> **ai_Abstract:** 本研究提出了一种新颖的单层Transformer框架，该框架整合了自注意力和MLP模块，旨在解决大型语言模型在知识获取和提取方面的理论不透明性。研究人员通过追踪梯度动态，从理论上证明了该模型能够有效获取和提取知识，并分析了在不同微调策略和数据条件下模型性能的变化，包括可能出现的幻觉现象。实验结果表明，该框架在处理知识密集型任务时具有潜力。

> **摘要翻译:** 现代大型语言模型在知识密集型任务中表现出色，但Transformer在预训练期间如何获取（存储）知识以及在微调推理期间如何提取（检索）知识，在理论上仍然不透明。尽管以往的理论工作已开始通过分析训练动态来探讨这些问题，但此类研究仅限于单层、仅注意力架构。然而，大多数现有研究表明，MLP是Transformer类语言模型中存储知识的最有贡献的组成部分。与此同时，我们的实证研究表明，这些简化的模型，在采用标准的下一个词预测目标进行训练时，可能无法获取或提取事实知识。为了克服这一限制，我们引入了一个易于处理的单层Transformer框架，该框架关键地结合了自注意力（self-attention）和MLP模块。通过追踪其梯度动态，我们建立了收敛性和泛化性保证，阐明了知识获取和提取的能力。我们证明了1）Transformer在预训练期间可以实现接近最优的训练损失，这标志着有效的知识获取；2）在满足大量微调数据集和特定的数据多重性条件的情况下，Transformer在仅在预训练期间学习到但在微调期间未得到加强的事实知识上可以实现低泛化误差，这表明了成功的知识提取；3）当条件不满足时，Transformer表现出高泛化损失，导致产生幻觉。我们的分析包括全参数微调和低秩微调。此外，我们的分析为学习率调度等几个相关的经验现象提供了理论见解。实验在合成和真实世界的PopQA数据集上，使用GPT-2和Llama-3.2-1B进行了验证，证实了我们的结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [706] [RegMean++: Enhancing Effectiveness and Generalization of Regression Mean for Model Merging](https://arxiv.org/abs/2508.03121)
> *RegMean++：增强回归均值在模型合并中的有效性和泛化能力*

*The-Hai Nguyen, Dang Huu-Tien, Takeshi Suzuki, Le-Minh Nguyen* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 模型合并, 回归均值, 层内依赖性, 跨层依赖性, 泛化能力

**Comment:** 17 pages, 11 figures, 11 tables

> **TL;DR:** RegMean++ 通过考虑层内和跨层依赖性改进了模型合并，在各种设置下均优于 RegMean。

**AI_Comments:** RegMean++ 的创新之处在于它将层内和跨层依赖性纳入模型合并的框架中，解决了 RegMean 独立处理各层的局限性。这种方法在理论上更符合信息在神经网络中传播的实际情况，并且在实践中获得了显著的性能提升。然而，计算这些依赖性可能会增加额外的计算成本，尽管作者声称其效率，但其在非常大规模模型上的实际扩展性仍有待进一步验证。该研究对于模型合并领域具有重要意义，为提高合并模型性能提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的 RegMean 方法独立合并模型的线性层，忽略了信息在层间的传播和影响，这限制了其合并效果。

**Method:** RegMean++ 是一种新的模型合并方法，它通过将层内和跨层依赖性纳入目标函数来改进 RegMean，从而更准确地捕捉合并模型的行为。

**Result:** RegMean++ 在各种设置下（包括域内和域外泛化、顺序合并、大规模任务和分布变化下的鲁棒性）持续优于 RegMean，并且在与先进的模型合并方法相比时，表现出具有竞争力的或最先进的性能。

**Conclusion:** RegMean++ 通过整合层间依赖性，在模型合并方面取得了显著的改进，在各种评估指标和场景下都优于 RegMean 和其他先进方法。

> **ai_Abstract:** 本文提出 RegMean++，一种改进的 RegMean 模型合并方法，通过显式考虑层内和跨层依赖性来增强合并模型的有效性和泛化能力。实验证明 RegMean++ 在多项任务和分布变化下均优于 RegMean 及其他先进方法。

> **摘要翻译:** 回归均值（RegMean）是一种将模型合并表述为线性回归问题的方​​法，旨在通过最小化合并模型与候选模型之间预测的差异来找到合并模型中每个线性层的最优权重。RegMean 为合并问题提供了精确的闭式解；因此，它提供了可解释性和计算效率。然而，RegMean 独立地合并每个线性层，忽略了早期层中的特征和信息如何通过各层传播并影响合并模型中的最终预测。在本文中，我们引入了 RegMean++，它是 RegMean 的一种简单而有效的替代方案，它将合并模型层之间的层内和跨层依赖性明确地纳入 RegMean 的目标中。通过考虑这些依赖性，RegMean++ 更好地捕捉了合并模型的行为。广泛的实验表明，RegMean++ 在各种设置下持续优于 RegMean，包括域内（ID）和域外（OOD）泛化、顺序合并、大规模任务以及在几种类型的分布变化下的鲁棒性。此外，RegMean++ 与各种最近先进的模型合并方法相比，取得了具有竞争力的或最先进的性能。我们的代码可在 https://github.com/nthehai01/RegMean-plusplus 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [719] [Unveiling Location-Specific Price Drivers: A Two-Stage Cluster Analysis for Interpretable House Price Predictions](https://arxiv.org/abs/2508.03156)
> *揭示特定地点的价格驱动因素：用于可解释房价预测的两阶段聚类分析*

*Paul Gümmer, Julian Rosenberger, Mathias Kraus, Patrick Zschech, Nico Hambauer* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 房价预测, 两阶段聚类, 可解释性, 局部市场差异, 广义加性模型

**Comment:** Accepted at 20th International Conference on Wirtschaftsinformatik
  (WI25); September 2025, M\"unster, Germany

> **TL;DR:** 该研究提出了一种两阶段聚类方法，结合线性回归或广义加性模型来提高房价预测的准确性和可解释性，特别是在处理局部市场差异时。

**AI_Comments:** 该研究有效地解决了房价预测中的可解释性和局部市场差异问题。两阶段聚类方法与 GAM 或 LR 的结合，在提高预测准确性的同时，也增强了模型的透明度。该研究的局限性可能在于聚类过程对初始位置特征选择的敏感性，以及在不同地理区域或房地产市场类型上的泛化能力。未来的工作可以探索更复杂的聚类算法或集成方法，以进一步提高模型的鲁棒性和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的房价评估方法要么依赖于缺乏可解释性的黑箱机器学习模型，要么依赖于无法捕捉市场异质性的简单线性回归模型。

**Method:** 该研究提出了一种机器学习方法，采用两阶段聚类。首先，基于最少的基于位置的特征对房产进行分组，然后纳入其他特征。接着，使用线性回归或广义加性模型对每个集群进行建模。

**Result:** 与不使用聚类的模型相比，该方法在平均绝对误差方面分别使广义加性模型提高了 36%，使线性回归模型提高了 58%。此外，图形分析揭示了集群之间的模式变化。

**Conclusion:** 该研究强调了特定于集群的见解的重要性，这些见解可以提高可解释性，并为寻求更可靠的房产估值的买家、卖家和房地产分析师提供实用价值。

> **ai_Abstract:** 该研究提出了一种两阶段聚类方法，用于提高房价预测的准确性和可解释性。通过首先根据位置特征对房产进行分组，然后为每个集群应用线性回归或广义加性模型，该方法在德国房产数据上实现了显著的平均绝对误差改进（GAM 为 36%，LR 为 58%），并揭示了集群间的模式差异，从而为房地产市场参与者提供了更可靠的估值。

> **摘要翻译:** 房价估值因局部市场差异而保持挑战性。现有方法通常依赖于缺乏可解释性的黑箱机器学习模型，或者像线性回归（LR）这样无法捕捉市场异质性的简化方法。为了解决这个问题，我们提出了一种机器学习方法，该方法采用两阶段聚类，首先基于最少的基于位置的特征对房产进行分组，然后再纳入其他特征。然后，使用 LR 或广义加性模型（GAM）对每个集群进行建模，在预测性能和可解释性之间取得平衡。通过在 2023 年对 43,309 处德国房产挂牌信息进行构建和评估，与不进行聚类的模型相比，我们使 GAM 的平均绝对误差提高了 36%，使 LR 提高了 58%。此外，图形分析揭示了集群之间的模式变化。这些发现强调了特定于集群的见解的重要性，提高了可解释性，并为寻求更可靠的房产估值的买家、卖家和房地产分析师提供了实用价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [733] [Overcoming Algorithm Aversion with Transparency: Can Transparent Predictions Change User Behavior?](https://arxiv.org/abs/2508.03168)
> *克服算法厌恶：透明度能否改变用户行为？*

*Lasse Bohlen, Sven Kruschel, Julian Rosenberger, Patrick Zschech, Mathias Kraus* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 算法厌恶,透明度,可解释性,用户行为,机器学习

**Comment:** Accepted at 20th International Conference on Wirtschaftsinformatik
  (WI25); September 2025, M\"unster, Germany

> **TL;DR:** 用户可以通过调整算法预测来减少对算法的厌恶，但透明度对减少算法厌恶的效果不如预期，并且与可调整性是独立的影响。

**AI_Comments:** 该研究探讨了透明度和可调整性在减少算法厌恶方面的作用，结果表明透明度的效果不如预期，这可能为未来的研究提供了新的方向，例如探索更有效的透明度机制或在特定场景下应用透明度。

<details>
  <summary>Details</summary>

**Motivation:** 在用户不了解模型推理过程的情况下，允许用户调整机器学习模型的预测可以减少对算法的厌恶。然而，尚不清楚可解释的机器学习模型是否能进一步减少算法厌恶，或者使调整功能变得不必要。

**Method:** 通过一项包含280名参与者的预注册用户研究，对一项关于可调整预测对算法厌恶影响的现有研究进行了概念复制和扩展，引入了一个可视化决策逻辑的可解释机器学习模型，以研究透明度与可调整性在减少算法决策厌恶方面的相互作用。

**Result:** 研究结果证实了可调整性对减轻算法厌恶有显著效果，允许用户修改算法预测可以减轻他们的厌恶。然而，透明度对减轻算法厌恶的影响低于预期，并且在本次研究的样本中未达到显著性水平。此外，透明度和可调整性的影响似乎比预期的更为独立。

**Conclusion:** 虽然允许用户调整算法预测可以减轻对算法的厌恶，但提高算法的透明度（通过可视化决策逻辑）对减轻算法厌恶的效果不如预期，并且与可调整性相比，其影响较小且相对独立。

> **ai_Abstract:** 本研究旨在探讨提高机器学习模型透明度是否能像允许用户调整模型预测一样，有效减少用户对算法的厌恶感。通过用户研究发现，允许用户调整模型预测确实能减轻算法厌恶，但提高模型透明度的效果不如预期，且与调整功能的作用相对独立。

> **摘要翻译:** 先前的工作表明，允许用户调整机器学习（ML）模型的预测可以减少对不完美算法决策的厌恶。然而，这些结果是在用户不了解模型推理过程的情况下获得的。因此，目前尚不清楚可解释的机器学习模型是否能进一步减少算法厌恶，甚至使可调整性变得不必要。在本研究中，我们对一项检验可调整预测对算法厌恶影响的著名研究进行了概念复制，并通过引入一个可视化决策逻辑的可解释机器学习模型对其进行了扩展。通过一项包含280名参与者的预注册用户研究，我们调查了透明度与可调整性在减少算法决策厌恶方面的相互作用。我们的结果复制了可调整性效应，表明允许用户修改算法预测可以减轻厌恶。透明度的影响似乎低于预期，并且在我们研究的样本中不显著。此外，透明度和可调整性的影响似乎比预期的更为独立。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [745] [Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility](https://arxiv.org/abs/2507.17748)
> *大学习率同时实现对伪相关和可压缩性的鲁棒性*

*Melih Barsbey, Lucas Prieto, Stefanos Zafeiriou, Tolga Birdal* | **Category: cs.LG, cs.AI, cs.CV, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 高学习率, 伪相关性, 模型鲁棒性, 网络压缩, 资源效率

**Comment:** Accepted at ICCV 2025, 25 pages

> **TL;DR:** 研究表明，高学习率有助于提高模型对伪相关和网络压缩的鲁棒性。

**AI_Comments:** 该研究首次提出并证明了高学习率在同时实现模型鲁棒性和资源效率方面的潜力，为模型优化提供了新的视角。研究结果具有重要的理论和实践意义，但需要进一步探索高学习率在不同模型架构和更复杂任务中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 在现代机器学习模型中，鲁棒性和资源效率是两个非常理想的特性，但要同时实现它们仍然是一个挑战。

**Method:** 通过实验证明，高学习率可以促进对伪相关和网络压缩的鲁棒性，并产生理想的表示特性，如不变特征利用、类别分离和激活稀疏性。

**Result:** 高学习率在满足这些特性方面优于其他超参数和正则化方法，并且在各种伪相关数据集、模型和优化器中都表现良好。

**Conclusion:** 高学习率是实现模型鲁棒性和资源效率的关键因素，并且其在标准分类任务中的成功可能与解决训练数据中隐藏/罕见的伪相关有关。

> **ai_Abstract:** 本研究发现，高学习率能够同时提升机器学习模型在处理伪相关性方面的鲁棒性以及模型的压缩性。研究表明，高学习率还能带来不变特征利用、类别分离和激活稀疏性等理想的表示特性，并且在这些方面优于其他超参数和正则化方法。此外，研究还指出，高学习率在标准分类任务中的成功可能与解决训练数据中隐藏的伪相关性有关。

> **摘要翻译:** 鲁棒性和资源效率是现代机器学习模型两个非常理想的特性。然而，同时实现它们仍然是一个挑战。在本论文中，我们将高学习率确定为同时实现对伪相关和网络可压缩性的鲁棒性的促进因素。我们证明，高学习率也能产生理想的表示特性，如不变特征利用、类别分离和激活稀疏性。我们的研究结果表明，高学习率在持续满足这些特性方面，优于其他超参数和正则化方法。除了证明高学习率在各种伪相关数据集、模型和优化器中的积极作用外，我们还提供了强有力的证据，表明先前记录的高学习率在标准分类任务中的成功与解决训练数据中隐藏/罕见的伪相关有关。我们对这一现象潜在机制的调查揭示了在高学习率下，偏差冲突样本的自信错误预测的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [746] [Quantum Spectral Reasoning: A Non-Neural Architecture for Interpretable Machine Learning](https://arxiv.org/abs/2508.03170)
> *量子谱推理：一种可解释机器学习的非神经网络架构*

*Andrew Kiruluta* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 量子谱推理, 可解释机器学习, 符号推理, Pade 近似, Lanczos 算法

**Comment:** 

> **TL;DR:** 提出了一种利用量子谱方法（Pade近似和Lanczos算法）的机器学习架构，用于信号分析和符号推理，无需反向传播或深度学习模型，实现了可解释性和数据效率。

**AI_Comments:** 该研究提出了一种创新的、非神经网络的机器学习架构，该架构融合了量子谱方法、稀疏近似和符号人工智能，旨在解决传统深度学习模型的可解释性和数据效率问题。其优势在于能够直接从信号中提取物理上有意义的表示，并进行符号推理，这在需要透明度和对底层机制有深入理解的应用领域具有重要意义。然而，该方法的计算复杂度和在不同类型数据上的泛化能力仍需进一步研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器学习模型（尤其是深度学习）通常是黑箱模型，缺乏可解释性，并且需要大量数据。需要一种新的方法来构建可解释、数据高效且具有物理意义的机器学习模型。

**Method:** 利用量子谱方法（Pade近似和Lanczos算法）将时域信号转换为稀疏的、物理上有意义的谱表示。通过有理谱近似提取共振结构，并使用核投影函数将其映射到符号谓词，最终通过基于规则的推理引擎进行逻辑推理。

**Result:** 该谱符号架构在时间序列异常检测、符号分类和混合推理任务上取得了具有竞争力的准确性，同时保持了可解释性和数据效率。

**Conclusion:** 所提出的谱符号架构为物理信息、能够进行推理的机器学习提供了一个有前途的新方向，它在可解释性和数据效率方面优于传统的深度学习模型。

> **ai_Abstract:** 本文提出了一种名为“量子谱推理”的新型机器学习架构，该架构不依赖于神经网络，而是利用量子谱方法（如 Pade 近似和 Lanczos 算法）来处理信号。其核心在于将原始信号转换为具有物理意义的谱表示，然后通过符号谓词和规则推理引擎进行逻辑分析。这种方法无需反向传播或高维嵌入，能够直接从数据中提取共振结构，实现高度可解释性和数据效率。实验证明，该架构在异常检测、符号分类和混合推理任务上表现出色，为构建物理信息驱动且具备推理能力的机器学习系统开辟了新途径。

> **摘要翻译:** 我们提出了一种新颖的机器学习架构，它摒弃了传统的神经网络范式，利用量子谱方法，特别是 Pade 近似和 Lanczos 算法，进行可解释的信号分析和符号推理。我们方法的核心创新在于，它能够在不使用反向传播、高维嵌入或数据密集型黑箱模型的情况下，将原始时域信号转换为稀疏的、物理上有意义的谱表示。通过有理谱近似，该系统提取共振结构，然后通过核投影函数将其映射到符号谓词，从而通过基于规则的推理引擎实现逻辑推理。该架构融合了数学物理、稀疏近似理论和符号人工智能，为深度学习模型提供了一种透明且物理上可行的替代方案。我们开发了支持管道每个阶段的完整数学形式，提供了一个模块化的算法实现，并通过在时间序列异常检测、符号分类和混合推理任务上的比较评估来展示系统的有效性。我们的结果表明，这种谱符号架构在保持可解释性和数据效率的同时，实现了具有竞争力的准确性，预示着物理信息、能够进行推理的机器学习的一个有前途的新方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [760] [Adaptive Sparse Softmax: An Effective and Efficient Softmax Variant](https://arxiv.org/abs/2508.03175)
> *自适应稀疏Softmax：一种有效且高效的Softmax变体*

*Qi Lv, Lei Geng, Ziqiang Cao, Min Cao, Sujian Li, Wenjie Li, Guohong Fu* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** AS-Softmax, Softmax变体, 自适应梯度累积, 训练效率, 分类性能

**Comment:** Accept by IEEE TASLP (Early accept version)

> **TL;DR:** 提出了一种名为AS-Softmax的Softmax变体，通过有选择地学习样本和使用自适应梯度累积策略来提高训练效率和分类性能，并在多项任务中验证了其优越性。

**AI_Comments:** 该研究提出了一种新颖的AS-Softmax方法，通过引入有选择性的样本学习和自适应梯度累积，有效解决了标准Softmax在训练效率和过拟合方面存在的问题。其优势在于能够让模型专注于关键样本，从而加速收敛并提升性能。然而，对于“强劲对手”的定义和选择机制的鲁棒性，以及在不同数据集和模型架构下的泛化能力，仍需进一步的探讨和验证。

<details>
  <summary>Details</summary>

**Motivation:** 标准的Softmax交叉熵损失函数在训练过程中存在目标分数永不可达、导致训练时间过长和过拟合的问题。此外，训练目标“接近1”迫使模型学习所有样本，浪费了处理已正确分类样本的时间，而测试目标仅要求目标类别得分最高。

**Method:** 提出自适应稀疏Softmax（AS-Softmax），设计了一种合理的、与测试匹配的Softmax变换。在训练中，丢弃得分远小于实际类别的类别，使模型专注于区分目标类别及其强劲对手。同时，开发了一种基于掩码样本比例的自适应梯度累积策略来加速训练。

**Result:** AS-Softmax在文本多分类、文本多标签、文本词分类、图像分类和音频分类任务中持续优于标准的Softmax及其变体。AS-Softmax的损失与验证集上的分类性能高度相关。自适应梯度累积策略比标准Softmax训练速度快1.2倍，同时保持了分类效果。

**Conclusion:** AS-Softmax通过有针对性的学习和自适应梯度累积，有效解决了标准Softmax的训练效率和过拟合问题，并在多种任务上展现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为AS-Softmax的Softmax变体，旨在解决标准Softmax训练效率低下和过拟合的问题。AS-Softmax通过在训练过程中有选择地关注与目标类别最相关的样本（即强劲对手），以及采用一种基于掩码样本比例的自适应梯度累积策略来加速训练，从而实现更高效和有针对性的学习。实验结果表明，AS-Softmax在多项分类任务上均优于标准Softmax及其变体，并能显著提升训练速度。

> **摘要翻译:** Softmax与交叉熵损失是当前神经分类模型标准的配置。目标类别的黄金分数应为1，但在softmax模式下永远无法达到。这个问题导致训练过程永远持续并导致过拟合。此外，“目标-接近1”的训练目标迫使模型持续学习所有样本，在处理一些已经以高置信度正确分类的样本时浪费了时间，而测试目标仅要求每个样本的目标类别持有最高分数。为了解决上述缺点，我们提出了自适应稀疏Softmax（AS-Softmax），它在softmax的基础上设计了一种合理且与测试匹配的变换。为了进行更有目的性的学习，我们在训练中丢弃了得分远小于实际类别的类别。然后，模型可以专注于区分目标类别与其强劲对手，这也是测试中的巨大挑战。此外，由于AS-Softmax中简单样本的训练损失会逐渐降至0，我们开发了一种基于掩码样本比例的自适应梯度累积策略来加速训练。我们在多种文本多分类、文本多标签、文本词分类、图像分类和音频分类任务中，类别数量从5到5000+不等，验证了所提出的AS-Softmax。结果表明，AS-Softmax持续优于softmax及其变体，并且AS-Softmax的损失与验证集上的分类性能显著相关。此外，与标准softmax相比，自适应梯度累积策略可以将训练速度提高约1.2倍，同时保持分类效果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [766] [Neural Approximators for Low-Thrust Trajectory Transfer Cost and Reachability](https://arxiv.org/abs/2508.02911)
> *低推力轨迹转移成本和可达性的神经逼近器*

*Zhong Zhang, Francesco Topputo* | **Category: cs.LG, cs.SY, eess.SY, math.OC** | **Updated: 2025-08-04**

**Keywords:** 低推力轨迹, 神经网络, 预测, 燃料消耗, 轨迹可达性

**Comment:** 

> **TL;DR:** 该研究提出了一种基于神经网络的低推力任务轨迹设计方法，可以预测燃料消耗和轨迹可达性。该方法使用一种新的同伦射线法构建了最大的数据集，并将其转换为自相似空间，使其能够适应不同的任务参数而无需重新训练。结果显示，该方法在预测速度增量和最小转移时间方面具有高精度和效率，并在多个场景中得到了验证。

**AI_Comments:** 这项研究在低推力轨迹设计领域具有重要意义，通过引入神经网络和创新的数据处理方法，显著提高了预测精度和泛化能力。其通用性和跨平台实现也使其在实际应用中具有很高的价值。然而，对于神经网络的训练细节和可能存在的过拟合风险，摘要中未详细说明，这可能是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在轨迹设计中，燃料消耗和轨迹可达性是低推力任务的关键性能指标。

**Method:** 提出通用的预训练神经网络来预测燃料消耗和轨迹可达性。利用同伦射线法构建数据集，并将数据转换为自相似空间，使神经网络能够适应任意的半长轴、倾角和中心天体，从而扩展了适用性。

**Result:** 预测速度增量的相对误差为0.78%，估计最小转移时间的相对误差为0.63%。

**Conclusion:** 该研究提出了目前最通用、最准确的低推力轨迹逼近器，并提供了C++、Python和MATLAB的实现。该模型在第三方数据集、多飞越任务设计问题和任务分析场景中得到了验证，证明了其泛化能力、预测准确性和计算效率。

> **ai_Abstract:** 本研究提出了一种基于神经网络的低推力任务轨迹设计方法，用于预测燃料消耗和轨迹可达性。通过同伦射线法构建大规模数据集，并利用自相似空间转换，使得神经网络能够泛化到不同的任务参数。实验结果表明，该方法在预测速度增量和最小转移时间方面具有高精度和效率，并在多种场景下得到了验证。

> **摘要翻译:** 在轨迹设计中，燃料消耗和轨迹可达性是低推力任务的两个关键性能指标。本研究提出了通用的预训练神经网络来预测这些指标。本文的贡献如下：首先，基于对适用于低推力轨迹逼近的尺度定律的确认，利用提出的同伦射线法构建了最大的数据集，该数据集符合任务设计导向的数据要求。其次，将数据转换为自相似空间，使神经网络能够适应任意的半长轴、倾角和中心天体。这扩展了超越现有研究的适用性，并能够跨不同任务场景进行泛化，而无需重新训练。第三，据我们所知，这项工作提出了目前最通用、最准确的低推力轨迹逼近器，并提供了C++、Python和MATLAB的实现。所得神经网络在预测速度增量方面的相对误差为0.78%，在估计最小转移时间方面的相对误差为0.63%。该模型还在第三方数据集、多飞越任务设计问题和任务分析场景中得到了验证，证明了其泛化能力、预测准确性和计算效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [769] [Mathematical Foundations of Geometric Deep Learning](https://arxiv.org/abs/2508.02723)
> *几何深度学习的数学基础*

*Haitz Sáez de Ocáriz Borde, Michael Bronstein* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 几何深度学习, 数学基础, 深度学习, 几何学, 综述

**Comment:** 78 pages

> **TL;DR:** 该论文回顾了研究几何深度学习所需的关键数学概念。

**AI_Comments:** 该论文对几何深度学习的数学基础进行了概述，为该领域的研究者提供了一个基础性的参考。

<details>
  <summary>Details</summary>

**Motivation:** 研究几何深度学习的必要性。

**Method:** 回顾关键的数学概念。

**Result:** 未在摘要中提及。

**Conclusion:** 未在摘要中提及。

> **ai_Abstract:** 本文对几何深度学习（Geometric Deep Learning）所需的关键数学基础进行了综述。

> **摘要翻译:** 我们回顾了研究几何深度学习所需的关键数学概念。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [773] [Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies](https://arxiv.org/abs/2508.03194)
> *深度强化学习决策制定扩展：数据、网络和训练预算策略综述*

*Yi Ma, Hongyao Tang, Chenjun Xiao, Yaodong Yang, Wei Wei, Jianye Hao, Jiye Liang* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 深度强化学习, 扩展定律, 数据扩展, 网络扩展, 训练预算, 决策制定

**Comment:** 

> **TL;DR:** 该综述探讨了深度强化学习（DRL）在决策制定中的应用，重点关注数据、网络和训练预算方面的扩展策略。虽然深度学习在计算机视觉和自然语言处理领域取得了显著进展，但DRL在该领域的应用仍处于初步阶段。本综述分析了优化数据效率、改进网络架构以及提高训练效率的方法，并强调了在扩展DRL能力的同时平衡计算效率的重要性，为未来的研究提供了方向。

**AI_Comments:** 该综述对于理解和推进深度强化学习在决策制定领域的应用具有重要意义。它系统地梳理了扩展策略，并指出了未来研究的方向，特别是强调了在追求模型性能提升的同时，必须关注计算效率的平衡，这是一个在实际应用中至关重要的考量因素。文章的结构清晰，涵盖了数据、网络和训练预算等关键方面，为研究人员和工程师提供了一个有价值的参考框架。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）在决策制定方面的应用潜力巨大，但与计算机视觉和自然语言处理领域相比，其扩展策略（如利用Scaling Laws）的研究尚不充分。本综述旨在弥合这一差距，系统地分析DRL中的数据、网络和训练预算扩展策略。

**Method:** 本综述系统地分析了DRL的扩展策略，涵盖了三个主要维度：1. 数据扩展：优化数据效率，例如通过并行采样和数据生成，并研究数据量与学习结果的关系。2. 网络扩展：研究网络架构的改进，包括单体扩展、集成和混合专家（MoE）方法以及智能体数量扩展技术。3. 训练预算扩展：评估分布式训练、高回放比、大批量大小和辅助训练对训练效率和收敛性的影响。

**Result:** 通过对数据、网络和训练预算扩展策略的综合分析，本综述揭示了它们在推动DRL决策制定能力方面的协同作用，并为未来的研究提供了路线图。研究强调了平衡可扩展性与计算效率的重要性。

**Conclusion:** 本综述强调了平衡可扩展性与计算效率的重要性，并指出了利用扩展策略解锁DRL在机器人控制、自动驾驶和大型语言模型训练等各种任务中全部潜力的前景。未来的研究应侧重于优化这些策略的组合，以实现DRL在决策制定任务中的最佳性能。

> **ai_Abstract:** 本综述系统地分析了深度强化学习（DRL）在决策制定中的扩展策略，重点关注数据、网络和训练预算三个维度。文章探讨了如何通过优化数据效率、改进网络架构（如集成和MoE方法）以及提高训练效率（如分布式训练）来提升DRL的性能。同时，作者也指出了在扩展DRL能力的同时，需要平衡计算效率，并为未来的研究提出了方向，旨在充分发挥DRL在机器人控制、自动驾驶和大型语言模型训练等领域的潜力。

> **摘要翻译:** 近年来，神经网络模型和训练数据的扩展推动了深度学习的显著进步，尤其是在计算机视觉和自然语言处理领域。这种进步以Scaling Laws（扩展定律）为基础，该定律证明了扩展模型参数和训练数据能够提升学习性能。尽管这些领域取得了突破性进展，例如GPT-4等大型语言模型和Midjourney等先进视觉模型的开发，但扩展定律在深度强化学习（DRL）中的应用仍相对未被充分探索。尽管在决策制定方面具有提升性能的潜力，但将扩展定律整合到DRL中尚未完全实现。本综述通过系统地分析数据、网络和训练预算三个维度的扩展策略，解决了这一差距。在数据扩展方面，我们探讨了通过并行采样和数据生成优化数据效率的方法，并研究了数据量与学习结果之间的关系。在网络扩展方面，我们研究了架构改进，包括单体扩展、集成和混合专家（MoE）方法以及智能体数量扩展技术，这些技术共同增强了模型的表达能力，但也带来了独特的计算挑战。最后，在训练预算扩展方面，我们评估了分布式训练、高回放比、大批量大小和辅助训练对训练效率和收敛性的影响。通过综合这些策略，本综述不仅强调了它们在推动DRL决策制定能力方面的协同作用，还为未来的研究提供了路线图。我们强调了平衡可扩展性与计算效率的重要性，并概述了利用扩展策略解锁DRL在机器人控制、自动驾驶和大型语言模型训练等各种任务中全部潜力的有希望的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [782] [Training Multi-Layer Binary Neural Networks With Local Binary Error Signals](https://arxiv.org/abs/2412.00119)
> *训练具有局部二值误差信号的多层二值神经网络*

*Luca Colombo, Fabrizio Pittorino, Manuel Roveri* | **Category: cs.LG, cs.CV, I.2.6** | **Updated: 2025-08-05**

**Keywords:** 二值神经网络, 全二值训练, 无梯度学习, 局部二值误差信号, 突触可塑性

**Comment:** 

> **TL;DR:** 提出了一种完全二值、无梯度的多层二值神经网络（BNN）训练算法，使用局部二值误差信号和二值权重更新，无需反向传播的浮点梯度。该算法仅使用XNOR、Popcount和增量/减量操作，并在多类分类基准测试中取得了显著的准确性提升，同时大幅降低了计算成本。

**AI_Comments:** 这项工作在BNN训练领域取得了重要进展，首次提出了完全二值、无梯度的训练方法，解决了现有方法的局限性。其神经生物学上的合理性也为未来研究提供了新的方向。然而，仅在多类分类基准上进行的实验可能无法完全代表其在更广泛应用中的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有BNN训练算法依赖于量化感知浮点随机梯度下降（SGD），这限制了二值运算在推理阶段的充分利用。本研究旨在提出一种完全二值、无梯度的训练算法，以克服这些限制。

**Method:** 提出了一种完全二值、无梯度的训练算法，该算法依赖于局部二值误差信号和二值权重更新。它使用整数值隐藏权重作为突触可塑性机制，从而增强了神经生物学上的合理性。该算法仅使用XNOR、Popcount和增量/减量操作来训练二值多层感知机。

**Result:** 在多类分类基准测试中，与现有的全二值单层最先进解决方案相比，测试准确性提高了高达+35.47%。与全精度SGD相比，在相同的总内存需求下，测试准确性提高了高达+35.30%，同时将总门数减少了两个数量级。

**Conclusion:** 所提出的全二值、无梯度训练算法能够有效地训练多层BNN，在准确性和计算效率方面均优于现有方法，并具有神经生物学上的合理性。

> **ai_Abstract:** 本研究提出了一种新颖的、完全二值且无梯度的多层二值神经网络（BNN）训练算法。该算法利用局部二值误差信号和二值权重更新，无需反向传播浮点梯度，并采用整数权重作为突触可塑性机制。实验结果表明，该方法在准确性和计算效率上均取得了显著提升，优于现有方法，并具有更好的神经生物学合理性。

> **摘要翻译:** 二值神经网络（BNN）通过仅用一位来表示权重和激活，显著降低了机器学习和深度学习中的计算复杂性和内存使用。然而，大多数现有的BNN训练算法依赖于量化感知的浮点随机梯度下降（SGD），这仅将二值运算的充分利用限制在推理阶段。在本研究中，我们首次提出了一种用于多层BNN的完全二值、无梯度训练算法，消除了对反向传播的浮点梯度的需求。具体而言，所提出的算法依赖于局部二值误差信号和二值权重更新，采用整数值隐藏权重作为突触可塑性机制，从而增强了其神经生物学上的合理性。我们提出的解决方案能够仅使用XNOR、Popcount和增量/减量操作来训练二值多层感知机。在多类分类基准测试上的实验结果表明，与现有的唯一全二值单层最先进解决方案相比，测试准确性提高了高达+35.47%。与全精度SGD相比，在相同的总内存需求下，我们的解决方案将测试准确性提高了高达+35.30%，同时还将计算成本降低了两个到三个数量级的总门数。所提出的算法已作为公共存储库提供给科学界。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [784] [Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation](https://arxiv.org/abs/2508.03663)
> *森林与树木：可复现机器学习评估中的（N，K）权衡*

*Deepak Pandita, Flip Korn, Chris Welty, Christopher M. Homan* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 机器学习评估, 可复现性, N-K权衡, 人类标注, 预算优化

**Comment:** 

> **TL;DR:** 研究了在固定预算下，通过调整样本数量（N）和每个样本的标注数量（K）来优化机器学习评估数据收集的权衡，发现大多数情况下，K>10的较小样本量（N*K<=1000）足以保证评估的可靠性，并且权衡关系取决于评估指标。

**AI_Comments:** 该研究解决了机器学习评估中一个实际且重要的问题，即如何在有限预算下有效地利用人类标注数据。通过量化N和K的权衡，为实践者提供了具体的指导。研究的创新之处在于系统地分析了忽略人类分歧的影响，并发现K>10通常是获得可靠结果的有效策略。然而，研究可能未充分探讨不同类型机器学习模型对这种权衡的影响，以及在标注数据质量参差不齐的情况下，该方法的鲁棒性。未来的工作可以进一步探索这些方面。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习评估的可复现性至关重要，但人类标注数据存在分歧，且收集多标注成本高。现有研究对忽略分歧的影响研究不足，需要探索在有限预算下优化数据收集策略。

**Method:** 分析了包含多标注的分类数据集和模拟分布，研究了在固定预算（N*K）下，样本数量（N）和每个样本的标注数量（K）对机器学习评估可靠性的影响，以确定最优的（N, K）配置。

**Result:** 在大多数测试数据集上，使用K>10且总样本量N*K不超过1000（甚至更低）即可获得可靠的评估结果。N和K之间的权衡关系取决于评估指标，对响应分布更敏感的指标在较高的K值下表现更好。

**Conclusion:** 在固定预算下，通过优化N和K的组合，可以更有效地收集机器学习评估数据，提高评估的可靠性。研究结果表明，通常选择较多的标注数K（K>10）和较少的样本数N（使得N*K<=1000）是更优的策略，但具体最优配置取决于所使用的评估指标。

> **ai_Abstract:** 本研究探讨了在机器学习评估中，如何在固定预算下平衡样本数量（N）和每个样本的标注数量（K），以最大化评估的可靠性。通过分析包含多人标注的数据集，研究发现，在大多数情况下，采用较多的标注数（K>10）和较少的总样本量（N*K<=1000）即可达到可靠的评估效果。研究还强调，N与K的权衡关系以及最优配置会因评估指标的敏感性而异。

> **摘要翻译:** 可复现性是科学验证及其赋予结果权威性的基石。机器学习评估的可复现性可带来更大的信任、信心和价值。然而，机器学习中使用的地面真实响应往往不可避免地来自人类，而人类之间普遍存在分歧，并且很少有研究专门研究有效忽略这些响应中分歧的影响，而这通常是常规做法。研究缺乏的一个原因是，用于收集人类标注评估数据的预算是有限的，并且为每个样本从多个标注者那里获取更多样本会大大增加每个项目的标注成本。我们研究了可靠的机器学习评估所需的样本数量（N）与每个样本的响应数量（K）之间的权衡。我们分析了包含多标注的各种分类数据集以及拟合这些数据集的模拟分布，以确定在固定预算（N×K）下，用于收集评估数据和可靠比较机器学习模型性能的最优（N, K）配置。我们的研究结果表明，首先，考虑到人类分歧可能需要每个测试数据集至少有一个指标的N×K不超过1000（通常远低于此）。此外，这种最小的N×K几乎总是发生在K>10的情况下。此外，K与N之间的权衡性质——或者是否存在这种权衡——取决于评估指标，对响应完整分布更敏感的指标在较高的K值下表现更好。我们的方法可用于帮助机器学习实践者通过寻找最优指标以及收集的样本数量和每个样本的标注数量来获得更有效的测试数据，从而为其预算带来最大的可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [785] [Minimal Convolutional RNNs Accelerate Spatiotemporal Learning](https://arxiv.org/abs/2508.03614)
> *最小卷积循环神经网络加速时空学习*

*Coşku Can Horuz, Sebastian Otte, Martin V. Butz, Matthias Karlbauer* | **Category: cs.LG, cs.NE** | **Updated: 2025-08-05**

**Keywords:** 卷积循环神经网络,最小RNN,时空学习,并行训练,预测模型

**Comment:** Accepted at ICANN 2025

> **TL;DR:** 提出了一种结合卷积和最小RNN的新型时空模型MinConvLSTM和MinConvGRU，实现了并行训练，减少了参数量，并在Navier-Stokes动力学和地势高度数据预测任务上取得了更快的训练速度和更低的预测误差。

**AI_Comments:** 这项研究提出了一个有前景的时空学习方法，通过结合卷积和最小RNN的优点，解决了现有模型在训练效率上的瓶颈。其并行训练能力和在预测任务上的优异表现值得关注。然而，模型的泛化能力和在更复杂、更大规模数据集上的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统的卷积循环神经网络（ConvRNN）在训练过程中存在瓶颈，因为需要顺序更新隐藏状态，限制了并行训练。本研究旨在解决这一问题，并提高模型的效率和性能。

**Method:** 提出了MinConvLSTM和MinConvGRU模型，将最小RNN（MinRNN）的对数域前缀和公式扩展到卷积架构。通过消除教师强制期间的顺序隐藏状态更新，实现了完全并行训练。此外，MinConvLSTM还引入了受xLSTM启发的指数门控机制，简化了计算。

**Result:** MinConvLSTM和MinConvGRU在训练速度上显著优于标准的ConvLSTM和ConvGRU。在Navier-Stokes动力学和地势高度数据预测任务中，无论是在开放循环还是封闭循环自回归模式下，新模型都取得了更低的预测误差。

**Conclusion:** 最小循环结构结合卷积输入聚合，为时空序列建模提供了一种高效且有竞争力的方法，能够平衡循环结构的简洁性和卷积的空间复杂性。

> **ai_Abstract:** 该研究提出了MinConvLSTM和MinConvGRU，这是两种新型时空模型，它们结合了卷积网络的空间建模能力和最小RNN的训练效率。这些模型通过允许完全并行训练，解决了传统ConvRNNs中隐藏状态更新的瓶颈问题。实验结果表明，与标准的ConvLSTMs和ConvGRUs相比，MinConvLSTM和MinConvGRU在训练速度和预测精度上都有显著提升，尤其是在Navier-Stokes动力学和地势高度数据预测任务中。

> **摘要翻译:** 我们引入了MinConvLSTM和MinConvGRU，两种新颖的时空模型，它们将卷积循环网络的空间归纳偏置与最小、可并行化RNN的训练效率相结合。我们的方法将MinLSTM和MinGRU的对数域前缀和公式扩展到卷积架构，实现了完全并行训练，同时保留了局部空间建模。这消除了在教师强制期间顺序隐藏状态更新的需要——这是传统ConvRNN模型的一个主要瓶颈。此外，我们将受xLSTM架构启发的指数门控机制融入MinConvLSTM，这进一步简化了对数域计算。我们的模型在结构上最小，计算效率高，参数量减少，可扩展性提高。我们在两个时空预测任务上评估了我们的模型：Navier-Stokes动力学和真实世界地势高度数据。在训练速度方面，我们的架构显著优于标准的ConvLSTMs和ConvGRUs。此外，我们的模型在两个领域都取得了较低的预测误差，即使在封闭循环自回归模式下也是如此。这些发现表明，当与卷积输入聚合相结合时，最小循环结构为时空序列建模提供了一种引人注目的高效替代方案，弥合了循环简洁性与空间复杂性之间的差距。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [787] [FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting](https://arxiv.org/abs/2507.18219)
> *FedSA-GCL：一个具有个性化聚合和集群感知广播的半异步联邦图学习框架*

*Zhongzheng Yuan, Lianshuai Guo, Xunkai Li, Yinlin Zhu, Wenyu Wang, Meixia Qu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 联邦图学习, 半异步, 图神经网络, ClusterCast, 联邦学习

**Comment:** 

> **TL;DR:** 该论文提出了FedSA-GCL，一个用于联邦图学习的半异步框架，通过ClusterCast机制解决同步通信效率低下和现有异步方法不适用于图数据的问题。实验表明，该方法在Louvain和Metis分割下表现优于基线。

**AI_Comments:** 该论文提出了一种新颖的半异步联邦图学习框架FedSA-GCL，解决了现有方法的局限性。ClusterCast机制是其核心创新，能够同时处理异步通信和图拓扑特性，这在联邦图学习领域是一个重要的进步。实验结果也充分证明了该方法的有效性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦图学习（FGL）方法依赖同步通信，效率低下且不适用于实际部署。现有的异步联邦学习（AFL）方法未考虑图数据的拓扑特性，可能导致全局模型出现语义漂移和表示不一致。

**Method:** 提出FedSA-GCL，一个半异步联邦框架，利用客户间标签分布差异和图拓扑特性，通过新颖的ClusterCast机制进行高效训练。

**Result:** 在Louvain和Metis分割的真实图数据集上的广泛实验表明，FedSA-GCL方法表现出强大的鲁棒性和出色的效率，在Louvain分割下平均比基线高2.92%，在Metis分割下高3.4%。

**Conclusion:** FedSA-GCL是一个有效的半异步联邦图学习框架，通过ClusterCast机制在效率和模型一致性方面优于现有方法，并在实际数据集上取得了显著的性能提升。

> **ai_Abstract:** FedSA-GCL是一个半异步联邦图学习框架，通过新颖的ClusterCast机制解决了同步通信效率低下和现有异步方法不适用于图数据的问题。该框架利用客户间标签分布差异和图拓扑特性进行高效训练，并在真实数据集上取得了优于基线方法的性能。

> **摘要翻译:** 联邦图学习（FGL）是一种分布式学习范式，能够对位于多个本地系统的大规模子图进行协作训练。然而，大多数现有的FGL方法依赖于同步通信，这会导致效率低下，并且在实际部署中通常不切实际。同时，现有的异步联邦学习（AFL）方法主要针对图像分类和自然语言处理等常规任务，而没有考虑到图数据的独特拓扑特性。将这些方法直接应用于图学习可能会导致全局模型出现语义漂移和表示不一致。为了解决这些挑战，我们提出了FedSA-GCL，一个半异步联邦框架，它通过新颖的ClusterCast机制利用客户间标签分布差异和图拓扑特性进行高效训练。我们在使用Louvain和Metis分割算法的多个真实图数据集上评估了FedSA-GCL，并将其与9个基线进行了比较。广泛的实验表明，我们的方法表现出强大的鲁棒性和出色的效率，在Louvain分割下平均比基线高2.92%，在Metis分割下高3.4%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [788] [Convergence of Deterministic and Stochastic Diffusion-Model Samplers: A Simple Analysis in Wasserstein Distance](https://arxiv.org/abs/2508.03210)
> *确定性与随机扩散模型采样器收敛性：Wasserstein距离的简单分析*

*Eliot Beyler, Francis Bach* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 扩散模型,Wasserstein距离,收敛性,采样器,分数函数

**Comment:** 

> **TL;DR:** 该论文在Wasserstein距离方面为基于扩散的生成模型提供了新的收敛保证，涵盖了随机（DDPM类）和确定性（DDIM类）采样方法，并提出了一个分析离散化、初始化和分数估计误差的简单框架。

**AI_Comments:** 这项工作在理论上为扩散模型的收敛性分析做出了贡献，特别是在Wasserstein距离方面。它提出的分析框架简单而有效，能够处理多种误差源。然而，该分析的实际影响和对不同扩散模型架构的普适性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 提供基于扩散的生成模型（包括随机和确定性采样方法）在Wasserstein距离方面的收敛保证，并分析离散化、初始化和分数估计误差。

**Method:** 提出一个简单的框架来分析离散化、初始化和分数估计误差，并推导了Heun采样器的Wasserstein收敛界限，以及改进了概率流ODE的Euler采样器的现有结果，并结合了平滑Wasserstein距离的近期结果来收紧初始化误差界限。

**Result:** 推导了Heun采样器的第一个Wasserstein收敛界限，并改进了概率流ODE的Euler采样器的现有结果。

**Conclusion:** 该分析强调了学习到的分数函数的空间正则性的重要性，并主张根据真实的逆过程来控制分数误差，这与去噪分数匹配一致。

> **ai_Abstract:** 该研究在Wasserstein距离方面为扩散模型生成器提供了新的理论分析，涵盖了随机和确定性采样方法。研究提出了一个分析框架，用于评估离散化、初始化和分数估计误差，并为Heun采样器提供了首个收敛界限，同时改进了Euler采样器的结果。分析结果强调了学习到的分数函数的空间正则性的重要性，并建议通过去噪分数匹配来控制分数误差。

> **摘要翻译:** 我们为基于扩散的生成模型在Wasserstein距离方面提供了新的收敛保证，涵盖了随机（DDPM类）和确定性（DDIM类）采样方法。我们引入了一个简单的框架来分析离散化、初始化和分数估计误差。值得注意的是，我们推导出了Heun采样器的第一个Wasserstein收敛界限，并改进了概率流ODE的Euler采样器的现有结果。我们的分析强调了学习到的分数函数的空间正则性的重要性，并主张根据真实的逆过程来控制分数误差，这与去噪分数匹配一致。我们也结合了关于平滑Wasserstein距离的最新结果来收紧初始化误差界限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [795] [The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation](https://arxiv.org/abs/2503.10636)
> *条件之祸：分析与改进用于条件流生成的最佳传输*

*Ho Kei Cheng, Alexander Schwing* | **Category: cs.LG, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 最优传输, 条件生成, 流匹配, 先验分布, C^2OT

**Comment:** ICCV 2025. Project page: https://hkchengrex.github.io/C2OT

> **TL;DR:** 在条件生成任务中，最小批量最优传输（minibatch optimal transport）由于训练和测试时先验分布不匹配而表现不佳。本文提出了条件最优传输（C^2OT），通过在计算最优传输分配时添加条件权重项来解决这个问题，并在多个数据集上取得了优于现有基线方法的性能。

**AI_Comments:** 该研究提出了一种简单而有效的改进方法（C^2OT），解决了最优传输在条件生成任务中的一个关键问题。通过在成本矩阵中添加条件权重，成功弥合了训练和测试阶段的差距，并在多个数据集上取得了优于基线方法的性能，具有重要的理论和实践意义。代码的公开也增加了其可复现性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 最小批量最优传输在条件生成任务中存在不足，因为其映射忽略了条件，导致训练时先验分布偏斜，而测试时又无法访问该偏斜的先验，从而造成训练和测试之间的差距，导致性能下降。

**Method:** 提出条件最优传输（C^2OT），通过在计算最优传输分配时，在成本矩阵中添加一个条件权重项来弥合训练和测试之间的差距。

**Result:** C^2OT 方法在 8gaussians-to-moons、CIFAR-10、ImageNet-32x32 和 ImageNet-256x256 数据集上，对于离散和连续条件均表现良好，并且在不同函数评估预算下，整体性能优于现有基线方法。

**Conclusion:** C^2OT 通过在成本矩阵中添加条件权重项，有效解决了最小批量最优传输在条件生成任务中的先验分布不匹配问题，并在多个数据集上取得了优于现有方法的性能。

> **ai_Abstract:** 本研究分析了最小批量最优传输在条件生成任务中的局限性，指出其在训练和测试阶段的先验分布不匹配问题。为解决此问题，论文提出了条件最优传输（C^2OT），通过在成本矩阵中引入条件权重项来优化最优传输分配。实验结果表明，C^2OT 在多个数据集和不同条件下均优于现有方法。

> **摘要翻译:** 最小批量最优传输耦合将无条件流匹配中的路径拉直。这使得推理在计算上要求较低，因为在测试时数值求解常微分方程时可以采用较少的积分步骤和较复杂的数值求解器。然而，在条件设置中，最小批量最优传输表现不佳。这是因为默认的最优传输映射忽略了条件，导致训练期间先验分布产生条件偏斜。相比之下，在测试时，我们无法访问偏斜的先验，而是从完整、无偏的先验分布中采样。训练和测试之间的这种差距导致性能不佳。为了弥合这一差距，我们提出了条件最优传输 C^2OT，它在计算最优传输分配时，在成本矩阵中添加了一个条件权重项。实验表明，这种简单的修复方法在 8gaussians-to-moons、CIFAR-10、ImageNet-32x32 和 ImageNet-256x256 数据集上，对离散和连续条件均有效。我们的方法在不同函数评估预算下，整体性能优于现有基线方法。代码可在 https://hkchengrex.github.io/C2OT 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [802] [Revisiting Deep Information Propagation: Fractal Frontier and Finite-size Effects](https://arxiv.org/abs/2508.03222)
> *重新审视深度信息传播：分形边界与有限尺寸效应*

*Giuseppe Alessio D'Inverno, Zhiyuan Hu, Leo Davy, Michael Unser, Gianluigi Rozza, Jonathan Dong* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 信息传播, 深度神经网络, 有限尺寸效应, 分形结构, 卷积神经网络

**Comment:** 17 pages

> **TL;DR:** 该研究探讨了深度神经网络中信息传播的有限尺寸效应，发现有限宽度网络中阶- chaos 边界呈现分形结构，并证明了卷积神经网络也具有此特性。

**AI_Comments:** 该研究对于理解深度神经网络在实际应用中的行为具有重要意义，特别是在有限尺寸网络方面。分形边界的发现为神经网络动力学提供了一个新的视角。然而，抽象中并未详细说明实现分形结构的具体数学方法，也没有提供实验结果的具体量化指标，这可能限制了对研究结论的深入理解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信息传播研究主要基于均值场理论，该理论假设网络宽度无限，但实际应用中的网络尺寸有限，这使得该理论的假设失效。

**Method:** 通过研究随机初始化的、具有有限宽度的神经网络中的信息传播，并利用傅里叶变换结构化变换来分析卷积神经网络。

**Result:** 发现有限宽度网络中阶- chaos 边界呈现分形结构，并证明了卷积神经网络的信息传播也遵循此行为。

**Conclusion:** 深度神经网络中的信息传播具有复杂的动力学特性，有限网络深度对于分离和鲁棒性之间的权衡至关重要。

> **ai_Abstract:** 本研究关注深度神经网络中的信息传播，特别是在实际的有限尺寸网络中。研究发现，与无限宽度假设不同，有限宽度网络中的有序和混沌状态边界表现出分形特征。这一发现独立于输入数据和优化过程，揭示了神经网络动力学的内在复杂性。此外，研究还表明卷积神经网络也展现出类似的信息传播行为。最后，研究强调了有限网络深度在平衡信息分离和鲁棒性方面的重要性。

> **摘要翻译:** 信息传播是深度神经网络中输入相关性跨层演化的特征。该框架已通过均值场理论得到了充分研究，该理论假设网络宽度无限。然而，这些假设对于实际的有限尺寸网络来说会失效。在这项工作中，我们研究了具有有限宽度和随机初始化的神经网络中的信息传播，并揭示了有序和混沌状态之间的边界呈现分形结构。这表明了神经网络动力学的基本复杂性，而且这种设置独立于输入数据和优化。为了将此分析扩展到多层感知机之外，我们利用了最近引入的基于傅里叶的结构化变换，并表明卷积神经网络中的信息传播也遵循相同的行为。我们的研究强调了有限网络深度对于分离和鲁棒性之间权衡的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [810] [Imbalance-Robust and Sampling-Efficient Continuous Conditional GANs via Adaptive Vicinity and Auxiliary Regularization](https://arxiv.org/abs/2508.01725)
> *通过自适应邻近和辅助正则化的不平衡鲁棒和采样高效连续条件GAN*

*Xin Ding, Yun Chen, Yongwei Wang, Kao Zhang, Sen Zhang, Peibei Cao, Xiangxue Wang* | **Category: cs.LG, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 连续条件GAN, 数据不平衡, 自适应邻近, 辅助正则化, 采样效率

**Comment:** 

> **TL;DR:** 提出CcGAN-AVAR，一种改进的CcGAN框架，通过自适应邻近机制和多任务判别器来解决数据不平衡和采样效率问题，实现了与CCDM相当的生成质量，同时推理速度提高了300-2000倍。

**AI_Comments:** 该研究提出了一种新颖的CcGAN-AVAR框架，通过自适应邻近和多任务判别器有效解决了数据不平衡和采样效率问题，在生成质量和速度上均有显著提升，为连续条件生成领域带来了重要的贡献。然而，其对不同类型不平衡数据的普适性以及在更大规模数据集上的表现仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的连续条件生成模型CcGAN和CCDM在处理高维数据分布时存在局限性：CcGAN因固定邻近约束导致数据不平衡，CCDM采样过程计算成本高昂。

**Method:** 提出CcGAN-AVAR框架，包含两个关键组件：1. 自适应邻近机制，动态调整邻近大小以解决数据不平衡问题。2. 多任务判别器，通过辅助回归和密度比估计构建正则化项，以改善生成器训练。

**Result:** 在四个不同分辨率（64x64至192x192）和八种不平衡设置的基准数据集上进行的大量实验表明，CcGAN-AVAR实现了最先进的生成质量，同时保持了采样效率，并且推理速度比CCDM快300-2000倍。

**Conclusion:** CcGAN-AVAR框架通过引入自适应邻近和辅助正则化，成功解决了CcGAN在数据不平衡和采样效率方面面临的挑战，并在生成质量和效率上均达到了最先进水平。

> **ai_Abstract:** 本文提出了一种名为CcGAN-AVAR的改进型CcGAN框架，旨在解决现有连续条件生成模型在处理数据不平衡和采样效率方面的不足。CcGAN-AVAR通过引入自适应邻近机制来动态调整邻近大小，并利用多任务判别器进行辅助正则化，从而有效缓解数据不平衡问题。同时，该框架保留了GAN的单步生成优势，实现了比CCDM快300-2000倍的推理速度。实验结果表明，CcGAN-AVAR在多种不平衡设置下均能达到最先进的生成质量。

> **摘要翻译:** 近期，条件生成模型在估计标量、连续回归标签（例如，角度、年龄或温度）的高维数据分布方面取得了进展，包括连续条件生成对抗网络（CcGAN）和连续条件扩散模型（CCDM）。然而，这些方法面临根本性的局限性：CcGAN由于固定的邻近约束而导致数据不平衡，而CCDM需要计算成本高昂的迭代采样。我们提出了CcGAN-AVAR，一个增强的CcGAN框架，解决了这两个挑战：（1）利用GAN框架原生的单步生成来克服CCDM的采样瓶颈（实现300倍-2000倍的更快的推理），同时（2）两个新颖的组件专门针对数据不平衡——一个自适应邻近机制，动态调整邻近的大小，以及一个多任务判别器，通过辅助回归和密度比估计构建两个正则化项，以显著改善生成器训练。在四个基准数据集（64x64到192x192分辨率）上，跨越八个具有挑战性的不平衡设置进行的广泛实验表明，CcGAN-AVAR在保持采样效率的同时，实现了最先进的生成质量。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [818] [On Conformal Machine Unlearning](https://arxiv.org/abs/2508.03245)
> *关于保形机器学习遗忘*

*Yahya Alkhatib, Wee Peng Tay* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 机器学习遗忘,保形预测,数据隐私,统计保证,ECF

**Comment:** 

> **TL;DR:** 本研究提出了一种基于保形预测的机器学习遗忘新定义和新方法，解决了现有方法缺乏统计保证和计算成本高的问题，并通过实验证明了其有效性。

**AI_Comments:** 该研究在机器学习遗忘领域提出了一个创新的方法，通过引入保形预测，为遗忘过程提供了坚实的统计基础和不确定性度量。这不仅解决了现有方法的局限性，而且可能为隐私保护和模型更新开辟新的途径。然而，该方法在实际应用中的计算效率和可扩展性仍需进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习遗忘方法缺乏严格的统计保证，依赖启发式指标，并且需要昂贵的重新训练基线。

**Method:** 提出了一种基于保形预测的机器学习遗忘新定义，并提出了量化遗忘效果的经验指标ECF和EuCF，以及一种优化这些指标的遗忘方法。

**Result:** 提出的方法在各种遗忘场景、数据集和模型上进行了广泛的实验，证明了其在移除目标数据方面的有效性。

**Conclusion:** 本研究基于保形预测提出了统计上可靠、具有不确定性感知保证的机器学习遗忘新方法，克服了现有方法的局限性。

> **ai_Abstract:** 本研究提出了一种新颖的机器学习遗忘（MU）框架，该框架基于保形预测（CP），旨在解决现有MU方法在统计保证和计算效率方面的不足。研究人员定义了衡量遗忘效果的保形标准，并引入了有效覆盖频率（ECF at c）和有效未覆盖频率（EuCF at d）作为经验指标。此外，他们还开发了一种优化这些指标的实际遗忘方法。实验结果表明，该方法在移除目标数据方面是有效的。

> **摘要翻译:** 日益增长的数据隐私需求，受GDPR和CCPA等法规的驱动，使得机器学习遗忘（MU）成为必需，它能在保留保留数据性能的同时，移除特定训练样本对机器学习模型的影响。然而，大多数现有的MU方法缺乏严格的统计保证，依赖启发式指标，并且通常需要计算成本高昂的重新训练基线。为了克服这些局限性，我们提出了一种基于保形预测（CP）的MU新定义，提供了统计上可靠、不确定性感知保证，且无需朴素重新训练的概念。我们形式化了保形标准，用于量化遗忘样本被排除在CP集之外的频率，并提出了经验指标——有效覆盖频率（ECF at c）及其补集——有效未覆盖频率（EuCF at d），以衡量遗忘的有效性。我们还提出了一种旨在优化这些保形指标的实际遗忘方法。在跨越不同遗忘场景、数据集和模型的广泛实验表明，我们的方法在移除目标数据方面是有效的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [823] [Clinical Expert Uncertainty Guided Generalized Label Smoothing for Medical Noisy Label Learning](https://arxiv.org/abs/2508.02495)
> *临床专家不确定性指导的泛化标签平滑用于医学噪声标签学习*

*Kunyu Zhang, Lin Gu, Liangchen Liu, Yingke Chen, Binyang Wang, Jin Yan, Yingying Zhu* | **Category: cs.LG, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 标签噪声,医学图像分析,临床专家不确定性,标签平滑,文本挖掘

**Comment:** 

> **TL;DR:** 该研究提出了一种新的方法来解决从临床笔记中提取标签时产生的医学图像标签噪声问题，特别是考虑了临床专家在笔记中表达的不确定性，并通过一种新的标签平滑方法来提高模型性能。

**AI_Comments:** 这项研究解决了医学图像分析中的一个关键且被忽视的问题——由临床专家不确定性引起的标签噪声。通过提出一种新的基准和一种考虑不确定性的标签平滑方法，该研究为处理和利用包含不确定性信息的医学数据提供了一种创新的解决方案。其优点在于能够更准确地反映临床实践中的细微差别，从而可能提高模型的鲁棒性和泛化能力。然而，该方法在实际应用中的计算成本和对不同类型不确定性表达的泛化能力有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 从临床笔记中提取图像标签以创建大规模医学图像数据集成本低廉，但这种方法会因临床专家的不确定性而产生固有的标签噪声。现有方法忽略了专家不确定性导致的细微差别，导致标签噪声。现有的处理医学图像分析中噪声标签的方法大多忽略了专家驱动的不确定性是造成标签噪声的重要原因。

**Method:** 首先研究临床专家不确定性对标签噪声的影响，然后提出了一种临床专家不确定性感知基准和一种标签平滑方法。

**Result:** 所提出的方法比当前最先进的方法在性能上有了显著的提高。

**Conclusion:** 通过将专家写入临床笔记中的不确定性纳入医学图像分析，并采用一种新的标签平滑方法，可以有效解决标签噪声问题，并提高模型性能。

> **ai_Abstract:** 本研究提出了一种新颖的标签平滑方法，旨在解决医学图像分析中因临床专家在笔记中表达不确定性而导致的标签噪声问题。研究人员首先分析了专家不确定性对标签噪声的影响，然后开发了一种能够感知这种不确定性的基准和标签平滑技术，该技术在实验中表现出优于现有最先进方法的性能。

> **摘要翻译:** 许多以往的研究提出了从临床笔记中提取图像标签，以低成本创建大规模医学图像数据集。然而，这些方法由于临床专家的不确定性而固有地遭受标签噪声的影响。当放射科医生和医师分析医学图像以做出诊断时，他们经常包含“也许”或“未排除”等不确定性提示。不幸的是，当前文本挖掘方法忽略了这些细微差别，导致产生了带噪声的标签。现有的处理医学图像分析中噪声标签的方法，通常通过后处理技术来解决问题，但它们在很大程度上忽略了专家驱动的不确定性对标签噪声的重要影响。为了更好地将专家在临床笔记中书写的不确定性纳入医学图像分析并解决标签噪声问题，我们首先研究了临床专家不确定性对标签噪声的影响。然后，我们提出了一个临床专家不确定性感知基准，以及一种标签平滑方法，与当前最先进的方法相比，该方法显著提高了性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [825] [Learning New Concepts, Remembering the Old: Continual Learning for Multimodal Concept Bottleneck Models](https://arxiv.org/abs/2411.17471)
> *新概念学习与旧概念记忆：多模态概念瓶颈模型的持续学习*

*Songning Lai, Mingqian Liao, Zhangyi Hu, Jiayu Yang, Wenshuo Chen, Hongru Xiao, Jianheng Tang, Haicheng Liao, Yutao Yue* | **Category: cs.LG, cs.CR, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 概念瓶颈模型,持续学习,多模态学习,灾难性遗忘,线性回归

**Comment:** 

> **TL;DR:** 本研究提出了CONCIL框架，一种用于概念瓶颈模型（CBM）的持续学习新方法，通过将概念和决策层更新重新构建为线性回归问题，利用递归矩阵运算有效解决了灾难性遗忘问题，实现了绝对知识记忆，并在概念和类别增量学习方面显著优于传统CBM方法。

**AI_Comments:** 该研究在概念瓶颈模型（CBMs）领域取得了重要进展，通过引入CONCIL框架有效解决了持续学习中的关键挑战，特别是灾难性遗忘问题。其创新的方法，即将概念和决策层更新重构为线性回归问题，并利用递归矩阵运算，不仅提高了计算效率，而且实现了“绝对知识记忆”，这在理论和实践上都具有重要意义。该研究为处理不断变化的多模态数据提供了新的思路和有效的解决方案，尤其是在需要实时性和可解释性的应用场景中，其价值尤为突出。然而，未来可以进一步探索该方法在更复杂、更大规模的多模态数据集上的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有概念瓶颈模型（CBMs）通常假设静态数据集，无法适应现实世界中不断演变的多模态数据流，限制了其在动态多模态理解中的应用。

**Method:** 提出CONCIL（CONceptual Continual Incremental Learning）框架，将概念和决策层更新重构为线性回归问题，仅依赖递归矩阵运算，避免了基于梯度的优化，从而防止灾难性遗忘。

**Result:** CONCIL实现了“绝对知识记忆”，在概念增量和类别增量设置中均显著优于传统CBM方法。

**Conclusion:** CONCIL框架为CBMs的持续学习开辟了新范式，能够有效处理概念和类别增量学习，实现知识的持续获取和保留，特别适用于需要实时和大规模处理的动态多模态数据应用。

> **ai_Abstract:** 本研究提出了一种名为CONCIL的新型框架，用于解决概念瓶颈模型（CBMs）在持续学习中的挑战。CONCIL通过将概念和决策层的更新视为线性回归问题，并仅使用递归矩阵运算，有效避免了灾难性遗忘，实现了“绝对知识记忆”。实验证明，CONCIL在概念和类别增量学习任务上均表现优于传统CBM方法，为处理动态多模态数据提供了更优的解决方案。

> **摘要翻译:** 概念瓶颈模型（CBMs）增强了人工智能系统的可解释性，特别是通过连接视觉输入和人类可理解的概念，有效地充当了多模态可解释性模型的一种形式。然而，现有的CBMs通常假设静态数据集，这从根本上限制了它们适应现实世界中不断演变的多模态数据流的能力。为了解决这个问题，我们为CBMs定义了一个新颖的持续学习任务：同时处理概念增量和类别增量学习。这个任务要求模型在持续获取新概念（通常代表跨模态属性）和类别的同时，稳健地保留先前学到的知识。为了解决这个具有挑战性的问题，我们提出了CONCIL（CONceptual Continual Incremental Learning），一个新颖的框架，它从根本上将概念和决策层的更新重新构想为线性回归问题。这种重构消除了对基于梯度优化的需求，从而有效地防止了灾难性遗忘。至关重要的是，CONCIL仅依赖于递归矩阵运算，使其计算效率极高，非常适合实时和大规模的多模态数据应用。实验结果有力地证明，CONCIL实现了“绝对知识记忆”，并在概念增量和类别增量设置方面显著优于传统的CBM方法，从而为CBMs的持续学习建立了一个新的范式，这对于动态多模态理解尤其有价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [836] [Towards Interpretable Concept Learning over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2508.03269)
> *走向通过时间逻辑语义可解释的概念学习*

*Irene Ferfoglia, Simone Silvetti, Gaia Saveri, Laura Nenzi, Luca Bortolussi* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 时间序列分类, 可解释性, 神经符号框架, 信号时间逻辑, 逻辑概念

**Comment:** 

> **TL;DR:** 该研究提出了一种新颖的神经符号框架，用于时间序列分类，该框架将时间序列直接嵌入信号时间逻辑（STL）概念空间，以实现可解释性。通过使用新的STL启发式核，该模型在优化准确性的同时，还生成了与预测相关的逻辑概念，从而提供基于人类可理解的时间模式的分类和符号解释。初步结果表明，该方法具有竞争力，并能为模型决策提供高质量的逻辑依据。

**AI_Comments:** 该研究有效地结合了深度学习的分类能力和符号逻辑的可解释性，为时间序列分析领域带来了新的视角。通过将时间序列映射到STL概念空间，该方法解决了“黑箱”模型的固有局限性。然而，预定义STL公式的选择和构建可能是一个挑战，并且其泛化能力和在大规模数据集上的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列分类在安全关键应用中至关重要，但现有的深度学习方法通常是“黑箱”，难以理解其输出的根本原因。

**Method:** 提出了一种神经符号框架，将时间序列直接嵌入信号时间逻辑（STL）概念空间。引入了一种新颖的STL启发式核，将原始时间序列映射到其与预定义STL公式的对齐程度。该模型联合优化准确性和可解释性。

**Result:** 初步结果显示，该方法具有竞争力，同时为模型决策提供了高质量的逻辑依据。

**Conclusion:** 该神经符号框架能够实现基于人类可理解的时间模式的时间序列分类，并提供本地和全局的符号解释。

> **ai_Abstract:** 该研究提出了一种神经符号框架，用于解决时间序列分类中的可解释性问题。该框架将时间序列数据与信号时间逻辑（STL）概念相结合，通过一个新颖的STL启发式核实现，该核能够衡量时间序列与预定义逻辑公式的匹配程度。这种方法不仅提高了分类的准确性，还通过提供与预测相关的逻辑概念来增强模型的可解释性，从而实现基于人类可理解的时间模式的分类，并生成本地和全局的符号解释。初步实验结果表明，该框架在保持竞争力的同时，能够提供高质量的逻辑依据。

> **摘要翻译:** 时间序列分类是一项至关重要的任务，因为这类数据通常出现在安全关键的应用中。然而，它通常通过黑箱深度学习方法来解决，使得人类难以理解其输出背后的基本原理。为了应对这一挑战，我们提出了一种神经符号框架，通过将轨迹直接嵌入信号时间逻辑（STL）概念空间来统一分类和解释。通过引入一种新颖的STL启发式核，将原始时间序列映射到其与预定义STL公式的对齐程度，我们的模型联合优化准确性和可解释性，因为每个预测都伴随着表征它的最相关的逻辑概念。这使得分类能够以人类可理解的时间模式为基础，并产生本地和全局的符号解释。早期结果表明，该方法具有竞争力，同时能为模型决策提供高质量的逻辑依据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [843] [Online Continual Graph Learning](https://arxiv.org/abs/2508.03283)
> *在线持续图学习*

*Giovanni Donghi, Luca Pasa, Daniele Zambon, Cesare Alippi, Nicolò Navarin* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 在线持续图学习,图神经网络,灾难性遗忘,数据流,基准测试

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出了在线持续图学习的通用公式，并提供了基准测试，以解决现实世界中不断变化的图数据和GNN的在线学习问题。

**AI_Comments:** 该研究为图数据的在线持续学习提供了一个重要的框架和基准，解决了现实世界中图数据动态变化的挑战。然而，文中并未详细说明所提出的通用公式的具体数学形式以及所引入基准测试的详细配置。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的图数据会随着时间演变，需要及时和在线的预测，但现有的持续图学习方法与在线持续学习的设置不符，并且缺乏明确的在线持续图学习的定义。

**Method:** 提出一个通用的在线持续图学习公式，强调在图拓扑上进行批处理的效率要求，并提供一个明确的设置用于系统化的模型评估。最后，引入了一套基准测试，并报告了几种适应于该设置的持续学习方法的性能。

**Result:** 引入了一套基准测试，并报告了几种适应于该设置的持续学习方法的性能。

**Conclusion:** 本文提出了一个在线持续图学习的通用公式和评估设置，为该领域的研究奠定了基础。

> **ai_Abstract:** 本文提出了一种针对图数据的在线持续学习（OCL）通用公式和评估框架，以解决现实世界中不断演变的图数据流问题。研究强调了在图拓扑上进行高效批处理的要求，并为该领域的系统化评估提供了明确的设置。此外，还引入了一套基准测试，并评估了几种现有持续学习方法在该框架下的表现。

> **摘要翻译:** 持续学习（CL）的目的是在学习新任务的同时增量地学习，同时避免灾难性的遗忘。在线持续学习（OCL）特别关注从具有不断变化分布的数据流中进行有效学习。虽然最近的研究利用图神经网络（GNN）探索了图上的持续学习，但很少有研究关注流式传输设置。然而，许多现实世界的图会随着时间演变，通常需要及时和在线的预测。然而，目前的方法与标准的OCL设置不太一致，部分原因是缺乏对图上在线持续学习的明确定义。在本文中，我们提出了图上在线持续学习的通用公式，强调在图拓扑上进行批处理的效率要求，并提供一个明确的设置用于系统化的模型评估。最后，我们引入了一套基准测试，并报告了几种适应于该设置的持续学习方法的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [844] [A neural network machine-learning approach for characterising hydrogen trapping parameters from TDS experiments](https://arxiv.org/abs/2508.03371)
> *一种用于表征TDS实验氢陷参数的神经网络机器学习方法*

*N. Marrani, T. Hageman, E. Martínez-Pañeda* | **Category: cs.LG, cs.CE, physics.chem-ph** | **Updated: 2025-08-05**

**Keywords:** 热脱附光谱, 氢陷参数, 神经网络, 机器学习, 金属合金

**Comment:** 

> **TL;DR:** 该研究提出了一种基于机器学习（特别是多神经网络模型）的方法，用于从热脱附光谱（TDS）数据中直接提取金属合金的氢陷参数（如结合能和密度），解决了传统TDS方法提取参数的挑战，并在三种马氏体钢上验证了其有效性。

**AI_Comments:** 这项研究通过引入机器学习方法，为从TDS实验数据中提取关键材料参数提供了一种创新且高效的解决方案。其优势在于能够直接从光谱数据中预测参数，减少了传统间接方法的复杂性和不确定性。模型设计考虑了数据效率，这对于实际应用非常重要。然而，仅使用合成数据进行训练的策略可能会限制模型在处理复杂或未知实验条件下的泛化能力，未来可以进一步探索结合部分实验数据进行微调的可能性。代码的开源共享是一个亮点，有助于推动相关领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的TDS方法在从光谱数据中提取氢陷参数（结合能和密度）方面存在挑战，本研究旨在解决这些局限性。

**Method:** 开发并训练了一个仅使用合成数据进行训练的多神经网络（NN）模型。该模型包含两个多层、全连接、前馈神经网络，使用反向传播进行训练。第一个网络（分类模型）用于预测不同陷阱类型的数量，第二个网络（回归模型）用于预测相应的陷阱密度和结合能。通过优化网络架构、超参数和数据预处理来最小化训练数据量。

**Result:** 所提出的模型在应用于三种不同成分的回火马氏体钢时，表现出强大的预测能力。

**Conclusion:** 该研究成功开发了一种基于机器学习的方法，可以从TDS光谱中直接识别氢陷参数，并证明了其在实际材料上的有效性。

> **ai_Abstract:** 本研究提出了一种新颖的基于机器学习的方法，利用多神经网络模型从热脱附光谱（TDS）数据中直接提取金属合金的氢陷参数（结合能和密度）。该方法通过分类网络预测陷阱数量，并通过回归网络预测具体参数，有效解决了传统TDS方法的局限性。研究结果表明，该模型在三种回火马氏体钢上具有良好的预测性能，并且通过优化设计，所需的训练数据量得到了最小化。

> **摘要翻译:** 金属合金的氢陷行为通常使用热脱附光谱（TDS）进行表征。然而，作为一种间接方法，提取关键参数（陷阱结合能和密度）仍然是一个重大挑战。为了解决这些局限性，这项工作引入了一种基于机器学习的方案，用于从TDS光谱中识别参数。开发了一个仅使用合成数据进行训练的多神经网络（NN）模型，用于直接从实验数据中预测陷阱参数。该模型包括两个多层、全连接、前馈神经网络，通过反向传播进行训练。第一个网络（分类模型）预测不同陷阱类型的数量。第二个网络（回归模型）然后预测相应的陷阱密度和结合能。对NN架构、超参数和数据预处理进行了优化，以最小化训练数据量。所提出的模型在应用于三种不同成分的回火马氏体钢时，表现出强大的预测能力。所开发的代码是免费提供的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [845] [Forecasting NCAA Basketball Outcomes with Deep Learning: A Comparative Study of LSTM and Transformer Models](https://arxiv.org/abs/2508.02725)
> *利用深度学习预测NCAA篮球比赛结果：LSTM与Transformer模型的比较研究*

*Md Imtiaz Habib* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 深度学习, LSTM, Transformer, NCAA篮球, 预测模型

**Comment:** 20 page scientific report

> **TL;DR:** 本研究使用LSTM和Transformer模型，结合特征工程和不同的损失函数，来预测2025年NCAA篮球比赛结果。结果显示Transformer模型在区分能力上更优，而LSTM模型在概率校准上表现更好。

**AI_Comments:** 这项研究为体育预测分析提供了一个严谨的比较框架，特别是在深度学习模型和损失函数的选择方面。Transformer和LSTM在不同评估指标上的表现差异，突显了在实际应用中根据具体目标（如提高准确率还是概率校准）来定制模型的重要性。研究的亮点在于其可复现性，为未来的研究奠定了基础。然而，仅限于2025年的数据可能限制了模型的普适性，未来可以考虑纳入更多年份的数据以增强模型的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了预测NCAA篮球比赛结果，探索和比较LSTM和Transformer这两种深度学习序列模型的预测能力。

**Method:** 使用LSTM和Transformer模型，并结合特征工程（包括GLM、Elo评分、种子差异、比赛统计数据）和两种损失函数（二元交叉熵和Brier损失）来训练和评估模型。

**Result:** Transformer模型（使用BCE损失）具有更高的区分能力（AUC为0.8473），而LSTM模型（使用Brier损失）具有更好的概率校准（Brier得分为0.1589）。

**Conclusion:** 选择合适的模型架构和损失函数对于预测任务至关重要，Transformer模型在区分能力上表现优异，而LSTM模型在概率校准上表现更好。

> **ai_Abstract:** 本研究比较了LSTM和Transformer深度学习模型在预测2025年NCAA篮球比赛结果方面的表现。通过结合GLM、Elo评分等特征工程和BCE、Brier损失函数，研究发现Transformer模型在区分能力上更胜一筹（AUC为0.8473），而LSTM模型在概率校准方面表现更好（Brier得分为0.1589）。研究强调了根据特定需求选择模型和损失函数的重要性，并提供了一个可复现的分析框架。

> **摘要翻译:** 本研究旨在探索先进的深度学习方法，以预测2025年NCAA甲级男子和女子篮球锦标赛的结果。利用历史NCAA比赛数据，我实现了两种复杂的序列模型：长短期记忆（LSTM）和Transformer架构。这些模型的预测能力通过全面的特征工程得到增强，包括源自广义线性模型（GLM）、Elo评分、种子差异和汇总的比赛统计数据的球队质量指标。为了评估预测的稳健性和可靠性，我使用二元交叉熵（BCE）和Brier损失函数来训练每个模型的变体，从而深入了解分类性能和概率校准。我的比较分析显示，虽然使用BCE优化的Transformer架构产生了优越的区分能力（最高的AUC为0.8473），但使用Brier损失训练的LSTM模型表现出优越的概率校准（最低的Brier得分为0.1589）。这些发现强调了根据预测任务的具体要求选择合适的模型架构和损失函数的重要性。这里提出的详细分析流程为体育分析及其他领域的未来预测建模任务提供了一个可复现的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [846] [Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented Generation](https://arxiv.org/abs/2508.02835)
> *防御检索增强生成过程中的知识投毒攻击*

*Kennedy Edemacu, Vinay M. Shashidhar, Micheal Tuape, Dan Abudu, Beakcheol Jang, Jong Wook Kim* | **Category: cs.LG, cs.IR** | **Updated: 2025-08-04**

**Keywords:** 检索增强生成, 知识投毒, 防御方法, FilterRAG, PoisonedRAG

**Comment:** Preprint for Submission

> **TL;DR:** 提出FilterRAG和ML-FilterRAG方法来防御PoisonedRAG攻击，通过识别和过滤掉知识库中的对抗性文本来保护检索增强生成模型。

**AI_Comments:** 这项研究解决了检索增强生成（RAG）领域的一个关键安全问题——知识投毒攻击。提出的FilterRAG和ML-FilterRAG方法通过识别和过滤对抗性文本来提供一种有效的防御机制，这对于确保RAG系统在实际应用中的可靠性和安全性至关重要。该研究的创新之处在于提出了区分干净文本和对抗性文本的新属性，并将其应用于实际防御策略。然而，该方法在面对更复杂或未知类型的投毒攻击时的鲁棒性仍有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）虽然能增强大型语言模型（LLM）的能力，但也引入了知识投毒攻击的风险，攻击者可以利用受损的知识源来误导模型生成虚假信息。

**Method:** 提出了一种新的属性来区分对抗性文本和干净文本，并基于此属性设计了FilterRAG和ML-FilterRAG两种防御方法，用于过滤掉知识数据源中的对抗性文本。

**Result:** 评估结果表明，所提出的防御方法在性能上接近原始的RAG系统，有效减轻了PoisonedRAG攻击。

**Conclusion:** FilterRAG和ML-FilterRAG是有效的防御检索增强生成中知识投毒攻击的方法，它们通过识别和过滤对抗性文本来保护模型的完整性。

> **ai_Abstract:** 本研究提出了一种名为FilterRAG和ML-FilterRAG的新型防御机制，旨在应对检索增强生成（RAG）系统中的知识投毒攻击（特别是PoisonedRAG）。研究人员开发了一种新属性来识别和区分知识源中的对抗性文本，并利用该属性过滤掉这些有害文本，从而保护RAG系统免受攻击。实验结果表明，这些防御方法能够有效减轻攻击的影响，并且性能与原始RAG系统相当。

> **摘要翻译:** 检索增强生成（RAG）已成为一种强大的方法，通过整合外部、最新的知识源来提升大型语言模型（LLM）的能力。然而，这也引入了知识投毒攻击的潜在漏洞，在这种攻击中，攻击者可以破坏知识源以误导生成模型。其中一种攻击是PoisonedRAG，在这种攻击中，注入的对抗性文本会引导模型对目标问题生成攻击者选择的响应。在这项工作中，我们提出了新颖的防御方法FilterRAG和ML-FilterRAG来减轻PoisonedRAG攻击。首先，我们提出了一个新的属性来揭示区分知识数据源中对抗性文本和干净文本的独特属性。接下来，我们在提出的方法设计中利用这一属性来过滤掉对抗性文本。使用基准数据集对这些方法的评估证明了它们的有效性，性能接近原始RAG系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [850] [Strategic Hypothesis Testing](https://arxiv.org/abs/2508.03289)
> *策略性假设检验*

*Safwan Hossain, Yatong Chen, Yiling Chen* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 假设检验,主代理理论,博弈论,p值阈值,信息不对称

**Comment:** 

> **TL;DR:** 该研究在主代理框架下研究假设检验，考虑了代理人的策略性报告行为，并提出了一个最优p值阈值的解析方法，通过药物审批数据进行了实证验证。

**AI_Comments:** 该研究将博弈论应用于假设检验，解决了信息不对称和激励兼容性问题，具有重要的理论和实践意义。然而，模型的可扩展性和对其他领域的适用性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 在主代理框架下，代理人拥有关于产品有效性的私有信息，并向代理人提交数据以决定是否批准。主代理人需要设定一个p值阈值，以平衡错误肯定和错误否定，同时要考虑到代理人的激励机制。

**Method:** 利用博弈论模型来捕捉代理人的参与和报告行为如何响应主代理人的统计决策规则，并推导出主代理人最优p值阈值的解析方法。

**Result:** 尽管交互复杂，但主代理人的错误会随着一个可计算的关键p值阈值表现出清晰的单调行为，从而可以明确地刻画出最优p值阈值。

**Conclusion:** 该研究为假设检验框架下的策略性互动提供了全面的视角，并为技术和监管提供了见解。

> **ai_Abstract:** 本研究在主代理框架下，通过博弈论模型分析了代理人的策略性报告行为对主代理人假设检验决策的影响。研究发现，主代理人的错误呈现出清晰的单调行为，并推导出了最优p值阈值的解析方法，该方法考虑了代理人的激励机制。研究通过药物审批数据进行了实证验证，为假设检验中的策略互动和监管提供了有价值的见解。

> **摘要翻译:** 我们研究了主代理框架下的假设检验，其中战略代理人拥有关于产品有效性的私有信念，并将数据提交给决定批准的代理人。代理人采用假设检验规则，旨在选择一个p值阈值，在预期代理人最大化预期盈利能力的同时，平衡假阳性和假阴性。在先前工作的基础上，我们开发了一个博弈论模型，该模型捕捉了代理人的参与和报告行为如何响应代理人的统计决策规则。尽管交互复杂，我们表明，当按一个可有效计算的关键p值阈值进行分割时，代理人的错误会表现出清晰的单调行为，从而导致对其最优p值阈值的可解释的刻画。我们使用有关药物审批的公开数据对我们的模型和这些见解进行了经验验证。总的来说，我们的工作为假设检验框架下的策略互动提供了全面的视角，并提供了技术和监管方面的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [855] [Vertical Federated Continual Learning via Evolving Prototype Knowledge](https://arxiv.org/abs/2502.09152)
> *垂直联邦持续学习通过演化原型知识*

*Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu* | **Category: cs.LG, cs.NE** | **Updated: 2025-08-05**

**Keywords:** 垂直联邦学习,持续学习,灾难性遗忘,原型知识,模型优化

**Comment:** 

> **TL;DR:** 本研究提出了一种名为V-LETO的新型垂直联邦持续学习方法，通过演化原型知识来解决灾难性遗忘问题，并在分类和特征持续学习任务中取得了优于现有方法的性能。

**AI_Comments:** 这项研究解决了垂直联邦学习中的一个重要问题——灾难性遗忘。通过提出一种新颖的演化原型知识的方法，V-LETO能够有效地在持续学习场景中保留和转移知识。该方法在CIL和FIL任务上的性能提升显著，表明了其潜力和有效性。代码的公开也为后续研究提供了便利。

<details>
  <summary>Details</summary>

**Motivation:** 传统的垂直联邦学习（VFL）方法无法解决类别和特征持续学习的挑战，导致先前任务的知识被遗忘。

**Method:** 提出了一种名为V-LETO的新型垂直联邦持续学习方法，该方法通过演化原型知识来促进先前任务知识的转移，并引入了一种通过限制局部模型特定参数更新的模型优化技术来缓解先前任务知识的遗忘。

**Result:** V-LETO方法在CIL和FIL设置下均优于其他最先进方法，分别提高了10.39%和35.15%。

**Conclusion:** V-LETO通过演化原型知识和优化模型更新，成功解决了垂直联邦持续学习中的灾难性遗忘问题，并在实验中表现出优越的性能。

> **ai_Abstract:** 本研究提出了一种名为V-LETO的垂直联邦持续学习方法，通过演化原型知识来解决灾难性遗忘问题。该方法通过允许全局模型保留先前和当前任务的知识，并限制局部模型参数更新来优化性能。实验证明V-LETO在CIL和FIL任务上均优于现有方法。

> **摘要翻译:** 垂直联邦学习（VFL）作为一种用于样本对齐特征联邦的隐私保护机器学习框架，已引起了广泛关注。然而，传统的VFL方法并未解决类别和特征持续学习的挑战，导致先前任务知识的灾难性遗忘。为了解决上述挑战，我们提出了一种名为“通过演化原型知识的垂直联邦持续学习”（V-LETO）的新型垂直联邦持续学习方法，该方法主要通过原型知识的演化来促进先前任务知识的转移。具体来说，我们提出了一种演化原型知识的方法，使全局模型能够保留先前和当前任务的知识。此外，我们引入了一种模型优化技术，通过限制对局部模型特定参数的更新来缓解先前任务知识的遗忘，从而提高整体性能。在CIL和FIL设置下进行的广泛实验表明，我们的V-LETO方法优于其他最先进的方法。例如，我们的方法在CIL和FIL任务上分别比最先进的方法提高了10.39%和35.15%。我们的代码可在https://anonymous.4open.science/r/V-LETO-0108/README.md获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [857] [Average-Reward Soft Actor-Critic](https://arxiv.org/abs/2501.09080)
> *平均奖励软 Actor-Critic*

*Jacob Adamczyk, Volodymyr Makarenko, Stas Tiomkin, Rahul V. Kulkarni* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 平均奖励, 软 Actor-Critic, 熵正则化, 深度强化学习, Actor-Critic

**Comment:** Accepted at the 2nd Reinforcement Learning Conference (Journal Track)

> **TL;DR:** 提出了一种新的平均奖励软 Actor-Critic 算法，该算法结合了平均奖励和熵正则化的优点，并在标准 RL 基准测试中取得了优于现有算法的性能。

**AI_Comments:** 该研究填补了平均奖励强化学习与熵正则化相结合的空白，提出了一种新颖的 Actor-Critic 算法。实验结果显示了其在平均奖励标准上的优越性，但关于算法的具体实现细节、理论分析以及在更广泛问题上的泛化能力仍有待深入探讨。

<details>
  <summary>Details</summary>

**Motivation:** 解决在平均奖励设定下，如何结合熵正则化以改进深度强化学习算法的问题，并填补了平均奖励 Actor-Critic 框架的空白。

**Method:** 提出并实现了一种平均奖励软 Actor-Critic 算法。

**Result:** 所提出的算法在标准 RL 基准测试中，在平均奖励标准上取得了优于现有算法的性能。

**Conclusion:** 所提出的平均奖励软 Actor-Critic 算法能够有效地解决平均奖励设定下的强化学习问题，并取得优于现有算法的性能。

> **ai_Abstract:** 本文提出了一种平均奖励软 Actor-Critic 算法，旨在解决深度强化学习在平均奖励设定下结合熵正则化的问题。该算法结合了平均奖励公式化和熵正则化的优点，填补了相关研究的空白。实验结果表明，该算法在标准强化学习基准测试中，在平均奖励标准上优于现有算法。

> **摘要翻译:** 近年来，平均奖励公式化在强化学习（RL）中的应用引起了越来越多的关注，因为它能够在不依赖折扣的情况下解决时间跨度较长的问题。同时，在折扣设定下，已经开发出具有熵正则化的算法，从而改进了确定性方法。尽管这些方法具有独特的优点，但尚未开发出针对熵正则化平均奖励目标的深度强化学习算法。虽然最近为平均奖励文献提出了基于策略梯度的方​​法，但相应的 Actor-Critic 框架的探索仍然较少。在本文中，我们介绍了一种平均奖励软 Actor-Critic 算法来解决该领域的这些空白。我们通过在标准 RL 基准上与现有的平均奖励算法进行比较来验证我们的方法，在平均奖励标准上取得了优越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [859] [Bridging ocean wave physics and deep learning: Physics-informed neural operators for nonlinear wavefield reconstruction in real-time](https://arxiv.org/abs/2508.03315)
> *海洋波浪物理与深度学习的桥梁：用于非线性波场实时重建的物理信息神经网络算子*

*Svenja Ehlers, Merten Stender, Norbert Hoffmann* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 物理信息神经网络算子, 海洋波场重建, 深度学习, 非线性波, 数据同化

**Comment:** 13 pages, 7 figures

> **TL;DR:** 提出了一种物理信息神经网络算子（PINO）框架，用于从稀疏测量数据中实时重建非线性海浪波场，无需地面实况数据进行训练，通过将自由表面边界条件残差嵌入损失函数来实现。

**AI_Comments:** 这项研究巧妙地结合了物理学原理和深度学习技术，解决了海洋波场重建中的一个关键难题。通过物理信息神经网络算子（PINO）将物理约束嵌入模型，该方法在数据稀疏的情况下表现出色，避免了对昂贵地面实况数据的依赖。其在实时重建和泛化能力方面的成果尤为突出，为海洋科学和工程领域带来了重要的实际应用价值。未来的工作可以进一步探索PINO在处理更复杂海洋现象或与其他数据源融合方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 准确的实时相位分辨海浪波场预测是一个关键但尚未解决的问题，主要是由于缺乏实用的数据同化方法从稀疏或间接的波浪测量中重建初始条件。现有监督深度学习方法需要大量标记的地面实况波浪数据，这在现实世界中难以获得。

**Method:** 提出了一种物理信息神经网络算子（PINO）框架，通过将海洋重力波自由表面边界条件的残差软约束到PINO的损失函数中，实现了从稀疏测量中重建空间和时间上相位分辨的非线性海浪波场，且训练时无需地面实况数据。

**Result:** PINO框架能够准确地从浮标时间序列和雷达快照中重建非线性波场，并且在广泛的波浪条件下表现出鲁棒的泛化能力，实现了准确的实时重建。

**Conclusion:** PINO框架为在真实的海洋环境中进行操作性的、数据驱动的波浪重建和预测铺平了道路。

> **ai_Abstract:** 该研究提出了一种名为物理信息神经网络算子（PINO）的新框架，用于解决实时预测相位分辨海浪波场的挑战。与需要大量地面实况数据的传统深度学习方法不同，PINO通过将物理定律（具体来说是自由表面边界条件）的残差嵌入到神经网络的损失函数中，从而能够从稀疏的测量数据中进行训练和重建，而无需地面实况数据。实验结果表明，该方法能够准确地从浮标数据和雷达快照中重建非线性波场，并且在各种条件下都表现出良好的泛化能力，为实际的海洋环境中的波浪监测和预测提供了新的途径。

> **摘要翻译:** 准确的实时相位分辨海浪波场预测仍然是一个关键但尚未完全解决的问题，这主要是由于缺乏实用的数据同化方法，以便从稀疏或间接的波浪测量中重建初始条件。虽然最近监督深度学习的进展显示出这方面的潜力，但它们需要大量的地面实况波浪数据的标记数据集，而这在现实场景中是无法获得的。为了克服这一限制，我们提出了一个物理信息神经网络算子（PINO）框架，用于从稀疏测量中重建空间和时间上相位分辨的非线性海浪波场，而无需在训练期间进行地面实况数据。这是通过将海洋重力波的自由表面边界条件的残差软约束到PINO的损失函数中来实现的。训练后，我们使用高度真实的合成波浪数据验证了我们的方法，并展示了从浮标时间序列和雷达快照中对非线性波场的准确重建。我们的结果表明，PINO能够实现准确的实时重建，并在广泛的波浪条件下表现出鲁棒的泛化能力，从而为在真实的海洋环境中进行操作性的、数据驱动的波浪重建和预测铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [861] [HALO: Hindsight-Augmented Learning for Online Auto-Bidding](https://arxiv.org/abs/2508.03267)
> *HALO：用于在线自动竞价的后视增强学习*

*Pusen Dong, Chenglong Cao, Xinyu Zhou, Jirong You, Linhe Xu, Feifan Xu, Shuo Yuan* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 在线自动竞价,多约束竞价,后视学习,B样条,实时竞价

**Comment:** 13 pages, 5 figures

> **TL;DR:** HALO是一种新的在线自动竞价方法，通过“后视”机制和B样条函数表示，解决了传统方法的样本效率低和泛化能力差的问题，在工业数据集上表现出优越的性能。

**AI_Comments:** 该研究提出的HALO方法在解决数字广告竞价中的多约束适应性问题上具有创新性，其后视机制和B样条函数表示为提高样本效率和泛化能力提供了新的思路。然而，关于该方法在不同规模和复杂度的广告平台上的普适性以及计算成本方面的进一步研究将是有价值的。

<details>
  <summary>Details</summary>

**Motivation:** 传统自动竞价方法在处理数字广告平台中多变的预算和投资回报率（ROI）目标时存在样本效率低下和泛化能力不足的问题，因为它们无法有效利用失败的探索数据，也未能考虑约束之间的物理关系。

**Method:** HALO引入了一个基于理论的后视机制，通过轨迹重定向将所有探索转化为训练数据，以适应任意的约束配置。此外，它采用B样条函数表示，实现了跨约束空间的连续、可导的竞价映射。

**Result:** 在工业数据集上的评估表明，HALO在处理多尺度约束方面表现出优越性，能够减少约束违反并提高GMV（总商品销售额）。

**Conclusion:** HALO通过其创新的后视机制和B样条函数表示，有效解决了在线自动竞价中的多约束适应性问题，并在实际应用中取得了显著的性能提升。

> **ai_Abstract:** HALO是一种新颖的在线自动竞价方法，通过引入“后视”机制来重新利用所有探索数据，并结合B样条函数表示来处理约束变化，解决了传统方法在样本效率和泛化能力方面的不足，并在工业数据评估中显示出优越性能。

> **摘要翻译:** 数字广告平台通过实时竞价（RTB）系统进行毫秒级拍卖，广告商通过算法出价争夺广告展示机会。这种动态机制能够实现精准的受众定位，但由于广告商的异质性，其运营复杂性也大大增加：从个人商户到跨国品牌，预算和投资回报率（ROI）目标跨越多个数量级。这种多样性为多约束竞价（MCB）带来了严峻的适应性挑战。传统的自动竞价解决方案在这种环境下会失效，主要有两个关键缺陷：1）严重的样本效率低下，在特定约束下的失败探索无法为新的预算-ROI组合提供可转移的知识；2）在约束变化下的泛化能力有限，因为它们忽略了约束和竞价系数之间的物理关系。为了解决这个问题，我们提出了HALO：用于在线自动竞价的后视增强学习。HALO引入了一个基于理论的后视机制，通过轨迹重定向将所有探索转化为训练数据，以适应任意的约束配置。此外，它采用了B样条函数表示，实现了跨约束空间的连续、可导的竞价映射。HALO即使在预算/ROI要求与训练场景差异很大的情况下，也能确保鲁棒的适应性。工业数据集评估证明了HALO在处理多尺度约束方面的优越性，在提高GMV的同时减少了约束违反。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [862] [SALAD: Systematic Assessment of Machine Unlearning on LLM-Aided Hardware Design](https://arxiv.org/abs/2506.02089)
> *SALAD：LLM辅助硬件设计的机器反学习系统评估*

*Zeng Wang, Minghao Shao, Rupesh Karn, Likhitha Mankali, Jitendra Bhandari, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel* | **Category: cs.LG, cs.AI, cs.CR** | **Updated: 2025-08-05**

**Keywords:** 机器反学习,大型语言模型,硬件设计,数据安全,Verilog

**Comment:** 

> **TL;DR:** SALAD通过机器反学习技术，解决了LLM在硬件设计中带来的数据安全问题，如数据污染、知识产权泄露和恶意代码生成，无需完全重新训练即可移除不良数据。

**AI_Comments:** 该研究首次系统性地评估了机器反学习在LLM辅助硬件设计中的应用，解决了实际工程中面临的关键数据安全挑战，具有重要的理论和实践意义。其无需完全重新训练即可移除不良数据的能力，为LLM的安全应用提供了有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在硬件设计自动化中（尤其是在Verilog代码生成方面）展现了变革潜力，但也带来了数据安全挑战，包括Verilog评估数据污染、知识产权（IP）设计泄露以及恶意Verilog生成风险。

**Method:** SALAD利用机器反学习技术，选择性地从预训练的LLM中移除受污染的基准测试、敏感IP和设计构件或恶意代码模式。

**Result:** 通过详细的案例研究，证明了机器反学习技术能有效降低LLM辅助硬件设计中的数据安全风险。

**Conclusion:** 机器反学习技术是应对LLM在硬件设计中数据安全挑战的有效手段。

> **ai_Abstract:** SALAD是一项针对LLM辅助硬件设计的评估框架，专注于利用机器反学习技术解决数据安全问题，如Verilog数据污染、IP泄露和恶意代码生成，无需重新训练即可实现对LLM的“反学习”。

> **摘要翻译:** 大型语言模型（LLM）为硬件设计自动化提供了变革性的能力，尤其是在Verilog代码生成方面。然而，它们也带来了严峻的数据安全挑战，包括Verilog评估数据污染、知识产权（IP）设计泄露以及恶意Verilog生成风险。我们引入了SALAD，这是一项利用机器反学习来缓解这些威胁的全面评估。我们的方法能够在无需完全重新训练的情况下，选择性地从预训练的LLM中移除受污染的基准测试、敏感IP和设计构件或恶意代码模式。通过详细的案例研究，我们展示了机器反学习技术如何有效地降低LLM辅助硬件设计中的数据安全风险。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [867] [Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?](https://arxiv.org/abs/2508.03323)
> *软件公平性困境：偏见缓解是零和博弈吗？*

*Zhenpeng Chen, Xinyue Li, Jie M. Zhang, Weisong Sun, Ying Xiao, Tianlin Li, Yiling Lou, Yang Liu* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 公平性, 偏见缓解, 表格数据, 零和博弈, 弱势群体

**Comment:** Accepted by the ACM International Conference on the Foundations of
  Software Engineering (FSE 2025)

> **TL;DR:** 偏见缓解在表格数据任务中表现为零和博弈，但有方法可以缓解这一困境。

**AI_Comments:** 该研究对机器学习公平性领域做出了重要贡献，特别是揭示了表格数据任务中偏见缓解的零和博弈现象，并提出了一种有前景的解决方案。研究方法严谨，实验覆盖面广，结果具有说服力。未来的工作可以进一步探索该解决方案在不同类型表格数据和更复杂模型上的适用性，以及量化其对实际应用的影响。

<details>
  <summary>Details</summary>

**Motivation:** 评估现有偏见缓解方法在表格数据上的表现，并探索无零和博弈的缓解策略。

**Method:** 评估了八种用于表格数据的偏见缓解方法，涵盖了44个任务、五个真实世界数据集和四种常用机器学习模型。

**Result:** 与先前研究不同，本研究发现偏见缓解方法呈零和博弈状态，即对弱势群体的改进与对优势群体收益的减少相关。然而，一种仅将最先进的偏见缓解方法应用于弱势群体的方法显示出在不影响优势群体或整体机器学习性能的情况下，增强弱势群体收益的潜力。

**Conclusion:** 本研究表明，可以通过特定策略实现公平性改进，而无需零和博弈，这有助于推动偏见缓解方法的应用。

> **ai_Abstract:** 本研究调查了机器学习软件中的公平性问题，特别是偏见缓解方法在表格数据任务中的应用。研究发现，与计算机视觉和自然语言处理任务不同，表格数据任务中的偏见缓解方法呈现零和博弈的特征，即改进弱势群体的公平性可能会降低优势群体的性能。然而，研究也探索了一种新的策略，即仅将最先进的偏见缓解方法应用于弱势群体，并取得了积极成果，即在不损害优势群体或整体模型性能的情况下提高了弱势群体的公平性。这项研究为在不牺牲性能的情况下实现公平性改进提供了新的思路，有助于促进偏见缓解技术的广泛应用。

> **摘要翻译:** 公平性是机器学习（ML）软件的关键要求，推动了众多偏见缓解方法的发展。以往的研究发现在计算机视觉和自然语言处理任务中存在偏见缓解的“水平下降”效应，即通过降低所有群体的性能来实现公平性，而未使弱势群体受益。然而，这种效应是否适用于表格数据任务的偏见缓解，这一公平性研究的关键领域及其重要的现实应用，仍不清楚。本研究在五个真实世界数据集和四种常用机器学习模型上的44个任务中，评估了八种用于表格数据的偏见缓解方法，包括广泛使用和前沿的方法。与以往的研究结果相反，我们的结果表明，这些方法以零和方式运作，即对弱势群体的改进与对传统上优势群体的收益减少有关。然而，以往的研究表明，对零和权衡的看法可能会使公平性政策的更广泛采用复杂化。为了探索替代方案，我们研究了一种仅将最先进的偏见缓解方法应用于弱势群体的方法，该方法显示出在不负面影响优势群体或整体机器学习性能的情况下，增强弱势群体收益的潜力。我们的研究突显了在不进行零和权衡的情况下实现公平性改进的潜在途径，这可能有助于推动偏见缓解方法的应用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [873] [AI on the Pulse: Real-Time Health Anomaly Detection with Wearable and Ambient Intelligence](https://arxiv.org/abs/2508.03436)
> *人工智能在脉搏上：利用可穿戴和环境智能进行实时健康异常检测*

*Davide Gabrielli, Bardh Prenkaj, Paola Velardi, Stefano Faralli* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 实时异常检测,可穿戴智能,环境智能,UniTS,个性化健康监测

**Comment:** 

> **TL;DR:** 该研究提出了一种名为“AI on the Pulse”的实时健康异常检测系统，该系统融合了可穿戴传感器、环境智能和先进的人工智能模型（特别是UniTS时间序列模型），能够自主学习患者的个体生理和行为模式，并实时检测异常以发出预警。该系统在真实家庭环境（@HOME）中成功部署，证明了无需临床级设备即可实现高质量健康监测，并且通过集成大型语言模型提高了可解释性。

**AI_Comments:** 该研究提出了一种名为“AI on the Pulse”的创新性健康异常检测系统，其亮点在于能够实时、个性化地监测患者健康状况，尤其是在家庭环境中。该系统融合了可穿戴设备和环境智能，并采用了先进的UniTS时间序列模型，克服了传统方法对持续标记的依赖。其在真实环境中的成功部署和优于现有方法的性能，以及通过LLM增强的可解释性，都使其具有重要的临床应用价值和研究意义。然而，报告中未提及该系统在处理不同类型异常或应对数据噪声方面的具体局限性，这可能是一个潜在的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统健康异常检测方法依赖于持续标记，这在实际应用中难以实现。本研究旨在开发一种无需持续标记即可进行实时、个性化健康风险预警的系统，以支持家庭主动护理。

**Method:** 本研究提出了一种名为“AI on the Pulse”的系统，该系统融合了可穿戴传感器和环境智能，并利用UniTS这一先进的通用时间序列模型。该系统能够自主学习患者的生理和行为模式，通过异常检测来识别潜在健康风险，并提供实时警报。此外，还集成了大型语言模型（LLMs）以提高可解释性。

**Result:** “AI on the Pulse”系统在真实家庭环境（@HOME）中成功部署，展示了其在连续患者监测方面的实际应用能力。与12种先进的异常检测方法相比，该系统在F1分数上提高了约22%，证明了其在包括ECG和智能手表在内的各种设备上的鲁棒性。

**Conclusion:** “AI on the Pulse”系统成功实现了无需临床级设备的高质量健康监测，并通过融合UniTS模型和LLMs，在真实家庭环境中提供了实时、个性化的健康异常检测和可解释的洞察，证明了其在主动家庭护理中的有效性和实用性。

> **ai_Abstract:** “AI on the Pulse”是一个创新的实时健康异常检测系统，它结合了可穿戴传感器、环境智能和先进的UniTS时间序列模型，无需持续标记即可自主学习个体健康模式并发出预警。该系统已成功应用于真实家庭环境，证明了其在非临床设备上的有效性和鲁棒性，并利用LLM提高了结果的可解释性。

> **摘要翻译:** 我们引入了AI on the Pulse，一个真实世界就绪的异常检测系统，它利用可穿戴传感器、环境智能和先进的人工智能模型的融合来持续监测患者。我们的框架由最先进（SoTA）的通用时间序列模型UniTS提供支持，能够自主学习每个患者独特的生理和行为模式，检测细微的偏差，从而发出潜在健康风险的信号。与需要实际中不切实际的持续标记的分类方法不同，我们的方法使用异常检测来提供实时的、个性化的警报，用于反应性的家庭护理干预。我们的方法在12种SoTA异常检测方法中表现更好，在高质量医疗设备（ECG）和消费类可穿戴设备中都显示出鲁棒性，F1分数提高了约22%。然而，“AI on the Pulse”的真正影响力在于@HOME，它已被成功部署用于连续的、真实的患者监测。通过使用智能手表等非侵入式、轻量级设备运行，我们的系统证明了在没有临床级设备的情况下实现高质量健康监测是可能的。除了检测之外，我们还通过集成LLM来增强可解释性，将异常分数转化为对医疗保健专业人员有临床意义的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [874] [SolarSeer: Ultrafast and accurate 24-hour solar irradiance forecasts outperforming numerical weather prediction across the USA](https://arxiv.org/abs/2508.03590)
> *太阳先知：美国范围内超快、准确的 24 小时太阳辐照度预报，优于数值天气预报*

*Mingliang Bai, Zuliang Fang, Shengyu Tao, Siqi Xiang, Jiang Bian, Yanfei Xiang, Pengcheng Zhao, Weixin Jin, Jonathan A. Weyn, Haiyu Dong, Bin Zhang, Hongyu Sun, Kit Thambiratnam, Qi Zhang, Hongbin Sun, Xuan Zhang, Qiuwei Wu* | **Category: cs.LG, cs.CE** | **Updated: 2025-08-05**

**Keywords:** 太阳辐照度预报, 人工智能, 数值天气预报, 太阳能, 速度与准确性

**Comment:** 

> **TL;DR:** SolarSeer是一个人工智能模型，可以超快速（3秒内）和准确地预测美国未来24小时的太阳辐照度，其准确性优于传统的天气预报模型。

**AI_Comments:** 该研究引入了一个名为 SolarSeer 的人工智能模型，用于太阳辐照度预报，并在速度和准确性方面取得了显著的突破。与传统的数值天气预报（NWP）模型相比，SolarSeer 的效率提升尤为突出，运行速度快了 1500 多倍，并且在准确性方面也表现更优。这项工作对于可再生能源领域的实际应用具有重要意义，尤其是在支持向净零排放能源系统的过渡方面。然而，该研究主要集中在美国本土，其在其他地区或不同气候条件下的泛化能力有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 准确的 24 小时太阳辐照度预报对于太阳能光伏系统的安全和经济运行至关重要。

**Method:** SolarSeer是一个端到端的大型人工智能模型，直接将历史卫星观测映射到未来预报，无需数据同化和偏微分方程求解，从而实现高效预测。

**Result:** 与最先进的数值天气预报（NWP）模型相比，SolarSeer在再分析数据上将太阳辐照度预报的均方根误差显著降低了 27.28%，在 1800 个站点上降低了 15.35%。

**Conclusion:** SolarSeer 提供了超快、准确的 24 小时太阳辐照度预报，为向可持续、净零排放的能源系统转型提供了有力支持。

> **ai_Abstract:** SolarSeer 是一个创新的端到端人工智能模型，用于美国本土的太阳辐照度预报。它通过直接映射历史卫星观测到未来预报，显著提高了效率和准确性，运行速度比传统数值天气预报模型快 1500 多倍，并能将太阳辐照度预报的均方根误差降低高达 27.28%。

> **摘要翻译:** 准确的 24 小时太阳辐照度预报对于太阳能光伏系统的安全和经济运行至关重要。传统的数值天气预报（NWP）模型在预报性能方面代表了最先进的水平，但它们依赖于计算成本高昂的数据同化和求解模拟大气物理学的复杂偏微分方程（PDE）。在这里，我们介绍了 SolarSeer，一个用于美国本土（CONUS）太阳辐照度预报的端到端大型人工智能（AI）模型。SolarSeer 旨在直接将历史卫星观测映射到未来预报，消除了数据同化和 PDE 求解的计算开销。这种效率使得 SolarSeer 的运行速度比传统的 NWP 快 1500 多倍，在 3 秒内即可为 CONUS 生成 5 公里分辨率的 24 小时云量和太阳辐照度预报。与美国本土最先进的 NWP（即高分辨率快速刷新（HRRR））相比，SolarSeer 在再分析数据上将太阳辐照度预报的均方根误差显著降低了 27.28%，在 1800 个站点上降低了 15.35%。SolarSeer 还有效地捕捉了太阳辐照度的波动，并显著提高了一阶辐照度差的预报准确性。SolarSeer 超快、准确的 24 小时太阳辐照度预报为向可持续、净零排放的能源系统转型提供了有力支持。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [880] [An Auditable Agent Platform For Automated Molecular Optimisation](https://arxiv.org/abs/2508.03444)
> *面向自动化分子优化的可审计代理平台*

*Atabey Ünlü, Phil Rohr, Ahmet Celebi* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 分子优化, 代理框架, 药物发现, 可审计性, 大型语言模型

**Comment:** 

> **TL;DR:** 该研究构建了一个多代理框架，用于自动化分子优化，以加速药物发现。该框架通过引入可审计的推理路径和上下文学习来整合不同的专业知识和工具。实验表明，多代理设置在提高结合亲和力方面优于单代理或无代理设置，但单代理设置在药物相似性方面表现更好。该研究强调了可审计性、反馈循环和工具集在将通用语言模型转化为分子设计系统中的重要性。

**AI_Comments:** 这项研究提出了一种创新的多代理框架，用于自动化分子优化，解决了药物发现中的关键瓶颈。该框架的可审计性设计，通过记录和检查推理路径，增加了透明度和可信度，这在科学研究中至关重要。虽然多代理设置在提高结合亲和力方面显示出显著优势，但单代理在药物相似性方面的表现也值得关注，这可能为未来的研究提供了结合两种优势的途径。该研究的局限性可能在于其仅限于AKT1蛋白的测试，以及对ADMET和选择性预测器的扩展仍需验证。总的来说，这项工作为利用大型语言模型加速药物发现提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 药物发现过程因数据、专业知识和工具的分散而减慢。本研究旨在通过一个自动化分子优化的代理框架来缩短这一过程。

**Method:** 构建了一个分层、基于代理的框架，其中包含一个主要研究员、数据库代理、AI专家、药物化学家、排名代理和科学评论员。这些代理通过包含分子谱系的简洁来源记录进行通信，以构建可审计的、以分子为中心的推理轨迹，并通过上下文学习重用成功的转换。研究人员使用五种大型语言模型对AKT1蛋白进行了三个周期的研究循环，并对表现最佳的模型进行了扩展测试，最后比较了不同配置下（仅LLM、单代理、多代理）的结合亲和力结果。

**Result:** 与单代理和仅LLM设置相比，多代理设置将平均预测结合亲和力提高了31%，在专注的结合优化方面表现出色。然而，单代理设置产生的分子具有更优的药物相似性，但结合分数较低。仅LLM的运行速度最快，但由于缺乏透明的工具信号，其推理路径的有效性未经验证。

**Conclusion:** 研究结果表明，测试时扩展、专注的反馈循环和来源记录可以将通用目的的大型语言模型转化为可审计的分子设计系统。研究还建议将工具集扩展到ADMET和选择性预测器，以进一步推进药物发现流程。

> **ai_Abstract:** 本研究介绍了一种名为“可审计代理平台”的创新框架，旨在通过自动化分子优化来加速药物发现过程。该平台利用分层代理架构，整合了从数据检索、新分子生成到编辑和评分等多个专业领域的功能。通过记录和追踪每个工具调用的来源，该平台确保了推理过程的可审计性，并能够通过上下文学习重用成功的分子转换策略。实验结果显示，多代理配置在提高分子结合亲和力方面效果显著（平均提高31%），尽管单代理配置在保持分子药物相似性方面表现更优。研究强调了可审计性、反馈循环和工具集成在将通用大型语言模型转化为可靠的分子设计工具方面的重要性，并为未来扩展到ADMET和选择性预测等领域提供了方向。

> **摘要翻译:** 药物发现过程经常因数据、专业知识和工具的分散而失去动力，从而减慢了设计周期。为了缩短这一循环，我们构建了一个分层的、使用代理框架的工具，以自动化分子优化。主要研究员定义每个目标，数据库代理检索目标信息，AI专家使用序列到分子的深度学习模型生成新的支架，药物化学家在调用对接工具的同时编辑它们，排名代理对候选分子进行评分，科学评论员对逻辑进行审查。每个工具的调用都会被总结并存储，使得完整的推理路径保持可检查状态。代理通过捕捉分子谱系的简洁来源记录进行通信，以构建可审计的、以分子为中心的推理轨迹，并通过上下文学习重用成功的转换。我们使用五种大型语言模型针对AKT1蛋白进行了三个周期的研究循环。在按平均对接分数对模型进行排名后，我们对表现最佳的两个模型进行了20次独立的扩展测试。然后，我们比较了三种配置（仅LLM、单代理和多代理）下领先的LLM的结合亲和力结果。我们的结果揭示了一个架构权衡：多代理设置在专注的结合优化方面表现出色，平均预测结合亲和力提高了31%。相比之下，单代理运行产生的分子具有优越的药物相似性，但结合分数较低。未引导的LLM运行速度最快，但由于缺乏透明的工具信号，其推理路径的有效性未经验证。这些结果表明，测试时扩展、专注的反馈循环和来源记录可以将通用目的的LLM转化为可审计的分子设计系统，并表明将工具集扩展到ADMET和选择性预测器可以将研究工作流程推向发现流程的更远端。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [887] [SLA-MORL: SLA-Aware Multi-Objective Reinforcement Learning for HPC Resource Optimization](https://arxiv.org/abs/2508.03509)
> *SLA-意识的高性能计算资源优化多目标强化学习*

*Seraj Al Mahmud Mostafa, Aravind Mohan, Jianwu Wang* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 多目标强化学习, HPC资源优化, SLA合规性, 动态资源分配, 机器学习工作负载

**Comment:** 

> **TL;DR:** SLA-MORL是一个多目标强化学习框架，用于优化高性能计算中的GPU和CPU资源分配，以平衡训练时间、成本和SLA合规性。它通过智能初始化和动态权重调整来解决冷启动和动态适应问题，并在各种机器学习工作负载中实现了显著的性能、成本和SLA改进。

**AI_Comments:** 该研究提出了一个在HPC资源优化中具有实际应用价值的框架，特别是在满足SLA约束的同时平衡多重目标方面。该方法通过解决冷启动和动态适应性问题，展现了其优越性。然而，21维的状态表示和actor-critic网络的具体实现细节可能影响其在不同规模和复杂度的HPC环境中的可扩展性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 云环境中机器学习工作负载的动态资源分配面临着最小化训练时间、运营成本和满足服务水平协议（SLA）约束等相互竞争的目标。传统方法采用静态资源分配或单目标优化，导致SLA违规或资源浪费。

**Method:** SLA-MORL是一个自适应多目标强化学习框架，通过用户定义的偏好（时间、成本或平衡）来智能分配GPU和CPU资源，同时确保SLA合规性。该框架引入了智能初始化（通过历史学习或有效的基线运行）来解决冷启动问题，并将动态权重调整用于基于实时SLA违规严重性的自动优化优先级调整。它使用21维状态表示和actor-critic网络进行资源分配决策。

**Result:** 与静态基线相比，SLA-MORL在截止日期关键任务方面将训练时间减少了67.2%，在预算受限工作负载方面将成本减少了68.8%，并将整体SLA合规性提高了73.4%。

**Conclusion:** SLA-MORL通过解决冷启动效率低下和动态适应挑战，为云资源管理提供了一个实用的解决方案，在现代机器学习训练环境中平衡了性能、成本和可靠性。

> **ai_Abstract:** SLA-MORL是一种创新的多目标强化学习框架，旨在优化高性能计算（HPC）中的资源分配，以满足机器学习工作负载的性能、成本和SLA要求。通过智能初始化和动态权重调整，该框架有效解决了冷启动问题和动态资源需求，与传统方法相比，在减少训练时间、降低成本和提高SLA合规性方面取得了显著成果。

> **摘要翻译:** 在云环境中，机器学习工作负载的动态资源分配因最小化训练时间、运营成本并满足服务水平协议（SLA）约束等相互竞争的目标而仍然充满挑战。传统方法采用静态资源分配或单目标优化，导致SLA违规或资源浪费。我们提出了SLA-MORL，一个自适应的多目标强化学习框架，该框架能够根据用户定义的偏好（时间、成本或平衡）智能地分配GPU和CPU资源，同时确保SLA合规性。我们的方法引入了两个关键创新：（1）通过历史学习或有效的基线运行进行智能初始化，消除了冷启动问题，将初始探索开销减少了60%。（2）动态权重调整，根据实时SLA违规严重性自动调整优化优先级，创建了一个自我纠正系统。SLA-MORL构建了一个21维的状态表示，捕获资源利用率、训练进度和SLA合规性，使actor-critic网络能够在9种可能的动作中做出明智的分配决策。在生产HPC基础设施上使用13种不同的ML工作负载进行的广泛评估表明，与静态基线相比，SLA-MORL在截止日期关键任务方面将训练时间减少了67.2%，在预算受限工作负载方面将成本降低了68.8%，并将整体SLA合规性提高了73.4%。通过解决冷启动效率低下和动态适应挑战，SLA-MORL为云资源管理提供了一个实用的解决方案，在现代ML训练环境中平衡了性能、成本和可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [888] [CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements](https://arxiv.org/abs/2502.04592)
> *因果增强多模态事件驱动的金融预测：整合时间序列模式和显著宏观经济公告*

*Yang Zhang, Wenbo Yang, Jun Wang, Qiang Ma, Jie Xiong* | **Category: cs.LG, cs.AI, cs.CE, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 因果学习,多模态金融预测,宏观经济事件,时间序列分析,LLM事件增强

**Comment:** Accepted in SIGKDD 2025

> **TL;DR:** 该研究提出了CAMEF框架，通过整合文本、时间序列数据和因果学习机制，并利用LLM进行事件增强，以更准确地预测宏观经济事件对金融市场的影响。

**AI_Comments:** 该研究提出了一种新颖的多模态框架CAMEF，用于预测宏观经济事件对金融市场的影响。其主要创新点在于结合了文本分析、时间序列建模以及因果学习机制，并通过LLM技术进行事件增强，从而解决了现有方法未能充分捕捉数据多模态性和事件因果关系的问题。研究中构建的新金融数据集和验证方法也具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有金融预测方法未能捕捉金融市场的多模态性质以及宏观经济事件与价格变动之间的因果关系。

**Method:** 提出了一种名为CAMEF的多模态框架，该框架结合了文本和时间序列数据，并利用因果学习机制和基于LLM的对策性事件增强技术来进行金融预测。

**Result:** CAMEF框架在与最先进的基于Transformer的时间序列和多模态基线模型进行比较时，以及通过消融研究验证了因果学习机制和事件类型的有效性，均表现出优越的性能。

**Conclusion:** CAMEF框架通过整合多模态数据和因果学习机制，能够有效捕捉宏观经济事件对金融市场的影响，并在金融预测任务中取得了优于现有方法的性能。

> **ai_Abstract:** CAMEF是一个创新的多模态金融预测框架，它通过整合文本、时间序列数据和因果学习机制，并利用LLM进行事件增强，以更准确地预测宏观经济事件对金融市场的影响。该框架能够捕捉事件与市场行为之间的因果关系，并已在包含高频交易数据的新金融数据集上得到验证。

> **摘要翻译:** 准确预测宏观经济事件的影响对于投资者和政策制定者至关重要。货币政策决定和就业报告等显著事件通过塑造对经济增长和风险的预期，常常引发市场波动，从而在事件与市场行为之间建立因果关系。现有的预测方法通常只关注文本分析或时间序列建模，但未能捕捉金融市场的多模态性质以及事件与价格变动之间的因果关系。为了解决这些差距，我们提出了CAMEF（因果增强多模态事件驱动的金融预测），一个多模态框架，它有效地将文本和时间序列数据与因果学习机制以及基于LLM的对策性事件增强技术相结合，以进行因果增强的金融预测。我们的贡献包括：(1) 一个捕捉政策文本与历史价格数据之间因果关系的多模态框架；(2) 一个包含2008年至2024年4月六种宏观经济发布以及五种关键美国金融资产的高频真实交易数据的新金融数据集；(3) 一种基于LLM的对策性事件增强策略。我们将CAMEF与最先进的基于Transformer的时间序列和多模态基线进行比较，并进行消融研究以验证因果学习机制和事件类型的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [893] [Streaming Generated Gaussian Process Experts for Online Learning and Control](https://arxiv.org/abs/2508.03679)
> *用于在线学习和控制的流式生成高斯过程专家*

*Zewen Yang, Dongfa Zhang, Xiaobing Dai, Fengyi Yu, Chi Zhang, Bingkun Huang, Hamid Sadeghian, Sami Haddadin* | **Category: cs.LG, cs.SY, eess.SY, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 高斯过程,在线学习,流式数据,计算效率,专家系统

**Comment:** 

> **TL;DR:** 提出了一种名为SkyGP的框架，用于解决高斯过程（GPs）在处理流式数据时面临的计算和内存限制问题，通过维护一组有限的专家来实现，同时保留了精确GPs的学习性能保证。SkyGP有两种变体：SkyGP-Dense（最大化预测精度）和SkyGP-Fast（提高计算效率）。实验证明SkyGP优于现有方法。

**AI_Comments:** 该研究有效地解决了高斯过程在流式数据处理中的可扩展性挑战，提出了一种新颖的框架SkyGP，并通过实验证明了其在性能和效率上的优势。将GPs的理论优势与实际应用中的计算效率相结合是一个重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 高斯过程（GPs）虽然在函数逼近方面具有灵活性和不确定性量化能力，并且支持在线学习，但其精确推断和在线更新在处理流式数据时存在三次计算时间和二次存储内存的复杂性，限制了其在实时大型数据集上的可扩展性。

**Method:** 提出了一种名为SkyGP（流式核诱导渐进生成高斯过程专家框架）的框架，通过维护一个有界的专家集合来解决计算和内存限制，同时继承精确高斯过程的学习性能保证。此外，还引入了两种SkyGP变体：SkyGP-Dense（最大化预测精度）和SkyGP-Fast（提高计算效率）。

**Result:** SkyGP通过广泛的基准测试和实时控制实验得到了验证，证明了其在性能上优于最先进的方法。

**Conclusion:** SkyGP框架通过维护一组有限的专家，成功解决了精确高斯过程在处理流式数据时的计算和内存瓶颈问题，同时保持了学习性能，并在预测精度和计算效率方面实现了权衡。

> **ai_Abstract:** 本文提出了一种名为SkyGP的新框架，旨在克服高斯过程（GPs）在处理流式数据时的计算和内存效率问题。SkyGP通过管理一组固定的专家来维持GPs的性能保证，同时降低了计算和存储成本。该框架包含两种变体，分别侧重于预测精度（SkyGP-Dense）和计算速度（SkyGP-Fast）。实验结果表明，SkyGP在性能上超越了现有技术。

> **摘要翻译:** 高斯过程（GPs）作为一种非参数学习方法，为函数逼近提供了灵活的建模能力和校准的不确定性量化。此外，GPs通过高效地整合新数据（计算复杂度为多项式时间）支持在线学习，使其非常适合需要快速适应的安全关键动力学系统。然而，当处理流式数据时，精确GPs的推断和在线更新会产生三次计算时间和二次存储内存的复杂性，这限制了它们在实时环境中处理大型数据集的可扩展性。在本文中，我们提出了一种名为SkyGP（流式核诱导渐进生成高斯过程专家框架）的框架，通过维护一组有限的专家来解决计算和内存限制，同时继承了精确高斯过程的学习性能保证。此外，我们还引入了两种SkyGP变体，每种都针对特定目标进行了定制，要么最大化预测精度（SkyGP-Dense），要么提高计算效率（SkyGP-Fast）。SkyGP的有效性已通过广泛的基准测试和实时控制实验得到验证，证明了其与最先进方法相比具有卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [894] [VRPRM: Process Reward Modeling via Visual Reasoning](https://arxiv.org/abs/2508.03556)
> *VRPRM：通过视觉推理进行过程奖励建模*

*Xinquan Chen, Bangwei Liu, Xuhong Wang* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 过程奖励模型, 视觉推理, 思维链, 大型语言模型, 训练策略

**Comment:** 13 pages, 5 figures

> **TL;DR:** 提出了一种名为VRPRM的视觉推理过程奖励模型，通过高效的两阶段训练策略，在较低的数据标注成本下实现了高质量的推理能力，优于现有的大型模型。

**AI_Comments:** 该研究提出了一种创新的方法来解决过程奖励模型的局限性，通过引入视觉推理和高效的训练策略，显著降低了数据标注成本，并提高了模型的性能。其在数据效率和性能提升方面的成果具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的过程奖励模型（PRM）缺乏长期推理和深度思考能力，而引入思维链（CoT）的PRM标注成本过高。VRPRM旨在解决这些挑战。

**Method:** 提出了一种名为VRPRM的视觉推理过程奖励模型，并设计了一种高效的两阶段训练策略。

**Result:** VRPRM仅使用3.6K CoT-PRM SFT数据和50K非CoT PRM RL训练数据，在BoN实验中相对于基线模型实现了高达118%的相对性能提升，并且优于使用400K数据的非思考PRM。

**Conclusion:** 所提出的结合训练策略能在更低的标注成本下实现更高质量的推理能力，为PRM训练提供了新的范式，实现了更有效的数据利用。

> **ai_Abstract:** VRPRM是一种通过视觉推理增强过程奖励模型（PRM）的新方法，解决了现有PRM推理能力不足和CoT-PRM标注成本高的问题。通过采用高效的两阶段训练策略，VRPRM在较低的数据量和标注成本下，显著提升了模型的推理能力，优于基线模型和现有PRM。

> **摘要翻译:** 过程奖励模型（PRM）因其能够对生成内容的推理步骤进行细粒度评估，而被广泛应用于大型语言模型（LLM）的训练后阶段。然而，大多数PRM缺乏长期的推理和深度思考能力。另一方面，尽管少数研究尝试将思维链（Chain-of-Thought）能力引入PRM，但CoT-PRM数据的标注成本过高，难以在各种任务中发挥稳定作用。为了应对这些挑战，我们提出了通过视觉推理的过程奖励模型VRPRM，并设计了一种高效的两阶段训练策略。实验结果表明，仅使用3.6K CoT-PRM SFT数据和50K非CoT PRM RL训练数据，VRPRM就能超越总数据量为400K的非思考PRM，并在BoN实验中实现了高达118%的相对性能提升。这一结果证实了所提出的结合训练策略能在更低的标注成本下实现更高质量的推理能力，从而为PRM训练提供了新的范式，实现了更有效的数据利用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [899] [Shaping Sparse Rewards in Reinforcement Learning: A Semi-supervised Approach](https://arxiv.org/abs/2501.19128)
> *塑造稀疏奖励在强化学习中的应用：一种半监督方法*

*Wenyun Li, Wenjie Huang, Chen Sun* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 稀疏奖励, 奖励塑造, 半监督学习, 数据增强

**Comment:** 

> **TL;DR:** 该研究提出了一种半监督学习方法，利用零奖励转换来改进奖励塑造，并在雅达利和机器人操作实验中显示出优于监督方法的性能。

**AI_Comments:** 该研究提出了一种创新的半监督方法来解决强化学习中的稀疏奖励问题，利用零奖励转换是该方法的一大亮点。实验结果令人信服，尤其是在极端稀疏奖励环境下性能的大幅提升。然而，数据增强的具体机制及其对不同类型稀疏奖励环境的泛化能力有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中强化学习的奖励信号通常非常稀疏，这使得学习有效的奖励函数变得困难。

**Method:** 该方法结合了半监督学习（SSL）和一种新的数据增强技术，利用零奖励转换来学习轨迹空间表示，从而改进奖励塑造。

**Result:** 该方法在雅达利和机器人操作任务中，相比于监督方法，在奖励推断方面表现更好，代理得分更高。在更稀疏的环境中，得分最高可达监督基线的两倍。提出的双熵数据增强将最佳得分提高了15.8%。

**Conclusion:** 该半监督方法能够有效利用零奖励转换，显著提高了稀疏奖励环境下的强化学习性能，优于现有监督方法。

> **ai_Abstract:** 本研究提出了一种利用半监督学习（SSL）和新颖数据增强技术来改进稀疏奖励强化学习的方法。该方法通过学习零奖励转换的轨迹空间表示来增强奖励塑造，并在雅达利和机器人操作实验中取得了优于监督方法的成果，特别是在奖励稀疏的环境中，性能提升显著。

> **摘要翻译:** 在许多现实场景中，智能体的奖励信号极其稀疏，使得学习有效的奖励函数以进行奖励塑造变得困难。为了解决这个问题，本文提出的方法不仅利用非零奖励转换进行奖励塑造，还采用了	extit{半监督学习}（SSL）技术，并结合一种新颖的数据增强方法，从大多数转换（即零奖励转换）中学习轨迹空间表示，从而提高了奖励塑造的效率。在雅达利和机器人操作方面的实验结果表明，我们的方法在奖励推断方面优于基于监督的方法，从而提高了智能体得分。值得注意的是，在奖励更稀疏的环境中，我们的方法相比于监督基线，最高得分提高了两倍。提出的双熵数据增强提高了性能，相比于其他增强方法，最佳得分提高了15.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [901] [Zero-Variance Gradients for Variational Autoencoders](https://arxiv.org/abs/2508.03587)
> *变分自编码器的零方差梯度*

*Zilei Shao, Anji Liu, Guy Van den Broeck* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 变分自编码器, 静默梯度, 零方差梯度, 生成模型, ELBO

**Comment:** 

> **TL;DR:** 提出了一种名为“静默梯度”的新方法，通过利用特定的解码器架构来解析计算期望的ELBO，从而得到零方差梯度，用于训练变分自编码器（VAEs）。该方法在早期训练阶段使用精确的零方差梯度，然后过渡到标准的随机估计器，并在多个数据集上证明了其优于现有方法的性能。

**AI_Comments:** 该研究提出了一种创新的“静默梯度”方法，通过解析计算期望ELBO来消除VAE训练中的梯度方差，这在理论和实践上都具有重要意义。它不仅提高了训练的稳定性和效率，而且通过结合解析计算和深度学习架构的优势，为未来的生成模型研究开辟了新方向。然而，该方法在复杂解码器上的泛化能力和计算成本仍需进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 变分自编码器（VAEs）的训练常因其潜在变量的随机采样引入估计方差而受阻，这会减慢收敛速度并降低性能。

**Method:** 提出了一种名为“静默梯度”的新方法，该方法不改进随机估计器，而是利用特定的解码器架构来解析计算期望的ELBO，从而得到零方差梯度。为了在复杂的解码器中推广该方法，引入了一种新颖的训练动态，在早期训练阶段使用精确的零方差梯度，然后逐渐过渡到标准的随机估计器。

**Result:** 该技术在多个数据集上一致地提高了重参数化、Gumbel-Softmax和REINFORCE等基线方法的性能。

**Conclusion:** 这项工作通过结合解析计算的稳定性和深度非线性架构的表现力，为训练生成模型开辟了新的方向。

> **ai_Abstract:** 本文提出了一种名为“静默梯度”的新方法，用于解决变分自编码器（VAEs）训练中的梯度估计方差问题。通过利用特定的解码器架构解析计算期望的ELBO，该方法生成了零方差梯度。该技术在训练初期使用精确梯度，然后过渡到随机估计器，并在实验中显示出对现有基线方法的性能提升，为生成模型训练提供了新的途径。

> **摘要翻译:** 训练深度生成模型（如变分自编码器，VAEs）常常受到需要对潜在变量的随机采样进行反向传播梯度的阻碍，这一过程固有地引入了估计方差，可能减慢收敛速度并降低性能。在本文中，我们提出了一个规避此问题的新视角，我们称之为静默梯度。我们不改进随机估计器，而是利用特定的解码器架构来解析计算期望的ELBO，从而得到一个零方差梯度。我们首先为该方法提供了理论基础，并在具有线性解码器的受控环境中证明了其优于现有估计器的性能。为了将我们的方法推广到具有复杂、富有表现力的解码器的实际应用中，我们引入了一种新颖的训练动态，该动态在编码器训练的早期阶段使用精确的、零方差的梯度来指导，然后在退火到标准的随机估计器。我们的实验表明，该技术在多个数据集上一致地提高了重参数化、Gumbel-Softmax和REINFORCE等现有基线方法的性能。这项工作通过结合解析计算的稳定性和深度非线性架构的表现力，为训练生成模型开辟了新的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [913] [On the (In)Significance of Feature Selection in High-Dimensional Datasets](https://arxiv.org/abs/2508.03593)
> *论高维数据集特征选择的（不）重要性*

*Bhavesh Neekhra, Debayan Gupta, Partha Pratim Chakravarti* | **Category: cs.LG, q-bio.GN, stat.ML** | **Updated: 2025-08-05**

**Keywords:** 特征选择,高维数据,基因表达,分类性能,随机特征选择

**Comment:** submitted to Nature Computational Science (double-blind review in
  progress). supplementary material included in pdf; anonymized code at:
  https://anonymous.4open.science/r/Feature_Selection_HD-D853/README.md

> **TL;DR:** 特征选择在高维数据集（特别是基因表达）的分类任务中没有用。

**AI_Comments:** 这项研究的贡献在于其对特征选择在高维数据（尤其是基因表达数据）中的实际价值提出了质疑，并提供了一种通过与随机选择的特征进行比较来验证特征选择方法有效性的新颖方法。研究结果具有重要的实际意义，尤其是在计算基因组学领域，它促使研究人员重新审视和验证他们基于特征选择的发现。然而，该研究可能存在局限性，例如其结论可能不适用于所有类型的高维数据集或所有类型的机器学习模型。未来的研究可以探索在不同数据集和模型上重复这些发现，并进一步探讨特征选择在其他领域（如图像识别或自然语言处理）中的作用。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进模型性能、降低计算成本和识别感兴趣的特征，对高维数据集的特征选择（FS）算法进行了广泛研究。

**Method:** 通过测试使用随机选择的特征与FS算法选择的特征进行比较，以验证后者的性能。

**Result:** 在分类任务中，高维数据集（特别是基因表达）的特征选择没有用。随机选择的小子集（占所有特征的0.02%-1%）训练的模型几乎总是与在所有特征上训练的模型表现相当，或者随机选择的“典型”大小的子集提供的性能与各种已 published 研究中的前k个特征选择的性能相当或更优。

**Conclusion:** 该研究结果对许多关于高维数据集的特征选择结果提出了质疑，尤其是在计算基因组学领域。对于那些未经湿式实验进一步验证就基于计算选择的基因提出药物设计或靶向干预的研究，该研究提出了严重的担忧。

> **ai_Abstract:** 这项研究通过将随机选择的特征与特征选择算法选择的特征进行比较，评估了特征选择在高维数据集（特别是基因表达数据）上的有效性。研究结果表明，特征选择在这种情况下并没有带来性能上的提升，随机选择的特征子集往往能达到与使用全部特征或通过传统特征选择方法选出的特征相当甚至更好的分类性能。这挑战了现有研究的结论，并对基于计算选择的基因进行药物设计或干预提出了警告。

> **摘要翻译:** 对高维数据集的特征选择（FS）算法进行了广泛研究，旨在提高模型性能、降低计算成本并识别感兴趣的特征。我们检验了使用随机选择的特征来与FS算法选择的特征进行比较的零假设，以验证后者的性能。我们的结果表明，在高维数据集（特别是基因表达）的分类任务中，特征选择是无用的。我们发现（1）在随机选择的特征的小子集（占所有特征的0.02%-1%）上训练的模型几乎总是与在所有特征上训练的模型表现相当，并且（2）“典型”大小的随机子集提供的性能与各种已 published 研究中选择的前k个特征相当或更优。因此，我们的工作对高维数据集上的许多特征选择结果提出了质疑，特别是在计算基因组学领域。它对那些未经湿式实验进一步验证就基于计算选择的基因提出药物设计或靶向干预的研究提出了严重的担忧。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [914] [Learning Fluid-Structure Interaction Dynamics with Physics-Informed Neural Networks and Immersed Boundary Methods](https://arxiv.org/abs/2505.18565)
> *物理信息神经网络与浸入边界法流固耦合动力学学习*

*Afrah Farea, Saiful Khan, Reza Daryani, Emre Cenk Ersan, Mustafa Serdar Celebi* | **Category: cs.LG, cs.CE, physics.flu-dyn** | **Updated: 2025-08-04**

**Keywords:** 物理信息神经网络, 浸入边界法, 流固耦合, 欧拉-拉格朗日网络, 自适应B样条激活

**Comment:** 

> **TL;DR:** 该研究提出了结合物理信息神经网络（PINNs）和浸入边界法（IBM）的两种新神经网络架构，用于解决流固耦合（FSI）问题。结果表明，欧拉-拉格朗日架构和自适应B样条激活函数在2D空腔流动问题中表现更优，但压力恢复仍具挑战性。

**AI_Comments:** 该研究在将PINNs与IBM结合以解决FSI问题方面取得了重要进展，提出了两种新颖的架构，并对不同激活函数的性能进行了评估。研究结果强调了架构设计和激活函数选择对提高模型性能的重要性。然而，论文也指出了在压力恢复方面存在的挑战，这为未来的研究提供了方向。总体而言，这项工作为利用深度学习方法解决复杂的物理问题提供了一个有前景的途径。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决流固耦合（FSI）问题，探索将物理信息神经网络（PINNs）与浸入边界法（IBM）相结合的新方法。

**Method:** 提出两种神经网络架构：单一FSI网络（统一参数空间）和欧拉-拉格朗日网络（分离参数空间）。研究了Tanh和自适应B样条激活函数。

**Result:** 在2D空腔流动问题中，欧拉-拉格朗日架构表现优于单一FSI网络。自适应B样条激活函数提高了近边界处的精度。速度场预测效果好，但压力恢复因缺乏显式力耦合约束而面临挑战。

**Conclusion:** 域名特定的架构设计和自适应激活函数对于在PINN框架内模拟FSI问题至关重要。

> **ai_Abstract:** 本研究提出了一种结合物理信息神经网络（PINNs）和浸入边界法（IBM）的新方法来解决流固耦合（FSI）问题。研究了两种神经网络架构：单一FSI网络和欧拉-拉格朗日网络，并评估了Tanh和自适应B样条激活函数。在二维空腔流动问题中，欧拉-拉格朗日网络结合自适应B样条激活函数表现出最佳性能，提高了精度，尤其是在边界附近。然而，由于缺乏显式的力耦合约束，压力恢复仍然是一个挑战。该研究强调了针对特定领域设计网络架构和使用自适应激活函数在PINN框架下进行FSI建模的重要性。

> **摘要翻译:** 我们介绍了结合物理信息神经网络（PINNs）和浸入边界法（IBM）的神经网络架构，用于解决流固耦合（FSI）问题。我们的方法具有两种不同的架构：具有统一参数空间的单一FSI网络，以及保持流体和结构域分离参数空间的创新欧拉-拉格朗日网络。我们使用标准的Tanh和自适应B样条激活函数研究了每种架构。涉及移动固体结构的二维空腔流问题的经验研究表明，欧拉-拉格朗日架构表现明显更好。通过提供近边界处的局部感知表示，自适应B样条激活进一步提高了精度。虽然我们的方法在预测速度场方面显示出有希望的结果，但由于当前公式中缺少显式的力耦合约束，压力恢复仍然具有挑战性。我们的发现强调了域名特定的架构设计和自适应激活函数在PINN框架内模拟FSI问题的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [921] [From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation](https://arxiv.org/abs/2507.20968)
> *从纠缠到对齐：表示空间分解用于无监督时间序列域适应*

*Rongyao Cai, Ming Jin, Qingsong Wen, Kexin Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 无监督域适应, 时间序列分析, 表示空间分解, 域不变性, 对比学习

**Comment:** 15 pages, 7 figures

> **TL;DR:** DARSD是一种新的无监督域适应（UDA）框架，通过表示空间分解来实现UDA任务。它通过解开可转移知识和混合表示来适应不同域，包含三个部分：通用不变基、原型伪标签机制和混合对比优化策略。实验证明DARSD优于其他12种UDA算法。

**AI_Comments:** 该研究提出了一种新颖的无监督域适应框架DARSD，通过表示空间分解来解决时间序列分析中的域移位问题。该方法的核心思想是将特征进行解耦，区分可转移知识和域特定知识，这与以往将特征视为整体的方法有所不同，具有一定的创新性。框架的三个组成部分协同工作，理论上具有可解释性。实验结果也显示了DARSD的优越性。然而，对于“通用不变基”和“原型伪标签机制”的具体实现细节及其理论保证，在摘要中描述不够详细，可能需要进一步阅读全文来了解。此外，该方法在35/53场景最优，虽然表现优异，但并非所有场景都最优，这可能暗示其在某些特定类型的域移位或数据集上仍有改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 现有无监督域适应（UDA）方法在对齐跨域特征分布时，将特征视为不可分割的整体，忽略了其内在构成，而这些构成对域适应至关重要。

**Method:** DARSD框架通过表示空间分解实现UDA任务，包含三个部分：1. 敌对可学习的通用不变基，将原始特征投影到域不变子空间并保留语义内容；2. 原型伪标签机制，基于置信度动态分离目标特征以防止误差累积；3. 混合对比优化策略，同时强制执行特征聚类和一致性，并缓解分布差距。

**Result:** DARSD在四个基准测试（WISDM、HAR、HHAR和MFD）上的综合实验表明，其性能优于12种UDA算法，在53个场景中有35个达到最优，并在所有基准测试中排名第一。

**Conclusion:** DARSD通过表示空间分解，特别是解开可转移知识和混合表示，实现了有效的无监督域适应，并在多个基准测试中取得了优越的性能。

> **ai_Abstract:** DARSD是一种新颖的无监督域适应（UDA）框架，它通过表示空间分解来解决时间序列分析中的域移位问题。与现有方法不同，DARSD显式地将表示空间分解，以解开可转移知识和混合表示。该框架包含三个关键组件：一个通用不变基，一个原型伪标签机制和一个混合对比优化策略。实验结果表明，DARSD在多个基准测试中均优于现有算法。

> **摘要翻译:** 域移位是时间序列分析中的一个基本挑战，在源域上训练的模型在应用于具有不同但相似分布的目标域时，往往会严重失败。虽然当前无监督域适应（UDA）方法试图对齐跨域特征分布，但它们通常将特征视为不可分割的实体，忽略了它们控制域适应的内在构成。我们引入了DARSD，一个具有理论可解释性的新颖UDA框架，它从表示空间分解的角度显式地实现了UDA任务。我们的核心见解是，有效的域适应不仅需要对齐，还需要对可转移知识与混合表示进行原则性的解开。DARSD包含三个协同的组成部分：（I）一个敌对可学习的通用不变基，将原始特征投影到域不变子空间，同时保留语义内容；（II）一个原型伪标签机制，根据置信度动态地分离目标特征，从而阻碍误差累积；（III）一个混合对比优化策略，同时强制执行特征聚类和一致性，同时缓解新兴的分布差距。在四个基准测试（WISDM、HAR、HHAR和MFD）上进行的综合实验表明，DARSD相对于12种UDA算法具有优越性，在53个场景中有35个场景取得了最优性能，并在所有基准测试中排名第一。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [922] [Pair Correlation Factor and the Sample Complexity of Gaussian Mixtures](https://arxiv.org/abs/2508.03633)
> *高斯混合模型的配对相关因子与样本复杂度*

*Farzad Aryan* | **Category: cs.LG, stat.ML, 62H30, 68T05, 62F12, 68Q32, I.2.6; G.3** | **Updated: 2025-08-05**

**Keywords:** 高斯混合模型, 样本复杂度, 配对相关因子, 参数恢复, 最小距离

**Comment:** 21 pages, no figures

> **TL;DR:** 高斯混合模型学习的样本复杂度不仅取决于成分间的最小距离，还与捕捉成分均值聚集性的配对相关因子（PCF）有关。PCF更能准确地指示参数恢复的难度，并且在特定条件下，样本复杂度会超过通常的ε⁻²。

**AI_Comments:** 该研究提出了“配对相关因子”（PCF）这一新颖的几何量，为理解高斯混合模型学习的样本复杂度提供了新的视角，并且在理论上改进了特定情况下的样本复杂度界限，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 探究哪些结构属性决定了高斯混合模型（GMM）的学习样本复杂度，并指出仅关注最小成分间距的观点是不完整的。

**Method:** 引入了“配对相关因子”（PCF）这一几何量来捕捉成分均值的聚集性，并将其与最小成分间距进行对比。

**Result:** 在统一球形的情况下，提出了一种样本复杂度更优的算法，并展示了何时需要超过通常的ε⁻²样本量。

**Conclusion:** 配对相关因子（PCF）比最小成分间距更能准确地反映高斯混合模型参数恢复的难度，并且在某些情况下，样本复杂度会比预期的要高。

> **ai_Abstract:** 本文研究高斯混合模型（GMM）的学习问题，指出仅关注成分间最小距离来衡量样本复杂度是不够的。研究引入了“配对相关因子”（PCF）来量化成分均值的聚集性，并证明PCF比最小距离更能准确地反映参数恢复的难度。在特定条件下，研究提出了一种改进样本复杂度界限的算法，并表明样本需求可能超过通常的ε⁻²。

> **摘要翻译:** 我们研究学习高斯混合模型（GMM）的问题，并提出：哪些结构属性决定了它们的样本复杂度？先前的研究在很大程度上将这种复杂度与成分间的最小成对分离联系起来，但我们证明这种观点是不完整的。
我们引入了“配对相关因子”（PCF），一个捕捉成分均值聚集性的几何量。与最小间隙不同，PCF更准确地决定了参数恢复的难度。
在统一球形的情况下，我们给出了一个样本复杂度边界得到改善的算法，展示了何时需要比通常的ε⁻²更多的样本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [927] [Entropy-Lens: The Information Signature of Transformer Computations](https://arxiv.org/abs/2502.16570)
> *熵透镜：Transformer计算的信息特征*

*Riccardo Ali, Francesco Caso, Christopher Irwin, Pietro Liò* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 熵剖面,Transformer,信息论,可解释性,模型签名

**Comment:** 

> **TL;DR:** 该研究提出了一种名为Entropy-Lens的框架，通过分析Transformer模型每一层输出的词汇分布的香农熵，形成一个“熵剖面”来揭示模型的计算模式、预测能力和任务相关性，且该方法不依赖梯度或模型内部结构。

**AI_Comments:** 该研究提出的Entropy-Lens框架提供了一种新颖且实用的方法来理解Transformer模型的内部工作机制，特别是在缺乏梯度信息或无法进行微调的情况下。通过关注信息论的熵度量，该方法有效地将高维度的分布信息转化为易于理解的标量序列，从而揭示了模型计算的深层模式。其模型无关的特性增加了其广泛适用性。然而，未来可以进一步探索不同类型的熵度量（如Renyi熵的不同参数）对模型行为的影响，以及该方法在更复杂的模型架构（如混合专家模型）上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Transformer可解释性研究主要关注内部的潜在表示，而忽略了词汇空间中token级分布的演变。然而，这些分布具有高维度且支持无序的特点，使得常用的描述符（如矩或累积量）不适用。

**Method:** 提出了一种名为Entropy-Lens的框架，该框架可以从冻结的、现成的Transformer模型中提取熵剖面。熵剖面是通过计算模型每一层预测分布的香农熵得到的，形成一个信息论上的特征。

**Result:** 熵剖面能够揭示与深度重缩放无关的模型计算模式，预测提示类型和任务格式，并与输出的正确性相关。此外，Rényi熵在广泛的α值范围内也能产生相似的结果，表明香农熵是稳定且有原则的总结。这些结果在不同的Transformer模型上均成立，且无需梯度、微调或访问模型内部。

**Conclusion:** 熵剖面作为一种信息论上的签名，为理解Transformer模型的计算过程提供了一种模型无关、无需梯度和微调的有效方法，并且能够揭示与模型性能和任务相关的关键信息。

> **ai_Abstract:** 本研究提出了一种名为Entropy-Lens的新型框架，用于分析Transformer模型中逐层输出的词汇分布。通过计算这些分布的香农熵，形成一个“熵剖面”作为模型的“信息签名”。实验表明，熵剖面能够揭示模型特有的计算模式，预测任务和提示的类型，并与输出的准确性相关。该方法具有模型无关、无需梯度或微调的优点，适用于分析各种Transformer模型。

> **摘要翻译:** Transformer模型逐层地将输入token序列映射到输出token分布。虽然大多数可解释性工作都关注内部的潜在表示，但我们直接研究词汇空间中这些token级分布的演变。然而，这类分布具有高维度且定义在无序支持上，使得矩或累积量等常用描述符不适用。我们通过计算每层中间预测分布的香农熵来解决这个问题，从而得到每层一个可解释的标量。由此产生的序列，即熵剖面，构成了模型计算的一个紧凑的、信息论的特征。我们引入了Entropy-Lens，一个模型无关的框架，可以从冻结的、现成的Transformer中提取熵剖面。我们表明，这些剖面（i）揭示了与深度重缩放无关的家族特定计算模式，（ii）可以预测提示类型和任务格式，并且（iii）与输出的正确性相关。我们进一步表明，Rényi熵在广泛的α值范围内也能产生相似的结果，这证明了使用香农熵作为稳定和有原则的总结是合理的。我们的结果在不同的Transformer上均成立，且无需梯度、微调或访问模型内部。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [929] [Cross-patient Seizure Onset Zone Classification by Patient-Dependent Weight](https://arxiv.org/abs/2508.03635)
> *患者依赖权重在跨患者癫痫发作起始区分类中的应用*

*Xuyang Zhao, Hidenori Sugano, Toshihisa Tanaka* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 癫痫发作起始区, 机器学习, 跨患者问题, 患者特定权重, 微调

**Comment:** 

> **TL;DR:** 提出一种通过患者特定权重微调预训练模型来解决跨患者问题，以提高癫痫发作起始区分类性能的方法，平均准确率提升超过10%。

**AI_Comments:** 该研究提出的患者特定权重微调方法有效地解决了医学数据中普遍存在的跨患者问题，为提高机器学习模型在个体化医疗诊断中的性能提供了有价值的思路。实验结果显著，但未来可以进一步探索更鲁棒的相似性度量方法以及在更多样化的数据集上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 医学数据通常是针对个体患者收集的，由于患者个体差异（疾病、身体状况、病史等），导致数据分布不同，这给机器学习模型在新患者数据集上实现可靠性能带来了“跨患者问题”。

**Method:** 首先，使用监督学习训练一个预训练模型。然后，利用测试患者数据获取该模型的中间特征，定义测试患者数据与每个训练患者数据之间的相似性，从而确定用于后续微调的每个训练患者的权重。最后，使用训练数据和患者权重对预训练模型中的所有参数进行微调。

**Result:** 通过留一患者交叉验证评估，所提出的方法提高了所有测试患者的分类准确率，平均提升超过10%。

**Conclusion:** 所提出的基于患者特定权重的微调方法能够有效解决跨患者问题，显著提高癫痫发作起始区的分类准确率。

> **ai_Abstract:** 本研究提出了一种解决医学数据“跨患者问题”的方法，该问题源于患者个体数据的分布差异。研究人员开发了一种通过患者特定权重微调预训练模型的技术，以提高癫痫发作起始区（SOZ）的分类准确性。实验结果显示，该方法平均可将分类准确率提高10%以上。

> **摘要翻译:** 识别局灶性癫痫患者的癫痫发作起始区（SOZ）对于手术治疗至关重要，但由于其依赖于临床专家对视觉的判断，因此仍然具有挑战性。机器学习的发展可以辅助诊断，并取得了令人瞩目的进展。然而，与其它领域的数据不同，医学数据通常是针对个体患者收集的，并且每个患者都有不同的疾病、身体状况和病史，这导致每个患者的数据分布存在差异。这使得机器学习模型难以在新患者数据集上实现始终可靠的性能，我们称之为“跨患者问题”。在本研究中，我们提出一种方法，通过对每个新的测试患者使用患者特定的权重进行微调预训练模型，以提高诊断性能。首先，使用监督学习方法训练一个机器学习模型。然后，利用通过测试患者数据获得的训练模型的中间特征，定义测试患者数据与每个训练患者数据之间的相似性，以确定用于后续微调的每个训练患者的权重。最后，我们使用训练数据和患者权重对预训练模型中的所有参数进行微调。在实验中，我们采用留一患者交叉验证的方法来评估所提出的方法，结果表明，对于每个测试患者，分类准确率都有所提高，平均提升超过10%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [931] [Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning](https://arxiv.org/abs/2507.06402)
> *使用混合机器学习检测无线心电图信号中的智能篡改*

*Siddhant Deshpande, Yalemzerf Getnet, Waltenegus Dargie* | **Category: cs.LG, cs.CR, eess.SP** | **Updated: 2025-08-04**

**Keywords:** 无线 ECG, 篡改检测, 机器学习, Transformer, Siamese 网络

**Comment:** 

> **TL;DR:** 该研究提出了使用混合机器学习模型（CNN、ResNet、Transformer-CNN 和 Siamese 网络）来检测无线心电图（ECG）信号中的智能篡改和进行身份验证。实验表明，这些模型在模拟的结构化和随机篡改场景下表现出色，准确率高达 99.5%。特别是混合 CNN-Transformer Siamese 模型在身份验证方面达到了 100% 的准确率。

**AI_Comments:** 该研究在检测无线 ECG 信号篡改和身份验证方面取得了显著进展，提出的混合机器学习方法表现出很高的准确性和鲁棒性。然而，在真实世界的部署中，需要考虑计算复杂性、实时处理能力以及不同环境和攻击下的泛化能力。未来的研究可以探索更轻量级的模型或自适应学习机制，以应对不断变化的攻击模式。

<details>
  <summary>Details</summary>

**Motivation:** 随着无线心电图（ECG）系统在健康监测和身份验证中的广泛应用，保护信号完整性免受篡改变得至关重要。

**Method:** 研究采用了卷积神经网络（CNN）、残差网络（ResNet）以及混合 Transformer-CNN 模型来检测篡改，并评估了 Siamese 网络在基于 ECG 的身份验证方面的性能。为了模拟真实世界的攻击，研究人员模拟了六种篡改策略，包括结构化片段替换和随机插入。一维 ECG 信号通过连续小波变换（CWT）转换为二维时频域表示。实验使用了来自 54 名受试者在不同活动期间记录的 ECG 数据。

**Result:** 在高度碎片化的操纵场景中，CNN、FeatCNN-TranCNN、FeatCNN-Tran 和 ResNet 模型达到了超过 99.5% 的准确率。对于细微的操纵（例如，50% A 和 50% B 替换，75% A 和 25% B 替换），FeatCNN-TranCNN 模型表现出持续可靠的性能，平均准确率为 98%。在身份验证方面，纯 Transformer-Siamese 网络达到了 98.30% 的平均准确率，而混合 CNN-Transformer Siamese 模型则实现了 100% 的完美准确率。

**Conclusion:** 混合机器学习模型，特别是结合了 CNN 和 Transformer 的 Siamese 网络，在检测无线 ECG 信号的智能篡改和进行身份验证方面非常有效，即使在复杂的攻击场景下也能保持高准确率。

> **ai_Abstract:** 本研究旨在通过混合机器学习方法检测无线心电图（ECG）信号中的智能篡改，并进行身份验证。研究人员采用了 CNN、ResNet 以及结合 Transformer 和 CNN 的混合模型，并评估了 Siamese 网络在身份验证中的应用。通过模拟多种篡改策略，并使用连续小波变换将 ECG 信号转换为时频域表示，实验结果显示，所提出的模型在检测碎片化和细微篡改方面均取得了高准确率（超过 99.5% 和 98%）。特别是混合 CNN-Transformer Siamese 模型在身份验证任务中达到了 100% 的准确率，证明了其在保护 ECG 信号完整性和安全方面的有效性。

> **摘要翻译:** 随着无线心电图（ECG）系统在健康监测和身份验证中的广泛应用，保护信号完整性免受篡改变得越来越重要。本文分析了 CNN、ResNet 和混合 Transformer-CNN 模型在篡改检测方面的性能。它还评估了 Siamese 网络在基于 ECG 的身份验证方面的性能。模拟了六种篡改策略，包括结构化片段替换和随机插入，以模拟真实世界的攻击。一维 ECG 信号使用连续小波变换（CWT）转换为时频域的二维表示。模型使用来自 54 名受试者在 2019 年至 2025 年期间在临床环境外记录的 ECG 数据进行训练和评估，这些受试者在记录期间进行了七种不同的日常活动。实验结果表明，在高度碎片化的操纵场景中，CNN、FeatCNN-TranCNN、FeatCNN-Tran 和 ResNet 模型达到了超过 99.5% 的准确率。同样，对于细微的操纵（例如，50% 来自 A 和 50% 来自 B 的替换，以及 75% 来自 A 和 25% 来自 B 的替换），我们的 FeatCNN-TranCNN 模型表现出持续可靠的性能，平均准确率为 98%。对于身份验证，纯 Transformer-Siamese 网络达到了 98.30% 的平均准确率。相比之下，混合 CNN-Transformer Siamese 模型实现了完美的 100% 准确率的验证性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [936] [Efficient Morphology-Aware Policy Transfer to New Embodiments](https://arxiv.org/abs/2508.03660)
> *面向新具身的高效形态感知策略迁移*

*Michael Przystupa, Hongyao Tang, Martin Jagersand, Santiago Miret, Mariano Phielipp, Matthew E. Taylor, Glen Berseth* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 形态感知策略, 策略迁移, 参数高效微调, 机器人学习, 零样本学习

**Comment:** 19 pages, 10 Figures, Published at the 2025 Reinforcement Learning
  Conference

> **TL;DR:** 该研究提出结合形态感知预训练和参数高效微调（PEFT）技术，以减少将形态感知策略迁移到新具身所需的参数量和样本量，并取得了优于从头端到端微调的效果。

**AI_Comments:** 这项研究在策略迁移领域取得了重要进展，特别是在处理不同具身形态的挑战方面。通过结合形态感知预训练和参数高效微调（PEFT），该方法有效地解决了传统方法中零样本性能不佳和微调成本高昂的问题。研究中对不同PEFT技术的对比分析也为实际应用提供了有价值的参考。然而，研究可能还需要进一步探索在更复杂或更动态的环境中该方法的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的形态感知策略虽然能泛化不同形态的变异，但在新形态上的零样本性能仍不理想，而端到端微调成本高昂。

**Method:** 研究人员将形态感知预训练与参数高效微调（PEFT）技术相结合，并对比了调整部分模型权重、输入可学习适配器和前缀调优等方法，以减少将形态感知策略特化到目标具身所需的参数。

**Result:** 研究结果表明，PEFT技术与策略预训练相结合，相比从头端到端训练，通常能减少策略改进所需的样本数量。并且，仅调整不到1%的总参数即可在策略性能上优于基础预训练策略的零样本性能。

**Conclusion:** 结合形态感知预训练和参数高效微调（PEFT）技术，能够有效提高策略迁移的样本效率，并减少所需优化的参数量，在机器人等实际应用中具有重要意义。

> **ai_Abstract:** 本研究提出了一种结合形态感知预训练和参数高效微调（PEFT）技术的方法，旨在提高策略迁移的效率。研究人员通过调整少量参数（如调整子集权重、输入适配器或前缀调优）来优化策略，以适应新的具身形态。实验结果表明，该方法相比于传统的端到端微调，能够显著减少所需的样本数量，并且仅需优化不到1%的参数即可获得优于零样本性能的提升，为机器人等领域的策略迁移提供了更高效的解决方案。

> **摘要翻译:** 形态感知策略学习是通过聚合来自多个代理的数据来提高策略样本效率的一种手段。先前已证明这类策略有助于泛化代理形态之间的动态、运动学和肢体配置变化。不幸的是，与在部署时针对形态进行端到端微调相比，这些策略在零样本性能方面仍然不理想。这在机器人等实际应用中会产生影响，因为进行端到端微调所需的数据收集可能成本高昂。在本研究中，我们研究了将形态感知预训练与参数高效微调（PEFT）技术相结合，以帮助减少将形态感知策略特化到目标具身所需的学习参数。我们直接对比了调整模型权重子集、输入可学习适配器和前缀调优技术进行在线微调。我们的分析表明，与从头端到端训练相比，PEFT技术与策略预训练相结合通常有助于减少改进策略所需的样本数量。我们还发现，仅调整不到100%的总参数即可在策略性能上优于基础预训练策略的零样本性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [943] [No LLM Solved Yu Tsumura's 554th Problem](https://arxiv.org/abs/2508.03685)
> *没有语言模型解决津村友的第554个问题*

*Simon Frieder, William Hart* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型,数学问题解决,国际数学奥林匹克,津村友的第554个问题,证明复杂性

**Comment:** 67 pages

> **TL;DR:** 尽管最近的LLM在解决问题方面取得了成功，但津村友的第554个问题，一个不需要复杂证明技巧的IMO级别问题，无法被现有的LLM解决，即使其解决方案可能存在于训练数据中。

**AI_Comments:** 这项研究有效地挑战了关于LLM解决数学问题能力的普遍乐观情绪。通过选择一个看似适合LLM能力但实际上无法解决的问题，研究人员揭示了当前LLM在理解和生成复杂数学证明方面的固有挑战。该研究的价值在于其明确的反例，强调了在评估AI能力时需要仔细考虑问题类型和数据可用性。未来的研究可以探索LLM在解决更广泛的数学问题上的失败模式，并开发能够克服这些局限性的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 评估LLM在解决具有IMO级别证明复杂性的数学问题方面的能力，特别是那些不属于组合学领域且对LLM来说可能更易于解决的问题，并挑战关于LLM问题解决能力的乐观情绪。

**Method:** 评估现有的商业和开源LLM在解决津村友的第554个问题上的表现，该问题具有IMO级别的证明复杂性，但不需要组合学技巧或广泛的证明技术。

**Result:** 现有的商业和开源LLM无法解决津村友的第554个问题，尽管该问题在复杂性、证明技术需求和潜在训练数据可及性方面被认为对LLM来说是可管理的。

**Conclusion:** 现有LLM在解决具有IMO级别证明复杂性的数学问题方面仍然存在局限性，即使这些问题不属于组合学领域，并且其解决方案可能包含在训练数据中。

> **ai_Abstract:** 本研究评估了大型语言模型（LLM）在解决具有国际数学奥林匹克（IMO）级别证明复杂性的数学问题方面的能力。研究人员发现，即使是像津村友的第554个问题这样，不属于组合学领域、所需证明技术较少且可能存在于训练数据中的问题，也无法被现有的商业或开源LLM轻易解决。这表明，尽管LLM在解决问题方面取得了进展，但它们在处理需要深刻数学推理的任务方面仍存在局限性。

> **摘要翻译:** 我们表明，与最近因获得金牌而引发的关于LLM解决问题能力的乐观情绪相反，存在一个问题——津村友的第554个问题——该问题a)在证明复杂性方面属于IMO问题的范围，b)不是导致LLM出现问题的组合学问题，c)需要的证明技术比典型的困难IMO问题少，d)有公开的解决方案（可能存在于LLM的训练数据中），以及e)任何现有的现成LLM（商业或开源）都无法轻易解决。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [950] [PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement Learning](https://arxiv.org/abs/2508.03693)
> *PAC强化学习中的贝叶斯主动逆强化学习*

*Ondrej Bajgar, Dewi S. W. Gould, Jonathon Liu, Alessandro Abate, Konstantinos Gatsis, Michael A. Osborne* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 主动IRL, 逆强化学习, PAC保证, 信息论, 奖励学习

**Comment:** Published at RLC 2025

> **TL;DR:** 该研究提出了一种名为PAC-EIG的主动逆强化学习方法，旨在通过策略性地选择演示场景来获得具有概率近似正确（PAC）保证的学习策略，解决了在需要高可靠性的领域（如自动驾驶）中获取足够演示数据的成本问题。

**AI_Comments:** 该研究在主动IRL领域取得了重要进展，首次为具有噪声专家演示的主动IRL提供了PAC理论保证，这对于需要高可靠性的AI应用具有重要意义。方法论清晰，理论分析和实验结果都支持其有效性。然而，研究仅限于有限状态-动作空间，未来可以探索其在连续空间中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI系统日益自主化，确保其决策与人类偏好保持一致至关重要。逆强化学习（IRL）是推断偏好的有效方法，但为了获得可靠的策略（尤其是在自动驾驶或机器人等高风险领域），需要大量的演示数据，这可能成本高昂。因此，需要一种方法来有效选择最有价值的演示场景。

**Method:** 提出了一种名为PAC-EIG的信息论获取函数，直接针对学习策略的概率近似正确（PAC）保证。该方法通过最大化学徒策略的遗憾信息增益来识别需要进一步演示的状态。此外，还提出了Reward-EIG作为以学习奖励为主要目标的替代方案。研究重点关注有限状态-动作空间，并提供了收敛界限。

**Result:** PAC-EIG是第一个为具有噪声专家演示的主动IRL提供理论保证的方法。实验证明了该方法在识别需要演示的状态方面的效率，并优于先前启发式方法。

**Conclusion:** PAC-EIG方法能够通过主动选择演示场景，高效地获得具有PAC保证的策略，解决了高风险领域中获取可靠策略的演示数据成本问题，并在有限状态-动作空间内展示了其优越性。

> **ai_Abstract:** 本研究提出了一种名为PAC-EIG的主动逆强化学习方法，旨在通过最大化学徒策略的遗憾信息增益来选择最有价值的演示场景，从而获得具有概率近似正确（PAC）保证的策略。该方法解决了在高风险领域获取可靠策略所需的演示数据的成本问题，并在有限状态-动作空间内通过理论分析和实验证明了其有效性。

> **摘要翻译:** 随着人工智能系统变得越来越自主，确保它们的决策与人类偏好保持一致至关重要。逆强化学习（IRL）提供了一种从演示中推断偏好的有前途的方法。然后，可以将这些偏好用于生成能够在该演示任务上表现良好的学徒策略。然而，在自动驾驶或机器人等领域，错误可能导致严重后果，我们需要的不仅仅是良好的平均性能，而是具有正式保证的可靠策略——然而，要获得足够的、能保证可靠性的演示，成本可能很高。主动IRL通过战略性地选择信息量最大的场景进行演示来应对这一挑战。我们引入了PAC-EIG，一种信息论获取函数，直接以学习策略的概率近似正确（PAC）保证为目标——为具有噪声专家演示的主动IRL提供了第一个此类理论保证。我们的方法最大化学徒策略遗憾的信息增益，有效地识别需要进一步演示的状态。当我们以学习奖励为主要目标时，我们还提出了Reward-EIG作为一种替代方案。我们专注于有限状态-动作空间，证明了收敛界限，阐述了先前启发式方法的失败模式，并通过实验证明了我们方法的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [954] [DeepFaith: A Domain-Free and Model-Agnostic Unified Framework for Highly Faithful Explanations](https://arxiv.org/abs/2508.03586)
> *DeepFaith：一个无领域、无模型、统一的、高度忠实解释框架*

*Yuhan Guo, Lizhong Ding, Shihan Jia, Yanyu Ren, Pengqi Li, Jiarun Fu, Changsheng Li, Ye yuan, Guoren Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 可解释AI, 忠实度, 统一框架, DeepFaith, 模型无关

**Comment:** 22 pages

> **TL;DR:** 提出了一种名为DeepFaith的统一可解释AI框架，它不依赖特定领域或模型，并通过优化多个忠实度指标来生成高度忠实的解释，并在多项任务中表现优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的、统一的XAI框架DeepFaith，解决了现有方法缺乏客观评估标准的问题。其创新之处在于通过统一表述多种忠实度指标来定义最优解释，并设计了一个能够生成高度忠实解释的学习框架。该方法在多个任务和模型上的出色表现证明了其有效性和通用性。然而，对于“模式一致性损失”和“局部相关性”的具体数学定义及其在训练中的作用，需要更详细的阐述。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释AI（XAI）方法缺乏统一的地面真实标准进行客观评估和优化，因为没有统一的最佳解释。

**Method:** 提出DeepFaith框架，通过统一表述多种忠实度指标，推导出一个最优解释目标，该目标的解决方案可在多个指标上同时实现最优忠实度。设计了一个explainer学习框架，利用现有的多种解释方法，通过去重和过滤构建高质量的监督解释信号，并优化模式一致性损失和局部相关性来训练一个忠实的explainer。

**Result:** DeepFaith在12个不同的解释任务（涵盖6个模型和6个数据集）上，在10个指标上的整体忠实度均高于所有基线方法，证明了其有效性和跨领域通用性。

**Conclusion:** DeepFaith通过统一表述多种忠实度指标，并优化模式一致性损失和局部相关性，提供了一个无领域、无模型的统一框架，能够生成高度忠实的解释，并在广泛的任务中表现出色。

> **ai_Abstract:** DeepFaith是一个新提出的、不依赖特定领域或模型的统一可解释AI框架。它通过整合多种忠实度指标并优化一个统一的目标函数，解决了现有XAI方法缺乏客观评估标准的问题。该框架通过一个学习过程生成高度忠实的解释，并在广泛的任务和模型上验证了其优越性。

> **摘要翻译:** 可解释人工智能（XAI）通过揭示决策逻辑的模型归因方法来建立对复杂系统的信任。然而，由于缺乏统一的最佳解释，现有的XAI方法缺乏客观评估和优化的地面真实标准。为了解决这个问题，我们提出了基于深度架构的忠实度解释器（DeepFaith），一个在忠实度视角下的无领域、无模型统一解释框架。通过建立多种广泛使用且经过充分验证的忠实度指标的统一表述，我们推导出一个最优解释目标，其解决方案可以同时在这些指标上实现最优忠实度，从而从理论上提供一个地面真实标准。我们设计了一个explainer学习框架，它利用多种现有的解释方法，应用去重和过滤来构建高质量的监督解释信号，并优化模式一致性损失和局部相关性来训练一个忠实的explainer。一旦训练完成，DeepFaith可以通过单次前向传播生成高度忠实的解释，而无需访问被解释的模型。在涵盖6个模型和6个数据集的12个不同解释任务上，DeepFaith在10个指标上的整体忠实度均高于所有基线方法，凸显了其有效性和跨领域通用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [969] [VITA: Variational Pretraining of Transformers for Climate-Robust Crop Yield Forecasting](https://arxiv.org/abs/2508.03589)
> *VITA：用于气候稳健作物产量预测的Transformer变分预训练*

*Adib Hasan, Mardavij Roozbehani, Munther Dahleh* | **Category: cs.LG** | **Updated: 2025-08-05**

**Keywords:** 作物产量预测, 变分预训练, Transformer, 数据不对称, 气候变化

**Comment:** 

> **TL;DR:** VITA是一个变分预训练框架，通过利用详细天气变量作为代理目标，解决了预训练天气数据集丰富而微调数据有限的数据不对称问题。它在预测玉米和大豆产量方面取得了最先进的性能，尤其是在极端天气年份，并且优于现有的框架，如GNN-RNN，同时使用的数据量更少。

**AI_Comments:** 该研究提出的VITA框架在解决AI模型在作物产量预测中因数据不对称而导致的性能下降问题上具有重要意义。通过利用详细天气变量作为代理目标进行预训练，并结合自监督特征掩码，VITA有效地提升了模型在数据稀缺和极端天气条件下的预测能力。其在实际应用中优于现有方法且数据需求更少，为应对气候变化带来的农业挑战提供了有前景的解决方案。然而，进一步研究其在不同地理区域和作物类型的泛化能力，以及对模型可解释性的探讨将是未来有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能模型在预测偏离历史趋势的作物产量时表现不佳，这是由于预训练天气数据集丰富而微调数据有限的数据不对称性造成的。

**Method:** VITA是一个变分预训练框架，它使用详细的天气变量作为代理目标，并通过自监督特征掩码学习预测丰富的气象状态，从而解决数据不对称问题。

**Result:** VITA在美国玉米带的763个县进行了应用，在所有评估场景下预测玉米和大豆产量均实现了最先进的性能。在正常条件下，其性能始终优越，在极端天气年份的优势尤为明显（配对t检验，p≈0.01）。此外，VITA使用的数据量少于GNN-RNN等现有框架，在数据稀缺地区更具实用性。

**Conclusion:** 该研究强调了领域感知的人工智能设计如何克服数据限制，并在不断变化的气候中支持具有韧性的农业预测。

> **ai_Abstract:** VITA是一个新颖的变分预训练框架，旨在解决作物产量预测中数据不对称的问题。通过利用详细天气变量作为代理目标和自监督特征掩码，VITA能够有效地利用丰富的预训练数据，并仅使用基本天气统计数据进行微调。该模型在美国玉米带的玉米和大豆产量预测方面取得了最先进的成果，尤其是在应对极端天气事件方面表现出色，并优于现有方法，同时需要更少的数据。

> **摘要翻译:** 准确的作物产量预测对全球粮食安全至关重要。
然而，当前的人工智能模型在产量偏离历史趋势时会系统性地表现不佳。
这个问题源于关键的数据挑战，包括丰富的预训练天气数据集和有限的微调数据之间的主要不对称性。
我们引入了VITA（用于不对称数据的变分推理Transformer），一个解决这种不对称性的变分预训练框架。
VITA不依赖于输入重建，而是使用详细的天气变量作为预训练期间的代理目标，并通过自监督特征掩码学习预测丰富的大气状态。
这使得模型在部署期间仅使用基本的天气统计数据即可进行微调。
VITA应用于美国玉米带的763个县，在所有评估场景下预测玉米和大豆产量均实现了最先进的性能。
虽然它在正常条件下始终提供优越的性能，但其优势在极端天气年份尤为明显，具有统计学上显著的改进（配对t检验，$p \approx 0.01$）。
重要的是，VITA比GNN-RNN等现有框架表现更好，使用的数据量更少，使其在现实世界中的应用更具实用性——尤其是在数据稀缺的地区。
这项工作强调了领域感知的人工智能设计如何克服数据限制，并在不断变化的气候中支持具有韧性的农业预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [974] [DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening](https://arxiv.org/abs/2508.02741)
> *DeepGB-TB：一种风险平衡的交叉注意力梯度提升卷积网络，用于快速、可解释的结核病筛查*

*Zhixiang Lu, Yulong Li, Feilong Tang, Zhengyong Jiang, Chong Li, Mian Zhou, Tenglong Li, Jionglong Su* | **Category: cs.LG, cs.AI, cs.SD** | **Updated: 2025-08-02**

**Keywords:** 结核病筛查,人工智能,卷积神经网络,梯度提升树,交叉注意力

**Comment:** 

> **TL;DR:** 该研究提出了一种名为DeepGB-TB的AI系统，该系统仅使用咳嗽音频和基本人口统计学数据，通过结合一维卷积神经网络和梯度提升决策树，并引入交叉注意力模块和风险平衡损失函数，能够快速、可解释地评估结核病风险，并在多国数据集上达到了新的最先进性能，适用于低资源环境。

**AI_Comments:** 该研究提出的DeepGB-TB系统在结核病筛查方面取得了显著进展，特别是在利用咳嗽音频和人口统计学数据进行快速、可解释的风险评估方面。交叉模态双向交叉注意力（CM-BCA）模块和结核病风险平衡损失（TRBL）函数的结合是该方法的关键创新点，解决了临床上对减少漏诊的迫切需求。该系统在多国数据集上达到的先进性能和在移动设备上进行实时离线推理的能力，使其在低资源环境下的应用潜力巨大。然而，未来研究可以进一步探讨该模型在不同地理区域和人群中的泛化能力，以及其长期临床影响的评估。

<details>
  <summary>Details</summary>

**Motivation:** 传统结核病诊断方法成本高、操作复杂，需要人工智能解决方案来支持大规模筛查。

**Method:** 提出了一种名为DeepGB-TB的非侵入性系统，该系统耦合了用于音频处理的轻量级一维卷积神经网络和用于表格特征的梯度提升决策树。其创新之处在于使用交叉模态双向交叉注意力（CM-BCA）模块在模态间交换线索，并采用结核病风险平衡损失（TRBL）函数来降低漏诊率。

**Result:** 在包含来自七个国家1105名患者的数据集上，DeepGB-TB实现了0.903的AUROC和0.851的F1分数，达到了新的最先进水平。该系统计算效率高，可在常见移动设备上进行实时、离线推理，并能提供临床验证的解释。

**Conclusion:** DeepGB-TB通过结合人工智能创新和对速度、可负担性和可靠性的公共卫生要求，提供了一个促进全球结核病控制的工具。

> **ai_Abstract:** DeepGB-TB是一种创新的AI系统，利用咳嗽音频和人口统计学数据，结合卷积神经网络和梯度提升树，并通过交叉注意力和风险平衡损失函数优化，实现了快速、可解释的结核病筛查，性能优于现有技术，并适用于低资源环境。

> **摘要翻译:** 大规模结核病（TB）筛查受到传统诊断方法的高成本和操作复杂性的限制，这需要人工智能解决方案。我们提出DeepGB-TB，一种非侵入性系统，仅使用咳嗽音频和基本人口统计学数据即可即时分配TB风险评分。该模型将用于音频处理的轻量级一维卷积神经网络与用于表格特征的梯度提升决策树相结合。其主要创新之处在于交叉模态双向交叉注意力模块（CM-BCA），该模块在模态间迭代交换显着线索，模拟了临床医生整合症状和风险因素的方式。为了满足最小化漏诊病例的临床优先事项，我们设计了一种结核病风险平衡损失（TRBL），该损失对假阴性预测施加更强的惩罚，从而减少高风险误分类。DeepGB-TB在一个包含来自七个国家的1105名患者的多样化数据集上进行了评估，实现了0.903的AUROC和0.851的F1分数，代表了新的最先进水平。其计算效率使其能够在常见的移动设备上进行实时、离线推理，非常适合低资源环境。重要的是，该系统能够产生临床验证的解释，从而促进一线医护人员的信任和采纳。通过将人工智能创新与对速度、可负担性和可靠性的公共卫生要求相结合，DeepGB-TB提供了一个促进全球结核病控制的工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [28] [Analysis of logics with arithmetic](https://arxiv.org/abs/2508.03574)
> *算术逻辑分析*

*Michael Benedikt, Chia-Hsuan Lu, Tony Tan* | **Category: cs.LO** | **Updated: 2025-08-05**

**Keywords:** 逻辑, 算术, 有限可满足性, 复杂性, Presburger量词

**Comment:** 

> **TL;DR:** 该论文提出了关于带有计数和算术的逻辑的有限可满足性的新结果，包括复杂性紧密界限和对先前关键结果的更简单证明。

**AI_Comments:** 该论文的创新之处在于其提出了新的结果和更简单的证明，这对于推进逻辑和复杂性理论领域的理论理解具有重要意义。通过简化现有证明，它可能为未来的研究奠定更坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是提出关于带有计数和算术的逻辑的有限可满足性的新结果，并为这些逻辑的某些关键先前结果提供更简单的证明。

**Method:** 该研究通过理论分析和证明的方式，提出了新的复杂性界限，并提供了对现有结果的简化证明。

**Result:** 结果包括：1. 带有计数和算术的逻辑的有限可满足性的新结果。2. 带有计数和一元公式之间基数比较的双变量逻辑的复杂性紧密界限。3. 带有局部Presburger量词的逻辑的复杂性紧密界限。4. 为这些逻辑的有限可满足性和谱的半线性提供了一些关键先前结果的更简单证明。

**Conclusion:** 该论文成功地在带有计数和算术的逻辑的有限可满足性方面取得了新进展，并为相关领域的先前重要结果提供了更简洁的证明。

> **ai_Abstract:** 本论文介绍了关于带有计数和算术的逻辑的有限可满足性的新发现。具体而言，它为包含计数和一元公式之间基数比较的双变量逻辑以及使用局部Presburger量词的逻辑建立了精确的复杂性界限。此外，论文还为这些逻辑的有限可满足性和谱的半线性相关的重要先前结果提供了更简化的证明。

> **摘要翻译:** 我们提出了关于带有计数和算术的逻辑的有限可满足性的新结果。这包括具有计数和一元公式之间基数比较的双变量逻辑的复杂性紧密界限，以及具有所谓局部Presburger量词的逻辑。在此过程中，我们为这些逻辑的有限可满足性和谱的半线性提供了一些关键先前结果的更简单证明。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [148] [Effective AGM Belief Contraction: A Journey beyond the Finitary Realm (Technical Report)](https://arxiv.org/abs/2409.09171)
> *有效的AGM信念收缩：超越有限领域之旅（技术报告）*

*Dominik Klumpp, Jandson S. Ribeiro* | **Category: cs.LO, cs.AI** | **Updated: 2025-08-04**

**Keywords:** AGM信念收缩, 非有限逻辑, 可计算性, 线性时序逻辑, Büchi自动机

**Comment:** 21 pages, 5 figures

> **TL;DR:** 在非有限逻辑中，AGM收缩函数存在大量不可计算的情况，并且现有控制计算性的策略无效。本文提出了新的方法来控制计算性，并以线性时序逻辑（LTL）为例，展示了可计算的AGM收缩函数。

**AI_Comments:** 这篇论文解决了信念变化领域中一个长期存在的计算性空白，特别是将AGM范式扩展到非有限逻辑时遇到的挑战。其创新之处在于揭示了该领域中普遍存在的不可计算性问题，并批判性地指出现有策略的不足。更重要的是，它提出了基于Büchi自动机的新颖方法，为在复杂逻辑（如LTL）中实现可计算的AGM收缩提供了具体且有效的设计方案，对该领域的理论和实践都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在将AGM范式扩展到非有限逻辑方面付出了巨大努力，但AGM的计算方面几乎未被触及。研究发现，在非有限逻辑中存在大量不可计算的AGM收缩函数，且当前的事实标准策略（限制认知状态空间）无法解决此问题，促使作者提出新的方法来控制计算性。

**Method:** 研究了AGM收缩在非有限逻辑上的可计算性。提出新的方法来控制超越有限领域的计算性。使用线性时序逻辑（LTL）作为案例研究，识别出无限类可计算的AGM收缩函数。利用Büchi自动机来构建这些函数，并表示和推理LTL信念。

**Result:** 发现非有限逻辑中存在无限多的不可计算AGM收缩函数。当前的控制计算性的标准策略（依赖于限制认知状态空间）失败，在所有非有限情况下，不可计算性依然存在。识别出无限类完全理性的AGM收缩函数，这些函数本质上是可计算的。

**Conclusion:** 在非有限逻辑中实现有效的AGM信念收缩需要新的计算性控制方法，并且通过使用Büchi自动机和特定逻辑（如LTL）可以构建出可计算的完全理性AGM收缩函数。

> **ai_Abstract:** 本研究探讨了AGM信念收缩在非有限逻辑中的计算性问题。研究揭示了在这些逻辑中存在大量不可计算的AGM收缩函数，并且现有通过限制认知状态空间来控制计算性的标准方法无效。为解决这一挑战，论文提出了新的计算性控制方法，并以线性时序逻辑（LTL）为例，展示了如何通过Büchi自动机构建出可计算的、完全理性的AGM收缩函数，为超越有限领域的有效信念收缩提供了可行途径。

> **摘要翻译:** 尽管在将AGM范式扩展到有限逻辑之外方面付出了巨大努力，但AGM的计算方面几乎未被触及。我们研究了AGM收缩在非有限逻辑上的可计算性，并展示了一个有趣的负面结果：在这种逻辑中存在无限多个不可计算的AGM收缩函数。更甚的是，我们还表明，当前控制计算性的事实标准策略，即依赖于限制认知状态空间的方法，也失败了：在所有非有限情况下，不可计算性依然存在。受此颠覆性结果的启发，我们提出了控制超越有限领域的计算性的新方法。以线性时序逻辑（LTL）为例，我们识别出无限类本质上可计算的完全理性AGM收缩函数。我们使用Büchi自动机来构建这些函数，并表示和推理LTL信念。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [212] [Deciding subspace reachability problems with application to Skolem's Problem](https://arxiv.org/abs/2410.06528)
> *子空间可达性问题的判定及其在斯科伦问题中的应用*

*Samuel Everett* | **Category: cs.LO, 11B37, 03D99, 68Q01, F.0; G.2.0** | **Updated: 2025-08-05**

**Keywords:** 子空间可达性, 斯科伦问题, 轨道问题, 几何视角, 可判定性

**Comment:** 24 pages, 0 figures

> **TL;DR:** 本文提出了一种解决离散和连续轨道问题以及斯科伦问题的几何方法，为特定类别的实例推导出了一个判定过程，并为一些现有结果提供了替代证明。

**AI_Comments:** 这篇论文的创新之处在于它摒弃了传统的代数和数论方法，为极具挑战性的轨道问题引入了几何视角。尽管它仅为“某一类实例”提供了判定过程，但这种新方法意义重大，因为它为探索这些臭名昭著的难解问题提供了一条新途径，并为已知结果提供了更简单的替代证明。其局限性在于未能为所有实例提供通用解决方案。

<details>
  <summary>Details</summary>

**Motivation:** Kannan和Lipton的轨道问题（离散和连续版本）的高维版本以及斯科伦问题的可判定性仍然是开放问题。传统的代数和数论方法高度技术化。本文的动机是提供一种替代的、几何的视角来解决这些问题。

**Method:** 本文采用了一种有别于传统代数和数论方法的几何视角来研究离散和连续轨道问题。推导出了一个简单的判定过程。

**Result:** 本文推导出了一个简单的判定过程，能够判定轨道问题的某一类实例。作为应用，它利用初等几何论证为许多结果提供了替代证明。

**Conclusion:** 本文成功引入了一种几何方法来解决轨道问题，为特定类别的实例提供了一个部分解决方案，并为已知结果提供了新的证明，这表明了传统方法之外的一种有前景的替代途径。

> **ai_Abstract:** 本文探讨了尚未解决的高维轨道问题及其连续模拟，这些问题是斯科伦问题的推广。它引入了一种新颖的几何视角，有别于传统的代数和数论方法。作者开发了一个适用于特定类别轨道问题实例的简单判定过程，并利用初等几何论证为现有结果提供了替代证明。

> **摘要翻译:** Kannan和Lipton的轨道问题的高维版本询问，在重复应用线性变换的情况下，目标子空间是否可以从起始点到达，这是否是可判定的。类似地，轨道问题的连续模拟询问，由线性微分方程组引起的流是否会到达某个指定的子空间。这两个问题的可判定性仍然悬而未决，事实上，这些问题是斯科伦问题离散和连续版本的推广。本文的目的是传达离散和连续轨道问题的几何视角，以替代传统上高度技术性的代数和数论方法。我们推导出一个简单的判定过程，能够判定轨道问题的某一类实例，并且作为应用，我们利用初等几何论证获得了许多结果的替代证明。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [268] [Cobblestone: A Divide-and-Conquer Approach for Automating Formal Verification](https://arxiv.org/abs/2410.19940)
> *Cobblestone：一种自动化形式化验证的分而治之方法*

*Saketh Ram Kasibatla, Arpan Agarwal, Yuriy Brun, Sorin Lerner, Talia Ringer, Emily First* | **Category: cs.LO, cs.AI, cs.PL** | **Updated: 2025-08-04**

**Keywords:** 形式化验证, 证明合成, 分而治之, 大型语言模型, Coq

**Comment:** 14 pages, 14 figures

> **TL;DR:** Cobblestone是一种分而治之的证明合成方法，它利用LLM自动生成和完善Coq项目的形式化证明，即使LLM本身不可靠，也能保证证明的正确性，并且性能优于现有工具。

**AI_Comments:** Cobblestone的创新之处在于其“分而治之”策略，巧妙地利用了LLM的生成能力，同时通过迭代和验证机制克服了LLM固有的“不可靠性”问题，从而在保证证明正确性的前提下大幅提升了自动化水平。其能够集成外部输入的能力也增加了其实用性。该方法为将不完全可靠的AI工具应用于高精度要求的领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 形式化验证（如使用Coq）能有效提升软件质量，但需要大量精力和专业知识。机器学习虽能自动合成证明，但其能力有限，只能证明一小部分所需属性。

**Method:** Cobblestone采用分而治之的方法进行证明合成。它使用大型语言模型（LLM）生成潜在证明，利用这些证明将问题分解为更简单的部分，自动识别哪些部分已成功证明，并迭代处理剩余部分，从而构建出即使依赖不可靠LLM也能保证正确性的可靠证明。它还可以利用用户或外部工具提供的证明结构或相关引理作为外部输入。

**Result:** 在四个开源Coq项目基准测试中，Cobblestone在全自动模式下优于最先进的非LLM工具，并能证明其他基于LLM的工具无法证明的许多定理，在许多基准测试中表现更优。每次运行平均成本1.25美元，耗时14.7分钟。结合外部输入（如预言机），Cobblestone能证明高达58%的定理。

**Conclusion:** 研究表明，工具可以利用部分进展和外部输入来更有效地自动化形式化验证。

> **ai_Abstract:** 本文介绍了Cobblestone，一种用于自动化形式化验证的分而治之方法。Cobblestone利用大型语言模型（LLM）生成潜在证明，并将复杂的证明任务分解为更简单的子问题，通过迭代和自动验证确保最终证明的正确性，即使LLM本身不可靠。在对开源Coq项目的评估中，Cobblestone在全自动模式下显著优于现有非LLM及其他LLM工具，且成本和时间效率高。研究结果表明，结合部分进展和外部输入能有效提升形式化验证的自动化水平。

> **摘要翻译:** 形式化验证使用证明助手，例如Coq，是提高软件质量的有效方法，但需要大量的精力和专业知识。机器学习可以自动合成证明，但此类工具只能证明所需软件属性的一小部分。我们引入了Cobblestone，一种用于证明合成的分而治之方法。Cobblestone使用大型语言模型（LLM）生成潜在证明，利用这些证明将问题分解为更简单的部分，自动识别哪些部分已成功证明，并迭代处理剩余部分，以构建一个正确的、保证可靠的证明，尽管依赖于不可靠的LLM。我们在四个开源Coq项目基准测试中评估了Cobblestone，并控制了训练数据泄露。在全自动模式下，Cobblestone超越了最先进的非LLM工具，并证明了许多其他基于LLM的工具无法证明的定理，在许多基准测试中表现优异。每次Cobblestone运行平均仅花费1.25美元，耗时14.7分钟。Cobblestone还可以与来自用户或另一个工具的外部输入一起使用，提供证明结构或相关引理。在与此类预言机一起评估时，Cobblestone证明了高达58%的定理。总的来说，我们的研究表明，工具可以利用部分进展和外部输入来更有效地自动化形式化验证。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [905] [When are two algorithms the same? Towards addressing Hilbert's 24th problem](https://arxiv.org/abs/2508.02764)
> *两个算法何时相同？—— 迈向解决希尔伯特第24问题*

*Konstantin Doubrovinski* | **Category: cs.LO** | **Updated: 2025-08-04**

**Keywords:** 程序等价性, 希尔伯特第24问题, 柯尔莫哥洛夫复杂性, 递归论, 形式化证明

**Comment:** 

> **TL;DR:** 该研究提出了一种基于柯尔莫哥洛夫复杂性理论的最小化方法，用于在递归论的框架下，定义和区分计算机程序（递归函数）的“本质相同性”，以期解决希尔伯特第24问题。

**AI_Comments:** 该研究将一个具有历史意义的哲学数学问题（希尔伯特第24问题）与现代计算机科学（程序等价性）相结合，具有开创性。利用柯尔莫哥洛夫复杂性作为工具来解决程序等价性问题是一个有趣且有潜力的方向。然而，抽象的理论框架如何转化为实际可操作的算法仍有待观察。

<details>
  <summary>Details</summary>

**Motivation:** 希尔伯特曾考虑将“两个定理证明本质上是否相同”的问题纳入其著名问题列表，但最终放弃。该研究将此问题延伸至计算机程序（递归函数），并寻求在递归论框架内解决。

**Method:** 利用柯尔莫哥洛夫复杂性理论，提出一种最小化方法来界定程序的“本质相同性”。

**Result:** 尚未明确提及具体研究结果，但提出了一个基于柯尔莫哥洛夫复杂性理论的框架。

**Conclusion:** 尚未明确提及具体结论，但研究旨在为程序等价性提供一个理论基础。

> **ai_Abstract:** 本研究借鉴希尔伯特关于定理证明“本质相同性”的思想，将其应用于计算机程序（递归函数）的等价性问题。研究者提出了一种基于柯尔莫哥洛夫复杂性理论的最小化方法，在递归论的框架内探讨程序何时可以被认为是“本质相同”的。

> **摘要翻译:** “两个定理证明本质上是否相同”这一非正式问题可以追溯到大卫·希尔伯特，他曾考虑将其（或与之大致等价的问题）添加到他著名的开放性问题列表中，但最终决定将其排除。鉴于形式化证明的概念与（计算机）程序，即递归函数，的概念密切相关，因此将相同的问题用在程序上可能是有用的。在这里，我们提出一种在递归论内的最小化方法来处理这个问题，该方法在很大程度上借鉴了柯尔莫哥洛夫复杂性理论。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [953] [Intensional FOL over Belnap's Billatice for Strong-AI Robotics](https://arxiv.org/abs/2508.02774)
> *用于强人工智能机器人的内涵一阶逻辑与贝尔纳格格*

*Zoran Majkic* | **Category: cs.LO** | **Updated: 2025-08-04**

**Keywords:** 强人工智能, 机器人, 内涵一阶逻辑, 贝尔纳格格, 四真值逻辑

**Comment:** 28 pages

> **TL;DR:** 该论文提出了一种基于贝尔纳格格的内涵一阶逻辑（IFOL），作为对标准一阶逻辑的扩展，旨在解决强人工智能（AGI）机器人面临的悖论和不完整知识问题，使其更接近人类智能，具备自我意识、问题解决、学习和规划能力。

**AI_Comments:** 该研究提出了一种新颖的逻辑框架IFOL，旨在解决AGI机器人面临的关键挑战，如处理不确定性和不完整信息。将贝尔纳格格的四真值系统应用于IFOL是一个有前景的方向，但其在实际机器人应用中的有效性和效率仍需进一步验证。该方法在理论上具有重要意义，为AGI的认知架构提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 强人工智能（AGI）旨在创造与人类心智难以区分的智能机器人。AGI机器人需要像人类一样通过输入和经验学习，并具备自我意识、解决问题、学习和规划能力。标准二值一阶逻辑在处理悖论和机器人处理不完整知识方面存在问题，因此需要一种更先进的逻辑系统。

**Method:** 提出一种内涵一阶逻辑（IFOL），作为标准一阶逻辑的扩展。该IFOL具有相同的语法，但采用不同的语义，基于贝尔纳格格（Belnap's billatice），包含四种真值，能够处理真值排序和知识排序，以解决标准二值逻辑的悖论和不完整知识问题。

**Result:** 提出了一种新的逻辑系统IFOL，它扩展了标准一阶逻辑，并结合了贝尔纳格格的四真值系统，能够处理真值排序和知识排序，从而为AGI机器人的发展提供理论基础，以应对复杂性和不确定性。

**Conclusion:** 所提出的内涵一阶逻辑（IFOL）通过引入贝尔纳格格的四真值系统，为解决强人工智能（AGI）机器人在处理悖论和不完整知识方面的问题提供了一种新的方法，使其能够更有效地模拟人类智能。

> **ai_Abstract:** 本研究提出了一种内涵一阶逻辑（IFOL），作为对标准一阶逻辑的扩展，并结合了贝尔纳格格的四真值系统。该逻辑旨在为强人工智能（AGI）机器人提供一种更接近人类智能的框架，使其能够处理悖论和不完整知识，并具备自我意识、学习和规划能力。

> **摘要翻译:** 通用人工智能（AGI）（强人工智能）旨在创造在某种程度上可以与人类心智相媲美的智能机器人。AGI机器人就像一个孩子，需要通过输入和经验来学习，并随着时间的推移不断进步和提升其能力。AGI机器人将需要一种更接近人类的智能：它将拥有自我意识，能够解决问题、学习和规划。基于这种方法，提出了一种内涵的、多类型的、（一阶）逻辑（IFOL），它作为具有塔斯基语义的标准一阶逻辑的扩展，旨在避免标准二值一阶逻辑在悖论（矛盾公式）和机器人处理不完整（未知）知识的必要性方面的问题。这是IFOL的一个更复杂的版本，具有相同的语法但具有不同的语义，能够基于众所周知的具有四种真值的贝尔纳格格来处理真值排序和知识排序，这扩展了经典二值真值的集合。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [92] [Distributionally Robust Markov Games with Average Reward](https://arxiv.org/abs/2508.03136)
> *具有平均奖励的分布鲁棒马尔可夫博弈*

*Zachary Roch, Yue Wang* | **Category: cs.MA** | **Updated: 2025-08-05**

**Keywords:** 分布鲁棒, 马尔可夫博弈, 平均奖励, 纳什均衡, 多智能体决策

**Comment:** 

> **TL;DR:** 本文提出了具有平均奖励的分布鲁棒马尔可夫博弈（DR-MG）公式，证明了鲁棒纳什均衡的存在性，并开发了一种算法来计算它。

**AI_Comments:** 本文的创新之处在于将分布鲁棒性与平均奖励准则相结合，用于多智能体马尔可夫博弈，这对于需要长期稳定性和可靠性的系统至关重要。理论上，它证明了鲁棒纳什均衡的存在性，并提供了计算方法，填补了现有模型在长期不确定性下多智能体决策的空白。其重要性在于为应对复杂多变环境中的多智能体决策提供了坚实的理论和实用工具。

<details>
  <summary>Details</summary>

**Motivation:** 在不确定性下，多智能体决策需要一个能够捕捉长期性能的框架，尤其是在需要持续可靠性的系统中。现有模型（有限视界或折扣模型）无法自然地捕捉这一点。

**Method:** 1. 引入了具有平均奖励的分布鲁棒马尔可夫博弈（DR-MG）的公式。2. 建立了多智能体与单智能体设置之间的联系。3. 推导了平均奖励公式下鲁棒贝尔曼方程的可解性。4. 严格证明了鲁棒纳什均衡（NE）的存在性。5. 开发并分析了名为“鲁棒纳什迭代”的算法来计算鲁棒纳什均衡。6. 证明了平均奖励NE与折扣NE之间的联系，即前者可以近似为折扣因子趋近于1的情况。

**Result:** 1. 建立了多智能体与单智能体设置之间的联系。2. 证明了平均奖励公式下鲁棒贝尔曼方程的可解性。3. 严格证明了鲁棒纳什均衡（NE）的存在性。4. 开发了用于计算鲁棒纳什均衡的鲁棒纳什迭代算法。5. 证明了平均奖励NE可以近似为折扣因子趋近于1时的折扣NE。

**Conclusion:** 这些贡献为在复杂、不确定和长期运行的多玩家环境中识别最优策略提供了全面的理论和算法基础，并允许未来将鲁棒平均奖励单智能体问题扩展到多智能体设置。

> **ai_Abstract:** 本文提出了具有平均奖励的分布鲁棒马尔可夫博弈（DR-MG）框架，用于解决不确定性下多智能体决策的长期性能问题。研究建立了多智能体与单智能体设置的联系，并证明了鲁棒贝尔曼方程的可解性及鲁棒纳什均衡的存在性。此外，论文还开发了鲁棒纳什迭代算法来计算纳什均衡，并揭示了平均奖励纳什均衡与折扣纳什均衡之间的近似关系。这些工作为复杂、不确定多玩家环境中的最优策略识别提供了理论和算法基础。

> **摘要翻译:** 本文引入了具有平均奖励的分布鲁棒马尔可夫博弈（DR-MG）的公式，这是在不确定性下长期多智能体决策的关键框架。与有限视界或折扣模型不同，平均奖励准则自然地捕捉了为连续运行而设计的系统的长期性能，其中持续可靠性至关重要。我们考虑了转移核中的不确定性，玩家旨在优化他们的最坏情况平均奖励。我们首先建立了多智能体和单智能体设置之间的联系，并推导了平均奖励公式下鲁棒贝尔曼方程的可解性。然后，我们严格证明了鲁棒纳什均衡（NE）的存在性，为系统稳定性提供了重要的理论保证。我们进一步开发并分析了一种名为鲁棒纳什迭代的算法，用于计算所有智能体之间的鲁棒纳什均衡，为在复杂、不确定和长期运行的多玩家环境中识别最优策略提供了实用工具。最后，我们证明了平均奖励NE与广受研究的折扣NE之间的联系，表明前者可以近似为折扣因子趋近于一的情况。总而言之，这些贡献为在复杂、不确定和长期运行的多玩家环境中识别最优策略提供了全面的理论和算法基础，这将允许未来将鲁棒平均奖励单智能体问题扩展到多智能体设置。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [195] [Frequency Point Game Environment for UAVs via Expert Knowledge and Large Language Model](https://arxiv.org/abs/2508.02757)
> *无人机基于专家知识和大型语言模型的频点博弈环境*

*Jingpu Yang* | **Category: cs.MA, cs.GT, cs.RO** | **Updated: 2025-08-03**

**Keywords:** 无人机, 频点博弈, 专家知识, 大型语言模型, 抗干扰策略

**Comment:** 

> **TL;DR:** 提出UAV-FPG，一个结合专家知识和LLM的无人机通信博弈环境模型，用于提升抗干扰策略和路径规划，实验证明LLM在动态场景下优于固定路径策略。

**AI_Comments:** 这篇论文的创新点在于将专家知识和大型语言模型（LLM）结合应用于无人机通信的频谱博弈和路径规划。LLM用于模拟“强对抗者”并进行动态路径规划，这为解决无人机在复杂电磁环境下的智能决策提供了新颖且有效的方法。其重要性在于为无人机抗干扰策略的开发提供了一个更真实、更智能的仿真平台。

<details>
  <summary>Details</summary>

**Motivation:** 解决无人机频谱竞争建模、专家知识整合和对手行为预测方面的挑战。

**Method:** 提出UAV-FPG，一个博弈论环境模型，模拟无人机通信频段中干扰与反干扰策略的动态交互。该模型结合先验专家知识库优化频率选择，并采用大型语言模型进行路径规划，模拟“强对抗者”。

**Result:** 实验结果表明，整合专家知识库和大型语言模型是有效的，其中大型语言模型通过迭代交互显著改善了动态场景下的路径规划，优于固定路径策略。

**Conclusion:** UAV-FPG为推进无人机通信系统中的抗干扰策略和智能决策提供了强大的平台。

> **ai_Abstract:** 本文提出了UAV-FPG，一个针对无人机通信中频谱竞争和对抗行为建模的博弈论环境。该模型创新性地结合了专家知识库进行频率选择优化，并利用大型语言模型模拟强对抗者进行动态路径规划。实验证明，这种集成方法，特别是LLM在动态场景下的路径规划能力，显著优于传统固定路径策略，为无人机抗干扰和智能决策提供了新途径。

> **摘要翻译:** 无人机（UAV）通过跳频、信号扩频和自适应干扰抑制等技术，在通信稳定性和安全性方面取得了显著进展。然而，在频谱竞争建模、专家知识整合和对手行为预测方面仍然存在挑战。为了解决这些问题，我们提出了UAV-FPG（无人机-频点博弈），这是一个博弈论环境模型，模拟了无人机在通信频段中干扰方和反干扰方之间策略的动态交互。该模型结合了先验专家知识库来优化频率选择，并采用大型语言模型进行路径规划，模拟“强对抗者”。实验结果突出显示了整合专家知识库和大型语言模型的有效性，其中后者通过迭代交互显著改善了动态场景中的路径规划，优于固定路径策略。UAV-FPG为推进无人机通信系统中的抗干扰策略和智能决策提供了一个强大的平台。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [325] [TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding](https://arxiv.org/abs/2508.02826)
> *TransAM：基于Transformer的通过局部轨迹编码实现多智能体系统中的智能体建模*

*Conor Wallace, Umer Siddique, Yongcan Cao* | **Category: cs.MA, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 智能体建模, 多智能体系统, Transformer, 局部轨迹编码, 策略表示

**Comment:** 

> **TL;DR:** TransAM是一种基于Transformer的智能体建模方法，它利用局部轨迹编码来学习其他智能体的策略表示，解决了现有方法需要全局轨迹的局限性，并在多智能体环境中取得了更好的性能。

**AI_Comments:** 这项工作通过引入基于Transformer的局部轨迹编码，为多智能体系统中的智能体建模提供了一个实用的解决方案，克服了传统方法对全局轨迹的依赖，具有重要的实际应用价值。其创新性在于利用Transformer的强大表示能力处理局部信息，从而在复杂的多智能体交互中实现高效的策略推断。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多智能体系统中智能体建模方法通常需要访问其他智能体的完整轨迹，这在实际应用中往往不切实际。因此，需要一种仅基于受控智能体局部轨迹来学习其他智能体策略的鲁棒表示的实用方法。

**Method:** 论文提出了TransAM，一种新颖的基于Transformer的智能体建模方法。该方法将局部轨迹编码到嵌入空间中，以有效地捕获其他智能体的策略。

**Result:** 实验结果表明，TransAM方法能够生成强大的策略表示，改进智能体建模，并带来更高的回合回报。

**Conclusion:** TransAM通过有效编码局部轨迹，成功地解决了多智能体系统中智能体建模对全局轨迹的依赖问题，显著提升了智能体建模的性能和系统的回报。

> **ai_Abstract:** 本文提出了TransAM，一种新颖的基于Transformer的智能体建模方法，旨在解决现有方法依赖全局轨迹的局限性。TransAM通过将受控智能体的局部轨迹编码到嵌入空间中，学习并表示其他智能体的策略。在合作、竞争和混合多智能体环境中的广泛实验证明，TransAM能生成强大的策略表示，显著提升智能体建模能力，并最终提高回合回报。

> **摘要翻译:** 智能体建模是开发多智能体系统中有效策略的关键组成部分，因为它使智能体能够形成对其他智能体行为、意图和能力的信念。许多现有方法假设可以访问其他智能体的回合轨迹，这在现实世界应用中通常是不切实际的条件。因此，一种实用的智能体建模方法必须仅基于受控智能体的局部轨迹来学习其他智能体策略的鲁棒表示。在本文中，我们提出了 TransAM，一种新颖的基于 Transformer 的智能体建模方法，用于将局部轨迹编码到嵌入空间中，以有效地捕获其他智能体的策略。我们在合作、竞争和混合多智能体环境中评估了所提出方法的性能。大量的实验结果表明，我们的方法生成了强大的策略表示，改进了智能体建模，并带来了更高的回合回报。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [333] [TVDO: Tchebycheff Value-Decomposition Optimization for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2306.13979)
> *TVDO：切比雪夫值分解优化用于多智能体强化学习*

*Xiaoliang Hu, Pengcheng Guo, Yadong Li, Guanyu Li, Zhen Cui, Jian Yang* | **Category: cs.MA** | **Updated: 2025-08-05**

**Keywords:** 多智能体强化学习, 值分解, 切比雪夫方法, 策略一致性, 集中式训练分散式执行

**Comment:** 

> **TL;DR:** 提出TVDO方法，通过切比雪夫值分解解决CTDE中联合训练策略与个体执行动作不一致问题，理论证明满足IGM，并在实验中表现优越。

**AI_Comments:** 该论文的创新点在于将多目标优化中的切比雪夫方法引入到多智能体强化学习的值分解中，以解决CTDE范式下策略一致性问题。通过理论证明IGM条件和在SMAC基准上的优越性能，展示了其有效性和潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 合作多智能体强化学习（MARL）中的集中式训练分散式执行（CTDE）面临联合训练策略与个体执行动作之间存在不一致性的困境。

**Method:** 提出了一种分解的切比雪夫值分解优化（TVDO）方法。该方法通过构建一个非线性切比雪夫聚合函数，严格约束个体动作值偏差的上限，从而实现全局最优。理论上证明了其满足个体-全局最大化（IGM）的充分性和必要性。

**Result:** 在爬升和惩罚游戏中，TVDO精确表达了全局到个体的值分解，并保证了策略一致性。在SMAC基准测试中，TVDO表现出显著优于现有SOTA MARL基线的性能。

**Conclusion:** TVDO方法通过切比雪夫值分解，有效解决了多智能体强化学习中CTDE范式下的策略不一致问题，并在理论和实践中均展现出其有效性和优越性。

> **ai_Abstract:** 本文提出了一种名为TVDO（Tchebycheff Value-Decomposition Optimization）的新方法，旨在解决合作多智能体强化学习（MARL）中集中式训练分散式执行（CTDE）范式下策略不一致的挑战。TVDO引入了一个非线性切比雪夫聚合函数，通过严格限制个体动作值偏差的上限来实现全局最优，并从理论上证明了其满足个体-全局最大化（IGM）条件，从而确保全局与个体最优动作值函数的一致性。实验结果表明，TVDO在策略一致性方面表现出色，并在SMAC基准测试中显著超越了现有最先进的MARL方法。

> **摘要翻译:** 在合作多智能体强化学习（MARL）中，由于物理需求，集中式训练分散式执行（CTDE）最近受到了更多关注。然而，其中最大的困境是联合训练策略与个体执行动作之间的不一致性。在本文中，我们提出了一种分解的切比雪夫值分解优化（TVDO）方法来克服不一致性问题。特别是，受多目标优化中切比雪夫方法的启发，我们构建了一个非线性切比雪夫聚合函数，通过严格约束个体动作值偏差的上限来实现全局最优。我们理论证明，在没有额外限制的情况下，带有切比雪夫聚合的分解值分解满足个体-全局最大化（IGM）的充分性和必要性，这保证了全局和个体最优动作值函数之间的一致性。在实证方面，在爬升和惩罚游戏中，我们验证了TVDO精确表达了全局到个体的值分解，并保证了策略一致性。同时，我们在SMAC基准测试中评估了TVDO，大量的实验表明TVDO在性能上显著优于一些SOTA MARL基线。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [507] [Engineered over Emergent Communication in MARL for Scalable and Sample-Efficient Cooperative Task Allocation in a Partially Observable Grid](https://arxiv.org/abs/2508.02912)
> *多智能体强化学习中工程化与涌现式通信在部分可观测网格中可扩展且样本高效的协作任务分配研究*

*Brennen A. Hill, Mant Koh En Wei, Thangavel Jishnuanandh* | **Category: cs.MA, cs.AI, cs.LG, cs.SY, eess.SY, 68T42, 68T05, 90C40, 93E35, 68T07, I.2.11; I.2.6; I.2.8** | **Updated: 2025-08-04**

**Keywords:** 多智能体强化学习, 通信策略, 工程化通信, 涌现式通信, 合作任务分配

**Comment:** 

> **TL;DR:** 在多智能体强化学习中，研究比较了学习型（涌现式）和工程化通信策略的有效性。结果表明，工程化方法在性能和可扩展性上优于涌现式通信，尤其在环境复杂性增加时。

**AI_Comments:** 这篇论文的创新点在于直接对比了多智能体强化学习中两种截然不同的通信范式：涌现式学习通信和预先设计的工程化通信。其重要性在于揭示了在特定合作任务和复杂环境下，工程化通信可能比完全依赖学习的涌现式通信更具优势，为设计高效的多智能体协作系统提供了实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在比较在合作多智能体强化学习环境中，学习型通信策略（涌现式）与工程化通信策略的有效性。

**Method:** 研究提出了两种通信策略：1. 学习型方法：学习直接通信（LDC），智能体通过神经网络同时生成消息和动作。2. 工程化方法：意图通信，采用想象轨迹生成模块（ITGM）和消息生成网络（MGN）基于预测的未来状态来制定消息。两种策略都在完全可观测和部分可观测条件下的合作任务中，通过成功率进行评估。

**Result:** 研究发现，虽然涌现式通信是可行的，但工程化方法表现出卓越的性能和可扩展性，尤其是在环境复杂性增加时。

**Conclusion:** 在所研究的合作多智能体强化学习环境中，工程化通信策略在性能和可扩展性方面优于涌现式通信。

> **ai_Abstract:** 该研究在合作多智能体强化学习（MARL）环境中，对比了学习型（涌现式）与工程化通信策略的效能。研究提出了学习直接通信（LDC）作为学习型方法，以及基于想象轨迹生成模块（ITGM）和消息生成网络（MGN）的意图通信作为工程化方法。实验结果表明，尽管涌现式通信可行，但工程化方法在性能和可扩展性方面表现更优，尤其适用于复杂环境。

> **摘要翻译:** 我们比较了在合作多智能体强化学习（MARL）环境中，学习型通信策略与工程化通信策略的有效性。对于学习型方法，我们引入了学习直接通信（LDC），其中智能体通过神经网络同时生成消息和动作。我们的工程化方法，意图通信，采用想象轨迹生成模块（ITGM）和一个消息生成网络（MGN），基于预测的未来状态来制定消息。这两种策略都在完全可观测和部分可观测条件下的合作任务中，通过成功率进行评估。我们的发现表明，尽管涌现式通信是可行的，但工程化方法表现出卓越的性能和可扩展性，尤其是在环境复杂性增加时。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [839] [VisAug: Facilitating Speech-Rich Web Video Navigation and Engagement with Auto-Generated Visual Augmentations](https://arxiv.org/abs/2508.03410)
> *VisAug：通过自动生成的视觉增强促进富含语音的网络视频导航和参与度*

*Baoquan Zhao, Xiaofan Ma, Qianshi Pang, Ruomei Wang, Fan Zhou, Shujin Lin* | **Category: cs.MM, cs.HC** | **Updated: 2025-08-05**

**Keywords:** VisAug,视觉增强,富含语音的视频,视频导航,用户参与度

**Comment:** 

> **TL;DR:** VisAug是一个新系统，通过根据视频的语音内容自动生成视觉增强来改善富含语音的视频的导航和用户参与度。

**AI_Comments:** 该研究提出了一种创新的方法来解决富含语音的视频内容消费的挑战。通过自动生成视觉增强，VisAug有望提高用户参与度和信息获取效率。然而，该系统在不同类型的富含语音视频上的有效性以及生成增强的质量和相关性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 与包含丰富视觉线索的监控录像等视频类型不同，富含语音的视频（如在线学习、社交和工作活动中的视频）主要通过音频通道传达有意义的信息。这给使用现有的基于视觉的视频摘要、导航和探索系统带来了挑战。

**Method:** VisAug是一个新颖的交互式系统，它根据视频的语音内容自动生成信息丰富且富有表现力的视觉增强，以改善富含语音的视频的导航和用户参与度。

**Result:** 研究结果表明，该系统有潜力显著改善在日益增长的视频驱动的数字环境中的信息消费和用户参与度。

**Conclusion:** VisAug系统通过自动生成视觉增强，可以显著提高用户对富含语音的视频内容的消费和参与度，从而应对现有视频导航和探索系统的挑战。

> **ai_Abstract:** VisAug是一个新颖的交互式系统，旨在通过利用视频的语音内容自动生成视觉增强来改善富含语音的视频的导航和用户参与度。它解决了传统视频摘要和导航系统在处理主要依赖音频内容而非视觉线索的视频时遇到的挑战。

> **摘要翻译:** 数字技术的广泛采用标志着我们生活所有方面数字化转型的新时代。在线学习、社交和工作活动，如远程教育、视频会议、面试和讲座，导致富含语音的视频内容急剧增加。与通常包含丰富视觉线索的监控录像等其他视频类型相比，富含语音的视频主要通过音频通道传达其有意义的信息。这给使用现有的基于视觉的视频摘要、导航和探索系统来改善内容消费带来了挑战。在本文中，我们提出了VisAug，一个新颖的交互式系统，旨在通过根据视频的语音内容自动生成信息丰富且富有表现力的视觉增强来改善富含语音的视频的导航和用户参与度。我们的研究结果表明，该系统有潜力显著改善在日益增长的视频驱动的数字环境中的信息消费和用户参与度。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [890] [OpenLifelogQA: An Open-Ended Multi-Modal Lifelog Question-Answering Dataset](https://arxiv.org/abs/2508.03583)
> *开放式生活日志问答：一个开放式多模态生活日志问答数据集*

*Quang-Linh Tran, Binh Nguyen, Gareth J. F. Jones, Cathal Gurrin* | **Category: cs.MM, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 生活日志, 问答, 多模态, 数据集, OpenLifelogQA

**Comment:** 

> **TL;DR:** 该研究提出了OpenLifelogQA数据集，用于生活日志数据的开放式多模态问答，包含14,187个问答对，旨在促进生活日志技术的相关研究。

**AI_Comments:** 该研究通过构建一个大规模、真实的开放式多模态生活日志问答数据集，有效解决了现有研究资源的局限性。数据集的多样性和基线实验结果为后续研究提供了坚实的基础，尤其是在推动个性化生活日志助手等实际应用方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对生活日志数据的问答研究资源有限，主要局限于小型或合成数据集，未能满足实际应用需求。

**Method:** 构建了一个基于18个月生活日志数据的、包含14,187个问答对的OpenLifelogQA数据集，并报告了一个使用LLaVA-NeXT-Interleave 7B模型的基线实验。

**Result:** 基线实验报告了89.7%的BERT Score，25.87%的ROUGE-L和3.9665的LLM Score。

**Conclusion:** OpenLifelogQA数据集的发布将支持生活日志技术的新研究，例如实现基于聊天的个人生活日志助手。

> **ai_Abstract:** 本研究介绍了OpenLifelogQA，一个包含14,187个问答对的新型生活日志问答数据集，该数据集基于18个月的真实生活日志数据，专注于开放式和多模态问答，旨在推动个性化生活日志助手等应用的研究。

> **摘要翻译:** 生活日志是指使用可穿戴设备被动地收集、存储和分析个人日常生活数据的过程。这些数据可以支持记忆保存和增强的应用。例如，利用问答策略，对生活日志数据进行问答为探索难忘事件和日常生活见解提供了一种互动且有趣的方式。然而，生活日志数据问答的研究资源仅限于小型或合成问答数据集。在本文中，我们提出了一个名为OpenLifelogQA的新型生活日志问答数据集，该数据集建立在18个月的生活日志数据集之上。我们的数据集专注于开放式和实际的问答，并在日常生活日志使用中具有实际应用。我们构建了14,187对不同类型和难度级别的问答。本文报告了该数据集的基线实验，使用LLaVA-NeXT-Interleave 7B模型取得了89.7%的BERT Score，25.87%的ROUGE-L和3.9665的LLM Score的竞争性平均性能。我们向研究界发布了这个问答数据集，以支持生活日志技术的新研究，例如使基于聊天的个人生活日志助手成为现实。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [695] [VCNet: Recreating High-Level Visual Cortex Principles for Robust Artificial Vision](https://arxiv.org/abs/2508.02995)
> *VCNet：重现高级视觉皮层原理以实现强大的机器视觉*

*Brennen A. Hill, Zhang Xinyu, Timothy Putra Prasetio* | **Category: cs.NE, cs.AI, cs.CV, cs.LG, 68T07, 68T45, 68U10, I.2.6; I.4.8; I.2.10; I.5.1** | **Updated: 2025-08-05**

**Keywords:** VCNet, 机器视觉, 灵长类视觉皮层, 神经科学原理, 鲁棒性

**Comment:** 

> **TL;DR:** VCNet是一种受灵长类视觉皮层启发的新的神经网络架构，它通过模仿生物机制来提高数据效率、泛化能力和鲁棒性，并在Spots-10和光场图像分类任务上取得了优于现有模型的性能。

**AI_Comments:** 该研究将灵长类视觉皮层的生物机制融入神经网络设计，解决了传统CNN在效率和鲁棒性方面的不足，并取得了优于现有模型的性能，为开发更强大的AI视觉系统提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现代卷积神经网络（CNN）在数据效率、分布外泛化和对抗扰动鲁棒性方面存在局限性，而灵长类视觉系统则表现出优越的效率和鲁棒性，这表明其架构原理可以为更强大的机器视觉系统提供蓝图。

**Method:** VCNet模仿了灵长类视觉皮层宏观组织的关键生物机制，包括跨不同皮层区域的层级处理、双流信息分离以及自上而下的预测反馈。

**Result:** VCNet在Spots-10数据集上达到了92.1%的分类准确率，在光场数据集上达到了74.4%的分类准确率，超过了同等规模的当代模型。

**Conclusion:** 将神经科学原理融入网络设计可以构建更高效、更鲁棒的模型，为解决机器学习中的长期挑战提供了一个有前景的方向。

> **ai_Abstract:** VCNet是一种新型神经网络架构，其设计灵感来源于灵长类视觉皮层的宏观组织和生物机制（如层级处理、双流信息和预测反馈）。与传统的CNN相比，VCNet在数据效率、泛化能力和鲁棒性方面表现更优，并在Spots-10和光场图像分类任务上取得了领先性能。

> **摘要翻译:** 尽管现代卷积神经网络（CNN）在图像分类方面取得了成功，但它们在数据效率、分布外泛化和对抗性扰动鲁棒性方面存在根本性局限。相比之下，灵长类视觉系统表现出优越的效率和鲁棒性，这表明其架构原理可以为更强大的机器视觉系统提供蓝图。本文介绍了一种名为Visual Cortex Network（VCNet）的新型神经网络架构，其设计灵感来源于灵长类视觉皮层的宏观组织。VCNet模仿了关键的生物机制，包括跨不同皮层区域的层级处理、双流信息分离以及自上而下的预测反馈。我们在两个专门的基准测试上对VCNet进行了评估：Spots-10动物图案数据集和光场图像分类任务。我们的结果表明，VCNet在Spots-10数据集上的分类准确率为92.1%，在光场数据集上的分类准确率为74.4%，超过了同等规模的当代模型。这项工作表明，将神经科学原理融入网络设计可以带来更高效、更鲁棒的模型，为解决机器学习中的长期挑战提供了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [821] [Cascading CMA-ES Instances for Generating Input-diverse Solution Batches](https://arxiv.org/abs/2502.13730)
> *级联 CMA-ES 实例以生成输入多样化的解决方案批次*

*Maria Laura Santoni, Christoph Dürr, Carola Doerr, Mike Preuss, Elena Raponi* | **Category: cs.NE** | **Updated: 2025-08-05**

**Keywords:** CMA-ES, 多样化解决方案, 级联优化, 禁忌区域, 优化算法

**Comment:** 

> **TL;DR:** 该研究提出了一种名为 CMA-ES-DS 的新方法，通过级联 CMA-ES 实例并继承禁忌区域来生成高质量且多样化的解决方案批次，解决了现有算法在满足最小距离要求的同时优化适应度方面的不足。

**AI_Comments:** 该研究提出了一种新颖的级联 CMA-ES 方法来解决生成输入多样化解决方案批次的问题，这对于需要多种设计选择的应用场景非常重要。该方法通过继承禁忌区域来确保解决方案的多样性，同时保持高质量。实验结果表明该方法优于现有技术，但其在不同优化问题上的泛化能力和计算成本仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 用户通常需要一组多样化的解决方案而非单一最优解，因为最优解可能在难以建模的附加目标或约束方面表现不佳。因此，生成一组高质量且多样化的解决方案具有重要意义，因为这能满足用户在事后偏好的灵活性，同时不牺牲最优解的质量。

**Method:** 提出了一种新的方法，其中协方差矩阵自适应进化策略（CMA-ES）的并行运行以级联方式继承禁忌区域。具体算法命名为 CMA-ES-Diversity Search (CMA-ES-DS)。

**Result:** 实验证明，CMA-ES-DS 算法生成的轨迹能够提取出满足给定最小距离要求的高质量解决方案批次，并且在性能上明显优于现成的随机采样、多模态优化算法以及标准的 CMA-ES。

**Conclusion:** 所提出的 CMA-ES-DS 方法能够有效地生成高质量且满足最小距离要求的多样化解决方案批次，克服了现有算法在该问题上的局限性。

> **ai_Abstract:** 本研究提出了一种名为 CMA-ES-DS 的新算法，通过级联 CMA-ES 实例并继承禁忌区域，能够生成满足最小距离要求的高质量多样化解决方案批次。该方法解决了现有算法在平衡解决方案质量和多样性方面的不足，并在实验中优于随机采样、多模态优化算法和标准 CMA-ES。

> **摘要翻译:** 与为给定的优化问题获得单一的良好解决方案不同，用户通常会寻求替代的设计选择，因为找到的最佳解决方案在难以纳入建模过程的附加目标或约束方面可能表现不佳。
旨在获得高质量多样化解决方案批次通常是可取的，因为它能为适应事后用户偏好提供灵活性。同时，关键在于不牺牲找到的最佳解决方案的质量。
一个平衡高质量和多样性的特定问题设置是固定解决方案之间所需的最小距离，同时获得最佳可能的适应度。Santoni 等人 [arXiv 2024] 的近期工作揭示，该设置并未被最先进的算法很好地解决，其表现与纯随机采样相当或更差。
基于这一重要限制，我们提出了一种新方法，其中协方差矩阵自适应进化策略（CMA-ES）的并行运行以级联方式继承禁忌区域。我们通过实验证明，我们的 CMA-ES-Diversity Search (CMA-ES-DS) 算法生成的轨迹能够提取出满足给定最小距离要求的高质量解决方案批次，其性能明显优于从现成的随机采样、多模态优化算法和标准 CMA-ES 中获得的解决方案。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [5] [Scalability and Performance Evaluation of IEEE 802.11ah IoT Deployments: A Testbed Approach](https://arxiv.org/abs/2508.03146)
> *IEEE 802.11ah 物联网部署的可扩展性和性能评估：一种测试平台方法*

*Kostas Chounos, Katerina Kyriakou, Thanasis Korakis* | **Category: cs.NI** | **Updated: 2025-08-05**

**Keywords:** IEEE 802.11ah, 物联网, 性能评估, 可扩展性, 测试平台, 能耗

**Comment:** 

> **TL;DR:** 本研究通过构建IEEE 802.11ah测试平台，揭示了实际物联网部署中网络性能和可扩展性的局限性，特别是网络争用和邻信道干扰对吞吐量和能耗的影响。

**AI_Comments:** 这项研究的创新之处在于它是首次在复杂真实世界环境中对IEEE 802.11ah进行实施和性能评估，揭示了网络争用和邻信道干扰等实际挑战，并提供了能耗分析，对于未来物联网和5G应用的规划具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了分析日益增长的数据需求及其影响，并揭示IEEE 802.11ah网络在实际部署中的性能和可扩展性限制，尤其是在复杂场景下可能出现的意外行为。

**Method:** 研究团队构建了一个IEEE 802.11ah (WiFi Halow) 办公测试平台，进行真实世界的实验，以评估网络性能和设备能耗。

**Result:** 研究发现，在紧密部署的无线链路中，吞吐量会显著下降。强烈的网络争用和邻信道干扰（ACI）会严重影响无线链路的性能。实验分析还考虑了被测设备的能耗。

**Conclusion:** 有效揭示这些意外现象有助于在物联网到云的连续体中做出良好规划的决策和能耗优化。

> **ai_Abstract:** 本研究通过构建一个IEEE 802.11ah WiFi Halow测试平台，对物联网部署的性能和可扩展性进行了深入评估。研究发现，在真实世界复杂场景下，网络争用和邻信道干扰会导致显著的吞吐量下降。此外，研究还分析了设备的能耗，为物联网到云的部署提供了更全面的洞察，旨在通过揭示意外现象来优化决策和能耗。

> **摘要翻译:** 本研究关注现代无线物联网（IoT）架构的开发和评估，与新兴的5G及未来应用相关。为了分析日益增长的数据需求及其影响，我们构建了一个IEEE 802.11ah（WiFi Halow）办公室测试平台，用于真实世界的实验。这种部署使我们能够在各种挑战性场景下，揭示此类网络的实际性能和可扩展性限制。据我们所知，这是首次考虑复杂的真实世界IEEE 802.11ah实现的研究，旨在专门揭示意外的性能行为，例如在紧密部署的无线链路中出现的显著吞吐量下降。我们的研究结果表明，强烈的网络争用和邻信道干扰（ACI）严重影响了所涉及无线链路的性能。除了评估网络性能外，我们的实验分析还考虑了被测设备的能耗，从而对IEEE 802.11ah在实际部署中的可行性提供了更全面的视角。有效揭示这些意外现象，可以促使在物联网到云的连续体中做出良好规划的决策和能耗优化。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [76] [Energy-efficient Federated Learning for UAV Communications](https://arxiv.org/abs/2508.03171)
> *无人机通信中的节能联邦学习*

*Chien-Wei Fu, Meng-Lin Ku* | **Category: cs.NI, cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 联邦学习, 无人机通信, 节能, 联合优化, 能耗优化

**Comment:** 

> **TL;DR:** 该文提出了一种无人机辅助的联邦学习框架，通过联合优化无人机轨迹、用户参与、功率分配和数据量控制来最小化整体系统能耗，并设计了迭代能耗优化（ECO）算法，仿真结果表明其性能优于现有基线方案。

**AI_Comments:** 该研究通过将无人机通信与联邦学习相结合，并提出多参数联合优化策略，为实现节能的分布式AI训练提供了新颖的解决方案，特别是在资源受限的无人机场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决无人机辅助联邦学习中整体系统能耗过高的问题，通过联合优化多个参数来最小化能耗。

**Method:** 提出了一种无人机（UAV）辅助的联邦学习（FL）框架，联合优化无人机轨迹、用户参与、功率分配和数据量控制。推导了多局部更新下FL模型的收敛精度。针对非凸联合优化问题，采用交替优化（AO）和逐次凸近似（SCA）技术，设计了迭代能耗优化（ECO）算法。

**Result:** 仿真结果证实，所提出的ECO算法始终优于现有基线方案。

**Conclusion:** 所提出的ECO算法能够有效降低无人机辅助联邦学习系统的整体能耗。

> **ai_Abstract:** 本文提出一种无人机辅助的联邦学习框架，通过联合优化无人机轨迹、用户参与、功率分配和数据量来最小化系统能耗。针对非凸优化问题，文章利用交替优化和逐次凸近似技术，设计了迭代能耗优化（ECO）算法。仿真结果表明，ECO算法在能耗方面优于现有基线方案。

> **摘要翻译:** 在本文中，我们提出了一种无人机（UAV）辅助的联邦学习（FL）框架，该框架联合优化无人机轨迹、用户参与、功率分配和数据量控制，以最小化整体系统能耗。我们首先推导了多局部更新下FL模型的收敛精度，从而对用户参与和数据量如何影响FL学习性能有了理论理解。由此产生的联合优化问题是非凸的；为了解决这个问题，我们采用交替优化（AO）和逐次凸近似（SCA）技术来凸化非凸约束，从而设计出一种迭代能耗优化（ECO）算法。仿真结果证实，ECO始终优于现有基线方案。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [85] [Statistical QoS Provision in Business-Centric Networks](https://arxiv.org/abs/2408.15609)
> *以业务为中心的网络中的统计QoS保障*

*Chang Wu, Yuang Chen, Hancheng Lu* | **Category: cs.NI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 统计QoS, 业务中心网络, 深度强化学习, 跨层优化, 资源管理

**Comment:** 19 figures

> **TL;DR:** 论文提出了一个基于DRL的框架（COHA-ES），用于在业务中心网络（BCN）中实现可扩展的统计QoS保障，通过跨层优化资源。

**AI_Comments:** 本文的创新点在于提出了以业务为中心的网络（BCN）概念以实现QoS保障，并采用跨层优化方法。特别值得关注的是，其提出的COHA-ES深度强化学习框架及其多线程经验共享机制，有效解决了复杂参数耦合问题并加速了训练过程。该研究对于在现代无线网络中实现可扩展和高效的QoS保障具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有无线通信技术需要更精细的资源管理和QoS保障，以实现可扩展的服务质量供应。

**Method:** 提出了一种新颖的以业务为中心的网络（BCN），基于捕获应用、传输参数和信道之间关系的跨层框架。研究了连续流和事件驱动流模型，并关注吞吐量、延迟和可靠性等QoS指标。通过联合考虑跨层的功率和带宽分配、传输参数以及AP网络拓扑，优化了具有统计QoS保障的加权资源效率。为解决参数耦合问题，提出了一种名为COHA-ES（基于经验共享的异构行动者协同优化）的深度强化学习（DRL）框架，其中代表多个AP的功率和子信道（SC）行动者在共同评论员的统一指导下进行联合优化。此外，引入了一种多线程经验共享机制以加速训练并提高奖励。

**Result:** 广泛的对比实验验证了所提出的DRL框架在收敛性和效率方面的有效性。对比分析表明，BCN结构在提高频谱效率和能量效率方面具有综合优势。

**Conclusion:** 论文提出的BCN结构和基于DRL的COHA-ES框架能够有效提供可扩展的统计QoS，并显著提升无线网络的资源效率。

> **ai_Abstract:** 本文提出了一种以业务为中心的网络（BCN）框架，旨在无线通信中实现可扩展的统计QoS保障。该框架采用跨层方法，通过联合考虑各种网络参数来优化资源效率。为解决参数耦合问题，论文提出了一种新颖的深度强化学习（DRL）框架——COHA-ES，用于优化多AP间的资源分配。实验结果验证了所提DRL框架的有效性以及BCN结构在提高频谱和能量效率方面的综合优势。

> **摘要翻译:** 更精细的资源管理和QoS（服务质量）保障是无线通信技术的一个关键目标。本文提出了一种新颖的以业务为中心的网络（BCN），旨在实现可扩展的QoS保障，该网络基于一个捕获应用、传输参数和信道之间关系的跨层框架。我们研究了连续流和事件驱动流模型，并提出了吞吐量、延迟和可靠性等关键QoS指标。通过联合考虑跨层的功率和带宽分配、传输参数以及AP网络拓扑，我们优化了具有统计QoS保障的加权资源效率。为了解决参数之间的耦合问题，我们提出了一种新颖的深度强化学习（DRL）框架，即基于经验共享的异构行动者协同优化（COHA-ES）。代表多个AP的功率和子信道（SC）行动者在共同评论员的统一指导下进行联合优化。此外，我们引入了一种新颖的多线程经验共享机制，以加速训练并提高奖励。广泛的对比实验验证了我们DRL框架在收敛性和效率方面的有效性。此外，对比分析表明BCN结构在提高频谱效率和能量效率方面具有综合优势。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [110] [Bidirectional TLS Handshake Caching for Constrained Industrial IoT Scenarios](https://arxiv.org/abs/2508.03321)
> *受限工业物联网场景下的双向TLS握手缓存*

*Jörn Bodenhausen, Simon Mangel, Thomas Vogt, Martin Henze* | **Category: cs.NI, cs.CR** | **Updated: 2025-08-05**

**Keywords:** TLS握手, 缓存, 工业物联网, 资源受限, wolfSSL

**Comment:** Accepted for publication in Proceedings of the 2025 IEEE 50th
  Conference on Local Computer Networks (LCN)

> **TL;DR:** BiTHaC通过缓存TLS握手中的静态部分（特别是证书），显著减少了受限工业物联网环境中TLS握手的带宽和计算开销，同时保持了安全性。

**AI_Comments:** 该论文提出了一种创新的TLS优化方案，通过利用握手过程中的静态信息进行缓存，有效解决了工业物联网等资源受限环境中TLS应用面临的性能瓶颈。其双向缓存的思路具有独特性，并且实验结果表明了显著的带宽和计算资源节省。这项工作对于推动TLS在边缘设备和受限网络中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** TLS作为端到端安全的标准，在资源受限的工业物联网（IIoT）场景中应用受限，主要是因为TLS握手建立安全连接会产生显著的带宽和处理开销，这在受限环境中难以处理。

**Method:** 本文提出了BiTHaC，它通过利用重复TLS握手（特别是证书）的显著静态部分，实现了双向TLS握手缓存。这样，冗余信息既不需要传输也不需要进行相应的计算。

**Result:** 通过在wolfSSL上实现BiTHaC，结果显示TLS握手的带宽消耗可降低高达61.1%，计算开销可降低高达8.5%，同时只产生可管理的内存开销，并保留了TLS严格的安全保证。

**Conclusion:** BiTHaC通过缓存TLS握手中的静态部分，有效解决了受限工业物联网场景中TLS握手带来的高带宽和计算开销问题，同时保持了TLS的安全性。

> **ai_Abstract:** 本文针对工业物联网（IIoT）中TLS握手因资源受限而导致的带宽和处理开销问题，提出了一种名为BiTHaC的双向TLS握手缓存机制。BiTHaC利用TLS握手中（特别是证书）的静态部分进行缓存，从而避免了冗余数据传输和计算。在wolfSSL上的实现表明，该方法可将TLS握手带宽降低高达61.1%，计算开销降低高达8.5%，且内存开销可控，同时保持了TLS的严格安全保障。

> **摘要翻译:** 虽然TLS已成为端到端安全的实际标准，但其在不断发展的工业物联网场景中用于保护关键通信的应用受到设备和网络普遍资源限制的严重制约。最值得注意的是，建立安全连接的TLS握手会产生显著的带宽和处理开销，这在受限环境中通常无法处理。为了缓解这种情况，我们提出了BiTHaC，它通过利用重复TLS握手（特别是证书）的显著静态部分是静态的这一事实，实现了双向TLS握手缓存。因此，冗余信息既不需要传输也不需要执行相应的计算，从而节省了宝贵的带宽和处理资源。通过为wolfSSL实现BiTHaC，我们表明我们可以将TLS握手的带宽消耗降低高达61.1%，计算开销降低高达8.5%，同时仅产生易于管理的内存开销并保留TLS严格的安全保证。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [125] [SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate](https://arxiv.org/abs/2411.08767)
> *SANDWICH：迈向离线、可微分、完全可训练的无线神经射线追踪替代方案*

*Yifei Jin, Ali Maatouk, Sarunas Girdzijauskas, Shugong Xu, Leandros Tassiulas, Rex Ying* | **Category: cs.NI, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 无线射线追踪, 神经网络, B5G, 离线训练, 生成模型

**Comment:** Accepted in ICMLCN 2025

> **TL;DR:** SANDWICH提出了一种离线、可微分、完全可训练的无线神经射线追踪替代方案，通过将射线轨迹生成重新定义为顺序决策问题，并利用生成模型来学习光学、物理和信号特性，以解决现有无线射线追踪在B5G网络建模中的挑战。

**AI_Comments:** SANDWICH的创新之处在于其离线、可微分和完全可训练的特性，以及将射线轨迹生成重新定义为顺序决策问题，并利用生成模型进行学习。这解决了传统在线学习方法的成本高昂和GPU不兼容问题，对于B5G网络信道建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的无线射线追踪方法难以准确建模超越5G（B5G）网络信号，这些信号通常在更高频率下运行，并且更容易受到环境条件和变化的影响。现有在线学习解决方案在训练期间需要实时环境监督，这既昂贵又与基于GPU的处理不兼容。

**Method:** 本研究提出了一种新颖的方法，将射线轨迹生成重新定义为顺序决策问题，利用生成模型共同学习每个指定环境中的光学、物理和信号特性。该工作引入了场景感知神经决策无线信道射线追踪层次结构（SANDWICH），这是一种创新的离线、完全可微分的方法，可以在GPU上完全训练。

**Result:** SANDWICH与现有在线学习方法相比，性能更优，射线追踪精度比基线提高4e^-2弧度，信道增益估计仅比顶级水平衰减0.5 dB。

**Conclusion:** SANDWICH提供了一种创新的离线、可微分、完全可训练的无线神经射线追踪替代方案，能够有效解决现有方法在B5G网络建模中的挑战，并在性能上超越了现有在线学习方法。

> **ai_Abstract:** SANDWICH提出了一种创新的离线、可微分、完全可训练的无线神经射线追踪替代方案。该方法将射线轨迹生成视为顺序决策问题，并利用生成模型学习环境中的光学、物理和信号特性，以应对B5G网络建模的挑战。SANDWICH在GPU上进行训练，性能优于现有在线学习方法，并在射线追踪精度和信道增益估计方面表现出色。

> **摘要翻译:** 无线射线追踪（RT）在图形渲染技术进步的推动下，正成为三维（3D）无线信道建模的关键工具。目前的方法难以准确建模超越5G（B5G）网络信号，这些信号通常在更高频率下运行，并且更容易受到环境条件和变化的影响。现有在线学习解决方案在训练期间需要实时环境监督，这既昂贵又与基于GPU的处理不兼容。为此，我们提出了一种新颖的方法，将射线轨迹生成重新定义为顺序决策问题，利用生成模型共同学习每个指定环境中的光学、物理和信号特性。我们的工作引入了场景感知神经决策无线信道射线追踪层次结构（SANDWICH），这是一种创新的离线、完全可微分的方法，可以在GPU上完全训练。SANDWICH与现有在线学习方法相比，性能更优，射线追踪精度比基线提高4e^-2弧度，信道增益估计仅比顶级水平衰减0.5 dB。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [165] [An Extensible Software Transport Layer for GPU Networking](https://arxiv.org/abs/2504.17307)
> *GPU网络的可扩展软件传输层*

*Yang Zhou, Zhongjie Chen, Ziming Mao, ChonLam Lao, Shuo Yang, Pravein Govindan Kannan, Jiaqi Gao, Yilong Zhao, Yongji Wu, Kaichao You, Fengyuan Ren, Zhiying Xu, Costin Raiciu, Ion Stoica* | **Category: cs.NI** | **Updated: 2025-08-04**

**Keywords:** GPU网络, 软件传输层, RDMA, 机器学习, 流冲突

**Comment:** 

> **TL;DR:** 面对机器学习工作负载对网络日益增长的需求，现有RDMA网卡的主机网络传输难以演进，导致性能问题。本文提出了UCCL，一个可扩展的软件传输层，通过解耦RDMA网卡的数据和控制路径，并在CPU上运行控制路径，实现了传输创新（如多路径传输以解决流冲突）。基于UCCL的ML集合通信性能比现有RDMA网卡提高了4.5倍。

**AI_Comments:** UCCL通过将网络传输创新从僵硬的硬件转移到灵活的软件，解决了ML高性能计算中的一个关键瓶颈。这种解耦策略是创新的，为未来数据中心，特别是GPU上的计算密集型任务的网络优化提供了一条有前景的路径。它能够实现多路径传输等功能，直接解决了常见的性能下降问题。

<details>
  <summary>Details</summary>

**Motivation:** 快速发展的机器学习（ML）工作负载对网络的要求越来越高，但RDMA网卡上的主机网络传输难以演进，导致ML工作负载出现问题，例如单路径RDMA流量容易发生流冲突，严重降低了集体通信性能。

**Method:** 本文提出了UCCL，一个可扩展的软件传输层，用于发展GPU网络。UCCL将现有RDMA网卡的数据路径和控制路径解耦，并在主机CPU上高效运行控制路径传输。这种软件可扩展性带来了硬件无法为ML工作负载实现的传输创新，例如，解决流冲突的多路径传输。

**Result:** 与现有RDMA网卡相比，基于UCCL的ML集合通信性能提高了4.5倍。

**Conclusion:** UCCL提供了一个可扩展的软件传输层，通过克服硬件RDMA网卡的局限性，实现了软件创新，显著提升了面向ML工作负载的GPU网络性能。

> **ai_Abstract:** 本文介绍了一种名为UCCL的可扩展软件传输层，旨在增强面向快速演进的机器学习工作负载的GPU网络性能。UCCL通过解耦RDMA网卡的数据和控制路径，并在主机CPU上运行控制路径，从而实现软件驱动的传输创新，例如多路径传输以缓解流冲突。这种方法显著提升了ML集体通信性能，相比传统RDMA网卡实现了高达4.5倍的性能提升。

> **摘要翻译:** 快速发展的机器学习（ML）工作负载对网络的要求越来越高。然而，RDMA网卡上的主机网络传输难以演进，给ML工作负载带来了问题。例如，单路径RDMA流量容易发生流冲突，严重降低了集体通信性能。我们提出了UCCL，一个可扩展的软件传输层，用于发展GPU网络。UCCL将现有RDMA网卡的数据路径和控制路径解耦，并在主机CPU上高效运行控制路径传输。这种软件可扩展性带来了硬件无法为ML工作负载实现的传输创新，例如，解决流冲突的多路径传输。与现有RDMA网卡相比，基于UCCL的ML集合通信性能提高了4.5倍。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [178] [Directives for Function Offloading in 5G Networks Based on a Performance Characteristics Analysis](https://arxiv.org/abs/2508.03287)
> *基于性能特征分析的5G网络功能卸载指令*

*Falk Dettinger, Matthias Weiß, Daniel Baumann, Martin Sommer, Michael Weyrich* | **Category: cs.NI, cs.DC, C.2.4; C.4** | **Updated: 2025-08-05**

**Keywords:** 5G网络, 功能卸载, 车辆, 性能分析, 云计算

**Comment:** 7 pages, 4 figures

> **TL;DR:** 本文评估了在德国真实5G非独立组网环境下，车辆AI功能云卸载的性能，发现信号质量良好，传输时间受地理位置和网络连接影响，处理时间受硬件影响，且云卸载在往返时间超过150毫秒时更适用。

**AI_Comments:** 该论文通过在真实世界5G非独立组网环境下对车辆功能卸载进行实证评估，填补了理论研究与实际应用之间的空白，具有重要的实践意义。其创新之处在于结合了AI算法、多种部署策略和不同地理环境进行测试，并提出了基于往返时间的功能卸载指导原则。研究结果对未来5G车联网的应用部署具有直接的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决资源密集型车辆算法的能耗和性能挑战，基于云的卸载是一种解决方案。5G的低延迟和高带宽特性使其成为车云集成的理想选择。然而，目前只有非独立组网的5G可用，且与理论研究相比，实际应用尚未得到充分探索，因此需要对5G非独立组网进行实际评估。

**Method:** 本研究评估了在5G非独立组网下车辆功能在云端的执行情况，重点关注延迟、往返时间(RTT)和数据包传输。测试使用了两种基于AI的算法（情感识别和物体识别），在德国巴登-符腾堡州8.8公里的城市、乡村和森林路线上进行。分析了法兰克福的一个云小机和曼海姆的一个云平台，并采用了包括传统应用、容器化和容器编排在内的多种部署策略。

**Result:** 主要发现包括：平均信号质量为84%，尽管在建成区有轻微下降，但没有连接中断。两种算法的数据包错误率均低于0.1%。传输时间因地理位置和后端服务器的网络连接而显著不同，而处理时间主要受所用计算硬件的影响。此外，当往返时间超过150毫秒时，云卸载似乎才是一个合适的选择。

**Conclusion:** 本研究评估了真实5G非独立组网环境下车辆功能云卸载的性能，并得出结论：信号质量良好，数据包错误率低，但传输时间受地理位置和网络连接影响，处理时间受计算硬件影响。重要的是，云卸载在往返时间超过150毫秒时才具备可行性，这为5G网络中的功能卸载提供了具体的指导。

> **ai_Abstract:** 本研究评估了在真实5G非独立组网环境下，车辆AI功能（情感识别和物体识别）进行云端卸载的性能特征。通过在德国8.8公里的混合路线上测试，并比较了云小机和云平台的多种部署策略，结果显示5G网络连接稳定（平均信号质量84%，PER低于0.1%），但传输时间受地理位置和网络连接影响，处理时间受硬件影响。研究指出，当往返时间超过150毫秒时，云卸载才是一个合适的选择，为5G网络中的车辆功能卸载提供了实用指导。

> **摘要翻译:** 基于云的卸载有助于解决执行资源密集型车辆算法时的能耗和性能挑战。利用5G的低延迟和高带宽特性，可以实现车辆到云端的无缝集成。目前，只有非独立组网的5G可供公众使用，与理论研究相比，实际应用仍未得到充分探索。本文评估了5G非独立组网在车辆功能云端执行方面的性能，重点关注延迟、往返时间以及数据包传输。测试使用了两种基于AI的算法——情感识别和物体识别——在德国巴登-符腾堡州一条8.8公里的路线上进行，该路线涵盖了城市、乡村和森林区域。分析了两个平台：法兰克福的一个云小机和曼海姆的一个云平台，采用了各种部署策略，如传统应用程序以及容器化和容器编排设置。主要发现突出显示，平均信号质量为84%，尽管在建成区有轻微下降，但没有连接中断。数据包分析显示，两种算法的数据包错误率均低于0.1%。传输时间因地理位置和后端服务器的网络连接而显著不同，而处理时间主要受所用计算硬件的影响。此外，当往返时间超过150毫秒时，云卸载似乎才是一个合适的选择。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [205] [ATRO: A Fast Algorithm for Topology Engineering of Reconfigurable Datacenter Networks](https://arxiv.org/abs/2507.13717)
> *ATRO：一种可重构数据中心网络拓扑工程的快速算法*

*Yingming Mao, Qiaozhu Zhai, Ximeng Liu, Xinchi Han, Fafan li, Shizhen Zhao, Yuzhou Zhou, Zhen Yao, Xia Zhu* | **Category: cs.NI, C.2.3** | **Updated: 2025-08-05**

**Keywords:** 可重构数据中心网络, 拓扑优化, 路由优化, ATRO, 流量工程

**Comment:** 

> **TL;DR:** ATRO是一种用于可重构数据中心网络中拓扑和路由优化的快速算法，它能有效处理单跳和多跳场景，并在运行时和链路利用率方面优于现有方法。

**AI_Comments:** ATRO的创新之处在于其统一的框架能够高效地解决可重构DCNs中的拓扑和路由联合优化问题，尤其是在组合难度高的场景下。其在单跳情况下保证全局最优，并在多跳情况下通过交替优化和支持无求解器方案，展现了强大的实用性和效率。该方法对于提升数据中心网络的灵活性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可重构数据中心网络（DCNs）通过光电路交换机（OCSs）增强了传统架构，实现了互连链路的动态重构，即逻辑拓扑。优化此拓扑对于适应流量动态至关重要，但由于其组合性质而极具挑战性。当需求可以分布在多条路径上时，需要联合优化拓扑和路由，这进一步增加了复杂性。

**Method:** 本文提出了交替拓扑和路由优化（ATRO），一个统一的框架，支持单跳拓扑优化（流量通过直接路径路由）和多跳联合优化（路由也进行优化）。ATRO能高效处理这两种组合困难的情况：在单跳情况下，通过加速二分搜索保证全局最优；在多跳情况下，它在拓扑和路由更新之间交替进行，路由步骤可选地通过现有流量工程（TE）方法加速。ATRO支持热启动并在迭代过程中单调提高解决方案质量。

**Result:** 在单跳情况下，ATRO通过加速二分搜索保证了全局最优。在多跳情况下，即使与无求解器（solver-free）的流量工程方法结合，ATRO也保持了竞争力，形成了一个完全无求解器的优化流程，并且在运行时和不同工作负载下的最大链路利用率方面仍然优于现有方法。

**Conclusion:** ATRO是一种高效且高性能的算法，能够有效解决可重构数据中心网络中的拓扑和路由联合优化问题，尤其在处理复杂场景下表现出显著优势。

> **ai_Abstract:** ATRO是一种用于优化可重构数据中心网络（DCNs）拓扑和路由的快速算法。它解决DCNs中拓扑优化面临的组合难题，并能同时处理单跳拓扑优化和多跳联合拓扑与路由优化。ATRO在单跳场景下通过加速二分搜索保证全局最优，在多跳场景下则通过拓扑和路由的交替更新实现高效优化。该算法支持热启动并能单调提升解决方案质量，即使与无求解器方法结合，也能在运行时和最大链路利用率方面超越现有方法。

> **摘要翻译:** 可重构数据中心网络（DCNs）通过光电路交换机（OCSs）增强了传统架构，实现了互连链路的动态重构，即逻辑拓扑。优化此拓扑对于适应流量动态至关重要，但由于其组合性质而极具挑战性。当需求可以分布在多条路径上时，需要联合优化拓扑和路由，这进一步增加了复杂性。我们提出了交替拓扑和路由优化（ATRO），一个统一的框架，支持单跳拓扑优化（流量通过直接路径路由）和多跳联合优化（路由也进行优化）。尽管这些设置在约束上有所不同，但两者都具有组合困难性，并对基于求解器的方法构成挑战。ATRO高效地解决了这两种情况：在单跳情况下，它通过加速二分搜索保证全局最优；在多跳情况下，它在拓扑和路由更新之间交替进行，路由步骤可选地通过现有流量工程（TE）方法加速。ATRO支持热启动并在迭代过程中单调提高解决方案质量。即使与无求解器（solver-free）的流量工程方法结合，ATRO也保持了竞争力，形成了一个完全无求解器的优化流程，并且在运行时和不同工作负载下的最大链路利用率方面仍然优于现有方法。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [220] [NANDA Adaptive Resolver: Architecture for Dynamic Resolution of AI Agent Names](https://arxiv.org/abs/2508.03113)
> *NANDA 自适应解析器：AI 代理名称动态解析架构*

*John Zinky, Hema Seshadri, Mahesh Lambe, Pradyumna Chari, Ramesh Raskar* | **Category: cs.NI, cs.AI, cs.MA** | **Updated: 2025-08-05**

**Keywords:** AI 代理通信, 动态解析, 微服务架构, 分布式环境, 自适应解析器

**Comment:** 

> **TL;DR:** AdaptiveResolver 是一种动态微服务架构，用于在分布式异构环境中实现 AI 代理名称的实时、上下文感知解析，克服了静态端点解析的局限性。

**AI_Comments:** 该论文的创新之处在于提出了一个动态、上下文感知的 AI 代理名称解析架构，克服了传统静态 DNS/URL 的局限性。它通过支持实时环境因素和代理能力协商，极大地提升了分布式 AI 系统中代理间通信的灵活性、安全性和可扩展性。其重要性在于为未来复杂且不断演进的 AI 生态系统提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在分布式、异构环境中，AI 代理通信面临静态端点解析的局限性（如传统 DNS 或静态 URL）。需要一种能够根据地理位置、系统负载、代理能力和安全威胁等因素进行上下文感知、实时选择通信端点的方法。

**Method:** AdaptiveResolver 是一种动态微服务架构。代理通过代理注册表/索引中的代理事实卡片宣传其代理名称和上下文要求。请求代理使用注册表发现目标代理，然后解析目标代理名称，以根据代理之间实际的环境上下文获取量身定制的通信通道。该架构支持信任、服务质量和资源约束的协商。

**Result:** 它促进了灵活、安全和可扩展的代理到代理交互，超越了经典的客户端-服务器模型。AdaptiveResolver 为健壮、面向未来的代理通信提供了基础，能够随着生态系统复杂性的增加而发展。

**Conclusion:** AdaptiveResolver 提供了一个强大、可扩展的解决方案，用于动态 AI 代理通信，能够适应复杂且不断发展的生态系统。

> **ai_Abstract:** AdaptiveResolver 是一种动态微服务架构，旨在解决分布式异构环境中 AI 代理通信的静态端点解析问题。它通过允许代理宣传自身能力，并根据地理位置、系统负载和安全威胁等上下文因素，实时动态选择和解析通信端点，从而提供量身定制的通信通道。该架构支持信任和资源协商，实现了超越传统客户端-服务器模型的灵活、安全和可扩展的代理间交互，为未来复杂的 AI 生态系统奠定了基础。

> **摘要翻译:** AdaptiveResolver 是一种动态微服务架构，旨在解决分布式、异构环境中 AI 代理通信静态端点解析的局限性。与传统 DNS 或静态 URL 不同，AdaptiveResolver 能够根据地理位置、系统负载、代理能力和安全威胁等因素，实现通信端点的上下文感知、实时选择。代理通过代理注册表/索引中的代理事实卡片宣传其代理名称和上下文要求。请求代理使用注册表发现目标代理。然后，请求代理可以解析目标代理名称，以根据代理之间实际的环境上下文获取量身定制的通信通道。该架构支持信任、服务质量和资源约束的协商，促进了灵活、安全和可扩展的代理到代理交互，超越了经典的客户端-服务器模型。AdaptiveResolver 为健壮、面向未来的代理通信提供了基础，能够随着生态系统复杂性的增加而发展。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [651] [Morphlux: Programmable chip-to-chip photonic fabrics in multi-accelerator servers for ML](https://arxiv.org/abs/2508.03674)
> *Morphlux：用于多加速器服务器中机器学习的可编程芯片到芯片光互连*

*Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Rachee Singh* | **Category: cs.NI, cs.AR, cs.LG** | **Updated: 2025-07-20**

**Keywords:** 光互连, 机器学习, 服务器, 带宽瓶颈, 可编程

**Comment:** 

> **TL;DR:** 该研究提出了一种名为Morphlux的可编程光互连方案，用于解决当前多加速器服务器中，由于电互连带宽限制导致机器学习（ML）加速器资源利用率低的问题。实验证明，Morphlux能够显著提高带宽（高达66%），减少资源碎片（高达70%），并最终将ML模型训练吞吐量提高1.72倍，同时还能快速替换故障的加速器。

**AI_Comments:** 该研究提出了一种非常有前景的光互连解决方案，解决了当前ML服务器面临的关键瓶颈问题。其可编程性和快速故障恢复能力是重要的创新点，但实际部署的成本和功耗等因素需要进一步考虑。

<details>
  <summary>Details</summary>

**Motivation:** 当前多加速器服务器中的电互连带宽已成为机器学习（ML）发展的瓶颈，导致加速器资源（如GPU）利用率低下和闲置。

**Method:** 开发了一种名为Morphlux的服务器级可编程光互连结构，并构建了端到端的硬件原型进行验证。

**Result:** 与现有的光互连方案相比，Morphlux能够将租户计算分配的带宽提高高达66%，将计算碎片减少高达70%，并将ML模型的训练吞吐量提高1.72倍。此外，它能在1.2秒内快速替换服务器中的故障加速器。

**Conclusion:** Morphlux作为一种可编程的光互连方案，能够有效解决当前服务器内加速器互连的带宽瓶颈问题，显著提升ML工作负载的性能和资源利用率，并具备快速故障恢复能力。

> **ai_Abstract:** Morphlux是一种创新的、服务器规模的可编程光互连结构，旨在解决当前机器学习（ML）服务器中由电互连带宽限制引起的性能瓶颈。通过光学互连加速器芯片，Morphlux能够显著提高计算带宽、减少资源碎片，并最终提升ML模型的训练吞吐量。该方案已通过硬件原型验证，并展示了其快速替换故障加速器的能力。

> **摘要翻译:** 我们使用新近可行的可编程芯片到芯片光互连技术，在服务器内部光学互连加速器芯片（例如GPU、TPU）。相比之下，当前作为机器学习主力军的商用多加速器计算服务器，使用电互连在服务器内网络加速器芯片。然而，最近的趋势表明，由于加速器浮点运算能力的扩展速度快于同一服务器内加速器之间互连带宽的扩展速度，互连带宽已达到瓶颈。这导致了云数据中心GPU资源的利用不足和闲置。我们开发了Morphlux，一种服务器规模的可编程光互连结构，用于互连服务器内的加速器。我们表明，用Morphlux增强最先进的面向ML的光互连数据中心，可以将租户计算分配的带宽提高高达66%，并将计算碎片减少高达70%。我们开发了Morphlux的一个新颖的端到端硬件原型来演示这些性能优势，这些优势转化为机器学习模型训练吞吐量1.72倍的提升。通过在我们硬件测试台中快速编程服务器规模的互连结构，Morphlux可以在1.2秒内逻辑地替换一个发生故障的加速器芯片。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [903] [A Survey of AI Agent Registry Solutions](https://arxiv.org/abs/2508.03095)
> *人工智能代理注册表解决方案调查*

*Aditi Singh, Abul Ehtesham, Ramesh Raskar, Mahesh Lambe, Pradyumna Chari, Jared James Grogan, Abhishek Singh, Saket Kumar* | **Category: cs.NI, cs.AI, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 人工智能代理,注册表,元数据,去中心化,互操作性

**Comment:** 

> **TL;DR:** 该论文调查了三种主要的人工智能代理注册表方法：MCP 的 mcp.json、A2A 的 Agent Card 和 NANDA 的 AgentFacts，并根据安全性、可扩展性、身份验证和可维护性对它们进行了比较。

**AI_Comments:** 该调查为理解和导航日益增长的人工智能代理注册表领域提供了宝贵的见解。它有效地比较了不同的方法，并强调了标准化和互操作性的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 随着自主人工智能代理在各种环境中的扩展，需要标准化的注册表系统来进行发现、身份和能力共享。

**Method:** 对三种主要的注册表方法（MCP 的 mcp.json、A2A 的 Agent Card 和 NANDA 的 AgentFacts）进行了调查和比较，重点关注它们的元数据模型、部署（中心化与去中心化）以及跨安全、可扩展性、身份验证和可维护性四个维度。

**Result:** MCP 使用中心化元注册表，A2A 使用基于 URI 的去中心化方法，NANDA 使用具有加密验证和隐私保护功能的 AgentFacts。这些方法在安全性、可扩展性、身份验证和可维护性方面有所不同。

**Conclusion:** 该论文提出了关于未来人工智能代理注册表系统设计和采用的建议和指导方针。

> **ai_Abstract:** 本文对人工智能代理注册表解决方案进行了全面的调查，重点介绍了 MCP、A2A 和 NANDA 的三种主要方法。它深入探讨了它们的元数据模型、部署策略和关键特性，并根据安全、可扩展性、身份验证和可维护性等标准对它们进行了比较，为未来人工智能代理生态系统的发展提供了宝贵的见解和建议。

> **摘要翻译:** 随着自主人工智能代理在云、企业和去中心化环境中的扩展，标准化注册表系统以支持发现、身份和能力共享的需求变得至关重要。本文调查了三种主要的注册表方法，每种方法都由独特的元数据模型定义：MCP 的 mcp.json、A2A 的 Agent Card 和 NANDA 的 AgentFacts。MCP 使用中心化的元注册表，通过 GitHub 身份验证发布和结构化元数据来进行服务器发现。A2A 通过基于 JSON 的 Agent Card 实现去中心化交互，可通过众所周知的 URI、精选目录或直接配置进行发现。NANDA Index 引入了 AgentFacts，这是一个可加密验证且注重隐私的元数据模型，旨在实现动态发现、凭证化能力和跨域互操作性。这些方法在安全性、可扩展性、身份验证和可维护性四个维度上进行了比较。本文最后提出了指导人工智能代理互联网注册表系统未来设计和采用的建议和指导方针。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [947] [A Reinforcement Learning Framework for Mobility Control of gNBs in Dynamic Radio Access Networks](https://arxiv.org/abs/2508.02960)
> *用于动态无线接入网络中 gNB 移动控制的强化学习框架*

*Pedro Duarte, André Coelho, Manuel Ricardo* | **Category: cs.NI** | **Updated: 2025-08-04**

**Keywords:** 强化学习, 移动基站, 移动控制, 视线连接, CONVERGE Chamber Simulator

**Comment:** 

> **TL;DR:** 本研究提出了一种基于强化学习的移动基站（gNB）移动控制框架，并通过名为 CC-SIM 的 3D 模拟器进行了验证。该框架使用深度 Q 网络（DQN）来预测性地重新定位 gNB，以减少视线（LoS）阻塞时间。

**AI_Comments:** 该研究提出了一种创新的强化学习框架，用于解决动态无线网络中移动基站（gNB）的移动控制问题。通过开发 CC-SIM 模拟器，研究为验证和部署此类算法提供了一个现实的平台。DQN 代理在减少视线阻塞时间方面取得了显著成效，证明了其在提高无线网络性能方面的潜力。然而，该研究的局限性在于其在模拟环境中的验证，未来的工作可以探索在真实网络条件下的部署和性能评估。

<details>
  <summary>Details</summary>

**Motivation:** 无线环境日益复杂，用户移动和动态障碍物对保持视线（LoS）连接提出了挑战。移动基站（gNB）通过物理重新定位来恢复或维持 LoS，因此需要智能算法来实现自主移动控制。

**Method:** 研究人员开发了一个名为 CONVERGE Chamber Simulator (CC-SIM) 的 3D 模拟环境，用于开发、训练和验证移动 gNB 的移动控制算法。该模拟器集成了用户和障碍物移动、视觉遮挡以及射频（RF）传播行为，并支持离线强化学习和通过 OpenAirInterface (OAI) RF 模拟器与独立的 5G 系统进行实时测试。在此基础上，研究人员训练了一个深度 Q 网络（DQN）代理，用于根据环境动态变化主动重新定位 gNB。

**Result:** 实验表明，与静态部署相比，所训练的 DQN 代理显著减少了视线（LoS）阻塞时间，最多可减少 42%。

**Conclusion:** 基于学习的移动控制对于自适应的下一代无线网络是有效的。

> **ai_Abstract:** 本研究提出了一种基于强化学习的移动基站（gNB）移动控制框架，并通过名为 CC-SIM 的 3D 模拟器进行了验证。该框架使用深度 Q 网络（DQN）来预测性地重新定位 gNB，以减少视线（LoS）阻塞时间，实验结果显示最多可减少 42% 的阻塞时间。

> **摘要翻译:** 无线环境日益复杂，用户移动和动态障碍物给维持视线（LoS）连接带来了挑战。移动基站（gNB）通过物理重新定位来恢复或维持 LoS，这使得开发自主移动控制的智能算法成为必要。
作为 CONVERGE 研究项目的一部分，该项目正在开发一个集成计算机视觉（CV）到移动网络中并增强动态无线环境中服务质量（QoS）的实验室，本文提出了两项主要贡献。首先，我们引入了 CONVERGE Chamber Simulator (CC-SIM)，一个用于开发、训练和验证移动 gNB 移动控制算法的 3D 模拟环境。CC-SIM 模拟了用户和障碍物的移动、视觉遮挡以及射频（RF）传播行为。它通过与通过 OpenAirInterface (OAI) RF 模拟器独立的 5G 系统进行紧密集成，支持离线强化学习和实时测试，从而能够在真实的网络条件下进行验证。
其次，利用 CC-SIM，我们开发了一个深度 Q 网络（DQN）代理，该代理能够学习根据动态环境变化主动重新定位 gNB。在三个代表性用例中进行的实验表明，与静态部署相比，所训练的代理显著减少了视线（LoS）阻塞时间——最多可达 42%。这些结果凸显了学习驱动的移动控制在自适应的下一代无线网络中的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [960] [Using the NANDA Index Architecture in Practice: An Enterprise Perspective](https://arxiv.org/abs/2508.03101)
> *在实践中使用 NANDA 索引架构：企业视角*

*Sichao Wang, Ramesh Raskar, Mahesh Lambe, Pradyumna Chari, Rekha Singhal, Shailja Gupta, Rajesh Ranjan, Ken Huang* | **Category: cs.NI, cs.AI, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 自主 AI 代理, NANDA 框架, 零信任代理访问, AgentFacts, 代理可见性和控制

**Comment:** 

> **TL;DR:** 该论文提出了 NANDA 框架，一个用于管理和保护自主 AI 代理生态系统的基础设施，解决了发现、身份验证、能力验证和跨协议协作等关键挑战。

**AI_Comments:** 该论文提出了一个名为 NANDA 的框架，旨在解决自主 AI 代理生态系统中的关键基础设施挑战。它通过提供代理发现、身份验证、能力验证和跨异构协议的安全协作来解决这些问题。NANDA 框架通过实施零信任代理访问 (ZTAA) 和代理可见性与控制 (AVC) 机制来增强安全性和治理，从而将孤立的 AI 代理转变为一个互联的、可信的智能服务网络。这项工作对于应对当前 AI 代理能力与安全、可扩展、多代理协作的基础设施要求之间的差距至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自主 AI 代理的激增需要复杂的机制来进行发现、身份验证、能力验证和跨异构协议环境的安全协作，而当前的 AI 代理能力与安全、可扩展、多代理协作的基础设施要求之间存在关键差距。

**Method:** 该论文提出了 NANDA（去中心化架构中的网络化 AI 代理）框架，该框架提供了全局代理发现、通过 AgentFacts 进行的加密可验证能力证明，以及跨 Anthropic 的 Modal Context Protocol (MCP)、Google 的 Agent-to-Agent (A2A)、Microsoft 的 NLWeb 和标准 HTTPS 通信的跨协议互操作性。NANDA 实现了零信任代理访问 (ZTAA) 原则，并定义了代理可见性和控制 (AVC) 机制。

**Result:** NANDA 框架将孤立的 AI 代理转变为一个可验证、可信的智能服务的互联生态系统，为跨企业和消费者环境的大规模自主代理部署奠定了基础。

**Conclusion:** NANDA 框架为实现安全、可信和可互操作的 AI 代理生态系统奠定了基础，解决了当前 AI 代理能力与安全、可扩展、多代理协作的基础设施要求之间的差距。

> **ai_Abstract:** 该论文介绍了 NANDA 框架，这是一个用于自主 AI 代理生态系统的基础设施解决方案。它解决了代理发现、身份验证、能力验证和跨不同协议的安全协作等挑战。NANDA 框架通过实现零信任代理访问 (ZTAA) 和代理可见性与控制 (AVC) 机制，增强了安全性和治理，从而将孤立的 AI 代理转变为一个互联的、可信的智能服务网络。

> **摘要翻译:** 自主 AI 代理的激增代表了从传统 Web 架构到需要复杂的发现、身份验证、能力验证和跨异构协议环境的安全协作机制的协作智能系统的范式转变。本文提出了一个全面的框架，解决了安全、可信和可互操作的 AI 代理生态系统的基本基础设施要求。我们引入了 NANDA（去中心化架构中的网络化 AI 代理）框架，提供了全局代理发现、通过 AgentFacts 的加密可验证能力证明，以及跨 Anthropic 的 Modal Context Protocol (MCP)、Google 的 Agent-to-Agent (A2A)、Microsoft 的 NLWeb 和标准 HTTPS 通信的跨协议互操作性。NANDA 实现了零信任代理访问 (ZTAA) 原则，扩展了传统的零信任网络访问 (ZTNA)，以解决自主代理安全挑战，包括能力欺骗、身份模拟攻击和敏感数据泄露。该框架定义了代理可见性和控制 (AVC) 机制，使企业能够在保持操作自主性和合规性的同时进行治理。我们的方法将孤立的 AI 代理转变为一个可验证、可信的智能服务的互联生态系统，为跨企业和消费者环境的大规模自主代理部署奠定了基础。这项工作解决了当前 AI 代理能力与安全、可扩展、多代理协作的基础设施要求之间的关键差距，为下一代自主智能系统奠定了基础。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csos'></a>
## cs.OS 

### [292] [AgentSight: System-Level Observability for AI Agents Using eBPF](https://arxiv.org/abs/2508.02736)
> *AgentSight：使用eBPF实现AI代理的系统级可观测性*

*Yusheng Zheng, Yanpeng Hu, Tong Yu, Andi Quinn* | **Category: cs.OS, cs.SE** | **Updated: 2025-08-02**

**Keywords:** AI代理, 可观测性, eBPF, 边界追踪, 语义鸿沟

**Comment:** 

> **TL;DR:** AgentSight是一个使用eBPF进行边界追踪的AgentOps可观测性框架，它通过关联LLM意图和系统级操作来弥合语义鸿沟，从而实现对AI代理的有效监控和调试。

**AI_Comments:** AgentSight的创新之处在于其采用eBPF进行“边界追踪”的方法，实现了对AI代理的系统级可观测性，有效弥合了高级意图与低级操作之间的语义鸿沟。这种无需插桩的设计使其具有高度的实用性和适应性，尤其在LLM代理快速迭代的环境中显得尤为重要。其能够检测恶意攻击和性能瓶颈的能力，对于保障AI系统安全和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代软件基础设施日益依赖LLM代理，但这些AI代理与传统确定性软件不同，给传统监控和调试带来了巨大挑战。现有工具无法关联代理的高级意图和低级操作，导致难以区分良性操作、恶意攻击和代价高昂的故障。

**Method:** AgentSight采用混合方法，即边界追踪，在应用程序代码外部、通过稳定的系统接口使用eBPF监控代理。它拦截TLS加密的LLM流量以提取语义意图，监控内核事件以观察系统范围的影响，并使用实时引擎和二次LLM分析跨进程边界因果关联这两个流。这是一种无需插桩的技术，与框架无关，对API快速变化具有弹性。

**Result:** AgentSight能够检测提示注入攻击，识别浪费资源的推理循环，并揭示多代理系统中隐藏的协调瓶颈。其性能开销低于3%。

**Conclusion:** AgentSight通过创新性的边界追踪方法，有效解决了AI代理监控和调试中的语义鸿沟问题，提供了对代理行为的全面可观测性，并证明了其在检测异常和优化多代理系统方面的有效性。

> **ai_Abstract:** AgentSight是一个创新的AgentOps可观测性框架，旨在解决AI代理监控和调试中的“语义鸿沟”问题。它通过使用eBPF进行边界追踪，从系统层面而非应用内部，关联LLM代理的高级意图（通过拦截加密流量）和低级系统操作（通过监控内核事件）。这种无插桩的方法具有框架无关性、对API变化的高弹性，且性能开销低。实验证明，AgentSight能有效检测提示注入攻击、识别资源浪费的推理循环，并揭示多代理系统的协调瓶颈。

> **摘要翻译:** 现代软件基础设施日益依赖LLM代理进行开发和维护，例如Claude Code和Gemini-cli。然而，这些AI代理与传统的确定性软件根本不同，这对传统的监控和调试提出了重大挑战。这造成了一个关键的语义鸿沟：现有工具要么观察代理的高级意图（通过LLM提示），要么观察其低级操作（例如系统调用），但无法关联这两种视图。这种盲点使得区分良性操作、恶意攻击和代价高昂的故障变得困难。我们引入了AgentSight，一个AgentOps可观测性框架，它使用混合方法弥合了这一语义鸿沟。我们的方法，即边界追踪，通过使用eBPF在稳定的系统接口处从应用程序代码外部监控代理。AgentSight拦截TLS加密的LLM流量以提取语义意图，监控内核事件以观察系统范围的影响，并使用实时引擎和二次LLM分析跨进程边界因果关联这两个流。这种无需插桩的技术与框架无关，对API快速变化具有弹性，并且性能开销低于3%。我们的评估表明，AgentSight能够检测提示注入攻击，识别浪费资源的推理循环，并揭示多代理系统中隐藏的协调瓶颈。AgentSight已作为开源项目在https://github.com/agent-sight/agentsight 发布。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

### [327] [MaLV-OS: Rethinking the Operating System Architecture for Machine Learning in Virtualized Clouds](https://arxiv.org/abs/2508.03676)
> *MaLV-OS：重新思考虚拟化云中机器学习的操作系统架构*

*Stella Bitchebe, Oana Balmau* | **Category: cs.OS, cs.LG** | **Updated: 2025-08-05**

**Keywords:** MaLV-OS, 机器学习, 操作系统, 虚拟化云, MLaaS

**Comment:** 

> **TL;DR:** MaLV-OS提出了一种专门为机器学习工作负载设计的操作系统架构，旨在通过操作系统来提升机器学习模型的性能，尤其是在虚拟化云环境中。

**AI_Comments:** 该论文的创新点在于其“反向”思维：不再是机器学习赋能操作系统，而是操作系统为机器学习服务。这种专门为机器学习工作负载定制操作系统的方法，特别是在虚拟化云环境中，具有重要的理论和实践意义。它解决了现有系统在处理机器学习任务时缺乏特定优化的问题，有望显著提升机器学习应用的效率和性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究多利用机器学习改进操作系统决策。然而，目前还没有工作采取相反方向，即利用操作系统来改进机器学习。尽管一些工作提出了系统级优化，但它们并未针对机器学习上下文定制操作系统。本研究旨在通过定制操作系统来解决这一局限性，以增强机器学习模型的性能。

**Method:** MaLV-OS通过重新设计操作系统架构来实现其目标。其设想的架构包括：(1) 一个微内核Micro-LAKE，允许内核空间应用程序使用GPU；(2) 一个MLaaS（机器学习即服务）子系统，用于帮助Micro-LAKE进行内存管理和CPU调度。MaLV-OS还旨在将模型中系统敏感的部分卸载到操作系统，以减轻模型复杂性和编程，并加速执行。此外，它将开源GPU虚拟化软件直接集成到管理程序中，并允许虚拟机动态选择MLaaS策略。

**Result:** Not mentioned in abstract

**Conclusion:** MaLV-OS的愿景是使虚拟机能够动态选择MLaaS策略以提升用户运行模型的性能，并且由于MLaaS被设计为可加载的内核模块，MaLV-OS架构能够动态地向MLaaS子系统添加新功能。

> **ai_Abstract:** 该论文提出了MaLV-OS，一个为虚拟化云中机器学习工作负载量身定制的新型操作系统架构。与现有利用机器学习优化操作系统的研究不同，MaLV-OS旨在通过重新设计操作系统来提升机器学习模型的性能。其核心组件包括一个支持GPU访问的微内核Micro-LAKE和一个用于资源管理及调度的MLaaS子系统。此外，MaLV-OS通过将模型部分卸载到操作系统、集成GPU虚拟化，并允许动态选择MLaaS策略来简化模型复杂性并加速执行。

> **摘要翻译:** 大量研究已采用机器学习（ML）模型来开发学习型操作系统（OS）和内核。后者动态适应作业负载并动态调整资源（CPU、IO、内存、网络带宽）分配以响应实际用户需求。这些工作的共同点是利用ML改进内核决策。迄今为止，据我们所知，还没有工作采取相反的方向，即利用OS改进ML。虽然有些工作提出将系统级优化应用于ML算法，但它们并未根据ML上下文定制OS。为了解决这一局限性，本文采取了一种正交方法，利用OS来增强ML模型和算法的性能。我们探索了通向ML专用OS——MaLV-OS的路径。MaLV-OS重新思考了OS架构，使其专门为ML工作负载量身定制，尤其是在现在广泛用于运行ML应用程序的虚拟化云中。MaLV-OS设想的架构包括（1）一个微内核Micro-LAKE，它允许内核空间应用程序使用GPU，以及（2）一个MLaaS（ML即服务）子系统，它收集ML模型以帮助Micro-LAKE进行内存管理和CPU调度。MaLV-OS架构还将模型中系统敏感的部分卸载到OS，以减轻模型复杂性和编程，并加速其执行。最后，MaLV-OS集成了一个开源GPU虚拟化软件，直接合并到管理程序中。为了更大的灵活性，MaLV-OS的愿景是使虚拟机能够动态选择可以提高用户正在运行模型性能的MLaaS策略。因为MLaaS被设计为可加载的内核模块，MaLV-OS架构能够动态地向MLaaS子系统添加新功能。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

<a id='cspf'></a>
## cs.PF 

### [946] [A Novel Hybrid Optical and STAR IRS System for NTN Communications](https://arxiv.org/abs/2508.03147)
> *一种用于非地面网络的混合光学和STAR IRS新颖系统*

*Shunyuan Shang, Emna Zedini, Abla Kammoun, Mohamed-Slim Alouini* | **Category: cs.PF, cs.IT, math.IT** | **Updated: 2025-08-05**

**Keywords:** 非地面网络, 光学智能反射面, STAR-IRS, 自由空间光, 射频

**Comment:** 

> **TL;DR:** 本论文提出了一种结合光学智能反射面（OIRS）和同步传输反射智能反射面（STAR-IRS）的新型非地面网络（NTN）系统，以应对下一代通信网络中的关键挑战。该系统模型利用安装在高空平台（HAP）上的水平OIRS，将信号从光学地面站（OGS）传输到地球站（ES）。ES使用具有固定增益的放大转发（AF）中继进行信号中继，然后通过安装在建筑物上的垂直STAR-IRS传输，以便与室内外用户进行通信。自由空间光（FSO）链路采用了多输入多输出（MIMO）技术，并且本文为OIRS单元数量超过一个的场景开发了专门的信道模型。对于射频（RF）链路，引入了一种新颖且高度精确的近似方法，与基于中心极限定理（CLT）的传统方法相比，具有更高的准确性。推导了该新型五跳系统中关键性能指标（包括中断概率（OP）、遍历容量和平均比特误差率（BER））的Fox-H二元函数闭式解析表达式。还提出了高信噪比下的渐近表达式，以揭示系统分集阶数。

**AI_Comments:** 该研究提出了一种创新的混合NTN系统，结合了OIRS和STAR-IRS技术，以解决下一代通信网络中的挑战。通过开发精确的信道模型和推导闭式解析表达式，为理解和优化此类系统性能提供了重要贡献。然而，实际部署的复杂性和成本可能是一个限制因素。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对下一代通信网络中的关键挑战，集成光学智能反射面（OIRS）和同步传输反射智能反射面（STAR-IRS）。

**Method:** 提出了一种结合OIRS和STAR-IRS的新型NTN系统模型。该模型包括从OGS到ES的FSO链路（使用OIRS和MIMO），以及ES到用户的RF链路（使用STAR-IRS）。开发了OIRS单元数量超过一个的信道模型，并提出了一种用于RF链路的新型精确近似方法。推导了关键性能指标（OP、遍历容量、BER）的闭式解析表达式（基于Fox-H二元函数）和高信噪比下的渐近表达式。

**Result:** 推导了新型五跳系统中关键性能指标（OP、遍历容量、BER）的闭式解析表达式，并提供了高信噪比下的渐近表达式。

**Conclusion:** 本论文提出并分析了一种集成了OIRS和STAR-IRS的新型NTN系统，通过精确的信道建模和性能指标推导，为未来通信网络提供了有前景的解决方案。

> **ai_Abstract:** 本论文提出了一种集成了光学智能反射面（OIRS）和同步传输反射智能反射面（STAR-IRS）的新型非地面网络（NTN）系统。该系统通过自由空间光（FSO）链路和射频（RF）链路实现通信，并针对特定场景开发了信道模型和精确的近似方法。研究推导了系统的关键性能指标，并提供了高信噪比下的分析。

> **摘要翻译:** 本论文提出了一种新颖的非地面网络（NTN）系统，该系统集成了光学智能反射面（OIRS）和同步传输与反射智能反射面（STAR-IRS），以应对下一代通信网络中的关键挑战。所提出的系统模型包括一个信号从光学地面站（OGS）通过安装在平流层平台（HAP）上的水平OIRS传输到地球站（ES）。ES使用具有固定增益的放大转发（AF）中继进行信号中继，然后通过安装在建筑物上的垂直STAR-IRS传输，以便与室内外用户进行通信。自由空间光（FSO）链路采用了（多输入多输出）MIMO技术，并且本文开发了一个专门针对OIRS单元数量超过一个的场景设计的信道模型。对于射频（RF）链路，引入了一种新颖且高度精确的近似方法，与基于中心极限定理（CLT）的传统方法相比，具有更高的准确性。针对这种新颖的五跳系统，推导了中断概率（OP）、遍历容量和平均比特错误率（BER）等关键性能指标的Fox-H二元函数闭式解析表达式。还提出了高信噪比下的渐近表达式，以提供对系统分集阶数的见解。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [552] [Compositional Quantum Control Flow with Efficient Compilation in Qunity](https://arxiv.org/abs/2508.02857)
> *Qunity中带有高效编译的组合式量子控制流*

*Mikhail Mints, Finn Voichick, Leonidas Lampropoulos, Robert Rand* | **Category: cs.PL, quant-ph** | **Updated: 2025-08-04**

**Keywords:** 量子控制流, Qunity, 编译器, 量子编程语言, 优化

**Comment:** 88 pages, 30 figures

> **TL;DR:** 本文实现了Qunity语言的编译器，并开发了优化技术，显著提高了高层量子控制流的编译效率，减少了量子比特和门的使用。

**AI_Comments:** 本文的创新点在于成功实现了Qunity语言的编译器，并针对其原始设计中存在的编译效率低下问题提出了有效的解决方案。通过引入新的抽象和多阶段优化技术，极大地提升了量子控制流编译的效率，使得Qunity作为一种高级量子编程语言更具实用价值。这项工作对于推动高级量子编程语言的发展和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有量子编程语言多基于量子电路模型，高层抽象（特别是量子控制流）难以实现。Qunity语言虽然提供了量子控制流抽象，但缺乏工作实现，且其原始编译过程效率低下，导致生成的电路过大。

**Method:** 以Qunity为起点，专注于高层量子控制流构造的有效编译。引入了更广泛的抽象，并创建了完整的Qunity编译器，将Qunity高级代码转换为OpenQASM 3。开发了多阶段优化技术，包括低层电路优化和考虑Qunity程序高层结构的方法。

**Result:** 通过优化，编译器使用的量子比特和门数量大大减少。

**Conclusion:** 本文成功实现了Qunity编译器并开发了高效的编译优化技术，解决了Qunity在实际应用中的效率问题，使得高层量子控制流的实现更加可行和高效。

> **ai_Abstract:** 本文解决了Qunity语言在量子控制流编译方面存在的效率和实现问题。作者们以Qunity为基础，引入了新的高级抽象，并开发了一个完整的Qunity编译器，能够将高级Qunity代码高效地转换为OpenQASM 3。通过在编译过程的多个阶段应用优化技术，包括低层电路优化和高层结构优化，显著减少了编译后电路所需的量子比特和门数量，从而提高了Qunity的实用性和编译效率。

> **摘要翻译:** 大多数现有的量子编程语言都基于量子电路计算模型，因为高级抽象特别难以实现——尤其是与量子控制流相关的抽象。Voichick等人提出的Qunity语言以量子控制构造的形式提供了这种抽象，并精心确保了所产生的语言仍然是可实现的。然而，Qunity缺乏一个可工作的实现，并且最初提出的编译过程效率非常低，即使简单的量子算法也会编译成不合理的大电路。

在这项工作中，我们以Qunity为起点，专注于高级量子控制流构造的有效编译。我们在Qunity的核心语言之上引入了更广泛的抽象，与现有控制构造相比，这些抽象提供了引人注目的权衡。我们创建了一个完整的Qunity编译器实现，它将高级Qunity代码转换为量子汇编语言OpenQASM 3。我们为Qunity编译过程的多个阶段开发了优化技术，包括低层电路优化以及考虑Qunity程序高层结构的方法，大大减少了编译器使用的量子比特和门的数量。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [586] [SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation](https://arxiv.org/abs/2508.03558)
> *SAGE-HLS：语法感知型 AST 引导的用于高层综合代码生成的 LLM*

*M Zafir Sadik Khan, Nowfel Mashnoor, Mohammad Akyash, Kimia Azar, Hadi Kamali* | **Category: cs.PL** | **Updated: 2025-08-05**

**Keywords:** 高层综合, 大型语言模型, 代码生成, 抽象语法树, EDA

**Comment:** Accepted to the IEEE International Conference on Computer Design
  (ICCD 2025)

> **TL;DR:** SAGE-HLS 是首个针对高层综合 (HLS) 代码生成进行微调的大型语言模型 (LLM)。它通过将 Verilog 代码转换为 C/C++ 来创建数据集，并使用基于抽象语法树 (AST) 的指令提示进行微调。实验表明，SAGE-HLS 在代码可综合性和功能正确性方面取得了很高的成功率。

**AI_Comments:** SAGE-HLS 在解决 HLS 代码生成的数据稀疏性问题方面取得了重大进展，其 AST 引导的微调方法具有创新性。然而，75% 的功能正确性成功率表明仍有改进空间，未来研究可以关注提高生成代码的功能保真度。此外，数据集的规模和多样性对于模型的泛化能力也至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 高层综合 (HLS) 在自动化硬件设计方面至关重要，但在设计空间探索和优化方面面临挑战。尽管 LLM 在代码生成方面表现出色，但由于缺乏 HLS 代码数据集，其在该领域的应用受到限制。

**Method:** SAGE-HLS 的方法包括：1) 通过 Verilog 到 C/C++ 移植创建包含 16.7K HLS 代码的数据集；2) 采用基于抽象语法树 (AST) 引导的指令提示微调策略；3) 开发使用 VerilogEval 的半自动化评估框架来评估生成代码的功能。

**Result:** 在 QwenCoder (2.5) 7B 模型上微调的 SAGE-HLS 在代码可综合性方面达到了近 100% 的成功率，在功能正确性方面达到了 75% 的成功率。

**Conclusion:** SAGE-HLS 是一个专门为 HLS 代码生成设计的微调 LLM，通过其独特的数据集创建和 AST 引导的微调策略，在代码可综合性和功能正确性方面取得了显著成果，为 HLS 自动化开辟了新途径。

> **ai_Abstract:** 本文提出了 SAGE-HLS，一个针对高层综合 (HLS) 代码生成进行微调的首创 LLM。该模型通过 Verilog 到 C/C++ 代码转换创建了一个包含 16.7K HLS 代码的数据集，并采用基于抽象语法树 (AST) 引导的指令提示微调策略。使用 VerilogEval 进行的评估显示，SAGE-HLS 在代码可综合性和功能正确性方面取得了优异的成果。

> **摘要翻译:** 在当今快速发展的电子设计自动化 (EDA) 领域，硬件设计的复杂性不断增加，这需要更复杂的自动化解决方案。高层综合 (HLS) 作为一种关键解决方案，可以自动执行从高级抽象（例如 C/C++）到硬件设计。然而，它面临着重大挑战，尤其是在设计空间探索和优化方面。虽然大型语言模型 (LLM) 在代码生成方面表现出卓越的能力，但由于（公开）可用的 HLS 代码数据集稀少，其在 HLS 领域的应用受到限制。因此，该领域的研究主要集中在提示工程和检索增强生成 (RAG) 等技术上。为了克服这一限制，本文介绍了 SAGE-HLS，这是首个专门为 HLS 代码生成进行微调的 LLM。我们的方法包括三项关键进展：(i) 我们实现了 Verilog 到 C/C++ 的移植，将经过验证且可综合的 Verilog 代码转换为相应的 C 代码，创建了一个包含 16.7K HLS 代码的数据集；(ii) 我们实现了一种基于指令提示的代码生成微调策略，该策略由抽象语法树 (AST) 引导；(iii) 我们开发了一个使用 VerilogEval 的半自动化评估框架，以评估生成 HLS 代码的功能。我们的实验表明，在 QwenCoder (2.5) 7B 模型上进行微调的 SAGE-HLS 在代码可综合性方面取得了近 100% 的成功率，在功能正确性方面取得了 75% 的成功率。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [619] [Teaching Introductory Functional Programming Using Haskelite](https://arxiv.org/abs/2508.03640)
> *使用Haskelite教授函数式编程入门*

*Pedro Vasconcelos* | **Category: cs.PL, D.3.2;D.3.4;K.3.1** | **Updated: 2025-08-05**

**Keywords:** 函数式编程, Haskelite, 逐步解释器, 教学经验, Haskell

**Comment:** In Proceedings TFPiE 2025, arXiv:2508.02305

> **TL;DR:** 本文报告了在葡萄牙波尔图大学的入门函数式编程课程中使用Haskelite（一个Haskell子集的逐步跟踪解释器）的经验，旨在帮助学生克服在函数式编程中应用基于替换的计算模型的困难。

**AI_Comments:** 本文的创新点在于实践性地探索了特定工具（Haskelite）在解决函数式编程初学者常见困难方面的有效性。其重要性体现在为教育者提供了关于如何利用逐步解释器改进教学的实际经验和学生反馈。局限性在于这只是一个经验报告，缺乏严格的实验设计和量化数据来证明其效果。

<details>
  <summary>Details</summary>

**Motivation:** 学生在学习函数式编程时，尽管替换是高中代数中的熟悉概念，但他们难以将其应用于递归定义、代数数据类型和高阶函数等新环境。逐步解释器已被证明有助于初学者澄清误解和提高理解，因此本文旨在报告使用这种工具的经验。

**Method:** 本文报告了在葡萄牙波尔图大学教授入门函数式编程课程时，使用一个针对Haskell子集的逐步跟踪解释器Haskelite的经验。作者描述了解释器的使用情况，并呈现了从学生那里获得的一些反馈。

**Result:** 结果是报告了使用解释器的经验，呈现了从学生那里获得的一些反馈，并反思了所学到的经验教训。

**Conclusion:** 本文反思了在教学中使用逐步跟踪解释器Haskelite所学到的经验教训，并指出了未来工作的方向。虽然没有明确的“结论”部分，但这是从摘要中推断出的最终目的。

> **ai_Abstract:** 本文探讨了在入门函数式编程课程中使用Haskelite（一个Haskell子集的逐步跟踪解释器）的经验。鉴于学生在将替换概念应用于函数式编程的复杂结构时面临的挑战，逐步解释器被认为是有效的辅助工具。作者报告了在葡萄牙波尔图大学的教学经验，分享了Haskelite的使用方法、学生反馈以及从中吸取的教训，并展望了未来的工作方向。

> **摘要翻译:** 学习函数式编程需要学习一种基于替换的计算模型。虽然替换在高中代数中应该是一个熟悉的概念，但学生们在将其应用于新环境时常常遇到困难，例如递归定义、代数数据类型和高阶函数。逐步解释器已被证明可以通过澄清误解和提高理解来帮助初学者。
本文报告了在波尔图大学教授入门函数式编程课程时，使用一个针对Haskell子集的逐步跟踪解释器Haskelite的经验。我们描述了解释器的使用，呈现了从学生那里获得的一些反馈，反思了所学到的经验教训，并指出了未来工作的方向。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [12] [DriveSOTIF: Advancing Perception SOTIF Through Multimodal Large Language Models](https://arxiv.org/abs/2505.07084)
> *DriveSOTIF：通过多模态大型语言模型推进感知SOTIF*

*Shucheng Huang, Freda Shi, Chen Sun, Jiaming Zhong, Minghao Ning, Yufeng Yang, Yukun Lu, Hong Wang, Amir Khajepour* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 感知SOTIF, 多模态大型语言模型, 自动驾驶, 预期功能安全, VQA

**Comment:** This work has been submitted to the IEEE for possible publication. V2
  of the manuscript, submitted to IEEE-TVT;

> **TL;DR:** 本文提出通过在定制数据集上微调多模态大型语言模型（MLLMs），以提升自动驾驶中感知SOTIF（预期功能安全）能力，并在VQA任务中取得了显著性能提升。

**AI_Comments:** 这项工作具有创新性，因为它首次将领域特定的多模态大型语言模型微调应用于自动驾驶的SOTIF（预期功能安全）领域，填补了自动驾驶车辆在复杂感知风险管理方面的空白。其通过定制数据集和MLLM微调的方法，有效提升了车辆识别和应对潜在危险的能力，对提高自动驾驶系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆缺乏人类驾驶员的空间和因果智能，导致在复杂或不可预测的驾驶条件下，感知相关的预期功能安全（SOTIF）风险难以管理。

**Method:** 通过在专门设计用于捕获感知相关SOTIF场景的定制数据集上微调多模态大型语言模型（MLLMs）。

**Result:** 微调后的MLLMs在封闭式VQA准确率上提高了11.8%，在开放式VQA分数上提高了12.0%，同时保持了0.59秒的平均推理时间，实现了实时性能。通过加拿大和中国的实际案例研究验证了该方法，模型能够正确识别甚至对经验丰富的人类驾驶员也构成挑战的安全风险。

**Conclusion:** 通过对多模态大型语言模型进行领域特定微调，可以有效提升自动驾驶车辆在复杂场景下感知SOTIF的能力，从而更好地管理感知相关的安全风险。

> **ai_Abstract:** 本文提出了一种新颖的自动驾驶感知SOTIF风险管理方法，即在专门构建的感知SOTIF数据集上微调多模态大型语言模型（MLLMs）。实验结果表明，该方法显著提升了模型在VQA任务上的性能，并在实际场景中成功识别了复杂安全风险，首次将领域特定MLLM微调应用于自动驾驶SOTIF领域。

> **摘要翻译:** 人类驾驶员拥有空间和因果智能，使他们能够感知驾驶场景、预测危险并对动态环境做出反应。相比之下，自动驾驶车辆缺乏这些能力，这使得管理感知相关的预期功能安全（SOTIF）风险变得具有挑战性，尤其是在复杂或不可预测的驾驶条件下。为了弥补这一差距，我们提出在专门设计用于捕获感知相关SOTIF场景的定制数据集上微调多模态大型语言模型（MLLMs）。基准测试结果表明，与基线模型相比，微调后的MLLMs在封闭式VQA准确率上提高了11.8%，在开放式VQA分数上提高了12.0%，同时保持了实时性能，平均每张图像推理时间为0.59秒。我们通过在加拿大和中国的实际案例研究验证了我们的方法，微调后的模型能够正确识别甚至对经验丰富的人类驾驶员也构成挑战的安全风险。这项工作代表了领域特定MLLM微调在自动驾驶SOTIF领域中的首次应用。数据集和相关资源可在 github.com/s95huang/DriveSOTIF.git 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [30] [Multimodal Human-Intent Modeling for Contextual Robot-to-Human Handovers of Arbitrary Objects](https://arxiv.org/abs/2508.02982)
> *任意物体情境下机器人对人递送的多模态人类意图建模*

*Lucas Chen, Guna Avula, Hanwen Ren, Zixing Wang, Ahmed H. Qureshi* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 机器人递送,多模态意图建模,人机交互,物体抓取,人类偏好

**Comment:** 

> **TL;DR:** 本文提出了一种统一的多模态方法，通过理解人类的隐性和显性偏好，实现机器人对任意物体的递送，解决了现有方法在目标选择和抓取方式上的局限性。

**AI_Comments:** 该论文的创新之处在于其统一的多模态方法，它不仅考虑了目标物体的选择，还深入到理解人类在抓取和递送过程中的隐性和显性偏好，这对于实现真正自然和流畅的人机交互至关重要。其对“任意物体”的处理能力扩展了现有系统的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人机物体递送方法依赖于预选目标物体，并且没有结合人类在递送过程中的隐含和显性偏好，这限制了人机之间自然流畅的互动。这些偏好可能与从杂乱环境中选择目标物体以及机器人应如何抓取选定物体以方便人类在递送过程中进行理想抓取有关。

**Method:** 本文提出了一种统一的方法，该方法使用人类的口头和非口头指令来选择远距离目标物体，并通过情境化人类的隐性和显性偏好来生成机器人抓取和柔顺递送运动序列，从而执行递送操作。

**Result:** 通过真实世界实验和用户研究，评估了所提出的集成框架及其组件在处理任意日常物体递送任务方面的有效性，结果表明该方法在理解人类偏好方面表现出色。

**Conclusion:** 本文提出的统一多模态方法能够有效地处理任意物体的机器人对人递送任务，通过理解人类的隐性和显性偏好，实现了更自然和流畅的人机交互。

> **ai_Abstract:** 本文提出了一种用于机器人对人递送任意物体的多模态统一方法。该方法旨在解决现有递送系统无法理解人类隐性和显性偏好的局限性，通过整合人类的口头和非口头指令来选择目标物体，并生成考虑人类抓取偏好的机器人抓取和递送动作。通过真实世界实验和用户研究，验证了该框架在理解人类偏好并有效执行物体递送任务方面的有效性。

> **摘要翻译:** 人机物体递送是辅助机器人帮助人们日常生活（包括老年护理、医院和工厂车间）的关键要素。现有解决这些任务的方法依赖于预选目标物体，并且没有情境化人类在递送过程中的隐性和显性偏好，这限制了人机之间自然流畅的互动。这些偏好可能与从杂乱环境中选择目标物体以及机器人应如何抓取选定物体以方便人类在递送过程中进行理想抓取有关。因此，本文提出了一种统一的方法，该方法使用人类的口头和非口头指令来选择远距离目标物体，并通过情境化人类的隐性和显性偏好来生成机器人抓取和柔顺递送运动序列，从而执行递送操作。我们通过真实世界实验和使用任意日常物品的用户研究评估了我们的集成框架及其组件。这些评估的结果证明了我们提出的管道在通过理解人类偏好来处理物体递送任务方面的有效性。我们的演示视频可以在 https://youtu.be/6z27B2INl-s 找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [55] [Rethink Repeatable Measures of Robot Performance with Statistical Query](https://arxiv.org/abs/2505.08216)
> *重新思考基于统计查询的机器人性能可重复测量*

*Bowen Weng, Linda Capito, Guillermo A. Castillo, Dylan Khor* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 机器人性能, 可重复性, 统计查询, 算法测试, 标准化评估

**Comment:** 

> **TL;DR:** 本研究提出了一种轻量级、参数化、自适应的统计查询（SQ）算法修改方案，旨在提高机器人性能测试的可重复性，并保证准确性和效率，适用于机械臂、自动驾驶车辆和人形机器人等多种应用场景。

**AI_Comments:** 这项研究的创新之处在于它直接解决了机器人性能评估中一个关键但日益严峻的挑战——算法层面的可重复性。通过修改统计查询算法，它提供了一个理论上可证明且实践中有效的解决方案，这对于确保机器人测试结果的可靠性和标准化至关重要。其方法的普适性，能够应用于不同采样技术和多种机器人应用场景，也显示出其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人性能的标准化测试中，可重复性是一个关键属性，但随着组件变得更复杂、智能、多样化和随机化，实现可重复测试变得越来越困难。现有工作解决了伦理、硬件和程序层面的可重复性，但算法层面的可重复性仍是挑战。

**Method:** 本研究针对标准化评估中广泛采用的统计查询（SQ）算法，提出了一种轻量级、参数化、自适应的修改方案。该方案适用于基于蒙特卡洛采样、重要性采样或自适应重要性采样的任何SQ例程，使其具有可证明的可重复性，并保证准确性和效率。

**Result:** 所提出的方法在三个代表性场景中展示了其有效性：(i) 机械臂的标准化测试，(ii) 自动驾驶车辆操作风险评估的智能测试算法，以及 (iii) 人形机器人在运动任务中命令跟踪性能评估的新兴用例。

**Conclusion:** 通过对统计查询算法进行修改，本研究成功地在算法层面提高了机器人性能测试的可重复性，并提供了准确性和效率的保证，从而解决了复杂随机系统中可重复性测试的挑战。

> **ai_Abstract:** 本研究致力于解决机器人性能测试中可重复性面临的日益严峻的挑战，尤其是在算法层面。针对广泛使用的统计查询（SQ）算法，论文提出了一种创新性的、轻量级、参数化且自适应的修改方法。该方法能够使任何SQ例程，无论其采样基础如何，都实现可证明的可重复性，并对准确性和效率提供严格的保证。通过在机械臂测试、自动驾驶车辆风险评估以及人形机器人命令跟踪性能评估等多个代表性应用场景中的验证，该研究成功展示了其方案的有效性。

> **摘要翻译:** 对于旨在评估机器人特定性能方面的通用标准化测试算法，通常会施加几个关键期望。除了准确性（即与通常未知的真实参考的接近程度）和效率（即在可接受的测试成本和设备限制内的可行性）之外，一个特别重要的属性是可重复性。可重复性是指当不同利益相关者在不同时间或地点对同一机器人执行相似的测试算法时，能够始终获得相同的测试结果。然而，随着所涉及的组件变得越来越复杂、智能、多样化，最重要的是随机性，实现可重复性测试变得越来越具有挑战性。虽然相关工作在伦理、硬件和程序层面解决了可重复性问题，但本研究专门关注算法层面的可重复性测试。具体来说，我们针对标准化评估中广泛采用的一类测试算法：统计查询（SQ）算法（即使用采样数据估计分布上有界函数的期望值的算法）。我们提出了一种轻量级、参数化且自适应的修改方案，适用于任何SQ例程，无论是基于蒙特卡洛采样、重要性采样还是自适应重要性采样，使其具有可证明的可重复性，并保证准确性和效率的界限。我们证明了所提出方法在三个代表性场景中的有效性：(i) 机械臂的既定和广泛采用的标准化测试，(ii) 自动驾驶车辆操作风险评估的新兴智能测试算法，以及 (iii) 涉及人形机器人在运动任务中命令跟踪性能评估的开发用例。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [62] [Estimation of Aerodynamics Forces in Dynamic Morphing Wing Flight](https://arxiv.org/abs/2508.02984)
> *动态变形机翼飞行中气动力的估计*

*Bibek Gupta, Mintae Kim, Albert Park, Eric Sihite, Koushil Sreenath, Alireza Ramezani* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 气动力估计, 动态变形机翼, 扑翼机器人, 哈密顿力学, 神经网络

**Comment:** 

> **TL;DR:** 本文研究了两种估算动态变形扑翼飞行机器人气动力的独立方法：一种基于哈密顿力学的物理模型观察器，另一种是基于多层感知器的神经网络回归模型。两种方法在测量三个力分量时表现出良好的一致性。

**AI_Comments:** 这篇论文通过比较物理模型和数据驱动模型在动态变形扑翼机器人气动力估计上的表现，提供了一个全面的分析。其创新之处在于结合了无需训练数据的物理观察器与基于MLP的回归模型，并验证了它们的一致性。研究结果对于推进扑翼机器人的闭环控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确估计气动力对于推进动态变形扑翼飞行机器人的控制、建模和设计至关重要。研究目标是在系留飞行中量化气动力贡献，这是实现闭环飞行控制的关键一步。

**Method:** 本文在仿生扑翼平台Aerobat上研究了两种力估计方法。第一种是基于哈密顿力学的物理观察器，利用共轭动量推断外部气动力，无需训练数据。第二种是基于多层感知器（MLP）的神经网络回归模型，通过学习关节运动学、扑翼频率和环境参数到气动力输出的映射。两种估计器均使用六轴力传感器在高频数据采集装置中进行评估。

**Result:** 共轭动量观察器和回归模型在三个力分量（Fx、Fy、Fz）上表现出高度一致性。

**Conclusion:** 两种不同的气动力估计方法（物理模型观察器和神经网络回归模型）在动态变形扑翼飞行机器人上均能有效且一致地估算气动力，为未来的闭环飞行控制奠定了基础。

> **ai_Abstract:** 本文研究了动态变形扑翼飞行机器人气动力估计的两种方法。一种是基于哈密顿力学的物理观察器，利用共轭动量在无需训练数据的情况下推断气动力；另一种是基于多层感知器（MLP）的神经网络回归模型，通过学习运动学、频率和环境参数来预测气动力。两种方法均在仿生平台Aerobat上通过六轴力传感器进行评估，结果显示在三个力分量上具有良好的一致性，这对于实现闭环飞行控制至关重要。

> **摘要翻译:** 准确估计气动力对于推进具有动态变形能力的扑翼飞行机器人的控制、建模和设计至关重要。在本文中，我们研究了两种不同的气动力估计方法，应用于Aerobat平台，这是一个受生物启发设计的扑翼平台，旨在模拟蝙蝠飞行中观察到的惯性和气动行为。我们的目标是在系留飞行中量化气动力贡献，这是实现闭环飞行控制的关键一步。第一种方法是基于哈密顿力学的物理观察器，它利用共轭动量的概念来推断作用在机器人上的外部气动力。该观察器建立在系统的降阶动态模型之上，并利用实时传感器数据来估计力，而无需训练数据。第二种方法采用基于神经网络的回归模型，特别是多层感知器（MLP），以学习从关节运动学、扑翼频率和环境参数到气动力输出的映射。我们使用六轴力传感器在高频数据采集装置中评估了这两种估计器，该装置能够在周期性拍打翅膀期间实现精细的力测量。共轭动量观察器和回归模型在三个力分量（Fx、Fy、Fz）上表现出高度一致性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [94] [Thruster-Enhanced Locomotion: A Decoupled Model Predictive Control with Learned Contact Residuals](https://arxiv.org/abs/2508.03003)
> *推进器增强型运动：一种基于学习接触残差的解耦模型预测控制*

*Chenghao Wang, Alireza Ramezani* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 推进器增强运动, 解耦控制, 模型预测控制, 接触残差动力学, Husky Carbon

**Comment:** 

> **TL;DR:** 为解决轻型致动器带宽限制，本文提出一种解耦控制架构，结合位置控制和带学习接触残差的MPC，实现推进器辅助的稳定机器人运动。

**AI_Comments:** 该研究通过提出解耦控制架构和引入学习接触残差动力学，巧妙地解决了轻量级机器人执行器带宽不足的问题，为推进器辅助的混合运动控制提供了创新思路，提高了机器人在复杂环境下的稳定性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统统一模型预测控制（MPC）框架在控制Husky Carbon机器人时，受限于系统轻量级致动器较低的扭矩控制带宽，难以有效优化地面反作用力和推进器力，限制了其可行性。

**Method:** 本文提出了一种解耦控制架构：一个Raibert型控制器使用基于位置的控制来管理腿部运动，而另一个模型预测控制（MPC）则通过学习到的接触残差动力学（CRD）来调节推进器，以解释腿地冲击。这种方法旨在绕过扭矩控制速率瓶颈，同时使推进器MPC能够明确考虑腿地冲击动力学。

**Result:** 通过仿真和硬件实验验证了该方法，结果表明，与没有接触残差动力学（CRD）的解耦控制器相比，带有CRD的解耦控制架构在推力恢复和猫步姿态方面表现出更稳定的行为。

**Conclusion:** 带有学习接触残差动力学的解耦控制架构，能够有效解决轻型机器人执行器带宽限制，实现更稳定的推进器增强型腿足运动。

> **ai_Abstract:** 本文针对东北大学的Husky Carbon机器人，提出了一种解耦控制架构，以克服传统统一模型预测控制（MPC）在轻量级执行器低扭矩控制带宽下的局限性。该架构将Raibert型腿部位置控制与基于学习接触残差动力学（CRD）的推进器MPC相结合，有效处理腿地冲击并提高控制稳定性。仿真和硬件实验验证了该方法在推力恢复和步态稳定性方面的优越性。

> **摘要翻译:** Husky Carbon是东北大学开发的一款机器人，作为研究平台，旨在探索姿态操纵和推力矢量化的统一。与传统四足机器人不同，其关节执行器和推进器增强了控制权限，有助于推进器辅助的窄路径行走。虽然一个统一的模型预测控制（MPC）框架理论上可以优化地面反作用力和推进器力来解决这个控制问题，但其实用性受限于系统轻量级执行器较低的扭矩控制带宽。为了克服这一挑战，我们提出了一种解耦控制架构：Raibert型控制器使用基于位置的控制来管理腿部运动，而MPC则通过学习到的接触残差动力学（CRD）来调节推进器，以解释腿地冲击。这种分离绕过了扭矩控制速率瓶颈，同时保留了推进器MPC来明确考虑腿地冲击动力学，通过学习到的残差来解释腿地冲击。我们通过仿真和硬件实验验证了这种方法，结果表明，与没有CRD的解耦控制器相比，带有CRD的解耦控制架构在推力恢复和猫步姿态方面表现出更稳定的行为。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [103] [Improving Drone Racing Performance Through Iterative Learning MPC](https://arxiv.org/abs/2508.01103)
> *通过迭代学习模型预测控制改进无人机竞速性能*

*Haocheng Zhao, Niklas Schlüter, Lukas Brunke, Angela P. Schoellig* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 无人机竞速, 迭代学习MPC, 模型预测控制, 自主控制, 路径优化

**Comment:** Accepted for oral presentation at IROS 2025

> **TL;DR:** 本文通过自适应成本函数、局部安全集偏移和基于笛卡尔坐标系的公式化，改进了迭代学习模型预测控制（LMPC），显著提升了无人机竞速性能，在模拟和实际实验中均实现了更快的圈速和碰撞避免。

**AI_Comments:** 本文通过对迭代学习模型预测控制（LMPC）进行三项关键创新，有效解决了无人机竞速中实时性、安全性和性能优化之间的权衡问题。自适应成本函数和偏移局部安全集的设计是其创新点，特别是基于笛卡尔坐标系的公式化避免了传统Frenet框架的缺陷，增强了方法的鲁棒性。该研究不仅在模拟中取得了显著成果，也在真实世界实验中验证了其有效性，为自主无人机竞速的实际应用提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 自主无人机竞速是一个具有挑战性的控制问题，需要实时决策和鲁棒处理非线性系统动力学。虽然迭代学习模型预测控制（LMPC）为迭代性能改进提供了一个有前景的框架，但其直接应用于无人机竞速面临实时兼容性或时间最优与安全遍历之间权衡的挑战。

**Method:** 本文通过三项关键创新增强了LMPC：1）一个自适应成本函数，动态权衡时间最优跟踪与中心线依从性；2）一个偏移的局部安全集，以防止过度抄近路并实现更鲁棒的迭代更新；3）一个基于笛卡尔坐标系的公式化，可以容纳安全约束，避免了与Frenet框架转换相关的奇点或积分误差。

**Result:** 在广泛的模拟和实际实验中，改进算法可以将各种控制器生成的初始轨迹进行优化，最大圈速提升了60.85%。即使应用于最激进调优的最新基于模型的控制器MPCC++，在真实无人机上仍实现了6.05%的提升。

**Conclusion:** 所提出的方法推动无人机实现更快的遍历，并在模拟和实际实验中避免碰撞，使其成为提高无人机竞速峰值性能的实用解决方案。

> **ai_Abstract:** 本文针对无人机竞速中迭代学习模型预测控制（LMPC）面临的挑战，提出了一系列改进。通过引入自适应成本函数、偏移局部安全集和基于笛卡尔坐标系的公式化，该方法显著提升了无人机竞速性能。实验结果表明，该算法能有效优化轨迹，在模拟中实现高达60.85%的圈速提升，在真实无人机上对先进控制器也能带来6.05%的提升，证明了其在提高无人机竞速峰值性能方面的实用性。

> **摘要翻译:** 自主无人机竞速提出了一个具有挑战性的控制问题，需要实时决策和对非线性系统动力学的鲁棒处理。虽然迭代学习模型预测控制（LMPC）为迭代性能改进提供了一个有前景的框架，但其直接应用于无人机竞速面临着实时兼容性或时间最优与安全遍历之间权衡的挑战。在本文中，我们通过三项关键创新增强了LMPC：(1) 一个自适应成本函数，动态权衡时间最优跟踪与中心线依从性；(2) 一个偏移的局部安全集，以防止过度抄近路并实现更鲁棒的迭代更新；(3) 一个基于笛卡尔坐标系的公式化，可以容纳安全约束，避免了与Frenet框架转换相关的奇点或积分误差。广泛的模拟和实际实验结果表明，我们改进的算法可以优化由各种调优水平不同的控制器生成的初始轨迹，最大圈速提升了60.85%。即使应用于最激进调优的最新基于模型的控制器MPCC++，在真实无人机上，仍实现了6.05%的提升。总体而言，所提出的方法推动无人机在模拟和实际实验中实现更快的遍历并避免碰撞，使其成为提高无人机竞速峰值性能的实用解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [104] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
> *基于残差Koopman模型预测控制增强车辆动力学与少量赛道数据输入*

*Yonghao Fu, Cheng Hu, Haokun Xiong, Zhanpeng Bao, Wenyuan Du, Edoardo Ghignone, Michele Magno, Lei Xie, Hongye Su* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 残差Koopman模型预测控制, 车辆动力学, 轨迹跟踪, 模型预测控制, 神经网络

**Comment:** 

> **TL;DR:** 本文提出了一种残差Koopman模型预测控制（RKMPC）框架，通过结合线性MPC和神经网络来优化车辆轨迹跟踪，显著减少了训练数据需求并提高了跟踪性能。

**AI_Comments:** 该论文的创新点在于提出了一个双MPC架构，将传统机械模型的可靠性与神经网络的性能优化相结合，通过残差建模有效处理了车辆非线性动力学问题。其显著减少训练数据需求（仅需20%）并显著提升跟踪性能的特点，对于实际应用具有重要意义，尤其是在数据采集成本较高或数据稀缺的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 传统的纯路径跟踪（PP）控制不考虑车辆模型约束，影响驾驶安全。模型预测控制（MPC）依赖于精确的车辆建模，但传统建模方法在捕获非线性动力学和计算效率之间存在权衡，导致控制性能下降。

**Method:** 本文提出了残差Koopman模型预测控制（RKMPC）框架。该方法使用双线性MPC架构计算控制输入：一个线性模型预测控制（LMPC）基于车辆运动学模型计算基线控制输入，一个基于神经网络的RKMPC计算补偿输入。最终控制指令由两部分相加得到。这种设计保留了传统机械模型的可靠性和可解释性，并通过残差建模实现了性能优化。

**Result:** RKMPC在Carsim-Matlab联合仿真平台和1:10比例F1TENTH赛车上进行了验证。实验结果表明，RKMPC仅需传统Koopman模型预测控制（KMPC）20%的训练数据即可提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差降低了11.7%-22.1%，航向误差降低了8.9%-15.8%，并使前轮转向稳定性提高了27.6%。

**Conclusion:** 本文提出的残差Koopman模型预测控制（RKMPC）框架通过结合传统机械模型的可靠性和神经网络的优化能力，有效解决了车辆轨迹跟踪中的挑战，在减少数据需求的同时显著提升了控制性能和稳定性。

> **ai_Abstract:** 本文提出了一种名为残差Koopman模型预测控制（RKMPC）的新型车辆轨迹跟踪框架。该方法结合了基于车辆运动学模型的线性MPC和基于神经网络的残差补偿，旨在克服传统MPC在非线性动力学建模和计算效率之间的权衡。RKMPC在仿真和物理赛车上验证，结果显示其在仅需少量训练数据的情况下，比传统方法表现出更优越的跟踪性能和稳定性。

> **摘要翻译:** 在车辆轨迹跟踪任务中，最简单的方法是纯路径跟踪（PP）控制。然而，这种单点预览跟踪策略未能考虑车辆模型约束，从而影响了驾驶安全。模型预测控制（MPC）作为一种广泛采用的控制方法，通过结合机械模型和物理约束来优化控制动作。其控制性能关键取决于车辆建模的准确性。传统的车辆建模方法在捕获非线性动力学和保持计算效率之间面临固有的权衡，通常导致控制性能下降。为了解决这些挑战，本文提出了残差Koopman模型预测控制（RKMPC）框架。该方法使用双线性MPC架构来计算控制输入：一个线性模型预测控制（LMPC）基于车辆运动学模型计算基线控制输入，一个基于神经网络的RKMPC计算补偿输入。最终控制指令通过将这两个组件相加获得。这种设计保留了传统机械模型的可靠性和可解释性，同时通过残差建模实现了性能优化。该方法已在Carsim-Matlab联合仿真平台和物理1:10比例F1TENTH赛车上进行了验证。实验结果表明，RKMPC仅需传统Koopman模型预测控制（KMPC）20%的训练数据即可提供卓越的跟踪性能。与传统LMPC相比，RKMPC将横向误差降低了11.7%-22.1%，航向误差降低了8.9%-15.9%，并使前轮转向稳定性提高了27.6%。实施代码可在：https://github.com/ZJU-DDRX/Residual Koopman 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [134] [LiGen: GAN-Augmented Spectral Fingerprinting for Indoor Positioning](https://arxiv.org/abs/2508.03024)
> *LiGen：GAN增强光谱指纹室内定位*

*Jie Lin, Hsun-Yu Lee, Ho-Ming Li, Fang-Jing Wu* | **Category: cs.RO, I.2.9; C.3** | **Updated: 2025-08-05**

**Keywords:** 室内定位, 光谱指纹, 生成对抗网络, 数据增强, LiGen

**Comment:** 6 pages, 10 figures

> **TL;DR:** LiGen是一个利用环境光光谱指纹进行室内定位的系统，通过GAN增强数据，实现了亚米级精度，优于Wi-Fi系统，且在复杂环境中鲁棒性强。

**AI_Comments:** 该论文的创新点在于首次将环境光光谱指纹与GANs数据增强技术相结合应用于室内定位，为解决传统Wi-Fi定位的局限性提供了一个新颖且无需基础设施的解决方案。其提出的PointGAN和FreeGAN在有限数据下的数据增强能力是关键。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Wi-Fi的室内定位系统易受环境条件影响，需要一个更稳定、无需基础设施的替代方案。

**Method:** 提出LiGen系统，利用环境光的光谱强度模式作为指纹。为解决光谱数据有限问题，设计了基于GAN的数据增强框架，包括：PointGAN（根据坐标生成指纹）和FreeGAN（使用弱定位模型标记无条件样本）。定位模型采用多层感知机（MLP）架构在合成数据上训练。

**Result:** 实现了亚米级定位精度，比基于Wi-Fi的基线系统性能高出50%以上。在复杂环境中表现出强大的鲁棒性。

**Conclusion:** LiGen是首个结合光谱指纹和基于GAN的数据增强的室内定位系统，提供了一种准确、鲁棒的解决方案。

> **ai_Abstract:** LiGen是一种新型室内定位系统，利用环境光的光谱指纹作为定位依据，以克服传统Wi-Fi系统对环境的敏感性。为解决光谱数据不足，该系统引入了基于GAN的数据增强框架（PointGAN和FreeGAN）。通过在合成数据上训练MLP模型，LiGen实现了亚米级定位精度，并显著优于Wi-Fi基线系统，同时在复杂环境中展现出高鲁棒性。

> **摘要翻译:** 精确和鲁棒的室内定位对于智能建筑应用至关重要，但现有的基于Wi-Fi的系统往往容易受到环境条件的影响。这项工作提出了一种新颖的室内定位系统，名为LiGen，它利用环境光的光谱强度模式作为指纹，提供了一种比无线电信号更稳定、无需基础设施的替代方案。为了解决光谱数据有限的问题，我们设计了一个基于生成对抗网络（GANs）的数据增强框架，该框架具有两种变体：PointGAN，它根据坐标生成指纹；以及FreeGAN，它使用弱定位模型标记无条件样本。我们的定位模型利用多层感知机（MLP）架构在合成数据上进行训练，实现了亚米级精度，性能优于基于Wi-Fi的基线系统50%以上。LiGen在复杂环境中也表现出强大的鲁棒性。据我们所知，这是第一个将光谱指纹与基于GAN的数据增强相结合用于室内定位的系统。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [174] [CogniPlan: Uncertainty-Guided Path Planning with Conditional Generative Layout Prediction](https://arxiv.org/abs/2508.03027)
> *CogniPlan: 不确定性引导的路径规划与条件生成布局预测*

*Yizhuo Wang, Haodong He, Jingsong Liang, Yuhong Cao, Ritabrata Chakraborty, Guillaume Sartoretti* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 路径规划, 不确定性, 生成模型, 机器人导航, 环境探索

**Comment:** Accepted for presentation at CORL 2025

> **TL;DR:** CogniPlan是一个新的路径规划框架，它利用条件生成模型预测的多个可能环境布局，以在不确定性下进行有效的探索和导航，并在多个数据集和真实环境中表现出色。

**AI_Comments:** CogniPlan的创新之处在于其将条件生成模型引入路径规划，通过预测多种可能的环境布局来显式地处理不确定性，这类似于人类的认知地图。这种方法有效地结合了图像生成和图规划的优势，提高了在未知环境中的决策能力。其在真实世界部署的验证也增加了其实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人在未知环境中进行路径规划是一个关键但具有挑战性的能力，主要包括自主探索和点目标导航。机器人需要感知环境、更新信念并实时估计潜在的信息增益来指导规划。

**Method:** 本文提出了CogniPlan，一个新颖的路径规划框架。它利用一个条件生成式图像修复模型（COnditional GeNerative Inpainting model）预测的多个合理布局，类似于人类在导航时依赖认知地图。这些预测基于部分观测到的地图和一组布局条件向量，使规划器能够在不确定性下有效推理。该方法结合了生成式图像布局预测和基于图注意力机制的路径规划，将图表示的可扩展性与占用图的保真度和预测性结合起来。

**Result:** CogniPlan在探索和导航方面都取得了显著的性能提升。在两个数据集（数百张地图和真实的平面图）上进行了广泛评估，始终优于最先进的规划器。此外，还在高保真模拟器和硬件上进行了部署，展示了其高质量的路径规划和实际应用性。

**Conclusion:** CogniPlan通过利用条件生成模型预测的多个可能环境布局，有效地解决了未知环境下路径规划的挑战，并在实际应用中展现了优越的性能和可靠性。

> **ai_Abstract:** CogniPlan是一个创新的路径规划框架，旨在解决移动机器人在未知环境中的探索和导航问题。它通过利用一个条件生成式图像修复模型来预测多个可能的环境布局，从而在不确定性下进行有效的推理。该方法结合了生成式布局预测与图注意力路径规划的优势，实现了图表示的可扩展性与占用图的精确性和预测性。实验结果表明，CogniPlan在探索和导航任务中均显著优于现有技术，并在模拟器和实际硬件上验证了其高性能和实用性。

> **摘要翻译:** 在未知环境中进行路径规划是移动机器人一项关键但本身具有挑战性的能力，主要包括自主探索和点目标导航两项耦合任务。在这两种情况下，机器人都必须感知环境、更新其信念并准确估计潜在的信息增益，以实时指导规划。在这项工作中，我们提出了CogniPlan，一个新颖的路径规划框架，它利用条件生成式图像修复模型（COnditional GeNerative Inpainting model）预测的多个合理布局，这反映了人类在导航时如何依赖认知地图。这些预测基于部分观测到的地图和一组布局条件向量，使我们的规划器能够在不确定性下有效推理。我们展示了生成式基于图像的布局预测与基于图注意力的路径规划之间的强大协同作用，使CogniPlan能够将图表示的可扩展性与占用图的保真度和预测性相结合，从而在探索和导航方面都取得了显著的性能提升。我们对CogniPlan在两个数据集（数百张地图和真实的平面图）上进行了广泛评估，始终优于最先进的规划器。我们进一步将其部署在高保真模拟器和硬件上，展示了其高质量的路径规划和实际适用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [214] [Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control](https://arxiv.org/abs/2508.03043)
> *通过深度学习的鲁棒管式模型预测控制，实现昆虫级扑翼飞行机器人的特技机动*

*Yi-Hsuan Hsiao, Andrea Tagliabue, Owen Matteson, Suhan Kim, Tong Zhao, Jonathan P. How, YuFeng Chen* | **Category: cs.RO, cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 扑翼机器人, 模型预测控制, 深度学习, 飞行敏捷性, 鲁棒性

**Comment:** 27 pages, 26 supplementary pages, 6 main figures, 16 supplementary
  figures, 1 table

> **TL;DR:** 该研究通过深度学习的鲁棒管式模型预测控制，使750毫克扑翼机器人实现了昆虫级的飞行敏捷性和鲁棒性，包括快速侧向移动和连续翻转，显著超越了现有技术。

**AI_Comments:** 该论文的创新之处在于将深度学习与鲁棒管式模型预测控制相结合，以解决昆虫级扑翼机器人面临的性能瓶颈。通过模仿学习训练神经网络，有效解决了实时计算约束下的高反馈率需求，使机器人能够执行此前难以实现的复杂特技动作。其成果在速度、加速度和抗干扰能力方面均取得了显著突破，特别是连续翻转的实现，为未来小型飞行器的自主导航和复杂任务执行奠定了基础。这对于微型飞行器领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 昆虫级飞行机器人目前在跟踪非激进轨迹方面受限，与昆虫的高度敏捷机动（如急刹车、眼跳和身体翻转）存在显著性能差距。这种差距源于机器人惯性低、动力学快、扑翼气动不确定性以及易受环境干扰。为了实现高动态机动，需要生成激进的飞行轨迹并设计能够应对模型和环境不确定性的高速反馈控制器。

**Method:** 研究设计了一种深度学习的鲁棒管式模型预测控制器（deep-learned robust tube model predictive controller），并利用模仿学习方法训练了一个双层全连接神经网络，以在计算受限的实时系统中实现高反馈速率。该神经网络模仿了昆虫的飞行控制架构，包括中枢神经系统和运动神经元。

**Result:** 该机器人展示了昆虫般的眼跳运动，侧向速度达到197厘米/秒，加速度达到11.7米/秒²，分别比现有结果提高了447%和255%。机器人还能在160厘米/秒的风扰和大的指令到力映射误差下执行眼跳机动。此外，它在11秒内连续完成了10次身体翻转，这是亚克级飞行器中最具挑战性的机动。

**Conclusion:** 这些结果代表了在实现昆虫级飞行敏捷性方面的一个里程碑，并为未来在传感和计算自主性方面的研究提供了启示。

> **ai_Abstract:** 本研究通过开发一种深度学习的鲁棒管式模型预测控制器，显著提升了750毫克扑翼机器人的飞行敏捷性和鲁棒性，使其能够执行昆虫般的特技机动。该控制器结合模仿学习训练的双层神经网络，实现了在计算受限系统中的高速反馈控制。实验结果表明，该机器人能以创纪录的速度和加速度进行眼跳机动，并在强风和模型误差下保持鲁棒性，甚至完成了连续的身体翻转，为昆虫级飞行器的自主性和敏捷性研究树立了新标杆。

> **摘要翻译:** 空中昆虫表现出高度敏捷的机动，例如在扰动下的急刹车、眼跳和身体翻转。相比之下，昆虫级空中机器人仅限于跟踪具有小身体加速度的非激进轨迹。这种性能差距是由于机器人惯性低、动力学快、扑翼气动不确定性以及对环境干扰的高度敏感性共同造成的。执行高动态机动需要生成突破硬件极限的激进飞行轨迹，以及能够考虑模型和环境不确定性的高速反馈控制器。在这里，通过设计一种深度学习的鲁棒管式模型预测控制器，我们展示了750毫克扑翼机器人在昆虫级飞行敏捷性和鲁棒性。我们的模型预测控制器可以在扰动下跟踪激进的飞行轨迹。为了在计算受限的实时系统中实现高反馈速率，我们设计了模仿学习方法来训练一个双层全连接神经网络，该网络类似于由中枢神经系统和运动神经元组成的昆虫飞行控制架构。我们的机器人展示了昆虫般的眼跳运动，侧向速度和加速度分别为197厘米/秒和11.7米/秒²，分别比先前结果提高了447%和255%。该机器人还可以在160厘米/秒的风扰和大的指令到力映射误差下执行眼跳机动。此外，它在11秒内连续完成了10次身体翻转——这是亚克级飞行器中最具挑战性的机动。这些结果代表了在实现昆虫级飞行敏捷性方面的一个里程碑，并启发了未来对传感和计算自主性的研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [246] [Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching](https://arxiv.org/abs/2508.03068)
> *手眼自主递送：学习类人机器人导航、运动和抓取*

*Sirui Chen, Yufei Ye, Zi-Ang Cao, Jennifer Lew, Pei Xu, C. Karen Liu* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 类人机器人, 导航, 运动, 抓取, 模仿学习

**Comment:** 

> **TL;DR:** HEAD是一个框架，通过学习人类运动和视觉感知数据，使类人机器人能够自主导航、运动和抓取。

**AI_Comments:** 该论文的创新之处在于提出了一个名为HEAD的模块化框架，使类人机器人能够直接从人类运动和视觉感知数据中学习复杂的导航、运动和抓取技能。这种直接从人类数据中学习的方法，以及将视觉感知与物理动作解耦的模块化设计，有望显著提高类人机器人的学习效率和对新环境的泛化能力。在模拟和现实世界中的验证进一步证明了其在复杂环境中的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是开发一个框架，使类人机器人能够直接从人类运动和视觉感知数据中学习导航、运动和抓取技能，从而实现自主递送。

**Method:** 该研究提出了手眼自主递送（HEAD）框架，采用模块化方法。高层规划器指令类人机器人的手和眼睛的目标位置和方向，由控制全身运动的低层策略执行。具体来说，低层全身控制器从现有的、大规模的人类运动捕捉数据中学习跟踪三个点（眼睛、左手和右手），而高层策略则从通过Aria眼镜收集的人类数据中学习。这种模块化方法将自我中心视觉感知与物理动作解耦，从而促进高效学习和扩展到新场景。

**Result:** 该方法在模拟和现实世界中都进行了评估，展示了类人机器人在为人类设计的复杂环境中导航和抓取的能力。

**Conclusion:** 该研究成功地展示了通过HEAD框架，类人机器人能够直接从人类运动和视觉感知数据中学习导航、运动和抓取技能，并在复杂环境中表现出良好的性能。

> **ai_Abstract:** 本文提出了手眼自主递送（HEAD）框架，旨在使类人机器人能够直接从人类运动和视觉感知数据中学习导航、运动和抓取技能。该框架采用模块化设计，高层规划器负责设定手眼目标，低层策略控制全身运动，分别从大规模人类运动捕捉数据和Aria眼镜收集的人类数据中学习。这种解耦的视觉感知与物理动作的方法，提升了学习效率和场景适应性。实验结果表明，该方法在模拟和现实世界中都能有效赋能类人机器人在复杂人类环境中进行导航和抓取。

> **摘要翻译:** 我们提出了手眼自主递送（HEAD），一个直接从人类运动和视觉感知数据中学习类人机器人导航、运动和抓取技能的框架。我们采用模块化方法，其中高层规划器指令类人机器人的手和眼睛的目标位置和方向，由控制全身运动的低层策略执行。具体来说，低层全身控制器从现有的、大规模的人类运动捕捉数据中学习跟踪三个点（眼睛、左手和右手），而高层策略则从通过Aria眼镜收集的人类数据中学习。我们的模块化方法将自我中心视觉感知与物理动作解耦，促进高效学习和扩展到新场景。我们在模拟和现实世界中都对我们的方法进行了评估，展示了类人机器人在为人类设计的复杂环境中导航和抓取的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [278] [Point2Act: Efficient 3D Distillation of Multimodal LLMs for Zero-Shot Context-Aware Grasping](https://arxiv.org/abs/2508.03099)
> *Point2Act：多模态大型语言模型的高效3D蒸馏用于零样本上下文感知抓取*

*Sang Min Kim, Hyeongjun Heo, Junho Kim, Yonghyeon Lee, Young Min Kim* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 3D抓取, 多模态大型语言模型, 零样本, 上下文感知, 机器人操作

**Comment:** 

> **TL;DR:** Point2Act利用多模态LLM高效地从自然语言描述中检索3D动作点，实现零样本上下文感知抓取，并能在20秒内生成空间定位响应。

**AI_Comments:** 该论文的创新点在于提出了“3D相关性场”和多视图聚合，有效解决了MLLM在从2D语义到精确3D动作点映射的挑战。它通过高效的3D蒸馏，使得通用机器人能够更准确、快速地执行基于自然语言的零样本抓取任务，对于提升机器人具身智能的实用性具有重要意义。其全栈管道能够在20秒内生成响应，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法（基于MLLM的通用机器人）虽然能从2D图像和语言数据集中获取语义理解，但在2D区域识别和精确3D动作点定位方面存在不足，导致模糊的2D区域和难以找到精确的3D位置。

**Method:** 提出Point2Act，它利用多模态大型语言模型（MLLMs）直接检索与上下文描述任务相关的3D动作点。该方法通过“3D相关性场”绕过高维特征，高效地注入轻量级2D点级指导，并采用多视图聚合来补偿几何歧义（如遮挡）或语义不确定性。其全栈管道包括捕获、MLLM查询、3D重建和抓取姿态提取。

**Result:** 输出区域高度局部化，能够推理精细的3D空间上下文，直接转换为物理动作的明确位置。完整的流程能在20秒内生成空间定位响应，有助于实际操作任务。

**Conclusion:** Point2Act通过其创新的3D相关性场和多视图聚合，有效解决了MLLM在3D动作点定位上的不足，实现了高效、精确的零样本上下文感知抓取，并能快速应用于实际机器人操作。

> **ai_Abstract:** Point2Act是一种利用多模态大型语言模型（MLLM）实现零样本上下文感知抓取的新方法。针对现有MLLM在精确3D动作点定位上的不足，Point2Act引入了高效的3D相关性场和多视图聚合，能够从自然语言描述中直接检索并定位精确的3D动作点。该系统能快速生成高精度、空间定位的3D动作点，显著提升了通用机器人在复杂环境中执行操作任务的能力，并在20秒内完成整个流程。

> **摘要翻译:** 我们提出了Point2Act，它利用多模态大型语言模型（MLLMs）直接检索与上下文描述任务相关的3D动作点。基础模型为通用机器人开辟了可能性，这些机器人可以在未知的环境中根据自然语言描述执行零样本任务。虽然从大规模图像和语言数据集中获得的语义理解提供了2D图像中的上下文理解，但丰富而细致的特征推断出模糊的2D区域，并且难以找到精确的3D动作位置。我们提出的3D相关性场绕过了高维特征，而是有效地注入了针对任务特定动作量身定制的轻量级2D点级指导。多视图聚合有效地补偿了由于几何模糊（如遮挡）或语言描述中固有的语义不确定性造成的错位。输出区域高度局部化，能够推断精细的3D空间上下文，可以直接转换为场景即时重建时的物理动作的明确位置。我们的全栈管道，包括捕获、MLLM查询、3D重建和抓取姿态提取，能在20秒内生成空间定位响应，从而促进实际操作任务。项目页面：https://sangminkim-99.github.io/point2act/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [285] [The Starlink Robot: A Platform and Dataset for Mobile Satellite Communication](https://arxiv.org/abs/2506.19781)
> *星链机器人：一个用于移动卫星通信的平台和数据集*

*Boyi Liu, Qianyi Zhang, Qiang Yang, Jianhao Jiao, Jagmohan Chauhan, Dimitrios Kanoulas* | **Category: cs.RO, cs.NI** | **Updated: 2025-08-05**

**Keywords:** 星链机器人, 移动卫星通信, 数据集, 机器人平台, 遮挡

**Comment:** 

> **TL;DR:** 本文介绍了星链机器人，一个配备星链互联网的移动机器人平台和多模态数据集，用于系统研究移动和遮挡条件下的卫星通信性能。

**AI_Comments:** 该论文的创新点在于构建了首个集成星链卫星互联网的移动机器人平台，并创建了一个独特的多模态数据集，专门用于研究移动和遮挡条件下卫星通信的性能。这对于理解和优化未来移动设备和自动驾驶汽车的卫星连接至关重要。其重要性在于为未来研究提供了实验平台和丰富的数据，填补了现有研究的空白。

<details>
  <summary>Details</summary>

**Motivation:** 尽管卫星通信与移动设备的集成带来了连接性的范式转变，但在运动和环境遮挡下的性能特征仍未被充分理解。

**Method:** 本文提出了星链机器人，这是第一个配备星链卫星互联网和包括向上摄像头、激光雷达和惯性测量单元（IMU）在内的综合传感器套件的移动机器人平台，旨在系统研究运动期间的卫星通信性能。该研究还构建了一个多模态数据集，捕获了同步的通信指标、运动动态、天空可见性和3D环境上下文，涵盖了稳态运动、变速和不同遮挡条件等多种场景。研究中使用了LEOViz进行实时卫星跟踪和数据收集。

**Result:** 本文成功构建并呈现了星链机器人平台及其配套的多模态数据集。该数据集能够捕获移动卫星通信的性能特征，包括通信指标、运动动态、天空可见性和3D环境上下文，涵盖多种场景。

**Conclusion:** 该平台和数据集使研究人员能够开发运动感知通信协议，预测连接中断，并优化卫星通信，以适应从智能手机到自动驾驶汽车等新兴移动应用。

> **ai_Abstract:** 本文介绍了星链机器人，这是一个创新的移动机器人平台，首次集成了星链卫星互联网和一套全面的传感器（包括摄像头、激光雷达和IMU）。该平台旨在系统研究在移动和环境遮挡条件下卫星通信的性能。研究还构建了一个多模态数据集，同步记录了通信指标、运动状态、天空可视性和3D环境信息，涵盖了多种移动和遮挡场景。该平台和数据集为研究人员提供了宝贵资源，以开发运动感知通信协议、预测连接中断并优化未来移动应用的卫星通信。

> **摘要翻译:** 卫星通信与移动设备的集成代表着连接性方面的范式转变，然而，在运动和环境遮挡下的性能特征仍知之甚少。我们提出了星链机器人，这是第一个配备星链卫星互联网、包括向上摄像头、激光雷达和IMU在内的综合传感器套件的移动机器人平台，旨在系统研究运动期间的卫星通信性能。我们的多模态数据集捕获了同步的通信指标、运动动态、天空可见性和3D环境上下文，涵盖了稳态运动、变速和不同遮挡条件等多种场景。该平台和数据集使研究人员能够开发运动感知通信协议，预测连接中断，并优化卫星通信，以适应从智能手机到自动驾驶汽车等新兴移动应用。在这项工作中，我们使用LEOViz进行实时卫星跟踪和数据收集。星链机器人项目可在https://github.com/StarlinkRobot获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [306] [Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection](https://arxiv.org/abs/2508.03129)
> *MPC引导扰动注入的安全性感知模仿学习*

*Le Qiu, Yusuf Umut Ciftci, Somil Bansal* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 模仿学习, 安全性, 模型预测控制, 扰动注入, 机器人学习

**Comment:** 

> **TL;DR:** 本文提出MPC-SafeGIL，一种在专家演示中注入对抗性扰动以提高模仿学习安全性的设计时方法，使其能够学习鲁棒的恢复行为，并在模拟和真实世界实验中验证了其在安全性和任务性能上的改进。

**AI_Comments:** 该论文的创新点在于将模型预测控制（MPC）与模仿学习相结合，通过在数据收集阶段主动注入“最坏情况”扰动来提高策略的安全性。这种设计时方法避免了对交互式专家或精确分析模型的依赖，使其在实际应用中更具普适性和可扩展性，尤其是在高维和黑盒系统中。

<details>
  <summary>Details</summary>

**Motivation:** 模仿学习在学习复杂机器人行为方面有前景，但学习到的策略可能出现导致安全违规的错误，这限制了其在安全关键应用中的部署。

**Method:** 本文提出MPC-SafeGIL，一种通过在专家演示期间注入对抗性扰动来增强模仿学习安全性的设计时方法。该方法使用基于采样的模型预测控制（MPC）来近似最坏情况扰动，使其可扩展到高维和黑盒动态系统。与依赖分析模型或交互式专家的现有工作不同，MPC-SafeGIL将安全考虑直接集成到数据收集中。

**Result:** 通过包括四足动物运动和视觉运动导航在内的广泛模拟以及四旋翼无人机上的真实世界实验，验证了该方法，证明了在安全性和任务性能方面的改进。

**Conclusion:** MPC-SafeGIL通过在数据收集中直接整合安全考虑，显著提高了模仿学习策略的安全性，使其能够学习鲁棒的恢复行为，从而提高了在安全关键应用中的部署潜力。

> **ai_Abstract:** 本文提出MPC-SafeGIL，一种通过在专家演示中注入MPC引导的对抗性扰动来提高模仿学习安全性的设计时方法。该方法旨在使模仿策略学习鲁棒的恢复行为，从而解决现有模仿学习在安全关键应用中的部署限制。MPC-SafeGIL利用基于采样的MPC来近似最坏情况扰动，使其适用于复杂系统，并直接在数据收集中整合安全考量。实验结果表明，该方法在安全性和任务性能方面均有显著提升。

> **摘要翻译:** 模仿学习为从专家演示中学习复杂机器人行为提供了一种有前景的方法。然而，学习到的策略可能会出现导致安全违规的错误，这限制了它们在安全关键应用中的部署。我们提出了MPC-SafeGIL，这是一种设计时方法，通过在专家演示期间注入对抗性扰动来增强模仿学习的安全性。这使专家暴露于更广泛的安全关键场景，并允许模仿策略学习鲁棒的恢复行为。我们的方法使用基于采样的模型预测控制（MPC）来近似最坏情况扰动，使其可扩展到高维和黑盒动态系统。与依赖分析模型或交互式专家的现有工作不同，MPC-SafeGIL将安全考虑直接集成到数据收集中。我们通过包括四足动物运动和视觉运动导航在内的广泛模拟以及四旋翼无人机上的真实世界实验验证了我们的方法，证明了在安全性和任务性能方面的改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [342] [UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands](https://arxiv.org/abs/2508.03339)
> *UniFucGrasp：受人手启发的统一功能抓取标注策略及多类型灵巧手数据集*

*Haoran Lin, Wenrui Chen, Xianchi Chen, Fan Yang, Qiang Diao, Wenxin Xie, Sijie Wu, Kailun Yang, Maojun Li, Yaonan Wang* | **Category: cs.RO, cs.CV, eess.IV** | **Updated: 2025-08-05**

**Keywords:** 功能抓取, 灵巧手, 数据集, 仿生学, 抓取标注

**Comment:** The project page is at https://haochen611.github.io/UFG

> **TL;DR:** UniFucGrasp提出了一种受人手启发的通用功能抓取标注策略和数据集，解决了传统灵巧抓取数据集中忽略功能性、成本高昂和泛化性差的问题，显著提升了多类型机械手的抓取准确性和稳定性。

**AI_Comments:** 该论文的创新点在于首次关注并系统地解决了灵巧机器人抓取中“功能性抓取”的标注和数据集构建问题，而不仅仅是抓取稳定性。其受人手启发的仿生学方法为多类型灵巧手提供了通用的解决方案，有效降低了数据收集成本并增强了模型的泛化能力，对具身智能领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的灵巧抓取数据集主要侧重于抓取稳定性，而忽略了执行开瓶盖、握持杯柄等任务所需的功能性抓取。此外，大多数数据集依赖于笨重、昂贵且难以控制的高自由度（DOF）Shadow Hands。

**Method:** 受人手欠驱动机制的启发，本文建立了UniFucGrasp，一个用于多种灵巧手类型的通用功能抓取标注策略和数据集。该方法基于仿生学，将自然人体运动映射到不同的手部结构，并利用基于几何的力闭合来确保功能性、稳定、类人抓取。此方法支持低成本、高效地收集多样化、高质量的功能抓取。最终，建立了第一个多手功能抓取数据集，并提供了一个合成模型来验证其有效性。

**Result:** 在UFG数据集、IsaacSim和复杂机器人任务上的实验表明，该方法提高了功能操作精度和抓取稳定性，实现了在不同机器人手之间的有效泛化，并克服了灵巧抓取中的标注成本和泛化挑战。

**Conclusion:** 本文提出的UniFucGrasp方法通过提供一个受人手启发的多类型灵巧手功能抓取数据集和标注策略，显著提高了机器人功能操作的准确性和抓取稳定性，解决了现有数据集的局限性，并实现了高效的跨手泛化。

> **ai_Abstract:** 本文提出UniFucGrasp，一个受人手启发的统一功能抓取标注策略和数据集，旨在解决现有灵巧抓取数据集仅关注稳定性而忽视功能性、且成本高昂、泛化性差的问题。通过仿生学方法，将人体运动映射到多种灵巧手结构，并利用几何力闭合确保抓取的功能性和稳定性。该策略实现了低成本、高效地收集高质量功能抓取数据，并构建了首个多手功能抓取数据集。实验证明，UniFucGrasp显著提升了功能操作精度和抓取稳定性，实现了对不同机器人手的有效泛化，并克服了标注成本和泛化挑战。

> **摘要翻译:** 灵巧抓取数据集对于具身智能至关重要，但大多强调抓取稳定性，忽略了执行开瓶盖或握持杯柄等任务所需的功能性抓取。大多数依赖于笨重、昂贵且难以控制的高自由度（DOF）Shadow Hands。受人手欠驱动机制的启发，我们建立了UniFucGrasp，一个用于多种灵巧手类型的通用功能抓取标注策略和数据集。基于仿生学，它将自然人体运动映射到不同的手部结构，并利用基于几何的力闭合来确保功能性、稳定、类人抓取。此方法支持低成本、高效地收集多样化、高质量的功能抓取。最终，我们建立了第一个多手功能抓取数据集，并提供了一个合成模型来验证其有效性。在UFG数据集、IsaacSim和复杂机器人任务上的实验表明，我们的方法提高了功能操作精度和抓取稳定性，实现了在不同机器人手之间的有效泛化，并克服了灵巧抓取中的标注成本和泛化挑战。项目页面位于https://haochen611.github.io/UFG。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [348] [Language as Cost: Proactive Hazard Mapping using VLM for Robot Navigation](https://arxiv.org/abs/2508.03138)
> *语言即成本：利用VLM进行机器人导航的主动危险映射*

*Mintaek Oh, Chan Kim, Seung-Woo Seo, Seong-Woo Kim* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** VLM, 机器人导航, 危险映射, 动态风险, 语言即成本

**Comment:** Accepted at IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025. 8 pages, 7 figures

> **TL;DR:** 本研究提出了一种零样本的“语言即成本”映射框架，利用视觉语言模型（VLM）为机器人导航主动识别和规避动态危险，显著提高了导航成功率并减少了危险遭遇。

**AI_Comments:** 这项工作具有显著的创新性，它将先进的视觉语言模型与传统的机器人导航相结合，解决了动态环境中机器人安全导航的关键挑战。通过将“语言”转化为“成本”，模型能够理解并预测潜在的人类意图或环境变化带来的危险，这远超了传统的几何障碍物检测。其零样本能力也预示着在现实世界部署的潜力，无需大量特定场景的训练。这项研究为未来更智能、更安全的机器人自主导航系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器人导航系统依赖于静态地图，难以处理动态风险，例如突然打开的门后出现的人，导致系统在处理动态危险时通常是反应式的而非预测式的。机器人需要在以人为中心或危险环境中主动预测和规避危险。

**Method:** 本研究提出了一种零样本的“语言即成本”映射框架，该框架利用视觉语言模型（VLM）解释视觉场景，评估潜在的动态风险，并先发性地分配风险感知导航成本。通过将这种基于语言的成本图与几何障碍物地图相结合，机器人不仅能识别现有障碍物，还能预测并主动规划规避由环境动态引起的潜在危险。

**Result:** 在模拟和多样化的动态环境中进行的实验表明，所提出的方法与反应式基线规划器相比，显著提高了导航成功率并减少了危险遭遇。

**Conclusion:** 通过将视觉语言模型（VLM）整合到导航成本映射中，机器人能够主动感知和规避动态危险，从而在复杂和动态环境中实现更安全、更高效的导航。

> **ai_Abstract:** 本论文介绍了一种新颖的“语言即成本”框架，该框架利用视觉语言模型（VLM）使机器人在动态环境中进行主动危险映射和规避。针对传统导航系统在处理动态风险时的被动性，该方法通过VLM解释视觉信息，评估潜在危险并生成风险感知的导航成本图。结合几何障碍物地图，机器人能预测并规划规避未发生的危险。实验证明，该方法显著提高了导航成功率并减少了危险遭遇。

> **摘要翻译:** 机器人要在以人为中心或危险环境中运行，必须主动预测和规避超出基本障碍物检测范围的危险。传统的导航系统通常依赖静态地图，难以应对动态风险，例如突然打开的门后出现的人。因此，这些系统在处理动态危险时往往是反应式的，而非预测性的。预训练大型语言模型和视觉语言模型（VLM）的最新进展为主动规避危险创造了新的机会。在这项工作中，我们提出了一种零样本的“语言即成本”映射框架，该框架利用VLM解释视觉场景，评估潜在的动态风险，并先发性地分配风险感知导航成本，使机器人能够在危险实际发生之前预测危险。通过将这种基于语言的成本图与几何障碍物地图相结合，机器人不仅能识别现有障碍物，还能预测并主动规划规避由环境动态引起的潜在危险。在模拟和多样化动态环境中的实验表明，与反应式基线规划器相比，所提出的方法显著提高了导航成功率并减少了危险遭遇。代码和补充材料可在https://github.com/Taekmino/LaC获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [384] [CookBench: A Long-Horizon Embodied Planning Benchmark for Complex Cooking Scenarios](https://arxiv.org/abs/2508.03232)
> *CookBench：一个用于复杂烹饪场景的长期具身规划基准*

*Muzhen Cai, Xiubo Chen, Yining An, Jiaxin Zhang, Xuesong Wang, Wang Xu, Weinan Zhang, Ting Liu* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 具身规划, 长期任务, 烹饪场景, 基准, CookBench

**Comment:** 9 pages, 5 figures

> **TL;DR:** CookBench 是一个针对复杂烹饪场景的长期具身规划新基准，解决了现有基准任务周期短、动作粒度粗的问题，并揭示了现有模型在此类任务中的不足。

**AI_Comments:** CookBench的创新之处在于其针对长期具身规划的复杂烹饪场景，解决了现有基准动作粒度粗和任务周期短的问题。其两阶段设计和细粒度的空间动作设定，更贴近真实世界操作，对具身智能体的决策能力提出了更高要求。通过开源基准和工具集，它为具身AI领域的研究提供了宝贵且具有挑战性的平台，有助于推动更智能、更通用的具身智能体的开发。同时，对SOTA模型不足的揭示，也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有具身规划基准常以短周期任务和粗粒度动作原语为特点，无法有效应对复杂物理世界中的长期任务，因此需要一个新的基准来解决这一挑战。

**Method:** 本文引入了CookBench，一个基于Unity高保真模拟环境的长期具身规划基准，用于复杂烹饪场景。它设计为两阶段过程：意图识别和具身交互，并细化了动作粒度到空间层面。此外，提供了一个统一API的综合工具集，支持宏观操作和细粒度具身动作。研究还对最先进的闭源大型语言模型和视觉-语言模型进行了深入分析。

**Result:** 通过CookBench，揭示了最先进的闭源大型语言模型和视觉-语言模型在处理复杂、长期任务时的主要缺点和挑战。

**Conclusion:** CookBench作为一个新的具身规划基准，旨在促进未来在复杂烹饪场景中长期具身规划的研究，并已揭示了当前先进模型的不足。该基准将全面开源以促进研究。

> **ai_Abstract:** CookBench是一个新颖的具身规划基准，旨在解决现有基准在处理复杂、长期任务方面的不足。它利用高保真Unity模拟环境，提出了一个两阶段的烹饪任务：意图识别和具身交互，并引入了细粒度的空间级动作。该基准提供了一个全面的工具集，支持宏观和微观操作，使研究人员能够专注于高层规划。通过对现有大型语言模型和视觉-语言模型的分析，CookBench揭示了它们在应对此类复杂任务时的局限性，并将全面开源以推动未来研究。

> **摘要翻译:** 具身规划致力于创建能够在复杂物理世界中执行长期任务的智能体。然而，现有的具身规划基准通常具有短周期任务和粗粒度动作原语的特点。为了解决这一挑战，我们引入了CookBench，一个用于复杂烹饪场景中长期规划的基准。通过利用基于强大的Unity游戏引擎构建的高保真模拟环境，我们在一个复杂、现实的环境中定义了前沿的AI挑战。CookBench的核心任务设计为一个两阶段过程。首先，在意图识别阶段，智能体需要准确解析用户的复杂意图。其次，在具身交互阶段，智能体应通过长期、细粒度的物理动作序列来执行已识别的烹饪目标。与现有具身规划基准不同，我们将动作粒度细化到空间层面，该层面考虑了关键操作信息，同时抽象了低级机器人控制。此外，我们提供了一个封装了模拟器的综合工具集。其统一API支持宏观操作（如订购和购买食材）以及一套丰富的用于物理交互的细粒度具身动作，使研究人员能够专注于高级规划和决策。此外，我们对最先进的闭源大型语言模型和视觉-语言模型进行了深入分析，揭示了它们在复杂、长期任务中面临的主要缺点和挑战。完整的基准将开源以促进未来的研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [420] [Force-Compliance MPC and Robot-User CBFs for Interactive Navigation and User-Robot Safety in Hexapod Guide Robots](https://arxiv.org/abs/2508.03246)
> *六足导盲机器人中用于交互式导航和人机安全的力-柔顺模型预测控制和机器人-用户控制障碍函数*

*Zehua Fan, Feng Gao, Zhijun Chen, Yunpeng Yin, Limin Yang, Qingxing Xi, En Yang, Xuefeng Luo* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 六足机器人, 导盲机器人, 模型预测控制, 控制障碍函数, 人机交互, 避障

**Comment:** 

> **TL;DR:** 提出了一种结合力-柔顺MPC和机器人-用户CBF的六足导盲机器人系统，实现了在复杂环境中的安全交互式导航和避障。

**AI_Comments:** 这项工作在导盲机器人领域具有重要意义，通过结合FC-MPC和CBFs，有效地解决了实时交互和人机安全的关键挑战。特别值得注意的是，DBSCAN算法的改进显著降低了计算复杂度，使得在资源受限的机器人上实现实时感知成为可能，这对于实际应用至关重要。该系统集成了力柔顺、自主导航和避障，展现了较强的实用性和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂环境中引导视障人士需要实时双向交互和安全保障。

**Method:** 1. 力-柔顺模型预测控制（FC-MPC）：通过机器人动态模型和递归最小二乘法（RLS）估计用户施加的力和力矩，并相应调整机器人运动，实现双向交互。2. 机器人-用户控制障碍函数（CBFs）：处理静态和动态障碍物，使用加权松弛变量克服复杂动态环境中的可行性问题，确保用户和机器人的安全。3. 障碍物聚类：采用八向连接DBSCAN方法将计算复杂度从O(n2)降低到大约O(n)，实现实时局部感知。4. 障碍物建模与预测：使用最小边界椭圆（MBEs）对障碍物进行建模，并通过卡尔曼滤波预测其轨迹。5. 在HexGuide机器人上实现。

**Result:** 系统能够适应用户的力指令，同时在复杂环境导航中保证用户和机器人的安全。障碍物聚类计算复杂度从O(n2)降低到大约O(n)，实现了资源受限车载计算机上的实时局部感知。

**Conclusion:** 该系统成功地将力柔顺性、自主导航和避障功能集成在一起，并在实验中证明了其在复杂环境中进行安全、交互式导航的能力。

> **ai_Abstract:** 本研究提出了一种用于六足导盲机器人的力-柔顺模型预测控制（FC-MPC）与机器人-用户控制障碍函数（CBFs）相结合的系统，旨在实现复杂环境下的交互式导航和人机安全。FC-MPC通过估计用户施加的力来调整机器人运动，实现双向交互；CBFs则通过处理障碍物并利用加权松弛变量确保用户和机器人的安全。此外，研究还引入了八向连接DBSCAN方法以降低障碍物聚类计算复杂度，并采用最小边界椭圆建模和卡尔曼滤波进行障碍物轨迹预测。该系统已在HexGuide机器人上实现，实验证明其能有效适应用户指令，同时保证导航过程中的安全性。

> **摘要翻译:** 在复杂环境中引导视障人士需要实时双向交互和安全保障。我们提出了一种力-柔顺模型预测控制（FC-MPC）和机器人-用户控制障碍函数（CBFs），用于六足导盲机器人的力柔顺导航和避障。FC-MPC通过使用机器人的动态模型和递归最小二乘（RLS）方法估计用户施加的力和力矩，然后相应调整机器人的运动来实现双向交互。同时，机器人-用户CBFs通过处理静态和动态障碍物来确保用户和机器人的安全，并采用加权松弛变量来克服复杂动态环境中的可行性问题。我们还采用了一种八向连接DBSCAN方法进行障碍物聚类，将计算复杂度从O(n2)降低到大约O(n)，从而在资源受限的车载机器人计算机上实现实时局部感知。障碍物使用最小边界椭圆（MBEs）进行建模，并通过卡尔曼滤波预测其轨迹。该系统在HexGuide机器人上实现，无缝集成了力柔顺性、自主导航和避障功能。实验结果表明，该系统能够在复杂环境导航过程中适应用户力指令，同时保证用户和机器人的安全。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [447] [Opti-Acoustic Scene Reconstruction in Highly Turbid Underwater Environments](https://arxiv.org/abs/2508.03408)
> *高浊度水下环境中的光声场景重建*

*Ivana Collado-Gonzalez, John McConnell, Paul Szenher, Brendan Englot* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 光声融合, 场景重建, 水下机器人, 浊水环境, 声纳视觉

**Comment:** 

> **TL;DR:** 本文提出了一种实时光声场景重建方法，专门针对高浊度水下环境进行了优化，通过结合视觉和声纳数据，克服了单一传感器在浊水中的局限性，并得到了实验验证。

**AI_Comments:** 该论文提出了一种创新的光声融合方法，有效解决了高浊度水下环境中场景重建的挑战。其关键创新在于避免了传统视觉方法中对点特征的依赖，转而使用区域匹配，并巧妙结合了声纳的深度优势和视觉的高程信息。该方法对于水下机器人导航和探测具有重要意义，开源代码的举措也有助于推动相关领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 水下机器人近距离导航时，场景重建能力至关重要。然而，单目视觉重建方法在浊水环境中不可靠且缺乏深度尺度信息；声纳虽然对浊水和非均匀光照鲁棒，但分辨率低且存在高程模糊。因此，需要一种能在高浊度水下环境中有效进行场景重建的方法。

**Method:** 本文提出了一种实时光声场景重建方法。该策略避免了在视觉数据中识别点特征，转而识别数据中的感兴趣区域。然后，将图像中相关的区域与对应的声纳数据进行匹配。通过利用声纳的距离数据和相机图像的高程数据来获得重建。

**Result:** 通过与不同浊度水平下的其他基于视觉和基于声纳的方法进行实验比较，以及在码头环境中进行的现场测试，验证了所提出方法的有效性。

**Conclusion:** 所提出的光声场景重建方法在高浊度水下环境中表现出有效性，克服了单一视觉或声纳方法的局限性。

> **ai_Abstract:** 本文提出了一种针对高浊度水下环境优化的实时光声场景重建方法。该方法结合了视觉和声纳数据，通过识别视觉数据中的感兴趣区域并将其与声纳数据匹配，利用声纳的距离信息和相机的海拔信息进行重建。实验和现场测试证明了该方法在浊水环境下的有效性，克服了传统视觉或声纳方法的局限性。

> **摘要翻译:** 场景重建是水下机器人在结构附近导航时必不可少的能力。基于单目视觉的重建方法在浊水中不可靠且缺乏深度尺度信息。声纳对浊水和非均匀光照条件具有鲁棒性，但其分辨率低且存在高程模糊。这项工作提出了一种实时光声场景重建方法，该方法经过专门优化，可在浊水中使用。我们的策略避免了在视觉数据中识别点特征，而是识别数据中的感兴趣区域。然后，我们将图像中相关的区域与对应的声纳数据进行匹配。通过利用声纳的距离数据和相机图像的高程数据来获得重建。在不同浊度水平下与其他基于视觉和基于声纳的方法进行实验比较，以及在码头环境中进行的现场测试，验证了所提出方法的有效性。我们已将代码开源，以促进可重复性并鼓励社区参与。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [475] [DiWA: Diffusion Policy Adaptation with World Models](https://arxiv.org/abs/2508.03645)
> *DiWA：基于世界模型的扩散策略适应*

*Akshay L Chandra, Iman Nematollahi, Chenguang Huang, Tim Welschehold, Wolfram Burgard, Abhinav Valada* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 扩散策略, 世界模型, 离线学习, 机器人技能, 样本效率

**Comment:** Accepted at the 2025 Conference on Robot Learning (CoRL)

> **TL;DR:** DiWA是一个新框架，它利用世界模型完全离线地微调基于扩散的机器人技能，显著提高了样本效率，使其在现实世界机器人学习中更实用、更安全。

**AI_Comments:** DiWA的创新之处在于首次将离线世界模型应用于扩散策略的微调，解决了传统RL方法在扩散策略中存在的样本效率低下和对真实世界交互依赖性过高的问题。通过利用预训练的世界模型进行完全离线学习，DiWA极大地提高了机器人学习的实用性和安全性，为复杂机器人技能的快速适应提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 使用强化学习（RL）微调扩散策略面临巨大挑战：每次动作预测的长时间去噪序列阻碍了有效的奖励传播。此外，标准RL方法需要数百万次真实世界交互，这对实际微调构成了主要瓶颈。尽管现有工作将扩散策略中的去噪过程视为马尔可夫决策过程以实现基于RL的更新，但其对环境交互的强烈依赖仍然效率低下。

**Method:** 我们引入了DiWA，这是一个新颖的框架，它利用世界模型完全离线地使用强化学习微调基于扩散的机器人技能。DiWA通过仅使用在数十万次离线游戏交互中训练一次的世界模型来实现有效适应。

**Result:** 与需要数百万次环境交互才能微调一系列机器人技能的无模型方法不同，DiWA实现了有效适应，并显著提高了样本效率，使其在现实世界机器人学习中更加实用和安全。在具有挑战性的CALVIN基准测试中，DiWA仅使用离线适应就在八项任务中提高了性能，并且比无模型基线所需的物理交互次数少几个数量级。据我们所知，这是首次演示使用离线世界模型微调现实世界机器人技能的扩散策略。

**Conclusion:** DiWA框架成功利用离线世界模型微调扩散策略，显著提高了样本效率，使其在现实世界机器人学习中更具实用性和安全性。

> **ai_Abstract:** 本研究提出了DiWA，一个利用世界模型完全离线地微调基于扩散的机器人技能的新框架。针对现有扩散策略微调中样本效率低、对环境交互依赖性强的问题，DiWA通过仅使用少量离线交互训练一次的世界模型，显著提高了样本效率。实验结果表明，DiWA在CALVIN基准测试中表现出色，仅通过离线适应就在多个任务上提升了性能，并且比现有方法所需的物理交互次数少几个数量级，从而使其在现实世界机器人学习中更实用、更安全。这是首次利用离线世界模型微调用于现实世界机器人技能的扩散策略。

> **摘要翻译:** 使用强化学习（RL）微调扩散策略面临巨大挑战。每次动作预测的长时间去噪序列阻碍了有效的奖励传播。此外，标准RL方法需要数百万次真实世界交互，这对实际微调构成了主要瓶颈。尽管现有工作将扩散策略中的去噪过程视为马尔可夫决策过程以实现基于RL的更新，但其对环境交互的强烈依赖仍然效率低下。为了弥合这一差距，我们引入了DiWA，这是一个新颖的框架，它利用世界模型完全离线地使用强化学习微调基于扩散的机器人技能。与需要数百万次环境交互才能微调一系列机器人技能的无模型方法不同，DiWA通过仅使用在数十万次离线游戏交互中训练一次的世界模型来实现有效适应。这显著提高了样本效率，使该方法在现实世界机器人学习中更加实用和安全。在具有挑战性的CALVIN基准测试中，DiWA仅使用离线适应就在八项任务中提高了性能，并且比无模型基线所需的物理交互次数少几个数量级。据我们所知，这是首次演示使用离线世界模型微调现实世界机器人技能的扩散策略。我们已将代码公开在 https://diwa.cs.uni-freiburg.de。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [482] [Residual Neural Terminal Constraint for MPC-based Collision Avoidance in Dynamic Environments](https://arxiv.org/abs/2508.03428)
> *动态环境下基于MPC的避碰残差神经网络终端约束*

*Bojan Derajić, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Wolfgang Hönig* | **Category: cs.RO, cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** MPC, 碰撞避免, 残差神经网络, Hamilton-Jacobi, 安全集

**Comment:** 

> **TL;DR:** 提出一种基于学习的MPC局部规划器，通过神经网络估计安全集作为终端约束，实现动态环境下高效避碰，性能优于现有方法。

**AI_Comments:** 该论文的创新点在于将复杂的Hamilton-Jacobi (HJ) 可达性分析得到的安全集通过神经网络进行实时近似，并巧妙地利用了HJ价值函数的结构（SDF与残差之差），从而在保证安全性的同时实现实时性。通过引入超网络进一步提升了实时性能和泛化能力，使其在实际应用中更具潜力。其在动态环境避碰中的显著性能提升表明了该方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 实时计算Hamilton-Jacobi (HJ) 可达性分析得到的价值函数以获得安全集是不可行的，因此需要一种实时且能保证安全性的方法来近似这个安全集，并将其应用于MPC的终端约束。

**Method:** 提出一种混合MPC局部规划器。该方法利用Hamilton-Jacobi (HJ) 价值函数可表示为符号距离函数 (SDF) 与一个非负残差函数之差的特性。残差部分被建模为一个输出非负的神经网络，并从SDF中减去，从而得到一个实时价值函数估计，该估计在设计上至少与SDF一样安全。此外，通过超网络参数化神经网络残差以提高实时性能和泛化特性。

**Result:** 在仿真和硬件实验中，与三种现有最先进方法进行比较，所提出的方法成功率比最佳基线提高了30%，同时所需的计算量相似，并产生了高质量（低旅行时间）的解决方案。

**Conclusion:** 该方法能够有效提高动态环境下基于MPC的避碰性能，同时保持计算效率和解决方案质量。

> **ai_Abstract:** 本文提出了一种用于动态环境下避碰的混合MPC局部规划器。该方法通过一个学习到的神经网络来近似时间变化的HJ价值函数，将其作为MPC的终端约束。该神经网络模型巧妙地将价值函数分解为符号距离函数和非负残差，并通过超网络优化进一步提升了实时性能和泛化能力，从而实现实时安全集估计。实验结果表明，该方法在成功率上比现有技术提高了30%，同时保持了计算效率和解的质量。

> **摘要翻译:** 在本文中，我们提出了一种混合MPC局部规划器，该规划器使用基于学习的时变安全集近似，该安全集源自局部观测并作为MPC终端约束应用。该集合可以表示为通过Hamilton-Jacobi (HJ) 可达性分析计算的价值函数的零超水平集，这在实时应用中是不可行的。我们利用HJ价值函数可以表示为相应符号距离函数 (SDF) 与非负残差函数之差的特性。残差部分被建模为一个具有非负输出的神经网络，并从计算出的SDF中减去，从而得到一个实时价值函数估计，该估计在设计上至少与SDF一样安全。此外，我们通过超网络参数化神经网络残差，以提高实时性能和泛化特性。所提出的方法在仿真和硬件实验中与三种最先进的方法进行了比较，与最佳基线相比，成功率提高了30%，同时所需的计算量相似，并产生了高质量（低旅行时间）的解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [516] [CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation](https://arxiv.org/abs/2508.03526)
> *CollaBot：视觉语言引导的同步协作操作*

*Kun Song, Shentao Ma, Gaoming Chen, Ninglong Jin, Guangbao Zhao, Mingyu Ding, Zhenhua Xiong, Jia Pan* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 多机器人, 协作操作, 视觉语言, 抓取规划, CollaBot

**Comment:** 9 pages,5 figures

> **TL;DR:** CollaBot提出了一个通用的框架，用于多机器人协作操作大型物体，通过场景分割、协作抓取和两阶段规划实现，实验表明其有效性。

**AI_Comments:** CollaBot的创新之处在于其提出了一个通用的多机器人协作操作框架，能够处理大型物体，并结合了视觉语言模型进行场景理解。其分解任务和两阶段规划的方法使得系统更具鲁棒性。尽管52%的成功率可能还有提升空间，但它在不同配置下的泛化能力预示着其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 机器人领域的一个核心研究课题是如何使系统与物理世界交互。传统操作任务主要集中在小型物体，但在工厂或家庭环境中，大型物体（如桌子）的移动需求日益增加，这需要多机器人系统协作。现有研究缺乏一个可以扩展到任意大小机器人并泛化到各种任务的框架。

**Method:** CollaBot是一个用于同步协作操作的通用框架。首先，使用SEEM进行场景分割和目标物体的点云提取。然后，提出一个协作抓取框架，将任务分解为局部抓取姿态生成和全局协作。最后，设计一个两阶段规划模块，生成无碰撞轨迹来完成任务。

**Result:** 实验表明，在不同数量的机器人、物体和任务下，该框架的成功率为52%。

**Conclusion:** 实验结果表明，所提出的CollaBot框架在多机器人协作操作中是有效的。

> **ai_Abstract:** CollaBot是一个针对多机器人同步协作操作大型物体的通用框架。该框架结合了视觉语言模型（SEEM）进行场景理解和点云提取，提出了一种将任务分解为局部抓取姿态生成和全局协作的抓取策略，并设计了一个两阶段的轨迹规划模块以确保无碰撞操作。实验结果显示，在处理不同机器人数量、物体和任务时，CollaBot实现了52%的成功率，证明了其有效性和通用性。

> **摘要翻译:** 机器人领域的一个核心研究课题是如何使用该系统与物理世界交互。传统的操作任务主要集中在小型物体。然而，在工厂或家庭环境中，通常需要移动大型物体，例如移动桌子。这些任务通常需要多机器人系统协同工作。以往的研究缺乏一个可以扩展到任意大小的机器人并推广到各种任务的框架。在这项工作中，我们提出了CollaBot，一个用于同步协作操作的通用框架。首先，我们使用SEEM进行场景分割和目标物体的点云提取。然后，我们提出了一个协作抓取框架，它将任务分解为局部抓取姿态生成和全局协作。最后，我们设计了一个两阶段规划模块，可以生成无碰撞的轨迹来完成此任务。实验表明，在不同数量的机器人、物体和任务下，成功率为52%，这表明了所提出框架的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [546] [Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions](https://arxiv.org/abs/2508.03541)
> *用于自动递送机器人与行人交互的基于视觉的感知系统*

*Ergi Tushe, Bilal Farooq* | **Category: cs.RO, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 自动递送机器人, 视觉感知, 行人交互, 姿态估计, 深度感知

**Comment:** 

> **TL;DR:** 该研究开发了一种基于单目视觉的感知系统，用于自动递送机器人在行人密集区域安全导航，通过整合人体姿态估计和深度信息，显著提升了行人轨迹预测和身份保持能力。

**AI_Comments:** 该论文创新性地将人体姿态估计和深度信息整合到基于单目视觉的机器人感知系统中，以提升自动递送机器人在复杂行人环境中的导航能力。其重要性在于为未来自动驾驶和递送机器人的安全、高效及社会接受度提供了实际可行的技术方案，尤其强调了对弱势群体的识别，体现了对社会包容性的关注。

<details>
  <summary>Details</summary>

**Motivation:** 自动递送机器人（ADRs）在行人密集的城市空间中集成时，在安全、高效和社交可接受的导航方面面临独特的挑战。

**Method:** 开发了一个完整的基于单目视觉传感器的多行人检测与跟踪、姿态估计和单目深度感知系统。利用真实世界的MOT17数据集序列，将人体姿态估计和深度线索整合到行人轨迹预测和身份保持中。

**Result:** 结果显示出可衡量的改进，包括身份保持（IDF1）提升高达10%，多目标跟踪准确性（MOTA）提升7%，即使在具有挑战性的场景下，检测精度也持续超过85%。系统还能识别弱势行人群体。

**Conclusion:** 该研究表明，整合人体姿态估计和深度线索能显著增强基于视觉的感知系统在自动递送机器人与行人交互中的性能，尤其是在拥挤和遮挡环境下，有助于实现更具社会意识和包容性的机器人行为。

> **ai_Abstract:** 本研究开发了一种基于单目视觉的感知系统，旨在解决自动递送机器人在行人密集城市空间中安全高效导航的挑战。该系统整合了多行人检测与跟踪、姿态估计和单目深度感知功能。利用MOT17数据集，实验证明结合人体姿态估计和深度信息，能显著提高行人轨迹预测和身份保持的准确性，即使在遮挡和拥挤环境下也能保持高性能，并能识别弱势行人，从而促进机器人更具社会意识的交互行为。

> **摘要翻译:** 自动递送机器人（ADRs）融入行人密集的城市空间，在安全、高效和社交可接受的导航方面带来了独特的挑战。我们开发了一个完整的基于单一视觉传感器的多行人检测与跟踪、姿态估计和单目深度感知管线。本研究利用真实世界的MOT17数据集序列，展示了如何整合人体姿态估计和深度线索，即使在遮挡和密集人群下，也能增强行人轨迹预测和身份保持。结果显示出可衡量的改进，包括身份保持（IDF1）提升高达10%，多目标跟踪准确性（MOTA）提升7%，即使在具有挑战性的场景下，检测精度也持续超过85%。值得注意的是，该系统能够识别弱势行人群体，支持更具社会意识和包容性的机器人行为。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [565] [AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed](https://arxiv.org/abs/2508.02947)
> *AeroSafe：基于气溶胶停留时间分析和机器人咳嗽模拟器测试平台的移动式室内空气净化*

*M Tanjid Hasan Tonmoy, Rahath Malladi, Kaustubh Singh, Forsad Al Hossain, Rajesh Gupta, Andrés E. Tejada-Martínez, Tauhidur Rahman* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 室内空气净化, 气溶胶, 机器人咳嗽模拟器, 数字孪生, 空气质量

**Comment:** Accepted at IEEE International Conference on Robotics and Automation
  (ICRA) 2025. Author Accepted Manuscript

> **TL;DR:** AeroSafe系统利用机器人咳嗽模拟器和数字孪生模型，通过分析气溶胶停留时间，实现移动式室内空气净化，有效应对呼吸道气溶胶风险。

**AI_Comments:** 本文提出了一种创新的、实用的室内空气净化方法，通过结合机器人模拟和数字孪生技术，解决了传统空气净化器对呼吸道气溶胶响应不足的问题。其亮点在于实时动态响应和对复杂气溶胶动力学的预测能力，有望显著提升高风险环境下的空气安全。

<details>
  <summary>Details</summary>

**Motivation:** 室内空气质量对居住者安全和健康至关重要，尤其是在空降疾病背景下。现有便携式空气净化器常忽略咳嗽产生的呼吸道气溶胶浓度，在高暴露环境（如医疗机构和公共场所）构成风险。本文旨在解决这一不足，提升室内空气净化系统效率。

**Method:** 本文提出了AeroSafe系统，通过一个机器人咳嗽模拟器测试平台和一个基于数字孪生的气溶胶停留时间分析来增强室内空气净化系统的效率。该系统包含一个机器人双代理物理模拟器：一个模拟咳嗽事件的可移动人体模型和一个自主响应气溶胶的便携式空气净化器。模拟器生成的数据用于训练一个数字孪生模型，该模型结合了基于物理的隔室模型与机器学习方法（使用长短期记忆（LSTM）网络和图卷积层）。

**Result:** 实验结果表明，该模型能够预测气溶胶浓度动态，平均停留时间预测误差在35秒以内。所提出的系统实时干预策略优于静态空气过滤器放置。

**Conclusion:** AeroSafe系统通过其实时干预策略，在减轻空气传播病原体风险方面展现出巨大潜力。

> **ai_Abstract:** 本文提出了AeroSafe系统，旨在通过机器人咳嗽模拟器和数字孪生模型提升室内空气净化效率，特别关注由咳嗽产生的呼吸道气溶胶。该系统利用一个结合可移动人体模型和自主净化器的机器人双代理模拟器生成数据，并训练一个结合物理模型和机器学习（LSTM、图卷积）的数字孪生模型。实验证明，该模型能准确预测气溶胶浓度动态，且其实时干预策略优于传统静态过滤器，有效降低了空气传播病原体风险。

> **摘要翻译:** 室内空气质量在居住者安全和福祉中扮演着重要角色，尤其是在空降疾病背景下。本文介绍了AeroSafe，一种旨在通过机器人咳嗽模拟器测试平台和基于数字孪生的气溶胶停留时间分析来提高室内空气净化系统效率的新颖方法。当前的便携式空气过滤器通常忽视咳嗽产生的呼吸道气溶胶浓度，特别是在医疗机构和公共场所等高暴露环境中构成风险。为解决这一空白，我们提出了一个机器人双代理物理模拟器，包括一个模拟咳嗽事件的可移动人体模型和一个自主响应气溶胶的便携式空气净化器。该模拟器生成的数据用于训练一个数字孪生模型，该模型结合了基于物理的隔室模型与机器学习方法，使用长短期记忆（LSTM）网络和图卷积层。实验结果表明，该模型能够预测气溶胶浓度动态，平均停留时间预测误差在35秒以内。所提出的系统实时干预策略优于静态空气过滤器放置，展示了其在减轻空气传播病原体风险方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [579] [Online Learning for Vibration Suppression in Physical Robot Interaction using Power Tools](https://arxiv.org/abs/2508.03559)
> *使用电动工具进行物理机器人交互中振动抑制的在线学习*

*Gokhan Solak, Arash Ajoudani* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 振动抑制, 在线学习, 协作机器人, BMFLC, 自适应控制

**Comment:** Submitted, under review

> **TL;DR:** 本文提出了一种带有自适应步长和阻尼机制的BMFLC方法，用于在线抑制机器人与电动工具交互时的振动，通过仿真和实际实验证明其在收敛速度、抗噪声能力和抑制率方面的改进。

**AI_Comments:** 该论文通过引入创新的自适应步长和基于逻辑函数的阻尼机制来改进BMFLC算法，这对于实际应用中抵抗噪声和实现更快的收敛至关重要。将其应用于机器人与电动工具在建筑工地等挑战性环境中的交互，突显了其实际意义。对在线学习的关注也是一个关键优势，能够实现适应性。

<details>
  <summary>Details</summary>

**Motivation:** 振动抑制是协作机器人在建筑工地等挑战性环境中部署的重要能力，尤其是在电动工具等外部源引起的振动情况下。

**Method:** 采用带限多傅里叶线性组合器（BMFLC）算法进行在线振动学习并通过前馈力控制进行抵消。提出了一种阻尼BMFLC方法，通过新颖的自适应步长方法扩展了BMFLC，并引入了基于逻辑函数的阻尼机制，以改善收敛时间和抗噪声能力。

**Result:** 仿真实验表明，与原始BMFLC及其递归最小二乘和卡尔曼滤波扩展相比，本文方法提高了抑制率，并且效率更高。在实际抛光实验中进一步验证了该方法的有效性。

**Conclusion:** 本文提出的阻尼BMFLC方法能有效抑制物理机器人交互中的振动，与现有方法相比，具有更好的性能和效率。

> **ai_Abstract:** 本文旨在解决协作机器人在与电动工具交互时遇到的振动抑制问题，这对于在建筑工地等恶劣环境中部署的机器人至关重要。研究人员提出了一种新颖的阻尼带限多傅里叶线性组合器（BMFLC）算法。该算法通过引入自适应步长和基于逻辑函数的阻尼机制，显著提高了算法的收敛速度、抗噪声能力并允许更大的学习率。通过对逼真时变多频率振动的广泛模拟实验和真实世界的抛光实验进行评估，结果表明，与原始BMFLC及其递归最小二乘和卡尔曼滤波扩展相比，所提出的方法在振动抑制率和效率方面均表现出卓越的性能。

> **摘要翻译:** 振动抑制是部署在建筑工地等挑战性环境中的协作机器人的一项重要能力。我们研究了由电动工具等外部来源引起的振动的主动抑制。我们采用带限多傅里叶线性组合器（BMFLC）算法在线学习振动，并通过前馈力控制对其进行抵消。我们提出了阻尼BMFLC方法，通过一种新颖的自适应步长方法扩展了BMFLC，该方法改善了收敛时间和抗噪声能力。我们基于逻辑函数的阻尼机制减少了噪声的影响，并实现了更大的学习率。我们在具有逼真时变多频率振动的大量模拟实验和真实世界的物理交互实验中评估了我们的方法。模拟实验表明，与原始BMFLC及其递归最小二乘和基于卡尔曼滤波的扩展相比，我们的方法提高了抑制率。此外，我们的方法比后两者效率更高。我们进一步在真实世界的抛光实验中验证了我们方法的有效性。补充视频可在 https://youtu.be/ms6m-6JyVAI 观看。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [614] [Inland-LOAM: Voxel-Based Structural Semantic Mapping for Inland Waterways](https://arxiv.org/abs/2508.03672)
> *内陆LOAM：用于内陆水道的基于体素的结构化语义建图*

*Zhongbi Luo, Yunjia Wang, Jan Swevers, Peter Slaets, Herman Bruyninckx* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 激光雷达SLAM, 内陆水道, 语义建图, 垂直漂移, 体素分析

**Comment:** 

> **TL;DR:** Inland-LOAM是一个针对内陆水道的激光雷达SLAM框架，通过改进特征提取和水面约束解决垂直漂移问题，并能生成结构化2D语义地图和提取岸线，提供比现有方法更优的定位精度和实用的导航数据。

**AI_Comments:** Inland-LOAM的创新点在于结合了改进的特征提取和水面平面约束来解决水域环境中激光雷达SLAM特有的垂直漂移问题，并引入了基于体素的几何分析来生成结构化语义地图，这对于内陆水道的自主导航至关重要。其能够实时计算导航参数（如桥梁净空）并自动提取岸线的功能，显示了其强大的实用性。该研究对于推动内陆水路运输的自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有内陆水道图表（IENC）缺乏实时细节，传统激光雷达SLAM在水域环境中失效，导致垂直漂移和非语义地图，阻碍了自主导航，因此需要准确的地理空间信息。

**Method:** 本文提出了Inland-LOAM，一个用于水域的激光雷达SLAM框架。它使用改进的特征提取和水面平面约束来减轻垂直漂移。一个新颖的流程将3D点云通过基于体素的几何分析转换为结构化2D语义地图，从而实现导航参数（如桥梁净空）的实时计算。此外，一个自动化模块提取岸线并将其导出为轻量级、与IENC兼容的格式。

**Result:** 在真实世界数据集上的评估显示，Inland-LOAM的定位精度优于最先进的方法。生成的语义地图和岸线与真实世界条件一致，为增强态势感知提供了可靠数据。

**Conclusion:** Inland-LOAM通过提供高精度的定位和实用的语义地图，有效解决了内陆水道自主导航中遇到的挑战，显著提高了态势感知能力。

> **ai_Abstract:** 本文提出Inland-LOAM，一个针对内陆水道的激光雷达SLAM框架，旨在解决现有图表信息不足和传统SLAM在水域中失效的问题。该框架通过改进特征提取和引入水面平面约束来消除垂直漂移，并利用基于体素的几何分析将3D点云转换为结构化2D语义地图，以实时计算导航参数。此外，它还能自动化提取岸线并兼容IENC格式。实验证明，Inland-LOAM在定位精度上优于现有方法，并能生成与实际情况吻合的语义地图和岸线，为内陆水道的自主导航提供了可靠的数据支持。

> **摘要翻译:** 准确的地理空间信息对于安全、自主的内陆水路运输（IWT）至关重要，因为现有图表（IENC）缺乏实时细节，且传统激光雷达SLAM在水域环境中失效。这些挑战导致垂直漂移和非语义地图，阻碍了自主导航。
本文介绍了Inland-LOAM，一个用于水域的激光雷达SLAM框架。它使用改进的特征提取和水面平面约束来减轻垂直漂移。一个新颖的流程通过基于体素的几何分析将3D点云转换为结构化2D语义地图，从而实现桥梁净空等导航参数的实时计算。一个自动化模块提取岸线并将其导出为轻量级、与IENC兼容的格式。
在真实世界数据集上的评估显示，Inland-LOAM的定位精度优于最先进的方法。生成的语义地图和岸线与真实世界条件一致，为增强态势感知提供了可靠数据。代码和数据集将公开发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [653] [GACL: Grounded Adaptive Curriculum Learning with Active Task and Performance Monitoring](https://arxiv.org/abs/2508.02988)
> *GACL：基于接地自适应课程学习的活跃任务与性能监控*

*Linji Wang, Zifan Xu, Peter Stone, Xuesu Xiao* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 课程学习, 机器人, 自适应学习, 任务设计, 性能监控

**Comment:** 7 pages, IROS 2025

> **TL;DR:** GACL是一个为机器人任务设计的自适应课程学习框架，通过处理复杂任务空间、主动性能跟踪和保持目标域相关性，提高了复杂机器人任务的成功率。

**AI_Comments:** GACL的创新在于其结合了自适应课程生成、主动性能监控和目标域接地，有效解决了机器人领域课程学习的实际挑战。这对于减少手动工程量和提高训练效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的课程学习方法在机器人任务中主要依赖手动设计，耗时且可能次优。自动化课程学习在简单领域成功，但在机器人任务中面临复杂任务空间和有限样本下目标域相关性维护的挑战。

**Method:** 本文提出了GACL（Grounded Adaptive Curriculum Learning）框架，包含三项关键创新：1) 一种能够持续处理复杂机器人任务设计的任务表示；2) 一种允许根据机器人当前能力生成自适应课程的主动性能跟踪机制；3) 一种通过在参考任务和合成任务之间交替采样来保持目标域相关性的接地方法。

**Result:** GACL在受限环境下的轮式导航和挑战性3D受限空间中的四足机器人运动任务上进行了验证，成功率分别比现有最佳方法高出6.8%和6.1%。

**Conclusion:** GACL框架通过其创新的任务表示、主动性能跟踪和接地方法，有效解决了复杂机器人任务中课程学习的挑战，显著提高了任务的成功率。

> **ai_Abstract:** GACL是一个为复杂机器人任务设计的自适应课程学习框架，旨在解决传统手动课程设计效率低和自动化课程学习在复杂任务中面临的挑战。该框架引入了创新的任务表示、主动性能跟踪机制和接地方法，以处理复杂任务空间并保持目标域相关性。实验结果表明，GACL在轮式导航和四足机器人运动任务上均显著优于现有最佳方法，提高了任务成功率。

> **摘要翻译:** 课程学习已成为训练复杂机器人任务的一种有前景的方法，但当前应用主要依赖手动设计的课程，这需要大量的工程投入，并且可能受到主观和次优的人为设计选择的影响。虽然自动化课程学习在网格世界和游戏等任务分布易于指定的简单领域取得了成功，但机器人任务面临独特的挑战：它们需要处理复杂的任务空间，同时通过有限的样本维持对仅部分已知目标域分布的相关性。为此，我们提出了接地自适应课程学习（GACL），一个专门为机器人课程学习设计的框架，具有三项关键创新：(1) 一种能够持续处理复杂机器人任务设计的任务表示，(2) 一种允许根据机器人当前能力生成自适应课程的主动性能跟踪机制，以及(3) 一种通过在参考任务和合成任务之间交替采样来保持目标域相关性的接地方法。我们在受限环境下的轮式导航和挑战性3D受限空间中的四足机器人运动任务上验证了GACL，成功率分别比每个领域的现有最佳方法高出6.8%和6.1%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [684] [Real-Time Sense and Detect of Drones Using Deep Learning and Airborne LiDAR](https://arxiv.org/abs/2310.09589)
> *基于深度学习和机载激光雷达的无人机实时感知与探测*

*Manduhu Manduhu, Alexander Dow, Petar Trslic, Gerard Dooly, Benjamin Blanck, James Riordan* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 无人机群探测, 机载激光雷达, 3D深度学习, 稀疏卷积, 数字孪生

**Comment:** 

> **TL;DR:** 该研究提出了一种创新的机载激光雷达（LiDAR）结合3D深度学习模型，用于实时探测和定位无人机群，解决了传统依赖外部系统（如GNSS）的导航方式的脆弱性。通过改进的稀疏卷积和数字孪生技术生成训练数据，该模型在实际测试中取得了优异的性能（召回率>80%，精确率>96%），并结合跟踪算法有效监控多无人机间的安全距离。

**AI_Comments:** 这项研究解决了无人机群安全运行中的一个关键挑战，即在近距离飞行时避免碰撞。通过结合机载LiDAR和先进的3D深度学习技术，该方法提供了一种比依赖外部导航系统更鲁棒的解决方案。提出的稀疏卷积和数字孪生数据增强技术是该研究的创新点，使得模型在实际应用中表现出色。然而，该方法在复杂天气条件下的性能以及对LiDAR传感器成本和功耗的影响有待进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 为了确保无人机群在超视距（BVLOS）安全运行，需要减少无人机之间近距离飞行的碰撞风险，而依赖预规划轨迹、卫星和网络连接以及GNSS定位的合作导航策略容易失败。因此，无人机自带的感知和探测能力是实现无人机间分离、冲突避免和碰撞规避的关键。

**Method:** 提出了一种基于机载激光雷达（LiDAR）的无人机群探测和定位解决方案，采用了3D深度学习模型。该模型通过垂直扩展扫描空间来适应空中对飞行的无人机场景，并引入了一种新的稀疏卷积来加速神经网络中最耗时的骨干层。同时，利用数字孪生（Digital Twin）技术生成高保真的合成数据来增强真实数据集，以收集安全关键的近距离多无人机操作训练数据。最后，结合跟踪-检测算法来监控无人机间的间隔。

**Result:** 在真实世界数据集的测试中，该模型实现了超过80%的召回率和96%的精确率。通过集成跟踪-检测算法，该系统能够有效监控具有挑战性环境中多架无人机之间的分离距离。

**Conclusion:** 该研究成功开发了一种基于机载激光雷达和3D深度学习的无人机实时感知与探测系统，显著提高了无人机群在近距离操作中的安全性，为超视距飞行提供了可靠的保障。

> **ai_Abstract:** 该论文介绍了一种创新的无人机群探测与定位方法，利用机载激光雷达（LiDAR）和3D深度学习模型实现实时感知。该方法通过改进模型结构（稀疏卷积）和数据生成技术（数字孪生）来解决无人机近距离飞行中的安全问题，并在实际测试中取得了高精度和高召回率，为无人机群的安全运行提供了有效解决方案。

> **摘要翻译:** 为了确保无人机群在超视距（BVLOS）安全运行，需要采取多重保障措施，以降低无人机在近距离场景下飞行的碰撞风险。依赖预规划轨迹、持续的卫星和网络连接以及可靠的全球导航卫星系统（GNSS）定位的合作导航和飞行协调策略，在面对故障时非常脆弱。无人机嵌入式感知和探测提供了无人机之间用于冲突避免和碰撞规避的全面分离模式。本文提出了首个基于机载激光雷达的无人机群探测和定位解决方案，采用了3D深度学习模型。通过垂直扩展扫描空间，该模型适应了空对空无人机场景。提出了一种新的稀疏卷积，用于加速神经网络中最耗时的骨干层。为了收集安全关键的近距离多无人机操作训练数据，利用了数字孪生（Digital Twin）场景来用高保真的合成数据扩充真实数据集。训练好的模型在真实世界数据集上的测试，实现了超过80%的召回率和96%的精确率。通过结合跟踪-检测算法，该系统能够可靠地监控具有挑战性环境中多架无人机之间的分离距离。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [718] [Opt-in Camera: Person Identification in Video via UWB Localization and Its Application to Opt-in Systems](https://arxiv.org/abs/2409.19891)
> *选择加入摄像头：通过UWB定位和选择加入系统应用进行视频中的人物识别*

*Matthew Ishige, Yasuhiro Yoshimura, Ryo Yonetani* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 选择加入摄像头, UWB定位, 隐私保护, 人员识别, 轨迹匹配

**Comment:** IROS 2025

> **TL;DR:** 该研究提出了一种名为“opt-in camera”的隐私保护摄像系统，利用超宽带（UWB）技术和个人物品上的无线标签来识别和记录自愿参与的个体。

**AI_Comments:** 这项研究提出了一个创新的隐私保护摄像系统概念，利用UWB技术实现了对自愿参与者的精准识别和录制。该系统在处理人群和非视距问题方面表现出色，具有重要的实际应用价值，尤其是在需要兼顾监控和个人隐私的场景中。然而，对于大规模人群或更复杂的环境下的性能表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 为了在保护隐私的前提下，识别和记录特定人群中的个体，尤其是在公共场所。

**Method:** 使用超宽带（UWB）设备和网络摄像头，通过无迹卡尔曼滤波器（UKF）跟踪无线标签的地面位置，并将标签轨迹与视频中的行人跟踪结果进行匹配，以识别标签携带者。该方法还包括一种基于约束线性优化的轨迹匹配技术和一种处理非视距（NLoS）问题的校准技术。

**Result:** 实验证明，该系统能够以10 fps的实时速率进行选择加入录制，在8-23人的拥挤环境中具有可靠的识别准确性。

**Conclusion:** 提出的opt-in camera系统能够有效地在人群中识别和记录自愿参与的个体，实现了隐私保护的视频录制。

> **ai_Abstract:** 该研究提出了一种名为“opt-in camera”的隐私保护摄像系统，利用超宽带（UWB）定位技术和附着在个人物品上的无线标签来识别自愿被录制的个体。系统通过跟踪UWB标签的位置并将其与视频中的行人进行匹配，实现了在人群中对特定个体的实时识别。实验结果表明，该系统在拥挤环境中具有较高的准确性和实时性。

> **摘要翻译:** 本篇论文提出了opt-in camera，一种隐私保护摄像系统的概念，该系统能够仅记录人群中明确同意被录制的特定个体。我们的系统利用附着在个人物品上的移动无线通信标签，作为opt-in的证明以及在视频片段中定位标签携带者的一种方式。具体来说，首先利用无迹卡尔曼滤波器（UKF）随时间跟踪无线标签的地面位置。然后，将标签轨迹与视频中行人的视觉跟踪结果进行匹配，以识别标签携带者。技术上，我们设计了一种基于约束线性优化的专用轨迹匹配技术，以及一种新颖的校准技术，该技术处理无线标签-摄像头校准和UKF的超参数调整，从而减轻了无线本地化中的非视距（NLoS）问题。我们使用超宽带（UWB）设备和现成的网络摄像头实现了所提出的opt-in camera系统。实验结果表明，我们的系统能够在拥挤环境中以10 fps的实时速率执行opt-in录制，并对8-23人进行可靠的身份识别。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [750] [Why Evolve When You Can Adapt? Post-Evolution Adaptation of Genetic Memory for On-the-Fly Control](https://arxiv.org/abs/2508.03600)
> *为何要进化，而不是适应？遗传记忆的即时控制后适应性*

*Hamze Hammami, Eva Denisa Barbulescu, Talal Shaikh, Mouayad Aldada, Muhammad Saad Munawar* | **Category: cs.RO, cs.NE** | **Updated: 2025-08-05**

**Keywords:** 机器人控制, 遗传算法, 赫布塑形, 零样本自适应, 进化机器人学

**Comment:** This work was accepted for presentation at the ALIFE 2025 Conference
  in Kyoto, and will be published by MIT Press as part of the ALIFE 2025
  proceedings

> **TL;DR:** 本研究提出了一种结合遗传算法（GA）和在线赫布塑形（Hebbian plasticity）的零样本自适应机制，用于机器人控制。该机制利用基因型作为记忆，赫布更新作为学习，通过适应度函数动态调整突触权重，使机器人在运行时能应对环境变化，并在任务结束后恢复原有状态，无需额外训练。实验在T迷宫导航任务中验证了该混合控制器的有效性。

**AI_Comments:** 该研究提出了一种新颖的机器人自适应控制方法，通过结合遗传算法和赫布塑形，实现了在运行时动态适应环境变化的能力，并能在任务结束后恢复原有状态。
这种“后适应”机制避免了在每次环境变化时都需要重新进行遗传进化的开销，提高了效率。
方法将记忆（基因型）和学习（赫布更新）分离，并利用适应度函数进行实时调控，具有生物启发性。
实验验证了该方法在T迷宫导航任务中的有效性。
未来的工作可以探索该方法在更复杂环境和机器人任务中的应用，以及对学习和记忆机制的进一步优化。

<details>
  <summary>Details</summary>

**Motivation:** 机器人控制器需要具备像人类突触一样的实时自适应能力，以应对不可预见的挑战。

**Method:** 提出了一种新颖的零样本自适应机制，将标准的遗传算法（GA）控制器与在线赫布塑形相结合。基因型充当记忆，赫布更新负责学习。适应度函数被用作赫布学习的实时缩放因子，允许机器人的神经网络控制器在运行时调整突触权重，而无需额外训练。这种机制增加了一个动态自适应层，仅在运行时激活以处理意外的环境变化。任务结束后，机器人会“遗忘”临时调整，恢复到原始权重，从而保留核心知识。

**Result:** 在改变光照条件和障碍物的T迷宫导航任务中，该混合GA-赫布控制器在e-puck机器人上得到了验证。

**Conclusion:** 本研究提出的混合遗传算法-赫布塑形控制器能够实现机器人的实时自适应，有效应对环境变化，并在任务结束后保留核心知识。

> **ai_Abstract:** 本研究提出了一种创新的零样本自适应机制，将遗传算法（GA）的记忆功能与在线赫布塑形的学习能力相结合，用于机器人控制。
该机制利用基因型作为记忆载体，通过赫布更新进行学习，并利用适应度函数作为实时调整突触权重的因子。
与传统的进化方法不同，该控制器能在运行时动态适应环境变化，并在任务完成后恢复到初始状态，无需额外训练。
实验结果表明，该混合控制器在模拟的T迷宫导航任务中表现出色。

> **摘要翻译:** 想象一个具有像人类突触一样适应能力的机器人控制器，能够实时动态地重塑自身以克服不可预见的挑战。
本论文提出了一种新颖的零样本自适应机制，用于进化机器人学，将标准的遗传算法（GA）控制器与在线赫布塑形相结合。
受生物系统的启发，该方法将学习和记忆分开，基因型充当记忆，赫布更新负责学习。
在我们的方法中，适应度函数被用作赫布学习的实时缩放因子，使机器人的神经网络控制器能够在运行时调整突触权重，而无需额外训练。
这增加了一个动态自适应层，仅在运行时激活以处理意外的环境变化。
任务结束后，机器人会“遗忘”临时调整，恢复到原始权重，从而保留核心知识。
我们在改变光照条件和障碍物的T迷宫导航任务中，在e-puck机器人上验证了这种混合GA-赫布控制器。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [759] [Non-Prehensile Tool-Object Manipulation by Integrating LLM-Based Planning and Manoeuvrability-Driven Controls](https://arxiv.org/abs/2412.06931)
> *非抓取式工具-物体操作：融合基于大语言模型的规划与操控性驱动控制*

*Hoi-Yin Lee, Peng Zhou, Anqing Duan, Wanyu Ma, Chenguang Yang, David Navarro-Alarcon* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 非抓取式操作, 工具使用, 大语言模型, 机器人规划, 操控性控制

**Comment:** 

> **TL;DR:** 该研究提出了一种结合大语言模型（LLM）规划和操控性驱动控制的方法，用于解决机器人非抓取式工具-物体操作的复杂性，特别是双臂机器人的动作协调问题。

**AI_Comments:** 该研究将大语言模型应用于机器人非抓取式工具操作领域，这是一个具有潜力的研究方向。然而，摘要中并未提供具体的实验结果或性能评估，因此其有效性和实际应用效果仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 人类拥有卓越的工具使用能力，这延伸了其能力并增强了与环境的互动。机器人系统也可以通过工具获得类似的能力，但开发这种操控技能仍然是一个开放的研究问题，尤其是规划和协调双臂机器人动作的复杂性。

**Method:** 将大语言模型（LLM）整合到规划和执行过程中，以增强机器人在多样化场景中的操控能力。

**Result:** 未在摘要中提及

**Conclusion:** 未在摘要中提及

> **ai_Abstract:** 本研究旨在解决机器人非抓取式工具-物体操作的挑战，特别是双臂机器人的协调问题。研究提出了一种新方法，将大语言模型（LLM）的规划能力与操控性驱动控制相结合，以提高机器人在复杂场景下的操作灵活性和效率。

> **摘要翻译:** 能够使用工具被广泛认为是跨物种智能的一个标志。
例如，人类在两百多万年的时间里一直展示出使用工具的熟练技巧。
使用工具的能力是无价的，因为它可以延伸生物体的触及范围，并增强其与物体和环境互动 G 的能力。
理解工具-物体-环境之间的几何-机械关系，使某些物种（例如，猿和乌鸦）能够在狭窄受限的空间中获取食物。
物理增强及其相关的非抓取式操控能力也适用于机器人系统。
例如，通过为其配备不同类型的末端执行器，机器人（原则上）可以像生物学上的对应物一样灵巧地与各种形状和质量的物体进行互动（例如，推和翻）。
然而，开发这种操控技能仍然是一个开放的研究问题。
此外，规划工具-物体操控任务的复杂性，尤其是在协调双臂机器人的动作时，带来了巨大的挑战。
为了解决这些复杂性，我们提出将大语言模型（LLM）整合到规划和执行这些复杂操控中，从而增强机器人 G 在多样化场景中的表现能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [765] [Learning User Interaction Forces using Vision for a Soft Finger Exosuit](https://arxiv.org/abs/2508.02870)
> *用于软指部外骨骼的学习视觉交互力方法*

*Mohamed Irfan Refai, Abdulaziz Y. Alkayas, Anup Teejo Mathew, Federico Renda, Thomas George Thuruthel* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 软指部外骨骼, 交互力估计, 基于视觉的学习, 闭环控制, 替代力传感器

**Comment:** 13 pages, 9 figures

> **TL;DR:** 该研究提出了一种基于图像学习的方法，用于估算软指部外骨骼与人体交互的力，实现了对未见过形状和驱动水平的泛化，并成功应用于闭环控制。

**AI_Comments:** 这项研究在解决软体外骨骼力估计的挑战方面取得了显著进展，其基于视觉的学习方法具有新颖性和实用性。该方法在泛化能力和鲁棒性方面的表现尤为突出，为未来开发更智能、更安全的可穿戴辅助设备奠定了基础。然而，在实际应用中，图像质量和计算资源的限制可能仍然是需要考虑的因素。

<details>
  <summary>Details</summary>

**Motivation:** 随着可穿戴辅助设备的软化，需要对它们与人体组织的交互进行建模，以捕捉动态辅助的传递。然而，这些设备的非线性和顺应性使得物理建模和嵌入式传感变得困难。

**Method:** 提出了一种基于图像学习的框架，利用低分辨率灰度图像来估计软指部外骨骼系统的分布式接触力。使用SoRoSim工具箱生成了用于训练的数据集，并评估了模型在泛化能力、对视觉噪声和对比度变化的鲁棒性，以及在闭环控制中的应用。

**Result:** 该方法能够准确估计多个接触点的交互力，并能泛化到未见过的新形状和驱动水平，同时在存在视觉噪声和对比度变化的情况下仍保持鲁棒性。将该模型集成到反馈控制器中，证明了其作为闭环控制的替代力传感器的潜力。

**Conclusion:** 基于视觉的学习方法可以作为一种非侵入式的方法，用于外骨骼的实时力估计，并可作为力传感器的替代方案应用于闭环控制。

> **ai_Abstract:** 本研究提出了一种新颖的基于视觉和学习的框架，用于精确估计软指部外骨骼与人体交互时产生的接触力。该方法利用低分辨率灰度图像，能够处理非线性和顺应性交互，并成功泛化到未见过的情况。研究表明，该方法不仅准确且鲁棒，还能作为一种非侵入式的力传感器集成到闭环控制系统中，为可穿戴辅助设备提供了重要的技术支持。

> **摘要翻译:** 可穿戴辅助设备正变得越来越软。对其与人体组织的界面进行建模对于捕捉动态辅助的传递是必要的。然而，它们的非线性和顺应性使得物理建模和嵌入式传感都具有挑战性。在本研究中，我们开发了一个基于图像、基于学习的框架，用于估计指部外骨骼系统的分布式接触力。我们使用SoRoSim工具箱生成了多样化的外骨骼几何形状和驱动场景数据集用于训练。该方法能够从低分辨率灰度图像中准确估计多个接触点的交互力，能够泛化到未见过的新形状和驱动水平，并且在视觉噪声和对比度变化下保持鲁棒性。我们将该模型集成到反馈控制器中，发现基于视觉的估计器可以作为闭环控制的替代力传感器。这种方法可以作为外骨骼实时力估计的一种非侵入式替代方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [786] [Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles](https://arxiv.org/abs/2508.02873)
> *用于跨不同地面轮廓进行节能垂直跳跃的单腿跳跃机器人的可调腿部刚度*

*Rongqian Chen, Jun Kwon, Kefan Wu, Wei-Hsi Chen* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 可调腿部刚度, 能量效率, 垂直跳跃, 地形适应, 单腿跳跃机器人

**Comment:** 2025 IEEE International Conference on Robotics & Automation (ICRA)

> **TL;DR:** 通过调整腿部刚度，HASTA 机器人可以在不同地面条件下优化垂直跳跃的能量效率和高度。

**AI_Comments:** 这项研究通过引入可调腿部刚度来解决机器人跳跃中的能量效率问题，这是一个有前景的方向。然而，仅在单腿跳跃机器人和垂直跳跃场景下进行测试可能限制了其在更复杂机器人和运动中的应用。未来的研究可以探索多腿机器人和不同类型的运动，以及更广泛的地面条件。

<details>
  <summary>Details</summary>

**Motivation:** 为了在各种地面轮廓（地面刚度和阻尼条件）上优化能量效率，需要一种具有实时可调腿部刚度的垂直跳跃机器人。

**Method:** 设计和实现了 HASTA（具有可调刚度的地形适应性跳跃机器人），并通过实验测试和模拟来调整腿部刚度，以最大化跳跃高度。

**Result:** 研究发现，在给定的地面刚度和阻尼条件下，存在最佳的腿部刚度，可以实现最大化跳跃高度。

**Conclusion:** 可调刚度可在受控的实验条件下提高节能运动能力，并且仿真结果为未来开发用于选择腿部刚度的控制器提供了见解。

> **ai_Abstract:** 该论文介绍了 HASTA 机器人，一种具有可调腿部刚度的单腿跳跃机器人，旨在通过调整刚度来优化在不同地面条件下的能量效率和跳跃高度。实验和模拟结果表明，可调刚度确实可以提高跳跃性能，并为未来的控制器开发提供了见解。

> **摘要翻译:** 我们设计并实现了一个名为 HASTA（Hopper with Adjustable Stiffness for Terrain Adaptation）的垂直跳跃机器人，该机器人具有实时可调的腿部刚度，旨在优化各种地面轮廓（地面刚度和阻尼条件）下的能量效率。通过调整腿部刚度，我们的目标是最大化跳跃高度，这是节能垂直跳跃的关键指标。我们假设，较软的腿部通过最小化渗透和能量损失，在较软、阻尼较大的地面上表现更好，而较硬的腿部通过减少肢体变形和能量耗散，在较硬、阻尼较小的地面上表现更好。通过实验测试和模拟，我们在所选的刚度范围内找到了每种地面刚度和阻尼组合的最佳腿部刚度，使机器人能够在恒定的能量输入下实现最大稳态跳跃高度。这些结果支持我们的假设，即在受控的实验条件下，可调刚度可以提高节能运动能力。此外，仿真还提供了可能有助于未来开发用于选择腿部刚度的控制器。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [801] [Unveiling the Potential of iMarkers: Invisible Fiducial Markers for Advanced Robotics](https://arxiv.org/abs/2501.15505)
> *iMarkers的潜力揭秘：用于高级机器人的隐形定位标记*

*Ali Tourani, Deniz Isinsu Avsar, Hriday Bavle, Jose Luis Sanchez-Lopez, Jan Lagerwall, Holger Voos* | **Category: cs.RO, cs.CV, I.2.10; I.2.9; I.4.8** | **Updated: 2025-08-05**

**Keywords:** 定位标记,机器人,增强现实,隐形标记,计算机视觉

**Comment:** 18 pages, 10 figures, 3 tables

> **TL;DR:** 本研究提出了一种名为iMarkers的新型定位标记，它对人类不可见，但可被配备特殊传感器的机器人检测到，解决了传统标记影响视觉美观的问题，并展示了其在机器人领域的广泛应用潜力。

**AI_Comments:** 这项研究提出了一个关于机器人定位标记的创新性解决方案，通过引入对人类不可见但对机器人可见的iMarkers，解决了传统标记在美学和非侵入性应用方面的局限性。其灵活性和可定制性是该技术的关键优势。然而，需要进一步研究其在复杂现实世界环境中的鲁棒性以及对特定传感器依赖性的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 传统定位标记虽然对机器人和AR应用有益，但因其可见性会破坏环境视觉美观，不适用于非侵入性场景。本研究旨在解决这一问题，提出一种对人类不可见但可被机器人检测到的新型定位标记。

**Method:** 提出了一种名为iMarkers的新型定位标记，该标记对人类不可见，但可被配备特殊传感器的机器人检测到。研究介绍了用于检测iMarkers的硬件设计和软件算法，并对其适应性和鲁棒性进行了评估。

**Result:** 评估结果表明，与传统的（打印的）和混合定位标记相比，iMarkers在检测和识别阶段表现出更高的有效性和适用性，并证实了其在各种机器人场景中的应用能力。

**Conclusion:** iMarkers作为一种对人类不可见的定位标记，能够有效解决传统标记在视觉美观方面的不足，并展现出在机器人领域的广泛应用前景。

> **ai_Abstract:** 本研究介绍了一种名为iMarkers的新型定位标记，它对人类不可见，但可被特定机器人传感器检测到，从而解决了传统定位标记影响环境视觉美观的问题。iMarkers具有生产灵活性，允许定制可见范围和编码算法，并配有专门的检测硬件和软件。评估结果证实了iMarkers在机器人任务中的有效性和鲁棒性。

> **摘要翻译:** 定位标记在各种机器人任务中被广泛使用，有助于增强导航、物体识别和场景理解。尽管它们对机器人和增强现实（AR）应用程序有优点，但由于它们对人类可见，通常会破坏环境的视觉美感，因此不适用于非侵入性用例。为了解决这一差距，本文提出了“iMarkers”——一种创新的、不显眼的定位标记，只能被配备特殊传感器的机器人检测到。这些标记在生产中具有高度灵活性，允许根据各种需求定制其可见范围和编码算法。本文还介绍了用于检测iMarkers的硬件设计和软件算法，强调了它们在检测和识别阶段的适应性和鲁棒性。各种评估已证明iMarkers与传统（印刷）和混合定位标记相比的有效性，并证实了它们在各种机器人场景中的适用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [816] [Co-designing Zoomorphic Robot Concepts for Animal Welfare Education](https://arxiv.org/abs/2508.02898)
> *为动物福利教育共同设计拟人化动物机器人概念*

*Isobel Voysey, Lynne Baillie, Joanne Williams, Michael Herrmann* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 拟人化动物机器人,动物福利教育,参与式设计,儿童互动,情感表达

**Comment:** 

> **TL;DR:** 本研究通过参与式设计工作坊，与动物福利教育者和儿童合作，为动物福利教育设计了拟人化动物机器人。研究确定了机器人的外观、行为、特征和叙事方面的关键需求，并强调了面部特征、尾巴和毛茸茸外观的重要性。研究还提出了一些针对儿童的参与式设计活动，并讨论了在设计过程中达成共识的挑战。

**AI_Comments:** 这项研究在利用技术促进儿童动物福利教育方面具有创新性。通过参与式设计方法，研究确保了最终的机器人设计能够满足目标用户的需求和期望。研究结果为未来设计具有情感表达能力的教育机器人提供了宝贵的见解，尤其是在处理儿童与动物互动和情感交流方面。

<details>
  <summary>Details</summary>

**Motivation:** 动物福利教育可以通过定制机器人帮助儿童了解动物及其行为，从而促进积极、安全的儿童与动物互动。

**Method:** 通过与动物福利教育者和儿童举办参与式设计工作坊，收集他们对拟人化动物机器人的关键需求。

**Result:** 研究确定了拟人化动物机器人的外观、行为、特征和相关叙事概念。研究发现，儿童对不良行为的负面反应、利用面部特征和尾巴传递动物内部状态信号以及采用自然毛茸茸的外观和质地非常重要。此外，研究还提出了一些针对儿童的参与式设计活动，如分支故事板和互动叙事。

**Conclusion:** 本研究通过参与式设计工作坊，成功地从动物福利教育者和儿童的角度确定了拟人化动物机器人的关键设计需求，为动物福利教育提供了新的途径。

> **ai_Abstract:** 本研究旨在通过参与式设计工作坊，与动物福利教育者和儿童共同设计用于动物福利教育的拟人化动物机器人。研究结果强调了机器人的外观、行为和特征，特别是面部表情、尾巴信号以及毛茸茸的质地，对于有效传达动物的情感状态至关重要。此外，研究还提出了一些创新的儿童参与式设计方法，并探讨了在设计过程中平衡不同用户需求所面临的挑战。

> **摘要翻译:** 动物福利教育可以通过定制机器人帮助儿童了解动物及其行为，从而促进积极、安全的儿童与动物互动。为此，我们与动物福利教育者和儿童举办了参与式设计工作坊，以从他们的角度确定拟人化动物机器人的关键需求。我们的研究结果涵盖了拟人化动物机器人的外观、行为和特征，以及围绕该机器人的叙事概念。通过对这两组进行比较和对比，我们发现以下几点的重要性：儿童对不良行为的负面反应；利用面部特征和尾巴提供信号动物内部状态的线索；以及自然、毛茸茸的外观和质地。我们还为与儿童的参与式设计贡献了一些新颖的活动，包括受主题统觉测验启发的 ज्यात分支故事板和互动叙事，并反思了在尽管设计概念有很大重叠的情况下，在两组之间达成共识的一些关键设计挑战。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [820] [SkeNa: Learning to Navigate Unseen Environments Based on Abstract Hand-Drawn Maps](https://arxiv.org/abs/2508.03053)
> *SkeNa：基于抽象手绘地图的未知环境导航学习*

*Haojun Xu, Jiaqi Xiang, Wu Wei, Jinyu Chen, Linqing Zhong, Linjiang Huang, Hongyu Yang, Si Liu* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 具身导航, 手绘地图, 草图导航, SkeNavigator, SoR数据集

**Comment:** 9 pages, 5 figures

> **TL;DR:** 该研究提出了一种名为SkeNa的新型具身导航任务，代理仅使用手绘草图地图在未见过的环境中导航至目标点。为此，研究人员构建了一个包含54k轨迹和草图地图对的大型数据集SoR，并提出了一种名为SkeNavigator的导航框架，通过对齐视觉观测和手绘地图来估计导航目标，同时引入了Ray-based Map Descriptor（RMD）和Dual-Map Aligned Goal Predictor（DAGP）来增强地图特征表示和对齐。SkeNavigator在抽象验证集上的成功率（SPL）比现有方法提高了105%。

**AI_Comments:** 该研究提出了一种新颖的导航任务，并构建了一个大规模数据集，同时提出了一个有效的导航框架。其创新性在于利用抽象的手绘地图进行导航，这更符合人类的实际导航方式。然而，手绘地图的抽象程度对导航性能的影响以及在更复杂、动态环境中的泛化能力仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 人类通常通过绘制草图来提供导航指示，这启发了研究人员探索在未知环境中仅使用手绘草图地图进行导航的可能性。

**Method:** 提出了一种名为SkeNa的具身导航任务，构建了SoR数据集（包含54k轨迹和草图地图对），并设计了SkeNavigator导航框架，该框架使用Ray-based Map Descriptor（RMD）来表示草图地图特征，并利用Dual-Map Aligned Goal Predictor（DAGP）来对齐视觉观测和草图地图特征以预测目标点。

**Result:** SkeNavigator导航框架在抽象验证集上的成功率（SPL）比现有方法提高了105%，证明了其在基于草图导航方面的优越性。

**Conclusion:** SkeNa任务和SkeNavigator框架为基于草图的具身导航研究提供了新的方向和有效的解决方案，并在实际导航任务中取得了显著的性能提升。

> **ai_Abstract:** 本研究提出了Sketch map-based visual Navigation (SkeNa)任务，代理仅依靠手绘草图地图在未知环境中导航。为支持该任务，研究人员创建了包含54k轨迹和草图地图对的大型数据集SoR，并提出SkeNavigator框架，通过对齐视觉信息和草图地图来定位目标。SkeNavigator引入了RMD和DAGP模块，以提升地图特征表示和对齐能力，并在抽象验证集上实现了105%的性能提升。

> **摘要翻译:** 一项典型的策略是根据环境布局绘制路线图。受此启发，我们引入了基于草图地图的视觉导航（SkeNa），这是一项具身导航任务，代理必须仅使用手绘草图地图作为指导，在未见过的环境中到达目标点。为了支持SkeNa的研究，我们提出了一个名为SoR的大型数据集，其中包含71个室内场景的54k个轨迹和草图地图对。在SoR中，我们引入了两个具有不同抽象程度手绘草图的导航验证集，这些验证集根据其对环境中空间尺度的保留程度进行分类，以促进未来的研究。为了构建SoR，我们开发了一个自动草图生成流程，能够有效地将平面图转换为手绘表示。为了解决SkeNa问题，我们提出了SkeNavigator，一个导航框架，它将视觉观测与手绘地图对齐以估计导航目标。它采用基于射线（Ray-based）的地图描述符（RMD）来增强草图地图有效特征表示，使用等距采样点和边界距离。为了改进与视觉观测的对齐，一个双地图对齐目标预测器（DAGP）利用草图地图特征和现场构建的探索地图特征之间的对应关系来预测目标位置并指导导航。SkeNavigator的性能明显优于以往的平面图导航方法，在高度抽象的验证集上的SPL提高了105%。我们的代码和数据集将被公开。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [834] [Context-aware Risk Assessment and Its Application in Autonomous Driving](https://arxiv.org/abs/2508.02919)
> *上下文感知风险评估及其在自动驾驶中的应用*

*Boyang Tian, Weisong Shi* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 上下文感知风险指数, 自动驾驶, 风险评估, 责任敏感安全, 自适应控制

**Comment:** ITSC 2025, 7 pages

> **TL;DR:** 该研究提出了一种名为上下文感知风险指数（CRI）的轻量级模块化框架，用于自动驾驶中的定向风险量化和实时行为调整，并在基准测试中显著提高了安全性。

**AI_Comments:** 该研究提出了一种创新的上下文感知风险指数（CRI）框架，解决了现有自动驾驶风险评估方法的局限性。其模块化设计、实时自适应能力以及在真实基准测试中取得的显著安全改进（如碰撞率降低）使其具有重要的实际应用价值和研究意义。然而，该框架在不同天气条件、传感器故障等极端情况下的鲁棒性有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶风险评估方法存在全局指标解释性差、未集成到实际系统或过于狭窄等问题，需要更精确、实时的风险评估和自适应行为。

**Method:** 提出上下文感知风险指数（CRI）框架，通过目标运动学和空间关系量化定向风险，并利用方向感知空间划分、责任敏感安全（RSS）原则、混合概率-最大融合策略和自适应控制策略进行实时行为调整。

**Result:** 在Bench2Drive基准测试中，CRI将碰撞率降低了19%（p=0.003），每公里碰撞率降低了20%（p=0.004），综合驾驶得分提高了17%（p=0.016），并显著降低了处罚分数（p=0.013），同时决策周期开销低（3.6毫秒）。

**Conclusion:** CRI框架在复杂、高风险环境中显著提高了自动驾驶的安全性、鲁棒性，同时保持了模块化和低运行时开销。

> **ai_Abstract:** 本研究提出了一种名为上下文感知风险指数（CRI）的新型框架，用于自动驾驶中的实时风险评估和自适应控制。CRI通过考虑物体运动学和空间关系来量化定向风险，并利用RSS原则和混合融合策略进行调整。在Bench2Drive基准测试中，CRI显著降低了碰撞率，提高了驾驶得分，并保持了低计算开销，证明了其在提高自动驾驶安全性和鲁棒性方面的有效性。

> **摘要翻译:** 确保自动驾驶安全需要精确的实时风险评估和自适应行为。现有风险估计工作要么输出缺乏可解释性的粗粒度全局场景指标，要么提出未经具体集成到自主系统中的指标，要么仅关注特定的驾驶场景。我们引入了上下文感知风险指数（CRI），一个轻量级的模块化框架，该框架基于目标运动学和空间关系量化定向风险，并实时动态调整控制指令。CRI在动态安全包中使用方向感知空间划分，遵循责任敏感安全（RSS）原则，采用混合概率-最大融合策略进行风险聚合，并通过自适应控制策略进行实时行为调制。我们在包含220个安全关键场景的Bench2Drive基准测试中使用最先进的端到端模型Transfuser++在具有挑战性的路线上评估了CRI。我们的碰撞率指标显示，每条失败路线的车辆碰撞次数减少了19%（p = 0.003），每公里碰撞次数减少了20%（p = 0.004），综合驾驶得分提高了17%（p = 0.016），并且处罚分数有了统计学上的显著降低（p = 0.013），同时运行时开销非常低（每个决策周期3.6毫秒）。这些结果表明，CRI在复杂、风险密集型环境中显著提高了安全性和鲁棒性，同时保持了模块化和低运行时开销。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [842] [16 Ways to Gallop: Energetics and Body Dynamics of High-Speed Quadrupedal Gaits](https://arxiv.org/abs/2503.13716)
> *16种奔跑方式：高速四足步态的能量学与身体动力学*

*Yasser G. Alqaham, Jing Cheng, Zhenyu Gan* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 奔跑步态,能量效率,飞行阶段,四足机器人,轨迹优化

**Comment:** 7 pages, 6 figures, Accepted for IROS 2025

> **TL;DR:** 本研究通过对大量可能的奔跑步态进行分类和分析，发现奔跑步态的能量效率受飞行阶段数量的影响，其中无飞行阶段的奔跑在低速时最优，而双飞行阶段的奔跑在高速时能耗最低。

**AI_Comments:** 该研究系统地分析了四足奔跑步态的能量效率，并提出了飞行阶段数量对能耗影响的关键见解，为机器人设计提供了有价值的参考。研究方法结合了理论建模和仿真验证，具有一定的说服力。然而，研究仅限于A1机器人模型，其普适性有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 奔跑是一种常见的高速四足步态，但其能量特性尚未得到充分探索。

**Method:** 本研究系统分析了大量可能的奔跑步态，根据每个步态的飞行阶段数量和前后腿的相位关系进行分类。研究人员使用A1四足机器人作为模型，将奔跑动力学建模为混合动力系统，并采用轨迹优化（TO）方法来最小化不同速度下的运输成本（CoT）。最后，在Gazebo仿真环境中，使用基于二次规划（QP）的控制器验证了这些发现。

**Result:** 研究结果表明，旋转和横向奔跑的落脚点顺序在能量上没有本质区别，尽管身体的偏航和滚动运动有所不同。然而，飞行阶段的数量显著影响能量效率：在低速时，无飞行阶段的奔跑是最佳选择；而在高速时，具有两个飞行阶段的奔跑可以最大限度地降低能量消耗。

**Conclusion:** 本研究揭示了奔跑步态的能量效率与飞行阶段数量的关系，为未来四足机器人的设计提供了参考，使其能够适应不同的速度并实现节能的步态转换。

> **ai_Abstract:** 本研究对四足奔跑步态进行了系统分析，发现奔跑的能量效率与飞行阶段的数量密切相关。研究结果表明，低速时无飞行阶段的奔跑最节能，而高速时双飞行阶段的奔跑最为高效。这些发现有助于理解和设计更节能的四足机器人。

> **摘要翻译:** 奔跑是一种常见的高速步态，在动物和四足机器人中都很普遍，但其能量特性仍有待充分探索。本研究通过遵循希尔德布兰德不对称步态框架，根据每个步态的飞行阶段数量和前后腿的相位关系，对大量可能的奔跑步态进行了系统分析。我们使用Unitree的A1四足机器人，将奔跑动力学建模为混合动力系统，并采用轨迹优化（TO）方法来最小化不同速度下的运输成本（CoT）。我们的结果表明，尽管身体的偏航和滚动运动有所不同，但旋转和横向奔跑的落脚点顺序在能量上没有本质区别。然而，飞行阶段的数量显著影响能量效率：在低速时，无飞行阶段的奔跑是最佳选择，而在高速时，具有两个飞行阶段的奔跑可以最大限度地降低能量消耗。我们在Gazebo仿真中，使用我们先前工作中开发的基于二次规划（QP）的控制器验证了这些发现。这些见解促进了对四足运动能量学的理解，并可能为未来四足机器人的设计提供信息，以实现自适应、节能的步态转换。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [856] [Model-agnostic Meta-learning for Adaptive Gait Phase and Terrain Geometry Estimation with Wearable Soft Sensors](https://arxiv.org/abs/2508.02930)
> *基于模型无关元学习的穿戴式软传感器自适应步态相位和地形几何估计*

*Zenan Zhu, Wenxi Chen, Pei-Chun Kao, Janelle Clark, Lily Behnke, Rebecca Kramer-Bottiglio, Holly Yanco, Yan Gu* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 模型无关元学习, 穿戴式软传感器, 步态相位估计, 地形几何估计, 自适应学习

**Comment:** 8 pages, 5 figures

> **TL;DR:** 该研究提出一种基于模型无关元学习（MAML）的框架，使用织物基软传感器同时准确估计步态相位和地形几何，并能有效适应新用户和不同地形，优于基线方法。

**AI_Comments:** 该研究在利用软传感器进行步态和地形估计方面提出了创新的解决方案，特别是在处理个体差异和数据稀疏性方面，MAML的应用具有重要意义。然而，实际应用中传感器的长期稳定性和鲁棒性仍需进一步考察。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究面临织物基软传感器带来的非线性问题（滞后、放置误差、形变）以及个体和地形差异性，同时校准数据有限，这些都增加了准确估计的难度。

**Method:** 提出一种将MAML集成到深度学习架构中的框架，以学习能够捕捉与个体和地形无关的结构的通用模型初始化，从而实现高效适应和强大泛化能力。

**Result:** 实验表明，该框架在估计步态相位、运动模式和坡度角方面优于基线方法，在准确性、适应效率和泛化能力方面表现更佳。

**Conclusion:** 所提出的基于MAML的框架能够有效地利用穿戴式软传感器进行步态相位和地形几何估计，在面对个体差异和不同地形时具有良好的适应性和泛化能力。

> **ai_Abstract:** 本研究提出一种基于模型无关元学习（MAML）的框架，利用织物基软传感器实现步态相位和地形几何的同时估计。该框架通过学习通用的模型初始化，有效解决了软传感器带来的非线性问题以及个体和地形差异性，实现了高效适应和强大泛化能力，并在实验中取得了优于基线方法的性能。

> **摘要翻译:** 本通讯提出一种基于模型无关元学习（MAML）的框架，使用少量织物基穿戴式软传感器，能够同时准确地估计人体步态相位和地形几何，并能高效地适应未见过的主体，同时在不同主体和地形之间具有强大的泛化能力。与惯性测量单元等刚性替代品相比，织物基软传感器提高了舒适度，但由于滞后、放置误差和织物形变，会引入非线性。此外，个体和地形的变异性，加上在实际部署中校准数据有限，进一步增加了准确估计的复杂性。为解决这些挑战，所提出的框架将MAML集成到深度学习架构中，以学习能够捕捉与个体和地形无关的结构的通用模型初始化。这种初始化能够高效地适应新用户（即仅使用少量校准数据和几次微调即可适应），同时保持强大的泛化能力（即在不同主体和地形之间保持高估计精度）。在九名参与者在五种地形条件下以各种速度行走进行的实验表明，所提出的框架在估计步态相位、运动模式和坡度角方面优于基线方法，在准确性、适应效率和泛化能力方面表现更佳。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [863] [Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running](https://arxiv.org/abs/2508.03070)
> *优化仿人机器人Cassie的百米冲刺步态并与人类跑进行比较*

*Devin Crowley, Jeremy Dao, Helei Duan, Kevin Green, Jonathan Hurst, Alan Fern* | **Category: cs.RO, cs.AI, I.2.9** | **Updated: 2025-08-05**

**Keywords:** 仿人机器人, 跑步步态, 步态优化, 百米冲刺, 生物力学比较

**Comment:** 7 pages, 7 figures, published by IEEE at ICRA 2023, pp. 12205-12211,
  see https://ieeexplore.ieee.org/document/10160436

> **TL;DR:** 该论文提出了一种优化仿人机器人Cassie跑步步态的方法，使其能够达到极高的速度，并将其与人类跑步力学进行了比较。研究结果表明，尽管机器人的形态与人类不同，但在广泛的速度范围内，其步态的关键特性与人类高度相似。此外，该研究还将优化后的步态整合到一个完整的控制器中，使其能够满足现实世界百米冲刺任务的规则，包括从站立姿势开始和停止。该控制器已在硬件上进行了演示，并创下了仿人机器人百米跑最快速度的世界纪录。

**AI_Comments:** 这项研究在仿人机器人领域具有重要意义，它不仅展示了通过步态优化实现高速运动的可能性，还通过与人类跑步力学的比较，为理解和设计更高效的机器人运动系统提供了新的视角。该研究的成果——创下世界纪录——也证明了其方法的有效性和实用性。然而，未来可以进一步探索不同环境和地形对机器人步态的影响，以及更精细的生物力学特征的比较。

<details>
  <summary>Details</summary>

**Motivation:** 为了使仿人机器人Cassie能够实现极高的运行速度，并将其跑步步态与已知高效的人类跑步力学进行比较。

**Method:** 1.提出一种优化步态效率的方法，以实现极高的硬件运行速度。 2.基于已建立的人类生物力学研究，对机器人步态与人类跑步力学进行比较。 3.将优化后的跑步步态整合到满足百米冲刺任务规则（包括启动和停止）的完整控制器中。

**Result:** 尽管Cassie机器人和人类在形态上存在差异，但在广泛的速度范围内，它们的步态的关键特性高度相似。该控制器已在硬件上成功演示，并创下了仿人机器人百米跑最快速度的世界纪录。

**Conclusion:** 通过优化步态效率和整合控制器，仿人机器人Cassie成功实现了高速奔跑，其步态特性与人类跑步相似，并创下了百米跑的世界纪录。

> **ai_Abstract:** 本研究旨在优化仿人机器人Cassie的跑步步态，以实现高速度并与人类跑步进行比较。研究人员开发了一种优化步态效率的方法，发现机器人的步态特性与人类相似。此外，他们还将优化的步态整合到一个控制器中，成功完成了百米冲刺任务，并创下了世界纪录。

> **摘要翻译:** 在本论文中，我们探索了仿人机器人Cassie的跑步步态空间。我们的第一个贡献是提出一种优化步态效率的方法，以实现极高的运行速度。这引发了一个问题：由此产生的步态与人类跑步力学相比如何？已知人类跑步力学与四足动物相比效率极高。我们的第二个贡献是基于已建立的人类生物力学研究进行此比较。我们发现，尽管Cassie和人类在形态上存在差异，但在广泛的速度范围内，步态的关键特性高度相似。最后，我们的第三个贡献是将优化后的跑步步态整合到一个完整的控制器中，该控制器满足现实世界百米冲刺任务的规则，包括从站立姿势开始和停止。我们在硬件上演示了这个控制器，并创下了仿人机器人百米跑最快速度的世界纪录。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [872] [Equivariant Volumetric Grasping](https://arxiv.org/abs/2507.18847)
> *等变体积抓取*

*Pinhao Song, Yutong Hu, Pengteng Li, Renaud Detry* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 体积抓取, 等变性, 三平面特征, 可变形可控卷积, 机器人抓取

**Comment:** 19 pages

> **TL;DR:** 提出了一种新的体积抓取模型，该模型对围绕垂直轴的旋转具有等变性，从而显著提高了样本效率。该模型采用三平面体积特征表示，并通过新的可变形可控卷积实现，该卷积结合了可变形卷积的适应性和可控卷积的旋转等变性。通过将此方法应用于 GIGA 和 IGD 等抓取规划器，并推导出 IGD 的可变形注意力机制的等变公式以及基于流匹配的抓取方向等变生成模型，可以显著降低计算和内存成本，并提高抓取性能。

**AI_Comments:** 该研究在机器人抓取领域取得了重要进展，通过引入等变性设计显著提高了样本效率和抓取性能。其创新的三平面特征表示和可变形可控卷积为解决旋转不变性问题提供了新的思路。然而，模型的计算复杂度和在实际应用中的鲁棒性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高机器人抓取的样本效率和性能，提出了一种对垂直轴旋转具有等变性的新型体积抓取模型。

**Method:** 提出了一种基于三平面体积特征表示的抓取模型，其中水平平面特征对90度旋转具有等变性，而其他两个平面的特征和保持不变。通过使用一种新的可变形可控卷积来实现这一点，该卷积结合了可变形卷积的适应性和可控卷积的旋转等变性。此外，还开发了GIGA和IGD抓取规划器的等变版本，包括IGD的可变形注意力机制的等变公式以及基于流匹配的抓取方向等变生成模型。

**Result:** 该模型显著降低了计算和内存成本，并且在模拟和现实世界的实验中，其等变抓取模型在性能上持续优于非等变对应模型，同时只增加了适度的计算开销。

**Conclusion:** 基于所提出的基于投影的设计显著降低了计算和内存成本。此外，建立在三平面特征上的等变抓取模型始终优于其非等变对应模型，以适度的计算开销实现了更高的性能。

> **ai_Abstract:** 本文提出了一种新颖的体积抓取模型，该模型利用三平面体积特征表示，并对垂直轴旋转具有等变性。通过引入一种结合了可变形卷积和可控卷积特性的新颖可变形可控卷积，实现了对局部几何形状的适应性，同时保持了旋转等变性。该模型通过等变化 GIGA 和 IGD 等抓取规划器，并在模拟和现实世界实验中得到验证，证明了其在降低计算和内存成本以及提高抓取性能方面的有效性。

> **摘要翻译:** 我们提出了一种新的体积抓取模型，该模型对围绕垂直轴的旋转具有等变性，从而显著提高了样本效率。我们的模型采用了三平面体积特征表示——即三维特征到三个标准平面的投影。我们引入了一种新颖的三平面特征设计，其中水平平面上的特征对于90度旋转具有等变性，而其他两个平面上的特征和对于相同的变换保持不变。这种设计是通过一种新的可变形可控卷积实现的，它结合了可变形卷积的适应性与可控卷积的旋转等变性。这使得感受野能够适应局部对象几何形状，同时保持等变性属性。我们进一步开发了两种最先进的体积抓取规划器 GIGA 和 IGD 的等变适应。具体来说，我们推导了 IGD 的可变形注意力机制的新等变公式，并提出了一种基于流匹配的抓取方向的等变生成模型。我们对所提出的等变属性进行了详细的分析论证，并通过大量的模拟和现实世界实验验证了我们的方法。我们的结果表明，所提出的基于投影的设计显著降低了计算和内存成本。此外，基于我们三平面特征构建的等变抓取模型始终优于其非等变对应模型，以适度的计算开销实现了更高的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [883] [Theatre in the Loop: A Rehearsal-Based, Collaborative Workflow for Expressive Robotic Behaviours](https://arxiv.org/abs/2508.03514)
> *戏剧中的循环：一种基于排练、协作的工作流程，用于表达机器人行为*

*Pavlos Panagiotidis, Victor Zhi Heung Ngo, Sean Myatt, Roma Patel, Rachel Ramchurn, Alan Chamberlain, Ayse Kucukyilmaz* | **Category: cs.RO, cs.HC** | **Updated: 2025-08-05**

**Keywords:** 戏剧中的循环, 机器人行为, 艺术表演, 木偶操纵, 共创方法

**Comment:** The paper is accepted for presentation to International Conference on
  Social Robotics + AI (https://icsr2025.eu/)

> **TL;DR:** 本研究提出了一种名为“戏剧中的循环”的框架，通过导演指导的木偶操纵工作流程，利用戏剧方法开发用于艺术表演的机器人行为。该方法使用叙事目标指导操作员即兴创作机器人手势以传达情感，并将这些即兴创作收集起来构建可重用的动作模板数据集，用于未来自主表演。初步试验表明，该方法能够精确地将机器人手势塑造成连贯的情感弧线，但也揭示了机器人机械限制带来的挑战。研究认为，该实践主导的框架为跨学科团队创建具有社会表现力的机器人行为提供了一个模型，并有助于将戏剧作为人机交互的互动训练场以及人机共创方法。

**AI_Comments:** 该研究提出了一种创新的方法，将戏剧原理应用于机器人行为开发，特别是在艺术表演领域。通过“戏剧中的循环”框架，研究者能够利用导演指导的木偶操纵来创造富有表现力的机器人动作，并将其转化为可重用的模板。这种跨学科的方法不仅为机器人行为的设计提供了新的思路，也为人机交互和共创方法的研究开辟了新的途径。然而，研究也指出了机器人机械限制带来的挑战，这为未来的研究提供了进一步优化的方向。总体而言，这项工作具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种用于艺术表演的机器人行为开发框架，特别是通过利用戏剧方法来创造富有表现力的机器人行为。

**Method:** 本研究提出了一种名为“戏剧中的循环”的框架，该框架利用导演指导的木偶操纵工作流程，通过叙事目标指导操作员即兴创作机器人手势以传达特定情感。这些即兴创作被捕获和整理，以构建可重用的运动模板数据集，用于未来自主表演。

**Result:** 初步试验表明，该框架能够有效地将机器人手势塑造成连贯的情感弧线，但同时也暴露出机器人机械限制带来的挑战。

**Conclusion:** 该实践主导的框架为跨学科团队创建具有社会表现力的机器人行为提供了一个模型，并将戏剧作为人机交互的互动训练场以及人机共创方法。

> **ai_Abstract:** 本研究提出了一种名为“戏剧中的循环”的框架，通过导演指导的木偶操纵工作流程，利用戏剧方法开发用于艺术表演的机器人行为。该方法使用叙事目标指导操作员即兴创作机器人手势以传达情感，并将这些即兴创作收集起来构建可重用的动作模板数据集，用于未来自主表演。初步试验表明，该方法能够精确地将机器人手势塑造成连贯的情感弧线，但也揭示了机器人机械限制带来的挑战。该框架为跨学科团队创建具有社会表现力的机器人行为提供了一个模型，并有助于将戏剧作为人机交互的互动训练场以及人机共创方法。

> **摘要翻译:** 在本论文中，我们提出了“戏剧中的循环”框架，该框架通过导演指导的木偶操纵工作流程，为开发针对艺术表演的富有表现力的机器人行为。利用戏剧方法，我们使用叙事目标来指导木偶操纵者生成即兴的机器人手势，以传达特定的情感。这些即兴创作被捕获和整理，以构建一个可重用的运动模板数据集，用于未来自主表演的独立播放。初步试验表明，该方法的可行性，说明了该工作流程能够精确地将机器人手势塑造成连贯的情感弧线，同时揭示了机器人机械约束带来的挑战。我们认为，这种实践主导的框架为跨学科团队创建具有社会表现力的机器人行为提供了一个模型，并有助于（1）将戏剧作为人机交互的互动训练场，以及（2）人与机器之间的共创方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [885] [A novel autonomous microplastics surveying robot for beach environments](https://arxiv.org/abs/2508.02952)
> *一种用于海滩环境的新型自主微塑料测量机器人*

*Hassan Iqbal, Kobiny Rex, Joseph Shirley, Carlos Baiz, Christian Claudel* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 微塑料, 海滩环境, 自主机器人, 近红外光谱, 污染检测

**Comment:** 12 pages, 11 figures

> **TL;DR:** 该研究介绍了一种能自动检测和分析海滩微塑料的机器人平台，通过摄像头和近红外光谱技术，实现了高精度的定位和分类。

**AI_Comments:** 该研究提出了一种创新的机器人解决方案，用于解决微塑料污染这一重要的环境问题。其亮点在于机器人的自主性和在复杂海滩环境中进行实时化学分析的能力。然而，对于机器人在实际海滩环境中的部署效率、能源续航以及数据处理能力等方面的进一步研究将是未来工作的重点。

<details>
  <summary>Details</summary>

**Motivation:** 微塑料是普遍存在的环境污染物，在海滩上的检测和浓度测绘是解决这一环境问题的关键挑战。

**Method:** 该机器人平台利用安装在机械臂末端执行器上的摄像头扫描区域，并能有效分割沙地上的微塑料颗粒，即使存在有机物。一旦检测到候选微塑料颗粒，系统会利用近红外光谱和视觉反馈，实时对其进行化学分析。

**Result:** 实验证明，该系统在操作控制方面具有出色的定位精度，并且微塑料分类准确率很高。

**Conclusion:** 该新型机器人平台能够有效地在海滩环境中自主检测和化学分析微塑料，为解决微塑料污染问题提供了一种有效的技术手段。

> **ai_Abstract:** 本文提出了一种创新的自主微塑料测量机器人，专门用于海滩环境。该机器人利用集成在机械臂上的摄像头进行大范围扫描，并能有效区分沙地上的微塑料颗粒，即使在有杂物的情况下也能实现高精度检测。一旦识别出微塑料，机器人便利用近红外光谱技术进行实时化学分析。实验结果表明，该系统在定位精度和微塑料分类准确性方面均表现优异，为解决海滩微塑料污染问题提供了有效的解决方案。

> **摘要翻译:** 微塑料被定义为小于5毫米的塑料颗粒，由于风型和潮汐作用，已成为一种普遍存在的环境污染物，并在海滩上积聚。在野外检测微塑料并绘制其浓度图仍然是解决这一环境问题的首要挑战之一。本文介绍了一种新型机器人平台，该平台能够自动检测海滩表面的微塑料并对其进行化学分析。该移动操作员系统使用安装在机械臂末端执行器上的摄像头扫描区域以检测微塑料。即使存在树叶和蛤蜊等有机物，该系统也能有效地将候选微塑料颗粒与沙地表面分离开来。一旦检测到候选微塑料颗粒，系统将利用近红外（NIR）和视觉反馈，将近红外光谱传感器引导到该颗粒上，并实时对其进行化学分析。通过在实验室和海滩环境中的实验，证明该系统在操作控制方面实现了出色的定位精度，并且微塑料分类准确率很高。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [886] [Doppler-SLAM: Doppler-Aided Radar-Inertial and LiDAR-Inertial Simultaneous Localization and Mapping](https://arxiv.org/abs/2504.11634)
> *多普勒SLAM：多普勒辅助雷达-惯性与激光雷达-惯性同步定位与建图*

*Dong Wang, Hannes Haag, Daniel Casado Herraez, Stefan May, Cyrill Stachniss, Andreas Nüchter* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 多普勒SLAM, 雷达-惯性SLAM, 激光雷达-惯性SLAM, 4D雷达, FMCW激光雷达

**Comment:** 8 pages, 7 figures

> **TL;DR:** 提出了一种结合4D雷达、FMCW激光雷达和惯性测量单元的多普勒辅助SLAM框架，通过整合多普勒速度测量和空间数据，提高了在恶劣条件下的定位和建图能力，并在动态环境和传感器校准方面进行了改进，实验证明其性能优于现有雷达SLAM和激光雷达SLAM系统。

**AI_Comments:** 该研究通过引入多普勒信息显著提升了SLAM系统的鲁棒性和准确性，特别是在挑战性环境下。其创新的传感器融合和在线标定机制是该工作的亮点。代码和数据集的公开也为该领域的研究做出了贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统SLAM方法在低光照或无特征环境中存在挑战，需要更鲁棒的解决方案。

**Method:** 提出了一种新的多普勒辅助雷达-惯性与激光雷达-惯性SLAM框架，该框架将多普勒速度测量和空间数据紧密耦合到前端和图优化后端，并引入了基于多普勒的扫描匹配技术和在线外参标定机制。

**Result:** 该系统在准确性和鲁棒性方面显著优于最先进的雷达SLAM和激光雷达SLAM框架。

**Conclusion:** 提出的多普勒辅助SLAM框架能够有效克服传统SLAM在恶劣条件下的局限性，提供更准确、更鲁棒的定位和建图能力。

> **ai_Abstract:** 本研究提出了一种名为Doppler-SLAM的新型框架，该框架集成了4D雷达、FMCW激光雷达和惯性测量单元（IMU），并通过多普勒速度测量来增强同步定位与建图（SLAM）能力。该方法旨在克服传统SLAM在恶劣环境下的局限性，通过紧密耦合传感器数据和优化算法，实现了更精确的里程计、速度估计和地图构建，特别是在动态环境中和传感器外参标定方面。实验结果表明，Doppler-SLAM在准确性和鲁棒性方面均优于现有技术。

> **摘要翻译:** 同步定位与建图（SLAM）是自主系统的关键能力。传统上依赖视觉或激光雷达传感器的SLAM方法，在低光照或无特征环境等恶劣条件下会遇到重大挑战。为了克服这些局限性，我们提出了一种新颖的多普勒辅助雷达-惯性与激光雷达-惯性SLAM框架，该框架利用了4D雷达、FMCW激光雷达和惯性测量单元的互补优势。我们的系统将多普勒速度测量和空间数据整合到一个紧密集成的Мини-SLAM前端和一个图优化后端中，以提供增强的自身速度估计、精确的里程计和鲁棒的建图。我们还引入了一种基于多普勒的扫描匹配技术，以在动态环境中改进前端里程计。此外，我们的框架包含了一个创新的在线外参标定机制，利用多普勒速度和回环检测来动态维护传感器对齐。在公开和专有数据集上的广泛评估表明，我们的系统在准确性和鲁棒性方面显著优于最先进的雷达SLAM和激光雷达SLAM框架。为了鼓励进一步的研究，我们的Doppler-SLAM代码和数据集可在：https://github.com/Wayne-DWA/Doppler-SLAM 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [907] [Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization](https://arxiv.org/abs/2508.02953)
> *蛇形机器人垂直起伏运动中的最优轨迹规划与接触隐式优化*

*Adarsh Salagame, Eric Sihite, Alireza Ramezani* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 蛇形机器人,轨迹规划,接触优化,刚体动力学,莫罗前进法

**Comment:** 

> **TL;DR:** 该研究提出了一种基于莫罗前进法和刚体动力学的简化的蛇形机器人运动模型，并通过仿真和实验验证了其准确性和有效性，以解决传统方法忽略接触或过于复杂的问题。

**AI_Comments:** 该研究在蛇形机器人运动控制领域提出了一个创新的简化模型，有效地解决了传统方法在处理接触复杂性方面存在的局限性。通过实验验证增强了研究的可信度，但其在真实复杂环境下的泛化能力仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有蛇形机器人控制研究多集中于模仿其运动模式，但忽略了复杂的接触交互，或过于关注如挖掘等特定复杂交互。缺乏介于两者之间、基于简单刚体动力学并能缓解接触与控制分配问题的模型和控制框架。

**Method:** 提出一种基于莫罗前进法（差分包含数学）的降阶模型，并通过仿真和实验验证该模型的准确性。

**Result:** 通过仿真和实验验证了所提出模型的准确性和有效性。

**Conclusion:** 该研究通过引入简化的刚体动力学模型，为蛇形机器人的轨迹和接触规划提供了一种新的优化方法，解决了现有方法在处理复杂接触交互时的不足。

> **ai_Abstract:** 本研究针对蛇形机器人运动的轨迹规划问题，提出了一种基于莫罗前进法和刚体动力学的降阶模型。该模型旨在简化复杂的接触交互问题，并为控制分配提供解决方案，填补了现有研究在简单动力学模型方面的空白。通过仿真和实验验证，证明了该模型的准确性和有效性。

> **摘要翻译:** 接触丰富的爬行问题，例如蛇形机器人的运动，提供了未被充分探索但却具有巨大潜力的优化轨迹和无环接触规划机会。迄今为止，大量的控制研究集中于模仿蛇形运动并复制其独特的运动模式，使用忽略交互复杂性或专注于与物质的复杂交互（例如挖掘运动）的形状函数。然而，介于这两种范式之间、基于简单的、基本的刚体动力学、能够缓解蛇形运动中接触和控制分配的挑战性问题的模型和控制框架仍然缺失。这项工作通过仿真和实验，在以下几个方向做出了有意义的贡献：1）提出一种基于莫罗前进法（差分包含数学）的降阶模型，2）验证模型准确性，3）实验验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [935] [Simultaneous Pick and Place Detection by Combining SE(3) Diffusion Models with Differential Kinematics](https://arxiv.org/abs/2504.19502)
> *结合SE(3)扩散模型与微分运动学实现同步抓取与放置检测*

*Tianyi Ko, Takuya Ikeda, Balazs Opra, Koichi Nishiwaki* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 抓取检测, SE(3)扩散模型, 微分运动学, 抓取可行性, 机器人抓取

**Comment:** Accepted for IROS2025

> **TL;DR:** 该研究提出了一种结合SE(3)扩散模型和微分运动学的抓取检测方法，将抓取可行性约束纳入抓取检测阶段，提高了抓取成功率和计算效率。

**AI_Comments:** 该研究将扩散模型应用于抓取检测领域，并巧妙地结合了微分运动学来处理多重物理约束，这是一个有前景的方向。通过在检测阶段就考虑约束，避免了后处理的低效性，具有实际应用价值。未来的工作可以探索更复杂的约束条件或更广泛的机器人应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的抓取检测方法仅关注抓取姿态，未考虑物理约束，导致部分抓取姿态不可行，且后处理过滤效率低下。本研究旨在解决此问题，将抓取和放置的物理约束（如无翻转放置、关节限制、避障）集成到抓取检测过程中。

**Method:** 提出一种SE(3)抓取扩散模型，该模型估计空间速度形式的噪声，并通过多目标微分逆运动学和不等式约束来约束去噪过程，以确保抓取姿态在机器人运动范围内且能无碰撞放置。

**Result:** 实验证实，该方法不仅提高了抓取成功率，而且在计算时间上比传统的两阶段方法更有效率且更一致。

**Conclusion:** 通过将SE(3)扩散模型与微分运动学相结合，并考虑抓取和放置的物理约束，可以实现更高效、更一致的抓取检测。

> **ai_Abstract:** 本研究提出了一种新颖的抓取检测方法，将SE(3)扩散模型与微分运动学相结合，以解决传统方法在考虑物理约束方面的不足。该方法在抓取检测阶段就集成了放置可行性、关节限制和避障等约束，通过估计空间速度噪声并进行约束去噪，确保了抓取的成功率和放置的可行性。实验结果表明，该方法在提高抓取成功率和计算效率方面优于传统方法。

> **摘要翻译:** 抓取检测方法通常以检测一组能够抓取对象的自由浮动的手部姿态为目标。然而，并非所有检测到的抓取姿态都由于物理约束而可执行。尽管在后处理中过滤无效抓取姿态很简单，但这种两阶段的方法在计算上效率低下，尤其是在约束条件很严格的情况下。在本研究中，我们提出一种方法，在抓取检测阶段考虑以下两个约束：（i）抓取的对象必须能够在不进行手中操作的情况下以预定义的配置进行放置，（ii）在抓取和放置的情况下，机器人必须能够在关节限制和避障约束下到达该对象。我们的核心思想是训练一个SE(3)抓取扩散网络来估计空间速度形式的噪声，并通过具有不等式约束的多目标微分逆运动学来约束去噪过程，从而保证状态是可达的，并且可以无碰撞地进行放置。除了提高成功率外，我们还通过实验证实了我们的方法与朴素的两阶段方法相比，在计算时间上更有效率且更一致。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [941] [Robot builds a robot's brain: AI generated drone command and control station hosted in the sky](https://arxiv.org/abs/2508.02962)
> *机器人构建机器人大脑：人工智能生成的无人机指挥与控制站部署在空中*

*Peter Burke* | **Category: cs.RO** | **Updated: 2025-08-04**

**Keywords:** 人工智能,无人机控制,代码生成,自主系统,机器人工程

**Comment:** 

> **TL;DR:** 一篇关于人工智能（AI）生成无人机指挥与控制（C2）系统的论文，该系统完全由AI编写代码，并在实际无人机和模拟环境中进行了部署和测试。AI生成的系统在开发速度上远超人类编写的系统，但存在模型上下文窗口和推理深度方面的局限性。

**AI_Comments:** 这项工作展示了AI在自主生成复杂机器人控制系统方面的巨大潜力，尤其是在开发速度方面。然而，文中也指出了当前AI模型在上下文窗口和推理深度方面的局限性，这表明在实现完全自主和鲁棒的AI机器人开发之前，仍有进一步研究和改进的空间。该研究为机器人工程领域开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 探索利用AI，特别是LLM和混合推理模型，来重新构想自主机器人（如无人机）的设计、开发和验证过程，并展示AI在自主创建机器人控制系统方面的潜力。

**Method:** 开发了一个完全由AI生成的无人机控制系统，AI模型在极少人工干预下编写了实时、自托管的无人机指挥与控制平台代码，并将其部署在实际飞行和云端模拟的无人机上，实现了实时地图绘制、飞行遥测、自主任务规划与执行以及安全协议。

**Result:** AI生成的代码能够实现功能完整的指挥与控制堆栈，开发周期比人类编写的架构快几个数量级。然而，在特定模型上下文窗口和推理深度方面存在明显的局限性。

**Conclusion:** 这项工作为自主创建机器人控制系统树立了先例，并提出了一种新的机器人工程范式，未来机器人可能主要由AI进行协同设计、开发和验证。AI生成的代码在开发速度上有显著优势，但当前在模型能力方面存在局限。

> **ai_Abstract:** 该论文介绍了一个完全由AI生成的无人机指挥与控制系统，该系统在实际无人机和模拟环境中成功部署。AI在极少人工干预下编写了所有代码，实现了快速开发周期，但目前在模型能力方面存在局限性，预示着未来机器人工程的新范式。

> **摘要翻译:** 人工智能（AI）的进步，包括大型语言模型（LLM）和混合推理模型，为重新构想自主机器人（如无人机）的设计、开发和验证方式提供了机会。在此，我们演示了一个完全由AI生成的无人机控制系统：在一个人工智能（AI）模型的编写下，仅需极少的人工输入，就完成了实时、自托管的无人机指挥与控制平台的全部代码，该平台已在实际飞行中的无人机以及云端的模拟虚拟无人机上进行了部署和演示。该系统能够实现实时地图绘制、飞行遥测、自主任务规划与执行以及安全协议——所有这些都通过托管在无人机本身上的Web界面进行编排。没有一行代码是由人类编写的。我们对系统性能、代码复杂性和开发速度与先前的人类编码架构进行了定量基准测试，发现AI生成的代码能够以数量级更快的开发周期交付功能完整的指挥与控制堆栈，尽管在特定模型上下文窗口和推理深度方面存在可识别的当前局限性。我们的分析揭示了当前模型规模下AI驱动的机器人控制代码生成的实际边界，以及AI生成的机器人代码中出现的优势和失败模式。这项工作为自主创建机器人控制系统树立了先例，更广泛地说，它提出了一种新的机器人工程范式——在这种范式中，未来的机器人可能在很大程度上由人工智能进行协同设计、开发和验证。在这个初步工作中，一个机器人构建了一个机器人大脑。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [955] [DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping](https://arxiv.org/abs/2502.20900)
> *DexGraspVLA：一个面向通用灵巧抓取的视觉-语言-动作框架*

*Yifan Zhong, Xuchuan Huang, Ruochong Li, Ceyao Zhang, Zhang Chen, Tianrui Guan, Fanlian Zeng, Ka Num Lui, Yuyao Ye, Yitao Liang, Yaodong Yang, Yuanpei Chen* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 灵巧抓取, 视觉-语言-动作, 泛化能力, 扩散模型, 模仿学习

**Comment:** 19 pages, 11 figures

> **TL;DR:** DexGraspVLA是一个结合视觉、语言和动作的机器人抓取框架，通过使用预训练的视觉语言模型作为高级规划器和基于扩散的模型作为低级动作控制器，实现了在复杂场景下的鲁棒泛化抓取，成功率超过90%，并能在各种干扰下进行恢复和适应。

**AI_Comments:** 该研究在机器人灵巧抓取领域取得了重要进展，通过融合视觉、语言和动作模态，并创新性地利用基础模型解决领域转移问题，显著提升了抓取的泛化能力和鲁棒性。其在复杂场景下的高成功率和多功能性（如指令执行、干扰应对、失败恢复）证明了该框架的有效性。然而，文中未详细说明“领域不变表示”的具体实现方式，以及在“非抓握式抓取”方面的具体应用细节，这些是未来研究可以进一步探索的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人抓取研究在单物体或有限环境的假设下，泛化能力受限。需要一个能够处理多样化物体和任意场景的通用机器人抓取系统。

**Method:** 提出了一种分层框架DexGraspVLA，使用预训练的视觉-语言模型作为高级规划器，学习基于扩散的低级动作控制器。通过基础模型将语言和视觉输入转化为领域不变表示，并利用模仿学习来缓解领域转移问题。

**Result:** 在数千个具有挑战性的、未见的、杂乱的场景下，实现了90%以上的灵巧抓取成功率。验证了模型在不同环境变化下的一致性。首次实现了自由形式的长期指令执行、对抗性物体和人类干扰的鲁棒性以及失败恢复能力。在非抓握式抓取方面也证明了其通用性。

**Conclusion:** DexGraspVLA框架通过结合视觉、语言和动作，并利用基础模型处理领域转移问题，成功实现了通用灵巧抓取，并在泛化能力、鲁棒性和多功能性方面取得了显著进展。

> **ai_Abstract:** DexGraspVLA是一个新颖的机器人抓取框架，它整合了视觉、语言和动作模态，旨在解决通用灵巧抓取中的泛化能力问题。该框架采用分层结构，上层利用预训练的视觉-语言模型进行规划，下层则使用基于扩散的模型来控制动作。通过将输入转化为领域不变表示，有效缓解了领域转移问题，使得模仿学习更加高效。实验结果表明，DexGraspVLA在处理大量未见过的复杂场景时，抓取成功率超过90%，并且在面对干扰和执行长期任务时表现出优越的鲁棒性和通用性，甚至成功应用于非抓握式抓取。

> **摘要翻译:** 灵巧抓取仍然是机器人领域一个基本但充满挑战的问题。一个通用的机器人必须能够抓取各种场景下的多样化物体。然而，现有研究通常依赖于限制性假设，例如单物体设置或有限的环境，表现出受限的泛化能力。我们提出了DexGraspVLA，一个用于语言引导的通用灵巧抓取及更广泛领域的鲁棒泛化的分层框架。它利用预训练的视觉-语言模型作为高级规划器，并学习一个基于扩散的低级动作控制器。实现泛化的关键在于通过基础模型将多样化的语言和视觉输入迭代地转化为领域不变表示，由于领域转移的缓解，模仿学习可以被有效地应用。值得注意的是，我们的方法在数千个具有挑战性的未见过的杂乱场景下，实现了90%以上的灵巧抓取成功率。实证分析证实了内部模型行为在环境变化中的一致性，验证了我们的设计。DexGraspVLA还首次同时展示了自由形式的长期指令执行、对抗性物体和人类干扰的鲁棒性以及失败恢复能力。扩展应用到非抓握式抓取进一步证明了其通用性。项目网址：https://dexgraspvla.github.io。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [970] [Physics-informed Neural Time Fields for Prehensile Object Manipulation](https://arxiv.org/abs/2508.02976)
> *面向可抓取物体操作的物理信息神经时间场*

*Hanwen Ren, Ruiqi Ni, Ahmed H. Qureshi* | **Category: cs.RO** | **Updated: 2025-08-05**

**Keywords:** 物理信息神经网络, 物体操作, 机器人抓取, 轨迹规划, Eikonal方程

**Comment:** 

> **TL;DR:** 该研究提出了一种新颖的多模态物理信息神经网络（PINN），用于解决物体操作任务。该方法无需专家数据即可高效学习求解Eikonal方程，并在复杂、杂乱的环境中快速找到物体操作轨迹。它还能在操作过程中动态重新规划机器人的抓取，以达到期望的物体姿态。实验证明该方法在各种物体上都有效，与先前基于学习的方法相比训练效率更高，并在规划时间、轨迹长度和成功率方面表现出高性能。

**AI_Comments:** 该研究提出了一种创新的方法，将物理信息与神经网络相结合，用于解决机器人操作的复杂问题。其无需专家数据和动态重规划能力是该方法的亮点，具有重要的实际应用价值。然而，对于其在不同物理模型和复杂性下的泛化能力以及对计算资源的需求仍需进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 现有物体操作方法效率低下，需要专家演示或通过反复试验学习，不适合实际应用。

**Method:** 提出了一种新颖的多模态物理信息神经网络（PINN），用于学习求解Eikonal方程，并能动态重新规划机器人的抓取。

**Result:** 该方法在模拟和真实世界场景中均有效，训练效率高，在规划时间、轨迹长度和成功率方面表现优异。

**Conclusion:** 该物理信息神经网络（PINN）方法在物体操作任务中表现出高效性和优越性，能够应对复杂环境并实现高成功率。

> **ai_Abstract:** 本研究提出了一种新颖的多模态物理信息神经网络（PINN），用于解决机器人物体操作任务。该方法无需专家数据即可高效学习求解Eikonal方程，并在复杂环境中快速生成操作轨迹，同时还能动态调整抓取以适应目标姿态。实验结果表明，该方法在效率和性能上优于现有技术。

> **摘要翻译:** 物体操作技能对于在各种日常场景中运行的机器人至关重要，从仓库到医院。它们使机器人能够将给定物体操纵到杂乱环境中所需的排列。现有的解决物体操作的方法要么是低效的基于采样技术，需要专家演示，要么通过反复试验学习，这使得它们不太适合实际场景。在本文中，我们提出了一种新颖的多模态物理信息神经网络（PINN）来解决物体操作任务。我们的方法有效地学习求解Eikonal方程，而无需专家数据，并在复杂的杂乱环境中快速找到物体操作轨迹。我们的方法是多模态的，因为它在操作过程中动态地重新规划机器人的抓取，以达到期望的物体姿态。我们在模拟和真实世界场景中都展示了我们的方法，并将其与最先进的基线方法进行了比较。结果表明，我们的方法在各种物体上都有效，与以前基于学习的方法相比具有高效的训练，并在规划时间、轨迹长度和成功率方面表现出高稳定性。我们的演示视频可以在https://youtu.be/FaQLkTV9knI找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [154] [When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs](https://arxiv.org/abs/2508.03365)
> *当好声音变得对抗性：用良性输入劫持音频语言模型*

*Bodam Kim, Hiskias Dingeto, Taeyoun Kwon, Dasol Choi, DongGeon Lee, Haon Park, JaeHoon Lee, Jongho Shin* | **Category: cs.SD, cs.AI, cs.CR, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 对抗性音频攻击, 音频语言模型, WhisperInject, 越狱, 安全漏洞

**Comment:** 

> **TL;DR:** 研究人员开发了WhisperInject，一个两阶段的对抗性音频攻击框架，能利用人耳无法察觉的扰动，使音频语言模型生成有害内容，成功率超过86%。

**AI_Comments:** WhisperInject的创新之处在于其两阶段攻击框架，特别是结合强化学习和投影梯度下降来绕过AI安全协议，并通过“良性”音频载体进行隐蔽攻击。这不仅揭示了音频语言模型在实际应用中的严重安全漏洞，也为未来AI安全防御提供了新的研究方向。其高成功率和对主流模型的有效性凸显了这项研究的重要性和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型日益融入日常生活，音频作为人机交互的关键接口，也带来了新的漏洞，使其成为潜在的攻击面。本研究旨在揭示并利用这些漏洞，展示一种操纵AI行为的可行且隐蔽的方法。

**Method:** 本研究引入了WhisperInject，一个两阶段的对抗性音频攻击框架。第一阶段使用一种新颖的基于奖励的优化方法——带有投影梯度下降的强化学习（RL-PGD），引导目标模型规避其安全协议并生成有害的本地响应。第二阶段，即有效载荷注入，使用投影梯度下降（PGD）优化嵌入到良性音频载体（如天气查询或问候信息）中的微小扰动，使这些扰动对人类听众来说是无法察觉的。

**Result:** 在StrongREJECT、LlamaGuard以及人工评估安全评估框架下，实验证明WhisperInject在Qwen2.5-Omni-3B、Qwen2.5-Omni-7B和Phi-4-Multimodal上的成功率超过86%。

**Conclusion:** 本研究揭示了一种新型的、实用的、音频原生的威胁，超越了理论上的漏洞利用，展示了一种可行且隐蔽的操纵AI行为的方法。

> **ai_Abstract:** 本研究提出了WhisperInject，一个两阶段对抗性音频攻击框架，旨在利用人耳无法察觉的微小扰动来劫持音频语言模型，使其生成有害内容。该方法通过RL-PGD引导模型绕过安全协议生成有害响应，再通过PGD将扰动嵌入良性音频。实验证明，WhisperInject在多种先进模型上攻击成功率超过86%，揭示了音频语言模型面临的新型实际威胁。

> **摘要翻译:** 随着大型语言模型日益融入日常生活，音频已成为人机交互的关键接口。然而，这种便利性也带来了新的漏洞，使音频成为攻击者潜在的攻击面。我们的研究引入了WhisperInject，一个两阶段的对抗性音频攻击框架，能够操纵最先进的音频语言模型生成有害内容。我们的方法利用音频输入中人耳无法察觉的扰动，这些扰动对人类听众来说仍然是良性的。第一阶段使用一种新颖的基于奖励的优化方法——带有投影梯度下降的强化学习（RL-PGD），引导目标模型规避其自身安全协议并生成有害的本地响应。然后，这种本地有害响应作为第二阶段——有效载荷注入的目标，我们使用投影梯度下降（PGD）来优化嵌入到良性音频载体（如天气查询或问候信息）中的微妙扰动。在严格的StrongREJECT、LlamaGuard以及人工评估安全评估框架下进行验证，我们的实验表明在Qwen2.5-Omni-3B、Qwen2.5-Omni-7B和Phi-4-Multimodal上的成功率超过86%。我们的工作展示了一种新型的实用、音频原生威胁，超越了理论上的漏洞利用，揭示了一种可行且隐蔽的操纵AI行为的方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [227] [Fine-Tuning Text-to-Speech Diffusion Models Using Reinforcement Learning with Human Feedback](https://arxiv.org/abs/2508.03123)
> *使用人类反馈强化学习微调文本到语音扩散模型*

*Jingyi Chen, Ju Seung Byun, Micha Elsner, Pichao Wang, Andrew Perrault* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 文本到语音, 扩散模型, 强化学习, 人类反馈, DLPO

**Comment:** 4 pages, 1 figure, INTERSPEECH 2025. arXiv admin note: text overlap
  with arXiv:2405.14632

> **TL;DR:** 本文提出DLPO，一个用于TTS扩散模型的RLHF框架，通过将原始训练损失集成到奖励函数中，提高了扩散模型在实时文本到语音生成中的效率和质量。

**AI_Comments:** 该论文通过引入RLHF框架DLPO，创新性地解决了扩散模型在实时TTS应用中的效率和韵律建模问题。将原始训练损失纳入奖励函数是一个巧妙的设计，有助于在优化人类偏好的同时保持生成质量。这项工作对于推动扩散模型在实际TTS系统中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型虽然能生成高质量语音，但由于去噪步骤长以及在建模语调和韵律方面存在挑战，导致其在实时应用中效率低下。

**Method:** 本文提出了扩散损失引导策略优化（DLPO），一个用于文本到语音（TTS）扩散模型的RLHF（带人类反馈的强化学习）框架。DLPO将原始训练损失集成到奖励函数中，并使用自然度得分作为反馈，将奖励优化与扩散模型结构对齐。

**Result:** 在WaveGrad 2上的评估显示，DLPO在客观指标（UTMOS 3.65，NISQA 4.02）和主观评价方面均有显著改进，DLPO生成的音频有67%的时间被优先选择。

**Conclusion:** DLPO框架在实时、资源受限的环境中，为高效、高质量的扩散TTS提供了潜力。

> **ai_Abstract:** 本文提出了一种名为扩散损失引导策略优化（DLPO）的强化学习与人类反馈（RLHF）框架，旨在解决文本到语音（TTS）扩散模型在实时应用中效率低和建模语调韵律困难的问题。DLPO通过将原始训练损失融入奖励函数并利用自然度得分作为反馈，在保持生成能力的同时显著提高了语音质量和效率。实验结果表明，DLPO在客观和主观评价上均优于基线模型，证明了其在实时、资源受限环境下实现高效高质量扩散TTS的潜力。

> **摘要翻译:** 扩散模型能产生高保真语音，但由于去噪步骤长以及在建模语调和韵律方面存在挑战，使得它们在实时使用中效率低下。为了改进这一点，我们提出了扩散损失引导策略优化（DLPO），一个用于TTS扩散模型的RLHF框架。DLPO将原始训练损失集成到奖励函数中，在保留生成能力的同时减少了低效率。通过使用自然度分数作为反馈，DLPO将奖励优化与扩散模型的结构对齐，从而提高了语音质量。我们在WaveGrad 2（一个非自回归扩散式TTS模型）上评估了DLPO。结果显示，在客观指标（UTMOS 3.65，NISQA 4.02）和主观评价方面均有显著改进，DLPO的音频有67%的时间被优先选择。这些发现表明DLPO在实时、资源受限的环境中，为高效、高质量的扩散TTS提供了潜力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [304] [Adaptive Knowledge Distillation for Device-Directed Speech Detection](https://arxiv.org/abs/2508.02801)
> *设备定向语音检测的自适应知识蒸馏*

*Hyung Gun Chi, Florian Pesce, Wonil Chang, Oggi Rudovic, Arturo Argueta, Stefan Braun, Vineet Garg, Ahmed Hussen Abdelaziz* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-08-04**

**Keywords:** 设备定向语音检测, 知识蒸馏, 语音助手, 预训练模型, 等错误率

**Comment:** 5 pages, 2 figures, Interspeech accepted

> **TL;DR:** 提出一种自适应知识蒸馏方法，通过利用预训练ASR编码器的知识，显著提高了设备定向语音检测的准确性，并在不同模型架构上表现出泛化能力。

**AI_Comments:** 这项工作通过引入自适应知识蒸馏，巧妙地利用了大型预训练ASR模型的强大通用表示，有效地解决了设备定向语音检测的准确性问题。其创新点在于结合了任务特定适配器，使得知识转移更加高效且目标明确。在提高性能的同时，也考虑了部署效率，这对于实际应用非常重要。

<details>
  <summary>Details</summary>

**Motivation:** DDSD对于实现自然的语音助手用户体验至关重要，并且需要提高准确性同时保证高效部署。

**Method:** 本文提出了一种新颖的自适应知识蒸馏（KD）方法，旨在从一个大型预训练ASR声学编码器（教师模型）的通用表示中转移知识。具体做法是在冻结的教师编码器之上应用任务特定的适配器，并与学生模型在DDSD任务上进行联合训练。

**Result:** 所提出的自适应KD方法在关键词和无关键词（后续）调用中，等错误率分别比没有蒸馏的学生模型提高了26%和19%。此外，该方法被证明可以泛化到Transformer和Conformer模型架构。

**Conclusion:** 自适应知识蒸馏能够显著提高设备定向语音检测的准确性，并具有良好的模型泛化能力，有助于实现更自然的语音助手用户体验。

> **ai_Abstract:** 本文提出了一种新颖的自适应知识蒸馏（KD）方法，用于设备定向语音检测（DDSD）。该方法通过将来自大型预训练ASR声学编码器的知识转移到学生模型，并在冻结的教师编码器上使用任务特定适配器进行联合训练，显著提高了DDSD的准确性。实验结果表明，该方法在关键词和无关键词调用中，等错误率分别提高了26%和19%，并且在Transformer和Conformer架构上具有良好的泛化能力，有助于提升语音助手的用户体验。

> **摘要翻译:** 设备定向语音检测（DDSD）是一项二元分类任务，用于将用户对语音助手（VA）的查询与背景语音或侧边对话区分开来。这对于实现自然的用户体验至关重要。为此，我们提出了知识蒸馏（KD）来提高DDSD的准确性，同时确保高效部署。具体而言，我们引入了一种新颖的自适应KD方法，该方法从ASR大型预训练声学编码器（教师模型）的通用表示中转移知识。我们在（冻结的）教师编码器之上应用任务特定的适配器，并与学生模型在DDSD上联合训练。我们证明了所提出的自适应KD在关键词和无关键词（后续）调用中，分别在等错误率方面比没有蒸馏的学生模型提高了+26%和+19%。我们还表明，这种方法可以泛化到Transformer和Conformer模型架构。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [338] [SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering](https://arxiv.org/abs/2508.03448)
> *SonicMaster：迈向可控的一体化音乐修复与母带处理*

*Jan Melechovsky, Ambuj Mehrish, Dorien Herremans* | **Category: cs.SD, cs.AI, cs.MM, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 音乐修复, 母带处理, 生成模型, 音频质量, 文本控制

**Comment:** 

> **TL;DR:** SonicMaster 是一种统一的生成模型，通过文本控制或自动模式，解决音乐录音中的多种音频质量问题，实现了音乐修复和母带处理的一体化，并显著提升了音质。

**AI_Comments:** SonicMaster 的创新之处在于提出了首个统一的、可控的（通过文本指令）生成模型，用于音乐修复和母带处理，这极大地简化了传统上需要多个独立工具和手动调整的复杂过程。其构建的大型模拟降级数据集也为该领域的研究提供了宝贵的资源。该研究对于非专业人士和专业音乐制作人都有重要意义，因为它提供了一个更高效、更易用的解决方案来提升音频质量。

<details>
  <summary>Details</summary>

**Motivation:** 音乐录音，尤其是在非专业环境下制作的，常存在混响过大、失真、削波、音调不平衡和立体声像变窄等音频质量问题。传统方法需要使用独立的专业工具和手动调整来纠正这些问题。

**Method:** 本文提出了 SonicMaster，这是首个用于音乐修复和母带处理的统一生成模型，通过文本指令或自动模式处理各种音频伪影。该模型通过构建 SonicMaster 数据集进行训练，该数据集包含模拟了十九种常见降解类型（属于均衡、动态、混响、振幅和立体声五类增强组）的配对的降级和高质量音轨。该方法利用流匹配生成训练范式，学习将降级输入映射到经文本提示引导的清理和母带处理版本。

**Result:** 客观音频质量指标表明，SonicMaster 在所有伪影类别中显著提升了音质。此外，主观听力测试证实听众更偏爱 SonicMaster 增强后的输出而非原始降级音频。

**Conclusion:** SonicMaster 的统一方法能有效解决音乐录音中的多种音频质量问题，并能显著提升音质。

> **ai_Abstract:** SonicMaster 是一种创新的统一生成模型，旨在解决音乐录音中常见的音频质量问题，如混响、失真和音调不平衡。它支持文本指令控制和自动修复模式，通过流匹配生成训练范式，将降级音频转换为高质量版本。该模型利用专门构建的 SonicMaster 数据集进行训练，该数据集模拟了多种音频降级类型。客观和主观评估均表明，SonicMaster 能显著提升音质，并获得听众的偏爱。

> **摘要翻译:** 音乐录音经常遭受音频质量问题，例如混响过大、失真、削波、音调不平衡以及立体声像变窄，尤其是在非专业环境下制作时，缺乏专业设备或专业知识。这些问题通常需要使用独立的专业工具和手动调整来纠正。在本文中，我们介绍了 SonicMaster，这是首个用于音乐修复和母带处理的统一生成模型，它通过基于文本的控制解决了广泛的音频伪影问题。SonicMaster 根据自然语言指令应用有针对性的增强，也可以在自动模式下进行通用修复。为了训练这个模型，我们构建了 SonicMaster 数据集，这是一个大型的配对降级和高质量音轨数据集，通过模拟属于五种增强组（均衡、动态、混响、振幅和立体声）的十九种降级功能来创建常见的降级类型。我们的方法利用流匹配生成训练范式，学习一种音频转换，将降级输入映射到由文本提示引导的清理和母带处理版本。客观音频质量指标表明，SonicMaster 在所有伪影类别中显著提升了音质。此外，主观听力测试证实听众更偏爱 SonicMaster 增强后的输出而非原始降级音频，突出了我们统一方法的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [445] [AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation](https://arxiv.org/abs/2505.22053)
> *音频精灵：一个用于多样化多模态到多音频生成的免训练多智能体框架*

*Yan Rong, Jinting Wang, Guangzhi Lei, Shan Yang, Li Liu* | **Category: cs.SD, cs.MA, cs.MM, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 多模态到多音频生成, 多智能体系统, 免训练, AudioGenie, MA-Bench

**Comment:** 

> **TL;DR:** AudioGenie是一个免训练的多智能体框架，用于多样化多模态到多音频生成，通过双层架构解决数据稀缺和多音频处理挑战，并引入了MM2MA任务的第一个基准MA-Bench，实现了SOTA性能。

**AI_Comments:** 本文的创新点在于提出了一个“免训练”的多智能体框架AudioGenie，这对于数据稀缺的MM2MA任务具有重要意义。其双层架构（生成团队和监督团队）以及内置的自我校正机制，有效提升了多模态理解和多样化音频事件的处理能力。此外，构建并发布了首个MM2MA任务基准MA-Bench，为该领域未来的研究提供了宝贵资源，具有显著的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 多模态到多音频（MM2MA）生成面临高质量配对数据集稀缺和缺乏鲁棒多任务学习框架的挑战。直接应用多智能体系统到MM2MA任务存在三个关键挑战：对多模态输入（特别是视频）的细粒度理解不足；单一模型无法处理多样化的音频事件；以及缺乏用于可靠输出的自我校正机制。

**Method:** 提出AudioGenie，一个新颖的免训练多智能体系统，采用双层架构，包含生成团队和监督团队。生成团队设计了细粒度任务分解、自适应专家混合（MoE）协作实体用于多模态理解和动态模型选择，以及试错迭代细化模块用于自我校正。监督团队通过反馈循环确保时空一致性并验证输出。此外，构建了MA-Bench，这是第一个MM2MA任务基准，包含198个带有多种类型音频的标注视频。

**Result:** AudioGenie在8个任务的9项指标上取得了最先进（SOTA）或可媲美的性能。用户研究进一步验证了该方法在质量、准确性、对齐性和美学方面的有效性。

**Conclusion:** AudioGenie通过一个免训练的多智能体框架有效解决了多样化MM2MA生成中的挑战，该框架具有双层架构和自我校正机制。它实现了最先进的性能，并引入了新的基准MA-Bench。

> **ai_Abstract:** 本论文提出了AudioGenie，一个新颖的免训练多智能体框架，旨在解决多模态到多音频（MM2MA）生成中的挑战，例如数据稀缺和处理多样化音频类型的问题。AudioGenie采用双层架构，包括一个负责任务分解、MoE协作和迭代细化的生成团队，以及一个负责确保时空一致性和验证输出的监督团队。作者还构建了MA-Bench，这是首个MM2MA任务基准。实验证明，AudioGenie在多项指标和任务上达到了SOTA性能，用户研究也进一步证实了其有效性。

> **摘要翻译:** 多模态到多音频（MM2MA）生成在从多模态输入（例如视频、文本、图像）合成多样化且上下文对齐的音频类型（例如音效、语音、音乐和歌曲）方面面临重大挑战，这归因于高质量配对数据集的稀缺性以及缺乏鲁棒的多任务学习框架。最近，多智能体系统在解决上述问题方面展现出巨大潜力。然而，将其直接应用于MM2MA任务面临三个关键挑战：（1）对多模态输入（特别是视频）的细粒度理解不足，（2）单一模型无法处理多样化的音频事件，以及（3）缺乏用于可靠输出的自我校正机制。为此，我们提出了AudioGenie，一个新颖的免训练多智能体系统，其特点是具有生成团队和监督团队的双层架构。对于生成团队，设计了细粒度任务分解和自适应专家混合（MoE）协作实体，用于详细全面的多模态理解和动态模型选择，并设计了试错迭代细化模块用于自我校正。监督团队通过反馈循环确保时空一致性并验证输出。此外，我们构建了MA-Bench，这是第一个MM2MA任务基准，包含198个带有多种类型音频的标注视频。实验表明，我们的AudioGenie在8个任务的9项指标上取得了最先进（SOTA）或可媲美的性能。用户研究进一步验证了我们方法在质量、准确性、对齐性和美学方面的有效性。包含音频样本的项目网站可在https://audiogenie.github.io/找到。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [543] [AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation](https://arxiv.org/abs/2508.00733)
> *AudioGen-Omni：一种用于视频同步音频、语音和歌曲生成的统一多模态扩散Transformer*

*Le Wang, Jun Wang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 多模态扩散Transformer, 视频同步音频生成, 语音生成, 歌曲生成, 联合训练

**Comment:** 12 pages, 2 figures

> **TL;DR:** AudioGen-Omni 是一种统一的多模态扩散Transformer，能够生成与视频同步的高保真音频、语音和歌曲，并在效率和通用性方面实现了显著提升。

**AI_Comments:** AudioGen-Omni 的创新之处在于其统一的多模态扩散Transformer架构和新颖的联合训练范式，这使其能够同时处理并生成视频同步的音频、语音和歌曲，显著提升了生成内容的连贯性和真实感。特别是其通过解冻所有模态来克服文本冻结范式语义约束的方法，以及结合AdaLN和PAAPI的注意力机制，为多模态生成领域带来了新的思路。该工作在效率和通用性方面的提升也具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在文本冻结范式下存在语义约束，并且缺乏能够统一生成与视频同步的高保真音频、语音和歌曲的能力。

**Method:** AudioGen-Omni 基于多模态扩散Transformer (MMDit)，采用新颖的联合训练范式，整合了大规模视频-文本-音频语料库。它引入了一个统一的歌词-转录编码器，将歌唱和语音输入的字素和音素编码为密集帧级表示。这些表示通过一个基于AdaLN的联合注意力机制融合，该机制通过相位对齐各向异性位置注入 (PAAPI) 增强，并选择性地将RoPE应用于时间结构化模态以确保精确的跨模态对齐。通过解冻所有模态并掩蔽缺失输入，该方法缓解了文本冻结范式的语义约束。

**Result:** AudioGen-Omni 能够生成高保真音频、语音和歌曲，并与输入视频连贯同步。它能生成语义丰富、声学多样的音频，并在Text-to-Audio/Speech/Song 任务上取得了最先进的结果，同时增强了音频质量、语义对齐和唇形同步准确性。对于8秒的音频，推理时间为1.91秒，显著提高了效率和通用性。

**Conclusion:** AudioGen-Omni 提供了一种统一且高效的多模态扩散Transformer 方法，能够生成与视频高度同步的高质量音频、语音和歌曲，并在多项任务上实现了最先进的性能。

> **ai_Abstract:** AudioGen-Omni 是一种创新的多模态扩散Transformer，旨在统一生成与视频高度同步的高保真音频、语音和歌曲。它通过引入独特的联合训练范式，整合了大规模视频-文本-音频数据，并采用统一的歌词-转录编码器和增强的注意力机制（AdaLN与PAAPI结合），实现了语义丰富、声学多样的音频生成。该方法通过解冻所有模态并掩蔽缺失输入，克服了传统文本冻结范式的限制，显著提升了音频质量、语义对齐和唇形同步准确性，并在相关任务中达到了最先进的性能，同时展现出卓越的效率和通用性。

> **摘要翻译:** 我们提出了 AudioGen-Omni——一种基于多模态扩散Transformer (MMDit) 的统一方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲。AudioGen-Omni 引入了一种新颖的联合训练范式，无缝整合了大规模视频-文本-音频语料库，使模型能够生成以多模态输入为条件的语义丰富、声学多样的音频，并适应各种音频生成任务。AudioGen-Omni 采用统一的歌词-转录编码器，将歌唱和语音输入中的字素和音素编码为密集的帧级表示。密集的帧级表示通过基于 AdaLN 的联合注意力机制融合，该机制通过相位对齐各向异性位置注入 (PAAPI) 增强，其中 RoPE 被选择性地应用于时间结构化模态，以确保精确和稳健的跨模态对齐。通过解冻所有模态并掩蔽缺失输入，AudioGen-Omni 缓解了文本冻结范式的语义约束，从而实现了有效的跨模态条件化。这种联合训练方法提高了音频质量、语义对齐和唇形同步准确性，同时在文本到音频/语音/歌曲任务上取得了最先进的结果。对于 8 秒的音频，推理时间为 1.91 秒，它在效率和通用性方面提供了显著改进。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [739] [Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers](https://arxiv.org/abs/2508.02175)
> *隐藏在噪音中：通过潜在声学模式触发器揭示音频大语言模型对齐中的后门*

*Liang Lin, Miao Yu, Kaiwen Luo, Yibo Zhang, Lilan Peng, Dexian Wang, Xuehai Tang, Yuanhe Zhang, Xikang Yang, Zhenhong Zhou, Kun Wang, Yang Liu* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 音频大语言模型, 后门攻击, 声学触发器, 隐藏在噪音中, AudioSafe

**Comment:** 

> **TL;DR:** 该研究引入了一种名为HIN的新型后门攻击框架，该框架利用细微的、特定于音频的特征来攻击音频大语言模型（ALLM）。通过修改音频波形（如时间动态和噪声注入），HIN嵌入了鲁棒的触发器，导致ALLM的准确性下降。研究人员还开发了一个名为AudioSafe的基准来评估ALLM的鲁棒性，发现ALLM对环境噪声和语速变化等音频特征非常敏感，而对音量变化不敏感，并且攻击具有高度隐蔽性。

**AI_Comments:** 这项研究首次深入探讨了音频大语言模型（ALLM）在后门攻击方面的脆弱性，并提出了一种名为HIN的新型攻击框架。该框架利用了音频信号特有的声学特征，如时间动态和噪声模式，成功实现了高攻击率和高隐蔽性。研究人员开发的AudioSafe基准为评估ALLM的安全性提供了一个重要的工具。然而，该研究也指出了ALLM在处理不同声学特征时的敏感度差异，特别是对音量变化不敏感的特性，这为未来的研究提供了方向。总的来说，这项工作对于理解和防御ALLM的安全风险具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着音频大语言模型（ALLM）在语音处理领域的广泛应用，对其安全性的担忧日益增加。与文本和视觉领域不同，音频领域具有独特的挑战，使得ALLM容易受到后门攻击，这些攻击利用了音频的特定声学特征。

**Method:** 该研究提出了一种名为“隐藏在噪音中”（HIN）的新型后门攻击框架。HIN通过对原始音频波形进行声学修改来实现，例如改变时间动态和注入经过精心设计的频谱噪声，从而在音频流中嵌入鲁棒的触发器。为了评估ALLM对基于音频特征的触发器的鲁棒性，研究人员开发了AudioSafe基准，该基准包含九种不同的风险类型。

**Result:** 实验结果表明，ALLM在面对利用环境噪声和语速变化等音频特征的后门攻击时，平均攻击成功率超过90%。然而，ALLM对音量变化等触发器表现出较低的敏感度。此外，在训练数据中加入被污染的样本只会导致损失曲线发生微小的波动，表明该攻击具有高度隐蔽性。

**Conclusion:** 研究证明了ALLM在利用声学特征（如环境噪声和语速变化）的后门攻击方面存在显著的漏洞，这些攻击具有高成功率和高度隐蔽性。研究结果强调了开发更强大的ALLM安全机制的必要性，以应对这些特定于音频的威胁。

> **ai_Abstract:** 本研究提出了一种名为HIN的新型后门攻击框架，用于利用音频大语言模型（ALLM）中的声学触发器。通过修改音频波形中的时间动态和注入噪声，HIN能够成功地在ALLM中嵌入触发器，导致超过90%的攻击成功率，同时保持高度隐蔽性。研究还开发了一个名为AudioSafe的基准来评估ALLM的鲁棒性，并发现ALLM对某些声学特征（如环境噪声和语速）敏感，而对其他特征（如音量）不敏感。

> **摘要翻译:** 随着音频大语言模型（ALLM）成为强大的语音处理工具，其安全影响已引起迫切关注。尽管在文本和视觉安全方面已有大量研究，但音频的独特特性带来了严峻的挑战。本文首先探讨：ALLM是否容易受到利用声学触发器的后门攻击？为应对此问题，我们引入了隐藏在噪音中（HIN），一个旨在利用细微的、特定于音频的特征的新颖后门攻击框架。HIN对原始音频波形进行声学修改，例如改变时间动态和注入经过频谱定制的噪声。这些改变引入了ALLM的声学特征编码器所捕获的一致模式，从而在音频流中嵌入了鲁棒的触发器。为评估ALLM对音频特征触发器的鲁棒性，我们开发了AudioSafe基准，评估了九种不同的风险类型。在AudioSafe和三个已建立的安全数据集上的广泛实验揭示了现有ALLM的关键漏洞：(I) 环境噪声和语速变化等音频特征实现了超过90%的平均攻击成功率。(II) ALLM在不同声学特征上表现出显著的敏感度差异，特别是对音量作为触发器反应很小，以及(III) 被污染样本的包含仅导致损失曲线的边际波动，凸显了攻击的隐蔽性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [865] [Neural Speech Extraction with Human Feedback](https://arxiv.org/abs/2508.03041)
> *神经语音提取与人类反馈*

*Malek Itani, Ashton Graves, Sefik Emre Eskimez, Shyamnath Gollakota* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 目标语音提取,人类反馈,迭代改进,神经网络,数据增强,Human-in-the-loop,Target Speech Extraction,Neural Speech Extraction,Human Feedback,Iterative Refinement,Synthetic Data,Noise Power Masking,Probabilistic Thresholding

**Comment:** Interspeech 2025

> **TL;DR:** 提出了一种使用人类反馈进行迭代改进的神经目标语音提取（TSE）系统，通过用户标记错误片段并生成编辑掩码来优化输出，同时保留未标记区域。由于难以收集大规模人类标记错误数据集，因此使用多种自动化掩码函数生成合成数据集进行模型训练。评估表明，基于噪声功率（dBFS）掩码和概率阈值训练的模型表现最佳，并且用户更喜欢改进后的输出。

**AI_Comments:** 这项工作首次将人类反馈引入神经目标语音提取领域，并通过实验证明了其有效性。通过模拟人类反馈来生成训练数据是一个巧妙的解决方案，解决了大规模标注数据的瓶颈问题。然而，模拟函数的选择和性能对最终结果的影响还需要进一步探讨。此外，用户研究的规模虽然有22名参与者，但可以考虑更大规模的测试以提高结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 由于难以收集大规模人类标记的错误数据，因此需要一种有效的方法来改进神经目标语音提取（TSE）系统的性能，并探索人类反馈在这一过程中的作用。

**Method:** 提出了一种使用人类反馈进行迭代改进的神经目标语音提取（TSE）系统。用户通过标记TSE输出中的特定片段来生成编辑掩码，然后系统利用此掩码来优化标记区域，同时保持未标记区域不变。为了解决大规模人类标记错误数据集难以收集的问题，研究人员生成了使用各种自动化掩码函数的合成数据集，并在这些数据集上训练模型。

**Result:** 基于噪声功率（dBFS）掩码和概率阈值训练的模型在与人类标注的匹配度上表现最佳。在包含22名参与者的研究中，用户更倾向于选择经过改进的输出而非基线TSE输出。

**Conclusion:** 人类在环路中的改进是一种有前景的方法，可以提高神经语音提取系统的性能。

> **ai_Abstract:** 该研究提出了一种新颖的神经目标语音提取（TSE）系统，该系统利用人类反馈进行迭代改进。通过允许用户标记错误并生成编辑掩码，该系统能够优化特定区域，同时保留其他部分。为了克服大规模标注数据的挑战，研究利用自动化掩码函数生成合成数据集进行模型训练。结果显示，特定掩码方法（基于噪声功率和概率阈值）效果最佳，并且用户研究证实了改进后输出的优越性，表明人类在环路中的改进方法在提升TSE性能方面潜力巨大。

> **摘要翻译:** 我们提出了第一个使用人类反馈进行迭代改进的神经目标语音提取（TSE）系统。我们的方法允许用户标记TSE输出的特定片段，生成一个编辑掩码。然后，该改进系统在保持未标记区域的同时，改进被标记的区域。由于难以收集大规模的人类标记错误数据集，我们使用各种自动化掩码函数生成合成数据集，并在每个数据集上训练模型。评估表明，使用基于噪声功率（以dBFS为单位）的掩码和概率阈值进行训练的模型表现最佳，与人类标注一致。在一项涉及22名参与者的研究中，用户倾向于选择改进后的输出而不是基线TSE。我们的研究结果表明，人类在环路中的改进是提高神经语音提取系统性能的一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [891] [EmoSteer-TTS: Fine-Grained and Training-Free Emotion-Controllable Text-to-Speech via Activation Steering](https://arxiv.org/abs/2508.03543)
> *EmoSteer-TTS：通过激活引导实现细粒度且无需训练的情感可控文本到语音*

*Tianxin Xie, Shan Yang, Chenxing Li, Dong Yu, Li Liu* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 文本到语音,情感控制,激活引导,无需训练,细粒度控制

**Comment:** 

> **TL;DR:** EmoSteer-TTS是一种新的、无需训练的方法，通过操纵TTS模型内部的激活来精确控制语音情感，实现了情感转换、插值和消除等功能，并且可以集成到各种预训练模型中。

**AI_Comments:** 该研究在TTS情感控制领域提出了一个重要的创新，通过“激活引导”这一无需训练的方法实现了细粒度和连续的情感控制，克服了现有方法的局限性。该方法的可扩展性和集成性（可应用于多种预训练模型）也为其应用前景增添了亮点。然而，文中提到的“情感令牌搜索”的具体实现细节和其对情感控制精度的具体影响有待进一步阐述。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到语音（TTS）系统的情感控制粗糙且僵化，通常需要离散的情感标签或精心设计的文本提示，并且需要大量高质量数据进行训练。

**Method:** 通过实证观察修改基于流匹配的TTS模型内的部分激活可以改变语音情感，提出了一种无需训练且高效的算法，包括激活提取、情感令牌搜索和推理时引导，可集成到多种预训练模型中。

**Result:** EmoSteer-TTS能够实现细粒度、可解释和连续的语音情感控制，性能优于现有技术（SOTA），是首个实现无需训练和连续细粒度情感控制的TTS方法。

**Conclusion:** EmoSteer-TTS通过激活引导实现了训练免费、细粒度、可解释和连续的情感控制，克服了现有TTS系统的局限性。

> **ai_Abstract:** EmoSteer-TTS是一种创新的、无需训练的文本到语音（TTS）方法，通过操纵模型内部激活来实现细粒度的语音情感控制，包括情感转换、插值和消除。该方法可以集成到现有的预训练TTS模型中，并已在实验中证明其在控制语音情感方面的有效性和优越性。

> **摘要翻译:** 文本到语音（TTS）近年来取得了巨大进展。然而，大多数现有的TTS系统只能提供粗糙和僵化的情感控制，通常通过离散的情感标签或精心制作的详细情感文本提示来实现，这使得细粒度情感操纵要么无法实现，要么不稳定。这些模型还需要进行训练的大量高质量数据集。为了解决这些限制，我们提出了EmoSteer-TTS，一种新颖的无需训练的方法，通过激活引导实现细粒度的语音情感控制（转换、插值、消除）。我们首先通过实证观察到，修改基于流匹配的TTS模型中的部分内部激活可以有效地改变合成语音的情感语调。在此洞察的基础上，我们开发了一种无需训练且高效的算法，包括激活提取、情感令牌搜索和推理时引导，它可以无缝集成到各种预训练模型中（例如，F5-TTS、CosyVoice2和E2-TTS）。此外，为了获得有效的引导向量，我们构建了一个包含多样化说话人的精选情感语音数据集。大量的实验表明，EmoSteer-TTS能够实现细粒度、可解释和连续的语音情感控制，性能优于最先进（SOTA）的方法。据我们所知，这是首个在TTS中实现无需训练和连续细粒度情感控制的方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [892] [TF-MLPNet: Tiny Real-Time Neural Speech Separation](https://arxiv.org/abs/2508.03047)
> *小型实时神经网络语音分离*

*Malek Itani, Tuochao Chen, Shyamnath Gollakota* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 语音分离, 实时, 低功耗, TF-MLPNet, 助听设备

**Comment:** The 6th Clarity Workshop on Improving Speech-in-Noise for Hearing
  Devices (Clarity 2025)

> **TL;DR:** TF-MLPNet是首个能在低功耗加速器上实时运行的语音分离网络，性能优于现有模型，能在GAP9处理器上实时处理6毫秒音频，运行时长减少3.5-4倍。

**AI_Comments:** 该研究解决了在资源受限的助听设备上实现实时语音分离的关键挑战。TF-MLPNet的设计巧妙地结合了全连接层和卷积层，以适应低功耗硬件。其在GAP9处理器上的实时性能和 runtime 改进是重要的实际贡献。未来的工作可以探索在不同类型的噪声和多说话人场景下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为了在助听器等小型、低功耗设备上实现实时语音分离，以提供增强的听觉能力，但现有模型因计算能力限制无法在这些设备上运行。

**Method:** TF-MLPNet在时频域操作，通过交替堆叠全连接层处理频域序列，并通过卷积层独立处理每个频率单元的时间序列。模型采用混合精度量化感知训练（QAT）。

**Result:** TF-MLPNet能够在GAP9处理器上实时处理6毫秒的音频块，运行时长相比现有模型减少了3.5-4倍。

**Conclusion:** TF-MLPNet是首个能在低功耗加速器上实时运行的语音分离网络，在盲语音分离和目标语音提取方面优于现有模型。

> **ai_Abstract:** TF-MLPNet是一种新颖的语音分离网络，专为在助听器等低功耗设备上实现实时运行而设计。它在时频域处理，利用交替堆叠的全连接层和卷积层，并采用量化感知训练。实验证明，TF-MLPNet能在GAP9处理器上实时处理音频，且性能优于现有模型，运行时长显著减少。

> **摘要翻译:** 语音分离在助听设备上可以实现变革性的增强和强化听觉能力。然而，由于其有限的计算能力，最先进的语音分离网络无法在专为助听设备设计的微型、低功耗神经网络加速器上实时运行。我们提出了TF-MLPNet，这是首个能够在此类低功耗加速器上实时运行的语音分离网络，并且在盲语音分离和目标语音提取方面优于现有的流式模型。我们的网络在时频域操作，通过沿通道和频率维度交替堆叠的全连接层处理频率序列，并使用卷积层独立处理每个频率单元中的时间序列。结果表明，我们采用混合精度量化感知训练（QAT）的模型能够在GAP9处理器上实时处理6毫秒的音频块，与之前的语音分离模型相比，运行时长减少了3.5-4倍。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [920] [MiSTR: Multi-Modal iEEG-to-Speech Synthesis with Transformer-Based Prosody Prediction and Neural Phase Reconstruction](https://arxiv.org/abs/2508.03166)
> *多模态脑电图到语音合成：基于Transformer的韵律预测和神经相位重建*

*Mohammed Salah Al-Radhi, Géza Németh, Branislav Gerazov* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-08-05**

**Keywords:** MiSTR, 脑电图信号, 语音合成, Transformer, 韵律预测

**Comment:** 5 pages, 2 figures, 1 table. Accepted for presentation at Interspeech
  2025

> **TL;DR:** MiSTR是一个深度学习框架，利用脑电图信号合成语音，在提高语音清晰度和自然度方面取得了最先进的成果。

**AI_Comments:** 该研究提出了一种新颖的多模态语音合成方法MiSTR，有效地结合了iEEG信号的时域、频域和神经生理学信息，并通过Transformer模型实现了对语音韵律的精准预测和相位重建，显著提高了语音合成的清晰度和自然度。然而，在真实世界应用中，该模型对iEEG信号质量和标注的依赖性可能是一个挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为严重言语障碍者恢复交流能力。

**Method:** 1. 采用基于小波的特征提取来捕捉脑电图信号的精细时间、频谱和神经生理学表示。
2. 使用基于Transformer的解码器进行韵律感知频谱图预测。
3. 引入神经相位声码器，通过自适应频谱校正来强制执行谐波一致性。

**Result:** 在公开的脑电图数据集上评估，MiSTR在语音清晰度方面达到了最先进的水平，重建和原始梅尔频谱图之间的平均皮尔逊相关性为0.91，优于现有的神经语音合成基线。

**Conclusion:** MiSTR框架通过整合小波特征提取、基于Transformer的韵律感知预测和神经相位声码器，能够从脑电图信号合成清晰自然的语音，为言语障碍者的交流恢复提供了有前景的解决方案。

> **ai_Abstract:** MiSTR是一个创新的深度学习框架，用于从颅内脑电图（iEEG）信号合成语音。该框架结合了小波特征提取、基于Transformer的韵律预测和神经相位重建技术，旨在克服现有方法的局限性，实现更清晰、更自然的语音合成。实验结果表明，MiSTR在语音清晰度方面取得了显著进展，重建的语音特征与原始语音高度相关。

> **摘要翻译:** 从颅内脑电图（iEEG）信号合成语音为恢复严重言语障碍者的交流能力提供了一条有希望的途径。然而，由于特征表示、韵律建模和相位重建方面的限制，实现清晰自然的语音仍然具有挑战性。我们引入了MiSTR，一个深度学习框架，集成了：1）基于小波的特征提取，以捕捉iEEG信号精细的时间、频谱和神经生理学表示；2）一个基于Transformer的解码器，用于韵律感知频谱图预测；3）一个强制执行谐波一致性的神经相位声码器，通过自适应频谱校正。在公共iEEG数据集上进行评估，MiSTR在语音清晰度方面达到了最先进的水平，重建和原始梅尔频谱图之间的平均皮尔逊相关性为0.91，优于现有的神经语音合成基线。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [8] [PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset](https://arxiv.org/abs/2503.02497)
> *PennyLang：开创基于LLM的量子代码生成，采用新型以PennyLane为中心的L数据集*

*Abdul Basit, Nouhaila Innan, Muhammad Haider Asif, Minghao Shao, Muhammad Kashif, Alberto Marchisio, Muhammad Shafique* | **Category: cs.SE, cs.AI, quant-ph, 68T50 (Primary), I.2.7** | **Updated: 2025-08-05**

**Keywords:** 量子代码生成, 大型语言模型, PennyLane, 数据集, RAG

**Comment:** 8 pages, 6 figures, 7 tables

> **TL;DR:** PennyLang是一个新的量子代码数据集，专门用于PennyLane，显著提升了LLM在量子代码生成中的表现。

**AI_Comments:** 这项工作通过创建首个以PennyLane为中心的量子代码数据集，填补了LLM在量子软件开发领域的数据空白，具有重要的创新性。其提出的自动化数据集构建框架也为未来的研究提供了可复现的方法，对于推动AI辅助的量子编程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在量子软件开发中的应用受限，部分原因是缺乏用于LLM训练和作为可靠知识源的高质量数据集。

**Method:** 本文引入了PennyLang，一个包含3,347个PennyLane特有量子代码样本及其上下文描述的高质量现成数据集，这些数据源自教科书、官方文档和开源仓库。贡献包括：创建并开源PennyLang数据集；一个用于自动化量子代码数据集构建的框架，系统化了整理、标注和格式化以最大化LLM可用性；以及在检索增强生成（RAG）管道中对数据集进行多模型基线评估和消融研究。

**Result:** 结合PennyLang和RAG显著提升了性能：例如，Qwen 7B的成功率从无检索时的8.7%提升至全上下文增强后的41.7%，LLaMa 4从78.8%提升至84.8%，同时减少了幻觉并增强了量子代码的正确性。

**Conclusion:** 通过引入LLM工具和可复现的方法到PennyLane，本文旨在推动AI辅助的量子开发，超越了以往以Qiskit为中心的研究。

> **ai_Abstract:** 本文介绍了PennyLang，一个专为PennyLane量子编程设计的高质量数据集，旨在解决LLM在量子软件开发中缺乏高质量数据集的问题。该数据集包含3,347个来自多源的量子代码样本及其描述，并提供了一个自动化构建框架。通过在检索增强生成（RAG）管道中进行评估，研究表明PennyLang显著提升了LLM（如Qwen 7B和LLaMa 4）在量子代码生成任务上的成功率和代码正确性，并减少了幻觉，从而推动了AI辅助的PennyLane量子开发。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成、自然语言理解和领域特定推理方面提供了强大的能力。它们在量子软件开发中的应用仍然有限，部分原因是缺乏用于LLM训练和作为可靠知识源的高质量数据集。为了弥补这一差距，我们引入了PennyLang，一个现成的、高质量数据集，包含3,347个PennyLane特有的量子代码样本及其上下文描述，这些样本从教科书、官方文档和开源仓库中整理而来。我们的贡献有三方面：（1）创建并开源了PennyLang，一个专为PennyLane量子编程而构建的数据集；（2）一个自动化量子代码数据集构建框架，该框架系统化了整理、标注和格式化，以最大化下游LLM的可用性；（3）在检索增强生成（RAG）管道中，对多个开源模型（包括消融研究）进行了数据集的基线评估。使用PennyLang与RAG显著提高了性能：例如，Qwen 7B的成功率从无检索时的8.7%提升至全上下文增强后的41.7%，LLaMa 4从78.8%提升至84.8%，同时减少了幻觉并增强了量子代码的正确性。超越了以Qiskit为中心的研究，我们将基于LLM的工具和可复现的方法引入PennyLane，以推动AI辅助的量子开发。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [10] [Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors](https://arxiv.org/abs/2508.02968)
> *开发者对利用低代码方法为老年人构建无障碍和自适应应用的看法*

*Shavindra Wickramathilaka, John Grundy, Kashumi Madampe, Omar Haggag* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 低代码, 无障碍应用, 自适应应用, 老年人, 开发者感知

**Comment:** This paper has been submitted to ACM Transactions on Software
  Engineering and Methodology (TOSEM)

> **TL;DR:** 本研究通过对18位软件开发者的访谈，评估了低代码工具AdaptForge在为老年人开发无障碍和自适应应用方面的潜力，并提出了设计此类工具的建议。

**AI_Comments:** 本研究通过聚焦低代码技术在解决老年人应用无障碍和自适应问题上的潜力，具有重要的社会意义和实践价值。通过开发者访谈，提供了宝贵的经验数据，有助于未来低代码工具的设计和推广。其创新点在于结合了低代码、模型驱动工程与无障碍设计，以应对老龄化社会的特定需求。

<details>
  <summary>Details</summary>

**Motivation:** 全球老龄化人口带来了对包容性技术的需求，以促进老年人的自主性。传统开发方法在时间与资源限制下，常导致应用存在可访问性和个性化障碍。欧洲无障碍法案(EAA)等法规压力以及开发者对支持老年亲属的同理心，促使对支持无障碍和自适应软件开发的工具产生需求。

**Method:** 本研究采用基于访谈的实证研究方法，对18位软件开发者进行了访谈。研究评估了AdaptForge：一个低代码模型驱动工程(MDE)工具，该工具通过自动化代码生成来缓解开发限制，从而高效创建无障碍和自适应的老年用户应用。

**Result:** 基于访谈洞察，研究识别了开发者对采纳此类工具作为行业标准解决方案的期望，并提供了基于实证的建议，用于设计支持无障碍和自适应软件开发的低代码工具。

**Conclusion:** 本研究通过评估低代码工具AdaptForge并收集开发者反馈，为未来开发支持老年用户的无障碍和自适应应用提供了实践指导和设计建议。

> **ai_Abstract:** 本研究旨在探讨开发者对利用低代码方法为老年人构建无障碍和自适应应用的看法。面对全球老龄化带来的挑战和传统开发模式的局限性，论文通过对18位软件开发者的访谈，实证评估了低代码MDE工具AdaptForge的潜力。研究结果揭示了开发者对低代码工具的期望，并为设计高效、无障碍和自适应的软件开发工具提供了实用建议。

> **摘要翻译:** 全球老龄化人口带来了日益增长的社会挑战，迫切需要包容性技术来促进老年人的自主性。软件从业者可以通过提供增强老年人独立性、减少对家庭成员和医疗基础设施日常支持的数字服务来解决这一问题。然而，受时间和资源限制的传统开发实践，往往导致应用程序存在主要的无障碍和个性化障碍。欧洲无障碍法案（EAA）等监管要求的日益增长的压力，以及许多开发者对支持他们的老年亲人及他们未来自己的个人同理心，催生了对支持无障碍和自适应软件开发的工具的需求。为了满足这一需求，本文提出了一项基于访谈的实证研究，对18位软件从业者进行了访谈，评估了AdaptForge：一个低代码模型驱动工程（MDE）工具，该工具通过自动化代码生成缓解开发限制，从而高效创建适用于老年用户的无障碍和自适应应用程序。基于这些见解，我们识别了开发者对采用此类工具作为行业标准解决方案的期望，并为设计支持无障碍和自适应软件开发的低代码工具提供了基于实证的建议。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [38] [MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation](https://arxiv.org/abs/2508.02998)
> *MRG-Bench：评估和探索仓库级代码生成中上下文的需求*

*Haiyang Li* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 代码生成, 大型语言模型, 基准测试, 上下文, 多语言

**Comment:** 

> **TL;DR:** 当前LLM代码生成评估存在缺陷。MRG-Bench是一个新的多语言、真实世界、仓库级基准测试数据集。研究表明，当前模型在理解用户需求方面存在困难，并揭示了语言特异性上下文的需求。

**AI_Comments:** MRG-Bench通过引入真实世界数据、多语言支持和项目级可运行测试用例，显著提升了代码生成评估的实用性和可信度。其创新点在于不仅提供了一个更健壮的评估工具，还深入分析了模型失败的原因，特别是指出了“理解用户需求”是主要瓶颈，并强调了语言特异性上下文的重要性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLMs）在代码生成方面的评估数据集存在局限性，包括缺乏可运行的测试用例、偏离真实世界代码分布以及仅支持Python语言，这些问题削弱了评估结果的可靠性。

**Method:** 引入了MRG-Bench（多语言仓库级代码生成基准），这是一个新的数据集，用于更准确地评估LLMs在实际仓库级代码生成任务中的表现。MRG-Bench具有三个主要特点：(1) 源自真实世界代码仓库的实用数据，与实际分布对齐；(2) 支持多种编程语言，包括Python、Java和Go；(3) 提供项目级可运行测试用例以评估生成代码的质量。基于MRG-Bench，进行了包括大型语言模型、长上下文模型和RAG相关方法在内的广泛实验，并设计了新颖的实验来标注生成错误的原因。

**Result:** 当前的仓库级代码生成技术存在显著的性能缺陷。大多数方法都存在“难以理解用户需求”的问题，未能准确理解分配的任务。此外，不同仓库级上下文对这一问题的影响在不同编程语言之间表现出显著差异。

**Conclusion:** 当前仓库级代码生成模型存在性能不足，主要原因是难以准确理解用户需求。实践中需要为不同的编程语言设计专门的上下文信息。

> **ai_Abstract:** MRG-Bench是一个新的多语言、仓库级代码生成基准测试数据集，旨在解决现有评估数据集的局限性。它提供真实世界数据、支持Python、Java和Go等多种语言，并包含项目级可运行测试用例。基于MRG-Bench的实验表明，当前仓库级代码生成技术性能不足，主要原因是模型难以准确理解用户需求。研究还发现，不同仓库级上下文对模型性能的影响在不同编程语言中存在显著差异，提示需要为不同语言设计专门的上下文信息。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成方面展现了令人印象深刻的能力。然而，当前的评估数据集存在一些问题，例如缺乏可运行的测试用例、偏离真实世界代码的分布以及只能评估Python语言。这些局限性削弱了评估结果的可靠性。
为了解决这些局限性，我们引入了MRG-Bench（多语言仓库级代码生成基准），这是一个新颖的数据集，可以更准确地评估LLMs在实际仓库级代码生成任务中的表现。MRG-Bench具有三个主要特点：(1) 源自真实世界代码仓库的实用数据，与实际分布对齐；(2) 支持多种编程语言，包括Python、Java和Go；(3) 提供项目级可运行测试用例以评估生成代码的质量。
基于MRG-Bench，我们进行了包括大型语言模型、长上下文模型和RAG相关方法在内的广泛实验。这些评估结果表明，当前的仓库级代码生成技术存在显著的性能缺陷。为了进一步探究模型失败的原因，我们设计了新颖的实验来标注生成错误的根本原因。结果明确显示，大多数方法都存在“难以理解用户需求”的问题，未能准确理解其分配的任务。此外，不同仓库级上下文对这一问题的影响在不同编程语言之间表现出显著差异，这表明在实践中需要为不同的语言设计专门的上下文信息。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [70] [A System Model Generation Benchmark from Natural Language Requirements](https://arxiv.org/abs/2508.03215)
> *从自然语言需求生成系统模型的基准*

*Dongming Jin, Zhi Jin, Linyu Li, Zheng Fang, Jia Li, Xiaohong Chen* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 系统模型, 自然语言, 大型语言模型, 基准, 评估

**Comment:** 16 pages, 14 figures

> **TL;DR:** 大型语言模型（LLMs）在从自然语言需求生成系统模型方面表现不佳，研究人员为此提出了一个新基准SysMBench和评估指标SysMEval。

**AI_Comments:** 该论文的创新之处在于首次提出了用于评估大型语言模型生成系统模型能力的基准SysMBench和语义感知评估指标SysMEval，填补了该领域的空白。其重要性在于揭示了当前LLMs在处理复杂系统模型生成任务上的显著局限性，并为未来研究提供了宝贵的资源和评估框架。研究结果强调了该领域仍有巨大的改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 系统模型是软件开发中的关键工件，但其开发面临挑战，原因在于模型描述语言的特定语法和公共模型示例的相对稀缺性。尽管大型语言模型（LLMs）在代码生成方面表现出潜力，但目前缺乏评估其生成系统模型能力的基准。

**Method:** 本研究提出了SysMBench，一个包含151个人工策划场景的基准，涵盖流行领域和不同难度级别。每个场景包含自然语言需求描述、特定模型描述语言表达的系统模型和可视化系统模型图。自然语言需求作为LLM的输入，系统模型用于验证生成结果，可视化图用于手动验证。研究还引入了SysMEval，一种语义感知的评估指标，用于评估生成系统模型的质量。研究评估了17个流行的LLM，使用了三种传统指标和SysMEval，从直接提示到三种常用的增强策略。

**Result:** 大型语言模型在SysMBench上的表现不佳，最高的BLEU评分为4%，SysMEval-F1评分为62%。

**Conclusion:** 大型语言模型在从自然语言需求生成系统模型方面的表现不佳。研究发布了SysMBench及其评估框架，以促进未来基于LLM的系统模型生成研究。

> **ai_Abstract:** 本研究针对大型语言模型（LLMs）在从自然语言需求生成系统模型方面的能力评估，提出了首个专门的基准SysMBench和语义感知评估指标SysMEval。SysMBench包含151个人工策划的场景，每个场景包括自然语言需求、对应的系统模型和可视化图。研究使用SysMBench评估了17个主流LLMs，结果显示LLMs在此任务上表现普遍不佳，最高BLEU和SysMEval-F1分数分别为4%和62%。本工作为未来LLM在系统模型生成领域的研究提供了重要的基准和评估框架。

> **摘要翻译:** 系统模型是软件开发中的关键工件，它提供了软件系统结构和行为方面的形式化抽象，有助于早期的需求分析和架构设计。然而，由于模型描述语言的特定语法和公共模型示例的相对稀缺性，开发系统模型仍然充满挑战。尽管大型语言模型（LLMs）在用编程语言生成代码方面显示出潜力，并且可能有助于系统模型的开发，但目前还没有基准来评估它们使用特定描述语言生成系统模型的能力。我们提出了SysMBench，它包含151个人工策划的场景，涵盖了广泛的流行领域和不同难度级别。每个场景主要包括自然语言需求描述、用特定模型描述语言表达的系统模型以及可视化系统模型图。需求描述作为用户输入提供给LLM，带有描述语言的系统模型用于验证生成的系统模型是否符合需求，可视化图用于支持手动验证。我们引入了SysMEval，一种语义感知的评估指标，用于评估生成的系统模型的质量。我们使用三种传统指标和SysMEval，从直接提示到三种常用的增强策略，评估了17个流行的LLM在此任务上的表现。我们深入的评估表明，LLM在SysMBench上表现不佳，最高的BLEU评分为4%，SysMEval-F1评分为62%。我们发布了SysMBench及其评估框架，以促进未来基于LLM的系统模型生成研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [102] [SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization](https://arxiv.org/abs/2508.03258)
> *SmartLLMs调度器：一个经济高效的LLMs利用框架*

*Yueyue Liu, Hongyu Zhang, Yuantian Miao* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** LLMs, 调度器, 成本效益, 动态调度, 软件工程

**Comment:** 

> **TL;DR:** SmartLLMs调度器（SLS）是一个动态且经济高效的解决方案，用于解决LLMs在高并发查询场景下部署面临的成本高、响应时间长和性能波动等挑战。SLS通过自适应缓存、性能成本优化调度和动态更新管理，显著提高了LLM在软件工程任务中的性能并缩短了处理时间。

**AI_Comments:** 这项工作提出了一种创新的动态调度框架，通过结合实时反馈和自适应缓存机制，有效解决了LLMs在大规模部署中的实际挑战。其创新性在于从静态调度转向动态调度，显著提高了资源利用效率和性能，对于推动LLMs在生产环境中的广泛应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在各种软件工程任务中表现出色，但其实际部署面临挑战，包括高昂的财务成本、漫长的响应时间以及性能波动，尤其是在处理大量查询（作业）时。现有优化策略侧重于静态调度，需要大量训练数据进行性能预测，这增加了计算成本并限制了适用性和灵活性。

**Method:** 本文提出了SmartLLMs调度器（SLS），一个动态且经济高效的调度解决方案。其核心思想是学习LLMs在不同任务上的性能，并结合实时反馈定期更新策略。SLS包含三个关键组件：自适应缓存管理器用于减少冗余计算和最小化响应时间；性能成本优化调度器根据预测的性能和成本动态分配查询到最合适的LLM；动态更新管理器持续根据分配查询的实时反馈优化缓存和调度策略。

**Result:** 在日志解析和代码生成这两个基于LLM的软件工程任务上进行的广泛实验表明，SLS显著优于基线方法，平均性能提升198.82%，平均处理时间减少63.28%。

**Conclusion:** SmartLLMs调度器（SLS）通过其动态、自适应的调度策略，有效解决了大型语言模型在高并发场景下部署的成本和性能问题，并在实际软件工程任务中展现出显著的性能提升和时间缩减。

> **ai_Abstract:** 本文提出SmartLLMs调度器（SLS），旨在解决大型语言模型（LLMs）在高并发部署中面临的成本高、响应慢和性能不稳等问题。SLS是一个动态且经济高效的调度框架，通过学习LLM性能并整合实时反馈来更新策略。它由自适应缓存管理器、性能成本优化调度器和动态更新管理器组成，能够减少冗余计算、优化任务分配并持续适应任务特性。实验证明，SLS在日志解析和代码生成等软件工程任务中显著提升了性能并缩短了处理时间。

> **摘要翻译:** 大型语言模型（LLMs），如GPT-4和Llama，在各种软件工程任务中展现出卓越的能力。尽管取得了这些进展，但它们的实际部署仍面临挑战，包括高昂的财务成本、漫长的响应时间以及性能波动，尤其是在处理大量查询（作业）时。现有用于部署LLM以完成不同任务的优化策略侧重于静态调度，这需要大量的训练数据进行性能预测，从而增加了计算成本并限制了适用性和灵活性。在本文中，我们提出了SmartLLMs调度器（SLS），一个动态且经济高效的调度解决方案。其核心思想是学习LLM在不同任务上的性能，并结合它们的实时反馈定期更新策略。具体而言，SLS包含三个关键组件，包括一个自适应缓存管理器、一个性能成本优化调度器和一个动态更新管理器。缓存管理器存储先前处理查询的输出，并采用自适应策略来减少冗余计算并最小化响应时间。对于未在缓存中找到的查询，调度器根据从同时考虑查询特定和LLM特定特征的模型预测的性能和成本，将它们动态分配给最合适的LLM。更新管理器根据分配查询的实时反馈持续优化缓存和调度策略，以增强决策制定并适应不断变化的任务特征。为了评估SLS的有效性，我们对两个基于LLM的软件工程任务（包括日志解析和代码生成）进行了广泛实验。结果表明，SLS显著优于基线方法，平均性能提升198.82%，平均处理时间减少63.28%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [142] [GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking](https://arxiv.org/abs/2508.03298)
> *GUI-ReRank：通过多模态LLM重排序增强GUI检索*

*Kristian Kolthoff, Felix Kretzer, Christian Bartelt, Alexander Maedche, Simone Paolo Ponzetto* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** GUI检索, 多模态LLM, 重排序, GUI原型, 嵌入式检索

**Comment:** 

> **TL;DR:** GUI原型构建耗时且现有检索方法性能有限。本文提出GUI-ReRank框架，结合快速嵌入式检索和多模态LLM重排序，显著优于现有技术，并支持自定义GUI库检索。

**AI_Comments:** GUI-ReRank的创新点在于将快速嵌入式检索与强大的多模态LLM重排序相结合，有效解决了现有GUI检索方法的性能和泛化性问题。其可定制的GUI存储库管道也大大提升了实用性，使其能够应用于更广泛的场景，并促进LLM-based RAG工作流的集成。这项工作为GUI设计和开发带来了显著的效率提升。

<details>
  <summary>Details</summary>

**Motivation:** GUI原型构建耗时且需要大量资源。现有的基于自然语言的GUI检索方法（通常依赖嵌入式检索或定制排名模型）在检索性能和跨任意GUI数据集的泛化能力方面存在局限性。

**Method:** 本文提出了GUI-ReRank，一个结合了快速嵌入式约束检索模型和高效MLLM（多模态大型语言模型）重排序技术的新颖框架。GUI-ReRank还引入了一个完全可定制的GUI存储库注释和嵌入管道，使用户能够轻松地使其自己的GUI存储库可搜索。

**Result:** GUI-ReRank在一个既定的基于自然语言的GUI检索基准上进行了评估，结果表明其在检索准确性和泛化能力方面显著优于最先进的定制LTR模型。此外，还对使用MLLM进行重排序的成本和效率进行了全面分析，提供了关于检索有效性和计算资源之间权衡的宝贵见解。

**Conclusion:** GUI-ReRank通过结合嵌入式检索和多模态LLM重排序，有效提升了GUI检索的性能和泛化能力，并支持自定义GUI库的快速检索。

> **ai_Abstract:** 本文提出了GUI-ReRank，一个旨在解决GUI原型构建耗时且现有NL-based GUI检索方法性能受限问题的框架。GUI-ReRank结合了快速嵌入式检索和多模态LLM（MLLM）重排序技术，并提供了可定制的GUI存储库注释和嵌入管道。实验结果表明，GUI-ReRank在GUI检索的准确性和泛化能力上显著优于现有最先进的模型，并对MLLM重排序的成本效益进行了分析。

> **摘要翻译:** GUI原型设计是现代交互系统开发中的一个基本组成部分，这些系统现在广泛应用于各种应用领域。GUI原型通过使利益相关者能够协作地可视化、评估和完善系统概念，在需求启发中发挥着关键作用。此外，原型作为早期测试、迭代评估以及与最终用户和开发团队验证设计思想的有效工具。尽管有这些优点，构建GUI原型的过程仍然资源密集且耗时，经常需要大量的精力和专业知识。最近的研究试图通过基于自然语言的GUI检索方法来减轻这一负担，这些方法通常依赖于基于嵌入的检索或针对特定GUI存储库的定制排名模型。然而，这些方法常常检索性能有限，并且难以泛化到任意GUI数据集。在这项工作中，我们提出了GUI-ReRank，一个新颖的框架，它将快速基于嵌入的约束检索模型与高效的基于MLLM的重排序技术相结合。GUI-ReRank进一步引入了一个完全可定制的GUI存储库注释和嵌入管道，使用户能够轻松地使其自己的GUI存储库可搜索，从而实现快速发现相关GUI以获取灵感或无缝集成到定制的基于LLM的RAG工作流中。我们在一个既定的基于自然语言的GUI检索基准上评估了我们的方法，证明GUI-ReRank在检索准确性和泛化能力方面显著优于最先进的定制LTR模型。此外，我们对使用MLLM进行重排序的成本和效率进行了全面分析，提供了关于检索有效性和计算资源之间权衡的宝贵见解。视频：https://youtu.be/_7x9UCh82ug

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [182] [Key-Augmented Neural Triggers for Knowledge Sharing](https://arxiv.org/abs/2508.03340)
> *键增强神经触发器用于知识共享*

*Alex Wolf, Marco Edoardo Palma, Pooja Rani, Harald C. Gall* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 代码理解, 知识共享, 大型语言模型, 知识锚点, 本地部署

**Comment:** 

> **TL;DR:** KANT通过嵌入知识锚点和合成数据来解决大型语言模型在代码理解和知识共享中的语义碎片化、检索效率低和数据稀缺问题，从而实现高效的本地部署和显著的推理延迟降低。

**AI_Comments:** KANT的创新之处在于其通过“知识锚点”机制，有效地将代码库内部知识整合到LLM的训练和推理过程中，这直接解决了传统RAG方法中上下文过长和注意力饱和的问题。其从代码直接合成训练数据的方法也巧妙地克服了特定领域数据稀缺的挑战。该方法对于需要本地化部署和低延迟响应的工业应用具有重要意义，尤其是在代码理解和知识共享领域。

<details>
  <summary>Details</summary>

**Motivation:** 代码库级别的代码理解和知识共享是软件工程中的核心挑战。尽管大型语言模型（LLMs）在生成程序结构和逻辑解释方面展现出潜力，但仍面临以下限制：相关知识在代码库中分布造成的语义碎片化；RAG管道中检索效率低下和注意力饱和；代码库特定训练数据稀缺且过时；以及专有LLM带来的隐私和部署限制。

**Method:** 本文提出了键增强神经触发器（KANT），一种将知识锚点嵌入训练和推理过程的新方法。KANT允许内部访问代码库特定知识，以减少碎片化并将推理基于本地化上下文。此外，KANT直接从代码合成专用数据。在推理阶段，知识锚点替代冗长的上下文，从而减少令牌开销和延迟，并支持高效的本地部署。KANT通过定性人工评估合成数据集的意图覆盖率和质量、与SOTA基线在定性维度和推理速度上进行比较，以及在不同LLM上进行复制以评估泛化性。

**Result:** 合成训练数据与信息检索需求一致。KANT在人类标注员中获得了超过60%的偏好（LocalStack专家偏好79%的案例）。此外，KANT将所有模型的推理延迟降低了高达85%。

**Conclusion:** KANT非常适合可扩展、低延迟的本地部署，为代码理解提供了坚实的基础。

> **ai_Abstract:** 本文提出了一种名为键增强神经触发器（KANT）的新方法，旨在解决大型语言模型（LLMs）在代码库级别代码理解和知识共享中面临的挑战，如语义碎片化、检索效率低下、数据稀缺和部署限制。KANT通过在训练和推理中嵌入知识锚点，并直接从代码合成专用数据，实现了对代码库特定知识的内部访问。这减少了上下文冗余，降低了推理延迟，并支持高效的本地部署。实验结果表明，KANT的合成数据质量高，获得了人类评估者的高度偏好，并显著降低了推理延迟（高达85%），证明了其在可扩展、低延迟、本地化代码理解方面的潜力。

> **摘要翻译:** 代码库级别的代码理解和知识共享仍然是软件工程中的核心挑战。大型语言模型（LLMs）通过生成程序结构和逻辑的解释展现出前景。然而，这些方法仍然面临限制：首先，相关知识分布在代码库中的多个文件中，即语义碎片化。其次，检索效率低下和注意力饱和会降低RAG（检索增强生成）管道的性能，其中冗长、未对齐的上下文会使注意力过载。第三，代码库特定的训练数据稀缺且通常过时。最后，专有LLM由于隐私和部署限制阻碍了工业应用。为了解决这些问题，我们提出了键增强神经触发器（KANT），一种将知识锚点嵌入训练和推理过程的新方法。与现有方法不同，KANT允许内部访问代码库特定知识，从而减少碎片化并将推理基于本地化上下文。此外，我们直接从代码合成专用数据。在推理阶段，知识锚点替代冗长的上下文，从而减少令牌开销和延迟，同时支持高效的本地部署。我们通过以下方式评估KANT：对合成数据集的意图覆盖率和质量进行五个维度的人工定性评估；与现有最先进的基线在五个定性维度和推理速度上进行比较；以及在不同LLM上进行复制以评估泛化性。结果表明，合成训练数据与信息检索需求一致。KANT在人类标注员和LocalStack专家（偏好79%的案例）中获得了超过60%的偏好。此外，KANT将所有模型的推理延迟降低了高达85%。总的来说，它非常适合可扩展、低延迟的本地部署，为代码理解提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [221] [Psychological safety in software workplaces: A systematic literature review](https://arxiv.org/abs/2508.03369)
> *软件工作场所的心理安全：一项系统文献综述*

*Beatriz Santana, Lidivânio Monte, Bianca Santana de Araújo Silva, Glauco Carneiro, Sávio Freire, José Amancio Macedo Santos, Manoel Mendonça* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 心理安全, 软件工程, 系统文献综述, 团队绩效, 前因后果

**Comment:** 

> **TL;DR:** 本研究对软件工程领域心理安全现有知识进行了系统综述，识别了其前因和后果，发现学术界对此兴趣日益增长，并指出未来研究需填补理解空白。

**AI_Comments:** 该研究的重要性在于首次系统性地梳理了软件工程领域心理安全的研究现状，填补了该领域系统性二次研究的空白。它不仅确认了心理安全对软件团队绩效的重要性，还识别了多层面的影响因素。其局限性在于，虽然指出了研究空白，但未提供具体的解决方案，而是将此留给未来研究。然而，作为一项综述性研究，其价值在于为后续研究奠定了基础和指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 心理安全（PS）是影响团队福祉和绩效的重要因素，尤其在软件开发等协作和动态领域。尽管其重要性得到认可，但软件工程领域对PS的研究仍有限。软件开发的社会技术复杂性和快节奏特性对培养PS提出了挑战。目前尚未有系统性二次研究综合软件工程背景下PS的现有知识，因此本研究旨在系统回顾和综合软件工程中PS的现有知识。

**Method:** 本研究进行了一项系统文献综述，涵盖了从四个数字图书馆检索到的研究。提取的数据经过定量和定性分析。

**Result:** 研究结果表明，软件工程领域对心理安全的学术兴趣日益增长，大多数研究都以埃德蒙森的框架为基础。心理安全的前因因素在个体、团队和组织层面都有体现，包括团队自主性、敏捷方法和领导行为。

**Conclusion:** 心理安全促进软件开发中的创新、学习和团队绩效。然而，在理解影响心理安全的背景因素、其潜在机制以及增强心理安全的有效策略方面仍存在显著空白。未来的研究应通过调查心理安全在软件工程领域不同组织环境中的实际应用来填补这些空白。

> **ai_Abstract:** 本研究对软件工程领域中的心理安全（PS）进行了首次系统文献综述，旨在综合现有知识并识别PS的前因和后果。研究通过检索四个数字图书馆的文献并进行定量和定性分析，发现学术界对PS的兴趣日益增长，并识别出个体、团队和组织层面的前因因素。研究强调PS对软件开发中的创新、学习和团队绩效至关重要，并指出未来研究应关注其背景因素、机制和增强策略的实际应用，以填补现有知识空白。

> **摘要翻译:** 背景：心理安全（PS）是影响团队福祉和绩效的重要因素，尤其在软件开发等协作和动态领域。尽管其重要性得到认可，但软件工程领域对PS的研究仍然有限。软件开发的社会技术复杂性和快节奏特性对培养PS提出了挑战。据我们所知，目前尚未有系统性的二次研究综合软件工程背景下PS的现有知识。
目的：本研究旨在系统回顾和综合软件工程中PS的现有知识体系。具体而言，它旨在识别与软件开发过程中个体是否存在PS相关的潜在前因和后果。
方法：进行了一项系统文献综述，涵盖了从四个数字图书馆检索到的研究。提取的数据经过定量和定性分析。
结果：研究结果表明，软件工程领域对PS的学术兴趣日益增长，大多数研究都以埃德蒙森的框架为基础。PS的前因因素在个体、团队和组织层面都有体现，包括团队自主性、敏捷方法和领导行为。
结论：PS促进软件开发中的创新、学习和团队绩效。然而，在理解影响PS的背景因素、其潜在机制以及增强PS的有效策略方面仍存在显著空白。未来的研究应通过调查PS在软件工程领域不同组织环境中的实际应用来填补这些空白。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [254] [On the Evaluation of Large Language Models in Multilingual Vulnerability Repair](https://arxiv.org/abs/2508.03470)
> *大型语言模型在多语言漏洞修复中的评估*

*Dong wang, Junji Yu, Honglin Shu, Michael Fu, Chakkrit Tantithamthavorn, Yasutaka Kamei, Junjie Chen* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 漏洞修复, 多语言, GPT-4o, 软件工程

**Comment:** 

> **TL;DR:** 本文对大型语言模型（LLMs）在七种编程语言中的多语言漏洞修复性能进行了大规模实证研究，发现GPT-4o在少样本提示下表现出色，甚至优于现有领先方法，并在修复独特和危险漏洞方面展现优势，同时具有强大的泛化能力。

**AI_Comments:** 这项工作首次对LLMs在多语言漏洞修复方面进行了大规模的实证评估，填补了现有研究的空白，因为之前的方法大多局限于单一语言。其创新之处在于，它证明了通用LLMs在特定任务（如漏洞修复）上可以超越或媲美专门构建的工具，尤其是在处理多语言和泛化能力方面。研究结果对LLMs在软件工程领域的应用具有重要指导意义，特别是揭示了GPT-4o在修复独特和危险漏洞方面的优势，以及其强大的跨语言泛化能力。然而，论文也提到了LLM失败案例的原因，这为未来的研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于深度学习的漏洞修复方法局限于特定编程语言（如C/C++），而大型语言模型（LLMs）具有语言无关性和强大的语义理解能力，有望克服多语言漏洞修复的局限性。尽管已有工作探索LLMs的修复性能，但其效果不尽如人意，因此需要进行大规模实证研究来评估其性能。

**Method:** 进行了一项大规模实证研究，调查了自动化漏洞修复方法和最先进的LLMs在七种编程语言中的性能。

**Result:** GPT-4o（通过少样本提示进行指令调优）与领先方法VulMaster相比表现出竞争力。基于LLM的方法在修复独特漏洞方面表现优越，并且更有可能修复最危险的漏洞。指令调优的GPT-4o在以前未见的语言中的漏洞上表现出强大的泛化能力，优于现有方法。分析显示，Go语言在所有模型类型中始终达到最高的有效性，而C/C++表现最差。

**Conclusion:** LLMs在多语言漏洞修复方面具有广阔前景，特别是在修复独特和危险漏洞以及泛化到新语言方面。这项工作首次对跨多种语言的修复方法和LLMs进行了考察，强调了采用LLMs进行多语言漏洞修复的未来潜力。

> **ai_Abstract:** 本文对大型语言模型（LLMs）在七种编程语言中的多语言漏洞修复能力进行了首次大规模实证评估。研究发现，尽管现有深度学习方法受限于特定语言，但LLMs，尤其是指令调优的GPT-4o，在少样本提示下能与领先的专用工具（VulMaster）竞争，并在修复独特及高危漏洞方面表现更优。GPT-4o还展现出强大的跨语言泛化能力。分析表明Go语言的修复效果最佳，而C/C++最差。研究强调了LLMs在多语言漏洞修复领域的巨大潜力。

> **摘要翻译:** 各种基于深度学习的方法，包括预训练语言模型，已被提出用于自动修复软件漏洞。然而，这些方法仅限于特定的编程语言（C/C++）。大型语言模型（LLMs）的最新进展提供了语言无关的能力和强大的语义理解，展示了克服多语言漏洞限制的潜力。尽管一些工作已经开始探索LLMs的修复性能，但其有效性并不令人满意。为了解决这些限制，我们进行了一项大规模实证研究，以调查自动化漏洞修复方法和最先进的LLMs在七种编程语言中的性能。结果显示，通过少样本提示进行指令调优的GPT-4o与领先方法VulMaster相比表现出竞争力。此外，基于LLM的方法在修复独特漏洞方面表现出优越性能，并且更有可能修复最危险的漏洞。指令调优的GPT-4o在以前未见的语言中的漏洞上表现出强大的泛化能力，优于现有方法。分析显示，Go语言在所有模型类型中始终达到最高的有效性，而C/C++表现最差。基于研究结果，我们讨论了LLM在多语言漏洞修复方面的前景以及LLM失败案例背后的原因。这项工作首次考察了跨多种语言的修复方法和LLMs，突出了采用LLMs进行多语言漏洞修复的未来前景。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [283] [ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs](https://arxiv.org/abs/2507.10593)
> *ToolRegistry: 一个面向函数调用型LLMs的协议无关工具管理库*

*Peng Ding* | **Category: cs.SE, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-11**

**Keywords:** ToolRegistry, LLM, 工具管理, 协议无关, 函数调用

**Comment:** 

> **TL;DR:** ToolRegistry是一个协议无关的工具管理库，通过统一接口简化LLM工具集成，显著减少代码量并提高性能。

**AI_Comments:** ToolRegistry的创新之处在于其协议无关性，它通过统一接口解决了LLM工具集成中的核心痛点，显著降低了开发复杂性和开销。其开源性质和明确的性能提升数据（代码量减少、性能提升、兼容性）使其在LLM应用开发领域具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）的工具集成方法存在碎片化、协议限制和实现复杂性等问题，导致巨大的开发开销，限制了LLM能力的扩展。

**Method:** 本文提出了ToolRegistry，一个协议无关的工具管理库。它通过统一接口简化了工具的注册、表示、执行和生命周期管理。

**Result:** ToolRegistry将工具集成代码减少了60-80%，通过并发执行实现了高达3.1倍的性能提升，并与OpenAI函数调用标准100%兼容。实际案例研究表明，在各种集成场景中，开发效率和代码可维护性得到了显著改善。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了ToolRegistry，一个协议无关的工具管理库，旨在解决大型语言模型（LLM）工具集成中存在的碎片化、协议限制和复杂性问题。ToolRegistry通过提供统一接口简化了工具的注册、表示、执行和生命周期管理。评估结果显示，它能将工具集成代码减少60-80%，通过并发执行提升性能高达3.1倍，并与OpenAI函数调用标准完全兼容，显著提高了开发效率和代码可维护性。

> **摘要翻译:** 大型语言模型（LLM）应用程序越来越依赖外部工具来扩展其超越文本生成的能力。然而，当前的工具集成方法存在碎片化、协议限制和实现复杂性等问题，导致巨大的开发开销。本文提出了ToolRegistry，一个协议无关的工具管理库，通过统一接口简化了工具的注册、表示、执行和生命周期管理。我们的评估表明，ToolRegistry将工具集成代码减少了60-80%，通过并发执行实现了高达3.1倍的性能提升，并与OpenAI函数调用标准100%兼容。实际案例研究表明，在各种集成场景中，开发效率和代码可维护性得到了显著改善。ToolRegistry是开源的，可在https://github.com/Oaklight/ToolRegistry获取，并提供完整的文档https://toolregistry.readthedocs.io/。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [286] [LaTCoder: Converting Webpage Design to Code with Layout-as-Thought](https://arxiv.org/abs/2508.03560)
> *LaTCoder：通过布局即思考将网页设计转换为代码*

*Yi Gui, Zhen Li, Zhongyi Zhang, Guohao Wang, Tianpeng Lv, Gaoyang Jiang, Yi Liu, Dongping Chen, Yao Wan, Hongyu Zhang, Wenbin Jiang, Xuanhua Shi, Hai Jin* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 网页设计转代码, 布局即思考, 多模态大语言模型, 思维链, 布局保留

**Comment:** KDD 2025 v2

> **TL;DR:** LaTCoder提出了一种新的方法，通过将网页设计分解为图像块并使用基于思维链的提示生成代码，显著改善了多模态大语言模型在设计到代码转换任务中布局的保留，并在自动和人工评估中显示出显著提升。

**AI_Comments:** LaTCoder的创新点在于引入了“布局即思考”（Layout-as-Thought）的概念，将复杂的网页布局问题分解为更小的、可管理的块，并利用思维链提示来指导MLLM生成代码，从而有效解决了现有MLLM在设计到代码转换中布局保留不足的痛点。这种模块化和CoT结合的方法，为提高设计到代码的准确性和实用性提供了新的思路，对于前端开发效率的提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将网页设计转换为代码（设计到代码）在前端UI开发中至关重要，它弥合了视觉设计和功能实现之间的鸿沟。然而，当前的多模态大语言模型（MLLMs）在执行设计到代码任务时，往往无法准确保留布局。

**Method:** LaTCoder受到人类认知的“思维链”（CoT）推理启发，提出“布局即思考”（LaT）方法来增强网页设计中代码生成时的布局保留。具体而言，首先将网页设计划分为图像块；然后使用基于CoT的方法提示MLLMs为每个块生成代码；最后，应用两种组装策略（绝对定位和基于MLLM的方法），并通过动态选择确定最佳输出。

**Result:** 在公共基准和新的CC-HARD基准上，使用DeepSeek-VL2时，TreeBLEU分数提高了66.67%，MAE降低了38%，相比直接提示有显著改进。此外，人工偏好评估结果显示，注释者在超过60%的情况下更喜欢LaTCoder生成的网页。

**Conclusion:** LaTCoder通过引入“布局即思考”方法，显著提升了多模态大语言模型在设计到代码转换任务中布局的保留能力，并在多项评估中验证了其有效性。

> **ai_Abstract:** LaTCoder提出了一种新颖的“布局即思考”（LaT）方法，旨在解决多模态大语言模型（MLLMs）在将网页设计转换为代码时布局保留不准确的问题。该方法通过将设计分解为图像块，并结合基于思维链（CoT）的提示为每个块生成代码，再通过动态选择的组装策略（绝对定位或MLLM方法）优化最终输出。实验结果表明，LaTCoder显著提升了代码生成中的布局准确性，并在自动和人工评估中均表现出优越性，尤其在TreeBLEU和MAE指标上取得了显著改善。

> **摘要翻译:** 将网页设计转换为代码（设计到代码）在用户界面（UI）开发中对前端开发者至关重要，它弥合了视觉设计和功能实现之间的鸿沟。尽管最近的多模态大语言模型（MLLMs）在设计到代码任务中展现出巨大潜力，但它们在代码生成过程中常常未能准确保留布局。为此，我们从人类认知的思维链（CoT）推理中获得启发，提出了LaTCoder，这是一种通过“布局即思考”（LaT）来增强网页设计在代码生成过程中布局保留的新方法。具体而言，我们首先引入了一种简单而高效的算法，将网页设计划分为图像块。接下来，我们使用基于CoT的方法提示MLLMs为每个块生成代码。最后，我们应用两种组装策略——绝对定位和基于MLLM的方法——然后进行动态选择以确定最佳输出。我们使用多个骨干MLLMs（即DeepSeek-VL2、Gemini和GPT-4o）在公共基准和新引入的、更具挑战性的（具有复杂布局的）基准（CC-HARD）上评估了LaTCoder的有效性。自动度量指标的实验结果显示出显著改进。具体而言，与直接提示相比，使用DeepSeek-VL2时，TreeBLEU分数提高了66.67%，MAE降低了38%。此外，人工偏好评估结果表明，注释者在超过60%的情况下更喜欢LaTCoder生成的网页，这为我们方法的有效性提供了有力证据。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [320] [Intent Preserving Generation of Diverse and Idiomatic (Code-)Artifacts](https://arxiv.org/abs/2508.03642)
> *意图保持的多样化和地道（代码）工件生成*

*Oliver Westphal* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** 代码生成, 抽象构建块, 工件生成, 编程练习, 多样性

**Comment:** In Proceedings TFPiE 2025, arXiv:2508.02305

> **TL;DR:** 提出一种通过抽象构建块生成多样化、地道代码及相关工件的方法，解决传统生成器复杂性问题。

**AI_Comments:** 该论文的创新点在于提出了一个基于抽象构建块的通用框架，以解决在自动生成编程任务时，生成多样化、地道且相互关联的代码及其他工件的复杂性问题。这种模块化、抽象化的方法提高了生成器的适应性和可维护性，避免了为每种工件手动编写复杂生成器的困境。抽象中未提及具体实现细节或实验结果，因此无法评估其性能或实际效果。

<details>
  <summary>Details</summary>

**Motivation:** 自动生成编程练习任务时，需要生成多样化且地道的程序及相关工件（如行为规范、文本描述）。手动编写适用于多种相关工件的生成器复杂且难以适应新任务。

**Method:** 该方法不使用单一的整体生成器，而是定义少量抽象构建块，并为每个构建块定义各种工件的具体实现。然后，通过组合这些抽象构建块来指定所需工件的结构。这个抽象描述作为共同来源，自动派生出相关的工件。

**Result:** 该方法在可生成的工件种类上具有通用性，因此适用于广泛的上下文。

**Conclusion:** 通过定义抽象构建块和其组合来生成相关工件，可以有效地解决编程任务生成中多样化和地道性问题，并且该方法具有通用性和广泛的适用性。

> **ai_Abstract:** 本文提出一种新方法，用于自动生成多样化且地道的代码及相关工件，以解决传统单一生成器在处理复杂编程练习任务时的挑战。该方法通过定义抽象构建块及其具体实现，并将其组合来描述目标工件结构，从而实现从一个共同的抽象来源自动派生出多种相关工件，具有高度的通用性和适应性。

> **摘要翻译:** 当自动生成编程练习任务时，通常也需要自动生成程序。至少在提供示例解决方案作为自动反馈的一部分时是如此。但程序也可以作为练习任务描述的一部分，用于传达任务要求。编写能够生成多样化但地道代码且易于适应新任务的优秀程序生成器具有挑战性。如果任务生成需要额外的工件，例如用于测试的更通用的行为规范或额外的文本描述，挑战会加剧。手动为多个不同但密切相关的工件编写生成器会很快变得复杂。我们提出一种方法，即不为多个连接的工件编写单一的整体生成器，而是指定一小组抽象构建块，并为每个这样的构建块定义各种工件的具体实现集。然后，将生成工件的预期结构指定为这些小抽象构建块的组合。这个抽象描述随后作为共同来源，从中可以自动派生出相关的工件。该方法在可生成的工件种类上具有通用性，因此适用于广泛的上下文。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [353] [Automated Validation of LLM-based Evaluators for Software Engineering Artifacts](https://arxiv.org/abs/2508.02827)
> *软件工程工件中基于LLM评估器的自动化验证*

*Ora Nova Fandina, Eitan Farchi, Shmulik Froimovich, Rami Katan, Alice Podolsky, Orna Raz, Avi Ziv* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-04**

**Keywords:** LLM评估器, 自动化验证, 软件工程, REFINE, COBOL

**Comment:** 

> **TL;DR:** REFINE是一个自动化框架，用于验证软件工程任务中基于LLM的评估器。它通过生成质量递减的工件并测量评估器排名与预期排序的对齐程度来工作。该框架已在IBM内部用于COBOL编码任务，成功将LLM评估器的对齐分数从低于0.7提升到高于0.9。

**AI_Comments:** REFINE通过其独特的数据集构建方法（自动合成渐进式质量降低的工件）和可控的降级粒度，解决了LLM评估器验证中细粒度评估的难题。其在IBM生产环境中的实际应用证明了其实用价值和有效性，对于提升LLM在软件工程领域应用的可靠性具有重要意义。该框架为自动化评估LLM在复杂软件工程任务中的表现提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在软件工程中，LLM越来越多地用于生成、审查和评估代码工件，但建立LLM作为可靠的评估器仍然是一个开放的挑战。这是因为人工评估成本高昂、主观且不可扩展，而现有自动化方法无法识别工件质量的细微变化。

**Method:** 本文引入了REFINE（Ranking Evaluators for FIne grained Nuanced Evaluation），一个用于基准测试软件工程任务中基于LLM评估器的自动化框架。REFINE包含两个模块：层次数据集构建器（Hierarchy Dataset Builder）应用新颖的生成技术自动合成质量逐渐降低的工件；评估器测试器（Evaluator Tester）通过测量每个候选评估器配置的排名与预期排序的接近程度来量化其性能。REFINE的一个关键特性是可控性，用户可以调整降级粒度，从粗略过滤到对细微质量差距进行压力测试。

**Result:** REFINE已集成到IBM的内部开发工作流程中，并应用于COBOL的企业关键编程语言的代码生成、翻译和摘要任务，使用了工业数据。它被用于识别出在某些编码任务中将对齐分数从低于0.7提升到高于0.9的“LLM作为评判者”（LLM as a Judge）配置。这些对细微差别敏感的评估器现在正被模型训练团队积极使用，以支持模型发布决策。

**Conclusion:** REFINE框架提供了一种自动化、可控且有效的LLM评估器验证方法，显著提升了LLM在软件工程任务中评估的准确性和可靠性，并已被应用于实际生产环境，为模型发布决策提供了支持。

> **ai_Abstract:** 本文介绍了REFINE，一个用于自动化验证和基准测试软件工程任务中基于大型语言模型（LLM）评估器的框架。针对人工评估成本高昂且现有自动化方法缺乏细粒度识别能力的问题，REFINE通过其层次数据集构建器自动生成质量递减的工件，并通过评估器测试器量化评估器配置与预期排序的对齐程度。该框架在IBM的生产环境中应用于COBOL编码任务，成功将LLM评估器的对齐分数从0.7以下提升到0.9以上，生成的评估器已用于支持模型发布决策。

> **摘要翻译:** 自动化在软件工程中越来越依赖大型语言模型（LLM）来生成、审查和评估代码工件。然而，将LLM确立为可靠的评估器仍然是一个开放的挑战：人工评估成本高、主观且不可扩展，而现有自动化方法未能识别工件质量的细微变化。
我们引入了REFINE（Ranking Evaluators for FIne grained Nuanced Evaluation），一个用于基准测试软件工程任务中基于LLM评估器的自动化框架。REFINE由两个模块组成：层次数据集构建器（Hierarchy Dataset Builder）应用新颖的生成技术自动合成质量逐渐降低的工件，评估器测试器（Evaluator Tester）通过测量每个候选评估器配置的排名与预期排序的接近程度来量化其性能。
REFINE的一个关键特性是可控性：用户可以调整降级粒度，以逐步优化评估器配置，从粗略过滤到对细微质量差距进行压力测试。
虽然该方法是通用的，但我们专注于反映我们生产环境中实际需求的编码任务。REFINE已集成到IBM的内部开发工作流程中，并应用于COBOL（一种企业关键编程语言）的代码生成、翻译和摘要任务，使用了工业数据。它被用于识别出在某些编码任务中将对齐分数从低于0.7提升到高于0.9的“LLM作为评判者”配置。这些对细微差别敏感的评估器现在正被模型训练团队积极使用，以支持模型发布决策。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [357] [Agentic LMs: Hunting Down Test Smells](https://arxiv.org/abs/2504.07277)
> *智能体语言模型：追捕测试异味*

*Rian Melo, Pedro Simões, Rohit Gheyi, Marcelo d'Amorim, Márcio Ribeiro, Gustavo Soares, Eduardo Almeida, Elvys Soares* | **Category: cs.SE** | **Updated: 2025-08-04**

**Keywords:** 测试异味, 智能体语言模型, 代码重构, 自动化测试, Phi-4-14B

**Comment:** 

> **TL;DR:** 本研究评估了小型参数LLMs（如Llama-3.2-3B, Gemma-2-9B, DeepSeek-R1-14B, Phi-4-14B）通过智能体工作流检测和重构测试异味的能力。Phi-4-14B表现最佳，多智能体设置优于单智能体，且成功将生成代码合并到开源项目中。

**AI_Comments:** 该论文的创新点在于探索了小型参数语言模型结合智能体工作流来自动化检测和重构测试异味，而非传统上依赖大型或专有模型。其重要性在于证明了在资源受限环境下实现测试自动化和代码质量提升的可能性。成功将生成代码合并到开源项目是其方法实用性的有力证明。这为未来的软件工程自动化，尤其是在代码重构和维护方面，提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 测试异味会降低测试套件的可靠性并使维护复杂化。尽管有许多方法可以检测测试异味，但很少有方法支持自动化移除，且大多数依赖于静态分析或机器学习。本研究旨在评估小型参数语言模型在检测和重构测试异味方面的能力。

**Method:** 研究评估了Llama-3.2-3B、Gemma-2-9B、DeepSeek-R1-14B和Phi-4-14B等相对较小参数的语言模型，通过基于智能体的工作流（单智能体、双智能体和四智能体）检测和重构测试异味。实验使用了来自真实世界Java项目的150个实例中的5种常见异味。该方法可推广到Python、Golang和JavaScript。

**Result:** 所有模型几乎检测到所有测试异味实例。Phi-4-14B取得了最佳的重构准确率（pass@5达到75.3%）。Phi-4-14B在四智能体设置下的表现与专有大型语言模型（单智能体）的差距在5%以内。在五种异味类型中，多智能体设置在三种类型上优于单智能体设置，但对于断言轮盘（Assertion Roulette），一个智能体就足够了。Phi-4-14B生成的代码被提交到开源项目，其中六个被合并。

**Conclusion:** 小型参数的智能体语言模型在检测和重构测试异味方面表现出显著能力，尤其是在多智能体设置下。Phi-4-14B在重构准确性方面表现最佳，并且其生成的代码已被实际应用于开源项目，证明了其实用性。

> **ai_Abstract:** 本研究探讨了小型参数语言模型（如Phi-4-14B）在检测和自动化重构测试异味方面的潜力，采用单智能体和多智能体工作流。实验结果表明，这些模型能够有效检测异味，并且Phi-4-14B在四智能体设置下实现了高重构准确率，接近专有大型语言模型。多智能体方法在多数异味类型上表现更优，且部分生成的代码已被成功集成到开源项目中，突显了智能体语言模型在软件测试自动化中的实际应用价值。

> **摘要翻译:** 测试异味会降低测试套件的可靠性并使维护复杂化。虽然有许多方法可以检测测试异味，但很少有方法支持自动化移除，而且大多数依赖于静态分析或机器学习。本研究评估了参数量相对较小的模型——Llama-3.2-3B、Gemma-2-9B、DeepSeek-R1-14B和Phi-4-14B——通过基于智能体的工作流检测和重构测试异味的能力。我们评估了在一、二和四个智能体的工作流，针对来自真实世界Java项目的150个实例中的5种常见异味。我们的方法可以推广到Python、Golang和JavaScript。所有模型几乎检测到所有实例，其中Phi-4-14B实现了最佳的重构准确率（pass@5为75.3%）。Phi-4-14B在四智能体设置下的表现与专有LLM（单智能体）的差距在5%以内。在五种异味类型中，多智能体设置在其中三种上优于单智能体设置，但对于断言轮盘（Assertion Roulette），一个智能体就足够了。我们向开源项目提交了由Phi-4-14B生成的代码的拉取请求，其中六个已被合并。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [391] [Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures](https://arxiv.org/abs/2507.23425)
> *使用Kieker对Python软件进行动态和静态分析，包括重建架构*

*Daphné Larrivain, Shinhyung Yang, Wilhelm Hasselbring* | **Category: cs.SE** | **Updated: 2025-08-05**

**Keywords:** Python分析, 动态分析, 静态分析, Kieker, 可观测性框架

**Comment:** 9 pages, 9 figures. Added doi to zenodo reference. Replaced the
  pipeline diagram

> **TL;DR:** 该论文提出了一种结合静态和动态分析的Python分析管道，用于Kieker可观测性框架，以获取Python应用程序的结构洞察。

**AI_Comments:** 本文的创新点在于将Kieker可观测性框架扩展到Python领域，通过结合静态和动态分析来应对Python应用程序分析的挑战。这对于需要深入了解Python系统行为和架构的开发者和研究人员来说具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Kieker可观测性框架最初为Java设计，但鉴于Python日益增长的流行及其应用程序结构洞察的价值，支持Python变得非常有必要。

**Method:** 该论文提出了一种Python分析管道，它结合了静态分析和动态分析，以构建给定系统的完整视图。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种为Kieker可观测性框架扩展Python支持的方法。鉴于Python的日益普及以及获取其应用程序结构洞察的重要性，作者开发了一个结合静态和动态分析的Python分析管道，旨在为Python系统提供全面的视图。

> **摘要翻译:** Kieker可观测性框架是一个为用户提供为其应用程序设计自定义可观测性管道的工具。该工具最初是为Java量身定制的，但支持Python是值得的。近年来，Python的流行度呈爆炸式增长，因此获取Python应用程序的结构洞察变得非常有价值。我们的Python分析管道结合了静态和动态分析，以便构建给定系统的完整图景。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [508] [Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach](https://arxiv.org/abs/2508.03329)
> *工业监管下基于LLM的代码优化：一种代理混合方法*

*Mari Ashiga, Vardan Voskanyan, Fateme Dinmohammadi, Jingzhi Gong, Paul Brookes, Matthew Truscott, Rafail Giavrimis, Mike Basios, Leslie Kanthan, Wei Jie* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 工业代码优化, 大型语言模型, 代理混合, 监管合规, 开源模型

**Comment:** Submitted to ASE'25 Industry Showcase

> **TL;DR:** 在受监管的工业环境中，为了克服商业LLM的使用限制，本文提出了一种代理混合（MoA）方法，利用开源LLM进行代码优化，实现了成本节约和优化时间缩短，并提供了部署指南。

**AI_Comments:** 这篇论文的创新点在于首次将代理混合（MoA）方法应用于受监管的工业代码优化场景，并明确提出了使用开源LLM的有效性，为那些受限于商业模型使用的组织提供了切实可行的解决方案。其重要性在于，它不仅解决了实际的合规性难题，还通过经验证据量化了成本和时间效益，并提供了实用的部署指导，填补了工业LLM集成评估的空白。

<details>
  <summary>Details</summary>

**Motivation:** 受监管行业的组织由于数据隐私和合规要求，无法使用商业大型语言模型（LLM），这给在保持成本效益的同时实现高质量代码优化带来了巨大挑战。

**Method:** 本文通过实现一种代理混合（MoA）方法来解决这个问题，该方法直接从多个专门的LLM合成代码。研究将此方法与TurinTech AI的普通遗传算法（GA）集成系统以及单独的LLM优化器在真实工业代码库上进行了比较。

**Result:** 1. 首次将MoA应用于使用真实世界代码库的工业代码优化。
2. 经验证据表明，MoA在使用开源模型时表现出色，为受监管环境实现了14.3%至22.2%的成本节约和28.6%至32.2%更快的优化时间。
3. 部署指南显示，GA在商业模型方面具有优势，同时两种集成方法都优于单个LLM。
4. 通过对50个代码片段和七种LLM组合进行真实世界验证，生成了超过8,700个变体，弥补了工业LLM集成评估的空白。

**Conclusion:** 本文为组织在生产环境中平衡监管合规性与优化性能提供了可操作的指导。

> **ai_Abstract:** 本文针对受监管行业无法使用商业LLM进行代码优化的挑战，提出了一种代理混合（MoA）方法。该方法通过整合多个专业LLM生成代码，并与传统GA集成系统及单一LLM优化器进行对比。研究发现，MoA在开源模型上表现卓越，能显著降低成本并缩短优化时间，特别适用于受监管环境。此外，文章还提供了部署指南，指出GA在商业模型上的优势，并强调集成方法普遍优于单一LLM。这项工作通过大规模真实世界验证，为工业界在合规前提下实现高效代码优化提供了实用指导。

> **摘要翻译:** 近期大型语言模型（LLMs）在代码优化方面的进展，使得工业平台能够以前所未有的规模和速度自动化软件性能工程。然而，受监管行业的组织面临严格的LLM使用限制——许多组织由于数据隐私法规和合规性要求无法使用商业模型，这给在保持成本效益的同时实现高质量代码优化带来了巨大挑战。我们通过实施一种代理混合（MoA）方法来解决这个问题，该方法直接从多个专门的LLM合成代码，并将其与TurinTech AI的普通遗传算法（GA）集成系统以及单独的LLM优化器在真实工业代码库上进行比较。我们的主要贡献包括：(1) 首次将MoA应用于使用真实世界代码库的工业代码优化；(2) 经验证据表明，MoA在使用开源模型时表现出色，为受监管环境实现了14.3%至22.2%的成本节约和28.6%至32.2%更快的优化时间；(3) 部署指南显示，GA在商业模型方面具有优势，同时两种集成方法都优于单个LLM；(4) 通过对50个代码片段和七种LLM组合进行真实世界验证，生成了超过8,700个变体，弥补了工业LLM集成评估的空白。这为组织在生产环境中平衡监管合规性与优化性能提供了可操作的指导。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [524] [$\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection](https://arxiv.org/abs/2507.10583)
> *Droid：一个用于检测AI生成代码的资源套件*

*Daniil Orel, Indraneil Paul, Iryna Gurevych, Preslav Nakov* | **Category: cs.SE, cs.AI, cs.CY** | **Updated: 2025-08-05**

**Keywords:** AI生成代码检测, DroidCollection, DroidDetect, 对抗性样本, 度量学习

**Comment:** 

> **TL;DR:** 本文介绍了DroidCollection，一个包含百万级代码样本、七种编程语言和43个编码模型输出的AI生成代码检测数据集，以及DroidDetect，一个基于该数据集训练的编码器-only检测器套件。研究表明现有检测器泛化能力差，且易受对抗性攻击，但少量对抗性数据训练可弥补此问题，并通过度量学习和不确定性重采样提升训练效果。

**AI_Comments:** 该论文通过构建迄今为止最广泛的AI生成代码检测数据集DroidCollection，解决了现有检测器泛化能力和鲁棒性不足的问题。其创新点在于集合了多样化的代码样本（包括人机协作和对抗性样本），并提出了DroidDetect检测器，同时探讨了对抗性训练、度量学习和不确定性重采样等方法对提升检测器性能的重要性，为AI生成代码检测领域提供了宝贵的资源和深入的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI生成代码检测器在多样化的编码领域和编程语言上的泛化能力不足，且易受对抗性样本攻击。

**Method:** 本文编译了DroidCollection，一个包含超过百万代码样本、七种编程语言、43个编码模型输出以及人类-AI合著和对抗性样本的开放数据套件。随后，开发了DroidDetect，一个使用多任务目标在DroidCollection上训练的编码器-only检测器套件。实验中，通过对抗性数据训练、度量学习和基于不确定性的重采样来提高检测器性能。

**Result:** 实验表明，现有检测器在训练数据范围之外的编码领域和编程语言上泛化能力不足。大多数检测器容易被表面提示和对齐方法“人性化”输出分布所规避。通过少量对抗性数据训练可以弥补这个问题。度量学习和基于不确定性的重采样可以有效增强在可能嘈杂分布上的检测器训练。

**Conclusion:** 现有AI生成代码检测器泛化能力差且易受攻击，但通过构建大规模多样化数据集（DroidCollection）并在此基础上训练新的检测器（DroidDetect），结合对抗性数据训练、度量学习和不确定性重采样，可以显著提高AI生成代码检测器的性能和鲁棒性。

> **ai_Abstract:** 本文介绍了DroidCollection，一个大规模开放数据集，用于训练和评估AI生成代码检测器，该数据集包含百万级多语言代码样本，涵盖AI生成、人机协作及对抗性代码。在此基础上，作者开发了DroidDetect，一个基于多任务学习的编码器-only检测器。研究发现现有检测器泛化能力差且易受对抗性攻击，但通过少量对抗性数据训练可有效提升鲁棒性，同时度量学习和不确定性重采样也能增强检测器在噪声数据上的训练效果。

> **摘要翻译:** 在这项工作中，我们编译了DroidCollection，这是用于训练和评估机器生成代码检测器的最广泛的开放数据套件，包含超过一百万个代码样本、七种编程语言、来自43个编码模型的输出以及超过三个真实世界的编码领域。除了完全由AI生成的样本外，我们的集合还包括人机协作编写的代码以及明确设计用于逃避检测的对抗性样本。随后，我们开发了DroidDetect，这是一个使用多任务目标在DroidCollection上训练的编码器-only检测器套件。我们的实验表明，现有检测器的性能无法泛化到其狭窄训练数据之外的各种编码领域和编程语言。此外，我们证明了虽然大多数检测器很容易通过使用表面提示和对齐方法使输出分布“人性化”而受到损害，但通过在少量对抗性数据上进行训练可以很容易地弥补这个问题。最后，我们展示了度量学习和基于不确定性的重采样作为在可能嘈杂的分布上增强检测器训练的有效手段。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [570] [Agentic AI in 6G Software Businesses: A Layered Maturity Model](https://arxiv.org/abs/2508.03393)
> *6G软件业务中的代理AI：分层成熟度模型*

*Muhammad Zohaib, Muhammad Azeem Akbar, Sami Hyrynsalmi, Arif Ali Khan* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 代理AI, 6G, 软件业务, 成熟度模型, 组织准备度

**Comment:** 6 pages, 3 figures and FIT'25 Conference

> **TL;DR:** 本研究对6G软件业务中代理AI的采用进行了初步主题映射，识别了促成因素和阻碍因素，旨在为组织评估和提升其代理优先能力提供实用框架，并为后续开发分层成熟度模型奠定基础。

**AI_Comments:** 本论文通过识别代理AI在6G软件业务中采用的促成和阻碍因素，为该新兴领域提供了重要的初步洞察。其创新之处在于提出并启动了开发分层成熟度模型的工作，这对于指导组织有效整合代理AI至关重要。该研究的局限性在于其仍处于早期阶段，仅为可行性评估，尚未提供成熟度模型的具体细节或验证。

<details>
  <summary>Details</summary>

**Motivation:** 6G软件业务中代理AI系统的出现带来了战略机遇（如自主性、可扩展性和智能决策），但也伴随着技术不成熟、集成复杂性、组织准备不足以及性能-成本权衡等挑战。本研究旨在解决这些挑战，并帮助组织评估和提升其代理优先能力。

**Method:** 本研究进行了初步主题映射，结合多声部文献综述和目标扫描，识别了影响6G背景下代理软件采用的29个促成因素和27个阻碍因素。这些因素被进一步归类为每组五个高层主题。该研究被定位为一项可行性评估。

**Result:** 主题映射提供了一个结构化的概述，揭示了塑造组织代理转型准备度的促成和阻碍力量。本研究作为一项可行性评估，代表了一项更广泛研究计划的早期阶段，该计划旨在开发和验证一个基于CMMI模型的分层成熟度模型。

**Conclusion:** 本研究旨在提供一个实用的框架，以帮助软件驱动型组织评估、构建和提升其代理优先能力，以适应6G的需求。这项工作代表了开发和验证基于CMMI模型的分层成熟度模型的早期阶段。

> **ai_Abstract:** 本研究探讨了6G软件业务中代理AI的采用，识别了其带来的机遇与挑战。通过初步主题映射、文献综述和目标扫描，研究识别了影响代理软件采用的29个促成因素和27个阻碍因素，并将其归类为高层主题。这项可行性评估为组织代理转型提供了结构化视图，并为未来开发基于CMMI的分层成熟度模型奠定了基础，旨在帮助组织提升其代理优先能力以适应6G需求。

> **摘要翻译:** 6G软件业务中代理AI系统的出现带来了战略机遇和重大挑战。尽管此类系统有望在分布式环境中提高自主性、可扩展性和智能决策，但其采用引发了对技术不成熟、集成复杂性、组织准备不足以及性能-成本权衡的担忧。在本研究中，我们进行了一项初步主题映射，以识别影响6G背景下代理软件采用的因素。通过多声部文献综述和目标扫描，我们识别了29个促成因素和27个阻碍因素，这些因素进一步被归类为每组五个高层主题。这项主题映射提供了塑造组织代理转型准备度的促成和阻碍力量的结构化概述。本研究作为一项可行性评估，代表了一项旨在开发和验证基于CMMI模型的分层成熟度模型的更广泛研究计划的早期阶段，该模型可能包含数据、业务逻辑和表示层这三个软件架构维度。最终，这项工作旨在提供一个实用框架，以帮助软件驱动型组织评估、构建和提升其代理优先能力，使其与6G的需求保持一致。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [658] [Automated Code Repair for C/C++ Static Analysis Alerts](https://arxiv.org/abs/2508.02820)
> *C/C++静态分析警报的自动化代码修复*

*David Svoboda, Lori Flynn, William Klieber, Michael Duggan, Nicholas Reimer, Joseph Sible* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-04**

**Keywords:** 自动化代码修复, 静态分析, C/C++, 警报修复, 程序修复

**Comment:** 

> **TL;DR:** 本文介绍了一种自动化程序修复(APR)工具，用于修复C/C++代码中的静态分析警报，显著减少了手动工作量并提高了修复率。

**AI_Comments:** 本文的创新之处在于提出并实现了一个高效的自动化程序修复工具，专门针对C/C++静态分析工具产生的警报。其重要性体现在显著减少了软件开发中代码审查和缺陷修复的人工成本，并通过实证数据展示了其高修复率和低副作用。该工作还促成了标准机构对评估指标的更新，显示了其潜在的行业影响力。局限性可能在于其修复的简单性和局部性，以及是否能推广到更复杂的缺陷类型。

<details>
  <summary>Details</summary>

**Motivation:** 静态分析(SA)工具会产生大量指示C/C++代码缺陷和潜在安全漏洞的诊断警报，其中许多是误报。识别真阳性警报并修复相关代码需要巨大的努力，自动化程序修复(APR)工具可以提供帮助。

**Method:** 本文详细介绍了一个自动化程序修复(APR)工具的设计、开发和性能测试，该工具旨在修复由多个SA工具产生的、与3类警报相关的C/C++代码。其修复是简单且局部的。

**Result:** 该APR工具修复了在一个代码库上由一个SA工具产生的9234个警报中的8718个。对于2个缺陷类别、2个SA工具和2个代码库，该工具平均修复或判定为误报的警报超过80%。测试表明修复并未明显降低代码性能或引起新的警报。

**Conclusion:** 该APR工具能够显著减少C/C++静态分析警报的数量和分析师的手动工作量，并且其发现促使CERT编码标准重新评估和更新检测或修复违规的指标。本文还描述了包括SA数据的新实证分析、缺陷类别选择方法、APR工具的发布以及SA警报数据集等独特贡献。

> **ai_Abstract:** 本文介绍了一种针对C/C++静态分析警报的自动化程序修复(APR)工具。该工具旨在解决静态分析工具产生大量误报和修复缺陷所需手动工作量大的问题。作者详细阐述了该APR工具的设计、开发和性能测试，该工具能够修复由多个SA工具产生的3类警报。实验结果表明，该工具能显著减少警报数量，修复率高，并且修复不会显著影响代码性能。研究还促使CERT编码标准更新其评估指标，并贡献了新的SA数据分析和数据集。

> **摘要翻译:** （注：这项工作是一份预印本。）静态分析（SA）工具产生许多诊断警报，表明C或C++源代码可能存在缺陷并潜在地容易受到安全漏洞的攻击。其中许多警报是误报。识别真阳性警报并修复相关代码是巨大的努力，自动化程序修复（APR）工具可以提供帮助。我们的经验表明，APR可以显著减少SA警报的数量，并减少分析师审查代码的手动工作量。这篇工程经验论文详细介绍了我们构建的用于修复与多个SA工具产生的3类警报相关的C/C++代码的APR工具的设计、开发和性能测试。其修复是简单和局部的。此外，我们的发现说服了CERT编码标准的维护者重新评估和更新用于评估何时可检测或可修复违规指南的指标。我们讨论了为支持可信度和开发人员可接受性目标而做出的工程设计选择。我们的APR工具修复了一个代码库上由一个SA工具产生的9234个警报中的8718个。它可以修复3个缺陷类别。对于2个缺陷类别、2个SA工具和2个代码库，我们的工具平均修复或判定为误报的警报超过80%。测试表明修复并未明显降低代码性能或引起新的警报（sqlite3.c可能除外）。本文描述了独特的贡献，包括对SA数据的新实证分析、我们选择要修复的缺陷类别的方法、我们的APR工具的发布以及从开源SA工具在开源代码库上运行获得的SA警报数据集。它讨论了积极和消极的结果以及经验教训。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [690] [StoneDetector: Conventional and versatile code clone detection for Java](https://arxiv.org/abs/2508.03435)
> *StoneDetector：Java 的常规且通用的代码克隆检测*

*Thomas S. Heinze, André Schäfer, Wolfram Amme* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-05**

**Keywords:** 代码克隆, Java, 支配树, 文本比较, StoneDetector

**Comment:** supplementary information available at
  https://stonedetector.fmi.uni-jena.de/

> **TL;DR:** StoneDetector 是一个用于在 Java 源代码和字节码中查找代码克隆的平台，它使用基于支配树路径的文本比较，能够检测精确、相似和语法多样的代码克隆，并在性能和可扩展性方面优于其他工具。

**AI_Comments:** StoneDetector 在代码克隆检测领域具有重要意义，它提供了一种通用的方法来处理不同类型的代码克隆，并且在性能和可扩展性方面表现出色。其基于支配树路径的文本比较方法能够检测到更广泛的代码克隆变体，这是其创新之处。然而，对于更复杂的克隆变体（例如，通过重构或高级抽象实现的克隆）的处理能力仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发中的复制粘贴实践导致代码克隆频繁出现，这会增加项目体积并传播错误或漏洞，因此识别代码克隆非常重要。

**Method:** StoneDetector 平台利用基于支配树路径的文本比较方法来检测 Java 源代码和字节码中的代码克隆，支持不同的字符串度量和哈希算法。

**Result:** StoneDetector 能够检测精确、相似和语法多样的代码克隆，并且在性能和可扩展性方面优于其他常规克隆检测器，适用于 Java 源代码和字节码。

**Conclusion:** StoneDetector 是一个通用且高效的代码克隆检测平台，能够检测多种类型的代码克隆，并且在性能和可扩展性方面表现出色。

> **ai_Abstract:** StoneDetector 是一个用于检测 Java 代码克隆的平台，它采用基于支配树路径的文本比较方法，能够识别精确、相似和语法多样的代码克隆。该平台具有通用性，并支持多种配置选项，在性能和可扩展性方面经过广泛评估，优于其他常规克隆检测器。

> **摘要翻译:** 复制粘贴是软件开发中普遍的做法，因此，重复的代码随后被修改在软件项目中频繁出现。由于这种代码克隆，即相同或相似的代码片段，会使软件项目臃肿并导致错误或漏洞传播等问题，因此识别它们很重要。在本文中，我们提出了 StoneDetector 平台及其底层方法，用于在 Java 源代码和字节码中查找代码克隆。StoneDetector 实现了一种基于支配树表示的代码路径的文本比较的常规克隆检测方法。通过这种方式，该工具不仅可以找到精确和语法相似的近乎完美的代码克隆，还可以检测到由于语法变化较大而更难检测到的代码克隆。我们证明了 StoneDetector 作为常规克隆检测平台的通用性，并分析了其各种可用配置参数，包括不同字符串度量、哈希算法等的用法。在我们对多个最先进基准测试中的其他常规克隆检测器进行的详尽评估中，我们可以展示 StoneDetector 在 Java 源代码和字节码中查找代码克隆的性能和可扩展性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [724] [ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs](https://arxiv.org/abs/2508.03603)
> *ReFuzzer：一种增强 LLM 生成的测试程序有效性的反馈驱动方法*

*Iti Shree, Karine Even-Mendoz, Tomasz Radzik* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-05**

**Keywords:** LLM，编译器模糊测试，测试程序有效性，代码覆盖率，反馈驱动

**Comment:** 

> **TL;DR:** ReFuzzer 通过反馈循环和本地 LLM 改进了 LLM 生成的测试程序的有效性，提高了编译和运行时错误的检测和纠正能力，从而提高了代码覆盖率。

**AI_Comments:** 该研究提出了一个名为 ReFuzzer 的新颖框架，旨在解决现有基于 LLM 的编译器模糊测试器生成无效测试程序的挑战。通过引入反馈循环和本地 LLM 来检测和纠正错误，ReFuzzer 显著提高了测试程序的有效性和代码覆盖率。这项工作的重要性在于其在提高编译器测试自动化和效率方面的潜力。然而，该方法在不同编译器和复杂场景下的可扩展性和性能仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于 LLM 的编译器模糊测试器生成的测试程序常常存在语法或语义错误，这限制了它们在编译器优化和后端组件方面的有效性。

**Method:** ReFuzzer 通过一个反馈循环和一个本地 LLM 来系统地检测和纠正编译及运行时错误（例如除零或数组越界访问），从而对 LLM 生成的测试程序进行优化。

**Result:** ReFuzzer 将测试程序的有效性从 47.0-49.4% 提高到 96.6-97.3%，平均处理时间为 2.9-3.5 秒/测试程序，并显著提高了关键优化和 IR 生成组件的代码覆盖率（例如，向量化覆盖率在黑盒、灰盒和白盒模糊测试中分别提高了 9.2%、2.3% 和 7.1%）。

**Conclusion:** ReFuzzer 通过反馈驱动的方法显著提高了 LLM 生成的测试程序的有效性，能够检测和纠正编译及运行时错误，从而提高了代码覆盖率和测试效率。

> **ai_Abstract:** ReFuzzer 是一个创新的框架，通过利用反馈循环和本地 LLM 来改进大型语言模型 (LLM) 生成的测试程序的有效性。它解决了现有 LLM 模糊测试器生成的测试程序中普遍存在的语法和语义无效性问题。通过系统地检测和纠正编译及运行时错误，ReFuzzer 显着提高了测试程序的有效性，并增加了代码覆盖率，特别是在编译器优化和 IR 生成等关键领域。

> **摘要翻译:** 现有的基于 LLM 的编译器模糊测试器生成的测试程序常常存在语法或语义错误，这限制了它们在编译器优化和后端组件方面的有效性。我们引入了 ReFuzzer，一个通过系统地检测和纠正编译及运行时错误（例如除零或数组越界访问）来优化 LLM 生成的测试程序的框架。ReFuzzer 采用一个反馈循环和一个本地 LLM，在执行之前验证和过滤错误的程序，从而超越了崩溃检测，提高了模糊测试的有效性，并能够生成多样化且有效的测试程序。
我们评估了 ReFuzzer 在针对 LLVM/Clang 的黑盒、灰盒和白盒模糊测试方法中的有效性。ReFuzzer 将测试程序的有效性从 47.0-49.4% 提高到 96.6-97.3%，在双 GPU 机器上平均处理时间为 2.9-3.5 秒/测试程序。此外，ReFuzzer 显著提高了关键优化和 IR 生成组件的代码覆盖率。例如，向量化覆盖率在黑盒、灰盒和白盒模糊测试中分别提高了 9.2%、2.3% 和 7.1%，从而提高了测试效率。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [728] [Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](https://arxiv.org/abs/2508.02721)
> *蓝图优先，模型第二：确定性大语言模型工作流框架*

*Libin Qiu, Yuhang Ye, Zhirong Gao, Xide Zou, Junfu Chen, Ziming Gui, Weizhi Huang, Xiaobo Xue, Wenkai Qiu, Kun Zhao* | **Category: cs.SE, cs.AI, cs.PL** | **Updated: 2025-08-01**

**Keywords:** LLM代理,确定性工作流,源代码代理,执行蓝图,tau-bench

**Comment:** 8 pages, 6 figures, 3 tables

> **TL;DR:** 该研究提出了一种名为“源代码代理”的新框架，将工作流逻辑与大语言模型（LLM）分离，通过“蓝图优先，模型第二”的理念，使用源代码定义执行蓝图，并由确定性引擎执行，LLM仅作为工具处理复杂子任务，从而解决了LLM固有的非确定性问题，在tau-bench基准测试中取得了显著的性能提升和效率改进，适用于需要严格程序逻辑的应用。

**AI_Comments:** 这项工作通过将LLM的规划和执行能力解耦，有效地解决了LLM在确定性任务中的核心挑战。将工作流逻辑编码为源代码执行蓝图，并利用确定性引擎，确保了可预测性和可靠性，这对于许多现实世界的应用至关重要。在tau-bench上的出色表现证明了该框架的有效性。然而，该方法在多大程度上能够处理高度动态或未预料到的情况，以及蓝图的创建和维护成本，是值得进一步探讨的。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）代理的固有非确定性限制了它们在需要严格过程保真度和可预测执行能力的结构化操作环境中的应用。

**Method:** 提出“源代码代理”框架，遵循“蓝图优先，模型第二”的理念，将工作流逻辑与生成模型分离。首先将专家定义的运行程序编入基于源代码的执行蓝图，然后由确定性引擎执行。LLM被用作处理工作流中特定、复杂子任务的专用工具。

**Result:** 在tau-bench基准测试中，源代码代理取得了新的最先进成果，平均Pass^1得分比最强的基线高出10.1个百分点，同时显著提高了执行效率。

**Conclusion:** 该研究通过将工作流逻辑与LLM分离，实现了可验证和可靠的自主代理部署，适用于受严格过程逻辑约束的应用。

> **ai_Abstract:** 本研究提出了一种名为“源代码代理”的新框架，通过“蓝图优先，模型第二”的策略，将LLM工作流的逻辑与模型本身分离。该框架首先将操作程序编码为源代码执行蓝图，然后由确定性引擎执行，LLM仅作为工具处理特定子任务。该方法在tau-bench基准测试中取得了显著的性能提升和效率改进，为在严格的程序逻辑环境中部署LLM代理提供了可行的解决方案。

> **摘要翻译:** 虽然功能强大，但大型语言模型（LLM）代理固有的非确定性限制了它们在结构化操作环境中的应用，在这些环境中，过程保真度和可预测执行是严格的要求。这种限制源于当前将概率性、高层规划与低层动作执行在单一生成过程中相混淆的架构。为了解决这个问题，我们引入了源代码代理框架，这是一个基于“蓝图优先，模型第二”理念的新范式。我们的框架将工作流逻辑与生成模型分离。首先将专家定义的运行程序编入基于源代码的执行蓝图，然后由确定性引擎执行。LLM被战略性地调用，作为处理工作流中特定、复杂子任务的专用工具，但从不用于决定工作流的路径。我们对为复杂用户-工具-规则场景设计的具有挑战性的tau-bench基准进行了全面评估。我们的结果表明，源代码代理建立了新的最先进水平，在平均Pass^1得分上比最强的基线高出10.1个百分点，同时显著提高了执行效率。我们的工作使得在受严格过程逻辑约束的应用中部署可验证和可靠的自主代理成为可能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [778] [Tool-integrated Reinforcement Learning for Repo Deep Search](https://arxiv.org/abs/2508.03012)
> *用于代码库深度搜索的工具集成强化学习*

*Zexiong Ma, Chao Peng, Qunhong Zeng, Pengfei Gao, Yanzhen Zou, Bing Xie* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 问题定位, 大型语言模型, 代码库检索, 强化学习, 工具集成

**Comment:** 

> **TL;DR:** 本研究提出了一种名为ToolTrain的框架，通过两阶段训练（包括监督微调和工具集成强化学习），提升大型语言模型（LLM）利用代码库检索工具进行问题定位的能力。实验证明，ToolTrain显著提高了LLM在问题定位任务上的表现，并进而改善了端到端的软件问题解决能力。

**AI_Comments:** 该研究提出了一种新颖的框架ToolTrain，有效地解决了在软件问题定位任务中，大型语言模型（LLM）利用代码库检索工具的挑战。通过结合监督微调和强化学习，该方法在提升LLM的推理和导航能力方面取得了显著成果，并在实验中超越了现有最先进的模型。研究强调了针对特定任务（如问题定位）进行训练对于提升自动化软件开发的重要性，这为未来研究提供了有价值的方向。然而，对于该框架在不同规模的模型和更广泛的软件开发场景下的泛化能力，以及其训练成本和效率方面，可能还需要进一步的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于大型语言模型（LLM）的智能体在尝试解决软件问题定位（Issue Localization）这一具有挑战性的任务时，需要利用代码库检索工具。然而，这使得问题定位变成了一个复杂且要求严苛的“代码库深度搜索”任务，LLM需要有效地利用各种检索工具，并在多步推理和导航过程中进行操作。因此，需要一种方法来增强LLM使用检索工具的能力。

**Method:** 本研究提出了一种名为ToolTrain的两阶段工具集成训练框架。第一阶段采用拒绝采样监督微调（rejection-sampled supervised fine-tuning），第二阶段采用工具集成强化学习（tool-integrated reinforcement learning），旨在提升LLM利用检索工具进行问题定位的能力。

**Result:** 实验结果表明，经过ToolTrain训练的模型在问题定位任务上取得了最先进（state-of-the-art）的性能。具体来说，研究中320亿参数的模型在函数级别的定位准确率上甚至超过了Claude-3.7。此外，性能的提升也带来了更好的端到端问题解决效果，证明了针对问题定位进行训练是提升自动化软件开发能力的有效策略。

**Conclusion:** ToolTrain框架通过结合监督微调和强化学习，能够显著提升大型语言模型在代码库深度搜索和问题定位任务中的表现，并最终促进自动化软件开发能力的提升。针对问题定位进行训练是一种可行且有效的方法。

> **ai_Abstract:** 本研究提出ToolTrain框架，通过监督微调和强化学习相结合的两阶段训练方法，增强大型语言模型（LLM）在软件问题定位任务中利用代码库检索工具的能力。该方法解决了“代码库深度搜索”的挑战，实验结果显示其性能优于现有方法，并能提升整体软件开发效率。

> **摘要翻译:** 问题定位，即识别需要修改以解决软件问题的代码位置，是软件开发中一项关键但充满挑战的任务。自然语言问题描述与错误代码之间存在语义鸿沟，需要通过代码依赖关系进行复杂的多跳推理。现有的基于大型语言模型（LLM）的智能体试图通过集成代码库检索工具来解决这一问题。然而，这使得问题定位成为一项我们称之为“代码库深度搜索”的艰巨任务，要求LLM在多步推理和导航过程中有效地利用各种代码库检索工具。为了应对这一挑战，我们提出了ToolTrain，一个两阶段的工具集成训练框架，结合了拒绝采样监督微调和工具集成强化学习，以增强LLM利用检索工具进行问题定位的能力。实验结果表明，经过ToolTrain训练的模型取得了最先进的性能，其中我们32B模型在函数级别定位上甚至超越了Claude-3.7。结果还表明，改进的定位性能转化为更好的端到端问题解决性能。这进一步证明了针对问题定位进行训练是提高自动化软件开发能力的可行且有效策略。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [798] [What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus](https://arxiv.org/abs/2508.02733)
> *什么是一个证明？分析F*和Verus中的专家证明编写过程*

*Rijul Jain, Shraddha Barke, Gabriel Ebner, Md Rakib Hossain Misu, Shan Lu, Sarah Fakhoury* | **Category: cs.SE, cs.HC** | **Updated: 2025-08-01**

**Keywords:** 形式化证明, 专家编程, F*, Verus, AI证明助手

**Comment:** 

> **TL;DR:** 本研究分析了专家在F*和Verus两种语言中编写形式化证明的过程，发现了专家策略和挑战，并提出了改进AI证明助手的具体设计建议。

**AI_Comments:** 这项研究通过实际的用户研究和数据分析，深入探讨了专家在形式化证明过程中的行为，为AI驱动的证明工具的设计提供了宝贵的见解。研究的亮点在于识别出影响任务结果的非正式实践，并将其转化为可操作的设计原则。然而，研究的局限性可能在于样本量（仅八位专家）和语言选择（仅F*和Verus），这可能限制了结果的普适性。未来的工作可以扩展到更多语言和更多样化的用户群体，以验证这些发现的普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管有形式化证明能力的编程语言（POPLs）功能强大，但它们学习曲线陡峭，尚未被广泛采用。缺乏对证明开发过程和专家如何使用POPLs的理解，阻碍了有效的证明工程和证明合成模型/工具的发展。

**Method:** 通过用户研究，收集和分析了八位专家在使用F*和Verus这两种语言时的细粒度源代码遥测数据。

**Result:** 研究结果揭示了专家如何进行证明推理以及在证明开发过程中遇到的关键挑战。发现了三种不同的策略和多种非正式实践，这些实践虽未体现在最终代码快照中，但能预测任务结果。

**Conclusion:** 研究结果为AI证明助手提供了具体的设计指导，包括偏向早期规范起草、显式子目标分解、有限的活动错误和规范的验证器交互。研究还展示了一个基于这些建议的F*证明代理，其性能优于基线LLM。

> **ai_Abstract:** 本研究通过对使用F*和Verus语言的八位专家进行用户研究，分析了专家在形式化证明过程中的策略和挑战。研究结果揭示了未包含在最终代码中的关键实践，并据此提出了改进AI证明助手的具体设计建议，如早期规范起草和子目标分解。研究还展示了一个基于这些建议的F*证明代理，证明了其性能的提升。

> **摘要翻译:** 证明导向的编程语言（POPLs）使开发人员能够编写代码以及形式化正确性证明，提供代码符合指定要求的形式化保证。尽管它们具有强大的功能，但POPLs的学习曲线陡峭，尚未被更广泛的软件社区采用。对证明开发过程以及专家证明开发人员如何与POPLs交互的理解不足，阻碍了有效的证明工程以及证明合成模型/工具的发展。

在这项工作中，我们进行了一项用户研究，收集并分析了八位使用F*和Verus这两种语言的专家的细粒度源代码遥测数据。结果揭示了专家如何推理证明以及在证明开发过程中遇到的关键挑战方面有趣的趋势和模式。我们确定了三种不同的策略和多种非正式实践，这些实践未被最终代码快照捕获，但可以预测任务结果。我们将这些发现转化为对AI证明助手的具体设计指导：偏向早期规范起草、显式的子目标分解、有限的活动错误和有纪律的验证器交互。我们还展示了一个基于这些建议的F*证明代理的案例研究，并证明其性能优于基线LLM。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [827] [BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice](https://arxiv.org/abs/2508.03487)
> *位AI修复：LLM驱动的方法用于实际中的自动化Lint错误解决*

*Yuanpeng Li, Qi Long, Zhiyuan Yao, Jian Xu, Lintao Xie, Xu He, Lu Geng, Xin Han, Yueyan Chen, Wenbo Duan* | **Category: cs.SE, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** LLMs,Lint errors,automated code repair,reinforcement learning,static analysis

**Comment:** 

> **TL;DR:** 该论文提出了一种名为BitsAI-Fix的自动化工作流程，利用大型语言模型（LLMs）来解决代码中的Lint错误，以应对日益增长的技术债务和效率瓶颈。

**AI_Comments:** 该研究在解决实际工业代码库中普遍存在的Lint错误问题方面具有重要意义。通过结合LLMs、tree-sitter和创新的RL训练策略，BitsAI-Fix有效地解决了手动修复的瓶颈。85%的准确率和大规模部署的成功案例证明了该方法的有效性和可扩展性。然而，对“冗余修改”的界定和惩罚机制的有效性，以及在不同项目和语言上的泛化能力，可能还需要进一步的探索。

<details>
  <summary>Details</summary>

**Motivation:** 随着企业代码库规模和复杂性的增长，Lint错误数量庞大，超出了工程师手动修复的能力，导致技术债务累积和开发效率下降。

**Method:** BitsAI-Fix利用tree-sitter进行上下文扩展，并通过专门训练的LLMs生成搜索和替换格式的补丁，然后进行Lint扫描重新验证以输出最终的修复结果。该方法还引入了一种渐进式强化学习（RL）训练策略，用于在项目冷启动阶段自动获取可验证的训练数据，并通过收集在线样本进行持续迭代。此外，还设计了一种结合格式奖励和正确性奖励并惩罚冗余修改的基于规则的奖励机制，以及一种用于持续跟踪在线效果的“代码差异匹配”方法。

**Result:** 在字节跳动（ByteDance）的生产环境中部署后，该解决方案支持了超过5000名工程师，解决了超过12000个静态分析问题，修复准确率约为85%，每周活跃用户约1000人。

**Conclusion:** 该工作证明了基于LLM的代码修复解决方案在企业环境中的实际可行性，并为大规模工业场景中的自动化代码修复提供了参考。

> **ai_Abstract:** BitsAI-Fix是一个利用LLMs自动修复代码Lint错误的工作流程，通过上下文扩展、LLM生成的补丁和渐进式RL训练，在字节跳动生产环境中取得了85%的修复准确率，解决了大量静态分析问题，为企业级自动化代码修复提供了实践参考。

> **摘要翻译:** 随着企业代码库的规模和复杂性不断增长，Lint错误的数量远远超出了工程师手动修复的能力，导致技术债务的持续积累和开发效率的下降。本文提出了BitsAI-Fix，一个基于大型语言模型（LLMs）的自动化Lint错误修复工作流程，旨在解决工业规模环境中这一关键挑战。BitsAI-Fix采用tree-sitter进行上下文扩展，并通过专门训练的LLMs生成搜索和替换格式的补丁，然后进行Lint扫描重新验证以输出最终的修复结果。此外，我们的方法引入了一种创新的渐进式强化学习（RL）训练策略，能够在项目冷启动阶段自动获取可验证的训练数据，并通过系统部署后的反馈收集在线样本来持续迭代模型。我们还设计了一种有针对性的基于规则的奖励机制，该机制结合了格式奖励和正确性奖励，同时惩罚冗余修改。我们还提出了一种“代码差异匹配”方法来持续跟踪在线效果。在我们字节跳动（ByteDance）的生产部署中，我们的解决方案已支持超过5000名工程师，解决了超过12000个静态分析问题，实现了约85%的修复准确率，每周活跃采用者约1000人。这项工作证明了基于LLM的代码修复解决方案在企业环境中的实际可行性，并为大规模工业场景中的自动化代码修复提供了参考。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [882] [Interpreting Performance Profiles with Deep Learning](https://arxiv.org/abs/2508.02729)
> *深度学习在性能剖析中的应用*

*Zhuoran Liu* | **Category: cs.SE, cs.AI, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 性能剖析, 深度学习, 代码摘要, CodeBERT, 程序优化

**Comment:** Master of Science in Computer Science thesis, North Carolina State
  University, 2022. Advisor: Dr. Xu Liu

> **TL;DR:** 该论文提出了一种结合深度学习和程序语义的新方法，以简化性能剖析数据的解释，并为软件工程师提供可操作的优化建议。

**AI_Comments:** 该研究为性能剖析领域提供了一个有前景的方向，通过引入深度学习来弥合性能数据和程序语义之间的差距。其创新性在于利用CodeBERT进行代码摘要，并将其集成到剖析流程中，为软件工程师提供了更直观、更易于理解的性能分析辅助。然而，对于大规模或复杂项目的扩展性以及模型在不同编程语言或场景下的泛化能力，可能还需要进一步的研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的性能剖析工具虽然有用，但给软件工程师带来了额外的负担，需要他们解读复杂的数据并识别可行的优化措施，这可能很困难，尤其是在代码不熟悉的情况下。

**Method:** 结合了Async Profiler生成的性能剖析数据和经过微调的CodeBERT模型提取的代码摘要，并通过图形用户界面展示代码摘要。

**Result:** 所提出的系统能够有效地辅助分析多个Java基准测试程序。

**Conclusion:** 深度学习方法能够有效地结合性能剖析数据和程序语义，从而更好地理解程序低效问题并提供可操作的优化建议。

> **ai_Abstract:** 本研究提出了一种创新的方法，利用深度学习技术来增强性能剖析工具。该方法通过结合Async Profiler生成的性能数据和CodeBERT模型提取的代码摘要，解决了传统剖析工具中解释复杂性能数据和关联程序语义的挑战。通过图形用户界面展示代码摘要，该系统能够有效帮助软件工程师识别程序中的低效之处并进行优化，尤其是在代码不熟悉的情况下，显著提升了剖析工具的可用性。

> **摘要翻译:** 性能剖析工具（也称为剖析器）在理解程序运行时性能方面发挥着重要作用，例如热点、瓶颈和低效率。虽然剖析器已被证明是有用的，但它们给软件工程师带来了额外的负担。作为用户的软件工程师负责解释复杂的性能数据，并识别程序源代码中可行的优化措施。然而，用户很难将低效率与程序语义相关联，特别是当用户不是代码的作者时，这限制了剖析器的适用性。在本论文中，我们探索了一种结合性能剖析和程序语义的新方向，采用深度学习方法。关键思想是提取代码摘要以获取（一定程度上的）语义信息，并将其集成到剖析器中，以便更好地理解程序低效率问题，从而进行可行的优化。具体来说，我们将Async Profiler（最先进的Java剖析器）生成的剖析与来自经过微调的CodeBERT模型的代码摘要相结合。我们在图形用户界面中展示了任何选定调用路径的代码摘要。我们的系统能够有效地辅助分析多个Java基准测试。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [916] [A Note on Code Quality Score: LLMs for Maintainable Large Codebases](https://arxiv.org/abs/2508.02732)
> *代码质量分数说明：面向可维护的大型代码库的语言模型*

*Sherman Wong, Jalaj Bhandari, Leo Zhou Fan Yang, Xylan Xu, Yi Zhuang, Cem Cayiroglu, Payal Bhuptani, Sheela Yadawad, Hung Duong* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 代码质量分数, 大型代码库, Llama3, 代码审查, 软件维护

**Comment:** 24 pages, ICLR format

> **TL;DR:** 该论文介绍了一个名为代码质量分数（CQS）的系统，该系统利用经过微调的Llama3模型来自动检测代码变更中的质量问题，并提供可行的见解。该系统已在工业环境中成功部署，用户帮助率达到60%，并展示了其在真实世界中的有效性。

**AI_Comments:** 该论文提出的CQS系统利用LLM解决了大型代码库的代码质量维护问题，并在工业界取得了实际应用和积极的用户反馈，具有重要的实际意义。然而，关于模型微调的具体细节、评估指标的详细说明以及与其他代码质量工具的比较分析可以进一步加强该研究。此外，对于“用户帮助率”的具体定义和衡量方式也需要更清晰的阐述。

<details>
  <summary>Details</summary>

**Motivation:** 在大型代码库中维护代码质量，特别是在多工程师并发工作的情况下，存在重大挑战。

**Method:** 该论文介绍了一个名为代码质量分数（CQS）的系统，该系统利用两个经过微调（通过SFT和离线RL方法）的Llama3模型来检测代码质量问题并提供代码审查批评。该系统还包含手工规则以过滤不正确的响应。

**Result:** 离线评估表明，CQS系统在识别有效问题方面具有很高的精确率。该系统在工业环境中已实现60%的周用户帮助率。

**Conclusion:** CQS系统通过利用微调的Llama3模型和手工规则，有效地解决了大型代码库的代码质量维护挑战，并在实际应用中取得了显著的用户帮助率。

> **ai_Abstract:** 本文提出了一个名为代码质量分数（CQS）的系统，该系统利用经过微调的Llama3模型（通过SFT和离线RL）来自动识别大型代码库中的代码质量问题，并为代码审查提供反馈。通过结合手工规则来减少错误响应，该系统在工业环境中显示出高精确率和60%的周用户帮助率，证明了其在实际应用中的有效性。

> **摘要翻译:** 维护大型软件系统中的代码质量带来了重大挑战，尤其是在大量工程师并发处理代码库的环境中。本文介绍了代码质量分数（CQS）系统，该系统能够自动检测一组代码变更的问题并提供可行的见解。CQS系统的核心由两个Llama3模型驱动，通过（SFT和离线RL方法）进行了微调，以a）检测与编码最佳实践相关的常见代码质量问题，以及b）为LLM生成的代码审查提供良好的“批评”。为了保持良好的用户体验，我们使用手工规则对系统进行分层，以过滤掉不正确的响应/幻觉。离线评估表明，我们的CQS系统在识别有效问题方面能够达到令人印象深刻的精确率。该系统已在工业规模的环境中推广给开发人员，并持续实现了60%的周用户帮助率，证明了其在真实世界环境中的有效性。在本文中，我们详细介绍了CQS系统，并分享了一些关于策划开发人员反馈以创建用于LLM微调的训练数据的经验。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [66] [Can We Fix Social Media? Testing Prosocial Interventions using Generative Social Simulation](https://arxiv.org/abs/2508.03385)
> *我们能修复社交媒体吗？使用生成式社会模拟测试亲社会干预措施*

*Maik Larooij, Petter Törnberg* | **Category: cs.SI, cs.CY** | **Updated: 2025-08-05**

**Keywords:** 社交媒体, 生成式社会模拟, 大型语言模型, 亲社会干预, 平台架构

**Comment:** 

> **TL;DR:** 本研究使用一种新颖的生成式社会模拟方法（将大型语言模型嵌入到基于代理的模型中）来测试亲社会干预措施，以解决社交媒体的弊病。研究发现，即使在最小的平台上，也存在回音室、影响力集中和极端声音放大等问题。测试的六种干预措施效果甚微，甚至有时适得其反，表明核心功能障碍可能根植于平台架构的基础动态中。

**AI_Comments:** 这项研究的创新之处在于其将大型语言模型与基于代理的模型相结合，创建了高度逼真的社会模拟平台，为研究社交媒体动态提供了一个强大的新工具。其发现表明，即使是看似简单的平台设计也可能导致复杂且难以纠正的社会问题，这对于社交媒体的未来发展和监管具有重要启示。研究的局限性在于其“最小平台”的设定可能无法完全捕捉现实社交媒体的复杂性，但其强调基础架构重要性的结论值得深思。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体平台被广泛认为是导致社会危害的原因，包括两极分化加剧和建设性辩论的侵蚀。本研究旨在探讨这些问题能否通过亲社会干预措施得到缓解。

**Method:** 研究采用一种新颖的“生成式社会模拟”方法，将大型语言模型（LLMs）嵌入到基于代理的模型（ABMs）中，以创建社会丰富的合成平台。研究构建了一个最小平台，代理可以在其中发布、转发和关注他人，并测试了包括时间线排序和桥接算法在内的六种干预措施。

**Result:** 研究发现，生成的关注网络再现了三个已充分记录的功能障碍：1）党派回音室；2）少数精英中影响力集中；3）两极分化声音的放大，形成扭曲政治话语的“社交媒体棱镜”。测试的六种干预措施只取得了适度的改善，在某些情况下甚至使结果恶化。

**Conclusion:** 核心功能障碍可能根植于反应性参与和网络增长之间的反馈循环，这意味着有意义的改革可能需要重新思考平台架构的基础动态。

> **ai_Abstract:** 本研究利用一种创新的生成式社会模拟方法，将大型语言模型整合到基于代理的模型中，构建了一个合成社交媒体平台，旨在探究亲社会干预措施能否缓解社交媒体的负面影响。研究发现，即使是最小的平台也内生性地再现了回音室、影响力集中和极端声音放大等问题。尽管测试了多种干预措施，但效果甚微，甚至有时适得其反。这表明社交媒体的核心功能障碍可能源于其基本架构中参与和网络增长的反馈机制，提示未来改革需从根本上重塑平台设计。

> **摘要翻译:** 社交媒体平台被广泛认为与社会危害有关，包括两极分化加剧和建设性辩论的侵蚀。这些问题能否通过亲社会干预措施得到缓解？我们使用一种新颖的方法——生成式社会模拟——来解决这个问题，该方法将大型语言模型嵌入到基于代理的模型中，以创建社会丰富的合成平台。我们创建了一个最小平台，代理可以在其中发布、转发和关注他人。我们发现，由此产生的关注网络再现了三个有据可查的功能障碍：(1) 党派回音室；(2) 少数精英中影响力集中；(3) 两极分化声音的放大——这创造了一个扭曲政治话语的“社交媒体棱镜”。我们测试了六种提议的干预措施，从按时间顺序排列的动态消息到桥接算法，发现只有适度的改善——在某些情况下，结果甚至更糟。这些结果表明，核心功能障碍可能根植于反应性参与和网络增长之间的反馈循环，这提出了有意义的改革将需要重新思考平台架构的基础动态的可能性。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [118] [Revealing The Secret Power: How Algorithms Can Influence Content Visibility on Twitter/X](https://arxiv.org/abs/2410.17390)
> *揭示秘密力量：算法如何影响Twitter/X上的内容可见性*

*Alessandro Galeazzi, Pujan Paudel, Mauro Conti, Emiliano De Cristofaro, Gianluca Stringhini* | **Category: cs.SI** | **Updated: 2025-08-04**

**Keywords:** 算法影响, 内容可见性, Twitter/X, 影子禁令, 透明度

**Comment:** To Appear in the Proceedings of the 33rd Network and Distributed
  System Security Symposium (NDSS 2026)

> **TL;DR:** Twitter/X算法会系统性地降低带有外部链接的推文可见性，并根据特定账户调整内容可见性，凸显了透明度的重要性。

**AI_Comments:** 这项研究通过大规模数据分析揭示了社交媒体平台算法在内容可见性方面的潜在偏见和不透明性，特别是对外部链接和特定账户的处理。其创新之处在于利用浏览量作为指标来量化可见性变化，并将其与用户特征和内容属性关联。该工作的重要性在于，它直接回应了公众对社交媒体平台信息操纵的担忧，并为呼吁提高算法透明度提供了实证支持，对于维护数字时代的言论自由和信息公平具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交网络推荐算法的不透明设计和公众理解有限，引发了对信息曝光潜在操纵的担忧，尤其是内容可见性降低（即“影子禁令”）可能被用于压制异议声音，因此需要更高的透明度和更好的理解。

**Method:** 通过对两个Twitter/X数据集（包含超过900万用户的4000万条推文，专注于乌克兰-俄罗斯冲突和2024年美国总统大选）进行大规模定量分析，利用浏览量检测可见性降低或提升的模式，并检查这些模式与用户观点、社会角色和叙事框架的关联。

**Result:** 分析显示，算法系统性地惩罚包含外部链接的推文，将其可见性降低多达八倍，而与意识形态立场或来源可靠性无关。此外，内容可见性可能根据发布特定账户（如比较Kyiv Independent与RT.com，或唐纳德·特朗普与卡马拉·哈里斯的推文）而被惩罚或偏袒。

**Conclusion:** 这项工作强调了内容审核和推荐系统透明度的重要性，以保护公共讨论的完整性并确保在线平台的公平访问。

> **ai_Abstract:** 本研究通过对Twitter/X上4000万条推文的大规模定量分析，揭示了算法对内容可见性的影响。研究发现，算法系统性地降低带有外部链接推文的可见性，并根据发布账户的特定性（而非内容本身）来调整可见性。这强调了社交媒体平台在内容审核和推荐方面提高透明度，以维护公共讨论的完整性和公平访问的重要性。

> **摘要翻译:** 近年来，社交网络推荐算法的不透明设计和公众有限的理解引发了人们对信息曝光潜在操纵的担忧。降低内容可见性，即“影子禁令”，可能有助于限制有害内容；然而，它也可能被用来压制异议声音。这促使人们需要更大的透明度和对这种做法的更好理解。
在本文中，我们通过对两个Twitter/X数据集（包含超过900万用户的4000万条推文，主要关注乌克兰-俄罗斯冲突和2024年美国总统大选的讨论）进行大规模定量分析，调查了可见性改变的存在。我们使用浏览量来检测可见性降低或提升的模式，并检查这些模式与用户观点、社会角色和叙事框架的关联。我们的分析表明，算法系统性地惩罚包含外部资源的推文，将其可见性降低多达八倍，而与意识形态立场或来源可靠性无关。相反，内容可见性可能根据发布特定账户而被惩罚或偏袒，正如在比较Kyiv Independent和RT.com的推文或唐纳德·特朗普和卡马拉·哈里斯的推文时所观察到的那样。总的来说，我们的工作强调了内容审核和推荐系统透明度的重要性，以保护公共讨论的完整性并确保在线平台的公平访问。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [150] [Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiation](https://arxiv.org/abs/2507.13368)
> *通过邻域分化实现可扩展的属性缺失图聚类*

*Yaowen Hu, Wenxuan Tu, Yue Liu, Xinhang Wan, Junyi Yan, Taichun Zhou, Xinwang Liu* | **Category: cs.SI, cs.AI** | **Updated: 2025-08-05**

**Keywords:** 深度图聚类, 属性缺失, 大规模图, 邻域分化, 多视图聚类

**Comment:** 

> **TL;DR:** 提出了一种名为CMV-ND的新型深度图聚类方法，用于解决大规模和属性缺失图的聚类问题，通过互补多视图邻域分化显著提高了现有方法的性能。

**AI_Comments:** 该论文的创新点在于提出了CMV-ND方法，通过递归邻域搜索确保结构信息的完整性，并通过邻域分化策略消除冗余，从而有效地处理大规模和属性缺失的图数据。这种多视图生成方法为深度图聚类提供了新的视角，并被证明能够显著提升现有方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度图聚类方法在处理大规模和属性缺失的真实世界属性图（如社交网络交互）时面临挑战。

**Method:** 提出了互补多视图邻域分化（CMV-ND）方法。首先，通过递归邻域搜索完整地扩展不同跳距的节点邻域，以确保结构信息的完整性。其次，引入邻域分化策略，确保不同跳表示之间没有重叠节点，以消除冗余。然后，从K个差分跳表示和目标节点特征构建K+1个互补视图。最后，将现有的多视图聚类或DGC方法应用于这些视图。

**Result:** 在六个广泛使用的图数据集上的实验结果表明，CMV-ND显著提高了各种方法的性能。

**Conclusion:** CMV-ND通过有效处理大规模和属性缺失的图数据，显著提升了深度图聚类任务的性能。

> **ai_Abstract:** 本研究提出了一种名为互补多视图邻域分化（CMV-ND）的新型深度图聚类（DGC）方法，旨在解决大规模和属性缺失图的聚类挑战。CMV-ND通过递归邻域搜索和邻域分化策略，将图结构信息转化为完整且非冗余的多个视图。这些视图随后可用于现有的多视图聚类或DGC方法。实验结果表明，CMV-ND显著提升了各种图聚类方法的性能。

> **摘要翻译:** 深度图聚类（DGC）旨在将属性图中的节点无监督地分为不同的簇，在社区检测和推荐等各种工业场景中显示出巨大的潜力。然而，现实世界的属性图，例如社交网络交互，通常是大规模且属性缺失的。为了解决这两个问题，我们提出了一种新颖的DGC方法，称为互补多视图邻域分化（CMV-ND），该方法以完整但不冗余的方式将图结构信息预处理成多个视图。首先，为了确保结构信息的完整性，我们提出了一种递归邻域搜索，通过完全扩展不同跳距的节点邻域来递归探索图的局部结构。其次，为了消除不同跳邻域之间的冗余，我们引入了一种邻域分化策略，确保差分跳表示之间没有重叠节点。然后，我们从K个差分跳表示和目标节点的特征构建K+1个互补视图。最后，我们将现有的多视图聚类或DGC方法应用于这些视图。在六个广泛使用的图数据集上的实验结果表明，CMV-ND显著提高了各种方法的性能。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [775] [OSINT or BULLSHINT? Exploring Open-Source Intelligence tweets about the Russo-Ukrainian War](https://arxiv.org/abs/2508.03599)
> *OSINT还是BULLSHINT？ 探索关于俄乌战争的开源情报推文*

*Johannes Niu, Mila Stillman, Anna Kruspe* | **Category: cs.SI, cs.CL** | **Updated: 2025-08-05**

**Keywords:** OSINT, BULLSHINT, 俄乌战争, 虚假信息, 推特

**Comment:** 

> **TL;DR:** 该研究分析了2022年1月至2023年7月期间关于俄乌战争的近200万条推文，区分了真实的OSINT和虚假信息（BULLSHINT）。通过情感分析、党派检测、虚假信息识别和命名实体识别，研究揭示了战争事件对负面情绪的影响、亲乌克兰和亲俄罗斯党派的细微分布以及信息被操纵的可能性。社区检测技术也用于识别不同的党派、主题和虚假信息集群，突显了社交媒体信息传播的复杂性。

**AI_Comments:** 这项研究在区分真实的OSINT和虚假信息方面做得很好，并且使用了大量的数据集。然而，它可能没有完全考虑到OSINT在实际冲突中的所有潜在应用和影响。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探讨开源情报（OSINT）在俄乌战争中的作用，并区分真实的OSINT和被称为“BULLSHINT”的欺骗性虚假信息。

**Method:** 研究人员利用2022年1月至2023年7月期间收集的近200万条推文数据，分析了约1040名用户发布的内容。研究采用了情感分析、党派检测、虚假信息识别和命名实体识别（NER）等技术，并应用了社区检测技术来识别不同的党派、主题和虚假信息集群。

**Result:** 研究发现，战争事件主要影响了负面情绪，亲乌克兰和亲俄罗斯的党派分布存在细微差别，信息存在被战略性操纵的可能性。社区检测技术能够识别出不同的党派、主题和虚假信息集群。

**Conclusion:** 该研究有助于理解数字战争和虚假信息动态，并为地缘政治冲突中OSINT的运作提供了见解。

> **ai_Abstract:** 这项研究分析了2022年1月至2023年7月期间推特上与俄乌战争相关的近200万条推文，重点区分了真实的开源情报（OSINT）和虚假信息（BULLSHINT）。通过情感分析、党派检测、虚假信息识别和命名实体识别等方法，研究揭示了战争事件对用户情绪的影响、不同政治立场的分布以及信息操纵的可能策略。社区检测技术的应用进一步揭示了信息传播的复杂性，为理解数字战争和虚假信息在冲突中的作用提供了重要见解。

> **摘要翻译:** 本研究探讨了开源情报（OSINT）在推特上关于俄乌战争的作用，区分了真实的OSINT和被称为“BULLSHINT”的欺骗性虚假信息。我们利用2022年1月至2023年7月期间的数据集，分析了约1040名用户发布的近200万条推文，内容涉及实时军事交战、战略分析和与冲突相关的虚假信息。通过情感分析、党派检测、虚假信息识别和命名实体识别（NER），我们揭示了OSINT社区内的沟通模式和传播策略。重要发现包括：战争事件影响了普遍的负面情绪，亲乌克兰和亲俄罗斯的党派分布存在细微差别，以及信息被战略性操纵的可能性。此外，我们应用了社区检测技术，能够识别出不同的党派、主题和虚假信息集群，突显了社交媒体信息传播的复杂动态。本研究有助于理解数字战争和虚假信息动态，为地缘政治冲突中OSINT的运作提供了见解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [332] [SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec](https://arxiv.org/abs/2508.02849)
> *SecoustiCodec：跨模态对齐流式单码本语音编解码器*

*Chunyu Qiang, Haoyu Wang, Cheng Gong, Tianrui Wang, Ruibo Fu, Tao Wang, Ruilong Chen, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Longbiao Wang, Jianwu Dang, Jianhua Tao* | **Category: eess.AS, cs.AI, cs.CL, cs.SD** | **Updated: 2025-08-04**

**Keywords:** 语音编解码器, 跨模态对齐, 流式传输, 语义解耦, 低比特率

**Comment:** 

> **TL;DR:** 提出SecoustiCodec，一种低比特率流式语音编解码器，通过跨模态对齐和信息解耦，解决现有编解码器在语义编码、重建和流式传输上的挑战，并在极低比特率下达到SOTA重建质量。

**AI_Comments:** SecoustiCodec的创新之处在于其独特的单码本空间中语义和副语言信息的解耦机制，以及结合VAE和FSQ的高效量化方法，有效解决了令牌长尾分布问题。此外，采用对比学习进行跨模态对齐以实现语义解耦，对于提升语音编解码器的语义纯度至关重要。该研究对于推动低比特率流式语音通信和统一语音文本模型具有重要意义，其达到的SOTA性能证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音编解码方法在语义编码方面面临挑战，包括残余的副语言信息（如音色、情感）、语义完整性不足、重建能力有限以及不支持流式传输。

**Method:** 提出SecoustiCodec，一种跨模态对齐的低比特率流式语音编解码器，它在单一码本空间中解耦语义和副语言信息。引入副语言编码以弥合语义和声学编码之间的信息鸿沟。提出一种基于VAE和FSQ的仅语义高效量化方法，以缓解令牌长尾分布问题并保持高码本利用率。提出一种基于对比学习的语义解耦方法，在联合多模态帧级空间中对齐文本和语音，有效去除语义编码中的副语言信息。提出一种声学约束的多阶段优化策略以确保鲁棒和稳定的收敛。

**Result:** SecoustiCodec在0.27/1 kbps的比特率下实现了1.77/2.58的SOTA重建质量（PESQ）。

**Conclusion:** SecoustiCodec通过其创新的设计，成功解决了现有语音编解码器在语义编码、重建能力和流式传输方面的挑战，并在极低比特率下达到了最先进的语音重建质量。

> **ai_Abstract:** 本文提出SecoustiCodec，一种创新的低比特率流式语音编解码器，旨在解决现有方法在语义编码、重建能力和流式支持方面的不足。该方法通过在单一码本空间中解耦语义和副语言信息，引入副语言编码弥合信息鸿沟。它还采用基于VAE和FSQ的高效语义量化方法，并利用对比学习实现文本和语音的跨模态对齐与语义解耦。通过声学约束的多阶段优化策略，SecoustiCodec在极低比特率下实现了最先进的语音重建质量。

> **摘要翻译:** 语音编解码器是统一语音和文本语言模型的关键桥梁。现有编解码方法在语义编码方面面临多项挑战，例如残余的副语言信息（如音色、情感）、语义完整性不足、重建能力有限以及缺乏对流式传输的支持。为了解决这些挑战，我们提出了SecoustiCodec，一种跨模态对齐的低比特率流式语音编解码器，它在单一码本空间中解耦语义和副语言信息。为了确保语义完整性和重建保真度，引入了副语言编码以弥合语义和声学编码之间的信息鸿沟。提出了一种基于VAE（变分自编码器）和FSQ（有限标量量化）的仅语义高效量化方法。这种方法在保持高码本利用率的同时，缓解了令牌的长尾分布问题。提出了一种基于对比学习的语义解耦方法，该方法在联合多模态帧级空间中对齐文本和语音，有效去除语义编码中的副语言信息。提出了一种声学约束的多阶段优化策略，以确保鲁棒和稳定的收敛。图1显示SecoustiCodec在0.27/1 kbps下实现了1.77/2.58的SOTA（最先进）重建质量（PESQ）。SecoustiCodec的代码和模型权重将在同行评审过程完成后开源。我们已经开源了SecoustiCodec的演示、代码和模型权重。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [453] [Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis](https://arxiv.org/abs/2504.10352)
> *伪自回归神经编解码器语言模型用于高效零样本文本到语音合成*

*Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen* | **Category: eess.AS, cs.CL** | **Updated: 2025-08-05**

**Keywords:** 零样本TTS, 伪自回归, 神经编解码器, 语言模型, PALLE

**Comment:** Accepted in ACMMM 2025

> **TL;DR:** 本文提出了一种伪自回归（PAR）编解码器语言模型PALLE，它结合了自回归和非自回归模型的优点，实现了高效且高质量的零样本文本到语音合成，速度比现有技术快十倍。

**AI_Comments:** 本文的创新点在于提出了伪自回归（PAR）编解码器语言模型，巧妙地结合了自回归（AR）和非自回归（NAR）模型的优点，克服了它们各自的局限性。PALLE的两阶段设计，特别是PAR在第一阶段的并行预测和逐步保留，以及NAR在第二阶段的并行细化，是其高效和高质量的关键。其在小规模数据集上训练却能超越大规模数据集训练的SOTA系统，并实现显著的速度提升，显示了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有零样本文本到语音（TTS）系统面临困境：自回归（AR）模型生成速度慢且缺乏持续时间可控性，而非自回归（NAR）模型缺乏时间建模且通常需要复杂设计。

**Method:** 本文引入了一种新颖的伪自回归（PAR）编解码器语言建模方法，该方法统一了AR和NAR建模，结合了AR的显式时间建模和NAR的并行生成。在此基础上，提出了PALLE，一个两阶段TTS系统。第一阶段，PAR沿时间维度逐步生成语音标记，每一步并行预测所有位置但只保留最左侧的跨度。第二阶段，并行迭代细化低置信度标记，利用全局上下文信息。

**Result:** 实验表明，PALLE在LibriSpeech test-clean数据集上，在语音质量、说话人相似性和可懂度方面优于包括F5-TTS、E2-TTS和MaskGCT在内的最先进系统（即使这些系统是在大规模数据上训练的），同时实现了高达十倍的推理速度。

**Conclusion:** PALLE通过结合伪自回归方法，有效解决了零样本文本到语音合成中AR和NAR模型的局限性，实现了卓越的性能和显著的推理速度提升。

> **ai_Abstract:** 本文提出了一种新颖的伪自回归（PAR）编解码器语言建模方法，旨在解决零样本文本到语音（TTS）系统中自回归（AR）模型生成慢和非自回归（NAR）模型时间建模不足的问题。PAR结合了AR的时间建模和NAR的并行生成优势。在此基础上，作者提出了PALLE，一个两阶段TTS系统：第一阶段使用PAR进行初始语音标记生成，第二阶段通过NAR并行精炼低置信度标记。实验结果显示，PALLE在语音质量、说话人相似性和可懂度方面超越了现有最先进的系统，并且推理速度提高了十倍。

> **摘要翻译:** 近期零样本文本到语音（TTS）系统面临一个共同困境：自回归（AR）模型生成速度慢且缺乏持续时间可控性，而非自回归（NAR）模型缺乏时间建模且通常需要复杂设计。在本文中，我们介绍了一种新颖的伪自回归（PAR）编解码器语言建模方法，该方法统一了AR和NAR建模。PAR结合了AR的显式时间建模和NAR的并行生成，在固定时间步生成动态长度的跨度。在此基础上，我们提出了PALLE，一个两阶段TTS系统，它利用PAR进行初始生成，然后进行NAR精炼。在第一阶段，PAR沿时间维度逐步生成语音标记，每一步并行预测所有位置但只保留最左侧的跨度。在第二阶段，低置信度标记被并行迭代细化，利用全局上下文信息。实验表明，PALLE在LibriTTS上训练，在LibriSpeech test-clean数据集上，在语音质量、说话人相似性和可懂度方面优于包括F5-TTS、E2-TTS和MaskGCT在内的最先进系统（即使这些系统是在大规模数据上训练的），同时实现了高达十倍的推理速度。音频样本可在https://microsoft.com/research/project/vall-e-x/palle 获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [461] [Real-time speech enhancement in noise for throat microphone using neural audio codec as foundation model](https://arxiv.org/abs/2508.02974)
> *喉麦克风在噪声环境下的实时语音增强，使用神经音频编解码器作为基础模型*

*Julien Hauret, Thomas Joubaud, Éric Bavu* | **Category: eess.AS** | **Updated: 2025-08-05**

**Keywords:** 语音增强, 喉麦克风, 神经音频编解码器, 实时处理, 噪声环境

**Comment:** 2 pages, 2 figures

> **TL;DR:** 本文展示了一个使用喉麦克风进行实时语音增强的演示，通过在Vibravox数据集上微调Kyutai的Mimi神经音频编解码器，实现了在嘈杂环境下优于现有技术的语音增强效果。

**AI_Comments:** 这篇论文的创新点在于将神经音频编解码器作为基础模型应用于喉麦克风的语音增强，有效解决了喉麦克风因带宽受限而导致的音质问题。其重要性在于提供了一种在噪声环境下高质量语音捕获的实时解决方案，对于通信、可穿戴设备等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 喉麦克风虽然能有效衰减外部噪声，但会牺牲音频带宽，导致语音质量下降。本文旨在解决喉麦克风在噪声环境中语音带宽受限的问题，并展示完整的实时语音增强流程。

**Method:** 本文通过在包含空气传导和喉麦克风配对录音的Vibravox数据集上，微调了支持实时推理的Kyutai Mimi神经音频编解码器，以实现语音增强。

**Result:** 该增强策略与现有最先进的模型相比，表现出更优越的性能。

**Conclusion:** 通过微调神经音频编解码器，可以有效地解决喉麦克风在噪声环境下音频带宽受限的问题，并实现优于现有技术的实时语音增强。

> **ai_Abstract:** 本文介绍了一个针对喉麦克风在噪声环境下实时语音增强的演示系统。该系统通过利用喉麦克风的固有降噪特性，并结合对Kyutai Mimi神经音频编解码器在Vibravox数据集上的微调，解决了喉麦克风音频带宽受限的问题。实验结果表明，该方法在语音增强方面表现出优于现有先进模型的性能，并提供了一个用户友好的交互界面。

> **摘要翻译:** 我们展示了一个使用喉麦克风捕获语音的实时语音增强演示。该演示旨在展示在嘈杂环境下使用体传导麦克风捕获语音的完整流程，从录音到基于深度学习的后处理。喉麦克风记录皮肤振动，这自然会衰减外部噪声，但这种鲁棒性是以降低音频带宽为代价的。为了应对这一挑战，我们在Vibravox数据集上微调了Kyutai的Mimi——一个支持实时推理的神经音频编解码器，该数据集包含空气传导和喉麦克风的配对录音。我们将这种增强策略与现有最先进的模型进行了比较，并展示了其卓越的性能。推理运行在一个交互式界面中，允许用户切换增强功能、可视化频谱图并监控处理延迟。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [496] [Kernel ridge regression based sound field estimation using a rigid spherical microphone array](https://arxiv.org/abs/2508.03087)
> *基于核岭回归的刚性球形麦克风阵列声场估计*

*Ryo Matsuda, Juliano G. C. Ribeiro, Hitoshi Akiyama, Jorge Trevino* | **Category: eess.AS** | **Updated: 2025-08-05**

**Keywords:** 核岭回归, 声场估计, 刚性球形麦克风阵列, 边界条件, 散射声场

**Comment:** This paper has been accepted to the IEEE Workshop on Applications of
  Signal Processing to Audio and Acoustics (WASPAA) 2025

> **TL;DR:** 本文提出了一种基于核岭回归的声场估计方法，用于刚性球形麦克风阵列，通过整合散射体的边界条件来解决现有方法的局限性。

**AI_Comments:** 该创新的核心在于将核岭回归应用于存在刚性球形散射体的声场估计场景，特别是通过将散射体的边界条件整合到模型中。这对于存在散射体的更实际的声场分析至关重要，超越了理想化的开放球形假设。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于核岭回归（KRR）的声场估计方法通常假设开放球形麦克风阵列（即没有散射体），或者即使存在散射体，也未能有效整合其边界条件。本文旨在解决这些局限性。

**Method:** 本文提出了一种使用刚性球形麦克风阵列的基于核岭回归的声场估计方法。它在核岭回归框架内构建散射声场，并引入了一种结合边界约束的新型声场表示，特别利用了刚性球体明确定义的虚拟散射源位置和边界条件。

**Result:** 通过数值模拟和使用新开发的球形麦克风阵列进行的真实世界实验，证明了所提方法的有效性。

**Conclusion:** 本文成功提出并验证了一种基于核岭回归的声场估计方法，该方法通过整合刚性球形散射体的边界条件，有效地处理了此类散射体，解决了先前方法的局限性。

> **ai_Abstract:** 本文提出了一种利用刚性球形麦克风阵列的基于核岭回归（KRR）的新型声场估计方法。它解决了传统KRR方法通常假设开放球形环境或未能整合散射体边界条件的局限性。通过利用刚性球体的明确定义特性，作者在KRR框架内构建了散射声场，并提出了一种包含边界约束的新型声场表示。数值模拟和真实世界实验证实了该方法的有效性。

> **摘要翻译:** 我们提出了一种使用刚性球形麦克风阵列的基于核岭回归的声场估计方法。事实证明，具有物理约束核函数，以及进一步适应观测声场的核函数的核岭回归是强大的工具。然而，此类方法通常假设开放球形麦克风阵列配置，即观察或估计区域内不存在散射体。或者，一些方法假设存在散射体并试图通过最小二乘公式消除其影响。即便如此，这些方法通常不包含散射体的边界条件，这些条件不被假定为已知。相反，我们利用了此处散射体是刚性球体的事实。这意味着虚拟散射源位置和边界条件都明确定义。在此基础上，我们在核岭回归框架内构建了散射声场，并提出了一种包含边界约束的新型声场表示。通过数值模拟和使用新开发的球形麦克风阵列进行的真实世界实验，证明了所提方法的有效性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [532] [PatchDSU: Uncertainty Modeling for Out of Distribution Generalization in Keyword Spotting](https://arxiv.org/abs/2508.03190)
> *PatchDSU：关键词识别中域外泛化的不确定性建模*

*Bronya Roni Chernyak, Yael Segal, Yosi Shrem, Joseph Keshet* | **Category: eess.AS, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 关键词识别, 域外泛化, 不确定性建模, PatchDSU, 语音处理

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** PatchDSU通过对输入语音数据进行分块不确定性建模，有效提升了关键词识别任务在域外泛化场景下的性能和一致性。

**AI_Comments:** 该论文提出PatchDSU，通过将DSU方法应用于语音数据的局部补丁，创新性地解决了语音信号的时序性和稀疏性带来的域外泛化挑战。这种分块处理方法有效避免了对整个输入进行统计时可能出现的特征统计偏差，提升了模型在复杂真实环境下的鲁棒性，对于关键词识别等实际语音应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在现实世界语音系统中，由于环境、录音条件和说话人多样性导致的训练与测试数据分布不一致，泛化能力受到限制。现有的DSU（域偏移与不确定性）方法在处理具有时序性和稀疏性的语音数据时存在局限，导致特征统计偏差。

**Method:** 本文提出了PatchDSU，该方法通过将输入语音数据分割成多个独立补丁（patches），并对每个补丁独立进行不确定性增强来扩展DSU。这种分块处理方式旨在克服语音数据特性带来的挑战。

**Result:** 在Google Speech Commands、Librispeech和TED-LIUM数据集上，以及白高斯噪声和MUSAN音乐噪声条件下，PatchDSU和DSU在大多数情况下都优于其他方法。特别是，PatchDSU在不同评估场景中表现出比其他方法更一致的性能改进。

**Conclusion:** PatchDSU通过对语音数据进行分块处理并独立增强，成功解决了DSU在语音领域应用时面临的挑战，显著提升了关键词识别模型在复杂真实世界环境中域外泛化的性能和稳定性。

> **ai_Abstract:** 本文针对深度学习模型在真实世界语音系统中因数据分布偏移导致的泛化能力下降问题，提出了PatchDSU。该方法通过将输入语音分割成多个补丁并独立进行不确定性增强，改进了现有的DSU方法在处理语音数据时的局限性。实验结果表明，PatchDSU在多个基准数据集和噪声条件下，相比其他方法展现出更优且更一致的域外泛化性能。

> **摘要翻译:** 深度学习模型在许多任务中表现出色，但它们依赖于训练和测试数据遵循相同分布的假设。在真实世界的语音系统中，由于环境、录音条件和说话人多样性的变化，这种假设通常不成立，分布偏移很常见。
域偏移与不确定性（DSU）方法根据输入特征统计数据增强每个神经网络层的输入。它通过假设特征统计数据遵循多元高斯分布，并用从该分布中采样的特征替换输入来解决域外泛化问题。虽然DSU对计算机视觉有效，但由于数据本身的性质，将其应用于语音带来了挑战。与静态视觉数据不同，语音是一种时间信号，通常由频谱图表示——频率随时间的变化。这种表示不能被视为简单的图像，并且当应用于整个输入时，由此产生的稀疏性可能导致特征统计数据倾斜。
为了解决关键词识别中的域外泛化问题，我们提出了PatchDSU，它通过将输入分割成补丁并独立增强每个补丁来扩展DSU。我们在Google Speech Commands、Librispeech和TED-LIUM数据集上评估了PatchDSU和DSU以及其他方法。此外，我们还在白高斯噪声和MUSAN音乐噪声条件下评估了性能。我们还通过分析模型在未训练过的数据集上的表现来探索域外泛化。总的来说，在大多数情况下，PatchDSU和DSU都优于其他方法。值得注意的是，与其他方法相比，PatchDSU在评估场景中表现出更一致的改进。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [948] [Fast Algorithm for Moving Sound Source](https://arxiv.org/abs/2508.03065)
> *移动声源的快速算法*

*Dong Yang* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-04**

**Keywords:** 运动声源,时变混响,杨氏运动时空采样重建理论,语音增强,分层采样

**Comment:** 

> **TL;DR:** 提出了一种基于杨氏运动时空采样重建理论的快速算法，用于模拟运动声源引起的时变混响，解决了现有方法在模拟物理规律运动数据方面的不足，并通过分层采样和快速合成技术实现了高效实时模拟，实验证明其在恢复幅度和相位变化方面优于GSound，并提高了语音增强和多通道语音跟踪算法的鲁棒性。

**AI_Comments:** 该研究提出的杨氏运动时空采样重建理论在模拟运动声源引起的时变混响方面具有创新性，解决了实际应用中的关键挑战。分层采样策略和快速合成架构的设计体现了对效率的关注。然而，论文中提到的“物理规律”和“带限特性”的具体数学表述和理论依据可以进一步阐述，以增强其理论深度。此外，虽然实验结果显示优于GSound，但与其他先进的模拟方法或真实数据采集方法相比的性能评估可以提供更全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经网络语音处理系统需要大量的混响数据进行训练，但现有的模拟动态场景的方法难以模拟符合物理规律的运动数据，导致运动场景下的语音增强模型训练数据不足。

**Method:** 提出杨氏运动时空采样重建理论，将运动镜像源的冲激响应分解为线性时不变调制和离散时变分数延迟，建立符合物理规律的运动声场模型。采用分层采样策略（低阶镜像高采样率，高阶镜像低采样率）并结合快速合成架构，以实现实时模拟。

**Result:** 与开源模型GSound相比，该理论能更准确地恢复运动场景下的幅度和相位变化，解决了运动声源数据模拟的行业挑战，为语音增强模型提供了高质量的动态训练数据，并提高了多通道端到端语音跟踪算法的鲁棒性。

**Conclusion:** 该研究提出的杨氏运动时空采样重建理论能够高效模拟运动声源引起的时变混响，解决了训练数据不足的问题，并在恢复幅度相位变化和提高算法鲁棒性方面取得了显著效果。

> **ai_Abstract:** 本研究提出了一种名为杨氏运动时空采样重建理论的新方法，旨在解决运动声源场景下语音增强模型训练数据不足的问题。该方法能够高效地模拟运动引起的连续时变混响，通过将运动镜像源的冲激响应分解为线性时不变调制和离散时变分数延迟，突破了传统方法的局限性，并建立了符合物理规律的运动声场模型。该方法采用了分层采样策略和快速合成架构，实现了高效的实时模拟。实验结果表明，该方法在恢复幅度和相位变化方面优于现有方法，并能提高语音增强和语音跟踪算法的鲁棒性。

> **摘要翻译:** 现代基于神经网络的语音处理系统需要混响抵抗力，依赖大量的混响数据进行训练。现有方法通过采样静态系统或补充测量数据来模拟动态场景，但在模拟符合物理定律的运动数据方面存在困难。为了解决运动场景下语音增强模型训练数据不足的问题，本文提出了杨氏运动时空采样重建理论，能够高效模拟运动引起的连续时变混响。它通过将运动镜像源的冲激响应分解为线性时不变调制和离散时变分数延迟，突破了传统静态图像源法（ISM）在时变系统中的局限性，建立了符合物理规律的运动声场模型。基于运动位移的带限特性，采用了分层采样策略：低阶镜像采用高采样率以保留细节，高阶镜像采用低采样率以降低复杂度，并结合快速合成架构以实现实时模拟。实验表明，与开源模型GSound相比，该理论能更准确地恢复运动场景下的幅度和相位变化，解决了业界在运动声源数据模拟方面的挑战。它为语音增强模型提供了高质量的动态训练数据，并提高了多通道端到端语音跟踪算法的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [126] [Evaluation of 3D Counterfactual Brain MRI Generation](https://arxiv.org/abs/2508.02880)
> *3D反事实脑部MRI生成评估*

*Pengwei Sun, Wei Peng, Lun Yu Li, Yixin Wang, Kilian M. Pohl* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 3D反事实生成, 脑部MRI, 生成模型, 解剖学引导, 图像评估

**Comment:** 

> **TL;DR:** 本研究评估了六种将生成模型转换为3D反事实方法的效果，通过解剖学引导框架生成脑部MRI，发现其能成功修改目标区域但难以保留非目标结构，并强调了未来模型需更好地捕捉解剖学相互依赖性。

**AI_Comments:** 本研究通过系统性地评估多种生成模型在3D反事实脑部MRI生成中的表现，填补了该领域在标准化评估协议方面的空白。其创新之处在于引入了基于因果图的解剖学引导框架，使得区域脑容量可以直接作为条件输入，增强了生成过程的可控性和解释性。研究结果揭示了当前方法在保持非目标结构完整性方面的局限性，这对于未来开发更鲁棒、临床更可用的反事实生成模型具有重要指导意义。这项工作不仅为理解疾病机制提供了新的工具，也为生成高质量的合成医学影像数据奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 反事实生成在医学影像中具有模拟假设变化、理解疾病机制和生成生理学上合理数据的潜力。然而，生成逼真的、符合解剖学和因果约束的3D脑部MRI面临数据稀缺、结构复杂性和缺乏标准化评估协议等挑战。

**Method:** 本研究将六种生成模型通过结合基于因果图的解剖学引导框架，转换为3D反事实方法，其中区域脑容量作为直接的条件输入。每个模型在来自ADNI的T1加权脑部MRI上，就合成、可逆性、真实性、有效性和最小性进行了评估。此外，还在NCANDA的T1加权MRI上测试了模型的泛化能力。

**Result:** 研究结果表明，基于解剖学基础的条件化方法成功修改了目标解剖区域；然而，在保留非目标结构方面表现出局限性。

**Conclusion:** 本基准研究为更具可解释性和临床相关性的脑部MRI生成建模奠定了基础，并强调了需要新颖的架构来更准确地捕捉解剖学相互依赖性。

> **ai_Abstract:** 本研究旨在评估3D反事实脑部MRI生成方法，以应对现有技术在生成逼真、符合解剖学和因果约束的图像方面面临的挑战。研究人员将六种生成模型通过一个基于因果图的解剖学引导框架转换为3D反事实方法，并以区域脑容量作为条件输入。这些模型在来自ADNI的T1加权脑部MRI上进行了多方面评估，并测试了其在NCANDA数据集上的泛化能力。结果显示，基于解剖学的条件化能够成功修改目标区域，但在保留非目标结构方面存在不足。该研究为未来的脑部MRI生成建模奠定了基础，并指出需要开发更能捕捉解剖学相互依赖性的新型架构。

> **摘要翻译:** 反事实生成为模拟医学影像中的假设变化提供了一个原则性的框架，在理解疾病机制和生成生理学上合理的数据方面具有潜在应用。然而，由于数据稀缺、结构复杂性以及缺乏标准化评估协议，生成逼真的、符合解剖学和因果约束的结构化3D脑部MRI仍然具有挑战性。在这项工作中，我们通过结合基于因果图的解剖学引导框架，将六种生成模型转换为3D反事实方法，其中区域脑容量作为直接的条件输入。每个模型在来自阿尔茨海默病神经影像倡议 (ADNI) 的T1加权脑部MRI (T1w MRI) 上，就合成、可逆性、真实性、有效性和最小性进行了评估。此外，我们还测试了每个模型在国家酒精和神经发育青少年联盟 (NCANDA) 的T1w MRI上的泛化能力。我们的结果表明，解剖学上基于的条件化成功修改了目标解剖区域；然而，在保留非目标结构方面表现出局限性。除了为脑部MRI更具可解释性和临床相关性的生成建模奠定基础外，这项基准研究还强调了需要新颖的架构来更准确地捕捉解剖学相互依赖性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [166] [REFLECT: Rectified Flows for Efficient Brain Anomaly Correction Transport](https://arxiv.org/abs/2508.02889)
> *REFLECT：用于高效脑异常校正传输的整流流*

*Farzad Beizaee, Sina Hajimiri, Ismail Ben Ayed, Gregory Lodygensky, Christian Desrosiers, Jose Dolz* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 脑异常检测, 整流流, 无监督学习, 医学图像分割, 单步推理

**Comment:** Accepted in Medical Image Computing and Computer Assisted
  Intervention Society (MICCAI 2025)

> **TL;DR:** REFLECT是一种利用整流流进行单步脑异常校正和定位的新框架，在无监督异常检测任务中表现优于现有方法。

**AI_Comments:** REFLECT的创新之处在于将整流流应用于脑异常校正，实现了单步推理，这与传统的迭代扩散模型形成鲜明对比，极大地提高了效率。其重要性在于为无监督脑异常检测提供了一个更高效、更精确的解决方案，尤其在医学影像领域，快速准确的异常识别至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 脑成像中的无监督异常检测(UAD)对于在没有标记数据的情况下识别病理至关重要，但由于大脑解剖结构的复杂性和异常样本的稀缺性，准确地定位异常仍然具有挑战性。

**Method:** 本文提出了REFLECT框架，它利用整流流为异常MR图像向正常分布的校正建立直接的线性轨迹。通过学习一个直线、一步的校正传输图，该方法能高效校正脑异常，并通过检测异常输入与校正对应物之间的差异来精确地定位异常。与需要迭代随机采样的扩散模型不同，整流流提供直接传输图，实现单步推理。

**Result:** 在流行的UAD脑分割基准测试中进行的广泛实验表明，REFLECT显著优于最先进的无监督异常检测方法。

**Conclusion:** REFLECT通过利用整流流实现单步、高效的脑异常校正和精确的异常定位，在无监督脑异常检测领域取得了显著的性能提升。

> **ai_Abstract:** REFLECT是一个用于脑图像无监督异常检测的新框架。它利用整流流建立一个直接的、线性的传输图，实现从异常图像到正常分布的单步校正。该方法能高效校正异常并精确地定位它们，与迭代的扩散模型相比，具有显著的推理优势。实验证明，REFLECT在脑异常检测任务上优于现有SOTA方法。

> **摘要翻译:** 无监督异常检测（UAD）在脑成像中对于在无需标记数据的情况下识别病理至关重要。然而，由于大脑解剖结构的复杂性和异常样本的稀缺性，准确地定位异常仍然具有挑战性。在这项工作中，我们引入了REFLECT，这是一个新颖的框架，它利用整流流来建立一个直接的线性轨迹，用于将异常MR图像校正到正常分布。通过学习一个直线、一步的校正传输图，我们的方法能高效地校正脑异常，并通过检测异常输入与校正对应物之间的差异来精确地定位异常。与需要迭代随机采样的基于扩散的UAD模型不同，整流流提供了一个直接的传输图，实现了单步推理。在流行的UAD脑分割基准测试中进行的广泛实验表明，REFLECT显著优于最先进的无监督异常检测方法。代码可在https://github.com/farzad-bz/REFLECT获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [206] [AMD-Mamba: A Phenotype-Aware Multi-Modal Framework for Robust AMD Prognosis](https://arxiv.org/abs/2508.02957)
> *AMD-Mamba：一种表型感知多模态框架，用于稳健的AMD预后*

*Puzhen Wu, Mingquan Lin, Qingyu Chen, Emily Y. Chew, Zhiyong Lu, Yifan Peng, Hexin Dong* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-04**

**Keywords:** 年龄相关性黄斑变性, 多模态框架, 预后, 生物标志物, Vision Mamba

**Comment:** Accepted at the MICCAI 2025 MIML Workshop

> **TL;DR:** AMD-Mamba是一个多模态框架，结合眼底图像、遗传和人口数据，利用表型感知度量学习和Vision Mamba，显著提高了AMD早期预后和高危患者检测能力，并发现了一种新的重要生物标志物。

**AI_Comments:** 这项研究通过结合多模态数据（图像、遗传、人口社会信息）和引入创新的表型感知度量学习策略，显著提升了AMD预后的准确性。其采用Vision Mamba处理全局和局部信息的能力，以及发现新生物标志物的潜力，是其主要创新点。该框架对于早期干预和个性化AMD管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 年龄相关性黄斑变性（AMD）是不可逆视力丧失的主要原因，因此有效的预后对于及时干预至关重要。现有模型主要关注局部信息且使用传统CNN，未能充分捕捉疾病进展模式。

**Method:** 本文提出了AMD-Mamba多模态框架，整合彩色眼底图像、遗传变异和人口社会变量。其核心是引入表型感知度量学习策略，利用AMD严重程度评分作为先验知识，使模型学习更丰富的特征表示，并与临床表型对齐。不同于传统CNN，AMD-Mamba采用Vision Mamba，同时融合局部和长程全局信息。此外，通过多尺度融合，结合不同分辨率的图像信息和临床变量，进一步提升预测性能。

**Result:** 在AREDS数据集上进行评估，实验结果表明，该框架提出的生物标志物是AMD进展最重要的生物标志物之一。将此生物标志物与其他现有变量结合，在早期检测高危AMD患者方面取得了显著改进。

**Conclusion:** AMD-Mamba多模态框架及其新发现的生物标志物，有望促进更精确和主动的AMD管理。

> **ai_Abstract:** 本文提出了AMD-Mamba，一个新颖的多模态框架，用于年龄相关性黄斑变性（AMD）的预后。该框架整合了彩色眼底图像、遗传变异和人口社会变量，并引入了利用AMD严重程度评分的表型感知度量学习策略，以学习与临床表型对齐的丰富特征。它采用Vision Mamba同时捕获局部和全局信息，并通过多尺度融合提升性能。实验证明，AMD-Mamba发现了一种重要的AMD进展生物标志物，并显著提高了早期高危AMD患者的检测能力，有望实现更精确的疾病管理。

> **摘要翻译:** 年龄相关性黄斑变性（AMD）是不可逆视力丧失的主要原因，因此有效的预后对于及时干预至关重要。在这项工作中，我们提出了AMD-Mamba，一个用于AMD预后的新型多模态框架，并进一步开发了一种新的AMD生物标志物。该框架将彩色眼底图像与遗传变异和人口社会变量相结合。其核心是，AMD-Mamba引入了一种创新的度量学习策略，该策略利用AMD严重程度评分作为先验知识。该策略通过将学习到的特征与临床表型对齐，使模型能够学习更丰富的特征表示，从而提高了传统预后方法捕获疾病进展模式的能力。此外，与现有模型使用传统CNN骨干并主要关注局部信息（如玻璃膜疣的存在）不同，AMD-Mamba应用Vision Mamba并同时融合局部和长程全局信息（如血管变化）。此外，我们通过多尺度融合，结合不同分辨率的图像信息和临床变量，增强了预测性能。我们在AREDS数据集上评估了AMD-Mamba，该数据集包括来自2,741名受试者的45,818张彩色眼底照片、52个遗传变异和3个社会人口变量。我们的实验结果表明，我们提出的生物标志物是AMD进展最重要的生物标志物之一。值得注意的是，将此生物标志物与其他现有变量结合，在早期检测高危AMD患者方面取得了有希望的改进。这些发现突显了我们多模态框架在促进更精确和主动的AMD管理方面的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [238] [A Survey of Medical Point Cloud Shape Learning: Registration, Reconstruction and Variation](https://arxiv.org/abs/2508.03057)
> *医学点云形状学习综述：配准、重建与变异*

*Tongxu Zhang, Zhiming Liang, Bei Wang* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学点云, 形状学习, 配准, 重建, 变异建模

**Comment:** 

> **TL;DR:** 本文对医学点云形状学习进行了全面系统的综述，重点关注配准、重建和变异建模三个基本任务。

**AI_Comments:** 这是一篇重要的综述性文章，它系统地梳理了医学点云形状学习领域的最新进展和挑战，为研究人员提供了宝贵的参考。其创新之处在于对特定时间段（2021-2025）的文献进行了回顾，并明确指出了医学领域的独特挑战和未来方向。重要性体现在其对新兴技术在医学图像分析中应用的总结和展望，有助于推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 点云已成为三维医学成像中日益重要的表示形式，并随着深度学习的进步，直接从点云数据中提取、建模和分析解剖形状取得了快速进展。因此，需要对医学点云的学习型形状分析进行全面系统的综述。

**Method:** 本文对2021年至2025年的最新文献进行了回顾，总结了代表性的方法、数据集和评估指标，并强调了医学领域的临床应用和独特挑战。

**Result:** 主要趋势包括混合表示的集成、大规模自监督模型和生成技术。当前局限性包括数据稀缺、患者间变异性以及对可解释和鲁棒解决方案的需求。

**Conclusion:** 文章最后概述了推动医学成像中基于点云的形状学习的未来方向。

> **ai_Abstract:** 本文对2021年至2025年间医学点云形状学习的最新进展进行了全面综述。论文重点关注配准、重建和变异建模这三个核心任务，总结了相关方法、数据集和评估指标，并探讨了临床应用及面临的挑战。文章指出了混合表示、大规模自监督模型和生成技术是当前的主要趋势，同时也讨论了数据稀缺性、患者间变异性以及对可解释性解决方案的需求等局限性，并展望了未来的研究方向。

> **摘要翻译:** 点云已成为三维医学成像中日益重要的表示形式，与传统的基于体素或网格的方法相比，它提供了一种紧凑、保留表面的替代方案。深度学习的最新进展使得直接从点云数据中提取、建模和分析解剖形状取得了快速进展。本文对医学点云的学习型形状分析进行了全面系统的综述，重点关注三个基本任务：配准、重建和变异建模。我们回顾了2021年至2025年的最新文献，总结了代表性的方法、数据集和评估指标，并强调了医学领域的临床应用和独特挑战。主要趋势包括混合表示的集成、大规模自监督模型和生成技术。我们还讨论了当前的局限性，例如数据稀缺、患者间变异性以及临床部署对可解释和鲁棒解决方案的需求。最后，概述了推动医学成像中基于点云的形状学习的未来方向。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [270] [Nexus-INR: Diverse Knowledge-guided Arbitrary-Scale Multimodal Medical Image Super-Resolution](https://arxiv.org/abs/2508.03073)
> *Nexus-INR：多样化知识引导的任意尺度多模态医学图像超分辨率*

*Bo Zhang, JianFei Huo, Zheng Zhang, Wufan Wang, Hui Gao, Xiangyang Gong, Wendong Wang* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学图像超分辨率, 任意尺度超分辨率, 多模态图像, 知识蒸馏, 深度学习

**Comment:** 

> **TL;DR:** Nexus-INR是一个新的框架，通过利用多样化知识和下游任务，实现了高质量的任意尺度多模态医学图像超分辨率，并在BraTS2020数据集上优于现有方法。

**AI_Comments:** Nexus-INR的创新之处在于其整合了多样化知识（如辅助分类任务、知识蒸馏和解剖语义）来指导任意尺度超分辨率，并且考虑了下游任务的性能提升。这种多任务、多模态融合的方法对于复杂医学图像分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统CNN方法不适用于任意分辨率超分辨率 (ARSR)；现有INR方法难以有效处理和利用多模态图像，导致无法有效处理和利用具有不同分辨率和细节的多模态图像。

**Method:** 提出Nexus-INR，一个多样化知识引导的任意分辨率超分辨率 (ARSR) 框架。该框架包含三个关键组件：1. 带有辅助分类任务的双分支编码器，用于有效解耦共享解剖结构和模态特定特征。2. 使用跨模态注意力的知识蒸馏模块，通过高分辨率参考引导低分辨率模态重建，并通过自监督一致性损失增强。3. 集成分割模块，嵌入解剖语义以提高重建质量和下游分割性能。

**Result:** 在BraTS2020数据集上进行的超分辨率和下游分割实验表明，Nexus-INR在各种指标上均优于最先进的方法。

**Conclusion:** Nexus-INR成功解决了任意尺度多模态医学图像超分辨率的挑战，并通过整合多样化知识和下游任务，显著提升了重建和分割性能。

> **ai_Abstract:** 本文提出了Nexus-INR，一个针对任意尺度多模态医学图像超分辨率的框架。它通过结合双分支编码器（用于特征解耦）、基于跨模态注意力的知识蒸馏（用于引导重建）和集成分割模块（用于嵌入解剖语义），克服了传统方法和现有INR方法在处理多模态图像时的局限性。在BraTS2020数据集上的实验证明，Nexus-INR在超分辨率和下游分割任务上均超越了现有技术水平。

> **摘要翻译:** 任意分辨率超分辨率 (ARSR) 通过适应多样化的空间分辨率，为医学图像分析提供了关键的灵活性。然而，传统的基于CNN的方法天生不适合ARSR，因为它们通常是为固定的上采样因子设计的。虽然基于INR的方法克服了这一限制，但它们仍然难以有效处理和利用具有不同分辨率和细节的多模态图像。在本文中，我们提出了Nexus-INR，一个多样化知识引导的ARSR框架，它利用不同的信息和下游任务来实现高质量、自适应分辨率的医学图像超分辨率。具体来说，Nexus-INR包含三个关键组件。一个带有辅助分类任务的双分支编码器，以有效解耦共享解剖结构和模态特定特征；一个使用跨模态注意力的知识蒸馏模块，通过高分辨率参考引导低分辨率模态重建，并通过自监督一致性损失增强；一个集成分割模块，嵌入解剖语义以提高重建质量和下游分割性能。在BraTS2020数据集上进行的超分辨率和下游分割实验表明，Nexus-INR在各种指标上均优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [377] [GL-LCM: Global-Local Latent Consistency Models for Fast High-Resolution Bone Suppression in Chest X-Ray Images](https://arxiv.org/abs/2508.03357)
> *GL-LCM：用于胸部X射线图像中快速高分辨率骨骼抑制的全局-局部潜在一致性模型*

*Yifei Sun, Zhanghao Chen, Hao Zheng, Yuqing Lu, Lixin Duan, Fenglei Fan, Ahmed Elazab, Xiang Wan, Changmiao Wang, Ruiquan Ge* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 骨骼抑制, 胸部X射线, 扩散模型, 潜在一致性模型, 医学图像处理

**Comment:** 11 pages, 3 figures, accepted by MICCAI 2025

> **TL;DR:** GL-LCM是一种新的扩散模型，用于在胸部X射线图像中快速、高分辨率地抑制骨骼，同时保留细节并提高计算效率。

**AI_Comments:** 该论文的创新点在于提出了GL-LCM架构，通过结合全局-局部处理和局部增强引导，有效地解决了现有扩散模型在胸部X射线骨骼抑制中面临的平衡难题（即完全抑制骨骼同时保留局部纹理细节）和计算效率低下的问题。其方法无需额外训练即可提升细节保留能力，具有良好的实用价值和临床转化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 胸部X射线（CXR）成像中，骨骼结构会遮挡关键诊断细节。现有基于扩散模型的骨骼抑制方法难以平衡骨骼完全抑制与局部纹理细节保留，且计算需求高、处理时间长，限制了临床应用。

**Method:** 本文提出了一种全局-局部潜在一致性模型（GL-LCM）架构。该模型结合了肺部分割、双路径采样和全局-局部融合，以实现胸部X射线图像中快速高分辨率的骨骼抑制。为解决局部路径采样中潜在的边界伪影和细节模糊问题，作者进一步提出了局部增强引导（Local-Enhanced Guidance），该方法无需额外训练。

**Result:** 在自收集数据集SZCH-X-Rays和公共数据集JSRT上的综合实验表明，GL-LCM提供了卓越的骨骼抑制效果和显著的计算效率，显著优于几种有竞争力的现有方法。

**Conclusion:** GL-LCM成功解决了现有扩散模型在胸部X射线骨骼抑制中面临的平衡问题和效率挑战，为临床应用提供了更实用、更有效的解决方案。

> **ai_Abstract:** 本文针对胸部X射线（CXR）图像中骨骼遮挡诊断细节的问题，以及现有扩散模型在骨骼抑制与细节保留、计算效率方面的不足，提出了一种全局-局部潜在一致性模型（GL-LCM）。该模型结合了肺部分割、双路径采样和全局-局部融合，并引入了局部增强引导以解决局部采样中的伪影和模糊问题。实验结果表明，GL-LCM在骨骼抑制效果和计算效率上均显著优于现有方法，为CXR图像分析提供了更实用、高效的解决方案。

> **摘要翻译:** 胸部X射线（CXR）成像在肺部诊断中提出了重大挑战，主要是因为骨骼结构会遮挡准确诊断所需的关键细节。深度学习的最新进展，特别是扩散模型，为有效最小化CXR图像中骨骼结构的可见性提供了巨大希望，从而提高了清晰度和诊断准确性。然而，现有的用于CXR成像中骨骼抑制的基于扩散的方法难以在完全抑制骨骼和保留局部纹理细节之间取得平衡。此外，它们高计算需求和延长处理时间阻碍了其在临床环境中的实际应用。为了解决这些限制，我们引入了一种全局-局部潜在一致性模型（GL-LCM）架构。该模型结合了肺部分割、双路径采样和全局-局部融合，从而能够在CXR图像中实现快速高分辨率的骨骼抑制。为了解决局部路径采样中潜在的边界伪影和细节模糊问题，我们进一步提出了局部增强引导（Local-Enhanced Guidance），该方法无需额外训练即可解决这些问题。在自收集数据集SZCH-X-Rays和公共数据集JSRT上的综合实验表明，我们的GL-LCM提供了卓越的骨骼抑制效果和显著的计算效率，显著优于几种有竞争力的现有方法。我们的代码可在https://github.com/diaoquesang/GL-LCM获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [412] [Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy](https://arxiv.org/abs/2508.03461)
> *评估术前MRI对根治性前列腺切除术后勃起功能障碍预测价值*

*Gideon N. L. Rouwendaal, Daniël Boeke, Inge L. Cox, Henk G. van der Poel, Margriet C. van Dijk-de Haan, Regina G. H. Beets-Tan, Thierry N. Boellaard, Wilson Silva* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 勃起功能障碍, 根治性前列腺切除术, MRI, 预测模型, 临床特征

**Comment:** 13 pages, 5 figures, 2 tables. Accepted at PRedictive Intelligence in
  MEdicine workshop @ MICCAI 2025 (PRIME-MICCAI). This is the submitted
  manuscript with added link to github repo, funding acknowledgements and
  authors' names and affiliations. No further post submission improvements or
  corrections were integrated. Final version not published yet

> **TL;DR:** 术前MRI在预测根治性前列腺切除术后勃起功能障碍方面的附加价值有限，临床特征仍是最佳预测因子，但MRI可能在未来多模态方法中提供补充信息。

**AI_Comments:** 本研究的重要之处在于系统地评估了不同MRI建模策略对术后ED预测的贡献，并明确指出目前MRI在预测ED方面未能超越传统临床特征。其创新性在于尝试了深度学习和多模态融合，并使用SHAP分析和显著性图解释了模型行为。局限性在于MRI的独立预测价值有限，提示未来研究需更深入探索其与临床数据的有效融合方式。

<details>
  <summary>Details</summary>

**Motivation:** 准确的术前勃起功能障碍（ED）预测对于根治性前列腺切除术患者的咨询至关重要。虽然临床特征是已确立的预测因子，但术前MRI的附加价值尚未得到充分探索。

**Method:** 研究评估了四种建模策略来预测术后12个月的ED：1) 仅基于临床特征的基线模型；2) 使用MRI手工提取解剖特征的经典模型；3) 直接在MRI切片上训练的深度学习模型；4) 图像和临床输入的多模态融合模型。

**Result:** 图像模型（最大AUC 0.569）略优于手工解剖特征方法（AUC 0.554），但均低于临床基线模型（AUC 0.663）。融合模型仅带来微小提升（AUC 0.586），但未超越纯临床性能。SHAP分析证实临床特征对预测性能贡献最大。最佳图像模型的显著性图显示其主要关注前列腺和神经血管束等解剖学上合理区域。

**Conclusion:** 尽管基于MRI的模型并未比临床特征显著提高预测性能，但研究结果表明它们试图捕捉相关解剖结构中的模式，并可能在未来的多模态方法中补充临床预测因子。

> **ai_Abstract:** 本研究旨在评估术前MRI在预测根治性前列腺切除术后12个月勃起功能障碍方面的附加价值。通过比较仅临床模型、基于MRI手工特征模型、基于MRI深度学习模型以及多模态融合模型，研究发现MRI模型表现均逊于纯临床模型，且多模态融合模型提升有限。尽管如此，MRI模型能关注相关解剖区域，表明其可能在未来的多模态预测中作为补充信息。

> **摘要翻译:** 准确预测术前勃起功能障碍（ED）对于接受根治性前列腺切除术的患者咨询至关重要。虽然临床特征是已确立的预测因子，但术前MRI的附加价值仍未得到充分探索。我们研究了MRI是否能为术后12个月的ED提供额外的预测价值，评估了四种建模策略：（1）仅基于临床的基线模型，代表当前最先进水平；（2）使用从MRI中提取的手工解剖特征的经典模型；（3）直接在MRI切片上训练的深度学习模型；（4）图像和临床输入的多模态融合模型。基于图像的模型（最大AUC 0.569）略优于手工解剖方法（AUC 0.554），但逊于临床基线模型（AUC 0.663）。融合模型带来了微小的增益（AUC 0.586），但并未超过仅基于临床的性能。SHAP分析证实临床特征对预测性能贡献最大。表现最佳的图像模型的显著性图表明其主要关注解剖学上合理的区域，例如前列腺和神经血管束。尽管基于MRI的模型并未比临床特征提高预测性能，但我们的研究结果表明它们试图捕捉相关解剖结构中的模式，并可能在未来的多模态方法中补充临床预测因子。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [440] [CADD: Context aware disease deviations via restoration of brain images using normative conditional diffusion models](https://arxiv.org/abs/2508.03594)
> *CADD：基于范式条件扩散模型通过脑图像修复实现上下文感知疾病偏差*

*Ana Lawry Aguila, Ayodeji Ijishakin, Juan Eugenio Iglesias, Tomomi Takenaga, Yukihiro Nomura, Takeharu Yoshikawa, Osamu Abe, Shouhei Hanaoka* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 脑图像, 疾病检测, 范式建模, 条件扩散模型, 图像修复

**Comment:** 

> **TL;DR:** CADD是一种新的条件扩散模型，通过结合临床信息和改进的图像修复，在异质性脑图像数据集中实现了神经异常检测的SOTA性能。

**AI_Comments:** CADD的创新之处在于它是第一个将条件扩散模型应用于3D图像的范式建模，并引入了结合临床上下文的推理修复策略。这解决了现有扩散模型在医学图像异常检测中缺乏上下文信息和健康区域修复不佳的关键局限性，显著提升了在复杂临床数据中的检测性能，对于脑疾病的早期诊断和监测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习方法在异质性医学数据中检测疾病面临挑战。范式建模有潜力，但现有扩散模型方法未整合临床信息，且在健康区域修复上表现不佳，导致检测性能次优。

**Method:** 提出CADD，首个用于3D图像范式建模的条件扩散模型。引入一种新颖的推理修复策略，平衡异常去除和保留受试者特异性特征，以指导健康图像修复过程。

**Result:** 在三个具有挑战性的数据集（包括临床扫描）上进行评估，CADD在异质性队列中检测神经异常方面取得了最先进的性能。

**Conclusion:** CADD通过结合上下文信息和优化的修复策略，显著提高了脑图像中疾病异常检测的准确性和鲁棒性。

> **ai_Abstract:** 本文提出了CADD，一个用于3D脑图像范式建模的条件扩散模型，旨在解决现有方法在异质性医学数据中检测疾病时缺乏临床上下文和修复健康区域效果不佳的问题。CADD通过引入一种新颖的推理修复策略，平衡了异常去除与受试者特异性特征的保留，从而有效地指导健康图像修复过程。实验结果表明，CADD在多个挑战性数据集上实现了神经异常检测的最新性能。

> **摘要翻译:** 将机器学习应用于现实世界的医疗数据，例如医院档案，有潜力彻底改变脑图像中的疾病检测。然而，在此类异质性队列中检测病理是一个艰巨的挑战。范式建模，一种无监督异常检测形式，为研究此类队列提供了一种有前景的方法，其中“正常”行为被建模，并可在受试者层面用于检测与疾病病理相关的偏差。扩散模型已成为异常检测的强大工具，因为它们能够捕获复杂的数据分布并生成高质量图像。它们的性能依赖于图像修复；原始图像和修复图像之间的差异突出了潜在的异常。然而，与范式模型不同，这些扩散模型方法没有整合临床信息，而临床信息提供了重要的上下文来指导疾病检测过程。此外，标准方法通常无法很好地修复健康区域，导致重建效果不佳和次优的检测性能。我们提出了CADD，这是第一个用于3D图像范式建模的条件扩散模型。为了指导健康修复过程，我们提出了一种新颖的推理修复策略，该策略平衡了异常去除和受试者特异性特征的保留。在三个具有挑战性的数据集（包括可能具有较低对比度、较厚切片和运动伪影的临床扫描）上进行评估，CADD在异质性队列中检测神经异常方面取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [593] [MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves](https://arxiv.org/abs/2508.02726)
> *基于MPCA的超声导波迁移学习域适应*

*Lucio Pinello, Francesco Cadini, Luca Lomazzi* | **Category: eess.IV, cs.LG, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 超声导波, 迁移学习, 域适应, 多线性主成分分析, 结构健康监测

**Comment:** 

> **TL;DR:** 本文提出了一种基于MPCA的迁移学习框架，用于解决超声导波结构健康监测中数据稀缺和泛化能力差的问题，显著降低了定位误差。

**AI_Comments:** 这篇论文的创新点在于将MPCA与CNN微调相结合，用于超声导波的迁移学习，有效地解决了SHM中数据稀缺和模型泛化能力差的问题。通过在特征空间层面进行域适应，无需大量目标域数据即可实现模型的高效迁移，对于实际工程应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 超声导波（UGWs）在薄壁结构结构健康监测（SHM）中很有前景，但其与机器学习算法结合的大规模部署受到数据稀缺以及跨不同材料和传感器配置泛化能力有限的限制。

**Method:** 提出了一种基于多线性主成分分析（MPCA）的迁移学习（TL）框架。首先，训练一个用于回归的卷积神经网络（CNN）进行板结构损伤定位。然后，结合MPCA和微调，使CNN适用于不同的板材。通过将MPCA共同应用于源域和目标域，提取共享的潜在特征，实现有效的域适应。MPCA之后，通过微调使预训练的CNN适应新域，而无需大量训练数据集。

**Result:** 所提出的基于MPCA的TL方法在涉及不同复合材料和传感器阵列的12个案例研究中进行了测试。结果表明，与标准TL技术相比，定位误差显著降低。

**Conclusion:** 所提出的方法是一种鲁棒、数据高效且基于统计的UGW结构健康监测迁移学习框架。

> **ai_Abstract:** 本文针对超声导波（UGWs）在结构健康监测（SHM）中面临的数据稀缺和泛化能力差的挑战，提出了一种基于多线性主成分分析（MPCA）的新型迁移学习（TL）框架。该框架首先训练一个CNN进行损伤定位，然后结合MPCA和微调，通过提取共享潜在特征实现跨不同材料和传感器配置的域适应。实验结果表明，与传统方法相比，该方法显著降低了定位误差，证明其作为一种鲁棒、数据高效的UGW-SHM TL框架的有效性。

> **摘要翻译:** 超声导波（UGWs）是薄壁结构结构健康监测（SHM）中一种很有前景的诊断工具，其与机器学习（ML）算法的结合正日益被采用以实现实时监测能力。然而，基于UGW的ML方法的大规模部署受到数据稀缺以及跨不同材料和传感器配置泛化能力有限的限制。为了解决这些限制，本文提出了一种基于多线性主成分分析（MPCA）的新型迁移学习（TL）框架。首先，训练一个用于回归的卷积神经网络（CNN）进行板结构损伤定位。然后，结合MPCA和微调，使CNN适用于不同的板材。通过将MPCA共同应用于源域和目标域，该方法提取共享的潜在特征，从而实现有效的域适应，而无需对维度进行先验假设。在MPCA之后，微调使预训练的CNN能够适应新域，而无需大量训练数据集。所提出的基于MPCA的TL方法在涉及不同复合材料和传感器阵列的12个案例研究中进行了测试。统计指标用于评估MPCA前后域对齐情况，结果表明与标准TL技术相比，定位误差显著降低。因此，所提出的方法成为一种鲁棒、数据高效且基于统计的UGW结构健康监测迁移学习框架。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [627] [Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification](https://arxiv.org/abs/2508.02839)
> *结合稀疏可变形令牌序列的时空-光谱Mamba用于增强MODIS时间序列分类*

*Zack Dewis, Zhengsen Xu, Yimin Zhu, Motasem Alkayid, Mabel Heffring, Lincoln Linlin Xu* | **Category: eess.IV, eess.SP** | **Updated: 2025-07-29**

**Keywords:** MODIS, 时间序列分类, Mamba, 时空-光谱, 可变形令牌序列

**Comment:** 

> **TL;DR:** 本文提出了一种名为STSMamba的新型时空-光谱Mamba模型，结合稀疏可变形令牌序列，用于提高MODIS时间序列数据的分类精度并降低计算复杂度，有效解决了高维度、混合像素和耦合效应带来的挑战。

**AI_Comments:** 本文创新性地将Mamba结构引入到时空-光谱数据处理中，并针对MODIS时间序列数据的特性，设计了TGS模块解耦特征，以及SDMS方法优化Mamba序列的效率和适应性。通过构建分层可变形Mamba模块，实现了对MODIS复杂特征的精细捕捉。该方法在提高分类精度的同时降低了计算复杂度，对于大规模遥感图像分类具有重要意义和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** MODIS时间序列数据对于动态、大规模的土地覆盖/土地利用分类至关重要，但由于高时间维度、混合像素以及时空-光谱耦合效应等关键困难，捕捉细微的类别特征信息具有挑战性。

**Method:** 本文提出了一种新颖的时空-光谱Mamba（STSMamba）模型，结合可变形令牌序列，用于增强MODIS时间序列分类。主要贡献包括：1. 设计了时间分组主干（TGS）模块，用于初始特征学习以解耦时序-光谱特征耦合。2. 设计了稀疏可变形Mamba序列（SDMS）方法，以提高Mamba建模效率和准确性，减少信息冗余并提高Mamba序列的适应性和可学习性。3. 基于SDMS，设计了一种新颖的时空-光谱Mamba架构，包含稀疏可变形空间Mamba（SDSpaM）、稀疏可变形光谱Mamba（SDSpeM）和稀疏可变形时间Mamba（SDTM）三个模块，以显式学习MODIS中的关键信息源。

**Result:** 该方法在MODIS时间序列数据上进行了测试，并与许多最先进的方法进行了比较，结果表明，所提出的方法在提高分类精度的同时降低了计算复杂性。

**Conclusion:** 本文提出的STSMamba模型通过引入TGS模块、SDMS方法以及包含SDSpaM、SDSpeM、SDTM的Mamba架构，有效解决了MODIS时间序列分类中的挑战，实现了更高的分类精度和更低的计算复杂度。

> **ai_Abstract:** 本文提出了一种名为STSMamba的新型时空-光谱Mamba模型，旨在克服MODIS时间序列数据在土地覆盖分类中面临的高维度、混合像素和特征耦合挑战。该模型通过引入时间分组主干（TGS）模块来解耦时序-光谱特征，并设计了稀疏可变形Mamba序列（SDMS）方法以提高Mamba模型的效率、准确性、适应性和可学习性。在此基础上，构建了包含稀疏可变形空间、光谱和时间Mamba模块的整体架构，以显式捕捉MODIS的关键信息。实验结果表明，STSMamba在提高分类精度的同时显著降低了计算复杂度。

> **摘要翻译:** 尽管MODIS时间序列数据对于支持动态、大规模的土地覆盖土地利用分类至关重要，但由于MODIS的关键困难，例如高时间维度、混合像素以及时空-光谱耦合效应，捕获细微的类别特征信息是一项具有挑战性的任务。本文提出了一种新颖的时空-光谱Mamba（STSMamba）模型，结合可变形令牌序列，用于增强MODIS时间序列分类，并具有以下主要贡献。首先，为了解耦时序-光谱特征耦合，设计了一个时间分组主干（TGS）模块用于初始特征学习。其次，为了提高Mamba建模效率和准确性，设计了一种稀疏可变形Mamba序列（SDMS）方法，该方法可以减少Mamba序列中潜在的信息冗余，并提高Mamba序列的适应性和可学习性。第三，基于SDMS，为了改进特征学习，设计了一种新颖的时空-光谱Mamba架构，形成了三个模块，即稀疏可变形空间Mamba模块（SDSpaM）、稀疏可变形光谱Mamba模块（SDSpeM）和稀疏可变形时间Mamba模块（SDTM），以显式学习MODIS中的关键信息源。所提出的方法在MODIS时间序列数据上与许多最先进的方法进行了比较测试，结果表明，所提出的方法能够以降低的计算复杂度实现更高的分类精度。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [698] [FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and Diffusion-Based Model for Sinogram Inpainting](https://arxiv.org/abs/2409.06714)
> *用于投影图修复的物理引导双向频率感知卷积与扩散模型*

*Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang, Bin Ren* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 投影图修复, 稀疏视场CT, 扩散模型, 频率感知, 物理引导

**Comment:** 

> **TL;DR:** 一种基于扩散模型的方法，通过双向频率推理和角度感知掩码来修复CT扫描中的缺失投影数据，并利用物理引导约束确保结果的合理性，在合成和真实数据集上均优于现有方法。

**AI_Comments:** 该研究提出了一种新颖的基于扩散模型的方法来解决稀疏视场CT中的投影图修复问题，该方法考虑了投影数据的独特特性（如重叠特征和方向频谱模式）以及物理一致性，这使其在理论上具有吸引力。实验结果表明该方法在定量指标上表现优异。然而，该方法在处理不同程度的稀疏性或不同类型的CT扫描（如锥束CT）上的泛化能力有待进一步验证。此外，模型的可解释性以及计算成本也是未来研究可以关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏视场CT虽然能降低辐射剂量和扫描时间，但会导致投影数据不完整和结构性信号丢失，影响重建准确性。现有的修复模型忽视了投影数据特有的重叠特征和方向频谱模式，未能充分考虑角度依赖性和物理一致性。

**Method:** 提出了一种名为FCDM的扩散模型框架，该框架通过双向频率推理和角度感知掩码来恢复全局结构，并通过物理引导约束和频率自适应噪声控制来强制执行物理合理性。

**Result:** 在合成和真实世界数据集上的实验表明，FCDM在各种稀疏视场场景下始终优于基线方法，实现了超过0.93的SSIM和31 dB以上的PSNR。

**Conclusion:** FCDM是一种有效的投影图修复方法，能够处理稀疏视场CT带来的挑战，并在定量和定性评估中表现出优越性。

> **ai_Abstract:** 该研究提出了一种名为FCDM的物理引导双向频率感知卷积与扩散模型，用于解决稀疏视场CT中投影图修复的问题。该模型通过考虑投影图的重叠特征和方向频谱模式，并结合物理约束，能够有效地恢复缺失的数据，并在实验中取得了优于现有方法的性能。

> **摘要翻译:** 计算机断层扫描（CT）广泛应用于科学和医学成像，但获取全视场投影图需要高辐射剂量和长时间扫描。稀疏视场CT可以减轻这种负担，但会产生不完整的投影图，并伴有结构性信号丢失，从而阻碍准确重建。与RGB图像不同，投影图沿投影路径编码重叠特征，并表现出方向频谱模式。标准的修复模型忽略了这些特性，将缺失数据视为局部空洞，并忽视了角度依赖性和物理一致性。我们提出了一种名为FCDM的、专门针对投影图的基于扩散的框架，它通过双向频率推理和角度感知掩码来恢复全局结构，同时通过物理引导约束和频率自适应噪声控制来强制执行物理合理性。在合成和真实世界数据集上的实验表明，FCDM在各种稀疏视场场景下始终优于基线方法，实现了超过0.93的SSIM和31 dB以上的PSNR。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [732] [Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer](https://arxiv.org/abs/2506.21880)
> *基于物理退化模型引导的展开式Transformer干涉高光谱重建*

*Yuansheng Li, Yunhao Zou, Linwei Chen, Ying Fu* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 干涉高光谱成像, 重建, 退化模型, Transformer, 深度学习

**Comment:** 

> **TL;DR:** 该研究提出了一种新的干涉高光谱成像（IHI）重建方法，通过物理退化模型生成训练数据，并设计了IHRUT模型来校正光谱和恢复细节，实验证明了其优越性能和泛化能力。

**AI_Comments:** 该研究通过结合物理模型和深度学习（特别是Transformer架构）来解决IHI重建中的关键挑战，思路新颖。利用物理模型生成训练数据是一种有效的克服数据稀疏性问题的方法。IHRUT模型在光谱校正和细节恢复方面的设计具有潜力，但其在复杂退化场景下的鲁棒性和计算效率仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的IHI重建算法在处理成像误差和消除IHI特有退化方面存在局限性，并且缺乏训练数据集。为了提高IHI性能，需要解决数据缺乏和退化成分难以学习的问题。

**Method:** 1. 建立IHI退化模型和参数估计方法，用于合成训练数据。2. 设计了干涉高光谱重建展开式Transformer（IHRUT），利用条纹增强机制和时空Transformer架构进行光谱校正和细节恢复。

**Result:** 实验结果表明，所提出的方法在性能和泛化能力上优于现有方法。

**Conclusion:** 所提出的基于物理退化模型引导的展开式Transformer方法能够有效解决IHI重建中的数据缺乏和退化问题，并在光谱校正和细节恢复方面取得良好效果。

> **ai_Abstract:** 本研究提出了一种新颖的干涉高光谱成像（IHI）重建方法，该方法首先利用物理成像模型和辐射定标数据构建IHI退化模型，并开发参数估计方法以合成训练数据，解决了数据缺乏的问题。随后，设计了一种名为IHRUT的展开式Transformer模型，通过条纹增强机制和时空Transformer架构有效进行光谱校正和细节恢复。实验证明该方法具有优越的性能和泛化能力。

> **摘要翻译:** 干涉高光谱成像（IHI）作为一种关键的大规模遥感技术，因其通量和光谱分辨率的优势而备受关注。然而，IHI易受成像过程中复杂的误差影响，并且现有基于信号处理的重建算法限制了其质量提升。影响性能增强的两个关键挑战是：1）缺乏训练数据集。2）基于学习的方法难以消除IHI特有的退化成分。为了应对这些挑战，我们提出了一种新颖的IHI重建流程。首先，基于成像物理和辐射定标数据，我们建立了一个简化但准确的IHI退化模型和参数估计方法。该模型能够从高光谱图像（HSIs）合成真实的IHI训练数据集，弥合了IHI重建与深度学习之间的差距。其次，我们设计了干涉高光谱重建展开式Transformer（IHRUT），它通过条纹模式增强机制和时空Transformer架构实现了有效的光谱校正和细节恢复。实验结果证明了我们方法的优越性能和泛化能力。代码和可在https://github.com/bit1120203554/IHRUT获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [736] [ClinicalFMamba: Advancing Clinical Assessment using Mamba-based Multimodal Neuroimaging Fusion](https://arxiv.org/abs/2508.03008)
> *基于Mamba的多模态神经影像融合的临床应用：ClinicalFMamba*

*Meng Zhou, Farzad Khalvati* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 多模态图像融合, Mamba, CNN, 深度学习, 医学影像

**Comment:** Accepted at MICCAI MLMI 2025 Workshop

> **TL;DR:** ClinicalFMamba是一种结合了CNN和Mamba的新型混合架构，用于多模态医学图像融合，能够有效结合局部和全局特征，实现实时融合，并在脑肿瘤分类任务中表现优于基线方法。

**AI_Comments:** 该研究提出了一种新颖的混合架构ClinicalFMamba，有效地结合了CNN和Mamba的优势，解决了多模态医学图像融合中的计算效率和长距离依赖建模问题。三平面扫描策略对于处理3D数据是一个重要的创新。临床验证部分增加了研究的实际价值。然而，文中未详细说明Mamba的具体实现细节以及与其他SSM变体的比较。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习方法在多模态医学图像融合方面存在局限性：CNN擅长局部特征但难以建模全局上下文，Transformer能有效建模长距离依赖但计算复杂度高。SSM提供了一种有前景的替代方案，但其在3D数据上的扩展和临床验证尚待探索。

**Method:** 提出了一种名为ClinicalFMamba的新型端到端CNN-Mamba混合架构，用于2D和3D图像的融合，结合了局部和全局特征。设计了一种三平面扫描策略来学习3D图像的体积依赖性。

**Result:** 在三个数据集上的综合评估表明，该方法在多个定量指标上实现了卓越的融合性能，并达到了实时融合。在下游的2D/3D脑肿瘤分类任务中，该方法也取得了优于基线方法的性能。

**Conclusion:** ClinicalFMamba通过结合CNN和Mamba的优势，并采用创新的三平面扫描策略，实现了高效且准确的多模态医学图像融合，为实时临床部署提供了新的范式，并在临床效用验证中表现出色。

> **ai_Abstract:** ClinicalFMamba是一种创新的CNN-Mamba混合架构，旨在解决多模态医学图像融合中的局部和全局特征建模挑战。该方法通过结合CNN的局部特征提取能力和Mamba的高效长距离依赖建模能力，并引入三平面扫描策略处理3D数据，实现了实时、高性能的图像融合。在脑肿瘤分类等下游任务中的临床验证结果表明，ClinicalFMamba在准确性和效率上均优于现有方法，为临床应用提供了有前景的解决方案。

> **摘要翻译:** 多模态医学图像融合整合了来自不同成像模态的互补信息，以提高诊断准确性和治疗规划。尽管深度学习方法在性能上取得了进步，但现有方法面临关键限制：卷积神经网络（CNN）擅长局部特征提取，但在有效建模全局上下文方面存在困难；而Transformer在实现卓越的长距离建模的同时，其二次计算复杂度限制了临床部署。最近的状态空间模型（SSM）提供了一种有前景的替代方案，通过选择性扫描机制，能够在线性时间内实现高效的长距离依赖建模。尽管取得了这些进展，但将其扩展到3D体积数据以及对融合图像进行临床验证仍然是未被充分探索的领域。在本研究中，我们提出了ClinicalFMamba，一种新颖的端到端CNN-Mamba混合架构，它协同结合了2D和3D图像的局部和全局特征建模。我们进一步设计了一种三平面扫描策略，以有效地学习3D图像中的体积依赖性。在三个数据集上的综合评估证明了其在多个定量指标上的卓越融合性能，同时实现了实时融合。我们进一步验证了我们的方法在下游2D/3D脑肿瘤分类任务中的临床效用，取得了优于基线方法的性能。我们的方法为适用于实时临床部署的高效多模态医学图像融合建立了一个新的范例。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [772] [Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic](https://arxiv.org/abs/2507.23763)
> *医学图像分割中的拓扑优化与快速欧拉示性数*

*Liu Li, Qiang Ma, Cheng Ouyang, Johannes C. Paetzold, Daniel Rueckert, Bernhard Kainz* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 医学图像分割, 拓扑优化, 欧拉示性数, 拓扑感知, 深度学习

**Comment:** 

> **TL;DR:** 该研究提出了一种基于欧拉示性数（$\chi$）的快速拓扑感知分割方法，用于解决深度学习医学图像分割中的拓扑不正确问题。该方法通过快速计算$\chi$误差和生成拓扑违规图，并结合一个拓扑感知校正网络来优化分割结果，能在保持像素级精度的同时显著提高拓扑正确性。

**AI_Comments:** 该研究提出了一种创新的方法来解决医学图像分割中的关键问题——拓扑正确性。利用欧拉示性数替代计算成本高昂的持久同调，并引入拓扑违规图和校正网络，这是一个重要的进展。该方法在理论和实践上都具有潜力，能够提升分割结果的临床可靠性。然而，在实际应用中，不同模态和分辨率的医学图像对该方法鲁棒性的影响仍需进一步考察。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度学习医学图像分割方法在处理需要拓扑约束（如连续边界或闭合曲面）的病例时，即使在Dice分数或交并比等常规指标上表现良好，也常常无法达到临床可接受的精度。在医学图像分割中，分割结果在拓扑学上的正确性（例如，所需的拓扑基因数）有时比像素级精度更重要。现有的拓扑感知方法依赖持久同调（PH），但其计算复杂度高，难以应用于高维数据。

**Method:** 1. 提出了一种快速计算2D和3D欧拉示性数（$\chi$）的公式。2. 将预测与真实值之间的标量$\chi$误差作为拓扑评估指标。3. 通过“拓扑违规图”（高亮显示$\chi$误差区域）来估计任意分割网络的空间拓扑正确性。4. 利用拓扑违规图，通过一个拓扑感知校正网络来优化任意分割网络的分割结果。

**Result:** 所提出的方法能够显著提高医学图像分割结果的拓扑正确性，同时保持像素级的分割精度。实验在2D和3D数据集上进行了验证。

**Conclusion:** 该研究提出的基于欧拉示性数的快速拓扑感知分割方法，能够有效解决现有深度学习分割方法在拓扑正确性方面的不足，为提高医学图像分割的临床应用价值提供了新的解决方案。

> **ai_Abstract:** 本研究提出了一种新颖快速的拓扑感知医学图像分割方法，旨在解决传统深度学习方法在满足临床拓扑约束方面的不足。该方法利用欧拉示性数（$\\chi$）作为拓扑评估指标，通过快速计算$\\chi$误差和生成拓扑违规图，并结合一个专门的校正网络来优化分割结果，以提高分割的拓扑正确性，同时保持像素级的精度。

> **摘要翻译:** 基于深度学习的医学图像分割技术在基于Dice分数或交并集等常规指标进行评估时，已显示出有希望的结果。然而，这些全自动方法在满足临床可接受的精度方面常常失败，特别是在拓扑约束（例如连续边界或闭合曲面）应该被观察的情况下。在医学图像分割中，分割结果在拓扑基因数方面的正确性有时甚至比像素级精度更重要。现有的拓扑感知方法通常通过持久同调（PH）的概念来估计和约束拓扑结构。然而，由于其多项式计算复杂度，这些方法难以应用于高维数据。为了解决这个问题，我们提出了一种基于欧拉示性数（$\chi$）的、新颖且快速的拓扑感知分割方法。首先，我们提出了一种在2D和3D中计算$\chi$的快速公式。预测与真实值之间的标量$\chi$误差作为拓扑评估指标。然后，我们通过所谓的拓扑违规图来估计任何分割网络的空间拓扑正确性，即一个突出显示$\chi$误差区域的详细图。最后，通过拓扑感知校正网络，根据拓扑违规图对任意网络分割结果进行优化。我们的实验在2D和3D数据集上进行，并表明我们的方法可以在保持像素级分割精度的同时，显著提高拓扑正确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [817] [Predicting EGFR Mutation in LUAD from Histopathological Whole-Slide Images Using Pretrained Foundation Model and Transfer Learning: An Indian Cohort Study](https://arxiv.org/abs/2508.01352)
> *使用预训练的基金模型和迁移学习从组织病理学全切片图像预测LUAD中的EGFR突变：一项印度队列研究*

*Sagar Singh Gwal, Rajan, Suyash Devgan, Shraddhanjali Satapathy, Abhishek Goyal, Nuruddin Mohammad Iqbal, Vivaan Jain, Prabhat Singh Mallik, Deepali Jain, Ishaan Gupta* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 肺腺癌, EGFR突变, 全切片成像, 基金模型, 迁移学习

**Comment:** 14 pages, 4 figures and 2 tables

> **TL;DR:** 本研究提出了一种基于ViT基金模型和ABMIL的深度学习框架，用于从H&E染色的WSI预测LUAD的EGFR突变状态。该模型在印度队列数据上训练，并在内部和外部数据集上表现出优异的性能（AUC分别为0.933和0.965），证明了其在资源有限环境下通过常规病理切片准确预测EGFR突变状态的可行性。

**AI_Comments:** 这项研究在利用AI预测癌症相关生物标志物方面取得了重要进展，特别是在资源有限的地区。使用基金模型和迁移学习的方法使得模型在小型数据集上也能获得良好的性能，这对于许多临床应用场景具有重要意义。然而，研究中使用的“小型数据集”的具体定义以及模型在不同地理区域和人群中的泛化能力仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** EGFR突变在LUAD中很常见，携带EGFR突变的患者可以通过特定的酪氨酸激酶抑制剂（TKIs）进行治疗。因此，预测EGFR突变状态有助于临床决策。H&E染色的全切片成像（WSI）是一种常规的癌症筛查程序，特别是在东南亚人群中，EGFR突变发病率显著高于高加索人。

**Method:** 提出了一种基于Vision Transformers（ViT）病理基金模型和注意力机制多实例学习（ABMIL）架构的深度学习（DL）框架，用于从H&E染色的WSI预测EGFR突变状态。该框架使用来自印度队列的170个WSI进行训练，并在来自印度队列的30个WSI的内部测试集和来自TCGA的86个WSI的外部测试集上进行了评估。

**Result:** 该模型在内部和外部测试集上均表现出一致的性能，AUC值分别为0.933（+/-0.010）和0.965（+/-0.015）。与之前的研究相比，该模型在小型数据集上能够高效训练并取得优越的性能。

**Conclusion:** 本研究证明了使用常规病理切片，特别是利用基金模型和注意力机制多实例学习，在资源有限的环境中准确预测EGFR突变状态的可行性。

> **ai_Abstract:** 本研究提出了一种新颖的深度学习框架，结合了Vision Transformer（ViT）基金模型和注意力机制多实例学习（ABMIL），能够从常规的H&E染色全切片图像（WSI）中准确预测肺腺癌（LUAD）患者的EGFR突变状态。研究在印度队列数据上进行训练，并在内部和外部数据集上验证了模型的有效性，取得了高AUC值（分别为0.933和0.965）。该框架在小型数据集上表现出高效训练和优越性能，尤其适用于资源受限的医疗环境。

> **摘要翻译:** 肺腺癌（LUAD）是非小细胞肺癌（NSCLC）的一个亚型。EGFR基因突变的LUAD约占LUAD病例的46%。携带EGFR突变的患者可以使用特定的酪氨酸激酶抑制剂（TKIs）进行治疗。因此，预测EGFR突变状态有助于临床决策。H&E染色的全切片成像（WSI）是癌症分期和分型的常规筛查程序，尤其影响东南亚人群，与高加索人相比（分别为39-64% vs 7-22%），其突变发生率显著更高。近期人工智能模型的进展在癌症检测和分类方面显示出有希望的结果。在本研究中，我们提出了一种基于Vision Transformers（ViT）病理基金模型和注意力机制多实例学习（ABMIL）架构的深度学习（DL）框架，用于从H&E染色的WSI预测EGFR突变状态。所开发的流程使用印度队列（170 WSI）的数据进行训练，并在两个独立的测试集上进行评估：内部测试集（来自印度队列的30 WSI）和来自TCGA的外部测试集（86 WSI）。该模型在两个数据集上均表现出一致的性能，内部和外部测试集的AUC分别为0.933（+/-0.010）和0.965（+/-0.015）。与之前的多项研究相比，该提出的框架能够在小型数据集上高效训练，并取得优越的性能，无论训练域如何。目前的研究证明了使用常规病理切片，特别是在资源有限的环境中使用基金模型和注意力机制多实例学习，准确预测EGFR突变状态的可行性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [858] [Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder](https://arxiv.org/abs/2508.02431)
> *使用高效的非对称 Transformer 解码器识别肺癌中的可操作驱动基因突变*

*Biagio Brattoli, Jack Shi, Jongchan Park, Taebum Lee, Donggeun Yoo, Sergio Pereira* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 非小细胞肺癌, 驱动基因突变, 计算病理学, 多示例学习, Transformer 解码器

**Comment:** Accepted at MICCAI 2025 Workshop COMPAYL

> **TL;DR:** 该研究提出了一种新的非对称 Transformer 解码器模型，用于在计算病理学中检测非小细胞肺癌（NSCLC）的六种关键可操作驱动基因突变。该模型通过使用不同维度的查询和键值来保持低查询维度，从而有效地提取信息并减少过拟合风险。此外，该研究还提出了一种直接利用组织类型的方法，克服了传统多示例学习（MIL）方法的局限性。实验结果表明，该方法在检测常见和罕见突变方面均优于现有的 MIL 模型，为基于机器学习的测试提供了更实用的替代方案。

**AI_Comments:** 该研究提出了一种新颖的非对称 Transformer 解码器模型，并成功应用于计算病理学中 NSCLC 驱动基因突变的检测。该模型在处理 MIL 设置和整合组织类型信息方面具有创新性，并且在实验中取得了优于现有方法的性能提升。然而，关于模型的可解释性、在更大规模数据集上的泛化能力以及在真实临床环境中的部署和验证方面，可能还需要进一步的研究。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基因检测指南推荐，但由于可用性有限和周转时间长，更广泛地采用基因检测仍然具有挑战性。计算病理学（CPath）中的机器学习（ML）方法提供了一种潜在的解决方案，但现有研究通常只关注一两种常见突变，限制了这些工具的临床价值和受益患者群体。

**Method:** 本研究评估了多种多示例学习（MIL）技术，以检测 ALK、BRAF、EGFR、ERBB2、KRAS 和 MET ex14 这六种关键的可操作 NSCLC 驱动基因突变。此外，研究引入了一种非对称 Transformer 解码器模型，该模型采用不同维度的查询和键值，以保持低查询维度，从而有效地从块嵌入中提取信息并最小化过拟合风险。研究还提出了一种直接利用组织类型的方法来解决 MIL 分析中忽略生物学相关性的局限性。

**Result:** 该方法在预测罕见突变（如 ERBB2 和 BRAF）方面平均比顶级 MIL 模型高出 4% 以上，在整体上平均高出 3%，使基于机器学习的测试更接近于标准基因检测的实用替代方案。

**Conclusion:** 本研究提出的非对称 Transformer 解码器模型在计算病理学中检测 NSCLC 驱动基因突变方面表现出优越的性能，并且通过直接利用组织类型解决了 MIL 方法的局限性，为临床实践提供了更实用、更有效的工具。

> **ai_Abstract:** 本研究提出了一种新的非对称 Transformer 解码器模型，用于计算病理学中检测非小细胞肺癌（NSCLC）的六种关键可操作驱动基因突变。该模型通过使用不同维度的查询和键值来保持低查询维度，从而有效地提取信息并减少过拟合风险。此外，该研究还提出了一种直接利用组织类型的方法，克服了传统多示例学习（MIL）方法的局限性。实验结果表明，该方法在检测常见和罕见突变方面均优于现有的 MIL 模型，为基于机器学习的测试提供了更实用的替代方案。

> **摘要翻译:** 在非小细胞肺癌（NSCLC）中识别可操作的驱动基因突变可以影响治疗决策并显著改善患者的预后。尽管有指南建议，但由于可用性有限和周转时间长，更广泛地采用基因检测仍然具有挑战性。计算病理学（CPath）中的机器学习（ML）方法提供了一种潜在的解决方案；然而，研究通常只关注一种或两种常见突变，这限制了这些工具的临床价值以及能够从中受益的患者群体。本研究评估了各种多示例学习（MIL）技术，以检测六种关键的可操作 NSCLC 驱动基因突变：ALK、BRAF、EGFR、ERBB2、KRAS 和 MET ex14。此外，我们引入了一种非对称 Transformer 解码器模型，该模型采用不同维度的查询和键值，以保持低查询维度。这种方法有效地从块嵌入中提取信息，并最小化了过拟合风险，被证明在 MIL 环境中具有高度适应性。此外，我们提出了一种直接利用组织类型的方法，解决了传统 MIL 方法中分析所有区域或仅分析某些特定区域而忽略生物学相关性的典型局限性。我们的方法在平均性能上比顶级 MIL 模型提高了 3%，在预测 ERBB2 和 BRAF 等罕见突变时提高了 4% 以上，使基于 ML 的测试更接近于标准基因检测的实用替代方案。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [23] [Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread](https://arxiv.org/abs/2508.02950)
> *Zak-OTFS在移动性和延迟扩展存在下的超奈奎斯特信号传输*

*Sandesh Rao Mattu, Nishant Mehrotra, Robert Calderbank* | **Category: eess.SP** | **Updated: 2025-08-04**

**Keywords:** Zak-OTFS, 超奈奎斯特信号, 延迟-多普勒域, 移动性, 预编码

**Comment:** 5 pages, 2 figures. Submitted to IEEE

> **TL;DR:** 本文提出了一种基于Zak-OTFS的超奈奎斯特信号传输方案，通过信息符号叠加和预编码，在保持类似奈奎斯特性能的同时，简化了接收处理并提升了编码性能。

**AI_Comments:** 这项研究通过引入Zak-OTFS调制和信息符号叠加的独特方法，为实现超奈奎斯特信号传输提供了一种创新途径。通过将接收处理简化为高斯噪声检测，极大地降低了接收端的复杂性，并为利用更先进的编码方案提升性能奠定了基础。这对于在移动和延迟扩展环境中提高频谱效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 正交信号传输限制了在给定带宽和时间内传输的信息符号数量（奈奎斯特限制）。超奈奎斯特信号传输旨在传输更多的信息符号，但这会导致正交性损失和复杂的接收处理。本文旨在通过一种不同的方法实现超奈奎斯特信号传输，以克服这些挑战。

**Method:** 本文提出了一种基于Zak变换的正交时频空间（Zak-OTFS）调制方案，用于超奈奎斯特信号传输。该方案通过在延迟-多普勒（DD）域中，在保持奈奎斯特信号原始间距的同时，叠加信息符号。它利用DD信道缓慢变化的特性来构建预编码器，以减轻双扩展信道的影响。此外，信息符号被放置在两个相互无偏的基上，使得它们之间的干扰表现为高斯噪声，从而将接收器处理简化为高斯噪声中的检测。这使得能够使用格雷利编码调制来提高误码性能。

**Result:** 数值结果表明，所提出的超奈奎斯特信号方案在无编码时实现了与奈奎斯特信号相似的性能，并且在编码时，在高信噪比下性能优于奈奎斯特信号。

**Conclusion:** 本文提出的基于Zak-OTFS的超奈奎斯特信号传输方案，通过创新的信息符号叠加和预编码技术，成功地在移动性和延迟扩展环境中实现了更高的频谱效率，同时保持了良好的误码性能，尤其是在高信噪比下。

> **ai_Abstract:** 本文提出了一种新颖的超奈奎斯特信号传输方法，利用基于Zak变换的正交时频空间（Zak-OTFS）调制。该方法通过在延迟-多普勒域中叠加信息符号，并构建预编码器来减轻信道影响。通过将信息符号放置在两个相互无偏的基上，使得相互干扰表现为高斯噪声，从而简化了接收处理。数值结果显示，该方案在无编码时性能与奈奎斯特信号相当，而在编码时，高信噪比下的性能更优。

> **摘要翻译:** 正交信号传输将带宽$B$和时间$T$内传输的信息符号数量限制为$BT$。这对应于奈奎斯特信号传输，通过将信息符号加载到跨越$BT$维空间、间隔为$rac{1}{B}$和$rac{1}{T}$的$BT$维基上实现。超奈奎斯特信号传输涉及在$BT$维空间中传输超过$BT$个信息符号。这会导致正交性损失。这通过在相同的$BT$维空间中打包更多信息符号（间隔小于$rac{1}{B}$和/或$rac{1}{T}$）而导致的时间和/或带宽扩展来实现。在本文中，我们对超奈奎斯特信号传输采取了不同的方法。我们建议在保持奈奎斯特信号传输中原始间隔的同时，将信息符号相互叠加。我们使用基于Zak变换的正交时频空间（Zak-OTFS）调制在延迟-多普勒（DD）域中进行此操作。在Zak-OTFS中，信道变化缓慢。此外，Zak-OTFS还允许构建相互无偏的基，它们之间的干扰表现为高斯噪声。所提出的方案利用DD信道中的缓慢变化来构建一个预编码器，以减轻双扩展信道的影响。此外，在所提出的方案中，我们将信息符号加载到两个相互无偏的基上，这允许信息符号的叠加。这简化了接收器处理，使其在高斯噪声中进行检测，因为每个基对另一个基来说都表现为高斯噪声。这种简化使得可以使用格雷利编码调制来增强误码性能。数值结果表明，超奈奎斯特信号方案在无编码时实现了与奈奎斯特信号相似的性能，并且在编码时，在高信噪比下性能优于奈奎斯特信号。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [27] [SpectrumFM: A New Paradigm for Spectrum Cognition](https://arxiv.org/abs/2508.02742)
> *SpectrumFM：频谱认知的新范式*

*Chunyu Liu, Hao Zhang, Wei Wu, Fuhui Zhou, Qihui Wu, Derrick Wing Kwan Ng, Chan-Byoung Chae* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-08-02**

**Keywords:** 频谱认知, 基础模型, 自监督学习, LoRA, 频谱感知

**Comment:** This paper has been accepted for presentation at the 2025 IEEE Global
  Communications Conference (GLOBECOM 2025), Cognitive Radio and AI-Enabled
  Network Symposium

> **TL;DR:** 本文提出了SpectrumFM，一个用于频谱认知的基础模型，通过创新的编码器、自监督预训练和LoRA微调，在多种频谱任务中显著提升了性能。

**AI_Comments:** 该论文的创新点在于将基础模型范式应用于频谱认知领域，通过结合先进的神经网络架构（CNNs和多头自注意力）、自监督学习以获得可迁移的表示，以及高效的微调技术（LoRA），显著提升了模型在不同频谱任务中的泛化能力和准确性。这为未来的频谱管理和利用提供了新的可能性和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的频谱认知方法在部署到不同频谱环境和任务时，泛化能力有限且准确性不佳。

**Method:** 本文提出了一个名为SpectrumFM的频谱基础模型。它包含一个创新的频谱编码器，该编码器利用卷积神经网络和多头自注意力机制来有效捕获频谱数据中的细粒度局部信号结构和高级全局依赖。为了增强其适应性，开发了两种新颖的自监督学习任务（掩蔽重建和下一时隙信号预测）用于预训练SpectrumFM，使其能够学习丰富且可迁移的表示。此外，利用低秩适应（LoRA）参数高效微调，使SpectrumFM能够无缝适应各种下游频谱认知任务，包括频谱感知（SS）、异常检测（AD）和无线技术分类（WTC）。

**Result:** SpectrumFM在SS任务中，在-4 dB信噪比（SNR）下将检测概率提高了30%；在AD任务中，将曲线下面积（AUC）提高了10%以上；在WTC任务中，将准确性提高了9.6%。

**Conclusion:** SpectrumFM在各种频谱认知任务中表现出优于现有最先进方法的卓越性能，为频谱认知提供了一个新范式。

> **ai_Abstract:** 本文针对现有频谱认知方法泛化能力和准确性不足的问题，提出了一个名为SpectrumFM的频谱基础模型。该模型采用创新的频谱编码器来捕获频谱数据的局部和全局特征，并通过掩蔽重建和下一时隙信号预测两种自监督任务进行预训练，以学习可迁移的表示。结合LoRA参数高效微调，SpectrumFM能够高效适应频谱感知、异常检测和无线技术分类等多种下游任务，并在实验中展现出显著优于现有方法的性能。

> **摘要翻译:** 频谱效率的提升和安全频谱利用的实现，关键依赖于频谱认知。然而，现有的频谱认知方法在部署到不同的频谱环境和任务时，往往表现出有限的泛化能力和次优的准确性。为了克服这些挑战，我们提出了一个频谱基础模型，命名为SpectrumFM，它为频谱认知提供了一个新范式。我们提出了一种创新的频谱编码器，该编码器利用卷积神经网络和多头自注意力机制，以有效地捕获频谱数据中细粒度的局部信号结构和高级全局依赖。为了增强其适应性，开发了两种新颖的自监督学习任务，即掩蔽重建和下一时隙信号预测，用于预训练SpectrumFM，使模型能够学习丰富且可迁移的表示。此外，利用低秩适应（LoRA）参数高效微调，使SpectrumFM能够无缝适应各种下游频谱认知任务，包括频谱感知（SS）、异常检测（AD）和无线技术分类（WTC）。广泛的实验表明，SpectrumFM优于最先进的方法。具体而言，它在SS任务中，在-4 dB信噪比下将检测概率提高了30%，在AD任务中将曲线下面积（AUC）提高了10%以上，并将WTC准确性提高了9.6%。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [71] [Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation](https://arxiv.org/abs/2508.03021)
> *超表面赋能的超大规模天线系统：收发器架构、物理建模与信道估计*

*Zhengyu Wang, Tiebin Mi, Gui Zhou, Robert C. Qiu* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 超表面, 超大规模天线阵列, 信道估计, 收发器架构, 物理建模

**Comment:** 

> **TL;DR:** 本文提出了一种名为MELA的新型超表面赋能超大规模天线系统，通过可重构透射超表面实现高效RF-天线耦合和相位控制，并开发了物理模型和两阶段信道估计算法，实验证明其具有接近最优的空间分辨率和高精度信道估计能力，是ELAA的实用化解决方案。

**AI_Comments:** 这篇论文的创新点在于将可重构超表面引入超大规模天线阵列，显著简化了传统ELAA复杂的硬件架构，降低了成本和体积。其提出的物理建模和两阶段信道估计算法，特别是对近远场混合场景的考虑，展现了对实际应用需求的深刻理解。MELA在空间分辨率和信道估计精度上的表现，预示着其在未来无线通信中具有巨大的潜力，是推动ELAA实用化的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 超大规模天线阵列（ELAAs）是下一代无线通信系统满足前所未有性能需求的关键技术，但其实现面临实际应用上的挑战。

**Method:** 本文提出超表面赋能的超大规模天线（MELA）系统，采用可重构透射超表面实现高效的空中射频到天线耦合和相位控制，从而避免了传统方案中笨重的开关矩阵和昂贵的移相器网络。研究开发了表征电磁场通过单个透射单元传播的物理模型，以及有利于高效参数估计和信号处理的距离相关近似模型。基于此信道模型，针对近场和远场混合用户场景，提出了一种两阶段信道估计框架：第一阶段采用字典驱动的波束空间滤波实现快速角度域扫描；第二阶段利用子阵的旋转对称性设计超分辨率估计器，联合恢复角度和距离参数。

**Result:** 研究推导了MELA半功率波束宽度的解析表达式，揭示其相对于传统ELAA架构具有接近最优的空间分辨率。数值实验进一步验证了所提出信道估计算法的高分辨率和电磁模型的保真度。

**Conclusion:** MELA架构是实现ELAA实际部署的极具竞争力且前瞻性的解决方案。

> **ai_Abstract:** 本文提出了一种名为MELA（Metasurface-Enabled Extremely Large-scale Antenna）的新型超大规模天线系统，旨在解决传统ELAA在下一代无线通信中实用性不足的问题。MELA利用可重构透射超表面实现高效的射频-天线耦合和相位控制，从而简化了收发器架构，避免了昂贵的传统组件。文章详细阐述了MELA的物理建模和一种针对混合近远场用户的两阶段信道估计框架，该框架结合了字典驱动的波束空间滤波和基于旋转对称性的超分辨率估计。理论分析和数值实验表明，MELA具有接近最优的空间分辨率和高精度的信道估计能力，是ELAA实际部署的有力竞争者。

> **摘要翻译:** 超大规模天线阵列（ELAAs）已成为满足下一代无线通信系统前所未有性能需求的关键技术。为了提高其实用性，我们提出了超表面赋能的超大规模天线（MELA）系统——一种新颖的收发器架构，它采用可重构透射超表面来促进高效的空中射频到天线耦合和相位控制。这种架构消除了传统解决方案中通常需要的笨重开关矩阵和昂贵的移相器网络。本文开发了物理基础模型来表征电磁场通过单个透射单元的传播，捕获了波变换和传输的基本物理原理。此外，还引入了距离相关的近似模型，这些模型展现出有利于高效参数估计和信号处理的结构特性。基于此信道模型，针对近场和远场混合用户场景，提出了一种两阶段信道估计框架。在第一阶段，字典驱动的波束空间滤波技术能够实现快速角度域扫描。在细化阶段，利用子阵的旋转对称性设计超分辨率估计器，联合恢复角度和距离参数。本文推导了MELA半功率波束宽度的解析表达式，揭示其相对于传统ELAA架构具有接近最优的空间分辨率。数值实验进一步验证了所提出信道估计算法的高分辨率和电磁模型的保真度，将MELA架构定位为实际ELAA部署的极具竞争力且前瞻性的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [119] [Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training](https://arxiv.org/abs/2508.03084)
> *基于对比自监督预训练的场景无关深度学习定位*

*Lingyan Zhang, Yuanfeng Qiu, Dachuan Li, Shaohua Wu, Tingting Zhang, Qinyu Zhang* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 深度学习, 定位, 对比学习, 自监督预训练, 场景无关

**Comment:** 

> **TL;DR:** CSSLoc是一种基于对比自监督预训练的深度学习定位框架，旨在学习通用表示以在各种场景下实现准确且对环境动态鲁棒的定位，优于现有方法。

**AI_Comments:** 本文的创新点在于将对比自监督预训练引入深度学习定位领域，有效解决了现有方法对环境动态的脆弱性和场景特异性问题。通过学习场景无关的通用表示，CSSLoc显著提升了定位的鲁棒性和泛化能力，使其更适用于实际复杂的环境，推动了深度学习定位技术从特定应用走向更广泛的通用应用，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管无线定位在特定场景下精度有所提高，但其对环境动态的脆弱性限制了其实际应用，现有方法缺乏通用性。

**Method:** 本文提出了CSSLoc框架，通过对比自监督预训练来学习无线电数据的相似性判别度量，无需位置信息监督。它使相似样本在表示空间中紧密聚类，不同样本分离，以实现场景无关的学习。训练好的特征编码器可直接用于下游定位任务，位置预测器则用于估计准确且对环境动态鲁棒的位置。

**Result:** CSSLoc在典型的室内场景中，性能优于经典和最先进的基于DNN的定位方案。

**Conclusion:** CSSLoc将深度学习定位从特异性推向了通用性，提升了其在各种场景下的实际应用潜力。

> **ai_Abstract:** 本文提出了一种名为CSSLoc的新型深度学习框架，它利用对比自监督预训练来解决传统无线定位方法在环境动态性和场景通用性方面的局限性。CSSLoc无需位置监督，通过学习无线电数据的相似性判别度量，使相似样本在表示空间中聚集，不同样本分离，从而实现场景无关的通用表示学习。训练后的特征编码器可直接用于下游定位任务，并提供对环境动态鲁棒的准确位置估计。实验结果表明，CSSLoc在典型室内场景中优于现有深度学习定位方案，显著提升了深度学习定位的通用性。

> **摘要翻译:** 无线定位已成为提供智能基于位置服务的一项有前景的技术。尽管其在特定场景下的定位精度有所提高，但环境动态脆弱性的不足仍然阻碍了这种方法在实际应用中的全面普及。在本文中，我们提出了CSSLoc，一个基于对比自监督预训练的新颖框架，用于学习通用表示，以便在各种场景下实现准确的定位。在没有位置信息监督的情况下，CSSLoc试图学习一种对无线电数据相似性判别的深刻度量，以一种场景无关的方式，使得相似样本在表示空间中紧密聚类，不同样本则被分离。此外，训练好的特征编码器可以直接用于下游定位任务，并且训练位置预测器以估计准确的位置，并具有环境动态的鲁棒性。通过大量的实验结果表明，CSSLoc在典型的室内场景中能够超越经典和最先进的基于DNN的定位方案，将基于深度学习的定位从特异性推向了通用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [151] [Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition](https://arxiv.org/abs/2508.03131)
> *使用高阶动态模态分解的大规模电路模型降阶*

*Na Liu, Chengliang Dai, Qiuyue Wu, Qiuqi Li, Guoxiong Cai* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 模型降阶, 动态模态分解, 高阶动态模态分解, 大规模电路, 电路仿真

**Comment:** 

> **TL;DR:** 本文提出了一种高阶动态模态分解 (HODMD) 方法，用于加速大规模电路仿真，解决了传统动态模态分解 (DMD) 在空间分辨率不足时无法重构输出信号的问题，并经验证其计算效率和准确性。

**AI_Comments:** 本文的创新点在于将高阶动态模态分解 (HODMD) 应用于大规模电路的模型降阶，并通过引入延迟嵌入技术解决了传统DMD在处理低空间分辨率数据时的局限性。这对于加速复杂电路仿真具有重要意义，且其普适性强，不依赖于电路的具体结构，使其具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 加速大规模瞬态电路仿真，同时解决传统动态模态分解 (DMD) 在空间分辨率不足时无法重构输出信号的问题。

**Method:** 首先推导了动态模态分解 (DMD) 算法，然后提出了一种结合延迟嵌入技术的高阶动态模态分解 (HODMD) 方法，专门针对大规模电路仿真中的计算效率。

**Result:** 提出的HODMD方法克服了DMD方法在空间分辨率不足时无法重构输出信号的问题。该算法适用于一般电路，并且对电路拓扑或元件类型没有限制。通过三个代表性的数值测试案例，系统地验证了HODMD方法的计算效率和准确性。

**Conclusion:** 高阶动态模态分解 (HODMD) 是一种有效且准确的模型降阶方法，适用于大规模电路仿真，能够克服传统DMD的局限性。

> **ai_Abstract:** 本文针对大规模瞬态电路仿真中的模型降阶问题，提出了一种基于高阶动态模态分解 (HODMD) 的新方法。该方法结合了延迟嵌入技术，旨在提高计算效率，并解决了传统动态模态分解 (DMD) 在空间分辨率不足时无法重构输出信号的局限性。HODMD算法普适于各种电路，且不限制其拓扑或元件类型。通过数值测试案例验证了其在计算效率和准确性方面的优越性。

> **摘要翻译:** 模型降阶 (MOR) 长期以来一直是加速大规模瞬态电路仿真的主流策略。动态模态分解 (DMD) 代表了一种新颖的数据驱动表征方法，无需显式系统方程即可直接从时域仿真数据中提取主导动态模态。本文首先推导了DMD算法，然后提出了结合延迟嵌入技术的高阶动态模态分解 (HODMD)，专门针对大规模电路仿真中的计算效率。与DMD方法相比，HODMD方法克服了当空间分辨率不足时输出信号无法重建的问题。所提出的HODMD算法适用于一般电路，并且对相关电路的拓扑或元件类型不施加任何约束。本文提出了三个代表性的数值测试案例，以系统地验证所提出的HODMD方法的计算效率和准确性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [191] [Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication](https://arxiv.org/abs/2508.03248)
> *基于矢量量化的语义通信中结合特征重建的联邦学习*

*Yoon Huh, Bumjun Kim, Wan Choi* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 联邦学习, 语义通信, 特征重建, 矢量量化, 差分隐私

**Comment:** 

> **TL;DR:** 本文提出FedSFR，一个结合语义特征重建的联邦学习框架，用于解决基于矢量量化的图像语义通信中的知识库不匹配和模型过时问题，通过在参数服务器引入特征重建步骤并允许客户端传输紧凑特征向量，从而提高训练稳定性、通信效率，并在容量受限环境下优于现有基线。

**AI_Comments:** FedSFR的创新之处在于将语义特征重建引入联邦学习框架，以解决语义通信中的核心问题，即知识库不匹配和模型过时。通过在PS端进行特征重建并允许传输紧凑特征向量，有效提升了通信效率和训练稳定性，这对于资源受限的边缘设备尤其重要。此外，其对损失函数的设计、收敛性分析和差分隐私变体的考量，都增强了其理论基础和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语义通信系统（特别是基于神经网络的联合源信道编码）主要关注图像传输，但常因用户间知识库不匹配和模型过时导致语义通信错误和性能下降，需要频繁的模型更新。

**Method:** 本文提出FedSFR，一个新颖的联邦学习（FL）框架，该框架融入了语义特征重建（FR）。FedSFR在参数服务器（PS）引入了一个FR步骤，并允许部分客户端传输紧凑的特征向量而非完整的本地模型更新，以提高训练稳定性和通信效率。为实现有效的FR学习，设计了一个针对VQ图像语义通信的损失函数，并证明其可作为图像重建误差的替代。此外，还提供了严格的收敛性分析，并提出了FedSFR的差分隐私变体及正式的隐私分析。

**Result:** 在两个基准数据集上的实验结果验证了FedSFR优于现有基线，尤其是在容量受限的设置中，证实了其有效性和鲁棒性。

**Conclusion:** FedSFR通过结合特征重建的联邦学习，有效解决了基于矢量量化的图像语义通信中知识库不匹配和模型过时的问题，提高了训练稳定性、通信效率，并在容量受限环境下表现出卓越的性能和鲁棒性。

> **ai_Abstract:** 本文提出了FedSFR，一个针对基于矢量量化的图像语义通信的联邦学习框架，旨在解决知识库不匹配和模型过时问题。FedSFR在参数服务器端引入语义特征重建，并允许客户端传输紧凑特征向量，从而提升训练稳定性和通信效率。论文设计了专门的损失函数，并进行了收敛性及差分隐私分析。实验结果表明，FedSFR在容量受限环境下表现出优越的性能和鲁棒性。

> **摘要翻译:** 最近语义通信的进展主要集中在图像传输，其中基于神经网络（NN）的联合源信道编码（JSCC）模块发挥核心作用。然而，此类系统常因用户间知识库不匹配和模型过时导致语义通信错误和性能下降，需要定期模型更新。为解决矢量量化（VQ）图像语义通信系统中的这些挑战，我们提出了FedSFR，一个新颖的联邦学习（FL）框架，该框架融入了语义特征重建（FR）。FedSFR在参数服务器（PS）引入了一个FR步骤，并允许部分客户端传输紧凑的特征向量而非完整的本地模型更新，从而提高训练稳定性和通信效率。为实现有效的FR学习，我们设计了一个针对VQ图像语义通信的损失函数，并证明其可作为图像重建误差的替代。此外，我们提供了严格的收敛性分析，并提出了FedSFR的差分隐私变体以及正式的隐私分析。在两个基准数据集上的实验结果验证了FedSFR优于现有基线，尤其是在容量受限的设置中，证实了其有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [231] [Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks](https://arxiv.org/abs/2508.03279)
> *用于无人机无线网络资源分配的脉冲神经网络*

*Vasileios Kouvakis, Stylianos E. Trevlakis, Ioannis Arapakis, Alexandros-Apostolos A. Boulogeorgos* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 脉冲神经网络, 无人机, 资源分配, UE-BS关联, 非地面网络

**Comment:** 

> **TL;DR:** 本研究提出并比较了两种基于脉冲神经网络（SNN）的方法，用于无人机无线网络中的用户设备-基站（UE-BS）关联，以实现高效资源管理。

**AI_Comments:** 该论文创新性地将脉冲神经网络应用于异构无人机无线网络的资源分配问题，特别是用户设备-基站关联。SNN的事件驱动特性可能带来更快的推理速度和更高的能效，这对于资源受限的无线网络至关重要。论文比较了集中式和分布式两种SNN策略，并用射线追踪模拟验证了其有效性，为实际部署提供了参考价值。其局限性可能在于实际网络环境的复杂性远超模拟，以及SNN在更大规模网络中的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 随着无人机引入无线网络，系统架构变得异构，需要动态高效的管理来避免拥塞并维持整体性能。

**Method:** 本研究提出了一种新的基于脉冲神经网络（SNN）的方法，用于非地面网络（NTN）中的用户设备-基站（UE-BS）关联。具体比较了两种SNN优化策略：一种是具有完整网络可见性的自上而下集中式方法，另一种是针对单个网络节点的自下而上分布式方法。SNN基于具有时间分量的漏积分放电神经元，可进行快速高效的事件驱动推理，并通过真实的射线追踪模拟进行验证。

**Result:** 射线追踪模拟结果显示，自下而上模型达到了90%以上的准确率，而自上而下模型保持了80-100%的准确率。

**Conclusion:** 两种方法都在个体最优解决方案和UE-BS关联可行性之间存在权衡，表明它们在不同部署场景下均有效。

> **ai_Abstract:** 本论文提出了一种基于脉冲神经网络（SNN）的新方法，用于无人机增强型无线网络中的用户设备与基站关联。论文比较了两种SNN优化策略：自上而下的集中式方法和自下而上的分布式方法。SNN采用漏积分放电神经元进行事件驱动推理。通过射线追踪模拟验证，自下而上模型准确率超过90%，自上而下模型准确率在80-100%之间。研究发现，两种方法在个体最优性和关联可行性之间存在权衡，且其有效性取决于具体的部署场景。

> **摘要翻译:** 这项工作提出了一种新的基于脉冲神经网络（SNN）的方法，用于非地面网络（NTN）中的用户设备-基站（UE-BS）关联。随着无人机引入无线网络，系统架构变得异构，因此需要动态高效的管理来避免拥塞并维持整体性能。所提出的框架比较了两种基于SNN的优化策略。具体而言，一种是具有完整网络可见性的自上而下集中式方法，另一种是针对单个网络节点的自下而上分布式方法。SNN基于具有时间分量的漏积分放电神经元，可以执行快速高效的事件驱动推理。进行了真实的射线追踪模拟，结果表明自下而上模型达到了90%以上的准确率，而自上而下模型保持了80-100%的准确率。两种方法都揭示了个体最优解决方案和UE-BS关联可行性之间的权衡，从而揭示了两种方法根据部署场景的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [263] [Quantum Deep Learning for Massive MIMO User Scheduling](https://arxiv.org/abs/2508.03327)
> *量子深度学习用于大规模MIMO用户调度*

*Xingyu Huang, Ruining Fan, Mouli Chakraborty, Avishek Nag, Anshu Mukherjee* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 量子深度学习, 大规模MIMO, 用户调度, 混合量子神经网络, 5G/B5G

**Comment:** 

> **TL;DR:** 本文提出了一种混合量子神经网络（QNN）架构，用于5G/B5G大规模MIMO系统中的高效用户调度，解决了传统方法的可扩展性问题，并通过利用统计信道状态信息（CSI），减少计算开销，提高频谱效率，且性能优于经典卷积神经网络（CNNs），在噪声信道中保持鲁棒性。

**AI_Comments:** 这篇论文的创新点在于将量子神经网络应用于大规模MIMO用户调度，提出了一种混合架构，有效解决了传统方法的扩展性问题。其重要性在于展示了量子计算在无线通信领域的实际应用潜力，尤其是在提高效率和鲁棒性方面。

<details>
  <summary>Details</summary>

**Motivation:** 解决5G/超越5G（B5G）大规模多输入多输出（MIMO）系统中传统用户调度方法的可扩展性问题。

**Method:** 引入一种混合量子神经网络（QNN）架构，该架构将经典神经网络与变分量子电路核相结合，并利用统计信道状态信息（CSI）进行用户调度。

**Result:** 该模型能够减少计算开销，提高频谱效率，性能优于经典的卷积神经网络（CNNs），并在噪声信道中保持鲁棒的性能。

**Conclusion:** 证明了量子增强机器学习在无线调度领域的潜力。

> **ai_Abstract:** 本文提出了一种混合量子神经网络（QNN）架构，旨在解决5G/超越5G（B5G）大规模MIMO系统中用户调度的可扩展性挑战。该模型通过整合经典神经网络和变分量子电路核，并利用统计信道状态信息（CSI），显著降低了计算开销并提升了频谱效率。实验结果表明，该QNN架构不仅超越了传统卷积神经网络（CNN）的性能，而且在噪声环境下展现出强大的鲁棒性，突显了量子增强机器学习在无线通信调度领域的巨大潜力。

> **摘要翻译:** 我们引入了一种混合量子神经网络（QNN）架构，用于5G/超越5G（B5G）大规模多输入多输出（MIMO）系统中高效的用户调度，解决了传统方法的可扩展性问题。通过利用统计信道状态信息（CSI），我们的模型减少了计算开销并提高了频谱效率。它将经典神经网络与变分量子电路核相结合，性能优于经典卷积神经网络（CNN），并在噪声信道中保持鲁棒的性能。这证明了量子增强机器学习在无线调度方面的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [275] [Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information](https://arxiv.org/abs/2508.02799)
> *从Wi-Fi信道状态信息中提取移动目标的距离-多普勒信息*

*Jessica Sanson, Rahul C. Shah, Maximilian Pinaroc, Valerio Frascolla* | **Category: eess.SP, cs.AI** | **Updated: 2025-08-04**

**Keywords:** Wi-Fi传感, 信道状态信息, 距离估计, 多普勒估计

**Comment:** 

> **TL;DR:** 本文首次提出一种从商用Wi-Fi CSI中提取移动目标距离和多普勒信息的方法，通过新的信号处理技术克服了硬件挑战，实现了高精度传感。

**AI_Comments:** 这项研究的创新之处在于首次实现了在单基地设置下，从商用Wi-Fi CSI中提取距离和多普勒信息，并且克服了非全双工硬件固有的挑战。其重要性在于证明了利用现有标准Wi-Fi设备进行高精度传感的潜力，无需昂贵的专用硬件或修改，这为智能家居、安防监控等领域提供了低成本、易部署的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 从非全双工Wi-Fi网卡中利用CSI相位进行Wi-Fi感知面临两大挑战：1) 硬件异步导致显著相位误差；2) 发射和接收天线距离过近产生强耦合，淹没运动信号。

**Method:** 提出了一种新的信号处理方法，通过三个关键创新解决上述挑战：时间偏移抵消、相位对齐校正和发射/接收耦合缓解。

**Result:** 该方法实现了对移动目标厘米级的距离和多普勒估计精度，并使用商用Intel Wi-Fi AX211网卡进行了验证。结果表明，在真实环境中成功检测和跟踪移动物体。

**Conclusion:** 该研究证实了使用标准Wi-Fi数据包通信和现成硬件（无需修改或特殊全双工能力）进行高精度传感的可行性。

> **ai_Abstract:** 本文首次提出一种利用商用Wi-Fi信道状态信息（CSI）提取移动目标距离和多普勒信息的方法。针对非全双工网卡在CSI相位利用中面临的硬件异步和天线强耦合两大挑战，作者提出了一套创新的信号处理方法，包括时间偏移抵消、相位对齐校正和Tx/Rx耦合缓解。实验验证表明，该方法能实现厘米级的距离和多普勒估计精度，并在真实环境中成功检测和跟踪移动物体，证明了使用标准Wi-Fi硬件实现高精度传感的可行性。

> **摘要翻译:** 本文首次提出一种从商用Wi-Fi信道状态信息（CSI）中提取距离和多普勒信息的方法，采用单基地（单收发器）设置。从非为全双工操作设计的网卡（NIC）中利用Wi-Fi感知的CSI相位具有挑战性，原因在于：（1）硬件异步，引入显著的相位误差；（2）发射（Tx）和接收（Rx）天线距离过近，产生强耦合，淹没了感兴趣的运动信号。我们提出了一种新的信号处理方法，通过三项关键创新来解决这两个挑战：时间偏移抵消、相位对齐校正和Tx/Rx耦合缓解。我们的方法在移动目标的距离和多普勒估计中达到了厘米级精度，并使用商用Intel Wi-Fi AX211网卡进行了验证。我们的结果显示，在真实环境中成功检测和跟踪移动物体，从而确立了使用标准Wi-Fi数据包通信和现成硬件（无需任何修改或专用全双工能力）进行高精度传感的可行性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [287] [Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications](https://arxiv.org/abs/2508.03391)
> *LEO卫星通信中免授权随机接入的跳波束模式设计*

*Seunghyeon Jeon, Seonjung Kim, Gyeongrae Im, Yo-Seb Jeon* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** LEO卫星通信, 波束跳变, 免授权随机接入, 资源分配, 优化算法

**Comment:** 

> **TL;DR:** 本文提出了一种新的波束跳变模式设计算法，用于低地球轨道（LEO）卫星通信中的免授权随机接入系统，以根据流量需求动态分配资源，并通过仿真验证了其优越性和鲁棒性。

**AI_Comments:** 本文的创新点在于将波束跳变模式设计问题公式化为二元优化问题，并提出了结合二分法和改进ADMM的交替优化算法来解决。这种方法有效地平衡了碰撞避免和解码成功率，并增强了ADMM的适用性。研究对于提高LEO卫星通信系统在资源受限和流量不均衡情况下的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 欠服务区域对大规模设备连接的需求不断增长，推动了先进LEO卫星通信系统的发展。波束跳变LEO系统无需建立连接，为实现按需资源分配和低接入延迟提供了解决方案。本文旨在解决如何为免授权随机接入系统设计波束跳变模式，以根据服务小区流量需求动态分配卫星资源。

**Method:** 本文将波束跳变模式设计问题表述为一个二元优化问题，目标是在有限的卫星波束生成容量下，最大化各小区最小成功传输概率。为解决此问题，提出了新颖的波束跳变设计算法，该算法在交替优化框架内交替增强防碰撞率和解码成功概率。具体地，算法采用二分法根据需求优化每个小区的照明分配，并使用交替方向乘子法（ADMM）优化波束跳变模式以最大化解码成功概率。此外，通过用两个等效的连续值约束代替严格的二元约束来增强ADMM。

**Result:** 仿真结果表明，所提出的算法优于其他波束跳变方法，并验证了其在管理流量需求不平衡方面的鲁棒性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对低地球轨道（LEO）卫星通信中的免授权随机接入系统，研究了波束跳变模式设计问题。为了动态分配卫星资源以满足各小区流量需求，作者将此问题建模为一个二元优化问题，旨在最大化最小成功传输概率。为此，提出了一种基于交替优化框架的新算法，结合二分法优化照明分配和改进的交替方向乘子法（ADMM）优化波束跳变模式。仿真结果验证了所提算法在性能上优于现有方法，并展现了其在应对流量不平衡方面的鲁棒性。

> **摘要翻译:** 欠服务区域对大规模设备连接日益增长的需求推动了先进低地球轨道（LEO）卫星通信系统的发展。无需建立连接的跳波束LEO系统为实现按需资源分配和低接入延迟提供了一种有前景的解决方案。本文研究了免授权随机接入系统中的跳波束模式设计，以根据服务小区的流量需求动态分配卫星资源。我们提出了一个二元优化问题，旨在在有限的卫星波束生成容量下，最大化各小区最小成功传输概率。为了解决这个问题，我们提出了新颖的跳波束设计算法，该算法在交替优化框架内交替增强防碰撞率和解码成功概率。具体地，算法采用二分法根据需求优化每个小区的照明分配，同时使用交替方向乘子法（ADMM）优化跳波束模式以最大化解码成功概率。此外，我们通过用两个等效的连续值约束代替严格的二元约束来增强ADMM。仿真结果表明，所提出的算法优于其他跳波束方法，并验证了其在管理流量需求不平衡方面的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [309] [How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.03423)
> *如何使用无蜂窝大规模MIMO主动监测不可信通信？*

*Isabella W. G. da Silva, Zahra Mobini, Hien Q. Ngo, Hyundong Shin, Michail Matthaiou* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 无蜂窝大规模MIMO, 主动监测, CSI获取, 干扰功率控制, 贝叶斯优化

**Comment:** 

> **TL;DR:** 本文提出并评估了一种基于CF-mMIMO的主动监测系统，该系统通过创新的CSI获取和优化方法，能有效监测和干扰不可信通信，并显著优于现有基准。

**AI_Comments:** 该论文提出了一种新颖的CF-mMIMO主动监测系统，其创新点在于结合了有效的CSI获取方案和基于贝叶斯优化的联合模式分配及干扰功率控制方法。通过利用CF-mMIMO的优势，该系统在监测不可信通信方面取得了显著的性能提升，尤其是在监测成功概率方面表现出色。这对于提升未来无线通信系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究一个无蜂窝大规模多输入多输出（CF-mMIMO）主动监测系统，以监测来自不可信发射机（UT）的传输或干扰不可信接收机（UR）的接收。

**Method:** 提出了一种有效的信道状态信息（CSI）获取方案，通过最小均方误差（MMSE）估计方案利用不可信链路上下行阶段的导频信号估计有效信道。推导了不可信链路和监测系统的新频谱效率（SE）表达式。为提高监测性能，提出了一种基于贝叶斯优化框架的联合模式分配和干扰功率控制优化方法，以最大化监测成功概率（MSP）。

**Result:** 数值结果表明：(a) 所提出的CF-mMIMO主动监测系统，依赖于所提出的CSI获取和优化方法，显著优于所考虑的基准；(b) 无论不可信节点的天线数量或不可信传输链路的预编码方案如何，CF-mMIMO主动监测系统的MSP性能均大于0.8。

**Conclusion:** 所提出的基于CF-mMIMO的主动监测系统及其CSI获取和优化方法能够显著提高对不可信通信的监测成功概率，并展现出优越的性能。

> **ai_Abstract:** 本文提出了一种基于无蜂窝大规模MIMO（CF-mMIMO）的主动监测系统，旨在观察或干扰不可信通信。该系统引入了创新的CSI获取方案，利用MMSE估计信道，并推导了新的频谱效率表达式。为优化监测性能，论文进一步提出了基于贝叶斯优化的联合模式分配和干扰功率控制方法，以最大化监测成功概率。数值结果验证了该系统在性能上显著优于现有基准，并且在不同配置下监测成功概率均高于0.8，展现了其在主动监测不可信通信方面的有效性和鲁棒性。

> **摘要翻译:** 本文研究了一种无蜂窝大规模多输入多输出（CF-mMIMO）主动监测系统，其中多个多天线监测节点（MNs）被分配用于观察不可信发射机（UT）的传输或干扰不可信接收机（UR）的接收。我们为监测系统提出了一种有效的信道状态信息（CSI）获取方案。在我们的方法中，MNs利用不可信链路在上行和下行阶段传输的导频信号，并通过最小均方误差（MMSE）估计算法估计与UT和UR对应的有效信道。我们推导了不可信链路和监测系统的新频谱效率（SE）表达式。对于后者，SE是在中央处理单元（CPU）的两种CSI可用性情况下推导的；即情况1：MNs和CPU都有不完美的CSI知识，情况2：MNs有不完美的CSI知识而CPU没有CSI知识。为了提高监测性能，我们提出了一种新颖的联合模式分配和干扰功率控制优化方法，以基于贝叶斯优化框架最大化监测成功概率（MSP）。数值结果表明：(a) 我们依赖于所提出的CSI获取和优化方法的CF-mMIMO主动监测系统显著优于所考虑的基准；(b) 无论不可信节点的天线数量或不可信传输链路的预编码方案如何，我们的CF-mMIMO主动监测系统的MSP性能均大于0.8。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [343] [Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO](https://arxiv.org/abs/2508.03460)
> *动态TDD蜂窝自由MIMO系统中的联合感知与双向通信*

*Anubhab Chowdhury, Sai Subramanyam Thoota, Erik G. Larsson* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 集成感知与通信, 动态时分双工, 蜂窝自由MIMO, 广义似然比检验, 雷达截面估计

**Comment:** Accepted for publication in the IEEE Transactions on Wireless
  Communications 14 pages, 9 figures (one with two subfigures)

> **TL;DR:** 本研究探讨了在动态时分双工(DTDD)蜂窝自由(CF)大规模MIMO(mMIMO)系统中实现集成感知与通信(ISAC)。通过利用半双工(HD)接入点(AP)的空间分离特性，DTDD使得UL和DL用户能够并发服务。论文提出了针对目标检测的集中式和分布式广义似然比检验(GLRTs)，并量化了其权衡。同时，还提出了联合UL用户数据检测和RCS估计的统一框架，并针对通信部分推导了SINR最优组合器和两种DL预编码器。数值研究表明GLRT对AP间干扰具有鲁棒性，且DTDD相较于传统TDD系统能使90%概率下的UL-DL和速率翻倍。

**AI_Comments:** 该论文的创新点在于将动态时分双工（DTDD）引入蜂窝自由（CF）大规模MIMO系统，以实现集成感知与通信（ISAC），并在半双工（HD）硬件限制下仍能显著提升系统性能。提出的GLRT方法在AP间干扰环境下表现出鲁棒性，并且DTDD能够使和速率翻倍，这对于未来6G通信与感知一体化系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本论文研究的动机是为了在动态时分双工（DTDD）蜂窝自由（CF）大规模多输入多输出（mMIMO）系统中实现集成感知与通信（ISAC），以利用半双工（HD）接入点（AP）的空间分离特性，使系统能够同时服务上行（UL）和下行（DL）用户并进行目标感知。

**Method:** 本研究提出了以下方法：1. 针对目标检测，提出了集中式和分布式广义似然比检验（GLRTs），将UL用户信号视为感知干扰。2. 量化了分布式和集中式GLRTs之间的最优性与复杂性权衡，并以贝叶斯Cramér-Rao下界（CRLB）为基准评估了目标雷达截面（RCS）的估计器。3. 提出了一个用于联合UL用户数据检测和RCS估计的统一框架。4. 对于通信，推导了考虑交叉链路和雷达干扰的UL数据处理的信噪比加干扰比（SINR）最优组合器。5. 在DL中，对用户使用正则化迫零，并为目标提出了两种预编码器：一种是“用户中心”的预编码器，用于消除目标信号对DL用户的干扰；另一种是“目标中心”的预编码器，基于目标与AP之间复合信道的主导特征向量。

**Result:** 研究结果表明：1. 广义似然比检验（GLRT）对AP间干扰具有鲁棒性。2. 动态时分双工（DTDD）相较于传统的基于TDD的CF-mMIMO ISAC系统，在90%概率下能使上行-下行（UL-DL）和速率（SE）翻倍，同时使用半双工（HD）硬件。

**Conclusion:** 本论文的结论是，在动态时分双工（DTDD）蜂窝自由（CF）大规模MIMO系统中，可以有效地实现集成感知与通信（ISAC）。通过提出的GLRT方法，目标检测对AP间干扰具有鲁棒性，并且DTDD在保持半双工硬件的同时，能够显著提升UL-DL和速率，使其相比传统TDD系统翻倍。

> **ai_Abstract:** 本文研究了动态时分双工（DTDD）蜂窝自由（CF）大规模多输入多输出（mMIMO）系统中的集成感知与通信（ISAC）。该系统利用半双工（HD）接入点（AP）实现上行（UL）和下行（DL）用户的并发服务。研究提出了针对目标检测的集中式和分布式广义似然比检验（GLRTs），并分析了其性能与复杂性权衡。此外，还提出了联合UL用户数据检测和雷达截面（RCS）估计的统一框架，并针对UL和DL通信分别设计了SINR最优组合器和两种目标预编码器。数值结果表明，GLRT对AP间干扰具有鲁棒性，且DTDD在相同硬件条件下能将UL-DL和速率提升一倍。

> **摘要翻译:** 本文研究了动态时分双工（DTDD）蜂窝自由（CF）大规模多输入多输出（mMIMO）系统中的集成感知与通信（ISAC）。DTDD使得CF mMIMO系统能够利用空间分离的半双工（HD）接入点（AP）使用相同的时间-频率资源同时服务上行（UL）和下行（DL）用户。此外，为了促进ISAC，UL APs被用于UL数据和目标回波接收，而DL APs则联合传输预编码的DL数据流和目标信号。在此背景下，我们提出了集中式和分布式广义似然比检验（GLRTs）用于目标检测，将UL用户信号视为感知干扰。然后，我们量化了分布式和集中式GLRTs之间的最优性和复杂性权衡，并以目标雷达截面（RCS）的贝叶斯Cramér-Rao下界（CRLB）为基准评估了各自的估计器。接着，我们提出了一个用于联合UL用户数据检测和RCS估计的统一框架。其次，对于通信，我们推导了考虑交叉链路和雷达干扰的UL数据处理的信噪比加干扰比（SINR）最优组合器。在DL中，我们对用户使用正则化迫零，并为目标提出了两种类型的预编码器：一种是“用户中心”的预编码器，用于消除目标信号对DL用户造成的干扰；另一种是“目标中心”的预编码器，基于目标与AP之间复合信道的主导特征向量。最后，数值研究证实了我们的理论发现，并揭示了GLRT对AP间干扰具有鲁棒性，并且DTDD相较于传统的基于TDD的CF-mMIMO ISAC系统，在90%概率下能使UL-DL和速率翻倍；同时使用了HD硬件。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [364] [Millimeter-Wave Communication Testbed Using Digital Coding Dynamic Metasurface Antenna: Practical Design and Implementation](https://arxiv.org/abs/2502.13705)
> *采用数字编码动态超表面天线的毫米波通信测试平台：实际设计与实现*

*Abdul Jabbar, Mostafa Elsayed, Jalil Ur-Rehman Kazim, Zhibo Pang, Julien Le Kernec, Muhammad Imran, Hadi Larijani, Masood Ur-Rehman, Qammer Abbasi, Muhammad Usman* | **Category: eess.SP** | **Updated: 2025-08-05**

**Keywords:** 动态超表面天线, 毫米波通信, 波束赋形, 集成传感与通信

**Comment:** 13 pages, 11 figures

> **TL;DR:** 论文展示了一个使用数字编码动态超表面天线（DMA）的毫米波通信测试平台，实现了实时波束赋形、空间复用和多路视频传输，为未来的集成传感与通信（ISAC）奠定基础。

**AI_Comments:** 该论文的创新点在于构建了一个实用的、基于数字编码动态超表面天线（DMA）的毫米波通信测试平台，成功展示了DMA在实现高效波束赋形、空间复用和多路传输方面的潜力。其重要性在于为未来5G-A和6G网络中的集成传感与通信（ISAC）提供了关键技术验证，并展示了DMA在实际通信系统中的应用前景，如毫米波回程和大规模MIMO。

<details>
  <summary>Details</summary>

**Motivation:** 动态超表面天线（DMA）通过可编程超材料单元实现节能、经济高效的波束赋形，有望彻底改变下一代无线通信和传感网络的波束赋形技术。本文旨在设计并实现一个基于DMA的毫米波通信平台，以验证其在实际应用中的潜力。

**Method:** 论文设计并实现了在60 GHz毫米波频段运行的DMA辅助无线通信平台。系统使用FPGA生成高速二进制编码序列，实现实时波束转向、空间复用和独立数据传输。通过概念验证实验，成功演示了62 GHz下的高清QPSK调制视频传输，并利用DMA的多波束能力同时向两个空间分离的接收器传输视频。

**Result:** 成功演示了在62 GHz下高清QPSK调制视频传输。利用DMA的多波束能力，同时向两个空间分离的接收器传输视频并实现了精确解调。

**Conclusion:** 提出的毫米波测试平台为实现传感与通信的无缝集成（ISAC）铺平了道路，并展示了在毫米波回程链路和大规模MIMO毫米波基站等实际用例中的潜力。

> **ai_Abstract:** 本文介绍并实现了一个基于数字编码动态超表面天线（DMA）的毫米波通信测试平台。该平台在60 GHz频段运行，利用FPGA生成高速二进制编码序列，实现了实时波束转向、空间复用和多路视频传输。实验证明了其在高清视频传输和多用户通信方面的能力，并展望了其在集成传感与通信（ISAC）、毫米波回程和大规模MIMO等未来6G应用中的潜力。

> **摘要翻译:** 动态超表面天线 (DMA) 通过可编程超材料单元实现节能、经济高效的波束赋形，无需传统的移相器和延迟线，正在改变可重构天线技术。这项突破性技术正在兴起，以彻底改变下一代无线通信和传感网络的波束赋形。在本文中，我们提出了在免许可的60 GHz毫米波 (mmWave) 频段运行的DMA辅助无线通信平台的设计和实际实现。我们的系统采用通过现场可编程门阵列 (FPGA) 生成的高速二进制编码序列，实现实时波束转向，用于空间复用和独立数据传输。一项概念验证实验成功演示了在62 GHz下的高清正交相移键控 (QPSK) 调制视频传输。此外，利用DMA的多波束能力，我们同时向两个空间分离的接收器传输视频，实现了精确解调。我们设想所提出的毫米波测试平台可以作为实现传感与通信无缝集成的平台，通过用传感数据替换视频传输或利用辅助无线信道向多个接收器传输传感信息。这种协同作用为推进超越5G和6G网络中的集成传感与通信 (ISAC) 铺平了道路。此外，我们的测试平台展示了在实际用例中的潜力，包括毫米波回程链路和大规模多输入多输出 (MIMO) 毫米波基站。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [409] [Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks](https://arxiv.org/abs/2508.02856)
> *基于主动式ISAC防御波束窃取攻击的安全毫米波波束成形*

*Seyed Bagher Hashemi Natanzi, Hossein Mohammadi, Bo Tang, Vuk Marojevic* | **Category: eess.SP, cs.AI, cs.NI** | **Updated: 2025-08-04**

**Keywords:** 毫米波通信, 波束成形, 物理层安全, 深度强化学习, 集成传感与通信

**Comment:** 

> **TL;DR:** 本文提出了一种利用深度强化学习（DRL）代理和集成传感与通信（ISAC）能力，主动防御毫米波波束窃取攻击的新框架，实现了高攻击者检测率和良好的通信性能。

**AI_Comments:** 该论文的创新之处在于将深度强化学习与集成传感与通信（ISAC）相结合，用于主动防御毫米波波束窃取攻击。特别是，引入课程学习策略以克服DRL在安全关键任务中的探索难题，增强了代理的鲁棒性。这种结合提供了一种智能且自适应的物理层安全解决方案，对于未来毫米波系统的安全通信具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 毫米波（mmWave）通信系统日益容易受到高级波束窃取攻击的影响，这构成了重大的物理层安全威胁，需要有效的防御机制。

**Method:** 本研究引入了一个新颖的框架，该框架采用基于近端策略优化（PPO）算法的深度强化学习（DRL）代理。该代理利用集成传感与通信（ISAC）能力进行主动、智能的威胁评估，并动态控制ISAC探测动作以调查可疑活动。为克服复杂的探索挑战，引入了一种密集的课程学习策略，以确保代理在训练期间成功检测。

**Result:** 数值结果表明，该框架实现了92.8%的平均攻击者检测率，同时保持了平均用户信噪比（SINR）超过13 dB。

**Conclusion:** 该框架通过智能地平衡安全性和通信性能，实现了对毫米波波束窃取攻击的鲁棒和自适应防御。

> **ai_Abstract:** 本文提出了一种基于深度强化学习（DRL）代理和集成传感与通信（ISAC）能力的新型毫米波通信系统安全框架，旨在主动防御高级波束窃取攻击。该框架利用ISAC进行智能威胁评估，DRL代理通过近端策略优化（PPO）和课程学习策略，学习平衡安全与通信性能的鲁棒策略。实验结果表明，该方法能有效检测攻击者并保持良好的通信质量。

> **摘要翻译:** 毫米波（mmWave）通信系统日益容易受到高级波束窃取攻击的影响，这构成了重大的物理层安全威胁。本文引入了一个新颖的框架，该框架采用先进的深度强化学习（DRL）代理，用于主动和自适应地防御这些复杂的攻击。一个关键的创新是利用集成传感与通信（ISAC）能力进行主动、智能的威胁评估。该DRL代理基于近端策略优化（PPO）算法构建，动态控制ISAC探测动作以调查可疑活动。我们引入了一种密集的课程学习策略，以确保代理在训练期间经历成功的检测，从而克服这种安全关键任务固有的复杂探索挑战。因此，该代理学习了一种鲁棒且自适应的策略，智能地平衡了安全性和通信性能。数值结果表明，我们的框架实现了92.8%的平均攻击者检测率，同时保持了平均用户信噪比（SINR）超过13 dB。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [540] [Evaluation of Deep Learning Models for LBBB Classification in ECG Signals](https://arxiv.org/abs/2508.02710)
> *ECG信号中左束支传导阻滞分类的深度学习模型评估*

*Beatriz Macas Ordóñez, Diego Vinicio Orellana Villavicencio, José Manuel Ferrández, Paula Bonomini* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 深度学习, ECG, LBBB, 分类, 神经网络

**Comment:** Accepted for presentation in the 47th Annual International Conference
  of the IEEE Engineering in Medicine and Biology Society (EMBC 2025)

> **TL;DR:** 本研究评估了不同深度学习模型在ECG信号中对健康受试者、左束支传导阻滞和严格左束支传导阻滞进行分类的能力，以优化心脏再同步治疗的候选人选择。

**AI_Comments:** 该研究的创新点在于应用深度学习模型对ECG信号中的LBBB进行细致分类，这对于心脏再同步治疗的患者选择具有重要的临床意义。通过探索不同的神经网络架构，有望提升诊断的准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索不同神经网络架构在心电图（ECG）信号中提取空间和时间模式的能力，并将其分为健康受试者、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）三组，以优化左束支传导阻滞患者的分类，从而选择心脏再同步治疗（CRT）的候选人。

**Method:** 本研究探索了不同的神经网络架构，以评估它们从心电图（ECG）信号中提取空间和时间模式的能力，并将信号分类为健康受试者、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）三组。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究评估了多种深度学习模型在分析心电图（ECG）信号方面的能力，旨在识别并区分健康个体、左束支传导阻滞（LBBB）患者和严格左束支传导阻滞（sLBBB）患者。其主要临床意义在于通过改进LBBB的分类精度，为心脏再同步治疗（CRT）的患者选择提供更优支持。

> **摘要翻译:** 本研究探索了不同的神经网络架构，以评估它们从心电图（ECG）信号中提取空间和时间模式的能力，并将信号分为三组：健康受试者、左束支传导阻滞（LBBB）和严格左束支传导阻滞（sLBBB）。临床相关性方面，创新技术通过优化左束支传导阻滞（LBBB）患者的分类，能够帮助选择心脏再同步治疗（CRT）的候选人。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [585] [Physics-guided denoiser network for enhanced additive manufacturing data quality](https://arxiv.org/abs/2508.02712)
> *物理引导去噪网络，用于增强增材制造数据质量*

*Pallock Halder, Satyajit Mojumder* | **Category: eess.SP, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 物理引导, 去噪, 增材制造, 物理信息神经网络, 传感器数据

**Comment:** 28 pages, 13 figures, 5 tables

> **TL;DR:** 提出了一种物理信息去噪框架，结合能量模型和Fisher分数正则化，有效降低传感器数据噪声，提高增材制造数据质量和实时解释能力。

**AI_Comments:** 该论文的创新之处在于将物理信息（通过能量模型、Fisher分数正则化和PINN代理模型）融入到去噪网络中，有效解决了传统数据驱动去噪方法可能缺乏物理一致性的问题。这对于需要高精度和实时决策的工程应用（如增材制造）尤为重要，能够显著提升传感器数据的实用价值和系统的控制能力。

<details>
  <summary>Details</summary>

**Motivation:** 现代工程系统中的传感器数据常伴有噪声且难以解释，限制了其在控制和诊断中的效用。本研究旨在解决增材制造中低成本传感器数据噪声大、难以实时有效利用的问题。

**Method:** 提出了一种物理信息去噪框架，该框架整合了基于能量的模型和Fisher分数正则化，以联合减少数据噪声并强制与物理模型保持物理一致性。该方法首先在基准问题（包括简谐振子、Burgers方程和拉普拉斯方程）上进行了验证，然后应用于激光粉末床熔融（LPBF）增材制造实验的真实热辐射数据，使用经过训练的物理信息神经网络（PINN）代理模型来指导去噪。

**Result:** 所提出的方法优于基线神经网络去噪器，在各种LPBF加工条件下均能有效降低噪声。

**Conclusion:** 这种物理引导的去噪策略能够实现对低成本传感器数据进行鲁棒、实时的解释，从而促进增材制造中的预测控制和改进缺陷缓解。

> **ai_Abstract:** 本研究提出了一种物理信息去噪框架，旨在解决现代工程系统（特别是增材制造）中传感器数据噪声大、难以解释的问题。该框架结合了基于能量的模型和Fisher分数正则化，以同时实现数据去噪和物理一致性。通过在基准问题和激光粉末床熔融（LPBF）增材制造的真实热辐射数据上的验证，结果表明该方法优于传统神经网络去噪器，能有效降低噪声。这使得对低成本传感器数据进行鲁棒、实时的解释成为可能，从而促进增材制造中的预测控制和缺陷缓解。

> **摘要翻译:** 现代工程系统越来越多地配备传感器，用于实时监测和决策。然而，这些传感器收集的数据通常噪声大且难以解释，限制了其在控制和诊断方面的实用性。在这项工作中，我们提出了一种物理信息去噪框架，该框架整合了基于能量的模型和Fisher分数正则化，以联合减少数据噪声并强制与物理模型保持物理一致性。该方法首先在基准问题上进行了验证，包括简谐振子、Burgers方程和拉普拉斯方程，跨越不同的噪声水平。然后，我们将去噪框架应用于激光粉末床熔融（LPBF）增材制造实验的真实热辐射数据，使用经过训练的物理信息神经网络（PINN）代理模型来指导去噪。结果表明，所提出的方法优于基线神经网络去噪器，在各种LPBF加工条件下均能有效降低噪声。这种物理引导的去噪策略能够对低成本传感器数据进行鲁棒、实时的解释，从而促进增材制造中的预测控制和改进缺陷缓解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [610] [SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG](https://arxiv.org/abs/2508.02718)
> *SleepLiteCNN：基于单导联心电图的1秒分辨率节能睡眠呼吸暂停亚型分类*

*Zahra Mohammadi, Siamak Mohammadi* | **Category: eess.SP, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 睡眠呼吸暂停, 亚型分类, 节能, 卷积神经网络, 单导联ECG

**Comment:** 

> **TL;DR:** SleepLiteCNN是一种节能的卷积神经网络，利用单导联心电图实现高精度、1秒分辨率的睡眠呼吸暂停亚型分类，适用于可穿戴设备。

**AI_Comments:** SleepLiteCNN的创新之处在于其针对可穿戴设备进行了优化，在实现高精度的同时，显著降低了能耗和硬件资源占用。这种结合高时间分辨率（1秒）、单导联ECG输入以及极低功耗的特性，使其在实际应用中具有重要价值，尤其是在需要长时间连续监测的医疗健康领域。

<details>
  <summary>Details</summary>

**Motivation:** 准确、高时间分辨率地检测睡眠呼吸暂停亚型对于有效治疗和管理至关重要，尤其是在可穿戴设备需要实时监测的场景下。

**Method:** 该研究评估了多种经典机器学习算法和深度学习架构在1秒ECG窗口上的表现，并在此基础上提出了SleepLiteCNN，一个紧凑且节能的卷积神经网络。通过8位量化和FPGA综合进一步优化和验证。

**Result:** SleepLiteCNN实现了超过95%的准确率和92%的宏观F1分数，每次推理仅需1.8微焦耳（8位量化后）。FPGA综合显示硬件资源显著减少。

**Conclusion:** SleepLiteCNN被证实是一种实用且有效的解决方案，适用于可穿戴设备中的睡眠呼吸暂停亚型检测，尤其是在能源受限的环境中。

> **ai_Abstract:** 本文提出了SleepLiteCNN，一种专为可穿戴设备设计的节能卷积神经网络，用于基于单导联心电图以1秒分辨率对阻塞性、中枢性和混合性睡眠呼吸暂停亚型进行高精度分类。该方法通过评估多种机器学习和深度学习模型后优化得出，实现了95%以上的准确率和92%的宏观F1分数，并且在8位量化后每次推理能耗极低，仅为1.8微焦耳。FPGA综合结果进一步验证了其在硬件资源和能源效率方面的优势，使其成为可穿戴设备实时监测睡眠呼吸暂停的理想方案。

> **摘要翻译:** 呼吸暂停是一种常见的睡眠障碍，其特征是呼吸中断至少持续十秒，每小时发生超过五次。准确、高时间分辨率地检测睡眠呼吸暂停亚型——阻塞性、中枢性和混合性——对于有效的治疗和管理至关重要。本文提出了一种节能方法，利用单导联心电图（ECG）以高时间分辨率对这些亚型进行分类，以满足可穿戴设备的实时需求。我们评估了1秒ECG窗口上各种经典机器学习算法和深度学习架构的准确性、复杂性和能耗。在此分析的基础上，我们引入了SleepLiteCNN，这是一种专门为可穿戴平台设计的紧凑型节能卷积神经网络。SleepLiteCNN实现了超过95%的准确率和92%的宏观F1分数，而8位量化后每次推理仅需1.8微焦耳。现场可编程门阵列（FPGA）综合进一步证明了硬件资源的大幅减少，证实了其适用于能源受限环境中的连续、实时监测。这些结果确立了SleepLiteCNN作为可穿戴设备睡眠呼吸暂停亚型检测的实用且有效解决方案。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [620] [Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition](https://arxiv.org/abs/2508.02847)
> *将机器学习与多模态监测系统相结合，利用声学和视觉传感评估激光定向能量沉积中的几何变化*

*Ke Xu, Chaitanya Krishna Prasad Vallabh, Souran Manoochehri* | **Category: eess.SP, cs.SY, eess.IV, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 激光定向能量沉积, 多模态监测, 机器学习, 几何变化, 声发射, 机器视觉

**Comment:** 

> **TL;DR:** 本研究开发了一种结合声学和视觉传感的多模态监测系统，并利用机器学习评估激光定向能量沉积（DED）部件的几何变化，实现了94.4%的分类准确率。

**AI_Comments:** 本研究的创新点在于将声学和视觉两种不同模态的传感数据与机器学习相结合，用于实时监测和评估DED过程中的几何变化，这对于提升增材制造的质量控制具有重要意义。其多模态融合策略显著提高了识别精度，为未来智能制造和质量保障提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 激光定向能量沉积（DED）增材制造由于熔池动力学复杂和工艺变化，零件质量一致性差。现有研究多集中于缺陷检测，而很少有工作验证工艺监测系统来评估熔池动力学和工艺质量。

**Method:** 本研究提出了一种新型多模态监测框架，将接触式声发射（AE）传感与同轴相机视觉相结合，用于逐层识别和评估DED零件的几何变化。实验使用三种零件配置（无孔、3mm通孔、5mm通孔）进行测试。原始传感器数据经过预处理：声学信号进行时域和频域特征提取，相机数据进行熔池分割和形态特征提取。多种机器学习算法（包括SVM、随机森林和XGBoost）被评估以找到最佳模型来分类逐层几何变化。

**Result:** 集成的多模态策略实现了94.4%的卓越分类性能，而仅使用AE的性能为87.8%，仅使用相机的性能为86.7%。验证证实，集成系统能有效捕获与几何变化相关的结构振动特征和表面形态变化。

**Conclusion:** 本研究证明了集成多模态监测系统结合机器学习能有效识别DED部件的几何变化。尽管本研究侧重于特定几何形状，但其区分特征的能力为未来表征零件变化（如几何不准确和制造缺陷）的应用奠定了技术基础。

> **ai_Abstract:** 本研究针对激光定向能量沉积（DED）增材制造中零件质量一致性差的问题，提出了一种创新的多模态监测框架。该框架结合了声发射（AE）传感和同轴相机视觉，并利用多种机器学习算法（如SVM、随机森林、XGBoost）对DED零件的逐层几何变化进行识别和评估。实验结果表明，该集成系统在分类几何变化方面取得了94.4%的优异性能，显著优于单一传感模式。这为未来DED零件的质量控制和缺陷表征奠定了技术基础。

> **摘要翻译:** 激光定向能量沉积（DED）增材制造由于复杂的熔池动力学和工艺变化，难以保持零件质量的一致性。尽管许多研究致力于缺陷检测，但很少有工作验证工艺监测系统用于评估熔池动力学和工艺质量。本研究提出了一种新颖的多模态监测框架，协同整合了基于接触的声发射（AE）传感与同轴相机视觉，以实现DED零件几何变化的逐层识别和评估。实验研究使用了三种零件配置：一个没有孔的基线零件、一个带有3毫米直径通孔的零件和一个带有5毫米通孔的零件，以测试系统的识别能力。原始传感器数据经过预处理：声学信号经过滤波以进行时域和频域特征提取，而相机数据则进行了熔池分割和形态特征提取。评估了多种机器学习算法（包括支持向量机、随机森林和XGBoost），以找到用于分类逐层几何变化的最佳模型。集成的多模态策略实现了94.4%的卓越分类性能，而仅使用AE的性能为87.8%，仅使用相机的性能为86.7%。验证证实，集成系统能有效捕获与几何变化相关的结构振动特征和表面形态变化。尽管本研究侧重于特定几何形状，但所展示的区分特征的能力为未来在表征零件变化（如几何不准确和制造缺陷）方面的应用奠定了技术基础。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [638] [Can Large Language Models Identify Materials from Radar Signals?](https://arxiv.org/abs/2508.03120)
> *大型语言模型能否从雷达信号中识别材料？*

*Jiangyou Zhu, Hongyu Deng, He Chen* | **Category: eess.SP, cs.ET, cs.RO** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 雷达信号, 材料识别, 开放集识别, 检索增强生成

**Comment:** 

> **TL;DR:** 首次研究利用LLM直接从雷达信号识别材料，通过物理信息信号处理和RAG策略实现开放集识别。

**AI_Comments:** 该研究具有创新性，首次探索了LLM在雷达信号材料识别领域的应用，突破了传统方法的封闭集限制。通过结合物理信息信号处理和RAG策略，有效解决了LLM缺乏雷达领域知识和雷达数据冗余的问题。这为AI机器人实现更高级的上下文感知操作提供了新的可能性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于雷达的材料识别方案通常受限于封闭集对象类别，并需要任务特定的数据收集来训练深度学习模型，这极大地限制了它们的实际适用性。因此，提出了一个重要问题：能否利用预训练LLM的强大推理能力直接从原始雷达信号推断材料组成？

**Method:** 本文引入了LLMaterial，这是第一个研究使用LLM直接从雷达信号识别材料的可行性的研究。首先，引入了一个物理信息信号处理管道，将高冗余雷达原始数据提炼成一组紧凑的中间参数。其次，采用检索增强生成（RAG）策略，为LLM提供领域特定知识，使其能够解释和推理提取的中间参数。通过这种集成，LLM能够对压缩的雷达特征进行逐步推理，实现直接从原始雷达信号进行开放集材料识别。

**Result:** 初步结果表明，LLMaterial能够有效区分多种常见材料，凸显了其在实际材料识别应用中的强大潜力。

**Conclusion:** LLMaterial首次证明了利用大型语言模型直接从雷达信号进行开放集材料识别的可行性，并展示了其在现实世界应用中的巨大潜力。

> **ai_Abstract:** 本文提出了LLMaterial，首次探索利用大型语言模型（LLM）直接从原始雷达信号识别材料的可行性。针对雷达信号冗余和LLM缺乏雷达数据先验知识的问题，LLMaterial采用物理信息信号处理管道将原始雷达数据提炼为紧凑的材料特性参数，并结合检索增强生成（RAG）策略为LLM提供领域知识。这种方法使LLM能够对雷达特征进行推理，实现开放集材料识别。初步结果验证了其区分多种常见材料的有效性，展现了在实际应用中的巨大潜力。

> **摘要翻译:** 准确识别物体的材料组成是AI机器人（由大型语言模型驱动）执行上下文感知操作的关键能力。雷达技术为材料识别任务提供了有前景的传感模式。当与深度学习结合时，雷达技术在识别各种物体材料方面展现出强大潜力。然而，现有的基于雷达的解决方案通常受限于封闭集对象类别，并且通常需要任务特定的数据收集来训练深度学习模型，这极大地限制了它们的实际适用性。这提出了一个重要问题：我们能否利用预训练大型语言模型（LLM）强大的推理能力直接从原始雷达信号推断材料组成？回答这个问题并非易事，因为雷达信号固有的冗余性以及预训练LLM在训练期间没有接触过原始雷达数据的事实。为了解决这个问题，我们引入了LLMaterial，这是第一个研究使用LLM直接从雷达信号识别材料的可行性的研究。首先，我们引入了一个物理信息信号处理管道，将高冗余雷达原始数据提炼成一组紧凑的中间参数，这些参数封装了材料的内在特性。其次，我们采用检索增强生成（RAG）策略，为LLM提供领域特定知识，使其能够解释和推理提取的中间参数。利用这种集成，LLM能够对压缩的雷达特征进行逐步推理，实现直接从原始雷达信号进行开放集材料识别。初步结果表明，LLMaterial能够有效区分多种常见材料，凸显了其在实际材料识别应用中的强大潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [649] [Generating Light-based Fingerprints for Indoor Localization](https://arxiv.org/abs/2508.03011)
> *生成基于光的指纹用于室内定位*

*Hsun-Yu Lee, Jie Lin, Fang-Jing Wu* | **Category: eess.SP, cs.RO, I.2.9; C.3** | **Updated: 2025-08-05**

**Keywords:** 室内定位, 可见光通信, 光谱指纹, 数据增强, TabGAN

**Comment:** 5 pages, 12 figures; presented at the 2024 MC & WASN Conference (Best
  Paper Candidate)

> **TL;DR:** 该研究提出了一种基于可见光通信（VLC）和光谱特征的室内定位方法，并利用TabGAN增强训练数据集，将定位误差降低了20%。

**AI_Comments:** 该论文的创新点在于将可见光通信与光谱指纹相结合用于室内定位，并引入了基于GAN的数据增强技术以解决数据稀缺问题。这种方法在提高定位精度的同时，显著降低了数据收集的成本和工作量，为室内定位领域提供了一种有前景的替代方案，特别是在射频技术受限的环境中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的室内定位对于寻路、应急响应、资产跟踪和智能建筑服务至关重要。然而，现有的射频解决方案（如Wi-Fi、RFID、UWB）容易受到多径衰落、干扰和不可控覆盖范围变化的影响。

**Method:** 本文探索了可见光通信（VLC）这一正交模态，并证明了低成本AS7341传感器捕获的光谱特征可以作为鲁棒的位置指纹。提出了一种两阶段框架：(i) 在真实光谱测量数据上训练多层感知器（MLP）；(ii) 使用TabGAN生成的合成样本扩充训练语料库。

**Result:** 扩充后的数据集将平均定位误差从62.9厘米降低到49.3厘米，提升了20%，同时仅需额外5%的数据收集工作。

**Conclusion:** 实验结果证实，基于GAN的数据增强缓解了数据稀缺问题并增强了泛化能力。

> **ai_Abstract:** 本论文提出了一种利用可见光通信（VLC）和低成本AS7341传感器捕获光谱特征进行室内定位的新方法。为解决数据稀缺问题，该研究引入了一个两阶段框架：首先使用真实光谱数据训练多层感知器（MLP），然后利用TabGAN生成合成样本来扩充训练数据集。实验结果表明，这种数据增强方法将平均定位误差从62.9厘米显著降低至49.3厘米，实现了20%的精度提升，且仅需少量额外数据收集工作，有效增强了模型的泛化能力。

> **摘要翻译:** 准确的室内定位是寻路、应急响应、资产跟踪和智能建筑服务等应用的基础。射频解决方案（例如Wi-Fi、RFID、UWB）被广泛采用，但仍然容易受到多径衰落、干扰和不可控覆盖变化的影响。我们探索了一种正交模态——可见光通信（VLC）——并证明了低成本AS7341传感器捕获的光谱特征可以作为鲁棒的位置指纹。我们引入了一个两阶段框架，该框架(i) 在真实光谱测量数据上训练多层感知器（MLP），以及(ii) 使用TabGAN生成的合成样本扩充训练语料库。增强后的数据集将平均定位误差从62.9厘米降低到49.3厘米——提升了20%——同时仅需额外5%的数据收集工作。在U形实验室的42个参考点上获得的实验结果证实，基于GAN的增强缓解了数据稀缺问题并增强了泛化能力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [673] [Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG](https://arxiv.org/abs/2508.03274)
> *研究刹车灯在启动刹车动作中的认知反应*

*Ramaswamy Palaniappan, Surej Mouli, Howard Bowman, Ian McLoughlin* | **Category: eess.SP, cs.ET, cs.HC, cs.IR** | **Updated: 2025-08-05**

**Keywords:** 刹车灯, 脑电图, 认知反应, LED, 驾驶员注意力

**Comment:** arXiv admin note: text overlap with arXiv:2010.10584

> **TL;DR:** 该研究使用脑电图（EEG）评估不同刹车灯设计对驾驶员刹车行为的影响，发现LED刹车灯比白炽灯刹车灯能更快地引发认知反应。

**AI_Comments:** 这项研究利用脑电图（EEG）来评估刹车灯设计对驾驶员行为的影响，这是一个新颖且重要的研究方向。研究结果表明LED刹车灯比白炽灯刹车灯能更快地引起驾驶员的注意并促使他们刹车，这对于提高道路安全具有潜在的应用价值。然而，研究中提到的“大量的运动伪影”可能会影响结果的准确性，未来需要更先进的技术来克服这一挑战。此外，研究样本量（22名受试者）和刹车灯设计的数量（8种LED，2种白炽灯）也可能限制了结果的普适性。尽管存在这些局限性，这项研究为理解和优化车辆安全设计提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 道路事故中近一半是由于驾驶员注意力不集中或车距不足造成的，而后方碰撞是最常见的事故类型。刹车灯是提醒后方驾驶员减速或刹车的主要机制。

**Method:** 研究人员在模拟驾驶环境中，使用脑电图（EEG）记录了22名受试者对不同刹车灯设计（包括LED和白炽灯）的反应。通过分析Pz通道的P3成分来评估驾驶员在决定刹车时的认知反应时间。

**Result:** 研究结果显示，白炽灯刹车灯引发认知反应的时间比所有测试的LED刹车灯都要慢。虽然LED设计之间也存在差异，但由于脑电图信号中的运动伪影，这些差异并未达到统计学上的显著性。

**Conclusion:** LED刹车灯在引发驾驶员刹车动作的认知反应方面优于白炽灯刹车灯。

> **ai_Abstract:** 本研究利用脑电图（EEG）技术，通过分析P3成分来量化驾驶员对不同刹车灯设计的认知反应。研究在模拟驾驶环境中测试了LED和白炽灯刹车灯，结果表明LED刹车灯能够更快地引发驾驶员的刹车决策，从而可能减少追尾事故的发生。

> **摘要翻译:** 一半的道路事故是由于驾驶员缺乏注意力或车辆间距不足造成的。追尾碰撞尤其被认为是英国最常见的事故类别，其影响因素已被研究多年。后置刹车灯在刹车时点亮，是提醒后方驾驶员减速或刹车的主要机制。本文开发了一种新颖的脑反应方法来测量受试者对不同刹车灯设计的反应。在一项物理模拟驾驶环境中，对22名受试者进行了评估，记录了他们的认知反应时间。测试了八种LED刹车灯和两种白炽灯刹车灯。利用Pz通道提取的P3成分来评估受试者在决定抬起油门踏板并踩下刹车踏板时大脑决策过程中的成分。脑电图分析表明，白炽灯刹车灯引发认知反应的时间比所有测试的LED刹车灯都要慢。在LED设计之间也存在差异，但由于脑电图信号中存在大量的运动伪影，这些差异并未达到统计学上的显著性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [738] [An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method](https://arxiv.org/abs/2508.02687)
> *一种由AI驱动的EDA算法赋能的VCO和LDO协同设计方法*

*Yijia Hao, Maarten Strackx, Miguel Gandara, Sandy Cochran, Bo Liu* | **Category: eess.SP** | **Updated: 2025-07-23**

**Keywords:** AI驱动EDA算法, VCO, LDO, 协同设计, 相位噪声

**Comment:** 

> **TL;DR:** 提出了一种AI驱动的EDA算法，用于VCO和LDO的协同设计，以解决传统顺序设计方法在优化低频相位噪声和LDO引起的噪声之间的权衡问题。

**AI_Comments:** 该研究提出了一种新颖的AI驱动EDA算法，用于VCO和LDO的协同设计，解决了传统方法在处理噪声权衡方面的局限性。其在改善相位噪声和降低功耗方面取得了显著成果，为集成电路设计提供了有价值的见解。然而，该算法的通用性和在不同工艺节点下的性能仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统LDO和VCO的顺序设计方法未能充分解决高频相位噪声和LDO引起的低频相位噪声之间的权衡问题。

**Method:** 提出了一种AI驱动的EDA算法，用于低相位噪声LC- tanque VCO和LDO的协同设计。

**Result:** 与传统顺序设计方法相比，该协同设计方法将相位噪声提高了1.2 dB（在1 MHz偏移处），将动态功耗降低了28.8%，FoM提高了2.4 dBc/Hz。

**Conclusion:** AI驱动的EDA算法能够有效地实现VCO和LDO的协同设计，从而改善相位噪声并降低功耗。

> **ai_Abstract:** 本研究提出了一种创新的AI驱动EDA算法，用于压控振荡器（VCO）和低压差线性稳压器（LDO）的协同设计。与传统的顺序设计方法相比，该方法有效解决了在优化低频相位噪声和LDO引起的噪声之间的权衡问题。通过一个5.6 GHz LC- tanque VCO与集成LDO的设计实例，仿真结果表明，该方法在1 MHz偏移处将相位噪声提高了1.2 dB，降低了28.8%的动态功耗，并使FoM提高了2.4 dBc/Hz。

> **摘要翻译:** 传统上，低压差线性稳压器（LDO）的输出噪声和电源抑制被优化以最小化电源波动，从而减少它们对目标压控振荡器（VCO）的低频噪声的影响。然而，这种顺序设计方法未能充分解决高频噪声和LDO引起的低频相位噪声之间的权衡问题。为了克服这一限制，本文提出了一种低相位噪声LC- tanque VCO与LDO的协同设计方法。使用传统的手动设计技术很难进行协同设计。因此，采用了一种高效的AI驱动EDA算法。为了验证所提出的方法，采用65 nm CMOS工艺设计了一个集成LDO的5.6 GHz LC- tanque VCO。仿真表明，与传统的顺序设计方法相比，协同设计方法将1 MHz偏移处的相位噪声提高了1.2 dB，将动态功耗降低了28.8%，FoM提高了2.4 dBc/Hz。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [781] [On Improving PPG-Based Sleep Staging: A Pilot Study](https://arxiv.org/abs/2508.02689)
> *关于改进基于PPG的睡眠分期：一项初步研究*

*Jiawei Wang, Yu Guan, Chen Chen, Ligang Zhou, Laurence T. Yang, Sai Gu* | **Category: eess.SP, cs.LG** | **Updated: 2025-07-23**

**Keywords:** PPG, 睡眠分期, 双流交叉注意力, 可穿戴技术, MESA数据集

**Comment:** 

> **TL;DR:** 该研究通过结合PPG及其辅助信息，并采用双流交叉注意力架构，显著提高了基于PPG的睡眠分期性能。

**AI_Comments:** 该研究为利用PPG信号进行睡眠分期提供了有价值的见解，特别是双流交叉注意力架构的潜力。然而，其“初步研究”的性质意味着需要进一步验证其在更广泛数据集和不同人群中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 可穿戴设备中的PPG传感器虽被广泛采用，但仅凭PPG实现可靠的睡眠分期仍具挑战性，本研究旨在探索提升PPG睡眠分期性能的策略。

**Method:** 比较了传统的单流模型与基于PPG和PPG衍生模态（如增强PPG或合成ECG）的双流交叉注意力策略，并在MESA数据集上进行了四阶段睡眠监测任务的实验。

**Result:** 结合PPG及其辅助信息，在双流交叉注意力架构下，实现了显著的性能提升。

**Conclusion:** 双流交叉注意力架构结合PPG及其辅助信息，能够有效提升睡眠分期性能。

> **ai_Abstract:** 本研究旨在通过探索多种策略来提高基于PPG的睡眠分期性能。研究比较了传统的单流模型与双流交叉注意力策略，该策略利用PPG及其衍生模态（如增强PPG或合成ECG）来学习互补信息。在MESA数据集上进行的实验表明，双流交叉注意力架构结合PPG及其辅助信息可显著提升睡眠分期性能。

> **摘要翻译:** 通过可穿戴技术进行睡眠监测对于改善普遍存在的计算中的福祉至关重要。尽管光电容积脉搏波（PPG）传感器已广泛应用于消费设备，但仅依靠PPG实现持续可靠的睡眠分期仍然是一个非平凡的挑战。在本研究中，我们探索了多种策略来提高基于PPG的睡眠分期性能。具体来说，我们比较了传统的单流模型与双流交叉注意力策略，基于此可以通过PPG和PPG衍生的模态（如增强PPG或合成ECG）学习互补信息。为了研究上述方法在四阶段睡眠监测任务中的有效性，我们在世界上最大的睡眠分期数据集，即动脉粥样硬化多民族研究（MESA）上进行了实验。我们发现，在双流交叉注意力架构下结合PPG及其辅助信息可以实现显著的性能提升。该项目的源代码可在https://github.com/DavyWJW/sleep-staging-models找到。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [797] [Decoding and Engineering the Phytobiome Communication for Smart Agriculture](https://arxiv.org/abs/2508.03584)
> *解码和工程化植物组学通讯以实现智慧农业*

*Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford* | **Category: eess.SP, cs.AI, cs.ET, cs.NI, q-bio.MN** | **Updated: 2025-08-05**

**Keywords:** 植物组学通讯,智慧农业,通信工程,分子通信,电生理信号

**Comment:** Under revision for IEEE Communications Magazine

> **TL;DR:** 该论文提出将通信工程的视角应用于理解和工程化植物组学通讯，以促进智慧农业的发展。研究人员提出了一种多尺度框架来模拟植物组学，并展示了如何利用该框架来模拟植物的电生理信号。此外，还提出了一些利用植物组学通讯的智慧农业应用，例如智能灌溉和农用化学品的靶向输送，并讨论了相关的挑战和未来前景。

**AI_Comments:** 该研究将通信工程的跨学科视角引入植物组学领域，为理解和操纵植物与其环境的相互作用提供了一个新颖的框架。将植物组学视为一个通信网络，并利用ML/AI和物联网技术进行工程化，为实现可持续和高效的农业生产开辟了新的可能性。然而，实际应用中信号传输的复杂性、环境因素的干扰以及数据解读的准确性仍是需要进一步研究的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对日益增长的粮食需求、环境污染和水资源短缺等现代挑战，智慧农业应运而生。该论文旨在利用通信工程的视角来全面理解植物组学通讯，并弥合植物组学通讯与智慧农业之间的差距。

**Method:** 提出了一种将植物组学视为通信网络的宏观框架，并通过植物实验演示了如何利用该框架模拟电生理信号。

**Result:** 展示了如何利用提出的宏观框架模拟电生理信号，并提出了一些利用工程化植物组学通讯的智慧农业应用，例如智能灌溉和农用化学品的靶向输送。

**Conclusion:** 将通信工程的视角应用于植物组学通讯，为实现更高效、可持续和环保的农业生产提供了新的途径，并讨论了相关的挑战和未来前景。

> **ai_Abstract:** 该研究提出了一种将通信工程原理应用于植物组学通讯的方法，旨在促进智慧农业的发展。文章介绍了一个多尺度框架，用于将植物组学建模为通信网络，并通过实验验证了其在模拟植物电生理信号方面的有效性。此外，还探讨了利用该方法在智能灌溉和农用化学品靶向输送等方面的潜在应用，并对相关挑战和未来前景进行了讨论。

> **摘要翻译:** 智慧农业应用，整合了物联网、机器学习/人工智能（ML/AI）等技术，有望解决日益增长的粮食需求、环境污染和水资源短缺等现代挑战。随着植物组学（定义为包括植物、其环境和相关生物的区域）概念以及分子通信（MC）的最新出现，存在着利用通信理论推动农业科学和实践的重要机会。在本文中，我们着重于利用通信工程的视角来全面理解植物组学通讯，并弥合植物组学通讯与智慧农业之间的差距。首先，介绍了通过分子和电生理信号进行植物组学通讯的概述，并概念化了一个将植物组学建模为通信网络的多尺度框架。然后，通过植物实验证明了该框架如何用于模拟电生理信号。此外，还提出了一些可能的智慧农业应用，例如智能灌溉和农用化学品的靶向输送，通过工程化植物组学通讯来实现。这些应用融合了ML/AI方法和由MC支持的生物-纳米-物联网，为更高效、可持续和环保的农业生产铺平了道路。最后，讨论了这些应用的实施挑战、开放性研究问题和产业前景。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [813] [Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction](https://arxiv.org/abs/2508.02724)
> *Veli：低成本空气质量传感器校正的无监督方法和统一基准*

*Yahia Dalbah, Marcel Worring, Yen-Chia Hsu* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 空气质量监测,低成本传感器,无监督学习,变分推断,传感器校正

**Comment:** Main content: 7 pages, 9 Figures, 3 Tables. Appendix: 4 pages, 6
  Figures

> **TL;DR:** Veli是一种无监督贝叶斯模型，利用变分推断来校正低成本空气质量传感器的读数，无需参考站点，并引入了包含23,737个传感器的AQ-SDR基准。

**AI_Comments:** 这项研究通过提出一种无需参考站点即可校正低成本空气质量传感器读数的无监督方法（Veli），并引入了一个大规模的基准数据集（AQ-SDR），解决了空气质量监测领域的一个重要问题。Veli的解耦表示方法和变分推断的应用是该研究的创新之处。然而，该方法在实际部署中的可扩展性和鲁棒性仍需进一步验证。此外，AQ-SDR数据集的公开将对该领域的研究产生重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 城市空气污染是一个严重的健康危机，需要准确可扩展的空气质量监测。低成本传感器（LCS）虽然有潜力，但易受漂移、校准错误和环境干扰的影响。

**Method:** Veli是一种无监督贝叶斯模型，利用变分推断来校正LCS读数，通过构建解耦表示来分离真实污染物读数和传感器噪声。此外，还引入了AQ-SDR，这是迄今为止最大的空气质量传感器基准，包含来自23,737个LCS和参考站点的数据。

**Result:** Veli在同分布和异分布设置中表现出强大的泛化能力，有效处理了传感器漂移和异常行为。

**Conclusion:** Veli通过其无监督方法和AQ-SDR基准，为低成本空气质量传感器校正提供了一个有效的解决方案，克服了部署障碍并解决了标准化基准的缺乏问题。

> **ai_Abstract:** Veli是一种新颖的无监督贝叶斯模型，通过变分推断校正低成本空气质量传感器的读数，无需参考站点，从而解决了准确、可扩展的空气质量监测的关键挑战。该研究还引入了AQ-SDR，这是最大的空气质量传感器基准，包含来自23,737个传感器的数据，为模型评估和未来研究提供了标准化平台。Veli在各种设置下都表现出强大的泛化能力，有效地处理了传感器漂移和异常行为。

> **摘要翻译:** 城市空气污染是一个重大的健康危机，每年导致数百万人过早死亡，这凸显了对空气质量（AQ）进行准确和可扩展监测的迫切需求。虽然低成本传感器（LCS）提供了比昂贵的参考级站点更具可扩展性的替代方案，但它们的读数受到漂移、校准错误和环境干扰的影响。为了应对这些挑战，我们引入了Veli（通过潜在推理进行的无参考变分估计），这是一种无监督的贝叶斯模型，它利用变分推断来校正LCS读数，而无需与参考站点进行共同定位，从而消除了主要的部署障碍。具体来说，Veli构建了LCS读数的解耦表示，有效地将真实的污染物读数与传感器噪声分离开来。为了构建我们的模型并解决AQ监测中标准化基准的缺乏问题，我们还引入了空气质量传感器数据存储库（AQ-SDR）。AQ-SDR是迄今为止最大的AQ传感器基准，包含来自多个地区23,737个LCS和参考站点的数据。Veli在同分布和异分布设置中均表现出强大的泛化能力，能有效处理传感器漂移和异常的传感器行为。模型和数据集的代码将在论文发表时公开。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [822] [Federated Learning in Active STARS-Aided Uplink Networks](https://arxiv.org/abs/2508.02693)
> *联邦学习在主动 STARS 辅助的上行链路网络中*

*Xinwei Yue, Xinning Guo, Xidong Mu, Jingjing Zhao, Peng Yang, Junsheng Mu, Zhiping Lu* | **Category: eess.SP** | **Updated: 2025-07-24**

**Keywords:** 联邦学习, 主动同时传输和反射面, 过顶计算, 模型聚合误差, 学习效率

**Comment:** 

> **TL;DR:** 该论文提出了一种利用主动同时传输和反射面（ASTARS）来辅助联邦学习（FL）上行链路模型传输的方法，并通过过顶（OTA）计算技术减少上传参数数量。研究人员分析了模型聚合误差的影响，并推导了OTA-FL模型的聚合误差上限，量化了通信误差导致的训练损失。通过联合优化 ASTARS 的波束赋形和相移，以最大化学习效率和信号传输质量。结果表明，ASTARS 辅助的 FL 上行链路网络比现有网络具有更高的准确性，并且在数据集更离散时，使用更少的有源单元也能获得更好的学习准确性。此外，放大功率越高，FL 准确性越高，但过高的放大功率会导致热噪声成为主要的误差来源。

**AI_Comments:** 该研究将 ASTARS 技术应用于联邦学习的上行链路，通过 OTA 计算减少了通信开销，并在理论和实验上都展示了其优越性。特别是，对模型聚合误差的量化和优化问题的提出，为实际应用提供了指导。然而，对于 ASTARS 的实际部署和成本效益的分析，以及在更复杂的通信环境下的鲁棒性，可以作为未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了利用主动同时传输和反射面（ASTARS）的优势，以辅助联邦学习（FL）的上行链路模型传输，并进一步通过过顶（OTA）计算技术减少上传参数的数量。

**Method:** 利用 ASTARS 辅助联邦学习（FL）的上行链路模型传输，并通过过顶（OTA）计算技术减少上传参数。推导了 OTA-FL 模型的聚合误差上限，并量化了通信误差导致的训练损失。将 OTA-FL 的性能定义为一个联合优化问题，该问题包含接收波束的分配和 ASTARS 的相移，旨在最大化学习效率和高质量的信号传输。

**Result:** i) ASTARS 上行链路网络中的 FL 准确性相比于现有网络有所提高；ii) ASTARS 赋能的 FL 系统，即使使用更少的有源单元，也能获得更好的学习准确性，尤其是在数据集更离散的情况下；iii) FL 准确性随放大功率的提高而提高，但过高的放大功率会导致热噪声成为主要的误差来源。

**Conclusion:** ASTARS 技术能够有效地辅助联邦学习的上行链路模型传输，通过优化波束赋形和相移，可以实现更高的学习效率和信号传输质量。ASTARS 相比现有网络具有优势，尤其是在数据集离散的情况下，并且放大功率对准确性有积极影响，但需注意避免过高的放大功率引入过多的热噪声。

> **ai_Abstract:** 本文提出利用主动同时传输和反射面（ASTARS）技术辅助联邦学习（FL）上行链路模型传输，并通过过顶（OTA）计算减少参数上传量。研究量化了模型聚合误差和通信误差对训练损失的影响，并通过联合优化 ASTARS 的波束赋形和相移来最大化学习效率。结果显示，ASTARS 辅助的 FL 系统在准确性和效率上优于现有方法，尤其是在数据集离散的情况下，并且放大功率对性能有积极影响，但需注意热噪声的限制。

> **摘要翻译:** 主动同时传输和反射面（ASTARS）因其能够缓解乘性衰落和重塑整个空间中的电磁环境而引起了日益增长的研究兴趣。在本文中，我们利用 ASTARS 来辅助联邦学习（FL）的上行链路模型传输，并通过过顶（OTA）计算技术进一步减少上传的参数数量。我们对模型聚合误差对 ASTARS 辅助的 FL 上行链路网络的影响进行了表征。我们推导了 OTA-FL 模型的聚合误差上限，并量化了由于通信误差导致的训练损失。然后，我们将 OTA-FL 的性能定义为一个联合优化问题，该问题包含了接收波束的分配和 ASTARS 的相移，旨在实现最大的学习效率和高质量的信号传输。数值结果表明：i）与现有网络相比，ASTARS 上行链路网络中的 FL 准确性得到了提高；ii）ASTARS 赋能的 FL 系统使用比其他基线更少的有源单元实现了更好的学习准确性，尤其是在数据集更离散时；iii）FL 准确性随放大功率的提高而提高，但过高的放大功率会使热噪声成为误差的主要来源。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [866] [A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting](https://arxiv.org/abs/2508.02698)
> *一种用于OFDM的盲信道估计技术，通过星座分裂实现*

*Sameera Bharadwaja H., D. K. Mehra* | **Category: eess.SP** | **Updated: 2025-07-27**

**Keywords:** OFDM,盲信道估计,星座分裂,二阶统计量,非冗余预编码

**Comment:** 

> **TL;DR:** 该论文提出了一种新的盲信道估计算法，用于解决OFDM系统中基于二阶统计量（SOS）的估计模糊问题，无需导频或参考符号，性能与半盲方法相当。

**AI_Comments:** 该方法在无需导频的情况下解决了OFDM盲信道估计中的关键模糊问题，具有实际应用价值。然而，其在不同M值（调制阶数）下的具体性能表现以及对不同噪声环境的鲁棒性有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有SOS类盲信道估计方法存在的复杂标量估计模糊问题，该问题通常需要导频或参考符号来解决。

**Method:** 提出一种利用频域线性非冗余预编码和交替子载波星座分裂的算法来解决估计模糊问题。

**Result:** 仿真结果表明，该方法在M-PSK系统中性能与半盲方法相当。

**Conclusion:** 提出的盲信道估计算法能够有效解决SOS类方法的估计模糊问题，并且在性能上能达到半盲方法的水平。

> **ai_Abstract:** 本研究提出了一种新颖的OFDM盲信道估计技术，通过频域线性非冗余预编码和星座分裂来解决现有SOS类方法中的复杂标量估计模糊问题，无需额外的导频或参考符号，并在M-PSK系统中实现了与半盲方法相当的性能。

> **摘要翻译:** 本文解决了OFDM系统中基于二阶统计量（SOS）的盲信道估计问题。迄今为止提出的几乎所有SOS类方法都存在一个复杂的标量估计模糊问题，该问题通过使用导频或参考符号来解决。我们提出了一种算法，通过使用频域线性非冗余预编码和交替子载波上的星座分裂来以盲方式解决此模糊问题。通过在MATLAB环境中进行数值模拟评估了所提出方案的性能。仿真结果表明，所提出的方法在M-PSK系统中性能与半盲方法相当。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [871] [AI-driven Wireless Positioning: Fundamentals, Standards, State-of-the-art, and Challenges](https://arxiv.org/abs/2501.14970)
> *人工智能驱动的无线定位：基础、标准、最新进展和挑战*

*Guangjin Pan, Yuan Gao, Yilin Gao, Wenjun Yu, Zhiyong Zhong, Xiaoyu Yang, Xinyu Guo, Shugong Xu* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 无线定位,人工智能,蜂窝定位,3GPP标准,机器学习

**Comment:** 37 pages. This work has been submitted to the IEEE for possible
  publication

> **TL;DR:** 该论文全面概述了人工智能（AI）驱动的蜂窝定位技术，重点介绍了其在3GPP标准中的演变、当前的研究进展（包括AI辅助和直接AI方法）以及面临的挑战和机遇。

**AI_Comments:** 这篇论文对AI驱动的无线定位领域进行了全面的概述，涵盖了从基础知识、标准演进到最新的研究进展和挑战。文章结构清晰，分类明确，对于理解该领域的发展脉络和前沿方向非常有帮助。特别的是，它紧密结合了3GPP标准，这对于推动实际应用具有重要意义。然而，论文可能更侧重于综述和分类，对某些具体算法的深入分析和创新性提出可能有所不足。

<details>
  <summary>Details</summary>

**Motivation:** 无线定位技术在自动驾驶、扩展现实（XR）和无人机（UAV）等应用中具有重要价值。利用AI增强定位精度和鲁棒性是一个充满潜力的领域，尤其是在3GPP标准的要求和功能驱动下，AI/ML已成为克服传统方法局限性的关键技术。

**Method:** 该论文首先回顾了无线定位和AI模型的基础知识，分析了它们的挑战和协同作用。接着，全面审查了3GPP定位标准的演变，重点关注AI/ML在当前和未来标准版本中的集成。论文根据3GPP定义的分类，将最新的研究分为两大类：AI/ML辅助定位（包括视线/非视线检测、到达时间/到达时间差估计和角度预测）和直接AI/ML定位（包括指纹识别、知识辅助学习和信道映射）。此外，还回顾了代表性的公共数据集，并使用这些数据集对AI定位算法进行了性能评估。

**Result:** 论文对AI/ML辅助定位和直接AI/ML定位的最新研究进行了分类和总结，并回顾了公共数据集和AI定位算法的性能评估。

**Conclusion:** AI驱动的无线定位技术在克服传统定位方法的局限性方面展现出巨大潜力，并在3GPP标准的推动下不断发展。未来的研究需要解决现有挑战并抓住机遇，以进一步推动该领域的发展。

> **ai_Abstract:** 本篇综述全面探讨了人工智能（AI）驱动的无线定位技术，特别是其在蜂窝网络中的应用。文章首先介绍了无线定位和AI模型的基础知识及其面临的挑战，随后重点阐述了3GPP标准中AI/ML的集成演进。接着，论文根据3GPP的分类，对AI/ML辅助定位（如LOS/NLOS检测、TOA/TDOA估计）和直接AI/ML定位（如指纹识别、信道映射）等最新研究进行了梳理和总结。此外，还对相关公共数据集和AI定位算法的性能进行了评估。最后，文章指出了AI驱动无线定位所面临的挑战与机遇。

> **摘要翻译:** 无线定位技术在自动驾驶、扩展现实（XR）、无人机（UAV）等应用中具有重要价值。随着人工智能（AI）的发展，利用AI提高定位精度和鲁棒性已成为一个充满潜力的领域。在第三代合作伙伴项目（3GPP）标准定义的と要件和功能驱动下，基于AI/机器学习（ML）的蜂窝定位正成为克服传统方法局限性的关键技术。本文全面介绍了AI驱动的蜂窝定位。我们首先回顾了无线定位和AI模型的基础知识，分析了各自的挑战和协同作用。我们全面回顾了3GPP定位标准的演变，重点关注AI/ML在当前和未来标准版本中的集成。在3GPP定义的分类的指导下，我们将最新的研究分为两大类：AI/ML辅助定位和直接AI/ML定位。前者包括视线（LOS）/非视线（NLOS）检测、到达时间（TOA）/到达时间差（TDOA）估计和角度预测；后者包括指纹识别、知识辅助学习和信道映射。此外，我们还回顾了代表性的公共数据集，并使用这些数据集对AI定位算法进行了性能评估。最后，我们总结了AI驱动的无线定位的挑战和机遇。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [912] [Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations](https://arxiv.org/abs/2508.02703)
> *测量生物信号之间的时间自监督依赖性及其局限性*

*Evangelos Sariyanidi, John D. Herrington, Lisa Yankowitz, Pratik Chaudhari, Theodore D. Satterthwaite, Casey J. Zampella, Robert T. Schultz, Russell T. Shinohara, Birkan Tunc* | **Category: eess.SP, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 自监督学习, 生物信号, 依赖性测量, 非线性相互作用, concurrence

**Comment:** To be submitted to NeurIPS 2025 AI for Science Workshop

> **TL;DR:** 提出了一种名为concurrence的自监督方法，用于在没有先验知识的情况下测量生物信号之间的非线性依赖性，并在fMRI、生理和行为信号上进行了实验验证，但仍存在由外部因素引起的依赖性问题。

**AI_Comments:** 该研究提出了一种新颖的自监督方法来解决生物信号依赖性测量中的一个重要挑战，即捕捉非线性相互作用。该方法在多种生物信号类型上的有效性以及无需先验知识的特点使其具有广泛的应用前景。然而，论文也坦诚地指出了由外部因素引起的依赖性问题，并强调了对结果进行验证的重要性，这体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测量生物信号之间统计依赖性的方法难以捕捉复杂的非线性相互作用，需要先验知识。

**Method:** 提出了一种名为concurrence的自监督方法，该方法基于一个假设：如果两个信号相关，那么应该能够区分它们之间的时间对齐和未对齐片段。

**Result:** concurrence是在fMRI、生理和行为信号上进行实验的第一个能够暴露广泛信号关系并提取科学相关差异的方法，且无需进行自适应参数调整或依赖先验信息。

**Conclusion:** concurrence是一种强大的工具，可以促进跨领域的科学发现，但研究人员仍需验证所揭示的关系是否真正与研究问题相关，因为由外部因素引起的依赖性问题尚未解决。

> **ai_Abstract:** 本文提出了一种名为concurrence的自监督方法，用于测量生物信号之间的非线性依赖性。该方法通过区分时间对齐和未对齐的信号片段来工作，并在fMRI、生理和行为数据上显示出有效性，无需先验知识或参数调整。尽管该方法能够揭示广泛的信号关系，但由外部因素引起的依赖性仍是未来研究的挑战。

> **摘要翻译:** 测量观察信号之间的统计依赖性是科学发现的主要工具。然而，生物系统通常表现出复杂的非线性相互作用，目前在没有关于依赖性性质的先验知识的情况下无法捕捉。我们提出了一种名为concurrence的自监督方法，其灵感来自于一个观察：如果两个信号是相关的，那么应该能够区分从它们中提取的时间对齐与未对齐片段。fMRI、生理和行为信号的实验表明，据我们所知，concurrence是第一个能够在如此广泛的信号谱上暴露关系并提取科学相关差异的方法，而无需进行自适应参数调整或依赖先验信息，为跨领域的科学发现提供了有力的工具。然而，由外部因素引起的依赖性仍然是一个公开的问题，因此研究人员应验证所暴露的关系是否真正与研究问题相关。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [956] [Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach](https://arxiv.org/abs/2508.02713)
> *用户中心网络大规模MIMO的预编码器设计：一种辛优化方法*

*Pengxu Lin, An-An Lu, Xiqi Gao* | **Category: eess.SP** | **Updated: 2025-07-31**

**Keywords:** 辛优化,预编码器设计,用户中心网络,大规模MIMO,加权和速率

**Comment:** 

> **TL;DR:** 该研究提出了一种基于辛优化的预编码器设计方法，用于解决用户中心网络（UCN）大规模MIMO系统中的计算复杂性问题，通过将优化问题转化为耗散哈密顿动力学系统来避免矩阵求逆，并取得了比传统WMMSE预编码器更优的性能。

**AI_Comments:** 该研究在处理大规模MIMO系统中的预编码器设计问题上提出了一个创新的辛优化方法，有效地解决了传统方法中的计算复杂度瓶颈。将物理动力学系统理论应用于通信系统优化是一个有前景的方向，尤其是在处理高维度问题时。然而，该方法在实际部署中的鲁棒性、对不同信道条件和系统参数变化的适应性以及与现有硬件的兼容性仍需进一步评估。

<details>
  <summary>Details</summary>

**Motivation:** 传统的线性预编码器在用户中心网络（UCN）大规模MIMO系统中存在计算复杂度高的问题，主要是由于需要进行矩阵求逆。

**Method:** 提出了一种基于辛优化框架的预编码器设计方法，将加权和速率（WSR）最大化问题转化为一个基于耗散哈密顿动力学系统的优化问题。通过将目标函数视为势能，利用能量耗散系统收敛到最小势能状态的特性，并将连续系统离散化以获得迭代的预编码器设计方法，从而避免了矩阵求逆。

**Result:** 所提出的基于辛优化的预编码器设计方法在UCN大规模MIMO系统中，其性能优于加权最小均方误差（WMMSE）预编码器。

**Conclusion:** 基于辛优化的预编码器设计方法能够有效降低UCN大规模MIMO系统的计算复杂度，并实现比现有方法更优的性能。

> **ai_Abstract:** 本研究提出了一种新颖的基于辛优化的预编码器设计方法，用于解决用户中心网络（UCN）大规模MIMO系统中的计算挑战。该方法通过将加权和速率（WSR）最大化问题转化为一个由耗散哈密顿动力学系统驱动的优化问题，从而有效避免了传统方法中计算量大的矩阵求逆步骤。通过将优化目标函数视为势能，并利用系统能量耗散的特性，该方法能够收敛到最优解。通过对连续系统进行离散化处理，研究人员获得了一种高效的迭代式预编码器设计算法。仿真结果证实，该辛优化方法在UCN大规模MIMO场景下，相比于加权最小均方误差（WMMSE）预编码器，能够实现更优的系统性能，并具有更高的计算效率。

> **摘要翻译:** 在本论文中，我们利用辛优化为用户中心网络（UCN）大规模多输入多输出（MIMO）系统设计预编码器，其中一部分基站（BS）服务于每个用户终端（UT），而不是使用所有基站。在UCN大规模MIMO系统中，与传统网络大规模MIMO相比，预编码器的维度减小了。这简化了预编码器在实际系统中的实现。然而，传统线性预编码器中的矩阵求逆仍然需要很高的计算复杂度。为了避免矩阵求逆，我们采用了辛优化框架，其中优化问题基于耗散哈密顿动力学系统求解。为了更好地适应辛优化，我们将接收模型转换到实数域，并重新表述了加权和速率（WSR）最大化问题。将优化问题的目标函数视为动力系统的势能。由于能量耗散，连续动力系统总是收敛到势能最小的状态。通过在保持辛结构的同时对连续系统进行离散化，我们得到了一个用于预编码器设计的迭代方法。还提供了所提出的辛方法的复杂度分析，以显示其高计算效率。仿真结果表明，所提出的基于辛优化的预编码器设计在UCN大规模MIMO系统中优于加权最小均方误差（WMMSE）预编码器。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [9] [Semi-Data-Driven Model Predictive Control: A Physics-Informed Data-Driven Control Approach](https://arxiv.org/abs/2504.00746)
> *半数据驱动模型预测控制：一种物理信息数据驱动控制方法*

*Sebastian Zieglmeier, Mathias Hudoba de Badyn, Narada D. Warakagoda, Thomas R. Krogstad, Paal Engelstad* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 半数据驱动控制, 模型预测控制, 数据使能预测控制, 鲁棒性, 物理信息

**Comment:** 8 pages, 5 figures

> **TL;DR:** 提出了一种半数据驱动模型预测控制（SD-MPC）框架，结合有限模型信息与DeePC，以提高在未捕获运行状态下的鲁棒性，克服纯数据驱动方法的缺点。

**AI_Comments:** 这篇论文通过引入有限的物理模型信息来增强纯数据驱动控制的鲁棒性，特别是在数据稀疏或噪声环境下。这种半数据驱动的方法是数据驱动控制领域一个重要的发展方向，它结合了传统模型方法的优点，弥补了纯数据驱动方法的不足，具有较高的实用价值和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据使能预测控制（DeePC）虽然强大，但纯粹依赖离线数据轨迹来表示系统动力学存在缺点，如对噪声数据敏感和缺乏鲁棒性，尤其是在未被离线数据捕获的运行状态下表现不佳。

**Method:** 提出了半数据驱动模型预测控制（SD-MPC）框架，该框架将有限的模型信息与DeePC相结合。通过引入底层参数模型来解决纯数据驱动DeePC的缺点。

**Result:** SD-MPC在确定性线性时不变系统上表现出与DeePC等效的闭环性能。仿真结果表明，SD-MPC在线性时不变系统和非线性系统（建模为线性参数变化系统）中均表现出良好的通用控制性能。这些结果提供了SD-MPC比经典DeePC增强鲁棒性的数值证据。

**Conclusion:** SD-MPC通过结合有限模型信息，有效克服了纯数据驱动DeePC的缺点，特别是在提高鲁棒性方面表现出色，并在不同系统类型中展示了良好的控制性能。

> **ai_Abstract:** 本文提出了一种新颖的半数据驱动模型预测控制（SD-MPC）框架，旨在解决纯数据驱动预测控制（DeePC）在应对噪声数据和缺乏鲁棒性方面的缺点，尤其是在数据未覆盖的操作区域。SD-MPC通过将有限的模型信息与DeePC相结合，有效提升了控制系统的鲁棒性。仿真结果表明，SD-MPC在多种系统类型中均表现出与DeePC相当或更优的控制性能和显著增强的鲁棒性。

> **摘要翻译:** 数据使能预测控制（DeePC）已成为一种强大的技术，无需大量建模工作即可控制复杂系统。然而，仅依靠离线收集的数据轨迹来表示系统动力学存在某些缺点。因此，我们提出了一种新颖的半数据驱动模型预测控制（SD-MPC）框架，该框架将（有限的）模型信息与DeePC相结合，以解决一系列这些缺点，包括对噪声数据的敏感性和鲁棒性不足。在这项工作中，我们关注DeePC在离线收集数据轨迹未捕获的操作区域中的性能，并展示了如何结合底层参数模型可以抵消这个问题。SD-MPC在确定性线性时不变系统上表现出与DeePC等效的闭环性能。仿真结果证明了所提出的SD-MPC在线性时不变系统和建模为线性参数变化系统的非线性系统中的通用控制性能。这些结果为SD-MPC相对于经典DeePC增强鲁棒性提供了数值证据。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [58] [Optimizing Preventive and Reactive Defense Resource Allocation with Uncertain Sensor Signals](https://arxiv.org/abs/2508.02881)
> *优化具有不确定传感器信号的预防性和反应性防御资源分配*

*Faezeh Shojaeighadikolaei, Shouhuai Xu, Keith Paarporn* | **Category: eess.SY, cs.CR, cs.GT, cs.SY** | **Updated: 2025-08-04**

**Keywords:** 网络防御, 资源分配, 预防性防御, 反应性防御, 传感器不确定性

**Comment:** 6 pages, 6 figures. Accepted for presentation at the 61st Allerton
  Conference on Communication, Control, and Computing

> **TL;DR:** 本文研究了在存在不确定传感器信号的情况下，网络防御者如何在预防性防御和反应性防御之间优化资源分配。研究发现，传感器质量的提高会增加预防性投资，且在攻击成功率较低时，传感器带来的性能提升最大。

**AI_Comments:** 这项研究创新性地将传感器信号的不确定性纳入到网络防御资源分配模型中，填补了传统决策框架的空白。它不仅考虑了攻击预防，还考虑了攻击后的恢复成本，并揭示了传感器质量对防御策略和整体安全水平的关键影响。这对于实际的网络安全资源规划具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管网络防御技术不断进步，但网络攻击仍是主要担忧。标准决策框架通常只关注阻止攻击成功，而忽略了成功攻击造成的清理成本。同时，攻击检测器不完美导致传感器信号存在不确定性。因此，本文旨在研究在考虑传感器信号不确定性的情况下，如何在预防性防御和反应性防御之间进行资源分配。

**Method:** 本文提出并研究了一个新的资源分配问题模型。防御者需决定如何将投资分配给预防性防御（旨在增强节点防御能力）和反应性防御（旨在快速清理受损节点）。研究重点是传感器信号质量如何影响防御者的战略投资以及最终可达到的安全水平。

**Result:** 研究结果表明，随着传感器质量的提高，对预防性资源的最佳投资会增加，从而使反应性资源投资减少。此外，当攻击者只能实现较低的攻击成功概率时，防御者相对于不使用传感器的基线，其性能提升最大。

**Conclusion:** 传感器信号的质量对网络防御者在预防性和反应性防御之间的战略投资分配以及最终安全水平具有显著影响。高质量的传感器信号能够促使防御者更多地投资于预防性防御，并且在攻击成功率较低的场景下，传感器能带来最大的防御性能提升。

> **ai_Abstract:** 本文研究了在网络防御中，防御者如何在预防性防御和反应性防御之间进行资源分配，尤其是在存在不确定传感器信号的情况下。传统的防御策略忽视了攻击后的清理成本和传感器信号的不完美性。研究发现，传感器信号质量的提高会使防御者更倾向于投资预防性防御，从而减少反应性防御的投入。此外，当攻击成功概率较低时，传感器带来的防御性能提升最为显著。

> **摘要翻译:** 尽管网络防御技术不断进步，网络攻击仍然是一个令人担忧的问题。虽然网络攻击无法完全预防，但标准的决策框架通常只关注如何阻止其成功，而没有考虑成功攻击造成的损害清理成本。这促使我们研究本文中提出的一种新的资源分配问题：防御者必须决定如何在其预防性防御（旨在增强节点免受攻击的能力）和反应性防御（旨在快速清理受受损节点）之间分配投资。这面临着与观察或传感器信号相关的不确定性所带来的挑战，即节点是否真的被攻破；这种不确定性是真实存在的，因为攻击检测器并非完美无缺。我们研究了传感器信号的质量如何影响防御者在这两种防御类型中的战略投资，并最终影响可以实现的安全水平。特别是，我们表明，随着传感器质量的提高，对预防性资源的最佳投资会增加，从而反应性资源投资减少。我们还表明，当攻击者只能实现较低的攻击成功概率时，防御者相对于不使用传感器的基线的性能提升是最大的。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [276] [A Robust Cooperative Vehicle Coordination Framework for Intersection Crossing](https://arxiv.org/abs/2508.03417)
> *一种用于交叉路口通行的鲁棒协同车辆协调框架*

*Haojie Bai, Jiping Luo, Huafu Li, Xiongwei Zhao, Yang Wang* | **Category: eess.SY, cs.MA, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 车辆协调, 鲁棒性, 交叉口, 轨迹规划, 状态更新

**Comment:** 

> **TL;DR:** 本文提出了一种鲁棒的协同车辆协调框架，通过结合鲁棒协同轨迹规划器和上下文感知状态更新调度器，解决了非信号交叉口车辆协调中存在的状态不确定性和通信限制问题，显著降低了碰撞概率并有效利用了无线资源。

**AI_Comments:** 该论文的创新之处在于其提出的鲁棒协同车辆协调框架，它同时解决了非信号交叉口协调中的两个关键实际挑战：状态不确定性和通信带宽限制。通过结合概率安全保证的轨迹规划器和上下文感知的状态更新调度器，该框架显著提高了实际应用中的安全性和资源效率，超越了现有简化模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的非信号交叉口协同车辆协调研究大多过分简化了协调系统，假设车辆状态信息准确且状态更新过程理想，导致在存在状态不确定性和通信限制时存在驾驶风险。

**Method:** 本文提出了一种鲁棒且全面的交叉口协调框架，包括一个鲁棒协同轨迹规划器和一个上下文感知状态更新调度器。轨迹规划器直接控制轨迹分布的演变，提供概率安全保证。状态更新调度器根据车辆的驾驶紧急程度动态优先排序状态更新，以适应带宽受限的实际条件。

**Result:** 仿真结果验证了所提出协调框架的鲁棒性和有效性，表明在保持与最新策略相当的协调效率的同时，碰撞概率显著降低。此外，该框架在实际不确定和带宽受限条件下，在无线资源利用方面表现出卓越的有效性。

**Conclusion:** 本文提出的鲁棒协同车辆协调框架能够有效解决非信号交叉口车辆协调中的状态不确定性和通信限制问题，显著提高安全性并优化资源利用，从而实现更可靠和高效的交通流。

> **ai_Abstract:** 本文针对非信号交叉口车辆协调中现有研究对状态不确定性和通信限制的忽视，提出了一种鲁棒的协同车辆协调框架。该框架包含一个鲁棒协同轨迹规划器，提供概率安全保证，以及一个上下文感知状态更新调度器，动态优化带宽受限条件下的状态更新。仿真结果表明，该框架能显著降低碰撞概率，同时保持高协调效率，并有效利用无线资源。

> **摘要翻译:** 近年来，非信号交叉口的协同车辆协调在学术界和工业界都引起了极大的兴趣，突显了其在提高交通吞吐量和燃油效率方面的显著优势。然而，大多数现有研究都过分简化了协调系统，假设车辆状态信息准确且状态更新过程理想。在存在状态不确定性和通信限制的情况下，这些疏忽会带来驾驶风险。为了弥补这一空白，我们提出了一种鲁棒而全面的交叉口协调框架，包括一个鲁棒协同轨迹规划器和一个上下文感知状态更新调度器。轨迹规划器在频繁的车辆交互过程中直接控制轨迹分布的演变，从而提供概率安全保证。为了进一步与实际带宽受限条件下的协调安全保持一致，我们提出了一种上下文感知状态更新调度器，根据车辆的驾驶紧急程度动态优先排序车辆的状态更新。仿真结果验证了所提出协调框架的鲁棒性和有效性，表明在保持与最新策略相当的协调效率的同时，碰撞概率可以显著降低。此外，我们提出的框架在实际不确定和带宽受限条件下，在利用无线资源方面表现出卓越的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [293] [State dimension reduction of recurrent equilibrium networks with contraction and robustness preservation](https://arxiv.org/abs/2508.02843)
> *具有收缩性和鲁棒性保持的循环平衡网络状态降维*

*M. F. Shakib* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-04**

**Keywords:** 循环平衡网络, 模型降维, 收缩性, 鲁棒性, 投影

**Comment:** 

> **TL;DR:** 本文提出了一种基于投影的方法，用于降低循环平衡网络（REN）的状态维度，同时保持其收缩性和鲁棒性，以解决在资源受限设备上部署大规模REN的挑战。

**AI_Comments:** 该论文的创新之处在于其双管齐下的投影方法，该方法同时解决了模型降维、精度保持以及REN关键特性（收缩性和鲁棒性）的保留问题。这使得REN在实际的嵌入式应用中更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在资源有限的设备上实时部署大规模循环平衡网络（REN）仍然具有挑战性。

**Method:** 本文提出了一种基于投影的方法来降低已训练REN的线性时不变（LTI）组件的状态维度。该方法使用两个投影矩阵：一个用于利用已学习的REN收缩性证书来保持收缩性和鲁棒性；另一个根据LTI模型降维所需的$h_2$-最优性条件进行迭代更新，以提高降阶REN的精度。

**Result:** 数值示例验证了该方法，表明在保持收缩性和鲁棒性的同时，实现了显著的状态维度降低和有限的精度损失。

**Conclusion:** 所提出的基于投影的方法能够有效降低循环平衡网络的状态维度，同时保持其关键的收缩性和鲁棒性，使其更适合在资源受限设备上部署。

> **ai_Abstract:** 本文旨在解决大规模循环平衡网络（REN）在资源受限设备上部署的挑战。为此，提出了一种基于投影的方法来降低已训练REN中线性时不变（LTI）组件的状态维度。该方法利用两个投影矩阵：一个用于确保收缩性和鲁棒性的保留，另一个则通过迭代更新来优化降阶REN的精度。数值实验结果证实，该方法在显著降低状态维度的同时，能有效保持网络性能和关键特性，且精度损失有限。

> **摘要翻译:** 循环平衡网络 (REN) 通过无约束学习，能够有效学习具有认证收缩性和鲁棒性特性的复杂动力学系统。虽然这为学习大规模 REN 提供了可能，但在资源有限的设备上实时部署此类大规模 REN 仍然具有挑战性。由于 REN 由线性时不变 (LTI) 动力学和静态激活函数的反馈互连组成，本文提出了一种基于投影的方法来降低已训练 REN 的 LTI 组件的状态维度。两个投影矩阵中的一个专门用于利用已学习到的 REN 收缩性证书来保持收缩性和鲁棒性。另一个投影矩阵则根据 LTI 模型降维所需的 $h_2$-最优性条件进行迭代更新，以提高降阶 REN 的精度。数值示例验证了该方法，表明在保持收缩性和鲁棒性的同时，实现了显著的状态维度降低和有限的精度损失。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [328] [Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty](https://arxiv.org/abs/2508.02906)
> *具有鲁棒LQR控制器的主动式四分之一汽车悬架在道路扰动和参数不确定性下的建模与仿真*

*Mehmet Karahan* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-04**

**Keywords:** 主动悬架, LQR控制器, 鲁棒性, 道路扰动, 参数不确定性

**Comment:** 16 pages, 13 figures

> **TL;DR:** 本研究设计并比较了在道路扰动和参数不确定性下，鲁棒LQR控制器控制的主动悬架与被动悬架和PID控制的主动悬架的性能，结果表明LQR控制的主动悬架提供了更舒适和安全的乘坐体验。

**AI_Comments:** 该论文通过对比LQR控制的主动悬架与被动悬架和PID控制的主动悬架，强调了LQR在处理道路扰动和参数不确定性方面的鲁棒性优势，为主动悬架系统的控制器设计提供了有价值的参考。其创新点在于对不同悬架系统在复杂条件下的性能进行了量化比较。

<details>
  <summary>Details</summary>

**Motivation:** 车辆悬架对乘客的舒适性、减少振动和冲击以及提高车辆的道路保持能力、安全转弯和降低交通事故风险至关重要。尽管主动悬架系统比被动悬架系统结构更复杂、成本更高，但它们更安全，并且需要改进其控制器以提高性能。

**Method:** 本研究设计了一个比被动悬架和PID控制的主动悬架更鲁棒的LQR控制主动悬架。对被动悬架、PID控制的主动悬架和LQR控制的主动悬架进行了鲁棒性分析。在道路扰动以及同时存在道路扰动和参数不确定性的情况下，对所有三种悬架进行了悬架行程、簧载质量加速度和簧载质量运动仿真。通过获取悬架的上升时间、超调量和稳定时间数据进行比较分析。

**Result:** LQR控制的主动悬架表现出最小的超调量和最短的稳定时间。

**Conclusion:** LQR控制的主动悬架与被动悬架和PID控制的主动悬架相比，提供了更舒适和安全的乘坐体验。

> **ai_Abstract:** 本研究旨在设计和评估一种基于鲁棒LQR控制器的主动式四分之一汽车悬架系统，并将其性能与传统的被动悬架系统和采用PID控制的主动悬架系统进行比较。通过在道路扰动和参数不确定性条件下进行建模和仿真，研究人员对三种悬架系统的悬架行程、簧载质量加速度和簧载质量运动进行了分析。结果表明，LQR控制的主动悬架在超调量和稳定时间方面表现出卓越的性能，从而证明其在提供更舒适和安全驾驶体验方面的优越性。

> **摘要翻译:** 车辆悬架对于乘客舒适出行以及减少振动和冲击等影响至关重要。一个好的悬架系统可以提高车辆的道路保持能力，使其安全转弯并降低交通事故风险。被动悬架系统因其结构简单和成本低廉而成为车辆中最广泛使用的悬架系统。被动悬架系统没有执行器，因此没有控制器。主动悬架系统具有执行器和控制器。尽管它们的结构更复杂且成本更高，但它们更安全。PID控制器因其结构简单、成本合理和易于调节系数而在主动悬架系统中广泛使用。在本研究中，设计了一种比被动悬架和PID控制主动悬架更鲁棒的LQR控制主动悬架。对被动悬架、PID控制主动悬架和LQR控制主动悬架进行了鲁棒性分析。在道路扰动以及同时存在道路扰动和参数不确定性的情况下，对所有三种悬架进行了悬架行程、簧载质量加速度和簧载质量运动仿真。通过获取悬架的上升时间、超调量和稳定时间数据进行了比较分析。结果表明，LQR控制的主动悬架表现出最小的超调量和最短的稳定时间。在这种情况下，证明了LQR控制的主动悬架与另外两种悬架系统相比，提供了更舒适和安全的乘坐体验。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [363] [Integrating Upstream Supply Chains into Generation Expansion Planning](https://arxiv.org/abs/2508.03001)
> *将上游供应链整合到发电扩张规划中*

*Boyu Yao, Andrey Bernstein, Yury Dvorkin* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 供应链限制, 发电扩张规划, SC-GEP, 提前期, 系统可靠性

**Comment:** 10 pages, 9 figures

> **TL;DR:** 本文提出了一种多阶段供应链受限的发电扩张规划（SC-GEP）模型，以解决传统模型中忽视的材料、制造能力和提前期等上游供应链限制，研究表明这些限制会影响技术选择、投资成本和系统可靠性。

**AI_Comments:** 本文创新性地将上游供应链中的材料可用性和提前期等约束整合到发电扩张规划中，这相比传统模型是一个显著的进步。这种整体性的方法提供了一个更现实、更健壮的规划框架，对于在电力需求增长和潜在供应链中断面前确保系统可靠性和成本效益至关重要。其研究结果突出了这些约束对投资决策和系统韧性的实际影响。

<details>
  <summary>Details</summary>

**Motivation:** 不断增长的电力需求要求安全可靠的发电扩张规划，但传统模型常忽视上游供应链中的材料、制造能力、部署提前期和现场可用性等限制，这些限制可能导致计划资源延迟上线，从而威胁系统可靠性。

**Method:** 本文引入了一个多阶段供应链受限的发电扩张规划（SC-GEP）模型，该模型在优化长期投资的同时，考虑了材料可用性、生产限制、空间和时间约束以及报废资产的材料再利用。一个分解算法被用于高效地解决由此产生的混合整数线性规划（MILP）问题。

**Result:** 马里兰州的案例研究表明：供应链限制会改变技术选择；加剧由提前期引起的部署延迟；促使更早地投资于提前期更短、材料强度更低的方案。在低需求情景下，供应链限制使投资成本增加了12亿美元。在高需求下，出现持续的发电和备用短缺。

**Conclusion:** 将上游供应链限制整合到长期发电规划中是必要的，以应对潜在的部署延迟、成本增加以及在高需求情景下可能出现的发电和备用短缺，从而确保系统可靠性。

> **ai_Abstract:** 本文提出了一种多阶段供应链受限的发电扩张规划（SC-GEP）模型，旨在解决传统模型中忽视的材料可用性、制造能力和提前期等上游供应链限制。该模型通过优化长期投资，同时考虑材料可用性、生产限制、空间和时间约束以及报废资产的材料再利用，由分解算法高效求解。马里兰州的案例研究表明，供应链限制会影响技术选择、加剧部署延迟、鼓励投资于提前期更短且材料强度较低的方案，并在低需求情景下增加投资成本，在高需求下导致持续的发电短缺，从而强调了将这些上游限制整合到长期规划中的重要性。

> **摘要翻译:** 不断增长的电力需求凸显了对安全可靠的发电扩张规划的需求，该规划需要考虑上游供应链的限制。传统模型通常忽视材料、制造能力、部署提前期和现场可用性方面的限制，这些限制可能延迟计划资源的可用性，从而威胁系统可靠性。本文引入了一种多阶段供应链受限的发电扩张规划（SC-GEP）模型，该模型在优化长期投资的同时，捕获了材料可用性、生产限制、空间和时间限制以及报废资产的材料再利用。一种分解算法有效地解决了由此产生的MILP问题。一项马里兰州的案例研究表明，供应链限制会改变技术选择，加剧由提前期引起的部署延迟，并促使更早地投资于提前期更短、材料强度更低的方案。在低需求情景下，供应链限制使投资成本增加了12亿美元。在高需求下，出现持续的发电和备用短缺，这凸显了将上游限制整合到长期规划中的必要性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [398] [Power System Voltage Stability Boundary: Computational Results and Applications](https://arxiv.org/abs/2508.03119)
> *电力系统电压稳定性边界：计算结果与应用*

*Zhenyao Li, Yifan Yao, Deqiang Gan* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 电压稳定性, DAE稳定性边界, 正则化变换, 伪鞍点, 稳定裕度

**Comment:** 

> **TL;DR:** 本文报告了DAE稳定性边界理论的计算结果，提出了一种新的正则化变换方法，研究了电压稳定性边界上锚点的存在性，并给出了计算控制伪鞍点的优化方法，最终验证了方法的准确性和有效性，旨在推进电力系统电压稳定性研究的应用。

**AI_Comments:** 本文提出了一种DAE稳定性边界理论的计算方法，特别是引入了新的正则化变换和优化方法来处理电压稳定性边界上的锚点和伪鞍点问题，并给出了电压稳定裕度表达式，对于电力系统电压稳定性分析具有一定的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 报告DAE稳定性边界理论的计算结果，旨在推进电力系统电压稳定性研究的应用。

**Method:** 首先，提出了一种新的标准微分代数方程（DAEs）正则化变换。然后，检验了电压稳定性边界上锚点的存在性，并提出了一种计算控制伪鞍点的优化方法。随后，给出了稳定性边界上伪鞍点稳定流形的局部表示，并获得了电压稳定裕度表达式。最后，通过多个例子验证了所提出结果的准确性和有效性。

**Result:** 提出了一种新的DAEs正则化变换；检验了电压稳定性边界上锚点的存在性；提出了一种计算控制伪鞍点的优化方法；获得了电压稳定裕度表达式。所提出的方法在多个例子中得到了验证，显示出准确性和有效性。

**Conclusion:** 所提出的方法在电力系统电压稳定性研究中具有准确性和有效性，有助于推进该领域的应用。

> **ai_Abstract:** 本文旨在报告DAE稳定性边界理论的计算结果及其在电力系统电压稳定性研究中的应用。研究内容包括提出新的DAEs正则化变换、检验电压稳定性边界上锚点的存在性、提出计算控制伪鞍点的优化方法、给出伪鞍点稳定流形的局部表示以及获得电压稳定裕度表达式。通过多个例子验证了所提方法的准确性和有效性。

> **摘要翻译:** 本文旨在报告DAE稳定性边界理论的一些计算结果，以期推进电力系统电压稳定性研究的应用。首先，提出了一种新的标准微分代数方程（DAEs）正则化变换。然后，检验了电压稳定性边界上锚点的存在性，并提出了一种计算控制伪鞍点的优化方法。随后，给出了稳定性边界上伪鞍点稳定流形的局部表示，并获得了电压稳定裕度表达式。最后，通过几个例子验证了所提出的结果，证明了所建议方法的准确性和有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [426] [Filtering and 1/3 Power Law for Optimal Time Discretisation in Numerical Integration of Stochastic Differential Equations](https://arxiv.org/abs/2508.03135)
> *随机微分方程数值积分中优化时间离散化的滤波与1/3幂律*

*Igor G. Vladimirov* | **Category: eess.SY, cs.SY, math.OC, math.PR, 65C30, 34K28, 60J60, 60J65, 93E11, 62F15, 65L50, 65K10, 60G15, 60H35** | **Updated: 2025-08-05**

**Keywords:** 随机微分方程, 数值积分, 时间离散化, 滤波, 1/3幂律

**Comment:** 6 pages, submitted to IFAC World Congress 2026

> **TL;DR:** 本文研究了随机微分方程数值积分中的最优时间离散化问题，通过滤波视角和贝叶斯方法，发现渐近最优网格密度函数遵循1/3幂律。

**AI_Comments:** 本文的创新之处在于将滤波理论应用于随机微分方程的数值积分，并通过理论推导和优化问题揭示了最优时间离散化网格密度的1/3幂律。这一发现对于提高SDEs数值模拟的效率和精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究随机微分方程（SDEs）的数值积分问题，特别是针对由标准维纳过程驱动的扩散过程，寻求最优的时间离散化方法。

**Method:** 作者从滤波的角度重新审视了SDE的近似强解，将其视为隐藏系统状态的估计。通过贝叶斯方法和中间时间间隔上的布朗桥更新条件概率分布。对于一类多变量线性SDE，数值解被组织为卡尔曼滤波器。研究了当时间离散化由均匀网格的平滑单调变换指定时，终端和积分均方误差泛函的细网格渐近行为，从而引出时间离散化剖面上的约束优化问题。

**Result:** 研究结果表明，渐近最优的网格密度函数遵循1/3幂律。该结果通过一维奥恩斯坦-乌伦贝克过程进行了示例说明。

**Conclusion:** 通过对随机微分方程数值积分中时间离散化问题的研究，发现渐近最优的网格密度函数遵循1/3幂律，这为SDEs的数值求解提供了理论指导。

> **ai_Abstract:** 本文探讨了随机微分方程（SDEs）数值积分中的最优时间离散化问题。通过将SDE的近似强解视为隐藏系统状态的估计，并利用滤波视角、贝叶斯方法和布朗桥，作者研究了多变量线性SDE在卡尔曼滤波器框架下的均方误差行为。研究发现，在对时间离散化剖面进行约束优化后，渐近最优的网格密度函数遵循1/3幂律。该理论结果通过奥恩斯坦-乌伦贝克过程进行了验证。

> **摘要翻译:** 本文关注由标准维纳过程驱动的扩散过程所控制的随机微分方程（SDEs）的数值积分。当后者被一系列离散时刻的增量取代时，我们重新审视了SDE近似强解的滤波观点，将其视为隐藏系统状态的估计，其条件概率分布通过贝叶斯方法和中间时间间隔上的布朗桥进行更新。对于一类多变量线性SDE，其中数值解被组织为卡尔曼滤波器，我们研究了当时间离散化由均匀网格的足够平滑的单调变换指定时，终端和积分均方误差泛函的细网格渐近行为。这导致了时间离散化剖面上的约束优化问题，其解揭示了渐近最优网格密度函数遵循1/3幂律。作为一维示例，结果以奥恩斯坦-乌伦贝克过程为例进行了说明。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [454] [An Event-based State Estimation Approach for Positive Systems with Positive Observers](https://arxiv.org/abs/2508.03154)
> *一种基于事件的带正观测器的正系统状态估计方法*

*Bhargavi Chaudhary, Krishanu Nath, Subashish Datta, Indra Narayan Kar* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 正系统, 事件触发, 状态估计, 正观测器, Zeno行为

**Comment:** 16 pages, 7 figures and 3 tables

> **TL;DR:** 本文提出了一种用于连续时间线性正网络系统的基于事件测量的正观测器设计，旨在带宽受限环境下确保状态估计始终非负，并证明了其渐近稳定性、正性以及无Zeno行为。

**AI_Comments:** 该论文的创新点在于将事件触发机制引入到正系统的状态估计中，特别是在带宽受限的网络环境下。正观测器的设计确保了系统状态估计的物理可行性（非负性），这对于许多实际物理系统（如化学过程、生物系统）至关重要。同时，通过避免Zeno行为，保证了系统的实时性和可实现性。该方法结合了Luenberger观测器和LMI方法，理论严谨，并得到了实际系统模拟的验证，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决连续时间线性正网络系统的状态观测器设计问题，尤其是在通信网络带宽受限的情况下。其核心挑战在于设计一种“正观测器”，确保所有状态估计在任何时候都保持非负。

**Method:** 提出了一种基于事件测量的正观测器设计方法。该方法利用带有加权采样误差的输出测量律来确定系统与观测器之间的采样序列。观测器动力学采用标准Luenberger结构，并结合基于事件采样的输出信息，仅在事件发生时更新。通过线性矩阵不等式推导了稳定性和正性的充分条件，并确保了所设计的基于事件的架构没有Zeno行为。

**Result:** 建立了带采样信息的观测器动力学的渐近稳定性。利用线性矩阵不等式推导了稳定性和正性的充分条件。所设计的架构确保了基于事件的体系结构没有Zeno行为，保证了执行间隔时间的最小正界。通过对具有可变截面的三罐系统的数值模拟验证了所提出的基于事件的正观测器的有效性。

**Conclusion:** 本文成功设计并验证了一种基于事件的正观测器，该观测器能够在带宽受限的连续时间线性正网络系统中实现渐近稳定、正性状态估计，并有效避免了Zeno现象。

> **ai_Abstract:** 本文提出了一种针对连续时间线性正网络系统的基于事件测量的正观测器设计方法，以解决通信网络带宽受限下的状态估计问题。该观测器旨在确保所有状态估计始终保持非负。通过利用带有加权采样误差的输出测量律和标准Luenberger结构，观测器仅在特定事件发生时更新。研究建立了观测器动力学的渐近稳定性，并利用线性矩阵不等式推导了正性和稳定性的充分条件。此外，该设计有效避免了Zeno行为。数值模拟在一个三罐系统上验证了所提出方法的有效性。

> **摘要翻译:** 本文解决了连续时间线性正网络系统的状态观测器设计问题。考虑到通信网络的带宽限制，提出了一种基于事件测量的正观测器设计。正观测器的物理解释与一般观测器不同，其主要目标是确保所有状态估计始终保持非负。利用输出测量，采用带有加权采样误差的律来确定系统与观测器之间的采样序列。观测器动力学采用标准Luenberger结构，并利用基于事件采样的输出信息进行设计，该信息仅在事件发生时更新。在可观测性和系统正性充分条件的前提下，建立了带采样信息的观测器动力学的渐近稳定性。利用线性矩阵不等式推导了稳定性和正性的充分条件。此外，该设计确保了基于事件的架构没有Zeno行为，保证了执行间隔时间的最小正界。此外，通过对具有可变截面的三罐系统进行数值模拟，证明了所提出的基于事件的正观测器的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [490] [Grid-Forming Vector Current Control FRT Modes Under Symmetrical and Asymmetrical Faults](https://arxiv.org/abs/2508.03389)
> *具备对称和不对称故障下构网矢量电流控制的故障穿越模式*

*Ognjen Stanojev, Orcun Karaca, Mario Schweizer* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 构网控制, 矢量电流控制, 故障穿越, 对称故障, 不对称故障

**Comment:** 

> **TL;DR:** 本文提出并分析了针对构网矢量电流控制（GFVCC）的故障穿越（FRT）策略，以使其在对称和不对称电网故障下仍能提供故障电流、保持同步并维持构网行为。

**AI_Comments:** 这篇论文的创新点在于为构网矢量电流控制（GFVCC）开发了专门的故障穿越（FRT）策略，特别是考虑了对称和不对称故障，并通过模块化引入负序环路来增强其鲁棒性。这对于提高基于GFVCC的并网变流器在复杂电网环境中的可靠性和稳定性至关重要。其重要性体现在它解决了构网型逆变器在电网故障下的关键挑战，有助于推动其在现代电网中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 构网矢量电流控制（GFVCC）在并网变流器中具有简单、模块化和无缝过渡等显著优势，但其在对称和不对称短路故障等电网故障场景下的处理是一个重要方面。因此，需要开发鲁棒的故障穿越（FRT）策略。

**Method:** 本文提出并分析了几种针对GFVCC的故障穿越（FRT）策略。这些策略通过模块化扩展变流器控制方案以包含负序环路，从而能够处理对称和不对称故障。所提出的FRT策略通过包含无限母线设置和多单元电网的案例研究进行了分析。

**Result:** 所提出的FRT策略使变流器能够在故障期间提供故障电流，保持与电网同步，同时遵守硬件限制并保留构网行为。摘要中未提供具体的量化分析结果。

**Conclusion:** 摘要中未明确给出结论，但可以推断所提出的FRT策略能够有效应对对称和不对称故障，使GFVCC变流器在故障期间保持稳定运行和构网特性。

> **ai_Abstract:** 本文针对构网矢量电流控制（GFVCC）方案在并网变流器中的应用，提出了多项故障穿越（FRT）策略。这些策略旨在使GFVCC变流器在对称和不对称电网短路故障期间，仍能提供故障电流，保持与电网同步，并维持其构网特性，同时兼顾硬件限制。通过引入负序环路，该控制方案得到模块化扩展。文章通过案例研究，包括无限母线和多单元电网，对所提策略进行了分析。

> **摘要翻译:** 近期研究表明，使用构网矢量电流控制（GFVCC）方案运行并网变流器具有显著优势，包括控制架构的简单性和模块化，以及实现从基于锁相环的跟网控制到构网控制的无缝过渡。任何并网变流器控制策略的一个重要方面是处理电网故障场景，例如对称和不对称短路故障。本文提出了几种针对GFVCC的故障穿越（FRT）策略，使变流器能够在遵守变流器硬件限制并保留构网行为的同时提供故障电流并保持与电网同步。变流器控制方案以模块化方式扩展以包含负序环路，并且所提出的FRT策略解决了对称和不对称故障。所提出的FRT策略通过案例研究进行了分析，包括无限母线设置和多单元电网。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [522] [Improving Q-Learning for Real-World Control: A Case Study in Series Hybrid Agricultural Tractors](https://arxiv.org/abs/2508.03647)
> *改进Q学习用于实际控制：以串联混合动力农业拖拉机为例*

*Hend Abououf, Sidra Ghayour Bhatti, Qadeer Ahmed* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** Q学习, 强化学习, 混合动力拖拉机, 奖励整形, 专家演示

**Comment:** 

> **TL;DR:** 本研究评估了Q值强化学习算法在混合动力农业拖拉机动力总成控制中的性能，并引入了分段领域特定奖励整形策略和专家演示来加速训练和提高效率。

**AI_Comments:** 这篇论文的创新点在于结合了多个策略来改进强化学习在实际复杂系统中的应用。通过引入领域特定的奖励整形和利用专家演示来初始化经验回放，有效解决了传统Q学习在收敛速度和效率方面的挑战。这对于将强化学习应用于实际工程问题，特别是需要高效率和快速适应性的能源管理系统，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 混合动力农业拖拉机中多变且不可预测的负载需求使得设计最优的基于规则的能量管理策略变得困难，这促使研究者使用自适应的、基于学习的控制方法。现有的方法通常依赖于基本的燃料奖励，并且没有利用专家演示来加速训练。

**Method:** 1. 评估了Double Q-Learning (DQL)、Deep Q-Networks (DQN)和Double DQN (DDQN)三种Q值强化学习算法在混合动力农业拖拉机动力总成控制中的性能，并比较了收敛速度和策略最优性。2. 引入了一种分段领域特定奖励整形策略，以提高学习效率并将代理行为引导至发动机燃油效率高的运行区域。3. 检查了经验回放缓冲器的设计，重点关注了用专家演示初始化缓冲器的效果，并分析了不同类型的专家策略如何影响收敛动态和最终性能。

**Result:** 1. 在此应用领域中，DDQN比DQN的收敛速度快70%。2. 所提出的奖励整形方法有效地将学习到的策略偏向燃油效率高的结果。3. 使用结构化专家数据初始化回放缓冲器可使收敛速度提高33%。

**Conclusion:** 本研究表明，通过使用DDQN算法、引入分段领域特定奖励整形策略以及利用专家演示初始化经验回放缓冲器，可以显著提高Q学习算法在混合动力农业拖拉机动力总成控制中的学习效率和性能。

> **ai_Abstract:** 本论文旨在改进Q学习在混合动力农业拖拉机实际控制中的应用，以应对传统基于规则能量管理策略的局限性。研究评估并比较了DQL、DQN和DDQN三种Q值强化学习算法的性能，发现DDQN收敛速度最快。为提高学习效率和燃油经济性，论文引入了分段领域特定奖励整形策略，并探讨了利用专家演示初始化经验回放缓冲器对收敛速度和最终性能的影响。实验结果验证了所提出方法的有效性，包括DDQN的快速收敛、奖励整形对燃油效率的积极影响以及专家数据对收敛速度的显著提升。

> **摘要翻译:** 混合动力农业拖拉机中多变且不可预测的负载需求使得设计最优的基于规则的能量管理策略变得困难，这促使研究者使用自适应的、基于学习的控制方法。然而，现有方法通常依赖于基本的基于燃料的奖励，并且没有利用专家演示来加速训练。本文首先评估了基于Q值的强化学习算法在混合动力农业拖拉机动力总成控制中的性能。比较了Double Q-Learning (DQL)、Deep Q-Networks (DQN)和Double DQN (DDQN)三种算法的收敛速度和策略最优性。其次，引入了一种分段领域特定奖励整形策略，以提高学习效率并将代理行为引导至发动机燃油效率高的运行区域。第三，研究了经验回放缓冲器的设计，重点关注了用专家演示初始化缓冲器的影响，并分析了不同类型的专家策略如何影响收敛动态和最终性能。实验结果表明：(1) 在此应用领域中，DDQN比DQN的收敛速度快70%；(2) 所提出的奖励整形方法有效地将学习到的策略偏向燃油效率高的结果；(3) 使用结构化专家数据初始化回放缓冲器可使收敛速度提高33%。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [911] [Differentially Private Distributed Nonconvex Stochastic Optimization with Quantized Communication](https://arxiv.org/abs/2403.18254)
> *差分隐私分布式非凸随机优化与量化通信*

*Jialong Chen, Jimin Wang, Ji-Feng Zhang* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 差分隐私,分布式优化,非凸优化,量化通信,随机优化

**Comment:** 

> **TL;DR:** 提出了一种结合隐私保护、通信效率和收敛性的分布式非凸随机优化算法，通过添加隐私噪声和量化状态来增强隐私和效率，并利用双时间尺度步长和子采样技术实现了平均平方收敛和更好的隐私保护。

**AI_Comments:** 该研究在分布式优化领域取得了重要进展，成功地将差分隐私、通信效率和非凸优化相结合，解决了现有方法在这些方面存在的权衡问题。通过引入新颖的噪声添加和量化机制，以及分析工具，为设计更安全、更高效的分布式学习系统提供了理论基础和实践指导。然而，算法在不同网络拓扑和异构数据分布下的性能表现仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种能够同时实现隐私保护、通信效率和收敛性的分布式非凸随机优化算法。

**Method:** 1. 每个节点向其本地状态添加一般隐私噪声以避免信息泄露。
2. 对噪声扰动后的状态进行量化，以提高通信效率。
3. 使用子采样方法控制样本大小参数，以减少累积差分隐私参数（ε, δ），从而增强差分隐私级别。
4. 采用双时间尺度步长方法，实现非凸成本函数的均方收敛。
5. 在全局成本函数满足Polyak-Lojasiewicz条件时，给出收敛速率和预言机复杂度。

**Result:** 1. 提出的算法实现了均方收敛，并且当样本量趋于无穷时，在无限次迭代中实现了有限的累积差分隐私参数（ε, δ）。
2. 通过MNIST数据集上的分布式训练的数值示例，证明了该算法的有效性。

**Conclusion:** 该算法成功地实现了隐私保护、通信效率和收敛性，并通过数值实验得到了验证。

> **ai_Abstract:** 本文提出了一种创新的分布式非凸随机优化算法，该算法在保护隐私、提高通信效率和保证收敛性方面取得了显著的平衡。通过在本地状态中加入隐私噪声并进行量化传输，有效防止了信息泄露并减少了通信开销。该算法采用了子采样技术和双时间尺度步长，不仅降低了差分隐私参数，还实现了非凸函数的均方收敛，并在满足特定条件时提供了收敛速率和复杂度分析。MNIST数据集上的实验结果证实了该算法的有效性。

> **摘要翻译:** 本文提出了一种能够同时实现隐私保护、通信效率和收敛性的分布式非凸随机优化算法。具体来说，每个节点向其本地状态添加一般隐私噪声以避免信息泄露，然后对其噪声扰动后的状态进行量化以提高通信效率。通过使用由样本大小参数控制的子采样方法，所提出的算法减小了累积差分隐私参数{\epsilon}，{\delta}，从而增强了差分隐私级别，这与现有工作有显著不同。通过使用双时间尺度步长方法，给出了非凸成本函数的均方收敛性。此外，当全局成本函数满足Polyak-Lojasiewicz条件时，给出了所提出算法的收敛速率和预言机复杂度。此外，当样本量趋于无穷时，所提出算法在无限次迭代中实现了均方收敛和有限的累积差分隐私参数{\epsilon}，{\delta}。通过分布式训练的数值示例在"MNIST"数据集上展示了该算法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [942] [Robust Sensor-Limited Control with Safe Input-Output Constraints for Hydraulic In-Wheel Motor Drive Mobility Systems](https://arxiv.org/abs/2409.11823)
> *用于液压轮毂电机驱动移动系统的鲁棒传感器限制控制及安全输入输出约束*

*Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 液压轮毂驱动, 鲁棒控制, 障碍李雅普诺夫函数, 移动机器人, 传感器限制

**Comment:** This work has been submitted for possible publication in the Elsevier

> **TL;DR:** 本研究提出了一种新的鲁棒转矩观测阀控（RTOVC）框架，用于解决液压轮毂驱动（IWD）的重型轮式移动机器人（HWMR）的速度跟踪问题。该框架利用自适应障碍李雅普诺夫函数（BLF）构建鲁棒观测器网络来估计所需的轮毂电机转矩，并设计了另一个自适应BLF来控制阀门信号以生成该转矩。RTOVC策略通过对阀门控制信号、实际速度、速度跟踪误差和转矩进行约束，确保了用户定义的安全性。实验结果表明，该方法在存在外部干扰和模型不确定性的情况下，能够保证HWMR的鲁棒性和一致指数稳定性。

**AI_Comments:** 该研究提出了一种创新的RTOVC框架，有效地解决了液压轮毂驱动移动系统在传感器受限和安全约束下的速度跟踪问题。方法新颖，将BLF理论应用于观测器和控制器设计，实现了对系统状态的鲁棒估计和精确控制。实验验证了该方法的有效性，为类似系统的设计提供了有价值的参考。然而，对于不同类型的HWMR和更复杂的工况下的性能表现仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决液压轮毂驱动（IWD）的重型轮式移动机器人（HWMR）在速度跟踪时面临的轮滑、传感器限制、恶劣地形和模型不确定性等挑战，需要一种能够处理传感器限制和保证安全输入输出约束的新型鲁棒控制方法。

**Method:** 提出了一种鲁棒转矩观测阀控（RTOVC）框架。该框架包含一个基于自适应障碍李雅普诺夫函数（BLF）的鲁棒观测器网络，用于估计所需的轮毂电机转矩，以克服传感器依赖性。此外，还采用了一个用于阀门控制信号的自适应BLF，以调节液压流体来产生估计的转矩。该策略通过BLF框架对阀门控制信号、实际速度、速度跟踪误差和转矩进行约束，以确保用户定义的安全性。

**Result:** RTOVC策略能够确保在存在外部干扰和模型不确定性的情况下，HWMR的鲁棒性和一致指数稳定性。实验结果表明，该方法在重型HWMR上表现良好，即使在强干扰和安全约束条件下也能有效运行。

**Conclusion:** 提出的RTOVC框架能够有效地解决液压轮毂驱动（IWD）的重型轮式移动机器人（HWMR）在传感器受限和需要安全输入输出约束下的速度跟踪问题，并在实验中得到了验证。

> **ai_Abstract:** 本研究提出了一种新颖的鲁棒转矩观测阀控（RTOVC）框架，用于解决重型轮式移动机器人（HWMR）的液压轮毂驱动（IWD）的速度跟踪问题。该框架利用基于自适应障碍李雅普诺夫函数（BLF）的鲁棒观测器网络来估计所需的轮毂电机转矩，并采用另一个自适应BLF来控制阀门信号以生成该转矩。该方法克服了传感器限制、轮滑和模型不确定性等挑战，并通过对关键参数进行约束来确保安全性。实验结果表明，该框架在重型HWMR上实现了鲁棒性和稳定性。

> **摘要翻译:** 轮毂驱动（IWD）系统通过使每个车轮能够独立运行，提高了车辆的响应性、牵引力和维护效率。本文提出了一种新颖的鲁棒转矩观测阀控（RTOVC）框架，用于解决重型轮式移动机器人（HWMR）的液压IWD的速度跟踪问题，考虑了诸如车轮打滑、传感器限制、崎岖地形和模型不确定性等挑战。为了克服与液压IWD驱动的HWMR中的闭环转矩/压力相关的传感器依赖控制系统，提出了一种基于自适应障碍李雅普诺夫函数（BLF）的鲁棒观测器网络，以估计跟踪速度参考所需的轮毂电机转矩。然后，采用另一个用于阀门控制信号的自适应BLF来调节液压流体，为每个IWD产生估计的转矩。RTOVC策略通过在对数BLF框架内约束HWMR中每个液压IWD的阀门控制信号、实际速度、速度跟踪误差和转矩，以避免超过指定限制，从而确保用户定义的安全性。尽管存在安全约束、外部干扰和模型不确定性，RTOVC应用的液压IWD机制在HWMR中的鲁棒性和一致指数稳定性得到了保证。使用一台由四个独立IWD驱动的6500公斤HWMR进行的实验研究，在强干扰和安全定义的约束下，验证了RTOVC的性能。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [963] [Model Reference-Based Control with Guaranteed Predefined Performance for Uncertain Strict-Feedback Systems](https://arxiv.org/abs/2502.03263)
> *具有保证的预定义性能的不确定严格反馈系统模型参考自适应控制*

*Mehdi Heydari Shahna, Jukka-Pekka Humaloja, Jouni Mattila* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-05**

**Keywords:** 模型参考自适应控制, 严格反馈系统, 齐次自适应估计器, 对数屏障李雅普诺夫函数, 预定义性能, 控制幅值饱和, 稳定性连接项, 均匀指数稳定性, 机电线性驱动器, 负载扰动

**Comment:** 

> **TL;DR:** 本研究提出了一种新的模型参考自适应控制（MRBC）框架，用于解决具有时变和状态变不确定性的严格反馈系统（SFF）的控制问题。该框架利用新的齐次自适应估计器（HAEs）将不确定系统与参考模型进行匹配，并结合模型驱动的齐次自适应控制器（HAC-BLFs）来控制参考模型，同时通过对数屏障李雅普诺夫函数（BLF）确保跟踪性能和控制幅值饱和。该方法通过一个通用的稳定性连接项实现了均匀指数稳定性，并分析了参数敏感性。实验结果表明，该方法在不确定SFF的机电线性驱动器系统上表现良好。

**AI_Comments:** 该研究提出了一种新颖的MRBC框架，能够处理严格反馈系统中存在的不确定性和控制幅值饱和问题，并保证预定义的跟踪性能。通过引入HAEs和HAC-BLFs，以及利用BLF和稳定性连接项，该方法在理论和实验上都得到了验证，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 严格反馈系统（SFF）的时变和状态变不确定性以及解析导数的计算复杂性。

**Method:** 提出了一种新的模型参考自适应控制（MRBC）框架，该框架将齐次自适应估计器（HAEs）应用于每个子系统，以匹配不确定SFF系统和参考模型。然后，使用模型驱动的齐次自适应控制器（HAC-BLFs）和对数屏障李雅普诺夫函数（BLF）来控制参考模型，同时确保预定义的跟踪响应和控制幅值饱和。通过一个通用的稳定性连接项实现均匀指数稳定性，并分析了参数敏感性。

**Result:** 提出的MRBC框架实现了均匀指数稳定性，并成功地在具有不确定SFF的机电线性驱动器系统上进行了实验验证，该系统承受了高达其容量95%的负载扰动。

**Conclusion:** 该研究成功地提出并验证了一种新的模型参考自适应控制（MRBC）框架，用于具有不确定性的严格反馈系统。该框架通过结合齐次自适应估计器（HAEs）和模型驱动的齐次自适应控制器（HAC-BLFs），能够保证预定义的跟踪性能，并处理控制幅值饱和。

> **ai_Abstract:** 本研究提出了一种新颖的模型参考自适应控制（MRBC）框架，用于解决具有时变和状态变不确定性的严格反馈系统（SFF）的控制问题。该框架利用齐次自适应估计器（HAEs）将不确定系统与参考模型进行匹配，并结合模型驱动的齐次自适应控制器（HAC-BLFs）来控制参考模型，同时通过对数屏障李雅普诺夫函数（BLF）确保跟踪性能和控制幅值饱和。该方法通过一个通用的稳定性连接项实现了均匀指数稳定性，并分析了参数敏感性。实验结果表明，该方法在不确定SFF的机电线性驱动器系统上表现良好。

> **摘要翻译:** 为了解决时变和状态变不确定性以及严格反馈形式（SFF）系统中解析导数计算的复杂性，本研究引入了一种新颖的基于模型的参考控制（MRBC）框架，该框架局部应用于每个子系统（SS），以确保输出跟踪性能在指定的瞬态和稳态响应标准内。该框架包括1）新颖的齐次自适应估计器（HAEs），旨在将不确定的非线性SFF系统与参考模型进行匹配，从而在局部层面实现更简单的分析和控制设计；以及2）模型驱动的齐次自适应控制器，通过对数屏障李雅普诺夫函数（HAC-BLFs）进行增强，旨在控制每个SS中的HAEs提供的参考模型，同时确保在控制幅值饱和下的预规定跟踪响应。固有的鲁棒MRBC使用通用的稳定性连接项实现均匀指数稳定性，该连接项解决了相邻SS之间的动态交互问题。对MRBC框架中HAEs和HAC-BLFs的参数敏感性进行了分析，重点关注系统的鲁棒性和响应能力。所提出的MRBC框架通过涉及机电线性执行器系统的几个场景进行了实验验证，该系统具有不确定的SFF，并承受着挑战其容量0-95%的负载扰动。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [37] [Goal-Oriented Adaptive Finite Element Multilevel Quasi-{M}onte {C}arlo](https://arxiv.org/abs/2508.02925)
> *目标导向自适应有限元多层准蒙特卡洛*

*Joakim Beck, Yang Liu, Erik von Schwerin, Raúl Tempone* | **Category: math.NA, cs.NA, 65C05, 65N50, 65N22, 35R60** | **Updated: 2025-08-04**

**Keywords:** 多层准蒙特卡洛, 自适应有限元, 对数正态扩散率, 不确定性量化, 重要性采样

**Comment:** 

> **TL;DR:** 本文提出了一种多层准蒙特卡洛（QMC）框架，用于高效近似具有对数正态扩散率的偏微分方程（PDE）产生的感兴趣量，通过自适应网格、重要性采样和控制变量显著降低了计算成本。

**AI_Comments:** 本文的创新点在于将多层准蒙特卡洛方法与自适应网格、重要性采样和零级控制变量相结合，以解决不确定性量化中PDE相关感兴趣量的高效近似问题。特别是，引入零级控制变量并强调其对自适应网格优势的体现，是其独到之处。其重要性在于提供了一种更高效、更经济的计算方法。

<details>
  <summary>Details</summary>

**Motivation:** 不确定性量化中，高效近似来源于具有对数正态扩散率的偏微分方程的感兴趣量是一个核心挑战。

**Method:** 本研究提出了一个多层准蒙特卡洛（QMC）框架，用于近似依赖于具有对数正态扩散系数（由49维高斯随机向量参数化）的线性椭圆PDE解的确定性、实值、有界线性泛函。该方法分析了参数正则性，并基于一系列自适应网格开发了多层实现。为了进一步降低方差，引入了重要性采样，并在多层层次结构中引入了零级控制变量。

**Result:** 数值实验表明，所提出的自适应QMC算法在达到预定精度的同时，计算成本远低于标准多层蒙特卡洛方法。

**Conclusion:** 所提出的自适应多层准蒙特卡洛算法能够以显著降低的计算成本高效地近似具有对数正态扩散率的偏微分方程的感兴趣量，优于标准多层蒙特卡洛方法。

> **ai_Abstract:** 本文提出了一种目标导向的自适应有限元多层准蒙特卡洛（QMC）框架，旨在高效近似具有对数正态扩散率的PDE所产生的感兴趣量。该框架通过分析参数正则性，并基于自适应网格序列实现，结合了重要性采样和零级控制变量以进一步降低方差。数值实验证明，与标准多层蒙特卡洛方法相比，该自适应QMC算法能在显著降低计算成本的同时达到预设精度。

> **摘要翻译:** 不确定性量化中，高效近似来源于具有对数正态扩散率的偏微分方程（PDE）的感兴趣量是一个核心挑战。在本研究中，我们提出了一种多层准蒙特卡洛框架，用于近似依赖于具有对数正态扩散系数（由49维高斯随机向量参数化）和$\\mathbb{R}^d$有界域中确定性几何奇异点的线性椭圆PDE解的确定性、实值、有界线性泛函。我们分析了参数正则性，并基于一系列自适应网格开发了多层实现，该实现参考了“Goal-oriented adaptive finite element multilevel Monte Carlo with convergence rates”, \\emph{CMAME}, 402 (2022), p. 115582。为了进一步降低方差，我们结合了重要性采样，并在多层层次结构中引入了零级控制变量。引入这种控制变量可以改变初始网格的最优选择，进一步凸显了自适应网格的优势。数值实验表明，我们的自适应QMC算法在达到预定精度的同时，计算成本远低于标准多层蒙特卡洛方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [77] [Sparse Identification of Nonlinear Dynamics for Stochastic Delay Differential Equations](https://arxiv.org/abs/2508.03040)
> *随机延迟微分方程非线性动力学的稀疏识别*

*Dimitri Breda, Dajana Conte, Raffaele D'Ambrosio, Ida Santaniello, Muhammad Tanveer* | **Category: math.NA, cs.NA, 60H10, 34K50, 68T05, 93E12** | **Updated: 2025-08-05**

**Keywords:** 随机延迟微分方程, SINDy, 非线性动力学, 稀疏识别, 漂移扩散动力学

**Comment:** 

> **TL;DR:** 首次提出了一个基于SINDy的通用框架，用于从采样轨迹中识别随机延迟微分方程的漂移和扩散动力学。

**AI_Comments:** 本文的创新之处在于首次将SINDy算法扩展应用于随机延迟微分方程，解决了从采样数据中识别其复杂动力学的问题。该框架结合了处理随机性和延迟的特定技术，并通过数值研究验证了其有效性，为相关领域的研究提供了新的工具和思路。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在首次为一个通用框架，从采样轨迹中恢复随机延迟微分方程（SDDEs）的漂移和扩散动力学，以填补现有方法的空白。

**Method:** 该方法基于成熟的SINDy算法，结合了处理随机问题的高阶漂移和协方差估计，并利用增强库来处理延迟参数。文中讨论了三种利用实际可用数据的策略。

**Result:** 对不同模型进行了彻底的比较数值研究，结果有助于指导选择有效且可能表现优异的方案。

**Conclusion:** 成功提出了一个从采样轨迹中识别随机延迟微分方程漂移和扩散动力学的通用框架，并通过数值研究验证了其有效性，并提供了方案选择的指导。

> **ai_Abstract:** 本文首次提出了一个基于SINDy算法的通用框架，用于从采样轨迹中识别随机延迟微分方程的漂移和扩散动力学。该方法结合了高阶估计和增强库来处理随机性和延迟，并探讨了三种数据利用策略。通过对不同模型的数值比较研究，验证了方法的有效性并提供了方案选择的指导。

> **摘要翻译:** 首次提出了一个从采样轨迹中恢复随机延迟微分方程的漂移和扩散动力学的通用框架。其核心依赖于成熟的SINDy算法，用于非线性动力学的稀疏识别。所提出的方法结合了最近提出的高阶漂移和协方差估计，以处理随机问题，并结合增强库来处理延迟参数。文中讨论了三种策略，以期仅利用实际可用的数据。对不同模型进行了彻底的比较数值研究，这有助于指导选择有效且可能表现优异的方案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [115] [Low-rankness and Smoothness Meet Subspace: A Unified Tensor Regularization for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2508.03049)
> *低秩性和平滑性与子空间结合：一种用于高光谱图像超分辨率的统一张量正则化*

*Jun Zhang, Chao Yi, Mingxi Ma, Chao Wang* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 高光谱图像超分辨率, 张量正则化, 低秩性, 平滑性, 子空间

**Comment:** 13 pages, 71 figures

> **TL;DR:** 提出了一种名为JLRST的统一张量正则化方法，通过在子空间中结合低秩性和平滑性先验，显著提升了高光谱图像超分辨率的性能和效率。

**AI_Comments:** 该论文的创新点在于将低秩性和平滑性先验在子空间框架下进行统一，并通过在子空间系数上施加先验来解决高光谱数据维度过高的问题，显著提升了计算效率和准确性。引入模式-3对数TNN以减轻偏差也是一个亮点。这项工作为高光谱图像超分辨率提供了一个高效且高性能的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱图像超分辨率（HSI-SR）是遥感领域一个具有挑战性但至关重要的问题。现有方法主要利用低秩性和局部平滑性先验，但由于高光谱数据的维度过高，直接应用存在障碍。

**Method:** 提出了一种名为JLRST的统一张量正则化器，它在子空间框架下联合编码低秩性和局部平滑性先验。具体来说，计算聚类系数张量沿所有三个张量模式的梯度以利用光谱相关性和非局部相似性。通过在子空间系数而不是整个HR-HSI数据上施加先验，提高了计算效率和准确性。此外，引入了模式-3对数张量核范数（TNN）来处理梯度张量以减轻TNN引入的偏差。开发了一种具有收敛性证明的交替方向乘子法（ADMM）来求解所提出的模型。

**Result:** 实验结果表明，该方法在HSI-SR中显著优于最先进的方法。

**Conclusion:** 所提出的JLRST方法通过在子空间中统一低秩性和平滑性先验，并结合改进的TNN和ADMM求解器，能够有效解决高光谱图像超分辨率问题，并取得了卓越的性能。

> **ai_Abstract:** 本文针对高光谱图像超分辨率（HSI-SR）问题，提出了一种统一的张量正则化方法JLRST。该方法在子空间框架下联合利用低秩性和局部平滑性先验，通过计算聚类系数张量在所有模式上的梯度，并引入模式-3对数张量核范数来处理梯度张量，以提高效率和准确性。实验证明，JLRST显著优于现有最先进的HSI-SR方法。

> **摘要翻译:** 高光谱图像超分辨率（HSI-SR）已成为遥感领域一个具有挑战性但至关重要的问题。现有方法主要侧重于利用低秩性和局部平滑性先验的正则化技术。最近，引入了相关全变分，将这些先验集成到一个单一的正则化框架中。然而，由于高光谱数据的高光谱维度，直接应用于HSI-SR受到了阻碍。在本文中，我们提出了一种统一的张量正则化器，称为JLRST，它在子空间框架下联合编码低秩性和局部平滑性先验。具体来说，我们计算聚类系数张量沿所有三个张量模式的梯度，以充分利用HSI中的光谱相关性和非局部相似性。通过在子空间系数而不是整个HR-HSI数据上施加先验，所提出的方法实现了更高的计算效率和准确性。此外，为了减轻张量核范数（TNN）引入的偏差，我们引入了模式-3对数TNN来处理梯度张量。开发了一种具有收敛性证明的交替方向乘子法来求解所提出的模型。实验结果表明，我们的方法在HSI-SR中显著优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [157] [Reduced Order Data-driven Twin Models for Nonlinear PDEs by Randomized Koopman Orthogonal Decomposition and Explainable Deep Learning](https://arxiv.org/abs/2508.03325)
> *基于随机Koopman正交分解和可解释深度学习的非线性偏微分方程降阶数据驱动孪生模型*

*D. A. Bistrian* | **Category: math.NA, cs.NA, 00A71, 46N40, 34A45** | **Updated: 2025-08-05**

**Keywords:** Koopman算子, 降阶模型, 数据驱动, 非线性偏微分方程, 可解释深度学习

**Comment:** 34 pages, 9 figures

> **TL;DR:** 本研究提出了一种基于Koopman算子理论的数据驱动孪生建模框架，通过随机Koopman正交分解和可解释的深度学习，为非线性偏微分方程（PDEs）构建了紧凑、高保真、自洽且可解释的降阶模型，并在激波现象上进行了验证。

**AI_Comments:** 该论文的创新点在于将随机Koopman正交分解与可解释深度学习相结合，为非线性偏微分方程提供了一种无需手动干预、高保真且可解释的数据驱动孪生建模方法。其自洽性和对激波现象的成功应用凸显了其在复杂系统建模领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在克服经典模态分解在捕获非线性动力学方面的局限性，并实现无需手动参数调整的降阶模型，同时平衡准确性和效率。

**Method:** 该方法整合了Koopman算子理论、随机正交投影计算正交Koopman模式、Pareto前沿分析以构建紧凑高保真降阶模型，并采用可解释的NLARX深度学习框架进行实时自适应校准和预测。它避免了启发式选择，并通过可解释学习技术增强了可解释性。

**Result:** 该方法在激波现象上通过三个复杂度递增的实验得到了验证，并对所生成的数据驱动孪生模型进行了定性分析。

**Conclusion:** 该研究提出的数据驱动孪生建模方法能够准确捕获非线性动力学，构建紧凑、高保真、自洽且可解释的降阶模型，无需手动参数调整，并在激波现象中表现出有效性。

> **ai_Abstract:** 本研究提出了一种基于Koopman算子理论的数据驱动孪生建模框架，旨在解决非线性偏微分方程的复杂动力学建模问题。该框架结合了随机Koopman正交分解和可解释的NLARX深度学习，构建了紧凑、高保真、无需手动调整参数的降阶模型。通过Pareto前沿分析优化模型，并利用可解释学习增强其可解释性。该方法在激波现象上进行了验证，展示了其在捕获非线性动力学方面的准确性和效率。

> **摘要翻译:** 本研究引入了一种基于现代Koopman算子理论的数据驱动孪生建模框架，与经典模态分解相比，它通过以降低的复杂性准确捕获非线性动力学，且无需手动参数调整，实现了显著的进步。该方法集成了一种新颖的算法与Pareto前沿分析，以构建一个紧凑、高保真、平衡准确性和效率的降阶模型。一个可解释的NLARX深度学习框架能够实现实时、自适应的校准和预测，而一项关键创新——通过随机正交投影计算正交Koopman模式——确保了最佳的数据表示。这种数据驱动孪生建模方法是完全自洽的，避免了启发式选择，并通过集成的可解释学习技术增强了可解释性。所提出的方法在激波现象上通过三个复杂度递增的实验进行了演示，并对所生成的数据驱动孪生模型进行了定性分析。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [199] [Estimation of Hemodynamic Parameters via Physics Informed Neural Networks including Hematocrit Dependent Rheology](https://arxiv.org/abs/2508.03326)
> *通过物理信息神经网络估计血流动力学参数，包括血细胞比容依赖性流变学*

*Moises Sierpe, Ernesto Castillo, Hernan Mella, Felipe Galarce* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 物理信息神经网络, 血流动力学, 血细胞比容, 非牛顿流体, 4D流MRI

**Comment:** 

> **TL;DR:** 本文利用物理信息神经网络（PINNs）从合成的4D流MRI数据中估计血流动力学参数，特别关注非牛顿血流和血细胞比容依赖性流变学，结果显示其在准确性和时间分辨率上优于现有方法。

**AI_Comments:** 这项研究创新性地将PINNs应用于估计包括血细胞比容依赖性流变学在内的非牛顿血流动力学参数，解决了观测数据稀疏的逆问题。其在准确性、时间分辨率以及与现有方法结合方面的优势，显示了PINNs在医学图像分析和生物力学模拟领域的巨大潜力，尤其对于个性化医疗和疾病诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在观测数据有限且稀疏的情况下，利用物理信息神经网络（PINNs）解决血流动力学参数的逆问题，特别是考虑非牛顿血流和血细胞比容对血流动力学的影响。

**Method:** 本文使用物理信息神经网络（PINNs）从合成的4D流磁共振成像（MRI）数据中估计平滑的速度和压力场。研究分析了现实主动脉模型中的五个非牛顿动态3D血流案例，涵盖了从贫血到红细胞增多症的血细胞比容范围。为提高状态估计结果，采用了自适应损失平衡、课程训练和现实测量算子等PINNs设计和训练技术。

**Result:** 在血液流变学方面，PINN方法在峰值收缩期准确估计了整体和局部粘度，并为舒张期提供了清晰的模式识别。在质量守恒方面，PINN估计有效地再现了主动脉不同分支的血流分叉，展示了壁面无滑移条件的出色表示，并准确估计了压力降，整个压力场中的相对误差低于5%。测试表明，在准确性和时间分辨率方面，该方法优于最先进的虚拟功能量相对压力（vWERP）估计器。此外，通过PINN计算速度场并将其整合到vWERP框架中，可获得时间超采样和高阶近似，并具有临床可接受的准确性。

**Conclusion:** 物理信息神经网络（PINNs）能够准确有效地估计包括血细胞比容依赖性流变学在内的非牛顿血流动力学参数。该方法在准确性和时间分辨率方面优于现有技术，并且与现有框架结合使用时能进一步提高性能，具有临床应用潜力。

> **ai_Abstract:** 本文利用物理信息神经网络（PINNs）从合成的4D流MRI数据中估计非牛顿血流动力学参数，包括血细胞比容依赖性流变学。研究在现实主动脉模型中分析了不同血细胞比容条件下的血流，并采用多种训练技术优化PINNs。结果表明，PINNs能准确估计粘度、再现血流分叉、满足无滑移条件并准确估计压力降，且在准确性和时间分辨率上优于vWERP方法。将PINN计算的速度场与vWERP结合可进一步提高性能，达到临床可接受的准确性。

> **摘要翻译:** 物理信息神经网络（PINNs）在解决逆问题方面显示出巨大潜力，尤其是在观测数据有限和稀疏的情况下，前提是已知相关的物理方程。我们使用PINNs从合成的4D流磁共振成像（MRI）数据中估计平滑的速度和压力场。我们分析了现实主动脉模型中的五个非牛顿动态3D血流案例，涵盖了从贫血到红细胞增多症的血细胞比容值范围。为了提高状态估计结果，我们考虑了PINNs的各种设计和训练技术，包括自适应损失平衡、课程训练和现实测量算子。在血液流变学方面，PINN方法在峰值收缩期准确估计了整体和局部粘度。它还为舒张期提供了清晰的模式识别。在质量守恒方面，PINN估计有效地再现了主动脉不同分支的血流分叉，展示了壁面无滑移条件的出色表示，并准确估计了压力降，整个压力场中的相对误差低于5%。我们将我们的压力降估计与最先进的虚拟功能量相对压力（vWERP）估计器进行了测试，我们观察到我们的结果在准确性和时间分辨率方面都优于vWERP。此外，我们发现最佳结果是通过使用PINN计算速度场，然后将其整合到vWERP框架中来实现的，从而获得了时间超采样和高阶近似，并具有临床可接受的准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [237] [Two operator splitting methods for three-dimensional stochastic Maxwell equations with multiplicative noise](https://arxiv.org/abs/2508.03390)
> *三维随机麦克斯韦方程乘性噪声下的两种算子分裂方法*

*Liying Zhang, Xinyue Kang, Lihai Ji* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 算子分裂方法, 随机麦克斯韦方程, 乘性噪声, 能量守恒, 数值方法

**Comment:** 

> **TL;DR:** 本文提出了两种能量守恒的算子分裂方法，用于求解带乘性噪声的三维随机麦克斯韦方程，并经理论和数值验证其能量守恒性及一阶收敛性。

**AI_Comments:** 这项研究的创新点在于提出了两种新的能量守恒算子分裂方法，专门用于处理带有乘性噪声的三维随机麦克斯韦方程。能量守恒特性对于数值模拟的稳定性和长期准确性至关重要，特别是在随机偏微分方程领域。方法的结合了确定性与随机部分的独特处理方式，以及理论和数值验证的完整性，增强了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 求解由乘性噪声驱动的三维随机麦克斯韦方程。

**Method:** 本文提出了两种能量守恒的算子分裂方法（分裂方法I和分裂方法II）。这些方法通过算子分裂将随机麦克斯韦方程解耦为简单的一维子系统，确定性部分采用空间紧致差分法和时间中点规则，随机部分采用精确酉解析解。

**Result:** 理论证明两种方法都严格保留了离散能量守恒定律。数值实验充分验证了方法的能量守恒性，并表明两种分裂方法的时间收敛阶数均为一阶。

**Conclusion:** 本文提出的两种算子分裂方法能够有效且能量守恒地求解三维随机麦克斯韦方程，并具有一阶时间收敛性。

> **ai_Abstract:** 本文提出了两种能量守恒的算子分裂方法，用于数值求解具有乘性噪声的三维随机麦克斯韦方程。通过将方程解耦为一维子系统，并结合空间紧致差分、时间中点规则和精确酉解析解，构建了两种具体的分裂方法。理论分析和数值实验均证实了这两种方法严格保持离散能量守恒，并且具有一阶时间收敛性。

> **摘要翻译:** 在本文中，我们提出了两种能量守恒的分裂方法，用于求解由乘性噪声驱动的三维随机麦克斯韦方程。我们使用算子分裂方法将随机麦克斯韦方程解耦为简单的一维子系统，并通过结合空间紧致差分方法和时间离散化中的中点规则处理确定性部分，以及使用精确酉解析解处理随机部分，构建了两种随机分裂方法，即分裂方法I和分裂方法II。理论证明表明，这两种方法都严格保留了离散能量守恒定律。最后，数值实验充分验证了方法的能量守恒性，并证明了两种分裂方法的时间收敛阶数为一阶。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [277] [A matrix preconditioning framework for physics-informed neural networks based on adjoint method](https://arxiv.org/abs/2508.03421)
> *基于伴随法的物理信息神经网络矩阵预处理框架*

*Jiahao Song, Wenbo Cao, Weiwei Zhang* | **Category: math.NA, cs.NA, physics.flu-dyn** | **Updated: 2025-08-05**

**Keywords:** 物理信息神经网络, 矩阵预处理, 伴随法, 雅可比矩阵, 收敛性

**Comment:** 16 pages, 8 figures

> **TL;DR:** 本文提出了一种基于伴随法的矩阵预处理方法，以改善物理信息神经网络（PINNs）的收敛性，成功解决了PINNs在多尺度和高雷诺数问题上的局限性。

**AI_Comments:** 本文的创新之处在于提出了一个将矩阵预处理与伴随法相结合的框架，以提高物理信息神经网络（PINNs）的收敛性。它通过降低雅可比矩阵的条件数和巧妙地解决自动微分与三角求解的兼容性问题，有效克服了PINNs在复杂问题（如多尺度和高雷诺数）上的挑战，对于PINNs在更广泛和复杂应用中的推广具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 物理信息神经网络（PINNs）在解决偏微分方程（PDEs）的正向和逆向问题方面表现出色，但基于卷积神经网络的PINNs在某些情况下仍面临收敛缓慢甚至失败的问题。

**Method:** 本研究提出了一种矩阵预处理方法。具体来说，结合自动微分和矩阵着色计算PDE系统的雅可比矩阵，并通过不完全LU分解构建预处理器。该预处理器用于缩放损失函数中的PDE残差，以降低雅可比矩阵的条件数。为解决自动微分和预处理中三角求解的不兼容性，还设计了一个基于伴随法计算损失函数对网络参数梯度的框架。

**Result:** 数值实验验证了所提出的方法成功且高效地解决了多尺度问题和高雷诺数问题，而在这两种问题中，传统的PINNs未能获得令人满意的结果。

**Conclusion:** 本文提出的基于伴随法的矩阵预处理框架显著改善了物理信息神经网络在解决多尺度和高雷诺数问题时的收敛性和性能。

> **ai_Abstract:** 本文提出了一种基于伴随法的矩阵预处理框架，旨在解决物理信息神经网络（PINNs）在处理偏微分方程（PDEs）时收敛缓慢或失败的问题。该方法通过结合自动微分和矩阵着色计算雅可比矩阵，并利用不完全LU分解构建预处理器来降低雅可比矩阵的条件数。此外，为解决自动微分与三角求解的兼容性问题，引入了基于伴随法计算损失函数梯度。实验证明，该方法能有效解决PINNs在多尺度和高雷诺数问题上的局限性。

> **摘要翻译:** 物理信息神经网络（PINNs）最近已成为解决涉及偏微分方程（PDEs）的正向和逆向问题的流行方法。与全连接神经网络相比，基于卷积神经网络的PINNs在边界条件的硬性强制执行和减少偏导数计算成本方面具有优势。然而，后者仍然存在收敛缓慢甚至在某些场景下失败的问题。在本研究中，我们提出了一种矩阵预处理方法来改善后者的收敛性。具体来说，我们将自动微分与矩阵着色相结合，计算PDE系统的雅可比矩阵，并通过不完全LU分解构建预处理器。随后，我们使用预处理器缩放损失函数中的PDE残差，以降低雅可比矩阵的条件数，这是改善PINNs收敛性的关键。为了克服自动微分和预处理中三角求解之间的不兼容性，我们还设计了一个基于伴随法的框架来计算损失函数对网络参数的梯度。通过数值实验，我们验证了所提出的方法成功且高效地解决了多尺度问题和高雷诺数问题，而在这两种问题中，PINNs都未能获得令人满意的结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [319] [Numerical study on a multi-dimensional pressureless Euler-type model with non-local interactions and chemotaxis for collective cell migration](https://arxiv.org/abs/2508.03439)
> *细胞集体迁移的多维无压欧拉型模型与非局部相互作用和趋化性数值研究*

*Marta Menci, Roberto Natalini, Tommaso Tenna* | **Category: math.NA, cs.NA, 35Q92, 92C17, 65M06, 65M22, 35R30** | **Updated: 2025-08-05**

**Keywords:** 细胞集体迁移, 欧拉型模型, 非局部相互作用, 趋化性, 数值研究

**Comment:** 

> **TL;DR:** 本文对细胞集体迁移的宏观模型进行了数值研究，重点关注一个多维无压欧拉型模型，该模型结合了非局部相互作用和趋化性，并通过参数估计验证了其与微观动力学的吻合性。

**AI_Comments:** 本文的创新点在于提出了一个从微观动力学严格推导而来的多维无压欧拉型模型，并对其进行了数值研究。模型考虑了多种机械相互作用，并扩展到多细胞群，增加了其普适性。通过参数估计分析进行模型验证，增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 对细胞集体迁移的宏观模型进行数值研究，特别是提出并研究一个结合了非局部相互作用和趋化性的多维无压欧拉型模型。

**Method:** 提出了一个从微观动力学严格推导而来的多维无压欧拉型模型，该模型结合了非局部相互作用和趋化性，并对其进行了数值研究。研究了包括吸引-排斥效应在内的不同机械相互作用。将模型扩展到不同相互作用细胞群的情况。通过在特定设置下的参数估计分析，评估了该宏观模型的有效性及其与微观动力学的吻合性。

**Result:** 通过参数估计分析，评估并证实了所提出的宏观模型的有效性及其与微观动力学的吻合性。

**Conclusion:** 所提出的宏观模型是有效的，并与微观动力学表现出良好的一致性。

> **ai_Abstract:** 本文对细胞集体迁移的宏观模型进行了数值研究，提出了一个结合非局部相互作用和趋化性的多维无压欧拉型模型，该模型从微观动力学严格推导而来。研究内容包括不同机械相互作用（如吸引-排斥效应），并将模型扩展到不同细胞群。通过参数估计分析，验证了该宏观模型的有效性及其与微观动力学的吻合性。

> **摘要翻译:** 本文对细胞集体迁移的宏观模型进行了数值研究，重点关注一个多维无压欧拉型模型，该模型结合了非局部相互作用和趋化性，并严格从微观动力学推导而来。研究了不同的机械相互作用，包括吸引-排斥效应。此外，该模型还扩展到不同相互作用细胞群的情况。最后，通过在特定设置下的参数估计分析，评估了该宏观模型的有效性及其与微观动力学的吻合性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [355] [Error Estimates of Semi-Lagrangian Schemes for Diffusive Conservation Laws](https://arxiv.org/abs/2508.03455)
> *扩散守恒律半拉格朗日格式的误差估计*

*Haruki Takemura* | **Category: math.NA, cs.NA, Primary: 65M12, Secondary: 65M06, 65M25** | **Updated: 2025-08-05**

**Keywords:** 半拉格朗日格式, 误差估计, 扩散守恒律, 收敛速率, 高阶插值

**Comment:** 25 pages, 3 figures

> **TL;DR:** 本文提出了用于求解一维非线性扩散守恒律（包括Burgers方程）的全半拉格朗日格式的误差估计，并在L2范数和Hs范数下建立了收敛速率，数值结果与理论分析一致。

**AI_Comments:** 这项工作在分析半拉格朗日格式的误差方面具有重要意义，特别是在处理扩散守恒律时。它为理解这些方案的精度和稳定性提供了严格的理论基础，并通过数值验证增强了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 针对一维非线性扩散守恒律（包括Burgers方程）的初始值问题，研究全半拉格朗日格式的误差估计。

**Method:** 采用高阶插值算子（如样条插值和Hermite插值）的全半拉格朗日格式，并对插值算子施加特定假设。通过理论分析建立了收敛速率，并用数值结果验证。

**Result:** 在L2范数下建立了 $ O(\Delta t + h^{2 s} / \Delta t) $ 的收敛速率，在Hs范数下建立了 $ O(\Delta t + h^{s} / (\Delta t)^{1/2} + h^{2s} / \Delta t) $ 的收敛速率，其中 $ h $ 是空间网格尺寸， $ \Delta t $ 是时间步长，且使用了 $ (2s - 1) $ 次的样条或Hermite插值算子。数值结果与理论分析一致。

**Conclusion:** 建立了全半拉格朗日格式在L2和Hs范数下的收敛速率，并通过数值实验验证了理论分析的正确性。

> **ai_Abstract:** 本文研究了一维非线性扩散守恒律（包括Burgers方程）的全半拉格朗日格式的误差估计。通过对高阶插值算子（如样条和Hermite插值）施加特定假设，推导了在L2和Hs范数下的收敛速率公式。数值实验结果验证了理论分析的准确性。

> **摘要翻译:** 我们提出了使用高阶插值算子的全半拉格朗日格式的误差估计，该格式用于求解一维非线性扩散守恒律的初值问题，包括 Burgers 方程。我们对插值算子施加了某些假设，这些假设通过样条插值和 Hermite 插值都得到了满足。我们建立了空间网格尺寸 $ h $ 和时间步长 $ \Delta t $ 在 $ L^2 $ 范数下为 $ O(\Delta t + h^{2 s} / \Delta t) $ 以及在 $ H^s $ 范数下为 $ O(\Delta t + h^{s} / (\Delta t)^{1/2} + h^{2s} / \Delta t) $ 的收敛速率，其中采用了 $ (2s - 1) $ 次的样条或 Hermite 插值算子。数值结果与理论分析一致。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [383] [Homogenization rates of beam lattices to micropolar continua](https://arxiv.org/abs/2508.03512)
> *梁格架到微极连续体的均质化速率*

*Eric T. Chung, Kuang Huang, Changqing Ye* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 梁格架, 均质化, 微极弹性, 收敛速率, 舒尔补

**Comment:** 

> **TL;DR:** 本文严谨分析了梁格架到微极连续体的均质化过程，并首次定量给出了均质化误差的收敛速率估计。

**AI_Comments:** 本文创新性地将傅里叶变换和舒尔补相结合，对梁格架的均质化过程进行了严谨的数学分析，首次定量给出了均质化误差的收敛速率估计，填补了该领域的一个空白。同时，发现了高频区域的特殊性，对理解微极连续体的行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 工程界对梁格架均质化过程的误差估计通常是定性的，缺乏定量分析。

**Method:** 研究从周期性边界条件下三角形格架上的力学问题出发，通过傅里叶变换将其简化为频域方程。关键技术是利用舒尔补对位移和旋转场进行解耦。通过分析格架和连续体模型中舒尔补的强制性，推导收敛速率估计。并通过数值实验进行验证。

**Result:** 得到了梁格架均质化后的偏微分方程形式的连续体模型。发现在高频区域，由于梁的额外旋转自由度，梁格架的均质化与经典周期均质化理论不同。成功推导了均质化误差的收敛速率估计，并通过数值实验验证了其最优性。

**Conclusion:** 本文对梁格架到微极连续体的均质化过程进行了严谨的定量分析，首次获得了均质化误差的收敛速率估计，并揭示了高频区域的特殊性。

> **ai_Abstract:** 本文严谨地分析了梁格架均质化为微极连续体的过程，旨在弥补工程领域缺乏定量误差估计的不足。研究从三角形格架上的周期性问题出发，利用傅里叶变换和舒尔补技术，成功解耦位移和旋转场，并推导了均质化误差的收敛速率估计。数值实验验证了这些估计的最优性，并揭示了在高频区域，梁的旋转自由度导致均质化行为异于经典理论。

> **摘要翻译:** 当具有梁模型边缘的机械格架的尺寸趋近于零时，它会均质化为一个连续体模型，该模型表现出与经典柯西弹性力学不同的不寻常力学特性，被称为微极弹性。通常，均质化过程在工程领域是定性的，缺乏定量的均质化误差估计。在本文中，我们严谨地分析了梁格架到连续体的均质化过程。我们的方法始于一个在周期性边界条件下定义的三角形格架上的工程力学问题。通过应用傅里叶变换，我们将问题简化为频域中的一系列方程。当格架尺寸趋近于零时，这会产生一个以偏微分方程形式存在的均质化模型，并带有周期性边界条件。如果频域中的外部条件仅在低频模式下非零，则此过程可以很容易地被证明是合理的。然而，通过数值实验，我们发现，超出低频范围，由于梁中额外的旋转自由度，梁格架的均质化与经典周期均质化理论不同。我们分析中的一个关键技术是通过线性代数操作（称为舒尔补）实现位移场和旋转场的解耦。通过专门的分析，我们建立了格架和连续体模型中舒尔补的强制性，这使我们能够推导出均质化误差的收敛速率估计。数值实验验证了均质化速率估计的最优性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [495] [A three-field Multiscale Method](https://arxiv.org/abs/2404.16978)
> *一种三场多尺度方法*

*Franklin de Barros, Alexandre L. Madureira, Frédéric Valentin* | **Category: math.NA, cs.NA** | **Updated: 2025-08-04**

**Keywords:** 多尺度方法, 三场公式, Darcy模型, 有限元方法, 对称正定

**Comment:** 

> **TL;DR:** 本文提出了一种基于三场域分解方法的多尺度混合杂交方法（MH$^2$M），用于Darcy模型，该方法能得到对称正定公式，并展示了其稳定性和收敛性。

**AI_Comments:** 本文在经典的三场域分解方法基础上，为Darcy模型提出了一种创新的多尺度有限元方法。其亮点在于推导出了对称正定公式，这对于数值求解的稳定性和效率至关重要。研究结果验证了其稳定性和收敛性，并建立了与其他方法的联系，显示出其在多尺度问题求解中的潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文基于F. Brezzi和L. D. Marini提出的《一种三场域分解方法》这篇开创性论文，该论文引入了椭圆偏微分方程的三场公式，在此基础上提出了一种新的多尺度方法。

**Method:** 本文提出了一种多尺度有限元方法——多尺度混合杂交方法（MH$^2$M），用于Darcy模型。该方法经过一系列形式操作，能够得到一个仅依赖于解的迹的对称正定公式。

**Result:** 本文展示了针对一系列有限元空间的稳定性和收敛性结果，并建立了与其他多尺度有限元方法之间的关系。

**Conclusion:** 本文提出的多尺度混合杂交方法（MH$^2$M）在Darcy模型中表现出良好的稳定性和收敛性，并与其他多尺度有限元方法存在关联。

> **ai_Abstract:** 本文基于Brezzi和Marini提出的三场域分解方法，针对Darcy模型提出了一种新型多尺度有限元方法——多尺度混合杂交方法（MH$^2$M）。该方法通过形式操作，能够推导出一个仅依赖于解的迹的对称正定公式。研究结果表明，该方法对于一系列有限元空间具有稳定性和收敛性，并且与现有的其他多尺度有限元方法存在关联。

> **摘要翻译:** 《一种三场域分解方法》是F. Brezzi和L. D. Marini的一篇开创性论文的标题，该论文引入了椭圆偏微分方程的三场公式。在此基础上，我们提出了用于Darcy模型的多尺度混合杂交方法（MH$^2$M），这是一种多尺度有限元方法，经过一系列形式操作后，可以得到一个仅依赖于解的迹的对称正定公式。我们展示了一系列有限元空间的稳定性和收敛性结果，并建立了与其他多尺度有限元方法的关系。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [520] [Weighted sampling recovery of functions with mixed smoothness](https://arxiv.org/abs/2405.16400)
> *混合光滑函数加权采样恢复*

*Dinh Dũng* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 加权采样, 混合光滑度, 稀疏网格, 采样n-宽度, 函数恢复

**Comment:** arXiv admin note: text overlap with arXiv:2309.04994

> **TL;DR:** 本文研究了两种加权设置下，用于混合光滑函数近似恢复的稀疏网格线性采样算法及其最优性，并构建了实现正确收敛速度的算法。

**AI_Comments:** 本文针对混合光滑函数在不同加权空间中的恢复问题，提出了创新的稀疏网格线性采样算法。其亮点在于区分了两种不同的加权设置，并为每种设置设计了特定的算法。同时，通过构造性方法在一维情况下以及非构造性方法在高维情况下实现了理论上的最优收敛速度，这在理论和应用上都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究稀疏网格线性采样算法及其最优性，用于从一组n个采样值中近似恢复$\\mathbb{R}^d$上具有混合光滑度的函数。

**Method:** 研究了两种不同设置下的稀疏网格线性采样算法：(i) 函数在加权Sobolev空间$W^r_{p,w}(\\mathbb{R}^d)$中，误差由加权Lebesgue空间$L_{q,w}(\\mathbb{R}^d)$的范数衡量；(ii) 函数在带测度的Sobolev空间$W^r_p(\\mathbb{R}^d; \\mu_w)$中，误差由带测度的Lebesgue空间$L_q(\\mathbb{R}^d; \\mu_w)$的范数衡量。通过相关的采样n-宽度研究了线性采样算法的最优性。构建了针对设置(i)和(ii)完全不同的稀疏网格线性采样算法。在高维情况下($d\\ge 2$)的设置(ii)中，通过非构造性方法实现了收敛速度。

**Result:** 构建的稀疏网格线性采样算法为相应的采样n-宽度提供了上限。在一维情况下，这些算法实现了采样宽度的正确收敛速度。在设置(ii)的高维情况($d\\ge 2$)中，对于$1\\le q \\le 2 \\le p \\le \\infty$，通过非构造性方法也实现了采样n-宽度的正确收敛速度。

**Conclusion:** 本文构建的稀疏网格线性采样算法在两种不同的加权设置下，对于混合光滑函数的近似恢复表现出良好的性能，并在某些情况下实现了采样n-宽度的最优收敛速度。

> **ai_Abstract:** 本文研究了在两种不同加权设置下，用于近似恢复具有混合光滑度函数的稀疏网格线性采样算法及其最优性。针对加权Sobolev空间和带测度Sobolev空间中的函数，构建了不同的采样算法，并分析了其在采样n-宽度方面的最优性。结果表明，所构建的算法在一维情况下能实现正确的收敛速度，在高维情况下（特定参数范围）通过非构造性方法也能达到正确的收敛速度。

> **摘要翻译:** 我们研究了稀疏网格线性采样算法及其最优性，用于从一组n个采样值中近似恢复$\\mathbb{R}^d$上具有混合光滑度的函数，分为两种不同的设置：(i) 待恢复函数位于混合光滑度的加权Sobolev空间$W^r_{p,w}(\\mathbb{R}^d)$中，近似误差通过加权Lebesgue空间$L_{q,w}(\\mathbb{R}^d)$的范数衡量；(ii) 待恢复函数位于混合光滑度的带测度Sobolev空间$W^r_p(\\mathbb{R}^d; \\mu_w)$中，近似误差通过带测度的Lebesgue空间$L_q(\\mathbb{R}^d; \\mu_w)$的范数衡量。其中，函数w，一个张量积Freud型权重，是设置(i)中的权重，也是设置(ii)中测度$\\mu_w$的密度函数。线性采样算法的最优性通过相关的采样n-宽度进行研究。我们构建了针对设置(i)和(ii)完全不同的稀疏网格线性采样算法，这些算法给出了相应采样n-宽度的上限。我们证明，在一维情况下，这些算法实现了采样宽度的正确收敛速度。在设置(ii)的高维情况($d\\ge 2$)中，对于$1\\le q \\le 2 \\le p \\le \\infty$，我们还通过非构造性方法实现了采样n-宽度的正确收敛速度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [545] [Shear-flexible geometrically exact beam element based on finite differences](https://arxiv.org/abs/2410.04915)
> *基于有限差分的剪切柔性几何精确梁单元*

*Milan Jirasek, Martin Horak, Emma La Malfa Ribolla, Chiara Bonvissuto* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 梁单元, 几何精确, 有限差分, 剪切变形, 屈曲

**Comment:** 42 pages, 18 figures

> **TL;DR:** 本文提出了一种基于有限差分的二维剪切柔性几何精确梁单元，该单元通过将边界值问题转换为初值问题并利用中心差分，实现了高精度和高效的计算，并能有效模拟梁的屈曲行为。

**AI_Comments:** 该论文的创新之处在于将剪切变形和分布式载荷纳入几何精确梁单元中，并通过结合有限差分和射击法，实现了高效和高精度的求解。其优势在于能够在单元层面通过细化网格有效降低误差，同时保持较低的全局自由度，并通过直接使用全局坐标避免了转换，提高了计算效率。这对于复杂结构分析，特别是屈曲行为的精确预测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在扩展作者之前的工作，将剪切变形以及沿梁分布的力和力矩的影响纳入其几何精确梁单元模型中。

**Method:** 该方法采用基于柔性的公式，结合运动学方程、反向截面方程和平衡方程的积分形式。由此产生的三组一阶微分方程通过有限差分进行离散化，并使用射击法将边界值问题转换为初值问题。文中还提出了Reissner和Ziegler两种截面方程模型进行比较和测试。

**Result:** 所提出的方法具有高精度和二次收敛性（当空间离散化细化时），易于建模沿单元变化的刚度（如刚性接头偏移），并能高效准确地表征屈曲和屈曲后行为。由于控制方程的特殊结构，即使一阶导数采用中心差分近似，该方案仍保持显式。

**Conclusion:** 所提出的基于有限差分的剪切柔性几何精确梁单元在处理剪切变形和分布式载荷方面表现出高精度和高效性，并能有效分析梁/柱的稳定性和屈曲行为。

> **ai_Abstract:** 本文提出了一种二维剪切柔性几何精确梁单元，扩展了现有工作，并纳入了剪切变形和分布式载荷效应。该模型采用基于柔性的公式，结合运动学和平衡方程，并通过有限差分和射击法离散化和求解。研究比较了Reissner和Ziegler两种截面模型，并验证了该方法在处理变刚度、屈曲和屈曲后行为方面的高精度、高效率和二次收敛性。

> **摘要翻译:** 所提出的二维几何精确梁单元通过包含剪切变形以及沿梁作用的分布力和力矩的影响，扩展了我们之前的工作。通用的基于柔性的公式利用运动学方程结合反向截面方程和平衡方程的积分形式。由此产生的三组一阶微分方程通过有限差分进行离散化，并使用射击法将边界值问题转换为初值问题。由于控制方程的特殊结构，即使一阶导数采用中心差分近似，该方案仍保持显式，从而实现高精度。所采用方法的主要优点是，通过细化单元级别的有限差分计算网格，可以有效降低误差，同时保持全局自由度数量较低。通过直接处理全局中心线坐标和相对于全局轴线的截面倾斜作为单元级别的主要未知量，从而避免了局部和全局坐标之间的转换，也提高了效率。文中介绍了Reissner和Ziegler两种截面方程公式并进行了比较。特别是，研究了轴向加载梁/柱的稳定性，并讨论了与Haringx和Engesser稳定性理论的联系。两种方法都在一系列数值示例中进行了测试，这些示例说明了（i）当空间离散化细化时，具有二次收敛的高精度，（ii）沿单元（例如刚性接头偏移）可变刚度的轻松建模，（iii）屈曲和屈曲后行为的高效准确表征。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [578] [A practical recipe for variable-step finite differences via equidistribution](https://arxiv.org/abs/2412.05598)
> *通过等分布实现变步长有限差分的一种实用方法*

*Mário B. Amaro* | **Category: math.NA, cs.NA, physics.comp-ph** | **Updated: 2025-08-05**

**Keywords:** 有限差分, 非均匀网格, 等分布, 薛定谔方程, 实用方法

**Comment:** 6 pages, 2 figures

> **TL;DR:** 本文提供了一个关于如何在非均匀网格上应用变步长有限差分的实用工作流程，通过等分布方法提高局部特征函数的解析度，并附有参考实现。

**AI_Comments:** 本文虽然不声称创新性，但其价值在于提供了一个清晰、可复现的实用工作流程，将分散的、广泛使用的有限差分和网格生成思想整合在一起。对于需要解决涉及局部特征或高梯度问题的研究人员和工程师来说，这是一个非常有用的“操作指南”，能够有效地提高计算效率和精度，而无需深入复杂的理论细节。其提供的参考实现也大大降低了使用门槛。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在将广泛使用的非均匀网格上有限差分的概念整合为一个单一、即用型的实用方法，作为一份操作指南，而不是提出新的方法。

**Method:** 该方法描述了一个短小、可复现的工作流程，用于在由正权重函数g确定的非均匀网格上应用有限差分。网格通过等分布获得，即将均匀计算坐标映射到物理空间，在多维情况下通过相应的变扩散（调和）映射。然后，使用标准的三点中心模板在不均匀间距上计算一阶和二阶导数。

**Result:** 通过在均匀和可变网格上求解谐振子的二维时间无关薛定谔方程，结果显示在不增加矩阵大小的情况下，局部特征函数的解析度得到了预期的改进。

**Conclusion:** 本文旨在作为一份操作指南，而非提出一种新方法，它将广泛使用的思想整合为一个单一、即用型的实用方法，不声称任何新颖性。

> **ai_Abstract:** 本文提出了一种在由正权重函数g确定的非均匀网格上应用变步长有限差分的实用方法。通过等分布技术，将均匀计算坐标映射到物理空间，并结合标准的三点中心模板进行导数计算。文章收集了相关公式，阐述了对权重函数的约束，并提供了一个小型参考实现。通过求解二维时间无关薛定谔方程的案例，展示了该方法在不增加计算成本的情况下，有效提高了局部特征函数的解析度。该工作旨在提供一个实用的操作指南，整合现有技术，而非提出新的理论。

> **摘要翻译:** 我们描述了一个短小、可复现的工作流程，用于在由正权重函数g确定的非均匀网格上应用有限差分。网格通过等分布获得，即将均匀计算坐标$\\xi\\in[0,1]$通过累积积分$S(x)=\\int_a^x\!1/g(s)\,ds$及其逆函数映射到物理空间，在多维情况下通过相应的张量$P=(1/g)I$的变扩散（调和）映射。然后，我们使用标准的三点中心模板在不均匀间距上计算一阶和二阶导数。我们收集了公式，阐述了对g的温和约束（正性、有界性、可积性），并提供了一个小型参考实现。最后，我们针对谐振子在均匀和可变网格上求解二维时间无关薛定谔方程，结果显示在不增加矩阵大小的情况下，局部特征函数的解析度得到了预期的改进。我们意图将这份笔记作为一份操作参考，而非一种新方法，它将广泛使用的思想整合为一个单一、即用型的实用方法，不声称任何新颖性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [613] [Surrogate modeling of resonant behavior in scattering problems through adaptive rational approximation and sketching](https://arxiv.org/abs/2503.10194)
> *基于自适应有理逼近和草图的散射问题共振行为代理建模*

*Davide Pradovera, Ralf Hiptmair, Ilaria Perugia* | **Category: math.NA, cs.NA, math-ph, math.MP, 35B34, 35J05, 41A20, 65N38** | **Updated: 2025-08-05**

**Keywords:** 散射问题, 共振行为, 有理逼近, 代理建模, 场放大

**Comment:** 

> **TL;DR:** 该研究提出了一种通过有理逼近和草图技术来识别散射问题中（近似）共振行为的新算法，以构建“场放大”的代理模型。该方法具有离散化无关性、无需非实数波数计算以及自适应采样等特点。数值实验表明，一种标准方法和一种混合方法表现最佳，具体选择取决于对精度或效率的侧重。

**AI_Comments:** 该研究提出了一种创新的方法来解决散射问题中的共振行为识别问题，通过有理逼近和草图技术构建代理模型，这在理论和实践上都具有重要意义。其离散化无关性和无需非实数波数计算的特点进一步增强了方法的通用性和实用性。然而，文中提到的“标准”方法和“混合”方法的具体细节以及它们在不同场景下的适用性还需要更深入的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 识别散射问题中的（近似）共振行为，并构建“场放大”的代理模型。

**Method:** 提出基于有理逼近的算法，包括直接对解算子或其随机“草图”版本进行有理逼近的标准方法，以及结合有理逼近辅助求根和径向基函数逼近的混合方法。

**Result:** 数值实验表明，两种方法（一种标准方法，一种混合方法）表现最佳，具体取决于对精度或效率的侧重。

**Conclusion:** 所提出的基于有理逼近和草图的方法能够有效地识别散射问题中的共振行为，并构建代理模型，且具有离散化无关性、无需非实数波数计算和自适应采样等优点。

> **ai_Abstract:** 本文提出了一种新颖的算法，利用有理逼近和草图技术来识别散射问题中的共振行为，并构建“场放大”的代理模型。该方法具有离散化无关性、无需非实数波数计算以及自适应采样等优点。通过二维散射体的数值实验表明，一种标准方法和一种混合方法表现最佳，具体选择取决于对精度或效率的侧重。

> **摘要翻译:** 本文描述了用于识别散射问题中（近似）共振行为的新颖算法。我们的方法依赖于有理逼近，旨在构建我们称之为“场放大”的代理模型，场放大被定义为散射问题解算子的范数，我们通过边界积分方程来表达它。为了给我们的技术提供理论基础，我们首先推导了将场放大与定义散射问题的算子的谱性质联系起来的结果。然后使用这些结果来证明有理逼近在代理建模任务中的使用是合理的。我们提出的一些方法以“标准”方式应用有理逼近，直接为解算子或为了计算效率而对其随机“草图”版本构建有理逼近。我们的其他“混合”方法更具创新性，将有理逼近辅助求根与径向基函数逼近相结合。我们方法的三项关键特征是（i）它们不依赖于用于离散化散射问题的策略，（ii）它们不需要任何涉及非实数波数的计算，并且（iii）它们可以通过使用自适应采样策略来适应不同的设置。我们进行了一些涉及二维散射体的数值实验来比较我们的方法。在我们的测试中，我们的两种方法（一种标准方法，一种混合方法）成为最佳执行者，其中一种或另一种方法更受青睐，具体取决于对精度或效率的侧重。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [640] [Full Vectorial Maxwell Equations with Continuous Angular Indices](https://arxiv.org/abs/2508.02675)
> *全矢量麦克斯韦方程与连续角向指标*

*Mustafa Bakr* | **Category: math.NA, cs.NA, math-ph, math.MP, physics.class-ph** | **Updated: 2025-07-10**

**Keywords:** 麦克斯韦方程组, 连续角向指标, 广义谱积分, 奇异行为, 有限能量

**Comment:** 

> **TL;DR:** 该论文提出了一种在柱坐标和球坐标下求解麦克斯韦方程组的数学框架，该框架使用广义谱积分，允许连续的角向指标，可以处理在几何中心处具有奇异行为但能量有限的电磁场。

**AI_Comments:** 这项工作在处理具有奇异行为的电磁场方面具有重要意义，特别是通过引入连续角向指标和广义谱积分。然而，实际应用的复杂性和计算成本可能是一个挑战。

<details>
  <summary>Details</summary>

**Motivation:** 标准的离散谐波分解无法处理具有奇异行为但能量有限的电磁场，需要一种新的数学框架来解决这个问题。

**Method:** 使用广义谱积分将离散谐波分解扩展到连续谱表示，并在加权 Sobolev 空间中研究了具有连续角向指标 $\ell, m \in \mathbb{R}$ 的解的存在性和唯一性，证明了当 $\ell > -\frac{1}{2}$ 时有限能量，并通过双正交函数系统构建了显式谱核。

**Result:** 该框架能够处理具有连续角向指标的麦克斯韦方程组，可以捕捉到在几何中心处具有奇异行为但能量有限的电磁场。论文还对奇异场行为进行了渐近分析，研究了谱近似的收敛率，并通过 Galerkin 投影方法和数值谱积分验证了理论框架。

**Conclusion:** 该论文提出的数学框架能够有效地处理具有连续角向指标的麦克斯韦方程组，为理解和计算具有奇异行为的电磁场提供了新的途径。

> **ai_Abstract:** 本文提出了一种用于求解具有连续角向指标的柱坐标和球坐标麦克斯韦方程组的数学框架。该框架使用广义谱积分进行连续谱表示，能够处理在几何中心处具有奇异行为但能量有限的电磁场。论文研究了具有连续角向指标的解的存在性和唯一性，证明了有限能量的条件，并通过双正交函数系统构建了谱核。此外，还进行了奇异场行为的渐近分析，研究了收敛率，并通过数值方法验证了该框架。

> **摘要翻译:** 本文提出了一个在柱坐标和球坐标几何中求解麦克斯韦方程组的数学框架，该框架具有连续的角向指标。我们超越了标准的离散谐波分解，采用了广义谱积分的连续谱表示，能够捕捉到在几何中心处表现出奇异行为但能量有限的电磁场。对于连续角向指标 $\ell, m \in \mathbb{R}$，我们遵循 ~	fine\cite{adams2003, reed1975} 中建立的框架，在加权 Sobolev 空间 $H^s_{\alpha(\ell,m)}(\Omega)$ 中研究了解的存在性和唯一性，证明了当 $\ell > -\frac{1}{2}$ 时有限能量，并通过双正交函数系统构建了显式谱核。该框架包括具有连续方位角指标 $\nu \in (0,1)$ 的可分离柱坐标模式和通过矢量旋度算子耦合场分量的不可分离球坐标模式。我们提出了奇异场行为的渐近分析，研究了谱近似的收敛率，并通过 Galerkin 投影方法和数值谱积分验证了理论框架。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [647] [When surface evolution meets Fokker-Planck equation: a novel tangential velocity model for uniform parametrization](https://arxiv.org/abs/2508.02676)
> *当曲面演化遇到Fokker-Planck方程：一种用于均匀参数化的新型切向速度模型*

*Jiangong Pan, Guozhi Dong, Hailong Guo, Zuoqiang Shi* | **Category: math.NA, cs.NA, math-ph, math.MP** | **Updated: 2025-07-11**

**Keywords:** 曲面演化, Fokker-Planck方程, 切向速度, 无网格方法, 均匀参数化

**Comment:** 

> **TL;DR:** 本文提出一种基于Fokker-Planck方程生成切向速度的新方法，以解决曲面演化模拟中点聚簇问题，实现均匀参数化，并在无网格框架下展示了其鲁棒性和有效性。

**AI_Comments:** 该论文的创新点在于将Fokker-Planck方程引入到曲面演化中，通过生成人工切向速度来解决点聚簇导致的数值不稳定性问题。其采用的无网格框架增强了方法的灵活性和对非结构化数据的处理能力，对于几何演化模拟领域具有重要意义。该方法有望提高数值模拟的稳定性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 在模拟曲面几何演化时，点的不均匀聚簇会导致数值不稳定。

**Method:** 提出一种新型人工切向速度方法。该切向速度由Fokker-Planck方程控制的曲面密度场生成，用于引导点分布。开发了利用曲面Kullback-Leibler散度进行密度函数匹配的目标分布算法。数值方法在完全无网格框架下，使用移动最小二乘近似，无需网格生成，可灵活处理非结构化点云数据。

**Result:** 广泛的数值实验表明，该方法在各种曲面演化问题（包括平均曲率流）中具有鲁棒性、准确性和有效性。

**Conclusion:** 通过引入基于Fokker-Planck方程的人工切向速度模型，本文成功解决了曲面演化中的点聚簇问题，实现了均匀参数化，并提供了一种鲁棒、准确且有效的无网格数值方法。

> **ai_Abstract:** 本文提出一种解决曲面几何演化中点聚簇问题的新型人工切向速度模型。该模型利用Fokker-Planck方程生成切向速度以引导点分布，并通过Kullback-Leibler散度实现目标分布匹配。方法采用无网格框架下的移动最小二乘近似，无需网格生成，适用于非结构化点云数据。实验证明该方法在多种曲面演化问题中表现出良好的鲁棒性、准确性和有效性。

> **摘要翻译:** 在模拟曲面几何演化时，一个常见问题是意外的点聚簇可能导致数值不稳定。针对此问题，我们提出了一种新颖的人工切向速度方法。该人工切向速度由Fokker-Planck方程控制的曲面密度场生成，用于引导点分布。利用密度函数的曲面Kullback-Leibler散度，开发了一种目标分布匹配算法。该数值方法在完全无网格框架下，使用移动最小二乘近似进行构建，从而消除了网格生成的需要，并允许灵活处理非结构化点云数据。进行了广泛的数值实验，以证明所提出方法在各种曲面演化问题（包括平均曲率流）中的鲁棒性、准确性和有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [648] [Error estimates for numerical approximations of a nonlinear gradient flow model](https://arxiv.org/abs/2505.13929)
> *非线性梯度流模型数值逼近的误差估计*

*Jerome Droniou, Kim-Ngan Le, Huateng Zhu* | **Category: math.NA, cs.NA** | **Updated: 2025-08-05**

**Keywords:** 非线性梯度流, 梯度离散化方法, 误差估计, 数值分析, 隐式格式

**Comment:** 

> **TL;DR:** 本文对非线性梯度流模型进行了数值分析，提出了一种全离散隐式格式，并使用梯度离散化方法（GDM）证明了其解的存在性、唯一性、稳定性和一致性，同时建立了误差估计，并通过数值结果进行了验证。

**AI_Comments:** 该论文的创新之处在于将统一的梯度离散化方法（GDM）应用于非线性梯度流模型，并为所提出的新型隐式格式建立了一套全面的理论基础，包括解的存在性、唯一性、稳定性、一致性以及误差估计。这对于复杂非线性问题的鲁棒数值分析具有重要贡献。GDM的运用尤其值得关注，因为它能够涵盖多种数值方法。

<details>
  <summary>Details</summary>

**Motivation:** 对一个可被视为抛物线型最小曲面问题或正则化全变分流的非线性梯度流模型进行数值分析，并建立其数值逼近的误差估计。

**Method:** 采用梯度离散化方法（GDM）对模型进行分析。提出了一种模型的全离散隐式格式，并证明了该格式解的存在性和唯一性。分析了该格式的稳定性和一致性。建立了误差估计。提供了基于协调和非协调P1有限元的数值结果。

**Result:** 提出了一种全离散隐式格式。证明了该格式解的存在性和唯一性。分析了该格式的稳定性和一致性。建立了误差估计。提供了数值结果以支持理论分析。

**Conclusion:** 本文成功提出并分析了一种用于非线性梯度流模型数值逼近的全离散隐式格式，利用GDM框架证明了其关键性质（存在性、唯一性、稳定性、一致性）并建立了误差估计，数值结果也支持了这些发现。

> **ai_Abstract:** 本文针对非线性梯度流模型（可视为抛物线型最小曲面问题或正则化全变分流）的数值逼近进行了研究。论文采用梯度离散化方法（GDM），提出了一种全离散隐式格式，并严格证明了其解的存在性和唯一性。同时，对该格式的稳定性和一致性进行了分析，并建立了重要的误差估计。这些理论发现得到了基于协调和非协调P1有限元的数值结果的支持。

> **摘要翻译:** 我们对非线性梯度流进行了数值分析，该梯度流可被视为抛物线型最小曲面问题或正则化全变分流，并使用了梯度离散化方法（GDM）。GDM是一个统一的收敛性分析框架，涵盖了协调和非协调数值方法，例如协调和非协调有限元、两点通量近似等。本文提出了一种模型的全离散隐式格式，证明了该格式解的存在性和唯一性，分析了该格式的稳定性和一致性，并建立了误差估计。还提供了基于协调和非协调P1有限元的数值结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [675] [Automated $h$-adaptivity for finite element approximations of the Falkner-Skan equation](https://arxiv.org/abs/2508.02677)
> *有限元方法求解 Falkner-Skan 方程的自动化 h-自适应*

*B. Veena S. N. Rao* | **Category: math.NA, cs.NA** | **Updated: 2025-07-14**

**Keywords:** h-自适应, 有限元方法, Falkner-Skan 方程, 边界层, 皮摩擦系数

**Comment:** 

> **TL;DR:** 本文提出了一种自动化 h-自适应有限元方法来求解 Falkner-Skan 方程，使用 Kelly 误差估计器来控制网格自适应，能够精确高效地解析边界层行为，并计算了不同压力梯度下的皮摩擦系数。

**AI_Comments:** 这项工作在自动化自适应有限元方法领域取得了进展，特别是在解决具有挑战性的非线性边界层问题方面。 Kelly 误差估计器的使用是为了提高计算效率和准确性，这对于捕捉流动现象至关重要。然而，该研究的范围可能限于特定的流动参数，并且可能需要进一步的验证来评估其在更广泛条件下的性能。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在开发一种自动化 h-自适应有限元方法，以解决 Falkner-Skan 方程，重点关注边界层行为和皮摩擦系数的精确计算。

**Method:** 本文采用自动化 h-自适应有限元方法，并使用 Kelly 误差估计器（基于单元间梯度的跳跃）来控制网格自适应。

**Result:** 该方法能够准确高效地解析 Falkner-Skan 流的边界层行为，并成功计算了各种楔形流动参数（包括有利和不利压力梯度）下的皮摩擦系数，证明了该方法在处理这类非线性边界层问题上的鲁棒性和准确性。

**Conclusion:** 自动化 h-自适应有限元方法能够鲁棒且准确地解决 Falkner-Skan 方程这类非线性边界层问题，特别是在计算皮摩擦系数方面。

> **ai_Abstract:** 本文介绍了一种用于求解 Falkner-Skan 方程的自动化 h-自适应有限元方法。该方法利用 Kelly 误差估计器来优化网格，以精确捕捉边界层行为和计算皮摩擦系数。研究结果表明，该方法对于不同压力梯度的流动条件都具有鲁棒性和准确性。

> **摘要翻译:** 本文详细介绍了一种用于数值求解 Falkner-Skan 方程的 h-自适应有限元方法的开发和应用。a posteriori 误差估计控制着网格的自适应性，特别是已建立的 Kelly 误差估计器，它利用了跨单元梯度的跳跃。该方法的实现能够准确有效地解析 Falkner-Skan 流所特有的边界层行为。数值解获得了各种楔形流动参数，包括有利和不利的压力梯度。本研究的一个关键重点是在整个多样化的流动条件下精确计算作为边界层分析关键参数的皮摩擦系数。结果进行了呈现和讨论，证明了该自适应有限元方法在处理此类非线性边界层问题上的鲁棒性和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [683] [Interpolation in Polynomial Spaces of p-Degree](https://arxiv.org/abs/2507.13640)
> *p次多项式空间的插值*

*Phil-Alexander Hofmann, Damar Wicaksono, Michael Hecht* | **Category: math.NA, cs.NA, 65D15** | **Updated: 2025-08-05**

**Keywords:** 快速牛顿变换,多项式空间,牛顿插值,计算复杂度,敏感性分析,$\\ell^p$范数,下闭集,空间维度,张量积空间,活性得分,超指数衰减,p-Degree Polynomial Spaces,Fast Newton Transform,Newton Interpolation,Complexity Analysis,Sensitivity Analysis,$\\ell^p$ norm,Downward Closed Sets,Tensor Product Spaces,Activity Scores,Super-exponential Decay

**Comment:** 

> **TL;DR:** 该论文分析了多变量牛顿插值算法（FNT）在特定多项式空间（$\Pi_{m,n,p}$）中的性能，该空间由$\\ell^p$范数小于n的多指标定义。结果表明，与张量积空间（$\\Pi_{m,n,\infty}$）相比，$\\Pi_{m,n,p}$可以显著降低计算复杂度，尤其是在m\lesssim n^p时。论文还通过计算敏感性分析中的活性得分展示了FNT的效率。

**AI_Comments:** 该研究提出了一种改进的牛顿插值算法（FNT），并通过理论分析和实例证明了其在特定多项式空间上的效率提升。研究的创新点在于定义了一类新的多项式空间$\\Pi_{m,n,p}$，并揭示了其在降低插值计算复杂度方面的优势，特别是在高维情况下。然而，论文可能需要进一步探讨该方法在更广泛应用场景下的鲁棒性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 介绍了一种用于任意下闭多项式空间的多变量牛顿插值算法（FNT），并分析了其在特定$\\ell^p$范数定义的下闭集$A_{m,n,p}$上的性能。

**Method:** 分析了快速牛顿变换（FNT）算法在由$\\ell^p$范数小于n的多指标定义的下闭集$A_{m,n,p}$上的时间复杂度，并将其与张量积空间$\\Pi_{m,n,\infty}$进行了比较。

**Result:** FNT算法在$\\Pi_{m,n,p}$空间上的时间复杂度为$\\mathcal{O}(|A_{m,n,p}|mn)$。与张量积空间$\\Pi_{m,n,\infty}$相比，$\\Pi_{m,n,p}$可以将时间复杂度降低一个因子$\\rho_{m,n,p}$，当m\lesssim n^p时，该因子随空间维度m呈超指数衰减。

**Conclusion:** FNT算法在特定多项式空间$\\Pi_{m,n,p}$上的应用能够有效降低计算复杂度，并通过在敏感性分析中计算活性得分的实例证明了其效率。

> **ai_Abstract:** 本研究分析了快速牛顿变换（FNT）在特定下闭多项式空间$\\Pi_{m,n,p}$上的性能，该空间由$\\ell^p$范数小于n的多指标定义。研究表明，与张量积空间相比，$\\Pi_{m,n,p}$能显著降低计算复杂度，尤其是在m\lesssim n^p时，降低因子随空间维度的增加呈超指数衰减。论文通过敏感性分析中的活性得分计算实例，验证了FNT的效率。

> **摘要翻译:** 我们最近介绍了快速牛顿变换（FNT），这是一种用于执行空间维度为m的任意下闭多项式空间中的多变量牛顿插值的分层算法。在这里，我们分析了FNT在由所有$\\ell^p$范数小于n的$\\ell^p$范数定义的一类特定的下闭集$A_{m,n,p}$（其中$p \in [0,\infty]$）的背景下的应用。FNT在诱导的下闭多项式空间$\\Pi_{m,n,p}$上具有$\\mathcal{O}(|A_{m,n,p}|mn)$的时间复杂度。我们证明了与张量积空间$\\Pi_{m,n,\infty}$相比，选择$\\Pi_{m,n,p}$可以将时间复杂度降低一个因子$\\rho_{m,n,p}$，当$m \lesssim n^p$时，该因子随空间维度的增加呈超指数衰减。我们通过计算敏感性分析中的活性得分来展示FNT的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [710] [On sliced Cramér metrics](https://arxiv.org/abs/2508.02678)
> *关于切片Cramér度量*

*William Leeb* | **Category: math.NA, cs.NA** | **Updated: 2025-07-15**

**Keywords:** 切片Cramér度量,几何变形,鲁棒性,傅里叶基离散化,异方差噪声

**Comment:** 50 pages, 7 figures. This work supersedes arXiv:2101.10867

> **TL;DR:** 该研究探讨了切片Cramér度量，证明了它们对几何变形具有鲁棒性，并提出了度量变形位移的方法，同时讨论了其在断层扫描投影和卷积中的应用，并与Wasserstein距离进行了比较，最后提出了傅里叶基离散化方法并验证了其对异方差噪声的鲁棒性。

**AI_Comments:** 该研究对切片Cramér度量进行了全面的理论和计算分析，揭示了其在几何变形和噪声处理方面的鲁棒性，并提供了与Wasserstein距离的比较，为该度量的应用提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 研究切片Cramér度量对几何变形的鲁棒性，并探索其在断层扫描投影、卷积以及与Wasserstein距离的比较中的应用。

**Method:** 通过理论分析证明切片Cramér度量对几何变形的鲁棒性，并推导出度量变形位移的界限。研究了其在断层扫描投影中的延伸应用，并分析了卷积的影响。将切片Cramér度量与Wasserstein距离的性质进行比较。开发了切片Cramér距离的傅里叶基离散化方法，并证明了其对异方差噪声的鲁棒性。

**Result:** 切片Cramér度量对广泛的几何变形具有鲁棒性。切片Cramér距离可由变形的位移度量和函数的平均混合范数界定。该结果可推广到断层扫描投影的切片Cramér距离。研究了卷积对切片Cramér度量的影响，并与Wasserstein距离进行了比较。提出了计算高效的傅里叶基离散化方法，并证明了其对异方差噪声的鲁棒性。

**Conclusion:** 切片Cramér度量在几何变形方面表现出良好的鲁棒性，并且可以通过位移度量和函数范数进行界定。其傅里叶基离散化方法为在实际应用中处理噪声提供了有效途径。

> **ai_Abstract:** 本研究深入探讨了切片Cramér度量，证明了其对几何变形的鲁棒性，并提出了量化变形影响的方法。研究结果表明，切片Cramér距离可以被变形的位移和函数的平均混合范数所界定，并且该性质同样适用于断层扫描投影。此外，研究还分析了卷积对切片Cramér度量的影响，并将其与Wasserstein距离的特性进行了对比。最后，论文提出了一种计算高效的傅里叶基离散化方法，并验证了该方法在处理异方差噪声时的鲁棒性，并通过数值实验进行了说明。

> **摘要翻译:** 我们研究了切片Cramér度量族，表明它们对广泛的几何变形具有鲁棒性。我们的核心结果是，函数与其变形之间的切片Cramér距离可以被变形的位移的某些自然度量乘以函数的平均混合范数来界定。这些结果延伸到断层扫描投影之间的切片Cramér距离。我们还讨论了卷积对切片Cramér度量的影响。我们将切片Cramér度量的这些性质与Wasserstein距离所满足的类似性质进行了比较。此外，我们研究了Cramér和切片Cramér距离在1D和2D中的计算高效的傅里叶基离散化，并证明它们对异方差噪声具有鲁棒性。结果通过数值实验进行了说明。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [743] [Accelerating Conjugate Gradient Solvers for Homogenization Problems with Unitary Neural Operators](https://arxiv.org/abs/2508.02681)
> *用于均质化问题的共轭梯度求解器的加速，基于酉神经算子*

*Julius Herb, Felix Fritzen* | **Category: math.NA, cs.LG, cs.NA, 65** | **Updated: 2025-07-18**

**Keywords:** 均质化问题, 共轭梯度, 神经算子, 预处理, 科学机器学习

**Comment:** 

> **TL;DR:** 该研究提出了一种名为UNO-CG的混合求解器，它使用酉神经算子（一种改进的傅立叶神经算子）作为预处理，来加速共轭梯度（CG）求解器在均质化问题中的应用。该方法通过数据驱动的方式发现格林函数，从而加速迭代求解过程，并在保持收敛性的同时，显著减少了迭代次数，性能可与手工设计的预处理方法相媲美，并且在多种边界条件下表现出良好的通用性和鲁棒性。

**AI_Comments:** 该研究提出的UNO-CG方法在加速均质化问题求解方面取得了显著进展，通过结合机器学习和经典数值方法，有效解决了传统方法的计算成本和收敛速度问题。特别是酉神经算子的应用，为数据驱动的预处理提供了新的思路。然而，对于其在更广泛的PDE问题上的泛化能力以及模型的可解释性仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 科学和工程领域需要快速可靠的参数化偏微分方程（PDE）求解器，特别是在复合材料和结构材料设计中，均质化问题需要针对广泛的材料参数和微结构进行求解。传统求解器虽然准确但计算成本高、收敛慢，而科学机器学习方法虽然有前景但缺乏精度和物理一致性保证。因此，需要一种结合数据驱动方法和经典求解器优点的混合方法。

**Method:** 提出了一种名为UNO-CG的混合求解器，它使用酉神经算子（Unitary Neural Operators）作为预处理，来加速共轭梯度（CG）求解器。酉神经算子是傅立叶神经算子（Fourier Neural Operators）的改进版本。该方法将数据驱动方法与经典求解器相结合，通过发现格林函数来加速迭代求解，并保证收敛性。

**Result:** UNO-CG在涉及异质微结构和数百万自由度的均质化问题上进行了评估。结果表明，UNO-CG能够显著减少迭代次数，并且在需要专家知识的均质化问题上，其性能可与手工设计的预处理方法相媲美。此外，UNO-CG在多种边界条件下均表现出强大的性能，而许多专用求解器在此类条件下不适用，这显示了其通用性和鲁棒性。

**Conclusion:** UNO-CG作为一种混合求解器，通过使用酉神经算子作为预处理，成功地加速了共轭梯度求解器在均质化问题中的应用。该方法不仅提高了求解效率，减少了迭代次数，而且在保持物理一致性和跨边界条件的应用性方面也表现出色，为解决复杂的科学和工程问题提供了一种有前景的解决方案。

> **ai_Abstract:** 本研究提出了一种名为UNO-CG的混合求解器，旨在加速均质化问题的求解。该方法结合了经典共轭梯度（CG）求解器和机器学习预处理器，具体采用了改进的傅立叶神经算子——酉神经算子（Unitary Neural Operators）。UNO-CG通过数据驱动的方式学习格林函数，从而有效加速CG迭代过程并保证收敛性。实验结果表明，UNO-CG在处理具有复杂微结构的大规模均质化问题时，能显著减少迭代次数，且性能与手工设计的预处理器相当，并在多种边界条件下展现出良好的通用性和鲁棒性。

> **摘要翻译:** 科学和工程的许多领域都需要参数化偏微分方程（PDE）的快速可靠求解器。例如，对具有异质微观结构的复合材料和结构材料的需求日益增长。设计此类材料并在实际应用中预测其行为，需要针对广泛的材料参数和微观结构求解均质化问题。虽然经典数值求解器提供了可靠且准确的解决方案，并有坚实的理论基础支持，但其高昂的计算成本和缓慢的收敛速度仍然是限制因素。因此，科学机器学习正成为一种有前景的替代方案。然而，这些方法往往缺乏可保证的准确性和物理一致性。这就提出了是否有可能开发出结合数据驱动方法和经典求解器优点的混合方法的问题。为了解决这个问题，我们引入了UNO-CG，一种混合求解器，它通过专门设计的机器学习预处理器来加速共轭梯度（CG）求解器，同时通过构造来确保收敛性。作为预处理器，我们提出酉神经算子作为傅立叶神经算子的改进版本。我们的方法可以被解释为数据驱动的格林函数发现，然后用于加速迭代求解器。我们在涉及异质微结构和数百万自由度的各种均质化问题上评估了UNO-CG。我们的结果表明，UNO-CG能够显著减少迭代次数，并且在涉及专家知识的均质化问题上，其性能可与手工设计的预处理器相媲美。此外，UNO-CG在许多专用求解器不适用的各种边界条件下保持了强大的性能，凸显了其通用性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [779] [Transient thermal analysis of a bi-layered composites with the dual-reciprocity inclusion-based boundary element method](https://arxiv.org/abs/2508.02683)
> *双重倒数包含边界元法瞬态热分析复合材料*

*Chunlin Wu, Liangliang Zhang, Tengxiang Wang, Huiming Yin* | **Category: math.NA, cs.NA, 65N38** | **Updated: 2025-07-20**

**Keywords:** 双重倒数包含边界元法, 瞬态热分析, 双层复合材料, 材料不匹配, 功能梯度材料

**Comment:** 21 pages, 11 figures, Submitted to International Journal of Heat and
  Mass Transfer. No derivative works (including translation or adaptation)
  permitted before the journal Version of Record. Data withheld until formal
  publication

> **TL;DR:** 该研究提出了一种用于三维全粘合双层复合材料的单域双重倒数包含边界元法（DR-iBEM），用于分析嵌入椭球形不均匀体在瞬态/谐波热负荷下的热行为。该方法将热方程转化为边界积分，并引入了特征温度梯度和特征热源来模拟材料不匹配。与有限元法（FEM）相比，DR-iBEM在精度和鲁棒性方面得到了验证，并成功应用于功能梯度材料。

**AI_Comments:** 该方法在处理复杂材料结构（如功能梯度材料）的热分析方面显示出巨大潜力，但可能需要进一步研究其在高维度和复杂几何形状下的计算效率和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在开发一种有效的方法来分析具有嵌入不均匀体的双层复合材料在瞬态/谐波热负荷下的热行为，特别关注材料不匹配的影响。

**Method:** 提出并应用了单域双重倒数包含边界元法（DR-iBEM），将热方程转化为边界积分，并引入特征温度梯度和特征热源来模拟材料不匹配。

**Result:** DR-iBEM方法在数值上得到了验证，并与有限元法（FEM）进行了比较，证明了其鲁棒性和准确性。该方法还成功应用于功能梯度材料，评估了颗粒尺寸和梯度分布的影响。

**Conclusion:** 所提出的DR-iBEM是一种用于分析双层复合材料瞬态和谐波热行为的有效方法，能够准确模拟材料不匹配。

> **ai_Abstract:** 本研究提出了一种新颖的单域双重倒数包含边界元法（DR-iBEM），用于分析三维全粘合双层复合材料中嵌入椭球形不均匀体在瞬态/谐波热负荷下的热行为。该方法通过将热方程转化为边界积分，并引入特征温度梯度和特征热源来有效处理材料不匹配问题。通过与有限元法（FEM）的比较，验证了DR-iBEM的准确性和鲁棒性，并成功应用于功能梯度材料的分析。

> **摘要翻译:** 本论文提出了一种用于三维全粘合双层复合材料的单域双重倒数包含边界元法（DR-iBEM），该复合材料嵌入了椭球形不均匀体，并承受瞬态/谐波热负荷。热方程被解释为包含时间相关和频率相关非齐次源项的静态方程，这与特征场相似，但通过双重倒数法转化为边界积分。利用稳态双材料格林函数，提出了考虑温度和热流连续性条件的边界积分方程，从而避免了在双材料界面上设置任何连续性方程。引入了特征温度梯度和特征热源，分别用于模拟热导率和热容的材料失配。DR-iBEM算法特别适用于研究双层复合材料的瞬态和谐波热行为，并通过有限元法（FEM）进行了验证。与FEM的数值比较证明了其鲁棒性和准确性。该方法已应用于功能梯度材料，作为具有梯度颗粒分布的双材料，并评估了颗粒尺寸和梯度分布的影响。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [815] [Diffusive behavior of transport noise on $\mathbb{S}^2$](https://arxiv.org/abs/2508.02707)
> *球体上的输运噪声的扩散行为*

*Sagy Ephrati, Erik Jansson, Andrea Papini* | **Category: math.NA, cs.NA, math.PR, physics.flu-dyn, 60H15, 65M75, 35Q35, 76B03** | **Updated: 2025-07-30**

**Keywords:** 输运噪声, 扩散行为, 球体, 能量耗散, 涡度

**Comment:** 13 pages, 2 figures. All comments are welcome!

> **TL;DR:** 研究了球体上由输运噪声引起的扩散行为，发现适当的输运噪声可以导致能量耗散，同时保持涡度。

**AI_Comments:** 这项研究在理论和数值上都很有价值，它将输运噪声在球体上的扩散行为与之前的研究联系起来，并提出了具体的数值模拟方法。研究结果对于理解和模拟地球物理流体系统中的复杂现象具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究在球体上由输运噪声引起的扩散行为，并将其与先前的托拉斯上的分析进行比较。

**Method:** 通过理论和数值模拟，包括使用Zeitlin离散化的结构保持数值模拟，来分析球体上的动力学。

**Result:** 在球体上，适当缩放的输运噪声可以诱导能量耗散，同时保持涡度（enstrophy）和共轭轨道。

**Conclusion:** 研究为输运噪声的进一步理论研究奠定了基础，并支持将输运噪声模型作为地球物理流体模拟中未解析过程参数化的校准。

> **ai_Abstract:** 本文研究了球体上输运噪声引起的扩散行为。研究表明，在球体上，通过使用特定的输运噪声，可以实现能量耗散，同时保持涡度。研究结果为进一步的理论研究和地球物理流体模拟中的参数化提供了基础。

> **摘要翻译:** 我们从输运理论和数值上研究了球体上由噪声引起的扩散。先前在环面上进行的分析表明，在欧拉方程中选择合适的输运噪声会导致类似Navier-Stokes方程的扩散行为。在这里，我们分析了具有噪声引起的微分椭圆算子耗散的球体动力学，并表征了它们的能量和涡度衰减特性。通过使用Zeitlin离散化的结构保持数值模拟，我们证明了适当缩放的输运噪声可以诱导能量耗散，同时保持涡度（enstrophy）和共轭轨道。所提出的分析为输运噪声的进一步理论研究奠定了基础，并支持将输运噪声模型作为地球物理流体模拟中未解析过程参数化的校准。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [847] [Spline Shallow Water Moment Equations](https://arxiv.org/abs/2508.02714)
> *三次样条浅水矩方程*

*Ullika Scholz, Julian Koellermeier* | **Category: math.NA, cs.NA, math.AP, physics.flu-dyn, 76D05, 35L65, 65M08, 76M12** | **Updated: 2025-07-31**

**Keywords:** 浅水矩方程,三次样条,速度剖面,降阶模型,双曲正则化

**Comment:** 

> **TL;DR:** 该研究提出了三次样条浅水矩方程（SSWME），使用分段三次样条作为基函数来灵活表示速度剖面，解决了传统浅水方程无法提供垂向速度剖面信息的问题，并推导了其正则化双曲形式，数值模拟显示了新模型的准确性和鲁棒性。

**AI_Comments:** 该研究通过引入三次样条基函数，为浅水流建模提供了一种更灵活、更适应性的方法，尤其是在处理具有复杂垂向速度剖面时。解析证明双曲性是该工作的一个重要贡献，为数值模拟的稳定性和准确性提供了理论保障。未来的工作可以探索更复杂的流体现象或更广泛的应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的浅水方程（SWE）在计算表面高度时，无法提供垂向速度剖面信息。虽然先前的矩方法（SWME）使用勒让德多项式作为速度剖面的试函数，但仅限于全局多项式。

**Method:** 提出使用分段三次样条作为试函数来构建浅水矩方程（SSWME），以灵活表示速度剖面。系统地推导和分析了不同基函数数量和次数的SSWME模型层级，并推导了正则化双曲形式，并提供了双曲性的解析证明。

**Result:** 数值模拟结果表明，SSWME模型具有高精度和鲁棒性。

**Conclusion:** 三次样条浅水矩方程（SSWME）提供了一种比传统方法更灵活的速度剖面表示方法，并且其正则化双曲形式在数值模拟中表现出高精度和鲁棒性。

> **ai_Abstract:** 本文提出了一种新的浅水流降阶模型——三次样条浅水矩方程（SSWME），使用分段三次样条作为基函数来灵活表示速度剖面，解决了传统浅水方程在垂向速度剖面信息上的不足。该方法能够通过调整基函数数量和次数来构建不同层级的模型，并通过正则化推导出双曲形式，数值结果验证了其准确性和鲁棒性。

> **摘要翻译:** 由于需要完全解析垂直方向上的流动来计算表面高度，因此需要降低描述自由表面流动的模型维度，以应对高维度的不可压缩纳维-斯托克斯方程。另一方面，经典的浅水方程（SWE）等降阶模型，其假设了长度比很小的深度并且使用了深度平均，因此无法提供垂向速度剖面变化的信息。作为一个折衷，最近提出的一种使用勒让德多项式作为垂向速度变化试函数的浅水流矩方法，推导出了所谓的浅水矩方程（SWME），它结合了低维度和速度剖面建模的优点。然而，到目前为止只考虑了全局多项式。
本文介绍了三次样条浅水矩方程（SSWME），其中分段定义的三次样条试函数允许对具有较低正则性的速度剖面进行灵活表示。三次样条基函数具有局部支撑，这使得它们在处理某些典型的剖面形状时具有自适应性和更大的灵活性。我们系统地推导和分析了具有不同数量基函数和不同次数的SSWME模型层级，然后通过对高阶SSWME模型层级进行解析证明的双曲正则化，推导出一个正则化双曲形式。数值模拟表明了新模型的高精度和鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [884] [DD-DeepONet: Domain decomposition and DeepONet for solving partial differential equations in three application scenarios](https://arxiv.org/abs/2508.02717)
> *DD-DeepONet：域分解和DeepONet用于三个应用场景中的偏微分方程求解*

*Bo Yang, Xingquan Li, Jie Zhao, Ying Jiang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-31**

**Keywords:** DD-DeepONet, 偏微分方程, 域分解, 拉伸变换, 深度学习

**Comment:** 

> **TL;DR:** DD-DeepONet是一种用于求解偏微分方程的框架，通过域分解和拉伸变换处理复杂几何形状，在三种不同场景下（几何、边界条件或参数变化）均表现出良好的计算潜力，并能降低训练难度、减少数据和显存需求并加速求解。

**AI_Comments:** 该研究提出了一种创新的DD-DeepONet框架，通过域分解和拉伸变换技术，有效地解决了偏微分方程在多种工程应用场景下的重复求解问题。其在降低训练难度、减少数据和显存需求以及加速求解速度方面的优势，使其在实际应用中具有重要的价值。然而，对于更广泛的几何形状和更复杂的PDE类型，其性能仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在实际工程应用中，尤其是在几何、边界条件或参数发生变化的场景下，需要快速重复求解偏微分方程（PDE）。

**Method:** 提出了一种名为DD-DeepONet的框架，该框架的核心思想是将复杂几何形状分解为简单的结构，反之亦然。它还应用拉伸变换来处理形状相关的PDE问题，并主要研究由矩形和长方体组成的复杂几何形状。该框架被应用于求解拉普拉斯方程、泊松方程、N-S方程和漂移扩散方程等原型PDE。

**Result:** DD-DeepONet在三个应用场景中均展示了其计算潜力。实验结果表明，该方法能够降低训练难度，减少每个网络所需的数据量和显存（VRAM），并加快求解速度。

**Conclusion:** DD-DeepONet框架通过域分解和拉伸变换，能够有效地解决不同场景下的偏微分方程问题，并在计算效率和资源消耗方面具有优势。

> **ai_Abstract:** DD-DeepONet框架通过域分解和拉伸变换技术，有效地解决了在几何、边界条件或参数变化的三种不同应用场景下的偏微分方程（PDE）求解问题。该方法能够处理复杂的几何形状，并显著提高了计算效率，降低了训练难度、数据和显存需求。

> **摘要翻译:** 在某些实际工程应用中，迫切需要能在短时间内重复求解偏微分方程（PDE）。本文主要考虑了需要大量重复仿真的三种场景。这三种场景根据几何形状、边界条件（BCs）或参数是否变化进行分类。我们引入了具有强大可扩展性的DD-DeepONet框架，其核心概念涉及将复杂几何分解为简单结构，反之亦然。我们主要研究由矩形和长方体组成的复杂几何形状，这些几何形状具有众多实际应用。同时，应用拉伸变换来处理依赖于形状的问题。这项工作求解了三种场景下的几个原型PDE，包括拉普拉斯方程、泊松方程、N-S方程和漂移扩散方程，证明了DD-DeepONet的计算潜力。实验结果表明，DD-DeepONet降低了训练难度，需要更少的数据集和每个网络的VRAM，并加速了求解的获取。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [897] [Orbit recovery for spherical functions](https://arxiv.org/abs/2508.02674)
> *球函数轨道恢复*

*Tamir Bendory, Dan Edidin, Josh Katz, Shay Kreymer* | **Category: math.NA, cs.IT, cs.NA, math.IT, 94A12, 22D10** | **Updated: 2025-06-30**

**Keywords:** 轨道恢复, 球函数, 双谱, SO(3), 结构生物学

**Comment:** 15 pages

> **TL;DR:** 该研究表明，三阶不变量（双谱）足以恢复球函数在旋转作用下的轨道，并为所需样本数量提供了界限，特别是在 SO(3) 情况下，三个球壳足以恢复轨道，验证了一个隐含的猜想。

**AI_Comments:** 该研究在轨道恢复领域取得了重要进展，特别是在处理球函数和 SO(n) 作用下的情况。其理论贡献在于证明了低阶不变量（三阶双谱）在特定条件下足以恢复轨道，这对于实际应用具有重要意义。算法的有效性和在蛋白质结构分析中的成功应用也凸显了该研究的实用价值。然而，研究主要关注“通用轨道”，对于非通用轨道的恢复能力以及算法在处理大规模或高噪声数据时的鲁棒性还有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 轨道恢复在数学和应用科学中是一个核心问题，尤其在结构生物学中有重要应用。本研究旨在恢复函数在 SO(n) 旋转作用下在 R^n 和 S^(n-1) 上的轨道。

**Method:** 通过带限化球分量和离散化径向方向，对 L^2(R^n) 进行有限维近似，并利用三阶不变量（双谱）来恢复函数的轨道。推导了恢复所需的径向样本数量界限，并提出了一种通过求解线性方程组的算法。

**Result:** 证明了三阶不变量（双谱）足以恢复有限维近似下的函数轨道。对于 SO(3) 情况，证明了三个球壳（径向样本）足以恢复通用轨道，这验证了 Bandeira 等人的一个隐含猜想。所提出的算法已被实现并成功应用于两个蛋白质结构。

**Conclusion:** 研究表明，三阶不变量（双谱）对于恢复球函数在 SO(n) 旋转作用下的轨道是足够的，并且在 SO(3) 的情况下，三个径向采样点足以实现轨道恢复，验证了一个重要的猜想。该方法提供了一个有效的算法，并在实际应用中得到了验证。

> **ai_Abstract:** 本研究解决了轨道恢复问题，特别关注在 SO(n) 旋转作用下，函数在 R^n 和 S^(n-1) 上的轨道恢复。研究表明，使用三阶不变量（双谱）足以恢复函数的通用轨道，并且通过带限化和离散化技术得到的有限维近似是有效的。论文为恢复所需的径向样本数量提供了明确的界限，特别是在结构生物学中至关重要的 SO(3) 情况，证明了三个径向采样点足以恢复通用轨道，验证了一个先前存在的猜想。此外，研究还提出并实现了一种高效的算法，通过求解线性方程组来恢复信号，并在蛋白质结构分析中展示了其有效性。

> **摘要翻译:** 轨道恢复是数学和应用科学中的一个核心问题，在结构生物学中有重要的应用。本文着重于恢复函数在 SO(n) 作用下在 R^n 和 S^(n-1) 上的通用轨道。具体来说，我们证明了三阶不变量（称为双谱）足以在通过带限化球分量和离散化径向方向获得的 L^2(R^n) 的有限维近似中恢复函数的通用轨道。特别是，我们的主要结果明确了从三阶不变量恢复所需的径向样本数量。从应用角度来看，最重要的案例是 SO(3)，它出现在许多科学领域，并且在诸如低温电子断层扫描和低温电子显微镜等领先的结构生物学应用中起着核心作用。我们关于 SO(3) 的结果表明，考虑三个球壳（即径向样本）足以恢复通用轨道，这验证了 Bandeira 等人论文中隐含的一个猜想。我们的证明技术提供了一种显式的、计算上有效的算法，通过依次求解线性方程组来恢复信号。我们实现了该算法，并通过两个蛋白质结构证明了其有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [906] [Floquet stability of periodically stationary pulses in a short-pulse fiber laser](https://arxiv.org/abs/2508.02735)
> *短脉冲光纤激光器中周期性稳态脉冲的弗洛凯稳定性*

*Vrushaly Shinglot, John Zweck* | **Category: math.NA, cs.NA, math.DS, 35B10, 35Q56, 37L15, 47D06, 78A60 (Primary)** | **Updated: 2025-08-02**

**Keywords:** 短脉冲光纤激光器,周期性稳态脉冲,单度性算子,傅里叶分裂步长法,线性稳定性,梯度优化,弗洛凯稳定性

**Comment:** arXiv admin note: text overlap with arXiv:2508.01133

> **TL;DR:** 该论文研究了短脉冲光纤激光器中周期性稳态脉冲的稳定性。研究人员开发了一种基于梯度的优化方法来发现周期性脉冲，并引入了一种新的傅里叶分裂步长方法来计算传播方程的线性化。模拟结果验证了该方法的准确性，并展示了周期性稳态脉冲及其光谱和特征函数，讨论了它们的稳定性。

**AI_Comments:** 该研究在短脉冲光纤激光器建模领域取得了重要进展，特别是在处理周期性稳态脉冲的稳定性和发现方面。傅里叶分裂步长法的引入为求解复杂非线性方程提供了新的思路。然而，该方法在计算梯度时涉及对单度性算子伴随体的数值计算，这可能带来一定的计算成本和精度问题。未来的研究可以关注如何优化计算过程，以及将该方法应用于更广泛的激光器系统。

<details>
  <summary>Details</summary>

**Motivation:** 现代短脉冲光纤激光器的定量建模和设计不能仅依靠平均模型，因为脉冲参数在每个往返过程中存在很大变化，因此需要使用包含激光器各个组件的模型。

**Method:** 该研究利用单度性算子（往返算子关于脉冲的线性化）来研究周期性脉冲的线性稳定性。开发了一种基于梯度的优化方法来发现周期性脉冲，该方法通过数值计算往返算子和单度性算子伴随体的作用来计算目标函数的梯度。引入了一种新的傅里叶分裂步长方法来计算模型的光传播的非线性、非局部、刚性方程的线性化解。

**Result:** 模拟结果验证了所用数值方法的准确性，展示了周期性稳态脉冲的示例、它们的光谱和特征函数，并讨论了它们的稳定性。

**Conclusion:** 该研究通过数值方法和模拟验证了短脉冲光纤激光器中周期性稳态脉冲的稳定性的计算方法。

> **ai_Abstract:** 本研究针对短脉冲光纤激光器中周期性稳态脉冲的稳定性问题，提出了一种新的建模和分析方法。由于脉冲参数在往返过程中变化剧烈，平均模型不足以进行精确设计，因此研究采用集总模型，并利用单度性算子进行线性稳定性分析。为寻找周期性脉冲，开发了基于梯度的优化方法，并通过傅里叶分裂步长方法求解线性化方程。模拟结果证实了该方法的有效性，并对周期性稳态脉冲的性质及稳定性进行了探讨。

> **摘要翻译:** 现代短脉冲光纤激光器的定量建模和设计不能仅依靠平均模型，因为脉冲参数在每个往返过程中存在很大变化。因此，需要使用由激光器各个组件的模型串联而成的集总模型。由于集总模型中的光脉冲是周期性的，因此使用单度性算子（往返算子关于脉冲的线性化）来研究它们的线性稳定性。开发了一种基于梯度的优化方法来发现周期性脉冲。目标函数梯度的计算涉及往返算子和单度性算子伴随体作用的数值计算。引入了一种新的傅里叶分裂步长方法来计算模型的光传播的非线性、非局部、刚性方程的线性化解。该方法是通过线性化非线性方程的两个分裂步长解算子导出的。单度性算子的谱由本征谱和特征值组成，其中本征谱有一个解析公式，而特征值则可以通过单度性算子的矩阵离散化来确定。存在一个重数为二的特征值 $\lambda=1$，这是由于相位和时间平移不变性。模拟结果验证了数值方法的准确性，展示了周期性稳态脉冲的示例、它们的光谱和特征函数，并讨论了它们的稳定性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [940] [Mixed Finite Element Method for a Hemivariational Inequality of Stationary convective Brinkman-Forchheimer Extended Darcy equations](https://arxiv.org/abs/2508.02797)
> *用于平稳对流布林克曼-福克海默扩展达西方程的混合有限元方法*

*Wasim Akram, Manil T. Mohan* | **Category: math.NA, cs.NA** | **Updated: 2025-08-04**

**Keywords:** 混合有限元方法, 半变分不等式, 对流布林克曼-福克海默扩展达西方程, 多孔介质流动, 非光滑边界条件

**Comment:** 

> **TL;DR:** 该研究提出并分析了一种用于处理具有非光滑边界条件的饱和多孔介质中不可压缩流体的混合有限元方法，该方法在理论和数值上都得到了验证。

**AI_Comments:** 该研究在处理具有复杂非光滑边界条件的流体问题方面具有创新性。提出的混合有限元方法在理论分析和数值验证上都表现出色，为解决类似工程问题提供了有价值的工具。然而，数值实验的规模和多样性可以进一步扩展，以更全面地评估该方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 对流布林克曼-福克海默扩展达西（CBFeD）方程模型，该模型通过引入阻尼和泵送效应扩展了不可压缩纳维-斯托克斯方程，并考虑了非光滑、非凸的摩擦型滑移边界条件下的粘性不可压缩流体在饱和多孔介质中的流动问题。

**Method:** 提出了一种混合有限元方法，并进行了理论分析，包括解的存在性和唯一性证明，以及误差分析。该方法使用了 P1b/P1 单元对，并进行了数值实验验证。

**Result:** 在合适的正则性假设下，该混合有限元方法实现了最优收敛率，并通过数值实验验证了理论结果和预期的收敛行为。

**Conclusion:** 该研究成功地提出并分析了一种适用于 CBFeD 方程的混合有限元方法，该方法能够处理复杂的非光滑边界条件，并实现了最优收敛率，为相关问题的数值模拟提供了有效手段。

> **ai_Abstract:** 本研究提出了一种用于求解平稳对流布林克曼-福克海默扩展达西（CBFeD）方程的混合有限元方法。该方法能够处理包含非光滑、非凸摩擦型滑移边界条件的不可压缩流体在饱和多孔介质中的流动问题。通过混合变分公式处理不可压缩性约束，并利用算子的伪单调性和协强性证明了解的存在唯一性。理论分析表明，使用低阶混合有限元对（如 P1b/P1）可以获得最优收敛率。数值实验结果证实了该方法的有效性和理论分析的准确性。

> **摘要翻译:** 本文提出了用于处理平稳对流布林克曼-福克海默扩展达西（CBFeD）方程的半变分不等式的混合有限元方法的提法和分析。该模型通过结合阻尼和泵送效应来扩展不可压缩的纳维-斯托克斯方程。该半变分不等式描述了粘性、不可压缩流体在饱和多孔介质中的流动，该流动受到非光滑、非凸摩擦型滑移边界条件的影响。通过混合变分提法处理了不可压缩性约束。我们利用相关算子的伪单调性和协强性性质，建立了解的存在性和唯一性，并对提出的数值格式进行了详细的误差分析。在合适的正则性假设下，该方法使用低阶混合有限元对实现了最优收敛率。该格式使用 P1b/P1 单元对进行实现，并通过数值实验验证了理论结果并证实了预期的收敛行为。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [975] [H(curl)-based approximation of the Stokes problem with weakly enforced no-slip boundary conditions](https://arxiv.org/abs/2508.02861)
> *基于H(curl)的斯托克斯问题近似及其弱化无滑移边界条件的应用*

*Wietse M. Boon, Wouter Tonnon, Enrico Zampa* | **Category: math.NA, cs.NA, 65N12, 65N30, 76D07** | **Updated: 2025-08-04**

**Keywords:** 斯托克斯流,无滑移边界条件,H(curl),Nitsche方法,有限元方法

**Comment:** 27 pages, 6 figures

> **TL;DR:** 该研究提出了一种使用Nitsche有限元方法来处理斯托克斯流的无滑移边界条件的方法，以解决直接施加边界条件导致的病态离散化问题，并通过数值实验验证了其稳定性和最优收敛性。

**AI_Comments:** 这项工作解决了在求解斯托克斯流时施加无滑移边界条件的一个关键挑战，特别是在需要保持结构的离散化方案中。通过使用Nitsche方法，作者提供了一种比直接施加边界条件更稳健的替代方案，并用理论分析和数值结果支持了其有效性。这对于需要精确模拟流体边界行为的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在结构保持的Navier-Stokes和磁流体动力学方程离散化中，需要对斯托克斯流施加无滑移边界条件。直接施加这些条件（切向部分为H(curl)的本质边界条件，法向部分通过散度项的分部积分自然施加）可能会导致离散化病态。

**Method:** 提出了一种基于Nitsche的有限元方法来处理无滑移边界条件，并分析了离散系统的稳定性和误差先验估计。

**Result:** 数值实验验证了该方法的分析结果，并证明了速度场的收敛率是最优的。

**Conclusion:** 基于Nitsche的有限元方法可以有效地处理斯托克斯流的无滑移边界条件，解决了直接施加边界条件可能导致的离散化病态问题，并具有良好的稳定性和最优收敛性。

> **ai_Abstract:** 本文提出了一种用于解决斯托克斯流的无滑移边界条件的Nitsche有限元方法。研究表明，直接施加无滑移边界条件可能导致离散化病态。所提出的方法通过分析离散系统的稳定性和误差估计，并通过数值实验验证了其最优收敛性。

> **摘要翻译:** 在本工作中，我们展示了如何为基于H(curl)的不可压缩斯托克斯流形式化施加无滑移边界条件，该形式化用于结构保持的Navier-Stokes和磁流体动力学方程的离散化。乍一看，施加无滑移边界条件似乎很简单：切向部分是H(curl)上的本质边界条件，法向分量可以通过散度项的积分来自然施加。然而，我们表明这可能导致离散化病态，因此我们提出了一种基于Nitsche的有限元方法。我们分析了离散系统，建立了稳定性和推导了先验误差估计。数值实验验证了我们的分析，并证明了速度场的收敛率是最优的。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [159] [Density Estimation from Aggregated Data with Integrated Auxiliary Information: Estimating Population Densities with Geospatial Data](https://arxiv.org/abs/2508.03610)
> *从聚合数据中进行密度估计并整合辅助信息：利用地理空间数据估计人口密度*

*Michael Mühlbauer, Timo Schmid* | **Category: stat.AP** | **Updated: 2025-08-05**

**Keywords:** 密度估计, 聚合数据, 辅助信息, 地理空间数据, 人口密度

**Comment:** 

> **TL;DR:** 该研究提出了一种将辅助信息整合到聚合地理空间数据密度估计中的方法，通过基于相关性的加权方案，提高了估计的精度。

**AI_Comments:** 这项研究的创新之处在于提出了一种基于相关性加权方案，将辅助信息有效整合到从聚合数据进行密度估计的过程中。这对于在保密性限制下无法获取精细地理坐标的场景具有重要的实际意义，提供了一个提高估计精度的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 地理空间数据的密度估计通常依赖于精确的地理坐标，但由于保密性限制，这些详细信息往往无法获得。分析师因此经常处理空间聚合数据，这使得精确的密度估计成为挑战。

**Method:** 本研究通过引入辅助信息来扩展现有方法，以提高从聚合数据中获得的密度估计的精度。具体采用了一种基于相关性的加权方案，将辅助密度与从聚合数据获得的估计相结合。该方法通过一系列模型模拟场景和两个真实世界的案例研究（德国2022年巴伐利亚州人口密度估计和德国下萨克森州野兔狩猎数据分析）进行了评估。

**Result:** 研究结果表明，将辅助信息整合到密度估计过程中可以获得更精确的密度估计。

**Conclusion:** 通过将辅助信息整合到估计过程中，可以显著提高从聚合数据中进行密度估计的精度，从而克服了精确地理空间数据不可用的限制。

> **ai_Abstract:** 本论文提出了一种新的方法，旨在提高从聚合地理空间数据中进行密度估计的精度，尤其是在无法获得精确地理坐标的情况下。该方法通过采用基于相关性的加权方案，将辅助信息（如夜间灯光卫星图像）与从聚合数据获得的估计相结合。研究通过模型模拟和两个真实世界案例（德国人口密度估计和野兔狩猎数据分析）验证了该方法的有效性，结果显示整合辅助信息显著提升了密度估计的精度。

> **摘要翻译:** 地理空间数据的密度估计理想情况下依赖于精确的地理坐标，通常由经度和纬度定义。然而，由于保密性限制，这些详细信息往往无法获得。因此，分析师经常处理空间聚合数据，这些数据通常通过等值线图进行可视化。文献中已经提出了在核密度估计背景下使用测量误差模型逆转聚合过程的方法。从方法论的角度来看，我们通过整合辅助信息来扩展这项工作，以提高从聚合数据中获得的密度估计的精度。我们的方法采用了一种基于相关性的加权方案，将辅助密度与从聚合数据获得的估计相结合。我们通过一系列反映辅助数据质量不同条件下的基于模型的模拟场景来评估该方法。从应用的角度来看，我们在两个真实世界的案例研究中展示了我们方法的实用性：(1) 使用夜间灯光卫星图像作为辅助数据，估计德国2022年巴伐利亚州人口普查的人口密度；(2) 分析德国下萨克森州的野兔狩猎捕获数据。总的来说，我们的结果表明，将辅助信息整合到估计过程中可以获得更精确的密度估计。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [198] [Optimized imaging prefiltering for enhanced image segmentation](https://arxiv.org/abs/2508.03653)
> *优化图像预滤波以增强图像分割*

*Ronny Vallejos, Felipe Osorio, Sebastian Vidal, Grisel Britos* | **Category: stat.AP, stat.ME** | **Updated: 2025-08-05**

**Keywords:** Box-Cox变换, 图像分割, 预处理, 机器学习, 深度学习

**Comment:** 20 pages, 9 figures, 8 tables

> **TL;DR:** 本文探讨了Box-Cox变换作为图像分割预处理步骤的应用，发现它能增强传统机器学习模型的特征可分性和计算效率，但在深度学习模型中效果不一致。

**AI_Comments:** 该研究创新性地将Box-Cox变换应用于图像分割的预处理阶段，并详细分析了其对不同类型机器学习模型的影响。其重要性在于揭示了传统统计方法在特定场景下（如无训练数据）对经典机器学习模型的潜在优势，同时也指出了其在深度学习领域的局限性，为未来的研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究Box-Cox变换作为图像分割预处理步骤的应用，并关注变换参数的估计，以期提升图像分割效果。

**Method:** 研究通过比较各种分割方法来评估Box-Cox变换的有效性，并特别关注其对传统机器学习技术的优势，尤其是在没有训练数据的情况下。

**Result:** 研究结果表明，Box-Cox变换能增强特征可分性和计算效率，对判别分析等模型特别有益。然而，深度学习模型并未显示出一致的改进。

**Conclusion:** Box-Cox变换作为图像分割的预处理步骤，能有效提升传统机器学习模型的性能，特别是在无训练数据时，但对深度学习模型的改善不一致。

> **ai_Abstract:** 本文探讨了Box-Cox变换作为图像分割预处理步骤的有效性，重点研究了变换参数的估计。研究发现，该变换能显著提升传统机器学习模型（如判别分析）的特征可分性和计算效率，尤其是在缺乏训练数据的情况下。然而，它对深度学习模型的改进效果不一致，表明其影响因模型类型和图像特性而异。

> **摘要翻译:** Box-Cox变换于1964年引入，是一种广泛使用的统计工具，用于稳定数据分析中的方差和改善正态性。近年来，其在图像处理，特别是图像增强中的应用受到越来越多的关注。本文研究了Box-Cox变换作为图像分割预处理步骤的应用，重点关注变换参数的估计。我们通过比较各种分割方法来评估该变换的有效性，强调其对传统机器学习技术的优势——尤其是在没有训练数据的情况下。结果表明，该变换增强了特征可分性和计算效率，使其对判别分析等模型特别有益。相比之下，深度学习模型并未显示出一致的改进，这突显了该变换在不同模型类型和图像特性上的不同影响。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [349] [Quantifying Grid Resilience Against Extreme Weather Using Large-Scale Customer Power Outage Data](https://arxiv.org/abs/2109.09711)
> *利用大规模客户停电数据量化电网抵御极端天气的能力*

*Shixiang Zhu, Rui Yao, Yao Xie, Feng Qiu, Yueming Qiu, Xuan Wu* | **Category: stat.AP** | **Updated: 2025-08-05**

**Keywords:** 电网韧性, 极端天气, 停电数据, 统计模型, 灾害响应

**Comment:** 

> **TL;DR:** 本研究利用大规模历史停电数据和天气记录，构建了一个统计模型，对电网韧性进行了量化定义和分析，揭示了累积天气效应和停电传播现象，并证明了在关键位置增强基础设施能有效减少停电，同时模型在预测停电进展方面表现出良好准确性。

**AI_Comments:** 这篇论文的创新点在于首次提出了电网韧性的定量可测量定义，并利用大规模真实停电数据进行实证分析，突破了以往概念性或局部组件层面的研究局限。其重要性体现在为电力行业提供了具体的韧性评估工具和增强策略，特别是关于累积天气效应和关键位置投资的发现，具有很强的实践指导意义。模型在停电预测方面的准确性也为灾害响应提供了前瞻性支持。该研究为应对气候变化带来的电网挑战提供了坚实的数据驱动方法。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，全球天气变得更加不规律和极端，经常导致大规模、长时间的停电。电网韧性（即承受、适应和从大规模中断中恢复的能力）已成为电力行业的首要任务。然而，目前对电网韧性的理解大多停留在概念层面或仅关注特定组件，未能提供可操作的结果或揭示系统层面的深刻见解。

**Method:** 本研究提出了一种可定量测量的电网韧性定义，并使用一个受数据模式和领域知识启发的统计模型。研究分析了大规模的每刻钟历史电力客户停电数据和相应的天气记录，并将模型与行业韧性实践联系起来。通过对美国东海岸三个主要服务区域的韧性分析进行了展示。

**Result:** 分析表明，累积天气效应在导致即时、持续停电方面起着关键作用，并且这些停电会传播并导致邻近区域的二次停电。所提出的模型还为电网韧性增强规划提供了一些有趣的见解，例如，模拟结果表明，在少数关键位置增强电力基础设施可以将马萨诸塞州客户停电数量减少近一半。此外，研究还表明，该模型在预测极端天气事件期间客户停电进展方面取得了令人满意的准确性。

**Conclusion:** 本研究提出的模型不仅为电网韧性提供了一个可量化的定义和分析框架，还为系统运营商和联邦机构制定灾害响应计划提供了宝贵的预测工具，并通过在关键区域进行有针对性的基础设施增强，显著提升电网抵御极端天气的能力。

> **ai_Abstract:** 本研究旨在通过构建一个统计模型，对电网抵御极端天气的能力进行定量化定义和分析。研究利用大规模历史客户停电数据和天气记录，揭示了累积天气效应是导致即时、持续停电的关键因素，且停电具有传播性。模型在预测停电进展方面表现出高准确性，并提供了有价值的见解，例如通过在少数关键位置增强基础设施可显著减少停电数量。该研究为电力部门的韧性增强规划和灾害响应提供了实用的工具和策略。

> **摘要翻译:** 近年来，全球天气变得更加不规律和极端，经常导致大规模、长时间的停电。韧性——即承受、适应和从大规模中断中恢复的能力——已成为电力行业的首要任务。然而，目前对电网韧性的理解大多停留在概念层面，或仅关注特定组件，未能产生可操作的结果或揭示系统层面的深刻见解。本研究利用受数据和领域知识观察模式启发的统计模型，提供了电网韧性的定量可测量定义。我们分析了大规模的每刻钟历史电力客户停电数据和相应的天气记录，并建立了模型与行业韧性实践之间的联系。我们展示了利用美国东海岸三个主要服务区域进行韧性分析。我们的分析表明，累积天气效应在导致即时、持续停电方面起着关键作用，并且这些停电会传播并导致邻近区域的二次停电。所提出的模型还为电网韧性增强规划提供了一些有趣的见解。例如，我们的模拟结果表明，在少数关键位置增强电力基础设施可以将马萨诸塞州客户停电数量减少近一半。此外，我们已经证明，我们的模型在预测极端天气事件期间客户停电进展方面取得了令人满意的准确性，这对于系统运营商和联邦机构准备灾害响应非常有价值。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [371] [Tomographic reconstruction of a disease transmission landscape via GPS recorded random paths](https://arxiv.org/abs/2404.04455)
> *通过GPS记录的随机路径对疾病传播景观进行断层重建*

*Jairo Diaz-Rodriguez, Juan Pablo Gomez, Jeremy P. Orange, Nathan D. Burkett-Cadena, Samantha M. Wisely, Jason K. Blackburn, Sylvain Sardy* | **Category: stat.AP** | **Updated: 2025-08-04**

**Keywords:** 流行病学断层扫描, GPS动物追踪, 疾病传播景观, Radon变换, 总变差正则化

**Comment:** 

> **TL;DR:** 一种新颖的流行病学断层扫描方法，利用GPS动物追踪数据估算景观对疾病感染的倾向性，表现优于传统方法。

**AI_Comments:** 该方法的创新之处在于将医学成像（PET）中常用的断层扫描技术应用于流行病学监测，并结合GPS动物追踪数据。这提供了一种数据驱动的方法来识别疾病热点，超越了对生态假设的依赖。其优于替代方法的性能以及解决数据限制的能力突显了其在疾病管理方面的实际重要性。该框架的新颖性，即没有针对此类数据量身定制的现有统计方法，进一步强调了其贡献。

<details>
  <summary>Details</summary>

**Motivation:** 识别景观中个体疾病感染可能性较高的区域是疾病管理的关键。本文旨在提供一种新颖的方法，不同于依赖生态假设的传统方法。

**Method:** 本研究采用一种新颖的流行病学断层扫描技术，利用GPS动物追踪数据估算景观对疾病感染的倾向性，其方式类似于正电子发射断层扫描（PET）中的断层扫描技术。将追踪数据视为随机Radon变换，分析保护区内鹿科动物的移动，并结合流行性出血病病毒（EHDV）的抗体水平。通过对场域进行离散化并构建每只鹿在网格点停留时间的回归矩阵，将二元响应（感染或未感染）建模为一个二项式线性逆问题，并通过总变差正则化强制执行空间相干性。重建的倾向性图的光滑度由分位数通用阈值选择。为解决小样本量限制并评估估计的显著性，采用基于引导的数据增强程序量化不确定性。

**Result:** 本方法在使用模拟数据和真实数据时均优于替代方法。

**Conclusion:** 这种断层扫描框架是新颖的，没有针对此类数据量身定制的现有统计方法。该方法有效且优于替代方案。

> **ai_Abstract:** 本文介绍了一种新颖的流行病学断层扫描方法，该方法利用GPS动物追踪数据（类似于PET扫描）来重建景观中的疾病感染倾向性图。通过将追踪数据视为随机Radon变换，并应用具有总变差正则化的二项式线性逆问题，该方法有效地识别了高风险区域。在鹿科动物移动和EHDV抗体水平数据上进行测试，该方法表现出优于传统方法的性能，并通过基于引导的数据增强程序解决了小样本量限制。

> **摘要翻译:** 识别景观中个体疾病感染可能性较高的区域是疾病管理的关键。与依赖生态假设的传统方法不同，我们采用一种新颖的流行病学断层扫描技术，利用GPS动物追踪数据，以类似于正电子发射断层扫描（PET）中的断层扫描技术的方式，估算景观对疾病感染的倾向性。我们将追踪数据视为随机Radon变换，分析了保护区内鹿科动物的移动，并结合了流行性出血病病毒（EHDV）的抗体水平——这是一种由蠓叮咬传播的媒介传播疾病。在对场域进行离散化并构建每只鹿（行）在网格（列）的每个点停留时间的回归矩阵后，我们将二元响应（感染或未感染）建模为一个二项式线性逆问题，其中通过总变差正则化强制执行空间相干性。重建的倾向性图的光滑度通过分位数通用阈值选择。为了解决小样本量限制并评估我们估计的显著性，我们使用基于引导的数据增强程序量化不确定性。我们的方法在使用模拟数据和真实数据时均优于替代方法。这种断层扫描框架是新颖的，没有针对此类数据量身定制的现有统计方法。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [385] [The Impact of Question Framing on the Performance of Automatic Occupation Coding](https://arxiv.org/abs/2501.05584)
> *问卷措辞对自动职业编码性能的影响*

*Olga Kononykhina, Frauke Kreuter, Malte Schierholz* | **Category: stat.AP, stat.OT** | **Updated: 2025-08-05**

**Keywords:** 职业数据, 自动编码, 问卷措辞, 调查实验, 数据质量

**Comment:** 

> **TL;DR:** 本研究调查了职业问题措辞对数据变异性和自动编码工具性能的影响，发现自动编码工具对问题格式敏感，且“职位名称”格式比“职业任务”格式更高效。

**AI_Comments:** 本研究通过实验方法，揭示了看似细微的问卷措辞差异对自动编码工具性能的显著影响，具有重要的实践意义。它不仅指出了现有自动编码工具的局限性，即对输入数据格式的敏感性，还为如何改进职业数据收集提供了具体建议（例如，优先使用“职位名称”格式）。此外，研究也强调了后续指导示例的作用，尽管其对词汇多样性的影响有限。论文的创新点在于量化了问卷设计对自动化流程效率的影响，对于依赖自动化编码的大规模调查尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 职业数据在研究、官方统计和政策制定中至关重要，但其收集和准确分类仍面临挑战。本研究旨在调查职业问题措辞对数据变异性以及自动编码工具性能的影响。

**Method:** 本研究在德国进行并复制了一项分票调查实验，使用了两种常见的职业问题格式：一种侧重于“职位名称”，另一种侧重于“职业任务”。研究还分析了提供指导性示例对后续“详细任务和职责”问题回答的影响。

**Result:** 分析显示，CASCOT和OccuCoDe等自动编码工具对数据形式和来源敏感。具体而言，这些工具在编码“职位名称”问题格式的回答时比“职业任务”格式更高效。在随后的“详细任务和职责”问题中，提供指导性示例促使受访者给出更长的答案，但并未拓宽他们使用的独特词汇范围。

**Conclusion:** 研究结果强调了协调调查问题和确保自动编码工具对问题措辞差异具有鲁棒性的重要性。论文强调需要进一步研究以优化问题设计和编码工具，从而提高职业数据收集的准确性和适用性。

> **ai_Abstract:** 本研究探讨了职业问题措辞对数据质量和自动职业编码工具性能的影响。通过在德国进行分票调查实验，比较了“职位名称”和“职业任务”两种问题格式，发现自动编码工具（如CASCOT和OccuCoDe）对问题格式敏感，且对“职位名称”格式的编码效率更高。此外，在详细任务问题中提供示例可增加回答长度。研究强调了协调调查问题和提高自动编码工具鲁棒性的重要性，并呼吁进一步优化问卷设计和编码工具。

> **摘要翻译:** 职业数据在研究、官方统计和政策制定中发挥着至关重要的作用，但其收集和准确分类仍然是一个挑战。本研究调查了职业问题措辞对数据变异性和自动编码工具性能的影响。我们在德国进行并复制了一项分票调查实验，使用了两种常见的职业问题格式：一种侧重于“职位名称”（Berufsbezeichnung），另一种侧重于“职业任务”（berufliche T"atigkeit）。我们的分析表明，CASCOT和OccuCoDe等自动编码工具对数据的形式和来源表现出敏感性。具体而言，与职业任务格式相比，这些工具在编码对职位名称问题格式的回答时效率更高，这表明可以改进许多德国调查中的相关问题。在随后的“详细任务和职责”问题中，提供指导性示例促使受访者给出更长的答案，而没有拓宽他们使用的独特词汇范围。这些发现突出了协调调查问题以及确保自动编码工具对问题措辞差异具有鲁棒性的重要性。我们强调需要进一步研究以优化问题设计和编码工具，从而在职业数据收集中实现更高的准确性和适用性。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='q-finmf'></a>
## q-fin.MF 

### [301] [Modeling Loss-Versus-Rebalancing in Automated Market Makers via Continuous-Installment Options](https://arxiv.org/abs/2508.02971)
> *通过连续分期期权建模自动化做市商的损失与再平衡*

*Srisht Fateh Singh, Reina Ke Xin Li, Samuel Gaskin, Yuntao Wu, Jeffrey Klinck, Panagiotis Michalopoulos, Zissis Poulos, Andreas Veneris* | **Category: q-fin.MF, q-fin.PR, q-fin.TR** | **Updated: 2025-08-05**

**Keywords:** 自动化做市商, 损失与再平衡, 连续分期期权, 期权理论, 流动性提供

**Comment:** 

> **TL;DR:** 该论文通过连续分期期权对自动化做市商（AMM）的损失与再平衡（LVR）进行建模，证明LVR等同于期权的时间价值衰减，并为流动性提供者提供了一种估算恒定LVR的方法。

**AI_Comments:** 该论文为理解和量化AMM中的LVR提供了一个新颖且严谨的期权理论框架。通过将LVR与期权的时间价值衰减（theta）联系起来，它提供了深刻的理论见解。为流动性提供者提供基于可预测LVR优化其头寸的实用指导，是解决DeFi中关键挑战的一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在通过数学建模常数函数自动化做市商（CFAMM）头寸，以理解和量化损失与再平衡（LVR），并为流动性提供者提供一个实用的框架来优化他们的头寸并估计未来的逆向选择成本。

**Method:** 该论文将CFAMM头寸建模为永续美式连续分期（CI）期权的投资组合。它利用此模型复制AMM头寸的delta并分析LVR。论文还描述了如何校准常数波动率参数。

**Result:** 结果表明：(a) AMM的LVR在分析上与复制投资组合中嵌入的平价CI期权所赚取的连续资金费用（theta）完全相同。(b) 该模型推导出了AMM流动性头寸的delta曲线和边界，这些曲线和边界在任意长的远期窗口内能承受近似恒定的LVR。(c) 论文描述了如何校准永续期权所需的常数波动率参数，并估计了隐含波动率校准和LVR残余误差的误差。(d) 该工作提供了一个实用框架，使流动性提供者能够选择AMM流动性配置和价格边界，以实现近似恒定且与价格无关的LVR。

**Conclusion:** 该工作为AMM及其LVR提供了严格的期权理论解释，并为流动性提供者估计未来逆向选择成本和优化头寸参数提供了可操作的指导。

> **ai_Abstract:** 这篇论文将常数函数自动化做市商（CFAMM）头寸建模为永续美式连续分期（CI）期权的投资组合。它证明了自动化做市商（AMM）的损失与再平衡（LVR）等同于嵌入式CI期权的连续资金费用。该模型还推导了在较长时间内具有近似恒定LVR的流动性配置，并提供了校准波动率的方法。该框架为流动性提供者提供了实用指导，通过选择AMM流动性配置和价格边界，以优化其头寸并估计逆向选择成本。

> **摘要翻译:** 这篇论文通过将常数函数自动化做市商（CFAMM）头寸数学建模为一系列奇异期权（即永续美式连续分期（CI）期权）的投资组合。该模型在无限时间范围内复制了AMM头寸在每个时间点的delta，从而考虑了流动性提供的永续性和提款期权。该框架产生了两个关键的理论结果：(a) 它证明了AMM的逆向选择成本，即损失与再平衡（LVR），在分析上与复制投资组合中嵌入的平价CI期权所赚取的连续资金费用（时间价值衰减或theta）完全相同。(b) 该模型的一个特例推导出了AMM流动性头寸的delta曲线和边界，这些曲线和边界在任意长的远期窗口内，除有界残余误差外，承受近似恒定的LVR。最后，论文描述了如何从隐含波动率的期限结构中校准永续期权所需的常数波动率参数，并估计了隐含波动率校准和LVR残余误差的误差。因此，这项工作提供了一个实用的框架，使流动性提供者能够选择AMM流动性配置和价格边界，以便在任意长的、前瞻性的时间窗口内，他们可以预期近似恒定且与价格无关的LVR。这些结果建立了对AMM及其LVR的严格期权理论解释，并为流动性提供者估计未来逆向选择成本和优化头寸参数提供了可操作的指导。

</details>

[⬆️ 返回分类顶部](#q-finmf) | [⬆️ 返回总目录](#toc)

---

### [329] [Pricing energy spread options with variance gamma-driven Ornstein-Uhlenbeck dynamics](https://arxiv.org/abs/2507.11480)
> *基于方差伽马驱动Ornstein-Uhlenbeck动力学模型的能源价差期权定价*

*Tim Leung, Kevin W. Lu* | **Category: q-fin.MF** | **Updated: 2025-08-05**

**Keywords:** 能源价差期权, 方差伽马过程, Ornstein-Uhlenbeck过程, 期权定价, FFT方法

**Comment:** 

> **TL;DR:** 本文提出了一种基于方差伽马驱动的Ornstein-Uhlenbeck过程来定价能源价差期权的方法，并推导了定价公式和提供了数值结果。

**AI_Comments:** 本文的创新之处在于将方差伽马过程引入到Ornstein-Uhlenbeck动力学模型中，以更好地捕捉能源价格的均值回归和无限活跃特性。通过结合Esscher变换和FFT方法，提供了一种有效且实用的期权定价框架，对于金融工程和能源市场风险管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为遵循指数Ornstein-Uhlenbeck过程的现货价格，特别是具有均值回归和无限活跃价格动态的能源价差期权进行定价。

**Method:** 研究考虑了由独立多元方差伽马过程之和驱动的指数Ornstein-Uhlenbeck过程。通过Esscher变换得到等价鞅测度，并关注弱方差alpha-gamma过程。推导了创新项累积量生成函数的解析表达式，从而得到了远期合约的定价公式，并应用Hurd和Zhou的FFT方法对价差期权进行定价。最后，还展示了模型如何在真实世界测度下对能源价格进行估计以及如何根据远期或看涨期权价格进行校准。

**Result:** 本文得到了远期合约的定价公式，并成功应用FFT方法对价差期权进行了定价。此外，还提供了价差期权定价的数值结果，并展示了模型在真实世界测度下估计和校准的方法。

**Conclusion:** 该研究成功地开发并验证了一种基于方差伽马驱动的Ornstein-Uhlenbeck过程的能源价差期权定价模型，提供了实用的定价公式和数值结果。

> **ai_Abstract:** 本文研究了能源价差期权的定价问题，其中现货价格由指数Ornstein-Uhlenbeck过程和独立多元方差伽马过程共同驱动。通过Esscher变换和累积量生成函数的解析推导，获得了远期合约的定价公式，并结合Hurd和Zhou的FFT方法实现了价差期权的定价。文章还详细阐述了模型在实际能源价格数据上的估计与校准方法，并提供了相应的数值结果。

> **摘要翻译:** 我们考虑了能源价差期权的定价，其中现货价格遵循由独立多元方差伽马过程之和驱动的指数Ornstein-Uhlenbeck过程，这产生了均值回归、无限活跃的价格动态。在这类驱动过程中，Esscher变换被用来获得等价鞅测度，重点关注弱方差alpha-gamma伽马过程。通过推导创新项累积量生成函数的解析表达式，我们获得了远期合约的定价公式，并应用Hurd和Zhou的FFT方法对价差期权进行定价。最后，我们演示了该模型如何在真实世界测度下对能源价格进行估计和根据远期或看涨期权价格进行校准，并提供了价差期权定价的数值结果。

</details>

[⬆️ 返回分类顶部](#q-finmf) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [11] [Model Accuracy and Data Heterogeneity Shape Uncertainty Quantification in Machine Learning Interatomic Potentials](https://arxiv.org/abs/2508.03405)
> *模型精度与数据异质性影响机器学习原子间势的不确定性量化*

*Fei Shuang, Zixiong Wei, Kai Liu, Wei Gao, Poulumi Dey* | **Category: cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 不确定性量化, 机器学习原子间势, 数据异质性, 集成学习, D-最优性

**Comment:** 

> **TL;DR:** 本研究探讨了机器学习原子间势（MLIPs）中的不确定性量化（UQ）策略。研究发现，模型精度越高，UQ效果越好，但数据异质性会降低UQ性能。为解决异质数据集的问题，论文提出了一种聚类增强的局部D-最优性方法，显著提高了新颖原子环境的检测能力，为MLIPs的开发提供了更稳健的主动学习和自适应采样策略。

**AI_Comments:** 该论文通过阐明模型精度、数据异质性与机器学习原子间势（MLIPs）中不确定性量化（UQ）之间的相互作用，做出了重要贡献。引入聚类增强的局部D-最优性是一种创新性解决方案，有效解决了MLIP开发中处理多样化数据的实际问题，提高了UQ的鲁棒性。这项工作对改进主动学习和自适应采样策略具有直接的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习原子间势（MLIPs）能够实现精确的原子模拟，但可靠的不确定性量化（UQ）仍然难以捉摸。本研究旨在阐明模型保真度和数据异质性在UQ性能中的作用，以解决这一挑战。

**Method:** 本研究在原子团簇展开框架内，调查了两种不确定性量化（UQ）策略：集成学习（ensemble learning）和D-最优性（D-optimality）。为解决异质数据集上的限制，引入了聚类增强的局部D-最优性方法，该方法在训练期间将配置空间划分为簇，并在每个簇内应用D-最优性。

**Result:** 研究发现，更高的模型精度能增强预测不确定性与实际误差之间的相关性，并改善新颖性检测，其中D-最优性产生了更保守的估计。两种方法在同质训练集上都能提供良好校准的不确定性，但在异质数据集上会低估误差并表现出新颖性敏感性降低。新引入的聚类增强的局部D-最优性方法显著改善了异质数据集中新颖原子环境的检测。

**Conclusion:** 本研究的发现阐明了模型保真度和数据异质性在不确定性量化性能中的作用，并为机器学习原子间势（MLIPs）开发中稳健的主动学习和自适应采样策略提供了实用途径。

> **ai_Abstract:** 本论文探讨了机器学习原子间势（MLIPs）中的不确定性量化（UQ）策略，重点研究了集成学习和D-最优性。研究表明，模型精度越高，不确定性预测与实际误差的相关性越强，新颖性检测能力越好；然而，数据异质性会导致误差低估和新颖性敏感性降低。为应对这一挑战，论文提出了一种聚类增强的局部D-最优性方法，通过在训练时将配置空间划分为簇并在簇内应用D-最优性，显著提高了异质数据集中新颖原子环境的检测能力。这项工作阐明了模型保真度和数据异质性对UQ性能的影响，并为MLIP开发提供了实用的主动学习和自适应采样策略。

> **摘要翻译:** 机器学习原子间势（MLIPs）能够实现精确的原子模拟，但可靠的不确定性量化（UQ）仍然难以捉摸。在本研究中，我们研究了原子团簇展开框架内的两种UQ策略：集成学习和D-最优性。结果表明，更高的模型精度能增强预测不确定性与实际误差之间的相关性，并改善新颖性检测，其中D-最优性产生了更保守的估计。这两种方法在同质训练集上都能提供良好校准的不确定性，但在异质数据集上，它们会低估误差并表现出新颖性敏感性降低。为了解决这一限制，我们引入了聚类增强的局部D-最优性，该方法在训练期间将配置空间划分为簇，并在每个簇内应用D-最优性。这种方法显著改善了异质数据集中新颖原子环境的检测。我们的发现阐明了模型保真度和数据异质性在UQ性能中的作用，并为MLIP开发中稳健的主动学习和自适应采样策略提供了实用途径。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [248] [CrystalGRW: Generative Modeling of Crystal Structures with Targeted Properties via Geodesic Random Walks](https://arxiv.org/abs/2501.08998)
> *CrystalGRW：通过测地线随机游走实现具有目标性质的晶体结构生成模型*

*Krit Tangsongcharoen, Teerachote Pakornchote, Chayanon Atthapak, Natthaphon Choomphon-anomakhun, Annop Ektarawong, Björn Alling, Christopher Sutton, Thiti Bovornratanaraks, Thiparat Chotibut* | **Category: cond-mat.mtrl-sci, cond-mat.stat-mech, cs.LG, physics.comp-ph, 68T07** | **Updated: 2025-08-04**

**Keywords:** 晶体结构生成, 扩散模型, 黎曼流形, 等变图神经网络, 材料发现

**Comment:** Updated results using the model trained on the ALEX-MP-20 dataset.
  13+14 pages, 12 figures

> **TL;DR:** CrystalGRW是一种基于扩散的生成模型，它能在黎曼流形上生成具有目标性质的稳定晶体结构，加速材料发现。

**AI_Comments:** CrystalGRW的创新之处在于其将扩散模型应用于黎曼流形，以处理晶体结构的周期性和对称性，这为晶体材料的生成建模提供了一个新颖且强大的框架。其条件控制能力对于有针对性的材料设计尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 计算材料科学中的一个核心挑战是确定候选晶体材料是否热力学稳定，这依赖于识别其真正的基态结构。

**Method:** 本文引入了CrystalGRW，一个在黎曼流形上基于扩散的生成模型。它通过在黎曼流形上表示晶体性质（如分数坐标、原子类型和晶格矩阵）来确保生成过程中晶体结构的周期性。模型还整合了一个等变图神经网络，以在生成过程中考虑旋转和平移对称性。

**Result:** CrystalGRW能够生成接近基态的真实晶体结构，其准确性与现有模型相当。它还支持条件控制，例如指定所需的晶体点群。

**Conclusion:** CrystalGRW通过提供稳定、对称一致的晶体候选结构，加速了材料发现和逆向设计，有助于实验验证。

> **ai_Abstract:** CrystalGRW是一种新型的基于扩散的生成模型，用于在黎曼流形上生成具有目标性质的晶体结构。该模型通过在黎曼流形上表示晶体特性并结合等变图神经网络，确保生成结构的周期性和对称性。它能有效预测稳定的晶体相，并生成接近基态的真实结构，其性能与现有模型相当，并支持条件生成，从而加速了材料发现和逆向设计过程。

> **摘要翻译:** 确定候选晶体材料是否热力学稳定取决于识别其真正的基态结构，这是计算材料科学中的一个核心挑战。我们引入了CrystalGRW，一种在黎曼流形上基于扩散的生成模型，它能提出新颖的晶体构型，并能预测经密度泛函理论验证的稳定相。晶体性质，如分数坐标、原子类型和晶格矩阵，在合适的黎曼流形上表示，确保通过扩散过程生成的新预测保留晶体结构的周期性。我们整合了一个等变图神经网络，以在生成过程中也考虑旋转和平移对称性。CrystalGRW展示了生成接近其基态的真实晶体结构的能力，其准确性与现有模型相当，同时还支持条件控制，例如指定所需的晶体点群。这些特性通过为实验验证提供稳定、对称一致的晶体候选结构，有助于加速材料发现和逆向设计。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [256] [PET-MAD, a lightweight universal interatomic potential for advanced materials modeling](https://arxiv.org/abs/2503.14118)
> *PET-MAD：一种用于先进材料建模的轻量级通用原子间势*

*Arslan Mazitov, Filippo Bigi, Matthias Kellner, Paolo Pegolo, Davide Tisi, Guillaume Fraux, Sergey Pozdnyakov, Philip Loche, Michele Ceriotti* | **Category: cond-mat.mtrl-sci, cs.LG, physics.chem-ph** | **Updated: 2025-08-04**

**Keywords:** 机器学习原子间势, PET-MAD, 材料模拟, 通用势, 轻量级

**Comment:** New version of the Manuscript after a latest resubmission

> **TL;DR:** PET-MAD是一种轻量级通用机器学习原子间势，通过多样化数据集训练，在保持高精度的同时，适用于无机、有机材料及表面，并能有效进行热力学和量子涨落研究。

**AI_Comments:** PET-MAD的创新之处在于其轻量级架构和小训练集却能达到与SOTA模型相当的性能，并且通用性强，能同时处理无机和有机材料及表面。其通过系统修改数据集以增强原子多样性的方法值得关注。此外，其开箱即用的能力以及高效微调达到全量子力学精度的潜力，使其在材料科学模拟领域具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的“通用”机器学习原子间势虽然能提供接近第一性原理计算的精度且成本较低，但往往偏向于低能量构型。因此，需要开发一种更通用、更可靠、且能处理原子多样性的新型原子间势。

**Method:** 本文引入了PET-MAD，这是一种通用的机器学习原子间势，其训练数据集结合了稳定的无机和有机固体，并经过系统修改以增强原子多样性。在适中但高度一致的电子结构理论水平下，通过对既定基准和六种材料的先进模拟评估了PET-MAD的准确性。

**Result:** 尽管训练集较小且架构轻量，PET-MAD在无机固体方面与最先进的机器学习原子间势具有竞争力，同时对分子、有机材料和表面也表现出可靠性。它稳定且快速，能够开箱即用地对热力学和量子力学涨落、功能特性和相变进行接近定量的研究。此外，它可以通过最少量的目标计算进行高效微调，以达到完全的量子力学精度。

**Conclusion:** PET-MAD是一种高性能、通用且高效的轻量级机器学习原子间势，能够以接近第一性原理的精度，对多种材料（包括无机、有机和表面）进行广泛的原子尺度模拟，并支持后续的精确微调。

> **ai_Abstract:** 本文介绍了PET-MAD，一种轻量级且通用的机器学习原子间势，旨在克服现有通用模型偏向低能量构型的问题。PET-MAD通过结合无机和有机固体的多样化数据集进行训练，并在适中的电子结构理论水平下进行评估。研究表明，尽管训练集小且架构轻量，PET-MAD在无机材料、分子、有机材料和表面方面均表现出与最先进模型相当甚至更优的精度和可靠性。它还具有稳定性、速度快、支持热力学和量子涨落研究，并能高效微调以达到全量子力学精度等优点。

> **摘要翻译:** 机器学习原子间势（MLIPs）极大地扩展了原子尺度模拟的范围，以一小部分成本提供了第一性原理计算的精度。利用大型量子力学数据库和富有表现力的架构，最近的“通用”模型在整个元素周期表中提供了定性精度，但通常偏向于低能量构型。我们引入了PET-MAD，这是一种通用的MLIP，其训练数据集结合了稳定的无机和有机固体，并经过系统修改以增强原子多样性。使用适中但高度一致的电子结构理论水平，我们评估了PET-MAD在既定基准和六种材料的先进模拟中的准确性。尽管训练集较小且架构轻量，PET-MAD在无机固体方面与最先进的MLIPs具有竞争力，同时对分子、有机材料和表面也表现出可靠性。它稳定且快速，能够开箱即用地对热力学和量子力学涨落、功能特性和相变进行接近定量的研究。它可以通过最少量的目标计算进行高效微调，以达到完全的量子力学精度。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [403] [Artificial Intelligence and Generative Models for Materials Discovery -- A Review](https://arxiv.org/abs/2508.03278)
> *人工智能和生成模型在材料发现中的应用——综述*

*Albertus Denny Handoko, Riko I Made* | **Category: cond-mat.mtrl-sci, cs.AI, physics.app-ph** | **Updated: 2025-08-05**

**Keywords:** 人工智能, 生成模型, 材料发现, 逆向设计, 机器学习

**Comment:** Review Article in the Thematic Issue on Artificial Intelligence for
  Materials Discovery in World Scientific Annual Review of Functional Materials

> **TL;DR:** 本综述探讨了人工智能驱动的生成模型在材料发现中的应用，包括其原理、具体应用、挑战以及未来发展方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地总结了人工智能，特别是生成模型，在材料发现领域的最新进展、应用、面临的挑战以及未来的发展方向。它强调了从传统实验驱动向AI驱动的“逆向设计”范式转变，并指出了数据、计算和可解释性方面的关键问题。对于希望进入或深入了解AI在材料科学中应用的研究人员来说，这是一份非常有价值的指南。

<details>
  <summary>Details</summary>

**Motivation:** 随着高通量实验工具、机器学习方法和开放材料数据库的发展，材料发现正从实验驱动转向人工智能驱动，以实现“逆向设计”能力，从而根据所需的性能发现新材料。本综述旨在讨论适用于材料发现的人工智能驱动生成模型的不同原理。

**Method:** 本综述讨论了适用于材料发现的人工智能驱动生成模型的不同原理，包括可用于此目的的不同材料表示方法。它重点介绍了生成模型在设计新催化剂、半导体、聚合物或晶体方面的具体应用，同时探讨了数据稀缺、计算成本、可解释性、可合成性和数据集偏差等挑战。此外，还讨论了克服局限性并将人工智能与实验工作流程相结合的新兴方法，包括多模态模型、物理信息架构和闭环发现系统。

**Result:** 本综述提供了对研究人员的见解，旨在帮助他们利用人工智能的变革潜力，加速可持续发展、医疗保健和能源创新领域的材料发现。它系统地讨论了生成模型的原理、应用、挑战以及克服这些挑战的新兴方法。

**Conclusion:** 人工智能和生成模型在加速材料发现方面具有巨大的潜力，通过解决数据稀缺、计算成本等挑战，并结合新兴方法，可以推动可持续发展、医疗保健和能源领域的创新。

> **ai_Abstract:** 本综述探讨了人工智能（AI）驱动的生成模型在材料发现中的应用。文章讨论了这些模型的原理、不同的材料表示方法，并重点介绍了它们在设计催化剂、半导体、聚合物和晶体方面的具体应用。同时，综述也深入分析了数据稀缺、计算成本、可解释性、可合成性及数据集偏差等现有挑战，并提出了多模态模型、物理信息架构和闭环发现系统等新兴解决方案。该综述旨在为研究人员提供指导，以利用AI加速材料发现，从而促进可持续发展、医疗保健和能源领域的创新。

> **摘要翻译:** 高通量实验工具、机器学习（ML）方法和开放材料数据库正在彻底改变新材料的发现方式。我们正从过去以实验驱动的方法迅速转向人工智能（AI）驱动的方法，实现“逆向设计”能力，从而根据所需的性能发现新材料。本综述旨在讨论适用于材料发现的人工智能驱动生成模型的不同原理，包括可用于此目的的不同材料表示方法。我们还将重点介绍生成模型在设计新催化剂、半导体、聚合物或晶体方面的具体应用，同时解决数据稀缺、计算成本、可解释性、可合成性和数据集偏差等挑战。为了克服这些局限性并将人工智能与实验工作流程相结合，本文还将讨论新兴方法，包括多模态模型、物理信息架构和闭环发现系统。本综述旨在为旨在利用人工智能的变革潜力，加速可持续发展、医疗保健和能源创新领域的材料发现的研究人员提供见解。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [611] [Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning](https://arxiv.org/abs/2508.02956)
> *通过多智能体物理感知科学推理实现无机材料的自主发现*

*Alireza Ghafarollahi, Markus J. Buehler* | **Category: cond-mat.mtrl-sci, cond-mat.dis-nn, cond-mat.mes-hall, cs.AI, cs.LG** | **Updated: 2025-08-04**

**Keywords:** 无机材料发现, 多智能体AI, 材料设计, 科学推理, SparksMatter

**Comment:** 

> **TL;DR:** SparksMatter是一个多智能体AI模型，能自主进行无机材料设计，从构思到实验验证，并生成新颖的材料，超越现有模型。

**AI_Comments:** SparksMatter的创新在于其多智能体架构和自主执行完整材料发现周期的能力，包括自我批判和后续验证建议，这超越了传统单次机器学习模型的局限性。它不仅能预测和生成材料，还能进行科学推理和迭代优化，显著提高了材料发现的效率和新颖性。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习在无机材料设计中受限于训练数据，无法自主执行从构思到迭代优化的完整发现周期，这是一个核心挑战。

**Method:** 本文引入了SparksMatter，一个多智能体AI模型，用于自动化无机材料设计。它通过生成想法、设计和执行实验工作流、持续评估和完善结果来响应用户查询，并提出符合目标的候选材料。SparksMatter还能自我批判、识别研究空白并建议后续验证步骤，包括DFT计算和实验合成与表征。

**Result:** SparksMatter在热电材料、半导体和钙钛矿氧化物材料设计案例中进行了评估。结果表明它能生成针对用户需求的新颖稳定无机结构。与前沿模型进行基准测试显示，SparksMatter在相关性、新颖性和科学严谨性方面持续获得更高分数，并在多项实际设计任务中显著提高了新颖性。

**Conclusion:** 这些结果表明SparksMatter具有生成超出现有材料知识的化学有效、物理有意义且富有创造性的无机材料假设的独特能力。

> **ai_Abstract:** 本文介绍了SparksMatter，一个用于自主无机材料发现的多智能体AI模型。它旨在克服传统机器学习在材料设计中受限于训练数据和无法自主完成整个发现周期的不足。SparksMatter能够从构思、规划到实验执行和结果优化，自主生成、评估并提出符合用户目标的新颖材料。通过在热电材料、半导体和钙钛矿氧化物等案例中的评估，SparksMatter展现出生成新颖稳定无机结构的能力，并在相关性、新颖性和科学严谨性方面超越现有前沿模型，特别是在新颖性方面有显著提升。

> **摘要翻译:** 传统机器学习方法通过准确的性能预测和有针对性的材料生成加速无机材料设计，但它们作为单次模型运行，受限于训练数据中隐含的知识。一个核心挑战在于创建一个能够自主执行完整无机材料发现周期的智能系统，从构思和规划到实验和迭代完善。我们引入了SparksMatter，一个用于自动化无机材料设计的多智能体AI模型，它通过生成想法、设计和执行实验工作流、持续评估和完善结果，并最终提出符合目标候选材料来解决用户查询。SparksMatter还能批判和改进自己的响应，识别研究空白和局限性，并建议严格的后续验证步骤，包括DFT计算和实验合成与表征，所有这些都嵌入在结构良好的最终报告中。该模型在热电材料、半导体和钙钛矿氧化物材料设计案例中进行了性能评估。结果表明SparksMatter能够生成针对用户需求的新颖稳定无机结构。与前沿模型进行基准测试显示，SparksMatter在相关性、新颖性和科学严谨性方面持续获得更高分数，在多项实际设计任务中，经盲审评估员评估，新颖性显著提高。这些结果证明了SparksMatter具有生成超越现有材料知识的化学有效、物理有意义且富有创造性的无机材料假设的独特能力。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [979] [The Open DAC 2025 Dataset for Sorbent Discovery in Direct Air Capture](https://arxiv.org/abs/2508.03162)
> *用于直接空气捕获吸附剂发现的开放 DAC 2025 数据集*

*Anuroop Sriram, Logan M. Brabson, Xiaohan Yu, Sihoon Choi, Kareem Abdelmaqsoud, Elias Moubarak, Pim de Haan, Sindy Löwe, Johann Brehmer, John R. Kitchin, Max Welling, C. Lawrence Zitnick, Zachary Ulissi, Andrew J. Medford, David S. Sholl* | **Category: cond-mat.mtrl-sci, cs.LG, physics.chem-ph** | **Updated: 2025-08-05**

**Keywords:** 直接空气捕获, MOFs, 数据集, 机器学习势能, 吸附剂发现

**Comment:** 

> **TL;DR:** 该研究提出了 Open DAC 2025 (ODAC25) 数据集，这是 ODAC23 的重大扩展和改进，包含近 7000 万次 DFT 单点计算，涵盖 15,000 种 MOF 中 CO2、H2O、N2 和 O2 的吸附。ODAC25 通过功能化的 MOF、高能 GCMC 衍生的吸附位点以及合成生成的框架引入了化学和构型多样性，并改进了 DFT 计算的准确性和柔性 MOF 的处理。此外，研究还发布了在 ODAC25 上训练的先进机器学习势能，并评估了其在吸附能和亨利系数预测方面的性能。

**AI_Comments:** 该研究通过构建一个大规模、多样化的数据集（ODAC25）并结合先进的机器学习势能，为直接空气捕获吸附剂的发现提供了一个强大的新平台。数据集的扩展性和计算的改进是显著的，但实际应用中的计算成本和模型泛化能力仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 在潮湿空气中识别用于直接空气捕获 (DAC) 的有用吸附剂材料仍然是一个挑战。

**Method:** 提出了 Open DAC 2025 (ODAC25) 数据集，该数据集包含近 7000 万次 DFT 单点计算，用于 15,000 种 MOF 中 CO2、H2O、N2 和 O2 的吸附。ODAC25 通过功能化的 MOF、高能 GCMC 衍生的吸附位点以及合成生成的框架引入了化学和构型多样性。此外，还发布了在 ODAC25 上训练的机器学习势能，并评估了其在吸附能和亨利系数预测方面的性能。

**Result:** ODAC25 数据集包含近 7000 万次 DFT 计算，涵盖 15,000 种 MOF 中 CO2、H2O、N2 和 O2 的吸附。发布了在 ODAC25 上训练的机器学习势能，并在吸附能和亨利系数预测方面进行了评估。

**Conclusion:** ODAC25 数据集及其关联的机器学习势能为直接空气捕获吸附剂的发现提供了重要的资源，有望克服现有挑战。

> **ai_Abstract:** 该研究介绍了 Open DAC 2025 (ODAC25) 数据集，这是对现有 ODAC23 数据集的重大改进和扩展，包含了针对 15,000 种金属有机框架 (MOF) 中 CO$_2$、H$_2$O、N$_2$ 和 O$_2$ 吸附的近 7000 万次 DFT 计算。ODAC25 通过引入功能化 MOF、高能 GCMC 衍生的吸附位点和合成框架，增加了化学和构型多样性，并提高了 DFT 计算的准确性和对柔性 MOF 的处理能力。此外，研究还发布了基于 ODAC25 训练的先进机器学习势能，并评估了其在吸附能和亨利系数预测方面的性能。

> **摘要翻译:** 在潮湿空气中识别用于直接空气捕获 (DAC) 的有用吸附剂材料仍然是一个挑战。我们提出了 Open DAC 2025 (ODAC25) 数据集，这是 ODAC23 (Sriram 等人，ACS Central Science, 10 (2024) 923) 的重大扩展和改进，包含近 7000 万次 DFT 单点计算，用于 15,000 种 MOF 中 CO$_2$、H$_2$O、N$_2$ 和 O$_2$ 的吸附。ODAC25 通过功能化的 MOF、高能 GCMC 衍生的吸附位点以及合成生成的框架引入了化学和构型多样性。ODAC25 在 ODAC23 的 DFT 计算准确性和柔性 MOF 处理方面也进行了显著改进。除了数据集，我们还发布了在 ODAC25 上训练的新的最先进的机器学习势能，并评估了它们在吸附能和亨利系数预测方面的性能。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [14] [A Dual Optimization View to Empirical Risk Minimization with f-Divergence Regularization](https://arxiv.org/abs/2508.03314)
> *带有f-散度正则化的经验风险最小化的对偶优化视角*

*Francisco Daunas, Iñaki Esnaola, Samir M. Perlaza* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 经验风险最小化, f-散度正则化, 对偶优化, 归一化函数, 非线性常微分方程

**Comment:** Conference paper to appear in ITW 2025. arXiv admin note: substantial
  text overlap with arXiv:2502.14544; text overlap with arXiv:2402.00501

> **TL;DR:** 本文介绍了带有f-散度正则化的经验风险最小化（ERM-fDR）的对偶公式，通过非线性常微分方程将其解与归一化函数联系起来，从而提供了一种高效的计算方法。

**AI_Comments:** 本文的创新之处在于利用勒让德-芬切尔变换和隐函数定理等高级数学工具，将带有f-散度正则化的经验风险最小化（ERM-fDR）与通过非线性常微分方程表示的归一化函数联系起来，从而提供了一种计算高效的方法。这为理解和解决此类优化问题提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 探索带有f-散度正则化的经验风险最小化（ERM-fDR）的对偶公式，并提供一种计算其归一化函数的有效方法。

**Method:** 引入带有f-散度正则化的经验风险最小化（ERM-fDR）的对偶公式。该对偶方法利用勒让德-芬切尔变换和隐函数定理，为归一化函数提供了一个非线性常微分方程表达式。

**Result:** 非线性常微分方程表达式及其性质提供了一种在温和条件下计算ERM-fDR解的归一化函数的计算高效方法。

**Conclusion:** 通过对偶优化视角，本文为带有f-散度正则化的经验风险最小化（ERM-fDR）的归一化函数提供了一种计算高效的方法。

> **ai_Abstract:** 本文提出了带有f-散度正则化的经验风险最小化（ERM-fDR）的对偶优化框架。通过勒让德-芬切尔变换和隐函数定理，该框架将对偶解与一个归一化函数通过非线性常微分方程联系起来，从而提供了一种计算该归一化函数的有效方法。

> **摘要翻译:** 本文介绍了带有f-散度正则化的经验风险最小化（ERM-fDR）的对偶公式。ERM-fDR对偶优化问题的解与作为隐函数引入的归一化函数概念相关联。这种对偶方法利用勒让德-芬切尔变换和隐函数定理，为归一化函数提供了一个非线性常微分方程表达式。此外，该非线性常微分方程表达式及其性质在温和条件下提供了一种计算ERM-fDR解的归一化函数的计算高效方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [40] [Learning quadratic neural networks in high dimensions: SGD dynamics and scaling laws](https://arxiv.org/abs/2508.03688)
> *高维二次神经网络学习：SGD动态与尺度律*

*Gérard Ben Arous, Murat A. Erdogdu, N. Mert Vural, Denny Wu* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 二次神经网络, SGD动态, 尺度律, 高维, 优化

**Comment:** 84 pages

> **TL;DR:** 本文研究了高维二次激活两层神经网络的基于梯度训练的优化和样本复杂度，并推导了预测风险的尺度律。

**AI_Comments:** 该研究通过结合矩阵Riccati微分方程和矩阵单调性论证，在高维背景下对二次神经网络的SGD动态进行了深入且精确的理论分析，特别是推导了预测风险的尺度律，为理解高维神经网络的优化行为提供了重要的理论依据和创新方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究高维环境下，使用二次激活函数的两层神经网络的梯度训练的优化和样本复杂度。

**Method:** 研究了特征学习机制下的SGD动态，包括种群极限和有限样本（在线）离散化。分析结合了精确的矩阵Riccati微分方程表征和新颖的矩阵单调性论证，以建立无限维有效动态的收敛保证。

**Result:** 推导了预测风险的尺度律，强调了优化时间、样本大小和模型宽度上的幂律依赖关系。建立了无限维有效动态的收敛保证。

**Conclusion:** 通过对SGD动态的深入分析，并结合矩阵Riccati微分方程和矩阵单调性论证，成功推导了高维二次神经网络预测风险的尺度律，并建立了其收敛性。

> **ai_Abstract:** 本文在高维环境下，研究了使用二次激活函数的两层神经网络的梯度训练的优化和样本复杂度。通过对SGD动态的精确分析，包括种群极限和有限样本离散化，并结合矩阵Riccati微分方程和矩阵单调性论证，推导了预测风险的尺度律，揭示了其对优化时间、样本大小和模型宽度的幂律依赖关系，并建立了无限维有效动态的收敛保证。

> **摘要翻译:** 我们研究了高维环境下，使用二次激活函数的两层神经网络的基于梯度训练的优化和样本复杂度。其中数据生成方式为 $y \propto \sum_{j=1}^{r}\lambda_j \sigma\left(\langle \boldsymbol{\theta_j}, \boldsymbol{x}\rangle\right), \boldsymbol{x} \sim N(0,\boldsymbol{I}_d)$，$\sigma$ 是二次Hermite多项式，$\lbrace\boldsymbol{\theta}_j \rbrace_{j=1}^{r} \subset \mathbb{R}^d$ 是正交信号方向。我们考虑了扩展宽度机制 $r \asymp d^\beta$，其中 $\beta \in [0, 1)$，并假设（非负）第二层系数 $\lambda_j\asymp j^{-\alpha}$ 呈幂律衰减，其中 $\alpha \geq 0$。我们对特征学习机制下的SGD动态进行了精确分析，包括种群极限和有限样本（在线）离散化，并推导了预测风险的尺度律，强调了优化时间、样本大小和模型宽度上的幂律依赖关系。我们的分析结合了相关矩阵Riccati微分方程的精确表征和新颖的矩阵单调性论证，以建立无限维有效动态的收敛保证。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [232] [Discovering group dynamics in coordinated time series via hierarchical recurrent switching-state models](https://arxiv.org/abs/2401.14973)
> *通过分层循环切换状态模型发现协调时间序列中的群体动态*

*Michael T. Wojnowicz, Kaitlin Gili, Preetish Rath, Eric Miller, Jeffrey Miller, Clifford Hancock, Meghan O'Donovan, Seth Elkin-Frankston, Tad T. Brunyé, Michael C. Hughes* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 群体动态, 协调时间序列, 分层模型, 切换状态模型, 循环模型

**Comment:** 

> **TL;DR:** 提出一种分层循环切换状态模型，以高效地学习交互实体协调时间序列中的系统级和个体级动态，并通过结合自上而下和自下而上的影响来提高可解释性和预测准确性。

**AI_Comments:** 该论文的创新之处在于提出了一种能够同时捕捉系统级和个体级动态的分层模型，并通过结合自上而下和自下而上的影响，显著提高了模型的可解释性。其计算效率高，能够线性扩展，解决了现有模型在处理集体行为方面的不足。模型的参数精简性使其在资源有限的情况下仍能表现出色，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的个体时间模式模型未能整合能影响个体轨迹的显式系统级集体行为。

**Method:** 提出一种新的分层切换状态模型，该模型可以以无监督方式进行训练，以同时学习系统级和个体级动态。采用一个潜在的系统级离散状态马尔可夫链，对潜在的实体级链施加自上而下的影响，而实体级链又控制每个观测时间序列的发射。通过从观测值到实体和系统两级的潜在链的循环反馈，将最近的情境信息以自下而上的方式融入动态演变。该模型通过封闭形式的变分坐标上升更新进行学习，其计算成本与实体数量呈线性关系。

**Result:** 在合成数据和真实篮球团队运动数据上的分析表明，该参数模型与需要更多计算资源的神经网络模型相比，能实现有竞争力的预测。对士兵数据和包含64个协作实体的合成任务的进一步实验表明，该方法可以提供关于团队动态随时间演变的易于解释的见解。

**Conclusion:** 该分层循环切换状态模型能够有效、可解释地发现协调时间序列中的群体动态，并通过结合自上而下和自下而上的影响，在预测准确性和可解释性方面表现出色，同时保持计算效率。

> **ai_Abstract:** 该论文提出了一种新的分层循环切换状态模型，旨在高效地分析来自多个交互实体的时间序列集合中的群体动态。该模型通过结合潜在的系统级和个体级马尔可夫链，并整合自上而下和自下而上的影响，以无监督方式同时学习系统和个体层面的动态。实验结果表明，该模型在预测准确性方面与大型神经网络模型具有竞争力，并且能提供更强的可解释性，同时保持计算效率，尤其适用于发现协调时间序列中的复杂群体行为。

> **摘要翻译:** 我们寻求一个计算高效的模型，用于处理来自多个交互实体（又称“代理”）的时间序列集合。最近关于个体时间模式的模型未能整合可以影响个体实体轨迹的显式系统级集体行为。为了弥补文献中的这一空白，我们提出了一种新的分层切换状态模型，该模型可以以无监督方式进行训练，以同时学习系统级和个体级动态。我们采用一个潜在的系统级离散状态马尔可夫链，它对潜在的实体级链提供自上而下的影响，而实体级链又控制每个观测时间序列的发射。从观测值到实体和系统两级的潜在链的循环反馈允许最近的情境信息以自下而上的方式影响所有层级的动态展开。我们假设，在群体动态中包含自上而下和自下而上的影响将提高学习动态的可解释性并减少预测误差。我们的分层切换循环动力学模型可以通过对所有潜在链进行封闭形式的变分坐标上升更新来学习，其计算量与实体数量呈线性关系。这在渐近上不比为每个实体拟合单独模型更昂贵。对合成数据和真实篮球团队运动的分析表明，我们精简的参数模型与需要更多计算资源的更大神经网络模型相比，可以实现有竞争力的预测。对士兵数据以及包含64个协作实体的合成任务的进一步实验表明，我们的方法可以产生关于团队动态随时间演变的易于解释的见解。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [240] [Beyond Log-Concavity and Score Regularity: Improved Convergence Bounds for Score-Based Generative Models in W2-distance](https://arxiv.org/abs/2501.02298)
> *超越对数凹性和分数正则性：W2距离下基于分数的生成模型的改进收敛界限*

*Marta Gentiloni-Silveri, Antonio Ocello* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-05**

**Keywords:** Score-Based Generative Models, W2-distance, Log-Concavity, Ornstein--Uhlenbeck process, Convergence Bounds

**Comment:** 

> **TL;DR:** 本文提出了一个分析基于分数的生成模型（SGMs）在W2距离收敛性的新框架，显著放宽了对数据分布的传统严格假设（如对数凹性和分数正则性）。

**AI_Comments:** 这项工作通过引入Ornstein--Uhlenbeck过程的正则化特性和PDE分析，创新性地放宽了基于分数的生成模型在W2距离收敛性分析中的严格假设，特别是对数凹性和分数正则性。这对于扩展SGMs的理论基础和实际应用范围具有重要意义，使其能够处理更广泛的真实世界数据分布，而无需过于严苛的条件。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于分数的生成模型（SGMs）在W2距离上的收敛界限依赖于对数据分布的严格假设，如对数凹性和分数正则性，这限制了其理论分析和实际应用。

**Method:** 本文提出了一个分析SGMs在W2距离收敛性的新框架。该框架利用Ornstein--Uhlenbeck (OU) 过程的正则化特性，并通过控制对数密度演化的Hamilton--Jacobi--Bellman方程的PDE分析，量化了弱对数凹性随时间演变为对数凹性的过程。此外，研究了时间反向OU过程的漂移在收缩和非收缩状态之间的交替。

**Result:** 研究表明，弱对数凹性数据分布会随时间演变为对数凹性；时间反向OU过程的漂移在收缩和非收缩状态之间交替；该方法规避了对分数函数及其估计器的严格正则性条件，转而依赖更温和、更实际的假设；通过在高斯混合模型上的计算，证明了该框架的广泛适用性。

**Conclusion:** 本文提出的新框架显著放宽了基于分数的生成模型在W2距离收敛性分析中的传统严格假设，提供了更广泛适用的收敛性界限，并为理解其动态提供了新的理论视角。

> **ai_Abstract:** 本文提出了一个分析基于分数的生成模型（SGMs）在W2距离上收敛性的新框架，旨在解决现有方法对数据分布严格假设（如对数凹性和分数正则性）的依赖问题。通过利用Ornstein--Uhlenbeck过程的正则化特性和PDE分析，研究发现弱对数凹性会随时间演变为对数凹性，并且时间反向OU过程的漂移呈现交替动态。该框架显著放宽了对分数函数正则性的要求，并被证明适用于高斯混合模型等多种数据分布。

> **摘要翻译:** 基于分数的生成模型（SGMs）旨在通过学习使用高斯噪声扰动样本的分数函数来从目标分布中进行采样。SGMs在$\mathcal{W}_2$-距离上的现有收敛界限依赖于对数据分布的严格假设。在这项工作中，我们提出了一个分析SGMs在$\mathcal{W}_2$-收敛性的新颖框架，显著放宽了传统假设，如对数凹性和分数正则性。利用Ornstein--Uhlenbeck（OU）过程的正则化特性，我们表明数据分布的弱对数凹性会随时间演变为对数凹性。这种转变通过控制前向过程对数密度的Hamilton--Jacobi--Bellman方程的基于PDE的分析得到了严格量化。此外，我们建立了时间反向OU过程的漂移在收缩和非收缩状态之间交替，反映了凹度的动态。我们的方法规避了对分数函数及其估计器的严格正则性条件的需求，而是依赖于更温和、更实际的假设。我们通过对高斯混合模型的明确计算展示了该框架的广泛适用性，说明了其多功能性和对更广泛数据分布类的潜力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [294] [Likelihood Matching for Diffusion Models](https://arxiv.org/abs/2508.03636)
> *扩散模型的似然匹配*

*Lei Qian, Wu Su, Yanqi Huang, Song Xi Chen* | **Category: stat.ML, cs.LG, math.ST, stat.AP, stat.ME, stat.TH** | **Updated: 2025-08-05**

**Keywords:** 扩散模型, 似然匹配, 准似然, 得分函数, Hessian函数

**Comment:** 

> **TL;DR:** 提出一种用于训练扩散模型的似然匹配方法，通过准似然估计得分和Hessian函数，并引入随机采样器，提供收敛性保证。

**AI_Comments:** 这篇论文的创新点在于提出了似然匹配框架来训练扩散模型，并通过引入准似然和随机采样器克服了计算挑战，同时提供了强有力的理论收敛性保证，这对于理解和改进扩散模型训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 训练扩散模型。

**Method:** 提出似然匹配方法，通过建立目标数据分布似然与逆向扩散样本路径似然的等价性。使用准似然近似每个逆向转换密度，用匹配条件均值和协方差的高斯分布来估计得分和Hessian函数。引入随机采样器，利用估计的得分和Hessian信息。

**Result:** 建立了准最大似然估计的一致性，并为提出的采样器提供了非渐近收敛保证，量化了由于得分和Hessian估计、维度和扩散步数引起的近似误差率。经验和仿真评估证明了所提似然匹配的有效性并验证了理论结果。

**Conclusion:** 提出的似然匹配方法和随机采样器在理论上具有一致性和收敛性保证，并在实践中表现出有效性。

> **ai_Abstract:** 本文提出了一种新颖的似然匹配方法来训练扩散模型。该方法通过将目标数据似然与逆向扩散路径似然等同起来，并利用高斯近似的准似然来高效估计得分和Hessian函数。引入的随机采样器利用这些估计，并提供了严格的理论收敛性保证，其有效性通过实验得到验证。

> **摘要翻译:** 我们提出了一种用于训练扩散模型的似然匹配方法，首先建立了目标数据分布的似然与逆向扩散样本路径似然之间的等价性。为了有效计算逆向样本似然，我们考虑使用准似然，通过匹配条件均值和协方差的高斯分布来近似每个逆向转换密度。通过最大化准似然来估计扩散生成的得分函数和Hessian函数，确保每两个时间点之间前两个转换矩的一致匹配。引入了一个随机采样器，以促进利用估计的得分和Hessian信息进行计算。我们建立了准最大似然估计的一致性，并为所提出的采样器提供了非渐近收敛保证，量化了由于得分和Hessian估计、维度和扩散步数引起的近似误差率。经验和仿真评估证明了所提出的似然匹配的有效性并验证了理论结果。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [705] [TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models](https://arxiv.org/abs/2507.10643)
> *泰勒PODA：一种基于泰勒展开的方法，用于改进不透明模型的事后归因*

*Yuchi Tang, Iñaki Esnaola, George Panoutsos* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 事后归因, 泰勒展开, 模型无关, 特征重要性, 可解释性AI

**Comment:** 18 pages, 4 figures. Submitted to AAAI 2026. Re-upload with amended
  manuscript

> **TL;DR:** TaylorPODA是一种基于泰勒展开的新方法，通过引入“精确性”、“联合性”和“零差异”等公理，并增加一个“适应性”属性，来改进事后归因，使其更具原则性、易于可视化，并能更好地与特定任务目标对齐，从而增强了不透明模型的可靠部署。

**AI_Comments:** 该研究在事后归因领域提出了一个具有理论基础的新框架，通过引入公理和适应性属性来解决现有方法的局限性，并在实证评估中展现出良好的性能和可视化潜力，对于增强模型的可信度和可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的事后模型无关方法在量化单个特征的贡献方面缺乏明确和系统的框架。

**Method:** 提出了一套严格的公理（精确性、联合性、零差异）来规范泰勒项的归因，并引入了TaylorPODA，增加了一个“适应性”属性，以实现与特定任务目标的对齐。

**Result:** TaylorPODA在经验评估中取得了与基线方法相当的结果，提供了有原则且易于可视化的解释。

**Conclusion:** 这项工作通过提供具有更强理论基础的解释，增强了不透明模型的值得信赖的部署。

> **ai_Abstract:** 该研究提出了一种名为TaylorPODA的新型事后归因方法，该方法基于泰勒展开，并引入了精确性、联合性、零差异和适应性等公理，以改进对不透明模型的特征贡献量化。实验证明，TaylorPODA能够生成有原则且易于可视化的解释，并能与特定任务目标对齐，从而提升了不透明模型的可靠性。

> **摘要翻译:** 现有的事后模型无关方法通过局部地将模型输出归因于其输入特征来为不透明模型生成外部解释。然而，它们通常缺乏一个明确且系统的框架来量化单个特征的贡献。基于Deng等人（2024）引入的泰勒展开框架来统一现有的局部归因方法，我们提出了一套严格的公理——“精确性”、“联合性”和“零差异”——来规范泰勒项的归因。在这些公理的指导下，我们引入了TaylorPODA（源自泰勒展开的重要性顺序适应归因），它包含了一个额外的“适应性”属性。该属性能够实现与特定任务目标的对齐，尤其是在缺乏真实解释的事后设置中。实证评估表明，TaylorPODA在与基线方法相比时取得了有竞争力的结果，提供了有原则且易于可视化的解释。这项工作通过提供具有更强理论基础的解释，增强了不透明模型的值得信赖的部署。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [919] [Supervised Dynamic Dimension Reduction with Deep Neural Network](https://arxiv.org/abs/2508.03546)
> *监督深度动态降维*

*Zhanye Luo, Yuefeng Han, Xiufan Yu* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 监督降维, 深度学习, 时间序列预测, 主成分分析, 因子模型

**Comment:** 

> **TL;DR:** 提出了一种名为SDDP的新框架，结合目标变量和滞后观测值进行因子提取，以提高时间序列预测的准确性。

**AI_Comments:** 该研究提出了一种新颖的监督降维方法（SDDP），并将其成功应用于时间序列预测任务。其创新之处在于将目标变量信息融入因子提取过程，提高了预测精度和因子可解释性。该方法在处理高维数据和部分可观测数据方面也显示出潜力。未来的工作可以进一步探索该方法在其他领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列预测在高维预测变量的情况下，需要更有效的降维方法来提高预测精度。

**Method:** 提出了一种监督深度动态主成分分析（SDDP）框架，该框架将目标变量和滞后观测值纳入因子提取过程。通过时间神经网络构建目标感知预测变量，并通过主成分分析提取SDDP因子。在此基础上，提出了一个因子增强的非线性动态预测模型。

**Result:** 在几个真实世界的公共数据集上进行了验证，与最先进的方法相比，该算法在预测准确性方面取得了显著的改进。

**Conclusion:** SDDP框架能够提高预测准确性，并产生更具可解释性和目标特异性的潜在因子，在时间序列预测任务中表现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为监督深度动态主成分分析（SDDP）的新框架，用于处理高维预测变量的时间序列预测问题。SDDP通过整合目标变量和滞后观测值，并利用时间神经网络进行目标感知预测变量的构建，从而在因子提取过程中引入监督信息。这种方法不仅提高了预测准确性，还使得提取的潜在因子更具可解释性和目标特异性。此外，基于SDDP，研究还提出了一个因子增强的非线性动态预测模型，并将其应用于预测变量部分可观测的场景。实验结果表明，SDDP在真实世界数据集上的表现优于现有最先进的方法。

> **摘要翻译:** 本文研究了旨在改善高维预测变量时间序列预测的降维问题。我们提出了一种新颖的监督深度动态主成分分析（SDDP）框架，该框架将目标变量和滞后观测值纳入因子提取过程。借助时间神经网络，我们通过监督方式缩放原始预测变量来构建目标感知预测变量，将更大的权重分配给具有更强预测能力的预测变量。然后对目标感知预测变量执行主成分分析以提取估计的SDDP因子。这种监督因子提取不仅提高了下游预测任务的预测准确性，而且产生了更具可解释性和目标特异性的潜在因子。在SDDP的基础上，我们提出了一种因子增强的非线性动态预测模型，它统一了广泛的基于因子模型的预测方法。为了进一步证明SDDP的广泛适用性，我们将研究扩展到一个更具挑战性的场景，即预测变量仅部分可观测。我们在几个真实世界的公共数据集上验证了所提出方法的实证性能。结果表明，与最先进的方法相比，我们的算法在预测准确性方面取得了显著的改进。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [972] [Hedging with memory: shallow and deep learning with signatures](https://arxiv.org/abs/2508.02759)
> *带记忆的对冲：签名法的浅层和深度学习*

*Eduardo Abi Jaber, Louis-Amand Gérard* | **Category: stat.ML, cs.LG, 60L10, 91G20, 91G60** | **Updated: 2025-08-03**

**Keywords:** 路径签名, 机器学习, 金融对冲, 随机波动率, 深度学习

**Comment:** 

> **TL;DR:** 该研究将路径签名应用于金融衍生品对冲，在深度学习和浅层学习场景下均表现优异，尤其是在非马尔可夫随机波动率模型下，其性能超越了长短期记忆网络（LSTM），且训练计算量大大减少。

**AI_Comments:** 该研究将路径签名这一强大的序列特征提取工具成功应用于金融对冲领域，特别是在处理复杂的非马尔可夫随机波动率模型时，展现出优越的性能和计算效率。研究结果为量化交易和风险管理提供了新的思路和方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究如何利用路径签名结合机器学习方法来对冲奇异衍生品，特别是在非马尔可夫随机波动率模型下。

**Method:** 在深度学习方面，将签名作为前馈神经网络的特征；在浅层学习方面，比较了两种回归方法：一种直接从价格过程的预期签名中学习对冲策略，另一种则使用签名波动率模型来模拟波动率动态。

**Result:** 深度学习方法在大多数情况下优于LSTM，并且训练计算量更小。浅层学习中的签名波动率模型在不同收益和波动率动态下提供了更准确和稳定的对冲结果。

**Conclusion:** 路径签名是一种有效的特征表示，可以提升机器学习模型在对冲奇异衍生品任务上的表现，尤其是在处理非马尔可夫随机波动率模型时，相比传统方法具有计算效率和准确性优势。

> **ai_Abstract:** 本研究探讨了在非马尔可夫随机波动率模型下，如何利用路径签名结合深度学习和浅层学习方法来对冲奇异衍生品。研究发现，在深度学习中，签名特征优于LSTM，且计算效率更高；在浅层学习中，基于签名波动率模型的对冲策略更为准确和稳定。

> **摘要翻译:** 我们研究了在非马尔可夫随机波动率模型下，使用路径签名在机器学习背景下对冲奇异衍生品。在深度学习场景下，我们将签名作为前馈神经网络的特征，并表明在大多数情况下，其性能优于LSTM，并且训练计算量大大减少。在浅层学习场景下，我们比较了两种回归方法：第一种直接从价格过程的预期签名中学习对冲策略；第二种使用签名波动率模型来模拟波动率动态，该模型基于波动率的预期签名进行校准。在校准后的签名波动率模型中求解对冲问题，在不同的收益和波动率动态下都能产生更准确和稳定的结果。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [24] [Quantum Neural Network applications to Protein Binding Affinity Predictions](https://arxiv.org/abs/2508.03446)
> *量子神经网络在蛋白质结合亲和力预测中的应用*

*Erico Souza Teixeira, Lucas Barros Fernandes, Yara Rodrigues Inácio* | **Category: quant-ph, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 量子神经网络, 蛋白质结合亲和力, 结合能预测, 机器学习, 量子计算

**Comment:** 16 pages, 7 figures

> **TL;DR:** 本研究探索了量子神经网络（QNNs）在预测蛋白质结合能方面的可行性，提出了30种基于多层感知器的QNN变体，并与经典模型进行比较。结果显示QNNs在某些数据集上准确率更高，且训练时间显著缩短。

**AI_Comments:** 该论文的创新之处在于系统地探索了多种基于多层感知器的量子神经网络变体在蛋白质结合能预测中的应用。其重要性在于证明了量子模型在特定情况下可以超越经典模型，尤其是在训练效率方面，这对于处理大规模生物医学数据具有重要意义。虽然在所有数据集上准确性表现不一，但其在训练时间上的巨大优势表明了量子计算在特定计算密集型任务中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 结合能是分子相互作用的关键热力学性质，在药物开发和疫苗设计等领域至关重要。尽管经典计算在预测模型方面表现出色，但量子计算在机器学习中的变体（特别是量子神经网络）作为一种有前景的替代方案出现，促使研究探索其在结合能预测中的潜在优势。

**Method:** 本研究提出了30种基于多层感知器的量子神经网络（QNNs）变体，涵盖三种不同的架构，每种架构包含十种不同的量子电路来配置其量子层。研究将这些量子模型的性能与最先进的经典多层感知器人工神经网络进行了比较，评估了准确性和训练时间。使用一个主要数据集进行训练，并使用两个包含完全未见样本的额外数据集进行测试。

**Result:** 结果表明，量子模型在一个未见数据集上的准确率提高了约20%，尽管在其他数据集上的准确率较低。值得注意的是，量子模型的训练时间比经典模型缩短了几个数量级。

**Conclusion:** 量子神经网络在蛋白质结合能预测方面显示出巨大的潜力，尤其是在训练效率上，尽管其在所有数据集上的准确性表现不一，但证明了其作为经典方法有前景的替代方案的可行性。

> **ai_Abstract:** 本研究探讨了量子神经网络（QNNs）在蛋白质结合能预测中的应用潜力。通过提出并测试30种不同架构和量子电路配置的QNN变体，并将其性能与经典多层感知器模型进行比较。结果显示，QNNs在特定未见数据集上实现了更高的预测准确性，并且训练时间显著缩短，突显了其在生物医学领域高效预测结合能的潜力。

> **摘要翻译:** 结合能是分子相互作用的基本热力学性质，在医疗保健和自然科学等领域发挥着关键作用。它在药物开发、疫苗设计和其他生物医学应用中尤其重要。多年来，人们开发了各种方法来估计蛋白质结合能，从实验技术到计算方法，其中机器学习对该领域做出了重大贡献。尽管经典计算在构建预测模型方面表现出强大的结果，但用于机器学习的量子计算变体已成为一种有前景的替代方案。量子神经网络（QNNs）作为研究热点受到关注，引发了它们在预测结合能方面的潜在优势问题。为了探究这一潜力，本研究通过提出三十种基于多层感知器的量子神经网络变体来探索QNNs完成这项任务的可行性。这些变体涵盖了三种不同的架构，每种架构都包含十种不同的量子电路来配置其量子层。将这些量子模型的性能与最先进的经典多层感知器人工神经网络进行了比较，评估了准确性和训练时间。使用一个主要数据集进行训练，同时使用两个包含完全未见样本的额外数据集进行测试。结果表明，量子模型在一个未见数据集上的准确率提高了约20%，尽管在其他数据集上的准确率较低。值得注意的是，量子模型的训练时间比经典模型缩短了几个数量级，突显了它们在高效蛋白质结合能预测方面的潜力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [245] [Automatic Configuration Protocols for Optical Quantum Networks](https://arxiv.org/abs/2504.19613)
> *自动配置光量子网络协议*

*Amin Taherkhani, Andrew Todd, Kentaro Teramoto, Rodney Van Meter, Shota Nagayama* | **Category: quant-ph, cs.NI, C.2.2** | **Updated: 2025-08-05**

**Keywords:** 量子网络, 自动配置, 协议, 光学开关, 时间-数字转换器

**Comment:** 11 pages, 7 figures

> **TL;DR:** 本文提出协议和算法，旨在自动化光量子网络中的连接识别和节点与光开关的连接识别，以促进量子网络的规模化部署。

**AI_Comments:** 本文解决了量子网络部署中的一个核心实际问题——自动化配置，这对于量子网络从实验阶段走向实用化和规模化至关重要。其提出的协议和算法具有很强的工程实践意义，为后续更复杂的量子网络协议（如路由、拓扑发现）的开发奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前量子网络测试平台主要依赖手动配置，包括节点构建和连接信息跟踪，这容易导致实验失败和长时间调试，阻碍了量子网络的实际规模化应用。

**Method:** 论文提出了协议和算法来自动化两个手动过程：一是自动识别量子网络节点与时间-数字转换器之间的连接；二是识别连接到量子网络光开关的节点。

**Result:** 这些协议的实施将有助于实现量子网络所需的其他协议，如网络拓扑发现、链路质量监测、资源命名和路由。

**Conclusion:** 本文旨在为近期实现量子网络的自动化配置提供路线图，并促进未来量子网络其他关键协议的开发。

> **ai_Abstract:** 本文针对量子网络当前手动配置的痛点，提出了自动化协议和算法。具体解决了量子网络节点与时间-数字转换器以及节点与光开关之间的连接自动识别问题。这些协议的实施对于量子网络的规模化发展至关重要，并将为拓扑发现、链路质量监测等未来协议的开发奠定基础，为近期实践提供了路线图。

> **摘要翻译:** 在量子网络扩展到实用规模之前，许多部署和配置任务必须自动化。目前，量子网络测试平台大多是手动配置的：网络节点由自由空间和光纤光学器件组合构建，然后连接到共享的单光子探测器、时间-数字转换器和光开关。这些连接的信息必须手动跟踪；错误标记可能导致实验失败和漫长的调试会话。在本文中，我们提出了协议和算法来自动化其中两个手动过程。首先，我们解决了自动识别量子网络节点和时间-数字转换器之间连接的问题。然后，我们转向更复杂的挑战，即识别连接到量子网络光开关的节点。这些协议的实施将有助于实现量子网络所需的其他协议，例如网络拓扑发现、链路质量监测、资源命名和路由。我们希望本文能作为近期实施的路线图。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [264] [QCPINN: Quantum-Classical Physics-Informed Neural Networks for Solving PDEs](https://arxiv.org/abs/2503.16678)
> *QCPINN: 量子-经典物理信息神经网络求解偏微分方程*

*Afrah Farea, Saiful Khan, Mustafa Serdar Celebi* | **Category: quant-ph, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 量子计算, 物理信息神经网络, 偏微分方程, 参数效率, 机器学习

**Comment:** 

> **TL;DR:** QCPINN结合量子和经典组件，以更少的参数解决PDEs，同时保持与经典PINNs相当的精度和收敛性，展现了参数效率的量子优势。

**AI_Comments:** 这篇论文的创新点在于将量子计算的思想引入到物理信息神经网络中，通过结合量子和经典组件，有效解决了传统PINNs参数量大的问题。其重要性在于展示了量子计算在特定机器学习任务中实现“量子优势”的潜力，即在资源（参数）效率上的显著提升，这对于处理大规模和复杂物理问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 经典的物理信息神经网络（PINNs）在解决复杂偏微分方程（PDEs）时需要大量参数才能达到合理精度。

**Method:** 提出了量子-经典物理信息神经网络（QCPINN），它结合了量子和经典组件。通过在五种基准PDE上系统评估了两种量子电路架构的不同配置，以确定最佳QCPINN设计。

**Result:** QCPINN实现了稳定的收敛和可比的精度，所需的训练参数约为经典方法的10%。对于对流-扩散方程，相对误差L2降低了40%。

**Conclusion:** 这些发现表明参数效率在物理信息机器学习中具有可衡量的量子优势潜力，显著降低了模型复杂性同时保持了求解质量。该方法为解决PDEs相关的计算挑战提供了一个有前景的解决方案。

> **ai_Abstract:** 本文提出了一种量子-经典物理信息神经网络（QCPINN），旨在克服传统PINNs在解决复杂偏微分方程时所需参数量大的问题。QCPINN通过结合量子和经典组件，能够在显著减少参数的同时，保持与经典PINNs相当的精度和收敛性。实验结果表明，QCPINN仅需经典方法约10%的参数即可达到相似性能，并在特定方程上显著降低了误差，证明了参数效率作为一种量子优势的潜力，为PDE求解提供了高效的计算方案。

> **摘要翻译:** 物理信息神经网络（PINNs）通过在神经网络架构中嵌入物理定律，已成为求解偏微分方程（PDEs）的一种有前景的方法。然而，这些经典方法通常需要大量参数才能达到合理精度，特别是对于复杂的PDEs。在本文中，我们提出了一种量子-经典物理信息神经网络（QCPINN），它结合了量子和经典组件，使我们能够以显著更少的参数求解PDEs，同时保持与经典PINNs相当的精度和收敛性。我们系统地评估了两种量子电路架构在五种基准PDE上的各种配置，以确定最佳QCPINN设计。我们的结果表明，QCPINN实现了稳定的收敛和可比的精度，同时所需的训练参数约为经典方法的10%。它还使对流-扩散方程的相对误差L2降低了40%。这些发现表明参数效率在物理信息机器学习中具有可衡量的量子优势潜力，显著降低了模型复杂性同时保持了求解质量。这种方法为解决与求解PDEs相关的计算挑战提供了一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [686] [Thermodynamic Signature of Logical Depth in Quantum Circuits](https://arxiv.org/abs/2508.03203)
> *量子电路的逻辑深度的热力学特征*

*Issam Ibnouhsein* | **Category: quant-ph, cs.CC** | **Updated: 2025-08-05**

**Keywords:** 量子电路,逻辑深度,热力学特征,熵流,退相相干

**Comment:** 

> **TL;DR:** 通过研究量子电路的内部逻辑结构在逐渐退相干过程中的表现，我们发现具有条件分支的深层电路比浅层、均匀的电路会产生更多的熵流向环境，这可以用一个量化环境相互作用过程中熵积累的逻辑深度因子$L_d$来表示。通过对两种4分支量子电路的分析，我们证明了条件逻辑深度因子$L_d "
"约等于1.615，这表明条件架构比均匀架构产生更多的熵。我们还提出了一个基于辅助比特的实验方案，利用受控-相位门在当前的量子平台上检测这些热力学特征，这对于电路设计、编译策略和验证协议具有重要意义。

**AI_Comments:** 这项研究巧妙地将信息论中的逻辑深度概念与物理学中的热力学联系起来，提出了一种在量子退相干过程中检测电路结构的新方法。通过量化熵流，该研究不仅为理解量子计算的物理基础提供了新的见解，而且其提出的实验方案具有实际应用价值，可能促进量子计算机的设计、优化和验证。

<details>
  <summary>Details</summary>

**Motivation:** 研究量子电路的内部逻辑结构如何影响其在退相干过程中的热力学表现，特别是逻辑深度对熵流的影响。

**Method:** 通过比较深层、条件分支电路与浅层、均匀电路在退相干过程中的熵流，并引入逻辑深度因子$L_d$进行量化。通过对两种4分支量子电路进行详细分析进行验证，并提出了一个基于辅助比特的实验方案。

**Result:** 深层、条件分支电路比浅层、均匀电路产生更大的熵流。逻辑深度因子$L_d$量化了这种熵积累，在比较的电路中$L_d "
"约等于1.615。

**Conclusion:** 逻辑深度是量子电路中一个可测量的物理量，它通过熵流的形式在环境交互中留下热力学印记，并对电路设计、编译和验证策略有重要影响。

> **ai_Abstract:** 本研究表明，量子电路的逻辑深度（即其内部的条件分支结构）可以通过熵流的形式在退相干过程中留下可测量的热力学印记。研究人员通过对比不同逻辑深度的电路，发现具有条件分支的深层电路会产生更多的环境熵。他们提出了一个名为$L_d$的逻辑深度因子来量化这种现象，并通过实验方案验证了其有效性，为量子电路的设计和验证提供了新的视角。

> **摘要翻译:** 我们证明了量子电路的内部逻辑结构可以在逐渐退相干的过程中留下独特的热力学特征。通过比较深层、条件分支电路与浅层、均匀电路——同时控制整体停止概率和物理资源——我们发现分支结构会诱导更大的熵流向环境。这种效应通过逻辑深度因子$L_d$来捕捉，该因子量化了在环境相互作用过程中熵的积累。我们通过对两种4分支量子电路的详细分析来验证我们的框架，证明了条件架构比均匀架构具有更高的熵产生，其中$L_d "
"约等于1.615。一个基于辅助比特的实验方案，使用受控-相位门，为在当前量子平台检测这些热力学特征提供了具体的途径。我们的结果将逻辑深度确立为一个物理上可测量的量，并对电路设计、编译策略和验证协议产生了影响。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [755] [Efficient Variational Quantum Algorithms via Circuit Knitting and Architecture Search](https://arxiv.org/abs/2508.03376)
> *高效变分量子算法通过电路裁剪和架构搜索*

*Jun Wu, Jiaqi Yang, Jicun Li, Wei Xie, Xiang-Yang Li* | **Category: quant-ph, cs.ET** | **Updated: 2025-08-05**

**Keywords:** 电路裁剪, 变分量子算法, 量子电路架构搜索, 采样开销, CKVQA

**Comment:** 13 pages, 10 figures

> **TL;DR:** 该研究提出了一种名为CKVQA的框架，该框架结合了电路裁剪和量子电路架构搜索技术，用于优化变分量子算法（VQAs）。CKVQA旨在通过寻找参数化量子电路来最小化采样开销，同时保持算法性能。此外，它还包括一个子电路级别的优化方法，以加速VQAs的训练和减少执行时间。实验结果表明，CKVQA能显著降低采样开销，同时保持与传统方法相当的准确性。

**AI_Comments:** 该研究提出了一种创新的框架CKVQA，通过结合电路裁剪和架构搜索来解决当前量子硬件限制下变分量子算法的效率问题。通过最小化采样开销和优化训练过程，该方法在保持准确性的同时显著提高了算法的可行性。这项工作对于推动量子算法在实际硬件上的应用具有重要意义，但未来的研究可以进一步探索更复杂的电路结构和更大规模问题的应用。

<details>
  <summary>Details</summary>

**Motivation:** 当前的量子硬件在可用量子比特数量上存在显著限制，这阻碍了实际量子算法的应用。电路裁剪技术通过将大型量子电路分解为可在当前设备上执行的小部分来解决此问题，但会导致采样开销随着切割点数量呈指数级增长。

**Method:** 提出CKVQA框架，该框架将电路裁剪应用于变分量子算法（VQAs），并结合了针对此场景优化的量子电路架构搜索，以最小化采样开销。同时，开发了一种子电路级别的优化方法来加速VQAs的训练和减少执行时间。

**Result:** CKVQA框架显著降低了采样开销，同时保持了与传统参数化量子电路设计相当的准确性。

**Conclusion:** CKVQA框架通过结合电路裁剪和架构搜索，有效地解决了当前量子硬件限制下VQAs的采样开销问题，并在实际应用中展现出优越的性能。

> **ai_Abstract:** 该研究提出了CKVQA框架，结合了电路裁剪和量子电路架构搜索技术，以优化变分量子算法（VQAs）。该框架旨在通过识别能够平衡算法性能和采样开销的参数化量子电路来降低采样开销，并包含一个子电路优化方法以加速训练。实验证明，CKVQA能显著减少采样开销，同时保持与传统方法相当的准确性。

> **摘要翻译:** 当前量子硬件在可用量子比特数量上相比实际量子算法的要求存在显著限制。电路裁剪已被提出作为解决此问题的一种方法，它通过将较大的量子电路分解为可以在当前设备上执行的小部分。然而，这种方法通常会导致较高的采样开销，该开销随着切割点的数量呈指数级增长。在本篇论文中，我们引入了CKVQA，一个将电路裁剪应用于变分量子算法（VQAs）的框架。通过采用针对此场景优化的量子电路架构搜索，CKVQA旨在通过识别在算法性能和采样开销之间取得良好平衡的参数化量子电路来最小化采样开销。此外，由于电路裁剪会生成多个子电路，我们开发了一种子电路级别的优化方法来加速VQAs的训练并减少整体执行时间。我们将此框架应用于两种广泛使用的VQAs：量子近似优化算法和变分量子特征求解器。我们的数值结果表明，CKVQA框架显著降低了采样开销，同时保持了与传统参数化量子电路设计相当的准确性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [875] [Task Scheduling Optimization with Direct Constraints from a Tensor Network Perspective](https://arxiv.org/abs/2311.10433)
> *基于张量网络的有向约束任务调度优化*

*Alejandro Mata Ali, Iñigo Perez Delgado, Beatriz García Markaida, Aitor Moreno Fdez. de Leceta* | **Category: quant-ph, cs.ET, 68Q12, 15A69, 90C27, G.1.3; G.2.1** | **Updated: 2025-08-04**

**Keywords:** 张量网络, 任务调度, 约束优化, 量子启发式, 计算复杂性

**Comment:** 14 pages, 15 figures, improved version, with more experiments,
  analysis, new explanations and demonstrations, and open source code

> **TL;DR:** 本文提出一种利用量子启发式张量网络技术进行工业工厂任务优化的新方法，该方法能够为机器上的任务组合提供精确且明确的最优解，并通过多种算法优化和实际测试来降低计算复杂性。

**AI_Comments:** 该研究将张量网络技术应用于工业任务调度优化，提供了一种新颖的解决方案。方法论的创新性在于其利用量子启发式技术处理约束和优化计算复杂性。然而，抽象中关于“量子启发式”的具体实现细节和与传统调度算法的详细比较可以进一步阐述。

<details>
  <summary>Details</summary>

**Motivation:** 在工业工厂中优化任务调度，解决具有有向约束的任务组合问题。

**Method:** 利用量子启发式张量网络技术构建张量表示，并通过问题预处理、逻辑约束压缩、值确定技术优化、中间计算重用和迭代关系等方法降低计算复杂性。提出了主算法、迭代算法和遗传算法三种计算方法。

**Result:** 实现了一个简化的算法版本，并进行了性能测试，结果表明该方法可行。

**Conclusion:** 提出了一种使用张量网络技术进行任务调度优化的新方法，该方法能够提供精确的解决方案，并通过多种优化技术降低了计算复杂性。

> **ai_Abstract:** 本文介绍了一种基于张量网络技术的工业工厂任务调度优化方法，该方法能够处理有向约束并找到最优任务组合。通过问题预处理、约束压缩和迭代计算等技术，该方法显著降低了计算复杂性，并提供了精确的解决方案。文章还提出了三种算法（主算法、迭代算法和遗传算法）并进行了实现与测试。

> **摘要翻译:** 这项工作提出了一种使用量子启发式张量网络技术在工业工厂中进行任务优化 的新方法。该方法能够为一组机器上的任务组合提供最佳可能组合，并具有定向约束。使用此方法，可以为问题提供精确且明确的解决方案。该算法构建了提供问题解决方案的张量的张量网络表示。为了降低解决方案计算的计算复杂性，对该方法进行了改进，采用了问题预处理、新的逻辑约束压缩技术、具有先前计算结果的值确定技术优化、中间计算的重用以及约束的迭代关系。提出了三种计算算法：主算法、仅添加最少必要约束的迭代算法以及结合了迭代算法和基本遗传算法的遗传算法。最后，实现了两种算法的简化版本，并对它们的性能进行了测试，所有这些都是公开可用的。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [917] [End-to-End Protocol for High-Quality QAOA Parameters with Few Shots](https://arxiv.org/abs/2408.00557)
> *面向低采样次数的高质量QAOA参数的端到端协议*

*Tianyi Hao, Zichang He, Ruslan Shaydulin, Jeffrey Larson, Marco Pistoia* | **Category: quant-ph, cs.ET** | **Updated: 2025-08-04**

**Keywords:** QAOA, 参数优化, 低采样次数, 离子阱, 端到端协议

**Comment:** 13+2 pages, 11+3 figures, accepted by Physical Review Research

> **TL;DR:** 本研究提出了一种端到端协议，用于在量子近似优化算法（QAOA）的采样次数有限的情况下，优化参数以获得高质量的解决方案。该协议结合了多种参数设置和微调技术，并通过大规模数值实验进行了优化，发现在最简单的内部模型（线性）下优化器表现最佳。在32量子比特和5层QAOA的离子阱处理器上进行了实验验证，证明了该协议对硬件噪声具有鲁棒性，并且是有史以来在离子阱处理器上进行的最大的QAOA参数微调演示之一（以2量子比特门计数衡量）。

**AI_Comments:** 该研究在实际量子硬件上实现了QAOA参数的端到端优化，解决了有限采样次数下的关键挑战。通过结合多种优化技术并验证其对噪声的鲁棒性，为在嘈杂中型量子（NISQ）设备上运行QAOA提供了重要的实践指导。其在2量子比特门计数方面的规模是该领域的一个显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 量子近似优化算法（QAOA）在组合优化问题中表现出优于经典算法的潜力，但其性能高度依赖于参数的选择。在有限的电路执行次数（shots）下，为特定问题实例微调参数以获得有意义的性能提升是一项挑战。

**Method:** 开发了一种端到端的协议，结合了多种参数设置和微调技术。通过大规模数值实验优化该协议，发现简单的线性模型优化器效果最佳。在32量子比特、5层QAOA的离子阱处理器上实现了该协议，并评估了其对硬件噪声的鲁棒性。

**Result:** 在低采样次数设置下，具有最简单内部模型（线性）的优化器表现最佳。在离子阱处理器上进行了高达32量子比特和5层QAOA的实验演示，证明了该协议对小幅度硬件噪声的鲁棒性。这是在离子阱处理器上关于QAOA参数微调的最大规模演示之一（以2量子比特门计数衡量）。

**Conclusion:** 本研究提出的端到端协议能够有效地在采样次数有限的情况下优化QAOA参数，并在实际的离子阱量子处理器上得到了验证，证明了其在面对硬件噪声时的鲁棒性，为QAOA的应用提供了实用的解决方案。

> **ai_Abstract:** 本研究提出了一种端到端的协议，用于优化量子近似优化算法（QAOA）在采样次数有限情况下的参数选择。该协议结合了多种参数设置和微调技术，并通过大规模数值实验证明了简单的线性模型优化器效果最佳。在32量子比特的离子阱处理器上的实验结果表明，该协议对硬件噪声具有鲁棒性，并且是迄今为止在离子阱处理器上进行的最大规模的QAOA参数微调演示。

> **摘要翻译:** 量子近似优化算法（QAOA）是一种用于组合优化的量子启发式算法，已被证明在某些问题上比最先进的经典求解器具有更好的可扩展性。对于给定的问题实例，QAOA的性能在很大程度上取决于参数的选择。虽然在许多情况下可以使用平均情况下的最优参数，但通过针对特定实例进行微调可以获得有意义的性能提升。然而，当电路执行次数（shots）有限时，这项任务尤其具有挑战性。在本研究中，我们开发了一种端到端的协议，该协议结合了多种参数设置和微调技术。我们使用大规模数值实验来优化针对有限采样次数的协议，并观察到具有最简单内部模型（线性）的优化器表现最佳。我们在使用多达32个量子比特和5个QAOA层的离子阱处理器上实现了优化的流水线，并证明了该流水线对少量硬件噪声具有鲁棒性。据我们所知，这是在离子阱处理器上进行的关于QAOA参数微调的最大规模的演示，以2量子比特门计数衡量。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [31] [A Minimax Optimal Controller for Positive Systems](https://arxiv.org/abs/2502.01180)
> *正系统的一种极小极大最优控制器*

*Alba Gurpegui, Emma Tegling, Anders Rantzer* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 极小极大最优控制, 正系统, 贝尔曼方程, 扰动惩罚, 显式解

**Comment:** Presented at the 26th International Symposium on Mathematical Theory
  of Networks and Systems (Cambridge, UK)

> **TL;DR:** 本文提出了在无约束扰动下正系统极小极大最优控制的离散时间贝尔曼方程的显式解，并通过推导扰动惩罚的界限来表征有限解的存在性。

**AI_Comments:** 这项工作通过提供极小极大最优控制的显式解和确定扰动惩罚的界限，为正系统在存在扰动情况下的控制理论做出了重要贡献。其创新性在于解决了无约束扰动下的贝尔曼方程，并揭示了问题在特定条件下的收敛性。

<details>
  <summary>Details</summary>

**Motivation:** 解决在无约束扰动下正系统的极小极大最优控制问题，并提供其显式解。

**Method:** 通过推导扰动惩罚的界限，为离散时间贝尔曼方程的极小极大最优控制问题提供了显式解。

**Result:** 提出了离散时间贝尔曼方程的显式解；推导出了扰动惩罚的界限，该界限表征了该类问题存在有限解；揭示了在解可行的情况下，问题在无扰动时收敛到其等效的最小化问题。

**Conclusion:** 通过推导扰动惩罚的界限，成功为正系统在无约束扰动下的极小极大最优控制提供了显式解，并揭示了其在无扰动情况下的收敛性。

> **ai_Abstract:** 这篇论文为在无约束扰动下正系统的极小极大最优控制问题提供了一个离散时间贝尔曼方程的显式解。研究的关键在于推导了一个扰动惩罚的界限，该界限决定了问题存在有限解的条件。此外，该约束还揭示了当解可行时，该问题在无扰动的情况下会收敛到等效的最小化问题。

> **摘要翻译:** 我们提出了在无约束扰动下正系统的极小极大最优控制的离散时间贝尔曼方程的一个显式解。我们结果的主要贡献在于推导出了扰动惩罚的一个界限，该界限表征了该类问题存在有限解。此外，扰动惩罚的这一约束表明，在解可行的情况下，问题在没有扰动时收敛到其等效的最小化问题。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [63] [Self-sustained oscillations in discrete-time relay feedback systems](https://arxiv.org/abs/2504.05941)
> *离散时间继电器反馈系统中的自持振荡*

*Kang Tong, Christian Grussler, Michelle S. Chong* | **Category: math.OC, cs.SY, eess.SY, math.DS, 34A34, 34C12, 93C55** | **Updated: 2025-08-05**

**Keywords:** 自持振荡, 离散时间系统, 继电器反馈, 全正性, 单峰振荡

**Comment:** Update some figures by the comments from reviewers

> **TL;DR:** 研究离散时间继电器反馈系统中的单峰自持振荡，并利用全正性理论给出存在条件、周期界限和唯一性。

**AI_Comments:** 本文创新性地将全正性理论应用于离散时间继电器反馈系统的自持振荡分析，为理解和预测这类系统的行为提供了新的工具和严格的数学基础。

<details>
  <summary>Details</summary>

**Motivation:** 确定离散时间线性时不变继电器反馈系统中自持振荡的条件，特别是预测何时系统会出现单峰振荡。

**Method:** 在线性系统稳定且脉冲响应在其无限支撑上严格单调递减的假设下，采用全正性框架来解决主要问题。

**Result:** 证明了单峰自振荡只有在周期内正负元素数量一致时才能存在。基于此结果，推导了此类振荡的存在条件，确定了其周期的界限，并讨论了唯一性问题。

**Conclusion:** 单峰自振荡的存在条件、周期界限和唯一性可以通过全正性框架得到确定，且其存在要求周期内正负元素数量相等。

> **ai_Abstract:** 本文研究离散时间线性时不变继电器反馈系统中的自持振荡，特别是单峰振荡的预测问题。在特定假设下，作者创新性地运用全正性框架，证明了单峰自振荡存在的必要条件是周期内正负元素数量相等，并基于此推导了存在条件、周期界限和唯一性。

> **摘要翻译:** 我们研究了离散时间线性时不变继电器反馈系统中自持振荡的确定问题。具体来说，我们感兴趣的是预测这种系统何时会出现单峰振荡，即输出具有单峰周期。在假设线性系统稳定且其脉冲响应在其无限支撑上严格单调递减的情况下，我们采用了一种新颖的方法，利用全正性框架来解决我们的主要问题。结果表明，单峰自振荡只有在周期内正负元素的数量一致时才能存在。基于这一结果，我们推导了此类振荡的存在条件，确定了其周期的界限，并解决了唯一性问题。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [272] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control: Penalty Approach](https://arxiv.org/abs/2507.18114)
> *非凸优化框架用于组稀疏反馈线性二次最优控制：惩罚方法*

*Lechen Feng, Xun Li, Yuan-Hua Ni* | **Category: math.OC, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 非凸优化, 组稀疏, 反馈控制, 线性二次, PALM算法

**Comment:** 

> **TL;DR:** 本文提出了一个统一的非凸优化框架，用于设计无限时域线性二次 (LQ) 问题中的组稀疏反馈控制器，并开发了一种基于惩罚的近端交替线性化最小化 (PALM) 算法，解决了分布式LQ和稀疏反馈LQ问题，无需凸松弛。

**AI_Comments:** 本文的创新之处在于其直接处理非凸组 $\ell_0$ 范数正则化稀疏控制的方法，避免了限制性的凸松弛。所开发的基于惩罚的PALM算法及其对非强制性目标函数的严格收敛性分析是一项重要的理论贡献，这使得大规模系统中组稀疏反馈控制器能够进行实用且理论上可靠的设计。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖凸松弛或仅限于块对角结构，无法直接设计大规模系统中可扩展且结构感知的组稀疏反馈控制器。因此，需要一个统一的非凸优化框架来解决分布式LQ (DFT-LQ) 和稀疏反馈LQ (SF-LQ) 问题。

**Method:** 直接将控制器综合表述为具有组 $\ell_0$ 范数正则化的有限维非凸优化问题，以捕获一般稀疏模式。提出了一种基于惩罚的近端交替线性化最小化 (PALM) 算法，并提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。

**Result:** 建立了DFT-LQ和SF-LQ问题之间的联系，表明两者都可以在所提出的统一框架内解决。所提出的方法允许对所有子问题进行高效求解，并保证全局收敛到临界点。通过直接设计具有理论保证的组稀疏反馈增益，填补了现有文献中的一个关键空白，无需借助凸替代或限制性结构假设。

**Conclusion:** 本文提出了一个统一的非凸优化框架和一种基于惩罚的PALM算法，用于直接设计具有理论保证的组稀疏反馈控制器，解决了无限时域线性二次问题中的挑战，并克服了现有方法的局限性。

> **ai_Abstract:** 本文提出了一个统一的非凸优化框架，用于在无限时域线性二次 (LQ) 问题中设计组稀疏反馈控制器。它通过直接将控制器综合表述为具有组 $\ell_0$ 范数正则化的有限维非凸问题，解决了分布式LQ (DFT-LQ) 和稀疏反馈LQ (SF-LQ) 问题，这与现有依赖凸松弛的方法不同。该文提出了一种基于惩罚的近端交替线性化最小化 (PALM) 算法，并提供了严格的收敛性保证。该方法能够处理通用稀疏模式，高效求解子问题，并实现了具有理论保证的组稀疏反馈增益的直接设计，填补了相关研究领域的空白。

> **摘要翻译:** 本文开发了一个统一的非凸优化框架，用于在无限时域线性二次 (LQ) 问题中设计组稀疏反馈控制器。我们解决了经典 LQ 问题的两个突出扩展：具有固定通信拓扑的分布式 LQ 问题 (DFT-LQ) 和稀疏反馈 LQ 问题 (SF-LQ)，两者都源于大规模系统中对可扩展和结构感知控制的需求。与依赖凸松弛或仅限于块对角结构的现有方法不同，我们直接将控制器综合表述为具有组 $\ell_0$ 范数正则化的有限维非凸优化问题，捕获一般的稀疏模式。我们建立了 DFT-LQ 和 SF-LQ 问题之间的联系，表明两者都可以在我们统一的框架内解决。此外，我们提出了一种基于惩罚的近端交替线性化最小化 (PALM) 算法，并在温和假设下提供了严格的收敛性分析，克服了目标函数缺乏强制性（coercivity）的问题。所提出的方法允许对所有子问题进行高效求解，并保证全局收敛到临界点。我们的结果通过直接设计具有理论保证的组稀疏反馈增益，而无需借助凸替代或限制性结构假设，填补了文献中的一个关键空白。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [280] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control: Non-Penalty Approach](https://arxiv.org/abs/2507.19895)
> *非凸优化框架用于组稀疏反馈线性二次最优控制：无惩罚方法*

*Lechen Feng, Xun Li, Yuan-Hua Ni* | **Category: math.OC, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 非凸优化, 组稀疏, 反馈控制, ADMM, 无惩罚方法

**Comment:** arXiv admin note: substantial text overlap with arXiv:2507.18114

> **TL;DR:** 本文提出一种无惩罚的非凸优化方法，直接解决组稀疏反馈LQ控制问题，避免了惩罚方法的缺点。

**AI_Comments:** 本文的创新点在于提出了一种非惩罚方法来解决组稀疏反馈LQ控制中的非凸优化问题，有效避免了传统惩罚方法中参数调优困难和虚假驻点的问题。通过直接处理约束问题并提供ADMM的收敛性分析，以及在特定情况下结合次梯度下降与DC松弛的方法，该研究为直接设计具有理论保证的稀疏反馈增益提供了坚实的基础，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有惩罚方法在处理分布式线性二次（DFT-LQ）和稀疏反馈LQ（SF-LQ）问题时存在的固有缺点，如惩罚参数调优困难和引入虚假驻点。

**Method:** 首先从上图组合函数（epi-composition function）角度重新表述SF-LQ和DFT-LQ问题，旨在直接求解约束问题。然后，从理论角度重新审视交替方向乘子法（ADMM），并在特定假设下建立其收敛性。当这些假设不成立时，可采用结合次梯度下降和差分凸（Difference-of-Convex, DC）松弛方法的替代方法。

**Result:** 实现了具有理论保证的组稀疏反馈增益的直接设计，避免了使用凸替代、限制性结构假设或将约束纳入成本函数的惩罚公式。

**Conclusion:** 本文提出了一种有效的非惩罚方法，用于直接设计具有理论保证的组稀疏反馈增益，解决了传统惩罚方法的弊端。

> **ai_Abstract:** 本文提出了一种非惩罚的非凸优化框架，用于解决组稀疏反馈线性二次（SF-LQ）和分布式固定拓扑线性二次（DFT-LQ）最优控制问题。为了克服传统惩罚方法在参数调优和引入虚假驻点方面的缺点，作者通过上图组合函数视角重新表述了问题，并直接求解约束。理论上，论文分析了交替方向乘子法（ADMM）的收敛性，并提出当ADMM假设不满足时，可结合次梯度下降与差分凸（DC）松弛方法。最终，该方法能够直接设计具有理论保证的组稀疏反馈增益，避免了凸替代和惩罚公式的局限性。

> **摘要翻译:** 这项工作是[8]的配套论文，其中分布式线性二次问题与固定通信拓扑（DFT-LQ）和稀疏反馈LQ问题（SF-LQ）被表述为具有仿射约束的非光滑非凸优化问题。此外，在\cite{feng-part1}中考虑了惩罚方法，并研究了PALM（近端交替线性化最小化）算法的收敛性和复杂性分析。在本文中，我们旨在解决惩罚方法的固有缺点，例如惩罚参数调优的挑战以及引入虚假驻点的风险。具体来说，我们首先从上图组合函数（epi-composition function）的角度重新表述SF-LQ问题和DFT-LQ问题，旨在直接解决约束问题。然后，从理论角度，我们重新审视交替方向乘子法（ADMM），并在某些假设下建立其收敛到聚点集的理论。当这些假设不成立时，我们可以有效地利用结合次梯度下降和差分凸（Difference-of-Convex）松弛方法的替代方法。总之，我们的结果使得能够直接设计具有理论保证的组稀疏反馈增益，而无需借助凸替代、限制性结构假设或将约束纳入成本函数的惩罚公式。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [459] [Improved algorithms and novel applications of the FrankWolfe.jl library](https://arxiv.org/abs/2501.14613)
> *FrankWolfe.jl库的改进算法和新颖应用*

*Mathieu Besançon, Sébastien Designolle, Jannis Halbey, Deborah Hendrych, Dominik Kuzinowicz, Sebastian Pokutta, Hannah Troppens, Daniel Viladrich Herrmannsdoerfer, Elias Wirth* | **Category: math.OC, cs.MS** | **Updated: 2025-08-05**

**Keywords:** Frank-Wolfe, 约束优化, Julia, 算法库, 性能评估

**Comment:** 

> **TL;DR:** 本文总结了FrankWolfe.jl库在Frank-Wolfe算法开发中的进展，展示了其作为实践者工具箱和算法设计者模块化生态系统的双重作用，并通过实验验证了其性能。

**AI_Comments:** 该论文的创新点在于FrankWolfe.jl库本身，它为Frank-Wolfe算法的实践者和研究者提供了一个高性能、模块化且易于使用的平台。这对于推动大规模约束优化领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Frank-Wolfe (FW) 算法已成为约束优化，特别是大规模问题的重要方法。本文的动机是总结FrankWolfe.jl库在FW算法开发中的算法设计选择和进展，并展示其作为实践者首选工具箱和算法设计者模块化生态系统的双重目的。

**Method:** 本文总结了FrankWolfe.jl的算法设计选择和过去几年取得的进展。作者回顾了该库在近期文献中的关键用例，并展示了几个FW变体在重要问题类别上的性能，这些实验被整理在一个单独的存储库中用于持续基准测试。

**Result:** Not mentioned in abstract

**Conclusion:** FrankWolfe.jl库成功地实现了其作为应用FW方法的实践者工具箱和供算法设计者试验其变体的模块化生态系统的双重目的。通过实验证明，该库中的FW变体在重要问题类别上表现良好。

> **ai_Abstract:** 本文总结了FrankWolfe.jl库在Frank-Wolfe (FW) 算法开发中的进展，该库提供了最先进FW变体的高性能实现。文章回顾了该库作为实践者工具箱和算法设计者模块化生态系统的双重目的的关键用例。此外，通过在重要问题类别上的实验，展示了该库中几种FW变体的性能。

> **摘要翻译:** Frank-Wolfe (FW) 算法已成为约束优化，特别是在大规模问题上的重要方法。在本文中，我们总结了FrankWolfe.jl——一个汇集了最先进FW变体高性能实现的Julia软件包——在过去几年开发中取得的算法设计选择和进展。我们回顾了该库在近期文献中的关键用例，这些用例符合其最初的双重目的：首先，成为应用FW方法的实践者的事实标准工具箱；其次，为试验自己的变体和算法块实现的算法设计者提供一个模块化生态系统。最后，我们在几个实验中展示了几个FW变体在重要问题类别上的性能，这些实验被我们整理在一个单独的存储库中用于持续基准测试。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [717] [Lyapunov Analysis For Monotonically Forward-Backward Accelerated Algorithms](https://arxiv.org/abs/2412.13527)
> *Lyapunov分析用于单调前向-后向加速算法*

*Mingwei Fu, Bin Shi* | **Category: math.OC, cs.NA, math.NA, stat.ML** | **Updated: 2025-08-05**

**Keywords:** Lyapunov分析, M-NAG, M-FISTA, 线性收敛性, 单调加速算法

**Comment:** 20 pages, 4 figures, and 1 table

> **TL;DR:** 该论文使用Lyapunov分析方法证明了M-NAG和M-FISTA的线性收敛性，并提出了一种新的Lyapunov函数，消除了动能项，并适用于M-NAG。

**AI_Comments:** 该研究在Lyapunov分析方面取得了重要进展，为单调加速算法的理论分析提供了新的方法和见解。通过引入新的Lyapunov函数和证明其线性收敛性，该研究解决了M-NAG和M-FISTA长期存在的理论难题。然而，该方法在实际应用中的效率和普适性仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** Nesterov加速梯度法（NAG）虽然比梯度下降法收敛更快，但其函数值不具有单调性。为了解决这个问题，M-NAG被提出，并扩展到M-FISTA用于复合问题。然而，在强凸条件下，M-NAG和M-FISTA的线性收敛性仍未得到证明。

**Method:** 该论文通过隐式速度相位表示来分析M-NAG，并表明需要附加假设来完全恢复NAG的迭代。它证明了M-NAG更新足以构建一个保证线性收敛的Lyapunov函数。通过修改混合序列以包含前向索引梯度，开发了一种新的Lyapunov函数，消除了动能项，并可以直接扩展到M-NAG。最后，利用新开发的近邻不等式，将结果扩展到M-FISTA，证明其线性收敛性。

**Result:** 该论文证明了M-NAG的线性收敛性，即使没有完全恢复NAG的迭代。它还开发了一种新的Lyapunov函数，消除了动能项，并且可以扩展到M-FISTA，证明了M-FISTA的线性收敛性。

**Conclusion:** 该论文通过Lyapunov分析方法，证明了M-NAG和M-FISTA的线性收敛性，并加深了对单调加速方法的理论理解。

> **ai_Abstract:** 本研究利用Lyapunov分析方法，成功证明了M-NAG和M-FISTA在强凸条件下的线性收敛性。论文提出了一种新的Lyapunov函数，该函数通过引入前向索引梯度消除了动能项，从而简化了分析过程，并将结果直接推广到M-FISTA。研究结果不仅填补了M-NAG和M-FISTA线性收敛性证明的空白，也为理解和发展单调加速优化算法提供了新的理论视角。

> **摘要翻译:** Nesterov加速梯度法（NAG）比梯度下降法在凸优化方面收敛更快，但其函数值不具有单调性。为了解决这个问题，Beck和Teboulle[2009b]提出了一种单调变体M-NAG，并将其扩展到近邻设置，如Lasso等复合问题的M-FISTA。然而，在强凸条件下证明M-NAG和M-FISTA的线性收敛性仍然是一个悬而未决的问题。在本文中，我们通过隐式速度相位表示分析了M-NAG，并表明需要附加假设，即位置更新或相位耦合关系，才能完全恢复NAG的迭代。M-NAG的本质在于控制一个辅助序列以强制非增加。我们进一步证明，仅M-NAG更新就足以构建一个保证线性收敛的Lyapunov函数，而无需依赖完整的NAG迭代。通过修改混合序列以包含前向索引梯度，我们开发了一种新的Lyapunov函数，该函数消除了动能项，从而可以直接扩展到M-NAG。所需的起始索引仅取决于动量参数，而不取决于问题常数。最后，利用新开发的近邻不等式，我们将结果扩展到M-FISTA，证明了其线性收敛性，并加深了对单调加速方法的理论理解。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [725] [Global Optimality in Multi-Flyby Asteroid Trajectory Optimization: Theory and Application Techniques](https://arxiv.org/abs/2508.02904)
> *多飞掠小行星轨迹优化的全局最优性：理论与应用技术*

*Zhong Zhang, Xiang Guo, Di Wu, Hexi Baoyin, Junfeng Li, Francesco Topputo* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 全局最优性, 多飞掠轨迹优化, 动态规划, 小行星任务, 最优控制

**Comment:** 

> **TL;DR:** 该论文提出了一种处理多飞掠小行星任务轨迹优化问题的方法，通过将问题转化为多阶段决策问题，并应用动态规划，以实现全局最优。该方法考虑了各种约束和推进方式，并通过计算技术提高了效率，并在多个测试问题中证明了其有效性，优于现有最优轨迹。

**AI_Comments:** 该研究提出了一种有前景的方法来解决小行星任务轨迹优化的长期存在的问题。将最优控制问题转化为多阶段决策问题，从而可以应用动态规划，这是一个新颖的途径。该方法在确保全局最优性和提供误差界限方面具有显著优势。然而，该方法在处理高维问题或非常复杂约束时的可扩展性仍有待进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 设计多飞掠小行星任务的最优轨迹在科学上至关重要，但由于非线性动力学、中间约束和众多局部最优解，在技术上具有挑战性。

**Method:** 将具有内点等式约束的原始最优控制问题转化为多阶段决策问题，从而可以直接应用动态规划。该方法还提供了一个可量化的全局最优误差界限，并包含提高效率的计算技术，如双脉冲特例的专门解和自适应步进优化策略。

**Result:** 所提出的方法在GTOC4（脉冲和低推力变体）、GTOC11问题上进行了验证，并显示出优于已知最优轨迹的燃料消耗。

**Conclusion:** 该方法在小行星轨迹优化方面是普遍且有效的，能够实现全局最优性，并优于现有轨迹。

> **ai_Abstract:** 本研究提出了一种用于多飞掠小行星任务轨迹优化的新方法，旨在解决传统方法中的局部最优性问题。通过将问题转化为多阶段决策问题，并应用动态规划和贝尔曼最优性原理，该方法能够实现全局最优。该方法还提供了误差界限，并考虑了脉冲和低推力等多种情况。在GTOC4和GTOC11等竞赛问题的测试中，该方法均显示出优于现有轨迹的燃料消耗，证明了其有效性和广泛适用性。

> **摘要翻译:** 设计多飞掠小行星任务的最优轨迹在科学上至关重要，但由于非线性动力学、中间约束和众多局部最优解，在技术上具有挑战性。本文提出了一种在给定序列下，逼近多飞掠轨迹优化全局最优性的方法。将具有内点等式约束的原始最优控制问题转化为多阶段决策问题。这种重新表述使得动态规划能够在较低的维度下直接应用，并遵循贝尔曼最优性原理。此外，该方法还提供了由离散化和近似假设引起的全局最优误差的可量化界限，从而确保了所得解的置信度。该方法能够适应交会和飞掠场景中脉冲和低推力机动方案。介绍了多种提高效率的计算技术，包括双脉冲情况的专门解和自适应步进优化策略。所提出的方法通过三个问题进行了验证：1）第四届全球轨迹优化竞赛问题（GTOC4）的脉冲变体，2）GTOC11问题，3）原始低推力GTOC4问题。每个案例都证明了在燃料消耗方面优于已知的最优轨迹。这些结果证明了该方法在全局轨迹优化中的普遍性和有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [809] [A Comparative Study of Optimal Control and Neural Networks in Asteroid Rendezvous Mission Analysis](https://arxiv.org/abs/2508.02920)
> *最优控制与神经网络在小行星交会任务分析中的比较研究*

*Zhong Zhang, Niccolò Michelotti, Gonçalo Oliveira Pinho, Francesco Topputo* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 最优控制, 神经网络, 小行星交会, 猪肉排图, 轨迹优化

**Comment:** 

> **TL;DR:** 该研究比较了最优控制和神经网络在小行星交会任务设计中的应用。结果表明，在没有路径约束的简化场景下，神经网络在预测燃料消耗和飞行时间方面表现良好，能捕捉猪肉排图的主要特征。当最优控制方法因多重局部最优而失败时，神经网络仍能提供平滑且全局一致的预测，提高了早期小行星候选筛选的效率。然而，路径约束会影响神经网络在边界区域的预测精度，限制了其在详细任务设计阶段的应用。总的来说，神经网络与猪肉排图分析的结合为任务设计者提供了一个有效的决策工具。

**AI_Comments:** 这项研究通过比较两种不同的方法（最优控制和神经网络）在小行星交会任务设计中的应用，为该领域提供了有价值的见解。神经网络在处理复杂问题和提高效率方面的潜力尤其值得关注，尽管在存在路径约束的情况下其准确性有所下降。未来的研究可以进一步探索如何改进神经网络模型以克服这些限制，或者研究混合方法以结合两者的优点。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在比较最优控制方法和神经网络在小行星交会任务初步设计中的适用性和准确性，特别是在猪肉排图分析的背景下，为任务设计者提供更有效的决策工具。

**Method:** 本研究提出了一种低推力轨迹优化模型，并结合了序列凸规划（SCP）和解延拓策略来解决最优控制问题。同时，还构建了一个包含两种模型的神经网络框架：一个用于预测最小燃料消耗（Δv），另一个用于估计最小飞行时间（Δt）。

**Result:** 在没有路径约束的简化场景下，神经网络方法在设计空间的绝大多数区域实现了较低的相对误差，并成功捕捉了猪肉排图的主要结构特征。在SCP方法因多重局部最优而失败的情况下，神经网络仍能提供平滑且全局一致的预测。然而，路径约束的存在会导致神经网络在某些边界区域出现明显的差异。

**Conclusion:** 最优控制方法和神经网络在小行星交会任务初步设计中各有优劣。神经网络在处理复杂问题和提高早期筛选效率方面具有显著优势，但其在存在路径约束的详细设计阶段的应用存在局限性。将神经网络与猪肉排图分析相结合，为任务设计者提供了一个有效的决策支持工具。

> **ai_Abstract:** 本研究比较了最优控制和神经网络在小行星交会任务初步设计中的应用。在无路径约束的简化场景下，神经网络在预测燃料消耗和飞行时间方面表现出良好的精度，并能有效捕捉猪肉排图特征。特别是在最优控制方法因多重局部最优失效时，神经网络仍能提供稳定预测，提升了早期候选筛选效率。然而，路径约束会影响神经网络在边界区域的预测精度。研究认为，神经网络与猪肉排图分析的结合为任务设计提供了有效的决策支持，但其在详细设计阶段的应用仍需谨慎。

> **摘要翻译:** 本文研究了最优控制方法和基于神经网络的估计器在初步小行星交会任务设计中，尤其是在猪肉排图分析方面的适用性和准确性。所考虑的场景涉及一个配备低推力发动机的深空立方星，从地球出发，在三年发射窗口内与近地小行星交会。提出了一种低推力轨迹优化模型，该模型结合了可变比冲、最大推力和路径约束。最优控制问题采用序列凸规划（SCP）结合解延拓策略来有效求解。神经网络框架包含两个模型：一个预测最小燃料消耗（Δv），另一个估计最小飞行时间（Δt），用于评估转移的可行性。案例结果表明，在没有路径约束的简化场景下，神经网络方法在设计空间的绝大多数区域实现了较低的相对误差，并成功捕捉了猪肉排图的主要结构特征。在SCP方法因存在多重局部最优而失败的情况下，神经网络仍能提供平滑且全局一致的预测，显著提高了早期小行星候选筛选的效率。然而，路径约束导致的易变可行区域在某些边界区域引起了明显的差异，从而限制了该网络在详细任务设计阶段的适用性。总的来说，将神经网络与猪肉排图分析相结合，为任务设计者和行星科学家提供了一个有效的决策工具，具有显著的工程应用潜力。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [849] [Quantum Hamiltonian Descent based Augmented Lagrangian Method for Constrained Nonconvex Nonlinear Optimization](https://arxiv.org/abs/2508.02969)
> *基于量子哈密顿下降的增广拉格朗日方法用于约束非凸非线性优化*

*Mingze Li, Lei Fan, Zhu Han* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-08-05**

**Keywords:** 非线性规划, 增广拉格朗日方法, 量子哈密顿下降, 模拟退火, 非凸优化

**Comment:** 

> **TL;DR:** 提出了一种结合量子哈密顿下降和增广拉格朗日方法的框架（QHD-ALM），用于解决大规模约束非凸非线性规划问题，并使用模拟退火算法在经典计算机上模拟。

**AI_Comments:** 该研究将量子计算概念（量子哈密顿下降）应用于经典的优化问题（非线性规划），并提出了一种在经典计算机上实现的方法（模拟退火）。这为利用量子计算解决实际优化问题提供了一种可能的途径，但其在大规模问题上的可扩展性和实际性能仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 解决大规模、非凸、约束非线性规划（NLP）问题的挑战。

**Method:** 将约束NLP问题转化为无约束NLP问题，然后利用量子哈密顿下降（QHD）求解，并通过模拟退火算法在经典计算机上模拟QHD的动态过程。

**Result:** 在“电力制氢系统”上的模拟结果验证了该算法的有效性。

**Conclusion:** 所提出的QHD-ALM框架能够有效地解决大规模、约束非凸非线性规划问题。

> **ai_Abstract:** 本文提出了一种量子哈密顿下降（QHD）增强型拉格朗日方法（ALM）框架（QHD-ALM），用于解决大规模、约束性非凸非线性规划（NLP）问题。该方法将约束NLP问题转化为无约束问题，并利用QHD求解，同时通过模拟退火算法在经典计算机上模拟动态过程。在电力制氢系统上的应用表明了该算法的有效性。

> **摘要翻译:** 非线性规划（NLP）在电力能源系统、化学工程、通信网络和金融工程等领域起着至关重要的作用。然而，由于解景观的复杂性和非线性非凸约束的存在，求解大规模、非凸的NLP问题仍然是一个重大挑战。在本文中，我们开发了一个基于量子哈密顿下降的增广拉格朗日方法（QHD-ALM）框架，以解决大规模、约束的非凸NLP问题。增广拉格朗日方法（ALM）可以将约束NLP转换为无约束NLP，然后可以使用量子哈密顿下降（QHD）进行求解。为了在经典机器上运行QHD，我们提出使用模拟退火算法作为模拟动态过程的引擎。我们将该算法应用于一个电力制氢系统，仿真结果验证了我们算法的有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [32] [Machine Learning Algorithms for Transplanting Accelerometer Observations in Future Satellite Gravimetry Missions](https://arxiv.org/abs/2508.03522)
> *机器学习算法在未来卫星重力测量任务中用于加速度计观测值移植*

*Mohsen Romeshkani, Jürgen Müller, Sahar Ebadi, Alexey Kupriyanov, Annike Knabe, Nina Fletling, Manuel Schilling* | **Category: physics.geo-ph, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 卫星重力测量, 加速度计移植, 机器学习, 冷原子干涉仪, 量子传感器

**Comment:** 

> **TL;DR:** 本研究评估了在未来卫星重力测量任务中，利用机器学习和新型加速度计配置（如冷原子干涉仪）进行加速度计数据移植，以提升重力场恢复的精度和成本效益。

**AI_Comments:** 本文的创新点在于将量子传感器技术（冷原子干涉仪）与数据驱动的机器学习移植方法相结合，用于解决传统静电加速度计在卫星重力测量中的局限性。这提供了一种高精度且成本效益的解决方案，对于未来地球重力场监测任务具有重要意义，有望提升全球质量再分配过程的监测能力。

<details>
  <summary>Details</summary>

**Motivation:** 地球重力场的精确连续监测对于追踪与气候变化、水文循环和地球动力学现象相关的质量再分配过程至关重要。GRACE和GRACE-FO任务的重力场恢复精度强烈依赖于加速度计的性能和数据连续性，而传统静电加速度计存在局限性，促使人们探索先进传感器技术和数据恢复技术。

**Method:** 本研究系统评估了使用新型加速度计配置（包括冷原子干涉仪(CAI)加速度计和混合EA-CAI设置）的加速度计数据移植，并应用了分析和基于机器学习的方法。通过全面的闭环低低卫星间跟踪(LL-SST)模拟，比较了四种场景（从传统EA-only到理想双混合配置），并特别关注了使用不同神经网络方法的移植方法的性能。

**Result:** 双混合配置提供了最准确的重力场恢复。然而，基于移植的混合设置，特别是在机器学习的支持下，被证明是一种稳健且成本效益高的替代方案，以最少的额外硬件实现了可比的性能。

**Conclusion:** 结合量子传感器技术和数据驱动的移植方法有望改进未来卫星重力测量任务，为地球动态重力场的全球监测铺平道路。

> **ai_Abstract:** 本研究旨在通过探索新型加速度计配置（如冷原子干涉仪和混合EA-CAI设置）以及结合机器学习方法，来提高未来卫星重力测量任务中加速度计数据移植的精度和成本效益。通过闭环模拟，研究发现双混合配置能提供最准确的重力场恢复，而基于机器学习支持的移植混合设置则是一种具有成本效益且性能相当的替代方案，这为结合量子传感器和数据驱动移植改进地球重力场监测开辟了新途径。

> **摘要翻译:** 地球重力场的精确和连续监测对于追踪与气候变率、水文循环和地球动力学现象相关的质量再分配过程至关重要。虽然GRACE和GRACE Follow-On (GRACE-FO)任务通过低低卫星间跟踪(LL-SST)为卫星重力测量设定了基准，但重力场恢复的精度仍然强烈依赖于加速度计(ACC)的性能和ACC数据的连续性。传统的静电加速度计(EA)面临可能阻碍任务成果的局限性，这促使人们探索先进的传感器技术和数据恢复技术。本研究系统地评估了使用新型加速度计配置（包括冷原子干涉仪(CAI)加速度计和混合EA-CAI设置）的加速度计数据移植，并应用了分析和基于机器学习的方法。通过全面的闭环LL-SST模拟，我们比较了从传统EA-only设置到理想双混合配置的四种场景，特别关注了使用不同神经网络方法的基于移植的方法的性能。我们的结果表明，双混合配置提供了最准确的重力场恢复。然而，基于移植的混合设置，特别是在机器学习的支持下，被证明是一种稳健且成本效益高的替代方案，以最少的额外硬件实现了可比的性能。这些发现突出了量子传感器技术和数据驱动移植相结合在未来卫星重力测量任务中的前景，为改进地球动态重力场的全球监测铺平了道路。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-biogn'></a>
## q-bio.GN 

### [60] [A Novel cVAE-Augmented Deep Learning Framework for Pan-Cancer RNA-Seq Classification](https://arxiv.org/abs/2508.02743)
> *一种用于泛癌RNA-Seq分类的新型cVAE增强深度学习框架*

*Vinil Polepalli* | **Category: q-bio.GN, cs.AI, cs.LG** | **Updated: 2025-08-02**

**Keywords:** 泛癌分类, RNA-Seq, 深度学习, cVAE, 数据增强

**Comment:** 

> **TL;DR:** 本研究提出了一种基于cVAE增强的深度学习框架，通过生成合成数据来提高泛癌RNA-Seq分类的准确性，尤其对代表性不足的癌症类别效果显著。

**AI_Comments:** 该论文的创新点在于利用cVAE进行数据增强，有效解决了泛癌RNA-Seq分类中数据稀疏和类别不平衡的问题。通过生成高质量的合成样本，显著提升了分类模型的性能，尤其对罕见癌症类型具有重要应用价值。这是一个很有前景的方向，未来可以探索其在更多癌症类型和更复杂生物医学数据上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 泛癌分类使用转录组（RNA-Seq）数据面临维度极高和样本量有限的挑战，这限制了其在肿瘤分型和治疗选择中的应用。

**Method:** 该研究提出了一种深度学习框架：首先对来自TCGA的801个肿瘤RNA-Seq样本（涵盖5种癌症类型）进行特征选择，将20,531个基因表达特征减少到500个。然后，训练一个类条件变分自编码器（cVAE）来学习基因表达的潜在表示，并生成合成基因表达样本，使训练集数据量加倍，以缓解过拟合和类别不平衡。最后，在一个增强的数据集上训练一个两层多层感知器（MLP）分类器来预测肿瘤类型。

**Result:** 该增强框架在保留的测试集上实现了约98%的高分类准确率，显著优于仅使用原始数据训练的分类器。结果表明，基于cVAE的合成数据增强可以显著提高泛癌预测性能，特别是对于代表性不足的癌症类别。

**Conclusion:** cVAE（类条件变分自编码器）在泛癌RNA-Seq分类中通过数据增强显著提升了模型的预测性能，尤其对样本稀缺的癌症类型具有重要意义。

> **ai_Abstract:** 本研究提出了一种新颖的深度学习框架，利用类条件变分自编码器（cVAE）生成合成数据，以解决泛癌RNA-Seq分类中高维度和样本量有限的挑战。该框架首先对TCGA数据进行特征选择，然后使用cVAE生成训练样本，将数据集大小加倍，以缓解过拟合和类别不平衡。最终，在一个增强的数据集上训练MLP分类器，并在测试集上取得了约98%的高分类准确率，显著优于未增强的模型，尤其在处理样本量较少的癌症类别时表现出优势。

> **摘要翻译:** 使用转录组（RNA-Seq）数据进行泛癌分类可以为肿瘤亚型鉴定和治疗选择提供信息，但由于维度极高和样本量有限而具有挑战性。在本研究中，我们提出了一种新颖的深度学习框架，该框架使用类条件变分自编码器（cVAE）来增强泛癌基因表达分类的训练数据。我们使用来自癌症基因组图谱（TCGA）的801个涵盖5种癌症类型的肿瘤RNA-Seq样本，首先进行特征选择，将20,531个基因表达特征减少到500个变异表达最高的基因。然后，在此数据上训练一个cVAE，以学习以癌症类型为条件的基因表达潜在表示，从而能够为每个肿瘤类别生成合成基因表达样本。我们使用这些cVAE生成的样本（使数据集大小加倍）来增强训练集，以减轻过拟合和类别不平衡。随后，在一个增强的数据集上训练一个两层多层感知器（MLP）分类器来预测肿瘤类型。该增强框架在保留的测试集上实现了高分类准确率（约98%），显著优于仅在原始数据上训练的分类器。我们提供了详细的实验结果，包括VAE训练曲线、分类器性能指标（ROC曲线和混淆矩阵）以及说明该方法的架构图。结果表明，基于cVAE的合成增强可以显著提高泛癌预测性能，特别是对于代表性不足的癌症类别。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

<a id='mathlo'></a>
## math.LO 

### [84] [Difference-restriction algebras with operators](https://arxiv.org/abs/2508.03432)
> *带有算子的差限制代数*

*Célia Borlido, Ganna Kudryavtseva, Brett McLean* | **Category: math.LO, cs.LO** | **Updated: 2025-08-05**

**Keywords:** 差限制代数, 伴随, 对偶性, Hausdorff 'etale空间, 偏函数

**Comment:** 35 pages

> **TL;DR:** 本文引入了差限制代数，并在其与Hausdorff 'etale空间之间建立了伴随和对偶性，推广了广义布尔代数的相关理论，并将其扩展到带有算子的情况。

**AI_Comments:** 这篇论文在范畴论和代数拓扑的交叉领域做出了贡献，通过引入差限制代数并建立其与Hausdorff 'etale空间之间的伴随和对偶性，成功地推广了广义布尔代数的相关理论。其创新点在于定义了新的代数结构并将其与拓扑空间联系起来，特别是推广到带有算子的情况，增强了理论的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在推广广义布尔代数与Hausdorff空间之间的伴随和对偶性，将其应用于一类新的抽象偏函数代数——差限制代数。

**Method:** 本文引入了差限制代数的概念，定义了其有限兼容完备化，并通过伴随诱导的单子展示了这种完备化。研究了该伴随如何限制为对偶性，并将这些结果推广到带有任意额外兼容性保持算子的差限制代数。

**Result:** 建立了差限制代数与Hausdorff 'etale空间之间的伴随关系，并证明了该伴随诱导的单子产生了差限制代数的有限兼容完备化。此外，该伴随限制为有限兼容完备的差限制代数与局部紧零维Hausdorff 'etale空间之间的对偶性。这些结果进一步推广到带有任意额外兼容性保持算子的差限制代数。

**Conclusion:** 成功地建立了差限制代数及其带有算子的推广形式与拓扑空间之间的伴随和对偶性，推广了广义布尔代数与拓扑空间的相关理论。

> **ai_Abstract:** 本文引入了差限制代数，这是一种在相对补和域限制下闭合的抽象偏函数代数。研究建立了差限制代数与Hausdorff 'etale空间范畴之间的伴随关系，并证明了该伴随诱导的单子能实现差限制代数的有限兼容完备化。进一步，该伴随在特定条件下可限制为这些代数与局部紧零维Hausdorff 'etale空间之间的对偶性。所有这些伴随、对偶和完备化结果都被推广到带有任意额外兼容性保持算子的差限制代数，从而推广了广义布尔代数与拓扑空间之间已知的相关理论。

> **摘要翻译:** 我们展示了一类抽象偏函数代数（我们称之为差限制代数）与Hausdorff 'etale空间范畴之间的伴随。差限制代数是那些同构于在相对补和域限制下闭合的偏函数集合的代数。我们的伴随推广了广义布尔代数范畴与Hausdorff空间范畴之间的伴随。我们定义了差限制代数的有限兼容完备化，并表明由我们的伴随诱导的单子产生了任何差限制代数的有限兼容完备化。作为推论，该伴随限制为有限兼容完备的差限制代数与局部紧零维Hausdorff 'etale空间之间的对偶性，推广了广义布尔代数与局部紧零维Hausdorff空间之间的对偶性。然后，我们将这些伴随、对偶性和完备化结果扩展到配备有任意额外兼容性保持算子的差限制代数。

</details>

[⬆️ 返回分类顶部](#mathlo) | [⬆️ 返回总目录](#toc)

---

### [431] [Complexity of inversion of functions on the reals](https://arxiv.org/abs/2412.07592)
> *实数函数求逆的复杂性*

*George Barmpalias, Mingyang Wang, Xiaoyan Zhang* | **Category: math.LO, cs.IT, math.IT, math.PR** | **Updated: 2025-08-05**

**Keywords:** 复杂性, 函数求逆, 实数, 可计算函数

**Comment:** 

> **TL;DR:** 研究实数上可计算函数求逆的复杂性。

**AI_Comments:** 该论文主要关注实数域上函数求逆的计算复杂性，具体探讨了确定性和概率性两种求逆方式。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了实数域上偏可计算函数的确定性与概率性求逆的复杂性。

> **摘要翻译:** 我们研究了实数上偏可计算函数的确定性和概率性求逆的复杂性。

</details>

[⬆️ 返回分类顶部](#mathlo) | [⬆️ 返回总目录](#toc)

---

<a id='physicshist-ph'></a>
## physics.hist-ph 

### [204] [Beyond the Wavefunction: Qualia Abstraction Language Mechanics and the Grammar of Awareness](https://arxiv.org/abs/2508.02755)
> *超越波函数：感受质抽象语言力学与意识语法*

*Mikołaj Sienicki, Krzysztof Sienicki* | **Category: physics.hist-ph, cs.AI** | **Updated: 2025-08-03**

**Keywords:** 感受质抽象语言, 量子力学, 主观经验, 观察者悖论, 意识语法

**Comment:** 65 pages, 49 references, 7 figures

> **TL;DR:** 该论文提出了一种基于主观经验的量子力学形式化重构，引入感受质抽象语言（QAL）来重新诠释量子概念，并认为观察者悖论是语言而非本体论问题。

**AI_Comments:** 这篇论文极具创新性，它试图将量子力学的基础从传统的数学抽象转向主观经验，并从语言学的角度重新审视观察者悖论。其引入的感受质抽象语言（QAL）框架，挑战了物理学中的柏拉图主义观点，并为构建一种以意识和内省为核心的物理理论提供了新的视角。该研究的局限性可能在于其概念的抽象性和验证的难度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量子力学根植于外部数学抽象，并且缺乏建模第一人称结构的正式词汇，这导致了量子力学中的观察者悖论。该研究旨在提出一种基于主观经验的替代性框架。

**Method:** 论文提出了感受质抽象语言（QAL），它将物理系统建模为内省单元的演化流，而非希尔伯特空间中的态矢量。QAL将叠加重新定义为结构化模糊性，将坍缩重新定义为内省收缩，并将纠缠建模为感受质流之间的语义共振。它引入了一个正式词汇来建模第一人称结构，提供了一个将观察者嵌入系统内部的形态动力学框架。

**Result:** QAL与内物理方法对齐，并与量子理论的标准解释形成对比。它为一种后柏拉图主义的、基于内省的物理学提供了启示。

**Conclusion:** 该论文的结论是，QAL引入了一种新的词汇和形态动力学框架，用于建模第一人称结构，从而将观察者嵌入到系统中，并为建立一种基于内省的物理学提供了基础，解决了量子力学中的观察者悖论。

> **ai_Abstract:** 本论文提出感受质抽象语言（QAL），旨在从主观经验的结构化动态出发，对量子力学进行形式化重构。QAL将物理系统视为内省单元的演化流，并以此重新诠释了叠加、坍缩和纠缠等量子概念。论文认为，量子力学中的观察者悖论源于缺乏描述第一人称结构的语言，QAL正提供了这种语言，从而将观察者内嵌于系统之中，为建立一种基于内省的、后柏拉图主义的物理学奠定了基础。

> **摘要翻译:** 我们提出了一种量子力学的形式化重构，其基础并非外部数学抽象，而是主观经验的结构化动态。感受质抽象语言（QAL）将物理系统建模为内省单元的演化流，即模态、形状和功能效应的结构化序列，而非希尔伯特空间中的态矢量。这种方法重新构想了核心量子概念：叠加成为一种结构化模糊性；坍缩被重新定义为内省收缩；纠缠被建模为感受质流之间的语义共振。借鉴唯名论哲学和人工智能中监督理论限制的见解，我们认为量子力学中的观察者悖论并非本体论上的缺失，而是语言上的缺失：缺乏一个用于建模第一人称结构的正式词汇。QAL引入了这样一个词汇，提供了一个将观察者嵌入系统内部并用内源性转换取代抽象投影的形态动力学框架。我们分析了QAL与内物理方法的对齐性，将其与量子理论的标准解释进行对比，并探讨了其对后柏拉图主义的、基于内省的物理学的意义。

</details>

[⬆️ 返回分类顶部](#physicshist-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [239] [Random Effects Models for Understanding Variability and Association between Brain Functional and Structural Connectivity](https://arxiv.org/abs/2508.02908)
> *随机效应模型用于理解大脑功能连接和结构连接之间的变异性和关联*

*Lingyi Peng, Qiaochu Wang, Yaotian Wang, Jie He, Xu Zou, Shuoran Li, Dana L. Tudorascu, David J. Schaeffer, Lauren Schaeffer, Diego Szczupak, Emily S. Rothwell, Stacey J. Sukoff Rizzo, Gregory W. Carter, Afonso C. Silva, Tingting Zhang* | **Category: q-bio.NC, stat.AP** | **Updated: 2025-08-04**

**Keywords:** 随机效应模型, 功能连接, 结构连接, 脑网络, 变异性

**Comment:** 

> **TL;DR:** 本研究引入新的随机效应模型，揭示了网络级和边缘级脑功能-结构连接相关性受不同效应影响，并首次提供了量化功能连接和结构连接变异来源的统计方法。

**AI_Comments:** 本文的创新之处在于引入了新的随机效应模型，能够首次系统地分解和量化功能连接和结构连接变异的不同来源。这对于理解脑网络功能与结构之间的复杂关系具有重要意义，尤其是在解释网络级和边缘级关联差异方面提供了新的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究主要关注网络级功能连接-结构连接(FC-SC)相关性，而边缘级相关性受关注较少。本研究发现两者得出不同的结论，因此需要引入新的模型来解释这些差异，并理解FC和SC变异的不同来源。

**Method:** 系统分析了网络级和边缘级FC-SC相关性，并引入了新的随机效应模型，将FC和SC的变异分解为受试者效应、边缘效应及其相互作用。

**Result:** 结果表明，网络级和边缘级FC-SC相关性受不同效应的影响，这些效应各自对FC和SC的总变异贡献不同。

**Conclusion:** 该建模框架首次提供了一种统计方法，用于分离和量化FC和SC变异的不同来源，并为功能性和结构性脑网络之间的关系提供了新见解。

> **ai_Abstract:** 本研究系统地分析了脑功能连接（FC）和结构连接（SC）的网络级和边缘级相关性，发现两者对脑功能-结构关联强度得出不同结论。为解释这些差异，研究引入了新的随机效应模型，将FC和SC变异分解为受试者效应、边缘效应及其相互作用。结果表明，不同效应影响网络级和边缘级FC-SC相关性，并对总变异有不同贡献。该模型首次提供了量化FC和SC变异来源的统计方法，为理解脑功能和结构网络关系提供了新视角。

> **摘要翻译:** 人脑是一个复杂的网络，区域间的连接通过功能连接（FC）和结构连接（SC）来表征。虽然之前的研究主要关注网络级FC-SC相关性（即预定义网络中所有边缘的FC和SC之间的相关性），但边缘级相关性（即每个边缘上跨受试者的FC和SC之间的相关性）受到的关注相对较少。在本研究中，我们系统地分析了网络级和边缘级FC-SC相关性，并证明它们对脑功能-结构关联强度得出不同的结论。为了解释这些差异，我们引入了新的随机效应模型，将FC和SC的变异分解为不同来源：受试者效应、边缘效应及其相互作用。我们的结果表明，网络级和边缘级FC-SC相关性受不同效应的影响，每个效应都对FC和SC的总变异做出不同贡献。该建模框架首次提供了一种统计方法，用于分离和定量评估FC和SC变异的不同来源，并为功能性脑网络和结构性脑网络之间的关系提供了新见解。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [271] [Poisson Inventory Models with Many Items: An Empirical Bayes Approach](https://arxiv.org/abs/2508.03074)
> *泊松库存模型与多项目：一种经验贝叶斯方法*

*Edward Anderson, Nam Ho-Nguyen, Peter Radchenko* | **Category: stat.ME, stat.AP** | **Updated: 2025-08-05**

**Keywords:** 泊松需求, 库存模型, 经验贝叶斯, 需求估计, 多项目

**Comment:** 

> **TL;DR:** 本文探讨了如何利用经验贝叶斯方法来优化具有泊松需求特征的多种商品的库存决策，强调了对不同需求水平进行后验估计的重要性，以及对特定商品组进行单独分析的益处。

**AI_Comments:** 本文的创新之处在于将经验贝叶斯方法应用于多项泊松需求库存管理，特别强调了对不同需求水平的细致估计以及对特定商品组进行单独分析的价值。其重要性在于为企业提供了一个实用且有效的框架，以应对常见的库存管理挑战，即使面对中等规模的库存也能发挥作用。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有泊松需求的众多商品的库存决策问题，即确定哪些商品应保持库存以及每种商品的库存量，同时需要根据历史数据估算单个商品的需求率。

**Method:** 采用经验贝叶斯方法。具体实践中，该方法强调对不同需求水平进行后验估计，而非仅估计泊松率。同时，论文还探讨了对某些特定区分的商品组进行单独分析的策略。

**Result:** 展示了如何在实践中应用经验贝叶斯方法；强调了对不同需求水平进行后验估计的重要性；证明了经验贝叶斯方法在处理具有泊松需求的项目时具有价值，即使项目数量相对较少（例如100个）也能有效；讨论了应用经验贝叶斯方法的最佳方式，并指出错误的应用方式会减少或消除潜在的好处。

**Conclusion:** 经验贝叶斯方法对于处理具有泊松需求的众多商品的库存决策是有效且有价值的，即使是相对较少数量的独立商品也能奏效，但前提是必须正确应用该方法。

> **ai_Abstract:** 本文探讨了如何利用经验贝叶斯方法来处理具有泊松需求的众多商品的库存决策问题。研究强调了根据历史数据对单个商品需求率进行后验估计的重要性，并讨论了对特定商品类别进行单独分析的益处。论文指出，该方法即使在商品种类相对较少的情况下也能有效，并提供了关于如何正确应用以最大化其效益的指导。

> **摘要翻译:** 我们考虑具有许多项目的库存决策，每个项目都有泊松需求。单个项目的需求率是根据过去的需求观察结果估算的。问题在于确定要库存的项目及其数量。我们的设置提供了一个应用经验贝贝叶斯方法的自然框架。我们展示了如何在实践中做到这一点，并证明了对不同需求水平进行后验估计的重要性，而不仅仅是估计泊松率。我们还探讨了何时对以某种方式区分的一组项目进行单独分析是有益的问题。一个例子是图书零售商的库存，他们可能会发现单独查看某些类型的书籍（例如传记）是有利的。经验贝叶斯方法在处理具有泊松需求的项目时很有价值，即使是相对较少数量的不同项目（例如100个）也能有效。我们讨论了在这种情况下应用经验贝叶斯方法的最佳方式，并表明错误地应用会减少或消除潜在的好处。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [322] [A New Approach to Partial Conjunction Analysis in Neuroimaging](https://arxiv.org/abs/2508.03675)
> *神经影像中部分合取分析的新方法*

*Monitirtha Dey, Anna Vesely, Thorsten Dickhaus* | **Category: stat.ME, stat.AP** | **Updated: 2025-08-05**

**Keywords:** 神经影像, 部分合取, CoFilter, 大脑激活, 统计推断

**Comment:** 

> **TL;DR:** 该论文提出了一种新的方法，即应用CoFilter方法，来解决神经影像学中部分合取分析的问题，旨在减少传统多重检验过程的保守性，并适用于高维数据，通过仿真研究和真实数据集验证了其性能。

**AI_Comments:** 本文的创新之处在于将CoFilter方法应用于神经影像学中的部分合取分析，有效地解决了传统多重检验方法在处理此类问题时存在的保守性。该方法对高维数据的适用性也是一个重要优势，有望在实际神经影像研究中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 在神经影像学中识别由特定认知任务激活的大脑区域至关重要，但当涉及多个认知任务或多个受试者时，问题变得更加复杂。本文将此问题视为部分合取（PC）假设检验问题，即检验特定大脑区域是否在至少γ个受试者中被激活。传统的多重检验程序在检验PC假设时表现出保守性。

**Method:** 本文提出将同步统计推断领域的最新进展，即CoFilter方法，应用于神经影像中的激活定位。该方法通过消除许多保守的PC p值来减轻传统多重检验程序在检验PC假设时表现出的保守性。它特别适用于多个高维研究，每个研究都检验大量零假设。论文还通过对神经影像数据和真实数据集进行广泛的模拟研究，比较了该方法与现有PC假设检验方法的性能。

**Result:** 所提出的CoFilter方法通过消除许多保守的PC p值，减轻了传统多重检验程序在检验PC假设时表现出的保守性。它特别适用于多个高维研究。通过广泛的模拟研究和真实数据集的比较，展示了其性能。

**Conclusion:** 本文提出的CoFilter方法在神经影像中的部分合取分析方面具有显著优势，能够有效解决传统方法的保守性问题，并适用于高维数据。

> **ai_Abstract:** 本论文提出了一种神经影像中部分合取（PC）分析的新方法，将识别由认知任务激活的脑区问题重新定义为PC假设检验。该方法应用了同步统计推断领域的最新进展——CoFilter方法，旨在发现至少在γ个受试者中激活的脑区。其主要优势在于减轻了传统多重检验过程的保守性，并通过消除保守的PC p值来提高效率，同时特别适用于多个高维研究。论文通过广泛的模拟研究和真实数据集与现有方法进行比较，验证了其有效性。

> **摘要翻译:** 识别通过特定认知任务激活的大脑区域问题在神经影像学中至关重要。如果涉及多个认知任务或多个受试者，这个问题会变得更加复杂。在本文中，我们将此问题视为部分合取（PC）假设检验问题，即我们正在检验特定大脑区域是否在至少γ（对于某些预先固定的γ）个受试者中被激活。我们提出将同步统计推断文献中的最新进展应用于神经影像中的激活定位。我们将最近提出的CoFilter方法应用于神经影像数据，以发现至少在γ个受试者中激活的大脑区域。我们的提议具有两个显著优势。首先，它通过消除许多保守的PC p值，减轻了传统多重检验程序在检验PC假设时表现出的保守性。其次，它特别适用于多个高维研究，每个研究都检验大量零假设。我们还通过对神经影像数据和真实数据集进行广泛的模拟研究，比较了我们的提议与现有PC假设检验方法的性能。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [389] [Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments](https://arxiv.org/abs/2505.12796)
> *非平稳环境下基于对称偏差的贝叶斯与逆贝叶斯推断的自适应推断*

*Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Yoshihiro Nakajima, Yukio-Pegio Gunji, Ung-il Chung* | **Category: stat.ME, cs.MA** | **Updated: 2025-08-05**

**Keywords:** 贝叶斯推断, 逆贝叶斯推断, 自适应推断, 非平稳环境, 临界状态

**Comment:** 

> **TL;DR:** 本研究提出了一种结合对称偏差的贝叶斯与逆贝叶斯推断（BIB）框架，通过动态调节学习率解决传统贝叶斯推断在非平稳环境中的适应性-准确性权衡问题，并发现其在临界状态下运行，展现出计算效率和临界动力学的共存，以及尺度无关行为。

**AI_Comments:** 该论文创新性地提出了贝叶斯与逆贝叶斯（BIB）推断框架，通过引入对称偏差和动态学习率调节机制，有效解决了传统贝叶斯推断在非平稳环境下的适应性-准确性权衡问题。其关键创新在于发现BIB系统在临界状态下运行，这不仅提高了计算效率，也展现了类似自然系统的尺度无关动力学行为，为自适应系统设计提供了新的理论视角和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 传统贝叶斯推断在非平稳环境中存在局限性，即在适应突变环境变化和在稳定时期保持准确性之间存在根本性的权衡。本研究旨在解决这一适应性-准确性权衡问题。

**Method:** 本研究提出了一种新颖的贝叶斯与逆贝叶斯（BIB）推断框架，该框架将对称偏差纳入贝叶斯更新过程，以同时执行常规和逆贝叶斯更新。该模型在涉及从具有随机时变均值的高斯分布中提取观测值的序贯估计任务中进行了评估。通过逆贝叶斯更新动态调制学习率，增强了自适应灵活性。

**Result:** BIB模型在环境转换期间表现出学习率的自发爆发，暂时进入高敏感度状态，从而促进了快速适应。这种爆发-弛豫动态平衡了适应性和准确性。雪崩分析和去趋势波动分析表明，BIB系统可能在临界状态附近运行，这是标准贝叶斯推断中未观察到的特性。

**Conclusion:** BIB模型独特地实现了计算效率和临界动力学的共存，解决了适应性-准确性权衡问题，同时保持了尺度无关行为。这些发现为自然系统中的尺度无关动力学提供了新的计算视角，并为非平稳环境中自适应推断系统的设计提供了有价值的见解。

> **ai_Abstract:** 本研究引入了一种新型的贝叶斯与逆贝叶斯（BIB）推断框架，旨在解决传统贝叶斯推断在非平稳环境中适应性与准确性的权衡问题。BIB框架通过引入对称偏差并动态调节学习率，实现了对环境变化的快速适应。实验结果表明，BIB模型在环境转换时能自发爆发学习率，进入高敏感度状态，从而实现快速适应，并平衡了适应性和准确性。此外，分析发现BIB系统可能在临界状态下运行，展现出计算效率、临界动力学和尺度无关行为的独特共存，为自适应推断系统的设计提供了新思路。

> **摘要翻译:** 本研究提出了一种新颖的推断框架，称为贝叶斯与逆贝叶斯（BIB）推断，该框架将对称偏差纳入贝叶斯更新过程，以同时执行常规和逆贝叶斯更新。该模型在涉及从具有随机时变均值的高斯分布中提取观测值的序贯估计任务中进行了评估。传统贝叶斯推断受到适应环境突变和在稳定时期保持准确性之间根本性权衡的限制。BIB框架通过逆贝叶斯更新动态调制学习率来解决这一限制，从而增强了自适应灵活性。值得注意的是，BIB模型在环境转换期间表现出学习率的自发爆发，暂时进入高敏感度状态，从而促进了快速适应。这种爆发-弛豫动态是平衡适应性和准确性的一种机制。此外，雪崩分析和去趋势波动分析表明，BIB系统可能在临界状态附近运行——这是标准贝叶斯推断中未观察到的特性。这表明BIB模型独特地实现了计算效率和临界动力学的共存，解决了适应性-准确性权衡问题，同时保持了尺度无关行为。这些发现为自然系统中的尺度无关动力学提供了新的计算视角，并为非平稳环境中自适应推断系统的设计提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [399] [A Hybrid Mixture of $t$-Factor Analyzers for Clustering High-dimensional Data](https://arxiv.org/abs/2504.21120)
> *用于高维数据聚类的t因子分析器的混合模型*

*Kazeem Kareem, Fan Dai* | **Category: stat.ME, astro-ph.HE, stat.AP, stat.CO, stat.ML, 62H05, 62H12, 62H20, 62H25, 62H30, 62P35, G.3; I.2; I.5; I.6; J.2** | **Updated: 2025-08-04**

**Keywords:** 混合t因子分析器, 高维数据, 聚类, 计算效率, 伽马射线暴

**Comment:** 

> **TL;DR:** 本文提出了一种结合轮廓似然法和EM框架的混合t因子分析器方法，解决了传统方法在高维数据聚类中的计算效率问题，并保持了精度和对异常值的鲁棒性。

**AI_Comments:** 本文的创新点在于提出了将轮廓似然法与EM框架相结合，以解决高维数据下t因子分析器混合模型估计的计算效率问题。这对于处理大规模复杂数据集具有重要意义，尤其是在保留聚类精度和对异常值鲁棒性的前提下提升效率，使其在实际应用中更具竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 传统t因子分析器（MtFA）的估计方法在高维设置中面临计算挑战，特别是在处理大型协方差矩阵的特征分解以及EM算法的迭代性质时，会导致可伸缩性问题。

**Method:** 本文提出了一种计算方案，将轮廓似然法整合到EM框架中，以有效地获取模型参数估计。

**Result:** 通过模拟，证明了所提方法相比现有方法具有卓越的计算效率，同时保持了聚类精度和对异常值的弹性。该方法应用于伽马射线暴的聚类，证实了文献中关于伽马射线暴具有异质子群的几个主张，并提供了对估计组的特征描述。

**Conclusion:** 所提出的混合t因子分析器方法在处理高维数据聚类时具有更高的计算效率和良好的聚类性能，并且成功应用于实际数据，支持了关于伽马射线暴异质性的现有观点。

> **ai_Abstract:** 本文提出了一种新颖的混合t因子分析器（MtFA）方法，旨在解决传统MtFA在高维数据聚类中面临的计算效率和可伸缩性问题。该方法将轮廓似然法融入期望最大化（EM）框架中，以提高参数估计效率。实验结果表明，与现有方法相比，该方法在保持聚类精度和对异常值鲁棒性的同时，显著提升了计算效率。此外，该方法成功应用于伽马射线暴的聚类分析，证实了其具有异质子群的观点。

> **摘要翻译:** 本文开发了一种新颖的混合方法，用于估计t因子分析器（MtFA）的混合模型，该方法采用多元t分布和因子模型对分组数据进行聚类和表征。传统的MtFA估计方法面临计算挑战，特别是在高维设置中，大型协方差矩阵的特征分解和期望最大化（EM）算法的迭代性质导致可伸缩性问题。我们提出了一种计算方案，将轮廓似然法整合到EM框架中，以有效地获取模型参数估计。通过模拟，证明了我们方法的有效性，展示了其相对于现有方法的卓越计算效率，同时保持了聚类精度和对异常值的弹性。我们的方法应用于伽马射线暴的聚类，证实了文献中关于伽马射线暴具有异质子群的几个主张，并提供了对估计组的特征描述。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [297] [Data-Driven Persuasion](https://arxiv.org/abs/2507.03203)
> *数据驱动的贝叶斯说服*

*Maxwell Rosenthal* | **Category: econ.TH, cs.GT** | **Updated: 2025-08-05**

**Keywords:** 贝叶斯说服, 数据驱动, 先验不确定性, 鲁棒优化, 信息设计

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的贝叶斯说服方法，其中发送者在不了解接收者先验分布的情况下，通过观察历史行为数据来推断可能的先验分布，并寻求最大化最坏情况收益的信号。研究发现双状态多行动问题存在鞍点，而双行动多状态问题不存在。

**AI_Comments:** 这篇论文的创新点在于将数据驱动的方法引入到贝叶斯说服领域，解决了发送者在先验分布未知情况下的决策问题。它通过观察历史数据来推断可能的先验分布，并采用最坏情况优化（鲁棒优化）的思路，为信息设计提供了新的视角。这种方法在实际应用中具有重要意义，尤其是在发送者难以获取完整先验信息时。论文的贡献在于理论上证明了特定问题（双状态多行动）存在鞍点解，并对另一类问题（双行动多状态）进行了鲁棒性分析，展示了复杂性差异。

<details>
  <summary>Details</summary>

**Motivation:** 在传统的贝叶斯说服模型中，发送者通常假设已知状态的先验分布。然而，在实际应用中，发送者可能无法完全了解接收者的先验信息。本文的动机在于开发一种数据驱动的方法，使发送者即使在不知道接收者先验分布的情况下，也能通过观察历史数据来推断合理的先验分布，并在此不确定性下优化其说服策略，以最大化最坏情况收益。

**Method:** 本文开发了一种数据驱动的贝叶斯说服方法。模型设定为：接收者私下了解状态的先验分布；发送者了解接收者的偏好但不了解状态变量的分布；发送者的收益取决于接收者的行动而非状态。发送者在与接收者互动前，观察到一群与接收者偏好相同的决策者对未知且可能异构信号产生的消息的最佳响应行动分布数据。发送者将任何能解释这些数据的先验视为合理，并寻求一个能最大化其在所有此类分布集合中最坏情况收益的信号。研究方法包括分析双状态多行动问题和双行动多状态问题。

**Result:** 研究结果表明，双状态多行动问题存在一个鞍点，并且在这种情况下，论文识别出了对抗性先验和最优信号。然而，双行动多状态问题则不存在鞍点。在后者的情况下，论文描述了鲁棒最优的布莱克威尔实验集合。

**Conclusion:** 本文证明了在数据驱动的贝叶斯说服框架下，双状态多行动问题存在一个鞍点解，并能识别出最优策略，这为发送者在先验信息不确定时提供了一种稳健的策略。然而，双行动多行动问题则更为复杂，没有简单的鞍点解，但论文仍能刻画出鲁棒最优的实验集合，为理解此类问题提供了理论基础。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动的贝叶斯说服方法，解决了发送者在不了解接收者先验分布情况下的说服问题。通过观察历史行动数据，发送者推断出可行的先验分布集合，并旨在最大化其在此集合中最坏情况下的收益。研究发现，在双状态多行动问题中存在一个鞍点，并能识别出相应的对抗性先验和最优信号。然而，在双行动多状态问题中则不存在鞍点，但论文仍能刻画出鲁棒最优的布莱克威尔实验集合。

> **摘要翻译:** 本文提出了一种数据驱动的贝叶斯说服方法。接收者私下了解世界状态的先验分布，发送者了解接收者的偏好但不了解状态变量的分布，发送者的收益取决于接收者的行动而非状态。在与接收者互动之前，发送者观察到一群与接收者偏好相同的决策者对未知且可能异构信号生成的消息做出最佳响应的行动分布数据。发送者将任何能解释这些数据的先验视为合理，并寻求一个能最大化其在所有此类分布集合中最坏情况收益的信号。我们积极地表明，双状态多行动问题存在一个鞍点，而消极地表明，双行动多状态问题不存在。在前一种情况下，我们识别了对抗性先验和最优信号。在后一种情况下，我们刻画了鲁棒最优的布莱克威尔实验集合。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [310] [Investigation on deep learning-based galaxy image translation models](https://arxiv.org/abs/2508.03291)
> *基于深度学习的星系图像翻译模型研究*

*Hengxin Ruan, Qiufan Lin, Shupei Chen, Yang Wang, Wei Zhang* | **Category: astro-ph.IM, astro-ph.GA, cs.CV** | **Updated: 2025-08-05**

**Keywords:** 星系图像翻译, 深度学习, 高阶物理信息, 红移, 生成模型

**Comment:** Accepted at A&A; 18+6 pages; 12+6 figures

> **TL;DR:** 本研究探讨了基于深度学习的星系图像翻译模型在保留高阶物理信息（如光谱红移）方面的有效性，发现现有模型在保留这些信息方面存在局限性，尽管它们在像素和形态级别表现良好。

**AI_Comments:** 这项研究揭示了当前深度学习图像翻译模型在处理天文学中复杂高阶物理信息（如红移）时的关键局限性。它超越了传统的像素级和形态级评估，强调了模型在科学应用中保留深层物理意义的挑战。这一发现对于指导未来模型开发至关重要，促使研究人员思考如何设计能够更好地编码和传输科学信息的模型，而不仅仅是视觉上的相似性。其创新之处在于对高阶物理信息保存的关注，以及对多对多映射性质导致不确定性的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习生成模型在星系图像翻译中取得了进展，但大多数研究主要关注像素级和形态级统计信息，缺乏对复杂高阶星系物理信息（如光谱红移）保存的讨论，而这对于依赖高保真图像翻译的研究至关重要。

**Method:** 研究调查了生成模型在保留高阶物理信息（以光谱红移表示）以及像素级和形态级信息方面的有效性。使用了SDSS和CFHTLS星系图像，并测试了四种代表性模型：Swin Transformer、SRGAN、胶囊网络和扩散模型。

**Result:** 研究发现这些模型在保留红移信息方面表现出不同程度的不足，即使星系的整体结构和形态级统计数据可以大致重现。特别是，星系的跨波段峰值通量包含有意义的红移信息，但在图像翻译中存在显著的不确定性，这可能主要归因于多对多映射的性质。

**Conclusion:** 尽管翻译后的图像可能不完美，但它们仍可能包含大量信息，并有望用于对图像保真度要求不高的下游应用。这项工作可以促进关于复杂物理信息如何在星系图像上体现的进一步研究，并为开发用于科学用途的图像翻译模型提供启示。

> **ai_Abstract:** 本研究旨在评估基于深度学习的星系图像翻译模型在保留高阶物理信息（如光谱红移）方面的能力，这对于高保真图像翻译至关重要。通过测试Swin Transformer、SRGAN、胶囊网络和扩散模型，并使用SDSS和CFHTLS星系图像，研究发现这些模型在保留红移信息方面存在局限性，即使它们能大致重现像素级和形态级特征。研究指出，跨波段峰值通量中包含的红移信息在翻译过程中存在不确定性，这可能与多对多映射的性质有关。然而，研究也提出，即使是不完美的翻译图像仍可能对某些下游应用有价值，并强调了未来在理解复杂物理信息如何在图像中体现以及开发更适用于科学用途的模型方面的研究方向。

> **摘要翻译:** 星系图像翻译是星系物理学和宇宙学中的一个重要应用。随着基于深度学习的生成模型的发展，图像翻译已被用于图像生成、数据质量增强、信息提取，并推广到解混叠和异常检测等其他任务。然而，大多数图像翻译的努力主要集中在星系图像的像素级和形态级统计上。对于复杂高阶星系物理信息（这对于依赖高保真图像翻译的研究更具挑战性但至关重要）的保存缺乏讨论。因此，我们研究了生成模型在保留高阶物理信息（以光谱红移表示）以及像素级和形态级信息方面的有效性。我们使用SDSS和CFHTLS星系图像测试了四种代表性模型，即Swin Transformer、SRGAN、胶囊网络和扩散模型。我们发现这些模型在保留红移信息方面表现出不同程度的不足，即使星系的整体结构和形态级统计数据可以大致重现。特别是，星系的跨波段峰值通量被发现包含有意义的红移信息，但在图像翻译中它们受到显著不确定性的影响，这可能主要归因于多对多映射的性质。尽管如此，不完美的翻译图像仍可能包含大量信息，因此对于对图像保真度要求不高的下游应用仍有前景。我们的工作可以促进关于复杂物理信息如何在星系图像上体现的进一步研究，并为开发用于科学用途的图像翻译模型提供启示。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

### [551] [A Multi-Scale Attention-Enhanced Architecture for Gravity Wave Localization in Satellite Imagery](https://arxiv.org/abs/2508.02704)
> *一种用于卫星图像重力波定位的多尺度注意力增强架构*

*Seraj Al Mahmud Mostafa, Jianwu Wang* | **Category: astro-ph.IM, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 重力波定位, 卫星图像, 多尺度注意力, YOLOv5, 目标检测

**Comment:** 

> **TL;DR:** 本文提出YOLO-DCAT，一个基于YOLOv5的改进模型，通过多尺度空洞卷积和简化空间通道注意力机制，显著提高了卫星图像中重力波的定位精度。

**AI_Comments:** 该论文的创新点在于将多尺度空洞卷积和简化注意力机制集成到YOLOv5框架中，以专门解决卫星图像中重力波的复杂多变特性。这种结合有效提升了在具有挑战性背景下目标检测的鲁棒性和准确性，对气候科学的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 卫星图像中重力波的检测面临巨大挑战，因为它们尺度、形状和模式变化大，且易受云、城市灯光和仪器噪声等干扰。传统检测方法难以捕捉这些多样且细微的特征。

**Method:** 本文引入了YOLO-DCAT，它是YOLOv5的增强版本，专门用于改善重力波定位。YOLO-DCAT结合了多空洞残差卷积（MDRC）来捕获多尺度特征，以及简化空间和通道注意力（SSCA）机制来关注最相关的区域和特征，以提高检测精度并抑制背景噪声。

**Result:** 实验结果显示，改进后的模型优于现有SOTA方法，平均精度（mAP）提高了14%以上，交并比（IoU）提高了约17%，显著提升了在复杂卫星图像中重力波的定位精度。

**Conclusion:** 本文提出的YOLO-DCAT模型有效解决了卫星图像中重力波定位的挑战，通过其多尺度特征捕获和注意力增强机制，显著提高了定位精度，为更精确的气候研究和建模做出了贡献。

> **ai_Abstract:** 本文针对卫星图像中重力波定位的挑战，提出了一种名为YOLO-DCAT的新模型。该模型是YOLOv5的增强版，通过引入多空洞残差卷积（MDRC）捕获多尺度特征，并结合简化空间和通道注意力（SSCA）机制来增强关键特征并抑制噪声。实验证明，YOLO-DCAT在重力波定位方面显著优于现有技术，mAP和IoU分别提升了14%和17%以上，为气候研究提供了更精确的工具。

> **摘要翻译:** 卫星图像由于其高目标变异性和较低的空间分辨率而面临独特的挑战，特别是对于检测大气重力波，其在尺度、形状和模式范围上表现出显著的变异性，使得准确的定位极具挑战性。这种变异性进一步被诸如云和城市灯光等主要的非目标物体以及仪器噪声所加剧，所有这些都在单个图像通道中，而传统的检测方法难以捕捉重力波在不同条件下的多样且通常细微的特征。为了解决这些问题，我们引入了YOLO-DCAT，它结合了多空洞残差卷积（MDRC）和简化空间和通道注意力（SSCA），是YOLOv5的增强版本，专门设计用于通过有效处理重力波复杂和可变的特性来改善其定位。MDRC通过具有不同空洞率的并行空洞卷积捕获多尺度特征，而SSCA则关注最相关的空间区域和通道特征，以提高检测精度并抑制背景噪声的干扰。在我们的实验中，改进后的模型优于现有最先进的替代方案，平均精度（mAP）提高了14%以上，交并比（IoU）提高了约17%，证明在具有挑战性的卫星图像中重力波的定位精度显著提高，并有助于更精确的气候研究和建模。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [340] [Backbone colouring of chordal graphs](https://arxiv.org/abs/2508.02980)
> *弦图的骨干着色*

*Júlio Araújo, Nicolas Nisse, Lucas Picasarri-Arrieta* | **Category: math.CO, cs.DM** | **Updated: 2025-08-05**

**Keywords:** 骨干着色, 弦图, 色数, 区间图, 图着色

**Comment:** 

> **TL;DR:** 本文研究了弦图的2-骨干着色问题，得到了在不同条件下，2-骨干色数与图的色数之间的界限，并给出了一个反例。

**AI_Comments:** 这篇论文对图着色理论中的一个重要开放问题进行了深入研究。它不仅在特定条件下验证了现有猜想的正确性，还通过构造反例揭示了猜想的局限性。此外，文章在更广泛的图类和骨干图结构下，给出了新的、更紧密的界限，这对于理解骨干着色问题及其在不同图族上的行为具有重要意义。其创新之处在于结合了多种图论技术来分析骨干着色数。

<details>
  <summary>Details</summary>

**Motivation:** Broersma等人在其论文中提出了一个问题：对于任意弦图$G$和其任意生成森林$H$，是否${m BBC}_2(G,H)\leq \chi(G)+O(1)$。

**Method:** 本文通过分析不同类型的图$G$和生成子图$H$的性质来研究2-骨干着色问题。具体方法包括：证明在特定条件下（H是二部图且G是每个顶点属于至多两个最大团的区间图）原始猜想成立；通过构造反例族证明猜想不适用于作为骨干的二部图；证明了当$H$具有有界最大平均度时（特别是森林），${m BBC}_2(G,H)$的界限；以及证明了当$H$不含$C_4$时，${m BBC}_2(G,H)$的另一个界限。

**Result:** 1. 当$H$是二部图且$G$是每个顶点属于至多两个最大团的区间图时，${\rm BBC}_2(G,H)\leq \chi(G)+O(1)$成立。
2. 存在一族弦图$G$及其生成二部子图$H$，使得${\rm BBC}_2(G,H)\geq \frac{5\chi(G)}{3}$，表明猜想不适用于所有二部骨干图。
3. 如果$G$是弦图且$H$具有有界最大平均度（特别是森林），则${\rm BBC}_2(G,H)\leq \chi(G)+O(\sqrt{\chi(G)})$。
4. 当$G$是弦图且$H$不含$C_4$时，${\rm BBC}_2(G,H)\leq \frac{3}{2}\chi(G)+O(1)$。

**Conclusion:** 本文部分回答了Broersma等人提出的关于弦图2-骨干着色的问题，在特定条件下证明了原始猜想成立，并通过反例表明其不普遍适用。同时，在骨干图$H$具有有界最大平均度或不含$C_4$的条件下，给出了${\rm BBC}_2(G,H)$与$\chi(G)$之间新的界限。

> **ai_Abstract:** 本文研究了弦图$G$的2-骨干着色问题，即在$G$的正常着色中，要求其生成子图$H$上的边两端顶点颜色差至少为2。针对Broersma等人提出的${\rm BBC}_2(G,H)\leq \chi(G)+O(1)$猜想，本文首先证明了当$H$为二部图且$G$为特定区间图时该猜想成立。随后，通过构造反例，证明了该猜想不适用于所有二部骨干图。此外，论文还为弦图$G$在骨干图$H$具有有界最大平均度（如森林）或不含$C_4$的条件下，给出了${\rm BBC}_2(G,H)$与$\chi(G)$之间更精确的界限。

> **摘要翻译:** 图$G=(V,E)$的一个正常$k$-着色是一个函数$c: V(G)\to \{1,\ldots,k\}$，使得对于每条边$uv\in E(G)$，都有$c(u)\neq c(v)$。图$G$的色数$\chi(G)$是使得存在一个$G$的正常$k$-着色的最小$k$值。给定$G$的一个生成子图$H$，$(G,H)$的一个$q$-骨干$k$-着色是$G$的一个正常$k$-着色$c$，使得对于$H$的每条边$uv\in E(H)$，都有$\lvert c(u)-c(v)\rvert \ge q$。$q$-骨干色数${\rm BBC}_q(G,H)$是使得存在一个$(G,H)$的$q$-骨干$k$-着色的最小$k$值。在他们的开创性论文中，Broersma等人~\[BFGW07\]提出问题：对于任意弦图$G$和$G$的任意生成森林$H$，是否${\rm BBC}_2(G,H)\leq \chi(G)+O(1)$。在这项工作中，我们首先表明，只要$H$是二部图且$G$是每个顶点属于至多两个最大团的区间图，这个结论就成立。然后我们通过展示一族弦图$G$及其生成二部子图$H$，满足${\rm BBC}_2(G,H)\geq \frac{5\chi(G)}{3}$，来表明这不适用于将二部图作为骨干的情况。接着，我们表明如果$G$是弦图且$H$具有有界最大平均度（特别是当$H$是森林时），那么${\rm BBC}_2(G,H)\leq \chi(G)+O(\sqrt{\chi(G)})$。我们最后表明，只要$G$是弦图且$H$不含$C_4$，则${\rm BBC}_2(G,H)\leq \frac{3}{2}\chi(G)+O(1)$成立。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [388] [Chromatic discrepancy of locally $s$-colourable graphs](https://arxiv.org/abs/2508.02985)
> *局部$s$可着色图的色差异*

*Timothée Corsini, Lucas Picasarri-Arrieta, Théo Pierron, François Pirot, Eileen Robinson* | **Category: math.CO, cs.DM** | **Updated: 2025-08-05**

**Keywords:** 色差异, 局部$s$可着色图, 无三角形图, 图着色, 色数

**Comment:** 

> **TL;DR:** 本文定义了图的色差异，证明了无三角形图的下界，并将其推广到局部$s$可着色图，提出了猜想并提供了部分证明。

**AI_Comments:** 本文引入了一个新颖的图参数——色差异，并通过为各种图类（包括无三角形图、局部$s$可着色图和无$C_{\ell+1}$图）建立下界做出了重要贡献。它回答了一个开放问题并提出了新的猜想，并对其进行了部分证明。关于图中球的色数的发现可能是一个有价值的独立结果。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在定义图的色差异（chromatic discrepancy），并为无三角形图的色差异提供一个下界，从而回答Aravind、Kalyanasundaram、Sandeep和Sivadasan提出的一个问题。此外，它还旨在将这一概念推广到局部$s$可着色图并探索其界限。

**Method:** 该研究通过数学证明来建立色差异的下界。它定义了“局部$s$可着色图”的概念，并应用图论原理。对于无$C_{\ell+1}$图，通过确定半径至多为$\ell/2$的球的色数的一个几乎紧密界限来得到结果。

**Result:** 1. 无三角形图$G$的色差异至少为$\chi(G)-2$，这是最佳结果，并回答了一个开放问题。2. 提出了一个猜想：每个局部$s$可着色图$G$都满足$\phi(G) \geq \chi(G)-s$。3. 当$\chi(G) \le 11s/6$时，证明了上述猜想。4. 作为一个部分结果，证明了每个局部$s$可着色图$G$都满足$\phi(G) \geq \chi(G) - s\ln \chi(G)$。5. 如果上述猜想成立，则对于每个整数$\ell\geq 2$，任何无$C_{\ell+1}$图$G$都满足$\phi(G) \geq \chi(G) - \ell$。6. 当$\ell \ge 3$且$G\neq K_\ell$时，猜想$\phi(G)\ge \chi(G) - \ell + 1$，并在特殊情况$\ell = 3$或$\chi(G) \le 5\ell/3$时证明了它。7. 进一步得到每个无$C_{\ell+1}$图$G$都满足$\phi(G) \geq \chi(G) - O_{\ell}(\ln \ln \chi(G))$。8. 通过确定$G$中半径至多$\ell/2$的球的色数的几乎紧密界限，获得了上述结果，该界限可能具有独立的兴趣。

**Conclusion:** 本研究建立了关于色差异的新界限和猜想，特别针对无三角形图、局部$s$可着色图和无$C_{\ell+1}$图，回答了开放问题并提供了部分证明。用于获得这些结果的方法，即确定球的色数界限，可能具有独立的理论价值。

> **ai_Abstract:** 本文引入了图的色差异$\phi(G)$的概念，即诱导子图$H$所跨越的颜色数与其色数之间的最大差异的最小值。研究证明了无三角形图的$\phi(G) \geq \chi(G)-2$，解决了现有问题。工作推广到局部$s$可着色图，提出了$\phi(G) \geq \chi(G)-s$的猜想，并在特定条件下（$\chi(G) \le 11s/6$）或作为部分结果（$\phi(G) \geq \chi(G) - s\ln \chi(G)$）进行了证明。此外，论文还探讨了无$C_{\ell+1}$图的色差异，推导了其界限，并针对$\ell \ge 3$且$G\neq K_\ell$提出了更强的猜想并进行了部分证明。其中一项关键技术是确定图中球的色数界限。

> **摘要翻译:** 图$G$的色差异，记作$\phi(G)$，是在$G$的所有真着色$\sigma$中，诱导子图$H$所跨越的颜色数$|\sigma(V(H))|$与其色数$\chi(H)$之间最大差异的最小值。我们证明了无三角形图$G$的色差异至少为$\chi(G)-2$。这是最佳结果，并积极回答了Aravind、Kalyanasundaram、Sandeep和Sivadasan提出的一个问题。
更一般地，如果图$G$中任意顶点$v\in V(G)$的闭邻域都可以被正确地$s$着色，我们称图$G$是局部$s$可着色的；特别地，无三角形图是局部$2$可着色的。我们猜想每个局部$s$可着色图$G$都满足$\phi(G) \geq \chi(G)-s$，并表明这几乎是最佳结果。当$\chi(G) \le 11s/6$时，我们证明了这个猜想，并且作为一般情况的部分结果，我们证明了每个局部$s$可着色图$G$都满足$\phi(G) \geq \chi(G) - s\ln \chi(G)$。
如果这个猜想成立，它特别意味着，对于每个整数$\ell\geq 2$，任何不包含$C_{\ell+1}$（长度为$\ell+1$的循环）副本的图$G$都满足$\phi(G) \geq \chi(G) - \ell$。当$\ell \ge 3$且$G\neq K_\ell$时，我们猜想实际上有$\phi(G)\ge \chi(G) - \ell + 1$，并在特殊情况$\ell = 3$或$\chi(G) \le 5\ell/3$时证明了它。总的来说，我们进一步得到每个无$C_{\ell+1}$-自由图$G$都满足$\phi(G) \geq \chi(G) - O_{\ell}(\ln \ln \chi(G))$。我们通过确定$G$中半径至多$\ell/2$的球的色数的几乎紧密界限来做到这一点，这可能具有独立的兴趣。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [443] [On universal graphs for trees and treewidth $k$ graphs](https://arxiv.org/abs/2508.03335)
> *关于树和树宽 $k$ 图的通用图*

*Neel Kaul, David R. Wood* | **Category: math.CO, cs.DM** | **Updated: 2025-08-05**

**Keywords:** 通用图, 树, 树宽, 上界, 图论

**Comment:** 

> **TL;DR:** 本文纠正了关于包含所有n顶点树的通用图边数上界的错误，并给出了新的、更紧凑的上界O(n(log n)(log log n))，同时将其推广到树宽k的图。

**AI_Comments:** 本文的主要创新在于纠正了先前研究的错误，并提供了一个更精确且完全自包含的通用图边数上界证明。其重要性在于改进了图理论中关于通用图的已知界限，并将其推广到更一般的树宽k图，对图嵌入和图结构理论具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 指出Chung和Graham (1983) 在证明s(n)上界时的错误，并指出Chung, Graham和Pippenger (1976) 的证明缺少关键细节，旨在提供一个完整且改进的证明。

**Method:** 通过提供一个完全自包含的证明来改进现有关于通用图边数s(n)的上界，并将这些结果推广到树宽k的图，确定其最小边数s_k(n)的界限。

**Result:** 纠正了Chung和Graham (1983) 的错误。为s(n)提供了新的、改进的、完全自包含的上界：s(n) <= O(n(log n)(log log n))。将结果推广到树宽k的图，得到了s_k(n)的界限：Omega(k n log n) <= s_k(n) <= O(kn(log n)(log log n))。

**Conclusion:** 本文纠正了先前关于通用图边数上界的错误，并提供了更精确和完全自包含的证明，同时将这些结果成功推广到了树宽k的图。

> **ai_Abstract:** 本文研究了包含所有n顶点树作为子图的通用图的最小边数s(n)问题。作者指出了Chung和Graham (1983) 证明中的错误，并针对s(n)给出了一个改进的、完全自包含的上界O(n(log n)(log log n))，取代了先前不完整的O(n(log n)(log log n)^2)上界。此外，研究将这些结果推广到树宽为k的图，确定了包含所有n顶点、树宽为k的图的最小边数s_k(n)的上下界为Omega(k n log n)和O(kn(log n)(log log n))。

> **摘要翻译:** 令 $s(n)$ 为包含每个 $n$ 顶点树作为子图的图的最小边数。Chung 和 Graham [J. London Math. Soc. 1983] 声称证明了 $s(n)\leqslant O(n\log n)$。我们指出了他们证明中的一个错误。此前已知的最佳上界是 Chung, Graham 和 Pippenger [Proc. Hungarian Coll. on Combinatorics 1976] 提出的 $s(n)\leqslant O(n(\log n)(\log\log n)^{2})$，其证明缺少许多关键细节。我们给出了一个完全自包含的证明，得到了新的改进上界 $s(n)\leqslant O(n(\log n)(\log\log n))$。已知的最佳下界是 $s(n)\geqslant \Omega(n\log n)$。
我们将这些结果推广到树宽为 $k$ 的图。对于整数 $k\geqslant 1$，令 $s_k(n)$ 为包含每个 $n$ 顶点、树宽为 $k$ 的图作为子图的图的最小边数。因此 $s(n)=s_1(n)$。我们证明了 $\Omega(k n\log n) \leqslant s_k(n) \leqslant O(kn(\log n)(\log\log n))$。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [561] [Three Tone Networks and a Tessellation](https://arxiv.org/abs/2505.08752)
> *三个音调网络和一个镶嵌*

*Jeffrey R. Boland, Lane P. Hughston* | **Category: math.CO, eess.AS, math.AG** | **Updated: 2025-08-05**

**Keywords:** 音网, 二分图, 射影几何, 音乐理论, 五声音阶音乐

**Comment:** 36 pages, 16 figures

> **TL;DR:** 本文探讨了欧拉音网与二分图的表示，并将其特征与射影平面中的点线配置联系起来，还展示了如何为五声音阶音乐和十二音音乐构建类似的音调网络。

**AI_Comments:** 该论文通过将音乐理论中的音网概念与图论及射影几何相结合，提供了一种新颖的视角来理解音调关系。其创新之处在于利用几何配置直观地解释音网特性，并将其推广到不同的音乐体系，为音乐分析提供了一个强大的工具。其局限性可能在于抽象性较高，对于非专业读者理解门槛较高。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过将其与实射影平面中的几何配置联系起来，深入理解欧拉音网的有趣特征（如六循环和八循环），这些特征对于理解十九世纪的声部进行至关重要。此外，论文还旨在展示如何将这种音调网络的概念推广到其他音乐系统，如五声音阶音乐和十二音音乐。

**Method:** 作者将欧拉音网表示为一个二分图（Levi图），该图唯一确定了实射影平面中十二个点和十二条线的特殊配置。通过这种几何表示，音网的特性可以直接从配置中解读。随后，作者展示了如何基于类似原理为五声音阶音乐和十二音音乐构建相应的音调网络。

**Result:** 研究表明，欧拉音网的关键特征（如四个主六循环和三个主八循环）可以直接从其在实射影平面中的几何配置中读出。此外，论文成功展示了如何为五声音阶音乐和十二音音乐构建出类似的音调网络。

**Conclusion:** 本文通过将欧拉音网的理论与图论及射影几何相结合，提供了一种统一且直观的方式来理解和分析音调关系。其主要结论是，这种几何表示不仅能够揭示音网的内在属性，还能成功地将音调网络的概念扩展到五声音阶音乐和十二音音乐等不同音乐体系中。

> **ai_Abstract:** 本文研究了欧拉音网的结构，将其表示为一个二分图（Levi图），该图唯一确定了实射影平面中一种特殊的点线配置。作者指出，音网的关键特征，如六循环和八循环，可以直接从这种几何配置中解读。此外，文章还展示了如何为五声音阶音乐和十二音音乐构建类似的音调网络，从而扩展了音网理论的应用范围。

> **摘要翻译:** 欧拉音网，它将三个小和弦与每个大和弦关联，并将三个大和弦与每个小和弦关联，可以用一个二分图表示，其中有十二个白色顶点表示大和弦，十二个黑色顶点表示小和弦。这个所谓的Levi图唯一确定了实射影平面中十二个点和十二条线的显著配置的组合几何，其性质是每条线上有三个点，每个点通过三条线。音网的有趣特征，例如四个主六循环和三个主八循环的存在，对于理解十九世纪的声部进行至关重要，可以直接作为配置的属性读出。我们展示了如何为五声音阶音乐和十二音音乐构建类似的音调网络。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [405] [All-optical temporal integration mediated by subwavelength heat antennas](https://arxiv.org/abs/2505.04405)
> *通过亚波长热天线介导的全光时间积分*

*Yi Zhang, Nikolaos Farmakidis, Ioannis Roumpos, Miltiadis Moralis-Pegios, Apostolos Tsakyridis, June Sang Lee, Bowei Dong, Yuhan He, Samarth Aggarwal, Nikolaos Pleros, Harish Bhaskaran* | **Category: physics.optics, cs.AI, physics.app-ph** | **Updated: 2025-08-05**

**Keywords:** 全光计算, 神经形态计算, 时间积分, 热光调制, 纳米天线

**Comment:** 

> **TL;DR:** 该研究展示了一个基于时间复用的全光神经形态计算系统，能够处理超过25万个元素的高维向量，并通过热时间动力学实现超快信号的时间积分和非线性激活功能，为大规模光子计算迈出重要一步。

**AI_Comments:** 该论文的创新之处在于利用独特的亚波长热天线和热时间动力学，在全光学域内实现了高维向量处理、超快信号积分和非线性激活功能，这对于克服传统光学计算在AI应用中的维度限制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有集成光学计算系统在处理现代人工智能所需的向量维度方面存在局限性。

**Method:** 该系统是基于时间复用的全光神经形态计算系统，利用钛纳米天线在驻波光学场中进行光驱动热光调制，并通过系统的热时间动力学实现超快信号的时间积分和可编程非线性激活功能。

**Result:** 成功演示了一个能够处理超过250,000个元素输入向量的全光神经形态计算系统，并实现了对超快（50GHz）信号的同时时间积分和可编程非线性激活功能。

**Conclusion:** 该统一框架是迈向满足人工智能工作负载维度要求的大规模光子计算的重要一步。

> **ai_Abstract:** 本文展示了一种创新的全光神经形态计算系统，通过时间复用技术和亚波长热天线介导的热光调制，实现了对超过25万个元素的高维向量的处理。该系统能够同时对50GHz的超快信号进行时间积分，并应用可编程的非线性激活函数，所有操作均在光学域内完成，为满足人工智能需求的大规模光子计算奠定了基础。

> **摘要翻译:** 光学计算系统为标量运算提供了无与伦比的处理速度。然而，集成实现一直受限于低维张量运算，未能达到现代人工智能所需的向量维度。我们展示了一种基于时间复用的全光神经形态计算系统，能够在统一框架内处理超过250,000个元素的输入向量。该平台利用驻波光学场中光驱动的热光调制，其中钛纳米天线作为波长选择性吸收器。反直觉的是，系统的热时间动力学使得超快（50GHz）信号的同时时间积分和可编程非线性激活功能的应用完全在光学域内实现。这个统一的框架构成了向满足人工智能工作负载维度要求的大规模光子计算的飞跃。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [411] [Polynomial complexity sampling from multimodal distributions using Sequential Monte Carlo](https://arxiv.org/abs/2508.02763)
> *使用序贯蒙特卡洛从多模态分布进行多项式复杂度采样*

*Ruiyu Han, Gautam Iyer, Dejan Slepčev* | **Category: math.ST, cs.NA, math.NA, math.PR, stat.CO, stat.TH, Primary: 60J22, Secondary: 65C05, 65C40, 60J05, 60K35** | **Updated: 2025-08-04**

**Keywords:** 序贯蒙特卡洛, 多模态分布, 吉布斯测度, 朗之万扩散, 复杂度分析

**Comment:** 58 pages, 5 figures

> **TL;DR:** 该研究提出了一种序贯蒙特卡洛算法，用于在低温下从具有非凸能量函数的吉布斯测度中采样，并证明了其蒙特卡洛估计器的收敛性，时间复杂度大致与逆温度的四次方和允许误差的平方成比例。

**AI_Comments:** 这项工作在处理多模态分布的采样问题上具有重要意义，特别是在低温和非凸能量函数的情况下。其创新之处在于通过局部混合策略显著缩短了朗之万扩散所需的运行时间，并对算法的收敛时间和复杂度给出了明确的多项式界限，这对于理解和应用此类算法至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 研究目标是在低温下从具有非凸能量函数的吉布斯测度中进行采样，这是一个具有挑战性的问题。

**Method:** 本研究使用了一种序贯蒙特卡洛算法，结合了几何退火调度和在每个温度水平下的朗之万扩散。朗之万扩散仅需运行足以确保能量谷内局部混合的时间，这远短于全局混合所需的时间。

**Result:** 主要结果表明，蒙特卡洛估计器的收敛时间复杂度大致与逆温度的四次方和允许误差的平方成比例。研究还在一个说明性模型场景中研究了该算法，可以给出更明确的估计。

**Conclusion:** 该研究展示了一种序贯蒙特卡洛算法在低温下从具有非凸能量函数的吉布斯测度中采样的有效性，并量化了其多项式时间复杂度。

> **ai_Abstract:** 本文研究了一种用于在低温下从具有非凸能量函数的吉布斯测度中采样的序贯蒙特卡洛算法。该算法结合了几何退火调度和朗之万扩散，其中朗之万扩散仅需局部混合时间。研究的主要贡献是证明了蒙特卡洛估计器的收敛性，其时间复杂度大致与逆温度的四次方和允许误差的平方成比例。

> **摘要翻译:** 我们研究了一种序贯蒙特卡洛算法，用于在低温下从具有非凸能量函数的吉布斯测度中进行采样。我们使用了实用且流行的几何退火调度，并在每个温度水平下使用朗之万扩散。朗之万扩散仅需要运行足够长的时间以确保能量谷内的局部混合，这比全局混合所需的时间短得多。我们的主要结果表明，蒙特卡洛估计器的收敛时间复杂度近似地与逆温度的四次方和允许误差的平方成比例。我们还在一个说明性模型场景中研究了该算法，在该场景中可以给出更明确的估计。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [467] [A nonstandard finite difference scheme for an SEIQR epidemiological PDE mode](https://arxiv.org/abs/2508.02928)
> *SEIQR流行病学偏微分方程模型的非标准有限差分方案*

*Achraf Zinihi, Matthias Ehrhardt, Moulay Rchid Sidi Ammi* | **Category: q-bio.QM, cs.NA, math.DS, math.NA, 92D30, 65M06, 35K57, 37N30** | **Updated: 2025-08-04**

**Keywords:** 非标准有限差分, SEIQR模型, 流行病学, 偏微分方程, 结构保持

**Comment:** 

> **TL;DR:** 本文为SEIQR流行病学PDE模型提出了一种非标准有限差分（NSFD）方案，该方案能保持连续模型的关键定性特征。

**AI_Comments:** 该论文的创新之处在于引入了非标准有限差分方法来解决SEIQR流行病学PDE模型，特别是其能够保留连续模型的重要定性特征，这对于确保数值模拟结果的生物学合理性至关重要。这克服了传统有限差分方法可能引入的数值伪影问题，对于传染病建模的准确性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准有限差分方法常常损害连续模型的关键定性特征（如正性、有界性和稳定性），因此需要一种能保持这些特征的离散化方法。

**Method:** 本文为反应-扩散SEIQR流行病学模型引入了一种非标准有限差分（NSFD）方法，该模型被表述为半线性抛物型偏微分方程（PDEs）系统。研究分析了模型的适定性，构建了保结构NSFD方案，并研究了其收敛性和局部截断误差。

**Result:** 数值模拟验证了理论发现，并证明了该方案在保持生物学上一致的动力学方面的有效性。

**Conclusion:** 该非标准有限差分方案能够有效保持SEIQR流行病学PDE模型的生物学一致动力学特征。

> **ai_Abstract:** 本文提出了一种针对反应-扩散SEIQR流行病学PDE模型的非标准有限差分（NSFD）方案。该方案旨在克服标准有限差分方法在保持模型定性特征（如正性、有界性、稳定性）方面的不足。研究分析了模型的适定性，构建了保结构NSFD方案，并验证了其收敛性和局部截断误差。数值模拟结果证实了该方案在保持生物学一致动力学方面的有效性。

> **摘要翻译:** 本文为反应-扩散SEIQR流行病学模型引入了一种非标准有限差分（NSFD）方法，该模型捕捉了传染病传播的时空动态。该模型被表述为半线性抛物型偏微分方程（PDEs）系统，通过引入空间扩散来解释人口移动和空间异质性，从而扩展了经典的仓室模型。所提出的NSFD离散化旨在保持连续模型的基本定性特征，例如正性、有界性和稳定性，而这些特征常常被标准有限差分方法所损害。我们严格分析了模型的适定性，为PDE系统构建了一个保结构的NSFD方案，并研究了其收敛性和局部截断误差。数值模拟验证了理论发现，并证明了该方案在保持生物学上一致的动力学方面的有效性。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [659] [Timing is everything: How subtle timing changes in MRI echo planar imaging can significantly alter mechanical vibrations and sound level](https://arxiv.org/abs/2508.03220)
> *时机就是一切：MRI回波平面成像中细微的时间变化如何显著改变机械振动和声级*

*Amir Seginer, Alexander Bratch, Shahar Goren, Edna Furman-Haran, Noam Harel, Essa Yacoub, Rita Schmidt* | **Category: physics.med-ph, eess.IV** | **Updated: 2025-08-05**

**Keywords:** MRI, EPI, 声学噪音, 机械振动, 时序控制

**Comment:** 

> **TL;DR:** MRI扫描中的时间变化会影响声学特性，并且可以调整以降低噪音和伪影。

**AI_Comments:** 这项研究强调了在MRI成像中，时序控制对于声学和图像质量的重要性。通过对EPI扫描时序的精细调整，可以有效解决超高场MRI带来的噪音和伪影问题，具有重要的临床和技术意义。模型的可验证性和实验结果的显著性是本研究的亮点。

<details>
  <summary>Details</summary>

**Motivation:** MRI扫描产生的声学噪音是一个重要问题，尤其是在超高场系统中，它可能导致图像质量下降、硬件损坏。本研究旨在探索通过改变MRI扫描中的时间参数来控制声学噪音。

**Method:** 提出了一种新的模型来表征给定EPI扫描的声谱，该模型考虑了电流周期之间的相对时间。通过在临床7T和10.5T人类扫描仪上进行实验来验证该模型。

**Result:** 研究表明，即使是细微的时间变化也会显著改变声级。在接近机械共振时，声能变化可达47倍，在其他区域可达5倍。此外，增加单位时间内的采集次数有时反而会降低最小声能。还发现伪影对扫描的声学特性有很强的依赖性，并且通过调整导航器的内部校正采集时间可以改善伪影。

**Conclusion:** 通过调整MRI扫描中的时序参数，可以有效控制声学噪音和伪影，这为降低MRI噪音和提高图像质量提供了新的途径。

> **ai_Abstract:** 本研究提出了一个新模型，用于表征MRI回波平面成像（EPI）产生的声学特性。研究发现，EPI扫描中电流切换的细微时间变化会显著影响声级，甚至可以实现高达47倍的声能变化。通过调整扫描参数，不仅可以降低噪音，还能改善图像伪影。

> **摘要翻译:** 现代MRI依赖于成熟的回波平面成像（EPI）方法进行快速采集。EPI是神经科学中扩散和功能MRI以及临床身体成像的许多动态应用的主力。其速度源于梯度线圈中电流的快速切换，梯度线圈负责空间编码。这些在强静磁场中的快速变化会感应出产生机械振动的洛伦兹力，从而导致响亮、特征性的MRI噪音。这种声学噪音已经是标准临床扫描仪的一个重要问题，需要听力保护，并可能导致图像退化甚至硬件损耗。在超高场系统中，由于洛伦兹力更强，问题更加严重。在本研究中，我们引入了一个新的模型，该模型可以表征给定EPI扫描的声谱。该谱是由多个相同的交变电流周期之间的干涉产生的，使得它们之间的相对时间成为一个关键因素。我们表明，即使是细微的时间变化也会显著改变声级。在临床7T和研究性10.5T人类扫描仪上进行的具有高空间分辨率或高时间分辨率的扫描证实了该模型及其预测的声谱。在接近机械共振时，声能变化高达47倍，在其他区域高达5倍。有趣的是，在某些条件下，单位时间内采集次数加倍实际上将最小声能降低了两倍。同样重要的是，伪影伪影对扫描的声学特性表现出很强的依赖性，并且还证明了内部校正采集（导航器）的细微时间延迟的好处。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [691] [Optimal control driven functional electrical stimulation: A scoping review](https://arxiv.org/abs/2508.02899)
> *最优控制驱动的功能性电刺激：一项范围审查*

*Kevin Co, Mickaël Begon, François Bailly, Florent Moissenet* | **Category: physics.med-ph, cs.SY, eess.SY** | **Updated: 2025-08-04**

**Keywords:** 功能性电刺激, 最优控制, 肌肉疲劳, 康复, 运动控制

**Comment:** 37 pages, 7 figures, 3 tables

> **TL;DR:** 本综述探讨了最优控制在功能性电刺激 (FES) 中的应用，旨在解决 FES 引起的肌肉疲劳和运动精度问题。研究发现，最优控制 FES 可实现精确运动并减少疲劳，但临床应用受模型不确定性、模型识别协议不便以及定制硬件可用性等因素的阻碍。未来的研究方向包括开发更优的 FES 模型、进行大规模纵向试验以及改进开放科学实践。

**AI_Comments:** 该研究对功能性电刺激 (FES) 领域一个重要且日益受到关注的方面进行了全面的概述。通过结合最优控制理论，研究人员正在努力克服 FES 的关键限制，如肌肉疲劳和运动精度。本综述清晰地阐述了该领域的研究现状、挑战和未来方向。然而，研究中提到的大部分研究集中在计算机模拟和健康的年轻男性，这可能限制了其结果向更广泛人群和临床环境的推广性。此外，对“最优控制”的具体算法或模型类型没有进行深入探讨，这使得评估其在不同应用场景下的有效性变得困难。尽管存在这些局限性，但该研究为未来在康复领域利用 FES 和最优控制技术提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 功能性电刺激 (FES) 在神经损伤康复中很有前景，但其应用受到早期肌肉疲劳的限制，阻碍了恢复进程。最优控制作为一种减少过度刺激和提高运动精度的潜在解决方案，正受到越来越多的关注。

**Method:** 遵循 PRISMA 指南，在五个数据库（Medline、Embase、CINAHL Complete、Web of Science 和 ProQuest Dissertations & Theses Citation Index）中检索了截至 2024 年 2 月的文献，关键词组合为“FES”、“optimal control”或“fatigue”。纳入标准包括将最优控制与 FES 结合用于健康个体和神经肌肉疾病患者的研究。

**Result:** 纳入的 44 项研究中，有一半是计算机模拟研究，一半是体内研究，共涉及 87 名参与者，其中大部分是健康的年轻男性。研究调查了十二种不同的运动任务，主要集中在单关节下肢运动。这些研究主要使用了简单的 FES 模型，通过调节脉冲宽度或强度来跟踪关节角度。

**Conclusion:** 最优控制驱动的 FES 能够实现精确的运动并减少疲劳。然而，临床应用因缺乏关于建模的共识、不便的模型识别协议以及有限的验证而受到阻碍。其他障碍还包括开放科学实践不足、计算性能报告以及可定制商用硬件的可用性。需要进行更多的比较 FES 模型研究和大规模队列纵向试验来提高技术就绪水平，从而促进临床应用并改善患者预后。

> **ai_Abstract:** 本综述对最优控制驱动的功能性电刺激 (FES) 进行了范围审查，旨在解决 FES 引起的肌肉疲劳和运动精度问题。审查发现，虽然最优控制 FES 在实现精确运动和减少疲劳方面显示出潜力，但其临床应用面临模型不确定性、模型识别协议不便以及硬件限制等挑战。未来的研究应侧重于改进 FES 模型、进行大规模临床试验以及加强开放科学实践，以推动该技术的临床转化和患者预后。

> **摘要翻译:** 引言：神经损伤后的康复可以通过功能性电刺激 (FES) 来支持。然而，FES 受早期肌肉疲劳的限制，减缓了恢复进程。利用最优控制来减少过度刺激和提高运动精度的应用正受到越来越多的关注。本综述旨在绘制当前文献的现状，同时阐明最佳实践，识别持续存在的挑战，并为未来研究指明方向。方法：遵循 PRISMA 指南，截至 2024 年 2 月，使用“FES”、“optimal control”或“fatigue”的组合关键词在五个数据库（Medline、Embase、CINAHL Complete、Web of Science 和 ProQuest Dissertations & Theses Citation Index）中进行了检索。纳入标准包括将最优控制与 FES 结合用于健康个体和神经肌肉疾病患者的研究。结果：在纳入的 44 项研究中，有一半是计算机模拟研究，一半是体内研究，共涉及 87 名参与者，其中大部分是健康的年轻男性。研究调查了十二种不同的运动任务，主要集中在单关节下肢运动。这些研究主要使用了简单的 FES 模型，通过调节脉冲宽度或强度来跟踪关节角度。结论：最优控制驱动的 FES 能够实现精确的运动并减少疲劳。然而，临床应用因缺乏关于建模的共识、不便的模型识别协议以及有限的验证而受到阻碍。其他障碍还包括开放科学实践不足、计算性能报告以及可定制商用硬件的可用性。需要进行更多的比较 FES 模型研究和大规模队列纵向试验来提高技术就绪水平。这些进展将有助于临床应用并改善患者预后。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-biope'></a>
## q-bio.PE 

### [682] [Fitness and Overfitness: Implicit Regularization in Evolutionary Dynamics](https://arxiv.org/abs/2508.03187)
> *适宜性与过度拟合：进化动力学中的隐式正则化*

*Hagai Rappeport, Mor Nitzan* | **Category: q-bio.PE, cs.NE** | **Updated: 2025-08-05**

**Keywords:** 进化动力学, 学习理论, 生物复杂性, 隐式正则化, 过度适宜

**Comment:** 

> **TL;DR:** 该研究提出一个数学框架，通过比对进化动力学和学习理论，研究进化生物体复杂性与环境复杂性之间的关系。研究表明，进化中的隐式正则化机制能够防止“过度拟合”，并促使生物体复杂性与环境复杂性相匹配，避免“过度适宜”或“适应不足”。频繁变化的环境会降低所选的复杂性。最终，这种在过度适应瞬时环境特征与对环境挑战的灵活性不足之间的平衡，驱动了最优复杂性的出现。

**AI_Comments:** 这项研究巧妙地将进化动力学和学习理论联系起来，提供了一个强大的新框架来理解生物复杂性。通过引入“过度适宜”和“适应不足”的概念，它为进化过程中的复杂性演变提供了新的见解。该研究的局限性可能在于其数学框架的简化程度以及在现实生物系统中的直接应用。然而，它为未来的研究开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 进化理论认为适应性会驱动生物复杂性增加，但其规律更为微妙。学习理论在理解复杂性方面有更成熟的研究。本研究旨在利用进化动力学与学习理论之间的数学同构性，研究进化生物体复杂性与环境复杂性之间的关系。

**Method:** 提出一个数学框架，利用进化动力学（如复制子方程）和学习理论（如序列贝叶斯学习）之间的数学同构性。将进化类型比作竞争性假设，将环境适应性比作证据的似然性。

**Result:** 进化中的隐式正则化机制能够防止“过度拟合”，并促使生物体复杂性与环境复杂性相匹配，避免“过度适宜”（overfitness）或“适应不足”（underfitness）。频繁变化的环境会降低所选的复杂性。最优复杂性的出现是由过度适应瞬时环境特征与对环境挑战的灵活性不足之间的平衡所驱动的。

**Conclusion:** 该框架为生物复杂性提供了新的思考方式，并暗示了在不同环境中生物复杂性增加或减少的潜在原因。它表明，生物体复杂性与环境结构相匹配是进化的关键。

> **ai_Abstract:** 本研究提出了一种将进化动力学与学习理论联系起来的数学框架，以研究生物体复杂性与环境复杂性之间的关系。该框架利用了复制子方程与序列贝叶斯学习之间的数学同构性，表明进化中的隐式正则化机制可以防止过度拟合，使生物体复杂性与其所处环境的复杂性相匹配。研究发现，生物体过于复杂或过于简单都会导致“过度适宜”或“适应不足”。此外，频繁变化的环境会降低进化选择的复杂性。最终，最优复杂性的出现是适应瞬时环境特征与应对环境挑战的灵活性之间平衡的结果。该研究为理解生物复杂性的起源和演变提供了新的视角。

> **摘要翻译:** 进化思想中的一个普遍假设是适应性会驱动生物复杂性的增加。然而，控制复杂性进化的规则似乎更为微妙。进化与学习密切相关，而学习理论对复杂性的理解更为深入，并有关于适合给定学习任务的最优复杂性的既定结果。在本工作中，我们建议使用一个数学框架来研究进化生物体复杂性与环境复杂性之间的关系，该框架利用了进化动力学与学习理论之间的数学同构性。即，在复制子方程与序列贝叶斯学习之间，进化类型对应于竞争性假设，给定环境中的适应性对应于观察到的证据的可能性。在贝叶斯学习中，隐式正则化可以防止过度拟合，并驱动推断出与学习挑战相匹配的复杂性的假设。我们展示了这些结果如何自然地延伸到进化环境中，在那里它们被解释为进化生物体复杂性以匹配环境复杂性，而过于复杂或过于简单的生物体分别会遭受“过度适宜”和“适应不足”。其他方面，特别是进化而非学习的方面，揭示了额外的趋势。一个这样的趋势是频繁变化的环境会降低选择的复杂性，这一结果可能对进化和学习都有影响。总而言之，我们的结果表明，过度适应瞬时环境特征与对环境挑战的灵活性不足之间的平衡，驱动了最优复杂性的出现，反映了环境结构。该框架为思考生物复杂性提供了新的途径，并暗示了在不同环境中生物复杂性增加或减少的新潜在原因。

</details>

[⬆️ 返回分类顶部](#q-biope) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstat-mech'></a>
## cond-mat.stat-mech 

### [700] [Stochastic thermodynamics of computation](https://arxiv.org/abs/1905.05669)
> *计算的随机热力学*

*David H. Wolpert* | **Category: cond-mat.stat-mech, cs.CC** | **Updated: 2025-08-05**

**Keywords:** 随机热力学, 计算, 熵成本, 非平衡统计物理学, 计算机科学理论

**Comment:** 113 pages, no figures. arXiv admin note: text overlap with
  arXiv:1901.00386

> **TL;DR:** 本篇综述文章探讨了计算的随机热力学，重点关注计算的能量消耗。它回顾了信息论、计算机科学理论和随机热力学的基础知识，并总结了在计算熵成本方面的最新研究进展，包括位擦除、无环电路、逻辑可逆电路、信息棘轮和图灵机等。这些研究不仅揭示了设计低热力学成本计算机的新工程挑战，而且在基础层面结合了计算机科学和随机热力学，从而推动了两个领域的发展。

**AI_Comments:** 该综述文章在信息论、计算机科学理论和随机热力学等领域之间架起了一座桥梁，为理解计算的能量成本提供了一个统一的框架。文章强调了非平衡统计物理学在解决这些问题中的重要性，并指出了未来在设计高效计算系统方面的潜在应用价值。然而，文章主要侧重于理论回顾和总结，对于具体的工程实现和实验验证方面的讨论相对较少。

<details>
  <summary>Details</summary>

**Motivation:** 计算机的能量消耗是其主要资源需求之一，这促使物理学界对此进行了长期研究。早期的研究主要关注计算所需的功，但随着非平衡统计物理学的突破，现在可以更深入地研究统计物理学与计算之间的关系，超越了位擦除的功耗问题。

**Method:** 本文回顾了信息论、计算机科学理论和随机热力学的基础知识，并总结了在计算熵成本方面的最新研究进展，涵盖了位擦除、无环电路、逻辑可逆电路、信息棘轮和图灵机等多种计算形式。

**Result:** 研究揭示了设计具有最小热力学成本的计算机所面临的新工程挑战，并使得计算机科学理论与随机热力学能够在基础层面进行结合，从而促进了两个领域的发展。

**Conclusion:** 本综述强调了计算的随机热力学在理解和设计低功耗计算机方面的重要性，并指出了结合计算机科学和随机热力学在基础理论层面上的潜力。

> **ai_Abstract:** 本文综述了计算的随机热力学，重点关注计算的能量消耗问题。文章回顾了信息论、计算机科学理论和随机热力学的基础知识，并总结了在位擦除、无环电路、逻辑可逆电路、信息棘轮和图灵机等计算形式的熵成本方面的最新研究进展。这些研究不仅为设计低能耗计算机带来了新的工程挑战，也促进了计算机科学理论与随机热力学在基础层面的融合与发展。

> **摘要翻译:** 计算机的能量消耗是计算机的主要资源需求之一，从生物细胞、人脑到高性能（工程）计算机，概莫能外。运行这些计算机所需的成本长期以来一直是物理学研究的重点，可以追溯到 Landauer 早期的工作。计算机最显著的特点之一是它们本质上是不平衡系统。然而，早期的研究是在非平衡统计物理学尚处于起步阶段时进行的，因此其理论基础是建立在平衡统计物理学之上的。自那时以来，非平衡统计物理学取得了重大突破，使我们能够研究统计物理学与计算之间关系的诸多方面，其研究范围远远超出了擦除一个比特所需的功耗问题。本文回顾了近期在“计算的随机热力学”方面的一些研究工作。在回顾了信息论、计算机科学理论和随机热力学等相关知识的基础上，总结了在计算熵成本方面取得的成果，这些成果涵盖了从位擦除、无环电路、逻辑可逆电路、信息棘轮到图灵机等广泛的计算。这些结果揭示了设计具有最小热力学成本的计算机方面新的、具有挑战性的工程问题。它们也使我们能够开始在基础层面结合计算机科学理论和随机热力学，从而扩展了两者。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phep'></a>
## astro-ph.EP 

### [716] [A Genetic Algorithm Framework for Optimizing Three-Impulse Orbital Transfers with Poliastro Simulation](https://arxiv.org/abs/2508.03466)
> *用于使用Poliastro仿真的三脉冲轨道转移的遗传算法框架*

*Phuc Hao Do, Tran Duc Le* | **Category: astro-ph.EP, astro-ph.IM, cs.NE** | **Updated: 2025-08-05**

**Keywords:** 遗传算法, 轨道转移, Poliastro, 燃料优化, 天体动力学

**Comment:** 12 pages, 3 figures, and 2 tables

> **TL;DR:** 本研究提出了一种结合遗传算法和Poliastro库的计算框架，用于优化三脉冲轨道转移，并在LEO到GEO和高能转移到遥远轨道的场景中进行了验证。结果表明，该框架能够准确找到霍曼转移轨迹，并发现比霍曼转移更优的双椭圆转移轨迹，但后者会显著增加任务时间。

**AI_Comments:** 该研究有效地结合了遗传算法和Poliastro库，为解决三脉冲轨道转移优化问题提供了一个实用的框架。研究结果清晰地展示了该方法在不同场景下的准确性和适应性，特别是在发现比传统方法更优的轨迹方面。然而，对于高能转移场景中任务时间的显著延长，这是一个重要的权衡，需要进一步的研究来探索在实际任务中平衡燃料效率和任务时间的方法。此外，该框架的通用性可以进一步通过在更多样化的轨道场景和考虑其他约束条件（如推力限制、行星引力干扰等）进行测试来加以证明。

<details>
  <summary>Details</summary>

**Motivation:** 传统的轨道转移方法（如霍曼转移和双椭圆转移）在特定情况下有效，但缺乏解决更通用优化问题的灵活性。本研究旨在开发一种能够自主发现燃料最优、三脉冲转移轨迹的计算框架。

**Method:** 本研究将遗传算法（GA）与Poliastro轨道力学库相结合，构建了一个计算框架，用于自主寻找共面圆轨道之间燃料最优的三脉冲转移轨迹。

**Result:** 在LEO到GEO的转移中，遗传算法精确地收敛到经典的霍曼转移，$\Delta V$为3853.96 m/s。对于高能转移，遗传算法发现的双椭圆转移轨迹比霍曼转移节省了213.47 m/s的$\Delta V$，但任务时间从约1天延长到140多年。

**Conclusion:** 本研究证明了一个易于使用的强大工具链，可用于快速原型设计最优轨迹。该研究展示了如何将进化算法与开源库相结合，为解决复杂天体动力学问题提供了一种稳健的方法，并量化了关键的设计权衡。

> **ai_Abstract:** 本研究提出了一种结合遗传算法（GA）和Poliastro库的计算框架，用于优化三脉冲轨道转移。该框架在LEO到GEO的低能转移和高能转移到遥远轨道的场景中得到了验证。结果表明，该框架能够精确找到霍曼转移轨迹，并在高能转移场景中发现比霍曼转移更优的双椭圆转移轨迹，尽管后者会显著增加任务时间。该研究强调了进化算法与开源库结合在解决天体动力学问题和权衡设计因素方面的潜力。

> **摘要翻译:** 轨道机动规划是任务设计的一个关键方面，旨在最大限度地减少推进剂消耗，而推进剂消耗与总速度变化（$\Delta V$）直接相关。虽然像霍曼转移和双椭圆转移这样的解析解为特定情况提供了最优策略，但它们缺乏解决更通用优化问题的灵活性。本文提出了一个计算框架，将遗传算法（GA）与Poliastro轨道力学库相结合，以自主发现共面圆轨道之间燃料最优的三脉冲转移轨迹。我们在两种不同的场景中验证了这个框架：一种是从低地球轨道（LEO）到地球静止轨道（GEO）的低能转移，另一种是到半径是LEO半径20倍的遥远轨道的高能转移。我们的结果证明了该框架的出色适应性。对于LEO到GEO的转移，GA精确地收敛到经典的霍曼转移，实现了相同的$\Delta V$（3853.96 m/s），验证了该方法的准确性。相反，对于高能转移，GA发现了一个优于霍曼转移的双椭圆轨迹，与霍曼转移相比，$\Delta V$节省了213.47 m/s。然而，这种燃料效率需要权衡，将任务持续时间从大约1天延长到140多年。这项工作证明了一个易于访问且强大的工具链，用于快速原型设计最优轨迹，展示了如何将进化算法与开源库相结合，为解决复杂的天体动力学问题提供了一种稳健的方法，并量化了其关键的设计权衡。

</details>

[⬆️ 返回分类顶部](#astro-phep) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [793] [Decomposition of Symmetrical Classes of Central Configurations](https://arxiv.org/abs/2508.02918)
> *对称阶数中心构型分解*

*Marcelo P. Santos, Leon D. da Silva* | **Category: math.DS, cs.SC, math.RT** | **Updated: 2025-08-04**

**Keywords:** 中心构型,对称性,群表示论,对称性适应基,嵌套多面体

**Comment:** 

> **TL;DR:** 该研究利用群表示论中的一个定理来简化中心构型方程，并提出了一种对称性适应基方法。该方法已被应用于分析嵌套正四面体、正八面体和正立方体的中心构型，并对立方体情况进行了扩展。

**AI_Comments:** 该研究将群表示论应用于中心构型问题，提供了一种新颖的分析方法。对称性适应基方法的应用简化了复杂的方程，并且在实际应用中取得了具体成果，尤其是在立方体案例的扩展分析上。然而，该方法对于更广泛的对称群和更高维度的普适性有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 研究对称中心构型，简化中心构型方程，并提供更精细的分解。

**Method:** 利用群表示论定理，采用对称性适应基方法，结合有理参数化和多元多项式零点分离技术。

**Result:** 为嵌套正四面体、正八面体和正立方体提供了中心构型存在性和质量的完整描述，并扩展了立方体情况的分析。

**Conclusion:** 所提出的分解方法允许使用符号计算来研究表达式，总结了先前的讨论，并通过完成立方体情况的逆问题和正问题分析进行了扩展。

> **ai_Abstract:** 本研究提出了一种利用群表示论和对称性适应基方法来分解中心构型方程的新方法。该方法能够简化任意数量物体、对称群和维度的中心构型方程。研究人员将此方法应用于分析嵌套正四面体、正八面体和正立方体的中心构型，并给出了它们存在性和质量的完整描述，特别是在立方体情况下，对逆问题和正问题进行了扩展分析。

> **摘要翻译:** 我们研究当位置集是对称时的中心构型。我们利用有限群表示论中的一个定理来探索中心构型方程的对称性质。这种方法通过考虑任意数量的物体、对称群和维度来简化中心构型方程。我们讨论了如何使用这个定理来获得比以前更精细的方程分解。这里提出的分解使用了对称性适应基方法。作为应用，我们完整地描述了两个嵌套正四面体、两个嵌套正八面体和两个嵌套正立方体的中心构型的存在性和可能的质量。为此，我们采用了一些有理参数化和多元多项式零点分离的方法。所获得的分解允许使用符号计算来研究表达式。通过这种方式，我们总结了先前的讨论，并通过完成立方体情况的逆问题和正问题分析来扩展它们。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='q-finst'></a>
## q-fin.ST 

### [803] [CreditARF: A Framework for Corporate Credit Rating with Annual Report and Financial Feature Integration](https://arxiv.org/abs/2508.02738)
> *企业年报与财务特征集成公司信用评级框架：CreditARF*

*Yumeng Shi, Zhongliang Yang, DiYang Lu, Yisi Wang, Yiting Zhou, Linna Zhou* | **Category: q-fin.ST, cs.CE, cs.CL, cs.LG** | **Updated: 2025-08-02**

**Keywords:** 信用评级,年报,财务特征,FinBERT,CCRD

**Comment:** 

> **TL;DR:** 该研究提出了CreditARF框架，集成了财务数据和年报文本特征（利用FinBERT提取），以提高公司信用评级准确性，并发布了包含财务和文本数据的CCRD数据集，实验表明该方法能提升8-12%的预测准确率。

**AI_Comments:** 这项研究的创新之处在于将非结构化的年报文本数据与传统的财务数据相结合，以提高公司信用评级的准确性。使用FinBERT模型来提取文本特征是一个值得关注的方法。然而，该研究在模型的可解释性、对不同行业或地区公司的普适性以及处理更广泛的非结构化数据源（如新闻稿、分析师报告等）方面的潜力有待进一步探索。构建CCRD数据集为后续研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有信用评级模型主要依赖财务指标和深度学习，但忽略了公司年报等非结构化文本数据中的信息，未能充分挖掘文本数据的价值。

**Method:** 提出了一种名为CreditARF的信用评级框架，该框架整合了传统的财务数据和通过FinBERT模型从公司年报中提取的文本特征。同时，构建了一个包含财务数据和年报文本数据的综合性公司评级数据集（CCRD）。

**Result:** 实验结果表明，所提出的CreditARF框架将信用评级预测的准确性提高了8-12%，显著增强了公司信用评级的有效性和可靠性。

**Conclusion:** 通过整合财务数据和从年报中提取的非结构化文本特征，所提出的CreditARF框架能够显著提高公司信用评级的准确性、有效性和可靠性。

> **ai_Abstract:** 本研究提出了一种名为CreditARF的公司信用评级框架，通过集成传统财务数据和利用FinBERT技术从公司年报中提取的文本特征，旨在克服现有模型仅依赖财务指标而忽视非结构化文本信息的局限性。研究人员还构建了一个包含财务和文本数据的CCRD数据集。实验证明，该方法能有效提升信用评级预测的准确性8-12%，从而增强评级的有效性和可靠性。

> **摘要翻译:** 公司信用评级是市场经济中一项至关重要的中介服务，在维护经济秩序方面发挥着关键作用。现有的信用评级模型依赖于财务指标和深度学习。然而，它们常常忽略来自公司年报等非财务数据中的见解。为了解决这个问题，本文提出了一种公司信用评级框架，该框架将财务数据与使用FinBERT从年报中提取的特征相结合，旨在充分利用非结构化文本数据的潜在价值。此外，我们开发了一个大规模数据集，即综合公司评级数据集（CCRD），它结合了传统的财务数据和年报中的文本数据。实验结果表明，所提出的方法将评级预测的准确性提高了8-12%，显著提高了公司信用评级的有效性和可靠性。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [851] [CTBench: Cryptocurrency Time Series Generation Benchmark](https://arxiv.org/abs/2508.02758)
> *加密货币时间序列生成基准：CTBench*

*Yihao Ang, Qiang Wang, Qiang Huang, Yifan Bao, Xinyu Xi, Anthony K. H. Tung, Chen Jin, Zhiyong Huang* | **Category: q-fin.ST, cs.AI, cs.CE, cs.DB, cs.LG** | **Updated: 2025-08-03**

**Keywords:** 时间序列生成,加密货币,基准测试,预测效用,统计套利

**Comment:** 14 pages, 14 figures, and 3 tables

> **TL;DR:** CTBench是首个针对加密货币市场的综合时间序列生成（TSG）基准，旨在解决现有方法在处理加密货币特有的挑战（如高波动性和快速的模式转变）方面的不足。它包含一个包含452个代币的数据集，并使用13个指标评估TSG模型在预测准确性、排名保真度、交易表现、风险评估和计算效率等五个关键维度上的表现。CTBench引入了一个双任务评估框架，包括“预测效用”任务（衡量合成数据对预测的的时间和横截面模式的保留能力）和“统计套利”任务（评估重建序列是否支持交易的均值回归信号）。通过对八个模型在四种市场模式下的基准测试，CTBench揭示了统计保真度和实际盈利能力之间的权衡，并为在加密货币分析和策略开发中选择和部署TSG模型提供了模型排名分析和指导。

**AI_Comments:** 该研究填补了加密货币时间序列生成基准的空白，提出了一个全面的评估框架和数据集。其双任务评估（预测效用和统计套利）的设计非常有新意，能够同时考察合成数据的统计特性和实际交易应用价值。然而，抽象中并未详细说明“四个不同的市场模式”的具体定义，这可能影响结果的可复现性。此外，仅评估了八个模型，未来可以扩展到更多不同类型的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列生成（TSG）方法和基准在加密货币市场应用中存在不足，无法有效处理其24/7交易、极端波动性和快速模式转变等特点，并且通常缺乏针对金融应用（尤其是交易应用）的关键评估。因此，需要一个专门针对加密货币领域的TSG基准来解决这些问题。

**Method:** 引入CTBench，这是首个针对加密货币领域的综合TSG基准。CTBench包含一个包含452个代币的开源数据集，并使用涵盖预测准确性、排名保真度、交易表现、风险评估和计算效率这五个关键维度的13个指标来评估TSG模型。该基准采用了一个双任务评估框架：“预测效用”任务用于衡量合成数据在预测方面的模式保留能力，而“统计套利”任务用于评估重建序列在交易均值回归信号方面的支持能力。对八个代表性模型在四种不同市场模式下进行了基准测试。

**Result:** 通过对八个代表性模型在四种不同市场模式下的基准测试，CTBench揭示了统计保真度和实际盈利能力之间的权衡。研究结果为在加密货币分析和策略开发中选择和部署TSG模型提供了模型排名分析和可操作的指导。

**Conclusion:** CTBench是首个针对加密货币领域的综合TSG基准，通过其全面的数据集、多维度指标和创新的双任务评估框架，弥补了现有研究的不足。它不仅能够评估TSG模型在加密货币市场的表现，还能揭示统计保真度和实际交易盈利能力之间的权衡，为相关研究和应用提供了宝贵的指导。

> **ai_Abstract:** CTBench是一个新提出的、针对加密货币市场的时间序列生成（TSG）基准。它通过包含452个代币的数据集和一套全面的评估指标（涵盖预测、排名、交易、风险和效率），解决了现有TSG方法在加密货币领域应用的局限性。CTBench的创新之处在于其双任务评估框架，用于衡量合成数据在预测和交易方面的效用，并为在加密货币分析和策略开发中选择和部署TSG模型提供了指导。

> **摘要翻译:** 合成时间序列是量化金融中数据增强、压力测试和算法原型设计的关键工具。然而，在加密货币市场中，其特点是24/7交易、极端波动性和快速的模式转变，现有的时间序列生成（TSG）方法和基准常常表现不佳，损害了其实际效用。先前的大部分工作（1）针对的是非金融或传统金融领域，（2）狭隘地关注分类和预测，而忽略了加密货币特有的复杂性，并且（3）缺乏关键的金融评估，尤其是在交易应用方面。为了解决这些差距，我们引入了CTBench，这是第一个针对加密货币领域量身定制的综合TSG基准。CTBench策划了一个来自452个代币的开源数据集，并在涵盖预测准确性、排名保真度、交易表现、风险评估和计算效率这五个关键维度的13个指标上对TSG模型进行了评估。一项关键创新是双任务评估框架：（1）“预测效用”任务衡量合成数据在保留时间序列和跨序列模式以进行预测方面的能力，而（2）“统计套利”任务评估重建序列是否支持交易的均值回归信号。我们在四个不同的市场模式下对来自五个方法学家族的八个代表性模型进行了基准测试，揭示了统计保真度和实际盈利能力之间的权衡。值得注意的是，CTBench提供了模型排名分析以及在加密货币分析和策略开发中选择和部署TSG模型的可操作指导。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [945] [Kronos: A Foundation Model for the Language of Financial Markets](https://arxiv.org/abs/2508.02739)
> *金融市场语言的基础模型Kronos*

*Yu Shi, Zongliang Fu, Shuo Chen, Bohan Zhao, Wei Xu, Changshui Zhang, Jian Li* | **Category: q-fin.ST, cs.AI, cs.LG** | **Updated: 2025-08-02**

**Keywords:** 金融时间序列, 基础模型, K线建模, 预训练, Kronos

**Comment:** 

> **TL;DR:** Kronos是一个针对金融K线建模的统一、可扩展的预训练框架，通过专门的tokenizer将连续市场信息离散化为token序列，并在海量多市场数据上进行预训练，在零样本设置下在价格预测、波动率预测和合成数据生成等金融任务上表现优于现有模型。

**AI_Comments:** Kronos在金融时间序列分析领域取得了重要突破，通过其创新的tokenizer和大规模预训练方法，显著提升了多种下游任务的性能。模型的公开可用性也为相关研究和应用提供了宝贵资源。然而，模型在不同市场和不同时间范围内的泛化能力，以及其对不同类型金融数据（如新闻、财报等）的适应性仍有待进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列基础模型（TSFM）在金融K线数据上的应用受限且表现不佳，并且忽视了波动率预测和合成数据生成等下游任务。

**Method:** 提出Kronos，一个统一、可扩展的预训练框架，采用专门的tokenizer将连续市场信息离散化为token序列，并在海量多市场K线数据上进行自回归预训练。

**Result:** Kronos在价格预测、波动率预测和合成数据生成等任务上显著优于现有模型，在零样本设置下，价格预测的RankIC比领先的TSFM高93%，比非预训练基线高87%，波动率预测的MAE低9%，合成K线序列的生成保真度提高22%。

**Conclusion:** Kronos是一个强大且通用的基础模型，能够端到端地进行金融时间序列分析。

> **ai_Abstract:** Kronos是一个新提出的、针对金融K线建模的统一且可扩展的预训练框架。它使用一种特殊的tokenizer将连续的市场信息转化为token序列，并利用来自全球45个交易所的超过120亿条K线记录的海量多市场语料库进行预训练。Kronos在零样本设置下，在价格预测、波动率预测和合成数据生成等多种金融任务上均取得了显著优于现有模型（包括TSFM和非预训练模型）的性能。

> **摘要翻译:** 大型语言模型（LLMs）所例证的大规模预训练范式的成功，激发了时间序列基础模型（TSFMs）的发展。然而，它们在金融K线数据上的应用仍然有限，表现常常不如未经预训练的架构。此外，现有的TSFM经常忽略关键的下游任务，如波动率预测和合成数据生成。为了解决这些局限性，我们提出了Kronos，一个针对金融K线建模量身定制的统一、可扩展的预训练框架。Kronos引入了一个专门的tokenizer，将连续的市场信息离散化为token序列，同时保留了价格动态和交易活动模式。我们在海量的、来自45个全球交易所的超过120亿条K线记录的多市场语料库上，以自回归目标对Kronos进行预训练，使其能够学习细微的时间和跨资产表示。Kronos在各种金融任务的零样本设置中表现出色。在基准数据集上，Kronos在价格序列预测的RankIC方面比领先的TSFM提高了93%，比最佳的非预训练基线提高了87%。它在波动率预测方面的MAE也降低了9%，在合成K线序列生成方面的保真度提高了22%。这些结果确立了Kronos作为端到端金融时间序列分析的强大、多功能的基础模型。我们的预训练模型可在https://github.com/shiyu-coder/Kronos公开获取。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [957] [Benchmarking Classical and Quantum Models for DeFi Yield Prediction on Curve Finance](https://arxiv.org/abs/2508.02685)
> *去中心化金融收益预测在 Curve Finance 上的经典与量子模型基准测试*

*Chi-Sheng Chen, Aidan Hung-Wen Tsai* | **Category: q-fin.ST, cs.LG, q-fin.TR** | **Updated: 2025-07-22**

**Keywords:** DeFi, Curve Finance, 收益预测, XGBoost, 量子机器学习

**Comment:** 

> **TL;DR:** 在 Curve Finance 的 DeFi 收益预测任务中，XGBoost 和随机森林等经典模型优于深度学习和量子模型，在准确性和误差方面表现更佳。

**AI_Comments:** 这项研究通过对 DeFi 收益预测中的经典和量子模型进行基准测试，为实际应用提供了有价值的见解。研究结果强调了经典模型在准确性和效率方面的优势，并指出了量子模型在该特定领域仍面临挑战。研究方法具有可重现性，为未来研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 去中心化金融（DeFi）的兴起对准确的收益和绩效预测提出了日益增长的需求，以指导流动性分配策略。

**Method:** 对来自 28 个 Curve Finance 池的为期一年的历史数据，对 XGBoost、随机森林、LSTM、Transformer、量子神经网络（QNN）和具有量子特征映射的量子支持向量机（QSVM-QNN）这六种模型进行了基准测试，并使用测试 MAE、RMSE 和方向准确性评估了模型性能。

**Result:** 经典集成模型（特别是 XGBoost 和随机森林）在 Curve Finance 的 DeFi 收益预测任务中表现优于深度学习和量子模型。XGBoost 实现了最高的方向准确性（71.57%），测试 MAE 为 1.80；随机森林的测试 MAE 最低（1.77），准确性为 71.36%。量子模型表现不佳，方向准确性低于 50%，误差较高。

**Conclusion:** 对于 DeFi 时间序列数据，经典模型（如 XGBoost 和随机森林）比目前的量子模型更适合，后者在准确性和误差方面表现不佳。

> **ai_Abstract:** 本研究对用于 Curve Finance 的 DeFi 收益预测的六种经典和量子模型进行了基准测试。研究发现，XGBoost 和随机森林等经典模型在预测准确性和误差方面优于 LSTM、Transformer 和量子模型（QNN、QSVM-QNN）。XGBoost 取得了最高的方向准确性（71.57%），随机森林的 MAE 最低（1.77）。研究结果表明，在当前的 DeFi 时间序列数据应用中，经典方法比新兴的量子方法更具优势。

> **摘要翻译:** 去中心化金融（DeFi）的兴起，为指导流动性分配策略而对准确的收益和绩效预测产生了日益增长的需求。在本研究中，我们对六种模型——XGBoost、随机森林、LSTM、Transformer、量子神经网络（QNN）以及具有量子特征映射的量子支持向量机（QSVM-QNN）——在来自 28 个 Curve Finance 池的一年历史数据上进行了基准测试。我们评估了模型在测试 MAE、RMSE 和方向准确性方面的表现。我们的结果表明，经典的集成模型，特别是 XGBoost 和随机森林，在表现上持续优于深度学习和量子模型。XGBoost 实现了最高方向准确性（71.57%），测试 MAE 为 1.80，而随机森林的测试 MAE 最低（1.77），准确性为 71.36%。相比之下，量子模型表现不佳，方向准确性低于 50%，误差较高，这凸显了当前在实际 DeFi 时间序列数据中应用量子机器学习的局限性。这项工作为 DeFi 应用提供了可重现的基准和实用的模型适用性见解，强调了该领域经典方法相对于新兴量子方法的稳健性。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [964] [Evaluating Transfer Learning Methods on Real-World Data Streams: A Case Study in Financial Fraud Detection](https://arxiv.org/abs/2508.02702)
> *评估迁移学习方法在真实世界数据流上的表现：金融欺诈检测案例研究*

*Ricardo Ribeiro Pereira, Jacopo Bono, Hugo Ferreira, Pedro Ribeiro, Carlos Soares, Pedro Bizarro* | **Category: q-fin.ST, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 迁移学习, 数据流, 金融欺诈检测, 动态评估, 域偏移

**Comment:** 16 pages, 7 figures, submitted to ECML PKDD 2025

> **TL;DR:** 该研究提出了一个数据处理框架，用于在数据可用性随时间变化的情况下，更真实地评估和比较迁移学习（TL）算法在金融欺诈检测等现实应用中的表现，并以银行卡支付和银行账户欺诈数据集为例进行了演示。

**AI_Comments:** 该研究提出的数据处理框架对于评估迁移学习方法在真实世界动态环境中的表现具有重要意义。通过模拟现实世界中常见的数据可用性变化和域偏移，该框架能够提供比传统静态评估方法更具参考价值的评估结果。然而，框架在模拟不同类型域偏移的复杂性和计算效率方面可能还有进一步优化的空间。此外，虽然案例研究展示了其有效性，但将该框架推广应用于更多不同领域的动态数据流评估将更有助于验证其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的迁移学习（TL）方法通常基于固定的数据可用性假设进行设计和评估，这与许多现实应用中数据和标签可用性随时间动态变化的特点不符，导致评估结果与实际应用表现存在差距。

**Method:** 提出一个数据处理框架，该框架能够模拟随时间变化的可用数据场景，通过重采样创建多个域，并引入现实的域转换（如协变量和概念偏移）来模拟不同时间依赖性的变化，从而为TL算法提供更真实的实验环境。

**Result:** 该框架能够模拟大量实验变体，从而更深入地了解算法在动态环境下的潜在行为。研究通过一个专有的真实世界银行卡支付数据集和一个公开的银行账户欺诈数据集进行了案例研究，证明了该框架的有效性。

**Conclusion:** 该框架提供了一种在真实数据可用性场景下随时间评估TL方法的方法，有助于理解模型和算法的行为，从而在将模型部署到真实世界的动态环境中时做出更明智的决策。

> **ai_Abstract:** 本研究针对迁移学习在现实世界数据流中的应用评估问题，提出了一个创新的数据处理框架。该框架旨在克服传统迁移学习评估方法在静态数据假设下的局限性，通过模拟数据可用性的动态变化和引入真实的域偏移，为迁移学习算法在如金融欺诈检测等动态场景下的表现提供更贴合实际的评估。研究通过具体案例展示了该框架的有效性，为优化模型部署提供了重要依据。

> **摘要翻译:** 当目标域的可用数据有限时，可以使用迁移学习（TL）方法在相关的数据丰富域上开发模型，然后再将其部署到目标域。然而，这些TL方法通常是基于对可用目标数据的标记和未标记数量的特定、静态假设来设计的。这与许多现实世界的应用形成对比，在这些应用中，数据和相应标签的可用性会随时间变化。由于TL方法的评估通常也在相同的数据可用性静态假设下进行，这会导致对其在现实世界环境中的表现产生不切实际的期望。为了支持对TL算法和模型进行更现实的评估和比较，我们提出了一个数据处理框架，该框架（1）模拟随时间变化的可用数据场景，（2）通过对给定数据集进行重采样来创建多个域，以及（3）通过应用现实的域转换（例如，创建各种可能随时间变化协变量和概念偏移）来引入域间变异性。这些能力能够模拟大量现实的实验变体，进而提供更多关于算法在动态环境中部署时潜在行为的信息。我们通过对专有的真实世界银行卡支付数据集进行案例研究来证明该框架的有用性。鉴于案例研究的机密性质，我们还说明了该框架在公开的银行账户欺诈（BAF）数据集上的使用。通过提供一种随时间在现实数据可用性场景下评估TL方法的方法，我们的框架有助于理解模型和算法的行为。这使得在现实世界的环境中为新域部署模型时能够做出更好的决策。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [830] [Spatiotemporal wall pressure forecast of a rectangular cylinder with physics-aware DeepUFNet](https://arxiv.org/abs/2508.03183)
> *具有物理感知能力的深度傅里叶神经网络预测矩形圆柱体的时空壁压*

*Junle Liu, Chang Liu, Yanyu Ke, Wenliang Chen, Kihing Shum, K. T. Tse, Gang Hu* | **Category: physics.flu-dyn, cs.AI, cs.CE** | **Updated: 2025-08-05**

**Keywords:** 时空壁压预测, 矩形圆柱体, 深度学习, DeepUFNet, 物理信息神经网络

**Comment:** In total, 26 pages, 21 figures

> **TL;DR:** 该研究提出了一种名为DeepUFNet的物理感知深度学习模型，结合了UNet和傅里叶神经网络，并加入了高频损失控制，能够高精度地预测矩形圆柱体流动中的时空壁压，并且在稀疏空间信息输入下表现出令人满意的外插能力。

**AI_Comments:** 该研究将物理知识（高频损失控制）融入深度学习模型（DeepUFNet），解决了现有模型在时空预测方面的局限性，并取得了良好的预测效果。模型在处理高频细节和外插能力方面的优势值得关注，但需要进一步研究其在不同几何形状和流动条件下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 理解流体引起的力与结构响应需要知道壁压，但现有的深度学习模型通常只能预测单个快照。

**Method:** 提出了一种结合UNet结构和傅里叶神经网络的物理感知深度学习模型DeepUFNet，并在模型训练中嵌入了物理高频损失控制。通过风洞实验收集数据来训练和测试模型。

**Result:** DeepUFNet模型能够高精度地预测时空壁压信息，预测结果在统计信息、时间压力变化、功率谱密度、空间分布和时空相关性方面与实验数据一致。嵌入物理高频损失控制系数β可以显著提高模型性能，尤其是在预测高阶频率波动和壁压方差方面。

**Conclusion:** DeepUFNet模型能够高精度地预测矩形圆柱体的时空壁压，并且通过嵌入物理高频损失控制可以进一步提升预测性能，尤其是在高频波动和方差预测方面，同时该模型也展现了良好的外插能力。

> **ai_Abstract:** 本研究提出了一种名为DeepUFNet的物理感知深度学习模型，用于预测矩形圆柱体流动的时空壁压。该模型结合了UNet和傅里叶神经网络，并通过嵌入物理高频损失控制来优化性能。实验结果表明，DeepUFNet能够高精度地预测时空壁压，并与实验数据在多个方面表现出良好的一致性。该模型特别擅长预测高频波动和压力方差，并具有良好的外插能力。

> **摘要翻译:** 壁压对于理解由流体引起的力与结构响应至关重要。近期的研究已经探讨了深度学习技术在预测平均压力系数和脉动压力系数方面的潜力，但现有的大部分深度学习框架仅限于使用完整的空间信息来预测单个快照。为了预测矩形圆柱体流动的时空壁压，本研究开发了一种物理感知的深度傅里叶神经网络（DeepUFNet）深度学习模型。DeepUFNet包含UNet结构和傅里叶神经网络，并在模型训练阶段嵌入了物理高频损失控制以优化模型性能，其中参数β随训练轮次的进行而变化。通过风洞试验收集了边比为1.5、迎角为零的二维矩形圆柱体的壁压数据，并使用高频压力扫描技术，从而构建了DeepUFNet训练和测试数据库。研究发现DeepUFNet模型能够高精度地预测时空壁压信息。预测结果与实验数据对比显示，在统计信息、时间压力变化、功率谱密度、空间分布和时空相关性方面均表现出一致性。研究还发现，在DeepUFNet模型中嵌入物理高频损失控制系数β可以显著提高模型在预测时空壁压信息方面的性能，特别是在预测高阶频率波动和壁压方差方面。此外，还测试了DeepUFNet在输入稀疏空间信息时的外插能力，模型表现出令人满意的外插能力。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='physicsbio-ph'></a>
## physics.bio-ph 

### [949] [Exogeneous PpIX model for brain tumour assessment](https://arxiv.org/abs/2507.10230)
> *脑肿瘤评估的外源性PpIX模型*

*John Raschke, Jean Pierre Ndabakuranye, Bobbi Fleiss, Arman Ahnood* | **Category: physics.bio-ph, eess.IV** | **Updated: 2025-08-05**

**Keywords:** 外源性PpIX模型, 脑肿瘤, 荧光引导手术, 光电器件开发, 体外模型

**Comment:** Alterations have been made to this paper and will need to be updated

> **TL;DR:** 该研究提出了一种外源性脑肿瘤模型，通过将PpIX溶液注入大鼠大脑皮层区域来模拟肿瘤，该模型能很好地复制体内荧光条件，并可用于荧光检测设备（如荧光引导手术）的开发，克服了传统体内模型的局限性。

**AI_Comments:** 这项研究提出的外源性PpIX脑肿瘤模型是一个有前景的替代方案，可以解决传统体内模型在临床前设备开发中的不确定性问题。模型能够很好地复制体内荧光条件，并且易于控制和复制，这对于优化荧光检测设备至关重要。然而，需要进一步研究该模型在模拟肿瘤异质性和对不同治疗干预的反应方面的能力。此外，与现有体内模型的长期比较研究将有助于更全面地评估其优势和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的体内模型（如动物模型）在诱导胶质瘤和使用5-ALA诱导PpIX荧光方面存在固有的不确定性，这限制了它们在需要一致和可控肿瘤复制的临床前设备开发中的应用。虽然荧光标记凝胶模型易于复制，但未能捕捉体内模型的复杂性。

**Method:** 研究人员开发了一种外源性脑肿瘤模型，通过将PpIX溶液注入切除的大鼠大脑皮层区域，模拟了浓度梯度变化的肿瘤区域。他们还评估了溶剂DMSO对自发荧光（AF）的影响，并分析了储存对AF的短期影响。

**Result:** 该外源性模型准确复制了手术荧光条件，其荧光分布与体内条件（使用5-ALA）相关性达到R2>0.93。研究证实溶剂DMSO不会改变AF，并且建议将大脑样本保存在Hanks平衡盐溶液中并在冷藏条件下储存以保持水分和AF。

**Conclusion:** 该外源性PpIX脑肿瘤模型为评估PpIX荧光检测提供了一种有效的替代方案，克服了传统体内模型的局限性，有助于荧光检测设备（如荧光引导手术）的开发。

> **ai_Abstract:** 本研究提出了一种创新的外源性脑肿瘤模型，通过将PpIX溶液注入大鼠大脑，模拟了具有浓度梯度的肿瘤区域。该模型在复制体内荧光条件方面表现出色（R2>0.93），并解决了传统动物模型固有的不确定性问题，为荧光引导手术等光电器件的开发提供了更稳定、可控的体外评估平台。研究还验证了溶剂和储存条件对模型荧光特性的影响。

> **摘要翻译:** 可靠的体外模型被用于光电器件的开发，例如用于胶质瘤荧光引导手术的荧光检测设备。一种常用方法是诱导动物模型中的胶质瘤。然后，对胶质瘤进行5-ALA剂量处理以诱导原卟啉IX（PpIX），后者会发荧光。尽管这些方法在捕捉肿瘤的关键生物分子和生理特征方面表现出色，但它们本质上是不确定的。这限制了它们在临床前设备开发中的应用范围，而在这种开发中，需要跨多个动物的一致且可控的肿瘤复制。使用凝胶中的荧光标记的方法可以简单地复制，但未能捕捉体内模型的复杂性。在这项研究中，我们提出了一种用于评估PpIX荧光检测的外源性脑肿瘤模型。该模型通过将PpIX溶液注入切除的成年大鼠大脑皮层区域来开发，注射部位模拟了PpIX浓度升高的肿瘤区域。肿瘤区域具有浓度梯度，中心浓度最高，向边缘逐渐降低，类似于体内胶质瘤。将荧光分布与使用5-ALA的体内条件进行了比较，与其他已报道的工作高度相关，相关系数R2>0.93。通过检查溶剂DMSO对大脑样本自发荧光（AF）的影响以及储存对AF的短期影响，检验了模型的有效性。检查证实溶剂不会改变AF，并且大脑样本应保存在Hanks平衡盐溶液中并在冷藏条件下储存，以保持水分和保存AF。该模型准确地复制了手术荧光条件，并为胶质瘤诱导提供了一种合适的替代方案，有利于设计迭代过程中荧光检测设备的开发。

</details>

[⬆️ 返回分类顶部](#physicsbio-ph) | [⬆️ 返回总目录](#toc)

