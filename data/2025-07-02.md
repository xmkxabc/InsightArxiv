# AI-Enhanced arXiv Daily 2025-07-02

<a id='toc'></a>
## 今日总计: 518 篇论文
### 目录
- [cs.CR](#cscr) (14 篇)
- [cs.AI](#csai) (19 篇)
- [cs.LG](#cslg) (99 篇)
- [cs.MA](#csma) (3 篇)
- [cs.RO](#csro) (25 篇)
- [cs.CV](#cscv) (99 篇)
- [cs.HC](#cshc) (17 篇)
- [cs.ET](#cset) (3 篇)
- [cs.SE](#csse) (12 篇)
- [cs.SI](#cssi) (3 篇)
- [cs.NI](#csni) (6 篇)
- [cs.IT](#csit) (10 篇)
- [cs.AR](#csar) (3 篇)
- [cs.DC](#csdc) (11 篇)
- [cs.CY](#cscy) (6 篇)
- [cs.CE](#csce) (1 篇)
- [cs.FL](#csfl) (1 篇)
- [eess.SY](#eesssy) (11 篇)
- [eess.SP](#eesssp) (8 篇)
- [eess.IV](#eessiv) (19 篇)
- [eess.AS](#eessas) (7 篇)
- [cs.CL](#cscl) (42 篇)
- [cs.DS](#csds) (4 篇)
- [cs.GR](#csgr) (4 篇)
- [cs.IR](#csir) (8 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (17 篇)
- [cs.SD](#cssd) (7 篇)
- [cs.GT](#csgt) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (4 篇)
- [cs.DM](#csdm) (2 篇)
- [econ.TH](#econth) (1 篇)
- [cs.CC](#cscc) (1 篇)
- [quant-ph](#quant-ph) (5 篇)
- [cs.PL](#cspl) (2 篇)
- [math.CO](#mathco) (1 篇)
- [astro-ph.IM](#astro-phim) (2 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [cs.DL](#csdl) (1 篇)
- [math.FA](#mathfa) (1 篇)
- [math.OC](#mathoc) (4 篇)
- [physics.chem-ph](#physicschem-ph) (2 篇)
- [stat.ML](#statml) (5 篇)
- [math.AP](#mathap) (2 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [cs.MS](#csms) (1 篇)
- [cs.DB](#csdb) (1 篇)
- [hep-ph](#hep-ph) (1 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (2 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [physics.app-ph](#physicsapp-ph) (1 篇)
- [astro-ph.CO](#astro-phco) (1 篇)
- [math.DG](#mathdg) (1 篇)
- [cond-mat.dis-nn](#cond-matdis-nn) (1 篇)
- [nlin.AO](#nlinao) (1 篇)
- [stat.CO](#statco) (1 篇)
- [math.DS](#mathds) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [astro-ph.SR](#astro-phsr) (1 篇)
- [q-bio.BM](#q-biobm) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets](https://arxiv.org/abs/2507.00096)
> *适用于网络可信另类资产代币化的AI治理代理架构*

*Ailiya Borjigin, Wei Zhou, Cong He* | **Category: cs.CR, cs.AI**

**Keywords:** AI治理, 代理架构, 代币化, 另类资产, 区块链

**Comment:** 8 Pages, 1 figure

> **TL;DR:** 提出了一种AI治理的代理架构，结合区块链，以实现另类资产在网络上的可信代币化。

**AI_Comments:** 该论文提出了一种创新的AI治理代理架构，通过将AI与多代理系统和区块链相结合，有效解决了另类资产网络代币化中的信任、安全和合规性问题。其AI驱动的治理层和实时异常检测机制是重要的创新点，为构建可信的代币化平台提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 另类资产代币化在网络交易中面临可信度挑战，包括链下数据验证和监管合规性。

**Method:** 提出一种AI治理的代理架构，将智能代理与区块链结合。其中，自主代理协调代币化过程（资产验证、估值、合规性检查和生命周期管理），AI治理层通过自适应策略和加密经济激励来监控代理行为并强制执行信任。

**Result:** 该方法增强了资产代币化的透明度、安全性和合规性，解决了数据真实性和欺诈问题。房地产代币化案例研究表明，通过实时AI异常检测和链上强制执行，该架构可以减轻欺诈性列表和洗钱等风险。

**Conclusion:** 结合AI治理、多代理系统和区块链可以显著增强代币化资产生态系统的信任。该工作为网络上可信的资产代币化提供了一个新颖的框架，并为旨在部署安全、合规代币化平台的从业者提供了见解。

> **ai_Abstract:** 本文提出了一种AI治理的代理架构，旨在解决另类资产在网络代币化过程中面临的可信度挑战。该架构结合了智能代理和区块链，其中智能代理负责资产验证、估值和合规性等流程，而AI治理层则通过监控和激励机制确保信任。研究表明，该方法显著提升了代币化资产的透明度、安全性及合规性，并通过房地产代币化案例验证了其在风险缓解方面的有效性。

> **摘要翻译:** 另类资产代币化正在改变非传统金融工具在网络上的表示和交易方式。然而，在基于网络的代币化生态系统中确保可信度带来了重大挑战，从链下资产数据验证到强制执行监管合规性。本文提出了一种AI治理的代理架构，该架构将智能代理与区块链集成，以实现另类资产的网络可信代币化。在所提出的架构中，自主代理协调代币化过程（资产验证、估值、合规性检查和生命周期管理），而AI驱动的治理层通过自适应策略和加密经济激励来监控代理行为并强制执行信任。我们证明了这种方法增强了资产代币化的透明度、安全性与合规性，解决了数据真实性和欺诈等关键问题。一个关于房地产资产代币化的案例研究说明了该架构如何通过实时AI异常检测和链上强制执行来减轻风险（例如，欺诈性列表和洗钱）。我们的评估和分析表明，将AI治理与多代理系统和区块链相结合可以显著增强代币化资产生态系统的信任。这项工作为网络上可信的资产代币化提供了一个新颖的框架，并为旨在部署安全、合规代币化平台的从业者提供了见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise](https://arxiv.org/abs/2507.00145)
> *AI-Hybrid TRNG：基于核的深度学习实现从物理噪声中近均匀熵的提取*

*Hasan Yiğit* | **Category: cs.CR, cs.AI, cs.ET, cs.IT, eess.SP, math.IT**

**Keywords:** 深度学习, 真随机数生成器, 物理噪声, 熵提取, 嵌入式设备

**Comment:** 

> **TL;DR:** 该论文提出了一种名为AI-Hybrid TRNG的深度学习框架，它能从物理噪声中提取近乎均匀的熵，无需昂贵硬件，且生成的随机数通过了密码学标准测试，适用于资源受限平台。

**AI_Comments:** 这篇论文的创新点在于结合深度学习从物理噪声中提取熵，摆脱了对昂贵量子设备或实验室级射频接收器的依赖，显著降低了真随机数生成的成本和复杂性。其小巧的模型尺寸（<0.5 MB）使其在资源受限的嵌入式和边缘设备上具有极高的实用价值。通过了严格的密码学标准测试，证明了其生成的随机数质量。这对于需要高完整性随机数的各类安全系统和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的真随机数生成器（TRNGs）需要笨重的量子设备或昂贵的实验室级射频接收器。该研究旨在提供一种低成本、可部署、能从物理噪声中提取高质量随机数的方案，以扩大高完整性随机数生成器的应用范围。

**Method:** 提出AI-Hybrid TRNG，一个深度学习框架。它利用低成本的拇指大小射频前端和CPU时序抖动进行训练，然后无需量化步骤直接发射32位高熵流。其动态内外网络结合自适应自然源和重播种，生成不可预测的自主序列。模型大小小于0.5 MB。

**Result:** 生成的随机数通过了NIST SP 800-22测试，表现优于基于CPU的方法。它还通过了19项定制的统计测试（位和整数级别），所有结果均满足密码学标准。前向和后向预测实验未发现可利用的偏差。模型占用空间小于0.5 MB。

**Conclusion:** AI-Hybrid TRNG通过将随机性质量与专用硬件解耦，拓宽了高完整性随机数生成器在安全系统、密码协议、嵌入式和边缘设备、随机模拟以及需要随机数的服务器应用中的应用范围。

> **ai_Abstract:** 本文介绍了一种名为AI-Hybrid TRNG的深度学习框架，旨在从物理噪声中高效提取高质量的真随机数。该系统利用低成本的射频前端和CPU时序抖动进行训练，生成符合密码学标准的32位高熵随机数流，且无需昂贵的专用硬件。其独特的动态内外网络设计确保了生成序列的不可预测性。实验结果表明，AI-Hybrid TRNG在各项统计测试中表现优异，模型体积小巧，适用于资源受限的嵌入式和边缘设备，从而扩大了高完整性随机数生成器的应用范围。

> **摘要翻译:** AI-Hybrid TRNG是一个深度学习框架，它直接从物理噪声中提取近均匀的熵，无需笨重的量子设备或昂贵的实验室级射频接收器。相反，它依赖于低成本、拇指大小的射频前端，加上CPU时序抖动进行训练，然后无需任何量化步骤即可发射32位高熵流。
与确定性或经过训练的人工智能随机数生成器（RNGs）不同，我们的动态内外网络结合了自适应自然源和重播种，产生了真正不可预测和自主的序列。生成的数字通过NIST SP 800-22测试套件的表现优于基于CPU的方法。它还通过了19项定制的统计测试，用于位和整数级别的分析。所有结果均满足密码学标准，同时前向和后向预测实验未发现可利用的偏差。该模型的占用空间小于0.5 MB，使其可部署在微控制器（MCUs）和FPGA软核上，也适用于其他资源受限平台。
通过将随机性质量与专用硬件分离，AI-Hybrid TRNG拓宽了高完整性随机数生成器在安全系统、密码协议、嵌入式和边缘设备、随机模拟以及需要随机数的服务器应用中的应用范围。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [Plug. Play. Persist. Inside a Ready-to-Go Havoc C2 Infrastructure](https://arxiv.org/abs/2507.00189)
> *即插即用。持久化。深入即用型Havoc C2基础设施。*

*Alessio Di Santo* | **Category: cs.CR, cs.OS**

**Keywords:** Havoc C2, 命令与控制, Azure, 无文件攻击, 威胁情报

**Comment:** 

> **TL;DR:** 本文分析了一个Azure上部署的Havoc C2基础设施，揭示了其组件、攻击链和操作者特点。

**AI_Comments:** 该分析深入揭示了一个活跃的Havoc C2基础设施的内部运作机制和攻击者策略。其价值在于提供了对现实世界威胁的详细剖析，包括攻击者的技术选择（如无文件执行、内存加载）、工具集以及操作安全习惯。这对于防御者理解和对抗此类复杂威胁具有重要意义。特别值得注意的是，该研究通过分析一个具体的C2节点，揭示了攻击者如何利用云服务和模块化C2框架进行快速部署和规避检测。

<details>
  <summary>Details</summary>

**Motivation:** 分析一个被攻击者转化为一体化投递、暂存和命令与控制节点的Azure虚拟机，以揭示其内部结构和运作方式。

**Method:** 通过分析一个特定的Azure虚拟机（52.230.23.114），包括其暴露的Apache实例、开放目录、网络流量、HTML钓鱼文件、PowerShell命令、内存中的DLL重构技术以及运行时遥测数据来揭示攻击者的活动和工具。

**Result:** 发现该VM运行过时的Apache，暴露钓鱼诱饵、PowerShell加载器、Reflective Shell-Code、Havoc Demon植入物和横向移动工具。初始访问通过模仿Google登录通知的HTML文件实现，随后PowerShell禁用AMSI，在内存中执行Reflective-Loader技术加载Havoc Demon。Havoc Demon使用哈希查找Windows API和间接系统调用隐藏活动。运行时遥测显示对注册表、软件限制策略键的兴趣，以及大量使用加密DLL。攻击工具包包含Chisel、PsExec、Doppelganger和Whisker，并且泄露了开发者身份。

**Conclusion:** 分析表明，攻击者是技术娴熟的，重视快速工具重组而非深度操作安全，并利用Havoc模块化和合法云服务来混淆恶意流量。

> **ai_Abstract:** 本文深入分析了一个基于Azure的Havoc C2基础设施，该基础设施被用作一体化的投递、暂存和命令与控制节点。研究揭示了其过时的Apache服务、暴露的攻击工具（如钓鱼诱饵、PowerShell加载器、Havoc Demon植入物），以及通过模仿Google登录通知的HTML文件实现初始访问的攻击链。详细分析了PowerShell禁用AMSI、内存中加载Havoc Demon的技术，以及其利用哈希查找和间接系统调用隐藏活动的方法。此外，还发现了攻击者使用的横向移动工具集和其操作特点，即重视快速工具重组和利用合法云服务规避检测。

> **摘要翻译:** 这项分析侧重于一个Azure托管的虚拟机，IP地址为52.230.23.114，攻击者将其转换为一个一体化的投递、暂存和命令与控制节点。该主机暴露了一个过时的Apache 2.4.52实例，其开放目录暴露了钓鱼诱饵、PowerShell加载器、反射型Shell-Code、编译后的Havoc Demon植入物以及一套横向移动二进制工具；同一服务器还在8443/80端口响应加密信标流量。Web层充斥着公开记录的关键漏洞，如果攻击者尚未拥有该设备，这些漏洞本可以实现初始代码执行。
初始访问通过一个HTML文件实现，该文件一旦去混淆，就会完美模仿Google的异常登录尝试通知，并将受害者引向凭据收集。随后是一个PowerShell命令：它在内存中禁用AMSI，下载一个Base64编码的stub，分配RWX页面并在不触及磁盘的情况下启动shell-code。该stub使用反射加载器技术在内存中重构一个DLL，并将控制权交给Havoc Demon植入物。所有Demon变体——32位和64位——都与同一个后端通信，使用哈希查找解析Windows API，并通过间接系统调用隐藏其活动。
运行时遥测显示对Image File Execution Options下的注册表、对Software Restriction Policy键的刻意查询以及大量使用加密DLL来保护有效载荷和C2流量的兴趣。攻击者工具包还包含Chisel、PsExec、Doppelganger和Whisker，其中一些在用户目录下重新编译，泄露了开发者身份tonzking123和thobt。这些发现共同描绘了一个技术娴熟的攻击者形象，他们重视快速工具重组而非深度操作安全，并依赖Havoc的模块化和合法的云服务将恶意流量融入到正常的企业流量中。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [Addressing malware family concept drift with triplet autoencoder](https://arxiv.org/abs/2507.00348)
> *使用三重态自编码器解决恶意软件家族概念漂移*

*Numan Halit Guldemir, Oluwafemi Olukoya, Jesús Martínez-del-Rincón* | **Category: cs.CR**

**Keywords:** 恶意软件检测, 概念漂移, 三重态自编码器, DBSCAN, 机器学习

**Comment:** 

> **TL;DR:** 本文提出一种结合监督自编码器、三重态损失和DBSCAN的新方法，用于有效识别和分类新型恶意软件家族，以应对概念漂移挑战。

**AI_Comments:** 本文的创新点在于将监督自编码器与三重态损失结合，并辅以DBSCAN算法，以专门解决恶意软件家族概念漂移中“新家族出现”这一特定难题。这种结合度量学习和聚类的方法，对于提高动态网络安全环境中恶意软件检测系统的适应性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 恶意软件特性随时间变化导致的概念漂移，尤其是新恶意软件家族的出现，对现有机器学习恶意软件检测系统的有效性构成挑战。

**Method:** 本文提出一种创新方法，结合监督自编码器和三重态损失来区分已知和新型恶意软件家族。通过使用度量学习技术和DBSCAN算法，创建清晰且鲁棒的聚类，以提高恶意软件家族分类的准确性和弹性。

**Result:** 该方法在Android恶意软件数据集和Windows PE恶意软件数据集上进行了验证，结果表明其显著提高了新型恶意软件家族的检测能力，并能维持模型性能。

**Conclusion:** 本文提出的方法为应对新兴恶意软件威胁中的概念漂移问题提供了一个可靠的解决方案，显著提高了新型恶意软件家族的检测能力。

> **ai_Abstract:** 本文针对恶意软件检测中概念漂移带来的新型恶意软件家族识别挑战，提出了一种创新方法。该方法结合监督自编码器、三重态损失和DBSCAN算法，旨在通过创建鲁棒的聚类来有效区分已知与新型恶意软件家族。实验在Android和Windows PE数据集上验证了其有效性，结果显示该方法显著提升了新型恶意软件家族的检测能力，为动态变化的恶意软件威胁提供了可靠的解决方案。

> **摘要翻译:** 机器学习在网络安全，特别是在恶意软件检测中，变得越来越重要。然而，概念漂移，即恶意软件特征随时间变化的现象，对维持这些检测系统的有效性构成了挑战。概念漂移可以以两种形式出现：全新恶意软件家族的出现和现有家族的演变。本文提出了一种创新的方法来解决前者，重点是有效识别新型恶意软件家族。我们的方法利用监督自编码器结合三重态损失来区分已知和新型恶意软件家族。通过利用这种度量学习技术和基于密度的带噪声应用空间聚类（DBSCAN）算法，我们创建了清晰且鲁棒的聚类，从而提高了恶意软件家族分类的准确性和弹性。我们的方法在Android恶意软件数据集和Windows可执行文件（PE）恶意软件数据集上得到了验证，展示了其在新兴恶意软件威胁动态环境中维持模型性能的能力。我们的结果表明，在检测新型恶意软件家族方面取得了显著改进，为持续的网络安全挑战提供了可靠的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [20] [Find a Scapegoat: Poisoning Membership Inference Attack and Defense to Federated Learning](https://arxiv.org/abs/2507.00423)
> *寻找替罪羊：针对联邦学习的投毒成员推断攻击与防御*

*Wenjin Mo, Zhiyuan Li, Minghong Fang, Mingwei Fang* | **Category: cs.CR, cs.DC, cs.LG**

**Keywords:** 联邦学习, 投毒攻击, 成员推断攻击, 隐私, FedPoisonMIA

**Comment:** To appear in ICCV 2025

> **TL;DR:** 本文提出了一种名为FedPoisonMIA的投毒成员推断攻击，旨在从联邦学习中窃取成员信息，并提出了一种防御机制以减轻其影响。

**AI_Comments:** 本文提出了一种新颖的投毒成员推断攻击，将投毒攻击的范畴从模型完整性扩展到隐私泄露，这是对联邦学习安全研究的重要贡献。同时，论文也提出了相应的防御机制，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）尽管在保护隐私方面具有吸引力，但其分布式特性使其容易受到投毒攻击。现有的投毒攻击主要关注模型完整性（如降低准确性），而很少关注这些攻击带来的隐私问题。本研究旨在解决FL中通过投毒攻击进行的隐私泄露问题。

**Method:** 本研究引入了一种新颖的投毒成员推断攻击FedPoisonMIA，其中恶意客户端精心制作本地模型更新以推断成员信息。此外，本文还提出了一种鲁棒的防御机制来减轻FedPoisonMIA攻击的影响。

**Result:** 广泛的实验表明，该攻击是有效的。同时，所提出的防御方法在一定程度上降低了攻击的影响。

**Conclusion:** 本文成功开发了一种针对联邦学习的投毒成员推断攻击FedPoisonMIA，并提出了一种有效的防御机制来减轻其影响，揭示了联邦学习中新的隐私漏洞和相应的缓解策略。

> **ai_Abstract:** 本文提出了一种针对联邦学习（FL）的新型投毒成员推断攻击FedPoisonMIA。该攻击利用恶意客户端精心构造的本地模型更新来推断成员信息，填补了现有投毒攻击对隐私影响关注不足的空白。为应对此威胁，研究还提出了一种鲁棒的防御机制。实验结果证实了FedPoisonMIA的有效性，并表明所提出的防御措施能够有效减轻攻击的影响。

> **摘要翻译:** 联邦学习（FL）允许多个客户端在中央服务器的协调下协同训练一个全局机器学习模型，而无需共享其原始数据。这种方法在GDPR等隐私法规时代特别有吸引力，导致许多知名公司采用它。然而，FL的分布式特性使其容易受到投毒攻击，即受攻击者控制的恶意客户端发送有害数据以损害模型。FL中大多数现有的投毒攻击旨在降低模型的完整性，例如降低其准确性，而很少关注这些攻击带来的隐私问题。在本研究中，我们引入了FedPoisonMIA，一种针对FL的新型投毒成员推断攻击。FedPoisonMIA涉及恶意客户端制作本地模型更新以推断成员信息。此外，我们提出了一种鲁棒的防御机制来减轻FedPoisonMIA攻击的影响。在各种数据集上进行的广泛实验证明了该攻击的有效性，而我们的防御方法在一定程度上降低了其影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [40] [Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning](https://arxiv.org/abs/2507.00522)
> *采用混合统计深度学习的数字变电站通信网络网络攻击检测、预防和源定位*

*Nicola Cibin, Bas Mulder, Herman Carstens, Peter Palensky, Alexandru Ştefanov* | **Category: cs.CR, cs.SY, eess.SY**

**Keywords:** 数字变电站, 网络攻击, IEC 61850, 混合深度学习, 入侵预防

**Comment:** 10 pages, 6 figures. This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 本研究提出了一种混合统计深度学习方法，用于检测、预防和定位数字变电站中IEC 61850 SV注入攻击的来源，解决了现有协议缺乏安全功能的问题。

**AI_Comments:** 该研究的创新之处在于结合了统计建模（指数修正高斯分布）和深度学习（LSTM、Elman RNN）来处理数字变电站通信中的网络攻击问题，特别是关注了入侵预防而非仅仅是检测。其提出的方法有效解决了IEC 61850协议的安全漏洞，并在多样的测试环境下进行了全面验证，证明了其在实际部署中的可行性和鲁棒性，为关键基础设施的网络安全提供了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 电力系统数字化转型中，IEC 61850标准的应用日益加速，但其通信协议（如采样值SV）缺乏内置安全功能（如身份验证和加密），易受恶意数据包注入攻击，可能导致故障清除延迟或断路器误操作。现有研究主要集中于检测，而忽略了预防系统因可能造成通信网络中断的风险。

**Method:** 本研究提出了一种混合统计深度学习方法，用于检测、预防和定位IEC 61850 SV注入攻击。该方法使用指数修正高斯分布（EMG）来建模通信网络延迟，并利用长短期记忆（LSTM）和Elman循环神经网络来检测估计概率分布中的异常变化，从而有效丢弃恶意SV帧。

**Result:** 该方法能够有效丢弃恶意SV帧，处理开销和延迟极小，对通信网络延迟变化和时间同步问题保持鲁棒性，并在非攻击场景下保证接近零的误报率。在涉及工业级设备、硬件在环仿真、虚拟智能电子设备和合并单元以及高保真模拟通信网络的三个测试平台上进行了全面验证。

**Conclusion:** 该方法在IEC 61850兼容的数字变电站中具有实际部署的适用性。

> **ai_Abstract:** 本论文提出了一种新颖的混合统计深度学习方法，旨在解决数字变电站中IEC 61850采样值（SV）通信协议缺乏安全功能而易受恶意注入攻击的问题。该方法结合指数修正高斯分布建模网络延迟，并利用LSTM和Elman循环神经网络检测异常，实现对网络攻击的检测、预防和源定位。经验证，该方法能有效丢弃恶意数据帧，具有低开销、低延迟，并对网络延迟和同步问题具有鲁棒性，在非攻击情景下误报率接近零，显示出在实际数字变电站部署的潜力。

> **摘要翻译:** 电力系统的数字化转型正在加速IEC 61850标准的采用。然而，其通信协议，包括采样值（SV），缺乏内置的安全功能，如身份验证和加密，使其容易受到恶意数据包注入的攻击。此类网络攻击可能延迟故障清除或触发意外的断路器操作。尽管大多数现有研究侧重于数字变电站中的网络攻击检测，但由于存在潜在的通信网络中断风险，入侵预防系统一直被忽视。本文提出了一种使用混合统计深度学习的新方法，用于检测、预防和定位IEC 61850 SV注入攻击的来源。该方法使用指数修正高斯分布来建模通信网络延迟，并使用长短期记忆和Elman循环神经网络来检测估计概率分布中的异常变化。它能够以最小的处理开销和延迟有效丢弃恶意SV帧，对通信网络延迟变化和时间同步问题保持鲁棒性，并保证在非攻击场景下接近零的误报率。在涉及工业级设备、硬件在环仿真、虚拟智能电子设备和合并单元以及高保真模拟通信网络的三个测试平台上进行了全面验证。结果表明该方法适用于在IEC 61850兼容的数字变电站中实际部署。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [62] [BadViM: Backdoor Attack against Vision Mamba](https://arxiv.org/abs/2507.00577)
> *针对Vision Mamba的后门攻击：BadViM*

*Yinghao Wu, Liyan Zhang* | **Category: cs.CR, cs.AI, cs.CV**

**Keywords:** Vision Mamba, 后门攻击, BadViM, 谐振频率触发器, 隐藏状态对齐

**Comment:** 

> **TL;DR:** BadViM是一种针对Vision Mamba的新型后门攻击，它利用谐振频率触发器和隐藏状态对齐损失，实现了高攻击成功率并能抵御常见防御措施。

**AI_Comments:** 这项工作首次深入探讨了Vision Mamba架构的后门攻击脆弱性，填补了该领域的研究空白。其创新点在于提出了专门针对ViM频率敏感特性的谐振频率触发器（RFT）和用于增强攻击效果的隐藏状态对齐损失。攻击对多种防御措施的鲁棒性凸显了ViM架构潜在的安全风险，对于未来ViM的安全加固具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉状态空间模型（如Vision Mamba, ViM）作为Vision Transformers的替代品日益普及，但其安全隐患，特别是对后门攻击的脆弱性，尚未得到充分研究。

**Method:** 本文提出了BadViM，一个专门为Vision Mamba设计的后门攻击框架。它利用谐振频率触发器（RFT）来创建隐蔽的分布式触发器，利用模型对频率的敏感性。为提高攻击效率，还引入了隐藏状态对齐损失，通过对齐后门图像与目标类别的隐藏状态来操纵模型的内部表示。

**Result:** BadViM在保持干净数据准确性的同时，实现了卓越的攻击成功率。此外，BadViM对PatchDrop、PatchShuffle和JPEG压缩等常见防御措施表现出显著的鲁棒性，这些防御通常能中和普通后门攻击。

**Conclusion:** Vision Mamba容易受到后门攻击，而BadViM是一种有效且鲁棒的攻击方法，能够成功嵌入后门并抵御多种防御措施，揭示了ViM架构在安全方面的潜在漏洞。

> **ai_Abstract:** 本文提出了BadViM，一种针对Vision Mamba (ViM) 的新型后门攻击框架，旨在解决ViM架构安全漏洞未被充分探索的问题。BadViM通过利用谐振频率触发器（RFT）创建隐蔽的分布式触发器，并引入隐藏状态对齐损失来操纵模型内部表示。实验证明，BadViM在保持高干净数据准确性的同时，实现了优异的攻击成功率，并且对常见的后门防御措施（如PatchDrop、PatchShuffle和JPEG压缩）具有显著的鲁棒性。

> **摘要翻译:** 视觉状态空间模型（SSM），特别是像Vision Mamba（ViM）这样的架构，已成为视觉Transformer（ViT）的有前景的替代方案。然而，这种新型架构的安全隐患，特别是它们对后门攻击的脆弱性，仍然严重缺乏探索。后门攻击旨在将隐藏的触发器嵌入到受害者模型中，导致模型在包含这些触发器的输入上错误分类，同时在干净输入上保持正常行为。本文通过引入BadViM，一个专门为Vision Mamba设计的创新后门攻击框架，研究了ViM对后门攻击的敏感性。所提出的BadViM利用谐振频率触发器（RFT），该触发器利用受害者模型的频率敏感模式来创建隐蔽的分布式触发器。为了最大限度地提高攻击效率，我们提出了一种隐藏状态对齐损失，通过将后门图像的隐藏状态与目标类别的隐藏状态对齐，策略性地操纵模型的内部表示。广泛的实验结果表明，BadViM在保持干净数据准确性的同时，实现了卓越的攻击成功率。同时，BadViM对常见的防御措施，包括PatchDrop、PatchShuffle和JPEG压缩，表现出显著的鲁棒性，这些防御措施通常会中和正常的后门攻击。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [84] [The Secrets Must Not Flow: Scaling Security Verification to Large Codebases (extended version)](https://arxiv.org/abs/2507.00595)
> *秘密不得外泄：将安全验证扩展到大型代码库（扩展版）*

*Linard Arquint, Samarth Kishor, Jason R. Koenig, Joey Dodds, Daniel Kroening, Peter Müller* | **Category: cs.CR, cs.PL, cs.SE**

**Keywords:** 安全验证, 大型代码库, Diodon, 程序验证, I/O独立性

**Comment:** 

> **TL;DR:** Diodon方法通过将代码库分割为核心和应用部分，并结合半自动化和全自动化验证技术，实现了对大型代码库的安全验证，显著降低了验证成本。

**AI_Comments:** Diodon的创新之处在于其分层验证方法，通过将大型代码库分解为安全关键的核心和其余应用层，并结合不同自动化程度的验证技术，有效解决了程序验证在大规模代码上的可伸缩性问题。这种混合方法显著降低了手动验证的负担，使其在实际生产环境中变得可行。该研究对软件安全验证领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的程序验证工具难以扩展到大型代码库，因为需要大量手动工作来验证安全协议实现。

**Method:** 提出了一种名为Diodon的新方法，将代码库分为安全协议实现（Core）和其余部分（Application）。对安全关键的Core部分采用强大的半自动化验证技术，同时利用全自动化静态分析将验证扩展到整个代码库，通过证明I/O独立性（即Application的I/O操作与Core的安全相关数据无关）来确保Application不会使Core的安全属性失效。该方法已通过证明Diodon的可靠性（Application可安全执行I/O独立于安全协议，且手动验证和静态分析可可靠组合）来证实其有效性。

**Result:** Diodon在两个案例研究中进行了评估：一个签名Diffie-Hellman密钥交换的实现，以及一个包含10万多行代码的生产级Go代码库。通过对Go代码库中约1%的核心代码使用Gobra验证器，在不到三个人月内获得了保密性和注入式一致性保证。

**Conclusion:** Diodon方法通过创新的代码库分割和混合验证策略，成功地将安全验证扩展到大型代码库，显著降低了所需的人工成本，并提供了可靠的安全保证。

> **ai_Abstract:** 这篇论文提出了一种名为Diodon的新方法，旨在解决现有程序验证器难以扩展到大型代码库的问题。Diodon通过将代码库分割为安全关键的“Core”和其余的“Application”部分，对Core使用半自动化验证，并对Application使用全自动化静态分析，通过证明I/O独立性来确保Core的安全属性不被破坏。该方法已被证明可靠，并在两个案例研究（包括一个10万行代码的生产级Go项目）中得到验证，显著降低了大规模代码安全验证所需的时间和精力，成功获得了保密性和注入式一致性等安全保证。

> **摘要翻译:** 现有程序验证器能够证明安全协议实现的高级属性，但由于所需的手动工作量，难以扩展到大型代码库。我们开发了一种名为Diodon的新颖方法来解决这一挑战，该方法将代码库分为协议实现（核心Core）和其余部分（应用程序Application）。这种划分使我们能够对安全关键的Core应用强大的半自动化验证技术，同时通过确保Application不会使Core已证明的安全属性失效，使全自动化静态分析将验证扩展到整个代码库。静态分析通过证明I/O独立性来实现这一点，即Application中的I/O操作独立于Core的安全相关数据（如密钥），并且Application满足Core的要求。我们通过首先证明我们可以安全地允许Application执行独立于安全协议的I/O，其次证明手动验证和静态分析能够可靠地组合，从而证明了Diodon的可靠性。我们在两个案例研究中评估了Diodon：一个签名Diffie-Hellman密钥交换的实现，以及一个大型（10万+代码行）生产Go代码库，该代码库实现了密钥交换协议，我们通过使用自动活性程序验证器Gobra验证了约1%的代码核心，在不到三个人月内获得了保密性和注入式一致性保证。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [108] [Integrating Network and Attack Graphs for Service-Centric Impact Analysis](https://arxiv.org/abs/2507.00637)
> *整合网络和攻击图以进行以服务为中心的影响分析*

*Joni Herttuainen, Vesa Kuikka, Kimmo K. Kaski* | **Category: cs.CR, cs.SI**

**Keywords:** 网络攻击, 攻击图, 服务影响分析, 概率建模, 风险缓解

**Comment:** 17 pages, 13 figures, submitted for peer-review

> **TL;DR:** 该论文提出了一种新的方法，用于建模、可视化和分析网络威胁、攻击路径及其对企业网络中用户服务的影响，通过整合网络和攻击图并使用概率方法。

**AI_Comments:** 该研究通过整合网络和攻击图，并引入概率传播分析，为服务中心的影响分析提供了一个全面的框架。其创新之处在于能够从用户服务角度评估攻击影响，这对于制定实用的风险缓解策略至关重要。该方法对于理解复杂企业网络中的威胁传播具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解网络攻击在不同层面的传播，以及其对用户服务的影响，从而帮助早期检测、缓解和制定风险缓解策略。

**Method:** 提出了一种新颖的方法，通过整合网络和攻击图来建模、可视化和分析网络威胁。该方法使用概率方法来跟踪攻击通过攻击图、服务/应用层以及物理通信网络的传播。

**Result:** 该模型能够分析不同详细程度的网络攻击，并展示了这种基于网络的影响传播建模方法能够评估各种攻击场景，并开发保护和缓解措施。它还有助于安全专家和系统管理员做出明智的风险缓解决策。

**Conclusion:** 整合网络和攻击图的建模方法可以有效地分析网络攻击的传播及其对用户服务的影响，从而支持早期检测、缓解和制定基于服务关键性的风险管理策略。

> **ai_Abstract:** 该论文介绍了一种新颖的方法，用于整合网络和攻击图，以对企业网络中的网络威胁、攻击路径及其对用户服务的影响进行建模、可视化和分析。该方法采用概率方法跟踪攻击在不同层面的传播，从而能够评估多样的攻击场景，并协助开发保护和缓解措施，同时考虑服务的关键性，旨在帮助安全专业人员做出明智的风险决策。

> **摘要翻译:** 我们提出了一种新颖的方法，用于建模、可视化和分析网络威胁、攻击路径以及它们对企业或基础设施网络中数字设备及其提供的用户服务的影响。通过使用概率方法跟踪攻击通过攻击图、服务或应用层以及物理通信网络的传播，我们的模型使我们能够分析不同详细程度的网络攻击。理解攻击在微服务内部的服务中的传播以及其在不同服务或应用服务器之间的扩散有助于早期检测和缓解。我们证明了这种基于网络的影响传播建模方法能够评估各种攻击场景，并开发保护和缓解措施，同时考虑到从用户角度看服务的关键性。这种方法还可以帮助安全专家和系统管理员在风险缓解策略方面做出明智的决策。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [132] [Safe Low Bandwidth SPV: A Formal Treatment of Simplified Payment Verification Protocols and Security Bounds](https://arxiv.org/abs/2507.00740)
> *安全的低带宽SPV：简化支付验证协议和安全边界的正式处理*

*Craig S Wright* | **Category: cs.CR, cs.CL, cs.DC, 68Q85, 68M10, 94A60, 91A80, 68Q17, 68W10, 68R10, C.2.2; F.2.2; D.4.6; K.6.5**

**Keywords:** SPV, 比特币, 形式化验证, 安全性, 低带宽

**Comment:** 56 pages 5 images

> **TL;DR:** 本文对中本聪白皮书中定义的简化支付验证（SPV）协议进行了完整的形式化规范和数学证明，证明了SPV在有界对抗假设下不仅安全而且最优，并提出了低带宽优化措施。

**AI_Comments:** 本文的创新之处在于对SPV协议进行了首次完整的形式化处理和严谨的数学证明，纠正了长期以来对SPV安全性的普遍误解。其重要性在于为SPV的实际安全实现提供了坚实的理论基础和蓝图，特别是针对低带宽环境的优化，对数字现金系统的可扩展性和验证性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对流行实现中对SPV的误解，本文旨在通过形式化方法证明SPV协议在有界对抗假设下的安全性、最优性以及其活泼性和安全性特性。

**Method:** 本文提供了完整的形式化规范、协议描述和数学证明结构。它从第一性原理重建了SPV协议，将其验证模型建立在符号自动机、默克尔成员关系和证明链主导谓词上。通过严格的概率和博弈论分析，推导了协议安全运行的经济边界，并在部分连接、恶意中继网络和对抗性传播延迟下验证了其活泼性和安全性。

**Result:** 研究结果表明，SPV在有界对抗假设下不仅是安全的，而且对于需要可扩展和可验证交易包含的数字现金系统来说是严格最优的。本文推导了协议安全运行的经济边界，并在部分连接、恶意中继网络和对抗性传播延迟下验证了其活泼性和安全性。此外，规范还引入了自适应轮询和压缩头同步等低带宽优化措施，同时保持了正确性。

**Conclusion:** 本文既是安全SPV实现的蓝图，也是对围绕非验证客户端的常见误解的反驳。

> **ai_Abstract:** 本文对中本聪白皮书中定义的简化支付验证（SPV）协议进行了全面的形式化处理，包括规范、协议描述和数学证明。它驳斥了关于SPV不安全的常见误解，通过严格的概率和博弈论分析，证明了SPV在有界对抗假设下的安全性和最优性，并确定了其经济安全边界。此外，论文还引入了保持正确性的低带宽优化方案，旨在为安全的SPV实现提供指导并纠正公众认知。

> **摘要翻译:** 本文对中本聪白皮书中所定义的简化支付验证（SPV）进行了完整的形式化规范、协议描述和数学证明结构。与流行实现中普遍存在的错误理解形成鲜明对比的是，我们证明了SPV在有界对抗假设下不仅是安全的，而且对于需要可扩展和可验证交易包含的数字现金系统来说是严格最优的。我们从第一性原理重建了SPV协议，将其验证模型建立在符号自动机、默克尔成员关系和证明链主导谓词上。通过严格的概率和博弈论分析，我们推导了协议安全运行的经济边界，并在部分连接、恶意中继网络和对抗性传播延迟下验证了其活泼性和安全性。我们的规范进一步引入了自适应轮询和压缩头同步等低带宽优化措施，同时保持了正确性。本文既可作为安全SPV实现的蓝图，也可作为对围绕非验证客户端的常见误解的反驳。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [153] [A Technique for the Detection of PDF Tampering or Forgery](https://arxiv.org/abs/2507.00827)
> *一种检测PDF篡改或伪造的技术*

*Gabriel Grobler, Sheunesu Makura, Hein Venter* | **Category: cs.CR**

**Keywords:** PDF篡改, 文档伪造, 数字取证, 元数据检测, 页面对象

**Comment:** 19 Pages, 5 figures, published in Online Proceedings of the South
  African Institute of Computer Scientists and Information Technologists 2024
  Conference, ISSN 2959-8877

> **TL;DR:** 本文提出了一种新的技术，通过利用PDF文档的文件页面对象来检测PDF文档中的篡改，解决了现有哈希或水印技术无法检测PDF签名或元数据更改的局限性，并开发了一个原型来检测文本、图像或元数据的变化。

**AI_Comments:** 该论文的创新之处在于其超越了传统的哈希和水印方法，通过分析PDF特定的结构（文件页面对象）来检测非视觉篡改，例如元数据更改。这对于PDF的取证分析是一个重要的改进。

<details>
  <summary>Details</summary>

**Motivation:** 数字文档的篡改或伪造已变得普遍，可能导致金融欺诈和声誉损害等负面后果。现有的文档篡改检测技术（如生成哈希或水印）存在局限性，无法检测到PDF签名或其他非视觉方面（如元数据）的更改。

**Method:** 本文提出了一种通过利用PDF文档的文件页面对象来检测PDF文档内部篡改的新技术。该技术采用了一个原型。

**Result:** 该技术及其原型能够检测PDF文档的更改，例如对文本、图像或元数据所做的更改。

**Conclusion:** 本文提出了一种新的技术，通过分析PDF文档的文件页面对象，有效解决了传统哈希或水印技术在检测PDF文档篡改方面的局限性，特别是对非视觉方面（如元数据）的篡改检测能力。

> **ai_Abstract:** 本文提出了一种检测PDF文档篡改的新技术，旨在解决现有哈希和水印方法无法检测PDF签名或元数据变更的不足。该技术通过利用PDF文档的文件页面对象来实现，并已通过一个原型验证，能够检测PDF文件中文本、图像或元数据的变化。

> **摘要翻译:** 数字文档的篡改或伪造已变得普遍，最常见的是在没有任何恶意意图的情况下改变图像，例如增强图像的整体外观。然而，数字文档的篡改有时会产生负面后果，例如金融欺诈和声誉损害。篡改可以通过改变数字文档的文本或编辑图像的像素发生。许多技术已被开发出来用于检测文档是否发生更改。这些技术大多依赖于生成哈希或对文档进行水印。然而，这些技术存在局限性，它们无法检测便携式文件格式（PDF）签名或其他非视觉方面（如元数据）的更改。本文提出了一种新颖的技术，该技术可以通过利用PDF文档的文件页面对象来检测PDF文档内部的篡改。该技术采用了一个原型，可以检测PDF文档的更改，例如对该文件的文本、图像或元数据所做的更改。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [174] [On the Surprising Efficacy of LLMs for Penetration-Testing](https://arxiv.org/abs/2507.00829)
> *关于大型语言模型在渗透测试中惊人效能的研究*

*Andreas Happe, Jürgen Cito* | **Category: cs.CR**

**Keywords:** 大型语言模型, 渗透测试, 网络安全, 双重用途, 人工智能安全

**Comment:** 

> **TL;DR:** 大型语言模型在渗透测试中展现出惊人的效能，但其双重用途、可靠性和伦理问题带来了挑战。

**AI_Comments:** 该论文深入探讨了LLMs在渗透测试领域的颠覆性潜力，其创新之处在于系统性地审视了LLMs的“惊人效能”及其背后的驱动因素。论文不仅肯定了LLMs的强大能力，更重要的是，它前瞻性地指出了该技术固有的“双重用途”挑战，以及在实际部署中面临的可靠性、安全性、成本、隐私和伦理等关键限制和障碍。这对于平衡技术发展与安全治理具有重要指导意义，为未来的研究和政策制定提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在批判性地审视大型语言模型（LLMs）在渗透测试中惊人的效能，并探讨其快速发展能力如何使其日益适用于复杂的渗透测试操作。

**Method:** 该论文通过全面回顾LLMs的演变及其不断扩展的能力，系统地详细介绍了LLMs在学术研究和工业中的历史应用，展示了它们在各种攻击性安全任务和网络杀伤链更广泛阶段的应用。它还分析了LLMs被恶意行为者采用的情况，并对LLM辅助渗透测试的当前格局进行了分类。

**Result:** LLMs在渗透测试中的意外有效性归因于其与渗透测试对模式匹配的依赖性高度契合、管理动态环境中不确定性的固有能力以及通过LLM提供商经济高效地获取合格预训练模型。LLM辅助渗透测试分为交互式“vibe-hacking”和全自主系统。研究发现LLMs存在双重用途挑战，并识别出阻碍其广泛采用和安全部署的重大障碍，包括模型可靠性和稳定性、安全问题、成本、隐私、数字主权、问责制和伦理困境。

**Conclusion:** 该综合性审查和分析为未来人工智能与安全交叉领域的研究方向和强大保障措施的开发奠定了基础。

> **ai_Abstract:** 该论文对大型语言模型（LLMs）在渗透测试中的惊人效能进行了批判性审查。它追溯了LLMs的演变和在攻防安全任务中的应用，并强调了其双重用途的挑战。论文分析了LLMs有效的原因，并将其在渗透测试中的应用分为“vibe-hacking”和自主系统。同时，它也指出了推广和安全部署LLMs所面临的重大障碍，包括可靠性、安全性、成本、隐私和伦理问题。最终，该研究旨在为AI与安全领域的未来研究和保障措施的开发提供基础。

> **摘要翻译:** 本论文对大型语言模型（LLMs）在渗透测试中惊人的效能进行了批判性审视。论文全面回顾了LLMs的演变及其迅速扩展的能力，这些能力使其日益适用于复杂的渗透测试操作。它系统地详细介绍了LLMs在学术研究和工业中的历史应用，展示了它们在各种攻击性安全任务中的应用，并涵盖了网络杀伤链的更广泛阶段。至关重要的是，该分析还扩展到观察到的恶意行为者对LLMs的采用，强调了这项技术在安全领域固有的双重用途挑战。
LLMs在此背景下出乎意料的有效性通过几个关键因素得到阐明：渗透测试对模式匹配的依赖性与LLMs核心优势之间的强烈契合、它们管理动态环境中不确定性的固有能力，以及通过LLM提供商经济高效地获取合格预训练模型。
当前LLM辅助渗透测试的格局被分为交互式“vibe-hacking”和全自主系统的出现。论文识别并讨论了阻碍更广泛采用和安全部署的重大障碍。这些障碍包括模型可靠性和稳定性方面的关键问题、至关重要的安全和保障问题、巨大的经济和生态成本、对隐私和数字主权的影响、复杂的问责制问题以及深刻的伦理困境。这项全面的审查和分析为未来人工智能与安全交叉领域的研究方向和强大保障措施的开发奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [191] [Stealtooth: Breaking Bluetooth Security Abusing Silent Automatic Pairing](https://arxiv.org/abs/2507.00847)
> *窃齿：滥用静默自动配对打破蓝牙安全*

*Keiichiro Kimura, Hiroki Kuzuno, Yoshiaki Shiraishi, Masakatu Morii* | **Category: cs.CR, cs.NI**

**Keywords:** 蓝牙安全, 自动配对, Stealtooth, 中间人攻击, 漏洞

**Comment:** 13 pages, 6 figures. We plan to extend our evaluation to additional
  device categories. Responsible disclosure completed

> **TL;DR:** Stealtooth 是一种新型攻击，利用商用蓝牙设备中未知的自动配对漏洞，实现完全静默的设备链路密钥覆盖，并可扩展为中间人攻击。

**AI_Comments:** 这项研究的创新之处在于发现了蓝牙自动配对功能中此前未被探索的攻击面，并提出了两种具体的攻击方式（Stealtooth 和 MitM Stealtooth）。其重要性在于揭示了蓝牙设备中普遍存在的系统性漏洞，且攻击门槛极低，对数十亿蓝牙设备的安全构成威胁。同时，研究人员负责任地披露了漏洞并提出了防御建议，推动了行业安全改进。

<details>
  <summary>Details</summary>

**Motivation:** 蓝牙设备的自动配对功能为用户带来了便利，但也创造了一个此前未被探索过的攻击面。本文旨在揭示和利用这些自动配对功能中存在的未知漏洞，从而打破蓝牙的安全性。

**Method:** 本文提出了 Stealtooth 攻击，通过滥用商用蓝牙设备中的自动配对功能，实现静默的设备链路密钥覆盖。该攻击利用蓝牙音频设备在特定条件下自动进入配对模式的特性，使攻击者能够在用户不知情或无需专用工具的情况下劫持配对过程。此外，研究还扩展了 MitM Stealtooth 攻击，将自动配对滥用与省电模式技术相结合，实现中间人攻击。

**Result:** 研究人员对来自主要制造商的10款商用蓝牙设备进行了攻击评估，结果表明不同设备类型和制造商普遍存在漏洞。实际实现仅需商用硬件和开源软件，突显了攻击者较低的门槛。

**Conclusion:** 目前自动配对的实现方式在安全性和可用性之间存在关键矛盾，导致了系统性漏洞。研究提出了设备和协议层面的防御措施，包括增强用户通知和标准化自动配对指南。相关发现已负责任地披露给受影响的厂商，部分厂商已发布补丁。

> **ai_Abstract:** 本文提出了一种名为 Stealtooth 的新型蓝牙攻击，该攻击利用商用蓝牙设备中自动配对功能的未公开漏洞，实现了静默的设备链路密钥覆盖。攻击者可以利用蓝牙设备在特定条件下自动进入配对模式的特性，在用户无感知的情况下劫持配对过程，甚至可以扩展为中间人攻击。研究评估了10款商用蓝牙设备，发现普遍存在的漏洞，且攻击实现成本低。文章还探讨了安全与可用性之间的冲突，并提出了设备和协议层面的防御建议。

> **摘要翻译:** 蓝牙是一种普遍存在的无线通信技术，数十亿设备使用它进行短距离连接。蓝牙的安全性依赖于配对过程，设备在此过程中建立共享的长期密钥以实现安全通信。然而，许多商用蓝牙设备实现了自动配对功能以提高用户便利性，这创造了一个此前未被探索的攻击面。
我们提出了 Stealtooth，这是一种新型攻击，它滥用商用蓝牙设备中未知的自动配对功能漏洞，实现完全静默的设备链路密钥覆盖。Stealtooth 攻击利用了蓝牙音频设备在特定条件下自动转换为配对模式的事实，使攻击者能够在用户不知情或无需专用工具的情况下劫持配对过程。我们还将攻击扩展为 MitM Stealtooth 攻击，将自动配对滥用与省电模式技术相结合，以实现中间人攻击。
我们评估了对来自主要制造商的10款商用蓝牙设备的攻击，展示了跨不同设备类型和制造商的广泛漏洞。我们的实际实现仅需要商品硬件和开源软件，突出了攻击者的低门槛。
我们提出了设备和协议层面的防御措施，包括增强用户通知和标准化自动配对指南。我们的发现揭示了安全性和可用性之间的关键矛盾，表明当前的自动配对实现方式产生了系统性漏洞。我们负责任地向受影响的供应商披露了我们的发现，其中几家已经发布了补丁。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [210] [The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses](https://arxiv.org/abs/2507.00907)
> *感知零信任时代：为什么我们不能再相信我们的感官*

*Fabio Correa Xavier* | **Category: cs.CR, cs.AI, 68T07, 68T45, 94A60, K.6.5; D.4.6; I.2.6**

**Keywords:** 感知零信任, 深度伪造, 生成式AI, 零信任, 信息验证

**Comment:** 14 pages

> **TL;DR:** 面对深度伪造和克隆声音，论文提出“感知零信任”新安全理念，强调系统性怀疑感官信息，并建立验证协议以对抗生成式AI欺诈。

**AI_Comments:** 这篇论文的创新点在于将“零信任”原则从传统的IT安全领域扩展到人类感官信息的验证，以应对生成式AI带来的新型欺诈挑战。它强调了在AI时代，人类感官的不可靠性，并提出了一个实用的框架来缓解这种风险，对未来的网络安全和信息验证具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造和克隆声音正在成为复杂的攻击向量，组织需要一种新的安全思维来应对基于生成式人工智能的欺诈风险。

**Method:** 本文提出了一个将零信任原则扩展到人类感官信息的框架，整合了带外验证、作为取证协作者的视觉-语言模型（VLM）、加密溯源和人类培训等关键概念。

**Result:** Not mentioned in abstract

**Conclusion:** 在AI生成现实的时代，即使是我们的眼睛和耳朵在未经验证的情况下也无法再被隐式信任；领导者应培养一种方法论上的怀疑文化，以保护组织的完整性。

> **ai_Abstract:** 本文提出了“感知零信任”的新安全理念，以应对深度伪造和克隆声音等生成式AI带来的复杂攻击。它系统性地分析了怀疑感官信息的必要性，并构建了一个框架，整合了带外验证、VLM作为取证工具、加密溯源和人类培训，旨在将零信任原则应用于人类感官信息，以减轻欺诈风险。论文强调在AI生成现实的时代，感官信息必须经过验证，并呼吁培养批判性怀疑文化。

> **摘要翻译:** 在深度伪造和克隆声音成为复杂攻击向量的世界中，组织需要一种新的安全思维：感知零信任 [9]。本文对系统性怀疑通过感官感知到的信息的必要性进行了科学分析，建立了严格的验证协议，以减轻基于生成式人工智能的欺诈风险。带外验证、作为取证协作者的视觉-语言模型（VLM）、加密溯源和人类培训等关键概念被整合到一个将零信任原则扩展到人类感官信息的框架中。该方法以经验发现和学术研究为基础，强调在人工智能生成现实的时代，即使是我们的眼睛和耳朵，在未经验证的情况下也无法再被隐式信任。呼吁领导者培养一种方法论上的怀疑文化，以在这个新的威胁环境中保护组织的完整性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [11] [DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning](https://arxiv.org/abs/2507.00008)
> *DiMo-GUI：通过模态感知视觉推理推进GUI接地中的测试时扩展*

*Hang Wu, Hongkai Chen, Yujun Cai, Chang Liu, Qingwen Ye, Ming-Hsuan Yang, Yiwei Wang* | **Category: cs.AI, cs.CV, cs.HC**

**Keywords:** GUI接地, 模态感知, 视觉推理, 无需训练, 动态聚焦

**Comment:** 8 pages, 6 figures

> **TL;DR:** DiMo-GUI是一个无需训练的GUI接地框架，通过分离文本和图标元素并动态聚焦细化，有效处理视觉多样性和歧义，提升了现有基线的性能。

**AI_Comments:** DiMo-GUI的创新点在于其无需训练的特性以及结合了模态分离和动态区域聚焦的推理策略。这使得它能够有效地处理GUI接地中常见的视觉复杂性和语言歧义问题，并在不增加模型训练负担的情况下提升性能。其动态细化机制对于处理视觉拥挤布局尤其有益。

<details>
  <summary>Details</summary>

**Motivation:** 在图形用户界面（GUI）中接地自然语言查询面临独特的挑战，这归因于视觉元素的多样性、空间杂乱以及语言的模糊性。

**Method:** DiMo-GUI是一个无需训练的GUI接地框架，它利用动态视觉接地和模态感知优化。该方法将GUI输入分为文本元素和图标元素，允许模型使用通用视觉-语言模型独立推理。当预测模糊或不正确时，DiMo-GUI通过生成以初始预测为中心的候选焦点区域并逐步放大子区域来动态聚焦注意力，从而细化接地结果。这种分层细化过程有助于消除视觉拥挤布局的歧义，无需额外训练或标注。

**Result:** DiMo-GUI在标准GUI接地基准上进行了评估，并展示了对基线推理管道的持续改进。

**Conclusion:** 结合模态分离与区域聚焦推理的DiMo-GUI方法，有效解决了GUI接地中的视觉拥挤和歧义问题，提升了测试时性能，且无需额外训练或标注。

> **ai_Abstract:** DiMo-GUI是一个无需训练的GUI接地框架，旨在解决GUI中自然语言查询的视觉多样性和模糊性问题。它通过将GUI输入分离为文本和图标模态，并利用通用视觉-语言模型独立处理。当预测不确定时，DiMo-GUI会动态生成焦点区域并进行分层细化，以提高接地精度，尤其是在视觉拥挤的布局中。实验结果表明，DiMo-GUI在标准基准测试中优于现有基线。

> **摘要翻译:** 在图形用户界面（GUI）中接地自然语言查询带来了独特的挑战，这归因于视觉元素的多样性、空间杂乱以及语言的模糊性。在本文中，我们介绍了DiMo-GUI，一个无需训练的GUI接地框架，它利用两个核心策略：动态视觉接地和模态感知优化。我们的方法不将GUI视为一个整体图像，而是将输入分成文本元素和图标元素，允许模型使用通用视觉-语言模型独立地对每种模态进行推理。当预测模糊或不正确时，DiMo-GUI通过生成以模型初始预测为中心的候选焦点区域并逐步放大子区域来动态聚焦注意力，以细化接地结果。这种分层细化过程有助于消除视觉拥挤布局的歧义，而无需额外的训练或标注。我们在标准GUI接地基准上评估了我们的方法，并展示了对基线推理管道的持续改进，突出了模态分离与区域聚焦推理相结合的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [27] [TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables](https://arxiv.org/abs/2507.00041)
> *TalentMine：基于LLM的多模态人才表格提取与问答*

*Varun Mannam, Fang Wang, Chaochun Liu, Xin Chen* | **Category: cs.AI, cs.CV, cs.IR**

**Keywords:** 人才管理, LLM, 表格提取, 问答, 语义理解

**Comment:** Submitted to KDD conference, workshop: Talent and Management
  Computing (TMC 2025), https://tmcworkshop.github.io/2025/

> **TL;DR:** TalentMine是一个基于LLM的框架，通过语义丰富表示解决了人才管理系统中复杂表格信息检索的挑战，在问答任务中实现了100%的准确率。

**AI_Comments:** TalentMine通过解决表格数据中语义关系丢失的关键瓶颈，为人才管理系统中的信息检索带来了显著创新。其100%的准确率证明了其在解决复杂表格问答方面的强大能力。该方法的多模态推理和LLM增强表示是其核心创新点，有望在其他需要精确表格理解的领域产生重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 在人才管理系统中，关键信息常以复杂表格形式存在，传统语言模型难以有效检索。现有表格提取方法在语义理解上存在不足，导致在检索增强型聊天应用中表现不佳。主要瓶颈在于结构信息可提取，但表格元素间的语义关系丢失，导致后续查询失败。

**Method:** 本文引入了TalentMine，一个新颖的LLM增强框架，将提取的表格转换为语义丰富的表示。与依赖CSV或文本线性化的传统方法不同，TalentMine采用专门的多模态推理来保留表格数据的结构和语义维度。

**Result:** 在员工福利文档集合上的实验评估表明，TalentMine在查询回答任务中实现了100%的准确率，而标准AWS Textract提取为0%，AWS Textract Visual Q&A能力为40%。比较分析还显示，Claude v3 Haiku模型在人才管理应用中表现最佳。

**Conclusion:** 本文的关键贡献包括：1) 对当前表格提取管道中语义信息丢失的系统分析；2) 一种用于语义丰富表格表示的新型基于LLM的方法；3) 一个用于检索增强型系统作为端到端系统的高效集成框架；4) 在人才分析任务上的全面基准测试，显示在多个类别中都有显著改进。

> **ai_Abstract:** 本文提出了TalentMine，一个基于LLM的框架，旨在解决人才管理系统中复杂表格数据的检索和问答挑战。传统方法在处理表格的语义关系时表现不佳。TalentMine通过多模态推理将表格转换为语义丰富的表示，从而保留了结构和语义信息。实验结果表明，TalentMine在问答任务中实现了100%的准确率，显著优于现有方法，并发现Claude v3 Haiku模型表现最佳。该工作的主要贡献在于对语义信息丢失的分析、新型LLM方法的提出、集成框架的构建以及全面的性能基准测试。

> **摘要翻译:** 在人才管理系统中，关键信息通常以复杂的表格形式存在，这给传统的语言模型带来了显著的检索挑战。当处理需要精确解释表格关系以进行准确信息检索和后续决策的人才文档时，这些挑战尤为突出。当前的表格提取方法在语义理解方面存在困难，导致在集成到检索增强型聊天应用程序时性能不佳。本文识别出一个关键瓶颈——虽然可以提取结构化表格信息，但表格元素之间的语义关系丢失，从而导致后续查询失败。为了解决这个问题，我们引入了TalentMine，一个新颖的LLM增强框架，它将提取的表格转换为语义丰富的表示。与依赖CSV或文本线性化的传统方法不同，我们的方法采用专门的多模态推理来保留表格数据的结构和语义维度。对员工福利文档集合的实验评估表明，TalentMine表现出卓越的性能，在查询回答任务中实现了100%的准确率，而标准AWS Textract提取为0%，AWS Textract Visual Q&A能力为40%。我们的比较分析还揭示，Claude v3 Haiku模型在人才管理应用中实现了最佳性能。这项工作的关键贡献包括（1）对当前表格提取管道中语义信息丢失的系统分析，（2）一种用于语义丰富表格表示的新型基于LLM的方法，（3）一个用于检索增强型系统作为端到端系统的高效集成框架，以及（4）对人才分析任务的全面基准测试，显示在多个类别中都有显著改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [47] [A collaborative digital twin built on FAIR data and compute infrastructure](https://arxiv.org/abs/2507.00048)
> *基于FAIR数据和计算基础设施的协作式数字孪生*

*Thomas M. Deucher, Juan C. Verduzco, Michael Titus, Alejandro Strachan* | **Category: cs.AI, cond-mat.mtrl-sci, cs.CE, cs.LG**

**Keywords:** 自驱动实验室, FAIR数据, 数字孪生, 机器学习, 顺序优化

**Comment:** 10 pages, 5 figures

> **TL;DR:** 本文介绍了一个基于FAIR数据和nanoHUB服务的分布式自驱动实验室（SDL）实现，该实现允许地理分散的协作者共享实验数据，利用自动更新的机器学习模型进行分析和顺序优化，以加速发现和优化任务。

**AI_Comments:** 本文的创新点在于将分布式自驱动实验室与FAIR数据原则和主动学习相结合，构建了一个协作式数字孪生。这极大地提升了科研协作的效率和数据的可重用性。通过利用nanoHUB的现有服务，降低了实现门槛，并提供了一个可扩展的框架。其重要性在于为加速材料发现和优化提供了一个强大的、可复制的范式，尤其适合需要大量实验数据和迭代优化的领域。通过“节俭孪生”的概念和低成本材料的示例，也降低了教育和研究的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 在科学和工程应用中，将机器学习与自驱动实验室（SDL）中的自动化实验相结合，能够有效加速发现和优化任务。通过可查找、可访问、可互操作和可重用（FAIR）数据基础设施的支持，具有重叠兴趣的SDL可以更有效地协作。

**Method:** 本文提出了一个基于nanoHUB服务构建的分布式SDL实现，用于在线模拟和FAIR数据管理。在该框架中，地理分散的协作者将原始实验数据贡献到一个共享的中央数据库。新数据通过简单的网络界面提交，并使用nanoHUB Sim2L自动处理，提取导出量并将所有输入和输出索引到名为ResultsDB的FAIR数据存储库中。一个单独的nanoHUB工作流通过主动学习实现顺序优化，其中研究人员定义优化目标，机器学习模型会根据所有现有数据进行实时训练，指导未来实验的选择。该方法以“节俭孪生”概念为灵感，通过一个食品染料混合的优化任务进行示例。

**Result:** 该工作实现了一个分布式SDL，能够支持地理分散的协作者共享实验数据，并受益于自动更新的分析工具和机器学习模型。通过一个食品染料混合的优化任务，展示了利用FAIR数据、预测性机器学习模型和顺序优化的组合。研究人员和学生可以使用易于获取和廉价的材料设置实验，与协作者共享数据，并探索上述组合。

**Conclusion:** 本文介绍的工具具有普遍适用性，可以很容易地扩展到其他优化问题。

> **ai_Abstract:** 本文介绍了一个基于nanoHUB服务和FAIR数据基础设施的分布式自驱动实验室（SDL）实现，旨在促进科学和工程领域的协作式发现和优化。该系统允许地理分散的研究人员共享实验数据到一个中央数据库，并通过自动更新的机器学习模型和分析工具进行处理。通过Sim2L和ResultsDB确保数据符合FAIR原则，并利用主动学习进行顺序优化，指导未来实验。一个食品染料混合的优化任务被用作概念验证，展示了FAIR数据、预测性ML模型和顺序优化的有效结合，并强调了该工具的普遍适用性和可扩展性。

> **摘要翻译:** 自驱动实验室（SDL）中机器学习与自动化实验的结合，为加速科学和工程应用中的发现和优化任务提供了强大的方法。当由可查找、可访问、可互操作和可重用（FAIR）数据基础设施支持时，具有重叠兴趣的SDL可以更有效地协作。这项工作提出了一个基于nanoHUB服务构建的分布式SDL实现，用于在线模拟和FAIR数据管理。在此框架中，地理上分散的协作者进行独立的优化任务，将原始实验数据贡献到一个共享的中央数据库。这些研究人员随后可以从分析工具和机器学习模型中受益，这些工具和模型会随着新数据的可用而自动更新。新的数据点通过简单的网络界面提交，并使用nanoHUB Sim2L自动处理，该工具提取派生量并将所有输入和输出索引到名为ResultsDB的FAIR数据存储库中。一个单独的nanoHUB工作流通过主动学习实现顺序优化，其中研究人员定义优化目标，机器学习模型会根据所有现有数据进行实时训练，指导未来实验的选择。受“节俭孪生”概念的启发，优化任务旨在找到最佳配方，以混合食用染料以达到所需的目标颜色。通过易于获取且廉价的材料，研究人员和学生可以设置自己的实验，与协作者共享数据，并探索FAIR数据、预测性机器学习模型和顺序优化的结合。所引入的工具普遍适用，并且可以很容易地扩展到其他优化问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [67] [SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network](https://arxiv.org/abs/2507.00050)
> *SEZ-HARN: 自我解释的零样本人体活动识别网络*

*Devin Y. De Silva, Sandareka Wickramanayake, Dulani Meedeniya, Sanka Rasnayaka* | **Category: cs.AI, cs.HC, cs.LG, I.2.0**

**Keywords:** 人体活动识别, 零样本学习, 可解释人工智能, 惯性测量单元, 骨骼视频

**Comment:** 

> **TL;DR:** SEZ-HARN 是一种新的零样本人体活动识别模型，它不仅能识别训练中未见的活动，还能通过骨骼视频提供可解释的决策过程，同时保持与现有模型相当的识别准确率。

**AI_Comments:** SEZ-HARN的创新之处在于其结合了零样本学习能力和自我解释性，解决了现有HAR模型在实际部署中的两大痛点：数据不足和缺乏透明度。通过提供骨骼视频作为解释，显著增强了模型的可信度和用户接受度，这对于医疗保健等关键应用领域尤为重要。其在保持竞争性准确率的同时实现可解释性，是该研究的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于惯性测量单元（IMU）的人体活动识别（HAR）模型在实际应用中受限于缺乏全面的数据集和模型透明度。零样本HAR（ZS-HAR）解决了数据限制，但模型缺乏解释性，导致透明度不足。

**Method:** 本文提出了一种名为SEZ-HARN（自我解释的零样本人体活动识别网络）的新型基于IMU的ZS-HAR模型。该模型能够识别训练中未曾遇到的活动，并通过提供骨骼视频来解释其决策过程。作者在PAMAP2、DaLiAc、HTD-MHAD和MHealth四个基准数据集上评估了SEZ-HARN的有效性，并将其性能与三种最先进的黑盒ZS-HAR模型进行了比较。

**Result:** 实验结果表明，SEZ-HARN能够生成真实且易于理解的解释，同时实现了具有竞争力的零样本识别准确率。在PAMAP2数据集上，SEZ-HARN的零样本预测准确率与表现最佳的黑盒模型相差不到3%，在其他三个数据集上保持了可比的性能。

**Conclusion:** SEZ-HARN成功地解决了零样本人体活动识别中数据稀缺和模型透明度不足的问题，通过提供可解释的决策过程和保持高识别精度，为HAR的实际应用提供了更可靠和可信赖的解决方案。

> **ai_Abstract:** 本文提出了SEZ-HARN，一个针对基于IMU的零样本人体活动识别（ZS-HAR）的新模型。该模型旨在解决当前ZS-HAR在数据稀缺和模型透明度方面的局限性。SEZ-HARN不仅能识别训练中未见的活动，还能通过生成骨骼视频提供其决策的可解释性。实验结果表明，SEZ-HARN在四个基准数据集上取得了与现有黑盒模型相当的零样本识别准确率，同时提供了真实且易于理解的解释。

> **摘要翻译:** 人体活动识别（HAR）利用惯性测量单元（IMU）传感器的数据，在医疗保健和辅助生活环境中具有许多实际应用。然而，其在实际场景中的使用受到限制，原因在于缺乏涵盖广泛活动范围的全面基于IMU的HAR数据集，以及现有HAR模型缺乏透明度。零样本HAR（ZS-HAR）克服了数据限制，但当前模型难以解释其决策，使其透明度较低。本文介绍了一种新型的基于IMU的ZS-HAR模型，称为自我解释的零样本人体活动识别网络（SEZ-HARN）。它能够识别在训练期间未曾遇到的活动，并提供骨骼视频来解释其决策过程。我们在PAMAP2、DaLiAc、HTD-MHAD和MHealth四个基准数据集上评估了所提出的SEZ-HARN的有效性，并将其性能与三种最先进的黑盒ZS-HAR模型进行了比较。实验结果表明，SEZ-HARN能够生成真实且易于理解的解释，同时实现了具有竞争力的零样本识别准确率。SEZ-HARN在PAMAP2上的零样本预测准确率与表现最佳的黑盒模型相差不到3%，同时在其他三个数据集上保持了可比的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [89] [Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation](https://arxiv.org/abs/2507.00054)
> *使用奖励引导数据集蒸馏增强小型语言模型（SLMs）的推理能力*

*Shreyansh Padarha* | **Category: cs.AI, cs.CL, cs.LG**

**Keywords:** 知识蒸馏, 小型语言模型, 推理能力, 奖励引导, 数据集蒸馏

**Comment:** 17 Pages, 7 figures

> **TL;DR:** 本研究提出AdvDistill框架，通过奖励引导的数据集蒸馏，显著提升小型语言模型在数学和复杂推理任务上的性能，克服了传统知识蒸馏在泛化性和计算成本上的局限。

**AI_Comments:** 该论文通过引入奖励引导机制，创新性地改进了知识蒸馏技术，克服了传统方法在泛化性和推理能力上的局限。AdvDistill框架通过利用教师模型的多种响应并基于奖励进行加权训练，为提升小型语言模型的复杂推理能力提供了一条有效途径，对于在资源受限环境下部署高性能语言模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的知识蒸馏（KD）技术在将大型语言模型（LLMs）的能力压缩到小型语言模型（SLMs）时，学生模型往往只是复制教师模型的分布内响应，这限制了其泛化能力，尤其在推理任务上表现更差，且计算成本较高。

**Method:** 本研究提出了AdvDistill，一个奖励引导的数据集蒸馏框架。该方法为每个提示利用教师模型的多次生成（响应），并基于规则验证器分配奖励。这些不同且呈正态分布的奖励作为训练学生模型时的权重。

**Result:** AdvDistill方法及其行为分析表明，学生模型在数学和复杂推理任务上的性能得到了显著提升。

**Conclusion:** 将奖励机制纳入数据集蒸馏过程能够有效且有益地增强小型语言模型在推理任务上的性能和泛化能力。

> **ai_Abstract:** 本研究提出了一种名为AdvDistill的奖励引导数据集蒸馏框架，旨在解决传统知识蒸馏在小型语言模型（SLMs）推理能力泛化性方面的不足。该框架通过让大型教师模型为每个提示生成多个响应，并根据规则验证器分配奖励作为训练权重，从而使学生模型能够更好地学习复杂的推理模式。实验结果表明，AdvDistill显著提升了SLMs在数学和复杂推理任务上的性能，证明了在数据集蒸馏中引入奖励机制的有效性。

> **摘要翻译:** 将大型语言模型（LLMs）的熟练度压缩并赋予更易部署和高效的小型语言模型（SLMs）的努力，得益于知识蒸馏（KD）技术的改进。这些技术允许较小的学生模型从能力更强、更大的教师模型的响应中学习。然而，蒸馏通常围绕着学生模型仅仅复制教师模型的分布内响应，限制了其泛化能力。这种限制在推理任务上被放大，并且可能计算成本高昂。在本研究中，我们提出了AdvDistill，一个奖励引导的数据集蒸馏框架。我们为每个提示利用教师模型的多次生成（响应），并根据基于规则的验证器分配奖励。这些不同且呈正态分布的奖励在训练学生模型时作为权重。我们的方法及其随后的行为分析表明，学生模型在数学和复杂推理任务上的性能得到了显著提升，展示了在数据集蒸馏过程中引入奖励机制的有效性和益处。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [113] [VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems](https://arxiv.org/abs/2507.00079)
> *VoyagerVision：探究多模态信息在开放式学习系统中的作用*

*Ethan Smyth, Alessandro Suglia* | **Category: cs.AI, cs.LG**

**Keywords:** 开放式学习, 多模态信息, 大型语言模型, Minecraft, 视觉反馈

**Comment:** website: https://esmyth-dev.github.io/VoyagerVision.github.io/

> **TL;DR:** VoyagerVision是一个多模态模型，通过提供视觉输入（Minecraft截图）来增强开放式学习系统解释空间环境和解决任务的能力。它在Minecraft中成功创建了独特的结构，并在构建单元测试中表现出一定的成功率，扩展了现有系统的局限性。

**AI_Comments:** VoyagerVision的创新之处在于将多模态信息（特别是视觉反馈）引入开放式学习系统，这对于提升AGI在复杂环境中的感知和行动能力至关重要。其在Minecraft环境中的实验性验证，展示了视觉输入在空间理解和任务执行方面的潜力。然而，论文也提到了在复杂结构构建中仍存在局限性，这提示了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）能够解释图像输入，但它们在解释空间环境和执行更多任务方面仍有提升空间。本文旨在通过提供视觉输入来增强模型的空间解释能力和任务执行数量，从而扩展其开放式学习潜力，以实现更强大的通用人工智能（AGI）。

**Method:** 本文提出了VoyagerVision，一个建立在Voyager基础上的多模态模型。它利用Minecraft截图作为视觉反馈，使模型能够在游戏中创建结构。通过这种方式，它为模型提供了视觉输入，以增强其对空间环境的解释能力。

**Result:** VoyagerVision在50次迭代中平均创建了2.75个独特的结构，而Voyager无法做到这一点。此外，在构建单元测试中，VoyagerVision在平面世界中一半的尝试中取得了成功，大多数失败发生在更复杂的结构中。

**Conclusion:** 通过向开放式学习系统提供多模态视觉信息，可以显著增强其解释空间环境和成功执行任务的能力，从而扩展其开放式学习潜力。

> **ai_Abstract:** 本文提出了VoyagerVision，一个基于Voyager的多模态开放式学习系统，旨在通过整合视觉输入（如Minecraft截图）来增强模型解释空间环境和执行任务的能力。该系统在Minecraft中成功创建了独特的结构，并在构建单元测试中显示出一定效果，证明了多模态信息对于扩展开放式系统潜力、迈向通用人工智能的重要性。

> **摘要翻译:** 开放式学习是追求强大通用人工智能（AGI）的一个活跃研究领域，它允许模型自主选择任务。同时，GPT-4o [9] 等大型语言模型（LLMs）的最新进展使得此类模型能够解释图像输入。OMNI-EPIC [4] 等实现已经利用了这些特性，为LLM提供代理人视角的像素数据以解析环境并解决任务。本文提出，向模型提供这些视觉输入使其能够更好地解释空间环境，因此可以增加其成功执行的任务数量，从而扩展其开放式潜力。为此，本文提出了VoyagerVision——一个多模态模型，能够使用Minecraft截图作为视觉反馈在Minecraft中创建结构，它建立在Voyager的基础上。VoyagerVision在系统五十次迭代中平均创建了2.75个独特的结构，而Voyager无法做到这一点，这是在一个全新方向上的扩展。此外，在一组构建单元测试中，VoyagerVision在平面世界中一半的尝试中取得了成功，大多数失败发生在更复杂的结构中。项目网站可在https://esmyth-dev.github.io/VoyagerVision.github.io/访问。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [136] [Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models](https://arxiv.org/abs/2507.00092)
> *思考思考：SAGE-nano用于自我感知语言模型的逆向推理*

*Basab Jha, Firoj Paudel, Ujjwal Puri, Zhang Yuting, Choi Donghyuk, Wang Junhao* | **Category: cs.AI, cs.CL, cs.LG**

**Keywords:** 逆向推理, 大型语言模型, 可解释性, 自我感知, SAGE-nano

**Comment:** 19 pages, 2 figures, 9 tables

> **TL;DR:** SAGE-nano引入了逆向推理，使大型语言模型能够事后解释其决策过程，提高了透明度和性能，与顶级模型表现相当。

**AI_Comments:** 这项研究的关键创新在于提出了“逆向推理”的概念，使大型语言模型能够超越简单的思维链生成，进一步解释其决策背后的“为什么”，从而显著提升了AI的可解释性和透明度。SAGE-nano模型在相对较小的参数规模下，实现了与顶级大型模型相近的性能，这表明逆向推理在提高模型性能的同时，也有效地解决了AI的“黑箱”问题，对于AI安全、教育和科学研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在复杂推理任务中展现出卓越能力，但其决策过程仍像一个黑箱。本研究旨在通过使LLMs解释自己的推理链来提高透明度。

**Method:** 引入了“逆向推理”这一新范式，使LLMs能够分解并事后解释其自身的推理链。SAGE-nano（一个40亿参数的推理模型）采用了元认知结构，通过注意力过程进行反思，以识别主要决策点并生成推理选择的解释。与传统的正向推理不同，逆向推理提供了对特定推理链为何被选择的洞察。

**Result:** SAGE-nano在逻辑推理谜题、数学问题和道德困境测试中表现出色，在AQUA-RAT上推理准确率达到74.6%，解释质量的人类偏好得分达到92.1%。其性能几乎与Claude-3.5 Sonnet或GPT-4o等模型持平。主要贡献包括：LLM通过逆向推理进行自我反思的第一个严格框架；一种逆转注意力流的新型元学习框架；用于推理透明度的综合评估框架；以及逆向推理在提高可解释性的同时改善推理性能的证据。

**Conclusion:** 这项工作为透明AI系统开辟了新途径，并弥补了AI安全、教育和科学发现方面的重大空白。

> **ai_Abstract:** 本文介绍了SAGE-nano，一个40亿参数的语言模型，它利用“逆向推理”范式来提高大型语言模型的透明度。该方法使模型能够事后分解并解释其决策过程中的推理链，通过元认知结构和反向注意力流实现。在逻辑推理、数学和伦理难题上的广泛测试表明，SAGE-nano在推理准确性和解释质量方面均表现出色，其性能可与更大的SOTA模型相媲美。这项工作为AI的自我反思、可解释性和安全性提供了新的框架和证据。

> **摘要翻译:** 大型语言模型（LLMs）在解决复杂推理任务方面展现出卓越的能力，通过思维链（CoT）提示，但其决策过程仍然有些像黑箱。我们引入了逆向推理，这是一种新颖的范式，使LLMs能够分解并事后解释其自身的推理链。我们的方法在SAGE-nano中应用，这是一个40亿参数的推理模型，它采用了一种元认知结构，通过注意力过程进行反思，以识别主要决策点并生成推理选择的解释。虽然典型的思维链方法旨在正向推理生成，但逆向推理提供了对特定推理链为何被选择而非其他推理链的洞察。通过对AQUA-RAT、CommonsenseQA和自定义基准测试中的逻辑推理谜题、数学问题和道德困境进行彻底测试，我们证明了SAGE-nano在其任务中在推理准确性（AQUA-RAT上74.6%）和解释质量（92.1%的人类偏好得分）方面都处于领先地位，并且其性能几乎与Claude-3.5 Sonnet或GPT-4o等模型持平。我们的贡献包括：(i) 第一个通过逆向推理实现LLM自我反思的严格框架，(ii) 一种逆转注意力流的新型元学习框架，(iii) 用于推理透明度的综合评估框架，以及 (iv) 证明使用逆向推理增加推理能力可以提高可解释性以及推理性能的证据。我们的工作为透明AI系统创造了新途径，并弥补了AI安全、教育和科学发现方面的重大空白。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [158] [BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis](https://arxiv.org/abs/2507.00180)
> *黑盒到蓝图：利用强化学习和反事实分析从遗留系统中提取可解释逻辑*

*Vidhi Rathore* | **Category: cs.AI, cs.LG**

**Keywords:** 遗留系统, 可解释逻辑, 强化学习, 反事实分析, 决策树

**Comment:** 

> **TL;DR:** 提出一种新方法，使用强化学习和反事实分析从黑盒遗留系统中自动提取可解释的决策逻辑，并通过决策树生成规则，有助于系统现代化。

**AI_Comments:** 这篇论文提出了一种创新的方法，利用强化学习和反事实分析来解决遗留系统现代化中的核心难题——理解其内部决策逻辑。其创新点在于将RL用于智能探索，并结合反事实分析来识别关键行为变化，最终通过决策树生成可解释的规则。这对于缺乏文档的黑盒系统尤其重要，有望显著降低现代化成本和风险。

<details>
  <summary>Details</summary>

**Motivation:** 现代化遗留软件系统因缺乏文档和对复杂决策逻辑的理解而面临挑战。传统方法（如行为克隆）仅复制输入-输出行为，无法捕捉底层意图。因此需要一种能从黑盒遗留系统中提取可解释决策逻辑的方法。

**Method:** 本文提出一个新颖的管道，将遗留系统视为黑盒。该方法使用强化学习（RL）代理探索输入空间，通过奖励导致系统输出有意义变化的动作来识别关键决策边界。收集这些输出变化的反事实状态转换，并使用K-Means进行聚类。然后，在这些聚类上训练决策树，以提取近似系统决策逻辑的人类可读规则。

**Result:** 该管道在三种不同复杂度的虚拟遗留系统（包括基于阈值、组合条件和非线性范围逻辑）上进行了演示。结果表明，RL代理成功地将探索集中在相关边界区域，并且提取的规则准确反映了底层虚拟系统的核心逻辑。

**Conclusion:** 提取的规则准确反映了底层虚拟系统的核心逻辑，为遗留系统迁移期间生成规范和测试用例提供了有希望的基础。

> **ai_Abstract:** 本文提出了一种名为“BlackBoxToBlueprint”的新型管道，旨在从缺乏文档的遗留黑盒系统中自动提取可解释的决策逻辑。该方法结合了强化学习（RL）代理进行输入空间探索和关键决策边界识别，利用反事实分析收集输出变化，并通过K-Means聚类和决策树训练来提取人类可读的规则。实验在多种复杂度的虚拟系统上验证了其有效性，结果表明该方法能准确捕捉系统核心逻辑，为遗留系统现代化过程中的规范生成和测试用例创建奠定基础。

> **摘要翻译:** 现代化遗留软件系统是一项关键但具有挑战性的任务，常常因缺乏文档和对原始系统复杂决策逻辑的理解而受阻。行为克隆等传统方法仅仅复制输入-输出行为，而未能捕捉底层意图。本文提出了一种新颖的管道，可以自动从被视为黑盒的遗留系统中提取可解释的决策逻辑。该方法使用强化学习（RL）代理探索输入空间，并通过奖励导致系统输出发生有意义变化的动作来识别关键决策边界。这些输出发生变化的反事实状态转换被收集并使用K-Means进行聚类。然后，在这些聚类上训练决策树，以提取近似系统在识别边界附近决策逻辑的人类可读规则。我在三种不同复杂度的虚拟遗留系统上演示了该管道的有效性，包括基于阈值、组合条件和非线性范围逻辑。结果表明，RL代理成功地将探索集中在相关边界区域，并且提取的规则准确反映了底层虚拟系统的核心逻辑，为遗留系统迁移期间生成规范和测试用例提供了有希望的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [178] [ChatGPT produces more "lazy" thinkers: Evidence of cognitive engagement decline](https://arxiv.org/abs/2507.00181)
> *ChatGPT 培养出更多“懒惰”的思考者：认知参与度下降的证据*

*Georgios P. Georgiou* | **Category: cs.AI**

**Keywords:** ChatGPT, 认知参与度, 教育AI, 认知卸载, 学术写作

**Comment:** 

> **TL;DR:** 在学术写作中使用ChatGPT会导致学生认知参与度下降，表明存在认知卸载。

**AI_Comments:** 这项研究通过实验证据揭示了ChatGPT等AI工具可能对认知参与度产生的负面影响，即认知卸载，这具有重要意义。它为教育工作者提出了一个关键问题，并呼吁在教育中谨慎整合AI工具。其创新之处在于使用了专门的CES-AI量表来量化这种影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在教育中的使用日益增多，但人们对其可能降低深度思考和主动学习的潜力表示担忧。本研究旨在调查生成式人工智能工具（特别是ChatGPT）对学生在学术写作任务中认知参与度的影响。

**Method:** 本研究采用实验设计，参与者被随机分配到AI辅助（ChatGPT）组或非辅助（对照）组。参与者完成一项结构化的议论性写作任务，随后使用专门开发的认知参与度量表（CES-AI）进行评估，该量表旨在衡量心理投入、注意力、深度处理和策略性思维。

**Result:** 结果显示，与对照组相比，ChatGPT组的认知参与度得分显著降低。

**Conclusion:** 研究结果表明，AI辅助可能导致认知卸载。本研究对人工智能在教育中的心理影响文献做出了贡献，并提出了关于将此类工具整合到学术实践中的重要问题。它呼吁采取教学策略，促进学生对AI生成内容的积极、反思性参与，以避免损害学生的自我调节学习和深度认知投入。

> **ai_Abstract:** 本实验研究调查了ChatGPT对学生在学术写作中认知参与度的影响。使用ChatGPT的参与者与对照组相比，认知参与度得分显著降低，这表明AI辅助会导致认知卸载。该论文强调了AI在教育中的心理影响，并呼吁采取教学策略，促进对AI生成内容的积极参与，以防止深度学习的减少。

> **摘要翻译:** 尽管大型语言模型（LLMs）在教育中的使用日益增多，但人们对其可能降低深度思考和主动学习的潜力表示担忧。本研究调查了生成式人工智能（AI）工具，特别是ChatGPT，对学生在学术写作任务中认知参与度的影响。该研究采用实验设计，参与者被随机分配到AI辅助（ChatGPT）组或非辅助（对照）组。参与者完成了一项结构化的议论性写作任务，随后使用认知参与度量表（CES），即CES-AI，该量表旨在评估心理投入、注意力、深度处理和策略性思维。结果显示，与对照组相比，ChatGPT组的认知参与度得分显著降低。这些发现表明，AI辅助可能导致认知卸载。这项研究为人工智能在教育中的心理影响日益增长的文献做出了贡献，并提出了关于将此类工具整合到学术实践中的重要问题。它呼吁采取教学策略，促进对AI生成内容的积极、反思性参与，以避免损害学生的自我调节学习和深度认知投入。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [196] [Holistic Artificial Intelligence in Medicine; improved performance and explainability](https://arxiv.org/abs/2507.00205)
> *医学中的整体人工智能：改进的性能和可解释性*

*Periklis Petridis, Georgios Margaritis, Vasiliki Stoumpou, Dimitris Bertsimas* | **Category: cs.AI, cs.LG**

**Keywords:** 整体人工智能, 可解释人工智能, 医学, 多模态数据, 生成式AI

**Comment:** Submitted to npj Digital Medicine

> **TL;DR:** xHAIM是一个利用生成式AI来提高医学AI性能和可解释性的框架，它通过生成患者摘要和提供临床解释，将AI从黑盒预测器转变为可解释的决策支持系统，并在HAIM-MIMIC-MM数据集上将平均AUC从79.9%提高到90.3%。

**AI_Comments:** 本文提出的xHAIM框架通过引入生成式AI，有效解决了医学AI中长期存在的“黑盒”问题，显著提升了模型的可解释性，同时保持甚至提高了预测性能。这种将AI预测与具体临床知识关联起来的能力，对于提高临床医生对AI的信任度和实际应用价值至关重要，是医学AI领域的一项重要创新。

<details>
  <summary>Details</summary>

**Motivation:** 之前的HAIM框架在处理数据时任务无关，并且缺乏可解释性。为了解决这些局限性，本研究引入了xHAIM。

**Method:** 本研究引入了xHAIM（可解释HAIM）框架，它利用生成式AI通过四个结构化步骤来增强预测和可解释性：1）自动识别跨模态的任务相关患者数据；2）生成全面的患者摘要；3）使用这些摘要改进预测建模；4）通过将预测与患者特异性医学知识联系起来提供临床解释。

**Result:** 在HAIM-MIMIC-MM数据集上进行评估，xHAIM在胸部病理和手术任务中将平均AUC从79.9%提高到90.3%。

**Conclusion:** xHAIM将人工智能从一个黑盒预测器转变为一个可解释的决策支持系统，使临床医生能够交互式地追溯预测到相关的患者数据，从而将人工智能的进步与临床实用性结合起来。

> **ai_Abstract:** 本研究针对现有HAIM框架在医学AI中数据处理的任务无关性及缺乏可解释性问题，提出了xHAIM（可解释HAIM）框架。xHAIM利用生成式AI，通过识别任务相关数据、生成患者摘要、优化预测模型以及提供临床解释，显著提升了医学预测的性能和可解释性。在HAIM-MIMIC-MM数据集上的评估显示，xHAIM在胸部病理和手术任务中将平均AUC从79.9%提升至90.3%，成功将AI从黑盒预测器转变为可追溯的决策支持系统，增强了AI在临床中的实用性。

> **摘要翻译:** 随着将人工智能部署到医学领域兴趣的日益增长，我们之前引入了HAIM（医学中的整体人工智能），一个融合多模态数据来解决下游临床任务的框架。然而，HAIM以任务无关的方式使用数据，并且缺乏可解释性。为了解决这些局限性，我们引入了xHAIM（可解释HAIM），这是一个利用生成式AI通过四个结构化步骤来增强预测和可解释性的新型框架：(1) 自动识别跨模态的任务相关患者数据，(2) 生成全面的患者摘要，(3) 使用这些摘要改进预测建模，以及 (4) 通过将预测与患者特异性医学知识联系起来提供临床解释。在HAIM-MIMIC-MM数据集上进行评估，xHAIM在胸部病理和手术任务中将平均AUC从79.9%提高到90.3%。重要的是，xHAIM将人工智能从一个黑盒预测器转变为一个可解释的决策支持系统，使临床医生能够交互式地追溯预测到相关的患者数据，从而将人工智能的进步与临床实用性结合起来。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [213] [Learning for routing: A guided review of recent developments and future directions](https://arxiv.org/abs/2507.00218)
> *路由学习：近期发展与未来方向的引导性综述*

*Fangting Zhou, Attila Lischka, Balazs Kulcsar, Jiaming Wu, Morteza Haghir Chehreghani, Gilbert Laporte* | **Category: cs.AI, math.OC**

**Keywords:** 机器学习, 路由问题, 组合优化, 旅行商问题, 车辆路径问题

**Comment:** Accepted for publication in Transportation Research Part E: Logistics
  and Transportation Review

> **TL;DR:** 本文综述了机器学习在解决旅行商问题和车辆路径问题等路由问题上的应用进展，并提出了一个分类法，旨在指导未来研究。

**AI_Comments:** 这篇综述文章具有重要的指导意义，它系统地梳理了机器学习在解决复杂路由问题上的应用，并提出了一个实用的分类框架。通过整合传统运筹学和新兴ML技术，它为该领域的未来研究提供了清晰的方向，特别是在处理车辆路径问题变体方面。

<details>
  <summary>Details</summary>

**Motivation:** 路由问题（如旅行商问题和车辆路径问题）是NP-hard组合优化问题，传统精确算法计算耗时，启发式算法无法保证最优。鉴于机器学习模型的成功，研究人员正积极探索利用ML技术解决这些挑战性问题。

**Method:** 本文通过综述机器学习在解决路由问题上的应用进展，并提出了一个将基于ML的路由方法分为构建式和改进式两类的分类法，旨在整合传统运筹学方法与最先进的ML技术。

**Result:** 本文提出了一个将基于机器学习的路由方法分类为构建式和改进式的方法学，并强调了它们在各种问题特征上的适用性。

**Conclusion:** 本综述旨在整合传统运筹学方法与最先进的机器学习技术，提供一个结构化框架，以指导未来的研究并解决新兴的车辆路径问题变体。

> **ai_Abstract:** 这篇综述文章探讨了机器学习在解决旅行商问题和车辆路径问题等NP-hard路由问题上的最新进展。鉴于传统方法的局限性，ML方法正成为解决这些复杂问题的有效途径。文章提出了一个将ML路由方法分为构建式和改进式的分类法，旨在整合传统运筹学与先进ML技术，为未来的研究提供指导框架，并应对新兴的VRP变体。

> **摘要翻译:** 本文综述了将机器学习（ML）工具应用于解决NP-hard组合优化问题，重点关注旅行商问题（TSP）和车辆路径问题（VRP）等路由问题的当前进展。由于这些问题固有的复杂性，精确算法通常需要过多的计算时间才能找到最优解，而启发式算法只能提供近似解，无法保证最优性。随着机器学习模型的近期成功，提出和实施各种ML技术以增强这些挑战性路由问题的解决能力已成为一种日益增长的趋势。我们提出了一个分类法，将基于ML的路由方法分为构建式和改进式两种方法，并强调了它们对各种问题特征的适用性。本综述旨在将传统运筹学方法与最先进的ML技术相结合，提供一个结构化的框架，以指导未来的研究并解决新兴的VRP变体。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [226] [ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context](https://arxiv.org/abs/2507.00417)
> *ASTRO：通过上下文反思和回溯教授语言模型推理*

*Joongwon Kim, Anirudh Goyal, Liang Tan, Hannaneh Hajishirzi, Srinivasan Iyer, Tianlu Wang* | **Category: cs.AI, cs.CL**

**Keywords:** 语言模型, 推理, 搜索算法, 强化学习, Llama 3

**Comment:** 36 pages, 23 figures

> **TL;DR:** ASTRO是一个框架，通过模拟搜索算法的自反思和回溯，训练语言模型进行推理，并在Llama 3上取得了显著的性能提升。

**AI_Comments:** 这篇论文的创新点在于提出了ASTRO框架，通过合成数据集和强化学习（RL）将搜索算法的“反思”和“回溯”行为教给语言模型，从而提升其推理能力。它解决了如何将推理能力注入到原本不具备强推理能力的模型（如Llama 3）中的问题，而不是仅仅依赖于已经强大的模型。这种通过模拟结构化搜索行为来提升模型推理能力的方法是新颖且有效的。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型虽然通过强化学习（RL）增强了推理能力，但开源复现依赖于本身已具有强推理能力的模型。对于Llama 3等非推理模型，如何提升其推理能力尚不清楚。

**Method:** ASTRO通过从数学问题解决轨迹的蒙特卡洛树搜索（MCTS）中派生合成数据集，将搜索轨迹转换为捕捉成功和从失败中恢复的自然语言思维链，从而引导模型内化结构化搜索行为。随后通过可验证的奖励进行强化学习微调。

**Result:** 将ASTRO应用于Llama 3系列模型，在MATH-500上实现了16.0%的绝对性能提升，在AMC 2023上提升26.9%，在AIME 2024上提升20.0%，尤其在需要迭代修正的挑战性问题上表现突出。

**Conclusion:** 搜索启发式训练为向开放大型语言模型（LLM）灌输强大的推理能力提供了一种原则性的方法。

> **ai_Abstract:** ASTRO是一个新框架，旨在通过模拟搜索算法的自反思和回溯来训练语言模型进行推理。它通过将蒙特卡洛树搜索轨迹转换为自然语言思维链来创建合成数据集，以教会Llama 3等非推理模型结构化搜索行为。该方法在Llama 3系列模型上实现了显著的性能提升，尤其是在复杂的数学问题上，证明了搜索启发式训练能有效提升开放LLM的推理能力。

> **摘要翻译:** 我们引入了ASTRO，即“自回归搜索教学推理器”，这是一个训练语言模型像搜索算法一样推理的框架，它明确地在其输出中利用了自反思、回溯和探索。最近，通过强化学习（RL）训练大型语言模型（LLM）导致了推理模型的出现，其推理能力大大增强。推理模型的开源复制虽然成功，但它们建立在已经表现出强大推理能力和甚至在RL之前就观察到的搜索行为的模型之上。因此，目前尚不清楚如何提升包括Llama 3在内的其他非推理模型的推理能力。ASTRO通过从数学问题解决轨迹的蒙特卡洛树搜索（MCTS）中派生合成数据集，教授这些模型内化结构化搜索行为。通过将搜索轨迹转换为捕捉成功和从失败中恢复的自然语言思维链，ASTRO为RL期间的探索提供了丰富的先验知识，从而引导模型。我们对这些搜索派生轨迹上的模型进行微调，并通过可验证的奖励进一步通过RL提高性能。我们将ASTRO应用于Llama 3系列模型，在MATH-500上实现了16.0%的绝对性能提升，在AMC 2023上实现了26.9%的提升，在AIME 2024上实现了20.0%的提升，尤其是在需要迭代修正的挑战性问题上有所改进。我们的结果表明，搜索启发式训练为向开放LLM灌输强大的推理能力提供了一种原则性的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [240] [Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning](https://arxiv.org/abs/2507.00432)
> *数学推理能否提升大型语言模型的通用能力？理解大型语言模型推理的可迁移性*

*Maggie Huan, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, Xiang Yue* | **Category: cs.AI, cs.CL**

**Keywords:** LLM, 数学推理, 迁移学习, 强化学习, 监督微调

**Comment:** 

> **TL;DR:** 研究发现，LLM在数学推理上的成功通常无法迁移到其他领域，其中RL调优模型比SFT调优模型具有更好的泛化能力，SFT会导致表示和输出漂移。

**AI_Comments:** 该论文对当前LLM领域的一个重要且常被忽视的问题进行了深入探讨：即特定领域（如数学推理）能力的提升是否具有普遍的积极影响。其创新点在于通过大量模型评估和受控实验，明确区分了RL和SFT在泛化能力上的差异，并通过潜在空间分析提供了机理解释。研究结果对LLM的训练范式，特别是后训练步骤，提出了重要的反思，指出当前过度依赖SFT可能存在局限性，对未来构建更通用、更鲁棒的LLM具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在数学基准测试上快速超越人类水平，作者质疑这些进步是否反映了更广泛的问题解决能力，还是仅仅是狭隘的过拟合，因此需要评估数学推理能力对LLM通用能力的提升作用及其可迁移性。

**Method:** 研究评估了超过20个开源的推理调优模型，涵盖数学、科学问答、智能体规划、编程和标准指令遵循等任务。为了深入研究，作者在Qwen3-14B模型上进行了受控实验，使用纯数学数据但采用不同的调优方法（强化学习RL和监督微调SFT），并分析了潜在空间表示和token空间分布漂移。

**Result:** 研究发现，大多数在数学上表现出色的模型未能将其优势迁移到其他领域。具体而言，强化学习（RL）调优的模型在不同领域泛化良好，而监督微调（SFT）调优的模型常常会遗忘通用能力。潜在空间表示和token空间分布漂移分析表明，SFT会导致显著的表示和输出漂移，而RL则保留了通用领域结构。

**Conclusion:** 本研究结果表明，需要重新思考标准的模型后训练方法，特别是对SFT蒸馏数据在推进推理模型方面的依赖。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在数学推理方面的进步是否能提升其通用能力。通过评估20多个开源推理调优模型，并对Qwen3-14B模型进行受控实验，发现大多数在数学上成功的模型未能将其能力迁移到其他领域。具体来说，RL调优的模型泛化性更好，而SFT调优的模型常导致通用能力遗忘和表示漂移。研究强调需重新思考当前LLM的后训练策略，特别是对SFT的过度依赖。

> **摘要翻译:** 数学推理已成为大型语言模型（LLMs）进展的典范，新模型在MATH和AIME等基准测试上迅速超越人类水平。但随着数学排行榜每周都在提升，值得一问的是：这些进步是否反映了更广泛的问题解决能力，还是仅仅是狭隘的过拟合？为了回答这个问题，我们评估了20多个开源的推理调优模型，涵盖广泛的任务，包括数学、科学问答、智能体规划、编程和标准指令遵循。我们惊讶地发现，大多数在数学上成功的模型未能将其优势迁移到其他领域。为了严谨地研究这一现象，我们使用纯数学数据但采用不同调优方法，对Qwen3-14B模型进行了受控实验。我们发现，强化学习（RL）调优的模型在不同领域泛化良好，而监督微调（SFT）调优的模型常常会遗忘通用能力。潜在空间表示和token空间分布漂移分析表明，SFT会导致显著的表示和输出漂移，而RL则保留了通用领域结构。我们的结果表明，需要重新思考标准的后训练方法，特别是对SFT蒸馏数据在推进推理模型方面的依赖。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [254] [Advancing Local Search in SMT-NRA with MCSAT Integration](https://arxiv.org/abs/2507.00557)
> *在SMT-NRA中通过集成MCSAT推进局部搜索*

*Tianyi Ding, Haokun Li, Xinpeng Ni, Bican Xia, Tianqi Zhao* | **Category: cs.AI, cs.LO, cs.SC**

**Keywords:** SMT-NRA, 局部搜索, MCSAT, 2d-cell-jump, 混合框架

**Comment:** 

> **TL;DR:** 该研究通过引入二维单元跳跃、提出集成MCSAT的2d-LS框架以及实现样本单元投影算子，显著改进了非线性实数算术可满足性模理论（SMT-NRA）的局部搜索效率，并通过混合框架进一步优化。

**AI_Comments:** 该论文在SMT-NRA的局部搜索领域进行了重要创新，通过引入2d-cell-jump和集成MCSAT的2d-LS框架，以及采纳样本单元投影算子，系统性地提升了搜索效率。特别是将MCSAT与局部搜索结合，并设计混合框架进行信息交换，显示了其在复杂问题求解上的潜力。其局限性可能在于未详细说明实验的具体设置和数据集，或与其他现有先进方法的详细对比。

<details>
  <summary>Details</summary>

**Motivation:** 改进非线性实数算术可满足性模理论（SMT-NRA）中的局部搜索效率。

**Method:** 首先，引入了二维单元跳跃（2d-cell-jump）操作。其次，提出了名为2d-LS的扩展局部搜索框架，该框架集成了模型构建可满足性演算（MCSAT）框架以提高搜索效率。为了进一步提高MCSAT的效率，实现了样本单元投影算子技术。最后，设计了一个结合MCSAT、2d-LS和OpenCAD的混合框架，通过信息交换提高搜索效率。

**Result:** 实验结果表明，局部搜索性能得到了改进，突出了所提出方法的有效性。

**Conclusion:** 所提出的方法，包括2d-cell-jump、集成MCSAT的2d-LS框架、样本单元投影算子以及混合框架，有效地提高了SMT-NRA中局部搜索的效率和性能。

> **ai_Abstract:** 本论文致力于提升非线性实数算术可满足性模理论（SMT-NRA）的局部搜索能力。研究引入了创新的二维单元跳跃（2d-cell-jump）操作，并构建了一个名为2d-LS的扩展局部搜索框架，该框架巧妙地整合了模型构建可满足性演算（MCSAT）以优化搜索效率。为进一步强化MCSAT，论文还采纳并实现了样本单元投影算子技术。最终，通过结合MCSAT、2d-LS和OpenCAD，设计了一个混合框架，旨在通过信息交互进一步提升整体搜索性能。实验验证了这些新方法的有效性，展示了局部搜索性能的显著提升。

> **摘要翻译:** 本文推进了非线性实数算术可满足性模理论（简称SMT-NRA）中的局部搜索。首先，我们引入了一种二维单元跳跃操作，称为“2d-cell-jump”，它推广了SMT-NRA局部搜索方法的关键操作——单元跳跃。然后，我们提出了一个名为“2d-LS”的扩展局部搜索框架（沿用了SMT-NRA的局部搜索框架LS），该框架集成了模型构建可满足性演算（MCSAT）框架以提高搜索效率。为了进一步提高MCSAT的效率，我们为MCSAT实现了一种最近提出的技术，称为“样本单元投影算子”，该技术非常适合实数域中的CDCL式搜索，并有助于引导搜索远离冲突状态。最后，我们设计了一个结合MCSAT、2d-LS和OpenCAD的SMT-NRA混合框架，通过信息交换提高搜索效率。实验结果表明局部搜索性能有所改进，突出了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [265] [Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess](https://arxiv.org/abs/2507.00726)
> *大型语言模型能否发展战略推理能力？从学习国际象棋中获得的后训练见解*

*Dongyoon Hwang, Hojoon Lee, Jaegul Choo, Dongmin Park, Jongho Park* | **Category: cs.AI, cs.LG**

**Keywords:** 大型语言模型, 战略推理, 强化学习, 国际象棋, 知识蒸馏

**Comment:** 27 pages

> **TL;DR:** 研究发现，通过强化学习（RL）训练LLM进行国际象棋的战略推理，尽管使用知识蒸馏的密集奖励表现优于稀疏奖励，但模型仍远低于专家水平，这可能源于预训练模型对国际象棋内部理解的不足。

**AI_Comments:** 这项研究提出了一个重要的问题：LLM在战略推理方面的潜在局限性。通过国际象棋这一经典的战略博弈，论文揭示了即使有先进的RL技术和知识蒸馏，预训练模型固有的领域理解不足仍可能成为性能瓶颈。这对于未来LLM在复杂战略任务中的应用和训练方向提供了宝贵的见解，强调了基础模型领域知识的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 探索LLM通过强化学习在国际象棋中发展战略推理能力，因为RL在LLM数学推理方面有前景，但在战略推理方面研究甚少。

**Method:** 利用国际象棋预训练的行动-价值网络为LLM的输出走法质量提供密集奖励，这被视为一种知识蒸馏形式。进行了SFT（监督微调）和RL的国际象棋推理训练消融实验。

**Result:** 基于蒸馏的密集奖励通常优于稀疏二元奖励。然而，所有模型都远低于专家水平。实验证据表明，这种限制源于预训练模型对国际象棋内部理解的不足。

**Conclusion:** 尽管强化学习和知识蒸馏可以帮助LLM学习国际象棋战略，但预训练模型对国际象棋内部理解的固有缺陷限制了其达到专家水平，RL alone可能无法完全克服。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）通过强化学习（RL）在国际象棋中发展战略推理能力的可能性。研究利用一个国际象棋预训练的行动-价值网络提供密集奖励（视为知识蒸馏），发现这种方法优于稀疏奖励。然而，尽管有这些进展，所有模型都未能达到专家水平。消融研究表明，这种性能瓶颈主要源于LLM预训练阶段对国际象棋内部理解的不足，仅靠RL难以完全弥补。

> **摘要翻译:** 尽管强化学习（RL）在大型语言模型（LLM）的数学推理方面已显示出前景，但LLM利用RL进行战略推理的研究仍 largely 未被探索。我们研究LLM是否能通过在国际象棋中进行RL来发展战略推理能力。为此，我们利用一个国际象棋预训练的行动-价值网络来为LLM的输出走法质量提供密集奖励，这可以看作是一种知识蒸识形式。我们的实验表明，我们基于蒸馏的密集奖励通常优于稀疏二元奖励。然而，令人惊讶的是，所有模型都远低于专家水平。我们对国际象棋推理训练进行了SFT和RL消融实验，并发现证据表明这种限制源于预训练模型对国际象棋内部理解的不足——这种不足仅靠RL可能无法完全克服。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [274] [A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis](https://arxiv.org/abs/2507.00810)
> *针对非独立同分布机器学习问题的鲁棒算法及其收敛性分析*

*Qing Xu, Xiaohua Xuan* | **Category: cs.AI, math.OC**

**Keywords:** Minimax问题, 非光滑优化, 二次规划, 收敛性分析, 鲁棒优化

**Comment:** 

> **TL;DR:** 提出了一种基于非光滑优化、二次规划和迭代过程的改进数值算法，用于解决minimax问题，并提供了严格的收敛性证明。

**AI_Comments:** 该论文的创新之处在于提出了一种结合多种优化技术的数值算法来解决minimax问题，并提供了严格的收敛性分析，这对于确保算法的可靠性至关重要。其重要性在于该算法能够应用于非独立同分布（Non-IID）的机器学习问题，这在现实世界中非常常见。

<details>
  <summary>Details</summary>

**Motivation:** 解决minimax问题，并将其应用于鲁棒优化、不平衡学习等领域。

**Method:** 基于非光滑优化、二次规划和迭代过程，提出了一种改进的数值算法来解决minimax问题。

**Result:** 提供了该算法在梯度连续性和有界性等温和假设下的严格收敛性证明。

**Conclusion:** 该算法在理论上具有收敛性，并可广泛应用于鲁棒优化和不平衡学习等领域。

> **ai_Abstract:** 本文提出了一种改进的数值算法，该算法结合了非光滑优化、二次规划和迭代过程，旨在解决minimax问题。作者为该算法在特定假设下的收敛性提供了严谨的证明，并指出其在鲁棒优化和不平衡学习等领域具有广泛的应用潜力。

> **摘要翻译:** 在本文中，我们提出了一种改进的数值算法，用于解决基于非光滑优化、二次规划和迭代过程的minimax问题。我们还在梯度连续性和有界性等一些温和假设下，为我们的算法提供了严格的收敛性证明。这种算法可以广泛应用于鲁棒优化、不平衡学习等各种领域。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [283] [SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents](https://arxiv.org/abs/2507.00841)
> *SafeMobile：多模态移动智能体链级越狱检测与自动化评估*

*Siyuan Liang, Tianmeng Fang, Zhe Liu, Aishan Liu, Yan Xiao, Jinyuan He, Ee-Chien Chang, Xiaochun Cao* | **Category: cs.AI, cs.CR**

**Keywords:** 越狱检测, 多模态智能体, 移动安全, 自动化评估, 行为序列

**Comment:** 12 pages

> **TL;DR:** 该研究针对多模态移动智能体面临的越狱风险，提出了一种结合行为序列信息的风险识别机制，并设计了基于大语言模型的自动化评估方案，旨在提高风险行为识别能力并降低智能体被越狱的概率。

**AI_Comments:** 该论文创新性地将行为序列信息引入多模态移动智能体的越狱检测中，并提出了基于大语言模型的自动化评估方案，有效弥补了现有安全措施在复杂交互场景下的不足。其重要性在于为保障智能体系统的安全稳定运行提供了新的思路和工具，尤其是在移动设备控制等高风险应用场景中具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着多模态基础模型在智能体系统中的广泛应用，移动设备控制等场景对大模型驱动的智能体依赖日益增加，但同时也面临越狱风险。攻击者可能通过特定输入诱导智能体绕过行为约束，触发修改设置、执行未经授权命令或冒充用户身份等敏感操作，对系统安全构成新挑战。现有安全措施在复杂多轮交互中检测潜在风险行为方面存在局限性，并且缺乏高效、一致的自动化风险评估方法。

**Method:** 该工作探索了移动多模态智能体的安全问题，尝试通过整合行为序列信息构建风险识别机制，并设计了基于大语言模型的自动化辅助评估方案。

**Result:** 通过在多个具有代表性的高风险任务中进行初步验证，结果表明该方法可以在一定程度上提高对风险行为的识别能力，并有助于降低智能体被越狱的概率。

**Conclusion:** 本研究希望为多模态智能体系统的安全风险建模和保护提供有价值的参考。

> **ai_Abstract:** 本研究关注多模态移动智能体日益增长的越狱风险，指出现有安全措施在复杂多轮交互和自动化评估方面的不足。为解决此问题，论文提出了一种创新方法，通过整合行为序列信息构建风险识别机制，并设计了基于大语言模型的自动化评估方案。初步验证结果表明，该方法能有效提高对风险行为的识别能力，并有助于降低智能体被越狱的概率，为多模态智能体系统的安全防护提供了有价值的参考。

> **摘要翻译:** 随着多模态基础模型在智能体系统中的广泛应用，移动设备控制、智能助手交互和多模态任务执行等场景正逐渐依赖于此类大模型驱动的智能体。然而，相关系统也日益暴露于潜在的越狱风险之中。攻击者可能通过特定输入诱导智能体绕过原有的行为约束，进而触发某些高风险和敏感操作，例如修改设置、执行未经授权的命令或冒充用户身份，这给系统安全带来了新的挑战。现有针对智能体的安全措施在面对复杂交互时仍存在局限性，尤其是在检测跨多轮对话或任务序列的潜在风险行为方面。此外，目前还缺乏一种高效且一致的自动化方法来辅助评估和确定此类风险的影响。本工作探讨了围绕移动多模态智能体的安全问题，尝试通过整合行为序列信息构建风险识别机制，并设计了基于大语言模型的自动化辅助评估方案。通过在多个具有代表性的高风险任务中进行初步验证，结果显示该方法在一定程度上可以提高对风险行为的识别，并有助于降低智能体被越狱的概率。我们希望这项研究能为多模态智能体系统的安全风险建模和保护提供一些有价值的参考。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [291] [Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact](https://arxiv.org/abs/2507.00951)
> *超越符号的思考：从类脑智能到通用人工智能的认知基础及其社会影响*

*Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Philip Torr, Seyedali Mirjalili* | **Category: cs.AI**

**Keywords:** 通用人工智能, 认知基础, 代理式RAG, 泛化策略, 类脑智能

**Comment:** 

> **TL;DR:** 本文通过跨学科综合分析，探讨了通用人工智能（AGI）的认知和架构基础，强调了超越当前基于符号预测的局限性，并提出了实现真正智能的关键途径和面临的挑战。

**AI_Comments:** 本文通过对通用人工智能（AGI）的跨学科综合分析，提供了一个超越当前大型语言模型（LLMs）局限性的新颖视角。其创新之处在于强调了认知基础，如模块化推理、持久记忆和多智能体协调，并提出了代理式RAG和泛化策略作为实现更高级智能的关键。论文的价值在于其前瞻性地指出了未来AGI研究的方向，特别是将智能视为记忆和推理的整合而非单纯的规模扩张。然而，作为一篇概念性综述，它并未提供具体的模型或实验结果，更多是理论框架和方向性指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管当前大型语言模型（如GPT-4.5, Claude 3.5 Sonnet等）展现出强大的多模态流畅性和部分推理能力，但它们仍受限于基于符号预测和缺乏具身能动性。本文旨在探讨如何超越这些局限，实现真正的通用人工智能（AGI）。

**Method:** 本文采用跨学科综合分析的方法，结合人工智能、认知神经科学、心理学、生成模型和基于代理的系统等领域的知识，分析通用智能的架构和认知基础。特别强调了代理式RAG框架、泛化策略（如信息压缩、测试时适应、免训练方法），并重新审视了视觉-语言模型（VLMs）的作用。

**Result:** 研究强调了模块化推理、持久记忆和多智能体协调在通用智能中的作用。提出智能并非仅源于规模，而是记忆和推理的整合，即模块化、交互式和自改进组件的协同。讨论了代理式RAG框架如何通过检索、规划和动态工具使用实现更具适应性的行为。同时，探索了神经符号系统、强化学习和认知支架的进展如何弥合统计学习和目标导向认知之间的鸿沟。

**Conclusion:** 本文识别了实现通用人工智能（AGI）道路上的关键科学、技术和伦理挑战。

> **ai_Abstract:** 本文对通用人工智能（AGI）的发展进行了跨学科综合分析，旨在超越当前大型语言模型基于符号预测的局限。论文深入探讨了通用智能的认知和架构基础，强调了模块化推理、持久记忆和多智能体协调的重要性。文中特别突出了代理式RAG框架在实现适应性行为方面的潜力，并讨论了信息压缩等泛化策略。此外，文章重新审视了视觉-语言模型作为具身理解接口的角色，并指出真正的智能源于记忆与推理的整合。最后，论文指出了实现AGI所面临的科学、技术和伦理挑战。

> **摘要翻译:** 机器能否像人类一样真正地思考、推理和行动？这个持久的问题持续塑造着对通用人工智能（AGI）的追求。尽管GPT-4.5、DeepSeek、Claude 3.5 Sonnet、Phi-4和Grok 3等模型的能力日益增强，展现出多模态流畅性和部分推理能力，但这些系统仍然受限于它们对符号级预测的依赖和缺乏具身能动性。本文对AGI发展进行了跨学科综合，涵盖了人工智能、认知神经科学、心理学、生成模型和基于代理的系统。我们分析了通用智能的架构和认知基础，强调了模块化推理、持久记忆和多智能体协调的作用。特别是，我们强调了代理式RAG框架的兴起，它结合了检索、规划和动态工具使用，以实现更具适应性的行为。我们讨论了泛化策略，包括信息压缩、测试时适应和免训练方法，作为实现灵活、领域无关智能的关键途径。视觉-语言模型（VLMs）不仅被重新审视为感知模块，而且是具身理解和协作任务完成的演进接口。我们还认为，真正的智能并非仅源于规模，而是记忆和推理的整合：模块化、交互式和自改进组件的协同，其中压缩能够实现适应性行为。借鉴神经符号系统、强化学习和认知支架的进展，我们探讨了最近的架构如何开始弥合统计学习和目标导向认知之间的鸿沟。最后，我们识别了实现AGI道路上的关键科学、技术和伦理挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [300] [Enhancing LLM Agent Safety via Causal Influence Prompting](https://arxiv.org/abs/2507.00979)
> *通过因果影响提示增强LLM智能体的安全性*

*Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee* | **Category: cs.AI, cs.CL, cs.LG**

**Keywords:** LLM智能体, 安全性, 因果影响图, 风险缓解, 自主智能体

**Comment:** Accepted at ACL 2025 Findings, Source code:
  https://github.com/HahmDY/causal_influence_prompting.git

> **TL;DR:** 本文提出了一种名为因果影响提示（CIP）的新技术，该技术利用因果影响图（CID）来识别和减轻大型语言模型（LLM）驱动的自主智能体决策中产生的风险，从而提高其安全性。

**AI_Comments:** 本文的创新之处在于利用因果影响图（CIDs）为LLM智能体的安全决策提供了一个结构化且可迭代优化的框架，这有助于智能体主动预测和规避风险，而非仅仅被动响应。这为提高LLM智能体的可靠性和减少意外后果提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）驱动的自主智能体在各种辅助任务中展现出潜力，确保其安全可靠的行为对于防止意外后果至关重要。

**Method:** 本文提出了一种名为因果影响提示（CIP）的新技术，该技术利用因果影响图（CID）来识别和减轻智能体决策中产生的风险。该方法包括三个关键步骤：1）根据任务规范初始化CID以概述决策过程；2）使用CID指导智能体与环境的交互；3）根据观察到的行为和结果迭代优化CID。

**Result:** 实验结果表明，该方法能有效提高代码执行和移动设备控制任务的安全性。

**Conclusion:** 本文提出的因果影响提示（CIP）方法通过利用因果影响图（CID）成功地增强了大型语言模型（LLM）智能体的安全性，有效减轻了其决策过程中可能出现的风险。

> **ai_Abstract:** 本文提出了一种名为因果影响提示（CIP）的新型技术，旨在增强大型语言模型（LLM）驱动的自主智能体的安全性。CIP通过利用因果影响图（CIDs）来结构化地表示因果关系，从而使智能体能够预测并避免潜在的有害结果。该方法包含初始化、指导交互和迭代优化CID三个步骤。实验证明，该方法在代码执行和移动设备控制任务中均能有效提升智能体的安全性。

> **摘要翻译:** 随着大型语言模型（LLM）驱动的自主智能体在各种辅助任务中持续展现潜力，确保其安全可靠的行为对于防止意外后果至关重要。在这项工作中，我们引入了CIP，这是一种新颖的技术，它利用因果影响图（CIDs）来识别和减轻智能体决策中产生的风险。CIDs提供了一种结构化的因果关系表示，使智能体能够预测有害结果并做出更安全的决策。我们的方法包括三个关键步骤：（1）根据任务规范初始化CID以概述决策过程，（2）使用CID指导智能体与环境的交互，以及（3）根据观察到的行为和结果迭代优化CID。实验结果表明，我们的方法能有效提高代码执行和移动设备控制任务的安全性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [12] [Hypertokens: Holographic Associative Memory in Tokenized LLMs](https://arxiv.org/abs/2507.00002)
> *超令牌：标记化大型语言模型中的全息联想记忆*

*Christopher James Augeri* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 超令牌, 全息联想记忆, 大型语言模型, 纠错码, HDRAM

**Comment:** preprint as accepted to https://qnlp.ai/ - Quantum AI and NLP
  Conference 2025

> **TL;DR:** 该研究提出HDRAM，一个基于超令牌的全息联想记忆框架，通过结合经典纠错码、全息计算和量子启发搜索，解决LLM中的信息扩散和精度损失问题，无需架构修改即可显著提升联想检索能力。

**AI_Comments:** 这篇论文的创新点在于将信息扩散问题重新定义为通信问题，并引入了HDRAM框架，巧妙地将经典纠错码、全息计算和量子启发搜索等跨领域原理融合，形成了“超令牌”这一新概念。它提供了一种无需改变现有LLM架构即可提升记忆和检索能力的方法，为解决LLM的精度损失提供了一个全新的视角和有效的解决方案。这种多学科交叉的方法论具有很高的启发性和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽然能力显著，但存在明显的精度损失问题，本文将其重新定义为信息扩散，并将其视为一个信息论上的通信问题，旨在解决LLM中的K:V和V:K记忆问题。

**Method:** 本研究通过引入HDRAM（全息定义随机存取记忆）来解决问题。HDRAM是一个符号记忆框架，将Transformer的潜在空间视为一个扩频信道。它基于超令牌构建，超令牌是整合了经典纠错码（ECC）、全息计算和量子启发搜索的结构化符号代码。HDRAM通过原则性的解扩来恢复分布式信息，利用相位相干的记忆地址实现高效的键值操作和Grover式搜索。通过结合ECC语法与压缩感知和Krylov子空间对齐，HDRAM在不改变架构的情况下显著改善了联想检索。

**Result:** HDRAM在不改变Transformer架构的情况下，显著改善了联想检索能力。

**Conclusion:** HDRAM展示了经典-全息-量子启发（CHQ）原理如何能够强化Transformer架构，有效解决了LLM中的信息扩散和记忆问题。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）中存在的精度损失和信息扩散问题，提出了一种名为HDRAM（全息定义随机存取记忆）的创新性符号记忆框架。HDRAM将Transformer的潜在空间视为扩频信道，并基于结合了经典纠错码、全息计算和量子启发搜索的“超令牌”构建。该框架通过原则性的解扩和相位相干的记忆地址，实现了高效的键值操作和Grover式搜索，并在不改变LLM现有架构的前提下，显著提升了联想检索性能，证明了经典-全息-量子启发（CHQ）原理在强化Transformer架构方面的潜力。

> **摘要翻译:** 大型语言模型（LLMs）展现出卓越的能力，但却遭受明显的精度损失，本文将其重新定义为信息扩散。这种重新定义将问题从计算精度转移到信息论上的通信问题。我们通过引入HDRAM（全息定义随机存取记忆）来解决LLMs中的K:V和V:K记忆问题，HDRAM是一个符号记忆框架，将Transformer潜在空间视为一个扩频信道。HDRAM基于超令牌构建，超令牌是整合了经典纠错码（ECC）、全息计算和量子启发搜索的结构化符号代码，通过原则性的解扩来恢复分布式信息。这些相位相干的记忆地址实现了潜在空间中高效的键值操作和Grover式搜索。通过将ECC语法与压缩感知和Krylov子空间对齐相结合，HDRAM在不改变架构的情况下显著改善了联想检索，展示了经典-全息-量子启发（CHQ）原理如何能够强化Transformer架构。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [28] [Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE](https://arxiv.org/abs/2507.00003)
> *何时不决定：基于不确定性感知的NeutroSENSE入侵检测*

*Eyhab Al-Masri* | **Category: cs.LG, cs.AI, cs.CR, cs.NI**

**Keywords:** 入侵检测, 中智逻辑, 不确定性量化, 物联网安全, 可解释AI

**Comment:** 

> **TL;DR:** NeutroSENSE是一个结合中智逻辑的集成框架，用于物联网入侵检测，能通过不确定性量化实现高准确率和可解释的决策，特别是在边缘部署中。

**AI_Comments:** 这项工作的创新之处在于将中智逻辑引入到集成学习框架中，以量化和利用预测的不确定性，从而在入侵检测中实现“何时不决定”的能力。这显著增强了AI决策的可信度和可解释性，特别是在对实时性和可靠性要求高的物联网边缘部署中具有重要意义。通过将不确定性作为代理来支持人工审查，该方法提供了一个实用的人机协作AI范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的物联网入侵检测系统可能缺乏对不确定性的量化，导致在关键时刻做出不可信的决策。本文旨在通过引入不确定性感知来增强物联网环境中的入侵检测的可信度和可解释性，尤其是在边缘部署中。

**Method:** 本文提出了NeutroSENSE框架，该框架将随机森林、XGBoost和逻辑回归等机器学习模型与中智逻辑相结合。该系统将预测置信度分解为真(T)、假(F)和不确定性(I)分量，从而实现不确定性量化和决策弃权。对于高不确定性的预测，系统会使用全局和自适应的类特定阈值进行标记以供人工审查。

**Result:** 在IoT-CAD数据集上，NeutroSENSE实现了97%的准确率。实验结果表明，误分类样本的不确定性(I = 0.62)显著高于正确分类样本(I = 0.24)。研究还验证了I得分与错误可能性之间的强相关性。

**Conclusion:** 中智逻辑能够有效提高入侵检测的准确性和可解释性，为边缘和雾计算物联网安全系统中的可信AI提供了实用基础。利用不确定性作为不确定性的代理，支持知情弃权和有针对性的审查，尤其适用于边缘部署，有助于实现更值得信赖的人机协作AI决策。

> **ai_Abstract:** NeutroSENSE是一个针对物联网入侵检测的可解释的集成框架。它结合了多种机器学习模型和中智逻辑，将预测置信度分解为真、假和不确定性分量，从而量化不确定性并支持决策弃权。该系统在IoT-CAD数据集上实现了97%的准确率，并证明了不确定性得分与错误预测之间的强相关性。这为在边缘和雾计算环境中构建可信赖、人机协作的AI安全系统提供了可行方案。

> **摘要翻译:** 这篇论文介绍了NeutroSENSE，一个中智增强的集成框架，用于物联网环境中可解释的入侵检测。通过将随机森林、XGBoost和逻辑回归与中智逻辑相结合，该系统将预测置信度分解为真(T)、假(F)和不确定性(I)分量，从而实现不确定性量化和弃权。具有高不确定性的预测会使用全局和自适应的、特定于类别的阈值进行标记以供审查。在IoT-CAD数据集上进行评估，NeutroSENSE实现了97%的准确率，同时表明错误分类样本表现出比正确分类样本显著更高的不确定性(I = 0.62 vs I = 0.24)。利用不确定性作为不确定性的代理，可以实现知情弃权和有针对性的审查——这在边缘部署中尤为宝贵。图表验证了I得分与错误可能性之间的相关性，支持更值得信赖的、人机协作的AI决策。这项工作表明，中智逻辑增强了准确性和可解释性，为边缘和雾计算物联网安全系统中的可信AI提供了实用基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [48] [A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search](https://arxiv.org/abs/2507.00004)
> *推理计算扩展理论：通过定向随机技能搜索进行推理*

*Austin R. Ellis-Mohr, Anuj K. Nayak, Lav R. Varshney* | **Category: cs.LG, cs.AI, cs.CY, cs.PF**

**Keywords:** 大型语言模型, 推理计算, 扩展定律, 定向随机技能搜索, 思维链

**Comment:** 

> **TL;DR:** 本文提出了一种名为定向随机技能搜索（DS3）的通用框架，用于分析大型语言模型（LLM）的推理计算成本和任务成功率。该框架通过统一的分析方法，解释了推理中的多种经验观察模式，并为算法设计和资源分配提供了理论基础。

**AI_Comments:** 这项工作在理解LLM推理成本和效率方面具有重要创新性。它提供了一个统一的理论框架，能够解释和预测多种复杂的推理行为，而这些行为此前多是经验观察到的。DS3框架不仅深化了对LLM推理过程的理解，还为未来优化LLM的算法设计和资源分配提供了坚实的理论基础，特别是在平衡计算成本与推理能力方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在训练和部署过程中需要大量的计算、能源和财务资源。虽然训练的扩展定律已指导了该领域的大部分进展，但推理成本，特别是对于侧重推理的模型，正成为整体资源负担中一个显著且不断增长的组成部分。现有的计算最优性表征可能忽视更高效的操作点。

**Method:** 本文引入了定向随机技能搜索（DS3），这是一个将推理表示为学习技能图上随机遍历的通用框架。从一个简化而富有表现力的实例中，作者推导出了在各种推理策略（包括思维链CoT和思维树ToT）下任务成功率和计算成本的闭式表达式，从而能够根据任务难度和模型能力进行比较分析。此外，该框架扩展了先前关于LLM训练的三方图框架以包含推理，并结合了表征LLM扩展行为的经验方法。

**Result:** 该理论恢复了经验观察到的模式，包括：精度随对数计算量线性扩展；首选推理策略随任务难度和模型能力的函数而变化；即使在参数扩展下性能趋于平稳时，推理也能引发涌现行为；以及最佳N（BoN）和多数投票行为都被统一的分析框架捕获。

**Conclusion:** 通过明确表征训练-推理的相互依赖性，该框架加深了理论理解，并支持原则性的算法设计和资源分配。

> **ai_Abstract:** 本研究提出了定向随机技能搜索（DS3）框架，旨在理论化大型语言模型（LLMs）的推理计算扩展。该框架将推理视为学习技能图上的随机遍历，并推导出任务成功率和计算成本的闭式表达式，覆盖了CoT和ToT等多种推理策略。通过将DS3与LLM训练框架和经验方法相结合，该理论成功解释了包括精度对数线性扩展、推理策略变化、涌现行为以及BoN和多数投票等多种经验观察到的推理模式。该工作为理解训练-推理依赖性、指导算法设计和资源分配提供了新的理论视角。

> **摘要翻译:** 大型语言模型（LLMs）在训练和部署过程中需要大量的计算、能源和财务资源。虽然训练的扩展定律已指导了该领域的大部分进展，但推理成本，特别是对于侧重推理的模型，正成为整体资源负担中一个显著且不断增长的组成部分。现有的计算最优性表征，孤立地或以固定组合考虑模型大小、数据集大小和推理令牌，可能忽视更高效的操作点。我们引入了定向随机技能搜索（DS3），这是一个将推理表示为学习技能图上随机遍历的通用框架。从一个简化而富有表现力的实例中，我们推导出了在各种推理策略（包括思维链（CoT）和思维树（ToT））下任务成功率和计算成本的闭式表达式，从而能够根据任务难度和模型能力进行比较分析。为此，我们扩展了先前关于LLM训练的第一个原则三方图框架以包含推理，并单独将DS3与表征LLM扩展行为的经验方法相结合。我们理论上恢复了经验观察到的模式，包括：精度随对数计算量线性扩展；首选推理策略随任务难度和模型能力的函数而变化；即使在参数扩展下性能趋于平稳时，推理也能引发涌现行为；以及最佳N（BoN）和多数投票行为都被统一的分析框架捕获。通过明确表征训练-推理的相互依赖性，我们的框架加深了理论理解，并支持原则性的算法设计和资源分配。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [57] [Data Collection with Non-Uniform Axial Power for Phase II of the OECD/NEA AI/ML Critical Heat Flux Benchmark](https://arxiv.org/abs/2507.00034)
> *OECD/NEA AI/ML 临界热通量基准第二阶段非均匀轴向功率数据收集*

*Reece Bourisaw, Reid McCants, Jean-Marie Le Corre, Anna Iskhakova, Arsen S. Iskhakov* | **Category: cs.LG, cs.CE**

**Keywords:** 临界热通量, 非均匀加热, 数据集, AI/ML基准, 核反应堆

**Comment:** 

> **TL;DR:** 为支持OECD/NEA AI/ML临界热通量基准的第二阶段，本研究编译并数字化了包含均匀和非均匀轴向加热条件的临界热通量数据集，以应对现有模型在非均匀功率分布下的预测不足问题，并为未来AI/ML模型开发奠定基础。

**AI_Comments:** 本文的主要创新在于为AI/ML模型在核反应堆热工水力领域，特别是临界热通量（CHF）预测中，提供了首个包含非均匀轴向功率分布的标准化、机器可读的数据集。这对于克服现有模型在复杂加热条件下的局限性至关重要。其重要性体现在为AI/ML研究提供了坚实的基础，特别是在迁移学习、不确定性量化和设计优化方面，有望显著提升核反应堆运行的安全性与效率。

<details>
  <summary>Details</summary>

**Motivation:** 临界热通量（CHF）定义了轻水反应堆的安全热工水力运行极限。经典CHF关联式在均匀加热下存在显著误差，在非均匀剖面下性能显著下降；现代表格方法虽有改进但仍不完善。一个仅在均匀数据上训练的神经网络在该区域表现良好，但无法推广到空间变化的场景，这凸显了需要明确纳入轴向功率分布的模型的需求。本工作旨在支持OECD/NEA AI/ML CHF基准的第二阶段，该阶段引入了空间变化的功率剖面。

**Method:** 本研究编译并数字化了一个广泛的临界热通量（CHF）数据集，涵盖均匀和非均匀轴向加热条件。加热剖面从技术报告中提取，插值到一致的轴向网格上，通过能量平衡检查进行验证，并编码成机器可读的格式以兼容基准测试。

**Result:** 经典临界热通量（CHF）关联式在均匀加热条件下表现出显著误差，在应用于非均匀剖面时性能显著下降。现代表格方法提供了改进但仍不完美的预测。一个仅在均匀数据上训练的神经网络在该区域表现良好，但未能推广到空间变化的场景，这强调了需要明确纳入轴向功率分布的模型。

**Conclusion:** 本研究通过提供这些精心策划的数据集和基线建模结果，为临界热通量（CHF）基准下一阶段的先进迁移学习策略、严格不确定性量化和设计优化工作奠定了基础，并强调了开发明确纳入轴向功率分布的模型的必要性。

> **ai_Abstract:** 本研究为OECD/NEA AI/ML临界热通量（CHF）基准的第二阶段提供了关键数据支持，该阶段引入了非均匀轴向功率分布。研究编译并数字化了一个包含均匀和非均匀加热条件下的CHF数据集，并详细说明了数据处理和验证过程。通过评估现有CHF关联式和基于均匀数据训练的神经网络，揭示了它们在处理非均匀功率剖面时的局限性。本工作强调了开发能够明确纳入轴向功率分布的AI/ML模型的必要性，并为未来的高级建模和优化奠定了基础。

> **摘要翻译:** 临界热通量（CHF）标志着轻水反应堆沸腾危机的发生，定义了安全的热工水力运行极限。为支持OECD/NEA AI/ML CHF基准的第二阶段，该阶段引入了空间变化的功率剖面，本工作编译并数字化了一个广泛的CHF数据集，涵盖均匀和非均匀轴向加热条件。加热剖面从技术报告中提取，插值到一致的轴向网格上，通过能量平衡检查进行验证，并编码成机器可读的格式以兼容基准测试。
经典的CHF关联式在均匀加热下表现出显著误差，在应用于非均匀剖面时性能显著下降，而现代表格方法提供了改进但仍不完善的预测。一个仅在均匀数据上训练的神经网络在该区域表现良好，但未能推广到空间变化的场景，这强调了需要明确纳入轴向功率分布的模型。通过提供这些精心策划的数据集和基线建模结果，本研究为CHF基准下一阶段的先进迁移学习策略、严格不确定性量化和设计优化工作奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [68] [Novel RL approach for efficient Elevator Group Control Systems](https://arxiv.org/abs/2507.00011)
> *新颖的强化学习方法用于高效电梯群控系统*

*Nathan Vaartjes, Vincent Francois-Lavet* | **Category: cs.LG, cs.AI**

**Keywords:** 强化学习, 电梯群控系统, 马尔可夫决策过程, Dueling Double Deep Q-learning, 交通管理

**Comment:** 15 pages, 12 figures

> **TL;DR:** 本文提出一种新颖的强化学习（RL）方法，用于电梯群控系统（EGCS），通过建模为马尔可夫决策过程并采用Dueling Double Deep Q-learning，解决了传统控制器在处理随机和组合复杂性方面的不足，实现了对交通模式的适应并超越了传统规则算法。

**AI_Comments:** 这篇论文通过将电梯群控问题转化为强化学习任务，并引入多项创新（如动作空间编码、infra-steps和定制奖励），有效地解决了传统方法在处理随机性和组合复杂性方面的不足。其创新性在于将复杂的实际系统成功建模为RL问题，并展示了RL在实时控制系统中的巨大潜力。这项研究对于提升大型建筑的交通效率和能源管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型建筑中高效的电梯交通管理对于最小化乘客旅行时间和能源消耗至关重要。传统的启发式或模式检测控制器难以处理调度中的随机性和组合复杂性。

**Method:** 将阿姆斯特丹自由大学的六部电梯、十五层系统建模为马尔可夫决策过程（MDP），并训练一个端到端强化学习（RL）电梯群控系统（EGCS）。主要创新包括：新颖的动作空间编码以处理组合复杂性，引入“infra-steps”来模拟连续乘客到达，以及定制的奖励信号以提高学习效率。还探索了调整折扣因子以适应“infra-step”公式的方法。RL架构基于Dueling Double Deep Q-learning。

**Result:** 所提出的基于RL的EGCS能够适应波动的交通模式，从高度随机的环境中学习，并且优于传统的基于规则的算法。

**Conclusion:** 基于强化学习的电梯群控系统能够有效应对复杂的电梯调度问题，展现出优于传统方法的性能和对随机环境的适应性。

> **ai_Abstract:** 本文提出了一种新颖的强化学习（RL）方法，用于构建高效的电梯群控系统（EGCS），以应对大型建筑中电梯调度的复杂性。研究将一个实际的电梯系统建模为马尔可夫决策过程，并利用Dueling Double Deep Q-learning训练了一个端到端的RL控制器。该方法引入了创新的动作空间编码、infra-steps概念和定制奖励信号。实验结果表明，所提出的RL-EGCS能够适应多变的交通模式，并显著优于传统的规则算法。

> **摘要翻译:** 电梯群控系统高效强化学习新方法
在大型建筑中，高效的电梯交通管理对于最小化乘客旅行时间和能源消耗至关重要。由于启发式或模式检测控制器难以处理调度的随机性和组合性质，我们将阿姆斯特丹自由大学的六部电梯、十五层系统建模为马尔可夫决策过程，并训练了一个端到端强化学习（RL）电梯群控系统（EGCS）。主要创新包括：处理电梯调度组合复杂性的新颖动作空间编码，引入“infra-steps”以模拟连续乘客到达，以及定制的奖励信号以提高学习效率。此外，我们探索了多种方法来调整折扣因子以适应“infra-step”公式。我们研究了基于Dueling Double Deep Q-learning的RL架构，结果表明所提出的基于RL的EGCS能够适应波动的交通模式，从高度随机的环境中学习，从而优于传统的基于规则的算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [73] [What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness](https://arxiv.org/abs/2507.00195)
> *局部更新为何有效：数据异质性和平滑度的作用*

*Kumar Kshitij Patel* | **Category: cs.LG, cs.AI, cs.MA, math.OC, stat.ML**

**Keywords:** 局部更新, 数据异质性, 联邦学习, Local SGD, 收敛性分析

**Comment:** 

> **TL;DR:** 本论文从理论上分析了在数据异质性下局部更新算法（特别是Local SGD）的有效性，指出有界二阶异质性是其优于中心化方法的关键，并提供了详细的收敛界限和分析框架。

**AI_Comments:** 这篇论文通过深入的理论分析，特别是引入有界二阶异质性假设，为理解局部更新算法在数据异质性环境中的有效性提供了坚实的理论基础。其提出的细粒度分析框架和对收敛界限的刻画，对于分布式和联邦学习的算法设计与优化具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本论文旨在对分布式和联邦优化中局部更新算法（特别是Local SGD）在数据异质性真实模型下的理论理解做出贡献。

**Method:** 本论文关注有界二阶异质性假设，并提出了一个基于共识误差的细粒度分析框架。通过建立紧密的上下界、刻画最小-最大复杂度，以及扩展到在线联邦学习，来分析各种局部更新算法。

**Result:** 1. 证明了有界二阶异质性假设是局部更新在凸和非凸设置下优于中心化或小批量方法的必要和充分条件。2. 建立了各种局部更新算法在多个机制下的紧密上下界。3. 刻画了多个问题类的最小-最大复杂度。4. 在三阶平滑和宽松异质性假设下，提供了更尖锐的有限时间收敛界限。5. 为在线联邦学习在零阶和强盗反馈下提供了基本的遗憾界限。

**Conclusion:** 这些结果阐明了局部更新何时以及为何提供可证明的优势，并且本论文为在异构环境中分析Local SGD提供了一个独立的指南。

> **ai_Abstract:** 本论文从理论上深入探讨了分布式和联邦优化中局部更新算法的有效性，特别关注Local SGD在数据异质性下的表现。研究发现，有界二阶异质性是局部更新优于传统方法的关键条件。论文建立了一系列紧密收敛界限和最小-最大复杂度，并提出了一个基于共识误差的分析框架，为理解和分析异构环境下的局部更新算法提供了全面的指导。

> **摘要翻译:** 本论文旨在对分布式和联邦优化中局部更新算法，特别是局部随机梯度下降（Local SGD）在真实数据异质性模型下的理论理解做出贡献。其核心关注点是有界二阶异质性假设，该假设被证明是局部更新在凸和非凸设置下优于中心化或小批量方法的必要和充分条件。本论文在多种机制下为各种局部更新算法建立了紧密的上下界，并刻画了多个问题类的最小-最大复杂度。其核心是一个细粒度的基于共识误差的分析框架，该框架在三阶平滑和宽松异质性假设下产生了更尖锐的有限时间收敛界限。本论文还扩展到在线联邦学习，在零阶和强盗反馈下提供了基本的遗憾界限。总而言之，这些结果阐明了局部更新何时以及为何提供可证明的优势，并且本论文为在异构环境中分析局部随机梯度下降提供了一个独立的指南。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [90] [Towards Undistillable Models by Minimizing Conditional Mutual Information](https://arxiv.org/abs/2507.00012)
> *通过最小化条件互信息实现不可蒸馏模型*

*Linfeng Ye, Shayan Mohajer Hamidi, En-hui Yang* | **Category: cs.LG, cs.AI, E.4**

**Keywords:** 知识蒸馏, 不可蒸馏模型, 条件互信息, 模型保护, 深度神经网络

**Comment:** 27 pages, 6 figures, Transactions on Machine Learning Research

> **TL;DR:** 提出了一种名为CMIM的新训练方法，通过最小化条件互信息来构建不可蒸馏的深度神经网络，保护模型知识产权，同时提高自身预测精度。

**AI_Comments:** 该论文提出了一种新颖的方法来解决深度学习模型知识产权保护的重要问题。通过引入条件互信息作为衡量模型可蒸馏性的指标，并将其整合到训练损失中，实现了“不可蒸馏”模型的构建。这对于商业应用中模型保护具有重要意义。创新点在于将信息论概念应用于模型防御，但其对模型性能和泛化能力可能带来的潜在影响值得进一步研究，以及在更广泛、更复杂的蒸馏攻击场景下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 保护深度神经网络（DNN）的知识产权，使其在作为黑盒教师模型时，无法通过知识蒸馏（KD）被有效复制，即蒸馏出的学生模型（仿冒学生）在预测精度上不优于独立训练的学生模型（LS学生。

**Method:** 基于观察到不可蒸馏的DNN的输出概率分布簇应高度集中（理想情况下每个标签的簇坍缩为单一概率分布），并使用条件互信息（CMI）来衡量簇的集中度。提出了一种名为CMIM（CMI minimized）的新训练方法，该方法通过联合最小化传统的交叉熵（CE）损失和整个温度谱上所有温度缩放簇的CMI值来训练DNN。

**Result:** 通过大量实验证明，所提出的CMIM模型对于文献中所有已测试的知识蒸馏方法都是不可蒸馏的，即通过这些KD方法从CMIM模型中蒸馏出的仿冒学生模型性能不如相应的LS学生模型。此外，CMIM模型在自身的预测精度方面也优于仅使用CE损失训练的模型。

**Conclusion:** 通过最小化条件互信息，可以构建出不可蒸馏的深度神经网络，有效保护模型知识产权，同时还能提升模型自身的预测性能。

> **ai_Abstract:** 本文提出了一种名为CMI最小化（CMIM）的新训练方法，旨在构建不可蒸馏的深度神经网络，以保护其知识产权。通过观察到不可蒸馏模型的输出概率分布簇应高度集中，并利用条件互信息（CMI）衡量这种集中度，CMIM方法联合最小化了传统的交叉熵损失和CMI值。实验结果表明，CMIM模型对于现有知识蒸馏方法是不可蒸馏的，即从其蒸馏出的学生模型性能不佳，并且CMIM模型自身的预测精度也得到了提升。

> **摘要翻译:** 一个深度神经网络（DNN）被称为是不可蒸馏的，如果它在作为黑盒输入输出教师模型时，不能通过知识蒸馏（KD）进行蒸馏。在这种情况下，蒸馏出的学生模型（称为仿冒学生）在预测精度方面不优于使用标签平滑（LS学生）独立训练的学生模型。为了保护DNN的知识产权，构建不可蒸馏的DNN是理想的。为此，首先观察到不可蒸馏的DNN可能具有以下特性：其对所有具有相同标签的样本实例的输出概率分布的每个簇应该高度集中，以至于每个对应于每个标签的簇理想情况下应坍缩成一个概率分布。基于这一观察，并通过条件互信息（CMI）来衡量每个簇的集中度，提出了一种名为CMI最小化（CMIM）的新训练方法，该方法通过联合最小化传统的交叉熵（CE）损失和整个温度谱上所有温度缩放簇的CMI值来训练DNN。通过大量实验表明，所得到的CMIM模型对于文献中所有已测试的KD方法都是不可蒸馏的。也就是说，这些KD方法从CMIM模型中蒸馏出的仿冒学生模型性能不如相应的LS学生模型。此外，CMIM模型在自身的预测精度方面也优于仅使用CE损失训练的模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [114] [ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting](https://arxiv.org/abs/2507.00013)
> *ST-MTM：基于季节-趋势分解的掩码时间序列建模用于时间序列预测*

*Hyunwoo Seo, Chiehyeon Lim* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 时间序列预测, 掩码时间序列建模, 季节-趋势分解, 对比学习

**Comment:** Accepted by KDD 2025 research track

> **TL;DR:** ST-MTM通过季节-趋势分解改进了掩码时间序列建模，并结合特定的掩码策略和对比学习，从而在时间序列预测方面取得了卓越的性能。

**AI_Comments:** ST-MTM的创新点在于将季节-趋势分解引入掩码时间序列建模，并针对分解后的季节和趋势分量设计了独特的、有针对性的掩码策略，辅以对比学习。这有效解决了传统掩码建模在处理复杂时间序列时可能学习到虚假模式的问题，通过更好地捕获时间序列的内在语义结构，显著提升了复杂时间序列的预测精度。该方法为时间序列分析提供了一个更鲁棒和有效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 复杂时间序列预测是一个重要但具有挑战性的问题。现有的掩码时间序列建模（MTM）简单地掩码原始时间序列，忽略了时间序列中固有的语义结构，这可能导致MTM学习到数据中虚假的时间模式。

**Method:** 本文提出了ST-MTM，一个结合季节-趋势分解的掩码时间序列建模框架。它为季节分量采用周期掩码策略以处理固有的多周期性，并为趋势分量采用子序列掩码策略以掩码具有相似变化的时间区域。此外，ST-MTM引入了一个对比学习任务，通过增强多个掩码季节表示之间的上下文一致性来支持掩码建模。

**Result:** 实验结果表明，我们提出的ST-MTM与现有掩码建模、对比学习和监督预测方法相比，取得了持续优越的预测性能。

**Conclusion:** ST-MTM通过结合季节-趋势分解和新颖的掩码策略，有效解决了复杂时间序列预测中现有掩码建模的局限性，并取得了卓越的预测性能。

> **ai_Abstract:** 本文提出了ST-MTM，一个新颖的掩码时间序列建模框架，通过结合季节-趋势分解解决了传统掩码建模忽略时间序列固有语义结构的局限性。ST-MTM为季节分量和趋势分量设计了独特的掩码策略（周期掩码和子序列掩码），并引入了对比学习任务以增强上下文一致性。实验结果表明，ST-MTM在时间序列预测性能上持续优于现有方法。

> **摘要翻译:** 预测复杂时间序列是一个重要但具有挑战性的问题，涉及各种工业应用。最近，掩码时间序列建模被提出，通过从非掩码段重建掩码段来有效建模时间依赖性以进行预测。然而，由于时间序列中的语义信息涉及由多个时间序列分量产生的复杂时间变化，简单地掩码原始时间序列会忽略固有的语义结构，这可能导致MTM学习到原始数据中存在的虚假时间模式。为了捕获不同的时间语义，我们表明掩码建模技术应通过分解方法解决纠缠模式。具体来说，我们提出了ST-MTM，一个结合季节-趋势分解的掩码时间序列建模框架，其中包括一种新颖的季节-趋势分量掩码方法，该方法结合了每个分量不同的时间变化。ST-MTM对季节分量使用周期掩码策略，根据固有的多周期性生成多个掩码季节序列，并对趋势分量使用子序列掩码策略，以掩码共享相似变化的时间区域。所提出的掩码方法为学习复杂的时间变化和依赖性提供了一个有效的预训练任务。此外，ST-MTM引入了一个对比学习任务，通过增强多个掩码季节表示之间的上下文一致性来支持掩码建模。实验结果表明，我们提出的ST-MTM与现有掩码建模、对比学习和监督预测方法相比，取得了持续优越的预测性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [137] [SWE-Bench-CL: Continual Learning for Coding Agents](https://arxiv.org/abs/2507.00014)
> *SWE-Bench-CL：面向编程代理的持续学习*

*Thomas Joshi, Shayan Chowdhury, Fatih Uysal* | **Category: cs.LG, cs.AI, cs.SE**

**Keywords:** 持续学习, 编程代理, 软件工程, 基准, 灾难性遗忘

**Comment:** 

> **TL;DR:** SWE-Bench-CL引入了一个新的持续学习基准，用于评估编程代理在模拟真实世界软件开发中积累经验、转移知识和抵抗灾难性遗忘的能力，并提供评估框架和指标。

**AI_Comments:** SWE-Bench-CL的创新之处在于其将持续学习的概念引入到编程代理的评估中，这对于模拟真实世界软件开发的动态性至关重要。通过构建时间序列化的GitHub问题数据集，并提供全面的评估框架和指标，它为研究如何使AI代理更具适应性、能够从经验中学习并抵抗灾难性遗忘提供了一个宝贵且可复现的平台。这对于开发能够长期维护和改进软件的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型在静态代码生成基准上表现出色，但现实世界的软件开发是一个持续演进的过程，包含不断出现的问题、修复和功能请求。因此，需要一个新的基准来评估编程代理在这种持续动态环境下的学习能力。

**Method:** 本文引入了SWE-Bench-CL，这是一个基于人类验证的SWE-Bench Verified数据集构建的持续学习基准。它通过将GitHub问题按时间顺序组织成序列，以反映代码库的自然演变，从而评估代理积累经验、跨任务迁移知识和抵抗灾难性遗忘的能力。该基准还辅以对任务间结构相似性和上下文敏感性的初步分析、一个基于LangGraph的交互式评估框架（带有FAISS支持的语义记忆模块），以及一套专门的持续学习指标（包括平均准确度、遗忘、前向/后向迁移、工具使用效率、广义复合持续学习分数和CL-F-beta分数）来捕捉稳定性-可塑性权衡。作者还概述了一个严格的实验协议，用于比较有记忆和无记忆的代理在不同Python仓库中的表现。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了SWE-Bench-CL，一个针对编程代理的持续学习新基准，旨在弥合静态代码生成与动态、持续演进的真实世界软件开发之间的差距。该基准基于SWE-Bench Verified数据集，通过时间排序的GitHub问题序列来模拟仓库演变，从而评估代理的经验积累、知识迁移和抗遗忘能力。为支持评估，SWE-Bench-CL提供了一套分析工具、一个集成了语义记忆的评估框架以及专门的持续学习指标，以全面衡量代理的稳定性和可塑性权。所有资源均已开源，旨在推动软件工程领域中更具适应性AI代理的研发。

> **摘要翻译:** 大型语言模型（LLMs）在静态代码生成基准上取得了令人瞩目的成果，但现实世界的软件开发是一个由不断演变的问题、修复和功能请求组成的持续流。我们引入了SWE-Bench-CL，这是一个基于OpenAI和Princeton-NLP于2024年推出的经过人工验证的SWE-Bench Verified数据集构建的新型持续学习基准。通过将GitHub问题组织成按时间顺序排列的序列，以反映代码仓库的自然演变，SWE-Bench-CL能够直接评估代理积累经验、跨任务迁移知识和抵抗灾难性遗忘的能力。我们补充了该数据集，包括 (i) 对任务间结构相似性和上下文敏感性的初步分析，(ii) 一个基于LangGraph的交互式评估框架，并辅以一个基于FAISS的语义记忆模块，以及 (iii) 一套专门的持续学习指标——包括平均准确度、遗忘、前向/后向迁移、工具使用效率，以及广义复合持续学习分数和CL-F-beta分数——以捕捉稳定性-可塑性权衡。我们概述了一个严格的实验协议，用于比较有记忆和无记忆的代理在不同Python仓库中的表现。所有代码和数据都在 https://github.com/thomasjoshi/agents-never-forget 公开可用，为社区提供了一个可复现的平台，用于开发软件工程中更具适应性和鲁棒性的AI代理。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [156] [MamNet: A Novel Hybrid Model for Time-Series Forecasting and Frequency Pattern Analysis in Network Traffic](https://arxiv.org/abs/2507.00304)
> *MamNet：一种用于网络流量时间序列预测和频率模式分析的新型混合模型*

*Yujun Zhang, Runlong Li, Xiaoxiang Liang, Xinhao Yang, Tian Su, Bo Liu, Yan Zhou* | **Category: cs.LG, cs.NI**

**Keywords:** 网络流量预测, 异常检测, MamNet, Mamba, 傅里叶变换

**Comment:** 16 pages

> **TL;DR:** MamNet是一种结合时域建模（Mamba）和频域特征提取（傅里叶变换）的新型混合模型，用于高效的网络流量预测和异常检测，在多个数据集上表现优于现有主流模型。

**AI_Comments:** MamNet的创新之处在于其混合模型设计，结合了Mamba的时域建模能力和傅里叶变换的频域分析能力，实现了对网络流量复杂模式的有效捕获。这种多尺度信息融合的方法提升了异常检测的准确性，对于网络安全领域具有重要意义。未来的工作方向，如整合外部事件信息，有望进一步增强模型的鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 网络流量的异常波动可能预示潜在的安全威胁或系统故障，因此，高效的网络流量预测和异常检测方法对于网络安全和流量管理至关重要。

**Method:** 本文提出了一种名为MamNet的新型网络流量预测和异常检测模型。该模型首先通过Mamba模块进行时域建模以捕获网络流量的长期依赖性，然后利用傅里叶变换进行频域特征提取以识别流量中的周期性波动。在特征融合层，模型整合多尺度信息以增强其检测网络流量异常的能力。

**Result:** 在UNSW-NB15和CAIDA数据集上进行的实验表明，MamNet在准确率、召回率和F1分数方面优于几种最近的主流模型。具体而言，对于复杂流量模式和长期趋势检测，其检测性能提升了约2%到4%。

**Conclusion:** MamNet能够有效捕获不同时间尺度下的网络流量异常，适用于网络安全和流量管理中的异常检测任务。

> **ai_Abstract:** MamNet是一种新型混合模型，用于网络流量预测和异常检测。它结合了Mamba模块进行时域长期依赖捕获和傅里叶变换进行频域周期性波动识别。通过特征融合，MamNet增强了异常检测能力。实验证明，该模型在UNSW-NB15和CAIDA数据集上优于现有主流模型，在检测复杂流量和长期趋势方面性能提升2%至4%，显示了其在网络安全和流量管理中的有效性。

> **摘要翻译:** 网络流量的异常波动可能预示潜在的安全威胁或系统故障。因此，高效的网络流量预测和异常检测方法对于网络安全和流量管理至关重要。本文提出了一种新型网络流量预测和异常检测模型MamNet，该模型集成了时域建模和频域特征提取。该模型首先通过Mamba模块（时域建模）捕获网络流量的长期依赖性，然后利用傅里叶变换（频域特征提取）识别流量中的周期性波动。在特征融合层，多尺度信息被整合以增强模型检测网络流量异常的能力。在UNSW-NB15和CAIDA数据集上进行的实验表明，MamNet在准确率、召回率和F1分数方面优于几种最近的主流模型。具体而言，对于复杂流量模式和长期趋势检测，其检测性能提升了约2%到4%。结果表明，MamNet能够有效捕获不同时间尺度下的网络流量异常，适用于网络安全和流量管理中的异常检测任务。未来的工作可以通过整合外部网络事件信息进一步优化模型结构，从而提高模型在复杂网络环境中的适应性和稳定性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [159] [Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications](https://arxiv.org/abs/2507.00015)
> *带有对抗性指示符令牌的视觉Transformer在无线电信号分类中对抗对抗性攻击*

*Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Xuekang Liu, Fabio Roli, Carsten Maple* | **Category: cs.LG, cs.AI, cs.CR**

**Keywords:** 视觉Transformer, 对抗性攻击, 无线电信号分类, 对抗性指示符令牌, 自动调制分类

**Comment:** 

> **TL;DR:** Transformer在无线电信号分类中易受对抗性攻击。本文提出了一种带有对抗性指示符（AdvI）令牌的视觉Transformer，并结合对抗性训练，以检测和防御这些攻击，表现出卓越的性能。

**AI_Comments:** 该论文引入了对抗性指示符（AdvI）令牌这一新颖概念，并将其直接集成到ViT架构中，以实现检测和防御。这种将训练时和运行时防御统一在一个模型中的方法具有创新性，可能比多模型系统更简单。研究聚焦于物联网重要的无线电信号分类领域，增加了实用相关性。

<details>
  <summary>Details</summary>

**Motivation:** Transformer在自动调制分类中取得了显著成功，但在无线电信号分类中容易受到微小但复杂的对抗性攻击。本文旨在解决这一问题，开发一种防御策略。

**Method:** 提出了一种新颖的视觉Transformer（ViT）架构，通过引入“对抗性指示符（AdvI）令牌”来检测对抗性攻击。该方法将对抗性训练与AdvI令牌检测机制相结合，在统一的神经网络模型中结合了训练时防御和运行时防御，从而降低了系统复杂性。此外，还研究了注意力机制的操作原理。

**Result:** 所提出的AdvI令牌在ViT中充当关键元素，影响注意力权重，从而突出输入数据中潜在可疑或异常的区域或特征。实验结果表明，在处理白盒攻击场景（包括使用快速梯度法、投影梯度下降攻击和基本迭代法）时，该方法超越了几种竞争方法。

**Conclusion:** 本研究提出的带有AdvI令牌的视觉Transformer及其集成的防御机制，能够有效防御无线电信号分类中的对抗性攻击，并优于现有方法。

> **ai_Abstract:** 本文旨在解决基于Transformer的无线电信号分类易受对抗性攻击的问题。为此，提出了一种新颖的视觉Transformer（ViT）架构，引入了“对抗性指示符（AdvI）令牌”来检测此类攻击。通过将对抗性训练与AdvI令牌检测机制相结合，该方法在一个统一模型中实现了训练时和运行时防御，从而简化了系统复杂性。实验结果表明，该方法能够有效识别可疑输入特征，并在白盒攻击场景中优于现有方法。

> **摘要翻译:** Transformer在自然语言处理和计算机视觉等各个领域的卓越成功，为其在自动调制分类（物联网（IoT）设备通信系统中的关键组件）中的应用铺平了道路。然而，已经观察到基于Transformer的无线电信号分类容易受到微小但复杂的对抗性攻击。为了解决这个问题，我们开发了一种基于Transformer的调制分类系统的防御策略，以对抗此类对抗性攻击。在本文中，我们提出了一种新颖的视觉Transformer（ViT）架构，引入了一个称为对抗性指示符（AdvI）令牌的新概念来检测对抗性攻击。据我们所知，这是首次提出在ViT中引入AdvI令牌以防御对抗性攻击的工作。通过将对抗性训练方法与使用AdvI令牌的检测机制相结合，我们将训练时防御和运行时防御统一到一个神经网络模型中，与使用单独模型检测对抗性扰动相比，这降低了系统的架构复杂性。我们通过检查注意力机制来研究我们方法的操作原理。我们展示了所提出的AdvI令牌在ViT中充当一个关键元素，影响注意力权重，从而突出输入数据中潜在可疑或异常的区域或特征。通过实验结果，我们证明我们的方法在处理白盒攻击场景（包括使用快速梯度法、投影梯度下降攻击和基本迭代法）方面超越了几种竞争方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models](https://arxiv.org/abs/2507.00026)
> *ROSE：迈向大型语言模型现实导向的安全评估*

*Jiale Ding, Xiang Zheng, Cong Wang, Wei-Bin Lee, Xingjun Ma, Yu-Gang Jiang* | **Category: cs.LG, cs.AI, cs.CL, cs.CY**

**Keywords:** 大型语言模型, 安全评估, 对抗性提示, 强化学习, 漏洞揭示

**Comment:** 

> **TL;DR:** 提出ROSE框架，通过多目标强化学习生成多样化、情境丰富的对抗性提示，以更现实地评估LLM的安全漏洞，并优于现有方法。

**AI_Comments:** 本文提出的ROSE框架通过引入多目标强化学习来生成更具多样性和现实情境的对抗性提示，有效解决了现有LLM安全评估方法在适应性、主题覆盖和现实对齐方面的不足，具有重要的创新性。其自动化和自适应的特性对于跟上LLM快速发展的步伐至关重要，有望推动LLM安全评估领域向更实用和高效的方向发展。

<details>
  <summary>Details</summary>

**Motivation:** LLM在实际应用中作为黑盒组件部署，其安全性评估（尤其是在对抗性提示下）至关重要。现有手动安全基准静态且更新劳动密集，难以跟上LLM发展。自动化方法存在主题覆盖不足和与现实世界背景对齐性差的问题，导致对抗性提示主题狭窄且场景重复。

**Method:** 本文提出Reality-Oriented Safety Evaluation (ROSE) 框架，该框架利用多目标强化学习来微调一个对抗性LLM，以生成主题多样且上下文丰富的对抗性提示。

**Result:** 实验表明，ROSE在揭示最先进LLM的安全漏洞方面优于现有方法，并在综合评估指标上取得了显著改进。

**Conclusion:** ROSE代表了LLM更实用和现实导向的安全评估方法迈出了一步。

> **ai_Abstract:** 本文提出ROSE框架，旨在解决大型语言模型安全评估中现有方法存在的局限性。针对手动基准的静态性和自动化方法的主题覆盖不足及现实对齐性差问题，ROSE利用多目标强化学习微调对抗性LLM，以生成主题多样且上下文丰富的对抗性提示，从而更有效地揭示LLM的安全漏洞，实验证明其优于现有方法。

> **摘要翻译:** 大型语言模型（LLM）正越来越多地作为黑盒组件部署到现实世界应用中，因此评估它们的安全性——尤其是在对抗性提示下——变得至关重要。可以说，有效的安全评估应该是自适应的，随LLM能力而演进，并且应涵盖广泛的有害主题和现实世界场景，以充分暴露潜在的漏洞。现有的手动安全基准建立在手工制作的对抗性提示之上，受限于其静态性质和更新所需的大量劳动，使其难以跟上快速发展的LLM。相比之下，自动化对抗性提示生成为自适应评估提供了一条有希望的途径。然而，当前方法往往存在对抗性主题覆盖不足（主题级别多样性）和与现实世界背景对齐性弱的问题。这些缺点源于黑盒优化中的探索-利用困境以及缺乏现实世界情境化，导致生成的对抗性提示主题狭窄且场景重复。为了解决这些问题，我们提出了现实导向安全评估（ROSE），这是一个新颖的框架，它使用多目标强化学习来微调一个对抗性LLM，以生成主题多样且上下文丰富的对抗性提示。实验表明，ROSE在揭示最先进LLM的安全漏洞方面优于现有方法，并在综合评估指标上取得了显著改进。我们希望ROSE代表了LLM更实用和现实导向的安全评估方法迈出了一步。警告：本文包含潜在有害文本的示例。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [165] [Best Agent Identification for General Game Playing](https://arxiv.org/abs/2507.00451)
> *通用游戏玩法中最佳代理识别*

*Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers* | **Category: cs.LG, cs.AI, cs.DS, cs.IT, math.IT, stat.ML**

**Keywords:** 多臂老虎机, 最佳臂识别, 通用游戏玩法, 代理评估, 威尔逊分数区间

**Comment:** 

> **TL;DR:** 本文提出了一种基于多臂老虎机的Optimistic-WS方法，用于高效识别通用游戏玩法中子任务的最佳代理，并在性能上取得了显著提升。

**AI_Comments:** 该论文将多臂老虎机最佳臂识别的新颖应用引入到通用游戏玩法中选择最佳代理的实际问题。利用威尔逊分数区间进行乐观选择是其创新之处，有助于提高性能。其可推广到其他算法运行时较高的多任务域的特性，突显了其更广泛的适用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在多问题域（特别是通用游戏玩法）中，需要在有限的试验次数内高效、准确地识别每个子任务的最佳执行算法或代理。

**Method:** 将问题视为多臂老虎机的一系列最佳臂识别问题。提出了一种基于威尔逊分数区间（Wilson score interval）的乐观选择过程（Optimistic-WS），根据潜在的遗憾减少量对所有老虎机（任务）中的每个臂（算法或代理）进行排名。在通用视频游戏AI（GVGAI）框架和Ludii通用游戏系统上进行了性能评估。

**Result:** 与以前的多臂老虎机最佳臂识别算法相比，Optimistic-WS在平均简单遗憾（average simple regret）方面表现出显著的性能改进。

**Conclusion:** Optimistic-WS这种新颖的方法可以显著提高通用游戏框架以及其他算法运行时较高的多任务域中代理评估程序的质量和准确性。

> **ai_Abstract:** 本文介绍了一种名为Optimistic-WS的高效通用程序，用于识别多问题域（特别是通用游戏玩法）中每个子任务的最佳执行算法（代理）。该方法将问题框定为多臂老虎机中的最佳臂识别，其中Optimistic-WS利用威尔逊分数区间根据潜在遗憾减少量对代理进行排名。在GVGAI和Ludii上的评估表明，与现有方法相比，该方法在平均简单遗憾方面取得了显著改进，这对于提高通用游戏框架和其他高运行时多任务域中的代理评估质量具有重要价值。

> **摘要翻译:** 论文标题：通用游戏玩法中最佳代理识别

论文摘要：我们提出了一种高效且通用的程序，用于在多问题域中准确识别每个子任务的最佳执行算法。我们的方法将其视为多臂老虎机的一系列最佳臂识别问题，其中每个老虎机对应一个特定任务，每个臂对应一个特定算法或代理。我们提出了一种基于威尔逊分数区间（Optimistic-WS）的乐观选择过程，该过程根据潜在的遗憾减少量对所有老虎机中的每个臂进行排名。我们在两个最流行的通用游戏领域，即通用视频游戏AI（GVGAI）框架和Ludii通用游戏系统上评估了Optimistic-WS的性能，目标是在有限的试验次数内识别每个游戏的最高性能代理。与以前用于多臂老虎机的最佳臂识别算法相比，我们的结果表明在平均简单遗憾方面有显著的性能改进。这种新颖的方法可用于显著提高通用游戏框架以及其他算法运行时较高的多任务域中代理评估程序的质量和准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [170] [GLU Attention Improve Transformer](https://arxiv.org/abs/2507.00022)
> *GLU 注意力改进 Transformer*

*Zehao Wang* | **Category: cs.LG, cs.AI, cs.CL, cs.NE**

**Keywords:** GLU Attention, Transformer, 非线性, 模型性能, 收敛速度

**Comment:** 4 pages 4 figures

> **TL;DR:** 提出GLU注意力机制，为Transformer引入非线性，零额外参数，提高模型性能和收敛速度，并可与其他技术结合。

**AI_Comments:** GLU Attention的创新之处在于将GLU的非线性引入注意力机制的值，这在不增加额外参数和计算成本的情况下实现了性能提升，并保持了与现有先进技术的良好兼容性，使其具有很高的实用价值和集成潜力。

<details>
  <summary>Details</summary>

**Motivation:** 门控线性单元（GLU）在增强神经网络性能方面展现出巨大潜力，本文旨在引入一种新颖的注意力机制GLU Attention，为注意力机制的值引入非线性。

**Method:** 本文引入了一种名为GLU Attention的新型注意力机制，它通过为Attention的值引入非线性来改进Transformer。

**Result:** 实验证明，GLU Attention在文本和视觉模态上都能提高模型性能和收敛速度，且无需额外参数，计算成本可忽略不计。它轻量级，可与Flash Attention、旋转位置嵌入（RoPE）和分组查询注意力（GQA）等多种多头注意力（MHA）变体无缝集成。

**Conclusion:** GLU Attention是一种有效且高效的注意力机制，能够在不增加额外参数和计算成本可忽略不计的情况下，提升Transformer模型的性能和收敛速度，同时保持轻量级和良好的兼容性。

> **ai_Abstract:** 本文提出一种名为GLU Attention的新型注意力机制，通过在注意力值中引入非线性来改进Transformer模型。实验证明，GLU Attention在文本和视觉任务中，在不增加额外参数和计算成本可忽略不计的情况下，显著提升了模型性能和收敛速度。该机制轻量且兼容性强，可与现有技术如Flash Attention、RoPE和GQA等结合使用。

> **摘要翻译:** 门控线性单元（GLU）在增强神经网络性能方面展现出巨大潜力。在本文中，我介绍了一种新颖的注意力机制，称为GLU注意力，它为注意力机制的值引入了非线性。我的实验表明，GLU注意力在文本和视觉模态上都能提高模型性能和收敛速度，且无需额外参数，计算成本可忽略不计。GLU注意力是轻量级的，并且可以与Flash Attention、旋转位置嵌入（RoPE）以及各种多头注意力（MHA）变体（如分组查询注意力（GQA））等其他技术无缝集成。本项目已在github上开源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Gradient-based Fine-Tuning through Pre-trained Model Regularization](https://arxiv.org/abs/2507.00016)
> *基于梯度的预训练模型正则化微调*

*Xuanbo Liu, Liu Liu, Fuxiang Wu, Fusheng Hao, Xianglong Liu* | **Category: cs.LG, cs.AI, cs.CV**

**Keywords:** 预训练模型微调, 梯度, 正则化, 参数效率, 知识迁移

**Comment:** 

> **TL;DR:** GRFT是一种高效的基于梯度的正则化微调方法，通过选择性更新权重矩阵的行或列并结合正则化，解决了大型预训练模型微调资源消耗大的问题，以极少的参数更新量实现了最先进的性能。

**AI_Comments:** GRFT的创新之处在于其结合了梯度选择性更新（针对权重矩阵的行或列）和正则化，有效解决了大型模型微调的资源效率问题。通过理论证明和实验验证，该方法不仅显著减少了计算和存储开销，还提升了性能，对于实际应用中部署大型预训练模型具有重要意义。其极低的参数更新比例显示出很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型预训练模型需要大量的计算资源和存储。即使是旨在减少参数的现有方法（如梯度选择性参数GPS）也面临计算和存储效率低下的挑战。

**Method:** 本文提出了一种高效的基于梯度的正则化微调方法（GRFT）。该方法通过更新权重矩阵的行或列进行微调，并理论证明选择梯度平方和最高的行或列进行更新是最佳策略。此外，GRFT还整合了正则化，以增强预训练模型的知识迁移能力。

**Result:** GRFT在FGVC和VTAB数据集上分别仅需更新总参数的1.22%和0.30%，显著降低了存储开销并提高了参数选择效率。它实现了最先进的性能，超越了GPS、Adapter Tuning和LoRA等现有方法。

**Conclusion:** GRFT是一种高效且有效的微调大型预训练模型的方法，通过选择性更新权重矩阵的行或列并结合正则化，在显著减少计算和存储需求的同时，实现了优异的性能。

> **ai_Abstract:** 本文提出了一种名为GRFT的高效梯度正则化微调方法，旨在解决大型预训练模型微调时计算和存储资源消耗大的问题。GRFT通过选择性地更新权重矩阵中梯度平方和最高的行或列，并结合正则化来增强知识迁移。实验结果表明，GRFT显著减少了所需更新的参数量（在某些数据集上仅更新0.30%），同时实现了超越现有微调方法（如GPS、Adapter Tuning和LoRA）的最先进性能。

> **摘要翻译:** 大型预训练模型已在各个领域展现出广泛应用。然而，针对特定下游任务对这些模型进行微调需要大量的计算资源和存储。一种微调方法，基于梯度的参数选择（GPS），侧重于仅微调每个神经元中梯度较高的参数，从而减少训练参数的数量。然而，这种方法增加了计算资源需求和存储需求。在本文中，我们提出了一种高效的基于梯度的正则化微调方法（GRFT），该方法更新权重矩阵的行或列。我们从理论上证明，梯度平方和最高的行或列是最佳的更新选择。该策略有效减少了存储开销并提高了参数选择的效率。此外，我们引入正则化以增强预训练模型的知识迁移。GRFT取得了最先进的性能，超越了GPS、Adapter Tuning和LoRA等现有方法。值得注意的是，GRFT在FGVC和VTAB数据集上分别仅需更新总参数的1.22%和0.30%，展示了其高效率和有效性。源代码即将发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [186] [Leveraging Unlabeled Audio-Visual Data in Speech Emotion Recognition using Knowledge Distillation](https://arxiv.org/abs/2507.00055)
> *利用知识蒸馏在语音情感识别中利用未标记的视听数据*

*Varsha Pendyala, Pedro Morgado, William Sethares* | **Category: cs.LG, cs.HC, cs.MM, eess.AS, eess.IV, eess.SP**

**Keywords:** 语音情感识别, 知识蒸馏, 未标记数据, 视听数据, LiSER

**Comment:** Accepted at INTERSPEECH 2025

> **TL;DR:** 本文提出了一种名为LiSER的知识蒸馏框架，利用未标记的视听数据进行语音情感识别（SER），通过从大型教师模型向轻量级学生模型转移知识，有效减少了对大量标记数据的依赖。

**AI_Comments:** LiSER框架的创新之处在于其利用知识蒸馏技术，有效利用了未标记的视听数据来解决语音情感识别中标记数据稀缺的问题。这种方法对于降低开发成本和促进SER系统的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语音接口可以通过语音情感识别（SER）来定制响应，因为人类通过多模态视听线索传达情感，所以开发结合两种模态的SER系统是有益的。然而，为开发这些系统收集大量标记数据成本高昂。

**Method:** 本文提出了一种名为LightweightSER（LiSER）的知识蒸馏框架，该框架利用未标记的视听数据进行SER。它使用基于先进语音和面部表示模型构建的大型教师模型，并将语音情感和面部表情方面的知识从教师模型转移到轻量级学生模型。

**Result:** 在RAVDESS和CREMA-D这两个基准数据集上进行的实验表明，LiSER可以减少SER任务对大量标记数据集的依赖。

**Conclusion:** LiSER框架通过利用未标记的视听数据和知识蒸馏，有效降低了语音情感识别系统对昂贵标记数据集的依赖。

> **ai_Abstract:** 本文提出了一种名为LightweightSER（LiSER）的知识蒸馏框架，旨在解决语音情感识别（SER）中标记数据收集成本高昂的问题。LiSER利用未标记的视听数据，通过从大型教师模型（基于先进的语音和面部表示）向轻量级学生模型转移知识。实验证明，该方法能有效降低SER任务对大量标记数据集的依赖性。

> **摘要翻译:** 语音接口作为人机交互系统的重要组成部分，可以通过语音情感识别（SER）根据用户情感定制响应，从而从中受益。由于人类通过多模态视听线索传达情感，因此开发同时使用这两种模态的SER系统是有益的。然而，为它们的开发收集大量标记数据成本高昂。本文提出了一种名为LightweightSER（LiSER）的知识蒸馏框架，该框架利用未标记的视听数据进行SER，使用基于先进语音和面部表示模型构建的大型教师模型。LiSER将关于语音情感和面部表情的知识从教师模型转移到轻量级学生模型。在RAVDESS和CREMA-D这两个基准数据集上进行的实验表明，LiSER可以减少SER任务对大量标记数据集的依赖。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [197] [Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections](https://arxiv.org/abs/2507.00018)
> *隐式奖励作为桥梁：SFT和DPO连接的统一视角*

*Bo Wang, Qinyuan Cheng, Runyu Peng, Rong Bao, Peiji Li, Qipeng Guo, Linyang Li, Zhiyuan Zeng, Yunhua Zhou, Xipeng Qiu* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 监督微调, 偏好学习, 隐式奖励, 统一框架, LLM后训练

**Comment:** 

> **TL;DR:** 本文提出了一个统一的理论框架，将SFT和DPO等偏好学习方法联系起来，证明它们在同一策略-奖励子空间中，并改进了SFT的局限性。

**AI_Comments:** 本文的创新点在于提出了一个统一的理论框架，将SFT和偏好学习置于同一视角下，揭示了SFT作为隐式奖励学习的特例。通过发现SFT中KL散度项的局限性并提出有效的改进方案（如学习率衰减和f-散度目标），对LLM的后训练优化提供了重要的理论和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 将预训练语言模型应用于实际任务时，SFT和偏好学习至关重要，但需要一个统一的理论框架来理解它们之间的联系及其局限性。

**Method:** 提出了一个统一的理论框架，通过严格的数学推导，证明SFT和DPO在同一最优策略-奖励子空间中，SFT是隐式奖励学习的特例。针对SFT的KL散度项问题，提出了学习率衰减方法和基于f-散度的替代SFT目标。还将LLM logits和Q函数的关系从偏好学习扩展到SFT。

**Result:** 学习率衰减方法在指令遵循任务中实现了高达25%的相对增益和6%的绝对胜率提升。基于f-散度的替代SFT目标进一步增强了DPO后模型的性能。

**Conclusion:** 本文通过统一的理论框架揭示了SFT和偏好学习（如DPO）之间的深层联系，并提出了改进SFT性能的方法，扩展了LLM logits与Q函数的关系。

> **ai_Abstract:** 本文提出了一个统一的理论框架，将LLM后训练中的监督微调（SFT）与直接偏好优化（DPO）等偏好学习方法联系起来。研究表明SFT是隐式奖励学习的一个特例，两者在相同的最优策略-奖励子空间中。针对传统SFT的KL散度项限制，作者提出了学习率衰减方法和基于f-散度的替代目标，显著提升了模型在指令遵循任务上的表现。研究还扩展了LLM logits与Q函数之间的理论关系。

> **摘要翻译:** 后训练过程是将预训练语言模型应用于实际任务的关键阶段，其中从演示或偏好信号中学习在此适应过程中起着至关重要的作用。我们提出了一个统一的理论框架，连接了大型语言模型（LLM）后训练中的监督微调（SFT）和偏好学习。通过严谨的数学推导，我们证明了SFT和像直接偏好优化（DPO）这样的偏好学习方法都在相同的最优策略-奖励子空间中运行，其中SFT代表了隐式奖励学习的一个特例。我们的分析揭示了传统SFT的一个关键局限性：分布匹配中的KL散度项在优化过程中相对于策略变为常数，未能约束模型更新。为了解决这个问题，我们提出了一种简单而有效的学习率降低方法，在指令遵循任务中取得了显著的性能改进（高达25%的相对增益和6%的绝对胜率提升）。此外，我们从各种f-散度函数中推导出替代的SFT目标，这些目标在优化过程中保留了KL项，进一步增强了DPO后模型的性能。最后，我们将LLM logits和Q函数之间从偏好学习到SFT上下文的理论关系进行了扩展，提供了数学推导和实验验证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [214] [Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations](https://arxiv.org/abs/2507.00019)
> *量子启发式机器学习模型编码策略：提出并评估实例级、全局离散和类别条件表示*

*Minati Rath, Hema Date* | **Category: cs.LG, cs.AI, quant-ph**

**Keywords:** 量子启发式, 数据编码, 机器学习, 分类, 编码策略

**Comment:** 

> **TL;DR:** 本研究提出并评估了三种量子启发式数据编码策略（实例级、全局离散、类别条件），旨在减少经典数据转换为量子数据时的编码时间，并分析其对分类性能的影响。

**AI_Comments:** 这项研究创新性地将量子启发式思想应用于经典机器学习的数据编码，旨在解决现有编码方法的效率和性能问题。其重要性在于为经典模型利用量子概念提供了一种新的途径，并详细探讨了不同编码策略的权衡，对未来混合量子-经典机器学习的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的主要目标是减少高昂的编码时间，同时确保编码值的正确性，并分析这些量子启发式编码策略对分类性能的影响，以优化经典机器学习工作流中的数据转换。

**Method:** 本文提出了三种量子启发式数据编码策略：实例级策略 (ILS)、全局离散策略 (GDS) 和类别条件值策略 (CCVS)。ILS 独立处理数据集的每一行；GDS 将所有唯一特征值统一映射到量子态；CCVS 为每个类别单独编码唯一值。这些策略被应用于分类任务，并评估了它们在编码效率、正确性、模型准确性和计算成本方面的影响。

**Result:** 通过分析编码时间、精度和预测性能之间的权衡，本研究为优化经典机器学习工作流中的量子启发式数据转换提供了见解。

**Conclusion:** 结论是该研究通过对不同量子启发式编码策略的评估和权衡分析，为优化经典机器学习中的数据转换提供了有价值的见解。

> **ai_Abstract:** 本研究提出并评估了三种量子启发式数据编码策略（实例级、全局离散和类别条件），用于将经典数据转换为量子数据，以应用于经典机器学习模型。主要目标是优化编码时间、确保编码正确性并分析其对分类性能的影响。研究将这些策略应用于分类任务，评估了其在效率、准确性和成本方面的表现，并提供了关于优化量子启发式数据转换的见解。

> **摘要翻译:** 在本研究中，我们提出、评估并比较了三种量子启发式数据编码策略：实例级策略 (ILS)、全局离散策略 (GDS) 和类别条件值策略 (CCVS)，旨在将经典数据转换为量子数据以用于纯经典机器学习模型。主要目标是减少高昂的编码时间，同时确保编码值的正确性并分析它们对分类性能的影响。实例级策略独立处理数据集的每一行，模拟局部量子态。全局离散值编码策略将整个数据集中所有独特的特征值统一映射到量子态。相比之下，类别条件值编码策略为每个类别单独编码独特值，从而保留了类别相关信息。我们将这些编码策略应用于分类任务，并评估它们对编码效率、正确性、模型准确性和计算成本的影响。通过分析编码时间、精度和预测性能之间的权衡，本研究为优化经典机器学习工作流中的量子启发式数据转换提供了见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [227] [Variational Autoencoder for Generating Broader-Spectrum prior Proposals in Markov chain Monte Carlo Methods](https://arxiv.org/abs/2507.00020)
> *变分自编码器在马尔可夫链蒙特卡罗方法中生成更广谱先验提议*

*Marcio Borges, Felipe Pereira, Michel Tosin* | **Category: cs.LG, stat.ML**

**Keywords:** 变分自编码器, 马尔可夫链蒙特卡罗, 先验提议, 贝叶斯逆问题, 降维

**Comment:** The main contribution of this work is to show the advantages of using
  deep generative models like VAE to provide more flexible and versatile prior
  distributions

> **TL;DR:** 本研究利用变分自编码器（VAE）生成更广谱的先验提议，以提高马尔可夫链蒙特卡罗（McMC）方法的效率和适用性，尤其是在高维贝叶斯逆问题中。

**AI_Comments:** 该研究的创新之处在于将变分自编码器应用于马尔可夫链蒙特卡罗方法中，解决了传统方法对协方差函数先验知识的依赖问题。其重要性体现在提高了贝叶斯逆问题在高维情况下的计算效率和推断的适应性。通过数据驱动的方式捕捉更广谱的相关结构，显著拓宽了McMC方法的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 传统的马尔可夫链蒙特卡罗（McMC）方法，如Karhunen-Loève展开（KLE），需要先验的协方差函数知识，这在实际应用中往往不可用。因此，需要一种数据驱动的方法来灵活捕捉更广泛的相关结构。

**Method:** 本研究使用变分自编码器（VAE）框架，通过数据驱动的方式生成更广谱的先验提议，从而增强马尔可夫链蒙特卡罗（McMC）方法。该方法在合成地下水流反演问题中进行了测试，利用压力数据估计渗透率场。

**Result:** 数值实验表明，当相关长度已知时，基于VAE的参数化方法能达到与KLE相当的精度；当假设的相关长度偏离真实值时，VAE的表现优于KLE。此外，VAE方法显著降低了随机维度，提高了计算效率。

**Conclusion:** 结果表明，在McMC方法中利用深度生成模型可以实现高维问题中更具适应性和效率的贝叶斯推断。

> **ai_Abstract:** 本研究提出了一种基于变分自编码器（VAE）的方法，用于在马尔可夫链蒙特卡罗（McMC）方法中生成更广谱的先验提议。与传统方法（如KLE）需要先验协方差知识不同，VAE提供了一种数据驱动的途径，能够灵活捕捉贝叶斯逆问题中的复杂相关结构。在合成地下水流反演问题中的实验证明，VAE在已知相关长度时可达与KLE相当的精度，在相关长度未知时表现更优，并显著提高了计算效率。这表明深度生成模型可有效提升高维贝叶斯推断的适应性和效率。

> **摘要翻译:** 本研究利用变分自编码器（VAE）方法，通过生成更广谱的先验提议，以提高马尔可夫链蒙特卡罗（McMC）方法的效率和适用性。传统的KLE（Karhunen-Loève Expansion）等方法需要协方差函数的先验知识，这在实际应用中通常不可用。VAE框架提供了一种数据驱动的方法，能够灵活地捕捉贝叶斯逆问题，特别是地下水流建模中更广泛的相关结构。该方法在一个合成地下水流反演问题中进行了测试，其中利用压力数据估计渗透率场。数值实验表明，当相关长度已知时，基于VAE的参数化方法能够达到与KLE相当的精度，并且当假设的相关长度偏离真实值时，其性能优于KLE。此外，VAE方法显著降低了随机维度，提高了计算效率。结果表明，在McMC方法中利用深度生成模型可以实现高维问题中更具适应性和效率的贝叶斯推断。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [230] [Time Series Foundation Models are Flow Predictors](https://arxiv.org/abs/2507.00945)
> *时间序列基础模型是流量预测器*

*Massimiliano Luca, Ciro Beneduce, Bruno Lepri* | **Category: cs.LG, cs.CY**

**Keywords:** 时间序列基础模型, 流量预测, 零样本, Moirai, TimesFM

**Comment:** arXiv admin note: text overlap with arXiv:2203.07372

> **TL;DR:** 时间序列基础模型（Moirai和TimesFM）在零样本设置下，无需空间信息，在人群流量预测上显著优于现有基线模型。

**AI_Comments:** 该论文的创新之处在于将时间序列基础模型应用于人群流量预测，并在严格的零样本设置下，不依赖空间信息，取得了显著优于现有基线模型的性能。这凸显了TSFMs在处理数据稀疏或空间上下文缺失场景下的强大能力和实用性，为未来的流量预测研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 研究时间序列基础模型（TSFMs）在人群流量预测中的有效性，特别关注Moirai和TimesFM。

**Method:** 在Bike NYC、Taxi Beijing和Spanish national OD flows三个真实世界移动性数据集上，以严格的零样本设置评估模型，仅使用每个OD流的时间演变，不使用明确的空间信息来部署Moirai和TimesFM。

**Result:** Moirai和TimesFM优于统计和深度学习基线模型，RMSE降低高达33%，MAE降低高达39%，CPC提高高达49%。

**Conclusion:** 时间序列基础模型（TSFMs）在准确、可扩展的流量预测方面具有实用价值，即使在标注数据有限或空间上下文缺失的情况下也是如此。

> **ai_Abstract:** 本研究评估了时间序列基础模型（TSFMs），特别是Moirai和TimesFM，在人群流量预测中的表现。在三个真实世界的移动性数据集上，这些模型在零样本设置下，仅利用时间演变，无需显式空间信息，表现出卓越的性能。与现有统计和深度学习基线相比，TSFMs显著降低了预测误差并提高了预测准确性，证明了它们在数据受限或空间信息缺失场景下进行准确、可扩展流量预测的实用价值。

> **摘要翻译:** 我们研究了时间序列基础模型（TSFMs）在人群流量预测中的有效性，重点关注Moirai和TimesFM。这些模型在Bike NYC、Taxi Beijing和Spanish national OD flows三个真实世界移动性数据集上进行评估，以严格的零样本设置部署，仅使用每个OD流的时间演变，而不使用明确的空间信息。Moirai和TimesFM优于统计和深度学习基线模型，与最先进的竞争对手相比，RMSE降低高达33%，MAE降低高达39%，CPC提高高达49%。我们的结果突出了TSFMs在准确、可扩展的流量预测方面的实用价值，即使在标注数据有限或空间上下文缺失的场景中也是如此。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [234] [Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data](https://arxiv.org/abs/2507.00061)
> *Smooth-Distill：一个用于可穿戴传感器数据多任务学习的自蒸馏框架*

*Hoang-Dieu Vu, Duc-Nghia Tran, Quang-Tu Pham, Hieu H. Pham, Nicolas Vuillerme, Duc-Tan Tran* | **Category: cs.LG, cs.AI, eess.SP**

**Keywords:** 自蒸馏, 多任务学习, 可穿戴传感器, 人体活动识别, 传感器位置检测

**Comment:** 

> **TL;DR:** 本文提出了Smooth-Distill，一个用于人体活动识别(HAR)和传感器位置检测的自蒸馏框架，它使用可穿戴传感器数据，并利用模型自身的平滑历史版本作为教师模型，从而显著降低计算开销，同时提高性能，并优于传统方法。

**AI_Comments:** 该论文的创新之处在于其自蒸馏方法，即使用模型自身的平滑历史版本作为教师模型，有效解决了知识蒸馏中常见的计算开销问题。这使得该框架在资源受限环境和需要频繁模型更新的场景下更具实用性。此外，新数据集的开发也增强了研究的全面性。其重要性在于为HAR和传感器位置检测提供了高效且准确的多任务学习解决方案，这对于可穿戴技术领域至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在为使用可穿戴传感器数据进行人体活动识别（HAR）和传感器位置检测的多任务学习提供一个高效且准确的解决方案。它特别关注解决传统蒸馏方法中存在的计算开销问题，并寻求在准确性和训练效率之间取得平衡，尤其是在资源受限的平台上。

**Method:** 本文提出了Smooth-Distill，一个自蒸馏框架。它采用统一的基于CNN的MTL-net架构，处理加速度计数据并为HAR和传感器位置检测任务生成两个输出。与传统蒸馏方法不同，Smooth-Distill使用模型自身的平滑历史版本作为教师模型，从而显著减少了训练计算开销。为了支持研究，作者开发了一个包含12种不同睡眠姿势和三种不同佩戴位置的加速度计数据集，并结合了两个现有公共数据集（MHealth和WISDM）。

**Result:** Smooth-Distill在不同评估场景中持续优于其他方法，在人体活动识别和设备放置检测任务中均取得了显著改进。该方法在训练期间表现出增强的收敛模式稳定性，并且与传统的多任务学习基线相比，过拟合现象有所减少。

**Conclusion:** Smooth-Distill框架有助于知识蒸馏在人体活动识别系统中的实际应用，为使用加速度计数据的多任务学习提供了一个平衡准确性和训练效率的有效解决方案。它显著降低了模型训练的计算成本，这对于需要频繁模型更新或在资源受限平台上训练的场景至关重要。

> **ai_Abstract:** 本文介绍了Smooth-Distill，一个新颖的自蒸馏框架，旨在利用可穿戴加速度计数据同时进行人体活动识别（HAR）和传感器位置检测。该框架采用统一的CNN-based架构MTL-net，并利用模型自身的平滑历史版本作为教师，显著降低了计算开销。通过开发新数据集并结合现有公共数据集，实验证明Smooth-Distill在HAR和设备放置任务中均优于现有方法，表现出更高的准确性、训练稳定性和更低的过拟合，为资源受限环境下的多任务学习提供了高效解决方案。

> **摘要翻译:** 本文介绍了 Smooth-Distill，一个新颖的自蒸馏框架，旨在同时使用可穿戴传感器数据执行人体活动识别 (HAR) 和传感器位置检测。所提出的方法利用统一的基于 CNN 的架构 MTL-net，该架构处理加速度计数据并分支为每个相应任务的两个输出。与需要单独的教师和学生模型的传统蒸馏方法不同，所提出的框架利用模型自身平滑的历史版本作为教师，显著降低了训练计算开销，同时保持了性能优势。为了支持这项研究，我们开发了一个全面的基于加速度计的数据集，捕获了三种不同佩戴位置的 12 种不同睡眠姿势，补充了两个现有公共数据集（MHealth 和 WISDM）。实验结果表明，Smooth-Distill 在不同评估场景中始终优于其他方法，在人体活动识别和设备放置检测任务中都取得了显著改进。与传统的多任务学习基线相比，该方法在训练期间表现出增强的收敛模式稳定性，并减少了过拟合。该框架有助于知识蒸馏在人体活动识别系统中的实际实施，为使用加速度计数据的多任务学习提供了一个有效的解决方案，平衡了准确性和训练效率。更广泛地说，它降低了模型训练的计算成本，这对于需要频繁模型更新或在资源受限平台上训练的场景至关重要。代码和模型可在 https://github.com/Kuan2vn/smooth\_distill 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [241] [HelixPipe: Efficient Distributed Training of Long Sequence Transformers with Attention Parallel Pipeline Parallelism](https://arxiv.org/abs/2507.00394)
> *HelixPipe：通过注意力并行流水线并行实现长序列Transformer的高效分布式训练*

*Geng Zhang, Shenggan Cheng, Xuanlei Zhao, Ziming Liu, Yang You* | **Category: cs.LG, cs.DC**

**Keywords:** 长序列Transformer, 流水线并行, 分布式训练, 注意力并行, 内存优化

**Comment:** 

> **TL;DR:** HelixPipe是一种新颖的流水线并行方法，用于训练长序列Transformer，通过引入注意力并行分区、双重先进后出微批调度以及无注意力重计算和分块MLP来解决现有方法在二次注意力计算和内存开销方面的次优性能，显著提高了吞吐量和可扩展性，尤其在长序列训练中表现出优势，相较基线方法可实现26%的加速。

**AI_Comments:** HelixPipe的创新点在于其结合了注意力并行分区和优化的微批调度策略，有效解决了长序列Transformer训练中的核心挑战。其通过减少流水线气泡和平衡内存使用，提升了分布式训练的效率和可扩展性，对于推动大型语言模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着Transformer序列长度的增长，现有的流水线并行方法由于二次注意力计算和巨大的内存开销，导致性能不佳。

**Method:** HelixPipe提出了一种新颖的流水线并行方法。它引入了注意力并行分区，将不同微批的注意力计算并行调度到不同的流水线阶段，从而减少流水线气泡。它采用双重先进后出（first-in-last-out）微批调度，以平衡内存使用并重叠通信与计算。此外，HelixPipe利用无注意力重计算和分块MLP来减轻碎片化并支持更长的序列。

**Result:** 实验表明，HelixPipe在更长的序列长度下优势日益显著，并在不同的流水线大小、模型大小和集群配置下，在吞吐量和可扩展性方面均优于现有方法。特别是在64个H20 GPU上训练具有128k序列长度的7B模型时，它比基线方法提速26%。

**Conclusion:** HelixPipe通过其创新的并行策略有效地解决了长序列Transformer训练中的性能瓶颈和内存挑战，显著提升了训练效率和可扩展性。

> **ai_Abstract:** HelixPipe是一种针对长序列Transformer训练的新型流水线并行方法，旨在解决现有方法在二次注意力计算和内存开销方面的性能瓶颈。它通过注意力并行分区减少流水线气泡，采用双重先进后出微批调度以平衡内存和重叠通信计算，并利用无注意力重计算和分块MLP支持更长序列。实验证明，HelixPipe在吞吐量和可扩展性方面优于现有方法，尤其在长序列训练中表现出显著优势，例如在特定配置下实现了26%的加速。

> **摘要翻译:** 随着Transformer序列长度的增长，现有流水线并行方法由于二次注意力计算和巨大的内存开销而导致性能不佳。为了缓解这些挑战，我们提出了HelixPipe，一种用于长序列Transformer训练的新型流水线并行方法。首先，HelixPipe引入了注意力并行分区，它将不同微批的注意力计算并行调度到不同的流水线阶段，从而减少流水线气泡。其次，它采用双重先进后出（first-in-last-out）的微批调度，以平衡内存使用并实现通信与计算的重叠。此外，HelixPipe利用无注意力重计算和分块MLP来减轻碎片化并支持更长的序列。实验表明，HelixPipe在更长的序列长度下获得了越来越显著的优势，并在不同的流水线大小、模型大小和集群配置下，在吞吐量和可扩展性方面均优于现有方法。值得注意的是，在64个H20 GPU上训练具有128k序列长度的7B模型时，它比基线方法提速26%。代码可在https://github.com/code-tunnel/Megatron-LM/tree/dev获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series](https://arxiv.org/abs/2507.00102)
> *迈向制造业透明化数据驱动故障检测：以单变量离散时间序列为例*

*Bernd Hofmann, Patrick Bruendl, Huong Giang Nguyen, Joerg Franke* | **Category: cs.LG, cs.AI, eess.SP**

**Keywords:** 故障检测, 数据驱动, 可解释性AI, 制造业, 时间序列

**Comment:** 

> **TL;DR:** 本论文提出了一种结合机器学习、Shapley解释和领域特定可视化技术的数据驱动且透明的工业故障检测方法，并在压接工艺中实现了高精度和可解释性，旨在提升工业环境中数据驱动故障检测的信任度。

**AI_Comments:** 本论文的创新之处在于其将数据驱动的机器学习模型与可解释性技术（如Shapley值）和领域特定可视化相结合，解决了工业环境中黑箱模型接受度低的问题。其以人为中心的设计理念，通过提供透明的解释来增强操作员对故障检测系统的信任，对于安全关键型应用尤为重要。通过在实际工业场景（压接工艺）中的应用验证，证明了其在提高产品质量和效率方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的质量控制方法依赖手动定义的阈值和特征，缺乏对生产数据复杂性和变异性的适应性，且需要广泛的领域专业知识。数据驱动方法（如机器学习）虽检测性能高，但通常是黑箱模型，限制了其在可解释性至关重要的工业环境中的接受度。

**Method:** 该方法整合了用于多类别故障分类的监督机器学习模型、用于事后可解释性的Shapley Additive Explanations，以及将模型解释映射到操作员可解释特征的领域特定可视化技术。此外，研究提出了一种评估方法，通过定量扰动分析评估模型解释，并通过定性专家评估可视化效果。

**Result:** 该系统在单变量离散时间序列数据集上实现了95.9%的故障检测准确率。定量选择性分析和定性专家评估均证实了所生成解释的相关性和可解释性。

**Conclusion:** 本研究提出了一种以人为中心的方法，旨在增强数据驱动故障检测的信任度和可解释性，从而为工业质量控制中的应用系统设计做出贡献。

> **ai_Abstract:** 本论文提出了一种针对制造业故障检测的透明且数据驱动的方法。该方法结合了监督机器学习模型进行故障分类、Shapley Additive Explanations进行事后可解释性，以及领域特定可视化技术，将模型解释转换为操作员可理解的特征。研究还提出了一种评估模型解释和可视化的方法。在压接工艺的单变量离散时间序列数据集上进行案例研究，系统实现了95.9%的检测准确率，并且解释的可解释性得到了定量和定性验证。该方法旨在通过提高可解释性来增强工业环境中数据驱动故障检测的信任度。

> **摘要翻译:** 在现代制造业中，确保产品质量的一致性至关重要，尤其是在安全关键型应用中。传统的质量控制方法依赖于手动定义的阈值和特征，缺乏对生产数据固有复杂性和变异性的适应性，并且需要广泛的领域专业知识。相反，数据驱动方法（例如机器学习）表现出高检测性能，但通常作为黑箱模型运行，从而限制了它们在可解释性至关重要的工业环境中的接受度。本文介绍了一种工业故障检测方法，该方法既是数据驱动的又是透明的。该方法集成了用于多类别故障分类的监督机器学习模型、用于事后可解释性的Shapley Additive Explanations，以及将模型解释映射到操作员可解释特征的领域特定可视化技术。此外，该研究提出了一种评估方法，通过定量扰动分析评估模型解释，并通过定性专家评估可视化效果。该方法应用于压接工艺（一种安全关键型连接技术），使用了单变量离散时间序列数据集。该系统实现了95.9%的故障检测准确率，并且定量选择性分析和定性专家评估均证实了所生成解释的相关性和可解释性。这种以人为中心的方法旨在增强数据驱动故障检测的信任度和可解释性，从而为工业质量控制中的应用系统设计做出贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [255] [AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity](https://arxiv.org/abs/2507.00024)
> *AIMatDesign：数据稀缺下知识增强的逆向材料设计强化学习*

*Yeyong Yu, Xilei Bian, Jie Xiong, Xing Wu, Quan Qian* | **Category: cs.LG, cond-mat.mtrl-sci, cs.AI**

**Keywords:** 逆向材料设计, 强化学习, 数据稀缺, 知识增强, 大型语言模型 (LLMs) 

**Comment:** 

> **TL;DR:** AIMatDesign是一种结合了知识增强和LLM辅助的强化学习框架，用于解决数据稀缺下高维材料逆向设计中的可靠性和专家知识整合问题，显著提升了材料发现效率。

**AI_Comments:** AIMatDesign的创新之处在于其结合了数据增强、LLM辅助的模型精炼以及领域知识融入强化学习奖励函数，有效解决了高维材料逆向设计中数据稀缺和专家知识难以利用的痛点。特别是LLM在动态纠正预测不一致性中的应用，为提升模型可靠性提供了一个新颖且有前景的方向。其在实际材料（Zr基合金）上的成功验证，也显示了其强大的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器学习驱动的逆向材料设计方法在高维材料组成空间和有限实验数据下存在两大挑战：1) 模型在高维空间中缺乏可靠性，导致预测偏差；2) 未能有效整合领域专家知识，限制了知识引导的逆向设计能力。

**Method:** AIMatDesign框架通过以下方式解决上述问题：1. 使用基于差异的算法增强实验数据，构建可信经验池，加速模型收敛。2. 引入由大型语言模型（LLMs）引导的自动化精炼策略，动态纠正预测不一致性，增强奖励信号与状态价值函数的一致性，从而提高模型可靠性。3. 设计基于知识的奖励函数，利用领域专家规则提高训练的稳定性和效率。

**Result:** AIMatDesign在发现效率、收敛速度和成功率方面显著超越了传统的机器学习和强化学习方法。通过AIMatDesign提出的候选材料，实验合成的代表性锆基合金获得了性能优异的块状金属玻璃（BMG），其屈服强度为1.7GPa，延伸率为10.2%，与预测值高度吻合。此外，该框架准确捕捉了屈服强度随成分变化的趋势。

**Conclusion:** AIMatDesign框架在数据稀缺条件下，通过知识增强的强化学习方法，有效解决了高维材料逆向设计中的可靠性和专家知识整合问题，展现了在闭环材料发现中的巨大潜力和可靠性。

> **ai_Abstract:** 本文提出了AIMatDesign，一个针对数据稀缺下逆向材料设计的强化学习框架。该框架通过差异化数据增强构建可信经验池加速收敛，利用大型语言模型（LLMs）引导的精炼策略提升模型可靠性，并引入基于知识的奖励函数融合专家经验。实验证明，AIMatDesign在发现效率、收敛速度和成功率上优于现有方法，并成功设计出高性能锆基块状金属玻璃，验证了其在闭环材料发现中的潜力。

> **摘要翻译:** 随着对新型材料需求的增长，机器学习驱动的逆向设计方法在协调高维材料组成空间与有限实验数据方面面临重大挑战。现有方法存在两大主要局限性：(I) 机器学习模型在高维空间中通常缺乏可靠性，导致设计过程中的预测偏差；(II) 这些模型未能有效整合领域专家知识，限制了它们支持知识引导的逆向设计的能力。为了应对这些挑战，我们引入了AIMatDesign，这是一个强化学习框架，通过使用基于差异的算法增强实验数据来构建可信经验池，从而加速模型收敛，解决了这些局限性。为了增强模型可靠性，一个由大型语言模型（LLMs）引导的自动化精炼策略动态纠正预测不一致性，加强了奖励信号与状态价值函数之间的一致性。此外，一个基于知识的奖励函数利用专家领域规则来提高训练期间的稳定性和效率。我们的实验表明，AIMatDesign在发现效率、收敛速度和成功率方面显著超越了传统的机器学习和强化学习方法。在AIMatDesign提出的众多候选材料中，对代表性锆基合金的实验合成产生了一种性能卓越的块状金属玻璃（BMG），其屈服强度为1.7GPa，延伸率为10.2%，与预测值高度吻合。此外，该框架准确捕捉了屈服强度随成分变化的趋势，展示了其可靠性和闭环材料发现的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [PPFL-RDSN: Privacy-Preserving Federated Learning-based Residual Dense Spatial Networks for Encrypted Lossy Image Reconstruction](https://arxiv.org/abs/2507.00230)
> *PPFL-RDSN：基于隐私保护联邦学习的残差密集空间网络用于加密有损图像重建*

*Peilin He, James Joshi* | **Category: cs.LG, cs.CR**

**Keywords:** 隐私保护, 联邦学习, 图像重建, 残差密集空间网络, 差分隐私

**Comment:** This paper is under review; do not distribute

> **TL;DR:** PPFL-RDSN是一个基于联邦学习的隐私保护图像重建框架，它在保证隐私和降低计算成本的同时，实现了与中心化方法相当的性能。

**AI_Comments:** 这篇论文通过将联邦学习与差分隐私和模型水印相结合，有效地解决了协作图像重建中数据隐私和计算效率的关键挑战，其创新点在于提出了一种综合性的隐私保护方案，使得高分辨率图像重建在多方协作场景下变得可行且安全。

<details>
  <summary>Details</summary>

**Motivation:** 在协作场景中，使用残差密集空间网络（RDSNs）从低分辨率输入重建高质量图像面临隐私风险（如数据泄露、推断攻击）和高计算成本。

**Method:** 提出了PPFL-RDSN框架，该框架集成了联邦学习（FL）、局部差分隐私和鲁棒模型水印技术，以确保数据在本地设备上安全，保护敏感信息并维护模型真实性。

**Result:** 经验评估表明，PPFL-RDSN在降低计算负担的同时，实现了与最先进的中心化方法相当的性能，并有效缓解了安全和隐私漏洞。

**Conclusion:** PPFL-RDSN是用于安全和隐私保护协作计算机视觉应用的一种实用解决方案。

> **ai_Abstract:** 该论文提出了PPFL-RDSN，一个结合联邦学习、局部差分隐私和模型水印的框架，旨在解决协作图像重建中中心化训练的隐私和计算挑战。它在保持与现有中心化方法相当的图像重建性能的同时，显著增强了数据隐私和模型安全性，并降低了计算负担。

> **摘要翻译:** 使用残差密集空间网络（RDSN）从低分辨率输入重建高质量图像至关重要但充满挑战，尤其是在协作场景中，中心化训练带来了显著的隐私风险，包括数据泄露和推断攻击，以及高昂的计算成本。我们提出了一种新颖的基于隐私保护联邦学习的残差密集空间网络（PPFL-RDSN）框架，专门为有损图像重建量身定制。PPFL-RDSN集成了联邦学习（FL）、局部差分隐私和鲁棒模型水印技术，确保数据在本地设备上安全，保护敏感信息，并在不泄露底层数据的情况下保持模型真实性。实证评估表明，PPFL-RDSN在降低计算负担的同时，实现了与最先进的中心化方法相当的性能，并有效缓解了安全和隐私漏洞，使其成为安全和隐私保护协作计算机视觉应用的实用解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [266] [Generalizing to New Dynamical Systems via Frequency Domain Adaptation](https://arxiv.org/abs/2507.00025)
> *通过频域自适应泛化到新的动力系统*

*Tiexin Qin, Hong Yan, Haoliang Li* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 动力系统, 泛化, 频域自适应, 傅里叶神经模拟器, 参数高效

**Comment:** Accepted by TPAMI 2025

> **TL;DR:** FNSDA是一种参数高效的方法，通过在傅里叶空间中进行自适应，可以很好地泛化到具有相同通用动力学但环境特征不同的新动力系统。

**AI_Comments:** 该论文提出了一种新颖的频域自适应方法FNSDA，解决了深度学习模型在动力系统泛化能力不足的问题。其创新点在于利用傅里叶空间进行参数高效的自适应，并通过自动划分傅里叶模式和条件化低维潜在参数来实现高效泛化。该方法在降低参数成本的同时提升了泛化性能，对于复杂物理动力学的建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度神经网络方法在从数据中学习底层动力学时，难以泛化到由相同通用动力学控制但环境特征不同的新系统，这限制了它们在特定领域做出可靠预测的能力。

**Method:** 本文提出了一种参数高效的方法，傅里叶神经动力学自适应模拟器（FNSDA）。FNSDA通过在傅里叶空间进行自适应来泛化到新的动力学系统。具体来说，FNSDA利用傅里叶模式的自动划分，识别基于已知环境的可共享动力学，并通过以低维潜在系统参数为条件来调整每个新环境特有的模式，以实现高效泛化。

**Result:** FNSDA在四种代表性动力系统家族上进行了评估，结果表明，与现有方法相比，FNSDA以显著降低的参数成本实现了优异或具有竞争力的泛化性能。

**Conclusion:** FNSDA通过在傅里叶空间中进行参数高效的自适应，有效解决了深度学习模型在动力系统泛化方面的挑战，实现了在新环境下的优越性能。

> **ai_Abstract:** 本文提出了一种名为傅里叶神经动力学自适应模拟器（FNSDA）的参数高效方法，旨在解决深度神经网络在泛化到具有相同通用动力学但环境特征不同的新动力系统时的挑战。FNSDA通过在傅里叶空间中自适应，利用傅里叶模式的自动划分来识别可共享动力学，并通过条件化低维潜在系统参数来调整特定模式。实验结果表明，FNSDA在泛化性能上优于或媲美现有方法，同时显著降低了参数成本。

> **摘要翻译:** 通过频域自适应泛化到新的动力系统

利用深度神经网络从数据中学习底层动力学，在建模各种复杂物理动力学方面展现了卓越的潜力。然而，当前的方法在特定领域进行可靠预测的能力受到限制，并且难以泛化到由相同通用动力学控制但环境特征不同的未知系统。在这项工作中，我们提出了一种参数高效的方法，即用于动力学自适应的傅里叶神经模拟器（FNSDA），该方法可以通过在傅里叶空间中进行自适应，轻松泛化到新的动力学系统。具体而言，FNSDA基于已知环境，利用傅里叶模式的自动划分来识别可共享的动力学，并通过以低维潜在系统参数为条件来调整每个新环境特有的模式，从而实现高效泛化。我们在四种代表性动力系统家族上评估了我们的方法，结果表明FNSDA与现有方法相比，以显著降低的参数成本实现了优异或具有竞争力的泛化性能。我们的代码可在https://github.com/WonderSeven/FNSDA获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [271] [Exploring Large Action Sets with Hyperspherical Embeddings using von Mises-Fisher Sampling](https://arxiv.org/abs/2507.00518)
> *使用von Mises-Fisher采样探索基于超球体嵌入的大型动作集*

*Walid Bendada, Guillaume Salha-Galvan, Romain Hennequin, Théo Bontempelli, Thomas Bouabça, Tristan Cazenave* | **Category: cs.LG, cs.IR**

**Keywords:** 强化学习, 动作探索, 超球体嵌入, von Mises-Fisher分布, 可伸缩性

**Comment:** 42nd International Conference on Machine Learning (ICML 2025)

> **TL;DR:** 本文提出vMF-exp，一种可扩展的强化学习方法，用于探索具有超球体嵌入的大型动作集，通过vMF分布采样并探索最近邻，解决了玻尔兹曼探索的伸缩性问题，并在理论和实践中得到验证。

**AI_Comments:** 本文提出了一种新颖且可扩展的探索方法vMF-exp，其创新点在于利用von Mises-Fisher分布和最近邻搜索来高效处理超球体嵌入空间中的大型动作集。这解决了传统方法（如B-exp）在动作空间巨大时的计算瓶颈。该方法的理论分析和在真实世界应用中的成功部署，突显了其在实际强化学习和推荐系统等领域的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在强化学习问题中，当动作由超球体嵌入向量表示时，探索大型动作集面临可伸缩性挑战。现有的玻尔兹曼探索（B-exp）等方法因需要计算每个动作的softmax值而存在伸缩性问题。

**Method:** 本文引入了von Mises-Fisher探索（vMF-exp），这是一种可扩展的方法。它首先使用von Mises-Fisher分布对状态嵌入表示进行采样，然后探索该表示的最近邻。这种方法可以扩展到几乎无限数量的候选动作。

**Result:** 在理论假设下，vMF-exp渐近地保持与玻尔兹曼探索（B-exp）相同的探索每个动作的概率。通过在模拟数据、真实世界公共数据以及在全球音乐流媒体服务的推荐系统上成功的大规模部署，经验性地验证了所提出方法的关键特性。

**Conclusion:** vMF-exp作为玻尔兹曼探索（B-exp）的一种可扩展替代方案，能够有效地探索具有超球体嵌入的大型动作集。

> **ai_Abstract:** 本文提出了一种名为vMF-exp的可扩展方法，旨在解决强化学习中探索由超球体嵌入表示的大型动作集所面临的伸缩性问题。vMF-exp通过von Mises-Fisher分布采样状态嵌入，并探索其最近邻，从而能够处理无限数量的动作。理论分析表明，vMF-exp在探索概率上与流行的玻尔兹曼探索（B-exp）渐近等效，但解决了B-exp的伸缩性限制。实验结果在模拟数据、真实世界数据和实际推荐系统部署中验证了其有效性。

> **摘要翻译:** 本文介绍了von Mises-Fisher探索（vMF-exp），这是一种可扩展的方法，用于在强化学习问题中探索大型动作集，其中超球体嵌入向量表示这些动作。vMF-exp涉及首先使用von Mises-Fisher分布采样状态嵌入表示，然后探索该表示的最近邻，这可以扩展到几乎无限数量的候选动作。我们表明，在理论假设下，vMF-exp渐近地保持与玻尔兹曼探索（B-exp）相同的探索每个动作的概率，而B-exp虽然是一种流行的替代方案，但由于需要计算每个动作的softmax值而存在可伸缩性问题。因此，vMF-exp可作为B-exp的一种可扩展替代方案，用于探索具有超球体嵌入的大型动作集。在模拟数据、真实世界公共数据以及在全球音乐流媒体服务的推荐系统上成功大规模部署vMF-exp的实验，都经验性地验证了所提出方法的关键特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [277] [Graph Neural Networks in Wind Power Forecasting](https://arxiv.org/abs/2507.00105)
> *风电预测中的图神经网络*

*Javier Castellano, Ignacio Villanueva* | **Category: cs.LG, cs.SY, eess.SY**

**Keywords:** 图神经网络, 风电预测, 数值天气预报, 卷积神经网络

**Comment:** 

> **TL;DR:** 研究了图神经网络在风电预测中的应用，发现其性能与最佳CNN模型相当。

**AI_Comments:** 该研究创新性地将图神经网络应用于风电预测，并证明其性能可与成熟的CNN方法媲美，这为风电预测提供了新的技术路径和研究方向。其重要性在于拓宽了GNN的应用边界，并可能为未来更精确、更高效的风电预测模型奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 研究图神经网络（GNNs）在风能预测问题上的适用性，以评估其在该领域的潜力。

**Method:** 该研究在三个风力发电设施上进行，使用了五年的历史数据。数值天气预报（NWP）变量被用作预测因子，并将GNN模型与基于CNN的基准模型进行比较。模型在24至36小时的提前测试范围内进行评估。

**Result:** 某些图神经网络（GNN）架构的性能与最佳的基于卷积神经网络（CNN）的基准模型相当。

**Conclusion:** 图神经网络（GNNs）在风电预测领域具有与现有最佳CNN方法相当的潜力，是解决该问题的一种有效方法。

> **ai_Abstract:** 本研究探讨了图神经网络（GNNs）在风电预测中的应用。通过在三个风力发电设施上使用五年历史数据和数值天气预报变量进行评估，结果表明部分GNN架构的预测性能可与最佳的卷积神经网络（CNN）基准模型相媲美。模型在24至36小时的提前预测范围内进行了测试。

> **摘要翻译:** 我们研究了图神经网络（GNNs）在风能预测问题中的适用性。我们发现某些架构的性能与我们最佳的基于卷积神经网络（CNN）的基准模型相当。这项研究在三个风力发电设施上进行，使用了五年的历史数据。数值天气预报（NWP）变量被用作预测因子，模型在24至36小时的提前测试范围内进行评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [284] [HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation](https://arxiv.org/abs/2507.00028)
> *HiT-JEPA：一种用于相似度计算的分层自监督轨迹嵌入框架*

*Lihuan Li, Hao Xue, Shuang Ao, Yang Song, Flora Salim* | **Category: cs.LG, cs.AI, cs.CV**

**Keywords:** 轨迹嵌入, 自监督学习, 分层表示, 相似度计算, 城市轨迹

**Comment:** 

> **TL;DR:** HiT-JEPA是一个分层自监督框架，用于学习多尺度城市轨迹表示，以更好地捕获细粒度细节和高层摘要，并在轨迹相似度计算方面表现出色。

**AI_Comments:** HiT-JEPA的创新之处在于其分层自监督学习方法，能够有效地整合轨迹数据的多尺度信息，从点级细节到高层抽象。这解决了现有方法在捕捉长期依赖和局部细微差别方面的不足，对于城市轨迹数据分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在轨迹表示中难以同时捕捉细粒度细节和高层摘要，限制了其处理长期依赖性并保留局部细微差别的能力。城市轨迹数据表示对于有效分析空间运动模式至关重要。

**Method:** 本文提出了HiT-JEPA（通过联合嵌入预测架构的轨迹语义分层交互），这是一个统一的框架，用于学习跨语义抽象级别的多尺度城市轨迹表示。HiT-JEPA采用三层层次结构，逐步捕获点级细粒度细节、中间模式和高层轨迹抽象，使模型能够在一个连贯的结构中整合局部动态和全局语义。

**Result:** 在多个真实世界数据集上进行的轨迹相似度计算的广泛实验表明，HiT-JEPA的分层设计产生了更丰富、多尺度的表示。

**Conclusion:** HiT-JEPA通过其分层设计，成功解决了现有方法在轨迹表示中难以同时捕捉细粒度细节和高层摘要的问题，从而提供了更丰富、多尺度的轨迹表示，并有效提升了轨迹相似度计算的性能。

> **ai_Abstract:** 本文提出了HiT-JEPA，一个分层自监督的轨迹嵌入框架，旨在解决现有方法在城市轨迹数据表示中难以同时捕获细粒度细节和高层摘要的问题。HiT-JEPA采用三层层次结构来学习多尺度轨迹表示，从而能够在一个统一的模型中整合局部动态和全局语义。在多个真实世界数据集上的实验证明，HiT-JEPA的分层设计能够产生更丰富、多尺度的表示，尤其适用于轨迹相似度计算。

> **摘要翻译:** 城市轨迹数据的表示在有效分析空间运动模式中起着关键作用。尽管取得了相当大的进展，但设计能够捕获多样化和互补信息的轨迹表示仍然是一个开放的研究问题。现有方法难以将轨迹的细粒度细节和高层摘要整合到单一模型中，限制了它们在保留局部细微差别的同时关注长期依赖的能力。为了解决这个问题，我们提出了HiT-JEPA（通过联合嵌入预测架构的轨迹语义分层交互），这是一个用于学习跨语义抽象级别的多尺度城市轨迹表示的统一框架。HiT-JEPA采用三层层次结构，逐步捕获点级细粒度细节、中间模式和高层轨迹抽象，使模型能够在一个连贯的结构中整合局部动态和全局语义。在多个真实世界数据集上进行的轨迹相似度计算的广泛实验表明，HiT-JEPA的分层设计产生了更丰富、多尺度的表示。代码可在以下网址获取：https://anonymous.4open.science/r/HiT-JEPA。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [292] [LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing](https://arxiv.org/abs/2507.00029)
> *LoRA-Mixer：通过串行注意力路由协调模块化LoRA专家*

*Wenbing Li, Zikai Song, Hang Zhou, Yunyao Zhang, Junqing Yu, Wei Yang* | **Category: cs.LG, cs.AI**

**Keywords:** LoRA, MoE, 大型语言模型, 参数效率, 注意力路由

**Comment:** 

> **TL;DR:** LoRA-Mixer是一个模块化、轻量级的MoE框架，通过动态路由的LoRA专家替换注意力模块的投影矩阵，提高了LLM在多任务适应上的参数效率和性能。

**AI_Comments:** LoRA-Mixer的创新之处在于其将LoRA专家集成到注意力模块的投影矩阵中，并引入动态路由机制，这避免了传统MoE方法中替换整个层或并联分支带来的参数效率问题。其提出的硬-软路由策略和自适应专业化平衡损失（SBL）对于在有限数据下实现鲁棒训练和高效专家重用至关重要。该方法不仅提高了性能，还显著降低了参数量，展现了其在LLM高效适应方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有将LoRA与MoE结合用于LLM多任务适应的方法存在局限性，它们要么替换整个注意力/前馈层，要么并联专家分支，导致参数效率和任务忠实度降低。

**Method:** 提出LoRA-Mixer，一个模块化、轻量级的MoE框架，集成了LoRA专家。核心创新在于用动态路由、任务特定的LoRA专家替换注意力模块输入/输出线性层的投影矩阵。该框架支持两种操作范式：1) 通过新颖的硬-软路由策略联合优化LoRA专家和路由机制；2) 直接部署来自外部存储库的预训练、冻结的LoRA模块。引入自适应专业化平衡损失（SBL）来联合优化专家平衡和任务特定对齐，以实现有限数据下的鲁棒路由器训练、稳定的路由决策和专家重用最大化。

**Result:** 在七个基准数据集（包括MedQA、CoLA、SST-2、GSM8K、ARC-E、ARC-C和HumanEval）上进行了广泛实验。在GSM8K、HumanEval和MedQA等数据集上，LoRA-Mixer比基础模型分别显著提高了7.61%、4.88%和3.08%。与最先进的方法相比，LoRA-Mixer使用仅48%的参数分别额外提高了1.09%、1.45%和1.68%。

**Conclusion:** LoRA-Mixer是一个高效且性能强大的框架，通过创新的LoRA专家集成和路由机制，有效解决了LLM多任务适应中现有LoRA-MoE方法的参数效率和任务忠实度问题，并在多个基准测试中取得了显著提升。

> **ai_Abstract:** LoRA-Mixer是一个针对大型语言模型多任务适应的模块化、轻量级专家混合（MoE）框架。它通过用动态路由的LoRA专家替换注意力模块的投影矩阵，解决了现有LoRA-MoE方法在参数效率和任务忠实度上的不足。该框架支持联合优化路由和专家或直接部署预训练LoRA模块，并引入了自适应专业化平衡损失（SBL）以优化专家平衡和任务对齐。实验证明LoRA-Mixer在多个基准数据集上显著优于基线模型和现有最先进方法，同时显著降低了参数量。

> **摘要翻译:** **标题**：LoRA-Mixer：通过串行注意力路由协调模块化LoRA专家

**摘要**：近期将低秩适应（LoRA）与专家混合（MoE）结合用于大型语言模型（LLMs）多任务适应的努力仍存在普遍局限性：它们要么用切换专家替换整个注意力/前馈层，要么并联专家分支，从而稀释了参数效率和任务忠实度。我们提出了LoRA-Mixer，一个模块化、轻量级的MoE框架，它集成了LoRA专家。我们的核心创新在于用动态路由、任务特定的LoRA专家替换注意力模块输入/输出线性层的投影矩阵。这种设计通过利用Transformer和状态空间模型（SSMs）等基础模型固有的线性投影结构，确保了与各种基础模型的无缝兼容性。该框架支持两种操作范式：(1) 通过新颖的硬-软路由策略联合优化LoRA专家和路由机制，或 (2) 直接部署来自外部存储库的预训练、冻结的LoRA模块。为了在有限数据下实现鲁棒的路由器训练，同时确保稳定的路由决策并最大化专家重用，我们引入了一种自适应专业化平衡损失（SBL），该损失联合优化专家平衡和任务特定对齐。在包括MedQA、CoLA、SST-2、GSM8K、ARC-E、ARC-C和HumanEval在内的七个基准数据集上进行的广泛实验证明了LoRA-Mixer的有效性。在GSM8K、HumanEval和MedQA等数据集上，LoRA-Mixer分别比基础模型显著提高了7.61%、4.88%和3.08%。与最先进的方法相比，LoRA-Mixer使用仅48%的参数分别额外提高了1.09%、1.45%和1.68%，这表明了其效率和强大的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.00030)
> *动态环境中深度强化学习的自适应动作持续时间与上下文老虎机*

*Abhishek Verma, Nallarasan V, Balaraman Ravindran* | **Category: cs.LG, cs.AI**

**Keywords:** 深度强化学习, 上下文老虎机, 动作持续时间, DQN, Atari 2600

**Comment:** 

> **TL;DR:** 本文提出了一种将上下文老虎机与深度强化学习相结合的新范式，以自适应地选择动作持续时间，从而在Atari 2600游戏中显著提高性能。

**AI_Comments:** 该论文的创新点在于将上下文老虎机引入深度强化学习，以自适应地调整动作持续时间。这解决了传统DRL中动作时间尺度固定的局限性，提高了策略的灵活性和计算效率。其重要性在于为实时应用（如游戏和机器人）提供了更高效和可扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）在复杂顺序决策任务中取得了显著成功，但动作执行的时间尺度是一个关键但尚未充分探索的方面。研究旨在解决这一问题，以增强策略灵活性和计算效率。

**Method:** 提出了一种将上下文老虎机与深度强化学习（DRL）结合的新范式，以自适应地选择动作持续时间。具体而言，该方法通过一个上下文老虎机模块来增强深度Q网络（DQN），该模块学习根据状态上下文选择最佳动作重复率。

**Result:** 在Atari 2600游戏上的实验表明，与静态持续时间基线相比，性能有显著提高，突出了自适应时间抽象在DRL中的有效性。

**Conclusion:** 这种自适应动作持续时间的范式为游戏和机器人等实时应用提供了一个可扩展的解决方案，在这些应用中，动态动作持续时间至关重要。

> **ai_Abstract:** 本文提出了一种结合上下文老虎机与深度强化学习（DRL）的新方法，旨在解决DRL中动作执行时间尺度这一未充分探索的问题。通过增强深度Q网络（DQN）与上下文老虎机模块，该方法能够根据状态上下文自适应地选择最佳动作重复率。实验结果表明，在Atari 2600游戏上，该方法比固定动作持续时间的基线表现出显著的性能提升。这为实时应用中需要动态动作持续的场景提供了一个可扩展且有效的解决方案。

> **摘要翻译:** 深度强化学习（DRL）在复杂的顺序决策任务中取得了显著成功，例如玩Atari 2600游戏和掌握棋盘游戏。DRL中一个关键但尚未充分探索的方面是动作执行的时间尺度。我们提出了一种新颖的范式，将上下文老虎机与DRL相结合，以自适应地选择动作持续时间，从而增强策略灵活性和计算效率。我们的方法通过一个上下文老虎机模块来增强深度Q网络（DQN），该模块学习根据状态上下文选择最佳动作重复率。在Atari 2600游戏上的实验表明，与静态持续时间基线相比，性能有显著提高，突出了自适应时间抽象在DRL中的有效性。这种范式为游戏和机器人等实时应用提供了一个可扩展的解决方案，在这些应用中，动态动作持续时间至关重要。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [303] [Neural Augmented Kalman Filters for Road Network assisted GNSS positioning](https://arxiv.org/abs/2507.00654)
> *神经网络增强卡尔曼滤波器用于道路网络辅助GNSS定位*

*Hans van Gorp, Davide Belli, Amir Jalalirad, Bence Major* | **Category: cs.LG, cs.SY, eess.SP, eess.SY**

**Keywords:** GNSS定位, 卡尔曼滤波器, 道路网络, 深度学习, 时态图神经网络

**Comment:** Accepted to ICML 2025 workshop ML4Wireless

> **TL;DR:** 提出了一种结合时态图神经网络（TGNN）和卡尔曼滤波器（KF）的新方法，利用道路网络数据提高城市环境中GNSS定位的精度，相较于纯GNSS-KF，定位误差降低了29%。

**AI_Comments:** 该论文的创新点在于首次将深度学习（特别是时态图神经网络）与卡尔曼滤波器结合，并利用道路网络数据来提升GNSS在复杂城市环境中的定位精度。这克服了传统方法在灵活性和在线应用方面的不足。29%的定位误差降低是一个显著的改进，表明了该方法的实际应用潜力。其重要性在于为高精度城市定位提供了一种新的、鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** GNSS在城市环境中受多径和非视距误差影响导致精度下降。现有利用道路网络数据的方法局限于离线应用或缺乏灵活性和鲁棒性。

**Method:** 提出训练一个时态图神经网络（TGNN），将道路网络信息整合到卡尔曼滤波器（KF）中。TGNN旨在预测正确的路段及其相关不确定性，用于KF的测量更新步骤。

**Result:** 在真实GNSS数据和开源道路网络上验证了该方法，在挑战性场景下，定位误差比仅使用GNSS的KF降低了29%。

**Conclusion:** 该研究首次提出了一个基于深度学习的方法，联合使用道路网络数据和GNSS测量来确定用户位置。

> **ai_Abstract:** 该论文提出了一种新颖的方法，通过训练一个时态图神经网络（TGNN）来增强卡尔曼滤波器（KF），以利用道路网络数据提升在全球导航卫星系统（GNSS）在城市环境中的定位精度。该方法旨在解决传统GNSS在城市中因多径和非视距误差导致的精度问题，并克服现有道路网络辅助定位方法在离线应用和灵活性上的局限。实验结果表明，与仅使用GNSS的KF相比，该方法在挑战性场景下能将定位误差降低29%。据作者所知，这是首次结合深度学习、道路网络数据和GNSS测量进行用户定位的研究。

> **摘要翻译:** 全球导航卫星系统（GNSS）提供全球关键的定位信息，但在密集的城市环境中，其精度常受多径和非视距误差的影响而降低。道路网络数据可用于减少这些误差的影响，提高定位系统的精度。以往利用道路网络数据的工作要么仅限于离线应用，要么依赖于卡尔曼滤波器（KF）的启发式方法，缺乏灵活性和鲁棒性。我们转而提出训练一个时态图神经网络（TGNN），将道路网络信息整合到KF中。TGNN旨在预测正确的路段及其相关不确定性，用于KF的测量更新步骤。我们使用真实世界的GNSS数据和开源道路网络验证了我们的方法，与仅使用GNSS的KF相比，在挑战性场景下，定位误差降低了29%。据我们所知，这是第一个联合使用道路网络数据和GNSS测量来确定地球上用户位置的基于深度学习的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [307] [Enhancing Spatio-Temporal Forecasting with Spatial Neighbourhood Fusion:A Case Study on COVID-19 Mobility in Peru](https://arxiv.org/abs/2507.00031)
> *通过空间邻域融合增强时空预测：以秘鲁COVID-19流动性为例*

*Chuan Li, Jiang You, Hassine Moungla, Vincent Gauthier, Miguel Nunez-del-Prado, Hugo Alatrista-Salas* | **Category: cs.LG**

**Keywords:** 时空预测, COVID-19流动性, 空间稀疏性, 空间邻域融合, H3网格

**Comment:** 

> **TL;DR:** 本研究提出了一种轻量级的空间邻域融合（SPN）技术，通过整合邻近单元格的信号来解决秘鲁COVID-19流动数据在时空预测中的空间稀疏性问题，实验证明该方法显著提高了预测性能。

**AI_Comments:** 该论文的创新点在于提出了一个轻量级且模型无关的空间邻域融合（SPN）技术，有效地解决了大规模COVID-19流动数据中的空间稀疏性挑战。其重要性在于提供了一种简单而有效的空间平滑方法，显著提升了时空预测的鲁棒性，这对于公共卫生危机期间的疫情理解和干预措施部署具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模人类流动性对于理解疫情传播和及时部署干预措施至关重要。然而，按小时计的六边形网格单元格流动计数存在空间稀疏性，这限制了传统时间序列模型的预测能力。

**Method:** 提出了一种轻量级且模型无关的空间邻域融合（SPN）技术。该技术通过聚合其直接H3邻居的信号来增强每个单元格的特征。该策略在NLinear、PatchTST和K-U-Net三种预测骨干网络上进行了评估，并考虑了不同的历史输入长度。

**Result:** SPN持续改进了预测性能，测试MSE（均方误差）降低了高达9.85%。

**Conclusion:** 我们的研究结果表明，稀疏移动信号的空间平滑为公共卫生危机期间的稳健时空预测提供了一条简单而有效的途径。

> **ai_Abstract:** 本研究旨在通过提出一种空间邻域融合（SPN）技术来解决秘鲁COVID-19流动性预测中遇到的空间稀疏性问题。通过利用秘鲁DCT应用的大规模时空数据集，SPN通过整合H3邻居的聚合信号来增强每个网格单元的特征。在NLinear、PatchTST和K-U-Net模型上的实验表明，SPN显著提高了预测精度，测试MSE降低了高达9.85%，证明了空间平滑在处理公共卫生危机中的稀疏时空数据方面的有效性。

> **摘要翻译:** 准确建模人类流动性对于理解疫情传播和及时部署干预措施至关重要。在这项工作中，我们利用秘鲁国家数字接触追踪（DCT）应用程序在COVID-19大流行期间收集的大规模时空数据集来预测城市区域的流动。一个关键挑战在于每小时流动计数在六边形网格单元格中的空间稀疏性，这限制了传统时间序列模型的预测能力。为了解决这个问题，我们提出了一种轻量级且模型无关的空间邻域融合（SPN）技术，该技术通过来自其直接H3邻居的聚合信号来增强每个单元格的特征。我们在NLinear、PatchTST和K-U-Net三种预测骨干网络上评估了这一策略，并考虑了各种历史输入长度。实验结果表明，SPN持续改进了预测性能，测试MSE（均方误差）降低了高达9.85%。我们的研究结果表明，稀疏移动信号的空间平滑为公共卫生危机期间的稳健时空预测提供了一条简单而有效的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [308] [Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems](https://arxiv.org/abs/2507.00358)
> *一类连续时间线性二次强化学习问题的数据驱动探索*

*Yilie Huang, Xun Yu Zhou* | **Category: cs.LG, cs.AI, cs.SY, eess.SY, math.OC**

**Keywords:** 连续时间强化学习, 线性二次, 数据驱动探索, 自适应探索, 次线性遗憾

**Comment:** 36 pages, 10 figures

> **TL;DR:** 本文提出了一种自适应数据驱动的探索机制，用于连续时间随机线性二次强化学习问题，实现了与现有最佳结果相当的次线性遗憾界，并加速了收敛。

**AI_Comments:** 该论文的创新点在于其提出的自适应探索机制，有效解决了传统固定探索策略在连续时间强化学习中存在的调优复杂和学习效率低下的问题。通过动态调整探索行为，它在保持理论性能（次线性遗憾界）的同时，显著提升了实际收敛速度和性能，对于此类LQ问题具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在解决连续时间随机线性二次（LQ）控制问题中，现有方法（如\[cite{huang2024sublinear}\]）采用的恒定或确定性探索策略需要大量调优且忽略学习进展的局限性，以提高学习效率。

**Method:** 提出了一种无模型、数据驱动的探索机制，该机制通过评论家自适应地调整熵正则化，并通过行动者自适应地调整策略方差。

**Result:** 该方法实现了次线性遗憾界，与该类LQ问题的已知最佳无模型结果相匹配，而这些结果此前仅通过固定探索策略获得。数值实验表明，自适应探索相比非自适应无模型和基于模型的方法，加速了收敛并改善了遗憾性能。

**Conclusion:** 所提出的自适应探索机制灵活且仅需最少调优，显著提高了连续时间LQ强化学习问题的学习效率，并达到了与现有最佳结果相当的遗憾界。

> **ai_Abstract:** 本文针对一类连续时间随机线性二次强化学习问题，提出了一种自适应、无模型、数据驱动的探索机制。该方法通过动态调整熵正则化和策略方差，克服了传统固定探索策略需要大量调优且效率低下的缺点。实验证明，该方法不仅能匹配现有最佳无模型结果的次线性遗憾界，还能显著加速收敛并提升遗憾性能。

> **摘要翻译:** 我们研究了与\cite{huang2024sublinear}中相同的一类连续时间随机线性二次（LQ）控制问题的强化学习（RL），其中波动性取决于状态和控制，而状态是标量值且缺少运行控制奖励。我们提出了一种无模型、数据驱动的探索机制，通过评论家自适应地调整熵正则化，并通过行动者自适应地调整策略方差。与\cite{huang2024sublinear}中采用的恒定或确定性探索策略不同，后者需要大量的实现调优并忽略迭代过程中的学习进展，我们的自适应探索方法以最小的调优提高了学习效率。尽管具有灵活性，我们的方法实现了次线性遗憾界，与该类LQ问题的已知最佳无模型结果相匹配，而这些结果此前仅通过固定探索策略获得。数值实验表明，与非自适应无模型和基于模型的方法相比，自适应探索加速了收敛并改善了遗憾性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [316] [IDRIFTNET: Physics-Driven Spatiotemporal Deep Learning for Iceberg Drift Forecasting](https://arxiv.org/abs/2507.00036)
> *IDRIFTNET：物理驱动的时空深度学习用于冰山漂移预测*

*Rohan Putatunda, Sanjay Purushotham, Ratnaksha Lele, Vandana P. Janeja* | **Category: cs.LG, physics.ao-ph**

**Keywords:** 冰山漂移, 预测, 深度学习, 物理驱动, 时空

**Comment:** 16 pages, 4 figures

> **TL;DR:** IDRIFTNET是一个物理驱动的深度学习模型，通过结合冰山漂移物理分析公式和增强残差学习模型，解决了冰山漂移预测中数据稀缺和复杂非线性运动的挑战，并在实际冰山数据上表现优于现有模型。

**AI_Comments:** IDRIFTNET的创新之处在于其将物理驱动模型与深度学习相结合的混合方法，有效克服了冰山漂移数据稀缺和运动复杂性的挑战。这种结合不仅提高了预测精度，也增强了模型的可解释性。该研究对于气候系统研究、海洋生态保护和极地航行安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测冰山轨迹是一个巨大的挑战，主要原因是时空数据稀缺以及冰山运动的复杂非线性特性，同时受到动态环境因素的影响。这些限制阻碍了深度学习模型有效捕捉潜在动态并提供可靠预测结果的能力。

**Method:** 本文提出了一个混合IDRIFTNET模型，这是一个物理驱动的深度学习模型。它将冰山漂移物理的分析公式与增强残差学习模型相结合。该模型学习分析解与地面真实观测之间不匹配的模式，并结合一个旋转增强光谱神经网络，该网络从数据中捕获全局和局部模式，以预测未来的冰山漂移位置。

**Result:** IDRIFTNET模型在南极冰山A23A和B22A上的性能优于最先进的模型，在不同时间点上实现了更低的最终位移误差（FDE）和平均位移误差（ADE）。

**Conclusion:** 这些结果突出表明IDRIFTNET在有限数据和动态环境条件下，有效捕捉冰山复杂非线性漂移并预测冰山轨迹的能力。

> **ai_Abstract:** 本文提出了IDRIFTNET，一个物理驱动的时空深度学习模型，旨在解决冰山漂移预测中数据稀缺和复杂非线性运动的挑战。该模型结合了冰山漂移物理的分析公式和增强残差学习，并通过旋转增强光谱神经网络捕捉数据中的全局和局部模式。在南极冰山A23A和B22A上的实验表明，IDRIFTNET在预测精度上优于现有最先进模型，显著降低了最终位移误差和平均位移误差，证明了其在复杂环境和有限数据下预测冰山轨迹的有效性。

> **摘要翻译:** 极地海洋中漂浮的冰山在地球气候系统中扮演着关键角色，影响着流入海洋的淡水通量和区域生态系统，同时也对极地航行构成挑战。然而，准确预测冰山轨迹仍然是一个艰巨的挑战，这主要是由于时空数据的稀缺性以及冰山运动的复杂非线性特性，后者也受到环境变量的影响。冰山运动受到多种动态环境因素的影响，形成一个高度可变的系统，使得轨迹识别变得复杂。这些限制阻碍了深度学习模型有效捕捉潜在动态并提供可靠预测结果的能力。为了应对这些挑战，我们提出了一个混合IDRIFTNET模型，这是一个物理驱动的深度学习模型，它结合了冰山漂移物理的分析公式和一个增强残差学习模型。该模型学习分析解与地面真实观测之间不匹配的模式，并结合一个旋转增强光谱神经网络，该网络从数据中捕获全局和局部模式，以预测未来的冰山漂移位置。我们将IDRIFTNET模型的性能与南极冰山A23A和B22A上的最先进模型进行了比较。我们的发现表明，IDRIFTNET在各种时间点上实现了更低的最终位移误差（FDE）和平均位移误差（ADE），从而优于其他模型。这些结果突出表明IDRIFTNET在有限数据和动态环境条件下，有效捕捉冰山复杂非线性漂移并预测冰山轨迹的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [318] [$μ^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation](https://arxiv.org/abs/2507.00316)
> *$μ^2$Tokenizer：用于放射学报告生成的差分多尺度多模态分词器*

*Siyou Li, Pengyao Qin, Huanan Wu, Dong Nie, Arun J. Thirunavukarasu, Juntao Yu, Le Zhang* | **Category: cs.LG, cs.CL, eess.IV**

**Keywords:** 放射学报告生成, 多模态, 分词器, 大型语言模型, 直接偏好优化

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** 该论文提出了一种名为$μ^2$LLM的多尺度多模态大型语言模型，并引入了$μ^2$Tokenizer作为其核心组件，用于自动化放射学报告生成，并在CT数据集上取得了优于现有方法的性能。

**AI_Comments:** 该论文的创新之处在于其提出的$μ^2$Tokenizer，它能够有效地整合来自视觉和文本模态的多尺度特征，这对于解决放射学报告生成中多源信息融合的复杂性至关重要。此外，通过直接偏好优化（DPO）结合GREEN-RedLlama进行训练，提升了模型生成报告的质量。在有限数据下取得优越性能，也突显了其在实际医疗应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动化放射学报告生成（RRG）旨在从临床影像中生成详细文本报告，以提高诊断准确性和效率。然而，RRG面临两大挑战：一是在资源受限下从影像数据中提取相关信息的固有复杂性；二是客观评估模型生成报告与专家报告之间差异的难度。

**Method:** 该论文提出了$μ^2$LLM，一个多尺度多模态大型语言模型，用于放射学报告生成（RRG）任务。其核心是一个名为$μ^2$Tokenizer的新型中间层，该层集成了来自多尺度视觉分词器和文本分词器的多模态特征。报告生成质量通过由GREEN-RedLlama指导的直接偏好优化（DPO）得到增强。

**Result:** 在四个大型CT图像-报告医学数据集上的实验结果表明，所提出的方法优于现有方法。

**Conclusion:** 微调后的$μ^2$LLM在有限数据下进行放射学报告生成任务显示出巨大潜力。

> **ai_Abstract:** 该论文提出了$μ^2$LLM，一个多尺度多模态大型语言模型，旨在解决自动化放射学报告生成（RRG）中的挑战。其核心创新是$μ^2$Tokenizer，它能够整合来自多尺度视觉和文本分词器的多模态特征。通过使用直接偏好优化（DPO）进行训练，该模型在多个大型CT图像-报告医学数据集上表现出优于现有方法的性能，证明了其在有限数据下进行RRG任务的有效性和潜力。

> **摘要翻译:** 自动化放射学报告生成（RRG）旨在从临床影像（如计算机断层扫描（CT）扫描）中生成详细的文本报告，以提高诊断的准确性和效率，并提供管理建议。RRG面临两个主要挑战：(1) 在资源受限下从影像数据中提取相关信息的固有复杂性，以及(2) 客观评估模型生成报告与专家撰写报告之间差异的难度。为了解决这些挑战，我们提出了$μ^2$LLM，一个用于RRG任务的多尺度多模态大型语言模型。作为中间层的新型$μ^2$Tokenizer集成了来自多尺度视觉分词器和文本分词器的多模态特征，然后通过由GREEN-RedLlama指导的直接偏好优化（DPO）来提高报告生成质量。在四个大型CT图像-报告医学数据集上的实验结果表明，我们的方法优于现有方法，突出了我们微调的$μ^2$LLM在有限数据下进行RRG任务的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [323] [Model Fusion via Neuron Interpolation](https://arxiv.org/abs/2507.00037)
> *通过神经元插值进行模型融合*

*Phoomraphee Luenam, Andreas Spanopoulos, Amit Sant, Thomas Hofmann, Sotiris Anagnostidis, Sidak Pal Singh* | **Category: cs.LG, cs.AI, I.2.6; I.2.1**

**Keywords:** 模型融合, 神经元插值, 神经网络, 零样本融合, 非IID

**Comment:** 5 figures, 15 tables, 23 pages

> **TL;DR:** 提出了一种新颖的、以神经元为中心的方法，通过整合神经元归因分数来有效融合多个神经网络，在零样本和非IID场景中表现优于现有技术。

**AI_Comments:** 该论文的创新点在于提出了一个以神经元为中心的模型融合框架，并首次将神经元归因分数整合到融合过程中，有效解决了模型内部表示差异带来的挑战。其能够泛化到任意层类型，并特别在零样本和非IID场景下表现出色，这对于实际应用中模型部署和更新具有重要意义，显示出其强大的鲁棒性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 模型融合旨在结合多个模型的知识，但由于内部表示的差异（如排列不变性、随机初始化或训练数据分布不同）而变得复杂和困难。

**Method:** 本文提出了一种新颖的、以神经元为中心的模型融合算法家族，旨在有效地将多个训练好的神经网络融合成一个单一网络，无论训练数据分布如何。该算法通过分组父模型的中间神经元来创建目标表示，并将其融合模型近似为相应的子网络。与以往方法不同，该方法将神经元归因分数纳入融合过程，并且可以推广到任意层类型。

**Result:** 在各种基准数据集上的实验结果表明，该算法始终优于以前的融合技术，特别是在零样本和非IID融合场景中。

**Conclusion:** 通过引入神经元插值和神经元归因分数，所提出的模型融合算法能够有效地整合多个神经网络，并在挑战性的融合场景中取得优越性能。

> **ai_Abstract:** 本文提出了一种名为“通过神经元插值进行模型融合”的新方法，旨在解决现有模型融合技术中因内部表示差异而导致的挑战。该方法引入了一个以神经元为中心的算法家族，通过对父模型的中间神经元进行分组并纳入神经元归因分数来有效地整合多个神经网络。实验证明，该方法在零样本和非IID融合场景中显著优于传统技术，展现了其在处理复杂数据分布下的强大能力。

> **摘要翻译:** 模型融合旨在通过创建一个代表性模型来结合多个模型的知识，该模型能够捕捉其所有父模型的优势。然而，由于内部表示的差异，这一过程并非易事，这些差异可能源于置换不变性、随机初始化或不同的训练数据分布。我们提出了一种新颖的、以神经元为中心的一系列模型融合算法，旨在有效地将多个训练好的神经网络集成到一个单一网络中，无论训练数据分布如何。我们的算法对父模型的中间神经元进行分组，以创建目标表示，融合模型通过其相应的子网络来近似这些表示。与以往的方法不同，我们的方法将神经元归因分数纳入融合过程。此外，我们的算法可以推广到任意层类型。在各种基准数据集上的实验结果表明，我们的算法始终优于以前的融合技术，特别是在零样本和非IID融合场景中。代码可在https://github.com/AndrewSpano/neuron-interpolation-model-fusion获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [326] [Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations](https://arxiv.org/abs/2507.00301)
> *结构保持的提升与学习：用于非线性守恒偏微分方程的科学机器学习*

*Harsh Sharma, Juan Diego Draxl Giannoni, Boris Kramer* | **Category: cs.LG, cs.NA, math.NA**

**Keywords:** 结构保持, 提升与学习, 科学机器学习, 降阶模型, 能量二次化

**Comment:** arXiv admin note: substantial text overlap with arXiv:2503.02273

> **TL;DR:** 提出了一种名为“结构保持提升与学习”的科学机器学习方法，通过能量二次化策略为非线性守恒偏微分方程构建高效且物理保持的降阶模型。

**AI_Comments:** 该论文的创新点在于结合了能量二次化策略与机器学习，使得非线性PDE的降阶模型学习变得高效且能够保持系统固有的物理结构。通过将非线性问题“提升”到线性域进行处理，极大地简化了模型学习过程，并确保了物理一致性。这种混合方法为科学机器学习在复杂非线性系统中的应用提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 针对非线性守恒偏微分方程，需要一种能够学习结构保持降阶模型的科学机器学习方法，以解决高维问题的计算效率和物理一致性问题。

**Method:** 提出了一种混合学习方法，基于能量二次化策略，利用PDE层面的非线性知识推导出等效的二次提升系统。该方法解析地推导二次降阶项，并通过约束优化问题学习剩余的线性降阶算子，从而以结构保持的方式构建计算高效的二次降阶模型。

**Result:** 该方法生成的二次降阶模型在计算效率和准确性方面与最先进的结构保持数据驱动模型降阶方法具有竞争力。通过一维波方程、二维Sine-Gordon方程和二维Klein-Gordon-Zakharov方程的数值例子，证明了所学模型的泛化能力。

**Conclusion:** 结构保持的提升与学习方法能够有效地为非线性守恒偏微分方程构建计算高效且物理保持的降阶模型，并在准确性和效率上表现出色。

> **ai_Abstract:** 本文提出了一种名为“结构保持提升与学习”的科学机器学习方法，旨在为具有守恒定律的非线性偏微分方程构建结构保持的降阶模型。该方法采用混合学习策略，基于能量二次化，将非线性系统转换为线性提升系统，从而高效学习模型。通过解析推导二次项并优化线性算子，该方法能够生成计算高效且尊重物理的二次降阶模型。数值实验证明，该方法在准确性和效率上均优于现有先进方法，并具有良好的泛化能力。

> **摘要翻译:** 这项工作提出了结构保持的“提升与学习”（Lift & Learn），这是一种科学机器学习方法，它采用提升变量变换来学习非线性偏微分方程（PDEs）的结构保持降阶模型，这些方程具有守恒定律。我们提出了一种基于最近开发的能量二次化策略的混合学习方法，该方法利用PDE层面的非线性知识推导出一个等价的二次提升系统，该系统具有二次系统能量。通过能量二次化获得的提升动力学在旧变量中是线性的，这使得在提升设置中模型学习非常有效。基于提升后的二次PDE模型形式，所提出的方法解析地推导了二次降阶项，然后利用这些推导出的项来制定一个约束优化问题，以结构保持的方式学习剩余的线性降阶算子。所提出的混合学习方法产生了计算高效的二次降阶模型，这些模型尊重高维问题的底层物理。我们通过三个数值例子：具有指数非线性的一维波动方程、二维Sine-Gordon方程和二维二维Klein-Gordon-Zakharov方程，证明了通过所提出的结构保持“提升与学习”方法学习到的二次模型的泛化能力。数值结果表明，所提出的学习方法在准确性和计算效率方面与最先进的结构保持数据驱动模型降阶方法具有竞争力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information](https://arxiv.org/abs/2507.00038)
> *质量优于数量：一种基于逐点V信息的高效大规模数据缩减策略*

*Fei Chen, Wenchi Zhou* | **Category: cs.LG, cs.AI**

**Keywords:** 数据缩减, 逐点V信息, PVI, 训练效率, 跨语言NLP

**Comment:** 

> **TL;DR:** 本文提出了一种基于逐点V信息（PVI）的有效数据缩减策略，通过识别并过滤低难度实例，以及采用渐进式学习，在保持或提升模型性能的同时显著提高大规模数据集的训练效率，并成功应用于中文NLP任务。

**AI_Comments:** 这篇论文的创新点在于提出了基于逐点V信息（PVI）的数据缩减策略，并将其成功应用于跨语言（中文NLP）场景，证明了其在提升训练效率和模型性能方面的有效性。其“质量优于数量”的理念在数据爆炸的时代具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据中心AI中，大规模数据集的训练效率和数据质量是核心挑战，需要有效识别最具信息量的实例进行模型训练，而非使用整个数据集。

**Method:** 本文提出基于逐点V信息（PVI）的数据缩减策略。首先，使用PVI量化实例难度并过滤掉低难度实例（静态方法）。其次，采用渐进式学习，在按PVI升序排序的实例上训练分类器。此外，将PVI框架从英语数据集迁移到中文NLP任务和基础模型。

**Result:** 实验表明，移除10%-30%的数据仅导致分类器准确率损失0.0001%至0.76%。渐进式学习加速收敛并比传统训练获得0.8%的准确率提升。PVI框架成功应用于中文NLP任务，获得跨语言数据缩减和更快训练的见解。

**Conclusion:** 通过有效的PVI数据缩减策略，在选择的最佳子集上训练分类器可以提高模型性能并提升训练效率，且该策略可应用于跨语言数据缩减。

> **ai_Abstract:** 本文提出了一种名为逐点V信息（PVI）的有效大规模数据缩减策略，旨在解决数据中心AI中大规模数据集的训练效率和数据质量挑战。该策略通过量化实例难度并过滤低难度实例，以及采用渐进式学习，在移除10%-30%数据的情况下保持甚至提升模型性能（最高提升0.8%准确率），同时显著加速训练。该方法已成功应用于中文NLP任务，并提供了跨语言数据缩减的见解。

> **摘要翻译:** 数据缩减在以数据为中心的AI中发挥着至关重要的作用，它通过在大规模数据集中识别最具信息量的实例来提高模型训练效率。核心挑战在于如何选择最优实例而非整个数据集，以提高数据质量和训练效率。在本文中，我们提出了一种基于逐点V信息（PVI）的有效数据缩减策略。首先，我们使用PVI量化实例难度，并过滤掉低难度实例，从而实现一种静态方法。实验表明，移除10%-30%的数据可以保持分类器性能，准确率损失仅为0.0001%到0.76%。其次，我们采用渐进式学习方法，在按PVI升序排序的实例上训练分类器，从而加速收敛并比传统训练获得0.8%的准确率提升。我们的结果表明，通过有效的数据缩减策略，在选择的最佳子集上训练分类器可以提高模型性能并提升训练效率。此外，我们将以前仅应用于英语数据集的PVI框架迁移到多样化的中文NLP任务和基础模型中，为跨语言数据缩减和更快的训练带来了宝贵的见解。代码已在https://github.com/zhouwenchi/DatasetReductionStrategy 发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [331] [A Test-Function Approach to Incremental Stability](https://arxiv.org/abs/2507.00695)
> *一种增量稳定性测试函数方法*

*Daniel Pfrommer, Max Simchowitz, Ali Jadbabaie* | **Category: cs.LG, cs.SY, eess.SY**

**Keywords:** 增量稳定性, 测试函数, 强化学习, 价值函数, Lyapunov函数

**Comment:** 8 pages

> **TL;DR:** 本文提出了一种基于奖励作为“测试函数”的新颖框架，用于分析增量输入-状态稳定性（δISS）。它建立了闭环系统增量输入-状态稳定性与强化学习（RL）风格价值函数正则性之间的新等价关系，提供了一种不同于传统Lyapunov方法的稳定性理解。

**AI_Comments:** 本文的创新之处在于，它为理解强化学习中的价值函数与控制理论中的增量稳定性之间提供了一个新颖的桥梁。通过引入“测试函数”的概念并建立新的等价关系，该研究成功地将RL价值函数的特性与系统稳定性联系起来，突破了传统Lyapunov方法的局限性。这对于将控制理论的严谨性引入到强化学习的分析中具有重要意义，尤其是在处理非光滑和无界奖励函数的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 传统的控制理论使用满足时间衰减条件的Lyapunov函数来分析稳定性，而强化学习（RL）的价值函数通过指数衰减的Lipschitz奖励函数构建，可能非光滑且双边无界，因此不能直接作为Lyapunov证书。本文旨在弥合这一差距，为RL风格价值函数提供一种理解增量稳定性的新方法。

**Method:** 本文提出了一种基于奖励作为“测试函数”的新颖框架来分析增量输入-状态稳定性（δISS）。具体方法是开发了一种新的等价关系，连接了在给定策略下闭环系统的增量输入-状态稳定性与在对抗性选择的H"older连续奖励函数下RL风格价值函数的正则性。

**Result:** 研究结果表明，在给定策略下闭环系统的增量输入-状态稳定性与在对抗性选择的H"older连续奖励函数下RL风格价值函数的正则性之间存在新的等价关系。这突出了价值函数的正则性及其与增量稳定性的联系，可以以一种不同于传统基于Lyapunov方法的控制理论稳定性认证方式来理解。

**Conclusion:** 本文得出结论，价值函数的正则性及其与增量稳定性的联系可以通过一种不同于控制理论中传统基于Lyapunov方法的稳定性认证方式来理解。这为RL风格的价值函数提供了一种新的稳定性分析视角。

> **ai_Abstract:** 本文提出了一种利用奖励作为“测试函数”的新框架，用于分析增量输入-状态稳定性（δISS）。针对RL价值函数与传统Lyapunov函数在性质上的差异，文章建立了一种新的等价关系：在给定策略下闭环系统的δISS与在对抗性H"older连续奖励函数下RL风格价值函数的正则性等价。这一发现提供了一种理解价值函数正则性及其与增量稳定性关系的新视角，区别于传统的基于Lyapunov的稳定性认证方法。

> **摘要翻译:** 本文提出了一种分析增量输入-状态稳定性（δISS）的新颖框架，该框架基于将奖励用作“测试函数”的思想。控制理论传统上处理满足时间衰减条件的Lyapunov函数，而强化学习（RL）的价值函数是通过指数衰减的Lipschitz奖励函数构建的，该奖励函数可能非光滑且双边无界。因此，这些RL风格的价值函数不能直接被理解为Lyapunov证书。我们开发了一种新的等价关系，连接了在给定策略下闭环系统的增量输入-状态稳定性与在对抗性选择的H"older连续奖励函数下RL风格价值函数的正则性。这一结果突出表明，价值函数的正则性及其与增量稳定性的联系，可以以一种不同于控制理论中传统基于Lyapunov方法的稳定性认证方式来理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [Privacy-Preserving Quantized Federated Learning with Diverse Precision](https://arxiv.org/abs/2507.00920)
> *隐私保护的量化联邦学习与多样化精度*

*Dang Qua Nguyen, Morteza Hashemi, Erik Perrins, Sergiy A. Vorobyov, David J. Love, Taejoon Kim* | **Category: cs.LG, eess.SP**

**Keywords:** 联邦学习, 隐私保护, 量化, 差分隐私, 异构性

**Comment:** 

> **TL;DR:** 本文提出了一种新型随机量化器（SQ）和聚合技术，旨在联邦学习中同时实现差分隐私和最小量化误差，并支持具有不同量化精度的设备参与，从而提升学习效用。

**AI_Comments:** 这篇论文的创新点在于同时解决了联邦学习中的隐私保护和异构量化精度问题，通过提出新型随机量化器(SQ)确保了有界失真，并结合了聚类优化和线性融合策略，提高了实际应用中的可用性。其在隐私和效用之间的权衡方面提供了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习面临两大挑战：一是本地模型更新传输过程中的隐私风险；二是参与设备间模型量化分辨率异构性导致的学习效用下降。现有工作通常未能同时解决这两个问题。

**Method:** 本文提出了一种新型随机量化器（SQ），旨在同时实现差分隐私（DP）和最小量化误差，并保证有界失真。此外，为解决量化异构性，结合了聚类大小优化技术和线性融合方法，以提高模型聚合精度。

**Result:** 数值模拟结果表明，与传统的LaplaceSQ-FL算法相比，所提出的方法在隐私保护和学习效用方面均表现出优势。

**Conclusion:** 本文提出的方法成功地在联邦学习中实现了隐私保护和学习效用的提升，同时有效应对了设备间量化精度的异构性问题。

> **ai_Abstract:** 本文提出了一种在联邦学习中同时解决隐私保护和量化异构性导致的学习效用下降问题的新方法。通过引入一种新型随机量化器（SQ），实现了差分隐私和最小量化误差，并保证有界失真。此外，结合聚类大小优化和线性融合技术，提高了模型聚合精度。数值模拟结果表明，该方法在隐私保护和学习效用方面优于现有算法。

> **摘要翻译:** 联邦学习（FL）已成为一种有前景的分布式机器学习范式，它使得在不要求共享原始数据的情况下，跨多个本地设备协作训练全局模型成为可能。尽管取得了进展，但FL受以下因素限制：(i) 源于本地模型更新传输到融合中心（FC）时未受保护而产生的隐私风险，以及 (ii) 参与设备间模型量化分辨率异构性导致的学习效用下降。以往的工作通常只解决其中一个挑战，因为在隐私风险和量化异构性下保持学习效用是一项非平凡的任务。因此，在本文中，我们的目标是提高隐私保护型FL的学习效用，该FL允许具有不同量化分辨率的设备集群参与每个FL轮次。具体而言，我们引入了一种新颖的随机量化器（SQ），旨在同时实现差分隐私（DP）和最小量化误差。值得注意的是，所提出的SQ保证了有界失真，这与其他DP方法不同。为了解决量化异构性，我们引入了一种聚类大小优化技术，并结合线性融合方法来提高模型聚合精度。数值模拟验证了我们的方法在隐私保护和学习效用方面优于传统的LaplaceSQ-FL算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [336] [Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing](https://arxiv.org/abs/2507.00039)
> *基于模式的图分类：质量度量比较与预处理的重要性*

*Lucas Potin, Rosa Figueiredo, Vincent Labatut, Christine Largeron* | **Category: cs.LG, cs.AI**

**Keywords:** 图分类, 模式挖掘, 质量度量, 预处理, 比较分析

**Comment:** 

> **TL;DR:** 本文对38种用于基于模式的图分类的质量度量进行了比较分析，并提出了一种基于聚类的预处理步骤，以提高分类性能并减少模式数量。

**AI_Comments:** 本文的创新之处在于对大量图模式质量度量进行了首次专门针对图的全面比较，并引入了一种有效的基于聚类的预处理步骤。这项工作的重要性在于它为选择合适的质量度量提供了指导，并证明了预处理在提高图分类效率和性能方面的潜力。研究结果挑战了业界对某些流行度量的普遍看法，为未来的研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 在基于模式的图分类中，选择合适的模式质量度量很困难，现有文献中缺乏针对图的度量比较研究，导致普遍使用流行度量而缺乏彻底评估。

**Method:** 本文对文献中38种质量度量进行了理论特征化（基于四种数学属性），并利用公开数据集构建基准，提出了一种模式黄金标准排序方法。通过实证比较这些度量在模式排序和分类性能方面的表现。此外，提出了一种基于聚类的预处理步骤，将出现在相同图中的模式进行分组，以提高分类性能。

**Result:** 实验结果表明，所提出的预处理步骤是有效的，它在实现可比性能的同时减少了需要处理的模式数量。此外，研究发现文献中一些广泛使用的流行度量并未与最佳结果相关联。

**Conclusion:** 本文通过对多种质量度量进行全面比较，并引入有效的预处理步骤，为基于模式的图分类提供了深入见解，证明了预处理的重要性，并挑战了流行度量的普遍适用性。

> **ai_Abstract:** 本研究针对基于模式的图分类中质量度量选择困难的问题，对文献中38种质量度量进行了理论和实证比较分析。研究利用公开数据集建立了基准，并提出了一种生成模式黄金标准排序的方法。此外，本文引入了一种新颖的基于聚类的预处理步骤，旨在通过分组相关模式来提高分类性能并减少模式数量。实验结果证实了该预处理步骤的有效性，并揭示了一些流行度量并非总是表现最佳。

> **摘要翻译:** 图分类旨在根据图的结构和属性特征对图进行分类，在社交网络分析和生物信息学等不同领域都有应用。在解决此任务的现有方法中，那些依赖模式（即子图）的方法提供了良好的可解释性，因为用于分类的模式可以直接解释。为了识别有意义的模式，一种标准方法是使用质量度量，即评估每个模式区分能力的函数。然而，文献中提供了数十种此类度量，这使得为给定应用选择最合适的度量变得困难。只有少数调查试图通过比较这些度量来提供一些见解，但没有一个专门关注图。这通常导致系统地使用最广泛的度量，而没有经过彻底评估。为了解决这个问题，我们对文献中的38种质量度量进行了比较分析。我们基于四种数学属性对它们进行了理论特征化。我们利用公开数据集构建了一个基准，并提出了一种制定模式黄金标准排序的方法。我们利用这些资源对这些度量进行了实证比较，包括模式排序和分类性能。此外，我们提出了一种基于聚类的预处理步骤，该步骤将出现在相同图中的模式进行分组，以提高分类性能。我们的实验结果证明了此步骤的有效性，它在实现可比性能的同时减少了需要处理的模式数量。此外，我们还表明，文献中一些广泛使用的流行度量并未与最佳结果相关联。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [351] [Fractional Policy Gradients: Reinforcement Learning with Long-Term Memory](https://arxiv.org/abs/2507.00073)
> *分数阶策略梯度：具有长期记忆的强化学习*

*Urvi Pawar, Kunal Telangi* | **Category: cs.LG, stat.ML, I.2.6; I.2.8**

**Keywords:** 分数阶策略梯度, 强化学习, 长期记忆, 分数阶微积分, 采样效率

**Comment:** Submitted to Journal of Machine Learning Research (JMLR), June 2025.
  24 pages, 3 figures. Under review

> **TL;DR:** 分数阶策略梯度（FPG）利用分数阶微积分，通过引入长期记忆来克服传统强化学习中马尔可夫假设的局限性，从而提高采样效率和降低方差。

**AI_Comments:** FPG的创新之处在于将分数阶微积分引入强化学习，以解决长期依赖性问题，这为策略优化提供了一个新的数学工具。其优势在于在不增加计算开销的情况下，显著提高了采样效率和降低了方差，解决了传统RL方法的一个关键痛点。

<details>
  <summary>Details</summary>

**Motivation:** 标准策略梯度方法受限于马尔可夫假设，导致高方差和低效采样。

**Method:** 提出分数阶策略梯度（FPG）框架，通过使用Caputo分数阶导数重新构建梯度，以建立状态转换之间的幂律时间相关性。开发了一种高效的递归计算技术，用于分数阶时间差分误差，具有恒定的时间和内存要求。

**Result:** 理论分析表明，FPG比标准策略梯度实现了O(t^(-alpha))阶的渐近方差降低，同时保持收敛性。经验验证表明，与最先进的基线相比，采样效率提高了35-68%，方差降低了24-52%。

**Conclusion:** FPG提供了一种数学上扎实的方法，可以在不增加计算开销的情况下利用长程依赖性。

> **ai_Abstract:** 本文提出分数阶策略梯度（FPG），一个利用分数阶微积分在强化学习中实现长期时间建模的框架。FPG通过Caputo分数阶导数克服了传统策略梯度方法中马尔可夫假设导致的局限性，有效降低了高方差并提高了采样效率。该方法通过高效的递归计算技术实现了恒定的时间和内存开销，并在理论上证明了渐近方差的显著降低，经验上展示了显著的采样效率提升和方差减少。

> **摘要翻译:** 我们提出了分数阶策略梯度（FPG），这是一个强化学习框架，结合分数阶微积分，用于策略优化中的长期时间建模。标准策略梯度方法面临马尔可夫假设的限制，表现出高方差和低效采样。通过使用Caputo分数阶导数重新构建梯度，FPG在状态转换之间建立了幂律时间相关性。我们开发了一种高效的递归计算技术，用于分数阶时间差分误差，具有恒定的时间和内存要求。理论分析表明，FPG比标准策略梯度实现了O(t^(-alpha))阶的渐近方差降低，同时保持收敛性。经验验证表明，与最先进的基线相比，采样效率提高了35-68%，方差降低了24-52%。该框架提供了一种数学上扎实的方法，可以在不增加计算开销的情况下利用长程依赖性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Residual Reward Models for Preference-based Reinforcement Learning](https://arxiv.org/abs/2507.00611)
> *基于偏好强化学习的残差奖励模型*

*Chenyang Cao, Miguel Rogel-García, Mohamed Nabail, Xueqian Wang, Nicholas Rhinehart* | **Category: cs.LG, cs.AI, cs.RO**

**Keywords:** 残差奖励模型, 基于偏好强化学习, 先验知识, 奖励学习, 强化学习

**Comment:** 26 pages, 22 figures

> **TL;DR:** 本文提出了一种残差奖励模型（RRM），通过结合先验知识和学习奖励来加速基于偏好的强化学习（PbRL）的收敛速度，并在模拟和真实机器人任务中取得了显著性能提升。

**AI_Comments:** 这项工作通过引入残差奖励模型（RRM）提供了一种新颖且实用的方法来解决基于偏好强化学习（PbRL）中奖励模型训练效率低下的问题。其创新点在于将先验知识（如粗略的奖励函数）与通过偏好学习的奖励相结合，避免了传统预训练和微调方法可能遇到的优化难题。RRM的灵活性体现在其能够整合多种形式的先验奖励，并显著提升了学习效率，尤其在真实机器人任务中的成功应用证明了其重要性和潜在的广泛应用价值。这为在奖励稀疏或难以定义的复杂环境中应用强化学习提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 基于偏好的强化学习（PbRL）在奖励信号难以指定的环境中表现出色，但由于需要训练奖励模型，其收敛速度较慢。现有方法通过预训练和微调奖励模型来解决，但当模型为神经网络时，使用不同的损失函数可能导致优化困难。

**Method:** 本文提出了一种残差奖励模型（RRM）来有效利用先验知识。RRM假设真实奖励是先验奖励和学习奖励之和。先验奖励是训练前可用的知识（如用户猜测或IRL学到的奖励），学习奖励则通过偏好进行训练。文中介绍了基于状态和基于图像的RRM版本。

**Result:** 实验结果表明，RRM显著提升了常见PbRL方法的性能，并适用于多种类型的先验奖励（包括代理奖励、IRL奖励甚至负向代理奖励）。在Meta-World环境套件中的多项任务上以及在Frank Panda真实机器人上的实验都显示，RRM显著加速了策略学习，在更少的步骤中取得了成功。

**Conclusion:** 残差奖励模型（RRM）通过有效整合先验知识，解决了基于偏好强化学习（PbRL）收敛速度慢的问题，并在各种模拟和真实机器人任务中展现出卓越的性能提升和学习加速效果。

> **ai_Abstract:** 本文提出了一种名为残差奖励模型（RRM）的新方法，旨在加速基于偏好的强化学习（PbRL）的收敛速度。RRM将环境的真实奖励分解为先验奖励和通过偏好学习的奖励两部分，从而有效利用先验知识。该方法解决了现有PbRL在神经网络奖励模型预训练和微调中存在的优化挑战。实验结果表明，RRM在Meta-World模拟环境和真实Frank Panda机器人上均显著提升了PbRL的性能，并加速了策略学习，适用于多种先验知识类型。

> **摘要翻译:** 基于偏好强化学习（PbRL）提供了一种在奖励信号难以指定的环境中学习高性能策略的方法，避免了启发式和耗时的奖励设计。然而，PbRL由于需要训练奖励模型，其收敛速度可能会很慢。先前的工作提出了从演示中学习奖励模型并使用偏好进行微调的方法。然而，当模型是神经网络时，预训练和微调使用不同的损失函数可能会给可靠优化带来挑战。在本文中，我们提出了一种利用残差奖励模型（RRM）有效利用先验知识的方法。RRM假设环境的真实奖励可以分为两部分之和：先验奖励和学习奖励。先验奖励是训练前可用的项，例如用户“最佳猜测”的奖励函数，或从逆强化学习（IRL）中学习到的奖励函数，而学习奖励则通过偏好进行训练。我们介绍了RRM的基于状态和基于图像的版本，并在Meta-World环境套件中的多个任务上对它们进行了评估。实验结果表明，我们的方法显著提高了常见PbRL方法的性能。我们的方法针对各种不同类型的先验奖励实现了性能改进，包括代理奖励、从IRL获得的奖励，甚至代理奖励的负向版本。我们还使用Frank Panda进行了实验，以表明我们的方法在真实机器人上取得了卓越的性能。它显著加速了不同任务的策略学习，比基线在更少的步骤中取得了成功。视频可在https://sunlighted.github.io/RRM-web/上查看。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [357] [Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap](https://arxiv.org/abs/2507.00075)
> *通过求解器-验证器差距对LLM自我改进训练动态的理论建模*

*Yifan Sun, Yushan Liang, Zhen Zhang, Jiaye Teng* | **Category: cs.LG, cs.AI**

**Keywords:** LLM自我改进, 训练动态, 求解器-验证器差距, 理论建模, 外部数据

**Comment:** 24 pages

> **TL;DR:** 本文通过求解器-验证器差距的概念，对LLM自我改进的训练动态进行了理论建模，并提出了一种仅利用早期训练信息预测最终性能的方法，还探讨了外部数据对这些动态的影响。

**AI_Comments:** 这篇论文的创新点在于首次通过“求解器-验证器差距”这一新颖概念，对LLM自我改进的训练动态进行了理论建模，为理解和预测LLM的自我改进过程提供了理论基础。其能够仅凭早期训练信息预测最终性能的能力，对于LLM的训练优化具有重要指导意义。此外，对外部数据影响的分析也为LLM的混合训练策略提供了新的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LLM的自我改进技术意义重大，但LLM性能在自我改进过程中如何演变仍未得到充分探索。

**Method:** 本文通过求解器-验证器差距的概念，对自我改进的训练动态进行理论建模。基于此理论框架，进一步引入了如何仅利用前几个训练周期的信息来预测自我改进的最终能力。

**Result:** 理论模型在各种LLM和数据集上得到了经验验证。分析发现，在有限的外部数据条件下，外部数据可以在任何阶段使用而不会显著影响最终性能，这与经验观察一致。

**Conclusion:** 本文成功地通过求解器-验证器差距对LLM自我改进的训练动态进行了理论建模，并提出了早期预测最终性能的方法，同时揭示了有限外部数据在自我改进过程中的灵活应用性。

> **ai_Abstract:** 本文通过引入“求解器-验证器差距”概念，首次对大型语言模型（LLM）自我改进的训练动态进行了理论建模，旨在解决该过程性能演变研究不足的问题。该模型能够仅根据早期训练数据预测自我改进的最终效果，并在多个LLM和数据集上得到验证。此外，研究还扩展到分析外部数据对这些动态的影响，发现少量外部数据在任何阶段的加入都不会显著影响最终性能。

> **摘要翻译:** 自我改进是大型语言模型（LLM）领域中最突出的技术之一，旨在不依赖外部数据的情况下提高LLM性能。尽管其意义重大，但LLM性能在自我改进过程中如何演变仍未得到充分探索。在本文中，我们通过求解器-验证器差距的概念，对自我改进的训练动态进行理论建模。这受到了LLM性能提升源于其求解器能力和验证器能力之间差距的猜想的启发。基于此理论框架，我们进一步引入了如何仅利用前几个训练周期的信息来预测自我改进的最终能力。我们通过经验验证了该理论模型在各种LLM和数据集上的有效性。除了自我改进，我们还将分析扩展到研究外部数据如何在该框架内影响这些动态。值得注意的是，我们发现，在有限的外部数据条件下，此类外部数据可以在任何阶段使用而不会显著影响最终性能，这与经验观察一致。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [360] [Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding](https://arxiv.org/abs/2507.00669)
> *Audio-3DVG：统一音频-点云融合用于三维视觉定位*

*Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang* | **Category: cs.LG, cs.AI, cs.CV, cs.RO**

**Keywords:** Audio-3DVG, 三维视觉定位, 音频-点云融合, 口语, 对象提及检测

**Comment:** Work in progress, 42 pages

> **TL;DR:** Audio-3DVG将音频与点云融合用于三维视觉定位，在基于音频的定位任务中达到SOTA，并能与基于文本的方法竞争。

**AI_Comments:** 该论文解决了基于音频的三维视觉定位这一未充分探索且具有挑战性的领域，具有高度创新性。所提出的Audio-3DVG框架，通过将其分解为对象提及检测和音频引导注意力，提供了一种将语音集成到三维视觉中的结构化方法。为数据集合成音频描述也是对该领域未来研究和基准测试的宝贵贡献。实验结果显示其达到了最先进的性能并能与基于文本的方法竞争，突出了这项工作的巨大潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 基于语音的三维视觉定位仍未被充分探索且充满挑战；受到自动语音识别（ASR）和语音表示学习进展的启发。

**Method:** 提出了Audio-3DVG框架，将任务分解为两个互补部分：对象提及检测（Object Mention Detection）和音频引导注意力模块（Audio-Guided Attention module）。同时，为基准测试合成了标准3DVG数据集的音频描述。

**Result:** Audio-3DVG在基于音频的定位任务中取得了新的最先进性能，并能与基于文本的方法竞争。

**Conclusion:** 突出了将语音集成到三维视觉任务中的前景。

> **ai_Abstract:** 本文提出了Audio-3DVG，一个新颖的三维视觉定位框架，它统一了音频和点云数据。针对基于音频的三维视觉定位这一未充分探索的领域，该框架将任务分解为对象提及检测和音频引导注意力模块。同时，它为标准数据集合成了音频描述。实验结果表明，Audio-3DVG在基于音频的定位中取得了最先进的性能，并能与基于文本的方法竞争，展示了将语音集成到三维视觉中的潜力。

> **摘要翻译:** 三维视觉定位（3DVG）涉及根据自然语言在三维点云中定位目标对象。虽然先前的工作在使用文本描述方面取得了进展，但利用口语（即基于音频的三维视觉定位）仍未被充分探索且充满挑战。受自动语音识别（ASR）和语音表示学习进展的启发，我们提出了Audio-3DVG，一个简单而有效的框架，它集成了音频和空间信息以增强定位能力。我们没有将语音视为单一输入，而是将任务分解为两个互补的组件。首先，我们引入了对象提及检测（Object Mention Detection），这是一项多标签分类任务，明确识别音频中提及的对象，从而实现更结构化的音频-场景推理。其次，我们提出了一个音频引导注意力模块（Audio-Guided Attention module），该模块捕获候选对象和关系语音线索之间的相互作用，改善了杂乱场景中的目标识别。为了支持基准测试，我们为标准3DVG数据集（包括ScanRefer、Sr3D和Nr3D）合成了音频描述。实验结果表明，Audio-3DVG不仅在基于音频的定位中取得了新的最先进性能，而且能与基于文本的方法竞争——这突出了将口语集成到三维视觉任务中的前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [361] [The language of time: a language model perspective on time-series foundation models](https://arxiv.org/abs/2507.00078)
> *时间的语言：从语言模型视角看时间序列基础模型*

*Yi Xie, Yun Xiong, Zejian Shi, Hao Niu, Zhengfu Liu* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 时间序列基础模型, 语言模型, 表示学习, 量化, 跨领域迁移

**Comment:** 

> **TL;DR:** 本文解释了时间序列基础模型在跨领域表现出色的原因，认为它们通过将时间序列数据量化为“语言”，从而概括了语言模型的表示范式。

**AI_Comments:** 本文的创新之处在于提供了一个新颖的理论框架，通过数据量化将时间序列分析与大型语言模型联系起来，解释了时间序列基础模型出人意料的成功。这为理解和进一步开发这些强大的模型提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 解决时间序列基础模型在不同动态系统的时间序列数据之间表现出色的跨领域迁移能力与直观上这种迁移不合理的矛盾。

**Method:** 从理论和实验角度，研究了基于补丁的时间序列基础模型的表示学习机制和泛化能力。提出这些模型通过将连续时间序列补丁忠实地量化为离散词汇，其关键统计特性与自然语言高度一致，从而概括了语言模型的表示范式。

**Result:** 理论分析表明，连续时间序列补丁可以被忠实地量化为一个离散词汇，其关键统计特性与自然语言高度一致。这种泛化使得时间序列模型能够继承大型语言模型的鲁棒表示和迁移能力，从而解释了它们在时间任务中的卓越性能。

**Conclusion:** 本工作为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了严谨的理论基石。

> **ai_Abstract:** 本文旨在解决时间序列基础模型在不同时间序列数据之间实现强大跨领域迁移的悖论。研究提出，这些模型通过概括语言模型的表示范式来工作。通过理论和实验研究，作者证明了连续时间序列补丁可以被量化为具有与自然语言相似统计特性的离散词汇。这种“时间语言”使时间序列模型能够继承大型语言模型的鲁棒表示和迁移能力，从而解释了它们的经验成功，并为这些强大模型的进一步发展提供了理论基础。

> **摘要翻译:** 随着大型语言模型的兴起，在海量数据集上训练具有大量参数的基础模型的范式已被多个领域采纳并取得了显著成功。时间序列基础模型代表了这种范式的重大延伸，展示了卓越的表达能力、泛化能力和跨领域迁移能力。然而，这带来了一个根本性的悖论：时间序列数据反映了不同的动态系统，使得跨领域迁移直观上似乎不合理，但模型的经验成功却与之相矛盾。为了解决这个悖论，本文从理论和实验两个角度，研究了基于补丁的时间序列基础模型的表示学习机制和泛化能力。我们认为，这类模型不仅仅是应用一种新的架构，而是通过将确定性基于向量的表示扩展到潜在概率分布形式，从根本上概括了语言模型的表示范式。我们的理论分析通过证明连续时间序列补丁可以被忠实地量化为一个离散词汇，其关键统计特性与自然语言高度一致，从而支持了这一框架。这种泛化使得时间序列模型能够继承大型语言模型的鲁棒表示和迁移能力，从而解释了它们在时间任务中的卓越性能。最终，我们的工作为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了严谨的理论基石。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [366] [Online Meal Detection Based on CGM Data Dynamics](https://arxiv.org/abs/2507.00080)
> *基于CGM数据动态的在线进餐检测*

*Ali Tavasoli, Heman Shakeri* | **Category: cs.LG, nlin.AO, stat.AP**

**Keywords:** CGM数据, 进餐检测, 动态模式, 葡萄糖变异, 特征提取

**Comment:** 

> **TL;DR:** 利用CGM数据的动态模式来在线检测进餐事件，提高了准确性和可解释性。

**AI_Comments:** 该论文提出了一种新颖的基于CGM数据动态模式的进餐检测方法，其创新点在于利用数据本身的内在动力学特性进行特征提取，这不仅提高了检测准确性，还增强了结果的可解释性。这对于糖尿病管理和个性化营养干预具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法在进餐检测方面可能存在不足，需要一种更准确、可解释且鲁棒的框架，尤其是在真实世界应用中。

**Method:** 利用连续血糖监测（CGM）数据的动态模式作为特征，捕捉葡萄糖变异的关键方面，从而识别与进餐相关的模式和异常。该方法侧重于动态特征提取，提供了一个鲁棒的框架。

**Result:** 提高了进餐检测的准确性，增强了底层葡萄糖动力学的可解释性。该方法在不同数据集上具有泛化能力，并确保了真实世界应用中的可靠性能。

**Conclusion:** 提出的技术在进餐检测方面优于传统方法，显著提高了检测准确性。

> **ai_Abstract:** 本文提出了一种基于连续血糖监测（CGM）数据动态模式的在线进餐检测方法。该方法利用葡萄糖动力学的固有特性提取动态特征，以识别与进餐相关的模式，从而提高进餐检测的准确性并增强葡萄糖动力学的可解释性。该技术提供了一个鲁棒的特征提取框架，适用于不同数据集，并在实际应用中表现出可靠的性能，优于传统方法。

> **摘要翻译:** 我们利用从连续血糖监测（CGM）数据中提取的动态模式作为特征来检测进餐事件。通过利用底层动力学的固有特性，这些模式捕捉了葡萄糖变异的关键方面，从而能够识别与进餐相关的模式和异常。这种方法不仅提高了进餐检测的准确性，还增强了底层葡萄糖动力学的可解释性。通过关注动态特征，我们的方法为特征提取提供了一个鲁棒的框架，促进了在不同数据集上的泛化，并确保了在真实世界应用中的可靠性能。所提出的技术比传统方法具有显著优势，提高了检测准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [371] [Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission](https://arxiv.org/abs/2507.00082)
> *联邦学习赋能的混合语言模型：实现通信高效的令牌传输*

*Faranaksadat Solat, Joohyung Lee, Mohamed Seif, Dusit Niyato, H. Vincent Poor* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 联邦学习, 混合语言模型, 通信效率, 不确定性感知, 边缘AI

**Comment:** 17 pages, 16 figures, IEEE Internet of Things

> **TL;DR:** FedHLM通过联邦学习优化不确定性阈值并利用P2P令牌复用，显著减少HLM中的LLM传输，同时保持准确性。

**AI_Comments:** FedHLM的创新点在于将联邦学习引入到混合语言模型的不确定性管理中，通过分布式学习优化LLM调用阈值，并结合P2P令牌复用和分层聚合，有效降低了通信开销。这对于边缘AI和资源受限环境下的LLM部署具有重要意义，提供了一种通信高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统混合语言模型（HLMs）在本地小型语言模型（SLM）预测不确定时仍需频繁卸载到大型语言模型（LLM），这在带宽受限的环境中导致显著的通信开销。

**Method:** 本文提出了FedHLM框架，一个通信高效的混合语言模型（HLM），它将不确定性感知推理与联邦学习（FL）相结合。FedHLM通过FL以隐私保护的分布式方式协同学习和优化令牌级不确定性阈值，以决定何时需要LLM协助。此外，它利用基于嵌入的令牌表示进行点对点（P2P）解析，使客户端能够重用语义相似对等体推断的令牌，而无需调用LLM。框架还引入了分层模型聚合：边缘服务器通过客户端更新细化本地路由策略，同时跨集群协调对齐全局决策边界，以捕捉重复的不确定性模式，减少冗余的LLM查询。

**Result:** 在大型新闻分类任务上的实验表明，FedHLM将LLM传输减少了95%以上，且准确性损失可忽略不计。

**Conclusion:** FedHLM通过减少LLM查询，实现了通信高效的混合语言模型，使其非常适合可扩展和高效的边缘AI应用。

> **ai_Abstract:** 本文提出了FedHLM，一个联邦学习赋能的混合语言模型框架，旨在解决传统HLM中因不确定性预测频繁调用LLM导致的通信开销问题。FedHLM通过联邦学习优化令牌级不确定性阈值，并引入基于嵌入的P2P令牌复用机制，允许客户端共享已推断的令牌。其分层聚合设计进一步减少了冗余的LLM查询。实验证明，FedHLM在保持准确性的同时，显著降低了LLM传输量，使其非常适合可扩展和高效的边缘AI应用。

> **摘要翻译:** 混合语言模型（HLMs）结合了边缘设备上小型语言模型（SLMs）的低延迟效率与集中式服务器上大型语言模型（LLMs）的高准确性。与传统的端到端LLM推理不同，HLMs仅在本地SLM预测不确定时（即令牌级置信度低或熵高时）调用LLM，从而减少延迟和通信。然而，模糊或低置信度的预测仍然需要频繁地卸载到LLM，这在带宽受限的环境中导致显著的通信开销。为了解决这个问题，我们提出了FedHLM，一个通信高效的HLM框架，它将不确定性感知推理与联邦学习（FL）相结合。FedHLM的关键创新在于协同学习控制何时需要LLM协助的令牌级不确定性阈值。FedHLM不使用静态或手动调整的阈值，而是采用FL以隐私保护的分布式方式优化这些阈值。此外，它利用基于嵌入的令牌表示进行点对点（P2P）解析，使客户端能够重用语义相似对等体推断的令牌，而无需调用LLM。我们进一步引入了分层模型聚合：边缘服务器通过客户端更新细化本地路由策略，而跨集群协调则对齐全局决策边界。这种分层设计捕捉重复的不确定性模式，减少了冗余的LLM查询。大规模新闻分类任务的实验表明，FedHLM将LLM传输减少了95%以上，且准确性损失可忽略不计，使其非常适合可扩展和高效的边缘AI应用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [375] [Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks](https://arxiv.org/abs/2507.00083)
> *介入感知时空因果图网络在深度打击空袭系统战略反事实建模中的应用*

*Wei Meng* | **Category: cs.LG, cs.AI, 91A80, 91B62, 68T07, I.2.6; J.7; K.4.1; C.2.4**

**Keywords:** 战略反事实建模, 时空图神经网络, 深度打击系统, 因果推断, 战略延迟

**Comment:** This paper proposes the first closed-loop causal modeling framework
  (IA-STGNN) that links tactical strike variables to strategic delay outcomes
  via graph neural networks with counterfactual reasoning

> **TL;DR:** 该研究提出了IA-STGNN，一个新颖的框架，用于在战略层面模拟战术打击行为与战略延迟之间的因果关系，并显著优于现有基线模型。

**AI_Comments:** 该研究的创新之处在于提出了一个新颖的图神经网络框架IA-STGNN，首次将介入感知和反事实模拟引入到战略级军事模拟中，以解决战术行为与战略结果之间复杂的因果关系建模问题。其重要性在于为高层政策制定提供了结构化、透明且可解释的AI决策支持机制，特别是在核威慑和外交策略评估等关键领域。该模型通过整合多物理模拟数据，增强了模型的实用性和可信度。

<details>
  <summary>Details</summary>

**Motivation:** 当前战略级模拟中，战术打击行为与战略延迟之间缺乏结构化的因果建模，尤其是在捕获“弹性-节点压制-谈判窗口”链中的中间变量方面存在结构性瓶颈。

**Method:** 提出了一种新颖的介入感知时空图神经网络（IA-STGNN）框架，它整合了图注意力机制、反事实模拟单元和空间介入节点重建。训练数据通过多物理模拟平台（GEANT4 + COMSOL）根据NIST SP 800-160标准生成。

**Result:** 实验结果表明，IA-STGNN显著优于基线模型（ST-GNN, GCN-LSTM, XGBoost），MAE降低了12.8%，Top-5%准确率提高了18.4%，同时改善了因果路径一致性和介入稳定性。

**Conclusion:** IA-STGNN能够实现战略延迟的可解释预测，并支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供结构化和透明的AI决策支持机制。

> **ai_Abstract:** 该论文提出了一种名为介入感知时空图神经网络（IA-STGNN）的新型框架，旨在解决战略级模拟中战术打击行为与战略延迟之间因果建模的不足。IA-STGNN通过整合图注意力、反事实模拟和空间介入节点重建，实现了从战术输入到战略延迟输出的因果循环闭合。该模型在由多物理模拟平台生成的数据上进行训练，并在实验中表现出优于现有基线模型的性能，显著降低了预测误差并提高了准确性。IA-STGNN为战略延迟提供了可解释的预测能力，并可应用于核威慑模拟、外交窗口评估和多策略优化等高层政策建模领域。

> **摘要翻译:** 本研究旨在解决当前战略级模拟中战术打击行为与战略延迟之间缺乏结构化因果建模的问题，特别是捕获“弹性-节点压制-谈判窗口”链中中间变量的结构性瓶颈。我们提出了一种新颖的介入感知时空图神经网络（IA-STGNN）框架，该框架闭合了从战术输入到战略延迟输出的因果循环。该模型整合了图注意力机制、反事实模拟单元和空间介入节点重建，以实现打击配置和同步策略的动态模拟。训练数据是在NIST SP 800-160标准下，通过多物理模拟平台（GEANT4 + COMSOL）生成的，确保了结构可追溯性和政策级验证。实验结果表明，IA-STGNN显著优于基线模型（ST-GNN、GCN-LSTM、XGBoost），MAE降低了12.8%，Top-5%准确率提高了18.4%，同时改善了因果路径一致性和介入稳定性。IA-STGNN能够实现战略延迟的可解释预测，并支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供结构化和透明的AI决策支持机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [377] [A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism](https://arxiv.org/abs/2507.00085)
> *用于具有数据异常的鲁棒交通速度预测的联合拓扑-数据融合图网络*

*Ruiyuan Jiang, Dongyao Jia, Eng Gee Lim, Pengfei Fan, Yuli Zhang, Shangbo Wang* | **Category: cs.LG, cs.AI**

**Keywords:** 交通预测, 图网络, 数据融合, 时空特征, 数据异常

**Comment:** 

> **TL;DR:** GFEN是一个新的图网络，通过融合拓扑和数据来准确预测交通速度，并能处理数据异常，比现有方法更准确、收敛更快。

**AI_Comments:** 该论文的创新点在于提出了一个联合拓扑-数据融合的图网络（GFEN），有效整合了空间和时间特征，并通过混合方法自适应处理了数据异常和非平稳性。其显著的性能提升（预测精度提高6.3%，收敛速度快两倍）表明了其在智能交通系统中的巨大应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前交通预测方法难以处理交通动态的复杂性、非线性和时空特征整合问题。此外，现有方法使用静态技术处理非平稳和异常历史数据，限制了适应性并损害了数据平滑。

**Method:** 提出图融合增强网络（GFEN），该网络引入新颖的拓扑时空图融合技术，通过可训练方法从数据分布和网络拓扑中提取并融合时空关联，以建模多尺度时空特征。GFEN还采用混合方法，结合基于k阶差分的数学框架和基于注意力机制的深度学习结构，自适应平滑历史观测数据并动态缓解数据异常和非平稳性。

**Result:** GFEN在预测精度上超越现有最先进方法约6.3%。收敛速度比近期混合模型快近两倍。

**Conclusion:** GFEN在交通预测中表现出卓越的性能和潜力，能显著提高交通预测系统效率。

> **ai_Abstract:** 本文提出图融合增强网络（GFEN），一个用于网络级交通速度预测的创新框架，旨在克服现有方法在处理交通动态复杂性、时空特征整合以及数据异常和非平稳性方面的局限。GFEN通过引入拓扑时空图融合技术，能够从数据分布和网络拓扑中提取并融合多尺度时空特征。同时，它结合了基于k阶差分的数学框架和注意力深度学习结构，以自适应地平滑历史数据并动态处理异常。实验结果表明，GFEN在预测精度上优于现有最先进方法约6.3%，并且收敛速度快近两倍，展现出其在提升交通预测系统效率方面的巨大潜力。

> **摘要翻译:** 准确的交通预测对于智能交通系统（ITS）至关重要，然而当前方法难以应对交通动态固有的复杂性和非线性，使其难以整合空间和时间特征。此外，现有方法使用静态技术处理非平稳和异常历史数据，这限制了适应性并损害了数据平滑。为了克服这些挑战，我们提出了图融合增强网络（GFEN），一个用于网络级交通速度预测的创新框架。GFEN引入了一种新颖的拓扑时空图融合技术，该技术通过可训练方法从数据分布和网络拓扑中精细提取并融合空间和时间相关性，从而能够建模多尺度时空特征。此外，GFEN采用一种混合方法，结合基于k阶差分的数学框架和基于注意力机制的深度学习结构，以自适应地平滑历史观测数据并动态缓解数据异常和非平稳性。大量实验表明，GFEN在预测精度上比最先进的方法高出约6.3%，并且收敛速度比最近的混合模型快近两倍，证实了其卓越的性能以及显著提高交通预测系统效率的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [379] [pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation](https://arxiv.org/abs/2507.00087)
> *pUniFind：一个统一的大型预训练深度学习模型，突破了质谱解释的极限*

*Jiale Zhao, Pengzhi Mao, Kaifei Wang, Yiming Li, Yaping Peng, Ranfei Chen, Shuqi Lu, Xiaohong Ji, Jiaxiang Ding, Xin Zhang, Yucheng Liao, Weinan E, Weijie Zhang, Han Wen, Hao Chi* | **Category: cs.LG, cs.AI**

**Keywords:** 质谱解释, 深度学习, 蛋白质组学, 预训练模型, 从头测序

**Comment:** 

> **TL;DR:** pUniFind是一个统一的大型预训练深度学习模型，用于质谱解释，它通过整合端到端肽谱评分和从头测序，显著提高了肽段识别的灵敏度和修饰覆盖率。

**AI_Comments:** pUniFind的创新之处在于其作为首个大规模、多模态、预训练的统一评分框架，解决了传统模型仅作为特征提取器的问题。其在处理大规模数据、支持广泛修饰以及结合零样本从头测序方面的能力，显著提升了蛋白质组学分析的灵敏度和深度。该模型通过其质量控制模块，甚至能识别出参考蛋白质组中缺失但存在于基因组的肽段，这对于发现新型生物标志物和理解蛋白质组复杂性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习模型在质谱数据解释中多为特征提取器而非统一评分框架，限制了其潜力。

**Method:** 提出了pUniFind，一个大型多模态预训练模型，在超过1亿个开放搜索衍生的谱图上进行训练。它通过跨模态预测对齐谱图和肽段模态，并集成了端到端肽谱评分与开放、零样本从头测序。还包含一个基于深度学习的质量控制模块。

**Result:** 在免疫肽组学中，识别的肽段数量增加了42.6%；支持超过1,300种修饰；尽管搜索空间大了300倍，但比现有从头测序方法多识别了60%的PSM；质量控制模块额外恢复了38.5%的肽段，包括1,891个映射到基因组但不在参考蛋白质组中的肽段；保留了完整的碎片离子覆盖率。

**Conclusion:** 这些结果建立了一个统一、可扩展的蛋白质组学分析深度学习框架，提供了改进的灵敏度、修饰覆盖率和可解释性。

> **ai_Abstract:** pUniFind是一个创新的大型多模态预训练深度学习模型，专为质谱数据解释而设计。它解决了现有模型缺乏统一评分框架的问题，通过在超过1亿谱图上训练，整合了肽谱评分和开放式从头测序。该模型在蛋白质组学分析中表现出色，显著提高了肽段识别率（例如，免疫肽组学中增加42.6%），支持大量修饰，并能识别更多肽谱匹配，同时通过质量控制模块进一步提升了恢复率，从而提供了一个更灵敏、覆盖范围更广且更具可解释性的统一框架。

> **摘要翻译:** 深度学习已推动质谱数据解释的进步，但大多数模型仍是特征提取器而非统一的评分框架。我们提出了pUniFind，这是蛋白质组学领域首个大规模多模态预训练模型，它将端到端肽段-谱图评分与开放式、零样本从头测序相结合。pUniFind在超过1亿个开放搜索衍生的谱图上进行训练，通过跨模态预测对齐谱图和肽段模态，并在各种数据集中超越了传统引擎，特别是在免疫肽组学中，识别的肽段数量增加了42.6%。pUniFind支持超过1,300种修饰，尽管搜索空间大了300倍，但比现有从头测序方法多识别了60%的PSM。一个基于深度学习的质量控制模块进一步恢复了额外38.5%的肽段，其中包括1,891个映射到基因组但不在参考蛋白质组中的肽段，同时保留了完整的碎片离子覆盖率。这些结果建立了一个统一、可扩展的蛋白质组学分析深度学习框架，提供了改进的灵敏度、修饰覆盖率和可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [382] [A new machine learning framework for occupational accidents forecasting with safety inspections integration](https://arxiv.org/abs/2507.00089)
> *一种结合安全检查的职业事故预测新机器学习框架*

*Aho Yapi, Pierre Latouche, Arnaud Guillin, Yan Bailly* | **Category: cs.LG, stat.ME**

**Keywords:** 职业事故预测, 机器学习, 安全检查, 时间序列, LSTM

**Comment:** 

> **TL;DR:** 该研究提出了一个利用安全检查数据预测职业事故的机器学习框架，通过将事故建模为二元时间序列，实现了高风险时期的提前检测，并能为决策者提供每周风险评分。

**AI_Comments:** 该论文的创新点在于将安全检查数据与二元时间序列模型相结合，用于职业事故预测，并提供了可操作的每周风险评分。其对LSTM模型的突出表现的验证，为利用复杂时间序列数据进行风险预测提供了强有力的证据。该框架的实际应用价值在于能够帮助企业在事故发生前进行干预，从而提高安全管理效率和投资回报。

<details>
  <summary>Details</summary>

**Motivation:** 目前的职业事故预测方法可能未能充分利用安全检查数据，且缺乏将预测结果转化为可操作的决策支持工具。本研究旨在开发一个能够提供可靠、可操作的短期职业事故预测框架，以帮助决策者预防事故并优化安全投入。

**Method:** 本研究提出了一个通用的短期职业事故预测框架，该框架利用安全检查数据并将事故发生建模为二元时间序列。它生成每日预测并聚合成每周安全评估。为确保可靠性，采用了专门针对时间序列数据的滑动窗口交叉验证程序，并结合了基于聚合周期级别指标的评估。框架内训练并比较了多种机器学习算法，包括逻辑回归、基于树的模型和神经网络，其中长短期记忆（LSTM）网络表现最佳。

**Result:** 长短期记忆（LSTM）网络在该框架中表现优于其他算法，以0.86的平衡准确率检测出即将到来的高风险时期。这证实了该方法论的稳健性，并表明二元时间序列模型能够基于安全检查数据预测关键时期。该方法将常规安全检查数据转化为清晰的每周风险评分。

**Conclusion:** 该研究提出的机器学习框架，特别是基于LSTM的二元时间序列模型，能够有效利用安全检查数据预测职业事故高风险时期。其生成的每周风险评分可供决策者整合到规划工具中，以优化检查优先级、安排有针对性的干预措施，并在事故发生前将资源导向高风险地点或班次，从而提高安全投资回报。

> **ai_Abstract:** 本研究提出了一种新型的机器学习框架，用于短期职业事故预测，该框架创新性地整合了安全检查数据，并将事故发生建模为二元时间序列。通过每日预测并聚合为每周安全评估，该框架旨在提供可操作的风险洞察。经过严谨的时间序列交叉验证和多模型比较，发现长短期记忆（LSTM）网络表现最佳，能以0.86的平衡准确率有效识别高风险时期。该方法能将日常安全检查数据转化为清晰的每周风险评分，赋能决策者优化资源配置和预防性干预措施，从而提升安全投资回报。

> **摘要翻译:** 我们提出了一个通用的短期职业事故预测框架，该框架利用安全检查数据并将事故发生建模为二元时间序列。该方法生成每日预测，然后将其聚合成每周安全评估，以更好地为决策提供信息。为确保预测的可靠性和操作适用性，我们应用了专门为时间序列数据设计的滑动窗口交叉验证程序，并结合了基于聚合周期级别指标的评估。在该框架内，训练并系统地比较了多种机器学习算法，包括逻辑回归、基于树的模型和神经网络。与其他方法不同，长短期记忆（LSTM）网络表现优于其他方法，并以0.86的平衡准确率检测出即将到来的高风险时期，这证实了我们方法论的稳健性，并表明二元时间序列模型可以基于安全检查数据预测这些关键时期。所提出的方法将常规安全检查数据转换为清晰的每周风险评分，检测事故最可能发生的时期。决策者可以将这些评分整合到他们的规划工具中，以对检查优先级进行分类，安排有针对性的干预措施，并将资源导向被分类为最高风险的地点或班次，从而在事故发生前介入，并获得最大的安全投资回报。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [385] [Generating Heterogeneous Multi-dimensional Data : A Comparative Study](https://arxiv.org/abs/2507.00090)
> *生成异构多维数据：一项比较研究*

*Corbeau Michael, Claeys Emmanuelle, Serrurier Mathieu, Zaraté Pascale* | **Category: cs.LG, cs.AI**

**Keywords:** 数据生成, 消防干预, 生成模型, 合成数据, 比较研究

**Comment:** accepted at IEEE SMC 2025 Vienna

> **TL;DR:** 本研究比较了多种数据生成方法，以创建用于消防干预模拟的复杂异构合成数据，并提出结合领域特定指标进行评估。

**AI_Comments:** 该论文解决了为消防干预模拟生成复杂、异构且不平衡数据的实际挑战，这是一个具有重要操作意义的领域。通过比较多种先进的生成模型并引入领域特定评估指标，该研究展示了对合成数据质量的深入理解和创新评估方法。然而，摘要中没有提供具体的比较结果，这使得读者无法了解哪种方法在此特定应用中表现最佳。

<details>
  <summary>Details</summary>

**Motivation:** 消防人员和物资资源的分配在消防干预中至关重要，而这种分配依赖于模拟不同场景来优化消防响应。为了研究各种场景，数据生成是必不可少的。

**Method:** 本研究比较了多种数据生成方法，包括随机抽样、表格变分自编码器（TVAE）、标准生成对抗网络（GANs）、条件表格生成对抗网络（CTGANs）和扩散概率模型（DPMs）。为了弥补传统评估指标在捕捉真实世界合成数据集细微需求方面的不足，研究结合了针对消防领域的领域特定指标（如响应时间分布、干预的时空分布、事故表示）和标准度量（如Wasserstein距离）来评估合成数据质量。这些指标旨在评估数据变异性、复杂关联的保留、异常情况的表示、与初始统计分布的一致性以及操作相关性。数据具有高度不平衡、非高斯分布的特点。

**Result:** 摘要中未提及具体的比较研究结果，但研究评估了不同数据生成方法在捕捉消防干预复杂性方面的有效性，并使用了领域特定和标准指标来评估合成数据质量。

**Conclusion:** 摘要中未提及具体的结论，但研究重点在于比较和评估不同生成方法在处理消防领域复杂异构数据方面的能力。

> **ai_Abstract:** 本研究旨在比较多种数据生成方法，包括随机抽样、TVAE、GANs、CTGANs和DPMs，以生成用于消防干预模拟的异构多维数据，从而优化资源分配。鉴于传统评估指标的不足，研究提出结合领域特定指标（如响应时间、时空分布、事故表示）和标准度量（如Wasserstein距离）来评估合成数据的质量和操作相关性，特别关注数据的高度不平衡和非高斯分布特性。

> **摘要翻译:** 人员和物资资源的分配在消防干预中高度敏感。这种分配依赖于模拟来试验各种场景。这种分配的主要目标是消防响应的全局优化。因此，数据生成对于研究各种场景是强制性的。在本研究中，我们提出比较不同的数据生成方法。研究了随机抽样、表格变分自编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型等方法，以确定它们在捕捉消防干预复杂性方面的功效。传统的评估指标往往未能捕捉到真实世界场景中合成数据集的细微要求。为了解决这一差距，研究结合了针对消防领域的领域特定指标和诸如Wasserstein距离等标准度量，对合成数据质量进行了评估。领域特定指标包括响应时间分布、干预的时空分布和事故表示。这些指标旨在评估数据变异性、保留精细和复杂关联以及事件发生率极低等异常情况的能力、与初始统计分布的一致性以及合成数据的操作相关性。该分布的特殊性在于高度不平衡，所有变量均不遵循高斯分布，这增加了数据生成过程的复杂性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [387] [DFReg: A Physics-Inspired Framework for Global Weight Distribution Regularization in Neural Networks](https://arxiv.org/abs/2507.00101)
> *DFReg：一种受物理学启发的神经网络全局权重分布正则化框架*

*Giovanni Ruggieri* | **Category: cs.LG**

**Keywords:** 神经网络正则化, 全局权重分布, 密度泛函理论, 泛函惩罚, DFReg

**Comment:** 

> **TL;DR:** DFReg 是一种受物理学启发的神经网络正则化方法，通过施加泛函惩罚来促使权重平滑、多样且分布良好，无需改变网络结构或引入随机扰动。

**AI_Comments:** DFReg的创新之处在于将密度泛函理论引入到神经网络正则化中，提供了一种非侵入性的全局权重分布控制方法。它克服了传统正则化方法可能需要架构调整或引入随机性的局限性，为深度学习模型的稳定性和泛化能力提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的正则化技术（如 Dropout 或 L2 衰减）可能无法在不改变网络结构或引入随机扰动的情况下实现全局结构正则性。本文旨在引入一种新的正则化方法，通过施加泛函惩罚来鼓励平滑、多样和分布良好的权重配置，从而解决这一问题。

**Method:** 引入了DFReg，这是一种受密度泛函理论（DFT）启发的深度神经网络正则化方法。DFReg通过对权重的全局分布施加一个泛函惩罚来运行，以鼓励平滑、多样和分布良好的权重配置。

**Result:** 实现了平滑、多样且分布良好的权重配置，并在不改变架构或引入随机扰动的情况下，对神经网络施加了全局结构正则性。

**Conclusion:** DFReg提供了一种新颖的、受物理学启发的全局权重分布正则化方法，它能够有效地改善神经网络的权重配置，且避免了传统方法的局限性，即无需架构更改或随机扰动即可实现全局结构正则性。

> **ai_Abstract:** 本文介绍了DFReg，一种基于物理学启发（源于密度泛函理论）的神经网络正则化方法。它通过对全局权重分布施加泛函惩罚，旨在促进权重配置的平滑性、多样性和良好分布。与传统方法不同，DFReg能在不修改网络架构或引入随机扰动的情况下，实现全局结构正则化。

> **摘要翻译:** 我们引入了DFReg，这是一种受物理学启发的深度神经网络正则化方法，它作用于权重的全局分布。DFReg借鉴了密度泛函理论（DFT），施加一个泛函惩罚来鼓励平滑、多样和分布良好的权重配置。与Dropout或L2衰减等传统技术不同，DFReg在不改变架构或引入随机扰动的情况下施加全局结构正则性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [393] [Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros](https://arxiv.org/abs/2507.00184)
> *适用于超级马里奥兄弟的带不同文本编码器的文本到关卡扩散模型*

*Jacob Schrum, Olivia Kilday, Emilio Salas, Bess Hagan, Reid Williams* | **Category: cs.LG, cs.AI**

**Keywords:** 文本到关卡生成, 扩散模型, Transformer, 超级马里奥兄弟, 游戏关卡生成

**Comment:** 

> **TL;DR:** 本文探讨了使用扩散模型进行文本到游戏关卡生成，发现简单的Transformer模型在效率和性能上优于复杂的文本编码器。

**AI_Comments:** 本文的创新点在于探索了扩散模型在文本到关卡生成领域的应用，并提出了一种自动标注方法。其重要发现是，简单的Transformer模型在文本嵌入方面表现出色且训练成本低，这挑战了在所有生成任务中都依赖大型复杂模型的普遍观念，为资源受限或需要快速迭代的应用提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型在文本到关卡生成方面的应用尚未得到充分探索，并且在构建可用模型时存在实际挑战，例如需要充足的标题/关卡对、合适的文本嵌入模型以及生成完整可玩关卡而非单个场景的能力。

**Method:** 作者提出了自动为现有关卡数据集分配描述性标题的策略。他们使用预训练的文本编码器和从头开始训练的简单Transformer模型来训练扩散模型。生成的关卡也会自动分配标题，以便比较输入和输出标题之间的重叠度。同时，还评估了生成关卡的多样性和可玩性。研究结果与无条件扩散模型、生成对抗网络以及其他文本到关卡方法进行了比较。

**Result:** 最佳的扩散模型使用了简单的Transformer模型进行文本嵌入，其训练时间比采用更复杂文本编码器的扩散模型更短，这表明在文本到关卡生成中不一定需要依赖大型语言模型。研究还提供了一个GUI，允许设计师从模型生成的场景构建长关卡。

**Conclusion:** 在文本到关卡生成任务中，简单的Transformer模型可以作为高效且性能优越的文本编码器，其训练成本低于复杂模型，从而降低了对大型语言模型的依赖。

> **ai_Abstract:** 本文探讨了使用扩散模型进行文本到游戏关卡（以超级马里奥兄弟为例）的生成。针对文本到关卡生成探索不足的问题，作者提出了一种自动为关卡数据集分配描述性标题的策略，并训练了使用预训练文本编码器和从头开始训练的简单Transformer模型的扩散模型。研究发现，使用简单Transformer作为文本编码器的扩散模型表现最佳，且训练效率更高，表明在文本到关卡生成任务中无需依赖大型语言模型。此外，还提供了一个GUI辅助设计师构建长关卡。

> **摘要翻译:** 最近的研究表明扩散模型可以无条件地生成基于瓦片的游戏关卡，但扩散模型在文本到关卡生成中的应用尚未得到充分探索。创建可用模型存在实际考量：需要标题/关卡对、文本嵌入模型，以及生成整个可玩关卡而非单个场景的方法。我们提出了自动为现有关卡数据集分配描述性标题的策略，并使用预训练的文本编码器和从头开始训练的简单Transformer模型来训练扩散模型。生成的关卡也会自动分配标题，以便比较输入和输出标题之间的重叠程度。我们还评估了生成关卡的多样性和可玩性。结果与无条件扩散模型、生成对抗网络以及文本到关卡方法Five-Dollar Model和MarioGPT进行了比较。值得注意的是，最佳的扩散模型使用简单的Transformer模型进行文本嵌入，并且训练时间比采用更复杂文本编码器的扩散模型更短，这表明不一定需要依赖大型语言模型。我们还提供了一个GUI，允许设计师从模型生成的场景构建长关卡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [396] [Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions](https://arxiv.org/abs/2507.00191)
> *超越传感器数据：可穿戴设备行为数据的基础模型改善健康预测*

*Eray Erturk, Fahad Kamran, Salar Abbaspourazad, Sean Jewell, Harsh Sharma, Yujie Li, Sinead Williamson, Nicholas J Foti, Joseph Futoma* | **Category: cs.LG, cs.AI**

**Keywords:** 可穿戴设备, 基础模型, 行为数据, 健康预测, 机器学习

**Comment:** Accepted to ICML 2025

> **TL;DR:** 该研究开发了基于可穿戴设备行为数据的基础模型，并证明其在多种健康预测任务上的优越性能，尤其是在行为驱动的任务中，且与原始传感器数据结合时效果更佳。

**AI_Comments:** 这项研究的创新之处在于，它将基础模型的应用范围从传统的低级传感器数据扩展到更具信息量的行为数据，并证明了其在健康预测领域的巨大潜力。通过利用大规模真实世界可穿戴设备数据，并针对其特点优化模型设计，为未来的个性化健康监测和干预提供了坚实的基础。其重要性在于，它可能开辟基于行为模式而非纯生理信号的全新健康洞察和应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基础模型在健康预测中日益普及，但它们主要应用于低级传感器数据。然而，行为数据因其与生理相关的时间尺度和数量更一致，通常能提供更多信息。本研究旨在利用行为数据开发基础模型，以提升健康预测能力。

**Method:** 研究人员利用来自16.2万名个体超过25亿小时的可穿戴设备数据，开发了行为信号的基础模型。他们系统性地优化了模型架构和分词策略，以适应这一独特的数据集。

**Result:** 该模型在57项健康相关任务上表现出强大的性能，包括个体层面的分类和时变健康状态预测。模型在睡眠预测等行为驱动型任务中表现出色，并且与原始传感器数据表示结合时性能进一步提升。

**Conclusion:** 研究结果强调了根据可穿戴设备特点定制基础模型设计的重要性，并展示了其在支持新型健康应用方面的潜力。

> **ai_Abstract:** 本研究提出了一种利用可穿戴设备行为数据构建基础模型的方法，旨在克服现有基础模型主要依赖低级传感器数据的局限性。通过对大规模数据集进行模型架构和分词策略的优化，该模型在多项健康预测任务中展现出卓越性能，尤其在行为驱动型任务中表现突出，且与原始传感器数据结合时效果更佳。这表明行为数据对于健康预测具有重要价值，并为可穿戴设备健康应用的发展提供了新途径。

> **摘要翻译:** 可穿戴设备记录生理和行为信号，可以改善健康预测。尽管基础模型越来越多地用于此类预测，但它们主要应用于低级传感器数据，尽管行为数据由于与生理相关的时间尺度和数量更一致，通常信息量更大。我们利用来自16.2万名个体超过25亿小时的可穿戴设备数据，开发了此类行为信号的基础模型，系统性地优化了针对这一独特数据集的架构和分词策略。在57项健康相关任务上进行评估，我们的模型在包括个体层面分类和时变健康状态预测在内的各种现实世界应用中表现出强大的性能。该模型在睡眠预测等行为驱动型任务中表现出色，并且与原始传感器数据表示结合时性能进一步提升。这些结果强调了根据可穿戴设备定制基础模型设计的重要性，并展示了其实现新健康应用的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations](https://arxiv.org/abs/2507.00234)
> *时间序列可解释AI：多模型热图融合、全局注意力和NLP生成解释*

*Jiztom Kavalakkatt Francis, Matthew J Darr* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 可解释AI, 时间序列, 热图融合, 全局注意力, NLP解释

**Comment:** 13 pages

> **TL;DR:** 提出了一种新的可解释AI框架，结合ResNet和Transformer热图，解决时空不对齐问题，并通过NLP生成解释，在医疗和工业时间序列任务中表现优异。

**AI_Comments:** 这篇论文的创新点在于其多模型热图融合方法，有效解决了时间序列数据中可解释性方法的时空不对齐问题，并结合NLP生成人类可理解的解释。这种将视觉解释与文本解释相结合的策略，极大地提升了AI模型在安全关键领域（如医疗和工业）的透明度和可操作性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释性方法（卷积网络无法捕获全局上下文，Transformer缺乏局部精度）存在时空不对齐问题，阻碍了在医疗和工业监控等安全关键领域提供可操作的见解。

**Method:** 提出一个新颖框架，融合ResNet的梯度加权激活图和重构的2D Transformer的注意力展开图，形成统一的可视化热图，实现完全时空对齐并保持实时性能。此外，一个NLP模块将融合热图转换为领域特定叙述。

**Result:** 在临床（ECG心律失律检测）和工业（能耗预测）数据集上，混合框架在PhysioNet数据集上达到94.1%准确率（F1 0.93），在UCI能源设备数据集上将回归误差降低到RMSE = 0.28 kWh（R2 = 0.95），比单独的ResNet、Transformer和InceptionTime基线提高了3.8-12.4%。NLP模块通过BLEU-4 (0.586) 和 ROUGE-L (0.650) 分数验证了其生成解释的能力。

**Conclusion:** 通过将可解释性形式化为因果保真度和时空对齐，该方法弥合了技术输出与利益相关者理解之间的鸿沟，为透明、时间感知的决策提供了可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的可解释AI框架，旨在解决时间序列模型中现有可解释性方法的时空不对齐问题。该框架通过融合ResNet和重构2D Transformer生成的注意力热图，实现了统一且时空对齐的可视化，同时保持了实时性能。此外，引入了一个NLP模块将这些融合的热图转化为领域特定的自然语言解释。在心电图心律失常检测和能耗预测等实际应用中，该混合框架显著优于现有基线模型，并为安全关键领域提供了透明且时间感知的决策支持。

> **摘要翻译:** 在本文中，我们提出了一个新颖的框架，通过整合ResNet和重构的2D Transformer分别产生的热图，并结合全局加权输入显著性，来增强模型的可解释性。我们解决了现有可解释性方法中时空不对齐的关键问题，其中卷积网络未能捕获全局上下文，而Transformer缺乏局部精度——这一限制阻碍了在医疗保健和工业监控等安全关键领域获得可操作的见解。我们的方法将梯度加权激活图（ResNet）和Transformer注意力展开图融合到一个统一的可视化中，实现了完全的时空对齐，同时保持了实时性能。在临床（ECG心律失常检测）和工业（能耗预测）数据集上的实证评估表明了显著的改进：该混合框架在PhysioNet数据集上实现了94.1%的准确率（F1 0.93），并将UCI能源设备数据集上的回归误差降低到RMSE = 0.28 kWh（R2 = 0.95）——比单独的ResNet、Transformer和InceptionTime基线提高了3.8-12.4%。一个NLP模块将融合的热图转换为领域特定的叙述（例如，“2-4秒间ST段抬高提示心肌缺血”），并通过BLEU-4（0.586）和ROUGE-L（0.650）分数进行了验证。通过将可解释性形式化为因果保真度和时空对齐，我们的方法弥合了技术输出与利益相关者理解之间的鸿沟，为透明、时间感知的决策提供了可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [405] [Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning](https://arxiv.org/abs/2507.00257)
> *Gym4ReaL：一个用于基准测试真实世界强化学习的套件*

*Davide Salaorni, Vincenzo De Paola, Samuele Delpero, Giovanni Dispoto, Paolo Bonetti, Alessio Russo, Giuseppe Calcagno, Francesco Trovò, Matteo Papini, Alberto Maria Metelli, Marco Mussi, Marcello Restelli* | **Category: cs.LG, cs.AI**

**Keywords:** 强化学习, 真实世界RL, 基准测试, 环境, Gym4ReaL

**Comment:** 9 pages

> **TL;DR:** 本文介绍了Gym4ReaL，一个用于基准测试真实世界强化学习算法的新环境套件，旨在解决现有基准测试中忽视的实际挑战，并鼓励开发更强大的RL方法。

**AI_Comments:** Gym4ReaL的创新之处在于其明确地填补了现有强化学习基准测试在真实世界复杂性方面的空白。它提供了一个更具挑战性和代表性的平台，以推动RL算法在实际应用中的发展。其重要性在于，通过提供更真实的测试环境，它能够促进研究人员开发出更鲁棒、更适应真实世界条件的RL方法，从而加速RL在实际问题中的部署。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在模拟环境中取得了显著进展，但在部署到真实世界应用时面临大型状态动作空间、非平稳性和部分可观测性等挑战。现有基准测试往往忽视这些实际复杂性，侧重于理想化环境，因此需要一个能反映真实世界复杂性的新基准。

**Method:** 本文介绍了Gym4ReaL，一个全面的真实环境套件，旨在支持开发和评估能在真实世界场景中运行的强化学习算法。该套件包含多样化的任务，使算法面临各种实际挑战。

**Result:** 实验结果表明，在这些真实世界设置中，标准强化学习算法与基于规则的基准测试相比具有竞争力。

**Conclusion:** 研究结果激励了新方法的开发，以充分利用强化学习的潜力来应对真实世界任务的复杂性。

> **ai_Abstract:** 本文介绍了Gym4ReaL，一个专门为真实世界强化学习设计的综合基准测试套件。针对当前基准测试忽视真实世界复杂性（如大型状态空间、非平稳性、部分可观测性）的问题，Gym4ReaL提供了一系列模拟真实场景的任务。实验证明，现有RL算法在该套件中仍具竞争力，这强调了开发更先进方法以应对真实世界挑战的必要性。

> **摘要翻译:** 近年来，强化学习（RL）取得了显著进展，在各种模拟环境中实现了超人的表现。随着研究转向在真实世界应用中部署RL，该领域面临着一系列真实世界环境中固有的新挑战，例如大型状态-动作空间、非平稳性和部分可观测性。尽管这些挑战很重要，但在当前的基准测试中往往未得到充分探索，这些基准测试倾向于关注理想化的、完全可观测的、平稳的环境，常常忽略明确地纳入真实世界的复杂性。在本文中，我们介绍了Gym4ReaL，一个全面的真实环境套件，旨在支持开发和评估能够在真实世界场景中运行的RL算法。该套件包含一系列多样化的任务，使算法面临各种实际挑战。我们的实验结果表明，在这些设置中，标准RL算法证实了它们相对于基于规则的基准测试的竞争力，这激励了新方法的开发，以充分利用RL的潜力来应对真实世界任务的复杂性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [407] [Who Should I Listen To? Adaptive Collaboration in Personalized Federated Learning](https://arxiv.org/abs/2507.00259)
> *我该听谁的？个性化联邦学习中的自适应协作*

*Amr Abourayya, Jens Kleesiek, Bharat Rao, Michael Kamp* | **Category: cs.LG**

**Keywords:** 联邦学习, 个性化, 自适应协作, 数据异质性, FEDMOSAIC

**Comment:** 

> **TL;DR:** 本文提出FEDMOSAIC，一种在个性化联邦学习中实现自适应协作的方法，通过在共享无标签数据集上交换预测来决定信任谁以及信任多少，从而在非独立同分布设置下优于现有方法。

**AI_Comments:** 本文的创新点在于提出了“自适应协作”的概念，并将其应用于个性化联邦学习中，通过细粒度的信任决策（在示例层面信任谁）来解决数据异质性问题。FEDMOSAIC通过共享无标签数据上的预测而非模型参数，提供了一种新颖的协作方式，这对于在高度异质环境中实现更有效的模型个性化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据异质性是联邦学习中的核心挑战，而现有的个性化联邦学习（PFL）方法未能显著优于本地或中心化基线，这表明它们强制执行的协作与数据结构之间存在不匹配。

**Method:** 本文提出一种基于自适应协作的方法，客户端不仅自适应地决定在多大程度上依赖他人，还决定在单个示例层面信任谁。具体实例化为FEDMOSAIC，这是一种联邦协同训练方法，客户端通过共享的无标签数据集交换预测。每个客户端根据私有数据和公共数据之间的一致性调整其损失权重，并根据其估计的每个示例的置信度按比例贡献全局伪标签。

**Result:** FEDMOSAIC在各种非独立同分布（non-IID）设置下，均优于最先进的个性化联邦学习方法，并且在标准假设下提供了收敛保证。

**Conclusion:** 研究结果表明，数据感知型协作对于实现稳健有效的个性化联邦学习具有巨大潜力。

> **ai_Abstract:** 本文针对联邦学习中数据异质性带来的挑战，提出了一种名为FEDMOSAIC的个性化联邦学习方法。该方法引入了自适应协作机制，允许客户端不仅决定对其他客户端的依赖程度，还能在单个数据示例层面选择信任对象。FEDMOSAIC通过在共享无标签数据集上交换预测，实现细粒度的信任决策，并根据私有与公共数据的一致性调整损失权重，依据置信度贡献伪标签。实验证明，FEDMOSAIC在多种非独立同分布场景下优于现有先进方法，并提供了收敛性保证，突出了数据感知协作在个性化联邦学习中的有效性。

> **摘要翻译:** 数据异质性是联邦学习中的核心挑战，个性化联邦学习（PFL）旨在通过为每个客户端定制模型来解决这个问题。然而，许多PFL方法未能优于本地或中心化基线，这表明它们强制执行的协作与数据结构之间存在不匹配。我们提出了一种基于自适应协作的方法，客户端不仅自适应地决定在多大程度上依赖他人，还决定在单个示例层面信任谁。我们在FEDMOSAIC中实例化了这一原则，这是一种联邦协同训练方法，其中客户端通过共享的无标签数据集交换预测。这使得参数共享难以实现的细粒度信任决策成为可能。每个客户端根据私有数据和公共数据之间的一致性调整其损失权重，并根据其估计的每个示例的置信度按比例贡献全局伪标签。经验上，FEDMOSAIC在各种非独立同分布设置下均优于最先进的PFL方法，并且我们在标准假设下提供了收敛保证。我们的结果证明了数据感知协作在实现稳健有效个性化方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [409] [Examining Reject Relations in Stimulus Equivalence Simulations](https://arxiv.org/abs/2507.00265)
> *探究刺激等价模拟中的拒绝关系*

*Alexis Carrillo, Asieh Abolpour Mofrad, Anis Yazidi, Moises Betancort* | **Category: cs.LG, q-bio.NC, I.2.0; J.4; I.6.5**

**Keywords:** 刺激等价, 拒绝关系, 神经网络, 联想学习, 计算模型

**Comment:** 18 pages, 6 figures

> **TL;DR:** 本研究探讨了人工神经网络（FFN、BERT、GPT）在存在拒绝关系时，是能形成刺激等价类还是仅依赖联想学习。结果表明，包括Transformer模型在内的人工神经网络可能依赖联想策略而非真正的刺激等价，这强调了在等价的计算模型中需仔细考虑拒绝关系并采用更严格的标准。

**AI_Comments:** 该研究通过模拟方法，对人工神经网络（包括先进的Transformer模型）在刺激等价习得中的能力提出了质疑。其创新点在于引入了“拒绝关系”这一变量，并将其与联想学习进行对比，揭示了当前AI模型可能并未真正实现等价类形成，而仅仅是利用了联想策略。这对于理解AI认知能力边界以及未来构建更符合人类学习机制的计算模型具有重要意义。研究结果强调了在评估AI模型时，需要更严谨的实验设计和衡量标准。

<details>
  <summary>Details</summary>

**Motivation:** 尽管模拟是探索刺激等价（SE）的宝贵工具，但拒绝关系干扰等价类形成评估的潜力仍存在争议。本研究旨在确定人工神经网络能否展示等价类形成，或者其表现是否反映了联想学习。

**Method:** 本研究使用计算模型，在匹配样本（MTS）模拟中，考察了前馈神经网络（FFN）、来自Transformer的双向编码器表示（BERT）和生成式预训练Transformer（GPT）在18种条件下。这些条件包括训练结构（线性序列、一对多、多对一）、关系类型（仅选择、仅拒绝、选择-拒绝）和负向比较选择（标准和有偏）。一个概率代理作为基准，代表纯粹的联想学习。

**Result:** 结果表明，拒绝关系影响了代理的表现。尽管一些代理在等价测试中取得了高准确率，尤其是在存在拒绝关系和有偏负向比较的情况下，但其表现与概率代理相当。

**Conclusion:** 这些发现表明，包括Transformer模型在内的人工神经网络可能依赖联想策略而非刺激等价。这强调了在等价的计算模型中需要仔细考虑拒绝关系和更严格的标准。

> **ai_Abstract:** 本研究探讨了拒绝关系在刺激等价习得中的作用，特别是人工神经网络（FFN、BERT、GPT）能否形成等价类。通过在匹配样本模拟中测试不同训练结构、关系类型和负向比较选择下的模型表现，并与概率代理进行比较。结果显示，拒绝关系影响了模型性能，但即使在表现较好的情况下，人工神经网络也更倾向于采用联想策略，而非真正的刺激等价。这强调了在构建刺激等价的计算模型时，需要更严格的标准和对拒绝关系的审慎考虑。

> **摘要翻译:** 模拟为探索刺激等价（SE）提供了宝贵的工具，然而拒绝关系可能干扰等价类形成的评估，这一点仍有争议。本研究使用计算模型，调查了拒绝关系在刺激等价习得中的作用。我们考察了前馈神经网络（FFN）、来自Transformer的双向编码器表示（BERT）和生成式预训练Transformer（GPT）在匹配样本（MTS）模拟中的18种条件。这些条件在训练结构（线性序列、一对多和多对一）、关系类型（仅选择、仅拒绝和选择-拒绝）以及负向比较选择（标准和有偏）上有所不同。一个概率代理作为基准，代表纯粹的联想学习。主要目标是确定人工神经网络是否能够展示等价类形成，或者它们的表现是否反映了联想学习。结果表明，拒绝关系影响了代理的表现。尽管一些代理在等价测试中取得了高准确率，特别是在存在拒绝关系和有偏负向比较的情况下，但这种表现与概率代理相当。这些发现表明，包括Transformer模型在内的人工神经网络可能依赖联想策略而非刺激等价。这强调了在等价的计算模型中需要仔细考虑拒绝关系和更严格的标准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [411] [Double Q-learning for Value-based Deep Reinforcement Learning, Revisited](https://arxiv.org/abs/2507.00275)
> *再探基于价值的深度强化学习中的双Q学习*

*Prabhat Nagarajan, Martha White, Marlos C. Machado* | **Category: cs.LG, cs.AI**

**Keywords:** 深度强化学习, 双Q学习, 过高估计, Double DQN, DDQL

**Comment:** 44 pages

> **TL;DR:** 本文研究了一种名为深度双Q学习（DDQL）的算法，它更紧密地遵循了原始双Q学习的核心思想，以减少深度强化学习中的过高估计。研究发现DDQL比Double DQN的过高估计更少，并且在Atari 2600游戏上表现更好。

**AI_Comments:** 本文的创新之处在于它重新审视了双Q学习的原始核心思想，并将其更严格地应用于深度强化学习，从而提出了DDQL。这解决了现有Double DQN在处理过高估计方面可能存在的不足。研究结果表明，DDQL不仅减少了过高估计，还在实际任务中展现了优越的性能，且无需引入额外的复杂性（超参数），这对于实际应用具有重要意义。该研究深入探讨了DDQL的几个关键方面，有助于理解其工作原理和优化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）中普遍存在过高估计问题，包括Q学习。Double DQN虽然旨在解决这一问题，但其对Double Q-learning的适应性不够紧密，没有训练两个相互引导的Q函数。本文旨在研究更忠实于Double Q-learning核心思想的算法（DDQL），以理解其是否能减少过高估计并实现高性能。

**Method:** 本文研究了Deep Double Q-learning (DDQL)算法，该算法适应了Double Q-learning的核心思想，即训练两个Q函数并利用它们在引导目标中解耦动作选择和动作评估。研究了DDQL的网络架构、回放比率和minibatch采样策略。

**Result:** 研究结果表明，DDQL减少了过高估计，并且在57款Atari 2600游戏中总体表现优于Double DQN，同时不需要额外的超参数。在Atari 2600游戏上，DDQL总体上表现优于Double DQN。

**Conclusion:** 本文肯定地回答了DDQL是否比Double DQN表现出更少的过高估计以及是否存在高性能的DDQL实例这两个问题。研究证明DDQL减少了过高估计并优于Double DQN。

> **ai_Abstract:** 本文重新审视了基于价值的深度强化学习中的双Q学习，提出了一种名为深度双Q学习（DDQL）的新算法。与现有Double DQN松散地适应原始双Q学习不同，DDQL更紧密地遵循了训练两个相互引导的Q函数以解耦动作选择和评估的核心思想。研究发现DDQL能有效减少过高估计，并在Atari 2600游戏上整体表现优于Double DQN，且无需额外超参数。此外，论文还探讨了DDQL的网络架构、回放比率和minibatch采样策略等关键方面。

> **摘要翻译:** 过高估计在强化学习（RL）中普遍存在，包括Q学习，它构成了许多基于价值的深度RL算法的算法基础。双Q学习是一种旨在通过训练两个Q函数并利用两者在引导目标中解耦动作选择和动作评估来解决Q学习过高估计问题的算法。Q学习被改编为深度RL形式的深度Q网络（DQN）后不久，双Q学习也被改编为深度RL形式的双DQN。然而，双DQN只是松散地改编了双Q学习，放弃了训练两个相互引导的Q函数。在本文中，我们研究了将双Q学习的这一核心思想应用于基于价值的深度RL的算法。我们将此类算法称为深度双Q学习（DDQL）。我们的目标是了解DDQL是否比双DQN表现出更少的过高估计，以及是否存在高性能的DDQL实例。我们对这两个问题都给出了肯定的回答，证明DDQL减少了过高估计，并且在57款Atari 2600游戏中总体上优于双DQN，而无需额外的超参数。我们还研究了DDQL的几个方面，包括其网络架构、回放比率和minibatch采样策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [415] [Open-ended Scientific Discovery via Bayesian Surprise](https://arxiv.org/abs/2507.00310)
> *通过贝叶斯惊喜实现开放式科学发现*

*Dhruv Agarwal, Bodhisattwa Prasad Majumder, Reece Adamson, Megha Chakravorty, Satvika Reddy Gavireddy, Aditya Parashar, Harshit Surana, Bhavana Dalvi Mishra, Andrew McCallum, Ashish Sabharwal, Peter Clark* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 贝叶斯惊喜, 开放式科学发现, 自主科学发现, 大型语言模型, 蒙特卡洛树搜索

**Comment:** 

> **TL;DR:** 本文介绍了AutoDS，一种利用贝叶斯惊喜来驱动开放式自主科学发现的新方法，该方法通过量化LLM信念的认知转变来指导探索，并在实验中表现优于现有方法。

**AI_Comments:** 本文的创新之处在于提出了一个基于贝叶斯惊喜的原则性框架，用于驱动开放式自主科学发现，克服了以往方法对人类预设目标或主观启发式的依赖。将贝叶斯惊喜作为内在奖励函数融入MCTS，为AI系统自主探索并发现新颖、非预期的科学知识提供了一条有效途径。人类评估结果进一步验证了其在实际应用中的潜力，是该领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自主科学发现（ASD）方法要么是目标驱动的（依赖于人类指定的研究问题），要么在开放式探索中依赖于多样性启发式或主观的人类兴趣代理，但这些方法在庞大的假设空间中导航困难且定义不精确。本研究的动机是允许AI系统通过自身标准驱动探索，以进一步加速科学发现。

**Method:** 本文提出了AutoDS，一种利用贝叶斯惊喜驱动科学探索的开放式ASD方法。它通过量化大型语言模型（LLM）对假设的先验信念到收集实验结果后的后验信念之间的认知转变。为了高效探索嵌套假设空间，AutoDS采用了一种带有渐进式扩宽的蒙特卡洛树搜索（MCTS）策略，并以惊奇度作为奖励函数。

**Result:** 在21个涵盖生物学、经济学、金融和行为科学等领域的真实世界数据集上的数据驱动发现评估中，AutoDS在固定预算下比竞争对手多产生5-29%被LLM认为是惊奇的发现。此外，人类评估发现AutoDS三分之二的发现对领域专家而言也具有惊奇性。

**Conclusion:** AutoDS通过使用贝叶斯惊喜来驱动科学探索，是构建开放式自主科学发现系统的重要一步。

> **ai_Abstract:** AutoDS是一种利用贝叶斯惊喜驱动开放式自主科学发现（ASD）的新方法。它解决了现有ASD方法在目标驱动或基于启发式探索方面的局限性。AutoDS通过量化大型语言模型（LLM）信念的认知转变来识别“惊奇”的发现，并结合蒙特卡洛树搜索（MCTS）策略以惊奇度作为奖励函数来高效探索复杂的假设空间。实验结果表明，在真实世界数据集中，AutoDS在固定预算下能产生更多LLM和领域专家都认为惊奇的发现，这标志着开放式ASD系统研究的重要进展。

> **摘要翻译:** 自主科学发现（ASD）的潜力不仅在于回答问题，还在于知道该问哪些问题。最近大多数ASD工作探索了在目标驱动设置中使用大型语言模型（LLM），依赖于人类指定的研究问题来指导假设生成。然而，通过允许AI系统根据自身标准驱动探索，科学发现可能会进一步加速。少数现有的开放式ASD方法根据多样性启发式或人类兴趣的主观代理来选择假设，但前者难以有效地在通常庞大的假设空间中导航，后者则存在定义不精确的问题。本文提出了AutoDS——一种利用贝叶斯惊喜驱动科学探索的开放式ASD方法。在这里，我们量化了LLM对假设的先验信念到收集实验结果后的后验信念之间的认知转变。为了高效探索嵌套假设空间，我们的方法采用了一种带有渐进式扩宽的蒙特卡洛树搜索（MCTS）策略，并以惊奇度作为奖励函数。我们在跨越生物学、经济学、金融和行为科学等领域的21个真实世界数据集的数据驱动发现设置中评估了AutoDS。我们的结果表明，在固定预算下，AutoDS通过产生比LLM认为惊奇的发现多5-29%，显著优于竞争对手。我们的人工评估进一步发现，AutoDS三分之二的发现对领域专家而言也具有惊奇性，这表明这是朝着构建开放式ASD系统迈出的重要一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [418] [Exploring Theory-Laden Observations in the Brain Basis of Emotional Experience](https://arxiv.org/abs/2507.00320)
> *探索情感体验大脑基础中的理论负荷观察*

*Christiana Westlin, Ashutosh Singh, Deniz Erdogmus, Georgios Stratis, Lisa Feldman Barrett* | **Category: cs.LG, cs.CV, q-bio.NC**

**Keywords:** 情感科学, 理论负荷, 大脑模式, 个体差异, 数据重分析

**Comment:** 

> **TL;DR:** 本研究重新分析了情感大脑研究的数据，发现个体间存在显著差异，而非普遍认为的情绪类别特异性模式，强调了起始假设对科学结论的影响。

**AI_Comments:** 这项研究的创新之处在于它对情感科学中根深蒂固的假设提出了挑战，即情绪类别是生物学和心理学上的类型学。通过重新分析数据并采用不同的理论视角，它揭示了之前被忽视的个体差异，并有力地论证了理论负荷（theory-ladenness）在科学观察中的作用。其重要性在于提醒研究者，起始假设并非中立，它们会主动塑造我们所“看到”的数据和最终得出的结论。这对于神经科学和心理学领域的研究设计和解释具有深远的启示。

<details>
  <summary>Details</summary>

**Motivation:** 情感科学中普遍假设情绪类别形成生物学和心理学类型学，并据此设计和分析研究，这强化了指导调查的假设。本研究旨在挑战这种普遍假设，并探索起始假设如何影响科学观察和科学结论。

**Method:** 本研究重新分析了一项先前“类型学指导”的研究数据，该研究报告了单个大脑模式与34种情绪类别的群体平均评分之间的映射关系。研究者采用了一种替代观点，即将情绪类别视为可变、情境化实例的群体，并预测类别内脑模式存在显著变异。分析过程中对数据中存在的方差结构做了最小假设。

**Result:** 正如预测，研究者并未观察到原始的映射关系，反而观察到个体间存在显著变异。

**Conclusion:** 这些发现表明，起始假设最终会影响科学结论，并提示一个假设在被认真对待之前，必须得到多种分析方法的支持。

> **ai_Abstract:** 本研究挑战了情感科学中关于情绪类别为生物学类型学的普遍假设。通过重新分析一项先前研究的数据，该研究报告了大脑模式与情绪类别之间的映射，本研究发现，与原始报告不同，个体间的大脑模式在同一情绪类别内存在显著变异。这表明，研究的初始假设会深刻影响其结果和结论，并强调了使用多种分析方法验证假设的重要性。

> **摘要翻译:** 在情感科学中，人们普遍认为民间情感类别构成了生物学和心理学上的类型学，并且研究通常以此为基础进行设计和分析，以识别特定情感模式。这种方法塑造了研究报告的观察结果，最终强化了指导调查的假设。在此，我们重新分析了一项此类由类型学指导的研究数据，该研究报告了单个大脑模式与34种情感类别的群体平均评级之间的映射。我们的重新分析以一种替代的观点为指导，即将情感类别视为可变、情境化实例的群体，这种观点先验地预测了类别内实例之间的大脑模式会存在显著变异。相应地，我们的分析对数据中存在的方差结构做了最小假设。正如预测，我们没有观察到原始的映射关系，反而观察到个体间存在显著变异。这些发现表明，起始假设最终会影响科学结论，并提示一个假设在被认真对待之前，必须得到多种分析方法的支持。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [421] [MoNE: Replacing Redundant Experts with Lightweight Novices for Structured Pruning of MoE](https://arxiv.org/abs/2507.00390)
> *MoNE：用轻量级新手替代冗余专家以实现MoE的结构化剪枝*

*Geng Zhang, Yuxuan Han, Yuxuan Lou, Wangbo Zhao, Yiqi Zhang, Yang You* | **Category: cs.LG**

**Keywords:** 专家混合, 结构化剪枝, 模型压缩, 冗余专家, 轻量级新手

**Comment:** 

> **TL;DR:** MoNE通过用轻量级新手替换冗余专家来有效压缩MoE模型，减少内存开销并保持性能。

**AI_Comments:** MoNE的创新之处在于其独特的冗余专家识别机制（基于访问频率和输出方差）以及用轻量级新手替代而非简单移除，这有效缓解了剪枝带来的性能下降。该方法对于部署大型MoE模型，尤其是在资源受限的环境下，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的MoE模型部署存在显著的内存开销，且现有结构化剪枝方法在模型架构、校准数据源和样本大小方面表现不佳且退化不稳定。

**Method:** MoNE基于访问频率和输出方差两个指标评估专家冗余度。表现出低使用率和稳定输出的专家被剪枝，并用轻量级新手（对其原始输出的无偏估计）替代，以最小化性能下降。

**Result:** MoNE在三个维度上始终优于基线方法，且准确率下降最小。在25%剪枝率下，平均零样本准确率提高高达2.71；在50%剪枝率下，提高高达3.61。

**Conclusion:** MoNE是一种有效且鲁棒的专家剪枝方法，能够显著压缩MoE模型并保持高性能。

> **ai_Abstract:** 本文提出了MoNE，一种用于MoE模型的新型专家剪枝方法，旨在解决现有方法内存开销大、性能下降不稳定的问题。MoNE通过评估专家访问频率和输出方差来识别冗余专家，并用轻量级新手替换它们，从而实现有效且鲁棒的模型压缩，同时最小化性能损失。实验证明MoNE在不同维度上均优于现有基线方法，显著提高了剪枝后模型的准确性。

> **摘要翻译:** 专家混合（MoE）通过为每个输入令牌仅激活一部分专家，实现了大型语言模型的有效扩展。然而，部署基于MoE的模型会产生显著的内存开销，因为需要将所有专家保留在内存中。虽然结构化剪枝有望降低内存成本，但现有方法在模型架构、校准数据源和校准样本大小这三个维度上通常表现出次优性能和不稳定的性能下降。本文提出了一种新颖的专家剪枝方法——新手与专家混合（MoNE），它用轻量级新手替换冗余专家，以实现有效且鲁棒的模型压缩。MoNE基于两个指标评估专家冗余度：访问频率和输出方差。表现出低使用率和稳定输出的专家被剪枝，并用轻量级新手（对其原始输出的无偏估计）替代，从而最大限度地减少性能下降。大量的实验表明，MoNE在三个维度上始终优于基线方法，且准确率下降最小，证实了其有效性和鲁棒性。值得注意的是，在25%的剪枝率下，它将九个下游任务的平均零样本准确率提高了高达2.71；在50%的剪枝率下，提高了3.61。代码可在https://github.com/zxgx/mode-pd获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [424] [Diffusion Disambiguation Models for Partial Label Learning](https://arxiv.org/abs/2507.00411)
> *扩散去歧义模型用于部分标签学习*

*Jinfu Fan, Xiaohui Zhong, Kangrui Ren, Jiangnan Li, Linqing Huang* | **Category: cs.LG**

**Keywords:** 扩散模型, 部分标签学习, 标签去歧义, 生成模型, 去噪

**Comment:** 

> **TL;DR:** 本文提出了DDMP，一个基于扩散模型的去噪方法，用于解决部分标签学习中的歧义标签问题。通过逆向去噪过程、构建伪干净标签和引入转换感知矩阵，DDMP在实验中展现了其优势和适用于部分标签学习的能力。

**AI_Comments:** 该论文创新性地将通常用于数据生成的扩散模型应用于部分标签学习中的标签去歧义问题。将标签去歧义重新定义为生成过程，并利用伪干净标签结合转换感知矩阵来细化标签，是处理标签模糊性的一种新颖方法。

<details>
  <summary>Details</summary>

**Motivation:** 从模糊标签中学习是机器学习实际应用中一个长期存在的问题。部分标签学习（PLL）的目的是从给定实例的一组候选标签中识别出真实标签。受扩散模型在各种生成任务中卓越性能的启发，本文探索了其通过逆向去噪过程来消除模糊标签潜力的可能性。

**Method:** 本文将标签去歧义问题从生成模型的角度重新定义，其中标签通过迭代细化初始随机猜测来生成。为了解决实例和标签之间由于模糊标签导致的不匹配问题，本文提出了一个用于PLL的扩散去歧义模型（DDMP）。DDMP首先利用实例和标签之间潜在的互补信息来构建伪干净标签进行初始扩散训练。此外，引入了一个转换感知矩阵来估计潜在的真实标签，这些标签在扩散生成过程中动态更新。在训练过程中，真实标签被逐步细化，从而改进分类器。

**Result:** 实验结果表明DDMP具有优势，并且适用于部分标签学习。

**Conclusion:** 本文提出的扩散去歧义模型（DDMP）通过逐步细化真实标签并改进分类器，有效解决了部分标签学习中的标签歧义问题，并在实验中证明了其有效性和适用性。

> **ai_Abstract:** 部分标签学习（PLL）旨在从模糊的候选标签集中识别真实标签。本文提出了用于PLL的扩散去歧义模型（DDMP），该模型利用扩散模型的去噪能力。DDMP将标签去歧义重新定义为一个生成过程，通过构建伪干净标签进行初始训练，并引入一个动态更新的转换感知矩阵来估计真实标签。这种在训练过程中逐步细化标签的方法提高了分类器性能。实验结果证实了DDMP的有效性和其在PLL中的适用性。

> **摘要翻译:** 从模糊标签中学习是机器学习实际应用中一个长期存在的问题。部分标签学习（PLL）的目的是从给定实例的一组候选标签中识别出真实标签。受扩散模型在各种生成任务中卓越性能的启发，本文探索了其通过逆向去噪过程来消除模糊标签的潜力。因此，本文从生成模型的角度重新定义了标签去歧义问题，其中标签通过迭代细化初始随机猜测来生成。这种视角使扩散模型能够学习标签信息是如何随机生成的。通过建模生成不确定性，我们可以使用标签的最大似然估计进行分类推断。然而，这种模糊标签导致实例与标签之间的不匹配，从而降低了生成数据的质量。为了解决这个问题，本文提出了一个用于PLL的扩散去歧义模型（DDMP），它首先利用实例和标签之间潜在的互补信息来构建伪干净标签进行初始扩散训练。此外，引入了一个转换感知矩阵来估计潜在的真实标签，这些标签在扩散生成过程中动态更新。在训练过程中，真实标签被逐步细化，从而改进了分类器。实验结果表明DDMP具有优势，并且适用于部分标签学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [426] [Flexible Language Modeling in Continuous Space with Transformer-based Autoregressive Flows](https://arxiv.org/abs/2507.00425)
> *基于Transformer自回归流的连续空间灵活语言建模*

*Ruixiang Zhang, Shuangfei Zhai, Jiatao Gu, Yizhe Zhang, Huangjie Zheng, Tianrong Chen, Miguel Angel Bautista, Josh Susskind, Navdeep Jaitly* | **Category: cs.LG, cs.CL**

**Keywords:** 语言建模, 连续空间, 自回归流, Transformer, TarFlowLM

**Comment:** 

> **TL;DR:** 本文提出了一种名为TarFlowLM的新型框架，它将语言建模从离散令牌空间转移到连续潜在空间，并使用基于Transformer的自回归归一化流，以实现更灵活的语言建模，包括捕获双向上下文和支持块式生成。

**AI_Comments:** 本文提出了一种新颖的语言建模范式，将离散令牌空间转移到连续潜在空间，这是一个重要的创新点。通过引入Transformer-based自回归流和新的混合耦合变换，TarFlowLM在捕获复杂依赖和提供建模灵活性方面表现出色，特别是在处理双向上下文和块式生成方面，为未来语言模型设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自回归语言模型虽然取得了显著进展，但其对离散令牌、单向上下文和单次解码的依赖，限制了建模的灵活性。因此，研究人员探索新的设计空间以提供更多灵活性。

**Method:** 本文提出了一种名为TarFlowLM的新型框架，将语言建模从离散令牌空间转移到连续潜在空间。该框架采用基于Transformer的自回归归一化流来建模这些连续表示。它通过堆叠、交替方向的自回归变换来捕获全局双向上下文，支持具有灵活令牌块大小的块式生成，并促进分层多遍生成过程。此外，还提出了新的基于混合的耦合变换，旨在捕获由离散数据形成的潜在空间中的复杂依赖关系，并证明了与传统离散自回归模型的理论联系。

**Result:** 在语言建模基准上的大量实验表明，该框架具有强大的似然性能，并突出了其固有的灵活建模能力。

**Conclusion:** 本文提出的TarFlowLM框架通过将语言建模转移到连续潜在空间并利用Transformer-based自回归流，成功实现了高度灵活的语言建模，并在性能和能力上展示了显著优势。

> **ai_Abstract:** 本文介绍了一种名为TarFlowLM的新型语言建模框架，旨在克服传统离散自回归模型的局限性。该框架将语言建模从离散令牌空间转移到连续潜在空间，并利用基于Transformer的自回归归一化流进行建模。TarFlowLM通过支持双向上下文捕获、灵活的块式生成和分层多遍生成过程，显著增强了建模灵活性。此外，研究还提出了新的混合耦合变换以处理复杂依赖关系，并建立了与离散模型的理论联系。实验结果验证了其在语言建模基准上的强大性能和灵活能力。

> **摘要翻译:** 自回归模型推动了语言建模的显著进展。它们对离散令牌、单向上下文和单次解码的根本依赖，虽然是其成功的核心，但也激发了对可能提供新建模灵活性的设计空间的探索。在这项工作中，我们探索了一种替代范式，将语言建模从离散令牌空间转移到连续潜在空间。我们提出了一种新颖的框架TarFlowLM，它采用基于Transformer的自回归归一化流来建模这些连续表示。这种方法释放了实质性的灵活性，使得能够构建通过堆叠、交替方向的自回归变换捕获全局双向上下文的模型，支持具有灵活令牌块大小的块式生成，并促进分层多遍生成过程。我们进一步提出了新的基于混合的耦合变换，旨在捕获由离散数据形成的潜在空间中的复杂依赖关系，并证明了与传统离散自回归模型的理论联系。在语言建模基准上的大量实验表明，该框架具有强大的似然性能，并突出了我们框架固有的灵活建模能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [428] [A Recipe for Causal Graph Regression: Confounding Effects Revisited](https://arxiv.org/abs/2507.00440)
> *因果图回归的一个秘诀：重新审视混淆效应*

*Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen* | **Category: cs.LG, cs.AI, stat.ME**

**Keywords:** 因果图回归, 混淆效应, 图神经网络, 出分布, 对比学习

**Comment:** ICML 2025 accepted

> **TL;DR:** 本文提出了一种解决因果图回归（CGR）问题的方法，通过重新处理混淆效应并泛化分类特定的因果干预技术到回归任务，并在图OOD基准上验证了其有效性。

**AI_Comments:** 本文填补了因果图学习在回归任务方面的空白，将因果推理与图神经网络结合，并通过对比学习泛化了分类特有的因果干预方法，为解决图OOD回归问题提供了新的思路和有效的“秘诀”。

<details>
  <summary>Details</summary>

**Motivation:** 因果图学习（CGL）在图神经网络（GNN）的出分布（OOD）泛化方面表现出潜力，但其成功主要体现在分类任务中，而图学习中更具挑战性的回归任务却被忽视了。因此，本文致力于解决因果图回归（CGR）问题。

**Method:** 本文通过重新塑造现有CGL研究中混淆效应的处理方式来解决CGR问题，这些研究主要处理分类任务。具体来说，本文反思了混淆因子在图级回归中的预测能力，并通过对比学习的视角将分类特定的因果干预技术泛化到回归任务。

**Result:** 在图OOD基准上的大量实验验证了本文提出的CGR方法的有效性。

**Conclusion:** 本文提出的针对因果图回归（CGR）的方法，通过重新处理混淆效应和泛化因果干预技术，在图OOD场景下表现出良好的有效性。

> **ai_Abstract:** 本文针对图学习中被忽视的因果图回归（CGR）任务，提出了新的解决方案。作者通过重新审视和处理混淆效应，并将分类任务中有效的因果干预技术通过对比学习泛化到回归任务。实验结果表明，该方法在图OOD基准测试中表现出有效性。

> **摘要翻译:** 通过识别因果子图，因果图学习（CGL）已成为一种有前景的方法，用于提高图神经网络在出分布（OOD）场景下的泛化能力。然而，CGL技术的经验成功大多体现在分类设置中，而回归任务（图学习中更具挑战性的设置）却被忽视了。因此，我们将这项工作致力于解决因果图回归（CGR）问题；为此，我们重塑了现有CGL研究中混淆效应的处理方式，这些研究主要处理分类。具体来说，我们反思了混淆因子在图级回归中的预测能力，并通过对比学习的视角将分类特定的因果干预技术泛化到回归。在图OOD基准上的大量实验验证了我们提出的CGR方法的有效性。模型实现和代码已在https://github.com/causal-graph/CGR上提供。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [431] [Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design](https://arxiv.org/abs/2507.00445)
> *生物分子设计中奖励引导扩散模型微调的迭代蒸馏方法*

*Xingyu Su, Xiner Li, Masatoshi Uehara, Sunwoo Kim, Yulai Zhao, Gabriele Scalia, Ehsan Hajiramezanali, Tommaso Biancalani, Degui Zhi, Shuiwang Ji* | **Category: cs.LG, cs.AI, q-bio.QM**

**Keywords:** 扩散模型, 奖励引导, 迭代蒸馏, 生物分子设计, 策略蒸馏

**Comment:** 

> **TL;DR:** 提出一种迭代蒸馏框架，用于稳定高效地微调扩散模型，以在生物分子设计中优化任意奖励函数，克服了现有强化学习方法的缺点。

**AI_Comments:** 这篇论文通过将奖励引导的扩散模型微调问题转化为策略蒸馏，有效地解决了现有强化学习方法在生物分子设计领域中遇到的稳定性、样本效率和模式崩溃等挑战。其创新点在于采用了离策略数据收集和KL散度最小化来稳定训练过程，并使其能够优化任意不可微的奖励函数。这种方法对于需要根据特定性能指标（如物理模拟结果）进行优化的生物分子生成任务具有重要意义，克服了传统RL的局限性，为高效率、高质量的生物分子设计提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在建模复杂数据方面有效，但实际应用需要根据不可微奖励函数进行优化。现有基于RL的方法在微调扩散模型时存在不稳定性、样本效率低和模式崩溃问题。

**Method:** 提出一种迭代蒸馏的微调框架。将问题视为策略蒸馏：在roll-in阶段收集离策略数据，在roll-out阶段模拟基于奖励的软最优策略，通过最小化模拟软最优策略与当前模型策略之间的KL散度来更新模型。离策略公式结合KL散度最小化提高了训练稳定性和样本效率。

**Result:** 经验结果表明，该方法在蛋白质、小分子和调控DNA设计等多种任务中表现出有效性和卓越的奖励优化能力。

**Conclusion:** 提出的迭代蒸馏框架通过离策略公式和KL散度最小化，显著提高了扩散模型在生物分子设计中奖励引导微调的稳定性和样本效率，并实现了优越的优化性能。

> **ai_Abstract:** 本文提出一种迭代蒸馏框架，用于在生物分子设计中对扩散模型进行奖励引导微调。针对现有强化学习方法在处理不可微奖励函数时面临的不稳定性、样本效率低和模式崩溃等问题，该方法将微调过程转化为策略蒸馏。通过收集离策略数据并最小化模拟软最优策略与当前模型策略之间的KL散度来更新模型，显著提升了训练稳定性和样本效率。实验证明，该方法在蛋白质、小分子和调控DNA设计等任务中表现出卓越的奖励优化能力。

> **摘要翻译:** 我们解决了生物分子设计中奖励引导生成对扩散模型进行微调的问题。虽然扩散模型在建模复杂、高维数据分布方面已被证明非常有效，但实际应用通常需要的不仅仅是高保真生成，还需要针对潜在不可微的奖励函数进行优化，例如基于物理的模拟或基于科学知识的奖励。尽管已经探索了强化学习方法来针对此类目标微调扩散模型，但由于其在线策略性质，它们通常存在不稳定性、样本效率低和模式崩溃的问题。在这项工作中，我们提出了一种基于迭代蒸馏的微调框架，该框架使扩散模型能够优化任意奖励函数。我们的方法将问题视为策略蒸馏：它在“roll-in”阶段收集离策略数据，在“roll-out”阶段模拟基于奖励的软最优策略，并通过最小化模拟软最优策略与当前模型策略之间的KL散度来更新模型。我们的离策略公式与KL散度最小化相结合，与现有的基于强化学习的方法相比，提高了训练稳定性和样本效率。经验结果表明，我们的方法在蛋白质、小分子和调控DNA设计等多种任务中具有有效性和卓越的奖励优化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [433] [Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention](https://arxiv.org/abs/2507.00449)
> *通过上下文依赖的稀疏注意力克服状态空间模型的长上下文限制*

*Zhihao Zhan, Jianan Zhao, Zhaocheng Zhu, Jian Tang* | **Category: cs.LG, cs.CL, I.2.7**

**Keywords:** 状态空间模型, 长上下文建模, 稀疏注意力, 联合回忆, HAX

**Comment:** Proceedings of the 42nd International Conference on Machine Learning,
  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18
  pages, 9 figures

> **TL;DR:** 本文通过引入上下文依赖的稀疏注意力（CDSA）并实例化为HAX，解决了状态空间模型（SSMs）在长上下文建模中表达能力不足的问题，并在合成和真实世界基准测试中表现优异。

**AI_Comments:** 本文创新性地指出了现有SSM评估任务的局限性，并提出了更符合实际的长上下文建模任务。通过理论分析揭示了SSM的表达能力瓶颈，并提出了结合上下文依赖稀疏注意力的解决方案，具有重要的理论和实践意义。HAX作为具体实现，在长上下文建模方面展现出优越性。

<details>
  <summary>Details</summary>

**Motivation:** 高效的长上下文建模是自然语言处理（NLP）中的一个关键挑战，因为Transformer架构的时间复杂度与序列长度呈二次方关系。虽然状态空间模型（SSMs）提供了亚二次方解决方案，但它们在有效捕获长距离依赖方面存在困难。本文旨在分析和改进SSMs的长上下文建模能力。

**Method:** 首先，作者指出广泛使用的合成任务“联想回忆”不足以代表真实世界的长上下文建模。为了解决这个问题，他们将其扩展到一个新的合成任务“联合回忆”，该任务要求模型在给定特定上下文的情况下回忆与键关联的值。理论上，他们证明了SSMs不具备在亚二次方时间复杂度下解决多查询联合回忆的表达能力。为了解决这个问题，他们提出了一种将SSMs与上下文依赖的稀疏注意力（CDSA）相结合的解决方案，该方案具有在亚二次方计算下解决多查询联合回忆的表达能力。为了弥合理论分析与实际应用之间的差距，他们提出了具有稀疏键选择的局部敏感哈希注意力（HAX），该方法实例化了理论解决方案并进一步针对自然语言领域进行了调整。

**Result:** 在合成和真实世界的长上下文基准测试中进行的广泛实验表明，HAX始终优于SSM基线以及与上下文无关的稀疏注意力（CISA）集成的SSM。

**Conclusion:** 本文通过引入上下文依赖的稀疏注意力（CDSA）并实例化为HAX，成功克服了状态空间模型（SSMs）在长上下文建模中的表达能力限制，并在多项基准测试中验证了其有效性。

> **ai_Abstract:** 本研究旨在克服状态空间模型（SSMs）在长上下文建模中的局限性。作者首先指出现有合成任务“联想回忆”不足以评估SSMs的长上下文能力，并提出了新的“联合回忆”任务。理论分析表明SSMs在亚二次方时间复杂度下无法解决多查询联合回忆。为此，论文提出将SSMs与上下文依赖的稀疏注意力（CDSA）结合，以提升其表达能力。进一步，他们开发了局部敏感哈希注意力（HAX）作为CDSA的实例化，并针对自然语言领域进行了优化。实验结果表明，HAX在合成和真实世界长上下文基准测试中均优于现有SSM基线和集成上下文无关稀疏注意力的SSM。

> **摘要翻译:** 高效的长上下文建模仍然是自然语言处理（NLP）中的一个关键挑战，因为主导的Transformer架构的时间复杂度与序列长度呈二次方关系。虽然状态空间模型（SSMs）提供了替代的亚二次方解决方案，但它们在有效捕获长距离依赖方面存在困难。在这项工作中，我们专注于分析和改进SSMs的长上下文建模能力。我们表明，广泛使用的合成任务“联想回忆”，它要求模型在没有上下文的情况下回忆与单个键关联的值，不足以代表真实世界的长上下文建模的复杂性。为了解决这一限制，我们将联想回忆扩展到一个新颖的合成任务，“联合回忆”，它要求模型在给定特定上下文的情况下回忆与键关联的值。理论上，我们证明了SSMs不具备在亚二次方时间复杂度下解决多查询联合回忆的表达能力。为了解决这个问题，我们提出了一种基于将SSMs与上下文依赖的稀疏注意力（CDSA）相结合的解决方案，该方案具有在亚二次方计算下解决多查询联合回忆的表达能力。为了弥合理论分析与实际应用之间的差距，我们提出了具有稀疏键选择的局部敏感哈希注意力（HAX），该方法实例化了理论解决方案并进一步针对自然语言领域进行了调整。在合成和真实世界的长上下文基准测试中进行的广泛实验表明，HAX始终优于SSM基线以及与上下文无关的稀疏注意力（CISA）集成的SSM。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [Recurrent Memory-Augmented Transformers with Chunked Attention for Long-Context Language Modeling](https://arxiv.org/abs/2507.00453)
> *带分块注意力的循环记忆增强型Transformer，用于长上下文语言建模*

*Ankit Kashyap* | **Category: cs.LG, F.2.2; I.2.6; I.2.7**

**Keywords:** 循环记忆增强型Transformer, 分块注意力, 长上下文语言建模, 旋转位置编码, FIFO记忆

**Comment:** 19 pages, 9 figures, 1 table; implemented entirely from scratch in
  PyTorch

> **TL;DR:** 一种结合了全局注意力、分块局部注意力和门控FIFO记忆的Transformer架构，用于高效的长上下文语言建模。

**AI_Comments:** 该论文通过结合全局、局部和记忆增强的注意力机制，提出了一种创新方法来解决Transformer在长上下文处理中注意力机制的二次方复杂性问题。其受生物学启发的组件和旋转位置编码的应用是亮点。从零开始的实现方式突出了其透明度和进一步研究的潜力。该模型在对话、代码补全和文档理解等任务中的适用性表明了其广泛的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了在长上下文语言建模中高效处理短程和长程依赖，同时避免注意力成本的二次方增长。

**Method:** 本文提出了一种Transformer架构，它结合了全局注意力、分块局部注意力和门控FIFO记忆机制。该模型使用受循环网络启发的门控更新机制来持久存储过去的token表示，并为每个注意力头应用旋转位置编码，以实现方向解耦、尺度不变的位置信号。该架构完全从零开始在PyTorch中实现。

**Result:** 该模型能够高效处理短程和长程依赖，且不会使注意力成本呈二次方增长。它为对话建模、代码补全和文档理解等任务提供了轻量级和可扩展的设计。

**Conclusion:** 本文提出的Transformer架构通过结合全局注意力、分块局部注意力以及门控FIFO记忆机制，为长上下文语言建模提供了一种轻量级且可扩展的设计，适用于对话建模、代码补全和文档理解等任务。

> **ai_Abstract:** 本文介绍了一种针对长上下文语言建模的Transformer架构，其核心是将全局注意力与分块局部注意力以及门控FIFO记忆机制相结合。这种设计旨在高效处理短程和长程依赖，同时避免注意力成本的二次方增长。该模型还采用了旋转位置编码以提供鲁棒的位置信号，并且完全使用PyTorch从零实现，强调了其模块化和在各种语言任务中的可扩展性。

> **摘要翻译:** 我们提出了一种用于长上下文语言建模的Transformer架构，它将全局注意力与两个受生物学启发的组件结合起来：分块局部注意力和门控FIFO记忆机制。这种统一的注意力块使得模型能够高效地处理短程和长程依赖，而不会使注意力成本呈二次方增长。记忆模块使用受循环网络启发的门控更新机制持久存储过去的token表示。每个注意力头都应用旋转位置编码，以实现方向解耦、尺度不变的位置信号。该架构完全从零开始在PyTorch中实现，不依赖于高级库，从而实现了透明和模块化的实验。我们的模型为对话建模、代码补全和文档理解等任务提供了轻量级和可扩展的设计。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [439] [Diversity Conscious Refined Random Forest](https://arxiv.org/abs/2507.00467)
> *多样性感知精炼随机森林*

*Sijan Bhattarai, Saurav Bhandari, Girija Bhusal, Saroj Shakya, Tapendra Pandey* | **Category: cs.LG, cs.AI**

**Keywords:** 随机森林, 集成学习, 多样性, 特征选择, 模型冗余

**Comment:** 

> **TL;DR:** 提出了一种精炼随机森林分类器，通过动态选择信息量丰富的特征和强制树的多样性来减少模型冗余并提高分类准确性。

**AI_Comments:** 该论文的创新点在于其提出的精炼随机森林模型，通过动态选择信息量丰富的特征和强制树的多样性，有效地解决了传统随机森林存在的模型冗余和推理成本高的问题。这种方法在保持甚至提高准确性的同时，提升了模型的效率，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准随机森林（RF）通常依赖数百棵树和所有输入特征，导致高昂的推理成本和模型冗余。

**Method:** 提出了一种精炼随机森林分类器，它通过迭代地移除信息量最少的特征，分析性地确定应生长多少新树，然后通过基于相关性的聚类来移除冗余树。其目标是在信息量丰富的特征上动态生长树，并通过聚类和保留不相关树来强制实现最大多样性。

**Result:** 在8个多基准数据集（包括二分类和多分类数据集）上的实验表明，所提出的模型与标准随机森林相比，实现了更高的分类准确性。

**Conclusion:** 该研究表明，通过动态特征选择和强制多样性来精炼随机森林，可以有效提高分类准确性，同时有望解决传统随机森林的推理成本和模型冗余问题。

> **ai_Abstract:** 本研究针对标准随机森林存在的推理成本高和模型冗余问题，提出了一种多样性感知精炼随机森林（Refined Random Forest）。该方法通过迭代地移除信息量最少的特征、动态确定新树数量以及基于相关性的聚类来移除冗余树，从而在信息量丰富的特征上动态生长树并强制最大多样性。实验结果表明，与标准随机森林相比，所提出的模型在分类准确性上有所提高。

> **摘要翻译:** 随机森林（RF）是一种广泛使用的集成学习技术，以其在不同领域中稳健的分类性能而闻名。然而，它通常依赖数百棵树和所有输入特征，导致高昂的推理成本和模型冗余。在这项工作中，我们的目标是仅在信息量丰富的特征上动态生长树，然后通过聚类和保留不相关树来强制实现最大多样性。因此，我们提出了一种精炼随机森林分类器，它通过以下步骤迭代地进行自我精炼：首先移除信息量最少的特征，然后分析性地确定应生长多少新树，接着通过基于相关性的聚类来移除冗余树。我们将我们模型的分类准确性与相同数量树的标准RF进行了比较。在8个多基准数据集（包括二分类和多分类数据集）上的实验表明，所提出的模型与标准RF相比，实现了更高的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [441] [Posterior Inference in Latent Space for Scalable Constrained Black-box Optimization](https://arxiv.org/abs/2507.00480)
> *潜在空间中的后验推断用于可扩展的受约束黑盒优化*

*Kiyoung Om, Kyuil Sim, Taeyoung Yun, Hyeongyu Kang, Jinkyoo Park* | **Category: cs.LG, stat.ML**

**Keywords:** 受约束优化, 黑盒优化, 贝叶斯优化, 基于流的模型, 后验推断

**Comment:** 25 pages, 11 figures, 5 tables. Equal contribution by Kiyoung Om,
  Kyuil Sim, and Taeyoung Yun

> **TL;DR:** 本文提出了一种新的框架，用于可扩展的受约束黑盒优化，该框架利用基于流的模型和潜在空间中的后验推断来处理多模态分布并提高可扩展性。

**AI_Comments:** 该论文通过巧妙地将基于流的模型与潜在空间中的后验推断相结合，解决了受约束黑盒优化中的关键挑战，特别是可扩展性和多模态问题。在更平滑的潜在空间中摊销采样以缓解由多模态和平台状后验分布引起的问题的思路具有创新性。代码的公开可用性也增强了其影响力和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 在黑盒约束下优化高维黑盒函数是一项普遍存在的挑战性任务。现有的贝叶斯优化（BO）方法面临维度灾难问题。基于生成模型的方法虽然有前景，但存在可扩展性差和模式崩溃的风险，尤其是在目标分布高度多模态时。

**Method:** 该方法分两个阶段：首先，训练基于流的模型以捕获数据分布和代理模型以预测函数值和约束违反，并进行不确定性量化。其次，将候选选择问题视为后验推断问题，以寻找具有高目标值且不违反约束的有前景的候选。为解决多模态后验分布和约束导致的平台问题，在基于流的模型的潜在空间中摊销后验分布的采样，该空间比数据空间更平滑。

**Result:** 经验性地证明了该方法在各种合成和真实世界的受约束黑盒优化任务上取得了卓越的性能。

**Conclusion:** 该方法通过解决受约束黑盒优化中的可扩展性和多模态挑战，实现了卓越的性能。

> **ai_Abstract:** 本文提出了一种用于可扩展受约束黑盒优化的新颖框架，解决了现有方法（如贝叶斯优化和基于生成模型的方法）的局限性。所提出的方法利用基于流的模型进行数据分布和代理模型进行预测，并结合在更平滑的潜在空间中的后验推断，以有效识别最优候选，同时处理多模态分布并提高高维受约束问题的可扩展性。实验结果表明其在各种任务上表现优越。

> **摘要翻译:** 在各种科学和工程问题中，在黑盒约束下优化高维黑盒函数是一项普遍存在的任务。由于难以找到可行区域，这些问题通常比无约束问题更难。虽然贝叶斯优化（BO）方法已被开发用于解决此类问题，但它们常常受到维度灾难的困扰。最近，基于生成模型的方法已成为受约束优化的一个有前景的替代方案。然而，它们存在可扩展性差的问题，并且容易出现模式崩溃，特别是当目标分布高度多模态时。在本文中，我们提出了一个新框架来克服这些挑战。我们的方法分两个阶段迭代。首先，我们训练基于流的模型来捕获数据分布和代理模型，这些模型可以预测函数值和约束违反，并进行不确定性量化。其次，我们将候选选择问题视为后验推断问题，以有效搜索具有高目标值且不违反约束的有前景的候选。在后验推断期间，我们发现后验分布是高度多模态的，并且由于约束而具有大的平台，特别是当约束反馈以可行性的二进制指示器形式给出时。为了缓解这个问题，我们在基于流的模型的潜在空间中摊销了从后验分布中采样的过程，这比在数据空间中平滑得多。我们经验性地证明，我们的方法在各种合成和真实世界的受约束黑盒优化任务上取得了卓越的性能。我们的代码已公开可用 
\href{https://github.com/umkiyoung/CiBO}{此处}。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning](https://arxiv.org/abs/2507.00485)
> *PNAct：在安全强化学习中构建后门攻击*

*Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang* | **Category: cs.LG, cs.AI**

**Keywords:** 安全强化学习, 后门攻击, PNAct, 漏洞, 强化学习

**Comment:** 

> **TL;DR:** 本文发现安全强化学习易受后门攻击，并提出了PNAct框架，利用正负动作样本来植入后门，实验证明了其有效性。

**AI_Comments:** 这篇论文首次在安全强化学习领域提出了后门攻击框架PNAct，其创新点在于引入了正负动作样本来精细化地植入后门。这对于提高安全强化学习系统的鲁棒性具有重要意义，提醒研究人员关注并防御此类潜在的安全威胁。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习中代理需要遵守安全约束。然而，本文发现安全强化学习容易受到后门攻击，这可能导致代理执行不安全的操作。因此，本文旨在识别并展示这种漏洞。

**Method:** 引入了安全强化学习中后门攻击的相关概念和评估指标。提出了PNAct框架，这是第一个在安全强化学习领域涉及正负动作样本（PNAct）的攻击框架，其中正动作样本提供参考动作，负动作样本指示要避免的动作。理论上指出了PNAct的特性并设计了攻击算法。

**Result:** 通过实验评估了所提出的后门攻击框架的有效性，并使用既定指标进行了评估。

**Conclusion:** 本文强调了安全强化学习相关的潜在风险，并强调了此类攻击的可行性。

> **ai_Abstract:** 本文揭示了安全强化学习（Safe RL）易受后门攻击的漏洞。研究者提出了PNAct攻击框架，该框架利用正负动作样本来植入后门，即提供参考动作和指示避免的动作。文章从理论上分析了PNAct的特性并设计了相应的攻击算法。通过实验验证了PNAct框架的有效性，强调了Safe RL中潜在的安全风险以及此类攻击的可行性。

> **摘要翻译:** 强化学习（RL）广泛应用于代理与环境交互以最大化奖励的任务中。在此基础上，安全强化学习（Safe RL）在奖励指标之外引入了成本指标，确保代理在决策过程中遵守安全约束。在本文中，我们发现安全强化学习容易受到后门攻击，这可以操纵代理执行不安全的操作。首先，我们介绍了安全强化学习中后门攻击的相关概念和评估指标。这是安全强化学习领域中第一个涉及正负动作样本（PNAct）的攻击框架，用于植入后门，其中正动作样本提供参考动作，负动作样本指示要避免的动作。我们从理论上指出了PNAct的特性并设计了攻击算法。最后，我们进行了实验，评估了我们提出的后门攻击框架的有效性，并使用既定指标对其进行了评估。本文强调了与安全强化学习相关的潜在风险，并强调了此类攻击的可行性。我们的代码和补充材料可在https://github.com/azure-123/PNAct获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [445] [Foundation Models for Clinical Records at Health System Scale](https://arxiv.org/abs/2507.00574)
> *医疗系统规模下的临床记录基础模型*

*Haresh Rengaraj Rajamohan, Xiang Gao, Weicheng Zhu, Shih-Lun Huang, Long Chen, Kyunghyun Cho, Cem M. Deniz, Narges Razavian* | **Category: cs.LG**

**Keywords:** 基础模型, 电子健康记录, 生成式预训练, 零样本预测, 临床预测

**Comment:** Accepted to ICML 2025 Workshop on Foundation Models for Structured
  Data

> **TL;DR:** 本文提出了一种用于处理结构化电子健康记录（EHR）的生成式预训练策略，通过预测下一次就诊事件来学习复杂的临床依赖关系。该模型在零样本预测疾病发病率方面表现出色，性能可与完全微调的模型媲美，且无需昂贵的任务特定微调。研究还指出了EHR基础模型评估中重复事件可能导致性能虚高的问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个针对EHR数据的生成式预训练策略，特别是其“下一就诊事件预测”方法，这使得模型能够学习异构临床事件之间的复杂关系。另一个重要贡献是揭示了EHR基础模型评估中重复事件可能夸大性能的陷阱，并提出了相应的正则化方法，这对于未来EHR模型评估的严谨性具有指导意义。其零样本预测能力也展示了该模型在实际应用中的巨大潜力，减少了对昂贵任务特定微调的需求。

<details>
  <summary>Details</summary>

**Motivation:** 大规模预训练在语言和其他数据类型建模中取得了巨大成功，但在医疗保健领域，特别是在结构化电子健康记录（EHRs）的应用潜力尚未得到充分探索。

**Method:** 提出了一种新颖的生成式预训练策略，用于基于下一次就诊事件预测的序列EHR数据。模型学习根据患者历史自回归生成下一次就诊的各种标记化临床事件，并固有地处理异构数据类型的联合预测。此外，引入了对重复事件预测的正则化，并强调了EHR基础模型评估中重复事件标记可能夸大性能指标的关键陷阱。

**Result:** 模型在零样本预测痴呆症和膝骨关节炎在2年和5年内的发病率方面进行了评估，其性能与完全微调的掩码预训练Transformer基线相当。

**Conclusion:** 该方法无需昂贵的任务特定微调即可捕获复杂的临床依赖关系。

> **ai_Abstract:** 本文提出了一种针对结构化电子健康记录（EHR）序列数据的生成式预训练策略，旨在解决EHR数据在医疗领域大规模预训练中的潜力未充分挖掘的问题。该模型通过学习自回归生成下一次就诊的临床事件，能够处理异构数据类型的联合预测。研究还引入了针对重复事件预测的正则化，并揭示了EHR基础模型评估中重复事件可能夸大性能的问题。实验结果显示，该模型在零样本预测痴呆症和膝骨关节炎发病率方面表现出色，性能可与完全微调的Transformer模型媲美，验证了其在无需昂贵微调的情况下捕获复杂临床依赖关系的能力。

> **摘要翻译:** 大规模预训练已经改变了语言和其他数据类型的建模，但其在医疗保健领域与结构化电子健康记录（EHRs）结合的潜力仍未充分探索。我们提出了一种新颖的生成式预训练策略，用于基于下一次就诊事件预测的序列EHR数据。我们的模型学习根据患者历史自回归生成下一次就诊的各种标记化临床事件，并固有地处理异构数据类型的联合预测。此外，我们引入了对重复事件预测的正则化，并强调了EHR基础模型评估中的一个关键陷阱：当新发事件与后续发生事件不区分时，重复事件标记可能会夸大性能指标。我们的模型通过零样本预测痴呆症和膝骨关节炎在2年和5年内的发病率进行了评估，模型性能与完全微调的掩码预训练Transformer基线相当，这表明我们的方法无需昂贵的任务特定微调即可捕获复杂的临床依赖关系。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [447] [Quantum Circuit Structure Optimization for Quantum Reinforcement Learning](https://arxiv.org/abs/2507.00589)
> *量子强化学习中的量子电路结构优化*

*Seok Bin Son, Joongheon Kim* | **Category: cs.LG, cs.AI**

**Keywords:** 量子强化学习, 量子电路优化, 量子神经网络架构搜索, 参数化量子电路

**Comment:** 

> **TL;DR:** 本文提出QRL-NAS算法，通过集成量子神经网络架构搜索（QNAS）来优化量子强化学习（QRL）中参数化量子电路（PQC）的结构，实验证明其能获得比固定电路更高的奖励。

**AI_Comments:** 本文的创新点在于将神经网络架构搜索（NAS）的思想引入量子领域，专门用于优化量子强化学习中的核心组件——参数化量子电路（PQC）的结构。这解决了以往QRL研究中PQC结构凭经验设定的局限性，为量子算法设计提供了一种数据驱动的优化方法，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在高维空间中面临维度诅咒导致学习效率降低。量子强化学习（QRL）利用量子计算的叠加和纠缠特性来解决高维问题，但以往的QRL研究中，作为核心计算模块的参数化量子电路（PQC）结构是基于经验直觉固定的，并未验证其最优性。

**Method:** 本文提出了一种QRL-NAS算法，该算法将量子神经网络架构搜索（QNAS）集成到量子强化学习（QRL）中，以优化参数化量子电路（PQC）的结构。

**Result:** 实验表明，QRL-NAS算法比使用固定电路的QRL算法获得了更高的奖励。

**Conclusion:** QRL-NAS算法通过优化量子电路结构，有效提升了量子强化学习的性能和实用性。

> **ai_Abstract:** 本文针对量子强化学习（QRL）中参数化量子电路（PQC）结构固定且未经优化的局限性，提出了一种名为QRL-NAS的新算法。该算法通过集成量子神经网络架构搜索（QNAS）来自动优化QRL中的PQC结构。实验结果表明，与使用固定电路的QRL相比，QRL-NAS能够获得更高的奖励，证明了其在提升QRL性能方面的有效性和实用性。

> **摘要翻译:** 强化学习（RL）使智能体能够通过环境交互学习最优策略。然而，RL在高维空间中面临维度诅咒，导致学习效率降低。量子强化学习（QRL）通过利用量子计算中的叠加和纠缠特性来解决这个问题，从而能够以更少的资源高效处理高维问题。QRL将量子神经网络（QNN）与RL相结合，其中参数化量子电路（PQC）作为核心计算模块。PQC通过门操作执行线性和非线性变换，类似于经典神经网络中的隐藏层。然而，以往的QRL研究中，PQC结构是基于经验直觉固定的，并未验证其最优性。本文提出了一种QRL-NAS算法，该算法将量子神经网络架构搜索（QNAS）集成到QRL中以优化PQC结构。实验表明，QRL-NAS比使用固定电路的QRL获得了更高的奖励，验证了其有效性和实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [450] [Cooperative Sheaf Neural Networks](https://arxiv.org/abs/2507.00647)
> *协作层束神经网络*

*André Ribeiro, Ana Luiza Tenório, Juan Belieni, Amauri H. Souza, Diego Mesquita* | **Category: cs.LG**

**Keywords:** 层束神经网络, 协作消息传递, 有向图, 图表示学习, 过挤压

**Comment:** 

> **TL;DR:** 本文提出了协作层束神经网络（CSNNs），通过引入有向图上的细胞层束来解决现有层束扩散方法缺乏消息方向性，无法实现协作行为的问题。CSNN在理论上允许节点选择性地关注远距离节点并可能缓解过挤压问题，在实验上优于现有层束扩散和协作图神经网络。

**AI_Comments:** 本文的创新点在于将“协作消息传递”的概念引入到“层束神经网络”中，并通过引入有向图上的细胞层束来解决现有层束扩散方法缺乏消息方向性的限制。这种结合不仅增强了信息扩散的灵活性，还可能缓解图神经网络中常见的过挤压问题，为异质图数据处理和更有效的图表示学习提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的层束扩散方法因缺乏消息方向性，无法实现节点独立选择信息传播/收集的协作行为，因此需要一种新的方法来克服这一限制。

**Method:** 本文引入了有向图上的细胞层束概念，并描述了它们的入度和出度拉普拉斯算子。在此基础上，提出了协作层束神经网络（CSNNs）。

**Result:** CSNN在理论上表征了其感受野，并证明它允许节点选择性地关注（监听）任意远的节点，同时忽略路径中的其他节点，这可能缓解过挤压问题。实验结果表明，CSNN在性能上优于现有的层束扩散方法和协作图神经网络。

**Conclusion:** 本文证明了现有层束扩散方法无法实现协作行为，并提出了协作层束神经网络（CSNNs）来解决此问题。CSNN通过引入有向图上的细胞层束实现了协作行为，并在理论和实验上均表现出优越性，有望缓解图神经网络中的过挤压问题。

> **ai_Abstract:** 本文针对现有层束扩散方法无法实现协作行为且缺乏消息方向性的问题，提出了一种新的模型——协作层束神经网络（CSNNs）。该模型通过引入有向图上的细胞层束概念，并表征其入出度拉普拉斯算子，从而实现了节点间的协作式信息传递。理论分析表明，CSNN的感受野允许节点选择性地关注远距离节点，有望缓解过挤压问题。实验结果验证了CSNN在性能上优于现有层束扩散和协作图神经网络。

> **摘要翻译:** 层束扩散最近已成为图表示学习中一种有前景的设计模式，因为它具有处理异质数据和避免过平滑的固有能力。同时，协作消息传递也被提出作为一种增强信息扩散灵活性的方式，它允许节点独立选择是否向邻居传播/从邻居收集信息。一个自然的问题随之而来：层束扩散能否表现出这种协作行为？在这里，我们对这个问题给出了否定的答案。特别是，我们表明现有的层束扩散方法由于缺乏消息方向性而未能实现协作行为。为了规避这一限制，我们引入了有向图上的细胞层束概念，并表征了它们的入度和出度拉普拉斯算子。我们利用我们的构造提出了协作层束神经网络（CSNNs）。在理论上，我们表征了CSNN的感受野，并表明它允许节点选择性地关注（监听）任意远的节点，同时忽略路径中的所有其他节点，这可能缓解过挤压问题。我们的实验表明，与现有层束扩散以及协作图神经网络相比，CSNN表现出总体上更好的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [GANs Secretly Perform Approximate Bayesian Model Selection](https://arxiv.org/abs/2507.00651)
> *GANs秘密地执行近似贝叶斯模型选择*

*Maurizio Filippone, Marius P. Linhard* | **Category: cs.LG, cs.CV, stat.ML**

**Keywords:** 生成对抗网络, 贝叶斯模型选择, 边际似然, 正则化, 奥卡姆剃刀

**Comment:** 

> **TL;DR:** 本文将GANs解释为贝叶斯神经网络，并将其优化过程视为边际似然的近似，从而提出正则化策略以改善性能并加深理解。

**AI_Comments:** 本文创新性地将GANs与贝叶斯模型选择理论联系起来，提供了一个新的视角来理解GANs的成功和挑战。通过将GANs的优化解释为边际似然的近似，并引入奥卡姆剃刀原则，为GANs的正则化提供了理论基础和实用策略，有助于解决GANs训练不稳定和过拟合的问题，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成对抗网络（GANs）是流行且成功的生成模型，但其优化过程极具挑战性且需要正则化以防止过拟合。本文旨在通过将其解释为概率生成模型来解释GANs的成功和局限性。

**Method:** 作者将GANs解释为具有部分随机性的贝叶斯神经网络，从而能够建立通用逼近条件。他们将GANs的对抗式优化视为边际似然代理的优化。利用边际似然优化与奥卡姆剃刀之间的联系，定义了正则化和优化策略，以平滑损失景观并寻找具有最小描述长度的解，这些解与平坦的最小值和良好的泛化能力相关。

**Result:** 在广泛实验中的结果表明，这些策略能够提高性能，并为更深入地理解GANs的正则化策略铺平了道路。

**Conclusion:** 本文通过将GANs解释为贝叶斯神经网络，并将其优化过程与边际似然关联起来，揭示了GANs秘密地执行近似贝叶斯模型选择，并提出了有效的正则化和优化策略，从而改善了GANs的性能和理解。

> **ai_Abstract:** 本文提出将生成对抗网络（GANs）视为具有部分随机性的贝叶斯神经网络，并将其对抗式优化解释为边际似然的近似优化。通过利用边际似然与奥卡姆剃刀的联系，研究人员设计了新的正则化和优化策略，旨在平滑损失函数并找到泛化能力强的解。实验结果表明，这些策略有效提升了GANs的性能，并有助于深入理解其正则化机制。

> **摘要翻译:** 生成对抗网络（GANs）是流行且成功的生成模型。尽管它们取得了成功，但优化过程却出了名的具有挑战性，并且需要正则化以防止过拟合。在这项工作中，我们通过将GANs解释为概率生成模型来解释它们的成功和局限性。这种解释使我们能够将GANs视为具有部分随机性的贝叶斯神经网络，从而能够建立通用逼近条件。然后，我们可以将几种GAN变体的对抗式优化视为边际似然代理的优化。利用边际似然优化与奥卡姆剃刀之间的联系，我们可以定义正则化和优化策略，以平滑损失景观并寻找具有最小描述长度的解，这些解与平坦的最小值和良好的泛化能力相关。在广泛实验中的结果表明，这些策略能够提高性能，并为更深入地理解GANs的正则化策略铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [454] [Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models](https://arxiv.org/abs/2507.00653)
> *认知负荷感知推理：一个优化大型语言模型代币经济的神经符号框架*

*Yilun Zhang* | **Category: cs.LG, cs.AI**

**Keywords:** 认知负荷, LLM推理, 代币经济, 神经符号, 优化

**Comment:** 23 pages

> **TL;DR:** 本文提出认知负荷感知推理（CLAI）框架，通过应用认知负荷理论优化大型语言模型（LLM）的代币使用效率，显著降低计算成本并提升性能。

**AI_Comments:** 本文的创新之处在于将认知负荷理论和神经科学原理引入LLM推理优化，这是一种超越传统统计或架构改进的新颖视角。通过将认知负荷量化为LLM指标，并将其转化为认知经济优化问题，为LLM的资源管理提供了理论指导。特别是CLAI-Tune展现的自主分解难题的涌现能力，暗示了其在复杂任务处理上的潜力，为构建更类人、更高效的AI系统开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）推理的计算成本不断上升，已成为其广泛和可持续部署的关键障碍。现有优化策略多基于统计启发式或架构修改，缺乏指导推理过程的认知理论。

**Method:** 本文引入了认知负荷感知推理（CLAI）框架，将认知负荷理论（CLT）和神经科学原理应用于LLM推理。该框架将内在、外在和相关认知负荷量化为LLM指标，并将推理过程重构为认知经济优化问题：根据问题复杂性最小化浪费计算，并战略性分配代币预算用于生产性推理。提出了两种实现路径：CLAI-Prompt（通过结构化元提示引导基础LLM的零样本方法）和CLAI-Tune（通过微调内化这些原则的模型）。

**Result:** 在复杂推理、长文本问答和代码生成等基准测试中，我们的方法在不牺牲准确性的前提下，显著降低了代币消耗（高达45%）。此外，CLAI-Tune展现出自主分解难题的涌现能力。

**Conclusion:** 通过模仿大脑的资源管理策略，我们可以构建更高效、更强大、更有能力的人工智能系统。

> **ai_Abstract:** 本文提出了认知负荷感知推理（CLAI）框架，将认知负荷理论和神经科学原理应用于大型语言模型（LLM）的推理优化，以应对LLM高昂的计算成本。该框架将LLM推理过程量化为内在、外在和相关认知负荷，并将其视为一个认知经济优化问题。通过CLAI-Prompt（零样本提示）和CLAI-Tune（微调模型）两种实现方式，该方法在不牺牲准确性的前提下，显著降低了LLM的代币消耗（最高达45%），并在CLAI-Tune中观察到自主分解难题的涌现能力，证明了模仿大脑资源管理策略能构建更高效的AI系统。

> **摘要翻译:** 大型语言模型（LLM）推理计算成本的不断上升已成为其广泛和可持续部署的关键障碍。虽然现有的优化策略是有效的，但它们主要基于统计启发式或架构修改，缺乏指导推理过程本身的认知理论。本文旨在通过引入一种新颖的范式来弥补这一差距：认知负荷感知推理（CLAI）框架，该框架将认知负荷理论（CLT）和神经科学的原理应用于LLM推理。我们将内在认知负荷、外在认知负荷和相关认知负荷的概念形式化为可量化的LLM指标（$ICL_{LLM}$、$ECL_{LLM}$和$GCL_{LLM}$），从而将推理过程重新定义为认知经济优化问题：根据问题的内在复杂性（$ICL_{LLM}$），最小化浪费的计算（$ECL_{LLM}$），并战略性地将代币预算分配给生产性推理（$GCL_{LLM}$）。我们提出了两种实现路径：CLAI-Prompt，一种零样本方法，通过结构化元提示引导基础LLM完成认知控制步骤；CLAI-Tune，一种经过微调的模型，将这些原则内化以实现自发的认知经济。在复杂推理、长文本问答和代码生成等一系列基准测试中，我们的方法在不牺牲准确性的前提下显著降低了代币消耗（高达45%）。此外，CLAI-Tune表现出自主分解难题的涌现能力，这是人类专家认知的一个关键特征。这项工作表明，通过模仿大脑的资源管理策略，我们可以构建更高效、更强大、更有能力的AI系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [Diffusion Classifier Guidance for Non-robust Classifiers](https://arxiv.org/abs/2507.00687)
> *非鲁棒分类器的扩散分类器引导*

*Philipp Vaeth, Dibyanshu Kumar, Benjamin Paassen, Magda Gregorová* | **Category: cs.LG, cs.CV**

**Keywords:** 扩散模型, 分类器引导, 非鲁棒分类器, 稳定性, 生成模型

**Comment:** Accepted at ECML 2025

> **TL;DR:** 本文提出了一种新的方法，允许扩散模型中的分类器引导使用非鲁棒分类器，通过去噪图像预测和稳定技术解决了噪声引起的准确性下降问题，提高了引导的稳定性。

**AI_Comments:** 这项工作具有重要意义，因为它打破了扩散模型中分类器引导对鲁棒分类器的依赖，使得更多未经专门噪声训练的通用分类器能够用于引导生成过程。这极大地扩展了分类器引导的应用范围，为条件生成任务提供了更大的灵活性。其创新点在于通过去噪预测和稳定技术有效解决了非鲁棒分类器在噪声环境下的准确性下降和梯度不稳定问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分类器引导方法大多局限于鲁棒分类器，这些分类器是专门针对扩散前向过程中的噪声进行训练的。本文的动机是扩展分类器引导，使其能够与未经噪声训练的通用非鲁棒分类器协同工作。

**Method:** 作者分析了非鲁棒和鲁棒分类器对扩散过程噪声的敏感性。为解决非鲁棒分类器在噪声条件下的准确性显著下降问题，他们提出了一种利用一步去噪图像预测的方法，并实施了受随机优化方法启发的稳定技术，例如指数移动平均。

**Result:** 实验结果表明，该方法在保持样本多样性和视觉质量的同时，提高了分类器引导的稳定性。

**Conclusion:** 这项工作有助于推进生成模型中的条件采样技术，从而使更广泛的分类器能够用作引导分类器。

> **ai_Abstract:** 本文提出了一种针对扩散模型中非鲁棒分类器的分类器引导方法。针对现有方法仅限于鲁棒分类器的问题，作者分析了非鲁棒分类器在噪声条件下的性能退化，并提出通过使用一步去噪图像预测和结合指数移动平均等稳定技术来解决不稳定性问题。实验证明，该方法显著提高了分类器引导的稳定性，同时保持了生成样本的质量和多样性，从而拓宽了可用于引导扩散过程的分类器范围。

> **摘要翻译:** 分类器引导旨在引导扩散过程，使得给定分类器能够可靠地将生成的点识别为特定类别。然而，大多数分类器引导方法仅限于鲁棒分类器，这些分类器是专门针对扩散前向过程中的噪声进行训练的。我们扩展了分类器引导，使其能够与未经噪声训练的通用非鲁棒分类器协同工作。我们分析了非鲁棒和鲁棒分类器在标准CelebA数据集、专业SportBalls数据集和高维真实世界CelebA-HQ数据集上对扩散过程噪声的敏感性。我们的发现表明，非鲁棒分类器在噪声条件下表现出显著的准确性下降，导致引导梯度不稳定。为了缓解这些问题，我们提出了一种利用一步去噪图像预测并实施受随机优化方法（如指数移动平均）启发的稳定技术的方法。实验结果表明，我们的方法在保持样本多样性和视觉质量的同时，提高了分类器引导的稳定性。这项工作有助于推进生成模型中的条件采样技术，从而使更广泛的分类器能够用作引导分类器。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [460] [SCAWaveNet: A Spatial-Channel Attention-based Network for Global Significant Wave Height Retrieval](https://arxiv.org/abs/2507.00701)
> *SCAWaveNet: 一种基于空间-通道注意力的全球有效波高反演网络*

*Chong Zhang, Xichao Liu, Yibing Zhan, Dapeng Tao, Jun Ni* | **Category: cs.LG**

**Keywords:** 有效波高, 空间-通道注意力, 深度学习, CYGNSS, SCAWaveNet

**Comment:** 16 pages,6 tables,11 figures

> **TL;DR:** SCAWaveNet是一种新颖的基于空间-通道注意力的网络，用于全球有效波高（SWH）反演，通过利用CYGNSS数据的跨通道信息，其性能优于现有模型。

**AI_Comments:** 这篇论文通过明确解决深度学习模型在SWH反演中对跨通道信息利用不足的问题，提出了一种创新方法。所提出的空间-通道注意力机制是一个显著的改进，有望增强基于卫星的海洋数据分析的鲁棒性和准确性。其相对于现有最先进模型的性能提升突出了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习模型在利用CYGNSS数据进行有效波高（SWH）反演时，通常采用单通道输入或简单的通道拼接，未充分利用训练过程中跨通道信息交互的优势。

**Method:** 本文提出SCAWaveNet网络，将DDM中每个通道的特征建模为独立的注意力头，以融合空间和通道信息。针对辅助参数，设计了一种轻量级注意力机制，沿空间和通道维度分配权重。最终特征整合了空间和通道层面的特性。

**Result:** SCAWaveNet在使用ERA5作为参考时，平均RMSE为0.438米；使用NDBC浮标数据时，平均RMSE为0.432米。与现有最先进模型相比，SCAWaveNet在ERA5数据集上的平均RMSE至少降低了3.52%，在NDBC浮标观测数据上降低了5.47%。

**Conclusion:** SCAWaveNet有效解决了有效波高反演中缺乏跨通道信息交互的限制，与现有最先进模型相比，其性能有所提高。

> **ai_Abstract:** 本文介绍了一种名为SCAWaveNet的新型深度学习模型，用于全球有效波高（SWH）反演。为解决现有模型忽视跨通道信息的局限性，SCAWaveNet采用了空间-通道注意力机制，将每个DDM通道视为独立的注意力头，并为辅助参数设计了轻量级注意力。通过四通道CYGNSS数据评估，SCAWaveNet展现出卓越性能，实现了更低的RMSE（ERA5为0.438米，NDBC浮标为0.432米），并通过显著降低两个数据集上的RMSE，超越了现有最先进的模型。

> **摘要翻译:** 空间GNSS任务的最新进展已经产生了广泛的全球数据集，为基于深度学习的有效波高（SWH）反演提供了坚实的基础。虽然现有的深度学习模型主要利用四通道CYGNSS数据，但它们通常采用单通道输入或简单的通道拼接，而没有在训练过程中利用跨通道信息交互的优势。为了解决这一限制，本文提出了一种新颖的基于空间-通道注意力的网络SCAWaveNet，用于SWH反演。具体来说，DDM中每个通道的特征被建模为独立的注意力头，从而实现空间和通道信息的融合。对于辅助参数，设计了一种轻量级注意力机制，用于沿空间和通道维度分配权重。最终特征整合了空间和通道层面的特性。模型性能使用四通道CYGNSS数据进行评估。当使用ERA5作为参考时，SCAWaveNet的平均RMSE达到0.438米。当使用NDBC浮标数据时，平均RMSE达到0.432米。与现有最先进的模型相比，SCAWaveNet在ERA5数据集上的平均RMSE至少降低了3.52%，在NDBC浮标观测数据上降低了5.47%。代码可在https://github.com/Clifx9908/SCAWaveNet获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [461] [Large Reasoning Models are not thinking straight: on the unreliability of thinking trajectories](https://arxiv.org/abs/2507.00711)
> *大型推理模型并非直线思考：关于思维轨迹不可靠性的研究*

*Jhouben Cuesta-Ramirez, Samuel Beaussant, Mehdi Mounsif* | **Category: cs.LG**

**Keywords:** 大型语言模型, 推理, 思维链, 过度思考, 可靠性

**Comment:** Accepted to KONVENS 2025

> **TL;DR:** 通过强化学习训练的大型语言模型在推理任务上表现出“过度思考”现象，生成冗长但无效的思维链，甚至忽略正确的解决方案，这对其推理能力和可靠性提出了质疑。

**AI_Comments:** 这篇论文揭示了当前大型语言模型在推理能力方面的一个关键限制：它们无法有效整合外部纠正信息或进行自我修正。这种“过度思考”现象质疑了模型在基准测试中高分背后的真实推理能力，并强调了在需要高可靠性和可解释性的实际应用中，模型仍存在显著不足。

<details>
  <summary>Details</summary>

**Motivation:** 尽管通过强化学习训练的大型语言模型在推理基准测试中取得了令人印象深刻的成果，但越来越多的证据表明，这些模型经常生成冗长但无效的思维链（CoTs），这让人质疑基准测试的提升是否反映了真正的推理改进。

**Method:** 研究人员在AIME2024数学基准测试上对三种最先进的模型进行了实验，观察模型在明确提供了正确解决方案的情况下，仍然会忽略这些解决方案。

**Result:** 实验揭示了这些模型在整合纠正信息方面的严重局限性。模型即使在获得正确解决方案后，仍会继续生成不必要的推理步骤，这通常导致错误的结论。

**Conclusion:** 大型推理模型中思维轨迹的不可靠性（过度思考现象）对实现鲁棒和可解释的推理提出了新的挑战，因为它们难以整合纠正信息。

> **ai_Abstract:** 大型语言模型（LLMs）通过强化学习（RL）训练后在推理任务上表现出色，但本研究揭示了其“过度思考”的局限性。模型倾向于生成冗长且无效的思维链，甚至在明确提供正确解决方案时也选择忽略，转而进行不必要的推理，最终导致错误结论。在AIME2024数学基准测试上对三种最先进模型的实验证实了这些模型在整合纠正信息方面的关键缺陷，这对实现可靠和可解释的推理构成了新的挑战。

> **摘要翻译:** 通过强化学习（RL）训练的大型语言模型（LLMs）最近在推理基准测试中取得了令人印象深刻的成果。然而，越来越多的证据表明，这些模型经常生成冗长但无效的思维链（CoTs），这让人质疑基准测试的提升是否反映了真正的推理改进。我们提出了过度思考的新证据，即模型甚至在明确提供了正确解决方案的情况下，也会忽略它们，反而继续生成不必要的推理步骤，这通常导致错误的结论。在AIME2024数学基准测试上对三种最先进模型进行的实验，揭示了这些模型在整合纠正信息方面的严重局限性，这为实现鲁棒和可解释的推理带来了新的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [Aleatoric and Epistemic Uncertainty Measures for Ordinal Classification through Binary Reduction](https://arxiv.org/abs/2507.00733)
> *通过二元归约的序数分类中的偶然性和认知不确定性度量*

*Stefan Haas, Eyke Hüllermeier* | **Category: cs.LG**

**Keywords:** 序数分类, 不确定性量化, 偶然性不确定性, 认知不确定性, 二元归约

**Comment:** 

> **TL;DR:** 本文提出了一种通过二元归约来度量序数分类中偶然性和认知不确定性的新方法，并在错误检测和OOD检测方面表现优异。

**AI_Comments:** 该论文的创新点在于首次针对序数分类问题提出了专门的偶然性和认知不确定性分解度量，并通过二元归约的巧妙方式解决了这一挑战。其重要性体现在为高风险领域的序数决策提供了更可靠的不确定性评估工具。该方法在错误检测和OOD检测方面的优异表现，证明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 序数分类问题在医学和金融等高风险领域普遍存在，而准确的不确定性量化（包括偶然性和认知不确定性分解）对于可靠决策至关重要。然而，现有研究主要集中在标称分类和回归。

**Method:** 本文引入了一种基于将序数分类问题适当地归约到二元情况（基于熵和方差的度量）的新型偶然性和认知不确定性度量方法。这些度量有效捕捉了序数分类中精确命中率和最小误差距离之间的权衡。

**Result:** 该方法在各种表格序数基准数据集上，使用梯度提升树和多层感知机集成进行近似贝叶斯推断时，表现出有效性。它显著优于标准和逐标签的基于熵和方差的度量，在错误检测方面（通过错误分类率和平均绝对误差衡量）表现更佳。此外，这些序数度量在分布外(OOD)检测中也显示出有竞争力的性能。

**Conclusion:** 研究结果强调了在评估不确定性时考虑分类问题序数性质的重要性。

> **ai_Abstract:** 本文针对序数分类问题中不确定性量化不足的现状，提出了一种新的偶然性和认知不确定性度量方法。该方法通过将序数问题归约为二元情况来构建度量，能够有效平衡精确命中率和最小误差距离。实验结果表明，该方法在错误检测方面显著优于现有方法，并在分布外检测中表现良好，强调了序数分类中不确定性评估的特殊性。

> **摘要翻译:** 序数分类问题，即标签具有自然顺序的问题，在医学和金融等高风险领域普遍存在。准确的不确定性量化，包括分解为偶然性（内在变异性）和认知性（知识缺乏）成分，对于可靠决策至关重要。然而，现有研究主要集中在标称分类和回归。在本文中，我们引入了一类新的序数分类中偶然性和认知不确定性度量方法，该方法基于对二元情况（基于熵和方差的度量）的适当归约。这些度量有效地捕捉了序数分类中精确命中率和最小误差距离之间的权衡。我们使用梯度提升树和多层感知机集成进行近似贝叶斯推断，在各种表格序数基准数据集上展示了我们方法的有效性。我们的方法在错误检测方面显著优于标准和逐标签的基于熵和方差的度量，如错误分类率和平均绝对误差所示。此外，这些序数度量在分布外（OOD）检测中也显示出有竞争力的性能。我们的发现强调了在评估不确定性时考虑分类问题序数性质的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [465] [Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN](https://arxiv.org/abs/2507.00736)
> *离散级别问题难度估计中的序数性：引入平衡DRPS和OrderedLogitNN*

*Arthur Thuy, Ekaterina Loginova, Dries F. Benoit* | **Category: cs.LG, stat.ML**

**Keywords:** 问题难度估计, 序数回归, 平衡DRPS, OrderedLogitNN, 类别不平衡

**Comment:** Published in the EvalLAC'25 workshop at AIED 2025

> **TL;DR:** 当前问题难度估计（QDE）方法忽视了难度级别的序数性和类别不平衡问题。本文引入了平衡离散排名概率分数（balanced DRPS）用于评估，并提出了OrderedLogitNN模型，在复杂任务上表现出更好的性能。

**AI_Comments:** 这篇论文通过突出并解决了QDE中两个关键但常被忽视的方面——难度级别的内在序数性和评估中的类别不平衡问题，做出了重要贡献。平衡DRPS的引入提供了一个更具原则性和公平性的评估框架，而OrderedLogitNN则展示了将序数回归原理融入神经网络在QDE中的实际益处。这项工作为该领域未来的研究树立了新的标准。

<details>
  <summary>Details</summary>

**Motivation:** 现有问题难度估计（QDE）方法在处理离散难度级别时，常忽略其固有的序数性质，将其视为分类或离散化回归任务。此外，评估指标未能充分考虑序数结构和类别不平衡，导致性能评估存在偏差，并阻碍了跨研究的可比性。

**Method:** 本研究通过引入一种新颖的度量——平衡离散排名概率分数（balanced DRPS），来基准测试三种模型输出类型（离散化回归、分类和序数回归），该度量能同时捕获序数性和类别不平衡。除了使用现有序数回归方法外，论文还提出了OrderedLogitNN模型，将计量经济学中的有序logit模型扩展到神经网络。模型在RACE++和ARC数据集上对BERT进行微调。

**Result:** OrderedLogitNN在复杂任务上表现显著更好。平衡离散排名概率分数（balanced DRPS）为离散级别QDE提供了一个稳健且公平的评估指标。

**Conclusion:** 本文通过引入新的评估指标（平衡DRPS）和新的模型（OrderedLogitNN），成功解决了离散级别问题难度估计中长期被忽视的序数性和类别不平衡问题，为未来的相关研究奠定了原则性基础。

> **ai_Abstract:** 本文旨在解决离散级别问题难度估计（QDE）中被忽视的序数性质和类别不平衡问题。研究引入了一种新颖的评估指标——平衡离散排名概率分数（DRPS），该指标能同时考虑序数性和类别不平衡。此外，论文提出了OrderedLogitNN，一个将有序logit模型扩展到神经网络的新模型。通过在RACE++和ARC数据集上进行基准测试，结果表明OrderedLogitNN在复杂任务上表现优异，且平衡DRPS为离散级别QDE提供了一个稳健且公平的评估框架。

> **摘要翻译:** 近年来，使用自然语言处理技术进行问题难度估计（QDE）的兴趣日益增长。问题难度通常用离散级别表示，由于从最易到最难的内在顺序，将任务框定为序数回归。然而，现有文献忽略了该任务的序数性质，依赖于分类或离散化回归模型，而专门的序数回归方法仍未被探索。此外，评估指标与建模范式紧密耦合，阻碍了跨研究的可比性。虽然一些指标未能考虑难度级别的序数结构，但没有一个能充分解决类别不平衡问题，导致性能评估存在偏差。本研究通过使用平衡离散排名概率分数（DRPS）来解决这些限制，DRPS是一种新颖的度量，它共同捕获序数性和类别不平衡，用于基准测试三种模型输出——离散化回归、分类和序数回归。除了使用流行的序数回归方法外，我们还提出了OrderedLogitNN，将计量经济学中的有序logit模型扩展到神经网络。我们在RACE++和ARC数据集上微调BERT，发现OrderedLogitNN在复杂任务上表现显著更好。平衡DRPS为离散级别QDE提供了一个稳健且公平的评估指标，为未来的研究奠定了原则性基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [467] [Evaluating LLMs and Prompting Strategies for Automated Hardware Diagnosis from Textual User-Reports](https://arxiv.org/abs/2507.00742)
> *评估LLM和提示策略在文本用户报告中进行自动化硬件诊断的应用*

*Carlos Caminha, Maria de Lourdes M. Silva, Iago C. Chaves, Felipe T. Brito, Victor A. E. Farias, Javam C. Machado* | **Category: cs.LG**

**Keywords:** 大型语言模型, 硬件诊断, 提示策略, 文本报告, 故障识别

**Comment:** To be published in the Proceedings of the Brazilian Integrated
  Software and Hardware Seminar 2025 (SEMISH 2025)

> **TL;DR:** 本研究评估了多种大型语言模型和提示策略在从用户文本报告中自动化诊断硬件故障方面的表现，并识别出性能与模型大小平衡的最佳模型。

**AI_Comments:** 这项研究通过系统地评估多种LLM和提示策略在实际的硬件诊断场景中的表现，提供了一个有价值的基准。其创新之处在于不仅验证了LLM在处理模糊文本报告方面的潜力，还特别关注了模型大小与性能的平衡，为在资源受限的终端设备上部署LLM提供了实用指导。这对消费者电子产品的故障诊断自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算机制造商的用户报告（如“我的屏幕在闪烁”）常用于描述设备故障，但报告通常模糊且缺乏细节，导致从报告中识别故障组件具有挑战性，而这对于自动化测试和改善用户体验至关重要。大型语言模型（LLMs）在此类问题中展现出潜力。

**Method:** 本研究评估了27个开源模型（1B-72B参数）和2个专有LLM，使用了四种提示策略：零样本（Zero-Shot）、少样本（Few-Shot）、思维链（Chain-of-Thought, CoT）和CoT+少样本（CoT+FS）。研究进行了98,948次推理，处理了超过5100万个输入tokens并生成了1300万个输出tokens。

**Result:** 研究实现了高达0.76的f1-score。结果表明，有三个模型在大小和性能之间提供了最佳平衡：mistral-small-24b-instruct以及两个较小的模型llama-3.2-1b-instruct和gemma-2-2b-it，后者在VRAM使用量较低的情况下提供了具有竞争力的性能，从而可以在现代笔记本电脑或带NPU的智能手机等终端用户设备上进行高效推理。

**Conclusion:** LLMs可以有效地用于从文本用户报告中进行自动化硬件诊断，并且存在小型模型能够在资源受限的终端设备上提供良好性能的潜力。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）及其提示策略在从用户文本报告中自动化诊断硬件故障方面的有效性。研究测试了29个LLM（包括开源和专有模型）和四种提示策略，进行了近10万次推理。结果显示，尽管报告内容模糊，LLMs仍能有效识别故障组件，并取得了高达0.76的f1-score。研究还识别出多个在性能和模型大小之间取得良好平衡的模型，特别是小模型也能在终端设备上实现高效推理。

> **摘要翻译:** 计算机制造商提供平台供用户使用文本报告（例如“我的屏幕在闪烁”）描述设备故障。从报告中识别故障组件对于自动化测试和改善用户体验至关重要。然而，此类报告通常模棱两可且缺乏细节，使得这项任务充满挑战。大型语言模型（LLMs）在此类问题中已显示出前景。本研究评估了27个开源模型（1B-72B参数）和2个专有LLM，使用了四种提示策略：零样本（Zero-Shot）、少样本（Few-Shot）、思维链（Chain-of-Thought, CoT）和CoT+少样本（CoT+FS）。我们进行了98,948次推理，处理了超过5100万个输入tokens并生成了1300万个输出tokens。我们实现了高达0.76的f1-score。结果显示，有三个模型在大小和性能之间提供了最佳平衡：mistral-small-24b-instruct以及两个较小的模型llama-3.2-1b-instruct和gemma-2-2b-it，后者在VRAM使用量较低的情况下提供了具有竞争力的性能，从而可以在现代笔记本电脑或带NPU的智能手机等终端用户设备上进行高效推理。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [469] [A Probabilistic Approach to Wildfire Spread Prediction Using a Denoising Diffusion Surrogate Model](https://arxiv.org/abs/2507.00761)
> *使用去噪扩散替代模型的野火蔓延预测概率方法*

*Wenbo Yu, Anirbit Ghosh, Tobias Sebastian Finn, Rossella Arcucci, Marc Bocquet, Sibo Cheng* | **Category: cs.LG**

**Keywords:** 野火蔓延预测, 去噪扩散模型, 生成式AI, 不确定性量化, 预测集合

**Comment:** 

> **TL;DR:** 本文提出了首个用于野火蔓延预测的去噪扩散模型，该模型能生成一系列可能的预测结果，以应对野火固有的不确定性，优于传统的确定性模型。

**AI_Comments:** 本文的创新点在于首次将去噪扩散模型应用于野火蔓延预测，并成功解决了传统确定性模型无法捕捉野火固有不确定性的局限性。通过生成预测集合而非单一结果，该方法显著提升了预测的实用性和可靠性，对野火管理和决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 野火蔓延预测因其不可预测性和多变的环境条件而变得困难。传统的确定性模型无法有效捕捉野火动态固有的不确定性。本研究旨在利用生成式AI的能力来解决这一挑战，提供更可靠的预测工具。

**Method:** 本研究提出了首个用于野火蔓延预测的去噪扩散模型。这是一种新型的AI框架，它学习模拟火灾，不仅限于一个固定的结果，而是生成一系列可能的场景。通过这种方式，它能够解释野火动态固有的不确定性，并生成反映火灾可能去向的物理意义分布的预测集合。

**Result:** 该模型能够生成一系列预测结果（预测集合），这些结果反映了火灾可能蔓延方向的物理意义分布。这与传统的确定性方法不同，后者只生成单一预测，而本模型能更好地体现野火固有的不确定性。

**Conclusion:** 这项技术有望帮助开发更智能、更快、更可靠的野火行为预测工具，从而辅助决策者进行火灾风险评估和响应规划。

> **ai_Abstract:** 本研究提出并应用了首个去噪扩散模型来预测野火蔓延。针对传统模型难以捕捉野火固有不确定性的问题，该新型AI框架能够模拟火灾的多种可能场景，而非单一确定性结果。通过生成反映物理意义分布的预测集合，该模型能更准确地表征野火动态的不确定性，有望为野灾风险评估和响应规划提供更智能、可靠的工具。

> **摘要翻译:** 得益于生成式AI的最新进展，计算机现在能够模拟真实且复杂的自然过程。我们将这项能力应用于预测野火如何蔓延，这项任务因火灾的不可预测性和其所依赖的各种环境条件而变得困难。在这项研究中，我们首次提出了用于预测野火蔓延的去噪扩散模型，这是一种新型的AI框架，它学会了模拟火灾，不仅作为一个固定的结果，而是一系列可能的场景。通过这样做，它解释了野火动态固有的不确定性，这是传统模型通常无法表示的特征。与生成单一预测的确定性方法不同，我们的模型生成了反映火灾下一步可能去向的具有物理意义分布的预测集合。这项技术可以帮助我们开发更智能、更快、更可靠的工具来预测野火行为，从而辅助决策者进行火灾风险评估和响应规划。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments](https://arxiv.org/abs/2507.00762)
> *在真实世界强化学习环境中利用遗传算法高效生成演示*

*Tom Maus, Asma Atamna, Tobias Glasmachers* | **Category: cs.LG**

**Keywords:** 遗传算法, 强化学习, 专家演示, 混合学习, 样本效率

**Comment:** This article has been submitted to and accepted for presentation at
  the 11th International Conference on Machine Learning, Optimization, and Data
  Science (LOD 2025). After publication, it will appear in the official LOD
  2025 proceedings

> **TL;DR:** 本文提出一种利用遗传算法生成专家演示来提升强化学习（DQN和PPO）在工业排序环境中的性能，实验证明该方法显著优于标准RL、启发式和暴力优化。

**AI_Comments:** 本文通过将遗传算法与强化学习相结合，提出了一种创新的混合方法，解决了真实世界RL中样本效率低下和学习动态不稳定的关键问题。利用GA生成的演示来增强回放缓冲区（DQN）和预热启动（PPO）是一种巧妙的方法，可以利用现有知识或搜索能力来加速和稳定RL训练。该框架的公开可用性对促进自适应RL策略的进一步研究具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在真实世界工业应用中面临样本效率低下和学习动态不稳定等挑战，限制了其广泛部署。本研究旨在提升RL在工业环境中的性能。

**Method:** 提出一种新颖方法，利用遗传算法（GA）生成专家演示来增强策略学习。这些演示被整合到深度Q网络（DQN）的经验回放缓冲区中，并用作近端策略优化（PPO）代理的预热轨迹以加速训练收敛。实验将该方法与标准RL训练、基于规则的启发式方法和暴力优化进行了比较。

**Result:** GA衍生的演示显著提高了RL性能。用GA生成的数据初始化的PPO代理获得了更高的累积奖励。

**Conclusion:** 混合学习范式（其中启发式搜索方法补充数据驱动的RL）在真实世界应用中具有潜力。所使用的框架是公开可用的，支持对自适应RL策略的进一步研究。

> **ai_Abstract:** 本论文旨在解决强化学习（RL）在真实世界工业应用中面临的局限性，提出了一种新颖的混合方法。该方法利用遗传算法（GA）生成专家演示，并将其用于增强RL策略学习。具体而言，这些演示被整合到DQN的经验回放缓冲区中，并作为PPO代理的预热轨迹。在工业启发式排序环境中的实验结果表明，GA衍生的演示显著提高了RL性能，特别是对于PPO代理，这证明了将启发式搜索方法与数据驱动RL相结合的有效性。

> **摘要翻译:** 强化学习（RL）在某些真实世界的工业应用中展示了巨大的潜力，然而其更广泛的部署仍受到诸如样本效率低下和学习动态不稳定等固有挑战的限制。本研究探讨了利用遗传算法（GA）作为一种机制来提高RL在工业启发式排序环境中的性能。我们提出了一种新颖的方法，其中GA生成的专家演示用于增强策略学习。这些演示被整合到深度Q网络（DQN）的经验回放缓冲区中用于基于经验的学习，并用作近端策略优化（PPO）代理的预热轨迹以加速训练收敛。我们的实验将标准RL训练与基于规则的启发式方法、暴力优化和演示数据进行了比较，结果表明GA衍生的演示显著提高了RL性能。值得注意的是，用GA生成的数据初始化的PPO代理获得了更高的累积奖励，这突出了混合学习范式的潜力，其中启发式搜索方法补充了数据驱动的RL。所使用的框架是公开可用的，并支持对真实世界应用的自适应RL策略进行进一步研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [474] [BoltzNCE: Learning Likelihoods for Boltzmann Generation with Stochastic Interpolants and Noise Contrastive Estimation](https://arxiv.org/abs/2507.00846)
> *BoltzNCE：使用随机插值和噪声对比估计学习玻尔兹曼生成中的似然*

*Rishal Aggrwal, Jacky Chen, Nicholas M. Boffi, David Ryan Koes* | **Category: cs.LG, physics.bio-ph**

**Keywords:** 玻尔兹曼分布, 噪声对比估计, 随机插值, 似然学习, 自由能计算

**Comment:** 19 pages, 25 figures, submitted to NeurIPS 2025

> **TL;DR:** BoltzNCE通过结合噪声对比估计和随机插值来有效学习玻尔兹曼分布的似然，解决了传统方法计算雅可比矩阵开销大的问题，并在分子系统上实现了与精确似然相当的自由能剖面和数量级加速。

**AI_Comments:** 这篇论文通过引入噪声对比估计和随机插值，巧妙地规避了玻尔兹曼生成器中计算雅可比矩阵的瓶颈，这对于处理大型分子系统具有重要意义。其创新之处在于将能量基模型与密度估计技术结合，实现了对似然的有效学习，并显著提升了计算效率，这对于计算化学和分子模拟领域是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** 在分子等物理系统建模中，从能量函数定义的玻尔兹曼分布中高效采样是一个关键挑战。传统的玻尔兹曼生成器在计算样本似然时需要计算成本高昂的雅可比矩阵，这使得其对大型分子系统不切实际。

**Method:** 提出BoltzNCE方法，通过一个使用噪声对比估计（NCE）和分数匹配（score matching）训练的基于能量的模型来学习生成分布的似然。该方法利用随机插值在先验分布和生成分布之间进行退火，结合目标函数以高效学习密度函数。

**Result:** 在丙氨酸二肽系统上，该方法产生的自由能剖面和能量分布与使用精确似然获得的结果相当。此外，该方法能够准确估计亚稳态之间的自由能差异，并实现了数量级的加速。

**Conclusion:** BoltzNCE提供了一种有效且高效的方法来学习玻尔兹曼分布的似然，克服了传统方法中雅可比矩阵计算的限制，并在复杂分子系统中实现了准确的自由能估计和显著的计算加速。

> **ai_Abstract:** 本文提出了BoltzNCE，一种新方法，旨在解决玻尔兹曼生成器在计算分子系统似然时雅可比矩阵计算成本高昂的问题。BoltzNCE通过结合噪声对比估计、分数匹配和随机插值，利用基于能量的模型高效学习生成分布的似然。实验结果表明，该方法在丙氨酸二肽系统上能够生成与精确似然相当的自由能剖面和能量分布，并能准确且显著加速地估计亚稳态间的自由能差异。

> **摘要翻译:** 高效地从由能量函数定义的玻尔兹曼分布中采样是建模分子等物理系统的一个关键挑战。玻尔兹曼生成器通过利用连续归一化流来解决这个问题，该归一化流将一个简单的先验分布转换为一个可以重新加权以匹配玻尔兹曼分布的分布，这需要使用样本似然。然而，获取似然需要在积分过程中计算成本高昂的雅可比矩阵，这使得其对大型分子系统不切实际。为了克服这个问题，我们提出通过一个使用噪声对比估计和分数匹配训练的基于能量的模型来学习生成分布的似然。通过使用随机插值在先验分布和生成分布之间进行退火，我们结合了这两个目标函数以高效学习密度函数。在丙氨酸二肽系统上，我们证明了我们的方法产生的自由能剖面和能量分布与使用精确似然获得的结果相当。此外，我们还表明，亚稳态之间的自由能差异可以准确估计，并实现了数量级的加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [476] [Quantum Approximate Optimization Algorithm for Spatiotemporal Forecasting of HIV Clusters](https://arxiv.org/abs/2507.00848)
> *用于艾滋病病毒集群时空预测的量子近似优化算法*

*Don Roosan, Saif Nirzhor, Rubayat Khan, Fahmida Hai, Mohammad Rifat Haidar* | **Category: cs.LG, q-bio.MN**

**Keywords:** 量子近似优化算法, 艾滋病病毒集群, 时空预测, 量子机器学习, 流行病学

**Comment:** Conference details can be found here:
  https://www.insticc.org/node/technicalprogram/DATA/2025

> **TL;DR:** 本研究使用量子增强机器学习方法（QAOA、混合量子-经典神经网络、量子贝叶斯网络）分析艾滋病病毒流行数据，在集群检测和预测方面优于经典算法，并识别出住房不稳定是关键驱动因素，为精准干预提供了新工具。

**AI_Comments:** 本论文创新性地将量子计算应用于复杂的流行病学数据分析，特别是艾滋病病毒集群的时空预测。其重要性在于通过量子增强方法实现了比经典算法更高的准确性和效率，并且通过量子贝叶斯网络揭示了社会经济决定因素与艾滋病病毒传播之间的因果关系，为精准公共卫生干预提供了新的视角和工具。这标志着量子机器学习在解决现实世界复杂健康挑战方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 艾滋病病毒流行病学数据日益复杂，需要先进的计算方法来准确检测和预测集群。本研究旨在利用量子加速机器学习来提高艾滋病病毒监测的精度和效率。

**Method:** 本研究采用量子加速机器学习方法分析了2022年ZIP编码级别的艾滋病病毒流行情况，数据来源于AIDSVu和合成的社会经济决定因素（SDoH）数据。具体方法包括：将经典聚类算法（DBSCAN、HDBSCAN）与量子近似优化算法（QAOA）进行比较；开发混合量子-经典神经网络用于艾滋病病毒流行预测；使用量子贝叶斯网络探索SDoH因素与艾滋病病毒发病率之间的因果关系。

**Result:** 基于QAOA的方法在集群检测中达到了92%的准确率，耗时1.6秒，优于经典算法。混合量子-经典神经网络预测艾滋病病毒流行的准确率达到94%，超越了纯经典对应方法。量子贝叶斯分析发现住房不稳定是艾滋病病毒集群出现和扩张的关键驱动因素，而污名化则表现出地理变异的影响。

**Conclusion:** 量子增强方法在艾滋病病毒监测中提供了更高的精度和效率，并揭示了关键的因果路径。这项工作可以指导有针对性的干预措施，优化PrEP资源分配，并解决导致艾滋病病毒传播的结构性不平等问题。

> **ai_Abstract:** 本研究利用量子加速机器学习分析艾滋病病毒流行数据，旨在提高集群检测和预测的准确性及效率。研究比较了量子近似优化算法（QAOA）与经典聚类方法，并开发了混合量子-经典神经网络进行流行预测。结果显示，QAOA在集群检测中表现优异，混合量子-经典神经网络在预测方面也超越了经典方法。此外，量子贝叶斯分析揭示了住房不稳定是艾滋病病毒集群形成的关键驱动因素。这些量子增强技术为艾滋病病毒监测提供了更精确、高效的工具，并有助于指导未来的干预策略。

> **摘要翻译:** 艾滋病病毒流行病学数据日益复杂，需要先进的计算方法来准确检测和预测集群。我们采用量子加速机器学习来分析2022年ZIP编码级别的艾滋病病毒流行情况，数据来源于AIDSVu和合成的社会经济决定因素（SDoH）数据。我们的方法比较了经典聚类（DBSCAN，HDBSCAN）与量子近似优化算法（QAOA），开发了用于艾滋病病毒流行预测的混合量子-经典神经网络，并使用量子贝叶斯网络探索了SDoH因素与艾滋病病毒发病率之间的因果联系。基于QAOA的方法在1.6秒内实现了92%的集群检测准确率，优于经典算法。同时，混合量子-经典神经网络预测艾滋病病毒流行的准确率达到94%，超越了纯经典对应方法。量子贝叶斯分析发现住房不稳定是艾滋病病毒集群出现和扩张的关键驱动因素，而污名化则表现出地理变异的影响。这些量子增强方法在艾滋病病毒监测中提供了更高的精度和效率，同时揭示了关键的因果路径。这项工作可以指导有针对性的干预措施，优化PrEP（暴露前预防）资源分配，并解决导致艾滋病病毒传播的结构性不平等问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [478] [Aligning Learning and Endogenous Decision-Making](https://arxiv.org/abs/2507.00851)
> *对齐学习与内生决策*

*Rares Cristian, Pavithra Harsha, Georgia Perakis, Brian Quanz* | **Category: cs.LG**

**Keywords:** 内生决策, 机器学习, 鲁棒优化, 两阶段随机优化, 反事实信息

**Comment:** 

> **TL;DR:** 本文提出了一种端到端的方法和一种鲁棒优化变体，用于训练机器学习模型在内生不确定性下做出更好的决策，并在定价和库存问题上表现优于现有方法。

**AI_Comments:** 本文的创新之处在于提出了一个端到端框架，使机器学习模型能够感知其在决策过程中的下游影响，并有效处理内生不确定性。通过整合鲁棒优化和两阶段随机优化问题，该方法在理论上提供了性能保证，并在实际应用（如定价和库存管理）中展示了优越性。这对于需要模型与决策紧密结合的实际场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多观察结果受到我们决策的偏见，导致缺乏反事实信息，需要通过学习来获取。传统的机器学习模型未能充分考虑其下游影响，限制了它们在决策阶段的有效应用。

**Method:** 本文提出了一种端到端的内生不确定性训练机器学习模型的方法，使其能够感知下游影响。此外，还引入了一种鲁棒优化变体，通过构建机器学习模型空间上的不确定性集合并优化行动以防止最坏情况预测来应对模型的不确定性。该框架还引入了一类新的两阶段随机优化问题，其中第一阶段是信息收集。

**Result:** 本文证明了所提出的鲁棒方法可以以高概率捕获接近最优的决策。在定价和库存搭配/推荐问题上的计算实验表明，该方法在在线学习、多臂老虎机和离线强化学习等现有方法上表现出持续改进的性能。

**Conclusion:** 本文提出的端到端学习框架，包括鲁棒优化变体和处理两阶段随机优化问题的能力，有效解决了内生不确定性下的决策挑战，并显著提高了性能。

> **ai_Abstract:** 本文旨在解决内生不确定性下决策制定中缺乏反事实信息的挑战。为此，作者提出了一种端到端的方法，用于训练机器学习模型以感知其下游影响。该方法包含一个鲁棒优化变体，通过构建不确定性集合来应对模型不确定性，并保证能以高概率实现接近最优的决策。此外，该框架还引入并解决了新的两阶段随机优化问题。通过在定价和库存问题上的实验，结果表明该方法在性能上持续优于现有的在线学习、多臂老虎机和离线强化学习方法。

> **摘要翻译:** 我们所做的许多观察都受到我们决策的偏见。例如，商品的需求受到定价的影响，在线结账选择受到所呈现商品组合的影响。在这种设置下，决策的挑战在于缺乏反事实信息，需要通过学习来获取。我们引入了一种在内生不确定性下训练机器学习模型的端到端方法，使其能够感知其下游影响，从而在决策阶段有效使用。我们进一步引入了一种鲁棒优化变体，它考虑了机器学习模型中的不确定性——具体来说，通过在机器学习模型空间上构建不确定性集合并优化行动以防止最坏情况预测。我们证明了这种鲁棒方法可以以高概率捕获接近最优的决策，概率是数据量的函数。除此之外，我们还将一类新的两阶段随机优化问题引入到端到端学习框架中，现在可以通过我们的框架来解决。在这里，第一阶段是一个信息收集问题，决定在做出第二阶段决策之前要调查哪个随机变量并获取相关信息。我们对定价和库存搭配/推荐问题进行了多项计算实验。我们与在线学习/多臂老虎机/离线强化学习中的现有方法进行了比较，结果表明我们的方法始终优于这些方法。正如在内生设置中一样，模型的预测也取决于所做的第一阶段决策。虽然此决策在此设置中不影响随机变量，但它确实影响了应该做出的正确点预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [Machine Learning-based Early Detection of Potato Sprouting Using Electrophysiological Signals](https://arxiv.org/abs/2507.00862)
> *机器学习结合电生理信号实现马铃薯发芽的早期检测*

*Davide Andreoletti, Aris Marcolongo, Natasa Sarafijanovic Djukic, Julien Roulet, Stefano Billeter, Andrzej Kurenda, Margot Visse-Mansiaux, Brice Dupuis, Carrol Annette Plummer, Beatrice Paoli, Omran Ayoub* | **Category: cs.LG**

**Keywords:** 马铃薯发芽,早期检测,电生理信号,机器学习,储存管理

**Comment:** 8 pages, 7 figures

> **TL;DR:** 本文提出一种基于机器学习和电生理信号的早期马铃薯发芽检测方法，优于传统视觉方法，有助于提高储存管理效率。

**AI_Comments:** 这项研究通过引入电生理信号和机器学习，为马铃薯发芽的早期检测提供了一种创新且非侵入性的方法，显著优于传统的视觉检测。其重要性在于能够实现更早期的干预，从而优化储存管理，减少化学品浪费，并应对CIPC禁令带来的挑战。尽管结果令人鼓舞，但文章也指出了需要进一步改进以降低最大预测误差的局限性，这表明该技术在实际应用中仍有提升空间。

<details>
  <summary>Details</summary>

**Motivation:** 马铃薯发芽会降低其商业和营养价值，准确预测发芽对有效储存管理至关重要。现有方法依赖视觉识别，只能在形态变化后检测，限制了主动管理。CIPC禁令导致替代防芽化学品成本更高，因此急需可靠的早期预测方法。

**Method:** 提出一种新颖的基于机器学习的方法，利用专有传感器记录的马铃薯电生理信号进行早期发芽预测。该方法包括信号预处理、从波域提取相关特征，并训练监督机器学习模型进行早期发芽检测。此外，还结合了不确定性量化技术以增强预测。

**Result:** 实验结果表明在马铃薯发芽早期检测方面表现良好，能够准确预测部分马铃薯的确切发芽日期，并在所有马铃薯上显示出可接受的平均误差。

**Conclusion:** 尽管结果喜人，但仍需进一步改进以最小化预测误差，特别是减少观测到的最大偏差。

> **ai_Abstract:** 本文提出了一种基于机器学习和电生理信号的马铃薯发芽早期检测新方法。针对传统视觉检测滞后、管理效率低下的问题，该方法通过预处理电生理信号、从小波域提取特征并训练监督机器学习模型，实现了在马铃薯出现可见发芽迹象之前进行预测。实验结果表明，该方法在早期检测方面表现出良好性能，能准确预测部分马铃薯的发芽日期，并显示出可接受的平均误差，有望显著提升马铃薯储存管理效率。

> **摘要翻译:** 马铃薯发芽在出现任何视觉迹象之前进行准确预测对于有效的储存管理至关重要，因为发芽会降低块茎的商业和营养价值。有效的预测可以精确施用抗发芽化学品 (ASCs)，最大限度地减少浪费并降低成本。由于健康和环境问题，异丙基N-(3-氯苯基)氨基甲酸酯 (CIPC) 或氯丙胺的禁令使得这一需求变得更加紧迫，这导致采用了明显更昂贵的替代ASC。现有方法主要依赖视觉识别，这只能在形态变化发生后检测发芽，限制了其主动管理的有效性。因此，可靠的早期预测方法对于实现及时干预和提高采后储存策略的效率至关重要，其中早期是指在出现任何可见迹象之前检测发芽。在这项工作中，我们解决了马铃薯发芽的早期预测问题。为此，我们提出了一种新颖的基于机器学习 (ML) 的方法，该方法能够使用专有传感器记录的块茎电生理信号对马铃薯发芽进行早期预测。我们的方法对记录的信号进行预处理，从小波域提取相关特征，并训练监督ML模型进行早期发芽检测。此外，我们结合了不确定性量化技术来增强预测。实验结果表明，在马铃薯发芽的早期检测方面表现出良好的性能，能够准确预测部分马铃薯的确切发芽日期，同时在所有马铃薯上显示出可接受的平均误差。尽管结果喜人，但仍需进一步完善以最小化预测误差，特别是减少观测到的最大偏差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [481] [NN-Former: Rethinking Graph Structure in Neural Architecture Representation](https://arxiv.org/abs/2507.00880)
> *NN-Former：重新思考神经架构表示中的图结构*

*Ruihan Xu, Haokui Zhang, Yaowei Wang, Wei Zeng, Shiliang Zhang* | **Category: cs.LG, cs.AI**

**Keywords:** 神经架构表示, 图神经网络, Transformer, 同级节点, 神经网络预测器

**Comment:** Accepted to CVPR 2025. Code is avaiable at
  https://github.com/XuRuihan/NNFormer

> **TL;DR:** NN-Former结合GNN和Transformer的优点，通过关注被忽视的同级节点来改进神经架构预测，解决了GNN表示复杂特征不足和Transformer泛化差的问题，并在准确性和延迟预测上表现出色。

**AI_Comments:** NN-Former的创新点在于其对神经架构图结构的重新思考，特别是强调了同级节点的重要性，并设计了新的模块来有效利用这些被忽视的信息。通过结合GNN和Transformer的优势，该方法为提升神经架构属性预测的准确性和泛化能力提供了有前景的解决方案，对高效网络设计和部署具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习的普及需要高效的网络设计和部署，使得神经预测器（如预测准确性和延迟）变得至关重要。然而，现有的图神经网络（GNNs）在表示复杂特征方面存在不足，而Transformer在架构深度增加时泛化能力较差，这些是当前神经架构表示方法的缺点。

**Method:** 重新思考神经架构拓扑，并指出同级节点（sibling nodes）是关键但被忽视的元素。提出了一种名为NN-Former的新型预测器，它结合了GNN和Transformer的优势来学习增强的拓扑结构。具体引入了一个考虑同级节点的新型令牌混合器（token mixer）和一个名为双向图同构前馈网络（bidirectional graph isomorphism feed-forward network）的新型通道混合器（channel mixer）。

**Result:** 该方法在准确性和延迟预测方面持续取得有希望的性能。

**Conclusion:** NN-Former成功结合了GNN和Transformer的优势，通过重新思考并利用同级节点改进了神经架构表示，并在准确性和延迟预测上表现出色，为学习有向无环图（DAG）拓扑提供了有价值的见解。

> **ai_Abstract:** 本文提出了NN-Former，一种结合图神经网络（GNN）和Transformer优势的新型预测器，旨在解决现有方法在神经架构表示中存在的复杂特征表示不足和泛化能力差的问题。该方法通过重新审视神经架构拓扑，发现并利用了先前被忽视的同级节点的重要性。NN-Former引入了创新的令牌混合器和双向图同构前馈网络，并在准确性和延迟预测任务上均取得了显著性能，为有向无环图（DAG）拓扑学习提供了新的视角。

> **摘要翻译:** 深度学习的日益普及使得高效的网络设计和部署成为必要，神经预测器在估计准确性和延迟等属性方面变得至关重要。最近，图神经网络（GNNs）和Transformer在表示神经架构方面表现出有希望的性能。然而，这两种方法都有其缺点。GNN缺乏表示复杂特征的能力，而Transformer在架构深度增加时面临泛化能力差的问题。为了缓解上述问题，我们重新思考神经架构拓扑，并表明同级节点在之前的研究中被忽视了，但它们是关键的。因此，我们提出了一种新颖的预测器，它利用GNN和Transformer的优势来学习增强的拓扑结构。我们引入了一种考虑同级节点的新型令牌混合器，以及一个名为双向图同构前馈网络的新型通道混合器。我们的方法在准确性和延迟预测方面持续取得有希望的性能，为学习有向无环图（DAG）拓扑提供了宝贵的见解。代码可在https://github.com/XuRuihan/NNFormer获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [482] [TABASCO: A Fast, Simplified Model for Molecular Generation with Improved Physical Quality](https://arxiv.org/abs/2507.00899)
> *TABASCO：一种用于分子生成且具有改进物理质量的快速简化模型*

*Carlos Vonessen, Charles Harris, Miruna Cretu, Pietro Liò* | **Category: cs.LG**

**Keywords:** 分子生成, Transformer, 物理质量, 药物设计, 旋转等变性

**Comment:** 

> **TL;DR:** TABASCO是一种快速、简化的分子生成模型，它放弃了传统归纳偏差，实现了更高的物理合理性和10倍的推理速度，并展示了涌现的旋转等变性。

**AI_Comments:** TABASCO的创新之处在于其对现有SOTA分子生成模型中复杂归纳偏差的“放松”，即放弃了SE(3)和消息传递等重度依赖，转而采用简化的非等变Transformer架构。这种“去归纳偏置化”的设计不仅显著提高了模型的计算效率和数据吞吐量，更令人惊讶的是，它在没有硬编码对称性的情况下，展示了“涌现的旋转等变性”，这挑战了传统观念中对复杂几何先验的必要性。其在物理合理性（PoseBusters有效性）方面的SOTA表现，结合其极高的推理速度，使其成为药物设计等领域中高吞吐量生成任务的有力工具。这篇工作为未来极简主义生成模型的开发提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D分子生成模型虽然采用了SE(3)、置换等变性等归纳偏差和图消息传递网络来捕获局部化学性质，但生成的分子在物理合理性方面仍然存在问题。

**Method:** 本文提出了TABASCO模型，该模型放宽了现有模型的假设：它采用标准的非等变Transformer架构，将分子中的原子视为序列，并在生成后确定性地重建键。这种方法避免了等变层和消息传递，从而显著简化了模型架构并提高了数据吞吐量。

**Result:** 在GEOM-Drugs基准测试中，TABASCO实现了最先进的PoseBusters有效性，推理速度比最强的基线快约10倍，并且尽管没有硬编码对称性，却表现出涌现的旋转等变性。

**Conclusion:** 这项工作为训练极简主义、高吞吐量的生成模型提供了蓝图，这些模型适用于结构和药效团药物设计等专业任务。

> **ai_Abstract:** TABASCO是一种用于3D分子生成的新模型，旨在解决现有模型在物理合理性方面的不足。它通过采用简化的非等变Transformer架构，将原子视为序列并确定性地重建键，从而避免了复杂的等变层和消息传递。这种方法显著提高了数据吞吐量和推理速度（比现有基线快10倍），并在GEOM-Drugs基准测试中达到了最先进的物理有效性，同时意外地展现了旋转等变性。TABASCO为开发适用于药物设计等专业任务的极简、高吞吐量生成模型提供了新范式。

> **摘要翻译:** 三维分子生成领域的最新模型基于显著的归纳偏置，如SE(3)和置换等变性以尊重对称性，以及图消息传递网络以捕获局部化学性质，然而生成的分子在物理合理性方面仍然存在问题。我们引入了TABASCO，它放宽了这些假设：该模型具有标准的非等变Transformer架构，将分子中的原子视为序列，并在生成后确定性地重建键。没有等变层和消息传递使我们能够显著简化模型架构并扩展数据吞吐量。在GEOM-Drugs基准测试中，TABASCO实现了最先进的PoseBusters有效性，推理速度比最强的基线快约10倍，同时尽管没有硬编码对称性，却表现出涌现的旋转等变性。我们的工作为训练极简主义、高吞吐量的生成模型提供了蓝图，这些模型适用于结构和药效团药物设计等专业任务。我们提供了实现代码的GitHub链接。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [485] [Understanding Generalization in Node and Link Prediction](https://arxiv.org/abs/2507.00927)
> *理解节点和链接预测中的泛化能力*

*Antonis Vasileiou, Timo Stoll, Christopher Morris* | **Category: cs.LG**

**Keywords:** MPNNs, 泛化能力, 节点预测, 链接预测, 图神经网络

**Comment:** arXiv admin note: text overlap with arXiv:2412.07106

> **TL;DR:** MPNNs在节点和链接预测中的泛化能力尚不明确，现有研究有局限。本文提出了一个统一框架来分析MPNN在归纳和转导设置下的泛化特性，并量化图结构的影响，且该框架可推广到其他分类任务。

**AI_Comments:** 该研究通过提出一个统一的分析框架，填补了MPNN在节点和链接预测泛化能力理解上的空白。其创新之处在于考虑了多样化的架构参数、损失函数和图结构的影响，并超越了传统的i.i.d.假设。该框架的普适性也增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** MPNNs在节点和链接预测中应用广泛，但其超越训练集的泛化能力理解不足。现有研究常依赖不切实际的i.i.d.假设，忽视节点/链接间相关性，并假设固定聚合和不切实际的损失函数，同时忽略图结构的影响。

**Method:** 本文引入了一个统一框架，用于分析MPNN在归纳和转导节点和链接预测设置中的泛化特性。该框架整合了多样化的架构参数和损失函数，并量化了图结构的影响。此外，该框架可应用于图之外的任何归纳或转导设置下的分类任务。

**Result:** 经验研究支持了理论见解，加深了对MPNN在节点和链接预测任务中泛化能力的理解。

**Conclusion:** 本文提出的统一框架加深了对MPNN在节点和链接预测任务中泛化能力的理解。

> **ai_Abstract:** 本文旨在解决消息传递图神经网络（MPNNs）在节点和链接预测任务中泛化能力理解不足的问题。针对现有研究常依赖不切实际的假设、忽略图结构影响的局限性，作者提出了一个统一的分析框架。该框架能够分析MPNN在归纳和转导设置下的泛化特性，考虑了不同的架构参数、损失函数，并量化了图结构的作用。该框架还具有普适性，可推广至其他分类任务。实证结果验证了理论分析，提升了对MPNN泛化能力的认识。

> **摘要翻译:** 使用消息传递图神经网络（MPNNs）进行节点和链接预测在各种科学和工业领域至关重要，这导致了多样化MPNN架构的发展。除了在实际环境中表现良好之外，它们超越训练集的泛化能力仍然知之甚少。虽然一些研究探索了MPNN在图级别预测任务中的泛化能力，但对节点和链接级别的预测关注较少。现有工作通常依赖不切实际的独立同分布（i.i.d.）假设，忽略了节点或链接之间可能存在的相关性，并假设了固定的聚合和不切实际的损失函数，同时忽略了图结构的影响。在这项工作中，我们引入了一个统一框架，用于分析MPNN在归纳和转导节点和链接预测设置中的泛化特性，该框架结合了多样化的架构参数和损失函数，并量化了图结构的影响。此外，我们提出的泛化框架可以应用于图之外的任何归纳或转导设置下的分类任务。我们的实证研究支持了我们的理论见解，加深了我们对MPNN在这些任务中泛化能力的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [488] [Benchmarking the Discovery Engine](https://arxiv.org/abs/2507.00964)
> *基准测试发现引擎*

*Jack Foxabbott, Arush Tagade, Andrew Cusick, Robbie McCorkell, Leo McKee-Reid, Jugal Patel, Jamie Rumbelow, Jessica Rumbelow, Zohreh Shams* | **Category: cs.LG, I.2.6; I.2.3; I.5.1; H.2.8; J.2; J.3; J.4**

**Keywords:** 发现引擎, 机器学习, 可解释性, 科学发现, 基准测试

**Comment:** 16 pages, 8 figures, benchmarks Discovery Engine on five scientific
  datasets (medicine, materials science, climate, air quality, social science)

> **TL;DR:** 发现引擎是一个结合机器学习和可解释性的自动化系统，在多领域科学发现中表现出色，超越或媲美现有方法，并提供更深入的洞察。

**AI_Comments:** 该论文通过将机器学习与强大的可解释性相结合，为自动化科学发现提供了一种创新方法。其重要性在于提供了一个不仅能预测，还能提供可操作洞察的工具，这对于实际科学应用至关重要。跨多个领域的基准测试表明其具有广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是展示发现引擎作为自动化、可解释科学建模新标准的潜力及其有效性。

**Method:** 通过将发现引擎与五篇近期发表的、将机器学习应用于医学、材料科学、社会科学和环境科学的同行评审科学出版物进行基准测试。

**Result:** 发现引擎在预测性能上达到或超越了先前的表现，并通过丰富的可解释性工件生成了更深入、更具可操作性的洞察。

**Conclusion:** 结果表明，发现引擎有潜力成为自动化、可解释科学建模的新标准，能够从数据中实现复杂的知识发现。

> **ai_Abstract:** 本文介绍并评估了发现引擎，一个结合机器学习和先进可解释性的通用自动化科学发现系统。通过与医学、材料科学、社会科学和环境科学领域的五篇同行评审出版物进行基准测试，发现引擎在预测性能上均达到或超越了现有方法，并提供了更深入、可操作的洞察，展示了其作为可解释科学建模新标准的巨大潜力。

> **摘要翻译:** 发现引擎是一个通用的自动化科学发现系统，它将机器学习与最先进的机器学习可解释性相结合，以实现跨不同数据集的快速、稳健的科学洞察。在本文中，我们将发现引擎与五篇近期发表的、将机器学习应用于医学、材料科学、社会科学和环境科学的同行评审科学出版物进行了基准测试。在每种情况下，发现引擎都达到或超越了先前的预测性能，同时通过丰富的可解释性工件生成了更深入、更具可操作性的洞察。这些结果表明其作为自动化、可解释科学建模新标准的潜力，能够从数据中实现复杂的知识发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [490] [Scalable Feature Learning on Huge Knowledge Graphs for Downstream Machine Learning](https://arxiv.org/abs/2507.00965)
> *面向下游机器学习的巨型知识图谱可扩展特征学习*

*Félix Lefebvre, Gaël Varoquaux* | **Category: cs.LG**

**Keywords:** 知识图谱, 嵌入学习, 可扩展性, 下游任务, 消息传递

**Comment:** 

> **TL;DR:** SEPAL是一种新的可扩展知识图谱嵌入算法，它通过在小核心上优化并在图上进行消息传递来解决现有方法的扩展性和下游任务性能问题，并在多个大型知识图谱和下游任务上表现出色。

**AI_Comments:** SEPAL的创新之处在于其独特的分阶段嵌入优化和传播策略，有效克服了传统知识图谱嵌入方法在处理超大规模图时的内存和计算瓶颈。通过在小核心上优化并进行消息传递，它实现了全局嵌入对齐，同时保持了良好的可扩展性，使其在下游机器学习任务中的应用潜力巨大。

<details>
  <summary>Details</summary>

**Motivation:** 当前的知识图谱嵌入方法主要针对链接预测进行优化，并且由于GPU内存限制难以扩展到最大的图，这限制了它们在下游机器学习任务中的应用。

**Method:** 我们引入了SEPAL（可扩展嵌入传播算法），它通过仅在实体的小核心上优化嵌入来强制执行全局嵌入对齐，然后通过消息传递将它们传播到图的其余部分，从而为下游任务生成高质量的、可扩展的嵌入。

**Result:** SEPAL在7个大型知识图谱和46个下游机器学习任务上显著优于以前的方法。此外，SEPAL扩展了其基础嵌入模型，使得在商品硬件上也能适应巨大的知识图谱。

**Conclusion:** SEPAL成功地解决了知识图谱嵌入在扩展性和为下游机器学习任务生成高质量表示方面的挑战，使其成为处理大型知识图谱的有效解决方案。

> **ai_Abstract:** 本研究提出了一种名为SEPAL（可扩展嵌入传播算法）的新方法，旨在解决现有知识图谱嵌入方法在可扩展性和对下游机器学习任务支持不足的问题。SEPAL通过在实体的小核心上优化嵌入并将其传播到整个图来确保全局对齐，从而生成高质量且可扩展的知识图谱嵌入。实验结果表明，SEPAL在多个大型知识图谱和下游任务上显著优于现有方法，并能在商品硬件上处理巨型知识图谱。

> **摘要翻译:** 许多机器学习任务可以从外部知识中受益。大型知识图谱存储此类知识，并且可以使用嵌入方法将其提炼成可供下游应用程序使用的向量表示。然而，为此目的，当前模型存在两个局限性：它们主要通过局部对比学习针对链接预测进行优化，并且由于GPU内存限制而难以扩展到最大的图。为了解决这些问题，我们引入了SEPAL：一种用于大型知识图谱的可扩展嵌入传播算法，旨在为下游任务大规模生成高质量嵌入。SEPAL的关键思想是通过仅在实体的小核心上优化嵌入来强制执行全局嵌入对齐，然后通过消息传递将它们传播到图的其余部分。我们在7个大型知识图谱和46个下游机器学习任务上评估了SEPAL。我们的结果表明，SEPAL在下游任务上显著优于以前的方法。此外，SEPAL扩展了其基础嵌入模型，使得在商品硬件上也能适应巨大的知识图谱。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [492] [Reasoning as an Adaptive Defense for Safety](https://arxiv.org/abs/2507.00971)
> *推理作为安全自适应防御*

*Taeyoun Kim, Fahim Tajwar, Aditi Raghunathan, Aviral Kumar* | **Category: cs.LG, cs.AI**

**Keywords:** LLM安全, 自适应推理, 强化学习, TARS, 越狱防御

**Comment:** 42 pages, 11 Figures, 7 Tables

> **TL;DR:** 本文提出TARS，一种基于强化学习的方法，用于训练大型语言模型（LLMs）通过自适应推理来提高对安全漏洞的鲁棒性，并在安全-拒绝权衡和抵御攻击方面取得了更好的表现。

**AI_Comments:** 本文的创新点在于将自适应推理方法应用于LLM的安全防御，并提出了一个具体的强化学习框架TARS。通过引入链式思考和精心设计的奖励函数，TARS有效地提升了模型对安全漏洞的鲁棒性，并在安全-拒绝权衡方面取得了显著改善。其提供的开放方案对于LLM安全领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前自适应计算推理方法已提升LLMs在数学和代码等易于验证领域的性能。本文旨在探索如何利用这种方法训练模型以应对安全漏洞，并展示其益处。

**Method:** 本文提出了名为TARS（Training Adaptive Reasoners for Safety）的强化学习方法，通过链式思考轨迹和平衡安全与任务完成的奖励信号来训练模型进行安全推理。TARS包含三个关键设计选择：(1) “轻量级”热启动SFT阶段，(2) 混合有害、无害和模糊提示以防止捷径行为（如过多拒绝），以及(3) 用于防止训练期间推理能力退化的奖励函数。

**Result:** 使用TARS训练的模型通过在模糊查询上投入更多计算展现出自适应行为，从而实现了更好的安全-拒绝权衡。它们还在内部学习更好地区分安全和不安全提示，并对白盒（如GCG）和黑盒攻击（如PAIR）都表现出更强的鲁棒性。

**Conclusion:** 本文提供了一个有效且开放的方案，用于通过对每个提示进行推理来训练大型语言模型抵御越狱和有害请求。

> **ai_Abstract:** 本文提出了一种名为TARS的强化学习方法，旨在训练大型语言模型（LLMs）通过自适应推理来增强其对安全漏洞的防御能力。TARS利用链式思考和平衡安全与任务完成的奖励信号，并结合了轻量级SFT、混合提示以及防止推理能力退化的奖励函数等关键设计。实验结果表明，TARS训练的模型能够根据查询的模糊性自适应地分配计算资源，从而在安全拒绝和任务完成之间取得更好的平衡，并显著提升了模型对白盒和黑盒攻击的鲁棒性。这项工作为训练LLMs抵御越狱和有害请求提供了一个实用的开放方案。

> **摘要翻译:** 自适应分配测试时计算的推理方法已经提升了大型语言模型（LLM）在数学和代码等易于验证领域的性能。在这项工作中，我们研究了如何利用这种方法来训练模型，使其对安全漏洞表现出一定程度的鲁棒性，并表明这样做可以带来益处。我们构建了一个名为TARS（Training Adaptive Reasoners for Safety）的方案，这是一种强化学习（RL）方法，它通过链式思考轨迹和平衡安全与任务完成的奖励信号来训练模型进行安全推理。为了构建TARS，我们确定了三个关键设计选择：（1）“轻量级”热启动SFT阶段，（2）混合有害、无害和模糊提示以防止捷径行为，例如过多的拒绝，以及（3）一个奖励函数，以防止训练期间推理能力退化。使用TARS训练的模型通过在模糊查询上花费更多计算来表现出自适应行为，从而实现更好的安全-拒绝权衡。它们还在内部学习更好地区分安全和不安全提示，并对白盒（例如GCG）和黑盒攻击（例如PAIR）都获得了更大的鲁棒性。总的来说，我们的工作提供了一个有效、开放的方案，用于通过对每个提示进行推理来训练LLMs抵御越狱和有害请求。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [494] [Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes](https://arxiv.org/abs/2507.01003)
> *通过遍历定理描述神经网络训练过程：幽灵节点*

*Eun-Ji Park, Sangwon Yun* | **Category: cs.LG, cs.AI**

**Keywords:** 神经网络训练, 遍历定理, 幽灵节点, 随机梯度下降, Lyapunov指数

**Comment:** 9 pages, 2 figures

> **TL;DR:** 本文提出一个统一框架，通过引入最大Lyapunov指数诊断和幽灵节点扩展来理解和加速深度神经网络的训练，从而提高早期训练的可训练性并保持渐近行为。

**AI_Comments:** 这篇论文通过结合遍历定理和提出“幽灵节点”的概念，为理解和加速神经网络训练提供了一个新颖且有原则的视角。引入最大Lyapunov指数作为诊断工具具有实用价值，而“幽灵节点”则是一种创新的架构级干预，旨在解决早期训练中遇到的局部最优问题，其能够严格降低近似误差并最终与原始模型行为一致的特性，显示了其设计的精妙之处。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究从遍历角度解释训练过程，本文在此基础上旨在提供一个统一框架来理解和加速通过随机梯度下降训练深度神经网络。

**Method:** 本文通过分析目标函数的几何景观，引入了最大Lyapunov指数的运行估计作为诊断工具，以区分真正的收敛和鞍点附近的统计稳定。此外，提出了一种针对标准分类器的“幽灵类别扩展”，通过添加辅助幽灵输出节点，为模型提供额外的下降方向，从而绕过狭窄的损失障碍并在早期训练阶段避开不良盆地。

**Result:** 研究表明，“幽灵类别扩展”严格降低了近似误差。在充分收敛后，幽灵维度会塌缩，扩展模型的 invariate law 与原始模型一致。在扩展参数空间中存在一条路径，沿该路径总损失不增加，而原始损失可以任意幅度减少。

**Conclusion:** 这些结果提供了一种有原则的架构级干预，可以加速早期训练的可训练性，同时保持渐近行为。

> **ai_Abstract:** 本文基于遍历定理，提出了一个统一的深度神经网络训练框架。该框架引入了最大Lyapunov指数作为诊断工具，以区分真实收敛与统计稳定。同时，提出了一种“幽灵类别扩展”方法，通过增加幽灵输出节点来提供额外下降方向，帮助优化器在训练早期绕过损失障碍。研究结果表明，该扩展能有效降低近似误差，并在收敛后保持原始模型的渐近行为，从而显著加速早期训练效率。

> **摘要翻译:** 近期研究提出从遍历角度解释训练过程。在此基础上，我们提出了一个统一的框架，用于通过随机梯度下降理解和加速深度神经网络的训练。通过分析目标函数的几何景观，我们引入了一个实用的诊断工具——最大Lyapunov指数的运行估计，它能够可靠地区分向稳定最小值的真正收敛与鞍点附近的单纯统计稳定。然后，我们为标准分类器提出了一种幽灵类别扩展，它增加了辅助的幽灵输出节点，使模型获得额外的下降方向，从而在狭窄的损失障碍周围开辟一条横向通道，并使优化器能够在早期训练阶段绕过不良盆地。我们证明了这种扩展严格降低了近似误差，并且在充分收敛后，幽灵维度会塌缩，扩展模型的不变律与原始模型重合，并且在扩展参数空间中存在一条路径，沿该路径总损失不增加，而原始损失可以任意幅度减少。总而言之，这些结果提供了一种有原则的架构级干预，它加速了早期训练的可训练性，同时保留了渐近行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [496] [ZeCO: Zero Communication Overhead Sequence Parallelism for Linear Attention](https://arxiv.org/abs/2507.01004)
> *ZeCO：线性注意力中的零通信开销序列并行*

*Yuhong Chou, Zehao Liu, Ruijie Zhu, Xinyi Wan, Tianjian Li, Congying Chu, Qian Liu, Jibin Wu, Zejun Ma* | **Category: cs.LG**

**Keywords:** 序列并行, 线性注意力, 通信开销, 大语言模型, All-Scan

**Comment:** 

> **TL;DR:** ZeCO是一种针对线性注意力模型的序列并行方法，通过引入All-Scan原语，有效消除了通信开销，实现了长序列训练的近线性扩展性，显著加速了LLM的训练。

**AI_Comments:** ZeCO的创新之处在于提出了All-Scan这一新的集体通信原语，它从根本上解决了线性注意力模型在序列并行中的通信瓶颈。这对于训练具有极长上下文的下一代大语言模型具有重要意义，因为它打破了现有方法的扩展性限制，使得在分布式系统上处理百万级甚至千万级序列长度成为可能。

<details>
  <summary>Details</summary>

**Motivation:** 现有序列并行（SP）方法在处理线性注意力机制的大语言模型（LLMs）时，由于通信开销巨大，成为主要瓶颈，限制了对超长序列（如1M上下文）的高效处理和扩展性。

**Method:** 本文引入了ZeCO（零通信开销）序列并行方法，其核心是新的集体通信原语All-Scan。All-Scan为每个SP等级提供所需的初始运算符状态，同时保持最小的通信足迹，从而有效消除通信开销。

**Result:** ZeCO在理论上被证明是最优的，仅引入可忽略的时间和空间开销。在实践中，ZeCO在256个GPU上处理8M序列长度时，比当前最先进的SP方法实现了60%的加速。例如，使用ZeCO在64个设备上训练1M序列长度的模型，所需时间与在单个设备上训练16k序列的模型大致相同。

**Conclusion:** ZeCO为高效训练下一代大语言模型（LLMs）提供了清晰的路径，使其能够处理以前难以实现的序列长度，从而克服了现有序列并行方法的主要瓶颈。

> **ai_Abstract:** 本文提出ZeCO（零通信开销）序列并行方法，旨在解决线性注意力大语言模型在长序列训练中现有序列并行方法面临的通信瓶颈。ZeCO通过引入新的集体通信原语All-Scan，实现了通信开销的有效消除，从而使模型训练能达到近线性的扩展性。理论分析证明了ZeCO的最优性，实验结果显示其在多GPU环境下对超长序列训练的显著加速。

> **摘要翻译:** 线性注意力机制通过提供线性计算复杂度，为大语言模型（LLMs）带来了显著优势，实现了对超长序列（例如1M上下文）的高效处理。然而，现有的序列并行（SP）方法，作为在设备间分配这些工作负载的关键，由于大量的通信开销而成为主要瓶颈。在本文中，我们针对线性注意力模型引入了ZeCO（零通信开销）序列并行，这是一种旨在克服这些限制并实现长序列训练端到端近线性扩展性的新SP方法。例如，使用ZeCO在64个设备上训练一个1M序列长度的模型，所需时间大致与在单个设备上训练16k序列的模型相同。ZeCO的核心是All-Scan，一种新的集体通信原语。All-Scan精确地为每个SP等级提供其所需的初始运算符状态，同时保持最小的通信足迹，有效地消除了通信开销。理论上，我们证明了ZeCO的最优性，表明它只引入了可忽略的时间和空间开销。经验上，我们比较了不同序列并行策略的通信成本，并证明All-Scan在SP场景中实现了最快的通信。具体而言，在256个GPU上处理8M序列长度时，ZeCO比当前最先进（SOTA）的SP方法实现了60%的加速。我们相信ZeCO为高效训练下一代LLM在以前难以处理的序列长度上铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [17] [State and Memory is All You Need for Robust and Reliable AI Agents](https://arxiv.org/abs/2507.00081)
> *状态和记忆是构建鲁棒可靠AI代理的全部所需*

*Matthew Muhoberac, Atharva Parikh, Nirvi Vakharia, Saniya Virani, Aco Radujevic, Savannah Wood, Meghav Verma, Dimitri Metaxotos, Jeyaraman Soundararajan, Thierry Masquelin, Alexander G. Godfrey, Sean Gardner, Dobrila Rudnicki, Sam Michael, Gaurav Chopra* | **Category: cs.MA, cs.AI, cs.CL, cs.ET, physics.chem-ph**

**Keywords:** LLM agents, State, Memory, SciBORG, Autonomous planning

**Comment:** 5 Main Figures, 10 Extended Data Figures (37 Pages) for Manuscript ;
  9 Supplementary Tables, 40 Supplementary Figures (180 Pages) for Supporting
  Information

> **TL;DR:** 本文引入SciBORG框架，通过状态和记忆增强LLM代理，实现复杂科学工作流中的鲁棒、可靠、自主规划和执行，无需手动提示工程。

**AI_Comments:** SciBORG通过引入FSA记忆和动态代理构建，有效解决了LLM在复杂任务中记忆和规划的局限性，其在实际硬件集成和多步科学任务中的验证展示了其创新性和实用性，为构建更通用、可靠的AI代理提供了新范式。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在复杂、真实世界的科学工作流中的应用受到记忆、规划和工具集成方面挑战的限制。

**Method:** 本文介绍了SciBORG（为研究目标优化的科学定制人工智能代理），这是一个模块化的代理框架。代理从源代码文档动态构建，并用有限状态自动机（FSA）记忆增强，实现持久状态跟踪和上下文感知决策。这种方法消除了手动提示工程的需求，并通过在扩展工作流中维护上下文以及从工具或执行故障中恢复，实现了在不同应用中的鲁棒、可扩展部署。

**Result:** SciBORG通过与物理和虚拟硬件（如微波合成器）集成得到验证，展示了上下文感知决策。它还被用于从PubChem数据库自主检索多步生物分析，涉及多步规划、推理、代理间通信和协调。系统基准测试表明，SciBORG代理实现了可靠的执行、自适应规划和可解释的状态转换。

**Conclusion:** 记忆和状态感知是代理规划和可靠性的关键推动因素，为在复杂环境中部署AI代理提供了可泛化的基础。

> **ai_Abstract:** 本文提出SciBORG，一个模块化AI代理框架，旨在解决大型语言模型在复杂科学工作流中记忆、规划和工具集成方面的局限性。SciBORG通过动态构建代理并结合有限状态自动机（FSA）记忆，实现持久状态跟踪和上下文感知决策，从而无需手动提示工程。该框架支持鲁棒、可扩展的部署，并能从故障中恢复。实验证明，SciBORG在与物理/虚拟硬件集成以及自主生物分析检索任务中表现出可靠的执行、自适应规划和可解释的状态转换，强调了记忆和状态感知对于AI代理规划和可靠性的重要性。

> **摘要翻译:** 大型语言模型（LLM）在自然语言理解和生成方面取得了强大的进展。然而，它们在复杂、真实的科学工作流中的应用仍然受到记忆、规划和工具集成方面的挑战的限制。本文介绍了SciBORG（为研究目标优化的科学定制人工智能代理），这是一个模块化的代理框架，允许基于LLM的代理自主规划、推理并实现鲁棒和可靠的领域特定任务执行。代理从源代码文档动态构建，并用有限状态自动机（FSA）记忆增强，从而实现持久的状态跟踪和上下文感知决策。这种方法消除了手动提示工程的需求，并通过在扩展工作流中维护上下文以及从工具或执行故障中恢复，实现了在不同应用中的鲁棒、可扩展部署。我们通过与物理和虚拟硬件（例如用于执行用户指定反应的微波合成器）集成来验证SciBORG，展示了其上下文感知决策能力，并演示了其在利用多步规划、推理、代理间通信和协调执行探索性任务方面，从PubChem数据库自主检索多步生物分析的应用。系统基准测试表明，SciBORG代理实现了可靠的执行、自适应规划和可解释的状态转换。我们的结果表明，记忆和状态感知是代理规划和可靠性的关键推动因素，为在复杂环境中部署AI代理提供了可泛化的基础。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [33] [Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms](https://arxiv.org/abs/2507.00491)
> *Twill：在异构移动边缘平台上调度复合AI系统*

*Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri* | **Category: cs.MA, cs.AI, cs.CV, cs.PF**

**Keywords:** 复合AI系统, 边缘计算, 调度, 深度学习, Transformer

**Comment:** 9 Pages, 9 Figures, Accepted in International Conference on
  Computer-Aided Design (ICCAD) 2025

> **TL;DR:** Twill是一个运行时框架，用于在异构移动边缘平台上调度复合AI系统（cAI），通过任务亲和性映射、优先级冻结/解冻和DVFS来最小化推理延迟并遵守功耗预算，平均降低推理延迟54%。

**AI_Comments:** Twill的创新点在于其运行时调度机制，能够动态处理复合AI系统中DNN和Transformer的并发推理请求，这与现有依赖设计时分析的方法不同。其重要性在于为移动边缘设备上复杂AI应用的部署提供了高效的解决方案，特别是在资源受限且功耗敏感的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 复合AI (cAI) 系统在异构移动边缘平台上部署时，调度并发的DNN-transformer推理任务面临巨大挑战，现有策略无法处理cAI系统所需的DNN和transformer并发推理。

**Method:** 本文提出了Twill，一个运行时框架，通过任务亲和性感知的集群映射和迁移、优先级感知的任务冻结/解冻以及DVFS来处理cAI工作负载的并发推理请求，同时在功耗预算内最小化推理延迟。该框架在Nvidia Jetson Orin NX平台实现并部署。

**Result:** Twill与现有最先进的边缘AI推理技术相比，平均将推理延迟降低了54%，同时遵守了功耗预算。

**Conclusion:** Twill有效解决了在异构移动边缘平台上调度复合AI系统的挑战，显著降低了推理延迟并保持在功耗预算内。

> **ai_Abstract:** 本文提出了Twill，一个针对异构移动边缘平台上的复合AI（cAI）系统设计的运行时调度框架。Twill旨在解决cAI系统中DNN和Transformer并发推理的调度难题，通过任务亲和性映射、优先级任务冻结/解冻和DVFS等机制，在功耗预算内最小化推理延迟。实验结果表明，Twill在Nvidia Jetson Orin NX平台上的表现优于现有技术，平均降低了54%的推理延迟。

> **摘要翻译:** 复合AI（cAI）系统将多个AI模型链接起来以解决复杂问题。cAI系统通常由深度神经网络（DNN）、Transformer和大型语言模型（LLM）组成，表现出高度的计算多样性和动态工作负载变化。在移动边缘平台上部署cAI服务对调度并发的DNN-Transformer推理任务提出了重大挑战，这些任务以未知的序列动态到达。现有的移动边缘AI推理策略管理多DNN或仅Transformer的工作负载，依赖于设计时分析，无法处理cAI系统所需的DNN和Transformer的并发推理。在这项工作中，我们解决了在异构移动边缘平台上调度cAI系统的挑战。我们提出了Twill，一个运行时框架，通过任务亲和性感知的集群映射和迁移、优先级感知的任务冻结/解冻以及DVFS来处理cAI工作负载的并发推理请求，同时在功耗预算内最小化推理延迟。我们在Nvidia Jetson Orin NX平台上实现并部署了Twill框架。我们针对当代DNN和LLM，评估了Twill与最先进的边缘AI推理技术，平均将推理延迟降低了54%，同时遵守了功耗预算。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [53] [Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications](https://arxiv.org/abs/2507.00914)
> *大型语言模型驱动的智能城市代理：概念、能力与应用*

*Jindong Han, Yansong Ning, Zirui Yuan, Hang Ni, Fan Liu, Tengfei Lyu, Hao Liu* | **Category: cs.MA, cs.AI**

**Keywords:** 大型语言模型, 智能城市, 城市代理, 综述, 城市智能

**Comment:** 

> **TL;DR:** 本文概述了大型语言模型（LLM）如何驱动智能城市代理，涵盖其概念、能力、应用领域、信任度问题以及未来研究方向，旨在为城市LLM代理领域奠定基础并提供路线图。

**AI_Comments:** 这是一篇重要的综述性文章，为大型语言模型在智能城市应用这一新兴交叉领域提供了全面的框架和路线图。其创新性在于系统地定义了“城市LLM代理”的概念，并从工作流和应用领域进行了详细的分类和梳理，有助于研究人员理解和进入该领域。文章还指出了可信度和评估等关键挑战，对未来的研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能城市的愿景是利用大数据和人工智能技术创建高效、宜居、可持续的城市环境。大型语言模型的出现为实现这一愿景开辟了新途径，因其强大的语义理解和推理能力，可部署为自主解决复杂问题的智能代理。

**Method:** 本文首先介绍了城市LLM代理的概念、独特能力和特点。其次，从代理工作流（包括城市感知、内存管理、推理、执行和学习）的角度调查了当前的研究现状。第三，将城市LLM代理的应用领域分为城市规划、交通、环境、公共安全和城市社会五类，并展示了各类的代表性工作。最后，讨论了实际部署中关键的信任度和评估问题，并指出了未来的开放性研究问题。

**Result:** 本文介绍了城市LLM代理的概念、能力和特点；调查了代理工作流（城市感知、内存管理、推理、执行和学习）的研究现状；将应用领域分为城市规划、交通、环境、公共安全和城市社会五大类，并列举了代表性工作；讨论了信任度和评估问题以及未来的开放性问题。

**Conclusion:** 本综述旨在为新兴的城市LLM代理领域奠定基础，并为推进LLM与城市智能的交叉研究提供路线图。

> **ai_Abstract:** 本文综述了大型语言模型（LLMs）在智能城市领域中作为“城市LLM代理”的应用。文章首先定义了城市LLM代理的概念、独特能力和特征。接着，从城市感知、内存管理、推理、执行和学习等代理工作流角度，梳理了当前的研究进展。随后，将城市LLM代理的应用场景划分为城市规划、交通、环境、公共安全和城市社会五大类，并提供了实例。最后，讨论了部署中的信任度与评估挑战，并提出了未来的研究方向，旨在为城市LLM代理这一新兴领域奠定基础并提供发展路线图。

> **摘要翻译:** 智能城市的长期愿景是利用大数据和人工智能技术创建高效、宜居、可持续的城市环境。最近，大型语言模型（LLMs）的出现为实现这一愿景开辟了新途径。凭借强大的语义理解和推理能力，LLMs可以被部署为能够自主解决跨领域复杂问题的智能代理。在本文中，我们关注城市LLM代理，它们是LLM驱动的代理，半具身于城市混合的赛博-物理-社会空间中，用于系统级的城市决策。首先，我们介绍了城市LLM代理的概念，讨论了它们的独特能力和特点。其次，我们从代理工作流的角度调查了当前的研究现状，包括城市感知、内存管理、推理、执行和学习。第三，我们将城市LLM代理的应用领域分为五类：城市规划、交通、环境、公共安全和城市社会，并在每类中展示了代表性工作。最后，我们讨论了对于实际部署至关重要的信任度和评估问题，并指出了未来研究的几个开放性问题。本综述旨在为新兴的城市LLM代理领域奠定基础，并为推进LLM与城市智能的交叉研究提供路线图。相关的论文和开源资源列表在https://github.com/usail-hkust/Awesome-Urban-LLM-Agents 上维护并持续更新。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [8] [Novel Design of 3D Printed Tumbling Microrobots for in vivo Targeted Drug Delivery](https://arxiv.org/abs/2507.00166)
> *新型3D打印翻滚微型机器人用于体内靶向药物递送*

*Aaron C. Davis, Siting Zhang, Adalyn Meeks, Diya Sakhrani, Luis Carlos Sanjuan Acosta, D. Ethan Kelley, Emma Caldwell, Luis Solorio, Craig J. Goergen, David J. Cappelleri* | **Category: cs.RO**

**Keywords:** 3D打印, 翻滚微型机器人, 靶向药物递送, 磁驱动, 体内

**Comment:** 

> **TL;DR:** 论文介绍了用于体内靶向药物递送的新型3D打印翻滚微型机器人设计，通过外部磁场驱动，并在不同条件下进行了运动、药物释放和生物相容性测试，结果显示其具有鲁棒性和潜力。

**AI_Comments:** 本文创新性地结合了3D打印技术和磁驱动机制，为体内靶向药物递送提供了一种灵活且可定制的解决方案。其全面性体现在从设计、制造、体外性能评估到体内动物模型的完整验证流程。该研究对于克服现有微型机器人设计的局限性，特别是在复杂生物环境中实现精确药物递送方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有翻滚微型机器人设计存在局限性，需要一种新型方法来改进体内靶向药物递送。

**Method:** 使用立体光刻3D打印技术设计并制造翻滚微型机器人，集成永磁体，通过旋转磁场执行器系统进行驱动。进行了一系列运动特性测试，评估在不同几何形状、驱动频率、干湿环境和温度变化下的性能。设计了三种药物加载方法，使用聚焦超声系统评估热药物释放，并进行了生物相容性测试。在组织模型和体内大鼠模型中进行动物实验。

**Result:** 所提出的微型机器人设计展现出鲁棒性和适应性，并显示出实现高效、靶向体内药物递送的潜力。

**Conclusion:** 这种新颖的方法解决了现有翻滚微型机器人设计的局限性，并为大肠内靶向药物递送的进步铺平了道路。

> **ai_Abstract:** 本文提出了一种用于体内靶向药物递送的新型3D打印翻滚微型机器人。该机器人通过立体光刻技术制造，并集成永磁体以实现磁场驱动。研究团队进行了全面的实验，包括运动特性、药物加载、热药物释放和生物相容性测试，并在体外和体内模型中进行了评估。结果表明，这些微型机器人设计具有良好的鲁棒性和适应性，为解决现有设计的局限性并推动大肠内靶向药物递送的发展提供了新途径。

> **摘要翻译:** 本文介绍了用于体内靶向药物递送应用的新型3D打印翻滚微型机器人创新设计。这些微型机器人设计采用立体光刻3D打印技术创建，并集成了永磁体，通过旋转磁场执行器系统实现驱动。实验框架包括一系列运动特性测试，以评估微型机器人在各种条件下的性能。测试变量包括微型机器人几何形状、驱动频率以及干湿环境和温度变化等环境条件。本文概述了三种药物加载方法的设计，以及使用聚焦超声系统进行的热药物释放的全面评估，以及生物相容性测试。动物模型测试涉及组织模型和体内大鼠模型，确保对微型机器人的性能和兼容性进行彻底评估。结果突出了所提出的微型机器人设计的鲁棒性和适应性，展示了在体内实现高效靶向药物递送的潜力。这种新颖的方法解决了现有翻滚微型机器人设计的当前局限性，并为大肠内靶向药物递送的进步铺平了道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [24] [Rethink 3D Object Detection from Physical World](https://arxiv.org/abs/2507.00190)
> *从物理世界重新思考三维目标检测*

*Satoshi Tanaka, Koji Minoda, Fumiya Watanabe, Takamasa Horibe* | **Category: cs.RO, cs.CV**

**Keywords:** 三维目标检测, 实时性能, 自动驾驶, 评估指标, 硬件优化

**Comment:** 15 pages, 10 figures

> **TL;DR:** 本文提出L-AP和P-AP新指标，考虑物理世界因素，更全面评估实时三维目标检测，并优化硬件和模型选择。

**AI_Comments:** 本文的创新之处在于引入了L-AP和P-AP两个新的评估指标，将物理世界中的时间、物理约束以及对运动规划的影响纳入了3D目标检测的性能评估体系，这比传统的mAP和延迟指标更为全面和实际。其重要性在于，为自动驾驶等实时应用提供了一个更符合实际需求的评估框架，有助于开发者在速度、精度和安全性之间做出更合理的权衡。此外，通过定量证明“点云越多性能越好”的假设不适用于实时应用，挑战了传统认知，并提出了基于新指标的硬件和模型优化方法，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的三维目标检测研究在评估性能时未能充分考虑速度与准确性之间的权衡、不同硬件设备和加速器之间的定量评估，以及对运动规划中碰撞避免的影响，这对于实时应用至关重要。

**Method:** 本文引入了延迟感知AP (L-AP) 和规划感知AP (P-AP) 作为新的评估指标，这些指标考虑了物理世界中的时间概念和物理约束。此外，还通过延迟感知超参数优化 (L-HPO) 开发了实时三维目标检测的性能模型，并利用所提出的指标优化了硬件和模型选择。

**Result:** 本文提出的指标在nuPlan数据集上展示了对整个自动驾驶系统的有效性，并评估了考虑硬件差异和加速器的三维目标检测模型。研究还定量证明了“点云越多，识别性能越好”的假设在实时应用中是不正确的。

**Conclusion:** 本文通过引入L-AP和P-AP等新指标，并考虑物理世界因素，为实时三维目标检测提供了更全面的评估方法，并开发了相应的优化策略，纠正了传统认知中的一些误区，从而提升了自动驾驶系统的性能和安全性。

> **ai_Abstract:** 本文针对现有三维目标检测评估方法未能充分考虑速度-精度权衡、硬件差异及对运动规划影响的问题，提出了延迟感知AP (L-AP) 和规划感知AP (P-AP) 新指标。这些指标将物理世界的时间和约束纳入考量，以提供更全面的实时三维目标检测评估。研究基于这些新指标，开发了性能模型并优化了硬件和模型选择，并纠正了“点云越多性能越好”的普遍认知，旨在提升自动驾驶系统的实用性和安全性。

> **摘要翻译:** 高精度和低延迟的三维目标检测对于自动驾驶系统至关重要。虽然以往关于三维目标检测的研究通常根据平均精度 (mAP) 和延迟来评估性能，但它们通常未能解决速度和精度之间的权衡问题，例如100毫秒时60.0 mAP与500毫秒时61.0 mAP的对比。尽管对实时应用至关重要，但不同硬件设备和加速器之间权衡的定量评估仍未被探索。此外，它们忽视了对运动规划中碰撞避免的影响，例如，60.0 mAP可能导致更安全的运动规划，而61.0 mAP可能导致高风险运动规划。在本文中，我们引入了延迟感知AP (L-AP) 和规划感知AP (P-AP) 作为新指标，它们考虑了物理世界（如时间概念和物理约束），为实时三维目标检测提供了更全面的评估。我们使用nuPlan数据集证明了我们指标对整个自动驾驶系统的有效性，并评估了考虑硬件差异和加速器的三维目标检测模型。我们还通过使用我们的指标进行延迟感知超参数优化 (L-HPO)，开发了实时三维目标检测的最新性能模型。此外，我们定量证明了“点云越多，识别性能越好”的假设对于实时应用来说是不正确的，并使用我们的指标优化了硬件和模型选择。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [44] [Sim2Real Diffusion: Learning Cross-Domain Adaptive Representations for Transferable Autonomous Driving](https://arxiv.org/abs/2507.00236)
> *Sim2Real Diffusion：学习跨域自适应表示以实现可迁移的自动驾驶*

*Chinmay Vilas Samak, Tanmay Vilas Samak, Bing Li, Venkat Krovi* | **Category: cs.RO**

**Keywords:** Sim2Real, 扩散模型, 自动驾驶, 域适应, 表示学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于条件潜在扩散模型的统一框架，用于学习跨域自适应表示，以弥合自动驾驶中的仿真到现实（sim2real）差距，并通过行为克隆案例研究证明了其有效性，将感知sim2real差距弥合了40%以上。

**AI_Comments:** 该论文的创新点在于将条件潜在扩散模型应用于仿真到现实（sim2real）迁移，这为解决自动驾驶领域中数据有限、域适应和样本多样性等挑战提供了一种新颖且有前景的方法。其能够将感知sim2real差距弥合超过40%的成果显著，且其模块化和少样本学习能力对于自动驾驶的实际开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的仿真到现实（sim2real）迁移方法难以全面解决自动驾驶中平衡条件域适应、有限样本下的鲁棒性能、处理多域表示的模块化以及实时性能等自治导向的需求。

**Method:** 本文提出了一个统一的框架，利用条件潜在扩散模型学习跨域自适应表示，以实现可迁移的自动驾驶算法。该框架提供了利用替代基础模型、少样本微调管道以及文本和图像提示进行跨源域和目标域映射的选项。它还能够在扩散跨参数空间（如一天中的时间、天气条件、季节和操作设计域）时生成多样化的高质量样本。

**Result:** 实验表明，所提出的框架能够将感知上的仿真到现实（sim2real）差距弥合40%以上。

**Conclusion:** 生成式扩散模型在仿真到现实（sim2real）迁移中具有巨大潜力，为更鲁棒和自适应的自动驾驶提供了途径。

> **ai_Abstract:** 本文提出了“Sim2Real Diffusion”，一个利用条件潜在扩散模型学习跨域自适应表示的统一框架，旨在弥合自动驾驶中的仿真到现实（sim2real）差距。该框架通过提供条件域适应、少样本微调、模块化处理多种域表示以及实时性能等功能，解决了现有sim2real方法的局限性。它还支持生成多样化的高质量样本，并可利用文本和图像提示进行域映射。通过行为克隆案例研究等实验，该方法显示能将感知sim2real差距弥合超过40%，强调了扩散模型在实现鲁棒和自适应自动驾驶方面的巨大潜力。

> **摘要翻译:** 基于仿真的自动驾驶算法设计、优化和验证多年来已被证明对其迭代改进至关重要。然而，衡量有效性的最终标准是它们从仿真到现实（sim2real）的成功过渡。但是，现有的sim2real迁移方法难以全面解决自动驾驶中平衡以下几点的自治导向需求：(i) 条件域适应，(ii) 有限样本下的鲁棒性能，(iii) 处理多域表示的模块化，以及 (iv) 实时性能。为了缓解这些痛点，我们提出了一个统一的框架，利用条件潜在扩散模型学习用于sim2real可迁移自动驾驶算法的跨域自适应表示。我们的框架提供了利用以下选项：(i) 替代基础模型，(ii) 少样本微调管道，以及 (iii) 文本和图像提示，用于在给定源域和目标域之间进行映射。它还能够在扩散跨参数空间（如一天中的时间、天气条件、季节和操作设计域）时生成多样化的高质量样本。我们系统地分析了所提出的框架，并以关键定量指标和消融研究的形式报告了我们的发现，以及富有洞察力的定性示例和评论。此外，我们通过行为克隆案例研究，证明了所提出的方法在弥合端到端自动驾驶的sim2real差距方面的实用性。我们的实验表明，所提出的框架能够将感知上的sim2real差距弥合40%以上。我们希望我们的方法能够强调生成式扩散模型在sim2real迁移中的潜力，为更鲁棒和自适应的自动驾驶提供途径。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [64] [Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems](https://arxiv.org/abs/2507.00268)
> *控制优化深度强化学习用于人工智能自主系统*

*Oren Fivel, Matan Rudman, Kobi Cohen* | **Category: cs.RO, cs.AI, cs.SY, eess.SY**

**Keywords:** 深度强化学习, 动作执行不匹配, 控制优化, 鲁棒性, 自主系统

**Comment:** 27 pages, 10 figures

> **TL;DR:** 深度强化学习（DRL）常忽略动作执行误差。本文提出一种控制优化的DRL框架，显式建模并补偿执行不匹配，提高真实世界应用中的鲁棒性，弥合理想化学习与现实世界实施的差距。

**AI_Comments:** 这篇论文通过显式处理深度强化学习中长期被忽视的动作执行不匹配问题，提供了一个重要的进步。其创新点在于将控制理论与DRL相结合，通过两阶段过程（期望动作决定与控制信号选择）来弥补理想化学习与现实世界实施之间的鸿沟。这对于机器人、机电一体化等需要高精度控制的领域具有显著的实用价值，提高了AI系统在复杂真实环境中的鲁棒性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 传统深度强化学习（DRL）方法假设完美的动作执行，但忽略了代理选择的动作与实际系统响应之间的不确定性和偏差。在机器人、机电一体化和通信网络等现实世界应用中，由系统动力学、硬件限制和延迟引起的执行不匹配会显著降低性能，现有方法普遍忽视了这一挑战。

**Method:** 本文提出一种新颖的控制优化深度强化学习（DRL）框架，旨在显式建模并补偿动作执行不匹配。该方法建立了一个结构化的两阶段过程：首先确定期望动作，然后选择适当的控制信号以确保正确执行。在训练代理时，该框架会考虑动作不匹配和控制器校正，使AI代理能够优化期望动作，同时兼顾实际控制信号、预期结果以及执行误差。

**Result:** 该方法增强了AI代理在真实世界不确定性下的决策鲁棒性。在五个经过重构以反映真实操作条件的开源机械仿真环境中进行的评估显示，该框架对不确定性表现出强大的鲁棒性，并为面向控制的应用提供了一个高度实用且高效的解决方案。

**Conclusion:** 该方法通过弥合理想化学习与现实世界实施之间的差距，为工程实践提供了实质性进展。它使在工程环境中运行的智能代理能够在训练期间预测和调整执行误差和系统干扰，从而在真实世界应用中提高性能和可靠性。

> **ai_Abstract:** 本文提出了一种控制优化的深度强化学习（DRL）框架，旨在解决传统DRL在现实世界应用中因动作执行不匹配（如系统动力学、硬件限制和延迟）导致的性能下降问题。该框架采用两阶段过程，显式建模并补偿动作执行误差，在训练过程中考虑动作不匹配和控制器校正，从而使AI代理能够优化期望动作并提高在不确定环境下的鲁棒性。实验在多个机械仿真环境中验证了其有效性，为工程实践提供了更实用的解决方案。

> **摘要翻译:** 深度强化学习（DRL）已成为机器学习和人工智能领域复杂决策的强大工具。然而，传统方法通常假设完美的动作执行，忽略了代理选择的动作与实际系统响应之间的不确定性和偏差。在机器人、机电一体化和通信网络等现实世界应用中，由系统动力学、硬件限制和延迟引起的执行不匹配会显著降低性能。这项工作通过开发一种新颖的控制优化DRL框架来推进人工智能，该框架显式建模并补偿动作执行不匹配，这是现有方法中很大程度上被忽视的挑战。我们的方法建立了一个结构化的两阶段过程：确定期望动作和选择适当的控制信号以确保正确执行。它在训练代理时考虑了动作不匹配和控制器校正。通过将这些因素纳入训练过程，AI代理优化了期望动作，同时考虑了实际控制信号和预期结果，并明确考虑了执行误差。这种方法增强了鲁棒性，确保决策在现实世界的不确定性下仍然有效。我们的方法通过弥合理想化学习与现实世界实施之间的差距，为工程实践提供了实质性进展。它使在工程环境中运行的智能代理能够在训练期间预测和调整执行误差和系统干扰。我们在五个广泛使用的开源机械仿真环境中评估了该框架，这些环境经过我们重构和开发以反映真实世界的操作条件，展示了其对不确定性的鲁棒性，并为面向控制的应用提供了高度实用和高效的解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [86] [Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation](https://arxiv.org/abs/2507.00273)
> *面向具有并联驱动的人形机器人的机械智能感知课程强化学习*

*Yusuke Tanaka, Alvin Zhu, Quanyou Wang, Dennis Hong* | **Category: cs.RO**

**Keywords:** 强化学习, 并联驱动, 人形机器人, 课程学习, MuJoCo

**Comment:** 

> **TL;DR:** 本研究提出了一种针对具有并联驱动人形机器人的课程强化学习框架，通过在模拟器中完整建模并联机构，实现了更好的泛化能力和真实世界部署性能。

**AI_Comments:** 该论文的创新点在于首次将完整的并联机构模拟引入到人形机器人的端到端强化学习框架中，解决了传统模拟器对闭合运动链支持不足的问题。通过利用GPU加速的MJX，它能够更准确地捕捉硬件的物理特性，从而训练出更鲁棒和高效的策略。这项工作对于推动具有复杂机械设计的人形机器人在现实世界中的部署具有重要意义，尤其是在机器人控制和模拟保真度方面取得了显著进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习框架在处理人形机器人运动时，由于模拟器对闭合运动链支持的限制，未能充分考虑并联驱动机构中嵌入的机械智能，导致运动建模不准确和策略次优，尤其对于高驱动复杂度的机器人。

**Method:** 本文提出了一种针对BRUCE（一种具有三种独特并联机构腿部的人形机器人）的端到端课程强化学习框架。该方法使用GPU加速的MJX（MuJoCo）原生模拟所有闭合链约束，从而在训练期间保留了硬件的物理特性，这与依赖简化串联近似的先前方法不同。

**Result:** 与模型预测控制器（MPC）相比，本研究的强化学习方法在真实世界的零样本部署中表现出更好的表面泛化能力和性能。

**Conclusion:** 这项工作强调了在类人腿部机器人端到端学习管道中完全模拟并联机构的计算方法和性能优势。

> **ai_Abstract:** 本论文介绍了一种新颖的课程强化学习框架，旨在解决现有方法在模拟具有复杂并联驱动机制的人形机器人时，因未能充分考虑机械智能而导致的建模不准确和策略次优问题。通过利用GPU加速的MJX模拟器原生支持闭合运动链，该框架成功地为BRUCE人形机器人（其腿部包含差动滑轮、五杆和四杆连杆机构）训练出高效的运动策略。实验结果表明，与传统的模型预测控制器相比，该方法在真实世界的零样本部署中展现出更优异的表面泛化能力和性能，凸显了在端到端学习中完整模拟并联机制的重要性及其带来的性能提升。

> **摘要翻译:** 强化学习（RL）使人形机器人运动取得了重大进展，但由于模拟器对闭合运动链支持的限制，大多数学习框架没有考虑并联驱动机制中嵌入的机械智能。这种遗漏可能导致不准确的运动建模和次优的策略，特别是对于具有高驱动复杂度的机器人。本文提出了一种针对BRUCE的端到端课程强化学习框架，BRUCE是一种儿童大小的人形机器人，其腿部具有三种独特的并联机制：差动滑轮、五杆连杆机构和四杆连杆机构。与依赖简化串联近似的现有方法不同，我们使用GPU加速的MJX（MuJoCo）原生模拟所有闭合链约束，在训练期间保留了硬件的物理特性。我们将我们的RL方法与模型预测控制器（MPC）进行了基准测试，证明了在真实世界零样本部署中更好的表面泛化能力和性能。这项工作强调了在类人腿部机器人端到端学习管道中完全模拟并联机制的计算方法和性能优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [95] [Novel Pigeon-inspired 3D Obstacle Detection and Avoidance Maneuver for Multi-UAV Systems](https://arxiv.org/abs/2507.00443)
> *多无人机系统的新型鸽子启发式三维障碍物检测与避障机动*

*Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad* | **Category: cs.RO, cs.AI, cs.MA**

**Keywords:** 多无人机系统, 避障, 编队控制, 自然启发, 半分布式控制

**Comment:** 11 Pages, 11 Pictures, 1 Table, 3 Algorithms

> **TL;DR:** 研究提出了一种受鸽子和罗非鱼启发的半分布式控制框架，用于多无人机系统在2D和3D动态环境中进行无碰撞编队控制和避障，并通过实验验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于结合了自然启发（鸽子和罗非鱼）和半分布式控制方法来解决多无人机系统的3D避障和编队控制问题。其将概率Lloyd算法用于集中式定位，并辅以分布式避障，这种混合方法具有一定的独特性。论文通过在2D和3D动态环境中的验证，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 城市地区多无人机系统的应用需求日益增长，但面临静态和动态障碍物。因此，需要开发有效的避障和编队控制方法。

**Method:** 该研究提出了一种受鸽子和罗非鱼集体行为启发的自然启发式无碰撞编队控制方法，并考虑了避障机动。该框架采用半分布式控制方法，其中集中式引导算法基于概率Lloyd算法实现无人机优化定位，而分布式控制方法则用于车辆间碰撞和障碍物避障。此外，所提出的框架扩展到3D空间，并定义了新型3D机动。

**Result:** 所提出的框架已应用于2D和3D场景下的多无人机系统，结果表明该方法在存在静止和移动障碍物的动态环境中是有效的。

**Conclusion:** 该研究成功开发并验证了一种受自然启发的半分布式控制框架，能够使多无人机系统在复杂的2D和3D动态环境中实现有效的无碰撞编队控制和障碍物规避。

> **ai_Abstract:** 本文提出了一种受罗非鱼和鸽子集体行为启发的半分布式控制框架，旨在解决多无人机系统在城市环境中面临的静态和动态障碍物问题。该框架结合了基于概率Lloyd算法的集中式引导算法进行无人机优化定位，以及用于车辆间和障碍物避障的分布式控制方法。该方法已扩展至三维空间，并定义了新的三维机动。实验结果验证了该方法在2D和3D动态环境中处理静止和移动障碍物的有效性。

> **摘要翻译:** 多无人机系统的新型鸽子启发式三维障碍物检测与避障机动

多智能体系统操纵的最新进展表明，在城市地区部署多无人机系统的需求日益增长，而这些地区总是存在静态和动态障碍物。受罗非鱼和鸽子集体行为的启发，本研究的重点是引入一种自然启发式的多无人机系统无碰撞编队控制，同时考虑避障机动。本研究中开发的框架采用半分布式控制方法，其中基于概率Lloyd算法的集中式引导算法用于无人机的最佳定位，而分布式控制方法则用于车辆间碰撞和障碍物避障。此外，所提出的框架已通过新型3D机动的定义扩展到三维空间。最后，所提出的框架已应用于2D和3D场景下的多无人机系统，所得结果证明了所提出方法在存在静止和移动障碍物的动态环境中的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [97] [RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles](https://arxiv.org/abs/2507.00937)
> *RaGNNarok：一种轻量级图神经网络，用于增强无人地面车辆上的雷达点云*

*David Hunt, Shaocheng Luo, Spencer Hallyburton, Shafii Nillongo, Yi Li, Tingjun Chen, Miroslav Pajic* | **Category: cs.RO, cs.AR, cs.CV, cs.LG**

**Keywords:** 雷达点云增强, 图神经网络, 毫米波雷达, 室内移动机器人, 轻量级

**Comment:** 8 pages, accepted by IROS 2025

> **TL;DR:** RaGNNarok是一个轻量级GNN框架，用于增强雷达点云，解决了低成本室内移动机器人中雷达传感器的稀疏性、噪声和误检问题。

**AI_Comments:** RaGNNarok的创新之处在于将GNN应用于雷达点云增强，尤其是在资源受限的边缘设备上实现了极低的推理延迟，这对于低成本室内移动机器人至关重要。其在Raspberry Pi 5上的高效运行和在多任务、多环境下的泛化能力是其重要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 低成本室内移动机器人中，现有激光雷达和摄像头解决方案在视觉受阻环境表现不佳、数据处理计算开销大且成本高。毫米波雷达虽然成本低、重量轻且不受可见度影响，但其点云生成稀疏、噪声大且存在误检。

**Method:** 本文引入了RaGNNarok，这是一个实时、轻量级、可泛化的基于图神经网络（GNN）的框架，用于增强雷达点云，即使在复杂动态环境中也能运行。

**Result:** RaGNNarok在低成本Raspberry Pi 5上的推理时间仅为7.3毫秒，无需额外计算资源即可高效运行。在定位、SLAM和自主导航等关键任务中，在三种不同环境下表现出强大的可靠性和泛化能力。

**Conclusion:** RaGNNarok为低成本室内移动机器人提供了一个强大的解决方案，能够有效增强雷达点云，克服现有雷达系统的局限性。

> **ai_Abstract:** 本文提出了RaGNNarok，一个轻量级、实时且可泛化的图神经网络框架，旨在增强毫米波雷达点云，以克服现有雷达系统在稀疏性、噪声和误检方面的挑战。该框架在低成本硬件上表现出高效性，推理时间仅为7.3毫秒，并在定位、SLAM和自主导航任务中展现出强大的可靠性和泛化能力，为低成本室内移动机器人提供了一种稳健的解决方案。

> **摘要翻译:** 低成本室内移动机器人随着自动化在家居和商业空间中的日益普及而广受欢迎。然而，现有的基于激光雷达和摄像头的解决方案存在局限性，例如在视觉受阻环境中的性能不佳、数据处理的计算开销大以及激光雷达成本高昂。相比之下，毫米波雷达传感器提供了一种经济高效且轻量级的替代方案，无论可见度如何都能提供准确的测距。然而，现有的基于雷达的定位存在点云生成稀疏、噪声和误检等问题。因此，在这项工作中，我们引入了RaGNNarok，一个实时、轻量级、可泛化的基于图神经网络（GNN）的框架，用于增强雷达点云，即使在复杂动态环境中也能实现。RaGNNarok在低成本Raspberry Pi 5上的推理时间仅为7.3毫秒，即使在此类资源受限设备上也能高效运行，无需额外计算资源。我们在三种不同环境中评估了其在定位、SLAM和自主导航等关键任务中的性能。我们的结果表明其具有强大的可靠性和泛化能力，使RaGNNarok成为低成本室内移动机器人的一个稳健解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [110] [When Digital Twins Meet Large Language Models: Realistic, Interactive, and Editable Simulation for Autonomous Driving](https://arxiv.org/abs/2507.00319)
> *当数字孪生遇见大型语言模型：用于自动驾驶的逼真、交互式和可编辑模拟*

*Tanmay Vilas Samak, Chinmay Vilas Samak, Bing Li, Venkat Krovi* | **Category: cs.RO**

**Keywords:** 数字孪生, 大型语言模型, 自动驾驶, 模拟, 场景编辑

**Comment:** 

> **TL;DR:** 该研究提出了一个结合数字孪生和大型语言模型（LLM）的新框架，旨在为自动驾驶提供逼真、交互式和可编辑的模拟环境。该框架解决了现有模拟方法在动态保真度、照片级渲染、场景编排和实时性能方面的不足，实现了高精度场景重建和实时动态模拟，并允许通过自然语言提示灵活编辑驾驶场景。

**AI_Comments:** 本文通过将大型语言模型与数字孪生技术相结合，为自动驾驶模拟提出了一个创新方法。通过自然语言提示编辑场景的能力显著增强了模拟环境的交互性和灵活性，这相对于传统方法是一个显著的进步。所实现的高保真度和实时性能对于自动驾驶的开发和验证具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶模拟方法难以全面平衡动态保真度、照片级真实感渲染、上下文相关场景编排和实时性能等以自主性为导向的需求。

**Method:** 本文提出了一个统一的框架，用于创建和管理高保真数字孪生。该框架结合了基于物理和数据驱动的技术，能够以几何和照片级真实感精度重建真实世界场景和资产（real2sim），并赋予其物理属性以实现实时动态模拟。此外，它还集成了一个大型语言模型（LLM）接口，允许通过自然语言提示在线灵活编辑驾驶场景。

**Result:** 该框架能够以高达97%的结构相似度重建3D场景和资产，同时保持帧率在60 Hz以上。它还可以通过自然语言提示生成多样化的驾驶场景，重复性高达95%，泛化性高达85%。

**Conclusion:** 所提出的框架通过提供一个高保真、实时且可交互编辑的模拟环境，成功解决了现有自动驾驶模拟方法的局限性，并利用了数字孪生和大型语言模型的优势。

> **ai_Abstract:** 本文介绍了一个新颖的统一框架，该框架结合了高保真数字孪生与大型语言模型（LLM），旨在为自动驾驶创建逼真、交互式和可编辑的模拟环境。针对现有方法在保真度、渲染、场景编排和实时性能方面的局限性，该框架利用物理和数据驱动技术进行准确的真实世界场景重建和实时动态模拟。其关键创新在于集成了LLM接口，使得通过自然语言提示能灵活编辑场景。评估结果显示，该框架在结构相似性上高达97%，能保持60 Hz以上的帧率，并能有效生成场景，重复性达95%，泛化性达85%。

> **摘要翻译:** 模拟框架一直是自动驾驶系统开发和验证的关键推动者。然而，现有方法难以全面解决以自主性为导向的平衡要求：(i) 动态保真度，(ii) 照片级真实感渲染，(iii) 上下文相关场景编排，以及 (iv) 实时性能。为了解决这些限制，我们提出了一个统一的框架，用于创建和管理高保真数字孪生，以加速自动驾驶研究的进展。我们的框架利用物理驱动和数据驱动技术的结合，开发和模拟自动驾驶车辆及其操作环境的数字孪生。它能够以几何和照片级真实感精度重建真实世界场景和资产（real2sim），并赋予它们各种物理属性，以实现后续驾驶场景的实时动态模拟。此外，它还集成了大型语言模型（LLM）接口，可以通过自然语言提示在线灵活编辑驾驶场景。我们分析了所提出的框架在保真度、性能和服务能力方面的表现。结果表明，我们的框架可以以高达97%的结构相似性重建3D场景和资产，同时保持帧率在60 Hz以上。我们还证明它可以通过自然语言提示生成多样化的驾驶场景，重复性高达95%，泛化性高达85%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [134] [Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding](https://arxiv.org/abs/2507.00416)
> *Evo-0：具有隐式空间理解的视觉-语言-动作模型*

*Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Bo Zhao* | **Category: cs.RO, cs.CV**

**Keywords:** 视觉-语言-动作模型, 空间理解, 隐式3D特征, 即插即用模块, 机器人

**Comment:** 

> **TL;DR:** Evo-0引入了一个即插即用模块，通过利用现成的视觉几何基础模型，将隐式3D几何特征注入视觉-语言-动作（VLA）模型，显著提高了其空间理解能力，无需显式3D输入。

**AI_Comments:** 这项工作提出了一种新颖且高效的方法来解决VLA模型中长期存在的空间理解不足问题。其创新之处在于采用“隐式”注入3D几何特征，并通过一个“即插即用”模块实现，大大降低了对额外硬件或复杂3D数据处理的需求，提高了模型的通用性和实用性。这对于推动通用机器人技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型，尽管在语义理解方面表现出色，但由于主要基于2D图像-文本对进行训练，缺乏精确的空间理解能力。同时，通过显式3D输入（如点云或深度图）来解决这一问题需要额外的深度传感器或复杂的估计。

**Method:** 本研究引入了一个即插即用的模块，通过利用现成的视觉几何基础模型，将隐式3D几何特征注入到视觉-语言-动作（VLA）模型中。为了验证方法的有效性，设计了五个需要精确空间理解能力的空间挑战性任务。

**Result:** 广泛的评估表明，该方法显著提高了最先进的视觉-语言-动作（VLA）模型在不同场景下的性能。

**Conclusion:** 通过即插即用模块隐式注入3D几何特征，可以有效提升视觉-语言-动作（VLA）模型的空间理解能力，无需依赖显式3D输入或额外的传感器。

> **ai_Abstract:** 本论文提出Evo-0，一个创新的视觉-语言-动作（VLA）模型，旨在解决现有VLA模型在空间理解上的局限性。通过引入一个即插即用模块，该模型能够隐式地将3D几何特征注入到VLA中，而无需依赖额外的3D传感器或显式3D输入。实验结果表明，该方法在多个空间挑战性任务中显著提升了最先进VLA模型的性能。

> **摘要翻译:** 视觉-语言-动作（VLA）模型已成为一种有前景的框架，能够使通用机器人感知、推理并在现实世界中行动。这些模型通常建立在预训练的视觉-语言模型（VLM）之上，后者由于大规模文本预训练而在语义理解方面表现出色。然而，VLM通常缺乏精确的空间理解能力，因为它们主要在没有3D监督的2D图像-文本对上进行调整。为了解决这一限制，最近的方法已经整合了显式3D输入，如点云或深度图，但这需要额外的深度传感器或有缺陷的估计。相比之下，我们的工作引入了一个即插即用模块，通过利用现成的视觉几何基础模型，将隐式3D几何特征注入到VLA模型中。我们设计了五个需要精确空间理解能力的空间挑战性任务来验证我们方法的有效性。广泛的评估表明，我们的方法显著提高了最先进的VLA模型在不同场景下的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [155] [RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation](https://arxiv.org/abs/2507.00435)
> *RoboEval：机器人操作 meets 结构化和可扩展评估*

*Yi Ru Wang, Carter Ung, Grant Tannert, Jiafei Duan, Josephine Li, Amy Le, Rishabh Oswal, Markus Grotz, Wilbert Pumacay, Yuquan Deng, Ranjay Krishna, Dieter Fox, Siddhartha Srinivasa* | **Category: cs.RO, cs.AI, cs.CV**

**Keywords:** 机器人操作, 评估, 双臂操作, 基准测试, 仿真

**Comment:** Project page: https://robo-eval.github.io

> **TL;DR:** RoboEval是一个新的仿真基准和评估框架，旨在通过细粒度诊断指标和分层任务揭示双臂操作策略的局限性，超越传统的二元成功率评估。

**AI_Comments:** RoboEval的创新之处在于其超越传统二元成功率评估的结构化和可扩展框架。通过引入分层任务、细粒度诊断指标和人类演示，它能够更深入地揭示机器人操作策略的潜在弱点和执行差异。这对于理解和改进复杂机器人技能至关重要，特别是双臂操作。该工具的提出强调了评估方法在机器人领域发展中的关键作用，并为未来的研究提供了更精细的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试通常只报告二元任务成功率，这掩盖了策略行为中的关键弱点（如协调性差、抓取时打滑或手臂使用不对称），因此需要一个更结构化和可扩展的评估框架来揭示这些限制。

**Method:** 本文提出了RoboEval，一个仿真基准和结构化评估框架，用于揭示当前双臂操作策略的局限性。它引入了一套分层、语义化的任务，这些任务被分解为特定技能的阶段，并包含系统性挑战空间、物理和协调能力的变体。任务与细粒度诊断指标和3000多个人类演示配对，以支持模仿学习。

**Result:** 实验表明，具有相似成功率的策略在任务执行方式上存在差异，有些策略在对齐方面遇到困难，有些则在时间上一致的双臂控制方面遇到困难。研究发现，行为指标在超过一半的任务-指标对中与成功率相关，并且即使在二元成功率饱和时仍具有信息量。

**Conclusion:** RoboEval通过精确指出策略何时以及如何失败，使得对机器人操作有更深入、更具可操作性的理解，并强调了需要超越单纯成功率的评估工具。

> **ai_Abstract:** RoboEval是一个新的仿真基准和评估框架，旨在解决现有机器人操作评估仅依赖二元成功率的不足。它通过引入分层、语义化的任务和细粒度诊断指标，系统性地挑战空间、物理和协调能力，并提供人类演示以支持模仿学习。实验证明，RoboEval能够揭示策略行为中的细微差异和潜在弱点，即使在二元成功率相似的情况下，也能提供更深入、更具可操作性的理解，从而推动机器人操作评估超越简单的成功与否。

> **摘要翻译:** 我们提出了RoboEval，一个旨在揭示当前双臂操作策略局限性的仿真基准和结构化评估框架。虽然之前的基准测试只报告二元任务成功率，但我们发现此类指标常常掩盖了策略行为中的关键弱点——例如协调性差、抓取时打滑或手臂使用不对称。RoboEval引入了一套分层、语义化的任务，这些任务被分解为特定技能的阶段，并包含系统性挑战空间、物理和协调能力的变体。任务与细粒度诊断指标和3000多个以上的人类演示配对，以支持模仿学习。我们的实验表明，具有相似成功率的策略在任务执行方式上存在差异——有些策略在对齐方面遇到困难，另一些则在时间上一致的双臂控制方面遇到困难。我们发现，行为指标在超过一半的任务-指标对中与成功率相关，并且即使在二元成功率饱和时仍具有信息量。通过精确指出策略何时以及如何失败，RoboEval使得对机器人操作有更深入、更具可操作性的理解——并强调了需要超越单纯成功率的评估工具。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [193] [DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing](https://arxiv.org/abs/2507.00446)
> *DIJE：用于鲁棒机器人自我识别和视觉伺服的密集图像雅可比估计*

*Yasunori Toshimitsu, Kento Kawaharazuka, Akihiro Miki, Kei Okada, Masayuki Inaba* | **Category: cs.RO**

**Keywords:** 图像雅可比, 视觉伺服, 自我识别, 光流, 卡尔曼滤波

**Comment:** 2022 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)

> **TL;DR:** 本文提出了DIJE算法，一种基于光流和卡尔曼滤波的实时像素级图像雅可比估计方法，无需标记或机器人结构知识。DIJE被用于机器人自我识别和视觉伺服控制，并在物理机器人上验证了其性能。

**AI_Comments:** DIJE的创新之处在于其无需标记和机器人结构知识的实时像素级图像雅可比估计能力，这大大提高了机器人自我识别和视觉伺服的鲁棒性和通用性。其结合光流和卡尔曼滤波的方法在计算效率和准确性之间取得了平衡，为机器人与现实世界的交互提供了一种新颖且实用的解决方案。该研究的重要性在于为未来的通用机器人操作框架奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 为了让机器人在现实世界中移动，它们必须正确理解自身身体和所持工具的状态。现有方法可能依赖标记或机器人结构知识，限制了其通用性。

**Method:** 本文提出了DIJE（Dense Image Jacobian Estimation）算法，用于估计每个像素的图像雅可比。该算法基于光流计算和简化的卡尔曼滤波器，可以实时高效地在整个图像上运行。它不依赖于标记，也不需要机器人结构的知识。

**Result:** DIJE被应用于机器人自我识别过程，即使在运动重叠的情况下，也能鲁棒地区分机器人自身运动和外部实体的运动。此外，基于DIJE的视觉伺服控制器能够学习控制机器人身体进行抓取动作或双臂工具尖端控制。这些算法已在物理肌肉骨骼机器人上实现并验证了性能。

**Conclusion:** 作者认为，这种对视觉运动策略的全局估计有潜力扩展到更通用的操作框架中。

> **ai_Abstract:** 本研究提出DIJE，一种用于机器人自我识别和视觉伺服的密集图像雅可比估计算法。DIJE利用光流和简化的卡尔曼滤波器，实现了无需标记或机器人结构知识的实时像素级雅可比估计。该算法在自我识别中能有效区分机器人自身与外部运动，并支持基于DIJE的视觉伺服控制器进行精确的机器人本体控制和工具尖端操作。实验在物理肌肉骨骼机器人上验证了其有效性，并展望了其在通用操作框架中的应用潜力。

> **摘要翻译:** 为了让机器人在现实世界中移动，它们必须首先正确理解自身身体和所持工具的状态。在这项研究中，我们提出了DIJE，一种估计每个像素图像雅可比的算法。它基于光流计算和简化的卡尔曼滤波器，可以实时高效地在整个图像上运行。它不依赖于标记，也不需要机器人结构的知识。我们将DIJE应用于自我识别过程，即使在运动重叠的情况下，也能鲁棒地区分机器人自身运动和外部实体的运动。我们还提出了一种基于DIJE的视觉伺服控制器，它可以学习控制机器人身体进行抓取动作或双臂工具尖端控制。所提出的算法在物理肌肉骨骼机器人上实现并验证了其性能。我们相信，这种对视觉运动策略的全局估计有潜力扩展到更通用的操作框架中。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [194] [Edge Computing and its Application in Robotics: A Survey](https://arxiv.org/abs/2507.00523)
> *边缘计算及其在机器人领域的应用：一项调查*

*Nazish Tahir, Ramviyas Parasuraman* | **Category: cs.RO, cs.DC, cs.NI**

**Keywords:** 边缘计算, 机器人, 综述, 实时处理, 人工智能应用

**Comment:** 

> **TL;DR:** 该论文调查了边缘计算在机器人领域的应用，弥补了现有文献中缺乏全面综述的空白，并深入分析了其动机、挑战和未来方向。

**AI_Comments:** 该论文作为一篇综述，填补了边缘计算在机器人领域应用方面全面分析的空白，为研究人员和行业从业者提供了宝贵的参考。其重要性在于系统梳理了现有工作，并明确指出了未来的研究挑战，有助于推动该领域的进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管边缘计算与机器人技术结合的优势众多，但目前缺乏一篇全面审视这些益处的最新综述。本论文旨在填补这一空白。

**Method:** 本论文通过突出边缘机器人领域的重要工作、审视最新进展，并深入探讨当前和新兴解决方案背后的挑战与动机，对边缘机器人领域的最新发展进行了全面评估，重点关注基本应用，并深入分析了该快速发展领域中的关键动机、挑战和未来方向。它还探讨了边缘计算在需要快速响应时间的真实世界机器人场景中的重要性，并概述了边缘机器人领域中各种开放的研究挑战。

**Result:** 本论文提供了边缘机器人领域最新发展的全面评估，强调了基本应用，并深入分析了关键动机、挑战和未来方向。它还探讨了边缘计算在需要快速响应时间的真实世界机器人场景中的重要性，并概述了边缘机器人领域中各种开放的研究挑战。

**Conclusion:** 本论文对边缘机器人领域的最新发展进行了全面评估，深入分析了关键动机、挑战和未来方向，并指出了该领域开放的研究挑战。

> **ai_Abstract:** 本调查论文全面探讨了边缘计算在机器人领域的应用，旨在弥补现有文献中缺乏对边缘机器人优势全面综述的空白。论文深入分析了边缘计算如何通过提供低延迟、移动性和位置感知能力来支持时间敏感的机器人应用和AI部署。它重点介绍了边缘机器人领域的重要工作和最新进展，并探讨了该领域的关键动机、挑战以及未来的研究方向和开放性问题。

> **摘要翻译:** 近年来，边缘计算范式在学术界和工业界都获得了显著的关注。通过在机器人技术中实现边缘计算设施和服务，它成为将人工智能应用部署到机器人中的关键推动者。时间敏感的机器人应用受益于边缘计算范式提供的低延迟、移动性和位置感知能力，这使得在网络边缘进行实时数据处理和智能成为可能。尽管将边缘计算集成到机器人技术中的优势众多，但目前还没有一篇全面的最新综述来审视这些益处。本论文旨在弥补这一空白，通过突出边缘机器人领域的重要工作，审视最新进展，并对当前和新兴解决方案背后的挑战和动机提供更深入的见解。特别是，本文对边缘机器人领域的最新发展进行了全面评估，重点关注基本应用，深入分析了这一快速发展领域中的关键动机、挑战和未来方向。它还探讨了边缘计算在需要快速响应时间的真实世界机器人场景中的重要性。最后，本文概述了边缘机器人领域中各种开放的研究挑战。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [212] [A Miniature High-Resolution Tension Sensor Based on a Photo-Reflector for Robotic Hands and Grippers](https://arxiv.org/abs/2507.00464)
> *微型高分辨率光电反射式张力传感器，适用于机器人手和夹持器*

*Hyun-Bin Kim, Kyung-Soo Kim* | **Category: cs.RO**

**Keywords:** 张力传感器, 光电反射器, 机器人手, 高分辨率, 弹性体结构

**Comment:** 

> **TL;DR:** 本文提出了一种基于光电反射器的微型高分辨率张力传感器，适用于紧凑型机器人手和夹持器，实现了高精度测量并显著提高了分辨率。

**AI_Comments:** 该研究的创新点在于采用光电反射器测量近场位移，避免了传统光电中断器设计的局限性，并通过优化弹性体结构显著提高了传感器的分辨率和性能。其小型化、高精度和易于集成的特点使其在机器人和假肢领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 针对紧凑型肌腱驱动夹持器和机器人手对高分辨率张力传感器的需求。

**Method:** 该传感器采用基于Timoshenko梁理论和FEM分析设计的对称弹性体结构，结合光电反射器（VCNT2020）测量近场位移。信号采集通过16位ADC和CAN-FD通信实现。

**Result:** 传感器尺寸为13x7x6.5mm，可测量高达200N的拉力。分辨率达到9.9mN（超过14位精度），RMSE为0.455N。在力控制实验中，RMSE低至0.073N。与传统光电中断器相比，分辨率提高了十倍以上，并减少了非线性和迟滞。

**Conclusion:** 该设计的传感器机械简单、轻巧、易于组装，非常适合集成到需要高分辨率力反馈的机器人和假肢系统中。

> **ai_Abstract:** 本文介绍了一种用于机器人手和夹持器的微型高分辨率张力传感器。该传感器采用紧凑的光电反射器和特殊设计的弹性体结构，实现了高达200N的力测量，并具有9.9mN的高分辨率。实验证明其在精度和抗干扰性方面优于传统方法，且设计紧凑轻便，易于集成到机器人和假肢系统中。

> **摘要翻译:** 本文提出了一种使用光电反射器的微型张力传感器，专为紧凑型肌腱驱动夹持器和机器人手设计。所提出的传感器尺寸为13毫米 x 7毫米 x 6.5毫米，能够测量高达200牛顿的拉力。基于Timoshenko梁理论设计并经有限元分析验证的对称弹性体结构，包含圆角和挠性铰链，提高了灵敏度和机械耐用性，同时最大限度地减少了扭转变形。该传感器利用紧凑型光电反射器（VCNT2020）测量近场位移，无需光电中断器设计中所需的光吸收材料或几何修改。16位模数转换器（ADC）和CAN-FD（灵活数据速率）通信实现了高达5kHz采样速率的高效信号采集。校准实验表明，其分辨率为9.9毫牛（对应于超过14位精度），均方根误差（RMSE）为0.455牛顿。使用绞线驱动器和PI控制的力控制实验产生的RMSE低至0.073牛顿。与之前使用光电中断器的研究相比，所提出的方法在分辨率上提高了十倍以上，同时还降低了非线性和迟滞。该设计机械简单、轻巧、易于组装，适用于集成到需要高分辨率力反馈的机器人和假肢系统中。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [239] [Generation of Indoor Open Street Maps for Robot Navigation from CAD Files](https://arxiv.org/abs/2507.00552)
> *从CAD文件生成用于机器人导航的室内开放街道地图*

*Jiajie Zhang, Shenrui Wu, Xu Ma, Sören Schwertfeger* | **Category: cs.RO**

**Keywords:** CAD文件, 机器人导航, 室内地图, OpenStreetMap, AreaGraph

**Comment:** 8 pages, 8 figures

> **TL;DR:** 一个系统将CAD文件转换为分层OpenStreetMap，用于机器人导航，解决了SLAM在时间、劳动力和鲁棒性方面的局限性。

**AI_Comments:** 该论文的创新之处在于利用现有的CAD数据来克服SLAM在地图生成方面的局限性，提供了一种更鲁棒和可扩展的室内机器人导航地图解决方案。其多阶段管道、基于AreaGraph的拓扑分割以及语义丰富和多楼层合并的能力是其主要亮点，有望显著简化大型室内环境中机器人地图的部署和维护。

<details>
  <summary>Details</summary>

**Motivation:** 传统的SLAM地图生成方法在时间、劳动力和鲁棒性方面存在显著局限性，尤其是在动态、大规模室内环境中，地图过时可能导致严重的定位失败，从而影响机器人定位。

**Method:** 本文提出一个多阶段管道，首先从原始CAD数据中分离出关键结构层，然后采用基于AreaGraph的拓扑分割将建筑布局划分为可导航空间的分层图。该过程通过自动关联CAD源中的文本标签并统一合并多个楼层，形成一个统一的、拓扑正确的模型，从而生成全面且语义丰富的地图。

**Result:** 该系统生成了一个全面且语义丰富的地图，通过利用CAD文件中固有的永久结构信息，规避了SLAM的低效和脆弱性，为在复杂室内空间部署机器人提供了一个实用且可扩展的解决方案。该软件封装在一个直观的图形用户界面（GUI）中。

**Conclusion:** 通过利用CAD文件中固有的永久结构信息，该系统规避了SLAM的低效和脆弱性，为在复杂室内空间部署机器人提供了一个实用且可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种自动化系统，旨在将建筑CAD文件转换为分层拓扑OpenStreetMap（OSM），以实现鲁棒的机器人导航。该系统通过一个多阶段管道工作，首先从CAD数据中提取关键结构层，然后利用基于AreaGraph的拓扑分割将建筑布局划分为可导航空间的分层图。它通过自动关联文本标签并合并多楼层来增强地图的语义丰富性。该方法克服了传统SLAM在地图生成方面的局限性，为复杂室内环境中的机器人部署提供了一个实用且可扩展的解决方案，并提供了一个直观的图形用户界面。

> **摘要翻译:** 自主移动机器人的部署取决于环境地图的可用性，然而，通过SLAM（同步定位与建图）进行的传统地图生成在时间、劳动力和鲁棒性方面存在显著局限性，特别是在动态、大规模室内环境中，地图过时可能导致关键的定位失败。为了解决这些挑战，本文提出了一个完整且自动化的系统，用于将建筑计算机辅助设计（CAD）文件转换为分层拓扑开放街道地图（OSM）表示，专为稳健的终身机器人导航而定制。我们的核心方法涉及一个多阶段管道，首先从原始CAD数据中分离出关键结构层，然后采用基于AreaGraph的拓扑分割将建筑布局划分为可导航空间的分层图。此过程生成了一个全面且语义丰富的地图，并通过自动关联CAD源中的文本标签并统一合并多个建筑楼层为一个统一的、拓扑正确的模型而进一步增强。通过利用CAD文件中固有的永久结构信息，我们的系统规避了SLAM的低效和脆弱性，为在复杂室内空间部署机器人提供了一个实用且可扩展的解决方案。该软件封装在一个直观的图形用户界面（GUI）中，以方便实际使用。代码和数据集可在https://github.com/jiajiezhang7/osmAG-from-cad获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [252] [Stable Tracking of Eye Gaze Direction During Ophthalmic Surgery](https://arxiv.org/abs/2507.00635)
> *眼科手术中眼球凝视方向的稳定跟踪*

*Tinghe Hong, Shenlin Cai, Boyang Li, Kai Huang* | **Category: cs.RO, cs.CV, cs.HC**

**Keywords:** 眼科手术, 眼球凝视跟踪, 机器人辅助手术, 机器学习, 虹膜检测

**Comment:** Accepted by ICRA 2025

> **TL;DR:** 本文提出了一种结合机器学习和传统算法的眼球定位和跟踪方法，用于眼科手术中稳定估计眼球凝视方向，并驱动机械臂，解决了现有方法对额外传感器、遮挡和面部检测的依赖问题，实现了较低的估计误差。

**AI_Comments:** 这项研究通过结合机器学习和传统算法，提出了一种新颖的眼球凝视跟踪方法，成功解决了眼科手术环境中现有技术的局限性，如对额外传感器和面部检测的依赖以及遮挡问题。其创新点在于无需地标即可实现稳定的虹膜检测和凝视估计，并在实际应用中展示了高精度（眼球方向估计误差0.58度，机械臂控制误差2.08度），对于提升眼科手术机器人的自动化和精确导航具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的眼科手术机器人虽然在稳定性上有所提升，但术前导航仍依赖手动操作，缺乏一致性且不确定性高。目前的眼球凝视估计技术存在依赖额外传感器、手术环境中的遮挡问题以及需要面部检测的局限性。

**Method:** 本研究提出了一种结合机器学习和传统算法的创新性眼球定位和跟踪方法。该方法消除了对地标的需求，并在不同光照和阴影条件下保持稳定的虹膜检测和凝视估计。

**Result:** 提出的方法在眼球方向估计方面的平均误差为0.58度，在基于计算方向的机械臂运动控制方面的平均控制误差为2.08度。

**Conclusion:** 该研究提出的眼球定位和跟踪方法能够稳定、准确地估计眼球凝视方向，并有效驱动手术机械臂，克服了现有方法的局限性，提升了眼科手术导航的自动化和精确性。

> **ai_Abstract:** 本文提出一种结合机器学习和传统算法的眼球定位与跟踪方法，以解决眼科手术中现有凝视估计技术面临的传感器依赖、遮挡和面部检测等问题。该方法无需地标，能在不同光照下稳定检测虹膜并估计凝视，并成功应用于机械臂控制。实验结果显示，其在眼球方向估计和机械臂运动控制方面均表现出较低的平均误差。

> **摘要翻译:** 眼科手术机器人通过减少人类外科医生的自然手部颤抖，提供了卓越的稳定性和精确性，从而能够在狭窄的手术空间内进行精细操作。尽管在开发基于视觉和力的手术机器人控制方法方面取得了进展，但术前导航仍然严重依赖手动操作，这限制了一致性并增加了不确定性。现有手术中，无论是传统方法还是基于深度学习的眼球凝视估计技术都面临挑战，包括对额外传感器的依赖、手术环境中的遮挡问题以及对面部检测的要求。为了解决这些局限性，本研究提出了一种结合机器学习和传统算法的创新性眼球定位和跟踪方法，该方法消除了对地标的需求，并在不同光照和阴影条件下保持稳定的虹膜检测和凝视估计。广泛的真实世界实验结果表明，我们提出的方法在眼球方向估计方面的平均估计误差为0.58度，在基于计算方向的机械臂运动方面的平均控制误差为2.08度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [264] [Parallel Transmission Aware Co-Design: Enhancing Manipulator Performance Through Actuation-Space Optimization](https://arxiv.org/abs/2507.00644)
> *并行传动感知协同设计：通过执行空间优化提升机械手性能*

*Rohit Kumar, Melya Boukheddimi, Dennis Mronga, Shivesh Kumar, Frank Kirchner* | **Category: cs.RO**

**Keywords:** 协同设计, 并行机构, 执行空间优化, 机械手性能, 传动比

**Comment:** 

> **TL;DR:** 本文提出了一种新的协同设计方法，通过在执行空间中考虑并行耦合约束来显著提高机械臂的动态有效载荷能力。

**AI_Comments:** 本文的创新之处在于明确地将并行耦合约束纳入机器人动态模型，并利用执行空间进行轨迹优化，这对于包含并行机构的机器人系统性能提升具有重要意义。通过这种协同设计，成功解决了传统方法在处理并行机制时的局限性，并实现了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器人结构设计和行为优化是分开进行的，导致系统能力有限。尽管协同设计方法有所发展，但大多数实现都假设机器人是串联或树状模型，忽略了许多机器人平台包含并行机构的事实。

**Method:** 本文提出了一种新颖的协同设计方法，它将并行耦合约束明确地纳入机器人的动态模型中。该框架包含一个外部优化循环，专注于设计参数（例如并行带驱动机械手的传动比），将所需的扭矩从关节空间映射到执行空间；一个内部循环在执行空间中执行轨迹优化，从而利用机械手的整个动态范围。该方法与基于简化树状模型的传统协同设计方法进行了比较。

**Result:** 通过利用执行空间表示，本文提出的方法与传统协同设计实现相比，显著增加了动态有效载荷能力。

**Conclusion:** 通过将并行耦合约束纳入动态模型并在执行空间进行优化，本文提出的协同设计方法能够显著提升机械臂的性能，尤其是在动态有效载荷方面。

> **ai_Abstract:** 本文针对现有协同设计方法忽略机器人并行机构的问题，提出了一种新的并行传动感知协同设计方法。该方法将并行耦合约束明确纳入机器人动态模型，并通过外部循环优化设计参数（如传动比），内部循环在执行空间进行轨迹优化。实验结果表明，与传统方法相比，该方法能显著提升机械手的动态有效载荷能力。

> **摘要翻译:** 在机器人领域，结构设计和行为优化长期以来被视为独立的过程，导致开发出的系统能力有限。最近，协同设计方法变得流行起来，其中采用双层公式同时优化机器人设计和特定任务行为。然而，大多数实现都假设机器人是串联或树状模型，忽略了许多机器人平台包含并行机构的事实。在本文中，我们提出了一种新颖的协同设计方法，它将并行耦合约束明确地纳入机器人的动态模型中。在该框架中，一个外部优化循环专注于设计参数，在我们的案例中是并行带驱动机械手的传动比，它将所需的扭矩从关节空间映射到执行空间。一个内部循环在执行空间中执行轨迹优化，从而利用机械手的整个动态范围。我们将所提出的方法与基于简化树状模型的传统协同设计方法进行了比较。通过利用执行空间表示，我们的方法与传统的协同设计实现相比，显著增加了动态有效载荷能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [273] [Learning Steerable Imitation Controllers from Unstructured Animal Motions](https://arxiv.org/abs/2507.00677)
> *从非结构化动物运动中学习可操纵的模仿控制器*

*Dongho Kang, Jin Cheng, Fatemeh Zargarbashi, Taerim Yoon, Sungjoon Choi, Stelian Coros* | **Category: cs.RO**

**Keywords:** 腿式机器人, 模仿学习, 动物运动, 变分自编码器, 强化学习

**Comment:** The supplementary video is available at https://youtu.be/DukyUGNYf5A

> **TL;DR:** 本文提出了一种用于腿式机器人的控制框架，该框架利用非结构化动物运动数据生成类似动物且用户可操纵的行为，通过逆运动学和模型预测控制将动物数据转换为机器人兼容的数据库，然后使用变分自编码器合成模块捕获多样的步态模式并生成平滑过渡，最后通过强化学习反馈控制器在物理机器人上实现。该方法使四足机器人能够自适应地切换步态并准确跟踪用户速度指令，同时保持运动数据的风格一致性。

**AI_Comments:** 该论文的创新点在于其将非结构化动物运动数据转化为机器人可用的步态信息，并通过多阶段的控制框架实现了对多样步态的模仿以及用户可操纵性。结合了逆运动学、模型预测控制、变分自编码器和强化学习等多种技术，构建了一个端到端的解决方案，有效弥合了生物与机器人之间的形态和物理鸿沟。其重要性在于为腿式机器人实现更自然、更灵活的运动提供了新的途径，尤其是在真实世界应用中具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法难以让腿式机器人生成类似动物且用户可操纵的行为，尤其是在利用非结构化真实动物运动数据方面存在挑战。本文旨在解决这一问题，使机器人能够模仿动物的多种步态并响应用户指令。

**Method:** 1. 将动物运动数据通过约束逆运动学和模型预测控制转换为机器人兼容的数据库，以弥合动物与机器人之间的形态和物理差距。
2. 使用基于变分自编码器（VAE）的运动合成模块捕获运动数据库中多样的步态模式，并根据速度指令生成它们之间的平滑过渡。
3. 将生成的运动学运动作为参考，用于部署在物理机器人上的基于强化学习（RL）的反馈控制器。
4. 进行分组件评估以深入分析系统行为。

**Result:** 该方法使四足机器人能够自适应地切换步态，并准确跟踪用户速度指令，同时保持运动数据的风格一致性。此外，分组件评估证明了该方法在实现更准确、更可靠的运动模仿方面的有效性。

**Conclusion:** 本文提出的控制框架成功地利用非结构化动物运动数据，使腿式机器人能够生成类似动物且用户可操纵的行为，有效实现了步态多样性、指令跟踪和风格保持，并证明了其在运动模仿方面的有效性和可靠性。

> **ai_Abstract:** 本文提出了一种利用非结构化动物运动数据训练腿式机器人模仿控制器的框架。该框架首先通过逆运动学和模型预测控制将动物数据转换为机器人兼容格式，然后使用变分自编码器学习并合成多样的步态模式，并根据速度指令生成平滑过渡。最后，一个强化学习反馈控制器利用这些合成运动作为参考，使物理机器人能够自适应地切换步态、准确跟踪用户指令并保持运动风格。实验证明了该方法在实现准确可靠的运动模仿方面的有效性。

> **摘要翻译:** 本文提出了一种用于腿式机器人的控制框架，该框架利用非结构化真实世界动物运动数据生成类似动物且用户可操纵的行为。我们的框架学习在再现原始数据集中多样步态模式的同时遵循速度指令。首先，通过约束逆运动学和模型预测控制将动物运动数据转换为机器人兼容的数据库，从而弥合了动物与机器人之间的形态和物理差距。随后，一个基于变分自编码器的运动合成模块捕获了运动数据库中多样的运动模式，并响应速度指令生成它们之间的平滑过渡。由此产生的运动学运动作为部署在物理机器人上的基于强化学习的反馈控制器的参考。我们展示了这种方法使四足机器人能够自适应地切换步态并准确跟踪用户速度指令，同时保持运动数据的风格一致性。此外，我们提供了分组件评估，以深入分析系统行为，并证明了我们方法在更准确和可靠的运动模仿方面的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [282] [PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments](https://arxiv.org/abs/2507.00816)
> *PI-WAN：一种用于未知环境下四旋翼飞行器动力学预测的物理信息风自适应网络*

*Mengyun Wang, Bo Wang, Yifeng Niu, Chang Wang* | **Category: cs.RO, cs.AI**

**Keywords:** 四旋翼飞行器, 动力学预测, 物理信息网络, 风自适应, 未知环境

**Comment:** 

> **TL;DR:** PI-WAN结合物理信息和数据驱动方法，通过TCN和物理约束损失函数，显著提高了四旋翼飞行器在未知环境下的动力学预测精度和轨迹跟踪性能。

**AI_Comments:** 本文的创新之处在于成功地将物理约束与数据驱动模型（TCN）相结合，通过物理信息损失函数克服了传统方法在未知环境下的局限性，提高了模型的泛化能力和鲁棒性。这种混合方法为复杂系统在不确定环境下的建模提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统物理知识驱动建模方法在未知环境（如可变载荷、风扰动和外部扰动）下存在显著局限性；数据驱动建模方法在处理分布外（OoD）数据时泛化性差，限制了其在未知场景中的有效性。

**Method:** 本文引入了物理信息风自适应网络（PI-WAN），它通过将物理约束直接嵌入训练过程，结合了知识驱动和数据驱动建模方法，以实现鲁棒的四旋翼动力学学习。具体而言，PI-WAN采用时间卷积网络（TCN）架构来高效捕获历史飞行数据中的时间依赖性，同时利用物理信息损失函数应用物理原理，以提高模型在先前未见条件下的泛化性和鲁棒性。此外，将实时预测结果整合到模型预测控制（MPC）框架中，以提升闭环跟踪性能。

**Result:** 全面的仿真和实际飞行实验表明，PI-WAN在预测精度、跟踪精度和对未知环境的鲁棒性方面均优于基线方法。

**Conclusion:** PI-WAN通过成功结合物理信息和数据驱动方法，有效解决了四旋翼飞行器在未知环境下进行精确动力学建模和轨迹跟踪的挑战，并实现了卓越的性能。

> **ai_Abstract:** 本文提出PI-WAN，一个结合物理信息和数据驱动方法的网络，旨在解决四旋翼飞行器在未知环境下动力学建模的挑战。PI-WAN利用TCN捕获时间依赖性，并通过物理信息损失函数嵌入物理约束，显著提高了模型在未知环境下的泛化性和鲁棒性。结合MPC框架，PI-WAN在预测精度、跟踪精度和环境鲁棒性方面均超越了现有基线方法。

> **摘要翻译:** 精确的动力学建模对于四旋翼飞行器在各种应用中实现精确轨迹跟踪至关重要。传统的物理知识驱动建模方法在以可变载荷、风扰动和外部扰动为特征的未知环境中面临显著限制。另一方面，数据驱动建模方法在处理分布外（OoD）数据时泛化性差，限制了它们在未知场景中的有效性。为了解决这些挑战，我们引入了物理信息风自适应网络（PI-WAN），它通过将物理约束直接嵌入训练过程，结合了知识驱动和数据驱动建模方法，以实现鲁棒的四旋翼动力学学习。具体而言，PI-WAN采用时间卷积网络（TCN）架构，有效捕获历史飞行数据中的时间依赖性，同时物理信息损失函数应用物理原理，以提高模型在先前未见条件下的泛化性和鲁棒性。通过将实时预测结果整合到模型预测控制（MPC）框架中，我们实现了闭环跟踪性能的提升。全面的仿真和实际飞行实验表明，我们的方法在预测精度、跟踪精度以及对未知环境的鲁棒性方面优于基线方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [290] [HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning](https://arxiv.org/abs/2507.00833)
> *HumanoidGen: 通过大型语言模型推理进行双臂灵巧操作的数据生成*

*Zhi Jing, Siyuan Yang, Jicong Ao, Ting Xiao, Yugang Jiang, Chenjia Bai* | **Category: cs.RO, cs.AI**

**Keywords:** 人形机器人, 双臂灵巧操作, 数据生成, LLM推理, 蒙特卡洛树搜索

**Comment:** Project Page: https://openhumanoidgen.github.io

> **TL;DR:** HumanoidGen利用LLM推理自动化生成人形机器人双臂灵巧操作数据，以解决现有数据集不足的问题。

**AI_Comments:** HumanoidGen的创新之处在于结合了LLM推理和原子灵巧操作，自动化生成复杂的双臂灵巧操作数据，这对于推动人形机器人发展至关重要。该方法通过MCTS增强LLM规划能力，提高了数据生成的鲁棒性。其重要性体现在为人形机器人提供了急需的高质量训练数据，有望加速该领域的策略学习和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人数据集主要针对机械臂平台，但人形机器人（配备双臂和灵巧手）的模拟任务和高质量演示数据严重缺乏。双臂灵巧操作复杂，需要协调手臂运动和手部操作，难以自主收集数据。

**Method:** 本文提出了HumanoidGen，一个自动化任务创建和演示收集框架，利用原子灵巧操作和LLM推理生成关系约束。具体方法包括：为资产和灵巧手提供基于原子操作的空间标注；LLM规划器根据物体可供性和场景生成手臂运动的行动空间约束链；采用蒙特卡洛树搜索的变体增强LLM在长时任务和标注不足情况下的推理能力。

**Result:** 创建了一个带有增强场景的新基准来评估收集数据的质量。实验结果表明，2D和3D扩散策略的性能可以随着生成数据集的增加而提升。

**Conclusion:** HumanoidGen成功解决了人形机器人双臂灵巧操作数据不足的问题，并证明了其生成数据能够有效支持学习策略的性能提升。

> **ai_Abstract:** 本文提出了HumanoidGen，一个自动化任务创建和演示收集框架，旨在解决人形机器人双臂灵巧操作数据缺乏的问题。该框架利用原子灵巧操作和大型语言模型（LLM）推理生成关系约束，并通过空间标注和LLM规划器生成手臂运动的行动空间约束链。为应对长时任务和标注不足，HumanoidGen还引入了蒙特卡洛树搜索的变体来增强LLM的推理能力。实验结果表明，HumanoidGen生成的数据集能够有效提升2D和3D扩散策略的性能。

> **摘要翻译:** 对于机器人操作，现有的机器人数据集和模拟基准主要针对机械臂平台。然而，对于配备双臂和灵巧手的人形机器人，模拟任务和高质量演示数据明显缺乏。双臂灵巧操作本身更为复杂，因为它需要协调手臂运动和手部操作，这使得自主数据收集具有挑战性。本文提出了HumanoidGen，一个自动化任务创建和演示收集框架，它利用原子灵巧操作和大型语言模型（LLM）推理来生成关系约束。具体来说，我们基于原子操作为资产和灵巧手提供空间标注，并执行一个LLM规划器，根据物体可供性和场景生成一系列可操作的手臂运动空间约束。为了进一步提高规划能力，我们采用了一种蒙特卡洛树搜索的变体来增强LLM在长时任务和标注不足情况下的推理能力。在实验中，我们创建了一个具有增强场景的新基准来评估所收集数据的质量。结果表明，2D和3D扩散策略的性能可以随着生成数据集的增加而扩展。项目页面是https://openhumanoidgen.github.io。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [299] [I Move Therefore I Learn: Experience-Based Traversability in Outdoor Robotics](https://arxiv.org/abs/2507.00882)
> *我行故我学：室外机器人中基于经验的可通行性*

*Miguel Ángel de Miguel, Jorge Beltrán, Juan S. Cely, Francisco Martín, Juan Carlos Manzanares, Alberto García* | **Category: cs.RO**

**Keywords:** 可通行性估计, 经验学习, 室外机器人, 变分自编码器, BIRCH算法

**Comment:** 

> **TL;DR:** 一种新的基于经验的方法，使室外机器人能够自主学习地形的可通行性，无需大量预标记数据，并在各种机器人和场景中表现出卓越的适应性。

**AI_Comments:** 这篇论文的创新点在于其“基于经验”的学习范式，摆脱了对大量预标记数据集的依赖，这在实际应用中具有重要意义。通过结合VAE进行特征编码和BIRCH进行聚类，实现了高效且自适应的系统。其在不同类型机器人和多样地形上的泛化能力和适应性是其突出优势。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂环境中运行的室外机器人，其安全有效的导航需要准确的可通行性估计。

**Method:** 本文提出了一种新颖的基于经验的方法，使机器人能够根据先前的导航经验自主学习哪些地形是可通行的，而无需依赖大量的预标记数据集。该方法将高程和纹理数据整合到多层网格地图中，并使用在通用纹理数据集上训练的变分自编码器（VAE）进行处理。在初始遥操作阶段，机器人收集感官数据，这些经验被编码成紧凑的特征向量，并使用BIRCH算法进行聚类，以有效地表示可通行地形区域。在部署时，机器人将新的地形块与其学习到的特征簇进行比较，以实时评估可通行性。

**Result:** 所提出的方法不需要使用目标场景的数据进行训练，可以泛化到不同的表面和平台，并随着遇到新地形而动态适应。在合成基准和真实世界场景中对轮式和腿式机器人进行的广泛评估表明，与最先进的方法相比，该方法具有有效性、鲁棒性和卓越的适应性。

**Conclusion:** 本文提出了一种创新的基于经验的可通行性估计方法，该方法无需预标记数据，能够自主学习和适应新环境，并在各种室外机器人应用中展现出优越的性能和泛化能力。

> **ai_Abstract:** 本文提出了一种创新的基于经验的室外机器人可通行性估计方法，该方法无需预先标记的数据集，而是通过机器人自身的导航经验自主学习。它利用高程和纹理数据构建多层网格地图，并通过VAE和BIRCH算法处理和聚类经验数据。该方法在部署时能实时评估地形，并具有跨平台、跨场景的泛化能力和动态适应性，在多种机器人和真实场景中表现出优于现有方法的性能。

> **摘要翻译:** 准确的可通行性估计对于在复杂环境中运行的室外机器人进行安全有效的导航至关重要。本文介绍了一种新颖的基于经验的方法，该方法允许机器人根据先前的导航经验自主学习哪些地形是可通行的，而无需依赖大量的预标记数据集。该方法将高程和纹理数据整合到多层网格地图中，并使用在通用纹理数据集上训练的变分自编码器（VAE）进行处理。在初始遥操作阶段，机器人收集感官数据，同时在环境中移动。这些经验被编码成紧凑的特征向量，并使用BIRCH算法进行聚类，以有效地表示可通行地形区域。在部署时，机器人将新的地形块与其学习到的特征簇进行比较，以实时评估可通行性。所提出的方法不需要使用目标场景的数据进行训练，可以泛化到不同的表面和平台，并随着遇到新地形而动态适应。在合成基准和真实世界场景中对轮式和腿式机器人进行的广泛评估表明，与最先进的方法相比，该方法具有有效性、鲁棒性和卓越的适应性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [306] [A Survey: Learning Embodied Intelligence from Physical Simulators and World Models](https://arxiv.org/abs/2507.00917)
> *一项综述：从物理模拟器和世界模型中学习具身智能*

*Xiaoxiao Long, Qingrui Zhao, Kaiwen Zhang, Zihao Zhang, Dingrui Wang, Yumeng Liu, Zhengjie Shu, Yi Lu, Shouzheng Wang, Xinzhe Wei, Wei Li, Wei Yin, Yao Yao, Jia Pan, Qiu Shen, Ruigang Yang, Xun Cao, Qionghai Dai* | **Category: cs.RO**

**Keywords:** 具身智能, 物理模拟器, 世界模型, 通用人工智能, 机器人综述

**Comment:** https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey

> **TL;DR:** 本综述审视了如何利用物理模拟器和世界模型来训练具身人工智能，并强调了它们在实现鲁棒具身智能中的作用。

**AI_Comments:** 本综述通过关注物理模拟器和世界模型这两项基础技术，综合了具身人工智能这一关键领域的最新进展，因此具有重要意义。它强调了它们的互补性以及弥合模拟与现实之间差距的挑战，为研究人员提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能的进步已将具身智能置于机器人研究的前沿。具身智能需要代理能够在物理世界中感知、推理和行动，并能将抽象认知落地到现实世界互动中。物理模拟器和世界模型是实现这一目标的关键技术。

**Method:** 本综述系统地回顾了通过整合物理模拟器和世界模型来学习具身人工智能的最新进展。它分析了它们在增强智能机器人自主性、适应性和泛化能力方面的互补作用，并讨论了外部模拟和内部建模之间在弥合模拟训练与现实世界部署之间差距的相互作用。

**Result:** 本综述综合了当前进展，并指出了在利用物理模拟器和世界模型学习具身人工智能方面的开放挑战。它旨在为实现更强大和更具泛化能力的具身人工智能系统提供全面的视角。

**Conclusion:** 物理模拟器和世界模型对于开发鲁棒且可泛化的具身人工智能至关重要。本综述强调了它们的互补作用以及外部模拟与内部建模之间的相互作用，为具身人工智能指明了前进的道路。

> **ai_Abstract:** 本综述系统地审视了物理模拟器和世界模型在推进具身智能中的作用，具身智能是通用人工智能的关键领域。它分析了这两种技术——分别提供受控训练环境和内部预测表示——如何增强智能机器人的自主性、适应性和泛化能力。论文综合了当前进展，讨论了从模拟到现实的差距，并指出了开放挑战，旨在为开发更强大的具身人工智能系统提供全面的视角。

> **摘要翻译:** 对通用人工智能（AGI）的追求已将具身智能置于机器人研究的最前沿。具身智能侧重于能够在物理世界中感知、推理和行动的代理。实现鲁棒的具身智能不仅需要先进的感知和控制，还需要将抽象认知根植于现实世界的交互中。物理模拟器和世界模型这两项基础技术已成为实现这一追求的关键推动因素。物理模拟器为训练和评估机器人代理提供了受控、高保真度的环境，从而可以安全高效地开发复杂行为。相比之下，世界模型赋予机器人对其周围环境的内部表示，从而能够进行预测性规划和超越直接感官输入的自适应决策。本综述系统地回顾了通过整合物理模拟器和世界模型来学习具身人工智能的最新进展。我们分析了它们在增强智能机器人自主性、适应性和泛化能力方面的互补作用，并讨论了外部模拟和内部建模之间在弥合模拟训练与现实世界部署之间差距的相互作用。通过综合当前进展并识别开放挑战，本综述旨在为实现更强大和更具泛化能力的具身人工智能系统提供全面的视角。我们还维护了一个活跃的存储库，其中包含最新的文献和开源项目，网址为 https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [315] [Box Pose and Shape Estimation and Domain Adaptation for Large-Scale Warehouse Automation](https://arxiv.org/abs/2507.00984)
> *大规模仓库自动化中的箱体姿态和形状估计及域适应*

*Xihang Yu, Rajat Talak, Jingnan Shi, Ulrich Viereck, Igor Gilitschenski, Luca Carlone* | **Category: cs.RO, cs.CV, cs.LG**

**Keywords:** 自监督学习, 域适应, 姿态估计, 形状估计, 仓库自动化

**Comment:** 12 pages, 6 figures. This work will be presented at the 19th
  International Symposium on Experimental Robotics (ISER2025)

> **TL;DR:** 本文提出了一种自监督域适应管道，利用未标注的真实世界数据改进感知模型，用于箱体姿态和形状估计，并在大规模真实世界数据上表现出色，显著优于仅在模拟中训练的模型。

**AI_Comments:** 该论文的创新点在于提出了一个自监督的域适应管道，有效解决了现代仓库自动化中大量未标注数据的问题，显著降低了数据标注成本。其“纠正和认证”机制为自监督学习在实际工业应用中的可靠性提供了保障，具有重要的实践意义和推广价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代仓库自动化系统依赖智能机器人产生大量未标注数据。为了在不依赖手动标注的情况下提升感知模型，特别是在箱体姿态和形状估计方面，需要一种有效的方法来利用这些未标注数据。

**Method:** 本文开发了一种自监督域适应管道，利用真实世界、未标注的数据来改进感知模型，无需手动标注。具体地，它专注于箱体的姿态和形状估计，并提出了一个“纠正和认证”（correct-and-certify）的自监督箱体姿态和形状估计管道。

**Result:** 该自监督模型显著优于仅在模拟中训练的模型。与零样本3D边界框估计基线相比，它显示出实质性的改进。该方法在包括适应50,000张图像的大规模真实世界数据集在内的多种模拟和真实工业环境中得到了广泛评估。

**Conclusion:** 本文提出的自监督域适应管道能够有效利用未标注的真实世界数据，显著提升了大规模仓库自动化中箱体姿态和形状估计的感知模型性能。

> **ai_Abstract:** 本文提出了一种用于大规模仓库自动化的自监督域适应管道，旨在利用大量未标注的真实世界数据来提升感知模型，特别是针对箱体的姿态和形状估计。该方法通过一个“纠正和认证”的自监督管道，在不需要人工标注的情况下，显著提高了模型性能，并在包含50,000张图像的真实数据集上表现出优于仅模拟训练模型和零样本基线的优势。

> **摘要翻译:** 现代仓库自动化系统依赖于智能机器人群，这些机器人生成海量数据——其中大部分仍未标注。本文开发了一种自监督域适应管道，利用真实世界、未标注的数据来改进感知模型，而无需手动标注。我们的工作特别关注箱体的姿态和形状估计，并提出了一个用于自监督箱体姿态和形状估计的“纠正和认证”管道。我们广泛评估了我们的方法在各种模拟和真实工业环境中的表现，包括适应一个包含50,000张图像的大规模真实世界数据集。该自监督模型显著优于仅在模拟中训练的模型，并且比零样本3D边界框估计基线有实质性改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [322] [Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations](https://arxiv.org/abs/2507.00990)
> *机器人通过模仿生成视频进行操作，无需物理演示*

*Shivansh Patel, Shraddhaa Mohan, Hanlin Mai, Unnat Jain, Svetlana Lazebnik, Yunzhu Li* | **Category: cs.RO, cs.AI, cs.CV**

**Keywords:** 机器人操作, 模仿学习, 生成视频, 扩散模型, 6D姿态跟踪

**Comment:** Project Page: https://rigvid-robot.github.io/

> **TL;DR:** RIGVid系统使机器人能够通过模仿AI生成的视频来执行复杂操作任务，无需物理演示或机器人特定训练。

**AI_Comments:** 该工作的创新之处在于通过利用AI生成的视频，完全消除了机器人模仿学习中对物理演示的依赖，这极大地扩展了机器人学习的适用性和可扩展性。此外，与具体机器人无关的轨迹重新定位也是一个关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器人操纵任务需要物理演示或机器人特定训练，这限制了其应用。本工作旨在通过模仿AI生成的视频，使机器人无需物理演示或机器人特定训练即可执行复杂操纵任务。

**Method:** RIGVid系统首先接收语言命令和初始场景图像，然后视频扩散模型生成潜在演示视频。视觉-语言模型（VLM）过滤掉不符合命令的视频。接着，6D姿态跟踪器从视频中提取物体轨迹，并以与具体机器人无关的方式将轨迹重新定位到机器人上。

**Result:** 实验证明，经过过滤的生成视频与真实演示同样有效，并且性能随生成质量的提高而提高。依赖生成视频的性能优于使用VLM进行关键点预测等更紧凑的替代方案。强大的6D姿态跟踪优于密集特征点跟踪等其他轨迹提取方式。

**Conclusion:** 最先进的现成模型生成的视频可以为机器人操作提供有效的监督来源。

> **ai_Abstract:** RIGVid是一个创新系统，它使机器人能够通过模仿AI生成的视频来学习复杂操作任务，完全摆脱了对物理演示和机器人特定训练的需求。该系统利用视频扩散模型生成潜在演示，并通过视觉-语言模型进行过滤，然后使用6D姿态跟踪器提取轨迹并重新定位到机器人。实验证明，其性能与真实演示相当，并且优于其他替代方法，表明AI生成视频是机器人操作的有效监督来源。

> **摘要翻译:** 这项工作介绍了机器人模仿生成视频系统（RIGVid），该系统使机器人能够纯粹通过模仿AI生成的视频来执行复杂的操纵任务——例如倒水、擦拭和混合——而无需任何物理演示或机器人特定训练。给定一个语言命令和一张初始场景图像，视频扩散模型会生成潜在的演示视频，然后视觉-语言模型（VLM）会自动过滤掉不符合命令的结果。接着，6D姿态跟踪器从视频中提取物体轨迹，并将这些轨迹以与具体机器人无关的方式重新定位到机器人上。通过广泛的真实世界评估，我们表明过滤后的生成视频与真实演示一样有效，并且性能随生成质量的提高而提高。我们还表明，依赖生成视频优于更紧凑的替代方案，例如使用VLM进行关键点预测；并且强大的6D姿态跟踪优于其他轨迹提取方式，例如密集特征点跟踪。这些发现表明，最先进的现成模型生成的视频可以为机器人操作提供有效的监督来源。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [327] [DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation](https://arxiv.org/abs/2507.01008)
> *DexWrist：一种用于受限和动态操作的机器人手腕*

*Martin Peticco, Gabriella Ulloa, John Marangola, Pulkit Agrawal* | **Category: cs.RO**

**Keywords:** 机器人手腕, 顺应性操作, 数据收集, 策略学习

**Comment:** More details about the wrist can be found at: dexwrist.csail.mit.edu

> **TL;DR:** DexWrist 是一种顺应性机器人手腕，旨在改善受限环境中的操作、实现动态任务并加速数据收集。

**AI_Comments:** DexWrist 的创新之处在于其对人类手腕功能的高度模仿，结合了机械顺应性和更大的工作空间，这对于在复杂和受限环境中进行精细操作至关重要。其能够加速数据收集和简化策略学习的特性，对于推动机器人学习领域的发展具有重要意义。特别是其扭矩透明和易于模拟的特性，为模拟训练提供了便利，有助于弥补现实世界数据收集的成本和难度。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人手腕在高度受限环境中的操作、动态任务执行以及数据收集速度方面存在局限性。该研究旨在开发一种功能接近人类手腕的机器人手腕，以克服这些限制。

**Method:** 提出了 DexWrist，这是一种顺应性机器人手腕，通过实现机械顺应性和更大的工作空间来模拟人类手腕的功能。它通过以下方式增强策略学习：实现更快的远程操作、减少任务步骤以缩短轨迹长度、设计为扭矩透明且运动学易于模拟，以及扩展操作工作空间以应对杂乱场景。

**Result:** DexWrist 能够促进高度受限环境中的机器人操作，实现动态任务，并显著加速数据收集。它通过更快的远程操作、更少的任务步骤、易于模拟的运动学以及扩展的操作工作空间来增强策略学习。

**Conclusion:** DexWrist 是一种先进的机器人手腕，通过其独特的设计和功能，显著提升了机器人操作能力，尤其是在复杂和受限环境中，并能有效加速机器人学习的数据收集过程。

> **ai_Abstract:** 本文介绍了一种名为 DexWrist 的顺应性机器人手腕，旨在解决机器人操作在受限环境、动态任务执行和数据收集效率方面的挑战。DexWrist 模仿人类手腕的功能，提供了卓越的机械顺应性和更大的工作空间。它通过加速远程操作、简化任务执行、提供易于模拟的运动学以及扩展操作范围来显著提升策略学习的效率和能力。

> **摘要翻译:** 我们介绍了 DexWrist，这是一种柔顺机器人手腕，旨在推进在高度受限环境中的机器人操作，实现动态任务，并加速数据收集。DexWrist 的设计目标是接近人类手腕的功能能力，与现有机器人手腕设计相比，它实现了机械柔顺性和更大的工作空间。DexWrist 可以通过以下方式极大促进策略学习：(i) 实现更快的远程操作，从而使数据收集更具可扩展性；(ii) 以更少的步骤完成任务，从而减少轨迹长度，进而简化策略学习；(iii) DexWrist 被设计为扭矩透明，其运动学易于模拟，便于模拟数据收集；以及 (iv) 最重要的是，它扩展了操作的工作空间，以应对高度混乱的场景和任务。有关该手腕的更多详细信息可在以下网址找到：dexwrist.csail.mit.edu。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [335] [VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers](https://arxiv.org/abs/2507.01016)
> *VQ-VLA：通过扩展矢量量化动作分词器改进视觉-语言-动作模型*

*Yating Wang, Haoyi Zhu, Mingyu Liu, Jiange Yang, Hao-Shu Fang, Tong He* | **Category: cs.RO, cs.CV**

**Keywords:** 矢量量化, 动作分词器, 视觉-语言-动作模型, 大规模数据集, 机器人控制

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了一种基于矢量量化的动作分词器VQ-VLA，利用迄今为止最大规模的动作轨迹数据集（比以往方法多100倍的数据）进行训练。该分词器能加速推理，生成更平滑连贯的动作，并可零样本适应下游任务。研究发现合成数据与真实数据之间的领域差距很小，大量合成数据能显著提高真实世界任务性能，特别是在长周期场景下成功率提升高达30%。

**AI_Comments:** 本文的创新点在于构建了迄今为止最大规模的动作轨迹数据集（是现有方法的100多倍），并在此基础上开发了矢量量化动作分词器。一个重要的发现是合成数据与真实数据之间的领域差距很小，这使得利用大量合成数据进行训练成为可能，并显著提升了真实世界的性能，尤其在长周期任务上的30%成功率提升是其重要性的体现。这为未来机器人控制和具身智能系统的发展提供了新的方向和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进视觉-语言-动作（VLA）模型，特别是提高推理速度、生成更平滑连贯的动作输出，并捕获丰富的时空动态，同时解决现有方法数据量不足的问题。

**Method:** 本文提出了一种创新的基于矢量量化的动作分词器，该分词器建立在迄今为止最大规模的动作轨迹数据集之上，其数据量是现有方法的100多倍。该方法利用大量合成数据进行训练，并通过在模拟环境和真实机器人平台上进行广泛实验来验证其有效性。

**Result:** 该分词器不仅加速了推理，还生成了更平滑、更连贯的动作输出。研究发现合成动作轨迹与真实动作轨迹之间的领域差距很小，允许有效利用大量合成数据。随着合成轨迹数据量的增加，分词器在下游任务上的性能显著提高，特别是在两个真实世界的长周期任务中，成功率提高了30%。

**Conclusion:** 本文提出的动作分词器是一种强大且可扩展的解决方案，适用于实时具身智能系统，为在不同应用领域中实现更高效、更可靠的机器人控制铺平了道路。

> **ai_Abstract:** 本文提出了VQ-VLA，一种基于矢量量化的新型动作分词器，其训练数据量是现有方法的百倍以上，能捕捉丰富的时空动态。该分词器不仅能加速推理并生成更流畅连贯的动作，还能零样本适应多种下游任务。研究发现，合成数据与真实数据之间的领域差距微乎其微，使得大量合成数据能有效提升真实世界性能，尤其在长周期任务中可将成功率提高30%。这表明VQ-VLA是具身智能系统可靠且可扩展的解决方案，有助于实现高效的机器人控制。

> **摘要翻译:** 在本文中，我们介绍了一种创新的基于矢量量化的动作分词器，该分词器建立在迄今为止最大规模的动作轨迹数据集之上，其数据量是现有方法的100多倍。这个庞大的数据集使我们的分词器能够捕获丰富的时空动态，从而使模型不仅能加速推理，还能生成更平滑、更连贯的动作输出。一旦训练完成，该分词器可以无缝地以零样本方式适应各种下游任务，从短周期反应行为到长周期规划。我们工作的一个关键发现是，合成动作轨迹和真实动作轨迹之间的领域差距很小，这使我们能够在训练期间有效利用大量的合成数据，而不会损害真实世界的性能。为了验证我们的方法，我们在模拟环境和真实机器人平台上进行了广泛的实验。结果表明，随着合成轨迹数据量的增加，我们的分词器在下游任务上的性能显著提高——最显著的是，在两个真实世界的长周期任务中，成功率提高了30%。这些发现突出了我们的动作分词器作为实时具身智能系统的一个强大且可扩展的解决方案的潜力，为在不同应用领域中实现更高效、更可靠的机器人控制铺平了道路。项目网站：https://xiaoxiao0406.github.io/vqvla.github.io

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [14] [Moment Sampling in Video LLMs for Long-Form Video QA](https://arxiv.org/abs/2507.00033)
> *视频LLM中的时刻采样用于长视频问答*

*Mustafa Chasmai, Gauri Jagatap, Gouthaman KV, Grant Van Horn, Subhransu Maji, Andrea Fanelli* | **Category: cs.CV, cs.AI, cs.CL**

**Keywords:** 视频LLM, 长视频问答, 时刻采样, 帧采样, 时刻检索

**Comment:** Workshop on Video Large Language Models (VidLLMs) at CVPR 2025

> **TL;DR:** 提出一种“时刻采样”方法，利用文本到视频时刻检索模型指导帧采样，以提高视频LLM在长视频问答中的性能，解决传统帧子采样的问题。

**AI_Comments:** 这篇论文的创新点在于将“时刻检索”的概念引入到视频LLM的帧采样过程中，以解决长视频问答中关键信息丢失和冗余帧的问题。通过动态选择与问题相关的帧，而不是简单的固定间隔采样，显著提高了模型的效率和准确性，对于扩展Video LLMs处理长视频的能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频LLMs在短视频上表现良好，但在长视频的远距离推理中表现不佳。常用的帧子采样方法次优，会导致关键帧丢失或冗余信息，影响准确性并增加计算消耗。

**Method:** 提出“时刻采样”方法，这是一种模型无关的新方法。该方法利用通用的文本到视频时刻检索模型来指导帧采样过程，特别是使用轻量级时刻检索模型优先选择与问题上下文最相关的帧。

**Result:** 通过在四个长视频问答数据集上，使用四个最先进的视频LLMs进行广泛实验，证明了所提出方法的有效性。

**Conclusion:** 所提出的“时刻采样”方法通过关注与给定问题最相关的帧，增强了视频LLM在长视频问答中的性能。

> **ai_Abstract:** 本文针对视频大型语言模型 (Video LLMs) 在长视频问答 (VideoQA) 中长距离推理能力不足的问题，提出了“时刻采样”这一新颖的模型无关方法。该方法利用文本到视频时刻检索模型指导帧采样过程，通过优先选择与问题上下文最相关的关键帧，避免了传统帧子采样导致的关键帧丢失和冗余信息问题，从而有效提升了Video LLMs在长视频问答任务上的性能。实验结果在多个数据集和模型上验证了其有效性。

> **摘要翻译:** 视频大型语言模型 (Video LLMs) 的最新进展显著推动了视频问答 (VideoQA) 领域的发展。虽然现有方法在短视频上表现良好，但它们在长视频的远距离推理中常常遇到困难。为了使视频LLM适用于更长的视频内容，通常采用帧子采样（以固定间隔选择帧）。然而，这种方法并非最优，常常导致关键帧的丢失或包含来自多个相似帧的冗余信息。丢失关键帧会损害模型准确回答问题的能力，而冗余帧则会导致模型关注不相关的视频片段并增加计算资源消耗。在本文中，我们研究了使用通用文本到视频时刻检索模型来指导帧采样过程。我们提出了“时刻采样”，这是一种新颖的、与模型无关的方法，它使模型能够根据问题的上下文选择最相关的帧。具体来说，我们采用轻量级时刻检索模型来优先选择帧。通过关注与给定问题最相关的帧，我们的方法增强了视频LLM在长视频问答中的性能。通过在四个长视频问答数据集上，使用四个最先进的视频LLM进行广泛实验，我们证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [30] [Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay](https://arxiv.org/abs/2507.00042)
> *灾难性遗忘缓解通过差异加权经验回放*

*Xinrun Xu, Jianwen Yang, Qiuhong Zhang, Zhanbiao Lian, Zhiming Ding, Shan Jiang* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 灾难性遗忘, 经验回放, 域适应, 目标检测, 云边协同

**Comment:** ICANN 2025

> **TL;DR:** 本文提出ER-EMU算法，利用基于域距离度量的经验选择（DDM-ES）和FIFO缓冲区，通过优先选择与当前域差异最大的历史数据来缓解云边协同目标检测中的灾难性遗忘问题，并在交通视频数据集上表现出优越性。

**AI_Comments:** 该论文创新性地将域距离度量（MK-MMD）引入经验回放机制，通过选择与当前域差异最大的历史数据，有效解决了灾难性遗忘问题，并提高了数据利用效率。这种方法在动态且数据分布不断变化的边缘AI部署场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在云边协同目标检测中，边缘模型在适应新数据分布时会遭受灾难性遗忘，导致模型失去先前学到的知识。尤其在动态交通环境中，过去知识仍然有价值。现有方法如经验回放和视觉提示无法有效优先处理和利用历史数据，简单存储和回放所有数据效率低下，且忽视了历史经验的不同重要性。

**Method:** 本文提出ER-EMU，一种基于自适应经验回放的边缘模型更新算法。它使用有限大小的FIFO经验缓冲区，并通过一种新颖的基于域距离度量的经验选择（DDM-ES）算法进行管理。DDM-ES利用多核最大均值差异（MK-MMD）量化目标域之间的不相似性，优先选择与当前目标域差异最大的历史数据，以确保训练多样性并促进知识保留。经验缓冲区还通过简单随机采样更新，以保持对先前域的平衡表示。

**Result:** 在贝尔维尤交通视频数据集（涉及重复的昼夜循环）上的实验表明，ER-EMU持续改进了几种最先进的云边协同目标检测框架的性能。

**Conclusion:** ER-EMU能够有效缓解云边协同目标检测中的灾难性遗忘问题，并通过智能地选择历史经验来提高模型在动态环境下的适应性和知识保留能力。

> **ai_Abstract:** 本文提出ER-EMU算法，旨在解决云边协同目标检测中边缘模型面临的灾难性遗忘问题。针对现有经验回放方法效率低下且未能有效利用历史数据的问题，ER-EMU采用FIFO缓冲区和新颖的DDM-ES算法。DDM-ES利用MK-MMD度量域间差异，优先选择与当前域差异大的历史数据进行回放，从而在有限缓冲区内实现训练多样性，防止过拟合，并有效保留知识。实验结果表明，ER-EMU显著提升了现有云边协同目标检测框架在动态交通环境下的性能。

> **摘要翻译:** 在云边协同目标检测中，持续适应边缘模型以进行交通监控会遭受灾难性遗忘，即模型在适应新的数据分布时会丢失先前学到的知识。这在以周期性变化（例如，白天/夜晚、高峰时段）为特征的动态交通环境中尤其成问题，因为过去的知识仍然很有价值。现有的方法，如经验回放和视觉提示，提供了一些缓解措施，但难以有效优先处理和利用历史数据以实现最佳的知识保留和适应。具体来说，简单地存储和回放所有历史数据可能效率低下，而将所有历史经验视为同等重要则忽略了它们与当前域的不同相关性。本文提出了ER-EMU，一种基于自适应经验回放的边缘模型更新算法，以解决这些限制。ER-EMU利用一个使用先进先出（FIFO）原则管理的有限大小的经验缓冲区，以及一种新颖的基于域距离度量的经验选择（DDM-ES）算法。DDM-ES采用多核最大均值差异（MK-MMD）来量化目标域之间的不相似性，优先选择与当前目标域差异最大的历史数据。这确保了训练多样性并促进了更广泛的过去经验的知识保留，同时还防止了对新域的过拟合。经验缓冲区还使用简单的随机采样策略进行更新，以保持对先前域的平衡表示。在贝尔维尤交通视频数据集（涉及重复的昼夜循环）上的实验表明，ER-EMU持续改进了几种最先进的云边协同目标检测框架的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [50] [MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations](https://arxiv.org/abs/2507.00043)
> *MR-CLIP：高效的元数据引导的MRI对比度表示学习*

*Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso* | **Category: cs.CV, cs.AI**

**Keywords:** MRI对比度, 元数据, 对比学习, DICOM, 表示学习

**Comment:** 

> **TL;DR:** 本文提出了MR-CLIP，一个多模态对比学习框架，通过将MRI图像与DICOM元数据对齐，在没有手动标签的情况下学习对比度感知表示，有效解决了MRI对比度识别中元数据缺失和不一致的问题。

**AI_Comments:** MR-CLIP的创新之处在于其利用多模态对比学习，将MRI图像与DICOM元数据直接对齐，从而在没有手动标签的情况下学习对比度表示。这解决了真实世界临床数据中元数据质量差和标签缺失的痛点，对于实现鲁棒的对比度感知表示和推动模态不变性、数据协调等高级临床应用具有重要意义。其公开代码和权重也方便了研究复现和后续开发。

<details>
  <summary>Details</summary>

**Motivation:** 临床系统中MRI图像的准确解释依赖于对图像对比度的精确理解，但对比度信息（如采集参数）存储在DICOM元数据中，而这些元数据常常不完整、有噪声或不一致，且常用的粗略标签（如T1/T2加权）在许多真实世界数据集中缺失。缺乏可靠和标准化的元数据使得图像解释、检索和整合到临床工作流程中变得复杂，也阻碍了高级临床应用如模态不变表示和数据协调的实现。

**Method:** 本文提出了MR-CLIP，一个多模态对比学习框架。该框架通过将MR图像与其DICOM元数据对齐，来学习对比度感知表示，且无需依赖手动标签。MR-CLIP在涵盖多种扫描仪和协议的多样化临床数据集上进行训练。

**Result:** MR-CLIP成功捕获了跨采集和扫描内的对比度变化，实现了与解剖结构无关的表示。其有效性在跨模态检索和对比度分类任务中得到了验证，并展现了其可扩展性和在未来临床应用中的潜力。

**Conclusion:** MR-CLIP提供了一种无需手动标签即可从MRI图像和DICOM元数据中学习有效对比度感知表示的方法，解决了现有元数据挑战，并为更高级的临床应用奠定了基础。

> **ai_Abstract:** 本文提出了MR-CLIP，一个多模态对比学习框架，旨在解决MRI图像对比度识别中元数据缺失、不完整和不一致的挑战。MR-CLIP通过将MR图像与DICOM元数据对齐，无需手动标签即可学习对比度感知表示。该方法在多样化的临床数据集上训练，能捕获对比度变化并实现解剖结构无关的表示，并在跨模态检索和对比度分类任务中展现了其有效性和潜力。

> **摘要翻译:** 在临床系统中，对磁共振成像（MRI）扫描的准确解释基于对图像对比度的精确理解。这种对比度主要由采集参数（例如回波时间、重复时间）控制，这些参数存储在DICOM元数据中。为了简化对比度识别，通常使用诸如T1加权或T2加权等宽泛标签，但这些标签仅提供了对底层采集设置的粗略近似。在许多真实世界数据集中，此类标签完全缺失，使得原始采集参数成为对比度的唯一指示。除了这一挑战，可用的元数据通常不完整、有噪声或不一致。缺乏可靠和标准化的元数据使图像解释、检索和整合到临床工作流程中变得复杂。此外，鲁棒的对比度感知表示对于实现更高级的临床应用（例如实现模态不变表示和数据协调）至关重要。为了解决这些挑战，我们提出了MR-CLIP，一个多模态对比学习框架，它将MR图像与其DICOM元数据对齐，以学习对比度感知表示，而无需依赖手动标签。MR-CLIP在涵盖各种扫描仪和协议的多样化临床数据集上进行训练，捕获了跨采集和扫描内的对比度变化，从而实现了与解剖结构无关的表示。我们展示了其在跨模态检索和对比度分类中的有效性，突出了其可扩展性和在进一步临床应用中的潜力。代码和权重已在https://github.com/myigitavci/MR-CLIP 公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [70] [HistoART: Histopathology Artifact Detection and Reporting Tool](https://arxiv.org/abs/2507.00044)
> *HistoART：组织病理学伪影检测与报告工具*

*Seyed Kahaki, Alexander R. Webber, Ghada Zamzmi, Adarsh Subbaswamy, Rucha Deshpande, Aldo Badano* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 组织病理学, 伪影检测, 全玻片成像, 基础模型, 深度学习

**Comment:** 14 pages, 5 figures

> **TL;DR:** 该研究提出了HistoART工具，通过比较三种方法（基础模型、深度学习和知识库方法），有效检测全玻片图像中的六种常见伪影，其中基础模型方法表现最佳，并提供质量报告记分卡以量化和可视化伪影分布。

**AI_Comments:** 该研究通过提出HistoART工具，有效解决了数字病理学中全玻片图像伪影检测的关键挑战。其创新之处在于比较并证明了基础模型（FMA）在伪影检测方面的卓越性能，以及开发了实用的质量报告记分卡，将检测结果转化为可操作的临床洞察。这对于提高WSI分析的可靠性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管全玻片成像（WSI）彻底改变了数字组织病理学并实现了自动化、精确分析，但其在玻片制备和扫描过程中引入的伪影会损害后续的图像分析。

**Method:** 该研究提出了并比较了三种鲁棒的WSI伪影检测方法：1) 基于基础模型的方法（FMA），使用微调的统一神经图像（UNI）架构；2) 基于ResNet50骨干的深度学习方法（DLA）；3) 基于知识的方法（KBA），利用纹理、颜色和频率特征。这些方法旨在检测六种常见的伪影类型。此外，开发了一个质量报告记分卡来量化高质量图像斑块并可视化伪影分布。

**Result:** 在来自不同扫描仪的50,000多个图像斑块上进行了评估。FMA的斑块级AUROC最高，达到0.995，优于基于ResNet50的方法（AUROC：0.977）和KBA（AUROC：0.940）。

**Conclusion:** 该研究成功开发了HistoART工具，通过先进的伪影检测方法（特别是表现最佳的基础模型方法）和质量报告记分卡，有效识别和报告全玻片图像中的伪影，从而提高了数字组织病理学分析的可靠性。

> **ai_Abstract:** 本文提出了HistoART工具，旨在解决全玻片成像（WSI）中由于制备和扫描引入的伪影问题，这些伪影会影响后续图像分析。研究比较了三种伪影检测方法：基于基础模型（FMA）、深度学习（DLA）和知识库（KBA），以识别组织折叠、失焦等六种常见伪影。FMA在超过50,000个图像斑块的评估中表现最佳，AUROC达到0.995。此外，论文还开发了一个质量报告记分卡，用于量化高质量区域并可视化伪影分布，从而将检测结果转化为可操作的质量洞察。

> **摘要翻译:** 在现代癌症诊断中，全玻片成像（WSI）被广泛用于数字化组织样本，以便进行详细、高分辨率的检查；然而，其他诊断方法，如液体活检和分子检测，也根据癌症类型和临床背景而使用。尽管WSI通过实现自动化、精确分析彻底改变了数字组织病理学，但它仍然容易受到玻片制备和扫描过程中引入的伪影的影响。这些伪影会损害下游图像分析。为了解决这一挑战，我们提出并比较了三种针对WSI的鲁棒伪影检测方法：(1) 一种基于基础模型的方法（FMA），使用微调的统一神经图像（UNI）架构；(2) 一种基于ResNet50骨干的深度学习方法（DLA）；以及 (3) 一种基于知识的方法（KBA），利用纹理、颜色和频率指标的手工特征。这些方法针对六种常见的伪影类型：组织折叠、失焦区域、气泡、组织损伤、标记痕迹和血液污染。评估在来自多个地点不同扫描仪（Hamamatsu、Philips、Leica Aperio AT2）的50,000多个图像斑块上进行。FMA实现了最高的斑块级AUROC，达到0.995（95% CI [0.994, 0.995]），优于基于ResNet50的方法（AUROC：0.977，95% CI [0.977, 0.978]）和KBA（AUROC：0.940，95% CI [0.933, 0.946]）。为了将检测转化为可操作的见解，我们开发了一个质量报告记分卡，用于量化高质量斑块并可视化伪影分布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [77] [Evolutionary computing-based image segmentation method to detect defects and features in Additive Friction Stir Deposition Process](https://arxiv.org/abs/2507.00046)
> *基于进化计算的图像分割方法，用于增材摩擦搅拌沉积工艺中的缺陷和特征检测*

*Akshansh Mishra, Eyob Mesele Sefene, Shivraman Thapliyal* | **Category: cs.CV, cs.CE**

**Keywords:** 进化计算, 图像分割, 增材摩擦搅拌沉积, 粒子群优化, 缺陷检测

**Comment:** 7 pages, 4 figures

> **TL;DR:** 本研究提出了一种基于进化计算的图像分割方法，通过粒子群优化（PSO）来分析增材摩擦搅拌沉积（AFSD）工艺中的缺陷和特征，并成功识别出不完全结合和不均匀区域。

**AI_Comments:** 该论文的创新点在于将进化计算（特别是PSO）与图像处理技术相结合，用于解决增材制造领域中缺陷检测的挑战。通过引入注意力加权可视化和多通道可视化，提升了传统图像分割方法的局限性，使得对微妙材料过渡区和缺陷的识别更为精确和自动化。这种方法为增材制造过程的质量控制和优化提供了有价值的定量工具，具有重要的工程应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种新的图像分割方法，用于分析增材摩擦搅拌沉积（AFSD）工艺中的健全性，并检测其中的缺陷和特征，因为传统成像方法难以观察到微妙的材料过渡区和潜在缺陷区域。

**Method:** 本研究提出了一种基于进化计算的图像分割方法。具体方法包括：1. 采用粒子群优化（PSO）确定最佳分割阈值，用于检测多层AFSD构建中的缺陷和特征。2. 将梯度幅度分析与距离变换相结合，创建新型的注意力加权可视化，突出关键界面区域。3. 使用自注意力图和多通道可视化等多种技术分析了五种不同条件下处理的AFSD样品。4. 多通道可视化技术有效结合了边界信息（红色通道）、空间关系（绿色通道）和材料密度数据（蓝色通道）。

**Result:** 1. PSO算法自动识别出每个样品的最佳阈值（范围从156-173），实现了材料界面的精确分割。2. 多通道可视化技术有效地将边界信息、空间关系和材料密度数据结合成量化界面质量的统一表示。3. 基于注意力的分析成功识别了AFSD接头中不完全结合和不均匀的区域。4. 该方法提供了用于工艺优化和增材制造部件质量评估的定量指标。

**Conclusion:** 基于进化计算的图像分割方法，特别是结合PSO和注意力加权可视化，能够有效检测和量化增材摩擦搅拌沉积工艺中的缺陷和特征，为过程优化和质量评估提供了新的工具。

> **ai_Abstract:** 本研究提出了一种基于进化计算的图像分割方法，用于分析增材摩擦搅拌沉积（AFSD）工艺中的健全性，并检测其中的缺陷和特征。该方法利用粒子群优化（PSO）来确定最佳分割阈值，并结合梯度幅度分析和距离变换创建注意力加权可视化。通过对AFSD样品进行多通道可视化分析，该方法成功识别了传统方法难以发现的材料过渡区、不完全结合和不均匀区域，并提供了量化界面质量的指标，为AFSD工艺优化和质量评估提供了有效工具。

> **摘要翻译:** 本工作提出了一种基于进化计算的图像分割方法，用于分析增材摩擦搅拌沉积（AFSD）工艺的健全性。采用粒子群优化（PSO）来确定最佳分割阈值，以检测多层AFSD构建中的缺陷和特征。该方法将梯度幅度分析与距离变换相结合，创建了新颖的注意力加权可视化，突出了关键界面区域。使用多种可视化技术，即自注意力图和多通道可视化，分析了在不同条件下处理的五个AFSD样品。这些互补的方法揭示了通过传统成像不易观察到的微妙材料过渡区和潜在缺陷区域。PSO算法自动识别了每个样品的最佳阈值（范围从156-173），从而实现了材料界面的精确分割。多通道可视化技术有效地将边界信息（红色通道）、空间关系（绿色通道）和材料密度数据（蓝色通道）组合成内聚表示，量化了界面质量。结果表明，基于注意力的分析成功识别了AFSD接头中不完全结合和不均匀的区域，为增材制造部件的工艺优化和质量评估提供了定量指标。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [92] [CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning](https://arxiv.org/abs/2507.00045)
> *CaughtCheating：您的多模态大语言模型是好的出轨侦探吗？探索视觉感知与推理的边界*

*Ming Li, Chenguang Wang, Yijun Liang, Xiyao Wang, Yuhang Zhou, Xiyang Wu, Yuqing Zhang, Ruiyi Zhang, Tianyi Zhou* | **Category: cs.CV, cs.AI, cs.CL**

**Keywords:** 多模态大语言模型, 视觉感知, 推理, 基准测试, CaughtCheating

**Comment:** 

> **TL;DR:** 本文引入了一个名为CaughtCheating的新基准，用于评估多模态大语言模型在检测图像中细微可疑线索方面的能力，发现现有模型在此类任务上的表现极差，揭示了其在人类水平侦探感知和推理方面的不足。

**AI_Comments:** 本文创新性地提出了一个贴近现实生活场景的挑战性基准——CaughtCheating，突破了现有基准的局限性。它不仅揭示了当前多模态大语言模型在高级视觉感知和复杂推理，特别是细微线索检测方面的显著不足，也为未来MLLMs向人类水平侦探能力发展指明了方向。其重要的实践价值在于为开发更鲁棒、更智能的AI模型提供了明确的测试目标。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态大语言模型（MLLMs）在现有基准测试中表现出色，但需要更具挑战性的测试任务。受社交媒体上请求他人从伴侣照片中发现可疑线索的启发，作者旨在探索MLLMs能否像人类侦探一样，发现图像中的细微线索并进行推理。

**Method:** 研究人员调查了GPT-o3在处理某些困难场景时的表现，并发现了一个名为CaughtCheating的常见场景，其中GPT-o3的性能几乎降至零。他们进行了广泛的实验和分析，以理解现有MLLMs为何缺乏解决此类任务的能力。CaughtCheating任务灵感来源于社交媒体上请求他人从伴侣照片中检测可疑线索的场景。

**Result:** 发现GPT-o3在名为CaughtCheating的特定场景中，性能几乎降至零。这表明现有MLLMs在检测图像中细微、可疑线索并进行连贯推理的能力方面存在显著不足。

**Conclusion:** CaughtCheating提供了一类具有重要价值和实际用途的挑战性视觉感知和推理任务。在这些任务上取得成功将为多模态大语言模型获得人类水平的侦探感知和推理能力铺平道路。

> **ai_Abstract:** 本文针对当前多模态大语言模型（MLLMs）在现有基准上表现优异但缺乏挑战性任务的现状，提出了一个名为CaughtCheating的新基准。该基准灵感来源于社交媒体上检测照片中可疑线索的需求，旨在测试MLLMs在视觉感知和推理方面的“侦探”能力。通过对GPT-o3的实验，发现其在该类任务上的性能几乎为零，揭示了现有MLLMs在处理此类细微线索检测和复杂推理方面的显著不足。CaughtCheating被认为是一类有实际价值的挑战性任务，其突破将有助于MLLMs达到人类水平的侦探能力。

> **摘要翻译:** 最近的智能多模态大语言模型（MLLMs）如GPT-o3在各种现有基准测试中取得了接近上限的分数，这激发了对更具挑战性测试任务的需求。据报道，这些MLLMs在一些人类专家级别的任务（例如GeoGuesser）中表现出色，这反映了它们作为侦探的潜力，能够注意到图像中微小的线索并将其编织成连贯的、情境化的解释，从而得出可靠的答案。但是它们能否与优秀人类侦探的表现相媲美呢？为了回答这个问题，我们调查了GPT-o3仍能处理的一些困难场景，并发现了一个o3性能几乎降至零的常见场景，我们将其命名为CaughtCheating。它的灵感来源于社交媒体上请求他人从发布者伴侣分享的照片中检测可疑线索的请求。我们进行了广泛的实验和分析，以理解为什么现有MLLMs缺乏解决此类任务的足够能力。CaughtCheating提供了一类具有巨大价值和实际用途的挑战性视觉感知和推理任务。在这些任务上取得成功为MLLMs获得人类水平的侦探感知和推理能力铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [121] [VirtualFencer: Generating Fencing Bouts based on Strategies Extracted from In-the-Wild Videos](https://arxiv.org/abs/2507.00261)
> *VirtualFencer：基于野外视频中提取策略的击剑回合生成*

*Zhiyin Lin, Purvi Goel, Joy Yun, C. Karen Liu, Joao Pedro Araujo* | **Category: cs.CV, cs.GR**

**Keywords:** VirtualFencer, 击剑, 动作生成, 策略提取, 无监督学习

**Comment:** 

> **TL;DR:** VirtualFencer是一个能够从野外视频中无监督地提取击剑动作和策略，并生成逼真击剑行为的系统。

**AI_Comments:** 该论文的创新点在于能够从“野外”视频中无监督地提取击剑动作和策略，并据此生成逼真的击剑回合。这对于体育分析、训练模拟以及游戏开发等领域都具有重要意义。其多功能性展示了系统在不同场景下的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 击剑运动中运动员的动作多样且具有战略逻辑，其行为常受对手影响。这种动作多样性与双人策略的结合，促使作者将数据驱动建模应用于击剑领域。

**Method:** 提出VirtualFencer系统，该系统能够从野外视频中无监督地提取3D击剑动作和策略，然后利用这些提取的知识生成逼真的击剑行为。

**Result:** 系统展示了多功能性，包括：(i) 自我对战，(ii) 与在线视频中的真实击剑运动员动作对战，以及 (iii) 与专业击剑运动员进行交互式对战。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了VirtualFencer系统，旨在解决击剑运动中动作多样性和双人策略的复杂性。该系统能够从野外视频中无监督地提取3D击剑动作和策略，并利用这些知识生成逼真的击剑行为。VirtualFencer通过自我对战、与真实击剑视频对战以及与专业击剑手交互对战，展示了其强大的功能和实用性。

> **摘要翻译:** 击剑是一项运动员进行多样化但具有战略逻辑动作的运动。虽然大多数动作属于少数高级动作（例如，步法、弓步、格挡），但执行方式可能差异很大——快与慢、大与小、进攻与防守。此外，击剑运动员的动作通常是根据对手的行为而形成的策略。这种动作多样性与底层双人策略的结合，推动了数据驱动建模在击剑领域的应用。我们提出了VirtualFencer，一个能够从野外视频中无监督地提取3D击剑动作和策略，然后利用所提取的知识生成逼真击剑行为的系统。我们通过让系统 (i) 自我对战，(ii) 与来自在线视频的真实击剑运动员动作对战，以及 (iii) 与专业击剑运动员进行交互式对战，展示了我们系统的多功能能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [139] [AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection Training](https://arxiv.org/abs/2507.00049)
> *AdaDeDup：高效大规模目标检测训练的自适应混合数据剪枝*

*Feiyang Kang, Nadine Chang, Maying Shen, Marc T. Law, Rafid Mahmood, Ruoxi Jia, Jose M. Alvarez* | **Category: cs.CV, cs.LG**

**Keywords:** 数据剪枝, 目标检测, 大规模数据集, 自适应, 混合方法

**Comment:** Preprint

> **TL;DR:** AdaDeDup是一种新的混合数据剪枝框架，它结合了基于密度的剪枝和模型反馈，以自适应地修剪大规模数据集，从而在保持接近原始模型性能的同时显著提高目标检测训练的数据效率。

**AI_Comments:** AdaDeDup的创新之处在于其混合方法，将基于密度的剪枝与模型反馈相结合，并引入了集群自适应的阈值调整机制。这使得剪枝过程能够更智能地识别并保留关键数据，同时积极去除冗余，从而有效解决了现有数据剪枝方法的局限性。其在多个大型目标检测基准上的显著性能提升，证明了其在实际应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前大规模数据集的计算负担和固有的数据冗余对机器学习模型训练提出了挑战。现有数据剪枝方法存在局限性：基于密度的方法可能与任务无关，而基于模型的技术可能引入冗余或计算成本过高。

**Method:** 本文提出了一种名为AdaDeDup的新型混合框架，它以集群自适应的方式协同整合了基于密度的剪枝和模型反馈。AdaDeDup首先对数据进行分区并进行初步的基于密度剪枝。然后，它使用一个代理模型通过比较保留样本与剪枝样本的损失来评估每个集群中初步剪枝的影响。这种任务感知信号自适应地调整集群特定的剪枝阈值，从而在冗余集群中进行更激进的剪枝，同时在信息丰富的集群中保留关键数据。

**Result:** AdaDeDup在Waymo、COCO和nuScenes等大规模目标检测基准测试中，使用BEVFormer和Faster R-CNN等标准模型进行了广泛实验。结果表明，AdaDeDup显著优于现有基线方法，大幅降低了性能下降（例如，在Waymo上比随机采样减少超过54%），并且在剪枝20%数据的情况下，实现了接近原始模型的性能。

**Conclusion:** AdaDeDup通过自适应混合数据剪枝，有效提高了大规模模型训练的数据效率，显著减少了计算负担，同时保持了高模型性能。

> **ai_Abstract:** AdaDeDup是一种新颖的混合数据剪枝框架，旨在解决大规模数据集训练中存在的计算负担和数据冗余问题。它结合了基于密度的初始剪枝和模型反馈的自适应调整，通过评估剪枝对每个数据集群的影响来动态调整剪枝阈值。在Waymo、COCO和nuScenes等目标检测数据集上的实验表明，AdaDeDup能够显著提高数据效率，在剪枝20%数据的情况下，仍能保持接近原始模型的性能，并优于现有基线方法。

> **摘要翻译:** 大规模数据集的计算负担和固有冗余对当代机器学习模型的训练提出了挑战。数据剪枝通过选择更小、信息量更大的子集来提供解决方案，但现有方法面临困境：基于密度的方法可能与任务无关，而基于模型的技术可能引入冗余或计算成本过高。我们引入了自适应去重（AdaDeDup），一个新颖的混合框架，它以集群自适应的方式协同整合了基于密度的剪枝和模型反馈。AdaDeDup首先对数据进行分区并应用初步的基于密度剪枝。然后，它使用一个代理模型通过比较保留样本与剪枝样本的损失来评估每个集群中初步剪枝的影响。这种任务感知信号自适应地调整集群特定的剪枝阈值，从而在冗余集群中进行更激进的剪枝，同时在信息丰富的集群中保留关键数据。在Waymo、COCO和nuScenes等大规模目标检测基准测试中，使用BEVFormer、Faster R-CNN等标准模型进行的广泛实验证明了AdaDeDup的优势。它显著优于现有基线方法，大幅降低了性能下降（例如，在Waymo上比随机采样减少超过54%），并且在剪枝20%数据的情况下，实现了接近原始模型的性能，突显了其在提高大规模模型训练数据效率方面的功效。代码已开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [161] [VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models](https://arxiv.org/abs/2507.00052)
> *VSF-Med：一个用于医学视觉语言模型的漏洞评分框架*

*Binesh Sadanandan, Vahid Behzadan* | **Category: cs.CV, cs.AI**

**Keywords:** 医学视觉语言模型, 漏洞评分, 安全评估, 对抗性攻击, VSF-Med

**Comment:** 

> **TL;DR:** VSF-Med是一个用于医学视觉语言模型（VLM）的端到端漏洞评分框架，旨在系统评估其安全性，并揭示了现有VLM在不同攻击向量下的显著脆弱性。

**AI_Comments:** VSF-Med的创新之处在于其端到端的框架设计，结合了多模态攻击（文本提示和视觉扰动）以及基于LLM的自动化评估机制，为医学VLM的安全性评估提供了一个系统且可复现的方法。其重要性在于填补了医学VLM安全评估领域的空白，并量化揭示了主流模型存在的脆弱性，对推动安全可靠的医学AI发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学视觉语言模型（VLMs）在简化劳动密集型医学影像工作流程方面前景广阔，但临床环境中的系统性安全评估仍然稀缺。

**Method:** 本文引入了VSF-Med，一个端到端医学VLM漏洞评分框架，包含三个新颖组件：(i) 针对新兴威胁向量的复杂文本提示攻击模板库；(ii) 由结构相似性（SSIM）阈值校准的不可感知视觉扰动，以保持临床真实性；(iii) 由两个独立的LLM裁判评估的八维评分标准，其原始分数通过z-score归一化整合，生成0-32的综合风险指标。VSF-Med完全基于公开数据集构建，并提供开源代码，可从5,000张放射影像中合成30,000多个对抗性变体，并支持对任何医学VLM进行可复现的基准测试。

**Result:** VSF-Med的综合分析报告显示，最先进的VLM在攻击效果持久性方面平均z-score偏移为0.90σ，提示注入有效性为0.74σ，安全绕过成功率为0.63σ。值得注意的是，Llama-3.2-11B-Vision-Instruct在攻击效果持久性方面表现出1.29σ的峰值漏洞增加，而GPT-4o在该向量上显示增加0.69σ，在提示注入攻击方面增加0.28σ。

**Conclusion:** VSF-Med揭示了现有医学视觉语言模型在面对特定攻击时的显著脆弱性，强调了对这些模型进行系统性安全评估的必要性。

> **ai_Abstract:** 本研究提出了VSF-Med，一个针对医学视觉语言模型（VLM）的端到端漏洞评分框架。该框架整合了新颖的文本提示攻击模板、基于SSIM的视觉扰动以及由LLM评估的八维评分标准，并通过z-score归一化生成综合风险指标。VSF-Med利用公开数据集生成了大量对抗性变体，并揭示了现有VLM（如Llama-3.2-11B-Vision-Instruct和GPT-4o）在持久性攻击效果、提示注入和安全绕过等方面的显著漏洞。

> **摘要翻译:** 视觉语言模型（VLMs）在简化劳动密集型医学影像工作流程方面前景广阔，然而，在临床环境中进行系统性安全评估仍然稀缺。我们引入了VSF-Med，一个用于医学VLM的端到端漏洞评分框架，它结合了三个新颖组件：(i) 一个针对新兴威胁向量的复杂文本提示攻击模板的丰富库；(ii) 由结构相似性（SSIM）阈值校准的不可感知视觉扰动，以保持临床真实性；以及(iii) 一个由两个独立的LLM裁判评估的八维评分标准，其原始分数通过z-score归一化整合，生成一个0-32的综合风险指标。VSF-Med完全基于公开数据集构建，并附带开源代码，它从5,000张放射影像中合成了30,000多个对抗性变体，并能通过一条命令对任何医学VLM进行可复现的基准测试。我们的综合分析报告显示，最先进的VLM在攻击效果持久性方面平均z-score偏移为0.90σ，提示注入有效性为0.74σ，安全绕过成功率为0.63σ。值得注意的是，Llama-3.2-11B-Vision-Instruct在攻击效果持久性方面表现出1.29σ的峰值漏洞增加，而GPT-4o在该向量上显示增加0.69σ，在提示注入攻击方面增加0.28σ。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [180] [MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding](https://arxiv.org/abs/2507.00068)
> *MANTA：面向长篇多模态理解的跨模态语义对齐与信息论优化*

*Ziqi Zhong, Daniel Tang* | **Category: cs.CV, cs.AI, cs.CL**

**Keywords:** 多模态学习, 语义对齐, 信息论优化, 长视频理解, 文本对齐

**Comment:** 

> **TL;DR:** MANTA是一个理论基础的多模态框架，通过将视觉和听觉输入统一到结构化文本空间中，以信息论优化实现跨模态语义对齐，并在长视频问答任务上显著提升了现有最佳模型的性能。

**AI_Comments:** MANTA的创新之处在于其理论基础和将多模态信息统一到结构化文本空间的策略，这使其能够与大型语言模型无缝集成。通过信息论优化和新颖的密度估计技术，它有效地解决了长篇多模态理解中的关键挑战，例如冗余最小化和稀有信号保留，并在多个任务中取得了显著的性能提升，尤其是在处理超长视频方面展现出强大的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态学习方法常将不同模态独立处理，导致表示和推理不一致。本研究旨在解决跨模态语义对齐、自适应时间同步、分层内容表示和上下文感知稀疏信息检索等挑战，以实现长篇多模态理解。

**Method:** 本研究提出了MANTA（Multi-modal Abstraction and Normalization via Textual Alignment）框架，通过信息论优化将视觉和听觉输入统一到结构化文本空间，以便与大型语言模型无缝处理。MANTA解决了语义对齐、自适应时间同步、分层内容表示和上下文感知检索四个关键挑战，并引入了新颖的密度估计技术来最小化冗余同时保留稀有信号。该方法在一个严格的数学框架内形式化，并证明了在令牌约束下上下文选择的最优性。

**Result:** 在长视频问答任务中，MANTA将现有最佳模型的整体准确率提高了22.6%，在超过30分钟的视频上获得了27.3%的显著提升。此外，MANTA在时间推理任务上提高了23.8%，在跨模态理解上提高了25.1%。

**Conclusion:** MANTA框架通过结构化文本统一了多模态表示，为解决长篇多模态理解中的关键挑战奠定了新基础，并在多项任务中展现出卓越的性能。

> **ai_Abstract:** MANTA是一个创新的多模态框架，旨在解决现有方法中模态分离导致的不一致问题。它将视觉和听觉输入统一到结构化文本空间中，通过信息论优化实现跨模态语义对齐，并处理时间同步、分层表示和稀疏信息检索等挑战。实验证明，MANTA在长视频问答、时间推理和跨模态理解等任务上显著优于现有最佳模型，尤其在处理长视频方面表现突出，为统一多模态表示提供了新范式。

> **摘要翻译:** 尽管多模态学习已取得显著进展，但当前方法常将模态独立处理，导致表示和推理存在不一致。我们引入了MANTA（多模态抽象和通过文本对齐进行归一化），一个有理论基础的框架，它将视觉和听觉输入统一到一个结构化文本空间中，以便与大型语言模型无缝处理。MANTA解决了四个关键挑战：(1) 通过信息论优化实现跨模态语义对齐，(2) 针对不同信息密度进行自适应时间同步，(3) 用于多尺度理解的分层内容表示，以及 (4) 从长序列中上下文感知地检索稀疏信息。我们在一个严格的数学框架内形式化了我们的方法，证明了在令牌约束下其上下文选择的最优性。在具有挑战性的长视频问答任务上进行的广泛实验表明，MANTA将现有最佳模型的整体准确率提高了22.6%，在超过30分钟的视频上取得了特别显著的增益（27.3%）。此外，我们还证明了MANTA在时间推理任务（提高23.8%）和跨模态理解（提高25.1%）方面的优越性。我们的框架引入了新颖的密度估计技术，以最小化冗余同时保留稀有信号，为通过结构化文本统一多模态表示奠定了新基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [199] [An efficient plant disease detection using transfer learning approach](https://arxiv.org/abs/2507.00070)
> *一种使用迁移学习方法的有效植物病害检测*

*Bosubabu Sambana, Hillary Sunday Nnadi, Mohd Anas Wajid, Nwosu Ogochukwu Fidelia, Claudia Camacho-Zuñiga, Henry Dozie Ajuzie, Edeh Michael Onyema* | **Category: cs.CV, cs.AI**

**Keywords:** 植物病害检测, 迁移学习, YOLOv7, YOLOv8, 农业

**Comment:** 15 pages , 4 figures. Scientific Reports 2025

> **TL;DR:** 本研究提出了一种基于YOLOv7和YOLOv8的迁移学习系统，用于早期检测植物病害，并在植物叶片图像数据集上取得了高精度，展示了YOLOv8在农业实践中的潜力。

**AI_Comments:** 该论文通过将YOLOv7和YOLOv8等先进的目标检测模型应用于植物病害检测，展示了迁移学习在农业领域的巨大潜力。其创新性在于利用成熟的深度学习框架解决实际农业问题，并提供了具体量化的性能指标。该研究的重要性在于为农民提供了一个高效、可扩展的自动化解决方案，有望显著提高作物产量并减少人工成本。然而，论文未详细说明数据集的规模和多样性，这可能会影响模型在真实世界复杂环境中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 植物病害对农业生产构成重大挑战，早期检测对于减轻其影响和防止大范围损害至关重要。现有技术为自动化监测和检测提供了机会，因此需要一种有效的自动化解决方案。

**Method:** 本研究提出了一种使用迁移学习方法的植物病害识别和监测系统。具体来说，该研究利用了YOLOv7和YOLOv8这两种最先进的目标检测模型，并通过在植物叶片图像数据集上进行微调来准确检测细菌、真菌和病毒性病害。

**Result:** 模型性能通过mAP、F1-score、Precision和Recall等指标进行评估，分别达到了91.05、89.40、91.22和87.66。结果表明YOLOv8比其他目标检测方法更优异和高效。

**Conclusion:** 本研究提出的方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续农业实践。

> **ai_Abstract:** 本研究提出了一种利用迁移学习方法进行植物病害早期检测的系统。该系统基于最先进的目标检测模型YOLOv7和YOLOv8，通过在植物叶片图像数据集上进行微调，能够准确识别多种细菌、真菌和病毒性病害。实验结果显示，YOLOv8在mAP、F1-score、Precision和Recall等指标上表现优异，证实了其在自动化植物病害检测中的高效性和潜力，有助于促进可持续农业发展。

> **摘要翻译:** 植物病害对农民和整个农业部门构成了重大挑战。然而，早期发现植物病害对于减轻其影响和防止大范围损害至关重要，因为病害爆发会严重影响作物的生产力和质量。随着技术的进步，自动化监测和检测植物病害爆发的机会越来越多。本研究提出了一种旨在利用迁移学习方法识别和监测植物病害的系统。具体来说，该研究利用了YOLOv7和YOLOv8这两种目标检测领域最先进的模型。通过在植物叶片图像数据集上对这些模型进行微调，该系统能够准确检测细菌、真菌和病毒性病害的存在，例如白粉病、角斑病、早疫病和番茄花叶病毒。模型的性能使用多项指标进行评估，包括平均精度均值 (mAP)、F1-分数、精确率和召回率，分别达到了91.05、89.40、91.22和87.66。结果表明YOLOv8比其他目标检测方法具有更卓越的有效性和效率，突显了其在现代农业实践中的应用潜力。该方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续农业实践。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [206] [Room Scene Discovery and Grouping in Unstructured Vacation Rental Image Collections](https://arxiv.org/abs/2507.00263)
> *非结构化度假租赁图片集中房间场景发现与分组*

*Vignesh Ram Nithin Kappagantula, Shayan Hassantabar* | **Category: cs.CV, cs.LG, cs.NE**

**Keywords:** 度假租赁, 房间场景发现, 图像分组, 机器学习, 多模态大型语言模型

**Comment:** 

> **TL;DR:** 针对度假租赁平台图片缺乏结构化分类的问题，本文提出一个高效的机器学习流程，用于发现和分组房间场景，并识别卧室中的床型，帮助旅行者理解房产布局。

**AI_Comments:** 本文的创新之处在于提出了一个端到端的机器学习流程，有效解决了度假租赁平台图片缺乏结构化信息的问题。其低延迟和样本高效学习的特性使其在实际应用中具有很高的价值，尤其适用于数据稀缺和实时处理的场景。结合MLLM识别床型也增加了其实用性。该工作对于提升用户在度假租赁平台上的体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 度假租赁平台图片量大且缺乏结构化分类，导致旅行者难以理解房产的空间布局，尤其当存在多个同类型房间时。

**Method:** 本文提出一个计算高效的机器学习流程，该流程具有低延迟和样本高效学习的特点，适用于实时和数据稀缺环境。它集成了有监督的房间类型检测模型、有监督的重叠检测模型（用于识别图片间重叠相似性），以及一个聚类算法（用于根据相似性分数将同一空间的图片分组）。此外，该流程还利用多模态大型语言模型（MLLM）根据视觉内容将每个卧室组映射到房产元数据中指定的床型。

**Result:** 对所提出的模型和整个流程进行的评估显示出强大的性能，显著优于对比学习和使用预训练嵌入的聚类等现有方法。

**Conclusion:** 本文提出了一种有效且计算高效的方法，用于解决度假租赁图片中的房间场景发现和分组问题，并能识别床型。该方法显著提升了旅行者理解房产空间布局的能力，并在性能上超越了现有方法。

> **ai_Abstract:** 本文针对度假租赁平台中非结构化房产图片导致旅行者难以理解空间布局的问题，提出了一种计算高效的机器学习流程。该流程能自动发现、分组房间场景，并识别卧室中的床型。它结合了房间类型检测、图片重叠相似度检测和聚类算法，并利用多模态大型语言模型识别床型。实验证明，该方法在实时和数据稀缺环境下表现优异，显著超越了现有基线方法，有效提升了用户体验。

> **摘要翻译:** 度假租赁（VR）平台的快速增长导致房产图片数量不断增加，这些图片通常未经结构化分类上传。这种缺乏组织性给旅行者理解房产的空间布局带来了重大挑战，尤其当存在多个相同类型的房间时。为了解决这个问题，我们引入了一种有效的方法来解决房间场景发现和分组问题，并识别每个卧室组内的床型。这种分组对于旅行者理解房产的空间组织、布局和睡眠配置非常有价值。我们提出了一种计算高效的机器学习流程，其特点是低延迟和能够通过样本高效学习有效执行，使其非常适合实时和数据稀缺的环境。该流程集成了一个有监督的房间类型检测模型、一个有监督的重叠检测模型来识别两张图片之间的重叠相似性，以及一个聚类算法，利用相似性分数将同一空间的图片分组。此外，该流程还利用多模态大型语言模型（MLLM）根据组图片中存在的视觉内容，将每个卧室组映射到房产元数据中指定的相应床型。我们对上述模型进行了单独评估，并对整个流程进行了评估，观察到强大的性能，显著优于对比学习和使用预训练嵌入的聚类等现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [215] [Diffusion-Based Image Augmentation for Semantic Segmentation in Outdoor Robotics](https://arxiv.org/abs/2507.00153)
> *面向户外机器人语义分割的扩散模型图像增强*

*Peter Mortimer, Mirko Maehlisch* | **Category: cs.CV**

**Keywords:** 图像增强, 扩散模型, 语义分割, 户外机器人, 分布外检测

**Comment:** Presented at the 2025 IEEE ICRA Workshop on Field Robotics

> **TL;DR:** 本文提出了一种基于扩散模型的图像增强方法，用于改善户外机器人学习型感知系统在雪地等不常见环境中的性能。

**AI_Comments:** 本文提出了一种创新的图像增强方法，利用扩散模型和预训练的视觉基础模型来解决户外机器人感知系统在非典型环境中的泛化性问题。其创新点在于能够控制增强数据的语义分布，并结合开放词汇语义分割进行质量控制，这对于提高模型在复杂多变户外场景下的鲁棒性具有重要意义。该方法概念新颖，具有很强的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 学习型感知算法在部署于分布外和代表性不足的环境时性能会下降。户外机器人特别容易受到光照、季节和天气等因素导致视觉场景外观快速变化的影响，这使得训练数据中缺乏对部署环境的充分表示，例如雪地环境。

**Method:** 本文提出了一种新颖的基于扩散模型的图像增强方法，以使训练数据更接近部署环境。该方法利用在大规模互联网数据集上训练的视觉基础模型，通过扩散模型图像增强来控制训练数据中地面表面的语义分布，并针对部署环境对模型进行微调。同时，采用开放词汇语义分割模型来过滤掉包含幻觉的增强候选。

**Result:** Not mentioned in abstract

**Conclusion:** 作者认为基于扩散模型的图像增强方法可以扩展到除雪地之外的许多其他环境，如沙地和火山地形。

> **ai_Abstract:** 本文提出了一种新颖的基于扩散模型的图像增强方法，旨在解决户外机器人学习型感知系统在雪地等分布外环境中性能下降的问题。该方法利用大规模视觉基础模型，通过控制训练数据中地面表面的语义分布来提高数据对部署环境的代表性，并使用开放词汇语义分割模型去除增强中的幻觉，从而微调模型以适应特定环境。

> **摘要翻译:** 当部署在分布外和代表性不足的环境中时，基于学习的感知算法的性能会受到影响。由于动态光照、季节性和天气效应导致视觉场景外观的快速变化，户外机器人特别容易受到影响，这使得学习型感知系统的训练数据中缺乏对场景的充分表示。在这篇概念性论文中，我们专注于为我们的自动驾驶车辆在雪地环境中部署做准备。我们提出了一种新颖的基于扩散模型的图像增强方法，以更紧密地表示训练数据中的部署环境。基于扩散模型的图像增强依赖于在互联网规模数据集上学习的视觉基础模型的公开可用性。基于扩散模型的图像增强使我们能够控制训练数据中地面表面的语义分布，并微调我们的模型以适应其部署环境。我们采用开放词汇语义分割模型来过滤掉包含幻觉的增强候选。我们相信基于扩散模型的图像增强可以扩展到除雪表面之外的许多其他环境，如沙质环境和火山地形。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [229] [FreeLong++: Training-Free Long Video Generation via Multi-band SpectralFusion](https://arxiv.org/abs/2507.00162)
> *FreeLong++：通过多波段光谱融合实现免训练长视频生成*

*Yu Lu, Yi Yang* | **Category: cs.CV**

**Keywords:** 长视频生成, 免训练, 多波段光谱融合, 时间一致性, 视觉保真度

**Comment:** under review

> **TL;DR:** FreeLong++是一个免训练框架，通过多波段光谱融合解决现有短视频生成模型在生成长视频时的时间一致性和视觉保真度下降问题。

**AI_Comments:** FreeLong++的创新之处在于其“免训练”特性和“多波段光谱融合”策略。它解决了长视频生成中的关键挑战——高频失真和时间一致性，通过巧妙地结合不同频率的信息，在不增加训练成本的情况下提升了现有模型的性能。其即插即用性使其具有很高的实用价值和广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频生成模型在生成高质量短视频方面表现良好，但将其扩展到长视频时，会遇到时间一致性和视觉保真度下降的挑战，特别是随着视频长度增加，高频分量会严重失真（高频失真问题）。

**Method:** 论文提出了FreeLong，一个免训练框架，通过融合全局低频特征（捕捉整体语义）和局部高频特征（保留细节），在去噪过程中平衡长视频特征的频率分布。FreeLong++在此基础上进一步扩展，将FreeLong的双分支设计扩展为多分支架构，每个注意力分支在不同的时间尺度上操作，从而实现从低频到高频的多波段频率融合，确保长视频序列的语义连续性和精细运动动态。它可以即插即用，无需额外训练，兼容现有视频生成模型。

**Result:** FreeLong++在长视频生成任务（例如原生长度的4倍和8倍）上显著提高了时间一致性和视觉保真度，优于现有方法。它还支持具有平滑场景过渡的连贯多提示视频生成，并能够使用长深度或姿态序列进行可控视频生成。

**Conclusion:** FreeLong++通过其多波段光谱融合的免训练框架，有效解决了长视频生成中的时间一致性和视觉保真度问题，显著提升了现有视频生成模型生成长视频的能力。

> **ai_Abstract:** FreeLong++是一个创新的免训练框架，旨在解决现有视频生成模型在生成长视频时面临的时间一致性和视觉保真度下降问题，特别是高频失真。它通过引入多分支架构，在不同时间尺度上融合全局低频特征和局部高频特征，实现多波段频率融合，从而在不进行额外训练的情况下，显著提升现有模型生成更长、更连贯、视觉质量更高的视频的能力。

> **摘要翻译:** 近期视频生成模型的进展使得从文本提示生成高质量短视频成为可能。然而，将这些模型扩展到更长的视频仍然是一个重大挑战，主要原因在于时间一致性和视觉保真度的下降。我们的初步观察表明，将短视频生成模型直接应用于长序列会导致明显的质量下降。进一步分析发现，随着视频长度的增加，高频分量会变得越来越扭曲，我们称之为高频失真问题。为了解决这个问题，我们提出了FreeLong，一个免训练框架，旨在去噪过程中平衡长视频特征的频率分布。FreeLong通过融合捕捉整个视频整体语义的全局低频特征，以及从短时间窗口中提取的局部高频特征以保留精细细节来实现这一点。在此基础上，FreeLong++将FreeLong的双分支设计扩展为多分支架构，每个注意力分支在不同的时间尺度上操作。通过从全局到局部排列多个窗口大小，FreeLong++实现了从低频到高频的多波段频率融合，确保了长视频序列中的语义连续性和精细运动动态。无需任何额外训练，FreeLong++可以即插即用到现有视频生成模型（例如Wan2.1和LTX-Video）中，以生成时间一致性和视觉保真度显著提高的更长视频。我们证明了我们的方法在更长视频生成任务（例如原生长度的4倍和8倍）上优于以前的方法。它还支持具有平滑场景过渡的连贯多提示视频生成，并能够使用长深度或姿态序列进行可控视频生成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [242] [SelvaBox: A high-resolution dataset for tropical tree crown detection](https://arxiv.org/abs/2507.00170)
> *SelvaBox：一个用于热带树冠检测的高分辨率数据集*

*Hugo Baudchon, Arthur Ouaknine, Martin Weiss, Mélisande Teng, Thomas R. Walla, Antoine Caron-Guay, Christopher Pal, Etienne Laliberté* | **Category: cs.CV, I.2.10; I.4.8; I.5.4**

**Keywords:** 热带树冠检测, 高分辨率数据集, SelvaBox, 遥感, 零样本检测

**Comment:** 

> **TL;DR:** SelvaBox是一个大型高分辨率热带树冠数据集，包含83,000多个标注，显著提升了检测精度，并支持跨数据集的零样本检测。

**AI_Comments:** SelvaBox数据集的创新之处在于其前所未有的规模和高分辨率特性，解决了热带树冠检测领域长期存在的标注数据稀缺问题。其揭示的高分辨率输入对精度提升的重要性，以及数据集在零样本学习方面的潜力，对未来的遥感和生态研究具有重要意义。该数据集的公开将极大促进相关算法的开发和应用。

<details>
  <summary>Details</summary>

**Motivation:** 检测热带森林中的个体树冠对于研究受人类干预和气候变化影响的复杂生态系统至关重要。然而，现有标注数据集稀缺，阻碍了稳健的模型开发。

**Method:** 本文引入了SelvaBox，一个用于高分辨率无人机图像中热带树冠检测的开放获取数据集。该数据集包含超过83,000个手动标注的树冠。研究人员在SelvaBox上进行了广泛的基准测试，并尝试了与其它数据集在统一的多分辨率管道中进行联合训练。

**Result:** 1) 更高分辨率的输入持续提高检测精度；2) 仅在SelvaBox上训练的模型在未见过的热带树冠数据集上实现了有竞争力的零样本检测性能，匹配或超越了竞争方法；3) 在统一的多分辨率管道中，SelvaBox与另外三个数据集联合训练的模型在所有评估数据集上排名第一或第二。

**Conclusion:** SelvaBox数据集的发布及其基准测试结果，证明了高分辨率数据对热带树冠检测的重要性，并为未来的模型开发提供了强大的资源。该数据集、代码和预训练权重已公开，将促进热带森林研究。

> **ai_Abstract:** 本文介绍了SelvaBox，一个用于热带树冠检测的大型高分辨率开放获取数据集，包含超过83,000个手动标注的树冠，规模远超现有数据集。研究发现，更高分辨率输入能显著提升检测精度，且仅在SelvaBox上训练的模型在未见数据集上表现出强大的零样本检测能力。此外，结合多分辨率联合训练可进一步提高检测器性能。该数据集、代码和预训练权重均已公开，旨在推动热带森林研究和模型开发。

> **摘要翻译:** 检测热带森林中的个体树冠对于研究受人类干预和气候变化影响的这些复杂而重要的生态系统至关重要。然而，热带树冠在大小、结构和模式上差异很大，并且高度重叠和交织，需要将先进的遥感方法应用于高分辨率图像。尽管对热带树冠检测的兴趣日益增长，但标注数据集仍然稀缺，阻碍了稳健的模型开发。我们引入了SelvaBox，这是用于高分辨率无人机图像中热带树冠检测的最大的开放获取数据集。它涵盖了三个国家，包含超过83,000个手动标注的树冠——比之前所有热带森林数据集的总和大一个数量级。SelvaBox上的广泛基准测试揭示了两个关键发现：(1) 更高分辨率的输入持续提高检测精度；(2) 仅在SelvaBox上训练的模型在未见过的热带树冠数据集上实现了有竞争力的零样本检测性能，匹配或超越了竞争方法。此外，在统一的多分辨率管道中，以每像素3到10厘米的分辨率在SelvaBox和另外三个数据集上联合训练，产生了一个在所有评估数据集上排名第一或第二的检测器。我们的数据集、代码和预训练权重已公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [Graph-Based Deep Learning for Component Segmentation of Maize Plants](https://arxiv.org/abs/2507.00182)
> *基于图深度学习的玉米植株组分分割*

*J. I. Ruíz, A. Méndez, E. Rodríguez* | **Category: cs.CV**

**Keywords:** 图深度学习, 玉米植株, 组分分割, 3D点云, 精准农业

**Comment:** 

> **TL;DR:** 本文提出了一种基于图神经网络（GNN）的深度学习架构，用于LiDAR 3D点云数据集中玉米植株组分的识别，该方法在IoU平均值上实现了80%以上的分割精度，优于现有模型。

**AI_Comments:** 本文的创新点在于将图神经网络应用于3D点云数据中的植物组分分割，有效解决了传统方法在处理复杂3D数据时的局限性。结合PCA进行特征增强和多层图结构处理，提高了分割精度，对于精准农业中的植物表型分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在精准农业中，识别单个植物组分是一项重要任务。传统的2D成像、3D重建和卷积神经网络（CNN）在处理3D数据和识别单个植物组分时存在缺陷。

**Method:** 本研究提出了一种基于图神经网络（GNN）的深度学习架构，用于检测LiDAR 3D点云数据集中单个植物的组分。该架构结合了主成分分析（PCA）进行特征增强。每个点被视为一个顶点，通过K-Nearest Neighbors（KNN）层建立边来表示3D点云数据集。随后，使用Edge-Conv层进一步增强每个点的特征，最后应用图注意力网络（GAT）对植物的可见表型组分（如叶片、茎和土壤）进行分类。

**Result:** 该图深度学习方法提高了识别单个植物组分的分割精度，在IoU平均值上达到了80%以上，优于其他基于点云的现有模型。

**Conclusion:** 本研究表明，所提出的基于图的深度学习方法显著提高了植物组分分割的准确性。

> **ai_Abstract:** 本文提出了一种新颖的基于图深度学习的架构，用于对LiDAR 3D点云数据中的玉米植株组分进行精确分割。针对传统方法在处理3D数据时存在的不足，该方法结合了图神经网络（GNN）、主成分分析（PCA）、K-Nearest Neighbors（KNN）和Edge-Conv层来构建和增强点云特征，并最终通过图注意力网络（GAT）进行分类。实验结果表明，该方法在分割精度上表现出色，IoU平均值超过80%，优于现有基于点云的模型。

> **摘要翻译:** 在精准农业中，探索作物生产时最重要的任务之一是识别单个植物组分。目前有几种尝试通过传统2D成像、3D重建和卷积神经网络（CNN）来完成这项任务。然而，它们在处理3D数据和识别单个植物组分时存在一些缺点。因此，在这项工作中，我们提出了一种新颖的深度学习架构，用于在光探测和测距（LiDAR）3D点云（PC）数据集上检测单个植物的组分。该架构基于图神经网络（GNN）的概念，并通过主成分分析（PCA）进行特征增强。为此，每个点被视为一个顶点，通过使用K-Nearest Neighbors（KNN）层建立边，从而表示3D点云数据集。随后，使用Edge-Conv层进一步增加每个点的特征。最后，应用图注意力网络（GAT）对植物的可见表型组分进行分类，例如叶片、茎和土壤。这项研究表明，我们基于图的深度学习方法提高了识别单个植物组分的分割精度，在IoU平均值上达到了80%以上，因此优于其他基于点云的现有模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [267] [Computer Vision for Objects used in Group Work: Challenges and Opportunities](https://arxiv.org/abs/2507.00224)
> *计算机视觉在小组工作中物体应用：挑战与机遇*

*Changsoo Jung, Sheikh Mannan, Jack Fitzgerald, Nathaniel Blanchard* | **Category: cs.CV, cs.HC**

**Keywords:** 6D Pose Estimation, Collaborative Learning, Computer Vision, Dataset, Object Detection

**Comment:** Accepted to AIED 2025 Late Breaking Results Track

> **TL;DR:** 本研究引入了一个新的6D姿态估计视频数据集FiboSB，用于小组协作中的物理对象交互场景。研究评估了现有最先进的6D姿态估计方法在该数据集上的表现，揭示了其在协作小组工作中的局限性，特别是目标检测模块的失败。通过微调YOLO11-x，研究显著提高了目标检测的性能，为在困难协作背景下应用6D姿态估计奠定了基础。

**AI_Comments:** 这项工作通过引入一个新颖且具有挑战性的数据集FiboSB，填补了在复杂协作环境中进行6D姿态估计的空白。它不仅揭示了现有SOTA方法在实际应用中的局限性（尤其是在目标检测方面），还提供了一个可行的解决方案（微调YOLO11-x），并为未来的研究提供了基准和错误分析，这对于推动计算机视觉在教育和协作技术领域的应用具有重要意义。数据集的建立和对现有方法挑战的揭示是其创新点。

<details>
  <summary>Details</summary>

**Motivation:** 在K-12教育环境中，交互式和空间感知技术在促进动手探索和概念理解方面具有重要作用。然而，现有系统在协作任务中难以准确捕捉学生与物理对象之间的真实世界交互。自动6D姿态估计能够解决这一问题，但现有方法在小组协作的复杂场景中存在挑战和局限性，尤其是在远距离记录和小型物体识别方面。

**Method:** 研究引入了一个新颖且具有挑战性的6D姿态视频数据集FiboSB，该数据集记录了三人小组解决涉及小型手持方块和秤的互动任务。为了捕捉所有参与者，数据集采用远距离整体记录方式。研究评估了四种最先进的6D姿态估计算法在FiboSB上的性能，并进行了详细的错误分析，发现现有方法的6D姿态目标检测模块存在失败。为解决此问题，研究对YOLO11-x进行了微调。

**Result:** 评估结果显示，当前最先进的6D姿态估计算法在协作小组工作中的表现存在局限性，其目标检测模块是失败的主要原因。通过对YOLO11-x进行微调，在FiboSB数据集上实现了0.898的整体mAP_50，显著改善了目标检测性能。

**Conclusion:** FiboSB数据集、基准测试结果以及对YOLO11-x错误的分析，为在复杂的协作环境中利用6D姿态估计奠定了基础，并指明了未来研究的方向。

> **ai_Abstract:** 这项研究旨在解决现有系统在协作学习环境中难以准确捕捉学生与物理对象交互的问题，提出通过6D姿态估计来关联对象和实体。为此，研究引入了FiboSB，一个专门针对三人小组协作、包含小型手持方块和秤的6D姿态视频数据集。对现有最先进的6D姿态估计方法进行评估后发现，其在协作场景中存在局限性，特别是目标检测模块表现不佳。通过对YOLO11-x进行微调，研究成功将目标检测的mAP_50提升至0.898，为未来在复杂协作背景下应用6D姿态估计奠定了基础。

> **摘要翻译:** 交互式和空间感知技术正在改变教育框架，特别是在K-12环境中，动手探索能促进更深层次的概念理解。然而，在协作任务中，现有系统往往缺乏准确捕捉学生与物理对象之间真实世界交互的能力。这个问题可以通过自动6D姿态估计来解决，即从RGB图像或视频中估计物体在3D空间中的位置和方向。对于与物理对象交互的协作小组，6D姿态估计允许AI系统关联对象和实体。作为这项工作的一部分，我们引入了FiboSB，这是一个新颖且具有挑战性的6D姿态视频数据集，其特点是三人小组解决涉及小型手持方块和秤的互动任务。这种设置对6D姿态提出了独特的挑战，因为小组是整体上从远处记录以捕捉所有参与者——这，加上方块的小尺寸，使得6D姿态估计本质上是非平凡的。我们评估了FiboSB上的四种最先进的6D姿态估计算法，揭示了当前算法在协作小组工作中的局限性。对这些方法的错误分析表明，6D姿态方法的目标检测模块失败。我们通过对FiboSB进行YOLO11-x的微调来解决这个问题，实现了0.898的整体mAP_50。此处呈现的数据集、基准测试结果以及YOLO11-x错误分析为在困难的协作环境中利用6D姿态估计奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [275] [VOCAL: Visual Odometry via ContrAstive Learning](https://arxiv.org/abs/2507.00243)
> *VOCAL：通过对比学习的视觉里程计*

*Chi-Yao Huang, Zeel Bhatt, Yezhou Yang* | **Category: cs.CV**

**Keywords:** 视觉里程计, 对比学习, 贝叶斯推理, 表示学习, 可解释性

**Comment:** 

> **TL;DR:** VOCAL是一种新的视觉里程计框架，它将VO重新构想为标签排序挑战，通过结合贝叶斯推理和表示学习来提高可解释性和灵活性。

**AI_Comments:** VOCAL的创新之处在于将视觉里程计问题转化为标签排序挑战，并结合贝叶斯推理和对比学习来提高模型的可解释性。这对于推动VO领域向更通用和可解释的空间智能发展具有重要意义，尤其是在需要高可靠性和透明度的自主系统中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的许多基于学习的视觉里程计（VO）技术依赖于僵化的几何假设，这通常在可解释性方面不足，并且在完全数据驱动的框架中缺乏坚实的理论基础。

**Method:** VOCAL将视觉里程计（VO）重新构想为标签排序挑战。它通过将贝叶斯推理与表示学习框架相结合，组织视觉特征以反映相机状态。排名机制强制相似的相机状态在潜在空间中收敛到一致且空间连贯的表示。

**Result:** 在KITTI数据集上的广泛评估突出显示了VOCAL增强的可解释性和灵活性。

**Conclusion:** VOCAL通过增强可解释性和灵活性，推动视觉里程计（VO）走向更通用和可解释的空间智能。

> **ai_Abstract:** VOCAL是一种新颖的视觉里程计（VO）框架，旨在克服现有学习方法在可解释性和理论基础上的不足。它将VO视为标签排序挑战，并通过整合贝叶斯推理和表示学习来组织视觉特征以反映相机状态，使相似的相机状态在潜在空间中形成一致表示。这种方法增强了特征的可解释性并兼容多模态数据。在KITTI数据集上的评估证明了VOCAL在可解释性和灵活性方面的提升。

> **摘要翻译:** 视觉里程计（VO）的突破从根本上重塑了机器人技术的前景，实现了对现代自主系统至关重要的超精确相机状态估计。尽管取得了这些进展，许多基于学习的VO技术依赖于僵化的几何假设，这通常在可解释性方面不足，并且在完全数据驱动的框架中缺乏坚实的理论基础。为了克服这些限制，我们引入了VOCAL（通过对比学习的视觉里程计），这是一个新颖的框架，它将VO重新构想为标签排序挑战。通过将贝叶斯推理与表示学习框架相结合，VOCAL组织视觉特征以反映相机状态。排名机制强制相似的相机状态在潜在空间中收敛到一致且空间连贯的表示。这种战略性对齐不仅增强了学习特征的可解释性，而且确保了与多模态数据源的兼容性。在KITTI数据集上的广泛评估突出显示了VOCAL增强的可解释性和灵活性，将VO推向更通用和可解释的空间智能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [285] [Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition](https://arxiv.org/abs/2507.00248)
> *针对有限数据开发轻量级深度神经网络模型用于实时手语识别*

*Nikita Nikitin, Eugene Fomin* | **Category: cs.CV, cs.AI, cs.CL, cs.LG**

**Keywords:** 手语识别, 轻量级DNN, 实时识别, 有限数据, 边缘计算

**Comment:** 7 pages, 2 figures, 2 tables, for associated mpeg file, see
  https://slait.app/static/Screen_Recording.mp4

> **TL;DR:** 本文提出一个使用有限数据训练的轻量级DNN框架，实现实时手语识别，解决了数据稀缺和计算成本高的问题，并在边缘设备上实现了高精度和低延迟。

**AI_Comments:** 该论文的创新点在于其针对手语识别的实际部署挑战（如数据稀缺和边缘设备限制）提出了一个全面的解决方案。通过结合特征工程（矢量化手语参数）、轻量级DNN设计和专用数据标注平台，实现了高效且准确的实时手语识别系统，特别适合资源受限的环境。

<details>
  <summary>Details</summary>

**Motivation:** 解决手语识别中的关键挑战，包括数据稀缺、高计算成本以及训练和推理环境之间帧速率的差异。

**Method:** 通过将手语特定参数（如手形、手掌方向、运动和位置）编码为矢量化输入，并利用MediaPipe进行关键点提取，实现高度可分离的输入数据表示。采用针对小于10MB部署优化的DNN架构，并使用数据标注平台“slait data”进行结构化标注和矢量提取。

**Result:** 模型能够准确分类343个手语，在边缘设备上延迟低于10毫秒，部署大小小于10MB。在孤立手语识别中达到92%的准确率，并已集成到“slait ai”网络应用中，表现出稳定的推理性能。

**Conclusion:** 该框架成功地利用有限数据和轻量级DNN实现了实时、高精度手语识别，并解决了实际部署中的挑战。

> **ai_Abstract:** 本文介绍了一种用于实时手语识别的轻量级深度神经网络（DNN）框架。该框架旨在克服数据稀缺、高计算成本和训练/推理帧率不匹配等挑战。通过将手语参数（如手形、方向、运动、位置）矢量化并结合MediaPipe进行关键点提取，模型实现了高效的数据表示。优化的DNN架构支持小于10MB的部署，能在边缘设备上以低于10ms的延迟准确识别343个手语，并在孤立手语识别中达到92%的准确率。该系统已集成到“slait ai”网络应用中。

> **摘要翻译:** 我们提出了一种新颖的框架，用于使用有限数据训练的轻量级DNN进行实时手语识别。我们的系统解决了手语识别中的关键挑战，包括数据稀缺、高计算成本以及训练和推理环境之间帧速率的差异。通过将手语特定参数（如手形、手掌方向、运动和位置）编码为矢量化输入，并利用MediaPipe进行关键点提取，我们实现了高度可分离的输入数据表示。我们的DNN架构针对小于10MB的部署进行了优化，能够在边缘设备上以低于10毫秒的延迟准确分类343个手语。数据标注平台“slait data”促进了结构化标注和矢量提取。我们的模型在孤立手语识别中达到了92%的准确率，并已集成到“slait ai”网络应用程序中，在那里它展示了稳定的推理性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [293] [GazeTarget360: Towards Gaze Target Estimation in 360-Degree for Robot Perception](https://arxiv.org/abs/2507.00253)
> *GazeTarget360：面向机器人感知的360度凝视目标估计*

*Zhuangzhuang Dai, Vincent Gbouna Zakka, Luis J. Manso, Chen Li* | **Category: cs.CV, cs.HC**

**Keywords:** 360度凝视目标估计, 机器人感知, 人机交互, 视觉编码器, 多尺度融合

**Comment:** 

> **TL;DR:** GazeTarget360是一个新颖的系统，能够从图像中估计360度凝视目标，解决了现有方法在非注视摄像头场景下的不足，并提高了机器人感知能力。

**AI_Comments:** GazeTarget360的创新点在于其能够处理360度凝视目标估计，克服了传统方法在非直视摄像头场景下的局限性。其系统集成眼部接触检测器、预训练视觉编码器和多尺度融合解码器的方法，使其在复杂视觉场景中具有鲁棒性。该系统的高效性和可部署性对于实际的人机交互应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有凝视估计方法在受试者不看摄像头时无法有效预测凝视目标，且未充分利用背景信息。实现机器人理解人类凝视目标对下游任务如注意力估计和运动预测至关重要。

**Method:** 本文提出了名为GazeTarget360的系统，用于在通用视觉场景中从图像估计360度凝视目标。该系统集成了眼部接触检测器、预训练视觉编码器和多尺度融合解码器的条件推理引擎。

**Result:** 交叉验证结果表明，GazeTarget360能在未见过的场景中生成准确可靠的凝视目标预测。

**Conclusion:** GazeTarget360是首个能从真实摄像机素材中预测凝视目标且高效可部署的系统。

> **ai_Abstract:** 本文提出了GazeTarget360系统，旨在解决机器人感知中360度凝视目标估计的难题。针对现有方法无法处理受试者不直视摄像头或忽略背景信息的问题，GazeTarget360整合了眼部接触检测器、预训练视觉编码器和多尺度融合解码器。实验证明，该系统能在未知场景中准确可靠地预测凝视目标，是首个高效且可部署的从真实视频预测凝视目标的系统。

> **摘要翻译:** 启用机器人理解人类凝视目标是使其在下游任务中具备能力的关键一步，例如在真实世界人机交互中的注意力估计和运动预测。先前的工作通过仔细移除画面外样本，利用数据驱动方法解决了画面内目标定位问题。基于视觉的凝视估计方法，如OpenFace，不能有效吸收图像中的背景信息，并且在受试者不看摄像头的情况下无法预测凝视目标。在这项工作中，我们提出了一个系统来解决在通用视觉场景中从图像估计360度凝视目标的问题。该系统名为GazeTarget360，集成了眼部接触检测器、预训练视觉编码器和多尺度融合解码器的条件推理引擎。交叉验证结果表明，GazeTarget360能够在未见过的场景中生成准确可靠的凝视目标预测。这使得它成为第一个能够从真实摄像机素材中预测凝视目标且高效可部署的系统。我们的源代码已公开：https://github.com/zdai257/DisengageNet。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [298] [Cage-Based Deformation for Transferable and Undefendable Point Cloud Attack](https://arxiv.org/abs/2507.00690)
> *基于笼的变形实现可转移和不可防御的点云攻击*

*Keke Tang, Ziyong Du, Weilong Peng, Xiaofei Wang, Peican Zhu, Ligang Liu, Zhihong Tian* | **Category: cs.CV, cs.CR**

**Keywords:** 点云攻击, 对抗样本, 变形, 笼子, 可转移性

**Comment:** 

> **TL;DR:** 提出CageAttack，一种基于笼的变形方法，可生成自然、可转移且不可防御的点云对抗样本，优于现有方法。

**AI_Comments:** CageAttack的创新之处在于引入了“笼”这一结构化变形基础，有效解决了点云对抗攻击中变形自然度和攻击效果的矛盾。这种方法提高了对抗样本的隐蔽性（真实性），同时增强了其可转移性和不可防御性，对于提升3D视觉模型的鲁棒性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的点云对抗攻击方法在保持几何约束的同时，限制了可转移性和不可防御性；非结构化变形方法可能导致不自然的失真，影响对抗样本的真实性。

**Method:** 本文提出了CageAttack，一种基于笼的变形框架。它首先围绕目标对象构建一个笼子，提供结构化基础以实现平滑、自然外观的变形。然后，对笼子顶点施加扰动，这些扰动无缝地传播到点云，确保产生的变形固有于对象并保持真实性。

**Result:** 在三个数据集上对七个3D深度神经网络分类器进行的广泛实验表明，CageAttack在可转移性、不可防御性和真实性之间取得了卓越的平衡，优于现有最先进的方法。

**Conclusion:** CageAttack通过引入基于笼的变形，有效解决了点云对抗攻击中可转移性、不可防御性和真实性之间的平衡问题，并取得了优于SOTA方法的性能。

> **ai_Abstract:** 本文提出了CageAttack，一种基于笼的变形框架，旨在解决现有方法在点云对抗攻击中面临的可转移性、不可防御性和真实性之间的平衡问题。通过构建围绕目标对象的笼子并扰动其顶点，CageAttack能够生成平滑、自然的对抗性点云。实验证明，该方法在多个数据集和分类器上表现出卓越的性能，超越了现有最先进的方法。

> **摘要翻译:** 点云上的对抗性攻击通常施加严格的几何约束以保持合理性；然而，此类约束固有地限制了可转移性和不可防御性。虽然变形提供了一种替代方案，但现有的非结构化方法可能会引入不自然的失真，使对抗性点云引人注目并损害其合理性。在本文中，我们提出了CageAttack，一种基于笼的变形框架，可生成自然的对抗性点云。它首先围绕目标对象构建一个笼子，为平滑、自然外观的变形提供结构化基础。然后，将扰动应用于笼子顶点，这些扰动无缝地传播到点云，确保所产生的变形保持对象固有的特性并保持合理性。在三个数据集上对七个3D深度神经网络分类器进行的广泛实验表明，CageAttack在可转移性、不可防御性和合理性之间取得了卓越的平衡，优于最先进的方法。代码将在接受后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [309] [Biorthogonal Tunable Wavelet Unit with Lifting Scheme in Convolutional Neural Network](https://arxiv.org/abs/2507.00739)
> *卷积神经网络中基于提升方案的双正交可调小波单元*

*An Le, Hung Nguyen, Sungbal Seo, You-Suk Bae, Truong Nguyen* | **Category: cs.CV, eess.IV, eess.SP**

**Keywords:** 双正交小波, 提升方案, 卷积神经网络, 图像分类, 异常检测

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的双正交可调小波单元，该单元采用提升方案构建，放宽了正交性和等长滤波器限制，提高了卷积神经网络在图像分类和异常检测任务中的性能。

**AI_Comments:** 该论文的创新之处在于引入了一种基于提升方案的灵活双正交可调小波单元，它突破了传统小波设计的正交性和等长滤波器限制。其重要性体现在通过增强CNN的基本操作，在图像分类和异常检测等不同任务和数据集上均取得了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 为了在滤波器设计中提供更大的灵活性，并增强卷积神经网络（CNN）中的卷积、池化和下采样操作，从而改进图像分类和异常检测性能。

**Method:** 本文引入了一种新颖的双正交可调小波单元，该单元通过提升方案构建，放宽了正交性和等长滤波器长度的限制，从而在滤波器设计中提供了更大的灵活性。该单元增强了卷积、池化和下采样操作。

**Result:** 当集成到18层残差神经网络（ResNet-18）中时，该方法在CIFAR-10数据集上的分类准确率提高了2.12%，在可描述纹理数据集（DTD）上提高了9.73%。在ResNet-34中也观察到了类似的改进。对于MVTec异常检测数据集中榛子类别的异常检测，所提出的方法在分割和检测任务中均实现了具有竞争力和均衡的性能，在准确性和鲁棒性方面优于现有方法。

**Conclusion:** 所提出的双正交可调小波单元能够有效捕获细粒度细节，并显著提高卷积神经网络在图像分类和异常检测任务中的性能。

> **ai_Abstract:** 本文提出了一种新颖的双正交可调小波单元，该单元采用提升方案构建，旨在放松传统的滤波器设计约束，并增强卷积神经网络（CNN）中的基本操作。该单元通过改进卷积、池化和下采样，显著提升了图像分类和异常检测任务的性能。实验结果表明，在CIFAR-10和可描述纹理数据集（DTD）上的图像分类准确率有所提高，并在MVTec异常检测数据集上取得了具有竞争力和鲁棒性的异常检测性能。

> **摘要翻译:** 这项工作引入了一种新颖的双正交可调小波单元，该单元采用提升方案构建，放宽了正交性和等长滤波器长度的限制，在滤波器设计中提供了更大的灵活性。所提出的单元增强了卷积、池化和下采样操作，从而改进了卷积神经网络（CNN）中的图像分类和异常检测。当集成到18层残差神经网络（ResNet-18）中时，该方法在CIFAR-10数据集上的分类准确率提高了2.12%，在可描述纹理数据集（DTD）上提高了9.73%，证明了其捕获细粒度细节的有效性。在ResNet-34中也观察到了类似的改进。对于MVTec异常检测数据集中榛子类别的异常检测，所提出的方法在分割和检测任务中均实现了具有竞争力和均衡的性能，在准确性和鲁棒性方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [Self-Supervised Multiview Xray Matching](https://arxiv.org/abs/2507.00287)
> *自监督多视图X射线匹配*

*Mohamad Dabboussi, Malo Huard, Yann Gousseau, Pietro Gori* | **Category: cs.CV, cs.AI**

**Keywords:** 自监督学习, 多视图X射线, 对应关系, 骨折检测, 数字重建射线照片 (DRR)

**Comment:** MICCAI 2025

> **TL;DR:** 提出了一种新的自监督方法，利用合成X射线图像（DRR）自动建立多视图X射线之间的对应关系，并证明其作为预训练策略能有效提升真实数据上的多视图骨折检测性能。

**AI_Comments:** 这篇论文的创新点在于其提出的自监督流水线，巧妙地利用未标注的CT数据生成合成X射线（DRR）来学习多视图间的对应关系，从而规避了高昂的手动标注成本。将这种对应关系学习作为预训练策略，进一步提升了真实世界医学图像分析的性能，尤其是在多视图骨折检测方面，显示了其在临床应用中的巨大潜力。这种方法为医学图像分析领域中数据标注稀缺的问题提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 准确解读多视图X射线对于诊断骨折和其他异常至关重要。尽管单图像AI分析取得了进展，但现有方法难以在不同X射线视图之间建立鲁棒的对应关系，而这对于精确临床评估是必不可少的。

**Method:** 提出了一种新颖的自监督流水线，通过从无标注CT体积自动生成数字重建射线照片（DRR），从而自动生成合成X射线视图之间的多对多对应矩阵，无需手动标注。该方法包含一个基于Transformer的训练阶段，用于准确预测两个或更多X射线视图之间的对应关系。此外，学习合成X射线视图之间的对应关系被用作预训练策略，以增强真实数据上的自动多视图骨折检测。

**Result:** 在合成和真实X射线数据集上的广泛评估表明，整合对应关系可以提高多视图骨折分类的性能。

**Conclusion:** 学习合成X射线视图之间的对应关系作为一种自监督预训练策略，能够有效提升真实世界多视图骨折检测的性能，解决了多视图X射线分析中对应关系难以建立的问题。

> **ai_Abstract:** 本文提出了一种新颖的自监督方法，用于解决多视图X射线图像之间建立对应关系的挑战。该方法通过从无标注CT数据生成数字重建射线照片（DRR）来创建合成X射线视图，并自动生成这些视图间的多对多对应矩阵，从而避免了手动标注。研究引入了一个基于Transformer的训练阶段来预测视图间的对应关系，并证明将这种对应关系学习作为预训练策略，能够有效提升真实数据上多视图骨折检测的性能。实验结果表明，结合对应关系能显著提高多视图骨折分类的准确性。

> **摘要翻译:** 准确解读多视图X射线对于诊断骨折、肌肉损伤及其他异常至关重要。尽管基于AI的单图像分析已取得显著进展，但当前方法在建立不同X射线视图之间的鲁棒对应关系方面常遇到困难，而这对于精确的临床评估是必不可少的。在这项工作中，我们提出了一种新颖的自监督流水线，通过自动生成合成X射线视图之间的多对多对应矩阵，消除了手动标注的需要。这通过使用数字重建射线照片（DRR）实现，这些DRR是从未标注的CT体积中自动派生的。我们的方法包含一个基于Transformer的训练阶段，以准确预测两个或更多X射线视图之间的对应关系。此外，我们证明了学习合成X射线视图之间的对应关系可以作为一种预训练策略，以增强真实数据上的自动多视图骨折检测。在合成和真实X射线数据集上的广泛评估表明，整合对应关系可以提高多视图骨折分类的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [Reducing Variability of Multiple Instance Learning Methods for Digital Pathology](https://arxiv.org/abs/2507.00292)
> *减少数字病理中多实例学习方法的变异性*

*Ali Mammadov, Loïc Le Folgoc, Guillaume Hocquet, Pietro Gori* | **Category: cs.CV, cs.AI**

**Keywords:** 数字病理, 多实例学习, 性能变异性, 模型融合, 全玻片图像

**Comment:** MICCAI 2025

> **TL;DR:** 针对数字病理中多实例学习（MIL）方法性能变异性高的问题，本文提出了一种多保真度模型融合策略，通过平均多个早期训练的模型来降低变异性，提高MIL方法的可靠性和可复现性。

**AI_Comments:** 这篇论文通过提出一种创新的多保真度模型融合策略，有效解决了数字病理中多实例学习方法（MIL）长期存在的性能变异性高的问题。其重要性在于提高了MIL模型在实际应用中的可靠性和可信度，使得不同MIL方法之间的比较更加公平。该方法具有普适性，可应用于现有任何MIL模型，并且在保持计算效率的同时，简化了超参数调优并提升了可复现性，对于推动数字病理学领域深度学习应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数字病理学中全玻片图像（WSIs）的高分辨率和大尺寸给深度学习模型应用带来挑战。多实例学习（MIL）方法是WSI分类的合适解决方案，但其主要缺点是性能在不同运行之间存在高变异性（测试集上可达10-15 AUC点），这使得可靠地比较不同MIL方法变得困难。这种变异性主要来源于权重初始化、批次排序和学习率。

**Method:** 提出了一种多保真度、模型融合策略（Multi-Fidelity, Model Fusion strategy）用于MIL方法。具体做法是：首先训练多个模型几个epochs，然后根据验证分数平均那些最稳定和最有前景的模型。这种方法可以应用于任何现有的MIL模型。

**Result:** 该方法能有效降低性能变异性，简化超参数调优，提高可复现性，同时保持计算效率。通过在2个不同数据集、3种初始化策略和5种MIL方法上进行了超过2000次实验，验证了该方法的有效性。

**Conclusion:** 通过引入多保真度模型融合策略，能够显著降低数字病理中多实例学习方法的性能变异性，提高其可靠性和可复现性，同时保持计算效率。

> **ai_Abstract:** 本文针对数字病理中全玻片图像（WSIs）分类所使用的多实例学习（MIL）方法存在高性能变异性的问题，提出了一种多保真度模型融合策略。该策略通过在早期训练阶段对多个模型进行评估，并平均其中最稳定和最有前景的模型，从而有效降低了MIL方法的性能波动。实验结果表明，该方法能够显著提高MIL方法的可复现性，简化超参数调优，并在保持计算效率的同时，有效减少了性能变异性。

> **摘要翻译:** 数字病理学通过将组织样本数字化为全玻片图像（WSIs）彻底改变了该领域。然而，WSIs的高分辨率和大尺寸在应用深度学习模型时带来了显著挑战。作为解决方案，WSIs通常被分成更小的图像块，每张玻片带有一个全局标签（即诊断），而不是（过于）昂贵的像素级标注。通过将每张玻片视为一个图像块包，多实例学习（MIL）方法已成为WSI分类的合适解决方案。MIL方法的一个主要缺点是它们在不同运行中的性能变异性很高，在测试集上可达到10-15个AUC点，这使得可靠地比较不同的MIL方法变得困难。这种变异性主要来自三个因素：i）权重初始化，ii）批次（混洗）排序，iii）和学习率。为了解决这个问题，我们引入了一种多保真度、模型融合策略用于MIL方法。我们首先训练多个模型几个epochs，并根据验证分数平均最稳定和最有前景的模型。这种方法可以应用于任何现有的MIL模型以减少性能变异性。它还简化了超参数调优并提高了可复现性，同时保持了计算效率。我们在使用2个不同数据集、3种初始化策略和5种MIL方法的WSI分类任务上广泛验证了我们的方法，总共进行了2000多次实验。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [324] [Beyond Low-Rank Tuning: Model Prior-Guided Rank Allocation for Effective Transfer in Low-Data and Large-Gap Regimes](https://arxiv.org/abs/2507.00327)
> *超越低秩调整：模型先验引导的秩分配，实现低数据和大差距场景下的有效迁移*

*Chuyan Zhang, Kefan Wang, Yun Gu* | **Category: cs.CV**

**Keywords:** 低秩适应, LoRA, 稳定秩, 秩分配, 迁移学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** SR-LoRA利用预训练模型的稳定秩作为先验，高效地为LoRA分配层级秩，在低数据量和大领域差距任务中优于现有自适应LoRA方法。

**AI_Comments:** 这篇论文通过引入“稳定秩”这一新的先验信息来指导LoRA的秩分配，提供了一种新颖且高效的自适应LoRA方法。其创新点在于避免了传统自适应方法中常见的计算密集型搜索或正则化，而是利用模型本身的内在特性来优化秩分配。这对于在资源受限或需要快速适应新领域的场景下应用大型模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LoRA方法因其固定的低秩结构，在存在显著领域差距的场景中适应性受限，需要更高的秩来捕获领域特异性复杂性。当前自适应LoRA方法虽然尝试动态扩展或选择性分配秩，但通常依赖计算密集型技术，如迭代剪枝、秩搜索或额外正则化，这增加了计算成本。

**Method:** 本文引入了稳定秩引导的低秩适应（SR-LoRA）框架，该框架利用预训练权重矩阵的稳定秩作为层级秩分配的自然先验。通过利用反映权重内在维度的稳定秩，SR-LoRA能够对跨层的秩进行原理性且高效的重新分配，从而在不产生额外搜索成本的情况下增强适应性。

**Result:** 在具有显著领域差距的少样本任务上的实证评估表明，SR-LoRA持续优于最近的自适应LoRA变体，在性能和效率之间取得了卓越的权衡。

**Conclusion:** SR-LoRA通过利用预训练模型的稳定秩作为先验，提供了一种原理性且高效的秩分配方法，显著提升了LoRA在低数据量和领域差距较大场景下的适应性和性能。

> **ai_Abstract:** 本文提出了SR-LoRA，一个新颖的低秩适应（LoRA）框架，旨在解决LoRA在低数据量和领域差距大场景下适应性受限的问题。SR-LoRA利用预训练模型权重矩阵的稳定秩作为先验，实现了层级秩的高效且有原则的分配，避免了现有自适应LoRA方法中常见的计算密集型搜索过程。实验结果表明，SR-LoRA在性能和效率之间取得了优越的平衡，在少样本和高领域差距任务中表现优于其他自适应LoRA变体。

> **摘要翻译:** 低秩适应（LoRA）已被证明在降低计算成本的同时，能在各种任务中保持与完全微调基础模型相当的性能。然而，其固定的低秩结构限制了其在存在显著领域差距的场景中的适应性，在这些场景中，通常需要更高的秩来捕获领域特定的复杂性。当前的自适应LoRA方法试图通过动态扩展或选择性分配秩来克服这一限制，但这些方法通常依赖于计算密集型技术，如迭代剪枝、秩搜索或额外正则化。为了解决这些这些挑战，我们引入了稳定秩引导的低秩适应（SR-LoRA），这是一个新颖的框架，它利用预训练权重矩阵的稳定秩作为层级秩分配的自然先验。通过利用反映权重内在维度的稳定秩，SR-LoRA能够对跨层的秩进行原理性且高效的重新分配，从而在不产生额外搜索成本的情况下增强适应性。在具有显著领域差距的少样本任务上的实证评估表明，SR-LoRA持续优于最近的自适应LoRA变体，在性能和效率之间取得了卓越的权衡。我们的代码可在https://github.com/EndoluminalSurgicalVision-IMR/SR-LoRA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [329] [MammoTracker: Mask-Guided Lesion Tracking in Temporal Mammograms](https://arxiv.org/abs/2507.00328)
> *MammoTracker：乳腺X线照片中掩膜引导的病灶追踪*

*Xuan Liu, Yinhao Ren, Marc D. Ryser, Lars J. Grimm, Joseph Y. Lo* | **Category: cs.CV**

**Keywords:** 病灶追踪, 乳腺X线照片, 计算机辅助诊断, MammoTracker, 数据集

**Comment:** 

> **TL;DR:** MammoTracker是一个新的框架，用于在时间序列乳腺X线照片中自动追踪病灶，并引入了一个大型数据集，其性能优于基线模型。

**AI_Comments:** 该论文的创新点在于提出了一个名为MammoTracker的掩膜引导病灶追踪框架，并构建了一个目前已知最大的乳腺X线照片时间病灶追踪数据集。数据集的公开可用性对于推动该领域的研究具有重要意义。该方法通过优于基线模型的表现，展示了其在增强计算机辅助诊断系统有效性方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在时间序列乳腺X线照片中准确追踪病灶对于监测乳腺癌进展和促进早期诊断至关重要。然而，在计算机辅助诊断（CAD）系统中，跨检查的自动化病灶对应仍然是一个挑战，限制了其有效性。

**Method:** 本文提出了MammoTracker，一个掩膜引导的病灶追踪框架，可以自动化跨连续检查的病灶定位。该方法采用粗到精的策略，包含三个关键模块：全局搜索、局部搜索和分数细化。为支持大规模训练和评估，研究人员引入了一个新数据集，其中包含来自公共EMBED乳腺X线照片数据集的730例肿块和钙化病例的精心策划的先前检查注释，产生了超过20000个病灶对，使其成为乳腺X线照片中时间病灶追踪的最大已知资源。

**Result:** 实验结果表明，MammoTracker实现了0.455的平均重叠和0.509的准确率，超越基线模型8%，突出了其增强基于CAD的病灶进展分析的潜力。

**Conclusion:** MammoTracker在时间序列乳腺X线照片中实现了高效准确的病灶追踪，显著优于现有基线，有望增强CAD系统中的病灶进展分析。

> **ai_Abstract:** 本研究提出MammoTracker，一个基于掩膜引导的病灶追踪框架，旨在解决时间序列乳腺X线照片中自动病灶对应难题。该框架采用粗到精的策略，包含全局搜索、局部搜索和分数细化三个模块。为支持模型训练和评估，研究人员构建了一个包含超过20000个病灶对的大型新数据集。实验结果显示，MammoTracker在平均重叠和准确率上均优于基线模型8%，显示出其在乳腺癌诊断和监测中的应用潜力。相关数据集将公开可用。

> **摘要翻译:** 在时间序列乳腺X线照片中准确追踪病灶对于监测乳腺癌进展和促进早期诊断至关重要。然而，在计算机辅助诊断（CAD）系统中，跨检查的自动化病灶对应仍然是一个挑战，限制了其有效性。我们提出了MammoTracker，一个掩膜引导的病灶追踪框架，可以自动化跨连续检查的病灶定位。我们的方法遵循粗到精的策略，包含三个关键模块：全局搜索、局部搜索和分数细化。为支持大规模训练和评估，我们引入了一个新数据集，其中包含来自公共EMBED乳腺X线照片数据集的730例肿块和钙化病例的精心策划的先前检查注释，产生了超过20000个病灶对，使其成为乳腺X线照片中时间病灶追踪的最大已知资源。实验结果表明，MammoTracker实现了0.455的平均重叠和0.509的准确率，超越基线模型8%，突出了其增强基于CAD的病灶进展分析的潜力。我们的数据集将在https://gitlab.oit.duke.edu/railabs/LoGroup/mammotracker提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [330] [An Improved U-Net Model for Offline handwriting signature denoising](https://arxiv.org/abs/2507.00365)
> *一种改进的U-Net模型用于离线手写签名去噪*

*Wanghui Xiao* | **Category: cs.CV, eess.IV**

**Keywords:** 手写签名, 去噪, U-Net, 离散小波变换, PCA

**Comment:** 

> **TL;DR:** 改进的U-Net模型结合离散小波变换和PCA增强了离线手写签名去噪，优于传统方法。

**AI_Comments:** 该研究的创新之处在于将离散小波变换（DWT）和PCA集成到U-Net架构中，用于专门的签名去噪，这对于样本质量通常较差的法医学应用至关重要。该方法直接解决了敏感领域中的实际挑战。

<details>
  <summary>Details</summary>

**Motivation:** 手写签名是身份识别的重要手段，但历史样本常混杂大量干扰信息，这给笔迹鉴定工作带来了严峻挑战。

**Method:** 本研究提出一种基于改进U-net结构的手写签名去噪模型，通过引入离散小波变换和PCA变换，增强模型抑制噪声的能力。

**Result:** 实验结果表明，该模型在去噪效果上显著优于传统方法，能有效提高签名图像的清晰度和可读性。

**Conclusion:** 改进的U-Net模型通过有效去噪离线手写签名，为签名分析和识别提供了更可靠的技术支持。

> **ai_Abstract:** 本文旨在解决离线手写签名中存在的噪声问题，该问题阻碍了法医学鉴定。研究提出了一种改进的U-Net模型，通过引入离散小波变换和PCA来增强去噪能力。实验结果表明，该模型在提高签名图像清晰度和可读性方面优于传统方法，从而为可靠的签名分析和识别提供了支持。

> **摘要翻译:** 手写签名作为身份识别的重要手段，因其法律效力和独特性，被广泛应用于金融交易、商业合同和个人事务等多个领域。在法医学鉴定中，离线手写签名的分析要求鉴定人提供一定数量的签名样本，这些样本通常来源于各种历史合同或档案材料。然而，所提供的手写样本常常混杂大量干扰信息，这给笔迹识别工作带来了严峻挑战。本研究提出一种基于改进U-net结构的手写签名去噪模型，旨在增强签名识别系统的鲁棒性。通过引入离散小波变换和PCA变换，模型抑制噪声的能力得到了增强。实验结果表明，该模型在去噪效果上显著优于传统方法，能有效提高签名图像的清晰度和可读性，并为签名分析和识别提供更可靠的技术支持。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [337] [Populate-A-Scene: Affordance-Aware Human Video Generation](https://arxiv.org/abs/2507.00334)
> *Populate-A-Scene: 场景填充：具身感知的人类视频生成*

*Mengyi Shan, Zecheng He, Haoyu Ma, Felix Juefei-Xu, Peizhao Zhang, Tingbo Hou, Ching-Yao Chuang* | **Category: cs.CV**

**Keywords:** 视频生成, 具身感知, 人机交互, 世界模拟器, 文本到视频

**Comment:** Project page: https://shanmy.github.io/Populate-A-Scene

> **TL;DR:** 本文探索了将文本到视频模型重新用作交互式世界模拟器的潜力，通过微调模型以根据场景图像和动作提示生成具身感知的人类视频，无需显式条件。

**AI_Comments:** 这项工作具有创新性，因为它探索了文本到视频模型在具身感知方面的潜力，并提出了一种无需显式条件即可生成具身感知人类视频的方法。其重要性在于，它为创建更智能、更具交互性的虚拟世界模拟器提供了新的途径，并且证明了可以从现有模型中挖掘出潜在的具身感知能力，减少了对昂贵标注数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 探索视频生成模型作为交互式世界模拟器的潜力，特别是通过预测人与环境的交互，以解决现有方法需要显式条件（如边界框或身体姿势）的局限性。

**Method:** 通过微调文本到视频模型，使其在给定场景图像和人类动作提示的情况下，将人物插入场景中，并确保行为、外观、协调性和场景具身感知的一致性。该方法从单个场景图像推断人类具身感知，无需显式条件。通过深度研究交叉注意力热图来揭示预训练视频模型固有的具身感知能力，无需标记的具身感知数据集。

**Result:** 成功揭示了预训练视频模型固有的具身感知能力，且无需标记的具身感知数据集。

**Conclusion:** 本文证明了文本到视频模型可以通过微调，在没有显式条件的情况下，从单一场景图像中推断并生成具身感知的人类与环境交互视频，从而展现了其作为交互式世界模拟器的潜力。

> **ai_Abstract:** 本文研究了将文本到视频模型用作交互式世界模拟器的可能性，通过微调模型使其能够根据场景图像和人类动作提示生成具身感知的人类视频。该方法无需边界框或身体姿势等显式条件，而是从单一场景图像推断人类具身感知。通过分析交叉注意力热图，研究表明可以发现预训练视频模型固有的具身感知能力，且不需要额外的具身感知数据集。

> **摘要翻译:** 视频生成模型能否被重新用作交互式世界模拟器？我们通过训练文本到视频模型预测人与环境的交互，探索了其具身感知潜力。给定一个场景图像和一个描述人类动作的提示，我们微调模型将一个人插入场景中，同时确保行为、外观、协调性和场景具身感知的一致性。与之前的工作不同，我们从单个场景图像中推断出用于视频生成的人类具身感知（即在哪里插入一个人以及他们应该如何表现），而无需像边界框或身体姿势这样的显式条件。对交叉注意力热图的深入研究表明，我们可以在没有标记的具身感知数据集的情况下，揭示预训练视频模型固有的具身感知能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [338] [Efficient Depth- and Spatially-Varying Image Simulation for Defocus Deblur](https://arxiv.org/abs/2507.00372)
> *用于散焦去模糊的有效深度和空间变化图像模拟*

*Xinge Yang, Chuong Nguyen, Wenbin Wang, Kaizhang Kang, Wolfgang Heidrich, Xiaoxing Li* | **Category: cs.CV, eess.IV**

**Keywords:** 图像模拟, 散焦去模糊, 深度学习, 数据集合成, 空间变化像差

**Comment:** 

> **TL;DR:** 提出一种高效、可扩展的数据集合成方法，用于散焦去模糊，解决了现有深度学习模型在真实世界中表现不佳的问题。

**AI_Comments:** 该论文的创新点在于提出了一种无需真实世界数据微调的高效、可扩展的数据集合成方法，同时模拟了深度依赖的散焦和空间变化的像差。这有效解决了深度学习模型在散焦去模糊任务中面临的领域鸿沟和高质量RGB-D数据集稀缺的挑战，对于推动固定焦距相机等应用场景下的图像去模糊技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代相机景深较浅导致图像模糊，尤其固定焦距相机难以增加自动对焦。现有深度学习模型因光学像差和散焦特性不匹配，在真实世界中存在领域鸿沟，表现不佳。

**Method:** 提出一种高效、可扩展的数据集合成方法，该方法不依赖于真实世界数据的微调，同时模拟深度依赖的散焦和空间变化的光学像差，解决了计算复杂性和高质量RGB-D数据集稀缺的问题。

**Result:** 实验结果表明，在低分辨率合成图像上训练的网络能够有效地泛化到高分辨率（12MP）的真实世界图像，适用于不同场景。

**Conclusion:** 该方法通过高效、可扩展的合成数据集生成，成功解决了深度学习模型在散焦去模糊任务中面临的领域鸿沟和数据稀缺问题，实现了良好的真实世界泛化能力。

> **ai_Abstract:** 本文提出一种高效且可扩展的数据集合成方法，用于解决现代相机因景深浅和固定焦距相机限制导致的图像模糊问题。该方法通过同时模拟深度依赖的散焦和空间变化的像差，有效弥补了现有深度学习模型在真实世界应用中的领域鸿沟和数据稀缺性。实验证明，利用该方法合成的低分辨率图像训练出的网络，能成功泛化到高分辨率真实世界图像。

> **摘要翻译:** 现代相机由于大光圈通常景深较浅，导致焦平面外的物体图像模糊。这一限制对于固定焦距相机（如智能眼镜中使用的相机）来说尤其成问题，因为其外形尺寸和功耗限制使得增加自动对焦机制具有挑战性。由于每种相机系统特有的不匹配的光学像差和散焦特性，在现有开源数据集上训练的深度学习模型常常面临领域鸿沟，在真实世界环境中表现不佳。在本文中，我们提出了一种高效且可扩展的数据集合成方法，该方法不依赖于真实世界数据的微调。我们的方法同时模拟了深度依赖的散焦和空间变化的光学像差，解决了计算复杂性和高质量RGB-D数据集稀缺的问题。实验结果表明，在我们的低分辨率合成图像上训练的网络能够有效地泛化到各种场景下的高分辨率（12MP）真实世界图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video](https://arxiv.org/abs/2507.00339)
> *训练X射线视觉：多摄像头视频中的非模态分割、非模态内容补全和视图不变目标表示*

*Alexander Moore, Amar Saini, Kylie Cancilla, Doug Poland, Carmen Carrano* | **Category: cs.CV, cs.AI, 68T45, 68T07, I.2.10; I.2.6; I.4.6**

**Keywords:** 非模态分割, 非模态内容补全, 多摄像头视频, 数据集, MOVi-MC-AC

**Comment:** 9 pages, 2 figures

> **TL;DR:** 本文介绍了MOVi-MC-AC，这是一个用于非模态分割和内容补全的大型多摄像头视频数据集，首次提供了真实非模态内容和跨摄像头一致的对象ID。

**AI_Comments:** MOVi-MC-AC数据集的创新性在于首次将多摄像头视角引入非模态任务，并提供了跨摄像头一致的对象ID和真实非模态内容，这对于训练更鲁棒的“X射线视觉”模型至关重要。它解决了现有剪切-粘贴方法无法处理自然遮挡的局限性，为未来研究提供了高质量的基准。

<details>
  <summary>Details</summary>

**Motivation:** 非模态分割和非模态内容补全需要利用对象先验来估计复杂场景中被遮挡物体的掩码和特征。现有的数据缺乏多摄像头共享场景视图的额外维度，且生成非模态内容伪标签的方法未能考虑模态掩码中存在的自然遮挡。

**Method:** 本文引入了MOVi-MC-AC数据集，这是迄今为止最大的非模态分割数据集和首个非模态内容数据集。该数据集在多摄像头视频中模拟了杂乱的日常家用物品场景，为检测、跟踪和分割提供了跨帧和多摄像头之间一致的对象ID，并首次提供了真实非模态内容标签。

**Result:** MOVi-MC-AC数据集提供了约580万个对象实例的标签，在非模态数据集文献中创下新高，并且是第一个提供真实非模态内容的。该数据集可公开获取。

**Conclusion:** MOVi-MC-AC数据集通过提供多摄像头视角下的真实非模态内容和一致的对象ID，极大地推进了非模态分割和内容补全任务的数据可用性，填补了现有数据集的空白。

> **ai_Abstract:** 本文介绍了MOVi-MC-AC数据集，旨在解决非模态分割和非模态内容补全任务中现有数据缺乏多摄像头上下文和真实非模态内容的问题。该数据集包含模拟的多摄像头视频中约580万个日常物品实例的标签，首次提供了跨帧和多摄像头一致的对象ID以及地面真实非模态内容。MOVi-MC-AC是目前最大的非模态分割数据集和首个非模态内容数据集，为计算机视觉领域贡献了重要资源。

> **摘要翻译:** 非模态分割和非模态内容补全需要使用对象先验来估计复杂场景中被遮挡物体的掩码和特征。到目前为止，还没有数据为对象上下文提供额外的维度：即多个摄像头共享一个场景视图的可能性。我们引入了MOVi-MC-AC：多对象多摄像头非模态内容视频数据集，这是迄今为止最大的非模态分割数据集和首个非模态内容数据集。该数据集在多摄像头视频中模拟了杂乱的日常家用物品场景。MOVi-MC-AC通过为计算机视觉深度学习世界带来两项新贡献，丰富了不断增长的对象检测、跟踪和分割文献。多摄像头（MC）设置，即对象可以在各种独特的摄像头视角之间被识别和跟踪，在合成视频和真实世界视频中都很少见。我们通过为单个场景中具有独特特征和运动模式的帧和多个摄像头之间的检测和分割提供一致的对象ID，为合成视频引入了新的复杂性。非模态内容（AC）是一种重建任务，模型通过遮挡预测目标对象的外观。在非模态分割文献中，一些数据集已经发布了非模态检测、跟踪和分割标签。虽然其他方法依赖于缓慢的剪切-粘贴方案来生成非模态内容伪标签，但它们没有考虑模态掩码中存在的自然遮挡。MOVi-MC-AC为约580万个对象实例提供了标签，在非模态数据集文献中创下了新高，同时也是第一个提供真实非模态内容的。完整数据集可在https://huggingface.co/datasets/Amar-S/MOVi-MC-AC 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [343] [Customizable ROI-Based Deep Image Compression](https://arxiv.org/abs/2507.00373)
> *可定制的基于ROI的深度图像压缩*

*Ian Jin, Fanxin Xia, Feng Ding, Xinfeng Zhang, Meiqin Liu, Yao Zhao, Weisi Lin, Lili Meng* | **Category: cs.CV, eess.IV**

**Keywords:** 基于ROI的压缩, 深度图像压缩, 定制化, 文本控制, 质量权衡

**Comment:** 

> **TL;DR:** 本文提出了一种可定制的基于感兴趣区域（ROI）的深度图像压缩范式，允许用户通过文本定义ROI并控制ROI与非ROI之间的质量权衡。

**AI_Comments:** 本文通过允许用户自定义ROI并灵活控制ROI与非ROI之间的质量权衡，在基于ROI的图像压缩领域引入了显著的创新。利用语义文本定义ROI和实现灵活质量平衡的机制尤为新颖，解决了多样化应用中的关键空白。其重要性在于提供了更具适应性和以用户为中心的压缩解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于ROI的图像压缩方案缺乏对ROI定义和ROI与非ROI之间质量权衡的定制能力，这对于满足多样化的用户偏好（包括人类客户和下游机器任务）至关重要。

**Method:** 本文提出了一种可定制的ROI深度图像压缩范式，包括：1. 文本控制掩码获取（TMA）模块：允许用户通过输入语义文本自定义ROI。2. 可定制值分配（CVA）机制：通过用户决定的可变程度遮罩非ROI，以管理ROI与非ROI之间的重建质量权衡。3. 潜在掩码注意力（LMA）模块：在潜在空间中提取并融合掩码的潜在空间先验和图像的潜在率失真优化（RDO）先验，以优化源图像的潜在表示。

**Result:** 实验结果表明，所提出的可定制的基于ROI的深度图像压缩范式有效解决了ROI定义、掩码获取的定制需求以及ROI与非ROI之间重建质量权衡的管理问题。

**Conclusion:** 本文成功提出了一种可定制的基于感兴趣区域的深度图像压缩范式，通过实现灵活的ROI定义和质量控制，克服了现有方法的局限性，从而满足了多样化的用户需求。

> **ai_Abstract:** 本文介绍了一种可定制的基于感兴趣区域（ROI）的深度图像压缩范式，旨在解决现有方法在ROI定义和质量权衡管理方面的局限性。该系统包含一个文本控制掩码获取（TMA）模块，用于通过文本实现ROI的定制化；一个可定制值分配（CVA）机制，用于灵活平衡ROI与非ROI之间的重建质量；以及一个潜在掩码注意力（LMA）模块，用于优化潜在表示。实验结果验证了其在满足多样化定制需求方面的有效性。

> **摘要翻译:** 基于感兴趣区域（ROI）的图像压缩通过优先考虑ROI以实现更高质量的重建来优化比特分配。然而，随着用户（包括人类客户和下游机器任务）变得更加多样化，基于ROI的图像压缩需要可定制以支持各种偏好。例如，不同的用户可能定义不同的ROI或要求ROI和非ROI之间有不同的质量权衡。现有的基于ROI的图像压缩方案预定义了ROI，使其不可更改，并且缺乏有效机制来平衡ROI和非ROI之间的重建质量。这项工作提出了一种可定制的基于ROI的深度图像压缩范式。首先，我们开发了一个文本控制掩码获取（TMA）模块，该模块允许用户只需输入相应的语义文本即可轻松自定义其用于压缩的ROI。它使编码器受文本控制。其次，我们设计了一个可定制值分配（CVA）机制，该机制以用户决定的可变程度而不是常数来遮罩非ROI，以管理ROI和非ROI之间的重建质量权衡。最后，我们提出了一个潜在掩码注意力（LMA）模块，在该模块中，掩码的潜在空间先验和图像的潜在率失真优化（RDO）先验在潜在空间中被提取和融合，并进一步用于优化源图像的潜在表示。实验结果表明，我们提出的可定制的基于ROI的深度图像压缩范式有效解决了ROI定义和掩码获取的定制需求以及ROI和非ROI之间重建质量权衡管理的需求。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [346] [CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation](https://arxiv.org/abs/2507.00356)
> *CGEarthEye：一个基于吉林一号卫星星座的高分辨率遥感视觉基础模型*

*Zhiwei Yi, Xin Cheng, Jingyu Ma, Ruifei Zhu, Junwei Tian, Yuanxiu Zhou, Xinge Zhao, Hongzhe Li* | **Category: cs.CV, cs.AI**

**Keywords:** 遥感, 基础模型, 吉林一号, 自监督学习, 高分辨率

**Comment:** A Remote Sensing Fundation Model for Very High Resolution Images

> **TL;DR:** CGEarthEye是一个基于吉林一号卫星数据构建的高分辨率遥感视觉基础模型，通过大规模自监督学习和新型数据集JLSSD实现了最先进的性能，有望促进吉林一号数据在地球观测中的应用。

**AI_Comments:** CGEarthEye的创新之处在于其专注于利用吉林一号这一大规模亚米级商业卫星星座的独特数据资源，构建了专为高分辨率遥感设计的视觉基础模型。通过开发大规模多时相自监督学习数据集JLSSD，并结合多种对比学习策略进行预训练，该模型有效地解决了高分辨率遥感图像数据获取受限和标注成本高的问题。其在多项基准测试中达到SOTA性能，显示了其在遥感智能解译领域的巨大潜力，特别是在促进吉ilin-1数据的实际应用方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虽然深度学习极大地推动了遥感智能解译，但超高分辨率光学遥感图像的有限获取渠道阻碍了高分辨率遥感视觉基础模型（RSVFM）的发展。吉林一号星座拥有丰富的亚米级图像资源，为解决这一限制提供了机会。

**Method:** 本研究提出了CGEarthEye，一个专为吉林一号卫星特性设计的RSVFM框架，包含五个不同参数规模的主干网络，总计21亿参数。为增强基础模型的表示能力，开发了JLSSD，这是首个1500万规模的多时相自监督学习（SSL）数据集，具有全球覆盖和季度时间采样。该框架集成了季节对比、基于增强的对比和掩码补丁令牌对比策略进行预训练。

**Result:** CGEarthEye在涵盖四种典型遥感任务的10个基准数据集上进行了全面评估，始终达到最先进（SOTA）的性能。进一步分析表明CGEarthEye在特征可视化、模型收敛、参数效率和实际制图应用方面具有卓越特性。

**Conclusion:** CGEarthEye出色的表示能力有望促进吉林一号数据在传统地球观测应用中更广泛、更高效的应用。

> **ai_Abstract:** 本研究提出了CGEarthEye，一个基于吉林一号卫星星座数据的高分辨率遥感视觉基础模型，旨在解决超高分辨率遥感图像获取受限的问题。CGEarthEye框架包含21亿参数，并利用首个1500万规模的全球覆盖多时相自监督学习数据集JLSSD进行预训练。通过集成多种对比学习策略，CGEarthEye在10个遥感基准数据集上实现了最先进的性能，并在特征可视化、模型收敛和参数效率等方面表现出色，有望推动吉林一号数据在地球观测领域的广泛应用。

> **摘要翻译:** 深度学习方法极大地推动了遥感（RS）智能解译的发展，基于大规模预训练范式的基础模型研究正在迅速重塑地球观测（EO）的各个领域。然而，与中分辨率数据的开放可访问性和高时空覆盖率相比，超高分辨率光学遥感图像的有限获取渠道限制了高分辨率遥感视觉基础模型（RSVFM）的进展。作为全球最大的亚米级商业遥感卫星星座，吉林一号星座拥有丰富的亚米级图像资源。本研究提出了CGEarthEye，一个专为吉林一号卫星特性设计的高分辨率遥感视觉基础模型框架，包含五个不同参数规模的主干网络，总计21亿参数。为了增强基础模型的表示能力，我们开发了JLSSD，这是首个1500万规模的多时相自监督学习（SSL）数据集，具有全球覆盖和一年内季度时间采样，通过多级表示聚类和采样策略构建。该框架集成了季节对比、基于增强的对比和掩码补丁令牌对比策略进行预训练。在涵盖四种典型遥感任务的10个基准数据集上进行的全面评估表明，CGEarthEye始终实现最先进（SOTA）的性能。进一步分析揭示了CGEarthEye在特征可视化、模型收敛、参数效率和实际制图应用方面的卓越特性。本研究预计CGEarthEye卓越的表示能力将促进吉林一号数据在传统地球观测应用中更广泛、更高效的应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [Latent Posterior-Mean Rectified Flow for Higher-Fidelity Perceptual Face Restoration](https://arxiv.org/abs/2507.00447)
> *潜在后验均值修正流用于更高保真度的感知人脸修复*

*Xin Luo, Menglin Zhang, Yunwei Lan, Tianyu Zhang, Rui Li, Chang Liu, Dong Liu* | **Category: cs.CV, eess.IV**

**Keywords:** 人脸修复, 感知-失真权衡, 潜在空间, 变分自编码器, 修正流

**Comment:** Code and Models will be publicly available at
  https://github.com/Luciennnnnnn/Latent-PMRF

> **TL;DR:** 提出Latent-PMRF，在潜在空间中重构PMRF，以更好平衡感知质量和保真度，并显著提高收敛效率。

**AI_Comments:** 本文的创新点在于将PMRF从像素空间提升到潜在空间，并强调了VAE设计对性能的关键影响，这为人脸修复领域提供了新的视角。通过在潜在空间操作，模型能够更有效地捕捉人类感知，同时显著提升了训练效率，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的PMRF方法在像素空间建模，限制了其与人类感知的对齐能力，导致在感知-失真权衡（PD-tradeoff）上表现不佳。

**Method:** 提出Latent-PMRF，将PMRF重构到变分自编码器（VAE）的潜在空间中，通过在最小失真估计的潜在表示上定义源分布，将最小失真限制在VAE的重建误差内。同时，设计了一种新的、性能更优的VAE。

**Result:** Latent-PMRF在盲人脸修复方面表现出优越性，提供了比现有方法更好的PD-tradeoff，并具有显著的收敛效率，在FID方面比PMRF加速5.79倍。

**Conclusion:** Latent-PMRF通过在潜在空间中重构PMRF并结合优化的VAE设计，有效解决了感知-失真权衡问题，显著提升了人脸修复的性能和效率。

> **ai_Abstract:** 本文提出了Latent-PMRF，一种在变分自编码器（VAE）潜在空间中重构的后验均值修正流（PMRF）方法，旨在解决人脸修复中的感知-失真权衡问题。通过在潜在空间进行建模并优化VAE设计，Latent-PMRF能更好地与人类感知对齐，从而在实现更高保真度的同时保持感知质量。实验证明，Latent-PMRF在盲人脸修复中表现出优越性，改进了PD-tradeoff，并显著提高了收敛效率。

> **摘要翻译:** 感知-失真权衡（PD-tradeoff）理论表明，人脸修复算法必须平衡感知质量和保真度。为了在保持完美感知质量的同时实现最小失真，后验均值修正流（PMRF）提出了一种基于流的方法，其中源分布是最小失真估计。尽管PMRF已被证明有效，但其像素空间建模方法限制了其与人类感知的对齐能力，其中人类感知被定义为人类区分两种图像分布的方式。在这项工作中，我们提出了Latent-PMRF，它在变分自编码器（VAE）的潜在空间中重新构建了PMRF，从而在优化过程中更好地与人类感知对齐。通过在最小失真估计的潜在表示上定义源分布，我们将最小失真限制在VAE的重建误差内。此外，我们揭示了VAE的设计至关重要，我们提出的VAE在重建和修复方面都显著优于现有VAE。对盲人脸修复的广泛实验证明了Latent-PMRF的优越性，与现有方法相比，它提供了改进的PD-tradeoff，并具有显著的收敛效率，在FID方面比PMRF加速5.79倍。我们的代码将作为开源提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [348] [Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters](https://arxiv.org/abs/2507.00792)
> *虚拟人体角色多约束运动生成的实时逆运动学*

*Hendric Voss, Stefan Kopp* | **Category: cs.CV, cs.HC**

**Keywords:** 逆运动学, 实时, 虚拟人体, 多约束运动, TensorFlow

**Comment:** 

> **TL;DR:** 本文提出了一种利用TensorFlow的实时逆运动学（IK）求解器，用于生成逼真的多约束虚拟人体运动，该方法在速度和成功率方面优于现有方法。

**AI_Comments:** 本文通过将IK视为可微分操作，并利用TensorFlow等现代深度学习框架，为实时逆运动学提供了一种创新方法。这使得能够高效处理复杂人体模型和多约束问题，克服了传统迭代方法的常见局限性。其实时性能和更高的鲁棒性对于需要逼真人体运动生成的应用来说是重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机图形学、交互式虚拟环境、机器人学和生物力学等应用中，生成准确逼真的实时虚拟人体运动至关重要。现有方法在处理多约束问题时面临误差累积和复杂关节限制等挑战。

**Method:** 本文介绍了一种新颖的实时逆运动学（IK）求解器。该求解器利用TensorFlow的自动微分和即时编译功能，将正向和逆向运动学视为可微分操作。它旨在高效处理具有高自由度的复杂关节式人体骨骼，并解决误差累积和复杂关节限制等问题。该求解器在SMPLX人体骨骼模型上进行了演示，并与循环坐标下降（CCD）、FABRIK和IPOPT等迭代IK算法进行了性能比较。

**Result:** 所提出的IK求解器实现了实时性能，表现出快速收敛、每次迭代计算开销最小，并且与现有方法（CCD、FABRIK、IPOPT）相比，在简单末端执行器任务和复杂的、具有逼真关节限制的多约束问题上均取得了更高的成功率。

**Conclusion:** 本文成功开发了一种实时、鲁棒的逆运动学求解器，显著改善了逼真多约束虚拟人体运动的生成，克服了以往方法的常见局限性。

> **ai_Abstract:** 本文提出了一种新颖的实时逆运动学（IK）求解器，用于生成逼真的多约束虚拟人体运动。该求解器利用TensorFlow的自动微分和即时编译功能，能够高效处理复杂人体骨骼，并有效解决误差累积和关节限制等问题。在SMPLX模型上的实验表明，该IK求解器实现了实时性能，具有更快的收敛速度、更低的计算开销和更高的成功率，优于传统的迭代IK算法。

> **摘要翻译:** 生成准确逼真的实时虚拟人体运动对于计算机图形学、交互式虚拟环境、机器人学和生物力学中的各种应用都至关重要。本文介绍了一种新颖的实时逆运动学（IK）求解器，专门设计用于生成逼真的人体运动。该求解器利用TensorFlow的自动微分和即时编译功能，能够高效处理具有高自由度的复杂关节式人体骨骼。通过将正向和逆向运动学视为可微分操作，我们的方法有效解决了多约束问题中常见的误差累积和复杂关节限制等挑战，这些对于逼真的人体运动建模至关重要。我们在SMPLX人体骨骼模型上展示了该求解器的有效性，并将其性能与广泛使用的基于迭代的IK算法（如循环坐标下降（CCD）、FABRIK和非线性优化算法IPOPT）进行了评估。我们的实验涵盖了简单的末端执行器任务和复杂的、具有逼真关节限制的多约束问题。结果表明，我们的IK求解器实现了实时性能，表现出快速收敛、每次迭代计算开销最小，并且与现有方法相比成功率更高。项目代码可在https://github.com/hvoss-techfak/TF-JAX-IK获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [352] [GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And Dynamic Density Control](https://arxiv.org/abs/2507.00363)
> *GDGS：通过几何引导初始化和动态密度控制的3D高斯泼溅*

*Xingjun Wang, Lianlei Shan* | **Category: cs.CV**

**Keywords:** 3D Gaussian Splatting, 实时渲染, 几何引导, 密度控制, 表面对齐

**Comment:** 

> **TL;DR:** GDGS通过几何引导初始化、表面对齐优化和动态密度控制改进了3D高斯泼溅，实现了高保真实时渲染和更好的视觉质量。

**AI_Comments:** 这篇论文通过引入几何引导初始化、表面对齐优化和动态密度控制，显著提升了3D高斯泼溅的性能和鲁棒性。其创新之处在于系统性地解决了3DGS在表示精度和效率方面的核心痛点，尤其是在复杂场景下的实时渲染能力，这对于虚拟现实、增强现实和电影制作等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅（3DGS）在初始化、优化非结构化高斯分布为有序表面以及自适应密度控制方面存在挑战，导致需要更精确的放置和更快的收敛。

**Method:** GDGS方法包括：1) 几何引导初始化，用于预测高斯参数，确保精确放置和更快收敛。2) 表面对齐优化策略，细化高斯放置，提高几何精度并与场景表面法线对齐。3) 动态自适应密度控制机制，根据区域复杂度调整高斯密度，以实现视觉保真度。

**Result:** GDGS方法实现了高保真实时渲染，显著改善了视觉质量，即使在复杂场景中也是如此。它与最先进的方法相比，表现出相当或更优异的结果，实时渲染高保真图像。

**Conclusion:** GDGS通过其创新的初始化、优化和密度控制机制，有效解决了3DGS的局限性，在实时高保真渲染方面取得了显著进展。

> **ai_Abstract:** 本文提出GDGS，一种改进3D高斯泼溅(3DGS)的方法，旨在解决其在初始化、优化和密度控制上的缺陷。GDGS引入了几何引导初始化以实现精确放置和快速收敛，表面对齐优化以提高几何精度，以及动态自适应密度控制以优化视觉保真度。这些改进使GDGS能够实现高保真实时渲染，并在视觉质量上超越现有技术。

> **摘要翻译:** 我们提出了一种增强3D高斯泼溅（3DGS）的方法，解决了初始化、优化和密度控制方面的挑战。高斯泼溅是渲染逼真图像同时支持实时性能的替代方案，并因其明确的3D高斯表示而广受欢迎。然而，3DGS严重依赖精确的初始化，并且在将非结构化高斯分布优化为有序表面方面面临困难，迄今为止提出的自适应密度控制机制有限。我们的第一个关键贡献是几何引导初始化，用于预测高斯参数，确保精确放置和更快收敛。然后，我们引入表面对齐优化策略，以细化高斯放置，提高几何精度并与场景的表面法线对齐。最后，我们提出了一种动态自适应密度控制机制，根据区域复杂度调整高斯密度，以实现视觉保真度。这些创新使我们的方法能够实现高保真实时渲染，并在视觉质量方面取得显著改进，即使在复杂场景中也是如此。我们的方法展示了与最先进方法相当或更优异的结果，实时渲染高保真图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [353] [Just Noticeable Difference for Large Multimodal Models](https://arxiv.org/abs/2507.00490)
> *大型多模态模型的最小可觉差*

*Zijian Chen, Yuan Tian, Yuze Sun, Wei Sun, Zicheng Zhang, Weisi Lin, Guangtao Zhai, Wenjun Zhang* | **Category: cs.CV, eess.IV**

**Keywords:** 最小可觉差, 大型多模态模型, 视觉感知, LMM-JND, VPA-JND

**Comment:** 19 pages, 19 figures

> **TL;DR:** 该研究引入LMM-JND概念和VPA-JND数据集，揭示大型多模态模型在视觉感知上存在显著盲点，且远低于人类水平，对模型安全和未来改进至关重要。

**AI_Comments:** 这项研究通过引入LMM-JND概念和构建VPA-JND数据集，开创性地系统量化了大型多模态模型在视觉感知上的缺陷。其创新之处在于将传统的JND概念拓展到机器视觉领域，并揭示了现有LMMs（包括SOTA模型）与人类视觉性能的巨大差距。这项工作对于未来LMMs的设计优化、提高其鲁棒性和安全性具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究缺乏系统性探索大型多模态模型（LMMs）在多任务和刺激类型上的感知边界，尤其是在LMMs快速发展且其感知缺陷未被充分研究的背景下，这可能导致安全问题和次优的响应效率。

**Method:** 提出了一个新的概念“LMM-JND”及其确定流程，用于量化LMM的视觉盲点。构建了一个名为VPA-JND的大规模数据集，包含21.5k参考图像和超过489k个刺激，涵盖12种失真类型。使用VPA-JND数据集测试了包括GPT-4o和InternVL2.5系列在内的LMM家族。进一步探讨了视觉和语言骨干网络对LMM-JND的影响。

**Result:** 目前的LMMs存在显著的视觉盲点。LMMs（包括GPT-4o和InternVL2.5系列）在基本比较查询上表现不佳，且远低于人类水平的视觉性能。发现视觉和语言骨干网络的设计理念之间存在显著相关性，这可能指导未来LMM视觉敏锐度的改进。

**Conclusion:** LMM-JND是研究LMMs的一个独特视角，可预测的LMM-JND对于安全问题至关重要。

> **ai_Abstract:** 本文首次系统性地探究了大型多模态模型（LMMs）的视觉感知边界，引入了“LMM-JND”概念及其确定流程。通过构建大规模VPA-JND数据集并测试主流LMMs（如GPT-4o），研究发现LMMs存在显著的视觉盲点，其视觉性能远低于人类水平。研究还揭示了视觉和语言骨干网络设计对LMMs视觉敏锐度的影响。这项工作强调了LMM-JND在理解LMMs感知缺陷和解决安全问题方面的重要性。

> **摘要翻译:** 最小可觉差（JND）是人类视觉系统（HVS）能够感知的最小变化，已研究数十年。尽管最近的工作已将此研究扩展到机器视觉领域，但系统性探索其在多任务和刺激类型上的感知边界的研究却很稀缺，尤其是在当前大型多模态模型（LMMs）快速发展的时代，研究模型的多方面能力已成为主流焦点。此外，LMMs的感知缺陷尚未得到彻底调查，导致潜在的安全问题和次优的响应效率。在本文中，我们首次尝试并证明了当前LMMs中存在显著的视觉盲点。为了系统地量化这一特性，我们提出了一个新的概念，{\bf LMM-JND}，以及其确定流程。为了揭示与HVS对齐的视觉感知任务中的行为共性，我们深入研究了多个LMM家族，并构建了一个名为VPA-JND的大规模数据集，该数据集包含21.5k张参考图像和超过489k个刺激，涵盖12种失真类型，以促进LMM-JND研究。VPA-JND揭示了包括GPT-4o和InternVL2.5系列在内的最先进LMMs在基本比较查询上表现不佳，并且显著低于人类水平的视觉性能。我们进一步探讨了视觉和语言骨干网络的影响，并发现它们的设计理念之间存在显著相关性，这可能指导未来LMMs视觉敏锐度的改进。总而言之，我们的研究强调了LMM-JND作为研究LMMs独特视角的重要性，以及可预测的LMM-JND对于安全问题至关重要。这项工作将在https://github.com/zijianchen98/LMM-JND 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [362] [Out-of-Distribution Detection with Adaptive Top-K Logits Integration](https://arxiv.org/abs/2507.00368)
> *离群样本检测与自适应Top-K Logits集成*

*Hikaru Shijo, Yutaka Yoshihama, Kenichi Yadani, Norifumi Murata* | **Category: cs.CV**

**Keywords:** 离群样本检测, Logits集成, 神经网络, MaxLogit, FPR95

**Comment:** 

> **TL;DR:** 提出ATLI方法，通过自适应集成Top-K Logits，显著提升了神经网络离群样本检测的准确性，优于MaxLogit和现有SOTA方法。

**AI_Comments:** 本文的创新点在于发现了最大logit之外的其他logit对OOD检测的有用性，并基于此提出了一种自适应集成Top-k logits的方法。ATLI通过动态选择和结合logits，相比单一的最大logit或固定Top-k策略，展现了更好的泛化能力和性能提升，对于提高机器学习模型的鲁棒性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络常对离群样本做出过度自信的预测，这降低了机器学习的安全性。研究发现，除了最大logit，其他logit也对离群样本检测有用。

**Method:** 本文提出ATLI（Adaptive Top-k Logits Integration）方法，该方法自适应地确定对每个模型有效的Top-K logits，并将最大logit与其他Top-K logits结合起来以提高离群检测性能。

**Result:** 在ImageNet-1K基准测试中，ATLI方法与MaxLogit相比，FPR95降低了6.73%；与现有最先进方法相比，FPR95额外降低了2.67%。

**Conclusion:** ATLI方法通过有效集成自适应Top-K Logits，显著提高了离群样本检测的性能，超越了MaxLogit和现有SOTA方法，从而增强了机器学习的安全性。

> **ai_Abstract:** 本文提出了一种名为ATLI（Adaptive Top-k Logits Integration）的离群样本检测新方法，旨在解决神经网络对离群样本过度自信预测的问题。研究发现，除了最大logit外，其他logit也对离群检测有效。ATLI方法能够自适应地确定并整合对特定模型有效的Top-k logits。在ImageNet-1K基准上的实验结果表明，ATLI在假阳性率（FPR95）方面显著优于MaxLogit和其他现有先进方法，从而提升了机器学习的安全性。

> **摘要翻译:** 神经网络经常对离群（OOD）样本做出过度自信的预测。因此，离群数据检测对于提高机器学习的安全性至关重要。最简单且最强大的离群检测方法是MaxLogit，它使用模型的最大logit来提供离群分数。我们发现，除了最大logit之外，其他一些logit也对离群检测有用。基于这一发现，我们提出了一种名为ATLI（自适应Top-k Logits集成）的新方法，该方法自适应地确定特定于每个模型的有效Top-k logits，并将最大logit与其他Top-k logits结合起来。在本研究中，我们使用ImageNet-1K基准测试评估了我们提出的方法。大量实验表明，我们提出的方法与MaxLogit方法相比，假阳性率（FPR95）降低了6.73%，与现有最先进方法相比，FPR95额外降低了2.67%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [365] [Multi-Modal Graph Convolutional Network with Sinusoidal Encoding for Robust Human Action Segmentation](https://arxiv.org/abs/2507.00752)
> *用于鲁棒人体动作分割的多模态图卷积网络与正弦编码*

*Hao Xing, Kai Zhe Boey, Yuankai Wu, Darius Burschka, Gordon Cheng* | **Category: cs.CV, cs.RO**

**Keywords:** 动作分割, 多模态, 图卷积网络, 正弦编码, 数据增强

**Comment:** 7 pages, 4 figures, accepted in IROS25, Hangzhou, China

> **TL;DR:** 本文提出了一种多模态图卷积网络（MMGCN），结合正弦编码和SmoothLabelMix数据增强，以提高人体动作分割的鲁棒性并减少过分割错误。

**AI_Comments:** 该论文通过引入多模态融合、新颖的正弦编码和创新的SmoothLabelMix数据增强技术，有效解决了人体动作分割中的核心挑战，即噪声导致的过分割问题。其方法在处理不同帧率数据和提升时间一致性方面具有显著创新性。

<details>
  <summary>Details</summary>

**Motivation:** 在协作环境中，智能机器人需要精确理解子活动标签及其时间结构。然而，人体姿态估计和目标检测中固有的噪声常导致过分割错误，破坏动作序列的连贯性。

**Method:** 本文提出了一种多模态图卷积网络（MMGCN），它融合了低帧率视觉数据和高帧率运动数据（骨架和目标检测）。主要贡献包括：1. 正弦编码策略，将3D骨架坐标映射到连续的正弦-余弦空间，增强空间表示鲁棒性。2. 时间图融合模块，通过分层特征聚合对齐不同分辨率的多模态输入。3. SmoothLabelMix数据增强技术，混合输入序列和标签生成具有渐进动作过渡的合成训练样本，以增强时间一致性并减少过分割。

**Result:** 在Bimanual Actions Dataset上进行了广泛实验，结果表明该方法优于现有最先进方法，尤其在动作分割精度方面，F1@10达到94.5%，F1@25达到92.8%。

**Conclusion:** 本文提出的多模态图卷积网络结合正弦编码和SmoothLabelMix数据增强，有效解决了人体动作分割中的噪声和过分割问题，显著提升了分割精度和鲁棒性。

> **ai_Abstract:** 本文提出了一种多模态图卷积网络（MMGCN）用于鲁棒的人体动作分割，旨在解决姿态估计和目标检测噪声导致的过分割问题。该网络融合了低帧率视觉数据和高帧率运动数据，并引入了三项关键创新：正弦编码策略以增强3D骨架表示的鲁棒性；时间图融合模块以对齐多模态输入；以及SmoothLabelMix数据增强技术以生成具有平滑过渡的训练样本，从而提高时间一致性。实验结果表明，该方法在动作分割精度上显著优于现有SOTA方法。

> **摘要翻译:** 准确地对人类动作进行时间分割对于协作环境中的智能机器人至关重要，在这种环境中，精确理解子活动标签及其时间结构是必不可少的。然而，人体姿态估计和目标检测中固有的噪声常常导致过分割错误，破坏动作序列的连贯性。为了解决这个问题，我们提出了一种多模态图卷积网络（MMGCN），它将低帧率（例如，1 fps）视觉数据与高帧率（例如，30 fps）运动数据（骨架和目标检测）相结合，以减轻碎片化。我们的框架提出了三项关键贡献。首先，一种正弦编码策略，将3D骨架坐标映射到连续的正弦-余弦空间，以增强空间表示的鲁棒性。其次，一个时间图融合模块，通过分层特征聚合来对齐不同分辨率的多模态输入。第三，受人类动作固有的平滑过渡的启发，我们设计了SmoothLabelMix，这是一种数据增强技术，通过混合输入序列和标签来生成具有渐进行动过渡的合成训练样本，从而增强预测的时间一致性并减少过分割伪影。在Bimanual Actions Dataset（一个用于人-物交互理解的公共基准）上进行的大量实验表明，我们的方法优于现有最先进的方法，尤其在动作分割精度方面，F1@10达到94.5%，F1@25达到92.8%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching](https://arxiv.org/abs/2507.00371)
> *PlantSegNeRF：一种用于植物3D实例点云重建的少样本、跨数据集方法，通过联合通道NeRF与多视角图像实例匹配实现*

*Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang, Yu Jiang, Haiyan Cen* | **Category: cs.CV**

**Keywords:** 植物点云, 实例分割, 神经辐射场, 3D重建, 表型分析

**Comment:** 

> **TL;DR:** PlantSegNeRF是一种新方法，能从多视角RGB图像序列直接生成高精度植物实例点云，解决了现有方法在分辨率、分割精度和泛化性上的局限性，并在语义和实例分割任务中表现优异。

**AI_Comments:** PlantSegNeRF的创新之处在于结合了2D实例分割、多视角实例匹配和神经辐射场（NeRF）技术，实现了从多视角图像直接重建高精度植物3D实例点云。其跨数据集和少样本的特性增强了方法的泛化能力，对植物表型研究具有重要意义，为植物科学领域的大规模模型开发提供了高质量的数据基础。

<details>
  <summary>Details</summary>

**Motivation:** 植物点云的器官分割是高分辨率和准确提取器官级表型性状的前提。尽管深度学习发展迅速，但现有植物点云器官分割技术在分辨率、分割精度和跨植物物种泛化性方面仍存在局限性。

**Method:** 本研究提出了一种名为PlantSegNeRF的新方法，旨在从多视角RGB图像序列直接生成高精度实例点云。PlantSegNeRF首先对多视角图像进行2D实例分割以生成带ID的器官实例掩膜。然后，通过专门设计的实例匹配模块对对应同一植物器官的多视角实例ID进行匹配和精炼。接着，开发了实例NeRF来渲染包含颜色、密度、语义和实例信息的隐式场景。最后，根据体积密度将隐式场景转换为高精度植物实例点云。

**Result:** 在点云语义分割方面，PlantSegNeRF在结构复杂的数据集上，与次优结果相比，在精度、召回率、F1-分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，在植物点云实例分割任务中，PlantSegNeRF表现出显著优势，在所有植物数据集上，mPrec、mRec、mCov和mWCov平均分别提高了11.7%、38.2%、32.2%和25.3%。

**Conclusion:** 本研究扩展了器官级植物表型分析，并提供了一种高通量的方法，为植物科学中大型模型的开发提供高质量的3D数据。

> **ai_Abstract:** 本研究提出了一种名为PlantSegNeRF的新颖方法，旨在解决现有植物点云器官分割技术在分辨率、精度和泛化性方面的不足。该方法通过对多视角RGB图像进行2D实例分割、实例匹配和基于NeRF的隐式场景渲染，直接生成高精度的植物实例点云。实验结果表明，PlantSegNeRF在点云语义分割和实例分割任务中均显著优于现有方法，为器官级植物表型分析和大规模植物科学模型开发提供了高质量的3D数据。

> **摘要翻译:** 植物点云的器官分割是高分辨率和准确提取器官级表型性状的先决条件。尽管深度学习的快速发展推动了许多关于植物点云分割的研究，但现有的器官分割技术在分辨率、分割精度和跨各种植物物种的泛化性方面仍然面临局限性。在本研究中，我们提出了一种名为植物分割神经辐射场（PlantSegNeRF）的新方法，旨在从多视角RGB图像序列直接生成各种植物物种的高精度实例点云。PlantSegNeRF对多视角图像执行2D实例分割，为每个器官生成带有对应ID的实例掩膜。然后，使用专门设计的实例匹配模块对对应同一植物器官的多视角实例ID进行匹配和精炼。开发了实例NeRF来渲染一个隐式场景，其中包含颜色、密度、语义和实例信息。最终，根据体积密度将隐式场景转换为高精度植物实例点云。结果证明，在点云语义分割方面，PlantSegNeRF优于常用方法，在结构复杂的数据集上，与次优结果相比，在精度、召回率、F1-分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，PlantSegNeRF在植物点云实例分割任务中表现出显著优势。在所有植物数据集上，它在mPrec、mRec、mCov和mWCov方面平均分别实现了11.7%、38.2%、32.2%和25.3%的改进。这项研究扩展了器官级植物表型分析，并提供了一种高通量的方法，为植物科学中大型模型的开发提供高质量的3D数据。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [Towards Open-World Human Action Segmentation Using Graph Convolutional Networks](https://arxiv.org/abs/2507.00756)
> *迈向基于图卷积网络的开放世界人体动作分割*

*Hao Xing, Kai Zhe Boey, Gordon Cheng* | **Category: cs.CV, cs.RO**

**Keywords:** 开放世界动作分割, 图卷积网络, 人体-物体交互, 分布外检测, 半监督学习

**Comment:** 8 pages, 3 figures, accepted in IROS25, Hangzhou, China

> **TL;DR:** 本文提出了一个基于图卷积网络的框架，用于在无需手动标注的情况下，在开放世界场景中检测和分割未见过的（OOD）人体动作，并在开放集评估指标上取得了显著提升。

**AI_Comments:** 这篇论文通过引入EPGCN、Mixup训练和时间聚类损失，为开放世界人体动作分割提供了一个创新且实用的解决方案。其核心创新在于无需手动标注即可处理未见动作的能力，这对于实际应用中动态多变的场景至关重要。实验结果的显著提升也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习方法在封闭世界动作分割中表现出色，但难以泛化到新动作出现的开放世界场景。由于人类活动的动态多样性，收集详尽的动作类别进行训练是不切实际的，因此需要能够检测和分割分布外动作而无需手动标注的模型。

**Method:** 提出了一个结构化框架来检测和分割未见过的动作。该框架包含三项创新：1) 增强金字塔图卷积网络（EPGCN）及新颖的解码器模块，用于鲁棒的时空特征上采样；2) 基于Mixup的训练，用于合成分布外数据，消除对手动标注的依赖；3) 新颖的时间聚类损失，用于聚合同分布动作并使分布外样本保持距离。

**Result:** 在Bimanual Actions和H2O数据集上进行了评估。实验结果表明，在多个开放集评估指标上，相对于最先进的动作分割模型有显著改进，在开放集分割（F1@50）和分布外检测性能（AUROC）方面分别实现了16.9%和34.6%的相对增益。此外，还进行了深入的消融研究。

**Conclusion:** 该论文成功地定义了开放世界动作分割问题，并提出了一个有效的框架，通过EPGCN、Mixup训练和时间聚类损失，显著提升了在开放世界场景中检测和分割未见动作的能力，且无需手动标注。

> **ai_Abstract:** 本文针对现有方法在开放世界人体动作分割中识别新动作的局限性，正式定义了该问题并提出了一个创新的结构化框架。该框架结合了增强金字塔图卷积网络（EPGCN）进行特征上采样、基于Mixup的训练生成分布外数据，以及时间聚类损失以区分已知和未知动作。实验结果表明，该方法在开放集分割和分布外检测性能上显著优于现有技术，证明了其在无需手动标注下处理开放世界动作分割的有效性。

> **摘要翻译:** 人体-物体交互分割是理解日常活动的一项基本任务，在辅助机器人、医疗保健和自主系统等应用中发挥着关键作用。大多数现有的基于学习的方法在封闭世界动作分割中表现出色，但它们难以泛化到新动作出现的开放世界场景。由于人类活动的动态多样性，收集详尽的动作类别进行训练是不切实际的，这使得模型需要能够在没有手动标注的情况下检测和分割分布外动作。为了解决这个问题，我们正式定义了开放世界动作分割问题，并提出了一个用于检测和分割未见动作的结构化框架。我们的框架引入了三项关键创新：1) 带有新颖解码器模块的增强金字塔图卷积网络（EPGCN），用于鲁棒的时空特征上采样。2) 基于Mixup的训练，用于合成分布外数据，消除了对手动标注的依赖。3) 一种新颖的时间聚类损失，用于聚合同分布动作，同时使分布外样本保持距离。我们在两个具有挑战性的人体-物体交互识别数据集上评估了我们的框架：Bimanual Actions和2 Hands and Object (H2O) 数据集。实验结果表明，在多个开放集评估指标上，相对于最先进的动作分割模型有显著改进，在开放集分割（F1@50）和分布外检测性能（AUROC）方面分别实现了16.9%和34.6%的相对增益。此外，我们还进行了深入的消融研究，以评估每个提出组件的影响，确定了开放世界动作分割的最佳框架配置。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond](https://arxiv.org/abs/2507.00886)
> *GaussianVLM：面向场景的3D视觉-语言模型，使用语言对齐高斯泼溅点用于具身推理及更广阔的应用*

*Anna-Maria Halacheva, Jan-Nico Zaech, Xi Wang, Danda Pani Paudel, Luc Van Gool* | **Category: cs.CV, cs.RO**

**Keywords:** 3D Vision-Language Models, Gaussian Splatting, Scene-centric, Embodied Reasoning, Multimodal Alignment

**Comment:** 

> **TL;DR:** GaussianVLM是一个面向场景的3D视觉-语言模型，它通过将语言特征嵌入高斯泼溅点来解决现有3D VLM对物体检测器的依赖，并显著提升了性能。

**AI_Comments:** 这项工作通过引入基于高斯泼溅点的VLM，为3D视觉-语言模型领域带来了创新。其核心贡献在于将语言特征直接嵌入到3D场景表示的底层（高斯基元），实现了更早和更深层次的模态对齐，避免了对物体检测器的依赖，从而解决了现有方法的瓶颈和灵活性问题。双重稀疏器的引入也有效地处理了由此产生的密集表示。性能上的显著提升，尤其是在域外设置下的表现，进一步凸显了其重要性和潜力，为具身推理等应用奠定了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多模态语言模型在3D场景理解中的应用面临挑战，主要表现为现有3D视觉-语言模型（VLMs）对物体检测器有强烈依赖，这导致了处理瓶颈和分类灵活性的限制。

**Method:** 本文提出了GaussianVLM，一个面向场景的3D VLM，用于3D高斯泼溅点场景。该模型采用语言和任务感知的场景表示，通过将丰富的语言特征直接嵌入到每个高斯基元中，实现了早期模态对齐。为处理由此产生的密集表示，引入了一个双重稀疏器，通过任务引导和位置引导路径将其提炼成紧凑、与任务相关的稀疏全局和局部场景token。这是首个基于高斯泼溅点的VLM。

**Result:** GaussianVLM展示了强大的泛化能力，利用从标准RGB图像导出的真实感3D表示，在域外设置下将先前3D VLM的性能提高了五倍。

**Conclusion:** GaussianVLM通过创新性地将语言特征与高斯泼溅点结合，并引入双重稀疏器，成功解决了现有3D VLM对物体检测器的依赖性及相关瓶颈，显著提升了3D场景理解和具身推理的性能和泛化能力。

> **ai_Abstract:** 本文提出了GaussianVLM，一个面向场景的3D视觉-语言模型，旨在克服现有3D VLM对物体检测器的依赖。该模型通过将语言特征直接嵌入到3D高斯泼溅点中实现早期模态对齐，并引入双重稀疏器将密集表示提炼为稀疏、任务感知的token。GaussianVLM是首个基于高斯泼溅点的VLM，它利用RGB图像生成逼真的3D表示，并在域外设置中将现有3D VLM的性能提升了五倍，展现出强大的泛化能力。

> **摘要翻译:** 随着多模态语言模型的进步，它们在3D场景理解中的应用是一个快速发展的前沿，推动了3D视觉-语言模型（VLMs）的发展。当前的方法对物体检测器表现出强烈的依赖，引入了处理瓶颈和分类灵活性的限制。为了解决这些限制，我们提出了一种面向场景的3D VLM，用于3D高斯泼溅点场景，该模型采用了语言和任务感知的场景表示。我们的方法通过将语言与每个高斯基元关联，将丰富的语言特征直接嵌入到3D场景表示中，实现了早期模态对齐。为了处理由此产生的密集表示，我们引入了一个双重稀疏器，通过任务引导和位置引导路径将其提炼成紧凑、与任务相关的token，生成稀疏、任务感知的全局和局部场景token。值得注意的是，我们提出了第一个基于高斯泼溅点的VLM，它利用从标准RGB图像导出的真实感3D表示，展示了强大的泛化能力：它在域外设置下将先前3D VLM的性能提高了五倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [378] [MedDiff-FT: Data-Efficient Diffusion Model Fine-tuning with Structural Guidance for Controllable Medical Image Synthesis](https://arxiv.org/abs/2507.00377)
> *MedDiff-FT：数据高效的扩散模型微调，通过结构引导实现可控医学图像合成*

*Jianhao Xie, Ziang Zhang, Zhenyu Weng, Yuesheng Zhu, Guibo Luo* | **Category: cs.CV**

**Keywords:** 扩散模型, 医学图像合成, 数据增强, 图像分割, 结构引导

**Comment:** 11 pages,3 figures

> **TL;DR:** MedDiff-FT是一个数据高效的扩散模型微调方法，通过结构引导和质量评估，生成高质量、多样化的合成医学图像，用于数据增强，提升了医学图像分割性能。

**AI_Comments:** MedDiff-FT的创新之处在于其结合了数据高效的扩散模型微调与结构引导机制，特别是在医学图像生成中解决了高质量和结构一致性难题。其引入的动态引导掩码和自动化质量评估协议显著提升了生成图像的实用性，为医学图像分割任务提供了有效的合成数据增强手段，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在医学图像分割中的进展受限于高质量训练数据的稀缺性。虽然扩散模型能生成合成图像，但其在医学成像中受限于对大规模数据集的依赖和对更高图像质量的需求。

**Method:** 提出MedDiff-FT，通过数据高效地微调扩散基础模型来生成具有结构依赖性和领域特异性的医学图像。在推理过程中，动态自适应引导掩码强制空间约束以确保解剖学连贯性；轻量级随机掩码生成器通过分层随机性注入增强多样性；自动化质量评估协议使用特征空间指标过滤次优输出，并通过掩码腐蚀细化保真度。

**Result:** 在五个医学分割数据集上评估，MedDiff-FT生成的合成图像-掩码对使SOTA分割方法的Dice分数平均提高1%。

**Conclusion:** 该框架有效平衡了生成质量、多样性和计算效率，为医学数据增强提供了一个实用的解决方案。

> **ai_Abstract:** MedDiff-FT是一种数据高效的医学图像合成方法，通过微调扩散模型并结合结构引导机制，旨在解决医学数据稀缺问题。该方法在推理时利用动态自适应引导掩码确保解剖学一致性，通过随机掩码生成器增加多样性，并通过自动化质量评估协议过滤和优化输出。实验证明，MedDiff-FT生成的合成数据能有效提升现有医学图像分割方法的性能，为医学数据增强提供实用方案。

> **摘要翻译:** 深度学习在医学图像分割方面的最新进展常常受到高质量训练数据稀缺的限制。虽然扩散模型通过生成合成图像提供了一个潜在的解决方案，但它们在医学成像中的有效性仍然受到对大规模医学数据集的依赖以及对更高图像质量需求的限制。为了解决这些挑战，我们提出了MedDiff-FT，一种可控的医学图像生成方法，它以数据高效的方式微调扩散基础模型，以生成具有结构依赖性和领域特异性的医学图像。在推理过程中，动态自适应引导掩码强制执行空间约束，以确保解剖学上连贯的合成，而轻量级随机掩码生成器通过分层随机性注入增强多样性。此外，自动化质量评估协议使用特征空间指标过滤次优输出，随后通过掩码腐蚀来提高保真度。在五个医学分割数据集上进行评估，MedDiff-FT的合成图像-掩码对将最先进方法的分割性能在Dice分数上平均提高了1%。该框架有效平衡了生成质量、多样性和计算效率，为医学数据增强提供了一个实用的解决方案。代码可在https://github.com/JianhaoXie1/MedDiff-FT获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [380] [Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space](https://arxiv.org/abs/2507.00392)
> *通过将单张2D图像提升到3D空间来学习密集特征匹配*

*Yingping Liang, Yutao Hu, Wenqi Shao, Ying Fu* | **Category: cs.CV**

**Keywords:** 特征匹配, 3D感知, 单视图图像, 泛化, 两阶段框架

**Comment:** 

> **TL;DR:** 本文提出了一种名为L2M的两阶段框架，通过将2D图像提升到3D空间，利用大规模单视图图像学习3D感知特征编码器和解码器，以实现鲁棒的密集特征匹配，并在零样本评估基准上表现出优越的泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个两阶段框架L2M，通过将单张2D图像提升到3D空间来解决传统特征匹配方法对多视图图像的依赖性，并增强了特征对3D信息的感知能力。其重要性在于利用大规模单视图数据训练，显著提高了特征匹配在多样化和挑战性场景下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有特征匹配方法严重依赖稀缺且干净的多视图图像集合，限制了它们在多样和挑战性场景中的泛化能力。此外，传统特征编码器通常在单视图2D图像上训练，这限制了它们捕获3D感知对应关系的能力。

**Method:** 我们提出了一种名为L2M的两阶段框架，将2D图像提升到3D空间，充分利用大规模多样的单视图图像。第一阶段，结合多视图图像合成和3D特征高斯表示，学习一个3D感知特征编码器，将3D几何知识注入其中。第二阶段，采用新视图渲染策略，结合从单视图图像生成的大规模合成数据，学习一个特征解码器，以实现鲁棒的特征匹配，从而在不同领域实现泛化。

**Result:** 大量实验表明，我们的方法在零样本评估基准上实现了卓越的泛化能力。

**Conclusion:** 所提出的框架对于鲁棒特征匹配是有效的。

> **ai_Abstract:** 本文提出了一种名为L2M的两阶段框架，旨在解决传统特征匹配方法对多视图数据依赖和2D编码器缺乏3D感知能力的问题。L2M通过将单张2D图像提升到3D空间，利用大规模单视图数据进行训练。第一阶段学习3D感知特征编码器，注入3D几何知识；第二阶段利用新视图渲染和合成数据学习特征解码器。实验证明该方法在零样本评估中表现出优越的泛化能力，实现了鲁棒的特征匹配。

> **摘要翻译:** 特征匹配在许多计算机视觉任务中扮演着基础角色，然而现有方法严重依赖稀缺且干净的多视图图像集合，这限制了它们在多样和挑战性场景中的泛化能力。此外，传统特征编码器通常在单视图2D图像上训练，限制了它们捕获3D感知对应关系的能力。在本文中，我们提出了一种新颖的两阶段框架，将2D图像提升到3D空间，命名为Lift to Match (L2M)，充分利用大规模多样的单视图图像。具体来说，在第一阶段，我们通过结合多视图图像合成和3D特征高斯表示来学习一个3D感知特征编码器，这将3D几何知识注入到编码器中。在第二阶段，采用新视图渲染策略，结合从单视图图像生成的大规模合成数据，用于学习一个特征解码器，以实现鲁棒的特征匹配，从而在不同领域实现泛化。大量实验表明，我们的方法在零样本评估基准上实现了卓越的泛化能力，突出了所提出框架在鲁棒特征匹配方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [383] [Few-shot Classification as Multi-instance Verification: Effective Backbone-agnostic Transfer across Domains](https://arxiv.org/abs/2507.00401)
> *小样本分类作为多实例验证：跨域的有效主干无关迁移*

*Xin Xu, Eibe Frank, Geoffrey Holmes* | **Category: cs.CV, cs.LG**

**Keywords:** 小样本学习, 跨域, 多实例验证, 骨干无关, 域适应

**Comment:** 

> **TL;DR:** 本文提出了一种名为“MIV-head”的新方法，用于在骨干网络无法微调的情况下进行跨域小样本学习，该方法在保持竞争性准确率的同时，显著降低了适应成本。

**AI_Comments:** 该论文解决了现实世界小样本学习中一个日益普遍且重要的约束（冻结骨干网络）。其创新之处在于将问题重新构建为多实例验证，并设计了一个新颖、高效且骨干网络无关的“MIV-head”。这在计算成本和适用性方面相对于微调或适配器方法具有显著优势，为高效模型适应做出了宝贵贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，骨干网络（即特征提取器）的微调变得不可能或不可行，这导致了在跨域小样本学习中需要处理由冻结的“黑盒”骨干网络产生的低质量和静态嵌入的挑战。

**Method:** 本文将小样本分类表示为一系列多实例验证（MIV）任务。在此基础上，引入了一种名为“MIV-head”的新型小样本域适应方法，它类似于分类头，与任何预训练骨干网络无关且计算高效。MIV-head的核心组件在目标域的小样本数据上训练，无需微调骨干网络，并在“元测试”阶段内完成。

**Result:** 在跨域小样本图像分类的Meta-dataset基准扩展上进行的实验表明，MIV-head与应用于相同骨干网络的最先进的“适配器”（或部分微调）方法相比，实现了极具竞争力的准确率，同时适应成本显著降低。此外，已知的“分类头”方法在准确率方面远远落后。消融研究也证实了该方法核心组件的有效性。

**Conclusion:** MIV-head有效解决了骨干网络无法微调的跨域小样本学习问题，提供了一种高效且骨干网络无关的解决方案，在实际应用中具有重要价值。

> **ai_Abstract:** 本文针对骨干网络微调不可行这一日益普遍的实际场景，研究了跨域小样本学习。作者将小样本分类问题重新表述为多实例验证（MIV）任务，并提出了一种新颖的、骨干网络无关且计算高效的“MIV-head”方法。该方法在目标域小样本数据上训练，无需微调骨干网络，便能在元测试阶段取得强大性能。实验结果表明，MIV-head在准确率上与最先进的适配器方法相当，但适应成本显著降低，且远优于传统分类头方法。这为在受限条件下实现高效跨域迁移提供了一种有效途径。

> **摘要翻译:** 我们研究了在骨干网络（即特征提取器）无法或不适合微调的约束下的跨域小样本学习——这种情况在实际用例中越来越常见。处理由冻结的“黑盒”骨干网络产生的低质量和静态嵌入，导致将小样本分类问题表示为一系列多实例验证（MIV）任务。受此表示的启发，我们引入了一种新颖的小样本域适应方法，命名为“MIV-head”，它类似于分类头，与任何预训练骨干网络无关且计算高效。为MIV-head设计的核心组件，当在目标域的小样本数据上训练时，共同在该域的测试数据上产生强大的性能。重要的是，它在不微调骨干网络的情况下，并在“元测试”阶段内完成。在各种设置下，以及在跨域小样本图像分类的Meta-dataset基准的扩展上进行实验，使用在ImageNet1K上预训练的代表性现成卷积神经网络和视觉Transformer骨干网络，我们表明MIV-head与应用于相同骨干网络的最先进的“适配器”（或部分微调）方法相比，实现了极具竞争力的准确率，同时适应成本显著降低。我们还发现，众所周知的“分类头”方法在准确率方面远远落后。消融研究从经验上证明了我们方法核心组件的合理性。我们已在https://github.com/xxweka/MIV-head分享了代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [386] [DiGA3D: Coarse-to-Fine Diffusional Propagation of Geometry and Appearance for Versatile 3D Inpainting](https://arxiv.org/abs/2507.00429)
> *DiGA3D：用于多功能3D修复的几何与外观粗到细扩散传播*

*Jingyi Pan, Dan Xu, Qiong Luo* | **Category: cs.CV**

**Keywords:** 3D修复, 扩散模型, 几何一致性, 外观一致性, 多视图

**Comment:** ICCV 2025, Project page: https://rorisis.github.io/DiGA3D/

> **TL;DR:** DiGA3D提出了一种新的3D修复管道，通过扩散模型以粗到细的方式传播一致的几何和外观，解决了现有方法在鲁棒性、外观和几何一致性方面的挑战。

**AI_Comments:** DiGA3D的创新之处在于其将扩散模型应用于3D修复，并通过粗到细的传播策略、多参考视图选择、AFP机制和TG-SDS损失有效解决了多视图一致性问题（外观和几何）。这对于实现多功能、鲁棒的文本引导3D修复具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本引导的3D修复需要一个统一的管道来灵活地移除、重新纹理或替换对象。现有方法面临挑战：1) 单一参考修复方法在远离参考视图时缺乏鲁棒性；2) 独立修复多视图图像时出现外观不一致；3) 修复区域几何变化大时几何不一致限制性能。

**Method:** 引入DiGA3D，一个新颖多功能的3D修复管道。它利用扩散模型以粗到细的方式传播一致的外观和几何。具体包括：1) 开发多参考视图选择策略以减少传播误差；2) 设计注意力特征传播（AFP）机制，通过扩散模型从参考视图传播注意力特征以保持外观一致性；3) 引入纹理-几何分数蒸馏采样（TG-SDS）损失以进一步提高修复3D场景的几何一致性。

**Result:** 在多个3D修复任务上的大量实验证明了该方法的有效性。

**Conclusion:** DiGA3D通过其多参考视图选择、AFP机制和TG-SDS损失，成功解决了多功能3D修复中鲁棒性、外观和几何一致性的挑战，并被证明是有效的。

> **ai_Abstract:** DiGA3D是一个创新的3D修复管道，旨在解决现有方法在鲁棒性、外观和几何一致性方面的不足。它通过利用扩散模型，以粗到细的方式传播几何和外观信息。该方法包括多参考视图选择策略以减少误差，注意力特征传播（AFP）机制以确保外观一致性，以及纹理-几何分数蒸馏采样（TG-SDS）损失以增强几何一致性。实验结果表明DiGA3D在多种3D修复任务中表现出色。

> **摘要翻译:** 开发一个统一的管道，使用户能够灵活地移除、重新纹理或替换对象，对于文本引导的3D修复至关重要。然而，在统一框架内执行多个3D修复任务仍然存在挑战：1) 单一参考修复方法在处理远离参考视图的视角时缺乏鲁棒性。2) 使用2D扩散先验独立修复多视图图像时会出现外观不一致；3) 当修复区域存在显著几何变化时，几何不一致限制了性能。为了解决这些挑战，我们引入了DiGA3D，一个新颖且多功能的3D修复管道，它利用扩散模型以粗到细的方式传播一致的外观和几何。首先，DiGA3D开发了一种鲁棒的策略来选择多个参考视图，以减少传播过程中的误差。其次，DiGA3D设计了一种注意力特征传播（AFP）机制，通过扩散模型将所选参考视图的注意力特征传播到其他视图，以保持外观一致性。此外，DiGA3D引入了一种纹理-几何分数蒸馏采样（TG-SDS）损失，以进一步提高修复3D场景的几何一致性。在多个3D修复任务上的大量实验证明了我们方法的有效性。项目页面可在https://rorisis.github.io/DiGA3D/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [MFH: Marrying Frequency Domain with Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2507.00430)
> *MFH: 结合频域与手写数学表达式识别*

*Huanxin Yang, Qiwen Wang* | **Category: cs.CV**

**Keywords:** 手写数学表达式识别, 频域, 离散余弦变换, HMER

**Comment:** 

> **TL;DR:** MFH通过利用离散余弦变换（DCT）将频域分析引入手写数学表达式识别（HMER），解决了复杂的公式结构问题。该方法在多个基线模型上表现出一致的性能提升，并在CROHME数据集上取得了显著的准确率，证明了频域信息的有效性。

**AI_Comments:** 本文通过将频域分析（特别是DCT）引入手写数学表达式识别领域，提出了一种创新方法。这种方法解决了数学公式结构固有的复杂性，提供了超越传统序列预测方法的新视角。在各种基线模型上实现的一致性能提升，突显了其通用性和提高HMER准确性的潜力。源代码的明确提供也有助于研究的可复现性和进一步的探索。

<details>
  <summary>Details</summary>

**Motivation:** 手写数学表达式识别（HMER）在序列预测中面临复杂的公式结构和字符布局问题。

**Method:** 本文将频域分析引入HMER，提出了一种结合频域与HMER的方法（MFH），该方法利用离散余弦变换（DCT），并强调频率信息对识别数学公式的结构分析辅助作用。

**Result:** 在各种基线模型上实现时，该网络表现出一致的性能提升，证明了频域信息的有效性。MFH-CoMER在CROHME 2014/2016/2019测试集上取得了61.66%/62.07%/63.72%的显著准确率。

**Conclusion:** 该研究证明了频域信息在增强手写数学表达式识别方面的有效性。

> **ai_Abstract:** 本文提出了一种名为MFH（Marrying Frequency Domain with HMER）的新方法，用于手写数学表达式识别（HMER），该方法通过离散余弦变换（DCT）将频域分析整合到HMER中。MFH旨在解决复杂公式结构和字符布局的挑战，利用频率信息辅助结构分析。实验结果表明，MFH能够一致地提升各种基线模型的性能，并且MFH-CoMER在CROHME 2014/2016/2019测试集上分别达到了61.66%/62.07%/63.72%的准确率，验证了频域信息在HMER中的有效性。

> **摘要翻译:** 手写数学表达式识别 (HMER) 在序列预测中面临复杂的公式结构和字符布局问题。在本文中，我们将频域分析引入 HMER，并提出了一种结合频域与 HMER 的方法 (MFH)，该方法利用离散余弦变换 (DCT)。我们强调频率信息对识别数学公式的结构分析辅助作用。在各种基线模型上实现时，我们的网络表现出一致的性能提升，证明了频域信息的有效性。实验表明，我们的 MFH-CoMER 在 CROHME 2014/2016/2019 测试集上取得了 61.66%/62.07%/63.72% 的显著准确率。源代码可在 https://github.com/Hryxyhe/MFH 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [391] [ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales](https://arxiv.org/abs/2507.00454)
> *ATSTrack：通过对齐时空尺度增强视觉-语言跟踪*

*Yihao Zhen, Qiang Wang, Yu Qiao, Liangqiong Qu, Huijie Fan* | **Category: cs.CV, cs.AI**

**Keywords:** 视觉-语言跟踪, 时空对齐, 特征修改, ATSTrack, 视觉-语言令牌

**Comment:** 

> **TL;DR:** 提出ATSTrack，通过对齐视觉和语言输入的时空尺度来解决视觉-语言跟踪中的特征错位问题，达到与现有方法相当的性能。

**AI_Comments:** 这篇论文通过关注视觉和语言输入之间固有的时空尺度差异，为视觉-语言跟踪领域提供了一个新颖的视角。其创新点在于提出ATSTrack，通过分解语言描述和引入视觉-语言令牌来细致地对齐这些尺度，从而提升特征对齐效果。虽然结果表明性能与现有方法相当，但这种对底层尺度错位问题的深入探讨和解决方案可能为未来的研究提供新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言跟踪（VLT）中的一个主要挑战是由于目标移动导致的视觉输入和语言描述之间的错位。现有方法忽视了视觉和语言输入之间信息固有的时空尺度差异，这阻碍了它们的性能。

**Method:** 提出ATSTrack，通过对齐不同输入组件的时空尺度来增强特征修改效果。具体来说，它将语言描述分解为基于时空对应关系的短语，并进行细粒度特征修改。此外，引入一个视觉-语言令牌，其中包含来自前一帧的修改后的语言信息，以指导模型提取与语言描述更相关的视觉特征，从而减少空间尺度差异的影响。

**Result:** 提出的ATSTrack实现了与现有方法相当的性能。

**Conclusion:** 通过对齐视觉和语言输入的时空尺度，ATSTrack有效解决了视觉-语言跟踪中的特征错位问题，并取得了有竞争力的性能。

> **ai_Abstract:** 本文提出ATSTrack，旨在解决视觉-语言跟踪中视觉输入与语言描述之间的时空尺度错位问题。该方法通过将语言描述分解为基于时空对应关系的短语并进行细粒度特征修改，以及引入视觉-语言令牌来指导视觉特征提取，从而增强特征对齐。实验证明，ATSTrack的性能与现有方法相当。

> **摘要翻译:** 视觉-语言跟踪（VLT）的一个主要挑战是目标移动导致的视觉输入和语言描述之间的错位。之前的跟踪器探索了许多有效的特征修改方法来保留更多对齐的特征。然而，一个重要但未被探索的因素最终阻碍了它们的能力，即视觉和语言输入之间信息固有的时空尺度差异。为了解决这个问题，我们提出了一种新颖的视觉-语言跟踪器，通过对齐不同输入组件的时空尺度来增强特征修改的效果，命名为ATSTrack。具体来说，我们将每个语言描述根据其与视觉输入的时空对应关系分解为具有不同属性的短语，并以细粒度方式修改它们的特征。此外，我们引入了一个视觉-语言令牌，其中包含来自前一帧的修改后的语言信息，以指导模型提取与语言描述更相关的视觉特征，从而减少空间尺度差异的影响。实验结果表明，我们提出的ATSTrack实现了与现有方法相当的性能。我们的代码将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [Unleashing the Potential of All Test Samples: Mean-Shift Guided Test-Time Adaptation](https://arxiv.org/abs/2507.00462)
> *释放所有测试样本的潜力：均值漂移引导的测试时自适应*

*Jizhou Han, Chenhao Ding, SongLin Dong, Yuhang He, Xinyuan Gao, Yihong Gong* | **Category: cs.CV**

**Keywords:** 测试时自适应, 均值漂移, 视觉语言模型, 分布偏移, 无需训练

**Comment:** 

> **TL;DR:** MS-TTA是一种无需训练的测试时自适应方法，它利用均值漂移增强特征表示，从而提高视觉语言模型在分布偏移下的性能。

**AI_Comments:** MS-TTA的创新点在于利用均值漂移来处理所有测试样本，包括低置信度样本，从而突破了传统TTA方法仅限于原始特征空间的限制。这种方法提升了特征表示的质量，使其在无需训练的情况下实现了更稳定和鲁棒的测试时自适应，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无训练测试时自适应（TTA）方法仅在CLIP的原始特征空间中操作，依赖高置信度样本而忽略了低置信度样本的潜力，导致在测试时面对分布偏移时视觉语言模型（如CLIP）性能下降。

**Method:** 提出MS-TTA，一种无需训练的方法，通过单步k近邻（kNN）均值漂移来增强CLIP特征空间之外的特征表示。它通过精炼所有测试样本来提高特征紧凑性和类别可分性。此外，还利用精炼嵌入的缓存来通过均值漂移增强的logits进一步提高推理效果。

**Result:** 在OOD（分布外）和跨数据集基准测试中，MS-TTA持续优于最先进的无训练TTA方法，实现了鲁棒的自适应，并且无需额外训练。

**Conclusion:** MS-TTA通过利用均值漂移精炼所有测试样本，显著提升了视觉语言模型在分布偏移下的测试时自适应能力，且无需额外训练，表现优于现有SOTA方法。

> **ai_Abstract:** 本文提出了一种名为MS-TTA的无训练测试时自适应方法，旨在解决视觉语言模型在分布偏移下性能下降的问题。与现有方法仅依赖高置信度样本不同，MS-TTA通过单步kNN均值漂移来精炼所有测试样本，从而在CLIP原始特征空间之外增强特征表示，提高特征紧凑性和类别可分性。通过利用精炼嵌入缓存提供增强的logits，MS-TTA在OOD和跨数据集基准测试中表现出优于现有SOTA方法的鲁棒自适应能力，且无需额外训练。

> **摘要翻译:** 视觉语言模型（VLM）如CLIP表现出强大的泛化能力，但在测试时面临分布偏移时会遇到困难。现有的无需训练的测试时自适应（TTA）方法严格在CLIP的原始特征空间内操作，依赖高置信度样本而忽视了低置信度样本的潜力。我们提出了MS-TTA，一种无需训练的方法，它通过单步k近邻（kNN）均值漂移来增强CLIP特征空间之外的特征表示。通过精炼所有测试样本，MS-TTA提高了特征紧凑性和类别可分性，从而实现更稳定的自适应。此外，精炼嵌入的缓存通过提供均值漂移增强的logits进一步提高了推理能力。在OOD和跨数据集基准测试上的广泛评估表明，MS-TTA持续优于最先进的无需训练TTA方法，实现了鲁棒的自适应，且无需额外训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [397] [Bisecle: Binding and Separation in Continual Learning for Video Language Understanding](https://arxiv.org/abs/2507.00469)
> *Bisecle：视频语言理解中持续学习的绑定与分离*

*Yue Tan, Xiaoqian Hu, Hao Xue, Celso De Melo, Flora D. Salim* | **Category: cs.CV, cs.LG**

**Keywords:** 持续学习, 视频语言理解, 海马体机制, 绑定与分离, 灾难性遗忘

**Comment:** 23 pages, 12 figures, 10 tables

> **TL;DR:** Bisecle受海马体机制启发，提出一种新的持续学习框架，通过多向监督和对比提示学习，解决大型视频语言模型在视频理解任务中面临的灾难性遗忘和更新冲突问题。

**AI_Comments:** 该论文的创新点在于将生物启发的海马体绑定与分离机制引入到视频语言模型的持续学习中，有效解决了大型模型在面对连续数据流时的遗忘和冲突问题。其提出的多向监督和对比提示学习方法为参数高效的持续学习提供了新的思路，对于推动VLM在真实世界应用中的适应性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有前沿视觉-语言模型在视频理解任务中表现出色，但真实世界的视频数据流需要模型持续适应。在参数高效的持续学习中，大型多模态基础模型面临灾难性遗忘和更新冲突的挑战。

**Method:** 受海马体快速绑定和模式分离机制的启发，本文提出Bisecle框架。该框架使用多向监督模块捕获更多跨模态关系，并设计对比提示学习方案以隔离任务特定知识，促进高效记忆存储。绑定和分离过程进一步增强了VLM保留复杂经验的能力。

**Result:** 在多个VideoQA基准测试中，所提出的Bisecle框架能够有效缓解遗忘问题，并增强跨任务泛化能力。

**Conclusion:** Bisecle通过模拟海马体的绑定和分离机制，显著提升了大型视频语言模型在持续学习视频理解任务中的鲁棒性和效率。

> **ai_Abstract:** 本文提出Bisecle，一个受人脑海马体记忆机制启发的持续学习框架，用于视频语言理解。针对大型视觉-语言模型在处理连续视频流时面临的灾难性遗忘和更新冲突问题，Bisecle通过引入多向监督模块和对比提示学习方案，有效捕获跨模态关系并隔离任务特定知识，从而实现高效的记忆存储和巩固。实验证明，Bisecle在VideoQA基准测试中有效缓解了遗忘并提升了跨任务泛化能力。

> **摘要翻译:** 前沿的视觉-语言模型（VLMs）在视频理解任务中取得了显著的进步。然而，真实世界的视频通常以持续演变的数据流形式存在（例如，可穿戴眼镜捕获的动态场景），这要求模型持续适应不断变化的数据分布和新场景。考虑到在新任务上微调模型的计算成本过高，通常只更新一小部分参数，而大部分模型保持冻结。这给现有持续学习框架在大型多模态基础模型的背景下带来了新的挑战，即灾难性遗忘和更新冲突。虽然基础模型在参数高效的持续学习方面面临困难，但人脑中的海马体已经进化出高效的记忆形成和巩固机制。受海马体中快速绑定和模式分离机制的启发，本文提出了Bisecle用于视频-语言持续学习，其中使用多向监督模块来捕获更多的跨模态关系，并设计了对比提示学习方案来隔离任务特定知识，以促进高效的记忆存储。绑定和分离过程进一步增强了VLM保留复杂经验的能力，从而在视频理解任务中实现鲁棒且高效的持续学习。我们对所提出的Bisecle进行了彻底评估，证明了其在多个VideoQA基准测试中减轻遗忘和增强跨任务泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [399] [ARIG: Autoregressive Interactive Head Generation for Real-time Conversations](https://arxiv.org/abs/2507.00472)
> *ARIG：实时对话的自回归交互式头部生成*

*Ying Guo, Xi Liu, Cheng Zhen, Pengfei Yan, Xiaoming Wei* | **Category: cs.CV**

**Keywords:** 自回归, 头部生成, 实时对话, 交互行为理解, 扩散模型

**Comment:** ICCV 2025. Homepage: https://jinyugy21.github.io/ARIG/

> **TL;DR:** ARIG是一个自回归的逐帧头部生成框架，通过非量化AR过程、扩散模型和对交互行为、对话状态的深度理解，实现了更实时、更真实的交互式头部生成。

**AI_Comments:** ARIG的创新之处在于其采用自回归的逐帧生成方式来解决实时性挑战，并利用扩散过程在连续空间进行更精确的运动预测。此外，引入交互行为理解（IBU）和对话状态理解（CSU）模块，从多模态和上下文层面深入理解对话动态，极大地提升了生成头部运动的交互真实感，是该领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 面对面交流是常见的活动，促使了交互式头部生成的研究。然而，以往的片段式生成范式或显式听者/说话者生成器切换方法在未来信号获取、上下文行为理解和切换平滑性方面存在局限性，难以实现实时和真实的效果。

**Method:** 本文提出了一个基于自回归（AR）的逐帧框架ARIG，以实现实时生成和更好的交互真实感。为了实现实时生成，我们将运动预测建模为非向量量化的AR过程。与离散码本索引预测不同，我们使用扩散过程来表示运动分布，在连续空间中实现更准确的预测。为了提高交互真实感，我们强调交互行为理解（IBU）和详细的对话状态理解（CSU）。在IBU中，基于双轨双模态信号，我们通过双向集成学习总结短程行为，并对长程进行上下文理解。在CSU中，我们利用语音活动信号和IBU的上下文特征来理解实际对话中存在的各种状态（中断、反馈、停顿等）。这些作为最终渐进式运动预测的条件。

**Result:** 广泛的实验验证了我们模型的有效性。

**Conclusion:** ARIG框架通过其新颖的自回归过程、交互行为理解（IBU）和对话状态理解（CSU），解决了以往方法的局限性，实现了实时生成并提升了交互真实感。

> **ai_Abstract:** 本文提出了ARIG，一个用于实时对话的自回归交互式头部生成框架。针对现有方法在实时性和真实感方面的局限性，ARIG采用非向量量化的自回归过程进行逐帧运动预测，并利用扩散过程在连续空间中实现更准确的预测。为增强交互真实感，模型引入了交互行为理解（IBU）和对话状态理解（CSU），通过双模态信号和上下文特征来捕捉短程行为和对话状态，作为运动预测的条件。实验证明了该模型的有效性，显著提升了交互式头部生成的实时性和真实感。

> **摘要翻译:** 面对面交流作为一种常见的人类活动，推动了交互式头部生成的研究。虚拟智能体可以根据对方用户和自身的音频或运动信号，生成具有听觉和说话能力的运动响应。然而，以往的片段式生成范式或显式听者/说话者生成器切换方法在未来信号获取、上下文行为理解和切换平滑性方面存在局限性，使得难以实现实时和真实的效果。在本文中，我们提出了一个基于自回归（AR）的逐帧框架ARIG，以实现实时生成和更好的交互真实感。为了实现实时生成，我们将运动预测建模为非向量量化的AR过程。与离散码本索引预测不同，我们使用扩散过程来表示运动分布，在连续空间中实现更准确的预测。为了提高交互真实感，我们强调交互行为理解（IBU）和详细的对话状态理解（CSU）。在IBU中，基于双轨双模态信号，我们通过双向集成学习总结短程行为，并对长程进行上下文理解。在CSU中，我们利用语音活动信号和IBU的上下文特征来理解实际对话中存在的各种状态（中断、反馈、停顿等）。这些作为最终渐进式运动预测的条件。广泛的实验验证了我们模型的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [401] [ADAptation: Reconstruction-based Unsupervised Active Learning for Breast Ultrasound Diagnosis](https://arxiv.org/abs/2507.00474)
> *ADAptation：基于重建的无监督主动学习用于乳腺超声诊断*

*Yaofei Duan, Yuhao Huang, Xin Yang, Luyi Han, Xinyu Xie, Zhiyuan Zhu, Ping He, Ka-Hou Chan, Ligang Cui, Sio-Kei Im, Dong Ni, Tao Tan* | **Category: cs.CV**

**Keywords:** 无监督主动学习, 域适应, 乳腺超声诊断, 扩散模型, 对比学习

**Comment:** 11 pages, 4 figures, 4 tables. Accepted by conference MICCAI2025

> **TL;DR:** ADAptation提出了一种新的无监督主动学习框架，通过扩散模型进行域适应，并结合对比学习和双评分机制，有效选择信息样本以提高乳腺超声诊断模型的性能。

**AI_Comments:** ADAptation的创新之处在于将扩散模型引入无监督主动学习框架，以解决域适应中的分布偏移问题，这为数据稀缺和标注成本高昂的医疗影像领域提供了一个高效的解决方案。结合对比学习和双评分机制，进一步优化了样本选择的质量和效率。该方法在实际临床应用中具有重要意义，因为它能有效利用未标注数据，降低对大量标注数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习诊断模型在训练（源）和测试（目标）域之间存在分布偏移时，性能会下降。收集和标注足够的目标域数据是最佳解决方案，但受限于时间和资源。主动学习（AL）可以降低标注成本，但难以处理不同数据集间的分布变化。

**Method:** 本研究提出了一种名为ADAptation的无监督主动学习框架，用于域适应。核心步骤是利用扩散模型的分布同质化能力，将目标图像转换为源域风格，以弥合跨数据集差距。然后引入两项创新：(a) 一个超球面约束对比学习网络，用于紧凑特征聚类；(b) 一个双评分机制，用于量化和平衡样本的不确定性和代表性。

**Result:** 在四个乳腺超声数据集（三个公开，一个内部/多中心）和五个常见深度分类器上的广泛实验表明，ADAptation方法超越了现有强大的基于AL的竞争对手。

**Conclusion:** ADAptation框架有效且泛化能力强，适用于临床域适应，能够解决乳腺超声诊断中跨域数据分布不一致的问题。

> **ai_Abstract:** 本文提出了一种名为ADAptation的无监督主动学习框架，旨在解决深度学习模型在乳腺超声诊断中因数据分布偏移导致的性能下降问题。该方法首先利用扩散模型进行跨域图像风格转换，以缩小数据集间差距。接着，通过引入超球面约束对比学习网络实现特征紧凑聚类，并设计双评分机制来平衡样本的不确定性和代表性，从而在有限标注预算下高效选择有价值的样本。实验结果表明，ADAptation在多个乳腺超声数据集上表现优于现有主动学习方法，验证了其在临床域适应中的有效性和泛化能力。

> **摘要翻译:** 基于深度学习的诊断模型经常由于训练（源）域和测试（目标）域之间的分布偏移而导致性能下降。收集和标注足够的目标域数据进行模型再训练是最佳解决方案，但受限于时间和稀缺资源。主动学习（AL）提供了一种有效的方法来降低标注成本，同时保持性能，但难以处理由不同数据集之间分布变化带来的挑战。在本研究中，我们提出了一种新颖的用于域适应的无监督主动学习框架，名为ADAptation，它能够在有限的标注预算下，从多域数据池中高效选择信息丰富的样本。作为基础步骤，我们的方法首先利用扩散模型的分布同质化能力，通过将目标图像转换为源域风格来弥合跨数据集的差距。然后我们引入了两项关键创新：(a) 一个用于紧凑特征聚类的超球面约束对比学习网络，以及 (b) 一个量化和平衡样本不确定性和代表性的双评分机制。在四个乳腺超声数据集（三个公开数据集和一个内部/多中心数据集）上对五个常见深度分类器进行的广泛实验表明，我们的方法超越了现有强大的基于AL的竞争对手，验证了其在临床域适应中的有效性和泛化能力。代码可在匿名链接获取：https://github.com/miccai25-966/ADAptation。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [406] [Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models](https://arxiv.org/abs/2507.00493)
> *视觉变位词揭示视觉模型中整体形状处理的隐藏差异*

*Fenil R. Doshi, Thomas Fel, Talia Konkle, George Alvarez* | **Category: cs.CV, cs.AI**

**Keywords:** 视觉模型, 形状处理, 配置形状分数, Transformer, 视觉变位词

**Comment:** Project page: https://www.fenildoshi.com/configural-shape/

> **TL;DR:** 本文引入配置形状分数（CSS）来衡量视觉模型识别基于整体配置的形状的能力，发现自监督和语言对齐的Transformer模型在此方面表现优异，并提出未来的视觉系统应整合局部纹理和全局配置形状。

**AI_Comments:** 这项研究通过引入“配置形状分数（CSS）”和“物体变位词对”提供了一种新颖且更绝对的形状处理能力评估方法，避免了传统形状-纹理偏置研究的局限性。它揭示了Transformer模型在整体形状处理方面的优越性，并强调了长程交互的重要性。这一工作对理解和构建更接近人类视觉的鲁棒、通用视觉系统具有重要意义，其创新点在于评估范式的转变以及对模型内部机制的深入洞察。

<details>
  <summary>Details</summary>

**Motivation:** 当前视觉模型主要依赖局部纹理线索，导致特征脆弱且非组合性。现有的形状-纹理偏置研究将形状和纹理对立起来，忽略了模型可以同时依赖两者，并掩盖了表示的绝对质量。本文旨在绝对地评估模型的配置能力。

**Method:** 本文提出配置形状分数（CSS）来衡量模型识别“物体变位词对”中图像的能力，这些图像保留局部纹理但打乱全局部件排列以描绘不同物体类别。通过机械探测，分析了高性能网络对长程交互的依赖性，并进行了表示相似性分析。使用BagNet作为对照组。

**Result:** 1. CSS揭示了86种卷积、Transformer和混合模型在配置敏感性上的广泛差异。2. 全自监督和语言对齐的Transformer模型（如DINOv2、SigLIP2和EVA-CLIP）在CSS得分中位居前列。3. 高CSS网络依赖长程交互，表现出独特的U形整合曲线，且在中层深度从局部编码过渡到全局编码。4. BagNet对照组的性能处于随机水平，排除了“边界破解”策略。5. 配置形状分数还能预测其他依赖形状的评估结果。

**Conclusion:** 通向真正鲁棒、泛化能力强和类人视觉系统的道路，可能不在于在形状和纹理之间做出人为选择，而在于能够无缝整合局部纹理和全局配置形状的架构和学习框架。

> **ai_Abstract:** 本文提出配置形状分数（CSS）以绝对地衡量视觉模型识别基于整体配置形状的能力，而非简单地与纹理对比。研究发现，虽然传统模型偏重局部纹理，但DINOv2、SigLIP2和EVA-CLIP等自监督和语言对齐的Transformer模型在CSS上表现出色，表明它们能更好地处理长程交互和全局信息。这挑战了形状与纹理的二元对立，并指出未来视觉系统应致力于无缝整合局部纹理和全局配置形状。

> **摘要翻译:** 人类能够根据局部纹理线索和物体部分的配置来识别物体，然而当代视觉模型主要收集局部纹理线索，产生脆弱的、非组合性的特征。关于形状与纹理偏置的研究将形状和纹理表示对立起来，通过纹理来衡量形状，忽略了模型（和人类）可以同时依赖这两种线索的可能性，并掩盖了这两种表示的绝对质量。因此，我们将形状评估重新定义为绝对配置能力问题，并通过配置形状分数（CSS）进行操作化，该分数（i）衡量识别物体变位词对中图像的能力，这些图像在保留局部纹理的同时，通过置换全局部件排列来描绘不同的物体类别。在86种卷积、Transformer和混合模型中，CSS（ii）揭示了广泛的配置敏感性，其中完全自监督和语言对齐的Transformer模型——以DINOv2、SigLIP2和EVA-CLIP为代表——占据了CSS谱系的顶端。机制探测显示（iii）高CSS网络依赖于长程交互：半径控制的注意力掩码消除了性能，显示出独特的U形整合曲线，并且表示相似性分析揭示了从局部到全局编码的中间深度转变。BagNet对照组（iv）保持在随机水平，排除了“边界破解”策略。最后，（v）我们表明配置形状分数也能预测其他依赖形状的评估。总的来说，我们提出通向真正鲁棒、泛化能力强和类人视觉系统的道路，可能不在于在形状和纹理之间强制做出人为选择，而在于能够无缝整合局部纹理和全局配置形状的架构和学习框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [408] [Laplace-Mamba: Laplace Frequency Prior-Guided Mamba-CNN Fusion Network for Image Dehazing](https://arxiv.org/abs/2507.00501)
> *Laplace-Mamba：拉普拉斯频率先验引导的Mamba-CNN融合图像去雾网络*

*Yongzhen Wang, Liangliang Chen, Bingwen Hu, Heng Liu, Xiao-Ping Zhang, Mingqiang Wei* | **Category: cs.CV**

**Keywords:** Laplace-Mamba, 图像去雾, 空间状态模型, CNN, 频率先验

**Comment:** 12 pages, 11 figures, 6 tables

> **TL;DR:** SSM在图像恢复中处理局部结构和高维数据时存在局限性。Laplace-Mamba提出一种新颖的Mamba-CNN混合网络，通过拉普拉斯频率分解将图像分为低频（SSM处理全局上下文）和高频（CNN处理局部细节）路径，有效实现高效高质量的图像去雾，并在基准测试中超越了现有先进方法。

**AI_Comments:** 该论文通过结合频率域分解（拉普拉斯先验）和混合Mamba-CNN架构，提出了一种创新方法，有效克服了纯SSM在图像去雾中的局限性。其双路径设计巧妙地利用了SSM在全局上下文建模和CNN在局部细节处理上的优势，同时频率引导的下采样也提升了效率。这种混合策略对图像恢复领域做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 空间状态模型（SSM）在图像恢复中建模长程依赖方面表现出色，但其在重建局部结构和处理高维数据时存在局限性，导致图像精细特征恢复效果不佳。

**Method:** 本文提出Laplace-Mamba框架，融合了拉普拉斯频率先验和混合Mamba-CNN架构。它利用拉普拉斯分解将图像分离为低频（捕获全局纹理）和高频（表示边缘和精细细节）分量。通过双并行路径进行处理：低频分支使用SSM进行全局上下文建模，高频分支使用CNN细化局部结构细节。此外，拉普拉斯变换有助于低频分量的信息保留下采样，从而提高计算效率。

**Result:** 在多个基准测试中，所提出的方法在恢复质量和计算效率方面均优于现有最先进的方法。

**Conclusion:** Laplace-Mamba通过结合拉普拉斯频率分解和Mamba-CNN混合架构，有效克服了SSM在图像去雾中处理局部结构和高维数据的局限性，实现了卓越的恢复质量和计算效率。

> **ai_Abstract:** Laplace-Mamba是一种新颖的图像去雾框架，旨在解决空间状态模型（SSM）在捕获局部细节和处理高维数据方面的局限性。它将拉普拉斯频率先验与混合Mamba-CNN架构相结合，通过拉普拉斯分解将图像解耦为低频（由SSM处理全局上下文）和高频（由CNN处理局部细节）分量。这种双分支方法，辅以高效的基于拉普拉斯变换的下采样，显著提高了恢复质量和计算效率，并在基准测试中超越了现有最先进的方法。

> **摘要翻译:** 图像恢复领域的最新进展表明，空间状态模型（SSM）由于其吸引人的线性复杂度和计算效率，是建模长程依赖的强大工具。然而，基于SSM的方法在重建局部结构方面表现出局限性，并且在处理高维数据时效果往往不佳，经常导致图像精细特征的恢复次优。为了解决这些这些挑战，我们引入了Laplace-Mamba，这是一种新颖的框架，它将拉普拉斯频率先验与混合Mamba-CNN架构相结合，用于高效的图像去雾。利用拉普拉斯分解，图像被分解为捕获全局纹理的低频分量和表示边缘及精细细节的高频分量。这种分解通过双并行路径实现专门处理：低频分支采用SSM进行全局上下文建模，而高频分支利用CNN来细化局部结构细节，有效应对各种雾霾场景。值得注意的是，拉普拉斯变换根据奈奎斯特理论促进了低频分量的信息保留下采样，从而显著提高了计算效率。在多个基准上的广泛评估表明，我们的方法在恢复质量和效率方面均优于最先进的方法。源代码和预训练模型可在https://github.com/yz-wang/Laplace-Mamba获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [410] [ExPaMoE: An Expandable Parallel Mixture of Experts for Continual Test-Time Adaptation](https://arxiv.org/abs/2507.00502)
> *ExPaMoE：一种用于持续测试时间适应的可扩展并行专家混合模型*

*JianChao Zhao, Songlin Dong* | **Category: cs.CV**

**Keywords:** 持续测试时间适应, 专家混合模型, 域适应, 灾难性遗忘, 分布偏移

**Comment:** 

> **TL;DR:** ExPaMoE是一种新的框架，通过可扩展并行专家混合架构来解决持续测试时间适应中现有方法在面对大范围或非平稳域偏移时易受特征纠缠和灾难性遗忘影响的问题，并在各种基准测试中表现出卓越的性能。

**AI_Comments:** ExPaMoE的创新之处在于其可扩展并行专家混合架构，它通过解耦域通用和域特定知识，并结合实时域变化检测机制，有效缓解了持续测试时间适应中的灾难性遗忘和特征纠缠问题。引入ImageNet++作为新的大规模CTTA基准，对于推动该领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续测试时间适应（CTTA）方法通常依赖于所有域共享模型参数，这使得它们在面对大范围或非平稳域偏移时容易出现特征纠缠和灾难性遗忘。为了解决这一限制，本文提出了ExPaMoE。

**Method:** 本文提出了ExPaMoE，一个基于可扩展并行专家混合架构的新型框架。ExPaMoE通过双分支专家设计和token引导的特征分离来解耦域通用知识和域特定知识，并基于光谱感知在线域判别器（SODD）动态扩展其专家池，该判别器利用频域线索实时检测分布变化。

**Result:** 广泛的实验证明了ExPaMoE在各种CTTA场景中的优越性。该方法在包括CIFAR-10C、CIFAR-100C、ImageNet-C和Cityscapes-to-ACDC（用于语义分割）等标准基准测试中进行了评估。此外，本文还引入了ImageNet++，一个由多个ImageNet衍生数据集构建的大规模且真实的CTTA基准，以更好地反映复杂域演变下的长期适应。ExPaMoE始终优于现有技术，表现出强大的鲁棒性、可扩展性和抗遗忘能力。

**Conclusion:** ExPaMoE通过其可扩展并行专家混合架构，成功解决了持续测试时间适应中特征纠缠和灾难性遗忘的问题，并在多个基准测试中展现出卓越的性能，证明了其在复杂域演变下进行长期适应的有效性。

> **ai_Abstract:** ExPaMoE提出了一种可扩展并行专家混合架构，旨在解决持续测试时间适应（CTTA）中现有方法因共享参数而导致的特征纠缠和灾难性遗忘问题。该框架通过双分支专家设计解耦域知识，并利用光谱感知在线域判别器动态扩展专家池以适应分布变化。实验表明，ExPaMoE在多个CTTA基准（包括新引入的ImageNet++）上表现出卓越的性能，展现了强大的鲁棒性、可扩展性和抗遗忘能力。

> **摘要翻译:** 持续测试时间适应（CTTA）旨在使模型在不断演变的分布偏移下，能够即时适应未标记数据流。然而，现有的CTTA方法通常依赖于所有域共享模型参数，这使得它们在面对大范围或非平稳域偏移时，容易受到特征纠缠和灾难性遗忘的影响。为了解决这一限制，我们提出了ExPaMoE，一个基于可扩展并行专家混合架构的新型框架。ExPaMoE通过双分支专家设计和token引导的特征分离来解耦域通用知识和域特定知识，并基于光谱感知在线域判别器（SODD）动态扩展其专家池，该判别器利用频域线索实时检测分布变化。广泛的实验证明了ExPaMoE在各种CTTA场景中的优越性。我们在包括CIFAR-10C、CIFAR-100C、ImageNet-C和Cityscapes-to-ACDC（用于语义分割）等标准基准测试中评估了我们的方法。此外，我们还引入了ImageNet++，一个由多个ImageNet衍生数据集构建的大规模且真实的CTTA基准，以更好地反映复杂域演变下的长期适应。ExPaMoE始终优于现有技术，表现出强大的鲁棒性、可扩展性和抗遗忘能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs](https://arxiv.org/abs/2507.00505)
> *LLaVA-SP：通过视觉空间令牌增强多模态大语言模型的视觉表示*

*Haoran Lou, Chunxiao Fan, Ziyan Liu, Yuexin Wu, Xinxiang Wang* | **Category: cs.CV**

**Keywords:** 多模态大语言模型, 视觉表示, 空间令牌, LLaVA-SP, 局部关系建模

**Comment:** ICCV

> **TL;DR:** LLaVA-SP通过仅添加六个视觉空间令牌，显著增强了多模态大语言模型的视觉表示能力，解决了现有模型在局部关系建模上的不足，并在多个基准测试中超越了SOTA模型。

**AI_Comments:** LLaVA-SP的创新之处在于其极简主义的方法：通过仅添加六个空间视觉令牌，就显著提升了MLLMs的视觉表示能力，尤其是在局部关系建模方面。这种轻量级的改进，结合创新的Projector设计，使得模型在不大幅增加计算开销的情况下，实现了性能的显著飞跃，这对于实际部署具有重要意义。它有效地解决了现有视觉编码器（如CLIP-ViT）在处理局部细节时的局限性，为未来MLLM的发展提供了一个高效且有效的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLMs）通常将基于CLIP-ViT的视觉编码器连接到大语言模型，但CLIP-ViT在捕获全局图像特征方面表现良好，却难以建模相邻补丁之间的局部关系，导致视觉表示能力较弱，从而影响了MLLMs的详细理解能力。

**Method:** 本文提出了LLaVA-SP，仅向原始视觉令牌添加六个空间视觉令牌以增强视觉表示。主要方法包括：1) 提出了一种新颖的Projector，使用卷积核从ViT补丁特征中导出视觉空间令牌，模拟“从中心区域到全局”和“从抽象到具体”两种视觉空间排序方法，并应用交叉注意力机制融合细粒度视觉信息。2) 提出了两种模型变体：LLaVA-SP-Cropping（通过渐进式裁剪关注细节特征）和LLaVA-SP-Pooling（通过自适应池化捕获全局语义），以处理多样化的视觉理解任务。

**Result:** 实验结果表明，经过LoRA微调的LLaVA-SP在各种多模态基准测试中实现了显著的性能提升，在多个任务中优于最先进的LLaVA-1.5模型，且推理延迟几乎相同。

**Conclusion:** LLaVA-SP通过引入少量视觉空间令牌和创新的Projector设计，有效解决了多模态大语言模型在局部视觉关系建模上的不足，显著增强了视觉表示能力，并在保持推理效率的同时，在多项任务中超越了现有SOTA模型。

> **ai_Abstract:** LLaVA-SP旨在增强多模态大语言模型（MLLMs）的视觉表示。针对现有模型在局部视觉关系建模上的不足，LLaVA-SP通过仅向原始视觉令牌添加六个空间视觉令牌来解决此问题。该方法引入了一个新颖的Projector，利用卷积核从ViT特征中提取视觉空间令牌，并结合交叉注意力机制融合细粒度信息。此外，还提出了LLaVA-SP-Cropping和LLaVA-SP-Pooling两种变体以适应不同视觉理解任务。实验证明，LLaVA-SP在多项多模态基准测试中表现优异，超越了LLaVA-1.5，且推理延迟几乎不变。

> **摘要翻译:** 多模态大语言模型（MLLMs）的架构通常将视觉编码器（通常基于CLIP-ViT）连接到大型语言模型。虽然CLIP-ViT在捕获全局图像特征方面表现良好，但它在建模相邻补丁之间的局部关系方面存在困难，导致视觉表示能力较弱，进而影响了MLLMs的详细理解能力。为了解决这个问题，我们提出了LLaVA-SP，它仅向原始视觉令牌添加六个空间视觉令牌以增强视觉表示。我们的方法具有三个关键优势：1) 我们提出了一种新颖的Projector，它使用卷积核从ViT补丁特征中导出视觉空间令牌，模拟两种视觉空间排序方法：“从中心区域到全局”和“从抽象到具体”。然后，应用交叉注意力机制融合细粒度视觉信息，丰富整体视觉表示。2) 我们提出了两种模型变体：LLaVA-SP-Cropping，通过渐进式裁剪关注细节特征；LLaVA-SP-Pooling，通过自适应池化捕获全局语义，使模型能够处理多样化的视觉理解任务。3) 大量实验表明，经过LoRA微调的LLaVA-SP在各种多模态基准测试中实现了显著的性能提升，在多个任务中优于最先进的LLaVA-1.5模型，且推理延迟几乎相同。代码和模型可在https://github.com/CnFaker/LLaVA-SP获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [SCING:Towards More Efficient and Robust Person Re-Identification through Selective Cross-modal Prompt Tuning](https://arxiv.org/abs/2507.00506)
> *SCING：通过选择性跨模态提示微调实现更高效、更鲁棒的行人重识别*

*Yunfei Xie, Yuxuan Cheng, Juncheng Wu, Haoyu Zhang, Yuyin Zhou, Shoudong Han* | **Category: cs.CV**

**Keywords:** 行人重识别, 跨模态, 提示微调, 视觉-语言模型, 鲁棒性

**Comment:** 

> **TL;DR:** SCING是一种新颖的行人重识别框架，通过选择性跨模态提示微调（包括SVIP和PDCA）来提高效率、鲁棒性和跨模态对齐，解决了现有方法计算成本高和对齐次优的问题，并在多个基准测试中表现出色。

**AI_Comments:** 该论文的创新之处在于其提出了一种简单而有效的SCING框架，通过选择性跨模态提示微调，在不依赖复杂适配器的情况下，显著提升了行人重识别的跨模态对齐和鲁棒性。SVIP和PDCA这两个核心模块设计巧妙，直接解决了视觉-语言模型在ReID应用中的关键痛点，实现了性能与计算效率的良好平衡，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前将CLIP等视觉-语言预训练模型应用于行人重识别（ReID）任务的方法，常依赖于复杂的适配器设计或模态特定微调，且忽视了跨模态交互，导致计算成本高昂或对齐效果不佳。

**Method:** 本文提出了一个名为选择性跨模态提示微调（SCING）的框架。该方法引入了两项关键创新：1. 选择性视觉提示融合（SVIP）：一个轻量级模块，通过跨模态门控机制将判别性视觉特征动态注入到文本提示中。2. 扰动驱动一致性对齐（PDCA）：一种双路径训练策略，通过正则化原始和增强跨模态嵌入之间的一致性，强制在随机图像扰动下实现不变特征对齐。

**Result:** 在Market1501、DukeMTMC-ReID、Occluded-Duke、Occluded-REID和P-DukeMTMC等多个流行基准测试上进行了广泛实验，结果表明所提出的方法性能令人印象深刻。值得注意的是，该框架在消除繁重适配器的同时保持了高效推理，在性能和计算开销之间取得了最佳平衡。

**Conclusion:** SCING框架通过选择性跨模态提示微调，有效提升了行人重识别的跨模态对齐和对真实世界扰动的鲁棒性。它在不引入复杂适配器的情况下，实现了高性能和高效推理的优化权衡，解决了现有方法的计算成本和对齐次优问题。

> **ai_Abstract:** 本文提出了一种名为SCING的行人重识别新框架，通过选择性跨模态提示微调来解决现有视觉-语言预训练模型（如CLIP）在ReID任务中存在的计算成本高和对齐次优问题。SCING引入了两项核心创新：选择性视觉提示融合（SVIP），一个轻量级模块，用于将判别性视觉特征动态注入文本提示；以及扰动驱动一致性对齐（PDCA），一个双路径训练策略，用于在图像扰动下实现鲁棒的特征对齐。实验结果表明，SCING在多个基准测试上表现出色，并在性能和计算效率之间实现了最佳平衡，同时避免了复杂适配器的使用。

> **摘要翻译:** 最近将CLIP等视觉-语言预训练模型应用于行人重识别（ReID）任务的进展，通常依赖于复杂的适配器设计或模态特定微调，同时忽视了跨模态交互，导致计算成本高昂或对齐效果不佳。为了解决这些限制，我们提出了一种简单而有效的框架，名为选择性跨模态提示微调（SCING），它增强了跨模态对齐和对真实世界扰动的鲁棒性。我们的方法引入了两项关键创新：首先，我们提出了选择性视觉提示融合（SVIP），这是一个轻量级模块，通过跨模态门控机制将判别性视觉特征动态注入到文本提示中。此外，所提出的扰动驱动一致性对齐（PDCA）是一种双路径训练策略，通过正则化原始和增强跨模态嵌入之间的一致性，强制在随机图像扰动下实现不变特征对齐。在Market1501、DukeMTMC-ReID、Occluded-Duke、Occluded-REID和P-DukeMTMC等多个流行基准测试上进行了广泛实验，结果证明了所提出方法的出色性能。值得注意的是，我们的框架在消除繁重适配器的同时保持了高效推理，在性能和计算开销之间实现了最佳权衡。代码将在接受后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [414] [Topology-Constrained Learning for Efficient Laparoscopic Liver Landmark Detection](https://arxiv.org/abs/2507.00519)
> *拓扑约束学习用于高效腹腔镜肝脏地标检测*

*Ruize Cui, Jiaan Zhang, Jialun Pei, Kai Wang, Pheng-Ann Heng, Jing Qin* | **Category: cs.CV**

**Keywords:** 肝脏地标检测, 拓扑约束学习, 腹腔镜手术, 深度学习, 图像处理

**Comment:** This paper has been accepted by MICCAI 2025

> **TL;DR:** TopoNet是一个新的拓扑约束学习框架，用于腹腔镜肝脏地标检测，通过双路径编码器和边界感知拓扑融合模块捕捉RGB和深度信息，并结合拓扑约束损失，在L3D和P2ILF数据集上实现了高精度和低计算复杂性。

**AI_Comments:** 这篇论文的创新点在于引入了拓扑约束学习框架TopoNet，特别是结合了snake-CNN双路径编码器处理多模态信息，以及边界感知拓扑融合模块和拓扑约束损失，有效地解决了肝脏地标检测中结构复杂性和形变的问题。其在精度和计算效率上的表现预示了其在实际临床腹腔镜手术中的重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 腹腔镜肝脏手术中，肝脏地标提供关键解剖指导以降低手术风险，但其管状结构特性和术中动态形变给自动地标检测带来挑战。

**Method:** 提出了TopoNet，一个拓扑约束学习框架。它采用snake-CNN双路径编码器同时捕获详细RGB纹理信息和深度拓扑结构。提出了边界感知拓扑融合（BTF）模块，自适应融合RGB-D特征以增强边缘感知并保留全局拓扑。嵌入了拓扑约束损失函数，包含中心线约束损失和拓扑持久性损失，以确保预测和标签之间的同伦等价。

**Result:** 在L3D和P2ILF数据集上的广泛实验表明，TopoNet实现了出色的准确性和计算复杂性。

**Conclusion:** TopoNet在腹腔镜肝脏地标检测方面表现出卓越的性能，具有在临床应用中的巨大潜力。

> **ai_Abstract:** 本文提出了TopoNet，一个新颖的拓扑约束学习框架，用于腹腔镜肝脏地标的自动检测，旨在解决其管状结构和动态形变带来的挑战。TopoNet通过snake-CNN双路径编码器结合RGB纹理和深度拓扑信息，并引入边界感知拓扑融合模块增强边缘感知和全局拓扑。此外，通过中心线和拓扑持久性损失确保预测的同伦等价性。实验证明TopoNet在准确性和计算效率上表现出色，具有临床应用前景。

> **摘要翻译:** 肝脏地标在腹腔镜肝脏手术中为外科医生提供关键的解剖指导，以最大程度地降低手术风险。然而，地标的管状结构特性和术中动态形变给自动地标检测带来了巨大挑战。在本研究中，我们引入了TopoNet，一个新颖的拓扑约束学习框架，用于腹腔镜肝脏地标检测。我们的框架采用snake-CNN双路径编码器，同时捕获详细的RGB纹理信息和深度信息拓扑结构。同时，我们提出了一个边界感知拓扑融合（BTF）模块，该模块自适应地融合RGB-D特征，以增强边缘感知，同时保留全局拓扑。此外，嵌入了一个拓扑约束损失函数，其中包含中心线约束损失和拓扑持久性损失，以确保预测和标签之间的同伦等价。在L3D和P2ILF数据集上进行的广泛实验表明，TopoNet实现了出色的准确性和计算复杂性，突显了其在腹腔镜肝脏手术临床应用中的潜力。我们的代码将可在https://github.com/cuiruize/TopoNet 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [416] [Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving](https://arxiv.org/abs/2507.00525)
> *Box-QAymo：用于自动驾驶的边界框指代VQA数据集*

*Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo* | **Category: cs.CV, cs.AI**

**Keywords:** Box-QAymo, VQA, 自动驾驶, 视觉语言模型, 时空推理

**Comment:** 

> **TL;DR:** Box-QAymo是一个新的边界框指代VQA数据集，旨在解决现有视觉语言模型（VLMs）在自动驾驶中理解真实世界用户意图的局限性。该数据集通过用户绘制边界框进行查询，并采用分层评估协议，揭示了当前VLMs在感知问题上的显著不足，为开发更稳健的自动驾驶系统奠定了基础。

**AI_Comments:** Box-QAymo通过引入边界框指代的用户查询方式，为自动驾驶VQA提供了一种新颖且更直观的交互范式，这对于复杂场景中的精准意图捕捉至关重要。其分层评估协议设计精巧，能够细致地评估VLM从基本感知到复杂时空推理的能力。该工作揭示了现有模型在真实世界感知方面的不足，为未来研究指明了方向，对于推动自动驾驶系统的安全性和可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现安全可靠的自动驾驶，可解释的通信至关重要，但当前的视觉语言模型（VLMs）在理想化假设下运行，难以捕捉真实世界场景中的用户意图。现有的面向驾驶的VQA数据集仅限于全场景描述或路径点预测，无法评估VLM是否能响应局部用户驱动的查询。

**Method:** 引入了Box-QAymo数据集和基准，旨在评估和微调VLM对用户指定对象的空间和时间推理能力。用户通过绘制边界框来表达意图。提出了一个分层评估协议，包括二元健全性检查、边界框指代对象的属性预测、目标实例的运动理解以及跨帧对象间动态的时空运动推理。通过众包细粒度的对象类别和视觉属性，并提取对象轨迹来构建时间关联的问答对。通过负采样、时间一致性检查和难度感知平衡等严格的质量控制来保证数据集的鲁棒性和多样性。

**Result:** 全面的评估揭示了当前VLM在处理感知问题时存在的显著局限性，突显了在实现真实世界性能方面的差距。

**Conclusion:** 这项工作为开发更稳健、更可解释的自动驾驶系统奠定了基础，这些系统能够在真实世界条件下与用户有效沟通。

> **ai_Abstract:** Box-QAymo是一个新的边界框指代VQA数据集和基准，旨在解决当前视觉语言模型（VLMs）在自动驾驶中理解真实世界用户意图的局限性。该数据集通过用户绘制边界框来表达查询意图，并提出了一个分层评估协议，包括属性预测、运动理解和时空运动推理。通过众包细粒度数据和严格的质量控制，Box-QAymo揭示了当前VLMs在感知问题上的显著不足，为开发更稳健、可解释的自动驾驶系统奠定了基础。

> **摘要翻译:** 可解释的通信对于安全可靠的自动驾驶至关重要，然而当前的视觉语言模型（VLMs）通常在理想化假设下运行，并且难以捕捉真实世界场景中的用户意图。现有的面向驾驶的VQA数据集仅限于全场景描述或路径点预测，这使得无法评估VLM是否能够响应局部用户驱动的查询。我们引入了Box-QAymo，一个边界框指代数据集和基准，旨在评估和微调VLM在用户指定对象上的空间和时间推理能力。用户通过绘制边界框来表达意图，为复杂场景中的聚焦查询提供了快速直观的界面。具体来说，我们提出了一种分层评估协议，首先进行二元健全性检查问题以评估模型的基本能力，然后逐步进行（1）边界框指代对象的属性预测，（2）目标实例的运动理解，以及（3）跨帧对象间动态的时空运动推理。为了支持这一点，我们众包了反映驾驶员所遇到复杂性的细粒度对象类别和视觉属性，并提取了对象轨迹以构建时间关联的问答对。通过负采样、时间一致性检查和难度感知平衡的严格质量控制保证了数据集的鲁棒性和多样性。我们全面的评估揭示了当前VLM在被询问感知问题时存在的显著局限性，突显了在实现真实世界性能方面的差距。这项工作为开发更稳健、更可解释的自动驾驶系统奠定了基础，这些系统能够在真实世界条件下与用户有效沟通。项目页面和数据集可在 https://djamahl99.github.io/qaymo-pages/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation](https://arxiv.org/abs/2507.00537)
> *并非所有注意力头都必要：通过注意力消融精炼CLIP的图像表示*

*Feng Lin, Marco Chen, Haokui Zhang, Xiaotian Yu, Guangming Lu, Rong Xiao* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** CLIP, 注意力消融, 图像表示, 下游任务, 视觉-语言模型

**Comment:** 21 pages, 7 figures

> **TL;DR:** 本文提出了一种名为注意力消融技术（AAT）的简单有效方法，通过抑制特定注意力头的贡献来提升CLIP模型在下游任务中的表现，且几乎不增加推理成本。

**AI_Comments:** 该论文的创新点在于提出了注意力消融技术（AAT），这是一种简单但有效的方法，能够识别并抑制CLIP模型中对性能有负面影响的注意力头。其重要性在于，它提供了一种在不显著增加推理成本的情况下提升大型视觉-语言模型性能的途径，这对于实际应用具有重要意义。该方法通过精炼现有模型的内部机制来提高效率和效果，而非依赖于更复杂的模型结构或更多的参数。

<details>
  <summary>Details</summary>

**Motivation:** 尽管CLIP在各种应用中表现出色，但研究人员假设某些注意力头会对最终表示产生负面影响，并且消除它们可以改善下游任务的性能。

**Method:** 本文提出了一种名为注意力消融技术（AAT）的简单有效方法。AAT通过操纵注意力权重来抑制特定注意力头的贡献。它整合了两种针对不同应用场景的策略，系统地识别并消除了有害的注意力头，以提高表示质量。

**Result:** 实验表明，AAT持续提升了各种领域下游任务的性能，在跨模态检索的CLIP家族模型上，召回率提高了高达11.1%。

**Conclusion:** AAT有潜力有效精炼大规模视觉-语言模型，且几乎不增加推理成本。

> **ai_Abstract:** 本文研究了CLIP图像编码器中注意力头的作用，并提出假设某些注意力头对模型性能有负面影响。为此，论文提出了一种名为注意力消融技术（AAT）的简单方法，通过调整注意力权重来抑制有害的注意力头，从而提升图像表示质量。实验证明，AAT能显著提高CLIP模型在多种下游任务上的表现，尤其是在跨模态检索中召回率提升高达11.1%，且几乎不增加推理成本。

> **摘要翻译:** 本文研究了注意力头在CLIP图像编码器中的作用。尽管CLIP在各种应用中表现出强大的性能，但我们假设某些注意力头会对最终表示产生负面影响，并且消除它们可以改善下游任务的性能。为了利用这一见解，我们提出了一种简单而有效的方法，称为注意力消融技术（AAT），通过操纵注意力权重来抑制特定头的贡献。通过整合两种针对不同应用场景的替代策略，AAT系统地识别并消除了有害的注意力头，以提高表示质量。实验表明，AAT持续改善了各种领域下游任务的性能，在跨模态检索的CLIP家族模型上，召回率提高了高达11.1%。结果强调了AAT在几乎不增加推理成本的情况下有效精炼大规模视觉-语言模型的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail Conserved Anti-Aliasing](https://arxiv.org/abs/2507.00554)
> *LOD-GS：细节保留抗锯齿的细节层次敏感3D高斯泼溅*

*Zhenya Yang, Bingchen Gong, Kai Chen, Qi Dou* | **Category: cs.CV**

**Keywords:** 3D Gaussian Splatting, Anti-Aliasing, Level-of-Detail, Sampling Rate, Filtering

**Comment:** 

> **TL;DR:** LOD-GS提出一种细节层次敏感的3D高斯泼溅抗锯齿框架，通过动态预测滤波强度解决现有方法不足，并在新数据集上实现SOTA效果。

**AI_Comments:** LOD-GS的创新之处在于引入了采样率敏感的基函数来动态调整滤波强度，解决了传统低通滤波的局限性，从而更有效地消除锯齿并保留细节。同时，提出考虑相机距离的新数据集，弥补了现有评估方法的不足，使得评估更加全面和真实。这对于提升3DGS的渲染质量和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅（3DGS）在3D场景渲染中存在锯齿伪影问题。现有低通滤波方法对采样率不敏感，导致渲染出现欠滤波或过平滑。

**Method:** 本文提出了LOD-GS，一个针对高斯泼溅的细节层次敏感滤波框架。该框架为每个3D高斯基元动态预测最佳滤波强度。具体地，为每个高斯引入一组基函数，以采样率作为输入来建模外观变化，从而实现采样率敏感的滤波。这些基函数参数与3D高斯进行端到端联合优化。此外，为了更全面评估，作者还引入了一个新的合成数据集，其中包含在不同相机距离下渲染的对象，弥补了现有方法仅依赖下采样模拟焦距变化的不足。

**Result:** 在公共数据集和新收集的数据集上进行的广泛实验表明，LOD-GS方法实现了最先进（SOTA）的渲染质量，同时有效消除了锯齿。代码和数据集已开源。

**Conclusion:** LOD-GS通过其细节层次敏感的滤波框架，成功解决了3DGS中的锯齿问题，并在公共数据集和新收集数据集上展示了卓越的渲染性能，达到了最先进水平。

> **ai_Abstract:** 本文提出LOD-GS，一种针对3D高斯泼溅的细节层次敏感滤波框架，旨在解决现有抗锯齿方法对采样率不敏感导致的欠滤波和过平滑问题。LOD-GS通过为每个高斯引入基于采样率的基函数来动态预测最佳滤波强度，并与3D高斯进行端到端优化。为更全面评估，作者还创建了一个包含不同相机距离渲染对象的新数据集。实验证明LOD-GS在公共数据集和新数据集上均能实现最先进的渲染质量并有效消除锯齿。

> **摘要翻译:** 尽管3D高斯泼溅（3DGS）在3D场景渲染的质量和效率方面取得了进步，但锯齿伪影仍然是一个持续的挑战。现有方法主要依靠低通滤波来减轻锯齿。然而，这些方法对采样率不敏感，常常导致欠滤波和过平滑的渲染。为了解决这一限制，我们提出了LOD-GS，一个针对高斯泼溅的细节层次敏感滤波框架，它动态预测每个3D高斯基元的最佳滤波强度。具体来说，我们为每个高斯引入了一组基函数，这些函数以采样率作为输入来建模外观变化，从而实现采样率敏感的滤波。这些基函数参数与3D高斯以端到端的方式联合优化。采样率受焦距和相机距离的影响。然而，现有方法和数据集仅依靠下采样来模拟焦距变化以进行抗锯齿评估，忽略了相机距离的影响。为了实现更全面的评估，我们引入了一个新合成数据集，其中包含在不同相机距离下渲染的对象。在公共数据集和我们新收集的数据集上进行的广泛实验表明，我们的方法在有效消除锯齿的同时实现了SOTA渲染质量。代码和数据集已开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [420] [Zero-shot Skeleton-based Action Recognition with Prototype-guided Feature Alignment](https://arxiv.org/abs/2507.00566)
> *基于原型引导特征对齐的零样本骨架动作识别*

*Kai Zhou, Shuhai Zhang, Zeng You, Jinwu Hu, Mingkui Tan, Fei Liu* | **Category: cs.CV**

**Keywords:** 零样本学习, 骨架动作识别, 特征对齐, 原型引导, 跨模态学习

**Comment:** This paper is accepted by IEEE TIP 2025. Code is publicly available
  at https://github.com/kaai520/PGFA

> **TL;DR:** 本文提出了一种名为PGFA的原型引导特征对齐范式，用于零样本骨架动作识别，通过端到端跨模态对比训练和原型引导文本特征对齐策略，显著提高了识别准确率。

**AI_Comments:** 该论文通过引入原型引导的特征对齐和端到端跨模态对比训练，有效地解决了零样本骨架动作识别中的关键挑战，即骨架特征判别力不足和对齐偏差。其创新点在于结合了对比学习和原型机制，以更有效地连接视觉（骨架）和语义（文本）模态。实验结果的显著提升表明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 零样本骨架动作识别由于难以从已知动作泛化到未知动作而极具挑战性。现有方法存在骨架特征判别力不足（固定骨架编码器无法捕获有效对齐信息）和测试时骨架与未知文本特征之间对齐偏差被忽视的问题。

**Method:** 本文提出了一种名为PGFA的原型引导特征对齐范式。具体来说，开发了一个端到端的跨模态对比训练框架，以改善骨架-文本对齐，确保骨架特征具有足够的判别力。此外，引入了一种原型引导的文本特征对齐策略，以减轻测试时分布差异的不利影响。提供了理论分析支持该策略。

**Result:** 与顶尖的SMIE方法相比，PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

**Conclusion:** 本文提出的PGFA范式通过解决现有零样本骨架动作识别方法中骨架特征判别力不足和对齐偏差的问题，显著提高了在多个数据集上的识别性能。

> **ai_Abstract:** 本文提出PGFA（原型引导特征对齐）范式，旨在解决零样本骨架动作识别中骨架特征判别力不足和测试时对齐偏差的问题。PGFA采用端到端跨模态对比训练框架以增强骨架-文本对齐，并引入原型引导文本特征对齐策略以缓解分布差异。实验结果表明，PGFA在多个基准数据集上显著优于现有方法。

> **摘要翻译:** 零样本骨架动作识别旨在对训练期间未曾接触过的骨架人体动作类别进行分类。这项任务极具挑战性，因为很难从已知动作泛化到未知动作。以往的研究通常采用两阶段训练：使用交叉熵损失在已知动作类别上预训练骨架编码器，然后对预提取的骨架和文本特征进行对齐，通过骨架-文本对齐和语言模型的泛化能力将知识迁移到未知类别。然而，它们的效率受到以下因素的阻碍：1) 骨架特征的判别力不足，因为固定的骨架编码器无法捕获有效骨架-文本对齐所需的必要对齐信息；2) 在测试时忽略了骨架与未知文本特征之间的对齐偏差。为此，我们提出了一种用于零样本骨架动作识别的原型引导特征对齐范式，命名为PGFA。具体来说，我们开发了一个端到端的跨模态对比训练框架，以改善骨架-文本对齐，确保骨架特征具有足够的判别力。此外，我们引入了一种原型引导的文本特征对齐策略，以减轻测试时分布差异的不利影响。我们提供了理论分析来支持我们的原型引导文本特征对齐策略，并在三个知名数据集上对我们的整体PGFA进行了实证评估。与顶尖的SMIE方法相比，我们的PGFA在NTU-60、NTU-120和PKU-MMD数据集上分别实现了22.96%、12.53%和18.54%的绝对准确率提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [Out-of-distribution detection in 3D applications: a review](https://arxiv.org/abs/2507.00570)
> *3D应用中的分布外检测：综述*

*Zizhao Li, Xueyang Kang, Joseph West, Kourosh Khoshelham* | **Category: cs.CV**

**Keywords:** 分布外检测, 3D应用, 综述, 可信赖AI, 不确定性

**Comment:** 

> **TL;DR:** 这篇综述全面回顾了3D应用中的分布外(OOD)检测，涵盖了用例、数据集、评估指标、方法论比较以及未来研究方向，旨在促进可靠AI的发展。

**AI_Comments:** 该综述论文及时且全面，解决了3D应用中OOD检测这一关键挑战，这对于提高AI系统的鲁棒性和安全性至关重要。其创新点在于将OOD检测置于可信赖AI的更广阔背景下，并为3D应用提供了专门的见解。文章结构清晰，涵盖了从用例到未来方向的多个方面，对新研究人员入门非常有益。它强调了OOD检测在弥补现实世界与训练数据之间差距方面的关键作用，并指出了3D视觉集成等重要研究机遇。

<details>
  <summary>Details</summary>

**Motivation:** 在许多3D应用（如自动驾驶）中，检测训练集中不常见的对象是一项关键能力。当前的机器学习方法通常假设所有推理时遇到的对象都属于训练数据中的已知类别，这限制了其在现实世界中的泛化能力，因为未见过的对象可能被错误分类或忽略。因此，作为可靠AI的一部分，OOD检测对于识别显著偏离训练分布的输入至关重要。

**Method:** 本文提供了一份关于可信赖和不确定AI范畴内OOD检测的全面综述。它首先介绍了不同领域的关键用例，引入了跨多种模态的基准数据集，并讨论了评估指标。接着，它对OOD检测方法进行了比较分析，探讨了模型结构、不确定性指标、分布距离分类法以及不确定性校准技术。最后，文章强调了有前景的研究方向，包括对抗性鲁棒OOD检测和故障识别。

**Result:** 本文提供了关于OOD检测的理论和实践见解，展示了新兴的研究机会，如3D视觉集成。这些见解有助于新研究人员更有效地探索该领域。

**Conclusion:** 本文旨在通过提供对OOD检测的理论和实践见解，并突出新兴研究机会（如3D视觉集成），帮助新研究人员更有效地驾驭该领域，从而促进可靠、安全和鲁棒AI系统的发展。

> **ai_Abstract:** 这篇综述论文全面探讨了3D应用中的分布外(OOD)检测问题，该问题对于自动驾驶等领域至关重要，因为传统机器学习模型难以处理训练数据中未出现的对象。文章详细介绍了OOD检测的用例、基准数据集、评估指标，并对现有方法进行了比较分析，涵盖了模型结构、不确定性指标和分布距离分类法。此外，论文还讨论了不确定性校准技术，并展望了包括对抗性鲁棒OOD检测在内的未来研究方向，旨在为可靠、安全、鲁棒的AI系统发展提供理论和实践指导。

> **摘要翻译:** 在许多3D应用（包括自动驾驶）中，检测训练集中不常见的对象是一项关键能力。用于对象识别的机器学习方法通常假设推理过程中遇到的所有对象类别都属于训练数据中存在的封闭类集。这一假设限制了其在现实世界中的泛化能力，因为在训练期间未见过的对象可能会被错误分类或完全忽略。作为可靠AI的一部分，OOD检测识别出与训练分布显著偏离的输入。本文在更广泛的可信赖和不确定AI范围内，对OOD检测进行了全面概述。我们首先介绍了跨不同领域的关键用例，引入了跨多种模态的基准数据集，并讨论了评估指标。接下来，我们对OOD检测方法进行了比较分析，探讨了模型结构、不确定性指标和分布距离分类法，以及不确定性校准技术。最后，我们强调了有前景的研究方向，包括对抗性鲁棒OOD检测和故障识别，这与3D应用尤其相关。本文提供了关于OOD检测的理论和实践见解，展示了新兴的研究机会，如3D视觉集成。这些见解有助于新研究人员更有效地探索该领域，从而促进可靠、安全和鲁棒AI系统的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [AI-Generated Video Detection via Perceptual Straightening](https://arxiv.org/abs/2507.00583)
> *基于感知矫正的AI生成视频检测*

*Christian Internò, Robert Geirhos, Markus Olhofer, Sunny Liu, Barbara Hammer, David Klindt* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** AI生成视频检测, 感知矫正, 神经网络表示, DINOv2, 时间曲率

**Comment:** 

> **TL;DR:** ReStraV提出了一种新颖的AI生成视频检测方法，通过分析神经网络表示域中视频轨迹的“感知矫正”偏差，实现了最先进的检测性能，且计算效率高。

**AI_Comments:** 该论文的创新点在于提出了“感知矫正”假设，并将其应用于AI生成视频检测，通过分析神经网络表示域中的几何特性来区分真伪。这种方法提供了一个新颖且有效的视角，避免了传统方法在泛化性上的不足。其高性能和计算效率使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI的快速发展使得高度逼真的合成视频成为可能，这对内容真实性构成了重大挑战，并引发了对滥用的紧急担忧。现有检测方法在泛化性和捕捉细微时间不一致性方面表现不佳。

**Method:** 我们提出了ReStraV（Representation Straightening Video），一种区分自然视频和AI生成视频的新方法。受“感知矫正”假设的启发，该假设认为真实世界视频轨迹在神经网络表示域中变得更直。我们分析了与这种预期几何属性的偏差。使用预训练的自监督视觉Transformer（DINOv2），我们量化了模型表示域中的时间曲率和逐步距离。我们汇总了每个视频的这些度量统计数据，并训练了一个分类器。

**Result:** AI生成视频与真实视频相比，表现出显著不同的曲率和距离模式。一个轻量级分类器实现了最先进的检测性能（例如，在VidProM基准测试中达到97.17%的准确率和98.63%的AUROC），大大优于现有的基于图像和视频的方法。

**Conclusion:** 这项工作为利用神经网络表示几何进行AI生成视频检测提供了新的见解，并提供了一个计算高效、低成本且有效的检测解决方案。

> **ai_Abstract:** ReStraV是一种新颖的AI生成视频检测方法，其灵感来源于“感知矫正”假说，即真实视频在神经网络表示域中轨迹更直。该方法利用预训练的DINOv2模型量化视频在表示域中的时间曲率和逐步距离，并基于这些统计数据训练分类器。实验结果表明，AI生成视频的曲率和距离模式与真实视频显著不同，ReStraV在VidProM基准上取得了最先进的检测性能，且计算效率高，为AI生成视频检测提供了新的几何视角。

> **摘要翻译:** 生成式AI的快速发展使得高度逼真的合成视频成为可能，这对内容真实性构成了重大挑战，并引发了对滥用的紧急担忧。现有检测方法在泛化性和捕捉细微时间不一致性方面表现不佳。我们提出了ReStraV（Representation Straightening Video），一种区分自然视频和AI生成视频的新方法。受“感知矫正”假设的启发——该假设认为真实世界视频轨迹在神经网络表示域中变得更直——我们分析了与这种预期几何属性的偏差。使用预训练的自监督视觉Transformer（DINOv2），我们量化了模型表示域中的时间曲率和逐步距离。我们汇总了每个视频的这些度量统计数据，并训练了一个分类器。我们的分析表明，AI生成视频与真实视频相比，表现出显著不同的曲率和距离模式。一个轻量级分类器实现了最先进的检测性能（例如，在VidProM基准测试中达到97.17%的准确率和98.63%的AUROC），大大优于现有的基于图像和视频的方法。ReStraV计算效率高，提供了一种低成本且有效的检测解决方案。这项工作为利用神经网络表示几何进行AI生成视频检测提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [Similarity Memory Prior is All You Need for Medical Image Segmentation](https://arxiv.org/abs/2507.00585)
> *相似性记忆先验是医学图像分割的全部所需*

*Tang Hao, Guo ZhiQing, Wang LieJun, Liu Chao* | **Category: cs.CV**

**Keywords:** 医学图像分割, 相似性记忆先验, 祖母细胞, Sim-MPNet, 深度学习

**Comment:** 

> **TL;DR:** 受“祖母细胞”启发，本文提出Sim-MPNet网络，通过相似性记忆先验和动态模块，在医学图像分割任务中取得了优于现有SOTA方法的性能。

**AI_Comments:** 本文的创新点在于将“祖母细胞”的理念引入医学图像分割领域，提出了基于相似性记忆先验的Sim-MPNet。通过DMW-LA和DS-GIM等模块，有效地利用了记忆机制和双相似性度量来提升分割性能，特别是在处理细微纹理变化和内部特征差异方面。其性能超越SOTA方法，表明了该方法的有效性和潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 受猴子初级视觉皮层(V1)中“祖母细胞”能直接识别复杂形状视觉输入的启发，研究者旨在探索这些细胞在促进医学图像分割研究中的价值。

**Method:** 本文设计了一个相似性记忆先验网络（Sim-MPNet）用于医学图像分割。具体来说，提出了动态记忆权重-损失注意力（DMW-LA），它通过原型记忆库中的相似性记忆先验来匹配和记忆医学图像中特定病变或器官的类别特征，并动态地通过权重-损失动态（W-LD）更新策略反向更新相似性记忆先验。此外，还提出了双相似性全局内部增强模块（DS-GIM），通过余弦相似度和欧氏距离深入探索输入数据特征分布的内部差异。

**Result:** 在四个公共数据集上的大量实验表明，Sim-MPNet比其他最先进的方法具有更好的分割性能。

**Conclusion:** 本文提出的Sim-MPNet网络，通过结合受“祖母细胞”启发的相似性记忆先验和创新的模块（DMW-LA, W-LD, DS-GIM），在医学图像分割任务中实现了优异的性能，超越了现有SOTA方法。

> **ai_Abstract:** 本文受“祖母细胞”启发，提出一种用于医学图像分割的相似性记忆先验网络（Sim-MPNet）。该网络包含动态记忆权重-损失注意力（DMW-LA）模块，利用原型记忆库中的相似性记忆先验学习类别特征并动态更新，以及双相似性全局内部增强模块（DS-GIM）以探索特征分布差异。在四个公共数据集上的实验证明，Sim-MPNet在分割性能上优于现有SOTA方法。

> **摘要翻译:** 近年来，研究发现猕猴初级视觉皮层（V1）中的“祖母细胞”可以直接识别复杂形状的视觉输入。这启发我们审视这些细胞在推动医学图像分割研究中的价值。本文设计了一种用于医学图像分割的相似性记忆先验网络（Sim-MPNet）。具体来说，我们提出了一种动态记忆权重-损失注意力（DMW-LA），它通过原型记忆库中的相似性记忆先验来匹配和记忆医学图像中特定病变或器官的类别特征，从而帮助网络学习类别之间细微的纹理变化。DMW-LA还通过权重-损失动态（W-LD）更新策略反向动态更新相似性记忆先验，有效地辅助网络直接提取类别特征。此外，我们提出了双相似性全局内部增强模块（DS-GIM），通过余弦相似度和欧氏距离深入探索输入数据特征分布的内部差异。在四个公共数据集上的大量实验表明，Sim-MPNet比其他最先进的方法具有更好的分割性能。我们的代码可在https://github.com/vpsg-research/Sim-MPNet上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [Context-Aware Academic Emotion Dataset and Benchmark](https://arxiv.org/abs/2507.00586)
> *情境感知学术情感数据集与基准*

*Luming Zhao, Jingwen Xuan, Jiamin Lou, Yonghui Yu, Wenwu Yang* | **Category: cs.CV**

**Keywords:** 学术情感识别, 情境感知, 数据集, CLIP, 面部表情识别

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 引入了一个名为RAER的新数据集，用于情境感知学术情感识别，并提出了CLIP-CAER方法，该方法通过整合面部表情和情境线索，在识别学术情感方面优于现有方法。

**AI_Comments:** 该论文的创新之处在于构建了首个涵盖多样化自然学习场景的情境感知学术情感数据集RAER，并提出了利用视觉-语言模型CLIP整合情境线索的CLIP-CAER方法。这对于解决学术情感识别中情境缺失的问题具有重要意义，为该领域的研究提供了宝贵资源和有效方法。

<details>
  <summary>Details</summary>

**Motivation:** 学术情感分析在评估学生参与度和认知状态方面至关重要，但由于缺乏公开可用的数据集，通过面部表情自动识别学术情感仍面临挑战。

**Method:** 提出了RAER数据集，包含约2,700个视频片段，来自约140名学生在多种自然学习环境中的数据，并使用了两种粒度的学术情感标签进行独立标注。在此基础上，提出了CLIP-CAER（基于CLIP的情境感知学术情感识别）方法，该方法利用视觉-语言模型CLIP中的可学习文本提示来有效整合视频中的面部表情和情境线索。

**Result:** 实验结果表明，CLIP-CAER显著优于主要为基本情感设计的现有视频面部表情识别方法。

**Conclusion:** 情境在准确识别学术情感中扮演着至关重要的角色。

> **ai_Abstract:** 本文针对学术情感识别领域数据集稀缺的问题，提出了一个名为RAER的新型情境感知学术情感数据集，该数据集包含来自多样化学习环境的学生视频，并进行了多粒度标注。基于该数据集，论文进一步提出了CLIP-CAER方法，该方法利用CLIP模型整合面部表情和情境线索来提高识别准确性。实验证明，CLIP-CAER在学术情感识别方面显著优于现有方法，强调了情境信息的重要性。

> **摘要翻译:** 学术情感分析在评估学生学习过程中的参与度和认知状态方面起着关键作用。本文旨在解决在真实学习环境中通过面部表情自动识别学术情感的挑战。尽管面部表情识别在基本情感方面取得了显著进展，但学术情感识别仍未得到充分探索，这主要是由于公开可用数据集的稀缺性。为了弥补这一差距，我们引入了RAER，这是一个新颖的数据集，包含从约140名学生在教室、图书馆、实验室和宿舍等多样化自然学习环境中收集的大约2,700个视频片段，涵盖课堂教学和个人学习。每个片段由大约十名标注员使用两组不同粒度的学术情感标签独立标注，从而增强了标注的一致性和可靠性。据我们所知，RAER是第一个捕捉多样化自然学习场景的数据集。观察到标注员在标注时自然地考虑面部表情以及情境线索——例如学生是否在看手机或读书——我们提出了CLIP-CAER（基于CLIP的情境感知学术情感识别）。我们的方法利用视觉-语言模型CLIP中的可学习文本提示来有效整合视频中的面部表情和情境线索。实验结果表明，CLIP-CAER显著优于主要为基本情感设计的现有视频面部表情识别方法，这强调了情境在准确识别学术情感中的关键作用。项目页面：https://zgsfer.github.io/CAER

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [429] [Overtake Detection in Trucks Using CAN Bus Signals: A Comparative Study of Machine Learning Methods](https://arxiv.org/abs/2507.00593)
> *使用CAN总线信号的卡车超车检测：机器学习方法的比较研究*

*Fernando Alonso-Fernandez, Talha Hanif Butt, Prayag Tiwari* | **Category: cs.CV**

**Keywords:** 超车检测, CAN总线信号, 机器学习, 卡车, ADAS

**Comment:** Under review at ESWA

> **TL;DR:** 本研究利用卡车CAN总线数据，比较了ANN、RF和SVM三种机器学习方法在超车检测中的性能，并发现融合策略能提高准确率，达到TNR 93%、TPR 86.5%。

**AI_Comments:** 本文的创新点在于利用CAN总线数据进行卡车超车检测，并提出分数级融合策略以提高分类性能，克服了真实世界数据多样性不足的挑战。这项研究对于发展更可靠的卡车ADAS系统具有重要意义，有助于提升道路安全和交通效率。

<details>
  <summary>Details</summary>

**Motivation:** 为了防止事故和确保交通流畅，卡车安全超车至关重要。先进驾驶辅助系统（ADAS）需要准确预测超车行为，以便及时做出明智决策。

**Method:** 研究使用沃尔沃集团提供的五辆卡车的CAN总线数据进行超车检测。评估了人工神经网络（ANN）、随机森林（RF）和支持向量机（SVM）三种分类器，并分析了不同预处理配置对性能的影响。通过多车数据训练提高泛化能力，并应用分数级融合策略以优化单车性能。

**Result:** 交通条件的可变性强烈影响信号模式，特别是在非超车类别中，如果训练数据缺乏足够多样性会影响分类性能。多车数据训练能提高泛化能力并减少特定条件偏置。单车分析表明分类准确性（特别是超车）取决于每辆车的训练数据量。分数级融合策略在大多数情况下取得了最佳的单车性能。总体通过融合实现了TNR=93%和TPR=86.5%的准确率。

**Conclusion:** 该研究表明，利用卡车CAN总线数据结合机器学习方法可以有效检测超车行为，特别是通过分数级融合策略可以提高性能。这对于开发更先进的驾驶辅助系统至关重要。

> **ai_Abstract:** 本研究利用从五辆沃尔沃卡车收集的CAN总线数据，比较了ANN、RF和SVM三种机器学习分类器在超车检测中的性能。研究发现交通条件多样性对分类性能有显著影响，多车数据训练能提高泛化能力。为解决单车数据量对准确率的影响，提出了分数级融合策略，最终实现了TNR 93%、TPR 86.5%的准确率，为ADAS系统提供支持。

> **摘要翻译:** 卡车使用CAN总线信号进行超车检测：机器学习方法的比较研究

卡车安全超车操作对于预防事故和确保高效交通流量至关重要。准确预测此类操作对于高级驾驶辅助系统（ADAS）及时做出明智决策至关重要。在本研究中，我们专注于使用从沃尔沃集团提供的五辆在役卡车收集的控制器局域网（CAN）总线数据进行超车检测。我们评估了三种常见的车辆操作检测分类器：人工神经网络（ANN）、随机森林（RF）和支持向量机（SVM），并分析了不同的预处理配置如何影响性能。我们发现交通条件的可变性强烈影响信号模式，特别是在非超车类别中，如果训练数据缺乏足够多样性会影响分类性能。由于数据是在不受限制的真实世界条件下收集的，因此无法先验地保证类别多样性。然而，使用多辆车的数据进行训练可以改善泛化能力并减少特定条件偏置。我们的单车分析还显示，分类准确性，特别是超车检测的准确性，取决于每辆车的训练数据量。为了解决这个问题，我们采用了分数级融合策略，该策略在大多数情况下都能产生最佳的单车性能。总体而言，通过融合，我们实现了TNR=93%（真阴性率）和TPR=86.5%（真阳性率）的准确率。这项研究是BIG FUN项目的一部分，该项目旨在探索如何将人工智能应用于记录的车辆数据，以理解和预测驾驶员行为，特别是与作为传统外后视镜数字替代品引入的摄像头监控系统（CMS）相关。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [432] [World4Drive: End-to-End Autonomous Driving via Intention-aware Physical Latent World Model](https://arxiv.org/abs/2507.00603)
> *World4Drive：基于意图感知物理潜在世界模型的端到端自动驾驶*

*Yupeng Zheng, Pengxuan Yang, Zebin Xing, Qichao Zhang, Yuhang Zheng, Yinfeng Gao, Pengfei Li, Teng Zhang, Zhongpu Xia, Peng Jia, Dongbin Zhao* | **Category: cs.CV**

**Keywords:** 自动驾驶, 端到端, 世界模型, 视觉基础模型, 自监督学习

**Comment:** ICCV 2025, first version

> **TL;DR:** World4Drive提出了一种无感知标注的端到端自动驾驶框架，利用视觉基础模型构建潜在世界模型，实现了SOTA性能并显著降低了错误率和碰撞率。

**AI_Comments:** 该论文提出了一种创新的端到端自动驾驶方法World4Drive，其核心在于利用视觉基础模型构建潜在世界模型，实现了无需感知标注的规划，显著降低了数据标注成本。通过引入意图感知和自监督学习，该框架在性能上超越了现有SOTA，特别是在L2误差和碰撞率方面的显著改善，以及训练速度的提升，显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的端到端自动驾驶依赖昂贵的感知监督来提取场景信息，存在构建信息丰富的驾驶世界模型以实现无需感知标注的端到端规划的挑战。

**Method:** World4Drive是一个端到端自动驾驶框架，利用视觉基础模型构建潜在世界模型。它首先提取包含驾驶意图和空间语义先验的场景特征，然后生成多模态规划轨迹并预测意图驱动的未来状态。最后，通过世界模型选择器模块评估并选择最佳轨迹，并通过实际与预测观测的自监督对齐实现无需感知标注的规划。

**Result:** World4Drive在开放循环nuScenes和闭环NavSim基准测试中，无需手动感知标注即可实现最先进的性能，L2误差相对降低18.1%，碰撞率降低46.7%，训练收敛速度提高3.75倍。

**Conclusion:** World4Drive成功地实现了无需感知标注的端到端自动驾驶规划，并在多个关键性能指标上达到了最先进水平，证明了其有效性和优越性。

> **ai_Abstract:** World4Drive是一个端到端自动驾驶框架，旨在解决传统方法对昂贵感知标注的依赖。它利用视觉基础模型构建意图感知的物理潜在世界模型，通过自监督学习实现无感知标注的轨迹生成和选择。该方法通过提取场景特征、生成多模态轨迹并预测未来状态，最终选择最佳轨迹。World4Drive在nuScenes和NavSim基准测试中取得了最先进的性能，显著降低了L2误差和碰撞率，并加快了训练收敛速度。

> **摘要翻译:** 端到端自动驾驶直接从原始传感器数据生成规划轨迹，但它通常依赖于昂贵的感知监督来提取场景信息。一个关键的研究挑战随之出现：构建一个信息丰富的驾驶世界模型，以通过自监督学习实现无需感知标注的端到端规划。在本文中，我们提出了World4Drive，一个端到端自动驾驶框架，它利用视觉基础模型构建潜在世界模型，用于生成和评估多模态规划轨迹。具体而言，World4Drive首先提取场景特征，包括驾驶意图和由视觉基础模型提供的富含空间语义先验的世界潜在表示。然后，它根据当前场景特征和驾驶意图生成多模态规划轨迹，并在潜在空间内预测多个意图驱动的未来状态。最后，它引入了一个世界模型选择器模块来评估和选择最佳轨迹。我们通过实际未来观测与从潜在空间重建的预测观测之间的自监督对齐，实现了无需感知标注的端到端规划。World4Drive在开放循环nuScenes和闭环NavSim基准测试中，无需手动感知标注即可实现最先进的性能，展示了L2误差相对降低18.1%，碰撞率降低46.7%，训练收敛速度提高3.75倍。代码将在https://github.com/ucaszyp/World4Drive 上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [434] [De-Simplifying Pseudo Labels to Enhancing Domain Adaptive Object Detection](https://arxiv.org/abs/2507.00608)
> *伪标签去简化以增强域适应目标检测*

*Zehua Fu, Chenguang Liu, Yuyu Chen, Jiaqi Zhou, Qingjie Liu, Yunhong Wang* | **Category: cs.CV**

**Keywords:** 无监督域适应, 目标检测, 自标记, 伪标签, 简单标签偏差

**Comment:** Accepted by IEEE Transactions on Intelligent Transportation Systems.
  15 pages, 10 figures

> **TL;DR:** 该论文提出了一种名为 DeSimPL 的新方法，通过解决训练过程中简单样本比例过高的问题，显著提高了自标记域适应目标检测器的性能。

**AI_Comments:** 该论文针对自标记域适应目标检测中的核心问题——简单标签偏差——提出了创新性的解决方案。通过引入实例级记忆库、对抗样本和自适应加权损失，DeSimPL 有效地提升了自标记方法的性能，使其更接近域对齐方法。其创新点在于对伪标签质量的精细化管理和训练过程的优化，对于推动自标记在无监督域适应领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 交通和运输场景中的目标检测需要大量高质量的标注数据，这耗时耗力。因此，无监督域适应（UDA）在目标检测中受到关注。尽管域对齐方法表现出色，但自标记方法因其简洁和高效而流行。本文旨在解决自标记检测器性能不如域对齐方法的问题，特别是识别出训练过程中简单样本比例过高（即简单标签偏差）是核心原因。

**Method:** 本文提出了一种名为 De-Simplifying Pseudo Labels (DeSimPL) 的新方法来缓解简单标签偏差问题。DeSimPL 利用实例级记忆库实现创新的伪标签更新策略，并在训练期间引入对抗样本以增加样本比例。此外，还提出了一种自适应加权损失，以避免模型在训练后期受大量假阳性伪标签的影响。

**Result:** 实验结果表明，DeSimPL 有效地减少了训练过程中简单样本的比例，从而显著提高了自标记检测器的性能。在四个基准测试上进行的广泛实验验证了作者的分析和结论。

**Conclusion:** 本文提出 DeSimPL 方法，通过解决自标记域适应目标检测中简单标签偏差问题，有效提升了模型性能，并在多个基准测试上得到验证。

> **ai_Abstract:** 该论文旨在解决无监督域适应目标检测中自标记方法存在的“简单标签偏差”问题，即训练过程中简单样本比例过高导致性能受限。为此，作者提出了 De-Simplifying Pseudo Labels (DeSimPL) 方法。DeSimPL 引入实例级记忆库用于伪标签更新，并利用对抗样本增加训练样本的多样性，同时采用自适应加权损失以应对后期训练中假阳性伪标签过多的问题。实验证明，DeSimPL 有效降低了简单样本比例，显著提升了自标记检测器的性能。

> **摘要翻译:** 尽管取得了显著成功，但在交通和运输场景中进行目标检测需要耗时费力地获取高质量的标注数据。因此，用于目标检测的无监督域适应（UDA）最近受到了越来越多的研究关注。用于目标检测的 UDA 一直由域对齐方法主导，这些方法取得了最佳性能。最近，自标记方法因其简洁性和高效性而受到欢迎。在本文中，我们研究了阻碍自标记检测器达到与域对齐方法相当性能的局限性。具体来说，我们认为训练过程中简单样本的比例过高，即简单标签偏差，是核心原因。我们提出了一种名为伪标签去简化（DeSimPL）的新方法来缓解这个问题。DeSimPL 利用实例级记忆库实现创新的伪标签更新策略。然后，在训练期间引入对抗样本以增加比例。此外，我们提出了一种自适应加权损失，以避免模型在训练后期受到大量假阳性伪标签的影响。实验结果表明，DeSimPL 有效地减少了训练过程中简单样本的比例，从而显著提高了自标记检测器的性能。在四个基准测试上进行的广泛实验验证了我们的分析和结论。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions](https://arxiv.org/abs/2507.00648)
> *UMDATrack：恶劣天气条件下统一多领域自适应跟踪*

*Siyuan Yao, Rui Zhu, Ziqi Wang, Wenqi Ren, Yanyang Yan, Xiaochun Cao* | **Category: cs.CV**

**Keywords:** 视觉目标跟踪, 域适应, 恶劣天气, 场景生成, 目标感知

**Comment:** Accepted to ICCV 2025

> **TL;DR:** UMDATrack提出一个统一域适应框架，通过场景生成器、域定制适配器和目标感知置信度对齐模块，显著提升了恶劣天气下的视觉目标跟踪性能。

**AI_Comments:** 这篇论文通过提出一个统一的域适应框架UMDATrack，有效地解决了视觉目标跟踪在恶劣天气下性能下降的关键问题。其创新点在于结合了可控场景生成器进行数据合成、设计了高效的域定制适配器（DCA）以及引入了基于最优传输的目标感知置信度对齐模块（TCA），这些组件共同确保了模型在多变环境中的鲁棒性和高精度。该研究对于提升实际应用中视觉跟踪系统的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉目标跟踪方法主要关注良好条件下的数据，在夜间或多雾等恶劣天气条件下，巨大的域偏移导致性能显著下降。

**Method:** 提出UMDATrack，一个统一的域适应框架。具体方法包括：1) 使用可控场景生成器合成少量（源白天数据集的2%以下）多天气条件下的未标注视频，由文本提示引导；2) 设计一个简单有效的域定制适配器（DCA），使目标表示快速适应各种天气条件，无需冗余模型更新；3) 引入目标感知置信度对齐模块（TCA），遵循最优传输定理，增强源域和目标域之间的定位一致性。

**Result:** UMDATrack能够超越现有先进的视觉跟踪器，并显著提升了最先进的性能。

**Conclusion:** UMDATrack通过其统一的域适应框架，在恶劣天气条件下实现了高质量的目标状态预测，并达到了最先进的跟踪性能。

> **ai_Abstract:** UMDATrack提出了一种统一的多领域自适应跟踪框架，旨在解决视觉目标跟踪在恶劣天气条件下因域偏移导致的性能下降问题。该方法通过可控场景生成器合成少量恶劣天气视频，并结合域定制适配器（DCA）实现快速域适应，同时引入目标感知置信度对齐模块（TCA）提升定位一致性。实验证明UMDATrack显著优于现有先进跟踪器，达到了新的SOTA水平。

> **摘要翻译:** 视觉目标跟踪在过去几十年取得了可喜的进展。现有的大多数方法都专注于在良好条件下的白天数据中学习目标表示，然而，对于夜间或多雾环境等不受约束的真实世界场景，巨大的域偏移导致性能显著下降。在本文中，我们提出了UMDATrack，它能够在统一的域适应框架下，在各种恶劣天气条件下保持高质量的目标状态预测。具体来说，我们首先使用一个可控场景生成器，在不同文本提示的指导下，合成少量（源白天数据集的不到2%帧）在多种天气条件下的未标注视频。然后，我们设计了一个简单而有效的域定制适配器（DCA），使得目标对象的表示能够快速适应各种天气条件，而无需冗余的模型更新。此外，为了增强源域和目标域之间的定位一致性，我们提出了一个遵循最优传输定理的目标感知置信度对齐模块（TCA）。大量的实验表明，UMDATrack可以超越现有先进的视觉跟踪器，并以显著优势达到新的最先进性能。我们的代码可在https://github.com/Z-Z188/UMDATrack 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [LoD-Loc v2: Aerial Visual Localization over Low Level-of-Detail City Models using Explicit Silhouette Alignment](https://arxiv.org/abs/2507.00659)
> *LoD-Loc v2: 基于显式轮廓对齐的低细节层次城市模型上的航空视觉定位*

*Juelin Zhu, Shuaibang Peng, Long Wang, Hanlin Tan, Yu Liu, Maojun Zhang, Shen Yan* | **Category: cs.CV**

**Keywords:** 航空视觉定位, 低细节层次模型, 轮廓对齐, 粒子滤波, 城市模型

**Comment:** Accepted by ICCV 2025

> **TL;DR:** LoD-Loc v2 提出了一种新的方法，首次实现了在低细节层次（LoD1）城市模型上进行航空视觉定位，通过显式轮廓对齐的粗到精策略，显著提升了定位精度并超越了现有方法。

**AI_Comments:** LoD-Loc v2的创新之处在于其首次成功地将航空视觉定位扩展到低细节层次（LoD1）城市模型，这对于大规模城市测绘和无人机导航具有重要意义。通过显式轮廓对齐的粗到精策略，有效地利用了LoD1模型中有限的几何信息。此外，发布数据集也极大地推动了该领域的研究进展。其超越基于纹理模型的方法的性能也显示了其在几何信息利用上的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LoD-Loc方法主要依赖高LoD城市模型（LoD2/3），但大多数可用和计划建设的城市模型都是低LoD（LoD1）。在低LoD模型上实现定位可以释放无人机在全球城市定位的潜力。

**Method:** 本文提出了LoD-Loc v2，采用粗到精的显式轮廓对齐策略来实现低LoD城市模型的精确空中定位。具体步骤包括：1. **建筑物轮廓获取：** 使用建筑物分割网络来塑造建筑物轮廓。2. **粗姿态选择：** 通过在先验姿态周围均匀采样姿态假设构建姿态成本体积，衡量投影轮廓和预测轮廓之间的对齐程度，选择最大值对应的姿态作为粗姿态。3. **精细姿态估计：** 采用结合多光束跟踪方法的粒子滤波来高效探索假设空间并获得最终姿态估计。此外，还发布了两个LoD1城市模型数据集（覆盖10.7平方公里），包含真实RGB查询和地面真值姿态标注，以促进研究。

**Result:** 实验结果表明，LoD-Loc v2 提高了高LoD模型的估计精度，并首次实现了在低LoD模型上的定位。此外，它以较大的优势超越了最先进的基线方法，甚至超过了基于纹理模型的方法，并拓宽了收敛范围以适应更大的先验误差。

**Conclusion:** LoD-Loc v2 成功解决了在低细节层次（LoD1）城市模型上进行航空视觉定位的难题，通过创新的显式轮廓对齐策略和粗到精的方法，显著提升了定位性能，并为该领域的研究提供了新的数据集，证明了其在实际应用中的巨大潜力。

> **ai_Abstract:** 本文提出了LoD-Loc v2，一种针对低细节层次（LoD1）城市模型进行航空视觉定位的新方法。针对现有方法依赖高LoD模型而实际广泛存在低LoD模型的问题，LoD-Loc v2采用显式轮廓对齐的粗到精策略。首先通过建筑物分割获取轮廓，然后进行粗姿态选择（基于姿态成本体积），最后通过粒子滤波和多光束跟踪进行精细姿态估计。实验证明，LoD-Loc v2不仅提升了高LoD模型的精度，更首次实现了低LoD模型的定位，并显著超越了现有SOTA方法。为促进研究，作者还发布了两个LoD1数据集。

> **摘要翻译:** 我们提出了一种在低细节层次（LoD）城市模型上进行航空视觉定位的新方法。以前基于线框对齐的方法LoD-Loc已经利用LoD模型显示出有希望的定位结果。然而，LoD-Loc主要依赖于高LoD（LoD3或LoD2）城市模型，但大多数可用模型和许多国家计划在全国范围内建设的模型都是低LoD（LoD1）。因此，在低LoD城市模型上实现定位可以释放无人机在全球城市定位的潜力。为了解决这些问题，我们引入了LoD-Loc v2，它采用粗到精的策略，使用显式轮廓对齐，在空中实现对低LoD城市模型的精确定位。具体来说，给定一个查询图像，LoD-Loc v2首先应用建筑物分割网络来塑造建筑物轮廓。然后，在粗姿态选择阶段，我们通过在先验姿态周围均匀采样姿态假设来构建姿态成本体积，以表示姿态概率分布。体积的每个成本都衡量投影轮廓和预测轮廓之间的对齐程度。我们选择具有最大值的姿态作为粗姿态。在精细姿态估计阶段，采用结合多光束跟踪方法的粒子滤波方法来有效探索假设空间并获得最终的姿态估计。为了进一步促进该领域的研究，我们发布了两个LoD1城市模型数据集，覆盖10.7平方公里，以及真实的RGB查询和地面真值姿态标注。实验结果表明，LoD-Loc v2提高了高LoD模型的估计精度，并首次实现了低LoD模型的定位。此外，它以较大的优势超越了最先进的基线方法，甚至超过了基于纹理模型的方法，并拓宽了收敛盆地以适应更大的先验误差。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [440] [A Unified Transformer-Based Framework with Pretraining For Whole Body Grasping Motion Generation](https://arxiv.org/abs/2507.00676)
> *一种基于Transformer的预训练统一框架，用于全身抓取运动生成*

*Edward Effendy, Kuan-Wei Tseng, Rei Kawakami* | **Category: cs.CV**

**Keywords:** 全身抓取, Transformer, 运动生成, 预训练, 数据稀缺

**Comment:** 

> **TL;DR:** 提出了一种基于Transformer的统一框架，通过预训练解决全身抓取中的姿态生成和运动填充问题，实现逼真稳定的物体交互。

**AI_Comments:** 该论文的创新点在于提出了一个统一的Transformer框架来解决全身抓取中的姿态和运动生成问题，并通过数据高效的预训练策略有效缓解了手-物体交互数据稀缺的挑战。其模块化设计使其具有良好的通用性和可扩展性，未来有望应用于更广泛的人体运动生成任务。

<details>
  <summary>Details</summary>

**Motivation:** 现有全身抓取方法在生成逼真稳定的物体交互方面存在挑战，且手-物体交互数据稀缺。

**Method:** 该框架包含三个阶段：抓取姿态生成、时间填充和LiftUp Transformer，用于将下采样关节恢复到高分辨率标记。为了解决数据稀缺问题，引入了数据高效的广义预训练阶段，在大规模多样化运动数据集上学习可转移的时空表示。

**Result:** 在GRAB数据集上的实验表明，该方法在连贯性、稳定性和视觉真实性方面优于现有基线。

**Conclusion:** 该统一框架能够生成逼真稳定的全身抓取运动，并通过数据高效的预训练克服了数据稀缺问题。其模块化设计也易于适应其他人体运动应用。

> **ai_Abstract:** 本文提出了一种新颖的基于Transformer的统一框架，用于全身抓取运动生成。该框架通过三阶段管道处理抓取姿态生成和运动填充，以实现逼真稳定的物体交互。为应对手-物体交互数据稀缺问题，研究引入了数据高效的广义预训练策略。实验结果表明，该方法在GRAB数据集上表现优越，并具有良好的模块化和可扩展性。

> **摘要翻译:** 已被ICIP 2025接收。
我们提出了一种新颖的基于Transformer的全身抓取框架，该框架解决了姿态生成和运动填充问题，从而实现逼真稳定的物体交互。我们的管道包括三个阶段：用于全身抓取生成的抓取姿态生成、用于平滑运动连续性的时间填充，以及将下采样关节细化回高分辨率标记的LiftUp Transformer。为了克服手-物体交互数据稀缺的问题，我们引入了一个数据高效的广义预训练阶段，在大规模多样化的运动数据集上进行，从而产生了可转移到抓取任务的鲁棒时空表示。在GRAB数据集上的实验表明，我们的方法在连贯性、稳定性、和视觉真实性方面优于现有最先进的基线。其模块化设计也支持轻松适应其他人体运动应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [Rectifying Magnitude Neglect in Linear Attention](https://arxiv.org/abs/2507.00698)
> *纠正线性注意力中的幅度忽略问题*

*Qihang Fan, Huaibo Huang, Yuang Ai, ran He* | **Category: cs.CV**

**Keywords:** 线性注意力, 幅度忽略, Softmax注意力, MALA, Transformer

**Comment:** Accepted by ICCV2025

> **TL;DR:** 线性注意力因忽略查询幅度而性能下降；本文提出MALA，通过整合幅度信息来纠正此问题，并在多任务上取得优异表现。

**AI_Comments:** 这篇论文通过精确识别线性注意力中“幅度忽略”这一关键缺陷，为该领域提供了深刻见解。所提出的MALA模型简洁而有效，显著提升了线性注意力的性能，使其在各种任务中成为Softmax注意力更具效率和可行性的替代方案，尤其适用于大规模应用。其广泛的适用性凸显了其潜在的重要影响。

<details>
  <summary>Details</summary>

**Motivation:** Softmax注意力的二次复杂度限制了其在视觉任务中的应用。线性注意力虽然具有线性复杂度，但与Softmax注意力相比，其性能显著下降。本文发现其根本原因是线性注意力完全忽略了查询（Query）的幅度信息，导致注意力分数分布无法动态适应，从而与Softmax注意力产生显著差异。

**Method:** 本文分析了线性注意力的公式，发现其忽略了查询的幅度信息。基于此观察，作者提出了幅度感知线性注意力（Magnitude-Aware Linear Attention, MALA），通过修改线性注意力的计算方式，使其充分整合查询的幅度。这种调整使得MALA能够生成与Softmax注意力非常相似且结构更均衡的注意力分数分布。

**Result:** MALA在多项任务上取得了很好的结果，包括图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成。

**Conclusion:** 通过整合查询的幅度信息，MALA成功纠正了线性注意力中的性能下降问题，使其在保持线性复杂度的同时，在各种应用中具备与Softmax注意力相当的竞争力。

> **ai_Abstract:** 本文旨在解决线性注意力（Linear Attention）相对于Softmax注意力（Softmax Attention）的性能下降问题。研究发现，线性注意力完全忽略了查询（Query）的幅度信息，导致注意力分数分布不佳。为此，作者提出了幅度感知线性注意力（Magnitude-Aware Linear Attention, MALA），通过修改计算方式来充分整合查询的幅度。实验结果表明，MALA在图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成等多项任务上均取得了显著的性能提升，证明了其在纠正线性注意力局限性方面的有效性。

> **摘要翻译:** 作为Transformer的核心操作，Softmax注意力表现出卓越的全局建模能力。然而，其二次复杂度限制了其在视觉任务中的适用性。相比之下，线性注意力与Softmax注意力具有相似的公式，同时实现了线性复杂度，从而实现了高效的全局信息建模。尽管如此，与标准Softmax注意力相比，线性注意力存在显著的性能下降。在本文中，我们基于线性注意力的公式分析了这一问题的根本原因。我们发现，与Softmax注意力不同，线性注意力完全忽略了查询（Query）的幅度信息。这阻止了注意力分数分布随查询的尺度动态调整。因此，尽管其结构与Softmax注意力相似，线性注意力表现出显著不同的注意力分数分布。基于这一观察，我们提出了幅度感知线性注意力（Magnitude-Aware Linear Attention, MALA），它修改了线性注意力的计算方式，以充分结合查询的幅度。这种调整使得MALA能够生成与Softmax注意力非常相似的注意力分数分布，同时表现出更均衡的结构。我们在多项任务上评估了MALA的有效性，包括图像分类、目标检测、实例分割、语义分割、自然语言处理、语音识别和图像生成。我们的MALA在所有这些任务上都取得了很好的结果。代码将在https://github.com/qhfan/MALA 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [BEV-VAE: Multi-view Image Generation with Spatial Consistency for Autonomous Driving](https://arxiv.org/abs/2507.00707)
> *BEV-VAE：用于自动驾驶的具有空间一致性的多视角图像生成*

*Zeming Chen, Hang Zhao* | **Category: cs.CV**

**Keywords:** BEV-VAE, 多视角图像生成, 自动驾驶, 空间一致性, 潜在扩散Transformer

**Comment:** 

> **TL;DR:** BEV-VAE提出了一种用于自动驾驶的，具有空间一致性的多视角图像生成方法，它通过统一的BEV潜在空间和潜在扩散Transformer实现。

**AI_Comments:** 创新点在于BEV-VAE引入了结构化的BEV潜在空间，并将变分自编码器与潜在扩散Transformer结合，以实现具有空间一致性的多视角图像生成，这与传统的2D图像集生成方法不同。其重要性在于解决了自动驾驶领域多视角图像生成中缺乏显式3D建模的问题，确保了视图间的空间一致性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中的多视角图像生成需要跨摄像头视图的一致3D场景理解。现有方法多将此视为2D图像集生成任务，缺乏显式3D建模。本文认为结构化表示对于场景生成，特别是自动驾驶应用至关重要。

**Method:** 本文提出了BEV-VAE，用于一致且可控的视图合成。BEV-VAE首先训练一个多视角图像变分自编码器以获得紧凑统一的BEV潜在空间，然后使用潜在扩散Transformer生成场景。它支持给定相机配置的任意视图生成，并可选地支持3D布局。

**Result:** 在nuScenes和Argoverse 2 (AV2)数据集上的实验表明，BEV-VAE在3D一致性重建和生成方面都表现出强大的性能。

**Conclusion:** 本文提出的BEV-VAE通过引入结构化的BEV潜在空间和结合潜在扩散Transformer，有效解决了自动驾驶中多视角图像生成缺乏3D一致性的问题，并在实验中验证了其在3D一致性重建和生成方面的强大能力。

> **ai_Abstract:** 本文介绍了BEV-VAE，一种用于自动驾驶中多视角图像生成的新方法，通过显式3D建模解决了现有2D中心方法的局限性。BEV-VAE利用多视角图像变分自编码器创建统一的BEV潜在空间，随后使用潜在扩散Transformer进行场景生成。该方法实现了连贯且可控的视图合成，支持任意视图生成和可选的3D布局。在nuScenes和Argoverse 2数据集上的实验证明了其在3D一致性重建和生成方面的强大性能。

> **摘要翻译:** 自动驾驶中的多视角图像生成需要跨摄像头视图的一致3D场景理解。大多数现有方法将此问题视为2D图像集生成任务，缺乏显式3D建模。然而，我们认为结构化表示对于场景生成至关重要，特别是对于自动驾驶应用。本文提出了BEV-VAE，用于一致且可控的视图合成。BEV-VAE首先训练一个多视角图像变分自编码器以获得紧凑统一的BEV潜在空间，然后使用潜在扩散Transformer生成场景。BEV-VAE支持给定相机配置的任意视图生成，并可选地支持3D布局。在nuScenes和Argoverse 2 (AV2)上的实验表明，在3D一致性重建和生成方面都表现出强大的性能。代码可在以下链接获取：https://github.com/Czm369/bev-vae。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving](https://arxiv.org/abs/2507.00709)
> *TopoStreamer：自动驾驶中车道段拓扑的时间推理*

*Yiming Yang, Yueru Luo, Bingkun He, Hongbin Lin, Suzhong Fu, Chao Yan, Kun Tang, Xinrui Yan, Chao Zheng, Shuguang Cui, Zhen Li* | **Category: cs.CV, cs.AI**

**Keywords:** 车道段拓扑推理, 自动驾驶, 时间感知, TopoStreamer, 道路网络

**Comment:** 

> **TL;DR:** TopoStreamer是一个端到端的时间感知模型，通过引入流属性约束、动态车道边界位置编码和车道段去噪，解决了现有车道段拓扑推理方法在一致性位置嵌入和时间多属性学习方面的局限性，显著提高了自动驾驶中车道段和中心线感知的性能。

**AI_Comments:** TopoStreamer的创新之处在于其对时间一致性和动态位置信息的处理，通过引入流属性约束和动态车道边界位置编码，有效克服了传统方法在处理时序数据时的局限性。车道段去噪的引入也增强了模型对复杂车道模式的适应性。这些改进对于自动驾驶中需要精确道路网络理解的场景（如变道、转弯）至关重要，为未来的研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在一致性位置嵌入和时间多属性学习方面存在局限性，阻碍了准确的道路网络重建，而这对于端到端自动驾驶系统执行转弯和变道等依赖道路的操作至关重要。

**Method:** 本文提出了TopoStreamer，一个用于车道段拓扑推理的端到端时间感知模型。TopoStreamer引入了三项关键改进：流属性约束（强制中心线和边界坐标及其分类的时间一致性），动态车道边界位置编码（增强查询中最新位置信息的学习），以及车道段去噪（帮助捕获多样化的车道段模式，从而提高模型性能）。

**Result:** 在OpenLane-V2数据集上，TopoStreamer相比最先进的方法取得了显著改进，在车道段感知中mAP提高了+3.4%，在中心线感知任务中OLS提高了+2.1%。

**Conclusion:** TopoStreamer通过其创新的组件，有效解决了车道段拓扑推理中的现有挑战，并在关键感知任务中展现出卓越的性能，从而提升了自动驾驶系统的道路网络理解能力。

> **ai_Abstract:** 本文提出了TopoStreamer，一个用于自动驾驶中车道段拓扑推理的端到端时间感知模型。针对现有方法在一致性位置嵌入和时间多属性学习方面的不足，TopoStreamer引入了流属性约束、动态车道边界位置编码和车道段去噪三项创新。这些改进有效提升了模型捕获时间一致性、最新位置信息和多样化车道模式的能力。实验结果表明，在OpenLane-V2数据集上，TopoStreamer在车道段和中心线感知任务上均显著超越了现有最先进方法，证明了其在构建准确道路网络方面的优越性，从而支持自动驾驶系统进行复杂的道路依赖操作。

> **摘要翻译:** 车道段拓扑推理通过捕获车道段之间的拓扑关系及其语义类型来构建一个全面的道路网络。这使得端到端自动驾驶系统能够执行依赖道路的操作，例如转弯和变道。然而，现有方法在一致性位置嵌入和时间多属性学习方面的局限性阻碍了准确的道路网络重建。为了解决这些问题，我们提出了TopoStreamer，一个用于车道段拓扑推理的端到端时间感知模型。具体来说，TopoStreamer引入了三项关键改进：流属性约束、动态车道边界位置编码和车道段去噪。流属性约束在中心线和边界坐标及其分类方面强制执行时间一致性。同时，动态车道边界位置编码增强了查询中最新位置信息的学习，而车道段去噪有助于捕获多样化的车道段模式，最终提高了模型性能。此外，我们使用车道边界分类度量评估了现有模型的准确性，该度量是自动驾驶中变道场景的关键衡量标准。在OpenLane-V2数据集上，TopoStreamer相比最先进的方法显示出显著改进，在车道段感知中mAP获得了+3.4%的实质性性能提升，在中心线感知任务中OLS获得了+2.1%的提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [448] [UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement](https://arxiv.org/abs/2507.00721)
> *UPRE：通过统一提示和表示增强实现目标检测的零样本域适应*

*Xiao Zhang, Fei Wei, Yong Wang, Wenda Zhao, Feiyi Li, Xiangxiang Chu* | **Category: cs.CV**

**Keywords:** 零样本域适应, 目标检测, 视觉-语言模型, 提示学习, 表示增强

**Comment:** ICCV2025

> **TL;DR:** UPRE通过统一优化文本提示和视觉表示，解决了零样本目标检测中VLM与任务不匹配的问题，并在多个基准测试中表现出色。

**AI_Comments:** UPRE的创新点在于其统一优化文本提示和视觉表示，并引入了多视图域提示和多级增强策略，有效解决了零样本域适应中VLM与检测任务的对齐问题。这对于在目标域无图像的情况下实现有效目标检测具有重要意义，尤其是在实际应用中数据稀缺的场景。

<details>
  <summary>Details</summary>

**Motivation:** 零样本域适应（ZSDA）在目标域缺乏图像的情况下具有挑战性。现有方法利用视觉-语言模型（VLMs）解决此问题，但主要关注域分布偏移，而忽略了检测任务与依赖手动提示的VLM之间的错位。

**Method:** 提出统一提示和表示增强（UPRE）框架，联合优化文本提示和视觉表示。具体包括：引入结合语言域先验和检测特定知识的多视图域提示；引入生成域风格变化的视觉表示增强模块。此外，引入多级增强策略，包括相对域距离（在图像级别对齐多模态表示）和正负分离（在实例级别捕获多样视觉表示）。

**Result:** 在九个基准数据集上进行了大量实验，结果表明该框架在零样本域适应检测场景中表现出卓越的性能。

**Conclusion:** UPRE框架通过统一提示和表示增强，有效解决了零样本域适应目标检测中的挑战，并在多个基准数据集上取得了优越的性能。

> **ai_Abstract:** 本文提出了UPRE框架，旨在解决零样本域适应（ZSDA）目标检测中现有视觉-语言模型（VLM）方法忽略任务与VLM之间错位的问题。UPRE通过联合优化文本提示和视觉表示，引入了结合领域先验和检测知识的多视图域提示，以及生成风格变化的视觉表示增强模块。此外，它还采用多级增强策略，在图像和实例级别对齐并捕获多样化表示。实验证明，UPRE在多个基准数据集上取得了显著的ZSDA检测性能提升。

> **摘要翻译:** 零样本域适应（ZSDA）由于目标域缺乏图像而带来了巨大的挑战。以往的方法利用视觉-语言模型（VLMs）来应对这一挑战，利用它们的零样本学习能力。然而，这些方法主要解决域分布偏移问题，而忽略了检测任务与依赖手动制作提示的VLM之间的错位。为了克服这些局限性，我们提出了统一提示和表示增强（UPRE）框架，该框架联合优化文本提示和视觉表示。具体而言，我们的方法引入了一个多视图域提示，它结合了语言域先验知识和检测特有的知识，以及一个产生域风格变化的视觉表示增强模块。此外，我们引入了多级增强策略，包括相对域距离和正负分离，它们分别在图像级别对齐多模态表示并在实例级别捕获多样化的视觉表示。在九个基准数据集上进行的广泛实验证明了我们的框架在ZSDA检测场景中的卓越性能。代码可在https://github.com/AMAP-ML/UPRE获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [449] [Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features](https://arxiv.org/abs/2507.00724)
> *Holmes：通过解耦通用特征实现个性化大型视觉模型有效无害的模型所有权验证*

*Linghui Zhu, Yiming Li, Haiqin Weng, Yan Liu, Tianwei Zhang, Shu-Tao Xia, Zhi Wang* | **Category: cs.CV, cs.AI**

**Keywords:** 模型所有权验证, 个性化模型, 大型视觉模型, 模型窃取, 解耦通用特征

**Comment:** 

> **TL;DR:** 本文提出了一种名为Holmes的新方法，通过解耦通用特征来验证个性化大型视觉模型的模型所有权，解决了现有方法在模型窃取防御方面的局限性。

**AI_Comments:** 该论文的创新之处在于专门针对个性化大型视觉模型提出了所有权验证方法，解决了现有方法对这类模型无效或存在安全隐患的问题。通过解耦通用特征并采用三阶段验证流程（影子模型、元分类器、假设检验），该方法提供了新颖且实用的解决方案，对保护大型视觉模型的知识产权具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 个性化的大型视觉模型通过私有和有价值的本地数据进行微调，使其成为所有者宝贵的知识产权。模型窃取攻击对这些个性化模型构成了重大风险。然而，现有的防御方法（为传统DNN开发）通常针对从头开始训练的模型设计，对微调模型要么引入额外的安全风险，要么容易误判，甚至无效。

**Method:** 本文提出了一种通过解耦相似通用特征的个性化模型无害模型所有权验证方法。该方法包含三个主要阶段：第一阶段，创建保留受害者模型通用特征但破坏数据集特定特征的影子模型，并通过影子模型与受害者模型之间的输出差异表示数据集特定特征。第二阶段，训练一个元分类器，通过判断可疑模型是否包含受害者的数据集特定特征来识别被窃取的模型。第三阶段，通过假设检验进行模型所有权验证，以减轻随机性并增强鲁棒性。

**Result:** 在基准数据集上进行的广泛实验验证了所提方法在同时检测不同类型模型窃取方面的有效性。

**Conclusion:** 本文提出了一种名为Holmes的有效且无害的模型所有权验证方法，专门用于个性化大型视觉模型，通过解耦通用特征解决了现有防御方法的局限性，有效应对了模型窃取攻击。

> **ai_Abstract:** 本文提出了Holmes，一种针对个性化大型视觉模型的有效且无害的模型所有权验证方法。针对现有模型窃取防御方法对微调模型无效或存在风险的问题，Holmes通过解耦通用特征来解决。该方法包括三个阶段：首先，创建影子模型以识别数据集特定特征；其次，训练元分类器来检测窃取模型；最后，通过假设检验增强验证的鲁棒性。实验证明，该方法能有效检测不同类型的模型窃取。

> **摘要翻译:** 大型视觉模型在各种下游任务中取得了卓越的性能，这主要通过使用私有且有价值的本地数据对预训练模型进行微调来实现，这使得个性化模型成为其所有者的宝贵知识产权。与传统DNN时代类似，模型窃取攻击也对这些个性化模型构成了重大风险。然而，在本文中，我们揭示了大多数现有防御方法（为传统DNN开发），通常为从头开始训练的模型设计，要么引入额外的安全风险，要么容易误判，甚至对微调模型无效。为了缓解这些问题，本文提出了一种通过解耦相似通用特征的个性化模型无害模型所有权验证方法。总的来说，我们的方法包括三个主要阶段。在第一阶段，我们创建影子模型，这些模型保留了受害者模型的通用特征，同时破坏了数据集特定特征。我们通过影子模型和受害者模型之间的输出差异来表示受害者模型的数据集特定特征。之后，训练一个元分类器，通过确定可疑模型是否包含受害者的数据集特定特征来识别被窃取的模型。在第三阶段，我们通过假设检验进行模型所有权验证，以减轻随机性并增强鲁棒性。在基准数据集上进行的广泛实验验证了所提方法在同时检测不同类型模型窃取方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [451] [ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2507.00898)
> *ONLY：单层干预足以减轻大型视觉语言模型中的幻觉*

*Zifu Wan, Ce Zhang, Silong Yong, Martin Q. Ma, Simon Stepputtis, Louis-Philippe Morency, Deva Ramanan, Katia Sycara, Yaqi Xie* | **Category: cs.CV, cs.CL**

**Keywords:** 大型视觉语言模型, 幻觉, 解码, 单层干预, 实时应用

**Comment:** Accepted by ICCV 2025. Project page: https://zifuwan.github.io/ONLY/

> **TL;DR:** ONLY是一种无需训练的解码方法，通过单层干预和单次查询有效减轻大型视觉语言模型（LVLMs）中的幻觉，优于现有方法并适用于实时应用。

**AI_Comments:** ONLY的创新点在于其“单层干预”和“单次查询”的训练无关解码方法，显著提高了缓解LVLM幻觉的效率，使其适用于实时应用。这解决了现有对比解码方法速度慢的痛点，为LVLM的实际部署提供了更可靠的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉语言模型（LVLMs）在多模态任务中表现出色，但面临持续的幻觉问题，这限制了它们在实际应用中的可靠部署。现有对比解码方法需要多次查询，导致响应生成速度慢，不适用于实时应用。

**Method:** 我们提出了ONLY，一种无需训练的解码方法。它仅在解码过程中需要单次查询和单层干预。具体来说，ONLY通过使用每个token的文本到视觉熵比率选择性地放大关键文本信息来增强文本输出。

**Result:** ONLY在各种基准测试中始终优于最先进的方法，并且只需要最少的实现工作和计算成本。

**Conclusion:** ONLY通过其高效的单层干预和单次查询方法，成功缓解了大型视觉语言模型中的幻觉问题，使其更适合实时部署。

> **ai_Abstract:** 本文提出了ONLY，一种针对大型视觉语言模型（LVLMs）幻觉问题的无训练解码方法。与需要多次查询的现有方法不同，ONLY仅需单次查询和单层干预，通过放大关键文本信息来提高效率和实时适用性。实验证明ONLY在性能上超越了现有SOTA方法，且计算成本和实现难度极低。

> **摘要翻译:** 最近的大型视觉语言模型（LVLMs）引入了一种通过文本响应理解和推理图像输入的新范式。尽管它们在一系列多模态任务中取得了卓越的性能，但它们面临着持续的幻觉挑战，这带来了实际的弱点并引发了对其在现实世界应用中可靠部署的担忧。现有工作已经探索了对比解码方法来缓解这个问题，其中将原始LVLM的输出与扰动版本的输出进行比较和对比。然而，这些方法需要两次或多次查询，这会减慢LVLMs响应生成的速度，使其不太适合实时应用。为了克服这一限制，我们提出了ONLY，一种无需训练的解码方法，它仅在解码过程中需要单次查询和单层干预，从而实现高效的实时部署。具体来说，我们通过使用每个token的文本到视觉熵比率选择性地放大关键文本信息来增强文本输出。广泛的实验结果表明，我们提出的ONLY在各种基准测试中始终优于最先进的方法，同时只需要最少的实现工作和计算成本。代码可在https://github.com/zifuwan/ONLY获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [453] [Improving the Reasoning of Multi-Image Grounding in MLLMs via Reinforcement Learning](https://arxiv.org/abs/2507.00748)
> *通过强化学习改进多模态大语言模型中的多图像定位推理能力*

*Bob Zhang, Haoran Li, Tao Zhang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Yanbin Hao* | **Category: cs.CV**

**Keywords:** 多模态大语言模型, 强化学习, 多图像定位, 推理, 视觉接地

**Comment:** 11 pages

> **TL;DR:** 论文通过强化学习后训练策略，显著提升了多模态大语言模型在多图像定位推理任务上的性能和泛化能力。

**AI_Comments:** 这篇论文创新性地将强化学习应用于MLLM的后训练，以解决其在多图像推理和泛化方面的固有局限性。通过引入思维链冷启动和基于规则的RL指导，该方法有效地提升了模型在复杂视觉任务中的推理性能，展示了RL在优化MLLM高级推理能力方面的潜力。其在多个基准上的显著性能提升证明了该策略的有效性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLM）在单图像视觉定位方面表现出色，但在处理涉及复杂多图像组合和多模态指令的实际应用时性能下降，这暴露出其在跨图像推理和泛化方面的局限性。

**Method:** 采用基于强化学习（RL）的后训练策略。首先，合成高质量的思维链（CoT）数据进行冷启动初始化，然后使用低秩适应（LoRA）进行监督微调（SFT）。冷启动训练阶段使模型能够识别正确的解决方案。随后，使用合并的SFT模型进行拒绝采样以筛选高质量的RL数据，并利用基于规则的RL来引导模型走向最佳推理路径。

**Result:** 在MIG-Bench上实现了+9.04%的改进，在几个域外推理定位基准上比SFT基线提高了+4.98%。在多图像感知方面也表现出强大的泛化能力，在BLINK和MMIU基准的子集上分别比基础模型提高了+3.1%和+2.4%。

**Conclusion:** 论文提出的基于强化学习的后训练策略有效提升了MLLM在多图像定位任务中的推理性能和泛化能力。

> **ai_Abstract:** 本文提出一种基于强化学习的后训练策略，旨在解决多模态大语言模型在复杂多图像定位任务中推理和泛化能力不足的问题。该方法通过合成思维链数据进行冷启动SFT，并结合拒绝采样和基于规则的强化学习来优化模型推理路径。实验证明，该方法显著提升了MLLM在多图像定位基准上的性能，并增强了其在多图像感知方面的泛化能力。

> **摘要翻译:** 最近，多模态大语言模型（MLLM）在具有文本引用的单图像场景中表现出色。然而，当处理涉及复杂多图像组合和多模态指令的实际应用时，它们的性能会下降，这揭示了其在跨图像推理和泛化方面的局限性。为了解决这些挑战，我们采用了一种基于强化学习（RL）的后训练策略，以提高MLLM在多图像定位任务中的推理性能。我们的方法首先合成高质量的思维链（CoT）数据进行冷启动初始化，然后使用低秩适应（LoRA）进行监督微调（SFT）。冷启动训练阶段使模型能够识别正确的解决方案。随后，我们使用合并的SFT模型进行拒绝采样，以筛选高质量的RL数据，并利用基于规则的RL来引导模型走向最佳推理路径。广泛的实验结果表明了我们方法的有效性，在MIG-Bench上取得了+9.04%的改进，在几个域外推理定位基准上比SFT基线提高了+4.98%。此外，我们的方法在多图像感知方面也表现出强大的泛化能力，在BLINK和MMIU基准的子集上分别比基础模型提高了+3.1%和+2.4%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [455] [Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs](https://arxiv.org/abs/2507.00754)
> *语言解锁型ViT (LUViT)：用大型语言模型赋能自监督视觉Transformer*

*Selim Kuzucu, Muhammad Ferjad Naeem, Anna Kukleva, Federico Tombari, Bernt Schiele* | **Category: cs.CV**

**Keywords:** ViT, LLM, 自监督学习, 模态匹配, LUViT

**Comment:** 26 pages, 6 figures

> **TL;DR:** LUViT提出了一种协同预训练策略，通过结合MAE和LoRA来解决LLM和ViT之间的模态不匹配问题，从而显著提升了下游视觉任务的性能。

**AI_Comments:** LUViT的创新点在于它成功地解决了LLM与ViT之间模态不匹配的核心问题，而非仅仅冻结LLM模块。通过MAE和LoRA的协同预训练，实现了ViT和LLM的共同适应，这对于释放LLM在视觉任务中的潜力至关重要。该方法为多模态学习提供了一个新的范式，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）与视觉Transformer（ViTs）的结合在纯视觉任务中具有巨大潜力，但面临文本中心预训练的LLMs与视觉中心训练的ViTs之间固有的模态不匹配挑战。直接融合往往无法充分利用LLM的潜力，并导致微调不稳定，通常只能冻结LLM模块。

**Method:** 本文引入了语言解锁型视觉Transformer (LUViT)，通过协同预训练策略来弥合模态不匹配。具体方法包括：1) 采用掩码自编码 (MAE) 对ViT骨干进行预训练，以获得更丰富的视觉表示；2) 利用MAE目标，同时训练LLM模块内的低秩适应 (LoRA) 层。这种联合优化引导ViT生成与LLM对齐的特征，并使LLM有效解释视觉信息。

**Result:** LUViT在各种下游视觉任务上显著提高了性能。

**Conclusion:** LUViT为利用LLM知识进行视觉理解提供了一种更有效和高效的途径。

> **ai_Abstract:** LUViT是一种新型的视觉Transformer模型，旨在解决大型语言模型（LLMs）与视觉Transformer（ViTs）在集成时面临的模态不匹配问题。通过提出一种协同预训练策略，LUViT结合了掩码自编码（MAE）来预训练ViT，并同时使用MAE目标训练LLM模块中的低秩适应（LoRA）层。这种联合优化使得ViT能够生成与LLM对齐的特征，并帮助LLM有效理解视觉信息。实验结果表明，LUViT显著提升了在多种下游视觉任务上的表现，为利用LLM知识增强视觉理解提供了一条高效途径。

> **摘要翻译:** 大型语言模型（LLMs）模块与视觉Transformer（ViTs）的集成，通过利用LLMs丰富的语义知识和推理能力，在纯视觉任务中展现出巨大的前景。然而，一个根本性的挑战在于LLMs以文本为中心的预训练与ViTs以视觉为中心的训练之间固有的模态不匹配。直接融合往往无法充分利用LLM的潜力，并导致微调不稳定。因此，LLM模块通常保持冻结，而只学习视觉组件。为了解决这些挑战，我们引入了语言解锁型视觉Transformer (LUViT)，这是一种通过协同预训练策略弥合模态不匹配的新方法。LUViT通过以下方式共同适应ViT骨干和LLM融合模块：(1) 采用掩码自编码 (MAE) 对ViT进行预训练，以获得更丰富的视觉表示；(2) 同时使用MAE目标训练LLM模块内的低秩适应 (LoRA) 层。这种联合优化引导ViT生成与LLM对齐的特征，并使LLM有效解释视觉信息。我们通过广泛的实验证明，LUViT显著提高了各种下游视觉任务的性能，展示了利用LLM知识进行视觉理解的更有效和高效的途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [458] [OptiPrune: Boosting Prompt-Image Consistency with Attention-Guided Noise and Dynamic Token Selection](https://arxiv.org/abs/2507.00789)
> *OptiPrune：通过注意力引导噪声和动态令牌选择提升提示-图像一致性*

*Ziji Lu* | **Category: cs.CV**

**Keywords:** 文本到图像扩散模型, 提示-图像一致性, 噪声优化, 令牌剪枝, 计算效率

**Comment:** 

> **TL;DR:** OptiPrune是一个统一框架，结合了注意力引导的噪声优化和动态令牌剪枝，以提高文本到图像扩散模型在资源受限硬件上的提示-图像一致性，同时显著降低计算成本。

**AI_Comments:** OptiPrune的创新在于其统一的框架，同时解决了文本到图像扩散模型的语义对齐和计算效率问题。通过结合注意力引导的噪声优化和动态令牌剪枝，它提供了一个平衡质量和性能的有效方案，特别适用于资源受限的硬件。其在噪声优化中保留高斯先验以及在令牌剪枝中引入随机性的设计，体现了对生成质量和泛化能力的细致考量，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像扩散模型在生成图像和文本提示之间实现准确的语义对齐方面存在困难，同时难以在资源受限的硬件上保持部署效率。现有方法要么通过噪声优化产生大量计算开销，要么通过激进的令牌剪枝损害语义保真度。

**Method:** 本文提出了OptiPrune，一个统一的框架，结合了分布感知初始噪声优化和基于相似性的令牌剪枝。具体来说，(1)引入了一个由注意力分数引导的分布感知噪声优化模块，将初始潜在噪声引导到语义有意义的区域，以减轻主题忽略和特征纠缠等问题；(2)设计了一种硬件高效的令牌剪枝策略，通过块级相似性选择代表性基础令牌，注入随机性以增强泛化能力，并在注意力操作之前使用最大相似度复制恢复剪枝令牌。该方法在噪声优化过程中保留了高斯先验。

**Result:** 在包括Animal-Animal在内的基准数据集上的实验表明，OptiPrune实现了最先进的提示-图像一致性，同时显著降低了计算成本。

**Conclusion:** OptiPrune通过结合分布感知噪声优化和高效令牌剪枝，有效解决了文本到图像扩散模型在语义对齐和计算效率方面的挑战，实现了卓越的性能和成本效益。

> **ai_Abstract:** OptiPrune是一个创新的统一框架，旨在解决文本到图像扩散模型在保持语义对齐和计算效率方面的挑战。它通过结合两个核心组件实现此目标：一个由注意力引导的分布感知噪声优化模块，用于将初始噪声引导至语义区域并解决主题忽略问题；以及一个硬件高效的令牌剪枝策略，通过相似性选择、随机性注入和恢复机制来优化令牌处理。该方法在噪声优化中保持高斯先验，并能在不牺牲对齐质量的情况下实现高效推理。实验证明，OptiPrune在提示-图像一致性方面达到了最先进的水平，并显著降低了计算成本。

> **摘要翻译:** 文本到图像扩散模型在生成的图像和文本提示之间实现准确的语义对齐方面常常遇到困难，同时难以在资源受限的硬件上保持部署效率。现有方法要么通过噪声优化产生大量计算开销，要么通过激进的令牌剪枝损害语义保真度。在这项工作中，我们提出了OptiPrune，一个统一的框架，它结合了分布感知的初始噪声优化和基于相似性的令牌剪枝，以同时解决这两个挑战。具体来说，(1)我们引入了一个由注意力分数引导的分布感知噪声优化模块，将初始潜在噪声引导到语义有意义的区域，从而减轻了主题忽略和特征纠缠等问题；(2)我们设计了一种硬件高效的令牌剪枝策略，通过块级相似性选择代表性基础令牌，注入随机性以增强泛化能力，并在注意力操作之前使用最大相似度复制恢复剪枝令牌。我们的方法在噪声优化过程中保留了高斯先验，并能在不牺牲对齐质量的情况下实现高效推理。在包括Animal-Animal在内的基准数据集上的实验表明，OptiPrune实现了最先进的提示-图像一致性，同时显著降低了计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [459] [LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling](https://arxiv.org/abs/2507.00790)
> *LD-RPS：通过潜在扩散循环后验采样实现零样本统一图像恢复*

*Huaqiu Li, Yong Wang, Tongwen Huang, Hailang Huang, Haoqian Wang, Xiangxiang Chu* | **Category: cs.CV, cs.AI**

**Keywords:** 图像恢复, 零样本, 潜在扩散模型, 统一方法, 后验采样

**Comment:** 

> **TL;DR:** LD-RPS提出了一种基于预训练潜在扩散模型的零样本、无数据集的统一图像恢复方法，通过引入多模态理解和循环细化，在各种退化任务中表现出色。

**AI_Comments:** 本文的创新点在于其零样本和无数据集的统一图像恢复方法，这显著提升了模型的泛化能力，并避免了对大量配对数据的依赖。通过结合潜在扩散模型、多模态语义先验和循环细化，LD-RPS为低级视觉任务提供了一个强大且灵活的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像恢复方法要么针对特定任务进行定制设计，导致泛化能力受限，要么依赖配对数据集训练，受限于封闭集约束。

**Method:** 本文提出了一种新颖的、无数据集的统一方法，通过利用预训练的潜在扩散模型进行循环后验采样。该方法结合了多模态理解模型以在任务盲条件下为生成模型提供语义先验，并利用轻量级模块将退化输入与扩散模型的生成偏好对齐，同时采用循环细化进行后验采样。

**Result:** 实验结果表明，该方法优于现有最先进的方法，验证了其有效性和鲁棒性。

**Conclusion:** LD-RPS通过其创新的零样本、无数据集方法，成功解决了统一图像恢复的挑战，并在性能上超越了现有技术。

> **ai_Abstract:** LD-RPS提出了一种新颖的零样本、无数据集的统一图像恢复方法，旨在克服现有方法在泛化性和数据集依赖性方面的局限。该方法利用预训练的潜在扩散模型进行循环后验采样，并整合了多模态理解模型提供语义先验，同时通过轻量级模块对齐输入与扩散模型偏好，并进行循环细化。实验证明其在多种退化任务中优于现有SOTA方法，展现出卓越的有效性和鲁棒性。

> **摘要翻译:** 统一图像恢复是低级视觉中一个极具挑战性的任务。现有方法要么为特定任务量身定制设计，限制了它们在各种类型退化中的泛化能力，要么依赖于配对数据集进行训练，从而受到封闭集约束的困扰。为了解决这些问题，我们提出了一种新颖的、无数据集的统一方法，通过利用预训练的潜在扩散模型进行循环后验采样。我们的方法结合了多模态理解模型，在任务盲条件下为生成模型提供语义先验。此外，它利用一个轻量级模块将退化输入与扩散模型的生成偏好对齐，并采用循环细化进行后验采样。大量实验表明，我们的方法优于现有最先进的方法，验证了其有效性和鲁棒性。我们的代码和数据将在https://github.com/AMAP-ML/LD-RPS上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [462] [TRACE: Temporally Reliable Anatomically-Conditioned 3D CT Generation with Enhanced Efficiency](https://arxiv.org/abs/2507.00802)
> *TRACE：具有增强效率的时间可靠解剖条件3D CT生成*

*Minye Shao, Xingyu Miao, Haoran Duan, Zeyu Wang, Jingkun Chen, Yawen Huang, Xian Wu, Jingjing Deng, Yang Long, Yefeng Zheng* | **Category: cs.CV**

**Keywords:** 3D医学图像生成, 条件扩散模型, 解剖保真度, 时空一致性, 计算效率

**Comment:** Accepted to MICCAI 2025 (this version is not peer-reviewed; it is the
  preprint version). MICCAI proceedings DOI will appear here

> **TL;DR:** TRACE是一个高效生成具有解剖保真度和时空一致性的3D医学图像的框架，解决了现有方法的局限性。

**AI_Comments:** TRACE的创新之处在于其将3D医学图像生成问题转化为2D视频帧对处理，并结合多模态信息（分割先验、放射学报告）和光流技术来确保解剖和时间一致性，同时显著提高效率。这对于资源有限的临床环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D医学图像生成对于数据增强和患者隐私至关重要，但现有方法存在解剖保真度有限、轴向长度受限以及计算成本高昂的问题，不适用于资源有限的地区。

**Method:** TRACE是一个利用2D多模态条件扩散方法生成具有时空对齐的3D医学图像的框架。它将连续2D切片建模为视频帧对，结合分割先验和放射学报告以实现解剖对齐，并引入光流以保持时间连贯性。在推理过程中，采用重叠帧策略将帧对链接成可变长度序列，并重建为时空和解剖对齐的3D体。

**Result:** 实验结果表明，TRACE有效地平衡了计算效率与解剖保真度和时空一致性的保持。

**Conclusion:** TRACE提供了一种高效且可靠的3D医学图像生成解决方案，克服了现有方法的局限性，适用于临床实践。

> **ai_Abstract:** TRACE是一个创新的框架，通过2D多模态条件扩散方法高效生成高质量的3D医学图像。它通过将2D切片视为视频帧对，并结合解剖先验和光流技术，解决了现有方法在解剖保真度、轴向长度和计算成本方面的局限性，实现了时空和解剖上的精确对齐。

> **摘要翻译:** 3D医学图像生成对于数据增强和患者隐私至关重要，需要适合临床实践的可靠高效模型。然而，现有方法存在解剖保真度有限、轴向长度受限以及计算成本高昂的问题，使得资源和基础设施有限的地区难以使用。我们引入了TRACE，一个利用2D多模态条件扩散方法生成具有时空对齐的3D医学图像的框架。TRACE将连续2D切片建模为视频帧对，结合分割先验和放射学报告以实现解剖对齐，并引入光流以保持时间连贯性。在推理过程中，采用重叠帧策略将帧对链接成可变长度序列，并重建为时空和解剖对齐的3D体。实验结果表明，TRACE有效地平衡了计算效率与解剖保真度和时空一致性的保持。代码可在：https://github.com/VinyehShaw/TRACE 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [464] [CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs](https://arxiv.org/abs/2507.00817)
> *CAVALRY-V: 针对视频多模态大语言模型的对抗性攻击的大规模生成器框架*

*Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim* | **Category: cs.CV, cs.AI**

**Keywords:** 对抗性攻击, 视频多模态大语言模型, CAVALRY-V, 跨模态理解, 生成器框架

**Comment:** 

> **TL;DR:** CAVALRY-V是一个新的大规模生成器框架，用于对视频多模态大语言模型（V-MLLMs）进行对抗性攻击，通过创新的双目标损失和两阶段生成器显著提升了攻击效果。

**AI_Comments:** CAVALRY-V的创新之处在于其双目标损失函数和两阶段生成器设计，特别是在处理视频复杂性和时间依赖性方面，通过隐式建模提高了攻击效率和效果。其在商业和开源模型上的显著性能提升，以及对图像理解的泛化能力，凸显了其作为多模态对抗性研究基础方法的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 视频多模态大语言模型（V-MLLMs）在时间推理和跨模态理解方面表现出色，但由于复杂的跨模态推理机制、时间依赖性和计算限制，其对抗性攻击的脆弱性仍未得到充分探索。

**Method:** 本文提出了CAVALRY-V（跨模态语言-视觉对抗性视频生成）框架，直接针对V-MLLMs中视觉感知和语言生成之间的关键接口。它引入了两项创新：1) 一个双目标语义-视觉损失函数，同时扰乱模型的文本生成逻辑和视觉表示，以破坏跨模态集成；2) 一个计算高效的两阶段生成器框架，结合大规模预训练以实现跨模型可迁移性，并进行专门微调以保持时空连贯性。

**Result:** 在综合视频理解基准测试中，CAVALRY-V显著优于现有攻击方法，在商业系统（GPT-4.1, Gemini 2.0）和开源模型（QwenVL-2.5, InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6）上，相对于最佳基线攻击平均提高了22.8%。通过隐式时间连贯性建模，对图像理解也实现了34.4%的平均增益。

**Conclusion:** CAVALRY-V作为一种基础方法，在多模态系统对抗性研究中具有巨大潜力。

> **ai_Abstract:** 本文提出了CAVALRY-V，一个针对视频多模态大语言模型（V-MLLMs）的新型对抗性攻击框架。该框架通过引入双目标语义-视觉损失函数和高效的两阶段生成器，有效攻击V-MLLMs的视觉与语言接口。实验证明，CAVALRY-V在视频理解和图像理解任务上均显著超越现有攻击方法，并对多种商业和开源模型有效，显示出其作为多模态对抗性研究基础方法的潜力。

> **摘要翻译:** 视频多模态大语言模型（V-MLLMs）在时间推理和跨模态理解方面表现出令人印象深刻的能力，然而，由于独特的挑战：复杂的跨模态推理机制、时间依赖性和计算限制，它们对对抗性攻击的脆弱性仍未得到充分探索。我们提出了CAVALRY-V（跨模态语言-视觉对抗性视频生成），这是一个新颖的框架，直接针对V-MLLMs中视觉感知和语言生成之间的关键接口。我们的方法引入了两项关键创新：(1) 一个双目标语义-视觉损失函数，同时扰乱模型的文本生成逻辑和视觉表示，以破坏跨模态集成；(2) 一个计算高效的两阶段生成器框架，结合大规模预训练以实现跨模型可迁移性，并进行专门微调以保持时空连贯性。在综合视频理解基准测试上的实证评估表明，CAVALRY-V显著优于现有攻击方法，在商业系统（GPT-4.1, Gemini 2.0）和开源模型（QwenVL-2.5, InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6）上，相对于最佳基线攻击平均提高了22.8%。我们的框架通过隐式时间连贯性建模而非显式正则化实现了灵活性，即使在图像理解方面也实现了显著的性能提升（平均增益34.4%）。这种能力证明了CAVALRY-V作为多模态系统对抗性研究基础方法的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data](https://arxiv.org/abs/2507.00822)
> *基于合成数据训练的CNN实现即时粒度分布测量*

*Yasser El Jarida, Youssef Iraqi, Loubna Mekouar* | **Category: cs.CV**

**Keywords:** 粒度分布, CNN, 合成数据, 工业监测, EfficientNet-B0

**Comment:** Accepted at the Synthetic Data for Computer Vision Workshop @ CVPR
  2025. 10 pages, 5 figures. Code available at
  https://github.com/YasserElj/Synthetic-Granular-Gen

> **TL;DR:** 使用Blender生成的合成数据训练CNN，实现即时、自动化的粒度分布测量，EfficientNet-B0表现最佳且计算高效。

**AI_Comments:** 本文的创新点在于利用Blender生成高度逼真的合成数据来训练CNN模型，有效地解决了真实工业场景中数据采集和标注的难题。这种方法为自动化、实时粒度分布测量提供了一条可行的路径，对于提高采矿、制药等行业的生产效率和产品质量具有重要意义。EfficientNet-B0在计算效率上的优势使其特别适合工业部署。

<details>
  <summary>Details</summary>

**Motivation:** 传统粒度分布测量方法（如筛分分析和激光衍射）手动、耗时且受颗粒重叠限制，而精确的粒度分布测量在采矿、制药和化肥制造等行业中对产品质量和运营效率至关重要。

**Method:** 提出了一种基于CNN的方法，利用Blender的高级渲染能力生成逼真的合成颗粒图像进行训练。通过系统地改变颗粒形状、纹理、光照和空间排列来复制各种工业场景。评估了ResNet-50、InceptionV3和EfficientNet-B0三种CNN架构来预测关键的粒度分布参数（d10、d50、d90）。

**Result:** 各模型表现出可比的准确性，其中EfficientNet-B0在计算效率方面表现最佳，适合实时工业部署。

**Conclusion:** 该方法展示了逼真合成数据在鲁棒CNN训练中的有效性，为自动化工业粒度分布监测提供了巨大潜力。

> **ai_Abstract:** 本文提出了一种利用卷积神经网络（CNN）实现即时、自动化粒度分布（PSD）测量的新方法。针对传统方法耗时且受限的问题，研究人员利用Blender生成逼真的合成颗粒图像训练CNN模型，以模拟多样化的工业场景。实验评估了ResNet-50、InceptionV3和EfficientNet-B0三种CNN架构，结果显示它们在预测PSD关键参数上均表现出相似的准确性，其中EfficientNet-B0在计算效率上最优，适合工业实时部署。该研究强调了合成数据在训练鲁棒CNN以实现工业自动化PSD监测方面的有效性。

> **摘要翻译:** 准确的粒度分布（PSD）测量在采矿、制药和化肥制造等行业中至关重要，显著影响产品质量和运营效率。传统的PSD方法，如筛分分析和激光衍射，是手动、耗时的，并且受限于颗粒重叠。卷积神经网络（CNNs）的最新发展使得直接从颗粒图像进行自动化、实时的PSD估计成为可能。在这项工作中，我们提出了一种基于CNN的方法，该方法使用Blender的高级渲染能力生成的逼真合成颗粒图像进行训练。使用这种方法生成的合成数据集可以通过系统地改变颗粒形状、纹理、光照和空间排列来复制各种工业场景，这些配置与实际情况非常相似。我们评估了ResNet-50、InceptionV3和EfficientNet-B0三种基于CNN的架构，用于预测关键的PSD参数（d10、d50、d90）。结果表明，所有模型都达到了可比的准确性，其中EfficientNet-B0实现了最佳的计算效率，适用于实时工业部署。这种方法展示了逼真合成数据在鲁棒CNN训练中的有效性，为自动化工业PSD监测提供了巨大的潜力。代码已在：https://github.com/YasserElj/Synthetic-Granular-Gen 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [468] [High-Frequency Semantics and Geometric Priors for End-to-End Detection Transformers in Challenging UAV Imagery](https://arxiv.org/abs/2507.00825)
> *高频语义和几何先验在挑战性无人机图像端到端检测Transformer中的应用*

*Hongxing Peng, Lide Chen, Hui Zhu, Yan Chen* | **Category: cs.CV, I.2.10; I.4.8; I.5.1**

**Keywords:** 无人机目标检测, 检测Transformer, 高频语义, 几何先验, 小目标检测

**Comment:** 14 pages, 9 figures, to appear in KBS

> **TL;DR:** HEGS-DETR是一个为无人机图像量身定制的实时检测Transformer框架，通过引入高频增强语义网络、高效小目标金字塔策略、选择性查询回忆和几何感知位置编码，显著提升了无人机目标检测在小目标、高密度和复杂背景下的性能，同时保持实时速度并减少了参数量。

**AI_Comments:** 本文的创新之处在于其针对无人机目标检测的特定挑战，对端到端检测Transformer进行了全面的定制和优化。通过引入高频语义和几何先验，HEGS-DETR有效地解决了小目标、高密度和复杂背景下的检测难题。其重要性体现在不仅在性能上取得了显著提升（AP50和AP分别提升5.1%和3.8%），而且在保持实时速度的同时，通过减少4M参数量展现了更高的效率，这对于资源受限的无人机平台尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 无人机目标检测（UAV-OD）面临小目标尺寸、高密度分布和杂乱背景等严峻挑战。现有算法常依赖手动设计的组件（如锚框和NMS），这些组件泛化能力有限且对阈值敏感，难以适应航空成像特性。此外，新兴的端到端框架也未能有效缓解这些航空特有的挑战。

**Method:** 本文提出了HEGS-DETR，一个全面增强的实时检测Transformer框架，专为无人机定制。首先，引入高频增强语义网络（HFESNet）作为新型骨干网络，用于保留高频空间细节以提取鲁棒语义特征，从而提高对复杂背景中小目标和遮挡目标的判别能力。其次，采用高效小目标金字塔（ESOP）策略，以最小的计算开销融合高分辨率特征图，显著提升小目标检测。最后，提出的选择性查询回忆（SQR）和几何感知位置编码（GAPE）模块增强了检测器解码器的稳定性及定位精度，有效优化了边界框并为密集场景提供了明确的空间先验。

**Result:** 在VisDrone数据集上的实验表明，HEGS-DETR比基线模型在AP50上提高了5.1%，在AP上提高了3.8%，同时保持了实时速度并将参数数量减少了4M。

**Conclusion:** HEGS-DETR通过将高频语义和几何先验集成到端到端检测Transformer中，有效解决了无人机目标检测的挑战，实现了卓越的性能和效率。

> **ai_Abstract:** 本文针对无人机目标检测（UAV-OD）中存在的小目标、高密度和杂乱背景等挑战，以及现有算法和新兴端到端框架的局限性，提出了HEGS-DETR。这是一个为无人机量身定制的实时检测Transformer框架，通过引入高频增强语义网络（HFESNet）以提取鲁棒语义特征、高效小目标金字塔（ESOP）策略以提升小目标检测，以及选择性查询回忆（SQR）和几何感知位置编码（GAPE）模块以增强检测器稳定性与定位精度。实验结果表明，HEGS-DETR在VisDrone数据集上显著提升了检测性能，并在保持实时速度的同时减少了模型参数。

> **摘要翻译:** 无人机目标检测（UAV-OD）面临严峻挑战，包括无人机图像中的小目标尺寸、高密度分布和杂乱背景。当前算法通常依赖手工设计的组件，如需要精细调优且泛化能力有限的锚框，以及对阈值敏感且容易误分类密集目标的非极大值抑制（NMS）。因此，这些通用架构难以适应航空成像特性，导致性能受限。此外，新兴的端到端框架尚未有效缓解这些航空特有的挑战。为了解决这些问题，我们提出了HEGS-DETR，一个全面增强的实时检测Transformer框架，专为无人机定制。首先，我们引入了高频增强语义网络（HFESNet）作为新型骨干网络。HFESNet保留了关键的高频空间细节，以提取鲁棒的语义特征，从而提高了在复杂背景中小目标和遮挡目标的判别能力。其次，我们的高效小目标金字塔（ESOP）策略以最小的计算开销策略性地融合高分辨率特征图，显著提升了小目标检测。最后，所提出的选择性查询回忆（SQR）和几何感知位置编码（GAPE）模块增强了检测器解码器的稳定性及定位精度，有效优化了边界框并为密集场景提供了明确的空间先验。VisDrone数据集上的实验表明，HEGS-DETR比基线模型在AP50上实现了5.1%的提升，在AP上实现了3.8%的提升，同时保持了实时速度并将参数数量减少了4M。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [Do Echo Top Heights Improve Deep Learning Nowcasts?](https://arxiv.org/abs/2507.00845)
> *回波顶高是否能改善深度学习临近预报？*

*Peter Pavlík, Marc Schleiss, Anna Bou Ezzeddine, Viera Rozinajová* | **Category: cs.CV, cs.LG**

**Keywords:** 降水临近预报, 回波顶高, 深度学习, 雷达反射率, 3D U-Net

**Comment:** Pre-review version of an article accepted at Transactions on
  Large-Scale Data and Knowledge-Centered Systems

> **TL;DR:** 研究探索了将回波顶高（ETH）作为辅助输入变量用于深度学习降水临近预报。结果显示ETH在低降雨率下能提高预报技能，但在高强度下效果不一致且存在低估，表明ETH的贡献潜力需进一步评估。

**AI_Comments:** 该论文创新性地将回波顶高（ETH）引入深度学习降水临近预报模型，试图利用3D雷达信息的垂直维度。其重要性在于指出了当前深度学习模型在利用垂直信息方面的不足，并提出了一个初步的解决方案。然而，研究结果也揭示了ETH作为辅助变量的局限性，即在高强度降水预报中的表现不佳和系统性低估，这为未来的研究提供了明确的方向，即如何更有效地融合多维雷达数据，以及如何解决模型在极端事件预报中的偏差问题。这项工作为后续更深入的多变量融合研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 降水临近预报对交通、农业和灾害减缓等天气敏感行业至关重要。当前深度学习模型主要依赖2D雷达反射率，忽略了3D雷达体积中的垂直信息。本研究旨在探索回波顶高（ETH）作为辅助输入变量是否能改善深度学习临近预报。

**Method:** 研究将回波顶高（ETH）作为辅助输入变量，并将其与雷达反射率的关系进行分析。实现了一个单通道3D U-Net模型，同时处理雷达反射率和ETH作为独立的输入通道。通过三个案例研究来评估ETH对模型性能的影响。

**Result:** 模型能够利用ETH在低降雨率阈值下提高技能，但在高强度下结果不一致，并且使用ETH的模型系统性地低估降水强度。三个案例研究表明ETH在某些情况下有帮助，但也可能使模型混淆并增加误差方差。

**Conclusion:** 尽管存在局限性，本研究为批判性评估额外变量对临近预报性能的潜在贡献奠定了基础，并指出ETH在低降雨率下可能有用，但在高强度下仍需改进。

> **ai_Abstract:** 本研究探讨了将回波顶高（ETH）作为辅助输入变量，以改善深度学习降水临近预报。通过一个处理雷达反射率和ETH的3D U-Net模型，研究发现ETH在低降雨率下能提升预报技能，但在高强度下效果不一致且导致模型低估降水。尽管存在挑战，本研究为评估额外变量对临近预报的价值提供了初步探索。

> **摘要翻译:** 降水临近预报——利用近期雷达观测数据对降雨进行短期预测——对于交通、农业和灾害缓解等天气敏感行业至关重要。尽管近期深度学习模型在提高临近预报技能方面显示出前景，但大多数方法仅依赖2D雷达反射率场，从而丢弃了完整3D雷达体积中可用的宝贵垂直信息。在这项工作中，我们探索了使用回波顶高（ETH），一个指示雷达反射率高于给定阈值的最大高度的2D投影，作为深度学习临近预报的辅助输入变量。我们研究了ETH与雷达反射率之间的关系，证实了其与预测降雨强度的相关性。我们实现了一个单通道3D U-Net，它将雷达反射率和ETH作为独立的输入通道进行处理。虽然我们的模型能够利用ETH在低降雨率阈值下提高技能，但在较高强度下结果不一致，并且使用ETH的模型系统性地低估降水强度。通过三个案例研究说明了ETH在某些情况下如何提供帮助，但也可能混淆模型并增加误差方差。尽管如此，这项研究为批判性评估额外变量对临近预报性能的潜在贡献奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [473] [UAVD-Mamba: Deformable Token Fusion Vision Mamba for Multimodal UAV Detection](https://arxiv.org/abs/2507.00849)
> *UAVD-Mamba：用于多模态无人机检测的可变形令牌融合视觉Mamba*

*Wei Li, Jiaman Tang, Yang Li, Beihao Xia, Ligang Tan, Hongmao Qin* | **Category: cs.CV**

**Keywords:** 无人机检测, 多模态融合, Mamba, 可变形卷积, 目标检测

**Comment:** The paper was accepted by the 36th IEEE Intelligent Vehicles
  Symposium (IEEE IV 2025)

> **TL;DR:** UAVD-Mamba是一个基于Mamba架构的多模态无人机目标检测框架，通过引入可变形令牌、优化多模态特征融合和改进多尺度检测来应对无人机检测中的挑战，并在DroneVehicle数据集上取得了SOTA性能。

**AI_Comments:** UAVD-Mamba的创新之处在于将Mamba架构引入多模态无人机检测领域，并通过可变形令牌（DTMB）增强了模型的几何适应性，这对于处理无人机目标的不规则形状至关重要。同时，针对多模态特征融合和多尺度检测进行了专门设计，例如独立的DTMBs和改进的DNM模块，这些都体现了其解决实际挑战的努力。性能的提升表明了该方法在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 无人机目标检测在交通管理、农业、应急救援等领域广泛应用，但面临遮挡、小目标尺寸和不规则形状等挑战，因此需要一个鲁棒高效的多模态无人机目标检测方法。

**Method:** 本文提出了UAVD-Mamba框架，基于Mamba架构进行多模态无人机目标检测。核心创新包括：1. 提出可变形令牌Mamba块（DTMB），通过结合来自可变形卷积的自适应补丁和来自常规卷积的常规补丁来生成可变形令牌，作为Mamba块的输入，以提高几何适应性。2. 为RGB和红外（IR）模态设计两个独立的DTMB，其输出整合到Mamba块中进行特征提取，并整合到融合Mamba块中进行特征融合，以优化多模态特征互补性。3. 堆叠四个不同尺度的DTMB以生成多尺度特征表示，然后送入检测颈部Mamba（DNM）模块，该模块受YOLO系列启发，并修改了YOLOv11的SPPF和C3K2以更好地处理多尺度特征。4. 在DTMB之前采用交叉增强空间注意力，在融合Mamba块之后采用交叉通道注意力，以提取更具区分性的特征。

**Result:** 在DroneVehicle数据集上的实验结果表明，该方法在mAP指标上比基线OAFA方法提高了3.6%。

**Conclusion:** UAVD-Mamba通过引入可变形令牌融合Mamba架构，有效解决了无人机目标检测中的挑战，并在多模态无人机检测方面取得了显著的性能提升。

> **ai_Abstract:** 本文提出了UAVD-Mamba，一个基于Mamba架构的多模态无人机目标检测框架，旨在解决无人机检测中存在的遮挡、小目标和不规则形状等挑战。该框架引入了可变形令牌Mamba块（DTMB）以增强几何适应性，并设计了独立的DTMBs用于RGB和红外模态的特征提取与融合。此外，通过堆叠多尺度DTMBs并结合受YOLO启发的检测颈部Mamba（DNM）模块，提升了多尺度目标检测能力，特别是针对小目标。实验结果显示，UAVD-Mamba在DroneVehicle数据集上相较于基线方法OAFA在mAP指标上提升了3.6%。

> **摘要翻译:** 无人机（UAV）目标检测已广泛应用于交通管理、农业、应急救援等领域。然而，它面临着重大挑战，包括遮挡、小目标尺寸和不规则形状。这些挑战凸显了对鲁棒高效的多模态无人机目标检测方法的必要性。Mamba在多模态图像融合中展现出巨大的潜力。基于此，我们提出了UAVD-Mamba，一个基于Mamba架构的多模态无人机目标检测框架。为了提高几何适应性，我们提出了可变形令牌Mamba块（DTMB），通过将来自可变形卷积的自适应补丁与来自常规卷积的常规卷积补丁结合起来生成可变形令牌，这些令牌作为Mamba块的输入。为了优化多模态特征互补性，我们为RGB和红外（IR）模态设计了两个独立的DTMB，两个DTMB的输出都整合到Mamba块中进行特征提取，并整合到融合Mamba块中进行特征融合。此外，为了改进多尺度目标检测，特别是小目标检测，我们堆叠了四个不同尺度的DTMB以生成多尺度特征表示，然后将它们发送到Mamba的检测颈部（DNM）。DNM模块受YOLO系列启发，对YOLOv11的SPPF和C3K2进行了修改，以更好地处理多尺度特征。特别是，我们在DTMB之前采用交叉增强空间注意力，并在融合Mamba块之后采用交叉通道注意力，以提取更具区分性的特征。在DroneVehicle数据集上的实验结果表明，我们的方法在mAP指标上比基线OAFA方法提高了3.6%。代码将在https://github.com/GreatPlum-hnu/UAVD-Mamba.git发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [475] [Robust Component Detection for Flexible Manufacturing: A Deep Learning Approach to Tray-Free Object Recognition under Variable Lighting](https://arxiv.org/abs/2507.00852)
> *柔性制造中的鲁棒部件检测：可变光照下无托盘物体识别的深度学习方法*

*Fatemeh Sadat Daneshmand* | **Category: cs.CV**

**Keywords:** 柔性制造, 深度学习, 物体识别, Mask R-CNN, 鲁棒性

**Comment:** 

> **TL;DR:** 开发了一种基于Mask R-CNN的计算机视觉系统，使工业机器人能够在可变光照下无托盘地检测和抓取物体，提高了柔性制造的效率和鲁棒性。

**AI_Comments:** 该论文的创新点在于将深度学习（Mask R-CNN）应用于工业柔性制造中的无托盘、可变光照下的物体识别，解决了传统方法对结构化环境的依赖。其重要性体现在显著提高了制造效率和灵活性，降低了设置成本，并展示了在实际工业部署中的强大鲁棒性。该研究对于推动工业4.0中智能制造的发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 工业4.0中的柔性制造系统要求机器人能够在非结构化环境中处理物体，而无需严格的定位限制。现有方法在可变光照或无托盘环境下表现不佳，限制了柔性制造的效率和适应性。

**Method:** 本文提出了一种基于Mask R-CNN的计算机视觉系统，用于工业机器人进行无托盘物体识别。该方法通过解决无位置约束下的物体检测、极端光照变化下的鲁棒性以及使用成本效益型摄像机的可靠性能这三个关键挑战来实现。

**Result:** 该系统在不同光照条件下实现了95%的检测精度，消除了对结构化部件放置的需求，从而使设置时间减少了30%，并显著提高了制造灵活性。该方法在四种不同光照场景下通过广泛测试得到验证。

**Conclusion:** 所提出的基于深度学习的系统在可变光照条件下实现了对无托盘物体的鲁棒检测，证明了其在实际工业部署中的实用性，并显著提升了柔性制造的效率和适应性。

> **ai_Abstract:** 本文介绍了一种基于深度学习（Mask R-CNN）的计算机视觉系统，旨在解决柔性制造中工业机器人在非结构化环境下对物体进行无托盘、可变光照下鲁棒识别的挑战。该系统在笔生产线上进行了验证，实现了95%的检测精度，显著减少了设置时间并提高了制造灵活性，证明了其在实际工业应用中的潜力。

> **摘要翻译:** 工业4.0中的柔性制造系统要求机器人能够在非结构化环境中处理物体，而无需严格的定位限制。本文提出了一种计算机视觉系统，使工业机器人能够以任意方向检测和抓取笔部件，无需结构化托盘，同时在可变光照条件下保持鲁棒性能。我们在ZHAW的完整笔生产线上实施并评估了一种基于Mask R-CNN的方法，解决了三个关键挑战：无位置约束的物体检测、对极端光照变化的鲁棒性以及使用经济型摄像机的可靠性能。我们的系统在不同光照条件下实现了95%的检测精度，同时消除了对结构化部件放置的需求，展示了设置时间减少30%和制造灵活性显著提高。该方法通过在四种不同光照场景下进行广泛测试得到验证，显示出在实际工业部署中的实用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [477] [SafeMap: Robust HD Map Construction from Incomplete Observations](https://arxiv.org/abs/2507.00861)
> *SafeMap：基于不完整观测的鲁棒高清地图构建*

*Xiaoshuai Hao, Lingdong Kong, Rong Yin, Pengwei Wang, Jing Zhang, Yunfeng Diao, Shu Zhao* | **Category: cs.CV**

**Keywords:** 高清地图, 鲁棒性, 不完整观测, 多视图相机, 自动驾驶

**Comment:** Accepted by ICML 2025

> **TL;DR:** SafeMap是一种新型框架，旨在解决自动驾驶中从不完整多视图相机数据构建鲁棒高清地图的挑战。它通过G-PVR和D-BEVC两个模块，即使在某些相机视图缺失的情况下也能确保准确性，并在实验中显著优于现有方法。

**AI_Comments:** SafeMap的创新之处在于其对不完整多视图数据的处理能力，通过G-PVR和D-BEVC模块协同工作，提高了高清地图构建的鲁棒性。其“即插即用”的特性也使其易于集成到现有系统中，具有较高的实用价值和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中鲁棒的高清地图构建至关重要，但现有方法在处理不完整的多视图相机数据时常遇到困难，难以保证准确性。

**Method:** 本文提出了SafeMap框架，它集成了两个核心组件：1. 高斯基透视视图重建（G-PVR）模块：利用视图重要性先验知识，根据可用相机视图之间的关系动态优先处理信息最丰富的区域。2. 基于蒸馏的鸟瞰图（BEV）校正（D-BEVC）模块：利用全景BEV特征校正从不完整观测中获得的BEV表示。这两个模块协同工作，实现了端到端地图重建和鲁棒的高清地图生成。

**Result:** 实验结果表明，SafeMap在完整和不完整场景中均显著优于现有方法。

**Conclusion:** SafeMap表现出卓越的性能和可靠性，为增强鲁棒性提供了一种即插即用的解决方案，能够有效地从不完整观测中构建高清地图。

> **ai_Abstract:** SafeMap是一个新颖的框架，旨在解决自动驾驶中从不完整多视图相机数据构建鲁棒高清地图的挑战。它通过整合高斯基透视视图重建（G-PVR）和基于蒸馏的鸟瞰图（BEV）校正（D-BEVC）模块，确保即使在相机视图缺失的情况下也能保持准确性。G-PVR优先处理信息丰富的区域，而D-BEVC则校正不完整观测产生的BEV表示。该框架易于实现，并被证明在完整和不完整场景下均显著优于现有方法，展现出卓越的性能和可靠性。

> **摘要翻译:** 鲁棒的高清（HD）地图构建对于自动驾驶至关重要，但现有方法在处理不完整的多视图相机数据时常常遇到困难。本文提出SafeMap，一个专门设计用于即使在某些相机视图缺失的情况下也能确保准确性的新型框架。SafeMap集成了两个关键组件：基于高斯的透视视图重建（G-PVR）模块和基于蒸馏的鸟瞰图（BEV）校正（D-BEVC）模块。G-PVR利用视图重要性先验知识，根据可用相机视图之间的关系动态优先处理信息最丰富的区域。此外，D-BEVC利用全景BEV特征来校正从不完整观测中获得的BEV表示。这些组件共同促进了端到端的地图重建和鲁棒的高清地图生成。SafeMap易于实现，并能无缝集成到现有系统中，为增强鲁棒性提供即插即用的解决方案。实验结果表明，SafeMap在完整和不完整场景中均显著优于现有方法，突显了其卓越的性能和可靠性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [479] [Is Visual in-Context Learning for Compositional Medical Tasks within Reach?](https://arxiv.org/abs/2507.00868)
> *视觉上下文学习在组合医学任务中是否触手可及？*

*Simon Reiß, Zdravko Marinov, Alexander Jaus, Constantin Seibold, M. Saquib Sarfraz, Erik Rodner, Rainer Stiefelhagen* | **Category: cs.CV**

**Keywords:** 视觉上下文学习, 组合任务, 医学图像, 任务序列, 码本

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文探讨了视觉上下文学习在处理多任务和测试时适应新任务的潜力，特别是针对医学领域中的复杂组合任务序列，并提出了一种新的训练方法。

**AI_Comments:** 该论文的创新点在于将视觉上下文学习应用于复杂的“组合任务序列”，特别是针对医学领域，这与以往专注于单个任务的方法不同。通过引入合成任务生成引擎来训练模型，解决了数据获取的难题。尽管研究还处于探索阶段并指出了挑战，但其对多任务处理和测试时适应性的关注，以及在医学图像分析中的潜在应用，都使其具有重要的研究价值和前景。

<details>
  <summary>Details</summary>

**Motivation:** 使单一模型能够在不重新训练的情况下处理多任务并在测试时适应新任务，特别是在解决涉及多个中间步骤的复杂组合任务时，允许用户在测试时灵活定义整个视觉管道。

**Method:** 通过训练上下文学习器来适应任务序列，而不是单独的任务。具体方法包括：1) 检查视觉上下文学习架构的特性和局限性，特别是码本的作用。2) 引入一种使用合成组合任务生成引擎来训练上下文学习器的新方法，该引擎从任意分割数据集引导任务序列。3) 研究不同的基于掩码的训练目标，以深入了解如何更好地训练模型来解决复杂的组合任务。

**Result:** 探索不仅为多模态医学任务序列提供了重要的见解，而且也突出了需要解决的挑战。

**Conclusion:** 研究表明视觉上下文学习在处理复杂组合医学任务方面具有潜力，但仍存在挑战需要进一步解决。该工作提供了重要见解，并为未来的研究方向提供了线索。

> **ai_Abstract:** 本文探讨了视觉上下文学习在使单一模型处理和适应医学领域中复杂组合任务的潜力。研究人员提出了一种新的方法，通过合成任务生成引擎训练上下文学习器，使其能够处理任务序列而非单个任务。文章还分析了视觉上下文学习架构的特性、码本的作用，并探讨了不同的训练目标。研究结果提供了关于多模态医学任务序列的重要见解，同时也指出了现有挑战。

> **摘要翻译:** 在本文中，我们探讨了视觉上下文学习的潜力，以使单个模型能够处理多个任务并在测试时无需重新训练即可适应新任务。与以前的方法不同，我们的重点是训练上下文学习器以适应任务序列，而不是单个任务。我们的目标是使用单个模型解决涉及多个中间步骤的复杂任务，允许用户在测试时灵活定义整个视觉管道。为了实现这一目标，我们首先检查了视觉上下文学习架构的属性和局限性，特别关注码本的作用。然后，我们介绍了一种使用合成组合任务生成引擎训练上下文学习器的新方法。该引擎从任意分割数据集引导任务序列，从而能够训练用于组合任务的视觉上下文学习器。此外，我们研究了不同的基于掩码的训练目标，以深入了解如何更好地训练模型来解决复杂的组合任务。我们的探索不仅为多模态医学任务序列提供了重要的见解，而且还突出了需要解决的挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [Masks make discriminative models great again!](https://arxiv.org/abs/2507.00916)
> *掩码让判别模型再次强大！*

*Tianshi Cao, Marie-Julie Rakotosaona, Ben Poole, Federico Tombari, Michael Niemeyer* | **Category: cs.CV**

**Keywords:** 单图像3D重建, 判别模型, 可见性掩码, 3D高斯散斑, 图像到3D提升

**Comment:** 

> **TL;DR:** Image2GS提出一种新颖方法，通过使用可见性掩码，将单张图像到3D场景重建中的“提升”问题与“补全”问题解耦，显著提高了可见区域的重建质量，并揭示了判别模型在处理未见区域时的局限性。

**AI_Comments:** 该论文的创新点在于将图像到3D重建中的“提升”与“补全”问题进行解耦，并引入了基于可见性掩码的训练策略。这不仅提高了模型在可见区域的重建质量，也深刻揭示了判别模型在处理未见区域时的内在局限性。其重要性在于为单张图像3D重建提供了一个更聚焦和有效的新范式，并为未来研究如何更有效地处理3D重建中的未知或不可见区域提供了新的思路和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 解决从单张图像重建逼真3D场景的挑战性问题，特别是图像到3D提升部分，以及判别模型在拟合未见区域时面临的根本困难。

**Method:** Image2GS是一种新颖的方法，它将图像到3D的“提升”问题（将图像转换为可见部分的3D模型）与“补全”问题（幻觉化输入中不存在的内容）解耦。该方法采用从优化的3D高斯散斑中导出的可见性掩码，在训练期间排除源视图中不可见的区域。这是一种蒙版训练策略。

**Result:** 与强大的基线相比，在可见区域的重建质量显著提高。尽管仅在蒙版区域进行训练，但在评估完整场景时，Image2GS与在完整目标图像上训练的现有判别模型保持竞争力。

**Conclusion:** 将图像到3D提升作为一个独特的、需要专门技术（如掩码训练）的问题来解决，具有显著优势，并揭示了判别模型在拟合未见区域时面临的根本困难。

> **ai_Abstract:** Image2GS是一种新颖的单张图像3D场景重建方法，它将图像到3D的“提升”与“补全”问题解耦，使提升任务更适合判别模型。该方法利用3D高斯散斑生成的可见性掩码，在训练时排除不可见区域。这种蒙版训练策略显著提升了可见区域的重建质量，并且即使仅在蒙版区域训练，其性能仍与在完整图像上训练的先进判别模型相当，突出了针对图像到3D提升问题采用专门技术的优势。

> **摘要翻译:** 我们提出了Image2GS，这是一种新颖的方法，通过专注于重建过程中图像到3D提升组件，解决了从单张图像重建逼真3D场景的挑战性问题。通过将提升问题（将图像转换为表示可见内容的3D模型）与补全问题（幻觉化输入中不存在的内容）解耦，我们创建了一个更适合判别模型的确定性任务。我们的方法采用从优化的3D高斯散斑中导出的可见性掩码，在训练期间排除源视图不可见的区域。这种掩码训练策略与强大的基线相比，显著提高了可见区域的重建质量。值得注意的是，尽管Image2GS仅在蒙版区域进行训练，但在评估完整场景时，它与在完整目标图像上训练的现有判别模型保持竞争力。我们的发现突出了判别模型在拟合未见区域时面临的根本困难，并证明了将图像到3D提升作为独立问题并采用专门技术的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [484] [MVP: Winning Solution to SMP Challenge 2025 Video Track](https://arxiv.org/abs/2507.00950)
> *MVP：SMP挑战赛2025视频赛道获胜方案*

*Liliang Ye, Yunyao Zhang, Yafeng Wu, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang, Zikai Song* | **Category: cs.CV, cs.LG, cs.MM**

**Keywords:** 视频流行度预测, 多模态, 梯度提升回归, SMP挑战赛, 社交媒体

**Comment:** 

> **TL;DR:** MVP是SMP挑战赛2025视频赛道的获胜方案，通过整合视频特征、用户元数据和上下文信息，使用梯度提升回归模型预测社交媒体视频的流行度。

**AI_Comments:** MVP的创新之处在于其整合多模态信息（视频特征、用户元数据、上下文信息）以及系统性的预处理方法（对数变换、异常值去除），并结合梯度提升回归模型来解决视频流行度预测问题。其在SMP挑战赛中获得第一名，证明了该方案的实用性和高性能。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测社交媒体视频的流行度对于内容推荐、趋势检测和观众参与具有重要应用价值。

**Method:** MVP通过整合预训练模型提取的深度视频特征、用户元数据和上下文信息构建富有表现力的帖子表示。该框架应用了系统的预处理技术，包括对数变换和异常值去除，以提高模型鲁棒性。训练了一个梯度提升回归模型来捕获跨模态的复杂模式。

**Result:** 该方法在视频赛道的官方评估中排名第一。

**Conclusion:** MVP在社交平台上的多模态视频流行度预测方面表现出有效性和可靠性。

> **ai_Abstract:** 本文介绍了MVP（多模态视频预测器），它是SMP挑战赛2025视频赛道的冠军解决方案。MVP通过结合预训练模型的深度视频特征、用户元数据和上下文信息来创建丰富的帖子表示。该方法采用对数变换和异常值去除等预处理技术增强模型鲁棒性，并利用梯度提升回归模型捕捉多模态复杂模式。MVP在官方评估中表现出色，证明了其在社交媒体视频流行度预测中的有效性和可靠性。

> **摘要翻译:** 社交媒体平台是内容传播、观点表达和跨模态公众参与的中心枢纽。准确预测社交媒体视频的流行度，可在内容推荐、趋势检测和受众参与方面实现有价值的应用。在本文中，我们提出了多模态视频预测器（MVP），这是我们赢得SMP挑战赛2025视频赛道的解决方案。MVP通过整合从预训练模型中提取的深度视频特征、用户元数据和上下文信息，构建了富有表现力的帖子表示。该框架应用了系统的预处理技术，包括对数变换和异常值去除，以提高模型鲁棒性。训练了一个梯度提升回归模型来捕获跨模态的复杂模式。我们的方法在视频赛道的官方评估中排名第一，证明了其在社交平台上多模态视频流行度预测方面的有效性和可靠性。源代码可在https://anonymous.4open.science/r/SMPDVideo 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [486] [Surgical Neural Radiance Fields from One Image](https://arxiv.org/abs/2507.00969)
> *单图像手术神经辐射场*

*Alberto Neri, Maximilan Fehrentz, Veronica Penza, Leonardo S. Mattos, Nazim Haouchine* | **Category: cs.CV, cs.AI**

**Keywords:** 神经辐射场, 单图像, 手术导航, 3D重建, 神经风格迁移

**Comment:** 

> **TL;DR:** 该工作提出一种利用单张术中图像和术前数据，通过神经风格迁移训练NeRF的方法，以解决手术环境中多视角数据采集困难的问题，实现高效的3D重建和视图合成。

**AI_Comments:** 这篇论文的创新之处在于解决了NeRF在实际手术环境中应用的核心挑战——数据稀缺性。通过巧妙地结合术前数据和术中单张图像，并利用神经风格迁移技术，它为在时间敏感的手术场景中实现实时3D重建和视图合成提供了可行的方案。这对于提高手术导航和增强现实应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经辐射场（NeRF）在3D重建和视图合成方面表现出色，但其依赖大量多视角数据，这在手术室内由于时间限制而不切实际。该工作旨在解决在手术环境中仅有有限数据（特别是单张术中图像）时训练NeRF的挑战。

**Method:** 该方法利用术前MRI数据定义相机视角和图像集进行训练。术中，通过神经风格迁移（特别是结合WTC2和STROTSS以防止过度风格化）将手术图像的外观转移到预构建的训练集上，从而创建数据集用于即时快速的单图像NeRF训练。

**Result:** 该方法在四个临床神经外科病例中进行了评估。与使用真实手术显微镜图像训练的NeRF模型进行定量比较表明，合成一致性强，相似性指标表明高重建保真度和风格对齐。与真实情况相比，该方法显示出高结构相似性，证实了良好的重建质量和纹理保留。

**Conclusion:** 该方法证明了在手术环境中进行单图像NeRF训练的可行性，克服了传统多视角方法的局限性。

> **ai_Abstract:** 这项工作提出了一种创新的方法，旨在解决神经辐射场（NeRF）在手术环境中由于缺乏多视角数据而面临的应用限制。通过利用术前MRI数据和单张术中图像，结合神经风格迁移技术（WTC2和STROTSS），该方法成功地构建了一个用于高效单图像NeRF训练的数据集。实验结果在多个临床神经外科病例中验证了该方法的有效性，显示出高重建保真度、风格对齐和结构相似性，证明了在手术设置中实现单图像NeRF训练的可行性。

> **摘要翻译:** 目的：神经辐射场 (NeRF) 在 3D 重建和视图合成方面具有卓越的能力，但其对大量多视角数据的依赖限制了它们在术中环境中的应用，因为在术中只能获得有限的数据。特别是，由于时间限制，在术中收集如此大量的数据是不切实际的。这项工作通过利用单张术中图像和术前数据来高效训练 NeRF 以适应手术场景，从而解决了这一挑战。
方法：我们利用术前 MRI 数据来定义稳健和无障碍训练所需的相机视点和图像集。在术中，手术图像的外观通过神经风格迁移（特别是结合 WTC2 和 STROTSS 以防止过度风格化）转移到预构建的训练集上。这个过程使得能够创建一个用于即时快速单图像 NeRF 训练的数据集。
结果：该方法在四个临床神经外科病例中进行了评估。与使用真实手术显微镜图像训练的 NeRF 模型进行定量比较表明，合成一致性强，相似性指标表明高重建保真度和风格对齐。与真实情况相比，我们的方法显示出高结构相似性，证实了良好的重建质量和纹理保留。
结论：我们的方法证明了在手术环境中进行单图像 NeRF 训练的可行性，克服了传统多视角方法的局限性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [487] [RTMap: Real-Time Recursive Mapping with Change Detection and Localization](https://arxiv.org/abs/2507.00980)
> *RTMap：实时递归建图，支持变化检测与定位*

*Yuheng Du, Sheng Yang, Lingxuan Wang, Zhenghua Hou, Chengying Cai, Zhitao Tan, Mingxia Chen, Shi-Sheng Huang, Qiang Li* | **Category: cs.CV**

**Keywords:** 实时建图, 高清地图, 变化检测, 定位, 众包

**Comment:** 

> **TL;DR:** RTMap提出了一种实时众包多遍历高清地图的方法，以解决现有在线高清地图方法在感知不准确性、遮挡和多智能体观测融合方面的局限性，并在地图质量和定位精度方面表现出色。

**AI_Comments:** RTMap的创新之处在于其将多遍历众包与实时递归建图相结合，形成一个自演化的记忆系统，这有效解决了现有在线高清地图在动态环境下的局限性。其端到端处理不确定性、定位和变化检测的能力，对于提升自动驾驶的鲁棒性和地图新鲜度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的在线高清地图方法受限于感知不准确性、密集交通中的遮挡以及无法融合多智能体观测。为了解决这些问题并增强单次遍历方法，本文提出RTMap。

**Method:** RTMap通过持续众包多遍历高清地图作为自演化记忆，增强了单次遍历方法。它在车载智能体上同时解决了三个核心挑战：1) 高清地图元素的感知不确定性位置建模；2) 基于众包先验地图的概率感知定位；3) 实时检测可能的道路结构变化。

**Result:** 在多个公共自动驾驶数据集上的实验表明，RTMap在先验辅助地图质量和定位精度方面均表现出色，能够有效地支持下游预测和规划模块，并异步逐步提高众包先验地图的准确性和新鲜度。

**Conclusion:** RTMap通过实时递归建图、变化检测和定位，有效地提升了在线高清地图的质量和定位精度，解决了现有方法的局限性，并能为自动驾驶系统提供鲁棒的服务。

> **ai_Abstract:** 本文提出了RTMap，一种实时递归建图系统，旨在解决现有在线高清地图方法在感知不准确性、遮挡和多智能体融合方面的局限性。RTMap通过众包多遍历高清地图作为自演化记忆，并在车载智能体上实现了不确定性感知的位置建模、概率感知定位以及实时道路变化检测。实验证明，RTMap在地图质量和定位精度方面均表现出色，能够有效支持自动驾驶的下游模块。

> **摘要翻译:** 虽然最近的在线高清地图方法减轻了繁重的离线流程并解决了地图新鲜度问题，但它们仍然受限于感知不准确性、密集交通中的遮挡以及无法融合多智能体观测。我们提出RTMap来增强这些单次遍历方法，通过持续众包多遍历高清地图作为自演化记忆。在车载智能体上，RTMap以端到端的方式同时解决了三个核心挑战：1) 高清地图元素的不确定性感知位置建模；2) 基于众包先验地图的概率感知定位；3) 实时检测可能的道路结构变化。在几个公共自动驾驶数据集上的实验表明，我们在先验辅助地图质量和定位精度方面均表现出色，证明了我们能够稳健地服务下游预测和规划模块，同时异步逐步提高众包先验地图的准确性和新鲜度。我们的源代码将在https://github.com/CN-ADLab/RTMap 公开发布（包含审稿人建议的最终版本将很快更新）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [489] [Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations](https://arxiv.org/abs/2507.00981)
> *使用程序化场景扰动评估单目深度估计的鲁棒性*

*Jack Nugent, Siyang Wu, Zeyu Ma, Beining Han, Meenal Parakh, Abhishek Joshi, Lingjie Mei, Alexander Raistrick, Xinyuan Li, Jia Deng* | **Category: cs.CV**

**Keywords:** 单目深度估计, 鲁棒性评估, 程序化生成, 基准测试, 场景扰动

**Comment:** 

> **TL;DR:** 引入了一个名为PDE的新基准，用于系统评估单目深度估计模型的鲁棒性，通过程序化生成3D场景并施加各种受控扰动。

**AI_Comments:** 该论文的创新点在于提出了一个全新的、专注于鲁棒性评估的基准PDE，填补了现有评估体系的空白。通过程序化生成场景和受控扰动，它提供了一种系统且可控的方式来测试模型在非理想条件下的性能，对于推动单目深度估计领域在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有标准基准主要评估单目深度估计模型的准确性而非鲁棒性，无法提供全面评估。

**Method:** 提出了PDE（Procedural Depth Evaluation），一个通过程序化生成3D场景来测试对物体、相机、材料和光照变化等各种受控扰动鲁棒性的新基准。

**Result:** 分析揭示了哪些扰动对最先进的深度模型构成了挑战。

**Conclusion:** 希望研究结果能为未来的研究提供信息。

> **ai_Abstract:** 该论文提出了PDE（Procedural Depth Evaluation），一个用于系统评估单目深度估计模型鲁棒性的新基准。针对现有基准仅关注准确性而忽略鲁棒性的不足，PDE利用程序化生成技术创建包含物体、相机、材料和光照等多种受控扰动的3D场景，以全面测试模型的鲁棒性。研究分析揭示了对当前最先进深度模型具有挑战性的扰动类型，旨在为未来的研究提供指导。

> **摘要翻译:** 近年来，单目深度估计取得了显著进展，尤其是在大型模型在标准基准测试中取得的成功方面。然而，标准基准测试的性能评估并不完整，因为大多数只评估准确性而非鲁棒性。在这项工作中，我们引入了PDE（Procedural Depth Evaluation），一个能够系统地评估鲁棒性的新基准。PDE使用程序化生成来创建3D场景，以测试模型对各种受控扰动（包括物体、相机、材料和光照变化）的鲁棒性。我们的分析揭示了哪些扰动对最先进的深度模型构成了挑战，我们希望这能为进一步的研究提供信息。代码和数据可在https://github.com/princeton-vl/proc-depth-eval获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [491] [UniGlyph: Unified Segmentation-Conditioned Diffusion for Precise Visual Text Synthesis](https://arxiv.org/abs/2507.00992)
> *UniGlyph：统一分割条件扩散用于精确视觉文本合成*

*Yuanrui Wang, Cong Han, YafeiLi, Zhipeng Jin, Xiawei Li, SiNan Du, Wen Tao, Yi Yang, shuanglong li, Chun Yuan, Liu Lin* | **Category: cs.CV**

**Keywords:** 视觉文本合成, 扩散模型, 分割引导, 字符掩码, 文本生成

**Comment:** Accepted by ICCV 2025

> **TL;DR:** UniGlyph提出了一种基于分割引导的扩散模型，通过像素级文本掩码实现精确的视觉文本合成，解决了现有方法在字体保留和风格控制上的问题，并在多项基准测试中取得了SOTA性能。

**AI_Comments:** UniGlyph的创新之处在于其统一的分割引导框架，通过利用像素级文本掩码作为条件输入，简化了模型设计并提高了灵活性，克服了传统多分支方法的局限性。引入新的评估基准也体现了对领域进步的贡献。该方法在处理小文本和复杂布局方面的卓越性能，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像生成在视觉文本渲染方面存在模糊字符、语义漂移和风格控制有限等挑战。依赖预渲染字符图像作为条件的方法难以保留原始字体风格和颜色信息，且需要复杂的多分支设计，增加了模型开销并降低了灵活性。

**Method:** 提出一个分割引导框架，使用像素级视觉文本掩码作为统一条件输入。该方法包含两个核心组件：1) 一个用于精确文本掩码提取的微调双语分割模型；2) 一个增强了自适应字符条件和区域特定损失的精简扩散模型，以保持文本内容和风格的保真度。此外，还引入了两个新基准：GlyphMM-benchmark和MiniText-benchmark用于更严格的评估。

**Result:** 在AnyText基准测试中，中文和英文设置下均显著超越现有方法，达到SOTA性能。在GlyphMM-benchmark和MiniText-benchmark上，模型表现优于现有方法，尤其擅长小文本渲染和复杂布局保留。

**Conclusion:** UniGlyph通过其分割引导框架和核心组件，有效地解决了视觉文本合成中的挑战，实现了内容和风格的高度保真，并展现出强大的泛化能力和部署就绪性。

> **ai_Abstract:** UniGlyph提出了一种创新的分割引导扩散框架，用于精确的视觉文本合成。该框架利用像素级视觉文本掩码作为统一条件输入，并通过一个微调的双语分割模型和增强的扩散模型，有效解决了现有方法在字体风格保留、颜色线索和复杂布局方面的挑战。UniGlyph在多个中英文基准测试中取得了最先进的性能，尤其在小文本渲染和复杂布局保持方面表现出色，验证了其在视觉文本生成领域的强大能力。

> **摘要翻译:** 文本到图像生成极大地推动了内容创作，然而，由于字符模糊、语义漂移和风格控制有限，准确渲染视觉文本仍然是一个关键挑战。现有方法通常依赖预渲染的字符图像作为条件，但这些方法难以保留原始字体风格和颜色线索，并且需要复杂的多分支设计，这增加了模型开销并降低了灵活性。为了解决这些问题，我们提出了一种分割引导框架，该框架使用像素级视觉文本掩码（富含字符形状、颜色和空间细节）作为统一的条件输入。我们的方法引入了两个核心组件：(1) 一个用于精确文本掩码提取的微调双语分割模型，以及 (2) 一个通过自适应字符条件和区域特定损失增强的精简扩散模型，以在内容和风格上保持文本保真度。我们的方法在AnyText基准测试中取得了最先进的性能，在中英文设置下均显著超越了现有方法。为了实现更严格的评估，我们还引入了两个新基准：用于测试复杂排版中布局和字符一致性的GlyphMM-benchmark，以及用于评估小规模文本区域生成质量的MiniText-benchmark。实验结果表明，我们的模型在这两种场景下都大大优于现有方法，尤其擅长小文本渲染和复杂布局保留，验证了其强大的泛化能力和部署就绪性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [493] [GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning](https://arxiv.org/abs/2507.01006)
> *GLM-4.1V-Thinking：迈向通用多模态推理与可扩展强化学习*

*Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, Leyi Pan, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Tianle Gong, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 视觉语言模型, 多模态推理, 强化学习, GLM-4.1V-Thinking, 开源模型

**Comment:** 

> **TL;DR:** GLM-4.1V-Thinking是一个通过大规模预训练和强化学习实现通用多模态推理的视觉语言模型，在多项任务上表现出色并开源。

**AI_Comments:** 该论文的创新之处在于结合大规模预训练和课程采样强化学习（RLCS）来优化视觉语言模型，以实现更通用的多模态推理能力。其重要性体现在开源了高性能模型，并展示了在多种复杂任务上超越现有模型的潜力，甚至能与大型闭源模型竞争，这对于推动多模态AI研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一个以推理为中心的训练框架，以推进通用多模态推理能力。

**Method:** 首先通过大规模预训练构建一个视觉基础模型，然后采用课程采样强化学习（RLCS）来充分释放模型的潜力，从而在多样化任务中全面提升能力。

**Result:** GLM-4.1V-9B-Thinking在同等规模模型中实现了最先进的性能，在28个公共基准测试中几乎所有任务上都优于Qwen2.5-VL-7B，在18个基准测试中与更大的Qwen2.5-VL-72B表现相当或更优，并且在长文档理解和STEM推理等挑战性任务上与GPT-4o等闭源模型相比也具有竞争力或更优。

**Conclusion:** GLM-4.1V-Thinking通过其创新的训练框架（预训练与RLCS结合）展示了强大的通用多模态推理能力，并在多个基准测试中取得了领先或竞争性的表现，证明了其在视觉语言模型领域的先进性。

> **ai_Abstract:** 本文介绍了GLM-4.1V-Thinking，一个通过大规模预训练和课程采样强化学习（RLCS）开发的视觉语言模型，旨在提升通用多模态推理能力。该模型在STEM问题解决、视频理解、长文档理解等多种任务上表现出强大的综合能力。其中，GLM-4.1V-9B-Thinking版本在多个公共基准测试中超越了同等规模模型，并与大型或闭源模型（如Qwen2.5-VL-72B和GPT-4o）表现出竞争力，证明了其先进的性能和通用性，并已开源以促进研究。

> **摘要翻译:** 我们提出了GLM-4.1V-Thinking，一个旨在推进通用多模态推理的视觉语言模型（VLM）。在本报告中，我们分享了在开发以推理为中心的训练框架中的关键发现。我们首先通过大规模预训练开发了一个具有巨大潜力的视觉基础模型，这可以说为最终性能设定了上限。然后，带有课程采样的强化学习（RLCS）充分释放了模型的全部潜力，从而在包括STEM问题解决、视频理解、内容识别、编码、接地、基于GUI的代理和长文档理解等多种任务上实现了全面的能力增强。为了促进该领域的研究，我们开源了GLM-4.1V-9B-Thinking，该模型在同等规模的模型中实现了最先进的性能。在对28个公共基准进行的全面评估中，我们的模型在几乎所有任务上都优于Qwen2.5-VL-7B，并且在18个基准测试中与明显更大的Qwen2.5-VL-72B表现相当甚至更优。值得注意的是，GLM-4.1V-9B-Thinking在包括长文档理解和STEM推理等挑战性任务上，与GPT-4o等闭源模型相比也表现出竞争性或更优的性能，进一步强调了其强大的能力。代码、模型和更多信息已在https://github.com/THUDM/GLM-4.1V-Thinking 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [495] [ShapeEmbed: a self-supervised learning framework for 2D contour quantification](https://arxiv.org/abs/2507.01009)
> *ShapeEmbed：一个用于二维轮廓量化的自监督学习框架*

*Anna Foix Romero, Craig Russell, Alexander Krull, Virginie Uhlmann* | **Category: cs.CV, q-bio.QM**

**Keywords:** ShapeEmbed, 自监督学习, 2D轮廓量化, 形状描述符, 几何不变性

**Comment:** 

> **TL;DR:** ShapeEmbed是一个自监督学习框架，用于生成对几何变换不变的二维物体轮廓描述符，并在形状分类任务中优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了一个自监督学习框架ShapeEmbed，有效地解决了二维轮廓量化中关键的几何变换不变性问题。它通过将欧氏距离矩阵编码为不变形描述符，克服了传统方法的局限性，并超越了现有先进的自编码器方法。其在生物成像领域的潜在应用表明了该方法的实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 物体形状是视觉信息的重要来源，而形状量化的核心挑战在于确保提取的测量值对保持物体内在几何的变换（如大小、方向、位置）保持不变。

**Method:** 本文引入了ShapeEmbed，一个自监督表示学习框架。它将二维图像中表示为欧氏距离矩阵的物体轮廓编码成一个对平移、缩放、旋转、反射和点索引不变的形状描述符。

**Result:** ShapeEmbed克服了传统形状描述符的局限性，并优于现有最先进的基于自编码器的方法。实验证明，该框架学习到的描述符在自然图像和生物图像的形状分类任务中表现优于竞争对手。

**Conclusion:** 该方法在生物成像应用中具有特别的 relevancy。

> **ai_Abstract:** ShapeEmbed是一个创新的自监督学习框架，专门用于二维物体轮廓的量化。它通过将物体轮廓编码为对多种几何变换（如平移、缩放、旋转、反射和点索引）不变的形状描述符，解决了传统形状量化中不变性不足的问题。该方法在性能上超越了传统的和现有的基于自编码器的方法，并在自然和生物图像的形状分类任务中展现出卓越的效能，尤其适用于生物成像领域。

> **摘要翻译:** 物体形状在广泛的应用中是视觉信息的重要来源。形状量化的核心挑战之一是确保提取的测量值对于保持物体内在几何的变换（例如改变其在图像中的大小、方向和位置）保持不变。在这项工作中，我们引入了ShapeEmbed，一个自监督表示学习框架，旨在将二维图像中表示为欧氏距离矩阵的物体轮廓编码成一个对平移、缩放、旋转、反射和点索引不变的形状描述符。我们的方法克服了传统形状描述符的局限性，同时改进了现有最先进的基于自编码器的方法。我们证明了我们的框架学习到的描述符在自然图像和生物图像的形状分类任务中优于其竞争对手。我们设想我们的方法与生物成像应用特别相关。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [DAM-VSR: Disentanglement of Appearance and Motion for Video Super-Resolution](https://arxiv.org/abs/2507.01012)
> *DAM-VSR：视频超分辨率中的外观与运动解耦*

*Zhe Kong, Le Li, Yong Zhang, Feng Gao, Shaoshu Yang, Tao Wang, Kaihao Zhang, Zhuoliang Kang, Xiaoming Wei, Guanying Chen, Wenhan Luo* | **Category: cs.CV**

**Keywords:** 视频超分辨率, 外观-运动解耦, 扩散模型, ControlNet, 时间一致性

**Comment:** Accepted by ACM SIGGRAPH 2025, Homepage:
  https://kongzhecn.github.io/projects/dam-vsr/ Github:
  https://github.com/kongzhecn/DAM-VSR

> **TL;DR:** 该论文提出了DAM-VSR，一个用于视频超分辨率的框架，它将外观和运动解耦，以解决现有方法在时间一致性和细节生成方面的不足，并在真实世界和AIGC数据上实现了最先进的性能。

**AI_Comments:** DAM-VSR的创新点在于其将视频超分辨率任务解耦为外观增强和运动控制，这有效地结合了图像超分辨率在细节生成方面的优势和视频ControlNet在保持时间一致性方面的能力。此外，提出的运动对齐双向采样策略对于处理长视频输入具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管最近一些利用图像扩散模型的视频超分辨率（VSR）方法在细节生成方面有所改进，但它们在产生时间一致的帧方面仍然存在困难。作者尝试使用Stable Video Diffusion (SVD) 结合ControlNet来解决此问题，但发现SVD固有的图像动画特性使得仅使用低质量视频难以生成精细细节。

**Method:** DAM-VSR是一个外观与运动解耦的VSR框架。它将VSR问题分解为外观增强和运动控制。外观增强通过参考图像超分辨率实现，而运动控制通过视频ControlNet实现。该框架充分利用了视频扩散模型的生成先验和图像超分辨率模型的细节生成能力。此外，它还配备了运动对齐的双向采样策略，以处理更长的输入视频。

**Result:** DAM-VSR在真实世界数据和AIGC数据上均取得了最先进的性能，展示了其强大的细节生成能力。

**Conclusion:** DAM-VSR成功地通过外观与运动解耦的方法解决了视频超分辨率中时间一致性和细节生成的问题，并在多种数据集上实现了优异的性能。

> **ai_Abstract:** 该论文提出了DAM-VSR，一个新颖的视频超分辨率框架，旨在解决现实世界VSR中时间不一致和细节生成不足的挑战。它将VSR解耦为外观增强（通过参考图像超分辨率）和运动控制（通过视频ControlNet），有效结合了图像和视频扩散模型的优势。结合运动对齐的双向采样策略，DAM-VSR在多种数据集上实现了最先进的性能。

> **摘要翻译:** 现实世界的视频超分辨率（VSR）由于复杂且不可预测的退化而面临重大挑战。尽管一些最近的方法利用图像扩散模型进行VSR并显示出改进的细节生成能力，但它们仍然难以生成时间上一致的帧。我们尝试使用Stable Video Diffusion（SVD）结合ControlNet来解决这个问题。然而，由于SVD固有的图像动画特性，仅使用低质量视频很难生成精细细节。为了解决这个问题，我们提出了DAM-VSR，一个用于VSR的外观与运动解耦框架。该框架将VSR解耦为外观增强和运动控制问题。具体来说，外观增强通过参考图像超分辨率实现，而运动控制通过视频ControlNet实现。这种解耦充分利用了视频扩散模型的生成先验和图像超分辨率模型的细节生成能力。此外，配备了所提出的运动对齐双向采样策略，DAM-VSR可以在更长的输入视频上进行VSR。DAM-VSR在真实世界数据和AIGC数据上取得了最先进的性能，展示了其强大的细节生成能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [18] [InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph](https://arxiv.org/abs/2507.00066)
> *InSight-R：一种由AutoGraph驱动的风险感知人因失效事件识别与界面诱发风险评估框架*

*Xingyu Xiao, Jiejuan Tong, Peng Chen, Jun Sun, Zhe Sui, Jingang Liang, Hongru Zhao, Jun Zhao, Haitao Wang* | **Category: cs.HC, cs.AI**

**Keywords:** 人因可靠性分析, 人因失效事件, 界面诱发风险, AutoGraph, 知识图谱

**Comment:** 

> **TL;DR:** InSight-R是一个由AutoGraph驱动的框架，用于自动化识别人因失效事件，并评估人机界面设计对操作员性能和错误易感性的影响，提高了人因可靠性分析的客观性和可解释性。

**AI_Comments:** 该论文的创新之处在于提出了一个结合自动化图基执行框架（AutoGraph）与经验行为数据的InSight-R框架，显著提升了人因失效事件识别的客观性和可解释性，克服了传统HRA方法对专家判断的过度依赖。其重要性体现在为安全关键领域（如核电）提供了更动态、实时的HRA能力，并为界面设计优化提供了数据驱动的洞察，有助于推进机制驱动的HRA方法学。

<details>
  <summary>Details</summary>

**Motivation:** 传统人因可靠性分析（HRA）方法过度依赖专家判断来识别人因失效事件（HFEs）和分配性能影响因素（PIFs），导致重现性差、主观性强，且缺乏界面级数据的集成。现有方法也无法严格评估人机界面设计如何影响操作员性能变异性和错误易感性。

**Method:** 本研究提出了一个由AutoGraph驱动的风险感知人因失效事件识别和界面诱发风险评估框架（InSight-R）。该框架通过将经验行为数据与由自动化图基执行框架（AutoGraph）构建的界面嵌入式知识图谱（IE-KG）关联起来，实现了基于易错和时间偏差操作路径的自动化HFE识别。

**Result:** InSight-R不仅增强了HFE识别的客观性和可解释性，而且为数字化控制环境中动态、实时的人因可靠性评估提供了一个可扩展的途径。研究还讨论了设计者-用户冲突与人因错误之间的关系。

**Conclusion:** InSight-R框架为界面设计优化提供了可操作的见解，并有助于推动机制驱动的人因可靠性分析（HRA）方法学的发展。

> **ai_Abstract:** 本研究提出了InSight-R框架，旨在解决传统人因可靠性分析（HRA）中专家判断的主观性和界面数据集成不足的问题。InSight-R利用AutoGraph构建的界面嵌入式知识图谱（IE-KG）和经验行为数据，实现人因失效事件（HFE）的自动化识别，并评估人机界面对操作员性能和错误的影响。该框架提高了HFE识别的客观性和可解释性，并为数字化控制环境中的实时HRA提供了可行路径，为界面设计优化提供了指导。

> **摘要翻译:** 人因可靠性在核电等安全关键领域仍然是一个关键问题，在这些领域，操作故障常常与人为错误有关。虽然传统的人因可靠性分析（HRA）方法已被广泛采用，但它们严重依赖专家判断来识别人因失效事件（HFEs）和分配性能影响因素（PIFs）。这种依赖性带来了与可重现性、主观性以及界面级数据集成有限相关的挑战。特别是，当前的方法缺乏严格评估人机界面设计如何影响操作员性能变异性和错误易感性的能力。为了解决这些限制，本研究提出了一个由AutoGraph驱动的风险感知人因失效事件识别和界面诱发风险评估框架（InSight-R）。通过将经验行为数据与由自动化图基执行框架（AutoGraph）构建的界面嵌入式知识图谱（IE-KG）关联起来，InSight-R框架能够基于易错和时间偏差操作路径实现自动化HFE识别。此外，我们还讨论了设计者-用户冲突与人因错误之间的关系。结果表明，InSight-R不仅增强了HFE识别的客观性和可解释性，而且为数字化控制环境中动态、实时的人因可靠性评估提供了一个可扩展的途径。该框架为界面设计优化提供了可操作的见解，并有助于推动机制驱动的人因可靠性分析方法学的发展。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [34] [Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments](https://arxiv.org/abs/2507.00161)
> *设计一个自适应讲故事平台，以促进政治两极分化学习环境中的公民教育*

*Christopher M. Wegemer, Edward Halim, Jeff Burke* | **Category: cs.HC, cs.AI**

**Keywords:** 政治两极分化, 公民教育, 自适应讲故事, 情感计算, AI-DCS

**Comment:** 

> **TL;DR:** 本文开发了一个AI辅助的自适应讲故事平台，旨在通过情感敏感的叙事来减少政治两极分化学习环境中的阻力，促进公民教育和换位思考。

**AI_Comments:** 这篇论文通过结合AI、情感计算和叙事学，为解决政治两极分化在公民教育中的负面影响提供了一个创新的方法。其亮点在于利用实时情感识别和GPT-4进行个性化故事叙述，以促进学生的情感投入和换位思考。这种方法在保持学习者自主性的同时，尝试缓解深度根植的身份抵抗，具有重要的实践意义。未来的挑战可能在于AI对话管理的复杂性以及确保算法公正性。

<details>
  <summary>Details</summary>

**Motivation:** 政治两极分化通过加剧基于身份的对立观点的抵制，从而损害了民主公民教育。新兴的AI技术为推进减少两极分化和促进政治开放的干预措施提供了新的机会。

**Method:** 论文借鉴政治心理学和叙事学理论，研究情感计算技术如何支持故事沉浸、角色认同和与讲故事者互动。采用设计本位研究（DBR）方法，迭代开发并完善了一个AI辅助数字公民讲故事（AI-DCS）平台原型。该原型整合了面部情绪识别和注意力跟踪，实时评估用户的情绪和注意力状态。叙事内容基于预设的故事大纲，通过GPT-4实现逐节语言自适应，个性化语言语调以维持学生对不同政治视角故事的情感投入。

**Result:** 该工作为AI支持的情感敏感策略奠定了基础，这些策略旨在解决情感两极分化，同时保留学习者的自主性。

**Conclusion:** 论文探讨了对公民教育干预、算法素养以及与AI对话管理和情感自适应学习环境相关的HCI挑战的影响。

> **ai_Abstract:** 本文提出并开发了一个AI辅助数字公民讲故事（AI-DCS）平台，旨在通过自适应和情感响应的叙事来促进政治两极分化环境中的公民教育。该平台利用面部情绪识别、注意力跟踪和GPT-4进行个性化语言适应，以增强学生对不同政治视角的理解和换位思考，从而减少情感两极分化，同时维护学习者自主性。

> **摘要翻译:** 政治两极分化通过加剧基于身份的对立观点的抵制，从而损害了民主公民教育。新兴的AI技术为推进减少两极分化和促进政治开放的干预措施提供了新的机会。我们研究了新颖的设计策略，这些策略利用自适应和情感响应的公民叙事，可能维持学生对故事的情感投入，进而促进他们对政治外群体成员的换位思考。借鉴政治心理学和叙事学理论，我们调查了情感计算技术如何支持三种讲故事机制：沉浸到故事世界中、与角色认同以及与讲故事者互动。我们采用设计本位研究（DBR）方法，迭代开发并完善了一个AI辅助数字公民讲故事（AI-DCS）平台。我们的原型整合了面部情绪识别和注意力跟踪，以实时评估用户的情感和注意力状态。叙事内容围绕预设的故事大纲组织，通过GPT-4实现逐节语言自适应，个性化语言语调以维持学生对以不同于他们自己政治观点为中心的故事的情感投入。我们的工作为AI支持的情感敏感策略奠定了基础，这些策略旨在解决情感两极分化，同时保留学习者的自主性。我们最后探讨了对公民教育干预、算法素养以及与AI对话管理和情感自适应学习环境相关的HCI挑战的影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [54] [Exploring AR Label Placements in Visually Cluttered Scenarios](https://arxiv.org/abs/2507.00198)
> *探索AR中视觉混乱场景下的标签放置*

*Ji Hwan Park, Braden Roper, Amirhossein Arezoumand, Tien Tran* | **Category: cs.HC**

**Keywords:** AR, 标签放置, 视觉混乱, 空间分组, 用户界面

**Comment:** 

> **TL;DR:** 该论文研究了在视觉混乱的AR环境中放置标签的方法，实现了三种标签放置技术并评估其效果。研究发现，使用标签对同类型物品进行空间分组有利于数据识别、比较和汇总。

**AI_Comments:** 该论文解决了AR领域中一个重要的实际问题：如何在视觉信息过载的环境中有效地管理信息呈现。其创新点在于超越现有指南，探索了特定的标签放置技术，尤其是提出了对同类型物品进行空间分组的概念。这种方法似乎是提高用户在AR中理解能力和任务表现的一种新颖且有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉混乱的AR环境中，随着用户视野中物体数量的增加，基于现有标签放置指南有效放置标签变得具有挑战性，尤其是当多种不同类型和多个相同类型的物品紧密排列时。

**Method:** 作者为AR应用中的视内物体实现了三种标签放置技术。这些技术专门针对物体分散且同类型物体紧密排列的场景。研究者对这些技术进行了评估，以完成三种目标任务。

**Result:** 研究表明，使用标签对相同类型的物品进行空间分组，对于识别、比较和汇总数据是有效的。

**Conclusion:** 在视觉混乱的AR场景中，通过标签对同类型物品进行空间分组是一种有效的标签放置策略，能够显著提升用户识别、比较和汇总数据的能力。

> **ai_Abstract:** 本论文旨在解决在视觉混乱的增强现实（AR）环境中有效放置标签的挑战，因为现有指南在此类场景中表现不足。作者为视内物体实现并评估了三种标签放置技术，特别关注于物体分散且多个相同类型物体紧密排列的场景。研究结果表明，利用单个标签对相似类型的物体进行空间分组，能够显著提升用户的数据识别、比较和汇总能力。

> **摘要翻译:** 我们研究了在视觉混乱的AR环境中放置标签的方法。随着用户视野中场景内物体数量的增加，基于现有标签放置指南有效放置标签变得具有挑战性。为了解决这个问题，我们为AR应用中的视内物体实现了三种标签放置技术。我们特别针对一种场景，即不同类型的各种物体分散在用户的视野中，并且多个相同类型的物体彼此靠近。我们评估了三种目标任务的三种放置技术。我们的研究表明，使用标签将相同类型的物体进行空间分组有利于识别、比较和汇总数据。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [74] [Examining the Social Communication and Community Engagement of Autistic Adults through an Asynchronous Focus Group](https://arxiv.org/abs/2507.00202)
> *通过异步焦点小组探讨自闭症成年人的社交沟通和社区参与*

*Blade Frisch, Betts Peters, Keith Vertanen* | **Category: cs.HC**

**Keywords:** 自闭症成年人, 社交沟通, 社区参与, 辅助和替代沟通, 异步焦点小组

**Comment:** 

> **TL;DR:** 本研究通过在线异步焦点小组探讨了自闭症成年人的社交沟通和社区参与，发现情绪、自闭症关闭状态影响沟通方式，并提出了未来AAC设计和自闭症研究的建议。

**AI_Comments:** 本研究通过采用异步焦点小组这一创新方法，有效收集了自闭症成年人关于社交沟通和AAC使用的独特视角，克服了传统面对面交流可能带来的挑战。其重要性在于揭示了情绪和自闭症关闭状态对沟通的深远影响，并为AAC设计提供了具体且实用的指导，填补了该领域研究的空白。研究还为未来自闭症研究指明了方向，具有较高的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究很少探讨自闭症成年人的沟通需求及其与其它残疾人群的区别。尽管辅助和替代沟通（AAC）可以支持这些需求，但需要更多关于如何为该人群设计AAC的指导。

**Method:** 研究通过一个在线、异步、基于文本的焦点小组，与五名自闭症成年人进行，以探讨他们的社交沟通、社区参与以及AAC如何提供支持。

**Result:** 分析参与者反馈发现：1) 参与者的情绪体验影响了他们使用的沟通方法；2) 会说话的自闭症成年人也能从AAC使用中受益；3) 自闭症关闭状态会产生动态的沟通需求。

**Conclusion:** 研究提出了未来AAC设计的启示：在关闭状态下支持沟通、向沟通伙伴表明沟通能力，以及需要更好地理解使用AAC的恐惧。这些启示可以为未来AAC系统的设计提供信息。此外，研究还提出了未来自闭症研究的主题：探索晚期诊断的影响、更好地理解自闭症关闭状态期间的沟通需求，以及扩大研究范围以包括影响沟通的社会和环境因素。最后，研究提供了关于如何以可访问的方式运行未来在线焦点小组的指导。

> **ai_Abstract:** 本研究通过对五名自闭症成年人进行在线异步文本焦点小组，探讨了他们的社交沟通、社区参与以及辅助和替代沟通（AAC）的作用。研究发现情绪和自闭症关闭状态对沟通方式有显著影响，并指出即使是会说话的自闭症成年人也能从AAC中获益。论文为未来的AAC设计提出了具体建议，包括支持关闭状态下的沟通和表明沟通能力，并为自闭症研究提出了新的方向，如晚期诊断的影响和社会环境因素。此外，研究还提供了进行可访问在线焦点小组的指导。

> **摘要翻译:** 目的：很少有研究探讨自闭症成年人的沟通需求以及他们的需求与其它残疾人群有何不同。辅助和替代沟通（AAC）可以支持这些沟通需求，但需要更多关于如何为该人群设计AAC的指导。
材料与方法：我们与五名自闭症成年人进行了一个在线、异步、基于文本的焦点小组，以探讨他们的社交沟通和社区参与，以及AAC如何帮助支持他们。
结果与结论：我们对参与者回应的分析发现：1) 参与者的情绪体验影响了他们使用的沟通方法；2) 会说话的自闭症成年人也能从AAC使用中受益；3) 自闭症关闭状态会产生动态的沟通需求。我们提出了未来AAC设计的启示：在关闭状态下支持沟通、向沟通伙伴表明沟通能力，以及需要更好地理解使用AAC的恐惧。这些启示可以为未来AAC系统的设计提供信息。我们还提供了未来自闭症研究的主题：探索晚期诊断的影响、更好地理解自闭症关闭状态期间的沟通需求，以及扩大研究范围以包括影响沟通的社会和环境因素。最后，我们提供了关于如何以可访问的方式运行未来在线焦点小组的指导。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [96] [User Concerns Regarding Social Robots for Mood Regulation: A Case Study on the "Sunday Blues"](https://arxiv.org/abs/2507.00271)
> *用户对用于情绪调节的社交机器人的担忧：以“周日忧郁”为例的案例研究*

*Zhuochao Peng, Jiaxin Xu, Jun Hu, Haian Xue, Laurens A. G. Kolks, Pieter M. A. Desmet* | **Category: cs.HC, cs.RO**

**Keywords:** 社交机器人, 情绪调节, 用户担忧, 人机交互, 周日忧郁

**Comment:** Accepted to International Conference on Social Robotics + AI (ICSR
  2025)

> **TL;DR:** 一项探索性案例研究，使用投机性机器人概念“Mora”，通过视频原型和共同构建故事的方法，与15名参与者讨论了他们对使用社交机器人进行情绪调节（特别是“周日忧郁”）的期望、疑虑和担忧，并提出了设计考虑。

**AI_Comments:** 这项研究的创新之处在于其采用的投机性设计方法和对特定、 relatable 情绪情境（“周日忧郁”）的关注，这有助于深入挖掘用户对社交机器人的真实担忧和期望。其通过共同构建故事的方法，有效地捕获了用户对复杂人机交互场景的细致见解，为未来社交机器人的设计和伦理发展提供了宝贵的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管近期研究强调了社交机器人在情绪调节方面的潜力，但对于潜在用户如何看待它们融入日常生活知之甚少，本研究旨在探索这一点。

**Method:** 本研究进行了一项探索性案例研究，使用了投机性机器人概念“Mora”来引发思考和促进讨论。研究以“周日忧郁”为背景，通过视频原型和共同构建故事的方法，让15名参与者想象与Mora的互动，并讨论他们的期望、疑虑和担忧。

**Result:** 研究揭示了一系列关于社交机器人属性的细致思考，例如同理心、干预有效性和伦理界限。

**Conclusion:** 研究结果被转化为人机交互未来研究和开发的设计考虑。

> **ai_Abstract:** 本研究通过一项探索性案例研究，探讨了潜在用户对社交机器人融入日常情绪调节的看法。研究以“周日忧郁”为具体情境，利用投机性机器人概念“Mora”、视频原型和共同构建故事的方法，与15名参与者进行了深入讨论。研究揭示了用户对社交机器人同理心、干预有效性和伦理界限等方面的细致担忧和思考，并将这些见解转化为未来人机交互设计和开发的重要考虑因素。

> **摘要翻译:** 尽管近期研究强调了社交机器人在情绪调节方面的潜力，但对于潜在用户如何看待它们融入日常生活知之甚少。为了探索这一点，我们进行了一项探索性案例研究，使用了一个投机性机器人概念“Mora”来引发思考，并促进关于使用社交机器人管理微妙的日常情感体验的有意义的讨论。我们聚焦于“周日忧郁”，这是一种在周末结束时常见的情绪低落，作为一个相关的背景来探索个体的见解。通过视频原型和共同构建故事的方法，我们让15名参与者想象与Mora的互动，并讨论他们的期望、疑虑和担忧。研究揭示了一系列关于社交机器人属性的细致思考，例如同理心、干预有效性和伦理界限，我们将其转化为未来人机交互研究和开发的设计考虑。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [119] [Visual Privacy Management with Generative AI for Blind and Low-Vision People](https://arxiv.org/abs/2507.00286)
> *生成式AI在盲人和低视力人群中的视觉隐私管理*

*Tanusree Sharma, Yu-Yun Tseng, Lotus Zhang, Ayae Ide, Kelly Avery Mack, Leah Findlater, Danna Gurari, Yang Wang* | **Category: cs.HC, cs.AI, cs.ET**

**Keywords:** 生成式AI, 视觉隐私, 盲人和低视力, 无障碍, 用户中心设计

**Comment:** 

> **TL;DR:** 本研究通过访谈调查，揭示了盲人和低视力（BLV）个体在使用生成式AI工具时面临的视觉隐私挑战，并提出了支持用户中心视觉隐私的设计偏好和建议。

**AI_Comments:** 该论文解决了AI无障碍领域一个关键且常被忽视的方面——盲人和低视力用户的隐私问题。其专注于以用户为中心的设计和可操作的建议，对于开发道德且有效的生成式AI工具至关重要。所识别出的设计偏好为未来的产品开发提供了具体的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI工具能增强盲人和低视力（BLV）个体对视觉内容的无障碍访问并提高其独立性，但这些工具也带来了复杂的视觉隐私挑战。因此，本研究旨在调查BLV个体当前的使用实践和未来的设计偏好。

**Method:** 通过对21名参与者进行访谈研究，调查了盲人和低视力个体在使用生成式AI工具时的当前实践和未来设计偏好。

**Result:** 研究发现，用户在使用生成式AI时会权衡隐私、效率和情感自主性，并在六个关键场景（如自我呈现、室内/室外空间隐私、社交分享和处理专业内容）中考虑隐私风险。设计偏好包括设备端处理、零保留保证、敏感内容编辑、隐私感知外观指示器以及多模式触觉镜像交互方法。

**Conclusion:** 本研究提出了可行的设计建议，以支持通过生成式AI实现以用户为中心的视觉隐私，并扩展了隐私和负责任地处理他人数据的概念。

> **ai_Abstract:** 本研究通过对21名盲人和低视力（BLV）个体进行访谈，探讨了他们在使用生成式AI工具时的视觉隐私实践和设计偏好。研究发现，BLV用户在自我呈现、空间隐私和内容共享等六个场景中权衡隐私与效率，并提出了设备端处理、零数据保留和敏感内容编辑等多项以用户为中心的设计需求。论文最终提出了支持BLV群体视觉隐私的实用设计建议。

> **摘要翻译:** 盲人和低视力（BLV）个体在日常生活中使用生成式AI（GenAI）工具来解读和管理视觉内容。虽然此类工具可以增强视觉内容的可访问性，从而提高用户的独立性，但它们也带来了复杂的视觉隐私挑战。在本文中，我们通过对21名参与者的访谈研究，调查了盲人和低视力个体的当前实践和未来设计偏好。我们的发现揭示了GenAI的各种当前实践，这些实践平衡了隐私、效率和情感自主性，用户在六个关键场景（如自我呈现、室内/室外空间隐私、社交分享和处理专业内容）中考虑了隐私风险。我们的发现揭示了设计偏好，包括设备端处理、零保留保证、敏感内容编辑、隐私感知外观指示器以及多模式触觉镜像交互方法。最后，我们提出了可行的设计建议，以通过GenAI支持以用户为中心的视觉隐私，扩展了隐私和负责任地处理他人数据的概念。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [142] [When Kids Mode Isn't For Kids: Investigating TikTok's "Under 13 Experience"](https://arxiv.org/abs/2507.00299)
> *当儿童模式不适合儿童时：调查TikTok的“13岁以下体验”*

*Olivia Figueira, Pranathi Chamarthi, Tu Le, Athina Markopoulou* | **Category: cs.HC, cs.CR**

**Keywords:** TikTok儿童模式, 儿童在线隐私, 内容筛选, COPPA, 安全审计

**Comment:** 

> **TL;DR:** 研究发现TikTok的“儿童模式”中83%的视频并非面向儿童，甚至包含不适宜内容，且缺乏家长控制功能，这可能促使儿童转向风险更高的普通模式。

**AI_Comments:** 这项研究的重要性在于填补了TikTok“儿童模式”研究的空白，揭示了该模式在保护未成年用户方面的显著不足。其创新之处在于提出了一种审计方法来系统性地评估内容筛选和安全措施。研究结果对监管机构和平台设计者具有重要的警示作用，强调了加强儿童在线保护的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管TikTok在儿童和青少年中很受欢迎，但其“儿童模式”的研究不足，且在内容筛选、安全和隐私保护方面缺乏透明度，这促使研究人员对其进行深入调查。

**Method:** 本文提出了一种审计方法，并将其应用于调查TikTok的“儿童模式”内容筛选，并根据《儿童在线隐私保护法》(COPPA)的规定，确定面向儿童内容的普遍性。

**Result:** 研究发现，“儿童模式”中“为你推荐”页面上83%的视频并非面向儿童，甚至发现了不适宜内容。该平台还缺乏关键功能，如家长控制和辅助功能设置。

**Conclusion:** 研究结果具有重要的设计和监管意义，因为儿童可能因此被激励使用TikTok的普通模式，而普通模式已知会让他们面临进一步的安全和隐私风险。

> **ai_Abstract:** 本研究调查了TikTok专为美国13岁以下用户设计的“儿童模式”。通过提出并应用一种审计方法，研究人员发现该模式在内容筛选上存在严重问题，高达83%的视频并非面向儿童，甚至包含不适宜内容。此外，该模式还缺乏关键的家长控制功能。这些发现揭示了“儿童模式”的不足，并指出其可能促使儿童转向风险更高的普通模式，对平台设计和监管提出了重要启示。

> **摘要翻译:** TikTok是儿童和青少年中流行的社交媒体平台，它为美国年轻用户提供了更严格的“13岁以下体验”，也称为TikTok的“儿童模式”。虽然之前的研究已经探讨了TikTok普通模式的各个方面，包括隐私和个性化，但TikTok的儿童模式仍未得到充分研究，并且其内容筛选以及对儿童的安全和隐私保护方面缺乏透明度。在本文中，(i) 我们提出了一种审计方法来全面调查TikTok的儿童模式，(ii) 我们将其应用于描述该平台的内容筛选特征，并根据《儿童在线隐私保护法》(COPPA)的规定确定面向儿童内容的普遍性。我们发现，在儿童模式的“为你推荐”页面上观察到的视频中，有83%实际上并非面向儿童，甚至发现了不适宜内容。该平台还缺乏关键功能，即家长控制和辅助功能设置。我们的发现具有重要的设计和监管意义，因为儿童可能会因此被激励使用TikTok的普通模式，而普通模式已知会让他们面临进一步的安全和隐私风险。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [143] [Scope Meets Screen: Lessons Learned in Designing Composite Visualizations for Marksmanship Training Across Skill Levels](https://arxiv.org/abs/2507.00333)
> *瞄准镜遇上屏幕：设计不同技能水平射击训练复合可视化界面的经验教训*

*Emin Zerman, Jonas Carlsson, Mårten Sjöström* | **Category: cs.HC, cs.CV, cs.GR, eess.IV**

**Keywords:** 射击训练, 复合可视化, 第一人称视频, 视觉分析, 技能水平

**Comment:** 5 pages, accepted at IEEE VIS 2025

> **TL;DR:** 本研究开发并评估了一种射击可视化系统，该系统结合了第一人称视频和叠加指标，发现仪表板风格的视图在不同技能水平的射击训练中最有效。

**AI_Comments:** 本文通过利用复合可视化和第一人称视频，为射击训练提供了一种创新方法，有效弥补了传统教练方法的不足。其优势在于以用户为中心的设计和评估，展示了实际应用价值。明确提出将其应用于其他精度型运动的建议，突显了其更广泛的影响力。

<details>
  <summary>Details</summary>

**Motivation:** 目前的射击训练主要依赖重复，教练无法通过射手的眼睛观察，分析也仅限于训练后的姿势和准确性，这限制了训练效果。因此，需要更有效的训练工具来提升射击技能。

**Method:** 研究开发了五种复合可视化界面，这些界面将第一人称射击视频与叠加的度量指标和图形摘要相结合。通过一项混合方法研究，对10名参与者（5名专家射手和5名新手）进行了评估，研究内容包括射击次数和瞄准解释任务、成对偏好比较以及半结构化访谈。

**Result:** 结果显示，一种结合了原始视频、极坐标图和选定图表的仪表板风格复合视图在10个案例中有9个被参与者偏爱，并且支持了不同技能水平的理解。

**Conclusion:** 这项设计研究的见解表明，将第一人称视频与视觉分析相结合对教练具有更广泛的价值，并提出了将这种方法应用于其他基于精度的运动的方向。

> **ai_Abstract:** 本文介绍并评估了一种新颖的射击可视化系统，旨在改进射击训练。该系统解决了传统训练中教练缺乏实时洞察的局限性，通过复合可视化界面将第一人称射击视频与叠加的性能指标和图形摘要相结合。一项针对新手和专家射手的混合方法研究表明，参与者强烈偏爱仪表板风格的视图，证明了其在增强不同技能水平理解方面的有效性。研究结果强调了将第一人称视频与视觉分析相结合用于教练的潜力，并建议将其更广泛地应用于其他精度型运动。

> **摘要翻译:** 射击练习在各种职业中都是必需的，包括警察、军事人员、猎人以及体育射手，如奥运射击、冬季两项和现代五项。目前的训练和指导形式主要基于重复，教练无法通过射手的眼睛观察，分析仅限于训练后的姿势和准确性。在本研究中，我们提出了一种射击可视化系统，并评估了其对新手和专家射手感知的有效性。为了实现这一目标，我们开发了五种复合可视化界面，它们使用第一人称射击视频记录，并辅以叠加的度量指标和图形摘要。这些视图通过一项混合方法研究（包括射击次数和瞄准解释任务、成对偏好比较以及半结构化访谈）对10名参与者（5名专家射手，5名新手）进行了评估。结果显示，一种仪表板风格的复合视图，结合了原始视频、极坐标图和选定图表，在10个案例中有9个被偏爱，并支持了不同技能水平的理解。这项设计研究获得的见解指出了将第一人称视频与视觉分析相结合用于教练的更广泛价值，我们建议将这种方法应用于其他基于精度的运动。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [164] [EEG-Based Auditory BCI for Communication in a Completely Locked-In Patient Using Volitional Frequency Band Modulation](https://arxiv.org/abs/2507.00305)
> *脑电图（EEG）听觉脑机接口用于完全闭锁患者的自主频带调制交流*

*Deland Liu, Frigyes Samuel Racz, Zoe Lalji, Jose del R. Millan* | **Category: cs.HC, q-bio.NC**

**Keywords:** 脑机接口, 完全闭锁状态, 脑电图, 听觉反馈, 频带调制

**Comment:** 

> **TL;DR:** CLIS患者通过EEG听觉BCI成功进行通信，通过自主调制alpha和beta波段功率实现“是/否”回答。

**AI_Comments:** 这项研究具有重要意义，因为它首次证明了非侵入性EEG-BCI在完全闭锁状态的ALS患者中实现自主通信的可能性。其创新之处在于使用了听觉反馈和频带调制作为通信机制。尽管在常识问题上的表现存在局限，但在辅助需求沟通上的成功以及患者持续的调制能力表明了该技术的巨大潜力，为CLIS患者带来了希望。

<details>
  <summary>Details</summary>

**Motivation:** 解决完全闭锁状态（CLIS）的肌萎缩侧索硬化症（ALS）患者失去所有可靠运动控制，无法进行交流的问题，并探索非侵入性EEG-BCI是否能支持CLIS患者的自主交流。

**Method:** 本研究对一名完全闭锁状态（CLIS）的ALS患者进行了一项研究。患者使用基于EEG的听觉脑机接口（BCI），通过自主调制不同通道的alpha和beta频带功率来给出“是/否”回答，并辅以实时听觉反馈。实验在多个在线会话中进行，要求患者回答常识问题和个人相关辅助问题。

**Result:** 一名CLIS患者能够在多个在线会话中操作EEG-BCI，成功回应常识问题和个人相关辅助问题，通过自主调制alpha和beta频带功率进行“是/否”回答。患者在所有会话中交流辅助需求的准确率均高于偶然水平，并在最后一次会话中达到满分。常识问题表现因会话而异，其中两次会话表现准确且高于偶然水平，而第一次和最后一次会话则保持在偶然水平。患者还显示出随时间推移一致的调制模式。

**Conclusion:** 这些发现表明，非侵入性脑机接口可能为恢复CLIS患者的基本交流提供潜在途径。

> **ai_Abstract:** 本研究探讨了基于脑电图（EEG）的听觉脑机接口（BCI）在一名完全闭锁状态（CLIS）的肌萎缩侧索硬化症（ALS）患者中恢复交流的可能性。患者成功学会通过自主调制alpha和beta频带功率，并在实时听觉反馈的引导下，在多个在线会话中进行“是/否”沟通，以回应常识和个人辅助问题。尽管常识问题表现有所波动，但患者在辅助需求沟通上表现出色，并在最终会话中达到满分，同时展现出一致的调制模式。研究结果表明非侵入性BCI有望为CLIS患者提供恢复基本交流的途径。

> **摘要翻译:** 肌萎缩侧索硬化症（ALS）患者在完全闭锁状态（CLIS）下会丧失所有可靠的运动控制，从而无法进行任何形式的交流。目前尚不清楚基于非侵入性脑电图（EEG）的脑机接口（BCI）是否能支持CLIS患者的自主交流。在此，我们展示了一名CLIS患者能够通过多个在线会话操作基于EEG的BCI，以回答常识问题和个人相关辅助问题。患者通过自主调制不同通道的alpha和beta频带功率，并在BCI的实时听觉反馈引导下，给出“是”/“否”的回答。患者在所有会话中交流辅助需求的准确率均高于偶然水平，并在最后一次会话中取得了满分。常识问题的表现因会话而异，其中两次会话显示出准确且高于偶然水平的回答，而第一次和最后一次会话则保持在偶然水平。患者还表现出随时间推移一致的调制模式。这些发现表明，非侵入性BCI可能为恢复CLIS患者的基本交流提供潜在途径。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [181] [Customer Service Representative's Perception of the AI Assistant in an Organization's Call Center](https://arxiv.org/abs/2507.00513)
> *客户服务代表对组织呼叫中心中AI助手的看法*

*Kai Qin, Kexin Du, Yimeng Chen, Yueyan Liu, Jie Cai, Zhiqiang Nie, Nan Gao, Guohui Wei, Shengzhu Wang, Chun Yu* | **Category: cs.HC, cs.AI, cs.CY**

**Keywords:** AI助手, 客户服务代表, 呼叫中心, 人工智能整合, 员工感知

**Comment:** ACM CSCW Poster 2025

> **TL;DR:** 研究发现，AI助手在呼叫中心能减轻客服代表部分传统负担，但同时带来新的负担，如学习、合规和心理负担。

**AI_Comments:** 这项研究通过实证访谈揭示了AI在客户服务领域应用的双重性，即在提高效率的同时也可能增加员工的认知和心理负担。其创新之处在于关注了AI集成后对一线员工的具体影响和适应过程，对未来AI系统设计和部署提供了重要的人本考量。

<details>
  <summary>Details</summary>

**Motivation:** 探究AI工具集成如何影响呼叫中心客户服务代表与客户互动时对AI助手的看法，特别是在复杂的社会技术环境中。

**Method:** 通过实地考察和对13名客户服务代表进行半结构化访谈。

**Result:** 发现AI能减轻电话沟通中的一些传统负担（如打字和记忆），但也带来了新的负担（如学习、合规和心理负担）。

**Conclusion:** 本研究有助于更细致地理解AI在组织环境中的整合，并强调了客户服务代表为适应更新系统所付出的努力和承担的负担。

> **ai_Abstract:** 本研究通过对电力公司呼叫中心13名客服代表的访谈，探讨了AI助手对客服工作的影响。结果表明，AI虽能减轻部分传统负担，但也引入了新的学习、合规和心理压力。研究旨在深入理解AI在组织中的整合及其对员工的实际影响。

> **摘要翻译:** 各种AI工具的集成创造了一个复杂的社会技术环境，其中员工与客户的互动构成了工作实践的核心。本研究调查了电力公司客户服务呼叫中心的客户服务代表（CSRs）在与客户互动时如何看待AI助手。通过实地考察和对13名客户服务代表进行半结构化访谈，我们发现AI可以减轻电话沟通中的一些传统负担（例如，打字和记忆），但同时也带来了新的负担（例如，学习、合规、心理负担）。这项研究有助于更细致地理解AI在组织环境中的整合，并强调了客户服务代表为适应更新系统所付出的努力和承担的负担。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [218] [Gaze3P: Gaze-Based Prediction of User-Perceived Privacy](https://arxiv.org/abs/2507.00596)
> *Gaze3P：基于凝视的用户感知隐私预测*

*Mayar Elfares, Pascal Reisert, Ralf Küsters, Andreas Bulling* | **Category: cs.HC, cs.CR**

**Keywords:** 用户感知隐私, 凝视数据, 机器学习, 隐私保护技术, Gaze3P

**Comment:** 

> **TL;DR:** 引入Gaze3P数据集，通过眼动数据训练机器学习模型预测用户感知隐私，并用于优化隐私保护技术参数。

**AI_Comments:** 这项工作具有创新性，通过引入Gaze3P数据集和基于眼动数据的机器学习模型，首次实现了对用户感知隐私的隐式、动态预测，克服了传统问卷调查的主观性和局限性。其重要性在于，为隐私保护技术的设计和优化提供了一个更客观、用户驱动的量化指标，有望提升隐私保护方案的用户体验和实际效用。

<details>
  <summary>Details</summary>

**Motivation:** 以前量化用户感知隐私主要依赖问卷，且将用户感知隐私应用于优化隐私保护技术参数的研究不足。

**Method:** 引入Gaze3P数据集（包含100名参与者和1000个刺激的凝视数据），训练机器学习模型从人类眼动中隐式、动态地预测感知隐私。

**Result:** 训练出的模型取得了高准确性，并展示了预测隐私可用于优化差分隐私机制的参数，使其更符合用户期望。

**Conclusion:** Gaze3P是首个用于系统研究用户感知隐私的数据集，通过眼动数据预测用户感知隐私是可行的，并且可以用于优化隐私保护技术，使其更好地满足用户需求。

> **ai_Abstract:** 本文针对现有用户感知隐私量化方法依赖问卷且难以优化隐私保护技术参数的局限性，提出了Gaze3P数据集。该数据集包含100名参与者的眼动数据，用于训练机器学习模型，实现从凝视数据中隐式、动态地预测用户感知隐私。实验结果表明模型预测准确性高，且预测的隐私可有效指导差分隐私机制的参数优化，使其更好地符合用户期望。

> **摘要翻译:** 隐私是一个高度主观的概念，不同个体对其感知各不相同。以往量化用户感知隐私的研究主要依赖于问卷调查。此外，将用户感知隐私应用于优化隐私保护技术（PPT）参数的研究仍然不足。为了解决这些局限性，我们引入了Gaze3P——第一个专门为促进用户感知隐私系统研究而设计的数据集。我们的数据集包含来自100名参与者和1000个刺激的凝视数据，涵盖了一系列私人和安全属性。利用Gaze3P，我们训练了一个机器学习模型，以隐式和动态地从人类眼动中预测感知隐私。通过全面的实验，我们表明所得到的模型实现了高准确性。最后，我们阐述了如何使用预测的隐私来优化差分隐私机制的参数，从而增强它们与用户期望的一致性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [232] [Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity](https://arxiv.org/abs/2507.00657)
> *LLM社交代理中的生成性夸大：一致性、偏见和毒性*

*Jacopo Nudo, Mario Edoardo Pandolfo, Edoardo Loru, Mattia Samory, Matteo Cinelli, Walter Quattrociocchi* | **Category: cs.HC, cs.AI, cs.SI**

**Keywords:** LLM, 社交代理, 政治话语, 生成性夸大, 偏见

**Comment:** 

> **TL;DR:** 研究发现，大型语言模型（LLMs）在模拟社交媒体政治话语时，会系统性地“生成性夸大”用户的显著特征，引入结构性偏见，从而损害其作为社会代理的可靠性，对其在内容审核等方面的应用提出挑战。

**AI_Comments:** 该研究通过大规模真实用户数据构建LLM代理，首次提出了“生成性夸大”这一新概念，揭示了LLM在模拟社交行为时存在的深层机制和结构性偏见。其创新之处在于实证性地展示了LLM作为社会代理的局限性，特别是在敏感的政治话语领域。这对于理解LLM的内在工作原理及其在社会应用中的潜在风险具有重要意义，为未来LLM的设计、部署以及相关政策制定提供了关键的警示和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 调查大型语言模型（LLMs）在模拟社交媒体政治话语时的行为表现。

**Method:** 利用2024年美国总统选举期间X（原Twitter）上的2100万互动数据，基于1,186名真实用户构建LLM代理。这些代理在受控条件下回复政治敏感推文，并以零样本或少样本方式初始化，以便与人类回复进行一对一比较。研究评估了Gemini、Mistral和DeepSeek三个模型家族在语言风格、意识形态一致性和毒性方面的表现。

**Result:** 研究发现，更丰富的上下文有助于提高LLM代理的内部一致性，但同时也会加剧两极分化、风格化信号和有害语言。研究观察到一种“生成性夸大”的扭曲现象：LLM系统性地放大了用户的显著特征，超出了经验基线。分析表明，LLM并非模仿用户，而是重构用户，其输出更多反映了内部优化动态而非观察到的行为，从而引入了结构性偏见，损害了其作为社会代理的可靠性。

**Conclusion:** LLM作为社会代理的可靠性受到结构性偏见的影响，这对其在内容审核、审议模拟和政策建模中的应用提出了挑战。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在模拟社交媒体政治话语时的行为模式。通过分析2024年美国总统选举期间X平台上的2100万次互动数据，研究人员构建了基于真实用户的LLM代理，并评估了它们在不同初始化条件下的回复表现。结果显示，尽管丰富的上下文能提升模型的一致性，但却会导致两极分化、风格化表达和有害语言的放大。研究揭示了一种“生成性夸大”现象，即LLMs会系统性地夸大用户显著特征，这表明LLMs更倾向于重构而非模仿用户，其输出反映了内部优化而非真实行为，从而引入了结构性偏见，削弱了其作为社会代理的可靠性，并对其在内容审核、审议模拟和政策建模等领域的应用提出了严峻挑战。

> **摘要翻译:** 我们研究了大型语言模型（LLMs）在模拟社交媒体政治话语时的行为。利用2024年美国总统选举期间X上的2100万次互动数据，我们基于1,186名真实用户构建了LLM代理，在受控条件下提示它们回复政治敏感推文。代理以最小的意识形态提示（零样本）或最近的推文历史（少样本）进行初始化，从而可以与人类回复进行一对一比较。我们评估了三个模型家族（Gemini、Mistral和DeepSeek）的语言风格、意识形态一致性和毒性。我们发现，更丰富的上下文有助于提高内部一致性，但也加剧了两极分化、风格化信号和有害语言。我们观察到一种新兴的扭曲，我们称之为“生成性夸大”：系统性地放大显著特征，超出经验基线。我们的分析表明，LLMs并非模仿用户，而是重构用户。它们的输出确实更多反映了内部优化动态而非观察到的行为，引入了结构性偏见，损害了它们作为社会代理的可靠性。这对其在内容审核、审议模拟和政策建模中的使用提出了挑战。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [243] [Social Robots for People with Dementia: A Literature Review on Deception from Design to Perception](https://arxiv.org/abs/2507.00963)
> *用于痴呆症患者的社交机器人：从设计到感知的欺骗性文献综述*

*Fan Wang, Giulia Perugia, Yuan Feng, Wijnand IJsselsteijn* | **Category: cs.HC, cs.CY, cs.RO**

**Keywords:** 社交机器人, 痴呆症, 欺骗, 设计, 感知

**Comment:** 

> **TL;DR:** 该综述探讨了社交机器人如何通过设计线索在痴呆症患者中引发欺骗性感知，并提出了基于双过程理论的欺骗定义。

**AI_Comments:** 这篇论文的创新之处在于它首次提出了一个基于经验和认知机制的机器人欺骗定义，特别是将双过程理论引入了对痴呆症患者与社交机器人互动中欺骗现象的理解。这对于指导未来社交机器人的伦理设计和应用具有重要意义，尤其是在易受影响人群的护理领域。

<details>
  <summary>Details</summary>

**Motivation:** 随着社交机器人越来越多地应用于痴呆症护理，人们对欺骗（无论有意与否）的担忧日益增加。然而，机器人设计线索如何引起痴呆症患者的误导性感知，以及这些感知如何产生，仍未得到充分理解。

**Method:** 本范围综述审查了26项关于痴呆症患者与实体社交机器人之间互动的实证研究。通过主题分析用户反应。

**Result:** 研究确定了四类可能影响欺骗性印象的关键设计线索：模仿生理迹象的线索（如模拟呼吸）、社交意图（如嬉戏动作）、熟悉的存在（如动物般的形态和声音），以及在较小程度上揭示人工性的线索。用户反应的主题分析显示，痴呆症患者经常将生物、社会和心理能力归因于机器人，在意识和幻觉之间动态转换。研究还提出了一个基于经验的定义：当Type 1（自动、启发式）处理主导Type 2（审慎、分析性）推理时，导致对机器人人工性质的误解，即发生机器人欺骗。

**Conclusion:** 这些发现强调了痴呆症背景下本体感知的波动性。现有关于机器人欺骗的定义往往基于哲学或行为主义前提，但很少涉及相关的认知机制。本研究提出的双过程视角凸显了痴痴呆症护理中社交机器人的伦理复杂性，并呼吁设计方法不仅要具有吸引力，还要在认知上尊重用户。

> **ai_Abstract:** 本综述旨在解决社交机器人在痴呆症护理中可能引起的欺骗问题。通过对26项实证研究的范围综述，研究识别了四类可能导致欺骗性感知的机器人设计线索，并发现痴呆症患者常将生物、社会和心理能力归因于机器人。文章提出了一个基于双过程理论的机器人欺骗新定义，即当自动处理导致对机器人人工性质的误解时。这项工作强调了在痴呆症护理中社交机器人设计的伦理复杂性，并倡导开发认知上尊重的机器人。

> **摘要翻译:** 随着社交机器人越来越多地进入痴呆症护理领域，人们对欺骗（无论有意与否）的担忧日益增加。然而，机器人设计线索如何引起痴呆症患者的误导性感知，以及这些感知如何产生，仍未得到充分理解。在这项范围综述中，我们审查了26项关于痴呆症患者与实体社交机器人之间互动的实证研究。我们确定了四类可能影响欺骗性印象的关键设计线索：模仿生理迹象的线索（例如，模拟呼吸）、社交意图（例如，嬉戏动作）、熟悉的存在（例如，动物般的形态和声音），以及在较小程度上揭示人工性的线索。对用户反应的主题分析显示，痴呆症患者经常将生物、社会和心理能力归因于机器人，在意识和幻觉之间动态转换。这些发现强调了痴呆症背景下本体感知的波动性。现有关于机器人欺骗的定义往往基于哲学或行为主义前提，但很少涉及相关的认知机制。我们提出了一个基于经验的定义：当Type 1（自动、启发式）处理主导Type 2（审慎、分析性）推理时，导致对机器人人工性质的误解，即发生机器人欺骗。这种双过程视角凸显了痴呆症护理中社交机器人的伦理复杂性，并呼吁设计方法不仅要具有吸引力，还要在认知上尊重用户。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [245] [Designing Visualization Widgets for Tangible Data Exploration: A Systematic Review](https://arxiv.org/abs/2507.00775)
> *为有形数据探索设计可视化小部件：一项系统综述*

*Haonan Yao, Lingyun Yu, Lijie Yao* | **Category: cs.HC**

**Keywords:** 有形数据探索, 可视化小部件, 系统综述, 交互设计, 研究议程

**Comment:** 

> **TL;DR:** 本文对有形数据探索中的任务、交互和可视化小部件进行了系统综述，旨在解决该领域缺乏结构化理解的现状，并提出了未来的研究议程。

**AI_Comments:** 这篇系统综述填补了有形数据探索领域中对任务、交互和小部件设计之间关系的结构化理解空白。通过系统分析，它不仅总结了现有设计，更重要的是为未来的研究和工具包开发提供了明确的指导和研究议程，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明有形小部件能减轻认知负荷、实现更自然的交互并支持复杂数据探索，但该领域缺乏对任务类型、交互方法和小部件设计如何协调的结构化理解，这限制了识别重复设计模式和创新机会的能力。

**Method:** 作者进行了一项系统综述，分析现有工作并描述了当前数据探索任务、交互和有形可视化小部件的设计。

**Result:** 通过系统综述，作者分析并表征了有形数据探索中任务、交互和可视化小部件的当前设计。

**Conclusion:** 作者基于研究发现提出了一个研究议程，旨在为未来有形数据探索的小部件设计工具包的开发提供信息。

> **ai_Abstract:** 本文对有形数据探索领域的任务、交互和可视化小部件进行了系统综述。鉴于现有研究缺乏对这些元素协调方式的结构化理解，作者通过分析现有工作来表征当前的设计，并基于发现提出了一个研究议程，旨在指导未来有形数据探索小部件设计工具包的开发。

> **摘要翻译:** 我们对有形数据探索背景下的任务、交互和可视化小部件（指通过特定交互完成数据探索任务的有形实体）进行了系统综述。有形小部件已被证明可以减轻认知负荷，实现更自然的交互，并支持复杂数据探索任务的完成。然而，该领域缺乏对任务类型、交互方法和小部件设计如何协调的结构化理解，这限制了识别重复设计模式和创新机会的能力。为了弥补这一空白，我们进行了一项系统综述，分析现有工作并描述了当前数据探索任务、交互和有形可视化小部件的设计。接下来，我们根据研究结果进行反思，并提出一个研究议程，以指导未来有形数据探索小部件设计工具包的开发。我们的系统综述和补充材料可在 physicalviswidget.github.io 和 osf.io/vjw5e 获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [258] [Sensemaking Through Making: Developing Clinical Domain Knowledge by Crafting Synthetic Datasets and Prototyping System Architectures](https://arxiv.org/abs/2507.00821)
> *通过制作理解：通过制作合成数据集和原型系统架构来发展临床领域知识*

*Mihnea Stefan Calota, Wessel Nieuwenhuys, Janet Yi-Ching Huang, Lin-Lin Chen, Mathias Funk* | **Category: cs.HC**

**Keywords:** 医疗保健设计, 领域知识, 合成数据集, 原型设计, 远程患者监测

**Comment:** 

> **TL;DR:** 本文介绍了一种以制作为导向的方法，帮助设计师在难以直接接触实际医疗系统的情况下，通过手工制作合成数据集和迭代原型系统来理解复杂的医疗保健系统并发展领域知识。

**AI_Comments:** 这项研究的创新之处在于提出了一种实用的“通过制作理解”方法，解决了在封闭医疗生态系统中获取领域知识的难题。通过强调合成数据制作和迭代原型设计，它为设计师提供了一种有效且低风险的学习途径，特别是在数据敏感或难以直接访问的领域。其重要性在于为医疗保健设计和更广泛的复杂系统设计提供了一种新的思维模式和工具。

<details>
  <summary>Details</summary>

**Motivation:** 设计师在医疗保健领域有很大的影响力，但医院通常是封闭的生态系统，导致难以接触临床利益相关者、发展领域知识以及获取相关系统和数据。

**Method:** 本文提出了一种以制作为导向的方法。以远程患者监测（RPM）为例，通过观察和建模真实的RPM环境，手工制作基于真实世界观察的合成数据集，并迭代原型化一个简化的RPM系统，该系统平衡了上下文的丰富性和有意的抽象。

**Result:** 通过这种迭代的“通过制作理解”过程，设计师即使在直接访问实际医疗系统受限的情况下，也能培养对上下文的熟悉度。该方法强调了与数据结构进行动手交互的价值，以支持设计师理解不透明的医疗保健系统。

**Conclusion:** 通过制作合成数据集和原型系统，设计师即使在直接访问受限的情况下，也能有效地理解复杂的医疗保健系统并发展领域知识，凸显了动手实践在理解不透明系统中的价值。

> **ai_Abstract:** 本文提出了一种“通过制作理解”的设计方法，旨在帮助设计师在医疗保健领域面临数据和系统访问限制时，发展领域知识。通过以远程患者监测为例，研究人员展示了如何通过手工制作合成数据集和迭代原型化系统，使设计师能够理解复杂的数据驱动型医疗系统，从而在实际系统难以直接接触的情况下也能获得上下文熟悉度。

> **摘要翻译:** 设计师在医疗保健领域有充足的机会发挥影响力。然而，医院通常是封闭的生态系统，这给接触临床利益相关者、发展领域知识以及访问相关系统和数据带来了挑战。在本文中，我们介绍了一种以制作为导向的方法，旨在帮助设计师理解其目标医疗保健环境的复杂性。我们以远程患者监测（RPM）为例，探讨了如何通过手动制作基于真实世界观察的合成数据集，使设计师能够了解复杂的数据驱动型医疗保健系统。我们的过程包括观察和建模真实的RPM环境，制作合成数据集，以及迭代原型化一个简化的RPM系统，该系统平衡了上下文的丰富性和有意的抽象。通过这种迭代的“通过制作理解”过程，设计师即使在直接访问实际医疗系统受限的情况下，也能培养对上下文的熟悉度。我们的方法强调了与数据结构进行动手交互的价值，以支持设计师理解不透明的医疗保健系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [269] [Towards Difficulty-Aware Analysis of Deep Neural Networks](https://arxiv.org/abs/2507.00881)
> *深度神经网络难度感知分析研究*

*Linhao Meng, Stef van den Elzen, Anna Vilanova* | **Category: cs.HC**

**Keywords:** 实例难度, 深度神经网络, 模型分析, 可视化工具, 图像分类

**Comment:** 

> **TL;DR:** 本文提出了一种将实例难度纳入深度神经网络评估的方法，并开发了交互式可视化工具DifficultyEyes，用于识别和分析不同难度模式的实例，以解决传统分析忽略实例难度的问题。

**AI_Comments:** 本文的创新之处在于将“实例难度”这一概念系统地引入深度神经网络的分析框架中，并从多维度（数据、模型、人类）进行量化和考量。这超越了传统仅关注错误分类实例的局限性，为理解模型鲁棒性和泛化能力提供了更深层次的视角。开发的可视化工具DifficultyEyes也为研究人员提供了直观的分析手段，有助于识别和解决模型与数据相关的问题。该研究对于提升深度学习模型的可解释性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的实例分析主要关注错误分类的实例，但忽略了不同实例的难度差异。理想的模型应能识别并反映内在困难实例的挑战，且模型感知的难度应与人类感知的一致。因此，需要将实例难度纳入深度神经网络的评估过程。

**Method:** 本文提出将实例难度纳入深度神经网络（DNN）评估过程，特别针对图像数据的有监督分类任务。具体而言，从数据、模型和人类三个维度考量难度度量，以实现全面评估和比较。此外，开发了一个交互式可视化工具DifficultyEyes，支持基于各种难度模式识别感兴趣的实例，并辅助分析潜在的数据或模型问题。

**Result:** 案例研究表明了我们方法的有效性。

**Conclusion:** 本文成功将实例难度引入深度神经网络的评估，并通过多维度难度考量和可视化工具提升了模型分析的全面性和有效性。

> **ai_Abstract:** 本文提出了一种针对深度神经网络的难度感知分析方法，旨在解决传统分析中忽略实例难度的问题。该方法将实例难度从数据、模型和人类三个维度纳入评估过程，特别适用于图像分类任务。为支持分析，研究者开发了交互式可视化工具DifficultyEyes，用于识别具有特定难度模式的实例并诊断潜在的数据或模型问题。案例研究验证了该方法的有效性。

> **摘要翻译:** 传统基于实例的模型分析主要集中在错误分类的实例上。然而，这种方法忽略了不同实例相关的不同难度。理想情况下，一个稳健的模型应该识别并反映内在困难实例所带来的挑战。研究模型感知的难度是否与人类感知的难度一致也很有价值。为了解决这个问题，我们建议将实例难度纳入深度神经网络的评估过程，特别是针对图像数据的有监督分类任务。具体而言，我们从数据、模型和人类三个角度考虑难度度量，以促进全面评估和比较。此外，我们开发了一个交互式可视化工具DifficultyEyes，支持根据各种难度模式识别感兴趣的实例，并帮助分析潜在的数据或模型问题。案例研究证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [287] [A Comprehensive Review of Human Error in Risk-Informed Decision Making: Integrating Human Reliability Assessment, Artificial Intelligence, and Human Performance Models](https://arxiv.org/abs/2507.01017)
> *风险知情决策中人为错误的综合综述：整合人为可靠性评估、人工智能和人类绩效模型*

*Xingyu Xiao, Hongxu Zhu, Jingang Liang, Jiejuan Tong, Haitao Wang* | **Category: cs.HC**

**Keywords:** 人为错误, 风险知情决策, 人为可靠性评估, 人工智能, 认知模型

**Comment:** 

> **TL;DR:** 该综述分析了在风险知情决策中，通过整合人为可靠性评估、人工智能和人类绩效模型，如何减少人为错误风险，并指出整合认知模型与AI分析能显著提高预测准确性，但需要高质量数据和透明算法。

**AI_Comments:** 这篇综述的创新之处在于其对人为错误风险缓解的综合性视角，尤其强调了人工智能、人为可靠性评估和认知科学的融合。它不仅指出了现有方法的局限性，还提出了通过多学科整合来提升预测精度和系统可靠性的可行路径。文章对未来研究方向的展望，特别是对高质量数据和算法透明度的呼吁，对于推动该领域的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 人为错误在核电、航空和医疗等安全关键领域仍然是主要的风险驱动因素，即使是微小的错误也可能导致灾难性后果。尽管数十年的研究产生了丰富的缓解技术，但高质量数据稀缺、算法不透明以及对专家判断的持续依赖等局限性，阻碍了进展。因此，本综述旨在综合风险知情决策、人为可靠性评估（HRA）、人工智能（AI）和认知科学的最新进展，以阐明它们的融合如何抑制人为错误风险。

**Method:** 本综述综合了风险知情决策、人为可靠性评估（HRA）、人工智能（AI）和认知科学领域的最新进展。首先，对复杂社会技术环境中观察到的人为错误主要形式进行了分类，并概述了它们对系统可靠性的量化影响。其次，审查了将HRA嵌入概率和数据驱动方法的风险知情框架，并强调了其成功之处和不足。然后，调查了认知和人类绩效模型，详细说明了感知、记忆和决策的机械解释如何丰富错误预测并补充HRA指标。在此基础上，批判性评估了支持AI的实时错误检测、操作员状态估计和AI增强HRA工作流程的技术。

**Result:** 本综述得出的一个反复出现的见解是：在风险知情的人为可靠性评估（HRA）流程中，将认知模型与基于AI的分析相结合，可以显著提高预测准确性。然而，这样做需要更丰富的数据集、透明的算法和严格的验证。

**Conclusion:** 为了提升高风险系统中的人为可靠性，本综述确定了有前景的研究方向，包括将韧性工程概念与扎根理论相结合，将事件成因的冰山模型操作化，以及建立跨领域数据联盟，以促进多学科范式。

> **ai_Abstract:** 本综述全面探讨了安全关键领域中人为错误的问题，指出其是主要风险驱动因素，并面临数据稀缺、算法不透明等挑战。文章综合了风险知情决策、人为可靠性评估（HRA）、人工智能（AI）和认知科学的最新进展，旨在阐明这些领域的融合如何有效降低人为错误风险。综述首先对人为错误进行分类并量化其影响，随后考察了嵌入HRA的风险知情框架和认知/人类绩效模型。文章重点评估了AI在错误检测和HRA中的应用，并强调将认知模型与AI分析结合能显著提高预测准确性，但需高质量数据和算法透明度。最后，提出了通过韧性工程、冰山模型和跨领域数据联盟来提升人为可靠性的未来研究方向。

> **摘要翻译:** 人为错误在核电、航空和医疗等安全关键领域仍然是主要的风险驱动因素，即使是看似微小的错误也可能导致灾难性的后果。尽管数十年的研究已经产生了丰富的缓解技术，但高质量数据稀缺、算法不透明以及对专家判断的持续依赖等持续存在的局限性，继续制约着进展。本综述综合了风险知情决策、人为可靠性评估（HRA）、人工智能（AI）和认知科学交叉领域的最新进展，以阐明它们的融合如何抑制人为错误风险。我们首先对复杂社会技术环境中观察到的人为错误主要形式进行分类，并概述它们对系统可靠性的量化影响。接下来，我们审查了将HRA嵌入概率和数据驱动方法的风险知情框架，重点强调了其成功之处和不足。然后，我们调查了认知和人类绩效模型，详细说明了感知、记忆和决策的机械解释如何丰富错误预测并补充HRA指标。在此基础上，我们批判性评估了支持AI的实时错误检测、操作员状态估计和AI增强HRA工作流程的技术。在这些方面，一个反复出现的见解是：在风险知情的人为可靠性评估（HRA）流程中，将认知模型与基于AI的分析相结合，可以显著提高预测准确性，但这样做需要更丰富的数据集、透明的算法和严格的验证。最后，我们确定了有前景的研究方向，包括将韧性工程概念与扎根理论相结合，将事件成因的冰山模型操作化，以及建立跨领域数据联盟，以促进提升高风险系统中人为可靠性的多学科范式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [6] [Origin-Destination Travel Demand Estimation: An Approach That Scales Worldwide, and Its Application to Five Metropolitan Highway Networks](https://arxiv.org/abs/2507.00306)
> *起点-终点出行需求估计：一种全球可扩展的方法及其在五个大都市高速公路网络中的应用*

*Chao Zhang, Neha Arora, Christopher Bian, Yechen Li, Willa Ng, Andrew Tomkins, Bin Yan, Janny Zhang, Carolina Osorio* | **Category: cs.ET**

**Keywords:** 起点-终点出行需求, 交通管理, 谷歌地图交通趋势, 非线性优化, 宏观网络模型

**Comment:** 

> **TL;DR:** 本文提出了一种新的起点-终点(OD)出行需求估计方法，该方法利用谷歌地图交通趋势的聚合匿名数据，通过一个计算轻量级的可微分分析宏观网络模型，解决了传统方法对高保真交通数据和先验OD估计的依赖，并在多个城市的高速公路网络上验证了其有效性和可扩展性。

**AI_Comments:** 该论文的创新之处在于其提出了一种无需传统普查或城市提供的OD数据，直接利用谷歌地图交通趋势聚合数据进行OD需求估计的方法。通过引入计算轻量级的可微分分析宏观网络模型和非线性优化框架，该方法显著提升了OD估计的效率、可扩展性和对数据稀缺的鲁棒性。其在全球范围内的适用性对城市规划和交通管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的起点-终点(OD)出行需求估计方法面临普遍存在的高保真交通数据稀缺以及难以获取城市特定的先验OD估计（或种子OD）的挑战，而这些先验OD估计通常是传统方法的先决条件。因此，开发一种普遍适用的OD估计方法至关重要。

**Method:** 本文提出的方法通过系统地利用谷歌地图交通趋势的聚合匿名统计数据直接估计OD出行需求，从而避免了对传统普查或城市提供的OD数据的需求。OD需求通过一个单层、一维、连续非线性优化问题来估计，该问题包含非线性等式和边界约束以复制高速公路路径出行时间。该方法通过采用一个可微分的分析宏观网络模型实现效率和可扩展性，该模型计算轻量级、参数化精简且可瞬时评估。

**Result:** 使用洛杉矶和圣地亚哥高速公路网络的片段传感器计数数据验证了所提出的方法，结果显示其对片段计数数据的拟合度比基线提高了三分之二到四分之三。此外，该方法在复制西雅图、奥兰多、丹佛、费城和波士顿等不同高速公路网络中的路径出行时间方面，不仅与基于模拟的基准对齐，而且在下午高峰时段，其拟合出行时间数据的能力比基线平均提高了13%。

**Conclusion:** 本文提出的起点-终点出行需求估计方法利用聚合的谷歌地图交通趋势数据，克服了传统方法对高保真数据和先验OD估计的依赖。该方法通过一个高效、可扩展且计算轻量级的可微分宏观网络模型，在全球范围内具有广泛的适用性和实用性，并在多个城市的高速公路网络中表现出显著的性能提升。

> **ai_Abstract:** 本文提出了一种创新的起点-终点（OD）出行需求估计方法，旨在解决传统方法对高保真交通数据和先验OD估计的依赖。该方法利用谷歌地图交通趋势的聚合匿名统计数据，通过一个计算轻量级、可微分的分析宏观网络模型，将OD需求估计问题表述为一个非线性优化问题。实验结果表明，该方法在拟合片段计数数据方面比基线有显著改进，并在多个大都市高速公路网络中展现出卓越的可扩展性和复制路径出行时间的性能，证明了其在全球范围内的广泛适用性和实用性。

> **摘要翻译:** 估计起点-终点（OD）出行需求对于有效的城市规划和交通管理至关重要。普遍存在的高保真交通数据稀缺以及难以获取城市特定的先验OD估计（或种子OD）极大地挑战了开发普遍适用的OD估计方法，而这些先验OD估计通常是传统方法的先决条件。我们提出的方法通过系统地利用谷歌地图交通趋势的聚合匿名统计数据直接估计OD出行需求，从而避免了对传统普查或城市提供的OD数据的需求。OD需求通过一个单层、一维、连续非线性优化问题来估计，该问题包含非线性等式和边界约束以复制高速公路路径出行时间。该方法通过采用一个可微分的分析宏观网络模型实现效率和可扩展性。该模型在设计上计算轻量级，其特点是参数化精简，需要最少的校准工作，并能够即时评估。这些属性确保了该方法在全球不同城市中的广泛适用性和实用性。我们使用洛杉矶和圣地亚哥高速公路网络的片段传感器计数数据验证了我们提出的方法，结果显示其对片段计数数据的拟合度比基线提高了三分之二到四分之三。除了验证之外，我们还在包括西雅图、奥兰多、丹佛、费城和波士顿在内的不同高速公路网络中，验证了该方法在复制路径出行时间方面的可扩展性和鲁棒性能。在这些扩展评估中，我们的方法不仅与基于模拟的基准对齐，而且在下午高峰时段，其拟合出行时间数据的能力比基线平均提高了13%。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [22] [DiffCkt: A Diffusion Model-Based Hybrid Neural Network Framework for Automatic Transistor-Level Generation of Analog Circuits](https://arxiv.org/abs/2507.00444)
> *DiffCkt：一种基于扩散模型的混合神经网络框架，用于模拟电路的自动晶体管级生成*

*Chengjie Liu, Jiajia Li, Yabing Feng, Wenhao Huang, Weiyu Chen, Yuan Du, Jun Yang, Li Du* | **Category: cs.ET**

**Keywords:** 扩散模型, 模拟电路, 自动生成, 晶体管级, 预布局设计

**Comment:** Accepted by ICCAD2025

> **TL;DR:** DiffCkt是一个基于扩散模型的混合神经网络框架，用于自动生成模拟电路的晶体管级设计，能够根据性能要求直接生成电路结构和器件参数，并通过引入CGEI指标，实现了显著的效率提升，达到最先进水平。

**AI_Comments:** 该论文的创新点在于首次将扩散模型引入模拟电路的晶体管级自动生成，并结合混合神经网络框架，实现了从性能要求到电路结构和参数的直接映射。通过引入CGEI这一综合评估指标，能够更全面地衡量生成电路的效率，并展现了其相对于传统方法的巨大优势。这项工作为模拟电路的自动化设计领域带来了革命性的方法，有望大幅缩短设计周期并降低对人工经验的依赖。数据集的开源也促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 模拟电路的预布局阶段直接决定最终电路性能，但高度依赖经验丰富的工程师进行手动设计，耗时且效率低下。为了克服这些挑战并自动化模拟电路的预布局设计阶段，本文提出了DiffCkt。

**Method:** 本文提出了DiffCkt，一个基于扩散模型的混合神经网络框架，用于自动晶体管级生成模拟电路。该框架可以直接生成针对特定性能要求定制的电路结构和器件参数。为了量化生成电路的效率，引入了电路生成效率指数（CGEI），该指数由单个生成电路的品质因数（FOM）和消耗时间共同决定。

**Result:** 与相关研究相比，DiffCkt的CGEI提高了2.21到8365倍，达到了最先进（SOTA）水平。

**Conclusion:** 扩散模型在学习和生成模拟电路结构和器件参数方面具有显著能力，为模拟电路的预布局设计自动化提供了一种革命性的方法。

> **ai_Abstract:** DiffCkt是一个创新的基于扩散模型的混合神经网络框架，旨在自动化模拟电路的晶体管级预布局设计。它能够根据特定的性能需求自动生成电路结构和器件参数。为了评估其效率，论文提出了电路生成效率指数（CGEI），并将DiffCkt与现有方法进行了比较，展示了其在CGEI上的显著提升（2.21至8365倍），达到了最先进水平。该研究强调了扩散模型在模拟电路自动化设计中的巨大潜力。

> **摘要翻译:** 模拟电路设计包括预布局和布局阶段。其中，预布局阶段直接决定最终电路性能，但严重依赖经验丰富的工程师根据特定应用场景进行手动设计。为了克服这些挑战并自动化模拟电路预布局设计阶段，我们引入了DiffCkt：一种基于扩散模型的混合神经网络框架，用于模拟电路的自动晶体管级生成，它可以直接生成根据特定性能要求定制的相应电路结构和器件参数。为了更准确地量化DiffCkt生成电路的效率，我们引入了电路生成效率指数（CGEI），该指数由单个生成电路的品质因数（FOM）和消耗时间共同决定。与相关研究相比，DiffCkt的CGEI提高了2.21到8365倍，达到了最先进（SOTA）水平。总而言之，这项工作表明扩散模型具有学习和生成模拟电路结构和器件参数的卓越能力，为模拟电路的预布局设计自动化提供了一种革命性的方法。电路数据集将开源，其预览版本可在https://github.com/CjLiu-NJU/DiffCkt获取。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [42] [Robust Task Offloading for UAV-enabled Secure MEC Against Aerial Eavesdropper](https://arxiv.org/abs/2507.00710)
> *针对空中窃听者的无人机安全MEC鲁棒任务卸载*

*Can Cui, ZIye Jia, Chao Dong, Qihui Wu* | **Category: cs.ET**

**Keywords:** 无人机,多接入边缘计算,鲁棒优化,空中窃听,安全

**Comment:** 

> **TL;DR:** 本文提出了一种鲁棒的任务卸载方案，以应对无人机辅助安全MEC中空中窃听者的威胁，并考虑了不确定性参数。

**AI_Comments:** 这篇论文通过引入分布鲁棒优化和CVaR来处理MEC任务卸载中与空中窃听和不确定性相关的安全挑战，具有创新性。其重要性在于为未来6G网络中无人机辅助MEC的实际部署提供了更安全、更可靠的解决方案。通过量化不确定性下的性能下降（仅5%的能量消耗增加），论文有力地证明了其方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 无人机（UAV）是未来6G通信网络中多接入边缘计算（MEC）的有前景候选，但空中窃听无人机（EUAV）对数据卸载构成重大安全威胁。

**Method:** 论文研究了一个多服务无人机（SUAV）的鲁棒MEC场景，以应对来自EUAV的潜在窃听，并考虑了任务复杂性等随机参数。问题被建模为优化SUAV的部署位置、地面用户（GU）与SUAV的连接关系以及卸载比。为了处理不确定的任务复杂性下的机会约束，首先使用K-means算法优化SUAV的预部署，然后采用分布鲁棒优化方法，并利用条件风险价值（CVaR）将机会约束转化为凸形式，通过凸优化工具包求解。

**Result:** 仿真结果表明，在考虑不确定性的情况下，与理想情况相比，仅多消耗5%的能量。

**Conclusion:** 所提出的算法在存在不确定性时仍能保持鲁棒性。

> **ai_Abstract:** 本文针对无人机辅助的多接入边缘计算（MEC）中空中窃听无人机（EUAV）带来的安全威胁，提出了一种鲁棒的任务卸载方案。该方案在考虑任务复杂性等不确定性参数的情况下，优化了服务无人机（SUAV）的部署、连接关系和卸载比。通过K-means算法进行预部署，并结合分布鲁棒优化和条件风险价值（CVaR）将机会约束转化为可解的凸形式。仿真结果验证了所提算法的鲁棒性，即使在不确定性下，能量消耗也仅略微增加。

> **摘要翻译:** 无人机（UAV）被认为是未来第六代通信网络中多接入边缘计算（MEC）的一个有前景的候选。然而，空中窃听无人机（EUAV）对数据卸载构成了重大的安全威胁。在本文中，我们研究了一个多服务无人机（SUAV）的鲁棒MEC场景，以应对来自EUAV的潜在窃听，其中考虑了实际应用中任务复杂性等随机参数。具体而言，该问题被表述为优化SUAV的部署位置、地面用户（GU）与SUAV的连接关系以及卸载比。针对不确定的任务复杂性，在不确定性集合下构建了相应的机会约束，这很难处理。因此，我们首先通过K-means算法优化SUAV的预部署。然后，采用分布鲁棒优化方法，并利用条件风险价值（CVaR）将机会约束转化为凸形式，可以通过凸工具包求解。最后，仿真结果表明，在考虑不确定性的情况下，与理想情况相比，仅多消耗5%的能量，这验证了所提出算法的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [5] [VTS-Guided AI Interaction Workflow for Business Insights](https://arxiv.org/abs/2507.00347)
> *VTS引导的AI交互工作流，用于商业洞察*

*Sun Ding, Ude Enebeli, Atilhan, Manay, Ryan Pua, Kamal Kotak* | **Category: cs.SE, cs.AI**

**Keywords:** 商业洞察, 视觉思维策略, AI代理, 非结构化数据, 自动化分析

**Comment:** 

> **TL;DR:** VTS-AI将视觉思维策略整合到AI代理中，能从非结构化报告中快速提取丰富的商业洞察，并允许人工干预。

**AI_Comments:** VTS-AI的创新之处在于其将人类认知策略（视觉思维策略）与AI技术相结合，以提高非结构化数据分析的质量和深度。它不仅关注效率，还通过保留人工判断环节来确保输出的可靠性和可调整性。其在测试中展现出比传统AI工具更丰富的结果，表明了其在商业洞察领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代企业面临大量密集、非结构化的报告，将其转化为可用洞察耗时且缺乏敏捷性，尤其在需要快速答案时。

**Method:** VTS-AI系统将视觉思维策略（强调基于证据的观察、链接和思考）整合到AI代理中，使其能从非结构化文本、表格和图像中大规模提取商业洞察。该系统分三层（微观、中观、宏观）工作，标记问题，将其链接到源页面，并将其整合为存储在可搜索YAML文件中的清晰行动杠杆。

**Result:** 在对一份18页商业报告的测试中，VTS-AI在速度上与一次性ChatGPT提示匹配，但产生了更丰富的结果，包括页面位置、原文摘录、严重性评分和因果链接。分析师可以在同一IDE中接受或调整这些输出，保持人工判断。早期结果显示VTS-AI能够识别关键指标的方向并指出需要更深入数据分析的地方。

**Conclusion:** VTS-AI是一个有前景的工具，能够从非结构化数据中快速提取丰富的商业洞察，并支持人工干预。未来的升级目标是使其成为一个生产就绪、审计友好的快速业务分析工具。

> **ai_Abstract:** VTS-AI是一个将视觉思维策略（VTS）融入AI代理的系统，旨在从非结构化商业报告中快速提取可操作的洞察。它通过三层架构识别问题、链接来源并生成可搜索的行动杠杆。测试显示，VTS-AI在速度上与ChatGPT相当，但提供了更丰富、更详细的分析结果，并允许人工干预。该系统旨在成为一个高效、可审计的业务分析工具，未来的升级将增强其财务分析能力和安全性。

> **摘要翻译:** 现代企业面临着大量密集的、非结构化的报告。将这些文档转化为可用的洞察需要大量的努力，并且在需要快速答案时远非敏捷。VTS-AI解决了这一差距。它将强调基于证据的观察、链接和思考的视觉思维策略整合到AI代理中，使代理能够从非结构化文本、表格和图像中大规模提取商业洞察。该系统分三层（微观、中观、宏观）工作。它标记问题，将它们链接到源页面，并将其整合为存储在可搜索YAML文件中的清晰行动杠杆。在对一份18页商业报告的测试中，VTS-AI的速度与一次性ChatGPT提示匹配，但产生了更丰富的结果：页面位置、原文摘录、严重性评分和因果链接。分析师可以在同一IDE中接受或调整这些输出，保持人工判断。早期结果显示VTS-AI能够发现关键指标的方向并指出需要更深入数据分析的地方。下一步包括将叙述标签映射到财务比率，通过模型-上下文协议添加针对财务优化的语言模型，并构建一个风险与安全层来对模型进行压力测试并保护数据。这些升级旨在使VTS-AI成为一个生产就绪、审计友好的快速业务分析工具。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [21] [An AST-guided LLM Approach for SVRF Code Synthesis](https://arxiv.org/abs/2507.00352)
> *一种基于AST引导的LLM SVRF代码合成方法*

*Abanoub E. Abdelmalak, Mohamed A. Elsayed, David Abercrombie, Ilhami Torunoglu* | **Category: cs.SE, cs.AI, cs.ET**

**Keywords:** SVRF, AST, LLM, 代码合成, RAG

**Comment:** 9 Pages, 5 Figures, 2 Tables

> **TL;DR:** 本文提出一种结合AST和RAG的LLM方法，用于SVRF代码合成，显著提高了代码生成准确性，解决传统SVRF开发面临的复杂性和专业知识鸿沟问题。

**AI_Comments:** 这篇论文通过结合AST和RAG，为SVRF代码合成提供了一个创新且实用的解决方案。其创新点在于将语法结构验证与领域知识检索相结合，有效弥补了大型语言模型在特定领域（如半导体设计规则）的专业性不足。40%的准确率提升是一个显著的进步，表明该方法在解决实际工程问题上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着半导体节点发展，设计规则日益复杂，导致传统SVRF开发效率低下并存在专业知识鸿沟，急需更有效的方法来合成SVRF代码。

**Method:** 本文提出一种新颖的方法，整合抽象语法树（AST）嵌入和检索增强生成（RAG），用于增强SVRF代码合成。该方法通过AST进行严格的结构验证，并利用RAG注入相关领域知识，以确保语义准确性和最小化错误。文中还评估了不同的T5模型，并提出了一个SVRF特有的评分框架来补充标准指标。

**Result:** 在包含740个DRC规则实现的综合基准测试中，与基本的基于文本的微调过程相比，该方法在代码生成准确性方面提高了高达40%。

**Conclusion:** 该方法将行业专业知识与先进编码策略融合，不仅优化了有限数据集约束下的SVRF开发，还创建了更直观高效的编码环境，使用户能够快速迭代设计周期，减少手动错误修正，显著提高整体生产力。

> **ai_Abstract:** 本文针对半导体SVRF代码合成中因复杂设计规则和专业知识鸿沟导致的传统开发效率低下问题，提出了一种新颖的AST引导的LLM方法。该方法结合抽象语法树（AST）嵌入和检索增强生成（RAG），通过AST进行结构验证和RAG注入领域知识，以确保SVRF代码的语义准确性和减少错误。在740个DRC规则实现的基准测试中，该方法比传统微调方法提高了高达40%的代码生成准确性，显著优化了SVRF开发并提高了生产力。

> **摘要翻译:** 标准验证规则格式（SVRF）对于半导体应用至关重要，例如设计规则检查（DRC）、版图与原理图比对（LVS）和光学邻近效应修正（OPC）。然而，随着先进节点创建复杂的设计规则，传统的SVRF开发变得低效并凸显了专业知识鸿沟，SVRF面临挑战。本文介绍了一种新颖的方法，整合抽象语法树（AST）嵌入和检索增强生成（RAG），以增强SVRF代码合成，通过结构验证和领域特定见解确保语义准确性和最小化错误，从而实现精确的代码生成。我们评估了不同的基于T5的模型，并提出了一个创新的SVRF专用评分框架，以补充BLEU和ROUGE-L等标准指标。在我们的方法中，AST提供严格的结构验证，而RAG则注入相关的领域知识，有效增强了代码生成工作流程。在包含740个DRC规则实现的综合基准测试中，我们的方法与基本的基于文本的微调过程相比，在代码生成准确性方面表现出高达40%的提升。这种将行业专业知识与先进编码策略融合的方法，不仅在有限数据集约束下优化了SVRF开发，还创建了更直观、高效的编码环境。因此，用户可以快速迭代设计周期，减少手动错误修正，并显著提高整体生产力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [41] [iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing](https://arxiv.org/abs/2507.00378)
> *iPanda：一种用于一致性测试的智能协议测试与调试代理*

*Xikai Sun, Fan Dang, Kebin Liu, Xin Miao, Zihao Yang, Haimo Lu, Yawen Zheng, Yunhao Liu* | **Category: cs.SE, cs.AI**

**Keywords:** 协议一致性测试, 大型语言模型, 自动化测试, 代码生成, 自校正

**Comment:** 14 pages, 6 figures

> **TL;DR:** iPanda是一个利用LLM自动化协议一致性测试的端到端框架，通过生成测试用例、代码和自校正机制，显著提高了测试代码生成成功率。

**AI_Comments:** iPanda的创新之处在于它是首个将LLM应用于端到端协议一致性测试的框架，其结合关键词生成、检索增强生成和迭代自校正的混合方法有效地提升了自动化测试的效率和准确性。特别是在代码生成方面，其表现显著优于纯LLM方法，展示了在复杂工程任务中集成LLM与其他技术的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的协议一致性测试方法需要手动创建大量测试用例和脚本，导致过程劳动密集且效率低下。

**Method:** iPanda是一个端到端框架，利用大型语言模型（LLMs）自动化协议一致性测试。它首先采用基于关键词的方法自动生成全面的测试用例；然后，利用基于代码的检索增强生成方法解释实现并生成可执行测试代码；为提高代码质量，iPanda引入了迭代自校正机制以交互式地优化生成的测试脚本；最后，通过执行和分析生成的测试，系统性地验证实现与协议规范之间的一致性。

**Result:** 综合实验表明，iPanda显著优于纯粹基于LLM的方法，将测试代码生成（Pass@1）的成功率提高了4.675倍至10.751倍。

**Conclusion:** iPanda成功地自动化了协议一致性测试过程，显著提高了测试代码的生成效率和质量。

> **ai_Abstract:** 本文提出了iPanda，一个利用大型语言模型（LLMs）自动化协议一致性测试的端到端框架。iPanda通过关键词生成测试用例、基于代码的检索增强生成技术生成可执行测试代码，并采用迭代自校正机制优化代码质量。实验证明，iPanda在测试代码生成成功率上显著优于纯LLM方法，提升了4.675到10.751倍，有效解决了传统手动测试的低效问题。

> **摘要翻译:** 一致性测试对于确保协议实现符合其规范至关重要。然而，传统的测试方法涉及手动创建大量测试用例和脚本，这使得过程劳动密集且效率低下。最近，大型语言模型（LLMs）展示了令人印象深刻的文本理解和代码生成能力，为自动化提供了有希望的机会。在本文中，我们提出了iPanda，这是第一个利用LLMs自动化协议一致性测试的端到端框架。给定协议规范文档及其实现，iPanda首先采用基于关键词的方法自动生成全面的测试用例。然后，它利用基于代码的检索增强生成方法有效地解释实现并生成可执行的测试代码。为了进一步提高代码质量，iPanda结合了迭代自校正机制，以交互方式优化生成的测试脚本。最后，通过执行和分析生成的测试，iPanda系统地验证了实现与协议规范之间的一致性。对各种协议进行的综合实验表明，iPanda显著优于纯粹基于LLM的方法，将测试代码生成（Pass@1）的成功率提高了4.675倍至10.751倍。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [63] [Recommending Variable Names for Extract Local Variable Refactorings](https://arxiv.org/abs/2507.00413)
> *为提取局部变量重构推荐变量名*

*Taiming Wang, Hui Liu, Yuxia Zhang, Yanjie Jiang* | **Category: cs.SE, D.2.7**

**Keywords:** 变量名推荐, 提取局部变量, 代码重构, 自动化, VarNamer

**Comment:** Accepted by TOSEM

> **TL;DR:** VarNamer是一种自动化方法，旨在为提取局部变量重构推荐变量名，它显著提高了变量名匹配的准确率，并被整合到Eclipse中，同时通过用户研究证明能加快重构速度并减少编辑量。

**AI_Comments:** 该论文的创新点在于它解决了开发者在进行“提取局部变量”重构时，现有IDE推荐的变量名不准确导致额外工作的问题。通过结合实证研究、静态分析和数据挖掘，VarNamer提供了一种更符合开发者习惯的自动化命名方案。其重要性体现在它不仅提出了理论方法，还将其部分规则成功集成到Eclipse中，证明了其实用性和工业价值。用户研究的结果也量化了其对开发效率的提升。该研究的通用性（在C++项目中的表现）是另一个亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的IDE和重构工具推荐的变量名与开发者手动构建的变量名有大约70%的不同，这增加了开发者的重命名负担并提供的帮助有限。

**Method:** 通过大规模实证研究识别了构建变量名的关键上下文；利用这些洞察力，通过程序静态分析技术开发了一套启发式规则，并采用数据挖掘技术有效推荐变量名。

**Result:** VarNamer相比Eclipse将精确匹配率提高了52.6%，相比IntelliJ IDEA提高了40.7%。在C++项目中的评估表明其在Java之外的编程语言上也能达到相当的性能。用户研究表明，该方法可以将重构速度提高27.8%，并减少49.3%的推荐变量名编辑量。

**Conclusion:** VarNamer是一种有效且可推广的自动化变量名推荐方法，它显著提升了提取局部变量重构的效率和准确性，并已成功集成到主流IDE中。

> **ai_Abstract:** 本文提出了一种名为VarNamer的自动化方法，用于在提取局部变量重构时推荐变量名。针对现有IDE推荐名与开发者习惯不符的问题，VarNamer通过识别关键上下文、结合静态分析和数据挖掘技术生成推荐。实验证明，VarNamer在提高变量名精确匹配率上显著优于Eclipse和IntelliJ IDEA，并展现出跨语言的通用性。此外，用户研究表明VarNamer能有效提升重构效率并减少手动编辑。部分启发式规则已集成至Eclipse。

> **摘要翻译:** 提取局部变量是最流行的重构之一，大多数IDE和重构工具都为此重构提供了自动化支持。然而，我们发现这些IDE推荐的大约70%的名称与开发者手动构建的名称不同，这增加了开发者的额外重命名负担并提供的帮助有限。在本文中，我们介绍了VarNamer，这是一种旨在为提取局部变量重构推荐变量名的自动化方法。通过大规模实证研究，我们确定了对构成变量名有用的关键上下文。利用这些见解，我们通过程序静态分析技术开发了一套启发式规则，并采用数据挖掘技术有效推荐变量名。值得注意的是，我们的一些启发式规则已成功集成到Eclipse中，并随IDE的最新版本发布。评估表明它优于最先进的IDE。具体来说，与Eclipse相比，VarNamer将精确匹配的机会显著提高了52.6%，与IntelliJ IDEA相比提高了40.7%。我们还通过在C++项目中进行的真实世界提取局部变量重构评估了所提出的方法，结果表明该方法除了Java之外的编程语言上也能达到相当的性能。这可能表明VarNamer的通用性。最后，我们设计并进行了一项用户研究，用户研究结果表明我们的方法可以将重构速度提高27.8%，并减少推荐变量名49.3%的编辑量。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [85] [Embedded DevOps: A Survey on the Application of DevOps Practices in Embedded Software and Firmware Development](https://arxiv.org/abs/2507.00421)
> *嵌入式DevOps：DevOps实践在嵌入式软件和固件开发中应用的调查*

*Parthiv Katapara, Anand Sharma* | **Category: cs.SE**

**Keywords:** 嵌入式DevOps, DevOps, 嵌入式系统, 持续集成, 持续交付

**Comment:** This paper present survey on DevOps practices which exists in
  Embedded Software development

> **TL;DR:** 本调查回顾了DevOps实践如何适应嵌入式系统和固件开发，探讨了其挑战、现有努力、局限性，并提出了未来的研究方向。

**AI_Comments:** 这篇论文通过对嵌入式DevOps实践的系统性综述，填补了该领域文献的空白，为理解DevOps在复杂嵌入式环境中的应用提供了宝贵的结构化视角。它不仅识别了现有实践，还明确指出了部署和可观测性等关键局限性，并为未来研究指明了方向，对于研究人员和从业者都具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于现代硬件-软件协同设计产品日益增长的复杂性，DevOps实践在嵌入式系统和固件开发中的应用应运而生。与云原生应用不同，嵌入式系统带来了硬件依赖、实时约束和安全关键要求等挑战。

**Method:** 本研究是一项文献综述，综合了来自20个学术和工业来源的发现，以审查DevOps原则（特别是持续集成、持续交付和自动化测试）如何适应嵌入式环境。研究将努力分为工具、测试策略、管道自动化和安全实践。

**Result:** 该综述强调了部署工作流和可观测性方面的当前局限性。研究将嵌入式DevOps的努力分为工具、测试策略、管道自动化和安全实践。

**Conclusion:** 本研究为研究人员和从业者提供了对嵌入式DevOps的综合理解，弥合了碎片化的文献，并提出了未来研究的路线图，特别是在部署工作流和可观测性方面。

> **ai_Abstract:** 本研究对嵌入式系统和固件开发中DevOps实践的应用进行了文献综述，旨在应对现代硬件-软件协同设计产品的日益复杂性及其特有挑战。通过分析20个来源，论文探讨了持续集成、持续交付和自动化测试等DevOps原则如何适应嵌入式环境，并将其努力分为工具、测试策略、管道自动化和安全实践。综述指出了当前在部署工作流和可观测性方面的局限性，并为未来的研究提出了路线图，为该领域的理解提供了结构化视角。

> **摘要翻译:** DevOps实践在嵌入式系统和固件开发中的应用正在兴起，以应对现代硬件-软件协同设计产品日益增长的复杂性。与云原生应用不同，嵌入式系统引入了硬件依赖、实时约束和安全关键要求等挑战。本文献综述综合了20个学术和工业来源的发现，以审查DevOps原则——特别是持续集成、持续交付和自动化测试——如何适应嵌入式环境。我们将努力分为工具、测试策略、管道自动化和安全实践。该综述强调了部署工作流和可观测性方面的当前局限性，并提出了未来研究的路线图。这项工作为研究人员和从业者提供了对嵌入式DevOps的综合理解，以结构化的视角弥合了碎片化的文献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [109] [The Influence of HEXACO Personality Traits on the Teamwork Quality in Software Teams -- A Preliminary Research Approach](https://arxiv.org/abs/2507.00481)
> *HEXACO人格特质对软件团队协作质量的影响——一项初步研究方法*

*Philipp M. Zähl, Sabine Theis, Martin R. Wolf* | **Category: cs.SE, cs.HC**

**Keywords:** HEXACO人格特质, 软件团队, 团队协作质量, 人为因素, 初步研究

**Comment:** 

> **TL;DR:** 本研究旨在设计一个测量HEXACO人格特质对软件团队协作质量影响的方案，并进行初步数据收集。结果表明，人格特质及其组成、女性比例和年龄分布对团队协作质量有显著影响，证明了研究设计的有效性。

**AI_Comments:** 这项初步研究强调了在软件工程中考虑人文因素，特别是人格特质和团队组成的重要性。它挑战了传统上过度关注流程和工具的观点，提出人格因素可能对软件开发效率产生更深远的影响。研究的创新之处在于将HEXACO人格模型应用于软件团队协作质量的分析，并提供了初步证据支持其有效性。尽管样本量较小（n=54），但其初步结果为未来更深入、更大规模的研究奠定了基础，并为IT组织优化团队构成提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管软件工程研究侧重于优化流程和技术，但人们日益认识到，人为因素，特别是团队协作，也显著影响优化。近期研究表明，开发人员的个性对团队协作有很强的影响，甚至可能比流程和工具的影响更大。因此，本文旨在设计一项研究来衡量HEXACO人格特质对软件团队协作质量（TWQ）的影响。

**Method:** 本研究旨在设计一个测量HEXACO人格特质对软件团队协作质量影响的方案。为此，进行了初步数据收集（n=54）。分析方法未具体说明，但结果表明对人格特质及其组成、女性比例和年龄分布进行了分析。

**Result:** 分析显示，几种人格特质及其组成对团队协作质量（TWQ）有显著影响。此外，其他变量，如女性比例和年龄分布，也影响了TWQ。研究的初步结果证明了研究设计的实用性和有效性。

**Conclusion:** 本研究的初步结果证明了所设计研究方案的实用性和有效性，并为IT组织改善团队协作提供了机会，也为未来的研究指明了方向。

> **ai_Abstract:** 本研究旨在探讨HEXACO人格特质对软件团队协作质量（TWQ）的影响。通过一项初步研究设计和对54名参与者的数据收集，发现人格特质及其组合、女性比例和年龄分布均对TWQ有显著影响。研究结果验证了研究设计的有效性，并为提升IT组织团队协作提供了潜在方向。

> **摘要翻译:** 尽管软件工程研究一直专注于优化流程和技术，但人们日益认识到，人为因素，尤其是团队协作，也显著影响优化。最近的研究表明，开发人员的个性对团队协作有很强的影响。事实上，个性因素对软件开发的影响可能比流程和工具更大。本文旨在设计一项研究，测量HEXACO人格特质对软件团队协作质量（TWQ）的影响。为此，进行了初步数据收集（n=54）。分析表明，几种人格特质及其组成对TWQ有显著影响。此外，其他变量，如女性比例和年龄分布，也影响了TWQ。这项研究的初步结果证明了研究设计的实用性和有效性。这些结果也为IT组织改善团队协作提供了若干机会，并为进一步研究指明了方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [133] [Coverage-Guided Testing for Deep Learning Models: A Comprehensive Survey](https://arxiv.org/abs/2507.00496)
> *深度学习模型的覆盖率引导测试：一项全面综述*

*Hongjing Guo, Chuanqi Tao, Zhiqiu Huang, Weiqin Zou* | **Category: cs.SE**

**Keywords:** 深度学习, 覆盖率引导测试, 软件质量保证, 综述, 测试输入生成

**Comment:** 

> **TL;DR:** 该论文全面综述了深度学习模型中覆盖率引导测试的最新方法、评估实践、开放挑战和未来方向，旨在为DL模型质量保证提供路线图。

**AI_Comments:** 这是一篇重要的综述性论文，因为它系统地整理了深度学习模型覆盖率引导测试领域的现有知识，填补了方法论碎片化的空白。它不仅提供了清晰的分类，还指出了未来的研究方向和实际部署挑战，对学术研究和工程实践都具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着深度学习模型在安全关键领域的广泛应用，确保其质量成为现代软件工程中的一个紧迫挑战。尽管覆盖率引导测试（CGT）作为一种识别错误或意外模型行为的系统框架日益受到关注，但现有研究在方法上仍然分散，限制了对当前进展和新兴趋势的理解。

**Method:** 本文通过对深度学习模型中最先进的覆盖率引导测试（CGT）方法进行全面回顾，包括测试覆盖率分析、覆盖率引导的测试输入生成和覆盖率引导的测试输入优化。它提供了详细的分类法，根据方法学特征和应用场景组织这些方法。同时，还调查了现有研究中采用的评估实践。

**Result:** 本文提供了详细的分类法来组织CGT方法，并调查了现有研究中采用的评估实践，包括基准数据集、模型架构和评估方面。最后，提出了开放挑战和未来方向，涉及结构覆盖率与测试目标之间的相关性、方法在任务和模型间的通用性、实际部署问题以及对标准化评估和工具支持的需求。

**Conclusion:** 本工作旨在为深度学习模型质量保证的未来学术研究和工程实践提供一份路线图。

> **ai_Abstract:** 本综述性论文全面探讨了深度学习模型中覆盖率引导测试（CGT）的最新进展。它旨在解决现有CGT研究方法分散的问题，通过对测试覆盖率分析、测试输入生成和优化等方法进行系统回顾，并构建详细的分类法。论文还分析了现有研究的评估实践，并指出了CGT领域的开放挑战和未来研究方向，旨在为DL模型质量保证提供清晰的路线图。

> **摘要翻译:** 随着深度学习（DL）模型在安全关键领域的日益广泛应用，确保其质量已成为现代软件工程中一个紧迫的挑战。在新兴的验证范式中，覆盖率引导测试（CGT）作为一种识别错误或意外模型行为的系统框架，已获得显著地位。尽管研究关注度不断增长，但现有的CGT研究在方法论上仍然分散，这限制了对当前进展和新兴趋势的理解。本工作通过全面回顾深度学习模型中最新的CGT方法来弥补这一空白，包括测试覆盖率分析、覆盖率引导的测试输入生成和覆盖率引导的测试输入优化。本工作提供了详细的分类法，根据方法学特征和应用场景来组织这些方法。我们还调查了现有研究中采用的评估实践，包括基准数据集、模型架构和评估方面的使用。最后，本文强调了开放挑战和未来方向，涉及结构覆盖率与测试目标之间的相关性、方法在任务和模型间的通用性、实际部署问题以及对标准化评估和工具支持的需求。本工作旨在为深度学习模型质量保证的未来学术研究和工程实践提供一份路线图。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [154] [A Domain-specific Language and Architecture for Detecting Process Activities from Sensor Streams in IoT](https://arxiv.org/abs/2507.00686)
> *物联网中用于从传感器流检测过程活动的领域特定语言和架构*

*Ronny Seiger, Daniel Locher, Marco Kaufmann, Aaron F. Kurz* | **Category: cs.SE, cs.ET**

**Keywords:** 物联网, 过程挖掘, 领域特定语言, 复杂事件处理, 传感器流

**Comment:** Submitted to Internet of Things (ISSN 2542-6605)

> **TL;DR:** 本文提出一种名为Radiant的领域特定语言（DSL）和相应的软件架构，用于将物联网（IoT）传感器流中的低级数据抽象为高级过程活动，并通过复杂事件处理（CEP）在智能制造和智能医疗领域进行评估。

**AI_Comments:** 本文的创新点在于引入了领域特定语言Radiant，使得领域专家能够直接参与到物联网低级传感器数据到高级业务过程活动的抽象过程中，降低了技术门槛。结合CEP技术实现了实时在线检测，具有重要的实践意义。该研究为物联网环境下的过程挖掘提供了新的工具和架构支持，特别是在智能制造和智能医疗等需要精细过程监控的领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现代物联网系统传感器数据过于细粒度，难以直接获得对大型过程执行的有用见解。将过程挖掘应用于物联网需要一个事件抽象步骤，将低级传感器数据提升到业务过程级别。

**Method:** 提出一种新的领域特定语言（DSL）Radiant，支持在传感器数据中指定模式以指示高级过程活动的执行。这些模式被转换为复杂事件处理（CEP）应用程序，用于在运行时检测活动执行。同时，提出一个相应的软件架构，用于使用CEP应用程序从物联网传感器流中进行在线事件抽象。

**Result:** 该方法在智能制造和智能医疗领域通过物联网传感器评估了活动执行的监控。评估结果向领域专家展示了活动检测的质量和潜在的改进空间。

**Conclusion:** 本文提出的DSL和架构能够有效地将物联网传感器数据抽象为高级过程活动，并为领域专家提供了评估和改进活动检测质量的工具。

> **ai_Abstract:** 本文提出了一种名为Radiant的领域特定语言（DSL）和相应的软件架构，旨在解决物联网（IoT）传感器数据过于细粒度，难以直接用于过程分析的问题。Radiant允许领域专家定义传感器数据中的模式，这些模式指示高级过程活动的发生。这些模式随后被转换为复杂事件处理（CEP）应用程序，用于实时从物联网传感器流中抽象并检测活动。该方法在智能制造和智能医疗领域得到了评估，结果表明其能有效监控活动执行，并为领域专家提供了关于检测质量和改进潜力的反馈。

> **摘要翻译:** 现代物联网（IoT）系统配备了大量传感器，提供有关其组件当前操作的实时数据，这对于系统的内部控制系统和流程至关重要。然而，这些数据往往过于细粒度，难以从中获得物联网系统可能参与的更大过程执行的有用见解。过程挖掘已经开发出用于业务流程分析的先进方法，这些方法也可以用于物联网环境。将过程挖掘引入物联网需要一个事件抽象步骤，将低级传感器数据提升到业务流程级别。在这项工作中，我们旨在通过新开发的领域特定语言（DSL）Radiant，赋能领域专家执行这一步骤。Radiant支持在传感器数据中指定模式，以指示更高级别过程活动的执行。这些模式被转换为复杂事件处理（CEP）应用程序，用于在运行时检测活动执行。我们提出了一种相应的软件架构，用于使用CEP应用程序从物联网传感器流中进行在线事件抽象。我们评估了这些应用程序，以在智能制造和智能医疗领域使用物联网传感器监控活动执行。评估方法和结果向领域专家提供了活动检测的质量和潜在改进空间的信息。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [175] [A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback](https://arxiv.org/abs/2507.00699)
> *一个用于细粒度代码指令遵循的分层可演化基准，具有多轮反馈*

*Guoliang Duan, Mingwei Liu, Yanlin Wang, Chong Wang, Xin Peng, Zibin Zheng* | **Category: cs.SE**

**Keywords:** 代码生成, 指令遵循, 基准测试, 大型语言模型, 多轮反馈

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在代码生成方面取得了显著进展，但其遵循复杂编程指令的能力仍未得到充分探索。MultiCodeIF是一个新的分层可演化基准，用于评估LLMs在多维度、多轮反馈下的代码指令遵循能力，揭示了性能差异并通过反馈实现了显著改进。

**AI_Comments:** 这篇论文通过引入MultiCodeIF基准，解决了LLM在代码生成领域评估中的一个关键空白，即超越单纯的功能正确性，深入到细粒度的、包含非功能性和分层约束的指令遵循能力。其多轮反馈机制尤为创新，模拟了真实世界的调试和迭代优化过程，这对于开发更健壮、更实用的代码LLM具有重要意义。自动化任务生成管道也保证了基准的可扩展性，使其成为推动代码LLM研究的重要工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的代码生成基准通常只优先考虑功能正确性，而忽视了真实世界开发中复杂的、分层的和多样化的细微指令要求，导致大型语言模型（LLMs）遵循复杂编程指令的能力未被充分探索。

**Method:** 研究人员引入了MultiCodeIF，这是一个综合性基准，旨在从约束类型、层次级别和迭代细化等多个维度评估代码生成中的指令遵循能力。该基准建立在包含9个类别和27种约束类型的结构化分类法之上，能够对功能性和非功能性指令遵循进行细粒度评估。通过一个名为ConstraGen的自动化管道，研究人员从14种编程语言中合成并演化出2021个代码任务，并通过反馈驱动的任务变体支持多轮评估。最后，对六个最先进的LLM进行了实证评估。

**Result:** 实证评估揭示了LLM之间存在显著的性能差异：表现最佳的模型Claude-3-7-Sonnet的平均约束满足率为63.0%，而较小的模型如Qwen3-1.7B则降至44.8%。模型在显式约束上表现良好，但在隐式或抽象约束上表现不佳。具有多个分层约束的任务显著降低了模型的成功率，从单层场景的54.5%降至多层场景的18.8%。然而，结构化反馈能够实现逐步改进：在四轮迭代细化后，平均约束满足率从63.0%上升到83.4%。

**Conclusion:** MultiCodeIF提供了一个可扩展、感知约束且对反馈敏感的框架，用于在现实代码生成场景下对大型语言模型进行基准测试，弥合了合成评估与真实世界指令复杂性之间的差距。

> **ai_Abstract:** MultiCodeIF是一个新颖的、分层可演化的基准，旨在评估大型语言模型（LLMs）遵循复杂、细粒度代码指令的能力，包括功能性和非功能性约束，并支持多轮反馈。该基准揭示了当前LLMs之间存在的显著性能差距，尤其是在处理隐式或多层次约束时，但也表明迭代反馈可以显著提高指令遵循的准确性。MultiCodeIF旨在提供一个更贴近实际的代码生成能力评估框架，弥合了现有合成评估与真实世界指令复杂性之间的鸿沟。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成方面取得了显著进展，但其遵循复杂编程指令（带有分层和多样化约束）的能力仍未得到充分探索。现有基准通常优先考虑功能正确性，忽视了真实世界开发中细微的要求。我们引入了MultiCodeIF，这是一个综合性基准，旨在从多个维度评估代码生成中的指令遵循能力：约束类型、层次级别和迭代细化。MultiCodeIF建立在包含9个类别和27种约束类型的结构化分类法之上，能够对功能性和非功能性指令遵循进行细粒度评估。我们使用自动化管道ConstraGen，合成并演化了来自14种编程语言的2021个代码任务，通过反馈驱动的任务变体支持多轮评估。对六个最先进的LLM进行的实证评估揭示了显著的性能差异。表现最佳的模型Claude-3-7-Sonnet的平均约束满足率为63.0%，而较小的模型如Qwen3-1.7B则降至44.8%。模型在显式约束上表现良好，但在隐式或抽象约束上表现不佳。具有多个分层约束的任务显著降低了模型的成功率，从单层场景的54.5%降至多层场景的18.8%。然而，结构化反馈能够实现逐步改进：在四轮迭代细化后，平均约束满足率从63.0%上升到83.4%。MultiCodeIF提供了一个可扩展、感知约束且对反馈敏感的框架，用于在现实代码生成场景下对LLM进行基准测试，弥合了合成评估与真实世界指令复杂性之间的差距。完整的基准数据集、评估管道和源代码可在https://github.com/SYSUSELab/MultiCodeIF获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [192] [Snaps: Bloated and Outdated?](https://arxiv.org/abs/2507.00786)
> *Snaps：臃肿且过时？*

*Jukka Ruohonen, Qusai Ramadan* | **Category: cs.SE**

**Keywords:** Snap, 软件打包, 软件包, 包管理器, Ubuntu

**Comment:** Submitted as a "poster paper" to APSEC

> **TL;DR:** 本研究通过实证观察发现，目前分发的Snap软件包平均而言在大小上是臃肿的，并且在更新频率上是过时的。

**AI_Comments:** 本文的创新之处在于通过实证数据证实了对Snap软件包的常见批评，即其臃肿和过时问题。其重要性在于为软件打包和分发领域提供了具体的、可量化的证据，有助于社区和开发者更好地理解和改进Snap系统。作为一篇短文，其深度可能有限，但为后续更深入的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Snap旨在提供跨Linux发行版的软件交付，但对其的担忧和批评频繁出现，促使研究人员调查这些批评的真实性。

**Method:** 本文通过对当前分发的Snap软件包进行实证观察和分析，评估了它们的包大小和更新频率。

**Result:** 研究结果表明，目前分发的Snap软件包平均而言在大小上是臃肿的，并且在更新频率上是过时的。

**Conclusion:** 本文通过实证观察，为软件打包、软件包和包管理器等研究领域提供了贡献，证实了对Snap的常见批评。

> **ai_Abstract:** 本研究旨在评估对Snap软件包的常见批评。通过对当前分发的Snap软件包进行实证分析，研究发现这些软件包平均而言在大小上是臃肿的，并且更新频率较低。这项工作为软件打包和包管理领域提供了经验性证据，证实了Snap在这些方面的不足。

> **摘要翻译:** Snap是由Canonical开发的一种替代软件打包系统，并在Ubuntu Linux发行版中默认提供。考虑到各种Linux发行版及其不同版本的异构性，Snap允许软件直接以可互操作的方式交付给用户。然而，担忧和批评也频繁出现。针对这些批评，本文表明当前分发的Snap软件包平均而言在大小上确实是臃肿的，并且在更新频率上是过时的。通过这些实证观察，这篇短文对软件打包、软件包和包管理器等研究领域做出了贡献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [211] [Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability](https://arxiv.org/abs/2507.00788)
> *AI的回响：探究AI助手对软件可维护性的下游影响*

*Markus Borg, Dave Hewett, Nadim Hagatulah, Noric Couderc, Emma Söderberg, Donald Graham, Uttam Kini, Dave Farley* | **Category: cs.SE, cs.AI**

**Keywords:** AI助手, 软件可维护性, 生产力, 代码健康度, 受控实验

**Comment:** Preprint of study preregistered at ICSME 2025 with In-Principal
  Acceptance.
  https://conf.researchr.org/track/icsme-2024/icsme-2024-registered-reports-track

> **TL;DR:** 研究发现AI助手能有效加速开发，且未观察到代码可维护性显著下降的警示信号，但在特定情况下可提升可维护性。

**AI_Comments:** 这项研究通过严格的对照实验，特别关注了AI助手对软件可维护性这一此前较少被深入探讨的下游影响，具有重要意义。其发现AI助手在提升生产力的同时，并未显著损害可维护性，甚至在特定用户群体中有所提升，为AI辅助开发的推广提供了更多实证支持。然而，研究也提出了“代码膨胀”和“认知债务”等潜在风险，为未来研究指明了方向，体现了审慎的科学态度。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究多关注AI助手对生产力的提升，但其对软件可维护性的影响，特别是其他开发者演进代码的难易程度，仍需深入研究。

**Method:** 本研究进行了一项两阶段对照实验，共151名参与者（95%为专业开发者）。第一阶段，参与者在有或没有AI助手的情况下，为Java web应用添加新功能。第二阶段，新的参与者在没有AI助手的情况下演进这些解决方案。

**Result:** AI辅助开发在后续演进中略微加速，平均CodeHealth略高。尽管整体差异不显著，但习惯性AI用户完成第一阶段时CodeHealth的提升具有统计学意义。AI助手使任务完成时间中位数减少30.7%，习惯性AI用户平均加速55.9%。

**Conclusion:** AI助手可以有效加速开发，且未观察到代码级可维护性下降的警示信号。建议未来研究关注过度代码生成导致的“代码膨胀”和开发者投入精力减少导致的“认知债务”等风险。

> **ai_Abstract:** 本研究通过一项包含151名专业开发者的两阶段实验，探究了AI助手（如GitHub Copilot）对软件开发生产力及代码可维护性的影响。结果显示，AI辅助开发显著缩短了任务完成时间，并对后续代码演进有轻微加速作用，且未观察到代码可维护性显著下降的迹象。研究强调AI助手能有效加速开发，并建议未来关注代码膨胀和认知债务等潜在风险。

> **摘要翻译:** [背景] 像GitHub Copilot和Cursor这样的AI助手正在改变软件工程。虽然多项研究强调了生产力的提升，但它们对可维护性的影响需要进一步调查。
[目标] 本研究调查与AI助手共同开发是否影响软件可维护性，特别是其他开发者演进所生成源代码的难易程度。
[方法] 我们进行了一项两阶段的对照实验，涉及151名参与者，其中95%是专业开发者。在第一阶段，参与者在有或没有AI助手的情况下，向一个Java web应用程序添加新功能。在第二阶段，通过一项随机对照试验，新的参与者在没有AI助手的情况下演进这些解决方案。
[结果] 第一阶段的AI辅助开发导致后续演进速度适度加快，并且平均CodeHealth略高。尽管总体上差异都不显著，但当习惯性AI用户完成第一阶段时，CodeHealth的增加具有统计学意义。对于第一阶段，我们还观察到一个显著效果，证实了先前的生产力发现：使用AI助手使任务完成时间中位数减少了30.7%。此外，对于习惯性AI用户，平均加速达到了55.9%。
[结论] 我们的研究增加了越来越多的证据，表明AI助手可以有效加速开发。此外，我们没有观察到代码级可维护性下降的警示信号。我们建议未来的研究应关注诸如过度代码生成导致的“代码膨胀”以及开发者在实现过程中投入更少心力导致的“认知债务”等风险。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [224] [Out of the Day Job: Perspectives of Industry Practitioners in Co-Design and Delivery of Software Engineering Courses](https://arxiv.org/abs/2507.00803)
> *走出日常工作：行业从业者在软件工程课程协同设计与交付中的视角*

*Gillian Daniel, Chris Hall, Per Hammer, Alec-Angus Macdonald, Hollie Marwick-Best, Emma McKenzie, George Popa, Derek Somerville, Tim Storer* | **Category: cs.SE**

**Keywords:** 软件工程, 行业合作, 课程协同设计, 从业者视角, 学术界-工业界合作

**Comment:** 

> **TL;DR:** 本研究探讨了行业从业者在软件工程课程协同设计和交付中的视角，旨在通过回顾性研究了解他们的动机、期望和经验，并提出未来合作的建议，以促进学术界与工业界合作的长期可持续性。

**AI_Comments:** 该论文解决了学术界与工业界合作中一个关键但研究不足的方面：行业从业者的视角。这对于此类伙伴关系的长期可持续性和有效性至关重要。通过对共同作者进行回顾性研究的方法，提供了一种实用的方式来收集这些宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献较少关注参与课程设计和交付的行业从业者的视角。由于从业者投入的精力巨大，了解他们的动机、期望和经验对于指导未来合作的形成和确保其长期可持续性至关重要。

**Method:** 本研究通过对论文的行业从业者共同作者进行回顾性研究来解决这一空白，由学术界共同作者担任协调人。研究明确关注了从业者的视角，并报告了讨论中出现的主题和由此产生的未来合作建议。

**Result:** 研究报告了讨论中出现的主题，并提出了针对未来合作的建议。

**Conclusion:** 本研究通过揭示行业从业者的视角，为指导未来学术界与工业界的合作提供了见解，有助于确保这些合作的长期可持续性。

> **ai_Abstract:** 本论文探讨了行业从业者在软件工程课程协同设计和交付中的视角。通过对参与课程的行业从业者共同作者进行回顾性研究，本研究旨在弥补现有文献中对这一重要群体视角关注不足的空白。研究识别了讨论中出现的主题，并基于这些发现提出了针对未来学术界与工业界合作的建议，以期增强合作的有效性和可持续性。

> **摘要翻译:** 二十多年来，格拉斯哥大学与行业合作伙伴共同设计并交付了众多以软件工程为重点的课程，涵盖了技术和学科特定的专业技能。此类合作并非独一无二，其许多益处已在文献中得到广泛认可。这些益处包括提高课程的现实相关性，在学生毕业前建立专业人脉网络，以及为雇主提供更便捷的招聘机会。
然而，关于参与课程设计和交付的行业从业者视角的学术研究相对较少。这一空白意义重大，因为从业者投入的精力通常是巨大的，并且可能需要行业合作伙伴和学术机构的持续支持。了解参与课程交付的从业者的动机、期望和经验可以指导未来伙伴关系的形成并确保其长期可持续性。
我们通过报告本论文的从业者共同作者之间进行的回顾性研究结果来开始弥补这一空白，由学术界共同作者担任协调人。所有共同作者都参与了近期软件工程课程的协同设计和交付，但我们选择明确关注从业者的视角。我们报告了讨论中出现的主题以及我们对未来合作的建议。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [7] [Evolutionary Dynamics with Self-Interaction Learning in Networked Systems](https://arxiv.org/abs/2507.00422)
> *网络系统中具有自交互学习的演化动力学*

*Ziyan Zeng, Minyu Feng, Attila Szolnoki* | **Category: cs.SI, physics.soc-ph**

**Keywords:** 演化动力学, 自交互学习, 网络系统, 合作演化, 自交互景观

**Comment:** 15 pages, 10 figures

> **TL;DR:** 研究发现，在网络演化动力学中引入适当的自交互学习可以促进合作的演化并保护合作者。

**AI_Comments:** 这篇论文通过引入“自交互学习”的概念，为理解网络中的合作演化提供了一个新视角。其创新点在于提出了“自交互景观”这一工具来量化并分析个体策略的自我坚持。研究结果表明自交互对于促进合作和保护合作者具有重要作用，这对于设计更鲁棒的社会或多智能体系统具有潜在的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解网络系统中合作的演化对于分析社会网络、多智能体系统和生物物种的动力学至关重要。现实世界中，个体策略的自我坚持很常见，而策略的自我替换能形成选择放大器，帮助网络系统避免完全背叛。

**Method:** 本文研究了网络演化动力学中的自交互学习。提出了一种自交互景观来捕捉基于局部拓扑复制策略的智能体自循环强度。

**Result:** 发现适当的自交互可以降低合作的条件，并帮助合作者在系统中获胜。对于有利于恶意演化的系统，自交互可以保护合作智能体免受伤害。在随机网络上的结果表明，适当的自交互景观可以显著降低有利突变体的临界条件，特别是对于大度网络。

**Conclusion:** 自交互学习在网络演化动力学中扮演着关键角色，能够促进合作的演化并增强系统的鲁棒性，甚至在不利条件下也能保护合作行为。

> **ai_Abstract:** 这项研究探讨了网络演化动力学中自交互学习的作用。通过引入并分析一种自交互景观，研究发现适当的自交互能够显著促进合作的演化，降低合作发生的条件，并在面对恶意行为时保护合作者。此外，研究还表明自交互可以降低有利突变体在随机网络中扩散的临界条件，尤其在大度网络中效果更为显著。

> **摘要翻译:** 网络系统中合作的演化有助于理解社会网络、多智能体系统和生物物种的动力学。个体策略的自我坚持在现实世界的决策中很常见。演化动力学中策略的自我替换形成了一个选择放大器，允许智能体坚持其自体策略，并帮助网络系统避免完全背叛。在本文中，我们研究了网络演化动力学中的自交互学习。我们提出了一种自交互景观来捕捉智能体自循环的强度，以基于局部拓扑复制策略。我们发现适当的自交互可以降低合作的条件，并帮助合作者在系统中获胜。对于一个有利于恶意演化的系统，自交互可以保护合作智能体免受伤害。我们在随机网络上的结果进一步表明，适当的自交互景观可以显著降低有利突变体的临界条件，特别是对于大度网络。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [23] [A Practical Guide to Interpretable Role-Based Clustering in Multi-Layer Financial Networks](https://arxiv.org/abs/2507.00600)
> *多层金融网络中可解释的基于角色聚类的实用指南*

*Christian Franssen, Iman van Lelyveld, Bernd Heidergott* | **Category: cs.SI, cs.LG**

**Keywords:** 金融网络, 基于角色聚类, 可解释性, 多层网络, 机构角色

**Comment:** 

> **TL;DR:** 本文提出了一种可解释的基于角色的多层金融网络聚类方法，用于识别金融机构的功能角色，并通过欧洲央行货币市场统计报告数据验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了一个可解释的、基于角色的多层金融网络聚类方法，解决了理解复杂金融网络中机构功能角色的挑战。其价值在于为金融监管和风险评估提供了新的工具，特别是通过构建可解释的节点嵌入，增强了结果的透明度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 理解金融机构在互联市场中的功能角色对于有效的监管、系统性风险评估和解决规划至关重要。

**Method:** 该方法遵循一个由邻近度量、聚类评估标准和算法选择定义的通用聚类框架。它构建了基于egonet特征的可解释节点嵌入，这些特征捕获了市场层内部和跨层直接及间接的交易关系。

**Result:** 该方法揭示了异构的机构角色，例如市场中介、跨部门连接器以及外围贷方或借方。结果突出了基于角色聚类在分析金融网络和理解复杂市场结构中机构行为的灵活性和实用价值。

**Conclusion:** 基于角色的聚类方法在分析金融网络和理解复杂市场结构中的机构行为方面具有灵活性和实用价值。

> **ai_Abstract:** 本文提出了一种针对多层金融网络的可解释的基于角色聚类方法，旨在识别金融机构在不同市场细分中的功能角色。该方法基于一个通用聚类框架，利用egonet特征构建可解释的节点嵌入，以捕捉复杂的交易关系。通过欧洲央行MMSR的交易数据验证，该方法成功揭示了如市场中介、跨部门连接器和外围贷借方等多种机构角色，展示了其在金融网络分析中的实用价值和灵活性。

> **摘要翻译:** 理解金融机构在互联市场中的功能角色对于有效的监管、系统性风险评估和解决规划至关重要。我们提出了一种可解释的基于角色的多层金融网络聚类方法，旨在识别机构在不同市场细分中的功能位置。我们的方法遵循一个由邻近度量、聚类评估标准和算法选择定义的通用聚类框架。我们构建了基于egonet特征的可解释节点嵌入，这些特征捕获了市场层内部和跨层直接和间接的交易关系。使用欧洲央行货币市场统计报告（MMSR）的交易级别数据，我们展示了该方法如何揭示异构的机构角色，例如市场中介、跨部门连接器以及外围贷方或借方。结果突出了基于角色聚类在分析金融网络和理解复杂市场结构中机构行为的灵活性和实用价值。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [43] [Gender Differences in International Research Collaboration in European Union](https://arxiv.org/abs/2507.00619)
> *欧盟国际研究合作中的性别差异*

*Elsa Fontainha, Tanya Araújo* | **Category: cs.SI**

**Keywords:** 国际研究合作, 性别差异, 欧盟, 合著网络, COVID-19

**Comment:** 29 pages, 10 figures

> **TL;DR:** 研究揭示了2011-2022年欧盟国际研究合作中的性别差异，女性作者的文章较少，且女性主导的合作网络更中心化。

**AI_Comments:** 这篇论文通过实证数据和网络科学方法，深入揭示了国际研究合作中存在的性别差异，特别是对女性研究者合作模式的洞察（如更中心化的网络）。其创新之处在于结合了性别、地域和疫情影响等多维度分析，为理解和促进科研领域的性别平等提供了重要依据。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在调查2011年至2022年欧盟（EU）国家间的国际研究合作（IRC），并重点关注基于性别的作者模式。

**Method:** 研究从Web of Science社会科学引文索引（WoS-SSCI）数据库构建了一个大型国际研究合作文章数据集，并根据性别、作者单位和COVID-19主题对作者类别进行了标注。研究利用网络科学方法绘制了合作结构。

**Result:** 国际研究合作在过去十年中显著增加，特别是与美国和中国。至少有一名女性作者的文章始终少于至少有一名男性作者的文章。纯女性合作显示出独特的网络拓扑结构，具有更中心化（星状）的模式和更短的树直径。COVID-19大流行暂时缩小了IRC中的性别差距，但也揭示了女性主导研究网络中的脆弱性。

**Conclusion:** 欧盟参与国际研究合作的性别动态既有进步，也存在持续的差异。

> **ai_Abstract:** 本文利用Web of Science数据，分析了2011-2022年欧盟国际研究合作中的性别差异。研究发现，虽然国际合作普遍增长，但女性作者的文章数量少于男性。女性专属的合作网络更中心化。COVID-19疫情暂时缩小了性别差距，但也揭示了女性主导网络的脆弱性。研究强调了欧盟国际研究合作中性别动态的进步与持续差距。

> **摘要翻译:** 本文调查了2011年至2022年欧盟（EU）国家间的国际研究合作（IRC），重点关注基于性别的作者模式。研究从Web of Science社会科学引文索引（WoS-SSCI）数据库中提取数据，构建了一个大型IRC文章数据集，并根据性别、作者单位和COVID-19主题对作者类别进行了标注。研究利用网络科学，绘制了合作结构，并揭示了合著网络中的性别差异。结果表明，在过去十年中，IRC显著增加，特别是与美国和中国这两个主要的非欧盟合作伙伴。至少有一名女性作者的文章始终少于至少有一名男性作者的文章。值得注意的是，纯女性合作显示出独特的网络拓扑结构，具有更中心化（星状）的模式和更短的树直径。COVID-19大流行进一步重塑了合作动态，暂时缩小了IRC中的性别差距，但也揭示了女性主导研究网络中的脆弱性。这些发现强调了欧盟参与IRC的性别动态既有进步，也存在持续的差异。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [9] [Plan-Based Scalable Online Virtual Network Embedding](https://arxiv.org/abs/2507.00237)
> *基于计划的可扩展在线虚拟网络嵌入*

*Oleg Kolosov, David Breitgand, Dean H. Lorenz, Gala Yadgar* | **Category: cs.NI**

**Keywords:** 虚拟网络嵌入, 在线VNE, 边缘计算, 可扩展性, OLIVE

**Comment:** Accepted to IEEE ICDCS 2025

> **TL;DR:** 该论文提出了一种名为OLIVE的新型在线虚拟网络嵌入（VNE）算法，它利用离线计算的计划来处理在线请求，显著提高了吞吐量，使其适用于边缘环境。

**AI_Comments:** 该论文的创新之处在于其“基于计划”的方法，将离线优化与在线动态适应相结合。这种混合策略有效地解决了在线VNE的扩展性挑战，这对于动态边缘计算环境至关重要。所实现的两个数量级的性能提升具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 网络虚拟化允许在共享边缘基础设施上托管具有不同计算和通信要求的应用程序。虚拟网络嵌入（VNE）问题是其核心挑战，但所有VNE变体都是NP-hard问题。现有的在线VNE解决方案在处理每秒大量请求和大型物理拓扑时扩展性不佳，这与边缘环境固有的高度倾斜和不可预测的需求不符。

**Method:** 本文提出了一种名为OLIVE的新型在线算法。OLIVE利用离线计算的聚合预期需求的近似最优嵌入作为计划。该计划指导OLIVE处理实际的单个请求，同时动态补偿与计划的偏差。

**Result:** 该解决方案（OLIVE）能够处理的每秒请求数量比文献中报道的最佳结果高出两个数量级。

**Conclusion:** OLIVE为在线虚拟网络嵌入提供了一个高度可扩展的解决方案，使其特别适用于具有不可预测和高需求的现实边缘环境。

> **ai_Abstract:** 该论文解决了在线虚拟网络嵌入（VNE）的扩展性问题，这是一个在共享边缘基础设施上部署虚拟化应用程序的关键NP-hard问题。鉴于现有在线VNE解决方案在高请求率和大型物理网络下表现不佳，作者提出了OLIVE，一种新型在线算法。OLIVE利用离线计算的、基于聚合预期需求的近似最优嵌入计划，指导其动态处理单个在线请求。实验证明，OLIVE的每秒请求处理能力比现有最佳方法高出两个数量级，使其非常适合现实世界的边缘环境。

> **摘要翻译:** 网络虚拟化允许在共享边缘基础设施上托管具有不同计算和通信需求的应用程序。给定一组部署虚拟化应用程序的请求，边缘提供商必须将最大数量的应用程序部署到底层物理网络，同时受容量限制。这一挑战被称为虚拟网络嵌入（VNE）问题：它将应用程序建模为虚拟网络，其中虚拟节点代表功能，虚拟链接代表虚拟节点之间的通信。
所有VNE变体都被认为是强NP-hard问题。由于其在网络虚拟化中的核心地位，VNE已被广泛研究。我们关注VNE的在线变体，其中部署请求不是预先知道的。这反映了边缘固有的高度倾斜和不可预测的需求。不幸的是，现有的在线VNE解决方案在每秒请求数量和物理拓扑规模方面扩展性不佳。
我们提出了一种新颖的方法，其中我们的新在线算法OLIVE利用针对聚合预期需求的近似最优嵌入。这种嵌入是离线计算的。它作为一个计划，OLIVE将其作为指导来处理实际的单个请求，同时动态补偿与计划的偏差。我们证明，我们的解决方案可以处理的每秒请求数量比文献中报道的最佳结果高出两个数量级。因此，它特别适用于现实的边缘环境。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [25] [Seeing Through the Fog: Empowering Mobile Devices to Expose and Mitigate RAN Buffer Effects on Delay-Sensitive Protocols](https://arxiv.org/abs/2507.00337)
> *拨开迷雾：赋能移动设备揭示和缓解RAN缓冲区对延迟敏感协议的影响*

*Yuxin Liu, Tianyang Zhang, Qiang Wu, Ju Ren, Kyle Jamieson, Yaxiong Xie* | **Category: cs.NI**

**Keywords:** RAN缓冲区, 延迟敏感协议, 蜂窝网络, 性能提升, CellNinjia, Gandalf

**Comment:** 

> **TL;DR:** 本文提出了CellNinjia和Gandalf系统，使移动设备能够识别并补偿蜂窝网络中无线接入网（RAN）缓冲区引入的延迟，从而显著提升基于延迟的协议性能。

**AI_Comments:** 该论文的创新之处在于其对RAN缓冲区引入的非拥塞相关延迟的深入识别和系统性处理，而非简单地将其视为随机噪声。通过CellNinjia提供实时可见性并由Gandalf进行精确补偿，该方法为基于延迟的协议在复杂的蜂窝网络环境中实现其全部潜力开辟了新途径，对于提升移动网络的用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于延迟的协议在蜂窝网络中表现不佳，因为无线接入网（RAN）缓冲区会引入与拥塞无关的显著延迟，这与这些协议的假设相悖。研究发现重传缓冲区和上行调度缓冲区会引入与拥塞相当的延迟，严重降低协议性能。

**Method:** 本文提出了CellNinjia，一个提供RAN操作实时可见性的软件系统，以及Gandalf，它利用这种可见性系统地处理RAN引起的延迟。与现有方法将这些延迟视为随机噪声不同，Gandalf识别特定的RAN操作并补偿其影响。

**Result:** 在商用4G LTE和5G网络中的评估显示，Gandalf在不修改协议核心算法的情况下，使性能得到了显著提升——Copa协议提升高达7.49倍，PCC Vivace协议提升高达9.53倍。

**Conclusion:** Gandalf证明了基于延迟的协议可以在蜂窝网络中充分发挥其潜力，通过识别和补偿RAN缓冲区引入的延迟，显著提升了协议性能。

> **ai_Abstract:** 本文针对蜂窝网络中RAN缓冲区对基于延迟协议性能的影响问题，提出了CellNinjia和Gandalf两个系统。CellNinjia提供RAN操作的实时可见性，而Gandalf则利用此可见性识别并补偿RAN引起的延迟，而非将其视为随机噪声。在4G LTE和5G网络中的评估表明，该方法在不修改现有协议核心算法的情况下，显著提升了Copa和PCC Vivace等基于延迟协议的性能，证明了它们在蜂窝网络中的潜力。

> **摘要翻译:** 基于延迟的协议依赖于端到端延迟测量来检测网络拥塞。然而，在蜂窝网络中，无线接入网（RAN）缓冲区引入了与拥塞无关的显著延迟，这从根本上挑战了这些协议的假设。我们识别出两种主要的RAN缓冲区——重传缓冲区和上行调度缓冲区——它们可以引入与拥塞引起的延迟相当的延迟，严重降低协议性能。我们提出了CellNinjia，一个提供RAN操作实时可见性的软件系统，以及Gandalf，它利用这种可见性系统地处理RAN引起的延迟。与现有方法将这些延迟视为随机噪声不同，Gandalf识别特定的RAN操作并补偿其影响。我们在商用4G LTE和5G网络中的评估显示，Gandalf在不修改协议核心算法的情况下，实现了显著的性能提升——Copa协议提升高达7.49倍，PCC Vivace协议提升高达9.53倍——这表明基于延迟的协议可以在蜂窝网络中充分发挥其潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [45] [Remote Rendering for Virtual Reality: performance comparison of multimedia frameworks and protocols](https://arxiv.org/abs/2507.00623)
> *虚拟现实的远程渲染：多媒体框架与协议的性能比较*

*Daniel Mejías, Inhar Yeregui, Roberto Viola, Miguel Fernández, Mario Montagud* | **Category: cs.NI**

**Keywords:** 远程渲染, XR, 多媒体框架, 流媒体协议, 性能比较

**Comment:** 

> **TL;DR:** 本文比较了在Wi-Fi和5G网络环境下，使用GStreamer和FFmpeg多媒体框架，通过不同流媒体协议（如WebRTC、DASH和基于QUIC的协议）进行虚拟现实远程渲染的性能。

**AI_Comments:** 本文通过集成主流多媒体框架和新兴协议，为XR远程渲染性能评估提供了一个先进的测试平台，具有创新性。它关注了实际应用中轻量级设备面临的挑战，并探索了通过远程渲染解决这些问题的方法。虽然摘要中未明确提及具体性能结果，但其构建的测试平台本身就是一项重要贡献，为未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 增强现实（XR）应用的日益复杂性要求强大的处理能力和高带宽通信，而这些能力通常是轻量级设备所不具备的。远程渲染可以将处理任务卸载到拥有强大GPU的远程节点，以解决此问题。

**Method:** 本研究描述了将GStreamer和FFmpeg这两个最流行的多媒体框架与一个作为远程渲染器的渲染引擎进行集成，并分析了它们在通过Wi-Fi或5G网络向终端设备提供不同协议（如WebRTC、DASH和基于QUIC的协议）传输渲染内容时的性能。

**Result:** Not mentioned in abstract

**Conclusion:** 该解决方案构成了一个超越现有技术水平的测试平台，可用于在XR领域进行前沿研究。

> **ai_Abstract:** 本研究探讨了虚拟现实远程渲染的性能，以解决轻量级XR设备处理能力和带宽不足的问题。论文详细介绍了如何将GStreamer和FFmpeg两大主流多媒体框架与远程渲染引擎集成，并评估了它们在使用WebRTC、DASH以及新兴的基于QUIC的协议在Wi-Fi和5G网络环境下传输渲染内容的性能。这项工作为XR领域的前沿研究提供了一个先进的测试平台。

> **摘要翻译:** 扩展现实（XR）应用日益增长的复杂性要求大量的处理能力和高带宽通信，而这些能力通常在轻量级设备上是不可用的。远程渲染包括将处理任务卸载到具有强大GPU的远程节点，并将渲染内容传输到终端设备。内容传输通常通过流行的流媒体协议进行，例如提供交互数据通道的Web实时通信（WebRTC），或更适合可扩展性的基于HTTP的动态自适应流（DASH）。此外，基于QUIC的新流媒体协议正在作为WebRTC和DASH的潜在替代方案出现，并提供连接迁移、流多路复用和多路径传输等优势。这项工作描述了GStreamer和FFmpeg这两个最流行的多媒体框架与一个充当远程渲染器的渲染引擎的集成，并分析了它们在通过WIFI或5G网络向终端设备提供不同协议传输渲染内容时的性能。该解决方案构成了一个超越现有技术水平的测试平台，可用于在XR领域进行前沿研究。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [65] [Toward Edge General Intelligence with Multiple-Large Language Model (Multi-LLM): Architecture, Trust, and Orchestration](https://arxiv.org/abs/2507.00672)
> *迈向边缘通用智能：多大型语言模型（Multi-LLM）的架构、信任与编排*

*Haoxiang Luo, Yinqiu Liu, Ruichen Zhang, Jiacheng Wang, Gang Sun, Dusit Niyato, Hongfang Yu, Zehui Xiong, Xianbin Wang, Xuemin Shen* | **Category: cs.NI, cs.DC**

**Keywords:** 多大型语言模型, 边缘计算, 编排, 信任, 多模态AI

**Comment:** 

> **TL;DR:** 本综述探讨了在边缘计算中集成多大型语言模型（Multi-LLM）以提升边缘AI的通用智能，重点关注其架构、信任和编排。

**AI_Comments:** 本综述具有高度的前瞻性和创新性，将大型语言模型与边缘计算深度融合，提出了多LLM协作以实现边缘通用智能的新范式。其对架构设计、信任机制和系统编排的全面探讨，特别是对多模态和可信赖系统的关注，为解决边缘AI面临的复杂挑战提供了重要的理论框架和实践指导，对相关领域的研究和发展具有显著推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统边缘AI模型在处理需要高级推理和多模态数据处理的复杂动态任务时表现不足，因此需要探索集成多大型语言模型（Multi-LLM）来提升边缘计算中的任务性能和适应性。

**Method:** 本综述探讨了在边缘计算中集成多大型语言模型（Multi-LLM）以应对复杂、动态任务。文章回顾了从传统边缘AI模型到单LLM部署，最终到多LLM系统的演变，并讨论了动态编排、资源调度和跨域知识转移等关键使能技术。

**Result:** 本综述探讨了多LLM系统如何增强资源受限环境下的任务性能和适应性。文章重点关注可信赖的多LLM系统，以确保在可靠性和隐私至关重要的环境中做出稳健的决策，并提出了多模态多LLM架构，通过整合处理不同数据模态（如文本、图像、音频）的LLM输出进行综合分析。

**Conclusion:** 本综述展望了多LLM系统在边缘计算中的未来发展方向，包括提高资源效率、实现可信治理，并解决隐私、信任和鲁棒性问题。该研究为旨在利用边缘计算中多LLM系统的研究人员和从业者提供了宝贵的参考。

> **ai_Abstract:** 这篇综述深入探讨了在边缘计算中集成多大型语言模型（Multi-LLM）以克服传统AI模型在处理复杂、动态和多模态任务时的局限性。文章回顾了边缘AI从传统模型到单LLM再到多LLM系统的演进，并详细讨论了实现多LLM的关键技术，如动态编排、资源调度和跨域知识转移。研究尤其强调了构建可信赖的多LLM系统和多模态架构的重要性。最后，综述指出了未来在资源效率、可信赖治理、隐私、信任和鲁棒性方面的研究方向，为边缘计算中多LLM系统的应用提供了全面的指导。

> **摘要翻译:** 边缘计算使数据处理更接近数据源，从而提高了边缘AI应用的延迟和性能。然而，传统AI模型在处理需要高级推理和多模态数据处理的复杂动态任务时往往力不从心。本综述探讨了多大型语言模型（Multi-LLM）在边缘计算中的集成，其中多个专业LLM协同工作，以提高资源受限环境中的任务性能和适应性。我们回顾了从传统边缘AI模型到单一LLM部署，最终到多LLM系统的转变。本综述讨论了动态编排、资源调度和跨域知识转移等关键使能技术，这些技术对于多LLM的实现至关重要。一个核心焦点是可信赖的多LLM系统，确保在可靠性和隐私至关重要的环境中做出稳健的决策。我们还提出了多模态多LLM架构，其中多个LLM专门处理不同的数据模态，如文本、图像和音频，通过整合它们的输出来进行全面分析。最后，我们强调了未来的方向，包括提高资源效率、可信治理多LLM系统，同时解决隐私、信任和鲁棒性问题。本综述为旨在利用边缘计算应用中多LLM系统的研究人员和从业者提供了宝贵的参考。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [87] [Enhancing Vehicular Platooning with Wireless Federated Learning: A Resource-Aware Control Framework](https://arxiv.org/abs/2507.00856)
> *增强车辆队列与无线联邦学习：一个资源感知控制框架*

*Beining Wu, Jun Huang, Qiang Duan, Liang Dong, Zhipeng Cai* | **Category: cs.NI, eess.SP**

**Keywords:** 车辆队列, 无线联邦学习, 资源感知控制, 信息适龄性, 深度强化学习

**Comment:** Under review at IEEE Transactions on Networking

> **TL;DR:** 该研究提出一个资源感知控制框架（RACE），通过结合联邦学习和深度强化学习，优化车辆队列在动态环境下的信息交换和模型同步，显著提升了信息适龄性和学习收敛性。

**AI_Comments:** 本文的创新点在于提出了一个结合联邦学习和深度强化学习的两阶段资源感知控制框架（RACE），以解决车辆队列在动态环境下通信和资源受限的问题。特别地，它同时考虑了信息适龄性（AoI）和联邦学习模型漂移（FLMD），并通过结合多头自注意力与LSTM捕获时空相关性，展现了其在复杂环境下的有效性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 在高度动态环境中，车辆队列面临频繁的通信变化和资源限制，这严重影响信息交换和学习模型同步。

**Method:** 1. 将无线联邦学习（WFL）在车辆队列（VP）中的应用表述为一个联合优化问题，同时考虑信息适龄性（AoI）和联邦学习模型漂移（FLMD）。2. 提出一个两阶段的资源感知控制框架（RACE）：第一阶段使用拉格朗日对偶分解进行资源配置；第二阶段采用多智能体深度强化学习方法进行车辆选择。3. 该方法整合了多头自注意力机制和长短期记忆网络来捕获通信状态的时空相关性。

**Result:** 实验结果表明，与基线方法相比，所提出的框架将信息适龄性（AoI）优化提高了高达45%，加速了学习收敛，并且在AI4MARS数据集上更有效地适应动态的车辆队列环境。

**Conclusion:** 所提出的资源感知控制框架（RACE）能够显著增强无线联邦学习在动态车辆队列系统中的性能，有效解决信息交换和模型同步的挑战。

> **ai_Abstract:** 本文提出一个名为RACE的两阶段资源感知控制框架，旨在解决动态车辆队列（VP）中无线联邦学习（WFL）面临的通信变化和资源限制挑战。该框架通过联合优化信息适龄性（AoI）和联邦学习模型漂移（FLMD），利用拉格朗日对偶分解进行资源配置，并采用结合多头自注意力与长短期记忆的多智能体深度强化学习进行车辆选择。实验证明，RACE显著提升了AoI优化（高达45%），加速了学习收敛，并增强了在动态VP环境中的适应性。

> **摘要翻译:** 本论文旨在增强与无线联邦学习（WFL）集成的车辆队列（VP）系统的性能。在高度动态的环境中，车辆队列会经历频繁的通信变化和资源限制，这显著影响信息交换和学习模型同步。为了解决这些挑战，我们首先将VP中的WFL表述为一个联合优化问题，该问题同时考虑信息适龄性（AoI）和联邦学习模型漂移（FLMD），以确保及时和准确的控制。通过理论分析，我们研究了FLMD对收敛性能的影响，并开发了一个两阶段的资源感知控制框架（RACE）。第一阶段采用拉格朗日对偶分解方法进行资源配置，而第二阶段则实施多智能体深度强化学习方法进行车辆选择。该方法整合了多头自注意力机制和长短期记忆网络，以捕获通信状态中的时空相关性。实验结果表明，与基线方法相比，所提出的框架将AoI优化提高了高达45%，加速了学习收敛，并能更有效地适应AI4MARS数据集上的动态VP环境。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [111] [QUIC Delay Control: an implementation of congestion and delay control](https://arxiv.org/abs/2507.00896)
> *QUIC 延迟控制：一种拥塞和延迟控制的实现*

*Saverio Mascolo, Andrea Vittorio Balillo, Gioacchino Manfredi, Davide D'Agostino, Luca De Cicco* | **Category: cs.NI, C.2.2; C.2.1**

**Keywords:** QUIC, 拥塞控制, 延迟控制, 实时应用, 排队延迟

**Comment:** 8 pages, 9 figures

> **TL;DR:** QUIC-DC 是一种新的拥塞和延迟控制算法，旨在通过估计单向排队延迟来减少数据包丢失和端到端通信延迟，同时保持网络利用率，适用于实时应用。

**AI_Comments:** QUIC-DC 的创新点在于将单向排队延迟估计引入拥塞控制，实现了对拥塞的早期反应，这对于提高实时应用的性能至关重要。其在减少延迟和数据包丢失方面的表现令人印象深刻，同时保持了网络利用率，显示出良好的实用前景。

<details>
  <summary>Details</summary>

**Motivation:** 为了控制拥塞和通信路径上的排队延迟，并为实时应用提供更好的性能。

**Method:** 提出了一种名为 QUIC Delay Control (QUIC-DC) 的新算法。其核心思想是估计连接的单向排队延迟以触发对拥塞的早期反应。该算法与 TCP Westwood+ 拥塞控制算法相结合，并在 QUIC-DC 中实现，并与 QUIC Cubic、BBRv2、NewReno 和 Westwood+ 进行了比较。

**Result:** 在模拟和真实网络连接中获得的结果表明，QUIC-DC 可以显著减少数据包丢失和端到端通信延迟，同时保持网络利用率。

**Conclusion:** QUIC-DC 是一种有效的拥塞和延迟控制算法，能够减少数据包丢失和延迟，同时保持网络利用率，使其非常适用于实时应用。

> **ai_Abstract:** 本文提出了一种名为 QUIC-DC 的新型拥塞和延迟控制算法。该算法通过估计单向排队延迟来提前响应拥塞，并与 TCP Westwood+ 结合实现。实验结果表明，QUIC-DC 在减少数据包丢失和端到端延迟方面表现出色，同时保持了网络利用率，特别适用于实时应用。

> **摘要翻译:** QUIC 延迟控制：一种拥塞和延迟控制的实现。

提出了一种名为 QUIC 延迟控制 (QUIC-DC) 的新拥塞和延迟控制算法，旨在不仅控制拥塞，还控制沿前向通信路径遇到的排队延迟。其核心思想是估计连接的单向排队延迟，以触发对拥塞的早期反应。该思想与 TCP Westwood+ 拥塞控制算法一起，已在 QUIC-DC 中实现，并与 QUIC Cubic、BBRv2、NewReno、Westwood+ 进行了比较。在模拟和真实网络连接中获得的结果表明，QUIC-DC 可以显著减少数据包丢失和端到端通信延迟，同时保持网络利用率，这些特性对于实时应用都非常有用。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [10] [On the Optimality of Coded Distributed Computing for Ring Networks](https://arxiv.org/abs/2507.00091)
> *环形网络中编码分布式计算的最优性*

*Zhenhao Huang, Minquan Cheng, Kai Wan, Qifu Tyler Sun, Youlong Wu* | **Category: cs.IT, math.IT**

**Keywords:** 编码分布式计算, 环形网络, 通信负载, 冗余计算, 最优性

**Comment:** Part of the work has been presented at ISIT 2025

> **TL;DR:** 本文研究环形网络中编码分布式计算问题，提出两种新的编码方案（用于all-gather和all-to-all），并证明其在特定条件下能达到通信负载、计算负载和广播距离之间的最优折衷。

**AI_Comments:** 这篇论文的创新点在于为环形网络中的分布式计算提出了新的编码方案，并从理论上证明了其在特定条件下的最优性。特别是区分了all-gather和all-to-all两种场景，并根据其特性设计了不同的优化策略。该研究对于理解和优化环形网络中的数据传输效率具有重要意义，揭示了冗余计算和广播距离对通信负载的不同影响机制。

<details>
  <summary>Details</summary>

**Motivation:** 解决环形通信网络中交换中间值时的通信瓶颈问题。

**Method:** 提出新的编码分布式计算方案，利用环形拓扑和冗余计算。针对all-gather情况，提出基于“连续反向拼车”的新编码方案。针对all-to-all情况，根据中间值与目标节点的接近程度来传递，以减少不必要的传输。进行理论反向证明和信息论下界推导。

**Result:** 对于all-gather情况，所提方案在N远大于d时，实现了通信负载、计算负载r和广播距离d之间的最优折衷。对于all-to-all情况，所提方案在N远大于r的循环放置下，渐近最优。最优性结果表明，在环形网络中，冗余计算r仅导致通信负载的加性增益，而广播距离d则有助于乘性增益。

**Conclusion:** 在环形网络中，冗余计算对通信负载的减少是加性增益，而广播距离则提供乘性增益，且所提出的编码方案在特定条件下能达到最优或渐近最优。

> **ai_Abstract:** 本文研究了环形网络中的编码分布式计算，旨在缓解通信瓶颈。研究了all-gather和all-to-all两种情况，并提出了利用环形拓扑和冗余计算的新编码方案。对于all-gather，基于连续反向拼车的方案在N>>d时实现了通信负载、计算负载和广播距离的最优折衷。对于all-to-all，通过优化中间值传递，方案在N>>r的循环放置下渐近最优。研究结果表明，冗余计算带来通信负载的加性增益，而广播距离带来乘性增益。

> **摘要翻译:** 我们考虑环形通信网络中的编码分布式计算问题，其中N个计算节点呈环形拓扑排列，每个节点只能与常数距离d内的邻居通信。为了缓解交换中间值时的通信瓶颈，我们为基于环形的网络提出了新的编码分布式计算方案，该方案利用了环形拓扑和冗余计算（即每个映射函数由r个节点计算）。考虑了两种典型情况：all-gather，其中每个节点需要从所有输入文件映射的所有中间值；以及all-to-all，其中每个节点需要其他节点提供的一组不同的中间值。对于all-gather情况，我们提出了一种基于连续反向拼车的新编码方案，其中节点传输每个编码包，其中包含沿相同路径沿相反方向传播的两个消息。理论反向证明表明，当N远大于d时，我们的方案在通信负载、计算负载r和广播距离d之间实现了最优折衷。对于all-to-all情况，我们没有简单地重复all-gather方案，而是根据中间值与目标节点的接近程度来巧妙地传递中间值，以减少不必要的传输。我们推导了最优通信负载的信息论下界，并表明在N远大于r的循环放置下，我们的方案是渐近最优的。最优性结果表明，在环形网络中，冗余计算r仅导致通信负载的加性增益，而广播距离d则有助于乘性增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [26] [Wireless AI Evolution: From Statistical Learners to Electromagnetic-Guided Foundation Models](https://arxiv.org/abs/2507.00366)
> *无线AI演进：从统计学习器到电磁引导基础模型*

*Jian Xiao, Ji Wang, Kunrui Cao, Xingwang Li, Zhao Chen, Chau Yuen* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** 无线AI, 6G, 无线基础模型, 电磁信息理论, 自监督预训练

**Comment:** 

> **TL;DR:** 6G网络需求推动无线AI向电磁引导的基础模型发展，但现有模型存在物理不一致等问题。本文提出EIT-SPT框架，通过自监督预训练将电磁物理注入无线基础模型，提升其物理一致性、泛化能力和数据效率。

**AI_Comments:** 本文提出了一个创新的EIT-SPT框架，通过自监督预训练将电磁物理原理系统地融入无线基础模型，解决了现有大型AI模型在无线通信中物理一致性差、缺乏电磁理解和数据效率低的问题。这一方法对于实现6G网络中对AI原生和物理感知能力的需求至关重要，有望提升无线AI在复杂电磁环境下的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 6G网络对全息通信、泛在传感和原生智能的革命性需求，正在推动无线AI向AI原生无线网络的必要演进。然而，现有大型AI模型面临关键局限性，包括预训练策略与电磁兼容性约束脱节导致物理上不一致的预测、缺乏对波传播物理的内在理解、以及难以获取大规模标注数据集进行全面的电磁感知训练。

**Method:** 本文提出了一个电磁信息理论引导的自监督预训练（EIT-SPT）框架，旨在系统地将电磁物理注入无线基础模型（WFMs）。该框架旨在为WFMs注入内在的电磁知识。

**Result:** 文章阐述了WFMs在6G场景中的多种潜在应用，并通过说明性案例研究验证了所提出EIT-SPT框架的有效性。

**Conclusion:** EIT-SPT框架能有效提升无线基础模型的物理一致性、在不同电磁环境下的泛化能力以及整体数据效率。文章还总结了WFMs的关键开放研究挑战和未来方向。

> **ai_Abstract:** 鉴于6G网络对AI原生无线通信的需求，本文探讨了无线AI从专用模型向电磁引导的无线基础模型（WFMs）演进的必要性。针对现有大型AI模型在物理一致性、电磁理解和数据效率方面的不足，文章提出了一个电磁信息理论引导的自监督预训练（EIT-SPT）框架。该框架通过系统地注入电磁物理知识，旨在提高WFMs的物理一致性、跨电磁环境的泛化能力和数据效率。文章还讨论了WFMs在6G中的应用潜力，并通过案例研究验证了EIT-SPT的有效性，并指出了未来的研究方向。

> **摘要翻译:** 过去十年中，人工智能（AI）在无线通信中的初步应用，利用专门模型完成了特定通信任务，展现出巨大潜力。然而，第六代（6G）网络对全息通信、泛在传感和原生智能的革命性需求，正在推动无线AI向AI原生无线网络的必要演进。大型AI模型的出现为无线AI的下一阶段铺平了道路，其核心驱动力是无线基础模型（WFMs）。特别是，基于通用电磁（EM）原理的预训练，使WFMs具备了应对各种苛刻6G应用所需的基本适应性。然而，现有大型AI模型面临关键局限性，包括：与电磁兼容性约束脱节的预训练策略导致物理上不一致的预测；缺乏对波传播物理的内在理解；以及难以获取大规模标注数据集进行全面的电磁感知训练。为应对这些挑战，本文提出了一个电磁信息理论引导的自监督预训练（EIT-SPT）框架，旨在系统地将电磁物理注入WFMs。EIT-SPT框架旨在为WFMs注入内在的电磁知识，从而增强其物理一致性、在不同电磁环境下的泛化能力以及整体数据效率。基于所提出的EIT-SPT框架，本文首先阐述了WFMs在6G场景中的各种潜在应用，然后通过说明性案例研究验证了所提出框架的有效性，最后总结了WFMs的关键开放研究挑战和未来方向。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [46] [Accuracy and Security-Guaranteed Participant Selection and Beamforming Design for RIS-Assisted Federated Learning](https://arxiv.org/abs/2507.00388)
> *RIS辅助联邦学习中精度和安全保证的参与者选择与波束成形设计*

*Mengru Wu, Yu Gao, Weidang Lu, Huimei Han, Lei Sun, Wanli Ni* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** 联邦学习, 可重构智能表面, 参与者选择, 波束成形, 安全性, 训练延迟

**Comment:** 

> **TL;DR:** 本文提出了一种在存在窃听的情况下，RIS辅助的联邦学习框架，通过联合优化参与者选择、带宽分配和RIS波束成形设计来最小化训练延迟，并采用TD3算法求解，实验结果显示训练延迟显著降低。

**AI_Comments:** 该论文的创新点在于将RIS技术引入联邦学习中，以解决在窃听环境下的安全性和效率问题。通过将部分设备作为协作干扰器，提供了一种新颖的对抗窃听的策略。同时，联合优化多个关键参数（参与者选择、带宽分配、RIS波束成形）以最小化训练延迟，并采用TD3算法进行求解，体现了其在优化方法上的贡献。该研究对于提升FL在实际部署中的鲁棒性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）能够不共享原始数据地训练神经网络模型，解决了数据隐私问题。然而，在存在窃听的情况下，如何保证FL训练的准确性和安全性，并优化训练效率是一个挑战。

**Method:** 本文提出了一个RIS辅助的联邦学习框架，其中部分边缘设备被选作FL训练参与者，其余设备作为协作干扰器发送干扰信号以对抗窃听。目标是联合优化参与者选择、带宽分配和RIS波束成形设计，以最小化每个FL轮次的训练延迟，同时满足FL的收敛精度和安全上传要求。为了解决由此产生的混合整数非线性规划问题，提出了一种双延迟深度确定性策略梯度（TD3）算法。

**Result:** 仿真结果表明，与基线相比，所提出的方案将FL训练延迟降低了约27%。

**Conclusion:** 所提出的RIS辅助联邦学习框架能够有效降低训练延迟，并在保证收敛精度和安全性的前提下，优化参与者选择、带宽分配和RIS波束成形设计，从而提升联邦学习的效率和鲁棒性。

> **ai_Abstract:** 该论文提出了一种新的RIS辅助联邦学习（FL）框架，旨在解决存在窃听时的训练效率和安全性问题。通过选择部分边缘设备作为FL参与者，其余设备作为协作干扰器，并联合优化参与者选择、带宽分配和RIS波束成形设计，以最小化训练延迟，同时保证FL收敛精度和数据安全上传。为求解此复杂的优化问题，本文采用了TD3算法。仿真结果验证了该方案能够显著降低FL训练延迟。

> **摘要翻译:** 联邦学习（FL）已成为一种无需共享参与者原始数据即可训练神经网络模型的有效方法，从而解决了数据隐私问题。在本文中，我们提出了一种在存在窃听情况下的可重构智能表面（RIS）辅助FL框架，其中部分边缘设备被选择参与FL训练过程。相比之下，其余设备作为协作干扰器，通过发送干扰信号来扰乱窃听。我们的目标是通过联合优化参与者选择、带宽分配和RIS波束成形设计，在满足FL收敛精度和安全上传要求的前提下，最小化每个FL轮次的训练延迟。为了解决由此产生的混合整数非线性规划问题，我们提出了一种双延迟深度确定性策略梯度（TD3）算法。仿真结果表明，所提出的方案与基线相比，将FL训练延迟降低了约27%。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [66] [Construction of LDPC convolutional codes with large girth from Latin squares](https://arxiv.org/abs/2507.00591)
> *基于拉丁方阵的大周长LDPC卷积码的构造*

*Elisa Junghans, Julia Lieb* | **Category: cs.IT, math.IT**

**Keywords:** LDPC码, 卷积码, 周长, 拉丁方阵, 紧凑构造

**Comment:** 

> **TL;DR:** 提出了一种利用拉丁方阵和提升步骤构造大周长、可高效存储的LDPC卷积码的方法。

**AI_Comments:** 该研究的创新之处在于结合拉丁方阵和提升步骤来构造具有大周长且结构紧凑的LDPC码，这对于提高通信系统中的纠错性能和存储效率具有重要意义。该方法不仅适用于卷积码，也适用于分组码，显示了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 为了降低解码失败的概率，需要具有大周长的LDPC码；为了高效存储这些码，需要紧凑的构造方法。

**Method:** 本文提出了一种利用特殊类型的拉丁方阵和若干提升步骤来构造周长可达12的LDPC卷积码。

**Result:** 这些技术能够实现码的紧凑表示，并为性能良好且可高效存储的时变和时不变LDPC卷积码以及LDPC分组码提供了构造方法。

**Conclusion:** 通过利用拉丁方阵和提升步骤，可以构造出具有大周长且可高效存储的LDPC卷积码和分组码。

> **ai_Abstract:** 该论文提出了一种利用特殊拉丁方阵和多级提升步骤构造大周长LDPC卷积码的方法，旨在提高解码性能并实现紧凑存储。这种方法能够生成周长高达12的LDPC卷积码，并适用于构建高效存储的时变、时不变LDPC卷积码和LDPC分组码。

> **摘要翻译:** 由于其接近容量的性能，低密度奇偶校验（LDPC）码在过去几年中受到了广泛关注。这些码的奇偶校验矩阵可以与一个二分图相关联，称为Tanner图。为了降低解码失败的概率，需要具有大周长的LDPC码的关联Tanner图。此外，为了高效存储这些码，需要紧凑的构造方法。在本文中，我们提出了一种利用特殊类型的拉丁方阵和若干提升步骤来构造周长可达12的LDPC卷积码的方法，这使得这些码能够紧凑表示。通过这些技术，我们可以为性能良好且可高效存储的时变和时不变LDPC卷积码以及LDPC分组码提供构造方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [88] [On the rank weight hierarchy of $M$-codes](https://arxiv.org/abs/2507.00609)
> *关于M码的秩权层次*

*G. Berhuy, J. Molina* | **Category: cs.IT, math.IT**

**Keywords:** 秩权层次, 线性码, M码, 循环自同态, 生成多项式

**Comment:** 

> **TL;DR:** 本文研究了在基域上由线性自同态保持稳定的线性码的秩权层次，特别是当自同态是循环的情况。对于这类码，文章给出了其第一秩权等于1的充要条件以及其最后一秩权的显式公式。

**AI_Comments:** 该论文通过对特定类型的线性码（M码）在循环自同态下的秩权层次进行深入分析，提供了具体的条件和公式，这对于理解和设计具有特定秩权性质的编码具有重要意义。其创新之处在于给出了第一秩权的充要条件和最后一秩权的显式公式。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究在线性自同态（特别是循环自同态）下保持稳定的线性码的秩权层次。

**Method:** 研究了在基域上由线性自同态保持稳定的线性码，尤其关注当自同态是循环的情况。通过分析生成多项式，给出了第一秩权等于1的充要条件，并推导了最后一秩权的显式公式。

**Result:** 对于在循环自同态下稳定的线性码，文章给出了其第一秩权等于1的充要条件（通过生成多项式描述），并提供了其最后一秩权的显式公式。

**Conclusion:** 本文为在循环自同态下稳定的线性码的秩权层次提供了关键的理解，包括第一秩权的充要条件和最后一秩权的显式计算方法。

> **ai_Abstract:** 本文深入探讨了在基域上的线性自同态（特别是循环自同态）下保持稳定的线性码的秩权层次。研究提供了此类码第一秩权等于1的充要条件，该条件由其生成多项式决定，并给出了其最后一秩权的明确计算公式。

> **摘要翻译:** 我们研究了在基域上由线性自同态保持稳定的线性码的秩权层次，特别是当自同态是循环的情况。在后一种情况下，我们给出了此类码的第一秩权等于1的充要条件（根据其生成多项式），以及其最后一秩权的显式公式。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [112] [Decentralized Pliable Index Coding For Federated Learning In Intelligent Transportation Systems](https://arxiv.org/abs/2507.00643)
> *智能交通系统中联邦学习的去中心化可塑索引编码*

*Sadina Kadakkottiri, Narisetty Harish, Nujoom Sageer Karat, Deepthi Paramel Pattathil, Balaji Sundar Rajan* | **Category: cs.IT, math.IT**

**Keywords:** 联邦学习, 智能交通系统, 非独立同分布数据, 去中心化可塑索引编码, 数据混洗

**Comment:** 

> **TL;DR:** 针对联邦学习中非独立同分布数据导致的收敛慢和准确性低问题，本文提出了一种去中心化可塑索引编码 (CDPIC) 方案，用于高效数据混洗，显著提升了联邦学习的性能。

**AI_Comments:** 本文的创新点在于将可塑索引编码（特别是去中心化和连续形式）应用于联邦学习中的数据混洗，以解决非独立同分布数据挑战。这种去中心化的方法避免了对中央服务器的依赖，更符合联邦学习的分布式特性，对于提升智能交通系统中联邦学习的实用性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在智能交通系统（ITS）中面临非独立同分布（Non-IID）数据分布问题，这严重影响了模型训练的收敛速度和准确性。

**Method:** 提出了一种去中心化可塑索引编码（DPIC）方案，特别是连续去中心化可塑索引编码（CDPIC(S,K)），用于联邦学习中的高效数据混洗。该方案为任意K和S值提供了可塑索引编码设计，并证明了部分情况下的最优性。

**Result:** 将CDPIC方案应用于联邦学习中的数据混洗，能够逐步将本地数据分布转化为独立同分布（IID），从而提高了联邦学习的性能。通过使用所提出的CDPIC方案进行不同程度的数据混洗，分析了最流行的联邦学习技术FedAvg和联邦子模型技术CELL在准确性和收敛性方面的改进。

**Conclusion:** 提出的CDPIC方案通过有效的数据混洗，成功解决了联邦学习中非独立同分布数据的问题，显著提升了联邦学习的准确性和收敛速度。

> **ai_Abstract:** 本文提出了一种去中心化可塑索引编码（CDPIC）方案，旨在解决智能交通系统（ITS）中联邦学习（FL）因非独立同分布（Non-IID）数据导致的收敛速度慢和准确性低的问题。通过在节点间进行高效数据混洗，CDPIC方案能够逐步将本地数据分布转换为独立同分布。实验结果表明，该方案显著提升了FedAvg和CELL等主流联邦学习技术在准确性和收敛性方面的表现。

> **摘要翻译:** 联邦学习是智能交通系统（ITS）中数据隐私和安全的一个有前景的选择，因为它允许边缘设备、路侧单元（RSU）和中央服务器（CS）共同训练机器学习模型。由于RSU从其范围内的车辆收集数据，每个RSU的本地数据将具有非独立同分布（Non-IID）的分布，这会对联邦学习训练的收敛速度和准确性产生不利影响。在各个节点本地生成合成数据，然后进行节点间的数据混洗，是解决非独立同分布数据问题的一种有前景的方法。在这项工作中，我们提出了可塑索引编码（PIC）解决方案，用于联邦学习系统中节点之间的高效数据混洗。在PIC(S)问题中，如果客户端能够检索其侧信息中原本不存在的任意S条新消息，则认为该客户端已满足。我们特别考虑去中心化可塑索引编码问题（DPIC），其中客户端之间无需中央服务器即可进行通信，以模拟联邦学习中的数据混洗。本文考虑了一类DPIC，称为连续去中心化可塑索引编码（CDPIC(S,K)），其中每个客户端具有K条连续消息作为侧信息。对于CDPIC(S,K)问题，提供了适用于K和S任何值的可塑索引编码设计，并建立了部分情况下的最优性证明。此外，这些CDPIC解决方案应用于联邦学习中的数据混洗，通过每次传输逐步将本地数据分布转换为独立同分布，从而提高联邦学习的性能。通过使用所提出的CDPIC方案提供不同程度的数据混洗，分析了最流行的联邦学习技术FedAvg和一种有前景的联邦子模型技术CELL（通信高效彩票学习）在准确性和收敛性方面的改进。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [135] [The Rate-Distortion Function for Sampled Cyclostationary Gaussian Processes with Memory and with Bounded Processing Delay: Extended Version with Proofs](https://arxiv.org/abs/2507.00656)
> *具有记忆和有界处理延迟的采样循环平稳高斯过程的速率失真函数：带证明的扩展版本*

*Zikun Tan, Ron Dabora, H. Vincent Poor* | **Category: cs.IT, math.IT**

**Keywords:** 速率失真函数, 循环平稳过程, 高斯过程, 信息谱, 有界处理延迟

**Comment:** accepted by the 2025 IEEE International Symposium on Information
  Theory (ISIT)

> **TL;DR:** 本文研究了由连续时间循环平稳高斯过程采样得到的离散时间宽平稳近似循环平稳高斯过程的速率失真函数（RDF），该过程具有记忆并允许有限有界处理延迟。作者利用信息谱框架解决了传统信息论工具因信息不稳定性而失效的问题，并进行了数值评估。

**AI_Comments:** 这篇论文的创新点在于将信息谱框架应用于表征具有信息不稳定性的WSACS过程的速率失真函数，并考虑了此前研究中未涉及的有限有界处理延迟和记忆效应。这对于通信信号的有效压缩具有重要的理论和实际意义，尤其是在处理异步采样和复杂信号特性方面。

<details>
  <summary>Details</summary>

**Motivation:** 连续时间循环平稳高斯过程代表通信信号，需要采样进行离散时间处理以实现压缩。振荡器的物理特性导致采样间隔与物理过程自相关函数的周期不匹配，从而产生了离散时间宽平稳近似循环平稳（WSACS）模型。此外，采样间隔通常短于相关长度，导致离散时间过程也具有相关性。由于WSACS过程的信息不稳定性，传统信息论工具无法适用，因此需要新的方法来表征速率失真函数。

**Method:** 本文利用信息谱框架来表征速率失真函数（RDF）。研究中考虑了后续源序列处理之间允许有限和有界延迟的场景，这扩展了作者之前关于没有处理延迟或没有记忆的设定研究。

**Result:** 论文成功表征了在有限和有界处理延迟下，采样后的离散时间宽平稳近似循环平稳高斯过程的速率失真函数。数值评估揭示了场景参数对异步采样下速率失真函数的影响。

**Conclusion:** 本文利用信息谱框架成功表征了具有记忆和有界处理延迟的采样循环平稳高斯过程的速率失真函数，并扩展了先前关于无延迟或无记忆的研究，为理解此类过程的有效压缩提供了重要见解。

> **ai_Abstract:** 本文深入研究了由连续时间宽平稳循环平稳高斯过程采样而来的离散时间宽平稳近似循环平稳高斯过程的速率失真函数（RDF），该过程具有记忆并允许有限有界处理延迟。鉴于WSACS过程的信息不稳定性导致传统信息论工具失效，作者创新性地采用信息谱框架进行RDF表征。这项工作不仅解决了实际通信信号压缩中遇到的挑战，还扩展了此前无延迟或无记忆的设定，并通过数值评估揭示了不同场景参数对异步采样下RDF的具体影响。

> **摘要翻译:** 我们研究了离散时间（DT）宽平稳近似循环平稳（WSACS）高斯过程的速率失真函数（RDF），该过程具有记忆，并且源于对连续时间（CT）宽平稳循环平稳（WSCS）高斯源过程的采样。这个问题的重要性在于，此类CT过程代表通信信号，必须应用采样以促进与其压缩相关的DT处理。此外，振荡器的物理特性意味着采样间隔与物理过程自相关函数（AF）的周期不匹配，从而产生了所考虑的DT WSACS模型。此外，为了减少损耗，采样间隔通常短于相关长度，因此DT过程也具有相关性。RDF表征的困难源于WSACS过程的信息不稳定性，这使得传统的信息论工具不适用。在这项工作中，我们利用信息谱框架来表征当后续源序列处理之间允许有限和有界延迟时的RDF。这种场景扩展了我们之前研究没有处理延迟或没有记忆设置的工作。数值评估揭示了场景参数对异步采样下RDF的影响。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [157] [On Hierarchical Coded Caching with Offline Users](https://arxiv.org/abs/2507.00727)
> *分层编码缓存与离线用户*

*Rashid Ummer N. T., B. Sundar Rajan* | **Category: cs.IT, math.IT**

**Keywords:** 分层编码缓存, 离线用户, 热插拔放置传输阵列, 组合t-设计, 两层网络

**Comment:** A short version of this is accepted for presentation in 2025 IEEE
  Information Theory Workshop; 8 pages, one figure

> **TL;DR:** 提出了一种分层热插拔放置传输阵列（HHPDA），用于解决具有离线用户的通用两层分层网络中的编码缓存问题，并使用组合t-设计构建了HHPDA。

**AI_Comments:** 这篇论文的创新点在于提出了HHPDA来解决具有离线用户的通用分层网络中的编码缓存问题，克服了现有方案的显著局限性。通过引入组合t-设计来构建HHPDA，也为该领域的研究提供了新的工具和方法。其重要性在于为更实际的网络场景（存在离线用户和非零内存镜像缓存）提供了理论基础和具体方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分层网络编码缓存方案在处理离线用户时，仅考虑了镜像缓存为零内存的特殊情况，这是一个显著的局限性。本文旨在解决这一局限性，提出更通用的方案。

**Method:** 提出了一种称为分层热插拔放置传输阵列（HHPDA）的新型阵列，用于描述具有离线用户的通用两层分层网络中编码缓存方案的放置和传输阶段。此外，还利用组合t-设计构建了一类HHPDA。

**Result:** 提出并构建了分层热插拔放置传输阵列（HHPDA），该阵列能够描述具有离线用户的通用两层分层网络中的编码缓存方案的放置和传输阶段。

**Conclusion:** 论文成功地提出了一个通用的框架（HHPDA）来解决具有离线用户的分层编码缓存问题，克服了现有方案的局限性。

> **ai_Abstract:** 本文研究了在内容传输阶段存在离线用户的两层分层网络中的编码缓存问题。针对现有方案仅限于镜像缓存零内存的局限性，论文提出了一种通用的分层热插拔放置传输阵列（HHPDA），用于描述具有离线用户的两层分层网络中编码缓存的放置和传输阶段。此外，论文还利用组合t-设计构建了一类HHPDA。

> **摘要翻译:** 本文研究了一个两层分层网络，其中一些用户在内容传输阶段处于离线状态。一个两层分层网络由一个连接到多个具有缓存功能的镜像站点的单一服务器组成，每个镜像站点连接到一组不同的具有缓存功能的用户。最近提出了一种用于此类具有离线用户分层系统的方案，但该方案仅考虑了所有镜像缓存内存为零的特殊情况，这是一个显著的局限性。我们提出了一种称为分层热插拔放置传输阵列（HHPDA）的阵列，它描述了用于具有离线用户的通用两层分层网络中编码缓存方案的放置和传输阶段。此外，我们利用组合t-设计构建了一类HHPDA。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [177] [MichelangeRoll: Sculpting Rational Distributions Exactly and Efficiently](https://arxiv.org/abs/2507.00915)
> *MichelangeRoll：精确高效地雕刻有理分布*

*Jui-Hsiang Shao, Hsin-Po Wang* | **Category: cs.IT, math.IT**

**Keywords:** 离散分布, 熵成本, 精确采样, 硬币抛掷, MichelangeRoll

**Comment:** 13 pages, 7 figures, RANDOM says no so here

> **TL;DR:** MichelangeRoll 提出了一种通过回收剩余熵来精确高效地模拟离散分布的方法，将每次采样的熵成本降低到 H(D) + ε，打破了先前的“+2”屏障。

**AI_Comments:** MichelangeRoll 的创新点在于其巧妙地回收了在离散分布采样过程中通常会被浪费的“剩余熵”。这一方法成功地打破了长期存在的“+2”熵成本障碍，将实际采样成本推向香农理论的下限 H(D)，从而在理论和实践上都具有重要意义。它为需要高效率随机数生成和分布采样的应用提供了一个更优的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 使用公平硬币抛掷模拟任意离散分布 D 存在熵复杂度、空间和时间复杂性之间的权衡。现有方法（如 Knuth 和 Yao 的决策树以及 Drapper 和 Saad 的工作）虽然能实现精确采样，但每次采样都会产生额外的“+2”熵成本。本研究的动机是消除或减少这个额外的熵成本。

**Method:** MichelangeRoll 通过回收剩余熵来解决问题。

**Result:** MichelangeRoll 将生成 D 的持续序列的熵成本降低到每次采样 H(D) + ε，并需要 O((n + 1/ε) log(m/ε)) 的内存。这打破了之前每次采样额外的“+2”熵成本的障碍。

**Conclusion:** 本论文的 MichelangeRoll 方法通过有效回收剩余熵，显著提高了离散分布精确模拟的熵效率，将每次采样的熵成本降低到接近理论最小值 H(D)。

> **ai_Abstract:** 本文提出了一种名为 MichelangeRoll 的新方法，旨在精确高效地模拟离散分布。针对现有方法在每次采样时引入的额外“+2”熵成本问题，MichelangeRoll 通过回收剩余熵，成功将生成离散分布序列的熵成本降低到每次采样 H(D) + ε，同时仅需 O((n + 1/ε) log(m/ε)) 内存。这显著提高了离散分布模拟的熵效率。

> **摘要翻译:** 使用公平硬币抛掷模拟任意离散分布 D ∈ [0, 1]^n 会在熵复杂度与空间和时间复杂度之间产生权衡。香农的理论表明 H(D) 次抛掷是必要且充分的，但不能保证精确分布。Knuth 和 Yao 表明，决策树对于一个精确样本消耗的抛掷次数少于 H(D) + 2 次。Drapper 和 Saad 最近的工作解决了空间和时间方面的问题，表明 H(D) + 2 次抛掷、O(n log(n) log(m)) 内存和 O(H(D)) 操作是其全部成本，其中 m 是 D 中概率质量的公分母，n 是可能结果的数量。
在本文中，MichelangeRoll 回收剩余熵以打破“+2”障碍。通过 O((n + 1/ε) log(m/ε)) 内存，生成 D 持续序列的熵成本降低到每次采样 H(D) + ε。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [195] [Optimal Feedback Schemes for Dirty Paper Channels With State Estimation at the Receiver](https://arxiv.org/abs/2507.00942)
> *接收端具有状态估计的脏纸信道最优反馈方案*

*Dengfeng Xia, Han Deng, Haonan Zhang, Fan Cheng, Bin Dai, Liuguo Yin* | **Category: cs.IT, math.IT**

**Keywords:** 脏纸信道, 状态估计, 反馈, 容量可达, Schalkwijk-Kailath方案

**Comment:** This paper will be presented at the 2025 IEEE Information Theory
  Workshop (ITW)

> **TL;DR:** 本文提出了针对接收端具有状态估计的脏纸信道（DPC-SE-R）的容量可达Schalkwijk-Kailath（SK）型反馈方案，并将其扩展到多址信道。

**AI_Comments:** 本文的创新之处在于，尽管已知反馈不增加特定脏纸信道的容量，但它展示了如何利用反馈来构建低复杂度的容量可达编码方案，这对于实际系统设计具有重要意义。文章提出的SK型方案结合了叠加编码，展现了其在复杂信道条件下的适应性。同时，论文也明确指出了一个尚未解决的问题，即在噪声状态观测情况下如何实现容量可达的SK型方案，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已知反馈不会增加接收端具有状态估计的脏纸信道（SE-R）的最优速率失真区域，但反馈在高斯信道中能帮助构建低复杂度编码方案（如Schalkwijk-Kailath (SK) 反馈方案）。这促使作者探索在具有SE-R和反馈的脏纸信道中实现容量的SK型方案。

**Method:** 本文首先提出了一种结合叠加编码和经典SK型方案的DPC-SE-R容量可达反馈方案。然后，将此方案扩展到具有SE-R和反馈的脏纸多址信道。最后，讨论了如何将该方案扩展到DPC-SE-R的噪声状态观测情况。

**Result:** 本文提出的方案对于DPC-SE-R和脏纸多址信道都是容量可达的。

**Conclusion:** 本文成功提出了DPC-SE-R及其多址扩展的容量可达SK型反馈方案。然而，对于噪声状态观测情况下的容量可达SK型方案仍是未知的。

> **ai_Abstract:** 本文针对接收端具有状态估计的脏纸信道（DPC-SE-R），提出了结合叠加编码和经典Schalkwijk-Kailath (SK) 型方案的容量可达反馈方案。该方案被进一步扩展到脏纸多址信道，并同样被证明是容量可达的。文章还探讨了将该方案应用于噪声状态观测情况的可能性，但指出在该场景下容量可达的SK型方案仍是一个开放问题。

> **摘要翻译:** 在文献中，已经表明反馈不会增加接收端具有状态估计的脏纸信道（SE-R）的最优速率失真区域。另一方面，众所周知，反馈有助于在高斯信道中构建低复杂度的编码方案，例如优雅的Schalkwijk-Kailath (SK) 反馈方案。这促使我们探索在具有SE-R和反馈的脏纸信道中实现容量的SK型方案。在本文中，我们首先提出了一种针对接收端具有状态估计的脏纸信道（DPC-SE-R）的容量可达反馈方案，该方案结合了叠加编码和经典的SK型方案。然后，我们将此方案扩展到具有SE-R和反馈的脏纸多址信道，并表明扩展方案也是容量可达的。最后，我们讨论了如何将我们的方案扩展到DPC-SE-R的噪声状态观测情况。然而，对于这种情况的容量可达SK型方案仍然未知。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [19] [Presto: Hardware Acceleration of Ciphers for Hybrid Homomorphic Encryption](https://arxiv.org/abs/2507.00367)
> *Presto: 混合同态加密密码的硬件加速*

*Yeonsoo Jeon, Mattan Erez, Michael Orshansky* | **Category: cs.AR, cs.CR**

**Keywords:** 混合同态加密, 硬件加速, 对称密码, FPGA, HERA, Rubato

**Comment:** 

> **TL;DR:** Presto是一种为混合同态加密（HHE）中特定对称密码（HERA和Rubato）设计的硬件加速器，在吞吐量、延迟和能耗方面均显著优于软件实现。

**AI_Comments:** 这项工作在混合同态加密的实际应用方面迈出了重要一步。通过为HHE中使用的特定对称密码（HERA和Rubato）设计硬件加速器，该论文解决了客户端部署中性能和能效的关键挑战。其创新点在于通过利用算法特性（如转置不变性）和优化硬件架构（如解耦RNG和密钥计算）来提高效率。所展示的显著性能和能耗改进表明了硬件加速在推动HE实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 混合同态加密（HHE）结合了对称密钥和同态加密，以减少密文膨胀，这在同态加密的客户端-服务器部署中至关重要。已开发出适合高效同态加密评估的特殊对称密码。这些密码的客户端部署需要高性能和高能效的实现。

**Method:** 本文开发并评估了针对两种已知面向CKKS的HHE密码（HERA和Rubato）的硬件加速器。设计了向量化和重叠的功能模块。该设计利用了MixColumns和MixRows函数的转置不变性，并交替中间状态的顺序，以消除流密钥生成中的气泡，从而提高延迟和吞吐量。解耦了RNG和密钥计算阶段，以隐藏RNG的延迟并减少FIFO中的关键路径，从而实现更高的工作频率。在AMD Virtex UltraScale+ FPGA上实现了加速器。

**Result:** 与软件实现相比，Rubato和HERA在吞吐量方面均实现了6倍的提升。在延迟方面，Rubato实现了5倍的降低，而HERA实现了3倍的降低。此外，与软件实现相比，硬件实现将Rubato的能耗降低了75倍，HERA的能耗降低了47倍。

**Conclusion:** 该研究成功开发了针对HHE密码HERA和Rubato的硬件加速器，显著提高了其性能和能效，证明了硬件加速在客户端HHE部署中的巨大潜力。

> **ai_Abstract:** 本文介绍了Presto，一个为混合同态加密（HHE）中的特定对称密码HERA和Rubato设计的硬件加速器。该加速器通过向量化、重叠模块设计、利用转置不变性以及解耦RNG和密钥计算阶段等优化措施，显著提升了性能。在AMD Virtex UltraScale+ FPGA上的实现结果显示，与软件相比，吞吐量提升了6倍，延迟降低了3-5倍，能耗降低了47-75倍，证明了硬件加速在HHE客户端部署中的高效性。

> **摘要翻译:** 混合同态加密（HHE）结合了对称密钥和同态加密，以减少密文膨胀，这在同态加密的客户端-服务器部署中至关重要。已开发出适合高效同态加密评估的特殊对称密码。这些密码的客户端部署需要高性能和高能效的实现，在本文中，我们开发并评估了针对两种已知面向CKKS的HHE密码HERA和Rubato的硬件加速器。
我们设计了向量化和重叠的功能模块。该设计利用了MixColumns和MixRows函数的转置不变性，并交替中间状态的顺序，以消除流密钥生成中的气泡，从而提高延迟和吞吐量。我们解耦了RNG和密钥计算阶段，以隐藏RNG的延迟并减少FIFO中的关键路径，从而实现更高的工作频率。
我们在AMD Virtex UltraScale+ FPGA上实现了加速器。与软件实现相比，Rubato和HERA在吞吐量方面均实现了6倍的提升。在延迟方面，Rubato实现了5倍的降低，而HERA实现了3倍的降低。此外，与软件实现相比，我们的硬件实现将Rubato的能耗降低了75倍，HERA的能耗降低了47倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [35] [ChatHLS: Towards Systematic Design Automation and Optimization for High-Level Synthesis](https://arxiv.org/abs/2507.00642)
> *ChatHLS：迈向高层次综合的系统化设计自动化与优化*

*Runkai Li, Jia Xiong, Xiuyuan He, Jieru Zhao, Qiang Xu, Xi Wang* | **Category: cs.AR**

**Keywords:** 高层次综合, 设计自动化, 大型语言模型, 硬件优化, ChatHLS

**Comment:** 

> **TL;DR:** ChatHLS是一个利用微调LLM和多智能体框架的高层次综合（HLS）设计自动化与优化工作流，显著提高了修复通过率和性能，加速了硬件开发。

**AI_Comments:** ChatHLS的创新点在于将微调LLM与多智能体框架相结合，以解决高层次综合（HLS）中的特定挑战，如错误纠正和设计优化。这提供了一种系统化的方法来克服传统HLS的局限性，并利用LLMs在硬件设计自动化中的潜力。其在修复通过率和性能提升方面的显著成果表明了其在加速硬件开发流程方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 计算需求的日益复杂加速了领域专用加速器的采用，但传统硬件设计方法受限于漫长的开发和验证周期。高层次综合（HLS）能从高级编程语言进行硬件设计，但其广泛应用受限于严格的编码约束和复杂的硬件特定优化，给开发者带来巨大障碍。尽管大型语言模型（LLMs）在硬件设计自动化方面展现潜力，但其有效性受限于高质量数据集的稀缺，尤其是在HLS领域。

**Method:** 我们引入了ChatHLS，一个敏捷的HLS设计自动化和优化工作流。它利用在多智能体框架内集成的微调大型语言模型（LLMs）进行错误纠正和设计优化。

**Result:** ChatHLS在612个测试用例上实现了82.7%的平均修复通过率，分别优于GPT-4o和Llama3-8B 19.1%和63.0%。此外，ChatHLS在资源受限的内核上提供了1.9倍到14.8倍的性能提升。通过在实际计算预算内实现复杂的优化推理，ChatHLS比最先进的基于DSL的方法实现了4.9倍的几何平均加速。

**Conclusion:** ChatHLS在显著加速硬件开发周期的同时，保持了设计可靠性和优化质量的严格标准，这突显了其巨大潜力。

> **ai_Abstract:** ChatHLS是一个旨在解决高层次综合（HLS）中开发周期长、编码约束严格和优化复杂等挑战的系统。它通过利用在一个多智能体框架内集成的微调大型语言模型（LLMs）来实现HLS设计自动化和优化，从而进行错误纠正和性能提升。实验结果表明，ChatHLS在修复通过率上显著优于现有LLM，并在资源受限内核上实现了显著的性能和速度提升，证明了其在加速硬件开发方面的有效性。

> **摘要翻译:** 计算需求的日益复杂加速了领域专用加速器的采用，但传统硬件设计方法受限于漫长的开发和验证周期。高层次综合（HLS）通过使硬件设计从高级编程语言成为可能，弥合了软件和硬件之间的鸿沟。然而，其广泛应用受限于严格的编码约束和复杂的硬件特定优化，给开发者带来了巨大障碍。大型语言模型（LLMs）的最新进展在硬件设计自动化方面展现出巨大潜力。然而，它们的有效性受限于高质量数据集的稀缺，特别是在HLS领域。为了解决这些挑战，我们引入了ChatHLS，一个敏捷的HLS设计自动化和优化工作流，它利用在多智能体框架内集成的微调LLMs进行错误纠正和设计优化。我们广泛的评估表明，ChatHLS在612个测试用例上实现了82.7%的平均修复通过率，分别优于GPT-4o和Llama3-8B 19.1%和63.0%。此外，ChatHLS在资源受限的内核上提供了1.9倍到14.8倍的性能提升。通过在实际计算预算内实现复杂的优化推理，ChatHLS比最先进的基于DSL的方法实现了4.9倍的几何平均加速。这些结果突显了ChatHLS在显著加速硬件开发周期的同时，保持设计可靠性和优化质量严格标准的潜力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [55] [VEDA: Efficient LLM Generation Through Voting-based KV Cache Eviction and Dataflow-flexible Accelerator](https://arxiv.org/abs/2507.00797)
> *VEDA：通过基于投票的KV缓存驱逐和数据流灵活加速器实现高效LLM生成*

*Zhican Wang, Hongxiang Fan, Haroon Waris, Gang Wang, Zhenyu Li, Jianfei Jiang, Yanan Sun, Guanghui He* | **Category: cs.AR**

**Keywords:** LLM推理, 边缘计算, KV缓存驱逐, 数据流优化, 硬件加速器

**Comment:** DAC 2025

> **TL;DR:** VEDA提出了一种结合算法、硬件和数据流优化的方法，通过投票式KV缓存驱逐和灵活数据流加速器，显著提升了LLM在边缘设备上的推理效率，降低了延迟和硬件复杂度。

**AI_Comments:** VEDA的创新之处在于其算法-硬件-数据流协同优化策略，特别是投票式KV缓存驱逐算法和灵活数据流设计，解决了LLM在边缘设备部署中的关键效率瓶颈。将硬件复杂度从O(N)降低到O(1)是一个显著的突破，对于实现真正的实时边缘LLM推理至关重要。这项工作对提升LLM的普适性和隐私性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言处理任务中表现出色，但由于其高资源需求，在边缘部署时面临巨大的计算和内存挑战。本研究旨在解决LLM推理的效率问题。

**Method:** 本研究通过算法-硬件-数据流三方优化来提高LLM推理效率。具体方法包括：1. 提出了一种新颖的基于投票的KV缓存驱逐算法，通过自适应识别不重要的KV向量来平衡硬件效率和算法精度。2. 引入了一种灵活乘积数据流和运行时可重构的PE阵列，用于矩阵-向量乘法，以处理多样化的维度需求和递增的序列长度。3. 提出了一种用于softmax和层归一化等非线性操作的元素串行调度方案。所有这些优化都在一个名为VEDA的定制加速器中实现。

**Result:** 结果显示，延迟大幅降低，硬件复杂度从O(N)显著降低到O(1)。定制设计的加速器VEDA优于现有硬件平台。

**Conclusion:** 本研究代表了LLM在资源受限边缘设备上推理的一个重大进展，有助于实现实时处理、增强数据隐私和模型定制。

> **ai_Abstract:** 本论文提出了VEDA，一个用于提升大型语言模型（LLM）在边缘设备上推理效率的解决方案。它通过算法、硬件和数据流的三方优化实现，包括创新的投票式KV缓存驱逐算法、灵活的数据流设计和运行时可重构的处理器阵列，以及针对非线性操作的元素串行调度。实验结果表明，VEDA显著降低了LLM推理的延迟，并将硬件复杂度从O(N)降低到O(1)，其定制加速器性能优于现有平台，为资源受限环境下的LLM部署提供了高效途径。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言处理任务中表现出色，但由于其高资源需求，在边缘部署时面临巨大的计算和内存挑战。这项工作通过算法-硬件-数据流三方优化来解决LLM推理的效率问题。我们提出了一种新颖的基于投票的KV缓存驱逐算法，通过自适应识别不重要的KV向量来平衡硬件效率和算法精度。从数据流的角度来看，我们引入了一种灵活乘积数据流和运行时可重构的PE阵列，用于矩阵-向量乘法。所提出的方法有效地处理了多样化的维度需求，并解决了序列长度递增变化的挑战。此外，还提出了一种用于softmax和层归一化（layernorm）等非线性操作的元素串行调度方案。结果表明，延迟大幅降低，同时硬件复杂度从O(N)显著降低到O(1)。所提出的解决方案在定制设计的加速器VEDA中实现，其性能优于现有硬件平台。这项研究代表了LLM在资源受限边缘设备上推理的一个重大进展，有助于实现实时处理、增强数据隐私和模型定制。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [13] [CrossPipe: Towards Optimal Pipeline Schedules for Cross-Datacenter Training](https://arxiv.org/abs/2507.00217)
> *CrossPipe：迈向跨数据中心训练的最佳流水线调度*

*Tiancheng Chen, Ales Kubicek, Langwen Huang, Torsten Hoefler* | **Category: cs.DC**

**Keywords:** 跨数据中心训练, 流水线调度, 大型语言模型, 网络延迟, 并行计算

**Comment:** USENIX ATC '25

> **TL;DR:** CrossPipe是一个优化跨数据中心大语言模型训练的框架，通过显式建模和缓解网络延迟及带宽限制来生成最优流水线调度，显著减少训练时间。

**AI_Comments:** CrossPipe的创新之处在于其显式地将网络延迟和带宽作为优化目标，并结合了流水线并行和数据并行通信的重叠，这对于地理分布的LLM训练至关重要。其灵活性体现在调度逻辑与通信细节的分离，以及提供最优和近似最优算法的选择。这项工作对于未来大规模模型在分布式环境下的高效训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型（LLMs）所需的资源已超出单个数据中心的能力，使得跨数据中心策略变得日益重要。该研究旨在优化跨地理分布数据中心的模型训练，解决网络延迟和带宽限制的影响。

**Method:** CrossPipe框架通过显式建模和缓解网络延迟及有限带宽的影响，实现统一分析和优化，结合了流水线并行（PP）和数据并行（DP）通信重叠的机会。它使用基于求解器的最优算法或快速近似最优贪婪算法生成优化的流水线调度，并构建于一个将调度逻辑与通信细节分离的灵活执行引擎之上。

**Result:** 与传统流水线调度相比，在相同的内存限制下，CrossPipe将训练时间减少了高达33.6%。当内存限制放宽时，CrossPipe在通信延迟下仍能保持强大的性能，接近无延迟的理想调度效率。

**Conclusion:** CrossPipe提供改进的可扩展性和资源利用率，特别是在网络延迟高或带宽有限的环境中，有效优化了跨数据中心的大型语言模型训练。

> **ai_Abstract:** CrossPipe是一个针对跨数据中心大型语言模型（LLMs）训练的优化框架。它通过显式建模和缓解网络延迟及带宽限制，实现了流水线并行与数据并行通信的统一优化。该框架采用最优或近似最优的贪婪算法生成流水线调度，并在评估中显示，在相同内存约束下可减少高达33.6%的训练时间，并在高延迟环境下保持高效，显著提升了可扩展性和资源利用率。

> **摘要翻译:** 训练大型语言模型（LLMs）现在需要超出单个数据中心的资源，使得跨数据中心策略变得日益重要。我们提出了CrossPipe，一个旨在优化跨地理分布数据中心模型训练的框架，通过显式建模和缓解网络延迟和有限带宽的影响。它实现了统一的分析和优化，整合了流水线并行（PP）和数据并行（DP）通信重叠的机会。CrossPipe使用基于求解器的最优算法或快速近似最优贪婪算法生成优化的流水线调度，这些算法建立在一个将调度逻辑与通信细节分离的灵活执行引擎之上。我们的评估显示，与传统流水线调度相比，在相同的内存限制下，CrossPipe将训练时间减少了高达33.6%。当内存限制放宽时，CrossPipe在通信延迟下仍能保持强大的性能，接近无延迟的理想调度效率。CrossPipe提供了改进的可扩展性和资源利用率，特别是在网络延迟高或带宽有限的环境中。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [29] [Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs](https://arxiv.org/abs/2507.00418)
> *在HPC集群中部署LLM：高通云AI 100 Ultra与高性能GPU的比较研究*

*Mohammad Firas Sada, John J. Graham, Elham E Khoda, Mahidhar Tatineni, Dmitry Mishin, Rajesh K. Gupta, Rick Wagner, Larry Smarr, Thomas A. DeFanti, Frank Würthwein* | **Category: cs.DC, cs.AI**

**Keywords:** LLM推理, 高通云AI 100 Ultra, GPU, 能效, HPC

**Comment:** To appear in Proceedings of the Practice and Experience in Advanced
  Research Computing (PEARC '25)

> **TL;DR:** 本研究比较了高通云AI 100 Ultra加速器与领先的NVIDIA和AMD GPU在LLM推理方面的能效和性能，发现QAic在大多数情况下具有良好的能效。

**AI_Comments:** 这项研究通过详细的基准测试，提供了高通云AI 100 Ultra在LLM推理领域与主流GPU的对比数据，对于评估新型AI加速器在HPC环境下的实际表现具有重要意义。其创新之处在于对非传统GPU加速器在LLM推理场景的深入探索，并着重于能效这一关键指标，这对于大规模部署和运行LLM具有实际指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 评估高通云AI 100 Ultra (QAic) 加速器在大型语言模型 (LLM) 推理方面的能效和性能，并与领先的GPU进行比较，以探索其在高性能计算 (HPC) 应用中的潜力。

**Method:** 使用vLLM框架，在国家研究平台 (NRP) 生态系统中，对15个参数范围从1.17亿到900亿的开源LLM进行推理，并比较QAic与NVIDIA (A100, H200) 和AMD (MI300A) GPU的能效（每瓦吞吐量）和性能。

**Result:** 高通云AI 100 Ultra推理卡在大多数情况下能效良好，并在能效指标上表现出色。

**Conclusion:** 高通云AI 100 Ultra在国家研究平台 (NRP) 的高性能计算 (HPC) 应用中具有潜力。

> **ai_Abstract:** 本研究对高通云AI 100 Ultra加速器在大型语言模型推理中的能效和性能进行了基准测试，并将其与NVIDIA和AMD的顶级GPU进行了比较。研究在国家研究平台生态系统中使用vLLM框架部署了15个不同规模的开源LLM。结果显示，高通云AI 100 Ultra在多数情况下表现出良好的能效和性能，表明其在高性能计算应用中具有应用潜力。

> **摘要翻译:** 本研究对高通云AI 100 Ultra (QAic) 加速器在大型语言模型 (LLM) 推理方面的性能进行了基准测试分析，评估了其能效（每瓦吞吐量）和性能，并将其与国家研究平台 (NRP) 生态系统中的领先NVIDIA (A100, H200) 和AMD (MI300A) GPU进行了比较。总共使用vLLM框架部署了15个开源LLM，参数范围从1.17亿到900亿。QAic推理卡在大多数情况下似乎具有良好的能效，并在能效指标上表现出色。这些发现为高通云AI 100 Ultra在国家研究平台 (NRP) 内的高性能计算 (HPC) 应用中的潜力提供了见解。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [49] [Real-Time In-Network Machine Learning on P4-Programmable FPGA SmartNICs with Fixed-Point Arithmetic and Taylor](https://arxiv.org/abs/2507.00428)
> *实时网络内机器学习，基于P4可编程FPGA智能网卡，采用定点算术和泰勒展开*

*Mohammad Firas Sada, John J. Graham, Mahidhar Tatineni, Dmitry Mishin, Thomas A. DeFanti, Frank Würthwein* | **Category: cs.DC, cs.NI**

**Keywords:** In-Network Machine Learning, P4, FPGA SmartNICs, Real-Time, Network Edge

**Comment:** To appear in Proceedings of the Practice and Experience in Advanced
  Research Computing (PEARC25)

> **TL;DR:** 该论文探讨了在P4可编程FPGA智能网卡上实现网络内机器学习，以支持低延迟的ML推理。

**AI_Comments:** 该论文的创新点在于将P4编程范式与FPGA智能网卡结合，实现在网络边缘进行实时、低延迟的机器学习推理。通过将权重和偏置存储在控制平面表查找中，实现了ML模型的灵活部署和动态重配置，这对于需要快速响应和适应性强的网络应用（如QoS和安全）具有重要意义，且独立于核心网络基础设施。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器学习（ML）应用成为现代网络操作不可或缺的一部分，对网络可编程性的需求日益增长，以实现低延迟的ML推理，用于诸如服务质量（QoS）预测和网络安全中的异常检测等任务。P4可编程FPGA智能网卡被认为是研究网络内机器学习（INML）的理想平台。

**Method:** 本文探索了将P4编程范式应用于神经网络和回归模型，其中权重和偏置存储在控制平面表查找中。这种方法使得在网络边缘灵活可编程和高效部署可再训练的ML模型成为可能。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了在P4可编程FPGA智能网卡上实现网络内机器学习（INML），以满足现代网络对低延迟ML推理的需求，例如QoS预测和异常检测。P4可编程FPGA智能网卡因其高吞吐量、低延迟和动态可重构性被认为是理想平台。论文提出将P4编程范式应用于神经网络和回归模型，通过控制平面表查找存储权重和偏置，从而实现ML模型在网络边缘的灵活部署和可重训练性。

> **摘要翻译:** 随着机器学习（ML）应用成为现代网络操作不可或缺的一部分，对网络可编程性的需求日益增长，以实现低延迟的ML推理，用于诸如服务质量（QoS）预测和网络安全中的异常检测等任务。ML模型通过动态权重调整提供适应性，使得可编程协议无关数据包处理器（P4）可编程FPGA智能网卡成为研究网络内机器学习（INML）的理想平台。这些设备提供高吞吐量、低延迟的数据包处理，并且可以通过控制平面动态重新配置，从而实现在网络边缘直接灵活集成ML模型。本文探讨了将P4编程范式应用于神经网络和回归模型，其中权重和偏置存储在控制平面表查找中。这种方法使得在网络边缘灵活可编程和高效部署可再训练的ML模型成为可能，且独立于交换机级别的核心基础设施。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [69] [LLM-Mesh: Enabling Elastic Sharing for Serverless LLM Inference](https://arxiv.org/abs/2507.00507)
> *LLM-Mesh：实现无服务器LLM推理的弹性共享*

*Chuhao Xu, Zijun Li, Quan Chen, Han Zhao, Minyi Guo* | **Category: cs.DC**

**Keywords:** LLM推理, 无服务器, 弹性共享, 异构硬件, 资源管理

**Comment:** 

> **TL;DR:** LLM-Mesh 是一种针对中小型LLM的无服务器推理方案，通过异构硬件上的弹性共享，显著提升了服务容量。

**AI_Comments:** 本文创新性地提出了在无服务器LLM推理中利用异构硬件进行弹性共享的方案，解决了现有独占GPU部署导致资源利用率低的问题。其在资源分配、内存管理和碎片化处理方面的机制设计具有实用价值，能够有效提升服务容量和资源利用率。

<details>
  <summary>Details</summary>

**Motivation:** 现有无服务器LLM部署方案采用独占GPU部署，导致新兴CPU架构内置加速器利用率不足，且CPU和GPU均可同时容纳多个LLM。本文旨在解决私有无服务器部署中，中等规模模型和不频繁请求带来的挑战，并探索如何通过弹性共享利用现有硬件资源。

**Method:** 本文提出了LLM-Mesh，一个用于中小型LLM的无服务器推理方案，旨在实现异构硬件间的弹性共享。LLM-Mesh解决了三个核心挑战：1) 精确、细粒度的令牌级计算资源分配，以应对波动的计算需求；2) 协调且前瞻性的内存扩展机制，以检测内存不足风险并减少操作开销；3) 通过主动抢占和被动装箱双重方法减少资源碎片。

**Result:** 在4个32核CPU和4个A100 GPU上的实验结果表明，LLM-Mesh通过共享将服务容量提高了44% - 63%，而进一步利用CPU则将服务容量提升至91% - 159%。

**Conclusion:** LLM-Mesh通过在异构硬件上实现弹性共享，显著提高了无服务器LLM推理的服务容量，有效利用了现有CPU和GPU资源。

> **ai_Abstract:** LLM-Mesh提出了一种用于中小型LLM的无服务器推理方案，旨在通过在异构CPU和GPU硬件之间实现弹性共享来提高服务容量。该方案通过精细的令牌级资源分配、前瞻性内存扩展和减少资源碎片化来应对挑战。实验结果表明，LLM-Mesh显著提升了服务容量，尤其是在利用CPU资源后。

> **摘要翻译:** 大型语言模型（LLM）的兴起推动了对私有无服务器部署的需求，其特点是中等规模模型和不频繁的请求。虽然现有解决方案遵循独占GPU部署，但我们退一步探索现代平台，发现：内置加速器的新兴CPU架构能够服务LLM，但仍未得到充分利用，并且CPU和GPU都可以同时容纳多个LLM。我们提出了LLM-Mesh，一个用于中小型LLM的无服务器推理方案，它实现了异构硬件间的弹性共享。LLM-Mesh解决了三个基本挑战：（1）精确的、细粒度的令牌级计算资源分配，以处理波动的计算需求；（2）协调且前瞻性的内存扩展机制，以检测内存不足危险并减少操作开销；（3）通过主动抢占和被动装箱的双重方法减少资源碎片。在4个32核CPU和4个A100 GPU上的实验结果表明，LLM-Mesh通过共享将服务容量提高了44% - 63%，而进一步利用CPU则将服务容量提升至91% - 159%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [75] [A New Family of Thread to Core Allocation Policies for an SMT ARM Processor](https://arxiv.org/abs/2507.00855)
> *一种适用于SMT ARM处理器的新型线程到核心分配策略家族*

*Marta Navarro, Josué Feliu, Salvador Petit, María E. Gómez, Julio Sahuquillo* | **Category: cs.DC, cs.AR**

**Keywords:** 线程到核心分配, SMT处理器, ARM处理器, 性能优化, ISC堆栈

**Comment:** 13 pages

> **TL;DR:** 该论文提出了一种名为SYNPA的新型线程到核心（T2C）分配策略家族，旨在解决SMT处理器中应用间干扰问题，并通过引入指令和停滞周期（ISC）堆栈克服了ARM PMU的限制。实验结果表明，SYNPA4在周转时间上比Linux提升了38%，是现有最佳策略的3倍。

**AI_Comments:** 这项研究通过引入创新的ISC堆栈，有效地解决了ARM处理器中性能监控单元（PMU）的限制，从而提高了性能堆栈的准确性，这是T2C分配策略性能提升的关键。SYNPA家族，特别是SYNPA4，在实际性能上取得了显著的飞跃，相对于现有技术实现了3倍的性能增益，这表明了其在实际应用中的巨大潜力。此外，其方法的通用性也值得关注，有望应用于其他SMT处理器架构。

<details>
  <summary>Details</summary>

**Motivation:** 现代高性能服务器中的同步多线程（SMT）处理器在优化性能时面临应用间干扰的挑战。为了减轻这种干扰，线程到核心（T2C）分配策略至关重要。现有T2C策略依赖于准确的性能堆栈和预测模型，但ARM处理器在构建性能堆栈时存在PMU限制，因此需要探索新的方法来提高性能堆栈的准确性，进而提升T2C策略的性能。

**Method:** 本文探索了在ARM处理器中构建性能堆栈的不同方法，并引入了一种新颖的指令和停滞周期（ISC）堆栈，以克服ARM PMU的限制。ISC堆栈作为性能预测模型的输入，用于估算考虑应用间干扰的性能。在此基础上，提出了SYNPA家族的T2C分配策略，并通过实验评估其性能。

**Result:** 实验结果表明，SYNPA家族中表现最佳的变体SYNPA4，在周转时间上比Linux提升了38%，这相当于现有ARM处理器最佳策略所获得增益的3倍。

**Conclusion:** 本文提出并验证了SYNPA家族的线程到核心分配策略，尤其SYNPA4在ARM处理器上表现出显著的性能提升。论文中提出的关于构建性能堆栈和精炼方法的讨论，可应用于其他供应商的SMT处理器，有助于性能分析师在实际处理器中构建准确的性能评估。

> **ai_Abstract:** 该论文提出了一种名为SYNPA的新型线程到核心（T2C）分配策略家族，旨在优化SMT ARM处理器的性能。为解决现有策略在ARM PMU上的限制，作者引入了指令和停滞周期（ISC）堆栈来构建更准确的性能堆栈，并将其作为性能预测模型的输入。实验证明，SYNPA4在周转时间上比Linux提升了38%，显著优于现有最佳策略，并且其方法具有推广到其他SMT处理器的潜力。

> **摘要翻译:** 现代高性能服务器通常集成同步多线程（SMT）处理器，这有效地提升了单线程核心的吞吐量。优化SMT处理器的性能面临挑战，原因在于每个SMT核心内部的应用间干扰。为了减轻这种干扰，线程到核心（T2C）分配策略发挥着关键作用。最先进的T2C策略分两步工作：i）使用性能计数器构建每个应用的性能堆栈，以及ii）构建性能预测模型以识别在每个核心上运行的最佳应用对。
本文探讨了在ARM处理器中构建性能堆栈的不同方式，并引入了指令和停滞周期（ISC）堆栈，这是一种克服ARM PMU限制的新颖方法。ISC堆栈用作性能预测模型的输入，用于估计考虑应用间干扰的应用性能。预测模型（第二步）的准确性取决于性能堆栈（第一步）的准确性；因此，性能堆栈的准确性越高，T2C分配策略可能获得的性能增益就越高。
本文介绍了SYNPA作为T2C分配策略的一个家族。实验结果表明，SYNPA中性能最佳的变体SYNPA4，在周转时间上比Linux提高了38%，这相当于现有ARM处理器最先进策略所获得增益的3倍。此外，本文中提出的多重讨论和改进可应用于来自不同供应商的其他SMT处理器，旨在帮助性能分析师构建性能堆栈，以在实际处理器中进行准确的性能估计。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [91] [Collaborative Multi-Agent Reinforcement Learning Approach for Elastic Cloud Resource Scaling](https://arxiv.org/abs/2507.00550)
> *弹性云资源扩展的协作式多智能体强化学习方法*

*Bruce Fang, Danyi Gao* | **Category: cs.DC**

**Keywords:** 多智能体强化学习, 弹性云资源扩展, 协作价值函数, 资源调度, 状态预测

**Comment:** 

> **TL;DR:** 本文提出了一种基于多智能体强化学习的弹性云资源扩展优化方法，通过引入协作价值函数和轻量级状态预测模型，实现了高效的资源调度和系统性能提升，实验证明其在资源利用率、SLA控制和调度延迟方面优于现有方法。

**AI_Comments:** 该论文的创新点在于将多智能体强化学习应用于云资源弹性扩展，并通过引入协作价值函数实现了分布式决策与全局协调的结合。轻量级状态预测模型的加入增强了系统的预见性，提升了决策的准确性。集中式训练和分散式执行的框架也有效解决了不完全信息下的策略学习问题。这项研究为提升云资源管理效率和可靠性提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 应对云计算环境中资源快速变化和任务负载高度不确定性的挑战，解决弹性云资源扩展问题。

**Method:** 提出了一种基于多智能体系统的弹性云资源扩展优化方法。该方法部署多个自主智能体并行感知资源状态并做出局部决策，通过引入协作价值函数实现全局协调。设计了轻量级状态预测模型以增强系统预见性。采用集中式训练和分散式执行的强化学习框架进行策略训练。

**Result:** 实验结果表明，所提出的多智能体扩展策略在资源利用率、SLA违规控制和调度延迟方面优于现有方法，并展示出强大的适应性和智能调节能力。

**Conclusion:** 本文为解决复杂云平台中弹性资源扩展问题提供了一种高效、可靠的新方法。

> **ai_Abstract:** 本文针对云计算中资源快速变化和不确定负载的挑战，提出了一种基于协作式多智能体强化学习的弹性云资源扩展方法。该方法通过分布式智能体的局部决策与协作价值函数的全局协调相结合，并辅以轻量级状态预测模型，提升了资源调度的响应性和系统性能。采用集中训练分散执行的强化学习框架进行策略学习。实验证明，该方法在资源利用率、SLA违规控制和调度延迟方面优于现有策略，为复杂云平台的弹性资源管理提供了高效可靠的新途径。

> **摘要翻译:** 本文解决了云计算环境中资源快速变化和任务负载高度不确定性的挑战。它提出了一种基于多智能体系统的弹性云资源扩展优化方法。该方法部署多个自主智能体并行感知资源状态并做出局部决策。在保持系统分布式特性的同时，引入协作价值函数以实现全局协调。这提高了资源调度的响应性并增强了整体系统性能。为了增强系统预见性，设计了一个轻量级状态预测模型。它协助智能体识别未来的工作负载趋势并优化扩展动作的选择。对于策略训练，该方法采用了集中式训练和分散式执行的强化学习框架。这使得智能体能够在信息不完全的条件下有效学习和协调策略。本文还构建了典型的云场景，包括多租户和突发流量，以评估所提出的方法。评估侧重于资源隔离、服务质量保证和鲁棒性。实验结果表明，所提出的多智能体扩展策略在资源利用率、SLA违规控制和调度延迟方面优于现有方法。结果显示出强大的适应性和智能调节能力。这为解决复杂云平台中的弹性资源扩展问题提供了一种高效、可靠的新方法。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [115] [DynoStore: A wide-area distribution system for the management of data over heterogeneous storage](https://arxiv.org/abs/2507.00576)
> *DynoStore：一种用于异构存储数据管理的广域分布式系统*

*Dante D. Sanchez-Gallegos, J. L. Gonzalez-Compean, Maxime Gonthier, Valerie Hayot-Sasson, J. Gregory Pauloski, Haochen Pan, Kyle Chard, Jesus Carretero, Ian Foster* | **Category: cs.DC**

**Keywords:** 广域分布式系统, 异构存储, 数据管理, 纠删码, 负载均衡

**Comment:** 10 pages. Conference: The 25th IEEE International Symposium on
  Cluster, Cloud, and Internet Computing

> **TL;DR:** DynoStore是一个广域分布式系统，通过数据容器、纠删码和负载均衡算法，有效管理异构存储系统中的数据，相比中心化系统性能提升10%，并具有更优的容错能力。

**AI_Comments:** DynoStore的创新之处在于其数据容器抽象，它为异构存储提供了统一的管理接口，有效解决了传统数据管理中的兼容性难题。其结合纠删码和负载均衡的设计，使其在性能和弹性方面表现出色，对于需要管理大规模、多样化数据的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据在不同设施间的分布带来了资源利用率提升、通过复制增强弹性以及通过靠近数据源处理来提高性能的益处。然而，管理此类数据面临挑战，包括异构访问协议、不同的认证模型以及缺乏统一的协调框架。

**Method:** DynoStore通过核心的数据容器抽象，为异构存储系统提供标准化接口，实现无缝数据管理。多个数据容器连接形成一个内聚的广域存储网络，使用纠删码策略确保弹性。此外，采用负载均衡算法确保存储资源的公平高效利用。

**Result:** DynoStore的评估结果显示，与中心化云托管系统相比，性能提升了10%，同时与Redis和IPFS等最先进解决方案保持了竞争力。DynoStore还表现出卓越的容错能力，能够承受比传统系统更多的故障。

**Conclusion:** DynoStore是一个有效的广域分布式系统，能够克服异构存储数据管理中的挑战，显著提升性能并增强容错能力。

> **ai_Abstract:** DynoStore是一个旨在解决异构存储系统数据管理挑战的广域分布式系统。它引入了数据容器作为核心抽象，提供统一接口，并通过纠删码实现弹性。系统还包含负载均衡算法以优化资源利用。评估结果表明，DynoStore在性能上优于中心化云系统，并与现有先进方案相当，同时展现出更强的故障容忍能力。

> **摘要翻译:** 数据在不同设施间的分布带来了诸多益处，例如增强资源利用率、通过复制提高弹性以及通过在数据源附近处理数据来提升性能。然而，由于异构的访问协议、不同的认证模型以及缺乏统一的协调框架，管理此类数据具有挑战性。本文介绍了DynoStore，一个管理异构存储系统中数据的系统。DynoStore的核心是数据容器，这是一种抽象，它提供标准化接口，实现无缝数据管理，而无论底层存储系统如何。多个数据容器连接创建了一个内聚的广域存储网络，使用纠删码策略确保弹性。此外，负载均衡算法确保存储资源的公平和高效利用。我们使用基准测试和实际案例研究（包括在地理分布式环境中管理医疗和卫星数据）评估了DynoStore。我们的结果表明，与中心化云托管系统相比，性能提升了10%，同时与Redis和IPFS等最先进的解决方案保持了竞争力。DynoStore还表现出卓越的容错能力，能够承受比传统系统更多的故障。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [120] [How Fast Can Graph Computations Go on Fine-grained Parallel Architectures](https://arxiv.org/abs/2507.00949)
> *细粒度并行架构上的图计算能有多快？*

*Yuqing Wang, Charles Colley, Brian Wheatman, Jiya Su, David F. Gleich, Andrew A. Chien* | **Category: cs.DC, cs.AR**

**Keywords:** 图计算, 细粒度并行, UpDown架构, PageRank, BFS

**Comment:** 13 pages, 11 figures, 6 tables

> **TL;DR:** 本文探讨了在为细粒度并行优化的UpDown架构上图计算的性能潜力，通过对PageRank和BFS的评估，展示了其在RMAT图上分别超越现有最佳结果5倍和100倍的显著性能提升。

**AI_Comments:** 这篇论文的创新点在于提出了一个针对细粒度并行和图数据特性优化的新型架构UpDown，并通过实际基准测试展示了其卓越的性能。其重要性在于为未来大规模图计算的硬件设计提供了新的方向和可能性，尤其是在处理不规则图数据方面的潜力巨大。该研究强调了硬件与软件协同设计的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型图问题日益重要，但历史上的并行架构对其支持不足。本文旨在探索在为细粒度并行、自然编程以及真实世界图的非规则性和偏斜性优化的架构上，图计算能达到多快的速度。

**Method:** 研究团队探索了一种名为UpDown的细粒度图架构，该架构针对细粒度并行、自然编程以及真实世界图的非规则性和偏斜性进行了优化。他们使用PageRank (PR) 和广度优先搜索 (BFS) 这两个图基准，并编写了这些算法的五种变体来评估其可编程性。通过对多达256个节点（524,288个通道）的模拟和对16,384个节点（33M个通道）的预测来评估性能。

**Result:** 模拟和预测结果显示，UpDown系统在RMAT图上可以达到637K GTEPS的PageRank性能和989K GTEPS的BFS性能，分别超越了现有最佳结果5倍和100倍。

**Conclusion:** 为细粒度并行优化的UpDown架构能够显著加速图计算，在PageRank和BFS等基准测试中取得了远超现有水平的性能。

> **ai_Abstract:** 本研究探讨了在专为细粒度并行、自然编程以及处理图数据不规则性而设计的UpDown架构上，图计算的性能潜力。通过对PageRank和广度优先搜索这两种核心图算法的评估，并编写了多种算法变体以展示可编程性，研究人员通过大规模模拟证明，UpDown系统在性能上显著超越了现有最佳成果，PR和BFS分别实现了5倍和100倍的提升。

> **摘要翻译:** 大规模图问题至关重要且日益增长，但历史上的并行架构对此类问题的支持甚少。本着协同设计的精神，我们探讨了“图计算在细粒度架构上能有多快？”这一问题。我们探索了为细粒度并行、自然编程以及真实世界图中发现的非规则性和偏斜性优化的架构的可能性。使用PageRank (PR) 和广度优先搜索 (BFS) 这两个图基准，我们评估了一种细粒度图架构UpDown，以探索协同设计能实现怎样的性能。为了展示可编程性，我们编写了这些算法的五种变体。对多达256个节点（524,288个通道）的模拟和对16,384个节点（33M个通道）的预测表明，UpDown系统在RMAT图上可以实现637K GTEPS的PR性能和989K GTEPS的BFS性能，分别超越了现有最佳结果5倍和100倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [138] [Accelerating Loading WebGraphs in ParaGrapher](https://arxiv.org/abs/2507.00716)
> *加速在ParaGrapher中加载Web图*

*Mohsen Koohi Esfahani* | **Category: cs.DC**

**Keywords:** 图加载, ParaGrapher, PG-Fuse, CompBin, 性能优化

**Comment:** 

> **TL;DR:** 本文通过引入PG-Fuse和CompBin两种优化，显著提升了ParaGrapher在加载大规模压缩图时的存储利用率和解压缩带宽，分别实现了高达7.6倍和21.8倍的速度提升。

**AI_Comments:** 本文通过提出PG-Fuse和CompBin两种创新方法，有效解决了大规模图加载中的核心性能瓶颈，即存储利用率和解压缩效率。PG-Fuse利用FUSE机制优化文件系统交互，而CompBin则通过紧凑数据表示提升解压缩速度，两者的结合显著提升了ParaGrapher的实用性，对于需要处理海量图数据的应用具有重要意义。其方法的通用性和显著的性能提升是本文的亮点。

<details>
  <summary>Details</summary>

**Motivation:** ParaGrapher是一个用于加载大规模压缩图的API和库，但之前的研究发现其存在两个主要限制：高带宽存储利用率低下和压缩比增加导致解压缩带宽降低。这些限制阻碍了高性能图算法的设计和评估。

**Method:** 为解决存储利用率问题，引入了ParaGrapher-FUSE (PG-Fuse)，一个基于FUSE的文件系统，通过增加请求块大小、减少底层文件系统调用次数以及缓存接收块来优化存储访问。为提高解压缩带宽，引入了CompBin，一种紧凑的CSR格式二进制表示，它便于直接访问邻居并防止未使用的字节占用存储空间。

**Result:** 在12个真实世界和合成图（高达1280亿条边）上的评估表明，PG-Fuse和CompBin分别实现了高达7.6倍和21.8倍的速度提升。

**Conclusion:** 通过引入PG-Fuse和CompBin，本研究成功克服了ParaGrapher在加载大规模图时的存储利用率和解压缩带宽瓶颈，显著提升了其性能。

> **ai_Abstract:** 本文针对ParaGrapher在加载大规模压缩图时存在的存储利用率低下和解压缩带宽受限问题，提出了两项优化。首先，引入了ParaGrapher-FUSE (PG-Fuse)，一个基于FUSE的文件系统，通过优化存储访问来提高高带宽存储的利用率。其次，提出了CompBin，一种紧凑的CSR格式二进制表示，以提升解压缩带宽。实验结果表明，PG-Fuse和CompBin分别实现了高达7.6倍和21.8倍的性能加速。

> **摘要翻译:** ParaGrapher是一个图加载API和库，它使图处理框架能够以最小的开销加载大规模压缩图。这项能力加速了新高性能图算法的设计和实现，以及它们在各种图和不同框架上的评估。然而，我们之前的研究发现ParaGrapher存在两个主要限制：高带宽存储的低效利用和由于压缩比增加导致的解压缩带宽降低。为了解决这些限制，本文提出了ParaGrapher的两个优化方案。为了提高存储利用率，特别是高带宽存储的利用率，我们引入了ParaGrapher-FUSE (PG-Fuse)，一个基于FUSE（用户空间文件系统）的文件系统。PG-Fuse通过增加请求块的大小、减少对底层文件系统的调用次数以及在内存中缓存接收到的块以供将来调用来优化存储访问。为了提高解压缩带宽，我们引入了CompBin，一种CSR格式的紧凑二进制表示。CompBin便于直接访问邻居，同时防止未使用的字节占用存储空间。我们在12个真实世界和合成图（高达1280亿条边）上的评估表明，PG-Fuse和CompBin分别实现了高达7.6倍和21.8倍的速度提升。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [160] [PANDAS: Peer-to-peer, Adaptive Networking for Data Availability Sampling within Ethereum Consensus Timebounds](https://arxiv.org/abs/2507.00824)
> *PANDAS：以太坊共识时限内数据可用性采样的点对点自适应网络*

*Matthieu Pigaglio, Onur Ascigil, Michał Król, Sergi Rene, Felix Lange, Kaleem Peeroo, Ramin Sadre, Vladimir Stankovic, Etienne Rivière* | **Category: cs.DC, cs.NI, cs.PF**

**Keywords:** 数据可用性采样, 以太坊, Danksharding, Layer-2, 点对点网络

**Comment:** 14 pages, 10 figures, 1 algorithm, 1 table, and 18 plots

> **TL;DR:** PANDAS提出了一种实用的方法，用于在以太坊Danksharding要求下集成数据可用性采样（DAS），以在4秒的共识时限内实现Layer-2数据传播和采样。

**AI_Comments:** PANDAS的创新之处在于其在不修改以太坊核心协议的情况下，解决了Danksharding中Layer-2数据可用性采样的关键时间挑战。其点对点自适应网络设计考虑了实际的网络问题如消息丢失和节点故障，并展示了良好的可扩展性，对于以太坊的未来发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 以太坊Layer-2协议的吞吐量受限，且全局广播Layer-2数据限制了其可扩展性。Danksharding旨在选择性分发Layer-2数据并通过随机数据可用性采样（DAS）验证其可用性。然而，在以太坊共识过程中集成DAS具有挑战性，因为Layer-2数据必须在每个共识槽开始的4秒内传播和采样，而现有解决方案无法满足如此严格的时限。

**Method:** PANDAS是一种实用的方法，用于在不修改以太坊共识和节点发现协议的情况下，将数据可用性采样（DAS）与以太坊集成。它通过轻量级的直接交换来传播Layer-2数据并采样其可用性。其设计考虑了消息丢失、节点故障和无响应参与者，并预期了以太坊网络扩展的需求。

**Result:** 在1,000个节点集群中的原型评估和对多达20,000个对等点的模拟显示，PANDAS允许在行星尺度的延迟下，在4秒的期限内完成Layer-2数据传播和采样。

**Conclusion:** PANDAS成功地解决了在以太坊严格的共识时限内进行Layer-2数据传播和采样的挑战，为Danksharding的实施提供了可行方案。

> **ai_Abstract:** PANDAS提出了一种创新的点对点自适应网络方法，旨在解决以太坊Danksharding中Layer-2数据可用性采样（DAS）的严格时间限制问题。针对现有解决方案无法在4秒共识时限内完成数据传播和采样的挑战，PANDAS通过轻量级直接交换实现数据分发和可用性验证，且无需修改以太坊核心协议。在大型节点集群和模拟中的评估表明，PANDAS能够在严苛的延迟条件下，在规定时间内成功完成Layer-2数据的传播和采样，为以太坊的可扩展性提供了实用方案。

> **摘要翻译:** Layer-2协议可以辅助以太坊有限的吞吐量，但全局广播Layer-2数据限制了它们的可扩展性。以太坊的Danksharding演进旨在支持Layer-2数据的选择性分发，其在网络中的可用性通过随机数据可用性采样（DAS）进行验证。将DAS集成到以太坊的共识过程中具有挑战性，因为Layer-2数据片段必须在每个共识槽开始的四秒内传播和采样。没有现有解决方案能够在这种严格的时间限制下支持传播和采样。
我们提出了PANDAS，一种在Danksharding要求下将DAS与以太坊集成而无需修改其共识和节点发现协议的实用方法。PANDAS通过轻量级的直接交换传播Layer-2数据并采样其可用性。其设计考虑了消息丢失、节点故障和无响应参与者，同时预期了以太坊网络扩展的需求。我们对PANDAS原型在1,000个节点集群中的评估以及对多达20,000个对等点的模拟表明，它允许在行星尺度的延迟下，在4秒的截止日期内完成Layer-2数据传播和采样。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [198] [Turning AI Data Centers into Grid-Interactive Assets: Results from a Field Demonstration in Phoenix, Arizona](https://arxiv.org/abs/2507.00909)
> *将AI数据中心转变为电网互动资产：亚利桑那州凤凰城实地演示结果*

*Philip Colangelo, Ayse K. Coskun, Jack Megrue, Ciaran Roberts, Shayan Sengupta, Varun Sivaram, Ethan Tiao, Aroon Vijaykar, Chris Williams, Daniel C. Wilson, Zack MacFarland, Daniel Dreiling, Nathan Morey, Anuja Ratnayake, Baskar Vairamohan* | **Category: cs.DC, cs.AI, cs.PF, cs.SY, eess.SY**

**Keywords:** AI数据中心, 电网互动资产, 能源管理, 软件定义, 电力需求侧响应

**Comment:** 10 pages, 6 figures, 1 table

> **TL;DR:** AI数据中心耗电量大，本文展示了一种纯软件方案，能将AI数据中心变为电网互动资产，在不影响AI服务质量的情况下减少25%的用电量，无需额外硬件投入。

**AI_Comments:** 这篇论文通过提出一种纯软件解决方案，将AI数据中心从单纯的电力消费者转变为潜在的电网参与者，具有显著的创新性。其重要性在于，在AI快速发展导致电力需求激增的背景下，该方法为缓解电网压力提供了一个无需大规模硬件投资的实用途径，同时维护了AI服务质量。这一突破性概念为未来数据中心与能源基础设施的协同发展提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）推动电力需求呈指数级增长，这威胁到电网可靠性，提高了新基础设施的成本，并阻碍了AI创新，因为数据中心需要等待连接到受限的电网。

**Method:** 本文提出了一种名为Emerald Conductor的纯软件方法，通过实时电网信号协调AI工作负载，将AI数据中心转变为灵活的电网资源，无需硬件修改或储能，并在商业、超大规模云数据中心内的256-GPU集群上进行了实地演示。

**Result:** 在凤凰城的一个256-GPU集群上，在电网高峰期事件期间，集群功耗降低了25%并持续了三个小时，同时保持了AI服务质量（QoS）保证。

**Conclusion:** 该平台通过将数据中心重塑为电网互动资产，增强了电网可靠性，提高了经济性，并加速了AI的发展。

> **ai_Abstract:** 本文介绍了一种名为Emerald Conductor的纯软件方法，旨在将AI数据中心转变为电网互动资产。该方法通过根据实时电网信号智能调整AI工作负载，实现了在不影响服务质量的前提下，有效降低数据中心的电力消耗。在一项256-GPU集群的实地演示中，该方案成功在电网高峰期将集群功耗降低了25%并持续三小时。这表明AI数据中心可以作为提升电网可靠性、降低成本并加速AI发展的灵活资源。

> **摘要翻译:** 人工智能（AI）正在推动电力需求的指数级增长，这威胁到电网可靠性，提高了社区为新能源基础设施支付的价格，并阻碍了AI创新，因为数据中心需要等待连接到受限的电网。本文首次与主要企业合作伙伴合作，展示了一种纯软件方法——Emerald Conductor——它将AI数据中心转变为灵活的电网资源，可以高效、即时地利用现有电力系统，而无需大规模基础设施建设。该试验在亚利桑那州凤凰城的一个商业超大规模云数据中心内，对运行代表性AI工作负载的256-GPU集群进行，在电网高峰期事件期间，实现了集群功耗25%的降低，并持续了三个小时，同时保持了AI服务质量（QoS）保证。通过在没有硬件修改或储能的情况下，根据实时电网信号协调AI工作负载，该平台将数据中心重新构想为电网互动资产，从而增强电网可靠性，提高经济性，并加速AI的发展。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [15] [Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy](https://arxiv.org/abs/2507.00007)
> *在教育实验室中整合通用生成式人工智能平台以培养批判性思维和数字素养*

*Vasiliy Znamenskiy, Rafael Niyazov, Joel Hernandez* | **Category: cs.CY, cs.AI, cs.LG, 68T50, 68U20, 97U50, 97D40, I.2.7; K.3.1; K.3.2; H.5.3**

**Keywords:** 生成式AI, 批判性思维, 数字素养, 教育框架, 实验室活动

**Comment:** http://doi.org/10.5121/ijci.2025.140302

> **TL;DR:** 本研究提出了一种在教育实验室中整合通用生成式人工智能平台的新框架，旨在培养本科生的批判性思维和数字素养，并通过一项试点项目展示了其有效性。

**AI_Comments:** 该论文创新性地将生成式AI平台整合到教育实验室中，将其重新定义为认知工具和研究对象，而非简单的信息来源。这种方法有效地解决了AI工具可能带来的批判性思维缺失问题，并通过实际试点证明了其在提升学生参与度和批判性反思方面的潜力，为未来AI在教育中的应用提供了可复制的实践模型，具有重要的教育意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种新的教育框架，将生成式人工智能（GenAI）平台整合到实验室活动中，以培养本科生的批判性思维和数字素养，同时认识到对大型语言模型（LLMs）不加批判的依赖所带来的局限性和风险。

**Method:** 本研究提出了一种教学模型，将GenAI重新定义为研究对象和认知工具。学生需要制定特定学科的提示，并评估GenAI在文本、图像和视频模式下生成的响应。该框架在一个面向非科学专业学生的普通天文学课程中进行了试点实施。

**Result:** 试点实施显示出高水平的学生参与度和批判性反思，许多学生在课后继续进行活动，并在研究研讨会上展示了成果。结果表明，结构化的人工智能互动在教育中非常重要，GenAI与反思性评估方法结合可以改善学习成果。

**Conclusion:** 本研究得出结论，将GenAI平台整合到教育实验室活动中，通过结构化的互动和反思性评估，可以有效培养学生的批判性思维和数字素数养，并提出了一个可复制的跨学科AI整合实验室工作模型。

> **ai_Abstract:** 本论文提出了一种创新的教育框架，旨在将ChatGPT、Claude和Gemini等通用生成式人工智能（GenAI）平台融入大学实验室活动中。该框架将GenAI视为研究对象和认知工具，以克服学生对大型语言模型（LLMs）的不加批判的依赖，并着重培养学生的批判性思维和数字素养。通过在一个普通天文学课程中的试点实施，研究发现学生参与度高，批判性反思能力增强，并取得了积极的学习成果。研究强调了结构化AI互动的重要性，并提出了一个可复制的跨学科AI整合实验室工作模型。

> **摘要翻译:** 本文提出了一种新的教育框架，用于将ChatGPT、Claude和Gemini等生成式人工智能（GenAI）平台整合到实验室活动中，旨在培养本科生的批判性思维和数字素养。认识到不加批判地依赖大型语言模型（LLMs）的局限性和风险，所提出的教学模型将GenAI重新定义为研究对象和认知工具。学生制定特定学科的提示，并评估GenAI在文本、图像和视频模式下生成的响应。在面向非科学专业学生的普通天文学课程中进行的试点实施，展示了高水平的参与度和批判性反思，许多学生在课后继续进行活动，并在研究研讨会上展示了成果。结果强调了结构化人工智能互动在教育中的重要性，并表明GenAI与反思性评估方法结合时可以改善学习成果。本研究提出了一个可复制的跨学科AI整合实验室工作模型，适用于科学学科。请参阅基于生成式AI平台的学习活动指南：https://doi.org/10.5281/zenodo.15555802

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [31] [Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing](https://arxiv.org/abs/2507.00032)
> *Ken 利用层：在学生知识范围内进行赫布式重放以实现自适应知识追踪*

*Grey Kuling, Marinka Zitnik* | **Category: cs.CY, cs.AI, cs.LG, cs.NE**

**Keywords:** 知识追踪, 赫布学习, 记忆巩固, 个性化学习, 持续学习

**Comment:** 

> **TL;DR:** KUL-KT 是一种受生物学启发的知识追踪模型，它结合了赫布式记忆和基于梯度的巩固，以实现自适应、高效和个性化的学习。

**AI_Comments:** 该论文的创新之处在于其生物学启发（赫布式记忆、记忆巩固），以及用于无需通过时间反向传播的持续学习的新颖 LIT 方法。KUL-KT 在效率（训练速度、内存使用）方面取得了显著提升，并能处理多样化的输入类型，实现少样本个性化。这些特性使其成为个性化学习领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在开发一种更具生物学基础、记忆效率高且输入灵活的知识追踪（KT）框架，以实现大规模个性化学习。现有模型可能缺乏生物学启发，或在没有通过时间反向传播的情况下难以实现持续学习，或需要大量数据/存储。

**Method:** KUL-KT 是一种受生物学启发的知识追踪架构，结合了赫布式记忆编码和基于梯度的巩固。它引入了两项创新：(i) 随时间衰减的赫布式记忆更新，实现优美遗忘；(ii) 一种新颖的损耗对齐内部目标（LIT）方法，用于计算理想内部状态，无需通过时间反向传播即可实现持续学习。该架构包含一个快速赫布式记忆，通过单次关联更新捕获每次学习者交互，以及一个较慢的线性网络，通过梯度下降巩固召回的样本。它在嵌入空间中运行，支持结构化和非结构化输入。

**Result:** KUL-KT 在十个公共知识追踪基准测试中，在 nDCG 和 Recall@10 等排名敏感指标上优于强大的基线模型。在课堂部署中，KUL-KT 根据短答案数据个性化测验，提高了学习者感知到的帮助性并降低了难度（p < 0.05）。消融研究证实赫布式衰减和 LIT 对持续适应至关重要。与强大的基于图的知识追踪模型相比，KUL-KT 训练速度快 1.75 倍，内存使用量减少 99.01%。

**Conclusion:** KUL-KT 被定位为一种生物学基础强、内存效率高、输入灵活的框架，适用于大规模个性化学习。

> **ai_Abstract:** KUL-KT 是一种新颖的、受生物学启发的知识追踪（KT）架构，它结合了赫布式记忆和基于梯度的巩固。该模型具有随时间衰减的赫布式记忆以实现遗忘，以及一种损耗对齐内部目标（LIT）方法，用于无需通过时间反向传播即可进行持续学习。KUL-KT 实现了少样本个性化和自然遗忘，无需存储原始数据，并支持结构化和非结构化输入。经验结果表明，KUL-KT 在十个 KT 基准测试中超越了基线模型，在课堂环境中改善了学习者体验，并展现出优于其他模型的训练速度和内存效率。它为大规模个性化学习提供了一个可扩展、具有生物学基础且灵活的解决方案。

> **摘要翻译:** 我们引入了 KUL-KT，这是一种受生物学启发的知识追踪（KT）架构，在一个可扩展、输入无关的框架中结合了赫布式记忆编码和基于梯度的巩固。KUL-KT 通过引入两项关键创新，将神经系统中记忆巩固的原理应用于学生建模：(i) 一种随时间衰减的赫布式记忆更新，实现优美遗忘；(ii) 一种新颖的损耗对齐内部目标（LIT）方法，用于计算理想的内部状态，无需通过时间反向传播即可实现持续学习。该架构由一个快速赫布式记忆组成，通过单次关联更新捕获每次学习者交互，以及一个较慢的线性网络，通过梯度下降巩固召回的样本。这种设计实现了少样本个性化和自然遗忘，无需存储原始数据或依赖大规模同群训练。KUL-KT 完全在嵌入空间中操作，支持结构化（表格）和非结构化（短答案）输入。经验上，KUL-KT 在十个公共 KT 基准测试中，在 nDCG 和 Recall@10 等排名敏感指标上优于强大的基线模型。在课堂部署中，KUL-KT 根据短答案数据个性化测验，提高了学习者感知到的帮助性并降低了难度（p < 0.05）。消融研究证实赫布式衰减和 LIT 对持续适应至关重要。与强大的基于图的 KT 模型相比，KUL-KT 训练速度快 1.75 倍，内存使用量减少 99.01%。这些结果将 KUL-KT 定位为一种生物学基础强、内存效率高、输入灵活的框架，适用于大规模个性化学习。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [51] [Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives](https://arxiv.org/abs/2507.00108)
> *生成式AI时代下的编程教学：文献洞察、教学建议与学生视角*

*Clemente Rubio-Manzano, Jazna Meza, Rodolfo Fernandez-Santibanez, Christian Vidal-Castro* | **Category: cs.CY, cs.AI, cs.ET, cs.PL**

**Keywords:** 生成式AI, 编程教学, 代码理解, 可视化编程, 学生视角

**Comment:** 

> **TL;DR:** 本文探讨了生成式AI对编程教学的影响，回顾了相关文献，提出了以代码理解和执行为重点的教学方法，并结合学生观点支持使用可视化工具。

**AI_Comments:** 这篇论文及时地探讨了生成式AI对编程教育的颠覆性影响。其创新之处在于不仅分析了现有文献，更提出了一种具体的、以深度理解为导向的教学范式，即强调可视化代码和执行模拟。这对于应对AI带来的挑战，培养学生适应未来编程环境的关键能力具有重要指导意义。论文结合学生反馈也增加了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI工具正在彻底改变计算机编程，这在大学入门编程课程中引发了关于如何教授、学习和评估编程的深入辩论。本文旨在应对这一挑战，探讨在生成式AI背景下的编程教学方法。

**Method:** 本文首先回顾了关于生成式AI对编程教学影响的现有文献，总结了其优缺点。其次，它提出了一种教学方法论，强调代码理解和执行而非单纯的编码，并特别倡导使用代码的可视化表示和执行的可视化模拟。最后，本文还呈现了学生关于在Java（或其他语言）中引入可视化模拟的初步意见，以提供支持性背景。

**Result:** 文献回顾揭示了生成式AI在编程教学中的优势和劣势。研究提出并倡导了一种新的教学方法，即通过使用代码的可视化表示和执行的可视化模拟，来促进学生对代码的更深层次理解和执行能力，而非仅仅关注编程功能。初步的学生意见也支持将可视化模拟纳入编程训练过程。

**Conclusion:** 在生成式AI时代，编程教学应从单纯的编码转向更深层次的代码理解和执行。通过采用可视化工具（如代码的可视化表示和执行模拟），可以有效提升学生的学习效果和评估质量，从而培养更深入的编程理解。

> **ai_Abstract:** 本文探讨了生成式AI对编程教学的深刻影响。它首先回顾了相关文献中关于生成式AI在编程教学中优缺点，随后提出了一种创新的教学方法，强调通过代码可视化和执行模拟来增强学生的代码理解和执行能力，而非仅仅关注编码。文章最后还提供了学生视角，支持在编程教育中引入可视化模拟工具的重要性。

> **摘要翻译:** 计算机编程正在经历一场由基于大型语言模型的强大自动源代码生成新工具驱动的真正变革。这场变革也体现在世界各地大学的入门编程课程中，引发了关于在生成式人工智能背景下如何教授、学习和评估编程的深入辩论。
本文一方面旨在回顾关于这一问题最相关的研究，突出专业文献中已识别的优点和缺点。另一方面，它建议通过侧重于代码理解和执行而非单纯的编码或程序功能来丰富教学方法。特别是，它倡导使用代码的可视化表示和其执行的可视化模拟作为教学、学习和评估编程的有效工具，从而培养学生更深入的理解。
最后，本文还呈现了参加面向对象编程课程的学生意见，以提供支持在Java（或其他语言）中将可视化模拟纳入培训过程的初步背景。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [71] [Intellectual Property Rights and Entrepreneurship in the NFT Ecosystem: Legal Frameworks, Business Models, and Innovation Opportunities](https://arxiv.org/abs/2507.00172)
> *NFT生态系统中的知识产权与创业：法律框架、商业模式和创新机遇*

*Pranav Darshan, Rohan J S, Raghuveer Rajesh, Ruchitha M, Sanika Kamath, Manas M N* | **Category: cs.CY, cs.ET**

**Keywords:** 知识产权, NFT, 创业, 法律框架, 商业模式

**Comment:** 11 pages

> **TL;DR:** 本研究探讨了NFT生态系统中日益突出的知识产权管理问题，分析了传统版权法与区块链交易之间的差距，并识别了执法、许可标准化和商业机会评估中的关键问题。

**AI_Comments:** 本研究通过构建知识产权矩阵和商业模式分类法，为理解NFT生态系统中的知识产权问题提供了结构化的分析框架，具有创新性。它揭示了当前法律框架与区块链技术之间的脱节，对于未来政策制定和商业实践具有重要指导意义，但抽象中未提及具体解决方案。

<details>
  <summary>Details</summary>

**Motivation:** NFT市场的快速增长暴露了知识产权管理方面的严重问题，即NFT所有权与标的物内容版权之间的混淆。本研究旨在探讨传统版权法与基于区块链的交易之间的差距。

**Method:** 本研究采用混合方法。具体包括：创建新的知识产权矩阵以阐明版权法与NFT所有权结构的关系；构建商业模式分类法，根据IP风险和可持续性对新的商业应用进行排序；以及通过审查重要法律案例、智能合约和利益相关者访谈进行分析。

**Result:** 研究发现，在不同地区执法、标准化许可和评估商业机会方面存在关键问题。

**Conclusion:** 抽象中未明确提及结论，主要聚焦于识别NFT生态系统中知识产权管理的关键问题。

> **ai_Abstract:** 本研究探讨了NFT生态系统中知识产权管理的复杂性，指出NFT所有权与标的物内容版权之间的混淆所带来的挑战。通过采用混合方法，包括开发知识产权矩阵和商业模式分类法，并分析法律案例、智能合约和利益相关者访谈，该研究识别了在跨区域执法、许可标准化和评估新商业机会方面存在的关键问题。

> **摘要翻译:** 非同质化代币（NFT）改变了数字所有权和创作者的赚钱方式。在2021年至2024年间，其市场价值超过400亿。然而，NFT生态系统的快速增长暴露出知识产权管理方面的严重问题。关于拥有NFT与拥有其标的物内容版权之间的区别存在很多混淆。本研究探讨了传统版权法与基于区块链的交易之间的差距。我们采用混合方法来分析这种脱节。我们创建了一个新的知识产权矩阵，清晰地展示了版权法与NFT所有权结构的关系。此外，我们还包含了一个商业模式分类法，根据其知识产权风险和可持续性因素对新的商业应用进行分类。通过审查重要的法律案例、智能合约以及对利益相关者的访谈，我们发现了在不同地区执法、标准化许可和评估商业机会方面的关键问题。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [93] [Partnering with AI: A Pedagogical Feedback System for LLM Integration into Programming Education](https://arxiv.org/abs/2507.00406)
> *携手AI：一个将大型语言模型集成到编程教育中的教学反馈系统*

*Niklas Scholz, Manh Hung Nguyen, Adish Singla, Tomohiro Nagashima* | **Category: cs.CY**

**Keywords:** 大型语言模型, 编程教育, 教学反馈, 自动化反馈, 人机协作

**Comment:** This is an extended version of a poster paper accepted and published
  at ECTEL-2025

> **TL;DR:** 本文介绍了一个基于教学原则的LLM驱动反馈框架，通过一个Python编程应用进行评估，结果显示LLM在提供即时精确反馈方面有效且有时优于人类教师，但仍需人类专业知识补充以应对动态课堂环境。

**AI_Comments:** 本文的创新之处在于提出了一个结合教学原则和本地教师洞察的LLM反馈框架，并验证了其在编程教育中的潜力。它不仅展示了LLM在提供即时精确反馈方面的优势，也坦诚地指出了其局限性，即难以适应动态课堂环境，从而强调了人机协作在教育反馈中的必要性，为未来智能教育系统的发展提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 编程教育中自动化反馈的重要性日益增加，但现有研究常忽视关键教学原则（如掌握和进度适应性），这促使作者开发一个遵循教学原则的LLM驱动反馈系统。

**Method:** 提出一个结合既定反馈模型和中学教师本地洞察的新型教学框架，用于LLM驱动的反馈生成。基于此框架，开发了一个用于Python编程的LLM反馈网络应用，并对八名中学计算机科学教师进行了混合方法评估。

**Result:** 教师认为，当与所提框架对齐时，LLMs能有效支持学生，并通过即时和精确的反馈在某些情况下甚至优于人类教师。然而，也发现了一些局限性，如无法适应动态课堂环境。

**Conclusion:** 这项工作展示了在遵循教学标准的前提下有效使用LLMs进行反馈的方法，并强调了未来系统需要考虑的重要因素，特别是需要人类专业知识来补充LLM生成的反馈，以确保有效的学生学习。

> **ai_Abstract:** 本文提出一个新颖的教学框架，用于将大型语言模型（LLMs）整合到编程教育的反馈系统中，以解决现有自动化反馈系统忽视教学原则的问题。研究团队开发了一个基于该框架的Python编程网络应用，并对中学教师进行了评估。结果表明，LLMs在提供即时精确反馈方面表现出色，甚至在某些场景下优于人类教师，但其在适应动态课堂环境方面存在局限性，强调了人机协作的重要性。

> **摘要翻译:** 反馈是促进有效学习最关键的组成部分之一。近年来，随着大型语言模型（LLM）的兴起，编程教育领域的研究越来越关注自动化反馈生成，以帮助教师为每位学生提供及时支持。然而，先前的研究往往忽视了塑造有效反馈策略的关键教学原则，如掌握和进度适应性。本文引入了一个新颖的、源自既定反馈模型和中学教师本地洞察的、由LLM驱动的反馈生成教学框架。为了评估这个框架，我们实现了一个基于LLM反馈的Python编程网络应用程序，该程序遵循该框架，并与八名中学计算机科学教师进行了混合方法评估。我们的研究结果表明，教师认为，当与该框架对齐时，LLMs可以有效地支持学生，甚至在某些情况下通过即时和精确的反馈超越人类教师。然而，我们也发现了一些局限性，例如它无法将反馈适应动态课堂环境。这种局限性强调了需要用人类专业知识来补充LLM生成的反馈，以确保有效的学生学习。这项工作展示了一种在遵循教学标准的同时有效使用LLM进行反馈的方法，并强调了未来系统的重要考虑因素。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [116] [Teacher-AI Collaboration for Curating and Customizing Lesson Plans in Low-Resource Schools](https://arxiv.org/abs/2507.00456)
> *教师-AI协作在低资源学校中策划和定制教案*

*Deepak Varuvel Dennison, Bakhtawar Ahtisham, Kavyansh Chourasia, Nirmit Arora, Rahul Singh, Rene F. Kizilcec, Akshay Nambi, Tanuja Ganu, Aditya Vashistha* | **Category: cs.CY, cs.HC**

**Keywords:** 教师-AI协作, 教案规划, 低资源学校, 教育技术, Shiksha copilot

**Comment:** 

> **TL;DR:** AI辅助工具Shiksha copilot帮助低资源学校教师制定教案，减轻工作量并促进基于活动的教学，尽管存在系统性挑战。

**AI_Comments:** 这篇论文突出了AI在教育中的实际应用，特别是解决了低资源环境中的挑战。其创新之处在于展示了AI如何增强而非取代人类专业知识（教师和课程管理员），从而带来减轻工作量和改进教学方法等实实在在的好处。然而，它也现实地指出了AI本身无法克服的系统性障碍，强调了教育改革需要采取整体方法。对多语言和全球南方背景的关注尤其有价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查Shiksha copilot，一种在印度卡纳塔克邦公立学校部署的AI辅助教案工具，以了解教师与AI的协作、评估AI生成内容的质量，并分析多语言、低资源环境中教学实践的变化。

**Method:** 本研究采用大规模混合方法，涉及1,043名教师和23名课程管理员。研究考察了教育工作者如何与AI协作生成情境敏感的教案，并进一步定制这些教案。

**Result:** 研究发现，Shiksha copilot减轻了教师的行政工作量，缩短了教案规划时间，降低了教学相关压力，并促进了向基于活动的教学法的转变。然而，人员短缺和行政要求等系统性挑战限制了更广泛的教学法变革。

**Conclusion:** 本研究通过教师-AI协作和实践社区的视角来阐述研究发现，并为未来以教师为中心的教育技术，特别是在多语言和全球南方背景下的设计方向提出了建议。

> **ai_Abstract:** 本研究评估了Shiksha copilot，一种在印度低资源学校使用的AI辅助教案工具。研究发现该工具减轻了教师的行政负担，缩短了备课时间，并促进了基于活动的学习。尽管有这些益处，但人员短缺等系统性问题限制了更广泛的教学法变革。该研究为未来在类似背景下以教师为中心的教育技术设计提供了见解。

> **摘要翻译:** 本研究调查了Shiksha copilot，一种在印度卡纳塔克邦公立学校部署的AI辅助教案工具。该系统通过结构化过程结合了大型语言模型（LLMs）和人类专业知识，其中英文和卡纳达语教案由课程管理员和AI共同创建；教师随后在AI支持下，利用自己的专业知识进一步为课堂定制这些策划好的教案。我们基于一项涉及1,043名教师和23名课程管理员的大规模混合方法研究，考察了教育工作者如何与AI协作生成情境敏感的教案，评估AI生成内容的质量，并分析多语言、低资源环境中教学实践的变化。我们的研究结果表明，教师使用Shiksha copilot既满足了行政文档需求，也支持了他们的教学。该工具减轻了官僚工作量，缩短了教案规划时间，降低了教学相关压力，同时促进了向基于活动的教学法的转变。然而，人员短缺和行政要求等系统性挑战限制了更广泛的教学法变革。我们通过教师-AI协作和实践社区的视角来阐述这些发现，以考察AI工具在教学中的有效整合。最后，我们为未来以教师为中心的教育技术，特别是在多语言和全球南方背景下的设计方向提出了建议。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [37] [Ensemble Kalman Filter for Data Assimilation coupled with low-resolution computations techniques applied in Fluid Dynamics](https://arxiv.org/abs/2507.00539)
> *流体动力学中结合低分辨率计算技术的数据同化集合卡尔曼滤波*

*Paul Jeanney, Ashton Hetherington, Shady E. Ahmed, David Lanceta, Susana Saiz, José Miguel Perez, Soledad Le CLainche* | **Category: cs.CE, physics.flu-dyn, 62M20 (Primary) 65F30, 65C20, 76M12 (Secondary), G.1.3; G.3; I.6.3; G.1.10**

**Keywords:** 数据同化, 集合卡尔曼滤波, 降阶模型, 低分辨率计算, 流体动力学

**Comment:** article, 49 pages, 29 figures, 4 tables

> **TL;DR:** 该文提出了一种结合低分辨率计算和lcSVD的EnKF数据同化方法，显著降低了流体动力学系统状态估计的计算成本和内存消耗，同时保持了高精度。

**AI_Comments:** 该论文的创新点在于首次将低成本奇异值分解（lcSVD）应用于数据同化，并将其与集合卡尔曼滤波（EnKF）和低分辨率计算技术结合，以解决流体动力学中数据同化的高计算成本问题。其重要性在于提供了一种高效、低成本且准确的流体系统状态估计和预测方法，有望推动计算流体力学和实时应用的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据同化方法在流体动力学系统中估计“真实”状态时计算成本高昂，需要一种能够平衡准确性与计算效率的方法。

**Method:** 提出了一种创新的降阶模型（ROM），将集合卡尔曼滤波（EnKF）应用于降维框架。为降低计算成本，该方法采用低分辨率（LR）技术对数据集进行降采样，并结合基于低成本奇异值分解（lcSVD）的高级重建技术。lcSVD是首次应用于数据同化。

**Result:** 实验结果表明，LR技术显著减少了计算时间和RAM使用，同时没有损害估计精度。例如，在湍流测试中，压缩率为15.9的LR方法实现了13.7倍的加速和90.9%的RAM压缩，相对均方根误差（RRMSE）为2.6%（高分辨率参考为0.8%）。EnKF在基于有限观测和低保真数值数据估计和预测流体流动系统状态方面表现出有效性。

**Conclusion:** 所提出的数据同化方法在流体动力学应用中具有巨大潜力，特别是在提高计算流体力学（CFD）及相关领域的计算效率方面。它能够平衡精度与低计算和内存成本，适用于大规模和实时应用，如环境监测或航空航天。

> **ai_Abstract:** 本文提出了一种创新的降阶模型（ROM），结合集合卡尔曼滤波（EnKF）和低分辨率（LR）计算技术以及低成本奇异值分解（lcSVD）进行数据同化，旨在高效估计流体动力学系统的真实状态。该方法通过对数据集降采样和高效重建，显著降低了计算时间和内存消耗，同时保持了高精度，尤其适用于大规模和实时流体动力学应用。

> **摘要翻译:** 这篇论文提出了一种创新的降阶模型（ROM），用于通过数据同化（DA）融合实验和模拟数据，以估计流体动力学系统的“真实”状态，从而实现更准确的预测。我们的方法引入了一种新颖的方法，在降维框架内实现集合卡尔曼滤波（EnKF），该方法基于坚实的理论基础并应用于流体动力学。为解决数据同化巨大的计算需求，所提出的ROM采用低分辨率（LR）技术大幅降低计算成本。这种方法涉及对DA计算的数据集进行降采样，然后采用基于低成本奇异值分解（lcSVD）的高级重建技术。lcSVD方法是本文的一项关键创新，以前从未应用于DA，它提供了一种高效的方式，以最少的计算资源提高分辨率。我们的结果表明，通过LR技术，计算时间和RAM使用量均显著减少，而没有损害估计的准确性。例如，在一个湍流测试案例中，压缩率为15.9的LR方法可以实现13.7倍的加速和90.9%的RAM压缩，同时保持2.6%的低相对均方根误差（RRMSE），而高分辨率（HR）参考的RRMSE为0.8%。此外，我们强调了EnKF在基于有限观测和低保真数值数据估计和预测流体流动系统状态方面的有效性。本文强调了所提出的DA方法在流体动力学应用中的潜力，特别是对于提高CFD及相关领域的计算效率。其平衡精度与低计算和内存成本的能力使其适用于大规模和实时应用，如环境监测或航空航天。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [38] [Eilenberg correspondence for Stone recognition](https://arxiv.org/abs/2507.00409)
> *Eilenberg对应与Stone识别*

*Jorge Almeida, Ondřej Klíma* | **Category: cs.FL, 46H05 (Primary) 06E15, 08A62 (Secondary)**

**Keywords:** Eilenberg对应, Stone识别, 语言簇, 拓扑代数, 正则语言

**Comment:** 

> **TL;DR:** 本文提出了基于Stone拓扑代数的语言识别新方法，建立了语言簇与有序Stone拓扑代数簇之间的Eilenberg对应，并提供了一种判断语言不属于特定语言簇的通用方法。

**AI_Comments:** 本文通过引入Stone拓扑代数和拓扑学概念，对经典的Eilenberg对应进行了创新性的扩展，将语言识别的范畴从形式语言推广到更广义的拓扑代数子集。其重要性在于，该工作不仅建立了新的理论对应关系，而且提供了一种超越正则语言的分析框架，并提出了一种通用的、基于序列的语言非成员性证明方法，这对于理论计算机科学和形式语言理论具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发并探索一种新的语言识别方法，即通过连续同态映射到Stone拓扑代数中闭开集的原像来识别语言，并将其应用于超越经典正则语言的范畴。

**Method:** 通过将语言（拓扑代数子集）识别为Stone拓扑代数中闭开集的原像，建立了语言簇与有序Stone拓扑代数簇之间的Eilenberg对应。利用Birkhoff/Reiterman型定理证明后者可通过伪不等式定义。对于经典形式语言，通过将最小自动机视为一元代数并进行Stone完备化，扩展了框架以超越正则语言。

**Result:** 获得了语言簇与有序Stone拓扑代数簇之间的Eilenberg对应。证明了后者可以通过某些伪不等式定义（Birkhoff/Reiterman型定理）。展示了该扩展框架如何通过处理最小自动机的Stone完备化来超越正则语言的范畴。

**Conclusion:** 本文提供了一种判断语言不属于特定语言簇的通用方法，该方法以词对序列的形式表达，并在上下文无关语言的有限交集类中进行了说明。

> **ai_Abstract:** 本文提出了一种基于Stone拓扑代数的新型语言识别框架，将语言识别为Stone拓扑代数中闭开集的原像。研究建立了语言簇与有序Stone拓扑代数簇之间的Eilenberg对应，并通过Birkhoff/Reiterman型定理展示了后者的定义方式。特别地，对于形式语言，该框架通过最小自动机的Stone完备化，能够超越传统正则语言的界限。此外，文章还提出了一种通用方法，用于证明语言不属于特定语言簇，并以上下文无关语言的有限交集为例进行了阐述。

> **摘要翻译:** 我们发展并探索了将语言（广义上指拓扑代数的子集）识别为连续同态映射到Stone拓扑代数中闭开集原像的想法。我们获得了语言簇与有序Stone拓扑代数簇之间的Eilenberg对应，以及一个Birkhoff/Reiterman型定理，表明后者可以通过某些伪不等式定义。对于经典的形式语言，即有限字母表上的词，我们还展示了该扩展框架如何通过使用最小自动机（视为一元代数）的Stone完备化来超越正则语言的范畴。这导致了一种通用方法，用于证明语言不属于某个语言簇，该方法以词对序列的形式表达，并在该类包含所有上下文无关语言的有限交集时进行了说明。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [59] [EMSpice 2.1: A Coupled EM and IR Drop Analysis Tool with Joule Heating and Thermal Map Integration for VLSI Reliability](https://arxiv.org/abs/2507.00270)
> *EMSpice 2.1：一款集成焦耳热和热图的VLSI可靠性耦合电迁移与IR压降分析工具*

*Subed Lamichhane, Haotian Lu, Sheldon X. -D. Tan* | **Category: eess.SY, cs.SY**

**Keywords:** 电迁移, IR压降, 焦耳热, 热图, VLSI可靠性

**Comment:** 4 Pages, accepted to SMACD 2025

> **TL;DR:** EMSpice 2.1 是一款新的工具，它首次将焦耳热效应和实际热图集成到电迁移（EM）和IR压降分析中，以提高VLSI电路的可靠性分析精度和效率。

**AI_Comments:** EMSpice 2.1的创新之处在于首次将焦耳热效应和实际热图集成到EM和IR压降分析中，这解决了现有工具未能充分考虑温度影响的局限性。其与商业EDA工具的互操作性增强了实用性。此外，该工具在保持高精度的同时实现了显著的加速，对于VLSI可靠性签核分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 电迁移（EM）是当前和未来铜基超大规模集成电路（VLSI）中的一个关键可靠性问题。随着技术尺寸的缩小，EM引起的IR压降变得越来越严重。现有的EM-aware IR压降分析工具很少考虑到温度分布对EM和IR压降效应的实际影响。

**Method:** 本研究介绍了EMSpice 2.1，一个在现有耦合IR-EM分析框架EMSpice 2.0基础上增强的工具，用于EM-aware IR压降分析。EMSpice 2.1首次独特地集成了焦耳热效应和从实际芯片条件导出的实用热图。此外，它还改进了与商业EDA工具的互操作性，从而促进了更全面的EM和IR压降签核分析。

**Result:** 研究结果表明，特定的热点模式显著影响互连线的寿命和由于EM故障导致的整体芯片可靠性。此外，该工具与COMSOL等行业标准工具高度一致，实现了超过200倍的加速，同时保持了高精度。

**Conclusion:** EMSpice 2.1通过集成焦耳热和实际热图，显著提高了VLSI电路中EM和IR压降分析的准确性和效率，对芯片可靠性分析具有重要意义。

> **ai_Abstract:** EMSpice 2.1是一款增强型工具，用于VLSI电路的电迁移（EM）感知IR压降分析。该工具首次将焦耳热效应和实际芯片热图集成到EM-IR分析框架中，并提高了与商业EDA工具的互操作性。研究表明，热点模式对互连寿命和芯片可靠性有显著影响。EMSpice 2.1在保持高精度的同时，比行业标准工具COMSOL快200多倍。

> **摘要翻译:** 电迁移（EM）仍然是当前和未来铜基超大规模集成电路（VLSI）中的一个关键可靠性问题。随着技术尺寸的缩小，EM引起的IR压降变得越来越严重。虽然已经提出了几种考虑EM的IR压降分析工具，但很少有工具能将温度分布对EM和IR压降效应的实际影响纳入其中。在这项工作中，我们介绍了EMSpice 2.1，一个在现有耦合IR-EM分析框架EMSpice 2.0基础上增强的工具，用于电迁移感知的IR压降分析。EMSpice 2.1首次独特地集成了焦耳热效应和从实际芯片条件导出的实用热图。此外，它还改进了与商业EDA工具的互操作性，从而促进了更全面的EM和IR压降签核分析。我们的研究结果表明，特定的热点模式由于EM故障而显著影响互连线的寿命和整体芯片可靠性。此外，我们的工具与COMSOL等行业标准工具高度一致，实现了超过200倍的加速，同时保持了高精度。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [79] [Iteratively Saturated Kalman Filtering](https://arxiv.org/abs/2507.00272)
> *迭代饱和卡尔曼滤波*

*Alan Yang, Stephen Boyd* | **Category: eess.SY, cs.SY**

**Keywords:** 卡尔曼滤波器, 鲁棒估计, 异常值, 迭代, 实时系统

**Comment:** 

> **TL;DR:** 提出了一种迭代饱和卡尔曼滤波器（ISKF），它能有效抵抗测量和过程噪声中的异常值，同时保持卡尔曼滤波器的低成本和简单性。

**AI_Comments:** 这篇论文的创新点在于提出了一种对异常值鲁棒的卡尔曼滤波变体，即ISKF。它通过将问题重新表述为凸鲁棒估计问题并使用尺度梯度方法求解，有效地解决了传统KF在存在异常值时性能下降的问题。更重要的是，ISKF保持了KF的计算效率和简单性，特别是其低迭代次数和稳态变体，使其在实际应用，尤其是实时系统中具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 标准卡尔曼滤波器（KF）虽然是线性高斯系统的最优状态估计器，但容易受到测量和过程噪声中异常值的影响。

**Method:** 引入了迭代饱和卡尔曼滤波器（ISKF），它被推导为求解凸鲁棒估计问题的尺度梯度方法。它通常只需一到两次迭代就能达到良好性能，并且有一个稳态变体，不需要每步进行线性系统求解。

**Result:** ISKF在实现异常值鲁棒性的同时，保留了KF的低每步成本和实现简单性。在实践中，通常只需一到两次迭代即可获得良好性能。其稳态变体适用于实时系统。

**Conclusion:** ISKF提供了一种对异常值鲁棒的卡尔曼滤波变体，同时保持了原始KF的计算效率和简单性，使其适用于各种应用，特别是实时系统。

> **ai_Abstract:** 本文提出了一种名为迭代饱和卡尔曼滤波器（ISKF）的新方法，旨在解决传统卡尔曼滤波器（KF）对测量和过程噪声中异常值敏感的问题。ISKF被推导为一种求解凸鲁棒估计问题的尺度梯度方法，它在提供异常值鲁棒性的同时，保持了KF原有的低计算成本和实现简易性，并且通常只需少量迭代即可达到良好性能。此外，ISKF还具有适用于实时系统的稳态变体。

> **摘要翻译:** 卡尔曼滤波器（KF）为线性高斯系统提供了最优递归状态估计，并支撑着控制、信号处理等领域的应用。然而，它容易受到测量和过程噪声中异常值的影响。我们引入了迭代饱和卡尔曼滤波器（ISKF），它被推导为求解凸鲁棒估计问题的尺度梯度方法。它在实现异常值鲁棒性的同时，保留了KF的低每步成本和实现简单性，因为在实践中，它通常只需一到两次迭代就能获得良好性能。ISKF还支持一种稳态变体，与标准稳态KF一样，不需要在每个时间步进行线性系统求解，使其非常适合实时系统。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [100] [Augmented Physics-Based Li-ion Battery Model via Adaptive Ensemble Sparse Learning and Conformal Prediction](https://arxiv.org/abs/2507.00353)
> *经自适应集成稀疏学习和共形预测增强的基于物理的锂离子电池模型*

*Samuel Filgueira da Silva, Mehmet Fatih Ozkan, Faissal El Idrissi, Marcello Canova* | **Category: eess.SY, cs.LG, cs.SY**

**Keywords:** 锂离子电池, 降阶模型, 自适应集成稀疏识别, 共形预测, 不确定性量化

**Comment:** 

> **TL;DR:** 本文提出了一种自适应集成稀疏识别（AESI）框架，通过集成扩展单粒子模型（ESPM）和进化集成稀疏学习，增强了锂离子电池降阶模型的预测精度和可靠性，并利用共形预测提供了不确定性量化。

**AI_Comments:** 这篇论文的创新点在于结合了物理模型（ESPM）、机器学习（自适应集成稀疏学习）和不确定性量化（共形预测），形成了一个鲁棒的混合模型。这种方法不仅提高了锂离子电池模型在复杂条件下的预测精度，更重要的是提供了理论上保证的不确定性量化，这对于电池管理系统中的安全性和可靠性至关重要。该框架为提升电池模型在实际应用中的性能提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的锂离子电池降阶模型（ROM）在捕捉复杂非线性行为（如高C倍率下的电池电压响应动态）方面存在局限性，影响了其在电动汽车和电网储能等实际应用中的安全高效运行。

**Method:** 提出了一种自适应集成稀释识别（AESI）框架。该框架将扩展单粒子模型（ESPM）与进化集成稀疏学习策略相结合，构建了一个鲁棒的混合模型。此外，AESI框架还引入了共形预测方法，为电压误差动态提供理论上保证的不确定性量化。

**Result:** 混合模型（ESPM + AESI）在不同操作条件下评估，将未见数据的电压预测均方误差降低了高达46%。共形预测进一步支持了预测的可靠性，基于bagging和稳定性选择的集成模型分别获得了96.85%和97.41%的统计有效预测区间覆盖率。

**Conclusion:** 通过结合自适应集成稀疏学习和共形预测，可以显著提高锂离子电池降阶模型的预测精度和可靠性，尤其是在处理复杂非线性动态和提供不确定性量化方面。

> **ai_Abstract:** 本文提出了一种名为自适应集成稀疏识别（AESI）的新框架，旨在解决锂离子电池降阶模型在捕捉复杂非线性行为方面的局限性。AESI通过将扩展单粒子模型（ESPM）与进化集成稀疏学习相结合，构建了一个混合模型，并利用共形预测提供不确定性量化。实验结果显示，该混合模型显著提高了电压预测精度（均方误差降低高达46%），并提供了高覆盖率的可靠预测区间。

> **摘要翻译:** 准确的电化学模型对于锂离子电池在电动汽车和电网储能等实际应用中的安全高效运行至关重要。降阶模型（ROM）在保真度和计算效率之间取得了平衡，但通常难以捕捉复杂和非线性的行为，例如高C倍率条件下电池电压响应的动态。为了解决这些局限性，本研究提出了一种自适应集成稀疏识别（AESI）框架，通过补偿不可预测的动态来提高降阶锂离子电池模型的准确性。该方法将扩展单粒子模型（ESPM）与进化集成稀疏学习策略相结合，构建了一个鲁棒的混合模型。此外，AESI框架还结合了共形预测方法，为电压误差动态提供理论上保证的不确定性量化，从而提高了模型预测的可靠性。在不同操作条件下的评估表明，混合模型（ESPM + AESI）提高了电压预测精度，在未见数据上的均方误差降低了高达46%。共形预测进一步支持了预测的可靠性，基于bagging和稳定性选择的集成模型分别获得了96.85%和97.41%的统计有效预测区间覆盖率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [124] [Minimal Construction of Graphs with Maximum Robustness](https://arxiv.org/abs/2507.00415)
> *具有最大鲁棒性的图的最小构造*

*Haejoon Lee, Dimitra Panagou* | **Category: eess.SY, cs.SI, cs.SY**

**Keywords:** 网络鲁棒性, 最小边数, 图构造, 弹性控制, MERGs

**Comment:** 

> **TL;DR:** 本文研究在有限资源下，如何用最少边数构建具有最大r-鲁棒性和(r,s)-鲁棒性的图。

**AI_Comments:** 本文的创新点在于，在保证网络鲁棒性的前提下，通过数学推导和图构造，找到了最小化网络通信结构（边数）的方法，这对于资源受限的分布式系统具有重要的理论和实际意义。它平衡了网络性能和资源消耗。

<details>
  <summary>Details</summary>

**Motivation:** 网络r-鲁棒性和(r,s)-鲁棒性用于实现存在恶意代理时的弹性控制。然而，高鲁棒性需要密集的通信结构，这对于能力和能量有限的系统来说是不可取的。因此，需要研究在最小化边数的同时实现最大鲁棒性的方法。

**Method:** 本文首先探索并建立了无向图实现最大r-鲁棒性和(r,s)-鲁棒性所需的边数的紧密必要条件。然后，利用这些条件构造了两类无向图，即γ-和(γ,γ)-最小边鲁棒图（MERGs），这些图被证明能以最少边数实现最大鲁棒性。最后通过仿真验证了工作。

**Result:** 本文建立了实现最大r-鲁棒性和(r,s)-鲁棒性所需的边数的紧密必要条件，并构造了两种新型的最小边鲁棒图（MERGs），这些图在最小化边数的同时实现了最大鲁棒性。

**Conclusion:** 本文成功地解决了在资源受限系统中，如何在保持网络最大鲁棒性的同时，通过最小化通信结构（边数）来提高效率的问题。

> **ai_Abstract:** 本文旨在解决在有限资源下，实现网络最大r-鲁棒性和(r,s)-鲁棒性所需密集通信结构的问题。研究通过建立无向图实现最大鲁棒性所需的边数的紧密必要条件，并在此基础上构造了两类新的图——γ-和(γ,γ)-最小边鲁棒图（MERGs），这些图被证明能在最小化边数的同时达到最大鲁棒性。仿真验证了所提方法。

> **摘要翻译:** 网络r-鲁棒性和(r,s)-鲁棒性的概念在文献中已被引入，以在存在恶意代理的情况下实现弹性控制。然而，尽管更高的鲁棒性水平为网络提供了更高的对抗恶意代理的容忍度，但它们也需要密集的通信结构，这对于能力和能量有限的系统来说并不总是可取的。因此，本文以两种不同方式研究了r-鲁棒性和(r,s)-鲁棒性特性背后的基本结构。(a)我们首先探索并建立了任何节点数的无向图实现最大r-和(r,s)-鲁棒性所需的边数的紧密必要条件。(b)然后，我们利用这些条件构造了两类无向图，分别称为γ-和(γ,γ)-最小边鲁棒图（MERGs），这些图被证明能够以最少边数实现最大鲁棒性。最后，我们通过一些仿真集验证了我们的工作。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [145] [Multi-Agent Coordination under Poisson Observations: A Global Game Approach](https://arxiv.org/abs/2507.00424)
> *多智能体泊松观测下的协调：一种全局博弈方法*

*Marcos M. Vasconcelos, Behrouz Touri* | **Category: eess.SY, cs.SY**

**Keywords:** 全局博弈, 多智能体协调, 泊松观测, 贝叶斯纳什均衡, 群体感应系统

**Comment:** 

> **TL;DR:** 该研究基于全局博弈模型，探讨了泊松观测下多智能体战略协调问题，证明了贝叶斯纳什均衡的存在性，并通过分析无限智能体系统的势函数简化了计算，可应用于细菌群体感应系统。

**AI_Comments:** 该论文的创新点在于将全局博弈理论应用于泊松观测下的多智能体协调问题，并提出了通过分析无限智能体系统势函数来简化有限智能体系统均衡计算的巧妙方法。这为处理具有不完全信息和噪声观测的复杂协调问题提供了一个有价值的理论框架，尤其是在生物系统建模方面具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决在泊松分布信号和伽马先验分布假设下，具有不完全信息的全局博弈中多智能体战略协调的问题，特别是找到贝叶斯纳什均衡。同时，该方法也适用于模拟细菌群体感应系统。

**Method:** 研究基于全局博弈模型，假设信号服从泊松分布，系统状态服从伽马先验分布。通过分析具有可数无限多个智能体的博弈势函数，证明了阈值策略下贝叶斯纳什均衡的存在性。对于有限智能体系统，通过数值例子展示了势函数是单峰的。

**Result:** 在泊松信号和伽马先验分布假设下，证明了在智能体行动线性效用函数的阈值策略中存在贝叶斯纳什均衡。通过分析可数无限多个智能体的博弈势函数，使得原先在有限智能体系统中难以计算的问题变得可处理。数值例子表明，所得势函数是单峰的，并具有明确的最大值。

**Conclusion:** 该研究为泊松观测下的多智能体协调问题提供了一种全局博弈方法，通过分析无限智能体系统简化了均衡的计算，并证明了贝叶斯纳什均衡的存在性，为细菌群体感应系统等实际应用提供了理论基础。

> **ai_Abstract:** 该论文研究了泊松观测下多智能体战略协调的全局博弈模型。在泊松信号和伽马先验分布假设下，证明了线性效用函数下阈值策略中贝叶斯纳什均衡的存在性。论文通过分析可数无限智能体系统的势函数，解决了有限智能体系统中均衡计算的复杂性问题，并通过数值例子验证了势函数的单峰性。该研究成果可应用于细菌群体感应系统的建模。

> **摘要翻译:** 我们研究了一种基于不完全信息博弈（称为全局博弈）的战略协调模型。在泊松分布信号和系统状态伽马先验分布的假设下，我们证明了在智能体行动线性效用函数的阈值策略中存在贝叶斯纳什均衡。尽管在有限智能体系统中计算构成均衡的精确阈值是一项非常复杂的任务，但通过分析具有可数无限多个智能体的博弈势函数，这个问题变得易于处理。通过数值例子，我们提供了证据表明所得势函数是单峰的，并表现出明确的最大值。我们的结果适用于细菌群体感应系统的建模，其噪声观测信号通常可以用泊松过程很好地近似。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [166] [The impact of the following vehicles behaviors on the car following behaviors of the ego-vehicle](https://arxiv.org/abs/2507.00452)
> *后车行为对自车跟驰行为的影响*

*Yang Liu, Jiahao Zhang, Yuxuan Ouyang, Huan Yu, Dengbo He* | **Category: eess.SY, cs.SY**

**Keywords:** 跟驰行为, 后车影响, 同伴压力, 逆强化学习, highD数据集

**Comment:** 

> **TL;DR:** 本研究基于highD数据集，探讨后车（FV）的行为如何影响自车（ego-vehicle）的跟驰（CF）行为。研究发现，在被后车紧跟时，自车驾驶员会调整跟驰行为，与前车保持更近距离，但同时更谨慎驾驶。

**AI_Comments:** 本文的创新之处在于突破了传统跟驰模型仅关注前车的局限性，首次深入探讨了后车对自车跟驰行为的影响，并引入了“同伴压力”这一新颖视角。通过结合统计分析和逆强化学习，为理解驾驶员在复杂交通环境下的决策提供了新的思路。研究结果对于提升交通流模型的准确性和开发更智能的驾驶辅助系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在所有交通事故中，追尾事故占主导地位，这与跟驰行为密切相关。传统的跟驰行为模型只关注前车的影响，但通常忽略了来自周围道路使用者（包括后车）的同伴压力。因此，本研究旨在调查后车状态是否会影响自车在跟驰事件中的跟驰行为。

**Method:** 本研究基于开放数据集highD，从中提取了两种跟驰事件：跟尾事件（后车与自车之间的时间间隙小于1秒）和有间隙事件（时间间隙大于3秒）。利用动态时间规整（DTW）提取了前车速度曲线相似的跟驰对。通过统计分析比较了跟尾事件和有间隙事件中的跟驰性能指标。随后，使用逆强化学习（IRL）恢复了不同跟驰事件中自车驾驶员的奖励函数。

**Result:** 结果表明，自车驾驶员会通过与前车保持更近的距离，但同时更谨慎地驾驶，来响应后车紧跟的压力。此外，即使在被后车紧跟的情况下，驾驶员仍然能够根据交通流速度和与前车的距离来调整其跟驰策略。

**Conclusion:** 这些发现为通过考虑来自周围道路使用者的同伴压力，更准确地建模交通流提供了见解。

> **ai_Abstract:** 本研究利用highD数据集，探讨了后车行为对自车跟驰行为的影响。研究发现，与传统模型不同，后车的“同伴压力”显著影响自车驾驶员的跟驰策略。具体而言，在被后车紧跟时，自车驾驶员会更靠近前车，但会表现出更谨慎的驾驶行为。即使在这种情况下，驾驶员仍能根据交通流速度和与前车的距离调整其策略。这些发现强调了在交通流建模中考虑后车影响的重要性，以提高模型的准确性。

> **摘要翻译:** 在所有类型的碰撞事故中，追尾事故占主导地位，这与跟驰（CF）行为密切相关。传统的跟驰行为模型侧重于前车的影响，但通常忽略了来自周围道路使用者，包括后车（FV）的同伴压力。基于开放数据集highD，我们研究了后车状态是否会影响自车在跟驰事件中的跟驰行为。从highD数据库中提取了两种类型的跟驰事件，包括跟尾事件（后车与自车之间的时间间隙小于1秒）和有间隙事件（时间间隙大于3秒）。动态时间规整用于提取前车（LV）速度曲线相似的跟驰对。进行了统计分析以比较跟尾事件和有间隙事件中的跟驰性能指标。然后，使用逆强化学习来恢复不同跟驰事件中自车驾驶员的奖励函数。结果表明，自车驾驶员会调整其跟驰行为以响应来自紧跟后车的压力，通过与前车保持更近的距离，但同时更谨慎地驾驶。此外，即使在被紧跟的情况下，驾驶员仍然能够根据交通流速度和与前车的距离来调整其跟驰策略。这些发现为通过考虑来自周围道路使用者的同伴压力，更准确地建模交通流提供了见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [184] [Price Aware Power Split Control in Heterogeneous Battery Storage Systems](https://arxiv.org/abs/2507.00628)
> *异构电池储能系统中价格感知功率分配控制*

*Sheng Yin, Vivek Teja Tanjavooru, Thomas Hamacher, Christoph Goebel, Holger Hesse* | **Category: eess.SY, cs.SY**

**Keywords:** 电池储能系统, 功率分配, 价格感知, 线性规划, 强化学习

**Comment:** 

> **TL;DR:** 本文提出了一个统一的框架，用于优化电池储能系统（BESS）的调度和内部功率分配，整合了市场信号和物理约束，并比较了基于模型的线性规划（LP）和无模型的强化学习（RL）方法。

**AI_Comments:** 本文的创新之处在于提出了一个统一的框架，将市场信号与物理约束相结合，同时优化BESS的外部调度和内部异构性管理。通过比较LP和RL两种截然不同的优化方法，并详细分析它们在经济效益、效率和内部平衡方面的优缺点，为BESS的实际应用提供了宝贵的指导。尤其是其强调了RL在动态环境下的适应性，为未来的实时控制提供了可行方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在优化电池储能系统（BESS）的外部能量调度和内部异构性管理，以提高其运行经济价值和性能，通过整合市场（价格感知）信号和物理系统约束来实现。

**Method:** 本文提出了一个统一的框架，用于优化BESS的电池调度和内部功率分配。该方法整合了市场信号和物理系统约束。研究比较了在不同预测假设下，基于模型的线性规划（LP）和无模型的强化学习（RL）两种优化方法，并使用定制的基于Gym的仿真环境进行评估。评估考虑了长期和短期性能，重点关注经济节约、荷电状态（SOC）和温度平衡以及整体系统效率。

**Result:** 长期结果显示，RL方法实现了比LP高10%的系统效率，而LP带来了高33%的累积节约。在内部异构性方面，LP方法导致较低的平均SOC不平衡，而RL方法在电池串之间实现了更好的温度平衡。短期评估表明，LP在已知和稳定条件下表现出强大的优化能力，而RL在动态环境中表现出更高的适应性。

**Conclusion:** 线性规划（LP）在已知稳定条件下能提供强大的优化，并带来更高的累积经济节约和更低的SOC不平衡；而强化学习（RL）在动态环境中表现出更高的适应性，并能实现更高的系统效率和更好的温度平衡，为实时BESS控制提供了潜在优势。

> **ai_Abstract:** 本文提出了一个优化异构电池储能系统（BESS）调度和内部功率分配的统一框架。该方法结合了市场价格信号和物理约束，旨在同时优化外部能量调度和内部异构性管理，以提升经济效益和性能。研究比较了线性规划（LP）和强化学习（RL）两种方法在不同预测下的表现。结果显示，长期来看，RL在系统效率上优于LP，而LP在累积经济节约上表现更佳。在内部异构性管理方面，LP在SOC平衡上表现更好，RL在温度平衡上更优。短期评估进一步指出，LP适用于稳定条件，而RL在动态环境中展现出更高的适应性。

> **摘要翻译:** 本文提出了一个统一的框架，用于优化电池储能系统（BESS）的电池调度和内部功率分配。这种新颖的方法整合了基于市场（价格感知）的信号和物理系统约束，以同时优化（1）外部能量调度和（2）BESS的内部异构性管理，从而提高其运行经济价值和性能。这项工作比较了在不同预测假设下，基于模型的线性规划（LP）和无模型的强化学习（RL）两种优化方法，并使用定制的基于Gym的仿真环境。评估考虑了长期和短期性能，重点关注经济节约、荷电状态（SOC）和温度平衡以及整体系统效率。总而言之，长期结果显示，RL方法实现了比LP高10%的系统效率，而LP带来了高33%的累积节约。在内部异构性方面，LP方法导致较低的平均SOC不平衡，而RL方法在电池串之间实现了更好的温度平衡。这种行为在短期评估中得到了进一步验证，表明LP在已知和稳定条件下能提供强大的优化，而RL在动态环境中表现出更高的适应性，为实时BESS控制提供了潜在优势。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [203] [Getting Dynamic Line Ratings into Markets](https://arxiv.org/abs/2507.00826)
> *将动态线路额定值引入市场*

*Zhiyi Zhou, Christoph Graf, Yury Dvorkin* | **Category: eess.SY, cs.SY**

**Keywords:** 动态线路额定值, 电力市场, 最优潮流, 不确定性, 边际定价

**Comment:** 

> **TL;DR:** 该论文提出了一种将动态线路额定值（DLRs）整合到电力市场中的方法，通过将其建模为具有时变相互依赖性的资源，并将其纳入多周期直流最优潮流问题中，以提高线路利用率并优化调度和定价。

**AI_Comments:** 该论文的创新之处在于将DLRs建模为具有时变相互依赖性的类库存资源，并将其与考虑不确定性的多周期最优潮流问题相结合，通过线性化解决了非凸性问题。这为DLRs在电力市场中的实际应用提供了可行的操作工具，对于提高电网效率、降低运营成本和减少碳排放具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 静态输电线路额定值可能导致线路容量利用不足，因为它们基于过于保守（最坏情况）的假设。尽管动态线路额定值（DLRs）等电网增强技术在技术经济上是可行的，但其采用缓慢，部分原因是缺乏能有效考虑对调度和定价同时影响的运营工具。

**Method:** 将动态线路额定值（DLRs）表示为具有时变相互依赖性的类库存资源，通过近似线路温度演化过程进行建模，从而解耦环境天气条件和潮流对输电线路温度和容量的影响。将DLRs集成到多周期直流最优潮流问题中，并使用机会约束来处理DLRs和可再生能源发电中相关的202不确定性。通过线性化将非凸问题转换为可处理的凸形式。推导了与竞争均衡一致的边际电能和辅助服务价格。

**Result:** 在11区和1814节点NYISO系统上的数值实验证明了其性能，包括对调度、定价和边际碳排放的影响。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文旨在解决静态输电线路额定值导致容量利用不足的问题，并促进动态线路额定值（DLRs）的采用。作者提出了一种将DLRs建模为类库存资源的方法，并将其集成到考虑不确定性的多周期直流最优潮流问题中。通过线性化将非凸问题转化为凸形式，并推导了与竞争均衡一致的边际价格。在NYISO系统上的实验表明，该方法能有效影响调度、定价和碳排放。

> **摘要翻译:** 静态输电线路额定值可能由于过于保守（最坏情况）的假设而导致线路容量利用不足。动态线路额定值（DLRs）等电网增强技术，根据实时条件调整线路容量，是提高现有电力线路利用率的技术经济上可行的替代方案。然而，它们的采用一直缓慢，部分原因是缺乏能有效考虑对调度和定价同时影响的运营工具。在本文中，我们将具有DLRs的输电容量表示为具有时变相互依赖性的类库存资源，通过近似线路温度演化过程进行建模，从而解耦环境天气条件和潮流对输电线路温度和容量的影响。我们将DLRs集成到多周期直流最优潮流问题中，并使用机会约束来处理DLRs和可再生能源发电中相关的202不确定性。这产生了非凸问题，我们通过线性化将其转换为可处理的凸形式。我们推导了与竞争均衡一致的边际电能和辅助服务价格。在11区和1814节点NYISO系统上的数值实验证明了其性能，包括对调度、定价和边际碳排放的影响。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [219] [Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite](https://arxiv.org/abs/2507.00877)
> *可验证的自然语言到线性时序逻辑翻译：一个基准数据集和评估套件*

*William H English, Chase Walker, Dominic Simon, Sumit Kumar Jha, Rickard Ewetz* | **Category: eess.SY, cs.CL, cs.SY**

**Keywords:** 自然语言处理, 线性时序逻辑, 基准数据集, 可验证性, 接地

**Comment:** 

> **TL;DR:** 引入VLTL-Bench，一个用于评估自然语言到线性时序逻辑翻译系统可验证性的新基准数据集，解决了现有基准忽视命题接地的缺点。

**AI_Comments:** 这篇论文通过引入VLTL-Bench，解决了自然语言到时序逻辑翻译领域一个重要的评估盲点，即“接地能力”和“可验证性”。现有基准未能充分评估系统将逻辑命题与具体环境关联的能力，导致性能指标失真。VLTL-Bench的创新之处在于其对接地和验证的强调，并提供了分解评估的机制，这将有助于推动该领域更鲁棒和可泛化的方法发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有自然语言到时序逻辑翻译系统的评估只关注翻译准确性，忽略了原子命题在新场景中的接地能力，这对于在具体状态空间中验证公式至关重要，且现有数据集常导致性能虚高。

**Method:** 引入了Verifiable Linear Temporal Logic Benchmark (VLTL-Bench)，这是一个统一的基准数据集，用于测量自动化自然语言到线性时序逻辑翻译的验证和可验证性。该数据集包含三个独特的状态空间、数千种自然语言规范及其对应的形式化时序逻辑规范，以及用于验证时序逻辑表达式的样本轨迹。它支持端到端评估，并为分解过程中的子步骤（提升、接地、翻译、验证）提供真实标签。

**Result:** 论文介绍了VLTL-Bench，一个旨在解决现有NL-to-TL翻译评估中接地能力不足的新基准数据集。该数据集提供了多样的自然语言和形式化规范，以及验证轨迹，并支持对翻译过程各阶段的评估。

**Conclusion:** VLTL-Bench的发布旨在鼓励在可验证的自然语言到线性时序逻辑翻译方法方面取得方法论上的进步，通过提供一个统一的、考虑接地和可验证性的评估框架。

> **ai_Abstract:** 本文针对现有自然语言到时序逻辑翻译系统评估中忽视原子命题接地能力的问题，提出了VLTL-Bench基准数据集。该数据集包含多样的自然语言和形式化时序逻辑规范，以及用于验证的样本轨迹，旨在统一衡量翻译系统的验证性和可验证性。VLTL-Bench不仅支持端到端评估，还为翻译过程的各个子步骤（如提升、接地、翻译、验证）提供了真实标签，以促进相关研究的进展。

> **摘要翻译:** 现有最先进的自然语言（NL）到时序逻辑（TL）翻译系统在现有基准测试中表现出近乎完美的性能。然而，当前的研究只测量自然语言逻辑翻译成形式化时序逻辑的准确性，而忽略了系统将原子命题接地到新场景或环境的能力。这是一个关键特性，对于在具体状态空间中验证所得公式是必需的。因此，大多数自然语言到时序逻辑翻译框架都提出了自己的定制数据集，其中正确的接地是先验已知的，这夸大了性能指标，并忽视了对可扩展、领域通用系统的需求。在本文中，我们引入了可验证线性时序逻辑基准（VLTL-Bench），这是一个统一的基准，用于测量自动化自然语言到线性时序逻辑翻译的验证和可验证性。该数据集包含三个独特的状态空间和数千种多样的自然语言规范以及相应的时序逻辑形式化规范。此外，该基准包含样本轨迹以验证时序逻辑表达式。虽然该基准直接支持端到端评估，但我们观察到许多框架将过程分解为：i）提升，ii）接地，iii）翻译，和iv）验证。该基准在这些步骤中的每一步之后都提供了真实标签，以使研究人员能够改进和评估整个问题的不同子步骤。为了鼓励在可验证的自然语言到线性时序逻辑翻译方法中取得方法论上的进展，我们在此发布VLTL-Bench：https://www.kaggle.com/datasets/dubascudes/vltl_bench。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [233] [Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks](https://arxiv.org/abs/2507.00902)
> *星座即服务：直接卫星到设备网络中的定制化连接管理*

*Feng Wang, Shengyu Zhang, Een-Kee Hong, Tony Q. S. Quek* | **Category: eess.SY, cs.AI, cs.SY, eess.SP**

**Keywords:** DS2D通信, 星座即服务, 多星座, 连接管理, 生成式AI

**Comment:** To appear in IEEE Communications Magazine

> **TL;DR:** 本文提出了一个名为“星座即服务”（CaaS）的框架，用于在多星座环境中高效管理直接卫星到设备（DS2D）连接，通过动态形成最优子星座来提供定制化连接，并利用生成式AI进行预测性波束赋形和预配置切换路径，显著提升服务速率并减少切换开销。

**AI_Comments:** 本文提出的CaaS框架通过将多星座视为共享资源池并动态形成子星座，为DS2D通信提供了创新的连接管理方法。其亮点在于引入生成式AI进行预测性波束赋形，以及预配置切换路径以优化移动性管理，这对于解决高干扰和频繁切换问题具有重要意义。该方案旨在充分挖掘多星座潜力，克服了现有单一星座解决方案的局限性，提升了服务性能。

<details>
  <summary>Details</summary>

**Motivation:** 直接卫星到设备（DS2D）通信在扩展全球移动服务方面前景广阔，但多星座DS2D连接管理面临挑战，包括高干扰、频繁切换以及现有方法局限于单一星座壳层，导致DS2D服务性能不佳。

**Method:** 本文提出了一个“星座即服务”（CaaS）框架。该框架将整个多星座基础设施视为共享资源池，并为每个DS2D服务区域动态形成最优子星座（SCs）。每个子星座的形成整合了来自不同轨道的卫星，以根据用户需求提供定制化连接。该框架由两种创新策略指导：使用生成式人工智能（GenAI）的预测性卫星波束赋形和用于高效卫星接入和移动管理的预配置切换路径。

**Result:** 仿真结果表明，CaaS显著提高了卫星服务速率，同时减少了切换开销。

**Conclusion:** CaaS是一个高效且可持续的解决方案，用于在多星座环境中管理DS2D连接。

> **ai_Abstract:** 本文提出“星座即服务”（CaaS）框架，旨在解决多星座直接卫星到设备（DS2D）通信中连接管理效率低下的问题。CaaS将多星座基础设施视为共享资源，并为DS2D服务区域动态形成最优子星座，以提供定制化连接。通过结合生成式AI的预测性波束赋形和预配置切换路径，该框架显著提升了卫星服务速率并降低了切换开销，为多星座DS2D环境提供了高效、可持续的连接管理方案。

> **摘要翻译:** 直接卫星到设备（DS2D）通信正作为全球移动服务扩展的一种有前景的解决方案而兴起，这得益于卫星星座的部署。然而，多星座DS2D连接管理的挑战变得突出，包括多覆盖重叠和快速卫星移动导致的高干扰和频繁切换。此外，现有方法主要在单一星座壳层内运行，这本身限制了利用多星座连接提供巨大潜力的能力，导致次优的DS2D服务性能。为了应对这些挑战，本文提出了一个“星座即服务”（CaaS）框架，该框架将整个多星座基础设施视为共享资源池，并为每个DS2D服务区域动态形成最优子星座（SCs）。每个子星座的形成整合了来自各种轨道的卫星，以根据用户需求提供定制化连接，并由两种创新策略指导：使用生成式人工智能（GenAI）的预测性卫星波束赋形和用于高效卫星接入和移动管理的预配置切换路径。仿真结果表明，CaaS显著提高了卫星服务速率，同时减少了切换开销，使其成为在多星座环境中管理DS2D连接的一种高效且可持续的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [246] [Geometrization of Higher-Order Linear Control Laws for Attitude Control on $\mathsf{SO(3)}$](https://arxiv.org/abs/2507.00997)
> *高阶线性控制律在$\\mathsf{SO(3)}$姿态控制中的几何化*

*Farooq Aslam, Hafiz Zeeshan Iqbal Khan, Muhammad Farooq Haydar, Suhail Akhtar, Jamshed Riaz* | **Category: eess.SY, cs.SY, math.OC**

**Keywords:** 几何控制, 姿态控制, SO(3), Lyapunov稳定性, 线性矩阵不等式, 高阶控制

**Comment:** 14 pages, 5 figures

> **TL;DR:** 本文提出了一个分析$\\mathrm{SO(3)}$上高阶几何非线性姿态控制律稳定性的理论框架，将现有PID型控制律分析扩展到更一般的高阶系统，并利用基于LMI的Lyapunov函数方法确保几乎全局渐近稳定。

**AI_Comments:** 本文通过将几何非线性控制律的稳定性分析扩展到$\\mathrm{SO(3)}$上的高阶系统，为复杂的姿态控制问题做出了重要贡献。受LTI系统启发的基于LMI的分析方法提供了一种系统且计算可行的方式来推导稳定性条件。考虑矩阵增益进一步增强了设计的灵活性并降低了保守性。在多旋翼飞行器上的实际应用凸显了该理论框架的相关性和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将PID型几何非线性控制律的分析扩展到$\\mathrm{SO(3)}$上更一般的高阶动态状态反馈补偿器，并受LTI系统广泛使用的LMI分析和设计工具的启发。

**Method:** 采用两步稳定性分析：首先，获得候选Lyapunov函数的正定性和其导数的负定性的充分必要条件，以确保几乎全局渐近稳定（AGAS）；其次，通过凸松弛将所提出条件转化为线性矩阵不等式（LMIs）。为减少保守性，控制器增益和Lyapunov函数系数均采用矩阵增益。

**Result:** 获得了确保期望平衡点几乎全局渐近稳定（AGAS）的条件；通过设计和分析一个用于多旋翼飞行器的21态几何非线性姿态控制律，验证了该方法的实际适用性。

**Conclusion:** 本文成功地将$\\mathrm{SO(3)}$上高阶几何非线性控制律的稳定性分析扩展到更一般的情况，并利用LMI方法提供了可行的分析框架，验证了其在实际问题中的适用性。

> **ai_Abstract:** 本文提出了一个理论框架，用于分析特殊正交群$\\mathrm{SO(3)}$上高阶几何非线性控制律的稳定性。该框架将现有PID型控制律分析扩展到更一般的高阶动态状态反馈补偿器。稳定性分析受LTI系统分析和LMI工具的启发，分两步进行：首先，推导出使用Lyapunov函数实现几乎全局渐近稳定的条件；其次，通过凸松弛将这些条件表述为线性矩阵不等式（LMIs）。该方法采用矩阵增益以减少保守性，并通过设计和分析一个用于多旋翼飞行器的21态姿态控制律进行了实际应用验证。

> **摘要翻译:** 本文提出了一个理论框架，用于分析特殊正交群$\\mathrm{SO(3)}$上姿态控制的高阶几何非线性控制律的稳定性。具体而言，本文将PID型几何非线性控制律的现有分析结果扩展到$\\mathrm{SO(3)}$上更一般的高阶动态状态反馈补偿器。候选Lyapunov函数的灵感来源于线性时不变（LTI）系统分析中通常考虑的$V(x)=x^{\\top}Px$形式的二次Lyapunov函数。稳定性分析分两步进行。第一步，获得了候选Lyapunov函数正定性的充分条件，以及相应Lyapunov函数导数负定性的充要条件。这些条件确保了期望的平衡点几乎全局渐近稳定（AGAS）。第二步，利用所提出条件的凸松弛形式，以线性矩阵不等式（LMIs）的形式获得了充分条件。总体而言，该方法受到LTI系统广泛使用的基于LMI的分析和设计工具的启发。为了降低保守性，控制器增益和Lyapunov函数系数都考虑了矩阵增益。通过设计和分析一个用于多旋翼飞行器的21态几何非线性姿态控制律，说明了该方法在实际问题中的适用性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [60] [Fast Simulation of Damage Diffusion Distribution in Scanning Transmission Electron Microscopy](https://arxiv.org/abs/2507.00294)
> *扫描透射电子显微镜中损伤扩散分布的快速模拟*

*Amir Javadi Rad, Amirafshar Moshtaghpour, Dongdong Chen, Angus I. Kirkland* | **Category: eess.SP, cond-mat.mtrl-sci**

**Keywords:** 扫描透射电子显微镜, 损伤扩散, 模拟, C++框架, 高性能计算

**Comment:** Presented in ISCS25

> **TL;DR:** 开发了一个高效的C++框架，用于快速准确地模拟扫描透射电子显微镜中的损伤扩散。

**AI_Comments:** 该工作通过开发一个优化的C++框架，显著提升了扫描透射电子显微镜中电子束损伤扩散模拟的计算效率和准确性。其创新点在于将多种高性能计算技术（高效数值计算、先进可视化、多线程）整合到一个易于使用的工具中，有望加速对原子尺度损伤机制的理解，并可能促进更稳定的成像技术发展。

<details>
  <summary>Details</summary>

**Motivation:** 扫描透射电子显微镜（STEM）中的电子束损伤机制尚不完全清楚，且损伤扩散过程的数值模拟计算量巨大，限制了相关研究。

**Method:** 引入了一个高性能C++框架，该框架结合了高效的数值计算、先进的可视化和多线程技术，用于模拟STEM中的损伤扩散过程。

**Result:** 该框架实现了高效的运行时间，同时保持了准确性。

**Conclusion:** 该高性能C++框架能够高效且准确地模拟扫描透射电子显微镜中的损伤扩散过程，克服了现有模拟计算量大的问题。

> **ai_Abstract:** 本文介绍了一个用于模拟扫描透射电子显微镜（STEM）中损伤扩散过程的高性能C++框架。鉴于现有模拟计算成本高昂且对损伤机制理解不足，该框架通过结合高效数值计算、高级可视化和多线程技术，显著提高了模拟效率和准确性，为原子尺度材料和生物样本的电子束损伤研究提供了强大工具。

> **摘要翻译:** 扫描透射电子显微镜（STEM）是原子尺度成像材料和生物标本特性的关键工具，但我们对相关电子束损伤机制的理解尚不完全。最近的研究表明，某些类型的损伤可以建模为扩散过程。然而，这种扩散过程的数值模拟仍然计算量巨大。这项工作引入了一个高性能C++框架，用于模拟STEM中的损伤扩散过程，该框架结合了高效的数值计算、先进的可视化和多线程技术，以在保持准确性的同时实现高效的运行时间。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [80] [Quadrature Over-the-Air-Computing for Multimodal Dual-Stream Signal Processing](https://arxiv.org/abs/2507.00508)
> *正交空口计算用于多模态双流信号处理*

*Hyeon Seok Rou, Kengo Ando, Giuseppe Thadeu Freitas de Abreu, David González G* | **Category: eess.SP**

**Keywords:** 空口计算, 正交空口计算, 双流信号处理, 多模态, B5G

**Comment:** 

> **TL;DR:** Q-OTAC是一种新颖的空口计算框架，通过利用复信号的IQ分量，在一个传输中同时计算两个独立函数或数据流，有效地将计算速率翻倍。

**AI_Comments:** 该论文创新性地将复信号的IQ分量用于空口计算，实现了计算速率的翻倍，显著提升了传统OTAC的效率。其提出的IQ解耦合并器设计简洁，且与现有技术兼容，具有很强的实用价值和广泛的应用前景，特别是在B5G通信领域。

<details>
  <summary>Details</summary>

**Motivation:** 传统的空口计算（OTAC）方案每次只能计算单个函数，效率较低，无法满足多模态和高效率B5G应用的需求。

**Method:** 提出正交空口计算（Q-OTAC）框架。该框架利用复信号的同相（I）和正交（Q）分量，在边缘设备（EDs）编码两个不同的函数和/或数据流，并在接入点（AP）采用一种新型低复杂度IQ解耦合并器来独立恢复每个流。

**Result:** 仿真结果验证了该方法的有效性，包括首次展示了双功能聚合（例如，并行求和和乘积），突出了Q-OTAC在实现多模态和高效率超越第五代（B5G）应用方面的潜力。

**Conclusion:** Q-OTAC框架通过利用复信号的IQ分量实现双流并发计算，显著提高了空口计算的效率和能力，且具有简单性和广泛兼容性，为多模态和高效率B5G应用提供了支持。

> **ai_Abstract:** 本文提出了一种名为正交空口计算（Q-OTAC）的新型框架，通过利用复信号的同相和正交（IQ）分量，在一个传输中同时处理两个独立的函数或数据流，从而将计算速率翻倍。Q-OTAC在边缘设备编码双流，并在接入点采用低复杂度IQ解耦合并器进行独立恢复。该框架概念简单且兼容性强，仿真验证了其有效性，并展示了双功能聚合能力，预示着其在多模态和高效B5G应用中的巨大潜力。

> **摘要翻译:** 我们提出了一种新颖的正交空口计算（Q-OTAC）框架，该框架能够在一次传输中同时计算两个独立的函数和/或数据流。与传统空口计算方案不同的是，传统方案将每个复信号视为单个分量来计算一个函数，而所提出的Q-OTAC利用复信号的同相（IQ）分量，在边缘设备（EDs）编码两个不同的函数和/或数据流，并在接入点（AP）采用一种新型低复杂度IQ解耦合并器来独立恢复每个流，从而有效地将计算速率翻倍。该框架的一个关键优势在于其简单性和广泛兼容性：扩展到正交域的概念非常直接，但功能强大，可以无缝集成到现有OTAC技术中。仿真结果验证了该方法的有效性，包括首次展示双功能聚合（例如，并行求和和乘积），突出了Q-OTAC在实现多模态和高效率超越第五代（B5G）应用方面的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [101] [Fair Rate Maximization for Fluid Antenna Relay (FAR)-assisted Multi-user MISO Communications](https://arxiv.org/abs/2507.00529)
> *流体天线中继（FAR）辅助多用户MISO通信的公平速率最大化*

*Ruopeng Xu, Zhaohui Yang, Ting Zhang, Mingzhe Chen, Chen Zhu, Zhaoyang Zhang* | **Category: eess.SP**

**Keywords:** 流体天线中继, 公平速率最大化, 多用户MISO, 逐次凸逼近, 位置优化

**Comment:** 

> **TL;DR:** 本文研究了流体天线中继辅助多用户MISO系统中，通过联合优化流体天线位置，利用SCA交替算法实现公平速率（最小速率）最大化的问题，仿真结果表明该方法优于传统方法。

**AI_Comments:** 本文的创新点在于将流体天线系统中的速率最大化问题从传统的总和速率最大化转向了公平速率（最小速率）最大化，这对于保障多用户系统中的弱用户体验具有重要意义。通过联合优化天线位置并采用SCA算法，为解决这类非凸问题提供了一个有效的框架。该研究为未来流体天线技术在追求系统公平性方面的应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于流体天线系统的工作大多关注最大化总和速率，这可能导致弱用户遭受无法忍受的速率损失。为了解决这个问题并确保公平性，本文提出最大化系统中的最小速率。

**Method:** 该研究将最大最小速率优化问题公式化，通过联合优化流体天线（FA）的位置，同时满足FA的最小距离要求、最大传输功率限制和可行天线区域约束。为了解决这个问题，提出了一种利用逐次凸逼近（SCA）方法的交替算法。

**Result:** 仿真结果表明，在不同的信噪比（SNR）和归一化区域大小下，所提出的方法在最大化最小可实现速率方面显著优于传统方法。

**Conclusion:** 本文提出的基于SCA交替算法的流体天线中继辅助多用户MISO系统中公平速率最大化方法，能够有效提升弱用户的速率，实现系统公平性，并优于传统方法。

> **ai_Abstract:** 本文针对流体天线中继辅助的多用户MISO系统，提出了一个最大最小速率优化问题，旨在通过联合优化流体天线位置来解决传统总和速率最大化可能导致的弱用户速率损失和公平性问题。研究人员设计了一种基于逐次凸逼近（SCA）的交替算法来求解该问题。仿真结果验证了所提方法在提高系统最小可实现速率方面的显著优势，从而有效地保障了系统公平性。

> **摘要翻译:** 在本文中，我们研究了流体天线中继（FAR）辅助的多用户上行多输入单输出（MISO）无线系统中的最大最小速率最大化问题，其中每个用户配备一个流体天线（FA），基站（BS）配备多个流体天线。与大多数现有关注最大化流体天线系统（FAS）总和速率的相关工作不同，现有方法可能导致弱用户遭受无法忍受的速率损失，我们提出最大化系统的最小速率以确保公平性。通过联合优化流体天线的位置，同时满足流体天线的最小距离要求、最大传输功率限制和可行天线区域约束，来制定最大最小优化问题。为了解决这个问题，我们提出了一种利用逐次凸逼近（SCA）方法的交替算法。仿真结果表明，在不同的信噪比（SNR）和归一化区域大小下，所提出的方法在最大化最小可实现速率方面显著优于传统方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [125] [Delay Bound Relaxation with Deep Learning-based Haptic Estimation for Tactile Internet](https://arxiv.org/abs/2507.00571)
> *基于深度学习的触觉估计在触觉互联网中放松延迟限制*

*Georgios Kokkinis, Alexandros Iosifidis, Qi Zhang* | **Category: eess.SP**

**Keywords:** 触觉互联网, 深度学习, 触觉估计, 延迟放松, 资源分配

**Comment:** 6 pages, 6 figures, 1 table, conference paper submitted in
  GLOBECOM2025

> **TL;DR:** 该研究提出一种基于深度学习的触觉估计模型，通过预测力反馈来放松触觉互联网的严格延迟要求，从而提高资源效率和可靠性。

**AI_Comments:** 该论文创新性地将深度学习应用于触觉反馈估计，有效解决了触觉互联网中严苛的延迟和资源分配挑战。通过放松延迟限制，它为高可靠性触觉通信提供了实用且高效的解决方案，对未来触觉遥操作和虚拟现实应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 触觉遥操作在触觉互联网中通常需要亚毫秒级延迟和超高可靠性，导致极高的分组传输速率，对及时交付构成重大挑战，并给无线资源分配带来巨大的复杂性和开销。

**Method:** 引入一种新的深度学习模型，利用多模态输入（远程侧的力测量和本地操作员运动信号）估计力反馈。该模型使用CNN和LSTM层捕获触觉时间序列的复杂时间特征，然后是Transformer编码器，并自回归地生成高度准确的下一个力值估计。通过确保估计误差在预定义阈值内，系统可以放松严格的延迟要求，从而批量传输多个触觉数据包，提高资源效率。

**Result:** 通过广泛模拟，评估了网络在可靠性和容量方面的性能。结果表明，对于动态和刚性物体交互，所提出的方法将可靠服务的用户数量提高了多达66%。

**Conclusion:** 所提出的基于深度学习的触觉估计方法能够有效放松触觉互联网的延迟限制，显著提高网络资源效率和可靠服务用户数量，从而解决了触觉遥操作中的关键挑战。

> **ai_Abstract:** 本研究提出一种基于深度学习的触觉估计模型，旨在解决触觉互联网中触觉遥操作对亚毫秒级延迟和超高可靠性的严苛要求。该模型结合CNN、LSTM和Transformer编码器，利用多模态输入（力测量和运动信号）精确预测未来力反馈。通过允许在估计误差可接受的情况下放松延迟限制，该方法能够实现触觉数据包的批量传输，显著提高无线资源效率和网络容量。模拟结果显示，该方法可将可靠服务的用户数量提高高达66%。

> **摘要翻译:** 触觉遥操作通常要求触觉互联网中达到亚毫秒级的延迟和超高可靠性（99.999%）。在1 kHz的触觉信号采样率下，这意味着极高的分组传输速率，对及时交付构成重大挑战，并给无线资源分配带来巨大的复杂性和开销。为了解决这一关键挑战，我们引入了一种新颖的深度学习模型，该模型使用多模态输入（即来自远端的力测量和本地操作员运动信号）来估计力反馈。该深度学习模型能够利用CNN和LSTM层捕获触觉时间序列的复杂时间特征，随后是一个Transformer编码器，并自回归地为不同的遥操作活动生成高度准确的下一个力值估计。通过确保估计误差在预定义阈值内，遥操作系统可以安全地放松其严格的延迟要求。这使得可以在单个资源块内批量传输多个触觉数据包，从而提高资源效率并促进资源分配中的调度。通过广泛的模拟，我们评估了网络在可靠性和容量方面的性能。结果表明，对于动态和刚性物体交互，所提出的方法将可靠服务的用户数量提高了多达66%。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [146] [Quantize-Sample-and-Verify: LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding](https://arxiv.org/abs/2507.00605)
> *量化-采样-验证：通过自适应边缘-云推测解码加速LLM*

*Guangyi Zhang, Yunlong Cai, Guanding Yu, Petar Popovski, Osvaldo Simeone* | **Category: eess.SP**

**Keywords:** 量化, 推测解码, LLM加速, 边缘-云, 通信带宽

**Comment:** Submit for review

> **TL;DR:** 该论文提出了一种新颖的量化-采样（Q-S）策略和自适应机制，用于边缘-云推测解码，以解决LLM加速中的通信带宽瓶颈，并通过动态调整草稿长度和量化精度来优化令牌吞吐量。

**AI_Comments:** 该论文的创新之处在于提出了可证明保留输出分布的量化-采样策略，以及考虑到通信延迟和信道条件的自适应吞吐量优化机制。这些方法直接解决了边缘-云LLM部署中的实际瓶颈，对于提高系统效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 边缘-云推测解码系统中的一个关键瓶颈是边缘和云之间有限的通信带宽，这使得传输的有关生成令牌的信息需要进行量化。

**Method:** 本文引入了一种新颖的量化-采样（Q-S）策略，该策略可证明地保留了基于云的模型的输出分布。此外，还开发了一个明确考虑通信延迟的边缘-云SD吞吐量模型，并基于此模型提出了一个自适应机制，通过根据语义不确定性和信道条件动态调整草稿长度和量化精度来优化令牌吞吐量。

**Result:** 仿真结果表明，所提出的Q-S方法在真实的边缘-云部署场景中显著提高了解码效率。

**Conclusion:** 所提出的量化-采样（Q-S）策略和自适应机制有效解决了边缘-云推测解码中的通信瓶颈，显著提高了LLM的加速效率。

> **ai_Abstract:** 该论文旨在解决边缘-云推测解码中LLM加速的通信带宽瓶颈。它提出了一种新颖的量化-采样（Q-S）策略，该策略能够证明性地保持云端模型的输出分布，并开发了一个考虑通信延迟的吞吐量模型。基于此模型，论文进一步提出了一种自适应机制，能够根据语义不确定性和信道条件动态调整草稿长度和量化精度，从而优化令牌吞吐量。仿真结果表明，该Q-S方法显著提高了边缘-云部署场景中的解码效率。

> **摘要翻译:** 在边缘-云推测解码（SD）中，配备小型语言模型（SLM）的边缘设备生成草稿令牌，这些令牌由云中的大型语言模型（LLM）进行验证。此类系统的一个关键瓶颈是边缘和云之间有限的通信带宽，这使得传输的有关生成令牌的信息需要进行量化。在这项工作中，我们引入了一种新颖的量化-采样（Q-S）策略，该策略可证明地保留了基于云的模型输出分布，确保验证的令牌与LLM直接生成的令牌的分布相匹配。我们开发了一个边缘-云SD的吞吐量模型，该模型明确考虑了通信延迟。利用该模型，我们提出了一种自适应机制，通过根据语义不确定性和信道条件动态调整草稿长度和量化精度来优化令牌吞吐量。仿真结果表明，所提出的Q-S方法在真实的边缘-云部署场景中显著提高了解码效率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [167] [Physical Layer Group Key Generation With the Aid of Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2507.00714)
> *借助可重构智能表面进行物理层群密钥生成*

*Vahid Shahiri, Guyue Li, Hamid Behroozi* | **Category: eess.SP**

**Keywords:** 可重构智能表面, 群密钥生成, 物理层安全, 主动RIS, 信道状态信息

**Comment:** This manuscript has been submitted to IEEE Transactions on
  Communications (TCOM) and is currently under review

> **TL;DR:** 本研究利用可重构智能表面（RIS）调整无线环境，使不同用户终端的聚合反射信道尽可能相似，从而从这些信道中提取共同的群密钥。主动RIS（ARIS）在群密钥生成方面表现优于被动RIS（PRIS），尤其是在静态环境下也能实现高群密钥生成率。

**AI_Comments:** 本文的创新点在于将RIS应用于物理层群密钥生成，并深入探讨了主动RIS（ARIS）相较于被动RIS（PRIS）的优势。通过利用RIS已有的CSI和采用广播机制，有效降低了系统开销。特别值得注意的是，该方案在静态环境下也能实现高GKG率，克服了现有方法可能存在的局限性。这为未来基于RIS的物理层安全通信提供了新的思路和技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究利用RIS改变无线环境。本文受此启发，旨在利用RIS使不同用户终端的聚合反射信道尽可能相似，以便从这些信道中提取共同的群密钥，并解决现有方法可能存在的局限性（例如对额外探测的负担、对静态环境的适用性）。

**Method:** 本研究利用RIS调整参数，基于用户终端的物理信道进行群密钥生成。该方法利用RIS中已收集的信道状态信息（CSI）来设计相位偏移，不增加额外探测负担。采用广播式方案，避免成对密钥生成的开销。考虑使用被动RIS（PRIS）和主动RIS（ARIS）两种类型。采用逐次凸逼近（SCA）和带高斯随机化的半定松弛（SDR-GR）等优化方法解决优化问题。通过归一化均方误差（NMSE）、密钥错误率（KER）、密钥生成率（KGR）和密钥随机性指标来评估性能。

**Result:** 所提出的方案可以在静态环境下实现高群密钥生成率。在相同的可用功率预算下，ARIS在NMSE和KER方面显著优于PRIS，并实现了比PRIS高四倍以上的KGR。

**Conclusion:** 本研究成功利用可重构智能表面（RIS）进行物理层群密钥生成，特别是证明了主动RIS（ARIS）在对齐聚合反射信道和实现高密钥生成率方面的优越性，且该方案无需额外探测负担，在静态环境下也表现良好。

> **ai_Abstract:** 本文研究了利用可重构智能表面（RIS）进行物理层群密钥生成（GKG）。通过调整RIS参数，使不同用户终端的聚合反射信道相似，从而提取共同群密钥。该方法利用现有信道状态信息（CSI）设计相位偏移，避免额外探测开销，并采用广播方式。研究比较了被动RIS（PRIS）和主动RIS（ARIS），发现ARIS在对齐信道和提高密钥生成率方面表现更优，尤其是在静态环境下也能实现高GKG率。数值结果表明，ARIS在相同功率预算下，NMSE和KER显著优于PRIS，KGR提升四倍以上。

> **摘要翻译:** 可重构智能表面（RIS）通过改变入射信号的能力来改变无线环境。受此能力的启发，本研究利用RIS使不同用户终端（UT）的聚合反射信道尽可能相似，以便从它们的信道中提取共同的群密钥。具体而言，RIS将调整其参数，为基于UT物理信道的群密钥生成（GKG）铺平道路。我们的方法利用RIS中已收集的信道状态信息（CSI）来有利地设计相位偏移，并且不会给网络增加额外的探测负担。此外，该方案是基于广播的，不会带来基于成对密钥生成的开销。我们考虑使用被动RIS（PRIS）和主动RIS（ARIS）来生成群密钥。PRIS因其使用无源元件而在物理层密钥生成（PLKG）研究中被广泛采用，而ARIS在本研究中证明了在GKG场景中对齐节点间聚合反射信道方面的卓越能力。我们将利用各种优化方法，如逐次凸逼近（SCA）和带高斯随机化的半定松弛（SDR-GR）来解决所提出的优化问题。与文献中的大多数研究不同，我们的方案在静态环境下也能实现高GKG率。最后，我们将通过归一化均方误差（NMSE）、密钥错误率（KER）、密钥生成率（KGR）和密钥随机性指标来检验所提出方法的性能。我们的数值结果验证了在相同的可用功率预算下，ARIS在NMSE和KER方面显著优于PRIS，实现了高出四倍以上的KGR。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [185] [SComCP: Task-Oriented Semantic Communication for Collaborative Perception](https://arxiv.org/abs/2507.00895)
> *SComCP：面向任务的协作感知语义通信*

*Jipeng Gan, Yucheng Sheng, Hua Zhang, Le Liang, Hao Ye, Chongtao Guo, Shi Jin* | **Category: eess.SP**

**Keywords:** 协作感知, 语义通信, 任务导向, 联合源信道编码, 联网自动驾驶汽车

**Comment:** 

> **TL;DR:** SComCP是一种面向任务的语义通信框架，通过选择重要特征和鲁棒编码，显著降低通信开销并在恶劣无线条件下提高协作感知性能。

**AI_Comments:** SComCP的创新点在于将任务导向的语义通信引入协作感知，通过智能特征选择和联合源信道编码有效解决了带宽限制和信道噪声对性能的影响。这对于提升联网自动驾驶汽车在复杂环境下的感知可靠性和安全性具有重要意义。其在低SNR下的优异表现和强大的泛化能力是显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 单车感知系统受限于感知范围和遮挡，在复杂交通环境中可靠性不足。协作感知虽有前景，但受限于无线通信约束，不可靠和带宽有限的信道阻碍了实时感知所需传感器数据的传输。

**Method:** 本文提出了SComCP，一个新颖的面向任务的协作感知语义通信框架。SComCP集成了一个重要性感知特征选择网络，用于选择并传输与感知任务最相关的语义特征，以降低通信开销。此外，它设计了一个基于联合源信道编码（JSCC）架构的语义编解码网络，以实现语义特征和抗噪声信道符号之间的双向转换，确保恶劣无线条件下的稳定感知。

**Result:** 广泛的实验表明SComCP能够保持优于现有方法的感知性能，尤其是在低信噪比（SNR）场景下。SComCP还展现出强大的泛化能力，即使在特定信道模型下训练，也能在不同信道条件下保持高性能。

**Conclusion:** SComCP框架通过创新的语义通信方法，有效解决了协作感知中的通信瓶颈问题，显著提升了在复杂和恶劣无线环境下的感知性能和鲁棒性。

> **ai_Abstract:** 本文提出了SComCP，一种面向任务的语义通信框架，旨在解决联网自动驾驶汽车协作感知中因无线通信限制导致的性能瓶颈。SComCP通过一个重要性感知特征选择网络显著降低通信开销，并利用基于JSCC的语义编解码网络在恶劣无线条件下确保稳定感知。实验证明SComCP在多种信道条件下，尤其是在低信噪比场景下，展现出优越的感知性能和强大的泛化能力。

> **摘要翻译:** 可靠地检测周围物体对于联网自动驾驶汽车（CAVs）的安全运行至关重要。然而，固有的局限性，如受限的感知范围和遮挡效应，损害了复杂交通环境中单车感知系统的可靠性。协作感知作为一种有前景的方法应运而生，它通过融合来自周围CAV的具有不同视角的传感器数据，从而提高了环境感知能力。尽管协作感知前景广阔，但其性能受到无线通信约束的瓶颈制约，因为不可靠和带宽受限的信道阻碍了实时感知所需的传感器数据传输。为了解决这些挑战，本文提出了SComCP，一个新颖的面向任务的协作感知语义通信框架。具体来说，SComCP集成了一个重要性感知特征选择网络，该网络选择并传输与感知任务最相关的语义特征，在不牺牲精度的情况下显著降低了通信开销。此外，我们设计了一个基于联合源信道编码（JSCC）架构的语义编解码网络，该网络能够实现语义特征和抗噪声信道符号之间的双向转换，从而确保在恶劣无线条件下的稳定感知。广泛的实验证明了所提出框架的有效性。特别是，与现有方法相比，SComCP在各种信道条件下，尤其是在低信噪比（SNR）场景中，能够保持卓越的感知性能。此外，SComCP展现出强大的泛化能力，即使在特定信道模型下训练，也能使该框架在不同信道条件下保持高性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [204] [Enhancing Open RAN Digital Twin Through Power Consumption Measurement](https://arxiv.org/abs/2507.00928)
> *通过功耗测量增强开放式RAN数字孪生*

*Ahmed Al-Tahmeesschi, Yi Chu, Josh Shackleton, Swarna Chetty, Mostafa Rahmani, David Grace, Hamed Ahmadi* | **Category: eess.SP**

**Keywords:** Open RAN, 功耗测量, 能源效率, 数字孪生, 5G

**Comment:** Accepted in PIMRC 2025

> **TL;DR:** 本文通过对Open RAN中RU、DU和CU的功耗进行测量研究，发现在不同网络负载下，功耗并不会随负载显著增加，大部分能耗是恒定的，这对于优化能源效率至关重要。

**AI_Comments:** 本文通过对Open RAN核心组件功耗的实证测量，填补了该领域的数据空白，尤其是在不同功能拆分和负载条件下的表现。其创新之处在于提供了真实硬件部署下的具体数据，而非仅限于理论分析。研究结果揭示了Open RAN中功耗的基线特性，即存在显著的固定能耗，这对于未来的节能策略和数字孪生模型构建具有重要指导意义。这项工作对于推动Open RAN的绿色发展和可持续运营具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 5G及未来网络对高速、超可靠和低延迟通信的需求导致功耗显著增加，尤其是在无线接入网络（RAN）中。这给移动网络运营商带来了运营和可持续性挑战。Open RAN虽然提供了灵活性，但也引入了新的复杂性，特别是在不同网络组件（如RU、DU、CU）的功耗方面。因此，理解不同O-RAN功能拆分中的功率效率对于优化能耗和网络可持续性至关重要。

**Method:** 本文对Open RAN中的无线单元（RUs）、分布式单元（DUs）和中央单元（CUs）在不同网络负载下（特别是物理资源块（PRB）在Split 8和Split 7.2b下的利用率影响）进行了全面的功耗测量研究。测量对象包括基于软件定义无线电（SDR）的RU、商用室内外RU及其对应的DU和CU。通过评估实际硬件部署在不同操作条件下的表现，提供了经验洞察。

**Result:** 研究结果表明，功耗并没有随网络负载显著增加，这表明大部分能耗在流量需求变化时仍然保持恒定。

**Conclusion:** 通过对Open RAN组件功耗的实证测量，揭示了系统能耗的基线特性，即大部分能耗与网络负载无关。这为未来优化Open RAN的能源效率和可持续性提供了关键见解和基础数据，尤其是在数字孪生技术的背景下。

> **ai_Abstract:** 本研究旨在通过实证测量提升Open RAN数字孪生技术。鉴于5G网络中RAN功耗的显著增长及其带来的可持续性挑战，本文对Open RAN架构中的RUs、DUs和CUs在不同网络负载（特别是PRB在Split 8和Split 7.2b下的利用率）下的功耗进行了全面测量。研究发现，Open RAN组件的功耗并不会随网络负载的增加而显著提高，表明大部分能耗是恒定的，这为优化Open RAN的能源效率和实现网络可持续性提供了关键的实证数据和见解。

> **摘要翻译:** 5G及未来网络中对高速、超可靠和低延迟通信日益增长的需求导致功耗显著增加，特别是在无线接入网络（RAN）中。这种不断增长的能源需求给移动网络运营商带来了运营和可持续性挑战，需要新的解决方案来提高能源效率，同时保持服务质量（QoS）。5G网络正朝着分解、可编程和智能的架构发展，其中开放无线接入网络（O-RAN）由O-RAN联盟主导，实现了更大的灵活性、互操作性和成本效益。然而，这种分解方法引入了新的复杂性，尤其是在包括开放无线单元（RUs）、开放分布式单元（DUs）和开放中央单元（CUs）在内的不同网络组件的功耗方面。了解不同O-RAN功能拆分的功率效率对于优化能耗和网络可持续性至关重要。在本文中，我们对RUs、DUs和CUs在不同网络负载下的功耗进行了全面的测量研究，特别分析了物理资源块（PRB）在Split 8和Split 7.2b中的利用率影响。测量是在基于软件定义无线电（SDR）的RUs以及商用室内外RU及其相应的DU和CU上进行的。通过评估不同操作条件下的实际硬件部署，这项研究为各种O-RAN配置的功率效率提供了经验性见解。结果表明，功耗并未随网络负载显著增加，这表明大部分能耗无论流量需求如何都保持不变。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [16] [Real-Time Guidewire Tip Tracking Using a Siamese Network for Image-Guided Endovascular Procedures](https://arxiv.org/abs/2507.00051)
> *基于孪生网络的实时导丝尖端追踪用于影像引导的血管内手术*

*Tianliang Yao, Zhiqiang Pei, Yong Li, Yixuan Yuan, Peng Qi* | **Category: eess.IV, cs.CV**

**Keywords:** 导丝追踪, 孪生网络, 血管内手术, 影像引导治疗, 实时

**Comment:** This paper has been accepted by Advanced Intelligent Systems

> **TL;DR:** 本文提出了一种基于孪生网络和双重注意力机制的实时导丝尖端追踪框架，用于影像引导的血管内手术，实现了高精度和高速度。

**AI_Comments:** 该论文创新性地将带有双重注意力机制的孪生网络应用于血管内手术中关键的实时导丝尖端追踪任务。其在处理视觉模糊方面的能力以及所实现的高精度和实时性能对于临床应用具有重要意义。在临床数据和机器人平台上的验证进一步增强了其实用价值和潜在的临床转化前景。

<details>
  <summary>Details</summary>

**Motivation:** 将AI解决方案融入临床实践，提高医疗服务的效率和有效性，特别是通过辅助医生进行导丝尖端追踪，以提高心血管疾病影像引导治疗的诊断和治疗质量。

**Method:** 提出了一种基于孪生网络的新型追踪框架，结合了自注意力和交叉注意力策略的双重注意力机制。该设计通过增强的时空特征学习来处理视觉模糊、组织变形和成像伪影。在临床数字减影血管造影（DSA）序列和机器人平台进行了验证。

**Result:** 在临床DSA序列上，平均定位误差为0.421 ± 0.138毫米（最大误差1.736毫米），平均交并比（IoU）为0.782。平均处理速度为每秒57.2帧。在机器人平台上的验证显示，两种不同实验场景下的追踪误差分别为0.708 ± 0.695毫米和0.148 ± 0.057毫米。

**Conclusion:** 所提出的孪生网络框架能够实现鲁棒、准确且实时的导丝尖端追踪，满足血管内成像的时间要求，并有望应用于临床常规中的自动化诊断和治疗。

> **ai_Abstract:** 本文提出了一种用于影像引导血管内手术的实时导丝尖端追踪框架。该框架基于带有双重注意力机制的孪生网络，旨在处理视觉模糊、组织变形和成像伪影，并通过增强的时空特征学习实现鲁棒追踪。在临床DSA序列上，该方法实现了高精度（平均定位误差0.421毫米）和高速度（57.2帧/秒），并进一步在机器人平台上进行了验证，展示了其在提高诊断和治疗质量以及支持自动化介入操作方面的潜力。

> **摘要翻译:** 人工智能解决方案在临床实践中日益广泛的应用提高了医疗服务的效率和有效性。本文关注影像引导的心血管疾病治疗中导丝尖端追踪任务，旨在帮助医生提高诊断和治疗质量。本文提出了一种基于孪生网络的新型追踪框架，该框架结合了双重注意力机制（自注意力和交叉注意力策略），实现了鲁棒的导丝尖端追踪。该设计通过增强的时空特征学习，处理视觉模糊、组织变形和成像伪影。在包含15个序列的数据集中，随机选择了3个临床数字减影血管造影（DSA）序列进行验证，涵盖了多种介入场景。结果显示，平均定位误差为0.421 ± 0.138毫米，最大误差为1.736毫米，平均交并比（IoU）为0.782。该框架保持了每秒57.2帧的平均处理速度，满足了血管内成像的时间要求。在临床常规中，使用机器人平台进行自动化诊断和治疗的进一步验证显示，在两种不同的实验场景中，追踪误差分别为0.708 ± 0.695毫米和0.148 ± 0.057毫米。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [32] [Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)](https://arxiv.org/abs/2507.00185)
> *多模态、多疾病医学影像基础模型 (MerMED-FM)*

*Yang Zhou, Chrystie Wan Ning Quek, Jun Zhou, Yan Wang, Yang Bai, Yuhe Ke, Jie Yao, Laura Gutierrez, Zhen Ling Teo, Darren Shu Jeng Ting, Brian T. Soetikno, Christopher S. Nielsen, Tobias Elze, Zengxiang Li, Linh Le Dinh, Lionel Tim-Ee Cheng, Tran Nguyen Tuan Anh, Chee Leong Cheng, Tien Yin Wong, Nan Liu, Iain Beehuat Tan, Tony Kiat Hon Lim, Rick Siow Mong Goh, Yong Liu, Daniel Shu Wei Ting* | **Category: eess.IV, cs.AI, cs.CV**

**Keywords:** 医学影像, 基础模型, 多模态, 多疾病, 自监督学习

**Comment:** 42 pages, 3 composite figures, 4 tables

> **TL;DR:** MerMED-FM是一个多模态、多疾病的医学影像基础模型，通过自监督学习和记忆模块在大量医学图像上训练，并在多种模态上表现出色，有望实现跨专业的医学影像解读。

**AI_Comments:** MerMED-FM的创新之处在于其多模态、多疾病的集成能力，以及采用自监督学习和记忆模块来克服对大量标注数据的依赖。其在多种医学影像模态上展现出的强大且一致的性能，预示着它在泛化和临床应用方面具有巨大潜力，有望推动医学影像AI的发展，实现更普适和鲁棒的诊断辅助。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医学影像人工智能模型大多是单模态和单疾病的，并且尝试创建多模态、多疾病模型时，临床准确性表现不一致。此外，训练这些模型通常需要大量、劳动密集型且标注良好的数据集。

**Method:** 研究人员开发了MerMED-FM，这是一个最先进的多模态、多专业基础模型。它采用自监督学习和记忆模块进行训练，并使用了来自十多个专业和七种模态（包括CT、CXR、US、病理切片、CFP、OCT和皮肤病图像）的330万张医学图像进行训练。

**Result:** MerMED-FM在所有模态中均取得了强大的性能，AUROC值分别为：0.988 (OCT)；0.982 (病理)；0.951 (US)；0.943 (CT)；0.931 (皮肤)；0.894 (CFP)；0.858 (CXR)。

**Conclusion:** MerMED-FM有潜力成为一个高度适应性强、多功能、跨专业的基础模型，能够在不同的医学领域实现稳健的医学影像解读。

> **ai_Abstract:** 本研究提出并开发了MerMED-FM，一个创新的多模态、多疾病医学影像基础模型。与现有单模态、单疾病模型或准确性不一致的多模态模型不同，MerMED-FM利用自监督学习和记忆模块，在包含七种模态和十多个专业的330万张医学图像上进行训练。实验结果表明，MerMED-FM在所有评估的模态上均表现出色，AUROC值范围从0.858到0.988。该模型展现了作为高度适应性、多功能、跨专业医学影像解读基础模型的巨大潜力。

> **摘要翻译:** 当前医学影像的人工智能模型主要是单模态和单疾病的。尝试创建多模态和多疾病模型导致临床准确性不一致。此外，训练这些模型通常需要大量、劳动密集型、标注良好的数据集。我们开发了MerMED-FM，一个采用自监督学习和记忆模块训练的最先进的多模态、多专业基础模型。MerMED-FM在来自十多个专业和七种模态（包括计算机断层扫描（CT）、胸部X光（CXR）、超声（US）、病理切片、彩色眼底照相（CFP）、光学相干断层扫描（OCT）和皮肤科图像）的330万张医学图像上进行了训练。MerMED-FM在多种疾病中进行了评估，并与现有基础模型进行了比较。在所有模态中均取得了强大的性能，AUROC值分别为0.988 (OCT)；0.982 (病理)；0.951 (US)；0.943 (CT)；0.931 (皮肤)；0.894 (CFP)；0.858 (CXR)。MerMED-FM有潜力成为一个高度适应性强、多功能、跨专业的基础模型，能够在不同的医学领域实现稳健的医学影像解读。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [52] [Towards 3D Semantic Image Synthesis for Medical Imaging](https://arxiv.org/abs/2507.00206)
> *面向医学成像的三维语义图像合成*

*Wenwu Tang, Khaled Seyam, Bin Yang* | **Category: eess.IV, cs.CV**

**Keywords:** 三维图像合成, 医学成像, 语义扩散模型, 数据增强, 隐私保护

**Comment:** 

> **TL;DR:** Med-LSDM是一种用于医学成像的三维语义图像合成模型，旨在通过生成合成数据来解决数据稀缺和隐私问题，并在计算效率和细节保留方面表现出色。

**AI_Comments:** Med-LSDM的创新之处在于其直接在三维域进行语义图像合成，并利用潜在空间扩散模型结合VQ-GAN，有效解决了医学图像数据稀缺和隐私保护的关键问题。其在计算效率和保持三维细节方面的优势使其在实际应用中具有重要潜力。该方法为医学图像的数据增强和隐私保护提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗领域，由于数据获取困难和严格的隐私法规，导致大型数据集的获取具有挑战性。数据可用性和隐私保护是机器学习在医学成像中应用的主要障碍。

**Method:** 本研究提出了Med-LSDM（潜在语义扩散模型），它直接在三维域中操作，并利用去识别的语义图来生成合成数据，以实现隐私保护和数据增强。Med-LSDM通过在预训练VQ-GAN的潜在空间中应用扩散模型，并结合引导机制来控制三维图像生成过程。在压缩的潜在空间中操作显著降低了计算复杂度，同时保留了关键的三维空间细节。

**Result:** Med-LSDM在三维语义医学图像合成中表现出强大的性能，在条件Duke乳腺数据集上实现了0.0054的3D-FID分数，并且Dice分数（0.70964）与真实图像（0.71496）相似。

**Conclusion:** 这些结果表明，我们模型生成的合成数据与真实数据之间的领域差距很小，并且可用于数据增强。

> **ai_Abstract:** 本文提出了一种名为Med-LSDM的潜在语义扩散模型，专门用于三维医学图像的语义合成。该模型旨在解决医学领域数据稀缺和隐私保护的挑战，通过利用去识别的语义图在三维潜在空间中生成高质量的合成数据。Med-LSDM通过在预训练VQ-GAN的潜在空间中应用扩散模型并引入引导机制，实现了计算效率和三维空间细节的保留。实验结果表明，该模型生成的合成数据与真实数据具有极小的领域差距，并能有效用于数据增强。

> **摘要翻译:** 在医疗领域，由于获取困难和严格的隐私法规，获取大型数据集极具挑战性。因此，数据可用性和隐私保护是机器学习在医学成像中应用的主要障碍。为了解决这个问题，我们的研究提出了Med-LSDM（潜在语义扩散模型），它直接在三维领域中运行，并利用去识别的语义图生成合成数据，作为隐私保护和数据增强的方法。与许多专注于生成二维切片的现有方法不同，Med-LSDM专为三维语义图像合成而设计，非常适合需要完整体积数据的应用。Med-LSDM结合了一种引导机制，通过在预训练的VQ-GAN的潜在空间中应用扩散模型来控制三维图像生成过程。通过在压缩的潜在空间中操作，该模型显著降低了计算复杂度，同时仍保留了关键的三维空间细节。我们的方法在三维语义医学图像合成中表现出强大的性能，在条件Duke乳腺数据集上实现了0.0054的3D-FID分数，并且Dice分数（0.70964）与真实图像（0.71496）相似。这些结果表明，我们模型生成的合成数据与真实数据之间的领域差距很小，并且可用于数据增强。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [72] [SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures](https://arxiv.org/abs/2507.00209)
> *SurgiSR4K：一个用于机器人辅助微创手术的高分辨率内窥镜视频数据集*

*Fengyi Jiang, Xiaorui Zhang, Lingbo Jin, Ruixing Liang, Yuxin Chen, Adi Chola Venkatesh, Jason Culman, Tiantian Wu, Lirong Shao, Wenqing Sun, Cong Gao, Hallie McNamara, Jingpei Lu, Omid Mohareri* | **Category: eess.IV, cs.AI, cs.CV, cs.RO**

**Keywords:** SurgiSR4K, 4K数据集, 机器人辅助手术, 微创手术, 计算机视觉

**Comment:** 

> **TL;DR:** SurgiSR4K是首个公开可用的原生4K分辨率机器人辅助微创手术视频数据集，旨在填补现有数据空白，并支持多种计算机视觉任务。

**AI_Comments:** SurgiSR4K数据集的创新之处在于它是首个公开可用的原生4K分辨率机器人辅助微创手术数据集，填补了该领域的重要空白。其重要性在于，高分辨率数据对于计算机辅助手术至关重要，该数据集的发布将极大地推动相关计算机视觉算法（如超分辨率、目标检测、3D重建等）在医疗领域的应用和发展，从而提高手术的精度和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 微创手术（MIS）中高分辨率成像对于提高视觉清晰度和实现精确的计算机辅助引导至关重要。然而，尽管4K内窥镜系统日益普及，但专门为机器人辅助MIS量身定制的公共原生4K数据集仍存在显著空白。

**Method:** 本文介绍了SurgiSR4K，这是第一个公开可用的原生4K分辨率手术图像和视频数据集，它捕捉了机器人辅助手术的真实条件。该数据集包含多种视觉场景，如镜面反射、工具遮挡、出血和软组织变形，旨在反映腹腔镜和机器人手术中常见的挑战。

**Result:** SurgiSR4K数据集的创建填补了机器人辅助微创手术领域原生4K分辨率公共数据集的空白。它提供了包含多种复杂视觉场景的数据，为高分辨率手术成像研究和智能成像技术开发奠定了坚实基础。

**Conclusion:** SurgiSR4K数据集为高分辨率手术成像研究提供了坚实基础，并促进了旨在提高图像引导机器人手术性能、安全性和可用性的智能成像技术的发展。该数据集为超分辨率、烟雾去除、手术器械检测等多种计算机视觉任务提供了可能性。

> **ai_Abstract:** 本文介绍了SurgiSR4K，一个针对机器人辅助微创手术的首个公开可用原生4K分辨率内窥镜视频数据集。该数据集旨在解决当前缺乏高分辨率手术数据的现状，并涵盖了真实手术中常见的挑战性视觉场景。SurgiSR4K的发布将为超分辨率、手术器械检测、3D重建等多种计算机视觉任务提供支持，从而推动高分辨率手术成像和智能图像引导手术技术的研究与发展。

> **摘要翻译:** 高分辨率成像对于提高微创手术（MIS）中的视觉清晰度并实现精确的计算机辅助引导至关重要。尽管4K内窥镜系统日益普及，但专门为机器人辅助MIS量身定制的公共原生4K数据集仍存在显著空白。我们介绍了SurgiSR4K，这是第一个公开可用的原生4K分辨率手术图像和视频数据集，它代表了机器人辅助手术的真实条件。SurgiSR4K包含多种视觉场景，包括镜面反射、工具遮挡、出血和软组织变形，经过精心设计以反映腹腔镜和机器人手术中常见的挑战。该数据集为可能受益于高分辨率数据的广泛计算机视觉任务打开了可能性，例如超分辨率（SR）、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视图合成和视觉-语言模型（VLM）开发。SurgiSR4K为推进高分辨率手术成像研究提供了坚实基础，并促进了旨在提高图像引导机器人手术性能、安全性和可用性的智能成像技术的发展。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [94] [Accurate and Efficient Fetal Birth Weight Estimation from 3D Ultrasound](https://arxiv.org/abs/2507.00398)
> *基于3D超声的准确高效胎儿出生体重估计*

*Jian Wang, Qiongying Ni, Hongkui Yu, Ruixuan Yao, Jinqiao Ying, Bin Zhang, Xingyi Yang, Jin Peng, Jiongquan Chen, Junxuan Yu, Wenlong Shi, Chaoyu Chen, Zhongnuo Yan, Mingyuan Luo, Gaocheng Cai, Dong Ni, Jing Lu, Xin Yang* | **Category: eess.IV, cs.CV**

**Keywords:** 胎儿出生体重估计, 3D超声, 深度学习, 多尺度特征融合, 半监督学习

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** 本文提出首个直接从3D胎儿超声体积估算胎儿出生体重的方法，通过多尺度特征融合网络和合成样本学习框架，实现了优于现有方法的准确性，并接近资深医生的水平。

**AI_Comments:** 该论文的创新点在于首次将3D超声体积直接应用于胎儿出生体重估计，克服了2D超声缺乏空间信息的限制。其提出的MFFN和SSLF框架有效解决了稀疏监督和数据增强的挑战，显著提升了估计精度，使其接近人类专家的水平，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 准确估计胎儿出生体重对优化分娩决策和降低围产期死亡率至关重要。然而，现有临床方法效率低下、依赖操作者且难以应用于复杂胎儿解剖结构；现有深度学习方法基于2D图像，缺乏空间信息，限制了预测精度。

**Method:** 本文提出首个直接从3D胎儿超声体积估算胎儿出生体重的方法。该方法整合了多尺度特征融合网络（MFFN）和合成样本学习框架（SSLF）。MFFN通过引入通道注意力、空间注意力和基于排名的损失函数，在稀疏监督下有效提取并融合多尺度特征。SSLF通过简单结合不同胎儿的头部和腹部数据生成合成样本，并利用半监督学习提高预测性能。

**Result:** 实验结果表明，该方法表现优越，平均绝对误差为$166.4\pm155.9$克，平均绝对百分比误差为$5.1\pm4.6$%。该方法优于现有方法，并接近资深医生的准确性。

**Conclusion:** 本文提出的基于3D超声的胎儿出生体重估计方法显著提高了预测精度和效率，克服了传统方法和现有2D深度学习方法的局限性，为临床实践提供了更可靠的工具。

> **ai_Abstract:** 本研究提出了一种创新方法，首次直接利用3D胎儿超声体积来准确高效地估计胎儿出生体重。该方法结合了多尺度特征融合网络（MFFN）和合成样本学习框架（SSLF），旨在克服传统2D超声和现有深度学习方法在空间信息和效率方面的局限性。MFFN通过注意力机制和排名损失处理稀疏监督下的特征提取，而SSLF则通过生成合成样本并结合半监督学习来提升预测性能。实验证明，该方法在精度上显著优于现有技术，其性能接近资深医生水平，为临床决策提供了更可靠的依据。

> **摘要翻译:** 准确估计胎儿出生体重（FBW）对于优化分娩决策和降低围产期死亡率至关重要。然而，临床上估计FBW的方法效率低下、依赖操作者，并且在胎儿解剖结构复杂的情况下难以应用。现有的深度学习方法基于2D标准超声（US）图像或视频，缺乏空间信息，限制了其预测精度。在本研究中，我们提出了第一个直接从3D胎儿超声体积估计FBW的方法。我们的方法整合了一个多尺度特征融合网络（MFFN）和一个基于合成样本的学习框架（SSLF）。MFFN通过结合通道注意力、空间注意力和基于排名的损失函数，在稀疏监督下有效提取和融合多尺度特征。SSLF通过简单地结合来自不同胎儿的胎儿头部和腹部数据来生成合成样本，利用半监督学习来提高预测性能。实验结果表明，我们的方法取得了卓越的性能，平均绝对误差为$166.4\pm155.9$克，平均绝对百分比误差为$5.1\pm4.6$%，优于现有方法并接近资深医生的准确性。代码可在https://github.com/Qioy-i/EFW获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [117] [Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+](https://arxiv.org/abs/2507.00511)
> *使用先进 U-Net 的医学图像分割：VMSE-Unet 和 VM-Unet CBAM+*

*Sayandeep Kanrar, Raja Piyush, Qaiser Razi, Debanshi Chakraborty, Vikas Hassija, GSS Chalapathi* | **Category: eess.IV, cs.CV, cs.LG**

**Keywords:** 医学图像分割, U-Net, 注意力机制, 深度学习, VMSE-Unet

**Comment:** under review

> **TL;DR:** 本研究提出了两种改进的U-Net模型（VMSE-Unet和VM-Unet CBAM+），通过集成SE和CBAM模块，显著提升了医学图像分割的准确性、特征定位和计算效率。VMSE-Unet表现最佳，具有高精度和高效率，有望应用于临床。

**AI_Comments:** 该论文创新性地将注意力机制（SE和CBAM）引入到VM U-Net架构中，有效提升了医学图像分割的性能。其在提高准确性和计算效率方面的双重优势，使得VMSE-Unet在临床应用中具有重要的潜力。未来研究可进一步探索其在不同病理图像和3D分割任务中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过开发先进的深度学习架构，提升医学图像分割的准确性、特征定位和计算效率。

**Method:** 本研究提出了VMSE U-Net和VM-Unet CBAM+模型，这两种模型将Squeeze-and-Excitation (SE)和Convolutional Block Attention Module (CBAM)技术集成到传统的VM U-Net框架中。

**Result:** 与基线VM-Unet相比，VMSE U-Net和VM-Unet CBAM+模型在多个数据集上均表现出卓越的性能。VMSE-Unet在准确性、IoU、精确度和召回率方面达到了最高水平，同时保持了低损失值。它还在GPU和CPU上展现出卓越的计算效率，推理时间更快，内存使用量更低。

**Conclusion:** 增强型架构VMSE-Unet是医学图像分析的宝贵工具，其研究结果突显了其在现实世界临床应用中的潜力，并强调了进一步研究以优化准确性、鲁棒性和计算效率的重要性。

> **ai_Abstract:** 本论文介绍了VMSE U-Net和VM-Unet CBAM+两种先进的深度学习模型，用于改进医学图像分割。通过将Squeeze-and-Excitation (SE)和Convolutional Block Attention Module (CBAM)集成到传统的VM U-Net中，这些模型显著提升了分割精度、特征定位和计算效率。实验结果表明，与基线VM-Unet相比，两种模型性能更优，其中VMSE-Unet表现最佳，在准确性、IoU、精确度、召回率和计算效率方面均达到领先水平。研究表明VMSE-Unet是医学图像分析的有效工具，具有潜在的临床应用价值。

> **摘要翻译:** 在本文中，我们提出了VMSE U-Net和VM-Unet CBAM+模型，这两种尖端的深度学习架构旨在增强医学图像分割。我们的方法将Squeeze-and-Excitation (SE)和Convolutional Block Attention Module (CBAM)技术集成到传统的VM U-Net框架中，显著提高了分割精度、特征定位和计算效率。与基线VM-Unet相比，这两种模型在多个数据集上均表现出卓越的性能。值得注意的是，VMSE-Unet在保持低损失值的同时，实现了最高的准确性、IoU、精确度和召回率。它还在GPU和CPU上展现出卓越的计算效率，推理时间更快，内存使用量更低。总体而言，这项研究表明增强型架构VMSE-Unet是医学图像分析的宝贵工具。这些发现突显了其在现实世界临床应用中的潜力，强调了进一步研究以优化准确性、鲁棒性和计算效率的重要性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [140] [Anti-aliasing Algorithm Based on Three-dimensional Display Image](https://arxiv.org/abs/2507.00527)
> *基于三维显示图像的抗锯齿算法*

*Ziyang Liu, Xingchen Xiao, Yueyang Xu* | **Category: eess.IV**

**Keywords:** 三维显示, 抗锯齿, 失真, 锯齿, 柱状透镜阵列

**Comment:** 

> **TL;DR:** 本文提出了一种基于空间和频率处理的抗锯齿算法，旨在解决裸眼3D显示设备中图像和文本的严重失真和锯齿问题，并通过提取柱状透镜阵列的退化函数来从根本上消除退化。

**AI_Comments:** 该论文旨在解决裸眼3D显示中普遍存在的图像失真和锯齿问题，这是一个重要的实际挑战。其创新点在于结合了空间和频率处理，并试图从光学原理（柱状透镜阵列退化函数）上解决问题，这可能提供一种更根本的解决方案。然而，摘要中未提及具体的实现细节和实验结果，无法评估其方法的有效性和实际效果。

<details>
  <summary>Details</summary>

**Motivation:** 裸眼3D显示技术在显示未经处理的图像和文本时会出现严重的失真和锯齿，极大地影响显示效果，因此需要一种方法来解决这种退化。

**Method:** 本研究尝试通过空间和频率处理来解决显示退化问题，并努力提取柱状透镜阵列的退化函数，以从根本上消除退化。

**Result:** 未在摘要中提及

**Conclusion:** 未在摘要中提及

> **ai_Abstract:** 本文针对裸眼3D显示设备中图像和文本存在的严重失真和锯齿问题，提出了一种基于空间和频率处理的抗锯齿算法。该方法旨在通过处理显示退化，并进一步提取柱状透镜阵列的退化函数，以期从根本上消除此类显示缺陷。

> **摘要翻译:** 三维显示技术是一个有前景的新兴领域，有潜力成为下一代显示技术的核心。当通过裸眼三维显示设备直接观察未经处理的图像和文本时，会出现严重的失真和锯齿，这将使显示效果大打折扣。在这项工作中，我们试图通过空间和频率处理来解决这种退化问题，此外，我们努力提取柱状透镜阵列的退化函数，从而从根本上消除退化。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [163] [Bridging Classical and Learning-based Iterative Registration through Deep Equilibrium Models](https://arxiv.org/abs/2507.00582)
> *通过深度平衡模型连接经典与学习型迭代配准*

*Yi Zhang, Yidong Zhao, Qian Tao* | **Category: eess.IV, cs.CV**

**Keywords:** 深度平衡模型, 医学图像配准, 变形配准, 收敛性, 内存效率

**Comment:** Submitted version. Accepted by MICCAI 2025

> **TL;DR:** 本文提出DEQReg，一种基于深度平衡模型（DEQ）的医学图像配准新框架，解决了现有学习型迭代配准方法缺乏收敛保证和内存消耗大的问题，实现了稳定收敛和显著的内存效率。

**AI_Comments:** DEQReg的创新之处在于将深度平衡模型引入医学图像配准，巧妙地将经典优化方法的收敛性与深度学习的表达能力相结合。通过将配准问题建模为平衡寻求问题，它不仅解决了基于展开的RNN方法在收敛性和内存效率方面的固有缺陷，还提供了一个理论上更坚实的基础。其保持恒定内存使用量和实现稳定收敛的能力，对实际应用具有重要意义，尤其是在处理大规模数据和需要高精度迭代的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 传统的变形医学图像配准方法是迭代求解的，而近期基于学习的方法（RNN）通过固定步数展开来模仿这一过程，但它们缺乏理论收敛保证且经验上不稳定。此外，展开方法在训练时存在实际瓶颈：由于反向传播（BPTT），GPU内存使用量随展开步数线性增长。现有展开方法在推断步数超过训练配置时性能会下降。

**Method:** 我们提出了DEQReg，一个基于深度平衡模型（DEQ）的新型配准框架，将配准问题表述为一个寻求平衡的问题。这在经典优化方法和基于学习的展开方法之间建立了自然的联系。DEQReg保持恒定的内存使用量，理论上支持无限迭代步数。

**Result:** DEQReg在公共脑部MRI和肺部CT数据集上进行了广泛评估，结果显示其能达到有竞争力的配准性能，同时相比最先进的展开方法显著降低了内存消耗。研究还发现一个有趣的现象：现有展开方法在推断步数超出训练配置时，性能先略有提升然后不可逆转地下降。相反，DEQReg凭借其内置的平衡寻求机制实现了稳定收敛。

**Conclusion:** DEQReg通过其内置的平衡寻求机制实现了稳定收敛，成功弥合了经典基于优化和现代基于学习的配准方法之间的鸿沟，并解决了现有学习型展开方法的理论和实践挑战。

> **ai_Abstract:** 本文提出DEQReg，一种基于深度平衡模型（DEQ）的新型变形医学图像配准框架。与传统的迭代优化方法和现有基于循环神经网络的展开方法相比，DEQReg通过将配准建模为平衡寻求问题，解决了学习型展开方法缺乏收敛保证、经验不稳定以及训练时内存消耗随迭代步数线性增长的问题。DEQReg实现了恒定的内存使用量和理论上无限的迭代步数，并在脑部MRI和肺部CT数据集上展示了与现有方法相当的配准性能，同时显著降低了内存消耗。此外，DEQReg在推断步数增加时表现出稳定的收敛性，成功连接了经典优化与现代学习型配准方法。

> **摘要翻译:** 变形医学图像配准传统上被公式化为一个优化问题。虽然经典方法迭代地解决这个问题，但最近基于学习的方法使用循环神经网络（RNN）通过固定步数展开变形场预测来模仿这一过程。然而，经典方法通常在足够迭代后收敛，而基于学习的展开方法缺乏理论收敛保证并且经验上显示出不稳定性。此外，展开方法在训练时存在实际瓶颈：由于通过时间反向传播（BPTT），GPU内存使用量随展开步数线性增长。为了解决理论和实践上的挑战，我们提出了DEQReg，一个基于深度平衡模型（DEQ）的新型配准框架，它将配准公式化为一个寻求平衡的问题，从而在经典优化和基于学习的展开方法之间建立了自然的联系。DEQReg保持恒定的内存使用量，从而实现理论上无限的迭代步数。通过在公共脑部MRI和肺部CT数据集上进行广泛评估，我们表明DEQReg可以实现有竞争力的配准性能，同时相比最先进的展开方法显著降低内存消耗。我们还揭示了一个有趣的现象：现有展开方法的性能在推断步数超出训练配置时，先略有提升然后不可逆转地下降。相比之下，DEQReg凭借其内置的平衡寻求机制实现了稳定收敛，弥合了经典基于优化和现代基于学习的配准方法之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [182] [Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping](https://arxiv.org/abs/2507.00613)
> *心脏T1图谱中用于时间动态建模的物理信息神经ODE*

*Nuno Capitão, Yi Zhang, Yidong Zhao, Qian Tao* | **Category: eess.IV, cs.AI**

**Keywords:** T1图谱, 物理信息神经ODE, 心脏MRI, 时间动态, 稀疏数据

**Comment:** Submitted version. Accepted at MICCAI 2025

> **TL;DR:** 本文提出了一种基于物理信息神经ODE的加速端到端T1图谱框架，可从稀疏基线图像中实现高精度T1估计，并克服了传统方法和现有深度学习方法的局限性。

**AI_Comments:** 本文的创新点在于将物理信息（通过ODE）与深度学习模型（LSTM）相结合，有效解决了传统T1图谱方法效率低、易受运动影响以及现有深度学习方法缺乏物理约束和可解释性的问题。这种结合使得模型在保持数据驱动优势的同时，融入了领域知识，增强了模型的泛化能力和结果的可靠性。其在稀疏数据下的高精度表现，对于临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的T1图谱方法（如MOLLI）扫描时间长，对患者不友好且易受运动伪影影响；同时，其需要复杂的体素级非线性拟合。现有深度学习方法虽能加速，但忽略了重要的物理约束，限制了解释性和泛化能力。

**Method:** 提出了一种加速的、端到端T1图谱框架，利用物理信息神经常微分方程（ODEs）来建模时间动态。具体而言，开发了一个连续时间LSTM-ODE模型，以实现任意时间延迟的选择性Look-Locker（LL）数据采集。

**Result:** 该方法能够从稀疏的基线图像子集中实现高精度的T1估计，并确保在测试时进行高效的零点指数估计。实验结果表明，该方法在原生和对比剂增强序列的T1估计中均表现出卓越的性能，并证明了基于物理的公式优于直接数据驱动的T1先验。

**Conclusion:** 本文提出的基于物理信息神经ODE的T1图谱框架，通过建模时间动态，克服了传统方法耗时和现有深度学习方法缺乏物理约束的挑战，实现了高精度、高效且具有良好泛化能力的T1估计。

> **ai_Abstract:** 本文提出了一种利用物理信息神经常微分方程（ODEs）的端到端T1图谱框架，以克服传统方法耗时长、易受伪影影响以及现有深度学习方法缺乏物理约束的缺点。通过开发连续时间LSTM-ODE模型，该方法能从稀疏图像数据中实现高精度T1估计，并支持任意时间延迟的数据采集。实验证明，该物理信息方法在T1估计上优于现有数据驱动方法，提高了心肌T1图谱的效率、准确性和可解释性。

> **摘要翻译:** 自旋晶格弛豫时间（T1）是心脏参数图谱中用于表征心肌组织和诊断心肌病的重要生物标志物。传统的改良Look-Locker反转恢复（MOLLI）方法需要采集11幅屏气基线图像，并穿插休息时间以确保图谱精度。然而，长时间扫描对屏气能力差的患者来说可能具有挑战性，常导致运动伪影，从而降低图像质量。此外，T1图谱需要对信号恢复模型进行体素级的非线性拟合，这涉及迭代估计过程。最近的研究提出了深度学习方法，通过缩短序列来加速T1图谱，以提高患者舒适度。然而，现有方法忽略了重要的物理约束，限制了解释性和泛化能力。在这项工作中，我们提出了一种加速的、端到端T1图谱框架，利用物理信息神经常微分方程（ODEs）来建模时间动态并解决这些挑战。我们的方法能够从稀疏的基线图像子集中实现高精度的T1估计，并确保在测试时进行高效的零点指数估计。具体而言，我们开发了一个连续时间LSTM-ODE模型，以实现任意时间延迟的选择性Look-Locker（LL）数据采集。实验结果表明，该方法在原生和对比剂增强序列的T1估计中均表现出卓越的性能，并证明了我们的基于物理的公式优于直接数据驱动的T1先验。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [201] [MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound](https://arxiv.org/abs/2507.00660)
> *MTCNet：运动与拓扑一致性引导学习在4D超声心动图中二尖瓣分割的应用*

*Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang, Dan Jia, Yuhan Zhang, Xing Tao, Haoran Dou, Qing Zhou, Xin Yang, Dong Ni* | **Category: eess.IV, cs.AI, cs.CV**

**Keywords:** 4D超声, 二尖瓣分割, 半监督学习, 运动一致性, 拓扑一致性

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** MTCNet是一个半监督网络，通过运动和拓扑一致性学习，解决了4D超声二尖瓣分割中缺乏跨期依赖性和标注稀疏的问题，取得了优越的跨期一致性分割效果。

**AI_Comments:** MTCNet的创新之处在于其结合了运动引导和拓扑引导的一致性学习策略，特别是利用双向注意力记忆库来处理时空特征，并引入了拓扑正则化来保持解剖学合理性。这种方法有效解决了4D超声影像中常见的标注稀疏和运动伪影问题，显著提升了二尖瓣分割的跨相位一致性，对于临床诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 4D二尖瓣（MV）分析面临挑战，包括有限的相位标注、严重的运动伪影和较差的成像质量。现有方法缺乏相间依赖性，阻碍了4D MV分析。

**Method:** 本文提出了一种运动-拓扑引导一致性网络（MTCNet），用于半监督学习中的精确4D MV超声分割，仅需要稀疏的舒张末期和收缩末期标注。MTCNet包含两个主要策略：1) 跨相位运动引导一致性学习策略，利用双向注意力记忆库传播时空特征；2) 新颖的拓扑引导相关性正则化，探索物理先验知识以保持解剖学合理性。

**Result:** 在最大的4D MV数据集（包含160名患者的1408个相位）上进行的广泛评估表明，MTCNet相比其他先进方法表现出卓越的跨相位一致性（Dice：87.30%，HD：1.75mm）。

**Conclusion:** MTCNet通过运动和拓扑一致性学习，能够有效利用标注和未标注相位之间的结构对应关系，在4D超声二尖瓣分割中实现优越的跨相位一致性表现。

> **ai_Abstract:** 本文提出了MTCNet，一个用于4D超声二尖瓣分割的半监督学习网络，旨在解决现有方法在处理有限标注和缺乏相间依赖性方面的不足。MTCNet通过引入跨相位运动引导一致性学习和拓扑引导相关性正则化，有效利用了标注和未标注相位之间的结构对应关系，从而在大型4D MV数据集上实现了优异的跨相位一致性分割性能。

> **摘要翻译:** 二尖瓣反流是最常见的心脏疾病之一。四维（4D）超声已成为评估动态瓣膜形态的主要成像方式。然而，由于有限的相位标注、严重的运动伪影和较差的成像质量，4D二尖瓣（MV）分析仍然具有挑战性。此外，现有方法缺乏相间依赖性，阻碍了4D MV分析。为了弥补这一空白，我们提出了一种运动-拓扑引导一致性网络（MTCNet），用于半监督学习（SSL）中精确的4D MV超声分割。MTCNet仅需要稀疏的舒张末期和收缩末期标注。首先，我们设计了一种跨相位运动引导一致性学习策略，利用双向注意力记忆库传播时空特征。这使得MTCNet能够在每个相位和相间都取得优异的性能。其次，我们设计了一种新颖的拓扑引导相关性正则化，探索物理先验知识以保持解剖学合理性。因此，MTCNet可以有效利用标注和未标注相位之间的结构对应关系。在第一个最大的4D MV数据集（包含160名患者的1408个相位）上进行的广泛评估表明，MTCNet相比其他先进方法表现出卓越的跨相位一致性（Dice：87.30%，HD：1.75mm）。代码和数据集均可在https://github.com/crs524/MTCNet获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [217] [Mind the Detail: Uncovering Clinically Relevant Image Details in Accelerated MRI with Semantically Diverse Reconstructions](https://arxiv.org/abs/2507.00670)
> *关注细节：通过语义多样化重建揭示加速MRI中临床相关图像细节*

*Jan Nikolas Morshuis, Christian Schlarmann, Thomas Küstner, Christian F. Baumgartner, Matthias Hein* | **Category: eess.IV, cs.CV**

**Keywords:** 加速MRI, 深度学习, 图像重建, 临床诊断, 语义多样性

**Comment:** MICCAI 2025

> **TL;DR:** 现有加速MRI重建可能遗漏临床相关细节，导致误诊。本文提出SDR方法，生成多样化重建，显著减少漏诊。

**AI_Comments:** 本文的创新点在于提出了“语义多样化重建”这一新颖概念，旨在解决现有加速MRI重建可能遗漏临床关键细节的问题。其重要性在于直接关注了图像质量之外的临床实用性，即诊断准确性，并通过生成多样化重建来主动揭示潜在的病理信息，而非仅仅优化感知质量。这种方法对于提高深度学习在医疗影像领域的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习加速MRI重建在图像质量上取得了显著进步，但从临床角度看，更重要的是确保所有临床相关信息（尤其是小型和罕见病理）在高度欠采样数据的重建中得以保留，现有技术可能无法重建这些细节，从而导致潜在的错误诊断（假阴性）。

**Method:** 本文提出了“语义多样化重建”（SDR）方法，该方法在给定原始重建的基础上，生成具有增强语义变异性的新重建，同时所有重建都与测量数据完全一致。为了自动评估SDR，研究人员在fastMRI+数据集上训练了一个对象检测器。

**Result:** SDR显著降低了假阴性诊断的可能性（提高了召回率），并且与原始重建相比，提高了平均精度。

**Conclusion:** SDR能够有效揭示加速MRI中可能被现有方法遗漏的临床相关细节，从而提高诊断的准确性，减少假阴性诊断的风险。

> **ai_Abstract:** 本文旨在解决深度学习加速MRI重建中可能遗漏临床关键细节的问题。研究指出，现有方法即使在图像质量表现良好时，也可能无法重建小型和罕见病理，导致潜在的假阴性诊断。为此，本文提出了一种名为“语义多样化重建”（SDR）的新方法，该方法在给定原始重建的基础上，生成与测量数据一致且具有增强语义变异性的新重建，以揭示潜在缺失的临床信息。通过在fastMRI+数据集上训练对象检测器进行评估，结果显示SDR显著降低了假阴性诊断的风险，并提高了平均精度，从而提升了加速MRI在临床应用中的可靠性。

> **摘要翻译:** 近年来，基于深度学习的加速MRI重建在图像质量方面取得了显著进步，在高加速因子下表现出色。然而，从临床角度看，图像质量是次要的；更重要的是，所有临床相关信息都必须在高度欠采样数据的重建中得以保留。在本文中，我们展示了现有技术，即使考虑基于扩散重建的重采样，也可能无法重建小型和罕见病理，从而导致潜在的错误诊断决策（假阴性）。为了揭示潜在缺失的临床信息，我们提出了“语义多样化重建”（SDR），这是一种在给定原始重建的情况下，生成具有增强语义变异性的新重建的方法，同时所有重建都与测量数据完全一致。为了自动评估SDR，我们在fastMRI+数据集上训练了一个对象检测器。我们表明，与原始重建相比，SDR显著降低了假阴性诊断的可能性（更高的召回率）并提高了平均精度。代码可在https://github.com/NikolasMorshuis/SDR 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [231] [Prompt2SegCXR:Prompt to Segment All Organs and Diseases in Chest X-rays](https://arxiv.org/abs/2507.00673)
> *Prompt2SegCXR：提示分割胸部X光片中的所有器官和疾病*

*Abduz Zami, Shadman Sobhan, Rounaq Hossain, Md. Sawran Sorker, Mohiuddin Ahmed, Md. Redwan Hossain* | **Category: eess.IV, cs.CV**

**Keywords:** 胸部X光片, 图像分割, 基于提示, 多器官分割, 多疾病分割

**Comment:** 29 Pages

> **TL;DR:** 本文提出Prompt2SegCXR模型，旨在通过用户提示在胸部X光片中分割多种器官和疾病，并为此构建了一个新的、包含23个类别（6个器官和17种疾病）的专家标注涂鸦提示数据集。

**AI_Comments:** 这项工作通过引入一个专门为胸部X光片设计的、基于提示的多器官多疾病分割模型Prompt2SegCXR，填补了现有研究在这一特定领域的空白。其创新之处在于结合了医学专家生成的涂鸦提示数据集，这为模型的训练和交互式应用提供了独特的支持。多阶段特征融合的设计有助于提高模型的空间和语义理解能力，从而显著提升分割精度，使其成为一个具有实际应用潜力的临床工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统图像分割模型通常只针对特定器官或疾病进行训练，限制了其处理其他区域的能力。目前缺乏能够灵活处理多器官和多疾病分割的先进模型，尤其是在胸部X光片领域，还没有专门针对基于提示的交互式多器官和多疾病分割的工作。

**Method:** 本文提出了两项主要贡献：1. 由医学专家生成了一个包含来自多个来源的23个类别（6个器官和17种疾病）数据集的涂鸦提示，专为基于提示的胸部X光片分割设计。2. 引入了Prompt2SegCXR，一个轻量级模型，通过结合多阶段特征融合技术，提高了空间和语义理解能力，从而准确分割胸部X光片中的多种器官和疾病。

**Result:** 与现有基于提示的图像分割预训练模型相比，Prompt2SegCXR模型表现良好，提供了可靠的解决方案。

**Conclusion:** Prompt2SegCXR为基于用户提示的胸部X光片分割提供了一个可靠且有效的解决方案。

> **ai_Abstract:** 本文针对传统医学图像分割模型在处理多器官和多疾病方面的局限性，以及基于提示的分割在胸部X光片应用中的空白，提出了Prompt2SegCXR模型。该模型是一个轻量级的解决方案，通过结合多阶段特征融合技术，能够准确地根据用户提示分割胸部X光片中的多种器官和疾病。同时，研究还构建了一个包含23个类别（6个器官和17种疾病）的专门数据集，其中包含医学专家生成的涂鸦提示，以支持基于提示的胸部X光片分割任务。实验结果表明，Prompt2SegCXR在分割精度方面优于现有预训练模型，为临床应用提供了可靠的工具。

> **摘要翻译:** 图像分割通过将器官或感兴趣区域从周围区域中分离出来，在医学领域发挥着至关重要的作用。传统上，分割模型针对特定器官或疾病进行训练，限制了它们处理其他器官和疾病的能力。目前，很少有先进模型能够进行多器官或多疾病分割，提供更大的灵活性。此外，最近，基于提示的图像分割作为一种更灵活的方法受到了关注。它允许模型根据用户提供的提示分割区域。尽管取得了这些进展，但还没有专门针对胸部X光片的基于提示的交互式多器官和多疾病分割工作。这项工作提出了两个主要贡献：首先，由医学专家生成了来自多个来源的数据集集合的涂鸦提示，包含23个类别，包括6个器官和17种疾病，专门设计用于基于提示的胸部X光片分割。其次，我们介绍了Prompt2SegCXR，一个轻量级模型，用于准确分割胸部X光片中的多种器官和疾病。该模型结合了多阶段特征融合，使其能够结合来自不同网络层的特征，以更好地理解空间和语义，从而提高分割精度。与现有基于提示的图像分割的预训练模型相比，我们的模型表现良好，为基于用户提示的胸部X光片分割提供了可靠的解决方案。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [244] [Tunable Wavelet Unit based Convolutional Neural Network in Optical Coherence Tomography Analysis Enhancement for Classifying Type of Epiretinal Membrane Surgery](https://arxiv.org/abs/2507.00743)
> *可调小波单元卷积神经网络在光学相干断层扫描分析增强中用于分类视网膜前膜手术类型*

*An Le, Nehal Mehta, William Freeman, Ines Nagel, Melanie Tran, Anna Heinke, Akshay Agnihotri, Lingyun Cheng, Dirk-Uwe Bartsch, Hung Nguyen, Truong Nguyen, Cheolhong An* | **Category: eess.IV, cs.CV, eess.SP**

**Keywords:** 可调小波单元, 卷积神经网络, 光学相干断层扫描, 视网膜前膜, 图像分类

**Comment:** 

> **TL;DR:** 研究开发了一种基于可调小波单元CNN的模型，用于从术后OCT图像中分类视网膜前膜手术类型（ILM切除或ERM单独切除），实现了78%的准确率，优于人类分级员。

**AI_Comments:** 这篇论文的创新点在于首次将可调小波单元集成到CNN中用于医学图像分类，特别是针对视网膜前膜手术类型的区分。通过允许滤波器系数在训练中自动调整，模型能够更好地捕捉图像特征，从而显著提高了分类准确率，并超越了人类专家的表现。这为眼科诊断和临床决策提供了新的、更准确的辅助工具。

<details>
  <summary>Details</summary>

**Motivation:** 提高临床决策中对视网膜前膜手术类型分类的准确性和可靠性。

**Method:** 本研究基于ResNet18卷积神经网络（CNN）架构，使用术后光学相干断层扫描（OCT）中心扫描作为输入。模型评估使用了原始扫描和经过能量裁剪和小波去噪预处理的扫描。为提高准确率，研究集成了两种可调小波单元：Orthogonal Lattice-based Wavelet Units (OrthLatt-UwU) 和 Perfect Reconstruction Relaxation-based Wavelet Units (PR-Relax-UwU)。这些单元被整合到下采样、步长为二的卷积和池化层中，允许模型在训练期间自动调整滤波器系数。

**Result:** 在预处理输入上，模型实现了72%的准确率，优于原始扫描的66%。集成OrthLatt-UwU后准确率提升至76%，PR-Relax-UwU则将性能提高到78%。该AI模型的性能优于训练有素的人类分级员（50%准确率）。

**Conclusion:** 基于CNN的模型，特别是结合了可调小波单元的模型，在分类视网膜前膜手术类型方面具有提高临床决策的潜力。这是首次将可调小波应用于分类不同类型ERM切除手术的工作。

> **ai_Abstract:** 这项研究开发了一种基于ResNet18卷积神经网络的深度学习模型，用于从术后光学相干断层扫描（OCT）图像中区分两种视网膜前膜（ERM）手术类型：内界膜切除或ERM单独切除。通过引入可调小波单元（OrthLatt-UwU和PR-Relax-UwU），模型能够在训练中自适应调整滤波器系数，显著提升了分类准确率，PR-Relax-UwU达到了78%，远超人类分级员的50%。该工作首次将可调小波应用于此类医学图像分类任务，展示了CNN模型在改善临床决策方面的巨大潜力。

> **摘要翻译:** 标题：可调小波单元卷积神经网络在光学相干断层扫描分析增强中用于分类视网膜前膜手术类型

摘要：在这项研究中，我们开发了一种基于深度学习的方法，用于分类视网膜前膜（ERM）切除手术的类型，无论是内界膜（ILM）切除还是单独ERM切除。我们的模型基于ResNet18卷积神经网络（CNN）架构，使用术后光学相干断层扫描（OCT）中心扫描作为输入。我们使用原始扫描和经过能量裁剪和小波去噪预处理的扫描对模型进行了评估，在预处理输入上实现了72%的准确率，优于原始扫描的66%准确率。为了进一步提高准确率，我们集成了可调小波单元，并进行了两项关键调整：基于正交格的小波单元（OrthLatt-UwU）和基于完美重建松弛的小波单元（PR-Relax-UwU）。这些单元允许模型在训练期间自动调整滤波器系数，并被整合到下采样、步长为二的卷积和池化层中，增强了其区分ERM-ILM切除和ERM单独切除的能力，其中OrthLattUwU将准确率提高到76%，PR-Relax-UwU将性能提高到78%。性能比较表明，我们的AI模型优于训练有素的人类分级员，后者在从术后OCT扫描中分类切除手术类型时仅达到50%的准确率。这些发现突出了基于CNN的模型通过提供更准确、更可靠的分类来改善临床决策的潜力。据我们所知，这是首次采用可调小波来分类不同类型的ERM切除手术。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [257] [Research on Improving the High Precision and Lightweight Diabetic Retinopathy Detection of YOLOv8n](https://arxiv.org/abs/2507.00780)
> *YOLOv8n高精度轻量化糖尿病视网膜病变检测改进研究*

*Fei Yuhuan, Sun Xufei, Zang Ran, Wang Gengchen, Su Meng, Liu Fenghao* | **Category: eess.IV, cs.CV**

**Keywords:** 糖尿病视网膜病变, YOLOv8n, 目标检测, 轻量化, 深度学习

**Comment:** in Chinese language

> **TL;DR:** 本文提出了一种名为YOLO-KFG的改进型YOLOv8n模型，用于高精度轻量化糖尿病视网膜病变检测，显著提高了检测精度和效率。

**AI_Comments:** 本文的创新点在于结合了动态卷积、多尺度特征融合和轻量化设计，有效提升了YOLOv8n在糖尿病视网膜病变检测任务上的性能。其重要性在于提供了一个高精度且易于部署的解决方案，有助于推动糖尿病视网膜病变的早期筛查和诊断。模型的轻量化特性使其在移动或嵌入式医疗设备上的应用潜力巨大。

<details>
  <summary>Details</summary>

**Motivation:** 早期糖尿病视网膜病变检测和诊断是眼科研究热点，但现有方法在准确性和鲁棒性方面面临挑战，尤其是在微小病变特征不明显且易受背景干扰的情况下。

**Method:** 提出了一种基于改进YOLOv8n的轻量化高精度检测模型YOLO-KFG。具体方法包括：1. 设计新的动态卷积KWConv和C2f-KW模块改进骨干网络，增强微小病变感知能力。2. 设计特征聚焦扩散金字塔网络FDPN，充分整合多尺度上下文信息，进一步提高微小病变感知能力。3. 设计轻量级共享检测头GSDHead，减少模型参数量，便于部署于资源受限设备。

**Result:** 与基础模型YOLOv8n相比，改进模型参数量减少20.7%，mAP@0.5提高4.1%，召回率提高7.9%。与YOLOv5n和YOLOv10n等单阶段主流算法相比，YOLO-KFG在检测精度和效率方面均表现出显著优势。

**Conclusion:** YOLO-KFG模型有效解决了糖尿病视网膜病变检测中精度和轻量化的挑战，在保持高精度的同时显著降低了模型复杂度，使其更适用于实际部署。

> **ai_Abstract:** 本文针对糖尿病视网膜病变早期检测中现有方法精度和鲁棒性不足的问题，提出了一种改进的YOLOv8n模型YOLO-KFG。该模型通过引入动态卷积KWConv、C2f-KW模块、特征聚焦扩散金字塔网络FDPN和轻量级共享检测头GSDHead，显著提升了对微小病变的感知能力，同时大幅减少了模型参数量。实验证明，YOLO-KFG在保持高检测精度的前提下实现了轻量化，性能优于YOLOv8n及其他主流单阶段算法，适用于资源受限设备的部署。

> **摘要翻译:** 糖尿病视网膜病变的早期检测和诊断是当前眼科学的研究重点之一。然而，由于微小病变特征的细微性及其易受背景干扰的影响，现有检测方法在准确性和鲁棒性方面仍面临诸多挑战。为解决这些问题，本文提出了一种基于改进YOLOv8n的轻量化高精度检测模型，命名为YOLO-KFG。首先，设计了一种新的动态卷积KWConv和C2f-KW模块来改进骨干网络，增强模型感知微小病变的能力。其次，设计了一种特征聚焦扩散金字塔网络FDPN，以充分整合多尺度上下文信息，进一步提高模型感知微小病变的能力。最后，设计了一种轻量级共享检测头GSDHead，以减少模型的参数量，使其更易于部署在资源受限的设备上。实验结果表明，与基础模型YOLOv8n相比，改进后的模型参数量减少了20.7%，mAP@0.5提高了4.1%，召回率提高了7.9%。与YOLOv5n和YOLOv10n等单阶段主流算法相比，YOLO-KFG在检测精度和效率方面均表现出显著优势。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [268] [Adiabatic Capacitive Neuron: An Energy-Efficient Functional Unit for Artificial Neural Networks](https://arxiv.org/abs/2507.00831)
> *绝热电容神经元：一种用于人工神经网络的节能功能单元*

*Sachin Maheshwari, Mike Smart, Himadri Singh Raghav, Themis Prodromakis, Alexander Serb* | **Category: eess.IV**

**Keywords:** 绝热电容神经元, 人工神经网络, 节能, 阈值逻辑, CMOS技术

**Comment:** 12 pages, 18 figures, 7 tables. This work has been submitted to the
  IEEE for possible publication

> **TL;DR:** 提出了一种新型的绝热电容神经元（ACN）硬件实现，具有更高的能效、精度和鲁棒性，并展示了显著的能耗节省。

**AI_Comments:** 这项工作在人工神经网络硬件实现方面具有重要创新，通过引入绝热计算原理和优化的阈值逻辑设计，显著提升了神经元的能效，对于边缘AI设备和低功耗神经网络应用具有重要意义。其详细的仿真验证和对工艺、温度、电压变化的鲁棒性分析增加了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人工神经元硬件实现可能在能效、功能、精度、鲁棒性和可扩展性方面有待改进。

**Method:** 本文引入了绝热电容神经元（ACN）作为人工神经元（AN）的硬件实现，并在0.18µm CMOS技术中实现了12位单神经元。此外，提出了一种新的阈值逻辑（TL）设计用于二元AN激活函数。通过版图后仿真和蒙特卡洛仿真验证了性能，并评估了电源电压缩放的影响。

**Result:** 所提出的阈值逻辑（TL）设计在宽泛的温度和工艺条件下产生了低对称偏移，最大上升和下降偏移电压为9mV，远低于传统TL。该TL设计相比传统TL，平均能耗在SS角降低1.5%，FF角降低2.3%。与非绝热CMOS电容神经元（CCN）相比，所提出的ACN在突触能耗方面实现了超过90%的节省（超过12倍改进），并通过蒙特卡洛仿真证实了最坏情况下的能耗节省。电源电压缩放也显示持续的能耗节省且不损失功能。

**Conclusion:** 绝热电容神经元（ACN）作为一种新型的人工神经元硬件实现，在能效、精度、鲁棒性和可扩展性方面表现出显著改进，特别是在突触能耗方面实现了超过90%的节省。

> **ai_Abstract:** 本文提出了一种名为绝热电容神经元（ACN）的新型人工神经元硬件实现，旨在显著提高能效、功能、精度、鲁棒性和可扩展性。该研究详细介绍了在0.18µm CMOS技术中实现的12位单神经元，并引入了一种优化的阈值逻辑（TL）设计，该设计在宽泛的温度和工艺条件下表现出低偏移和更低的能耗。仿真结果表明，ACN在突触能耗方面比传统非绝热CMOS电容神经元（CCN）节省了超过90%的能量，并通过蒙特卡洛仿真和电源电压缩放进一步验证了其节能优势和功能稳定性。

> **摘要翻译:** 本文介绍了一种新型、高能效的绝热电容神经元（ACN）硬件实现，作为人工神经元（AN）的一种形式，与现有工作相比，其功能、精度、鲁棒性和可扩展性均有所提高。本文描述了在0.18µm CMOS技术中实现一个12位单神经元，支持正负权重。本文还提出了一种用于二元AN激活函数的新型阈值逻辑（TL）设计，该设计在三个工艺角和-55°C至125°C的五个温度下产生低对称偏移。版图后仿真结果表明，与传统TL相比，其最大上升和下降偏移电压为9mV，而传统TL在不同温度和工艺下分别有27mV和5mV的上升和下降偏移电压。此外，与传统TL设计相比，所提出的TL设计在SS角平均能耗降低1.5%，在FF角降低2.3%。与非绝热CMOS电容神经元（CCN）基准相比，在500kHz至100MHz的频率范围内，所提出的ACN的总突触能耗节省超过90%（超过12倍的改进）。包含工艺变异和失配的1000次蒙特卡洛仿真证实，在突触能耗分布中，与CCN相比，最坏情况下的能耗节省超过90%。最后，电源电压缩放的影响表明，除了所有输入为零的情况外，能耗节省持续超过90%，且不损失功能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [276] [Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection](https://arxiv.org/abs/2507.00832)
> *基于解剖学的自动化后处理减少了深度学习颅内动脉瘤检测的假阳性并提高了可解释性*

*Jisoo Kim, Chu-Hsuan Lin, Alberto Ceballos-Arroyo, Ping Liu, Huaizu Jiang, Shrikanth Yadav, Qi Wan, Lei Qin, Geoffrey S Young* | **Category: eess.IV, cs.AI, cs.CV**

**Keywords:** 颅内动脉瘤检测, 深度学习, 假阳性减少, 解剖学后处理, CTA

**Comment:** 

> **TL;DR:** 本研究开发了一种基于解剖学的自动化后处理方法，显著降低了深度学习模型检测颅内动脉瘤的假阳性率，同时不影响真阳性，从而提高了模型的性能和临床可接受性。

**AI_Comments:** 该论文的创新点在于引入了一种自动化、基于解剖学知识的后处理方法来解决深度学习模型在医学图像诊断中常见的假阳性问题。通过利用解剖学分割掩膜来过滤DL模型的输出，有效地降低了假阳性率，这对于提高模型的临床实用性和可信度至关重要。这种“领域知情”的启发式学习方法为DL在医疗领域的应用提供了有价值的思路，尤其是在需要高精度和低误报率的诊断场景中。其局限性可能在于对高质量解剖学分割掩膜的依赖性，以及该方法是否能推广到其他器官或疾病的检测中。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在CTA上检测颅内动脉瘤时，尽管模型架构和策略（如检测阈值调整）有所改进，但高假阳性率仍然是其临床转化的障碍。本研究旨在通过采用一种自动化、基于解剖学、启发式学习混合的动脉-静脉分割后处理方法来进一步减少假阳性。

**Method:** 研究训练了两个深度学习模型：CPM-Net和一种可变形3D卷积神经网络-Transformer混合模型（3D-CNN-TR），使用了1,186个开源CTA（1,373个标注动脉瘤）进行训练，并用143个私有CTA（218个标注动脉瘤）进行评估。研究应用脑、动脉、静脉和海绵窦分割掩膜来移除与以下情况重叠的DL输出中可能的假阳性：(1) 脑掩膜；(2) 静脉掩膜；(3) 静脉多于动脉掩膜；(4) 脑加静脉掩膜；(5) 脑加静脉多于动脉掩膜。

**Result:** CPM-Net产生了139个真阳性（TP）、79个假阴性（FN）和126个假阳性（FP）。3D-CNN-TR产生了179个TP、39个FN和182个FP。假阳性常见于颅外（CPM-Net 27.3%；3D-CNN-TR 42.3%）、静脉（CPM-Net 56.3%；3D-CNN-TR 29.1%）、动脉（CPM-Net 11.9%；3D-CNN-TR 53.3%）和非血管（CPM-Net 25.4%；3D-CNN-TR 9.3%）结构。方法5表现最佳，使CPM-Net的FP减少了70.6%（89/126），3D-CNN-TR的FP减少了51.6%（94/182），且未减少TP，将CPM-NET的FP/病例率从0.88降至0.26，将3D-CNN-TR的FP/病例率从1.27降至0.62。

**Conclusion:** 基于解剖学、可解释的后处理可以提高基于深度学习的动脉瘤检测模型性能。更广泛地说，自动化、领域知情、混合启发式学习处理有望提高动脉瘤检测模型的性能和临床接受度。

> **ai_Abstract:** 本研究提出了一种基于解剖学的自动化后处理方法，旨在减少深度学习模型在CTA上检测颅内动脉瘤时的高假阳性率。通过将脑、动脉、静脉等分割掩膜应用于DL模型的输出，并测试了五种不同的掩膜组合，结果显示，最佳方法（脑加静脉多于动脉掩膜）能够显著减少CPM-Net和3D-CNN-TR模型的假阳性数量，分别降低70.6%和51.6%，同时不影响真阳性数量。这表明该后处理方法能有效提高DL模型在动脉瘤检测中的性能和临床可解释性。

> **摘要翻译:** 引言：深度学习（DL）模型有助于在CTA上检测颅内动脉瘤，但尽管模型架构和策略（如检测阈值调整）有所改进，高假阳性（FP）率仍然是其临床转化的障碍。我们采用了一种自动化、基于解剖学、启发式学习混合的动脉-静脉分割后处理方法来进一步减少假阳性。
方法：两个DL模型，CPM-Net和一种可变形3D卷积神经网络-Transformer混合模型（3D-CNN-TR），使用1,186个开源CTA（1,373个标注动脉瘤）进行训练，并用143个私有CTA（218个标注动脉瘤）进行评估。脑、动脉、静脉和海绵窦（CVS）分割掩膜被应用于移除DL输出中与以下情况重叠的可能假阳性：(1) 脑掩膜；(2) 静脉掩膜；(3) 静脉多于动脉掩膜；(4) 脑加静脉掩膜；(5) 脑加静脉多于动脉掩膜。
结果：CPM-Net产生了139个真阳性（TP）；79个假阴性（FN）；126个假阳性（FP）。3D-CNN-TR产生了179个TP；39个FN；182个FP。假阳性常见于颅外（CPM-Net 27.3%；3D-CNN-TR 42.3%）、静脉（CPM-Net 56.3%；3D-CNN-TR 29.1%）、动脉（CPM-Net 11.9%；3D-CNN-TR 53.3%）和非血管（CPM-Net 25.4%；3D-CNN-TR 9.3%）结构。方法5表现最佳，使CPM-Net的FP减少了70.6%（89/126），3D-CNN-TR的FP减少了51.6%（94/182），且未减少TP，将CPM-NET的FP/病例率从0.88降至0.26，将3D-CNN-TR的FP/病例率从1.27降至0.62。
结论：基于解剖学、可解释的后处理可以提高基于深度学习的动脉瘤检测模型性能。更广泛地说，自动化、领域知情、混合启发式学习处理有望提高动脉瘤检测模型的性能和临床接受度。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [286] [Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection](https://arxiv.org/abs/2507.00903)
> *深度学习在T1和T2心脏MRI图分割中的应用，用于自动化疾病检测*

*Andreea Bianca Popescu, Andreas Seitz, Heiko Mahrholdt, Jens Wetzl, Athira Jacob, Lucian Mihai Itu, Constantin Suciu, Teodora Chitiboi* | **Category: eess.IV, cs.AI, cs.CV**

**Keywords:** 深度学习, 心脏MRI, 图像分割, 疾病检测, 机器学习

**Comment:** This work has been submitted for consideration at European Radiology
  (Springer). Upon acceptance, this preprint will be updated with the journal
  reference

> **TL;DR:** 本研究评估了深度学习在T1和T2心脏MRI图分割中的准确性，并结合机器学习和多特征，提高了心脏疾病的自动化检测能力。

**AI_Comments:** 本研究的创新点在于结合深度学习进行精确的T1/T2心脏MRI图分割，并进一步利用多统计特征和机器学习来提高疾病检测的准确性。其重要性体现在解决了手动分割的观察者间变异性问题，并为心脏疾病的自动化、定量诊断提供了更可靠的方法。

<details>
  <summary>Details</summary>

**Motivation:** 参数化组织映射在定量心脏组织表征方面受到手动描绘时观察者间变异性的限制。传统的依赖平均弛豫值和单一阈值的方法可能过度简化心肌复杂性。

**Method:** 手动分割T1和T2图，评估观察者间变异性。训练深度学习模型分割左心室血池和心肌。计算心肌像素的平均值、下四分位数、中位数和上四分位数作为特征。使用截断法或机器学习进行分类。通过DICE、平均绝对百分比误差、Bland-Altman图、ROC分析、Pearson相关、F1分数、精确度、召回率和Wilcoxon检验评估性能。

**Result:** 分割模型实现了85.4%的DICE系数，超过了观察者间一致性。将随机森林应用于所有特征后，F1分数提高到92.7% (p < 0.001)。

**Conclusion:** 深度学习有助于T1/T2图的分割。结合多特征与机器学习可以改善疾病检测。

> **ai_Abstract:** 本研究旨在解决手动心脏MRI图分割中观察者间变异性高的问题，并改进疾病检测。研究团队利用深度学习模型对T1和T2心脏MRI图进行心肌和血池分割，其DICE系数达到85.4%，优于人工分割的观察者间一致性。此外，通过整合平均值、四分位数等多种统计特征，并结合机器学习（如随机森林）进行分类，显著提升了疾病检测的F1分数至92.7%。研究表明，深度学习能有效实现图像分割，而多特征结合机器学习则能显著提升心脏疾病的自动化检测能力。

> **摘要翻译:** **目的** 参数化组织映射能够实现定量心脏组织表征，但受限于手动描绘时的观察者间变异性。依赖平均弛豫值和单一阈值的传统方法可能过度简化心肌复杂性。本研究评估了深度学习(DL)能否达到与观察者间变异性相当的分割精度，探讨了除平均T1/T2值之外的统计特征的效用，并评估了结合多种特征的机器学习(ML)是否能增强疾病检测。
**材料与方法** 手动分割T1和T2图。测试子集由两名观察者独立标注，并评估了观察者间变异性。训练了一个DL模型来分割左心室血池和心肌。计算心肌像素的平均值(A)、下四分位数(LQ)、中位数(M)和上四分位数(UQ)，并通过应用阈值或ML进行分类。Dice相似系数(DICE)和平均绝对百分比误差评估分割性能。Bland-Altman图评估了用户间和模型-观察者间的一致性。受试者工作特征(ROC)分析确定了最佳阈值。Pearson相关性比较了模型和手动分割的特征。F1分数、精确度和召回率评估了分类性能。Wilcoxon检验评估了分类方法之间的差异，p < 0.05被认为是统计学显著的。
**结果** 144名受试者被分为训练(100)、验证(15)和评估(29)子集。分割模型实现了85.4%的DICE，超过了观察者间一致性。将随机森林应用于所有特征后，F1分数提高到92.7% (p < 0.001)。
**结论** 深度学习有助于T1/T2图的分割。结合多特征与机器学习可以改善疾病检测。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [294] [DMCIE: Diffusion Model with Concatenation of Inputs and Errors to Improve the Accuracy of the Segmentation of Brain Tumors in MRI Images](https://arxiv.org/abs/2507.00983)
> *DMCIE：一种结合输入和误差的扩散模型，用于提高MRI图像中脑肿瘤分割的准确性*

*Sara Yavari, Rahul Nitin Pandya, Jacob Furst* | **Category: eess.IV, cs.CV**

**Keywords:** 脑肿瘤分割, 扩散模型, MRI, 误差引导, DMCIE

**Comment:** 

> **TL;DR:** DMCIE提出了一种基于扩散模型的脑肿瘤分割新方法，通过将初始分割的误差图与原始MRI图像拼接，引导扩散模型，有效提高了分割精度，并在BraTS2020数据集上优于现有SOTA方法。

**AI_Comments:** DMCIE的创新点在于其独特的误差引导机制，通过将误差图与原始输入拼接来指导扩散模型，从而能够更精准地关注并修正初始分割中的错误区域，这是一种新颖且有效的校正分割策略。其重要性在于提升了脑肿瘤分割的精度，对临床诊断和治疗规划具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** MRI扫描中脑肿瘤的精确分割对于可靠的临床诊断和有效的治疗计划至关重要。

**Method:** 本文提出DMCIE（Diffusion Model with Concatenation of Inputs and Errors），这是一种用于多模态MRI扫描中精确脑肿瘤分割的新框架。该方法首先使用3D U-Net生成初始分割掩膜，然后通过识别预测与真实值之间的差异生成误差图。将误差图与原始MRI图像拼接后，用于引导扩散模型。DMCIE利用多模态MRI输入（T1、T1ce、T2、FLAIR），通过关注错误分类区域并由原始输入引导，有效提升了分割精度。

**Result:** 在BraTS2020数据集上进行评估，DMCIE优于几种最先进的基于扩散的分割方法，实现了93.46的Dice分数和5.94毫米的HD95。

**Conclusion:** 这些结果突出表明，误差引导的扩散模型在生成精确可靠的脑肿瘤分割方面是有效的。

> **ai_Abstract:** DMCIE是一种新颖的基于扩散模型的脑肿瘤分割框架，旨在提高MRI图像的分割精度。该方法首先利用3D U-Net生成初步分割结果，并从中提取误差图。随后，将该误差图与原始多模态MRI图像（T1、T1ce、T2、FLAIR）进行拼接，共同作为输入引导扩散模型，使其能够专注于纠正误分类区域。在BraTS2020数据集上的实验证明，DMCIE在Dice分数和HD95指标上均优于现有先进的扩散模型，验证了误差引导扩散在实现精确脑肿瘤分割中的有效性。

> **摘要翻译:** MRI扫描中脑肿瘤的精确分割对于可靠的临床诊断和有效的治疗计划至关重要。最近，扩散模型在图像生成和分割任务中表现出卓越的有效性。本文介绍了一种基于扩散模型的校正分割新方法。我们提出了DMCIE（Diffusion Model with Concatenation of Inputs and Errors），一个用于多模态MRI扫描中精确脑肿瘤分割的新框架。我们采用3D U-Net生成初始分割掩膜，然后通过识别预测与真实值之间的差异生成误差图。误差图与原始MRI图像拼接后，用于引导扩散模型。DMCIE利用多模态MRI输入（T1、T1ce、T2、FLAIR），通过关注错误分类区域并由原始输入引导，有效提升了分割精度。在BraTS2020数据集上进行评估，DMCIE优于几种最先进的基于扩散的分割方法，实现了93.46的Dice分数和5.94毫米的HD95。这些结果突出表明，误差引导的扩散模型在生成精确可靠的脑肿瘤分割方面是有效的。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [302] [Advancing Lung Disease Diagnosis in 3D CT Scans](https://arxiv.org/abs/2507.00993)
> *推进3D CT扫描中的肺部疾病诊断*

*Qingqiu Li, Runtian Yuan, Junlin Hou, Jilan Xu, Yuejie Zhang, Rui Feng, Hao Chen* | **Category: eess.IV, cs.CV**

**Keywords:** 肺部疾病诊断, 3D CT扫描, ResNeSt50, 类别不平衡, 宏F1分数

**Comment:** 

> **TL;DR:** 该论文提出了一种简单有效的模型，用于在3D胸部CT扫描中更准确地诊断肺部疾病，通过去除非肺区域、使用ResNeSt50特征提取器和加权交叉熵损失，在肺部疾病诊断挑战赛中取得了0.80的Macro F1分数。

**AI_Comments:** 该论文提出了一种实用且性能良好的肺部疾病诊断模型。其创新点在于结合了3D CT扫描的区域关注预处理、强大的ResNeSt50特征提取器以及针对类别不平衡的加权损失函数。模型的性能指标（0.80 Macro F1 Score）表明其在实际应用中具有潜力，尤其是在处理罕见疾病类别方面。其“直接而有效”的设计理念值得肯定。

<details>
  <summary>Details</summary>

**Motivation:** 为了在胸部CT扫描中实现更准确的肺部疾病诊断。

**Method:** 首先，分析3D CT扫描的特性并移除非肺区域，以帮助模型关注病变相关区域并降低计算成本。其次，采用ResNeSt50作为强大的特征提取器。最后，使用加权交叉熵损失来缓解类别不平衡问题，特别是针对代表性不足的鳞状细胞癌类别。

**Result:** 该模型在Fair Disease Diagnosis Challenge的验证集上取得了0.80的Macro F1分数。

**Conclusion:** 该模型在区分不同肺部疾病方面表现出强大的性能。

> **ai_Abstract:** 本研究提出了一种用于3D CT扫描中肺部疾病诊断的有效模型。该模型通过预处理去除CT图像中的非肺区域以提高效率和焦点，并利用ResNeSt50作为强大的特征提取器。为解决类别不平衡问题，特别是针对罕见病症，采用了加权交叉熵损失。该方法在Fair Disease Diagnosis Challenge的验证集上取得了0.80的Macro F1分数，证明了其在区分各类肺部疾病方面的卓越性能。

> **摘要翻译:** 为了在胸部CT扫描中实现更准确的肺部疾病诊断，我们提出了一种直接而有效的模型。首先，我们分析了3D CT扫描的特性并移除了非肺区域，这有助于模型关注病变相关区域并降低计算成本。我们采用ResNeSt50作为强大的特征提取器，并使用加权交叉熵损失来缓解类别不平衡问题，特别是针对代表性不足的鳞状细胞癌类别。我们的模型在Fair Disease Diagnosis Challenge的验证集上取得了0.80的Macro F1分数，这表明其在区分不同肺部疾病方面具有强大的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [61] [Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?](https://arxiv.org/abs/2507.00155)
> *音乐源分离模型能保留双耳音频中的空间信息吗？*

*Richa Namballa, Agnieszka Roginska, Magdalena Fuentes* | **Category: eess.AS, cs.SD, eess.SP**

**Keywords:** 音乐源分离, 双耳音频, 空间信息, 沉浸式音频, 头部相关传输函数

**Comment:** 6 pages + references, 4 figures, 2 tables, 26th International Society
  for Music Information Retrieval (ISMIR) Conference

> **TL;DR:** 现有的立体声音乐源分离模型在处理双耳音频时无法有效保留空间信息，且降级程度取决于模型架构和目标乐器。

**AI_Comments:** 这项研究填补了音乐信息检索领域在双耳音频处理方面的一个空白，特别是在音乐源分离背景下。其创新之处在于构建了新的双耳数据集，并采用信号处理和耳间线索指标来量化空间信息保留情况。研究结果对于开发未来适用于沉浸式音频应用的音乐源分离模型具有重要指导意义，强调了现有模型在空间信息处理上的局限性，并为未来的研究方向提供了明确的指引。

<details>
  <summary>Details</summary>

**Motivation:** 双耳音频在音乐信息检索领域尚未得到充分探索，但随着虚拟和增强现实体验的日益普及以及在无障碍应用方面的潜力，研究现有音乐源分离模型在双耳音频上的表现以及它们保留空间信息的有效性变得至关重要。

**Method:** 研究评估了多种流行的音乐源分离模型在标准立体声和新型双耳数据集上保留空间信息的能力。双耳数据通过使用MUSDB18-HQ的音轨和开源的头部相关传输函数，随机定位乐器源于水平面合成。然后，使用信号处理和基于耳间线索的指标评估分离音轨的空间质量。

**Result:** 结果显示，立体声音乐源分离模型未能保留对于维持双耳音频沉浸式质量至关重要的空间信息，并且降级程度取决于模型架构以及目标乐器。

**Conclusion:** 现有的立体声音乐源分离模型无法有效保留双耳音频中的空间信息，这表明需要在音乐源分离和沉浸式音频的交叉领域进行未来的研究以解决这一问题。

> **ai_Abstract:** 本研究探讨了现有音乐源分离（MSS）模型在双耳音频中保留空间信息的能力。鉴于虚拟现实和增强现实的兴起以及无障碍应用的需求，研究人员评估了流行的MSS模型在标准立体声和合成双耳数据集上的表现。结果表明，当前的立体声MSS模型无法有效保留双耳音频的沉浸式空间信息，且性能下降与模型架构和目标乐器有关。这凸显了未来在MSS与沉浸式音频交叉领域进行研究的重要性。

> **摘要翻译:** 双耳音频在音乐信息检索社区中仍未得到充分探索。受虚拟和增强现实体验日益普及以及无障碍应用潜在前景的推动，我们研究了现有音乐源分离（MSS）模型在双耳音频上的表现。尽管这些模型处理双通道输入，但它们保留空间信息的有效性尚不清楚。在这项工作中，我们评估了几种流行的MSS模型在标准立体声和新型双耳数据集上如何保留空间信息。我们的双耳数据是利用MUSDB18-HQ的音轨和开源头部相关传输函数，通过沿水平面随机定位乐器源来合成的。然后，我们使用信号处理和基于耳间线索的指标评估分离音轨的空间质量。我们的结果表明，立体声MSS模型未能保留对于维持双耳音频沉浸式质量至关重要的空间信息，并且降级程度取决于模型架构以及目标乐器。最后，我们强调了MSS和沉浸式音频交叉领域未来工作的宝贵机会。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [81] [Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis](https://arxiv.org/abs/2507.00227)
> *语音合成中韵律建模随机方法研究*

*Paul Mayer, Florian Lux, Alejandro Pérez-González-de-Martos, Angelina Elizarova, Lindsey Vanderlyn, Dirk Väth, Ngoc Thang Vu* | **Category: eess.AS, cs.AI**

**Keywords:** 随机方法, 韵律建模, 语音合成, Normalizing Flows, 可控性

**Comment:** Accepted at Interspeech 2025

> **TL;DR:** 本文研究了 Normalizing Flows、Conditional Flow Matching 和 Rectified Flows 等随机方法在语音合成韵律建模中的有效性，并发现它们能生成与人类语音媲美的自然韵律，且提供额外的可控性。

**AI_Comments:** 这项研究的创新之处在于将多种随机方法应用于语音合成中的韵律建模，并证明了它们在生成自然、富有表现力的韵律方面的优越性。其重要性在于提升了文本到语音合成的自然度和可控性，尤其是在处理韵律变异性方面。通过允许调整采样温度，也为未来的应用提供了新的控制维度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成方法近年来发展迅速，但在文本到语音合成中生成富有表现力的韵律仍然是一项具有挑战性的任务，特别是对于通过音高、能量和持续时间等参数显式建模韵律的系统，这通常是为了可解释性和可控性。

**Method:** 本文研究了 Normalizing Flows、Conditional Flow Matching 和 Rectified Flows 等随机方法，并将其与传统的确定性基线以及真实人类发音进行比较。

**Result:** 广泛的主观和客观评估表明，随机方法通过捕捉人类语音固有的可变性，生成了与人类说话者相媲美的自然韵律。

**Conclusion:** 随机方法在语音合成的韵律建模中表现出色，能生成与人类语音媲美的自然韵律，并通过调整采样温度提供额外的可控性。

> **ai_Abstract:** 本研究探讨了在文本到语音合成中，随机方法（如 Normalizing Flows、Conditional Flow Matching 和 Rectified Flows）在生成富有表现力韵律方面的有效性。通过与确定性基线和人类语音的比较，评估结果表明这些随机方法能生成与人类发音同样自然的韵律，并能捕捉语音的内在变异性，同时通过调整采样温度提供了额外的可控性。

> **摘要翻译:** 尽管生成方法近年来发展迅速，但在文本到语音合成中生成富有表现力的韵律仍然是一项具有挑战性的任务。对于通过音高、能量和持续时间等参数显式建模韵律的系统尤其如此，这通常是为了可解释性和可控性。在这项工作中，我们研究了随机方法在完成这项任务时的有效性，包括 Normalizing Flows、Conditional Flow Matching 和 Rectified Flows。我们将这些方法与传统的确定性基线以及真实人类发音进行了比较。我们广泛的主观和客观评估表明，随机方法通过捕捉人类语音固有的可变性，生成了与人类说话者相媲美的自然韵律。此外，它们通过允许调整采样温度，提供了额外的可控性选项。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [102] [Collecting, Curating, and Annotating Good Quality Speech deepfake dataset for Famous Figures: Process and Challenges](https://arxiv.org/abs/2507.00324)
> *为知名人物收集、整理和标注高质量语音深度伪造数据集：过程与挑战*

*Hashim Ali, Surya Subramani, Raksha Varahamurthy, Nithin Adupa, Lekha Bollinani, Hafiz Malik* | **Category: eess.AS**

**Keywords:** 语音深度伪造, 数据集, 语音合成, 公众人物, 语音真实性

**Comment:** 

> **TL;DR:** 本文提出了一种收集、整理和生成名人高质量语音深度伪造数据集的系统方法，并分析了挑战，最终构建了一个高质量数据集，具有高自然度分数和高人类误判率。

**AI_Comments:** 本文的创新之处在于提出了一套系统化的名人高质量语音深度伪造数据集的构建流程，包括自动化收集和基于转录的分割技术，这对于研究语音深度伪造检测和防御具有重要意义。数据集的高自然度和高人类误判率也凸显了当前语音深度伪造技术的威胁性。

<details>
  <summary>Details</summary>

**Motivation:** 语音合成的最新进展在维护语音真实性方面带来了前所未有的挑战，特别是对于经常成为模仿攻击目标的公众人物。

**Method:** 本文提出了一种全面的方法，用于收集、整理和生成政治人物的合成语音数据。该方法包含一个自动化管道，用于收集高质量的真实语音样本，并采用基于转录的分割技术来显著提高合成语音质量。研究人员还实验了从单说话人到零样本合成的各种合成方法。

**Result:** 最终的数据集包含来自十位公众人物的真实和合成语音样本，展示了卓越的质量，NISQA-TTS 自然度得分为 3.69，最高人类误判率为 61.9%。

**Conclusion:** 本文成功构建了一个高质量的名人语音深度伪造数据集，并详细阐述了其收集、处理和生成过程中的方法与挑战，证明了所生成合成语音的高真实度和误导性。

> **ai_Abstract:** 本文提出了一种针对知名人物高质量语音深度伪造数据集的收集、整理和标注方法，旨在应对语音合成带来的语音真实性挑战。研究开发了一个自动化管道，结合基于转录的分割技术，以提高合成语音质量。通过实验多种合成方法，最终构建了一个包含十位公众人物语音样本的数据集，其合成语音在自然度（NISQA-TTS 3.69）和人类误判率（61.9%）方面表现出色，证明了其高质量和潜在的欺骗性。

> **摘要翻译:** 语音合成的最新进展在维护语音真实性方面带来了前所未有的挑战，特别是对于经常成为模仿攻击目标的公众人物。本文提出了一种收集、整理和生成政治人物合成语音数据的综合方法，并详细分析了遇到的挑战。我们介绍了一种系统方法，该方法包含一个自动化管道，用于收集高质量的真实语音样本，其特点是基于转录的分割，显著提高了合成语音质量。我们尝试了各种合成方法；从单说话人到零样本合成，并记录了我们方法的演变过程。最终的数据集包含来自十位公众人物的真实和合成语音样本，展示了卓越的质量，NISQA-TTS 自然度得分为 3.69，最高人类误判率为 61.9%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [126] [Mitigating Language Mismatch in SSL-Based Speaker Anonymization](https://arxiv.org/abs/2507.00458)
> *缓解基于SSL的说话人匿名化中的语言不匹配问题*

*Zhe Zhang, Wen-Chin Huang, Xin Wang, Xiaoxiao Miao, Junichi Yamagishi* | **Category: eess.AS, cs.SD**

**Keywords:** 说话人匿名化, SSL, 语言不匹配, 多语言, 微调

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 本文研究并解决了基于SSL的说话人匿名化系统在非英语语言（如日语和普通话）中存在的语言不匹配问题，通过目标语言微调和多语言SSL模型，显著提高了系统在多语言环境下的实用性和性能。

**AI_Comments:** 本文创新性地探讨了说话人匿名化系统在多语言环境下的性能瓶颈，并提出了通过语言适应性和多语言预训练SSL模型来解决语言不匹配的有效策略。其重要性在于为构建更通用、更鲁棒的跨语言说话人匿名化系统提供了实践指导和理论支持，对于语音隐私保护技术在非英语语种的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数说话人匿名化系统（SASs）仅使用英语进行开发和评估，导致在其他语言（如日语和普通话）中的实用性下降。本文旨在调查并解决SASs中的语言不匹配问题。

**Method:** 首先，使用日语语音对基于自监督学习（SSL）的内容编码器进行微调，以验证有效的语言适应性。其次，提出使用日语语音微调多语言SSL模型，并在日语和普通话中评估说话人匿名化系统。

**Result:** 下游实验表明，使用目标语言微调仅限英语的SSL模型可以增强语音清晰度，同时保持隐私。此外，多语言SSL进一步扩展了SASs在不同语言间的实用性。

**Conclusion:** 研究结果强调了语言适应性和SSL多语言预训练对于实现鲁棒多语言说话人匿名化的重要性。

> **ai_Abstract:** 本文针对说话人匿名化系统（SASs）在非英语语言中存在的语言不匹配问题进行了深入研究。研究发现，现有SASs主要基于英语开发，导致在日语和普通话等语言中性能不佳。为解决此问题，作者提出并验证了两种方法：一是使用目标语言（日语）对基于SSL的内容编码器进行微调；二是使用日语微调多语言SSL模型，并在日语和普通话中进行评估。实验结果表明，对仅限英语的SSL模型进行目标语言微调能提高可懂度并维持隐私，而多语言SSL则能进一步提升SASs的跨语言实用性。这些发现强调了语言适应性和多语言预训练对构建鲁棒多语言说话人匿名化系统的重要性。

> **摘要翻译:** 说话人匿名化旨在保护说话人身份，同时保留内容信息和语音可懂度。然而，大多数说话人匿名化系统（SASs）仅使用英语进行开发和评估，导致在其他语言中的实用性下降。本文研究了日语和普通话语音中SASs的语言不匹配问题。首先，我们使用日语语音对基于自监督学习（SSL）的内容编码器进行微调，以验证有效的语言适应性。然后，我们提出使用日语语音微调多语言SSL模型，并在日语和普通话中评估SAS。下游实验表明，使用目标语言微调仅限英语的SSL模型可以增强可懂度，同时保持隐私，并且多语言SSL进一步扩展了SASs在不同语言间的实用性。这些发现强调了语言适应性和SSL多语言预训练对于实现鲁棒多语言说话人匿名化的重要性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [147] [LearnAFE: Circuit-Algorithm Co-design Framework for Learnable Audio Analog Front-End](https://arxiv.org/abs/2507.00755)
> *LearnAFE：可学习音频模拟前端的电路-算法协同设计框架*

*Jinhai Hu, Zhongyi Zhang, Cong Sheng Leow, Wang Ling Goh, Yuan Gao* | **Category: eess.AS, cs.AI, cs.SD**

**Keywords:** 电路-算法协同设计, 模拟前端, 音频分类, 联合优化, 带通滤波器

**Comment:** 11 pages, 15 figures, accepted for publication on IEEE Transactions
  on Circuits and Systems I: Regular Papers

> **TL;DR:** 本文提出了一个电路-算法协同设计框架LearnAFE，通过联合优化模拟前端（AFE）的传递函数和后端分类器，实现了音频信号分类系统级的最优性能，并在功耗和电容面积上优于传统方法。

**AI_Comments:** 本文的创新点在于提出了电路-算法协同设计框架，通过联合优化AFE和分类器，突破了传统分离设计的局限性，实现了系统级最优。这种方法在提高分类性能的同时，还能有效降低功耗和硬件面积，对于资源受限的嵌入式音频处理系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设计模拟前端（AFE）和后端分类器是常见的做法，但这种分离设计并非理想，无法达到系统级最优性能。

**Method:** 本文提出了一种电路-算法协同设计框架，通过联合优化后端分类器与AFE的传递函数，以实现系统级最优。具体而言，模拟带通滤波器（BPF）组的传递函数参数在分类器的信噪比（SNR）感知训练循环中进行调优，并使用协同设计损失函数LBPF，实现了滤波器组和分类器的协同优化。

**Result:** 在开源SKY130 130nm CMOS工艺中实现，优化后的设计在5 dB到20 dB的宽输入信号SNR范围内，针对10个关键词分类任务实现了90.5%-94.2%的准确率，且分类器参数仅为22k。与传统方法相比，所提出的音频AFE在功耗和电容面积上分别降低了8.7%和12.9%。

**Conclusion:** 本文提出的电路-算法协同设计框架通过联合优化AFE和分类器，显著提升了音频信号分类的系统性能，并在功耗和面积方面取得了优势。

> **ai_Abstract:** 本文提出了LearnAFE，一个用于音频信号分类中可学习模拟前端（AFE）的电路-算法协同设计框架。该框架通过联合优化AFE的传递函数和后端分类器，克服了传统分离设计的局限性，实现了系统级最优。具体方法包括在信噪比感知的训练循环中调优模拟带通滤波器组参数，并使用协同设计损失函数LBPF。实验结果表明，在SKY130 130nm CMOS工艺下，该设计在10个关键词分类任务上实现了90.5%-94.2%的准确率，并在功耗和电容面积上分别比传统方法减少了8.7%和12.9%。

> **摘要翻译:** 本文提出了一种用于可学习模拟前端（AFE）在音频信号分类中的电路-算法协同设计框架。如本文所示，分别设计AFE和后端分类器是常见但不理想的做法。相反，本文提出了一种对后端分类器与AFE的传递函数进行联合优化的方法，以实现系统级最优。更具体地说，模拟带通滤波器（BPF）组的传递函数参数在分类器的信噪比（SNR）感知训练循环中进行调优。通过使用协同设计损失函数LBPF，这项工作展示了滤波器组和分类器的卓越优化。该优化设计在开源SKY130 130nm CMOS工艺中实现，在5 dB至20 dB的宽输入信号SNR范围内，针对10个关键词分类任务实现了90.5%-94.2%的准确率，且分类器参数仅为22k。与传统方法相比，所提出的音频AFE在功耗和电容面积上分别降低了8.7%和12.9%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [168] [Improving Stereo 3D Sound Event Localization and Detection: Perceptual Features, Stereo-specific Data Augmentation, and Distance Normalization](https://arxiv.org/abs/2507.00874)
> *改进立体声3D声事件定位与检测：感知特征、立体声特有数据增强和距离归一化*

*Jun-Wei Yeow, Ee-Leng Tan, Santi Peksi, Woon-Seng Gan* | **Category: eess.AS**

**Keywords:** 立体声SELD, 感知特征, 数据增强, 距离归一化, DCASE挑战赛

**Comment:** Technical report for DCASE 2025 Challenge Task 3

> **TL;DR:** 该技术报告介绍了为DCASE 2025挑战赛任务3（立体声声事件定位与检测）提交的方案，通过引入感知特征、立体声特有数据增强和距离归一化来提高性能，并在STARSS23数据集上取得了显著提升。

**AI_Comments:** 该论文提出了一套全面的方法来提升立体声SELD性能，其创新性体现在结合了感知特征、针对立体声特性定制的数据增强（包括首次将FilterAugment应用于SELD）以及距离归一化。这些策略的结合为解决立体声SELD的复杂性提供了有效途径，并在DCASE挑战赛中展现了实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为DCASE 2025挑战赛的任务3（常规视频内容中的立体声声事件定位与检测，SELD）提供解决方案，并针对纯音频任务提出改进SELD性能的方法。

**Method:** 本研究提出了多项关键贡献：1. 设计了感知驱动的输入特征，以改善事件检测、声源定位和距离估计。2. 针对立体声音频的复杂性，调整了数据增强策略，包括通道交换和时频掩蔽，并引入了FilterAugment技术。3. 在训练期间应用了距离归一化方法，以稳定回归目标。

**Result:** 在立体声STARSS23数据集上的实验表明，所提出的方法在所有SELD指标上都取得了持续的性能提升。

**Conclusion:** 通过结合感知特征、立体声特有数据增强和距离归一化方法，可以显著提高立体声声事件定位与检测的性能。

> **ai_Abstract:** 本技术报告详细阐述了为DCASE 2025挑战赛任务3（立体声声事件定位与检测，SELD）提交的方案。该方案主要贡献包括：设计了感知驱动的输入特征以提升检测、定位和距离估计；针对立体声特性调整了数据增强策略，如通道交换、时频掩蔽和引入FilterAugment；以及在训练中应用距离归一化以稳定目标。实验结果显示，这些方法在STARSS23数据集上显著提升了SELD的各项性能指标。

> **摘要翻译:** 本技术报告介绍了我们对DCASE 2025挑战赛任务3：常规视频内容中的立体声声事件定位与检测（SELD）的提交方案。本报告针对纯音频任务，并介绍了多项关键贡献。首先，我们设计了感知驱动的输入特征，以改善事件检测、声源定位和距离估计。其次，我们专门针对立体声音频的复杂性调整了增强策略，包括通道交换和时频掩蔽。我们还纳入了最近提出的FilterAugment技术，该技术尚未在SELD工作中进行探索。最后，我们在训练期间应用了距离归一化方法，以稳定回归目标。在立体声STARSS23数据集上的实验表明，在所有SELD指标上都取得了持续的性能提升。复制我们工作的代码可在以下仓库中找到：https://github.com/itsjunwei/NTU_SNTL_Task3

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [238] [Musical Source Separation of Brazilian Percussion](https://arxiv.org/abs/2503.04995)
> *巴西打击乐器的音乐源分离*

*Richa Namballa, Giovana Morais, Magdalena Fuentes* | **Category: eess.AS, cs.SD, eess.SP**

**Keywords:** 音乐源分离, 巴西打击乐器, 苏尔多鼓, U-Net, 非西方音乐

**Comment:** 2 pages + references, 1 figure, 1 table, Extended Abstracts for the
  Late-Breaking Demo Session of the 25th International Society for Music
  Information Retrieval Conference

> **TL;DR:** 该演示展示了如何使用有限的巴西桑巴打击乐器数据集和U-Net模型，有效地从混合音乐中分离出苏尔多鼓，表明音乐源分离系统在数据量有限的情况下也能应用于非西方音乐。

**AI_Comments:** 该论文的创新之处在于将音乐源分离技术应用于非西方乐器，特别是巴西打击乐器，这拓展了该领域的应用范围。其重要性在于证明了即使在数据有限的情况下，通过利用乐器本身的特性，也能实现有效的源分离，这为未来处理数据稀缺的文化遗产音乐提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 西方音乐的音乐源分离（MSS）取得了重大突破，但由于数据缺乏，非西方乐器的研究仍然有限。

**Method:** 利用现有的巴西桑巴打击乐器数据集创建人工混合物，并使用U-Net模型进行训练，以分离苏尔多鼓。

**Result:** 尽管训练数据有限，但该模型能够有效分离苏尔多鼓，这得益于该鼓的重复模式和特有的低音音色。

**Conclusion:** 这些结果表明，音乐源分离系统可以在无需收集大量数据的情况下，成功应用于更具文化包容性的场景。

> **ai_Abstract:** 本演示旨在解决非西方音乐源分离领域数据稀缺的问题。研究人员利用现有巴西桑巴打击乐器数据集生成人工混合物，并训练U-Net模型以分离其中的苏尔多鼓。尽管训练数据有限，但模型仍能有效分离出苏尔多鼓，这归因于该乐器独特的重复模式和低音音色。该研究表明，音乐源分离系统无需大量数据也能成功应用于更多元文化的场景。

> **摘要翻译:** 音乐源分离（MSS）最近在西方音乐背景下实现了乐器从混合物中分离的重大突破，但由于数据缺乏，对非西方乐器的研究仍然有限。在此演示中，我们使用现有的巴西桑巴打击乐器数据集创建人工混合物，用于训练U-Net模型以分离苏尔多鼓，这是一种桑巴舞中的传统乐器。尽管训练数据有限，但考虑到该鼓的重复模式及其特有的低音音色，该模型仍能有效分离苏尔多鼓。这些结果表明，音乐源分离系统可以在无需收集大量数据的情况下，成功应用于更具文化包容性的场景。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [82] [Table Understanding and (Multimodal) LLMs: A Cross-Domain Case Study on Scientific vs. Non-Scientific Data](https://arxiv.org/abs/2507.00152)
> *表格理解与（多模态）LLM：科学与非科学数据跨领域案例研究*

*Ekaterina Borisova, Fabio Barth, Nils Feldhus, Raia Abu Ahmad, Malte Ostendorff, Pedro Ortiz Suarez, Georg Rehm, Sebastian Möller* | **Category: cs.CL**

**Keywords:** 表格理解, 大型语言模型, 多模态LLM, 科学数据, TableEval

**Comment:** TRL@ACL 2025, camera-ready version

> **TL;DR:** 本文探讨了文本和多模态大型语言模型（LLM）在表格理解任务中的有效性，通过跨领域和跨模态评估，发现LLM在处理科学表格时面临挑战，但在不同表格模态中保持鲁棒性。

**AI_Comments:** 本文通过引入TableEval基准和进行跨领域、跨模态评估，对LLM在表格理解方面的能力进行了深入探索，特别指出了LLM在处理科学表格时的局限性，这对于未来LLM在专业领域的应用具有重要指导意义。其创新之处在于构建了多模态、多格式的表格数据集，并进行了细致的鲁棒性和可解释性分析。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在下游任务中表现出色，但它们在处理表格数据方面的效率尚未得到充分探索。本文旨在探究LLMs在表格理解任务中的表现。

**Method:** 本文通过跨领域和跨模态评估，调查了文本和多模态LLMs在表格理解任务上的有效性。具体来说，研究比较了它们在科学与非科学背景表格上的性能，并检查了它们在图像和文本表示表格上的鲁棒性。此外，还进行了可解释性分析以衡量上下文使用和输入相关性。研究还引入了TableEval基准，包含来自学术出版物、维基百科和财务报告的3017个表格，每个表格提供五种不同格式：图像、字典、HTML、XML和LaTeX。

**Result:** 研究结果表明，虽然大型语言模型在不同表格模态中保持鲁棒性，但它们在处理科学表格时面临显著挑战。

**Conclusion:** 大型语言模型在表格理解方面，尤其是在处理科学数据时，仍有待改进，尽管它们在不同数据表示形式下表现出一致性。

> **ai_Abstract:** 本研究探讨了文本和多模态大型语言模型（LLM）在表格理解任务中的性能。通过对科学与非科学表格以及图像与文本格式表格的跨领域和跨模态评估，研究发现LLM在不同表格模态上表现出鲁棒性，但在处理科学表格时面临显著挑战。论文还引入了包含多格式表格的TableEval基准，并进行了可解释性分析。

> **摘要翻译:** 表格是研究、商业、医学和教育领域中表示结构化数据最广泛使用的工具之一。尽管大型语言模型（LLMs）在下游任务中表现出强大的性能，但它们在处理表格数据方面的效率仍未得到充分探索。在本文中，我们通过跨领域和跨模态评估，研究了基于文本和多模态LLMs在表格理解任务上的有效性。具体来说，我们比较了它们在科学与非科学背景表格上的性能，并检查了它们在以图像与文本形式表示的表格上的鲁棒性。此外，我们还进行了可解释性分析，以衡量上下文使用和输入相关性。我们还引入了TableEval基准，该基准包含来自学术出版物、维基百科和财务报告的3017个表格，其中每个表格都以五种不同格式提供：图像、字典、HTML、XML和LaTeX。我们的研究结果表明，虽然LLMs在不同表格模态中保持鲁棒性，但它们在处理科学表格时面临显著挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [103] [Prompting as Scientific Inquiry](https://arxiv.org/abs/2507.00163)
> *提示作为科学探究*

*Ari Holtzman, Chenhao Tan* | **Category: cs.CL**

**Keywords:** 提示, 大型语言模型, 行为科学, 科学探究, LLMs

**Comment:** 

> **TL;DR:** 本文主张将提示视为研究大型语言模型的行为科学，而非炼金术。

**AI_Comments:** 这篇论文通过重新定义和提升提示在大型语言模型研究中的地位，提供了一个重要的视角。它挑战了将提示视为非科学实践的普遍观念，并将其提升到行为科学的层面，这对于推动LLM研究方法的成熟和多样性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提示是研究和控制大型语言模型的主要且强大的方法，但它经常被贬低为炼金术而非科学，作者认为这是一种范畴错误。

**Method:** 作者提出将大型语言模型视为一种新的复杂且不透明的、经过训练而非编程的“有机体”，从而将提示重新定义为一种行为科学，通过其原生接口（语言）来探测模型。

**Result:** 本文没有具体实验结果，而是提出了一个概念性的观点：通过将大型语言模型视为一种“有机体”，提示被重新框架为一种行为科学，从而提升了其在理解大型语言模型中的科学地位。

**Conclusion:** 提示不仅不逊色于其他研究方法，反而是大型语言模型科学中的一个关键组成部分。

> **ai_Abstract:** 这篇论文认为，提示是研究和控制大型语言模型（LLMs）的核心且强大的方法，它解锁了LLMs的许多关键能力。尽管提示常被误解为“炼金术”而非科学，作者却主张，如果将LLMs视为复杂的、经训练的“有机体”，那么提示实际上是一种行为科学。与深入神经网络底层的机械可解释性不同，提示通过LLMs的自然语言接口进行探测。因此，论文强调提示并非次要，而是理解LLM科学不可或缺的一部分。

> **摘要翻译:** 提示是我们研究和控制大型语言模型的主要方法。它也是最强大的方法之一：几乎所有归因于大型语言模型的主要能力——少样本学习、思维链、宪法人工智能——都是通过提示首次解锁的。然而，提示很少被视为科学，并且经常被贬低为炼金术。我们认为这是一个范畴错误。如果我们把大型语言模型视为一种新型的复杂而不透明的、经过训练而非编程的“有机体”，那么提示就不是一种权宜之计：它就是行为科学。机械可解释性深入神经网络底层，而提示则通过其原生接口：语言来探测模型。我们认为提示并非低劣，而是大型语言模型科学中的一个关键组成部分。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [127] [LineRetriever: Planning-Aware Observation Reduction for Web Agents](https://arxiv.org/abs/2507.00210)
> *LineRetriever：规划感知型网页智能体观测减少方法*

*Imene Kerboua, Sahar Omidi Shayegan, Megh Thakkar, Xing Han Lù, Massimo Caccia, Véronique Eglin, Alexandre Aussem, Jérémy Espinas, Alexandre Lacoste* | **Category: cs.CL**

**Keywords:** LineRetriever, 网页智能体, 上下文减少, 规划感知, 大型语言模型

**Comment:** 

> **TL;DR:** LineRetriever通过识别与未来导航步骤最相关的观察行来减少网页代理的上下文大小，同时保持性能，解决了大型语言模型在网页导航中面临的上下文限制问题。

**AI_Comments:** LineRetriever提出了一种创新且实用的方法来解决LLM在处理复杂网页环境时面临的核心挑战——上下文窗口限制。其“规划感知”的检索策略是关键创新点，超越了简单的语义匹配，使模型能够更有效地进行自适应规划。这种方法对于提高网页代理的效率和鲁棒性具有重要意义，尤其是在需要多步推理和决策的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在网页导航任务中面临网页上下文过大（如DOM或可访问性树结构）超出模型上下文限制的问题。现有方法（如自下而上截断或基于嵌入的检索）会丢失页面状态和动作历史的关键信息，这对于网页智能体中的自适应规划尤其不利。作者假设嵌入模型缺乏捕获规划相关信息（尤其是支持未来动作预测的内容）的足够能力。

**Method:** 本文提出了LineRetriever，一种利用语言模型识别和检索与未来导航步骤最相关的观测行的新方法。与仅关注语义相似性的传统检索方法不同，LineRetriever明确考虑规划范围，优先选择有助于动作预测的元素。

**Result:** 实验表明，LineRetriever可以减少网页智能体在每一步的观测大小，同时在上下文限制内保持一致的性能。

**Conclusion:** LineRetriever通过智能地减少观测大小，有效地解决了大型语言模型在网页导航中面临的上下文限制问题，且不牺牲性能，尤其适用于自适应规划。

> **ai_Abstract:** LineRetriever旨在解决大型语言模型在网页导航中因网页上下文过大而导致的上下文限制问题。该方法通过使用语言模型识别并仅检索与未来导航步骤最相关的观测行，从而智能地减少输入信息量。与传统仅基于语义相似性的检索不同，LineRetriever明确考虑规划范围和动作预测需求。实验证明，它能在保持性能的同时有效减小网页代理的观测大小，使其在上下文限制内高效运行。

> **摘要翻译:** 虽然大型语言模型在网页导航任务中展示了令人印象深刻的能力，但网页的广泛上下文（通常表示为DOM或可访问性树结构）经常超出模型的上下文限制。当前的方法，如自下而上截断或基于嵌入的检索，会丢失关于页面状态和动作历史的关键信息。这对于网页智能体中的自适应规划尤其成问题，因为理解当前状态对于确定未来动作至关重要。我们假设嵌入模型缺乏捕获规划相关信息的足够能力，尤其是在检索支持未来动作预测的内容时。这提出了一个根本性问题：如何优化检索方法以实现网页导航任务中的自适应规划？作为回应，我们引入了\textit{LineRetriever}，这是一种新颖的方法，它利用语言模型识别和检索与未来导航步骤最相关的观测行。与仅关注语义相似性的传统检索方法不同，\textit{LineRetriever}明确考虑规划范围，优先选择有助于动作预测的元素。我们的实验表明，\textit{LineRetriever}可以减少网页智能体在每一步的观测大小，同时在上下文限制内保持一致的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [TransLaw: Benchmarking Large Language Models in Multi-Agent Simulation of the Collaborative Translation](https://arxiv.org/abs/2507.00875)
> *TransLaw: 大语言模型在协同翻译多智能体模拟中的基准测试*

*Xi Xuan, King-kui Sin, Yufei Zhou, Chunyu Kit* | **Category: cs.CL, cs.HC, cs.MA**

**Keywords:** 大语言模型, 多智能体系统, 法律翻译, 香港法律判决, 协同翻译

**Comment:** arXiv admin note: text overlap with arXiv:2501.09444; text overlap
  with arXiv:2409.20288 by other authors

> **TL;DR:** TransLaw是一个用于香港法律判决翻译的多智能体框架，它通过三个专业代理协同工作，在法律翻译准确性上超越了GPT-4o，并大幅降低了成本，但仍落后于人类专家。

**AI_Comments:** TransLaw的创新之处在于其多智能体协同翻译框架，特别针对法律领域，通过分解任务给专业代理来提升翻译质量。其超越GPT-4o的性能和显著的成本效益证明了这种特定领域多智能体LLM应用的可能性和价值。然而，在处理高度细致的语境和自然度方面仍需努力，这可能需要更深层次的领域知识整合或更先进的LLM微调技术。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在机器翻译等应用中表现出色，但在翻译香港法律判决方面仍存在不确定性，因为法律术语复杂、文化细微差别和严格的语言结构带来了挑战。

**Method:** 本文引入了TransLaw，一个为真实世界香港案例法翻译而实现的新型多智能体框架。它雇佣了翻译者、注释者和校对者三个专业代理，以协作方式生成译文，旨在确保法律含义的高准确性、风格的恰当性以及结构上的充分连贯性和衔接性。该框架支持可定制的LLM配置，并能显著降低成本。

**Result:** 使用13个开源和商业大语言模型作为代理进行性能评估，结果显示TransLaw在法律语义准确性、结构连贯性和风格保真度方面超越了GPT-4o。然而，在复杂术语的语境化和风格自然度方面，TransLaw仍落后于人类专家。

**Conclusion:** TransLaw证明了多智能体大语言模型框架在特定领域（如法律翻译）中超越单一LLM的能力，并提供了经济高效的解决方案，但仍需在语境理解和自然度方面进一步提升以媲美人类专家。

> **ai_Abstract:** 本文介绍了TransLaw，一个专为香港法律判决翻译设计的多智能体框架。该框架由翻译者、注释者和校对者三个代理组成，旨在提高法律翻译的准确性、风格恰当性和结构连贯性。实验表明，TransLaw在法律语义准确性等方面优于GPT-4o，且成本远低于人工翻译，但在处理复杂术语的语境和风格自然度方面仍有不足。

> **摘要翻译:** 由大语言模型（LLMs）驱动的多智能体系统在包括机器翻译在内的广泛下游应用中展现出卓越的能力。然而，由于复杂的法律术语、文化嵌入的细微差别和严格的语言结构等挑战，LLMs在翻译香港法律判决方面的潜力仍不确定。在这项工作中，我们引入了TransLaw，一个为真实世界香港案例法翻译而实现的新型多智能体框架。它雇佣了三个专业代理，即翻译者、注释者和校对者，以协作方式生成译文，以确保法律含义的高准确性、风格的恰当性以及结构上的充分连贯性和衔接性。该框架支持可定制的LLM配置，并与专业人工翻译服务相比，实现了巨大的成本降低。我们使用13个开源和商业LLMs作为代理评估了其性能，并获得了有趣的发现，包括它在法律语义准确性、结构连贯性和风格保真度方面超越了GPT-4o，但在复杂术语的语境化和风格自然度方面仍落后于人类专家。我们的平台网站可在香港城市大学访问，用于评估的双语判决语料库可在Hugging Face获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [148] [Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning](https://arxiv.org/abs/2507.00214)
> *两阶段推理注入学习：通过LLM生成的推理改进分类*

*Mads Henrichsen, Rasmus Krebs* | **Category: cs.CL, cs.AI**

**Keywords:** LLM, 推理生成, 文本分类, 两阶段学习, 情感分类

**Comment:** 

> **TL;DR:** 本文提出一种两阶段方法，利用LLM生成的推理来增强文本分类，显著提高了情感分类的准确性，并提供了显式解释。

**AI_Comments:** 该研究通过引入LLM生成的显式推理，有效解决了传统分类模型缺乏可解释性和性能瓶颈的问题。其两阶段训练方法，特别是利用一个通用推理生成模型来增强下游分类任务的训练数据，具有创新性。这种方法不仅提升了分类准确率，还为模型提供了可解释性，为未来的NLP任务提供了新的思路。其限制可能在于对LLM生成推理质量的依赖以及推理生成本身的计算成本。

<details>
  <summary>Details</summary>

**Motivation:** 标准分类模型通常将输入直接映射到标签，缺乏显式推理，这限制了它们的性能、鲁棒性和可解释性。本文旨在通过引入大型语言模型（LLM）生成的推理来解决这些局限性，从而提高文本分类的性能。

**Method:** 本文提出一种新颖的两阶段方法。第一阶段，微调一个Llama-3.2-1B-Instruct模型（Llama-R-Gen），使其在一个通用推理数据集上，根据问题及其答案生成文本推理（R）。第二阶段，这个经过通用训练的Llama-R-Gen被离线用于为下游生成模型创建增强训练数据集。这个下游模型基于Llama-3.2-1B-Instruct，只接收输入文本（Q），并被训练成输出生成的推理（R），紧接着是预测的情绪（A）。

**Result:** 在dair-ai/emotion数据集上的情感分类实验表明，训练输出推理和情感的生成模型（Classifier Q->RA）比仅输出情感的基线生成模型（Classifier Q->A）在准确率上显著提高了8.7个百分点。这突出了推理生成强大的泛化能力以及显式推理训练的益处。

**Conclusion:** LLM生成的推理在创建更丰富的训练数据集方面具有潜力，可以有效提高各种下游NLP任务的性能，并提供显式解释。

> **ai_Abstract:** 本文提出一种名为“两阶段推理注入学习”的新方法，旨在通过利用大型语言模型（LLM）生成的显式推理来提升文本分类的性能、鲁棒性和可解释性。该方法分为两个阶段：首先，微调一个Llama模型（Llama-R-Gen）用于生成通用推理；其次，利用Llama-R-Gen离线生成增强数据集，训练一个下游生成模型，使其能够同时输出推理和分类结果。实验结果表明，这种方法在情感分类任务上取得了显著的准确率提升，证明了LLM生成推理在丰富训练数据和提升下游NLP任务性能方面的有效性。

> **摘要翻译:** 标准分类模型通常将输入直接映射到标签，而没有显式推理，这可能会限制它们的性能、鲁棒性和可解释性。本文引入了一种新颖的两阶段方法，通过利用大型语言模型（LLM）生成的推理来增强文本分类。在第一阶段，我们对Llama-3.2-1B-Instruct模型（此后简称Llama-R-Gen）进行微调，使其在一个通用推理数据集（syvai/reasoning-gen）上，根据问题及其答案生成文本推理（R）。在第二阶段，这个经过通用训练的Llama-R-Gen被离线用于为下游生成模型创建增强训练数据集。这个下游模型基于Llama-3.2-1B-Instruct，只接收输入文本（Q），并被训练成输出生成的推理（R），紧接着是预测的情绪（A）。我们在dair-ai/emotion数据集上演示了这种情感分类方法。我们的实验表明，训练输出推理和情感的生成模型（Classifier Q->RA）比仅训练输出情感的基线生成模型（Classifier Q->A）在准确率（情感预测）上显著提高了8.7个百分点，这突出了推理生成强大的泛化能力以及显式推理训练的益处。这项工作强调了LLM生成的推理在创建更丰富的训练数据集方面的潜力，从而提高了各种下游NLP任务的性能并提供了显式解释。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [169] [Towards Style Alignment in Cross-Cultural Translation](https://arxiv.org/abs/2507.00216)
> *跨文化翻译中的风格对齐*

*Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar* | **Category: cs.CL**

**Keywords:** 跨文化翻译, 风格对齐, 大型语言模型, RASTA, 文化差异

**Comment:** Accepted to ACL 2025

> **TL;DR:** 本文提出RASTA方法，利用检索增强的风格概念来解决大型语言模型在跨文化翻译中风格对齐失败的问题，特别是中性偏见和非西方语言表现不佳。

**AI_Comments:** 本文识别并解决了当前大型语言模型在跨文化翻译中风格对齐的显著挑战，特别是其倾向于中性化和在非西方语言中表现不佳的问题。RASTA方法通过引入检索增强的风格概念，为提升LLM的文化敏感性和风格传达能力提供了一个创新途径。这对于促进更自然、更忠实于原意的跨文化交流具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 成功的跨文化交流需要说话者意图的风格与听者感知的风格对齐，但文化差异常常导致这种风格错位，例如礼貌在翻译中丢失。此外，大型语言模型（LLMs）在风格翻译方面存在缺陷，倾向于中性化翻译，并在非西方语言中表现更差。

**Method:** 本文提出了一种名为RASTA（Retrieval-Augmented STylistic Alignment，检索增强风格对齐）的方法。该方法利用学习到的风格概念来鼓励大型语言模型在翻译时恰当地传达文化交流规范并对齐风格。

**Result:** 研究发现大型语言模型在风格翻译方面存在缺陷，表现为翻译倾向于中性化，并且在非西方语言中的表现更差。RASTA方法能够缓解这些失败。

**Conclusion:** RASTA方法通过利用学习到的风格概念，有效鼓励大型语言模型在跨文化翻译中恰当地传达文化交流规范并对齐风格，从而弥补了现有LLM在风格翻译上的不足。

> **ai_Abstract:** 本文探讨了跨文化翻译中风格对齐的重要性，指出文化差异常导致风格错位，且现有大型语言模型（LLMs）在风格翻译上存在中性偏见和非西方语言表现不佳的问题。为解决这些问题，论文提出了一种名为RASTA（检索增强风格对齐）的方法，该方法利用学习到的风格概念来引导LLM在翻译时更好地传达文化交流规范，从而实现风格对齐。

> **摘要翻译:** 成功的沟通取决于说话者意图的风格（即说话者试图传达的内容）与听者理解的风格（即听者感知到的内容）保持一致。然而，文化差异常常导致两者之间的错位；例如，礼貌在翻译中经常丢失。我们描述了大型语言模型（LLMs）未能翻译风格的方式——它们使翻译偏向中性，并在非西方语言中表现更差。我们通过RASTA（检索增强风格对齐）来缓解这些失败，这是一种利用学习到的风格概念来鼓励大型语言模型翻译恰当地传达文化交流规范并对齐风格的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [187] [Linearly Decoding Refused Knowledge in Aligned Language Models](https://arxiv.org/abs/2507.00239)
> *对齐语言模型中被拒绝知识的线性解码*

*Aryan Shrivastava, Ari Holtzman* | **Category: cs.CL, cs.AI**

**Keywords:** 语言模型, 对齐, 越狱, 线性探针, 拒绝知识

**Comment:** 

> **TL;DR:** 本研究表明，对齐语言模型中被拒绝的有害信息并非被消除，而是被抑制了直接表达，但仍可通过线性探针解码并间接影响下游行为。

**AI_Comments:** 这项研究揭示了对齐语言模型安全机制的一个重要局限性。它创新性地展示了即使模型拒绝直接生成有害内容，其内部表征中仍保留了相关信息，并且这些信息可以通过线性探针被提取和预测。更重要的是，研究指出这些被抑制的信息并非死数据，而是仍在模型内部被“积极使用”，影响着模型的深层行为，这对于理解和改进语言模型的对齐和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数语言模型经过指令微调和对齐后会拒绝有害请求，但越狱提示词常能绕过这些机制。本研究旨在探究通过越狱提示词获取的信息在多大程度上可以通过线性探针从语言模型的隐藏状态中解码出来。

**Method:** 本研究使用在线性模型隐藏状态上训练的线性探针来解码通过越狱提示词获取的信息。研究还测试了在基础模型上训练的探针是否能迁移到其指令微调版本，并分析了探针预测值与语言模型生成行为之间的相关性。

**Result:** 结果显示，大量最初被拒绝的信息是可线性解码的。例如，对于一个国家的平均智商，越狱语言模型的响应可以通过线性探针以超过0.8的皮尔逊相关系数进行预测。令人惊讶的是，在基础模型（不拒绝）上训练的探针有时可以迁移到其指令微调版本，并揭示越狱生成解码的信息，这表明许多被拒绝属性的内部表示从基础语言模型通过指令微调得以保留。重要的是，这些信息不仅是“残余”的，而且被指令微调模型积极使用：探针预测值与语言模型生成的成对比较相关，表明探针解码的信息与被抑制的生成行为一致，这些行为可能在其他下游任务中表现得更微妙。

**Conclusion:** 总的来说，我们的结果表明，指令微调并没有完全消除甚至重新定位表示空间中的有害信息——它们只是抑制了其直接表达，使其既可线性访问，又在下游行为中产生间接影响。

> **ai_Abstract:** 本研究探讨了对齐语言模型中被拒绝的有害信息是否仍可被访问和利用。研究发现，通过越狱提示词访问的大量信息可通过线性探针从模型隐藏状态中解码，且在基础模型上训练的探针能迁移到指令微调版本。这表明，指令微调并未消除有害信息，而是抑制了其直接表达，但这些信息仍在线性上可访问并间接影响模型行为，例如通过与生成式比较相关联。

> **摘要翻译:** 大多数常用的语言模型（LMs）经过指令微调和强化学习的结合进行对齐，导致它们拒绝模型认为有害的用户请求。然而，越狱提示词通常可以绕过这些拒绝机制并引发有害响应。在这项工作中，我们研究了通过越狱提示词访问的信息在多大程度上可以通过在线性模型隐藏状态上训练的线性探针进行解码。我们表明，大量最初被拒绝的信息是可线性解码的。例如，在不同模型中，越狱语言模型对一个国家平均智商的响应可以通过线性探针以超过0.8的皮尔逊相关系数进行预测。令人惊讶的是，我们发现，在基础模型（不拒绝）上训练的探针有时可以迁移到其指令微调版本，并能够揭示越狱生成解码的信息，这表明许多被拒绝属性的内部表示从基础语言模型通过指令微调得以保留。重要的是，我们表明这些信息不仅仅是指令微调模型中的“残余”，而且被它们积极使用：我们发现探针预测值与语言模型生成的成对比较相关，这表明我们的探针解码的信息与被抑制的生成行为一致，这些行为可能在其他下游任务中表现得更微妙。总的来说，我们的结果表明，指令微调并没有完全消除甚至重新定位表示空间中的有害信息——它们只是抑制了其直接表达，使其既可线性访问，又在下游行为中产生间接影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [205] [The Algebraic Structure of Morphosyntax](https://arxiv.org/abs/2507.00244)
> *构词句法的代数结构*

*Isabella Senturia, Matilde Marcolli* | **Category: cs.CL, math.QA, 91F20, 18M60, 68Q70**

**Keywords:** 构词句法, 数学模型, 形态-句法接口, Operad, 分布式形态学

**Comment:** 45 pages, LaTeX, 2 png figures

> **TL;DR:** 本文在数学形式化的Merge和强极简主义论题背景下，提出了一个形态-句法接口的数学模型，并描述了构词句法树的结构形成过程。

**AI_Comments:** 本文的创新之处在于其对形态-句法接口的数学形式化，特别是引入了operad和代数理论来描述构词句法树的结构形成。这种抽象的数学方法为语言学理论提供了一个严谨的框架，可能有助于更精确地理解语言的组合性。其重要性在于为极简主义纲领提供了一个量化和可验证的视角，并为分布式形态学中的操作提供了新的解释。

<details>
  <summary>Details</summary>

**Motivation:** 在Merge和强极简主义论题的数学形式化背景下，建立形态-句法接口的数学模型。

**Method:** 本文将形态学描述为形态树的岩浆（magma），具有组合性质，负责构词。引入了协积分解（coproduct decomposition），并扩展了形态树的集合。构词句法树的形成被建模为在一个operad上的代数（algebra over an operad）以及operad上的代数之间的对应关系。通过这种将句法和形态数据配对的operadic对应关系和形态协积来描述结构形成过程。

**Result:** 提出了一个形态-句法接口的数学模型。描述了构词句法树的结构形成过程，并重新解释了分布式形态学中的某些操作，使其能够灵活地移动句法和形态之间的边界。

**Conclusion:** 本文提出的数学模型提供了一种重新解释分布式形态学中操作的方式，允许在构词句法对象中灵活调整句法和形态之间的边界。

> **ai_Abstract:** 本文在Merge和强极简主义论题的数学框架下，构建了一个形态-句法接口的数学模型。该模型将形态学视为形态树的岩浆，具有构词的组合特性，并引入了协积分解。构词句法树的形成被描述为在一个operad上的代数，并通过operadic对应关系和形态协积来解释其结构形成过程。此外，该模型重新诠释了分布式形态学中的操作，使其能够灵活调整句法与形态间的界限。

> **摘要翻译:** 在Merge和强极简主义论题的数学形式化背景下，我们提出了一个形态-句法接口的数学模型。在此背景下，形态学具有负责构词的组合性质，组织成形态树的岩浆。然而，与句法不同，形态学内部没有移动。存在一个协积分解，但这需要将形态树的集合扩展到岩浆单独生成的范围之外，扩展到更大的可能作为句法树形态输入的集合。这些作为在一个operad上的代数参与构词句法树的形成，以及operad上的代数之间的对应关系。构词句法树的结构形成过程可以通过这种将句法和形态数据配对的operadic对应关系和形态协积来描述。在此背景下，我们重新解释了分布式形态学中的某些操作，将其视为允许在构词句法对象中灵活移动句法和形态之间边界的转换。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [216] [Many LLMs Are More Utilitarian Than One](https://arxiv.org/abs/2507.00814)
> *多个大型语言模型比单个模型更具功利性*

*Anita Keshmirian, Razan Baltaji, Babak Hemmatian, Hadi Asghari, Lav R. Varshney* | **Category: cs.CL, cs.AI, cs.CY, I.2.7; I.2.11**

**Keywords:** LLMs, 道德判断, 多智能体系统, 功利主义, 群体动力学

**Comment:** 9 pages, 8 Figures, 7 tables

> **TL;DR:** 大型语言模型（LLMs）在群体中表现出比单独个体更强的功利主义道德判断，尽管其潜在机制与人类不同。

**AI_Comments:** 这项研究的创新之处在于，它不仅揭示了LLM群体在道德判断上与人类群体行为的相似性，更深入地探讨了其背后机制的差异。这对于理解LLM的内在决策逻辑，以及在设计多智能体系统时如何进行AI对齐和道德约束具有重要意义。它提示我们，即使AI表现出类似人类的行为，其内部原因也可能大相径庭，需要更细致的分析和设计。

<details>
  <summary>Details</summary>

**Motivation:** 道德判断对于大型语言模型（LLMs）的对齐和社会推理至关重要。随着多智能体系统的兴起，理解LLMs在协作中如何集体运作，与单个智能体相比，变得至关重要。本研究旨在探讨多智能体LLM系统中是否存在类似人类群体审议中出现的功利主义提升现象。

**Method:** 研究测试了六个LLM模型，在两组条件下（独立推理的“Solo”和进行多轮讨论的“Group”，包括两两或三人小组）对既定的道德困境进行判断。

**Result:** 在个人道德困境中，所有模型在群体中比单独个体更容易接受道德违规行为，这与人类实验结果相似。有些模型支持最大化整体福祉的行为，即使这会使陌生人受益而非熟人。其他模型在群体中更愿意违反道德规范。然而，尽管LLM群体表现出类似人类群体的行为偏向，但其功利主义提升的机制与人类不同：人类的转变源于对决策结果敏感度的提高，而LLM群体则表现出规范敏感度降低或公正性增强。

**Conclusion:** 研究表明，尽管LLM群体在表面行为上模仿了人类的群体推理，但其潜在驱动因素是不同的。这对于AI对齐、多智能体设计和人工智能道德推理具有重要意义。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）在多智能体系统中的道德判断。实验发现，与人类群体类似，LLM群体在面对道德困境时也表现出“功利主义提升”，即更倾向于接受能最大化整体利益的道德违规行为。然而，LLM群体产生这种转变的潜在机制与人类不同，人类是由于对结果的敏感度提高，而LLM则表现出规范敏感度降低或公正性增强。这为AI对齐和多智能体系统设计提供了重要启示。

> **摘要翻译:** 道德判断是大型语言模型（LLM）对齐和社会推理不可或缺的一部分。随着多智能体系统日益突出，了解LLM在协作过程中如何集体运作，与单个智能体相比，变得至关重要。在人类道德判断中，群体审议会带来功利主义的提升：一种倾向于认可尽管有危害但能为最多人带来最大利益的规范违反行为。我们研究了多智能体LLM系统是否会出现类似动态。我们测试了六个模型，在两种条件下对既定的道德困境进行判断：(1) 独立推理的“Solo”条件，和 (2) 进行多轮讨论（两人或三人小组）的“Group”条件。在个人道德困境中，即智能体必须决定直接伤害一个人以最大化他人的效用时，所有模型在群体中比单独个体更容易接受道德违规行为，这与人类实验结果相似。有些模型认可了最大化整体福祉的行为，即使这些行为使陌生人而非熟悉个体受益。其他模型在群体中变得更愿意违反道德规范。然而，尽管人类群体表现出类似的行为偏向，但其功利主义提升的机制与LLM不同。人类的转变源于对决策结果敏感度的提高，而LLM群体则表现出规范敏感度降低或公正性增强。这表明，虽然LLM集体的表面行为模仿了人类的群体推理，但其潜在驱动因素是不同的。我们讨论了这对AI对齐、多智能体设计和人工智能道德推理的意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [220] [EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning](https://arxiv.org/abs/2507.00246)
> *EfficientXLang：通过跨语言推理提升Token效率*

*Sanchit Ahuja, Praneetha Vaddamanu, Barun Patra* | **Category: cs.CL**

**Keywords:** 跨语言推理, Token效率, 语言模型, 多语言能力, 推理行为

**Comment:** 15 pages, 5 figures, 9 tables

> **TL;DR:** 研究发现，在非英语语言中进行推理可以显著减少大型语言模型的Token使用量，同时保持甚至提升准确性，这表明跨语言推理具有未被充分利用的潜力。

**AI_Comments:** 这项研究具有重要的创新性，它挑战了当前语言模型研究中普遍存在的“英语中心”范式，揭示了多语言预训练模型在非英语语言中进行推理的潜在优势。其发现非英语推理能减少Token使用并保持准确性，尤其是在推理行为层面而非仅表层语言效应上的转变，为未来高效且鲁棒的语言模型设计提供了新思路。研究结果强调了多语言能力作为模型核心基础的重要性，对推动多语言AI发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管许多语言推理模型（LRMs）在多语言数据上进行了预训练，但大多数现有研究仅关注英语，这促使作者探讨英语是否是推理任务中最Token高效的语言。

**Method:** 研究评估了DeepSeek R1、Qwen 2.5和Qwen 3这三个开源语言模型，在四个数学数据集和七种不同类型语言上进行了实验，以比较不同语言下的Token使用效率和推理准确性。

**Result:** 研究发现，在非英语语言中进行推理不仅能减少Token使用量，还能保持甚至提升准确性。即使将推理过程翻译成英语，这些优势依然存在，这表明推理行为发生了真正的转变，而非表层语言效应。然而，改进的程度取决于模型的多语言能力。

**Conclusion:** 研究结果表明，需要拓宽对语言模型推理的视角，强调多语言推理的潜力以及构建强大多语言基础的重要性。

> **ai_Abstract:** 本文探讨了语言推理模型中跨语言推理的Token效率问题。研究通过在多种语言和数学数据集上评估DeepSeek R1、Qwen 2.5和Qwen 3模型，发现非英语推理能有效减少Token消耗并保持准确性，甚至在翻译回英语后依然如此。这表明模型在非英语环境下展现出更深层次的推理行为转变。研究强调了多语言能力对模型表现的重要性，并呼吁更广泛地关注多语言推理的潜力。

> **摘要翻译:** 尽管语言推理模型（LRMs）取得了最新进展，但大多数研究仅关注英语，尽管许多模型都在多语言数据上进行了预训练。在这项工作中，我们调查：英语是推理任务中最Token高效的语言吗？我们评估了三个开源LRM：DeepSeek R1、Qwen 2.5和Qwen 3，跨越四个数学数据集和七种类型各异的语言。我们发现，在非英语语言中进行推理不仅减少了Token使用量，而且保持了准确性。即使将推理痕迹翻译成英语，这些收益依然存在，这表明推理行为发生了真正的转变，而非表层语言效应。然而，改进的程度取决于模型的多语言能力。我们的发现促使我们对语言模型中的推理采取更广阔的视角，突出了多语言推理的潜力以及强大多语言基础的重要性。我们工作的代码可在以下链接找到：https://github.com/microsoft/EfficientXLang。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [235] [Impact of Fine-Tuning Methods on Memorization in Large Language Models](https://arxiv.org/abs/2507.00258)
> *微调方法对大型语言模型记忆化的影响*

*Jie Hou, Chuxiong Wu, Lannan Luo, Qiang Zeng* | **Category: cs.CL, cs.AI**

**Keywords:** 微调, 记忆化, 隐私, 大型语言模型, 成员推断攻击

**Comment:** 

> **TL;DR:** 研究发现，相比于基于参数的微调，基于提示的微调在大型语言模型中表现出更低的记忆化风险，从而更好地保护隐私。

**AI_Comments:** 这项研究创新性地关注了大型语言模型微调过程中的隐私风险，并对比了不同微调策略对记忆化的影响。其重要性在于为开发更安全的LLM微调方法提供了实证依据，特别是强调了基于提示的微调在隐私保护方面的优势，这对于构建负责任的AI系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 预训练和微调范式在大型语言模型中日益普及，但微调过程中因记忆化导致的隐私风险却鲜受关注。本研究旨在填补这一空白。

**Method:** 研究人员对流行的微调方法进行了分类，并通过成员推断攻击（MIAs）评估了它们对记忆化的影响。

**Result:** 结果显示，与基于参数的微调相比，基于提示的微调在保持竞争性能的同时，对成员推断攻击的脆弱性更低。此外，基于提示的方法无论模型规模大小，都能保持较低的记忆化水平。

**Conclusion:** 研究表明，基于参数的微调更容易泄露私人信息，而基于提示的微调是更具隐私保护性的选择。

> **ai_Abstract:** 本研究探讨了不同微调方法对大型语言模型记忆化的影响，以解决微调过程中潜在的隐私风险。通过对流行微调方法的分类并使用成员推断攻击进行评估，研究发现基于提示的微调相比基于参数的微调，在保持性能的同时，对记忆化攻击的脆弱性更低，且这种低记忆化特性不受模型规模影响。这表明基于提示的微调是更具隐私保护性的选择。

> **摘要翻译:** 随着预训练大型语言模型（LLMs）能力的不断提升，“预训练和微调”范式已日益成为主流，催生了各种微调方法。然而，微调过程中因记忆化导致的隐私风险却相对较少受到关注。为了解决这一空白，我们对流行的微调方法进行了分类，并通过成员推断攻击（MIAs）的视角评估了它们对记忆化的影响。我们的结果显示，与基于参数的微调相比，基于提示的微调在实现竞争性能的同时，对MIAs的脆弱性更低。此外，基于提示的方法无论模型规模大小，都能保持较低的记忆化水平。这些发现表明，基于参数的微调更容易泄露私人信息，而基于提示的微调是更具隐私保护性的选择。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [248] [Natural language processing for African languages](https://arxiv.org/abs/2507.00297)
> *非洲语言的自然语言处理*

*David Ifeoluwa Adelani* | **Category: cs.CL, cs.AI**

**Keywords:** 非洲语言, 低资源NLP, 预训练语言模型, 命名实体识别, 机器翻译

**Comment:** PhD thesis

> **TL;DR:** 该论文专注于非洲低资源语言的自然语言处理，分析数据质量，展示多语言预训练语言模型的潜力，并为21种非洲语言构建了大规模标注数据集。

**AI_Comments:** 该论文在解决低资源语言NLP问题方面具有重要意义，特别是其对数据质量的强调以及为非洲语言构建大规模标注数据集的努力。这不仅推动了非洲语言NLP研究的发展，也为未来低资源语言的研究提供了宝贵的资源和方法论。

<details>
  <summary>Details</summary>

**Motivation:** 现有多语言模型在低资源语言上面临挑战，如数据稀缺、噪声大、缺乏标注数据集难以评估性能。非洲撒哈拉以南地区的本土语言在NLP任务中被视为低资源语言，缺乏标注和未标注数据。该研究旨在解决非洲语言在NLP研究中的代表性不足问题。

**Method:** 分析了公开语料库中的噪声，并整理了一个高质量语料库。实证展示了词嵌入的局限性和多语言预训练语言模型（PLM）的潜力。研究了如何使用少量单语文本来适应和专门化多语言PLM到未见过的非洲语言。为21种非洲语言的命名实体识别和机器翻译任务开发了大规模人工标注数据集。使用最先进的方法在监督学习、弱监督学习和迁移学习设置下进行了广泛的实证评估。

**Result:** 证明了语义表示学习的质量不仅取决于数据量，还取决于预训练数据的质量。实证展示了词嵌入的局限性以及多语言PLM在未见语言和低资源场景中的机会。成功为21种非洲语言在命名实体识别和机器翻译任务上创建了大规模人工标注数据集，并进行了广泛评估。

**Conclusion:** 该论文通过关注非洲低资源语言的NLP问题，强调了数据质量的重要性，展示了多语言预训练语言模型在低资源场景下的潜力，并通过构建大规模标注数据集和进行广泛评估，为解决非洲语言在NLP研究中的代表性不足做出了重要贡献。

> **ai_Abstract:** 本论文致力于解决非洲低资源语言在自然语言处理（NLP）领域的挑战，这些语言因数据稀缺和质量问题而面临性能瓶颈。研究分析了公开语料库的噪声，并强调了预训练数据质量对语义表示学习的重要性。论文实证探讨了词嵌入的局限性，并展示了多语言预训练语言模型（PLM）在低资源和未见语言场景下的优势。为解决非洲语言的代表性不足，研究为21种非洲语言的命名实体识别和机器翻译任务构建了大规模人工标注数据集，并进行了全面的多范式评估。

> **摘要翻译:** 词嵌入和语言模型的最新进展利用大规模、未标注数据和自监督学习来提升NLP性能。多语言模型通常在维基百科等网络来源数据上进行训练，面临挑战：很少包含低资源语言，其数据通常噪声大，并且缺乏标注数据集使得在英语等高资源语言之外难以评估性能。在本论文中，我们专注于撒哈拉以南非洲地区使用的语言，该地区所有本土语言在NLP任务的标注数据和网络上找到的未标注数据方面都可以被视为低资源语言。我们分析了公开可用语料库中的噪声，并整理了一个高质量语料库，证明了词嵌入中学习到的语义表示的质量不仅取决于数据量，还取决于预训练数据的质量。我们实证展示了词嵌入的局限性，以及多语言预训练语言模型（PLM）提供的机会，特别是对于预训练期间未见过的语言和低资源场景。我们进一步研究了如何使用少量单语文本来适应和专门化多语言PLM到未见过的非洲语言。为了解决非洲语言在NLP研究中代表性不足的问题，我们为21种非洲语言在两个重要的NLP任务：命名实体识别和机器翻译中开发了大规模人工标注数据集。我们在监督学习、弱监督学习和迁移学习设置下，使用最先进的方法进行了广泛的实证评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [260] [Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones](https://arxiv.org/abs/2507.00322)
> *干扰导致的失败：当有缺陷的机制掩盖健全的机制时，语言模型会犯平衡括号错误*

*Daking Rai, Samuel Miller, Kevin Moran, Ziyu Yao* | **Category: cs.CL, cs.AI, cs.SE, I.2.7**

**Keywords:** 语言模型, 平衡括号, 错误机制, RASteer, 模型可解释性

**Comment:** 23 pages, 10 figures, Preprint

> **TL;DR:** 研究发现语言模型在平衡括号任务上的错误是由于“有缺陷的机制”掩盖了“健全的机制”。提出了RASteer方法，通过识别并增强可靠组件的贡献，显著提高了模型在平衡括号和算术推理任务上的性能。

**AI_Comments:** 本研究创新性地揭示了语言模型中“健全”与“有缺陷”机制之间的内部冲突是导致特定错误的关键。RASteer方法通过干预模型内部组件的贡献来纠正错误，而非仅仅通过数据或模型结构调整，这提供了一种新的、可解释的错误缓解策略。其在平衡括号任务上将准确率从0%提升至接近100%的显著效果，以及在算术推理上的泛化能力，凸显了该方法的潜力和重要性。这为理解和改进大型语言模型的内部工作机制提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管语言模型在编码能力上取得了显著进展，但在生成平衡括号等简单句法任务上仍然存在困难。本研究旨在调查这些错误持续存在的基础机制，以理解并缓解这些错误。

**Method:** 研究通过分析不同大小（124M-7B）的语言模型，揭示了模型依赖于独立进行预测的组件（如注意力头和前馈神经网络神经元）。当有缺陷的机制（引入噪声）掩盖健全的机制（促进正确答案）时，就会发生错误。基于此洞察，研究引入了RASteer，一种转向方法，用于系统地识别并增加可靠组件的贡献，以提高模型性能。

**Result:** 研究发现语言模型中的错误是由于有缺陷的机制（产生不正确预测）掩盖了健全的机制（产生正确预测）。RASteer方法显著提高了模型在平衡括号任务上的性能，某些模型的准确率从0%提升到约100%，且不损害模型的通用编码能力。此外，该方法在算术推理任务中也显示出更广泛的适用性，性能提升高达约20%。

**Conclusion:** 语言模型在平衡括号等任务上的错误源于模型内部有缺陷机制对健全机制的干扰。通过RASteer方法，可以系统地识别并增强模型中可靠组件的贡献，从而有效缓解这些错误，显著提升模型在特定句法和推理任务上的表现，同时保持其通用能力。

> **ai_Abstract:** 本研究深入探讨了语言模型在生成平衡括号等句法任务中持续出错的根本原因。研究发现，模型内部存在“健全机制”（促进正确预测）与“有缺陷机制”（引入噪声和错误预测），当后者占据主导时便导致错误。基于这一洞察，论文提出了一种名为RASteer的转向方法，旨在系统性地识别并增强模型中可靠组件的贡献。实验结果表明，RASteer显著提升了模型在平衡括号任务上的性能（某些模型从0%提升至近100%），且未影响其通用编码能力，同时在算术推理任务中也实现了显著的性能增益。

> **摘要翻译:** 尽管在编码能力方面取得了显著进展，语言模型（LMs）仍然难以完成诸如生成平衡括号等简单的句法任务。在本研究中，我们调查了这些错误在不同大小（124M-7B）的语言模型中持续存在的基础机制，以理解和缓解这些错误。我们的研究表明，语言模型依赖于许多独立进行预测的组件（注意力头和前馈神经元）。虽然某些组件在广义输入范围内可靠地促进正确答案（即实现“健全机制”），但其他组件则不太可靠，通过促进不正确的标记引入噪声（即实现“有缺陷机制”）。当有缺陷的机制掩盖健全的机制并主导预测时，就会发生错误。受此启发，我们引入了RASteer，一种转向方法，用于系统地识别并增加可靠组件的贡献，以提高模型性能。RASteer显著提高了平衡括号任务的性能，将某些模型的准确率从0%提升到约100%，而不会损害模型的通用编码能力。我们进一步证明了其在算术推理任务中的更广泛适用性，实现了高达约20%的性能提升。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [261] [Modeling Data Diversity for Joint Instance and Verbalizer Selection in Cold-Start Scenarios](https://arxiv.org/abs/2507.00330)
> *在冷启动场景下建模数据多样性以进行联合实例和Verbalizer选择*

*Mohna Chakraborty, Adithya Kulkarni, Qi Li* | **Category: cs.CL, cs.IR**

**Keywords:** 冷启动场景, 基于提示的方法, Verbalizer选择, 实例选择, 数据多样性

**Comment:** 

> **TL;DR:** 本文提出了COLDSELECT，一种在冷启动场景下联合选择verbalizer和实例的方法，通过建模数据多样性来提高基于提示的方法的性能，并在八个基准测试上表现优于基线。

**AI_Comments:** 本文提出了一种创新的方法COLDSELECT，解决了基于提示学习中的一个关键挑战：在冷启动设置下联合选择verbalizer和实例。其创新之处在于通过嵌入空间映射、降维和聚类，明确地建模了数据多样性以及实例和verbalizer之间的依赖关系。该方法显著增强了基于提示的PLM的鲁棒性和泛化能力，尤其是在标注数据稀缺的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 基于提示的方法对模板、verbalizer和少样本实例的选择很敏感，尤其是在没有标注数据的冷启动设置中。现有研究忽略了实例和verbalizer之间的依赖关系，即实例标签概率取决于嵌入空间中verbalizer token的接近程度。

**Method:** 本文提出了COLDSELECT，一种联合verbalizer和实例选择方法，通过建模数据多样性来解决问题。COLDSELECT将预训练语言模型（PLM）的词汇和掩码嵌入映射到共享空间中，然后应用降维和聚类技术，以确保高效和多样化的选择。该方法通过优化最小不确定性和最大多样性来有效地捕获数据关系。

**Result:** 在八个基准测试上的实验表明，COLDSELECT在减少不确定性和增强泛化能力方面表现出优越性，在冷启动场景下的verbalizer和少样本实例选择方面优于基线方法。

**Conclusion:** COLDSELECT通过建模数据多样性，有效地解决了冷启动场景下实例和verbalizer选择的挑战，从而显著提高了基于提示的方法的性能和泛化能力。

> **ai_Abstract:** 本文介绍了COLDSELECT，一种在冷启动场景下（缺乏标注数据）用于基于提示方法的联合verbalizer和少样本实例选择的新颖方法。它通过建模数据多样性来解决实例和verbalizer之间被忽视的依赖关系。COLDSELECT将PLM词汇和掩码嵌入投影到共享空间中，利用降维和聚类来优化最小不确定性和最大多样性。在八个基准测试上的实验结果表明，COLDSELECT显著降低了不确定性并提高了泛化能力，优于现有基线。

> **摘要翻译:** 基于提示的方法利用预训练语言模型（PLM）通过掩码语言建模（MLM）目标训练的知识；然而，这些方法对模板、verbalizer和少样本实例的选择很敏感，尤其是在没有标注数据的冷启动设置中。现有研究忽略了实例和verbalizer之间的依赖关系，其中实例标签概率取决于嵌入空间中verbalizer token的接近程度。为了解决这个问题，我们提出了COLDSELECT，这是一种联合verbalizer和实例选择方法，它对数据多样性进行建模。COLDSELECT将PLM词汇和$h_{[MASK]}$嵌入映射到共享空间中，应用降维和聚类以确保高效和多样化的选择。通过优化最小不确定性和最大多样性，COLDSELECT有效地捕获了数据关系。在八个基准测试上的实验表明，COLDSELECT在减少不确定性和增强泛化能力方面表现出优越性，在冷启动场景下的verbalizer和少样本实例选择方面优于基线方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [279] [Question Decomposition for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.00355)
> *检索增强生成的问题分解*

*Paul J. L. Ammann, Jonas Golde, Alan Akbik* | **Category: cs.CL**

**Keywords:** 检索增强生成, 问题分解, 多跳问题, 大型语言模型, 重排序

**Comment:** Accepted to ACL SRW 2025. 9 Pages, 2 Figures, 4 Tables

> **TL;DR:** RAG在多跳问题上表现不佳，本文提出通过LLM分解问题、检索、重排序来改进RAG，显著提升了检索和答案准确性。

**AI_Comments:** 本文的创新在于将LLM驱动的问题分解与现成的重排序器相结合，有效解决了RAG在多跳问题上检索不足的挑战。其重要性在于提供了一个无需额外训练且易于部署的实用增强方案，显著提升了检索和问答性能。

<details>
  <summary>Details</summary>

**Motivation:** 标准的检索增强生成（RAG）在处理多跳问题时面临挑战，因为相关事实通常分散在多个文档中，导致难以检索到足够信息。

**Method:** 提出一个结合问题分解的RAG流程：(i) LLM将原始查询分解为子问题；(ii) 为每个子问题检索段落；(iii) 合并的候选池进行重排序，以提高检索证据的覆盖率和精确度。该方法无需额外训练或专门索引。

**Result:** 在MultiHop-RAG和HotpotQA数据集上，相对于标准RAG基线，检索（MRR@10: +36.7%）和答案准确性（F1: +11.6%）均有显著提升。问题分解有效组装互补文档，重排序减少噪音并提升最相关段落。

**Conclusion:** 将现成的交叉编码器重排序器与LLM驱动的问题分解结合，可以弥补多跳问题上的检索差距，提供一个实用、即插即用的增强方案。

> **ai_Abstract:** 本文提出一种改进检索增强生成（RAG）的方法，通过引入基于大型语言模型（LLM）的问题分解来处理多跳问题。该方法首先将复杂问题分解为子问题，然后为每个子问题检索信息，最后对合并的检索结果进行重排序。实验证明，该方法在MultiHop-RAG和HotpotQA数据集上显著提高了检索准确性（MRR@10 +36.7%）和答案准确性（F1 +11.6%），且无需额外训练或特殊索引，提供了一个即插即用的解决方案。

> **摘要翻译:** 将大型语言模型（LLM）基于可验证的外部来源是生成可靠答案的既定策略。检索增强生成（RAG）就是其中一种方法，尤其适用于问答等任务：它检索与问题语义相关的段落，然后根据这些证据对模型进行条件化。然而，多跳问题，例如“英伟达、苹果和谷歌中哪家公司在2023年利润最高？”，对RAG构成了挑战，因为相关事实通常分散在多个文档中，而不是共存于一个来源，这使得标准RAG难以检索到足够信息。为了解决这个问题，我们提出了一种结合问题分解的RAG流程：(i) LLM将原始查询分解为子问题，(ii) 为每个子问题检索段落，(iii) 合并的候选池进行重排序，以提高检索证据的覆盖率和精确度。我们表明，问题分解有效地组装了互补文档，而重排序在答案生成之前减少了噪音并提升了最相关的段落。尽管重排序本身是标准的，但我们表明，将现成的交叉编码器重排序器与LLM驱动的问题分解相结合，弥补了多跳问题上的检索差距，并提供了一个实用、即插即用的增强，无需任何额外训练或专门索引。我们在MultiHop-RAG和HotpotQA上评估了我们的方法，显示相对于标准RAG基线，检索（MRR@10: +36.7%）和答案准确性（F1: +11.6%）均有所提升。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [288] [Gregorian melody, modality, and memory: Segmenting chant with Bayesian nonparametrics](https://arxiv.org/abs/2507.00380)
> *格里高利旋律、调式与记忆：使用贝叶斯非参数方法分割圣咏*

*Vojtěch Lanz, Jan Hajič jr* | **Category: cs.CL**

**Keywords:** 格里高利圣咏, 贝叶斯非参数, 旋律分割, 调式分类, 记忆效率

**Comment:** 

> **TL;DR:** 本文使用嵌套分层Pitman-Yor语言模型对格里高利圣咏进行无监督分割，实现了调式分类的最新性能，并发现分割与记忆效率之间的联系，但指出这种分割并非传统意义上的“centonisation”。

**AI_Comments:** 本文的创新之处在于将贝叶斯非参数方法（嵌套分层Pitman-Yor语言模型）应用于格里高利圣咏的无监督分割，并首次将其与人类记忆过程联系起来，提供了新的视角来理解圣咏的结构。其重要性在于为圣咏研究提供了一种量化且数据驱动的方法，超越了纯粹的音乐学理论。然而，论文也明确指出，即使是这种优化后的分割，也未能完全支持传统的“centonisation”理论，这既是其诚实之处，也暗示了该理论的复杂性或需要进一步的重新定义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管“centonisation”理论受到批评，但圣咏中确实存在旋律片段的频繁重用，且先前的经验结果表明分割在调式分类中表现优异。受格里高利圣咏通过记忆学习的事实启发，本文旨在寻找圣咏旋律的最佳无监督分割，以探究其价值并验证分割在调式分类中的表现。

**Method:** 本文使用嵌套分层Pitman-Yor语言模型来寻找圣咏旋律的最佳无监督分割。

**Result:** 本文发现的分割在调式分类中达到了最先进的性能。通过模拟僧侣记忆礼仪手稿中的旋律，研究发现了调式分类与记忆效率之间联系的经验证据，并观察到旋律开头和结尾处有更多公式化区域，这与调式在表演中的实际作用相符。然而，分割结果本身表明，即使是这种记忆最优的分割也并非是传统理解的“centonisation”。

**Conclusion:** 尽管通过贝叶斯非参数方法获得的记忆最优分割在调式分类上表现出色，并揭示了与记忆效率的联系，但它并不符合传统上对“centonisation”的理解。

> **ai_Abstract:** 本文利用嵌套分层Pitman-Yor语言模型对格里高利圣咏进行无监督分割，旨在解决传统“centonisation”理论的争议并探索记忆与调式的关系。研究发现的分割在调式分类中取得了最先进的性能，并提供了调式分类与记忆效率之间联系的经验证据，揭示了旋律开头和结尾的公式化区域。尽管如此，研究指出这种记忆最优的分割与传统意义上的“centonisation”并不一致。

> **摘要翻译:** “格里高利旋律是由某些片段词汇构建而成”的观点长期以来一直是圣咏学术的一部分。这种所谓的“centonisation”理论受到了许多音乐学的批评，但圣咏旋律中确实观察到某些旋律片段的频繁重用，并且可能存在的分割数量难以处理，这使得人们认为可能存在某种未被发现的分割，可以证明“centonisation”的价值，最近的经验结果也表明，分割在调式分类中的表现优于音乐理论特征。受格里高利圣咏是通过记忆学习这一事实的启发，我们使用嵌套分层Pitman-Yor语言模型来寻找圣咏旋律的最佳无监督分割。我们发现的分割在调式分类中达到了最先进的性能。通过模拟一位僧侣记忆一份礼仪手稿中的旋律，我们找到了调式分类和记忆效率之间联系的经验证据，并观察到旋律开头和结尾处有更多公式化的区域，这与调式在表演中的实际作用相符。然而，由此产生的分割本身表明，即使是这种记忆最优的分割也并非是传统理解的“centonisation”。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [296] [Causal Prompting for Implicit Sentiment Analysis with Large Language Models](https://arxiv.org/abs/2507.00389)
> *因果提示在大型语言模型隐式情感分析中的应用*

*Jing Ren, Wenhao Zhou, Bowen Li, Mujie Liu, Nguyen Linh Dan Le, Jiade Cen, Liping Chen, Ziqi Xu, Xiwei Xu, Xiaodong Li* | **Category: cs.CL**

**Keywords:** 隐式情感分析, 因果提示, 大型语言模型, 链式思考, 因果推断

**Comment:** 

> **TL;DR:** 提出CAPITAL框架，通过将因果推理（前门调整）整合到CoT推理中，解决了LLM在隐式情感分析中存在的偏见和虚假相关性问题，并在准确性和鲁棒性上优于现有方法。

**AI_Comments:** 这项工作创新性地将因果推断，特别是前门调整，引入到大型语言模型的提示工程中，以解决隐式情感分析中的偏见和虚假相关性问题。通过对因果效应的分解和估计，并结合对比学习，提高了模型推理的透明度和可靠性。其在对抗性条件下的鲁棒性提升尤其重要，表明了该方法在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于提示的大型语言模型在隐式情感分析中表现出潜力，但它们通常依赖于链式思考（CoT）推理路径的多数投票，而没有评估其因果有效性，这使得它们容易受到内部偏见和虚假相关性的影响。

**Method:** 提出CAPITAL框架，将前门调整整合到链式思考（CoT）推理中。CAPITAL将整体因果效应分解为两部分：输入提示对推理链的影响，以及推理链对最终输出的影响。这些组件通过基于编码器的聚类和NWGM近似进行估计，并使用对比学习目标来更好地对齐编码器的表示与大型语言模型的推理空间。

**Result:** 在基准隐式情感分析数据集上使用三种大型语言模型进行的实验表明，CAPITAL在准确性和鲁棒性方面始终优于强大的提示基线，尤其是在对抗性条件下。

**Conclusion:** 这项工作提供了一种将因果推断整合到大型语言模型提示中的原则性方法，并强调了其在偏见感知情感推理中的益处。

> **ai_Abstract:** 本文提出了CAPITAL框架，一个将因果推断中的“前门调整”融入到大型语言模型（LLMs）的链式思考（CoT）推理中的因果提示方法，旨在解决现有LLMs在隐式情感分析（ISA）中因未评估因果有效性而导致的偏见和虚假相关性问题。CAPITAL通过分解并估计输入提示对推理链以及推理链对最终输出的影响，并结合对比学习进行优化。实验证明，该框架在ISA任务上显著提升了LLMs的准确性和鲁棒性，尤其是在对抗性环境下。

> **摘要翻译:** 隐式情感分析（ISA）旨在推断隐含而非明确表达的情感，要求模型对细微的上下文线索进行更深层次的推理。尽管最近使用大型语言模型（LLM）的基于提示的方法在ISA中显示出前景，但它们通常依赖于链式思考（CoT）推理路径的多数投票，而没有评估其因果有效性，这使得它们容易受到内部偏见和虚假相关性的影响。为了解决这一挑战，我们提出了CAPITAL，一个将前门调整纳入CoT推理的因果提示框架。CAPITAL将整体因果效应分解为两个组成部分：输入提示对推理链的影响，以及这些链对最终输出的影响。这些组件通过基于编码器的聚类和NWGM近似进行估计，并使用对比学习目标来更好地对齐编码器的表示与LLM的推理空间。在基准ISA数据集上使用三种LLM进行的实验表明，CAPITAL在准确性和鲁棒性方面始终优于强大的提示基线，特别是在对抗性条件下。这项工作提供了一种将因果推断整合到LLM提示中的原则性方法，并强调了其在偏见感知情感推理中的益处。源代码和案例研究可在以下网址获取：https://github.com/whZ62/CAPITAL。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [304] [Beyond Sociodemographic Prompting: Using Supervision to Align LLMs with Human Response Distributions](https://arxiv.org/abs/2507.00439)
> *超越社会人口学提示：使用监督来使大型语言模型与人类响应分布对齐*

*Gauri Kambhatla, Sanjana Gautam, Angela Zhang, Alex Liu, Ravi Srinivasan, Junyi Jessy Li, Matthew Lease* | **Category: cs.CL**

**Keywords:** 大型语言模型, 人类响应分布, 监督学习, 群体对齐, 基准

**Comment:** 

> **TL;DR:** 本研究展示了通过简单的监督可以显著提高大型语言模型与不同人群响应分布的对齐程度，并提供了实践指导和基准。

**AI_Comments:** 该研究通过引入“相对简单的监督”来提升LLM与人类响应分布的对齐，具有创新性。其关注LLM在不同人口群体中的表现，超越了平均性能评估，增加了研究的深度和实用性。开源工作和提供的基准对未来研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测不同人群如何回答主观问题具有重要价值。当前大型语言模型（LLMs）可能无法很好地对齐不同人口群体的响应分布。

**Method:** 使用相对简单的监督方法来提高语言模型与不同人群的对齐。在三个涵盖不同主题的数据集上进行测量。评估了平均性能和特定群体间的对齐差异。在多种LLM和提示策略上进行评估，并开源工作。

**Result:** 相对简单的监督可以大大改善语言模型与不同人群的对齐，并在三个数据集上得到验证。对齐程度在不同特定群体间有所不同。该方法的简单性和通用性促进了其易于采用。

**Conclusion:** 简单的监督方法能有效提升大型语言模型（LLMs）与人类响应分布的对齐，且其适用性广。研究提供了实践指导和未来研究的基准。

> **ai_Abstract:** 本研究探讨了如何通过简单的监督方法提高大型语言模型（LLMs）与不同人群在主观问题响应上的对齐度。作者在三个多样化数据集上验证了该方法的有效性，并分析了其在不同群体间的表现。研究强调了该方法的实用性和通用性，并为LLMs在现实世界中的应用提供了指导，同时通过开源工作为未来研究设立了基准。

> **摘要翻译:** 准确预测不同人群如何回答主观问题具有巨大的价值。在这项工作中，我们展示了使用相对简单的监督可以极大地改善语言模型与不同人群的对齐，这是通过跨越不同主题的三个数据集进行衡量的。除了评估平均性能，我们还报告了对齐程度在特定群体间的差异。我们方法的简单性和通用性促进了其易于采用，而我们广泛的发现为何时在实践中使用或不使用我们的方法提供了有用的指导。通过对许多大型语言模型和提示策略进行评估，并开源我们的工作，我们提供了一个有用的基准来激发未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [310] [Pitfalls of Evaluating Language Models with Open Benchmarks](https://arxiv.org/abs/2507.00460)
> *评估语言模型开放基准的陷阱*

*Md. Najib Hasan, Mohammad Fakhruddin Babar, Souvika Sarkar, Monowar Hasan, Santu Karmaker* | **Category: cs.CL**

**Keywords:** 语言模型评估, 开放基准, 作弊模型, HELM, 基准陷阱

**Comment:** 

> **TL;DR:** 开放式语言模型基准可能存在陷阱，因为模型可以通过在公共测试集上微调来“作弊”并获得高排名，但实际性能很差。需要重新评估基准测试实践。

**AI_Comments:** 这篇论文通过实证方法揭示了开放式基准测试中一个重要的“数据泄露”或“过拟合测试集”问题，对当前语言模型评估的可靠性提出了质疑。其创新点在于通过构建“作弊”模型来直观地展示问题，并提出了私有/动态基准作为解决方案。这对于LM社区理解和改进评估实践具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开放的大型语言模型（LLM）基准，如HELM和BIG-bench，虽然促进了语言模型的公平比较、可复现性和迭代进展，但其开放性也引入了关键且未被充分探索的陷阱。本研究旨在揭示这些弱点。

**Method:** 本研究通过系统地构建“作弊”模型来暴露开放基准的弱点，这些模型是BART、T5和GPT-2的较小变体，直接在公共测试集上进行微调。

**Result:** 这些“作弊”模型在一个著名的开放式综合基准（HELM）上取得了高排名，尽管它们的泛化能力差且实际效用有限。研究结果强调了三个关键见解：高排行榜表现不一定反映实际效果；私有或动态基准必须补充开放评估以保障完整性；以及对当前基准测试实践进行根本性的重新评估对于确保稳健和可信的LM评估至关重要。

**Conclusion:** 开放基准上的高排行榜表现可能不总是反映真实世界的效果。私有或动态基准必须补充开放评估以保障完整性。当前基准测试实践需要进行根本性的重新评估，以确保稳健和值得信赖的语言模型评估。

> **ai_Abstract:** 这项研究揭示了开放式大型语言模型基准（如HELM）的潜在缺陷。通过构建在公共测试集上微调的“作弊”模型（BART、T5、GPT-2的变体），研究表明这些模型尽管实际性能和泛化能力有限，却能在排行榜上获得高分。研究强调开放基准的高排名不一定代表实际效果，并建议结合私有或动态基准，呼吁对现有评估方法进行重新思考以确保可靠的语言模型评估。

> **摘要翻译:** 开放的大型语言模型（LLM）基准，如HELM和BIG-bench，提供了标准化、透明的协议，促进了语言模型（LM）的公平比较、可复现性和迭代进展。然而，它们的开放性也引入了关键且未被充分探索的陷阱。本研究通过系统地构建“作弊”模型——即在公共测试集上直接微调的BART、T5和GPT-2的较小变体——来揭示这些弱点，这些模型在一个著名的开放式综合基准（HELM）上取得了高排名，尽管它们的泛化能力差且实际效用有限。我们的发现强调了三个关键见解：高排行榜表现在开放基准上可能不总是反映真实世界的有效性；私有或动态基准必须补充开放评估以保障完整性；以及对当前基准测试实践进行根本性的重新评估对于确保稳健和值得信赖的LM评估至关重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [313] [TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search](https://arxiv.org/abs/2507.00509)
> *TeamCMU 在 Touché：对话式搜索中广告集成与检测的对抗性协同演化*

*To Eun Kim, João Coelho, Gbemileke Onilude, Jai Singh* | **Category: cs.CL, cs.AI**

**Keywords:** 对话式搜索, 广告集成, 广告检测, 对抗性协同演化, RAG

**Comment:** 

> **TL;DR:** 该研究提出了一种模块化管道，用于在基于RAG的对话系统中管理广告，通过广告重写器进行无缝集成，并使用强大的广告分类器进行检测，旨在实现广告的隐蔽集成和有效检测。

**AI_Comments:** 该论文的创新点在于提出了一个对抗性协同演化框架来同时优化广告的隐蔽集成和鲁棒检测。通过使用合成数据和分类器引导的优化策略，有效解决了生成式搜索中广告透明度不足的问题，对于提升用户体验和商业价值具有重要意义。其模块化设计也提供了未来研究的灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 随着对话式搜索引擎采用基于大型语言模型（LLMs）和检索增强生成（RAG）的范式，在生成响应中集成广告带来了商业机遇，但也对用户体验构成挑战。与传统搜索中广告明确区分不同，生成系统模糊了信息内容和推广材料之间的界限，引发了对透明度和信任的担忧。

**Method:** 我们提出了一个模块化管道，用于RAG对话系统中的广告管理，包括一个用于无缝广告集成的广告重写器和一个用于检测的鲁棒广告分类器。我们利用合成数据训练高性能分类器，并将其用于指导两种互补的广告集成策略：对广告重写器进行监督微调，以及一种“N中选一”的采样方法，从多个候选响应中选择最不易被检测到的广告集成响应。

**Result:** 实验结果表明，我们基于营销策略启发的合成广告数据并通过课程学习增强训练的广告分类器，实现了鲁棒的检测性能。此外，我们证明了通过微调和“N中选一”采样进行的分类器引导优化，显著提高了广告的隐蔽性，实现了更无缝的集成。

**Conclusion:** 这些发现为开发更复杂的广告感知生成搜索系统和鲁棒的广告分类器提供了一个对抗性协同演化框架。

> **ai_Abstract:** 本研究针对基于大型语言模型和RAG的对话式搜索中广告集成带来的透明度挑战，提出了一种模块化广告管理管道。该管道包含一个用于无缝集成的广告重写器和一个用于检测的广告分类器。通过利用合成数据训练分类器，并采用分类器引导的微调和“N中选一”采样策略，实验证明其能有效检测广告并实现广告的隐蔽集成，从而为开发更智能的广告感知生成系统提供了对抗性协同演化框架。

> **摘要翻译:** 随着对话式搜索引擎越来越多地采用由大型语言模型（LLMs）和检索增强生成（RAG）驱动的生成范式，将广告整合到生成的响应中既带来了商业机会，也对用户体验构成了挑战。与传统搜索中广告清晰划分不同，生成系统模糊了信息内容和推广材料之间的界限，引发了对透明度和信任的担忧。在这项工作中，我们提出了一种模块化管道，用于基于RAG的对话系统中的广告管理，该管道由一个用于无缝广告集成的广告重写器和一个用于检测的鲁棒广告分类器组成。我们利用合成数据训练高性能分类器，然后将其用于指导两种互补的广告集成策略：对广告重写器进行监督微调，以及一种“N中选一”的采样方法，从多个候选响应中选择最不易被检测到的广告集成响应。我们的评估侧重于两个核心问题：广告分类器在检测各种广告集成策略方面的有效性，以及最能支持连贯、最小干扰广告插入的训练方法。实验结果表明，我们的广告分类器，通过营销策略启发的合成广告数据训练并结合课程学习进行增强，实现了鲁棒的检测性能。此外，我们证明了分类器引导优化，通过微调和“N中选一”采样，显著提高了广告的隐蔽性，实现了更无缝的集成。这些发现为开发更复杂的广告感知生成搜索系统和鲁棒的广告分类器贡献了一个对抗性协同演化框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [320] [NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data](https://arxiv.org/abs/2507.00534)
> *NIRANTAR: 真实世界语音数据上的新语言和领域持续学习*

*Tahir Javed, Kaushal Bhogale, Mitesh M. Khapra* | **Category: cs.CL**

**Keywords:** 持续学习, 自动语音识别, 多语言, 多领域, 真实世界数据

**Comment:** Accepted in Interspecch 2025

> **TL;DR:** Nirantar是一个用于评估多语言多领域ASR持续学习的框架，利用真实世界的增量数据，揭示现有方法不足。

**AI_Comments:** Nirantar框架通过使用真实世界、增量收集的语音数据，并在多语言和多领域场景下进行评估，显著超越了以往依赖模拟数据的持续学习研究。它引入了语言增量领域增量学习（LIDIL）这一新颖场景，为持续学习研究提供了一个更具挑战性和代表性的测试平台。该工作的重要性在于它揭示了当前持续学习方法在真实世界应用中的局限性，并为未来鲁棒持续学习策略的开发奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决现有持续学习（CL）评估工作中依赖模拟数据的问题，本研究旨在提供一个反映真实世界挑战的综合框架，以促进更鲁棒的CL策略的开发。

**Method:** 本研究提出了Nirantar框架，用于评估多语言和多领域ASR中的持续学习。该框架利用在印度22种语言和208个地区通过自然事件逐步收集的真实语音数据，并支持语言增量学习（LIL）、领域增量学习（DIL）以及新颖的语言增量领域增量学习（LIDIL）场景的评估。该工作引入了1720小时的新数据，总计3250小时的人工转录语音用于系统地基准测试CL方法，并评估了现有方法。

**Result:** 评估结果表明，没有单一的现有持续学习方法在多语言和多领域ASR的真实世界场景中表现始终良好。

**Conclusion:** 本研究得出结论，现有持续学习方法不足以应对真实世界多语言和多领域ASR的挑战，突显了开发更鲁棒和适应性强的持续学习策略的必要性。

> **ai_Abstract:** 本论文介绍了Nirantar，一个用于评估多语言和多领域自动语音识别（ASR）中持续学习（CL）的全面框架。该框架利用从印度22种语言和208个地区增量收集的真实世界语音数据，支持语言增量学习（LIL）、领域增量学习（DIL）和语言增量领域增量学习（LIDIL）场景的评估。Nirantar提供动态、非均匀的语言和领域变化，克服了以往工作中模拟数据的局限性。通过3250小时的转录语音数据，该框架可用于系统地基准测试CL方法。研究结果表明，现有CL方法在真实世界场景下表现不佳，强调了开发更稳健策略的必要性。

> **摘要翻译:** 我们将介绍Nirantar，这是一个用于评估多语言和多领域ASR中持续学习（CL）的综合框架。Nirantar旨在反映真实世界的CL挑战，它利用通过自然事件在印度22种语言和208个地区逐步收集的数据。这使得能够评估语言增量学习（LIL）、领域增量学习（DIL）以及新颖的语言增量领域增量学习（LIDIL）场景。与依赖模拟事件的先前工作不同，Nirantar呈现动态的、非均匀的语言和领域变化，使其成为CL研究的理想测试平台。凭借3250小时的人工转录语音数据，包括这项工作中新引入的1720小时，我们的框架能够系统地基准测试CL方法。我们评估了现有方法，并证明没有单一方法表现始终良好，这强调了对更强大的CL策略的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [325] [Capsule Network-Based Semantic Intent Modeling for Human-Computer Interaction](https://arxiv.org/abs/2507.00540)
> *基于胶囊网络的语义意图建模用于人机交互*

*Shixiao Wang, Yifan Zhuang, Runsheng Zhang, Zhijun Song* | **Category: cs.CL**

**Keywords:** 胶囊网络, 语义意图建模, 人机交互, 意图识别, 动态路由

**Comment:** 

> **TL;DR:** 提出一种基于胶囊网络的语义意图建模算法，用于提高人机交互中的意图识别精度，实验证明其优于现有方法。

**AI_Comments:** 本文创新性地将胶囊网络应用于人机交互的语义意图建模，利用其特有的动态路由机制和部分-整体关系捕获能力，解决了传统方法在复杂语义环境下意图识别精度不足的问题。这为自然语言理解领域的意图识别提供了一个新的、有效的结构化建模范式，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决人机交互中意图识别精度不足的问题。

**Method:** 提出一种基于胶囊网络的语义意图建模算法。该方法通过向量化胶囊结构表示输入文本的语义特征，利用动态路由机制在多层胶囊间传递信息，以捕获语义实体间的层级和部分-整体结构。模型使用卷积特征提取模块作为低级编码器，通过迭代路由过程形成高级抽象意图表示，并引入基于边际的损失函数以增强意图类别区分能力。

**Result:** 在公开的自然语言理解数据集上与多个主流模型进行对比实验，结果表明所提出的模型在准确率、F1分数和意图检测率方面优于传统方法和其他深度学习结构。研究还分析了动态路由迭代次数对模型性能的影响，并提供了损失函数在训练过程中的收敛曲线，验证了方法的稳定性和有效性。

**Conclusion:** 本研究提出了一种新的结构化建模方法，有效提高了复杂语义条件下意图识别的精度和稳定性。

> **ai_Abstract:** 本文提出一种基于胶囊网络的人机交互语义意图建模算法，旨在解决现有方法意图识别精度不足的问题。该方法利用胶囊网络的向量化表示和动态路由机制，有效捕获文本语义的层级和部分-整体结构，并通过卷积编码器和迭代路由形成高级意图表示。引入基于边际的损失函数以增强区分能力。在公开数据集上的实验结果表明，该模型在准确率、F1分数和意图检测率上均优于传统及其他深度学习模型，验证了其在复杂语义条件下意图识别的稳定性和有效性。

> **摘要翻译:** 本文提出一种基于胶囊网络的语义意图建模算法，旨在解决人机交互中意图识别精度不足的问题。该方法通过向量化胶囊结构表示输入文本中的语义特征。它使用动态路由机制在多个胶囊层之间传递信息。这有助于更有效地捕获语义实体之间的层级关系和部分-整体结构。该模型使用卷积特征提取模块作为低级编码器。在生成初始语义胶囊后，通过迭代路由过程形成高级抽象意图表示。为了进一步提高性能，在损失函数中引入了基于边际的机制。这提高了模型区分意图类别的能力。实验使用公开的自然语言理解数据集进行。使用了多个主流模型进行比较。结果表明，所提出的模型在准确率、F1分数和意图检测率方面优于传统方法和其他深度学习结构。该研究还分析了动态路由迭代次数对模型性能的影响。提供了训练期间损失函数的收敛曲线。这些结果验证了所提出方法在语义建模中的稳定性和有效性。总的来说，本研究提出了一种新的结构化建模方法，以提高复杂语义条件下的意图识别。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [333] [Methodological Rigour in Algorithm Application: An Illustration of Topic Modelling Algorithm](https://arxiv.org/abs/2507.00547)
> *算法应用中的方法学严谨性：以主题建模算法为例*

*Malmi Amadoru* | **Category: cs.CL**

**Keywords:** 方法学严谨性, 算法应用, 主题建模, 透明度, 可信度

**Comment:** 

> **TL;DR:** 本文针对计算算法应用中缺乏透明度和严谨性的问题，以主题建模为例，提出了一套确保方法学严谨性的指导方针，旨在增强研究的可信度。

**AI_Comments:** 论文解决了计算密集型研究中一个关键且日益增长的问题，即算法应用中的方法学严谨性。其创新之处在于提供了一套具体的指导方针，并以主题建模为例进行阐释，这对于提高研究的可信度和透明度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高级计算算法在研究应用中缺乏透明度和严谨性，带来了方法学挑战，并可能损害研究的信任度。

**Method:** 作者通过阐释结构化主题建模算法的应用，并提出一套具体的指导方针，来讨论如何确保主题建模研究中的方法学严谨性。

**Result:** 论文提出了一套确保主题建模研究严谨性的指导方针，这些方针虽然主要针对主题建模，但可经调整后应用于其他算法。这些指导方针特别有助于应用主题建模的初级研究人员以及处理相关手稿的编辑和审稿人。

**Conclusion:** 该论文旨在为计算密集型理论构建研究中的方法学严谨性提供实用指导，并促进相关对话，以提高算法应用的可信度和透明度。

> **ai_Abstract:** 本文旨在解决高级计算算法在研究应用中因缺乏透明度和严谨性而导致的方法学挑战和信任问题。作者以主题建模算法为例，特别是结构化主题建模，提供了一套确保研究严谨性的指导方针。这些指导方针不仅适用于主题建模，也可推广至其他算法，旨在帮助初级研究人员、编辑和审稿人，从而促进计算密集型研究中方法学严谨性的讨论。

> **摘要翻译:** 先进计算算法的兴起为计算密集型理论发展研究方法开辟了新途径。然而，这些算法的不透明性以及其应用中缺乏透明度和严谨性带来了方法学挑战，可能损害研究的信任度。这种新型研究中关于方法学严谨性的讨论仍在兴起。在此背景下，我试图就方法学严谨性提供指导，特别是在主题建模算法的背景下。通过阐释结构化主题建模算法的应用并提出一套指导方针，我讨论了如何确保主题建模研究的严谨性。尽管这些指导方针是针对主题建模算法的应用，但它们可以在根据具体情境进行调整后应用于其他算法。这些指导方针特别有助于应用主题建模的初级研究人员以及处理主题建模手稿的编辑和审稿人。我为主题建模文献做出了贡献，并加入了计算密集型理论构建研究中关于方法学严谨性的新兴对话。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [340] [TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification](https://arxiv.org/abs/2507.00579)
> *TUM-MiKaNi 在 SemEval-2025 任务 3：迈向多语言和知识感知非事实幻觉识别*

*Miriam Anschütz, Ekaterina Gikalo, Niklas Herbster, Georg Groh* | **Category: cs.CL, cs.AI**

**Keywords:** LLM 幻觉, 多语言, 事实核查, BERT, SemEval-2025

**Comment:** 6 pages, 3 figures, SemEval-2025 Task 3, ACL

> **TL;DR:** 本文介绍了 TUM-MiKaNi 团队参加 SemEval-2025 任务 3 (Mu-SHROOM) 的提交，该团队提出了一个结合维基百科检索和 BERT 模型的多语言幻觉识别系统，在多种语言中取得了有竞争力的结果。

**AI_Comments:** 该论文的创新之处在于其对多语言幻觉识别的关注，这弥补了当前研究主要集中于英语的不足。其提出的结合检索式事实核查和 BERT 模型识别模式的两阶段管道方法，在解决 LLM 幻觉问题上具有实用价值。该系统在多个语言中取得的优异成绩，证明了其有效性和对未来 LLM 应用的潜在积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型 (LLMs) 的幻觉问题严重阻碍了它们的可靠性和广泛应用。当前研究主要集中于英语数据，忽略了 LLMs 的多语言特性，因此需要一个多语言的幻觉识别方案。

**Method:** 本文提出了一个两阶段的管道系统。第一阶段是基于维基百科的检索式事实核查；第二阶段是基于 BERT 的系统，该系统经过微调以识别常见的幻觉模式。

**Result:** 该系统在所有语言中均取得了有竞争力的结果，包括英语在内的八种语言进入了前十名。此外，它支持的任务中涵盖的十四种语言之外的更多语言。

**Conclusion:** 该多语言幻觉识别器能够帮助改进 LLM 的输出，并提升其未来的实用性。

> **ai_Abstract:** TUM-MiKaNi 团队在 SemEval-2025 任务 3 (Mu-SHROOM) 中提交了一个多语言、知识感知的非事实幻觉识别系统，旨在解决 LLMs 幻觉问题中缺乏多语言研究的现状。该系统采用两阶段管道，结合维基百科事实核查与微调的 BERT 模型来识别幻觉模式。该方法在多语言环境中表现出色，在八种语言中位列前十，并支持更多语言，有助于提升 LLM 的可靠性和实用性。

> **摘要翻译:** 幻觉是大型语言模型（LLMs）的主要问题之一，阻碍了它们的可靠性和向更广泛用例的部署。然而，大多数关于幻觉的研究都集中在英语数据上，忽略了 LLMs 的多语言特性。本文描述了我们提交给 SemEval-2025 任务 3——Mu-SHROOM（多语言幻觉和相关可观察过度生成错误共享任务）的系统。我们提出了一个两阶段的管道，该管道将基于维基百科的检索式事实核查与一个基于 BERT 的系统结合起来，该系统经过微调以识别常见的幻觉模式。我们的系统在所有语言中都取得了有竞争力的结果，在包括英语在内的八种语言中进入了前十名。此外，它支持共享任务所涵盖的十四种语言之外的多种语言。这种多语言幻觉识别器有助于改进 LLM 的输出及其未来的实用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [344] [Transferable Modeling Strategies for Low-Resource LLM Tasks: A Prompt and Alignment-Based](https://arxiv.org/abs/2507.00601)
> *面向低资源LLM任务的可迁移建模策略：一种基于提示和对齐的方法*

*Shuangquan Lyu, Yingnan Deng, Guiran Liu, Zhen Qi, Ruotong Wang* | **Category: cs.CL**

**Keywords:** 低资源LLM, 知识迁移, 参数高效微调, 提示调优, 跨语言任务

**Comment:** 

> **TL;DR:** 本文提出了一个统一框架，结合知识迁移模块和参数高效微调，旨在提升大型语言模型在低资源语言场景下的迁移和适应能力，尤其在数据稀缺条件下表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个统一的框架，通过结合知识对齐损失和软提示调优，有效解决了LLM在低资源场景下的适应性问题。其方法不仅提升了性能和稳定性，还通过轻量级模块和冻结策略兼顾了计算效率和模型通用性，对于推动LLM在资源受限环境下的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型在低资源语言场景下有限的迁移和适应能力问题。

**Method:** 提出一个统一框架，结合知识迁移模块和参数高效微调策略。具体方法包括引入知识对齐损失和软提示调优，以指导模型吸收目标语言或任务结构特征。框架包含轻量级适应模块以降低计算成本，并整合冻结策略和提示注入以保留原始知识并实现快速适应。

**Result:** 与现有模型和主流迁移方法相比，在MLQA、XQuAD和PAWS-X等跨语言任务上实现了更高的性能和稳定性，尤其在数据极度稀缺条件下表现出强大优势。

**Conclusion:** 提出的方法具有强大的通用性和可扩展性，在保留大型语言模型通用能力的同时增强了任务特定适应性，非常适用于复杂的语义建模和多语言处理任务。

> **ai_Abstract:** 本文提出了一个针对低资源LLM任务的可迁移建模框架，通过结合知识迁移模块、参数高效微调、知识对齐损失和软提示调优，旨在提高模型在数据稀缺环境下的泛化性能和稳定性。该框架还包含轻量级适应模块和冻结策略，以平衡计算成本和知识保留。实验证明，该方法在跨语言任务上优于现有方法，特别是在数据极度稀缺时表现出色，具有良好的通用性和可扩展性。

> **摘要翻译:** 本文旨在解决大型语言模型在低资源语言场景下有限的迁移和适应能力问题。本文提出了一个统一的框架，该框架结合了知识迁移模块和参数高效微调策略。该方法引入了知识对齐损失和软提示调优，以指导模型在最小标注下有效吸收目标语言或任务的结构特征。这增强了泛化性能和训练稳定性。该框架包括轻量级适应模块以降低计算成本。在训练过程中，它整合了冻结策略和提示注入，以保留模型的原始知识，同时能够快速适应新任务。该研究还进行了稳定性分析实验和合成伪数据迁移实验，以系统地评估该方法在不同低资源任务中的适用性和鲁棒性。实验结果表明，与现有的多语言预训练模型和主流迁移方法相比，所提出的方法在MLQA、XQuAD和PAWS-X等跨语言任务上实现了更高的性能和稳定性。它在数据极度稀缺的条件下表现出特别强大的优势。所提出的方法具有强大的通用性和可扩展性。它在保留大型语言模型通用能力的同时增强了任务特定适应性。这使得它非常适用于复杂的语义建模和多语言处理任务。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [349] [Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies](https://arxiv.org/abs/2507.00606)
> *混合推理：教授大型语言模型使用自适应策略进行推理*

*Tao Xiong, Xavier Hu, Wenyan Fan, Shengyu Zhang* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 混合推理, 自适应策略, 提示工程, 监督微调

**Comment:** 

> **TL;DR:** 引入Mixture of Reasoning (MoR) 训练框架，使LLMs能自主、自适应地推理，无需手动提示工程，显著提升性能并提供通用解决方案。

**AI_Comments:** 这篇论文的创新点在于提出了MoR框架，通过在模型内部嵌入多样化的推理策略，实现了LLMs的自主和任务自适应推理，从而摆脱了对外部手动提示工程的依赖。这对于提高LLMs的效率和通用性具有重要意义，尤其是在应对复杂和多样化任务时。其方法论中的“思维生成”阶段利用了更强大的模型（如GPT-4o）来创建模板，这是一种有效的知识蒸馏或策略学习方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）虽通过CoT和ToT等提示技术在复杂任务中表现出色，但其对手动、任务特定提示的依赖限制了适应性和效率。

**Method:** 论文引入了Mixture of Reasoning (MoR) 训练框架，旨在将多样化的推理策略嵌入LLMs中，实现自主、任务自适应的推理，无需外部提示工程。MoR包含两个阶段：1. 思维生成：利用GPT-4o等模型创建推理链模板。2. SFT数据集构建：将模板与基准数据集配对进行监督微调。

**Result:** 实验表明MoR显著提高了性能。MoR150在使用CoT提示时达到0.730（2.2%的提升），与基线相比达到0.734（13.5%的提升）。

**Conclusion:** MoR消除了对任务特定提示的需求，为跨多样化任务的鲁棒推理提供了一个通用化解决方案。

> **ai_Abstract:** 本文提出了一种名为Mixture of Reasoning (MoR) 的训练框架，旨在解决大型语言模型对任务特定提示的依赖性问题。MoR通过思维生成和SFT数据集构建两个阶段，将多样化的推理策略嵌入LLMs，使其能够自主并自适应地进行推理。实验结果显示，MoR显著提升了模型性能，并提供了一种无需手动提示工程的通用化、鲁棒性推理解决方案。

> **摘要翻译:** 大型语言模型（LLMs）通过链式思维（CoT）和思维树（ToT）等先进提示技术在复杂任务中表现出色，但它们对手动、任务特定提示的依赖限制了适应性和效率。我们引入了混合推理（MoR），这是一个训练框架，旨在将多样化的推理策略嵌入到LLMs中，以实现自主、任务自适应的推理，无需外部提示工程。MoR包含两个阶段：思维生成，利用GPT-4o等模型创建推理链模板；以及SFT数据集构建，将模板与基准数据集配对进行监督微调。我们的实验表明，MoR显著提高了性能，MoR150在使用CoT提示时达到了0.730（2.2%的提升），与基线相比达到了0.734（13.5%的提升）。MoR消除了对任务特定提示的需求，为跨多样化任务的鲁棒推理提供了一个通用化解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [354] [SAFER: Probing Safety in Reward Models with Sparse Autoencoder](https://arxiv.org/abs/2507.00665)
> *SAFER：使用稀疏自编码器探究奖励模型中的安全性*

*Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang* | **Category: cs.CL, cs.AI**

**Keywords:** 奖励模型, 稀疏自编码器, LLM安全, 可解释性, RLHF

**Comment:** 

> **TL;DR:** SAFER是一个利用稀疏自编码器解释和改进奖励模型的新框架，能精确地提升或降低大型语言模型的安全对齐性。

**AI_Comments:** SAFER的创新之处在于将稀疏自编码器应用于奖励模型的解释性分析，从而揭示了其内部决策机制，特别是在LLM安全对齐方面。这对于理解和改进RLHF过程中的“黑箱”问题至关重要。该方法通过精确控制安全对齐性，为LLM的审计和精炼提供了实用工具，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习人类反馈（RLHF）是使大型语言模型（LLM）与人类价值观对齐的关键范式，但其核心的奖励模型在很大程度上仍然不透明，缺乏可解释性。

**Method:** 本文提出了SAFER（用于增强奖励模型的稀疏自编码器）框架。该框架利用稀疏自编码器（SAEs）揭示奖励模型激活中的人类可解释特征，从而深入了解与安全相关的决策过程。SAFER应用于面向安全的偏好数据集，并通过选择和拒绝响应之间的激活差异来量化个体特征的显著性。利用这些特征层面的信号，设计了有针对性的数据投毒和去噪策略。

**Result:** 实验表明，SAFER可以在最小化数据修改的情况下，精确地降低或增强安全对齐性，且不牺牲通用聊天性能。

**Conclusion:** 本文提出的方法有助于解释、审计和改进高风险LLM对齐任务中的奖励模型。

> **ai_Abstract:** 本研究提出了SAFER框架，利用稀疏自编码器（SAEs）深入探究强化学习人类反馈（RLHF）中奖励模型的内部机制，特别是其在大型语言模型（LLM）安全对齐方面的决策过程。SAFER通过识别奖励模型中的可解释特征，量化其对安全决策的影响，并据此开发了数据投毒和去噪策略。实验证明，SAFER能以最小的数据改动精确地操纵LLM的安全对齐性，同时保持通用性能，为奖励模型的解释、审计和优化提供了新途径。

> **摘要翻译:** 强化学习人类反馈（RLHF）是使大型语言模型（LLM）与人类价值观对齐的关键范式，但其核心的奖励模型在很大程度上仍然不透明。在这项工作中，我们提出了用于增强奖励模型的稀疏自编码器（SAFER），这是一个通过机械分析解释和改进奖励模型的新颖框架。利用稀疏自编码器（SAEs），我们揭示了奖励模型激活中人类可解释的特征，从而深入了解与安全相关的决策制定。我们将SAFER应用于面向安全的偏好数据集，并通过选择和拒绝响应之间的激活差异来量化个体特征的显著性。利用这些特征层面的信号，我们设计了有针对性的数据投毒和去噪策略。实验表明，SAFER可以在最小化数据修改的情况下，精确地降低或增强安全对齐性，且不牺牲通用聊天性能。我们的方法有助于解释、审计和改进高风险LLM对齐任务中的奖励模型。我们的代码可在https://github.com/xzy-101/SAFER-code获取。

本论文讨论了与大型语言模型安全相关的话题，可能包含突出潜在风险或不安全结果的讨论或示例。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [358] [Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English](https://arxiv.org/abs/2507.00700)
> *视觉-语言模型中的认知风格对比：日语中的整体性注意力与英语中的分析性焦点*

*Ahmed Sabir, Azinovič Gasper, Mengsay Loem, Rajesh Sharma* | **Category: cs.CL**

**Keywords:** 视觉-语言模型, 文化认知, 注意力模式, 跨文化研究, 日语, 英语

**Comment:** 

> **TL;DR:** 研究发现，受不同语言（日语与英语）训练的视觉-语言模型展现出与人类文化相关的注意力模式，日语模型偏向整体性，英语模型偏向分析性，表明文化认知会影响模型输出。

**AI_Comments:** 这篇论文的创新点在于将跨文化认知研究的发现应用于视觉-语言模型，揭示了人工智能模型在学习语言的同时，也可能无意中吸收并复制了训练数据中隐含的文化偏好和认知模式。这对于理解AI模型的“黑箱”行为及其潜在的社会文化影响具有重要意义，尤其是在开发面向全球用户的AI系统时，需要考虑文化多样性对模型性能和输出的影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有跨文化研究表明不同文化背景个体处理视觉信息的方式不同（东亚人倾向整体性，西方人倾向分析性）。本研究旨在探究主要以不同语言（日语和英语）训练的视觉-语言模型是否也展现出类似的、受文化影响的注意力模式。

**Method:** 通过对图像描述进行比较分析，研究这些模型是否反映了整体性与分析性倾向的差异。

**Result:** 研究结果表明，视觉-语言模型不仅内化了语言的结构特性，还再现了训练数据中嵌入的文化行为。

**Conclusion:** 文化认知可能会隐性地塑造模型的输出。

> **ai_Abstract:** 本研究探讨了以日语和英语训练的视觉-语言模型是否像人类一样展现出不同的文化认知风格。通过比较图像描述，研究发现这些模型不仅学习了语言结构，还复制了训练数据中蕴含的文化行为，暗示文化认知能隐性影响模型输出。

> **摘要翻译:** 跨文化感知和认知研究表明，来自不同文化背景的个体以不同的方式处理视觉信息。例如，东亚人倾向于采用整体性视角，关注上下文关系，而西方人则经常采用分析性方法，专注于单个对象及其属性。在本研究中，我们调查了主要以不同语言（特别是日语和英语）训练的视觉-语言模型（VLMs）是否表现出类似的、受文化影响的注意力模式。通过对图像描述进行比较分析，我们检查了这些模型是否反映了整体性与分析性倾向的差异。我们的研究结果表明，视觉-语言模型不仅内化了语言的结构特性，而且再现了训练数据中嵌入的文化行为，这表明文化认知可能会隐性地塑造模型的输出。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [363] [AI Analyst: Framework and Comprehensive Evaluation of Large Language Models for Financial Time Series Report Generation](https://arxiv.org/abs/2507.00718)
> *AI分析师：用于金融时间序列报告生成的大型语言模型框架与综合评估*

*Elizabeth Fons, Elena Kochkina, Rachneet Kaur, Zhen Zeng, Berowne Hlavaty, Charese Smiley, Svitlana Vyetrenko, Manuela Veloso* | **Category: cs.CL**

**Keywords:** 大型语言模型, 金融报告生成, 时间序列, 评估框架, 提示工程

**Comment:** 

> **TL;DR:** 本文提出了一个框架，用于评估大型语言模型在生成金融时间序列报告方面的能力，并通过实验证明了其有效性。

**AI_Comments:** 该论文创新性地将LLMs应用于金融报告生成，并提出了一个全面的评估框架，特别是其自动化高亮系统，为评估LLM在特定领域的事实性和推理能力提供了新的视角，对于提升LLM在专业领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLMs）从时间序列数据生成金融报告的潜力。

**Method:** 提出一个包含提示工程、模型选择和评估的框架。引入一个自动化高亮系统，将报告中的信息分为直接来自时间序列数据、来自金融推理和依赖外部知识三类，以评估模型的事实依据和推理能力。

**Result:** 实验证明LLMs能够生成连贯且信息丰富的金融报告，使用了真实的股票市场指数数据和合成时间序列数据。

**Conclusion:** 大型语言模型在从时间序列数据生成金融报告方面具有显著潜力，并且提出的评估框架能够有效衡量其事实基础和推理能力。

> **ai_Abstract:** 本文提出了一个针对大型语言模型（LLMs）生成金融时间序列报告的框架，该框架涵盖了提示工程、模型选择和评估。为评估模型的准确性和推理能力，研究引入了一个自动化高亮系统，能将报告内容分类为数据驱动、推理驱动或知识驱动。实验证明，LLMs能够基于真实和合成时间序列数据生成高质量的金融报告。

> **摘要翻译:** 本文探讨了大型语言模型（LLMs）从时间序列数据生成金融报告的潜力。我们提出了一个包含提示工程、模型选择和评估的框架。我们引入了一个自动化高亮系统，用于对生成的报告中的信息进行分类，区分直接源于时间序列数据、源于金融推理以及依赖外部知识的见解。这种方法有助于评估模型的事实依据和推理能力。我们的实验利用真实股票市场指数数据和合成时间序列数据，证明了大型语言模型生成连贯且信息丰富的金融报告的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [368] [LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing](https://arxiv.org/abs/2507.00769)
> *LitBench：一个用于可靠评估创意写作的基准和数据集*

*Daniel Fein, Sebastian Russo, Violet Xiang, Kabir Jolly, Rafael Rafailov, Nick Haber* | **Category: cs.CL, cs.AI**

**Keywords:** 创意写作评估, 大型语言模型, LitBench, 奖励模型, 人类偏好

**Comment:** 

> **TL;DR:** LitBench是一个新的基准和数据集，旨在解决大型语言模型生成创意写作评估中的挑战。它提供了一个标准化的人类偏好数据集，用于训练和评估奖励模型，这些模型在评估LLM生成的创意写作方面比现成的LLM判断器更可靠，并与人类偏好高度一致。

**AI_Comments:** LitBench的创新之处在于其构建了一个大规模、去偏、人工标注的创意写作评估数据集，填补了该领域缺乏标准化基准的空白。其提出的训练奖励模型在评估LLM生成内容方面展现出比现有零样本LLM判断器更高的可靠性和准确性，这对于推动LLM创意写作能力的发展和优化具有重要意义。该工作对于解决开放式生成任务的评估难题提供了切实可行的方案。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型（LLMs）生成的创意写作仍然具有挑战性，因为开放式叙事缺乏真实基准。现成的（OTS）语言模型被用作零样本判断器，但其在这种情境下的可靠性尚不明确。因此，需要一个鲁棒的评估方法。

**Method:** 研究者引入了LitBench，这是第一个用于创意写作验证的标准化基准和配对数据集。该数据集包含一个由2,480个去偏、人工标注的故事比较组成的测试集，以及一个包含43,827对人类偏好标签的训练语料库。利用LitBench，研究者（i）对零样本LLM判断器进行了基准测试，（ii）训练了Bradley Terry和生成式奖励模型，以及（iii）进行了一项在线人体研究，以验证奖励模型对新生成的LLM故事的排名。

**Result:** 基准测试发现Claude-3.7-Sonnet是表现最强的现成判断器，与人类偏好达到73%的一致性。在训练的奖励模型中，Bradley-Terry和生成式奖励模型都达到了78%的准确率，优于所有现成判断器。在线人体研究进一步证实，训练的奖励模型在新生成的LLM故事中与人类偏好保持一致。

**Conclusion:** 研究者发布了LitBench和训练的奖励模型，提供了一个经过验证的资源，用于可靠、自动地评估和优化创意写作系统。

> **ai_Abstract:** 本文介绍了LitBench，一个针对大型语言模型（LLM）生成创意写作评估的标准化基准和数据集。鉴于现有评估方法的不足和零样本LLM判断器的不可靠性，LitBench提供了一个大规模的人类偏好数据集，用于训练和测试奖励模型。研究结果表明，训练的Bradley Terry和生成式奖励模型在与人类偏好的一致性方面，显著优于现成的LLM判断器（准确率达到78% vs. 73%）。该工作通过发布LitBench和训练模型，为自动化和可靠的创意写作评估提供了重要的资源。

> **摘要翻译:** 评估大型语言模型（LLMs）生成的创意写作仍然具有挑战性，因为开放式叙事缺乏真实基准。在没有高性能自动化评估方法的情况下，现成的（OTS）语言模型被用作零样本判断器，但它们在这种情境下的可靠性尚不明确。为了追求创意写作的鲁棒评估，我们引入了LitBench，这是第一个用于创意写作验证的标准化基准和配对数据集，它包含一个由2,480个去偏、人工标注的故事比较组成的保留测试集，这些比较来自Reddit，以及一个包含43,827对人类偏好标签的训练语料库。使用LitBench，我们（i）对零样本LLM判断器进行了基准测试，（ii）训练了Bradley Terry和生成式奖励模型，以及（iii）进行了一项在线人体研究，以验证奖励模型对新生成的LLM故事的排名。我们的基准测试发现Claude-3.7-Sonnet是表现最强的现成判断器，与人类偏好达到73%的一致性；在训练的奖励模型中，Bradley-Terry和生成式奖励模型都达到了78%的准确率，优于所有现成判断器。一项在线人体研究进一步证实，我们的训练奖励模型在新生成的LLM故事中与人类偏好保持一致。我们发布了LitBench和奖励模型（https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461），为可靠、自动化地评估和优化创意写作系统提供了经过验证的资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [372] [A Diagrammatic Calculus for a Functional Model of Natural Language Semantics](https://arxiv.org/abs/2507.00782)
> *自然语言语义函数模型的图解演算*

*Matthieu Pierre Boyer* | **Category: cs.CL, cs.PL, J.5; D.3.1; D.3.3**

**Keywords:** 自然语言语义, 函数式编程, 图解演算, 范畴论, 类型系统

**Comment:** 15 pages, preprint before submission to CSL 2026

> **TL;DR:** 本文提出了一种基于范畴类型和效应系统的图解演算，用于建模自然语言语义的解析和效应处理，旨在提高传统指称风格的表达能力。

**AI_Comments:** 该论文的创新点在于提出了一个将函数式编程、范畴论和图解演算相结合的新颖方法来处理自然语言语义，这可能为处理语言的复杂性和语义效应提供一种更强大和直观的工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究自然语言语义的函数式编程方法，以提高传统指称风格的表达能力。

**Method:** 形式化一个基于范畴的类型和效应系统，并构建一个图解演算来建模解析和效应处理。

**Result:** 使用图解演算高效计算句子的指称。

**Conclusion:** 通过构建图解演算，该方法能够有效地建模自然语言语义的解析和效应处理，并高效计算句子指称，从而增强了表达能力。

> **ai_Abstract:** 本文提出一种函数式编程方法来处理自然语言语义，旨在增强传统指称风格的表达能力。研究人员形式化了一个基于范畴的类型和效应系统，并构建了一个图解演算来模拟解析和效应处理过程，从而高效地计算句子的指称。

> **摘要翻译:** 本文研究了一种用于自然语言语义的函数式编程方法，该方法能够增加传统指称风格的表达能力。我们将形式化一个基于范畴的类型和效应系统，并构建一个图解演算来建模解析和效应处理，并用它来高效计算句子的指称。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [376] [Generative AI and the future of scientometrics: current topics and future questions](https://arxiv.org/abs/2507.00783)
> *生成式AI与科学计量学的未来：当前议题与未来问题*

*Benedetto Lepori, Jens Peter Andersen, Karsten Donnay* | **Category: cs.CL, cs.DL**

**Keywords:** 生成式AI, 科学计量学, 文本分析, 知识生产, 研究评估

**Comment:** 

> **TL;DR:** 本文回顾了生成式AI在科学计量学中的应用，探讨其潜力与局限，并提出其可能对科学测量指标产生影响，强调未来研究需进行系统比较和深入反思。

**AI_Comments:** 这篇论文及时地探讨了生成式AI在科学计量学这一特定领域的影响，具有重要的现实意义。其创新之处在于不仅审视了GenAI的当前应用，还深入探讨了其对科学计量学基本测量方式的潜在颠覆性影响。论文强调了系统比较不同GenAI模型的必要性，并呼吁进行严谨的实证研究和理论反思，这对于指导未来该领域的研究方向和应对AI带来的挑战具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在回顾生成式人工智能（GenAI）在科学计量学中的应用，并就其对该领域的更广泛影响展开辩论。

**Method:** 本文首先介绍了GenAI的生成性和概率性本质，并探讨其模仿人类“推理”的程度。其次，作者批判性地审视了GenAI在科学计量学中应用的最新实验，包括主题标注、引文上下文分析、预测应用、学者画像和研究评估。最后，本文探讨了GenAI通过生成大量科学语言是否会从根本上影响科学测量所用的文本特征。

**Result:** 生成式AI在以语言生成为主导的任务（如标注）中显示出潜力，但在需要稳定语义、语用推理或结构化领域知识的任务中面临局限。然而，这些结果可能很快过时。

**Conclusion:** 建议始终系统地比较不同生成式AI模型在特定任务中的表现。同时，作者认为，细致的实证工作和理论反思对于理解知识生产的演变模式至关重要。

> **ai_Abstract:** 本文回顾了生成式AI在科学计量学中的应用及其潜在影响。文章首先从分布语言学角度介绍了GenAI的本质，并探讨了其模拟人类推理的能力。随后，批判性地分析了GenAI在主题标注、引文分析、预测和研究评估等科学计量学任务中的应用，指出其在语言生成任务上的优势和在需要稳定语义或领域知识任务上的局限性。文章强调，这些应用的结果可能迅速过时，因此建议系统地比较不同GenAI模型的性能。最后，文章探讨了GenAI通过生成大量科学语言对科学测量指标可能产生的根本性影响，并呼吁通过细致的实证工作和理论反思来应对知识生产模式的演变。

> **摘要翻译:** 本文旨在回顾生成式人工智能（GenAI）在科学计量学中的应用，并就其对该领域的更广泛影响展开辩论。首先，我们介绍了GenAI的生成性和概率性本质，其根植于分布语言学。我们将其与GenAI在多大程度上能够模仿人类“推理”的辩论联系起来。其次，我们利用这一区别对科学计量学中近期使用GenAI的实验进行了批判性探讨，包括主题标注、引文上下文分析、预测应用、学者画像和研究评估。GenAI在以语言生成为主导的任务（如标注）中显示出潜力，但在需要稳定语义、语用推理或结构化领域知识的任务中面临局限。然而，这些结果可能很快过时。因此，我们的建议是始终努力系统地比较不同GenAI模型在特定任务中的表现。第三，我们探讨了GenAI通过生成大量科学语言，是否会通过影响用于衡量科学的文本特征（例如作者、词汇和参考文献）而对我们的领域产生根本性影响。我们认为，细致的实证工作和理论反思对于保持解释知识生产演变模式的能力至关重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [381] [ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering](https://arxiv.org/abs/2507.00828)
> *ProxAnn：面向用途的主题模型和文档聚类评估*

*Alexander Hoyle, Lorena Calvo-Bartolomé, Jordan Boyd-Graber, Philip Resnik* | **Category: cs.CL**

**Keywords:** 主题模型评估, 文档聚类, 人工评估, LLM代理, 可扩展性

**Comment:** Accepted to ACL 2025 (Main)

> **TL;DR:** 本文提出了一种可扩展的人工评估协议（ProxAnn）及其自动化近似方法，用于主题模型和文档聚类，发现最佳LLM代理与人类标注者无异，可替代人类进行自动化评估。

**AI_Comments:** 本文的创新点在于提出了一个面向实际使用场景的可扩展评估协议ProxAnn，并成功验证了LLM作为人类标注代理的可行性。这对于解决主题模型和文档聚类评估中人工标注成本高昂和自动化指标不足的问题具有重要意义，尤其是在大规模评估场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有主题模型和文档聚类评估方法要么使用与人类偏好不符的自动化指标，要么需要专家标签但难以扩展。

**Method:** 设计了一个可扩展的人工评估协议，通过标注者（或基于LLM的代理）审查分配给某个主题或聚类的文本项，推断出该组的类别，然后将该类别应用于其他文档。使用该协议，收集了大量众包标注数据，并用这些数据验证自动化代理。

**Result:** 最佳的LLM代理在统计学上与人类标注者无法区分。

**Conclusion:** LLM代理可以作为人类标注者在自动化评估中的合理替代品。

> **ai_Abstract:** 本文针对主题模型和文档聚类评估中现有方法（自动化指标与人类偏好不符或专家标签难以扩展）的不足，提出了一种名为ProxAnn的可扩展人工评估协议及其基于LLM的自动化近似方法。该协议模拟了从业者的实际使用场景，通过众包标注验证，结果表明最佳LLM代理与人类标注者在统计学上无异，可有效替代人类进行自动化评估。

> **摘要翻译:** 主题模型和文档聚类的评估要么使用与人类偏好不符的自动化指标，要么需要难以扩展的专家标签。我们设计了一种可扩展的人工评估协议和相应的自动化近似方法，以反映从业者对模型的实际使用情况。标注者——或基于LLM的代理——审查分配给某个主题或聚类的文本项，推断出该组的类别，然后将该类别应用于其他文档。使用该协议，我们在两个数据集上收集了大量来自众包工作者对多种主题模型输出的标注。然后，我们使用这些标注来验证自动化代理，发现最佳的LLM代理在统计学上与人类标注者无法区分，因此可以作为自动化评估中的合理替代品。软件包、网页界面和数据可在 https://github.com/ahoho/proxann 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [384] [Stylometry recognizes human and LLM-generated texts in short samples](https://arxiv.org/abs/2507.00838)
> *文体学识别短样本中的人类和大型语言模型生成文本*

*Karol Przystalski, Jan K. Argasiński, Iwona Grabska-Gradzińska, Jeremi K. Ochab* | **Category: cs.CL, cs.AI, cs.LG**

**Keywords:** 文体学, LLM检测, 文本分类, 作者归属, AI生成内容

**Comment:** 

> **TL;DR:** 该研究表明文体学能够有效区分人类和大型语言模型（LLM）生成的文本，即使在短样本中也能达到高准确率。

**AI_Comments:** 该论文的创新之处在于将传统的文体学方法应用于现代挑战——区分大型语言模型生成文本。它证明了即使在短文本样本和面对日益复杂的LLM时，文体学仍然是有效的。这对于数字取证、内容真实性验证以及打击虚假信息具有重要意义。然而，该研究的结论强调了“定义明确的文本类型”（如维基百科摘要），这可能限制了其在更广泛或不同类型文本上的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探索文体学作为一种方法来区分大型语言模型（LLM）和人类生成的文本，以解决模型归属、知识产权和AI伦理使用等问题。通过应用文体学，可以识别LLM生成的文本所呈现的新兴写作模式。

**Method:** 研究方法包括：1. 构建一个基于维基百科的基准数据集，包含人类编写的术语摘要、纯LLM生成文本（GPT-3.5/4, LLaMa 2/3, Orca, Falcon）、通过多种文本摘要方法（T5, BART, Gensim, Sumy）处理的文本以及通过复述方法（Dipper, T5）处理的文本。2. 使用10句话长的文本样本。3. 采用基于树的模型（决策树和LightGBM）进行分类。4. 使用人工设计（StyloMetrix）和基于N-gram（自研管道）的文体学特征，这些特征编码了词汇、语法、句法和标点模式。

**Result:** 交叉验证结果显示，在7个类别的多分类场景中，马修斯相关系数最高达0.87；在二元分类中，准确率介于0.79至1.0之间。在维基百科和GPT-4的特定示例中，平衡数据集上的准确率高达0.98。Shapley加性解释揭示了百科全书文本类型的特征、过度使用的个体词汇，以及LLM相对于人类编写文本在语法上更高的标准化程度。

**Conclusion:** 研究结果表明，即使在日益复杂的大型语言模型背景下，至少对于定义明确的文本类型，也可能区分机器生成和人类生成的文本。

> **ai_Abstract:** 本研究探讨了利用文体学区分人类与大型语言模型（LLM）生成文本的可行性，以应对模型归属、知识产权和AI伦理等挑战。研究构建了一个基于维基百科的基准数据集，包含人类、LLM原始生成、摘要处理和复述处理的10句话长文本样本。通过决策树和LightGBM模型，结合人工设计和基于N-gram的文体学特征，实现了高分类准确率，在多分类任务中马修斯相关系数最高达0.87，在二元分类中特定情况下准确率高达0.98。研究发现，LLM生成的文本在语法标准化和特定词汇使用上与人类文本存在显著差异，证明了即使是短样本，文体学也能有效识别AI生成内容。

> **摘要翻译:** 该论文探讨了文体学作为一种方法，用于区分大型语言模型（LLM）和人类创建的文本，解决了模型归属、知识产权和AI伦理使用等问题。文体学已被广泛用于表征文本风格和归属作者身份。通过将其应用于LLM生成的文本，我们识别了它们新兴的写作模式。该论文涉及创建一个基于维基百科的基准数据集，其中包含（a）人类编写的术语摘要，（b）纯粹由LLM生成（GPT-3.5/4, LLaMa 2/3, Orca和Falcon）的文本，（c）通过多种文本摘要方法（T5, BART, Gensim和Sumy）处理的文本，以及（d）通过复述方法（Dipper, T5）处理的文本。这些10句话长的文本通过基于树的模型（决策树和LightGBM）进行分类，使用了人工设计（StyloMetrix）和基于N-gram（我们自己的管道）的文体学特征，这些特征编码了词汇、语法、句法和标点模式。交叉验证结果显示，在7个类别的多分类场景中，性能达到高达0.87的马修斯相关系数，在二元分类中准确率介于0.79和1.0之间，其中维基百科和GPT-4的特定示例在平衡数据集上准确率高达0.98。Shapley加性解释指出了百科全书文本类型的特征、过度使用的个体词汇，以及LLM相对于人类编写文本在语法上更高的标准化程度。这些结果——至关重要的是，在日益复杂的大型语言模型的背景下——表明，至少对于定义明确的文本类型，有可能区分机器生成和人类生成的文本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [389] [Mathematics Isn't Culture-Free: Probing Cultural Gaps via Entity and Scenario Perturbations](https://arxiv.org/abs/2507.00883)
> *数学并非文化无关：通过实体和场景扰动探究文化差异*

*Aditya Tomar, Nihar Ranjan Sahoo, Ashish Mittal, Rudra Murthy, Pushpak Bhattacharyya* | **Category: cs.CL**

**Keywords:** 文化差异, 大型语言模型, 数学问题, GSM8K, 推理能力

**Comment:** 

> **TL;DR:** 大型语言模型在文化适应的数学问题上表现不如以美国为中心的数据集，但推理能力有助于弥合这种差距。

**AI_Comments:** 这项研究的创新之处在于它揭示了大型语言模型在看似文化中立的数学领域中存在的文化偏见，并为此创建了宝贵的、文化适应的数据集。这对于开发面向全球用户、更公平和鲁棒的人工智能系统至关重要。它强调了在评估和训练模型时考虑文化多样性的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数学常被认为是文化中立的，但数学问题的呈现方式可能带有隐性文化背景。现有基准测试（如GSM8K）主要植根于西方规范。本研究旨在评估大型语言模型在数学问题呈现中对文化差异的鲁棒性。

**Method:** 研究团队为非洲、印度、中国、韩国和日本这五个地区创建了GSM8K测试集的文化适应变体，使用了基于提示的转换并辅以人工验证。他们评估了六个参数范围从8B到72B的大型语言模型，并采用了五种提示策略。

**Result:** 研究发现存在一个持续的性能差距：模型在原始的以美国为中心的数据集上表现最佳，而在文化适应版本上的表现相对较差。

**Conclusion:** 具有推理能力的模型对文化转变更具弹性，表明更深层次的推理有助于弥合数学任务中文化呈现的差距。

> **ai_Abstract:** 本研究探讨了数学问题呈现中的文化偏见，指出如GSM8K等现有基准测试主要以美国为中心。研究人员为非洲、印度、中国、韩国和日本这五个地区创建了GSM8K测试集的文化适应变体，并评估了六个大型语言模型。结果显示，模型在文化适应版本上的性能持续下降，但具有更强推理能力的模型表现出更好的鲁棒性，这表明推理能力可以帮助弥合数学任务中的文化呈现差距。

> **摘要翻译:** 尽管数学常被认为是文化中立的，但数学问题的呈现方式可能带有隐性文化背景。现有基准测试（如GSM8K）主要植根于西方规范，包括人名、货币和日常场景。在这项工作中，我们通过基于提示的转换并辅以人工验证，为非洲、印度、中国、韩国和日本这五个地区创建了GSM8K测试集的文化适应变体。我们评估了六个大型语言模型（LLMs），参数范围从8B到72B，采用五种提示策略，以评估它们在数学问题呈现中对文化差异的鲁棒性。我们的发现揭示了一个持续的性能差距：模型在原始的以美国为中心的数据集上表现最佳，而在文化适应版本上的表现相对较差。然而，具有推理能力的模型对这些转变更具弹性，这表明更深层次的推理有助于弥合数学任务中文化呈现的差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [390] [Scaling Laws Are Unreliable for Downstream Tasks: A Reality Check](https://arxiv.org/abs/2507.00885)
> *下游任务的缩放定律不可靠：一次现实检验*

*Nicholas Lourie, Michael Y. Hu, Kyunghyun Cho* | **Category: cs.CL, cs.LG**

**Keywords:** 缩放定律, 下游任务, 可靠性, 元分析, 预训练损失

**Comment:** 

> **TL;DR:** 本文通过对现有下游缩放定律数据的元分析，发现线性缩放定律的拟合度在大多数情况下不佳，且实验设置的微小变化即可改变缩放趋势，强调理解缩放定律成功条件的重要性。

**AI_Comments:** 本文通过对现有数据的元分析，对广泛接受的“缩放定律”在下游任务中的普适性提出了质疑，具有重要的现实意义。它指出，并非所有下游任务都严格遵循线性缩放趋势，这挑战了当前人工智能模型开发中过度依赖简单缩放假设的倾向。研究结果提醒社区，需要更深入地探索预训练与下游性能之间的复杂关系，并考虑涌现和非线性行为，这对于未来更稳健和可预测的模型设计至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 下游任务的缩放定律旨在根据小规模预训练损失预测大规模任务性能，但其可行性存在争议，一些研究表明存在线性趋势，而另一些则指出存在涌现和逆向缩放等挑战。因此，需要对现有数据进行深入分析以澄清其可靠性。

**Method:** 本文对现有关于下游缩放定律的数据进行了元分析。

**Result:** 研究发现，线性缩放定律的紧密拟合仅在少数情况下（39%）发生。此外，实验设置中看似良性的变化可能完全改变缩放趋势。

**Conclusion:** 本文强调需要理解缩放定律成功的条件，并指出为了充分模拟预训练损失和下游任务性能之间的关系，必须接受缩放行为偏离线性趋势的情况。

> **ai_Abstract:** 本研究对现有下游缩放定律数据进行了元分析，旨在评估其预测大规模任务性能的可靠性。结果显示，线性缩放定律的紧密拟合仅在少数情况下（39%）出现，且实验设置的微小改变即可显著影响缩放趋势。这表明下游任务的缩放定律并非普遍可靠，强调了理解其成功条件以及接受非线性缩放行为的重要性。

> **摘要翻译:** 下游缩放定律旨在根据小规模预训练损失预测大规模任务性能。这种预测是否可能尚不明确：一些研究表明任务性能在转换下遵循清晰的线性缩放趋势，而另一些则指出下游缩放定律面临根本性挑战，例如涌现和逆向缩放。在这项工作中，我们对现有关于下游缩放定律的数据进行了元分析，发现线性缩放定律的紧密拟合仅在少数情况下发生：39%的时间。此外，实验设置中看似良性的变化可能完全改变缩放趋势。我们的分析强调需要理解缩放定律成功的条件。为了充分模拟预训练损失和下游任务性能之间的关系，我们必须接受缩放行为偏离线性趋势的情况。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [392] [MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes](https://arxiv.org/abs/2507.00891)
> *MemeCMD：一个自动生成的中文多轮对话数据集，包含上下文检索的表情包*

*Yuheng Wang, Xianhe Tang, Pufeng Huang* | **Category: cs.CL, cs.AI**

**Keywords:** 多模态对话, 表情包, 数据集, 自动生成, 中文

**Comment:** 

> **TL;DR:** MemeCMD是一个自动生成的中文多轮对话数据集，通过双代理和上下文检索的表情包，解决了现有对话数据集缺乏多模态表达的问题。

**AI_Comments:** MemeCMD的创新之处在于其自动生成多模态对话数据集的方法，特别是在表情包的整合方面。通过结合MLLM标注和双代理对话生成，并引入上下文检索机制，该工作为多模态对话研究提供了一个宝贵且可扩展的资源。其隐私保护特性也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对话数据集主要局限于手动标注或纯文本对话，缺乏多模态交互所提供的表达能力和上下文细微差别。表情包在在线社交互动中被广泛使用，提供生动、直观且通常幽默的表达意图和情感的方式，因此需要一个包含表情包的多模态对话数据集。

**Method:** 我们引入了MemeCMD，一个自动生成的中文多轮对话数据集，包含上下文检索的表情包。该数据集结合了一个大规模的、由MLLM标注的表情包库和由双代理在不同场景下自动生成的对话。我们引入了一个检索框架和自适应阈值，以确保表情包的使用与上下文相关且间隔自然。

**Result:** 实验证明了我们方法在生成上下文合适且多样化的包含表情包的对话方面的有效性。

**Conclusion:** MemeCMD提供了一个可扩展且隐私保护的资源，用于推进多模态会话AI，解决了现有对话数据集缺乏多模态表达和上下文细微差别的问题。

> **ai_Abstract:** 本文介绍了MemeCMD，一个自动生成的中文多轮对话数据集，旨在解决现有对话数据集缺乏多模态表达的问题。该数据集通过结合大规模MLLM标注的表情包库和双代理自动生成的对话来构建，并引入了检索框架和自适应阈值以确保表情包的上下文相关性和自然间隔。实验结果表明，该方法能够有效生成包含上下文恰当且多样化表情包的对话，为多模态会话AI的发展提供了可扩展且隐私保护的资源。

> **摘要翻译:** 表情包在在线社交互动中被广泛使用，提供生动、直观且通常幽默的方式来表达意图和情感。现有对话数据集主要局限于手动标注或纯文本对话，缺乏多模态交互所提供的表达能力和上下文细微差别。为了解决这些挑战，我们引入了MemeCMD，一个自动生成的中文多轮对话数据集，包含上下文检索的表情包。我们的数据集结合了一个大规模的、由MLLM标注的表情包库和由双代理在不同场景下自动生成的对话。我们引入了一个检索框架和自适应阈值，以确保表情包的使用与上下文相关且间隔自然。实验证明了我们方法在生成上下文合适且多样化的包含表情包的对话方面的有效性，为推进多模态会话AI提供了可扩展且隐私保护的资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [395] [The Cognate Data Bottleneck in Language Phylogenetics](https://arxiv.org/abs/2507.00911)
> *语言系统发育学中的同源数据瓶颈*

*Luise Häuser, Alexandros Stamatakis* | **Category: cs.CL, q-bio.PE**

**Keywords:** 同源数据, 语言系统发育学, 数据瓶颈, 计算语言学, BabelNet

**Comment:** 

> **TL;DR:** 计算系统发育方法在语言学中需要大量同源数据，但目前缺乏可行的自动生成方法。从BabelNet提取的数据导致的结果与已知事实不符，表明现有资源难以解决数据瓶颈。

**AI_Comments:** 该论文清晰地指出了计算语言学，特别是语言系统发育学中一个关键的数据限制问题。它的创新之处在于不仅提出问题，还通过实验验证了现有自动化方法的局限性，并对未来前景进行了悲观但现实的评估。这对于该领域的研究者而言具有重要警示作用，促使他们重新思考数据收集策略或寻找新的方法来克服这一瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 为了充分利用计算系统发育方法处理同源数据，需要复杂的模型和机器学习技术，而这些都需要比现有手动收集数据量大得多的数据集。目前尚无可行的方法自动生成更大的同源数据集，这成为了一个瓶颈。

**Method:** 作者通过从大型多语言百科词典BabelNet中自动提取数据集来验证其主张。然后，他们在相应的特征矩阵上进行系统发育推断，并与已建立的黄金标准真实树进行比较。

**Result:** 从BabelNet中提取的数据集在系统发育推断中产生的树与已建立的黄金标准真实树大体不一致。作者还讨论了为什么从其他多语言资源中提取更合适的特征矩阵也不太可能。

**Conclusion:** 需要更大数据集的系统发育数据分析方法无法应用于同源数据。因此，这些计算方法如何以及是否能应用于历史语言学仍然是一个悬而未决的问题。

> **ai_Abstract:** 该论文指出，计算系统发育方法在处理语言同源数据时面临“数据瓶颈”，因为复杂的模型和机器学习技术需要比现有手动收集数据量大得多的数据集，但目前缺乏自动生成大规模同源数据的方法。作者通过尝试从BabelNet中自动提取数据并进行系统发育推断，发现生成的结果与已知事实不符，并认为其他多语言资源也难以解决此问题。因此，需要大规模数据的计算方法目前无法应用于同源数据，这使得它们在历史语言学中的应用前景不明。

> **摘要翻译:** 为了充分利用计算系统发育方法处理同源数据的潜力，需要利用特定的（复杂）模型和基于机器学习的技术。然而，这两种方法都需要比目前可用的手动收集的同源数据大得多的数据集。据我们所知，目前尚不存在自动生成更大同源数据的可行方法。我们通过从大型多语言百科词典BabelNet中自动提取数据集来证实这一主张。我们证明，在相应特征矩阵上进行的系统发育推断所产生的树与已建立的黄金标准真实树大体不一致。我们还讨论了为什么我们认为从其他多语言资源中提取更合适的特征矩阵也不太可能。因此，需要更大数据集的系统发育数据分析方法无法应用于同源数据。因此，这些计算方法如何以及是否能应用于历史语言学仍然是一个悬而未决的问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [398] [Discourse Heuristics For Paradoxically Moral Self-Correction](https://arxiv.org/abs/2507.00985)
> *语篇启发式在自相矛盾的道德自我修正中的应用*

*Guangliang Liu, Zimo Qi, Xitong Zhang, Kristen Marie Johnson* | **Category: cs.CL**

**Keywords:** 道德自我修正, 大型语言模型, 语篇启发式, 悖论, 自我诊断

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型道德自我修正中的两个主要悖论，发现其依赖于启发式捷径，导致修正与诊断能力联合提升时的不一致性，并提出了基于启发式数据集的解决方案。

**AI_Comments:** 本文深入分析了LLM道德自我修正的深层机制，揭示了其依赖于语篇启发式而非深层理解的本质，具有重要的理论意义。其发现的悖论指出了当前自我修正方法的局限性，并提出了基于精选数据集启发式的新方向，对未来LLM的道德对齐研究具有指导价值。然而，文中未详细说明所提出的“解决方案”的具体实现细节，可能需要进一步的研究来验证其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的道德自我修正存在两个主要悖论：一是其修正能力停留在表面，二是LLMs虽能诊断不道德内容却难以识别其原因。为理解并解决这些悖论，本文展开研究。

**Method:** 作者分析了旨在增强道德自我修正的微调语料库中的语篇结构，以揭示有效结构背后的启发式方法。

**Result:** 研究表明，道德自我修正依赖于反映启发式捷径的语篇结构，并且这些启发式捷径的存在导致在同时增强自我修正和自我诊断能力时出现不一致性。

**Conclusion:** 基于研究发现，本文提出通过利用精选数据集的启发式方法来改进道德自我修正的解决方案，并强调了这种能力在从情境上下文学习和模型规模方面的泛化挑战。

> **ai_Abstract:** 本文探讨了大型语言模型道德自我修正中的固有悖论，即其修正的肤浅性以及诊断原因的困难。通过分析微调语料库的语篇结构，研究发现道德自我修正依赖于启发式捷径，这导致在同时提升自我修正和自我诊断能力时出现不一致。基于这些发现，论文提出了一种利用精选数据集启发式的方法来改进道德自我修正，并讨论了该能力在泛化方面的挑战。

> **摘要翻译:** 道德自我修正已成为使大型语言模型（LLMs）的输出与人类道德价值观保持一致的一种有前景的方法。然而，道德自我修正技术受到两个主要悖论的影响。首先，尽管有经验和理论证据支持自我修正的有效性，但这种LLM能力仅在表面层面运作。其次，虽然LLMs具有自我诊断其输出中不道德方面的能力，但在自我修正过程中，它们难以识别这种道德不一致的原因。为了更好地理解和解决这些悖论，我们分析了旨在增强道德自我修正的微调语料库中的语篇结构，揭示了有效结构背后启发式的存在。我们证明道德自我修正依赖于反映启发式捷径的语篇结构，并且这些启发式捷径的存在导致在试图同时增强自我修正和自我诊断能力时出现不一致。基于我们的发现，我们提出了一种通过利用精选数据集的启发式方法来改进道德自我修正的解决方案。我们还强调了这种能力的泛化挑战，特别是在从情境上下文学习和模型规模方面。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [400] [Should We Still Pretrain Encoders with Masked Language Modeling?](https://arxiv.org/abs/2507.00994)
> *我们是否仍应使用掩码语言建模预训练编码器？*

*Hippolyte Gisserot-Boukhlef, Nicolas Boizard, Manuel Faysse, Duarte M. Alves, Emmanuel Malherbe, André F. T. Martins, Céline Hudelot, Pierre Colombo* | **Category: cs.CL**

**Keywords:** 掩码语言建模, 因果语言建模, 编码器预训练, 两阶段训练, 文本表示

**Comment:** 23 pages, 10 figures, 17 tables

> **TL;DR:** 研究发现，虽然MLM在文本表示任务中通常表现更好，但CLM模型数据效率更高且微调稳定。本文提出了一种两阶段训练策略（先CLM后MLM），在固定计算预算下实现最佳性能，并可利用现有预训练CLM模型降低训练成本。

**AI_Comments:** 这项研究通过严格的实验控制和大规模的模型训练，系统地比较了MLM和CLM两种预训练范式，解决了NLP领域一个关键的实际问题。其创新点在于提出了两阶段训练策略，并证明了其在计算效率和性能上的优势，特别是利用现有LLM生态系统的潜力，为未来高效训练高性能编码器指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管编码器预训练传统上依赖掩码语言建模（MLM），但最近的证据表明，使用因果语言建模（CLM）预训练的解码器模型可以有效地重新用作编码器，并且通常在文本表示基准上超越传统编码器。然而，目前尚不清楚这些收益是否反映了CLM目标的固有优势，还是源于模型和数据规模等混杂因素。

**Method:** 通过一系列大规模、精心控制的预训练消融实验，训练了总共30个模型，参数范围从2.1亿到10亿，并进行了超过15,000次微调和评估运行。

**Result:** 发现使用MLM训练通常在文本表示任务中表现更好；CLM训练的模型数据效率更高，并表现出更好的微调稳定性。实验表明，一种依次应用CLM和MLM的两阶段训练策略，在固定的计算训练预算下实现了最佳性能。此外，该策略在从现有预训练CLM模型初始化时更具吸引力，减少了训练一流编码器模型所需的计算负担。

**Conclusion:** MLM在文本表示任务中通常表现更优，而CLM模型在数据效率和微调稳定性上具有优势。结合两者的两阶段训练策略（CLM后接MLM）在固定计算预算下表现最佳，尤其是在利用现有CLM模型时能有效降低计算成本。

> **ai_Abstract:** 本文通过大规模受控实验，比较了掩码语言建模（MLM）和因果语言建模（CLM）在编码器预训练中的效果。研究发现MLM在文本表示任务中表现通常更好，而CLM模型在数据效率和微调稳定性方面有优势。作者提出了一种两阶段训练策略（先CLM后MLM），该策略在固定计算预算下能达到最佳性能，并且可以通过利用现有预训练CLM模型来降低计算成本，为训练高性能编码器提供了新途径。

> **摘要翻译:** 学习高质量的文本表示是广泛NLP任务的基础。虽然编码器预训练传统上依赖掩码语言建模（MLM），但最近的证据表明，使用因果语言建模（CLM）预训练的解码器模型可以有效地重新用作编码器，并且通常在文本表示基准上超越传统编码器。然而，目前尚不清楚这些收益是否反映了CLM目标的固有优势，还是源于模型和数据规模等混杂因素。在本文中，我们通过一系列大规模、精心控制的预训练消融实验来解决这个问题，共训练了30个模型，参数范围从2.1亿到10亿，并进行了超过15,000次微调和评估运行。我们发现，虽然使用MLM训练通常在文本表示任务中表现更好，但CLM训练的模型数据效率更高，并表现出更好的微调稳定性。基于这些发现，我们通过实验表明，一种依次应用CLM和MLM的两阶段训练策略，在固定的计算训练预算下实现了最佳性能。此外，我们证明了当从现有LLM生态系统中现成的预训练CLM模型初始化时，该策略变得更具吸引力，从而减少了训练一流编码器模型所需的计算负担。我们将在https://hf.co/MLMvsCLM发布所有项目成果，以促进进一步研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [402] [La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America](https://arxiv.org/abs/2507.00999)
> *La Leaderboard：一个面向西班牙语变体以及西班牙和拉丁美洲语言的大型语言模型排行榜*

*María Grandury, Javier Aula-Blasco, Júlia Falcão, Clémentine Fourrier, Miguel González, Gonzalo Martínez, Gonzalo Santamaría, Rodrigo Agerri, Nuria Aldama, Luis Chiruzzo, Javier Conde, Helena Gómez, Marta Guerrero, Guido Ivetta, Natalia López, Flor Miriam Plaza-del-Arco, María Teresa Martín-Valdivia, Helena Montoro, Carmen Muñoz, Pedro Reviriego, Leire Rosado, Alejandro Vaca, María Estrella Vallecillo-Rodríguez, Jorge Vallego, Irune Zubiaga* | **Category: cs.CL**

**Keywords:** 大型语言模型, 排行榜, 西班牙语, 语言多样性, 开源评估

**Comment:** Accepted at ACL 2025 Main

> **TL;DR:** La Leaderboard是首个开源排行榜，用于评估针对西班牙语社区的生成式大型语言模型，涵盖西班牙和拉丁美洲的多种语言及方言，旨在建立评估标准并促进社区驱动的开发。

**AI_Comments:** La Leaderboard的创新之处在于它是首个专注于西班牙语系多语言和方言的开源大型语言模型排行榜，填补了现有评估体系的空白。其社区驱动的模式有助于促进更广泛的参与和标准的建立。此外，该项目强调减少小样本示例以降低环境影响和提高结果可复现性，体现了对可持续研究实践的关注，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了激励开发能够代表西班牙语社区语言和文化多样性的大型语言模型（LLMs）。

**Method:** 研究者提出了La Leaderboard，这是第一个开源排行榜，用于评估西班牙和拉丁美洲语言及方言中的生成式大型语言模型。该初始版本结合了巴斯克语、加泰罗尼亚语、加利西亚语和不同西班牙语变体的66个数据集，展示了50个模型的评估结果。他们还解释了其方法论，包括选择最合适的下游任务评估设置，并提供了使用较少小样本示例的理由，以减少环境影响并促进可复现结果的获取。

**Result:** La Leaderboard展示了50个大型语言模型在巴斯克语、加泰罗尼亚语、加利西亚语以及不同西班牙语变体的66个数据集上的评估结果。

**Conclusion:** La Leaderboard旨在为所有对开发西班牙语社区大型语言模型感兴趣的人建立一个评估标准。该项目鼓励其他语言排行榜的社区驱动开发，并通过减少小样本示例来降低环境影响并提高结果的可复现性。

> **ai_Abstract:** 本文介绍了La Leaderboard，这是首个针对西班牙语社区大型语言模型（LLMs）的开源评估排行榜。它旨在解决LLMs在西班牙和拉丁美洲多样化语言及方言上的表现评估问题，通过整合66个数据集并展示50个模型的评估结果。该项目是一个社区驱动的倡议，旨在建立一个通用评估标准，并提倡一种更环保、更易于复现的评估方法，通过使用更少的小样本示例来降低环境影响。

> **摘要翻译:** 排行榜展示了大型语言模型（LLMs）的当前能力和局限性。为了激励开发能够代表西班牙语社区语言和文化多样性的大型语言模型，我们推出了La Leaderboard，这是第一个开源排行榜，用于评估西班牙和拉丁美洲语言和语言变体中的生成式大型语言模型。La Leaderboard是一个社区驱动的项目，旨在为所有对开发西班牙语社区大型语言模型感兴趣的人建立一个评估标准。该初始版本结合了巴斯克语、加泰罗尼亚语、加利西亚语和不同西班牙语变体的66个数据集，展示了50个模型的评估结果。为了鼓励其他语言排行榜的社区驱动开发，我们解释了我们的方法论，包括为每个下游任务选择最合适的评估设置的指导。特别是，我们提供了使用比文献中通常发现的更少小样本示例的理由，旨在减少环境影响并促进更广泛研究社区对可复现结果的获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [404] [SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks](https://arxiv.org/abs/2507.01001)
> *SciArena：一个用于科学文献任务中基础模型的开放评估平台*

*Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan* | **Category: cs.CL, cs.AI**

**Keywords:** 科学文献, 基础模型, 评估平台, 社区投票, 自动化评估

**Comment:** 

> **TL;DR:** SciArena是一个开放的社区驱动平台，用于评估科学文献任务中的基础模型，通过社区投票收集了大量数据，并发布了用于自动化评估的基准测试。

**AI_Comments:** SciArena的创新之处在于其社区驱动的评估模式，借鉴了Chatbot Arena的成功经验，解决了传统基准测试在开放式科学文献任务评估上的局限性。它通过汇集研究人员的专业知识，为基础模型在复杂科学任务中的表现提供了更真实、更细致的评估。此外，发布SciArena-Eval基准对于推动更可靠的自动化评估系统发展具有重要意义，尽管它也揭示了现有自动化评估的挑战，指出了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统基准测试在科学文献理解和综合方面存在局限，需要一个能直接让研究社区参与、通过集体智慧评估开放式科学任务中模型性能的平台。

**Method:** SciArena是一个开放协作平台，采用Chatbot Arena的社区投票评估方法，让研究人员对模型进行比较和投票。它支持23个开源和专有基础模型，并收集了超过13,000张投票。此外，还发布了基于收集偏好数据的SciArena-Eval元评估基准，用于衡量模型判断答案质量的准确性。

**Result:** 平台已收集超过13,000张投票；提交的问题多样，符合实际文献需求；参与研究人员在评估中表现出强烈的自洽性和评估者间一致性；模型排名排行榜提供了结果和见解；SciArena-Eval基准测试突出了自动化评估的挑战，并强调了需要更可靠的自动化评估方法。

**Conclusion:** SciArena通过社区驱动的评估成功为科学文献任务中的基础模型提供了宝贵的评估数据和见解，并揭示了自动化评估的现有挑战和未来发展方向。

> **ai_Abstract:** SciArena是一个创新的开放式社区平台，旨在通过研究人员的集体投票来评估基础模型在科学文献任务中的表现，尤其侧重于需要长篇、文献支持回复的开放式问题。该平台已收集大量高质量评估数据，并在此基础上发布了SciArena-Eval元评估基准，以推动自动化评估方法的研究，同时揭示了当前自动化评估的挑战。

> **摘要翻译:** 我们提出了SciArena，一个用于评估科学文献任务中基础模型的开放协作平台。与传统的科学文献理解和综合基准不同，SciArena直接让研究社区参与，遵循Chatbot Arena的评估方法，即社区对模型比较进行投票。通过利用集体智慧，SciArena为需要以文献为基础的长篇回复的开放式科学任务提供了社区驱动的模型性能评估。该平台目前支持23个开源和专有基础模型，并已从不同科学领域的受信任研究人员那里收集了超过13,000张投票。我们分析了迄今为止收集的数据，并确认提交的问题是多样化的，符合现实世界的文献需求，并且参与的研究人员在评估中表现出强大的自洽性和评估者间一致性。我们根据模型排名排行榜讨论了结果和见解。为了进一步促进构建基于模型的文献任务自动化评估系统的研究，我们发布了SciArena-Eval，这是一个基于我们收集的偏好数据的元评估基准。该基准通过比较模型的成对评估与人类投票来衡量模型在判断答案质量方面的准确性。我们的实验突出了该基准的挑战，并强调了需要更可靠的自动化评估方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [39] [A Simple Algorithm for Trimmed Multipoint Evaluation](https://arxiv.org/abs/2507.00196)
> *修剪多点求值的简单算法*

*Nick Fischer, Melvin Kallmayer, Leo Wennmann* | **Category: cs.DS**

**Keywords:** 修剪多点求值, 递归算法, 计算机代数, 多项式求值, 简单算法

**Comment:** To appear at ESA 25

> **TL;DR:** 本文提出了一种简单易懂的递归算法，用于解决修剪多点求值问题，避免了复杂的计算机代数工具。

**AI_Comments:** 这篇论文的创新点在于提供了一种更简洁、更易于理解的算法来解决一个已知问题，降低了该领域研究的门槛。其重要性在于，作为关键子程序，更简单的实现有助于其在实际应用和未来算法中的推广。

<details>
  <summary>Details</summary>

**Motivation:** 修剪多点求值是计算机代数中的一个基本任务，并且是近期算法研究中的关键子程序。尽管已有解决方案，但其算法复杂且难以理解。

**Method:** 提出了一种简单的递归算法。

**Result:** 该算法避免了繁重的计算机代数工具，并且易于非专业背景的研究人员理解。

**Conclusion:** 本文成功提供了一种更简单、更易于理解的修剪多点求值算法，为该领域的进一步研究和应用提供了便利。

> **ai_Abstract:** 本文针对计算机代数中关键的修剪多点求值问题，提出了一种简单且易于理解的递归算法。该算法旨在替代现有复杂方法，使非专业背景的研究人员也能轻松掌握，并避免了对复杂计算机代数工具的依赖。

> **摘要翻译:** 在计算机代数中，对一组点进行多项式求值是一项基本任务。在这项工作中，我们重新审视了一种特殊的变体，称为修剪多点求值：给定一个具有有界个体度 $d$ 和总度 $D$ 的 $n$ 变量多项式，目标是在一类自然的输入点上对其进行求值。这个问题在最近的算法结果 [Dinur; SODA '21], [Dell, Haak, Kallmayer, Wennmann; SODA '25] 中作为关键子程序出现。已知修剪多点求值可以通过一种巧妙但有些复杂的算法在近线性时间内解决 [van der Hoeven, Schost; AAECC '13]。我们提出了一种简单的递归算法，它避免了繁重的计算机代数工具，并且可以被没有专业背景的研究人员轻易理解。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [58] [Lazy B-Trees](https://arxiv.org/abs/2507.00277)
> *惰性B树*

*Casper Moldrup Rysgaard, Sebastian Wild* | **Category: cs.DS, cs.DB**

**Keywords:** 惰性B树, 外部存储器, 惰性搜索树, 优先队列, 数据结构

**Comment:** MFCS 2025

> **TL;DR:** 本文设计了一种适用于外部存储器的惰性B树，它将B树在I/O操作上的加速扩展到平滑插值机制，并能作为高效的外部存储器优先队列。

**AI_Comments:** 这篇论文的创新点在于将惰性搜索树的概念扩展到外部存储器环境，通过设计惰性B树解决了外部存储器中数据结构性能优化的挑战。其克服了关键的技术难题，即缺乏外部偏置搜索树，并通过构建一个性能保证子集来实现。此外，其作为外部存储器优先队列的性能优势，特别是在decrease-key和insert操作上的提升，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的惰性搜索树在内部存储器中表现良好，但缺乏适用于外部存储器的变体，特别是其依赖的偏置搜索树的外部存储器版本不完善。因此，需要设计一种能够将惰性搜索树的优点扩展到外部存储器环境的数据结构。

**Method:** 作者设计了惰性B树，这是惰性搜索树的一种变体，专门针对外部存储器进行了优化。他们克服了缺乏外部偏置搜索树的挑战，构建了一个能够实现外部存储器惰性搜索树性能保证的子集。

**Result:** 惰性B树成功地将B树相对于二叉搜索树在I/O操作上的加速推广到相同的平滑插值机制。作为一个特例，惰性B树可以用作外部存储器优先队列，与一些定制的堆具有竞争力，并且在decrease-key和insert操作方面比已知的数据结构更快。

**Conclusion:** 惰性B树是一种高效的外部存储数据结构，它扩展了惰性搜索树的优势，解决了外部存储器环境下的特定技术难题，并在作为外部存储器优先队列时表现出卓越的性能。

> **ai_Abstract:** 本文介绍了惰性B树，一种为外部存储器设计的惰性搜索树变体。它将B树相对于二叉搜索树在I/O操作上的加速扩展到平滑插值机制，并克服了外部偏置搜索树的缺失问题。惰性B树可用作高效的外部存储器优先队列，在某些操作上优于现有数据结构。

> **摘要翻译:** 惰性搜索树（Sandlund & Wild FOCS 2020, Sandlund & Zhang SODA 2022）是一种排序字典，其更新和查询性能在高效优先队列和二叉搜索树之间平滑插值——自动实现，根据实际使用情况；无需对数据结构进行调整即可实现成本节约。在本文中，我们设计了惰性B树，它是惰性搜索树的一种变体，适用于外部存储器，将B树相对于二叉搜索树在输入/输出操作方面的加速推广到相同的平滑插值机制。
一个需要克服的关键技术难题是缺乏（完全令人满意的）偏置搜索树的外部变体，而惰性搜索树严重依赖于此。我们提供了一种性能保证子集的构造，足以实现外部存储器惰性搜索树，我们认为这本身就具有独立的意义。
作为一个特例，惰性B树可以用作外部存储器优先队列，在这种情况下，它们与一些定制的堆具有竞争力；事实上，它们比已知的数据结构提供更快的decrease-key和insert操作。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [78] [On the (In)Approximability of the Monitoring Edge Geodetic Set Problem](https://arxiv.org/abs/2507.00708)
> *关于监测边测地集问题的（不可）近似性*

*Davide Bilò, Giodano Colli, Luca Forlizzi, Stefano Leucci* | **Category: cs.DS, cs.CC**

**Keywords:** 监测边测地集, 不可近似性, NP-硬度, 近似算法, 图论

**Comment:** arXiv admin note: text overlap with arXiv:2405.13875

> **TL;DR:** 研究监测边测地集（MEGSET）问题的计算复杂性，证明了其对数级不可近似性，并为特定图类设计了改进的近似算法。

**AI_Comments:** 这项工作的主要创新在于首次建立了监测边测地集问题的非常数不可近似性界限，这对于理解该问题的固有计算难度至关重要。同时，为特定图类设计了有效的近似算法，弥补了通用算法的不足，显示了对问题结构利用的深度。然而，平面图上的NP-硬度问题仍然悬而未决，这为未来的研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 该论文研究了最小“监测边测地集”（MEGSET）问题，旨在找到图G中最小的顶点子集M，使得G的每条边至少被M中一对顶点所监测（即所有连接这对顶点的最短路径都经过该边）。

**Method:** 该研究通过理论证明来建立MEGSET问题的不可近似性下界，并加强了其在特定图类上的NP-硬度。同时，设计了一种算法，该算法能够为具有可有效计算的真正亚线性大小平衡分离器的遗传图类计算出良好的近似解。

**Result:** 证明了最小MEGSET问题的所有多项式时间近似算法必须具有$\Omega(\log n)$的近似比，除非P=NP，这是该问题已知的第一个非常数不可近似性结果。将该问题在2-顶点图上的NP-硬度加强到1-顶点图。为具有可有效计算的真正亚线性大小平衡分离器的遗传图类设计了近似算法，在平面图、有界亏格图和$k=O(n^{\frac{1}{4}})$的$k$-顶点图上，实现了$O(n^{\frac{1}{4}} \sqrt{\log n})$的近似比。在有界树宽图上，对于任意常数$\varepsilon > 0$获得了$O(\log^{3/2} n)$的近似比。这些结果优于通过简单地归约到集合覆盖问题在一般图上获得的最佳已知近似算法$O(\sqrt{n \log n})$。

**Conclusion:** 该论文证明了最小监测边测地集问题在多项式时间内存在$\Omega(\log n)$的不可近似性界限，并将其NP-硬度扩展到1-顶点图。同时，为具有特定结构（如平衡分离器）的图类设计了更有效的近似算法，显著改善了在这些图类上的近似比，但平面图上的NP-硬度仍是开放问题。

> **ai_Abstract:** 本论文深入探讨了最小监测边测地集（MEGSET）问题的计算复杂性和近似性。研究首次证明了该问题存在$\Omega(\log n)$的不可近似性下界，除非P=NP，并将其NP-硬度从2-顶点图扩展到1-顶点图。此外，论文为一系列具有良好结构（如平衡分离器）的图类（包括平面图、有界亏格图和有界树宽图）设计了高效的近似算法，取得了优于一般图算法的近似比，为MEGSET问题的理论研究和实际应用提供了重要进展。

> **摘要翻译:** 我们研究了[Foucaud et al., CALDAM'23]中引入的最小“监测边测地集”（\megset）问题：给定一个图$G$，如果顶点对$u,v$之间的“所有”最短路径都经过边$e$，则称边$e$被$u,v$监测；问题的目标是找到$G$的顶点子集$M$，使得$G$的每条边至少被$M$中的一对顶点监测，并且$|M|$最小化。
在本文中，我们证明了最小\megset问题的所有多项式时间近似算法的近似比必须为$\Omega(\log n)$，除非\p = \np。据我们所知，这是该问题已知的第一个非常数不可近似性结果。我们还通过证明相同的结果适用于1-顶点图，加强了该问题在2-顶点图上的已知\np-硬度。这留下了确定该问题在平面（即0-顶点）图上是否仍然是\np-硬度的问题。
积极的一面是，我们设计了一种算法，该算法能够为允许有效计算真正亚线性大小平衡分离器的遗传图类计算出良好的近似解。这立即导致了在平面图、有界亏格图和$k=O(n^{\frac{1}{4}})$的$k$-顶点图上，多项式时间近似算法的近似比达到$O(n^{\frac{1}{4}} \sqrt{\log n})$。在有界树宽图上，我们对于任意常数$\varepsilon > 0$获得了$O(\log^{3/2} n)$的近似比。这与通过简单地归约到\textsc{集合覆盖}问题而获得的通用图的最佳已知近似算法$O(\sqrt{n \log n})$相比，表现更优。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [99] [Inverse matroid optimization under subset constraints](https://arxiv.org/abs/2507.00930)
> *子集约束下的逆拟阵优化*

*Kristóf íBérczi, Lydia Mirabel Mendoza-Cadena, José Soto* | **Category: cs.DS, cs.DM**

**Keywords:** 逆拟阵, 子集约束, 多项式时间算法, $\ell_\infty$-范数, 组合优化

**Comment:** 20 pages

> **TL;DR:** 该论文扩展了逆拟阵问题，使其包含子集约束，并在无穷范数下为多个变体开发了多项式时间算法。

**AI_Comments:** 该论文通过引入子集约束，对经典的逆拟阵问题进行了重大扩展，这与实际场景中解受特定子集限制的情况高度相关。在$\ell_\infty$-范数下，借助改进的最小-最大定理，为这些变体开发多项式时间算法，代表了算法上的显著进步。这项工作不仅拓宽了对拟阵上逆优化的理论理解，而且为更广泛的问题提供了实用、高效的解决方案。改进的最小-最大定理被强调为一个可能独立的组合贡献。

<details>
  <summary>Details</summary>

**Motivation:** 经典的逆拟阵问题产生于需要通过最小化扰动输入来解释或强制给定解的场景。本文通过用基集的子集替换固定基，并对相对于该子集的最大权重基施加结构约束，从而扩展了该问题。

**Method:** 作者在$\ell_\infty$-范数下为所有六种变体开发了组合多项式时间算法。关键在于一个针对$\ell_\infty$-范数下逆拟阵的改进的最小-最大定理。

**Result:** 在$\ell_\infty$-范数下，为所有变体开发了多项式时间算法。改进的最小-最大定理使得算法比以前的方法更简单、更快。

**Conclusion:** 这项工作显著拓宽了拟阵上可以高效解决的逆优化问题的范围，特别是那些通过子集包含或排除来约束最优解结构的问题。

> **ai_Abstract:** 本文通过用基集的一个子集$S_0$替换固定基，并引入了相对于$S_0$的最大权重基的各种结构约束，从而扩展了经典的逆拟阵问题。它定义了六种变体（存在、全部、唯一及其否定对应物），并在$\ell_\infty$-范数下为所有这些变体提供了组合多项式时间算法。一个关键贡献是改进的最小-最大定理，该定理使得算法更简单、更快，从而拓宽了拟阵上带子集约束的逆优化问题的可高效解决范围。

> **摘要翻译:** 在逆拟阵问题中，给定一个拟阵、一个固定的基$B$和一个初始权重函数，目标是最小化地修改权重（通过某个函数衡量），使得$B$成为一个最大权重基。该问题自然出现在需要通过最小扰动输入来解释或强制给定解的场景中。
我们通过用基集的一个子集$S_0$替换固定基，并对相对于$S_0$的最大权重基集施加各种结构约束来扩展这个经典问题。具体来说，我们研究了六种变体：(A) 逆拟阵存在，其中$S_0$必须包含至少一个最大权重基；(B) 逆拟阵全部，其中$S_0$中包含的所有基都是最大权重基；以及 (C) 逆拟阵唯一，其中$S_0$恰好包含最大权重基，以及它们自然的否定对应物。
对于所有变体，我们在$\ell_\infty$-范数下开发了组合多项式时间算法。一个关键要素是针对$\ell_\infty$-范数下逆拟阵的改进的最小-最大定理，这使得算法比以前的方法更简单、更快，并且可能具有独立的组合兴趣。我们的工作显著拓宽了拟阵上可以高效解决的逆优化问题的范围，特别是那些通过子集包含或排除来约束最优解结构的问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [36] [MVGBench: Comprehensive Benchmark for Multi-view Generation Models](https://arxiv.org/abs/2507.00006)
> *MVGBench：多视角生成模型综合基准*

*Xianghui Xie, Chuhang Zou, Meher Gitika Karumuri, Jan Eric Lenssen, Gerard Pons-Moll* | **Category: cs.GR, cs.LG, eess.IV**

**Keywords:** 多视角生成, 基准测试, 3D一致性, 鲁棒性, 泛化能力

**Comment:** 17 pages, 11 figures, 9 tables, project page:
  https://virtualhumans.mpi-inf.mpg.de/MVGBench/

> **TL;DR:** 本文提出了MVGBench，这是一个用于评估多视角生成模型（MVGs）的综合基准，引入了新的3D自一致性度量，并系统比较了现有方法，揭示了其局限性，并基于此提出了一种新的模型。

**AI_Comments:** MVGBench的创新之处在于其提出的3D自一致性度量，这解决了传统基于真实值比较的局限性，更适合生成式任务的评估。该基准的全面性及其对鲁棒性和泛化能力的关注，对于推动多视角生成领域的发展至关重要。通过系统比较和识别关键设计选择，该研究为未来MVG模型的开发提供了清晰的方向。同时，其提出的ViFiGen模型也证明了基准指导下的优化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视角生成模型（MVGs）评估指标存在局限性，它们将生成图像与真实目标视图进行比较，这不适用于存在多种解决方案的生成任务。此外，现有方法对不同视角、合成数据和特定光照的鲁棒性以及对真实数据的泛化能力评估不足，导致不清楚哪些设计选择有助于MVGs的进步。

**Method:** 本文提出了MVGBench，一个综合性基准，用于评估多视角生成模型（MVGs）的几何和纹理3D一致性、图像质量和语义。MVGBench评估三个方面：最佳设置性能、对真实数据的泛化能力和鲁棒性。该基准引入了一种新颖的3D自一致性度量，通过比较来自不相交生成多视图的3D重建来代替与真实值的比较。研究系统地比较了12种现有MVGs在4个精心策划的真实和合成数据集上的表现。

**Result:** 通过MVGBench的分析，研究人员识别出现有方法在鲁棒性和泛化能力方面的重要局限性，并找到了最关键的设计选择。基于这些发现的最佳实践，本文提出了ViFiGen，该方法在3D一致性方面优于所有已评估的MVGs。

**Conclusion:** MVGBench提供了一个严格的评估协议，揭示了多视角生成模型在鲁棒性和泛化能力方面的关键局限性，并为未来模型的设计提供了指导，成功地提出了一个在3D一致性上表现更优的方法。

> **ai_Abstract:** 本文介绍了MVGBench，一个针对多视角图像生成模型（MVGs）的全面评估基准。该基准旨在解决现有评估方法无法充分衡量生成任务多样性和模型泛化能力的问题。MVGBench通过引入创新的3D自一致性度量，并评估模型在最佳性能、真实数据泛化和鲁棒性方面的表现。研究系统地比较了12种现有MVGs在多样化数据集上的性能，揭示了其在鲁棒性和泛化方面的不足，并识别出关键设计因素。基于这些发现，论文还提出了一种名为ViFiGen的新方法，该方法在3D一致性方面超越了现有模型。

> **摘要翻译:** 我们提出了MVGBench，一个用于多视角图像生成模型（MVGs）的综合基准，它评估了几何和纹理的3D一致性、图像质量以及语义（使用视觉语言模型）。最近，MVGs一直是3D物体创建的主要推动力。然而，现有指标将生成的图像与真实目标视图进行比较，这不适用于存在多种解决方案但与真实情况不同的生成任务。此外，不同的MVGs在不同的视角、合成数据和特定光照下进行训练——对这些因素的鲁棒性和对真实数据的泛化能力很少得到彻底评估。如果没有严格的评估协议，也不清楚哪些设计选择有助于MVGs的进展。MVGBench评估三个不同方面：最佳设置性能、对真实数据的泛化能力和鲁棒性。我们没有与真实情况进行比较，而是引入了一种新颖的3D自一致性度量，它比较了来自不相交生成的多个视图的3D重建。我们系统地比较了12种现有MVGs在4个不同的精心策划的真实和合成数据集上的表现。通过我们的分析，我们识别出现有方法的重要局限性，特别是在鲁棒性和泛化能力方面，并且我们找到了最关键的设计选择。利用发现的最佳实践，我们提出了ViFiGen，一种在3D一致性方面优于所有已评估MVGs的方法。我们的代码、模型和基准套件将公开发布。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [56] [ViscoReg: Neural Signed Distance Functions via Viscosity Solutions](https://arxiv.org/abs/2507.00412)
> *ViscoReg：基于粘性解的神经符号距离函数*

*Meenakshi Krishnan, Ramani Duraiswami* | **Category: cs.GR**

**Keywords:** 神经符号距离函数, 粘性解, Eikonal方程, 梯度流, 3D重建

**Comment:** 14 pages, 6 figures

> **TL;DR:** 提出ViscoReg，一种利用粘性解理论的新损失函数，解决了神经SDF训练中Eikonal损失导致的梯度流不稳定问题，并在理论和实践中均表现出优越性。

**AI_Comments:** 这项工作通过引入基于粘性解理论的新型损失函数ViscoReg，为神经SDF训练中的梯度流不稳定性问题提供了一个优雅且有效的解决方案。其创新之处在于将传统的数值分析理论与现代深度学习相结合，不仅提供了理论上的稳定性保证，还在经验上展现出优越的性能，且计算成本低，这对于提高3D重建模型的鲁棒性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经符号距离函数（Neural SDFs）在训练时强制执行Eikonal方程，但Eikonal损失会导致不稳定的梯度流，需要替代的稳定技术。

**Method:** 作者借鉴了传统数值求解器中依赖粘性方法进行正则化的经验，提出了一种名为ViscoReg的新型损失函数，用于增强神经SDF的训练。该方法利用了成熟的粘性解理论。

**Result:** 理论上，ViscoReg证明了其所提出的损失项的梯度流方程的稳定性。经验上，ViscoReg在不显著增加计算成本的情况下，优于SIREN、DiGS和StEik等最先进的方法。

**Conclusion:** ViscoReg通过引入基于粘性解理论的新损失函数，有效地解决了神经SDF训练中Eikonal损失带来的梯度流不稳定问题，并在理论和实践中均取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为ViscoReg的新型损失函数，用于解决基于Eikonal方程训练的神经符号距离函数（Neural SDFs）所面临的梯度流不稳定问题。ViscoReg借鉴了传统数值求解器中粘性方法的正则化思想，并从理论上证明了其梯度流的稳定性。实验结果表明，ViscoReg在不显著增加计算成本的前提下，在3D场景重建任务上超越了现有的先进方法。

> **摘要翻译:** 隐式神经表示（INRs）学习符号距离函数（SDF），是连续三维场景重建的强大工具。这些模型通过强制执行Eikonal方程进行训练。我们从理论上证明，尽管Eikonal方程是不适定的，但神经SDF的泛化误差估计可以根据训练误差获得。然而，使用Eikonal损失进行训练可能导致不稳定的梯度流，因此需要替代的稳定技术。该方程的传统数值求解器依赖粘性方法进行正则化。我们利用这一成熟的理论来增强神经SDF的训练，并引入了一种新的损失公式，我们称之为ViscoReg。我们从理论上证明了我们提出的损失项的梯度流方程的稳定性。在经验上，ViscoReg在不增加显著计算成本的情况下，优于SIREN、DiGS和StEik等最先进的方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [76] [FreNBRDF: A Frequency-Rectified Neural Material Representation](https://arxiv.org/abs/2507.00476)
> *FreNBRDF：一种频率校正的神经材料表示*

*Chenliang Zhou, Zheyuan Hu, Cengiz Oztireli* | **Category: cs.GR, cs.CV**

**Keywords:** 神经材料表示, BRDF, 频域, 球谐函数, 照片级渲染

**Comment:** 

> **TL;DR:** 该论文引入了FreNBRDF，一种频率校正的神经材料表示，通过整合频域考量和提出频率校正损失，显著提高了材料外观重建和编辑的准确性和鲁棒性。

**AI_Comments:** 这项工作通过将频域分析引入神经材料表示，解决了现有方法的一个关键限制，提高了模型的准确性和鲁棒性，具有创新性。其提出的频率校正损失和整合到通用管道的方***为未来的神经渲染研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 准确的材料建模对于实现照片级真实感渲染至关重要。虽然隐式神经表示提供了紧凑灵活的框架，但其在频域的行为尚不明确。本研究旨在解决这一问题。

**Method:** 引入FreNBRDF，一种频率校正的神经材料表示。通过利用球谐函数，将频域考虑集成到神经BRDF建模中。提出了一种新颖的频率校正损失，该损失源自对神经材料的频率分析，并将其整合到一个可推广和自适应的重建和编辑管道中。

**Result:** FreNBRDF与最先进的基线相比，提高了材料外观重建和编辑的准确性和鲁棒性，并支持了更结构化和可解释的下游任务和应用。

**Conclusion:** 通过将频域考量和频率校正损失引入神经材料表示，FreNBRDF增强了保真度、适应性和效率，从而在材料重建和编辑方面实现了更高的准确性和鲁棒性。

> **ai_Abstract:** 该论文引入了FreNBRDF，一种频率校正的神经材料表示，旨在解决现有隐式神经BRDF模型在频域行为理解上的不足。通过利用球谐函数和提出一种新颖的频率校正损失，FreNBRDF将频域考量融入神经BRDF建模中，并应用于可推广的重建和编辑流程。实验证明，FreNBRDF在材料外观重建和编辑方面比现有方法更准确和鲁棒。

> **摘要翻译:** 准确的材料建模对于实现照片级真实感渲染至关重要，它弥合了计算机生成图像与真实世界照片之间的鸿沟。传统的方***依赖于表格化的BRDF数据，而最近的工作已转向隐式神经表示，后者为一系列任务提供了紧凑而灵活的框架。然而，它们在频域中的行为仍然知之甚少。为了解决这个问题，我们引入了FreNBRDF，一种频率校正的神经材料表示。通过利用球谐函数，我们将频域考虑集成到神经BRDF建模中。我们提出了一种新颖的频率校正损失，该损失源自对神经材料的频率分析，并将其整合到一个可推广和自适应的重建和编辑管道中。这个框架增强了保真度、适应性和效率。大量的实验表明，与最先进的基线相比，我们的方法提高了材料外观重建和编辑的准确性和鲁棒性，从而支持了更结构化和可解释的下游任务和应用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [98] [Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory](https://arxiv.org/abs/2507.00725)
> *使用分段线性莫尔斯-塞尔夫理论分析时变标量场*

*Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan* | **Category: cs.GR, cs.CG, I.3.5**

**Keywords:** 莫尔斯-塞尔夫理论, 分段线性函数, 时变标量场, 拓扑描述符, 塞尔夫图

**Comment:** 

> **TL;DR:** 本文将莫尔斯-塞尔夫理论应用于分段线性函数，引入顶点图和塞尔夫图来表示临界点的演变，并提出了一个用于分析时变标量场的拓扑描述符和计算算法。

**AI_Comments:** 本文的创新点在于将光滑函数领域的莫尔斯-塞尔夫理论成功适配到分段线性函数，这对于处理离散或网格数据中的时变标量场分析具有重要意义。引入顶点图和塞尔夫图为理解临界点动态提供了直观的工具，而基于同调性的拓扑描述符则为场分析提供了新的数学基础。其提出的算法和比较度量也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 莫尔斯-塞尔夫理论研究流形上光滑函数族临界点随参数的演变。本文的动机是将其应用于分段线性（PL）函数族，以分析时变标量场。

**Method:** 本文引入了顶点图和塞尔夫图作为分段线性函数临界点演变的表示。基于顶点下链的同调性，对顶点图中的交叉点进行了表征，从而定义了一个时变标量场的拓扑描述符。同时描述了计算塞尔夫图的算法以及比较两个塞尔夫图的度量。

**Result:** 论文中描述了计算塞尔夫图的算法和比较两个塞尔夫图的度量，并提供了在时变标量场上的实验结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文将经典的莫尔斯-塞尔夫理论扩展到分段线性函数，通过引入顶点图和塞尔夫图来可视化和分析时变标量场中临界点的演变。研究提出了一种基于下链同调性的拓扑描述符，并开发了计算塞尔夫图的算法和比较方法，并通过实验结果验证了其有效性。

> **摘要翻译:** 莫尔斯-塞尔夫理论考虑了定义在流形上的一参数光滑函数族，并研究了它们的临界点随参数的演变。本文提出了莫尔斯-塞尔夫理论对分段线性（PL）函数族的适应。引入了顶点图和塞尔夫图作为PL函数临界点演变的表示。基于顶点下链的同调性对顶点图中的交叉点进行表征，从而定义了一个时变标量场的拓扑描述符。同时描述了计算塞尔夫图的算法以及比较两个塞尔夫图的度量，并提供了在时变标量场上的实验结果。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [105] [Read the Docs Before Rewriting: Equip Rewriter with Domain Knowledge via Continual Pre-training](https://arxiv.org/abs/2507.00477)
> *在重写前阅读文档：通过持续预训练为重写器装备领域知识*

*Qi Wang, Yixuan Cao, Yifan Liu, Jiangtao Zhao, Ping Luo* | **Category: cs.IR**

**Keywords:** RAG, 查询重写, 领域知识, 持续预训练, 专业问答

**Comment:** 

> **TL;DR:** R&R是一个通过持续预训练领域文档来增强领域知识的重写器，解决了RAG系统中专业领域查询重写的问题，并在多个领域QA任务中表现出色。

**AI_Comments:** 该论文提出了一种新颖的方法R&R，通过模拟“开卷考试”的思维，让重写器在重写前通过持续预训练吸收领域知识，这对于提升RAG系统在专业领域的性能具有重要意义。其创新点在于将领域知识的获取前置到重写阶段，有效解决了传统重写器在特定领域知识不足的问题。

<details>
  <summary>Details</summary>

**Motivation:** 在专业领域中，RAG系统的重写器模型可能因缺乏领域特定知识而难以处理用户查询与文档措辞之间的差异，这限制了RAG在专业领域的应用。

**Method:** 提出R&R（Read the doc before Rewriting）重写器，通过对专业文档进行持续预训练来获取领域知识。此外，还可以结合监督微调以进一步提高性能。

**Result:** 在多个数据集上的实验表明，R&R在多个领域的专业QA任务中表现出色，有效弥合了查询与文档之间的差距，同时在通用场景中也保持了良好的性能。

**Conclusion:** R&R重写器通过持续预训练在专业领域QA中表现出优越性，推动了RAG系统在专业领域的应用。

> **ai_Abstract:** 本文提出了R&R（Read the doc before Rewriting）重写器，旨在解决RAG（检索增强生成）系统中在专业领域内因缺乏领域知识导致的查询重写困难。R&R通过对专业文档进行持续预训练来获取领域知识，并可结合监督微调。实验证明，R&R在专业领域QA任务中能有效弥合查询与文档之间的差距，并在通用场景中保持良好性能，从而提升了RAG系统在专业领域的应用能力。

> **摘要翻译:** 一个基于检索增强生成（RAG）的问答（QA）系统通过根据用户查询检索相关文档来增强大型语言模型的知识。用户查询和文档措辞之间的差异通常需要查询重写。然而，在专业领域中，重写器模型可能由于有限的领域特定知识而遇到困难。为了解决这个问题，我们提出了R&R（在重写前阅读文档）重写器，它涉及对专业文档进行持续预训练，类似于学生通过复习教科书准备开卷考试。此外，它可以与监督微调相结合以获得改进的结果。在多个数据集上的实验表明，R&R在跨多个领域的专业QA中表现出色，有效弥合了查询-文档差距，同时在通用场景中保持了良好的性能，从而推动了基于RAG的QA系统在专业领域的应用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [129] [On Mitigating Data Sparsity in Conversational Recommender Systems](https://arxiv.org/abs/2507.00479)
> *缓解对话推荐系统中的数据稀疏性问题*

*Sixiao Zhang, Mingrui Liu, Cheng Long, Wei Yuan, Hongxu Chen, Xiangyu Zhao, Hongzhi Yin* | **Category: cs.IR**

**Keywords:** 对话推荐系统, 数据稀疏性, 知识图谱, 对话增强, 实体建模

**Comment:** 

> **TL;DR:** 本文提出了一种名为DACRS的对话推荐系统模型，通过对话增强、知识图谱引导的实体建模和对话-实体匹配三个模块，有效缓解了对话推荐系统中的数据稀疏性问题，并在两个公开数据集上取得了最先进的性能。

**AI_Comments:** 该论文通过引入对话增强和知识图谱引导的实体建模，为缓解对话推荐系统中的数据稀疏性提供了一个新颖且有效的方法。其模块化的设计思路清晰，特别是对文本线索的充分利用和实体表示的增强，是其创新之处。在解决数据稀疏性这一CRSs核心挑战方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 对话推荐系统（CRSs）通过对话中的文本信息捕获用户偏好，但存在严重的数据稀疏性问题：对话空间巨大且语言多样，而物品空间则呈现长尾和稀疏分布。现有方法难以泛化到多样的对话表达（未充分利用文本线索）以及在严重稀疏性下学习信息丰富的物品表示。

**Method:** 本文提出了一个名为DACRS的CRS模型，包含三个模块：
1.  **对话增强模块（Dialogue Augmentation）**：应用两阶段增强管道来丰富对话上下文，以提高数据和泛化能力。
2.  **知识引导的实体建模模块（Knowledge-Guided Entity Modeling）**：提出基于知识图谱（KG）的实体替换和实体相似性约束，以增强实体嵌入的表达能力。
3.  **对话-实体匹配模块（Dialogue-Entity Matching）**：通过对话引导的注意力聚合将对话嵌入与提及的实体嵌入融合，以获取包含显式和隐式用户偏好的用户嵌入。

**Result:** 在两个公共数据集上进行的广泛实验表明，DACRS模型达到了最先进的性能。

**Conclusion:** DACRS模型通过其创新的对话增强、知识引导的实体建模和对话-实体匹配模块，有效地缓解了对话推荐系统中的数据稀疏性问题，并显著提升了系统性能，达到了当前最佳水平。

> **ai_Abstract:** 本文提出了一种名为DACRS的对话推荐系统（CRS）模型，旨在解决CRSs中普遍存在的数据稀疏性问题，包括对话空间广阔性和物品分布稀疏性。DACRS包含三个核心模块：对话增强、知识引导的实体建模和对话-实体匹配。对话增强通过两阶段管道丰富对话上下文以提高泛化性；知识引导的实体建模利用知识图谱进行实体替换和相似性约束以增强实体嵌入；对话-实体匹配则通过注意力机制融合对话和实体嵌入以捕捉用户偏好。实验证明，DACRS在两个公开数据集上取得了最先进的性能，有效缓解了数据稀疏性。

> **摘要翻译:** 对话推荐系统（CRSs）通过对话中的文本信息捕获用户偏好。然而，它们面临双重数据稀疏性问题：对话空间广阔且语言多样，而物品空间则呈现长尾和稀疏分布。现有方法难以解决（1）由于未能充分利用丰富的文本线索而难以泛化到各种对话表达，以及（2）在严重稀疏性下学习信息丰富的物品表示的问题。为了解决这些问题，我们提出了一种名为DACRS的CRS模型。它由三个模块组成，即对话增强、知识引导的实体建模和对话-实体匹配。在对话增强模块中，我们应用两阶段增强管道来增强对话上下文，以丰富数据并提高泛化能力。在知识引导的实体建模中，我们提出了一种基于知识图谱（KG）的实体替换和实体相似性约束，以增强实体嵌入的表达能力。在对话-实体匹配模块中，我们通过对话引导的注意力聚合将对话嵌入与提及的实体嵌入融合，以获取包含显式和隐式用户偏好的用户嵌入。在两个公共数据集上进行的广泛实验表明，DACRS达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [150] [MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models](https://arxiv.org/abs/2507.00487)
> *MassTool：一个用于大型语言模型的多任务搜索式工具检索框架*

*Jianghao Lin, Xinyuan Wang, Xinyi Dai, Menghui Zhu, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang* | **Category: cs.IR, cs.CL**

**Keywords:** 大型语言模型, 工具检索, 多任务学习, 查询理解, 图卷积网络

**Comment:** 

> **TL;DR:** MassTool是一个多任务搜索框架，通过关注查询理解和工具检索，提高了LLM的工具检索精度。

**AI_Comments:** MassTool的创新之处在于其多任务学习方法和对查询理解的强调，特别是引入了双塔架构、QC-GCN、SUIM和AdaKT模块，这些都旨在提升LLM在复杂和多样化查询场景下的工具检索能力。其双步顺序决策流程也增强了查询理解的鲁棒性，对于提升LLM与外部工具交互的效率和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型工具检索方法主要关注工具表示优化，但忽视了精确查询理解的重要性。

**Method:** MassTool是一个多任务搜索框架，采用双塔架构：一个工具使用检测塔预测函数调用需求，一个工具检索塔利用以查询为中心的图卷积网络（QC-GCN）进行查询-工具匹配。它还结合了基于搜索的用户意图建模（SUIM）来处理多样化和分布外查询，以及自适应知识迁移（AdaKT）模块进行高效多任务学习。通过联合优化工具使用检测损失、列表式检索损失和对比正则化损失，建立了精确查询理解的双步顺序决策流程。

**Result:** 广泛的实验证明了MassTool在提高检索精度方面的有效性。

**Conclusion:** MassTool通过其创新的多任务框架和双步决策流程，有效解决了LLM工具检索中查询理解不足的问题，显著提高了检索精度。

> **ai_Abstract:** MassTool是一个为大型语言模型设计的、基于多任务搜索的工具检索框架，旨在解决现有方法忽视精确查询理解的问题。它采用双塔架构，结合了工具使用检测、基于QC-GCN的工具检索、用户意图建模和自适应知识迁移，并通过联合优化多种损失函数，构建了一个精确查询理解的双步决策流程，显著提高了工具检索的准确性。

> **摘要翻译:** 工具检索是使大型语言模型（LLM）有效与外部工具交互的关键组成部分。它的目标是将海量工具精确过滤成一小部分候选工具，供下游工具增强型LLM使用。然而，大多数现有方法主要关注优化工具表示，常常忽视精确查询理解的重要性。为了解决这一空白，我们引入了MassTool，一个基于多任务搜索的框架，旨在提高查询表示和工具检索的准确性。MassTool采用双塔架构：一个工具使用检测塔，用于预测函数调用的需求；一个工具检索塔，利用以查询为中心的图卷积网络（QC-GCN）进行有效的查询-工具匹配。它还结合了基于搜索的用户意图建模（SUIM）来处理多样化和分布外查询，以及自适应知识迁移（AdaKT）模块，用于高效的多任务学习。通过联合优化工具使用检测损失、列表式检索损失和对比正则化损失，MassTool建立了一个鲁棒的双步顺序决策流程，以实现精确的查询理解。广泛的实验证明了其在提高检索精度方面的有效性。我们的代码可在https://github.com/wxydada/MassTool获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [171] [\texttt{WebANNS}: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers](https://arxiv.org/abs/2507.00521)
> *WebANNS：Web浏览器中快速高效的近似最近邻搜索*

*Mugeng Liu, Siqi Zhong, Qi Yang, Yudong Han, Xuanzhe Liu, Yun Ma* | **Category: cs.IR**

**Keywords:** 近似最近邻搜索, Web浏览器, WebAssembly, 惰性加载, 内存优化

**Comment:** SIGIR 2025

> **TL;DR:** WebANNS是一种专为Web浏览器设计的近似最近邻搜索（ANNS）引擎，通过WebAssembly、惰性加载和启发式方法显著提高了查询速度并降低了内存使用，使浏览器内ANNS变得实用。

**AI_Comments:** WebANNS的创新之处在于其专门针对Web浏览器环境的限制（如计算、存储访问和内存）进行了优化。它通过结合WebAssembly、惰性加载和启发式内存管理，实现了显著的性能提升，特别是将查询延迟从秒级降低到毫秒级，这对于提升用户体验和推动浏览器内AI应用具有重要意义。该工作解决了在边缘设备上部署复杂AI功能时的实际挑战。

<details>
  <summary>Details</summary>

**Motivation:** 近似最近邻搜索（ANNS）在现代AI基础设施中至关重要，尤其是在检索增强生成（RAG）应用中。尽管出现了许多浏览器内ANNS引擎以解决隐私和异构设备部署问题，但Web浏览器固有的计算限制、外部存储访问问题和内存利用率约束，是现有SOTA解决方案未能全面解决的挑战。

**Method:** 本文提出了WebANNS，一种专为Web浏览器设计的ANNS引擎。WebANNS利用WebAssembly克服计算瓶颈，设计了一种惰性加载策略来优化外部存储数据检索，并应用启发式方法来减少内存使用。

**Result:** 实验表明，WebANNS快速且内存高效，与SOTA引擎相比，其第99百分位查询延迟提高了743.8倍，同时内存使用量减少了39%。WebANNS将浏览器中的查询时间从10秒缩短到10毫秒级别。

**Conclusion:** WebANNS显著提高了浏览器内近似最近邻搜索的性能和效率，使其在用户可接受的延迟范围内变得实用可行。

> **ai_Abstract:** WebANNS是一种针对Web浏览器中近似最近邻搜索（ANNS）挑战而设计的创新引擎。它通过利用WebAssembly解决计算瓶颈，采用惰性加载策略优化外部存储访问，并应用启发式方法减少内存消耗。实验结果显示，WebANNS显著优于现有SOTA解决方案，将查询延迟提高高达743.8倍，内存使用降低39%，从而使浏览器内ANNS在实际应用中达到用户可接受的响应速度。

> **摘要翻译:** 近似最近邻搜索（ANNS）已成为现代AI基础设施的关键，尤其是在检索增强生成（RAG）应用中。许多浏览器内ANNS引擎已经出现，旨在与流行的基于LLM的Web应用程序无缝集成，同时解决隐私保护和异构设备部署的挑战。然而，Web浏览器为ANNS带来了独特的挑战，包括计算限制、外部存储访问问题和内存利用率限制，而最先进（SOTA）的解决方案未能全面解决这些问题。
我们提出了WebANNS，一种专为Web浏览器设计的创新ANNS引擎。WebANNS利用WebAssembly克服计算瓶颈，设计了一种惰性加载策略来优化从外部存储的数据检索，并应用启发式方法来减少内存使用。实验表明，WebANNS快速且内存高效，其第99百分位查询延迟比SOTA引擎提高了743.8倍，同时内存使用量减少了39%。值得注意的是，WebANNS将浏览器中的查询时间从10秒缩短到10毫秒级别，使得浏览器内ANNS在用户可接受的延迟下变得实用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [188] [Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support](https://arxiv.org/abs/2507.00535)
> *生成式人工智能时代下重新思考群体推荐系统：从一次性推荐到智能体群体决策支持*

*Dietmar Jannach, Amra Delić, Francesco Ricci, Markus Zanker* | **Category: cs.IR, cs.AI**

**Keywords:** 群体推荐系统, 生成式AI, 代理决策, 人机交互, 系统采纳

**Comment:** Submitted for publication

> **TL;DR:** 本文呼吁重新调整群体推荐系统的研究方向，利用生成式AI的能力，构建基于AI代理的聊天式决策支持系统，以解决现有系统在实际应用中缺乏采纳的问题。

**AI_Comments:** 本文创新性地提出了将生成式AI引入群体推荐系统，以解决当前系统在实际应用中落地难的问题。通过将推荐过程从一次性输出转变为AI代理辅助的交互式决策支持，有望克服传统聚合方式的局限性，更好地适应群体沟通和决策的复杂性。其重要性在于为群体推荐系统的未来发展指明了一个全新的、更具实践潜力的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管群体推荐系统研究文献丰富，但实际应用案例却寥寥无几。这促使作者质疑学术研究中的常见假设，特别是关于群体沟通和推荐辅助决策过程的假设。作者认为这些假设和系统设计可能与用户需求或期望不符。

**Method:** 本文提出利用现代生成式AI助手（如ChatGPT）的能力，重新定位群体推荐系统。具体而言，未来的群体推荐系统应设想为人类群体成员在聊天中互动，而基于AI的群体推荐智能体则以代理方式协助决策过程。

**Result:** Not mentioned in abstract

**Conclusion:** 这种重新定位将使群体决策环境更加自然，并最终促使群体推荐系统在实践中得到更广泛的应用。

> **ai_Abstract:** 本文针对群体推荐系统在现实世界中应用不足的问题，质疑了现有研究中的常见假设。作者呼吁利用生成式AI技术，将群体推荐系统重新构想为AI代理在聊天环境中辅助人类群体决策的模式，以期实现更自然的决策过程和更广泛的实际应用。

> **摘要翻译:** 二十五年前，首次提出了如何设计一个能够为用户群体而非个体用户提供推荐的系统。自那时起，发表了大量算法提案，例如如何获取个体偏好、如何聚合这些偏好以及如何为用户群体生成推荐。然而，尽管该主题的文献丰富，却几乎找不到任何真实世界的群体推荐系统实例。这让我们质疑学术研究中的常见假设，特别是关于群体沟通过程以及推荐辅助决策方式的假设。在这篇文章中，我们认为这些常见假设和相应的系统设计往往可能不符合用户的需求或期望。因此，我们呼吁在该研究领域进行重新定位，利用现代生成式AI助手（如ChatGPT）的能力。具体而言，作为一个有前景的未来方向，我们设想群体推荐系统将是这样一种系统：人类群体成员在聊天中互动，而基于AI的群体推荐智能体以代理方式协助决策过程。最终，这将带来更自然的群体决策环境，并最终促使群体推荐系统在实践中得到更广泛的采纳。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [207] [Reliable Annotations with Less Effort: Evaluating LLM-Human Collaboration in Search Clarifications](https://arxiv.org/abs/2507.00543)
> *低成本实现可靠标注：评估大型语言模型与人类在搜索澄清任务中的协作*

*Leila Tavakoli, Hamed Zamani* | **Category: cs.IR, cs.HC**

**Keywords:** 大型语言模型, 人机协作, 标注, 搜索澄清, 可靠性

**Comment:** 9 pages,5 figures

> **TL;DR:** 大型语言模型在复杂标注任务中表现不佳，但结合人工协作的工作流程显著提高了标注可靠性，并减少了高达45%的人工工作量，尤其适用于搜索澄清任务。

**AI_Comments:** 该论文解决了在复杂任务中部署大型语言模型的一个关键实际挑战：它们在复制主观和细粒度标注方面的人类水平性能的局限性。其创新之处在于提出了一种简单而有效的人机协作（HITL）方法，巧妙地结合了LLM的效率和人类的准确性，证明在提高可靠性的同时显著减少了人工工作量。这为在实际应用中利用LLM的优势并减轻其劣势提供了一条务实的途径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人们对使用大型语言模型（LLMs）实现自动化标注的兴趣日益增长，但它们在复杂、细致入微和多维度标注任务（特别是搜索澄清）中的有效性仍未被充分探索。研究发现，即使是先进的LLMs也难以在主观或细粒度评估任务中达到人类水平的性能，表现出不一致性、校准不良和对提示变化的高度敏感性。

**Method:** 本研究利用一个高质量、多维度的搜索澄清任务数据集，该数据集包含五个不同的细粒度标注子任务。为解决LLM的局限性，研究提出了一种简单而有效的人机协作（HITL）工作流程，该流程通过置信度阈值和模型间分歧来选择性地引入人工审查。

**Result:** 提出的轻量级人机协作干预显著提高了标注的可靠性，同时将人工工作量减少了高达45%。

**Conclusion:** 所提出的人机协作工作流程为在实际评估设置中部署大型语言模型提供了一条相对可扩展、成本效益高且准确的路径，尤其适用于复杂标注任务。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在复杂、多维度标注任务（特别是搜索澄清）中的有效性。研究发现，即使是最先进的LLMs也难以在主观或细粒度评估任务中达到人类水平的性能，表现出不一致性、校准不良和对提示变化的高度敏感性。为解决这些问题，论文提出了一种简单有效的人机协作（HITL）工作流程，该流程利用置信度阈值和模型间分歧来选择性地引入人工审查。结果表明，该方法显著提高了标注可靠性，并将人工工作量减少了高达45%，为在实际评估场景中部署LLMs提供了一条实用且高效的途径。

> **摘要翻译:** 尽管人们对使用大型语言模型（LLMs）实现自动化标注的兴趣日益增长，但它们在复杂、细致入微和多维度标注任务中的有效性仍相对未被充分探索。本研究侧重于搜索澄清任务的标注，利用高质量、多维度的数据集，其中包括五个不同的细粒度标注子任务。尽管LLMs在一般设置中表现出令人印象深刻的能力，但我们的研究表明，即使是最先进的模型也难以在主观或细粒度评估任务中复制人类水平的性能。通过系统评估，我们证明LLM的预测通常不一致、校准不良，并且对提示变化高度敏感。为了解决这些局限性，我们提出了一种简单而有效的人机协作（HITL）工作流程，该流程使用置信度阈值和模型间分歧来选择性地引入人工审查。我们的研究结果表明，这种轻量级干预显著提高了标注的可靠性，同时将人工工作量减少了高达45%，为在实际评估设置中部署LLMs提供了一条相对可扩展、成本效益高且准确的前进道路。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [221] [EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens](https://arxiv.org/abs/2507.00715)
> *EARN：通过寄存器令牌实现基于大型语言模型的生成式推荐的高效推理加速*

*Chaoqun Yang, Xinyu Lin, Wenjie Wang, Yongqi Li, Teng Sun, Xianjing Han, Tat-Seng Chua* | **Category: cs.IR**

**Keywords:** LLMRec, 推理加速, KV缓存, 寄存器令牌, 注意力机制

**Comment:** Accepted by KDD 2025

> **TL;DR:** EARN是一种高效推理框架，通过利用早期层将信息压缩到寄存器令牌中，并在后续层中仅关注这些令牌，显著加速了基于LLM的生成式推荐（LLMRec），同时减少了KV缓存并提高了准确性。

**AI_Comments:** 该论文的创新点在于发现了LLMRec中注意力模式的两个关键洞察（层级注意力稀疏性反转和双注意力汇聚），并据此提出了利用“寄存器令牌”进行信息压缩和推理加速的EARN框架。这种方法有效地解决了LLMRec在实际部署中面临的效率瓶颈，尤其在推荐场景下，其在加速和KV缓存减少方面的显著效果具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于大型语言模型的生成式推荐（LLMRec）面临高推理延迟问题，原因在于巨大的计算开销和KV缓存的内存压力。现有KV缓存减少方法（如缓存压缩和提示压缩）存在局限性，无法有效解决推荐任务的短解码步长或存在丢失关键交互历史的风险。

**Method:** 通过对LLMRec中注意力模式的系统分析，发现了两个关键洞察：1）层级注意力稀疏性反转，即早期层保留密集信息模式，而后期层表现出高冗余；2）双注意力汇聚现象，即注意力分数集中在输入序列的头部和尾部令牌上。受此启发，提出了EARN框架，该框架利用早期层将信息压缩到放置在输入序列边界的寄存器令牌中，然后在后续层中仅关注这些令牌。

**Result:** 在三个数据集、两种LLMRec方法和两种LLM架构上的广泛实验表明，EARN具有优越性，实现了高达3.79倍的加速和80.8%的KV缓存减少，并且比通用微调方法具有更好的准确性。

**Conclusion:** 该工作弥合了LLMRec中的效率-有效性差距，为工业场景的实际部署提供了优势。

> **ai_Abstract:** 本研究提出了一种名为EARN的框架，旨在解决基于大型语言模型（LLM）的生成式推荐（LLMRec）中存在的推理延迟高和KV缓存压力大的问题。通过分析LLMRec的注意力模式，研究人员发现早期层信息密集而后期层冗余，且注意力集中在序列首尾。基于这些发现，EARN在早期层将信息压缩到“寄存器令牌”中，并在后续层仅处理这些令牌。实验结果表明，EARN在保持甚至提高准确性的同时，实现了显著的推理加速（高达3.79倍）和KV缓存减少（80.8%），有效提升了LLMRec的效率和实用性。

> **摘要翻译:** 基于大型语言模型的生成式推荐（LLMRec）取得了显著成功，但由于巨大的计算开销和KV缓存的内存压力，它面临高推理延迟问题。现有的KV缓存减少方法面临关键局限性：考虑到推荐任务的短解码步长，缓存压缩提供的加速效果微乎其微，而提示压缩则有丢弃重要交互历史的风险。通过对LLMRec中注意力模式的系统分析，我们发现了两个关键洞察：1）层级注意力稀疏性反转，即早期层保留密集的有信息模式，而后期层表现出高冗余；2）双注意力汇聚现象，即注意力分数集中在输入序列的头部和尾部令牌上。受这些洞察的启发，我们提出了EARN，一个高效的推理框架，它利用早期层将信息压缩到放置在输入序列边界的寄存器令牌中，然后在后续层中仅关注这些令牌。在三个数据集、两种LLMRec方法和两种LLM架构上的广泛实验证明了EARN的优越性，实现了高达3.79倍的加速和80.8%的KV缓存减少，并且比通用微调方法具有更好的准确性。我们的工作弥合了LLMRec中的效率-有效性差距，为工业场景提供了实际部署优势。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [236] [WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks](https://arxiv.org/abs/2507.00938)
> *WebArXiv：评估多模态智能体在时间不变arXiv任务上的表现*

*Zihao Sun, Meng Fang, Ling Chen* | **Category: cs.IR, cs.AI, cs.DB, F.2.2; I.2.7**

**Keywords:** 网络智能体, 评估, 基准测试, arXiv, 动态反射

**Comment:** 10 pages, 9 figures, 4 tables

> **TL;DR:** 本文提出了WebArXiv，一个静态且时间不变的基准测试平台，用于评估自主网络智能体。该平台包含275个基于arXiv的任务，并引入了一种动态反射机制来解决智能体过度依赖固定历史的问题，实验证明了其有效性。

**AI_Comments:** 这项工作通过引入一个静态、时间不变的基准WebArXiv，对自主网络智能体的评估领域做出了重要贡献，解决了现有动态基准带来的评估不稳定性问题。此外，提出的动态反射机制针对智能体在决策中过度依赖历史的常见失败模式，提供了一种有效的解决方案，具有创新性。这对于推动网络智能体研究的可靠性和进展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估自主网络智能体的基准测试平台存在不稳定和不一致的问题，常常依赖于动态内容或过于简化的模拟，这使得评估具有挑战性。

**Method:** 本文引入了WebArXiv，一个静态且时间不变的基准测试平台，包含275个基于arXiv平台的网络任务。WebArXiv通过将任务固定在网络快照上，提供确定性真值和标准化动作轨迹，以确保可复现和可靠的评估。通过行为分析，发现智能体存在“僵化历史反射”的常见失败模式，即过度依赖固定的交互历史。为解决此问题，提出了一种轻量级动态反射机制，允许智能体在决策时选择性地检索相关的历史步骤。

**Result:** 在WebArXiv上评估了十种最先进的网络智能体，结果显示智能体之间存在明显的性能差异，并验证了所提出的反射策略的有效性。

**Conclusion:** 本文成功引入了一个静态且时间不变的基准测试平台WebArXiv，解决了现有网络智能体评估基准的不稳定问题，并提出了一种有效的动态反射机制来改善智能体的决策能力。

> **ai_Abstract:** 本文提出了一种名为WebArXiv的静态且时间不变的基准测试平台，旨在解决当前自主网络智能体评估中存在的基准不稳定和不一致问题。WebArXiv包含275个基于arXiv的web任务，通过固定网络快照和标准化轨迹确保评估的可复现性。研究发现智能体存在“僵化历史反射”的失败模式，并为此提出了一种动态反射机制。实验结果表明，该基准能有效区分不同智能体的性能，且所提出的反射机制能有效提升智能体表现。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展使得能够开发出能够导航和与真实网站交互的自主网络智能体。然而，由于现有基准测试的不稳定性和不一致性（这些基准通常依赖于动态内容或过度简化的模拟），评估此类智能体仍然具有挑战性。在这项工作中，我们引入了WebArXiv，一个静态且时间不变的基准测试平台，包含275个基于arXiv平台的网络任务。WebArXiv通过将任务锚定在固定的网络快照中，具有确定性真值和标准化的动作轨迹，从而确保了可复现和可靠的评估。通过行为分析，我们识别出一种常见的失败模式，即僵化历史反射（Rigid History Reflection），其中智能体过度依赖固定的交互历史。为了解决这个问题，我们提出了一种轻量级的动态反射机制，允许智能体在决策时选择性地检索相关的过去步骤。我们在WebArXiv上评估了十种最先进的网络智能体。结果表明，智能体之间存在明显的性能差异，并验证了我们提出的反射策略的有效性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [83] [SwarmFusion: Revolutionizing Disaster Response with Swarm Intelligence and Deep Learning](https://arxiv.org/abs/2507.00005)
> *SwarmFusion：利用群体智能和深度学习彻底改变灾害响应*

*Vasavi Lankipalle* | **Category: cs.NE, cs.LG**

**Keywords:** 群体智能, 深度学习, 灾害响应, 资源分配, 路径规划

**Comment:** 6

> **TL;DR:** SwarmFusion是一个结合粒子群优化和卷积神经网络的新型混合框架，旨在优化实时资源分配和路径规划，从而加速灾害响应并提高幸存者覆盖率。

**AI_Comments:** SwarmFusion的创新之处在于将群体智能（粒子群优化）与深度学习（卷积神经网络）结合，以解决灾害响应中的复杂优化问题。其通过实时数据处理和显著的性能提升（如更快的响应时间和更高的幸存者覆盖率）证明了其重要性，为时间敏感的危机管理提供了强大的新工具。该方法的通用性和可扩展性也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 灾害响应需要在混乱环境中进行快速、适应性决策，当前方法可能效率不足。

**Method:** SwarmFusion是一个混合框架，它将粒子群优化与卷积神经网络相结合，用于优化实时资源分配和路径规划。该系统处理实时卫星、无人机和传感器数据。

**Result:** 使用DisasterSim2025数据集进行的模拟显示，与基线方法相比，响应时间加快了40%，幸存者覆盖率达到了90%。

**Conclusion:** SwarmFusion提供了一种可扩展、数据驱动的变革性解决方案，用于时间敏感的灾害管理，并具有应用于各种危机场景的潜力。

> **ai_Abstract:** SwarmFusion是一个创新的混合框架，结合了粒子群优化和卷积神经网络，旨在通过处理实时数据来优化灾害响应中的资源分配和路径规划。它显著提高了洪水和野火场景下的态势感知和操作效率。模拟结果表明，该系统能将响应时间缩短40%，并将幸存者覆盖率提高到90%，为灾害管理提供了一个高效且可扩展的解决方案。

> **摘要翻译:** 灾害响应需要在混乱环境中进行快速、适应性决策。SwarmFusion是一个新型混合框架，它将粒子群优化与卷积神经网络相结合，以优化实时资源分配和路径规划。通过处理实时卫星、无人机和传感器数据，SwarmFusion在洪水和野火情景中增强了态势感知和操作效率。使用DisasterSim2025数据集进行的模拟显示，与基线方法相比，响应时间加快了40%，幸存者覆盖率达到了90%。这种可扩展、数据驱动的方法为时间紧迫的灾害管理提供了变革性解决方案，并具有应用于各种危机场景的潜力。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [104] [A Review on Zeroing Neural Networks](https://arxiv.org/abs/2507.00387)
> *零化神经网络综述*

*Chengze Jiang, Jie Gui, Long Jin, Shuai Li* | **Category: cs.NE**

**Keywords:** 零化神经网络, ZNNs, 时变优化, 控制问题, 综述

**Comment:** This is what we submitted to IJCAI 2023. Maybe we will update this
  paper in the future

> **TL;DR:** 本综述旨在系统理解零化神经网络（ZNNs）领域，涵盖其实现方法、分析理论和实际应用进展，以解决现有研究中缺乏对不同ZNNs之间关系和推导的阐释问题。

**AI_Comments:** 这篇综述论文的重要性在于填补了零化神经网络（ZNNs）领域中系统性理解的空白，尤其是在不同ZNNs之间的关系和推导方面。它为研究人员提供了一个全面的视角，有助于促进该领域的进一步发展和应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管零化神经网络（ZNNs）在时变优化和控制问题上表现出色，但现有研究很少阐明不同ZNNs之间的关系及其推导过程。因此，需要对该领域的进展进行回顾以实现系统性的理解。

**Method:** 本文通过调查零化神经网络（ZNNs）在实现方法、分析理论和实际应用方面的进展来提供综述。

**Result:** 本文对零化神经网络的实现方法、分析理论和实际应用方面的进展进行了全面的综述。

**Conclusion:** 本综述旨在为零化神经网络领域提供系统性的理解，通过回顾其在实现方法、分析理论和实际应用方面的进展，以填补现有研究的空白。

> **ai_Abstract:** 本文旨在对零化神经网络（ZNNs）进行全面综述，以解决现有研究中缺乏对不同ZNNs之间关系和推导的系统性阐释问题。该综述涵盖了ZNNs的实现方法、分析理论和实际应用进展，旨在促进对该领域的系统性理解。

> **摘要翻译:** 零化神经网络（ZNNs）在时变优化和控制问题上表现出卓越的性能。然而，很少有研究致力于阐明不同ZNNs之间的关系及其推导过程。因此，对该领域的进展进行回顾以实现系统性的理解是可取的。本文对ZNNs在实现方法、分析理论和实际应用方面的进展进行了调查。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [128] [Novel Complex-Valued Hopfield Neural Networks with Phase and Magnitude Quantization](https://arxiv.org/abs/2507.00461)
> *具有相位和幅度量化的新型复值Hopfield神经网络*

*Garimella Ramamurthy, Marcos Eduardo Valle, Tata Jagannadha Swamy* | **Category: cs.NE, cs.AI**

**Keywords:** 复值Hopfield神经网络, 相位量化, 幅度量化, 激活函数, 状态数量

**Comment:** Paper submitted to the Fifth International Conference on Emerging
  Techniques in Computational Intelligence (ICETCI 2025)

> **TL;DR:** 本研究引入了两种新型复值Hopfield神经网络（CvHNNs），它们结合了相位和幅度量化，显著增加了网络状态数量，从而扩展了应用范围。

**AI_Comments:** 该论文的创新点在于将相位和幅度量化引入复值Hopfield神经网络，并提出了基于直角和极坐标表示的两种新型激活函数。这种方法有效解决了现有模型状态数量有限的问题，显著提升了网络的容量，为CvHNNs的实际应用开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有复值Hopfield神经网络（CvHNNs）的状态数量有限，限制了其潜在应用范围。本研究旨在通过引入相位和幅度量化来增加CvHNNs的状态数量。

**Method:** 本研究提出了两种新型复值Hopfield神经网络（CvHNNs）。第一种CvHNN采用作用于复数净贡献的直角坐标表示的上限型激活函数。第二种CvHNN同样结合了相位和幅度量化，但使用基于复数净贡献的极坐标表示的上限型激活函数。

**Result:** 所提出的CvHNNs，通过相位和幅度量化，与现有模型相比显著增加了状态数量。

**Conclusion:** 所提出的具有相位和幅度量化的复值Hopfield神经网络通过增加状态数量，扩展了CvHNNs的潜在应用范围。

> **ai_Abstract:** 本研究提出两种新型复值Hopfield神经网络（CvHNNs），其核心创新在于引入了相位和幅度量化。其中一个模型利用直角坐标下的上限型激活函数，另一个则基于极坐标。通过这种设计，这些新型CvHNNs显著提升了网络的状态容量，远超现有模型，从而极大地拓宽了复值Hopfield神经网络的应用潜力。

> **摘要翻译:** 这篇研究论文介绍了两种结合了相位和幅度量化的新型复值Hopfield神经网络（CvHNNs）。第一种CvHNN采用作用于复数净贡献的直角坐标表示的上限型激活函数。第二种CvHNN同样结合了相位和幅度量化，但使用基于复数净贡献的极坐标表示的上限型激活函数。所提出的CvHNNs，通过其相位和幅度量化，与文献中现有模型相比显著增加了状态数量，从而扩展了CvHNNs的潜在应用范围。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [149] [High-resolution spatial memory requires grid-cell-like neural codes](https://arxiv.org/abs/2507.00598)
> *高分辨率空间记忆需要网格细胞样神经编码*

*Madison Cotteret, Christopher J. Kymn, Hugh Greatorex, Martin Ziegler, Elisabetta Chicca, Friedrich T. Sommer* | **Category: cs.NE, cs.AI, cs.SC**

**Keywords:** 连续吸引子网络, 网格细胞, 空间记忆, 稳定性, 分辨率

**Comment:** 14 pages, 4 figures. Supplementary material: 11 pages, 5 figures

> **TL;DR:** 本研究表明，使用网格细胞样编码的连续吸引子网络可以同时实现高稳定性和高分辨率的空间记忆，解决了传统模型中稳定性与分辨率之间的困境。

**AI_Comments:** 本文的创新点在于提出了将网格细胞样编码应用于连续吸引子网络，从而有效地解决了传统CANs在稳定性与分辨率之间存在的固有矛盾。这为理解大脑如何实现高精度和鲁棒的空间记忆提供了一个新的理论框架，并对神经计算模型的改进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 连续吸引子网络（CANs）在生物系统中对噪声和异质性非常敏感，导致稳定性与分辨率之间存在困境，即提高稳定性会降低所表示变量的分辨率。

**Method:** 研究人员调查了基于随机特征嵌入的稀疏二元分布式编码，其中神经元具有空间周期性感受野，即网格细胞样编码。

**Result:** 理论和模拟结果表明，这种网格细胞样编码使得连续吸引子网络能够同时实现高稳定性和高分辨率。该模型还可扩展到在CAN中嵌入任意非线性流形，并泛化线性路径整合。

**Conclusion:** 这项工作提供了一种理论，解释了大脑如何能够以高分辨率稳健地表示连续变量，并对与任务相关的流形进行灵活计算。

> **ai_Abstract:** 本研究解决了连续吸引子网络（CANs）在建模空间记忆时面临的稳定性与分辨率之间的困境。传统CANs对噪声敏感且在高分辨率下表现不佳。作者提出并研究了一种基于网格细胞样编码的稀疏二元分布式编码方案。理论和模拟结果表明，这种新编码方式能够使CANs同时实现高稳定性和高分辨率，并且模型能够泛化到任意非线性流形的嵌入和路径整合。

> **摘要翻译:** 连续吸引子网络（CANs）被广泛用于建模大脑如何通过持续的循环活动暂时保留连续的行为变量，例如动物在环境中的位置。然而，这种记忆机制对即使是微小的缺陷也非常敏感，例如噪声或异质性，而这两者在生物系统中都很常见。以前的工作表明，将连续体离散化为有限的离散吸引子状态可以增强对这些缺陷的鲁棒性，但必然会降低所表示变量的分辨率，从而在稳定性和分辨率之间产生了困境。我们发现，对于使用单峰凸起状编码的CANs（如传统模型），这种稳定性-分辨率困境最为严重。为了克服这个问题，我们研究了基于随机特征嵌入的稀疏二元分布式编码，其中神经元具有空间周期性感受野。我们通过理论和模拟证明，这种网格细胞样编码能够使CANs同时实现高稳定性和高分辨率。该模型扩展到在CAN中嵌入任意非线性流形，例如球面或环面，并将线性路径整合泛化为沿着自由可编程流形向量场的整合。总而言之，这项工作提供了一种理论，解释了大脑如何能够以高分辨率稳健地表示连续变量，并对与任务相关的流形进行灵活计算。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [106] [Localized evaluation and fast summation in the extrapolated regularization method for integrals in Stokes flow](https://arxiv.org/abs/2507.00156)
> *斯托克斯流积分外推正则化方法中的局部评估与快速求和*

*Joseph Siebor, Svetlana Tlupova* | **Category: math.NA, cs.NA**

**Keywords:** 外推正则化, 斯托克斯流, 边界积分方程, 快速求和, 核无关树码

**Comment:** 

> **TL;DR:** 本文通过并行化、局部评估和核无关树码等技术，显著降低了斯托克斯流中外推正则化方法计算近奇异积分的成本。

**AI_Comments:** 本文在先前工作的基础上，通过结合多种先进的数值计算优化技术（如并行化、局部化处理和快速多极方法/树码的变体），有效解决了近奇异积分在斯托克斯流模拟中计算效率低下的问题。其创新点在于将这些优化策略巧妙地整合到外推正则化方法中，特别是非局部组件的O(N^2)瓶颈通过核无关树码得到解决，这对于大规模模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 边界积分方程方法在求解偏微分方程中广泛应用，但其表面积分核在边界附近评估时接近奇异，导致直接数值积分结果不准确。此外，现有的外推正则化方法计算成本较高，尤其是非局部组件的计算是瓶颈（O(N^2)）。

**Method:** 本文提出了几种降低外推正则化方法计算成本的技术：1. 对目标点进行OpenMP并行化。2. 利用正则化效果的局部性，仅对局部组件进行多次评估，而非局部组件仅评估一次并重复使用。3. 对非局部（远场）相互作用应用核无关树码以减少CPU时间。

**Result:** 通过实验确定了在精度和效率方面的最佳参数。成功将这些技术应用于计算两个几乎接触的球体周围的斯托克斯流。

**Conclusion:** 本文提出的技术显著降低了斯托克斯流中外推正则化方法计算近奇异积分的计算成本，提高了其效率和实用性。

> **ai_Abstract:** 边界积分方程方法在处理偏微分方程中的近奇异表面积分时面临精度和计算成本挑战。此前，外推正则化方法被提出以提高精度。本文在此基础上，引入了多种优化技术以降低其计算成本，包括OpenMP并行化、利用正则化局部性分离局部与非局部组件，以及对远场相互作用应用核无关树码。通过实验确定了最佳参数，并成功应用于模拟近接触球体的斯托克斯流，显著提升了该方法的计算效率。

> **摘要翻译:** 边界积分方程方法广泛应用于许多偏微分方程的求解中。当在边界附近评估时，这些表面积分中出现的核几乎是奇异的，直接的数值积分会产生不准确的结果。在Beale和Tlupova（Adv. Comput. Math, 2024）中，提出了一种外推正则化方法，用于精确评估谐波势或斯托克斯流的近奇异单层和双层表面积分。该方法使用平滑参数对核进行正则化，然后应用标准正交。对三种平滑参数选择计算积分，以找到达到五阶精度的外推值。在这项工作中，我们应用了几种技术来降低应用于斯托克斯单层和双层积分的外推正则化方法的计算成本。首先，我们对目标点使用直接的OpenMP并行化。其次，我们注意到正则化的效果是局部的，并且仅对三种平滑参数值评估和的局部组件。和的非局部组件仅评估一次并在其他和中重复使用。这个组件仍然是计算瓶颈，因为它与系统大小N呈O(N^2)关系。我们将核无关树码应用于这些远场相互作用，以减少CPU时间。我们进行了实验以确定在计算精度和效率方面的最佳参数。然后，我们使用这些技术来计算两个几乎接触的球体周围的斯托克斯流。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [130] [An energy-stable parametric finite element method for Willmore flow with normal-tangential velocity splitting](https://arxiv.org/abs/2507.00193)
> *具有法向-切向速度分解的Willmore流能量稳定参数有限元方法*

*Harald Garcke, Robert Nürnberg, Quan Zhao* | **Category: math.NA, cs.NA, 65M60, 65M15, 65M12, 35R01**

**Keywords:** Willmore流, 能量稳定, 参数有限元方法, 法向-切向速度分解, 几何PDE

**Comment:** 

> **TL;DR:** 本文提出了一种能量稳定的全离散参数有限元方法，用于模拟具有自发曲率效应和边界的Willmore流。该方法基于新的几何偏微分方程和弱公式，保证了无条件能量稳定性，并通过数值实验验证了其准确性和鲁棒性。

**AI_Comments:** 本文的创新点在于提出了一个新的几何PDE和相应的弱公式，通过法向-切向速度分解机制，成功实现了Willmore流模拟的无条件能量稳定性，这对于确保数值计算的长期稳定性和可靠性至关重要。此外，该方法考虑了自发曲率效应和开放曲面边界，显著扩展了Willmore流数值模拟的适用范围和实用性。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 本文提出了一种新的几何偏微分方程（PDE），通过结合平均曲率演化方程和切向速度方程，实现了法向-切向速度分解。该方法利用平均曲率确定法向速度，以保证离散解的无条件能量稳定性。此外，引入了新的弱公式，并在此基础上构建了全离散参数有限元方法。

**Result:** 该方法能够严格证明其适定性，并且在离散能量方面具有无条件稳定性估计。大量的数值实验表明，该方法在计算$\mathbb{R}^2$中的曲线和$\mathbb{R}^3$中的曲面Willmore流时表现出良好的准确性和鲁棒性。

**Conclusion:** 本文成功提出并分析了一种能量稳定的全离散参数有限元方法，用于模拟带有自发曲率效应和边界的Willmore流。该方法在理论上具有适定性和无条件能量稳定性，并已通过广泛的数值实验验证了其在实际应用中的准确性和鲁棒性。

> **ai_Abstract:** 本文提出了一种能量稳定的全离散参数有限元方法，用于模拟带有自发曲率和边界的超曲面Willmore流。该方法核心在于引入了一个新的几何PDE，通过法向-切向速度分解确保了离散解的无条件能量稳定性。通过构建新颖的弱公式并进行离散化，该方法在理论上证明了适定性及无条件稳定性，并通过广泛的数值实验验证了其在二维和三维Willmore流计算中的准确性和鲁棒性。

> **摘要翻译:** 我们提出并分析了一种能量稳定的全离散参数近似方法，用于二维和三维空间中超曲面的Willmore流。我们允许存在自发曲率效应以及带有边界的开放曲面。所提出的方案基于一个新的几何偏微分方程（PDE），该方程结合了平均曲率的演化方程和另一个规定切向速度的独立方程。平均曲率用于在梯度流结构中确定法向速度，从而在适当离散后保证离散解的无条件能量稳定性。我们为该几何PDE引入了一种新颖的弱公式，其中可以自然地施加不同类型的边界条件。我们进一步离散化了弱公式，以获得一种全离散参数有限元方法，其适定性可以严格证明。此外，所构建的方案在离散能量方面具有无条件稳定性估计。报告了大量的数值实验，以展示所提出的方法在计算$\mathbb{R}^2$中的曲线和$\mathbb{R}^3$中的曲面Willmore流时的准确性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [151] [Error Etimates for Non Conforming Discretisation of Time-dependent Convection-Diffusion-Reaction Model](https://arxiv.org/abs/2507.00219)
> *时变对流-扩散-反应模型非协调离散的误差估计*

*Hasan Alzubaidi, Yahya Alnashri* | **Category: math.NA, cs.NA**

**Keywords:** 梯度离散方法, 对流-扩散-反应模型, 收敛速率, 非协调离散, 数值分析

**Comment:** 

> **TL;DR:** 本文利用梯度离散方法（GDM）对时变对流-扩散-反应模型进行了统一的数值分析，并建立了收敛速率的新结果，通过数值实验验证了理论收敛率。

**AI_Comments:** 本文的创新点在于提出了一个通用的梯度离散方法（GDM）框架，实现了对时变对流-扩散-反应模型的统一数值分析。其重要性在于不仅建立了严格的理论收敛性、存在性和唯一性证明，还通过广泛的数值实验验证了其在复杂网格（包括极端扭曲网格）上的准确性和鲁棒性，拓展了该方法在多种近似方法和具体模型中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 为时变对流-扩散-反应模型提供统一的数值分析框架。

**Method:** 采用梯度离散方法（GDM）进行统一的数值分析，并使用混合拟态混合（HMM）方法对广义Burgers-Fisher（GBF）模型进行数值测试。

**Result:** 建立了数值近似收敛速率的新结果，证明了在适当小的时间步长下近似解的存在性和唯一性。数值测试（在各种通用网格上）证实了理论收敛率，即使在极端扭曲的网格上也是如此。该方法适用于多种近似方法和模型，如广义Burgers-Fisher (GBF) 和广义Burgers-Huxley (GBH) 模型。

**Conclusion:** 本文提出的基于梯度离散方法的数值分析框架，能够对时变对流-扩散-反应模型进行统一分析，并提供了具有理论保障的收敛性结果，通过数值验证证明了其在复杂网格上的准确性和鲁棒性。

> **ai_Abstract:** 本文利用梯度离散方法（GDM）为时变对流-扩散-反应模型提供了统一的数值分析框架。研究建立了数值近似的收敛速率结果，并证明了近似解的存在性和唯一性。该方法适用于广义Burgers-Fisher和广义Burgers-Huxley等模型。数值实验，特别是使用混合拟态混合（HMM）方法在各种网格上对广义Burgers-Fisher模型进行的测试，验证了理论收敛率，即使在高度扭曲的网格上也能保持准确性。

> **摘要翻译:** 我们使用一个通用框架，即梯度离散方法（GDM），对一般时变对流-扩散-反应模型提出统一的数值分析。我们在对精确解进行合理假设的前提下，建立了此类模型数值近似收敛速率的新结果，并证明了在适当小的时间步长下近似解的存在性和唯一性。我们结果的主要兴趣在于涵盖了几种近似方法和所考虑模型的各种应用，例如广义Burgers-Fisher（GBF）和广义Burgers-Huxley（GBH）模型。基于GBF模型的混合拟态混合（HMM）方法在各种类型的通用网格上进行了数值测试，以检验所提出的梯度方案的准确性。结果证实了我们的理论收敛率，即使在具有极端扭曲的网格上也是如此。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [172] [Minimal residual rational Krylov subspace method for sequences of shifted linear systems](https://arxiv.org/abs/2507.00267)
> *针对移位线性系统序列的最小残差有理Krylov子空间方法*

*Hussam Al Daas, Davide Palitta* | **Category: math.NA, cs.NA**

**Keywords:** 最小残差, 有理Krylov子空间, 移位线性系统, 复数移位, 极点选择

**Comment:** 

> **TL;DR:** 提出一种新的最小残差有理Krylov子空间方法和极点选择策略，用于高效求解移位线性系统序列，尤其在处理非对称复数移位问题上优于现有技术。

**AI_Comments:** 这项工作通过引入新的投影策略和定制的极点选择过程，解决了移位线性系统序列中一个特别棘手的问题，即非对称复数移位的情况。其创新性在于对有理Krylov子空间方法的改进，特别是在极点选择上的优化，这对于加速收敛至关重要。该研究对于数值线性代数领域，特别是解决特定类型的移位系统问题，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 求解移位线性系统序列是数值线性代数中的经典问题，但现有方法在处理移位为非共轭复数的非对称问题时表现不佳，缺乏有效的求解器。

**Method:** 本研究设计了一种基于有理Krylov子空间并配备最小残差条件的新型投影策略。同时，还开发了一种针对该问题量身定制的新型极点选择过程，该过程为有理Krylov基构造提供了比现有通用方案收敛更快的极点。

**Result:** 大量数值实验表明，该新方法比现有最先进技术表现更好，尤其在处理上述非常具有挑战性的问题时效果显著。

**Conclusion:** 该研究成功开发了一种新的最小残差有理Krylov子空间方法，结合创新的极点选择过程，有效解决了传统方法难以处理的特定移位线性系统问题，并在性能上超越了现有技术。

> **ai_Abstract:** 本论文提出了一种新的最小残差有理Krylov子空间方法，旨在解决现有技术在处理非共轭复数移位的非对称线性系统序列时面临的挑战。该方法引入了一种新颖的投影策略，并开发了一种专门的极点选择过程，该过程能够为有理Krylov基提供更快的收敛极点。数值实验证明，该方法在处理复杂问题方面优于现有最先进技术。

> **摘要翻译:** 移位线性系统序列的解是数值线性代数中的一个经典问题，多年来已经提出了各种有效的解法。然而，仍然存在一些具有挑战性的场景，缺乏高性能的求解器。例如，当移位是作为非共轭对出现的复数时，最先进的程序难以处理非对称问题。我们设计了一种基于有理Krylov子空间并配备最小残差条件的新型投影策略。我们还设计了一种针对我们问题量身定制的新型极点选择过程，为有理Krylov基构造提供了比现有通用方案计算出的极点收敛更快的极点。一系列不同的数值实验表明，我们的新方法比最先进的技术表现更好，尤其是在上述非常具有挑战性的问题上。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [189] [Automatic discovery of optimal meta-solvers for time-dependent nonlinear PDEs](https://arxiv.org/abs/2507.00278)
> *时变非线性偏微分方程最优元求解器自动发现*

*Youngkyu Lee, Shanqing Liu, Jerome Darbon, George Em Karniadakis* | **Category: math.NA, cs.NA**

**Keywords:** 元求解器, 非线性偏微分方程, 深度学习, 多目标优化, 数值方法

**Comment:** 

> **TL;DR:** 本文提出一个通用可扩展框架，通过结合经典数值方法和深度学习组件，自动发现求解时变非线性偏微分方程的最优元求解器，该方法在多个领域表现优于传统方法。

**AI_Comments:** 这项研究的创新之处在于将经典数值方法与现代深度学习技术相结合，以实现PDE求解器的自动化发现和优化。通过多目标优化来平衡性能标准，为特定问题量身定制最优求解器提供了新颖且实用的方法，显著提升了求解效率和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为时变非线性偏微分方程（PDEs）自动发现最优的元求解器，以实现灵活、按需的求解器设计，并平衡精度、速度和内存使用等多种性能标准。

**Method:** 该方法整合了经典数值方法（如Krylov方法）与现代深度学习组件（如神经算子），并将求解器发现问题表述为一个多目标优化问题，旨在平衡准确性、速度和内存使用。通过Newton-Raphson迭代或隐式-显式（IMEX）时间积分方案处理大型线性系统，并利用帕累托最优集为用户定义偏好函数提供求解器选择基础。

**Result:** 在反应-扩散、流体动力学和固体力学等问题中，所发现的元求解器始终优于传统的迭代方法，展现出实际效率和广泛适用性。

**Conclusion:** 该框架成功地为时变非线性偏微分方程发现了最优的元求解器，这些求解器在多个应用领域表现出优于传统方法的性能，具有灵活性和高效率。

> **ai_Abstract:** 本文提出一种通用可扩展框架，用于自动发现求解时变非线性偏微分方程的最优元求解器。该方法结合了传统数值方法（如Krylov方法）和现代深度学习组件（如神经算子），并将求解器发现建模为多目标优化问题，以平衡精度、速度和内存。实验结果表明，在反应-扩散、流体动力学和固体力学等领域，所发现的元求解器性能显著优于传统迭代方法，展现出高效率和广泛适用性。

> **摘要翻译:** 我们提出了一个通用且可扩展的框架，用于在适当离散化后自动发现求解时变非线性偏微分方程的最优元求解器。通过将经典数值方法（例如，基于Krylov的方法）与现代深度学习组件（例如，神经算子）相结合，我们的方法能够实现灵活的、按需的求解器设计，以适应特定的问题类别和目标。快速求解器处理由Newton-Raphson迭代或使用隐式-显式（IMEX）时间积分方案产生的大型线性系统。具体来说，我们将求解器发现表述为一个多目标优化问题，平衡了准确性、速度和内存使用等各种性能标准。由此产生的帕累托最优集为基于用户定义偏好函数的求解器选择提供了原则性基础。当应用于反应-扩散、流体动力学和固体力学等问题时，所发现的元求解器始终优于传统的迭代方法，展示了实际效率和广泛适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [208] [Adaptive finite element convergence analysis of AT1 phase-field model for quasi-static fracture in strain-limiting solids](https://arxiv.org/abs/2507.00376)
> *应变限制固体中准静态断裂的AT1相场模型自适应有限元收敛性分析*

*Ram Manohar, S. M. Mallikarjunaiah* | **Category: math.NA, cs.NA**

**Keywords:** 自适应有限元, 相场模型, 准静态断裂, 收敛性分析, 应变限制固体

**Comment:** arXiv admin note: text overlap with arXiv:2505.19801

> **TL;DR:** 本研究严格考察了弹性固体中准静态脆性断裂正则化变分模型自适应有限元方法的收敛性，特别是针对AT1相场模型。提出了两种新型自适应网格细化算法，并证明了其收敛性，其中第二种算法无需明确的停止准则。

**AI_Comments:** 这项研究在处理准静态脆性断裂的相场模型方面具有创新性，通过引入两种新型自适应算法，特别是非停止准则的第二种算法，显著提高了计算效率和收敛性保证。这对于数值模拟断裂力学问题，尤其是在非线性材料行为下，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在严格考察弹性固体中准静态脆性断裂正则化变分模型（特别是具有代数非线性应力-应变关系的材料模型中的Ambrosio-Tortorelli (AT1) 相场模型）自适应有限元方法的收敛性。

**Method:** 本研究引入了两种基于鲁棒局部误差指示器的新型自适应网格细化算法，用于高效求解潜在的非线性能量最小化问题。对这些策略产生的最小化序列进行了详细的收敛性分析，并通过广泛的数值模拟和案例研究验证了所提出自适应框架的实际有效性。

**Result:** 第一种自适应算法的最小化序列被严格证明能收敛到预设的容差。第二种算法被证明能生成固有的收敛序列，从而消除了对明确停止准则的需求。数值模拟和能量分量（体能、表面能和总能）的比较展示了两种自适应算法的卓越性能。

**Conclusion:** 本研究提出的两种自适应有限元算法在处理应变限制固体中准静态断裂的AT1相场模型时，表现出优越的收敛性和实用性。特别是第二种算法能生成固有收敛序列，无需明确的停止准则，这对于提高计算效率和稳定性具有重要意义。

> **ai_Abstract:** 本研究深入探讨了应变限制固体中准静态断裂的AT1相场模型自适应有限元方法的收敛性。论文提出了两种新型的自适应网格细化算法，并对其最小化序列进行了严格的收敛性分析。结果表明，第一种算法能实现预设容差收敛，而第二种算法能生成固有收敛序列，无需明确停止准则。广泛的数值模拟验证了该自适应框架的有效性和优越性。

> **摘要翻译:** 本研究严格考察了弹性固体中准静态脆性断裂正则化变分模型自适应有限元方法的收敛性。我们特别在弹性理论框架内，针对以代数非线性应力-应变关系为特征的材料模型，研究了一种新颖的Ambrosio-Tortorelli (AT1) 相场模型。引入了两种独特而新颖的自适应网格细化算法，它们以鲁棒的局部误差指示器为基础，以有效地解决潜在的非线性能量最小化问题。对这些策略产生的最小化序列进行了详细的收敛性分析。我们的研究结果严格证明了第一种自适应算法的最小化序列达到了预设的容差收敛。至关重要的是，第二种算法被证明能生成固有的收敛序列，从而消除了对明确停止准则的需求。所提出的自适应框架的实际有效性通过广泛的数值模拟得到了彻底验证。提出了一个涉及弹性体中边缘裂纹的案例研究，该裂纹由代数非线性应变限制关系控制并受到反平面剪切型载荷。对能量分量——体能、表面能和总能——的关键比较展示了两种自适应算法的卓越性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [222] [The Fourier spectral approach to the spatial discretization of quasilinear hyperbolic systems](https://arxiv.org/abs/2507.00516)
> *拟线性双曲系统空间离散化的傅里叶谱方法*

*Vincent Duchêne, Johanna Ulvedal Marstrander* | **Category: math.NA, cs.NA, math.AP, 65M12, 65M70, 76M22**

**Keywords:** 傅里叶谱方法, 拟线性双曲系统, 空间离散化, 稳定性估计, 谱收敛

**Comment:** 30 pages, 7 figures. Figures are reproducible using the Julia package
  WaterWaves1D at https://github.com/WaterWavesModels/WaterWaves1D.jl

> **TL;DR:** 本文讨论了傅里叶谱方法对拟线性双曲系统空间离散化的严格论证，提供了均匀稳定性估计以保证谱收敛，并比较了尖锐和光滑低通滤波器，指出后者理论上适用于更广泛的系统，但也提到了尚未有理论解释的数值行为。

**AI_Comments:** 该论文在傅里叶谱方法应用于拟线性双曲系统的空间离散化方面提供了重要的理论贡献，特别是通过严格的稳定性估计证明了谱收敛性。对尖锐和光滑低通滤波器的比较分析，揭示了光滑滤波器在理论上的优势，具有指导意义。然而，论文也坦诚地指出了数值结果中存在的理论空白，这为未来的研究提供了明确的方向，体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 为拟线性一阶双曲系统的傅里叶谱方法空间离散化提供严格的理论依据，并探究不同低通滤波器对其性能的影响。

**Method:** 通过傅里叶谱方法对拟线性一阶双曲系统进行空间离散化。研究中考虑了两种设置：带有尖锐低通滤波器和带有光滑低通滤波器的情况。

**Result:** 提供了统一的稳定性估计，证明了（空间）半离散化解向相应连续解的谱收敛性，前提是底层系统满足一些合适的结构假设。理论上，光滑低通滤波器可操作于更广泛的系统类别。数值证据支持了理论结果，但也发现了一些目前没有理论解释的数值行为。

**Conclusion:** 本文为拟线性双曲系统的傅里叶谱空间离散化提供了严格的理论证明，并揭示了光滑低通滤波器在理论上具有更广泛的适用性。尽管有数值证据支持，但仍存在部分数值现象缺乏理论解释。

> **ai_Abstract:** 本文对拟线性一阶双曲系统采用傅里叶谱方法进行空间离散化提供了严格的理论论证。研究给出了统一的稳定性估计，证明了半离散化解的谱收敛性。通过比较尖锐和光滑低通滤波器，文章指出光滑滤波器在理论上能应用于更广泛的系统。尽管有数值支持，但论文也指出了数值模拟中一些尚未得到理论解释的现象。

> **摘要翻译:** 我们讨论了拟线性一阶双曲系统通过傅里叶谱方法进行空间离散化的严格论证。我们提供了统一的稳定性估计，这些估计保证了（空间）半离散化解向相应连续解的谱收敛性，前提是底层系统满足一些合适的结构假设。我们考虑了带有尖锐低通滤波器和带有光滑低通滤波器两种设置，并论证了——至少在理论上——光滑低通滤波器可以在更广泛的系统类别上运行。虽然我们的理论结果得到了数值证据的支持，但我们也指出了数值方法中一些目前没有理论解释的行为。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [237] [An inverse-free fixed-time stable dynamical system and its forward-Euler discretization for solving generalized absolute value equations](https://arxiv.org/abs/2507.00531)
> *一种无逆固定时间稳定动力系统及其求解广义绝对值方程的前向欧拉离散化方法*

*Xuehua Li, Linjie Chen, Dongmei Yu, Cairong Chen, Deren Han* | **Category: math.NA, cs.NA, math.OC**

**Keywords:** 广义绝对值方程, 固定时间稳定, 动力系统, 前向欧拉离散化, 迭代方法

**Comment:** 14 pages

> **TL;DR:** 提出了一种无逆固定时间稳定动力系统及其前向欧拉离散化方法，用于在有限时间内求解广义绝对值方程。

**AI_Comments:** 该研究的创新之处在于提出了一种“无逆”且“固定时间稳定”的动力系统来解决广义绝对值方程，这意味着算法在理论上具有更优的收敛性能和鲁棒性。前向欧拉离散化方法的引入，将连续系统转化为可实际操作的迭代算法，并给出了严格的收敛性保证，这对于数值计算具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决广义绝对值方程 (GAVE) 的问题，旨在提供一种在固定时间内收敛且收敛时间有界的求解方法。

**Method:** 提出了一种无逆固定时间稳定的动力系统来求解GAVE。此外，通过该动力模型的前向欧拉离散化，开发了一种迭代方法。

**Result:** 所提出的动力系统能在固定时间内收敛，且收敛时间对所有初始点均匀有界。离散迭代方法在有限步内全局收敛到GAVE唯一解的任意小邻域，并给出了保证收敛的充分条件。

**Conclusion:** 通过无逆固定时间稳定动力系统及其前向欧拉离散化，可以有效地在固定时间内求解广义绝对值方程，并确保离散迭代的全局收敛性。

> **ai_Abstract:** 本论文提出了一种新的无逆固定时间稳定动力系统，旨在解决广义绝对值方程（GAVE）的求解问题。该系统确保了在固定时间内收敛，且收敛时间对所有初始点都是均匀有界的。在此基础上，通过对该动力模型进行前向欧拉离散化，开发了一种迭代方法，并给出了保证该离散迭代在有限步内全局收敛到GAVE唯一解任意小邻域的充分条件。

> **摘要翻译:** 提出了一种无逆动力系统，用于在固定时间内求解广义绝对值方程（GAVE），其中收敛时间是有限的，并且对所有初始点都均匀有界。此外，通过对所提出的动力模型进行前向欧拉离散化，开发了一种迭代方法，并给出了保证离散迭代在有限步内全局收敛到GAVE唯一解的任意小邻域的充分条件。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [249] [Isogeometric contact analysis in subsea umbilical and power cables](https://arxiv.org/abs/2507.00563)
> *水下脐带缆和电力电缆中的等几何接触分析*

*Tianjiao Dai, Shuo Yang, Xing Jin, Svein Sævik, Jiaxuan Zhang, Jun Wu, Naiquan Ye* | **Category: math.NA, cs.NA**

**Keywords:** 等几何分析, 接触分析, 水下脐带缆, 电力电缆, 有限元方法

**Comment:** 

> **TL;DR:** 论文提出并验证了一种等几何分析 (IGA) 方法，用于解决水下脐带缆和电力电缆中复杂的接触问题，提高了接触分析的精度和效率。

**AI_Comments:** 这篇论文通过引入等几何分析（IGA）来解决水下脐带缆和电力电缆中复杂的接触问题，具有重要的创新性。IGA的优势在于能够更精确地描述几何形状，从而提高接触分析的精度和效率，这对于涉及敏感接触参数的应力分析至关重要。将算法在MATLAB中实现并与ABAQUS进行验证，增强了其实用性和可信度。对影响IGA性能的参数（如单元细化、几何描述、罚因子）的讨论，也为未来的应用和优化提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 传统分析方法和有限元方法在水下脐带缆和电力电缆的复杂接触界面分析中存在挑战，无法准确高效地考虑接触表面特性，而这些特性是应力分析中最敏感的参数。因此，需要一种新颖的方法来提高接触分析的精度和效率。

**Method:** 本文提出了一种等几何分析（IGA）方法来解决动态脐带缆和电力电缆中的接触问题。该等几何接触算法首先在MATLAB中实现，作为一个包含几何描述、接触检测和罚函数工具。其次，利用该IGA算法建立了动态脐带缆中钢管和外护套之间的接触界面，并与ABAQUS的结果进行对比验证，以证明IGA的准确性和效率。最后，讨论了单元细化、几何描述、罚因子对IGA精度、效率和稳定性的影响。

**Result:** 通过与ABAQUS的验证，证明了等几何分析（IGA）方法在处理水下脐带缆接触问题上的准确性和效率。研究还讨论了单元细化、几何描述和罚因子对IGA精度、效率和稳定性的影响。

**Conclusion:** 等几何分析（IGA）方法是解决水下脐带缆和电力电缆中复杂接触问题的一种有效且更精确高效的新方法。

> **ai_Abstract:** 本文针对传统方法在水下脐带缆和电力电缆接触分析中存在的精度和效率问题，提出了一种基于等几何分析（IGA）的新方法。该方法在MATLAB中实现，包含几何描述、接触检测和罚函数，并通过与ABAQUS的对比验证，证明了其在分析钢管与外护套接触界面时的准确性和效率。研究还探讨了单元细化、几何描述和罚因子对IGA性能的影响。

> **摘要翻译:** 水下脐带缆和电力电缆包含大量不同几何形状和材料之间的接触界面。这些复杂的相互作用给传统分析解决方案或有限元方法准确考虑接触表面特性带来了重大挑战。这些特性已被确定为进行应力分析数值模拟时最敏感的参数。因此，应用一种新颖的接触分析方法来提高预测接触特性的精度和效率至关重要。本文提出了一种等几何分析（IGA）方法来解决动态脐带缆和电力电缆中的接触问题。首先，该等几何接触算法在MATLAB中被公式化为一个工具，包括几何描述、接触检测和罚函数。其次，通过该IGA接触算法建立了动态脐带缆中钢管和外护套之间的接触界面，并与ABAQUS中的结果进行验证，以证明IGA的准确性和效率。最后，讨论了单元细化、几何描述、罚因子对IGA精度、效率和稳定性的影响。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [262] [High order global flux schemes for general steady state preservation of shallow water moment equations with non-conservative products](https://arxiv.org/abs/2507.00573)
> *浅水矩量方程非保守项一般稳态保持的高阶全局通量格式*

*Mirco Ciallella, Julian Koellermeier* | **Category: math.NA, cs.NA**

**Keywords:** 全局通量格式, 浅水矩量方程, 稳态保持, 非保守项, WENO方法

**Comment:** 

> **TL;DR:** 本文提出了一种高阶全局通量WENO有限体积方法，用于处理浅水矩量方程等具有非保守项的通用双曲平衡律，即使没有解析稳态，也能保持稳态，并在数值测试中显示出优越的性能和灵活性。

**AI_Comments:** 本文的主要创新在于提出了基于全局通量方法的完全良好平衡高阶WENO有限体积方案，解决了在没有解析稳态的情况下，浅水矩量方程等具有非保守项的系统稳态保持的难题。这种方法通过重建全局通量而非保守变量来确保稳态的精确保持，这对于工程和物理模拟具有重要意义。其灵活性和在无稳态先验知识情况下的适用性是其突出优点。

<details>
  <summary>Details</summary>

**Motivation:** 浅水矩量方程作为自由表面流动的降阶模型，引入了非线性非保守项，使得稳态的解析表征变得极其困难甚至不可能。缺乏解析稳态对设计旨在保持稳态的良好平衡格式构成了挑战，而稳态在许多应用中至关重要。

**Method:** 本文提出了一种完全良好平衡的高阶WENO有限体积方法家族，适用于浅水矩量方程等具有非保守项的通用双曲平衡律。该方案基于通量全局化方法，其中源项和非保守项都通过定制的高阶求积集成到散度项中。然后，重建得到的全局通量而不是保守变量，以保持所有稳态。

**Result:** 数值测试表明，该方法具有最优收敛性，并显著降低了稳态解的误差。此外，对不同类型的浅水矩量方程的扰动稳态进行了数值比较，这表明该方法具有灵活性，适用于无需稳态先验知识的通用方程。

**Conclusion:** 本研究提出的高阶全局通量方案能够有效处理浅水矩量方程等具有非保守项的系统，即使没有解析稳态，也能实现稳态保持。该方法具有最优收敛性和显著的误差降低，并且对通用方程具有良好的灵活性。

> **ai_Abstract:** 本文提出了一种高阶全局通量WENO有限体积方法，用于解决浅水矩量方程等具有非保守项的双曲平衡律在缺乏解析稳态时保持稳态的挑战。该方法通过将源项和非保守项集成到散度项中并重建全局通量来实现稳态保持。数值实验证明了该方法的最优收敛性、稳态解的显著误差降低以及对通用方程的普适性。

> **摘要翻译:** 浅水矩量方程是自由表面流动的降阶模型，它允许以增加额外变量（即矩）的演化方程为代价来表示速度剖面的垂直变化。这在系统中引入了非线性非保守项，使得稳态的解析表征变得更加困难甚至不可能。缺乏解析稳态对设计良好平衡格式构成了挑战，而良好平衡格式旨在保持稳态，这在许多应用中至关重要。在这项工作中，我们提出了一系列完全良好平衡的高阶WENO有限体积方法，用于处理具有非保守项的通用双曲平衡律，如浅水矩量方程，即使没有解析稳态。这些方案基于通量全局化方法，其中源项和非保守项都通过定制的高阶求积集成到散度项中。然后，重建得到的全局通量而不是保守变量，以保持所有稳态。数值测试表明该方法具有最优收敛性，并显著降低了稳态解的误差。此外，我们提供了不同类型浅水矩量方程的扰动稳态的数值比较，这说明了我们方法的灵活性，它适用于无需稳态先验知识的通用方程。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [272] [Accelerating MPGP-type Methods Through Preconditioning](https://arxiv.org/abs/2507.00617)
> *通过预处理加速MPGP型方法*

*Jakub Kružík, David Horák* | **Category: math.NA, cs.NA, math.OC, 47N10, 65K10, G.1.6**

**Keywords:** MPGP型算法, 预处理, 二次规划, 面内预处理, 加速

**Comment:** 

> **TL;DR:** 本文研究了一种近似的预处理方法，用于加速MPGP型算法求解二次规划问题，并在数值实验中展示了显著的加速效果。

**AI_Comments:** 这项工作提出了一种通过近似预处理来提高MPGP型算法效率的新方法，其创新点在于将内部预处理器的计算次数从多次减少到一次，这对于大型或动态变化的二次规划问题可能具有重要意义，因为它能显著减少计算开销。

<details>
  <summary>Details</summary>

**Motivation:** 加速MPGP型算法以解决二次规划问题。

**Method:** 本研究探讨了使用预处理加速MPGP型算法。预处理仅在自由集上进行，以避免改变约束。文章提出了一种“面内预处理”的近似变体，其特点是内部预处理器只需计算一次，而不是在每次自由集改变时都重新计算或更新。研究分析了该近似变体的误差，并通过数值实验进行了验证。

**Result:** 数值实验表明，该近似变体可以实现非常大的加速。

**Conclusion:** 通过引入一种仅需计算一次内部预处理器的近似“面内预处理”方法，可以显著加速MPGP型算法，从而有效解决二次规划问题。

> **ai_Abstract:** 本文研究了通过预处理加速二次规划问题的MPGP型算法。针对每次自由集变化都需要重新计算内部预处理器的“面内预处理”方法，提出了一种只需计算一次内部预处理器的近似变体。研究分析了该近似变体的误差，并通过数值实验证明了其能显著提升算法速度。

> **摘要翻译:** 本工作研究了使用预处理加速MPGP型算法以解决二次规划问题。预处理只需在自由集上进行，以免改变约束。一种仅限于自由集的预处理变体是面内预处理。面内预处理中的内部预处理器需要在每次自由集改变时重新计算或更新。在此，我们研究了一种面内预处理的近似变体，它只计算一次内部预处理器。我们分析了该近似变体的误差，并提供了数值实验，证明该近似变体可以实现非常大的加速。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [281] [Special measures of smoothness for approximation by sampling operators in $L_p(\Bbb{R}^d)$](https://arxiv.org/abs/2507.00667)
> *《$L_p(\Bbb{R}^d)$空间中采样算子逼近的特殊光滑度测度》*

*Yurii Kolomoitsev* | **Category: math.NA, cs.NA, math.CA, 41A05, 41A15, 41A17, 41A25, 41A27**

**Keywords:** 光滑度测度, 采样算子, $L_p$空间, 误差估计, 逼近理论

**Comment:** 

> **TL;DR:** 本文引入了一种改进的光滑度测度，以提高采样或插值算子在$L_p$空间中对低光滑度函数的逼近误差估计的准确性，并获得了匹配的直接和逆误差估计。

**AI_Comments:** 这项工作在逼近理论领域具有重要意义，特别是在$L_p$空间中处理采样算子和低光滑度函数时。引入新的光滑度测度是其创新点，它能够提供更准确的误差估计，并为理解采样算子的行为提供了更深入的视角。文章不仅提出了理论框架，还通过具体算子验证了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的平滑度度量在采样或插值算子逼近中，尤其对于低平滑度函数，往往无法提供准确的$L_p$误差估计。

**Method:** 引入了一种结合采样点局部行为的修正光滑度测度，通过使用平均算子来实现。

**Result:** 获得了广泛采样算子和$L_p$空间中函数的匹配直接和逆误差估计；推导了$L_p$中采样算子收敛的判据；确定了确保精确逼近率的条件；构建了基于这些算子的K-泛函实现；研究了采样算子的平滑度性质；并将其结果应用于惠特克-香农采样算子、B样条生成的采样算子和基于高斯函数的采样算子等。

**Conclusion:** 通过引入新的光滑度测度，成功解决了传统方法在$L_p$误差估计中的不足，为采样算子的逼近理论提供了更准确和全面的分析工具。

> **ai_Abstract:** 本文提出了一种改进的光滑度测度，旨在解决传统方法在$L_p$空间中对采样或插值算子逼近低光滑度函数时误差估计不准确的问题。该新测度通过平均算子整合了函数在采样点的局部行为，从而获得了广泛采样算子和函数的匹配直接与逆误差估计。研究还包括收敛判据、精确逼近率条件、K-泛函实现以及采样算子的光滑度性质，并将其应用于多种经典算子。

> **摘要翻译:** 传统的平滑度度量在采样或插值算子逼近中，尤其对于低平滑度函数，往往无法提供准确的$L_p$误差估计。为了解决这个问题，我们引入了一种修正的光滑度度量，它通过使用平均算子来结合函数在采样点的局部行为。利用这个新工具，我们获得了广泛的采样算子和$L_p$空间中函数的匹配直接和逆误差估计。此外，我们还推导了$L_p$中采样算子收敛的判据，确定了确保精确逼近率的条件，构建了基于这些算子的K-泛函实现，并研究了采样算子的平滑度性质。我们还展示了我们的结果如何应用于几个著名的算子，包括经典的惠特克-香农采样算子、由B样条生成的采样算子以及基于高斯函数的采样算子。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [289] [A hyperboloidal method for numerical simulations of multidimensional nonlinear wave equations](https://arxiv.org/abs/2507.00674)
> *多维非线性波动方程数值模拟的一种双曲面方法*

*Oliver Rinne* | **Category: math.NA, cs.NA, math-ph, math.AP, math.MP**

**Keywords:** 双曲面方法,非线性波动方程,数值模拟,衰减指数,共形紧致化

**Comment:** 20 pages, 8 figures, 2 tables

> **TL;DR:** 该研究提出了一种基于双曲面叶状结构和共形紧致化的方法，用于数值模拟多维非线性波动方程，并计算了不同模式下解的晚期幂律衰减指数。

**AI_Comments:** 本文的创新之处在于其提出的双曲面方法，该方法成功地扩展了非线性波动方程数值模拟的适用范围，不再局限于径向对称或强对称性假设。这使得研究能够处理更普遍的多维问题，为理解复杂非线性系统的晚期行为提供了新的工具和见解。

<details>
  <summary>Details</summary>

**Motivation:** 以前的数值研究局限于径向情况或假设对称性，本研究旨在超越这些限制，处理更普遍的多维非线性波动方程，特别是在n=3时不再假设任何对称性，并在更高维度中仅施加SO(n-1)对称性。

**Method:** 该方法基于闵可夫斯基时空的双曲面叶状结构和共形紧致化。

**Result:** 研究计算了亚临界、临界和超临界、聚焦和散焦非线性波动方程在不同球谐模式下解的晚期幂律衰减（尾部）的衰减指数。

**Conclusion:** 本文成功地开发并应用了一种双曲面方法，能够对多维非线性波动方程进行数值模拟，并在更普遍的对称性条件下，量化了不同非线性类型和模式下解的晚期衰减特性。

> **ai_Abstract:** 本文提出了一种新颖的双曲面方法，用于数值模拟多维非线性波动方程。该方法克服了以往研究中对对称性的限制，尤其是在n=3维时无需对称性假设，并在高维中仅施加SO(n-1)对称性。研究利用闵可夫斯基时空的双曲面叶状结构和共形紧致化，计算并分析了亚临界、临界、超临界以及聚焦和散焦非线性波动方程在不同球谐模式下解的晚期幂律衰减指数。

> **摘要翻译:** 我们考虑n+1维带幂次非线性的标量波动方程。与以往的数值研究不同，我们超越了径向情况，在n=3时不再假设任何对称性，并且在更高维度中仅施加SO(n-1)对称性。我们的方法基于闵可夫斯基时空的双曲面叶状结构和共形紧致化。我们关注解的晚期幂律衰减（尾部），并计算了亚临界、临界和超临界、聚焦和散焦非线性波动方程在不同球谐模式下的衰减指数。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [297] [Sectional Kolmogorov N-widths for parameter-dependent function spaces: A general framework with application to parametrized Friedrichs' systems](https://arxiv.org/abs/2507.00678)
> *参数依赖函数空间的截面柯尔莫哥洛夫N宽：一个通用框架及其在参数化弗里德里希斯系统中的应用*

*Christian Engwer, Mario Ohlberger, Lukas Renelt* | **Category: math.NA, cs.NA, 65M22, 41A46, 65N30, 65J05**

**Keywords:** 参数依赖函数空间, 截面柯尔莫哥洛夫N宽, 纤维丛, 弗里德里希斯系统, 模型降阶

**Comment:** 18 pages, 2 figures

> **TL;DR:** 本文提出了一种基于纤维丛理论的新框架，并引入截面柯尔莫哥洛夫N宽来研究参数依赖函数空间中的参数化变分问题，特别是针对弗里德里希斯系统，并证明了其指数逼近率。

**AI_Comments:** 该论文创新性地将纤维丛理论引入到参数依赖函数空间的分析中，提出了截面柯尔莫哥洛夫N宽这一新概念，有效地解决了传统解流形理论在处理这类问题时的局限性。其提出的指数逼近率证明及其在弗里德里希斯系统上的应用，为模型降阶和数值分析领域提供了新的理论工具和分析方法，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的“解流形”解释在参数依赖函数空间中的参数化变分问题中不再适用，特别是对于弗里德里希斯系统这类解存在于依赖于参数的图空间中的问题。作者旨在为这类问题提供一个新的理论框架。

**Method:** 提出了一种基于纤维丛理论的新框架，并引入了“截面柯尔莫哥洛夫N宽”来推广已有的可逼近性概念。

**Result:** 证明了在满足范数等价准则的情况下，截面柯尔莫哥洛夫N宽可以达到指数逼近率。将此结果应用于弗里德里希斯结构问题，提供了一个易于验证的充分准则。

**Conclusion:** 通过引入截面柯尔莫哥洛夫N宽和基于纤维丛理论的框架，为参数依赖函数空间中的变分问题提供了一个新的、更普适的分析工具，特别适用于解决弗里德里希斯系统等复杂问题。

> **ai_Abstract:** 本文针对参数依赖函数空间中的变分问题，特别是弗里德里希斯系统，提出了一个基于纤维丛理论的新框架，以替代传统的“解流形”概念。通过引入截面柯尔莫哥洛夫N宽，作者推广了可逼近性等概念，并证明了在满足特定范数等价准则时，该N宽能实现指数逼近率，为解决此类复杂问题提供了一个可验证的充分准则。

> **摘要翻译:** 我们研究了参数化变分问题，其中对于每个参数，解可能源自一个不同的参数依赖函数空间。我们的主要动机是弗里德里希斯系统理论，这是一大类抽象的线性偏微分方程问题，其解在算子（因此也依赖于参数）相关的图空间中寻找。其他应用包括参数化域上的函数空间或涉及数据依赖稳定器的离散化。关于所有参数依赖解的集合，我们认为在这些情况下，模型降阶社区广泛采用的“解流形”解释不再适用。相反，我们提出了一种基于纤维丛理论的新颖框架，并解释了通过引入截面柯尔莫哥洛夫N宽，诸如可逼近性等既有概念如何得到推广。此外，我们证明了如果满足范数等价准则，该N宽具有指数逼近率。将此结果应用于具有弗里德里希斯结构的问题，则给出了一个易于验证的充分准则。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [305] [Analysis of A Mixed Finite Element Method for Poisson's Equation with Rough Boundary Data](https://arxiv.org/abs/2507.00697)
> *泊松方程粗糙边界数据混合有限元方法分析*

*Huadong Gao, Yuhui Huang, Wen Xie* | **Category: math.NA, cs.NA**

**Keywords:** 泊松方程, 混合有限元方法, 粗糙边界数据, 收敛速率, Raviart--Thomas

**Comment:** 18 pages,6 figures

> **TL;DR:** 本文提出了一种直接的Raviart-Thomas混合有限元方法，用于求解泊松方程的粗糙$L^2$边界数据问题，并证明了其收敛到弱解的性质及特定的收敛速率。

**AI_Comments:** 该论文通过直接处理粗糙的$L^2$边界数据，为泊松方程的有限元求解提供了一个重要进展，避免了常见的正则化步骤。这种直接的方法简化了数值处理，并拓宽了有限元方法在处理不规则边界条件问题时的适用性，这在许多实际场景中至关重要。论文中严谨的理论分析，包括针对不同类型域的详细收敛速率，为所提出的方法提供了强有力的支持。

<details>
  <summary>Details</summary>

**Motivation:** 传统的有限元方法要求泊松方程的边界数据$g$属于$H^{1/2}(\partial \Omega)$空间，但在许多实际应用中，边界数据$g$可能仅属于$L^2(\partial \Omega)$，这导致传统方法失效或需要对边界数据进行正则化处理。

**Method:** 本文采用Raviart--Thomas混合有限元方法直接求解具有粗糙边界数据的泊松方程，避免了对边界数据进行正则化。其分析基于正则化方法和对偶问题的严格估计。

**Result:** 所提出的混合方法得到的解收敛于非常弱解。数值解的收敛速率在凸域中为$O(h^{1/2})$，在非凸域中为$O(h^{s-1/2})$（其中$s > 1/2$取决于域的几何形状）。

**Conclusion:** 本文成功开发并分析了一种用于求解具有粗糙边界数据的泊松方程的直接混合有限元方法，并通过数值实验证实了理论预测的收敛速率。

> **ai_Abstract:** 本文旨在解决泊松方程在边界数据粗糙（仅属于$L^2(\partial \Omega)$）情况下的求解问题，这与传统方法要求边界数据属于$H^{1/2}(\partial \Omega)$形成对比。论文提出直接使用Raviart--Thomas混合有限元方法，避免了对边界数据进行正则化处理。研究证明了该混合方法的解收敛于非常弱解，并给出了具体的收敛速率：在凸域中为$O(h^{1/2})$，在非凸域中为$O(h^{s-1/2})$。数值实验结果也证实了这些理论预测的收敛速率。

> **摘要翻译:** 本文关注具有粗糙边界数据的泊松方程的有限元方法。传统方法要求问题的边界数据$g$属于$H^{1/2}(\partial \Omega)$。然而，在许多应用中，人们不得不考虑$g$仅在$L^2(\partial \Omega)$中的情况。为此，本文考虑了非常弱解以建立问题的适定性。大多数先前提出的数值方法都使用了边界数据的正则化。本文的主要目的是使用Raviart--Thomas混合有限元方法直接求解具有粗糙边界数据的泊松方程。我们证明了所提出的混合方法的解收敛于非常弱解。特别是，我们证明了数值解在凸域中的收敛速率为$O(h^{1/2})$，在非凸域中为$O(h^{s-1/2})$，其中$s > 1/2$取决于域的几何形状。分析基于正则化方法和对相应对偶问题的严格估计。数值实验证实了所提出的用于泊松方程粗糙边界数据的混合方法的理论预测收敛速率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [311] [Multi-goal-oriented anisotropic error control and mesh adaptivity for time-dependent convection-dominated problems](https://arxiv.org/abs/2507.00723)
> *多目标各向异性误差控制和网格自适应，用于时间相关的对流主导问题*

*Markus Bause, Marius Paul Bruchhäuser, Bernhard Endtmayer, Nils Margenberg, Ioannis Toulopoulos, Thomas Wick* | **Category: math.NA, cs.NA, 65M60, 65M50**

**Keywords:** Dual Weighted Residual (DWR), Anisotropic mesh adaptivity, Multi-goal error control, Convection-dominated problems, SUPG

**Comment:** 14 pages, 5 Figures, 2 Tables. Submitted to PAMM. arXiv admin note:
  substantial text overlap with arXiv:2504.04951

> **TL;DR:** 提出了一种基于DWR的多目标各向异性误差控制和网格自适应方法，用于时间相关的对流扩散反应方程，并在对流主导问题上表现出高效和鲁棒性。

**AI_Comments:** 该论文的创新点在于结合了多目标误差控制、各向异性网格自适应和DWR方法，以高效且鲁棒地处理时间相关的对流主导问题。特别是利用各向异性误差指示器生成自适应网格，能够有效捕获流场中的薄层结构，这对于对流主导问题至关重要。SUPG方法的应用进一步增强了在高Péclet数下的稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 为了对时间相关的对流扩散反应方程实现针对多个关注量同时进行准确高效的误差控制，尤其是在对流主导问题中需要有效捕获层。

**Method:** 该工作提出了一种基于双加权残差（DWR）方法的各向异性多目标误差控制策略。通过使用各向异性插值和限制算子，获得了空间和时间上的单元误差指示器，其中空间指示器还按单一方向分离。这些定向误差指示器量化了溶液相对于目标的各向异性，并生成了能够有效捕获层的自适应、各向异性网格。为了防止伪振荡，在高Péclet数情况下应用了流线迎风Petrov-Galerkin（SUPG）方法来稳定基础系统。

**Result:** 数值例子表明，所提出的方法对于对流主导传输的几个目标量，在使用已建立的基准测试时，显示出效率和鲁棒性。

**Conclusion:** 所提出的基于DWR的各向异性多目标误差控制和网格自适应方法，结合SUPG稳定化，能够高效且鲁棒地解决时间相关的对流主导问题，并对多个关注量进行准确的误差控制。

> **ai_Abstract:** 本研究提出了一种针对时间相关的对流扩散反应方程的各向异性多目标误差控制方法，该方法基于双加权残差（DWR）并结合了各向异性网格自适应技术。通过各向异性插值和限制算子，生成了空间和时间上的误差指示器，并利用定向误差指示器生成自适应各向异性网格以有效捕获层。同时，采用流线迎风Petrov-Galerkin（SUPG）方法在高Péclet数下稳定系统。数值实验证明了该方法在处理对流主导问题时对多个目标量的有效性和鲁棒性。

> **摘要翻译:** 在这项工作中，我们提出了一种基于双加权残差（DWR）方法的各向异性多目标误差控制，用于时间相关的对流-扩散-反应（CDR）方程。这种多目标导向的方法能够同时对多个关注量进行准确高效的误差控制。通过使用各向异性插值和限制算子，我们获得了空间和时间上的单元误差指示器，其中空间指示器还按单一方向分离。定向误差指示器量化了溶液相对于目标的各向异性，并生成了能够有效捕获层的自适应、各向异性网格。为了防止伪振荡，在高Péclet数情况下应用了流线迎风Petrov-Galerkin（SUPG）方法来稳定基础系统。数值例子表明，所提出的方法对于对流主导传输的几个目标量，在使用已建立的基准测试时，显示出效率和鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [314] [A posteriori and a priori error estimates for linearized thin sheet folding](https://arxiv.org/abs/2507.00807)
> *线性化薄板折叠的后验和先验误差估计*

*Harbir Antil, Sean P. Carney, Rohit Khandelwal* | **Category: math.NA, cs.NA**

**Keywords:** 后验误差估计, 先验误差估计, 不连续伽辽金方法, 薄板折叠, 边缘气泡函数

**Comment:** 

> **TL;DR:** 本文为薄板折叠的线性化模型中的不连续伽辽金方法提供了后验误差分析，并使用新颖的边缘气泡函数获得了局部效率界限，同时通过中间分析改进了先验误差估计。

**AI_Comments:** 本文的创新之处在于引入了新颖的边缘气泡函数来获得局部效率界限，这对于精确评估薄板折叠模型中的界面条件至关重要。通过结合后验和先验误差估计，并关注最小正则性假设，该研究对数值分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在为薄板折叠的线性化模型中出现的四阶椭圆界面问题的不连续伽辽金方法提供误差分析，以评估和改进其精度。

**Method:** 本文采用不连续伽辽金方法对线性化薄板折叠模型进行误差分析。主要贡献是通过构建新颖的边缘气泡函数，为衡量折叠处界面条件满足程度的估计器获得了局部效率界限。随后，通过中间分析在精确解的最小正则性假设下获得了改进的先验误差估计。

**Result:** 获得了衡量折叠处界面条件满足程度的估计器的局部效率界限，并通过构建新颖的边缘气泡函数实现了这一目标。在精确解的最小正则性假设下，通过中间分析获得了改进的先验误差估计。数值实验证明了该方法的性能。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文对用于薄板折叠线性化模型中四阶椭圆界面问题的不连续伽辽金方法进行了后验误差分析。研究主要通过构建新颖的边缘气泡函数，为评估界面条件满足程度的估计器导出了局部效率界限。此外，通过中间分析，在精确解的最小正则性假设下，获得了改进的先验误差估计。数值实验验证了该方法的有效性。

> **摘要翻译:** 我们描述了针对由薄板折叠线性化模型产生的四阶椭圆界面问题的不连续伽辽金方法的后验误差分析。主要贡献是为衡量折叠处界面条件满足程度的估计器提供了局部效率界限，这是通过构建一种新颖的边缘气泡函数实现的。随后，我们进行了一项中间分析，以在精确解的最小正则性假设下获得改进的先验误差估计。数值实验说明了该方法的性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [107] [A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss](https://arxiv.org/abs/2507.00229)
> *高保真语音超分辨率网络，使用复杂全局注意力模块和谱时域损失*

*Tarikul Islam Tamiti, Biraj Joshi, Rida Hasan, Rashedul Hasan, Taieba Athay, Nursad Mamun, Anomadarshi Barua* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 语音超分辨率, 复数域, 全局注意力, 相位重建, CTFT-Net

**Comment:** 

> **TL;DR:** CTFT-Net是一种新的语音超分辨率网络，通过在复数域重建幅度和相位，并结合复杂全局注意力模块和复杂Conformer，在极端上采样任务中表现优于现有模型，生成无噪声的高频语音。

**AI_Comments:** 这篇论文的创新点在于强调并实现了在复数域同时进行幅度和相位重建，这弥补了现有SSR方法的一个重要空白。引入复杂全局注意力模块和复杂Conformer是其模型结构上的亮点，有助于更全面地捕捉语音特征。特别是在极端上采样场景下的优秀表现，展示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音超分辨率方法主要关注幅度重建，但最近研究表明相位重建对提高感知质量至关重要。因此，需要一种能在复数域同时重建幅度和相位的网络，以改进语音超分辨率性能。

**Method:** 本文提出了CTFT-Net，一个复数时频变换网络，旨在复数域重建幅度和相位。它包含一个复杂全局注意力块来建模音素间和频率间的依赖关系，以及一个复杂Conformer来捕获长距离和局部特征，以改善频率重建和噪声鲁棒性。此外，CTFT-Net采用时域和多分辨率频域损失函数以提高泛化能力。

**Result:** 实验表明，CTFT-Net在VCTK数据集上优于现有最先进模型（NU-Wave, WSRGlow, NVSR, AERO），尤其在极端上采样（2 kHz到48 kHz）任务中表现出色，能有效重建高频部分且无噪声伪影。

**Conclusion:** CTFT-Net通过在复数域进行幅度和相位重建，并结合创新的网络结构和损失函数，显著提升了语音超分辨率的性能，尤其是在高倍率上采样和高频重建方面。

> **ai_Abstract:** 本文提出了一种名为CTFT-Net的语音超分辨率网络，旨在解决现有方法侧重幅度重建而忽略相位重建的问题。CTFT-Net通过在复数域同时重建语音的幅度和相位，并集成了复杂全局注意力模块和复杂Conformer来增强特征捕获和依赖建模。该网络利用时域和多分辨率频域损失函数优化性能。实验结果表明，CTFT-Net在极端上采样任务中表现优异，超越了多种现有SOTA模型，能够高质量地重建高频语音。

> **摘要翻译:** 语音超分辨率（SSR）通过提高采样率来增强低分辨率语音。虽然大多数SSR方法侧重于幅度重建，但最近的研究强调了相位重建对提高感知质量的重要性。因此，我们引入了CTFT-Net，一个复数时频变换网络，它在复数域重建幅度和相位，以改进SSR任务。它结合了一个复杂全局注意力块来建模音素间和频率间的依赖关系，以及一个复杂Conformer来捕获长距离和局部特征，从而改善频率重建和噪声鲁棒性。CTFT-Net采用时域和多分辨率频域损失函数，以实现更好的泛化能力。实验表明，CTFT-Net在VCTK数据集上优于现有最先进模型（NU-Wave、WSRGlow、NVSR、AERO），特别是在极端上采样（2 kHz到48 kHz）方面，能够有效重建高频而无噪声伪影。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [131] [Beat and Downbeat Tracking in Performance MIDI Using an End-to-End Transformer Architecture](https://arxiv.org/abs/2507.00466)
> *使用端到端Transformer架构对演奏MIDI中的节拍和下拍进行跟踪*

*Sebastian Murgul, Michael Heizmann* | **Category: cs.SD, cs.CL, cs.MM, eess.AS**

**Keywords:** 节拍跟踪, MIDI, Transformer, 符号音乐, 深度学习

**Comment:** Accepted to the 22nd Sound and Music Computing Conference (SMC), 2025

> **TL;DR:** 本文提出了一种基于端到端Transformer模型的方法，用于在演奏MIDI中进行节拍和下拍跟踪，并在多个数据集上表现优于现有方法。

**AI_Comments:** 这篇论文的创新点在于首次将端到端Transformer架构应用于演奏MIDI的节拍和下拍跟踪，并引入了专门针对MIDI数据优化的数据预处理技术。其重要性在于为符号音乐分析提供了一种高性能的新方法，并为未来与自动音乐转录系统的集成奠定了基础。局限性可能在于其性能是否能扩展到更复杂的音乐结构或非标准MIDI数据。

<details>
  <summary>Details</summary>

**Motivation:** 音乐演奏MIDI中的节拍跟踪对于乐谱级音乐转录和节奏分析是一项具有挑战性且重要的任务，但现有方法主要侧重于基于音频的方法。

**Method:** 本文提出了一种用于演奏MIDI中节拍和下拍跟踪的端到端Transformer模型，该模型利用编码器-解码器架构将MIDI输入序列到序列转换为节拍注释。该方法引入了新颖的数据预处理技术，包括动态增强和优化的分词策略。

**Result:** 实验结果表明，该模型优于现有的符号音乐节拍跟踪方法，在各种音乐风格和乐器上均取得了具有竞争力的F1分数。

**Conclusion:** 研究结果突出了Transformer架构在符号节拍跟踪方面的潜力，并建议未来与自动音乐转录系统集成，以增强音乐分析和乐谱生成。

> **ai_Abstract:** 本文提出了一种用于演奏MIDI中节拍和下拍跟踪的端到端Transformer模型。该模型采用编码器-解码器架构和新颖的数据预处理技术，旨在提高在MIDI数据上的节拍跟踪准确性和泛化能力。通过在多个数据集上的实验，该模型在符号音乐节拍跟踪方面优于现有方法，并展示了Transformer架构在该领域的潜力。

> **摘要翻译:** 音乐演奏MIDI中的节拍跟踪对于乐谱级音乐转录和节奏分析是一项具有挑战性且重要的任务，但现有方法主要侧重于基于音频的方法。本文提出了一种用于演奏MIDI中节拍和下拍跟踪的端到端Transformer模型，该模型利用编码器-解码器架构将MIDI输入序列到序列转换为节拍注释。我们的方法引入了新颖的数据预处理技术，包括动态增强和优化的分词策略，以提高不同数据集的准确性和泛化能力。我们使用A-MAPS、ASAP、GuitarSet和Leduc数据集进行了广泛的实验，并将我们的模型与最先进的隐马尔可夫模型（HMM）和基于深度学习的节拍跟踪方法进行了比较。结果表明，我们的模型优于现有的符号音乐节拍跟踪方法，在各种音乐风格和乐器上均取得了具有竞争力的F1分数。我们的发现突出了Transformer架构在符号节拍跟踪方面的潜力，并建议未来与自动音乐转录系统集成，以增强音乐分析和乐谱生成。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [152] [AudioBERTScore: Objective Evaluation of Environmental Sound Synthesis Based on Similarity of Audio embedding Sequences](https://arxiv.org/abs/2507.00475)
> *AudioBERTScore：基于音频嵌入序列相似性的环境音合成客观评估*

*Minoru Kishi, Ryosuke Sakai, Shinnosuke Takamichi, Yusuke Kanamori, Yuki Okamoto* | **Category: cs.SD, eess.AS**

**Keywords:** AudioBERTScore, 环境音合成, 客观评估, 音频嵌入, 文本到音频

**Comment:** 

> **TL;DR:** AudioBERTScore是一种新的客观评估指标，用于文本到音频（TTA）中的合成音频，通过计算合成声音和参考声音的音频嵌入相似性，提高了与主观评估的相关性。

**AI_Comments:** AudioBERTScore的创新之处在于将BERTScore的概念扩展到音频领域，并引入p-范数以更好地适应环境音的特性，这对于解决文本到音频（TTA）领域中客观评估与主观评估相关性弱的问题具有重要意义。该方法的提出有望降低TTA模型评估的成本，并加速模型性能的提升。

<details>
  <summary>Details</summary>

**Motivation:** 在文本到音频（TTA）领域中，合成声音的主观评估虽然重要但成本高昂。现有的客观评估指标（如梅尔倒谱失真）与主观评估值之间的相关性较弱，因此需要开发一种更有效、更客观的评估方法。

**Method:** 本文提出了一种名为AudioBERTScore的客观评估指标。该方法通过计算合成声音和参考声音的音频嵌入之间的相似性来评估合成音频。与传统的BERTScore不同，AudioBERTScore不仅使用最大范数（max-norm），还引入了p-范数（p-norm）以更好地反映环境声音的非局部特性。

**Result:** 实验结果表明，通过AudioBERTScore方法获得的分数与主观评估值相比传统指标具有更高的相关性。

**Conclusion:** AudioBERTScore作为一种新的客观评估指标，能够更准确地反映文本到音频（TTA）模型中合成声音的主观质量，有助于改进TTA模型的性能。

> **ai_Abstract:** 本文提出了一种名为AudioBERTScore的新型客观评估指标，用于评估文本到音频（TTA）模型生成的合成声音。针对现有主观评估成本高昂和客观评估相关性低的缺点，AudioBERTScore通过计算合成音频与参考音频的嵌入序列相似性来解决。该方法创新性地结合了BERTScore的最大范数和p-范数，以更好地捕捉环境音的非局部特征。实验证明，AudioBERTScore与主观评估结果具有更高的相关性，从而为TTA模型的性能提升提供了一个更可靠的评估工具。

> **摘要翻译:** 我们提出了一种用于文本到音频（TTA）中合成音频的新型客观评估指标，旨在提高TTA模型的性能。在TTA中，合成声音的主观评估虽然重要，但其实施需要金钱成本。因此，使用客观评估，如梅尔倒谱失真，但这些客观指标与主观评估值之间的相关性较弱。我们提出的客观评估指标AudioBERTScore计算合成声音和参考声音的嵌入相似性。该方法不仅基于传统BERTScore中使用的最大范数，还基于p范数以反映环境声音的非局部性质。实验结果表明，所提出的方法获得的分数与主观评估值相比传统指标具有更高的相关性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [173] [MuteSwap: Silent Face-based Voice Conversion](https://arxiv.org/abs/2507.00498)
> *MuteSwap：基于静默面部的语音转换*

*Yifan Liu, Yu Fang, Zhouhan Lin* | **Category: cs.SD, cs.CV, cs.LG, cs.MM, eess.AS**

**Keywords:** 语音转换, 静默面部, 视觉输入, MuteSwap, 对比学习

**Comment:** 

> **TL;DR:** MuteSwap是一种新的语音转换框架，它完全基于视觉输入（面部图像和唇部运动）进行语音转换，即使在无声视频或嘈杂环境中也能有效工作。

**AI_Comments:** 本文提出了一种新颖的基于静默面部的语音转换（SFVC）任务，解决了传统语音转换在无声或嘈杂环境中的局限性，具有重要的创新性。MuteSwap框架利用对比学习和互信息最小化来仅从视觉输入生成语音，这一方法非常巧妙。其在嘈杂环境下的出色表现突显了该研究的实用价值和突破性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的语音转换方法在缺乏清晰音频输入（如静默视频或嘈杂环境）时无法进行，因此需要一种新的方法来解决基于视觉输入的语音转换问题。

**Method:** 本研究提出了MuteSwap框架，通过对比学习对齐跨模态身份，并最小化互信息以分离共享视觉特征，从而实现基于静默面部的语音转换（SFVC）。

**Result:** 实验结果表明，MuteSwap在语音合成和身份转换方面均取得了令人印象深刻的性能，尤其是在依赖音频输入的方法无法产生可理解结果的嘈杂条件下。

**Conclusion:** MuteSwap证明了其训练方法的有效性和基于静默面部语音转换（SFVC）的可行性，解决了在无声或嘈杂环境下进行语音转换的挑战。

> **ai_Abstract:** MuteSwap是一种创新的基于视觉输入的语音转换框架，旨在解决传统方法在无声或嘈杂环境中音频输入不足的问题。该框架通过对比学习对齐跨模态身份并最小化互信息来分离视觉特征，仅利用目标说话者的图像和源说话者的静默视频中的唇部运动，即可生成保留内容并转换身份的可理解语音。实验证明MuteSwap在语音合成和身份转换方面表现出色，尤其在嘈杂条件下优于依赖音频的方法，证实了其训练策略的有效性和基于静默面部语音转换的可行性。

> **摘要翻译:** 传统的语音转换方法依赖于源说话者和目标说话者的音频输入来修改语音特征。然而，当无法获得清晰音频时（例如在无声视频或嘈杂环境中），此过程变得不可行。在这项工作中，我们专注于基于静默面部的语音转换（SFVC）任务，它完全通过视觉输入进行语音转换。即，给定目标说话者的图像和包含唇部动作的源说话者的静默视频，SFVC生成与目标说话者身份对齐的语音，同时保留源静默视频中的语音内容。由于此任务仅使用视觉线索生成可理解的语音并转换身份，因此特别具有挑战性。为了解决这个问题，我们引入了MuteSwap，这是一个新颖的框架，它采用对比学习来对齐跨模态身份并最小化互信息以分离共享视觉特征。实验结果表明，MuteSwap在语音合成和身份转换方面都取得了令人印象深刻的性能，尤其是在依赖音频输入的方法无法产生可理解结果的嘈杂条件下，这证明了我们训练方法的有效性和SFVC的可行性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [190] [Leveraging Large Language Models for Spontaneous Speech-Based Suicide Risk Detection](https://arxiv.org/abs/2507.00693)
> *利用大型语言模型进行自发语音自杀风险检测*

*Yifan Gao, Jiao Fu, Long Guo, Hong Liu* | **Category: cs.SD, cs.CL, eess.AS**

**Keywords:** 大型语言模型, 自杀风险检测, 语音分析, 心理健康, 青少年

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 该研究利用大型语言模型（LLM）和传统语音特征，通过自发语音检测青少年自杀风险，在SW1挑战中取得74%的准确率并排名第一。

**AI_Comments:** 这项研究通过结合大型语言模型和传统语音特征，在自发语音自杀风险检测方面取得了显著成果，并在特定挑战赛中排名第一，凸显了LLM在心理健康评估领域的创新应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 早期识别自杀风险对于预防自杀行为至关重要。当前研究的重点是识别和研究与自杀风险相关的模式和标记。本文旨在探索语音作为一种无创且易于获取的心理健康指标，用于识别有自杀风险的青少年。

**Method:** 该方法利用大型语言模型（LLM）作为主要的特征提取工具，并结合了传统的声学和语义特征。

**Result:** 所提出的方法在测试集上取得了74%的准确率，并在第一届SpeechWellness挑战赛（SW1）中排名第一。

**Conclusion:** 这些发现表明，基于LLM的方法在自杀风险评估中分析语音具有潜力。

> **ai_Abstract:** 本文介绍了在第一届SpeechWellness挑战赛（SW1）中的研究成果，该研究旨在利用自发语音作为非侵入性指标来识别有自杀风险的青少年。研究方法主要利用大型语言模型（LLM）进行特征提取，并结合传统声学和语义特征。该方法在测试集上实现了74%的准确率，并在SW1挑战中获得第一名，展示了LLM在语音自杀风险评估中的潜力。

> **摘要翻译:** 早期识别自杀风险对于预防自杀行为至关重要。因此，识别和研究与自杀风险相关的模式和标记已成为当前研究的重点。在本文中，我们展示了我们在第一届SpeechWellness挑战赛（SW1）中的工作成果，该挑战旨在探索语音作为一种无创且易于获取的心理健康指标，用于识别有自杀风险的青少年。我们的方法利用大型语言模型（LLM）作为主要的特征提取工具，同时结合了传统的声学和语义特征。所提出的方法在测试集上取得了74%的准确率，并在SW1挑战赛中排名第一。这些发现证明了基于LLM的方法在自杀风险评估背景下分析语音的潜力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [209] [Multi-interaction TTS toward professional recording reproduction](https://arxiv.org/abs/2507.00808)
> *多交互文本到语音合成（TTS）旨在实现专业录音再现*

*Hiroki Kanagawa, Kenichi Fujita, Aya Watanabe, Yusuke Ijima* | **Category: cs.SD, cs.CL, eess.AS**

**Keywords:** 多交互TTS, 风格细化, 迭代反馈, 语音合成, 专业录音

**Comment:** 7 pages,6 figures, Accepted to Speech Synthesis Workshop 2025 (SSW13)

> **TL;DR:** 本文提出了一种多步交互式文本到语音合成（TTS）方法，允许用户迭代地细化合成语音的风格，以模拟专业录音中配音导演与配音演员之间的反馈过程。

**AI_Comments:** 这篇论文的创新点在于将专业录音中配音导演与配音演员之间的迭代反馈机制引入到TTS领域。通过建立用户与TTS模型之间的多步交互模型，极大地增强了用户对合成语音风格的控制能力，使其能更精准地匹配用户意图，弥补了现有TTS系统在后期调整上的不足。这对于提高合成语音的自然度和表现力，以及推动TTS技术在专业内容创作中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在实际录音中，配音导演通过迭代反馈来细化配音演员的表演以达到预期效果，但文本到语音合成（TTS）中却忽略了这种迭代反馈细化过程。这导致初始合成后无法进行细粒度的风格细化，即使合成语音经常偏离用户预期的风格。

**Method:** 我们提出了一种具有多步交互的TTS方法，允许用户直观、快速地细化合成语音。该方法模拟了TTS模型与其用户之间的交互，以模仿配音演员和配音导演之间的关系。

**Result:** 实验表明，所提出的模型及其相应的数据集能够根据用户的指示进行迭代风格细化，从而展示了其多交互能力。

**Conclusion:** 本文提出的多交互TTS模型成功实现了合成语音的迭代风格细化，弥补了传统TTS在后期风格调整上的不足，使其更接近专业录音的精细化要求。

> **ai_Abstract:** 本文针对传统文本到语音合成（TTS）中缺乏细粒度风格迭代细化的问题，提出了一种多步交互式TTS方法。该方法通过模拟配音导演与配音演员之间的交互过程，使用户能够直观、快速地对合成语音进行风格调整。实验证明，该模型及其配套数据集能有效实现迭代风格细化，从而提升了TTS在专业录音再现方面的能力。

> **摘要翻译:** 配音导演通常通过提供反馈来迭代细化配音演员的表演，以达到预期的效果。虽然这种基于迭代反馈的细化过程在实际录音中非常重要，但在文本到语音合成（TTS）中却被忽视了。因此，即使合成语音经常偏离用户的预期风格，初始合成后也无法进行细粒度的风格细化。为了解决这个问题，我们提出了一种具有多步交互的TTS方法，允许用户直观、快速地细化合成语音。我们的方法模拟了TTS模型与其用户之间的交互，以模仿配音演员和配音导演之间的关系。实验表明，所提出的模型及其相应的数据集能够根据用户的指示进行迭代风格细化，从而展示了其多交互能力。样本音频可在以下网址获取：https://ntt-hilab-gensp.github.io/ssw13multiinteraction_tts/

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [223] [MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement](https://arxiv.org/abs/2507.00966)
> *MambAttention：结合多头注意力的Mamba用于可泛化的单通道语音增强*

*Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 语音增强, Mamba, 多头注意力, 泛化性能, 混合架构

**Comment:** Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing for possible publication

> **TL;DR:** 提出MambAttention，结合Mamba和多头注意力，显著提升单通道语音增强在域外数据集上的泛化性能。

**AI_Comments:** 本文的创新点在于首次探索了Mamba与时频多头注意力的结合，并引入权重共享机制以增强泛化能力。其重要性体现在有效解决了序列模型在语音增强中常见的过拟合问题，并通过在更具挑战性的数据集上训练和在域外数据集上的出色表现，证明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的序列模型（如LSTM和Mamba）在单通道语音增强中易于过拟合训练集，而混合Mamba和时频注意力模型在泛化性能方面的探索尚不足。

**Method:** 提出MambAttention混合架构，结合Mamba和共享时频多头注意力模块，用于可泛化的单通道语音增强。引入VB-DemandEx数据集进行训练，该数据集包含更具挑战性的噪声类型和更低的信噪比。

**Result:** MambAttention模型在VB-DemandEx数据集上训练后，在两个域外数据集（DNS 2020和EARS-WHAM_v2）上，其性能显著优于现有SOTA的LSTM、xLSTM、Mamba和Conformer系统，但在域内数据集VB-DemandEx上性能相当。消融研究表明时频多头注意力模块之间的权重共享对泛化性能有重要作用。将共享时频多头注意力模块与LSTM和xLSTM结合也能显著提升域外性能，但MambAttention仍表现最佳。

**Conclusion:** MambAttention通过结合Mamba和共享时频多头注意力，显著提高了单通道语音增强在域外数据集上的泛化性能，优于现有SOTA模型。

> **ai_Abstract:** 本文提出了一种名为MambAttention的新型混合架构，它结合了Mamba模型和共享时频多头注意力模块，旨在解决现有序列模型在单通道语音增强中泛化能力不足的问题。为训练模型，作者构建了更具挑战性的VB-DemandEx数据集。实验结果表明，MambAttention在域外数据集上的泛化性能显著优于多种现有先进模型，并在域内数据集上保持竞争力，验证了其在复杂噪声环境下实现可泛化语音增强的有效性。

> **摘要翻译:** 随着Mamba和xLSTM等新型序列模型的出现，多项研究表明这些模型在单通道语音增强、自动语音识别和自监督音频表示学习方面与最先进的模型相当或超越。然而，先前的研究表明，LSTM和Mamba等序列模型往往会过度拟合训练集。为了解决这个问题，以前的工作表明，向LSTM中添加自注意力可以显著改善单通道语音增强的泛化性能。尽管如此，Mamba混合时频注意力模型及其泛化性能在语音增强领域尚未被探索。在本文中，我们提出了一种新颖的混合架构MambAttention，它结合了Mamba和共享时频多头注意力模块，用于可泛化的单通道语音增强。为了训练我们的模型，我们引入了VoiceBank+Demand Extended (VB-DemandEx) 数据集，该数据集受VoiceBank+Demand启发，但具有更具挑战性的噪声类型和更低的信噪比。在VB-DemandEx上训练后，我们提出的MambAttention模型在两个域外数据集：DNS 2020和EARS-WHAM_v2上的所有报告指标上，显著优于现有复杂度相似的基于LSTM、xLSTM、Mamba和Conformer的系统，同时在域内数据集VB-DemandEx上与其性能相当。消融研究强调了时频多头注意力模块之间权重共享对泛化性能的作用。最后，我们探索了将共享时频多头注意力模块与LSTM和xLSTM集成，这在域外数据集上产生了显著的性能提升。然而，我们的MambAttention模型在两个域外数据集上的所有报告评估指标上仍然表现优越。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [118] [Horus: A Protocol for Trustless Delegation Under Uncertainty](https://arxiv.org/abs/2507.00631)
> *Horus：不确定性下无需信任委托的协议*

*David Shi, Kevin Joo* | **Category: cs.GT, cs.AI, cs.MA, I.2.11; F.2.2**

**Keywords:** 无需信任委托, AI代理, 正确性, 验证博弈, 纳什均衡

**Comment:** 9 pages, 1 figure

> **TL;DR:** Horus是一种协议，通过抵押索赔和递归验证博弈，在低信任环境中为自主AI代理提供无需信任的任务委托，确保正确性。

**AI_Comments:** Horus协议的创新之处在于其通过“抵押索赔”和“递归验证博弈”的机制，在无需信任的环境中实现了委托任务的正确性保障。它解决了传统方法（如预先规范或集中监督）在动态、低信任AI系统中的局限性。通过将错误暴露的成本设计得低于犯错的成本，并对所有参与者进行激励对齐和惩罚，协议创造了一个自我纠正的系统，使正确性成为纳什均衡，这对于构建鲁棒的去中心化AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在动态、低信任度的环境中，自主AI代理需要委托工作，但传统方法无法通过预先规范或集中监督来保证正确性。本研究的动机是设计一种机制，使得暴露错误的成本低于犯错的成本。

**Method:** Horus协议通过在递归验证博弈中抵押索赔来强制执行正确性。任务作为意图发布，解决者竞争完成。选定的解决者在风险下执行任务，正确性由验证者事后检查。任何挑战者都可以通过质押来挑战结果，触发验证过程。不正确的代理会被削减，正确的反对者会获得奖励，并存在一个升级路径惩罚错误的验证者。

**Result:** 当解决者、挑战者和验证者之间的激励机制对齐时，伪造条件使得正确性成为纳什均衡。

**Conclusion:** Horus协议通过一个递归验证博弈和激励对齐机制，确保了在无需信任的委托环境中，AI代理的任务正确性能够成为系统的纳什均衡。

> **ai_Abstract:** Horus是一种协议，旨在解决动态、低信任环境中自主AI代理在委托任务时难以保证正确性的问题。该协议通过一个递归验证博弈来强制执行正确性，其中任务发布为意图，解决者竞争完成。选定的解决者在风险下执行任务，其结果由验证者事后检查。任何挑战者都可以通过质押来质疑结果，从而触发验证过程。协议设计了惩罚机制，错误方将受到惩罚，而正确方则获得奖励。通过这种方式，Horus协议在解决者、挑战者和验证者之间建立了激励对齐，使得正确性成为系统中的纳什均衡。

> **摘要翻译:** 正确性是系统中出现错误成本低于犯错成本时所呈现的特性。在动态、低信任度的环境中，自主AI代理受益于将工作委托给子代理，但正确性无法通过预先规范或集中监督来保证。我们提出了一种协议，通过在递归验证博弈中抵押索赔来强制执行正确性。任务作为意图发布，解决者竞争完成它们。被选中的解决者在风险下执行任务，正确性由验证者事后检查。任何挑战者都可以通过质押来挑战结果，从而触发验证过程。不正确的代理将被削减，正确的反对者将获得奖励，并且存在一个升级路径，惩罚错误的验证者本身。当解决者、挑战者和验证者之间的激励机制对齐时，伪造条件使正确性成为纳什均衡。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [122] [The gradual transformation of inland countries -- human plowing, horse plowing and equity incentives](https://arxiv.org/abs/2507.00067)
> *内陆国家的渐进式转型——人耕、马耕与股权激励*

*Hongfa Zi, Zhen Liu* | **Category: physics.soc-ph, cs.CE, econ.GN, q-fin.EC**

**Keywords:** 文明演进, 治理手段, 股权激励, 对数正态分布, 农业转型

**Comment:** 9 pages,2 figures

> **TL;DR:** 本文探讨了现代国家如何从历史中学习以实现文明升级和稳定，通过追溯历史上的治理手段，并运用数学方法分析了从人耕到马耕的转型、统治者选择以及利用对数正态分布进行经济发展和财富分配优化。

**AI_Comments:** 该论文试图将历史上的社会转型（如农业耕作方式）与现代治理和经济原理通过数学建模联系起来，其创新之处在于将古代文明演变与股权激励、统计分布等当代概念进行桥接以优化社会。其局限性可能在于范围过于广泛，以及将复杂的历史和社会学因素过度简化为数学模型。

<details>
  <summary>Details</summary>

**Motivation:** 许多现代国家未能从历史中吸取教训，难以实现文明的渐进升级。本文旨在通过讲述文明进步的历史和治理手段，提高文明的综合实力和生存能力，并为冲突带来的磨砺和内部冲突的减少找到最优解。

**Method:** 首先，追随历史足迹，探索各国在冲突中长期稳定的原因（包括提供经济利益和镇压手段）；然后，使用数学方法证明在当前阶段如何实现最优解。具体分析了从人耕到马耕的文明转型、统治者选择（考试、选举、抽签）以及利用对数正态分布调整经济发展和财富差距。

**Result:** 从人耕到马耕转型的文明可以轻易地镇压人民的反抗，并赋予他们抵抗的能力；统治者的选择应考虑考试、选举、抽签等多种制度；经济发展遵循对数正态分布，可通过期望值和方差调整；利用最大值的对数正态分布划分股权可以调整贫富差距。

**Conclusion:** 通过分析历史上的文明进步和治理手段，结合数学方法，可以得出结论：从人耕到马耕的转型、多元化的统治者选择机制以及利用对数正态分布进行经济和股权管理，有助于实现文明的综合实力提升、内部冲突减少并找到最优解。

> **ai_Abstract:** 本文探讨了现代国家如何从历史中学习以促进文明渐进升级和实现稳定。研究首先追溯了各国长期稳定的历史原因，包括经济激励和镇压手段，然后运用数学方法寻求最优解。主要发现包括：从人耕到马耕的文明转型对社会控制的影响；统治者选择应综合考虑考试、选举和抽签等多种制度；经济发展遵循对数正态分布，其财富差距可通过基于对数正态分布的最大值股权划分进行调整。旨在通过这些分析提升文明的综合实力并减少内部冲突。

> **摘要翻译:** 许多现代国家没有吸取教训，常常寄希望于后人的智慧，导致它们只拥有现代科技，而难以迭代古老文明。目前，我们无法得知应如何从历史中学习并促进文明的渐进升级。因此，我们必须讲述文明进步的历史和治理手段，从经验中学习以提高文明的综合实力和生存能力，并为冲突带来的磨砺和内部冲突的减少找到最优解。首先，我们必须追随历史的足迹，探索每个国家在冲突中长期稳定的原因，包括为人民提供经济利益和镇压手段；然后，使用数学方法证明我们如何在现阶段实现最优解。经过分析，我们可以得出结论，从人耕到马耕转型的文明可以轻易地镇压人民的反抗，并赋予他们抵抗的能力；统治者的选择应考虑多种制度方面，例如考试、选举、抽签；经济发展遵循对数正态分布，可以通过期望值和方差进行调整。利用最大值的对数正态分布来划分股权可以调整贫富差距。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [200] [Can Machines Philosophize?](https://arxiv.org/abs/2507.00675)
> *机器能哲学化吗？*

*Michele Pizzochero, Giorgia Dellaferrera* | **Category: physics.soc-ph, cs.CY, physics.hist-ph**

**Keywords:** 机器哲学, 实验哲学, 科学实在论, 大型语言模型, 图灵测试

**Comment:** 

> **TL;DR:** 本文提出了一个评估机器哲学观点的新方法框架，发现机器的哲学观点与人类相似，但在科学实在论倾向上较弱，内部一致性更强，该框架有望改进实验哲学研究。

**AI_Comments:** 本文提出了一种创新的方法论框架，将大型语言模型应用于实验哲学领域，以评估机器的哲学倾向。其重要性在于提供了一种潜在的新途径，通过使用机器模仿者来克服传统实证研究中的效率和可重复性挑战。这可能为哲学研究带来新的范式，允许更大规模、更系统化的哲学观点探索。然而，该方法的局限性可能在于机器模仿的真实性和深度，以及它们是否能真正捕捉到人类哲学思维的细微差别和复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 受图灵测试启发，本文旨在评估机器在多大程度上反映人类的哲学观点，并探索利用机器替代人类参与者来解决实验哲学中基于调查的实证研究的效率和可重复性问题。

**Method:** 提出一个三步方法框架：(i) 指导机器模仿人类，反映其背景和信仰；(ii) 对人类和机器进行涵盖各种哲学立场的问卷调查；(iii) 统计分析结果。将此方法应用于科学实在论辩论，使用500多名人类参与者（包括物理学家和科学哲学家）的调查结果，并使用基于大型语言生成模型的AI引擎生成机器模仿者。

**Result:** 机器群体的哲学观点与人类群体（无论是物理学家还是科学哲学家）的观点平均而言相似。然而，与人类相比，机器对科学实在论的倾向较弱，其哲学立场表现出更强的一致性。

**Conclusion:** 鉴于人类和机器群体之间观察到的相似性，该方法框架可能为推进实验哲学研究提供前所未有的机会，通过用机器模仿者替代人类参与者，可能缓解影响基于调查的实证研究的效率和可重复性问题。

> **ai_Abstract:** 本文提出了一种新颖的方法框架，用于评估机器在多大程度上反映人类的哲学观点。该框架包含三个步骤：指导机器模仿人类、进行哲学问卷调查以及统计分析结果。研究将此方法应用于科学实在论的辩论，利用500多名人类参与者的调查数据和大型语言模型创建机器模仿者。结果显示，机器的哲学观点与人类平均相似，但机器对科学实在论的倾向较弱，且内部一致性更强。该研究认为，此框架有望通过机器替代人类参与者，来解决实验哲学中效率和可重复性问题。

> **摘要翻译:** 受图灵测试启发，我们提出了一种新颖的方法框架，用于评估机器群体在多大程度上反映人类群体的哲学观点。该框架包括三个步骤：(i) 指导机器模仿群体中的每个人类，反映他们的背景和信仰；(ii) 对人类和机器进行涵盖各种哲学立场的问卷调查；(iii) 统计分析所得结果。我们将此方法应用于科学实在论的辩论，这是一项探索科学与现实之间关系的长期哲学探究。通过考虑对500多名人类参与者（包括物理学家和科学哲学家）的调查结果，我们使用基于大型语言生成模型的人工智能引擎生成了他们的机器模仿者。我们发现，机器群体的哲学观点平均而言与人类群体所持的观点相似，无论他们是物理学家还是科学哲学家。然而，与人类相比，机器对科学实在论的倾向较弱，并且其哲学立场表现出更强的一致性。鉴于观察到的人类和机器群体之间的相似性，这种方法框架可能为推进实验哲学研究提供前所未有的机会，通过用机器模仿者替代人类参与者，可能缓解影响基于调查的实证研究的效率和可重复性问题。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [259] [Enhancing Car-Following Models with Bike Dynamics for Improved Traffic Simulation](https://arxiv.org/abs/2507.00062)
> *通过自行车动力学增强跟驰模型以改进交通仿真*

*Nico Ostendorf, Keno Garlichs, Lars Wolf* | **Category: physics.soc-ph, cs.SY, eess.SY**

**Keywords:** 交通模拟, 自行车动力学, SUMO, RBDM, 真实世界数据

**Comment:** 

> **TL;DR:** 该论文介绍了SUMO中首个专门的自行车动力学模型（RBDM），利用真实世界数据实现了更真实的自行车行为，显著优于现有近似方法，从而提高了交通模拟的准确性。

**AI_Comments:** 该论文的创新点在于为SUMO模拟器首次引入了专用的自行车动力学模型，填补了现有交通模拟工具在自行车行为建模方面的空白。其重要性在于，随着城市交通中自行车使用的增加，准确的自行车模拟对于城市规划、交通管理和智能交通系统（ITS）的开发至关重要。通过利用真实世界数据，RBDM显著提高了模拟的真实性。局限性可能在于模型对不同地理区域和数据收集方式的泛化能力，论文也提到了这一点并提供了适应建议。

<details>
  <summary>Details</summary>

**Motivation:** 现有的交通模拟器（如SUMO）在模拟自行车时存在显著不足，只能将其建模为慢速车辆或快速行人，这导致模拟结果与现实不符。鉴于自行车在交通中的重要性，需要一个更真实的自行车运动模型来提高交通模拟的准确性和效率。

**Method:** 论文引入了“现实自行车动力学模型”（RBDM），这是SUMO中第一个专门的自行车模型。该模型利用来自SimRa数据集的真实世界自行车数据，实现了自行车在城市场景中的真实速度、加速度和减速度行为。模型在摩纳哥SUMO交通场景和新生成的柏林场景中进行了评估。

**Result:** RBDM显著优于SUMO中现有的慢速车辆近似方法，与真实世界数据更吻合。结果强调了在准确模拟中，鉴于自行车、汽车和行人运动剖面的显著差异，一个真实的自行车运动模型的必要性。此外，模型还测试了其对不同场景和城市拓扑的泛化能力。

**Conclusion:** 一个真实的自行车运动模型对于准确的交通模拟至关重要，因为自行车、汽车和行人之间的运动特性存在显著差异。RBDM填补了SUMO中自行车建模的空白，提高了模拟的真实性。未来工作包括根据SimRa数据收集的方式和地理区域，推荐模型适应不同城市拓扑的方法。

> **ai_Abstract:** 本论文针对SUMO交通模拟器中自行车建模的不足，提出了首个专门的自行车动力学模型（RBDM）。通过利用SimRa数据集的真实世界自行车数据，RBDM在城市场景中实现了更准确的自行车速度、加速度和减速度行为。实验结果表明，RBDM显著优于现有的慢速车辆近似模型，与真实数据更吻合，强调了真实自行车模型对于提高交通模拟准确性的重要性。

> **摘要翻译:** 道路交通模拟对于建立安全高效的交通环境至关重要。它们用于在实际部署前测试各种道路应用。SUMO是一个知名的道路网络和多式联运交通模拟器，通常与其他工具结合使用以测试各种类型的应用。真实的模拟需要针对不同道路使用者（如汽车、自行车和公共汽车）的准确运动模型。虽然大多数车辆类型已经实现了真实的模型，但自行车（对于实现安全高效的交通至关重要）目前只能被建模为慢速车辆或快速行人。本文介绍了现实自行车动力学模型（RBDM），这是SUMO中第一个专门的自行车模型，解决了这一重大空白。RBDM利用来自SimRa数据集的真实世界自行车数据，实现了自行车在城市场景中的真实速度、加速度和减速度行为。评估使用摩纳哥SUMO交通场景和新生成的柏林场景进行。RBDM显著优于SUMO中现有的慢速车辆近似方法，与真实世界数据更吻合。这些结果强调了在一个真实的自行车运动模型在准确模拟中的必要性，鉴于自行车、汽车和行人运动剖面的显著差异。此外，模型还测试了其对不同场景和城市拓扑的泛化能力，这取决于SimRa数据收集的方式和地理区域。此外，还提供了关于如何使其适应不同城市拓扑的建议。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [430] [How large language models judge and influence human cooperation](https://arxiv.org/abs/2507.00088)
> *大型语言模型如何判断和影响人类合作*

*Alexandre S. Pires, Laurens Samson, Sennay Ghebreab, Fernando P. Santos* | **Category: physics.soc-ph, cs.AI, cs.SI**

**Keywords:** 大型语言模型, 人类合作, 社会决策, 进化博弈论, 规范校准

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLMs）对人类合作行为的判断能力及其对社会动态的长期影响，发现LLMs的判断存在一致性与差异性，这些差异会显著影响合作的普及率，并强调了校准LLM规范以维护人类合作的重要性。

**AI_Comments:** 这项研究具有重要的现实意义，因为它揭示了LLMs在社会决策中潜在的深远影响。其创新之处在于结合了LLM的行为评估与进化博弈论模型，从而能够预测LLM判断对长期社会合作动态的影响。研究还提供了校准LLM规范以促进亲社会行为的实用方法。潜在的局限性可能在于所选取的LLM样本的代表性，以及博弈论模型对现实复杂社会互动建模的简化程度。

<details>
  <summary>Details</summary>

**Motivation:** 人类日益依赖大型语言模型（LLMs）来支持社会决策，LLMs已被证明能影响人们的道德和政治判断。然而，基于LLM的社会决策对人类合作的长期影响尚不清楚，尤其是在间接互惠、声誉和判断他人互动驱动人类合作的背景下，这是一个紧迫的问题。

**Method:** 本研究首先评估了21个先进的LLM如何判断合作行为，通过提供大量在不同社会背景下个体合作或拒绝合作的例子，并询问这些互动应如何判断。其次，通过一个进化博弈论模型，评估了在LLM驱动的判断普遍存在的群体中合作动态，以评估LLM对人类亲社会行为的长期影响。最后，测试了能够引导LLM规范的提示，以探究此类干预如何塑造LLM的判断。

**Result:** 研究发现LLMs在评估与“好”对手的合作时表现出显著的一致性。然而，在判断与“声誉不佳”个体的合作时，模型内部和模型之间存在差异。研究表明，模型之间的这些差异可以显著影响合作的普及率。此外，测试表明通过提示可以引导LLM的规范，特别是通过面向目标的提示可以塑造LLM的判断。

**Conclusion:** 本研究将基于LLM的建议与长期社会动态联系起来，并强调了需要仔细校准LLM规范，以维护人类合作。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）如何判断人类合作行为及其对社会动态的长期影响。研究通过向21个LLM提供合作场景案例来评估其判断能力，并利用进化博弈论模型分析了LLM判断对合作普及率的影响。结果显示，LLMs在判断与“好”对手合作时表现出一致性，但在判断与“声誉不佳”个体合作时存在差异，这些差异显著影响了合作水平。研究还发现，可以通过特定提示引导LLM的判断。最终强调了为维护人类合作而校准LLM规范的重要性。

> **摘要翻译:** 标题：大型语言模型如何判断和影响人类合作

摘要：人类越来越依赖大型语言模型（LLMs）来支持社会环境中的决策。先前的研究表明，此类工具会影响人们的道德和政治判断。然而，基于LLM的社会决策的长期影响仍然未知。当社会互动的评估依赖于语言模型时，人类合作将如何受到影响？这是一个紧迫的问题，因为人类合作通常由间接互惠、声誉以及判断他人互动的能力驱动。在此，我们评估了最先进的LLMs如何判断合作行为。我们向21个不同的LLM提供了大量个体在各种社会情境中合作或拒绝合作的例子，并询问这些互动应如何判断。此外，通过一个进化博弈论模型，我们评估了在提取的LLM驱动判断普遍存在的群体中的合作动态，评估了LLM对人类亲社会行为的长期影响。我们观察到在评估与“好”对手的合作时存在显著的一致性。另一方面，我们注意到在判断与“声誉不佳”个体的合作时，模型内部和模型之间存在差异。我们表明，模型之间揭示的差异可以显著影响合作的普及率。最后，我们测试了引导LLM规范的提示，表明此类干预可以塑造LLM的判断，特别是通过面向目标的提示。我们的研究将基于LLM的建议与长期社会动态联系起来，并强调了需要仔细校准LLM规范，以维护人类合作。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [123] [Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31](https://arxiv.org/abs/2507.00059)
> *验证整数 p=31 的哈密顿路径猜想 (BHR 猜想)*

*Ranjan N Naik* | **Category: cs.DM, cs.DS, math.CO**

**Keywords:** 哈密顿路径猜想, BHR猜想, 图论, 猜想验证, 计算方法

**Comment:** This is a result an improvement over by Mariusz Meszka for all primes
  up to 23 (included) with the aid of a computer

> **TL;DR:** 本文提出了一种基于频率划分、局部/全局调整操作和回溯的方法，通过Python程序验证了BHR猜想，并将其验证范围扩展到p<37，是对先前工作的改进。

**AI_Comments:** 本文的创新点在于提出了基于频率划分、局部/全局调整操作和回溯的验证方法，并将其用Python程序实现，从而有效地将BHR猜想的验证范围从p=23扩展到p=31（甚至探索了p<37），这对于图论和组合数学领域的猜想验证具有重要意义。该工作展示了计算方法在数学猜想验证中的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** BHR（Buratti-Horak-Rosa）猜想（2006）提出，对于每个p和由(p-1)个正整数组成的模p多重集L，在完全图Kp中存在一条哈密顿路径，其连续边长由L的元素给出。本文旨在验证这一猜想。

**Method:** 本文提出了一种基于频率划分、局部/全局调整操作和回溯的方法来验证该猜想。数学策略、实验证据和Python程序实现被用于探索p < 37的有效哈密顿路径。

**Result:** 本文的结果将猜想的验证范围扩展到所有素数直至23（包括），并通过计算机辅助，进一步探索了p < 37的有效哈密顿路径。标题明确指出验证范围达到p=31。

**Conclusion:** 本文通过一种新方法和Python程序，成功验证了BHR猜想对于整数p最高达到31，并探索了p<37的情况，这比之前Mariusz Meszka的工作有所改进。

> **ai_Abstract:** 本文介绍了一种验证BHR（Buratti-Horak-Rosa）哈密顿路径猜想的方法。该方法基于频率划分、局部/全局调整操作和回溯，并通过Python程序实现。研究探索了p < 37的有效哈密顿路径，并成功将猜想的验证范围扩展到整数p=31，这比先前Mariusz Meszka的工作有所改进。

> **摘要翻译:** BHR（Buratti-Horak-Rosa）猜想（2006）提出，对于每个p和由(p-1)个正整数组成的模p多重集L，在完全图Kp中存在一条哈密顿路径，其连续边长由L的元素给出。在本文中，我们概述了一种基于频率划分和局部/全局调整操作以及回溯的猜想验证方法。我们描述了数学策略、实验证据以及在Python程序中的实现，以探索p < 37的有效哈密顿路径。这是对Mariusz Meszka在计算机辅助下对所有素数直至23（包括）的工作的改进。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [144] [$σ$-Maximal Ancestral Graphs](https://arxiv.org/abs/2507.00093)
> *$\\sigma$-最大祖先图*

*Binghua Yao, Joris M. Mooij* | **Category: cs.DM, cs.AI, cs.DS, math.ST, stat.TH**

**Keywords:** $\\sigma$-Maximal Ancestral Graphs, Cyclic Causal Relationships, Latent Variables, Markov Equivalence, Directed Graphs

**Comment:** It has beee accepted by the 41st Conference on Uncertainty in
  Artificial Intelligence (UAI)

> **TL;DR:** 最大祖先图（MAGs）无法表示循环因果关系。本文引入了$\\sigma$-最大祖先图（$\\sigma$-MAGs），以抽象地表示带有潜在变量的（可能循环的）有向图，并研究其性质。

**AI_Comments:** 这项工作通过引入$\\sigma$-MAGs，成功扩展了因果图模型的表示能力，使其能够处理循环因果关系，这是对现有MAGs理论的一个重要补充和创新。它为更复杂的因果模型分析提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 最大祖先图（MAGs）在表示带有潜在（选择）变量的有向无环图（DAGs）时，无法处理循环因果关系，这是一个显著的固有局限性。本文旨在解决这一限制。

**Method:** 本文引入并研究了一类新的图对象，命名为“$\\sigma$-最大祖先图”（$\\sigma$-MAGs）。该研究展示了这些图如何抽象地表示带有潜在（选择）变量的（可能循环的）有向图（DGs），并研究了这些对象的属性，提供了它们马尔可夫等价类的特征。

**Result:** 研究结果表明，$\\sigma$-最大祖先图（$\\sigma$-MAGs）能够提供带有潜在（选择）变量的（可能循环的）有向图（DGs）的抽象表示，成功扩展了传统最大祖先图（MAGs）在处理循环关系方面的能力。同时，本文还对$\\sigma$-MAGs的性质及其马尔可夫等价类进行了特征化。

**Conclusion:** 本文成功引入了$\\sigma$-最大祖先图（$\\sigma$-MAGs），解决了传统最大祖先图（MAGs）无法表示循环因果关系的局限性，为带有潜在变量的循环有向图的抽象表示提供了新的理论工具。

> **ai_Abstract:** 本文引入并研究了“$\\sigma$-最大祖先图”（$\\sigma$-MAGs），以解决传统最大祖先图（MAGs）无法表示循环因果关系的局限性。$\\sigma$-MAGs能够抽象表示带有潜在变量的（可能循环的）有向图，类似于MAGs表示有向无环图。文章详细探讨了$\\sigma$-MAGs的性质，并对其马尔可夫等价类进行了特征化。

> **摘要翻译:** 最大祖先图（MAGs）提供了一种带有潜在（选择）变量的有向无环图（DAGs）的抽象表示。这些图对象编码了它们所代表的DAGs的祖先关系和d-分离信息。这种抽象表示已被用于证明因果发现FCI算法的健全性和完备性，并为其输出推导do-演算。MAGs的一个显著固有局限性是它们排除了循环因果关系的可能性。在这项工作中，我们解决了这个局限性。我们引入并研究了一类我们称之为“$\\sigma$-最大祖先图”（“$\\sigma$-MAGs”）的图对象。我们展示了这些图如何提供带有潜在（选择）变量的（可能循环的）有向图（DGs）的抽象表示，类似于MAGs表示DAGs的方式。我们研究了这些对象的属性，并提供了它们马尔可夫等价类的特征。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [176] [Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context](https://arxiv.org/abs/2507.00288)
> *重构数字问责制：后国家会计背景下的AI驱动创新与跨国治理*

*Claire Li, David Freeborn* | **Category: econ.TH, cs.AI, cs.ET**

**Keywords:** 数字问责制, 人工智能, 跨国治理, 技术接受模型, 行动者网络理论

**Comment:** 22 pages

> **TL;DR:** 本研究探讨了人工智能如何重塑跨国治理背景下的组织问责制，并提出了两种组织策略来促进负责任的AI采纳。

**AI_Comments:** 该论文创新性地将技术接受模型、行动者网络理论和制度理论结合起来，深入探讨了AI在跨国背景下对问责制的影响，并提出了具体的组织策略，具有重要的理论和实践意义。其对问责制作为“关系和涌现属性”的重新概念化，为理解数字时代复杂治理挑战提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI系统越来越多地介导审计和财务报告等领域的决策，传统的问责机制正在被瓦解，因此需要探索AI驱动的数字创新如何重塑组织问责制。

**Method:** 本研究整合了技术接受模型（TAM）、行动者网络理论（ANT）和制度理论来分析组织如何采纳AI技术。研究扩展了TAM，将合规性和合法性纳入感知有用性和可用性的关键因素。借鉴ANT，将问责制重新概念化为网络集合体的关系和涌现属性。

**Result:** 研究认为，问责制是在全球社会技术网络中共同构建的，不仅受用户感知的影响，还受治理逻辑和规范期望的影响。提出了内部治理重构和外部行动者网络参与两种组织策略，以促进会计领域负责任、合法和全球接受的AI采纳。

**Conclusion:** 为了在会计领域促进负责任、合法和全球接受的AI采纳，组织应实施内部治理重构和外部行动者网络参与策略。

> **ai_Abstract:** 本研究探讨了人工智能驱动的数字创新如何重塑跨国治理背景下的组织问责制，因为AI系统正在瓦解传统的问责机制。通过整合技术接受模型、行动者网络理论和制度理论，研究分析了组织如何采纳AI以应对全球压力，并提出问责制是在全球社会技术网络中共同构建的。研究提出内部治理重构和外部行动者网络参与是促进负责任AI采纳的两种关键策略。

> **摘要翻译:** 本研究探讨了人工智能驱动的数字创新如何在跨国治理背景下重塑组织问责制。随着人工智能系统越来越多地介导审计和财务报告等领域的决策，基于控制、透明度和可审计性的传统问责机制正在被瓦解。我们整合了技术接受模型（TAM）、行动者网络理论（ANT）和制度理论，以检验组织如何响应超越国界的监管、道德和文化压力来采纳人工智能技术。我们认为，问责制是在全球社会技术网络中共同构建的，不仅受用户感知的影响，还受治理逻辑和规范期望的影响。在扩展TAM时，我们将合规性和合法性纳入感知有用性和可用性的关键因素。借鉴ANT，我们将问责制重新概念化为网络集合体的关系和涌现属性。我们提出了两种组织策略，包括内部治理重构和外部行动者网络参与，以促进会计领域负责任、合法和全球接受的人工智能采纳。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [183] [Hamiltonicity Parameterized by Mim-Width is (Indeed) Para-NP-Hard](https://arxiv.org/abs/2507.00612)
> *由Mim-宽度参数化的哈密顿性（确实）是Para-NP-Hard*

*Benjamin Bergougnoux, Lars Jaffke* | **Category: cs.CC, cs.DS, 68Q17, 68Q25, 68Q27**

**Keywords:** 哈密顿路径, 哈密顿环, NP-hard, mim-宽度, 参数化复杂性

**Comment:** 11 pages, 6 figures

> **TL;DR:** 证明了在给定线性mim-宽度为26的图上，哈密顿路径和哈密顿环问题是NP-hard，填补了之前证明中的一个空白。

**AI_Comments:** 这项研究的重要性在于它纠正了一个先前关于参数化复杂性理论中一个重要问题的错误证明，为该领域的进一步研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 填补了之前关于由mim-宽度参数化的哈密顿性问题是para-NP-hard的证明中的一个空白。

**Method:** 通过证明哈密顿路径和哈密顿环问题在线性mim-宽度为26的图上是NP-hard来完成。

**Result:** 证明了哈密顿路径和哈密顿环问题在线性mim-宽度为26的图上是NP-hard，即使输入图的线性顺序与mim-宽度一起提供。

**Conclusion:** 这项研究证实了由mim-宽度参数化的哈密顿性问题是para-NP-hard，纠正了之前一个有缺陷的证明。

> **ai_Abstract:** 本文证明了哈密顿路径和哈密顿环问题在具有线性mim-宽度26的图上是NP-hard，即使提供了相应的线性顺序。这一结果修正并填补了之前关于由mim-宽度参数化的哈密顿性问题是para-NP-hardness证明中的一个缺陷。

> **摘要翻译:** 我们证明了哈密顿路径和哈密顿环问题在线性mim-宽度为26的图上是NP-hard，即使在输入图的线性顺序与mim-宽度26一起提供的情况下也是如此。这填补了之前一个关于由mim-宽度参数化的哈密顿性问题的para-NP-hardness证明中的一个空白。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [202] [Quantum Speedups for Polynomial-Time Dynamic Programming Algorithms](https://arxiv.org/abs/2507.00823)
> *量子加速多项式时间动态规划算法*

*Susanna Caroppo, Giordano Da Lozzo, Giuseppe Di Battista, Michael T. Goodrich, Martin Nöllenburg* | **Category: quant-ph, cs.DS**

**Keywords:** 量子动态规划, 计算加速, 依赖有向图, Bellman-Ford算法, 空间复杂度

**Comment:** This is the extended version of a paper to appear at the 19th
  Algorithms and Data Structures Symposium (WADS 2025)

> **TL;DR:** 提出了一个量子动态规划框架，对大量经典动态规划算法实现计算加速，同时保持相同空间复杂度，并给出了具体的时间复杂度改进。

**AI_Comments:** 这篇论文的创新点在于提出了一个通用的量子动态规划框架，而非针对特定问题设计量子算法，这使得大量现有经典动态规划算法有望获得量子加速。其重要性在于为量子计算在组合优化领域的应用提供了新的范式，特别是在处理具有复杂依赖关系的子问题时，通过引入依赖有向图的平均度来量化加速效果，具有理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将大量经典动态规划算法扩展到量子领域，以实现计算加速。

**Method:** 引入了一个量子动态规划框架，该框架利用依赖有向图的平均度$\delta$来量化加速，能在$\tilde{O}(|V(G_{\mathcal{P}}(I))| \sqrt{\delta})$时间内解决问题。

**Result:** 实现了计算加速，同时保持了与经典算法相同的空间复杂度。例如，Bellman-Ford算法的量子版本在加权$n$顶点、$m$边的有向图中，运行时间为$\tilde{O}(n\sqrt{nm})$，在$m \in \Omega(n^{1.4})$时优于已知的最佳经典上限。

**Conclusion:** 该量子动态规划框架能够为广泛的经典动态规划算法提供量子加速，并在特定问题（如最短路径）上展现出显著的性能提升。

> **ai_Abstract:** 这篇论文提出了一个通用的量子动态规划框架，旨在将大量经典动态规划算法量子化，以实现计算加速。该框架在保持与经典算法相同空间复杂度的前提下，实现了基于依赖有向图平均度$\delta$的计算速度提升，具体时间复杂度为$\tilde{O}(|V(G_{\mathcal{P}}(I))| \sqrt{\delta})$。作为一个具体应用，研究者展示了Bellman-Ford最短路径算法的量子版本，其运行时间为$\tilde{O}(n\sqrt{nm})$，在特定条件下超越了现有最佳经典算法的性能。

> **摘要翻译:** 我们引入了一个量子动态规划框架，该框架允许我们将大量经典的动态规划算法直接扩展到量子领域。相应的量子动态规划算法在保持与其经典对应算法相同的空间复杂度的同时，实现了计算加速。对于组合（搜索或优化）问题$\mathcal P$和$\mathcal P$的实例$I$，这种加速可以用$I$的依赖有向图$G_{\mathcal{P}}(I)$的平均度$\delta$来表示，该图由$\mathcal P$的递归公式确定。该图的节点是$I$引起的子问题，其弧从每个子问题指向其解决方案所依赖的子问题。特别是，我们的框架允许我们在$\tilde{O}(|V(G_{\mathcal{P}}(I))| \sqrt{\delta})$时间内解决所考虑的问题。例如，我们获得了Bellman-Ford算法的量子版本，用于计算加权$n$顶点、$m$边有向图中从单个源顶点到所有其他顶点的最短路径，其运行时间为$\tilde{O}(n\sqrt{nm})$，当$m \in \Omega(n^{1.4})$时，这改进了已知的最佳经典上限。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [225] [Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD](https://arxiv.org/abs/2507.00254)
> *全并行BP解码量子LDPC码可超越BP-OSD*

*Ming Wang, Ang Li, Frank Mueller* | **Category: quant-ph, cs.IT, math.IT**

**Keywords:** 量子LDPC码, BP解码, 并行化, 推测性后处理, 解码复杂度

**Comment:** 

> **TL;DR:** 提出一种基于BP的轻量级并行解码器，结合推测性后处理，能以更低延迟实现与BP-OSD相当或更优的逻辑错误率，并显著降低解码复杂度。

**AI_Comments:** 创新点在于结合BP振荡统计和推测性后处理实现并行解码，并显著降低了量子LDPC码的解码延迟和复杂度，对量子纠错码的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种更高效、低延迟且低复杂度的量子LDPC码解码方法。

**Method:** 提出一种轻量级解码器，仅基于置信传播（BP），并结合受经典Chase解码启发的推测性后处理策略。该方法通过BP振荡统计识别不可靠比特，生成一组修改后的测试模式，并使用低迭代BP并行解码它们。

**Result:** 该方法在逻辑错误率上可与BP-OSD相当甚至更优，但在并行化方面具有更低的延迟，适用于多种双变量自行车码，显著降低了解码复杂度。

**Conclusion:** 所提出的轻量级并行BP解码器在性能上与现有先进方法相当，但在解码延迟和复杂度方面具有显著优势。

> **ai_Abstract:** 本文提出一种轻量级、全并行BP解码器，结合推测性后处理技术，通过分析BP振荡识别不可靠比特，并并行解码修改后的测试模式。实验表明，该解码器在逻辑错误率上可媲美BP-OSD，但在延迟和解码复杂度上表现更优，尤其适用于双变量自行车码。

> **摘要翻译:** 在这项工作中，我们提出了一种仅基于置信传播（BP）的轻量级解码器，并辅以受经典Chase解码启发的推测性后处理策略。我们的方法通过BP振荡统计识别不可靠比特，生成一组修改后的测试模式，并使用低迭代BP并行解码它们。我们证明了我们的方法可以实现与BP-OSD相当甚至更好的逻辑错误率，但对于各种双变量自行车码，其并行化具有更低的延迟，这显著降低了解码复杂度。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [250] [Authentication of Continuous-Variable Quantum Messages](https://arxiv.org/abs/2507.00095)
> *连续变量量子消息的认证*

*Mehmet Hüseyin Temel, Boris Škorić* | **Category: quant-ph, cs.CR, E.3**

**Keywords:** 量子认证, 连续变量, 陷阱态, 安全证明, Pauli Twirl

**Comment:** 15 pages

> **TL;DR:** 提出了首个用于连续变量量子态的量子认证方案，该方案基于陷阱态，并提供了安全证明。

**AI_Comments:** 该论文的创新点在于首次提出了针对连续变量量子态的认证方案，填补了量子信息安全领域的一个重要空白。其方法是对现有离散变量方案的扩展和优化，并通过严格的安全证明增强了方案的可靠性。推导Pauli Twirl的连续变量模拟也是一个重要的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究缺乏针对连续变量量子态的认证方案，本文旨在填补这一空白，引入首个此类方案，以增强量子通信的安全性。

**Method:** 该方案基于陷阱态，是对Broadbent等人提出的离散变量方案的改编，但提供了选择陷阱数量的更大自由度。安全证明主要遵循Broadbent和Wainewright的方法，并推导了Pauli Twirl的连续变量模拟作为证明的必要组成部分。

**Result:** 成功引入了首个针对连续变量量子态的量子认证方案，并为其提供了安全证明。此外，还推导了Pauli Twirl的连续变量模拟。

**Conclusion:** 本文成功引入了首个针对连续变量量子态的量子认证方案，并提供了严谨的安全证明，这为连续变量量子通信的安全领域做出了重要贡献。

> **ai_Abstract:** 本文提出了首个针对连续变量量子态的量子认证方案。该方案基于陷阱态，是对现有离散变量方案的改进，提供了更大的灵活性。作者为该方案提供了详细的安全证明，并为此目的推导了Pauli Twirl的连续变量模拟。

> **摘要翻译:** 我们引入了首个针对连续变量量子态的量子认证方案。我们的方案基于陷阱态，是Broadbent等人（arXiv:1211.1080）提出的离散变量方案的改编，但在陷阱数量的选择上具有更大的自由度。我们提供了安全证明，主要遵循Broadbent和Wainewright（arXiv:1607.03075）的方法。作为证明的必要组成部分，我们推导了Pauli Twirl的连续变量模拟。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [295] [Robustness Analysis for Quantum Systems Controlled by Continuous-Time Pulses](https://arxiv.org/abs/2507.00255)
> *连续时间脉冲控制下量子系统的鲁棒性分析*

*Sean Patrick O'Neil, Edmond Jonckheere, Sophie Schirmer* | **Category: quant-ph, cs.SY, eess.SY**

**Keywords:** 量子系统, 鲁棒性分析, 连续时间脉冲, 差分灵敏度, 完美保真度

**Comment:** 6 pages, 2 figures

> **TL;DR:** 本文将差分灵敏度技术推广到连续时间控制的闭合量子系统，证明了参数变化的零灵敏度与完美保真度一致，并基于哈密顿量和控制输入大小推导了灵敏度界限。

**AI_Comments:** 本文创新性地将差分灵敏度分析方法拓展到连续时间控制的量子系统，为量子系统的鲁棒性研究提供了理论基础和分析工具。其发现的零灵敏度与完美保真度的一致性以及灵敏度界限的推导，对于设计和优化鲁棒的量子控制方案具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将最初用于研究能量景观控制器鲁棒性的差分灵敏度技术推广到受连续变化控制的闭合量子系统，以分析其鲁棒性。

**Method:** 推广了差分灵敏度技术以研究受连续时间控制的闭合量子系统。基于系统哈密顿量和最大控制输入大小，推导了差分灵敏度幅度的界限。

**Result:** 证明了参数变化的零灵敏度与完美保真度一致。推导出了基于系统哈密顿量和最大控制输入大小的差分灵敏度幅度界限。

**Conclusion:** 差分灵敏度技术可有效分析连续时间控制下量子系统的鲁棒性，且零灵敏度与完美保真度等价，其灵敏度界限可被简单地确定。

> **ai_Abstract:** 本文将分析能量景观控制器鲁棒性的差分灵敏度技术推广应用于连续时间控制下的闭合量子系统。研究发现，参数变化的零灵敏度与完美保真度相符，并成功基于系统哈密顿量和控制输入的最大值推导出了差分灵敏度的幅度界限，为量子系统鲁棒性分析提供了新工具。

> **摘要翻译:** 最初用于研究能量景观控制器鲁棒性的差分灵敏度技术被推广到受连续变化控制的重要闭合量子系统案例中。结果表明，参数变化的零灵敏度与完美保真度一致，这与时间不变控制的情况相同。基于对系统哈密顿量和控制输入最大大小的简单了解，可以推导出对任何参数变化的差分灵敏度幅度的界限。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [321] [Segmentation-Based Regression for Quantum Neural Networks](https://arxiv.org/abs/2507.00065)
> *基于分段回归的量子神经网络*

*James C. Hateley* | **Category: quant-ph, cs.NA, math.NA**

**Keywords:** 量子神经网络, 分段回归, 混合量子-经典, 逆问题, 连续推理

**Comment:** 

> **TL;DR:** 本文提出了一种针对量子神经网络（QNNs）的基于分段的回归方法，通过将实值输出编码为数字序列并进行贪婪的逐位优化，实现了量子采样与经典推理的集成，并在偏微分方程约束的逆问题中展示了其有效性。

**AI_Comments:** 该论文的创新点在于提出了基于分段的回归方法，巧妙地将连续的回归问题转化为离散的组合优化问题，从而使量子神经网络能够处理实值输出。其混合量子-经典架构的设计，结合了量子计算的采样能力和经典计算的评估能力，为量子机器学习在实际问题中的应用提供了新的思路。在处理逆问题上的有效性展示了该方法的潜力，为量子硬件在科学计算中的应用提供了新的接口。

<details>
  <summary>Details</summary>

**Motivation:** 近期量子硬件的进展推动了将量子采样与经典推理相结合的算法框架的发展。

**Method:** 本文引入了一种针对量子神经网络（QNNs）的基于分段的回归方法，其中实值输出被编码为基-b数字序列并通过贪婪的逐位优化进行推断。通过将回归任务转换为结构化数字格上的约束组合问题，该方法将连续推理替换为可解释且易于处理的更新。采用混合量子-经典架构：量子电路通过投影测量生成候选数字，而经典前向模型根据特定任务的误差泛函评估这些候选数字。该算法从第一性原理进行了形式化，并推导了收敛性和复杂度界限。

**Result:** 该方法在涉及偏微分方程约束模型的逆问题上展示了其有效性。

**Conclusion:** 由此产生的框架为量子输出和连续科学推理之间提供了一个鲁棒、高精度的接口。

> **ai_Abstract:** 本文介绍了一种为量子神经网络（QNNs）量身定制的基于分段的回归方法，旨在将量子采样与经典推理相结合。该方法将实值输出编码为数字序列，并通过贪婪的逐位优化进行推断，从而将连续推理任务转化为可解释的组合问题。它采用混合量子-经典架构，利用量子电路生成候选数字，并由经典模型进行评估。文章还形式化了算法，推导了收敛性和复杂度界限，并通过解决偏微分方程约束的逆问题证明了其有效性，最终提供了一个连接量子输出与连续科学推理的鲁棒高精度框架。

> **摘要翻译:** 最近量子硬件的进展推动了将量子采样与经典推理相结合的算法框架的发展。这项工作引入了一种针对量子神经网络（QNNs）的基于分段的回归方法，其中实值输出被编码为基-b数字序列并通过贪婪的逐位优化进行推断。通过将回归任务转换为结构化数字格上的约束组合问题，该方法将连续推理替换为可解释且易于处理的更新。采用混合量子-经典架构：量子电路通过投影测量生成候选数字，而经典前向模型根据特定任务的误差泛函评估这些候选数字。我们从第一性原理形式化了该算法，推导了收敛性和复杂度界限，并在涉及偏微分方程约束模型的逆问题上展示了其有效性。由此产生的框架为量子输出和连续科学推理之间提供了一个鲁棒、高精度的接口。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [228] [Rust vs. C for Python Libraries: Evaluating Rust-Compatible Bindings Toolchains](https://arxiv.org/abs/2507.00264)
> *Rust 与 C 在 Python 库中的应用：评估 Rust 兼容的绑定工具链*

*Isabella Basso do Amaral, Renato Cordeiro Ferreira, Alfredo Goldman* | **Category: cs.PL, cs.DC, cs.PF, cs.SE, D.2.13; D.2.8; D.3.3; B.8**

**Keywords:** Python 性能, Rust, PyO3, 绑定工具链, ctypes, cffi

**Comment:** 10 pages, 27 figures (1 diagram, 4 graphs, 9 tables, 13 code
  listings), submitted to SBAC-PAD 2025

> **TL;DR:** Python 解释器速度慢，优化关键部分很复杂。本研究比较了 Rust 的 PyO3 绑定工具链与 ctypes 和 cffi，发现 PyO3 能够实现最先进的性能，且无需担心 API 兼容性。

**AI_Comments:** 这项研究强调了 Rust 在解决 Python 性能瓶颈方面的潜力。PyO3 工具链的引入提供了一种现代且高效的方法来编写高性能的 Python 扩展，解决了传统方法（如 ctypes 和 cffi）在易用性和 API 兼容性方面的痛点。其创新之处在于利用 Rust 的安全性和性能优势，为 Python 生态系统带来了显著的改进。

<details>
  <summary>Details</summary>

**Motivation:** Python 编程语言以其缓慢的解释器而闻名，优化关键代码段需要特殊的二进制交互知识，并且手动接口繁琐，常依赖复杂的第三方库。

**Method:** 本研究是一项比较研究，评估了 Rust 的 PyO3 Python 绑定工具链与 ctypes 和 cffi 的性能和易用性。

**Result:** 通过使用为 Python 开发的 Rust 工具，可以在不担心 API 兼容性的情况下实现最先进的性能。

**Conclusion:** Rust 兼容的绑定工具链，特别是 PyO3，通过提供高性能和无缝的 API 兼容性，为优化 Python 的关键部分提供了一种可行且优越的替代方案。

> **ai_Abstract:** 本文旨在解决 Python 解释器速度慢的问题及其优化关键部分的复杂性。研究通过比较 Rust 的 PyO3 Python 绑定工具链与 ctypes 和 cffi，评估了它们的性能和易用性。结果表明，使用为 Python 设计的 Rust 工具能够实现卓越的性能，同时避免了 API 兼容性问题，为 Python 性能优化提供了一种有效且先进的解决方案。

> **摘要翻译:** Python 编程语言以其语法和科学库而闻名，但也因其缓慢的解释器而臭名昭著。优化 Python 中的关键部分需要特殊的编程语言二进制交互知识，并且手动接口可能很麻烦，实现者通常会求助于复杂的第三方库。这项比较研究评估了 Rust 的 PyO3 Python 绑定工具链与 ctypes 和 cffi 的性能和易用性。通过使用为 Python 开发的 Rust 工具，我们可以在不担心 API 兼容性的情况下实现最先进的性能。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [251] [Estimating Correctness Without Oracles in LLM-Based Code Generation](https://arxiv.org/abs/2507.00057)
> *在基于LLM的代码生成中，无需预言机即可估计正确性*

*Thomas Valentin, Ardi Madadi, Gaetano Sapia, Marcel Böhme* | **Category: cs.PL, cs.AI, cs.LG, cs.SE**

**Keywords:** LLM, 代码生成, 正确性估计, 无预言机, 不连贯性

**Comment:** 8 pages + refs and appendix

> **TL;DR:** 提出了一种名为“不连贯性”的度量方法，可以在没有预言机的情况下有效估计LLM生成代码的错误率，并能可靠地替代基于预言机的评估。

**AI_Comments:** 这项研究的创新之处在于提出了一种在缺乏真实标签（预言机）的情况下，有效评估LLM代码生成正确性的新颖方法。这对于LLM在实际应用中的部署和迭代具有重要意义，因为它降低了评估成本，并提高了评估效率。其发现“不连贯性”可以可靠替代预言机评估，是推动LLM代码生成领域发展的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在从自然语言规范生成代码方面取得了成功，但存在“幻觉”问题，即生成语法正确但事实错误的输出。在没有现有正确实现（即预言机）的情况下，量化生成程序的正确性是一个挑战。

**Method:** 提出了一种名为“不连贯性”（incoherence）的错误度量方法，该方法可以在没有预言机的情况下高效估计，并提供错误率（即LLM为特定规范生成的程序不正确的概率）的下限。

**Result:** 实验表明，该方法非常有效。对于平均代码生成任务，基于不连贯性的方法可以自动识别约三分之二的不正确程序，且没有误报。基于不连贯性的LLM评估可以可靠地替代基于预言机的评估。特别是在LLM排名方面，通过预言机评估（pass@1）的正确程序数量排名与通过不连贯性评估的正确程序数量排名之间存在非常强的一致性。

**Conclusion:** 基于不连贯性的评估方法可以有效且可靠地在没有预言机的情况下估计LLM生成代码的正确性，甚至可以替代传统的基于预言机的评估。

> **ai_Abstract:** 本文提出了一种名为“不连贯性”的新型度量方法，用于在没有预言机的情况下估计大型语言模型（LLM）生成代码的正确性。鉴于LLM在代码生成中存在的“幻觉”问题，该方法旨在量化生成的程序不正确的可能性。实验结果表明，“不连贯性”能够高效且准确地识别出大量不正确代码（约三分之二），且无误报，并能可靠地替代传统的基于预言机的评估，尤其是在LLM性能排名方面表现出高度一致性。

> **摘要翻译:** 从自然语言规范生成代码是大型语言模型（LLM）最成功的应用之一。然而，它们会产生幻觉：LLM会生成语法正确但事实不准确的输出。在没有现有正确实现（即预言机）的情况下，我们能否量化生成的程序有多大可能是正确的？
在本文中，我们提出了一种不正确性度量，称为不连贯性，它可以在没有预言机的情况下高效估计，并提供错误率的下限，即LLM为该规范生成的程序不正确的概率。我们的实验展示了非凡的有效性。对于平均代码生成任务，我们基于不连贯性的方法可以自动识别约三分之二的不正确程序，且没有误报。事实上，基于预言机的LLM评估可以可靠地被基于不连贯性的评估所取代。特别是，我们发现通过预言机判断为正确的程序数量（pass@1）对LLM进行的排名与通过我们的不连贯性判断为正确的程序数量对LLM进行的排名之间存在非常强的一致性。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [253] [Linear rank-metric intersecting codes](https://arxiv.org/abs/2507.00569)
> *线性秩度量相交码*

*Daniele Bartoli, Martino Borello, Giuseppe Marino, Martin Scotti* | **Category: math.CO, cs.IT, math.IT**

**Keywords:** 秩度量码, 相交码, 线性码, 编码理论, 几何表征

**Comment:** 17 pages, 1 figure

> **TL;DR:** 本文引入并研究了秩度量相交码，探索了其编码理论和几何特性，并建立了与其他组合结构的关系。

**AI_Comments:** 本文引入了一种新的秩度量相交码，这在编码理论领域具有创新性。通过多角度（编码理论和几何）的深入分析，并与其他重要编码和组合结构建立联系，显示了其重要性。文章不仅提出了理论基础，还给出了构造方法和参数界限，但同时也指出仍有未探索的参数范围，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文引入并研究了一种新的线性码类别——秩度量相交码，其灵感来源于汉明度量中已充分研究的相交码概念。该研究旨在探索这种新类别在线性码秩度量上下文中的特性。

**Method:** 本文从编码理论和几何角度探索了秩度量相交码，突出了其与最小码、MRD码和汉明度量相交码的关系。研究方法包括推导结构性质、基于最小距离的充分条件、以及2-可张量q-系统方面的几何表征。此外，还建立了码参数的上下界并展示了一些构造。

**Result:** 研究结果包括揭示了秩度量相交码与最小码、MRD码和汉明度量相交码的关系。导出了结构性质、基于最小距离的充分条件以及2-可张量q-系统方面的几何表征。建立了码参数的上下界，并给出了一些构造。此外，还将秩相交码与其他组合结构（如(2,1)-分离系统和防伪码）联系起来。

**Conclusion:** 本文引入并详细研究了秩度量相交码这一新类别，揭示了其丰富的编码理论和几何特性，并建立了与其他重要编码和组合结构之间的联系，为该领域留下了进一步探索的参数范围。

> **ai_Abstract:** 本文介绍并深入研究了秩度量相交码，这是秩度量背景下的一种新型线性码，其定义是任意两个非零码字的支持非平凡地相交。研究从编码理论和几何两方面展开，揭示了其与最小码、MRD码和汉明度量相交码的内在联系。文章导出了其结构特性、基于最小距离的充分条件以及2-可张量q-系统形式的几何表征。同时，论文建立了码参数的上下界并提供了具体构造方法，并将其与其他组合结构如(2,1)-分离系统和防伪码建立了联系。

> **摘要翻译:** 本文引入并研究了秩度量相交码，这是秩度量背景下的一类新型线性码，其灵感来源于汉明度量中已充分研究的相交码概念。如果任意两个非零码字的支持非平凡地相交，则称一个秩度量码是相交的。我们从编码理论和几何角度探讨了这类码，强调了它与最小码、MRD码以及汉明度量相交码的关系。我们推导了结构性质、基于最小距离的充分条件以及2-可张量q-系统方面的几何表征。我们建立了码参数的上下界并展示了一些构造，这些构造留下了一系列未被探索的参数。最后，我们将秩相交码与其他组合结构（例如(2,1)-分离系统和防伪码）联系起来。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [270] [Time Invariant Sensor Tasking for Catalog Maintenance of LEO Space objects using Stochastic Geometry](https://arxiv.org/abs/2507.00076)
> *采用随机几何的时间不变传感器任务分配用于低地球轨道空间物体的目录维护*

*Partha Chowdhury, Harsha M, Chinni Prabhunath Georg, Arun Balaji Buduru, Sanat K Biswas* | **Category: astro-ph.IM, cs.RO, cs.SY, eess.SY, math-ph, math.MP**

**Keywords:** 空间物体目录维护, 传感器任务分配, 随机几何, 泊松点过程, 低地球轨道 (LEO) 

**Comment:** This work has been accepted and presented at the 35th AAS/AIAA Space
  Flight Mechanics Meeting, 2025, Kaua'i, Hawai

> **TL;DR:** 本文提出了一种利用随机几何和泊松点过程来优化地面传感器对低地球轨道空间物体进行时间不变跟踪和监视的方法，以提高目录维护效率和空间操作决策。

**AI_Comments:** 本文的创新点在于将随机几何（特别是泊松点过程）应用于地面传感器任务分配，以解决LEO空间物体目录维护中的挑战。这种方法提供了一个系统性的框架来优化传感器利用率和提高多目标跟踪效率，对于提升空间态势感知能力和支持空间安全与可持续性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 使用有限数量的地面传感器维护空间物体目录对空间界来说是一项艰巨而富有挑战性的任务。

**Method:** 本文提出了一种时间不变的跟踪和监视方法，通过优化地面传感器的指向，利用随机几何概念（特别是泊松点过程）来最大化从一组地面站观测到的空间物体数量。该方法提供了一个理解可见性模式和提高同时跟踪多个对象效率的系统框架。

**Result:** 本文提供了一个系统的框架，以理解可见性模式并提高同时跟踪多个物体的效率。

**Conclusion:** 该方法有助于在空间操作中做出更明智的决策，最终支持维护低地球轨道安全性和可持续性的努力。

> **ai_Abstract:** 本文提出了一种新颖的时间不变传感器任务分配方法，用于解决有限地面传感器在低地球轨道（LEO）空间物体目录维护中的挑战。该方法利用随机几何和泊松点过程来优化地面传感器的指向，以最大化可观测到的空间物体数量，并提供了一个理解可见性模式和提高多目标跟踪效率的系统框架。此研究旨在支持更明智的空间操作决策，从而维护LEO的安全性和可持续性。

> **摘要翻译:** 使用数量有限的地面传感器维护空间物体目录对空间界来说是一项艰巨而富有挑战性的任务。本文提出了一种通过优化地面传感器的指向，对低地球轨道（LEO）空间物体进行时间不变跟踪和监视的方法。我们的方法旨在利用随机几何的概念，特别是泊松点过程，从一组地面站最大化预期的空间物体数量。我们提供了一个系统的框架，以理解可见性模式并提高同时跟踪多个物体的效率。我们的方法有助于在空间操作中做出更明智的决策，最终支持维护低地球轨道安全性和可持续性的努力。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

### [514] [Template-Fitting Meets Deep Learning: Redshift Estimation Using Physics-Guided Neural Networks](https://arxiv.org/abs/2507.00866)
> *模板拟合与深度学习的结合：使用物理引导神经网络进行红移估计*

*Jonas Chris Ferrao, Dickson Dias, Pranav Naik, Glory D'Cruz, Anish Naik, Siya Khandeparkar, Manisha Gokuldas Fal Dessai* | **Category: astro-ph.IM, cs.LG**

**Keywords:** 光度红移, 模板拟合, 深度学习, 物理引导神经网络, 宇宙学

**Comment:** 

> **TL;DR:** 本文提出了一种结合模板拟合和深度学习的混合方法，用于精确的光度红移估计，并在PREML数据集上取得了优异性能。

**AI_Comments:** 该论文的创新点在于将传统的模板拟合方法与深度学习相结合，通过物理引导神经网络将物理先验知识融入模型训练中，这有助于提高模型的解释性和鲁棒性。多模态数据融合和不确定性估计的引入也增强了模型的实用性。该方法在实际天文巡天数据上的表现令人鼓舞，为未来的大规模宇宙学研究提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 准确的光度红移估计对于观测宇宙学至关重要，尤其是在光谱测量不切实际的大规模巡天中。传统方法各有优缺点，因此需要一种更鲁棒的方法。

**Method:** 本文提出了一种将模板拟合与深度学习相结合的混合方法，使用物理引导神经网络。该模型将光谱能量分布模板嵌入网络架构中，将物理先验编码到训练过程中。系统采用多模态设计，结合交叉注意力机制融合光度和图像数据，并使用贝叶斯层进行不确定性估计。

**Result:** 该模型在PREML数据集（包含约400,000个星系）上进行了评估，取得了0.0507的RMS误差，0.13%的3-sigma灾难性异常值率和0.0028的偏差。模型满足LSST对红移低于3的三个光度红移要求中的两个。

**Conclusion:** 这些结果突出了将物理驱动模板与数据驱动模型相结合，在即将到来的宇宙学巡天中进行鲁棒红移估计的潜力。

> **ai_Abstract:** 本文提出了一种结合模板拟合和深度学习的混合方法，用于光度红移估计。该方法利用物理引导神经网络，将光谱能量分布模板嵌入网络，编码物理先验，并通过多模态设计融合光度和图像数据，同时进行不确定性估计。在PREML数据集上的实验表明，该方法在RMS误差、异常值率和偏差方面表现出色，满足了部分LSST光度红移要求，证明了物理模板与数据驱动模型结合在宇宙学巡天中红移估计的潜力。

> **摘要翻译:** 准确的光度红移估计对于观测宇宙学至关重要，尤其是在光谱测量不切实际的大规模巡天中。传统方法包括模板拟合和机器学习，每种方法都有其独特的优点和局限性。我们提出了一种混合方法，将模板拟合与深度学习相结合，使用物理引导神经网络。通过将光谱能量分布模板嵌入网络架构中，我们的模型将物理先验编码到训练过程中。该系统采用多模态设计，结合交叉注意力机制融合光度和图像数据，并使用贝叶斯层进行不确定性估计。我们在公开可用的PREML数据集上评估了我们的模型，该数据集包含来自Hyper Suprime-Cam PDR3版本的大约400,000个星系，具有5波段测光、多波段成像和光谱红移。我们的方法实现了0.0507的RMS误差，0.13%的3-sigma灾难性异常值率和0.0028的偏差。该模型满足LSST对红移低于3的三个光度红移要求中的两个。这些结果突出了将物理驱动模板与数据驱动模型相结合，在即将到来的宇宙学巡天中进行鲁棒红移估计的潜力。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [278] [Observation of Blood Flow in Major Neck Vessels Modulated 1 by Physiological Maneuvers](https://arxiv.org/abs/2507.00231)
> *生理操作调节主要颈部血管血流的观察*

*Gennadi Saiko, Timothy Burton, Faraz Sadrzadeh-Afsharazar, Shota Yamashita, Kenshin Shimono, Yasuyuki Kakihana, Alexandre Douplik* | **Category: physics.med-ph, cs.SY, eess.SP, eess.SY**

**Keywords:** 血流, 生理操作, PPG, 颈部血管, 血流动力学

**Comment:** 

> **TL;DR:** 该研究通过PPG和ECG观察在各种生理操作下颈部血管的血流调节，发现新的操作如Valsalva和颈内静脉闭塞效果更显著。

**AI_Comments:** 该论文通过扩展用于颈部血管血流调节的生理操作范围，做出了有价值的贡献。将技术推向临床应用，在更真实的条件下进行测试的重点对于临床转化至关重要。发现Valsalva和颈内静脉闭塞等新操作更有效是一个关键创新点。其局限性在于样本量较小（两名健康志愿者），需要扩大样本量以实现更广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 过去的工作主要集中在正常生理条件和受控环境下的健康志愿者。本研究的动机是将技术推向临床应用，通过在更真实的条件下进行测试，并扩展用于血流调节的生理操作范围。

**Method:** 使用临床PPG和自建PPG传感器，并伴随ECG信号采集。从两名仰卧位的健康志愿者颈部收集数据。进行了七种操作（腹颈静脉压迫试验、屏气、Valsalva动作、右/左颈内静脉近端/远端闭塞）。每种操作持续1分钟，分为基线、实验和恢复三个阶段。比较了临床PPG的交流幅度、自建PPG的直流幅度以及ECG信号。

**Result:** 新提出的操作（Valsalva动作和颈内静脉闭塞）表现出比之前报道的操作（腹颈静脉压迫试验和屏气）更显著的血流调节。

**Conclusion:** 所提出的生理操作作为调节主要颈部血管血流的工具，展现出巨大的潜力。

> **ai_Abstract:** 本研究旨在推进无创血流动力学监测技术在临床中的应用，通过生理操作探讨主要颈部血管的血流调节。研究利用临床和自建PPG传感器以及ECG，收集了两名健康志愿者在七种不同操作（包括Valsalva动作和颈内静脉闭塞等新颖操作）下的数据。研究发现，这些新引入的操作比以往研究的方法能更显著地调节血流，突显了它们在各种真实临床环境中的潜在应用价值。

> **摘要翻译:** 大型颈部血管（颈动脉和颈内静脉，IJV）通过光学方式提供了一个独特的无创监测血流动力学的机会。过去工作的主要缺点是过于关注正常生理条件和良好受控环境下的健康志愿者。为了使这项技术更接近临床应用，需要在更真实的条件下进行测试，包括病理情况和实际环境（例如，类似于ICU或急诊护理设置）。当前工作的主要目标是通过引入新的操作并观察PPG对它们的响应，来扩展血流调节的生理操作范围。通过临床PPG和自建PPG传感器，并伴随ECG信号采集，收集了两名健康志愿者仰卧位时颈部的数据。七种操作（腹颈静脉压迫试验、屏气、Valsalva动作、右颈内静脉近端闭塞、右颈内静脉远端闭塞、左颈内静脉近端闭塞、左颈内静脉远端闭塞）按顺序进行，每种操作分配1分钟。这1分钟分为三个部分：基线（15秒）、实验（15秒）和恢复（30秒）。因此，实验总时长为7分钟。在所有七种生理操作期间，比较了临床PPG的交流幅度、自建PPG的直流幅度以及ECG信号。新提出的操作（Valsalva动作和IJV闭塞）表现出更显著的血流调节，这比之前报道的操作（腹颈静脉压迫试验和屏气）更显著。所提出的生理操作作为调节主要颈部血管血流的工具，展现出巨大的潜力。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [280] [Digital Collections Explorer: An Open-Source, Multimodal Viewer for Searching Digital Collections](https://arxiv.org/abs/2507.00961)
> *数字馆藏浏览器：一个用于搜索数字馆藏的开源多模态浏览器*

*Ying-Hsiang Huang, Benjamin Charles Germain Lee* | **Category: cs.DL, cs.IR**

**Keywords:** Digital Collections Explorer, CLIP, Multimodal Search, Digital Archives, Open-Source

**Comment:** 14 pages, 8 figures, 2 tables

> **TL;DR:** Digital Collections Explorer是一个开源的多模态网络平台，利用CLIP技术增强数字馆藏的视觉发现能力，支持自然语言和反向图像搜索，尤其适用于元数据匮乏的档案，并已证明其可扩展性和易用性。

**AI_Comments:** 该论文的创新点在于将CLIP等先进的多模态AI技术应用于数字馆藏的探索性搜索，尤其解决了元数据不全的数字档案的访问难题。其开源特性和本地部署能力降低了技术门槛，对民主化文化遗产数据的访问具有重要意义。易用性和可扩展性也为其广泛应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统数字馆藏的搜索方式可能无法有效进行视觉发现，尤其当元数据不完整时。本研究旨在通过开发一个利用多模态搜索技术（如CLIP）的平台，增强数字馆藏的视觉发现能力，并民主化对数字档案的访问，特别是那些元数据不完善的档案。

**Method:** 本研究提出了Digital Collections Explorer，一个基于网络的开源探索性搜索平台。该平台利用CLIP（对比语言-图像预训练）技术，实现了对数字馆藏的增强视觉发现。它支持自然语言查询和基于视觉特征的反向图像搜索。系统架构、实现和在各种文化遗产馆藏上的应用均有描述，并通过地图、照片和PDF的案例研究展示了其灵活性和易用性。

**Result:** Digital Collections Explorer可以本地安装和配置，只需几步即可在感兴趣的视觉馆藏上运行。它能够民主化对数字档案的访问，尤其适用于元数据匮乏的档案。案例研究展示了其在处理地图、照片和从网络档案中提取的PDF时的灵活性和易用性。该系统在配备M4芯片的MacBook Pro上可扩展到数十万张图像。此外，该项目还提供了一个公开演示。

**Conclusion:** Digital Collections Explorer是一个有效的开源多模态工具，能够通过利用CLIP技术和多模态搜索功能，显著提升数字馆藏的视觉发现能力，并为元数据不完善的数字档案提供更便捷的访问途径。其灵活性、易用性和可扩展性使其成为一个有潜力的解决方案。

> **ai_Abstract:** Digital Collections Explorer是一个开源的多模态网络平台，旨在通过利用CLIP技术和先进的多模态搜索方法，增强数字馆藏的视觉发现能力。该系统支持自然语言查询和反向图像搜索，易于本地安装和配置。研究通过案例研究展示了其在文化遗产馆藏中的应用潜力，尤其强调了其在民主化访问元数据匮乏档案方面的作用。该平台已证明其灵活性、易用性以及在大量图像上的可扩展性。

> **摘要翻译:** 我们提出了Digital Collections Explorer，一个基于网络的开源探索性搜索平台，它利用CLIP（对比语言-图像预训练）技术来增强数字馆藏的视觉发现。我们的Digital Collections Explorer可以本地安装和配置，只需几步即可在磁盘上感兴趣的视觉馆藏上运行。基于多模态搜索技术的最新进展，我们的界面能够对具有视觉特征的数字馆藏进行自然语言查询和反向图像搜索。本文描述了该系统的架构、实现及其在各种文化遗产馆藏中的应用，展示了其在民主化数字档案访问方面的潜力，特别是那些元数据匮乏的档案。我们提供了地图、照片和从网络档案中提取的PDF的案例研究，以展示Digital Collections Explorer的灵活性及其易用性。我们证明了Digital Collections Explorer可以在配备M4芯片的MacBook Pro上扩展到数十万张图像。最后，我们提供了一个Digital Collections Explorer的公开演示。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='mathfa'></a>
## math.FA 

### [319] [A Simple Proof of Nehari's Theorem Based on Duality](https://arxiv.org/abs/2507.00624)
> *基于对偶性的Nehari定理的简单证明*

*Cristian R. Rojas* | **Category: math.FA, cs.SY, eess.SY**

**Keywords:** Nehari定理, 凸对偶性, H无穷函数, 最优逼近

**Comment:** 11 pages

> **TL;DR:** 本文提供了一个基于凸对偶性的Nehari定理的简单证明。

**AI_Comments:** 这篇论文的创新点在于提供了一个更简洁的Nehari定理证明，这对于理解和应用该定理可能非常有益。其重要性在于简化了复杂数学定理的证明过程。

<details>
  <summary>Details</summary>

**Motivation:** 提供一个关于H无穷函数最优逼近的Nehari定理的简单证明。

**Method:** 基于凸对偶性来证明Nehari定理。

**Result:** 提供了一个Nehari定理的简单证明。

**Conclusion:** 通过凸对偶性可以提供Nehari定理的简单证明。

> **ai_Abstract:** 这篇技术笔记提出了一种基于凸对偶性的Nehari定理的简化证明方法，该定理涉及H无穷函数的最佳逼近。

> **摘要翻译:** 在这篇技术笔记中，我们提供了一个基于凸对偶性的关于H无穷函数最优逼近的Nehari定理的简单证明。

</details>

[⬆️ 返回分类顶部](#mathfa) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [334] [Affine-Invariant Global Non-Asymptotic Convergence Analysis of BFGS under Self-Concordance](https://arxiv.org/abs/2507.00361)
> *BFGS在自协调性下的仿射不变全局非渐近收敛性分析*

*Qiujiang Jin, Aryan Mokhtari* | **Category: math.OC, cs.NA, math.NA**

**Keywords:** BFGS, 拟牛顿法, 自协调性, 收敛性, 仿射不变

**Comment:** 

> **TL;DR:** 本文在目标函数严格凸且强自协调的条件下，证明了BFGS拟牛顿方法的全局非渐近收敛性，无需强凸性或梯度/Hessian的Lipschitz连续性假设，并首次建立了仿射不变的收敛性保证。

**AI_Comments:** 本文的创新之处在于，它成功地在比传统更弱的假设（即自协调性而非强凸性或Lipschitz连续性）下，为BFGS方法提供了严格的全局非渐近收敛性证明。更重要的是，它首次建立了BFGS的仿射不变收敛性保证，这与BFGS方法本身固有的仿射不变性完美契合，是理论上的一大进步，加深了我们对该算法行为的理解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的BFGS收敛性分析通常需要强凸性或梯度/Hessian的Lipschitz连续性等较强假设。本文旨在放宽这些限制，在更普适的条件下（即目标函数为严格凸且强自协调）为BFGS拟牛顿方法建立全局非渐近收敛性保证。

**Method:** 本文研究了BFGS拟牛顿方法，在目标函数严格凸且强自协调的设定下，对于任意初始点和任意正定初始Hessian近似，通过采用满足弱Wolfe条件的线搜索策略来确定步长，证明了BFGS的全局线性和超线性收敛性。

**Result:** 研究结果表明，BFGS方法在上述条件下具有全局线性和超线性收敛性。所有这些全局收敛性保证都是仿射不变的，且收敛速率仅取决于初始误差和强自协调常数。

**Conclusion:** 本文的工作将BFGS的全局非渐近收敛理论扩展到传统假设之外，并且首次建立了与BFGS方法固有的仿射不变性相符的仿射不变收敛性保证。

> **ai_Abstract:** 本文在目标函数严格凸且强自协调的条件下，对BFGS拟牛顿方法进行了全局非渐近收敛性分析。研究证明，在任意初始点和正定初始Hessian近似下，当采用满足弱Wolfe条件的线搜索时，BFGS具有全局线性和超线性收敛性。这些收敛性保证是仿射不变的，并且收敛速率仅依赖于初始误差和自协调常数。这项工作扩展了BFGS的收敛理论，并首次引入了仿射不变的收敛性证明。

> **摘要翻译:** 在本文中，我们建立了BFGS拟牛顿方法的全局非渐近收敛性保证，而无需强凸性或梯度或Hessian的Lipschitz连续性。相反，我们考虑了目标函数严格凸且强自协调的设置。对于任意初始点和任意正定初始Hessian近似，我们证明了当步长使用满足弱Wolfe条件的线搜索方案确定时，BFGS具有全局线性和超线性收敛性保证。此外，我们所有的全局保证都是仿射不变的，收敛速率仅取决于初始误差和强自协调常数。我们的结果将BFGS的全局非渐近收敛理论扩展到传统假设之外，并首次建立了与BFGS方法固有的仿射不变性相符的仿射不变收敛性保证。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [339] [Ranking Quantilized Mean-Field Games with an Application to Early-Stage Venture Investments](https://arxiv.org/abs/2507.00853)
> *排序分位数平均场博弈及其在早期风险投资中的应用*

*Rinel Foguen Tchuendom, Dena Firoozi, Michèle Breton* | **Category: math.OC, cs.SY, eess.SY, q-fin.MF**

**Keywords:** 分位数平均场博弈, 排序博弈, 早期风险投资, 纳什性质, 近似

**Comment:** 

> **TL;DR:** 本文研究了具有排序能力的分位数平均场博弈，其中代理人的表现根据其终端状态相对于群体$\\alpha$-分位数进行评估，旨在选择表现最佳的代理人。论文提出了两种公式（目标型和阈值型），获得了分析解和半显式解，并将其应用于早期风险投资，发现目标型公式能很好地近似阈值型公式。

**AI_Comments:** 本文的创新之处在于将分位数概念引入平均场博弈中，并赋予模型排序和选择的能力，这对于需要筛选顶尖表现者的场景（如风险投资）具有重要的实际意义。提出了两种不同的建模方法并提供了相应的理论分析和数值求解方案，特别是发现目标型公式可以作为阈值型公式的有效近似，这简化了实际应用中的计算复杂性。该研究为理解和设计基于排名的群体行为策略提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究一类具有排序能力的分位数平均场博弈模型，其中代理人的表现是根据其终端状态相对于群体分布的特定分位数来评估的，以选择表现最佳的代理人。具体应用背景是早期风险投资中，风险投资公司需要从一组初创公司中选出表现最好的公司进行下一轮融资。

**Method:** 研究了一类具有排序能力的分位数平均场博弈模型，其中代理人的表现基于其终端状态相对于群体$\\alpha$-分位数的值进行评估。提出了两种竞争公式：目标型公式和阈值型公式。对于目标型公式，获得了分析解并证明了N人博弈中渐近最佳响应策略的$\\epsilon$-纳什性质，其中分位数平均场一致性条件表示为一组前向-后向常微分方程。对于阈值型公式，获得了半显式解并数值求解了得到的分位数平均场一致性条件。随后，将模型应用于早期风险投资，并通过数值实验展示了两种公式的结果和解释。

**Result:** 对于目标型公式，获得了分析解，并证明了N人博弈中渐近最佳响应策略的$\\epsilon$-纳什性质，其分位数平均场一致性条件由一组前向-后向常微分方程描述。对于阈值型公式，获得了半显式解，并通过数值方法求解了其分位数平均场一致性条件。在早期风险投资的应用中，数值实验结果表明，目标型公式能很好地近似阈值型公式。

**Conclusion:** 本文成功构建并分析了一类具有排序能力的分位数平均场博弈模型，提出了目标型和阈值型两种建模方法，并为它们提供了分析或半显式解。通过将其应用于早期风险投资，验证了模型的实际应用价值，并指出目标型公式可以作为阈值型公式的良好近似。

> **ai_Abstract:** 本文研究了一类具有排序能力的分位数平均场博弈模型，其中代理人的表现是根据其终端状态相对于群体特定分位数进行评估的，旨在选择顶尖表现者。论文提出了目标型和阈值型两种竞争公式，并分别获得了分析解和半显式解。研究证明了目标型公式的$\\epsilon$-纳什性质，并将其应用于早期风险投资中的公司筛选问题。数值实验结果显示，目标型公式能很好地近似阈值型公式。

> **摘要翻译:** 分位数平均场博弈模型涉及群体分布的分位数。我们研究了一类具有排序能力的分位数平均场博弈，其中每个代理人的表现根据其终端状态相对于群体$\\alpha$-分位数的值进行评估，其中$\\alpha \in (0,1)$。这种评估标准旨在选择表现最佳的$(1-\\alpha)\\%$的代理人。我们为这种竞争提供了两种公式：目标型公式和阈值型公式。在前一种和后一种公式中，为了满足选择条件，每个代理人都力求其终端状态分别	extit{精确地}等于和	extit}至少}等于群体$\\alpha$-分位数的值。

对于目标型公式，我们获得了分析解，并证明了N人博弈中渐近最佳响应策略的$\\epsilon$-纳什性质。具体来说，分位数平均场一致性条件表示为一组前向-后向常微分方程，表征了均衡时的$\\alpha$-分位数。对于阈值型公式，我们获得了半显式解，并数值求解了得到的分位数平均场一致性条件。

随后，我们提出了一个在早期风险投资背景下的新应用，其中一家风险投资公司在有限的时间范围内为一群参与竞争的初创公司提供资金支持，目标是在时间期末选择一定比例的顶尖公司以获得下一轮融资。我们展示了在此背景下讨论的两种公式的数值实验结果和解释，并表明目标型公式为阈值型公式提供了非常好的近似。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [355] [General Perturbation Resilient Dynamic String-Averaging for Inconsistent Problems with Superiorization](https://arxiv.org/abs/2507.00717)
> *具有优越化的非一致问题通用扰动弹性动态弦平均法*

*Kay Barshad, Yair Censor* | **Category: math.OC, cs.NA, math.FA, math.NA, 46N10, 46N40, 47H09, 47H10, 47J25, 47N10, 65F10, 65J99**

**Keywords:** 通用动态弦平均, 非一致问题, 强相干性, 优越化, 迭代方法

**Comment:** 31 pages. Accepted for publication in Journal of Optimization Theory
  and Applications

> **TL;DR:** 本文引入了一种通用动态弦平均（GDSA）迭代方案，并研究了其在非一致情况下的收敛性，包括弱收敛和强收敛，以及有界扰动弹性。该方法结合了动态弦平均和强相干性的思想，并应用于优越化方法。

**AI_Comments:** 本文的创新之处在于将动态弦平均方法推广到更具挑战性的非一致问题场景，这在实际应用中具有重要意义。引入并利用“强相干性”这一较新的概念作为收敛性证明的工具，不仅提升了理论严谨性，也为未来迭代算法的分析提供了新的范式。此外，将GDSA应用于优越化方法，进一步拓展了其应用范围和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 以往的动态弦平均投影（DSAP）算法主要研究了其在一致情况下的收敛性。本文的动机是研究当输入算子没有共同不动点时，即在非一致情况下，通用动态弦平均（GDSA）迭代方案的收敛性质及其有界扰动弹性，并将其应用于优越化方法。

**Method:** 本文引入了通用动态弦平均（GDSA）迭代方案。该方法结合了动态弦平均的思想和“强相干性”序列算子的概念（这是对2001年引入的“相干性”的改进），以证明其收敛性。

**Result:** 研究了GDSA方法在非一致情况下对一般算子类的有界扰动弹性，并证明了其弱收敛和强收敛性质。此外，还讨论了GDSA方法在优越化方法中的应用，并开发了其优越化版本的行为结果。

**Conclusion:** 本文成功引入了通用动态弦平均（GDSA）迭代方案，并在非一致问题中，结合强相干性概念，分析了其收敛性和有界扰动弹性。研究结果表明GDSA方法能够有效处理非一致问题，并可应用于优越化方法，为其优越化版本的行为提供了理论基础。

> **ai_Abstract:** 本文介绍了一种通用动态弦平均（GDSA）迭代方案，旨在解决非一致问题。该方案通过结合动态弦平均和“强相干性”的概念，分析了其在算子无共同不动点情况下的弱收敛、强收敛及有界扰动弹性。研究还探讨了GDSA方法在优越化方法论中的应用及其优越化版本的行为。

> **摘要翻译:** 在本文中，我们引入了一种通用动态弦平均（GDSA）迭代方案，并研究了其在非一致情况下的收敛性质，即当输入算子没有共同不动点时。动态弦平均投影（DSAP）算法本身是在2013年的一篇论文中引入的，其中研究了其在一致情况下（即所考虑的集合具有非空交集时）的强收敛性和有界扰动弹性。涉及DSAP方法与优越化结合的结果于2015年提出。我们的GDSA方法的弱收敛性证明基于2019年引入的“强相干性”算子序列的概念。这是对Bauschke和Combettes于2001年引入的算子序列“相干性”性质的改进。强相干性为采用无限算子序列的方法提供了一个更方便的充分收敛条件，并且在证明许多迭代方法的收敛性时，它被证明是一个有用的通用工具。在本文中，我们结合了动态弦平均和强相干性的思想，以分析我们的GDSA方法在一般算子类中的应用，以及其在非一致情况下的有界扰动弹性与弱收敛和强收敛性。然后，我们讨论了GDSA方法在优越化方法论中的应用，开发了其优越化版本行为的结果。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [364] [Swarm-based optimization with jumps: a kinetic BGK framework and convergence analysis](https://arxiv.org/abs/2507.00871)
> *基于跳跃的群优化：动力学BGK框架和收敛性分析*

*Giacomo Borghi, Hyesung Im, Lorenzo Pareschi* | **Category: math.OC, cs.NA, math.NA, 65K10, 90C26, 65C35, 82C40, 35Q90**

**Keywords:** 群优化, 动力学BGK, 随机跳跃, 收敛性分析, 基于共识的优化

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于随机跳跃的群优化算法，通过动力学BGK框架进行建模，并提供了收敛性分析。

**AI_Comments:** 本文的创新之处在于将随机跳跃引入粒子群优化中，并使用动力学BGK框架进行严格的理论形式化。这不仅允许统一处理不同类型的噪声分布，还为算法提供了坚实的收敛性理论基础。此外，发现其与CBO的连接也具有重要意义，可能为两种算法的进一步研究和融合提供新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 元启发式算法是全局优化的强大工具，尤其适用于精确方法不切实际的非凸和不可微问题。基于粒子的优化方法因其在探索和利用之间的平衡而有效，本工作旨在通过引入随机跳跃来增强这类算法的随机探索能力。

**Method:** 引入了一种新的基于粒子的优化算法，其速度通过随机跳跃更新。该方法通过BGK类型的动力学建模进行形式化，提供了一个统一的框架来适应包括重尾分布在内的通用噪声分布。在适当的参数缩放下，该模型可简化为基于共识的优化（CBO）动力学。对于有界域中的非退化高斯噪声，证明了混沌传播和向最小值的收敛。

**Result:** 在基准问题上的数值结果验证了该方法的有效性，并突出了其与CBO的联系。对于特定条件下的噪声，理论上证明了向最小值的收敛性。

**Conclusion:** 本文提出了一种新颖且可证明收敛的基于随机跳跃的群优化算法，该算法通过动力学BGK模型进行构建，并与CBO存在联系。

> **ai_Abstract:** 本文提出了一种新颖的基于粒子群的优化算法，通过随机跳跃更新粒子速度以增强随机探索。该算法的动力学通过BGK类型的动力学模型进行形式化，提供了一个能适应各种噪声分布的统一框架。研究表明，在特定参数条件下，该模型可简化为基于共识的优化（CBO）动力学。对于有界域中的非退化高斯噪声，论文证明了混沌传播和向最小值的收敛性。数值实验验证了该方法的有效性及其与CBO的关联。

> **摘要翻译:** 元启发式算法是全局优化的强大工具，特别是对于精确方法通常不切实际的非凸和不可微问题。受群体智能原理启发的基于粒子的优化方法，由于其在搜索空间内平衡探索和利用的能力而显示出有效性。在这项工作中，我们引入了一种新颖的基于粒子的优化算法，其中速度通过随机跳跃更新，这是一种常用于增强随机探索的策略。我们通过描述BGK类型的动力学模型来形式化这种方法，提供了一个统一的框架，可以适应一般的噪声分布，包括柯西等重尾分布。在适当的参数缩放下，该模型可简化为基于共识的优化（CBO）动力学。对于有界域中的非退化高斯噪声，我们证明了混沌传播和向最小值的收敛。基准问题的数值结果验证了该方法并突出了其与CBO的联系。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [341] [Learning collective variables that respect permutational symmetry](https://arxiv.org/abs/2507.00408)
> *学习尊重置换对称性的集体变量*

*Jiaxin Yuan, Shashank Sule, Yeuk Yin Lam, Maria Cameron* | **Category: physics.chem-ph, cs.NA, math.NA, 82B31, 60G99, 70F99**

**Keywords:** 集体变量, 置换对称性, 粗粒度模型, 过渡速率, 自编码器

**Comment:** 66 pages, 35 figures, 18 tables

> **TL;DR:** 本文提出了一种学习集体变量的数值框架，该框架尊重平移、旋转和置换对称性，并能准确估计过渡速率和驻留时间，通过结合特征化、流形学习和自编码器实现。

**AI_Comments:** 该论文的创新之处在于提出了一种系统性的数值框架，能够有效地学习同时尊重平移、旋转和置换对称性的集体变量，这对于准确模拟多体系统动力学至关重要。其结合自编码器和特定损失函数的方法，以及在过渡路径采样中的应用，展现了其在复杂物理系统建模方面的潜力。结果与暴力方法的一致性验证了其准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在相同相互作用粒子团簇的粗粒度模型中，识别亚稳态、有效描述动力学和估计过渡速率至关重要，但需要学习能够尊重平移、旋转和置换对称性的集体变量。

**Method:** 提出了一种数值框架，结合了基于排序的特征化、特征空间中的驻留流形学习，以及使用其损失函数利用正交关系的自编码器来学习集体变量。该方法使用降维模型的committor作为反应坐标，用于正向通量采样和设计过渡路径过程的采样控制。通过二维Lennard-Jones-7和三维Lennard-Jones-8进行了案例研究。

**Result:** 降维模型计算出的过渡速率和驻留时间与通过暴力方法获得的结果一致。

**Conclusion:** 所提出的学习尊重平移、旋转和置换对称性的集体变量的框架能够准确估计过渡速率和驻留时间，并通过与暴力方法的结果一致性得到了验证。

> **ai_Abstract:** 本文介绍了一种用于学习集体变量的数值框架，该框架专门处理具有平移、旋转和置换对称性的粒子系统。该框架通过结合基于排序的特征化、特征空间中的流形学习以及利用正交关系损失函数的自编码器来构建。它利用降维模型的committor作为反应坐标，以估计过渡速率和驻留时间。通过对Lennard-Jones-7和Lennard-Jones-8系统的案例研究，证明了该方法计算出的结果与传统暴力方法的结果一致。

> **摘要翻译:** 除了平移和旋转对称性，相同相互作用粒子团簇还具有置换对称性。此类系统的粗粒度模型对于识别亚稳态、提供其动力学的有效描述以及估计过渡速率至关重要。我们提出了一种数值框架，用于学习尊重平移、旋转和置换对称性的集体变量，并用于估计过渡速率和驻留时间。它结合了基于排序的特征化、特征空间中的驻留流形学习，以及使用其损失函数利用正交关系（Legoll和Lelievre，2010）的自编码器学习集体变量。所得降维模型的committor被用作正向通量采样中的反应坐标，并用于设计采样过渡路径过程的控制。我们提供了两个案例研究，二维的Lennard-Jones-7和三维的Lennard-Jones-8。借助降维模型计算出的过渡速率和驻留时间与通过暴力方法获得的结果一致。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

### [498] [Augmenting Molecular Graphs with Geometries via Machine Learning Interatomic Potentials](https://arxiv.org/abs/2507.00407)
> *通过机器学习原子间势增强分子图的几何结构*

*Cong Fu, Yuchao Lin, Zachary Krueger, Haiyang Yu, Maho Nakata, Jianwen Xie, Emine Kucukbenli, Xiaofeng Qian, Shuiwang Ji* | **Category: physics.chem-ph, cs.AI, q-bio.QM**

**Keywords:** 机器学习原子间势, 分子几何, 性质预测, 弛豫数据集, 基础模型

**Comment:** 

> **TL;DR:** 本文通过在大型弛豫数据集上训练机器学习原子间势（MLIP）基础模型，旨在以更经济的方式获取分子3D几何结构，从而替代昂贵的密度泛函理论（DFT）方法，并展示其在分子性质预测中的益处。

**AI_Comments:** 本文的创新之处在于利用在大型分子弛豫数据集上训练的机器学习原子间势（MLIP）基础模型来获取分子3D几何结构，这为传统昂贵的密度泛函理论（DFT）方法提供了一个经济高效的替代方案。其提出的两种几何结构获取方式——显式几何优化和隐式直接微调——也值得关注。该研究的重要性在于能够加速分子性质预测，这对于药物发现和材料科学等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的分子性质预测需要3D几何结构，但获取这些结构（例如通过密度泛函理论DFT）成本高昂。本文旨在仅依靠机器学习原子间势（MLIP）模型来获取分子几何结构。

**Method:** 首先，作者构建了一个包含350万个分子和3亿个快照的大规模分子弛豫数据集。然后，使用监督学习训练MLIP基础模型，使其能够根据3D分子结构预测能量和力。训练完成后，这些基础模型可以通过两种方式获取几何结构：一是通过几何优化明确地获取低能量3D几何结构，并引入几何微调以减少潜在偏差；二是当有真实3D几何结构时，直接对基础模型进行微调以进行性质预测。

**Result:** 结果表明，在弛豫数据上训练的MLIP基础模型能够提供有价值的分子几何结构，从而有利于分子性质预测。

**Conclusion:** 在弛豫数据上训练的机器学习原子间势（MLIP）基础模型能够有效提供有价值的分子几何结构，显著提升分子性质预测的准确性。

> **ai_Abstract:** 本文旨在解决获取准确分子性质预测所需3D几何结构的高昂成本问题，提出利用机器学习原子间势（MLIP）模型。研究人员构建了一个包含350万个分子和3亿个快照的大规模分子弛豫数据集，并在此基础上训练MLIP基础模型以预测能量和力。这些模型可以显式地通过几何优化获取低能量3D几何结构（并进行几何微调），或在有真实3D几何结构时隐式地直接微调以进行性质预测。实验结果表明，在弛豫数据上训练的MLIP基础模型能够提供有价值的分子几何结构，从而有效提升分子性质预测的性能。

> **摘要翻译:** 准确的分子性质预测需要3D几何结构，这些结构通常通过密度泛函理论（DFT）等昂贵的方法获得。本文尝试仅依靠机器学习原子间势（MLIP）模型来获取分子几何结构。为此，我们首先整理了一个大规模分子弛豫数据集，包含350万个分子和3亿个快照。然后，使用监督学习训练MLIP基础模型，以根据3D分子结构预测能量和力。一旦训练完成，我们展示了基础模型可以以不同方式显式或隐式地获取几何结构。首先，它可以通过几何优化获得低能量3D几何结构，为下游分子性质预测提供弛豫的3D几何结构。为了减轻潜在偏差并增强下游预测，我们引入了基于弛豫3D几何结构的几何微调。其次，当存在真实3D几何结构时，基础模型可以直接微调用于性质预测。我们的结果表明，在弛豫数据上训练的MLIP基础模型可以提供有价值的分子几何结构，从而有益于性质预测。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [345] [Forward Reverse Kernel Regression for the Schrödinger bridge problem](https://arxiv.org/abs/2507.00640)
> *薛定谔桥问题的正反向核回归*

*Denis Belomestny, John. Schoenmakers* | **Category: stat.ML, cs.LG, cs.NA, math.NA, 90C40, 65C05, 62G08**

**Keywords:** 薛定谔桥问题, 核回归, 蒙特卡洛方法, 熵最优传输, 收敛性

**Comment:** 

> **TL;DR:** 本文提出了一种基于核回归的正反向蒙特卡洛迭代算法，用于非参数近似薛定谔桥问题的势函数，并证明了其收敛性和最优性。

**AI_Comments:** 该论文的创新之处在于提出了一个结合正反向蒙特卡洛模拟和核回归的非参数方法来解决薛定谔桥问题，并提供了严格的收敛性证明和收敛率分析。其重要性在于为熵最优传输提供了一种高效且理论上可靠的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 薛定谔桥问题 (SBP) 是熵最优传输的核心问题。

**Method:** 提出了一种正反向迭代蒙特卡洛过程，通过核回归在Picard迭代框架下非参数地近似薛定谔势，并确保迭代中的正性和收缩性。

**Result:** 开发了一种可证明收敛的算法，提供了势函数估计的收敛率并证明了其最优性。此外，提出了一种非嵌套蒙特卡洛过程用于薛定谔桥过程的最终维度分布。

**Conclusion:** 该研究成功开发了一种用于薛定谔桥问题的可证明收敛且最优的非参数近似方法，并展示了其在实际应用中的潜力。

> **ai_Abstract:** 本文研究了熵最优传输中的薛定谔桥问题，提出了一种正反向迭代蒙特卡洛方法，利用核回归在Picard迭代框架下非参数地近似薛定谔势。该算法被证明是收敛的，并提供了最优的收敛率。此外，还提出了一个非嵌套蒙特卡洛过程用于薛定谔桥过程的最终维度分布估计。

> **摘要翻译:** 标题：薛定谔桥问题的正反向核回归
摘要：在本文中，我们研究了薛定谔桥问题（SBP），它是熵最优传输的核心。对于一般的参考过程和起始-终点分布，我们提出了一种正反向迭代蒙特卡洛过程，以非参数方式近似薛定谔势。特别地，我们在对应不动点问题的Picard迭代背景下，使用基于核的蒙特卡洛回归。通过在迭代中保持希尔伯特度量意义上的正性和收缩性，我们开发了一种可证明收敛的算法。此外，我们提供了势函数估计的收敛率并证明了它们的最优性。最后，作为一项应用，我们基于构建的势函数和用于条件扩散的正反向模拟方法，为薛定谔桥过程的最终维度分布提出了一种非嵌套蒙特卡洛过程。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [502] [Disentangled Feature Importance](https://arxiv.org/abs/2507.00260)
> *解耦特征重要性*

*Jin-Hong Du, Kathryn Roeder, Larry Wasserman* | **Category: stat.ML, cs.LG, math.ST, stat.ME, stat.TH**

**Keywords:** 特征重要性, 最优传输, 解耦, 相关性偏差, DFI

**Comment:** 26 main and 29 supplementary pages

> **TL;DR:** 当预测变量相关时，现有特征重要性量化方法会低估其贡献。本文提出“解耦特征重要性（DFI）”方法，通过最优传输将相关特征转换为独立潜在变量，消除相关性偏差，并提供了全面的半参数理论支持，同时计算效率高。

**AI_Comments:** 这篇论文提出了一种新颖且理论严谨的方法来解决特征重要性量化中的一个核心挑战——即相关性引起的偏差。通过引入最优传输将相关特征解耦，DFI提供了一个强大的框架。其半参数理论支持以及计算效率的优势，使其在实际应用中具有显著潜力。该方法对理解复杂模型中的特征贡献具有重要意义，尤其是在高维和多重共线性数据场景下。

<details>
  <summary>Details</summary>

**Motivation:** 特征重要性量化面临一个根本挑战：当预测变量相关时，标准方法会系统性地低估它们的贡献。研究证明，现有主要方法在平方误差损失下针对相同的总体泛函，解释了它们为何共享这种由相关性引起的偏差。

**Method:** 为解决现有方法的局限性，本文引入了“解耦特征重要性（DFI）”，这是一种通过最优传输对经典R²分解的非参数泛化。DFI利用传输映射将相关特征转换为独立的潜在变量，从而消除相关性失真。重要性在这个解耦空间中计算，并通过传输映射的敏感性归因回原始空间。

**Result:** DFI提供了一种重要性分数的原则性分解，对于潜在加性模型，这些分数总和等于总预测变异性；对于更一般的交互加权函数ANOVA方差，在任意特征依赖下也成立。本文为DFI开发了全面的半参数理论。对于一般的传输映射，在潜在空间中建立了重要性估计量的根-n一致性和渐近正态性，对于Bures-Wasserstein映射，这一特性扩展到原始特征空间。值得注意的是，估计器实现了二阶估计误差，如果回归函数和传输映射的估计误差均为$o_{\mathbb{P}}(n^{-1/4})$，则该误差会消失。DFI通过设计避免了重复子模型重新拟合的计算负担和条件协变量分布估计的挑战，从而实现了计算效率。

**Conclusion:** DFI通过将相关特征转换为独立潜在变量，有效解决了现有特征重要性量化方法在处理相关预测变量时低估贡献的问题。它提供了一种理论上严谨且计算高效的解决方案，具有强大的统计特性和广泛的适用性。

> **ai_Abstract:** 本文提出“解耦特征重要性（DFI）”方法，旨在解决当预测变量相关时，标准特征重要性量化方法会低估特征贡献的问题。DFI通过最优传输将相关特征映射到独立潜在空间，在此空间计算特征重要性并归因回原始空间，从而消除相关性引起的偏差。该方法为重要性分数提供了一种原则性分解，并建立了全面的半参数理论，证明了估计器的一致性和渐近正态性，同时避免了高昂的计算成本，提升了效率。

> **摘要翻译:** 特征重要性量化面临一个根本挑战：当预测变量相关时，标准方法会系统性地低估它们的贡献。我们证明，现有主要方法在平方误差损失下针对相同的总体泛函，揭示了它们为何共享这种由相关性引起的偏差。
为解决这一局限性，我们引入了“解耦特征重要性（DFI）”，这是一种通过最优传输对经典R²分解的非参数泛化。DFI利用传输映射将相关特征转换为独立的潜在变量，从而消除相关性失真。重要性在这个解耦空间中计算，并通过传输映射的敏感性归因回原始空间。DFI提供了一种重要性分数的原则性分解，对于潜在加性模型，这些分数总和等于总预测变异性；对于更一般的交互加权函数ANOVA方差，在任意特征依赖下也成立。
我们为DFI开发了全面的半参数理论。对于一般的传输映射，在潜在空间中建立了重要性估计量的根-n一致性和渐近正态性，对于Bures-Wasserstein映射，这一特性扩展到原始特征空间。值得注意的是，我们的估计器实现了二阶估计误差，如果回归函数和传输映射的估计误差均为$o_{\mathbb{P}}(n^{-1/4})$，则该误差会消失。DFI通过设计避免了重复子模型重新拟合的计算负担和条件协变量分布估计的挑战，从而实现了计算效率。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [503] [Enhancing Interpretability in Generative Modeling: Statistically Disentangled Latent Spaces Guided by Generative Factors in Scientific Datasets](https://arxiv.org/abs/2507.00298)
> *增强生成模型的可解释性：科学数据集中生成因素引导的统计解缠潜空间*

*Arkaprabha Ganguli, Nesar Ramachandra, Julie Bessac, Emil Constantinescu* | **Category: stat.ML, cs.LG**

**Keywords:** 生成模型, 解缠潜空间, 变分自编码器, 辅助变量, 可解释性

**Comment:** 

> **TL;DR:** Aux-VAE通过引入辅助变量并对标准VAE损失函数进行最小修改，实现了潜在空间的统计解缠，从而增强了生成模型的可解释性。

**AI_Comments:** Aux-VAE的创新之处在于其通过辅助变量对标准VAE的轻微修改，实现了潜在空间的统计解缠，这对于提高生成模型在科学数据分析中的可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决在无监督或半监督设置下，从复杂、高维数据集中统计提取生成因素的挑战。

**Method:** 本文提出了一种名为Aux-VAE的新型架构，该架构基于经典的变分自编码器（VAE）框架。Aux-VAE通过利用先验统计知识和辅助变量，在对标准VAE损失函数进行最小修改的情况下，实现了低维潜在变量的解缠，这些辅助变量通过将潜在因素与学习到的辅助变量对齐来引导潜在空间的形成。

**Result:** Aux-VAE的有效性通过在包括天文模拟在内的多个数据集上的比较评估得到了验证。

**Conclusion:** Aux-VAE提供了一种有效且可解释的方法，用于在生成模型中实现潜在空间的统计解缠，从而有助于从复杂数据集中提取潜在的物理因素。

> **ai_Abstract:** 本文提出Aux-VAE，一种基于变分自编码器的新架构，旨在解决从复杂高维数据中统计提取生成因素的挑战。Aux-VAE通过引入辅助变量和最小化对标准VAE损失的修改，实现了潜在空间的统计解缠，从而提高生成模型的可解释性。该方法在多个数据集上（包括天文模拟）得到了有效性验证。

> **摘要翻译:** 本研究解决了在无监督或半监督设置下，从复杂、高维数据集中统计提取生成因素的挑战。我们研究了基于编码器-解码器的生成模型，用于非线性降维，重点是解缠与独立物理因素对应的低维潜在变量。我们引入了Aux-VAE，这是一种在经典变分自编码器框架内的新型架构，通过利用辅助变量的先验统计知识，在对标准VAE损失函数进行最小修改的情况下实现了解缠。这些变量通过将潜在因素与学习到的辅助变量对齐来引导潜在空间的形成。我们通过在包括天文模拟在内的多个数据集上的比较评估，验证了Aux-VAE的有效性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [505] [GRAND: Graph Release with Assured Node Differential Privacy](https://arxiv.org/abs/2507.00402)
> *GRAND：具有节点差分隐私保证的图发布*

*Suqing Liu, Xuan Bi, Tianxi Li* | **Category: stat.ML, cs.LG, math.ST, stat.ME, stat.TH**

**Keywords:** 差分隐私, 图发布, 节点隐私, 网络数据, 结构特性

**Comment:** 

> **TL;DR:** 提出GRAND，首个在保证节点差分隐私和结构特性的同时发布整个网络的机制，并证明其渐近地保持原始网络分布。

**AI_Comments:** 这篇论文的创新点在于提出了第一个在保证节点差分隐私的同时发布整个网络并保留其结构特性的机制，解决了现有方法在网络数据隐私保护方面的局限性。其在理论上证明了渐近分布一致性，并通过实验验证了有效性，为网络数据的安全共享提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私在网络数据（特别是节点级别）的应用尚未充分探索。现有节点级隐私方法要么仅限于查询，要么无法保留关键网络结构特性。

**Method:** 提出了GRAND（Graph Release with Assured Node Differential privacy），这是一种网络发布机制，能够在确保节点级差分隐私和保留网络结构特性的同时发布整个网络。

**Result:** 在广泛的潜在空间模型下，证明了发布的网络渐近地遵循与原始网络相同的分布。通过在合成和真实数据集上的大量实验评估了方法的有效性。

**Conclusion:** GRAND是首个在保证节点差分隐私和结构特性的同时发布整个网络的机制，并被证明能够渐近地保持原始网络分布，其有效性已通过实验验证。

> **ai_Abstract:** 本文提出了GRAND，一个新颖的网络发布机制，旨在解决网络数据中节点级差分隐私应用不足的问题。与现有方法不同，GRAND在发布整个网络的同时，确保了节点级的差分隐私并保留了网络的结构特性。研究表明，在广泛的潜在空间模型下，发布的网络渐近地与原始网络分布一致。该方法已在合成和真实数据集上通过实验验证了其有效性。

> **摘要翻译:** 差分隐私是一个用于保护数据中敏感信息的成熟框架。尽管其在各个领域得到了广泛应用，但其在网络数据——尤其是在节点级别——的应用仍未得到充分探索。现有的节点级隐私方法要么只关注基于查询的方法，这限制了输出为预先指定的网络统计数据，要么未能保留网络的关键结构属性。在这项工作中，我们提出了GRAND（Graph Release with Assured Node Differential privacy），据我们所知，这是第一个在确保节点级差分隐私和保留结构属性的同时发布整个网络的机制。在一类广泛的潜在空间模型下，我们证明了发布的网络渐近地遵循与原始网络相同的分布。该方法的有效性通过在合成和真实数据集上的大量实验进行了评估。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [515] [An in depth look at the Procrustes-Wasserstein distance: properties and barycenters](https://arxiv.org/abs/2507.00894)
> *深入探讨Procrustes-Wasserstein距离：性质与重心*

*Davide Adamo, Marco Corneli, Manon Vuillien, Emmanuelle Vila* | **Category: stat.ML, cs.LG**

**Keywords:** Procrustes-Wasserstein, 最优传输, 点云, 重心, 形状分析

**Comment:** 16 pages

> **TL;DR:** 本文深入探讨了Procrustes-Wasserstein (PW) 距离的性质和重心，这是一种对刚性变换不变的优化传输距离。研究建立了离散概率测度空间，证明了PW在此空间中是距离，并提出了PW重心的概念及估计算法。实验证明其在点云对齐和形状表示方面优于现有方法，在考古学背景下也展现了实用性，有望提升2D和3D点云分析。

**AI_Comments:** 这篇论文的创新点在于引入了Procrustes-Wasserstein (PW) 重心的概念，并开发了相应的估计算法，从而提供了一种从点云集合中计算代表性形状的新颖方法。其重要性体现在解决了传统最优传输距离在处理刚性变换时的局限性，并通过实验证明了在点云对齐和形状保持方面的优越性能。这对于机器学习和计算几何领域中处理2D和3D点云数据具有显著的应用前景，尤其是在需要形状不变性分析的场景。

<details>
  <summary>Details</summary>

**Motivation:** Procrustes-Wasserstein (PW) 距离被引入作为Wasserstein距离的替代方案，因为它对刚性变换（如旋转和反射）具有不变性，更适合点云的对齐和比较任务。本研究旨在深入探讨其性质并扩展其应用。

**Method:** 本文首先构建了离散概率测度空间，并证明了Procrustes-Wasserstein (PW) 在该空间中确实是一种距离。接着，通过讨论和测试多种初始化策略来扩展了PW框架。然后，引入了PW重心的概念，并详细介绍了一种从数据中估计它的算法。最后，将所提出的方法与现有最优传输（OT）方法进行基准测试。

**Result:** 研究成果是一种计算点云集合中代表性形状的新方法。与现有最优传输方法相比，该方法在需要精确对齐和形状保持的场景中表现出卓越的性能。此外，PW重心在考古学背景下也显示出实用性。

**Conclusion:** Procrustes-Wasserstein (PW) 距离及其重心在机器学习和计算几何应用中，在提升2D和3D点云分析方面具有巨大潜力。

> **ai_Abstract:** 本文深入探讨了Procrustes-Wasserstein (PW) 距离的性质和重心。研究首先构建了离散概率测度空间并证明PW是该空间上的距离。为解决PW问题，论文扩展了其框架，讨论并测试了多种初始化策略。更重要的是，引入了PW重心的概念，并提出了一种估计算法，从而提供了一种计算点云集合代表性形状的新方法。通过与现有最优传输方法比较，该方法在点云对齐和形状保持方面表现出卓越性能，并在考古学中得到应用，展示了PW在2D/3D点云分析中的巨大潜力。

> **摘要翻译:** 由于Procrustes-Wasserstein (PW) 对刚性变换（如旋转和反射）具有不变性，它被引入文献中作为一种最优传输（OT）距离，是Wasserstein距离的替代方案，更适合点云的对齐和比较等任务。考虑到这一应用，我们仔细构建了一个离散概率测度空间，并证明在该空间上PW确实是一种距离。解决PW问题的算法已经存在，但我们通过讨论和测试几种初始化策略来扩展了PW框架。然后，我们引入了PW重心的概念，并详细介绍了一种从数据中估计它的算法。结果是，这是一种从点云集合中计算代表性形状的新方法。我们将我们的方法与现有OT方法进行基准测试，证明了在需要精确对齐和形状保持的场景中具有卓越的性能。我们最后展示了PW重心在考古学背景下的实用性。我们的结果突出了PW在促进机器学习和计算几何应用中2D和3D点云分析方面的潜力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [350] [A convex lifting approach for the Calderón problem](https://arxiv.org/abs/2507.00645)
> *Calderón问题的凸提升方法*

*Giovanni S. Alberti, Romain Petit, Simone Sanna* | **Category: math.AP, cs.NA, math.FA, math.NA, math.OC**

**Keywords:** Calderón问题, 凸提升, 凸松弛, 逆问题, 偏微分方程

**Comment:** 

> **TL;DR:** 本文提出了一种基于提升和凸松弛技术的新方法来解决Calderón问题，将其转化为一个凸优化问题，并在一个简化模型上验证了其有效性。

**AI_Comments:** 该论文提出了一种将非线性逆问题转化为凸优化问题的新颖方法，这是解决此类问题的一个重要方向，有望克服传统方法的局部收敛性问题。其创新点在于将有限维二次逆问题的成功经验推广到Calderón问题。然而，目前仅在简化模型上进行了验证，关键的“非退化源条件”在完整Calderón设置中的普适性仍是未来的挑战和潜在局限。

<details>
  <summary>Details</summary>

**Motivation:** Calderón问题中的重建方法通常面临局部收敛问题，因为其前向算子是高度非线性的，这使得重建方法开发具有挑战性。

**Method:** 作者提出了一种基于提升（lifting）和凸松弛（convex relaxation）技术的方法，将Calderón问题转化为一个凸优化问题。该方法已成功应用于解决有限维二次逆问题。

**Result:** 在满足非退化源条件的情况下，所提出的凸优化问题的解与所需系数一致。在玩具模型上验证了该方法的有效性，并在此简化设置下，在未知系数的特定假设下验证了非退化源条件成立。

**Conclusion:** 本文提出了一种解决Calderón问题的新型凸提升方法，并在简化模型上验证了其可行性。然而，该方法在完整Calderón设置中非退化源条件的有效性尚待未来研究。

> **ai_Abstract:** 本文针对Calderón问题中重建方法常见的局部收敛问题，提出了一种创新的凸提升与凸松弛方法。该方法将原有的非线性逆问题转化为一个凸优化问题，并在满足特定非退化源条件时，保证其解即为所需系数。文章在一个简化模型上验证了该方法的有效性，并指出在完整Calderón设置下非退化源条件的验证将是未来的研究方向。

> **摘要翻译:** Calderón问题在于从解的边界测量中恢复偏微分方程的未知系数。这些测量会产生一个高度非线性的前向算子。因此，开发用于解决这个逆问题的重建方法具有挑战性，因为它们通常受到局部收敛问题的困扰。为了规避这个问题，我们提出了一种基于提升和凸松弛技术的替代方法，这些技术已成功应用于解决有限维二次逆问题。这导致了一个凸优化问题，只要非退化源条件成立，其解就与所寻求的系数一致。我们在一个玩具模型上证明了我们方法的有效性，在该模型中，偏微分方程的解在域的任何地方都是已知的。在这种简化的设置中，我们验证了在未知系数的某些假设下，非退化源条件成立。我们将在未来的工作中研究其在Calderón设置中的有效性。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

### [373] [Stable skeleton integral equations for general coefficient Helmholtz transmission problems](https://arxiv.org/abs/2507.00991)
> *广义系数亥姆霍兹传输问题的稳定骨架积分方程*

*Benedikt Gräßle, Ralf Hiptmair, Stefan Sauter* | **Category: math.AP, cs.NA, math.NA, 31B10, 35C15, 45A05, 65R20**

**Keywords:** 亥姆霍兹问题, 积分方程, 变分公式, 传输问题, 适定性

**Comment:** 

> **TL;DR:** 本文提出了一种新的变分积分方程方法，用于解决变系数亥姆霍兹传输问题，并证明了其适定性。

**AI_Comments:** 这项工作通过引入一种创新的变分公式，为解决变系数亥姆霍兹传输问题提供了重要进展，尤其是在传统格林函数方法受限的情况下。其创新之处在于将变分方法应用于积分方程的构建，并直接从传输问题的稳定性推导出适定性，这对于数值模拟和理论分析都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的格林函数方法无法直接应用于变系数亥姆霍兹问题。

**Method:** 本文提出了一种新颖的层势和边界积分算子的变分公式，推广了经典的格林函数构造。该方法通过变分定义直接获得波数显式估计和跳跃条件，并为分段Lipschitz系数的声学传输问题建立了非局部（“积分”）公式。该研究通过对外部亥姆霍兹问题施加人工边界并利用Dirichlet-to-Neumann映射的最新见解，对一般维度和复波数进行了同步分析，并直接从底层传输问题的稳定性获得了积分方程的适定性。

**Result:** 直接从底层传输问题的稳定性获得了积分方程的适定性。

**Conclusion:** 本研究成功地为变系数亥姆霍兹传输问题提供了一种新的、适定的稳定骨架积分方程方法。

> **ai_Abstract:** 本文提出了一种新颖的层势和边界积分算子的变分公式，以解决变系数亥姆霍兹问题中传统格林函数不可用的挑战。该方法导出了波数显式估计和跳跃条件，并为具有分段Lipschitz系数的声学传输问题提供了非局部积分公式。通过利用底层传输问题的稳定性，作者证明了所得积分方程的适定性。该分析涵盖了通用维度和复波数，并结合了人工边界和Dirichlet-to-Neumann映射的最新理论。

> **摘要翻译:** 层势和边界积分算子的一种新颖变分公式推广了它们经典的格林函数构造，而格林函数对于变系数亥姆霍兹问题并未明确可用。波数显式估计和跳跃条件等性质直接源于它们的变分定义，并使得具有分段Lipschitz系数的声学传输问题（TP）能够进行非局部（“积分”）公式化。我们直接从底层传输问题的稳定性获得了积分方程的适定性。本论文中对一般维度和复波数的同步分析对外部亥姆霍兹问题施加了人工边界，并采用了对相关Dirichlet-to-Neumann映射的最新见解。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [359] [A simplified unified wave-particle method for diatomic gases with rotational and vibrational non-equilibrium](https://arxiv.org/abs/2507.00720)
> *一种用于双原子气体旋转和振动非平衡的简化统一波粒方法*

*Sirui Yang, Chengwen Zhong, Ningchao Ding, Junzhe Cao, He Zhang, Congshan Zhuo, Sha Liu* | **Category: physics.flu-dyn, cs.NA, math.NA**

**Keywords:** 统一波粒方法, 双原子气体, 非平衡流, 量化模型竞争, 高超声速流

**Comment:** 

> **TL;DR:** 本文提出了一种简化的统一波粒（SUWP）方法，用于处理具有旋转和振动非平衡的双原子气体在多尺度高超声速流中的问题，该方法在保持准确性的同时提高了计算效率。

**AI_Comments:** 该论文的创新点在于提出了量化模型竞争（QMC）机制和简化的统一波粒（SUWP）方法，有效地解决了高超声速流中双原子气体旋转和振动非平衡的多尺度问题。该方法结合了宏观和微观求解器，在保证精度的前提下显著提升了计算效率，对于稀薄气体动力学和高超声速空气动力学模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高超声速飞行器周围的流场存在多尺度和稀薄气体效应，且高温会引起多原子分子的振动激发，需要能够准确处理多尺度流和考虑旋转与振动内能模式非平衡的数值方法。

**Method:** 本研究从包含旋转和振动能量的动力学模型方程的积分解出发，推导了双原子气体旋转和振动非平衡的量化模型竞争（QMC）机制。基于QMC机制，开发了一种简化的统一波粒（SUWP）方法。该方法的宏观部分将考虑旋转和振动能量的三温度模型整合到动力学无粘通量格式和Navier-Stokes求解器中。微观部分采用无碰撞DSMC求解器来解决非平衡流物理问题。

**Result:** 所提出的SUWP方法在冲击管、冲击结构、绕圆柱流、阿波罗6号指令舱和和平号空间站等基准案例中得到了旋转和振动非平衡的验证。与DSMC和确定性方法相比，SUWP方法在保持准确性的同时表现出良好的计算效率。

**Conclusion:** SUWP方法能够有效地处理具有旋转和振动非平衡的双原子气体在多尺度高超声速流中的问题，并在计算效率和准确性之间取得了良好的平衡。

> **ai_Abstract:** 本研究针对高超声速流中双原子气体存在的旋转和振动非平衡多尺度流动问题，提出了一种简化的统一波粒（SUWP）方法。该方法基于量化模型竞争（QMC）机制，结合了宏观的三温度模型（用于动力学无粘通量和Navier-Stokes求解器）和微观的无碰撞DSMC求解器。通过多个基准案例的验证表明，SUWP方法在处理非平衡流时，相比传统方法，在保持准确性的同时显著提高了计算效率。

> **摘要翻译:** 高超声速飞行器周围的高超声速流构成了一个多尺度流动问题。由于分子碰撞不足以达到平衡，流场中存在稀薄气体效应。因此，需要能够准确解析多尺度流动的数值方法。此外，高超声速流中的高温气体效应意味着多原子分子的振动激发。因此，需要考虑旋转和振动内能模式非平衡的数值方法。本研究从包含旋转和振动能量的动力学模型方程的积分解出发，推导了双原子气体旋转和振动非平衡的量化模型竞争（QMC）机制。QMC机制将单元格中的碰撞和自由输运粒子分类，并根据其局部尺度区域应用计算权重。我们基于QMC机制开发了一种用于双原子气体的简化统一波粒（SUWP）方法。对于该方法的宏观部分，将考虑旋转和振动能量的三温度模型整合到动力学无粘通量格式和Navier-Stokes求解器中。对于该方法的微观部分，采用无碰撞DSMC求解器来解决非平衡流物理问题。这项工作通过包括冲击管、冲击结构、绕圆柱流、阿波罗6号指令舱和和平号空间站等基准案例，验证了所提出的具有旋转和振动非平衡的SUWP方法。与DSMC和确定性方法相比，SUWP方法在保持准确性的同时表现出良好的计算效率。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [512] [Guided Unconditional and Conditional Generative Models for Super-Resolution and Inference of Quasi-Geostrophic Turbulence](https://arxiv.org/abs/2507.00719)
> *准地转湍流超分辨率和推断的引导式无条件和条件生成模型*

*Anantha Narayanan Suresh Babu, Akhil Sadam, Pierre F. J. Lermusiaux* | **Category: physics.flu-dyn, cs.LG, physics.ao-ph, physics.geo-ph**

**Keywords:** 生成模型, 扩散模型, 超分辨率, 准地转湍流, 地球物理逆问题

**Comment:** 56 pages, 23 figures, 7 tables

> **TL;DR:** 本文应用四种扩散模型（SDEdit、DPS、普通条件变体、无分类器引导）对粗糙、稀疏、不完整的准地转湍流数据进行超分辨率和推断，并评估了它们在性能和成本方面的权衡。

**AI_Comments:** 这篇论文为具有挑战性的地球物理逆问题提供了不同扩散模型方法的宝贵比较。对各种条件下的详细评估以及对权衡（实施便利性、保真度、循环一致性）的分析特别有见地。它将引导式和条件式扩散模型应用于湍流超分辨率是一个创新点，鉴于当前地球物理模拟和观测的局限性，这是一个关键领域。为部署提供的实用指导是一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 海洋、天气和气候的数值模拟通常是粗糙的，观测数据是稀疏且不完整的，因此需要从有限的数据中进行超分辨率和推断。

**Method:** 本文应用了四种生成扩散建模方法：SDEdit和扩散后验采样（DPS）作为两种引导方法，以及普通条件变体和无分类器引导作为两种条件方法。研究在beta平面上的受迫二维准地转湍流上进行，并考虑了八个测试用例，涵盖两种湍流状态、两种雷诺数和两种观测类型。性能评估包括重建涡度场范数、湍流统计量以及超分辨率概率集合及其误差的量化，并研究了调整参数的敏感性。

**Result:** SDEdit生成了非物理场；DPS以较低计算成本生成合理重建但细尺度特征被平滑。两种条件方法（普通变体和无分类器引导）虽然需要重新训练，但能重建缺失的细尺度特征，与观测数据保持循环一致性，并具有正确的统计量。它们的平均模型误差与集合标准差高度相关。结果揭示了扩散模型在实施便利性、保真度（清晰度）和循环一致性之间的权衡。

**Conclusion:** 本文通过比较不同生成扩散方法在湍流超分辨率和推断中的性能，强调了扩散模型在实施便利性、保真度与循环一致性之间的权衡，为地球物理逆问题中的模型部署提供了实用指导。

> **ai_Abstract:** 本文研究了SDEdit、扩散后验采样（DPS）、普通条件变体和无分类器引导这四种生成扩散模型，用于从粗糙、稀疏和不完整的地球物理观测数据中对准地转湍流进行超分辨率和推断。该研究通过综合技能指标评估了这些模型在不同湍流状态、雷诺数和观测类型下的表现。SDEdit产生了非物理结果，DPS以较低计算成本提供了平滑的特征重建；而条件方法虽然需要重新训练，但能有效重建细尺度细节，与观测数据保持循环一致性，并保留正确的统计量。研究结果突出了模型复杂性、重建保真度和一致性之间的关键权衡，为扩散模型在地球物理逆问题中的应用提供了实用见解。

> **摘要翻译:** 通常，海洋、天气和气候的数值模拟是粗糙的，观测数据是稀疏且不完整的。在这项工作中，我们应用四种生成扩散建模方法，从粗糙、稀疏和不完整的观测数据中，对beta平面上的受迫二维准地转湍流进行超分辨率和推断。两种引导方法对预训练的无条件模型进行最小程度的调整：SDEdit修改初始条件，而扩散后验采样（DPS）修改逆向扩散过程分数。另外两种条件方法，一种是普通变体，另一种是无分类器引导，需要使用配对的高分辨率和观测数据进行训练。我们考虑了八个测试用例，涵盖：两种状态，涡流和各向异性射流湍流；两种雷诺数，10^3和10^4；以及两种观测类型，4倍粗分辨率场和粗糙、稀疏、不完整的观测数据。我们的综合技能指标包括重建涡度场的范数、湍流统计量以及超分辨率概率集合及其误差的量化。我们还研究了对指导强度等调整参数的敏感性。结果表明，SDEdit生成了非物理场，而DPS以较低的计算成本生成了合理的重建，但细尺度特征被平滑。两种条件方法都需要重新训练，但它们能够重建缺失的细尺度特征，与观测数据保持循环一致性，并具有正确的统计量，如能量谱。此外，它们的平均模型误差与它们的集合标准差高度相关且可预测。结果强调了扩散模型在实施便利性、保真度（清晰度）和循环一致性之间的权衡，并为在地球物理逆问题中的部署提供了实用指导。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='csms'></a>
## cs.MS 

### [369] [Anatomy of High-Performance Column-Pivoted QR Decomposition](https://arxiv.org/abs/2507.00976)
> *高性能列主元QR分解的剖析*

*Maksim Melnichenko, Riley Murray, William Killian, James Demmel, Michael W. Mahoney, Piotr Luszczek, Mark Gates* | **Category: cs.MS, cs.NA, math.NA**

**Keywords:** QR分解, 列主元, 高性能计算, 算法框架, RandLAPACK

**Comment:** v1: 33 pages in the body, 7 pages in the appendices, 17 figures

> **TL;DR:** 本文提出了一个用于通用矩阵列主元QR分解（QRCP）的算法框架，通过用户选择核心子程序，实现了在CPU和GPU上显著的性能提升，最高可达两个数量级，并超越了现有最先进的方法。

**AI_Comments:** 本文的创新之处在于提出了一个灵活的算法框架，允许用户根据硬件特性优化QRCP的核心子程序，从而实现了前所未有的性能提升。其在CPU上高达两个数量级的性能提升以及在GPU上的良好表现，对于高性能计算领域的QR分解应用具有重要意义。将算法开源于RandLAPACK库中也促进了研究成果的推广和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的列主元QR分解（QRCP）算法在性能上存在局限性，尤其是在现代硬件平台上需要更高效、更实用的解决方案。

**Method:** 本文引入了一个用于在通用矩阵上执行列主元QR分解（QRCP）的算法框架。该框架通过允许用户选择核心子程序来设计实用的QRCP算法，并提供了在现代CPU和GPU硬件平台上进行这些选择的详细指导。开发的实用QRCP算法作为开源RandLAPACK库的一部分实现。

**Result:** 在双AMD EPYC 9734系统上，所提出的方法比LAPACK的标准QRCP例程性能提高了高达两个数量级，并且大大超越了当前最先进的随机QRCP算法的性能。在NVIDIA H100 GPU上，该方法达到了cuSOLVER无主元QR分解性能的大约65%。

**Conclusion:** 本文提出的算法框架能够设计出在CPU和GPU上都表现出卓越性能的实用列主元QR分解（QRCP）算法，显著优于现有标准和最先进方法，为高性能计算提供了新的解决方案。

> **ai_Abstract:** 本文提出了一个用于通用矩阵列主元QR分解（QRCP）的算法框架。该框架允许用户定制核心子程序，以适应现代CPU和GPU硬件。通过此框架开发的算法已集成到RandLAPACK库中。实验结果表明，在CPU上，该方法比LAPACK标准QRCP例程和当前最先进的随机QRCP算法有显著的性能提升，最高可达两个数量级；在GPU上，其性能接近cuSOLVER无主元QR分解的65%。

> **摘要翻译:** 我们引入了一个用于在通用矩阵上执行列主元QR分解（QRCP）的算法框架。该框架通过用户控制核心子程序的选择，使得设计实用的QRCP算法成为可能。我们提供了关于如何在现代硬件平台（包括CPU和GPU）上进行这些选择的全面概述，详细描述了替代方法。在这个框架内开发的实用QRCP算法作为开源RandLAPACK库的一部分实现。我们的实证评估表明，在双AMD EPYC 9734系统上，所提出的方法比LAPACK的标准QRCP例程性能提高了多达两个数量级，并且大大超越了当前最先进的随机QRCP算法的性能。此外，在NVIDIA H100 GPU上，我们的方法达到了cuSOLVER无主元QR分解性能的大约65%。

</details>

[⬆️ 返回分类顶部](#csms) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [436] [Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended)](https://arxiv.org/abs/2507.00094)
> *丰富数据感知Declare规范的有效一致性检查（扩展）*

*Jacobo Casas-Ramos, Sarah Winkler, Alessandro Gianola, Marco Montali, Manuel Mucientes, Manuel Lama* | **Category: cs.DB, cs.AI, cs.PL**

**Keywords:** 一致性检查, 数据感知, Declare, A*搜索, SMT求解

**Comment:** Extended version of the paper of the same title accepted at the 23rd
  International Conference on Business Process Management (BPM 2025)

> **TL;DR:** 本文提出了一种结合A*搜索和SMT求解的算法，用于高效地对具有丰富数据类型和条件的数据感知Declare规范进行一致性检查，并在实验中证明了其效率和表达能力。

**AI_Comments:** 本文通过解决流程挖掘领域的一个长期挑战——对丰富数据感知声明式模型进行高效一致性检查——做出了重要贡献。A*搜索和SMT求解的结合是解决问题计算复杂性的巧妙而有效的方式，实现了效率和表达性。其处理通用数据类型和条件的能力是一项关键创新，超越了以往的限制，为在复杂现实世界场景中更实际的应用打开了大门。实验验证进一步强化了其主张。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对数据感知规范的流程分析和挖掘兴趣日益增长，但现有基于对齐的声明式流程模型一致性检查主要集中于纯控制流或有限的数据感知扩展（仅限于数值数据和变量-常量比较）。在存在数据依赖的情况下，寻找对齐计算上非常困难。本文旨在解决使用具有通用数据类型和数据条件的数据感知Declare作为参考模型时的一致性检查问题。

**Method:** 该方法结合了A*搜索和SMT求解，以处理控制流和数据依赖。它引入了一种新颖的算法技术，通过应用旨在逐步解决约束违反的修复操作来有效探索搜索空间，生成后代状态。

**Result:** 研究表明，在这种丰富设置下，可以高效且富有表达性地计算数据感知的最优对齐。该算法已被证明是正确的，并通过实验展示了其效率。评估结果表明，该方法在支持明显更具表达性的数据依赖的同时，匹配或超越了现有技术的性能。

**Conclusion:** 所提出的方法实现了对丰富Declare规范的高效且富有表达力的数据感知一致性检查，展示了其支持实际应用的潜力。

> **ai_Abstract:** 本文解决了声明式流程模型中高效基于对齐的一致性检查的挑战，特别是针对具有通用数据类型和条件的数据感知Declare规范。它提出了一种新颖的算法技术，结合A*搜索和SMT求解来计算最优的数据感知对齐。该方法通过使用修复操作来解决约束违反，从而高效地探索搜索空间。作者证明了其正确性，并展示了其效率和表达能力，表明它在支持更丰富的数据依赖方面优于或匹配现有技术，从而支持实际应用。

> **摘要翻译:** 尽管对数据感知规范的流程分析和挖掘的兴趣日益增长，但基于对齐的声明式流程模型的一致性检查一直专注于纯控制流规范，或仅限于数值数据和变量到常量比较的轻微数据感知扩展。这并不奇怪：寻找对齐在计算上是困难的，在存在数据依赖的情况下更是如此。在本文中，我们挑战了当参考模型使用具有通用数据类型和数据条件的数据感知Declare捕获时的问题。我们发现，出乎意料的是，在这种丰富设置下，可以计算出数据感知的最优对齐，同时兼顾效率和表达性。这是通过仔细结合处理对齐计算中控制流和数据依赖的两种最著名方法来实现的，即A*搜索和SMT求解。具体来说，我们引入了一种新颖的算法技术，通过应用旨在逐步解决约束违反的修复操作来有效探索搜索空间，生成后代状态。我们证明了我们算法的正确性，并通过实验展示了其效率。评估表明，我们的方法在支持明显更具表达性的数据依赖的同时，匹配或超越了现有技术的性能，展示了其支持实际应用潜力。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [456] [Discovering the underlying analytic structure within Standard Model constants using artificial intelligence](https://arxiv.org/abs/2507.00225)
> *使用人工智能发现标准模型常数中潜在的解析结构*

*S. V. Chekanov, H. Kjellerstrand* | **Category: hep-ph, cs.AI, physics.data-an**

**Keywords:** 标准模型, 解析结构, 符号回归, 遗传编程, 物理常数

**Comment:** 42 pages, 10 tables

> **TL;DR:** 本文利用符号回归和遗传编程，探索标准模型基本参数之间的解析结构，并发现了数千个高精度表达式，这些发现可能有助于揭示SM常数间的隐藏模式或更深层的物理定律。

**AI_Comments:** 这篇论文的创新点在于将人工智能（特别是符号回归和遗传编程）应用于理论物理中的基本常数分析，旨在发现它们之间潜在的数学关系。这可能为理解标准模型参数的起源和相互关联性提供全新的视角，并可能推动新物理模型的构建。其重要性在于为理论物理学家提供了一种强大的计算工具，以探索传统方法难以发现的复杂模式。

<details>
  <summary>Details</summary>

**Motivation:** 寻找标准模型（SM）基本参数之间潜在的解析结构，以揭示SM常数间的隐藏模式，或作为构建连接所有SM参数的更深层物理定律的基石。

**Method:** 使用符号回归和遗传编程来识别连接标准模型常数对的最简单解析关系。

**Result:** 识别了连接标准模型常数对的最简单解析关系，并报告了基于约一千个相对精度优于1%的表达式的几个显著观察结果。

**Conclusion:** 这些结果可作为模型构建者和人工智能方法的宝贵输入，旨在揭示SM常数中的隐藏模式，或潜在地用作通过少量基本常数连接所有SM参数的更深层底层定律的构建模块。

> **ai_Abstract:** 本文利用符号回归和遗传编程，探索标准模型（SM）基本参数中潜在的解析结构。研究识别了连接这些常数对的最简单解析关系，并获得了约一千个精度优于1%的表达式。这些发现有望为构建新的物理模型、揭示SM常数间的隐藏模式，乃至探索更深层次的统一物理定律提供重要线索。

> **摘要翻译:** 本文介绍了使用符号回归和遗传编程在标准模型（SM）基本参数中寻找潜在解析结构的研究。我们识别了连接这些常数对的最简单解析关系，并报告了基于大约一千个相对精度优于1%的表达式的几个显著观察结果。这些结果可能为模型构建者和旨在揭示SM常数中隐藏模式的人工智能方法提供有价值的输入，或者潜在地用作通过少量基本常数连接所有SM参数的更深层底层定律的构建模块。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [471] [Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations](https://arxiv.org/abs/2507.00269)
> *特征整合空间：联合训练揭示神经网络表征中的双重编码*

*Omar Claflin* | **Category: q-bio.NC, cs.AI**

**Keywords:** 神经网络可解释性, 稀疏自编码器, 双重编码, 特征整合, 联合训练

**Comment:** 

> **TL;DR:** 现有稀疏自编码器（SAE）在神经网络可解释性方面存在局限。本文提出神经网络通过特征身份和特征整合进行双重编码，并开发联合训练架构。该架构显著改善了重建效果并揭示了有意义的非线性特征交互，为下一代SAE奠定基础。

**AI_Comments:** 这项工作通过引入“特征整合空间”和“双重编码”的概念，并提出联合训练架构，为神经网络可解释性领域带来了重要的创新。它挑战了传统SAE的线性叠加假设，强调了非线性特征交互的重要性，并为开发更有效、更符合生物学启发的下一代SAE奠定了基础。其方法不仅在性能上有所提升，更重要的是揭示了神经网络内部表征的深层机制，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的稀疏自编码器（SAE）方法假设激活可以通过线性叠加分解为稀疏、可解释的特征，但它们未能消除多义性并表现出病理性行为错误。

**Method:** 提出神经网络在特征身份和特征整合两个互补空间中编码信息。为验证双重编码假设，开发了顺序和联合训练架构来同时捕获身份和整合模式。还使用了2x2因子刺激设计进行干预实验。

**Result:** 联合训练实现了41.3%的重建改进和51.6%的KL散度误差减少。该架构自发地形成了双峰特征组织。小非线性组件（3%的参数）实现了16.5%的独立改进。干预实验表明整合特征对实验操作表现出选择性敏感性，并对模型输出产生系统的行为效应，包括跨语义维度显著的交互效应。

**Conclusion:** 本文为以下几点提供了系统性证据：(1) 神经网络表征中的双重编码；(2) 有意义的非线性编码特征交互；(3) 引入了一种从事后特征分析到集成计算设计的架构范式转变，为下一代SAE奠定了基础。

> **ai_Abstract:** 本文针对现有稀疏自编码器（SAE）在解释神经网络表征时存在的局限性，提出了神经网络通过“特征身份”和“特征整合”两个互补空间进行双重编码的假设。为验证此假设，作者开发了联合训练架构，该架构在重建效果上显著优于传统SAE，并能有效减少误差。研究发现，这种新架构能自发形成双峰特征组织，且其小非线性组件能够高效捕获关键的计算关系。通过干预实验，进一步证实了整合特征对模型行为输出的重要影响，包括显著的非线性交互效应。这项工作为理解神经网络的双重编码机制、非线性特征交互提供了证据，并为未来SAE的设计提出了新的范式。

> **摘要翻译:** 当前用于神经网络可解释性的稀疏自编码器（SAE）方法假设激活可以通过线性叠加分解为稀疏、可解释的特征。尽管重建保真度高，但SAE始终未能消除多义性并表现出病理性行为错误。我们提出神经网络在压缩到同一基质中的两个互补空间中编码信息：特征身份和特征整合。为了测试这种双重编码假设，我们开发了顺序和联合训练架构，以同时捕获身份和整合模式。联合训练实现了41.3%的重建改进和51.6%的KL散度误差减少。这种架构自发地形成了双峰特征组织：低平方范数特征有助于整合路径，其余特征直接有助于残差。小非线性组件（3%的参数）实现了16.5%的独立改进，证明了参数高效地捕获对行为至关重要的计算关系。此外，使用2x2因子刺激设计的干预实验表明，整合特征对实验操作表现出选择性敏感性，并对模型输出产生系统的行为效应，包括跨语义维度的显著交互效应。这项工作为以下几点提供了系统性证据：（1）神经网络表征中的双重编码，（2）有意义的非线性编码特征交互，以及（3）引入了一种从事后特征分析到集成计算设计的架构范式转变，为下一代SAE奠定了基础。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [499] [Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding](https://arxiv.org/abs/2507.00419)
> *地质万物模型3D：一个用于统一和零样本地下理解的可提示基础模型*

*Yimin Dou, Xinming Wu, Nathan L Bangs, Harpreet Singh Sethi, Jintao Li, Hang Gao, Zhixiang Guo* | **Category: physics.geo-ph, cs.AI**

**Keywords:** 地质万物模型3D, 基础模型, 零样本学习, 地下理解, 地球物理AI

**Comment:** 

> **TL;DR:** GEM是一个统一的生成式模型，通过将地下分析任务重构为基于提示的推理，实现了跨任务的零样本泛化，无需为新任务或数据源重新训练。

**AI_Comments:** GEM的创新之处在于提出了一个统一的生成式架构来解决地下分析中长期存在的碎片化问题，通过将所有任务重构为提示条件推理，实现了零样本泛化，这大大提高了模型的灵活性和适用性。其两阶段训练方法结合了自监督学习和对抗性微调，有助于模型学习鲁棒的表示并适应多样化的任务。GEM有望推动地球物理AI从传统的任务特定模型向更通用、更智能的系统发展，尤其是在数据稀缺或新任务出现的场景下具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前地下分析模型是碎片化的，需要针对结构解释、地层分析、地质体分割和属性建模等不同任务分别建立模型，且这些模型与特定数据分布和任务表述紧密耦合。

**Method:** 本文引入了地质万物模型3D（GEM），一个统一的生成式架构，将所有地下分析任务重构为沿地下成像导出的潜在结构框架进行的提示条件推理。GEM通过两阶段训练过程实现：结合大规模现场地震数据的自监督表示学习和使用混合提示与标签进行对抗性微调。

**Result:** GEM实现了跨异构提示类型的任务零样本泛化，无需为新任务或数据源重新训练。它在火星雷达地层分析、俯冲带结构解释、全地震地层解释、地质体描绘和属性建模等多种调查和任务中展示了广泛的适用性。

**Conclusion:** GEM通过结构感知的方式将专家知识与生成推理相结合，为可扩展的、人机协作的地球物理AI奠定了基础，实现了从碎片化管道到垂直集成、可提示推理系统的转变。

> **ai_Abstract:** 本文提出了地质万物模型3D（GEM），一个统一的生成式架构，旨在解决当前地下分析模型碎片化的问题。GEM将结构解释、地层分析、地质体分割和属性建模等任务重构为基于提示的推理，通过两阶段训练（自监督表示学习和对抗性微调）实现了对异构提示类型的零样本泛化。该模型能够利用人类提供的提示生成地质上连贯的输出，并在多项地球物理任务中展现了广泛的适用性，为构建可扩展的人机协作地球物理AI奠定了基础。

> **摘要翻译:** 理解地球地下对于能源转型、自然灾害缓解和行星科学至关重要。然而，地下分析仍然是碎片化的，结构解释、地层分析、地质体分割和属性建模需要单独的模型——每个模型都与特定的数据分布和任务表述紧密耦合。我们引入了地质万物模型3D（GEM），一个统一的生成式架构，它将所有这些任务重构为沿地下成像导出的潜在结构框架进行的提示条件推理。这种表述通过实现共享的推理机制，超越了特定任务的模型，GEM将人类提供的提示（例如测井曲线、掩膜或结构草图）沿着推断的结构框架传播，以生成地质上连贯的输出。通过这种机制，GEM在异构提示类型的任务中实现了零样本泛化，无需为新任务或数据源重新训练。这种能力来自于一个两阶段的训练过程，该过程将大规模现场地震数据的自监督表示学习与使用混合提示和标签在各种地下任务中的对抗性微调相结合。GEM在各种调查和任务中展示了广泛的适用性，包括火星雷达地层分析、俯冲带结构解释、全地震地层解释、地质体描绘和属性建模。通过以结构感知的方式将专家知识与生成推理相结合，GEM为可扩展的、人机协作的地球物理AI奠定了基础——从碎片化管道过渡到垂直集成、可提示的推理系统。项目页面：https://douyimin.github.io/GEM

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [500] [Process-aware and high-fidelity microstructure generation using stable diffusion](https://arxiv.org/abs/2507.00459)
> *基于稳定扩散的工艺感知高保真微观结构生成*

*Hoang Cuong Phan, Minh Tien Tran, Chihun Lee, Hoheok Kim, Sehyok Oh, Dong-Kyu Kim, Ho Won Lee* | **Category: cond-mat.mtrl-sci, cs.AI**

**Keywords:** 微观结构生成, 稳定扩散, 工艺感知, 材料设计, 生成模型

**Comment:** 46 pages, 13 figures, 5 tables, 3rd Word Congress on Artificial
  Intelligence in Materials & Manufacturing 2025

> **TL;DR:** 该研究提出了一种基于Stable Diffusion 3.5 Large的新型工艺感知生成模型，通过数值感知嵌入和高效微调，解决了微观结构图像生成中数据稀缺和连续变量编码的挑战，实现了高保真度、受控的微观结构图像合成，并经验证表现优于现有方法。

**AI_Comments:** 该论文的创新之处在于首次将先进的文本到图像扩散模型Stable Diffusion 3.5 Large应用于工艺感知的微观结构生成。通过引入数值感知嵌入，有效解决了连续加工变量的编码问题，这对于材料科学领域的数据驱动设计具有重要意义。同时，采用DreamBooth和LoRA进行高效微调，克服了材料领域数据稀缺的挑战，使得该方法具有良好的可扩展性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在材料设计中，合成受加工参数约束的真实微观结构图像对于理解工艺-结构关系至关重要。然而，由于训练显微照片有限以及加工变量的连续性，这项任务仍然具有挑战性。

**Method:** 本文提出了一种基于Stable Diffusion 3.5 Large（SD3.5-Large）的新型工艺感知生成建模方法。该方法引入了数值感知嵌入，将连续变量（退火温度、时间和放大倍数）直接编码到模型的条件中。为了解决数据稀缺和计算限制，通过DreamBooth和低秩适应（LoRA）仅对模型的一小部分权重进行微调。

**Result:** 通过基于微调U-Net和VGG16编码器的语义分割模型验证了真实性，在24张标记显微照片上实现了97.1%的准确率和85.7%的平均IoU，优于现有方法。使用物理描述符和空间统计的定量分析表明，合成微观结构与真实微观结构之间具有很强的一致性，其中两点相关误差和线性路径误差分别低于2.1%和0.6%。

**Conclusion:** 该方法首次将SD3.5-Large应用于工艺感知微观结构生成，为数据驱动的材料设计提供了一种可扩展的方法。

> **ai_Abstract:** 本研究提出了一种新颖的工艺感知生成建模方法，该方法基于Stable Diffusion 3.5 Large，旨在解决材料设计中微观结构图像合成面临的数据稀缺和连续加工变量编码的挑战。通过引入数值感知嵌入，模型能够直接编码并处理连续的加工参数（如温度、时间和放大倍数），从而实现受控的图像生成和捕获工艺驱动的微观结构变化。为应对数据限制，研究团队采用DreamBooth和LoRA技术高效微调模型。实验结果表明，该方法生成的微观结构图像具有高保真度，并通过语义分割模型验证，其准确率和平均IoU均优于现有方法，且物理描述符和空间统计分析显示合成图像与真实图像高度一致。该工作是首次将SD3.5-Large应用于工艺感知微观结构生成，为数据驱动的材料设计提供了可扩展的解决方案。

> **摘要翻译:** 合成受加工参数约束的真实微观结构图像对于理解材料设计中的工艺-结构关系至关重要。然而，由于训练显微照片有限以及加工变量的连续性，这项任务仍然具有挑战性。为了克服这些挑战，我们提出了一种基于Stable Diffusion 3.5 Large（SD3.5-Large）的新型工艺感知生成建模方法，SD3.5-Large是一种最先进的文本到图像扩散模型，适用于微观结构生成。我们的方法引入了数值感知嵌入，将连续变量（退火温度、时间和放大倍数）直接编码到模型的条件中，从而能够在指定工艺条件下进行受控图像生成，并捕获工艺驱动的微观结构变化。为了解决数据稀缺和计算限制，我们通过DreamBooth和低秩适应（LoRA）仅对模型的一小部分权重进行微调，从而有效地将预训练模型迁移到材料领域。我们使用基于微调U-Net和VGG16编码器的语义分割模型在24张标记显微照片上验证了真实性。它实现了97.1%的准确率和85.7%的平均IoU，优于现有方法。使用物理描述符和空间统计的定量分析表明，合成微观结构与真实微观结构之间具有很强的一致性。具体而言，两点相关误差和线性路径误差分别保持在2.1%和0.6%以下。我们的方法代表了SD3.5-Large首次应用于工艺感知微观结构生成，为数据驱动的材料设计提供了一种可扩展的方法。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [511] [Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer](https://arxiv.org/abs/2507.00683)
> *测试自注意力机制的自旋浴视角：GPT-2 Transformer的哈密顿量分析*

*Satadeep Bhattacharjee, Seung-Cheol Lee* | **Category: cond-mat.mtrl-sci, cs.LG**

**Keywords:** 自注意力机制, 自旋浴, GPT-2, 哈密顿量, 模型可解释性

**Comment:** 

> **TL;DR:** 本文通过从GPT-2模型中提取权重矩阵并推导有效哈密顿量，为大型语言模型中的自旋浴类比提供了首个强有力的实验证据，并揭示了其与输出概率的因果关系，为模型可解释性和新型生成模型奠定基础。

**AI_Comments:** 这篇论文的创新之处在于，它首次将凝聚态物理学中的“自旋浴”概念与大型语言模型的自注意力机制进行了实证结合，并提供了强有力的实验证据。这种跨学科的视角为理解LLM内部工作机制提供了一个新颖且可解释的框架，突破了传统AI解释方法的局限。其重要性不仅在于增强了模型的可解释性，更在于为未来基于物理原理设计新型生成模型奠定了理论和实证基础。这有望开启AI研究的一个全新方向，即从更深层次的物理规律来构建和理解智能系统。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在基于Huo和Johnson提出的将LLM注意力机制建模为相互作用的双体自旋系统的物理学框架，提供对重复和偏差等现象的第一性原理解释，并寻求对该自旋浴假设的实证验证。

**Method:** 研究人员从生产级GPT-2模型中提取了完整的Query-Key权重矩阵，并为每个注意力头推导了相应的有效哈密顿量。通过这些哈密顿量，他们获得了分析性的“相边界”logit间隙标准。随后，在20个事实召回提示上对144个头进行了系统评估，并进行了目标消融实验。

**Result:** 理论logit间隙与模型的经验token排名之间存在强烈的负相关性（r≈-0.70，p<10^-3）。目标消融实验进一步表明，抑制与自旋浴预测最一致的头部会引起输出概率的预期变化。

**Conclusion:** 研究结果为生产级模型中的自旋浴类比提供了首个强有力的经验证据。这种验证不仅提供了一种易于处理的、受物理学启发的解释性视角，也为新型生成模型奠定了基础，弥合了理论凝聚态物理学与人工智能之间的鸿沟。

> **ai_Abstract:** 该论文对大型语言模型（LLM）中注意力机制的自旋浴物理学模型进行了实证检验。研究人员从GPT-2模型中提取了Query-Key权重矩阵，并推导了每个注意力头的有效哈密顿量，进而获得了预测token分布的logit间隙标准。通过对GPT-2的系统评估和消融实验，发现理论预测与模型行为之间存在强负相关和因果关系。这首次为生产级模型中的自旋浴类比提供了强有力的实验证据，为LLM的可解释性和新型生成模型提供了物理学启发的新视角。

> **摘要翻译:** Huo和Johnson最近提出的基于物理学的框架将大型语言模型（LLM）的注意力机制建模为一个相互作用的双体自旋系统，为重复和偏差等现象提供了第一性原理的解释。基于这一假设，我们从生产级GPT-2模型中提取了完整的Query-Key权重矩阵，并为每个注意力头推导了相应的有效哈密顿量。从这些哈密顿量中，我们获得了分析性的“相边界”logit间隙标准，可以预测在给定上下文中哪个token应该在下一个token分布中占主导地位。对20个事实召回提示中的144个头的系统评估显示，理论logit间隙与模型的经验token排名之间存在强烈的负相关性（r≈-0.70，p<10^-3）。目标消融实验进一步表明，抑制与自旋浴预测最一致的头部会引起输出概率的预期变化，证实了因果关系而非巧合关联。总而言之，我们的发现为生产级模型中的自旋浴类比提供了首个强有力的经验证据。这种验证不仅提供了一种易于处理的、受物理学启发的解释性视角，也为新型生成模型奠定了基础，弥合了理论凝聚态物理学与人工智能之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [501] [Physics-Aware Style Transfer for Adaptive Holographic Reconstruction](https://arxiv.org/abs/2507.00482)
> *物理感知风格迁移用于自适应全息重建*

*Chanseok Lee, Fakhriyya Mammadova, Jiseong Barg, Mooseok Jang* | **Category: physics.optics, cs.AI, cs.LG**

**Keywords:** 全息重建, 风格迁移, 物理感知, 深度学习, 无监督学习

**Comment:** Keywords: holographic imaging, style transfer, phase retrieval, deep
  learning

> **TL;DR:** 一种物理感知的风格迁移方法，仅使用强度测量数据即可自适应地重建全息图像，无需高质量的真实标签数据。

**AI_Comments:** 该论文的创新点在于将物理信息（物-传感器距离）融入到深度学习的风格迁移框架中，巧妙地解决了全息重建中对高质量真实标签数据的依赖问题。通过自适应学习和仅使用强度测量数据进行训练，极大地拓宽了其在实际生物医学成像（如实时、无标记成像）中的应用潜力。这种利用固有物理线索的策略对于数据获取困难的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 内联全息成像的逆问题是病态的，现有深度学习方法需要高质量的复杂振幅图真实标签数据集，这在实际应用中难以获取。

**Method:** 提出一种物理感知风格迁移方法，将物-传感器距离解释为衍射图中的隐式风格。利用风格域作为中间域构建循环图像翻译，从而仅使用强度测量数据集即可自适应地学习逆映射操作。

**Result:** 该方法能够仅通过强度测量数据集自适应地学习逆映射操作，并成功重建动态流动的红细胞形态，展示了其在实时、无标记成像中的潜力。

**Conclusion:** 所提出的方法利用测量中固有的物理线索，为难以或无法获得真实标签数据的成像应用提供了一种实用的学习策略。

> **ai_Abstract:** 本文提出了一种物理感知风格迁移方法，用于解决内联全息成像中从衍射图样重建复杂振幅的病态逆问题。该方法将物-传感器距离视为衍射图样中的隐式风格，并利用风格域构建循环图像翻译，从而仅依赖强度测量数据即可自适应地学习逆映射。实验证明，该方法能有效重建动态红细胞形态，为缺乏真实标签数据的成像应用提供了一种实用的学习策略。

> **摘要翻译:** 内联全息成像提出了一个从记录的衍射图样中重建物体复杂振幅的病态逆问题。尽管最近的深度学习方法在经典相位恢复算法方面显示出前景，但它们通常需要高质量的复杂振幅图真实标签数据集，以实现两个域之间的统计逆映射操作。在此，我们提出一种物理感知风格迁移方法，该方法将物-传感器距离解释为衍射图样中的隐式风格。通过将风格域作为中间域构建循环图像翻译，我们表明逆映射操作可以仅使用由强度测量组成的数据集以自适应方式学习。我们进一步通过重建动态流动的红细胞形态来证明其生物医学适用性，突出了其在实时、无标记成像方面的潜力。作为一种利用测量中固有物理线索的框架，所提出的方法为难以或无法获得真实标签数据的成像应用提供了一种实用的学习策略。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='physicsapp-ph'></a>
## physics.app-ph 

### [504] [Inverse Design in Nanophotonics via Representation Learning](https://arxiv.org/abs/2507.00546)
> *通过表征学习实现纳米光子学中的逆向设计*

*Reza Marzban, Ali Adibi, Raphael Pestourie* | **Category: physics.app-ph, cs.AI, cs.LG, physics.optics**

**Keywords:** 纳米光子学, 逆向设计, 表征学习, 机器学习, 生成模型

**Comment:** 

> **TL;DR:** 这篇综述探讨了机器学习，特别是表征学习，如何解决纳米光子学逆向设计中传统方法的计算和维度挑战，并分类了不同的ML增强方法。

**AI_Comments:** 这篇综述清晰地阐述了表征学习在纳米光子学逆向设计中的重要作用和分类方法。其创新之处在于将复杂的ML方法归纳为输出侧和输入侧两大类，并强调了混合框架的潜力。论文不仅总结了现有进展，更重要的是指出了未来的研究方向和挑战，对于该领域的学者具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 纳米光子学中的逆向设计对于光学进展至关重要，但传统的直觉驱动或迭代优化方法面临高维度、非凸设计空间和巨大的电磁仿真计算需求挑战。机器学习已成为解决这些瓶颈的有效途径。

**Method:** 本综述从表征学习的角度，将机器学习增强的逆向设计方法分为两类：输出侧方法和输入侧方法。输出侧方法利用机器学习学习解空间中的表征以创建可微分求解器加速优化；输入侧技术则利用机器学习学习可行器件几何形状的紧凑潜在空间表征，通过生成模型实现高效的全局探索。此外，还讨论了结合物理优化与数据驱动表征的混合框架。

**Result:** 不同的策略在数据需求、泛化能力和新颖设计发现潜力方面各有优缺点。混合框架有助于避免局部最优、提高可扩展性并促进知识转移。

**Conclusion:** 论文总结了开放的挑战和机遇，包括复杂性管理、几何无关表征、制造约束的整合以及多物理场协同设计的进步。

> **ai_Abstract:** 这篇综述文章深入探讨了机器学习如何革新纳米光子学中的逆向设计，解决了传统方法在高维非凸设计空间和计算成本方面的局限性。文章将ML增强的逆向设计方法归类为输出侧和输入侧两种表征学习方法，并分析了它们的优缺点及混合框架的潜力。最后，文章指出了该领域的未来挑战和发展方向。

> **摘要翻译:** 纳米光子学中的逆向设计，即计算发现实现目标电磁（EM）响应的结构，已成为近期光学进展的关键工具。传统的直觉驱动或迭代优化方法难以应对固有的高维、非凸设计空间以及电磁仿真巨大的计算需求。最近，机器学习（ML）已出现并有效解决了这些瓶颈。本综述通过表征学习的视角来构建ML增强的逆向设计方法，将其分为两类：输出侧方法和输入侧方法。输出侧方法使用ML学习解空间中的表征以创建可微分求解器，从而加速优化。相反，输入侧技术采用ML学习可行器件几何形状的紧凑潜在空间表征，通过生成模型实现高效的全局探索。每种策略在数据需求、泛化能力和新颖设计发现潜力方面都呈现出独特的权衡。结合物理优化与数据驱动表征的混合框架有助于摆脱糟糕的局部最优，提高可扩展性，并促进知识转移。最后，我们强调了开放的挑战和机遇，着重于复杂性管理、几何无关表征、制造约束的整合以及多物理场协同设计的进步。

</details>

[⬆️ 返回分类顶部](#physicsapp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phco'></a>
## astro-ph.CO 

### [506] [Simulation-Efficient Cosmological Inference with Multi-Fidelity SBI](https://arxiv.org/abs/2507.00514)
> *基于多保真度SBI的模拟高效宇宙学推断*

*Leander Thiele, Adrian E. Bayer, Naoya Takeishi* | **Category: astro-ph.CO, cs.LG**

**Keywords:** 宇宙学推断, 多保真度, 模拟基础推断, 特征匹配, 知识蒸馏

**Comment:** 5 pages, 4 figures; accepted at ICML-colocated ML4Astro 2025 workshop

> **TL;DR:** 通过结合不同保真度的模拟数据集，提出了一种基于特征匹配和知识蒸馏的多保真度推断方法，以降低宇宙学模拟推断的成本，并提高后验质量。

**AI_Comments:** 该论文的创新点在于将特征匹配和知识蒸馏应用于多保真度模拟推断，有效解决了宇宙学模拟高成本的问题。这对于资源受限的研究环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 宇宙学模拟推断的模拟成本很高，需要找到方法来降低。

**Method:** 提出了一种基于特征匹配和知识蒸馏的多保真度推断方法。

**Result:** 该方法改善了后验质量，特别是在模拟预算有限和推断问题困难的情况下。

**Conclusion:** 通过结合不同保真度的模拟数据和采用特征匹配与知识蒸馏，可以有效提高宇宙学模拟推断的效率和质量。

> **ai_Abstract:** 本研究提出了一种针对宇宙学模拟推断的多保真度方法，旨在通过结合不同保真度的模拟数据集来降低高昂的模拟成本。该方法基于特征匹配和知识蒸馏，并已被证明能够提高后验质量，特别是在模拟预算受限或推断问题复杂的情况下表现更优。

> **摘要翻译:** 宇宙学模拟推断的模拟成本可以通过结合不同保真度的模拟集来降低。我们提出了一种基于特征匹配和知识蒸馏的多保真度推断方法。我们的方法能够改善后验质量，尤其是在模拟预算较小和推断问题困难的情况下。

</details>

[⬆️ 返回分类顶部](#astro-phco) | [⬆️ 返回总目录](#toc)

---

<a id='mathdg'></a>
## math.DG 

### [507] [Geometric Gaussian Approximations of Probability Distributions](https://arxiv.org/abs/2507.00616)
> *概率分布的几何高斯近似*

*Nathaël Da Costa, Bálint Mucsányi, Philipp Hennig* | **Category: math.DG, cs.LG, math.PR, math.ST, stat.TH**

**Keywords:** 几何高斯近似, 概率分布, 微分同胚, 黎曼指数映射, 普遍性

**Comment:** 

> **TL;DR:** 本文研究了几何高斯近似的表达能力，证明了它们可以普遍地近似任何概率分布，并探讨了它们之间的关系以及寻找通用微分同胚的可能性。

**AI_Comments:** 该论文的创新之处在于其对几何高斯近似普遍性的建设性证明，这表明了这类方法在近似复杂概率分布方面的强大潜力。它为贝叶斯推理等领域提供了新的理论基础和工具。论文还提出了一个重要的开放问题，即寻找通用微分同胚以统一近似一族分布，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 近似复杂的概率分布（如贝叶斯后验分布）在许多应用中具有核心重要性。

**Method:** 本文研究了几何高斯近似的两种不同类型（通过微分同胚或黎曼指数映射的高斯前推），回顾了它们，探讨了它们之间的关系，并提供了一个建设性证明，表明这些近似是普遍的。最后，讨论了是否能找到一个共同的微分同胚来获得高质量的近似。

**Result:** 提供了一个建设性证明，表明几何高斯近似是普遍的，即它们可以捕捉任何概率分布。

**Conclusion:** 几何高斯近似具有普遍性，能够近似任何概率分布；同时，论文也提出了未来研究方向，即探索是否存在一个通用的微分同胚来统一近似一族概率分布。

> **ai_Abstract:** 本文探讨了几何高斯近似的表达能力，这种近似通过微分同胚或黎曼指数映射将高斯分布前推来近似复杂的概率分布。文章回顾了这两种近似类型，分析了它们之间的关系，并提供了一个关键的建设性证明，表明几何高斯近似具有普遍性，能够捕捉任何概率分布。此外，论文还讨论了为给定的一族分布寻找共同微分同胚以实现高质量统一近似的潜力。

> **摘要翻译:** 近似复杂的概率分布，例如贝叶斯后验分布，在许多应用中具有核心重要性。我们研究了几何高斯近似的表达能力。这些近似包括通过微分同胚或黎曼指数映射进行高斯前推的近似。我们首先回顾了这两种不同类型的几何高斯近似。然后我们探讨了它们之间的关系。我们进一步提供了一个建设性证明，即这种几何高斯近似是普遍的，因为它们可以捕捉任何概率分布。最后，我们讨论了给定一族概率分布，是否可以找到一个共同的微分同胚来为该族分布获得统一的高质量几何高斯近似。

</details>

[⬆️ 返回分类顶部](#mathdg) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matdis-nn'></a>
## cond-mat.dis-nn 

### [508] [Generalization performance of narrow one-hidden layer networks in the teacher-student setting](https://arxiv.org/abs/2507.00629)
> *窄单隐藏层网络在教师-学生设置中的泛化性能*

*Jean Barbier, Federica Gerace, Alessandro Ingrosso, Clarissa Lauditi, Enrico M. Malatesta, Gibbs Nwemadji, Rodrigo Pérez Ortiz* | **Category: cond-mat.dis-nn, cs.LG, math.PR, math.ST, stat.TH**

**Keywords:** 泛化性能, 神经网络, 教师-学生设置, 统计物理学, 单隐藏层网络

**Comment:** 34 pages, figures

> **TL;DR:** 该研究为窄单隐藏层网络在教师-学生设置中提供了泛化性能的通用理论，并使用统计物理学方法给出了封闭形式的表达式，揭示了隐藏神经元特化的现象。

**AI_Comments:** 这项工作通过引入统计物理学方法，为理解窄单隐藏层网络的泛化性能提供了重要的理论基础，填补了现有理论的空白。其创新之处在于为特定网络结构提供了封闭形式的泛化误差表达式，并揭示了隐藏神经元的特化行为，这对于深入理解神经网络的学习机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解神经网络在简单输入-输出分布上的泛化能力对于解释它们在真实数据集上的学习性能至关重要。目前缺乏对具有通用激活函数的全连接单隐藏层网络性能的完整理论解释。

**Method:** 开发了一种针对窄网络（隐藏单元数量大但远小于输入维度）的通用理论。使用统计物理学方法，提供了有限温度（贝叶斯）和经验风险最小化估计器典型性能的封闭形式表达式，基于少量权重统计量。

**Result:** 提供了封闭形式的表达式，准确预测了神经网络在回归或分类任务上的泛化误差。强调了当样本数量足够大且与网络参数数量成比例时，隐藏神经元会特化的转变现象。

**Conclusion:** 该理论能够准确预测神经网络在回归或分类任务上通过带噪声全批梯度下降（Langevin动力学）或全批梯度下降训练时的泛化误差。

> **ai_Abstract:** 本文针对神经网络的泛化能力问题，在经典的教师-学生设置下，为窄（隐藏层单元数远小于输入维度）单隐藏层网络构建了一个通用理论框架。研究利用统计物理学方法，推导出了有限温度（贝叶斯）和经验风险最小化估计器泛化性能的封闭形式表达式，并揭示了当样本量足够大时隐藏神经元特化的现象。该理论能够准确预测神经网络在回归或分类任务中的泛化误差。

> **摘要翻译:** 理解神经网络在简单输入-输出分布上的泛化能力对于解释它们在真实数据集上的学习性能至关重要。经典的教师-学生设置，即网络从通过标签生成教师模型获得的数据中进行训练，是一个完美的理论测试平台。在这种背景下，目前缺乏对具有通用激活函数的全连接单隐藏层网络性能的完整理论解释。在这项工作中，我们为窄网络，即隐藏单元数量大但远小于输入维度的网络，开发了这样一个通用理论。我们使用统计物理学方法，根据少量权重统计量，为有限温度（贝叶斯）和经验风险最小化估计器的典型性能提供了封闭形式的表达式。在此过程中，我们强调了当样本数量足够大并与网络参数数量成比例时，隐藏神经元特化的转变现象。我们的理论准确预测了通过带噪声全批梯度下降（Langevin动力学）或全批梯度下降训练的神经网络在回归或分类任务上的泛化误差。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

<a id='nlinao'></a>
## nlin.AO 

### [509] [Hebbian Physics Networks: A Self-Organizing Computational Architecture Based on Local Physical Laws](https://arxiv.org/abs/2507.00641)
> *赫布物理网络：一种基于局部物理定律的自组织计算架构*

*Gunjan Auti, Hirofumi Daiguji, Gouhei Tanaka* | **Category: nlin.AO, cs.LG, stat.CO, stat.ME**

**Keywords:** 赫布物理网络, 自组织, 局部物理定律, 非平衡热力学, 复杂动力学系统

**Comment:** 6 pages, 2 figures, 2 supplementary videos

> **TL;DR:** 赫布物理网络（HPN）是一种新的计算框架，通过局部赫布更新和守恒定律的违反来学习，无需全局优化，能自发生成物理一致的结构。

**AI_Comments:** HPNs的创新之处在于其将物理定律内化为局部动力学，并通过残差驱动的赫布可塑性实现自组织学习，从而摆脱了对全局损失函数的依赖。这种方法提高了模型的可解释性，并使其更符合物理原理，为复杂系统建模提供了一个有前景的新方向。其基于非平衡热力学和耗散结构的灵感也很有趣，为机器学习与物理学的结合开辟了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习方法在物理领域依赖全局优化，限制了可解释性，并需要外部施加物理约束。本文旨在引入一种无需全局损失函数、可解释且物理基础的替代方案，以解决这些局限性。

**Method:** 本文引入了赫布物理网络（HPN），这是一种自组织计算框架。学习过程源于由守恒定律违反驱动的局部赫布更新。物理定律被直接编码到系统的局部动力学中，从而消除了对全局损失函数的需求。残差——即连续性、动量或能量中量化的不平衡——作为热力学信号，通过广义赫布可塑性驱动权重的适应。该方法以非平衡热力学为基础，并受到普利高津耗散结构理论的启发。

**Result:** HPNs在不可压缩流体流动和连续扩散的示例中得到了验证，结果表明物理一致的结构可以从随机初始条件自发地出现，且无需监督。

**Conclusion:** 赫布物理网络（HPNs）将计算重构为一种残差驱动的热力学过程，为复杂动力学系统建模提供了一种可解释、可扩展且物理基础的替代方案。

> **ai_Abstract:** 赫布物理网络（HPN）是一种新型自组织计算框架，它通过将物理定律直接编码到局部动力学中，并利用守恒定律违反产生的残差作为热力学信号，通过局部赫布更新驱动权重适应，从而避免了传统机器学习方法对全局优化的依赖。该网络基于非平衡热力学和耗散结构理论。实验证明，HPNs能在无需监督的情况下，从随机初始条件自发生成物理一致的结构，例如在流体流动和扩散模拟中。HPNs为复杂动力学系统建模提供了一种可解释、可扩展且物理基础的新范式。

> **摘要翻译:** 传统物理学中的机器学习方法依赖于全局优化，这限制了可解释性并需要外部施加物理约束。我们引入了赫布物理网络（HPN），这是一种自组织计算框架，其中学习源于由守恒定律违反驱动的局部赫布更新。HPNs以非平衡热力学为基础，并受到普利高津耗散结构理论的启发，通过将物理定律直接编码到系统的局部动力学中，消除了对全局损失函数的需求。残差——即连续性、动量或能量中量化的不平衡——作为热力学信号，通过广义赫布可塑性驱动权重适应。我们展示了这种方法在不可压缩流体流动和连续扩散上的应用，其中物理一致的结构从随机初始条件中自发出现，无需监督。HPNs将计算重构为一种残差驱动的热力学过程，为建模复杂动力学系统提供了一种可解释、可扩展且物理基础的替代方案。

</details>

[⬆️ 返回分类顶部](#nlinao) | [⬆️ 返回总目录](#toc)

---

<a id='statco'></a>
## stat.CO 

### [510] [Harnessing the Power of Reinforcement Learning for Adaptive MCMC](https://arxiv.org/abs/2507.00671)
> *利用强化学习增强自适应MCMC的能力*

*Congye Wang, Matthew A. Fisher, Heishiro Kanagawa, Wilson Chen, Chris. J. Oates* | **Category: stat.CO, cs.LG, stat.ML**

**Keywords:** 强化学习, MCMC, 自适应采样, 对比散度, Metropolis-Hastings

**Comment:** 

> **TL;DR:** 本文提出了一种基于对比散度的强化学习Metropolis-Hastings（RLMH）新型奖励函数，解决了现有奖励信号不足的问题，并展示了RLMH在自适应梯度采样器中的实际有效性。

**AI_Comments:** 本文的创新之处在于提出了一个有效的奖励函数（基于对比散度），解决了强化学习Metropolis-Hastings (RLMH) 在实践中训练信号不足的关键问题。这使得RLMH从理论概念走向了实际应用，为MCMC采样器的自适应调优提供了一个强大的框架。其重要性在于，它减轻了用户手动调优复杂采样算法的负担，有望提高概率机器学习模型的效率和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 随着采样算法日益复杂，其调优负担也随之增加，亟需将采样器的调优本身视为一个学习任务。尽管Wang et al (2025) 提出了将Metropolis-Hastings表述为马尔可夫决策过程，为使用强化学习进行自适应调优（RLMH）提供了理论基础，但其在实践中的益处尚未完全实现。

**Method:** 本文首先发现接受率或预期平方跳跃距离等自然奖励选择不足以训练RLMH。为此，提出了一种基于对比散度的新型奖励函数，并证明了其在RLMH背景下的优越性能。其次，探索了RLMH的潜力，并提出了自适应梯度采样器，这些采样器平衡了马尔可夫转移核的灵活性与相关RL任务的可学习性。

**Result:** 研究发现，接受率或预期平方跳跃距离等常规奖励信号不足以有效训练RLMH。相比之下，本文提出的基于对比散度的新型奖励函数在RLMH中表现出卓越的性能。通过使用posteriordb基准进行的全面模拟研究，支持了RLMH的实际有效性，特别是在自适应梯度采样器中的应用。

**Conclusion:** 本文成功地将强化学习应用于自适应MCMC采样器的调优，通过引入一种有效的新型奖励函数（基于对比散度）解决了训练信号不足的问题，并展示了RLMH在实际应用中的强大潜力，为复杂采样算法的自动化调优提供了可行方案。

> **ai_Abstract:** 本文解决了复杂采样算法（如MCMC）调优负担过重的问题，通过将调优视为强化学习任务。在Wang et al (2025) 将Metropolis-Hastings表述为马尔可夫决策过程的基础上，本文发现传统奖励（如接受率）不足以训练RLMH。为此，作者提出了一种基于对比散度的新型奖励函数，并证明其在RLMH中表现优越。此外，论文还探索了RLMH的潜力，并开发了自适应梯度采样器，平衡了转移核的灵活性和RL任务的可学习性。全面的模拟研究证实了RLMH的实际有效性。

> **摘要翻译:** 采样算法推动了概率机器学习的发展，近年来，用于此任务的工具种类呈爆炸式增长。然而，采样算法复杂性的增加与调优负担的增加相关。现在比以往任何时候都更需要将采样器的调优本身视为一个学习任务。在一项概念性突破中，Wang 等人 (2025) 将 Metropolis-Hastings 公式化为马尔可夫决策过程，为使用强化学习 (RL) 进行自适应调优打开了可能性。他们的重点是理论基础；实现强化学习 Metropolis-Hastings (RLMH) 的实际益处则留待后续工作。本文的目的有两方面：首先，我们观察到一个令人惊讶的结果，即诸如接受率或预期平方跳跃距离等自然奖励选择，为训练 RLMH 提供的信号不足。相反，我们提出了一种基于对比散度的新型奖励，并在 RLMH 的背景下证明了其卓越的性能。其次，我们探索了 RLMH 的潜力，并提出了自适应梯度采样器，这些采样器平衡了马尔可夫转移核的灵活性与相关 RL 任务的可学习性。一项使用 posteriordb 基准进行的全面模拟研究支持了 RLMH 的实际有效性。

</details>

[⬆️ 返回分类顶部](#statco) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [513] [SINDy on slow manifolds](https://arxiv.org/abs/2507.00747)
> *慢流形上的SINDy*

*Diemen Delgado-Cano, Erick Kracht, Urban Fasel, Benjamin Herrmann* | **Category: math.DS, cs.LG, physics.comp-ph**

**Keywords:** SINDy, 慢流形, 动力学系统, 稀疏识别, 非线性动力学

**Comment:** 18 pages, 6 figures, to be submitted to Nonlinear Dynamics (Springer)

> **TL;DR:** 本文提出了一种两步SINDy变体，用于识别慢快动力学系统。它首先识别慢流形，然后学习慢变量在流形上的动力学，通过定制的函数库来克服计算复杂性和病态性问题。

**AI_Comments:** 这项工作是SINDy领域的一个重要进展，通过巧妙地解决候选项的组合爆炸问题，扩展了SINDy在复杂慢快系统中的适用性。采用两步法并结合流形信息库是解决原始SINDy方法一个显著局限性的巧妙方案。

<details>
  <summary>Details</summary>

**Motivation:** 对于高维慢快动力学系统，稀疏识别非线性动力学（SINDy）方法面临计算上难以处理和病态的问题。这是因为，尽管原则上只对底层慢流形上的动力学进行建模可以解决这些挑战，但截断的快变量需要通过包含更高阶非线性项作为模型的候选项来补偿，这导致SINDy库的规模爆炸性增长。

**Method:** 开发了一种两步SINDy变体：(i) 识别慢流形，即快变量作为慢变量函数的代数方程；(ii) 学习限制在流形上的慢变量动力学模型。关键在于，(i) 中学习到的方程被用于为 (ii) 构建一个流形信息化的函数库，该库仅包含必要的更高阶非线性项作为候选项，而不是包含所有特定阶数的多项式，从而形成一个针对特定问题定制的稀疏子集。

**Result:** 该方法显著降低了条件数和SINDy库的大小，从而能够准确识别慢流形上的动力学。该方法在屈曲梁和NACA 0012翼型流动的数值示例上得到了验证。

**Conclusion:** 本文提出的两步SINDy变体通过利用流形信息构建稀疏且定制的库，有效解决了将SINDy应用于高维慢快动力学系统时的挑战，从而实现了更鲁棒和高效的模型识别。

> **ai_Abstract:** 本文提出了一种新颖的两步SINDy方法，旨在解决SINDy应用于高维慢快动力学系统时面临的计算复杂性和病态问题。该方法首先识别慢流形，然后在此流形上学习慢变量的动力学。其核心创新在于利用已识别的流形构建一个稀疏且定制的函数库，从而显著减小了库的规模并改善了条件数，最终实现了精确高效的模型识别。

> **摘要翻译:** 稀疏识别非线性动力学（SINDy）已被确立为一种从数据中学习动力系统可解释模型的有效方法。然而，对于高维慢快动力学系统，回归问题同时变得计算上难以处理和病态。尽管原则上，仅对底层慢流形上演化的动力学进行建模可以解决这两个挑战，但截断的快变量必须通过包含更高阶非线性项作为模型的候选项来补偿，这导致SINDy库的规模爆炸性增长。在这项工作中，我们开发了一种SINDy变体，能够以两步方式鲁棒且高效地识别慢快动力学：(i) 识别慢流形，即快变量作为慢变量函数的代数方程，以及 (ii) 学习限制在流形上的慢变量动力学模型。关键在于，在 (i) 中学习到的方程被利用来为 (ii) 构建一个流形信息化的函数库，该库仅包含必要的更高阶非线性项作为候选项。与包含特定阶数的所有单项式不同，由此产生的自定义库是后者的一个稀疏子集，专门针对手头的问题量身定制。该方法在屈曲梁和NACA 0012翼型流动的数值示例上得到了验证。我们发现我们的方法显著降低了条件数和SINDy库的大小，从而能够准确识别慢流形上的动力学。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [516] [HyperFusion: Hierarchical Multimodal Ensemble Learning for Social Media Popularity Prediction](https://arxiv.org/abs/2507.00926)
> *HyperFusion：面向社交媒体流行度预测的层次多模态集成学习*

*Liliang Ye, Yunyao Zhang, Yafeng Wu, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang, Zikai Song* | **Category: cs.MM, cs.LG**

**Keywords:** 社交媒体流行度预测, 多模态学习, 集成学习, 层次融合, 伪标签

**Comment:** 

> **TL;DR:** HyperFusion是一个用于社交媒体流行度预测的层次多模态集成学习框架，通过三层融合架构和两阶段训练方法，在SMP挑战赛数据集上取得了有竞争力的性能。

**AI_Comments:** HyperFusion的创新点在于其独特的三层融合架构和层次集成策略，有效整合了多模态数据。两阶段训练方法结合伪标签处理了数据稀缺问题，而跨模态相似性及层次聚类特征的引入进一步提升了模型捕获复杂依赖关系的能力。该方法在实际竞赛中的优异表现证明了其在社交媒体流行度预测领域的实用性和先进性。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体流行度预测对于内容优化、营销策略和用户参与度提升至关重要，但由于视觉、文本、时间、用户行为等复杂因素的相互作用，预测帖子流行度仍然具有挑战性。

**Method:** 本文提出了HyperFusion，一个用于社交媒体流行度预测的层次多模态集成学习框架。该方法采用三层融合架构，逐步整合抽象级别的特征，包括来自CLIP编码器的视觉表示、来自Transformer模型的文本嵌入以及时间-空间元数据和用户特征。该框架实现了一个结合CatBoost、TabNet和自定义多层感知器的层次集成策略。为解决标注数据有限的问题，提出了一种带有伪标签和迭代细化的两阶段训练方法。此外，引入了新颖的跨模态相似性度量和层次聚类特征，以捕获模态间依赖关系。

**Result:** 实验结果表明，HyperFusion在SMP挑战赛数据集上取得了有竞争力的性能。该团队在SMP挑战赛2025（图像赛道）中获得了第三名。

**Conclusion:** HyperFusion框架通过其层次多模态融合和集成策略，有效地解决了社交媒体流行度预测的挑战，并在实际竞赛中展现了其有效性和竞争力。

> **ai_Abstract:** 本文介绍了HyperFusion，一个针对社交媒体流行度预测的层次多模态集成学习框架。该框架通过三层架构融合视觉、文本、时间-空间和用户特征，并采用CatBoost、TabNet和MLP的层次集成策略。为应对数据稀缺，引入了两阶段伪标签训练方法，并设计了新的跨模态相似性和层次聚类特征。实验证明，HyperFusion在SMP挑战赛中表现出色，获得第三名。

> **摘要翻译:** 社交媒体流行度预测在数字平台上的内容优化、营销策略和用户参与度提升中扮演着关键角色。然而，由于视觉、文本、时间以及用户行为因素之间复杂的相互作用，预测帖子流行度仍然充满挑战。本文提出了HyperFusion，一个用于社交媒体流行度预测的层次多模态集成学习框架。我们的方法采用三层融合架构，逐步整合抽象级别的特征：来自CLIP编码器的视觉表示、来自Transformer模型的文本嵌入，以及时间-空间元数据和用户特征。该框架实现了一个结合CatBoost、TabNet和自定义多层感知器的层次集成策略。为解决标注数据有限的问题，我们提出了一种带有伪标签和迭代细化的两阶段训练方法。我们引入了新颖的跨模态相似性度量和层次聚类特征，以捕获模态间依赖关系。实验结果表明，HyperFusion在SMP挑战赛数据集上取得了有竞争力的性能。我们的团队在SMP挑战赛2025（图像赛道）中获得了第三名。源代码可在https://anonymous.4open.science/r/SMPDImage 获取。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phsr'></a>
## astro-ph.SR 

### [517] [Atmospheric model-trained machine learning selection and classification of ultracool TY dwarfs](https://arxiv.org/abs/2507.00957)
> *大气模型训练的超冷TY矮星机器学习选择与分类*

*Ankit Biswas* | **Category: astro-ph.SR, astro-ph.EP, astro-ph.IM, cs.LG**

**Keywords:** 超冷矮星, 机器学习, T型矮星, Y型矮星, 大气模型

**Comment:** 12 pages, 9 figures, to be published in Monthly Notices of the Royal
  Astronomical Society

> **TL;DR:** 本文提出了一种新颖的机器学习框架，完全基于大气模型的合成测光数据进行训练，用于检测和分类晚期T型和Y型矮星，并在发现新的暗弱晚期超冷矮星方面表现出色。

**AI_Comments:** 这项研究的创新之处在于利用大气模型生成的合成测光数据来训练机器学习模型，从而克服了晚期超冷矮星（UCDs）观测样本稀疏的限制。这种方法使得训练数据集的规模远超任何经验数据集，显著提高了模型在检测和分类这些难以观测的天体方面的性能和精度。此外，通过实际发现新的UCD候选者，验证了该方法的实际应用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** T型和Y型光谱类代表了最冷、质量最低的褐矮星群体，但由于统计数据有限，其普查仍不完整。现有探测框架通常受限于识别M、L和早期T型矮星，因为晚期超冷矮星（UCDs）的观测样本稀疏。

**Method:** 本文提出了一种新颖的机器学习框架，完全基于ATMO 2020和Sonora Bobcat模型生成的合成测光数据进行训练，用于检测和分类晚期T型和Y型矮星。通过对模型测光数据拟合多项式颜色关系来为这些合成模型分配光谱类型，进而训练一个分类器集合来识别和分类晚期UCDs的光谱类型。所使用的训练数据集比任何经验数据集大两个数量级以上。

**Result:** 该模型在合成和经验数据集上验证时都表现出高性能，对已知UCDs的目录验证对象分类指标超过99%，平均光谱类型精度在0.35 +/- 0.37子类型以内。将该模型应用于双鱼座周围1.5度区域和UKIDSS UDS场，发现了一个以前未编入目录的T8.2候选者。

**Conclusion:** 这种基于模型训练的方法能够有效地从测光星表中发现暗弱的晚期超冷矮星。

> **ai_Abstract:** 本文介绍了一种新颖的机器学习框架，专门用于检测和分类晚期T型和Y型褐矮星。该框架的独特之处在于其完全基于大气模型（ATMO 2020和Sonora Bobcat）生成的合成测光数据进行训练，从而构建了一个比现有经验数据集大两个数量级的训练集。通过拟合多项式颜色关系来为合成模型分配光谱类型，并训练一个分类器集合。该模型在合成和经验数据集上均表现出色，分类精度超过99%，光谱类型精度在0.35 +/- 0.37子类型内。此外，该模型成功发现了一个新的T8.2候选者，证明了其在从测光星表中发现暗弱晚期超冷矮星方面的有效性。

> **摘要翻译:** T型和Y型光谱类代表了最冷、质量最低的褐矮星群体，但由于统计数据有限，其普查仍不完整。现有探测框架通常受限于识别M、L和早期T型矮星，因为晚期超冷矮星（UCDs）的观测样本稀疏。本文提出了一种新颖的机器学习框架，能够检测和分类晚期T型和Y型矮星，该框架完全基于大气模型的合成测光数据进行训练。利用ATMO 2020和Sonora Bobcat模型的网格，我生成了一个训练数据集，其规模比任何经验性>T6 UCDs集合大两个数量级以上。通过对模型测光数据拟合多项式颜色关系来为这些合成模型分配光谱类型，进而训练一个分类器集合来识别和分类晚期UCDs的光谱类型。该模型在合成和经验数据集上验证时都表现出高性能，对已知UCDs的目录验证对象分类指标超过99%，平均光谱类型精度在0.35 +/- 0.37子类型以内。将该模型应用于双鱼座周围1.5度区域和UKIDSS UDS场，发现了一个以前未编入目录的T8.2候选者，这表明这种基于模型训练的方法能够从测光星表中发现暗弱的晚期UCDs。

</details>

[⬆️ 返回分类顶部](#astro-phsr) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [518] [From Sentences to Sequences: Rethinking Languages in Biological System](https://arxiv.org/abs/2507.00953)
> *从句子到序列：重新思考生物系统中的语言*

*Ke Liu, Shuanke Shen, Hao Chen* | **Category: q-bio.BM, cs.AI**

**Keywords:** 生物语言建模, 大语言模型, 结构评估, 自回归范式, 生物分子3D结构

**Comment:** 

> **TL;DR:** 本文重新审视生物系统中的语言概念，通过将生物分子的3D结构视为语义内容，并强调结构评估，以更好地将NLP方法应用于生物序列建模。

**AI_Comments:** 本文的创新点在于重新定义了生物系统中的“语言”概念，特别是将生物分子的3D结构视为语义内容，这为将NLP方法更有效地应用于生物领域提供了新的视角和理论基础。它强调了结构评估的重要性，纠正了简单迁移NLP范式可能带来的不足，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** NLP中的大语言模型在生物语言建模中显示出潜力，但自然语言和生物语言的内在结构关联存在根本差异，因此需要重新理解如何在生物领域有效应用NLP的成功经验。

**Method:** 将生物分子的3D结构视为句子的语义内容，并考虑残基或碱基之间的强关联性。通过这种方式，强调结构评估的重要性，并论证自回归范式在生物语言建模中的适用性。

**Result:** 强调了结构评估的重要性，并证明了自回归范式在生物语言建模中的适用性。

**Conclusion:** 通过重新定义生物语言并考虑其3D结构语义，NLP的自回归范式和评估方法可以有效应用于生物序列建模。

> **ai_Abstract:** 本文探讨了将自然语言处理（NLP）中的大语言模型范式应用于生物序列建模（如蛋白质、RNA、DNA）的潜力与挑战。尽管NLP的自回归生成和评估方法已被引入生物领域，但作者指出自然语言和生物语言在内在结构关联上存在根本差异。为了有效桥接这一鸿沟，文章提出将生物分子的三维结构视为“句子”的语义内容，并强调了结构评估的重要性，从而论证了自回归范式在生物语言建模中的适用性。

> **摘要翻译:** 自然语言处理（NLP）中的大型语言模型范式在建模蛋白质、RNA和DNA等生物语言方面也显示出前景。自回归生成范式和评估指标都已从NLP转移到生物序列建模。然而，自然语言和生物语言的内在结构关联存在根本差异。因此，我们重新审视生物系统中的语言概念，以更好地理解如何将NLP的成功经验有效地转化为生物领域。通过将生物分子的三维结构视为句子的语义内容，并考虑残基或碱基之间的强关联性，我们强调了结构评估的重要性，并证明了自回归范式在生物语言建模中的适用性。代码可在\href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}找到。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

