{"id": "2405.13156", "title": "A Privacy-Preserving DAO Model Using NFT Authentication for the Punishment not Reward Blockchain Architecture", "authors": ["Talgar Bayan", "Richard Banach"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This paper was accepted and presented at the International Conference on Blockchain Research and Applications (BCRA 2024), Hangzhou, China, July 26-27, 2024. An extended version has been submitted to the journal Blockchain: Research and Applications (Elsevier) for publication consideration. This arXiv version corresponds to the conference-accepted manuscript", "url": "http://arxiv.org/abs/2405.13156v2", "summary": "This paper presents a decentralised autonomous organisation (DAO) model that\nuses non-fungible tokens (NFTs) for identity management and privacy-preserving\ninteractions within a Punishment not Reward (PnR) blockchain mechanism. The\nproposed model introduces a dual NFT architecture deployed on Layer 2 networks:\nMembership NFTs (\\(NFT_{auth}\\)) for authentication and access control and\ninteraction NFTs (\\(NFT_{priv}\\)) for private interactions among participants.\nOur Layer 2 implementation achieves 97\\% gas cost reduction while maintaining\nsecurity through cross-chain mechanisms. The identity management system\nincorporates decentralised KYC processes and Sybil attack resistance using\nsoulbound token characteristics. Governance operates through smart contracts\nthat manage reputation and administer punitive measures, including conditional\nidentity disclosure for forensic purposes. Governance operates through smart\ncontracts that manage reputation and administer punitive measures, including\nconditional identity disclosure when misconduct is detected.", "comment": "This paper was accepted and presented at the International Conference\n  on Blockchain Research and Applications (BCRA 2024), Hangzhou, China, July\n  26-27, 2024. An extended version has been submitted to the journal\n  Blockchain: Research and Applications (Elsevier) for publication\n  consideration. This arXiv version corresponds to the conference-accepted\n  manuscript", "pdf_url": "http://arxiv.org/pdf/2405.13156v2", "cate": "cs.CR", "date": "2024-05-21", "updated": "2025-07-31", "AI": {"title_translation": "一种使用NFT认证的惩罚而非奖励区块链架构的隐私保护DAO模型", "tldr": "该论文提出了一种在惩罚而非奖励（PnR）区块链架构中，利用双NFT（身份认证NFT和隐私交互NFT）实现身份管理和隐私保护交互的去中心化自治组织（DAO）模型，并通过Layer 2实现97%的Gas成本降低。", "motivation": "该论文旨在提出一种去中心化自治组织（DAO）模型，该模型在“惩罚而非奖励”（PnR）区块链机制中，利用非同质化代币（NFTs）进行身份管理和隐私保护交互。", "method": "该模型引入了一种部署在Layer 2网络上的双NFT架构：用于认证和访问控制的成员NFT（NFT_auth）以及用于参与者之间私密交互的交互NFT（NFT_priv）。身份管理系统结合了去中心化KYC流程和使用灵魂绑定代币特性来抵抗女巫攻击。治理通过智能合约进行，管理声誉并实施惩罚措施，包括在检测到不当行为时有条件地披露身份以进行取证。", "result": "Layer 2实现将Gas成本降低了97%，同时通过跨链机制保持了安全性。", "conclusion": "该论文提出了一种创新的隐私保护DAO模型，该模型通过双NFT架构、Layer 2部署、去中心化身份管理和基于智能合约的惩罚性治理，在惩罚而非奖励的区块链环境中实现了高效且安全的身份和隐私管理。", "translation": "这篇论文提出了一种去中心化自治组织（DAO）模型，该模型在“惩罚而非奖励”（PnR）区块链机制中，利用非同质化代币（NFTs）进行身份管理和隐私保护交互。所提出的模型引入了一种部署在Layer 2网络上的双NFT架构：用于认证和访问控制的成员NFT（NFT_auth）和用于参与者之间私密交互的交互NFT（NFT_priv）。我们的Layer 2实现将Gas成本降低了97%，同时通过跨链机制保持了安全性。身份管理系统结合了去中心化KYC流程和使用灵魂绑定代币特性来抵抗女巫攻击。治理通过智能合约进行，管理声誉并实施惩罚措施，包括在检测到不当行为时有条件地披露身份以进行取证。", "summary": "该论文提出了一种基于“惩罚而非奖励”（PnR）区块链架构的隐私保护DAO模型。该模型核心是部署在Layer 2上的双NFT架构：成员NFT用于认证和访问控制，交互NFT用于私密通信。通过这种设计，实现了去中心化身份管理、抵抗女巫攻击，并在Layer 2上显著降低了Gas成本97%。治理通过智能合约进行，管理声誉并实施惩罚，包括在必要时有条件地披露身份。", "keywords": "DAO, NFT, 隐私保护, 区块链, 惩罚而非奖励", "comments": "该论文的创新点在于其将隐私保护与“惩罚而非奖励”的区块链范式相结合，并通过双NFT架构实现了精细的身份管理和隐私交互。特别值得注意的是，它在Layer 2上的实现显著降低了Gas成本，解决了区块链应用中常见的扩展性问题。去中心化KYC和灵魂绑定代币的使用也增强了系统的安全性和抗攻击能力。其惩罚性治理机制（有条件身份披露）为去中心化环境中的行为规范提供了一种新颖的解决方案。"}}
{"id": "2507.22933", "title": "Augmented Vision-Language Models: A Systematic Review", "authors": ["Anthony C Davis", "Burhan Sadiq", "Tianmin Shu", "Chien-Ming Huang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22933v1", "summary": "Recent advances in visual-language machine learning models have demonstrated\nexceptional ability to use natural language and understand visual scenes by\ntraining on large, unstructured datasets. However, this training paradigm\ncannot produce interpretable explanations for its outputs, requires retraining\nto integrate new information, is highly resource-intensive, and struggles with\ncertain forms of logical reasoning. One promising solution involves integrating\nneural networks with external symbolic information systems, forming neural\nsymbolic systems that can enhance reasoning and memory abilities. These neural\nsymbolic systems provide more interpretable explanations to their outputs and\nthe capacity to assimilate new information without extensive retraining.\nUtilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural\ncomponent, augmented by external systems, offers a pragmatic approach to\nrealizing the benefits of neural-symbolic integration. This systematic\nliterature review aims to categorize techniques through which visual-language\nunderstanding can be improved by interacting with external symbolic information\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22933v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "增强型视觉-语言模型：一项系统综述", "tldr": "本系统综述旨在分类通过与外部符号信息系统交互来增强视觉-语言理解的技术，以解决当前大型视觉-语言模型在可解释性、新信息整合、资源消耗和逻辑推理方面的局限性。", "motivation": "当前视觉-语言模型在处理大型非结构化数据集时表现出色，但存在无法提供可解释性、需要大量资源进行再训练以整合新信息以及在逻辑推理方面表现不佳的局限性。", "method": "本文进行了一项系统文献综述，旨在对通过与外部符号信息系统交互来提高视觉-语言理解的技术进行分类。其核心方法是利用强大的预训练视觉-语言模型作为神经核心组件，并辅以外部系统实现神经-符号集成。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "视觉-语言机器学习模型的最新进展在通过大型非结构化数据集训练后，展示了使用自然语言和理解视觉场景的卓越能力。然而，这种训练范式无法为其输出提供可解释的解释，需要重新训练以整合新信息，资源密集度高，并且在某些形式的逻辑推理方面存在困难。一个有前景的解决方案是将神经网络与外部符号信息系统集成，形成可以增强推理和记忆能力的神经符号系统。这些神经符号系统为其输出提供了更可解释的解释，并能够在不进行大量再训练的情况下吸收新信息。利用强大的预训练视觉-语言模型（VLM）作为核心神经组件，并由外部系统增强，为实现神经-符号集成的优势提供了一种实用方法。本系统文献综述旨在对通过与外部符号信息系统交互来提高视觉-语言理解的技术进行分类。", "summary": "本文是一项系统综述，探讨了增强型视觉-语言模型（Augmented VLMs）。现有的大型视觉-语言模型虽然功能强大，但在可解释性、新知识整合、资源效率和逻辑推理方面存在不足。为解决这些问题，研究提出了一种有前景的方案：将神经网络与外部符号信息系统结合，形成神经-符号系统。这种方法能够提供更易解释的输出，并允许在不进行大量再训练的情况下整合新信息。本综述旨在对利用预训练视觉-语言模型作为核心，并通过与外部符号系统交互来提升视觉-语言理解的各类技术进行分类。", "keywords": "视觉-语言模型, 神经-符号系统, 系统综述, 可解释性, 符号信息系统", "comments": "该论文通过系统综述的方式，聚焦于解决当前视觉-语言模型（VLMs）在可解释性、新信息整合和逻辑推理等方面的核心痛点，指出了神经-符号集成作为一种有前景的解决方案。其创新点在于强调了利用现有强大VLM作为基础，并通过外部符号系统进行增强的实用性方法。这篇综述对于推动VLM领域向更透明、更高效和更具推理能力的方向发展具有重要意义。"}}
{"id": "2507.22904", "title": "SketchMind: A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches", "authors": ["Ehsan Latif", "Zirak Khan", "Xiaoming Zhai"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Submitted to NeurIPS2025", "url": "http://arxiv.org/abs/2507.22904v1", "summary": "Scientific sketches (e.g., models) offer a powerful lens into students'\nconceptual understanding, yet AI-powered automated assessment of such\nfree-form, visually diverse artifacts remains a critical challenge. Existing\nsolutions often treat sketch evaluation as either an image classification task\nor monolithic vision-language models, which lack interpretability, pedagogical\nalignment, and adaptability across cognitive levels. To address these\nlimitations, we present SketchMind, a cognitively grounded, multi-agent\nframework for evaluating and improving student-drawn scientific sketches.\nSketchMind comprises modular agents responsible for rubric parsing, sketch\nperception, cognitive alignment, and iterative feedback with sketch\nmodification, enabling personalized and transparent evaluation. We evaluate\nSketchMind on a curated dataset of 3,575 student-generated sketches across six\nscience assessment items with different highest order of Bloom's level that\nrequire students to draw models to explain phenomena. Compared to baseline\nGPT-4o performance without SRG (average accuracy: 55.6%), and with SRG\nintegration achieves 77.1% average accuracy (+21.4% average absolute gain). We\nalso demonstrate that multi-agent orchestration with SRG enhances SketchMind\nperformance, for example, GPT-4.1 gains an average 8.9% increase in sketch\nprediction accuracy, outperforming single-agent pipelines across all items.\nHuman evaluators rated the feedback and co-created sketches generated by\n\\textsc{SketchMind} with GPT-4.1, which achieved an average of 4.1 out of 5,\nsignificantly higher than those of baseline models (e.g., 2.3 for GPT-4o).\nExperts noted the system's potential to meaningfully support conceptual growth\nthrough guided revision. Our code and (pending approval) dataset will be\nreleased to support reproducibility and future research in AI-driven education.", "comment": "Submitted to NeurIPS2025", "pdf_url": "http://arxiv.org/pdf/2507.22904v1", "cate": "cs.HC", "date": "2025-06-29", "updated": "2025-06-29", "AI": {"title_translation": "SketchMind：一种评估学生科学素描的多智能体认知框架", "tldr": "SketchMind是一个多智能体认知框架，用于评估和改进学生绘制的科学素描，通过模块化代理实现个性化和透明的评估，并在准确性和反馈质量方面优于现有基线模型。", "motivation": "现有的人工智能驱动的自由形式、视觉多样化科学素描自动化评估解决方案缺乏可解释性、教学一致性和跨认知水平的适应性，且通常将素描评估视为图像分类任务或单一视觉-语言模型。", "method": "SketchMind是一个基于认知的多智能体框架，包含负责评分标准解析、素描感知、认知对齐和通过素描修改进行迭代反馈的模块化代理。该框架在包含3,575幅学生绘制的科学素描数据集上进行了评估，这些素描涵盖了六个不同布鲁姆认知水平的科学评估项目。", "result": "与不集成SRG的基线GPT-4o性能（平均准确率：55.6%）相比，集成SRG后平均准确率达到77.1%（绝对增益+21.4%）。多智能体编排与SRG结合可提高SketchMind性能，例如，GPT-4.1在素描预测准确率上平均提高了8.9%，超越了所有项目中的单智能体管道。人类评估者对SketchMind与GPT-4.1生成的反馈和共同创建的素描平均评分为4.1/5，显著高于基线模型（例如GPT-4o的2.3）。", "conclusion": "SketchMind框架通过其多智能体认知方法，显著提高了学生科学素描的自动化评估准确性和反馈质量，并被专家认为具有通过引导式修改支持概念成长的潜力。", "translation": "科学素描（例如模型）为洞察学生的概念理解提供了有力的视角，然而，对这种自由形式、视觉多样化的人工制品进行人工智能驱动的自动化评估仍然是一个严峻的挑战。现有解决方案通常将素描评估视为图像分类任务或单一的视觉-语言模型，这缺乏可解释性、教学一致性和跨认知水平的适应性。为了解决这些局限性，我们提出了SketchMind，一个基于认知的多智能体框架，用于评估和改进学生绘制的科学素描。SketchMind包含负责评分标准解析、素描感知、认知对齐和通过素描修改进行迭代反馈的模块化代理，从而实现个性化和透明的评估。我们在一个包含3,575幅学生绘制的素描的精选数据集上评估了SketchMind，这些素描涵盖了六个不同的科学评估项目，这些项目具有不同的布鲁姆认知最高阶水平，要求学生绘制模型来解释现象。与不集成SRG的基线GPT-4o性能（平均准确率：55.6%）相比，集成SRG后实现了77.1%的平均准确率（平均绝对增益+21.4%）。我们还证明，多智能体编排与SRG结合可增强SketchMind性能，例如，GPT-4.1在素描预测准确率上平均提高了8.9%，超越了所有项目中的单智能体管道。人类评估者对SketchMind与GPT-4.1生成的反馈和共同创建的素描平均评分为4.1分（满分5分），显著高于基线模型（例如GPT-4o的2.3分）。专家指出该系统通过引导式修改有意义地支持概念增长的潜力。我们的代码和（待批准的）数据集将发布，以支持人工智能驱动教育领域的可复现性和未来研究。", "summary": "本研究提出了SketchMind，一个多智能体认知框架，旨在解决现有AI驱动的科学素描评估方案在可解释性、教学一致性和适应性方面的不足。SketchMind包含模块化代理，负责评分标准解析、素描感知、认知对齐和迭代反馈。在包含3,575幅学生素描的数据集上，SketchMind在评估准确性上显著优于GPT-4o等基线模型，并能生成高质量的反馈和共同创建的素描，被专家认为对学生概念成长有积极作用。", "keywords": "科学素描评估, 多智能体系统, 认知框架, 自动化评估, 学生理解", "comments": "SketchMind的创新之处在于其采用的多智能体认知框架，这使得评估过程更具解释性、教学一致性和适应性，克服了传统单一模型或图像分类方法的局限性。通过将评估分解为多个认知模块，它能够提供更精细、个性化的反馈，这对于学生概念理解的深化至关重要。其在准确性和反馈质量上的显著提升，以及专家对其支持概念成长的认可，凸显了该系统在AI教育领域的潜在重要性。"}}
{"id": "2507.22964", "title": "Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR", "authors": ["Sotheara Leang", "Éric Castelli", "Dominique Vaufreydaz", "Sethserey Sam"], "categories": ["eess.AS", "cs.CL", "cs.SD", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22964v1", "summary": "The dynamic characteristics of speech signal provides temporal information\nand play an important role in enhancing Automatic Speech Recognition (ASR). In\nthis work, we characterized the acoustic transitions in a ratio plane of\nSpectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture\nthe dynamic characteristics of the speech and minimize spectral variation.\nThese dynamic parameters were combined with Mel-Frequency Cepstral Coefficients\n(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The\nSSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to\ndescribe the tonal information robustly. The findings showed that the proposed\nparameters significantly reduce word error rates and exhibit greater gender\nindependence than the baseline MFCCs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22964v1", "cate": "eess.AS", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "探索越南语性别独立ASR的动态参数", "tldr": "本文提出并评估了基于SSCF和极坐标参数的新型动态特征，用于提高越南语性别独立语音识别性能。", "motivation": "语音信号的动态特性提供了时间信息，并在增强自动语音识别（ASR）中发挥重要作用。", "method": "本文利用光谱子带质心频率（SSCFs）比率平面中的极坐标参数来表征声学转换，以捕获语音的动态特性并最小化频谱变化。这些动态参数与梅尔频率倒谱系数（MFCCs）结合应用于越南语ASR，并使用SSCF0作为基频（F0）的伪特征来鲁棒地描述音调信息。", "result": "提出的参数显著降低了词错误率，并比基线MFCCs表现出更大的性别独立性。", "conclusion": "提出的动态参数能有效提高越南语ASR的性能，尤其是在性别独立性方面优于传统MFCCs。", "translation": "语音信号的动态特性提供了时间信息，并在增强自动语音识别（ASR）中发挥重要作用。在这项工作中，我们使用极坐标参数在频谱子带质心频率（SSCFs）的比率平面中表征了声学转换，以捕获语音的动态特性并最小化频谱变化。这些动态参数与梅尔频率倒谱系数（MFCCs）结合应用于越南语ASR，以捕获更详细的频谱信息。SSCF0被用作基频（F0）的伪特征，以稳健地描述音调信息。研究结果表明，所提出的参数显著降低了词错误率，并比基线MFCCs表现出更大的性别独立性。", "summary": "本文探索了新的动态参数以提高越南语性别独立自动语音识别（ASR）的性能。研究人员利用光谱子带质心频率（SSCFs）和极坐标参数来捕捉语音的动态特性，并结合梅尔频率倒谱系数（MFCCs）使用。特别地，SSCF0被用作基频的伪特征以描述音调信息。实验结果表明，与基线MFCCs相比，所提出的参数能显著降低词错误率并展现出更强的性别独立性。", "keywords": "动态参数, 语音识别, 性别独立, SSCFs, 越南语ASR", "comments": "这篇论文的创新点在于提出了基于SSCFs和极坐标参数的新型动态特征，并将其应用于越南语ASR，特别是解决了性别独立性问题。将SSCF0作为基频的伪特征来处理音调信息，也为处理声调语言提供了一种鲁棒的方法。"}}
{"id": "2507.23601", "title": "Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection", "authors": ["Xin Li", "Keren Fu", "Qijun Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 11 figures", "url": "http://arxiv.org/abs/2507.23601v1", "summary": "Existing video camouflaged object detection (VCOD) methods primarily rely on\nspatial appearance features to perceive motion cues for breaking camouflage.\nHowever, the high similarity between foreground and background in VCOD results\nin limited discriminability of spatial appearance features (e.g., color and\ntexture), restricting detection accuracy and completeness. Recent studies\ndemonstrate that frequency features can not only enhance feature representation\nto compensate for appearance limitations but also perceive motion through\ndynamic variations in frequency energy. Furthermore, the emerging state space\nmodel called Mamba, enables efficient perception of motion cues in frame\nsequences due to its linear-time long-sequence modeling capability. Motivated\nby this, we propose a novel visual camouflage Mamba (Vcamba) based on\nspatio-frequency motion perception that integrates frequency and spatial\nfeatures for efficient and accurate VCOD. Specifically, we propose a receptive\nfield visual state space (RFVSS) module to extract multi-scale spatial features\nafter sequence modeling. For frequency learning, we introduce an adaptive\nfrequency component enhancement (AFE) module with a novel frequency-domain\nsequential scanning strategy to maintain semantic consistency. Then we propose\na space-based long-range motion perception (SLMP) module and a frequency-based\nlong-range motion perception (FLMP) module to model spatio-temporal and\nfrequency-temporal sequences in spatial and frequency phase domains. Finally,\nthe space and frequency motion fusion module (SFMF) integrates dual-domain\nfeatures for unified motion representation. Experimental results show that our\nVcamba outperforms state-of-the-art methods across 6 evaluation metrics on 2\ndatasets with lower computation cost, confirming the superiority of Vcamba. Our\ncode is available at: https://github.com/BoydeLi/Vcamba.", "comment": "11 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.23601v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于Mamba的高效时空-频率运动感知视频伪装目标检测", "tldr": "本文提出Vcamba，一个基于Mamba的模型，结合时空和频率特征，用于高效准确的视频伪装目标检测，性能优于现有SOTA方法。", "motivation": "现有视频伪装目标检测（VCOD）方法主要依赖空间外观特征感知运动线索，但前景和背景的高度相似性导致空间外观特征（如颜色和纹理）的可区分性有限，从而限制了检测的准确性和完整性。最近研究表明，频率特征不仅能增强特征表示以弥补外观限制，还能通过频率能量的动态变化感知运动。此外，新兴的状态空间模型Mamba能高效感知帧序列中的运动线索，因为它具有线性时间长序列建模能力。", "method": "本文提出了一种基于时空-频率运动感知的新型视觉伪装Mamba（Vcamba），它整合了频率和空间特征，用于高效准确的VCOD。具体来说，提出了感受野视觉状态空间（RFVSS）模块，用于序列建模后提取多尺度空间特征。对于频率学习，引入了自适应频率分量增强（AFE）模块，采用新颖的频域顺序扫描策略来保持语义一致性。接着，提出了基于空间的远程运动感知（SLMP）模块和基于频率的远程运动感知（FLMP）模块，分别在空间和频率相位域建模时空和频率-时间序列。最后，空间和频率运动融合（SFMF）模块整合双域特征以实现统一的运动表示。", "result": "实验结果表明，Vcamba在2个数据集上的6项评估指标上均优于最先进的方法，且计算成本更低，证实了Vcamba的优越性。", "conclusion": "Vcamba通过整合基于Mamba的时空-频率运动感知，实现了卓越且更高效的视频伪装目标检测。", "translation": "现有视频伪装目标检测（VCOD）方法主要依靠空间外观特征来感知运动线索以打破伪装。然而，VCOD中前景与背景之间的高度相似性导致空间外观特征（例如颜色和纹理）的可区分性有限，从而限制了检测的准确性和完整性。最近的研究表明，频率特征不仅可以增强特征表示以弥补外观限制，还可以通过频率能量的动态变化感知运动。此外，新兴的状态空间模型Mamba，由于其线性时间长序列建模能力，能够高效感知帧序列中的运动线索。受此启发，我们提出了一种基于时空-频率运动感知的新型视觉伪装Mamba（Vcamba），它整合了频率和空间特征，用于高效准确的VCOD。具体来说，我们提出了一种感受野视觉状态空间（RFVSS）模块，用于在序列建模后提取多尺度空间特征。对于频率学习，我们引入了一个自适应频率分量增强（AFE）模块，该模块采用了一种新颖的频域顺序扫描策略来保持语义一致性。然后，我们提出了一个基于空间的远程运动感知（SLMP）模块和一个基于频率的远程运动感知（FLMP）模块，用于在空间和频率相位域中建模时空和频率-时间序列。最后，空间和频率运动融合（SFMF）模块整合双域特征以实现统一的运动表示。实验结果表明，我们的Vcamba在2个数据集上的6项评估指标上均优于最先进的方法，且计算成本更低，证实了Vcamba的优越性。我们的代码可在以下网址获取：https://github.com/BoydeLi/Vcamba。", "summary": "本文提出Vcamba，一个基于Mamba的新型视频伪装目标检测（VCOD）模型，旨在解决现有方法仅依赖空间特征的局限性。Vcamba结合了空间和频率特征，并利用Mamba模型的高效长序列建模能力进行运动感知。其核心模块包括用于多尺度空间特征提取的RFVSS，用于频率学习和语义一致性的AFE，以及分别用于空间和频率域中远程运动感知的SLMP和FLMP，最终通过SFMF模块融合双域特征。实验证明，Vcamba在多个评估指标和数据集上均超越了现有最先进方法，且计算成本更低，展现出卓越的性能和效率。", "keywords": "视频伪装目标检测, Mamba, 时空-频率, 运动感知, 状态空间模型", "comments": "本文的创新点在于将Mamba模型的高效序列建模能力与时空-频率特征相结合，以应对视频伪装目标检测中前景与背景高度相似的挑战。所提出的双域运动感知和融合方法显示出其鲁棒性。此外，其在降低计算成本的同时提高检测性能，是该研究的一个显著优势。"}}
{"id": "2507.17186", "title": "FinGAIA: A Chinese Benchmark for AI Agents in Real-World Financial Domain", "authors": ["Lingfeng Zeng", "Fangqi Lou", "Zixuan Wang", "Jiajie Xu", "Jinyi Niu", "Mengping Li", "Yifan Dong", "Qi Qi", "Wei Zhang", "Ziwei Yang", "Jun Han", "Ruilun Feng", "Ruiqi Hu", "Lejie Zhang", "Zhengbo Feng", "Yicheng Ren", "Xin Guo", "Zhaowei Liu", "Dongpo Cheng", "Weige Cai", "Liwen Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17186v2", "summary": "The booming development of AI agents presents unprecedented opportunities for\nautomating complex tasks across various domains. However, their multi-step,\nmulti-tool collaboration capabilities in the financial sector remain\nunderexplored. This paper introduces FinGAIA, an end-to-end benchmark designed\nto evaluate the practical abilities of AI agents in the financial domain.\nFinGAIA comprises 407 meticulously crafted tasks, spanning seven major\nfinancial sub-domains: securities, funds, banking, insurance, futures, trusts,\nand asset management. These tasks are organized into three hierarchical levels\nof scenario depth: basic business analysis, asset decision support, and\nstrategic risk management. We evaluated 10 mainstream AI agents in a zero-shot\nsetting. The best-performing agent, ChatGPT, achieved an overall accuracy of\n48.9\\%, which, while superior to non-professionals, still lags financial\nexperts by over 35 percentage points. Error analysis has revealed five\nrecurring failure patterns: Cross-modal Alignment Deficiency, Financial\nTerminological Bias, Operational Process Awareness Barrier, among others. These\npatterns point to crucial directions for future research. Our work provides the\nfirst agent benchmark closely related to the financial domain, aiming to\nobjectively assess and promote the development of agents in this crucial field.\nPartial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17186v2", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-31", "AI": {"title_translation": "FinGAIA：一个面向真实世界金融领域AI智能体的中文基准", "tldr": "AI智能体在金融领域的多步骤、多工具协作能力尚未充分探索。本文介绍了FinGAIA，一个包含407个任务、涵盖7个金融子领域和3个场景深度的端到端基准，旨在评估AI智能体在金融领域的实际能力。评估结果显示，表现最佳的ChatGPT准确率为48.9%，远低于金融专家，且错误分析揭示了多种失败模式，为未来研究指明了方向。", "motivation": "尽管AI智能体在自动化复杂任务方面潜力巨大，但它们在金融领域的多步骤、多工具协作能力仍未得到充分探索。因此，需要一个端到端的基准来评估AI智能体在金融领域的实际能力。", "method": "本文引入了FinGAIA，一个端到端基准，包含407个任务，涵盖证券、基金、银行、保险、期货、信托和资产管理七个主要金融子领域。这些任务按场景深度分为基本业务分析、资产决策支持和战略风险管理三个层次。研究团队在零样本设置下评估了10个主流AI智能体，并进行了错误分析以识别失败模式。", "result": "在零样本设置下，表现最好的AI智能体（ChatGPT）的整体准确率为48.9%。尽管这一成绩优于非专业人士，但仍比金融专家低35个百分点以上。错误分析揭示了五种常见的失败模式，包括跨模态对齐缺陷、金融术语偏差和操作流程意识障碍等。", "conclusion": "本文提供了第一个与金融领域密切相关的AI智能体基准，旨在客观评估和促进智能体在该关键领域的发展。所识别出的失败模式为未来的研究指明了关键方向。", "translation": "AI智能体蓬勃发展为自动化各种复杂任务带来了前所未有的机遇。然而，它们在金融领域的多步骤、多工具协作能力仍未得到充分探索。本文介绍了FinGAIA，一个旨在评估AI智能体在金融领域实际能力的端到端基准。FinGAIA包含407个精心设计的任务，涵盖证券、基金、银行、保险、期货、信托和资产管理七个主要金融子领域。这些任务按场景深度分为三个层次：基本业务分析、资产决策支持和战略风险管理。我们在零样本设置下评估了10个主流AI智能体。表现最好的智能体ChatGPT的整体准确率为48.9%，虽然优于非专业人士，但仍比金融专家低35个百分点以上。错误分析揭示了五种常见的失败模式：跨模态对齐缺陷、金融术语偏差、操作流程意识障碍等。这些模式为未来的研究指明了关键方向。我们的工作提供了第一个与金融领域密切相关的智能体基准，旨在客观评估和促进智能体在这个关键领域的发展。部分数据可在https://github.com/SUFE-AIFLM-Lab/FinGAIA获取。", "summary": "本文推出了FinGAIA，一个评估AI智能体在真实世界金融领域实际能力的端到端基准。该基准包含407个任务，覆盖证券、基金等七大金融子领域及三个场景深度层次。在零样本评估中，表现最佳的ChatGPT准确率为48.9%，与金融专家存在显著差距。错误分析揭示了跨模态对齐缺陷、金融术语偏差等常见失败模式，为未来金融AI智能体研究提供了重要方向。这项工作是首个金融领域智能体基准，旨在推动该领域的发展。", "keywords": "AI智能体, 金融领域, 基准, FinGAIA, 评估", "comments": "该论文通过创建首个专注于真实世界金融领域的AI智能体基准，填补了AI智能体评估的一个重要空白。基准的全面设计，涵盖多个子领域和分层任务深度，提供了一个强大的评估框架。定量结果清晰地表明了当前即使是先进AI智能体（如ChatGPT）在金融任务中的局限性，突显了当前AI能力与人类专家表现之间的差距。对具体失败模式的识别尤其富有洞察力，为未来改进金融AI智能体提供了具体的研发方向。"}}
{"id": "2408.05997", "title": "On the Formalization of Cryptographic Migration", "authors": ["Daniel Loebenberger", "Stefan-Lukas Gazdag", "Daniel Herzinger", "Eduard Hirsch", "Christian Näther", "Jan-Philipp Steghöfer"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.05997v4", "summary": "We present a novel approach to gaining insight into the structure of\ncryptographic migration problems which are classic problems in applied\ncryptography. We use a formal model to capture the inherent dependencies and\ncomplexities of such transitions. Using classical mathematical results from\ncombinatorics, probability theory, and combinatorial analysis, we evaluate the\nchallenges of migrating large cryptographic IT infrastructures and prove that -\nin a suitable sense - cryptographic migration exhibits a certain expected\ncomplexity. We also provide numerical data for selected parameter sets.\nFurthermore, we analyze the proposed model in terms of real-world patterns and\nits practical applicability. Additionally, we discuss the challenges of\nmodeling real-world migration projects. As concrete examples we examine the\ntransition to post-quantum cryptography of the CI/CD system GitLab and the\nmulti-level technological transition of distribution power grids. This work\npaves the way for future advancements in both the theoretical understanding and\npractical implementation of cryptographic migration strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.05997v4", "cate": "cs.CR", "date": "2024-08-12", "updated": "2025-07-31", "AI": {"title_translation": "关于密码迁移的形式化研究", "tldr": "本文提出了一种形式化方法来深入理解密码迁移问题的结构，利用组合学、概率论和组合分析等数学工具评估其复杂性，并提供了数值数据和实际案例分析，为未来的理论和实践奠定基础。", "motivation": "旨在深入了解密码迁移问题的结构，这类问题是应用密码学中的经典问题，并希望通过形式化模型捕捉此类转换固有的依赖性和复杂性。", "method": "采用形式化模型捕捉密码迁移的固有依赖性和复杂性。利用组合学、概率论和组合分析等经典数学结果，评估大规模密码IT基础设施迁移的挑战，并证明了密码迁移在特定意义上表现出预期的复杂性。同时，提供了选定参数集的数值数据，并分析了该模型在实际模式和实际适用性方面的表现。此外，还讨论了建模实际迁移项目的挑战，并以GitLab的后量子密码学过渡和配电网的多级技术过渡作为具体示例。", "result": "研究证明，在适当的意义上，密码迁移表现出一定的预期复杂性。为选定的参数集提供了数值数据。分析了所提出的模型在现实世界模式及其实际适用性方面的表现。", "conclusion": "这项工作为未来在密码迁移策略的理论理解和实际实施方面取得进展铺平了道路。", "translation": "我们提出了一种新颖的方法，以深入了解密码迁移问题的结构，这些问题是应用密码学中的经典问题。我们使用一个形式化模型来捕捉此类转换固有的依赖性和复杂性。利用组合学、概率论和组合分析等经典数学结果，我们评估了迁移大型密码IT基础设施的挑战，并证明——在适当的意义上——密码迁移表现出一定的预期复杂性。我们还为选定的参数集提供了数值数据。此外，我们根据现实世界模式及其实际适用性分析了所提出的模型。此外，我们讨论了建模现实世界迁移项目的挑战。作为具体示例，我们考察了CI/CD系统GitLab向后量子密码学的过渡以及配电网的多级技术过渡。这项工作为未来在密码迁移策略的理论理解和实际实施方面取得进展铺平了道路。", "summary": "本文提出了一种新颖的形式化方法来分析密码迁移问题，通过构建数学模型捕捉其内在依赖性和复杂性。研究利用组合学和概率论等数学工具，评估了大规模加密IT基础设施迁移的挑战，并证明了密码迁移具有可预期的复杂性，同时提供了数值数据。论文还结合实际案例（如GitLab的后量子加密过渡和电网升级）分析了模型的实用性，旨在为密码迁移的理论研究与实际应用提供基础。", "keywords": "密码迁移, 形式化, 复杂性, 组合学, 后量子密码学", "comments": "本文的创新之处在于将形式化的数学模型应用于复杂的实际密码迁移问题，为理解其固有复杂性提供了一个结构化的框架。通过结合组合学和概率论等经典数学工具，作者不仅提供了理论证明，还通过数值数据和现实世界案例（如GitLab的后量子密码迁移）增强了研究的实用性和可信度，为未来密码迁移策略的理论和实践进步奠定了基础。"}}
{"id": "2507.23698", "title": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents", "authors": ["Shaofei Cai", "Zhancun Mu", "Haiwen Xia", "Bowei Zhang", "Anji Liu", "Yitao Liang"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23698v1", "summary": "While Reinforcement Learning (RL) has achieved remarkable success in language\nmodeling, its triumph hasn't yet fully translated to visuomotor agents. A\nprimary challenge in RL models is their tendency to overfit specific tasks or\nenvironments, thereby hindering the acquisition of generalizable behaviors\nacross diverse settings. This paper provides a preliminary answer to this\nchallenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can\nachieve zero-shot generalization to unseen worlds. Specifically, we explore\nRL's potential to enhance generalizable spatial reasoning and interaction\ncapabilities in 3D worlds. To address challenges in multi-task RL\nrepresentation, we analyze and establish cross-view goal specification as a\nunified multi-task goal space for visuomotor policies. Furthermore, to overcome\nthe significant bottleneck of manual task design, we propose automated task\nsynthesis within the highly customizable Minecraft environment for large-scale\nmulti-task RL training, and we construct an efficient distributed RL framework\nto support this. Experimental results show RL significantly boosts interaction\nsuccess rates by $4\\times$ and enables zero-shot generalization of spatial\nreasoning across diverse environments, including real-world settings. Our\nfindings underscore the immense potential of RL training in 3D simulated\nenvironments, especially those amenable to large-scale task generation, for\nsignificantly advancing visuomotor agents' spatial reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23698v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于视觉运动智能体的可扩展多任务强化学习，实现通用空间智能", "tldr": "本文通过在Minecraft中对RL微调的视觉运动智能体进行大规模多任务训练，实现了对未见世界的零样本泛化，显著提升了空间推理能力。", "motivation": "强化学习（RL）在语言建模方面取得了显著成功，但在视觉运动智能体方面尚未完全实现。主要挑战在于RL模型容易过拟合特定任务或环境，阻碍了在多样化设置中获得通用行为。", "method": "本文通过以下方法解决挑战：1. 探索RL增强3D世界中通用空间推理和交互能力。2. 确立跨视角目标规范作为统一的多任务目标空间。3. 提出在Minecraft环境中自动化任务合成，用于大规模多任务RL训练。4. 构建高效的分布式RL框架支持训练。", "result": "实验结果表明，RL显著提升了交互成功率4倍，并实现了空间推理在多样化环境（包括真实世界）中的零样本泛化。", "conclusion": "研究结果强调了在3D模拟环境（特别是那些适合大规模任务生成的环境）中进行RL训练的巨大潜力，可以显著提升视觉运动智能体的空间推理能力。", "translation": "虽然强化学习（RL）在语言建模方面取得了显著成功，但其胜利尚未完全转化为视觉运动智能体。RL模型面临的一个主要挑战是它们倾向于过拟合特定任务或环境，从而阻碍了在多样化设置中获取通用行为。本文通过证明在Minecraft中经过RL微调的视觉运动智能体可以实现对未见世界的零样本泛化，为这一挑战提供了一个初步答案。具体来说，我们探索了RL增强3D世界中通用空间推理和交互能力的潜力。为了解决多任务RL表示中的挑战，我们分析并建立了跨视角目标规范作为视觉运动策略的统一多任务目标空间。此外，为了克服手动任务设计的显著瓶颈，我们提出在高度可定制的Minecraft环境中自动化任务合成，用于大规模多任务RL训练，并构建了一个高效的分布式RL框架来支持这一点。实验结果表明，RL显著提升了交互成功率4倍，并实现了空间推理在多样化环境（包括真实世界设置）中的零样本泛化。我们的发现强调了在3D模拟环境，特别是那些适合大规模任务生成的环境中进行RL训练的巨大潜力，可以显著推进视觉运动智能体的空间推理。", "summary": "本研究旨在解决强化学习模型在视觉运动智能体中泛化能力不足的问题。作者通过在Minecraft环境中进行大规模多任务RL训练，并提出跨视角目标规范作为统一目标空间以及自动化任务合成方法，成功使RL微调的视觉运动智能体实现了对未知环境的零样本泛化。实验结果显示，RL显著提高了交互成功率，并增强了空间推理的泛化能力，证明了在可大规模生成任务的3D模拟环境中进行RL训练对于提升视觉运动智能体空间智能的巨大潜力。", "keywords": "强化学习, 视觉运动智能体, 零样本泛化, 多任务学习, Minecraft", "comments": "这篇论文的创新点在于提出了在高度可定制的Minecraft环境中进行自动化任务合成，解决了手动任务设计的瓶颈，从而支持大规模多任务RL训练。同时，引入跨视角目标规范作为统一的多任务目标空间，有助于提升模型的泛化能力。其在零样本泛化方面的成功，尤其是在真实世界环境中的表现，展示了将RL应用于复杂3D视觉运动任务的巨大潜力。"}}
{"id": "2501.02184", "title": "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments", "authors": ["Ahmed A. Elgohary", "Sameh A. Eisa", "Shivam Bajpai"], "categories": ["cs.RO", "math.OC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.02184v4", "summary": "Many autonomous robots aimed at source-seeking are studied, and their\ncontrols designed, using unicycle modeling and formulation. This is true not\nonly for model-based controllers, but also for model-free, real-time control\nmethods such as extremum seeking control (ESC). In this paper, we propose a\nunicycle-based ESC design applicable to differential wheeled robots that: (1)\nis very simple design, based on one simple control-affine law, and without\nstate integrators; (2) attenuates oscillations known to persist in ESC designs\n(i.e., fully stop at the source); and (3) operates in a model-free, real-time\nsetting, tolerating environmental/sensor noise. We provide simulation and\nreal-world robotic experimental results for fixed and moving light source\nseeking by a differential wheeled robot using our proposed design. Results\nindicate clear advantages of our proposed design when compared to the\nliterature, including attenuation of undesired oscillations, improved\nconvergence speed, and better handling of noise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.02184v4", "cate": "cs.RO", "date": "2025-01-04", "updated": "2025-07-31", "AI": {"title_translation": "无模型实时单轮车式寻源与差分轮式机器人实验", "tldr": "提出一种简单、无模型、实时且能抑制振荡的单轮车式极值寻优控制（ESC）设计，用于差分轮式机器人寻源，并在实验中表现出优越性。", "motivation": "许多自主寻源机器人使用单轮车模型，但现有的无模型、实时控制方法（如极值寻优控制ESC）存在持续振荡的问题，需要一种更有效的设计来克服这些限制并提高性能。", "method": "提出了一种基于单轮车模型的极值寻优控制（ESC）设计，适用于差分轮式机器人。该设计特点包括：基于简单的控制仿射律，无状态积分器，能衰减ESC中常见的持续振荡（使机器人完全停在源头），并且在无模型、实时设置下运行，能容忍环境/传感器噪声。", "result": "模拟和实际机器人实验结果表明，与现有文献相比，所提出的设计具有明显优势，包括抑制了不期望的振荡、提高了收敛速度以及更好地处理了噪声。", "conclusion": "该论文成功提出了一种新颖的单轮车式极值寻优控制设计，有效解决了传统ESC设计中存在的振荡问题，并在无模型、实时环境下展现出优越的寻源性能和对噪声的鲁棒性，为差分轮式机器人的自主寻源提供了更可靠的解决方案。", "translation": "许多旨在寻源的自主机器人都在使用单轮车建模和公式化进行研究和控制设计。这不仅适用于基于模型的控制器，也适用于无模型、实时的控制方法，例如极值寻优控制（ESC）。在本文中，我们提出了一种适用于差分轮式机器人的基于单轮车的ESC设计，该设计具有以下特点：（1）设计非常简单，基于一个简单的控制仿射律，且没有状态积分器；（2）衰减了已知在ESC设计中持续存在的振荡（即在源头完全停止）；（3）在无模型、实时环境下运行，能容忍环境/传感器噪声。我们提供了使用我们提出的设计进行固定和移动光源寻源的差分轮式机器人的仿真和真实机器人实验结果。结果表明，与现有文献相比，我们提出的设计具有明显的优势，包括抑制了不期望的振荡、提高了收敛速度以及更好地处理了噪声。", "summary": "本文提出了一种新颖的、基于单轮车模型的极值寻优控制（ESC）设计，专为差分轮式机器人寻源任务而优化。该设计特点是结构简单、无状态积分器、能够有效抑制传统ESC中常见的持续振荡（使机器人完全停在源头），并能在无模型、实时且存在噪声的环境中稳定运行。通过仿真和真实机器人实验，验证了该设计在固定和移动光源寻源方面的优越性，包括更快的收敛速度、更强的噪声处理能力以及显著减少了不期望的振荡。", "keywords": "极值寻优控制, 差分轮式机器人, 无模型控制, 实时寻源, 振荡衰减", "comments": "这篇论文的创新点在于提出了一种改进的极值寻优控制方法，专门解决了传统ESC在机器人寻源中常见的持续振荡问题，实现了在源头完全停止。其无模型、实时和对噪声的鲁棒性使其在实际应用中具有较高的价值。简单化的控制律设计也降低了实现复杂性。"}}
{"id": "2507.23402", "title": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "authors": ["Wei Li", "Xun Gong", "Jiao Li", "Xiaobin Sun"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23402v1", "summary": "Learning medical visual representations from paired images and reports is a\npromising direction in representation learning. However, current\nvision-language pretraining methods in the medical domain often simplify\nclinical reports into single entities or fragmented tokens, ignoring their\ninherent structure. In addition, contrastive learning frameworks typically\ndepend on large quantities of hard negative samples, which is impractical for\nsmall-scale medical datasets. To tackle these challenges, we propose Adaptive\nGrouped Alignment (AGA), a new framework that captures structured semantics\nfrom paired medical images and reports. AGA introduces a bidirectional grouping\nmechanism based on a sparse similarity matrix. For each image-report pair, we\ncompute fine-grained similarities between text tokens and image patches. Each\ntoken selects its top-matching patches to form a visual group, and each patch\nselects its most related tokens to form a language group. To enable adaptive\ngrouping, we design two threshold gating modules, called Language Grouped\nThreshold Gate and Vision Grouped Threshold Gate, which learn grouping\nthresholds dynamically. Group representations are computed as weighted averages\nbased on similarity scores. To align each token with its group representation,\nwe introduce an Instance Aware Group Alignment loss that operates within each\nimage-text pair, removing the need for external negatives. Finally, a\nBidirectional Cross-modal Grouped Alignment module is applied to enhance\nfine-grained alignment between visual and linguistic group representations.\nExtensive experiments on public and private datasets show that our method\nachieves strong performance on image-text retrieval and classification tasks\nunder both fine-tuning and zero-shot settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23402v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "AGA：一种用于结构化医学跨模态表示学习的自适应分组对齐框架", "tldr": "AGA是一个新的医学跨模态表示学习框架，通过自适应分组对齐处理结构化报告并解决小数据集负样本问题，在检索和分类任务上表现出色。", "motivation": "当前的医学领域视觉-语言预训练方法常将临床报告简化为单一实体或碎片化标记，忽略其固有结构。此外，对比学习框架通常依赖大量困难负样本，这对于小规模医学数据集不切实际。", "method": "本研究提出了自适应分组对齐（AGA）框架，通过基于稀疏相似度矩阵的双向分组机制，捕获配对医学图像和报告的结构化语义。每个文本标记选择其最匹配的图像补丁形成视觉组，每个图像补丁选择其最相关的标记形成语言组。为实现自适应分组，设计了语言分组阈值门和视觉分组阈值门两个动态学习分组阈值的模块。组表示通过基于相似度分数的加权平均计算。为将每个标记与其组表示对齐，引入了实例感知组对齐损失，该损失在每个图像-文本对内部操作，无需外部负样本。最后，应用双向跨模态分组对齐模块增强视觉和语言组表示之间的细粒度对齐。", "result": "在公共和私有数据集上的大量实验表明，我们的方法在微调和零样本设置下的图像-文本检索和分类任务上均取得了优异性能。", "conclusion": "AGA框架通过捕获结构化语义并无需外部负样本，有效解决了现有医学跨模态表示学习方法在处理报告结构和负样本依赖方面的挑战，在相关任务上表现出强大的性能。", "translation": "从配对图像和报告中学习医学视觉表示是表示学习中一个有前景的方向。然而，当前医学领域的视觉-语言预训练方法常常将临床报告简化为单一实体或碎片化标记，忽略了它们的固有结构。此外，对比学习框架通常依赖大量困难负样本，这对于小规模医学数据集来说是不切实际的。为了解决这些挑战，我们提出了自适应分组对齐（AGA），这是一个新的框架，可以从配对的医学图像和报告中捕获结构化语义。AGA引入了一种基于稀疏相似度矩阵的双向分组机制。对于每个图像-报告对，我们计算文本标记和图像补丁之间的细粒度相似度。每个标记选择其最匹配的补丁形成一个视觉组，每个补丁选择其最相关的标记形成一个语言组。为了实现自适应分组，我们设计了两个阈值门控模块，称为语言分组阈值门和视觉分组阈值门，它们动态学习分组阈值。组表示根据相似度分数进行加权平均计算。为了将每个标记与其组表示对齐，我们引入了一种实例感知组对齐损失，该损失在每个图像-文本对内部操作，从而无需外部负样本。最后，应用双向跨模态分组对齐模块来增强视觉和语言组表示之间的细粒度对齐。在公共和私有数据集上的大量实验表明，我们的方法在微调和零样本设置下的图像-文本检索和分类任务上均取得了优异性能。", "summary": "AGA是一个针对医学跨模态表示学习的新框架，旨在解决现有方法忽略报告结构及对大量负样本依赖的问题。它通过引入自适应双向分组机制、动态阈值门控模块以及实例感知组对齐损失，在不依赖外部负样本的情况下，捕获图像和报告间的结构化语义。实验证明，AGA在图像-文本检索和分类任务上表现优异。", "keywords": "医学表示学习, 跨模态, 自适应分组, 结构化语义, 图像-文本检索", "comments": "AGA框架的创新点在于其自适应分组机制和实例感知组对齐损失，这使其能够有效地处理医学报告的结构化信息，并克服了传统对比学习在小规模医学数据集中对大量负样本的依赖问题。这对于提升医学领域视觉-语言预训练的实用性和性能具有重要意义。"}}
{"id": "2507.23211", "title": "Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples", "authors": ["Yunhao Liang", "Ruixuan Ying", "Takuya Taniguchi", "Zhe Cui"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23211v1", "summary": "Large Language Models exhibit powerful few-shot in-context learning (ICL)\ncapabilities, but the performance is highly sensitive to provided examples.\n  Recent research has focused on retrieving corresponding examples for each\ninput query, not only enhancing the efficiency and scalability of the learning\nprocess but also mitigating inherent biases in manual example selection.\n  However, these studies have primarily emphasized leveraging Positive samples\nwhile overlooking the additional information within Negative samples for\ncontextual learning.\n  We propose a novel method that utilizes Negative samples to better select\nPositive sample examples, thereby enhancing the performance of few-shot ICL.\nInitially, we construct Positive and Negative sample corpora based on\nZero-Shot-Cot. Then, during inference, we employ a semantic similarity-based\napproach to select the most similar examples from both the Positive and\nNegative corpora for a given query. Subsequently, we further retrieve Positive\nexamples from the Positive sample corpus based on semantic similarity to the\nNegative examples, then concatenating them with the previously selected\nPositive examples to serve as ICL demonstrations. Experimental results\ndemonstrate that our approach surpasses methods solely relying on the most\nsimilar positive examples for context, validating that the additional\ninformation in negative samples aids in enhancing ICL performance through\nimproved Positive sample selection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23211v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "失败是成功之母：通过利用负样本增强少样本上下文学习", "tldr": "提出一种利用负样本来更好地选择正样本的方法，以提高少样本上下文学习（ICL）的性能，实验证明其优于仅使用最相似正样本的方法。", "motivation": "现有研究主要关注利用正样本，而忽略了负样本在上下文学习中的额外信息。大型语言模型的少样本上下文学习性能对提供的示例高度敏感，且现有方法主要集中于检索正样本。", "method": "1. 基于Zero-Shot-Cot构建正样本和负样本语料库。 2. 推理时，使用基于语义相似度的方法从正负语料库中选择与查询最相似的示例。 3. 进一步根据负样本与正样本语料库的语义相似度检索正样本。 4. 将这些正样本与之前选择的正样本拼接作为ICL演示。", "result": "实验结果表明，该方法超越了仅依赖最相似正样本进行上下文学习的方法，验证了负样本中的额外信息通过改进正样本选择有助于增强ICL性能。", "conclusion": "通过利用负样本来优化正样本的选择，可以有效提升大型语言模型在少样本上下文学习中的表现。", "translation": "大型语言模型展现出强大的少样本上下文学习（ICL）能力，但其性能对所提供的示例高度敏感。最近的研究主要集中于为每个输入查询检索相应的示例，这不仅提高了学习过程的效率和可扩展性，还减轻了手动示例选择中固有的偏差。然而，这些研究主要强调利用正样本，而忽视了负样本中用于上下文学习的额外信息。我们提出了一种利用负样本来更好地选择正样本示例的新方法，从而增强少样本ICL的性能。首先，我们基于Zero-Shot-Cot构建正样本和负样本语料库。然后，在推理过程中，我们采用基于语义相似度的方法从正负语料库中为给定查询选择最相似的示例。随后，我们根据负样本与正样本语料库的语义相似度进一步检索正样本，然后将其与先前选择的正样本拼接起来，作为ICL演示。实验结果表明，我们的方法超越了仅依赖最相似正样本进行上下文学习的方法，验证了负样本中的额外信息通过改进正样本选择有助于增强ICL性能。", "summary": "该论文提出了一种新颖的方法，通过利用负样本来优化正样本的选择，从而增强大型语言模型的少样本上下文学习（ICL）性能。该方法首先构建正负样本语料库，然后在推理时基于语义相似度从正负语料库中选择示例，并进一步根据负样本与正样本的相似度检索更多正样本进行拼接。实验证明，该方法优于仅依赖最相似正样本的方法，验证了负样本在提升ICL性能中的价值。", "keywords": "少样本上下文学习, 负样本, 正样本选择, 大型语言模型, 语义相似度", "comments": "该论文的创新点在于首次明确提出并验证了负样本在少样本上下文学习中的潜在价值，打破了以往只关注正样本的局限。通过利用负样本来指导正样本的选择，提供了一种新颖且有效的方法来提升ICL性能，对未来相关研究具有启发意义。其方法设计巧妙，结合了语义相似度，具有一定的普适性。"}}
{"id": "2507.21004", "title": "Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability", "authors": ["Fang Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The project has been open sourced at Github ( this https URL )", "url": "http://arxiv.org/abs/2507.21004v2", "summary": "Deep Neural Networks (DNNs) deliver impressive performance but their\nblack-box nature limits deployment in high-stakes domains requiring\ntransparency. We introduce Compositional Function Networks (CFNs), a novel\nframework that builds inherently interpretable models by composing elementary\nmathematical functions with clear semantics. Unlike existing interpretable\napproaches that are limited to simple additive structures, CFNs support diverse\ncompositional patterns -- sequential, parallel, and conditional -- enabling\ncomplex feature interactions while maintaining transparency. A key innovation\nis that CFNs are fully differentiable, allowing efficient training through\nstandard gradient descent. We demonstrate CFNs' versatility across multiple\ndomains, from symbolic regression to image classification with deep\nhierarchical networks. Our empirical evaluation shows CFNs achieve competitive\nperformance against black-box models (96.24% accuracy on CIFAR-10) while\noutperforming state-of-the-art interpretable models like Explainable Boosting\nMachines. By combining the hierarchical expressiveness and efficient training\nof deep learning with the intrinsic interpretability of well-defined\nmathematical functions, CFNs offer a powerful framework for applications where\nboth performance and accountability are paramount.", "comment": "The project has been open sourced at Github\n  (https://github.com/fanglioc/Compositional_Function_Networks)", "pdf_url": "http://arxiv.org/pdf/2507.21004v2", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-31", "AI": {"title_translation": "组合函数网络：一种内置可解释性的高性能深度神经网络替代方案", "tldr": "组合函数网络（CFN）是一种新型的可解释模型框架，通过组合基本数学函数来构建模型，旨在提供高性能且具有内置可解释性的深度神经网络替代方案。CFN支持多种组合模式，并可通过标准梯度下降进行高效训练，在多个领域展现出与黑盒模型相当的性能，并优于现有的可解释模型。", "motivation": "深度神经网络（DNNs）性能优异，但其黑盒性质限制了它们在需要透明度的高风险领域的部署。本研究旨在开发一种既能保持高性能又具有内在可解释性的模型。", "method": "本文引入了组合函数网络（CFN），通过组合具有清晰语义的基本数学函数来构建模型，从而实现固有的可解释性。CFN支持序列、并行和条件等多种组合模式，能够处理复杂的特征交互。此外，CFN是完全可微的，允许通过标准梯度下降进行高效训练。", "result": "经验评估显示，CFN在多个领域（从符号回归到图像分类）均表现出通用性。在CIFAR-10数据集上，CFN达到了96.24%的准确率，实现了与黑盒模型相当的竞争性性能，同时优于最先进的可解释模型，如可解释提升机器（Explainable Boosting Machines）。", "conclusion": "组合函数网络（CFN）通过结合深度学习的分层表达能力和高效训练与明确定义的数学函数的内在可解释性，为那些性能和可解释性都至关重要的应用提供了一个强大的框架。", "translation": "深度神经网络 (DNN) 表现出色，但其黑盒性质限制了它们在需要透明度的高风险领域的部署。我们引入了组合函数网络 (CFN)，这是一种新颖的框架，通过组合具有清晰语义的基本数学函数来构建固有的可解释模型。与现有仅限于简单加性结构的可解释方法不同，CFN 支持多种组合模式——序列、并行和条件——在保持透明度的同时实现复杂的特征交互。一个关键创新是 CFN 是完全可微的，允许通过标准梯度下降进行高效训练。我们展示了 CFN 在多个领域的通用性，从符号回归到使用深度分层网络的图像分类。我们的经验评估表明，CFN 在与黑盒模型竞争的同时（CIFAR-10 上达到 96.24% 的准确率），优于最先进的可解释模型，如可解释提升机器。通过将深度学习的分层表达能力和高效训练与明确定义的数学函数的内在可解释性相结合，CFN 为性能和可解释性都至关重要的应用提供了一个强大的框架。", "summary": "本文介绍了组合函数网络（CFN），这是一种新颖的可解释机器学习框架。与不透明的深度神经网络不同，CFN通过组合基本数学函数来构建模型，确保了固有的透明度。它们支持复杂的组合模式，并且是可微的，可以进行高效训练。实证结果表明，CFN在性能上与黑盒模型具有竞争力，同时超越了其他可解释方法，使其适用于需要高性能和可解释性的高风险应用。", "keywords": "组合函数网络, 可解释性, 深度神经网络, 机器学习, 可解释人工智能", "comments": "CFN通过在不显著牺牲性能的前提下解决可解释性这一关键问题，为深度神经网络提供了一个有前景的替代方案。它们通过多样化的组合模式处理复杂特征交互的能力，以及可微性实现高效训练的特性，代表了可解释人工智能领域的一项重要创新。"}}
{"id": "2502.11641", "title": "A Zero-Knowledge Proof for the Syndrome Decoding Problem in the Lee Metric", "authors": ["Mladen Kovačević", "Tatjana Grbić", "Darko Čapko", "Nemanja Nedić", "Srdjan Vukmirović"], "categories": ["cs.CR", "cs.IT", "math.IT", "94A60, 68P25"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.11641v3", "summary": "The syndrome decoding problem is one of the NP-complete problems lying at the\nfoundation of code-based cryptography. The variant thereof where the distance\nbetween vectors is measured with respect to the Lee metric, rather than the\nmore commonly used Hamming metric, has been analyzed recently in several works\ndue to its potential relevance for building more efficient code-based\ncryptosystems. The purpose of this article is to present a zero-knowledge proof\nof knowledge for this variant of the problem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.11641v3", "cate": "cs.CR", "date": "2025-02-17", "updated": "2025-07-31", "AI": {"title_translation": "Lee度量下综合症解码问题的零知识证明", "tldr": "本文提出了Lee度量下综合症解码问题的零知识证明。", "motivation": "综合症解码问题是基于编码密码学的基础问题之一，Lee度量下的变体因其在构建更高效的基于编码密码系统方面的潜在相关性而受到关注。", "method": "本文旨在提出针对Lee度量下综合症解码问题变体的零知识知识证明。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "综合症解码问题是基于编码密码学基础的NP完全问题之一。该问题的变体，即向量间距离采用Lee度量而非更常用的Hamming度量来衡量，由于其在构建更高效的基于编码密码系统方面的潜在相关性，最近在多项工作中得到了分析。本文旨在提出针对该问题变体的零知识知识证明。", "summary": "本文提出了Lee度量下综合症解码问题的零知识知识证明。Lee度量下的综合症解码问题是基于编码密码学的重要NP完全问题，因其在构建高效密码系统中的潜力而受到关注。", "keywords": "零知识证明, 综合症解码, Lee度量, 基于编码密码学", "comments": "该论文的创新点在于将零知识证明应用于Lee度量下的综合症解码问题，这对于构建更高效的基于编码的密码系统具有潜在意义。"}}
{"id": "2507.23141", "title": "AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver", "authors": ["Xiangshu Gong", "Zhiqiang Xie", "Xiaowei Jin", "Chen Wang", "Yanling Qu", "Wangmeng Zuo", "Hui Li"], "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23141v1", "summary": "Many problems are governed by differential equations (DEs). Artificial\nintelligence (AI) is a new path for solving DEs. However, data is very scarce\nand existing AI solvers struggle with approximation of high frequency\ncomponents (AHFC). We propose an AI paradigm for solving diverse DEs, including\nDE-ruled first-principles data generation methodology and scale-dilation\noperator (SDO) AI solver. Using either prior knowledge or random fields, we\ngenerate solutions and then substitute them into the DEs to derive the sources\nand initial/boundary conditions through balancing DEs, thus producing\narbitrarily vast amount of, first-principles-consistent training datasets at\nextremely low computational cost. We introduce a reversible SDO that leverages\nthe Fourier transform of the multiscale solutions to fix AHFC, and design a\nspatiotemporally coupled, attention-based Transformer AI solver of DEs with\nSDO. An upper bound on the Hessian condition number of the loss function is\nproven to be proportional to the squared 2-norm of the solution gradient,\nrevealing that SDO yields a smoother loss landscape, consequently fixing AHFC\nwith efficient training. Extensive tests on diverse DEs demonstrate that our AI\nparadigm achieves consistently superior accuracy over state-of-the-art methods.\nThis work makes AI solver of DEs to be truly usable in broad nature and\nengineering fields.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23141v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "AI求解微分方程范式：第一性原理数据生成与尺度膨胀算子AI求解器", "tldr": "提出一种新的AI范式，通过第一性原理数据生成和尺度膨胀算子（SDO）AI求解器解决微分方程，有效解决数据稀缺和高频分量近似问题，并实现卓越精度。", "motivation": "现有AI求解微分方程面临数据稀缺和难以近似高频分量（AHFC）的问题。", "method": "提出AI范式，包含两部分：1. DE-ruled第一性原理数据生成：利用先验知识或随机场生成解，代入DEs推导源项和初始/边界条件，以极低计算成本生成大量一致性训练数据。2. 尺度膨胀算子（SDO）AI求解器：引入可逆SDO，利用多尺度解的傅里叶变换解决AHFC问题；设计时空耦合、基于注意力机制的Transformer AI求解器。证明损失函数Hessian条件数的上限与解梯度平方2范数成比例，表明SDO产生更平滑的损失景观，从而有效解决AHFC并实现高效训练。", "result": "在各种微分方程上的广泛测试表明，该AI范式始终优于最先进的方法，实现了卓越的精度。", "conclusion": "这项工作使AI微分方程求解器在广泛的自然科学和工程领域变得真正可用。", "translation": "许多问题都由微分方程（DEs）控制。人工智能（AI）是解决微分方程的新途径。然而，数据非常稀缺，并且现有的AI求解器在近似高频分量（AHFC）方面存在困难。我们提出了一种用于解决各种微分方程的AI范式，包括由微分方程控制的第一性原理数据生成方法和尺度膨胀算子（SDO）AI求解器。通过使用先验知识或随机场，我们生成解，然后将它们代入微分方程中，通过平衡微分方程推导出源项和初始/边界条件，从而以极低的计算成本产生任意大量的、符合第一性原理的训练数据集。我们引入了一个可逆的尺度膨胀算子（SDO），它利用多尺度解的傅里叶变换来修正AHFC，并设计了一个时空耦合、基于注意力机制的Transformer AI微分方程求解器，其中包含SDO。损失函数Hessian条件数的一个上限被证明与解梯度的平方2范数成比例，这表明SDO产生了更平滑的损失景观，从而通过高效训练修正了AHFC。对各种微分方程的广泛测试表明，我们的AI范式始终比最先进的方法实现更高的精度。这项工作使AI微分方程求解器在广泛的自然和工程领域真正可用。", "summary": "这篇论文提出了一种新的AI范式来解决微分方程，旨在克服现有方法数据稀缺和难以处理高频分量的问题。该范式包含两部分：一是基于微分方程的第一性原理数据生成方法，能以低成本生成海量高质量训练数据；二是引入了尺度膨胀算子（SDO）的AI求解器，通过傅里叶变换和Transformer架构有效解决高频分量近似问题，并优化了损失函数景观以实现高效训练。实验证明，该方法在多种微分方程上均表现出优于现有SOTA方法的精度。", "keywords": "微分方程, 人工智能, 数据生成, 尺度膨胀算子, 高频分量", "comments": "这项工作创新性地解决了AI求解微分方程面临的数据稀缺和高频分量近似两大核心挑战。通过结合第一性原理数据生成和尺度膨胀算子，提供了一个通用且高效的解决方案。特别是SDO在优化损失函数景观方面的理论证明，提升了方法的鲁棒性和训练效率。其在广泛领域的适用性使其具有重要的实际应用潜力。"}}
{"id": "2507.23495", "title": "Incorporating structural uncertainty in causal decision making", "authors": ["Maurits Kaptein"], "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work is under review at the Journal of Causal Inference", "url": "http://arxiv.org/abs/2507.23495v1", "summary": "Practitioners making decisions based on causal effects typically ignore\nstructural uncertainty. We analyze when this uncertainty is consequential\nenough to warrant methodological solutions (Bayesian model averaging over\ncompeting causal structures). Focusing on bivariate relationships ($X\n\\rightarrow Y$ vs. $X \\leftarrow Y$), we establish that model averaging is\nbeneficial when: (1) structural uncertainty is moderate to high, (2) causal\neffects differ substantially between structures, and (3) loss functions are\nsufficiently sensitive to the size of the causal effect. We prove optimality\nresults of our suggested methodological solution under regularity conditions\nand demonstrate through simulations that modern causal discovery methods can\nprovide, within limits, the necessary quantification. Our framework complements\nexisting robust causal inference approaches by addressing a distinct source of\nuncertainty typically overlooked in practice.", "comment": "This work is under review at the Journal of Causal Inference", "pdf_url": "http://arxiv.org/pdf/2507.23495v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "将结构不确定性纳入因果决策", "tldr": "实践中因果决策常忽略结构不确定性。本文提出贝叶斯模型平均方法，并在特定条件下证明其有效性，以解决这一被忽视的不确定性来源。", "motivation": "实践者在基于因果效应做决策时通常会忽略结构不确定性，而这种不确定性可能非常重要，需要相应的方法论解决方案。", "method": "本文分析了何时结构不确定性足够重要以需要方法论解决方案，并提出了贝叶斯模型平均作为解决竞争因果结构不确定性的方法。研究重点关注二元关系（X → Y vs. X ← Y），并通过证明最优性结果和模拟来支持其方法。", "result": "模型平均在以下情况下有益：(1) 结构不确定性适中到高，(2) 因果效应在不同结构之间存在显著差异，以及 (3) 损失函数对因果效应的大小足够敏感。研究证明了所提出方法在正则条件下的最优性，并通过模拟表明现代因果发现方法可以在一定限度内提供必要的量化。", "conclusion": "本文提出的框架通过解决实践中通常被忽视的独特不确定性来源，补充了现有的稳健因果推断方法。", "translation": "实践者在基于因果效应做决策时通常会忽略结构不确定性。我们分析了何时这种不确定性足够重要，以至于需要方法论解决方案（对竞争因果结构进行贝叶斯模型平均）。我们着重于二元关系（X → Y 与 X ← Y），并确立了模型平均在以下情况下是有益的：(1) 结构不确定性适中到高，(2) 因果效应在不同结构之间存在显著差异，以及 (3) 损失函数对因果效应的大小足够敏感。我们在正则条件下证明了我们建议的方法学解决方案的最优性结果，并通过模拟证明现代因果发现方法可以在一定限度内提供必要的量化。我们的框架通过解决实践中通常被忽视的独特不确定性来源，补充了现有的稳健因果推断方法。", "summary": "本文探讨了在因果决策中纳入结构不确定性的重要性，这种不确定性在实践中常被忽视。研究提出并分析了贝叶斯模型平均方法，特别是在二元因果关系中，并指出当结构不确定性适中到高、因果效应在不同结构间差异显著且损失函数敏感时，该方法具有优势。文章证明了其方法的最优性，并利用模拟验证了因果发现方法量化不确定性的能力，从而为稳健因果推断提供了一个新的补充视角。", "keywords": "结构不确定性, 因果决策, 贝叶斯模型平均, 因果发现, 稳健因果推断", "comments": "这篇论文的创新点在于它明确地解决了因果决策中结构不确定性这一长期被忽视的问题，并提出了贝叶斯模型平均作为一种系统性的解决方案。其重要性在于提供了一个理论框架和实践指导，帮助决策者在复杂的因果环境中做出更稳健的决策。通过明确指出模型平均的适用条件，它为实践者提供了清晰的指引。"}}
{"id": "2507.15857", "title": "Diffusion Beats Autoregressive in Data-Constrained Settings", "authors": ["Mihir Prabhudesai", "Mengning Wu", "Amir Zadeh", "Katerina Fragkiadaki", "Deepak Pathak"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Project Webpage: this https URL", "url": "http://arxiv.org/abs/2507.15857v4", "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.", "comment": "Project Webpage: https://diffusion-scaling.github.io", "pdf_url": "http://arxiv.org/pdf/2507.15857v4", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-31", "AI": {"title_translation": "扩散模型在数据受限设置下优于自回归模型", "tldr": "在数据稀缺的环境中，扩散模型显著优于自回归模型，因为它们能更好地利用重复数据并进行隐式数据增强。", "motivation": "自回归（AR）模型长期主导大型语言模型领域，但基于扩散的语言模型作为一种有前景的替代方案出现，其相对于AR模型的优势，尤其是在数据受限设置下，仍未得到充分探索。", "method": "本文系统地研究了数据受限设置下的掩码扩散模型，在这些设置中，训练涉及对有限数据进行重复遍历。", "result": "研究发现，当计算资源充足但数据稀缺时，掩码扩散模型显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。这种优势被解释为隐式数据增强，因为掩码扩散使模型接触到多样化的词元排序和预测任务分布。此外，研究还发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于AR模型的临界计算阈值的闭式表达式。", "conclusion": "当数据而非计算是瓶颈时，扩散模型为标准的AR范式提供了一个引人注目的替代方案。", "translation": "自回归（AR）模型长期以来主导着大型语言模型的领域，推动了各种任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相对于AR模型的优势仍未得到充分探索。在本文中，我们系统地研究了数据受限设置下的掩码扩散模型——在这些设置中，训练涉及对有限数据进行重复遍历——并发现当计算资源充足但数据稀缺时，它们显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。我们将这种优势解释为隐式数据增强：与AR固定的从左到右分解不同，掩码扩散使模型接触到多样化的词元排序和预测任务分布。我们发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于AR模型的临界计算阈值的闭式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准的AR范式提供了一个引人注目的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。", "summary": "本文研究了在数据受限条件下掩码扩散模型的性能，发现当计算资源充足但数据稀缺时，它们显著优于传统的自回归模型。这一优势归因于扩散模型对重复数据的更好利用和隐式数据增强，从而实现了更低的验证损失和更优的下游性能。该研究还确定了扩散模型的新缩放定律，并推导出了一个临界计算阈值，表明当数据是主要瓶颈时，扩散模型是一个有力的替代方案。", "keywords": "扩散模型, 自回归模型, 数据受限, 语言模型, 隐式数据增强", "comments": "该论文的主要创新在于系统地探索了掩码扩散模型在数据受限场景下的性能，在这些场景中，它们相对于自回归模型的优势此前尚未得到充分探索。通过将隐式数据增强识别为核心机制并推导缩放定律，这项研究为扩散模型的优势提供了宝贵的见解，特别是对于数据稀缺是主要挑战的场景。这项工作突出了在特定资源配置下，扩散模型作为主导AR范式的一个引人注目的替代方案。"}}
{"id": "2507.18518", "title": "Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment", "authors": ["Ruiqi He", "Zekun Fei", "Jiaqi Li", "Xinyuan Zhu", "Biao Yi", "Siyi Lv", "Weijie Liu", "Zheli Liu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18518v2", "summary": "Vector Database (VDB) can efficiently index and search high-dimensional\nvector embeddings from unstructured data, crucially enabling fast semantic\nsimilarity search essential for modern AI applications like generative AI and\nrecommendation systems. Since current VDB service providers predominantly use\nproprietary black-box models, users are forced to expose raw query text to them\nvia API in exchange for the vector retrieval services. Consequently, if query\ntext involves confidential records from finance or healthcare domains, this\nmechanism inevitably leads to critical leakage of user's sensitive information.\nTo address this issue, we introduce STEER (\\textbf{S}ecure \\textbf{T}ransformed\n\\textbf{E}mbedding v\\textbf{E}ctor\\textbf{ R}etrieval), a private vector\nretrieval framework that leverages the alignment relationship between the\nsemantic spaces of different embedding models to derive approximate embeddings\nfor the query text. STEER performs the retrieval using the approximate\nembeddings within the original VDB and requires no modifications to the server\nside. Our theoretical and experimental analyses demonstrate that STEER\neffectively safeguards query text privacy while maintaining the retrieval\naccuracy. Even though approximate embeddings are approximations of the\nembeddings from proprietary models, they still prevent the providers from\nrecovering the query text through Embedding Inversion Attacks (EIAs). Extensive\nexperimental results show that Recall@100 of STEER can basically achieve a\ndecrease of less than 5\\%. Furthermore, even when searching within a text\ncorpus of millions of entries, STEER achieves a Recall@20 accuracy 20\\% higher\nthan current baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18518v2", "cate": "cs.IR", "date": "2025-07-24", "updated": "2025-07-31", "AI": {"title_translation": "查询前转换：一种基于嵌入空间对齐的向量检索隐私保护方法", "tldr": "STEER是一个隐私保护向量检索框架，通过生成近似嵌入来避免向向量数据库服务提供商泄露敏感查询文本，同时保持高检索准确率。", "motivation": "当前的向量数据库（VDB）服务要求用户通过API暴露原始查询文本给专有模型，这导致了金融或医疗等领域敏感信息的泄露风险。", "method": "我们提出了STEER（安全转换嵌入向量检索），一个利用不同嵌入模型语义空间之间的对齐关系来推导查询文本近似嵌入的隐私保护向量检索框架。STEER在原始VDB中进行检索，无需修改服务器端。", "result": "STEER有效保护了查询文本隐私，同时保持了检索准确性。近似嵌入可以防止服务提供商通过嵌入反演攻击（EIAs）恢复查询文本。STEER的Recall@100下降不到5%。在数百万条目文本语料库中，STEER的Recall@20准确率比当前基线高20%。", "conclusion": "STEER框架在保护查询文本隐私的同时，能够维持甚至在某些情况下超越现有基线的检索准确性，为敏感数据在向量数据库中的安全使用提供了有效解决方案。", "translation": "向量数据库（VDB）可以高效地索引和搜索非结构化数据中的高维向量嵌入，这对于现代AI应用（如生成式AI和推荐系统）中必不可少的快速语义相似性搜索至关重要。由于当前的VDB服务提供商主要使用专有黑盒模型，用户被迫通过API向其暴露原始查询文本，以换取向量检索服务。因此，如果查询文本涉及金融或医疗领域的机密记录，这种机制不可避免地导致用户敏感信息的严重泄露。为了解决这个问题，我们引入了STEER（安全转换嵌入向量检索），一个隐私保护向量检索框架，它利用不同嵌入模型语义空间之间的对齐关系来推导查询文本的近似嵌入。STEER使用近似嵌入在原始VDB中执行检索，并且不需要对服务器端进行任何修改。我们的理论和实验分析表明，STEER有效地保护了查询文本隐私，同时保持了检索准确性。尽管近似嵌入是专有模型嵌入的近似值，它们仍然可以防止服务提供商通过嵌入反演攻击（EIAs）恢复查询文本。大量的实验结果表明，STEER的Recall@100基本可以实现不到5%的下降。此外，即使在数百万条目的文本语料库中进行搜索，STEER的Recall@20准确率也比当前基线高20%。", "summary": "本文提出了STEER，一个用于向量检索的隐私保护框架。针对当前向量数据库服务中用户需暴露敏感查询文本的隐私泄露问题，STEER利用不同嵌入模型间的语义空间对齐关系生成近似查询嵌入，并在不修改服务器端的情况下进行检索。实验证明，STEER在有效保护查询隐私的同时，能将检索准确率（Recall@100）的下降控制在5%以内，并在大规模语料库中实现比现有基线更高的Recall@20准确率，有效抵御嵌入反演攻击。", "keywords": "向量数据库, 隐私保护, 向量检索, 嵌入空间对齐, 语义相似性搜索", "comments": "该论文提出了一种新颖的隐私保护方法，通过在查询前转换嵌入来解决向量数据库中的敏感信息泄露问题。其创新点在于利用嵌入空间对齐生成近似嵌入，且无需修改现有VDB服务器，这大大降低了部署难度。在保护隐私的同时，检索准确率的损失极小，甚至在某些情况下有所提升，这使其在实际应用中具有很高的价值。"}}
{"id": "2507.19095", "title": "GCL-GCN: Graphormer and Contrastive Learning Enhanced Attributed Graph Clustering Network", "authors": ["Binxiong Li", "Xu Xiang", "Xue Li", "Quanzhou Lou", "Binyu Zhao", "Yujie Liu", "Huijie Tang", "Benhan Yang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The source code for this study is available at this https URL", "url": "http://arxiv.org/abs/2507.19095v2", "summary": "Attributed graph clustering holds significant importance in modern data\nanalysis. However, due to the complexity of graph data and the heterogeneity of\nnode attributes, leveraging graph information for clustering remains\nchallenging. To address this, we propose a novel deep graph clustering model,\nGCL-GCN, specifically designed to address the limitations of existing models in\ncapturing local dependencies and complex structures when dealing with sparse\nand heterogeneous graph data. GCL-GCN introduces an innovative Graphormer\nmodule that combines centrality encoding and spatial relationships, effectively\ncapturing both global and local information between nodes, thereby enhancing\nthe quality of node representations. Additionally, we propose a novel\ncontrastive learning module that significantly enhances the discriminative\npower of feature representations. In the pre-training phase, this module\nincreases feature distinction through contrastive learning on the original\nfeature matrix, ensuring more identifiable initial representations for\nsubsequent graph convolution and clustering tasks. Extensive experimental\nresults on six datasets demonstrate that GCL-GCN outperforms 14 advanced\nmethods in terms of clustering quality and robustness. Specifically, on the\nCora dataset, it improves ACC, NMI, and ARI by 4.94%, 13.01%, and 10.97%,\nrespectively, compared to the primary comparison method MBN.", "comment": "The source code for this study is available at\n  https://github.com/YF-W/GCL-GCN", "pdf_url": "http://arxiv.org/pdf/2507.19095v2", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-31", "AI": {"title_translation": "GCL-GCN：Graphormer 和对比学习增强的属性图聚类网络", "tldr": "提出GCL-GCN，结合Graphormer和对比学习，提升属性图聚类性能，在多个数据集上超越现有方法。", "motivation": "现有模型在处理稀疏和异构图数据时，难以捕获局部依赖和复杂结构，导致属性图聚类面临挑战。", "method": "GCL-GCN模型包含创新的Graphormer模块和新颖的对比学习模块。Graphormer结合中心性编码和空间关系，捕获全局和局部信息，提高节点表示质量。对比学习模块在预训练阶段通过对原始特征矩阵进行对比学习，增强特征表示的区分能力，确保初始表示更具可识别性。", "result": "在六个数据集上，GCL-GCN在聚类质量和鲁棒性方面优于14种先进方法。在Cora数据集上，ACC、NMI和ARI分别比主要对比方法MBN提高了4.94%、13.01%和10.97%。", "conclusion": "GCL-GCN通过结合Graphormer和对比学习，有效解决了属性图聚类中捕获复杂图信息和异构属性的挑战，显著提升了聚类性能和鲁棒性。", "translation": "属性图聚类在现代数据分析中具有重要意义。然而，由于图数据的复杂性和节点属性的异构性，利用图信息进行聚类仍然具有挑战性。为了解决这个问题，我们提出了一种新颖的深度图聚类模型GCL-GCN，它专门设计用于解决现有模型在处理稀疏和异构图数据时捕获局部依赖和复杂结构的局限性。GCL-GCN引入了一个创新的Graphormer模块，该模块结合了中心性编码和空间关系，有效地捕获节点之间的全局和局部信息，从而提高了节点表示的质量。此外，我们提出了一种新颖的对比学习模块，该模块显著增强了特征表示的判别能力。在预训练阶段，该模块通过对原始特征矩阵进行对比学习来增加特征区分度，确保后续图卷积和聚类任务的初始表示更具可识别性。在六个数据集上的大量实验结果表明，GCL-GCN在聚类质量和鲁棒性方面优于14种先进方法。具体而言，在Cora数据集上，与主要对比方法MBN相比，其ACC、NMI和ARI分别提高了4.94%、13.01%和10.97%。", "summary": "GCL-GCN是一种新颖的深度属性图聚类模型，旨在解决现有方法在处理稀疏和异构图数据时捕获复杂图信息不足的问题。它通过引入创新的Graphormer模块来增强节点表示质量，并通过对比学习模块提升特征区分能力。实验证明，GCL-GCN在多个数据集上显著优于现有先进方法，在聚类质量和鲁棒性方面表现出色。", "keywords": "属性图聚类, Graphormer, 对比学习, 图神经网络, 深度学习", "comments": "GCL-GCN的创新点在于结合了Graphormer的图结构建模能力和对比学习的特征判别能力，有效解决了属性图聚类中复杂信息捕获的挑战。其在稀疏和异构数据上的表现尤为重要，表明了模型在实际应用中的潜力。"}}
{"id": "2503.06989", "title": "Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application", "authors": ["Wenzhuo Xu", "Zhipeng Wei", "Xiongtao Sun", "Zonghao Ying", "Deyue Zhang", "Dongdong Yang", "Xiangzheng Zhang", "Quanchen Zou"], "categories": ["cs.CR", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06989v2", "summary": "Recently, Multimodal Large Language Models (MLLMs) have demonstrated their\nsuperior ability in understanding multimodal content. However, they remain\nvulnerable to jailbreak attacks, which exploit weaknesses in their safety\nalignment to generate harmful responses. Previous studies categorize jailbreaks\nas successful or failed based on whether responses contain malicious content.\nHowever, given the stochastic nature of MLLM responses, this binary\nclassification of an input's ability to jailbreak MLLMs is inappropriate.\nDerived from this viewpoint, we introduce jailbreak probability to quantify the\njailbreak potential of an input, which represents the likelihood that MLLMs\ngenerated a malicious response when prompted with this input. We approximate\nthis probability through multiple queries to MLLMs. After modeling the\nrelationship between input hidden states and their corresponding jailbreak\nprobability using Jailbreak Probability Prediction Network (JPPN), we use\ncontinuous jailbreak probability for optimization. Specifically, we propose\nJailbreak-Probability-based Attack (JPA) that optimizes adversarial\nperturbations on input image to maximize jailbreak probability, and further\nenhance it as Multimodal JPA (MJPA) by including monotonic text rephrasing. To\ncounteract attacks, we also propose Jailbreak-Probability-based Finetuning\n(JPF), which minimizes jailbreak probability through MLLM parameter updates.\nExtensive experiments show that (1) (M)JPA yields significant improvements when\nattacking a wide range of models under both white and black box settings. (2)\nJPF vastly reduces jailbreaks by at most over 60\\%. Both of the above results\ndemonstrate the significance of introducing jailbreak probability to make\nnuanced distinctions among input jailbreak abilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06989v2", "cate": "cs.CR", "date": "2025-03-10", "updated": "2025-07-31", "AI": {"title_translation": "多模态大型语言模型越狱的概率建模：从量化到应用", "tldr": "本文引入“越狱概率”来量化多模态大型语言模型的越狱潜力，并基于此开发了旨在最大化越狱概率的攻击方法（JPA/MJPA）和旨在最小化越狱概率的防御方法（JPF）。", "motivation": "鉴于多模态大型语言模型（MLLMs）响应的随机性，将越狱简单地二元分类为成功或失败是不合适的，因此需要一种更精细的量化方法来评估输入的越狱潜力。", "method": "本文引入越狱概率来量化输入导致MLLMs生成恶意响应的可能性，并通过多次查询MLLMs来近似该概率。使用越狱概率预测网络（JPPN）建模输入隐藏状态与越狱概率的关系。提出基于越狱概率的攻击（JPA），通过优化输入图像上的对抗性扰动来最大化越狱概率，并将其增强为多模态JPA（MJPA），纳入单调文本重述。同时，提出基于越狱概率的微调（JPF），通过更新MLLM参数来最小化越狱概率以进行防御。", "result": "(1) (M)JPA 在白盒和黑盒设置下攻击各种模型时都取得了显著改进。(2) JPF 大幅减少了越狱现象，最多超过60%。", "conclusion": "引入越狱概率对于对输入越狱能力进行细致区分具有重要意义。", "translation": "最近，多模态大型语言模型（MLLMs）在理解多模态内容方面展现出卓越的能力。然而，它们仍然容易受到越狱攻击，这些攻击利用其安全对齐中的弱点来生成有害响应。先前的研究根据响应是否包含恶意内容将越狱分为成功或失败。然而，鉴于MLLM响应的随机性，这种对输入越狱MLLM能力的二元分类是不合适的。基于这一观点，我们引入越狱概率来量化输入的越狱潜力，它表示当使用该输入提示时MLLMs生成恶意响应的可能性。我们通过多次查询MLLMs来近似该概率。在使用越狱概率预测网络（JPPN）建模输入隐藏状态及其相应越狱概率之间的关系后，我们使用连续的越狱概率进行优化。具体来说，我们提出了基于越狱概率的攻击（JPA），该攻击优化输入图像上的对抗性扰动以最大化越狱概率，并通过包含单调文本重述将其进一步增强为多模态JPA（MJPA）。为了对抗攻击，我们还提出了基于越狱概率的微调（JPF），该方法通过更新MLLM参数来最小化越狱概率。大量实验表明：（1）(M)JPA 在白盒和黑盒设置下攻击各种模型时都取得了显著改进。（2）JPF 大幅减少了越狱现象，最多超过60%。上述两项结果都证明了引入越狱概率来对输入越狱能力进行细致区分的重要性。", "summary": "本文针对多模态大语言模型（MLLMs）越狱二元分类的局限性，创新性地提出了“越狱概率”来量化输入的越狱潜力。基于此连续量化，研究者开发了两种攻击方法：JPA通过优化图像扰动，MJPA结合文本重述，旨在最大化越狱概率。同时，也提出了一种防御机制JPF，通过微调MLLM参数来最小化越狱概率。实验结果验证了所提攻防策略的有效性，并强调了越狱概率在细致区分输入越狱能力方面的重要性。", "keywords": "多模态大型语言模型, 越狱, 概率建模, 对抗性攻击, 安全对齐", "comments": "本文的创新点在于将MLLM越狱问题从传统的二元分类提升到连续的概率建模，这更准确地反映了MLLM响应的随机性。基于这一核心创新，论文不仅提出了有效的越狱攻击方法（JPA/MJPA），还设计了相应的防御机制（JPF），形成了一个完整的攻防框架。这种从量化到应用的全面研究，对于理解和提升MLLM的安全性具有重要理论和实践价值。"}}
{"id": "2507.23162", "title": "Neural Multi-View Self-Calibrated Photometric Stereo without Photometric Stereo Cues", "authors": ["Xu Cao", "Takafumi Taketomi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.23162v1", "summary": "We propose a neural inverse rendering approach that jointly reconstructs\ngeometry, spatially varying reflectance, and lighting conditions from\nmulti-view images captured under varying directional lighting. Unlike prior\nmulti-view photometric stereo methods that require light calibration or\nintermediate cues such as per-view normal maps, our method jointly optimizes\nall scene parameters from raw images in a single stage. We represent both\ngeometry and reflectance as neural implicit fields and apply shadow-aware\nvolume rendering. A spatial network first predicts the signed distance and a\nreflectance latent code for each scene point. A reflectance network then\nestimates reflectance values conditioned on the latent code and angularly\nencoded surface normal, view, and light directions. The proposed method\noutperforms state-of-the-art normal-guided approaches in shape and lighting\nestimation accuracy, generalizes to view-unaligned multi-light images, and\nhandles objects with challenging geometry and reflectance.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23162v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "神经多视角自校准光度立体，无需光度立体线索", "tldr": "该论文提出了一种神经逆渲染方法，可以从多视角图像联合重建几何、反射率和光照，无需光照校准或中间线索，且性能优于现有方法。", "motivation": "现有的多视角光度立体方法需要光照校准或中间线索（如每视角法线图），这增加了复杂性。本文旨在提出一种无需这些前提条件的方法，能够直接从原始图像联合优化所有场景参数。", "method": "提出了一种神经逆渲染方法，通过神经隐式场表示几何和反射率，并应用阴影感知体渲染。一个空间网络首先预测每个场景点的有符号距离和反射率潜在代码，然后一个反射率网络根据潜在代码、角度编码的表面法线、视角和光照方向估计反射率值。该方法在一个阶段内从原始图像联合优化所有场景参数。", "result": "该方法在形状和光照估计精度上优于最先进的法线引导方法，能够泛化到视角未对齐的多光照图像，并能处理具有挑战性几何形状和反射率的物体。", "conclusion": "所提出的神经逆渲染方法无需传统光度立体线索，能够从多视角图像中联合重建几何、空间变化的反射率和光照条件，并在准确性和泛化性方面超越了现有技术。", "translation": "我们提出了一种神经逆渲染方法，可以从在不同方向光照下捕获的多视角图像中联合重建几何、空间变化的反射率和光照条件。与之前需要光照校准或中间线索（如每视角法线图）的多视角光度立体方法不同，我们的方法在一个阶段内从原始图像中联合优化所有场景参数。我们将几何和反射率表示为神经隐式场，并应用阴影感知体渲染。一个空间网络首先预测每个场景点的有符号距离和反射率潜在代码。然后，一个反射率网络根据潜在代码以及角度编码的表面法线、视角和光照方向估计反射率值。所提出的方法在形状和光照估计精度方面优于最先进的法线引导方法，能够泛化到视角未对齐的多光照图像，并能处理具有挑战性的几何形状和反射率的物体。", "summary": "本文提出了一种新颖的神经逆渲染方法，旨在从多视角图像中联合重建场景的几何、空间变化的反射率和光照条件。与传统多视角光度立体方法依赖光照校准或中间线索不同，该方法通过神经隐式场和阴影感知体渲染，在一个单一阶段内直接从原始图像优化所有场景参数。实验结果表明，该方法在形状和光照估计精度上超越了现有技术，并展现出对视角未对齐图像和复杂物体的良好泛化能力。", "keywords": "神经逆渲染, 多视角, 光度立体, 隐式场, 反射率", "comments": "该论文的主要创新点在于无需传统光度立体方法所需的光照校准或中间线索，实现了从原始图像进行端到端的联合优化。通过引入神经隐式场和阴影感知体渲染，极大地简化了逆渲染流程，并提升了对复杂场景的适应性，具有重要的实际应用价值。"}}
{"id": "2507.23277", "title": "iLRM: An Iterative Large 3D Reconstruction Model", "authors": ["Gyeongjin Kang", "Seungtae Nam", "Xiangyu Sun", "Sameh Khamis", "Abdelrahman Mohamed", "Eunbyung Park"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.23277v1", "summary": "Feed-forward 3D modeling has emerged as a promising approach for rapid and\nhigh-quality 3D reconstruction. In particular, directly generating explicit 3D\nrepresentations, such as 3D Gaussian splatting, has attracted significant\nattention due to its fast and high-quality rendering, as well as numerous\napplications. However, many state-of-the-art methods, primarily based on\ntransformer architectures, suffer from severe scalability issues because they\nrely on full attention across image tokens from multiple input views, resulting\nin prohibitive computational costs as the number of views or image resolution\nincreases. Toward a scalable and efficient feed-forward 3D reconstruction, we\nintroduce an iterative Large 3D Reconstruction Model (iLRM) that generates 3D\nGaussian representations through an iterative refinement mechanism, guided by\nthree core principles: (1) decoupling the scene representation from input-view\nimages to enable compact 3D representations; (2) decomposing fully-attentional\nmulti-view interactions into a two-stage attention scheme to reduce\ncomputational costs; and (3) injecting high-resolution information at every\nlayer to achieve high-fidelity reconstruction. Experimental results on widely\nused datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms\nexisting methods in both reconstruction quality and speed. Notably, iLRM\nexhibits superior scalability, delivering significantly higher reconstruction\nquality under comparable computational cost by efficiently leveraging a larger\nnumber of input views.", "comment": "Project page: https://gynjn.github.io/iLRM/", "pdf_url": "http://arxiv.org/pdf/2507.23277v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "iLRM: 一种迭代式大型3D重建模型", "tldr": "iLRM是一种迭代式大型3D重建模型，通过解耦场景表示、分解多视图交互和注入高分辨率信息，有效解决了现有前馈3D建模方法的可扩展性问题，并在重建质量和速度上表现优异。", "motivation": "现有前馈3D建模方法，特别是基于Transformer架构的方法，在处理多视图输入时存在严重的可扩展性问题，因为它们依赖于跨图像token的完全注意力机制，导致计算成本随视图数量或图像分辨率的增加而急剧上升。", "method": "本研究提出了一种迭代式大型3D重建模型（iLRM），通过迭代细化机制生成3D高斯表示。其核心原则包括：1) 解耦场景表示与输入视图图像，以实现紧凑的3D表示；2) 将完全注意力的多视图交互分解为两阶段注意力方案，以降低计算成本；3) 在每一层注入高分辨率信息，以实现高保真重建。", "result": "在RE10K和DL3DV等广泛使用的数据集上的实验结果表明，iLRM在重建质量和速度方面均优于现有方法。值得注意的是，iLRM展现出卓越的可扩展性，在可比的计算成本下，通过有效利用更多输入视图，提供了显著更高的重建质量。", "conclusion": "iLRM通过其迭代细化机制和核心设计原则，成功克服了前馈3D重建中存在的规模化挑战，并在多个关键性能指标上超越了现有技术，尤其在处理大量输入视图时表现出优越的可扩展性。", "translation": "前馈3D建模已成为一种有前途的快速高质量3D重建方法。特别是，直接生成显式3D表示，例如3D高斯泼溅，因其快速高质量的渲染以及众多应用而引起了广泛关注。然而，许多最先进的方法，主要基于Transformer架构，由于它们依赖于跨多个输入视图的图像token进行完全注意力计算，导致随着视图数量或图像分辨率的增加，计算成本高得令人望步，因此面临严重的可扩展性问题。为了实现可扩展且高效的前馈3D重建，我们引入了一种迭代式大型3D重建模型（iLRM），该模型通过迭代细化机制生成3D高斯表示，并遵循三个核心原则：(1) 将场景表示与输入视图图像解耦，以实现紧凑的3D表示；(2) 将完全注意力的多视图交互分解为两阶段注意力方案，以降低计算成本；(3) 在每一层注入高分辨率信息，以实现高保真重建。在RE10K和DL3DV等广泛使用的数据集上的实验结果表明，iLRM在重建质量和速度方面均优于现有方法。值得注意的是，iLRM展现出卓越的可扩展性，在可比的计算成本下，通过有效利用更多输入视图，提供了显著更高的重建质量。", "summary": "本论文提出了一种名为iLRM的迭代式大型3D重建模型，旨在解决现有前馈3D建模方法在可扩展性方面的挑战。iLRM通过解耦场景表示、分解多视图注意力为两阶段机制以及在各层注入高分辨率信息等核心原则，有效地生成高质量的3D高斯表示。实验证明，iLRM在重建质量、速度和可扩展性方面均优于现有方法，尤其在处理大量输入视图时表现出卓越的性能。", "keywords": "3D重建, 高斯泼溅, 可扩展性, 迭代模型, 前馈建模", "comments": "iLRM的创新之处在于其迭代细化机制和三个核心设计原则，这些原则共同解决了前馈3D重建领域长期存在的可扩展性问题。通过优化多视图交互和表示方式，该模型显著提升了3D重建的效率和质量，尤其在大规模场景和多视图输入下的应用前景广阔。其对3D高斯泼溅的利用也体现了对新兴高效渲染技术的整合。"}}
{"id": "2507.23676", "title": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "authors": ["Rabeya Tus Sadia", "Qiang Cheng"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23676v1", "summary": "Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23676v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DepMicroDiff：基于扩散的依赖感知多模态微生物组数据插补", "tldr": "DepMicroDiff是一个新的基于扩散的模型，通过结合依赖感知Transformer和多模态数据，显著提高了微生物组数据的插补精度。", "motivation": "微生物组数据固有的稀疏性和噪声对准确插补构成重大挑战，阻碍了生物标志物发现等下游任务。现有方法未能捕捉复杂的微生物类群间相互依赖性，并忽视了可为插补提供信息的上下文元数据。", "method": "引入DepMicroDiff，一个结合了基于扩散的生成建模与依赖感知Transformer (DAT) 的新型框架，以明确捕捉相互成对依赖和自回归关系。通过基于VAE的预训练和通过大型语言模型 (LLM) 编码的患者元数据进行条件化，进一步增强了DepMicroDiff。", "result": "在TCGA微生物组数据集上的实验表明，DepMicroDiff显著优于最先进的基线方法，在多种癌症类型中实现了更高的皮尔逊相关性 (高达0.712)、余弦相似度 (高达0.812)，以及更低的RMSE和MAE。", "conclusion": "DepMicroDiff在微生物组数据插补方面表现出强大的鲁棒性和泛化能力。", "translation": "微生物组数据分析对于理解宿主健康和疾病至关重要，但其固有的稀疏性和噪声对准确插补构成了重大挑战，阻碍了生物标志物发现等下游任务。现有的插补方法，包括最近基于扩散的模型，往往未能捕捉微生物类群之间复杂的相互依赖性，并忽视了可以为插补提供信息的上下文元数据。我们引入了DepMicroDiff，这是一个结合了基于扩散的生成建模与依赖感知Transformer (DAT) 的新型框架，以明确捕捉相互成对依赖和自回归关系。DepMicroDiff通过在不同癌症数据集上进行基于VAE的预训练，以及通过大型语言模型 (LLM) 编码的患者元数据进行条件化，得到了进一步增强。在TCGA微生物组数据集上的实验表明，DepMicroDiff显著优于最先进的基线方法，在多种癌症类型中实现了更高的皮尔逊相关性 (高达0.712)、余弦相似度 (高达0.812)，以及更低的RMSE和MAE，证明了其在微生物组插补方面的鲁棒性和泛化能力。", "summary": "DepMicroDiff是一种新颖的基于扩散的生成模型，专为解决微生物组数据插补中的稀疏性和噪声问题而设计。它通过引入依赖感知Transformer (DAT) 来捕捉微生物类群间的复杂依赖关系，并通过VAE预训练和LLM编码的患者元数据进行多模态信息融合。实验证明，DepMicroDiff在TCGA微生物组数据集上显著优于现有方法，在皮尔逊相关性、余弦相似度、RMSE和MAE等指标上均表现出色，展现了其在微生物组数据插补方面的强大性能和泛化能力。", "keywords": "微生物组数据, 数据插补, 扩散模型, 依赖感知Transformer, 多模态", "comments": "DepMicroDiff的创新之处在于其将扩散模型与依赖感知Transformer相结合，以有效捕捉微生物数据中复杂的相互依赖性，并首次整合了患者元数据（通过LLM编码）进行多模态插补，这为微生物组数据分析提供了更全面和准确的解决方案。其在多个指标上超越现有SOTA的性能，显示了其在生物标志物发现等下游任务中的巨大潜力。"}}
{"id": "2507.23099", "title": "Hybrid Shifted Gegenbauer Integral-Pseudospectral Method for Solving Time-Fractional Benjamin-Bona-Mahony-Burgers Equation", "authors": ["Kareem T. Elgindy"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23099v1", "summary": "This paper presents a high-order hybrid shifted Gegenbauer\nintegral-pseudospectral (HSG-IPS) method for solving the time-fractional\nBenjamin-Bona-Mahony-Burgers (FBBMB) equation. A key innovation of our approach\nis the transformation of the original equation into a fractional\npartial-integro differential form that contains only a first-order derivative,\nwhich can be accurately approximated using a first-order shifted Gegenbauer\ndifferentiation matrix (SGDM), while all other terms in the transformed\nequation are resolved using highly accurate quadrature rules. The method\ncombines several advanced numerical techniques including the shifted Gegenbauer\npseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA),\nshifted Gegenbauer integration matrix (SGIM), shifted Gegenbauer integration\nrow vector (SGIRV), and SGDM to achieve spectral accuracy. Numerical\nexperiments demonstrate that the HSG-IPS method outperforms existing numerical\napproaches, achieving significantly lower average absolute errors (AAEs) with\ncomputational times as low as 0.04-0.05 seconds. The method's robustness is\nvalidated across various fractional orders, showing excellent agreement with\nanalytical solutions. The transformation strategy effectively circumvents the\nnumerical instability associated with direct approximation of high-order\nderivatives in the original equation, while the use of shifted Gegenbauer (SG)\npolynomials and barycentric representations ensures numerical stability and\nefficiency. This work provides a powerful computational framework for modeling\nwave propagation, dispersion, and nonlinearity in fractional calculus\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23099v1", "cate": "math.NA", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "求解时间分数阶Benjamin-Bona-Mahony-Burgers方程的混合移位Gegenbauer积分-伪谱方法", "tldr": "本文提出了一种混合移位Gegenbauer积分-伪谱（HSG-IPS）方法，用于高效准确地求解时间分数阶Benjamin-Bona-Mahony-Burgers（FBBMB）方程，通过方程变换和结合多种数值技术，实现了高精度和鲁棒性。", "motivation": "解决时间分数阶Benjamin-Bona-Mahony-Burgers (FBBMB) 方程的数值求解问题，并克服现有数值方法在精度、效率和稳定性方面的局限性，特别是避免直接逼近高阶导数带来的数值不稳定性。", "method": "提出了一种混合移位Gegenbauer积分-伪谱 (HSG-IPS) 方法。核心创新是将原始方程转换为只包含一阶导数的分数阶偏积分微分形式。该方法结合了移位Gegenbauer伪谱 (SGPS) 方法、基于Gegenbauer的分数阶逼近 (GBFA)、移位Gegenbauer积分矩阵 (SGIM)、移位Gegenbauer积分行向量 (SGIRV) 和移位Gegenbauer微分矩阵 (SGDM)，利用一阶移位Gegenbauer微分矩阵精确逼近一阶导数，并通过高精度求积规则处理其他项。", "result": "HSG-IPS方法在数值实验中表现优于现有数值方法，实现了显著更低的平均绝对误差 (AAE)，计算时间低至0.04-0.05秒。该方法在各种分数阶下均表现出鲁棒性，与解析解高度吻合。方程变换策略有效规避了原始方程中直接逼近高阶导数相关的数值不稳定性。", "conclusion": "HSG-IPS方法为时间分数阶Benjamin-Bona-Mahony-Burgers方程提供了一个强大、高效且稳定的计算框架，适用于分数阶微积分应用中的波传播、色散和非线性建模。", "translation": "本文提出了一种高阶混合移位Gegenbauer积分-伪谱（HSG-IPS）方法，用于求解时间分数阶Benjamin-Bona-Mahony-Burgers（FBBMB）方程。我们方法的关键创新是将原始方程转换为只包含一阶导数的分数阶偏积分微分形式，这可以通过一阶移位Gegenbauer微分矩阵（SGDM）精确逼近，而转换方程中的所有其他项则使用高精度求积规则来解决。该方法结合了多种先进的数值技术，包括移位Gegenbauer伪谱（SGPS）方法、基于Gegenbauer的分数阶逼近（GBFA）、移位Gegenbauer积分矩阵（SGIM）、移位Gegenbauer积分行向量（SGIRV）和SGDM，以实现谱精度。数值实验表明，HSG-IPS方法优于现有数值方法，在计算时间低至0.04-0.05秒的情况下，实现了显著更低的平均绝对误差（AAE）。该方法的鲁棒性在各种分数阶下得到了验证，显示出与解析解极好的一致性。变换策略有效规避了原始方程中直接逼近高阶导数相关的数值不稳定性，而移位Gegenbauer（SG）多项式和重心表示的使用确保了数值稳定性和效率。这项工作为分数阶微积分应用中波传播、色散和非线性建模提供了一个强大的计算框架。", "summary": "本文提出了一种高阶混合移位Gegenbauer积分-伪谱（HSG-IPS）方法，用于求解时间分数阶Benjamin-Bona-Mahony-Burgers（FBBMB）方程。该方法通过将原始方程转换为仅含一阶导数的形式，并结合移位Gegenbauer多项式、积分和微分矩阵等多种先进数值技术，实现了高精度和鲁棒性。数值实验表明，HSG-IPS方法在计算效率和误差方面均优于现有方法，为分数阶微积分中的波传播建模提供了有效工具。", "keywords": "时间分数阶方程, Benjamin-Bona-Mahony-Burgers方程, 混合移位Gegenbauer方法, 积分-伪谱方法, 谱精度", "comments": "该论文的主要创新在于其独特的方程变换策略，将复杂的分数阶偏微分方程转化为更易于处理的形式，有效避免了高阶导数带来的数值不稳定性。同时，结合多种成熟的Gegenbauer基数值技术，确保了方法的谱精度和计算效率，为分数阶微积分方程的数值求解提供了强大的新工具。"}}
{"id": "2503.04351", "title": "PLMP -- Point-Line Minimal Problems for Projective SfM", "authors": ["Kim Kiehn", "Albin Ahlbäck", "Kathlén Kohn"], "categories": ["cs.CV", "math.AG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04351v2", "summary": "We completely classify all minimal problems for Structure-from-Motion (SfM)\nwhere arrangements of points and lines are fully observed by multiple\nuncalibrated pinhole cameras. We find 291 minimal problems, 73 of which have\nunique solutions and can thus be solved linearly. Two of the linear problems\nallow an arbitrary number of views, while all other minimal problems have at\nmost 9 cameras. All minimal problems have at most 7 points and at most 12\nlines. We compute the number of solutions of each minimal problem, as this\ngives a measurement of the problem's intrinsic difficulty, and find that these\nnumber are relatively low (e.g., when comparing with minimal problems for\ncalibrated cameras). Finally, by exploring stabilizer subgroups of\nsubarrangements, we develop a geometric and systematic way to 1) factorize\nminimal problems into smaller problems, 2) identify minimal problems in\nunderconstrained problems, and 3) formally prove non-minimality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04351v2", "cate": "cs.CV", "date": "2025-03-06", "updated": "2025-07-31", "AI": {"title_translation": "PLMP -- 射影SfM中的点线最小问题", "tldr": "该论文全面分类了由未校准相机观察点和线在SfM中的所有最小问题，共发现291个，并开发了一种几何方法来分解、识别和证明问题的非最小性。", "motivation": "本研究旨在完全分类结构-运动(SfM)中的所有最小问题，这些问题涉及由多个未校准针孔相机完整观察到的点和线排列。", "method": "作者对最小问题进行了分类，计算了它们的解的数量，并通过探索子排列的稳定子群，开发了一种几何和系统的方法来分解、识别和证明问题的非最小性。", "result": "研究发现了291个最小问题，其中73个具有唯一解或可线性求解。其中两个线性问题支持任意数量的视图，而其他问题最多涉及9个相机。所有最小问题最多包含7个点和12条线。每个最小问题的解数相对较低。此外，开发了一种几何方法来分解最小问题、识别欠约束问题中的最小问题以及正式证明非最小性。", "conclusion": "该论文提供了射影SfM中点线最小问题的完整分类，明确了它们的特性和解的数量，并提出了一种系统的问题分析方法。", "translation": "我们完全分类了结构-运动(SfM)中的所有最小问题，其中点和线的排列由多个未校准的针孔相机完全观察到。我们发现了291个最小问题，其中73个具有唯一解，因此可以线性求解。其中两个线性问题允许任意数量的视图，而所有其他最小问题最多有9个相机。所有最小问题最多有7个点和最多12条线。我们计算了每个最小问题的解的数量，因为这提供了问题内在难度的度量，并发现这些数量相对较低（例如，与校准相机中的最小问题相比）。最后，通过探索子排列的稳定子群，我们开发了一种几何和系统的方法来1）将最小问题分解为更小的问题，2）识别欠约束问题中的最小问题，以及3）正式证明非最小性。", "summary": "本文全面分类了在未校准相机下观察点和线的结构-运动（SfM）中的最小问题。研究识别出291个此类问题，并指出其所需的视图、点、线数量以及相对较低的解数等特性。此外，论文引入了一种基于稳定子群的新颖几何方法，用于分解、识别和证明这些问题的非最小性。", "keywords": "结构-运动, 最小问题, 点线, 未校准相机, 射影几何", "comments": "这篇论文通过系统地分类和分析涉及点和线的最小问题，尤其是在未校准相机设置下，对结构-运动领域做出了重要贡献。线性可解问题的识别和几何分解方法的开发具有特别的创新性，为鲁棒的SfM解决方案提供了新途径。对问题特征（视图、点、线、解数）的详细枚举对于未来的研究和实际应用具有高度价值。"}}
{"id": "2504.13201", "title": "CEE: An Inference-Time Jailbreak Defense for Embodied Intelligence via Subspace Concept Rotation", "authors": ["Jirui Yang", "Zheyu Lin", "Zhihui Lu", "Yinggui Wang", "Lei Wang", "Tao Wei", "Xin Du", "Shuhan Yang"], "categories": ["cs.CR", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13201v2", "summary": "Large Language Models (LLMs) are increasingly becoming the cognitive core of\nEmbodied Intelligence (EI) systems, such as robots and autonomous vehicles.\nHowever, this integration also exposes them to serious jailbreak risks, where\nmalicious instructions can be transformed into dangerous physical actions.\nExisting defense mechanisms suffer from notable drawbacks--including high\ntraining costs, significant inference delays, and complex hyperparameter\ntuning--which limit their practical applicability. To address these challenges,\nwe propose a novel and efficient inference-time defense framework: Concept\nEnhancement Engineering (CEE). CEE enhances the model's inherent safety\nmechanisms by directly manipulating its internal representations, requiring\nneither additional training nor external modules, thereby improving defense\nefficiency. Furthermore, CEE introduces a rotation-based control mechanism that\nenables stable and linearly tunable behavioral control of the model. This\ndesign eliminates the need for tedious manual tuning and avoids the output\ndegradation issues commonly observed in other representation engineering\nmethods. Extensive experiments across multiple EI safety benchmarks and diverse\nattack scenarios demonstrate that CEE significantly improves the defense\nsuccess rates of various multimodal LLMs. It effectively mitigates safety risks\nwhile preserving high-quality generation and inference efficiency, offering a\npromising solution for deploying safer embodied intelligence systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13201v2", "cate": "cs.CR", "date": "2025-04-15", "updated": "2025-07-31", "AI": {"title_translation": "CEE：一种基于子空间概念旋转的具身智能推理时越狱防御方法", "tldr": "CEE是一种无需训练、高效的推理时防御框架，通过直接操作LLM内部表示来防御具身智能系统中的越狱攻击，同时保持性能。", "motivation": "现有防御机制存在高训练成本、显著推理延迟和复杂超参数调整等缺点，限制了其实用性，且大型语言模型与具身智能结合带来了恶意指令转化为危险物理行动的越狱风险。", "method": "提出CEE框架，通过直接操纵模型内部表示来增强模型固有的安全机制，无需额外训练或外部模块。引入基于旋转的控制机制，实现模型行为的稳定和线性可调控制，避免手动调整和输出退化。", "result": "在多个EI安全基准和不同攻击场景下，CEE显著提高了各种多模态LLM的防御成功率，有效缓解了安全风险，同时保持了高质量生成和推理效率。", "conclusion": "CEE为部署更安全的具身智能系统提供了一个有前景的解决方案。", "translation": "大型语言模型（LLMs）正日益成为具身智能（EI）系统（如机器人和自动驾驶汽车）的认知核心。然而，这种集成也使它们面临严重的越狱风险，恶意指令可能转化为危险的物理行动。现有防御机制存在显著缺点——包括高训练成本、显著推理延迟和复杂的超参数调整——这限制了其实际适用性。为了解决这些挑战，我们提出了一种新颖高效的推理时防御框架：概念增强工程（CEE）。CEE通过直接操纵模型内部表示来增强模型固有的安全机制，既不需要额外训练也不需要外部模块，从而提高了防御效率。此外，CEE引入了一种基于旋转的控制机制，能够实现模型行为的稳定和线性可调控制。这种设计消除了繁琐的手动调整需求，并避免了其他表示工程方法中常见的输出退化问题。在多个EI安全基准和不同攻击场景下进行的大量实验表明，CEE显著提高了各种多模态LLM的防御成功率。它在有效缓解安全风险的同时，保持了高质量的生成和推理效率，为部署更安全的具身智能系统提供了一个有前景的解决方案。", "summary": "本文提出了一种名为概念增强工程（CEE）的新型推理时防御框架，旨在解决大型语言模型（LLMs）在具身智能（EI）系统中面临的越狱攻击风险。CEE通过直接操纵LLM的内部表示来增强其安全机制，无需额外训练或外部模块，并引入了基于旋转的控制机制以实现稳定和线性的行为控制，避免了手动调整和输出退化。实验证明，CEE在多种攻击场景下显著提高了多模态LLM的防御成功率，同时保持了高性能和推理效率，为部署更安全的EI系统提供了有效方案。", "keywords": "具身智能, 越狱防御, 大型语言模型, 推理时防御, 概念增强工程", "comments": "CEE的创新之处在于其推理时防御的特性，无需额外的训练成本和复杂的超参数调整，解决了现有方法的主要局限。通过直接操纵模型内部表示并引入旋转控制机制，它在提高防御效率的同时避免了输出质量下降，为具身智能的安全部署提供了实用的解决方案。"}}
{"id": "2507.22903", "title": "A blessing or a burden? Exploring worker perspectives of using a social robot in a church", "authors": ["Andrew Blair", "Peggy Gregory", "Mary Ellen Foster"], "categories": ["cs.HC", "cs.RO"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted by the 2025 34th IEEE International Conference on Robot and Human Interactive Communication (ROMAN)", "url": "http://arxiv.org/abs/2507.22903v1", "summary": "Recent technological advances have allowed robots to assist in the service\nsector, and consequently accelerate job and sector transformation. Less\nattention has been paid to the use of robots in real-world organisations where\nsocial benefits, as opposed to profits, are the primary motivator. To explore\nthese opportunities, we have partnered with a working church and visitor\nattraction. We conducted interviews with 15 participants from a range of\nstakeholder groups within the church to understand worker perspectives of\nintroducing a social robot to the church and analysed the results using\nreflexive thematic analysis. Findings indicate mixed responses to the use of a\nrobot, with participants highlighting the empathetic responsibility the church\nhas towards people and the potential for unintended consequences. However,\ninformation provision and alleviation of menial or mundane tasks were\nidentified as potential use cases. This highlights the need to consider not\nonly the financial aspects of robot introduction, but also how social and\nintangible values shape what roles a robot should take on within an\norganisation.", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (ROMAN)", "pdf_url": "http://arxiv.org/pdf/2507.22903v1", "cate": "cs.HC", "date": "2025-06-28", "updated": "2025-06-28", "AI": {"title_translation": "是福是祸？探索工作人员在教堂使用社交机器人的看法", "tldr": "本文探讨了教堂工作人员对引入社交机器人的看法，发现回应褒贬不一，既有对同理心责任和潜在意外后果的担忧，也有在信息提供和琐碎任务缓解方面的潜在应用。研究强调在引入机器人时需考虑社会和无形价值。", "motivation": "机器人技术在服务业的应用日益广泛，并加速了就业和行业转型。然而，在以社会效益而非利润为主要驱动力的真实组织中，机器人使用的关注度较低。本文旨在探索机器人在教堂这类以社会效益为目标的组织中的应用机会。", "method": "研究团队与一个正在运营的教堂和旅游景点合作，对来自教堂内不同利益相关者群体的15名参与者进行了访谈，以了解他们对在教堂引入社交机器人的看法。访谈结果采用反思性主题分析法进行分析。", "result": "研究结果显示，受访者对使用机器人持复杂态度。参与者强调教堂对人的同理心责任以及可能出现的意外后果。然而，信息提供和减轻琐碎或日常任务被认为是潜在的使用场景。", "conclusion": "研究强调，在引入机器人时，不仅要考虑财务方面，还需要考虑社会和无形价值如何塑造机器人在组织中应扮演的角色。", "translation": "最近的技术进步使得机器人能够协助服务部门，并因此加速了就业和行业的转型。然而，对于机器人在以社会效益而非利润为主要驱动力的真实组织中的使用，关注度较低。为了探索这些机会，我们与一个正在运营的教堂和旅游景点合作。我们对教堂内一系列利益相关者群体的15名参与者进行了访谈，以了解工作人员对在教堂引入社交机器人的看法，并使用反思性主题分析法对结果进行了分析。研究结果表明，对机器人的使用反应褒贬不一，参与者强调教堂对人的同理心责任以及潜在的意外后果。然而，信息提供和减轻琐碎或日常任务被认为是潜在的使用场景。这突出表明，在引入机器人时，不仅要考虑财务方面，还需要考虑社会和无形价值如何塑造机器人在组织中应扮演的角色。", "summary": "本研究探讨了在教堂环境中引入社交机器人的工作人员视角，这是一个以社会效益而非利润为导向的独特场景。通过对15名教堂利益相关者的访谈，研究发现受访者对机器人的接受度复杂，既有对教堂同理心责任和潜在负面影响的担忧，也看到了机器人在信息提供和日常任务辅助方面的潜力。研究强调，在非营利组织中部署机器人时，除了经济考量，社会和无形价值同样至关重要。", "keywords": "社交机器人, 教堂, 工作人员视角, 人机交互, 非营利组织", "comments": "该论文将机器人部署的探讨扩展到非营利和以社会价值为导向的独特场景（教堂），这与传统上侧重于利润的机器人应用研究形成对比，具有创新性。它揭示了在情感敏感环境中人机交互的复杂性，并强调了除财务因素外，对社会和无形价值的深入考量在机器人角色设计中的重要性。"}}
{"id": "2507.22252", "title": "Multidimensional Assessment of Takeover Performance in Conditionally Automated Driving", "authors": ["Kexin Liang", "Jan Luca Kästle", "Bani Anvari", "Simeon C. Calvert", "J. W. C. van Lint"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22252v2", "summary": "When automated driving systems encounter complex situations beyond their\noperational capabilities, they issue takeover requests, prompting drivers to\nresume vehicle control and return to the driving loop as a critical safety\nbackup. However, this control transition places significant demands on drivers,\nrequiring them to promptly respond to takeover requests while executing\nhigh-quality interventions. To ensure safe and comfortable control transitions,\nit is essential to develop a deep understanding of the key factors influencing\nvarious takeover performance aspects. This study evaluates drivers' takeover\nperformance across three dimensions: response efficiency, user experience, and\ndriving safety - using a driving simulator experiment. EXtreme Gradient\nBoosting (XGBoost) models are used to investigate the contributions of two\ncritical factors, i.e., Situational Awareness (SA) and Spare Capacity (SC), in\npredicting various takeover performance metrics by comparing the predictive\nresults to the baseline models that rely solely on basic Driver Characteristics\n(DC). The results reveal that (i) higher SA enables drivers to respond to\ntakeover requests more quickly, particularly for reflexive responses; and (ii)\nSC shows a greater overall impact on takeover quality than SA, where higher SC\ngenerally leads to enhanced subjective rating scores and objective execution\ntrajectories. These findings highlight the distinct yet complementary roles of\nSA and SC in shaping performance components, offering valuable insights for\noptimizing human-vehicle interactions and enhancing automated driving system\ndesign.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22252v2", "cate": "cs.HC", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "有条件自动驾驶中接管性能的多维评估", "tldr": "本研究使用驾驶模拟器和XGBoost模型，评估了驾驶员在有条件自动驾驶中的接管性能，并探究了态势感知（SA）和备用能力（SC）对响应效率、用户体验和驾驶安全的影响。", "motivation": "当自动驾驶系统遇到超出其操作能力范围的复杂情况时，会发出接管请求，要求驾驶员恢复车辆控制。这种控制转换对驾驶员提出了很高的要求，需要他们迅速响应并高质量地干预。为了确保安全舒适的控制转换，深入理解影响接管性能各个方面的关键因素至关重要。", "method": "本研究通过驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估了驾驶员的接管性能。研究使用了极端梯度提升（XGBoost）模型来调查态势感知（SA）和备用能力（SC）这两个关键因素在预测各种接管性能指标方面的贡献，并将其预测结果与仅依赖基本驾驶员特征（DC）的基线模型进行了比较。", "result": "研究结果表明：(i) 较高的态势感知（SA）能使驾驶员更快地响应接管请求，特别是对于反射性响应；(ii) 备用能力（SC）对整体接管质量的影响大于态势感知（SA），其中较高的SC通常会带来更高的主观评分和更优的客观执行轨迹。", "conclusion": "研究结果突出了态势感知（SA）和备用能力（SC）在塑造性能组成部分方面各自独特而又互补的作用，为优化人车交互和增强自动驾驶系统设计提供了宝贵的见解。", "translation": "当自动驾驶系统遇到超出其操作能力范围的复杂情况时，它们会发出接管请求，促使驾驶员恢复车辆控制并返回驾驶循环，作为关键的安全备份。然而，这种控制转换对驾驶员提出了很高的要求，需要他们迅速响应接管请求，同时执行高质量的干预。为了确保安全舒适的控制转换，深入理解影响接管性能各个方面的关键因素至关重要。本研究通过驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估了驾驶员的接管性能。研究使用了极端梯度提升（XGBoost）模型来调查态势感知（SA）和备用能力（SC）这两个关键因素在预测各种接管性能指标方面的贡献，并将其预测结果与仅依赖基本驾驶员特征（DC）的基线模型进行了比较。结果显示：(i) 较高的SA能使驾驶员更快地响应接管请求，特别是对于反射性响应；(ii) SC对整体接管质量的影响大于SA，其中较高的SC通常会带来更高的主观评分和客观执行轨迹。这些发现突出了SA和SC在塑造性能组成部分方面各自独特而又互补的作用，为优化人车交互和增强自动驾驶系统设计提供了宝贵的见解。", "summary": "本研究旨在深入理解影响自动驾驶系统接管性能的关键因素。通过驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估了驾驶员的接管表现。研究采用XGBoost模型，探究了态势感知（SA）和备用能力（SC）对各项接管指标的贡献，并与仅基于驾驶员特征（DC）的基线模型进行了对比。结果表明，SA有助于提高响应速度，特别是反射性响应；而SC对整体接管质量的影响更为显著。这些发现强调了SA和SC在人车交互和自动驾驶系统设计优化中的重要且互补的作用。", "keywords": "接管性能, 有条件自动驾驶, 态势感知, 备用能力, 人车交互", "comments": "该研究通过多维度评估和先进的机器学习模型（XGBoost），深入分析了影响有条件自动驾驶中驾驶员接管性能的关键因素（SA和SC），提供了超越传统驾驶员特征的更精细的洞察。其创新性在于明确区分并量化了SA和SC在不同接管性能维度上的影响，为未来人机交互设计和自动驾驶系统优化提供了具体指导。"}}
{"id": "2507.23371", "title": "VMatcher: State-Space Semi-Dense Local Feature Matching", "authors": ["Ali Youssef"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23371v1", "summary": "This paper introduces VMatcher, a hybrid Mamba-Transformer network for\nsemi-dense feature matching between image pairs. Learning-based feature\nmatching methods, whether detector-based or detector-free, achieve\nstate-of-the-art performance but depend heavily on the Transformer's attention\nmechanism, which, while effective, incurs high computational costs due to its\nquadratic complexity. In contrast, Mamba introduces a Selective State-Space\nModel (SSM) that achieves comparable or superior performance with linear\ncomplexity, offering significant efficiency gains. VMatcher leverages a hybrid\napproach, integrating Mamba's highly efficient long-sequence processing with\nthe Transformer's attention mechanism. Multiple VMatcher configurations are\nproposed, including hierarchical architectures, demonstrating their\neffectiveness in setting new benchmarks efficiently while ensuring robustness\nand practicality for real-time applications where rapid inference is crucial.\nSource Code is available at: https://github.com/ayoussf/VMatcher", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23371v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "VMatcher：状态空间半密集局部特征匹配", "tldr": "VMatcher是一种混合Mamba-Transformer网络，用于半密集特征匹配，通过结合Mamba的线性复杂度和Transformer的注意力机制，实现了高效且高性能的特征匹配。", "motivation": "现有的基于学习的特征匹配方法虽然性能卓越，但高度依赖Transformer的注意力机制，其二次复杂度导致计算成本高昂。", "method": "论文提出了VMatcher，一个混合Mamba-Transformer网络，用于图像对之间的半密集特征匹配。它结合了Mamba高效的长序列处理能力（线性复杂度）和Transformer的注意力机制。论文还提出了多种VMatcher配置，包括分层架构。", "result": "VMatcher在效率上设定了新的基准，同时确保了实时应用的鲁棒性和实用性，尤其适用于需要快速推理的场景。", "conclusion": "Not mentioned in abstract", "translation": "本文介绍了VMatcher，一种用于图像对之间半密集特征匹配的混合Mamba-Transformer网络。基于学习的特征匹配方法，无论是基于检测器的还是无检测器的，都达到了最先进的性能，但它们严重依赖Transformer的注意力机制。尽管Transformer有效，但其二次复杂度会带来高昂的计算成本。相比之下，Mamba引入了一种选择性状态空间模型（SSM），以线性复杂度实现了可比或更优的性能，显著提高了效率。VMatcher利用一种混合方法，将Mamba高效的长序列处理能力与Transformer的注意力机制相结合。论文提出了多种VMatcher配置，包括分层架构，证明了它们在高效设定新基准方面的有效性，同时确保了实时应用中的鲁棒性和实用性，而快速推理在这些应用中至关重要。源代码可在：https://github.com/ayoussf/VMatcher 获取。", "summary": "本文提出VMatcher，一种创新的混合Mamba-Transformer网络，专为图像对之间的半密集特征匹配设计。针对现有Transformer模型在特征匹配中计算成本高的问题，VMatcher巧妙结合了Mamba模型的线性复杂度和Transformer的注意力优势，旨在实现高效且高性能的特征匹配。研究展示了VMatcher（包括其分层配置）不仅在性能上设立了新基准，还在保证鲁棒性的同时，为实时应用提供了实用的快速推理能力。", "keywords": "特征匹配, Mamba, Transformer, 混合网络, 状态空间模型", "comments": "这篇论文的创新点在于其混合架构，将Mamba模型的线性复杂度和Transformer的注意力机制相结合，有效地解决了传统Transformer在特征匹配中计算成本过高的问题。这种方法对于需要快速推理的实时应用具有重要意义，显示了在保持高性能的同时提升效率的潜力。"}}
{"id": "2507.21875", "title": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21875v3", "summary": "Pain is a complex and pervasive condition that affects a significant portion\nof the population. Accurate and consistent assessment is essential for\nindividuals suffering from pain, as well as for developing effective management\nstrategies in a healthcare system. Automatic pain assessment systems enable\ncontinuous monitoring, support clinical decision-making, and help minimize\npatient distress while mitigating the risk of functional deterioration.\nLeveraging physiological signals offers objective and precise insights into a\nperson's state, and their integration in a multimodal framework can further\nenhance system performance. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed approach introduces \\textit{Tiny-BioMoE}, a lightweight pretrained\nembedding model for biosignal analysis. Trained on $4.4$ million biosignal\nimage representations and consisting of only $7.3$ million parameters, it\nserves as an effective tool for extracting high-quality embeddings for\ndownstream tasks. Extensive experiments involving electrodermal activity, blood\nvolume pulse, respiratory signals, peripheral oxygen saturation, and their\ncombinations highlight the model's effectiveness across diverse modalities in\nautomatic pain recognition tasks. \\textit{\\textcolor{blue}{The model's\narchitecture (code) and weights are available at\nhttps://github.com/GkikasStefanos/Tiny-BioMoE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21875v3", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "Tiny-BioMoE：一种用于生物信号分析的轻量级嵌入模型", "tldr": "Tiny-BioMoE是一种轻量级预训练嵌入模型，用于生物信号分析，旨在通过提取高质量嵌入来改进自动疼痛评估系统。", "motivation": "疼痛是一种复杂且普遍的状况，准确一致的评估对于患者和有效的医疗管理至关重要。自动疼痛评估系统能够持续监测、支持临床决策并减少患者痛苦，而利用生理信号可以提供客观精确的洞察。", "method": "本研究提出了一种名为Tiny-BioMoE的轻量级预训练嵌入模型，用于生物信号分析。该模型在440万个生物信号图像表示上进行训练，仅包含730万个参数，旨在为下游任务提取高质量的嵌入。模型架构和权重已公开。", "result": "涉及电皮活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合的广泛实验表明，该模型在自动疼痛识别任务中对不同模态均有效。", "conclusion": "Tiny-BioMoE模型作为一种轻量级预训练嵌入工具，能够有效提取生物信号的高质量嵌入，从而提升自动疼痛评估系统的性能。", "translation": "疼痛是一种复杂且普遍的病症，影响着相当一部分人口。对于遭受疼痛的个体以及在医疗保健系统中制定有效的管理策略而言，准确和一致的评估至关重要。自动疼痛评估系统能够实现持续监测，支持临床决策，并有助于最大限度地减少患者痛苦，同时降低功能恶化的风险。利用生理信号可以提供对个体状态的客观和精确洞察，并且将它们整合到多模态框架中可以进一步提高系统性能。本研究已提交给“第二届下一代疼痛评估多模态感知大挑战（AI4PAIN）”。所提出的方法引入了Tiny-BioMoE，这是一种用于生物信号分析的轻量级预训练嵌入模型。该模型在440万个生物信号图像表示上进行训练，仅包含730万个参数，是提取高质量嵌入以供下游任务使用的有效工具。涉及电皮活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合的广泛实验突出显示了该模型在自动疼痛识别任务中跨不同模态的有效性。该模型的架构（代码）和权重可在https://github.com/GkikasStefanos/Tiny-BioMoE获取。", "summary": "本研究提出了一种名为Tiny-BioMoE的轻量级预训练嵌入模型，旨在改善自动疼痛评估系统。该模型在440万个生物信号图像表示上训练，参数量仅730万，能够有效提取高质量的生物信号嵌入。实验结果表明，Tiny-BioMoE在处理多种生理信号（如电皮活动、血容量脉搏、呼吸信号、血氧饱和度）及其组合的自动疼痛识别任务中表现出良好的有效性。该模型的代码和权重已公开，为下游任务提供了有用的工具。", "keywords": "疼痛评估, 生物信号, 嵌入模型, 轻量级, 多模态", "comments": "Tiny-BioMoE通过其轻量级设计和在大量生物信号数据上的预训练，提供了一种高效且实用的解决方案，用于从多模态生理信号中提取高质量嵌入，这对于改进自动疼痛评估系统至关重要。其开源特性也促进了研究社区的进一步应用和发展。"}}
{"id": "2507.21568", "title": "Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages", "authors": ["Aarón Galiano-Jiménez", "Juan Antonio Pérez-Ortiz", "Felipe Sánchez-Martínez", "Víctor M. Sánchez-Cartagena"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      17 pages, 12 figures", "url": "http://arxiv.org/abs/2507.21568v2", "summary": "This paper explores sequence-level knowledge distillation (KD) of\nmultilingual pre-trained encoder-decoder translation models. We argue that the\nteacher model's output distribution holds valuable insights for the student,\nbeyond the approximated mode obtained through beam search (the standard\ndecoding method), and present Multi-Hypothesis Distillation (MHD), a\nsequence-level KD method that generates multiple translations for each source\nsentence. This provides a larger representation of the teacher model\ndistribution and exposes the student model to a wider range of target-side\nprefixes. We leverage $n$-best lists from beam search to guide the student's\nlearning and examine alternative decoding methods to address issues like low\nvariability and the under-representation of infrequent tokens. For low-resource\nlanguages, our research shows that while sampling methods may slightly\ncompromise translation quality compared to beam search based approaches, they\nenhance the generated corpora with greater variability and lexical richness.\nThis ultimately improves student model performance and mitigates the gender\nbias amplification often associated with KD.", "comment": "17 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.21568v2", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "多假设蒸馏多语言神经翻译模型用于低资源语言", "tldr": "本文提出多假设蒸馏（MHD）方法，通过生成多个翻译来利用教师模型更丰富的输出分布，从而提升低资源语言的学生模型性能并缓解性别偏见。", "motivation": "标准的束搜索方法只能近似教师模型的输出模式，而教师模型的完整输出分布对学生模型具有宝贵价值。特别是在低资源语言场景下，需要更有效的方法来利用教师模型的知识，并解决知识蒸馏可能导致的性别偏见放大问题。", "method": "提出多假设蒸馏（MHD），一种序列级知识蒸馏方法；为每个源语句生成多个翻译，以更全面地表示教师模型分布，并使学生模型接触更广泛的目标端前缀；利用束搜索的n-best列表来指导学生学习；研究替代解码方法（如采样）以解决低变异性和不常见词元表示不足的问题。", "result": "对于低资源语言，采样方法虽然可能略微降低翻译质量，但能增强生成语料库的变异性和词汇丰富度；这最终提高了学生模型的性能；缓解了知识蒸馏常伴随的性别偏见放大问题。", "conclusion": "多假设蒸馏通过利用教师模型更丰富的输出分布，特别是通过采样方法生成多样化假设，能有效提升低资源语言的翻译模型性能，并减轻知识蒸馏的负面影响，如性别偏见。", "translation": "本文探讨了多语言预训练编码器-解码器翻译模型的序列级知识蒸馏（KD）。我们认为，教师模型的输出分布对学生模型具有宝贵的见解，而不仅仅是通过束搜索（标准解码方法）获得的近似模式。我们提出了多假设蒸馏（MHD），这是一种序列级KD方法，它为每个源语句生成多个翻译。这提供了教师模型分布的更大表示，并使学生模型接触到更广泛的目标端前缀。我们利用束搜索的n-best列表来指导学生的学习，并研究了替代解码方法，以解决低变异性和不常见词元表示不足等问题。对于低资源语言，我们的研究表明，虽然采样方法与基于束搜索的方法相比可能略微损害翻译质量，但它们增强了生成语料库的更大变异性和词汇丰富度。这最终提高了学生模型性能，并缓解了知识蒸馏常伴随的性别偏见放大问题。", "summary": "本文探讨了多语言预训练编码器-解码器翻译模型的序列级知识蒸馏。研究提出多假设蒸馏（MHD），通过为每个源语句生成多个翻译，以更全面地利用教师模型的输出分布，而非仅依赖束搜索的近似模式。MHD利用n-best列表并探索了采样等替代解码方法，以增加语料库的变异性和词汇丰富度。实验结果表明，尽管采样可能略微影响翻译质量，但它显著提升了低资源语言学生模型的性能，并有效缓解了知识蒸馏中常见的性别偏见放大问题。", "keywords": "知识蒸馏, 多假设, 低资源语言, 神经机器翻译, 性别偏见", "comments": "本文的创新点在于提出了多假设蒸馏（MHD）方法，突破了传统知识蒸馏仅依赖束搜索单一最佳翻译的局限，通过引入多假设来更全面地利用教师模型的知识。尤其是在低资源语言场景下，这种方法不仅提升了模型性能，还解决了知识蒸馏可能加剧性别偏见的重要问题，具有重要的实践意义。"}}
{"id": "2507.01694", "title": "Graph Representation-based Model Poisoning on Federated Large Language Models", "authors": ["Hanlin Cai", "Haofan Dong", "Houtianfu Wang", "Kai Li", "Ozgur B. Akan"], "categories": ["cs.CR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures (Submitted to IEEE Communication Magazine)", "url": "http://arxiv.org/abs/2507.01694v2", "summary": "Federated large language models (FedLLMs) enable powerful generative\ncapabilities within wireless networks while preserving data privacy.\nNonetheless, FedLLMs remain vulnerable to model poisoning attacks. This article\nfirst reviews recent advancements in model poisoning techniques and existing\ndefense mechanisms for FedLLMs, underscoring critical limitations, especially\nwhen dealing with non-IID textual data distributions. Current defense\nstrategies predominantly employ distance or similarity-based outlier detection\nmechanisms, relying on the assumption that malicious updates markedly differ\nfrom benign statistical patterns. However, this assumption becomes inadequate\nagainst adaptive adversaries targeting billion-parameter LLMs. The article\nfurther investigates graph representation-based model poisoning (GRMP), an\nemerging attack paradigm that exploits higher-order correlations among benign\nclient gradients to craft malicious updates indistinguishable from legitimate\nones. GRMP can effectively circumvent advanced defense systems, causing\nsubstantial degradation in model accuracy and overall performance. Moreover,\nthe article outlines a forward-looking research roadmap that emphasizes the\nnecessity of graph-aware secure aggregation methods, specialized vulnerability\nmetrics tailored for FedLLMs, and evaluation frameworks to enhance the\nrobustness of federated language model deployments.", "comment": "7 pages, 5 figures (Submitted to IEEE Communication Magazine)", "pdf_url": "http://arxiv.org/pdf/2507.01694v2", "cate": "cs.CR", "date": "2025-07-02", "updated": "2025-07-31", "AI": {"title_translation": "基于图表示的联邦大语言模型模型中毒攻击", "tldr": "本文探讨了联邦大语言模型（FedLLMs）在模型中毒攻击下的脆弱性，并提出了一种新的基于图表示的模型中毒（GRMP）攻击，该攻击能够绕过现有防御机制，导致模型性能显著下降。", "motivation": "联邦大语言模型（FedLLMs）在无线网络中提供了强大的生成能力，同时保护了数据隐私。然而，FedLLMs仍然容易受到模型中毒攻击。现有防御机制（主要基于距离或相似度的离群点检测）在处理非IID文本数据分布和对抗自适应攻击者时存在显著局限性，因为恶意更新可以被精心构造以与合法模式难以区分。", "method": "本文提出了一种基于图表示的模型中毒（GRMP）攻击，该攻击利用良性客户端梯度之间的高阶相关性来生成难以与合法更新区分的恶意更新。这种方法旨在规避现有先进的防御系统。", "result": "GRMP攻击能够有效规避先进的防御系统，导致模型准确性和整体性能的显著下降。", "conclusion": "FedLLMs易受高级模型中毒攻击，特别是GRMP，它能有效绕过现有防御。未来的研究应侧重于开发图感知的安全聚合方法、FedLLM专用的漏洞度量标准以及评估框架，以增强联邦语言模型的鲁棒性。", "translation": "联邦大语言模型（FedLLMs）在无线网络中实现了强大的生成能力，同时保护了数据隐私。尽管如此，FedLLMs仍然容易受到模型中毒攻击。本文首先回顾了模型中毒技术的最新进展和FedLLMs的现有防御机制，强调了其关键局限性，特别是在处理非独立同分布（non-IID）文本数据分布时。当前的防御策略主要采用基于距离或相似度的离群点检测机制，其依赖于恶意更新与良性统计模式显著不同的假设。然而，在对抗针对数十亿参数LLMs的自适应对手时，这一假设变得不足。本文进一步研究了基于图表示的模型中毒（GRMP），这是一种新兴的攻击范式，它利用良性客户端梯度之间的高阶相关性来精心制作与合法更新无法区分的恶意更新。GRMP可以有效规避先进的防御系统，导致模型准确性和整体性能的显著下降。此外，本文概述了一个前瞻性的研究路线图，强调了图感知安全聚合方法、为FedLLMs量身定制的专用漏洞指标以及评估框架的必要性，以增强联邦语言模型部署的鲁棒性。", "summary": "本文探讨了联邦大语言模型（FedLLMs）在模型中毒攻击下的脆弱性。现有防御机制在处理非IID数据和自适应攻击者时存在局限性。为此，文章提出了一种基于图表示的模型中毒（GRMP）攻击，该攻击通过利用客户端梯度的高阶相关性来生成难以区分的恶意更新，从而有效规避现有防御系统，导致模型性能显著下降。文章最后提出了未来研究方向，包括图感知安全聚合和专门的漏洞评估。", "keywords": "联邦大语言模型, 模型中毒, 图表示, 攻击, 安全", "comments": "本文识别并解决了联邦大语言模型在模型中毒攻击下，特别是面对自适应攻击时的关键漏洞。GRMP攻击的创新之处在于其利用了梯度的高阶相关性，使得恶意更新能够“伪装”成合法更新，从而绕过传统的基于距离的防御机制。这对于提升FedLLM的安全性具有重要意义，并为未来研究指明了方向，特别是强调了图感知方法的重要性。"}}
{"id": "2507.23370", "title": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "authors": ["Trae Research Team", "Pengfei Gao", "Zhao Tian", "Xiangxin Meng", "Xinchen Wang", "Ruida Hu", "Yuanan Xiao", "Yizhou Liu", "Zhao Zhang", "Junjie Chen", "Cuiyun Gao", "Yun Lin", "Yingfei Xiong", "Chao Peng", "Xia Liu"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Pengfei Gao and Zhao Tian contributed equally to this technical report", "url": "http://arxiv.org/abs/2507.23370v1", "summary": "Software issue resolution is a critical challenge in software engineering and\nhas garnered increasing attention in recent years. With the rapid advancement\nof large language models (LLMs), substantial progress has been made in\naddressing real-world software engineering tasks. Recent studies have\nintroduced ensemble reasoning techniques to enhance the performance of\nLLM-based issue resolution. However, existing prompting-based methods still\nface limitations in effectively exploring large ensemble spaces and lack the\ncapacity for repository-level understanding, both of which constrain their\noverall effectiveness. In this paper, we propose Trae Agent, the first\nagent-based ensemble reasoning approach for repository-level issue resolution.\nTrae Agent formulates our goal as an optimal solution search problem and\naddresses two key challenges, i.e., large ensemble spaces and repository-level\nunderstanding, through modular agents for generation, pruning, and selection.\nWe conduct extensive experiments using three leading LLMs on the widely-adopted\nSWE-bench benchmark, comparing Trae Agent against four state-of-the-art\nensemble reasoning techniques. Experimental results demonstrate that Trae Agent\nconsistently achieves superior performance, with an average improvement of\n10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first\nplace on the SWE-bench Verified leaderboard, with a notable Pass@1 score of\n75.20%. We are pleased to release Trae Agent as an open-source project to\nsupport the research community, with all resources available at\nhttps://github.com/bytedance/trae-agent.", "comment": "Pengfei Gao and Zhao Tian contributed equally to this technical\n  report", "pdf_url": "http://arxiv.org/pdf/2507.23370v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Trae Agent：一种基于LLM的软件工程智能体，具有测试时扩展能力", "tldr": "Trae Agent是首个基于LLM的智能体集成推理方法，用于解决存储库级别的软件问题，并在SWE-bench上取得了SOTA性能。", "motivation": "软件问题解决是软件工程中的关键挑战。现有基于提示的集成推理方法在探索大型集成空间和缺乏存储库级别理解方面存在局限性，从而限制了它们的整体有效性。", "method": "本文提出了Trae Agent，这是第一个用于存储库级别问题解决的基于智能体的集成推理方法。它将目标表述为最优解搜索问题，并通过用于生成、剪枝和选择的模块化智能体来解决大型集成空间和存储库级别理解这两个关键挑战。", "result": "在SWE-bench基准测试中，Trae Agent在Pass@1方面比所有基线平均提高了10.22%，并在SWE-bench Verified排行榜上以75.20%的Pass@1分数获得第一名。", "conclusion": "Trae Agent通过其创新的智能体集成推理方法，显著提升了LLM在存储库级别软件问题解决中的性能，并有望推动该领域的研究。", "translation": "软件问题解决是软件工程中的一个关键挑战，近年来受到了越来越多的关注。随着大型语言模型（LLMs）的快速发展，在解决实际软件工程任务方面取得了实质性进展。最近的研究引入了集成推理技术，以提高基于LLM的问题解决性能。然而，现有的基于提示的方法在有效探索大型集成空间方面仍然面临局限性，并且缺乏存储库级别的理解能力，这两者都限制了它们的整体有效性。在本文中，我们提出了Trae Agent，这是第一个用于存储库级别问题解决的基于智能体的集成推理方法。Trae Agent将我们的目标表述为最优解搜索问题，并通过用于生成、剪枝和选择的模块化智能体来解决两大关键挑战，即大型集成空间和存储库级别理解。我们使用三个领先的LLM在广泛采用的SWE-bench基准上进行了大量实验，将Trae Agent与四种最先进的集成推理技术进行了比较。实验结果表明，Trae Agent始终表现出卓越的性能，在Pass@1方面比所有基线平均提高了10.22%。Trae Agent在SWE-bench Verified排行榜上取得了第一名，Pass@1分数达到了75.20%。我们很高兴将Trae Agent作为开源项目发布，以支持研究社区，所有资源均可在https://github.com/bytedance/trae-agent获得。", "summary": "本文介绍了Trae Agent，一个基于LLM的智能体集成推理框架，旨在解决软件工程中的存储库级别问题。它通过将问题建模为最优解搜索，并利用模块化智能体处理大型集成空间和提供存储库级理解。实验证明，Trae Agent在SWE-bench基准上显著优于现有SOTA方法，平均Pass@1性能提升10.22%，并位居SWE-bench Verified排行榜首位。项目已开源。", "keywords": "LLM-based Agent, Software Engineering, Issue Resolution, Ensemble Reasoning, SWE-bench", "comments": "Trae Agent的创新之处在于它是首个将智能体方法应用于存储库级别集成推理来解决软件工程问题。它通过模块化智能体有效解决了现有方法在探索大型集成空间和缺乏全局理解方面的局限性。其在SWE-bench上的优异表现和开源发布，对LLM在软件工程领域的实际应用和后续研究具有重要意义。"}}
{"id": "2501.11842", "title": "Harnessing Rydberg Atomic Receivers: From Quantum Physics to Wireless Communications", "authors": ["Yuanbin Chen", "Xufeng Guo", "Chau Yuen", "Yufei Zhao", "Yong Liang Guan", "Chong Meng Samson See", "Merouane Débbah", "Lajos Hanzo"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This revised manuscript has been submitted to IEEE journal, 16 pages, 10 figures", "url": "http://arxiv.org/abs/2501.11842v2", "summary": "The intrinsic integration of Rydberg atomic receivers into wireless\ncommunication systems is proposed, by harnessing the principles of quantum\nphysics in wireless communications. More particularly, we conceive a pair of\nRydberg atomic receivers, one incorporates a local oscillator (LO), referred to\nas an LO-dressed receiver, while the other operates without an LO and is termed\nan LO-free receiver. The appropriate wireless model is developed for each\nconfiguration, elaborating on the receiver's responses to the radio frequency\n(RF) signal, on the potential noise sources, and on the signal-to-noise ratio\n(SNR) performance. The developed wireless model conforms to the classical RF\nframework, facilitating compatibility with established signal processing\nmethodologies. Next, we investigate the associated distortion effects that\nmight occur, specifically identifying the conditions under which distortion\narises and demonstrating the boundaries of linear dynamic ranges. This provides\ncritical insights into its practical implementations in wireless systems.\nFinally, extensive simulation results are provided for characterizing the\nperformance of wireless systems, harnessing this pair of Rydberg atomic\nreceivers. Our results demonstrate that LO-dressed systems achieve a\nsignificant SNR gain of approximately 40~50 dB over conventional RF receivers\nin the standard quantum limit regime. This SNR head-room translates into\nreduced symbol error rates, enabling efficient and reliable transmission with\nhigher-order constellations.", "comment": "This revised manuscript has been submitted to IEEE journal, 16 pages,\n  10 figures", "pdf_url": "http://arxiv.org/pdf/2501.11842v2", "cate": "cs.IT", "date": "2025-01-21", "updated": "2025-07-31", "AI": {"title_translation": "利用里德堡原子接收机：从量子物理到无线通信", "tldr": "本文提出并分析了将里德堡原子接收机应用于无线通信系统，特别是LO-dressed接收机，展示了其相对于传统RF接收机显著的信噪比增益（40-50 dB）。", "motivation": "通过将量子物理原理应用于无线通信，提出将里德堡原子接收机集成到无线通信系统中，以实现更高的性能。", "method": "研究了两种里德堡原子接收机：带本地振荡器（LO-dressed）和不带本地振荡器（LO-free）。为每种配置开发了无线模型，详细阐述了接收机对射频信号的响应、潜在噪声源以及信噪比（SNR）性能。此外，还研究了可能发生的失真效应，并提供了广泛的仿真结果来表征性能。", "result": "LO-dressed系统在标准量子极限状态下，相对于传统射频接收机实现了约40~50 dB的显著信噪比增益。这种信噪比余量转化为更低的符号错误率，从而能够实现高效、可靠的高阶星座传输。", "conclusion": "里德堡原子接收机，特别是LO-dressed配置，通过提供显著的信噪比增益，为无线通信系统带来了巨大的潜力，能够实现更高效和可靠的数据传输。", "translation": "里德堡原子接收机通过利用无线通信中的量子物理原理，被提议内在集成到无线通信系统中。更具体地说，我们设想了一对里德堡原子接收机，一个包含本地振荡器（LO），被称为LO-dressed接收机，而另一个在没有LO的情况下运行，被称为LO-free接收机。为每种配置开发了适当的无线模型，详细阐述了接收机对射频（RF）信号的响应、潜在噪声源以及信噪比（SNR）性能。所开发的无线模型符合经典的射频框架，便于与已建立的信号处理方法兼容。接下来，我们研究了可能发生的关联失真效应，特别是确定了失真产生的条件，并演示了线性动态范围的边界。这为其在无线系统中的实际实现提供了关键见解。最后，提供了广泛的仿真结果，用于表征利用这对里德堡原子接收机的无线系统的性能。我们的结果表明，LO-dressed系统在标准量子极限状态下，相对于传统射频接收机实现了约40~50 dB的显著信噪比增益。这种信噪比余量转化为更低的符号错误率，从而能够实现高效、可靠的高阶星座传输。", "summary": "本文提出了一种将里德堡原子接收机集成到无线通信系统的新方法，利用量子物理原理。研究了两种配置：LO-dressed和LO-free接收机。研究人员为每种类型开发了无线模型，分析了其响应、噪声和信噪比性能，并探讨了失真效应。仿真结果表明，LO-dressed系统比传统射频接收机具有显著的40-50 dB信噪比增益，从而降低了符号错误率，实现了高效可靠的高阶星座传输。", "keywords": "里德堡原子接收机, 无线通信, 量子物理, 信噪比增益, LO-dressed", "comments": "本文的创新之处在于将量子物理中的里德堡原子应用于无线通信领域，特别是提出了LO-dressed接收机。其最重要的贡献是展示了LO-dressed系统相对于传统RF接收机高达40-50 dB的信噪比增益，这对于未来无线通信的效率和可靠性具有革命性的意义。"}}
{"id": "2506.14662", "title": "PGLib-CO2: A Power Grid Library for Computing and Optimizing Carbon Emissions", "authors": ["Young-ho Cho", "Min-Seung Ko", "Hao Zhu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.14662v3", "summary": "A sustainable electricity infrastructure requires the explicit integration of\ncarbon emissions into power system modeling and optimization paradigms.\nHowever, existing open-source datasets for power system R&D lack\ngenerator-level carbon emission profiling, limiting the ability to benchmark\nand compare various carbon-aware grid operational strategies. To address this\ngap, this work introduces PGLib-CO2, an open-source extension to the widely\nadopted PGLib-OPF test case library. PGLib-CO2 enriches standard network cases\nwith CO2 and CO2-equivalent emission intensity factors by expanding the\nfuel-type categorization used by PGLib-OPF, attaining a realistic\ngenerator-level carbon profiling. It is also packaged for both Python's\npandapower and Julia's PowerModels.jl, for a seamless, user-friendly\nintegration of emission modeling into grid computation and optimization tasks.\nThe dataset produced by PGLib-CO2 can support grid-based carbon accounting,\nemission metric evaluation, and integration into AC optimal power flow (OPF)\nand optimal load shifting (OLS) formulations. We demonstrate PGLib-CO2's\nutility through case studies that quantify cost-emission trade-offs and\noptimize a carbon-aware objective function. By standardizing carbon-enhanced\ntest cases, PGLib-CO2 provides an open-source, reproducible foundation for\nbenchmarking carbon-aware computation, facilitating future research in\nsustainable power system operation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.14662v3", "cate": "eess.SY", "date": "2025-06-17", "updated": "2025-07-31", "AI": {"title_translation": "PGLib-CO2: 一个用于计算和优化碳排放的电网库", "tldr": "PGLib-CO2是一个新的开源库，通过为电力系统测试用例添加发电机级别的碳排放数据，以支持碳感知电网建模和优化，促进可持续电力系统研究。", "motivation": "现有电力系统研发的开源数据集缺乏发电机级别的碳排放配置，限制了对各种碳感知电网运行策略进行基准测试和比较的能力，而可持续电力基础设施需要将碳排放明确整合到电力系统建模和优化范式中。", "method": "本文引入了PGLib-CO2，它是广泛采用的PGLib-OPF测试用例库的开源扩展。PGLib-CO2通过扩展PGLib-OPF使用的燃料类型分类，用CO2和CO2当量排放强度因子丰富了标准网络案例，实现了逼真的发电机级别碳排放分析。它还被打包为Python的pandapower和Julia的PowerModels.jl版本，以便于将排放建模无缝、用户友好地集成到电网计算和优化任务中。", "result": "PGLib-CO2生成的数据集可以支持基于电网的碳核算、排放指标评估，并集成到交流最优潮流（OPF）和最优负荷转移（OLS）公式中。通过量化成本-排放权衡和优化碳感知目标函数的案例研究，该工作展示了PGLib-CO2的实用性。", "conclusion": "通过标准化碳增强测试用例，PGLib-CO2为碳感知计算提供了开放源代码、可复现的基础，促进了可持续电力系统运行的未来研究。", "translation": "可持续的电力基础设施需要将碳排放明确整合到电力系统建模和优化范式中。然而，现有用于电力系统研发的开源数据集缺乏发电机级别的碳排放配置，这限制了对各种碳感知电网运行策略进行基准测试和比较的能力。为了解决这一差距，这项工作引入了PGLib-CO2，它是广泛采用的PGLib-OPF测试用例库的开源扩展。PGLib-CO2通过扩展PGLib-OPF使用的燃料类型分类，用CO2和CO2当量排放强度因子丰富了标准网络案例，从而实现了逼真的发电机级别碳排放分析。它还被打包为Python的pandapower和Julia的PowerModels.jl版本，以便于将排放建模无缝、用户友好地集成到电网计算和优化任务中。PGLib-CO2生成的数据集可以支持基于电网的碳核算、排放指标评估，以及集成到交流最优潮流（OPF）和最优负荷转移（OLS）公式中。我们通过量化成本-排放权衡和优化碳感知目标函数的案例研究，展示了PGLib-CO2的实用性。通过标准化碳增强测试用例，PGLib-CO2为碳感知计算提供了开放源代码、可复现的基础，促进了可持续电力系统运行的未来研究。", "summary": "PGLib-CO2是一个开源库，旨在解决现有电力系统数据集中缺乏发电机级别碳排放数据的问题。它扩展了PGLib-OPF库，通过添加CO2排放强度因子，实现了更真实的碳排放分析，并支持碳核算、排放评估以及最优潮流和最优负荷转移等优化任务。该库提供了可复现的碳增强测试用例，旨在推动可持续电力系统领域的研究。", "keywords": "碳排放, 电网, 优化, 开源, PGLib-CO2", "comments": "这项工作通过提供一个包含发电机级别碳排放数据的开源库，弥补了现有电力系统数据集的空白，具有重要的创新性。它为评估和优化碳感知电网运行策略提供了标准化的基准测试基础，对于推动可持续电力系统的发展具有重要意义。其兼容Python和Julia也增强了其可用性。"}}
{"id": "2407.01621", "title": "Deciphering interventional dynamical causality from non-intervention complex systems", "authors": ["Jifan Shi", "Yang Li", "Juan Zhao", "Siyang Leng", "Rui Bao", "Kazuyuki Aihara", "Luonan Chen", "Wei Lin"], "categories": ["cs.LG", "q-bio.QM", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.01621v2", "summary": "Detecting and quantifying causality is a focal topic in the fields of\nscience, engineering, and interdisciplinary studies. However, causal studies on\nnon-intervention systems attract much attention but remain extremely\nchallenging. Delay-embedding technique provides a promising approach. In this\nstudy, we propose a framework named Interventional Dynamical Causality (IntDC)\nin contrast to the traditional Constructive Dynamical Causality (ConDC). ConDC,\nincluding Granger causality, transfer entropy and convergence of cross-mapping,\nmeasures the causality by constructing a dynamical model without considering\ninterventions. A computational criterion, Interventional Embedding Entropy\n(IEE), is proposed to measure causal strengths in an interventional manner. IEE\nis an intervened causal information flow but in the delay-embedding space.\nFurther, the IEE theoretically and numerically enables the deciphering of IntDC\nsolely from observational (non-interventional) time-series data, without\nrequiring any knowledge of dynamical models or real interventions in the\nconsidered system. In particular, IEE can be applied to rank causal effects\naccording to their importance and construct causal networks from data. We\nconducted numerical experiments to demonstrate that IEE can find causal edges\naccurately, eliminate effects of confounding, and quantify causal strength\nrobustly over traditional indices. We also applied IEE to real-world tasks. IEE\nperformed as an accurate and robust tool for causal analyses solely from the\nobservational data. The IntDC framework and IEE algorithm provide an efficient\napproach to the study of causality from time series in diverse non-intervention\ncomplex systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.01621v2", "cate": "cs.LG", "date": "2024-06-29", "updated": "2025-07-30", "AI": {"title_translation": "从非干预复杂系统中解读干预动力学因果关系", "tldr": "本研究提出了一个名为IntDC的框架和IEE算法，用于仅从观测时间序列数据中准确、鲁棒地识别和量化非干预复杂系统中的因果关系，无需实际干预或动力学模型知识。", "motivation": "在非干预系统中的因果关系研究备受关注，但仍然极具挑战性。传统的因果测量方法（如Granger因果关系、传递熵和交叉映射收敛）在构建动力学模型时未考虑干预，限制了其在复杂系统中的应用。", "method": "本研究提出了一个名为干预动力学因果关系（IntDC）的框架，并引入了一个计算准则：干预嵌入熵（IEE）。IEE是一种在延迟嵌入空间中的干预因果信息流，它理论上和数值上能够仅从观测（非干预）时间序列数据中解读IntDC，无需任何动力学模型或实际干预的知识。IEE可用于根据重要性对因果效应进行排序和从数据中构建因果网络。", "result": "数值实验表明，IEE能够准确找到因果边缘，消除混杂效应，并比传统指标更鲁棒地量化因果强度。在实际应用中，IEE被证明是一种准确且鲁鲁棒的因果分析工具，仅需观测数据。", "conclusion": "IntDC框架和IEE算法为研究各种非干预复杂系统中的时间序列因果关系提供了一种高效的方法。", "translation": "检测和量化因果关系是科学、工程和交叉学科领域的一个焦点话题。然而，对非干预系统的因果研究备受关注，但仍然极具挑战性。延迟嵌入技术提供了一种有前景的方法。在这项研究中，我们提出了一个名为干预动力学因果关系（IntDC）的框架，与传统的构建性动力学因果关系（ConDC）形成对比。ConDC，包括Granger因果关系、传递熵和交叉映射收敛，通过构建动力学模型来测量因果关系，而没有考虑干预。我们提出了一个计算准则，即干预嵌入熵（IEE），以干预的方式测量因果强度。IEE是一种干预的因果信息流，但在延迟嵌入空间中。此外，IEE在理论上和数值上能够仅从观测（非干预）时间序列数据中解读IntDC，而无需考虑所考虑系统中的任何动力学模型知识或实际干预。特别是，IEE可以应用于根据其重要性对因果效应进行排序，并从数据中构建因果网络。我们进行了数值实验，以证明IEE能够准确找到因果边缘，消除混杂效应，并比传统指标更鲁棒地量化因果强度。我们还将IEE应用于实际任务。IEE作为一种准确且鲁棒的工具，仅从观测数据进行因果分析。IntDC框架和IEE算法为研究各种非干预复杂系统中的时间序列因果关系提供了一种高效的方法。", "summary": "本研究提出了一个名为干预动力学因果关系（IntDC）的新框架，并引入了干预嵌入熵（IEE）作为其核心算法，旨在解决非干预复杂系统中因果关系检测和量化的挑战。与传统的构建性因果关系方法不同，IEE能够仅利用观测时间序列数据，在无需已知动力学模型或实际干预的情况下，准确地识别和量化系统内部的因果强度，并可用于构建因果网络。数值实验和实际应用均证明了IEE在准确性、鲁棒性和处理混杂效应方面的优越性，为非干预复杂系统的因果分析提供了一种高效且实用的工具。", "keywords": "因果关系, 非干预系统, 延迟嵌入, 干预嵌入熵, 复杂系统", "comments": "该论文的创新点在于提出了一个能够在非干预复杂系统中，仅凭观测数据就能“解读”出干预性因果关系的框架（IntDC）和算法（IEE）。这解决了传统因果分析方法需要实际干预或预设模型才能识别因果关系的局限性。IEE通过在延迟嵌入空间中测量因果信息流，提供了一种新颖且强大的工具，尤其在处理混杂因素和量化因果强度方面表现出色，对于科学、工程和交叉学科的复杂系统分析具有重要意义。"}}
{"id": "2507.21433", "title": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse", "authors": ["Kaiwen Chen", "Xin Tan", "Minchen Yu", "Hong Xu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures", "url": "http://arxiv.org/abs/2507.21433v2", "summary": "Large Reasoning Models (LRMs) have achieved significant advances in\nmathematical reasoning and formal logic tasks. However, their tendency to\ngenerate lengthy chain-of-thought sequences leads to substantial memory\noverhead during inference. We observe that LRMs frequently produce highly\nsimilar intermediate reasoning steps, which correspond to similar KV cache\nstates across layers. Motivated by this observation, we propose MemShare, a\nnovel KV cache management approach that effectively reduces memory overhead.\nMemShare employs a collaborative filtering algorithm to efficiently identify\nreusable KV cache blocks and enables zero copy cache reuse to significantly\nreduce memory overhead, improve throughput while maintaining accuracy.\nExperimental results demonstrate that MemShare delivers up to 84.79\\%\nimprovement in throughput while maintaining better accuracy compared to\nexisting KV cache management methods.", "comment": "11 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.21433v2", "cate": "cs.LG", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "MemShare：通过KV缓存重用来实现大型推理模型的内存高效推理", "tldr": "MemShare通过重用KV缓存块显著减少大型推理模型的内存开销并提高吞吐量。", "motivation": "大型推理模型（LRMs）在推理过程中生成冗长的思维链序列，导致巨大的内存开销。研究观察到LRMs经常产生高度相似的中间推理步骤，对应于跨层的相似KV缓存状态。", "method": "提出MemShare，一种新颖的KV缓存管理方法。它采用协同过滤算法高效识别可重用的KV缓存块，并实现零拷贝缓存重用。", "result": "实验结果表明，MemShare在保持更好准确性的同时，吞吐量提高了84.79%，优于现有KV缓存管理方法。", "conclusion": "MemShare通过KV缓存重用显著减少了大型推理模型的内存开销，提高了吞吐量，并保持了准确性。", "translation": "大型推理模型（LRMs）在数学推理和形式逻辑任务中取得了显著进展。然而，它们倾向于生成冗长的思维链序列，导致推理过程中巨大的内存开销。我们观察到LRMs频繁产生高度相似的中间推理步骤，这对应于跨层的相似KV缓存状态。受此观察的启发，我们提出了MemShare，一种新颖的KV缓存管理方法，可有效减少内存开销。MemShare采用协同过滤算法高效识别可重用的KV缓存块，并实现零拷贝缓存重用，以显著减少内存开销，提高吞吐量，同时保持准确性。实验结果表明，与现有KV缓存管理方法相比，MemShare在保持更好准确性的同时，吞吐量提高了84.79%。", "summary": "MemShare是一种针对大型推理模型（LRMs）的KV缓存管理新方法，旨在解决其在推理过程中因生成冗长思维链导致的内存开销问题。该方法基于LRMs会产生相似中间推理步骤的观察，利用协同过滤算法识别并零拷贝重用KV缓存块。实验证明，MemShare能显著减少内存消耗，提高吞吐量高达84.79%，同时保持或提高准确性。", "keywords": "大型推理模型, KV缓存, 内存效率, 协同过滤, 吞吐量", "comments": "MemShare的创新点在于其利用对LRM推理过程中KV缓存相似性的观察，通过协同过滤和零拷贝重用机制，有效地解决了大型模型推理时的内存瓶颈，同时提升了效率和准确性。这对于部署和运行大型模型具有重要意义。"}}
{"id": "2507.08540", "title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "authors": ["Ioannis Lamprou", "Alexander Shevtsov", "Ioannis Arapakis", "Sotiris Ioannidis"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08540v2", "summary": "The proliferation of software vulnerabilities presents a significant\nchallenge to cybersecurity, necessitating more effective detection\nmethodologies. We introduce White-Basilisk, a novel approach to vulnerability\ndetection that demonstrates superior performance while challenging prevailing\nassumptions in AI model scaling. Utilizing an innovative architecture that\nintegrates Mamba layers, linear self-attention, and a Mixture of Experts\nframework, White-Basilisk achieves state-of-the-art results in vulnerability\ndetection tasks with a parameter count of only 200M. The model's capacity to\nprocess sequences of unprecedented length enables comprehensive analysis of\nextensive codebases in a single pass, surpassing the context limitations of\ncurrent Large Language Models (LLMs). White-Basilisk exhibits robust\nperformance on imbalanced, real-world datasets, while maintaining computational\nefficiency that facilitates deployment across diverse organizational scales.\nThis research not only establishes new benchmarks in code security but also\nprovides empirical evidence that compact, efficiently designed models can\noutperform larger counterparts in specialized tasks, potentially redefining\noptimization strategies in AI development for domain-specific applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08540v2", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-31", "AI": {"title_translation": "White-Basilisk: 一种用于代码漏洞检测的混合模型", "tldr": "White-Basilisk是一种新型混合模型，通过集成Mamba层、线性自注意力和专家混合框架，以仅2亿参数在代码漏洞检测方面实现了最先进的性能，并能处理超长序列。", "motivation": "软件漏洞的泛滥对网络安全构成了重大挑战，需要更有效的检测方法。", "method": "White-Basilisk采用了一种创新的架构，集成了Mamba层、线性自注意力和专家混合（Mixture of Experts）框架。", "result": "White-Basilisk以仅2亿参数在漏洞检测任务中取得了最先进的结果，能够处理前所未有的超长序列，实现对大型代码库的单次全面分析，超越了当前大型语言模型的上下文限制。它在不平衡的真实世界数据集中表现出鲁棒性能，并保持了计算效率。", "conclusion": "这项研究不仅在代码安全领域建立了新基准，而且提供了实证证据，表明紧凑、高效设计的模型在特定领域任务中可以超越大型模型，这可能重新定义AI开发中针对领域特定应用的优化策略。", "translation": "软件漏洞的泛滥对网络安全构成了重大挑战，需要更有效的检测方法。我们引入了White-Basilisk，这是一种新颖的漏洞检测方法，它展示了卓越的性能，同时挑战了AI模型扩展的普遍假设。White-Basilisk利用一种创新的架构，集成了Mamba层、线性自注意力和专家混合框架，以仅2亿参数在漏洞检测任务中取得了最先进的结果。该模型处理前所未有长度序列的能力，使得对大型代码库进行单次全面分析成为可能，超越了当前大型语言模型（LLMs）的上下文限制。White-Basilisk在不平衡的真实世界数据集中表现出强大的性能，同时保持了计算效率，便于在不同组织规模下部署。这项研究不仅在代码安全领域建立了新基准，而且提供了实证证据，表明紧凑、高效设计的模型在特定领域任务中可以超越大型模型，这可能重新定义AI开发中针对领域特定应用的优化策略。", "summary": "White-Basilisk是一种新颖的混合模型，专为代码漏洞检测而设计。该模型融合了Mamba层、线性自注意力和专家混合框架，以仅2亿参数实现了代码漏洞检测任务的最先进性能。它能处理超长代码序列，克服了传统大型语言模型的上下文限制，并在真实世界的不平衡数据集中展现出鲁棒且高效的性能。这项研究不仅提升了代码安全检测能力，也证明了紧凑型模型在特定领域任务中超越大型模型的潜力。", "keywords": "代码漏洞检测, 混合模型, White-Basilisk, Mamba, 专家混合", "comments": "White-Basilisk的创新之处在于其混合架构，特别是结合Mamba层、线性自注意力和专家混合，以相对较小的参数量（200M）实现了SOTA性能。其能够处理超长序列并超越LLM上下文限制的能力，对于代码分析领域是一个重大突破。这项工作挑战了“越大越好”的AI模型扩展假设，为领域特定AI模型的优化策略提供了新的视角，具有重要的实践和理论意义。"}}
{"id": "2507.22922", "title": "Predicting stock prices with ChatGPT-annotated Reddit sentiment", "authors": ["Mateusz Kmak", "Kamil Chmurzyński", "Kamil Matejuk", "Paweł Kotzbach", "Jan Kocoń"], "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      International Conference on Computational Science 2025", "url": "http://arxiv.org/abs/2507.22922v1", "summary": "The surge of retail investor activity on social media, exemplified by the\n2021 GameStop short squeeze, raised questions about the influence of online\nsentiment on stock prices. This paper explores whether sentiment derived from\nsocial media discussions can meaningfully predict stock market movements. We\nfocus on Reddit's r/wallstreetbets and analyze sentiment related to two\ncompanies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's\nrole, we employ two existing text-based sentiment analysis methods and\nintroduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model\ndesigned to better interpret the informal language and emojis prevalent in\nsocial media discussions. We use correlation and causality metrics to determine\nthese models' predictive power. Surprisingly, our findings suggest that social\nmedia sentiment has only a weak correlation with stock prices. At the same\ntime, simpler metrics, such as the volume of comments and Google search trends,\nexhibit stronger predictive signals. These results highlight the complexity of\nretail investor behavior and suggest that traditional sentiment analysis may\nnot fully capture the nuances of market-moving online discussions.", "comment": "International Conference on Computational Science 2025", "pdf_url": "http://arxiv.org/pdf/2507.22922v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "使用ChatGPT标注的Reddit情绪预测股票价格", "tldr": "本文探究社交媒体情绪能否预测股价。研究发现，Reddit情绪与股价相关性较弱，而评论量和谷歌搜索趋势有更强的预测信号。", "motivation": "2021年GameStop事件等散户在社交媒体上的活跃度激增，引发了关于在线情绪对股价影响的疑问。本文旨在探究社交媒体讨论中提取的情绪是否能有效预测股市波动。", "method": "该研究聚焦Reddit的r/wallstreetbets，分析GameStop (GME) 和AMC Entertainment (AMC) 的相关情绪。研究采用了两种现有文本情绪分析方法，并引入了第三种方法：一个由ChatGPT标注并微调的RoBERTa模型，旨在更好地解释社交媒体中普遍存在的非正式语言和表情符号。通过相关性和因果关系指标来确定这些模型的预测能力。", "result": "令人惊讶的是，研究结果表明社交媒体情绪与股票价格的相关性很弱。同时，评论量和谷歌搜索趋势等更简单的指标显示出更强的预测信号。", "conclusion": "这些结果突显了散户投资者行为的复杂性，并表明传统情绪分析可能无法完全捕捉市场波动在线讨论的细微差别。", "translation": "零售投资者在社交媒体上的活跃度激增，以2021年GameStop逼空事件为例，引发了关于在线情绪对股价影响的疑问。本文探讨了从社交媒体讨论中提取的情绪是否能有效预测股票市场走势。我们关注Reddit的r/wallstreetbets，并分析了与两家公司——GameStop (GME) 和AMC Entertainment (AMC) 相关的情绪。为了评估情绪的作用，我们采用了两种现有的基于文本的情绪分析方法，并引入了第三种方法，即一个由ChatGPT标注和微调的基于RoBERTa的模型，该模型旨在更好地解释社交媒体讨论中普遍存在的非正式语言和表情符号。我们使用相关性和因果关系指标来确定这些模型的预测能力。令人惊讶的是，我们的研究结果表明，我们的研究结果表明，社交媒体情绪与股票价格的相关性很弱。同时，评论量和谷歌搜索趋势等更简单的指标表现出更强的预测信号。这些结果突显了散户投资者行为的复杂性，并表明传统情绪分析可能无法完全捕捉市场波动在线讨论的细微差别。", "summary": "本文探讨了社交媒体情绪对股票价格的预测能力，特别关注Reddit的r/wallstreetbets社区中关于GameStop和AMC的情绪。研究引入了一个由ChatGPT标注并微调的RoBERTa模型来处理社交媒体的非正式语言。结果显示，社交媒体情绪与股价的相关性较弱，而评论数量和谷歌搜索趋势等简单指标反而表现出更强的预测能力，这表明散户行为的复杂性以及传统情绪分析的局限性。", "keywords": "社交媒体情绪, 股票价格预测, Reddit, ChatGPT, RoBERTa", "comments": "本文的创新点在于引入了由ChatGPT标注和微调的RoBERTa模型来处理社交媒体中非正式语言和表情符号，试图更准确地捕捉情绪。然而，研究结果出人意料地发现社交媒体情绪与股价的相关性较弱，这挑战了普遍的看法，并强调了仅凭情绪分析可能不足以完全理解复杂的散户市场行为。其局限性在于可能需要更复杂的模型或结合更多异构数据源来捕捉市场动态。"}}
{"id": "2507.23609", "title": "Consistent Point Matching", "authors": ["Halid Ziya Yerebakan", "Gerardo Hermosillo Valadez"], "categories": ["cs.CV", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23609v1", "summary": "This study demonstrates that incorporating a consistency heuristic into the\npoint-matching algorithm \\cite{yerebakan2023hierarchical} improves robustness\nin matching anatomical locations across pairs of medical images. We validated\nour approach on diverse longitudinal internal and public datasets spanning CT\nand MRI modalities. Notably, it surpasses state-of-the-art results on the Deep\nLesion Tracking dataset. Additionally, we show that the method effectively\naddresses landmark localization. The algorithm operates efficiently on standard\nCPU hardware and allows configurable trade-offs between speed and robustness.\nThe method enables high-precision navigation between medical images without\nrequiring a machine learning model or training data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23609v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一致点匹配", "tldr": "本研究表明，将一致性启发式方法融入点匹配算法可提高医学图像解剖位置匹配的鲁棒性，在Deep Lesion Tracking数据集上超越了现有最佳结果，且无需机器学习模型。", "motivation": "旨在提高医学图像间解剖位置匹配的鲁棒性。", "method": "将一致性启发式方法纳入现有的点匹配算法中。该方法在涵盖CT和MRI模态的多种纵向内部和公共数据集上进行了验证。它在标准CPU硬件上高效运行，并允许在速度和鲁棒性之间进行可配置的权衡，无需机器学习模型或训练数据。", "result": "提高了医学图像对之间解剖位置匹配的鲁棒性；在Deep Lesion Tracking数据集上超越了最先进的结果；有效地解决了地标定位问题；在标准CPU硬件上高效运行；允许在速度和鲁棒性之间进行可配置的权衡。", "conclusion": "通过引入一致性启发式方法，显著提升了医学图像点匹配的性能和鲁棒性，提供了一种高效、高精度且无需机器学习的解决方案。", "translation": "这项研究表明，将一致性启发式方法纳入点匹配算法\\cite{yerebakan2023hierarchical}可以提高医学图像对之间解剖位置匹配的鲁棒性。我们验证了我们的方法在涵盖CT和MRI模态的各种纵向内部和公共数据集上的有效性。值得注意的是，它在Deep Lesion Tracking数据集上超越了最先进的结果。此外，我们还表明该方法有效地解决了地标定位问题。该算法在标准CPU硬件上高效运行，并允许在速度和鲁棒性之间进行可配置的权衡。该方法无需机器学习模型或训练数据即可实现医学图像之间的高精度导航。", "summary": "本研究通过将一致性启发式方法整合到现有的点匹配算法中，显著提升了医学图像间解剖位置匹配的鲁棒性。该方法在CT和MRI数据集上进行了验证，并在Deep Lesion Tracking数据集上超越了现有最佳表现。它还能有效解决地标定位问题，且无需机器学习模型或训练数据，可在标准CPU上高效运行，并支持速度与鲁棒性的灵活权衡，实现了医学图像间的高精度导航。", "keywords": "点匹配, 一致性启发, 医学图像分析, Deep Lesion Tracking, 地标定位", "comments": "该研究的创新之处在于通过引入一致性启发式方法，在不依赖机器学习模型和大量训练数据的情况下，显著提升了医学图像点匹配的鲁棒性和性能，并取得了超越现有技术水平的成果。其在标准CPU上的高效运行能力和可配置的权衡选项也增强了其实用性。"}}
{"id": "2507.23643", "title": "FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks", "authors": ["Changqing Xu", "Ziqiang Yang", "Yi Liu", "Xinfang Liao", "Guiqi Mo", "Hao Zeng", "Yintang Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23643v1", "summary": "Spiking Neural Networks (SNNs) offer a biologically plausible framework for\nenergy-efficient neuromorphic computing. However, it is a challenge to train\nSNNs due to their non-differentiability, efficiently. Existing gradient\napproximation approaches frequently sacrifice accuracy and face deployment\nlimitations on edge devices due to the substantial computational requirements\nof backpropagation. To address these challenges, we propose a Forward-Forward\n(FF) based gradient approximation-free training framework for Spiking Neural\nNetworks, which treats spiking activations as black-box modules, thereby\neliminating the need for gradient approximation while significantly reducing\ncomputational complexity. Furthermore, we introduce a class-aware complexity\nadaptation mechanism that dynamically optimizes the loss function based on\ninter-class difficulty metrics, enabling efficient allocation of network\nresources across different categories. Experimental results demonstrate that\nour proposed training framework achieves test accuracies of 99.58%, 92.13%, and\n75.64% on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, respectively,\nsurpassing all existing FF-based SNN approaches. Additionally, our proposed\nmethod exhibits significant advantages in terms of memory access and\ncomputational power consumption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23643v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "FFGAF-SNN: 基于前向-前向的无梯度近似尖峰神经网络训练框架", "tldr": "FFGAF-SNN提出了一种基于前向-前向的无梯度近似训练框架，用于解决尖峰神经网络（SNNs）的训练挑战，显著提高了准确性并降低了计算复杂度。", "motivation": "尖峰神经网络（SNNs）在能效神经形态计算方面具有潜力，但由于其不可微性，训练效率低下。现有的梯度近似方法常牺牲精度，且因反向传播的计算需求大，在边缘设备部署受限。", "method": "提出了一种名为FFGAF-SNN的基于前向-前向（FF）的无梯度近似训练框架。该框架将尖峰激活视为黑盒模块，从而无需梯度近似，并显著降低了计算复杂度。此外，引入了类别感知复杂性适应机制，根据类间难度指标动态优化损失函数，实现不同类别间网络资源的有效分配。", "result": "在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到了99.58%、92.13%和75.64%的测试准确率，超过所有现有基于FF的SNN方法。在内存访问和计算功耗方面也表现出显著优势。", "conclusion": "FFGAF-SNN训练框架通过消除梯度近似和引入类别感知复杂性适应机制，有效解决了SNN训练的挑战，并在准确性和效率方面取得了优于现有方法的成果。", "translation": "尖峰神经网络（SNNs）为能效神经形态计算提供了一个生物学上可信的框架。然而，由于其不可微性，有效训练SNNs是一个挑战。现有的梯度近似方法经常牺牲准确性，并且由于反向传播的巨大计算需求，在边缘设备上面临部署限制。为了解决这些挑战，我们提出了一种基于前向-前向（FF）的无梯度近似尖峰神经网络训练框架，该框架将尖峰激活视为黑盒模块，从而消除了对梯度近似的需求，同时显著降低了计算复杂度。此外，我们引入了一种类别感知复杂性适应机制，根据类间难度指标动态优化损失函数，从而实现跨不同类别的网络资源的有效分配。实验结果表明，我们提出的训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到了99.58%、92.13%和75.64%的测试准确率，超越了所有现有基于FF的SNN方法。此外，我们提出的方法在内存访问和计算功耗方面也表现出显著优势。", "summary": "该论文提出了FFGAF-SNN，一个基于前向-前向（FF）的尖峰神经网络（SNNs）无梯度近似训练框架。该框架将尖峰激活视为黑盒，避免了梯度近似的需要，显著降低了计算复杂性。它还引入了类别感知复杂性适应机制来优化资源分配。实验证明，FFGAF-SNN在多个数据集上取得了比现有FF-SNN方法更高的准确率，并在内存和功耗方面表现出优势。", "keywords": "尖峰神经网络, 前向-前向, 无梯度近似, 训练框架, 能效计算", "comments": "该论文的创新点在于提出了一个无需梯度近似的SNN训练框架，通过将尖峰激活视为黑盒，有效解决了SNN训练中的不可微性问题和计算复杂度问题。引入的类别感知复杂性适应机制也很有趣，能更有效地分配网络资源。其在多个数据集上超越现有FF-SNN方法的表现，以及在内存和功耗方面的优势，显示了其在边缘设备部署上的潜力，具有重要意义。"}}
{"id": "2507.23224", "title": "EMORe: Motion-Robust 5D MRI Reconstruction via Expectation-Maximization-Guided Binning Correction and Outlier Rejection", "authors": ["Syed M. Arshad", "Lee C. Potter", "Yingmin Liu", "Christopher Crabtree", "Matthew S. Tong", "Rizwan Ahmad"], "categories": ["eess.IV", "eess.SP"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23224v1", "summary": "We propose EMORe, an adaptive reconstruction method designed to enhance\nmotion robustness in free-running, free-breathing self-gated 5D cardiac\nmagnetic resonance imaging (MRI). Traditional self-gating-based motion binning\nfor 5D MRI often results in residual motion artifacts due to inaccuracies in\ncardiac and respiratory signal extraction and sporadic bulk motion,\ncompromising clinical utility. EMORe addresses these issues by integrating\nadaptive inter-bin correction and explicit outlier rejection within an\nexpectation-maximization (EM) framework, whereby the E-step and M-step are\nexecuted alternately until convergence. In the E-step, probabilistic (soft) bin\nassignments are refined by correcting misassignment of valid data and rejecting\nmotion-corrupted data to a dedicated outlier bin. In the M-step, the image\nestimate is improved using the refined soft bin assignments. Validation in a\nsimulated 5D MRXCAT phantom demonstrated EMORe's superior performance compared\nto standard compressed sensing reconstruction, showing significant improvements\nin peak signal-to-noise ratio, structural similarity index, edge sharpness, and\nbin assignment accuracy across varying levels of simulated bulk motion. In vivo\nvalidation in 13 volunteers further confirmed EMORe's robustness, significantly\nenhancing blood-myocardium edge sharpness and reducing motion artifacts\ncompared to compressed sensing, particularly in scenarios with controlled\ncoughing-induced motion. Although EMORe incurs a modest increase in\ncomputational complexity, its adaptability and robust handling of bulk motion\nartifacts significantly enhance the clinical applicability and diagnostic\nconfidence of 5D cardiac MRI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23224v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "EMORe：基于期望最大化引导的分箱校正和异常值剔除的运动鲁棒5D MRI重建", "tldr": "EMORe是一种自适应的5D心脏MRI重建方法，通过期望最大化框架下的分箱校正和异常值剔除，显著提升了运动鲁棒性，减少了伪影并增强了图像质量。", "motivation": "传统的基于自门控的5D MRI运动分箱方法在心脏和呼吸信号提取不准确以及偶发性整体运动的情况下，常导致残余运动伪影，从而影响临床实用性。", "method": "本文提出EMORe，一种自适应重建方法，通过在期望最大化（EM）框架内整合自适应的箱间校正和显式异常值剔除来解决问题。EM框架的E步和M步交替执行直至收敛。在E步中，通过纠正有效数据的错误分配并将运动损坏数据拒绝到专门的异常值箱来细化概率（软）箱分配。在M步中，使用细化的软箱分配来改进图像估计。", "result": "在模拟5D MRXCAT体模中验证表明，与标准压缩感知重建相比，EMORe表现出卓越的性能，在不同程度的模拟整体运动下，峰值信噪比、结构相似性指数、边缘锐度和箱分配准确性均显著提高。在13名志愿者的体内验证进一步证实了EMORe的鲁棒性，与压缩感知相比，显著增强了血心肌边缘锐度并减少了运动伪影，尤其是在受控咳嗽引起的运动场景中。", "conclusion": "尽管EMORe的计算复杂性略有增加，但其适应性和对整体运动伪影的鲁棒处理显著增强了5D心脏MRI的临床适用性和诊断信心。", "translation": "我们提出EMORe，一种自适应重建方法，旨在增强自由运行、自由呼吸自门控5D心脏磁共振成像（MRI）的运动鲁棒性。传统的基于自门控的5D MRI运动分箱常因心脏和呼吸信号提取不准确以及偶发性整体运动而导致残余运动伪影，从而影响临床实用性。EMORe通过在期望最大化（EM）框架内整合自适应的箱间校正和显式异常值剔除来解决这些问题，其中E步和M步交替执行直至收敛。在E步中，通过纠正有效数据的错误分配并将运动损坏数据拒绝到专门的异常值箱来细化概率（软）箱分配。在M步中，使用细化的软箱分配来改进图像估计。在模拟5D MRXCAT体模中的验证表明，与标准压缩感知重建相比，EMORe表现出卓越的性能，在不同程度的模拟整体运动下，峰值信噪比、结构相似性指数、边缘锐度和箱分配准确性均显著提高。在13名志愿者的体内验证进一步证实了EMORe的鲁棒性，与压缩感知相比，显著增强了血心肌边缘锐度并减少了运动伪影，尤其是在受控咳嗽引起的运动场景中。尽管EMORe的计算复杂性略有增加，但其适应性和对整体运动伪影的鲁棒处理显著增强了5D心脏MRI的临床适用性和诊断信心。", "summary": "EMORe是一种创新的自适应重建方法，旨在提升自由呼吸5D心脏MRI的运动鲁棒性。该方法通过一个期望最大化框架，结合了自适应的箱间校正和显式异常值剔除，以解决传统自门控分箱中由信号提取不准确和整体运动导致的伪影。EMORe在模拟和体内实验中均表现出优于标准压缩感知方法的性能，显著改善了图像质量、边缘锐度和分箱准确性，即使在存在显著运动的情况下也能有效减少伪影，从而增强了5D心脏MRI的临床实用性和诊断信心。", "keywords": "5D MRI, 运动鲁棒, 期望最大化, 分箱校正, 异常值剔除", "comments": "EMORe的创新点在于将期望最大化框架应用于5D MRI重建中的运动处理，通过精细的概率分箱分配校正和异常值剔除，有效克服了传统方法中难以解决的运动伪影问题。尽管计算复杂度略有增加，但其在提升图像质量和诊断信心方面的显著优势，使其在临床应用中具有重要价值。"}}
{"id": "2507.21197", "title": "AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction", "authors": ["Ling Liao", "Eva Aagaard"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.21197v2", "summary": "Machine learning interpretation (MLI) has primarily been leveraged to build\nclinician trust and uncover actionable insights in EHRs. However, the intrinsic\ncomplexity and heterogeneity of EHR data limit its effectiveness in guiding\nsubgroup-specific modeling. We propose AdaptHetero, a novel MLI-driven\nframework that transforms interpretability insights into actionable guidance\nfor tailoring model training and evaluation across subpopulations within\nindividual hospital systems. Evaluated on three large-scale EHR datasets:\nGOSSIS-1-eICU, WiDS, and MIMIC-IV, AdaptHetero consistently identifies\nheterogeneous model behaviors in predicting ICU mortality, in-hospital death,\nand hidden hypoxemia. By integrating SHAP-based interpretation and unsupervised\nclustering, the framework enhances the identification of clinically meaningful\nsubgroup-specific characteristics, leading to improved predictive performance\nand optimized clinical deployment.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.21197v2", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-30", "AI": {"title_translation": "AdaptHetero：机器学习解释驱动的电子健康记录（EHR）临床预测亚组适应", "tldr": "AdaptHetero是一个新的框架，它利用机器学习解释来指导EHR数据中亚组特定模型的训练和评估，从而提高预测性能和临床部署。", "motivation": "机器学习解释（MLI）在EHR中主要用于建立临床医生信任和发现可操作的见解。然而，EHR数据固有的复杂性和异质性限制了MLI在指导亚组特定建模方面的有效性。", "method": "本文提出了AdaptHetero，一个新颖的MLI驱动框架。该框架将可解释性洞察转化为可操作的指导，用于在单个医院系统内针对不同亚群调整模型训练和评估。它通过整合基于SHAP的解释和无监督聚类来增强临床上有意义的亚组特定特征的识别。", "result": "AdaptHetero在三个大型EHR数据集（GOSSIS-1-eICU、WiDS和MIMIC-IV）上进行评估，持续识别在预测ICU死亡率、住院死亡和隐匿性低氧血症方面的异构模型行为。该框架提高了预测性能，并优化了临床部署。", "conclusion": "AdaptHetero通过整合MLI和无监督聚类，成功地将解释性洞察转化为指导亚组特定模型训练和评估的行动，从而在处理EHR数据异质性方面表现出色，并最终提高了临床预测的准确性和实用性。", "translation": "机器学习解释（MLI）主要用于在电子健康记录（EHR）中建立临床医生信任并发现可操作的见解。然而，EHR数据固有的复杂性和异质性限制了其在指导亚组特定建模方面的有效性。我们提出了AdaptHetero，一个新颖的MLI驱动框架，它将可解释性洞察转化为可操作的指导，用于在单个医院系统内针对不同亚群调整模型训练和评估。在三个大型EHR数据集：GOSSIS-1-eICU、WiDS和MIMIC-IV上进行评估，AdaptHetero持续识别在预测ICU死亡率、住院死亡和隐匿性低氧血症方面的异构模型行为。通过整合基于SHAP的解释和无监督聚类，该框架增强了临床上有意义的亚组特定特征的识别，从而提高了预测性能并优化了临床部署。", "summary": "AdaptHetero是一个创新性的机器学习解释（MLI）驱动框架，旨在解决电子健康记录（EHR）数据异质性对亚组特定建模的挑战。该框架将MLI洞察转化为可操作的指导，用于定制跨亚群的模型训练和评估。通过整合SHAP解释和无监督聚类，AdaptHetero能够识别异构模型行为和有意义的亚组特征，从而在预测ICU死亡率、住院死亡和隐匿性低氧血症等任务上，提高了预测性能并优化了临床部署，并在大型EHR数据集上得到了验证。", "keywords": "机器学习解释, 亚组适应, 电子健康记录, 临床预测, SHAP, 异质性", "comments": "该论文的创新点在于将机器学习解释（MLI）从单纯的理解工具提升为指导模型训练和部署的行动框架。通过结合SHAP和无监督聚类，AdaptHetero有效地解决了EHR数据固有的复杂性和亚组异质性问题，这对于实现精准医疗至关重要。其在多个大型临床数据集上的验证增强了其可靠性和潜在的临床影响力。"}}
{"id": "2507.19060", "title": "PurpCode: Reasoning for Safer Code Generation", "authors": ["Jiawei Liu", "Nirav Diwan", "Zhe Wang", "Haoyu Zhai", "Xiaona Zhou", "Kiet A. Nguyen", "Tianjiao Yu", "Muntasir Wahed", "Yinlin Deng", "Hadjer Benkraouda", "Yuxiang Wei", "Lingming Zhang", "Ismini Lourentzou", "Gang Wang"], "categories": ["cs.CR", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19060v2", "summary": "We introduce PurpCode, the first post-training recipe for training safe code\nreasoning models towards generating secure code and defending against malicious\ncyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule\nLearning, which explicitly teaches the model to reference cybersafety rules to\ngenerate vulnerability-free code and to avoid facilitating malicious\ncyberactivities; and (ii) Reinforcement Learning, which optimizes model safety\nand preserves model utility through diverse, multi-objective reward mechanisms.\nTo empower the training pipelines with comprehensive cybersafety data, we\nconduct internal red-teaming to synthesize comprehensive and high-coverage\nprompts based on real-world tasks for inducing unsafe cyberactivities in the\nmodel. Based on PurpCode, we develop a reasoning-based coding model, namely\nPurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming\nvarious frontier models. Meanwhile, our alignment method decreases the model\noverrefusal rates in both general and cybersafety-specific scenarios, while\npreserving model utility in both code generation and common security knowledge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19060v2", "cate": "cs.CR", "date": "2025-07-25", "updated": "2025-07-31", "AI": {"title_translation": "PurpCode：更安全代码生成的推理", "tldr": "PurpCode是一个用于训练安全代码推理模型的后训练方法，通过规则学习和强化学习两阶段，旨在生成安全代码并抵御恶意网络活动，其开发的模型PurpCode-32B在网络安全方面表现出最先进的性能。", "motivation": "为了训练能够生成安全代码并防御恶意网络活动的模型，以应对日益增长的网络安全挑战和恶意网络活动。", "method": "PurpCode是一种两阶段后训练方法：(i) 规则学习：明确教导模型参考网络安全规则以生成无漏洞代码并避免促成恶意网络活动。(ii) 强化学习：通过多样化、多目标的奖励机制优化模型安全性并保持模型实用性。为了提供全面的网络安全数据，研究团队进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型产生不安全网络活动。", "result": "基于PurpCode，开发了推理型编码模型PurpCode-32B，该模型展示了最先进的网络安全性能，优于各种前沿模型。同时，该对齐方法在通用和网络安全特定场景中降低了模型的过度拒绝率，并保持了模型在代码生成和常见安全知识方面的实用性。", "conclusion": "PurpCode成功地提供了一种训练安全代码推理模型的方法，并开发了在网络安全方面表现卓越的模型，同时有效平衡了安全性与实用性。", "translation": "我们引入了PurpCode，这是第一个用于训练安全代码推理模型的后训练方案，旨在生成安全代码并抵御恶意网络活动。PurpCode分两个阶段训练推理模型：(i) 规则学习，明确教导模型参考网络安全规则以生成无漏洞代码并避免促成恶意网络活动；(ii) 强化学习，通过多样化、多目标的奖励机制优化模型安全性并保持模型实用性。为了为训练管道提供全面的网络安全数据，我们进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型产生不安全网络活动。基于PurpCode，我们开发了一个基于推理的编码模型，即PurpCode-32B，该模型展示了最先进的网络安全性能，优于各种前沿模型。同时，我们的对齐方法在通用和网络安全特定场景中降低了模型的过度拒绝率，同时保持了模型在代码生成和常见安全知识方面的实用性。", "summary": "PurpCode是一种新颖的、两阶段的后训练方法，用于开发能够生成安全代码并抵御网络攻击的推理模型。该方法结合了规则学习以避免漏洞和强化学习以优化安全性与实用性。通过内部红队演练生成全面的网络安全数据，PurpCode成功训练出PurpCode-32B模型，该模型在网络安全性能上超越了现有模型，并有效降低了过度拒绝率，同时保持了代码生成和安全知识的实用性。", "keywords": "安全代码生成, 推理模型, 网络安全, 强化学习, PurpCode", "comments": "PurpCode的创新之处在于其结合了规则学习和强化学习的两阶段后训练方法，专门针对代码生成的安全性。通过内部红队演练合成高质量的网络安全数据，解决了训练安全模型的数据稀缺问题。其成果PurpCode-32B在保持模型实用性的同时，显著提升了代码生成的安全性，这对于当前大模型在代码生成领域面临的安全挑战具有重要意义。"}}
{"id": "2507.23421", "title": "Dual-Mode Wireless Devices for Adaptive Pull and Push-Based Communication", "authors": ["Sara Cavallero", "Fabio Saggese", "Junya Shiraishi", "Israel Leyva-Mayorga", "Shashi Raj Pandey", "Chiara Buratti", "Petar Popovski"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Transactions on Communications, Copyright might be transferred without notice", "url": "http://arxiv.org/abs/2507.23421v1", "summary": "This paper introduces a dual-mode communication framework for wireless\ndevices that integrates query-driven (pull) and event-driven (push)\ntransmissions within a unified time-frame structure. Devices typically respond\nto information requests in pull mode, but if an anomaly is detected, they\npreempt the regular response to report the critical condition. Additionally,\npush-based communication is used to proactively send critical data without\nwaiting for a request. This adaptive approach ensures timely, context-aware,\nand efficient data delivery across different network conditions. To achieve\nhigh energy efficiency, we incorporate a wake-up radio mechanism and we design\na tailored medium access control (MAC) protocol that supports data traffic\nbelonging to the different communication classes. A comprehensive system-level\nanalysis is conducted, accounting for the wake-up control operation and\nevaluating three key performance metrics: the success probability of anomaly\nreports (push traffic), the success probability of query responses (pull\ntraffic) and the total energy consumption. Numerical results characterize the\nsystem's behavior and highlight the inherent trade-off in success probabilities\nbetween push- and pull-based traffic as a function of allocated communication\nresources. Our analysis demonstrates that the proposed approach reduces energy\nconsumption by up to 30% compared to a traditional approach, while maintaining\nreliable support for both communication paradigms.", "comment": "Submitted to IEEE Transactions on Communications, Copyright might be\n  transferred without notice", "pdf_url": "http://arxiv.org/pdf/2507.23421v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于自适应拉取和推送通信的双模无线设备", "tldr": "本文提出了一种双模无线通信框架，结合了拉取和推送传输，通过唤醒无线电和定制MAC协议实现高效、及时的自适应数据传输，并能显著降低能耗。", "motivation": "无线设备需要在不同网络条件下实现及时、上下文感知和高效的数据传输，同时解决能耗问题。", "method": "本文引入了一个双模通信框架，将查询驱动（拉取）和事件驱动（推送）传输整合到一个统一的时间帧结构中。该方法通过结合唤醒无线电机制和设计定制的媒体访问控制（MAC）协议来实现高能效，以支持不同通信类别的数据流量。", "result": "数值结果表明，该系统在推送和拉取流量的成功概率之间存在固有的权衡，并且所提出的方法与传统方法相比，能耗降低了高达30%，同时保持了对两种通信范式的可靠支持。", "conclusion": "所提出的双模通信方法通过优化资源分配，在保持两种通信模式可靠性的同时，显著降低了能耗。", "translation": "本文介绍了一种用于无线设备的双模通信框架，该框架将查询驱动（拉取）和事件驱动（推送）传输集成到统一的时间帧结构中。设备通常以拉取模式响应信息请求，但如果检测到异常，它们会抢占常规响应以报告关键情况。此外，基于推送的通信用于主动发送关键数据，而无需等待请求。这种自适应方法确保了在不同网络条件下及时、上下文感知和高效的数据传输。为了实现高能效，我们结合了唤醒无线电机制，并设计了定制的媒体访问控制（MAC）协议，以支持属于不同通信类别的数据流量。我们进行了全面的系统级分析，考虑了唤醒控制操作，并评估了三个关键性能指标：异常报告（推送流量）的成功概率、查询响应（拉取流量）的成功概率和总能耗。数值结果表征了系统的行为，并突出了推送和拉取流量成功概率之间固有的权衡，该权衡是分配通信资源的函数。我们的分析表明，与传统方法相比，所提出的方法将能耗降低了高达30%，同时保持了对两种通信范式的可靠支持。", "summary": "本文提出了一种创新的双模无线通信框架，该框架在一个统一的时间帧内集成了查询驱动（拉取）和事件驱动（推送）传输。通过自适应地在两种模式之间切换，并在检测到异常时优先推送关键信息，该系统旨在实现及时、上下文感知和高效的数据传输。为提高能效，研究引入了唤醒无线电机制并设计了定制的MAC协议。系统级分析和数值结果表明，该方法在推送和拉取流量的成功概率之间存在权衡，但与传统方法相比，能耗降低了高达30%，同时确保了两种通信模式的可靠性。", "keywords": "双模通信, 拉取, 推送, 唤醒无线电, 能效", "comments": "该论文的创新之处在于其提出的双模通信框架，它巧妙地结合了拉取和推送机制，并通过自适应行为和唤醒无线电技术显著提升了能效和数据传输的及时性。这种方法对于需要低功耗和高可靠性的物联网设备和传感器网络具有重要意义。"}}
{"id": "2507.23218", "title": "An Information Bottleneck Asset Pricing Model", "authors": ["Che Sun"], "categories": ["cs.CE", "cs.AI"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23218v1", "summary": "Deep neural networks (DNNs) have garnered significant attention in financial\nasset pricing, due to their strong capacity for modeling complex nonlinear\nrelationships within financial data. However, sophisticated models are prone to\nover-fitting to the noise information in financial data, resulting in inferior\nperformance. To address this issue, we propose an information bottleneck asset\npricing model that compresses data with low signal-to-noise ratios to eliminate\nredundant information and retain the critical information for asset pricing.\nOur model imposes constraints of mutual information during the nonlinear\nmapping process. Specifically, we progressively reduce the mutual information\nbetween the input data and the compressed representation while increasing the\nmutual information between the compressed representation and the output\nprediction. The design ensures that irrelevant information, which is\nessentially the noise in the data, is forgotten during the modeling of\nfinancial nonlinear relationships without affecting the final asset pricing. By\nleveraging the constraints of the Information bottleneck, our model not only\nharnesses the nonlinear modeling capabilities of deep networks to capture the\nintricate relationships within financial data but also ensures that noise\ninformation is filtered out during the information compression process.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23218v1", "cate": "cs.CE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "信息瓶颈资产定价模型", "tldr": "提出一种信息瓶颈资产定价模型，通过过滤金融数据中的噪声来提高深度神经网络的性能，解决过拟合问题。", "motivation": "深度神经网络在金融资产定价中容易对噪声信息过拟合，导致性能不佳。", "method": "提出一种信息瓶颈资产定价模型，通过在非线性映射过程中施加互信息约束来压缩低信噪比数据。具体而言，逐步减少输入数据与压缩表示之间的互信息，同时增加压缩表示与输出预测之间的互信息，以过滤掉噪声信息。", "result": "Not mentioned in abstract", "conclusion": "该模型利用信息瓶颈约束，不仅能利用深度网络的非线性建模能力捕捉金融数据中的复杂关系，还能在信息压缩过程中过滤掉噪声信息，解决了传统深度网络在金融数据中易受噪声影响的问题。", "translation": "深度神经网络（DNNs）因其在金融数据中建模复杂非线性关系的强大能力而在金融资产定价领域受到广泛关注。然而，复杂的模型容易对金融数据中的噪声信息过拟合，导致性能不佳。为了解决这个问题，我们提出了一种信息瓶颈资产定价模型，该模型通过压缩低信噪比数据来消除冗余信息并保留资产定价的关键信息。我们的模型在非线性映射过程中施加互信息约束。具体而言，我们逐步减少输入数据与压缩表示之间的互信息，同时增加压缩表示与输出预测之间的互信息。这种设计确保了在金融非线性关系建模过程中，不相关的信息（本质上是数据中的噪声）被遗忘，而不影响最终的资产定价。通过利用信息瓶颈的约束，我们的模型不仅能利用深度网络的非线性建模能力捕捉金融数据中的复杂关系，还能在信息压缩过程中过滤掉噪声信息。", "summary": "本文提出了一种信息瓶颈资产定价模型，旨在解决深度神经网络在金融资产定价中因噪声过拟合导致性能下降的问题。该模型通过在非线性映射过程中施加互信息约束，压缩低信噪比数据，有效去除冗余和噪声信息，同时保留对资产定价至关重要的信息。这种方法使得模型能够充分利用深度网络的非线性建模能力，同时确保在信息压缩过程中噪声被有效过滤。", "keywords": "信息瓶颈, 资产定价, 深度神经网络, 互信息, 金融数据", "comments": "该论文提出了一种创新的方法，将信息瓶颈原理应用于金融资产定价，以解决深度学习模型在处理金融数据时常见的过拟合噪声问题。其核心创新在于通过互信息约束来显式地过滤噪声，这对于提高金融模型在实际应用中的鲁棒性和性能具有重要意义。"}}
{"id": "2507.23256", "title": "EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision", "authors": ["Ahmed Jaheen", "Abdelrahman Elsayed", "Damir Kim", "Daniil Tikhonov", "Matheus Scatolin", "Mohor Banerjee", "Qiankun Ji", "Mostafa Salem", "Hu Wang", "Sarim Hashmi", "Mohammad Yaqub"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)", "url": "http://arxiv.org/abs/2507.23256v1", "summary": "Brain cancer affects millions worldwide, and in nearly every clinical\nsetting, doctors rely on magnetic resonance imaging (MRI) to diagnose and\nmonitor gliomas. However, the current standard for tumor quantification through\nmanual segmentation of multi-parametric MRI is time-consuming, requires expert\nradiologists, and is often infeasible in under-resourced healthcare systems.\nThis problem is especially pronounced in low-income regions, where MRI scanners\nare of lower quality and radiology expertise is scarce, leading to incorrect\nsegmentation and quantification. In addition, the number of acquired MRI scans\nin Africa is typically small. To address these challenges, the BraTS-Lighthouse\n2025 Challenge focuses on robust tumor segmentation in sub-Saharan Africa\n(SSA), where resource constraints and image quality degradation introduce\nsignificant shifts. In this study, we present EMedNeXt -- an enhanced brain\ntumor segmentation framework based on MedNeXt V2 with deep supervision and\noptimized post-processing pipelines tailored for SSA. EMedNeXt introduces three\nkey contributions: a larger region of interest, an improved nnU-Net v2-based\narchitectural skeleton, and a robust model ensembling system. Evaluated on the\nhidden validation set, our solution achieved an average LesionWise DSC of 0.897\nwith an average LesionWise NSD of 0.541 and 0.84 at a tolerance of 0.5 mm and\n1.0 mm, respectively.", "comment": "Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23256v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "EMedNeXt：一种为撒哈拉以南非洲地区优化的基于MedNeXt V2深度监督的增强型脑肿瘤分割框架", "tldr": "EMedNeXt是一个针对撒哈拉以南非洲地区（SSA）资源受限和图像质量下降问题，提出的增强型脑肿瘤分割框架，在BraTS-Lighthouse 2025挑战赛中表现出色。", "motivation": "全球数百万人口受脑癌影响，医生依赖MRI诊断和监测胶质瘤。然而，目前通过手动分割多参数MRI进行肿瘤量化的标准方法耗时、需要专家放射科医生，且在资源不足的医疗系统中往往不可行。在低收入地区，MRI扫描仪质量较低且放射学专业知识稀缺，导致分割和量化不准确。此外，非洲获取的MRI扫描数量通常较少。BraTS-Lighthouse 2025挑战赛旨在解决撒哈拉以南非洲（SSA）地区由于资源限制和图像质量下降带来的显著偏移问题。", "method": "本研究提出了EMedNeXt，一个基于MedNeXt V2并结合深度监督和针对SSA优化的后处理流水线的增强型脑肿瘤分割框架。EMedNeXt引入了三个关键贡献：更大的感兴趣区域、改进的基于nnU-Net v2的架构骨架以及一个鲁棒的模型集成系统。", "result": "在隐藏验证集上进行评估，EMedNeXt解决方案实现了平均病灶级DSC为0.897，平均病灶级NSD在0.5毫米容差下为0.541，在1.0毫米容差下为0.84。", "conclusion": "EMedNeXt框架为撒哈拉以南非洲地区面临的资源限制和图像质量下降挑战，提供了一个高效且鲁棒的脑肿瘤分割解决方案，其性能指标证明了其在该复杂环境下的实用性。", "translation": "脑癌影响全球数百万人，在几乎所有临床环境中，医生都依赖磁共振成像（MRI）来诊断和监测胶质瘤。然而，目前通过手动分割多参数MRI进行肿瘤量化的标准方法耗时、需要专家放射科医生，并且在资源不足的医疗系统中往往不可行。这个问题在低收入地区尤为突出，这些地区的MRI扫描仪质量较低，放射学专业知识稀缺，导致分割和量化不准确。此外，非洲获取的MRI扫描数量通常较少。为了应对这些挑战，BraTS-Lighthouse 2025挑战赛专注于在撒哈拉以南非洲（SSA）地区进行鲁棒的肿瘤分割，该地区资源限制和图像质量下降带来了显著的偏移。在这项研究中，我们提出了EMedNeXt——一个基于MedNeXt V2并结合深度监督和针对SSA优化的后处理流水线的增强型脑肿瘤分割框架。EMedNeXt引入了三个关键贡献：更大的感兴趣区域、改进的基于nnU-Net v2的架构骨架，以及一个鲁棒的模型集成系统。在隐藏验证集上进行评估，我们的解决方案实现了平均病灶级DSC为0.897，平均病灶级NSD在0.5毫米容差下为0.541，在1.0毫米容差下为0.84。", "summary": "EMedNeXt是一个为应对撒哈拉以南非洲（SSA）地区脑肿瘤分割挑战而设计的增强型框架。该地区面临MRI质量低、专家稀缺和扫描量少的问题。EMedNeXt基于MedNeXt V2，结合深度监督和优化的后处理流程，并引入了更大的感兴趣区域、改进的nnU-Net v2架构骨架和鲁棒的模型集成系统。在隐藏验证集上的评估显示，该框架在病灶级DSC和NSD方面取得了优异的性能，证明了其在资源受限环境下的有效性。", "keywords": "脑肿瘤分割, 撒哈拉以南非洲, MedNeXt V2, 深度监督, MRI", "comments": "该研究通过提出EMedNeXt框架，创新性地解决了撒哈拉以南非洲地区脑肿瘤分割面临的实际挑战，考虑了当地特有的资源限制和图像质量问题。其结合MedNeXt V2、深度监督、改进的nnU-Net v2架构以及模型集成，增强了模型的鲁棒性和准确性，对于改善该地区的医疗诊断具有重要意义。"}}
{"id": "2507.23247", "title": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "authors": ["Sneha Oram", "Pushpak Bhattacharyya"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23247v1", "summary": "There has been an increase in recent advancements in the explainability and\ndevelopment of personalized chatbots for mental health. However, the reasoning\naspects for explainability and dialogue discourse have not been explored\npreviously for mental health. Hence, we are investigating the pragmatic\nreasoning capability of large language models (LLMs) in this domain. We\nintroduce P-ReMe dataset, and propose a modified definition for the pragmatic\nphenomena of implicature (implied meaning) and presupposition (implicit\nassumption) in mental health. Following the definition, we formulate two tasks\nin implicature and one task in presupposition. To benchmark the dataset and the\npresented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and\nQwen. The results of the experiments suggest that Mistral and Qwen show\nsubstantial reasoning capabilities in the domain. In addition, we also propose\nStiPRompts to study the stigma around mental health with the state-of-the-art\nLLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings\nshow that Claude-3.5-haiku deals with the stigma more responsibly compared to\nthe other two LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23247v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "P-ReMIS：精神健康中的语用推理及其社会影响", "tldr": "本文研究大型语言模型在精神健康领域的语用推理能力，引入了P-ReMe数据集并提出了新的语用现象定义和任务。实验表明Mistral和Qwen在推理方面表现出色，Claude-3.5-haiku在处理精神健康污名方面更负责任。", "motivation": "尽管精神健康领域的可解释性和个性化聊天机器人取得了进展，但此前尚未探索针对精神健康的可解释性和对话语篇中的推理方面。", "method": "本文引入了P-ReMe数据集，并修改了精神健康中蕴涵和预设等语用现象的定义。基于此定义，构建了两项蕴涵任务和一项预设任务。使用Llama3.1、Mistral、MentaLLaMa和Qwen对数据集和任务进行基准测试。此外，还提出了StiPRompts来研究精神健康污名，并使用GPT-4o mini、Deepseek-chat和Claude-3.5-haiku进行评估。", "result": "实验结果表明，Mistral和Qwen在该领域展现出显著的推理能力。在处理精神健康污名方面，Claude-3.5-haiku比其他两个大型语言模型表现得更负责任。", "conclusion": "大型语言模型在精神健康领域的语用推理方面具有潜力，其中Mistral和Qwen表现突出。同时，LLMs在处理精神健康污名方面表现各异，Claude-3.5-haiku展现出更负责任的处理能力。", "translation": "近年来，精神健康领域的可解释性和个性化聊天机器人开发取得了显著进展。然而，精神健康领域的可解释性和对话语篇中的推理方面此前尚未被探索。因此，我们正在研究大型语言模型（LLMs）在该领域的语用推理能力。我们引入了P-ReMe数据集，并提出了精神健康中蕴涵（隐含意义）和预设（隐含假设）等语用现象的修改定义。根据该定义，我们制定了两项蕴涵任务和一项预设任务。为了对数据集和所提出的任务进行基准测试，我们考虑了四种模型——Llama3.1、Mistral、MentaLLaMa和Qwen。实验结果表明，Mistral和Qwen在该领域展现出显著的推理能力。此外，我们还提出了StiPRompts，以利用最先进的LLMs，如GPT-4o mini、Deepseek-chat和Claude-3.5-haiku，来研究精神健康相关的污名。我们的评估结果显示，与另外两个LLMs相比，Claude-3.5-haiku在处理污名方面表现得更负责任。", "summary": "本文旨在探讨大型语言模型在精神健康领域的语用推理能力。为此，作者构建了P-ReMe数据集，并重新定义了精神健康背景下的蕴涵和预设现象，设计了相应的推理任务。通过对Llama3.1、Mistral、MentaLLaMa和Qwen等模型的基准测试，发现Mistral和Qwen展现出强大的推理能力。此外，研究还通过StiPRompts评估了GPT-4o mini、Deepseek-chat和Claude-3.5-haiku在处理精神健康污名方面的表现，结果表明Claude-3.5-haiku的处理方式更为负责。", "keywords": "语用推理, 精神健康, 大型语言模型, 蕴涵, 预设", "comments": "本研究通过引入新的数据集和任务，首次系统地探索了大型语言模型在精神健康领域中的语用推理能力，填补了该领域的空白。其创新之处在于对精神健康背景下的语用现象进行了具体定义和任务设计。同时，对LLMs处理精神健康污名的探讨也具有重要的社会意义，为未来开发更负责任、更具同理心的心理健康AI提供了方向。"}}
{"id": "2503.07047", "title": "Recovering Partially Corrupted Objects via Sketch-Guided Bidirectional Feature Interaction", "authors": ["Yongle Zhang", "Yimin Liu", "Yan Huang", "Qiang Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2503.07047v2", "summary": "Text-guided diffusion models have achieved remarkable success in object\ninpainting by providing high-level semantic guidance through text prompts.\nHowever, they often lack precise pixel-level spatial control, especially in\nscenarios involving partially corrupted objects where critical uncorrupted cues\nremain. To overcome this limitation, sketch-guided methods have been\nintroduced, using either indirect gradient modulation or direct sketch\ninjection to improve structural control. Yet, existing approaches typically\nestablish a one-way mapping from the sketch to the masked regions only,\nneglecting the contextual information from unmasked object areas. This leads to\na disconnection between the sketch and the uncorrupted content, thereby causing\nsketch-guided inconsistency and structural mismatch. To tackle this challenge,\nwe propose a sketch-guided bidirectional feature interaction framework built\nupon a pretrained Stable Diffusion model. Our bidirectional interaction\nfeatures two complementary directions, context-to-sketch and\nsketch-to-inpainting, that enable fine-grained spatial control for partially\ncorrupted object inpainting. In the context-to-sketch direction, multi-scale\nlatents from uncorrupted object regions are propagated to the sketch branch to\ngenerate a visual mask that adapts the sketch features to the visible context\nand denoising progress. In the sketch-to-inpainting direction, a\nsketch-conditional affine transformation modulates the influence of sketch\nguidance based on the learned visual mask, ensuring consistency with\nuncorrupted object content. This interaction is applied at multiple scales\nwithin the encoder of the diffusion U-Net, enabling the model to restore object\nstructures with enhanced spatial fidelity. Extensive experiments on two newly\nconstructed benchmark datasets demonstrate that our approach outperforms\nstate-of-the-art methods.", "comment": "13 pages. This work has been submitted to the IEEE for possible\n  publication", "pdf_url": "http://arxiv.org/pdf/2503.07047v2", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-31", "AI": {"title_translation": "通过草图引导的双向特征交互恢复部分损坏的物体", "tldr": "提出一种草图引导的双向特征交互框架，用于恢复部分损坏的物体，解决了现有方法缺乏像素级控制和上下文信息利用不足的问题。", "motivation": "现有的文本引导扩散模型在物体修复中缺乏精确的像素级空间控制，而现有的草图引导方法通常只建立从草图到遮罩区域的单向映射，忽略了未遮罩区域的上下文信息，导致草图引导不一致和结构不匹配。", "method": "我们提出了一个基于预训练Stable Diffusion模型的草图引导双向特征交互框架。该框架包含两个互补方向：上下文到草图（context-to-sketch）和草图到修复（sketch-to-inpainting）。在上下文到草图方向，来自未损坏物体区域的多尺度潜在特征被传播到草图分支，生成一个视觉遮罩以使草图特征适应可见上下文和去噪过程。在草图到修复方向，一个草图条件仿射变换根据学习到的视觉遮罩来调节草图引导的影响，确保与未损坏的物体内容一致。这种交互在扩散U-Net编码器的多个尺度上应用。", "result": "在两个新构建的基准数据集上的广泛实验表明，我们的方法优于最先进的方法。", "conclusion": "我们提出的草图引导双向特征交互框架能够以增强的空间保真度恢复物体结构，有效解决了部分损坏物体修复中的像素级控制和上下文一致性问题。", "translation": "文本引导扩散模型通过文本提示提供高层次语义指导，在物体修复方面取得了显著成功。然而，它们通常缺乏精确的像素级空间控制，尤其是在涉及部分损坏物体且关键未损坏线索仍然存在的情况下。为了克服这一限制，引入了草图引导方法，通过间接梯度调制或直接草图注入来改善结构控制。然而，现有方法通常只建立从草图到遮罩区域的单向映射，忽略了来自未遮罩物体区域的上下文信息。这导致草图与未损坏内容之间的脱节，从而引起草图引导不一致和结构不匹配。为了解决这一挑战，我们提出了一个基于预训练Stable Diffusion模型的草图引导双向特征交互框架。我们的双向交互具有两个互补方向：上下文到草图和草图到修复，这使得部分损坏物体修复能够实现精细的空间控制。在上下文到草图方向，来自未损坏物体区域的多尺度潜在特征被传播到草图分支，生成一个视觉遮罩，使草图特征适应可见上下文和去噪过程。在草图到修复方向，一个草图条件仿射变换根据学习到的视觉遮罩来调节草图引导的影响，确保与未损坏的物体内容一致。这种交互在扩散U-Net编码器的多个尺度内应用，使模型能够以增强的空间保真度恢复物体结构。在两个新构建的基准数据集上的广泛实验表明，我们的方法优于最先进的方法。", "summary": "该论文提出了一种名为“草图引导双向特征交互”的新框架，用于修复部分损坏的物体。针对现有文本引导和草图引导方法在像素级控制和上下文信息利用上的不足，该框架基于Stable Diffusion模型，通过上下文到草图和草图到修复的双向交互，将未损坏区域的上下文信息融入草图引导过程，从而解决了草图引导不一致和结构不匹配的问题。实验证明，该方法在恢复物体结构方面表现出更高的空间保真度，并超越了现有最先进的方法。", "keywords": "物体修复, 扩散模型, 草图引导, 双向交互, 空间控制", "comments": "该论文的创新点在于提出了双向特征交互机制，有效解决了现有草图引导修复方法中草图与未损坏内容脱节的问题。通过引入上下文到草图和草图到修复的两个方向，实现了对部分损坏物体更精细的像素级空间控制，显著提升了修复结果的结构一致性和保真度，对于物体修复领域具有重要意义。"}}
{"id": "2507.23080", "title": "Causal-Inspired Multi-Agent Decision-Making via Graph Reinforcement Learning", "authors": ["Jing Wang", "Yan Jin", "Fei Ding", "Chongfeng Wei"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23080v1", "summary": "Since the advent of autonomous driving technology, it has experienced\nremarkable progress over the last decade. However, most existing research still\nstruggles to address the challenges posed by environments where multiple\nvehicles have to interact seamlessly. This study aims to integrate causal\nlearning with reinforcement learning-based methods by leveraging causal\ndisentanglement representation learning (CDRL) to identify and extract causal\nfeatures that influence optimal decision-making in autonomous vehicles. These\nfeatures are then incorporated into graph neural network-based reinforcement\nlearning algorithms to enhance decision-making in complex traffic scenarios. By\nusing causal features as inputs, the proposed approach enables the optimization\nof vehicle behavior at an unsignalized intersection. Experimental results\ndemonstrate that our proposed method achieves the highest average reward during\ntraining and our approach significantly outperforms other learning-based\nmethods in several key metrics such as collision rate and average cumulative\nreward during testing. This study provides a promising direction for advancing\nmulti-agent autonomous driving systems and make autonomous vehicles' navigation\nsafer and more efficient in complex traffic environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23080v1", "cate": "cs.MA", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "因果启发的图强化学习多智能体决策", "tldr": "本研究提出了一种结合因果学习和图强化学习的方法，通过提取因果特征来提升自动驾驶中多智能体在复杂交通场景下的决策能力，并在实验中表现出更高的奖励和更低的碰撞率。", "motivation": "现有的自动驾驶技术在处理多车辆无缝交互的环境中仍面临挑战，本研究旨在解决这一问题，提升自动驾驶车辆在复杂交通场景中的决策能力。", "method": "本研究将因果学习与强化学习相结合，利用因果解缠表示学习（CDRL）识别并提取影响自动驾驶车辆最佳决策的因果特征。这些特征随后被整合到基于图神经网络的强化学习算法中，以优化车辆在无信号交叉口的决策行为。", "result": "实验结果表明，所提出的方法在训练期间取得了最高的平均奖励，并且在测试期间，在碰撞率和平均累积奖励等关键指标上显著优于其他基于学习的方法。", "conclusion": "本研究为推进多智能体自动驾驶系统提供了一个有前景的方向，并使自动驾驶车辆在复杂交通环境中导航更安全、更高效。", "translation": "自自动驾驶技术问世以来，在过去十年中取得了显著进展。然而，大多数现有研究仍然难以解决多辆车必须无缝交互的环境所带来的挑战。本研究旨在通过利用因果解缠表示学习（CDRL）来识别和提取影响自动驾驶车辆最佳决策的因果特征，从而将因果学习与基于强化学习的方法相结合。然后，这些特征被整合到基于图神经网络的强化学习算法中，以增强复杂交通场景中的决策能力。通过使用因果特征作为输入，所提出的方法能够优化车辆在无信号交叉口的行驶行为。实验结果表明，我们提出的方法在训练期间实现了最高的平均奖励，并且在测试期间，我们的方法在碰撞率和平均累积奖励等几个关键指标上显著优于其他基于学习的方法。这项研究为推进多智能体自动驾驶系统提供了一个有前景的方向，并使自动驾驶车辆在复杂交通环境中的导航更安全、更高效。", "summary": "本研究提出了一种因果启发的图强化学习方法，旨在解决自动驾驶中多智能体交互的决策难题。该方法利用因果解缠表示学习（CDRL）提取影响最优决策的因果特征，并将其融入图神经网络强化学习算法中，以优化车辆在复杂交通场景，尤其是在无信号交叉口的决策。实验证明，该方法在训练中获得最高平均奖励，并在测试中显著降低碰撞率，提高累积奖励，为多智能体自动驾驶系统的发展提供了新的方向。", "keywords": "因果学习, 图强化学习, 多智能体决策, 自动驾驶, 因果特征", "comments": "这项研究的创新之处在于其将因果学习与图强化学习相结合，通过明确提取和利用因果特征来提升多智能体决策的解释性和鲁棒性。这种方法有望解决传统强化学习在复杂交互环境中因缺乏因果理解而导致的泛化性问题，对于提高自动驾驶系统的安全性和效率具有重要意义。"}}
{"id": "2507.22934", "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey", "authors": ["Jingwei Zhao", "Yuhua Wen", "Qifei Li", "Minchi Hu", "Yingying Zhou", "Jingyao Xue", "Junyang Wu", "Yingming Gao", "Zhengqi Wen", "Jianhua Tao", "Ya Li"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to ACM Computing Surveys", "url": "http://arxiv.org/abs/2507.22934v1", "summary": "Intent recognition aims to identify users' underlying intentions,\ntraditionally focusing on text in natural language processing. With growing\ndemands for natural human-computer interaction, the field has evolved through\ndeep learning and multimodal approaches, incorporating data from audio, vision,\nand physiological signals. Recently, the introduction of Transformer-based\nmodels has led to notable breakthroughs in this domain. This article surveys\ndeep learning methods for intent recognition, covering the shift from unimodal\nto multimodal techniques, relevant datasets, methodologies, applications, and\ncurrent challenges. It provides researchers with insights into the latest\ndevelopments in multimodal intent recognition (MIR) and directions for future\nresearch.", "comment": "Submitted to ACM Computing Surveys", "pdf_url": "http://arxiv.org/pdf/2507.22934v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "用于多模态意图识别的深度学习方法：一项综述", "tldr": "该综述论文回顾了深度学习在多模态意图识别中的应用，涵盖了从单模态到多模态方法的演变、相关数据集、方法、应用和挑战，并指出了未来的研究方向。", "motivation": "随着对自然人机交互需求的增长，意图识别领域已通过深度学习和多模态方法发展，并引入了音频、视觉和生理信号等数据。Transformer模型的引入带来了显著突破，因此需要对这些最新发展进行综述。", "method": "本文对用于意图识别的深度学习方法进行了综述，涵盖了从单模态到多模态技术的转变、相关数据集、方法论、应用和当前挑战。", "result": "该综述提供了关于多模态意图识别（MIR）最新进展的见解，并指出了未来的研究方向。", "conclusion": "该综述为研究人员提供了多模态意图识别领域的最新进展和未来研究方向的见解。", "translation": "意图识别旨在识别用户的潜在意图，传统上主要关注自然语言处理中的文本。随着对自然人机交互需求的增长，该领域已通过深度学习和多模态方法发展，并结合了来自音频、视觉和生理信号的数据。最近，基于Transformer模型的引入在该领域取得了显著突破。本文综述了用于意图识别的深度学习方法，涵盖了从单模态到多模态技术的转变、相关数据集、方法论、应用和当前挑战。它为研究人员提供了多模态意图识别（MIR）最新进展的见解和未来研究方向。", "summary": "本文对多模态意图识别（MIR）中的深度学习方法进行了全面综述。它追溯了意图识别领域从传统文本处理到整合音频、视觉和生理信号的多模态方法的演变，特别强调了Transformer模型带来的突破。该综述涵盖了相关数据集、方法论、应用和当前挑战，旨在为研究人员提供该领域的最新见解和未来研究方向。", "keywords": "意图识别, 深度学习, 多模态, Transformer, 综述", "comments": "该综述论文的重要性在于其及时性，它涵盖了深度学习，尤其是Transformer模型在多模态意图识别这一新兴且关键领域中的最新进展。它为研究人员提供了一个全面的概览，有助于理解当前的技术状态和识别未来的研究空白。"}}
{"id": "2507.22906", "title": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "authors": ["Bin Deng", "Jiatong Bai", "Feilong Zhao", "Zuming Xie", "Maolin Li", "Yan Wang", "Feng Shu"], "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22906v1", "summary": "As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO\narchitecture has been shown to own a great potential to replace the massive or\nextremely large-scale fully-digital MIMO in the future wireless networks to\naddress the three challenging problems faced by the latter: high energy\nconsumption, high circuit cost, and high complexity. However, how to\nintelligently sense the number and direction of multi-emitters via such a\nstructure is still an open hard problem. To address this, we propose a\ntwo-stage sensing framework that jointly estimates the number and direction\nvalues of multiple targets. Specifically, three target number sensing methods\nare designed: an improved eigen-domain clustering (EDC) framework, an enhanced\ndeep neural network (DNN) based on five key statistical features, and an\nimproved one-dimensional convolutional neural network (1D-CNN) utilizing full\neigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is\nachieved via the introduced online micro-clustering (OMC-DOA) method.\nFurthermore, we derive the Cram\\'er-Rao lower bound (CRLB) for the H2AD under\nmultiple-source conditions as a theoretical performance benchmark. Simulation\nresults show that the developed three methods achieve 100\\% number of targets\nsensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior\nunder extremely-low SNR conditions. The introduced OMC-DOA outperforms existing\nclustering and fusion-based DOA methods in multi-source environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22906v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于深度神经网络的绿色大规模H2AD MIMO接收机联合感知目标数量与方向的方法", "tldr": "该论文提出了一种基于深度神经网络的方法，用于绿色H2AD MIMO接收机联合感知目标数量和方向，旨在解决传统MIMO面临的挑战。", "motivation": "异构混合模拟-数字（H2AD）MIMO架构作为一种绿色MIMO结构，有望在未来无线网络中取代大规模或超大规模全数字MIMO，以解决后者面临的高能耗、高电路成本和高复杂性问题。然而，如何通过这种结构智能地感知多发射器的数量和方向仍然是一个开放的难题。", "method": "本文提出了一个两阶段感知框架，用于联合估计多个目标的数量和方向值。具体设计了三种目标数量感知方法：改进的特征域聚类（EDC）框架、基于五个关键统计特征的增强型深度神经网络（DNN），以及利用全特征值的改进一维卷积神经网络（1D-CNN）。随后，通过引入的在线微聚类（OMC-DOA）方法实现了低复杂度和高精度的到达方向（DOA）估计。此外，还推导了多源条件下H2AD的Cramér-Rao下界（CRLB）作为理论性能基准。", "result": "仿真结果表明，开发的三种目标数量感知方法在中高信噪比下实现了100%的感知准确率，而改进的1D-CNN在极低信噪比条件下表现出优越性。引入的OMC-DOA方法在多源环境中优于现有的聚类和基于融合的DOA方法。", "conclusion": "本文提出的基于DNN的两阶段框架，结合了目标数量感知和OMC-DOA的到达方向估计，有效解决了H2AD MIMO中的多目标感知问题，表现出高精度和高效率，尤其是在挑战性的信噪比条件下。", "translation": "作为一种绿色MIMO结构，异构混合模拟-数字（H2AD）MIMO架构已显示出在未来无线网络中取代大规模或超大规模全数字MIMO的巨大潜力，以解决后者面临的三个挑战性问题：高能耗、高电路成本和高复杂性。然而，如何通过这种结构智能地感知多发射器的数量和方向仍然是一个开放的难题。为了解决这个问题，我们提出了一个两阶段感知框架，联合估计多个目标的数量和方向值。具体来说，设计了三种目标数量感知方法：改进的特征域聚类（EDC）框架、基于五个关键统计特征的增强型深度神经网络（DNN），以及利用全特征值的改进一维卷积神经网络（1D-CNN）。随后，通过引入的在线微聚类（OMC-DOA）方法实现了低复杂度和高精度的DOA（到达方向）估计。此外，我们推导了多源条件下H2AD的Cramér-Rao下界（CRLB），作为理论性能基准。仿真结果表明，开发的三种方法在中高信噪比下实现了100%的目标数量感知，而改进的1D-CNN在极低信噪比条件下表现出优越性。引入的OMC-DOA在多源环境中优于现有的聚类和基于融合的DOA方法。", "summary": "本文提出了一种基于深度神经网络的两阶段感知框架，用于绿色H2AD MIMO接收机联合估计多个目标的数量和方向。该框架引入了三种目标数量感知方法（改进的EDC、增强型DNN、改进的1D-CNN）和一种用于低复杂度、高精度到达方向估计的OMC-DOA方法。仿真结果表明，所提出的方法具有高精度，特别是1D-CNN在低信噪比下表现优异，OMC-DOA的性能也优于现有方法。", "keywords": "深度神经网络, H2AD MIMO, 目标感知, 到达方向估计, 绿色MIMO", "comments": "该论文通过为未来无线网络中的目标感知提出一种绿色高效的解决方案，解决了一个关键问题。使用两阶段基于DNN的框架以及针对目标数量和DOA估计开发专门方法是创新的。CRLB的推导提供了一个有价值的理论基准。报告的在中高信噪比下目标数量感知的100%准确率、1D-CNN在极低信噪比下的卓越性能以及OMC-DOA的性能，都突出了所提出技术的实际适用性和鲁棒性。"}}
{"id": "2507.23159", "title": "Full-Duplex-Bench v1.5: Evaluating Overlap Handling for Full-Duplex Speech Models", "authors": ["Guan-Ting Lin", "Shih-Yun Shan Kuan", "Qirui Wang", "Jiachen Lian", "Tingle Li", "Hung-yi Lee"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Work in Progress", "url": "http://arxiv.org/abs/2507.23159v1", "summary": "While full-duplex speech agents promise natural, low-latency human--machine\ninteraction by concurrently processing input and output speech, overlap\nmanagement remains under-evaluated. We introduce Full-Duplex-Bench v1.5, a\nmodular, fully automated benchmark that simulates four overlap scenarios: user\ninterruption, listener backchannel, side conversation, and ambient speech. Our\nframework supports both open-sourced and commercial models, offering a\ncomprehensive, extensible metric suite -- categorical dialogue behaviors, stop\nand response latency, prosodic adaptation, and perceived speech quality -- that\ncan be tailored to application-specific criteria. Benchmarking five\nstate-of-the-art agents reveals two principal strategies: repair-first rapid\nyielding versus continuity-first sustained flow, and highlights\nscenario-dependent performance trends. The open-sourced design enables seamless\nextension with new audio assets, languages, and deployment contexts, empowering\npractitioners to customize and accelerate the evaluation of robust full-duplex\nspeech systems.", "comment": "Work in Progress", "pdf_url": "http://arxiv.org/pdf/2507.23159v1", "cate": "eess.AS", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "全双工基准 v1.5：评估全双工语音模型的重叠处理能力", "tldr": "引入Full-Duplex-Bench v1.5基准，用于评估全双工语音模型在四种重叠场景下的性能，揭示了两种主要处理策略，并支持定制化评估。", "motivation": "全双工语音代理虽然能实现低延迟人机交互，但其重叠管理能力尚未得到充分评估。", "method": "引入了Full-Duplex-Bench v1.5，一个模块化、全自动的基准测试平台，模拟了用户打断、听者反馈、侧边对话和环境语音四种重叠场景。该框架支持开源和商业模型，并提供了一套全面的、可扩展的指标套件，包括对话行为、延迟、韵律适应和感知语音质量。通过对五个最先进的代理进行基准测试。", "result": "基准测试揭示了两种主要策略：优先修复的快速让步策略与优先连续的持续流程策略，并突出了依赖于场景的性能趋势。", "conclusion": "Full-Duplex-Bench v1.5的开源设计使得其可以无缝扩展新的音频资产、语言和部署环境，从而使从业者能够定制和加速鲁棒全双工语音系统的评估。", "translation": "虽然全双工语音代理通过并发处理输入和输出语音，有望实现自然、低延迟的人机交互，但其重叠管理能力仍未得到充分评估。我们引入了Full-Duplex-Bench v1.5，这是一个模块化、全自动的基准测试平台，模拟了四种重叠场景：用户打断、听者反馈、侧边对话和环境语音。我们的框架支持开源和商业模型，提供了一套全面、可扩展的指标套件——包括分类对话行为、停止和响应延迟、韵律适应以及感知语音质量——这些指标可以根据特定应用需求进行定制。对五个最先进代理的基准测试揭示了两种主要策略：优先修复的快速让步策略与优先连续的持续流程策略，并突出了依赖于场景的性能趋势。其开源设计使得该基准可以无缝扩展新的音频资产、语言和部署上下文，从而使从业者能够定制和加速鲁棒全双工语音系统的评估。", "summary": "本文介绍了Full-Duplex-Bench v1.5，一个用于评估全双工语音模型重叠处理能力的自动化基准测试平台。该平台模拟四种典型重叠场景，并提供全面的可定制指标。通过对现有模型的测试，发现了两种主要的重叠处理策略。该开源工具旨在帮助从业者更有效地评估和开发鲁棒的全双工语音系统。", "keywords": "全双工语音, 重叠处理, 基准测试, 语音模型, 性能评估", "comments": "本文的创新点在于提出了一个专门用于评估全双工语音模型重叠处理能力的全面自动化基准测试平台Full-Duplex-Bench v1.5。它填补了该领域评估不足的空白，通过模拟多种真实场景和提供多维度指标，使得对全双工系统性能的评估更加细致和准确。其开源设计也极大地促进了该领域的研究和开发。"}}
{"id": "2507.22581", "title": "Unveiling the Influence of Amplifying Language-Specific Neurons", "authors": ["Inaya Rahmanisa", "Lyzander Marciano Andrylie", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Our code and dataset are made available at this https URL", "url": "http://arxiv.org/abs/2507.22581v2", "summary": "Language-specific neurons in LLMs that strongly correlate with individual\nlanguages have been shown to influence model behavior by deactivating them.\nHowever, their role in amplification remains underexplored. This work\ninvestigates the effect of amplifying language-specific neurons through\ninterventions across 18 languages, including low-resource ones, using three\nmodels primarily trained in different languages. We compare amplification\nfactors by their effectiveness in steering to the target language using a\nproposed Language Steering Shift (LSS) evaluation score, then evaluate it on\ndownstream tasks: commonsense reasoning (XCOPA, XWinograd), knowledge\n(Include), and translation (FLORES). The optimal amplification factors\neffectively steer output toward nearly all tested languages. Intervention using\nthis factor on downstream tasks improves self-language performance in some\ncases but generally degrades cross-language results. These findings highlight\nthe effect of language-specific neurons in multilingual behavior, where\namplification can be beneficial especially for low-resource languages, but\nprovides limited advantage for cross-lingual transfer.", "comment": "Our code and dataset are made available at\n  https://github.com/tauimbz/lang-task-neuron", "pdf_url": "http://arxiv.org/pdf/2507.22581v2", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "揭示放大语言特异性神经元的影响", "tldr": "研究发现，放大大型语言模型中语言特异性神经元可以有效引导模型输出到目标语言，对低资源语言有益，但对跨语言任务的提升有限。", "motivation": "大型语言模型中与特定语言强相关的语言特异性神经元已被证明通过停用可以影响模型行为，但它们在“放大”方面的作用仍未被充分探索。", "method": "本研究通过对18种语言（包括低资源语言）进行干预，放大语言特异性神经元，并使用三种不同语言训练的模型。通过提出的语言转向偏移（LSS）评估分数比较放大因子在引导目标语言方面的有效性，然后在下游任务（常识推理、知识、翻译）上进行评估。", "result": "最优放大因子能有效将输出引导至几乎所有测试语言。在下游任务中，使用此因子进行干预，在某些情况下能提高自语言性能，但通常会降低跨语言结果。", "conclusion": "这些发现强调了语言特异性神经元在多语言行为中的作用，其中放大可能特别有益于低资源语言，但对跨语言迁移的优势有限。", "translation": "大型语言模型（LLMs）中与特定语言强相关的语言特异性神经元已被证明通过停用可以影响模型行为。然而，它们在“放大”方面的作用仍未被充分探索。这项工作通过对18种语言（包括低资源语言）进行干预，并使用三种主要在不同语言中训练的模型，研究了放大语言特异性神经元的影响。我们通过提出的语言转向偏移（LSS）评估分数，比较了放大因子在引导目标语言方面的有效性，然后在下游任务：常识推理（XCOPA, XWinograd）、知识（Include）和翻译（FLORES）上进行评估。最佳放大因子能有效将输出引导至几乎所有测试语言。在下游任务中，使用此因子进行干预，在某些情况下能提高自语言性能，但通常会降低跨语言结果。这些发现强调了语言特异性神经元在多语言行为中的作用，其中放大可能特别有益于低资源语言，但对跨语言迁移的优势有限。", "summary": "这项研究探讨了放大大型语言模型中语言特异性神经元对模型行为的影响。通过在18种语言上进行干预，并使用LSS分数评估，发现最优放大因子能有效引导模型输出至目标语言。在下游任务中，这种放大对自语言性能有益，尤其对低资源语言，但对跨语言任务的性能提升有限。", "keywords": "语言特异性神经元, 放大, 多语言LLMs, 低资源语言, 跨语言迁移", "comments": "这项研究创新性地探讨了放大而非停用语言特异性神经元的作用，填补了该领域的空白。其重要性在于揭示了这种放大技术对提升低资源语言性能的潜力，但也指出了其在跨语言迁移方面的局限性。这为未来多语言LLM的优化提供了新的视角和方向。"}}
{"id": "2507.22879", "title": "RecGPT Technical Report", "authors": ["Chao Yi", "Dian Chen", "Gaoyang Guo", "Jiakai Tang", "Jian Wu", "Jing Yu", "Mao Zhang", "Sunhao Dai", "Wen Chen", "Wenjun Yang", "Yuning Jiang", "Zhujin Gao", "Bo Zheng", "Chi Li", "Dimin Wang", "Dixuan Wang", "Fan Li", "Fan Zhang", "Haibin Chen", "Haozhuang Liu", "Jialin Zhu", "Jiamang Wang", "Jiawei Wu", "Jin Cui", "Ju Huang", "Kai Zhang", "Kan Liu", "Lang Tian", "Liang Rao", "Longbin Li", "Lulu Zhao", "Na He", "Peiyang Wang", "Qiqi Huang", "Tao Luo", "Wenbo Su", "Xiaoxiao He", "Xin Tong", "Xu Chen", "Xunke Xi", "Yang Li", "Yaxuan Wu", "Yeqiu Yang", "Yi Hu", "Yinnan Song", "Yuchen Li", "Yujie Luo", "Yujin Yuan", "Yuliang Yan", "Zhengyang Wang", "Zhibo Xiao", "Zhixin Ma", "Zile Zhou", "Ziqi Zhang"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22879v2", "summary": "Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22879v2", "cate": "cs.IR", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "RecGPT 技术报告", "tldr": "RecGPT 提出了一种以用户意图为中心的新一代推荐系统框架，通过整合大型语言模型解决了传统推荐系统过度依赖历史行为导致的问题，并在淘宝上部署并取得了显著效果。", "motivation": "现有的推荐系统过度依赖历史共现模式和日志拟合目标，导致对狭窄的历史偏好过拟合，无法捕捉用户不断演变和潜在的兴趣。这加剧了信息茧房和长尾现象，最终损害用户体验并威胁推荐生态系统的可持续性。", "method": "论文提出 RecGPT 框架，将用户意图置于推荐流程的核心。它通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，将日志拟合推荐转变为以意图为中心的过程。为了有效地将通用 LLMs 大规模地与特定领域的推荐任务对齐，RecGPT 采用了多阶段训练范式，包括推理增强预对齐和自训练演进，并由人机协作判断系统指导。", "result": "RecGPT 已在淘宝App上全面部署。在线实验表明，它在所有利益相关者中都取得了持续的性能提升：用户受益于内容多样性和满意度增加，商家和平台获得更大的曝光和转化。", "conclusion": "LLM驱动的、以意图为中心的设计能够促进一个更可持续和互惠互利的推荐生态系统。", "translation": "推荐系统是人工智能最具影响力的应用之一，作为连接用户、商家和平台的关键基础设施。然而，目前大多数工业系统仍然严重依赖历史共现模式和日志拟合目标，即优化过去的用户互动而没有明确建模用户意图。这种日志拟合方法常常导致对狭窄历史偏好的过拟合，未能捕捉用户不断演变和潜在的兴趣。结果，它强化了信息茧房和长尾现象，最终损害用户体验并威胁整个推荐生态系统的可持续性。\n为了应对这些挑战，我们重新思考了推荐系统的整体设计范式，并提出了 RecGPT，一个将用户意图置于推荐流程中心的新一代框架。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，RecGPT 将日志拟合推荐转变为以意图为中心的过程。为了有效地将通用 LLMs 大规模地与上述特定领域的推荐任务对齐，RecGPT 采用了一种多阶段训练范式，该范式整合了推理增强预对齐和自训练演进，并由人机协作判断系统指导。目前，RecGPT 已在淘宝App上全面部署。在线实验表明，RecGPT 在所有利益相关者中都取得了持续的性能提升：用户受益于内容多样性和满意度增加，商家和平台获得更大的曝光和转化。这些在所有利益相关者中取得的全面改进结果验证了 LLM驱动的、以意图为中心的设计能够促进一个更可持续和互惠互利的推荐生态系统。", "summary": "这篇技术报告介绍了 RecGPT，一个以用户意图为中心的新一代推荐系统框架，旨在解决传统推荐系统过度依赖历史行为和日志拟合导致的问题。RecGPT 通过将大型语言模型（LLMs）集成到用户兴趣挖掘、物品检索和解释生成中，并采用多阶段训练范式（包括推理增强预对齐和自训练演进），成功地将推荐流程从日志拟合转变为意图驱动。该系统已在淘宝App上线，线上实验证明其显著提升了用户满意度、内容多样性以及商家和平台的曝光与转化，验证了 LLM 驱动的意图中心设计能够构建更可持续的推荐生态。", "keywords": "推荐系统, 大型语言模型, 用户意图, 多阶段训练, RecGPT", "comments": "这篇论文提出了一个重要的范式转变，从传统的日志拟合转向以用户意图为中心的推荐系统，这对于解决信息茧房和长尾问题具有重要意义。通过整合大型语言模型和设计精巧的多阶段训练范式，RecGPT 在实际工业场景（淘宝）中取得了显著效果，证明了 LLM 在推荐领域的巨大潜力及其在复杂应用中的可行性。其创新点在于将通用 LLM 有效地对齐到特定领域任务，并通过人机协作判断系统进行指导，这为未来推荐系统的发展提供了新的方向。"}}
{"id": "2503.05727", "title": "Toward Integrated Solutions: A Systematic Interdisciplinary Review of Cybergrooming Research", "authors": ["Heajun An", "Marcos Silva", "Qi Zhang", "Arav Singh", "Minqian Liu", "Xinyi Zhang", "Sarvech Qadir", "Sang Won Lee", "Lifu Huang", "Pamela J. Wisniewski", "Jin-Hee Cho"], "categories": ["cs.CY", "cs.CR"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05727v2", "summary": "Cybergrooming exploits minors through online trust-building, yet research\nremains fragmented, limiting holistic prevention. Social sciences focus on\nbehavioral insights, while computational methods emphasize detection, but their\nintegration remains insufficient. This review systematically synthesizes both\nfields using the PRISMA framework to enhance clarity, reproducibility, and\ncross-disciplinary collaboration. Findings show that qualitative methods offer\ndeep insights but are resource-intensive, machine learning models depend on\ndata quality, and standard metrics struggle with imbalance and cultural\nnuances. By bridging these gaps, this review advances interdisciplinary\ncybergrooming research, guiding future efforts toward more effective prevention\nand detection strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05727v2", "cate": "cs.CY", "date": "2025-02-18", "updated": "2025-07-31", "AI": {"title_translation": "迈向综合解决方案：网络诱骗研究的系统性跨学科综述", "tldr": "该综述系统地整合了社会科学和计算方法在网络诱骗研究中的应用，揭示了当前方法的局限性，并旨在推动跨学科合作以实现更有效的预防和检测。", "motivation": "网络诱骗研究目前碎片化，限制了全面的预防措施。社会科学侧重于行为洞察，而计算方法侧重于检测，但两者之间的整合不足。", "method": "本研究采用PRISMA框架，对社会科学和计算方法在网络诱骗研究中的应用进行了系统性综述和整合。", "result": "研究发现，定性方法能提供深入见解但资源密集，机器学习模型依赖数据质量，而标准指标在处理不平衡和文化细微差别时存在困难。", "conclusion": "通过弥合现有差距，本综述推动了跨学科网络诱骗研究，并为未来更有效的预防和检测策略提供了指导。", "translation": "网络诱骗通过在线建立信任来利用未成年人，然而相关研究仍然碎片化，限制了整体预防。社会科学侧重于行为洞察，而计算方法强调检测，但它们的整合仍然不足。本综述利用PRISMA框架系统地整合了这两个领域，以提高清晰度、可再现性和跨学科协作。研究结果表明，定性方法提供了深刻的见解但资源密集，机器学习模型依赖于数据质量，标准指标在不平衡和文化细微差别方面存在困难。通过弥合这些差距，本综述推动了跨学科网络诱骗研究，指导未来的努力，以实现更有效的预防和检测策略。", "summary": "本篇系统性综述旨在整合网络诱骗研究中社会科学与计算方法的碎片化现状。研究利用PRISMA框架，分析了现有方法的优缺点，如定性研究的资源消耗、机器学习对数据质量的依赖以及标准指标在处理不平衡和文化差异时的局限性。该综述旨在弥合学科间鸿沟，促进跨学科合作，从而为未来更有效的网络诱骗预防与检测策略提供指导。", "keywords": "网络诱骗, 系统综述, 跨学科研究, 预防, 检测", "comments": "该论文的创新之处在于其跨学科的系统综述方法，旨在整合社会科学和计算方法来解决网络诱骗问题，这对于推动该领域的全面理解和更有效的干预措施至关重要。它不仅指出了现有研究的局限性，还为未来的研究方向提供了明确的指导。"}}
{"id": "2507.23719", "title": "Design of a bioinspired robophysical antenna for insect-scale tactile perception and navigation", "authors": ["Parker McDonnell", "Lingsheng Meng", "Hari Krishna Hariprasad", "Alexander Hedrick", "Eduardo Miscles", "Samuel Gilinsky", "Jean-Michel Mongeau", "Kaushik Jayaram"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23719v1", "summary": "The American cockroach (Periplaneta americana) uses its soft antennae to\nguide decision making by extracting rich tactile information from tens of\nthousands of distributed mechanosensors. Although tactile sensors enable\nrobust, autonomous perception and navigation in natural systems, replicating\nthese capabilities in insect-scale robots remains challenging due to stringent\nsize, weight, and power constraints that limit existing sensor technologies. To\novercome these limitations, we introduce CITRAS (Cockroach Inspired Tactile\nRobotic Antenna Sensor), a bioinspired, multi-segmented, compliant laminate\nsensor with embedded capacitive angle sensors. CITRAS is compact (73.7x15.6x2.1\nmm), lightweight (491 mg), and low-power (32 mW), enabling seamless integration\nwith miniature robotic platforms. The segmented compliant structure passively\nbends in response to environmental stimuli, achieving accurate hinge angle\nmeasurements with maximum errors of just 0.79 degree (quasistatic bending) and\n3.58 degree (dynamic bending). Experimental evaluations demonstrate CITRAS'\nmultifunctional tactile perception capabilities: predicting base-to-tip\ndistances with 7.75 % error, estimating environmental gap widths with 6.73 %\nerror, and distinguishing surface textures through differential sensor\nresponse. The future integration of this bioinspired tactile antenna in\ninsect-scale robots addresses critical sensing gaps, promising enhanced\nautonomous exploration, obstacle avoidance, and environmental mapping in\ncomplex, confined environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23719v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一种用于昆虫尺度触觉感知和导航的仿生机器人天线设计", "tldr": "本文介绍了一种仿生多节柔顺层压传感器CITRAS，用于昆虫尺度机器人，以克服现有传感器在尺寸、重量和功耗方面的限制，实现触觉感知和导航。", "motivation": "尽管触觉传感器能使自然系统实现鲁棒、自主的感知和导航，但在昆虫尺度机器人中复制这些能力仍面临严峻挑战，主要受限于现有传感器技术的尺寸、重量和功耗。", "method": "本文提出了一种名为CITRAS（仿蟑螂触觉机器人天线传感器）的仿生、多节、柔顺层压传感器，其内部嵌入了电容式角度传感器。该结构紧凑、轻巧、低功耗，并通过被动弯曲实现精确的铰链角度测量，同时评估了其多功能触觉感知能力。", "result": "CITRAS尺寸为73.7x15.6x2.1毫米，重量491毫克，功耗32毫瓦。其铰链角度测量误差在准静态弯曲时为0.79度，动态弯曲时为3.58度。实验证明其能以7.75%的误差预测基端到尖端的距离，以6.73%的误差估计环境间隙宽度，并通过差分传感器响应区分表面纹理。", "conclusion": "CITRAS的未来集成将解决昆虫尺度机器人关键的传感空白，有望增强复杂受限环境中的自主探索、避障和环境建图能力。", "translation": "美洲蟑螂（Periplaneta americana）利用其柔软的触角，通过从数万个分布式机械传感器中提取丰富的触觉信息来指导决策。尽管触觉传感器使自然系统能够实现鲁棒、自主的感知和导航，但在昆虫尺度机器人中复制这些能力仍然充满挑战，因为严格的尺寸、重量和功耗限制了现有的传感器技术。为了克服这些限制，我们引入了CITRAS（仿蟑螂触觉机器人天线传感器），这是一种仿生、多节、柔顺层压传感器，内嵌电容式角度传感器。CITRAS结构紧凑（73.7x15.6x2.1毫米）、重量轻（491毫克）、功耗低（32毫瓦），能够与微型机器人平台无缝集成。分段柔顺结构响应环境刺激而被动弯曲，实现了精确的铰链角度测量，最大误差仅为0.79度（准静态弯曲）和3.58度（动态弯曲）。实验评估证明了CITRAS的多功能触觉感知能力：以7.75%的误差预测基端到尖端的距离，以6.73%的误差估计环境间隙宽度，并通过差分传感器响应区分表面纹理。未来将这种仿生触觉天线集成到昆虫尺度机器人中，将解决关键的传感空白，有望增强在复杂、受限环境中的自主探索、避障和环境建图能力。", "summary": "本文提出了一种名为CITRAS的仿生机器人触觉天线，其灵感来源于蟑螂触角，旨在解决昆虫尺度机器人触觉感知中的尺寸、重量和功耗限制。CITRAS是一种紧凑、轻量、低功耗的多节柔顺层压传感器，内嵌电容式角度传感器，能够精确测量弯曲角度。实验验证了其在距离预测、间隙宽度估计和纹理区分方面的多功能触觉感知能力，为昆虫尺度机器人的自主导航和环境探索提供了新的解决方案。", "keywords": "仿生机器人, 触觉感知, 昆虫尺度机器人, 机器人天线, 电容式传感器", "comments": "这项研究的创新之处在于其仿生设计，成功地将蟑螂触角的复杂触觉感知机制转化为可用于昆虫尺度机器人的实用传感器。其紧凑、轻量和低功耗的特性使其在微型机器人领域具有重要意义，克服了现有传感器技术的局限性。未来在自主探索和避障方面的应用潜力巨大。"}}
{"id": "2503.03449", "title": "Tiny LiDARs for Manipulator Self-Awareness: Sensor Characterization and Initial Localization Experiments", "authors": ["Giammarco Caroleo", "Alessandro Albini", "Daniele De Martini", "Timothy D. Barfoot", "Perla Maiolino"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, 3 tables, IEEE/RSJ International Conference on Intelligent Robots and Systems 2025 accepted paper", "url": "http://arxiv.org/abs/2503.03449v2", "summary": "For several tasks, ranging from manipulation to inspection, it is beneficial\nfor robots to localize a target object in their surroundings. In this paper, we\npropose an approach that utilizes coarse point clouds obtained from\nminiaturized VL53L5CX Time-of-Flight (ToF) sensors (tiny LiDARs) to localize a\ntarget object in the robot's workspace. We first conduct an experimental\ncampaign to calibrate the dependency of sensor readings on relative range and\norientation to targets. We then propose a probabilistic sensor model, which we\nvalidate in an object pose estimation task using a Particle Filter (PF). The\nresults show that the proposed sensor model improves the performance of the\nlocalization of the target object with respect to two baselines: one that\nassumes measurements are free from uncertainty and one in which the confidence\nis provided by the sensor datasheet.", "comment": "7 pages, 6 figures, 3 tables, IEEE/RSJ International Conference on\n  Intelligent Robots and Systems 2025 accepted paper", "pdf_url": "http://arxiv.org/pdf/2503.03449v2", "cate": "cs.RO", "date": "2025-03-05", "updated": "2025-07-31", "AI": {"title_translation": "用于机械手自感知的微型激光雷达：传感器表征和初步定位实验", "tldr": "本文提出了一种利用微型ToF传感器（微型激光雷达）获取的粗点云对机器人工作空间中的目标对象进行定位的方法，并通过提出的概率传感器模型显著提高了定位性能。", "motivation": "为了机器人更好地执行操作和检测等任务，需要能够在其环境中定位目标对象。", "method": "本文提出了一种利用微型VL53L5CX飞行时间（ToF）传感器（微型激光雷达）获取的粗点云来定位机器人工作空间中目标对象的方法。首先，进行实验活动以校准传感器读数对相对距离和目标方向的依赖性。然后，提出了一种概率传感器模型，并使用粒子滤波器（PF）在对象姿态估计任务中对其进行验证。", "result": "结果表明，所提出的传感器模型相对于两个基线（一个假设测量值没有不确定性，另一个置信度由传感器数据手册提供）提高了目标对象的定位性能。", "conclusion": "本文提出的基于微型ToF传感器的概率传感器模型，能够有效提高机器人工作空间中目标对象的定位性能。", "translation": "对于从操作到检测的多种任务，机器人能够在其周围环境中定位目标对象是有益的。在本文中，我们提出了一种利用从微型VL53L5CX飞行时间（ToF）传感器（微型激光雷达）获得的粗点云来定位机器人工作空间中目标对象的方法。我们首先进行了一项实验活动，以校准传感器读数对目标相对距离和方向的依赖性。然后，我们提出了一种概率传感器模型，我们使用粒子滤波器（PF）在对象姿态估计任务中对其进行了验证。结果表明，所提出的传感器模型相对于两个基线（一个假设测量值没有不确定性，另一个置信度由传感器数据手册提供）提高了目标对象的定位性能。", "summary": "本文提出了一种利用微型VL53L5CX ToF传感器（微型激光雷达）生成的粗点云，结合新颖的概率传感器模型，实现机器人工作空间中目标对象的精确本地化。通过实验校准传感器特性，并使用粒子滤波器验证该模型，结果显示其在目标定位方面优于现有基线。", "keywords": "微型激光雷达, 对象定位, 概率传感器模型, 粒子滤波器, ToF传感器", "comments": "本文的创新点在于利用成本较低的微型ToF传感器实现目标定位，并提出了一个有效的概率传感器模型来处理传感器固有的不确定性。这为机器人自感知提供了一种经济且实用的解决方案，对于资源受限或需要紧凑型传感器的应用具有重要意义。然而，粗点云的局限性可能会影响在复杂环境中的精确度。"}}
{"id": "2507.23455", "title": "Machine learning and machine learned prediction in chest X-ray images", "authors": ["Shereiff Garrett", "Abhinav Adhikari", "Sarina Gautam", "DaShawn Marquis Morris", "Chandra Mani Adhikari"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures", "url": "http://arxiv.org/abs/2507.23455v1", "summary": "Machine learning and artificial intelligence are fast-growing fields of\nresearch in which data is used to train algorithms, learn patterns, and make\npredictions. This approach helps to solve seemingly intricate problems with\nsignificant accuracy without explicit programming by recognizing complex\nrelationships in data. Taking an example of 5824 chest X-ray images, we\nimplement two machine learning algorithms, namely, a baseline convolutional\nneural network (CNN) and a DenseNet-121, and present our analysis in making\nmachine-learned predictions in predicting patients with ailments. Both baseline\nCNN and DenseNet-121 perform very well in the binary classification problem\npresented in this work. Gradient-weighted class activation mapping shows that\nDenseNet-121 correctly focuses on essential parts of the input chest X-ray\nimages in its decision-making more than the baseline CNN.", "comment": "8 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.23455v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "机器学习和胸部X射线图像中的机器习得预测", "tldr": "本文在5824张胸部X射线图像上比较了基线CNN和DenseNet-121在疾病预测上的表现，发现两者均表现良好，且DenseNet-121在决策时更准确地关注图像关键区域。", "motivation": "利用机器学习和人工智能处理复杂问题，并通过识别数据中的复杂关系进行预测，特别是在医学图像分析中。", "method": "使用5824张胸部X射线图像数据集，实现了两种机器学习算法：基线卷积神经网络（CNN）和DenseNet-121。通过二元分类问题来预测患病患者。使用梯度加权类激活映射（Grad-CAM）分析模型决策。", "result": "基线CNN和DenseNet-121在二元分类问题中表现都非常好。梯度加权类激活映射显示DenseNet-121在决策时比基线CNN更正确地关注输入胸部X射线图像的关键部分。", "conclusion": "DenseNet-121在胸部X射线图像的疾病预测任务中表现出色，并且在解释性（通过Grad-CAM）方面优于基线CNN，能够更准确地识别图像中的重要区域。", "translation": "机器学习和人工智能是快速发展的研究领域，其中数据用于训练算法、学习模式并进行预测。这种方法通过识别数据中复杂的关系，无需明确编程即可高精度地解决看似复杂的问题。我们以5824张胸部X射线图像为例，实现了两种机器学习算法，即基线卷积神经网络（CNN）和DenseNet-121，并展示了我们在胸部X射线图像中进行机器习得预测以预测患病患者的分析。基线CNN和DenseNet-121在本文提出的二元分类问题中都表现出色。梯度加权类激活映射显示，DenseNet-121在决策时比基线CNN更正确地关注输入胸部X射线图像中的重要部分。", "summary": "本文探讨了机器学习和人工智能在胸部X射线图像疾病预测中的应用。研究者在包含5824张胸部X射线图像的数据集上，比较了基线卷积神经网络（CNN）和DenseNet-121两种算法的性能。结果表明，这两种模型在二元分类任务中均表现良好，其中DenseNet-121通过梯度加权类激活映射（Grad-CAM）显示出在决策过程中能更准确地聚焦于图像的关键区域。", "keywords": "机器学习, 胸部X射线, 卷积神经网络, DenseNet-121, 疾病预测", "comments": "这篇论文通过比较两种深度学习模型在胸部X射线图像疾病预测上的表现，展示了机器学习在医学图像分析领域的潜力。其创新点在于不仅评估了模型的预测性能，还通过Grad-CAM提供了模型决策过程的可解释性分析，这对于医疗应用至关重要。DenseNet-121在关注关键区域方面的优势突出了其在诊断辅助方面的实用价值。"}}
{"id": "2507.23195", "title": "$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid", "authors": ["S. M. Mallikarjunaiah", "Pavithra Venkatachalapthy"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23195v1", "summary": "An $hp$-adaptive continuous Galerkin finite element method is developed to\nanalyze a static anti-plane shear crack embedded in a nonlinear,\nstrain-limiting elastic body. The geometrically linear material is described by\na constitutive law relating stress and strain that is algebraically nonlinear.\nIn this investigation, the constitutive relation utilized is \\textit{uniformly\nbounded}, \\textit{monotone}, \\textit{coercive}, and \\textit{Lipschitz\ncontinuous}, ensuring the well-posedness of the mathematical model. The\ngoverning equation, derived from the balance of linear momentum coupled with\nthe nonlinear constitutive relationship, is formulated as a second-order\nquasi-linear elliptic partial differential equation. For a body with an edge\ncrack, this governing equation is augmented with a classical traction-free\nboundary condition on the crack faces. An $hp$-adaptive finite element scheme\nis proposed for the numerical approximation of the resulting boundary value\nproblem. The adaptive strategy is driven by a dual-component error estimation\nscheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a\nposteriori error indicator of the \\textit{Kelly type}, while the local\npolynomial degree ($p$-adaptivity) is adjusted based on an estimator of the\nlocal solution regularity. The performance, accuracy, and convergence\ncharacteristics of the proposed method are demonstrated through numerical\nexperiments. The structure of the regularized crack-tip fields is examined for\nvarious modeling parameters. Furthermore, the presented framework establishes a\nrobust foundation for extension to more complex and computationally demanding\nproblems, including quasi-static and dynamic crack propagation in brittle\nmaterials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23195v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "$hp$-自适应有限元模拟非线性应变限制弹性固体中的静态反平面剪切裂纹", "tldr": "本文开发了一种$hp$-自适应连续Galerkin有限元方法，用于分析非线性、应变限制弹性体中的静态反平面剪切裂纹，并证明了其性能、精度和收敛性。", "motivation": "该研究旨在开发一种鲁棒的数值方法来分析非线性、应变限制弹性固体中静态反平面剪切裂纹的行为。", "method": "本文开发了一种$hp$-自适应连续Galerkin有限元方法。该方法采用一致有界、单调、强制和Lipschitz连续的代数非线性本构关系，并基于从线性动量守恒导出的二阶准线性椭圆偏微分方程。自适应策略由双分量误差估计方案驱动：$h$-自适应由Kelly型基于残差的后验误差指示器指导，而$p$-自适应则根据局部解正则性的估计器进行调整。", "result": "通过数值实验，证明了所提出方法的性能、精度和收敛特性。此外，还研究了各种建模参数下正则化裂纹尖端场的结构。", "conclusion": "所开发的$hp$-自适应有限元方法为模拟非线性应变限制弹性固体中的静态反平面剪切裂纹提供了一个鲁棒且精确的框架，并为未来扩展到更复杂的准静态和动态裂纹扩展问题奠定了基础。", "translation": "本文开发了一种$hp$-自适应连续Galerkin有限元方法，用于分析嵌入在非线性、应变限制弹性体中的静态反平面剪切裂纹。几何线性材料由代数非线性的应力-应变本构关系描述。在本研究中，所使用的本构关系是一致有界、单调、强制和Lipschitz连续的，这确保了数学模型的适定性。从线性动量守恒与非线性本构关系耦合导出的控制方程，被表述为二阶准线性椭圆偏微分方程。对于具有边缘裂纹的物体，该控制方程通过裂纹面上的经典无牵引边界条件得到增强。提出了一种$hp$-自适应有限元方案，用于所得边值问题的数值近似。自适应策略由双分量误差估计方案驱动：网格细化（$h$-自适应）由Kelly型基于残差的后验误差指示器指导，而局部多项式次数（$p$-自适应）则根据局部解正则性的估计器进行调整。通过数值实验证明了所提出方法的性能、精度和收敛特性。研究了各种建模参数下正则化裂纹尖端场的结构。此外，所提出的框架为扩展到更复杂和计算要求更高的问题（包括脆性材料中的准静态和动态裂纹扩展）奠定了坚实的基础。", "summary": "本文提出了一种$hp$-自适应连续Galerkin有限元方法，用于模拟非线性应变限制弹性固体中的静态反平面剪切裂纹。该方法基于适定性的非线性本构关系和二阶准线性椭圆偏微分方程，并采用双分量误差估计（Kelly型残差指示器用于$h$-自适应，局部解正则性估计器用于$p$-自适应）驱动的自适应策略。数值实验验证了方法的性能、精度和收敛性，并分析了裂纹尖端场结构。该框架为未来研究复杂裂纹问题奠定了基础。", "keywords": "$hp$-自适应有限元, 反平面剪切裂纹, 非线性弹性, 应变限制, 裂纹尖端场", "comments": "本文的创新之处在于将$hp$-自适应有限元方法应用于非线性、应变限制材料中反平面剪切裂纹的模拟，并通过明确的本构关系特性确保了数学模型的适定性。双分量误差估计驱动的自适应策略是该方法的关键优势。这项工作为断裂力学中一类具有挑战性的问题提供了一个鲁棒的数值工具。"}}
{"id": "2507.22069", "title": "A Compute-Matched Re-Evaluation of TroVE on MATH", "authors": ["Tobias Sesterhenn", "Ian Berlot-Attwell", "Janis Zenkner", "Christian Bartelt"], "categories": ["cs.PL", "cs.AI"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22069v2", "summary": "Reusing established theorems and formulas is central to mathematical problem\nsolving, serving as essential building blocks for tackling increasingly complex\nchallenges. Recent work, TroVE, argues that code-generating Large Language\nModels (LLMs) can benefit similarly on the MATH benchmark by inducing and\nreusing higher-level toolboxes. By allocating computational budget across an\nensemble of three modes -- directly generating code, creating tools, and\nreusing tools -- TroVE claims to outperform a PRIMITIVE baseline that only\nperforms direct generation. However, recent analysis (Berlot-Attwell et al.,\n2024) casts doubt on these gains, noting that the tools created are often\ntrivial or rarely reused, suggesting that improvements may stem from\nself-consistency or self-correction. In this work, we re-evaluate TroVE on\nMATH, analyze the impact of each of its modes, and show that its benefit does\nnot come from these mechanisms, but simply from a higher computational budget\nspent for TroVE compared to PRIMITIVE. To this end, we also perform a small\ncorrection in the original implementation of TroVE's selection mechanism,\nboosting TroVE's performance on MATH by 3\\% in accuracy. After matching for\ncompute, the benefit of TroVE reduces to a marginal improvement of 1\\%,\nsuggesting that this toolbox approach does not provide a significant benefit on\nMATH.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22069v2", "cate": "cs.PL", "date": "2025-07-16", "updated": "2025-07-31", "AI": {"title_translation": "TroVE在MATH数据集上的计算匹配再评估", "tldr": "先前的TroVE研究声称工具箱对LLM在MATH基准测试中表现有益，但本次重新评估显示，其优势主要归因于更高的计算预算，在计算资源匹配后，收益微乎其微。", "motivation": "鉴于此前对TroVE工具实用性的质疑，本研究旨在重新评估TroVE在MATH基准测试上的主张，特别是其报告的性能提升是源于其工具箱机制还是仅仅因为更高的计算预算。", "method": "作者在MATH基准测试上重新评估了TroVE，并分析了其三种模式（直接生成、工具创建和工具重用）的影响。他们还对TroVE原始实现中的选择机制进行了小幅修正。关键是，他们匹配了TroVE和PRIMITIVE基线之间的计算预算，以进行公平比较。", "result": "对TroVE选择机制的微小修正使其在MATH上的准确率提高了3%。然而，在匹配计算预算后，TroVE相对于PRIMITIVE基线的优势减少到仅1%的微小提升。", "conclusion": "研究得出结论，TroVE在MATH基准测试上声称的优势并非源于其工具箱机制，而是来自更高的计算预算。当计算资源匹配时，这种工具箱方法本身并未提供显著的益处。", "translation": "重用既定定理和公式是数学问题解决的核心，是应对日益复杂挑战的基本组成部分。最近的研究TroVE提出，通过诱导和重用更高级的工具箱，代码生成大型语言模型（LLM）可以在MATH基准测试上获得类似的好处。通过将计算预算分配给三种模式的集合——直接生成代码、创建工具和重用工具——TroVE声称其性能优于仅执行直接生成的PRIMITIVE基线。然而，最近的分析（Berlot-Attwell et al., 2024）对这些收益提出了质疑，指出所创建的工具通常是琐碎的或很少被重用，这表明改进可能源于自洽性或自我纠正。在这项工作中，我们重新评估了TroVE在MATH上的表现，分析了其每种模式的影响，并表明其益处并非来自这些机制，而仅仅是由于TroVE比PRIMITIVE花费了更高的计算预算。为此，我们还在TroVE选择机制的原始实现中进行了一个小修正，将TroVE在MATH上的准确率提高了3%。在计算资源匹配后，TroVE的益处减少到仅1%的微小提升，这表明这种工具箱方法在MATH上并未提供显著的益处。", "summary": "本文重新评估了TroVE，这是一种声称通过使用工具箱来提高LLM在MATH上性能的方法。与TroVE的主张相反，本研究发现其报告的收益主要归因于更高的计算预算，而非工具箱机制本身。在对TroVE的实现进行小幅修正并与基线匹配计算资源后，TroVE的益处降至微不足道的1%提升，这表明工具箱方法对LLM解决数学问题并未提供显著优势。", "keywords": "TroVE, MATH基准, 大型语言模型, 计算预算, 再评估", "comments": "这篇论文提供了一次关键的重新评估，强调了在AI研究中公平计算预算比较的重要性。它通过证明报告的收益主要是资源分配而非方法学优势的产物，挑战了先前的说法。这强调了严谨实验设计的必要性。"}}
{"id": "2507.23644", "title": "Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity", "authors": ["Alba Aguilera", "Georgina Curto", "Nardine Osman"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23644v1", "summary": "Agent-based simulations have an enormous potential as tools to evaluate\nsocial policies in a non-invasive way, before these are implemented to\nreal-world populations. However, the recommendations that these computational\napproaches may offer to tackle urgent human development challenges can vary\nsubstantially depending on how we model agents' (people) behaviour and the\ncriteria that we use to measure inequity. In this paper, we integrate the\nconceptual framework of the capability approach (CA), which is explicitly\ndesigned to promote and assess human well-being, to guide the simulation and\nevaluate the effectiveness of policies. We define a reinforcement learning\nenvironment where agents behave to restore their capabilities under the\nconstraints of a specific policy. Working in collaboration with local\nstakeholders, non-profits and domain experts, we apply our model in a case\nstudy to mitigate health inequity among the population experiencing\nhomelessness (PEH) in Barcelona. By doing so, we present the first proof of\nconcept simulation, aligned with the CA for human development, to assess the\nimpact of policies under parliamentary discussion.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23644v1", "cate": "cs.MA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "医疗保健障碍：基于代理的建模以减轻不平等", "tldr": "本文提出了一种结合能力方法和强化学习的基于代理的模拟模型，用于非侵入性地评估社会政策对人类发展和健康不平等的影响，并通过巴塞罗那无家可归者群体的案例研究进行了概念验证。", "motivation": "基于代理的模拟在非侵入性评估社会政策方面潜力巨大，但其建议的有效性取决于代理行为建模和不平等衡量标准。本文旨在整合能力方法来指导模拟，以更有效地评估政策对人类福祉和健康不平等的影响。", "method": "本文将能力方法（CA）的概念框架整合到基于代理的模拟中。研究人员定义了一个强化学习环境，其中代理在特定政策约束下行动以恢复其能力。该模型通过与当地利益相关者合作，应用于巴塞罗那无家可归者（PEH）群体的健康不平等缓解案例研究。", "result": "本文提出了第一个与人类发展能力方法相符的概念验证模拟，用于评估议会正在讨论的政策的影响。", "conclusion": "本文提出的基于能力方法和强化学习的代理模型，为非侵入性评估社会政策（特别是针对健康不平等）在实际实施前的影响提供了一种新颖有效的方法。", "translation": "基于代理的模拟作为一种非侵入性工具，在社会政策实际应用于真实人群之前对其进行评估，具有巨大的潜力。然而，这些计算方法可能为解决紧迫的人类发展挑战提供的建议，会因我们如何建模代理（人）的行为以及我们用来衡量不平等的标准而大相径庭。在本文中，我们将能力方法（CA）的概念框架整合进来，该框架明确旨在促进和评估人类福祉，以指导模拟并评估政策的有效性。我们定义了一个强化学习环境，其中代理在特定政策的约束下行为以恢复其能力。通过与当地利益相关者、非营利组织和领域专家的合作，我们将模型应用于一个案例研究，以减轻巴塞罗那无家可归者（PEH）群体中的健康不平等。通过这样做，我们提出了第一个与人类发展能力方法相符的概念验证模拟，用于评估议会正在讨论的政策的影响。", "summary": "本文提出了一种结合能力方法（CA）和强化学习的基于代理的模拟模型，旨在非侵入性地评估社会政策的有效性。该模型允许代理在政策约束下恢复其能力，并通过在巴塞罗那针对无家可归者健康不平等的案例研究进行了应用。研究展示了首个符合人类发展CA理念的概念验证模拟，用于评估正在讨论的政策影响。", "keywords": "基于代理建模, 健康不平等, 能力方法, 强化学习, 政策评估", "comments": "本文创新性地将基于代理的建模与能力方法和强化学习相结合，为社会政策的非侵入性评估提供了一种新颖的框架。其关注人类福祉和健康公平，并通过与实际利益相关者的合作进行案例研究，凸显了其重要的社会应用价值。作为一个“概念验证”工作，它为未来更全面、更精确的政策模拟奠定了基础。"}}
{"id": "2507.23154", "title": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Raphael Canals", "Rachid Nedjai"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted in the 2025 International Conference on Machine Intelligence for GeoAnalytics and Remote Sensing (MIGARS)", "url": "http://arxiv.org/abs/2507.23154v1", "summary": "Urban heatwaves, droughts, and land degradation are pressing and growing\nchallenges in the context of climate change. A valuable approach to studying\nthem requires accurate spatio-temporal information on land surface conditions.\nOne of the most important variables for assessing and understanding these\nphenomena is Land Surface Temperature (LST), which is derived from satellites\nand provides essential information about the thermal state of the Earth's\nsurface. However, satellite platforms inherently face a trade-off between\nspatial and temporal resolutions. To bridge this gap, we propose FuseTen, a\nnovel generative framework that produces daily LST observations at a fine 10 m\nspatial resolution by fusing spatio-temporal observations derived from\nSentinel-2, Landsat 8, and Terra MODIS. FuseTen employs a generative\narchitecture trained using an averaging-based supervision strategy grounded in\nphysical principles. It incorporates attention and normalization modules within\nthe fusion process and uses a PatchGAN discriminator to enforce realism.\nExperiments across multiple dates show that FuseTen outperforms linear\nbaselines, with an average 32.06% improvement in quantitative metrics and\n31.42% in visual fidelity. To the best of our knowledge, this is the first\nnon-linear method to generate daily LST estimates at such fine spatial\nresolution.", "comment": "Accepted in the 2025 International Conference on Machine Intelligence\n  for GeoAnalytics and Remote Sensing (MIGARS)", "pdf_url": "http://arxiv.org/pdf/2507.23154v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "FuseTen：一种基于时空卫星观测的每日10米地表温度估算生成模型", "tldr": "FuseTen是一种新颖的生成模型，通过融合多源卫星数据，首次实现了每日10米高分辨率地表温度的估算，显著优于传统方法。", "motivation": "城市热浪、干旱和土地退化是气候变化背景下日益严峻的挑战。研究这些现象需要准确的地表条件时空信息。地表温度（LST）是评估和理解这些现象的关键变量，但卫星平台在空间和时间分辨率之间存在固有的权衡，导致无法同时获得高时空分辨率的LST数据。", "method": "本文提出了一种名为FuseTen的新型生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成每日10米空间分辨率的地表温度观测数据。FuseTen采用基于物理原理的平均监督策略进行训练的生成式架构，并在融合过程中结合了注意力（attention）和归一化（normalization）模块，使用PatchGAN判别器来确保生成结果的真实性。", "result": "在多个日期进行的实验表明，FuseTen优于线性基线方法，在定量指标上平均提高了32.06%，在视觉保真度上提高了31.42%。", "conclusion": "FuseTen是首个能够生成每日10米高空间分辨率地表温度估计值的非线性方法。", "translation": "城市热浪、干旱和土地退化是气候变化背景下日益紧迫和增长的挑战。研究它们的一种有价值的方法需要关于地表条件的准确时空信息。评估和理解这些现象最重要的变量之一是地表温度（LST），它来源于卫星，提供了关于地球表面热状态的基本信息。然而，卫星平台在空间和时间分辨率之间存在固有的权衡。为了弥补这一差距，我们提出了FuseTen，一种新颖的生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成每日10米空间分辨率的精细地表温度观测数据。FuseTen采用基于物理原理的平均监督策略训练的生成式架构。它在融合过程中结合了注意力（attention）和归一化（normalization）模块，并使用PatchGAN判别器来强制实现真实感。在多个日期进行的实验表明，FuseTen优于线性基线方法，在定量指标上平均提高了32.06%，在视觉保真度上提高了31.42%。据我们所知，这是第一个生成如此精细空间分辨率的每日地表温度估计值的非线性方法。", "summary": "本文提出了FuseTen，一个创新的生成模型，旨在解决卫星地表温度（LST）数据在时空分辨率上的固有权衡。通过融合Sentinel-2、Landsat 8和Terra MODIS的多源卫星观测数据，FuseTen能够生成每日10米空间分辨率的LST数据。该模型采用基于物理原理的生成式架构，并集成了注意力、归一化模块和PatchGAN判别器以提高真实性。实验结果显示，FuseTen在定量和视觉效果上均显著优于传统线性方法，是首个实现如此高时空分辨率每日LST估计的非线性方法。", "keywords": "地表温度, 生成模型, 卫星数据融合, 高分辨率, 气候变化", "comments": "FuseTen的创新之处在于其作为首个非线性方法，实现了每日10米高空间分辨率的地表温度估算，这在以往是难以企及的。其采用生成式模型结合多源卫星数据融合，并融入注意力与归一化模块，以及PatchGAN判别器，提升了模型的性能和生成结果的真实感。这对于精细化研究城市热岛效应、干旱及土地退化等气候变化相关问题具有重要意义。"}}
{"id": "2507.23501", "title": "Directional Ensemble Aggregation for Actor-Critics", "authors": ["Nicklas Werge", "Yi-Shan Wu", "Bahareh Tasdighi", "Melih Kandemir"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23501v1", "summary": "Off-policy reinforcement learning in continuous control tasks depends\ncritically on accurate $Q$-value estimates. Conservative aggregation over\nensembles, such as taking the minimum, is commonly used to mitigate\noverestimation bias. However, these static rules are coarse, discard valuable\ninformation from the ensemble, and cannot adapt to task-specific needs or\ndifferent learning regimes. We propose Directional Ensemble Aggregation (DEA),\nan aggregation method that adaptively combines $Q$-value estimates in\nactor-critic frameworks. DEA introduces two fully learnable directional\nparameters: one that modulates critic-side conservatism and another that guides\nactor-side policy exploration. Both parameters are learned using ensemble\ndisagreement-weighted Bellman errors, which weight each sample solely by the\ndirection of its Bellman error. This directional learning mechanism allows DEA\nto adjust conservatism and exploration in a data-driven way, adapting\naggregation to both uncertainty levels and the phase of training. We evaluate\nDEA across continuous control benchmarks and learning regimes - from\ninteractive to sample-efficient - and demonstrate its effectiveness over static\nensemble strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23501v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "演员-评论家网络中的方向性集成聚合", "tldr": "提出一种名为DEA的新型Q值集成聚合方法，通过学习两个方向性参数，自适应地调整演员-评论家框架中的保守性和探索，优于静态策略。", "motivation": "现有的Q值集成聚合方法（如取最小值）虽然能缓解过高估计偏差，但它们是粗糙的、会丢弃有价值的信息，并且无法适应任务需求或不同的学习阶段。", "method": "提出方向性集成聚合（DEA）方法。DEA引入了两个完全可学习的方向性参数：一个用于调节评论家侧的保守性，另一个用于指导演员侧的策略探索。这两个参数通过集成不一致性加权的贝尔曼误差学习，该误差仅根据样本贝尔曼误差的方向进行加权。", "result": "在连续控制基准和从交互式到样本高效的学习机制中评估了DEA，并证明了其相对于静态集成策略的有效性。", "conclusion": "DEA通过自适应地调整保守性和探索，在演员-评论家框架中提供了比静态集成策略更有效和灵活的Q值聚合方法。", "translation": "异策略强化学习在连续控制任务中严重依赖于准确的Q值估计。集成上的保守聚合，例如取最小值，常用于缓解过高估计偏差。然而，这些静态规则是粗糙的，会丢弃集成中有价值的信息，并且无法适应特定任务需求或不同的学习机制。我们提出了方向性集成聚合（DEA），这是一种在演员-评论家框架中自适应结合Q值估计的聚合方法。DEA引入了两个完全可学习的方向性参数：一个用于调节评论家侧的保守性，另一个用于指导演员侧的策略探索。这两个参数通过集成不一致性加权的贝尔曼误差学习，该误差仅根据其贝尔曼误差的方向对每个样本进行加权。这种方向性学习机制使DEA能够以数据驱动的方式调整保守性和探索，使聚合适应不确定性水平和训练阶段。我们在连续控制基准和学习机制（从交互式到样本高效）中评估了DEA，并证明了其相对于静态集成策略的有效性。", "summary": "本文提出了一种名为方向性集成聚合（DEA）的新型Q值聚合方法，用于演员-评论家强化学习框架。针对现有保守聚合方法（如取最小值）的局限性，DEA引入了两个可学习的方向性参数，分别用于自适应调节评论家侧的保守性和演员侧的策略探索。这些参数通过基于贝尔曼误差方向的加权机制进行学习，使得DEA能够根据不确定性水平和训练阶段动态调整聚合策略。实验证明，DEA在连续控制任务中优于静态集成策略。", "keywords": "强化学习, 演员-评论家, Q值聚合, 方向性集成聚合, 异策略学习", "comments": "这篇论文的创新点在于引入了可学习的方向性参数来动态调整Q值聚合的保守性和探索性，解决了传统静态聚合方法的不足。其重要性在于提升了异策略强化学习在连续控制任务中的性能和适应性。"}}
{"id": "2507.23712", "title": "Anomalous Samples for Few-Shot Anomaly Detection", "authors": ["Aymane Abdali", "Bartosz Boguslawski", "Lucas Drumetz", "Vincent Gripon"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23712v1", "summary": "Several anomaly detection and classification methods rely on large amounts of\nnon-anomalous or \"normal\" samples under the assump- tion that anomalous data is\ntypically harder to acquire. This hypothesis becomes questionable in Few-Shot\nsettings, where as little as one anno- tated sample can make a significant\ndifference. In this paper, we tackle the question of utilizing anomalous\nsamples in training a model for bi- nary anomaly classification. We propose a\nmethodology that incorporates anomalous samples in a multi-score anomaly\ndetection score leveraging recent Zero-Shot and memory-based techniques. We\ncompare the utility of anomalous samples to that of regular samples and study\nthe benefits and limitations of each. In addition, we propose an\naugmentation-based validation technique to optimize the aggregation of the\ndifferent anomaly scores and demonstrate its effectiveness on popular\nindustrial anomaly detection datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23712v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于少样本异常检测的异常样本", "tldr": "本文提出了一种利用异常样本进行少样本异常检测的方法，通过多分数聚合和数据增强验证技术，并在工业数据集上验证了其有效性。", "motivation": "现有的异常检测方法依赖大量非异常样本，但在少样本设置下，异常样本的获取变得困难。本文旨在探讨如何有效利用难以获取的异常样本来训练二元异常分类模型。", "method": "提出了一种将异常样本整合到多分数异常检测中的方法，该方法利用了近期的零样本和基于记忆的技术。此外，提出了一种基于数据增强的验证技术，用于优化不同异常分数的聚合。", "result": "比较了异常样本和常规样本的效用，并研究了它们各自的优缺点。在流行的工业异常检测数据集上验证了所提出的数据增强验证技术的有效性。", "conclusion": "本文证明了在少样本设置下，异常样本可以有效地用于训练异常检测模型，并通过创新的多分数聚合和验证技术提升了性能。", "translation": "几个异常检测和分类方法依赖于大量的非异常或“正常”样本，因为它们假设异常数据通常更难获取。在少样本设置中，这个假设变得可疑，因为即使只有一个带注释的样本也能产生显著差异。在本文中，我们解决了在训练二元异常分类模型时利用异常样本的问题。我们提出了一种方法，将异常样本整合到多分数异常检测分数中，利用了最近的零样本和基于记忆的技术。我们比较了异常样本和常规样本的效用，并研究了它们各自的优点和局限性。此外，我们提出了一种基于增强的验证技术来优化不同异常分数的聚合，并在流行的工业异常检测数据集上展示了其有效性。", "summary": "本文针对少样本异常检测中异常样本难以获取的问题，提出了一种利用异常样本训练二元异常分类模型的新方法。该方法将异常样本整合到多分数异常检测框架中，并结合了零样本和基于记忆的技术。同时，提出了一种基于数据增强的验证技术来优化分数聚合。研究结果表明，该方法在工业异常检测数据集上表现出有效性，并探讨了异常样本与常规样本的效用及局限性。", "keywords": "少样本异常检测, 异常样本, 多分数聚合, 数据增强, 工业数据集", "comments": "该论文的创新点在于挑战了传统异常检测中异常样本难以获取的假设，并提出了一种有效利用这些样本的方法。通过结合多分数聚合和数据增强验证，它为少样本异常检测提供了一个有前景的解决方案，特别是在数据稀缺的工业应用中具有重要意义。"}}
{"id": "2507.21881", "title": "Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2507.21875", "url": "http://arxiv.org/abs/2507.21881v3", "summary": "Pain is a multifaceted phenomenon that affects a substantial portion of the\npopulation. Reliable and consistent evaluation benefits those experiencing pain\nand underpins the development of effective and advanced management strategies.\nAutomatic pain-assessment systems deliver continuous monitoring, inform\nclinical decision-making, and aim to reduce distress while preventing\nfunctional decline. By incorporating physiological signals, these systems\nprovide objective, accurate insights into an individual's condition. This study\nhas been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for\nNext-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline\nthat leverages electrodermal activity signals as input modality. Multiple\nrepresentations of the signal are created and visualized as waveforms, and they\nare jointly visualized within a single multi-representation diagram. Extensive\nexperiments incorporating various processing and filtering techniques, along\nwith multiple representation combinations, demonstrate the effectiveness of the\nproposed approach. It consistently yields comparable, and in several cases\nsuperior, results to traditional fusion methods, establishing it as a robust\nalternative for integrating different signal representations or modalities.", "comment": "arXiv admin note: text overlap with arXiv:2507.21875", "pdf_url": "http://arxiv.org/pdf/2507.21881v3", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "用于疼痛识别的多表示图：将各种皮肤电活动信号整合到单个图像中", "tldr": "该论文提出了一种利用皮肤电活动（EDA）信号的多表示图进行自动疼痛评估的方法，其结果与传统方法相当或更优。", "motivation": "疼痛是一种普遍且多方面的现象，需要可靠的评估。自动疼痛评估系统能够提供持续监测、辅助临床决策、减轻痛苦并防止功能下降。通过整合生理信号，这些系统可以提供客观、准确的洞察，从而促进有效和先进的疼痛管理策略的发展。", "method": "本研究提出了一种处理流程，利用皮肤电活动（EDA）信号作为输入模态。该方法创建了信号的多种表示形式，并将其可视化为波形，然后将这些波形共同整合到单个多表示图中。实验中包含了各种处理和滤波技术以及多种表示组合。", "result": "广泛的实验证明了所提出方法的有效性。它始终产生与传统融合方法相当，在某些情况下甚至更优的结果。", "conclusion": "所提出的方法被确立为一种可靠的替代方案，可用于整合不同的信号表示或模态以进行疼痛识别。", "translation": "疼痛是一种多方面的现象，影响着相当一部分人口。可靠且持续的评估有益于经历疼痛的人群，并支撑着有效和先进管理策略的开发。自动疼痛评估系统提供持续监测，为临床决策提供信息，旨在减轻痛苦并防止功能下降。通过整合生理信号，这些系统为个体状况提供客观、准确的见解。本研究已提交给《第二届下一代疼痛评估多模态感知大挑战赛 (AI4PAIN)》。所提出的方法引入了一个利用皮肤电活动信号作为输入模态的管道。创建信号的多种表示并将其可视化为波形，然后将它们共同可视化在一个多表示图中。结合各种处理和过滤技术以及多种表示组合的广泛实验，证明了所提出方法的有效性。它始终产生与传统融合方法相当，在某些情况下甚至更优的结果，从而确立了其作为整合不同信号表示或模态的强大替代方案的地位。", "summary": "本论文介绍了一种新颖的自动疼痛识别管道，该管道利用皮肤电活动（EDA）信号。它创建了EDA信号的多种表示形式，将其可视化为波形，并整合到一个单一的多表示图中。实验表明，这种方法是有效的，在客观疼痛评估方面，其性能与传统信号融合方法相当或更优。", "keywords": "疼痛识别, 皮肤电活动, 多表示图, 信号处理, 自动疼痛评估", "comments": "该研究的创新之处在于将单一生理信号（皮肤电活动）的多种表示形式整合到一个统一的视觉图中进行疼痛识别，这可能简化数据融合并提高评估准确性。其相较于传统融合方法的鲁棒性是其关键优势。"}}
{"id": "2507.22174", "title": "Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic", "authors": ["Molly Wang", "Kin. K Leung"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22174v2", "summary": "Reinforcement Learning (RL) has been widely used for packet routing in\ncommunication networks, but traditional RL methods rely on the Markov\nassumption that the current state contains all necessary information for\ndecision-making. In reality, internet traffic is non-Markovian, and past states\ndo influence routing performance. Moreover, common deep RL approaches use\nfunction approximators, such as neural networks, that do not model the spatial\nstructure in network topologies. To address these shortcomings, we design a\nnetwork environment with non-Markovian traffic and introduce a spatial-temporal\nRL (STRL) framework for packet routing. Our approach outperforms traditional\nbaselines by more than 19% during training and 7% for inference despite a\nchange in network topology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22174v2", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-31", "AI": {"title_translation": "空间-时间强化学习用于非马尔可夫流量的网络路由", "tldr": "针对非马尔可夫流量和网络拓扑空间结构未建模的问题，本文提出了一种空间-时间强化学习（STRL）框架，用于网络路由，并在性能上超越传统方法。", "motivation": "传统强化学习方法在网络路由中依赖马尔可夫假设，但实际互联网流量是非马尔可夫的，并且过去的流量状态会影响路由性能。此外，常见的深度强化学习方法没有对网络拓扑中的空间结构进行建模。", "method": "本文设计了一个具有非马尔可夫流量的网络环境，并引入了一种空间-时间强化学习（STRL）框架用于数据包路由。", "result": "该方法在训练期间比传统基线高出19%以上，在推断期间高出7%，即使网络拓扑发生变化。", "conclusion": "本文提出的空间-时间强化学习（STRL）框架有效解决了传统强化学习在非马尔可夫流量网络路由中的局限性，并在性能上显示出显著优势。", "translation": "强化学习（RL）已广泛应用于通信网络中的数据包路由，但传统的RL方法依赖于马尔可夫假设，即当前状态包含决策所需的所有信息。实际上，互联网流量是非马尔可夫的，并且过去的状态确实会影响路由性能。此外，常见的深度RL方法使用函数逼近器（例如神经网络），它们不模拟网络拓扑中的空间结构。为了解决这些缺点，我们设计了一个具有非马尔可夫流量的网络环境，并引入了一种空间-时间强化学习（STRL）框架用于数据包路由。我们的方法在训练期间比传统基线高出19%以上，在推断期间高出7%，尽管网络拓扑发生了变化。", "summary": "本文针对传统强化学习在网络路由中无法处理非马尔可夫流量和忽略网络拓扑空间结构的问题，提出了一种空间-时间强化学习（STRL）框架。该框架通过设计特定的非马尔可夫流量环境，有效解决了现有方法的局限性。实验结果表明，STRL在训练和推断阶段均显著优于传统基线，即使在网络拓扑发生变化的情况下也能保持性能优势。", "keywords": "空间-时间强化学习, 网络路由, 非马尔可夫流量, 强化学习, 网络拓扑", "comments": "本文的创新点在于提出了空间-时间强化学习（STRL）框架，以解决传统RL在处理非马尔可夫流量和建模网络拓扑空间结构方面的不足。其重要性在于提升了网络路由在真实复杂流量环境下的性能和鲁棒性。"}}
{"id": "2507.23694", "title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM", "authors": ["Virginia Padilla", "Jacinto Dávila"], "categories": ["cs.MA", "cs.AI", "68T42", "I.2.11"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      20 pages, 1 table", "url": "http://arxiv.org/abs/2507.23694v1", "summary": "We provide a comprehensive examination of agent-based approaches that codify\nthe principles and linkages underlying multi-agent systems, simulations, and\ninformation systems. Based on two decades of study, this paper confirms a\nframework intended as a formal specification for geosimulation platforms. Our\nfindings show that large language models (LLMs) can be effectively incorporated\nas agent components if they follow a structured architecture specific to\nfundamental agent activities such as perception, memory, planning, and action.\nThis integration is precisely consistent with the architecture that we\nformalize, providing a solid platform for next-generation geosimulation\nsystems.", "comment": "20 pages, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.23694v1", "cate": "cs.MA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多智能体地理模拟方法综述：从ABM到LLM", "tldr": "本文综述了多智能体地理模拟方法，并提出将大型语言模型（LLMs）整合到现有框架中，以支持下一代地理模拟系统。", "motivation": "本文旨在全面审视多智能体系统、模拟和信息系统中的基于智能体方法，并确认一个用于地理模拟平台的正式规范框架。", "method": "本文通过对二十年研究的综合审查，确认了一个旨在作为地理模拟平台形式规范的框架。", "result": "研究发现，如果大型语言模型（LLMs）遵循特定于感知、记忆、规划和行动等基本智能体活动的结构化架构，它们可以有效地作为智能体组件被整合。", "conclusion": "将LLMs整合到作者形式化的架构中，为下一代地理模拟系统提供了一个坚实平台。", "translation": "我们全面审视了将多智能体系统、模拟和信息系统背后的原理和联系编码化的基于智能体方法。基于二十年的研究，本文确认了一个旨在作为地理模拟平台形式规范的框架。我们的研究结果表明，如果大型语言模型（LLMs）遵循特定于感知、记忆、规划和行动等基本智能体活动的结构化架构，它们可以有效地作为智能体组件被整合。这种整合与我们形式化的架构精确一致，为下一代地理模拟系统提供了一个坚实的平台。", "summary": "本文对多智能体地理模拟方法进行了全面综述，并基于二十年的研究，提出了一个用于地理模拟平台的正式框架。研究特别指出，大型语言模型（LLMs）能够有效整合到该框架中作为智能体组件，前提是它们遵循特定的结构化架构，从而为下一代地理模拟系统奠定基础。", "keywords": "多智能体系统, 地理模拟, 大型语言模型, 智能体架构, ABM", "comments": "本文的创新之处在于提出了将大型语言模型（LLMs）整合到多智能体地理模拟系统中的可能性，并强调了这种整合需要遵循特定的结构化架构。这为地理模拟领域带来了新的范式，可能极大地提升模拟的复杂性和智能性，推动下一代地理模拟系统发展。"}}
{"id": "2507.23174", "title": "CNN-based solution for mango classification in agricultural environments", "authors": ["Beatriz Díaz Peón", "Jorge Torres Gómez", "Ariel Fajardo Márquez"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23174v1", "summary": "This article exemplifies the design of a fruit detection and classification\nsystem using Convolutional\n  Neural Networks (CNN). The goal is to develop a system that automatically\nassesses fruit quality for\n  farm inventory management. Specifically, a method for mango fruit\nclassification was developed using\n  image processing, ensuring both accuracy and efficiency. Resnet-18 was\nselected as the preliminary\n  architecture for classification, while a cascade detector was used for\ndetection, balancing execution speed\n  and computational resource consumption. Detection and classification results\nwere displayed through a\n  graphical interface developed in MatLab App Designer, streamlining system\ninteraction. The integration\n  of convolutional neural networks and cascade detectors proffers a reliable\nsolution for fruit classification\n  and detection, with potential applications in agricultural quality control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23174v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于CNN的农业环境下芒果分类解决方案", "tldr": "本文提出了一种基于CNN的芒果果实检测与分类系统，旨在实现农业环境中水果质量的自动评估和库存管理。", "motivation": "开发一个系统，用于自动评估水果质量，以实现农场库存管理。", "method": "使用卷积神经网络（CNN）设计了一个水果检测和分类系统。具体而言，采用图像处理技术开发了芒果分类方法，并选择Resnet-18作为分类的初步架构，同时使用级联检测器进行检测，以平衡执行速度和计算资源消耗。检测和分类结果通过在MatLab App Designer中开发的图形界面显示。", "result": "该系统提供了一种可靠的水果分类和检测解决方案，并通过MatLab App Designer开发的图形界面展示了检测和分类结果。", "conclusion": "卷积神经网络和级联检测器的集成提供了一种可靠的水果分类和检测解决方案，在农业质量控制方面具有潜在应用。", "translation": "本文展示了使用卷积神经网络（CNN）设计水果检测和分类系统。目标是开发一个系统，自动评估水果质量，用于农场库存管理。具体而言，开发了一种使用图像处理的芒果果实分类方法，确保了准确性和效率。Resnet-18被选为分类的初步架构，而级联检测器用于检测，平衡了执行速度和计算资源消耗。检测和分类结果通过在MatLab App Designer中开发的图形界面显示，简化了系统交互。卷积神经网络和级联检测器的集成提供了一种可靠的水果分类和检测解决方案，在农业质量控制方面具有潜在应用。", "summary": "本文设计并实现了一个基于卷积神经网络（CNN）的芒果果实检测与分类系统，旨在自动化农场库存管理中的水果质量评估。该系统采用图像处理技术，结合Resnet-18进行分类和级联检测器进行检测，以平衡性能和资源消耗。所有结果均通过MatLab App Designer开发的图形界面展示，为农业质量控制提供了可靠的解决方案。", "keywords": "芒果分类, 卷积神经网络, 图像处理, 农业环境, Resnet-18", "comments": "该论文提出了一种实用的、基于深度学习的农业应用方案。其创新点在于结合了Resnet-18和级联检测器来优化检测与分类的平衡，并利用MatLab App Designer开发了用户友好的图形界面，提升了系统的实用性。该系统在自动化农产品质量控制和库存管理方面具有重要意义。"}}
{"id": "2507.23278", "title": "UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing", "authors": ["Hao Tang", "Chenwei Xie", "Xiaoyi Bao", "Tingyu Weng", "Pandeng Li", "Yun Zheng", "Liwei Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23278v1", "summary": "In this paper, we propose UniLIP, which extends CLIP to reconstruction,\ngeneration and editing, thereby building a unified tokenizer upon its\nexceptional comprehension capabilities. Previous CLIP-based unified methods\noften require additional diffusion decoders or quantization to support\nreconstruction and generation tasks, leading to inconsistent reconstruction or\ndegradation of original comprehension performance.In contrast, we introduce a\ntwo-stage training scheme and a self-distillation strategy that progressively\nintegrates reconstruction capabilities into CLIP, allowing it to maintain\noriginal comprehension performance while achieving effective image\nreconstruction. Furthermore, we propose a dual-condition architecture to\nconnect the MLLM and diffusion transformer, using both learnable queries and\nthe last layer multimodal hidden states as joint conditions. This method not\nonly enables the utilization of the MLLM's strong reasoning capabilities in\ngeneration tasks, but also maximizes the exploitation of the rich information\nin UniLIP features during editing tasks. In text-to-image generation tasks,\nUniLIP obtains scores of 0.87 and 0.53 on GenEval and WISE benchmark\nrespectively, surpassing all previous unified models of similar scale. In image\nediting, UniLIP also achieves a score of 3.62 on the ImgEdit Benchmark,\nsurpassing recent state-of-the-art models such as BAGEL and UniWorld-V1. UniLIP\neffectively expand the application scope of CLIP, enabling continuous CLIP\nfeatures to not only serve as the optimal choice for understanding tasks but\nalso achieve highly competitive performance in generation and editing tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23278v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "UniLiP：将CLIP应用于统一的多模态理解、生成和编辑", "tldr": "UniLiP扩展了CLIP，通过两阶段训练和自蒸馏实现统一的多模态理解、生成和编辑，在保持原有理解性能的同时，在生成和编辑任务中取得了SOTA表现。", "motivation": "之前的基于CLIP的统一方法通常需要额外的扩散解码器或量化来支持重建和生成任务，这导致重建不一致或原有理解性能下降。", "method": "提出UniLIP，通过两阶段训练方案和自蒸馏策略逐步将重建能力整合到CLIP中，以保持原有理解性能并实现有效的图像重建。此外，提出了一个双条件架构，连接MLLM和扩散Transformer，使用可学习查询和最后一层多模态隐藏状态作为联合条件。", "result": "在文本到图像生成任务中，UniLiP在GenEval和WISE基准上分别获得0.87和0.53分，超越了所有之前类似规模的统一模型。在图像编辑中，UniLiP在ImgEdit基准上获得3.62分，超越了BAGEL和UniWorld-V1等最新SOTA模型。", "conclusion": "UniLiP有效地扩展了CLIP的应用范围，使连续的CLIP特征不仅能作为理解任务的最佳选择，也能在生成和编辑任务中实现极具竞争力的性能。", "translation": "在本文中，我们提出了UniLIP，它将CLIP扩展到重建、生成和编辑领域，从而在其卓越的理解能力之上构建了一个统一的tokenizer。之前基于CLIP的统一方法通常需要额外的扩散解码器或量化来支持重建和生成任务，这导致重建不一致或原有理解性能下降。相比之下，我们引入了一种两阶段训练方案和自蒸馏策略，逐步将重建能力整合到CLIP中，使其在保持原有理解性能的同时实现有效的图像重建。此外，我们提出了一种双条件架构来连接MLLM和扩散Transformer，使用可学习查询和最后一层多模态隐藏状态作为联合条件。这种方法不仅能够利用MLLM强大的推理能力进行生成任务，而且最大限度地利用UniLIP特征中的丰富信息进行编辑任务。在文本到图像生成任务中，UniLiP在GenEval和WISE基准上分别获得0.87和0.53分，超越了所有之前类似规模的统一模型。在图像编辑中，UniLiP在ImgEdit基准上也获得了3.62分，超越了BAGEL和UniWorld-V1等最新SOTA模型。UniLiP有效地扩展了CLIP的应用范围，使连续的CLIP特征不仅能作为理解任务的最佳选择，也能在生成和编辑任务中实现极具竞争力的性能。", "summary": "本文提出UniLiP，一个将CLIP扩展到统一多模态理解、生成和编辑的框架。它通过两阶段训练和自蒸馏策略，在保持CLIP原有理解能力的同时，有效整合了重建功能。UniLiP引入双条件架构连接MLLM和扩散Transformer，利用MLLM的推理能力和UniLiP特征的丰富信息，在文本到图像生成和图像编辑任务中均超越了现有SOTA模型，展现了CLIP特征在多模态任务中的广泛应用潜力。", "keywords": "CLIP, 多模态, 理解, 生成, 编辑, 统一模型", "comments": "UniLiP的创新之处在于其通过两阶段训练和自蒸馏策略，在不牺牲CLIP原有理解性能的前提下，成功将其能力扩展到生成和编辑领域。其双条件架构有效整合了MLLM的推理能力和UniLiP的特征信息，实现了多模态任务的统一和高性能，是CLIP应用扩展的重要进展。"}}
{"id": "2507.23372", "title": "UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries", "authors": ["Yijie Zhu", "Lingsen Zhang", "Zitong Yu", "Rui Shao", "Tao Tan", "Liqiang Nie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23372v1", "summary": "Emotional understanding and generation are often treated as separate tasks,\nyet they are inherently complementary and can mutually enhance each other. In\nthis paper, we propose the UniEmo, a unified framework that seamlessly\nintegrates these two tasks. The key challenge lies in the abstract nature of\nemotions, necessitating the extraction of visual representations beneficial for\nboth tasks. To address this, we propose a hierarchical emotional understanding\nchain with learnable expert queries that progressively extracts multi-scale\nemotional features, thereby serving as a foundational step for unification.\nSimultaneously, we fuse these expert queries and emotional representations to\nguide the diffusion model in generating emotion-evoking images. To enhance the\ndiversity and fidelity of the generated emotional images, we further introduce\nthe emotional correlation coefficient and emotional condition loss into the\nfusion process. This step facilitates fusion and alignment for emotional\ngeneration guided by the understanding. In turn, we demonstrate that joint\ntraining allows the generation component to provide implicit feedback to the\nunderstanding part. Furthermore, we propose a novel data filtering algorithm to\nselect high-quality and diverse emotional images generated by the well-trained\nmodel, which explicitly feedback into the understanding part. Together, these\ngeneration-driven dual feedback processes enhance the model's understanding\ncapacity. Extensive experiments show that UniEmo significantly outperforms\nstate-of-the-art methods in both emotional understanding and generation tasks.\nThe code for the proposed method is available at\nhttps://github.com/JiuTian-VL/UniEmo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23372v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "UniEmo：使用可学习专家查询统一情感理解与生成", "tldr": "UniEmo是一个统一的情感理解与生成框架，通过分层理解链和生成驱动的双重反馈机制，显著提升了模型在两项任务上的性能。", "motivation": "情感理解和生成通常被视为独立任务，但它们本质上是互补的，可以相互增强。关键挑战在于情感的抽象性，需要提取对两项任务都有益的视觉表示。", "method": "本文提出了UniEmo统一框架，无缝整合情感理解和生成任务。首先，通过具有可学习专家查询的分层情感理解链，逐步提取多尺度情感特征。其次，将这些专家查询和情感表示融合，引导扩散模型生成情感图像，并通过引入情感相关系数和情感条件损失来增强生成图像的多样性和保真度。此外，该框架通过联合训练实现生成组件对理解部分的隐式反馈，并提出一种新颖的数据过滤算法，选择高质量生成图像显式反馈到理解部分，形成生成驱动的双重反馈机制。", "result": "UniEmo在情感理解和生成任务上均显著优于现有最先进的方法。", "conclusion": "联合训练和生成驱动的双重反馈过程能够显著增强模型的情感理解和生成能力。", "translation": "情感理解和生成通常被视为独立任务，但它们本质上是互补的，可以相互增强。在本文中，我们提出了UniEmo，一个无缝整合这两项任务的统一框架。关键挑战在于情感的抽象性，需要提取对两项任务都有益的视觉表示。为了解决这个问题，我们提出了一种具有可学习专家查询的分层情感理解链，该链逐步提取多尺度情感特征，从而作为统一的基础步骤。同时，我们将这些专家查询和情感表示融合，以指导扩散模型生成唤起情感的图像。为了增强生成情感图像的多样性和保真度，我们进一步在融合过程中引入了情感相关系数和情感条件损失。这一步骤促进了由理解引导的情感生成的融合和对齐。反过来，我们证明了联合训练允许生成组件向理解部分提供隐式反馈。此外，我们提出了一种新颖的数据过滤算法，用于选择由训练有素的模型生成的高质量和多样化的情感图像，这些图像明确地反馈到理解部分。总之，这些生成驱动的双重反馈过程增强了模型的理解能力。大量实验表明，UniEmo在情感理解和生成任务上均显著优于现有最先进的方法。所提出方法的代码可在 https://github.com/JiuTian-VL/UniEmo 获取。", "summary": "本文提出了UniEmo，一个统一情感理解与生成的框架。针对情感的抽象性，它设计了分层情感理解链和可学习专家查询来提取多尺度情感特征。同时，通过融合专家查询和情感表示，并引入情感相关系数及情感条件损失，指导扩散模型生成高质量情感图像。该框架通过联合训练实现生成对理解的隐式反馈，并利用新型数据过滤算法提供显式反馈，形成生成驱动的双重反馈机制，显著提升了模型在两项任务上的性能。", "keywords": "情感理解, 情感生成, 统一框架, 扩散模型, 可学习专家查询", "comments": "该论文的创新点在于首次提出了一个统一的框架来处理情感理解和生成这两个通常被视为独立的任务，并利用生成驱动的双重反馈机制来相互增强。这种方法克服了情感抽象性的挑战，并通过引入可学习专家查询和特定的损失函数来提高生成图像的质量和多样性。其统一性和反馈机制是其重要贡献。"}}
{"id": "2407.03080", "title": "Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios", "authors": ["Patricia A. Apellániz", "Ana Jiménez", "Borja Arroyo Galende", "Juan Parras", "Santiago Zazo"], "categories": ["cs.LG", "cs.AI", "I.2.0"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      19 pages, 6 Figures", "url": "http://arxiv.org/abs/2407.03080v2", "summary": "While synthetic tabular data generation using Deep Generative Models (DGMs)\noffers a compelling solution to data scarcity and privacy concerns, their\neffectiveness relies on the availability of substantial training data, often\nlacking in real-world scenarios. To overcome this limitation, we propose a\nnovel methodology that explicitly integrates artificial inductive biases into\nthe generative process to improve data quality in low-data regimes. Our\nframework leverages transfer learning and meta-learning techniques to construct\nand inject informative inductive biases into DGMs. We evaluate four approaches\n(pre-training, model averaging, Model-Agnostic Meta-Learning (MAML), and Domain\nRandomized Search (DRS)) and analyze their impact on the quality of the\ngenerated text. Experimental results show that incorporating inductive bias\nsubstantially improves performance, with transfer learning methods\noutperforming meta-learning, achieving up to 60\\% gains in Jensen-Shannon\ndivergence. The methodology is model-agnostic and especially relevant in\ndomains such as healthcare and finance, where high-quality synthetic data are\nessential, and data availability is often limited.", "comment": "19 pages, 6 Figures", "pdf_url": "http://arxiv.org/pdf/2407.03080v2", "cate": "cs.LG", "date": "2024-07-03", "updated": "2025-07-31", "AI": {"title_translation": "数据稀缺场景下合成表格数据生成的人工归纳偏置", "tldr": "该研究提出了一种将人工归纳偏置集成到深度生成模型中的新方法，以提高数据稀缺场景下合成表格数据的质量，并发现迁移学习方法优于元学习方法。", "motivation": "深度生成模型在合成表格数据生成中面临数据量不足的限制，特别是在真实世界场景中，其有效性依赖于大量训练数据，而这往往是缺乏的。", "method": "提出了一种新颖的方法，将人工归纳偏置明确地集成到生成过程中，以改善低数据状态下的数据质量。该框架利用迁移学习和元学习技术来构建并将信息丰富的归纳偏置注入到深度生成模型中。评估了四种方法：预训练、模型平均、模型无关元学习（MAML）和域随机化搜索（DRS）。", "result": "实验结果表明，结合归纳偏置显著提高了性能，其中迁移学习方法优于元学习方法，在Jensen-Shannon散度方面实现了高达60%的增益。", "conclusion": "该方法是模型无关的，并且特别适用于医疗保健和金融等领域，在这些领域中高质量的合成数据至关重要，但数据可用性通常有限。通过集成人工归纳偏置，可以有效解决数据稀缺场景下合成表格数据质量差的问题。", "translation": "尽管使用深度生成模型（DGMs）生成合成表格数据为数据稀缺和隐私问题提供了引人注目的解决方案，但其有效性依赖于大量训练数据的可用性，而这在现实世界场景中往往是缺乏的。为了克服这一限制，我们提出了一种新颖的方法，将人工归纳偏置明确地集成到生成过程中，以改善低数据状态下的数据质量。我们的框架利用迁移学习和元学习技术来构建并将信息丰富的归纳偏置注入到DGMs中。我们评估了四种方法（预训练、模型平均、模型无关元学习（MAML）和域随机化搜索（DRS））并分析了它们对生成文本质量的影响。实验结果表明，结合归纳偏置显著提高了性能，其中迁移学习方法优于元学习方法，在Jensen-Shannon散度方面实现了高达60%的增益。该方法是模型无关的，并且特别适用于医疗保健和金融等领域，在这些领域中高质量的合成数据至关重要，但数据可用性通常有限。", "summary": "本研究旨在解决深度生成模型在数据稀缺场景下合成表格数据质量不高的问题。作者提出了一种将人工归纳偏置集成到生成过程中的新方法，通过利用迁移学习和元学习技术来注入有用的归纳偏置。实验评估了预训练、模型平均、MAML和DRS四种方法，结果显示引入归纳偏置能显著提升性能，尤其迁移学习方法表现最佳，在Jensen-Shannon散度上实现了高达60%的改进。该方法具有模型无关性，特别适用于医疗保健和金融等数据稀缺但对数据质量要求高的领域。", "keywords": "合成数据生成, 归纳偏置, 数据稀缺, 深度生成模型, 迁移学习", "comments": "该论文提出了一种解决深度生成模型在数据稀缺场景下生成高质量合成表格数据的重要问题的方法。其创新点在于明确地将人工归纳偏置集成到生成过程中，并通过结合迁移学习和元学习技术来实现。实验结果显示了显著的性能提升，尤其强调了迁移学习的有效性。该方法的模型无关性及其在关键领域（如医疗保健和金融）的适用性，使其具有重要的实际应用价值。"}}
{"id": "2503.10410", "title": "RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground Simulation", "authors": ["Yuwen Du", "Anning Hu", "Zichen Chao", "Yifan Lu", "Junhao Ge", "Genjia Liu", "Weitao Wu", "Lanjun Wang", "Siheng Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.10410v3", "summary": "Roadside Collaborative Perception refers to a system where multiple roadside\nunits collaborate to pool their perceptual data, assisting vehicles in\nenhancing their environmental awareness. Existing roadside perception methods\nconcentrate on model design but overlook data issues like calibration errors,\nsparse information, and multi-view consistency, leading to poor performance on\nrecent published datasets. To significantly enhance roadside collaborative\nperception and address critical data issues, we present the first simulation\nframework RoCo-Sim for road-side collaborative perception. RoCo-Sim is capable\nof generating diverse, multi-view consistent simulated roadside data through\ndynamic foreground editing and full-scene style transfer of a single image.\nRoCo-Sim consists of four components: (1) Camera Extrinsic Optimization ensures\naccurate 3D to 2D projection for roadside cameras; (2) A novel Multi-View\nOcclusion-Aware Sampler (MOAS) determines the placement of diverse digital\nassets within 3D space; (3) DepthSAM innovatively models foreground-background\nrelationships from single-frame fixed-view images, ensuring multi-view\nconsistency of foreground; and (4) Scalable Post-Processing Toolkit generates\nmore realistic and enriched scenes through style transfer and other\nenhancements. RoCo-Sim significantly improves roadside 3D object detection,\noutperforming SOTA methods by 83.74 on Rcooper-Intersection and 83.12 on\nTUMTraf-V2X for AP70. RoCo-Sim fills a critical gap in roadside perception\nsimulation. Code and pre-trained models will be released soon:\nhttps://github.com/duyuwen-duen/RoCo-Sim", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.10410v3", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-31", "AI": {"title_translation": "RoCo-Sim：通过前景模拟增强路侧协同感知", "tldr": "RoCo-Sim是一个首创的路侧协同感知模拟框架，通过解决数据问题显著提升了3D目标检测性能。", "motivation": "现有路侧感知方法主要关注模型设计，但忽略了标定误差、信息稀疏和多视角一致性等数据问题，导致在近期发布的公开数据集上表现不佳。", "method": "本文提出了首个路侧协同感知模拟框架RoCo-Sim，旨在解决关键数据问题。RoCo-Sim通过动态前景编辑和单图像全场景风格迁移，能够生成多样化、多视角一致的模拟路侧数据。该框架包含四个组件：1) 相机外参优化，确保路侧相机准确的3D到2D投影；2) 新颖的多视角遮挡感知采样器（MOAS），用于确定多样化数字资产在3D空间中的放置；3) DepthSAM，创新性地从单帧固定视角图像中建模前景-背景关系，确保前景的多视角一致性；4) 可扩展后处理工具包，通过风格迁移和其他增强生成更真实、更丰富的场景。", "result": "RoCo-Sim显著提升了路侧3D目标检测性能，在Rcooper-Intersection和TUMTraf-V2X数据集上，AP70指标分别超越SOTA方法83.74和83.12。", "conclusion": "RoCo-Sim填补了路侧感知模拟领域的关键空白。", "translation": "路侧协同感知是指多个路侧单元协作汇集其感知数据，以协助车辆增强其环境感知能力。现有的路侧感知方法侧重于模型设计，但忽略了标定误差、信息稀疏和多视角一致性等数据问题，导致在近期发布的公开数据集上表现不佳。为了显著增强路侧协同感知并解决关键数据问题，我们提出了首个路侧协同感知模拟框架RoCo-Sim。RoCo-Sim能够通过动态前景编辑和单图像全场景风格迁移生成多样化、多视角一致的模拟路侧数据。RoCo-Sim包含四个组件：(1) 相机外参优化，确保路侧相机准确的3D到2D投影；(2) 新颖的多视角遮挡感知采样器（MOAS），用于确定多样化数字资产在3D空间中的放置；(3) DepthSAM，创新性地从单帧固定视角图像中建模前景-背景关系，确保前景的多视角一致性；(4) 可扩展后处理工具包，通过风格迁移和其他增强生成更真实、更丰富的场景。RoCo-Sim显著提升了路侧3D目标检测性能，在Rcooper-Intersection和TUMTraf-V2X数据集上，AP70指标分别超越SOTA方法83.74和83.12。RoCo-Sim填补了路侧感知模拟领域的关键空白。代码和预训练模型将很快发布：https://github.com/duyuwen-duen/RoCo-Sim", "summary": "本文提出了RoCo-Sim，一个创新的路侧协同感知模拟框架，旨在解决现有方法中普遍存在的数据质量问题，如标定误差、信息稀疏和多视角不一致性。RoCo-Sim通过动态前景编辑和全场景风格迁移，能够生成多样且多视角一致的模拟数据。该框架由相机外参优化、多视角遮挡感知采样器、DepthSAM以及可扩展后处理工具包四个核心组件构成。实验结果表明，RoCo-Sim显著提升了路侧3D目标检测的性能，在多个数据集上超越了现有最佳方法，填补了路侧感知模拟的空白。", "keywords": "路侧协同感知, 模拟框架, 数据增强, 3D目标检测, 多视角一致性", "comments": "RoCo-Sim的创新在于它是首个专门针对路侧协同感知的数据模拟框架，通过解决数据质量问题（如多视角一致性和稀疏性）来提升性能，而非仅仅关注模型设计。其提出的组件，特别是DepthSAM和MOAS，为生成高质量、多视角一致的模拟数据提供了有效途径，对于弥补真实数据获取的困难和提升模型泛化能力具有重要意义。"}}
{"id": "2507.22902", "title": "Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting", "authors": ["Hashim Hayat", "Maksim Kudrautsau", "Evgeniy Makarov", "Vlad Melnichenko", "Tim Tsykunou", "Piotr Varaksin", "Matt Pavelle", "Adam Z. Oskowitz"], "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22902v1", "summary": "Background: Globally we face a projected shortage of 11 million healthcare\npractitioners by 2030, and administrative burden consumes 50% of clinical time.\nArtificial intelligence (AI) has the potential to help alleviate these\nproblems. However, no end-to-end autonomous large language model (LLM)-based AI\nsystem has been rigorously evaluated in real-world clinical practice. In this\nstudy, we evaluated whether a multi-agent LLM-based AI framework can function\nautonomously as an AI doctor in a virtual urgent care setting. Methods: We\nretrospectively compared the performance of the multi-agent AI system Doctronic\nand board-certified clinicians across 500 consecutive urgent-care telehealth\nencounters. The primary end points: diagnostic concordance, treatment plan\nconsistency, and safety metrics, were assessed by blinded LLM-based\nadjudication and expert human review. Results: The top diagnosis of Doctronic\nand clinician matched in 81% of cases, and the treatment plan aligned in 99.2%\nof cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not\nsupported by clinical findings). In an expert review of discordant cases, AI\nperformance was superior in 36.1%, and human performance was superior in 9.3%;\nthe diagnoses were equivalent in the remaining cases. Conclusions: In this\nfirst large-scale validation of an autonomous AI doctor, we demonstrated strong\ndiagnostic and treatment plan concordance with human clinicians, with AI\nperformance matching and in some cases exceeding that of practicing clinicians.\nThese findings indicate that multi-agent AI systems achieve comparable clinical\ndecision-making to human providers and offer a potential solution to healthcare\nworkforce shortages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22902v1", "cate": "cs.HC", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "迈向自主人工智能医生：在真实世界环境中对自主代理人工智能与委员会认证临床医生进行定量基准测试", "tldr": "一项大型研究表明，多智能体AI系统（Doctronic）在虚拟紧急护理环境中，其诊断和治疗计划与人类临床医生高度一致，且在某些方面表现更优，有望缓解医疗人员短缺。", "motivation": "全球面临医疗从业人员短缺和行政负担问题。尽管人工智能有潜力缓解这些问题，但目前尚无端到端自主大型语言模型（LLM）驱动的AI系统在真实临床实践中得到严格评估。本研究旨在评估一个多智能体LLM驱动的AI框架是否能作为AI医生在虚拟紧急护理环境中自主运行。", "method": "本研究回顾性比较了多智能体AI系统Doctronic与委员会认证临床医生在500次连续紧急护理远程医疗会诊中的表现。主要终点包括诊断一致性、治疗计划一致性和安全性指标，通过盲法LLM裁决和专家人工审查进行评估。", "result": "Doctronic的最高诊断与临床医生在81%的病例中匹配，治疗计划在99.2%的病例中保持一致。未发生临床幻觉。在不一致病例的专家审查中，AI表现优于36.1%的病例，人类表现优于9.3%的病例；其余病例的诊断则等效。", "conclusion": "这项首次对自主AI医生进行的大规模验证表明，其在诊断和治疗计划方面与人类临床医生具有高度一致性，且AI的性能在某些情况下与执业临床医生持平甚至超越。这些发现表明，多智能体AI系统能够实现与人类提供者相当的临床决策，并为医疗劳动力短缺提供潜在解决方案。", "translation": "背景：全球预计到2030年将面临1100万医疗从业人员的短缺，行政负担消耗了50%的临床时间。人工智能（AI）有潜力帮助缓解这些问题。然而，目前尚未有端到端的自主大型语言模型（LLM）驱动的AI系统在真实世界临床实践中得到严格评估。在本研究中，我们评估了一个多智能体LLM驱动的AI框架是否能作为AI医生在虚拟紧急护理环境中自主运行。方法：我们回顾性比较了多智能体AI系统Doctronic与委员会认证临床医生在500次连续紧急护理远程医疗会诊中的表现。主要终点：诊断一致性、治疗计划一致性和安全性指标，通过盲法LLM裁决和专家人工审查进行评估。结果：Doctronic的最高诊断与临床医生在81%的病例中匹配，治疗计划在99.2%的病例中保持一致。未发生临床幻觉（例如，诊断或治疗没有临床发现支持）。在不一致病例的专家审查中，AI表现优于36.1%的病例，人类表现优于9.3%；其余病例的诊断则等效。结论：在这项首次对自主AI医生进行的大规模验证中，我们展示了其与人类临床医生在诊断和治疗计划上的高度一致性，AI的性能与执业临床医生持平，在某些情况下甚至超越。这些发现表明，多智能体AI系统能够实现与人类提供者相当的临床决策，并为医疗劳动力短缺提供潜在解决方案。", "summary": "本研究首次大规模评估了一个名为Doctronic的多智能体LLM驱动的AI系统作为自主AI医生在虚拟紧急护理环境中的表现。通过回顾性比较500例远程医疗会诊，结果显示Doctronic在诊断和治疗计划上与委员会认证临床医生高度一致（诊断匹配81%，治疗计划一致99.2%），未出现临床幻觉，并且在部分诊断不一致的病例中表现优于人类。研究表明该AI系统具备与人类提供者相当的临床决策能力，有望成为解决医疗劳动力短缺的有效方案。", "keywords": "自主AI医生, LLM, 医疗AI, 临床决策, Doctronic", "comments": "这项研究创新性地在大规模真实世界场景中对端到端自主AI医疗系统进行了严格评估，填补了该领域的空白。其重要性在于验证了多智能体AI系统在临床决策上的可行性和有效性，尤其是在缓解医疗人员短缺方面的巨大潜力。AI在某些情况下超越人类的表现尤为引人注目，预示着未来AI在医疗领域将扮演更重要的角色。局限性可能在于研究是在虚拟紧急护理环境下进行的，真实线下临床环境的复杂性可能有所不同，且研究为回顾性研究。"}}
{"id": "2401.13481", "title": "How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment", "authors": ["Joshua Ashkinaze", "Julia Mendelsohn", "Li Qiwei", "Ceren Budak", "Eric Gilbert"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted at ACM Collective Intelligence 2025. Originally posted 2024", "url": "http://arxiv.org/abs/2401.13481v3", "summary": "Exposure to large language model output is rapidly increasing. How will\nseeing AI-generated ideas affect human ideas? We conducted an experiment (800+\nparticipants, 40+ countries) where participants viewed creative ideas that were\nfrom ChatGPT or prior experimental participants and then brainstormed their own\nidea. We varied the number of AI-generated examples (none, low, or high\nexposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic\nexperiment design -- ideas from prior participants in an experimental condition\nare used as stimuli for future participants in the same experimental condition\n-- speaks to the interdependent process of cultural creation: creative ideas\nare built upon prior ideas. Hence, we capture the compounding effects of having\nLLMs 'in the culture loop'. We find that high AI exposure (but not low AI\nexposure) did not affect the creativity of individual ideas but did increase\nthe average amount and rate of change of collective idea diversity. AI made\nideas different, not better. There were no main effects of disclosure. We also\nfound that self-reported creative people were less influenced by knowing an\nidea was from AI and that participants may knowingly adopt AI ideas when the\ntask is difficult. Our findings suggest that introducing AI ideas may increase\ncollective diversity but not individual creativity.", "comment": "Accepted at ACM Collective Intelligence 2025. Originally posted 2024", "pdf_url": "http://arxiv.org/pdf/2401.13481v3", "cate": "cs.CY", "date": "2024-01-24", "updated": "2025-07-31", "AI": {"title_translation": "人工智能思想如何影响人类思想的创造力、多样性和演变：来自一项大型动态实验的证据", "tldr": "高强度接触AI生成思想不会影响个体创造力，但会增加集体思想多样性；AI使思想变得不同而非更好。", "motivation": "随着大型语言模型输出的日益普及，本研究旨在探究接触AI生成思想将如何影响人类思想的创造力。", "method": "研究进行了一项大型动态实验（800多名参与者，40多个国家），参与者在头脑风暴自己的想法之前，会先查看来自ChatGPT或之前实验参与者的创意想法。实验变量包括AI生成示例的数量（无、低、高暴露）以及示例是否被标记为“AI”（披露）。动态实验设计使得前一批参与者的想法成为后续参与者的刺激，以捕捉LLM“在文化循环中”的复合效应。", "result": "高AI暴露（而非低AI暴露）不影响个体想法的创造力，但增加了集体想法多样性的平均量和变化率。AI使想法变得不同，而非更好。披露没有主要影响。自称有创造力的人受AI来源的影响较小，且参与者可能在任务困难时有意采纳AI想法。", "conclusion": "引入AI思想可能会增加集体多样性，但不会提高个体创造力。", "translation": "大型语言模型的输出正在迅速增加。看到AI生成的思想将如何影响人类思想？我们进行了一项实验（800多名参与者，40多个国家），参与者查看了来自ChatGPT或之前实验参与者的创意想法，然后集思广益提出自己的想法。我们改变了AI生成示例的数量（无、低或高暴露）以及示例是否被标记为“AI”（披露）。我们的动态实验设计——实验条件下先前参与者的想法被用作同一实验条件下未来参与者的刺激——说明了文化创造的相互依存过程：创意想法建立在先前的想法之上。因此，我们捕捉了将LLM“置于文化循环中”的复合效应。我们发现高AI暴露（但非低AI暴露）不影响个体想法的创造力，但确实增加了集体想法多样性的平均量和变化率。AI使想法变得不同，而非更好。披露没有主要影响。我们还发现，自称有创造力的人受AI来源的影响较小，并且参与者在任务困难时可能会有意采纳AI想法。我们的发现表明，引入AI想法可能会增加集体多样性，但不会提高个体创造力。", "summary": "本研究通过一项跨国大型动态实验，探讨了接触AI生成思想对人类思想创造力、多样性和演变的影响。结果显示，高强度AI暴露虽然不影响个体想法的创造力，但显著增加了集体想法的多样性，表明AI使想法变得不同而非更好。研究还发现，AI来源的披露没有主要影响，且自我报告的创意人士受AI影响较小，而参与者在任务困难时可能有意采纳AI想法。核心发现是引入AI思想能促进集体多样性而非个体创造力。", "keywords": "人工智能, 创造力, 多样性, 大型语言模型, 实验", "comments": "这项研究通过其大规模和动态实验设计，提供了一个独特的视角来理解AI在“文化循环”中的作用。其创新之处在于不仅关注个体效应，还考察了AI对集体思想多样性的影响。研究结果对于理解AI时代人类创造力的演变具有重要意义，尤其是在AI可能推动多样性而非简单提升个体“更好”想法方面。"}}
{"id": "2507.22905", "title": "Exploring LLM-generated Culture-specific Affective Human-Robot Tactile Interaction", "authors": ["Qiaoqiao Ren", "Tony Belpaeme"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22905v1", "summary": "As large language models (LLMs) become increasingly integrated into robotic\nsystems, their potential to generate socially and culturally appropriate\naffective touch remains largely unexplored. This study investigates whether\nLLMs-specifically GPT-3.5, GPT-4, and GPT-4o --can generate culturally adaptive\ntactile behaviours to convey emotions in human-robot interaction. We produced\ntext based touch descriptions for 12 distinct emotions across three cultural\ncontexts (Chinese, Belgian, and unspecified), and examined their\ninterpretability in both robot-to-human and human-to-robot scenarios. A total\nof 90 participants (36 Chinese, 36 Belgian, and 18 culturally unspecified)\nevaluated these LLM-generated tactile behaviours for emotional decoding and\nperceived appropriateness. Results reveal that: (1) under matched cultural\nconditions, participants successfully decoded six out of twelve emotions-mainly\nsocially oriented emotions such as love and Ekman emotions such as anger,\nhowever, self-focused emotions like pride and embarrassment were more difficult\nto interpret; (2) tactile behaviours were perceived as more appropriate when\ndirected from human to robot than from robot to human, revealing an asymmetry\nin social expectations based on interaction roles; (3) behaviours interpreted\nas aggressive (e.g., anger), overly intimate (e.g., love), or emotionally\nambiguous (i.e., not clearly decodable) were significantly more likely to be\nrated as inappropriate; and (4) cultural mismatches reduced decoding accuracy\nand increased the likelihood of behaviours being judged as inappropriate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22905v1", "cate": "cs.HC", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "探索LLM生成的文化特定情感人机触觉交互", "tldr": "本研究探讨了大型语言模型（LLMs）生成文化特定情感触觉行为在人机交互中的潜力，发现文化匹配、情感类型和交互方向显著影响触觉行为的解码准确性和感知适宜性。", "motivation": "尽管大型语言模型（LLMs）日益融入机器人系统，但它们生成符合社会和文化规范的情感触觉的潜力仍未被充分探索。", "method": "本研究使用GPT-3.5、GPT-4和GPT-4o生成了12种不同情感在三种文化背景（中国、比利时和未指定）下的文本触觉描述。90名参与者（36名中国人、36名比利时人、18名文化未指定者）评估了这些LLM生成的触觉行为的情感解码能力和感知适宜性，涉及机器人对人及人对机器人两种情景。", "result": "结果显示：(1) 在文化匹配条件下，参与者成功解码了12种情感中的6种，主要是社交导向情感（如爱）和艾克曼情感（如愤怒），而自我导向情感（如骄傲和尴尬）更难解释；(2) 人对机器人的触觉行为比机器人对人的更被认为合适，揭示了基于交互角色的社会期望不对称性；(3) 被解释为攻击性（如愤怒）、过度亲密（如爱）或情感模糊的行为被评为不合适的可能性显著更高；(4) 文化不匹配降低了解码准确性并增加了行为被判断为不合适的可能性。", "conclusion": "LLM能够生成部分可解码的文化特定情感触觉行为，但其有效性和适宜性受到情感类型、交互方向和文化匹配度的显著影响。", "translation": "随着大型语言模型（LLMs）日益融入机器人系统，它们生成符合社会和文化规范的情感触觉的潜力仍未被充分探索。本研究调查了LLM——特别是GPT-3.5、GPT-4和GPT-4o——是否能够生成文化适应性触觉行为，以在人机交互中传达情感。我们为三种文化背景（中国、比利时和未指定）下的12种不同情感生成了基于文本的触觉描述，并考察了它们在机器人对人及人对机器人情景中的可解释性。共有90名参与者（36名中国人、36名比利时人、18名文化未指定者）评估了这些LLM生成的触觉行为的情感解码能力和感知适宜性。结果显示：(1) 在文化匹配条件下，参与者成功解码了12种情感中的6种——主要是社交导向情感如爱和艾克曼情感如愤怒，然而，以自我为中心的情感如骄傲和尴尬更难解释；(2) 人对机器人的触觉行为比机器人对人的更被认为合适，揭示了基于交互角色的社会期望不对称性；(3) 被解释为攻击性（例如愤怒）、过度亲密（例如爱）或情感模糊（即不能清晰解码）的行为被评为不合适的可能性显著更高；(4) 文化不匹配降低了解码准确性并增加了行为被判断为不合适的可能性。", "summary": "本研究探讨了大型语言模型（LLMs）在人机交互中生成文化特定情感触觉行为的潜力。通过使用GPT模型生成跨文化情感触觉描述并由多文化参与者评估，研究发现LLM能够生成部分可解码的触觉情感，特别是在文化匹配和社交导向情感方面。然而，情感类型、交互方向（人对机器人比机器人对人更合适）和文化不匹配程度会显著影响触觉行为的解码准确性和感知适宜性，强调了在设计人机情感触觉交互时考虑文化适应性的重要性。", "keywords": "LLM, 人机交互, 触觉, 文化特定, 情感解码", "comments": "这项研究创新性地探索了LLM在生成文化特定情感触觉方面的应用，填补了现有研究的空白。它揭示了在人机触觉交互中文化适应性的重要性以及情感类型和交互方向对感知的影响，为未来设计更具文化敏感性的人机交互系统提供了宝贵见解。然而，研究结果也表明LLM在生成所有类型情感的文化适宜触觉方面仍存在局限性，特别是对于自我导向情感和跨文化情境。"}}
{"id": "2507.18493", "title": "Global Observer Design for a Class of Linear Observed Systems on Groups", "authors": ["Changwu Liu", "Yuan Shen"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      16 pages, 1 figure", "url": "http://arxiv.org/abs/2507.18493v2", "summary": "Linear observed systems on groups encode the geometry of a variety of\npractical state estimation problems. In this paper, we propose a unified\nobserver framework for a class of linear observed systems by restricting a\nbi-invariant system on a Lie group to its normal subgroup. This structural\nproperty powerfully enables a system immersion of the original system into a\nlinear time-varying system. Leveraging the immersion, an observer is\nconstructed by first designing a Kalman-like observer for the immersed system\nand then reconstructing the group-valued state via optimization. Under a rank\ncondition, global exponential stability (GES) is achieved provided one global\noptimum of the reconstruction optimization is found, reflecting the topological\ndifficulties inherent to the non-Euclidean state space. Semi-global stability\nis guaranteed when input biases are jointly estimated. The theory is applied to\nthe GES observer design for two-frame systems, capable of modeling a family of\nnavigation problems. Two non-trivial examples are provided to illustrate\nimplementation details.", "comment": "16 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.18493v2", "cate": "eess.SY", "date": "2025-07-24", "updated": "2025-07-31", "AI": {"title_translation": "群上一类线性观测系统的全局观测器设计", "tldr": "本文提出了一种针对群上线性观测系统的统一全局观测器设计框架，通过系统浸入和类卡尔曼滤波器结合优化方法，实现了全局指数稳定性，并应用于导航问题。", "motivation": "群上的线性观测系统编码了多种实际状态估计问题的几何结构。为解决这些问题，并克服非欧几里得状态空间固有的拓扑困难，需要设计有效的全局观测器。", "method": "本文通过将李群上的双不变系统限制在其正规子群上，提出了一种统一的观测器框架，从而将原始系统浸入到一个线性时变系统中。利用这种浸入，首先为浸入系统设计一个类卡尔曼观测器，然后通过优化重建群值状态来构建观测器。此外，通过联合估计输入偏差来保证半全局稳定性。", "result": "在满足秩条件且找到重构优化全局最优解的情况下，实现了全局指数稳定性（GES）。当联合估计输入偏差时，保证了半全局稳定性。该理论成功应用于双帧系统的GES观测器设计，这类系统能够建模一系列导航问题。提供了两个非平凡的例子来说明实现细节。", "conclusion": "本文为群上一类线性观测系统提供了一个统一的全局观测器设计框架，通过创新的系统浸入和优化重建方法，在特定条件下实现了全局指数稳定性，并有效解决了导航等实际状态估计问题中的拓扑挑战。", "translation": "群上的线性观测系统编码了多种实际状态估计问题的几何结构。本文通过将李群上的双不变系统限制在其正规子群上，提出了一种针对一类线性观测系统的统一观测器框架。这种结构特性有力地使得原始系统可以浸入到一个线性时变系统中。利用这种浸入，首先为浸入系统设计一个类卡尔曼观测器，然后通过优化重建群值状态来构建观测器。在满足秩条件的情况下，只要能找到重构优化中的一个全局最优解，就可以实现全局指数稳定性（GES），这反映了非欧几里得状态空间固有的拓扑困难。当联合估计输入偏差时，保证了半全局稳定性。该理论应用于双帧系统的GES观测器设计，这类系统能够建模一系列导航问题。提供了两个非平凡的例子来说明实现细节。", "summary": "本文提出了一种针对群上一类线性观测系统的统一全局观测器设计框架。该框架通过将李群上的双不变系统浸入到线性时变系统中，并结合类卡尔曼观测器与优化方法重建群值状态。研究表明，在满足秩条件且能找到全局最优解的情况下，可实现全局指数稳定性；同时，通过联合估计输入偏差可保证半全局稳定性。该理论成功应用于导航问题中双帧系统的观测器设计，并提供了具体实例。", "keywords": "全局观测器, 李群, 状态估计, 类卡尔曼观测器, 导航", "comments": "本文的创新之处在于利用李群理论和系统浸入方法，为非欧几里得状态空间设计全局观测器，有效解决了其固有的拓扑难题。通过结合类卡尔曼滤波器和优化重构，实现了理论上的全局指数稳定性。该研究在导航问题中的应用潜力，凸显了其重要的实际价值。"}}
{"id": "2507.23652", "title": "Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis", "authors": ["Kunpeng Qiu", "Zhiying Zhou", "Yongxin Guo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MICCAI2025", "url": "http://arxiv.org/abs/2507.23652v1", "summary": "Medical image annotation is constrained by privacy concerns and\nlabor-intensive labeling, significantly limiting the performance and\ngeneralization of segmentation models. While mask-controllable diffusion models\nexcel in synthesis, they struggle with precise lesion-mask alignment. We\npropose \\textbf{Adaptively Distilled ControlNet}, a task-agnostic framework\nthat accelerates training and optimization through dual-model distillation.\nSpecifically, during training, a teacher model, conditioned on mask-image\npairs, regularizes a mask-only student model via predicted noise alignment in\nparameter space, further enhanced by adaptive regularization based on\nlesion-background ratios. During sampling, only the student model is used,\nenabling privacy-preserving medical image generation. Comprehensive evaluations\non two distinct medical datasets demonstrate state-of-the-art performance:\nTransUNet improves mDice/mIoU by 2.4%/4.2% on KiTS19, while SANet achieves\n2.6%/3.5% gains on Polyps, highlighting its effectiveness and superiority. Code\nis available at GitHub.", "comment": "Accepted by MICCAI2025", "pdf_url": "http://arxiv.org/pdf/2507.23652v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "自适应蒸馏ControlNet：用于医学图像合成的加速训练和卓越采样", "tldr": "本文提出了一种名为自适应蒸馏ControlNet的新框架，通过双模型蒸馏加速医学图像合成的训练和采样，并在两个医学数据集上实现了最先进的性能。", "motivation": "医学图像标注受隐私问题和劳动密集型标签的限制，这严重制约了分割模型的性能和泛化能力。虽然掩模可控扩散模型在合成方面表现出色，但它们在精确病灶-掩模对齐方面存在困难。", "method": "本文提出了自适应蒸馏ControlNet，这是一个任务无关的框架，通过双模型蒸馏加速训练和优化。具体来说，在训练期间，一个以掩模-图像对为条件的教师模型通过参数空间中的预测噪声对齐来规范一个仅有掩模的学生模型，并通过基于病灶-背景比的自适应正则化进一步增强。在采样期间，仅使用学生模型，从而实现隐私保护的医学图像生成。", "result": "在两个不同的医学数据集（KiTS19和Polyps）上进行了全面评估，结果表明该方法达到了最先进的性能：TransUNet在KiTS19上将mDice/mIoU提高了2.4%/4.2%，而SANet在Polyps上实现了2.6%/3.5%的增益。", "conclusion": "自适应蒸馏ControlNet通过其双模型蒸馏和自适应正则化方法，有效解决了医学图像合成中的训练加速、采样效率和病灶-掩模对齐问题，并在多个数据集上展示了卓越的性能和隐私保护能力。", "translation": "医学图像标注受隐私问题和劳动密集型标签的限制，这严重制约了分割模型的性能和泛化能力。虽然掩模可控扩散模型在合成方面表现出色，但它们在精确病灶-掩模对齐方面存在困难。我们提出了自适应蒸馏ControlNet，这是一个任务无关的框架，通过双模型蒸馏加速训练和优化。具体来说，在训练期间，一个以掩模-图像对为条件的教师模型通过参数空间中的预测噪声对齐来规范一个仅有掩模的学生模型，并通过基于病灶-背景比的自适应正则化进一步增强。在采样期间，仅使用学生模型，从而实现隐私保护的医学图像生成。在两个不同的医学数据集上进行的全面评估表明其达到了最先进的性能：TransUNet在KiTS19上将mDice/mIoU提高了2.4%/4.2%，而SANet在Polyps上实现了2.6%/3.5%的增益，突出了其有效性和优越性。代码已在GitHub上提供。", "summary": "本文提出自适应蒸馏ControlNet，一个用于医学图像合成的创新框架，旨在解决医学图像标注的隐私和劳动密集型挑战。该框架通过双模型蒸馏加速训练和优化：教师模型（条件于掩模-图像对）通过预测噪声对齐和自适应正则化（基于病灶-背景比）来规范仅掩模的学生模型。在采样阶段，仅使用学生模型，确保隐私保护。实验证明，该方法在KiTS19和Polyps数据集上实现了最先进的性能，显著提高了分割模型的mDice/mIoU。", "keywords": "医学图像合成,蒸馏,ControlNet,深度学习,隐私保护", "comments": "该论文提出了一种新颖的自适应蒸馏ControlNet框架，其创新点在于采用双模型蒸馏策略，结合教师模型对学生模型的正则化以及基于病灶-背景比的自适应正则化，有效解决了医学图像合成中的精确对齐和隐私保护问题。其重要性在于，通过加速训练和优化，同时提升采样效率和质量，为受限的医学图像标注提供了实用且高性能的解决方案。在实际应用中，这种方法有望显著降低医学图像数据准备的成本和复杂性。"}}
{"id": "2507.05903", "title": "AI-Reporter: A Path to a New Genre of Scientific Communication", "authors": ["Gerd Graßhoff"], "categories": ["cs.DL", "cs.CL"], "primary_category": "Subjects:       Digital Libraries (cs.DL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05903v2", "summary": "The AI-Reporter represents a paradigmatic shift in scientific publication\npractice. This document demonstrates through a concrete case study how our\nsystem transforms academic presentations into publication-ready chapters -- in\nless than three minutes. Using Arno Simons' lecture on Large Language Models\nfrom the ``Large Language Models for the History, Philosophy, and Sociology of\nScience'' workshop (NEPI) as an example, we show how technological innovation\nbridges the gap between ephemeral presentation and permanent scientific\ndocumentation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05903v2", "cate": "cs.DL", "date": "2025-07-08", "updated": "2025-07-31", "AI": {"title_translation": "AI-Reporter：通往新型科学交流之路", "tldr": "AI-Reporter系统能够在三分钟内将学术演示文稿转化为可出版的章节，弥合了临时演示与永久科学文献之间的鸿沟，代表了科学出版实践的范式转变。", "motivation": "弥合临时性学术演示与永久性科学文献之间的鸿沟，改变传统的科学出版实践，提高效率。", "method": "AI-Reporter系统通过一个具体的案例研究，展示了其如何在不到三分钟内将学术演示文稿转化为可出版的章节。", "result": "系统成功地将Arno Simons关于大型语言模型的讲座转化为出版就绪的章节，证明了其能够快速将临时演示转化为永久科学文档。", "conclusion": "AI-Reporter系统通过技术创新，实现了科学出版实践的范式转变，有效连接了短暂的演示与持久的科学文档。", "translation": "AI-Reporter 代表着科学出版实践的范式转变。本文档通过一个具体的案例研究，展示了我们的系统如何在不到三分钟内将学术演示文稿转化为可出版的章节。以 Arno Simons 在“大型语言模型在科学史、哲学和社会学中的应用”研讨会 (NEPI) 上关于大型语言模型的讲座为例，我们展示了技术创新如何弥合了短暂演示与永久科学文献之间的鸿沟。", "summary": "AI-Reporter系统旨在革新科学出版方式，通过自动化流程在极短时间内将学术演示文稿转化为可出版的章节。该系统以大型语言模型讲座为例，成功展示了其如何有效连接临时性学术交流与永久性科学文档，预示着科学传播新范式的到来。", "keywords": "AI-Reporter, 科学交流, 科学出版, 大型语言模型, 自动化转化", "comments": "该论文提出了一种创新的科学交流方式，即AI-Reporter系统，其核心创新在于能够极大地缩短从学术演示到正式出版物的时间（不到三分钟）。这对于提高科学信息传播效率、促进知识快速转化具有重要意义。它解决了传统出版流程耗时长的痛点，有望开辟科学出版的新体裁。"}}
{"id": "2507.22951", "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22951v1", "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22951v1", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "统一知识图谱补全的后验解释", "tldr": "本论文提出了一个统一的知识图谱补全后验可解释性框架，通过多目标优化平衡解释的有效性和简洁性，并改进了评估协议，旨在提高KGC解释性研究的重现性和影响力。", "motivation": "知识图谱补全（KGC）的后验可解释性缺乏形式化和一致的评估，阻碍了研究的重现性和跨研究比较。", "method": "首先，提出了一个通用的框架，通过多目标优化来描述后验解释，平衡其有效性和简洁性，从而统一了现有KGC中的后验可解释性算法及其产生的解释。其次，建议并经验性地支持使用平均倒数排名（MRR）和Hits@k等流行指标改进评估协议。最后，强调了可解释性作为解释解决对终端用户有意义查询的能力的重要性。", "result": "通过多目标优化框架统一了现有KGC后验可解释性算法及其解释。经验性地支持了使用MRR和Hits@k等指标改进的评估协议。", "conclusion": "通过统一方法和完善评估标准，这项工作旨在使KGC可解释性研究更具重现性和影响力。", "translation": "知识图谱补全（KGC）的后验可解释性缺乏形式化和一致的评估，阻碍了研究的重现性和跨研究比较。本文主张对KGC中的后验可解释性采取统一的方法。首先，我们提出了一个通用框架，通过多目标优化来描述后验解释，平衡其有效性和简洁性。这统一了KGC中现有的后验可解释性算法及其产生的解释。其次，我们建议并经验性地支持使用平均倒数排名（Mean Reciprocal Rank）和Hits@k等流行指标改进评估协议。最后，我们强调了可解释性作为解释能够解决对终端用户有意义的查询的能力的重要性。通过统一方法和完善评估标准，这项工作旨在使KGC可解释性研究更具重现性和影响力。", "summary": "本论文针对知识图谱补全（KGC）后验可解释性缺乏形式化和评估一致性的问题，提出了一个统一的框架。该框架通过多目标优化平衡解释的有效性和简洁性，并统一了现有算法。此外，论文还提出了改进的评估协议，并强调了解释对终端用户查询的实际意义。这项工作旨在提高KGC可解释性研究的重现性和影响力。", "keywords": "知识图谱补全, 后验解释, 可解释性, 多目标优化, 评估协议", "comments": "该论文的创新点在于提出了一个统一的框架来描述和评估KGC的后验解释，并通过多目标优化平衡了有效性和简洁性。其重要性体现在解决了KGC解释性领域缺乏形式化和一致评估的痛点，有助于提高研究的重现性和可比较性。通过强调用户导向的可解释性，也提升了其实用价值。"}}
{"id": "2507.23425", "title": "Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures", "authors": ["Daphné Larrivain", "Shinhyung Yang", "Wilhelm Hasselbring"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      9 pages, 9 figures", "url": "http://arxiv.org/abs/2507.23425v1", "summary": "The Kieker observability framework is a tool that provides users with the\nmeans to design a custom observability pipeline for their application.\nOriginally tailored for Java, supporting Python with Kieker is worthwhile.\nPython's popularity has exploded over the years, thus making structural\ninsights of Python applications highly valuable. Our Python analysis pipeline\ncombines static and dynamic analysis in order to build a complete picture of a\ngiven system.", "comment": "9 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.23425v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用Kieker对Python软件进行动态和静态分析，包括重构架构", "tldr": "该论文提出了一种结合静态和动态分析的Python分析管道，以利用Kieker可观测性框架为Python应用程序提供结构洞察。", "motivation": "Kieker框架最初是为Java设计的，但Python的日益普及使得对Python应用程序进行结构洞察变得非常有价值，因此支持Python是值得的。", "method": "本文的Python分析管道结合了静态和动态分析方法，以构建给定系统的完整视图。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "Kieker可观测性框架是一个工具，它为用户提供了为其应用程序设计自定义可观测性管道的方法。该框架最初是为Java量身定制的，但支持Python是值得的。Python的流行度多年来呈爆炸式增长，因此对Python应用程序的结构洞察变得非常有价值。我们的Python分析管道结合了静态和动态分析，以构建给定系统的完整画面。", "summary": "本文介绍了一个为Python应用程序设计的分析管道，该管道扩展了Kieker可观测性框架的功能。鉴于Python日益增长的普及，该管道通过结合静态和动态分析技术，旨在提供对Python系统结构的全面理解。", "keywords": "Python分析, 动态分析, 静态分析, Kieker, 可观测性", "comments": "本文的创新之处在于将Kieker可观测性框架扩展到Python，并结合了静态和动态分析方法来提供更全面的系统视图。这对于理解和维护日益复杂的Python应用程序具有重要意义。"}}
{"id": "2504.05326", "title": "Totally Disjoint 3-Digit Decimal Check Digit Codes", "authors": ["Larry A. Dunning"], "categories": ["cs.IT", "math.CO", "math.IT", "68P30, 94B25, 05B15, 05B40, 20N15", "H.1.1; G.2.1; F.2.1"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.05326v2", "summary": "In 1969 J. Verhoeff provided the first examples of a decimal error detecting\ncode using a single check digit to provide protection against all single,\ntransposition and adjacent twin errors. The three versions of such a code that\nhe presented are length 3-digit codes with 2 information digits. Existence of a\n4-digit code would imply the existence of 10 such disjoint 3-digit codes. This\npaper presents 3 pairwise disjoint 3-digit codes. The codes developed herein,\nhave the property that the knowledge of the multiset of digits included in a\nword is sufficient to determine the entire codeword even though their positions\nwere unknown. Thus the codes are permutation-free, and this fulfills Verhoeff's\ndesire to eliminate \"cyclic errors\". Phonetic errors, where 2 digit pairs of\nthe forms X0 and 1X are interchanged, are also eliminated.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.05326v2", "cate": "cs.IT", "date": "2025-03-26", "updated": "2025-07-31", "AI": {"title_translation": "完全不相交的3位十进制校验码", "tldr": "本文提出了三种成对不相交的3位十进制校验码，它们是无置换的，可以消除循环错误和语音错误，改进了Verhoeff在1969年提出的错误检测码。", "motivation": "J. Verhoeff在1969年提供了首个使用单个校验位来保护所有单次、转置和相邻双胞胎错误的十进制错误检测码的例子。他提出的三种此类代码是长度为3位、包含2个信息位的代码。存在一个4位代码将意味着存在10个不相交的3位代码。本文的动机是进一步研究和开发具有改进特性的此类代码。", "method": "本文开发的代码具有一个特性：即使数字的位置未知，只要知道一个词中包含的数字多重集，就足以确定整个码字。因此，这些代码是无置换的，满足了Verhoeff消除“循环错误”的愿望。此外，这些代码还消除了语音错误，即形式为X0和1X的两位数字对互换的情况。", "result": "本文提出了3种成对不相交的3位代码。这些代码是无置换的，能够消除“循环错误”和语音错误（X0和1X形式的两位数字对互换）。", "conclusion": "本文成功开发了三种改进的3位十进制校验码，它们通过消除循环错误和特定类型的语音错误，增强了错误检测能力，并满足了Verhoeff关于消除“循环错误”的愿望。", "translation": "1969年，J. Verhoeff首次提供了十进制错误检测码的例子，该码使用单个校验位来提供对所有单一错误、转置错误和相邻双生错误的保护。他提出的此类代码有三种版本，它们是长度为3位的代码，包含2个信息位。4位代码的存在将意味着存在10个此类不相交的3位代码。本文提出了3种成对不相交的3位代码。本文开发的代码具有以下特性：即使数字的位置未知，只要知道一个词中包含的数字多重集，就足以确定整个码字。因此，这些代码是无置换的，这实现了Verhoeff消除“循环错误”的愿望。语音错误，即形式为X0和1X的两位数字对互换的情况，也得到了消除。", "summary": "本文介绍了三种成对不相交的3位十进制校验码，这些代码是Verhoeff在1969年提出的错误检测码的改进。这些新代码具有独特的无置换特性，这意味着即使在不知道数字位置的情况下，仅凭数字的多重集即可确定完整的码字。这一特性有助于消除Verhoeff所指的“循环错误”，并进一步消除了特定形式的语音错误（如X0和1X对互换）。这些代码的开发填补了对更多不相交3位代码的需求。", "keywords": "校验码, 错误检测, 无置换码, 循环错误, 语音错误", "comments": "本文的创新之处在于提出了具有无置换特性的校验码，这解决了Verhoeff之前提出的“循环错误”问题。通过利用数字多重集来确定码字，即使位置未知，也增强了错误检测的鲁棒性。此外，它还针对性地消除了语音错误，显示了其在实际应用中的潜力。重要性在于它推进了错误检测码的设计，特别是对于短长度代码，为更高维度的代码存在提供了基础。"}}
{"id": "2408.04210", "title": "Adaptive Cohen's Class Time-Frequency Distribution", "authors": ["Manjun Cui", "Zhichao Zhang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.04210v2", "summary": "Inspired by the use of adaptive kernel-based Cohen's class time-frequency\ndistributions (CCTFDs) for cross-term suppression, this paper aims to explore\nnovel adaptive kernel functions for denoising. We integrate Wiener filter\nprinciple and the time-frequency filtering mechanism of CCTFD to design the\nleast-squares adaptive filter method in the Wigner-Ville distribution (WVD)\ndomain, giving birth to the least-squares adaptive filter-based CCTFD whose\nkernel function can be adjusted with the input signal automatically to achieve\nthe minimum mean-square error denoising in the WVD domain. Some examples are\nalso carried out to demonstrate that the proposed adaptive CCTFD outperforms\nsome state-of-the-arts in noise suppression.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.04210v2", "cate": "eess.SP", "date": "2024-08-08", "updated": "2025-07-31", "AI": {"title_translation": "自适应科恩类时频分布", "tldr": "本文提出了一种基于最小二乘自适应滤波的科恩类时频分布（CCTFD），通过自动调整核函数，在Wigner-Ville分布（WVD）域实现最小均方误差去噪，并在噪声抑制方面优于现有技术。", "motivation": "受自适应核函数科恩类时频分布（CCTFD）在抑制交叉项方面的启发，本文旨在探索新的自适应核函数用于信号去噪。", "method": "本文将维纳滤波原理与CCTFD的时频滤波机制相结合，设计了Wigner-Ville分布（WVD）域的最小二乘自适应滤波方法，从而得到了基于最小二乘自适应滤波的CCTFD，其核函数可以随输入信号自动调整，以实现WVD域的最小均方误差去噪。", "result": "所提出的自适应CCTFD在噪声抑制方面优于一些现有技术。", "conclusion": "本文提出的基于最小二乘自适应滤波的科恩类时频分布能够有效地进行信号去噪，并且在噪声抑制方面表现出优越的性能。", "translation": "受自适应核函数科恩类时频分布（CCTFD）在抑制交叉项方面的启发，本文旨在探索新的自适应核函数用于去噪。我们将维纳滤波原理与CCTFD的时频滤波机制相结合，设计了Wigner-Ville分布（WVD）域的最小二乘自适应滤波方法，从而得到了基于最小二乘自适应滤波的CCTFD，其核函数可以随输入信号自动调整，以实现WVD域的最小均方误差去噪。通过一些例子也证明了所提出的自适应CCTFD在噪声抑制方面优于一些现有技术。", "summary": "本文提出了一种用于信号去噪的自适应科恩类时频分布（CCTFD）。该方法结合了维纳滤波原理和CCTFD的时频滤波机制，设计了Wigner-Ville分布（WVD）域的最小二乘自适应滤波器。其核心在于核函数能够根据输入信号自动调整，从而在WVD域实现最小均方误差去噪。实验结果表明，该自适应CCTFD在噪声抑制方面优于现有的先进技术。", "keywords": "科恩类时频分布, 自适应滤波, 去噪, 维纳滤波, Wigner-Ville分布", "comments": "这项研究的创新之处在于将维纳滤波原理引入科恩类时频分布的核函数设计中，实现了核函数的自适应调整以优化去噪性能。其重要性在于提供了一种在时频域进行有效噪声抑制的新方法，有望在信号处理领域，特别是在需要高精度时频分析的应用中发挥作用。论文明确指出其在噪声抑制方面优于现有技术，但未详细说明其在交叉项抑制方面的表现，这可能是进一步研究的方向。"}}
{"id": "2507.23279", "title": "Unveiling Super Experts in Mixture-of-Experts Large Language Models", "authors": ["Zunhai Su", "Qingyuan Li", "Hao Zhang", "YuLei Qian", "Yuchen Xie", "Kehong Yuan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23279v1", "summary": "Sparsely activated Mixture-of-Experts (MoE) models have shown promise in\nenhancing the learning capacity of large language models (LLMs). Leveraging the\nintrinsic importance differences among experts, recent research has explored\nexpert-level compression techniques to improve the efficiency of MoE LLMs.\nHowever, existing approaches often rely on empirical criteria to identify\ncritical experts, lacking a deeper exploration and understanding of the\nheterogeneous importance of experts. In this study, we present the first\ndiscovery and investigation of a distinct subset of experts that play a crucial\nrole in the underlying mechanisms during the model's forward inference. These\nexperts are prevalent in open-source MoE LLMs, and despite their limited\nnumber, pruning them leads to a significant decline in model performance (e.g.,\npruning three causes Qwen3-30B-A3B to produce repetitive and uninformative\noutputs). We refer to these experts as Super Experts (SEs). Our comprehensive\nanalysis provides progressively deeper insights into SEs. (i) SEs are\ncharacterized by rare but extreme activation outliers in the output of the\ndown_proj, which give rise to massive activations in the hidden states between\ndecoder layers. Moreover, the distribution of SEs remains model-specific and is\nunaffected by post-training processes. (ii) By pruning SEs, we assess their\nsignificance across a variety of tasks, revealing their considerable impact on\nthe model's overall performance, particularly in mathematical reasoning. (iii)\nWe further enhance our understanding of the influence of SEs compression. Our\nfindings confirm that MoE LLMs rely on SEs to induce attention sinks, which are\ncrucial for the distribution of attention scores but are significantly\ndisrupted by SE pruning. The code is available at\nhttps://github.com/ZunhaiSu/Super-Experts-Profilling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23279v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "揭示MoE大语言模型中的超级专家", "tldr": "本文首次发现并研究了MoE LLMs中一类关键专家，称为“超级专家”（SEs），它们数量虽少但对模型性能至关重要，其修剪会导致显著性能下降，并通过分析揭示了SEs的特性及其对注意力机制的影响。", "motivation": "现有的MoE LLMs专家级压缩方法通常依赖经验标准来识别关键专家，但缺乏对专家异质重要性的深入探索和理解。本研究旨在发现并理解在模型前向推理过程中扮演关键角色的特定专家子集。", "method": "本研究首次发现并调查了一类在模型前向推理中起关键作用的专家，并将其命名为“超级专家”（SEs）。研究通过剪枝SEs来评估它们在各种任务中的重要性，并深入分析了SEs的特性，包括它们在down_proj输出中的极端激活异常、对解码器层之间隐藏状态的巨大激活影响，以及它们如何通过诱导注意力汇聚（attention sinks）来影响注意力分数分布。", "result": "1. 首次发现并定义了“超级专家”（SEs），它们在开源MoE LLMs中普遍存在，数量有限但对模型性能至关重要（例如，剪枝三个SEs会导致Qwen3-30B-A3B产生重复且无信息量的输出）。\n2. SEs的特点是down_proj输出中存在罕见但极端的激活异常，这在解码器层之间的隐藏状态中引起大量激活。\n3. SEs的分布是模型特有的，不受训练后处理过程的影响。\n4. 剪枝SEs显著影响模型整体性能，尤其是在数学推理任务中。\n5. MoE LLMs依赖SEs来诱导注意力汇聚（attention sinks），这对于注意力分数的分布至关重要，而SEs的剪枝会严重破坏这一机制。", "conclusion": "本文首次揭示并深入研究了MoE LLMs中的“超级专家”（SEs），证明了它们在模型性能和注意力机制中的关键作用。这些发现为未来MoE LLMs的压缩和优化提供了新的视角和方向。", "translation": "稀疏激活的专家混合（MoE）模型已显示出增强大型语言模型（LLMs）学习能力的潜力。利用专家之间固有的重要性差异，最近的研究探索了专家级压缩技术以提高MoE LLMs的效率。然而，现有方法通常依赖经验标准来识别关键专家，缺乏对专家异质重要性的更深入探索和理解。在本研究中，我们首次发现并调查了一类在模型前向推理过程中扮演关键角色的独特专家子集。这些专家在开源MoE LLMs中普遍存在，尽管数量有限，但剪枝它们会导致模型性能显著下降（例如，剪枝三个会导致Qwen3-30B-A3B产生重复且无信息量的输出）。我们将这些专家称为超级专家（SEs）。我们的综合分析提供了对SEs逐步深入的见解。(i) SEs的特点是down_proj输出中存在罕见但极端的激活异常，这在解码器层之间的隐藏状态中引起大量激活。此外，SEs的分布保持模型特有，不受训练后处理过程的影响。(ii) 通过剪枝SEs，我们评估了它们在各种任务中的重要性，揭示了它们对模型整体性能的巨大影响，特别是在数学推理方面。(iii) 我们进一步增强了对SEs压缩影响的理解。我们的发现证实，MoE LLMs依赖SEs来诱导注意力汇聚（attention sinks），这对于注意力分数的分布至关重要，但会因SE剪枝而受到显著干扰。代码可在https://github.com/ZunhaiSu/Super-Experts-Profilling 获取。", "summary": "本研究首次识别并深入分析了MoE大语言模型中的一类关键专家，称之为“超级专家”（SEs）。研究发现，尽管SEs数量稀少，但它们在模型前向推理中扮演着至关重要的角色，其修剪会导致模型性能显著下降，尤其是在数学推理任务上。通过详细分析，论文揭示了SEs的独特激活模式及其在诱导注意力汇聚方面的关键作用，为理解MoE LLMs的内部机制和未来的模型优化提供了新的视角。", "keywords": "MoE LLMs, 超级专家, 专家混合模型, 模型压缩, 注意力机制", "comments": "这项研究首次系统地识别并深入剖析了MoE LLMs中一类名为“超级专家”的关键组件，具有重要的创新性。它不仅填补了现有研究在深入理解专家异质性方面的空白，还通过揭示SEs对模型性能、特别是注意力机制的关键影响，为未来MoE模型的剪枝、优化和设计提供了新的理论基础和实践指导。其发现SEs与注意力汇聚的关联尤其具有启发性。"}}
{"id": "2507.22477", "title": "LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks", "authors": ["Hui Liu", "Chen Jia", "Fan Shi", "Xu Cheng", "Mengfei Shi", "Xia Xie", "Shengyong Chen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.22477v2", "summary": "Achieving pixel-level segmentation with low computational cost using\nmultimodal data remains a key challenge in crack segmentation tasks. Existing\nmethods lack the capability for adaptive perception and efficient interactive\nfusion of cross-modal features. To address these challenges, we propose a\nLightweight Adaptive Cue-Aware Vision Mamba network (LIDAR), which efficiently\nperceives and integrates morphological and textural cues from different\nmodalities under multimodal crack scenarios, generating clear pixel-level crack\nsegmentation maps. Specifically, LIDAR is composed of a Lightweight Adaptive\nCue-Aware Visual State Space module (LacaVSS) and a Lightweight Dual Domain\nDynamic Collaborative Fusion module (LD3CF). LacaVSS adaptively models crack\ncues through the proposed mask-guided Efficient Dynamic Guided Scanning\nStrategy (EDG-SS), while LD3CF leverages an Adaptive Frequency Domain\nPerceptron (AFDP) and a dual-pooling fusion strategy to effectively capture\nspatial and frequency-domain cues across modalities. Moreover, we design a\nLightweight Dynamically Modulated Multi-Kernel convolution (LDMK) to perceive\ncomplex morphological structures with minimal computational overhead, replacing\nmost convolutional operations in LIDAR. Experiments on three datasets\ndemonstrate that our method outperforms other state-of-the-art (SOTA) methods.\nOn the light-field depth dataset, our method achieves 0.8204 in F1 and 0.8465\nin mIoU with only 5.35M parameters. Code and datasets are available at\nhttps://github.com/Karl1109/LIDAR-Mamba.", "comment": "This paper has been accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.22477v2", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "LIDAR：用于结构裂缝多模态分割的轻量级自适应线索感知融合视觉Mamba", "tldr": "LIDAR是一种轻量级自适应视觉Mamba网络，用于多模态裂缝分割，通过创新的模块和策略有效融合跨模态特征，实现了低计算成本下的SOTA性能。", "motivation": "在裂缝分割任务中，使用多模态数据以低计算成本实现像素级分割仍然是一个关键挑战。现有方法缺乏自适应感知和高效交互融合跨模态特征的能力。", "method": "本文提出了一种轻量级自适应线索感知视觉Mamba网络（LIDAR）。LIDAR由轻量级自适应线索感知视觉状态空间模块（LacaVSS）和轻量级双域动态协作融合模块（LD3CF）组成。LacaVSS通过掩码引导的高效动态引导扫描策略（EDG-SS）自适应建模裂缝线索，LD3CF则利用自适应频域感知器（AFDP）和双池化融合策略有效捕获跨模态的空间和频域线索。此外，还设计了轻量级动态调制多核卷积（LDMK）来感知复杂的形态结构，以最小的计算开销替换了LIDAR中的大部分卷积操作。", "result": "在三个数据集上的实验表明，该方法优于其他最先进（SOTA）的方法。在光场深度数据集上，该方法在仅有5.35M参数的情况下，F1达到0.8204，mIoU达到0.8465。", "conclusion": "LIDAR网络通过创新的模块设计和特征融合策略，成功解决了多模态裂缝分割中计算成本高和特征融合效率低的问题，实现了卓越的像素级分割性能。", "translation": "利用多模态数据以低计算成本实现像素级分割仍然是裂缝分割任务中的一个关键挑战。现有方法缺乏自适应感知和高效交互融合跨模态特征的能力。为了解决这些挑战，我们提出了一种轻量级自适应线索感知视觉Mamba网络（LIDAR），它能有效地感知和整合多模态裂缝场景下不同模态的形态和纹理线索，生成清晰的像素级裂缝分割图。具体来说，LIDAR由一个轻量级自适应线索感知视觉状态空间模块（LacaVSS）和一个轻量级双域动态协作融合模块（LD3CF）组成。LacaVSS通过所提出的掩码引导的高效动态引导扫描策略（EDG-SS）自适应地建模裂缝线索，而LD3CF则利用自适应频域感知器（AFDP）和双池化融合策略有效地捕获跨模态的空间和频域线索。此外，我们设计了一种轻量级动态调制多核卷积（LDMK），以最小的计算开销感知复杂的形态结构，取代了LIDAR中的大部分卷积操作。在三个数据集上的实验表明，我们的方法优于其他最先进（SOTA）的方法。在光场深度数据集上，我们的方法在仅有5.35M参数的情况下，F1达到0.8204，mIoU达到0.8465。代码和数据集可在https://github.com/Karl1109/LIDAR-Mamba获取。", "summary": "该论文提出了一种名为LIDAR的轻量级自适应线索感知视觉Mamba网络，旨在解决多模态裂缝分割中计算成本高和跨模态特征融合效率低的问题。LIDAR包含LacaVSS和LD3CF两个核心模块，分别负责自适应裂缝线索建模和高效跨模态特征融合。通过引入创新的EDG-SS、AFDP和LDMK等策略，LIDAR能够在低参数量下实现像素级裂缝分割，并在多个数据集上取得了超越现有SOTA方法的性能。", "keywords": "多模态分割, 裂缝分割, 视觉Mamba, 自适应融合, 轻量级", "comments": "该论文的创新点在于结合了Mamba架构的优势和自适应机制，针对多模态裂缝分割任务进行了优化。通过引入LacaVSS和LD3CF等模块，实现了对跨模态特征的有效感知和融合，同时通过LDMK降低了计算开销，展现了轻量化和高性能的潜力。其在低参数量下达到SOTA性能，对于实际部署具有重要意义。"}}
{"id": "2507.23015", "title": "Learning to Prune Branches in Modern Tree-Fruit Orchards", "authors": ["Abhinav Jain", "Cindy Grimm", "Stefan Lee"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23015v1", "summary": "Dormant tree pruning is labor-intensive but essential to maintaining modern\nhighly-productive fruit orchards. In this work we present a closed-loop\nvisuomotor controller for robotic pruning. The controller guides the cutter\nthrough a cluttered tree environment to reach a specified cut point and ensures\nthe cutters are perpendicular to the branch. We train the controller using a\nnovel orchard simulation that captures the geometric distribution of branches\nin a target apple orchard configuration. Unlike traditional methods requiring\nfull 3D reconstruction, our controller uses just optical flow images from a\nwrist-mounted camera. We deploy our learned policy in simulation and the\nreal-world for an example V-Trellis envy tree with zero-shot transfer,\nachieving a 30% success rate -- approximately half the performance of an oracle\nplanner.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23015v1", "cate": "cs.RO", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "学习在现代果园中修剪树枝", "tldr": "本文提出了一种用于机器人修剪的闭环视觉运动控制器，该控制器使用光学流图像在模拟和真实世界中进行训练和部署，实现了30%的成功率。", "motivation": "冬季修剪树木是劳动密集型工作，但对于维持现代高产果园至关重要。本研究旨在开发一种机器人解决方案来自动化这一过程。", "method": "提出了一种闭环视觉运动控制器，用于机器人修剪。该控制器引导切割器穿过杂乱的树木环境，到达指定切割点并确保切割器垂直于树枝。控制器使用新颖的果园模拟进行训练，该模拟捕捉了目标苹果园配置中树枝的几何分布。与传统方法不同，该控制器仅使用腕部安装摄像头的光学流图像。", "result": "所学习的策略在模拟和真实世界中部署于V型棚架Envy树上，实现了零样本迁移，成功率为30%，大约是理想规划器性能的一半。", "conclusion": "Not mentioned in abstract", "translation": "冬季修剪树木是劳动密集型工作，但对于维持现代高产果园至关重要。在这项工作中，我们提出了一种用于机器人修剪的闭环视觉运动控制器。该控制器引导切割器穿过杂乱的树木环境，到达指定的切割点，并确保切割器垂直于树枝。我们使用一种新颖的果园模拟训练该控制器，该模拟捕捉了目标苹果园配置中树枝的几何分布。与需要完整3D重建的传统方法不同，我们的控制器仅使用腕部安装摄像头的光学流图像。我们将我们学习到的策略在模拟和现实世界中部署在一个示例性的V型棚架Envy苹果树上，实现了零样本迁移，成功率为30%——大约是理想规划器性能的一半。", "summary": "本文介绍了一种用于机器人修剪的闭环视觉运动控制器，旨在解决现代果园中劳动密集型的树木修剪问题。该控制器利用新颖的果园模拟进行训练，并仅通过腕部摄像头的光学流图像进行导航，无需3D重建。在模拟和真实世界的V型棚架苹果树上进行零样本迁移部署，实现了30%的修剪成功率。", "keywords": "机器人修剪, 光学流, 果园自动化, 视觉运动控制器, 零样本迁移", "comments": "这项工作在自动化果园修剪方面展现了潜力，尤其是在其无需完整3D重建而仅依赖光学流图像的创新方法上。尽管30%的成功率仍有提升空间，但零样本迁移的能力和在真实世界中的部署验证了其可行性，为未来农业机器人研究提供了有价值的探索方向。"}}
{"id": "2507.22930", "title": "Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection", "authors": ["Shalini Jangra", "Suparna De", "Nishanth Sastry", "Saeed Fadaei"], "categories": ["cs.CL", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages, 4 Figures, Accepted in \"The 17th International Conference on Advances in Social Networks Analysis and Mining -ASONAM-2025\"", "url": "http://arxiv.org/abs/2507.22930v1", "summary": "Social platforms such as Reddit have a network of communities of shared\ninterests, with a prevalence of posts and comments from which one can infer\nusers' Personal Information Identifiers (PIIs). While such self-disclosures can\nlead to rewarding social interactions, they pose privacy risks and the threat\nof online harms. Research into the identification and retrieval of such risky\nself-disclosures of PIIs is hampered by the lack of open-source labeled\ndatasets. To foster reproducible research into PII-revealing text detection, we\ndevelop a novel methodology to create synthetic equivalents of PII-revealing\ndata that can be safely shared. Our contributions include creating a taxonomy\nof 19 PII-revealing categories for vulnerable populations and the creation and\nrelease of a synthetic PII-labeled multi-text span dataset generated from 3\ntext generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and\nzephyr-7b-beta, with sequential instruction prompting to resemble the original\nReddit posts. The utility of our methodology to generate this synthetic dataset\nis evaluated with three metrics: First, we require reproducibility equivalence,\ni.e., results from training a model on the synthetic data should be comparable\nto those obtained by training the same models on the original posts. Second, we\nrequire that the synthetic data be unlinkable to the original users, through\ncommon mechanisms such as Google Search. Third, we wish to ensure that the\nsynthetic data be indistinguishable from the original, i.e., trained humans\nshould not be able to tell them apart. We release our dataset and code at\nhttps://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster\nreproducible research into PII privacy risks in online social media.", "comment": "15 pages, 4 Figures, Accepted in \"The 17th International Conference\n  on Advances in Social Networks Analysis and Mining -ASONAM-2025\"", "pdf_url": "http://arxiv.org/pdf/2507.22930v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "保护弱势声音：用于自我披露检测的合成数据集生成", "tldr": "为了解决缺乏可公开访问的个人身份信息（PII）自我披露文本检测数据集的问题，本研究开发了一种新颖的方法，利用大型语言模型生成合成的、可安全共享的PII标注数据集，并评估其在可复现性、不可链接性和不可区分性方面的实用性。", "motivation": "识别和检索个人身份信息（PII）风险性自我披露的研究受到缺乏开源标注数据集的阻碍。", "method": "开发了一种新颖的方法来创建个人身份信息（PII）披露数据的合成等价物，以便安全共享。贡献包括：创建了一个包含19个PII披露类别的分类法，并使用Llama2-7B、Llama3-8B和zephyr-7b-beta这三种大型语言模型（LLMs）通过顺序指令提示生成并发布了一个合成的PII标注多文本跨度数据集，以模拟原始Reddit帖子。该方法通过三个指标进行评估：可复现性等效性（合成数据训练模型的结果应与原始数据可比）、与原始用户不可链接性，以及与原始数据不可区分性。", "result": "本研究创建并发布了一个合成的PII标注多文本跨度数据集及其生成方法，旨在促进PII隐私风险的可复现研究。该数据集通过可复现性、不可链接性和不可区分性三个指标进行了实用性评估。", "conclusion": "研究发布了合成数据集和代码，旨在促进在线社交媒体中个人身份信息（PII）隐私风险的可复现研究。", "translation": "社交平台（如Reddit）拥有共同兴趣的社区网络，其中普遍存在可以推断用户个人身份信息（PII）的帖子和评论。虽然这种自我披露可以带来有益的社交互动，但它们也带来了隐私风险和在线危害的威胁。识别和检索此类风险性PII自我披露的研究因缺乏开源标注数据集而受阻。为了促进PII披露文本检测的可复现研究，我们开发了一种新颖的方法来创建可以安全共享的PII披露数据的合成等价物。我们的贡献包括：为弱势群体创建了一个包含19个PII披露类别的分类法；以及创建并发布了一个合成的PII标注多文本跨度数据集，该数据集由Llama2-7B、Llama3-8B和zephyr-7b-beta三种大型语言模型（LLMs）通过顺序指令提示生成，以模仿原始Reddit帖子。我们通过三个指标评估了我们生成此合成数据集方法的实用性：首先，我们要求可复现性等效性，即在合成数据上训练模型的结果应与在原始帖子数据上训练相同模型获得的结果具有可比性。其次，我们要求合成数据通过Google搜索等常见机制与原始用户不可链接。第三，我们希望确保合成数据与原始数据不可区分，即经过训练的人类不应能够区分它们。我们已在https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/发布了我们的数据集和代码，以促进在线社交媒体中PII隐私风险的可复现研究。", "summary": "本研究旨在解决缺乏用于检测个人身份信息（PII）自我披露的开源标注数据集的问题，该问题阻碍了相关隐私风险研究。为此，作者提出了一种新颖的方法，利用大型语言模型（Llama2-7B、Llama3-8B、zephyr-7b-beta）生成合成的PII标注数据集。该方法包括建立一个包含19个PII类别的分类法，并通过顺序指令提示模拟Reddit帖子的方式生成数据。该合成数据集的实用性通过可复现性、与原始用户不可链接性以及与原始数据不可区分性三个关键指标进行评估。最终，研究发布了数据集和代码，以促进在线社交媒体中PII隐私风险的可复复现研究。", "keywords": "PII, 自我披露, 合成数据, 大语言模型, 隐私", "comments": "这篇论文的创新点在于提出了一个生成合成个人身份信息（PII）披露数据集的方法，有效解决了敏感数据共享和研究的难题。通过利用大型语言模型（LLMs）生成数据，并强调其在可复现性、不可链接性和不可区分性方面的评估，为隐私保护研究提供了宝贵的资源。其对弱势群体的关注和详细的PII分类法也提升了研究的实用价值。该工作的局限性可能在于合成数据能否完全捕获真实世界PII披露的复杂性和细微差别，以及LLM生成偏差的潜在影响。"}}
{"id": "2505.12928", "title": "Minos: Exploiting Cloud Performance Variation with Function-as-a-Service Instance Selection", "authors": ["Trever Schirmer", "Valentin Carl", "Nils Höller", "Tobias Pfandzelter", "David Bermbach"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted for Publication at the 13th IEEE International Conference on Cloud Engineering (IC2E 2025)", "url": "http://arxiv.org/abs/2505.12928v2", "summary": "Serverless Function-as-a-Service (FaaS) is a popular cloud paradigm to\nquickly and cheaply implement complex applications. Because the function\ninstances cloud providers start to execute user code run on shared\ninfrastructure, their performance can vary. From a user perspective, slower\ninstances not only take longer to complete, but also increase cost due to the\npay-per-use model of FaaS services where execution duration is billed with\nmicrosecond accuracy. In this paper, we present Minos, a system to take\nadvantage of this performance variation by intentionally terminating instances\nthat are slow. Fast instances are not terminated, so that they can be re-used\nfor subsequent invocations. One use case for this are data processing and\nmachine learning workflows, which often download files as a first step, during\nwhich Minos can run a short benchmark. Only if the benchmark passes, the main\npart of the function is actually executed. Otherwise, the request is re-queued\nand the instance crashes itself, so that the platform has to assign the request\nto another (potentially faster) instance. In our experiments, this leads to a\nspeedup of up to 13% in the resource intensive part of a data processing\nworkflow, resulting in up to 4% faster overall performance (and consequently 4%\ncheaper prices). Longer and complex workflows lead to increased savings, as the\npool of fast instances is re-used more often. For platforms exhibiting this\nbehavior, users get better performance and save money by wasting more of the\nplatforms resources.", "comment": "Accepted for Publication at the 13th IEEE International Conference on\n  Cloud Engineering (IC2E 2025)", "pdf_url": "http://arxiv.org/pdf/2505.12928v2", "cate": "cs.DC", "date": "2025-05-19", "updated": "2025-07-31", "AI": {"title_translation": "Minos：利用函数即服务实例选择来利用云性能变化", "tldr": "Minos通过终止慢速FaaS实例并重用快速实例来提高性能并降低成本。", "motivation": "由于共享基础设施，函数即服务（FaaS）实例的性能存在差异，较慢的实例不仅完成时间更长，而且由于按使用付费模式导致成本增加。", "method": "本文提出了Minos系统，通过有意终止慢速实例来利用这种性能变化，而快速实例则不被终止以便后续调用重复使用。Minos在函数执行前运行一个简短的基准测试，如果测试未通过，请求会被重新排队，实例会自行崩溃，从而将请求分配给另一个（可能更快）的实例。", "result": "在数据处理工作流的资源密集型部分，Minos实现了高达13%的加速；整体性能提升高达4%，成本降低4%。对于更长、更复杂的工作流，节省的效果更显著。", "conclusion": "Minos通过选择性地利用FaaS实例的性能差异，使用户获得更好的性能并节省资金，即使这会消耗更多平台资源。", "translation": "无服务器函数即服务（FaaS）是一种流行的云范式，可以快速且廉价地实现复杂的应用程序。由于云提供商启动执行用户代码的函数实例运行在共享基础设施上，它们的性能可能会有所不同。从用户的角度来看，较慢的实例不仅需要更长时间才能完成，而且由于FaaS服务的按使用付费模式（执行持续时间以微秒精度计费），还会增加成本。在本文中，我们提出了Minos，一个利用这种性能变化的系统，通过有意终止慢速实例。快速实例不会被终止，因此它们可以被重复用于后续调用。一个用例是数据处理和机器学习工作流，这些工作流通常在第一步下载文件，在此期间Minos可以运行一个简短的基准测试。只有当基准测试通过时，函数的主体部分才会被实际执行。否则，请求会被重新排队，实例会自行崩溃，这样平台就必须将请求分配给另一个（可能更快）的实例。在我们的实验中，这使得数据处理工作流的资源密集型部分的速度提高了高达13%，导致整体性能提高了高达4%（因此价格降低了4%）。更长、更复杂的工作流会带来更多的节省，因为快速实例池被更频繁地重复使用。对于表现出这种行为的平台，用户通过浪费更多的平台资源来获得更好的性能并节省资金。", "summary": "Minos是一个利用FaaS实例性能差异的系统。它通过在执行前运行基准测试来识别和终止慢速实例，并重复使用快速实例。这种方法显著提高了数据处理和机器学习工作流的性能，并降低了成本，尤其是在复杂的应用场景中。", "keywords": "FaaS, 性能优化, 云计算, 实例选择, Minos", "comments": "Minos的创新之处在于其“主动终止慢速实例”的策略，这与传统的负载均衡或资源调度不同，它从用户角度出发，通过“浪费”平台资源来优化用户体验和成本。这种方法对于利用FaaS服务的用户来说具有实际的经济和性能效益，特别是在性能波动较大的云环境中。"}}
{"id": "2507.23359", "title": "Pixel Embedding Method for Tubular Neurite Segmentation", "authors": ["Huayu Fu", "Jiamin Li", "Haozhi Qu", "Xiaolin Hu", "Zengcai Guo"], "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23359v1", "summary": "Automatic segmentation of neuronal topology is critical for handling large\nscale neuroimaging data, as it can greatly accelerate neuron annotation and\nanalysis. However, the intricate morphology of neuronal branches and the\nocclusions among fibers pose significant challenges for deep learning based\nsegmentation. To address these issues, we propose an improved framework: First,\nwe introduce a deep network that outputs pixel level embedding vectors and\ndesign a corresponding loss function, enabling the learned features to\neffectively distinguish different neuronal connections within occluded regions.\nSecond, building on this model, we develop an end to end pipeline that directly\nmaps raw neuronal images to SWC formatted neuron structure trees. Finally,\nrecognizing that existing evaluation metrics fail to fully capture segmentation\naccuracy, we propose a novel topological assessment metric to more\nappropriately quantify the quality of neuron segmentation and reconstruction.\nExperiments on our fMOST imaging dataset demonstrate that, compared to several\nclassical methods, our approach significantly reduces the error rate in\nneuronal topology reconstruction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23359v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "管状神经突触分割的像素嵌入方法", "tldr": "该论文提出了一种新的像素嵌入深度学习框架，用于自动分割神经元拓扑结构，并开发了一种端到端流程以及一种新的拓扑评估指标，实验证明显著降低了神经元拓扑重建的错误率。", "motivation": "处理大规模神经影像数据时，神经元拓扑的自动分割对于加速神经元标注和分析至关重要。然而，神经元分支的复杂形态和纤维间的遮挡给基于深度学习的分割带来了巨大挑战。", "method": "本文提出了一个改进的框架：首先，引入了一个输出像素级嵌入向量的深度网络，并设计了相应的损失函数，以有效区分遮挡区域内的不同神经元连接。其次，在此模型基础上，开发了一个端到端的流程，将原始神经元图像直接映射到SWC格式的神经元结构树。最后，提出了一种新颖的拓扑评估指标，以更准确地量化神经元分割和重建的质量。", "result": "在fMOST成像数据集上的实验表明，与几种经典方法相比，所提出的方法显著降低了神经元拓扑重建的错误率。", "conclusion": "本文提出的像素嵌入方法和端到端流程，结合新的拓扑评估指标，能够有效解决神经元分割中的挑战，并显著提高神经元拓扑重建的准确性。", "translation": "神经元拓扑的自动分割对于处理大规模神经影像数据至关重要，因为它可以极大地加速神经元标注和分析。然而，神经元分支的复杂形态以及纤维间的遮挡给基于深度学习的分割带来了巨大挑战。为了解决这些问题，我们提出了一个改进的框架：首先，我们引入了一个输出像素级嵌入向量的深度网络，并设计了相应的损失函数，使学习到的特征能够有效区分遮挡区域内的不同神经元连接。其次，在此模型基础上，我们开发了一个端到端流程，将原始神经元图像直接映射到SWC格式的神经元结构树。最后，认识到现有评估指标未能完全捕捉分割精度，我们提出了一种新颖的拓扑评估指标，以更恰当地量化神经元分割和重建的质量。我们在fMOST成像数据集上的实验表明，与几种经典方法相比，我们的方法显著降低了神经元拓扑重建的错误率。", "summary": "本研究提出了一种基于像素嵌入的深度学习框架，旨在解决神经元拓扑自动分割中遇到的复杂形态和遮挡问题。该框架包含一个生成像素级嵌入向量的深度网络及相应损失函数，一个将原始图像直接转换为SWC格式神经元结构树的端到端流程，以及一种新的拓扑评估指标。实验结果表明，该方法在神经元拓扑重建方面显著优于传统方法。", "keywords": "神经元分割, 像素嵌入, 神经元拓扑, 深度学习, SWC格式", "comments": "该论文的创新点在于提出了像素级嵌入向量来解决神经元连接在遮挡区域的区分问题，并开发了从原始图像到SWC格式的端到端流程。此外，针对现有评估指标的不足，提出了一种新的拓扑评估指标，这对于更准确地衡量神经元分割和重建质量具有重要意义。这些贡献共同提升了大规模神经影像数据处理的自动化和准确性。"}}
{"id": "2507.16725", "title": "RAVine: Reality-Aligned Evaluation for Agentic Search", "authors": ["Yilong Xu", "Xiang Long", "Zhi Zheng", "Jinhua Gao"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16725v2", "summary": "Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16725v2", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-31", "AI": {"title_translation": "RAVine：面向智能体搜索的真实对齐评估框架", "tldr": "现有智能体搜索评估框架存在现实性偏差、真值噪声和过程忽视问题。本文提出RAVine框架，通过真实查询、可归因真值和迭代过程评估来解决这些问题，并提供基准测试和见解。", "motivation": "现有智能体搜索评估框架未能与智能体搜索目标良好对齐，具体表现为：1) 基准测试中的复杂查询偏离真实用户场景；2) 提取端到端评估的真值时引入噪声，导致细粒度评估失真；3) 多数框架仅关注最终答案质量，忽略智能体搜索固有的迭代过程评估。", "method": "本文提出了RAVine，一个面向智能体LLM（大语言模型）的真实对齐评估框架。RAVine针对更符合用户意图的多点查询和长篇答案，引入了一种可归因的真值构建策略以提高细粒度评估的准确性。此外，RAVine还检查模型在迭代过程中与搜索工具的交互，并考虑效率因素。", "result": "使用RAVine对一系列模型进行了基准测试，并从中得出了一些见解。", "conclusion": "希望RAVine及其得出的见解能有助于推动智能体搜索系统的发展。", "translation": "智能体搜索作为一种更自主、适应性更强的检索增强范式，正在推动智能搜索系统的演进。然而，现有的评估框架未能很好地与智能体搜索的目标对齐。首先，当前基准测试中常用的复杂查询往往偏离真实用户搜索场景。其次，先前的方法在提取端到端评估的真值时倾向于引入噪声，导致细粒度评估的失真。第三，大多数现有框架只关注最终答案的质量，而忽视了智能体搜索固有的迭代过程的评估。为了解决这些局限性，我们提出了RAVine——一个面向智能体LLM（大语言模型）的真实对齐评估框架。RAVine针对更能反映用户意图的多点查询和长篇答案，并引入了一种可归因的真值构建策略，以提高细粒度评估的准确性。此外，RAVine检查模型在迭代过程中与搜索工具的交互，并考虑效率因素。我们使用RAVine对一系列模型进行了基准测试，并从中得出了一些见解，我们希望这些见解将有助于推动智能体搜索系统的发展。代码和数据集可在https://github.com/SwordFaith/RAVine获取。", "summary": "本文提出RAVine，一个针对智能体搜索LLM的真实对齐评估框架，旨在解决现有评估框架在现实性、真值准确性和迭代过程评估方面的不足。RAVine通过使用多点查询、长篇答案、可归因真值构建以及评估模型与搜索工具的迭代交互和效率来更准确地评估智能体搜索系统。研究团队使用RAVine对模型进行基准测试，并获得了有助于未来智能体搜索系统开发的见解。", "keywords": "智能体搜索, 评估框架, RAVine, 真值构建, 迭代过程", "comments": "这篇论文的创新点在于提出了一个更全面、更贴近实际的智能体搜索评估框架RAVine。它解决了现有评估方法中常见的三个关键局限性：非真实查询、真值噪声和忽视迭代过程。通过关注多点查询、长篇答案、可归因真值以及对交互过程和效率的评估，RAVine为智能体搜索的未来发展提供了更可靠的评估工具，有助于推动该领域的技术进步。"}}
{"id": "2507.22303", "title": "CS-SHRED: Enhancing SHRED for Robust Recovery of Spatiotemporal Dynamics", "authors": ["Romulo B. da Silva", "Diego Passos", "Cássio M. Oishi", "J. Nathan Kutz"], "categories": ["cs.LG", "68T07, 35Q35, 94A12", "I.2.6; I.5.4; I.6.3; J.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      30 pages, 7 figures, 13 tables. Code: this https URL", "url": "http://arxiv.org/abs/2507.22303v2", "summary": "We present CS-SHRED, a novel deep learning architecture that integrates\nCompressed Sensing (CS) into a Shallow Recurrent Decoder (SHRED) to reconstruct\nspatiotemporal dynamics from incomplete, compressed, or corrupted data. Our\napproach introduces two key innovations. First, by incorporating CS techniques\ninto the SHRED architecture, our method leverages a batch-based forward\nframework with $\\ell_1$ regularization to robustly recover signals even in\nscenarios with sparse sensor placements, noisy measurements, and incomplete\nsensor acquisitions. Second, an adaptive loss function dynamically combines\nMean Squared Error (MSE) and Mean Absolute Error (MAE) terms with a piecewise\nSignal-to-Noise Ratio (SNR) regularization, which suppresses noise and outliers\nin low-SNR regions while preserving fine-scale features in high-SNR regions.\n  We validate CS-SHRED on challenging problems including viscoelastic fluid\nflows, maximum specific humidity fields, sea surface temperature distributions,\nand rotating turbulent flows. Compared to the traditional SHRED approach,\nCS-SHRED achieves significantly higher reconstruction fidelity -- as\ndemonstrated by improved SSIM and PSNR values, lower normalized errors, and\nenhanced LPIPS scores-thereby providing superior preservation of small-scale\nstructures and increased robustness against noise and outliers.\n  Our results underscore the advantages of the jointly trained CS and SHRED\ndesign architecture which includes an LSTM sequence model for characterizing\nthe temporal evolution with a shallow decoder network (SDN) for modeling the\nhigh-dimensional state space. The SNR-guided adaptive loss function for the\nspatiotemporal data recovery establishes CS-SHRED as a promising tool for a\nwide range of applications in environmental, climatic, and scientific data\nanalyses.", "comment": "30 pages, 7 figures, 13 tables. Code:\n  https://github.com/romulobrito/cs-shred", "pdf_url": "http://arxiv.org/pdf/2507.22303v2", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "CS-SHRED: 增强SHRED以实现时空动力学的鲁棒恢复", "tldr": "CS-SHRED通过结合压缩感知和自适应损失函数，显著提高了从不完整、压缩或损坏数据中重建时空动力学的鲁棒性和精度。", "motivation": "在传感器稀疏、测量噪声大或采集不完整的情况下，从不完整、压缩或损坏数据中重建时空动力学面临挑战。", "method": "提出CS-SHRED，一种将压缩感知（CS）集成到浅层循环解码器（SHRED）中的深度学习架构。它引入了两项关键创新：1. 结合CS技术，采用基于批处理的前向框架与$\\ell_1$正则化，以鲁棒地恢复稀疏传感器、噪声测量和不完整采集情况下的信号。2. 引入自适应损失函数，动态结合均方误差（MSE）和平均绝对误差（MAE）项，并带有分段信噪比（SNR）正则化，以在低SNR区域抑制噪声和异常值，同时在高SNR区域保留精细尺度特征。该架构还包括一个用于表征时间演化的LSTM序列模型和一个用于建模高维状态空间的浅层解码器网络（SDN）。", "result": "CS-SHRED在粘弹性流体、最大比湿度场、海表温度分布和旋转湍流等挑战性问题上进行了验证。与传统SHRED相比，CS-SHRED实现了显著更高的重建保真度（SSIM和PSNR值更高，归一化误差更低，LPIPS分数更高），从而更好地保留了小尺度结构，并增强了对噪声和异常值的鲁棒性。", "conclusion": "联合训练的CS和SHRED设计架构（包括LSTM和SDN）以及SNR引导的自适应损失函数，使CS-SHRED成为环境、气候和科学数据分析中广泛应用的有前景的工具。", "translation": "我们提出了CS-SHRED，这是一种新颖的深度学习架构，它将压缩感知（CS）集成到浅层循环解码器（SHRED）中，以从不完整、压缩或损坏的数据中重建时空动力学。我们的方法引入了两项关键创新。首先，通过将CS技术纳入SHRED架构，我们的方法利用基于批处理的前向框架与$\\ell_1$正则化，即使在传感器稀疏、测量噪声大和传感器采集不完整的情况下也能鲁棒地恢复信号。其次，自适应损失函数动态结合了均方误差（MSE）和平均绝对误差（MAE）项，并带有分段信噪比（SNR）正则化，这在低SNR区域抑制噪声和异常值，同时在高SNR区域保留精细尺度特征。我们在粘弹性流体、最大比湿度场、海表温度分布和旋转湍流等挑战性问题上验证了CS-SHRED。与传统SHRED方法相比，CS-SHRED实现了显著更高的重建保真度——通过改进的SSIM和PSNR值、更低的归一化误差和增强的LPIPS分数来证明——从而更好地保留了小尺度结构，并增强了对噪声和异常值的鲁棒性。我们的结果强调了联合训练的CS和SHRED设计架构的优势，该架构包括用于表征时间演化的LSTM序列模型和用于建模高维状态空间的浅层解码器网络（SDN）。SNR引导的时空数据恢复自适应损失函数将CS-SHRED确立为在环境、气候和科学数据分析中广泛应用的有前景的工具。", "summary": "CS-SHRED是一种创新的深度学习架构，它将压缩感知（CS）技术与浅层循环解码器（SHRED）相结合，旨在从不完整、压缩或受损数据中鲁棒地重建时空动力学。该方法通过引入基于$\\ell_1$正则化的CS前向框架和结合MSE/MAE与SNR正则化的自适应损失函数，有效应对稀疏传感器、噪声测量和数据缺失等挑战。实验证明，CS-SHRED在多种复杂应用中，相比传统SHRED，能显著提高重建精度和对噪声的鲁棒性，更好地保留数据的小尺度结构。", "keywords": "压缩感知, 深度学习, 时空动力学, 数据恢复, 自适应损失函数", "comments": "该论文的创新点在于将压缩感知（CS）与深度学习架构SHRED相结合，并引入了新颖的自适应损失函数，有效提升了从不完整/损坏数据中恢复时空动力学的能力。这种结合增强了模型的鲁棒性，使其在实际应用中更具潜力，尤其是在数据采集受限或存在噪声的环境下。"}}
{"id": "2507.22929", "title": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "authors": ["Xiaoyu Pan", "Yang Bai", "Ke Zou", "Yang Zhou", "Jun Zhou", "Huazhu Fu", "Yih-Chung Tham", "Yong Liu"], "categories": ["cs.CL", "cs.CV", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 figures, 5 tables. submit/6621751", "url": "http://arxiv.org/abs/2507.22929v1", "summary": "Medical Large Language Models (MLLMs) play a crucial role in ophthalmic\ndiagnosis, holding significant potential to address vision-threatening\ndiseases. However, their accuracy is constrained by hallucinations stemming\nfrom limited ophthalmic knowledge, insufficient visual localization and\nreasoning capabilities, and a scarcity of multimodal ophthalmic data, which\ncollectively impede precise lesion detection and disease diagnosis.\nFurthermore, existing medical benchmarks fail to effectively evaluate various\ntypes of hallucinations or provide actionable solutions to mitigate them. To\naddress the above challenges, we introduce EH-Benchmark, a novel ophthalmology\nbenchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'\nhallucinations based on specific tasks and error types into two primary\nclasses: Visual Understanding and Logical Composition, each comprising multiple\nsubclasses. Given that MLLMs predominantly rely on language-based reasoning\nrather than visual processing, we propose an agent-centric, three-phase\nframework, including the Knowledge-Level Retrieval stage, the Task-Level Case\nStudies stage, and the Result-Level Validation stage. Experimental results show\nthat our multi-agent framework significantly mitigates both types of\nhallucinations, enhancing accuracy, interpretability, and reliability. Our\nproject is available at https://github.com/ppxy1/EH-Benchmark.", "comment": "9 figures, 5 tables. submit/6621751", "pdf_url": "http://arxiv.org/pdf/2507.22929v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "EH-Benchmark 眼科幻觉基准与智能体驱动的自上而下可追溯推理工作流", "tldr": "EH-Benchmark是一个新的眼科基准，用于评估医疗大语言模型（MLLMs）中的幻觉。该研究提出了一种智能体驱动的三阶段框架，可以显著减轻幻觉，提高准确性、可解释性和可靠性。", "motivation": "医疗大语言模型（MLLMs）在眼科诊断中具有巨大潜力，但其准确性受限于幻觉，这些幻觉源于眼科知识有限、视觉定位和推理能力不足以及多模态眼科数据稀缺。此外，现有医疗基准未能有效评估各种类型的幻觉或提供可行的缓解方案。", "method": "研究引入了EH-Benchmark，这是一个用于评估MLLMs中幻觉的新型眼科基准。根据特定任务和错误类型，将MLLMs的幻觉分为两大类：视觉理解和逻辑组成，每类包含多个子类。鉴于MLLMs主要依赖基于语言的推理而非视觉处理，研究提出了一个以智能体为中心的三阶段框架，包括知识级检索阶段、任务级案例研究阶段和结果级验证阶段。", "result": "实验结果表明，所提出的多智能体框架显著减轻了两种类型的幻觉，提高了准确性、可解释性和可靠性。", "conclusion": "本研究提出的EH-Benchmark和智能体驱动的三阶段框架能够有效评估并显著减轻医疗大语言模型在眼科诊断中的幻觉问题，从而提升模型的性能和可靠性。", "translation": "医疗大语言模型（MLLMs）在眼科诊断中扮演着关键角色，在解决威胁视力的疾病方面具有巨大潜力。然而，其准确性受到幻觉的限制，这些幻觉源于有限的眼科知识、不足的视觉定位和推理能力以及多模态眼科数据的稀缺，这些共同阻碍了精确的病灶检测和疾病诊断。此外，现有医疗基准未能有效评估各种类型的幻觉或提供可行的解决方案来缓解它们。为了解决上述挑战，我们引入了EH-Benchmark，这是一个新颖的眼科基准，旨在评估MLLMs中的幻觉。我们根据特定任务和错误类型将MLLMs的幻觉分为两大主要类别：视觉理解和逻辑组成，每个类别包含多个子类。鉴于MLLMs主要依赖基于语言的推理而非视觉处理，我们提出了一个以智能体为中心的三阶段框架，包括知识级检索阶段、任务级案例研究阶段和结果级验证阶段。实验结果表明，我们的多智能体框架显著减轻了两种类型的幻觉，增强了准确性、可解释性和可靠性。我们的项目可在 https://github.com/ppxy1/EH-Benchmark 获取。", "summary": "本研究介绍了EH-Benchmark，一个专为评估医疗大语言模型（MLLMs）在眼科领域中幻觉问题的新型基准。该基准将幻觉分为视觉理解和逻辑组成两大类，并进一步细分。针对MLLMs的语言推理特性，论文提出了一种智能体驱动的三阶段框架，旨在通过知识检索、案例研究和结果验证来缓解幻觉。实验证明，该框架能显著提升MLLMs在眼科诊断中的准确性、可解释性和可靠性，有效减轻幻觉问题。", "keywords": "医疗大语言模型, 眼科诊断, 幻觉评估, EH-Benchmark, 智能体驱动框架", "comments": "该论文通过引入EH-Benchmark和智能体驱动的推理框架，创新性地解决了医疗大语言模型在眼科诊断中幻觉问题评估和缓解的痛点。其对幻觉进行细致分类并提出可追溯的推理工作流，对于提升MLLMs在医疗领域的实际应用可靠性具有重要意义。"}}
{"id": "2507.23433", "title": "From Timestamps to Versions: Version AoI in Single- and Multi-Hop Networks", "authors": ["Erfan Delfani", "Nikolaos Pappas"], "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23433v1", "summary": "Timely and informative data dissemination in communication networks is\nessential for enhancing system performance and energy efficiency, as it reduces\nthe transmission of outdated or redundant data. Timeliness metrics, such as Age\nof Information (AoI), effectively quantify data freshness; however, these\nmetrics fail to account for the intrinsic informativeness of the content\nitself. To address this limitation, content-based metrics have been proposed\nthat combine both timeliness and informativeness. Nevertheless, existing\nstudies have predominantly focused on evaluating average metric values, leaving\nthe complete distribution-particularly in multi-hop network scenarios-largely\nunexplored. In this paper, we provide a comprehensive analysis of the\nstationary distribution of the Version Age of Information (VAoI), a\ncontent-based metric, under various scheduling policies, including randomized\nstationary, uniform, and threshold-based policies, with transmission\nconstraints in single-hop and multi-hop networks. We derive closed-form\nexpressions for the stationary distribution and average VAoI under these\nscheduling approaches. Furthermore, for threshold-based scheduling, we\nanalytically determine the optimal threshold value that minimizes VAoI and\nderive the corresponding optimal VAoI in closed form. Numerical evaluations\nverify our analytical findings, providing valuable insights into leveraging\nVAoI in the design of efficient communication networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23433v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "从时间戳到版本：单跳和多跳网络中的版本AoI", "tldr": "本文分析了单跳和多跳网络中版本信息年龄（VAoI）的稳态分布和平均值，推导了闭式表达式和最优阈值。", "motivation": "现有时间度量（如信息年龄AoI）未能考虑内容本身的内在信息量。尽管提出了基于内容的度量，但现有研究主要集中于平均值评估，其完整分布（特别是在多跳网络中）尚未得到充分探索。", "method": "本文在单跳和多跳网络中，对版本信息年龄（VAoI）的稳态分布进行了全面分析，考虑了随机平稳、均匀和基于阈值等多种调度策略及传输约束。推导了这些调度方法下稳态分布和平均VAoI的闭式表达式。对于基于阈值的调度，解析确定了最小化VAoI的最优阈值和相应的最优VAoI闭式解。", "result": "推导了在各种调度策略下，稳态分布和平均VAoI的闭式表达式。对于基于阈值的调度，解析确定了最小化VAoI的最优阈值，并以闭式形式推导了相应的最优VAoI。数值评估验证了分析结果。", "conclusion": "研究结果为在高效通信网络设计中利用VAoI提供了宝贵的见解。", "translation": "通信网络中及时且信息丰富的数据传播对于提高系统性能和能源效率至关重要，因为它减少了过时或冗余数据的传输。信息年龄（AoI）等及时性度量有效地量化了数据的新鲜度；然而，这些度量未能考虑内容本身的内在信息量。为了解决这一限制，已经提出了结合及时性和信息量的基于内容的度量。然而，现有研究主要集中于评估平均度量值，而完整分布——特别是在多跳网络场景中——在很大程度上尚未得到探索。在本文中，我们对版本信息年龄（VAoI）（一种基于内容的度量）在单跳和多跳网络中，在包括随机平稳、均匀和基于阈值策略在内的各种调度策略和传输约束下的稳态分布进行了全面分析。我们推导了这些调度方法下稳态分布和平均VAoI的闭式表达式。此外，对于基于阈值的调度，我们解析确定了最小化VAoI的最优阈值，并以闭式形式推导了相应的最优VAoI。数值评估验证了我们的分析结果，为在高效通信网络设计中利用VAoI提供了宝贵的见解。", "summary": "本文通过分析单跳和多跳网络中基于内容的度量——版本信息年龄（VAoI），解决了传统及时性度量的局限性。论文全面分析了VAoI在各种调度策略下的稳态分布和平均值，并推导了闭式表达式。此外，还解析确定了基于阈值调度中最小化VAoI的最优阈值。研究结果为高效通信网络的设计提供了见解。", "keywords": "版本信息年龄, 信息年龄, 多跳网络, 调度策略, 稳态分布", "comments": "本文通过分析基于内容的及时性度量（VAoI）的完整分布，而非仅仅平均值，特别是在多跳场景中，填补了一个关键空白。闭式表达式和最优阈值的推导为网络工程师提供了重要的理论贡献和实用的设计指导。"}}
{"id": "2507.23443", "title": "Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models", "authors": ["Long Chen", "Emre Oezkaya", "Jan Rottmayer", "Nicolas R. Gauger", "Zebang Shen", "Yinyu Ye"], "categories": ["cs.CE", "cs.LG", "math.OC"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23443v1", "summary": "We introduce an adjoint-based aerodynamic shape optimization framework that\nintegrates a diffusion model trained on existing designs to learn a smooth\nmanifold of aerodynamically viable shapes. This manifold is enforced as an\nequality constraint to the shape optimization problem. Central to our method is\nthe computation of adjoint gradients of the design objectives (e.g., drag and\nlift) with respect to the manifold space. These gradients are derived by first\ncomputing shape derivatives with respect to conventional shape design\nparameters (e.g., Hicks-Henne parameters) and then backpropagating them through\nthe diffusion model to its latent space via automatic differentiation. Our\nframework preserves mathematical rigor and can be integrated into existing\nadjoint-based design workflows with minimal modification. Demonstrated on\nextensive transonic RANS airfoil design cases using off-the-shelf and\ngeneral-purpose nonlinear optimizers, our approach eliminates ad hoc parameter\ntuning and variable scaling, maintains robustness across initialization and\noptimizer choices, and achieves superior aerodynamic performance compared to\nconventional approaches. This work establishes how AI generated priors\nintegrates effectively with adjoint methods to enable robust, high-fidelity\naerodynamic shape optimization through automatic differentiation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23443v1", "cate": "cs.CE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于扩散模型学习流形约束的伴随法气动外形优化", "tldr": "本文提出了一种基于伴随法的气动外形优化框架，通过扩散模型学习气动可行形状的流形约束，从而实现更鲁棒、性能更优越的设计。", "motivation": "传统的空气动力学外形优化方法存在参数随意调整、变量缩放以及鲁棒性不足的问题，本研究旨在通过引入AI模型解决这些限制，提升优化过程的鲁棒性和性能。", "method": "该方法引入了一个基于伴随法的气动外形优化框架，其中包含一个通过现有设计训练的扩散模型，用于学习气动可行形状的光滑流形。该流形被作为等式约束引入优化问题。伴随梯度通过首先计算相对于传统形状设计参数的形状导数，然后通过自动微分将其反向传播到扩散模型的潜在空间来获得。", "result": "该方法在跨音速RANS翼型设计案例中表现出色，消除了临时的参数调整和变量缩放，在初始化和优化器选择方面保持了鲁棒性，并实现了优于传统方法的空气动力学性能。", "conclusion": "人工智能生成的先验知识可以有效地与伴随方法结合，通过自动微分实现鲁棒、高保真度的气动外形优化。", "translation": "我们引入了一个基于伴随法的气动外形优化框架，该框架集成了经过现有设计训练的扩散模型，以学习气动可行形状的光滑流形。该流形被作为等式约束强制应用于外形优化问题。我们方法的核心是计算设计目标（例如阻力和升力）相对于流形空间的伴随梯度。这些梯度首先通过计算相对于传统外形设计参数（例如Hicks-Henne参数）的形状导数，然后通过自动微分将其反向传播到扩散模型的潜在空间中获得。我们的框架保持了数学严谨性，并且可以以最小的修改集成到现有的基于伴随的设计工作流程中。在广泛的跨音速RANS翼型设计案例中，使用现成的通用非线性优化器进行演示，我们的方法消除了临时的参数调整和变量缩放，在初始化和优化器选择方面保持了鲁棒性，并实现了优于传统方法的空气动力学性能。这项工作确立了人工智能生成的先验知识如何有效地与伴随方法结合，通过自动微分实现鲁棒、高保真度的气动外形优化。", "summary": "本文提出了一种创新的伴随法气动外形优化框架，其核心是将扩散模型学习到的气动可行形状流形作为优化问题的等式约束。通过自动微分将形状导数反向传播到扩散模型的潜在空间，从而计算出流形空间中的伴随梯度。该方法在跨音速RANS翼型设计案例中表现出优越性，不仅消除了对参数调整和变量缩放的需求，还在不同初始化和优化器选择下保持了鲁棒性，并取得了比传统方法更好的气动性能。这项工作证明了AI生成的先验知识能有效增强伴随法，实现更鲁棒、高精度的气动外形优化。", "keywords": "气动外形优化, 伴随法, 扩散模型, 流形约束, 自动微分", "comments": "这项工作的创新之处在于将扩散模型（用于学习设计流形或先验知识）与传统的伴随法优化相结合。这种集成解决了复杂设计空间中常见的参数调整和鲁棒性问题，有效利用AI提升了高精度设计的效率和有效性。"}}
{"id": "2507.23223", "title": "Feature Importance across Domains for Improving Non-Intrusive Speech Intelligibility Prediction in Hearing Aids", "authors": ["Ryandhimas E. Zezario", "Sabato M. Siniscalchi", "Fei Chen", "Hsin-Min Wang", "Yu Tsao"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.23223v1", "summary": "Given the critical role of non-intrusive speech intelligibility assessment in\nhearing aids (HA), this paper enhances its performance by introducing Feature\nImportance across Domains (FiDo). We estimate feature importance on spectral\nand time-domain acoustic features as well as latent representations of Whisper.\nImportance weights are calculated per frame, and based on these weights,\nfeatures are projected into new spaces, allowing the model to focus on\nimportant areas early. Next, feature concatenation is performed to combine the\nfeatures before the assessment module processes them. Experimental results show\nthat when FiDo is incorporated into the improved multi-branched speech\nintelligibility model MBI-Net+, RMSE can be reduced by 7.62% (from 26.10 to\n24.11). MBI-Net+ with FiDo also achieves a relative RMSE reduction of 3.98%\ncompared to the best system in the 2023 Clarity Prediction Challenge. These\nresults validate FiDo's effectiveness in enhancing neural speech assessment in\nHA.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.23223v1", "cate": "eess.AS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "跨域特征重要性用于改进助听器中非侵入式语音可懂度预测", "tldr": "本文引入跨域特征重要性（FiDo）方法，通过估计不同领域特征的重要性并进行特征投影和拼接，显著提升了助听器中非侵入式语音可懂度预测的性能。", "motivation": "鉴于助听器中非侵入式语音可懂度评估的关键作用，本文旨在通过引入跨域特征重要性（FiDo）来提升其性能。", "method": "本文引入了跨域特征重要性（FiDo）方法。该方法估计频谱、时域声学特征以及Whisper的潜在表示的特征重要性。重要性权重按帧计算，并基于这些权重将特征投影到新的空间中，使模型能够更早地关注重要区域。随后，在评估模块处理特征之前，执行特征拼接以结合这些特征。", "result": "实验结果表明，将FiDo整合到改进的多分支语音可懂度模型MBI-Net+中时，RMSE可降低7.62%（从26.10降至24.11）。与2023年Clarity预测挑战赛中表现最佳的系统相比，MBI-Net+结合FiDo也实现了3.98%的相对RMSE降低。", "conclusion": "这些结果验证了FiDo在增强助听器中神经语音评估方面的有效性。", "translation": "鉴于助听器（HA）中非侵入式语音可懂度评估的关键作用，本文通过引入跨域特征重要性（FiDo）来提升其性能。我们估计了频谱和时域声学特征以及Whisper的潜在表示的特征重要性。重要性权重按帧计算，并基于这些权重，将特征投影到新的空间中，使模型能够更早地关注重要区域。接下来，在评估模块处理特征之前，执行特征拼接以结合这些特征。实验结果表明，当FiDo被整合到改进的多分支语音可懂度模型MBI-Net+中时，RMSE可以降低7.62%（从26.10降至24.11）。MBI-Net+结合FiDo与2023年Clarity预测挑战赛中表现最佳的系统相比，也实现了3.98%的相对RMSE降低。这些结果验证了FiDo在增强助听器中神经语音评估方面的有效性。", "summary": "本文提出了一种名为跨域特征重要性（FiDo）的新方法，旨在提高助听器中非侵入式语音可懂度预测的性能。FiDo通过在频谱、时域以及Whisper潜在表示上估计特征重要性，并根据重要性权重将特征投影到新空间，然后进行拼接，使模型更有效地关注关键信息。实验证明，FiDo与MBI-Net+结合后，RMSE显著降低，相较于现有最佳系统也有明显提升，验证了其在神经语音评估中的有效性。", "keywords": "特征重要性, 语音可懂度, 助听器, 非侵入式, 深度学习", "comments": "本文的创新点在于引入了“跨域特征重要性（FiDo）”的概念，它通过在不同特征域中识别并利用重要特征，有效提升了助听器中语音可懂度预测模型的性能。这种方法能够引导模型更早地关注关键信息，从而优化了预测精度。实验结果的量化提升（RMSE降低）证明了其重要性和实用价值。"}}
{"id": "2507.23199", "title": "Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model", "authors": ["Kota Takeda"], "categories": ["math.NA", "cs.NA", "math.DS", "62M20, 62F15, 35R30, 93C55, 65C05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23199v1", "summary": "We consider the filtering problem with the partially observed Lorenz 96\nmodel. Although the accuracy of the 3DVar filter applied to this problem has\nbeen established, that of the EnKF has not yet been. This study aims to\nestablish the error bound of a variant of the EnKF, known as the PO method. By\nintroducing the additive inflation and a projection of the background\ncovariance to the observation space, we establish the error bound of the PO\nmethod. A numerical example validates theoretical findings and shows the\npotential to extend the analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23199v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "附加膨胀投影PO方法在部分观测Lorenz 96模型中的误差分析", "tldr": "本研究建立了部分观测Lorenz 96模型中，带有附加膨胀和投影的PO方法（EnKF的一种变体）的误差界限，并通过数值例子验证了理论结果。", "motivation": "尽管3DVar滤波器应用于部分观测Lorenz 96模型时其精度已确定，但集合卡尔曼滤波器（EnKF）的精度尚未确定。本研究旨在建立PO方法（EnKF的一种变体）的误差界限。", "method": "通过引入附加膨胀并将背景协方差投影到观测空间，本文建立了PO方法的误差界限。", "result": "数值示例验证了理论发现，并显示了扩展分析的潜力。", "conclusion": "本文成功建立了带有附加膨胀和投影的PO方法在部分观测Lorenz 96模型中的误差界限。", "translation": "我们考虑了部分观测Lorenz 96模型的滤波问题。尽管3DVar滤波器应用于此问题的精度已经确定，但EnKF的精度尚未确定。本研究旨在建立一种EnKF变体，即PO方法的误差界限。通过引入附加膨胀并将背景协方差投影到观测空间，我们建立了PO方法的误差界限。数值示例验证了理论发现，并显示了扩展分析的潜力。", "summary": "本文针对部分观测Lorenz 96模型的滤波问题，着重解决了集合卡尔曼滤波器（EnKF）变体PO方法的精度未确定的挑战。研究通过引入附加膨胀和将背景协方差投影到观测空间，成功建立了PO方法的误差界限。数值实验验证了理论结果，并表明该分析具有进一步扩展的潜力。", "keywords": "Lorenz 96模型, PO方法, 误差分析, 附加膨胀, 部分观测", "comments": "本文的创新之处在于首次为带有附加膨胀和投影的PO方法在特定模型中建立了误差界限，这为理解和应用该滤波方法提供了重要的理论依据。其重要性在于为数据同化领域中EnKF的一种变体提供了可靠性保证，有助于推动相关研究和实际应用。"}}
{"id": "2503.11806", "title": "Human-in-the-Loop Local Corrections of 3D Scene Layouts via Infilling", "authors": ["Christopher Xie", "Armen Avetisyan", "Henry Howard-Jenkins", "Yawar Siddiqui", "Julian Straub", "Richard Newcombe", "Vasileios Balntas", "Jakob Engel"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2503.11806v2", "summary": "We present a novel human-in-the-loop approach to estimate 3D scene layout\nthat uses human feedback from an egocentric standpoint. We study this approach\nthrough introduction of a novel local correction task, where users identify\nlocal errors and prompt a model to automatically correct them. Building on\nSceneScript, a state-of-the-art framework for 3D scene layout estimation that\nleverages structured language, we propose a solution that structures this\nproblem as \"infilling\", a task studied in natural language processing. We train\na multi-task version of SceneScript that maintains performance on global\npredictions while significantly improving its local correction ability. We\nintegrate this into a human-in-the-loop system, enabling a user to iteratively\nrefine scene layout estimates via a low-friction \"one-click fix'' workflow. Our\nsystem enables the final refined layout to diverge from the training\ndistribution, allowing for more accurate modelling of complex layouts.", "comment": "Project page: https://www.projectaria.com/scenescript/", "pdf_url": "http://arxiv.org/pdf/2503.11806v2", "cate": "cs.CV", "date": "2025-03-14", "updated": "2025-07-30", "AI": {"title_translation": "通过填充进行3D场景布局的人机交互局部校正", "tldr": "本文提出了一种新颖的人机交互方法，通过引入局部校正任务和利用基于SceneScript的“填充”模型，显著提高了3D场景布局的局部修正能力，并允许用户迭代地精炼布局。", "motivation": "现有3D场景布局估计方法在局部误差修正方面存在不足，需要一种能够利用人类反馈进行局部精确校正的方案。", "method": "本文提出了一种新颖的人机交互方法来估计3D场景布局。该方法引入了一个新的局部校正任务，用户识别局部错误并提示模型自动纠正。它构建在SceneScript框架之上，并将问题结构化为“填充”（infilling）任务。研究人员训练了一个多任务版本的SceneScript，并将其集成到一个低摩擦的“一键修复”工作流人机交互系统中。", "result": "该方法在保持全局预测性能的同时，显著提高了局部校正能力。该系统使最终的精炼布局能够偏离训练分布，从而能够更准确地建模复杂布局。", "conclusion": "本文提出的基于人机交互的局部校正系统能够有效地改进3D场景布局估计，使其能够更准确地建模复杂布局，并且最终的布局可以不受训练数据分布的限制。", "translation": "我们提出了一种新颖的人机交互方法来估计3D场景布局，该方法利用来自以自我为中心视角的S人类反馈。我们通过引入一个新的局部校正任务来研究这种方法，用户可以在其中识别局部错误并提示模型自动纠正它们。基于SceneScript（一个利用结构化语言的3D场景布局估计的最新框架），我们提出了一种将此问题结构化为“填充”（infilling）的解决方案，这是一项在自然语言处理中研究的任务。我们训练了一个多任务版本的SceneScript，它在保持全局预测性能的同时，显著提高了其局部校正能力。我们将此集成到一个人机交互系统中，使用户能够通过低摩擦的“一键修复”工作流迭代地改进场景布局估计。我们的系统使最终的精炼布局能够偏离训练分布，从而能够更准确地建模复杂布局。", "summary": "本文介绍了一种新颖的人机交互方法，用于3D场景布局的局部校正。该方法通过引入一个让用户识别并修正局部错误的任务，将问题建模为“填充”任务，并基于SceneScript框架构建。研究人员训练了一个多任务版本的SceneScript，显著提升了局部校正性能，并将其整合到易于操作的“一键修复”人机交互系统中。该系统允许最终布局超越训练数据分布，从而更精确地处理复杂场景布局。", "keywords": "3D场景布局, 人机交互, 局部校正, 填充, SceneScript", "comments": "这项工作的主要创新在于将自然语言处理中的“填充”概念引入到3D场景布局的局部校正中，并结合了人机交互的优势。通过允许用户进行“一键修复”的局部干预，极大地提升了模型处理复杂和多样化场景布局的能力，克服了传统模型可能受限于训练数据分布的局限性，具有重要的实际应用价值。"}}
{"id": "2507.23018", "title": "Data Readiness for Scientific AI at Scale", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, 2 tables", "url": "http://arxiv.org/abs/2507.23018v1", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "comment": "10 pages, 1 figure, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.23018v1", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "科学AI规模化数据准备度", "tldr": "论文探讨了科学AI数据准备度（DRAI）原则如何应用于大规模科学数据集以训练基础模型，并提出了一个两维度的准备度框架来指导基础设施发展，以支持可扩展和可复现的科学AI。", "motivation": "旨在解决大规模科学数据集用于训练基础模型时的数据准备度问题，识别常见预处理模式和领域特定限制，并指导基础设施开发以实现标准化、跨领域、可扩展和可复现的科学AI。", "method": "论文分析了气候、核聚变、生物/健康和材料四个代表性领域的典型工作流，以识别共同的预处理模式和领域特定约束。在此基础上，引入了一个由“数据准备度级别”（从原始到AI就绪）和“数据处理阶段”（从摄取到分片）组成的两维度准备度框架，该框架专为高性能计算（HPC）环境设计，并特别强调了基于Transformer的生成模型。", "result": "识别了跨领域科学数据预处理的常见模式和特定约束；提出了一个两维度的科学数据准备度框架（数据准备度级别和数据处理阶段），该框架适用于HPC环境并强调了Transformer模型；该框架形成了一个概念性成熟度矩阵，用于表征科学数据准备度。", "conclusion": "论文提出的两维度数据准备度框架和概念性成熟度矩阵，为解决大规模科学AI训练中的数据转换挑战提供了指导，旨在推动基础设施发展，以实现标准化、跨领域、可扩展和可复现的科学AI。", "translation": "本文探讨了AI数据准备度（DRAI）原则如何应用于用于训练基础模型的领导规模科学数据集。我们分析了气候、核聚变、生物/健康和材料四个代表性领域的典型工作流，以识别常见的预处理模式和领域特定约束。我们引入了一个由“数据准备度级别”（从原始数据到AI就绪数据）和“数据处理阶段”（从摄取到分片）组成的两维度准备度框架，两者都为高性能计算（HPC）环境量身定制。该框架概述了转换科学数据以进行可扩展AI训练的关键挑战，强调了基于Transformer的生成模型。这些维度共同形成了一个概念性成熟度矩阵，用于表征科学数据准备度，并指导基础设施开发，以实现对可扩展和可复现的科学AI的标准化、跨领域支持。", "summary": "本文研究了大规模科学数据集用于训练基础模型时的AI数据准备度（DRAI）问题。通过分析气候、核聚变等四个领域的典型工作流，识别了数据预处理的通用模式和领域约束。为此，论文提出了一个针对高性能计算环境的两维度数据准备度框架，该框架包含数据准备度级别和数据处理阶段，旨在解决科学数据向可扩展AI训练转换的挑战，并强调了Transformer模型。该框架形成了一个概念性成熟度矩阵，为科学AI基础设施的标准化和跨领域支持提供了指导。", "keywords": "科学AI, 数据准备度, 高性能计算, 基础模型, Transformer模型", "comments": "这篇论文的创新点在于提出了一个针对大规模科学AI数据准备度的两维度框架，并将其应用于高性能计算环境，特别关注了Transformer模型。这对于推动科学领域AI应用的数据标准化和可复现性具有重要意义，有助于解决科学大数据转化为AI可用数据的实际挑战。"}}
{"id": "2507.23029", "title": "A CPFSK Transceiver with Hybrid CSS-DSSS Spreading for LPWAN PHY Communication", "authors": ["Wenkun Wen", "Ruiqi Zhang", "Peiran Wu", "Tierui Min", "Minghua Xia"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      15 pages, 12 figures, and 4 tables. To appear in IEEE Internet of Things Journal", "url": "http://arxiv.org/abs/2507.23029v1", "summary": "Traditional low-power wide-area network (LPWAN) transceivers typically\ncompromise data rates to achieve deep coverage. This paper presents a novel\ntransceiver that achieves high receiver sensitivity and low computational\ncomplexity. At the transmitter, we replace the conventional direct sequence\nspread spectrum (DSSS) preamble with a chirp spread spectrum (CSS) preamble,\nconsisting of a pair of down-chirp and up-chirp signals that are conjugate to\neach other, simplifying packet synchronization. For enhanced coverage, the\npayload incorporates continuous phase frequency shift keying (CPFSK) to\nmaintain a constant envelope and phase continuity, in conjunction with DSSS to\nachieve a high spreading gain. At the receiver, we develop a double-peak\ndetection method to improve synchronization and a non-coherent joint\ndespreading and demodulation scheme that increases receiver sensitivity while\nmaintaining simplicity in implementation. Furthermore, we optimize the preamble\ndetection threshold and spreading sequences for maximum non-coherent receiver\nperformance. The software-defined radio (SDR) prototype, developed using GNU\nRadio and USRP, along with operational snapshots, showcases its practical\nengineering applications. Extensive Monte Carlo simulations and field-test\ntrials demonstrate that our transceiver outperforms traditional ones in terms\nof receiver sensitivity, while also being low in complexity and cost-effective\nfor LPWAN requirements.", "comment": "15 pages, 12 figures, and 4 tables. To appear in IEEE Internet of\n  Things Journal", "pdf_url": "http://arxiv.org/pdf/2507.23029v1", "cate": "cs.IT", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "具有混合CSS-DSSS扩频的CPFSK收发器，用于LPWAN物理层通信", "tldr": "本文提出了一种新型LPWAN收发器，通过混合CSS-DSSS扩频和改进的接收算法，实现了高接收灵敏度和低复杂度，优于传统方案。", "motivation": "传统低功耗广域网（LPWAN）收发器通常以牺牲数据速率为代价来实现深度覆盖。", "method": "在发射端，用Chirp扩频（CSS）前导码取代传统的直接序列扩频（DSSS）前导码，简化数据包同步。有效载荷结合连续相位频移键控（CPFSK）与DSSS，以保持恒定包络、相位连续性并实现高扩频增益。在接收端，开发了双峰检测方法以改进同步，以及非相干联合解扩和解调方案以提高接收灵敏度并保持实现简单性。此外，优化了前导码检测阈值和扩频序列以获得最大的非相干接收器性能。使用GNU Radio和USRP开发了软件定义无线电（SDR）原型。", "result": "软件定义无线电（SDR）原型展示了其实际工程应用。大量的蒙特卡洛仿真和现场测试表明，该收发器在接收灵敏度方面优于传统收发器，同时具有低复杂度和成本效益，符合LPWAN的要求。", "conclusion": "该新型LPWAN收发器通过创新的前导码设计、混合扩频技术和优化的接收算法，在实现高灵敏度、低复杂度和成本效益的同时，满足了LPWAN的通信需求。", "translation": "传统低功耗广域网（LPWAN）收发器通常以牺牲数据速率为代价来实现深度覆盖。本文提出了一种新型收发器，可实现高接收灵敏度和低计算复杂度。在发射端，我们用Chirp扩频（CSS）前导码取代了传统的直接序列扩频（DSSS）前导码，该前导码由一对相互共轭的下行Chirp和上行Chirp信号组成，简化了数据包同步。为了增强覆盖范围，有效载荷结合了连续相位频移键控（CPFSK）以保持恒定的包络和相位连续性，并与DSSS结合以实现高扩频增益。在接收端，我们开发了一种双峰检测方法来改进同步，以及一种非相干联合解扩和解调方案，该方案在保持实现简单性的同时提高了接收灵敏度。此外，我们优化了前导码检测阈值和扩频序列，以实现最大的非相干接收器性能。使用GNU Radio和USRP开发的软件定义无线电（SDR）原型以及操作快照展示了其实际工程应用。大量的蒙特卡洛仿真和现场测试表明，我们的收发器在接收灵敏度方面优于传统收发器，同时具有低复杂度和成本效益，符合LPWAN的要求。", "summary": "本文介绍了一种新型LPWAN收发器，旨在克服传统LPWAN设备在数据速率和覆盖范围之间的折衷。该收发器在发射端采用混合CSS-DSSS扩频技术，用CSS前导码简化同步，并结合CPFSK与DSSS用于有效载荷以增强覆盖和增益。在接收端，它引入了双峰检测和非相干联合解扩解调方案，以提高灵敏度并简化实现。通过优化检测阈值和扩频序列，该收发器在软件定义无线电原型上进行了验证，并通过仿真和现场测试证明其在接收灵敏度、复杂度和成本效益方面均优于传统LPWAN方案。", "keywords": "LPWAN, CPFSK, CSS, DSSS, 收发器, 接收灵敏度", "comments": "本文的创新点在于其混合扩频方案（CSS前导码与DSSS有效载荷）以及接收端的非相干联合解扩解调技术，有效地提升了LPWAN通信的接收灵敏度和同步性能，同时保持了低复杂度和成本效益。这对于需要广覆盖和低功耗的物联网应用具有重要的实际意义。"}}
{"id": "2507.22946", "title": "SmartCourse: A Contextual AI-Powered Course Advising System for Undergraduates", "authors": ["Yixuan Mi", "Yiduo Yu", "Yiyi Zhao"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, 1 table. *Corresponding author: Yixuan Mi. Code: this https URL", "url": "http://arxiv.org/abs/2507.22946v1", "summary": "We present SmartCourse, an integrated course management and AI-driven\nadvising system for undergraduate students (specifically tailored to the\nComputer Science (CPS) major). SmartCourse addresses the limitations of\ntraditional advising tools by integrating transcript and plan information for\nstudent-specific context. The system combines a command-line interface (CLI)\nand a Gradio web GUI for instructors and students, manages user accounts,\ncourse enrollment, grading, and four-year degree plans, and integrates a\nlocally hosted large language model (via Ollama) for personalized course\nrecommendations. It leverages transcript and major plan to offer contextual\nadvice (e.g., prioritizing requirements or retakes). We evaluated the system on\n25 representative advising queries and introduced custom metrics: PlanScore,\nPersonalScore, Lift, and Recall to assess recommendation quality across\ndifferent context conditions. Experiments show that using full context yields\nsubstantially more relevant recommendations than context-omitted modes,\nconfirming the necessity of transcript and plan information for personalized\nacademic advising. SmartCourse thus demonstrates how transcript-aware AI can\nenhance academic planning.", "comment": "7 pages, 6 figures, 1 table. *Corresponding author: Yixuan Mi. Code:\n  https://github.com/EthanYixuanMi/Smartcourse-Contextual-Advising", "pdf_url": "http://arxiv.org/pdf/2507.22946v1", "cate": "cs.CY", "date": "2025-07-26", "updated": "2025-07-26", "AI": {"title_translation": "SmartCourse：一个面向本科生的情境化人工智能驱动的课程咨询系统", "tldr": "SmartCourse是一个情境化人工智能驱动的课程咨询系统，它整合了学生成绩单和学习计划，通过本地大语言模型提供个性化课程推荐，实验证明其在提供相关建议方面优于无情境模式。", "motivation": "现有传统课程咨询工具的局限性，未能整合学生成绩单和学习计划等特定情境信息，导致无法提供个性化的建议。", "method": "SmartCourse是一个集成课程管理和AI驱动咨询系统。它结合了命令行界面（CLI）和Gradio网络图形用户界面（GUI），用于管理用户账户、课程注册、成绩和四年学位计划。系统整合了一个本地托管的大语言模型（通过Ollama）来提供个性化课程推荐，并利用成绩单和专业计划提供情境化建议（例如，优先考虑要求或重修）。系统通过25个代表性咨询查询进行评估，并引入了自定义指标：PlanScore、PersonalScore、Lift和Recall来评估推荐质量。", "result": "实验表明，使用完整的学生情境信息（成绩单和学习计划）比省略情境信息的模式能产生显著更相关的推荐。", "conclusion": "SmartCourse系统证明了结合成绩单信息的AI可以有效增强学术规划。", "translation": "我们提出了SmartCourse，一个面向本科生（专门针对计算机科学（CPS）专业）的集成课程管理和AI驱动的咨询系统。SmartCourse通过整合成绩单和学习计划信息，以获取学生特定情境，从而解决了传统咨询工具的局限性。该系统结合了命令行界面（CLI）和Gradio网络图形用户界面（GUI），供教师和学生使用，管理用户账户、课程注册、成绩和四年学位计划，并集成了一个本地托管的大语言模型（通过Ollama）以实现个性化课程推荐。它利用成绩单和专业计划提供情境化建议（例如，优先考虑要求或重修）。我们使用25个代表性咨询查询对系统进行了评估，并引入了自定义指标：PlanScore、PersonalScore、Lift和Recall来评估不同情境条件下的推荐质量。实验表明，使用完整情境比省略情境模式能产生显著更相关的推荐，证实了成绩单和计划信息对于个性化学术咨询的必要性。因此，SmartCourse展示了成绩单感知型AI如何增强学术规划。", "summary": "SmartCourse是一个为本科生（特别是计算机科学专业）设计的情境化人工智能驱动的课程咨询与管理系统。该系统通过整合学生成绩单和学习计划等特定情境信息，克服了传统咨询工具的不足。它结合了命令行和Web界面，管理课程、成绩和学位计划，并利用本地大语言模型提供个性化课程推荐。通过25个咨询查询和自定义指标的评估显示，利用完整情境信息能显著提高推荐的相关性，证实了成绩单和学习计划信息对于个性化学术咨询的必要性。SmartCourse证明了情境感知AI在增强学术规划方面的有效性。", "keywords": "课程咨询系统, 人工智能, 个性化推荐, 情境感知, 学术规划", "comments": "SmartCourse的创新之处在于其整合了学生成绩单和学习计划等具体情境信息，并通过本地大语言模型提供高度个性化的课程建议，解决了传统咨询工具的局限性。其引入自定义评估指标也增加了研究的严谨性。该系统的重要性在于展示了情境感知AI在提升学生学术规划效率和准确性方面的巨大潜力。"}}
{"id": "2507.23459", "title": "KLAN: Kuaishou Landing-page Adaptive Navigator", "authors": ["Fan Li", "Chang Meng", "Jiaqi Fu", "Shuchang Liu", "Jiashuo Zhang", "Tianke Zhang", "Xueliang Wang", "Xiaoqiang Feng"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      We propose PLPM, a new task for selecting optimal landing pages upon user entry. Our solution, KLAN, models static and dynamic user interests and is successfully deployed on Kuaishou, improving DAU and user lifetime", "url": "http://arxiv.org/abs/2507.23459v1", "summary": "Modern online platforms configure multiple pages to accommodate diverse user\nneeds. This multi-page architecture inherently establishes a two-stage\ninteraction paradigm between the user and the platform: (1) Stage I: page\nnavigation, navigating users to a specific page and (2) Stage II: in-page\ninteraction, where users engage with customized content within the specific\npage. While the majority of research has been focusing on the sequential\nrecommendation task that improves users' feedback in Stage II, there has been\nlittle investigation on how to achieve better page navigation in Stage I. To\nfill this gap, we formally define the task of Personalized Landing Page\nModeling (PLPM) into the field of recommender systems: Given a user upon app\nentry, the goal of PLPM is to proactively select the most suitable landing page\nfrom a set of candidates (e.g., functional tabs, content channels, or\naggregation pages) to optimize the short-term PDR metric and the long-term user\nengagement and satisfaction metrics, while adhering to industrial constraints.\nAdditionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a\nhierarchical solution framework designed to provide personalized landing pages\nunder the formulation of PLPM. KLAN comprises three key components: (1)\nKLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures\nintra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates\nboth components for optimal navigation decisions. Extensive online experiments\nconducted on the Kuaishou platform demonstrate the effectiveness of KLAN,\nobtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and\nuser Lifetime (LT). Our KLAN is ultimately deployed on the online platform at\nfull traffic, serving hundreds of millions of users. To promote further\nresearch in this important area, we will release our dataset and code upon\npaper acceptance.", "comment": "We propose PLPM, a new task for selecting optimal landing pages upon\n  user entry. Our solution, KLAN, models static and dynamic user interests and\n  is successfully deployed on Kuaishou, improving DAU and user lifetime", "pdf_url": "http://arxiv.org/pdf/2507.23459v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "KLAN：快手落地页自适应导航器", "tldr": "论文定义了个性化落地页建模（PLPM）任务，并提出了KLAN，一个用于优化快手平台用户落地页导航的层级解决方案，显著提升了DAU和用户生命周期。", "motivation": "现有研究主要关注用户在特定页面内的交互（第二阶段），但很少关注如何优化用户进入应用时的页面导航（第一阶段）。为了填补这一空白，论文正式定义了个性化落地页建模（PLPM）任务，旨在主动选择最合适的落地页以优化短期和长期用户指标。", "method": "提出KLAN（Kuaishou Landing-page Adaptive Navigator），一个分层解决方案框架，用于在个性化落地页建模（PLPM）的公式下提供个性化落地页。KLAN包含三个关键组件：KLAN-ISP（捕获日间静态页面偏好）、KLAN-IIT（捕获日内动态兴趣转换）和KLAN-AM（自适应整合两者以做出最佳导航决策）。", "result": "在快手平台进行的广泛在线实验表明，KLAN在日活跃用户（DAU）和用户生命周期（LT）方面分别获得了+0.205%和+0.192%的改进。KLAN最终在全流量下部署在在线平台，服务数亿用户。", "conclusion": "KLAN作为一种新颖的个性化落地页导航解决方案，在实际应用中被证明是有效的，显著提升了用户指标（DAU和LT），并已成功部署到大规模在线平台，解决了用户与平台交互的第一阶段痛点。", "translation": "现代在线平台配置多个页面以适应不同的用户需求。这种多页面架构固有地建立了用户与平台之间的两阶段交互范式：(1) 阶段一：页面导航，将用户导航到特定页面；(2) 阶段二：页内交互，用户在特定页面内与定制内容进行互动。虽然大多数研究一直专注于改进第二阶段用户反馈的序列推荐任务，但对于如何在第一阶段实现更好的页面导航却鲜有研究。为了填补这一空白，我们正式将个性化落地页建模（PLPM）任务定义到推荐系统领域：给定一个用户在应用入口处，PLPM的目标是从一组候选页面（例如，功能选项卡、内容频道或聚合页面）中主动选择最合适的落地页，以优化短期PDR指标和长期用户参与度和满意度指标，同时遵守行业约束。此外，我们提出了KLAN（快手落地页自适应导航器），一个旨在在PLPM的公式下提供个性化落地页的分层解决方案框架。KLAN包含三个关键组件：(1) KLAN-ISP捕获日间静态页面偏好；(2) KLAN-IIT捕获日内动态兴趣转换；(3) KLAN-AM自适应整合这两个组件以做出最佳导航决策。在快手平台进行的广泛在线实验证明了KLAN的有效性，在日活跃用户（DAU）和用户生命周期（LT）方面分别获得了+0.205%和+0.192%的改进。我们的KLAN最终在全流量下部署在在线平台，服务数亿用户。为了促进这一重要领域的进一步研究，我们将在论文被接受后发布我们的数据集和代码。", "summary": "这篇论文定义了推荐系统领域中的个性化落地页建模（PLPM）任务，旨在解决用户在应用入口时选择最合适落地页的问题。作者提出了KLAN（Kuaishou Landing-page Adaptive Navigator），一个分层解决方案框架，包含KLAN-ISP、KLAN-IIT和KLAN-AM三个组件，分别处理静态偏好、动态兴趣和自适应整合。在快手平台的在线实验表明，KLAN显著提升了日活跃用户（DAU）和用户生命周期（LT），并已成功部署服务数亿用户。", "keywords": "个性化落地页建模, 推荐系统, KLAN, 用户导航, 快手", "comments": "这篇论文的创新点在于首次将个性化落地页建模作为一个独立的推荐任务提出，并提出了一个实用的分层解决方案KLAN。其重要性体现在解决了用户与平台交互的第一阶段痛点，通过优化初始导航路径显著提升了用户体验和核心业务指标（DAU和LT），并且在真实大规模工业场景中得到了验证和部署。"}}
{"id": "2507.22995", "title": "Balancing Information Preservation and Disentanglement in Self-Supervised Music Representation Learning", "authors": ["Julia Wilkins", "Sivan Ding", "Magdalena Fuentes", "Juan Pablo Bello"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      In proceedings of WASPAA 2025. 4 pages, 4 figures, 1 table", "url": "http://arxiv.org/abs/2507.22995v1", "summary": "Recent advances in self-supervised learning (SSL) methods offer a range of\nstrategies for capturing useful representations from music audio without the\nneed for labeled data. While some techniques focus on preserving comprehensive\ndetails through reconstruction, others favor semantic structure via contrastive\nobjectives. Few works examine the interaction between these paradigms in a\nunified SSL framework. In this work, we propose a multi-view SSL framework for\ndisentangling music audio representations that combines contrastive and\nreconstructive objectives. The architecture is designed to promote both\ninformation fidelity and structured semantics of factors in disentangled\nsubspaces. We perform an extensive evaluation on the design choices of\ncontrastive strategies using music audio representations in a controlled\nsetting. We find that while reconstruction and contrastive strategies exhibit\nconsistent trade-offs, when combined effectively, they complement each other;\nthis enables the disentanglement of music attributes without compromising\ninformation integrity.", "comment": "In proceedings of WASPAA 2025. 4 pages, 4 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.22995v1", "cate": "cs.SD", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "自监督音乐表征学习中信息保留与解耦的平衡", "tldr": "本文提出了一个多视角自监督学习框架，结合对比和重建目标，以在不损害信息完整性的前提下解耦音乐属性。", "motivation": "现有自监督学习方法在音乐音频表征学习中，有些侧重于通过重建保留全面细节，有些则通过对比目标偏向语义结构，但很少有研究在一个统一的自监督学习框架中探讨这两种范式之间的相互作用。", "method": "本文提出了一个多视角自监督学习框架，用于解耦音乐音频表征，该框架结合了对比目标和重建目标。其架构旨在同时促进解耦子空间中信息保真度和因素的结构化语义。", "result": "研究发现，虽然重建和对比策略表现出一致的权衡，但当它们有效结合时，可以相互补充；这使得音乐属性的解耦成为可能，而不会损害信息完整性。", "conclusion": "通过有效结合对比和重建策略，可以在自监督音乐表征学习中实现音乐属性的解耦，同时保持信息完整性。", "translation": "自监督音乐表征学习中信息保留与解耦的平衡\n\n自监督学习（SSL）方法的最新进展提供了一系列策略，可以在无需标记数据的情况下从音乐音频中捕获有用的表征。虽然有些技术侧重于通过重建保留全面的细节，但其他技术则倾向于通过对比目标保留语义结构。很少有研究在一个统一的SSL框架中探讨这些范式之间的相互作用。在这项工作中，我们提出了一个多视角SSL框架，用于解耦音乐音频表征，该框架结合了对比和重建目标。该架构旨在促进解耦子空间中信息保真度和因素的结构化语义。我们在受控设置下，对使用音乐音频表征的对比策略的设计选择进行了广泛评估。我们发现，虽然重建和对比策略表现出一致的权衡，但当它们有效结合时，可以相互补充；这使得音乐属性的解耦成为可能，而不会损害信息完整性。", "summary": "本文提出了一个新颖的多视角自监督学习（SSL）框架，旨在平衡音乐音频表征中的信息保留和属性解耦。该框架创新性地结合了对比学习和重建目标，以期在解耦音乐属性的同时，不牺牲原始信息保真度。通过对不同对比策略的广泛评估，研究表明，虽然对比和重建策略各自存在权衡，但当它们被有效整合时，能够相互补充，从而成功实现音乐属性的解耦，并保持信息完整性。", "keywords": "自监督学习, 音乐表征学习, 信息解耦, 对比学习, 重建学习", "comments": "本文的创新点在于提出了一个统一的多视角自监督学习框架，有效地结合了对比学习和重建学习这两种不同的范式。这对于在音乐表征学习中实现信息完整性与语义解耦之间的平衡具有重要意义，克服了以往方法在这方面存在的局限性。"}}
{"id": "2507.22062", "title": "Meta CLIP 2: A Worldwide Scaling Recipe", "authors": ["Yung-Sung Chuang", "Yang Li", "Dong Wang", "Ching-Feng Yeh", "Kehan Lyu", "Ramya Raghavendra", "James Glass", "Lifei Huang", "Jason Weston", "Luke Zettlemoyer", "Xinlei Chen", "Zhuang Liu", "Saining Xie", "Wen-tau Yih", "Shang-Wen Li", "Hu Xu"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.22062v2", "summary": "Contrastive Language-Image Pretraining (CLIP) is a popular foundation model,\nsupporting from zero-shot classification, retrieval to encoders for multimodal\nlarge language models (MLLMs). Although CLIP is successfully trained on\nbillion-scale image-text pairs from the English world, scaling CLIP's training\nfurther to learning from the worldwide web data is still challenging: (1) no\ncuration method is available to handle data points from non-English world; (2)\nthe English performance from existing multilingual CLIP is worse than its\nEnglish-only counterpart, i.e., \"curse of multilinguality\" that is common in\nLLMs. Here, we present Meta CLIP 2, the first recipe training CLIP from scratch\non worldwide web-scale image-text pairs. To generalize our findings, we conduct\nrigorous ablations with minimal changes that are necessary to address the above\nchallenges and present a recipe enabling mutual benefits from English and\nnon-English world data. In zero-shot ImageNet classification, Meta CLIP 2\nViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%,\nand surprisingly sets new state-of-the-art without system-level confounding\nfactors (e.g., translation, bespoke architecture changes) on multilingual\nbenchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with\n64.3% on image-to-text retrieval.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.22062v2", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-30", "AI": {"title_translation": "Meta CLIP 2：一种全球范围的扩展方案", "tldr": "Meta CLIP 2是首个从零开始在全球范围的网络规模数据上训练CLIP的模型，克服了多语言挑战并实现了最先进的性能。", "motivation": "尽管CLIP已成功在十亿级英语图像-文本对上训练，但将其训练进一步扩展到全球网络数据仍面临挑战：1）缺乏处理非英语数据的策展方法；2）现有多语言CLIP的英语性能低于其纯英语对应版本，即大型语言模型中常见的“多语言诅咒”。", "method": "本文提出了Meta CLIP 2，这是首个从零开始在全球网络规模图像-文本对上训练CLIP的方案。为了推广研究发现，作者进行了严谨的消融实验，只进行了必要的最小改动以解决上述挑战，并提出了一种能够使英语和非英语世界数据互惠互利的方案。", "result": "在零样本ImageNet分类中，Meta CLIP 2 ViT-H/14超越其纯英语对应版本0.8%，超越mSigLIP 0.7%。令人惊讶的是，它在多语言基准测试中（例如CVQA达到57.4%，Babel-ImageNet达到50.2%，XM3600在图像到文本检索中达到64.3%）在没有系统级混杂因素（例如，翻译、定制架构更改）的情况下，创造了新的最先进水平。", "conclusion": "Meta CLIP 2成功地在全球网络规模数据上训练了CLIP，克服了多语言挑战，并在英语和多语言基准测试中均取得了卓越性能，证明了来自不同数据的互惠互利。", "translation": "对比语言-图像预训练（CLIP）是一种流行的基础模型，支持从零样本分类、检索到多模态大型语言模型（MLLMs）的编码器。尽管CLIP已成功在十亿级英语图像-文本对上训练，但将其训练进一步扩展到从全球网络数据中学习仍然具有挑战性：(1) 没有可用的策展方法来处理非英语世界的数据点；(2) 现有多语言CLIP的英语性能不如其纯英语对应版本，即在大型语言模型中常见的“多语言诅咒”。在此，我们提出了Meta CLIP 2，这是首个从零开始在全球网络规模图像-文本对上训练CLIP的方案。为了推广我们的发现，我们进行了严谨的消融实验，只进行了必要的最小改动以解决上述挑战，并提出了一个能够使英语和非英语世界数据互惠互利的方案。在零样本ImageNet分类中，Meta CLIP 2 ViT-H/14超越其纯英语对应版本0.8%，超越mSigLIP 0.7%，并且令人惊讶地在没有系统级混杂因素（例如，翻译、定制架构更改）的情况下，在多语言基准测试中，例如CVQA达到57.4%，Babel-ImageNet达到50.2%，XM3600在图像到文本检索中达到64.3%，创造了新的最先进水平。", "summary": "Meta CLIP 2引入了首个从零开始使用全球网络规模图像-文本数据训练对比语言-图像预训练（CLIP）模型的方法。它通过开发一种利用英语和非英语数据互惠互利的方案，解决了非英语数据策展和“多语言诅咒”的挑战。该模型取得了最先进的成果，在零样本ImageNet分类中超越了纯英语CLIP和mSigLIP，并在各种多语言任务中设定了新的基准。", "keywords": "CLIP, 多语言, 全球数据, 预训练, 视觉-语言", "comments": "这篇论文具有创新性，因为它提供了第一个真正全球规模的CLIP训练方案，克服了多语言视觉-语言模型中长期存在的挑战。它的重要性在于使CLIP能够利用庞大的非英语网络数据，从而可能产生更强大、更全球适用的基础模型。在不进行复杂架构更改的情况下，它既提高了英语性能又在多语言方面表现出色，这是一项重大成就。"}}
{"id": "2507.23045", "title": "A Certifably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration", "authors": ["Emmett Wise", "Pushyami Kaveti", "Qilong Chen", "Wenhao Wang", "Hanumant Singh", "Jonathan Kelly", "David M. Rosen", "Matthew Giamou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      25 pages, 10 figures, submitted to the International Journal of Robotics Research", "url": "http://arxiv.org/abs/2507.23045v1", "summary": "Automatic extrinsic sensor calibration is a fundamental problem for\nmulti-sensor platforms. Reliable and general-purpose solutions should be\ncomputationally efficient, require few assumptions about the structure of the\nsensing environment, and demand little effort from human operators. Since the\nengineering effort required to obtain accurate calibration parameters increases\nwith the number of sensors deployed, robotics researchers have pursued methods\nrequiring few assumptions about the sensing environment and minimal effort from\nhuman operators. In this work, we introduce a fast and certifiably globally\noptimal algorithm for solving a generalized formulation of the\n$\\textit{robot-world and hand-eye calibration}$ (RWHEC) problem. The\nformulation of RWHEC presented is \"generalized\" in that it supports the\nsimultaneous estimation of multiple sensor and target poses, and permits the\nuse of monocular cameras that, alone, are unable to measure the scale of their\nenvironments. In addition to demonstrating our method's superior performance\nover existing solutions, we derive novel identifiability criteria and establish\n$\\textit{a priori}$ guarantees of global optimality for problem instances with\nbounded measurement errors. We also introduce a complementary Lie-algebraic\nlocal solver for RWHEC and compare its performance with our global method and\nprior art. Finally, we provide a free and open-source implementation of our\nalgorithms and experiments.", "comment": "25 pages, 10 figures, submitted to the International Journal of\n  Robotics Research", "pdf_url": "http://arxiv.org/pdf/2507.23045v1", "cate": "cs.RO", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "广义机器人-世界和手眼标定的一种可证明正确的算法", "tldr": "本文提出了一种针对广义机器人-世界和手眼标定（RWHEC）问题的快速且可证明全局最优的算法。该算法支持多传感器和目标姿态的同步估计，并允许使用单目相机，其性能优于现有解决方案，并提供了全局最优性保证。", "motivation": "自动外部传感器标定是多传感器平台的一个基本问题。随着部署传感器数量的增加，获取精确标定参数所需的工程工作量也随之增加。因此，机器人研究人员致力于开发对传感环境假设少且对操作人员要求低的解决方案，以实现计算高效、通用且可靠的标定。", "method": "本文提出了一种快速且可证明全局最优的算法，用于解决广义的机器人-世界和手眼标定（RWHEC）问题。该广义公式支持同时估计多个传感器和目标姿态，并允许使用无法单独测量环境尺度的单目相机。此外，还引入了一个互补的李代数局部求解器，并与全局方法和现有技术进行了性能比较。", "result": "所提出的方法在性能上优于现有解决方案。研究人员推导了新颖的可识别性准则，并为具有有界测量误差的问题实例建立了全局最优性的先验保证。", "conclusion": "本文为广义机器人-世界和手眼标定问题提供了一种快速、可证明全局最优的算法，解决了多传感器平台标定的挑战，并提供了理论保证和开源实现。", "translation": "自动外部传感器标定是多传感器平台的一个基本问题。可靠且通用的解决方案应具备计算效率高、对传感环境结构假设少以及对人工操作要求低的特点。由于获取精确标定参数所需的工程工作量随部署传感器数量的增加而增加，机器人研究人员一直在寻求对传感环境假设少且对人工操作要求最低的方法。在这项工作中，我们引入了一种快速且可证明全局最优的算法，用于解决广义的机器人-世界和手眼标定（RWHEC）问题。所提出的RWHEC公式之所以“广义”，是因为它支持同时估计多个传感器和目标姿态，并允许使用单独无法测量其环境尺度的单目相机。除了展示我们方法优于现有解决方案的卓越性能外，我们还推导了新颖的可识别性准则，并为具有有界测量误差的问题实例建立了全局最优性的先验保证。我们还引入了一个互补的李代数局部求解器，用于RWHEC，并将其性能与我们的全局方法和现有技术进行了比较。最后，我们提供了我们算法和实验的免费开源实现。", "summary": "本论文提出了一种用于解决广义机器人-世界和手眼标定（RWHEC）问题的快速、可证明全局最优的算法，以应对多传感器平台自动外部传感器标定的挑战。该广义公式创新性地支持同时估计多个传感器和目标姿态，并兼容单目相机。实验结果表明，该方法性能优于现有方案，并提供了新颖的可识别性准则和全局最优性保证。此外，论文还引入了一个互补的局部求解器，并提供了开源实现。", "keywords": "机器人-世界标定, 手眼标定, 传感器标定, 全局最优性, 单目相机", "comments": "该论文的关键创新在于提出了一个针对广义RWHEC问题的“可证明全局最优”算法，这在机器人学中对于确保标定结果的鲁棒性和可靠性具有重要意义。其对单目相机和多传感器/目标姿态的支持极大地增强了实际应用价值。同时，推导可识别性准则和提供有界误差下的全局最优性保证，展示了坚实的理论基础。提供开源实现也显著提升了其影响力。"}}
{"id": "2507.22908", "title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "authors": ["Abhishek Sawaika", "Swetang Krishna", "Tushar Tomar", "Durga Pritam Suggisetti", "Aditi Lal", "Tanmaya Shrivastav", "Nouhaila Innan", "Muhammad Shafique"], "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "primary_category": "Subjects:       Computational Finance (q-fin.CP)", "pdf_link": null, "comments": "Comments:      To be published in proceedings of IEEE International Conference on Quantum Computing and Engineering (QCE) 2025", "url": "http://arxiv.org/abs/2507.22908v1", "summary": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data.", "comment": "To be published in proceedings of IEEE International Conference on\n  Quantum Computing and Engineering (QCE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.22908v1", "cate": "q-fin.CP", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "一种用于金融欺诈检测的混合量子增强学习隐私保护联邦框架", "tldr": "该论文提出了一种结合量子增强LSTM和隐私保护技术的联邦学习框架，用于提高金融欺诈检测的准确性，并防御攻击。", "motivation": "数字交易的快速增长导致欺诈活动激增，传统检测方法在金融领域面临挑战。", "method": "该论文引入了一个专门的联邦学习框架，独特地结合了量子增强长短期记忆（LSTM）模型和先进的隐私保护技术。通过将量子层集成到LSTM架构中，并提出了名为“FedRansel”的新方法来防御中毒和推理攻击。", "result": "与传统模型相比，该方法在关键评估指标上实现了约5%的性能提升。与标准差分隐私机制相比，“FedRansel”将模型退化和推理精度降低了4-8%。", "conclusion": "该伪集中式设置与量子LSTM模型增强了欺诈检测的准确性，并加强了敏感金融数据的安全性和保密性。", "translation": "数字交易的快速增长导致欺诈活动激增，给金融部门的传统检测方法带来了挑战。为了解决这个问题，我们引入了一个专门的联邦学习框架，它独特地结合了量子增强长短期记忆（LSTM）模型和先进的隐私保护技术。通过将量子层集成到LSTM架构中，我们的方法能够熟练地捕获复杂的跨交易模式，与传统模型相比，在关键评估指标上实现了约5%的性能提升。我们框架的核心是“FedRansel”，这是一种旨在防御中毒和推理攻击的新颖方法，与标准差分隐私机制相比，它将模型退化和推理精度降低了4-8%。这种带有量子LSTM模型的伪集中式设置，增强了欺诈检测的准确性，并加强了敏感金融数据的安全性和保密性。", "summary": "本研究提出了一种创新的联邦学习框架，旨在解决金融欺诈检测中的挑战。该框架融合了量子增强的LSTM模型与先进的隐私保护技术，特别是引入了“FedRansel”方法来抵御中毒和推理攻击。实验结果表明，与传统方法相比，该框架在性能上提升了约5%，同时通过“FedRansel”将模型退化和推理精度降低了4-8%，显著提升了金融欺诈检测的准确性和数据安全性。", "keywords": "联邦学习, 量子增强学习, 金融欺诈检测, 隐私保护, FedRansel", "comments": "该论文的创新点在于将量子增强学习与联邦学习相结合，并引入了专门的防御机制“FedRansel”来应对联邦学习中的常见攻击。这种混合方法有望在提高欺诈检测精度的同时，有效保护敏感金融数据的隐私。"}}
{"id": "2507.22935", "title": "Trusted Knowledge Extraction for Operations and Maintenance Intelligence", "authors": ["Kathleen Mealey", "Jonathan A. Karr Jr.", "Priscila Saboia Moreira", "Paul R. Brenner", "Charles F. Vardeman II"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22935v1", "summary": "Deriving operational intelligence from organizational data repositories is a\nkey challenge due to the dichotomy of data confidentiality vs data integration\nobjectives, as well as the limitations of Natural Language Processing (NLP)\ntools relative to the specific knowledge structure of domains such as\noperations and maintenance. In this work, we discuss Knowledge Graph\nconstruction and break down the Knowledge Extraction process into its Named\nEntity Recognition, Coreference Resolution, Named Entity Linking, and Relation\nExtraction functional components. We then evaluate sixteen NLP tools in concert\nwith or in comparison to the rapidly advancing capabilities of Large Language\nModels (LLMs). We focus on the operational and maintenance intelligence use\ncase for trusted applications in the aircraft industry. A baseline dataset is\nderived from a rich public domain US Federal Aviation Administration dataset\nfocused on equipment failures or maintenance requirements. We assess the\nzero-shot performance of NLP and LLM tools that can be operated within a\ncontrolled, confidential environment (no data is sent to third parties). Based\non our observation of significant performance limitations, we discuss the\nchallenges related to trusted NLP and LLM tools as well as their Technical\nReadiness Level for wider use in mission-critical industries such as aviation.\nWe conclude with recommendations to enhance trust and provide our open-source\ncurated dataset to support further baseline testing and evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22935v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "运维智能的可信知识提取", "tldr": "本文讨论了在运维领域构建知识图谱的可信知识提取，评估了NLP工具和LLM的零样本性能，发现存在显著性能限制，并提出了增强信任的建议和开源数据集。", "motivation": "从组织数据存储库中获取运营智能是一个关键挑战，原因在于数据保密性与数据集成目标之间的二分法，以及自然语言处理（NLP）工具相对于运维等领域特定知识结构的局限性。", "method": "作者讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取。他们评估了16种NLP工具，并与大型语言模型（LLM）的能力结合或比较，重点关注航空业可信应用中的运维智能用例。使用美国联邦航空管理局的公开数据集作为基线，评估了在受控、保密环境下运行的NLP和LLM工具的零样本性能。", "result": "观察到NLP和LLM工具存在显著的性能限制。", "conclusion": "讨论了可信NLP和LLM工具面临的挑战及其在航空等任务关键型行业中更广泛使用的技术成熟度水平。提出增强信任的建议，并提供开源的整理数据集以支持进一步的基线测试和评估。", "translation": "从组织数据存储库中获取运营智能是一个关键挑战，原因在于数据保密性与数据集成目标之间的二分法，以及自然语言处理（NLP）工具相对于运维等领域特定知识结构的局限性。在这项工作中，我们讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取等功能组件。然后，我们评估了16种NLP工具，并结合或比较了大型语言模型（LLM）的快速发展能力。我们专注于航空业可信应用中的运维智能用例。基线数据集来源于美国联邦航空管理局丰富的公共领域数据集，该数据集侧重于设备故障或维护要求。我们评估了可以在受控、保密环境中运行（不将数据发送给第三方）的NLP和LLM工具的零样本性能。基于我们观察到的显著性能限制，我们讨论了与可信NLP和LLM工具相关的挑战，以及它们在航空等任务关键型行业中更广泛使用的技术成熟度水平。最后，我们提出了增强信任的建议，并提供了我们的开源整理数据集以支持进一步的基线测试和评估。", "summary": "本文探讨了在运维领域从组织数据中提取可信知识的挑战，尤其是在数据保密性和NLP工具局限性方面。研究将知识提取过程细化为命名实体识别、共指消解、命名实体链接和关系提取，并评估了16种传统NLP工具与大型语言模型在航空业运维智能用例中的零样本性能。研究发现现有工具存在显著性能限制，并讨论了可信NLP和LLM工具的挑战及技术成熟度，最终提出增强信任的建议并开源了数据集。", "keywords": "知识提取, 运维智能, 自然语言处理, 大型语言模型, 知识图谱", "comments": "本文的创新点在于将知识提取的挑战置于“可信”环境中，强调了数据保密性在关键行业（如航空）中的重要性。通过评估传统NLP工具和LLM在受控环境下的零样本性能，揭示了当前技术在实际应用中的局限性，并提出了实用的建议和开源数据集，对推动该领域的发展具有重要意义。"}}
{"id": "2507.23771", "title": "Consensus-Driven Active Model Selection", "authors": ["Justin Kay", "Grant Van Horn", "Subhransu Maji", "Daniel Sheldon", "Sara Beery"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Highlight. 16 pages, 8 figures", "url": "http://arxiv.org/abs/2507.23771v1", "summary": "The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda.", "comment": "ICCV 2025 Highlight. 16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.23771v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "共识驱动的主动模型选择", "tldr": "提出了一种名为 CODA 的主动模型选择方法，通过利用模型间的共识和分歧来指导数据标注，显著减少了发现最佳模型所需的标注工作量。", "motivation": "现成的机器学习模型众多，如何为特定数据分析任务选择最佳模型是一个挑战。传统模型选择依赖于耗时且昂贵的验证数据集标注。", "method": "CODA 是一种共识驱动的主动模型选择方法。它在一个概率框架内建模分类器、类别和数据点之间的关系，利用候选模型池中模型间的共识和分歧来指导标签获取过程，并使用贝叶斯推断来更新关于最佳模型的信念。", "result": "CODA 在 26 项基准任务中表现优于现有主动模型选择方法，与现有最佳技术相比，将发现最佳模型所需的标注工作量减少了 70% 以上。", "conclusion": "CODA 有效地解决了模型选择中昂贵的数据标注问题，通过智能地选择要标注的数据点，显著提高了模型选择的效率。", "translation": "现成的机器学习模型的广泛可用性带来了一个挑战：针对特定的数据分析任务，应该从众多可用候选模型中选择哪一个？传统上，模型选择问题通过收集和标注验证数据集来解决——这是一个成本高昂且耗时的过程。我们提出了一种主动模型选择方法，利用候选模型的预测来优先标注那些能够有效区分最佳候选模型的测试数据点。我们的方法 CODA 通过在概率框架内对分类器、类别和数据点之间的关系进行建模，执行共识驱动的主动模型选择。该框架利用候选池中模型之间的共识和分歧来指导标签获取过程，并使用贝叶斯推断来随着收集到更多信息更新关于哪个模型是最佳的信念。我们通过整理 26 项基准任务集合来验证我们的方法，这些任务涵盖了一系列模型选择场景。CODA 显著优于现有的主动模型选择方法，与现有最先进技术相比，将发现最佳模型所需的标注工作量减少了 70% 以上。代码和数据可在 https://github.com/justinkay/coda 获取。", "summary": "该论文提出了一种名为 CODA 的主动模型选择新方法，旨在解决传统模型选择中耗时且昂贵的验证数据标注问题。CODA 利用候选模型间的共识和分歧，在一个概率框架内指导数据点标注，以高效地识别最佳模型。实验结果表明，CODA 在多项基准任务中显著优于现有方法，将发现最佳模型所需的标注努力减少了 70% 以上。", "keywords": "主动模型选择, 共识驱动, 贝叶斯推断, 标注效率, 模型选择", "comments": "这项工作提出了一种新颖的主动学习方法，专注于模型选择而非传统的数据点分类。其创新点在于利用模型间的共识和分歧来驱动标注过程，并通过贝叶斯推断优化选择。显著减少标注成本的成果具有重要的实际应用价值，尤其是在数据标注昂贵的领域。"}}
{"id": "2507.22359", "title": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "authors": ["Qianhong Guo", "Wei Xie", "Xiaofang Cai", "Enze Wang", "Shuoyoucheng Ma", "Kai Chen", "Xiaofeng Wang", "Baosheng Wang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22359v2", "summary": "Although large language models (LLMs) demonstrate remarkable capabilities\nacross various tasks, evaluating their capabilities remains a challenging task.\nExisting evaluation methods suffer from issues such as data contamination,\nblack-box operation, and subjective preference. These issues make it difficult\nto evaluate the LLMs' true capabilities comprehensively. To tackle these\nchallenges, we propose a novel benchmark-free evaluation paradigm,\nLLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,\nand evaluate mutually. This method integrates four key evaluation criteria:\ndynamic, transparent, objective, and professional, which existing evaluation\nmethods cannot satisfy simultaneously. Experiments on eight mainstream LLMs\nacross mathematics and programming verify the advantages of our method in\ndistinguishing LLM performance. Furthermore, our study reveals several novel\nfindings that are difficult for traditional methods to detect, including but\nnot limited to: (1) Gemini demonstrates the highest original and professional\nquestion-design capabilities among others; (2) Some LLMs exhibit\n''memorization-based answering'' by misrecognizing questions as familiar ones\nwith a similar structure; (3) LLM evaluation results demonstrate high\nconsistency (robustness).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22359v2", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "LLM-Crowdsourced: 一种无基准的大语言模型相互评估范式", "tldr": "提出了一种名为LLM-Crowdsourced的无基准评估范式，利用LLM进行问题生成、独立回答和相互评估，以解决现有评估方法的局限性。", "motivation": "现有的大语言模型（LLM）评估方法存在数据污染、黑盒操作和主观偏好等问题，难以全面评估LLM的真实能力。", "method": "提出了一种名为LLM-Crowdsourced的无基准评估范式。该方法利用LLM生成问题、独立回答并相互评估。它整合了动态、透明、客观和专业四项关键评估标准。", "result": "在数学和编程领域的八个主流LLM上进行的实验验证了该方法在区分LLM性能方面的优势。研究还揭示了一些传统方法难以发现的新发现：(1) Gemini在原始和专业问题设计能力方面表现最佳；(2) 一些LLM通过将问题误认为结构相似的熟悉问题而表现出“基于记忆的回答”；(3) LLM评估结果显示出高度一致性（鲁棒性）。", "conclusion": "LLM-Crowdsourced范式有效地解决了现有LLM评估方法的挑战，并提供了更全面、客观和鲁棒的评估结果，揭示了传统方法难以发现的LLM特性。", "translation": "尽管大型语言模型（LLM）在各种任务中表现出卓越的能力，但评估其能力仍然是一项具有挑战性的任务。现有评估方法存在数据污染、黑盒操作和主观偏好等问题。这些问题使得难以全面评估LLM的真实能力。为了解决这些挑战，我们提出了一种新颖的无基准评估范式——LLM-Crowdsourced。它利用LLM生成问题、独立回答并相互评估。该方法整合了现有评估方法无法同时满足的四个关键评估标准：动态、透明、客观和专业。在数学和编程领域的八个主流LLM上进行的实验验证了我们方法在区分LLM性能方面的优势。此外，我们的研究揭示了一些传统方法难以检测到的新发现，包括但不限于：(1) Gemini在原始和专业问题设计能力方面表现出最高水平；(2) 一些LLM通过将问题误识别为结构相似的熟悉问题而表现出“基于记忆的回答”；(3) LLM评估结果表现出高度一致性（鲁棒性）。", "summary": "本文提出了一种名为LLM-Crowdsourced的创新无基准评估范式，旨在解决当前大语言模型评估中存在的局限性，如数据污染和主观性。该方法利用LLM自身进行问题生成、独立作答和相互评估，并集成了动态、透明、客观和专业四项核心评估标准。实验结果表明，该方法能有效区分不同LLM的性能，并揭示了传统方法难以发现的现象，例如Gemini在问题设计上的优势、某些LLM的“记忆式回答”以及评估结果的高度一致性。", "keywords": "LLM评估, 无基准, 相互评估, LLM-Crowdsourced, 大语言模型", "comments": "该论文提出了一种新颖且具有前瞻性的LLM评估方法，通过利用LLM自身的生成和评估能力，有效规避了传统基准测试的局限性，如数据污染和黑盒问题。其创新点在于将LLM作为评估工具和被评估对象，实现了评估过程的动态化、透明化和自洽性。这对于推动LLM的公平、全面评估具有重要意义。揭示的特定LLM行为（如记忆式回答）也为未来LLM研究提供了宝贵的洞察。"}}
{"id": "2507.22498", "title": "Robust Adverse Weather Removal via Spectral-based Spatial Grouping", "authors": ["Yuhwan Jeong", "Yunseo Yang", "Youngho Yoon", "Kuk-Jin Yoon"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted by ICCV25", "url": "http://arxiv.org/abs/2507.22498v2", "summary": "Adverse weather conditions cause diverse and complex degradation patterns,\ndriving the development of All-in-One (AiO) models. However, recent AiO\nsolutions still struggle to capture diverse degradations, since global\nfiltering methods like direct operations on the frequency domain fail to handle\nhighly variable and localized distortions. To address these issue, we propose\nSpectral-based Spatial Grouping Transformer (SSGformer), a novel approach that\nleverages spectral decomposition and group-wise attention for multi-weather\nimage restoration. SSGformer decomposes images into high-frequency edge\nfeatures using conventional edge detection and low-frequency information via\nSingular Value Decomposition. We utilize multi-head linear attention to\neffectively model the relationship between these features. The fused features\nare integrated with the input to generate a grouping-mask that clusters regions\nbased on the spatial similarity and image texture. To fully leverage this mask,\nwe introduce a group-wise attention mechanism, enabling robust adverse weather\nremoval and ensuring consistent performance across diverse weather conditions.\nWe also propose a Spatial Grouping Transformer Block that uses both channel\nattention and spatial attention, effectively balancing feature-wise\nrelationships and spatial dependencies. Extensive experiments show the\nsuperiority of our approach, validating its effectiveness in handling the\nvaried and intricate adverse weather degradations.", "comment": "accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2507.22498v2", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "基于光谱空间分组的鲁棒恶劣天气去除", "tldr": "提出SSGformer，一种利用光谱分解和分组注意力机制的多天气图像恢复方法，有效解决了现有模型在处理复杂天气退化时的不足。", "motivation": "现有的一体化（AiO）模型在处理多样化和复杂的恶劣天气退化模式时表现不佳，因为全局滤波方法（如直接在频域操作）难以处理高度可变和局部化的失真。", "method": "本文提出光谱空间分组Transformer（SSGformer）。SSGformer通过传统边缘检测分解图像为高频边缘特征，并通过奇异值分解（SVD）获取低频信息。它利用多头线性注意力机制建模这些特征之间的关系，并将融合特征与输入集成以生成一个分组掩码，该掩码根据空间相似性和图像纹理对区域进行聚类。为充分利用此掩码，引入了分组注意力机制。此外，还提出了一个空间分组Transformer块，结合了通道注意力和空间注意力，以平衡特征关系和空间依赖性。", "result": "广泛的实验表明，所提出的方法具有优越性，验证了其在处理各种复杂恶劣天气退化方面的有效性。", "conclusion": "SSGformer通过结合光谱分解和创新的分组注意力机制，能够鲁棒地去除恶劣天气影响，并在各种天气条件下保持一致的性能。", "translation": "恶劣天气条件导致多样且复杂的退化模式，推动了一体化（AiO）模型的发展。然而，最近的AiO解决方案仍然难以捕捉多样化的退化，因为像直接在频域操作的全局滤波方法无法处理高度可变和局部化的失真。为了解决这些问题，我们提出了一种名为光谱空间分组Transformer（SSGformer）的新方法，该方法利用光谱分解和分组注意力机制进行多天气图像恢复。SSGformer通过传统的边缘检测将图像分解为高频边缘特征，并通过奇异值分解获取低频信息。我们利用多头线性注意力有效地模拟这些特征之间的关系。融合后的特征与输入集成，生成一个分组掩码，该掩码根据空间相似性和图像纹理对区域进行聚类。为了充分利用这个掩码，我们引入了一种分组注意力机制，实现了鲁棒的恶劣天气去除，并确保在各种天气条件下保持一致的性能。我们还提出了一个空间分组Transformer块，它同时使用通道注意力和空间注意力，有效地平衡了特征关系和空间依赖性。广泛的实验表明我们的方法具有优越性，验证了其在处理各种复杂恶劣天气退化方面的有效性。", "summary": "本文提出SSGformer，一种用于多天气图像恢复的新型Transformer模型，旨在解决现有AiO模型在处理复杂天气退化时的局限性。SSGformer通过光谱分解将图像分为高频和低频信息，并利用多头线性注意力进行特征融合。其核心创新在于生成一个基于空间相似性和纹理的分组掩码，并引入分组注意力机制，以实现鲁棒的恶劣天气去除。此外，一个空间分组Transformer块平衡了通道和空间注意力。实验证明了该方法在处理多样且复杂恶劣天气退化方面的有效性和优越性。", "keywords": "恶劣天气去除, 光谱分解, 空间分组, Transformer, 图像恢复", "comments": "该论文创新性地将光谱分解与空间分组注意力相结合，以应对恶劣天气图像恢复中复杂且局部化的退化问题。其核心思想在于通过将图像分解为不同频率信息并根据空间相似性进行分组处理，从而更精细地捕捉并校正局部失真。这种方法超越了传统的全局滤波，为多天气图像恢复提供了一个更鲁棒和灵活的解决方案。该模型的设计考虑了特征关系和空间依赖性，有望在实际应用中展现出强大的性能。"}}
{"id": "2507.23167", "title": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "authors": ["Jizhou Guo"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23167v1", "summary": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, with different models excelling in distinct domains and specific\nabilities. Effectively combining the predictions of multiple LLMs is crucial\nfor enhancing system robustness and performance. However, existing ensemble\nmethods often rely on simple techniques like voting or logits ensembling, which\noverlook the varying confidence and reliability of models in different\ncontexts. In this work, we propose LENS (Learning ENsemble confidence from\nNeural States), a novel approach that learns to estimate model confidence by\nanalyzing internal representations. For each LLM, we train a lightweight linear\nconfidence predictor that leverages layer-wise hidden states and normalized\nprobabilities as inputs. This allows for more nuanced weighting of model\npredictions based on their context-dependent reliability. Our method does not\nrequire modifying the model parameters and requires negligible additional\ncomputation. Experimental results on multiple-choice and boolean\nquestion-answering tasks demonstrate that LENS outperforms traditional ensemble\nmethods by a substantial margin. Our findings suggest that internal\nrepresentations provide valuable signals for determining model confidence and\ncan be effectively leveraged for ensemble learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23167v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "LENS：从神经状态学习集成置信度以实现多LLM答案集成", "tldr": "LENS是一种新颖的方法，通过分析大型语言模型（LLM）的内部表示来学习估计模型置信度，从而在多LLM答案集成中显著优于传统集成方法。", "motivation": "现有的大型语言模型（LLM）集成方法（如投票或logits集成）忽略了模型在不同上下文中的置信度和可靠性差异，而有效结合多个LLM的预测对于提高系统鲁棒性和性能至关重要。", "method": "本文提出了LENS（Learning ENsemble confidence from Neural States），一种通过分析LLM内部表示来估计模型置信度的新方法。LENS为每个LLM训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这种方法允许根据模型在上下文中的可靠性对其预测进行更细致的加权，且无需修改模型参数，仅需可忽略的额外计算。", "result": "在多项选择和布尔问答任务上的实验结果表明，LENS显著优于传统的集成方法。", "conclusion": "研究结果表明，内部表示为确定模型置信度提供了有价值的信号，并且可以有效地用于集成学习。", "translation": "大型语言模型（LLM）在各种任务中表现出令人印象深刻的性能，不同的模型在不同的领域和特定能力上表现出色。有效结合多个LLM的预测对于增强系统鲁棒性和性能至关重要。然而，现有的集成方法通常依赖于简单的技术，如投票或logits集成，这些方法忽略了模型在不同上下文中的置信度和可靠性差异。在这项工作中，我们提出了LENS（Learning ENsemble confidence from Neural States），一种通过分析内部表示来学习估计模型置信度的新方法。对于每个LLM，我们训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这使得可以根据模型在上下文中的可靠性对其预测进行更细致的加权。我们的方法不需要修改模型参数，并且只需要可忽略的额外计算。在多项选择和布尔问答任务上的实验结果表明，LENS显著优于传统的集成方法。我们的发现表明，内部表示为确定模型置信度提供了有价值的信号，并且可以有效地用于集成学习。", "summary": "LENS（Learning ENsemble confidence from Neural States）是一种新颖的LLM集成方法，旨在解决传统集成技术忽视模型上下文置信度的问题。该方法通过分析LLM的内部表示，为每个模型训练一个轻量级置信度预测器，利用隐藏状态和归一化概率来更精细地加权模型预测。LENS无需修改模型参数且计算开销小。实验证明，LENS在问答任务上显著优于现有集成方法，表明LLM的内部表示是评估模型置信度并进行有效集成学习的关键。", "keywords": "LLM集成, 置信度估计, 神经状态, LENS, 答案集成", "comments": "LENS的创新点在于其利用LLM的内部神经状态来动态评估模型在不同上下文中的置信度，这比传统的简单集成方法（如投票或logits）更为精细和有效。这种方法提升了多LLM系统在鲁棒性和性能上的表现，同时保持了轻量级和高效性，对LLM集成领域具有重要意义。"}}
{"id": "2507.23078", "title": "Experimentally-Driven Analysis of Stability in Connected Vehicle Platooning: Insights and Control Strategies", "authors": ["Niladri Dutta", "Elham Abolfazli", "Themistoklis Charalambous"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23078v1", "summary": "This paper presents the development of a tangible platform for demonstrating\nthe practical implementation of cooperative adaptive cruise control (CACC)\nsystems, an enhancement to the standard adaptive cruise control (ACC) concept\nby means of Vehicle-to-Everything (V2X) communication. It involves a detailed\nexamination of existing longitudinal controllers and their performance in\nhomogeneous vehicle platoons. Moreover, extensive tests are conducted using\nmultiple autonomous experimental vehicle platform topologies to verify the\neffectiveness of the controller. The outcomes from both simulations and field\ntests affirm the substantial benefits of the proposed CACC platooning approach\nin longitudinal vehicle platooning scenarios. This research is crucial due to a\nnotable gap in the existing literature; while numerous studies focus on\nsimulated vehicle platooning systems, there is lack of research demonstrating\nthese controllers on physical vehicle systems or robot platforms. This paper\nseeks to fill this gap by providing a practical demonstration of CACC systems\nin action, showcasing their potential for real-world application in intelligent\ntransportation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23078v1", "cate": "eess.SY", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "联网车辆队列稳定性实验驱动分析：见解与控制策略", "tldr": "本文介绍了一个用于演示合作式自适应巡航控制（CACC）系统实际应用的平台，并通过仿真和实地测试验证了其在纵向车辆队列中的有效性，填补了物理平台研究的空白。", "motivation": "现有文献中，虽然许多研究关注模拟车辆队列系统，但缺乏在物理车辆系统或机器人平台上演示这些控制器的研究。本文旨在通过提供CACC系统实际运行的实践演示来填补这一空白，展示其在智能交通系统中的实际应用潜力。", "method": "论文开发了一个有形平台来演示合作式自适应巡航控制（CACC）系统的实际应用。详细检查了现有的纵向控制器及其在同质车辆队列中的性能。使用多个自主实验车辆平台拓扑进行了广泛测试，并通过仿真和现场测试来验证控制器的有效性。", "result": "仿真和实地测试的结果都证实了所提出的CACC队列方法在纵向车辆队列场景中的显著益处。", "conclusion": "CACC系统在实际应用中具有巨大潜力，能够显著提升智能交通系统的性能，并且通过物理平台验证填补了现有研究的空白。", "translation": "本文介绍了一个有形平台的开发，用于演示合作式自适应巡航控制（CACC）系统的实际实现，该系统通过车联网（V2X）通信对标准自适应巡航控制（ACC）概念进行了增强。它涉及对现有纵向控制器及其在同质车辆队列中性能的详细检查。此外，使用多种自主实验车辆平台拓扑进行了广泛测试，以验证控制器的有效性。仿真和现场测试的结果都证实了所提出的CACC队列方法在纵向车辆队列场景中的显著益处。这项研究至关重要，因为现有文献中存在一个显著的空白；尽管许多研究关注模拟车辆队列系统，但缺乏在物理车辆系统或机器人平台上演示这些控制器的研究。本文旨在通过提供CACC系统实际运行的实践演示来填补这一空白，展示其在智能交通系统中的实际应用潜力。", "summary": "本文开发了一个用于演示合作式自适应巡航控制（CACC）系统的有形平台，该系统利用V2X通信增强了ACC。研究详细评估了纵向控制器在同质车辆队列中的性能，并利用多种实验平台拓扑进行了广泛的仿真和实地测试。结果表明，所提出的CACC队列方法在纵向车辆队列中具有显著优势。这项工作旨在弥补现有研究中缺乏物理平台演示的空白，展示CACC系统在智能交通系统中的实际应用潜力。", "keywords": "合作式自适应巡航控制, 车辆队列, V2X通信, 稳定性分析, 实验平台", "comments": "这项研究的创新点在于其强调了CACC系统在物理平台上的实际演示，而非仅仅停留在模拟层面。这对于推动CACC技术从理论走向实际应用具有重要意义，尤其是在填补了现有文献中关于物理验证的空白方面。其结合仿真和实地测试的方法也增加了研究结果的可信度。"}}
{"id": "2503.05911", "title": "Generalizable Image Repair for Robust Visual Control", "authors": ["Carson Sobolewski", "Zhenjiang Mao", "Kshitij Maruti Vejre", "Ivan Ruchkin"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 2 tables, 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)", "url": "http://arxiv.org/abs/2503.05911v2", "summary": "Vision-based control relies on accurate perception to achieve robustness.\nHowever, image distribution changes caused by sensor noise, adverse weather,\nand dynamic lighting can degrade perception, leading to suboptimal control\ndecisions. Existing approaches, including domain adaptation and adversarial\ntraining, improve robustness but struggle to generalize to unseen corruptions\nwhile introducing computational overhead. To address this challenge, we propose\na real-time image repair module that restores corrupted images before they are\nused by the controller. Our method leverages generative adversarial models,\nspecifically CycleGAN and pix2pix, for image repair. CycleGAN enables unpaired\nimage-to-image translation to adapt to novel corruptions, while pix2pix\nexploits paired image data when available to improve the quality. To ensure\nalignment with control performance, we introduce a control-focused loss\nfunction that prioritizes perceptual consistency in repaired images. We\nevaluated our method in a simulated autonomous racing environment with various\nvisual corruptions. The results show that our approach significantly improves\nperformance compared to baselines, mitigating distribution shift and enhancing\ncontroller reliability.", "comment": "8 pages, 4 figures, 2 tables, 2025 IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS 2025)", "pdf_url": "http://arxiv.org/pdf/2503.05911v2", "cate": "cs.RO", "date": "2025-03-07", "updated": "2025-07-31", "AI": {"title_translation": "可泛化的图像修复实现鲁棒视觉控制", "tldr": "本文提出一种实时的图像修复模块，利用CycleGAN和pix2pix等生成对抗模型，并引入以控制为中心的损失函数，以在控制器使用图像前修复受损图像，从而显著提高视觉控制在各种视觉损坏下的性能和可靠性。", "motivation": "基于视觉的控制系统对感知准确性要求高，但传感器噪声、恶劣天气和动态光照等图像分布变化会降低感知质量，导致控制决策不佳。现有方法（如域适应和对抗训练）虽能提高鲁棒性，但泛化能力不足，且引入了计算开销。", "method": "本文提出一个实时的图像修复模块，在图像被控制器使用前对其进行修复。该方法利用生成对抗模型进行图像修复，具体包括CycleGAN（用于非配对图像到图像的转换，以适应新颖的损坏）和pix2pix（在有配对数据时利用其提高质量）。为确保与控制性能对齐，引入了一个以控制为中心的损失函数，优先考虑修复图像的感知一致性。", "result": "在模拟的自动驾驶赛车环境中对该方法进行了评估，结果显示，与基线方法相比，本文方法显著提高了性能，有效缓解了分布偏移，并增强了控制器的可靠性。", "conclusion": "本文提出的实时图像修复模块，通过利用生成对抗模型和引入以控制为中心的损失函数，能够有效修复受损图像，显著提高基于视觉的控制系统在面对各种视觉损坏时的鲁棒性和可靠性。", "translation": "基于视觉的控制依赖于准确的感知来实现鲁棒性。然而，由传感器噪声、恶劣天气和动态照明引起的图像分布变化会降低感知质量，导致次优的控制决策。现有的方法，包括域适应和对抗训练，虽然提高了鲁棒性，但在泛化到未见过的损坏时表现不佳，同时引入了计算开销。为了解决这一挑战，我们提出了一个实时的图像修复模块，在图像被控制器使用之前对其进行修复。我们的方法利用生成对抗模型，特别是CycleGAN和pix2pix，进行图像修复。CycleGAN实现非配对图像到图像的转换，以适应新颖的损坏，而pix2pix在有配对图像数据时利用其来提高质量。为了确保与控制性能对齐，我们引入了一个以控制为中心的损失函数，优先考虑修复图像中的感知一致性。我们在一个模拟的自动驾驶赛车环境中评估了我们的方法，该环境包含各种视觉损坏。结果表明，我们的方法与基线相比显著提高了性能，缓解了分布偏移并增强了控制器的可靠性。", "summary": "本文提出了一种名为“可泛化的图像修复”的实时模块，旨在解决基于视觉的控制系统中因图像损坏（如噪声、恶劣天气、动态光照）导致的感知下降和控制性能问题。该模块利用CycleGAN和pix2pix等生成对抗网络进行图像修复，其中CycleGAN用于非配对转换以适应新型损坏，pix2pix则利用配对数据提升质量。为优化控制性能，论文引入了以控制为中心的损失函数，强调修复图像的感知一致性。在模拟自动驾驶赛车环境中的评估表明，该方法显著优于基线，有效减轻了分布偏移并提高了控制器可靠性。", "keywords": "图像修复, 鲁棒视觉控制, 生成对抗网络, 分布偏移, 实时性", "comments": "该论文提出了一种新颖且实用的方法来解决视觉控制中的鲁棒性问题，通过在感知前端进行图像修复，而非传统地在控制策略层面进行调整。其创新点在于结合了生成对抗网络（CycleGAN和pix2pix）进行图像修复，并特别设计了以控制性能为导向的损失函数，确保修复效果与实际控制需求高度契合。实时性是其重要优势，使其在实际应用中具有潜力。该方法有望在自动驾驶、机器人等领域提升视觉系统的可靠性。"}}
{"id": "2507.23373", "title": "Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation", "authors": ["Haoran Chen", "Zexiao Wang", "Haidong Cao", "Zuxuan Wu", "Yu-Gang Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23373v1", "summary": "Large Vision-Language Models like CLIP have become a powerful foundation for\nUnsupervised Domain Adaptation due to their strong zero-shot generalization.\nState-of-the-art methods typically leverage CLIP to generate pseudo-labels for\nthe target domain, then fine-tune the model to learn domain-invariant features.\nHowever, these methods attempt to align source and target domains using all\npseudo-labeled data simultaneously. This one-shot alignment struggles with\nnoisy, hard-to-classify samples, leading to error propagation and suboptimal\nfeature learning. The problem is even more amplified in the multi-source\nscenario, where diverse domain gaps and varying noise levels across multiple\nsource domains further destabilize the alignment process. To address this\nissue, in this work, we propose a progressive alignment strategy for adapting\nCLIP to unlabeled downstream task. Our method begins by training the model on a\nhigh-confidence subset of target samples, allowing it to first learn a\nwell-aligned representation from the most reliable data. As training\nprogresses, it gradually incorporates more challenging samples, guiding the\nmodel to refine its understanding without being overwhelmed by initial label\nnoise. This progressive approach effectively mitigates confirmation bias and\npromotes a more robust convergence, allowing for the learning of genuinely\ndomain-invariant features. We name our approach MP^2A and test it on three\npopular UDA benchmarks, namely ImageCLEF, Office-Home, and the most challenging\nDomainNet. Experiments showcase that MP^2A achieves state-of-the-art\nperformance when compared with most recent CLIP-based MS-UDA approaches,\ndemonstrating the effectiveness of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23373v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多提示渐进对齐用于多源无监督域适应", "tldr": "本文提出MP^2A，一种用于多源无监督域适应的渐进对齐策略，通过逐步整合样本，解决了现有方法在噪声样本上的问题，并在CLIP基础上取得了最先进的性能。", "motivation": "现有基于CLIP的无监督域适应方法在处理噪声大、难以分类的样本时表现不佳，因为它们采用一次性对齐策略，导致误差传播和次优特征学习。在多源场景中，由于域间隙多样和噪声水平不同，这个问题更加严重。", "method": "本文提出MP^2A（Multi-Prompt Progressive Alignment）方法。该方法首先在目标域高置信度子集上训练模型，学习良好对齐的表示。然后，随着训练的进行，逐步引入更具挑战性的样本，引导模型细化理解，同时避免初始标签噪声的干扰。这种渐进方法有效缓解了确认偏差，促进了更鲁棒的收敛，从而学习到真正的域不变特征。", "result": "MP^2A在三个流行的UDA基准测试（ImageCLEF、Office-Home和最具挑战性的DomainNet）上进行了测试。实验结果表明，与最近基于CLIP的MS-UDA方法相比，MP^2A实现了最先进的性能，证明了该方法的有效性。", "conclusion": "本文提出的渐进对齐策略（MP^2A）有效地解决了多源无监督域适应中噪声样本带来的挑战，实现了鲁棒的域不变特征学习，并取得了卓越的性能。", "translation": "大型视觉-语言模型（如CLIP）因其强大的零样本泛化能力，已成为无监督域适应（UDA）的强大基础。最先进的方法通常利用CLIP为目标域生成伪标签，然后微调模型以学习域不变特征。然而，这些方法试图同时使用所有伪标签数据来对齐源域和目标域。这种一次性对齐策略难以处理噪声大、难以分类的样本，导致误差传播和次优特征学习。在多源场景中，由于多样化的域间隙和多个源域中不同的噪声水平，这个问题甚至被进一步放大，从而使对齐过程更加不稳定。为了解决这个问题，在这项工作中，我们提出了一种渐进对齐策略，用于将CLIP适应到未标记的下游任务。我们的方法首先在目标样本的高置信度子集上训练模型，使其能够首先从最可靠的数据中学习到良好对齐的表示。随着训练的进行，它逐渐整合更具挑战性的样本，引导模型在不被初始标签噪声淹没的情况下完善其理解。这种渐进方法有效地缓解了确认偏差，并促进了更鲁棒的收敛，从而学习到真正的域不变特征。我们将我们的方法命名为MP^2A，并在三个流行的UDA基准测试（即ImageCLEF、Office-Home和最具挑战性的DomainNet）上对其进行了测试。实验表明，与最近基于CLIP的MS-UDA方法相比，MP^2A取得了最先进的性能，证明了我们方法的有效性。", "summary": "本文提出了一种名为MP^2A（Multi-Prompt Progressive Alignment）的新型多提示渐进对齐策略，用于基于CLIP的多源无监督域适应（MS-UDA）。针对现有方法在处理噪声伪标签时的一次性对齐局限性，MP^2A通过首先在高置信度目标样本上训练模型，然后逐步引入更具挑战性的样本，从而有效缓解确认偏差并促进更鲁棒的收敛。实验结果在ImageCLEF、Office-Home和DomainNet等基准测试上验证了MP^2A的有效性，并展示其优于现有基于CLIP的MS-UDA方法的最新性能。", "keywords": "无监督域适应, CLIP, 渐进对齐, 多源, 伪标签", "comments": "该论文的创新点在于其提出的渐进对齐策略，它有效地解决了现有一次性对齐方法在处理多源无监督域适应中存在的噪声伪标签和误差传播问题。通过从高置信度样本开始逐步引入挑战性样本，该方法显著提高了模型在复杂多源环境下的鲁棒性和域不变特征学习能力，具有重要的实践意义。"}}
{"id": "2408.05177", "title": "Coarse Graining with Neural Operators for Simulating Chaotic Systems", "authors": ["Chuwei Wang", "Julius Berner", "Zongyi Li", "Di Zhou", "Jiayun Wang", "Jane Bae", "Anima Anandkumar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.05177v5", "summary": "Accurately predicting the long-term behavior of chaotic systems is crucial\nfor various applications such as climate modeling. However, achieving such\npredictions typically requires iterative computations over a dense\nspatiotemporal grid to account for the unstable nature of chaotic systems,\nwhich is expensive and impractical in many real-world situations. An\nalternative approach to such a full-resolved simulation is using a coarse grid\nand then correcting its errors through a \\textit{closure model}, which\napproximates the overall information from fine scales not captured in the\ncoarse-grid simulation. Recently, ML approaches have been used for closure\nmodeling, but they typically require a large number of training samples from\nexpensive fully-resolved simulations (FRS). In this work, we prove an even more\nfundamental limitation, i.e., the standard approach to learning closure models\nsuffers from a large approximation error for generic problems, no matter how\nlarge the model is, and it stems from the non-uniqueness of the mapping. We\npropose an alternative end-to-end learning approach using a physics-informed\nneural operator (PINO) that overcomes this limitation by not using a closure\nmodel or a coarse-grid solver. We first train the PINO model on data from a\ncoarse-grid solver and then fine-tune it with (a small amount of) FRS and\nphysics-based losses on a fine grid. The discretization-free nature of neural\noperators means that they do not suffer from the restriction of a coarse grid\nthat closure models face, and they can provably approximate the long-term\nstatistics of chaotic systems. In our experiments, our PINO model achieves a\n330x speedup compared to FRS with a relative error $\\sim 10\\%$. In contrast,\nthe closure model coupled with a coarse-grid solver is $60$x slower than PINO\nwhile having a much higher error $\\sim186\\%$ when the closure model is trained\non the same FRS dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.05177v5", "cate": "cs.LG", "date": "2024-08-09", "updated": "2025-07-30", "AI": {"title_translation": "使用神经算子进行粗粒化以模拟混沌系统", "tldr": "本文提出了一种基于物理信息神经算子（PINO）的端到端学习方法，用于模拟混沌系统，克服了传统闭合模型在逼近误差上的限制，实现了显著的速度提升和更低的误差。", "motivation": "准确预测混沌系统的长期行为对于气候建模等应用至关重要，但传统方法（如全分辨率模拟）计算成本高昂且不切实际。替代方法是使用粗网格结合闭合模型，但现有的机器学习闭合模型需要大量昂贵的训练样本，且存在固有的近似误差和映射非唯一性问题。", "method": "本文提出了一种端到端学习方法，使用物理信息神经算子（PINO）。该方法不使用闭合模型或粗网格求解器。首先在粗网格求解器的数据上训练PINO模型，然后使用少量全分辨率模拟（FRS）数据和物理损失在细网格上进行微调。神经算子的无离散化特性使其不受粗网格限制，并能近似混沌系统的长期统计数据。", "result": "实验中，PINO模型与全分辨率模拟（FRS）相比实现了330倍的速度提升，相对误差约为10%。相比之下，与粗网格求解器耦合的闭合模型比PINO慢60倍，且在相同FRS数据集上训练时误差高达约186%。", "conclusion": "本文证明了标准学习闭合模型存在固有的近似误差限制，并提出了一种基于物理信息神经算子（PINO）的端到端学习方法，该方法通过不使用闭合模型或粗网格求解器，有效地克服了这一限制，并在模拟混沌系统方面表现出显著的效率和准确性提升。", "translation": "准确预测混沌系统的长期行为对于气候建模等各种应用至关重要。然而，实现这种预测通常需要对密集的时空网格进行迭代计算，以解释混沌系统的不稳定性质，这在许多实际情况中成本高昂且不切实际。这种全分辨率模拟的替代方法是使用粗网格，然后通过“闭合模型”纠正其误差，该模型近似粗网格模拟中未捕获的精细尺度整体信息。最近，机器学习方法已被用于闭合建模，但它们通常需要大量来自昂贵的全分辨率模拟（FRS）的训练样本。在这项工作中，我们证明了一个更基本的限制，即学习闭合模型的标准方法对于一般问题存在很大的近似误差，无论模型有多大，这源于映射的非唯一性。我们提出了一种替代的端到端学习方法，使用物理信息神经算子（PINO），通过不使用闭合模型或粗网格求解器来克服这一限制。我们首先在粗网格求解器的数据上训练PINO模型，然后使用（少量）FRS和细网格上的基于物理的损失对其进行微调。神经算子的无离散化性质意味着它们不受闭合模型面临的粗网格限制，并且它们可以证明地近似混沌系统的长期统计数据。在我们的实验中，我们的PINO模型与FRS相比实现了330倍的速度提升，相对误差约为10%。相比之下，与粗网格求解器耦合的闭合模型比PINO慢60倍，而当闭合模型在相同的FRS数据集上训练时，其误差高达约186%。", "summary": "本文针对混沌系统长期行为预测中全分辨率模拟计算成本高昂和传统闭合模型存在固有近似误差的问题，提出了一种创新的端到端学习方法——物理信息神经算子（PINO）。该方法通过避免使用闭合模型和粗网格求解器，并结合粗网格数据预训练和少量全分辨率数据及物理损失微调的方式，有效克服了现有方法的局限性。实验结果表明，PINO模型在保持低误差的同时，实现了比全分辨率模拟高330倍的速度提升，并且显著优于传统的闭合模型。", "keywords": "混沌系统, 神经算子, 粗粒化, 闭合模型, 物理信息神经网络", "comments": "该论文的创新点在于揭示了传统闭合模型学习的根本限制（映射非唯一性导致的近似误差），并提出了一种全新的、基于物理信息神经算子（PINO）的端到端学习范式。这种方法不仅规避了闭合模型的缺点，而且通过神经算子的无离散化特性，能够更好地捕捉混沌系统的长期统计行为。其在速度和精度上的显著提升，对于气候建模等需要高效、准确模拟混沌系统的应用具有重要意义。"}}
{"id": "2507.22633", "title": "H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity", "authors": ["Wei Guo", "Siyuan Lu", "Yiqi Tong", "Zhaojun Hu", "Fuzhen Zhuang", "Xiao Zhang", "Tao Fan", "Jin Dong"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22633v2", "summary": "Different from existing federated fine-tuning (FFT) methods for foundation\nmodels, hybrid heterogeneous federated fine-tuning (HHFFT) is an under-explored\nscenario where clients exhibit double heterogeneity in model architectures and\ndownstream tasks. This hybrid heterogeneity introduces two significant\nchallenges: 1) heterogeneous matrix aggregation, where clients adopt different\nlarge-scale foundation models based on their task requirements and resource\nlimitations, leading to dimensional mismatches during LoRA parameter\naggregation; and 2) multi-task knowledge interference, where local shared\nparameters, trained with both task-shared and task-specific knowledge, cannot\nensure only task-shared knowledge is transferred between clients. To address\nthese challenges, we propose H2Tune, a federated foundation model fine-tuning\nwith hybrid heterogeneity. Our framework H2Tune consists of three key\ncomponents: (i) sparsified triple matrix decomposition to align hidden\ndimensions across clients through constructing rank-consistent middle matrices,\nwith adaptive sparsification based on client resources; (ii) relation-guided\nmatrix layer alignment to handle heterogeneous layer structures and\nrepresentation capabilities; and (iii) alternating task-knowledge\ndisentanglement mechanism to decouple shared and specific knowledge of local\nmodel parameters through alternating optimization. Theoretical analysis proves\na convergence rate of O(1/\\sqrt{T}). Extensive experiments show our method\nachieves up to 15.4% accuracy improvement compared to state-of-the-art\nbaselines. Our code is available at\nhttps://anonymous.4open.science/r/H2Tune-1407.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22633v2", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "H2Tune：混合异构联邦基础模型微调", "tldr": "H2Tune提出了一种解决联邦基础模型微调中模型架构和下游任务双重异构性挑战的方法，通过稀疏三矩阵分解、关系引导矩阵层对齐和交替任务知识解耦机制，显著提高了准确性。", "motivation": "现有联邦微调（FFT）方法未能充分探索混合异构联邦微调（HHFFT）场景，即客户端在模型架构和下游任务上都存在双重异构性。这带来了两个主要挑战：1) 异构矩阵聚合，导致LoRA参数聚合时维度不匹配；2) 多任务知识干扰，无法确保只在客户端之间传输任务共享知识。", "method": "本文提出了H2Tune框架，包含三个关键组件：(i) 稀疏三矩阵分解，通过构建秩一致的中间矩阵来对齐隐藏维度，并根据客户端资源进行自适应稀疏化；(ii) 关系引导矩阵层对齐，处理异构层结构和表示能力；(iii) 交替任务知识解耦机制，通过交替优化解耦局部模型参数的共享和特定知识。", "result": "理论分析证明收敛率为O(1/√T)。实验结果显示，与现有最先进的基线方法相比，H2Tune的准确率提高了高达15.4%。", "conclusion": "H2Tune有效解决了联邦基础模型微调中混合异构带来的挑战，显著提升了性能，并提供了理论收敛性保证。", "translation": "与现有针对基础模型的联邦微调（FFT）方法不同，混合异构联邦微调（HHFFT）是一个尚未充分探索的场景，其中客户端在模型架构和下游任务上都表现出双重异构性。这种混合异构性引入了两个重大挑战：1）异构矩阵聚合，即客户端根据其任务需求和资源限制采用不同的H2Tune大规模基础模型，导致LoRA参数聚合期间的维度不匹配；2）多任务知识干扰，即通过任务共享和任务特定知识训练的局部共享参数无法确保仅在客户端之间传输任务共享知识。为了应对这些挑战，我们提出了H2Tune，一种具有混合异构性的联邦基础模型微调方法。我们的H2Tune框架由三个关键组件组成：（i）稀疏三矩阵分解，通过构建秩一致的中间矩阵来对齐客户端之间的隐藏维度，并根据客户端资源进行自适应稀疏化；（ii）关系引导矩阵层对齐，用于处理异构层结构和表示能力；（iii）交替任务知识解耦机制，通过交替优化来解耦局部模型参数的共享和特定知识。理论分析证明了O(1/√T)的收敛速度。广泛的实验表明，与现有最先进的基线方法相比，我们的方法实现了高达15.4%的准确率提升。我们的代码可在https://anonymous.4open.science/r/H2Tune-1407获取。", "summary": "本文提出H2Tune，一种解决联邦基础模型微调中混合异构性挑战的新框架。针对客户端在模型架构和下游任务上的双重异构性，H2Tune设计了稀疏三矩阵分解、关系引导矩阵层对齐和交替任务知识解耦机制，以应对维度不匹配和多任务知识干扰问题。理论分析证明了其收敛性，并通过实验验证了其相比现有方法在准确率上的显著提升。", "keywords": "联邦学习, 基础模型, 微调, 混合异构性, 知识解耦", "comments": "H2Tune的创新之处在于其首次明确提出了混合异构联邦微调（HHFFT）的概念，并针对其引入的两大挑战——异构矩阵聚合和多任务知识干扰——提出了系统性的解决方案。通过结合矩阵分解、层对齐和知识解耦，该方法有效地处理了模型架构和任务类型的双重异构性，这在实际应用中具有重要意义。高达15.4%的准确率提升表明了其方法的有效性。"}}
{"id": "2507.23067", "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23067v1", "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23067v1", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "FairReason: 平衡多模态大语言模型中的推理能力与社会偏见", "tldr": "研究发现，在多模态大语言模型中，通过特定比例的去偏见和推理样本（约1:4），并结合强化学习，可以在显著降低社会偏见的同时，有效保持推理准确性。", "motivation": "尽管多模态大语言模型（MLLMs）在提高推理能力方面取得了进展，但其输出常带有明显的社会偏见。目前尚不清楚推理能力提升与偏见缓解之间如何相互作用，以及两者是否存在固有的权衡，这是一个紧迫的研究问题。", "method": "研究首先在相同条件下基准测试了三种偏见缓解策略：监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL），以确定它们的优缺点。在此基础上，通过改变每种范式中以去偏见为重点和以推理为中心的样本比例，来描绘推理与偏见之间的权衡关系。", "result": "研究发现一个一致的最佳平衡点：使用强化学习训练的约1:4的样本混合比例，可以将刻板印象分数降低10%，同时保留模型原始推理准确性的88%。", "conclusion": "该研究为在多模态大语言模型中平衡公平性与能力提供了具体的指导。", "translation": "多模态大语言模型（MLLMs）已经在广泛的任务和模态中取得了最先进的结果。为了进一步提升其推理能力，最近的研究探索了先进的提示方案和后训练微调。尽管这些技术提高了逻辑准确性，但它们常常使模型的输出带有明显的社会偏见。因此，弄清推理能力的提升如何与偏见缓解相互作用，以及这两个目标是否存在固有的权衡，仍然是一个开放且紧迫的研究问题。本研究首先在相同条件下，对三种偏见缓解策略——监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL）——进行了基准测试，建立了它们的基线优势和劣势。在此结果的基础上，我们改变了每种范式中以去偏见为重点和以推理为中心的样本比例，以描绘推理与偏见之间的权衡。我们的扫描揭示了一个一致的最佳点：通过强化学习训练的约1:4的混合样本，可以将刻板印象分数降低10%，同时保留模型原始推理准确性的88%，为平衡多模态大语言模型中的公平性与能力提供了具体的指导。", "summary": "本文研究了多模态大语言模型（MLLMs）中推理能力提升与社会偏见缓解之间的权衡问题。作者基准测试了监督微调、知识蒸馏和基于规则的强化学习三种偏见缓解策略，并系统地探索了去偏见与推理样本比例对模型性能的影响。研究发现，采用强化学习并以约1:4的比例混合去偏见和推理样本，能在显著降低偏见（10%）的同时，有效保持推理准确性（88%），为MLLMs的公平性与能力平衡提供了实用指导。", "keywords": "多模态大语言模型, 社会偏见, 推理能力, 偏见缓解, 强化学习", "comments": "这项研究的创新之处在于系统地量化了多模态大语言模型中推理能力与社会偏见缓解之间的权衡，并提供了一个具体的、可操作的解决方案（强化学习与特定样本比例）。这对于开发更公平、更强大的AI系统具有重要意义，尤其是在实际应用中，平衡性能与伦理考量至关重要。"}}
{"id": "2507.23170", "title": "BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning", "authors": ["Jinan Zhou", "Rajat Ghosh", "Vaishnavi Bhargava", "Debojyoti Dutta", "Aryan Singhal"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23170v1", "summary": "When designing LLM services, practitioners care about three key properties:\ninference-time budget, factual authenticity, and reasoning capacity. However,\nour analysis shows that no model can simultaneously optimize for all three. We\nformally prove this trade-off and propose a principled framework named The BAR\nTheorem for LLM-application design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23170v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "BAR猜想：具有真实性和推理能力的推理预算受限LLM服务的可行性", "tldr": "LLM服务在推理预算、事实真实性和推理能力之间存在固有的权衡，无法同时优化所有三者，本文提出了BAR定理框架来指导LLM应用设计。", "motivation": "在设计大型语言模型（LLM）服务时，实践者关注三个关键特性：推理时间预算、事实真实性和推理能力。然而，本文分析表明没有模型可以同时优化这三个特性。", "method": "本文通过形式化证明了LLM服务在推理时间预算、事实真实性和推理能力之间存在的权衡，并提出了一个名为“BAR定理”的原则性框架，用于LLM应用设计。", "result": "分析表明，没有模型可以同时优化推理时间预算、事实真实性和推理能力这三个特性。本文形式化证明了这种权衡。", "conclusion": "LLM服务在推理时间预算、事实真实性和推理能力之间存在固有的权衡，无法同时优化。BAR定理为LLM应用设计提供了一个指导性框架。", "translation": "在设计大型语言模型（LLM）服务时，实践者关注三个关键特性：推理时间预算、事实真实性和推理能力。然而，我们的分析表明没有模型可以同时优化所有这三个特性。我们形式化证明了这种权衡，并提出了一个名为“BAR定理”的原则性框架，用于LLM应用设计。", "summary": "本研究探讨了大型语言模型（LLM）服务设计中的三个关键属性：推理时间预算、事实真实性和推理能力。作者指出，现有模型无法同时优化这三者，并形式化证明了这种固有的权衡。为此，论文提出了一个名为“BAR定理”的原则性框架，旨在指导LLM应用的设计。", "keywords": "LLM服务, 推理预算, 真实性, 推理能力, BAR定理", "comments": "本文揭示了LLM服务在性能、真实性和推理能力之间存在的根本性权衡，这一发现对于LLM应用的实际部署和设计具有重要指导意义。提出的“BAR定理”框架为开发者提供了在有限预算下进行系统设计时的理论依据，强调了在不同目标之间进行取舍的必要性。其创新之处在于将实践中遇到的挑战提升到理论层面进行形式化证明。"}}
{"id": "2507.23504", "title": "A Verifier Hierarchy", "authors": ["Maurits Kaptein"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is primarily relevant to cs.CC, but submitted under this http URL due to lack of endorsement. The paper is under review at \"Information and Communication\"", "url": "http://arxiv.org/abs/2507.23504v1", "summary": "We investigate the trade-off between certificate length and verifier runtime.\nWe prove a Verifier Trade-off Theorem showing that reducing the inherent\nverification time of a language from \\(f(n)\\) to \\(g(n)\\), where \\(f(n) \\ge\ng(n)\\), requires certificates of length at least \\(\\Omega(\\log(f(n) / g(n)))\\).\nThis theorem induces a natural hierarchy based on certificate complexity. We\ndemonstrate its applicability to analyzing conjectured separations between\ncomplexity classes (e.g., \\(\\np\\) and \\(\\exptime\\)) and to studying natural\nproblems such as string periodicity and rotation detection. Additionally, we\nprovide perspectives on the \\(\\p\\) vs. \\(\\np\\) problem by relating it to the\nexistence of sub-linear certificates.", "comment": "This paper is primarily relevant to cs.CC, but submitted under cs.ML\n  due to lack of endorsement. The paper is under review at \"Information and\n  Communication\"", "pdf_url": "http://arxiv.org/pdf/2507.23504v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "验证器层次结构", "tldr": "该论文研究了证书长度与验证器运行时之间的权衡，提出了一个验证器权衡定理，并基于证书复杂性引入了一个新的层次结构，对复杂性类分离和P vs NP问题提供了新的视角。", "motivation": "该论文旨在调查证书长度与验证器运行时之间的权衡关系，并探讨减少验证时间对所需证书长度的影响。", "method": "该论文通过证明一个“验证器权衡定理”来建立其研究方法，该定理量化了验证时间缩减与所需证书长度之间的关系。", "result": "1. 证明了一个验证器权衡定理：将语言的验证时间从f(n)减少到g(n)需要至少Ω(log(f(n)/g(n)))长度的证书。2. 该定理引出了一个基于证书复杂性的自然层次结构。3. 该定理适用于分析复杂性类（如NP和EXPTIME）之间推测的分离。4. 该定理可用于研究字符串周期性和旋转检测等自然问题。5. 通过将其与次线性证书的存在联系起来，为P vs NP问题提供了新的视角。", "conclusion": "该论文建立了一个验证器运行时与证书长度之间的基本权衡关系，从而形成了一个新的层次结构，并为复杂性理论中的长期问题提供了深刻见解。", "translation": "我们研究了证书长度和验证器运行时之间的权衡。我们证明了一个验证器权衡定理，表明将语言的固有验证时间从 \\(f(n)\\) 减少到 \\(g(n)\\)（其中 \\(f(n) \\ge g(n)\\)）需要证书长度至少为 \\(\\Omega(\\log(f(n) / g(n)))\\)。该定理根据证书复杂性引入了一个自然的层次结构。我们展示了其在分析复杂性类（例如 \\(\\np\\) 和 \\(\\exptime\\)）之间推测的分离以及研究诸如字符串周期性和旋转检测等自然问题方面的适用性。此外，我们通过将其与次线性证书的存在联系起来，提供了关于 \\(\\p\\) vs. \\(\\np\\) 问题的视角。", "summary": "该论文探讨了证书长度与验证器运行时之间的权衡关系。作者证明了一个验证器权衡定理，该定理量化了验证时间缩减与所需证书长度之间的关系，并由此引出了一个基于证书复杂性的自然层次结构。研究展示了该定理在分析复杂性类分离（如NP与EXPTIME）以及理解P vs NP问题方面的应用，通过将其与次线性证书的存在联系起来。", "keywords": "证书复杂性, 验证器运行时, 复杂性类, P vs NP, 权衡定理", "comments": "这篇论文提出了一个基础性的定理，量化了验证中的一个关键权衡，从而引出了一个新的层次结构。它对计算复杂性中长期存在的开放问题，如P vs NP以及复杂性类之间的分离，具有潜在的重要意义。基于证书复杂性的“验证器层次结构”概念是创新的，并提供了一个审视计算复杂性的新视角。"}}
{"id": "2301.04943", "title": "Robust Nonlinear Optimal Control via System Level Synthesis", "authors": ["Antoine P. Leeman", "Johannes Köhler", "Andrea Zanelli", "Samir Bennani", "Melanie N. Zeilinger"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Published in IEEE Transactions on Automatic Control (TAC). Code: this https URL", "url": "http://arxiv.org/abs/2301.04943v3", "summary": "This paper addresses the problem of finite horizon constrained robust optimal\ncontrol for nonlinear systems subject to norm-bounded disturbances. To this\nend, the underlying uncertain nonlinear system is decomposed based on a\nfirst-order Taylor series expansion into a nominal system and an error\n(deviation) described as an uncertain linear time-varying system. This\ndecomposition allows us to leverage system level synthesis to jointly optimize\nan affine error feedback, a nominal nonlinear trajectory, and, most\nimportantly, a dynamic linearization error over-bound used to ensure robust\nconstraint satisfaction for the nonlinear system. The proposed approach thereby\nresults in less conservative planning compared with state-of-the-art\ntechniques. We demonstrate the benefits of the proposed approach to control the\nrotational motion of a rigid body subject to state and input constraints.", "comment": "Published in IEEE Transactions on Automatic Control (TAC). Code:\n  https://github.com/antoineleeman/nonlinear-system-level-synthesis", "pdf_url": "http://arxiv.org/pdf/2301.04943v3", "cate": "math.OC", "date": "2023-01-12", "updated": "2025-07-31", "AI": {"title_translation": "鲁棒非线性最优控制通过系统级综合", "tldr": "本文提出一种通过系统级综合对受扰动的非线性系统进行鲁棒最优控制的方法，通过分解系统并联合优化，实现更少保守的规划。", "motivation": "解决受范数有界扰动的非线性系统的有限时域约束鲁棒最优控制问题。", "method": "将不确定非线性系统基于一阶泰勒级数展开分解为标称系统和误差系统（不确定线性时变系统）。利用系统级综合联合优化仿射误差反馈、标称非线性轨迹以及动态线性化误差上界，以确保非线性系统的鲁棒约束满足。", "result": "所提出的方法与现有技术相比，产生了更少保守的规划。通过控制受状态和输入约束的刚体旋转运动来证明了该方法的优势。", "conclusion": "通过系统级综合，该方法能够有效地解决非线性系统的鲁棒最优控制问题，并在规划保守性方面优于现有技术。", "translation": "本文解决了受范数有界扰动的非线性系统的有限时域约束鲁棒最优控制问题。为此，将底层不确定非线性系统基于一阶泰勒级数展开分解为标称系统和一个误差（偏差），该误差被描述为一个不确定线性时变系统。这种分解使我们能够利用系统级综合来联合优化仿射误差反馈、标称非线性轨迹，以及最重要的是，一个用于确保非线性系统鲁棒约束满足的动态线性化误差上界。因此，所提出的方法与现有技术相比，产生了更少保守的规划。我们通过控制受状态和输入约束的刚体旋转运动来证明了所提出方法的优势。", "summary": "本文提出了一种针对受范数有界扰动的非线性系统的有限时域约束鲁棒最优控制方法。该方法通过将非线性系统分解为标称系统和不确定线性时变误差系统，并利用系统级综合联合优化误差反馈、标称轨迹和动态线性化误差上界，从而实现了比现有技术更少保守的鲁棒规划。通过刚体旋转运动的控制案例验证了其有效性。", "keywords": "鲁棒最优控制, 非线性系统, 系统级综合, 泰勒级数展开, 动态线性化误差", "comments": "该论文创新性地将系统级综合应用于非线性鲁棒最优控制，通过系统分解和联合优化动态线性化误差上界，有效降低了规划的保守性，为非线性系统控制提供了更实用的解决方案。"}}
{"id": "2507.23657", "title": "OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction", "authors": ["Yang Gao", "Po-Chien Luan", "Kaouther Messaoud", "Lan Feng", "Alexandre Alahi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23657v1", "summary": "While large-scale pre-training has advanced human trajectory prediction, a\ncritical challenge remains: zero-shot transfer to unseen dataset with varying\ntemporal dynamics. State-of-the-art pre-trained models often require\nfine-tuning to adapt to new datasets with different frame rates or observation\nhorizons, limiting their scalability and practical utility. In this work, we\nsystematically investigate this limitation and propose a robust solution. We\nfirst demonstrate that existing data-aware discrete models struggle when\ntransferred to new scenarios with shifted temporal setups. We then isolate the\ntemporal generalization from dataset shift, revealing that a simple, explicit\nconditioning mechanism for temporal metadata is a highly effective solution.\nBased on this insight, we present OmniTraj, a Transformer-based model\npre-trained on a large-scale, heterogeneous dataset. Our experiments show that\nexplicitly conditioning on the frame rate enables OmniTraj to achieve\nstate-of-the-art zero-shot transfer performance, reducing prediction error by\nover 70\\% in challenging cross-setup scenarios. After fine-tuning, OmniTraj\nachieves state-of-the-art results on four datasets, including NBA, JTA,\nWorldPose, and ETH-UCY. The code is publicly available:\nhttps://github.com/vita-epfl/omnitraj", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23657v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "OmniTraj：基于异构数据预训练的自适应零样本人体轨迹预测", "tldr": "OmniTraj通过对帧率进行显式条件化，实现了对不同时间动态数据集的零样本人体轨迹预测，并显著优于现有方法。", "motivation": "大规模预训练在人体轨迹预测方面取得了进展，但一个关键挑战是零样本迁移到具有不同时间动态的未见数据集。现有预训练模型通常需要微调以适应不同帧率或观察范围的新数据集，这限制了它们的可扩展性和实用性。", "method": "本文首先证明了现有数据感知离散模型在转移到时间设置不同的新场景时表现不佳。然后，将时间泛化与数据集偏移分离，发现针对时间元数据（如帧率）的简单、显式条件化机制是一种非常有效的解决方案。基于此，提出了OmniTraj，一个基于Transformer的模型，在大规模、异构数据集上进行预训练，并通过显式条件化帧率来实现自适应预测。", "result": "显式条件化帧率使OmniTraj在具有挑战性的跨设置场景中实现了最先进的零样本迁移性能，预测误差降低了70%以上。经过微调后，OmniTraj在NBA、JTA、WorldPose和ETH-UCY四个数据集上取得了最先进的结果。", "conclusion": "OmniTraj通过对时间元数据进行显式条件化，成功解决了人体轨迹预测中零样本迁移到不同时间动态数据集的挑战，显著提高了模型的泛化能力和实用性。", "translation": "尽管大规模预训练推动了人体轨迹预测的发展，但一个关键挑战依然存在：零样本迁移到具有不同时间动态的未见数据集。最先进的预训练模型通常需要微调才能适应具有不同帧率或观察范围的新数据集，这限制了它们的可扩展性和实用性。在这项工作中，我们系统地研究了这一限制并提出了一个鲁棒的解决方案。我们首先证明了现有数据感知离散模型在转移到时间设置发生变化的新场景时表现不佳。然后，我们将时间泛化与数据集偏移分离，揭示了一个简单、显式的时间元数据条件化机制是一个高效的解决方案。基于这一见解，我们提出了OmniTraj，一个基于Transformer的模型，在大规模、异构数据集上进行预训练。我们的实验表明，显式条件化帧率使OmniTraj实现了最先进的零样本迁移性能，在具有挑战性的跨设置场景中将预测误差降低了70%以上。经过微调后，OmniTraj在包括NBA、JTA、WorldPose和ETH-UCY在内的四个数据集上取得了最先进的结果。代码已公开：https://github.com/vita-epfl/omnitraj", "summary": "OmniTraj是一种基于Transformer的模型，旨在解决人体轨迹预测中零样本迁移到具有不同时间动态数据集的挑战。通过系统研究现有模型的局限性，本文发现对时间元数据（如帧率）进行显式条件化是提高模型泛化能力的有效方法。OmniTraj在大规模异构数据集上进行预训练，并通过显式条件化帧率，在零样本迁移场景中将预测误差降低了70%以上，并在微调后在多个基准数据集上达到了最先进的性能。", "keywords": "人体轨迹预测, 零样本迁移, 预训练, 异构数据, 时间泛化", "comments": "该论文的创新点在于系统地识别并解决了现有预训练模型在不同时间动态数据集上进行零样本迁移的局限性。通过提出对时间元数据进行显式条件化这一简单而有效的方法，OmniTraj显著提升了模型的泛化能力和实用性，这对于实际应用中处理多样化数据具有重要意义。其在零样本和微调设置下均达到SOTA性能，证明了方法的有效性。"}}
{"id": "2503.14939", "title": "VisNumBench: Evaluating Number Sense of Multimodal Large Language Models", "authors": ["Tengjin Weng", "Jingyi Wang", "Wenhao Jiang", "Zhong Ming"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.14939v2", "summary": "Can Multimodal Large Language Models (MLLMs) develop an intuitive number\nsense similar to humans? Targeting this problem, we introduce Visual Number\nBenchmark (VisNumBench) to evaluate the number sense abilities of MLLMs across\na wide range of visual numerical tasks. VisNumBench consists of about 1,900\nmultiple-choice question-answer pairs derived from both synthetic and\nreal-world visual data, covering seven visual numerical attributes and four\ntypes of visual numerical estimation tasks. Our experiments on VisNumBench led\nto the following key findings: (i) The 17 MLLMs we tested, including\nopen-source models such as Qwen2.5-VL and InternVL2.5, as well as proprietary\nmodels like GPT-4o and Gemini 2.0 Flash, perform significantly below human\nlevels in number sense-related tasks. (ii) Multimodal mathematical models and\nmultimodal chain-of-thought (CoT) models did not exhibit significant\nimprovements in number sense abilities. (iii) Stronger MLLMs with larger\nparameter sizes and broader general abilities demonstrate modest gains in\nnumber sense abilities. We believe VisNumBench will serve as a valuable\nresource for the research community, encouraging further advancements in\nenhancing MLLMs' number sense abilities. Code and dataset are available at\nhttps://wwwtttjjj.github.io/VisNumBench/.", "comment": "accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.14939v2", "cate": "cs.CV", "date": "2025-03-19", "updated": "2025-07-31", "AI": {"title_translation": "VisNumBench：评估多模态大型语言模型的数字感", "tldr": "该研究引入了VisNumBench，一个用于评估多模态大型语言模型（MLLMs）数字感的新基准。实验结果显示，当前MLLMs在数字感相关任务上表现远低于人类水平，即使是更强大的模型也仅有适度提升，而多模态数学模型和思维链模型未显示显著改进。", "motivation": "旨在探究多模态大型语言模型（MLLMs）是否能像人类一样发展出直观的数字感。", "method": "研究引入了VisNumBench，一个包含约1,900个多项选择问答对的视觉数字基准，用于评估MLLMs的数字感。这些数据来源于合成和真实世界的视觉数据，涵盖了七种视觉数字属性和四种视觉数字估算任务。研究对17个MLLM进行了实验。", "result": "实验发现：(i) 测试的17个MLLM（包括开源和专有模型）在数字感相关任务上的表现显著低于人类水平。(ii) 多模态数学模型和多模态思维链（CoT）模型在数字感能力上没有表现出显著改进。(iii) 参数量更大、通用能力更强的MLLM在数字感能力上表现出适度提升。", "conclusion": "VisNumBench将成为研究社区的宝贵资源，鼓励进一步推动增强MLLMs数字感能力的研究。", "translation": "多模态大型语言模型（MLLMs）能否像人类一样发展出直观的数字感？针对这个问题，我们引入了视觉数字基准（VisNumBench），以评估MLLMs在广泛的视觉数字任务中的数字感能力。VisNumBench包含约1,900个多项选择问答对，这些问题来源于合成和真实世界的视觉数据，涵盖了七种视觉数字属性和四种类型的视觉数字估算任务。我们在VisNumBench上的实验得出了以下主要发现：(i) 我们测试的17个MLLM，包括Qwen2.5-VL和InternVL2.5等开源模型，以及GPT-4o和Gemini 2.0 Flash等专有模型，在数字感相关任务中的表现显著低于人类水平。(ii) 多模态数学模型和多模态思维链（CoT）模型在数字感能力上没有表现出显著改进。(iii) 参数量更大、通用能力更强的MLLM在数字感能力上表现出适度提升。我们相信VisNumBench将成为研究社区的宝贵资源，鼓励进一步推动增强MLLMs数字感能力的研究。代码和数据集可在https://wwwtttjjj.github.io/VisNumBench/获取。", "summary": "本论文介绍了VisNumBench，一个包含1,900个视觉数字任务的新基准，旨在评估多模态大型语言模型（MLLMs）的数字感。对17个MLLM的实验结果显示，它们在数字感任务上的表现远低于人类水平。尽管参数量更大的MLLM表现出适度提升，但专门的多模态数学模型和思维链模型并未带来显著改进。VisNumBench旨在推动提升MLLMs数字感能力的研究。", "keywords": "多模态大语言模型, 数字感, 基准, 视觉数字任务, 评估", "comments": "该论文通过引入VisNumBench基准，创新性地解决了多模态大模型在“数字感”这一特定认知能力评估上的空白。其重要性在于揭示了当前最先进的MLLMs（包括专有和开源模型）在处理视觉数字信息时存在的显著局限性，即使是结合了数学模块或思维链方法也未能有效改善。这表明MLLMs在深层次的数值理解和推理方面仍需大量工作，为未来研究指明了方向。"}}
{"id": "2507.23053", "title": "In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion", "authors": ["Yuanhao Chen", "Liu Zhao", "Ji Ma", "Peng Lu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23053v1", "summary": "Quadruped robots face persistent challenges in achieving versatile locomotion\ndue to limitations in reference motion data diversity. To address these\nchallenges, this approach introduces an in-between motion generation based\nmulti-style quadruped robot locomotion framework, integrating synergistic\nadvances in motion generation and imitation learning. Our approach establishes\na unified pipeline addressing two fundamental aspects: First, we propose a CVAE\nbased motion generator, synthesizing multi-style dynamically feasible\nlocomotion sequences between arbitrary start and end states. By embedding\nphysical constraints and leveraging joint poses based phase manifold\ncontinuity, this component produces physically plausible motions spanning\nmultiple gait modalities while ensuring kinematic compatibility with robotic\nmorphologies. Second, we adopt the adversarial motion priors algorithm. We\nvalidate the effectiveness of generated motion data in enhancing controller\nstability and improving velocity tracking performance. The proposed framework\ndemonstrates significant improvements in velocity tracking and deployment\nstability. We successfully deploy the framework on a real-world quadruped\nrobot, and the experimental validation confirms the framework's capability to\ngenerate and execute complex motion profiles, including gallop, tripod,\ntrotting and pacing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23053v1", "cate": "cs.RO", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "基于中间运动生成的多风格四足机器人步态", "tldr": "本文提出了一种基于中间运动生成的多风格四足机器人步态框架，通过CVAE生成多种步态模式，并利用对抗性运动先验算法，显著提升了速度跟踪和部署稳定性，并在真实四足机器人上成功验证。", "motivation": "四足机器人在实现多功能运动方面面临挑战，原因在于参考运动数据多样性有限。为了解决这些挑战，本文引入了一种基于中间运动生成的多风格四足机器人步态框架。", "method": "该方法建立了一个统一的流程，解决了两个基本方面：首先，提出了一个基于CVAE的运动生成器，用于在任意起始和结束状态之间合成多风格、动态可行的运动序列，并嵌入物理约束和利用基于关节姿态的相位流形连续性，生成物理上合理的、跨多种步态模式的运动。其次，采用了对抗性运动先验算法。该框架在真实四足机器人上成功部署。", "result": "生成的运动数据有效增强了控制器稳定性和提高了速度跟踪性能。所提出的框架在速度跟踪和部署稳定性方面表现出显著改进。实验验证证实了该框架能够生成和执行复杂的运动曲线，包括疾驰、三足步态、小跑和溜蹄。", "conclusion": "该框架通过结合运动生成和模仿学习的协同进展，成功解决了四足机器人运动多样性受限的问题，并在真实机器人上展示了其生成和执行复杂多风格运动的能力，显著提升了性能和稳定性。", "translation": "四足机器人在实现多功能运动方面面临持续挑战，原因在于参考运动数据多样性有限。为了解决这些挑战，本文引入了一种基于中间运动生成的多风格四足机器人步态框架，该框架整合了运动生成和模仿学习的协同进展。我们的方法建立了一个统一的流程，解决了两个基本方面：首先，我们提出了一个基于CVAE的运动生成器，用于在任意起始和结束状态之间合成多风格、动态可行的运动序列。通过嵌入物理约束并利用基于关节姿态的相位流形连续性，该组件能够生成物理上合理的、跨多种步态模式的运动，同时确保与机器人形态的运动学兼容性。其次，我们采用了对抗性运动先验算法。我们验证了生成的运动数据在增强控制器稳定性和提高速度跟踪性能方面的有效性。所提出的框架在速度跟踪和部署稳定性方面表现出显著改进。我们成功地将该框架部署在真实世界的四足机器人上，实验验证证实了该框架能够生成和执行复杂的运动曲线，包括疾驰、三足步态、小跑和溜蹄。", "summary": "本文提出了一种基于中间运动生成的多风格四足机器人步态框架，旨在解决现有参考运动数据多样性不足的问题。该框架包含一个基于CVAE的运动生成器，能够合成多种动态可行的运动序列，并确保物理合理性和运动学兼容性。同时，结合对抗性运动先验算法，该方法显著提升了控制器稳定性和速度跟踪性能。实验结果表明，该框架在真实四足机器人上成功实现了多种复杂步态的生成与执行，有效提高了运动能力和部署稳定性。", "keywords": "四足机器人, 运动生成, CVAE, 模仿学习, 多风格步态", "comments": "该论文的创新点在于提出了一个统一的框架，将基于CVAE的运动生成与对抗性运动先验相结合，以解决四足机器人运动多样性不足的问题。通过在运动生成过程中嵌入物理约束和利用相位流形连续性，确保了生成动作的物理可行性和机器人形态的兼容性。在真实机器人上的成功部署和对多种复杂步态的支持，证明了其在实际应用中的潜力和重要性。"}}
{"id": "2507.23185", "title": "Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network", "authors": ["Jongwook Si", "Sungyoung Kim"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2507.23185v1", "summary": "The problem of single-image rain streak removal goes beyond simple noise\nsuppression, requiring the simultaneous preservation of fine structural details\nand overall visual quality. In this study, we propose a novel image restoration\nnetwork that effectively constrains the restoration process by introducing a\nCorner Loss, which prevents the loss of object boundaries and detailed texture\ninformation during restoration. Furthermore, we propose a Residual\nConvolutional Block Attention Module (R-CBAM) Block into the encoder and\ndecoder to dynamically adjust the importance of features in both spatial and\nchannel dimensions, enabling the network to focus more effectively on regions\nheavily affected by rain streaks. Quantitative evaluations conducted on the\nRain100L and Rain100H datasets demonstrate that the proposed method\nsignificantly outperforms previous approaches, achieving a PSNR of 33.29 dB on\nRain100L and 26.16 dB on Rain100H.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2507.23185v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "单幅图像雨纹去除：结合Harris角点损失和R-CBAM网络", "tldr": "提出了一种结合角点损失和R-CBAM网络的单幅图像去雨方法，在Rain100L和Rain100H数据集上取得了SOTA性能。", "motivation": "单幅图像去雨不仅是简单的去噪，还需要同时保留精细的结构细节和整体视觉质量。", "method": "提出了一种新的图像恢复网络，引入了角点损失（Corner Loss）以防止对象边界和纹理信息丢失；在编码器和解码器中引入了残差卷积块注意力模块（R-CBAM），以动态调整空间和通道维度特征的重要性，使网络更专注于受雨纹影响的区域。", "result": "在Rain100L和Rain100H数据集上进行了定量评估，所提出的方法显著优于现有方法，在Rain100L上实现了33.29 dB的PSNR，在Rain100H上实现了26.16 dB的PSNR。", "conclusion": "该方法通过引入角点损失和R-CBAM网络，在单幅图像去雨任务中取得了显著的性能提升，有效保留了图像细节并提升了视觉质量。", "translation": "单幅图像雨纹去除问题超越了简单的噪声抑制，需要同时保留精细的结构细节和整体视觉质量。在这项研究中，我们提出了一种新颖的图像恢复网络，通过引入角点损失（Corner Loss）有效地约束恢复过程，从而防止在恢复过程中丢失对象边界和详细纹理信息。此外，我们在编码器和解码器中引入了残差卷积块注意力模块（R-CBAM）块，以动态调整空间和通道维度中特征的重要性，使网络能够更有效地关注受雨纹严重影响的区域。在Rain100L和Rain100H数据集上进行的定量评估表明，所提出的方法显著优于现有方法，在Rain100L上实现了33.29 dB的PSNR，在Rain100H上实现了26.16 dB的PSNR。", "summary": "本文提出了一种用于单幅图像去雨的新型图像恢复网络。该网络通过引入“角点损失”来有效防止恢复过程中对象边界和纹理信息的丢失，并通过在编码器和解码器中集成“残差卷积块注意力模块（R-CBAM）”来动态调整特征重要性，使网络更专注于雨纹区域。实验结果表明，该方法在Rain100L和Rain100H数据集上均显著优于现有方法，取得了更高的PSNR值。", "keywords": "单幅图像去雨, 角点损失, R-CBAM, 图像恢复, 深度学习", "comments": "该论文的创新点在于引入了结合Harris角点损失和R-CBAM网络，有效地解决了单幅图像去雨中细节保留和特征关注的问题。角点损失有助于保护图像的关键结构信息，而R-CBAM则增强了网络对雨纹区域的识别和处理能力，从而在去雨的同时保持了图像的视觉质量和细节完整性。"}}
{"id": "2507.23284", "title": "Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval", "authors": ["Dohwan Ko", "Ji Soo Lee", "Minhyuk Choi", "Zihang Meng", "Hyunwoo J. Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Highlight", "url": "http://arxiv.org/abs/2507.23284v1", "summary": "Text-Video Retrieval aims to find the most relevant text (or video) candidate\ngiven a video (or text) query from large-scale online databases. Recent work\nleverages multi-modal large language models (MLLMs) to improve retrieval,\nespecially for long or complex query-candidate pairs. However, we observe that\nthe naive application of MLLMs, i.e., retrieval based on candidate likelihood,\nintroduces candidate prior bias, favoring candidates with inherently higher\npriors over those more relevant to the query. To this end, we propose a novel\nretrieval framework, Bidirectional Likelihood Estimation with MLLM (BLiM),\nwhich leverages both query and candidate likelihoods by training the model to\ngenerate text from a given video as well as video features from a given text.\nFurthermore, we introduce Candidate Prior Normalization (CPN), a simple yet\neffective training-free score calibration module designed to mitigate candidate\nprior bias in candidate likelihood. On four Text-Video Retrieval benchmarks,\nour BLiM equipped with CPN outperforms previous state-of-the-art models by 6.4\nR@1 on average, effectively alleviating candidate prior bias and emphasizing\nquery-candidate relevance. Our in-depth analysis across various multi-modal\ntasks beyond retrieval highlights the broad applicability of CPN which enhances\nvisual understanding by reducing reliance on textual priors. Code is available\nat https://github.com/mlvlab/BLiM.", "comment": "ICCV 2025 Highlight", "pdf_url": "http://arxiv.org/pdf/2507.23284v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于多模态大语言模型的双向似然估计用于文本-视频检索", "tldr": "本文提出了BLiM框架和CPN模块，通过双向似然估计和候选先验归一化，显著提升了文本-视频检索的性能，有效缓解了候选先验偏差。", "motivation": "现有的多模态大语言模型（MLLMs）在文本-视频检索中直接应用时，存在候选先验偏差，即模型倾向于选择具有较高固有先验的候选而非与查询更相关的候选，尤其对于长或复杂的查询-候选对。", "method": "本文提出了BLiM（Bidirectional Likelihood Estimation with MLLM）框架，该框架利用查询似然和候选似然，通过训练模型生成给定视频的文本以及给定文本的视频特征。此外，引入了CPN（Candidate Prior Normalization）模块，这是一个简单有效的免训练分数校准模块，旨在减轻候选似然中的候选先验偏差。", "result": "在四个文本-视频检索基准测试中，配备CPN的BLiM模型平均比现有最先进模型高出6.4 R@1，有效缓解了候选先验偏差并强调了查询-候选相关性。", "conclusion": "BLiM框架结合CPN模块显著提升了文本-视频检索性能，并通过减轻候选先验偏差和减少对文本先验的依赖来增强视觉理解，显示出CPN在多模态任务中的广泛适用性。", "translation": "文本-视频检索旨在从大规模在线数据库中，根据给定的视频（或文本）查询找到最相关的文本（或视频）候选。最近的工作利用多模态大语言模型（MLLMs）来改进检索，特别是对于长或复杂的查询-候选对。然而，我们观察到MLLMs的朴素应用，即基于候选似然的检索，引入了候选先验偏差，使得模型更偏爱具有固有较高先验的候选，而非与查询更相关的候选。为此，我们提出了一种新颖的检索框架——基于MLLM的双向似然估计（BLiM），它通过训练模型从给定视频生成文本以及从给定文本生成视频特征，从而同时利用查询和候选似然。此外，我们引入了候选先验归一化（CPN），这是一个简单而有效的免训练分数校准模块，旨在减轻候选似然中的候选先验偏差。在四个文本-视频检索基准测试中，我们配备CPN的BLiM模型平均比现有最先进模型高出6.4 R@1，有效缓解了候选先验偏差并强调了查询-候选相关性。我们对检索之外的各种多模态任务进行的深入分析突出了CPN的广泛适用性，它通过减少对文本先验的依赖来增强视觉理解。代码可在https://github.com/mlvlab/BLiM获取。", "summary": "本文针对多模态大语言模型在文本-视频检索中存在的候选先验偏差问题，提出了BLiM（Bidirectional Likelihood Estimation with MLLM）框架和CPN（Candidate Prior Normalization）模块。BLiM通过双向似然估计（同时训练文本到视频特征和视频到文本生成）来利用查询和候选似然，而CPN则是一个免训练的校准模块，用于缓解候选先验偏差。实验结果表明，在四个基准测试中，BLiM结合CPN比现有SOTA模型平均提升6.4 R@1，有效提高了检索性能并强调了查询-候选相关性。此外，CPN在其他多模态任务中也展现出增强视觉理解的潜力。", "keywords": "文本-视频检索, 多模态大语言模型, 双向似然估计, 候选先验偏差, 候选先验归一化", "comments": "这项工作通过引入双向似然估计和候选先验归一化，解决了多模态大语言模型在文本-视频检索中存在的关键问题——候选先验偏差。BLiM框架的双向训练方法以及CPN模块的免训练特性，使其具有创新性和实用性。CPN的广泛适用性也暗示了其在其他多模态任务中可能发挥重要作用，提升模型对视觉内容的理解能力。"}}
{"id": "2410.16593", "title": "Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs", "authors": ["Haolin Li", "Haoyu Wang", "Luana Ruiz"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.16593v4", "summary": "Graph Neural Networks (GNNs) excel in many graph machine learning tasks but\nface challenges when scaling to large networks. GNN transferability allows\ntraining on smaller graphs and applying the model to larger ones, but existing\nmethods often rely on random subsampling, leading to disconnected subgraphs and\nreduced model expressivity. We propose a novel graph sampling algorithm that\nleverages feature homophily to preserve graph structure. By minimizing the\ntrace of the data correlation matrix, our method better preserves the graph\nLaplacian trace -- a proxy for the graph connectivity -- than random sampling,\nwhile achieving lower complexity than spectral methods. Experiments on citation\nnetworks show improved performance in preserving Laplacian trace and GNN\ntransferability compared to random sampling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.16593v4", "cate": "eess.SP", "date": "2024-10-22", "updated": "2025-07-30", "AI": {"title_translation": "同质图上可扩展和富有表达力的图神经网络的图采样", "tldr": "图神经网络 (GNNs) 在大型图上存在扩展性问题。本文提出了一种新的图采样算法，利用特征同质性来保留图结构，与随机采样相比，提高了可扩展性和表达能力。", "motivation": "图神经网络 (GNNs) 在扩展到大型网络时面临挑战。现有 GNN 可迁移性方法通常依赖随机子采样，这会导致子图断开连接并降低模型表达能力。", "method": "提出了一种新颖的图采样算法，利用特征同质性来保留图结构。通过最小化数据相关矩阵的迹，该方法能更好地保留图拉普拉斯迹（图连通性的代理），同时比谱方法具有更低的复杂度。", "result": "在引文网络上的实验表明，与随机采样相比，该方法在保留拉普拉斯迹和 GNN 可迁移性方面性能有所提高。", "conclusion": "本文提出了一种新颖的图采样算法，该算法利用特征同质性来保留图结构，从而提高了 GNN 的可扩展性和表达能力，在保留拉普拉斯迹和可迁移性方面优于随机采样。", "translation": "图神经网络 (GNNs) 在许多图机器学习任务中表现出色，但在扩展到大型网络时面临挑战。GNN 可迁移性允许在较小图上训练并将模型应用于较大图，但现有方法通常依赖于随机子采样，导致子图断开连接并降低模型表达能力。我们提出了一种新颖的图采样算法，该算法利用特征同质性来保留图结构。通过最小化数据相关矩阵的迹，我们的方法比随机采样能更好地保留图拉普拉斯迹——这是图连通性的一个代理——同时比谱方法具有更低的复杂度。在引文网络上的实验表明，与随机采样相比，在保留拉普拉斯迹和GNN可迁移性方面，性能有所提高。", "summary": "本文旨在解决图神经网络 (GNNs) 在大型图上的可扩展性和表达能力问题。论文提出了一种新颖的图采样算法，该算法利用特征同质性来维护图下采样过程中的结构完整性。通过最小化数据相关矩阵的迹，该方法能有效保留图连通性（拉普拉斯迹），且复杂度低于谱方法，在引文网络上表现出优于随机采样的 GNN 可迁移性。", "keywords": "图神经网络, 图采样, 同质性, 可扩展性, 可迁移性", "comments": "该论文的创新之处在于利用特征同质性进行图采样，以保留结构完整性，这对于 GNN 的可迁移性至关重要。这种方法在保持表达能力和实现可扩展性之间取得了实用的平衡，解决了随机采样的关键局限性。与谱方法相比，其较低的复杂度也是一个值得注意的优势，适用于实际应用。"}}
{"id": "2507.23319", "title": "What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content", "authors": ["Alfio Ferrara", "Sergio Picascia", "Laura Pinnavaia", "Vojimir Ranitovic", "Elisabetta Rocchetti", "Alice Tuveri"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23319v1", "summary": "Proprietary Large Language Models (LLMs) have shown tendencies toward\npoliteness, formality, and implicit content moderation. While previous research\nhas primarily focused on explicitly training models to moderate and detoxify\nsensitive content, there has been limited exploration of whether LLMs\nimplicitly sanitize language without explicit instructions. This study\nempirically analyzes the implicit moderation behavior of GPT-4o-mini when\nparaphrasing sensitive content and evaluates the extent of sensitivity shifts.\nOur experiments indicate that GPT-4o-mini systematically moderates content\ntoward less sensitive classes, with substantial reductions in derogatory and\ntaboo language. Also, we evaluate the zero-shot capabilities of LLMs in\nclassifying sentence sensitivity, comparing their performances against\ntraditional methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23319v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "你认为什么是禁忌？——大型语言模型对敏感内容行为的实证评估", "tldr": "本研究发现GPT-4o-mini在复述敏感内容时会系统性地进行隐式审查，使其变得不那么敏感，并评估了LLM在敏感度分类上的零样本能力。", "motivation": "之前的研究主要集中于明确训练模型进行内容审核，但对于大型语言模型（LLMs）是否在没有明确指示的情况下隐式地净化语言的探索有限。", "method": "本研究实证分析了GPT-4o-mini在复述敏感内容时的隐式审查行为，并评估了敏感度变化的程度。此外，还评估了LLMs在零样本分类句子敏感度方面的能力，并将其性能与传统方法进行了比较。", "result": "实验表明GPT-4o-mini系统性地将内容审核至不那么敏感的类别，显著减少了贬低性和禁忌性语言。", "conclusion": "GPT-4o-mini表现出显著的隐式内容审查行为，即使没有明确指示，也会使敏感内容变得不那么具有攻击性。同时，LLMs在零样本敏感度分类上表现出潜力。", "translation": "专有大型语言模型（LLMs）表现出礼貌、正式和隐式内容审查的倾向。虽然之前的研究主要集中于明确训练模型来审核和净化敏感内容，但对于LLMs是否在没有明确指令的情况下隐式地净化语言的探索有限。本研究实证分析了GPT-4o-mini在复述敏感内容时的隐式审查行为，并评估了敏感度变化的程度。我们的实验表明，GPT-4o-mini系统性地将内容审核为不那么敏感的类别，显著减少了贬低性和禁忌性语言。此外，我们还评估了LLMs在零样本分类句子敏感度方面的能力，并将其性能与传统方法进行了比较。", "summary": "本研究实证调查了大型语言模型（LLMs）对敏感内容的隐式审查行为，特别是以GPT-4o-mini为例。研究发现，即使没有明确指令，GPT-4o-mini在复述敏感内容时也会系统性地将其修改为不那么敏感的形式，显著减少了贬低性和禁忌性语言。此外，研究还评估了LLMs在零样本敏感度分类方面的能力，并与传统方法进行了对比。", "keywords": "大型语言模型, 敏感内容, 隐式审查, GPT-4o-mini, 零样本分类", "comments": "这篇论文揭示了LLMs在处理敏感内容时的一种重要且未被充分研究的隐式行为，即其内在的“礼貌”和“审查”倾向。这对于理解LLMs的偏见、安全性以及在实际应用中的表现具有重要意义。研究方法是实证分析，并比较了零样本分类能力，具有一定的创新性。"}}
{"id": "2507.22607", "title": "VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning", "authors": ["Ruifeng Yuan", "Chenghao Xiao", "Sicong Leng", "Jianyu Wang", "Long Li", "Weiwen Xu", "Hou Pong Chan", "Deli Zhao", "Tingyang Xu", "Zhongyu Wei", "Hao Zhang", "Yu Rong"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      21 pages, 5 figures, 6 tables. Work in progress", "url": "http://arxiv.org/abs/2507.22607v2", "summary": "Reinforcement learning has proven its effectiveness in enhancing the\nreasoning capabilities of large language models. Recent research efforts have\nprogressively extended this paradigm to multimodal reasoning tasks. Due to the\ninherent complexity and diversity of multimodal tasks, especially in semantic\ncontent and problem formulations, existing models often exhibit unstable\nperformance across various domains and difficulty levels. To address these\nlimitations, we propose VL-Cogito, an advanced multimodal reasoning model\ntrained via a novel multi-stage Progressive Curriculum Reinforcement Learning\n(PCuRL) framework. PCuRL systematically guides the model through tasks of\ngradually increasing difficulty, substantially improving its reasoning\nabilities across diverse multimodal contexts. The framework introduces two key\ninnovations: (1) an online difficulty soft weighting mechanism, dynamically\nadjusting training difficulty across successive RL training stages; and (2) a\ndynamic length reward mechanism, which encourages the model to adaptively\nregulate its reasoning path length according to task complexity, thus balancing\nreasoning efficiency with correctness. Experimental evaluations demonstrate\nthat VL-Cogito consistently matches or surpasses existing reasoning-oriented\nmodels across mainstream multimodal benchmarks spanning mathematics, science,\nlogic, and general understanding, validating the effectiveness of our approach.", "comment": "21 pages, 5 figures, 6 tables. Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.22607v2", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "VL-Cogito：用于高级多模态推理的渐进式课程强化学习", "tldr": "VL-Cogito提出了一种新颖的渐进式课程强化学习（PCuRL）框架，通过在线难度软加权和动态长度奖励机制，显著提升了多模态推理模型的稳定性和性能。", "motivation": "强化学习在增强大型语言模型的推理能力方面已显示出有效性，并逐渐扩展到多模态推理任务。然而，由于多模态任务固有的复杂性和多样性，现有模型在不同领域和难度级别上表现不稳定。", "method": "我们提出了VL-Cogito，一个通过新颖的多阶段渐进式课程强化学习（PCuRL）框架训练的先进多模态推理模型。PCuRL系统地引导模型通过难度逐渐增加的任务，并引入了两项关键创新：1) 在线难度软加权机制，动态调整RL训练阶段的难度；2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调整推理路径长度，以平衡推理效率和正确性。", "result": "实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和通用理解的主流多模态基准测试中，始终与现有推理导向模型持平或超越。", "conclusion": "VL-Cogito及其渐进式课程强化学习框架有效解决了现有模型在多模态推理中表现不稳定的问题，显著提升了模型在多样化多模态上下文中的推理能力和泛化性。", "translation": "强化学习已证明其在增强大型语言模型推理能力方面的有效性。最近的研究工作已逐步将这种范式扩展到多模态推理任务。由于多模态任务固有的复杂性和多样性，尤其是在语义内容和问题表述方面，现有模型在各种领域和难度级别上往往表现出不稳定的性能。为了解决这些限制，我们提出了VL-Cogito，一个通过新颖的多阶段渐进式课程强化学习（PCuRL）框架训练的先进多模态推理模型。PCuRL系统地引导模型通过难度逐渐增加的任务，大大提高了其在多样化多模态上下文中的推理能力。该框架引入了两项关键创新：(1) 在线难度软加权机制，动态调整连续RL训练阶段的训练难度；(2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调节其推理路径长度，从而平衡推理效率和正确性。实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和通用理解的主流多模态基准测试中，始终与现有推理导向模型持平或超越，验证了我们方法的有效性。", "summary": "VL-Cogito是一种新的多模态推理模型，旨在解决现有模型在处理复杂多样的多模态任务时性能不稳定的问题。该模型通过新颖的多阶段渐进式课程强化学习（PCuRL）框架进行训练，该框架包含在线难度软加权和动态长度奖励机制，旨在逐步提升模型在不同难度和领域的推理能力。实验结果表明，VL-Cogito在多个主流多模态基准测试中表现优异，验证了其有效性。", "keywords": "多模态推理, 强化学习, 课程学习, VL-Cogito, PCuRL", "comments": "VL-Cogito的创新之处在于其提出的渐进式课程强化学习（PCuRL）框架，特别是其在线难度软加权和动态长度奖励机制。这些机制有效地解决了多模态推理中任务复杂性和多样性带来的挑战，通过循序渐进地提升模型能力，增强了模型的稳定性和泛化性。该方法对于提升多模态AI的鲁棒性和效率具有重要意义。"}}
{"id": "2507.23190", "title": "Accessibility Scout: Personalized Accessibility Scans of Built Environments", "authors": ["William Huang", "Xia Su", "Jon E. Froehlich", "Yang Zhang"], "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.MA"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 16 figures. Presented at ACM UIST 2025", "url": "http://arxiv.org/abs/2507.23190v1", "summary": "Assessing the accessibility of unfamiliar built environments is critical for\npeople with disabilities. However, manual assessments, performed by users or\ntheir personal health professionals, are laborious and unscalable, while\nautomatic machine learning methods often neglect an individual user's unique\nneeds. Recent advances in Large Language Models (LLMs) enable novel approaches\nto this problem, balancing personalization with scalability to enable more\nadaptive and context-aware assessments of accessibility. We present\nAccessibility Scout, an LLM-based accessibility scanning system that identifies\naccessibility concerns from photos of built environments. With use,\nAccessibility Scout becomes an increasingly capable \"accessibility scout\",\ntailoring accessibility scans to an individual's mobility level, preferences,\nand specific environmental interests through collaborative Human-AI\nassessments. We present findings from three studies: a formative study with six\nparticipants to inform the design of Accessibility Scout, a technical\nevaluation of 500 images of built environments, and a user study with 10\nparticipants of varying mobility. Results from our technical evaluation and\nuser study show that Accessibility Scout can generate personalized\naccessibility scans that extend beyond traditional ADA considerations. Finally,\nwe conclude with a discussion on the implications of our work and future steps\nfor building more scalable and personalized accessibility assessments of the\nphysical world.", "comment": "18 pages, 16 figures. Presented at ACM UIST 2025", "pdf_url": "http://arxiv.org/pdf/2507.23190v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "无障碍侦察兵：建筑环境的个性化无障碍扫描", "tldr": "基于LLM的系统通过照片个性化扫描建筑环境的无障碍性，克服了手动和传统自动方法的局限性。", "motivation": "评估陌生建筑环境的无障碍性对残疾人至关重要。然而，手动评估费力且难以扩展，而现有自动化机器学习方法往往忽视用户个性化需求。", "method": "本文提出Accessibility Scout，一个基于大型语言模型（LLM）的无障碍扫描系统，它能从建筑环境的照片中识别无障碍问题。该系统通过人机协作评估，根据用户的移动能力、偏好和特定环境兴趣，个性化定制无障碍扫描。", "result": "技术评估（500张图片）和用户研究（10名参与者）的结果表明，Accessibility Scout能够生成超越传统ADA考虑的个性化无障碍扫描。", "conclusion": "本文讨论了这项工作的意义以及未来构建更具可扩展性和个性化的物理世界无障碍评估系统。", "translation": "评估陌生建筑环境的无障碍性对于残疾人至关重要。然而，由用户或其个人健康专业人员进行的手动评估费力且难以扩展，而自动机器学习方法往往忽视个体用户的独特需求。大型语言模型（LLMs）的最新进展为解决这个问题提供了新颖的方法，平衡了个性化与可扩展性，从而实现更具适应性和上下文感知的无障碍评估。我们提出了Accessibility Scout，一个基于LLM的无障碍扫描系统，它能从建筑环境的照片中识别无障碍问题。随着使用，Accessibility Scout通过人机协作评估，根据个人的移动能力、偏好和特定的环境兴趣，将无障碍扫描定制化，成为一个能力日益增强的“无障碍侦察兵”。我们展示了三项研究的结果：一项有六名参与者参与的形成性研究，旨在为Accessibility Scout的设计提供信息；一项针对500张建筑环境图片的技​​术评估；以及一项有10名不同移动能力参与者参与的用户研究。我们的技术评估和用户研究结果表明，Accessibility Scout可以生成超越传统ADA考虑的个性化无障碍扫描。最后，我们讨论了这项工作的意义以及未来构建更具可扩展性和个性化的物理世界无障碍评估系统。", "summary": "针对残疾人评估建筑环境无障碍性所面临的手动评估费力、自动化方法缺乏个性化的问题，本文提出了Accessibility Scout系统。该系统利用大型语言模型（LLM）从照片中识别无障碍问题，并通过人机协作根据用户的具体需求进行个性化扫描。多项研究表明，Accessibility Scout能够生成超越传统标准、更具个性化的无障碍评估。", "keywords": "无障碍性, 建筑环境, 大型语言模型, 个性化, 人机协作", "comments": "该论文的创新点在于将大型语言模型应用于建筑环境的无障碍评估，实现了传统方法难以达到的个性化和可扩展性。通过引入人机协作评估机制，系统能够更好地适应个体用户的独特需求，为残疾人提供了更实用、更定制化的无障碍信息。这项工作对于提升物理世界的无障碍性评估效率和准确性具有重要意义。"}}
{"id": "2507.22952", "title": "Automated Label Placement on Maps via Large Language Models", "authors": ["Harry Shomer", "Jiejun Xu"], "categories": ["cs.HC", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Workshop on AI for Data Editing (AI4DE) at KDD 2025", "url": "http://arxiv.org/abs/2507.22952v1", "summary": "Label placement is a critical aspect of map design, serving as a form of\nspatial annotation that directly impacts clarity and interpretability. Despite\nits importance, label placement remains largely manual and difficult to scale,\nas existing automated systems struggle to integrate cartographic conventions,\nadapt to context, or interpret labeling instructions. In this work, we\nintroduce a new paradigm for automatic label placement (ALP) that formulates\nthe task as a data editing problem and leverages large language models (LLMs)\nfor context-aware spatial annotation. To support this direction, we curate\nMAPLE, the first known benchmarking dataset for evaluating ALP on real-world\nmaps, encompassing diverse landmark types and label placement annotations from\nopen-source data. Our method retrieves labeling guidelines relevant to each\nlandmark type leveraging retrieval-augmented generation (RAG), integrates them\ninto prompts, and employs instruction-tuned LLMs to generate ideal label\ncoordinates. We evaluate four open-source LLMs on MAPLE, analyzing both overall\nperformance and generalization across different types of landmarks. This\nincludes both zero-shot and instruction-tuned performance. Our results\ndemonstrate that LLMs, when guided by structured prompts and domain-specific\nretrieval, can learn to perform accurate spatial edits, aligning the generated\noutputs with expert cartographic standards. Overall, our work presents a\nscalable framework for AI-assisted map finishing and demonstrates the potential\nof foundation models in structured data editing tasks. The code and data can be\nfound at https://github.com/HarryShomer/MAPLE.", "comment": "Workshop on AI for Data Editing (AI4DE) at KDD 2025", "pdf_url": "http://arxiv.org/pdf/2507.22952v1", "cate": "cs.HC", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "通过大型语言模型实现地图上的自动化标签放置", "tldr": "本文利用大型语言模型和新数据集，实现了地图标签的自动化放置，证明了大型语言模型能够执行精确的空间编辑。", "motivation": "地图上的标签放置是地图设计中的关键环节，但现有自动化系统难以整合制图规范、适应上下文或解释标注指令，导致其仍主要依赖手动且难以扩展。", "method": "本文提出了一种新的自动化标签放置范式，将任务表述为数据编辑问题，并利用大型语言模型（LLMs）进行上下文感知的空间标注。为此，作者构建了首个用于评估真实世界地图上自动化标签放置的基准数据集MAPLE。该方法利用检索增强生成（RAG）检索相关标注指南，将其整合到提示中，并使用指令调优的LLMs生成理想的标签坐标。研究评估了四种开源LLMs在MAPLE数据集上的表现。", "result": "结果表明，在结构化提示和领域特定检索的指导下，LLMs能够学习执行精确的空间编辑，并使生成结果符合专家制图标准。", "conclusion": "该工作提出了一个可扩展的AI辅助地图制图框架，并展示了基础模型在结构化数据编辑任务中的潜力。", "translation": "标签放置是地图设计的一个关键方面，它作为一种空间标注形式直接影响清晰度和可解释性。尽管其重要性，标签放置在很大程度上仍然是手动的，难以扩展，因为现有的自动化系统难以整合制图规范、适应上下文或解释标注指令。在这项工作中，我们引入了一种新的自动化标签放置（ALP）范式，将任务表述为数据编辑问题，并利用大型语言模型（LLMs）进行上下文感知的空间标注。为了支持这一方向，我们策划了MAPLE，这是第一个已知的用于评估真实世界地图上ALP的基准数据集，涵盖了来自开源数据的各种地标类型和标签放置标注。我们的方法利用检索增强生成（RAG）检索与每种地标类型相关的标注指南，将其整合到提示中，并采用指令调优的LLMs生成理想的标签坐标。我们评估了MAPLE上的四种开源LLMs，分析了整体性能和跨不同地标类型的泛化能力。这包括零样本和指令调优的性能。我们的结果表明，LLMs在结构化提示和领域特定检索的指导下，能够学习执行精确的空间编辑，使生成输出与专家制图标准保持一致。总的来说，我们的工作提出了一个可扩展的AI辅助地图完成框架，并展示了基础模型在结构化数据编辑任务中的潜力。代码和数据可在https://github.com/HarryShomer/MAPLE找到。", "summary": "本文提出了一种利用大型语言模型（LLMs）实现地图标签自动化放置的新范式。该方法将标签放置视为数据编辑问题，并构建了首个真实世界地图标签放置基准数据集MAPLE。通过结合检索增强生成（RAG）技术，LLMs能够根据制图规范生成精确的标签坐标。实验结果表明，LLMs在结构化指导下能够执行高质量的空间编辑，为AI辅助地图制图提供了可扩展的解决方案。", "keywords": "标签放置, 大型语言模型, 地图设计, 空间标注, RAG", "comments": "本文的创新点在于首次将大型语言模型应用于地图标签的自动化放置，提出了一种将该任务视为数据编辑问题的新范式。通过构建首个真实世界地图标签放置基准数据集MAPLE，并结合检索增强生成（RAG）技术，使得LLMs能够理解并遵循复杂的制图规范，从而实现精确且符合专家标准的空间编辑。这为AI辅助地图制图提供了一个可扩展的框架，展示了基础模型在结构化数据编辑方面的巨大潜力，对于提高地图制作效率和质量具有重要意义。"}}
{"id": "2504.14928", "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "authors": ["Yao Shi", "Rongkeng Liang", "Yong Xu"], "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Paper URL: this https URL ;Presentation Video: this https URL", "url": "http://arxiv.org/abs/2504.14928v3", "summary": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.", "comment": "Paper URL: https://aclanthology.org/2025.acl-long.1576 ;Presentation\n  Video: https://www.youtube.com/watch?v=j63ooKE50I0", "pdf_url": "http://arxiv.org/pdf/2504.14928v3", "cate": "cs.AI", "date": "2025-04-21", "updated": "2025-07-31", "AI": {"title_translation": "EducationQ：通过多智能体对话框架评估大型语言模型的教学能力", "tldr": "引入EducationQ多智能体框架，高效评估LLM教学能力，发现教学效果与模型规模或通用推理能力并非线性相关，强调需要专门优化教学AI。", "motivation": "尽管大型语言模型（LLMs）日益成为教育工具，但评估其教学能力仍然面临资源密集、高度依赖上下文和方法学复杂等挑战。", "method": "本文提出EducationQ多智能体对话框架，通过模拟动态教育场景，利用专门的教学、学习和评估智能体来高效评估大型语言模型的教学能力。该方法结合了定量指标、定性分析和专家案例研究进行混合方法评估。", "result": "实验测试了14个大型语言模型，涵盖13个学科和10个难度级别的1,498个问题，结果表明教学效果与模型规模或通用推理能力并非线性相关，一些小型开源模型在教学环境中表现优于大型商业模型。研究还发现顶尖模型具有独特的教学优势（如复杂的提问策略、自适应反馈机制），并且人类专家评估与自动化定性分析的有效教学行为一致性达到78%。", "conclusion": "LLMs作为教师需要专门的优化，而非简单的规模扩展；下一代教育AI应优先有针对性地增强特定教学效果。", "translation": "大型语言模型（LLMs）日益成为教育工具，然而，由于师生互动固有的资源密集、上下文依赖和方法学复杂性，评估其教学能力仍然充满挑战。我们引入了EducationQ，一个多智能体对话框架，通过模拟动态教育场景，利用专门的教学、学习和评估智能体，高效评估教学能力。对来自主要AI组织（OpenAI、Meta、Google、Anthropic及其他）的14个LLM进行了测试，涉及13个学科和10个难度级别的1,498个问题，结果显示教学效果与模型规模或通用推理能力并非线性相关——一些较小的开源模型在教学情境中表现优于较大的商业模型。这一发现突显了当前评估中优先考虑知识回忆而非互动教学法的关键差距。我们的混合方法评估，结合了定量指标、定性分析和专家案例研究，识别出表现最佳模型所采用的独特教学优势（例如，复杂的提问策略、自适应反馈机制）。人类专家评估显示，我们对有效教学行为的自动化定性分析与人类判断有78%的一致性，从而验证了我们的方法。EducationQ表明，作为教师的LLM需要专门的优化，而不仅仅是简单的规模扩展，这提示下一代教育AI应优先针对性地增强特定的教学效果。", "summary": "本文介绍了EducationQ，一个用于高效评估大型语言模型（LLMs）教学能力的多智能体对话框架。该框架通过模拟师生互动，测试了14个LLM在多学科和多难度问题上的表现。研究发现LLM的教学效果与模型规模或通用推理能力并非线性相关，一些小型模型甚至优于大型商业模型。EducationQ结合定量和定性分析，识别出优秀模型的教学策略，并通过人类专家验证了其评估方法的有效性。研究强调，未来的教育AI发展应侧重于专门的教学优化，而非单纯的模型扩展。", "keywords": "大型语言模型, 教学能力评估, 多智能体系统, 教育AI, EducationQ", "comments": "这篇论文的创新点在于提出了一个新颖的多智能体对话框架EducationQ，用于系统且高效地评估LLM的教学能力，解决了传统评估的挑战。其重要发现是揭示了LLM教学能力与模型规模并非线性相关，这挑战了“越大越好”的普遍认知，并强调了交互式教学策略的重要性。论文也为未来教育AI的发展指明了方向，即需要更精细化的教学优化，而非简单的模型扩展。"}}
{"id": "2507.23398", "title": "Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation", "authors": ["Oliver Bause", "Julia Werner", "Paul Palomero Bernardo", "Oliver Bringmann"], "categories": ["eess.IV", "cs.AR", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at the 32nd International Conference on Neural Information Processing - ICONIP 2025", "url": "http://arxiv.org/abs/2507.23398v1", "summary": "For many real-world applications involving low-power sensor edge devices deep\nneural networks used for image classification might not be suitable. This is\ndue to their typically large model size and require- ment of operations often\nexceeding the capabilities of such resource lim- ited devices. Furthermore,\ncamera sensors usually capture images with a Bayer color filter applied, which\nare subsequently converted to RGB images that are commonly used for neural\nnetwork training. However, on resource-constrained devices, such conversions\ndemands their share of energy and optimally should be skipped if possible. This\nwork ad- dresses the need for hardware-suitable AI targeting sensor edge\ndevices by means of the Video Capsule Endoscopy, an important medical proce-\ndure for the investigation of the small intestine, which is strongly limited by\nits battery lifetime. Accurate organ classification is performed with a final\naccuracy of 93.06% evaluated directly on Bayer images involv- ing a CNN with\nonly 63,000 parameters and time-series analysis in the form of Viterbi\ndecoding. Finally, the process of capturing images with a camera and raw image\nprocessing is demonstrated with a customized PULPissimo System-on-Chip with a\nRISC-V core and an ultra-low power hardware accelerator providing an\nenergy-efficient AI-based image clas- sification approach requiring just 5.31\n{\\mu}J per image. As a result, it is possible to save an average of 89.9% of\nenergy before entering the small intestine compared to classic video capsules.", "comment": "Accepted at the 32nd International Conference on Neural Information\n  Processing - ICONIP 2025", "pdf_url": "http://arxiv.org/pdf/2507.23398v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "智能视频胶囊内窥镜：基于原始图像的定位增强胃肠道检查", "tldr": "该研究提出了一种针对低功耗边缘设备的节能AI图像分类方法，通过直接处理拜耳图像并结合小型CNN和维特比解码，在视频胶囊内窥镜中实现了高精度器官分类和显著的能耗降低。", "motivation": "传统的深度神经网络由于模型尺寸大和计算需求高，不适用于低功耗边缘设备，如视频胶囊内窥镜，其电池寿命受限。此外，将相机传感器捕获的拜耳图像转换为RGB图像会消耗大量能量。本研究旨在为传感器边缘设备提供硬件友好的AI解决方案，以解决视频胶囊内窥镜在小肠检查中面临的能耗限制问题。", "method": "本研究直接在拜耳图像上进行器官分类，使用一个仅包含63,000个参数的卷积神经网络（CNN）和维特比解码形式的时序分析，实现了93.06%的分类准确率。图像捕获和原始图像处理过程在一个定制的PULPissimo片上系统（带有RISC-V核心和超低功耗硬件加速器）上实现，提供了一种节能的AI图像分类方法。", "result": "该方法在器官分类中达到了93.06%的最终准确率，每张图像仅需5.31微焦耳的能量。与传统视频胶囊相比，在进入小肠前平均可节省89.9%的能量。", "conclusion": "本研究成功开发了一种针对视频胶囊内窥镜的节能、高精度的AI图像分类方法，通过直接处理原始拜耳图像和优化硬件实现，显著降低了能耗，提升了低功耗边缘设备的性能，对于胃肠道检查具有重要意义。", "translation": "对于许多涉及低功耗传感器边缘设备的实际应用，用于图像分类的深度神经网络可能不适用。这是因为它们通常模型尺寸大，并且操作要求往往超出此类资源受限设备的能力。此外，相机传感器通常捕获应用了拜耳滤色器的图像，这些图像随后被转换为常用于神经网络训练的RGB图像。然而，在资源受限的设备上，这种转换会消耗能量，如果可能的话，最好跳过。这项工作通过视频胶囊内窥镜（一种用于检查小肠的重要医疗程序，其电池寿命受到严重限制）解决了对硬件友好型AI的需求，以满足传感器边缘设备的需求。器官分类直接在拜耳图像上进行，最终准确率达到93.06%，涉及一个仅有63,000个参数的CNN和维特比解码形式的时序分析。最后，通过定制的PULPissimo片上系统（带有RISC-V核心和超低功耗硬件加速器）演示了相机图像捕获和原始图像处理过程，提供了一种节能的AI图像分类方法，每张图像仅需5.31微焦耳。结果显示，与传统视频胶囊相比，在进入小肠前平均可节省89.9%的能量。", "summary": "本论文提出了一种针对智能视频胶囊内窥镜的节能AI图像分类方法，旨在解决低功耗边缘设备上深度学习的挑战。该方法通过直接处理拜耳原始图像，并结合一个小型CNN（63k参数）和维特比解码进行时序分析，实现了93.06%的器官分类准确率。在定制的PULPissimo片上系统上，每张图像的能耗仅为5.31微焦耳，相比传统视频胶囊，可节省89.9%的能量。这显著提升了胃肠道检查的效率和可行性。", "keywords": "视频胶囊内窥镜, 原始图像处理, 节能AI, 边缘计算, CNN", "comments": "该论文的创新点在于直接在原始拜耳图像上进行AI处理，避免了耗能的RGB转换，并结合了小型化CNN和时序分析，实现了在极低功耗边缘设备（如视频胶囊）上的高效部署。这种方法对于延长医疗设备的电池寿命和实现实时诊断具有重要意义。其贡献在于为资源受限的嵌入式AI应用提供了一个实用的解决方案，特别是在医疗领域。"}}
{"id": "2507.23207", "title": "Improved Analysis of Khatri-Rao Random Projections and Applications", "authors": ["Arvind K. Saibaba", "Bhisham Dev Verma", "Grey Ballard"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      27 pages and 4 figures", "url": "http://arxiv.org/abs/2507.23207v1", "summary": "Randomization has emerged as a powerful set of tools for large-scale matrix\nand tensor decompositions. Randomized algorithms involve computing sketches\nwith random matrices. A prevalent approach is to take the random matrix as a\nstandard Gaussian random matrix, for which the theory is well developed.\nHowever, this approach has the drawback that the cost of generating and\nmultiplying by the random matrix can be prohibitively expensive. Khatri-Rao\nrandom projections (KRPs), obtained by sketching with Khatri-Rao products of\nrandom matrices, offer a viable alternative and are much cheaper to generate.\nHowever, the theoretical guarantees of using KRPs are much more pessimistic\ncompared to their accuracy observed in practice. We attempt to close this gap\nby obtaining improved analysis of the use of KRPs in matrix and tensor low-rank\ndecompositions. We propose and analyze a new algorithm for low-rank\napproximations of block-structured matrices (e.g., block Hankel) using KRPs. We\nalso develop new algorithms to accelerate tensor computations in the Tucker\nformat using KRPs, and give theoretical guarantees of the resulting low-rank\napproximations. Numerical experiments on synthetic and real-world tensors show\nthe computational benefits of the proposed methods.", "comment": "27 pages and 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.23207v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Khatri-Rao随机投影的改进分析及应用", "tldr": "本文改进了Khatri-Rao随机投影（KRPs）的理论分析，提出了使用KRPs进行低秩矩阵和张量分解的新算法，并证明了其计算优势。", "motivation": "现有的随机矩阵分解方法（如高斯随机矩阵）计算成本过高。Khatri-Rao随机投影（KRPs）虽然成本较低且实践效果好，但其理论保证远低于实际观察到的准确性，存在理论与实践的差距。", "method": "1. 提出了并分析了一种使用KRPs对块结构矩阵（例如，块Hankel）进行低秩近似的新算法。2. 开发了新的算法，利用KRPs加速Tucker格式的张量计算。", "result": "获得了KRPs在矩阵和张量低秩分解中使用的改进分析。提出的方法能够提供低秩近似的理论保证。数值实验表明，所提出的方法具有计算优势。", "conclusion": "本文通过改进KRPs的理论分析，弥合了其理论保证与实际表现之间的差距，并提出了利用KRPs进行低秩矩阵和张量分解的新算法，这些算法在计算上更高效并具有理论保证。", "translation": "随机化已成为大规模矩阵和张量分解的强大工具集。随机算法涉及使用随机矩阵进行速写计算。一种普遍的方法是使用标准高斯随机矩阵，其理论已发展完善。然而，这种方法的缺点是生成和乘以随机矩阵的成本可能高得令人望而却步。Khatri-Rao随机投影（KRPs），通过使用随机矩阵的Khatri-Rao乘积进行速写获得，提供了一种可行的替代方案，并且生成成本低得多。然而，与实践中观察到的准确性相比，使用KRPs的理论保证要悲观得多。我们试图通过对KRPs在矩阵和张量低秩分解中的使用进行改进分析来弥合这一差距。我们提出并分析了一种使用KRPs对块结构矩阵（例如，块Hankel）进行低秩近似的新算法。我们还开发了新的算法，利用KRPs加速Tucker格式的张量计算，并给出了所得低秩近似的理论保证。在合成和真实世界张量上的数值实验表明了所提出方法的计算优势。", "summary": "本文针对Khatri-Rao随机投影（KRPs）在矩阵和张量低秩分解中理论保证与实践准确性之间的差距，进行了改进分析。研究提出了两种新算法：一种是利用KRPs对块结构矩阵进行低秩近似，另一种是加速Tucker格式张量计算。这些方法不仅提供了理论保证，而且通过数值实验证明了其计算效率。", "keywords": "Khatri-Rao随机投影, 低秩分解, 张量计算, 随机算法, 理论分析", "comments": "本文的创新点在于改进了Khatri-Rao随机投影的理论分析，从而弥合了其理论与实践性能之间的差距。此外，它还提出了利用KRPs处理块结构矩阵和加速张量计算的新算法，这对于大规模数据处理中的低秩分解具有重要意义，因为它提供了更经济高效且具有理论保证的替代方案。"}}
{"id": "2507.22530", "title": "HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors", "authors": ["Xincheng Yao", "Yijun Yang", "Kangwei Guo", "Ruiqiang Xiao", "Haipeng Zhou", "Haisu Tao", "Jian Yang", "Lei Zhu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MICCAI 2025", "url": "http://arxiv.org/abs/2507.22530v2", "summary": "The segmentation of the hepatic vasculature in surgical videos holds\nsubstantial clinical significance in the context of hepatectomy procedures.\nHowever, owing to the dearth of an appropriate dataset and the inherently\ncomplex task characteristics, few researches have been reported in this domain.\nTo address this issue, we first introduce a high quality frame-by-frame\nannotated hepatic vasculature dataset containing 35 long hepatectomy videos and\n11442 high-resolution frames. On this basis, we propose a novel high-resolution\nvideo vasculature segmentation network, dubbed as HRVVS. We innovatively embed\na pretrained visual autoregressive modeling (VAR) model into different layers\nof the hierarchical encoder as prior information to reduce the information\ndegradation generated during the downsampling process. In addition, we designed\na dynamic memory decoder on a multi-view segmentation network to minimize the\ntransmission of redundant information while preserving more details between\nframes. Extensive experiments on surgical video datasets demonstrate that our\nproposed HRVVS significantly outperforms the state-of-the-art methods. The\nsource code and dataset will be publicly available at\n\\{https://github.com/scott-yjyang/HRVVS}.", "comment": "Accepted by MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.22530v2", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "HRVVS：一种基于分层自回归残差先验的高分辨率视频血管分割网络", "tldr": "本文提出了HRVVS，一个用于肝脏血管分割的高分辨率视频网络，并通过引入新的高质量数据集和创新的网络结构，显著提升了分割性能。", "motivation": "在肝切除手术中，肝脏血管的分割具有重要的临床意义，但由于缺乏合适的数据集和任务本身的复杂性，该领域的研究较少。", "method": "本文首先构建了一个包含35个肝切除手术视频和11442帧高分辨率图像的高质量肝脏血管数据集。在此基础上，提出了HRVVS高分辨率视频血管分割网络。该网络创新性地将预训练的视觉自回归建模（VAR）模型作为先验信息嵌入到分层编码器的不同层中，以减少下采样过程中产生的信息退化。此外，还设计了一个基于多视图分割网络的动态记忆解码器，以在保留帧间更多细节的同时，最大限度地减少冗余信息的传输。", "result": "在手术视频数据集上的大量实验表明，所提出的HRVVS显著优于现有最先进的方法。", "conclusion": "HRVVS网络通过引入高质量数据集和创新的结构设计，有效解决了肝脏血管分割的挑战，并取得了优于现有方法的性能。", "translation": "HRVVS：一种基于分层自回归残差先验的高分辨率视频血管分割网络\n\n抽象：\n在肝切除手术中，手术视频中肝脏血管的分割具有重要的临床意义。然而，由于缺乏合适的数据集和任务固有的复杂性，该领域的研究报道很少。为了解决这个问题，我们首先引入了一个高质量的逐帧标注的肝脏血管数据集，其中包含35个长肝切除手术视频和11442帧高分辨率图像。在此基础上，我们提出了一种新颖的高分辨率视频血管分割网络，命名为HRVVS。我们创新性地将预训练的视觉自回归建模（VAR）模型作为先验信息嵌入到分层编码器的不同层中，以减少下采样过程中产生的信息退化。此外，我们设计了一个基于多视图分割网络的动态记忆解码器，以在保留帧间更多细节的同时，最大限度地减少冗余信息的传输。在手术视频数据集上的大量实验表明，我们提出的HRVVS显著优于现有最先进的方法。源代码和数据集将在{https://github.com/scott-yjyang/HRVVS}公开。", "summary": "本文针对肝切除手术中肝脏血管分割的挑战，首先构建了一个包含高质量逐帧标注的肝脏血管数据集。在此基础上，提出了一种名为HRVVS的高分辨率视频血管分割网络。HRVVS通过将预训练的视觉自回归建模作为先验信息嵌入到分层编码器中，以减少信息退化，并设计了动态记忆解码器以保留帧间细节并减少冗余信息。实验证明，HRVVS在手术视频数据集上显著优于现有先进方法。", "keywords": "血管分割, 高分辨率视频, 自回归建模, 肝切除术, 深度学习", "comments": "该论文的创新点在于构建了高质量的大规模肝脏血管分割数据集，并提出了HRVVS网络，通过引入视觉自回归建模作为先验信息和设计动态记忆解码器，有效解决了高分辨率视频血管分割中信息退化和冗余传输的问题，对于肝脏手术的精确导航具有重要意义。"}}
{"id": "2507.23091", "title": "Moravec's Paradox: Towards an Auditory Turing Test", "authors": ["David Noever", "Forrest McKee"], "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23091v1", "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23091v1", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "莫拉维克悖论：迈向听觉图灵测试", "tldr": "当前AI系统在人类轻松完成的听觉任务上表现糟糕。研究引入了一个包含917个挑战的听觉图灵测试，评估了包括GPT-4和Whisper在内的SOTA音频模型，发现其失败率超过93%，远低于人类表现。这揭示了AI在复杂听觉场景处理（如选择性注意力、噪声鲁棒性和上下文适应）方面的缺陷，并强调了开发新方法以实现类人听觉的必要性。", "motivation": "本研究旨在证明当前AI系统在人类轻松完成的听觉任务上表现极差，并受莫拉维克悖论启发，量化人机听觉差距，揭示AI在处理复杂听觉场景时的缺陷。", "method": "研究引入了一个包含917个挑战的听觉图灵测试，涵盖七个类别：重叠语音、噪声中语音、时间失真、空间音频、咖啡馆噪声、电话失真和感知错觉。研究评估了包括GPT-4音频能力和OpenAI Whisper在内的最先进音频模型。", "result": "评估结果显示，最先进的音频模型（包括GPT-4和Whisper）在听觉图灵测试上的失败率超过93%，即使表现最好的模型也仅达到6.9%的准确率，而人类在此类任务上的成功率高达52%。这表明AI系统在处理复杂听觉场景时存在选择性注意力、噪声鲁棒性和上下文适应方面的失败。", "conclusion": "当前AI系统在听觉任务上与人类存在显著差距，现有架构缺乏类人听觉场景分析的基本机制。本研究建立了一个诊断框架来衡量机器听觉向人类水平发展的进展，并强调了将选择性注意力、基于物理的音频理解和上下文感知集成到多模态AI系统中的必要性。", "translation": "这项研究工作表明，当前的人工智能系统在人类轻松完成的听觉任务上遭遇了灾难性的失败。受莫拉维克悖论（即对人类来说简单的任务对机器而言往往很难，反之亦然）的启发，我们引入了一项听觉图灵测试，其中包括七个类别共917项挑战：重叠语音、噪声中语音、时间失真、空间音频、咖啡馆噪声、电话失真和感知错觉。我们对包括GPT-4的音频能力和OpenAI的Whisper在内的最先进音频模型进行的评估显示，其失败率惊人地超过93%，即使是表现最好的模型在人类成功率高出7.5倍（52%）的任务上，也仅取得了6.9%的准确率。这些结果揭示了AI系统在处理复杂听觉场景时存在的焦点失败，特别是在选择性注意力、噪声鲁棒性和上下文适应方面。我们的基准测试不仅量化了人机听觉差距，还提供了关于这些失败为何发生的见解，表明当前的架构缺乏类人听觉场景分析的基本机制。传统音频验证码的设计突出了人类进化出的常见过滤器，而机器在多模态语言模型中未能选择这些过滤器。这项工作建立了一个诊断框架，用于衡量机器听觉向人类水平发展的进展，并强调了将选择性注意力、基于物理的音频理解和上下文感知整合到多模态AI系统中的新方法的需求。", "summary": "本研究揭示了当前AI系统在复杂听觉任务上与人类表现的巨大差距。受莫拉维克悖论启发，研究构建了一个包含917个挑战的听觉图灵测试，并评估了SOTA音频模型（包括GPT-4和Whisper）。结果显示，AI模型在这些任务上的失败率超过93%，远低于人类水平，暴露出AI在选择性注意力、噪声鲁棒性及上下文适应方面的缺陷。本工作不仅量化了人机听觉鸿沟，还提出了需要开发整合选择性注意力、物理声学理解和上下文感知的新型多模态AI方法。", "keywords": "莫拉维克悖论, 听觉图灵测试, 机器听觉, 选择性注意力, 多模态AI", "comments": "本论文通过构建一个全面的听觉图灵测试，创新性地量化了当前AI系统在复杂听觉任务上的不足。它明确指出了现有模型在选择性注意力、噪声鲁棒性和上下文适应方面的局限性，这些是实现类人听觉的关键挑战。这项工作为未来研究提供了重要的诊断框架和方向，强调了开发更接近人类听觉处理机制的新型多模态AI架构的紧迫性。"}}
{"id": "2507.23640", "title": "An Empirical Study on the Amount of Changes Required for Merge Request Acceptance", "authors": ["Samah Kansab", "Mohammed Sayagh", "Francis Bordeleau", "Ali Tizghadam"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23640v1", "summary": "Code review (CR) is essential to software development, helping ensure that\nnew code is properly integrated. However, the CR process often involves\nsignificant effort, including code adjustments, responses to reviewers, and\ncontinued implementation. While past studies have examined CR delays and\niteration counts, few have investigated the effort based on the volume of code\nchanges required, especially in the context of GitLab Merge Requests (MRs),\nwhich remains underexplored. In this paper, we define and measure CR effort as\nthe amount of code modified after submission, using a dataset of over 23,600\nMRs from four GitLab projects. We find that up to 71% of MRs require\nadjustments after submission, and 28% of these involve changes to more than 200\nlines of code. Surprisingly, this effort is not correlated with review time or\nthe number of participants. To better understand and predict CR effort, we\ntrain an interpretable machine learning model using metrics across multiple\ndimensions: text features, code complexity, developer experience, review\nhistory, and branching. Our model achieves strong performance (AUC 0.84-0.88)\nand reveals that complexity, experience, and text features are key predictors.\nHistorical project characteristics also influence current review effort. Our\nfindings highlight the feasibility of using machine learning to explain and\nanticipate the effort needed to integrate code changes during review.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23640v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "合并请求接受所需更改量的实证研究", "tldr": "本研究量化了GitLab合并请求中代码审查的修改工作量，发现高达71%的请求在提交后需要调整，且与审查时间或参与者数量无关。研究还训练了一个机器学习模型来预测此工作量，发现代码复杂性、开发者经验和文本特征是关键预测因子。", "motivation": "代码审查(CR)是软件开发中的重要环节，但其涉及大量的努力，包括代码调整。以往的研究多关注CR的延迟和迭代次数，但很少有研究深入探讨基于代码修改量的审查工作量，特别是在GitLab合并请求(MRs)的背景下，这方面仍未被充分探索。", "method": "本研究将CR工作量定义为提交后修改的代码量，并使用了来自四个GitLab项目的超过23,600个MRs数据集进行测量。为了更好地理解和预测CR工作量，研究训练了一个可解释的机器学习模型，该模型使用了多维度指标，包括文本特征、代码复杂性、开发者经验、审查历史和分支信息。", "result": "研究发现，高达71%的MRs在提交后需要调整，其中28%涉及超过200行代码的更改。令人惊讶的是，这种工作量与审查时间或参与者数量无关。机器学习模型表现出强大的性能（AUC 0.84-0.88），并揭示复杂性、经验和文本特征是关键预测因子。历史项目特征也影响当前的审查工作量。", "conclusion": "研究结果突显了使用机器学习来解释和预测代码审查期间整合代码更改所需工作量的可行性。此发现有助于更好地理解和管理软件开发中的代码审查过程。", "translation": "代码审查（CR）对于软件开发至关重要，有助于确保新代码的正确集成。然而，CR过程通常涉及大量的精力，包括代码调整、对审阅者的回应以及持续的实现。虽然过去的研究已经检查了CR延迟和迭代次数，但很少有研究调查基于所需代码更改量的努力，特别是在GitLab合并请求（MRs）的背景下，这仍然未被充分探索。在本文中，我们使用来自四个GitLab项目的23,600多个MRs数据集，将CR努力定义并测量为提交后修改的代码量。我们发现高达71%的MRs在提交后需要调整，其中28%涉及超过200行代码的更改。令人惊讶的是，这种努力与审查时间或参与者数量无关。为了更好地理解和预测CR努力，我们使用跨多个维度（文本特征、代码复杂性、开发者经验、审查历史和分支）的指标训练了一个可解释的机器学习模型。我们的模型取得了强大的性能（AUC 0.84-0.88），并揭示了复杂性、经验和文本特征是关键预测因子。历史项目特征也影响当前的审查努力。我们的发现突显了使用机器学习来解释和预测审查期间整合代码更改所需努力的可行性。", "summary": "本研究对GitLab合并请求中的代码审查工作量进行了实证分析。通过定义和测量提交后修改的代码量，研究发现大部分合并请求都需要后续调整，且工作量与审查时间或参与者数量无关。论文进一步构建了一个机器学习模型来预测此工作量，并识别出代码复杂性、开发者经验和文本特征为主要影响因素，验证了机器学习在预测代码审查工作量方面的潜力。", "keywords": "代码审查, 合并请求, 工作量预测, 机器学习, GitLab", "comments": "这项研究通过量化和预测代码审查中的实际修改工作量，填补了现有研究的空白。其创新之处在于将CR工作量定义为代码修改量，并应用机器学习模型进行预测。研究发现工作量与审查时间、参与者无关，这颠覆了传统认知，具有重要的实践指导意义。此外，模型的可解释性也提高了其在实际应用中的价值。"}}
{"id": "2404.18154", "title": "Explaining vague language", "authors": ["Paul Égré", "Benjamin Spector"], "categories": ["cs.CL", "cs.GT", "cs.IT", "math.IT", "91A86", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.18154v2", "summary": "Why is language vague? Vagueness may be explained and rationalized if it can\nbe shown that vague language is more useful to speaker and hearer than precise\nlanguage. In a well-known paper, Lipman proposes a game-theoretic account of\nvagueness in terms of mixed strategy that leads to a puzzle: vagueness cannot\nbe strictly better than precision at equilibrium. More recently, \\'Egr\\'e,\nSpector, Mortier and Verheyen have put forward a Bayesian account of vagueness\nestablishing that using vague words can be strictly more informative than using\nprecise words. This paper proposes to compare both results and to explain why\nthey are not in contradiction. Lipman's definition of vagueness relies\nexclusively on a property of signaling strategies, without making any\nassumptions about the lexicon, whereas \\'Egr\\'e et al.'s involves a layer of\nsemantic content. We argue that the semantic account of vagueness is needed,\nand more adequate and explanatory of vagueness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.18154v2", "cate": "cs.CL", "date": "2024-04-28", "updated": "2025-07-31", "AI": {"title_translation": "解释模糊语言", "tldr": "本文比较了两种关于模糊语言的理论（博弈论和贝叶斯理论），并论证了语义解释对于理解模糊性是必需且更恰当的。", "motivation": "探讨语言为何模糊，以及模糊语言是否比精确语言对说话者和听话者更有用。特别是针对Lipman的博弈论解释中模糊性不优于精确性的难题。", "method": "本文比较了Lipman的博弈论解释和'Egr'e et al.的贝叶斯解释，并分析了它们不矛盾的原因，通过区分信号策略和语义内容来论证。", "result": "解释了Lipman和'Egr'e et al.的两种模糊语言解释为何不矛盾，并指出模糊性的语义解释更具解释力且是必需的。", "conclusion": "语义层面的模糊性解释是理解模糊语言的必要且更恰当的理论。", "translation": "语言为何模糊？如果能证明模糊语言比精确语言对说话者和听话者更有用，那么模糊性就可以得到解释和合理化。在一篇著名的论文中，Lipman提出了一个关于模糊性的博弈论解释，以混合策略的形式呈现，但这导致了一个难题：在均衡状态下，模糊性不可能严格优于精确性。最近，'Egr'e、Spector、Mortier和Verheyen提出了一个贝叶斯解释，确立了使用模糊词语可以比使用精确词语提供更多信息。本文旨在比较这两种结果，并解释它们为何不矛盾。Lipman对模糊性的定义完全依赖于信号策略的一个属性，没有对词汇做任何假设，而'Egr'e等人则涉及一个语义内容层。我们认为，模糊性的语义解释是必需的，并且更充分、更能解释模糊性。", "summary": "本文旨在探讨语言模糊性的原因，并比较了两种主要的解释：Lipman基于博弈论的信号策略方法，以及'Egr'e等人基于贝叶斯理论的语义内容方法。针对Lipman理论中模糊性在均衡时不优于精确性的难题，文章阐明了两种理论并不矛盾，其关键在于对模糊性定义的不同侧重。最终，论文论证了引入语义内容的模糊性解释对于理解模糊语言是必要且更具解释力的。", "keywords": "模糊语言, 博弈论, 贝叶斯理论, 语义学, 信号策略", "comments": "本文通过对比分析两种关于模糊语言的理论，巧妙地解决了它们之间的表观矛盾，并提出了一个更全面的语义解释框架。其创新之处在于区分了信号策略和语义内容在模糊性解释中的作用，强调了语义层面的重要性，为理解语言的实用性和信息传递效率提供了新的视角。"}}
{"id": "2507.23266", "title": "CUHK-EE Systems for the vTAD Challenge at NCMMSC 2025", "authors": ["Aemon Yat Fei Chiu", "Jingyu Li", "Yusheng Tian", "Guangyan Zhang", "Tan Lee"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.23266v1", "summary": "This paper presents the Voice Timbre Attribute Detection (vTAD) systems\ndeveloped by the Digital Signal Processing & Speech Technology Laboratory\n(DSP&STL) of the Department of Electronic Engineering (EE) at The Chinese\nUniversity of Hong Kong (CUHK) for the 20th National Conference on\nHuman-Computer Speech Communication (NCMMSC 2025) vTAD Challenge. The proposed\nsystems leverage WavLM-Large embeddings with attentive statistical pooling to\nextract robust speaker representations, followed by two variants of Diff-Net,\ni.e., Feed-Forward Neural Network (FFN) and Squeeze-and-Excitation-enhanced\nResidual FFN (SE-ResFFN), to compare timbre attribute intensities between\nutterance pairs. Experimental results demonstrate that the WavLM-Large+FFN\nsystem generalises better to unseen speakers, achieving 77.96% accuracy and\n21.79% EER, while the WavLM-Large+SE-ResFFN model excels in the 'Seen' setting\nwith 94.42% accuracy and 5.49% EER. These findings highlight a trade-off\nbetween model complexity and generalisation, and underscore the importance of\narchitectural choices in fine-grained speaker modelling. Our analysis also\nreveals the impact of speaker identity, annotation subjectivity, and data\nimbalance on system performance, pointing to future directions for improving\nrobustness and fairness in timbre attribute detection.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.23266v1", "cate": "eess.AS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "香港中文大学电子工程系针对NCMMSC 2025 vTAD挑战的系统", "tldr": "本文介绍了香港中文大学电子工程系为NCMMSC 2025 vTAD挑战开发的语音音色属性检测系统，该系统利用WavLM-Large嵌入和两种Diff-Net变体（FFN和SE-ResFFN）。研究结果揭示了模型复杂性和泛化能力之间的权衡，并指出了影响系统性能的因素和未来改进方向。", "motivation": "为NCMMSC 2025语音音色属性检测（vTAD）挑战开发系统。", "method": "该系统利用WavLM-Large嵌入和注意力统计池化来提取鲁棒的说话人表示，随后使用两种Diff-Net变体：前馈神经网络（FFN）和挤压-激励增强残差FFN（SE-ResFFN），以比较话语对之间的音色属性强度。", "result": "WavLM-Large+FFN系统对未见过说话人表现出更好的泛化能力，准确率为77.96%，EER为21.79%。WavLM-Large+SE-ResFFN模型在“已见”设置中表现出色，准确率为94.42%，EER为5.49%。", "conclusion": "研究结果揭示了模型复杂性和泛化能力之间的权衡，并强调了架构选择在细粒度说话人建模中的重要性。分析还揭示了说话人身份、标注主观性和数据不平衡对系统性能的影响，为未来提高音色属性检测的鲁棒性和公平性指明了方向。", "translation": "本文介绍了香港中文大学电子工程系（EE）数字信号处理与语音技术实验室（DSP&STL）为第20届全国人机语音通讯学术会议（NCMMSC 2025）vTAD挑战开发的语音音色属性检测（vTAD）系统。所提出的系统利用WavLM-Large嵌入和注意力统计池化来提取鲁棒的说话人表示，随后使用两种Diff-Net变体，即前馈神经网络（FFN）和挤压-激励增强残差FFN（SE-ResFFN），以比较话语对之间的音色属性强度。实验结果表明，WavLM-Large+FFN系统对未见过说话人表现出更好的泛化能力，准确率为77.96%，EER为21.79%，而WavLM-Large+SE-ResFFN模型在“已见”设置中表现出色，准确率为94.42%，EER为5.49%。这些发现突出了模型复杂性和泛化能力之间的权衡，并强调了架构选择在细粒度说话人建模中的重要性。我们的分析还揭示了说话人身份、标注主观性和数据不平衡对系统性能的影响，为未来提高音色属性检测的鲁棒性和公平性指明了方向。", "summary": "本文详细介绍了香港中文大学电子工程系为NCMMSC 2025 vTAD挑战开发的语音音色属性检测（vTAD）系统。该系统采用WavLM-Large嵌入和注意力统计池化来提取说话人表示，并利用前馈神经网络（FFN）和挤压-激励增强残差FFN（SE-ResFFN）两种Diff-Net变体来比较音色属性强度。实验结果表明，FFN在未见说话人场景下泛化能力更强，而SE-ResFFN在已见说话人场景下性能更优，这揭示了模型复杂性与泛化能力之间的权衡。研究还指出了说话人身份、标注主观性和数据不平衡等因素对系统性能的影响，为未来提升音色属性检测的鲁棒性和公平性提供了指导。", "keywords": "语音音色属性检测, WavLM-Large, Diff-Net, 说话人建模, NCMMSC挑战", "comments": "该论文为vTAD挑战提出了一个有竞争力的系统，有效地利用了先进的嵌入技术和神经网络架构。论文明确讨论了模型复杂性与泛化能力之间的权衡，并识别了现实世界中的挑战（如说话人身份、标注主观性和数据不平衡），这通过指出细粒度说话人建模中的实际限制和未来研究方向，增加了重要的价值。"}}
{"id": "2507.22782", "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies", "authors": ["Hugo Garrido-Lestache", "Jeremy Kedziora"], "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.22782v2", "summary": "This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps).", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.22782v2", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "利用基于注意力的Actor-Critic策略增强多智能体协作", "tldr": "本文提出TAAC，一种新颖的强化学习算法，通过注意力机制和惩罚损失函数增强多智能体协作，并在模拟足球环境中表现出优异性能。", "motivation": "在合作环境中增强多智能体协作，并有效管理联合动作空间的指数级增长。", "method": "本文引入了Team-Attention-Actor-Critic (TAAC)算法，该算法采用集中式训练/集中式执行方案。TAAC在actor和critic中都融入了多头注意力机制，以促进动态的智能体间通信，从而允许智能体明确查询队友。此外，TA文还引入了一个惩罚损失函数，以促进智能体之间多样化而互补的角色。该方法在模拟足球环境中与PPO和MAAAC等基准算法进行了评估。", "result": "TAAC在模拟足球环境中表现出优异的性能和增强的协作行为，具体体现在胜率、净胜球、Elo等级、智能体间连接性、平衡的空间分布以及频繁的战术互动（如控球权交换）等多种指标上。", "conclusion": "TAAC算法通过其独特的注意力机制和惩罚损失函数，显著提升了多智能体在合作环境中的协作能力和整体性能。", "translation": "本文介绍了Team-Attention-Actor-Critic (TAAC)，一种旨在增强合作环境中多智能体协作的强化学习算法。TAAC采用集中式训练/集中式执行方案，在actor和critic中均融入了多头注意力机制。这种设计促进了动态的智能体间通信，允许智能体明确查询队友，从而有效管理联合动作空间的指数级增长，同时确保高度协作。我们进一步引入了一个惩罚损失函数，以促进智能体之间多样化而互补的角色。我们在模拟足球环境中，针对代表其他多智能体范式的基准算法（包括近端策略优化和多智能体Actor-Attention-Critic）评估了TAAC。我们发现TAAC在各种指标（胜率、净胜球、Elo等级、智能体间连接性、平衡的空间分布以及频繁的战术互动，如控球权交换）上均表现出卓越的性能和增强的协作行为。", "summary": "本文提出了一种名为Team-Attention-Actor-Critic (TAAC)的强化学习算法，旨在提升合作式多智能体环境中的协作效率。TAAC通过在actor和critic中集成多头注意力机制，实现了集中式训练/执行下的动态智能体间通信，有效管理了联合动作空间。此外，算法引入惩罚损失函数以鼓励智能体扮演多样化且互补的角色。在模拟足球环境中的评估结果显示，TAAC相比其他基准算法，在多项协作和性能指标上均表现出卓越的性能和更强的协作行为。", "keywords": "多智能体协作, 注意力机制, Actor-Critic, 强化学习, TAAC", "comments": "本文提出的TAAC算法通过结合多头注意力机制和惩罚损失函数，在多智能体协作方面展现了创新性。注意力机制促进了智能体间的显式通信，而惩罚损失函数则有助于形成多样化的角色分工，这对于复杂协作任务至关重要。其在模拟足球环境中的优异表现证明了该方法的有效性，为多智能体强化学习领域提供了有价值的贡献。"}}
{"id": "2507.22789", "title": "G-Core: A Simple, Scalable and Balanced RLHF Trainer", "authors": ["Junyu Wu", "Weiming Chang", "Xiaotao Liu", "Guanyou He", "Haoqiang Hong", "Boqi Liu", "Hongtao Tian", "Tao Yang", "Yunsheng Shi", "Feng Lin", "Ting Yao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      I haven't received company approval yet, and I uploaded it by mistake", "url": "http://arxiv.org/abs/2507.22789v2", "summary": "Reinforcement Learning from Human Feedback (RLHF) has become an increasingly\npopular paradigm for training large language models (LLMs) and diffusion\nmodels. While existing RLHF training systems have enabled significant progress,\nthey often face challenges in scaling to multi-modal and diffusion workflows\nand adapting to dynamic workloads. In particular, current approaches may\nencounter limitations in controller scalability, flexible resource placement,\nand efficient orchestration when handling complex RLHF pipelines, especially in\nscenarios involving dynamic sampling or generative reward modeling. In this\npaper, we present \\textbf{G-Core}, a simple, scalable, and balanced RLHF\ntraining framework designed to address these challenges. G-Core introduces a\nparallel controller programming model, enabling flexible and efficient\norchestration of complex RLHF workflows without the bottlenecks of a single\ncentralized controller. Furthermore, we propose a dynamic placement schema that\nadaptively partitions resources and schedules workloads, significantly reducing\nhardware idle time and improving utilization, even under highly variable\ntraining conditions. G-Core has successfully trained models that support WeChat\nproduct features serving a large-scale user base, demonstrating its\neffectiveness and robustness in real-world scenarios. Our results show that\nG-Core advances the state of the art in RLHF training, providing a solid\nfoundation for future research and deployment of large-scale, human-aligned\nmodels.", "comment": "I haven't received company approval yet, and I uploaded it by mistake", "pdf_url": "http://arxiv.org/pdf/2507.22789v2", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "G-Core：一个简单、可扩展且平衡的RLHF训练器", "tldr": "G-Core是一个新的RLHF训练框架，通过并行控制器和动态资源分配解决了现有RLHF系统在可扩展性、资源管理和编排方面的挑战，实现了高效且平衡的训练。", "motivation": "现有RLHF训练系统在扩展到多模态和扩散工作流以及适应动态工作负载时面临挑战，尤其在控制器可扩展性、灵活资源放置和高效编排方面存在局限性。", "method": "G-Core引入了并行控制器编程模型，实现了复杂RLHF工作流的灵活高效编排，并提出了动态放置方案，自适应地划分资源和调度工作负载。", "result": "G-Core成功训练了支持微信产品功能的大规模用户基础模型，显著减少了硬件空闲时间并提高了利用率，即使在高度可变的训练条件下也能表现出色。", "conclusion": "G-Core提升了RLHF训练的现有技术水平，为未来大规模、人类对齐模型的研发和部署奠定了坚实基础。", "translation": "来自人类反馈的强化学习（RLHF）已成为训练大型语言模型（LLM）和扩散模型越来越流行的范式。尽管现有的RLHF训练系统取得了显著进展，但它们在扩展到多模态和扩散工作流以及适应动态工作负载时经常面临挑战。特别是，当前方法在处理复杂的RLHF管道时可能会遇到控制器可扩展性、灵活资源放置和高效编排方面的限制，尤其是在涉及动态采样或生成奖励建模的场景中。在本文中，我们提出了G-Core，一个简单、可扩展且平衡的RLHF训练框架，旨在解决这些挑战。G-Core引入了一个并行控制器编程模型，实现了复杂RLHF工作流的灵活高效编排，避免了单一集中式控制器的瓶颈。此外，我们提出了一种动态放置方案，自适应地划分资源和调度工作负载，显著减少了硬件空闲时间并提高了利用率，即使在高度可变的训练条件下也是如此。G-Core已成功训练了支持微信产品功能并服务于大规模用户群体的模型，展示了其在实际场景中的有效性和鲁棒性。我们的结果表明，G-Core提升了RLHF训练的现有技术水平，为未来大规模、人类对齐模型的研发和部署提供了坚实的基础。", "summary": "G-Core是一个为解决现有RLHF训练系统在可扩展性和资源管理方面挑战而设计的新框架。它通过并行控制器编程模型和动态资源放置方案，实现了复杂RLHF工作流的高效编排和资源优化，显著提高了硬件利用率并减少了空闲时间。G-Core已成功应用于微信产品，验证了其在实际大规模场景中的有效性和鲁棒性。", "keywords": "RLHF, 大语言模型, 扩散模型, 训练框架, 可扩展性", "comments": "G-Core的创新点在于其并行控制器编程模型和动态资源放置方案，有效解决了传统RLHF系统在可扩展性和资源利用率方面的瓶颈，尤其适用于动态和大规模的训练场景。其在微信实际产品中的成功应用案例增强了其重要性和实用性。"}}
{"id": "2505.14422", "title": "MindVote: When AI Meets the Wild West of Social Media Opinion", "authors": ["Xutao Mao", "Ezra Xuanru Tao", "Leyao Wang"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.14422v3", "summary": "Large Language Models (LLMs) are increasingly used as scalable tools for\npilot testing, predicting public opinion distributions before deploying costly\nsurveys. To serve as effective pilot testing tools, the performance of these\nLLMs is typically benchmarked against their ability to reproduce the outcomes\nof past structured surveys. This evaluation paradigm, however, is misaligned\nwith the dynamic, context-rich social media environments where public opinion\nis increasingly formed and expressed. By design, surveys strip away the social,\ncultural, and temporal context that shapes public opinion, and LLM benchmarks\nbuilt on this paradigm inherit these critical limitations. To bridge this gap,\nwe introduce MindVote, the first benchmark for public opinion distribution\nprediction grounded in authentic social media discourse. MindVote is\nconstructed from 3,918 naturalistic polls sourced from Reddit and Weibo,\nspanning 23 topics and enriched with detailed annotations for platform,\ntopical, and temporal context. Using this benchmark, we conduct a comprehensive\nevaluation of 15 LLMs. MindVote provides a robust, ecologically valid framework\nto move beyond survey-based evaluations and advance the development of more\nsocially intelligent AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.14422v3", "cate": "cs.SI", "date": "2025-05-20", "updated": "2025-07-31", "AI": {"title_translation": "MindVote：当人工智能遇上社交媒体意见的狂野西部", "tldr": "MindVote是一个新基准，用于在社交媒体语境下预测公众意见分布，解决了当前基于调查的LLM评估的局限性。", "motivation": "当前用于预测公众意见分布的大型语言模型（LLMs）的评估范式，即与过去的结构化调查结果进行基准测试，与公众意见日益形成和表达的动态、语境丰富的社交媒体环境不符。调查剥离了塑造公众意见的社会、文化和时间背景，而基于此范式的LLM基准继承了这些局限性。", "method": "本文引入了MindVote，这是第一个基于真实社交媒体话语的公众意见分布预测基准。MindVote由3,918个来自Reddit和微博的自然民意调查构成，涵盖23个主题，并富含平台、主题和时间背景的详细注释。", "result": "使用MindVote基准，对15个大型语言模型进行了全面的评估。", "conclusion": "MindVote提供了一个强大、生态有效（ecologically valid）的框架，以超越基于调查的评估，并推动更具社会智能的AI系统的发展。", "translation": "大型语言模型（LLMs）正越来越多地被用作可扩展工具，在部署昂贵的调查之前，用于试点测试和预测公众意见分布。为了充当有效的试点测试工具，这些LLMs的性能通常通过其重现过去结构化调查结果的能力进行基准测试。然而，这种评估范式与公众意见日益形成和表达的动态、语境丰富的社交媒体环境不符。从设计上讲，调查剥离了塑造公众意见的社会、文化和时间背景，而基于此范式的LLM基准继承了这些关键限制。为了弥合这一差距，我们引入了MindVote，这是第一个基于真实社交媒体话语的公众意见分布预测基准。MindVote由3,918个来自Reddit和微博的自然民意调查构成，涵盖23个主题，并富含平台、主题和时间背景的详细注释。使用此基准，我们对15个LLMs进行了全面评估。MindVote提供了一个强大、生态有效（ecologically valid）的框架，以超越基于调查的评估，并推动更具社会智能的AI系统的发展。", "summary": "当前大型语言模型（LLMs）在预测公众意见方面主要基于结构化调查进行评估，但这与社交媒体中动态、丰富的意见形成环境脱节。为解决此问题，本文提出了MindVote，一个首个基于Reddit和微博真实社交媒体民意调查构建的公众意见分布预测基准。MindVote包含3,918个民意调查，涵盖23个主题，并详细标注了平台、主题和时间背景。研究者使用此基准对15个LLMs进行了全面评估。MindVote旨在提供一个更具生态有效性的框架，以推动开发更具社会智能的AI系统，超越传统基于调查的评估。", "keywords": "公众意见预测, 大型语言模型, 社交媒体, 基准测试, MindVote", "comments": "本文的创新点在于提出了MindVote这一全新的基准，它首次将大型语言模型对公众意见的预测评估从传统的结构化调查转向了更具真实性和动态性的社交媒体环境。这解决了现有评估范式与实际应用场景脱节的关键问题，为开发更具社会智能、更能理解复杂社会语境的AI系统提供了重要工具和方向。"}}
{"id": "2507.15230", "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "categories": ["cs.DC", "cs.GR"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.15230v3", "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "comment": "Accepted at IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.15230v3", "cate": "cs.DC", "date": "2025-07-21", "updated": "2025-07-30", "AI": {"title_translation": "GALE：利用异构系统进行高效非结构化网格数据分析", "tldr": "GALE提出一种新的任务并行方法，通过将网格连接性计算卸载到GPU，显著加速了非结构化网格数据分析，比现有方法快2.7倍。", "motivation": "非结构化网格数据分析面临挑战，因为其不规则分布和复杂连接性。计算和存储连接性信息是可视化算法的主要瓶颈，影响时间和内存性能。现有任务并行数据结构通过运行时预计算连接性信息来解决，但它们受限于CPU，导致数据结构和分析算法竞争计算资源，限制了加速潜力。", "method": "本文提出一种针对异构CPU-GPU系统优化的新型任务并行方法。具体来说，将网格连接性信息的计算卸载到GPU线程，使CPU线程专注于执行可视化算法。基于此范式，提出了GALE（GPU-Aided Localized data structurE），这是第一个为异构任务并行设计的开源基于CUDA的数据结构。", "result": "在两颗20核CPU和一块NVIDIA V100 GPU上的实验表明，GALE比现有最先进的局部数据结构实现了高达2.7倍的加速，同时保持了内存效率。", "conclusion": "GALE通过利用异构CPU-GPU系统，将网格连接性计算卸载到GPU，有效解决了非结构化网格数据分析中的性能瓶颈，显著提高了可视化算法的速度和效率。", "translation": "非结构化网格由于其不规则分布和复杂连接性，在科学数据分析中带来了挑战。计算和存储连接性信息是可视化算法的主要瓶颈，影响时间和内存性能。最近的任务并行数据结构通过在分析算法执行时运行时预计算连接性信息来解决这个问题，有效地隐藏了计算成本并提高了性能。然而，现有方法受限于CPU，迫使数据结构和分析算法竞争相同的计算资源，从而限制了潜在的加速。为了克服这一限制，我们引入了一种针对异构CPU-GPU系统优化的新型任务并行方法。具体来说，我们将网格连接性信息的计算卸载到GPU线程，使CPU线程能够专注于执行可视化算法。遵循这一范式，我们提出了GALE（GPU-Aided Localized data structurE），这是第一个为异构任务并行设计的开源基于CUDA的数据结构。在两颗20核CPU和一块NVIDIA V100 GPU上的实验表明，GALE比现有最先进的局部数据结构实现了高达2.7倍的加速，同时保持了内存效率。", "summary": "本文提出GALE，一种创新的任务并行数据结构，旨在解决非结构化网格数据分析中由复杂连接性引起的性能瓶颈。GALE通过将网格连接性信息的计算任务从CPU卸载到GPU，使得CPU能够专注于可视化算法的执行。作为首个开源的CUDA异构任务并行数据结构，GALE在实验中展示了相对于现有局部数据结构高达2.7倍的加速，同时保持了内存效率，为大规模科学数据分析提供了高效的解决方案。", "keywords": "非结构化网格, 异构系统, GPU加速, 任务并行, 数据结构", "comments": "GALE的创新之处在于其利用异构计算资源（CPU-GPU）来解决非结构化网格数据分析中的核心瓶颈，即连接性信息的计算。通过将计算密集型任务卸载到GPU，它有效避免了CPU资源竞争，显著提升了性能。作为第一个开源的CUDA异构任务并行数据结构，GALE为该领域的研究和应用奠定了基础，具有重要的实践意义和潜在影响。"}}
{"id": "2507.23088", "title": "Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance", "authors": ["Lalithkumar Seenivasan", "Jiru Xu", "Roger D. Soberanis Mukul", "Hao Ding", "Grayson Byrd", "Yu-Chun Ku", "Jose L. Porras", "Masaru Ishii", "Mathias Unberath"], "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23088v1", "summary": "Emerging surgical data science and robotics solutions, especially those\ndesigned to provide assistance in situ, require natural human-machine\ninterfaces to fully unlock their potential in providing adaptive and intuitive\naid. Contemporary AI-driven solutions remain inherently rigid, offering limited\nflexibility and restricting natural human-machine interaction in dynamic\nsurgical environments. These solutions rely heavily on extensive task-specific\npre-training, fixed object categories, and explicit manual-prompting. This work\nintroduces a novel Perception Agent that leverages speech-integrated\nprompt-engineered large language models (LLMs), segment anything model (SAM),\nand any-point tracking foundation models to enable a more natural human-machine\ninteraction in real-time intraoperative surgical assistance. Incorporating a\nmemory repository and two novel mechanisms for segmenting unseen elements,\nPerception Agent offers the flexibility to segment both known and unseen\nelements in the surgical scene through intuitive interaction. Incorporating the\nability to memorize novel elements for use in future surgeries, this work takes\na marked step towards human-machine symbiosis in surgical procedures. Through\nquantitative analysis on a public dataset, we show that the performance of our\nagent is on par with considerably more labor-intensive manual-prompting\nstrategies. Qualitatively, we show the flexibility of our agent in segmenting\nnovel elements (instruments, phantom grafts, and gauze) in a custom-curated\ndataset. By offering natural human-machine interaction and overcoming rigidity,\nour Perception Agent potentially brings AI-based real-time assistance in\ndynamic surgical environments closer to reality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23088v1", "cate": "cs.RO", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "超越僵硬AI：迈向术中辅助的自然人机共生", "tldr": "本文提出了一种名为“感知代理”（Perception Agent）的新型AI系统，通过整合LLM、SAM等技术，实现了更自然、灵活的术中人机交互，能够识别和记忆新物体，克服了现有AI的僵硬性。", "motivation": "现有AI驱动的术中辅助解决方案过于僵硬，依赖大量预训练、固定类别和手动提示，限制了在动态手术环境中的自然人机交互，未能充分发挥潜力。", "method": "本文引入了一种名为“感知代理”（Perception Agent）的新型系统，它利用语音集成、提示工程的大型语言模型（LLMs）、分割一切模型（SAM）和任意点跟踪基础模型，以在实时术中手术辅助中实现更自然的人机交互。该系统还包含一个记忆库和两种新颖的机制，用于分割未见过的元素，使其能够灵活分割手术场景中的已知和未知元素，并能记忆新颖元素以供未来使用。", "result": "定量分析表明，该代理的性能与劳动密集型的手动提示策略相当。定性分析显示，该代理在自定义数据集中分割新颖元素（器械、幻影移植物和纱布）方面具有灵活性。", "conclusion": "通过提供自然的人机交互并克服僵硬性，感知代理有望使基于AI的动态手术环境中的实时辅助更接近现实。", "translation": "新兴的手术数据科学和机器人解决方案，特别是那些旨在提供原位辅助的方案，需要自然的人机界面才能充分发挥其在提供自适应和直观帮助方面的潜力。当前的AI驱动解决方案本质上是僵硬的，灵活性有限，限制了在动态手术环境中的自然人机交互。这些解决方案严重依赖于广泛的特定任务预训练、固定的对象类别和明确的手动提示。这项工作引入了一种新颖的“感知代理”（Perception Agent），它利用语音集成、提示工程的大型语言模型（LLMs）、分割一切模型（SAM）和任意点跟踪基础模型，以在实时术中手术辅助中实现更自然的人机交互。通过整合一个记忆库和两种新颖的机制来分割未见过的元素，“感知代理”能够通过直观的交互灵活地分割手术场景中的已知和未见过的元素。通过纳入记忆新颖元素以供未来手术使用的能力，这项工作在手术过程中迈向人机共生迈出了显著一步。通过对公共数据集的定量分析，我们表明我们代理的性能与相当劳动密集型的手动提示策略相当。定性地，我们展示了我们的代理在自定义策划数据集中分割新颖元素（器械、幻影移植物和纱布）的灵活性。通过提供自然的人机交互并克服僵硬性，我们的“感知代理”有可能使基于AI的动态手术环境中的实时辅助更接近现实。", "summary": "本文提出“感知代理”（Perception Agent），旨在解决现有手术AI辅助系统僵硬、交互不自然的问题。该代理结合LLMs、SAM等基础模型，并引入记忆和新元素分割机制，实现了更自然、灵活的人机交互。实验证明其性能与手动提示相当，并能有效识别和记忆新物体，推动了手术中AI人机共生。", "keywords": "人机共生, 手术辅助, 感知代理, 大语言模型, 分割一切模型", "comments": "该研究的创新点在于结合了大型语言模型（LLMs）和视觉基础模型（SAM），并引入了记忆和新元素分割能力，极大地增强了AI在动态手术环境中的适应性和交互自然性。这对于实现真正的智能手术辅助具有重要意义，克服了传统AI在识别未见物体和灵活交互方面的局限性。其前景广阔，但实际部署仍需考虑鲁棒性和安全性。"}}
{"id": "2507.23461", "title": "Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection", "authors": ["Taeheon Lim", "Joohyung Lee", "Kyungjae Lee", "Jungchan Cho"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23461v1", "summary": "The Federated Learning (FL) approach enables effective learning across\ndistributed systems, while preserving user data privacy. To date, research has\nprimarily focused on addressing statistical heterogeneity and communication\nefficiency, through which FL has achieved success in classification tasks.\nHowever, its application to non-classification tasks, such as human pose\nestimation, remains underexplored. This paper identifies and investigates a\ncritical issue termed ``resolution-drift,'' where performance degrades\nsignificantly due to resolution variability across clients. Unlike class-level\nheterogeneity, resolution drift highlights the importance of resolution as\nanother axis of not independent or identically distributed (non-IID) data. To\naddress this issue, we present resolution-adaptive federated learning (RAF), a\nmethod that leverages heatmap-based knowledge distillation. Through\nmulti-resolution knowledge distillation between higher-resolution outputs\n(teachers) and lower-resolution outputs (students), our approach enhances\nresolution robustness without overfitting. Extensive experiments and\ntheoretical analysis demonstrate that RAF not only effectively mitigates\nresolution drift and achieves significant performance improvements, but also\ncan be integrated seamlessly into existing FL frameworks. Furthermore, although\nthis paper focuses on human pose estimation, our t-SNE analysis reveals\ndistinct characteristics between classification and high-resolution\nrepresentation tasks, supporting the generalizability of RAF to other tasks\nthat rely on preserving spatial detail.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23461v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "联邦学习中分辨率漂移的缓解：以关键点检测为例", "tldr": "论文提出了RAF方法，通过多分辨率知识蒸馏解决联邦学习在关键点检测等非分类任务中因客户端分辨率差异导致性能下降的问题。", "motivation": "联邦学习在非分类任务（如人体姿态估计）中的应用尚未得到充分探索。本文识别并研究了一个关键问题，即“分辨率漂移”，这导致性能因客户端分辨率差异而显著下降。这与类级别异构性不同，分辨率是另一个非独立同分布（non-IID）数据轴。", "method": "提出了一种名为“分辨率自适应联邦学习（RAF）”的方法。该方法利用基于热图的知识蒸馏，通过高分辨率输出（教师）和低分辨率输出（学生）之间的多分辨率知识蒸馏，在不引起过拟合的情况下增强分辨率鲁棒性。", "result": "广泛的实验和理论分析表明，RAF不仅有效缓解了分辨率漂移，实现了显著的性能提升，而且可以无缝集成到现有联邦学习框架中。t-SNE分析揭示了分类任务和高分辨率表示任务之间的显著特征差异，支持了RAF对其他依赖于保留空间细节的任务的泛化能力。", "conclusion": "RAF方法能够有效缓解联邦学习中非分类任务的分辨率漂移问题，提升性能，并具有良好的通用性。", "translation": "联邦学习（FL）方法能够在分布式系统之间实现有效学习，同时保护用户数据隐私。迄今为止，研究主要集中于通过解决统计异构性和通信效率问题，使FL在分类任务中取得了成功。然而，其在非分类任务（如人体姿态估计）中的应用仍未得到充分探索。本文识别并研究了一个关键问题，即“分辨率漂移”，即由于客户端之间的分辨率可变性导致性能显著下降。与类级别异构性不同，分辨率漂移强调了分辨率作为另一个非独立同分布（non-IID）数据轴的重要性。为了解决这个问题，我们提出了分辨率自适应联邦学习（RAF），这是一种利用基于热图的知识蒸馏的方法。通过高分辨率输出（教师）和低分辨率输出（学生）之间的多分辨率知识蒸馏，我们的方法在不引起过拟合的情况下增强了分辨率鲁棒性。广泛的实验和理论分析表明，RAF不仅有效缓解了分辨率漂移并实现了显著的性能改进，而且可以无缝集成到现有FL框架中。此外，尽管本文侧重于人体姿态估计，但我们的t-SNE分析揭示了分类任务和高分辨率表示任务之间的显著特征差异，支持了RAF对其他依赖于保留空间细节的任务的泛化能力。", "summary": "本文针对联邦学习在关键点检测等非分类任务中面临的分辨率漂移问题，提出了一种名为分辨率自适应联邦学习（RAF）的新方法。RAF利用基于热图的多分辨率知识蒸馏，使模型在不同分辨率数据下具有更强的鲁棒性，有效缓解了因客户端分辨率差异导致的性能下降。实验证明RAF显著提升了性能，并能无缝集成到现有FL框架，同时具有向其他高分辨率表示任务泛化的潜力。", "keywords": "联邦学习, 分辨率漂移, 关键点检测, 知识蒸馏, 非独立同分布", "comments": "该论文创新性地指出了联邦学习在非分类任务中遇到的“分辨率漂移”这一新问题，并提出了基于知识蒸馏的RAF方法来解决。这拓展了联邦学习的应用范围，特别是在需要处理高分辨率空间细节的任务上。其方法易于集成，且通过实验和理论分析验证了有效性和泛化性，具有较高的实用价值和研究意义。"}}
{"id": "2408.10610", "title": "On the Approximation of Stationary Processes using the ARMA Model", "authors": ["Anand Ganesh", "Babhrubahan Bose", "Anand Rajagopalan"], "categories": ["cs.LG", "math.PR", "stat.ME", "60G10", "G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 1 figure", "url": "http://arxiv.org/abs/2408.10610v4", "summary": "We look at a problem related to Autoregressive Moving Average (ARMA) models,\non quantifying the approximation error between a true stationary process $X_t$\nand an ARMA model $Y_t$. We take the transfer function representation $x(L)$ of\na stationary process $X_t$ and show that the $L^{\\infty}$ norm of $x$ acts as a\nvalid norm on $X_t$ that controls the $\\ell^2$ norm of its Wold coefficients.\nWe then show that a certain subspace of stationary processes, which includes\nARMA models, forms a Banach algebra under the $L^{\\infty}$ norm that respects\nthe multiplicative structure of $H^{\\infty}$ transfer functions and thus\nimproves on the structural properties of the cepstral norm for ARMA models. The\nnatural definition of invertibility in this algebra is consistent with the\noriginal definition of ARMA invertibility, and generalizes better to non-ARMA\nprocesses than Wiener's $\\ell^1$ condition. Finally, we calculate some explicit\napproximation bounds in the simpler context of continuous transfer functions,\nand critique some heuristic ideas on Pad\\'e approximations and parsimonious\nmodels.", "comment": "11 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2408.10610v4", "cate": "cs.LG", "date": "2024-08-20", "updated": "2025-07-31", "AI": {"title_translation": "关于使用ARMA模型逼近平稳过程", "tldr": "本文研究了平稳过程与ARMA模型之间的逼近误差量化问题，引入了新的范数，证明了特定平稳过程子空间形成巴拿赫代数，并计算了逼近界限。", "motivation": "量化真实平稳过程与ARMA模型之间的逼近误差，并改进ARMA模型的结构特性。", "method": "作者考察了平稳过程的传递函数表示，并证明了其$L^{\\infty}$范数可以作为控制Wold系数$\\\\ell^2$范数的有效范数。他们进一步证明了包含ARMA模型的特定平稳过程子空间在$L^{\\infty}$范数下形成一个巴拿赫代数，该代数尊重$H^{\\infty}$传递函数的乘法结构。还计算了连续传递函数背景下的显式逼近界限，并批判了Padé逼近和简约模型的一些启发式思想。", "result": "1. $L^{\\infty}$范数可以作为平稳过程$X_t$的有效范数，控制其Wold系数的$\\\\ell^2$范数。2. 包含ARMA模型的特定平稳过程子空间在$L^{\\infty}$范数下形成一个巴拿赫代数，该代数改善了ARMA模型的倒谱范数结构特性。3. 该代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比Wiener的$\\\\ell^1$条件更好地推广到非ARMA过程。4. 计算了连续传递函数背景下的一些显式逼近界限。", "conclusion": "本文通过引入新的范数和代数结构，改进了对平稳过程使用ARMA模型逼近的理论理解，并提供了更普适的逆性定义和逼近误差分析。", "translation": "我们研究了一个与自回归滑动平均（ARMA）模型相关的问题，即量化真实平稳过程$X_t$与ARMA模型$Y_t$之间的逼近误差。我们采用平稳过程$X_t$的传递函数表示$x(L)$，并证明$x$的$L^{\\infty}$范数作为$X_t$上的有效范数，可以控制其Wold系数的$\\\\ell^2$范数。然后我们证明了平稳过程的某个子空间（包括ARMA模型）在$L^{\\infty}$范数下形成一个巴拿赫代数，该代数尊重$H^{\\infty}$传递函数的乘法结构，从而改善了ARMA模型倒谱范数的结构特性。这个代数中可逆性的自然定义与ARMA可逆性的原始定义一致，并且比Wiener的$\\\\ell^1$条件更好地推广到非ARMA过程。最后，我们在连续传递函数的简单背景下计算了一些显式逼近界限，并批判了Padé逼近和简约模型的一些启发式思想。", "summary": "本文探讨了平稳过程与ARMA模型之间的逼近误差量化问题。研究表明，平稳过程传递函数的$L^{\\infty}$范数能够有效控制其Wold系数的$\\\\ell^2$范数。此外，文章证明了包含ARMA模型在内的特定平稳过程子空间在$L^{\\infty}$范数下构成一个巴拿赫代数，其可逆性定义更具普适性。研究还提供了连续传递函数背景下的具体逼近界限，并对相关启发式方法进行了评述。", "keywords": "ARMA模型, 平稳过程, 逼近误差, $L^{\\infty}$范数, 巴拿赫代数", "comments": "本文在理论上对ARMA模型逼近平稳过程的误差进行了深入分析，引入了$L^{\\infty}$范数和巴拿赫代数等数学工具，为理解和改进模型逼近提供了新的视角。其对可逆性定义的泛化以及对现有启发式思想的批判也显示了其重要性。"}}
{"id": "2503.15897", "title": "Learning 3D Scene Analogies with Neural Contextual Scene Maps", "authors": ["Junho Kim", "Gwangtak Bae", "Eun Sun Lee", "Young Min Kim"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2503.15897v2", "summary": "Understanding scene contexts is crucial for machines to perform tasks and\nadapt prior knowledge in unseen or noisy 3D environments. As data-driven\nlearning is intractable to comprehensively encapsulate diverse ranges of\nlayouts and open spaces, we propose teaching machines to identify relational\ncommonalities in 3D spaces. Instead of focusing on point-wise or object-wise\nrepresentations, we introduce 3D scene analogies, which are smooth maps between\n3D scene regions that align spatial relationships. Unlike well-studied single\ninstance-level maps, these scene-level maps smoothly link large scene regions,\npotentially enabling unique applications in trajectory transfer in AR/VR, long\ndemonstration transfer for imitation learning, and context-aware object\nrearrangement. To find 3D scene analogies, we propose neural contextual scene\nmaps, which extract descriptor fields summarizing semantic and geometric\ncontexts, and holistically align them in a coarse-to-fine manner for map\nestimation. This approach reduces reliance on individual feature points, making\nit robust to input noise or shape variations. Experiments demonstrate the\neffectiveness of our approach in identifying scene analogies and transferring\ntrajectories or object placements in diverse indoor scenes, indicating its\npotential for robotics and AR/VR applications. Project page including the code\nis available through this link:\nhttps://82magnolia.github.io/3d_scene_analogies/.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.15897v2", "cate": "cs.CV", "date": "2025-03-20", "updated": "2025-07-31", "AI": {"title_translation": "使用神经上下文场景图学习3D场景类比", "tldr": "本文提出了一种名为3D场景类比的新方法，它通过神经上下文场景图来学习3D场景区域之间的平滑映射，从而有效地识别空间关系并实现轨迹或物体放置的迁移，适用于机器人和AR/VR应用。", "motivation": "机器在未知或嘈杂的3D环境中执行任务和适应先验知识时，理解场景上下文至关重要。由于数据驱动的学习难以全面涵盖各种布局和开放空间，因此需要一种新的方法来识别3D空间中的关系共性。", "method": "我们提出了3D场景类比，这是一种在3D场景区域之间对齐空间关系的平滑映射。为了找到这些类比，我们引入了神经上下文场景图，它提取总结语义和几何上下文的描述符字段，并以从粗到精的方式整体对齐它们以进行映射估计。这种方法减少了对单个特征点的依赖，使其对输入噪声或形状变化具有鲁棒性。", "result": "实验证明了我们方法在识别场景类比以及在各种室内场景中迁移轨迹或物体放置方面的有效性。", "conclusion": "本研究提出的方法在机器人和AR/VR应用中具有巨大潜力，因为它能够有效地理解和迁移3D场景中的空间关系。", "translation": "理解场景上下文对于机器在未知或嘈杂的3D环境中执行任务和适应先验知识至关重要。由于数据驱动的学习难以全面涵盖各种布局和开放空间，我们提出教机器识别3D空间中的关系共性。我们不关注点对点或对象对点的表示，而是引入了3D场景类比，这是3D场景区域之间对齐空间关系的平滑映射。与研究充分的单实例级映射不同，这些场景级映射平滑地链接大场景区域，可能在AR/VR中的轨迹迁移、模仿学习中的长演示迁移以及上下文感知对象重新排列方面实现独特的应用。为了找到3D场景类比，我们提出了神经上下文场景图，它提取总结语义和几何上下文的描述符字段，并以从粗到精的方式整体对齐它们以进行映射估计。这种方法减少了对单个特征点的依赖，使其对输入噪声或形状变化具有鲁棒性。实验证明了我们方法在识别场景类比以及在各种室内场景中迁移轨迹或物体放置方面的有效性，表明其在机器人和AR/VR应用中的潜力。包括代码的项目页面可通过此链接获取：https://82magnolia.github.io/3d_scene_analogies/。", "summary": "本文提出了一种新颖的3D场景类比方法，通过构建3D场景区域间的平滑映射来识别空间关系。为实现这一目标，引入了神经上下文场景图，它通过提取并对齐语义和几何上下文描述符来估计映射，从而增强了对输入噪声和形状变化的鲁棒性。实验证明，该方法能有效识别场景类比，并在多样的室内场景中成功迁移轨迹和物体放置，展现了其在机器人和AR/VR领域的应用前景。", "keywords": "3D场景类比, 神经上下文场景图, 空间关系, 轨迹迁移, AR/VR", "comments": "这篇论文的创新点在于提出了“3D场景类比”和“神经上下文场景图”的概念，旨在解决传统数据驱动方法在复杂3D场景理解上的局限性。通过关注场景级而非点或对象级的映射，该方法能够更鲁棒地处理噪声和形状变化，并为轨迹迁移和上下文感知对象重新排列等新应用提供了可能性。其从粗到精的对齐策略也体现了设计上的精巧。"}}
{"id": "2507.23261", "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "authors": ["Hui Yi Leong", "Yuqing Wu"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23261v1", "summary": "Current multi-agent systems (MAS) frameworks often rely on manually designed\nand static collaboration graph structures, limiting adaptability and\nperformance. To address these limitations, we propose DynaSwarm, a dynamic\nframework that enhances LLM-based MAS through two key innovations: (1) an\nactor-critic reinforcement learning (A2C) mechanism to optimize graph\nstructures with improved stability over prior RL methods, and (2) a dynamic\ngraph selector that adaptively chooses the optimal graph structure for each\ninput sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the\nneed for rigid, one-fits-all graph architectures, instead leveraging\nsample-specific idiosyncrasies to dynamically route queries through specialized\nagent networks. (c) We propose to fine-tune the demonstration retriever to\nfully exploit the power of in-context learning (ICL). Extensive experiments on\nquestion answering, mathematical reasoning, and coding tasks demonstrate that\nDynaSwarm consistently outperforms state-of-the-art single-agent and MAS\nbaselines across multiple LLM backbones. Our findings highlight the importance\nof sample-aware structural flexibility in LLM MAS designs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23261v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DynaSwarm: 基于LLM的多智能体系统动态图结构选择", "tldr": "DynaSwarm是一个动态框架，通过A2C和动态图选择器，为基于LLM的多智能体系统提供样本感知的动态图结构优化，显著优于现有基线。", "motivation": "当前多智能体系统（MAS）框架依赖手动设计和静态的协作图结构，限制了适应性和性能。", "method": "提出DynaSwarm框架，包含两项创新：1. 一个Actor-Critic强化学习（A2C）机制，优化图结构并提高稳定性。2. 一个动态图选择器，通过参数高效的LLM微调，为每个输入样本自适应选择最优图结构。此外，还提出微调演示检索器以充分利用上下文学习（ICL）的能力。", "result": "在问答、数学推理和编码任务上的广泛实验表明，DynaSwarm在多个LLM骨干网络上始终优于最先进的单智能体和MAS基线。", "conclusion": "研究结果强调了LLM MAS设计中样本感知结构灵活性的重要性。", "translation": "当前的多智能体系统（MAS）框架通常依赖手动设计和静态的协作图结构，这限制了其适应性和性能。为了解决这些局限性，我们提出了DynaSwarm，一个动态框架，通过两项关键创新增强了基于大型语言模型（LLM）的MAS：(1) 一个Actor-Critic强化学习（A2C）机制，用于优化图结构，与先前的强化学习方法相比，提高了稳定性；(2) 一个动态图选择器，通过参数高效的LLM微调，为每个输入样本自适应地选择最优图结构。DynaSwarm消除了对僵硬的、一刀切的图架构的需求，转而利用样本特定的特性，通过专门的智能体网络动态路由查询。(c) 我们提出微调演示检索器，以充分利用上下文学习（ICL）的能力。在问答、数学推理和编码任务上的广泛实验表明，DynaSwarm在多个LLM骨干网络上始终优于最先进的单智能体和MAS基线。我们的研究结果强调了LLM MAS设计中样本感知结构灵活性的重要性。", "summary": "本文提出了DynaSwarm，一个用于基于LLM的多智能体系统的动态框架，旨在解决现有MAS静态图结构的局限性。DynaSwarm通过结合A2C强化学习机制优化图结构和动态图选择器自适应地选择样本特定图结构，从而实现更高的适应性和性能。实验证明，DynaSwarm在问答、数学推理和编码任务上优于现有基线，强调了LLM MAS中样本感知结构灵活性的重要性。", "keywords": "多智能体系统, LLM, 动态图结构, 强化学习, A2C", "comments": "DynaSwarm的创新点在于引入了动态图结构选择机制，通过结合强化学习和LLM微调，实现了多智能体系统在不同任务和样本上的自适应。这解决了传统MAS中图结构僵化的问题，提高了系统的灵活性和性能。其重要性在于为未来LLM-based MAS的设计提供了新的范式，即从静态设计转向动态和样本感知的结构优化。"}}
{"id": "2507.23556", "title": "Networked Physical Computing: A New Paradigm for Effective Task Completion via Hypergraph Aided Trusted Task-Resource Matching", "authors": ["Botao Zhu", "Xianbin Wang"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23556v1", "summary": "Due to the diverse physical attributes of computing resources and tasks,\ndeveloping effective mechanisms to facilitate task and resource matching in\ncomplex connected systems for value-oriented task completion has become\nincreasingly challenging. To address the challenge, this paper proposes a\nnetworked physical computing system that integrates the physical attributes of\ncomputing resources and tasks as well as task-specific trust relationships\namong devices to enable value-driven task completion. Specifically, we propose\na state-of-the-art hypergraph-aided trusted task-resource matching\n(TTR-matching) framework to achieve the envisioned physical computing. First, a\ntask-specific trusted physical resource hypergraph is defined, which integrates\ntask-specific trust, the physical attributes of resources, and task types. This\nenables accurate modeling of device collaboration dependencies under specific\ntask types. Next, a task hypergraph is generated to associate the task\ninitiator with the physical attributes of the corresponding tasks. Based on\nthese two hypergraphs, a hypergraph matching algorithm is designed to\nfacilitate task-specific trusted collaborator selection and accurate\ntask-resource matching for value-maximizing task completion. Extensive\nexperimental results demonstrate that the proposed TTR-matching framework\noutperforms comparison algorithms in identifying task-specific trustworthy\ncollaborators and maximizing the average value of task completion.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23556v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "网络化物理计算：一种通过超图辅助可信任务-资源匹配实现有效任务完成的新范式", "tldr": "本文提出了一种网络化物理计算系统，利用超图辅助的可信任务-资源匹配（TTR-matching）框架，解决了复杂互联系统中任务与资源匹配的挑战，提高了任务完成的价值。", "motivation": "由于计算资源和任务的物理属性多样性，在复杂的互联系统中开发有效的任务与资源匹配机制以实现价值导向的任务完成变得越来越具挑战性。", "method": "本文提出了一个网络化物理计算系统，并引入了最先进的超图辅助可信任务-资源匹配（TTR-matching）框架。具体而言，首先定义了一个任务特定的可信物理资源超图，整合了任务特定信任、资源物理属性和任务类型，以准确建模设备协作依赖关系。其次，生成一个任务超图，关联任务发起者与相应任务的物理属性。最后，基于这两个超图设计了一个超图匹配算法，以促进任务特定的可信协作者选择和准确的任务-资源匹配，从而最大化任务完成的价值。", "result": "广泛的实验结果表明，所提出的TTR-matching框架在识别任务特定的可信协作者和最大化任务完成的平均价值方面优于对比算法。", "conclusion": "本文提出的基于超图辅助的可信任务-资源匹配（TTR-matching）框架能够有效解决网络化物理计算中任务与资源的匹配问题，显著提升了任务完成的价值。", "translation": "由于计算资源和任务的物理属性多样性，在复杂的互联系统中开发有效的机制来促进任务和资源匹配，以实现价值导向的任务完成变得越来越具挑战性。为了应对这一挑战，本文提出了一种网络化物理计算系统，该系统整合了计算资源和任务的物理属性以及设备之间任务特定的信任关系，以实现价值驱动的任务完成。具体而言，我们提出了一种最先进的超图辅助可信任务-资源匹配（TTR-matching）框架，以实现设想中的物理计算。首先，定义了一个任务特定的可信物理资源超图，该超图整合了任务特定的信任、资源的物理属性和任务类型。这使得在特定任务类型下能够准确建模设备协作依赖关系。接下来，生成一个任务超图，将任务发起者与相应任务的物理属性相关联。基于这两个超图，设计了一种超图匹配算法，以促进任务特定的可信协作者选择和准确的任务-资源匹配，从而最大化任务完成的价值。广泛的实验结果表明，所提出的TTR-matching框架在识别任务特定的可信协作者和最大化任务完成的平均价值方面优于对比算法。", "summary": "本文针对复杂互联系统中计算资源和任务多样性带来的匹配挑战，提出了一种网络化物理计算系统。该系统通过整合资源和任务的物理属性以及设备间的任务特定信任关系，旨在实现价值驱动的任务完成。核心贡献是一个名为超图辅助可信任务-资源匹配（TTR-matching）的框架。此框架首先构建任务特定的可信物理资源超图和任务超图，然后设计超图匹配算法来精确选择可信协作者并优化任务-资源匹配。实验证明，TTR-matching框架在识别可信协作者和最大化任务完成价值方面表现优异。", "keywords": "网络化物理计算, 超图, 任务-资源匹配, 信任", "comments": "本文提出了一种新颖的网络化物理计算范式，通过引入超图来建模复杂的任务-资源关系和信任，具有创新性。这种方法能够更精细地处理物理属性和任务特定信任，对于提升复杂系统中任务完成的效率和价值具有重要意义。其将信任关系融入匹配过程，是其区别于传统匹配算法的关键。"}}
{"id": "2507.23600", "title": "EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution", "authors": ["Yu-Tang Chang", "Shih-Fang Chen"], "categories": ["cs.LG", "cs.CE", "G.1.6; G.3; G.4; I.6.5"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23600v1", "summary": "Signal unmixing analysis decomposes data into basic patterns and is widely\napplied in chemical and biological research. Multivariate curve resolution\n(MCR), a branch of signal unmixing, separates mixed chemical signals into base\npatterns (components) and their concentrations, playing a key role in\nunderstanding composition. Classical MCR is typically framed as matrix\nfactorization (MF) and requires a user-specified component count, usually\nunknown in real data. As dataset size or component count increases, the\nscalability and reliability of MF-based MCR face significant challenges. This\nstudy reformulates MCR as a generative process (gMCR), and introduces an\nenergy-based deep learning solver, EB-gMCR, that automatically discovers the\nsmallest component set able to reconstruct the data faithfully. EB-gMCR starts\nfrom a large candidate pool (e.g., 1024 spectra) and employs a differentiable\ngating network to retain only active components while estimating their\nconcentrations. On noisy synthetic datasets containing up to 256 latent\nsources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count\nwithin 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near\nexact component estimation. Additional chemical priors, such as non-negativity\nor nonlinear mixing, enter as simple plug-in functions, enabling adaptation to\nother instruments or domains without altering the core learning process. By\nuniting high-capacity generative modeling and hard component selection, EB-gMCR\noffers a practical route to large-scale signal unmixing analysis, including\nchemical library-driven scenarios. The source code is available at\nhttps://github.com/b05611038/ebgmcr_solver.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23600v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "EB-gMCR：基于能量的生成模型用于信号解混和多变量曲线分辨", "tldr": "EB-gMCR是一个基于能量的深度学习模型，用于自动识别信号解混中的组分数，并在大规模数据集上表现出色。", "motivation": "经典的多变量曲线分辨 (MCR) 通常被视为矩阵分解，需要用户指定组分数，但在实际数据中组分数通常未知。随着数据集大小或组分数增加，基于MF的MCR的可伸缩性和可靠性面临挑战。", "method": "本研究将MCR重新表述为生成过程 (gMCR)，并引入了基于能量的深度学习求解器EB-gMCR。EB-gMCR从大量候选池开始，使用可微分门控网络仅保留活动组分并估计其浓度，从而自动发现能够忠实重建数据的最小组分集。", "result": "在包含多达256个潜在源的噪声合成数据集上，EB-gMCR保持R^2 >= 0.98，并在5%的误差范围内恢复了组分数；在较低噪声下，R^2 >= 0.99，组分估计几乎精确。可以简单地插入额外的化学先验（如非负性或非线性混合）。", "conclusion": "通过结合高容量生成建模和硬组分选择，EB-gMCR为大规模信号解混分析（包括化学库驱动的场景）提供了一条实用途径。", "translation": "信号解混分析将数据分解为基本模式，广泛应用于化学和生物研究。多变量曲线分辨（MCR）是信号解混的一个分支，它将混合化学信号分离为基本模式（组分）及其浓度，在理解组成方面发挥着关键作用。经典的MCR通常被视为矩阵分解（MF），需要用户指定组分数量，这在真实数据中通常是未知的。随着数据集大小或组分数量的增加，基于MF的MCR的可伸缩性和可靠性面临重大挑战。本研究将MCR重新表述为生成过程（gMCR），并引入了一种基于能量的深度学习求解器EB-gMCR，该求解器能够自动发现能够忠实重建数据的最小组分集。EB-gMCR从一个大的候选池（例如1024个光谱）开始，并采用可微分门控网络，仅保留活动组分，同时估计其浓度。在包含多达256个潜在源的噪声合成数据集上，EB-gMCR保持R^2 >= 0.98，并在与真实值相差5%的范围内恢复了组分数量；在较低噪声下，它实现了R^2 >= 0.99，组分估计几乎精确。额外的化学先验，例如非负性或非线性混合，可以作为简单的插件函数引入，从而无需改变核心学习过程即可适应其他仪器或领域。通过结合高容量生成建模和硬组分选择，EB-gMCR为大规模信号解混分析（包括化学库驱动的场景）提供了一条实用途径。源代码可在https://github.com/b05611038/ebgmcr_solver获得。", "summary": "本文提出了一种名为EB-gMCR的新型基于能量的深度学习模型，用于解决信号解混和多变量曲线分辨（MCR）中的组分数量未知和可伸缩性问题。EB-gMCR将MCR重新定义为生成过程，通过从大量候选组分中自动选择最小有效组分集来忠实重建数据。该方法在合成数据集上表现出高精度，并能有效适应不同的化学先验，为大规模信号解混分析提供了实用方案。", "keywords": "信号解混, 多变量曲线分辨, 生成模型, 深度学习, 组分选择", "comments": "EB-gMCR的创新之处在于将MCR重新构建为生成过程，并利用基于能量的深度学习方法自动确定组分数量，解决了传统MF-based MCR在组分数量未知和大规模数据下的挑战。其可插拔的化学先验功能增加了模型的通用性和适应性。"}}
{"id": "2507.22918", "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "authors": ["Daniel Son", "Sanjana Rathore", "Andrew Rufail", "Adrian Simon", "Daniel Zhang", "Soham Dave", "Cole Blondin", "Kevin Zhu", "Sean O'Brien"], "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to ACL 2025 Student Research Workshop (poster)", "url": "http://arxiv.org/abs/2507.22918v1", "summary": "We investigate feature universality in Gemma-2 language models (Gemma-2-2B\nand Gemma-2-9B), asking whether models with a four-fold difference in scale\nstill converge on comparable internal concepts. Using the Sparse Autoencoder\n(SAE) dictionary-learning pipeline, we utilize SAEs on each model's\nresidual-stream activations, align the resulting monosemantic features via\nactivation correlation, and compare the matched feature spaces with SVCCA and\nRSA. Middle layers yield the strongest overlap, while early and late layers\nshow far less similarity. Preliminary experiments extend the analysis from\nsingle tokens to multi-token subspaces, showing that semantically similar\nsubspaces interact similarly with language models. These results strengthen the\ncase that large language models carve the world into broadly similar,\ninterpretable features despite size differences, reinforcing universality as a\nfoundation for cross-model interpretability.", "comment": "Submitted to ACL 2025 Student Research Workshop (poster)", "pdf_url": "http://arxiv.org/pdf/2507.22918v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "语义收敛：探究不同规模大型语言模型中的共享表征", "tldr": "尽管规模差异很大，大型语言模型仍能形成相似的可解释内部概念，尤其是在中间层。", "motivation": "探究不同规模（如Gemma-2-2B和Gemma-2-9B）的大型语言模型是否会收敛到可比较的内部概念。", "method": "使用稀疏自编码器（SAE）字典学习流程，在每个模型的残差流激活上应用SAE，通过激活相关性对单义特征进行对齐，并使用SVCCA和RSA比较匹配的特征空间。初步实验还将分析从单个token扩展到多token子空间。", "result": "中间层表现出最强的重叠，而早期和晚期层相似性较小。语义相似的子空间与语言模型的交互方式相似。", "conclusion": "这些结果强化了大型语言模型尽管存在规模差异，但仍能将世界划分为大致相似、可解释的特征的观点，从而强化了普遍性作为跨模型可解释性的基础。", "translation": "我们研究了Gemma-2语言模型（Gemma-2-2B和Gemma-2-9B）中的特征普遍性，探究规模相差四倍的模型是否仍能收敛于可比较的内部概念。我们利用稀疏自编码器（SAE）字典学习流程，在每个模型的残差流激活上使用SAE，通过激活相关性对生成的单义特征进行对齐，并使用SVCCA和RSA比较匹配的特征空间。结果显示，中间层表现出最强的重叠，而早期和晚期层显示出远较少的相似性。初步实验将分析从单个token扩展到多token子空间，表明语义相似的子空间与语言模型的交互方式相似。这些结果强化了大型语言模型尽管存在尺寸差异，但仍能将世界划分为大致相似、可解释特征的观点，从而强化了普遍性作为跨模型可解释性的基础。", "summary": "本研究探讨了Gemma-2系列中不同规模的大型语言模型（LLMs）是否会形成相似的内部概念。通过利用稀疏自编码器（SAE）和激活相关性技术，研究人员发现，尽管模型规模存在差异，但LLMs的中间层表现出最强的特征重叠和语义收敛性，而早期和晚期层相似性较低。这些发现支持了LLMs能够形成普遍且可解释的内部表征，为跨模型可解释性奠定基础。", "keywords": "语义收敛, 大型语言模型, 特征普遍性, 可解释性, 稀疏自编码器", "comments": "这篇论文的创新点在于系统地探究了不同规模LLM之间的语义收敛性，并指出了中间层在形成共享可解释特征方面的重要性。这对于理解LLM的内部工作机制和提升跨模型可解释性具有重要意义。它表明，即使模型大小不同，其学习到的概念也可能具有普遍性，这为构建更鲁棒和可解释的AI模型提供了理论基础。"}}
{"id": "2507.23683", "title": "I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation", "authors": ["Jialei Chen", "Wuhao Xu", "Sipeng He", "Baoru Huang", "Dongchun Ren"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23683v1", "summary": "Vast and high-quality data are essential for end-to-end autonomous driving\nsystems. However, current driving data is mainly collected by vehicles, which\nis expensive and inefficient. A potential solution lies in synthesizing data\nfrom real-world images. Recent advancements in 3D reconstruction demonstrate\nphotorealistic novel view synthesis, highlighting the potential of generating\ndriving data from images captured on the road. This paper introduces a novel\nmethod, I2V-GS, to transfer the Infrastructure view To the Vehicle view with\nGaussian Splatting. Reconstruction from sparse infrastructure viewpoints and\nrendering under large view transformations is a challenging problem. We adopt\nthe adaptive depth warp to generate dense training views. To further expand the\nrange of views, we employ a cascade strategy to inpaint warped images, which\nalso ensures inpainting content is consistent across views. To further ensure\nthe reliability of the diffusion model, we utilize the cross-view information\nto perform a confidenceguided optimization. Moreover, we introduce RoadSight, a\nmulti-modality, multi-view dataset from real scenarios in infrastructure views.\nTo our knowledge, I2V-GS is the first framework to generate autonomous driving\ndatasets with infrastructure-vehicle view transformation. Experimental results\ndemonstrate that I2V-GS significantly improves synthesis quality under vehicle\nview, outperforming StreetGaussian in NTA-Iou, NTL-Iou, and FID by 45.7%,\n34.2%, and 14.9%, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23683v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "I2V-GS：基于高斯泼溅的自动驾驶数据生成中的基础设施到车辆视角转换", "tldr": "I2V-GS是一种新方法，利用高斯泼溅将基础设施视角转换为车辆视角，以高效生成自动驾驶数据，并通过自适应深度扭曲、级联策略和置信度引导优化显著提高了合成质量。", "motivation": "端到端自动驾驶系统需要大量高质量数据，但现有数据收集方式昂贵且低效。通过合成真实世界图像来生成数据是一个潜在的解决方案，特别是利用3D重建技术进行逼真的新视角合成。", "method": "I2V-GS方法通过高斯泼溅实现基础设施到车辆的视角转换。为解决稀疏视角重建和大幅度视角转换下的渲染挑战，该方法采用自适应深度扭曲生成密集训练视图，并利用级联策略对扭曲图像进行修复以扩展视图范围并确保内容一致性。此外，通过跨视图信息进行置信度引导优化，确保扩散模型的可靠性。论文还引入了RoadSight数据集。", "result": "I2V-GS显著提高了车辆视角下的合成质量，在NTA-Iou、NTL-Iou和FID指标上分别优于StreetGaussian 45.7%、34.2%和14.9%。", "conclusion": "I2V-GS是首个利用基础设施到车辆视角转换生成自动驾驶数据集的框架，通过其创新方法显著提升了数据合成质量，为自动驾驶数据生成提供了一种高效且高质量的解决方案。", "translation": "海量高质量数据对于端到端自动驾驶系统至关重要。然而，目前的驾驶数据主要由车辆收集，这既昂贵又低效。一个潜在的解决方案是从真实世界图像中合成数据。3D重建的最新进展展示了逼真的新视角合成能力，突显了从道路上捕获的图像生成驾驶数据的潜力。本文介绍了一种新颖的方法I2V-GS，利用高斯泼溅将基础设施视角转换为车辆视角。从稀疏基础设施视角进行重建并在大视角转换下进行渲染是一个具有挑战性的问题。我们采用自适应深度扭曲来生成密集的训练视图。为了进一步扩展视图范围，我们采用级联策略来修复扭曲图像，这也确保了修复内容在不同视图之间的一致性。为了进一步确保扩散模型的可靠性，我们利用跨视图信息执行置信度引导优化。此外，我们引入了RoadSight，一个来自真实场景的基础设施视角下的多模态、多视图数据集。据我们所知，I2V-GS是第一个通过基础设施到车辆视角转换生成自动驾驶数据集的框架。实验结果表明，I2V-GS显著提高了车辆视角下的合成质量，在NTA-Iou、NTL-Iou和FID方面分别优于StreetGaussian 45.7%、34.2%和14.9%。", "summary": "本文提出I2V-GS，一个基于高斯泼溅的创新框架，旨在通过将基础设施视角转换为车辆视角，高效生成高质量的自动驾驶数据。针对稀疏视角重建和大幅度视角转换的挑战，I2V-GS采用自适应深度扭曲生成密集视图，并通过级联策略修复图像以扩展视图范围并确保一致性，同时利用跨视图信息进行置信度引导优化。该研究还引入了首个多模态、多视图基础设施视角数据集RoadSight。实验证明，I2V-GS在车辆视角下的合成质量显著优于现有方法。", "keywords": "自动驾驶数据生成, 视角转换, 高斯泼溅, I2V-GS, RoadSight", "comments": "I2V-GS的创新之处在于首次提出了基础设施到车辆的视角转换框架，以解决自动驾驶数据收集成本高昂的问题。其方法结合了高斯泼溅、自适应深度扭曲、级联修复和置信度引导优化，展现了在复杂视角转换下的强大性能。RoadSight数据集的引入也填补了该领域的数据空白，对未来的研究具有重要意义。该工作为自动驾驶数据生成提供了一个高效且高质量的新范式。"}}
{"id": "2408.03351", "title": "Quantum Transfer Learning for MNIST Classification Using a Hybrid Quantum-Classical Approach", "authors": ["Soumyadip Sarkar"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.03351v2", "summary": "We implement a hybrid quantum-classical model for image classification that\ncompresses MNIST digit images into a low-dimensional feature space and then\nmaps these features onto a 5-qubit quantum state. First, an autoencoder\ncompresses each $28\\times28$ image (784 pixels) into a 64-dimensional latent\nvector, preserving salient features of the digit with minimal reconstruction\nerror. We further reduce the latent representation to 5 principal components\nusing Principal Component Analysis (PCA), to match the 5 available qubits.\nThese 5 features are encoded as rotation angles in a quantum circuit with 5\nqubits. The quantum feature map applies single-qubit rotations ($R_y$ gates)\nproportional to the feature values, followed by a Hadamard gate and a cascade\nof entangling CNOT gates to produce a non-product entangled state. Measuring\nthe 5-qubit state yields a 32-dimensional probability distribution over basis\noutcomes, which serves as a quantum-enhanced feature vector for classification.\nA classical neural network with a softmax output is then trained on these\n32-dimensional quantum feature vectors to predict the digit class. We evaluate\nthe hybrid model on the MNIST dataset and compare it to a purely classical\nbaseline that uses the 64-dimensional autoencoder latent features for\nclassification. The results show that the hybrid model can successfully\nclassify digits, demonstrating the feasibility of integrating quantum computing\nin the classification pipeline, although its accuracy (about 75\\% on test data)\ncurrently falls below the classical baseline (about 98\\% on the same compressed\ndata).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.03351v2", "cate": "quant-ph", "date": "2024-08-05", "updated": "2025-07-31", "AI": {"title_translation": "用于MNIST分类的混合量子-经典量子迁移学习", "tldr": "本文提出了一种混合量子-经典模型，通过将MNIST图像压缩并映射到5量子比特状态，然后使用经典神经网络进行分类，成功展示了将量子计算集成到分类流程中的可行性，尽管其准确性低于纯经典方法。", "motivation": "研究旨在实现一种混合量子-经典模型用于图像分类，探索将量子计算集成到分类流程中的可行性。", "method": "研究实现了一个混合量子-经典模型。首先，使用自动编码器将28x28的MNIST图像压缩为64维潜在向量。接着，通过主成分分析（PCA）将该向量进一步降维至5个主成分，以匹配5个可用的量子比特。这5个特征被编码为量子电路中的旋转角度，通过单量子比特旋转（Ry门）、Hadamard门和纠缠CNOT门生成一个非积纠缠态。测量5量子比特态得到一个32维的概率分布，作为量子增强特征向量。最后，一个带有softmax输出的经典神经网络在此32维量子特征向量上进行训练以预测数字类别。该模型在MNIST数据集上进行评估，并与使用64维自动编码器潜在特征的纯经典基线进行比较。", "result": "混合模型可以成功分类数字，在测试数据上的准确率约为75%。然而，其准确率目前低于纯经典基线（在相同压缩数据上约为98%）。", "conclusion": "该研究证明了将量子计算集成到分类流程中的可行性，尽管当前混合模型的准确性低于纯经典基线。", "translation": "我们实现了一个用于图像分类的混合量子-经典模型，该模型将MNIST数字图像压缩到一个低维特征空间，然后将这些特征映射到5量子比特的量子态上。首先，一个自动编码器将每个28x28图像（784像素）压缩成一个64维的潜在向量，以最小的重建误差保留了数字的显著特征。我们使用主成分分析（PCA）将潜在表示进一步降维到5个主成分，以匹配5个可用的量子比特。这5个特征在5量子比特的量子电路中被编码为旋转角度。量子特征映射应用与特征值成比例的单量子比特旋转（Ry门），然后是Hadamard门和一系列纠缠CNOT门，以产生一个非积纠缠态。测量5量子比特态会产生一个32维的基结果概率分布，这作为分类的量子增强特征向量。然后，一个带有softmax输出的经典神经网络在这些32维量子特征向量上进行训练，以预测数字类别。我们在MNIST数据集上评估了该混合模型，并将其与使用64维自动编码器潜在特征进行分类的纯经典基线进行了比较。结果表明，混合模型可以成功分类数字，证明了将量子计算集成到分类流程中的可行性，尽管其准确性（测试数据上约为75%）目前低于经典基线（在相同压缩数据上约为98%）。", "summary": "本文提出并实现了一种用于MNIST图像分类的混合量子-经典模型。该模型首先使用自动编码器将图像压缩为64维潜在空间，然后通过PCA进一步降维至5个主要成分，这些成分被编码到5量子比特的量子态中。通过量子特征映射（包括单量子比特旋转和纠缠门），生成一个32维的量子增强特征向量。最后，一个经典的神经网络利用这些量子特征向量进行数字分类。实验结果表明，尽管该混合模型在MNIST数据集上的分类准确率（约75%）低于纯经典基线（约98%），但它成功展示了将量子计算应用于图像分类任务的可行性。", "keywords": "混合量子-经典, 量子机器学习, 图像分类, MNIST, 特征映射", "comments": "这项研究的创新之处在于其混合量子-经典架构，特别是将高维图像数据通过经典降维技术（自动编码器和PCA）映射到低维量子态进行特征增强。尽管目前的准确性低于经典基线，但它为量子机器学习，特别是量子特征工程在实际应用中的潜力提供了初步验证。其局限性在于当前量子硬件的规模和噪声限制，导致性能不佳，但该工作为未来量子算法的优化和硬件发展提供了有价值的探索方向。"}}
{"id": "2507.23163", "title": "Argumentatively Coherent Judgmental Forecasting", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      17 pages, 18 figures, ECAI 2025", "url": "http://arxiv.org/abs/2507.23163v1", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "comment": "17 pages, 18 figures, ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.23163v1", "cate": "cs.AI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "论证一致性的判断式预测", "tldr": "本文提出并形式化定义了“论证一致性”这一概念，并证明在人工和大型语言模型（LLM）的判断式预测中，过滤掉不一致的预测能提高准确性，但用户普遍不符合这种一致性，因此需要引入机制来过滤不一致的意见。", "motivation": "在判断式预测中，当人类意见形成论证结构时，研究其从论证角度的特性是有用的。本文旨在定义并评估论证一致性，以提高预测准确性，并解决用户意见不一致的问题。", "method": "本文首先提出并形式化定义了“论证一致性”这一属性，即预测者的推理应与其预测保持一致。然后，通过三项评估来验证这一概念：1. 评估强制执行一致性对人类预测者和基于大型语言模型（LLM）的预测者的影响。2. 通过众包用户实验，评估用户是否普遍符合这种一致性。", "result": "1. 过滤掉不一致的预测能够持续提高人类预测和LLM预测的准确性，证明了一致性在实践中的价值。2. 尽管论证一致性看似直观有用，但众包用户实验表明，用户普遍不符合这一一致性属性。", "conclusion": "论证一致性对于提高判断式预测（包括人类和LLM）的准确性具有实际价值。然而，由于用户普遍不符合这种一致性，因此在基于论证的判断式预测中，需要整合机制来在获得群体预测之前过滤掉不一致的意见。", "translation": "判断式预测采用人类意见来预测未来事件，而非像定量预测那样完全依赖历史数据。当这些意见围绕预测形成论证结构时，从论证角度研究预测的属性会很有用。本文倡导并形式化定义了论证一致性这一属性，其本质要求预测者的推理与其预测保持一致。然后，我们对我们的一致性概念进行了三项评估。首先，我们评估了强制执行一致性对人类预测者以及基于大型语言模型（LLM）的预测者的影响，鉴于它们最近已显示出与人类预测者具有竞争力。在这两种情况下，我们都表明，过滤掉不一致的预测能持续提高预测准确性，从而支持了一致性在人类和LLM预测中的实际价值。然后，通过众包用户实验，我们表明，尽管其明显具有直观性和有用性，但用户通常不符合这种一致性属性。这表明在基于论证的判断式预测中，需要在获得群体预测之前整合机制来过滤掉不一致的意见。", "summary": "本文提出并形式化定义了“论证一致性”这一概念，该概念要求预测者的推理与其预测保持一致。研究通过评估发现，在人类和大型语言模型（LLM）的判断式预测中，强制执行并过滤掉不一致的预测能显著提高预测准确性。然而，众包用户实验表明，尽管该概念直观且有用，但用户普遍不符合这种一致性。这强调了在基于论证的判断式预测中，需要引入机制来在形成群体预测前过滤不一致的意见。", "keywords": "论证一致性, 判断式预测, 大型语言模型, 预测准确性, 意见过滤", "comments": "本文创新性地将“论证一致性”引入判断式预测领域，并首次对其进行了形式化定义。其重要性在于证明了该属性在提升人类和LLM预测准确性方面的实际价值。同时，研究也揭示了一个关键挑战，即用户自身在论证一致性方面存在不足，这为未来研究提出了明确的方向，即如何设计有效的机制来引导或过滤不一致的意见，从而更好地利用群体智慧。"}}
{"id": "2507.23175", "title": "Optimal compressed sensing for mixing stochastic processes", "authors": ["Yonatan Gutman", "Adam Śpiewak"], "categories": ["cs.IT", "math.DS", "math.IT", "math.PR", "68P30, 94A29, 31E05, 37A35, 60G10"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23175v1", "summary": "Jalali and Poor introduced an asymptotic framework for compressed sensing of\nstochastic processes, demonstrating that any rate strictly greater than the\nmean information dimension serves as an upper bound on the number of random\nlinear measurements required for (universal) almost lossless recovery of\n$\\psi^*$-mixing processes, as measured in the normalized $L^2$ norm. In this\nwork, we show that if the normalized number of random linear measurements is\nstrictly less than the mean information dimension, then almost lossless\nrecovery of a $\\psi^*$-mixing process is impossible by any sequence of\ndecompressors. This establishes the mean information dimension as the\nfundamental limit for compressed sensing in this setting (and, in fact, the\nprecise threshold for the problem). To this end, we introduce a new quantity,\nrelated to techniques from geometric measure theory: the correlation dimension\nrate, which is shown to be a lower bound for compressed sensing of arbitrary\nstationary stochastic processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23175v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "混合随机过程的最优压缩感知", "tldr": "研究表明，均值信息维度是混合随机过程压缩感知的基本极限，并引入了新的相关维度率。", "motivation": "现有研究表明，压缩感知中测量率大于均值信息维度时可以实现恢复。本文的动机是探索测量率低于均值信息维度时的情况，以确定压缩感知的精确基本极限。", "method": "本文通过证明当归一化随机线性测量次数严格小于均值信息维度时，几乎无损恢复是不可能的。为此，引入了一个新的量——相关维度率，它与几何测度理论技术相关，并被证明是任意平稳随机过程压缩感知的下限。", "result": "证明了对于$\\psi^*$-混合过程，如果归一化随机线性测量次数严格小于均值信息维度，那么任何解压器序列都无法实现几乎无损恢复。这确立了均值信息维度在该设置下作为压缩感知的基本极限和精确阈值。此外，引入的相关维度率被证明是任意平稳随机过程压缩感知的下限。", "conclusion": "均值信息维度是混合随机过程压缩感知的精确阈值和基本极限。", "translation": "Jalali 和 Poor 引入了一个随机过程压缩感知的渐进框架，证明了任何严格大于均值信息维度的速率都可以作为（通用）几乎无损恢复 $\\psi^*$-混合过程所需的随机线性测量次数的上限，测量标准为归一化 $L^2$ 范数。在这项工作中，我们表明，如果归一化随机线性测量次数严格小于均值信息维度，那么任何解压器序列都无法实现 $\\psi^*$-混合过程的几乎无损恢复。这确立了均值信息维度在该设置下作为压缩感知的基本极限（事实上，是该问题的精确阈值）。为此，我们引入了一个与几何测度理论技术相关的新量：相关维度率，它被证明是任意平稳随机过程压缩感知的下限。", "summary": "本文在Jalali和Poor的渐进框架基础上，证明了对于$\\psi^*$-混合过程，均值信息维度是压缩感知的精确基本极限。具体而言，如果随机线性测量次数少于均值信息维度，则无法实现几乎无损恢复。为了支持这一发现，作者引入了新的相关维度率，该率与几何测度理论相关，并作为任意平稳随机过程压缩感知的下限。", "keywords": "压缩感知, 随机过程, 均值信息维度, 相关维度率, 基本极限", "comments": "本文的创新之处在于明确了混合随机过程压缩感知的基本极限，即均值信息维度，并证明了其作为精确阈值的地位。此外，引入相关维度率这一新概念，为理解和分析更广泛的随机过程压缩感知问题提供了新的工具和理论基础，具有重要的理论价值。"}}
{"id": "2507.22947", "title": "ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios", "authors": ["Shou'ang Wei", "Xinyun Wang", "Shuzhen Bi", "Jian Chen", "Ruijia Li", "Bo Jiang", "Xin Lin", "Min Zhang", "Yu Song", "BingDong Li", "Aimin Zhou", "Hao Hao"], "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22947v1", "summary": "The emergence of Large Language Models (LLMs) presents transformative\nopportunities for education, generating numerous novel application scenarios.\nHowever, significant challenges remain: evaluation metrics vary substantially\nacross different educational scenarios, while many emerging scenarios lack\nappropriate assessment metrics. Current benchmarks predominantly measure\ngeneral intelligence rather than pedagogical capabilities. To address this gap,\nwe introduce ELMES, an open-source automated evaluation framework specifically\ndesigned for assessing LLMs in educational settings. ELMES features a modular\narchitecture that enables researchers to create dynamic, multi-agent dialogues\nthrough simple configuration files, facilitating flexible scenario design\nwithout requiring extensive programming expertise. The framework incorporates a\nhybrid evaluation engine that objectively quantifies traditionally subjective\npedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic\nbenchmarking of state-of-the-art LLMs across four critical educational\nscenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching,\nInterdisciplinary Lesson Plan Generation, and Contextualized Question\nGeneration, employing fine-grained metrics developed in collaboration with\neducation specialists. Our results demonstrate distinct capability\ndistributions among models, revealing context-specific strengths and\nlimitations. ELMES provides educators and researchers with an accessible\nevaluation framework that significantly reduces adaptation barriers for diverse\neducational applications while advancing the practical implementation of LLMs\nin pedagogy. The framework is publicly available at\n\\emph{https://github.com/sii-research/elmes.git}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22947v1", "cate": "cs.CY", "date": "2025-07-27", "updated": "2025-07-27", "AI": {"title_translation": "ELMES：一个用于教育场景中评估大型语言模型的自动化框架", "tldr": "ELMES是一个开源的自动化评估框架，专门用于在教育场景中评估大型语言模型（LLMs），解决了现有评估方法在教育领域适用性不足的问题，并通过LLM作为评判者的方法客观量化了主观教学指标。", "motivation": "大型语言模型（LLMs）在教育领域带来了许多新的应用机会，但现有评估指标在不同教育场景中差异很大，许多新兴场景缺乏合适的评估标准。当前的基准测试主要衡量通用智能而非教学能力，这构成了评估LLMs在教育场景中应用的挑战。", "method": "本文引入了ELMES，一个开源的自动化评估框架，专为评估教育环境中的LLMs而设计。ELMES采用模块化架构，允许研究人员通过简单的配置文件创建动态、多智能体对话，从而实现灵活的场景设计。该框架整合了一个混合评估引擎，使用“LLM作为评判者”的方法客观量化了传统上主观的教学指标。研究人员与教育专家合作，开发了细粒度指标，并系统地对最先进的LLMs在四个关键教育场景（知识点解释、引导式问题解决教学、跨学科教案生成和情境化问题生成）中进行了基准测试。", "result": "基准测试结果表明，不同模型之间存在明显的能力分布，揭示了它们在特定情境下的优势和局限性。", "conclusion": "ELMES为教育工作者和研究人员提供了一个易于使用的评估框架，显著降低了各种教育应用的适应障碍，同时推动了LLMs在教学中的实际应用。", "translation": "大型语言模型（LLMs）的出现为教育带来了变革性机遇，催生了众多新颖的应用场景。然而，重大挑战依然存在：不同教育场景的评估指标差异很大，而许多新兴场景缺乏合适的评估指标。目前的基准测试主要衡量通用智能而非教学能力。为了弥补这一空白，我们引入了ELMES，一个专门为评估教育环境中的LLMs而设计的开源自动化评估框架。ELMES具有模块化架构，使研究人员能够通过简单的配置文件创建动态、多智能体对话，从而在无需大量编程专业知识的情况下实现灵活的场景设计。该框架整合了一个混合评估引擎，使用“LLM作为评判者”的方法客观量化了传统上主观的教学指标。我们与教育专家合作开发了细粒度指标，并在四个关键教育场景中对最先进的LLMs进行了系统基准测试：知识点解释、引导式问题解决教学、跨学科教案生成和情境化问题生成。我们的结果表明模型之间存在明显的能力分布，揭示了特定情境下的优势和局限性。ELMES为教育工作者和研究人员提供了一个易于使用的评估框架，显著降低了各种教育应用的适应障碍，同时推动了LLMs在教学中的实际应用。该框架已公开发布于\\emph{https://github.com/sii-research/elmes.git}。", "summary": "ELMES是一个开源的自动化评估框架，旨在解决大型语言模型（LLMs）在教育场景中评估指标不足的问题。它采用模块化架构，允许灵活设计多智能体对话场景，并通过“LLM作为评判者”的方法客观量化主观教学指标。该框架对LLMs在知识解释、问题解决、教案生成和问题生成等四个教育场景进行了系统评估，揭示了不同模型的特定优势和局限性，旨在降低LLMs在教育领域应用的适应障碍。", "keywords": "大型语言模型, 教育场景, 评估框架, 教学评估, LLM-as-a-Judge", "comments": "ELMES的创新之处在于其专门针对教育场景设计评估框架，解决了现有通用LLM基准测试在教育教学能力评估上的不足。其模块化架构和“LLM作为评判者”的混合评估引擎是亮点，能够灵活设计评估场景并客观量化主观教学指标，这对于推进LLMs在教育领域的实际应用具有重要意义。该框架的开源性也促进了相关研究的社区合作。"}}
{"id": "2507.23374", "title": "NeRF Is a Valuable Assistant for 3D Gaussian Splatting", "authors": ["Shuangkang Fang", "I-Chao Shen", "Takeo Igarashi", "Yufeng Wang", "ZeSheng Wang", "Yi Yang", "Wenrui Ding", "Shuchang Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV", "url": "http://arxiv.org/abs/2507.23374v1", "summary": "We introduce NeRF-GS, a novel framework that jointly optimizes Neural\nRadiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). This framework\nleverages the inherent continuous spatial representation of NeRF to mitigate\nseveral limitations of 3DGS, including sensitivity to Gaussian initialization,\nlimited spatial awareness, and weak inter-Gaussian correlations, thereby\nenhancing its performance. In NeRF-GS, we revisit the design of 3DGS and\nprogressively align its spatial features with NeRF, enabling both\nrepresentations to be optimized within the same scene through shared 3D spatial\ninformation. We further address the formal distinctions between the two\napproaches by optimizing residual vectors for both implicit features and\nGaussian positions to enhance the personalized capabilities of 3DGS.\nExperimental results on benchmark datasets show that NeRF-GS surpasses existing\nmethods and achieves state-of-the-art performance. This outcome confirms that\nNeRF and 3DGS are complementary rather than competing, offering new insights\ninto hybrid approaches that combine 3DGS and NeRF for efficient 3D scene\nrepresentation.", "comment": "Accepted by ICCV", "pdf_url": "http://arxiv.org/pdf/2507.23374v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "NeRF 是 3D Gaussian Splatting 的宝贵助手", "tldr": "NeRF-GS通过联合优化NeRF和3DGS，克服了3DGS的局限性，实现了最先进的3D场景表示性能。", "motivation": "3D Gaussian Splatting (3DGS) 存在多项局限性，包括对高斯初始化敏感、空间感知能力有限以及高斯间相关性弱，这些限制阻碍了其性能提升。", "method": "本文提出了NeRF-GS框架，通过联合优化神经辐射场 (NeRF) 和 3D Gaussian Splatting (3DGS)。该框架利用NeRF固有的连续空间表示来缓解3DGS的局限性。NeRF-GS重新设计了3DGS，并逐步将其空间特征与NeRF对齐，通过共享3D空间信息在同一场景中优化两种表示。此外，还通过优化隐式特征和高斯位置的残差向量来处理两种方法之间的形式差异，以增强3DGS的个性化能力。", "result": "在基准数据集上的实验结果表明，NeRF-GS超越了现有方法，并实现了最先进的性能。", "conclusion": "NeRF和3DGS是互补而非竞争的关系，这为结合3DGS和NeRF的高效3D场景表示的混合方法提供了新见解。", "translation": "我们引入了NeRF-GS，这是一个新颖的框架，它联合优化了神经辐射场（NeRF）和3D高斯散射（3DGS）。该框架利用NeRF固有的连续空间表示来缓解3DGS的几个局限性，包括对高斯初始化的敏感性、有限的空间感知和弱的高斯间相关性，从而增强其性能。在NeRF-GS中，我们重新审视了3DGS的设计，并逐步将其空间特征与NeRF对齐，使得两种表示可以通过共享的3D空间信息在同一场景中进行优化。我们还通过优化隐式特征和高斯位置的残差向量来解决两种方法之间的形式区别，以增强3DGS的个性化能力。基准数据集上的实验结果表明，NeRF-GS超越了现有方法并取得了最先进的性能。这一结果证实了NeRF和3DGS是互补而非竞争的，为结合3DGS和NeRF以实现高效3D场景表示的混合方法提供了新的见解。", "summary": "本文提出了NeRF-GS框架，该框架通过联合优化NeRF和3DGS，利用NeRF的连续空间表示来克服3DGS在初始化敏感性、空间感知和高斯间相关性方面的局限性。NeRF-GS通过逐步对齐两种表示的空间特征并优化残差向量来增强3DGS的性能。实验结果表明，NeRF-GS超越了现有方法并达到了最先进的性能，证实了NeRF和3DGS的互补性，为高效3D场景表示的混合方法提供了新思路。", "keywords": "NeRF, 3D Gaussian Splatting, 联合优化, 3D场景表示, 混合方法", "comments": "本文创新性地提出了NeRF-GS框架，首次将NeRF与3DGS进行联合优化，有效解决了3DGS在初始化和空间感知方面的固有缺陷。通过利用NeRF的连续空间表示，显著提升了3DGS的性能。这项工作不仅证明了NeRF和3DGS的互补性，也为未来3D场景表示领域中混合模型的研究开辟了新的方向，具有重要的理论和实践意义。"}}
{"id": "2507.23404", "title": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring", "authors": ["Salah Eddine Bekhouche", "Azeddine Benlamoudi", "Yazid Bounab", "Fadi Dornaika", "Abdenour Hadid"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23404v1", "summary": "Arabic poses a particular challenge for natural language processing (NLP) and\ninformation retrieval (IR) due to its complex morphology, optional diacritics\nand the coexistence of Modern Standard Arabic (MSA) and various dialects.\nDespite the growing global significance of Arabic, it is still underrepresented\nin NLP research and benchmark resources. In this paper, we present an enhanced\nDense Passage Retrieval (DPR) framework developed specifically for Arabic. At\nthe core of our approach is a novel Attentive Relevance Scoring (ARS) that\nreplaces standard interaction mechanisms with an adaptive scoring function that\nmore effectively models the semantic relevance between questions and passages.\nOur method integrates pre-trained Arabic language models and architectural\nrefinements to improve retrieval performance and significantly increase ranking\naccuracy when answering Arabic questions. The code is made publicly available\nat \\href{https://github.com/Bekhouche/APR}{GitHub}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23404v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "增强型阿拉伯语文本检索与注意力相关性评分", "tldr": "本文提出了一种针对阿拉伯语的增强型密集段落检索（DPR）框架，引入了注意力相关性评分（ARS）来提高检索性能和排名准确性。", "motivation": "阿拉伯语由于其复杂的形态、可选的变音符号以及现代标准阿拉伯语（MSA）和各种方言的共存，对自然语言处理（NLP）和信息检索（IR）构成了特殊挑战。尽管阿拉伯语的全球重要性日益增长，但在NLP研究和基准资源中仍然代表性不足。", "method": "本文提出了一种增强型密集段落检索（DPR）框架，专门为阿拉伯语开发。其核心是新颖的注意力相关性评分（ARS），它用自适应评分函数取代了标准交互机制，更有效地模拟问题和段落之间的语义相关性。该方法集成了预训练的阿拉伯语语言模型和架构改进。", "result": "显著提高了检索性能，并显著增加了回答阿拉伯语问题时的排名准确性。", "conclusion": "本文提出的增强型DPR框架及其注意力相关性评分（ARS）能够有效应对阿拉伯语NLP和IR的挑战，显著提升了阿拉伯语文本检索的性能和排名准确性。", "translation": "阿拉伯语由于其复杂的形态、可选的变音符号以及现代标准阿拉伯语（MSA）和各种方言的共存，对自然语言处理（NLP）和信息检索（IR）构成了特殊挑战。尽管阿拉伯语的全球重要性日益增长，但在NLP研究和基准资源中仍然代表性不足。在本文中，我们提出了一种专门为阿拉伯语开发的增强型密集段落检索（DPR）框架。我们方法的核心是一种新颖的注意力相关性评分（ARS），它用自适应评分函数取代了标准交互机制，更有效地模拟问题和段落之间的语义相关性。我们的方法集成了预训练的阿拉伯语语言模型和架构改进，以提高检索性能并显著增加回答阿拉伯语问题时的排名准确性。代码已在GitHub上公开提供。", "summary": "本文针对阿拉伯语文本检索的挑战，提出了一种增强型密集段落检索（DPR）框架。该框架引入了新颖的注意力相关性评分（ARS）机制，用自适应函数取代传统交互，以更精确地建模问题与段落间的语义关联。结合预训练的阿拉伯语语言模型和架构优化，该方法显著提升了阿拉伯语问答的检索性能和排名准确性。", "keywords": "阿拉伯语, 文本检索, DPR, 注意力机制, 信息检索", "comments": "该论文通过引入注意力相关性评分（ARS）改进了密集段落检索（DPR）框架，专门针对阿拉伯语的复杂性进行了优化。其创新点在于ARS能够更精细地捕捉语义相关性，并结合阿拉伯语预训练模型，有效解决了阿拉伯语在NLP研究中代表性不足的问题，对提升阿拉伯语信息检索的准确性具有重要意义。代码的公开性也促进了相关研究的进展。"}}
{"id": "2503.17526", "title": "Beyond the Encoder: Joint Encoder-Decoder Contrastive Pre-Training Improves Dense Prediction", "authors": ["Sébastien Quetin", "Tapotosh Ghosh", "Farhad Maleki"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17526v2", "summary": "Contrastive learning methods in self-supervised settings have primarily\nfocused on pre-training encoders, while decoders are typically introduced and\ntrained separately for downstream dense prediction tasks. However, this\nconventional approach overlooks the potential benefits of jointly pre-training\nboth encoder and decoder. In this paper, we propose DeCon, an efficient\nencoder-decoder self-supervised learning (SSL) framework that supports joint\ncontrastive pre-training. We first extend existing SSL architectures to\naccommodate diverse decoders and their corresponding contrastive losses. Then,\nwe introduce a weighted encoder-decoder contrastive loss with non-competing\nobjectives to enable the joint pre-training of encoder-decoder architectures.\nBy adapting an established contrastive SSL framework for dense prediction\ntasks, DeCon achieves new state-of-the-art results: on COCO object detection\nand instance segmentation when pre-trained on COCO dataset; across almost all\ndense downstream benchmark tasks when pre-trained on COCO+ and ImageNet-1K. Our\nresults demonstrate that joint pre-training enhances the representation power\nof the encoder and improves performance in dense prediction tasks. This gain\npersists across heterogeneous decoder architectures, various encoder\narchitectures, and in out-of-domain limited-data scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17526v2", "cate": "cs.CV", "date": "2025-03-21", "updated": "2025-07-31", "AI": {"title_translation": "超越编码器：联合编码器-解码器对比预训练改进密集预测", "tldr": "DeCon是一个新的自监督学习框架，通过联合对比预训练编码器和解码器，显著提高了密集预测任务的性能，并在COCO和ImageNet-1K数据集上取得了SOTA结果。", "motivation": "现有的自监督对比学习方法主要集中于预训练编码器，而解码器通常独立训练，这忽略了联合预训练编码器和解码器的潜在益处。", "method": "本文提出了DeCon，一个高效的编码器-解码器自监督学习（SSL）框架，支持联合对比预训练。它扩展了现有SSL架构以适应不同的解码器及其对比损失，并引入了具有非竞争目标的加权编码器-解码器对比损失，以实现编码器-解码器架构的联合预训练。", "result": "DeCon在COCO目标检测和实例分割任务上（在COCO数据集上预训练）实现了新的最先进结果；在COCO+和ImageNet-1K上预训练时，在几乎所有密集下游基准任务上都表现出色。结果表明联合预训练增强了编码器的表示能力并提高了密集预测任务的性能，这种增益在异构解码器架构、各种编码器架构以及域外有限数据场景中都持续存在。", "conclusion": "联合预训练编码器和解码器能够显著提升密集预测任务的性能，并增强编码器的表示能力，且这种优势在多种架构和数据场景下都保持稳定。", "translation": "自监督设置中的对比学习方法主要集中于预训练编码器，而解码器通常为下游密集预测任务单独引入和训练。然而，这种传统方法忽视了联合预训练编码器和解码器的潜在益处。在本文中，我们提出了DeCon，一个高效的编码器-解码器自监督学习（SSL）框架，支持联合对比预训练。我们首先扩展了现有的SSL架构，以适应多样化的解码器及其相应的对比损失。然后，我们引入了一种具有非竞争目标的加权编码器-解码器对比损失，以实现编码器-解码器架构的联合预训练。通过为密集预测任务调整已建立的对比SSL框架，DeCon取得了新的最先进结果：在COCO数据集上预训练时，在COCO目标检测和实例分割任务上；在COCO+和ImageNet-1K上预训练时，几乎在所有密集下游基准任务上。我们的结果表明，联合预训练增强了编码器的表示能力，并提高了密集预测任务的性能。这种增益在异构解码器架构、各种编码器架构以及域外有限数据场景中都持续存在。", "summary": "本文提出了一种名为DeCon的自监督学习框架，旨在通过联合对比预训练编码器和解码器来改进密集预测任务。与以往仅关注编码器预训练的方法不同，DeCon扩展了现有SSL架构以支持多种解码器，并引入了一种加权编码器-解码器对比损失。实验结果表明，DeCon在COCO目标检测和实例分割以及其他密集预测基准任务上取得了SOTA性能，证明了联合预训练能够显著提升编码器表示能力和任务表现，并且该优势在不同架构和有限数据场景下依然有效。", "keywords": "对比学习, 自监督学习, 密集预测, 编码器-解码器, 预训练", "comments": "该论文的创新点在于突破了传统自监督学习中仅预训练编码器的范式，首次提出了编码器-解码器联合对比预训练的DeCon框架。其重要性在于证明了联合预训练对于提升密集预测任务性能的显著效果，并在多种数据集和架构上验证了其泛化能力，为未来的自监督学习研究提供了新的方向。"}}
{"id": "2507.23172", "title": "Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks", "authors": ["Vira Joshi", "Zifan Xu", "Bo Liu", "Peter Stone", "Amy Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      RLC 2025", "url": "http://arxiv.org/abs/2507.23172v1", "summary": "Multi-task Reinforcement Learning (MTRL) has emerged as a critical training\nparadigm for applying reinforcement learning (RL) to a set of complex\nreal-world robotic tasks, which demands a generalizable and robust policy. At\nthe same time, \\emph{massively parallelized training} has gained popularity,\nnot only for significantly accelerating data collection through GPU-accelerated\nsimulation but also for enabling diverse data collection across multiple tasks\nby simulating heterogeneous scenes in parallel. However, existing MTRL research\nhas largely been limited to off-policy methods like SAC in the\nlow-parallelization regime. MTRL could capitalize on the higher asymptotic\nperformance of on-policy algorithms, whose batches require data from the\ncurrent policy, and as a result, take advantage of massive parallelization\noffered by GPU-accelerated simulation. To bridge this gap, we introduce a\nmassively parallelized $\\textbf{M}$ulti-$\\textbf{T}$ask $\\textbf{Bench}$mark\nfor robotics (MTBench), an open-sourced benchmark featuring a broad\ndistribution of 50 manipulation tasks and 20 locomotion tasks, implemented\nusing the GPU-accelerated simulator IsaacGym. MTBench also includes four base\nRL algorithms combined with seven state-of-the-art MTRL algorithms and\narchitectures, providing a unified framework for evaluating their performance.\nOur extensive experiments highlight the superior speed of evaluating MTRL\napproaches using MTBench, while also uncovering unique challenges that arise\nfrom combining massive parallelism with MTRL. Code is available at\n$\\href{https://github.com/Viraj-Joshi/MTBench}{\nhttps://github.com/Viraj-Joshi/MTBench}$", "comment": "RLC 2025", "pdf_url": "http://arxiv.org/pdf/2507.23172v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "机器人任务中大规模并行化多任务强化学习的基准测试", "tldr": "引入MTBench，一个针对机器人任务的大规模并行化多任务强化学习开源基准，旨在弥补现有研究在并行化方面的不足，并加速MTRL算法的评估。", "motivation": "现有的多任务强化学习（MTRL）研究主要局限于低并行度下的离策略方法。然而，MTRL可以利用在GPU加速模拟中大规模并行化带来的高渐近性能的在策略算法，但目前缺乏一个能充分利用这种大规模并行化的基准。", "method": "引入了一个名为MTBench的开源基准，用于机器人领域的大规模并行化多任务强化学习。MTBench包含基于GPU加速模拟器IsaacGym实现的50个操作任务和20个运动任务，以及结合了四种基础RL算法和七种最先进MTRL算法及架构的统一评估框架。", "result": "实验表明，使用MTBench可以显著加快MTRL方法的评估速度，同时也揭示了将大规模并行化与MTRL结合时出现的独特挑战。", "conclusion": "MTBench成功弥补了现有MTRL研究在并行化方面的不足，提供了一个高效的评估平台，并为未来研究指明了方向，即探索大规模并行化MTRL带来的挑战与机遇。", "translation": "多任务强化学习（MTRL）已成为将强化学习（RL）应用于一系列复杂真实世界机器人任务的关键训练范式，这需要一个可泛化且鲁棒的策略。同时，大规模并行化训练已日益普及，不仅通过GPU加速模拟显著加快了数据收集，还通过并行模拟异构场景实现了跨多个任务的多样化数据收集。然而，现有的MTRL研究主要局限于低并行度下的SAC等离策略方法。MTRL可以利用在策略算法的更高渐近性能，这些算法的批处理需要来自当前策略的数据，因此可以利用GPU加速模拟提供的大规模并行化。为了弥补这一差距，我们引入了一个用于机器人领域的大规模并行化多任务基准（MTBench），这是一个开源基准，包含50个操作任务和20个运动任务的广泛分布，使用GPU加速模拟器IsaacGym实现。MTBench还包括四种基础RL算法与七种最先进的MTRL算法和架构的结合，提供了一个统一的框架来评估它们的性能。我们的大量实验突出了使用MTBench评估MTRL方法的卓越速度，同时也揭示了将大规模并行化与MTRL结合时出现的独特挑战。代码可在https://github.com/Viraj-Joshi/MTBench获取。", "summary": "这篇论文介绍了一个名为MTBench的开源基准，旨在解决现有机器人多任务强化学习（MTRL）研究在利用大规模并行化方面的不足。MTBench利用GPU加速模拟器IsaacGym，包含了50个操作任务和20个运动任务，并集成了多种基础RL算法和最先进的MTRL算法，提供了一个统一的评估框架。实验结果表明，MTBench显著提升了MTRL方法的评估效率，并揭示了大规模并行化与MTRL结合时的新挑战。", "keywords": "多任务强化学习, 大规模并行化, 机器人学, 基准测试, IsaacGym", "comments": "这篇论文的创新点在于构建了一个大规模并行化的MTRL基准，填补了当前研究在利用GPU加速模拟进行高效MTRL评估方面的空白。其重要性在于，通过提供统一的评估框架和丰富任务集，MTBench能够加速MTRL算法的开发与比较，并促使研究人员探索在策略算法在大规模并行环境下的潜力。同时，它也指出了大规模并行化MTRL可能带来的新挑战，为未来的研究方向提供了宝贵的见解。"}}
{"id": "2507.22910", "title": "Large Language Models in the Travel Domain: An Industrial Experience", "authors": ["Sergio Di Meglio", "Aniello Somma", "Luigi Libero Lucio Starace", "Fabio Scippacercola", "Giancarlo Sperlì", "Sergio Di Martino"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Manuscript accepted to the International Conference on Software Engineering and Knowledge Engineering (SEKE) 2025", "url": "http://arxiv.org/abs/2507.22910v1", "summary": "Online property booking platforms are widely used and rely heavily on\nconsistent, up-to-date information about accommodation facilities, often\nsourced from third-party providers. However, these external data sources are\nfrequently affected by incomplete or inconsistent details, which can frustrate\nusers and result in a loss of market. In response to these challenges, we\npresent an industrial case study involving the integration of Large Language\nModels (LLMs) into CALEIDOHOTELS, a property reservation platform developed by\nFERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,\nfine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.\nBoth models were assessed based on their ability to generate consistent and\nhomogeneous descriptions while minimizing hallucinations. Mixtral 8x7B\noutperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision\n(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet\nmore concise content (249 vs. 277 words on average). However, this came at a\nsignificantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB\nand $0.16/hour for Mistral 7B. Our findings provide practical insights into the\ntrade-offs between model quality and resource efficiency, offering guidance for\ndeploying LLMs in production environments and demonstrating their effectiveness\nin enhancing the consistency and reliability of accommodation data.", "comment": "Manuscript accepted to the International Conference on Software\n  Engineering and Knowledge Engineering (SEKE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.22910v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "大型语言模型在旅游领域的应用：一项工业实践", "tldr": "该研究将大型语言模型（LLMs）集成到酒店预订平台CALEIDOHOTELS中，以解决第三方数据源不一致和不完整的问题。Mixtral 8x7B在性能上优于Mistral 7B，但在计算成本上更高，提供了在生产环境中部署LLM的实用权衡见解。", "motivation": "在线住宿预订平台依赖第三方数据，但这些数据常不完整或不一致，导致用户体验不佳和市场损失。因此，需要有效的方法来提高住宿数据的一致性和可靠性。", "method": "本研究将大型语言模型（LLMs）集成到FERVENTO开发的住宿预订平台CALEIDOHOTELS中。评估了两种LLM：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。评估标准包括生成一致和同质描述的能力，并最大程度地减少幻觉。", "result": "Mixtral 8x7B在完整性（99.6% vs 93%）、准确性（98.8% vs 96%）和幻觉率（1.2% vs 4%）方面均优于Mistral 7B，且生成内容更短更简洁（平均249字 vs 277字）。然而，Mixtral 8x7B的计算成本显著更高（50GB VRAM和$1.61/小时 vs Mistral 7B的5GB和$0.16/小时）。", "conclusion": "研究结果为模型质量和资源效率之间的权衡提供了实用见解，为在生产环境中部署大型语言模型提供了指导，并证明了LLMs在增强住宿数据一致性和可靠性方面的有效性。", "translation": "在线住宿预订平台被广泛使用，并严重依赖于关于住宿设施的一致、最新的信息，这些信息通常来源于第三方供应商。然而，这些外部数据源经常受到不完整或不一致细节的影响，这可能使用户感到沮丧并导致市场损失。为应对这些挑战，我们提出了一个工业案例研究，涉及将大型语言模型（LLMs）集成到FERVENTO开发的住宿预订平台CALEIDOHOTELS中。我们在此背景下评估了两种知名的大型语言模型：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。两种模型都根据其生成一致和同质描述同时最大程度地减少幻觉的能力进行了评估。Mixtral 8x7B在完整性（99.6% 对 93%）、准确性（98.8% 对 96%）和幻觉率（1.2% 对 4%）方面均优于Mistral 7B，生成的内容更短但更简洁（平均249字 对 277字）。然而，这带来了显著更高的计算成本：50GB显存和1.61美元/小时，而Mistral 7B为5GB和0.16美元/小时。我们的发现为模型质量和资源效率之间的权衡提供了实用见解，为在生产环境中部署大型语言模型提供了指导，并证明了它们在增强住宿数据一致性和可靠性方面的有效性。", "summary": "本工业案例研究探讨了将大型语言模型（LLMs）集成到在线住宿预订平台CALEIDOHOTELS中，以解决第三方数据源不一致的问题。研究比较了Mistral 7B（QLoRA微调）和Mixtral 8x7B（优化提示），发现Mixtral 8x7B在数据完整性、准确性和幻觉率方面表现更优，但计算成本显著更高。研究提供了在生产环境中部署LLMs时，模型质量与资源效率之间权衡的实用见解，并证明了LLMs在提高住宿数据一致性方面的有效性。", "keywords": "大型语言模型, 旅游领域, 数据一致性, 工业实践, 成本效益", "comments": "本文通过一个具体的工业案例，展示了大型语言模型在解决实际业务问题（如数据一致性）中的应用潜力。其创新点在于对不同LLM（Mistral 7B和Mixtral 8x7B）在特定业务场景下的性能和成本进行了量化比较，为企业在生产环境中选择和部署LLM提供了宝贵的实践指导。这种对性能与成本权衡的深入分析，对于LLM的实际落地具有重要意义。"}}
{"id": "2507.22937", "title": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering", "authors": ["Jinkun Zhao", "Yuanshuai Wang", "Xingjian Zhang", "Ruibo Chen", "Xingchuang Liao", "Junle Wang", "Lei Huang", "Kui Zhang", "Wenjun Wu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22937v1", "summary": "With the rapid evolution of artificial intelligence, AIOps has emerged as a\nprominent paradigm in DevOps. Lots of work has been proposed to improve the\nperformance of different AIOps phases. However, constrained by domain-specific\nknowledge, a single model can only handle the operation requirement of a\nspecific task,such as log parser,root cause analysis. Meanwhile, combining\nmultiple models can achieve more efficient results, which have been proved in\nboth previous ensemble learning and the recent LLM training domain. Inspired by\nthese works,to address the similar challenges in AIOPS, this paper first\nproposes a collaboration-of-expert framework(CoE-Ops) incorporating a\ngeneral-purpose large language model task classifier. A retrieval-augmented\ngeneration mechanism is introduced to improve the framework's capability in\nhandling both Question-Answering tasks with high-level(Code,build,Test,etc.)\nand low-level(fault analysis,anomaly detection,etc.). Finally, the proposed\nmethod is implemented in the AIOps domain, and extensive experiments are\nconducted on the DevOps-EVAL dataset. Experimental results demonstrate that\nCoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps\ntasks compared to existing CoE methods, delivers up to 8% accuracy enhancement\nover single AIOps models in DevOps problem resolution, and outperforms\nlarger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22937v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "CoE-Ops：基于LLM专家的协作，用于AIOps问答", "tldr": "CoE-Ops是一个基于大型语言模型（LLM）的专家协作框架，通过引入通用LLM任务分类器和检索增强生成机制，显著提升了AIOps问答任务的准确性，尤其是在高层级AIOps任务和DevOps问题解决方面。", "motivation": "现有的单一模型受限于领域特定知识，只能处理特定AIOps任务，无法高效处理多样化的操作需求。结合多个模型已被证明能带来更高效的结果，这激发了本文解决AIOps中类似挑战的动机。", "method": "本文提出了一个专家协作框架（CoE-Ops），其中包含一个通用大型语言模型任务分类器。为了增强框架处理高层级（如代码、构建、测试）和低层级（如故障分析、异常检测）问答任务的能力，引入了检索增强生成（RAG）机制。该方法在AIOps领域进行了实现。", "result": "CoE-Ops在DevOps-EVAL数据集上进行了实验。结果显示，与现有CoE方法相比，它在高层级AIOps任务的路由准确性方面提高了72%；在DevOps问题解决中，相对于单一AIOps模型，准确性提升了高达8%；并且在准确性方面，比更大规模的专家混合（MoE）模型高出14%。", "conclusion": "本文提出的CoE-Ops框架通过结合LLM专家协作和RAG机制，有效解决了AIOps领域中单一模型局限性和多样化任务处理的挑战，并显著提升了问答准确性。", "translation": "随着人工智能的快速发展，AIOps已成为DevOps中一个重要的范式。许多工作已经被提出以改善不同AIOps阶段的性能。然而，受限于领域特定知识，单一模型只能处理特定任务的操作需求，例如日志解析器、根本原因分析。同时，结合多个模型可以实现更高效的结果，这在之前的集成学习和最近的LLM训练领域都已得到证明。受这些工作的启发，为了解决AIOps中类似的挑战，本文首次提出了一个专家协作框架（CoE-Ops），其中包含一个通用大型语言模型任务分类器。引入了检索增强生成机制，以提高框架处理高层级（代码、构建、测试等）和低层级（故障分析、异常检测等）问答任务的能力。最后，所提出的方法在AIOps领域中实现，并在DevOps-EVAL数据集上进行了广泛的实验。实验结果表明，与现有CoE方法相比，CoE-Ops在高层级AIOps任务的路由准确性方面实现了72%的改进，在DevOps问题解决方面，相对于单一AIOps模型，准确性提升了高达8%，并且在准确性方面，比更大规模的专家混合（MoE）模型高出高达14%。", "summary": "本文提出了CoE-Ops（基于LLM专家的协作）框架，旨在解决AIOps领域中单一模型处理能力受限的问题。该框架结合了通用大型语言模型任务分类器和检索增强生成（RAG）机制，使其能够高效处理高层级和低层级的AIOps问答任务。在DevOps-EVAL数据集上的实验证明，CoE-Ops在路由准确性、问题解决准确性方面显著优于现有CoE方法、单一AIOps模型以及MoE模型。", "keywords": "AIOps, LLM, 专家协作, 问答, RAG", "comments": "CoE-Ops的创新点在于将LLM的通用能力与专家协作框架相结合，并通过RAG机制增强了其在AIOps问答任务中的表现。这种方法有效地解决了传统单一模型在处理复杂多样AIOps任务时的局限性，并通过实验数据展示了其显著的性能提升，尤其是在处理高层级AIOps任务时的路由准确性和整体问题解决能力。"}}
{"id": "2409.03146", "title": "Optimal Placement and Coordinated Scheduling of Distributed Space-Based Lasers for Orbital Debris Remediation", "authors": ["David O. Williams Rogers", "Matthew C. Fox", "Paul R. Stysley", "Hang Woon Lee"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      42 pages, Advances in Space Research (accepted), Copyright 2025. This manuscript version is made available under the CC-BY-NC-ND 4.0 license", "url": "http://arxiv.org/abs/2409.03146v3", "summary": "The significant expansion of the orbital debris population poses a serious\nthreat to the safety and sustainability of space operations. This paper\ninvestigates orbital debris remediation through a constellation of\ncollaborative space-based lasers, leveraging the principle of momentum transfer\nonto debris via laser ablation. A novel delta-v vector analysis framework\nquantifies the cumulative effects of multiple concurrent laser-to-debris (L2D)\nengagements by utilizing the vector composition of the imparted delta-v\nvectors. The paper formulates the Concurrent Location-Scheduling Optimization\nProblem (CLSP) to optimize the placement of laser platforms and the scheduling\nof L2D engagements, aiming to maximize debris remediation capacity. Given the\ncomputational intractability of the CLSP, a decomposition strategy is employed,\nyielding two sequential subproblems: (1) determining optimal laser platform\nlocations via the Maximal Covering Location Problem, and (2) scheduling L2D\nengagements using a novel integer linear programming approach to maximize\ndebris remediation capacity. Computational experiments evaluate the efficacy of\nthe proposed framework across diverse mission scenarios, demonstrating critical\nconstellation functions such as collaborative and controlled nudging,\ndeorbiting, and just-in-time collision avoidance. A sensitivity analysis\nfurther explores the impact of varying the number and distribution of laser\nplatforms on debris remediation capacity, offering insights into optimizing the\nperformance of space-based laser constellations.", "comment": "42 pages, Advances in Space Research (accepted), Copyright 2025. This\n  manuscript version is made available under the CC-BY-NC-ND 4.0 license", "pdf_url": "http://arxiv.org/pdf/2409.03146v3", "cate": "math.OC", "date": "2024-09-05", "updated": "2025-07-30", "AI": {"title_translation": "用于轨道碎片清除的分布式天基激光器优化部署与协同调度", "tldr": "本论文研究了利用分布式天基激光器星座通过激光烧蚀清除轨道碎片的问题，提出了一个优化激光平台位置和激光对碎片交战调度的框架，并通过分解策略解决了计算难题，实验证明了其在碎片清除和避免碰撞方面的有效性。", "motivation": "轨道碎片数量的显著增长对空间操作的安全性和可持续性构成了严重威胁，因此需要有效的轨道碎片清除方法。", "method": "论文提出了一个新颖的delta-v矢量分析框架来量化多次激光对碎片交战的累积效应。为了最大化碎片清除能力，论文构建了并发位置-调度优化问题（CLSP），并由于其计算复杂性，采用了分解策略，将其分解为两个子问题：1) 通过最大覆盖位置问题确定最优激光平台位置；2) 使用新颖的整数线性规划方法调度激光对碎片交战。", "result": "计算实验评估了所提出框架在不同任务场景下的效率，展示了关键的星座功能，如协同和受控的微调、离轨以及即时碰撞规避。敏感性分析进一步探讨了激光平台数量和分布对碎片清除能力的影响，为优化天基激光星座性能提供了见解。", "conclusion": "Not mentioned in abstract", "translation": "轨道碎片数量的显著增长对空间操作的安全性和可持续性构成了严重威胁。本文研究了通过协同天基激光器星座清除轨道碎片的方法，利用激光烧蚀将动量传递给碎片。一个新颖的delta-v矢量分析框架通过利用所施加的delta-v矢量的矢量合成，量化了多次并发激光对碎片（L2D）交战的累积效应。本文提出了并发位置-调度优化问题（CLSP），以优化激光平台的位置和L2D交战的调度，旨在最大化碎片清除能力。鉴于CLSP的计算难解性，本文采用了分解策略，产生了两个顺序子问题：(1) 通过最大覆盖位置问题确定最优激光平台位置，以及(2) 使用新颖的整数线性规划方法调度L2D交战以最大化碎片清除能力。计算实验评估了所提出框架在不同任务场景下的有效性，展示了关键的星座功能，如协同和受控的微调、离轨和即时碰撞规避。敏感性分析进一步探讨了改变激光平台数量和分布对碎片清除能力的影响，为优化天基激光星座的性能提供了见解。", "summary": "本论文针对日益增长的轨道碎片问题，提出了一种利用分布式天基激光器星座进行碎片清除的方案。研究引入了delta-v矢量分析框架来量化多激光交战的累积效应，并构建了并发位置-调度优化问题（CLSP）以优化激光平台部署和交战调度。为解决CLSP的计算复杂性，论文将其分解为最优位置确定（通过最大覆盖位置问题）和交战调度（通过整数线性规划）两个子问题。实验证明了该框架在协同碎片微调、离轨和碰撞规避方面的有效性，并通过敏感性分析提供了优化星座性能的策略。", "keywords": "轨道碎片清除, 天基激光器, 优化部署, 调度, 激光烧蚀", "comments": "该论文提出了一种创新的方法来解决日益严重的轨道碎片问题，通过优化天基激光器的部署和调度，有效地提高了碎片清除能力。其分解策略有效地处理了复杂的优化问题，并展示了实际应用潜力，对于空间安全领域具有重要意义。"}}
{"id": "2507.23408", "title": "An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients", "authors": ["Yuan-Yuan Huang", "Wei Qu", "Sean Y. Hon", "Siu-Long Lei"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23408v1", "summary": "In this paper, we propose an efficient method for solving multi-dimensional\nRiesz space fractional diffusion equations with variable coefficients. The\nCrank-Nicolson (CN) method is used for temporal discretization, while the\nfourth-order fractional centered difference (4FCD) method is employed for\nspatial discretization. Using a novel technique, we show that the CN-4FCD\nscheme for the multi-dimensional case is unconditionally stable and convergent,\nachieving second-order accuracy in time and fourth-order accuracy in space with\nrespect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level\nToeplitz-like structure of the coefficient matrix in the discrete linear\nsystems, we enhance the computational efficiency of the proposed scheme with a\nsine transform-based preconditioner, ensuring a mesh-size-independent\nconvergence rate for the conjugate gradient method. Finally, two numerical\nexamples validate the theoretical analysis and demonstrate the superior\nperformance of the proposed preconditioner compared to existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23408v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "变系数多维Riesz空间分数阶扩散方程高阶格式的最优预条件子", "tldr": "提出了一种求解变系数多维Riesz空间分数阶扩散方程的高效高阶方法，该方法通过CN-4FCD格式实现无条件稳定和高精度，并通过基于正弦变换的预条件子提高了计算效率。", "motivation": "解决变系数多维Riesz空间分数阶扩散方程的计算问题，并提高其求解效率。", "method": "时间离散化采用Crank-Nicolson (CN) 方法，空间离散化采用四阶分数阶中心差分 (4FCD) 方法。利用新颖技术证明了CN-4FCD格式的无条件稳定性和收敛性。为提高计算效率，利用系数矩阵的对称多级Toeplitz-like结构，提出了基于正弦变换的预条件子，用于共轭梯度法。", "result": "CN-4FCD格式在多维情况下是无条件稳定和收敛的，在离散L2范数下，时间达到二阶精度，空间达到四阶精度。提出的预条件子使得共轭梯度法具有网格尺寸无关的收敛速度。数值例子验证了理论分析，并表明所提出的预条件子性能优于现有方法。", "conclusion": "所提出的求解变系数多维Riesz空间分数阶扩散方程的高阶格式及其最优预条件子是高效且性能优越的，数值结果支持了理论分析。", "translation": "在本文中，我们提出了一种求解变系数多维Riesz空间分数阶扩散方程的高效方法。时间离散化采用Crank-Nicolson (CN) 方法，空间离散化采用四阶分数阶中心差分 (4FCD) 方法。我们采用一种新颖的技术表明，多维情况下的CN-4FCD格式是无条件稳定和收敛的，在离散L2范数下，时间上达到二阶精度，空间上达到四阶精度。此外，利用离散线性系统中系数矩阵的对称多级Toeplitz-like结构，我们通过基于正弦变换的预条件子提高了所提出格式的计算效率，确保了共轭梯度法具有与网格尺寸无关的收敛速度。最后，两个数值例子验证了理论分析，并展示了所提出的预条件子与现有方法相比的优越性能。", "summary": "本文提出了一种高效的数值方法来求解变系数多维Riesz空间分数阶扩散方程。该方法结合Crank-Nicolson和四阶分数阶中心差分进行时空离散化，并被证明是无条件稳定且高精度（时间二阶，空间四阶）的。为提高计算效率，作者设计了一个基于正弦变换的预条件子，利用系数矩阵的特殊结构，确保了共轭梯度法收敛速度与网格尺寸无关。数值实验验证了该方法的理论性能和预条件子的优越性。", "keywords": "Riesz分数阶扩散方程, 高阶格式, 预条件子, Crank-Nicolson, 稳定性", "comments": "这篇论文的创新点在于提出了一个高效的预条件子，该预条件子利用了离散化后系数矩阵的特殊结构，显著提升了求解变系数多维Riesz空间分数阶扩散方程的计算效率，并保证了收敛速度的网格无关性。同时，对所提出高阶格式的无条件稳定性和收敛性进行了严格的理论证明，增加了研究的严谨性。"}}
{"id": "2408.12319", "title": "Neural-ANOVA: Analytical Model Decomposition using Automatic Integration", "authors": ["Steffen Limmer", "Steffen Udluft", "Clemens Otte"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 3 tables, accepted for publication at MLSP 2025", "url": "http://arxiv.org/abs/2408.12319v2", "summary": "The analysis of variance (ANOVA) decomposition offers a systematic method to\nunderstand the interaction effects that contribute to a specific decision\noutput. In this paper we introduce Neural-ANOVA, an approach to decompose\nneural networks into the sum of lower-order models using the functional ANOVA\ndecomposition. Our approach formulates a learning problem, which enables fast\nanalytical evaluation of integrals over subspaces that appear in the\ncalculation of the ANOVA decomposition. Finally, we conduct numerical\nexperiments to provide insights into the approximation properties compared to\nother regression approaches from the literature.", "comment": "6 pages, 3 figures, 3 tables, accepted for publication at MLSP 2025", "pdf_url": "http://arxiv.org/pdf/2408.12319v2", "cate": "stat.ML", "date": "2024-08-22", "updated": "2025-07-31", "AI": {"title_translation": "神经-ANOVA：使用自动积分的分析模型分解", "tldr": "本文介绍了Neural-ANOVA，一种利用函数ANOVA分解将神经网络分解为低阶模型之和的方法，该方法能实现积分的快速解析评估。", "motivation": "方差分析（ANOVA）分解提供了一种理解对特定决策输出有贡献的交互效应的系统方法。本文的动机是引入Neural-ANOVA，以将神经网络分解为低阶模型之和，并实现ANOVA分解计算中出现的子空间积分的快速解析评估。", "method": "本文引入了Neural-ANOVA，这是一种利用函数ANOVA分解将神经网络分解为低阶模型之和的方法。该方法将ANOVA分解的计算公式化为一个学习问题，从而能够快速解析评估在计算过程中出现的子空间上的积分。", "result": "数值实验提供了与文献中其他回归方法相比，Neural-ANOVA近似特性方面的见解。", "conclusion": "本文提出了Neural-ANOVA，一种用于神经网络分析模型分解的方法，并通过数值实验提供了其近似特性的见解。", "translation": "方差分析（ANOVA）分解提供了一种系统的方法来理解对特定决策输出有贡献的交互效应。在本文中，我们引入了Neural-ANOVA，这是一种使用函数ANOVA分解将神经网络分解为低阶模型之和的方法。我们的方法提出了一个学习问题，该问题能够快速解析评估在ANOVA分解计算中出现的子空间上的积分。最后，我们进行了数值实验，以提供与文献中其他回归方法相比的近似特性方面的见解。", "summary": "本文提出了Neural-ANOVA，一种利用函数ANOVA分解将神经网络分解为低阶模型之和的新方法。该方法将分解过程公式化为一个学习问题，从而实现了在ANOVA分解计算中出现的子空间上积分的快速解析评估。通过数值实验，论文深入探讨了Neural-ANOVA与其他回归方法相比的近似特性。", "keywords": "Neural-ANOVA, ANOVA分解, 神经网络, 模型分解, 自动积分", "comments": "该论文的创新之处在于将函数ANOVA分解应用于神经网络，并将其公式化为一个学习问题，从而实现了高效的解析积分评估。这可能为理解复杂神经网络的决策提供了更好的可解释性，通过将其分解为更简单的组件。其重要性在于提高了神经网络的可解释性。"}}
{"id": "2507.22954", "title": "Neural Autoregressive Modeling of Brain Aging", "authors": ["Ridvan Yesiloglu", "Wei Peng", "Md Tauhidul Islam", "Ehsan Adeli"], "categories": ["cs.LG", "eess.IV", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at Deep Generative Models Workshop @ MICCAI 2025", "url": "http://arxiv.org/abs/2507.22954v1", "summary": "Brain aging synthesis is a critical task with broad applications in clinical\nand computational neuroscience. The ability to predict the future structural\nevolution of a subject's brain from an earlier MRI scan provides valuable\ninsights into aging trajectories. Yet, the high-dimensionality of data, subtle\nchanges of structure across ages, and subject-specific patterns constitute\nchallenges in the synthesis of the aging brain. To overcome these challenges,\nwe propose NeuroAR, a novel brain aging simulation model based on generative\nautoregressive transformers. NeuroAR synthesizes the aging brain by\nautoregressively estimating the discrete token maps of a future scan from a\nconvenient space of concatenated token embeddings of a previous and future\nscan. To guide the generation, it concatenates into each scale the subject's\nprevious scan, and uses its acquisition age and the target age at each block\nvia cross-attention. We evaluate our approach on both the elderly population\nand adolescent subjects, demonstrating superior performance over\nstate-of-the-art generative models, including latent diffusion models (LDM) and\ngenerative adversarial networks, in terms of image fidelity. Furthermore, we\nemploy a pre-trained age predictor to further validate the consistency and\nrealism of the synthesized images with respect to expected aging patterns.\nNeuroAR significantly outperforms key models, including LDM, demonstrating its\nability to model subject-specific brain aging trajectories with high fidelity.", "comment": "Accepted at Deep Generative Models Workshop @ MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.22954v1", "cate": "cs.LG", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "脑部衰老的神经自回归建模", "tldr": "提出NeuroAR，一种基于自回归Transformer的脑部衰老模拟模型，能高保真地预测个体脑部衰老轨迹，优于现有SOTA模型。", "motivation": "脑部衰老合成在临床和计算神经科学中具有广泛应用，从早期MRI预测未来脑部结构演变能提供有价值的衰老轨迹洞察。然而，数据高维度、结构细微变化和个体特异性模式给衰老脑部合成带来了挑战。", "method": "提出NeuroAR，一种基于生成式自回归Transformer的新型脑部衰老模拟模型。NeuroAR通过自回归地估计来自先前和未来扫描的连接令牌嵌入的便捷空间中的未来扫描的离散令牌图来合成衰老的脑部。为了指导生成，它在每个尺度中连接受试者的先前扫描，并通过交叉注意力在每个块中使用其采集年龄和目标年龄。", "result": "在老年人群和青少年受试者上进行评估，在图像保真度方面，表现优于最先进的生成模型，包括潜在扩散模型（LDM）和生成对抗网络。此外，使用预训练的年龄预测器进一步验证了合成图像与预期衰老模式的一致性和真实性。NeuroAR显著优于包括LDM在内的关键模型，证明了其高保真度地建模受试者特异性脑部衰老轨迹的能力。", "conclusion": "NeuroAR能够高保真地建模受试者特异性脑部衰老轨迹，并在图像保真度方面表现出优于现有最先进生成模型的卓越性能。", "translation": "脑部衰老合成是一项在临床和计算神经科学中具有广泛应用的关键任务。从早期MRI扫描预测受试者脑部未来结构演变的能力，为衰老轨迹提供了有价值的见解。然而，数据的高维度、结构在不同年龄段的细微变化以及受试者特异性模式构成了衰老脑部合成的挑战。为了克服这些挑战，我们提出了NeuroAR，这是一种基于生成式自回归Transformer的新型脑部衰老模拟模型。NeuroAR通过自回归地估计来自先前和未来扫描的连接令牌嵌入的便捷空间中的未来扫描的离散令牌图来合成衰老的脑部。为了指导生成，它在每个尺度中连接受试者的先前扫描，并通过交叉注意力在每个块中使用其采集年龄和目标年龄。我们在老年人群和青少年受试者上评估了我们的方法，结果表明在图像保真度方面，其性能优于最先进的生成模型，包括潜在扩散模型（LDM）和生成对抗网络。此外，我们采用预训练的年龄预测器，以进一步验证合成图像与预期衰老模式的一致性和真实性。NeuroAR显著优于包括LDM在内的关键模型，证明了其高保真度地建模受试者特异性脑部衰老轨迹的能力。", "summary": "本文提出了一种名为NeuroAR的新型脑部衰老模拟模型，该模型基于生成式自回归Transformer，旨在克服现有方法在处理高维数据、细微结构变化和个体特异性模式方面的挑战。NeuroAR通过自回归地预测未来扫描的离散令牌图来合成衰老脑部，并利用先前扫描和年龄信息进行引导。实验结果表明，NeuroAR在图像保真度方面优于包括LDM和GAN在内的现有最先进生成模型，并且能够高保真地模拟受试者特异性的脑部衰老轨迹。", "keywords": "脑部衰老, 自回归模型, Transformer, 生成模型, MRI", "comments": "NeuroAR的创新之处在于将自回归Transformer应用于脑部衰老模拟，并有效解决了高维数据和个体特异性模式的挑战。其通过利用先前扫描和年龄信息进行引导的机制，提高了合成图像的真实性和与预期衰老模式的一致性。该模型在临床和计算神经科学中具有重要应用潜力，尤其是在预测个体脑部衰老轨迹方面。"}}
{"id": "2507.23391", "title": "Policy Learning from Large Vision-Language Model Feedback without Reward Modeling", "authors": ["Tung M. Luu", "Donghoon Lee", "Younghwan Lee", "Chang D. Yoo"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025", "url": "http://arxiv.org/abs/2507.23391v1", "summary": "Offline reinforcement learning (RL) provides a powerful framework for\ntraining robotic agents using pre-collected, suboptimal datasets, eliminating\nthe need for costly, time-consuming, and potentially hazardous online\ninteractions. This is particularly useful in safety-critical real-world\napplications, where online data collection is expensive and impractical.\nHowever, existing offline RL algorithms typically require reward labeled data,\nwhich introduces an additional bottleneck: reward function design is itself\ncostly, labor-intensive, and requires significant domain expertise. In this\npaper, we introduce PLARE, a novel approach that leverages large\nvision-language models (VLMs) to provide guidance signals for agent training.\nInstead of relying on manually designed reward functions, PLARE queries a VLM\nfor preference labels on pairs of visual trajectory segments based on a\nlanguage task description. The policy is then trained directly from these\npreference labels using a supervised contrastive preference learning objective,\nbypassing the need to learn explicit reward models. Through extensive\nexperiments on robotic manipulation tasks from the MetaWorld, PLARE achieves\nperformance on par with or surpassing existing state-of-the-art VLM-based\nreward generation methods. Furthermore, we demonstrate the effectiveness of\nPLARE in real-world manipulation tasks with a physical robot, further\nvalidating its practical applicability.", "comment": "Accepted to IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.23391v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "从大型视觉语言模型反馈中学习策略，无需奖励建模", "tldr": "PLARE是一种新颖的离线强化学习方法，它利用大型视觉语言模型直接提供偏好标签来训练机器人策略，避免了传统奖励模型设计的高昂成本和复杂性，并在实验中取得了与现有最先进方法相当或更优的性能，并在真实机器人上验证了其有效性。", "motivation": "现有的离线强化学习算法通常需要奖励标注数据，但奖励函数的设计本身成本高昂、劳动密集且需要大量领域专业知识，这成为了一个额外的瓶颈。", "method": "本文引入了PLARE方法，该方法利用大型视觉语言模型（VLMs）为智能体训练提供指导信号。PLARE通过语言任务描述，向VLM查询视觉轨迹片段对的偏好标签，然后使用监督对比偏好学习目标直接从这些偏好标签训练策略，从而绕过了学习显式奖励模型的需要。", "result": "PLARE在MetaWorld的机器人操作任务上取得了与现有最先进的基于VLM的奖励生成方法相当或超越的性能。此外，PLARE在真实机器人上的实际操作任务中也展现了有效性。", "conclusion": "PLARE提供了一种有效且实用的方法，利用大型视觉语言模型反馈直接进行策略学习，无需复杂的奖励建模，从而克服了离线强化学习中的一个关键瓶颈，并展现了其在现实世界应用中的潜力。", "translation": "离线强化学习（RL）提供了一个强大的框架，用于使用预先收集的次优数据集训练机器人智能体，从而消除了昂贵、耗时且可能危险的在线交互需求。这在安全关键的现实世界应用中特别有用，因为在线数据收集既昂贵又不切实际。然而，现有的离线RL算法通常需要奖励标注数据，这引入了一个额外的瓶颈：奖励函数设计本身成本高昂、劳动密集且需要大量的领域专业知识。在本文中，我们引入了PLARE，这是一种新颖的方法，它利用大型视觉语言模型（VLMs）为智能体训练提供指导信号。PLARE不依赖手动设计的奖励函数，而是根据语言任务描述，向VLM查询视觉轨迹片段对的偏好标签。然后，策略直接从这些偏好标签中通过监督对比偏好学习目标进行训练，从而绕过了学习显式奖励模型的需要。通过在MetaWorld的机器人操作任务上进行大量实验，PLARE取得了与现有最先进的基于VLM的奖励生成方法相当或超越的性能。此外，我们还展示了PLARE在物理机器人真实世界操作任务中的有效性，进一步验证了其实际适用性。", "summary": "本文提出了一种名为PLARE的新型离线强化学习方法，旨在解决传统方法中奖励函数设计成本高昂且耗时的问题。PLARE利用大型视觉语言模型（VLMs）直接从语言任务描述中获取视觉轨迹片段的偏好标签，并使用监督对比偏好学习目标来训练策略，从而无需构建显式奖励模型。实验结果表明，PLARE在机器人操作任务上表现出色，性能与现有最佳的基于VLM的奖励生成方法相当或更优，并在真实机器人上验证了其在现实世界应用中的有效性。", "keywords": "离线强化学习, 视觉语言模型, 策略学习, 奖励建模, 偏好学习", "comments": "PLARE的创新之处在于通过利用大型视觉语言模型直接进行偏好学习，成功规避了传统离线强化学习中奖励模型设计这一主要瓶颈。这极大地降低了数据标注的复杂性和成本，使得离线强化学习在实际应用中更具可行性。其在真实机器人上的验证进一步突显了该方法的实用性和重要性。"}}
{"id": "2502.17482", "title": "MVCNet: Multi-View Contrastive Network for Motor Imagery Classification", "authors": ["Ziwei Wang", "Siyang Li", "Xiaoqing Chen", "Dongrui Wu"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      12 pages, 9 figures", "url": "http://arxiv.org/abs/2502.17482v4", "summary": "Electroencephalography (EEG)-based brain-computer interfaces (BCIs) enable\nneural interaction by decoding brain activity for external communication. Motor\nimagery (MI) decoding has received significant attention due to its intuitive\nmechanism. However, most existing models rely on single-stream architectures\nand overlook the multi-view nature of EEG signals, leading to limited\nperformance and generalization. We propose a multi-view contrastive network\n(MVCNet), a dual-branch architecture that parallelly integrates CNN and\nTransformer blocks to capture both local spatial-temporal features and global\ntemporal dependencies. To enhance the informativeness of training data, MVCNet\nincorporates a unified augmentation pipeline across time, frequency, and\nspatial domains. Two contrastive modules are further introduced: a cross-view\ncontrastive module that enforces consistency of original and augmented views,\nand a cross-model contrastive module that aligns features extracted from both\nbranches. Final representations are fused and jointly optimized by contrastive\nand classification losses. Experiments on five public MI datasets across three\nscenarios demonstrate that MVCNet consistently outperforms nine\nstate-of-the-art MI decoding networks, highlighting its effectiveness and\ngeneralization ability. MVCNet provides a robust solution for MI decoding by\nintegrating multi-view information and dual-branch modeling, contributing to\nthe development of more reliable BCI systems.", "comment": "12 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2502.17482v4", "cate": "eess.SP", "date": "2025-02-18", "updated": "2025-07-31", "AI": {"title_translation": "MVCNet：用于运动想象分类的多视图对比网络", "tldr": "MVCNet是一种双分支多视图对比网络，用于运动想象分类，通过整合多视图信息和数据增强，显著优于现有SOTA模型。", "motivation": "现有的运动想象解码模型大多依赖单流架构，忽略了脑电信号的多视图特性，导致性能和泛化能力有限。", "method": "MVCNet是一个双分支架构，并行集成CNN和Transformer模块以捕获局部时空特征和全局时间依赖。它引入了跨时间、频率和空间域的统一增强管道。此外，包含两个对比模块：一个跨视图对比模块用于强制原始视图和增强视图的一致性，以及一个跨模型对比模块用于对齐两个分支提取的特征。最终表示通过对比损失和分类损失联合优化。", "result": "在五个公共运动想象数据集上的实验表明，MVCNet在三种场景下始终优于九个最先进的运动想象解码网络。", "conclusion": "MVCNet通过整合多视图信息和双分支建模，为运动想象解码提供了一个鲁棒的解决方案，有助于开发更可靠的BCI系统。", "translation": "基于脑电图（EEG）的脑机接口（BCI）通过解码大脑活动进行外部通信，从而实现神经交互。运动想象（MI）解码因其直观的机制而受到广泛关注。然而，大多数现有模型依赖于单流架构，并忽略了脑电信号的多视图特性，导致性能和泛化能力有限。我们提出了一种多视图对比网络（MVCNet），这是一种双分支架构，并行集成了CNN和Transformer模块，以捕获局部时空特征和全局时间依赖。为了增强训练数据的信息量，MVCNet在时间、频率和空间域中整合了一个统一的增强管道。进一步引入了两个对比模块：一个跨视图对比模块，用于强制原始视图和增强视图的一致性；以及一个跨模型对比模块，用于对齐从两个分支提取的特征。最终表示通过对比损失和分类损失联合优化。在三个场景下的五个公共MI数据集上的实验表明，MVCNet始终优于九个最先进的MI解码网络，突出了其有效性和泛化能力。MVCNet通过整合多视图信息和双分支建模，为MI解码提供了一个鲁棒的解决方案，有助于开发更可靠的BCI系统。", "summary": "本论文提出了MVCNet，一个用于运动想象分类的多视图对比网络。它采用双分支架构，结合CNN和Transformer以捕捉多尺度特征。为提升数据信息量，MVCNet引入了跨时间、频率和空间域的数据增强。同时，设计了跨视图和跨模型对比模块来增强特征表示。实验证明，MVCNet在多个公共数据集上显著优于现有SOTA模型，展现了卓越的性能和泛化能力。", "keywords": "运动想象分类, 脑机接口, 对比学习, 多视图网络, 脑电图", "comments": "MVCNet的创新点在于其双分支架构结合多视图对比学习，有效利用了脑电信号的复杂特性。通过融合CNN和Transformer，以及引入多维度数据增强和两种对比损失，该模型在运动想象分类任务上取得了显著的性能提升和泛化能力，为BCI系统提供了更可靠的解码方案。"}}
{"id": "2503.06891", "title": "AKF-LIO: LiDAR-Inertial Odometry with Gaussian Map by Adaptive Kalman Filter", "authors": ["Xupeng Xie", "Ruoyu Geng", "Jun Ma", "Boyu Zhou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Submitted to IROS 2025 Conference, this https URL", "url": "http://arxiv.org/abs/2503.06891v2", "summary": "Existing LiDAR-Inertial Odometry (LIO) systems typically use sensor-specific\nor environment-dependent measurement covariances during state estimation,\nleading to laborious parameter tuning and suboptimal performance in challenging\nconditions (e.g., sensor degeneracy and noisy observations). Therefore, we\npropose an Adaptive Kalman Filter (AKF) framework that dynamically estimates\ntime-varying noise covariances of LiDAR and Inertial Measurement Unit (IMU)\nmeasurements, enabling context-aware confidence weighting between sensors.\nDuring LiDAR degeneracy, the system prioritizes IMU data while suppressing\ncontributions from unreliable inputs like moving objects or noisy point clouds.\nFurthermore, a compact Gaussian-based map representation is introduced to model\nenvironmental planarity and spatial noise. A correlated registration strategy\nensures accurate plane normal estimation via pseudo-merge, even in unstructured\nenvironments like forests. Extensive experiments validate the robustness of the\nproposed system across diverse environments, including dynamic scenes and\ngeometrically degraded scenarios. Our method achieves reliable localization\nresults across all MARS-LVIG sequences and ranks 8th on the KITTI Odometry\nBenchmark. The code will be released at https://github.com/xpxie/AKF-LIO.git.", "comment": "Submitted to IROS 2025 Conference,\n  https://github.com/xpxie/AKF-LIO.git", "pdf_url": "http://arxiv.org/pdf/2503.06891v2", "cate": "cs.RO", "date": "2025-03-10", "updated": "2025-07-31", "AI": {"title_translation": "AKF-LIO：基于自适应卡尔曼滤波的高斯地图激光雷达惯性里程计", "tldr": "AKF-LIO通过自适应卡尔曼滤波器和高斯地图动态估计传感器噪声，提高了激光雷达惯性里程计在挑战性环境中的鲁棒性。", "motivation": "现有激光雷达惯性里程计（LIO）系统在状态估计时通常使用传感器特定或依赖于环境的测量协方差，导致参数调整繁琐，并在挑战性条件（如传感器退化和噪声观测）下性能不佳。", "method": "本文提出了一种自适应卡尔曼滤波（AKF）框架，动态估计激光雷达和惯性测量单元（IMU）测量的时间变化噪声协方差，实现传感器间上下文感知的置信度加权。在激光雷达退化时，系统优先处理IMU数据，并抑制移动物体或噪声点云等不可靠输入。此外，引入了紧凑的高斯地图表示来建模环境平面性和空间噪声，并通过相关注册策略确保准确的平面法线估计。", "result": "广泛的实验验证了所提出系统在包括动态场景和几何退化场景在内的各种环境中的鲁棒性。该方法在所有MARS-LVIG序列中都取得了可靠的定位结果，并在KITTI里程计基准测试中排名第8。", "conclusion": "所提出的AKF-LIO系统在多样化和挑战性的环境中表现出鲁棒且可靠的定位性能，优于现有方法并取得了较高的基准排名。", "translation": "现有的激光雷达惯性里程计（LIO）系统在状态估计过程中通常使用传感器特定或依赖于环境的测量协方差，这导致了繁琐的参数调整以及在挑战性条件（例如传感器退化和噪声观测）下的次优性能。因此，我们提出了一种自适应卡尔曼滤波（AKF）框架，该框架动态估计激光雷达和惯性测量单元（IMU）测量的时间变化噪声协方差，从而实现传感器之间上下文感知的置信度加权。在激光雷达退化期间，系统优先处理IMU数据，同时抑制来自不可靠输入（如移动物体或噪声点云）的贡献。此外，引入了一种紧凑的基于高斯地图表示来建模环境平面性和空间噪声。即使在森林等非结构化环境中，相关注册策略也能通过伪合并确保准确的平面法线估计。广泛的实验验证了所提出系统在各种环境（包括动态场景和几何退化场景）中的鲁棒性。我们的方法在所有MARS-LVIG序列中都取得了可靠的定位结果，并在KITTI里程计基准测试中排名第8。代码将在https://github.com/xpxie/AKF-LIO.git发布。", "summary": "本文介绍了AKF-LIO，一种通过采用自适应卡尔曼滤波器（AKF）解决现有激光雷达惯性里程计（LIO）系统局限性的方法。AKF动态估计激光雷达和IMU随时间变化的噪声协方差，实现上下文感知的置信度加权，并在激光雷达退化时优先处理IMU数据。它还结合了基于高斯地图的环境平面性和空间噪声建模，以及用于准确平面法线估计的相关注册策略。实验证明AKF-LIO在多样化和挑战性环境中具有鲁棒性，实现了可靠的定位和高基准性能。", "keywords": "激光雷达惯性里程计, 自适应卡尔曼滤波, 高斯地图, 传感器融合, 定位", "comments": "这篇论文通过解决挑战性条件下动态噪声估计和传感器融合的关键问题，显著改进了LIO系统。自适应卡尔曼滤波框架与高斯地图表示和相关注册相结合，为可靠定位提供了鲁棒的解决方案。动态加权机制尤其创新，使系统能够适应传感器退化和噪声输入，这对于实际应用至关重要。在不同环境下的强有力实验验证和高基准排名进一步突出了其重要性。"}}
{"id": "2304.01430", "title": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "authors": ["Dong Lao", "Zhengyang Hu", "Francesco Locatello", "Yanchao Yang", "Stefano Soatto"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2304.01430v3", "summary": "We investigate the emergence of objects in visual perception in the absence\nof any semantic annotation. The resulting model has received no supervision,\ndoes not use any pre-trained features, and yet it can segment the domain of an\nimage into multiple independently moving regions. The resulting motion\nsegmentation method can handle an unknown and varying number of objects in\nreal-time. The core multi-modal conditional encoder-decoder architecture has\none modality (optical flow) feed the encoder to produce a collection of latent\ncodes (slots), and the other modality (color image) conditions the decoder to\ngenerate the first modality (flow) from the slots. The training criterion is\ndesigned to foster 'information separation' among the slots, while the\narchitecture explicitly allocates activations to individual slots, leading to a\nmethod we call Divided Attention (DivA). At test time, DivA handles a different\nnumber of objects and different image resolution than seen at training, and is\ninvariant to permutations of the slots. DivA achieves state-of-the-art\nperformance while tripling the runtime speed of comparable methods, up to 104\nFPS, and reduces the performance gap from supervised methods to 12% or less.\nObjects bootstrapped by DivA can then be used to prime static classifiers via\ncontrastive learning. On fewer than 5,000 video clips, training DINO on DivA's\nobject proposals narrows the performance gap to ImageNet-based training by up\nto 30.2% compared to training directly on the video frames.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2304.01430v3", "cate": "cs.CV", "date": "2023-04-04", "updated": "2025-07-31", "AI": {"title_translation": "分块注意力：基于上下文分离槽的无监督多目标发现", "tldr": "本文介绍了一种名为“分块注意力”（DivA）的无监督方法，用于实时多目标运动分割。该方法无需语义标注或预训练特征，实现了最先进的性能和速度，并可用于引导静态分类器。", "motivation": "本文旨在研究在没有任何语义标注的情况下，视觉感知中物体是如何出现的，并开发一种能够将图像域分割成多个独立移动区域的模型，且该模型无需任何监督或预训练特征。", "method": "本文提出了一种名为“分块注意力”（DivA）的多模态条件编码器-解码器架构。其中，一种模态（光流）输入编码器以产生一系列潜在代码（槽），另一种模态（彩色图像）则作为条件输入解码器，从这些槽中生成第一种模态（光流）。训练准则旨在促进槽之间的“信息分离”，同时架构明确地将激活分配给各个槽。", "result": "该模型无需监督或预训练特征，即可将图像域分割成多个独立移动的运动区域。该运动分割方法能够实时处理未知且数量可变的对象。DivA实现了最先进的性能，同时将可比较方法的运行速度提高了三倍（高达104 FPS），并将与有监督方法的性能差距缩小到12%或更少。通过DivA引导的对象可以通过对比学习来预训练静态分类器。在少于5,000个视频片段上，使用DivA的对象提议训练DINO，与直接在视频帧上训练相比，将与ImageNet训练的性能差距缩小了30.2%。", "conclusion": "DivA是一种高效且有效的无监督多目标发现和运动分割方法，它在不依赖语义标注或预训练特征的情况下，实现了最先进的性能和显著的运行速度提升，并能有效支持下游的静态分类任务。", "translation": "我们研究了在没有任何语义标注的情况下，视觉感知中物体的出现。所得到的模型没有接收任何监督，不使用任何预训练特征，但它能够将图像域分割成多个独立移动的区域。由此产生的运动分割方法可以实时处理未知且数量可变的对象。其核心的多模态条件编码器-解码器架构中，一种模态（光流）输入编码器以产生一系列潜在代码（槽），而另一种模态（彩色图像）则作为条件输入解码器，从这些槽中生成第一种模态（光流）。训练准则旨在促进槽之间的“信息分离”，同时架构明确地将激活分配给各个槽，从而形成我们称之为“分块注意力”（DivA）的方法。在测试时，DivA能够处理与训练时不同数量和不同图像分辨率的对象，并且对槽的排列保持不变。DivA在实现最先进性能的同时，将可比较方法的运行时间速度提高了三倍，达到104 FPS，并将与有监督方法的性能差距缩小到12%或更少。通过DivA引导的对象随后可以通过对比学习来预训练静态分类器。在少于5,000个视频片段上，使用DivA的对象提议训练DINO，与直接在视频帧上训练相比，将与ImageNet训练的性能差距缩小了30.2%。", "summary": "本文提出了一种名为“分块注意力”（DivA）的新型无监督方法，用于实现多目标发现和运动分割。该方法无需语义标注或预训练特征，通过一个多模态条件编码器-解码器架构，利用光流和彩色图像，并通过“信息分离”的训练准则，将图像分割成独立移动的区域。DivA在处理动态数量和分辨率的对象方面表现出色，不仅达到了最先进的性能，运行速度也远超同类方法，并显著缩小了与有监督方法的性能差距。此外，DivA发现的对象还能有效用于通过对比学习预训练静态分类器，从而提升下游任务的性能。", "keywords": "无监督学习, 多目标发现, 运动分割, 分块注意力, 光流", "comments": "DivA的创新之处在于其完全无监督的多目标发现能力，无需任何语义标注或预训练特征，这在视觉感知领域是一个重要的突破。其采用的多模态条件编码器-解码器架构结合“信息分离”的训练准则，是实现这一目标的关键。该方法不仅在性能上达到SOTA，更在运行速度上实现了显著提升，且能有效缩小与有监督方法的差距，甚至能作为下游分类任务的有效预训练手段，展现了其在实际应用中的巨大潜力。"}}
{"id": "2503.17856", "title": "ClaraVid: A Holistic Scene Reconstruction Benchmark From Aerial Perspective With Delentropy-Based Complexity Profiling", "authors": ["Radu Beche", "Sergiu Nedevschi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted ICCV 2025", "url": "http://arxiv.org/abs/2503.17856v2", "summary": "The development of aerial holistic scene understanding algorithms is hindered\nby the scarcity of comprehensive datasets that enable both semantic and\ngeometric reconstruction. While synthetic datasets offer an alternative,\nexisting options exhibit task-specific limitations, unrealistic scene\ncompositions, and rendering artifacts that compromise real-world applicability.\nWe introduce ClaraVid, a synthetic aerial dataset specifically designed to\novercome these limitations. Comprising 16,917 high-resolution images captured\nat 4032x3024 from multiple viewpoints across diverse landscapes, ClaraVid\nprovides dense depth maps, panoptic segmentation, sparse point clouds, and\ndynamic object masks, while mitigating common rendering artifacts. To further\nadvance neural reconstruction, we introduce the Delentropic Scene Profile\n(DSP), a novel complexity metric derived from differential entropy analysis,\ndesigned to quantitatively assess scene difficulty and inform reconstruction\ntasks. Utilizing DSP, we systematically benchmark neural reconstruction\nmethods, uncovering a consistent, measurable correlation between scene\ncomplexity and reconstruction accuracy. Empirical results indicate that higher\ndelentropy strongly correlates with increased reconstruction errors, validating\nDSP as a reliable complexity prior. The data and code are available on the\nproject page at https://rdbch.github.io/claravid/", "comment": "Accepted ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.17856v2", "cate": "cs.CV", "date": "2025-03-22", "updated": "2025-07-31", "AI": {"title_translation": "ClaraVid: 基于差分熵复杂性分析的空中视角整体场景重建基准", "tldr": "引入了一个名为ClaraVid的合成空中数据集，用于整体场景重建，并提出了一个基于差分熵的场景复杂度度量（DSP），发现高复杂度与重建误差增加相关。", "motivation": "现有的空中整体场景理解算法开发受限于缺乏同时支持语义和几何重建的全面数据集。现有合成数据集存在任务特定限制、不真实的场景构成和渲染伪影，影响了实际应用。", "method": "我们引入了ClaraVid，一个旨在克服上述限制的合成空中数据集。它包含16,917张高分辨率图像，提供密集深度图、全景分割、稀疏点云和动态对象掩模，并减轻了常见的渲染伪影。我们还提出了Delentropic Scene Profile (DSP)，一个基于差分熵分析的新型复杂度度量，用于量化评估场景难度。利用DSP，我们系统地基准测试了神经重建方法。", "result": "我们发现了场景复杂度与重建精度之间存在一致、可测量的相关性。实证结果表明，更高的差分熵（delentropy）与重建误差的增加密切相关，验证了DSP作为可靠的复杂度先验。", "conclusion": "ClaraVid数据集和Delentropic Scene Profile (DSP) 有助于推进神经重建，DSP被验证为评估场景难度和预测重建误差的可靠复杂度度量。", "translation": "空中整体场景理解算法的开发受限于缺乏能够同时进行语义和几何重建的综合数据集。尽管合成数据集提供了一种替代方案，但现有选项存在任务特定限制、不真实的场景构成和渲染伪影，从而损害了实际适用性。我们引入了ClaraVid，一个专门设计用于克服这些限制的合成空中数据集。ClaraVid包含16,917张从不同景观的多个视角捕获的4032x3024高分辨率图像，提供密集的深度图、全景分割、稀疏点云和动态对象掩模，同时减轻了常见的渲染伪影。为了进一步推进神经重建，我们引入了差分熵场景剖面（DSP），这是一种源自差分熵分析的新型复杂度度量，旨在量化评估场景难度并为重建任务提供信息。利用DSP，我们系统地基准测试了神经重建方法，揭示了场景复杂度和重建精度之间存在一致、可测量的相关性。实证结果表明，较高的差分熵与重建误差的增加密切相关，验证了DSP作为可靠的复杂度先验。数据和代码可在项目页面获取：https://rdbch.github.io/claravid/", "summary": "该论文介绍了ClaraVid，一个用于空中整体场景重建的合成数据集，旨在解决现有数据集的局限性，如缺乏全面性、不真实性和渲染伪影。ClaraVid包含大量高分辨率图像及多模态数据。此外，论文提出了Delentropic Scene Profile (DSP)，一种基于差分熵的场景复杂度度量，并利用其对神经重建方法进行基准测试。研究发现场景复杂度与重建精度之间存在显著相关性，高差分熵值预示着更大的重建误差，证明了DSP作为复杂度先验的有效性。", "keywords": "ClaraVid, 空中场景重建, 差分熵, 复杂度分析, 基准测试", "comments": "该论文的创新点在于提出了一个高质量、全面的合成空中数据集ClaraVid，解决了现有数据集在语义和几何重建方面的不足。同时，引入的Delentropic Scene Profile (DSP) 是一种新颖且有效的场景复杂度量化方法，为神经重建任务提供了重要的先验信息，有助于理解和预测模型性能。这项工作为未来的空中场景理解研究提供了宝贵的资源和分析工具。"}}
{"id": "2507.23269", "title": "XABPs: Towards eXplainable Autonomous Business Processes", "authors": ["Peter Fettke", "Fabiana Fournier", "Lior Limonad", "Andreas Metzger", "Stefanie Rinderle-Ma", "Barbara Weber"], "categories": ["cs.SE", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23269v1", "summary": "Autonomous business processes (ABPs), i.e., self-executing workflows\nleveraging AI/ML, have the potential to improve operational efficiency, reduce\nerrors, lower costs, improve response times, and free human workers for more\nstrategic and creative work. However, ABPs may raise specific concerns\nincluding decreased stakeholder trust, difficulties in debugging, hindered\naccountability, risk of bias, and issues with regulatory compliance. We argue\nfor eXplainable ABPs (XABPs) to address these concerns by enabling systems to\narticulate their rationale. The paper outlines a systematic approach to XABPs,\ncharacterizing their forms, structuring explainability, and identifying key BPM\nresearch challenges towards XABPs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23269v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "可解释的自主业务流程：迈向XABPs", "tldr": "自主业务流程（ABPs）虽有益处，但存在信任、调试等问题。本文提出可解释的ABPs（XABPs）来解决这些问题，并概述了其系统方法。", "motivation": "自主业务流程（ABPs）虽然能够提高运营效率、减少错误、降低成本并缩短响应时间，但它们也带来了利益相关者信任度下降、调试困难、问责受阻、偏见风险以及法规遵从性等问题。为了解决这些担忧，本文主张开发可解释的自主业务流程（XABPs）。", "method": "本文概述了一种系统性的XABPs方法，包括描述其形式、构建可解释性以及识别实现XABPs的关键业务流程管理（BPM）研究挑战。", "result": "Not mentioned in abstract", "conclusion": "为了解决自主业务流程（ABPs）带来的信任、调试、问责、偏见和合规性等问题，核心在于开发可解释的ABPs（XABPs），通过使系统能够阐明其决策逻辑来实现。", "translation": "自主业务流程（ABPs），即利用人工智能/机器学习的自我执行工作流，有潜力提高运营效率、减少错误、降低成本、缩短响应时间，并使人类员工能够从事更具战略性和创造性的工作。然而，ABPs可能会引发特定担忧，包括利益相关者信任度下降、调试困难、问责受阻、偏见风险以及法规遵从性问题。我们主张采用可解释的ABPs（XABPs）来解决这些担忧，通过使系统能够阐明其推理过程。本文概述了一种系统性的XABPs方法，描述了它们的具体形式，构建了可解释性，并指出了迈向XABPs的关键BPM研究挑战。", "summary": "本文探讨了自主业务流程（ABPs）的潜在优势及随之而来的挑战，如信任和调试问题。为应对这些挑战，作者提出了可解释的自主业务流程（XABPs）的概念，旨在通过让系统阐明其决策逻辑来解决上述问题。论文进一步概述了实现XABPs的系统方法，包括定义其形式、构建可解释性框架，并识别了业务流程管理（BPM）领域在实现XABPs过程中面临的关键研究挑战。", "keywords": "自主业务流程, 可解释性, 业务流程管理, 人工智能, 机器学习", "comments": "这篇论文提出了一个及时且重要的概念——可解释的自主业务流程（XABPs），以应对AI/ML驱动的业务流程在信任、调试和合规性方面日益增长的挑战。其创新之处在于将可解释性（Explainability）的概念引入到自动化业务流程管理中，这对于提高企业对AI系统采纳的信心至关重要。论文虽然没有提供具体的实现细节或实验结果，但其系统性的方法论和对未来研究挑战的识别，为该领域奠定了重要的理论基础和研究方向。"}}
{"id": "2507.23186", "title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "authors": ["Peter Sharpe"], "categories": ["cs.LG", "cs.PL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23186v1", "summary": "Sparsity detection in black-box functions enables significant computational\nspeedups in gradient-based optimization through Jacobian compression, but\nexisting finite-difference methods suffer from false negatives due to\ncoincidental zero gradients. These false negatives can silently corrupt\ngradient calculations, leading to difficult-to-diagnose errors. We introduce\nNaN-propagation, which exploits the universal contamination property of IEEE\n754 Not-a-Number floating-point values to trace input-output dependencies\nthrough floating-point numerical computations. By systematically contaminating\ninputs with NaN and observing which outputs become NaN, the method reconstructs\nconservative sparsity patterns that eliminate false negatives. We demonstrate\nthe approach on an aerospace wing weight model, achieving a 1.52x speedup while\ndetecting dozens of dependencies missed by conventional methods -- a\nsignificant improvement since gradient computation is the bottleneck in many\noptimization workflows. The technique leverages IEEE 754 compliance to work\nacross programming languages and math libraries without modifying existing\nblack-box codes. Advanced strategies including NaN payload encoding enable\nfaster-than-linear time complexity, improving upon existing black-box sparsity\ndetection methods. Practical algorithms are also proposed to mitigate\nchallenges from branching code execution common in engineering applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23186v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "NaN-传播：一种用于黑盒计算函数稀疏性检测的新方法", "tldr": "提出NaN-传播方法，利用NaN的特性检测黑盒函数的稀疏性，消除传统有限差分方法的假阴性，提高梯度计算速度。", "motivation": "现有有限差分方法在黑盒函数稀疏性检测中存在假阴性问题，导致梯度计算错误和难以诊断的误差，限制了基于梯度的优化中通过雅可比压缩实现计算加速。", "method": "引入NaN-传播，利用IEEE 754 NaN的普遍污染特性，通过系统地用NaN污染输入并观察哪些输出变为NaN来追踪输入-输出依赖关系，从而重建保守的稀疏模式以消除假阴性。该方法无需修改现有黑盒代码，且提出了高级策略（如NaN载荷编码）和实用算法来应对分支代码执行。", "result": "在航空航天机翼重量模型上实现了1.52倍的加速，并检测到数十个传统方法遗漏的依赖关系。该技术利用IEEE 754兼容性，可跨编程语言和数学库工作。高级策略实现了比线性时间复杂度更快的速度。", "conclusion": "NaN-传播是一种有效且鲁棒的黑盒函数稀疏性检测方法，通过消除假阴性提高了梯度计算的准确性和效率，对优化工作流程具有重要意义，且兼容性强。", "translation": "黑盒函数中的稀疏性检测可以通过雅可比压缩显著加速基于梯度的优化，但现有的有限差分方法由于巧合的零梯度而存在假阴性。这些假阴性会悄无声息地破坏梯度计算，导致难以诊断的错误。我们引入了NaN-传播，它利用IEEE 754非数字浮点值的普遍污染特性来追踪浮点数值计算中的输入-输出依赖关系。通过系统地用NaN污染输入并观察哪些输出变为NaN，该方法重建了保守的稀疏模式，消除了假阴性。我们在一个航空航天机翼重量模型上演示了该方法，实现了1.52倍的加速，同时检测到传统方法遗漏的数十个依赖关系——这是一个显著的改进，因为梯度计算是许多优化工作流程中的瓶颈。该技术利用IEEE 754兼容性，无需修改现有黑盒代码即可跨编程语言和数学库工作。包括NaN载荷编码在内的高级策略实现了比线性时间复杂度更快的速度，改进了现有的黑盒稀疏性检测方法。还提出了实用的算法来缓解工程应用中常见的分支代码执行带来的挑战。", "summary": "本文提出了一种名为NaN-传播的新方法，用于黑盒计算函数的稀疏性检测。该方法利用IEEE 754浮点数NaN的普遍污染特性，通过系统性地污染输入并观察输出变化来追踪输入-输出依赖，从而构建保守的稀疏模式，有效消除了传统有限差分方法中存在的假阴性问题。实验证明，该方法在航空航天模型上实现了显著的计算加速，并能检测出传统方法遗漏的依赖关系，且兼容多种编程语言和库，无需修改现有代码。", "keywords": "NaN-传播, 稀疏性检测, 黑盒函数, 梯度优化, IEEE 754", "comments": "这篇论文创新性地利用了IEEE 754浮点数NaN的特性来解决黑盒函数稀疏性检测中的假阴性问题，这是一个非常巧妙且鲁棒的方法。其优势在于无需修改源代码，兼容性强，并能显著提高梯度计算效率，对于基于梯度的优化领域具有重要意义。提出的高级策略和针对分支代码的算法也增加了其实用性。"}}
{"id": "2507.23512", "title": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "authors": ["Saleh Vatan Khah", "Savelii Chezhegov", "Shahrokh Farahmand", "Samuel Horváth", "Eduard Gorbunov"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      60 pages", "url": "http://arxiv.org/abs/2507.23512v1", "summary": "Gradient clipping is a fundamental tool in Deep Learning, improving the\nhigh-probability convergence of stochastic first-order methods like SGD,\nAdaGrad, and Adam under heavy-tailed noise, which is common in training large\nlanguage models. It is also a crucial component of Differential Privacy (DP)\nmechanisms. However, existing high-probability convergence analyses typically\nrequire the clipping threshold to increase with the number of optimization\nsteps, which is incompatible with standard DP mechanisms like the Gaussian\nmechanism. In this work, we close this gap by providing the first\nhigh-probability convergence analysis for DP-Clipped-SGD with a fixed clipping\nlevel, applicable to both convex and non-convex smooth optimization under\nheavy-tailed noise, characterized by a bounded central $\\alpha$-th moment\nassumption, $\\alpha \\in (1,2]$. Our results show that, with a fixed clipping\nlevel, the method converges to a neighborhood of the optimal solution with a\nfaster rate than the existing ones. The neighborhood can be balanced against\nthe noise introduced by DP, providing a refined trade-off between convergence\nspeed and privacy guarantees.", "comment": "60 pages", "pdf_url": "http://arxiv.org/pdf/2507.23512v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "差分隐私截断SGD：任意截断水平下的高概率收敛性", "tldr": "首次为固定截断水平的DP-Clipped-SGD提供了高概率收敛性分析，解决了现有分析与标准DP机制不兼容的问题，并证明了更快的收敛速度和更好的隐私-收敛权衡。", "motivation": "现有的高概率收敛性分析通常要求截断阈值随优化步数增加，这与高斯机制等标准差分隐私（DP）机制不兼容。", "method": "首次为具有固定截断水平的差分隐私截断SGD（DP-Clipped-SGD）提供了高概率收敛性分析，适用于重尾噪声下的凸和非凸光滑优化，该噪声由有界中心$\\alpha$阶矩假设（$\\alpha \\in (1,2]$）表征。", "result": "在固定截断水平下，该方法以比现有方法更快的速率收敛到最优解的邻域。该邻域可以与差分隐私引入的噪声进行平衡，从而在收敛速度和隐私保证之间提供更精细的权衡。", "conclusion": "本文成功解决了差分隐私机制中固定截断水平与高概率收敛分析不兼容的问题，实现了更快的收敛速度和优化的隐私-收敛权衡。", "translation": "梯度截断是深度学习中的一个基本工具，它提高了随机一阶方法（如SGD、AdaGrad和Adam）在重尾噪声下的高概率收敛性，这在训练大型语言模型时很常见。它也是差分隐私（DP）机制的关键组成部分。然而，现有的高概率收敛性分析通常要求截断阈值随优化步数增加，这与高斯机制等标准差分隐私机制不兼容。在这项工作中，我们通过为具有固定截断水平的差分隐私截断SGD（DP-Clipped-SGD）提供首次高概率收敛性分析来弥补这一空白，该分析适用于重尾噪声下的凸和非凸光滑优化，该噪声由有界中心$\\alpha$阶矩假设（$\\alpha \\in (1,2]$）表征。我们的结果表明，在固定截断水平下，该方法以比现有方法更快的速率收敛到最优解的邻域。该邻域可以与差分隐私引入的噪声进行平衡，从而在收敛速度和隐私保证之间提供更精细的权衡。", "summary": "本文针对差分隐私（DP）机制中梯度截断的挑战，首次为固定截断水平的DP-Clipped-SGD提供了高概率收敛性分析。该分析适用于重尾噪声下的凸和非凸优化，弥补了现有分析与标准DP机制不兼容的空白。研究结果表明，该方法不仅能以更快的速率收敛到最优解邻域，还能在收敛速度和隐私保证之间实现更精细的权衡。", "keywords": "差分隐私, 梯度截断, 高概率收敛, 重尾噪声, SGD", "comments": "这项工作在理论上具有重要意义，因为它解决了差分隐私训练中梯度截断阈值与收敛性分析之间的关键兼容性问题。通过证明固定截断水平下DP-Clipped-SGD的高概率收敛性，并展示其更快的收敛速度和优化的隐私-收敛权衡，为实际应用中差分隐私训练的稳定性和效率提供了更坚实的理论基础。"}}
{"id": "2507.23521", "title": "JPEG Processing Neural Operator for Backward-Compatible Coding", "authors": ["Woo Kyoung Han", "Yongjun Lee", "Byeonghun Lee", "Sang Hyun Park", "Sunghoon Im", "Kyong Hwan Jin"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23521v1", "summary": "Despite significant advances in learning-based lossy compression algorithms,\nstandardizing codecs remains a critical challenge. In this paper, we present\nthe JPEG Processing Neural Operator (JPNeO), a next-generation JPEG algorithm\nthat maintains full backward compatibility with the current JPEG format. Our\nJPNeO improves chroma component preservation and enhances reconstruction\nfidelity compared to existing artifact removal methods by incorporating neural\noperators in both the encoding and decoding stages. JPNeO achieves practical\nbenefits in terms of reduced memory usage and parameter count. We further\nvalidate our hypothesis about the existence of a space with high mutual\ninformation through empirical evidence. In summary, the JPNeO functions as a\nhigh-performance out-of-the-box image compression pipeline without changing\nsource coding's protocol. Our source code is available at\nhttps://github.com/WooKyoungHan/JPNeO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23521v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "JPEG 处理神经算子用于向后兼容编码", "tldr": "JPNeO是一种新的JPEG算法，它使用神经算子提高了图像质量和效率，同时完全兼容现有JPEG格式。", "motivation": "尽管基于学习的有损压缩算法取得了显著进展，但编解码器标准化仍然是一个严峻挑战。", "method": "本文提出了JPEG处理神经算子（JPNeO），这是一种通过在编码和解码阶段引入神经算子来改进图像压缩的下一代JPEG算法。它保持与当前JPEG格式的完全向后兼容性。", "result": "JPNeO与现有伪影去除方法相比，改进了色度分量保留并增强了重建保真度。它在减少内存使用和参数数量方面取得了实际效益，并作为一个高性能的即用型图像压缩管道。", "conclusion": "JPNeO作为一个高性能的即用型图像压缩管道，无需改变源代码编码协议，同时保持了与现有JPEG格式的完全向后兼容性。", "translation": "尽管基于学习的有损压缩算法取得了显著进展，但编解码器标准化仍然是一个严峻挑战。在本文中，我们提出了JPEG处理神经算子（JPNeO），这是一种下一代JPEG算法，它与当前的JPEG格式保持完全向后兼容。我们的JPNeO通过在编码和解码阶段引入神经算子，与现有伪影去除方法相比，改进了色度分量保留并增强了重建保真度。JPNeO在减少内存使用和参数数量方面取得了实际效益。我们通过经验证据进一步验证了我们关于存在高互信息空间的假设。总而言之，JPNeO作为一个高性能的即用型图像压缩管道，无需改变源代码编码协议。我们的源代码可在https://github.com/WooKyoungHan/JPNeO获取。", "summary": "本文介绍了JPEG处理神经算子（JPNeO），这是一种新型JPEG算法，旨在通过在编码和解码阶段集成神经算子来提高图像压缩性能。JPNeO与现有JPEG标准完全向后兼容，并在色度分量保留和图像重建保真度方面表现优异，同时降低了内存和参数开销。它提供了一个高性能的即用型图像压缩解决方案，无需修改现有协议。", "keywords": "JPEG压缩, 神经算子, 向后兼容, 图像处理, 有损压缩", "comments": "JPNeO的创新之处在于将神经算子引入到JPEG编码和解码流程中，同时保持了与现有标准的完全向后兼容性，这对于实际应用和标准化具有重要意义。它解决了传统压缩算法在质量和效率上的局限，提供了一种渐进式升级的方案。"}}
{"id": "2410.03094", "title": "Entanglement-induced provable and robust quantum learning advantages", "authors": ["Haimeng Zhao", "Dong-Ling Deng"], "categories": ["quant-ph", "cs.CC", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures + 13-page supplementary materials", "url": "http://arxiv.org/abs/2410.03094v2", "summary": "Quantum computing holds unparalleled potentials to enhance machine learning.\nHowever, a demonstration of quantum learning advantage has not been achieved so\nfar. We make a step forward by rigorously establishing a noise-robust,\nunconditional quantum learning advantage in expressivity, inference speed, and\ntraining efficiency, compared to commonly-used classical models. Our proof is\ninformation-theoretic and pinpoints the origin of this advantage: entanglement\ncan be used to reduce the communication required by non-local tasks. In\nparticular, we design a task that can be solved with certainty by quantum\nmodels with a constant number of parameters using entanglement, whereas\ncommonly-used classical models must scale linearly to achieve a\nlarger-than-exponentially-small accuracy. We show that the quantum model is\ntrainable with constant resources and robust against constant noise. Through\nnumerical and trapped-ion experiments on IonQ Aria, we demonstrate the desired\nadvantage. Our results provide valuable guidance for demonstrating quantum\nlearning advantages with current noisy intermediate-scale devices.", "comment": "7 pages, 2 figures + 13-page supplementary materials", "pdf_url": "http://arxiv.org/pdf/2410.03094v2", "cate": "quant-ph", "date": "2024-10-04", "updated": "2025-07-31", "AI": {"title_translation": "纠缠诱导的可证明和鲁棒的量子学习优势", "tldr": "本文通过理论证明和实验演示，建立了由纠缠引起的、对经典模型具有噪声鲁棒的、无条件量子学习优势。", "motivation": "尽管量子计算在机器学习方面具有巨大潜力，但迄今为止尚未实现量子学习优势的实际演示。", "method": "通过信息论方法严格建立了量子学习优势；设计了一个特定任务，量子模型可以使用恒定数量的参数和纠缠确定性地解决，而经典模型需要线性扩展才能达到更高的准确性；通过数值模拟和IonQ Aria上的俘获离子实验验证了优势。", "result": "证明了在表达能力、推理速度和训练效率方面，相对于常用经典模型，存在噪声鲁棒的、无条件的量子学习优势；该优势的起源在于纠缠可以减少非局部任务所需的通信；量子模型具有恒定资源的可训练性，并对恒定噪声具有鲁棒性；数值和俘获离子实验验证了预期的优势。", "conclusion": "本研究结果为在当前噪声中等规模量子设备上展示量子学习优势提供了宝贵的指导。", "translation": "量子计算在增强机器学习方面具有无与伦比的潜力。然而，迄今为止尚未实现量子学习优势的演示。我们通过严格确立与常用经典模型相比，在表达能力、推理速度和训练效率方面具有噪声鲁棒、无条件的量子学习优势，向前迈进了一步。我们的证明是信息论的，并指出了这种优势的起源：纠缠可以用于减少非局部任务所需的通信。特别是，我们设计了一个任务，量子模型可以使用恒定数量的参数并利用纠缠确定性地解决，而常用经典模型必须线性扩展才能获得大于指数级小的准确性。我们表明量子模型可以用恒定资源进行训练，并且对恒定噪声具有鲁棒性。通过IonQ Aria上的数值和俘获离子实验，我们展示了所需的优势。我们的结果为在当前噪声中等规模设备上展示量子学习优势提供了宝贵的指导。", "summary": "本文严格地证明并实验验证了由纠缠引起的量子学习优势，该优势在表达能力、推理速度和训练效率上优于常用经典模型，并且对噪声具有鲁棒性。研究通过信息论方法指出纠缠能减少非局部任务通信是优势来源，并通过设计特定任务和在IonQ Aria上进行数值与实验验证了这一优势。", "keywords": "量子学习优势, 纠缠, 鲁棒性, 表达能力, 推理速度", "comments": "这项研究的创新之处在于首次通过严谨的理论证明和实验验证，确立了由纠缠驱动的、对噪声鲁棒的量子学习优势。它不仅指出了纠缠作为优势的根本来源，还设计了具体的任务来展示这种优势，并考虑了实际量子设备中的噪声问题，这对于当前噪声中等规模量子设备的应用具有重要指导意义。"}}
{"id": "2409.17092", "title": "Accumulator-Aware Post-Training Quantization for Large Language Models", "authors": ["Ian Colbert", "Giuseppe Franco", "Fabian Grob", "Jinjie Zhang", "Rayan Saab"], "categories": ["cs.LG", "cs.AI", "cs.DM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.17092v2", "summary": "When quantizing weights and activations to increasingly narrower\nrepresentations, the cost of additions begins to dominate that of\nmultiplications in multiply-accumulate (MAC) units. Recent studies show that\nreducing addition costs via low-precision accumulation improves throughput,\npower, and area across inference platforms, albeit with an increased risk of\noverflow. Accumulator-aware quantization research has so far only considered\nthe quantization-aware training (QAT) paradigm, in which models are fine-tuned\nor trained from scratch with quantization in the loop. As models and datasets\ncontinue to grow in size, QAT techniques become increasingly more expensive,\nwhich has motivated the recent surge in post-training quantization (PTQ)\nresearch. To bridge this gap, we introduce AXE, the first accumulator-aware\nquantization framework explicitly designed to endow overflow avoidance\nguarantees to PTQ algorithms. We present theoretical motivation for AXE and\ndemonstrate its flexibility by implementing it on top of two existing\nalgorithms: GPFQ and OPTQ. We design AXE to support multi-stage accumulation,\nopening the door to full datapath optimization for the first time. We evaluate\nAXE using recent language generation models; when quantizing Llama3 8B for a\n16-bit multi-stage accumulation datapath, AXE maintains up to 98% of the FP16\nperplexity, surpassing naive bit width manipulation by up to 15%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.17092v2", "cate": "cs.LG", "date": "2024-09-25", "updated": "2025-07-31", "AI": {"title_translation": "累加器感知的大语言模型训练后量化", "tldr": "本文介绍了AXE，首个累加器感知训练后量化（PTQ）框架，它能为大语言模型提供溢出避免保证，并显著保持性能。", "motivation": "在将权重和激活量化为低精度表示时，加法成本在乘累加（MAC）单元中变得主导。虽然低精度累加可以提高推理性能，但存在溢出风险。现有的累加器感知量化方法主要集中在昂贵的量化感知训练（QAT）范式，而对于日益增长的大型模型，QAT成本过高，因此急需针对训练后量化（PTQ）的累加器感知解决方案。", "method": "本文提出了AXE，这是第一个专为PTQ算法设计并提供溢出避免保证的累加器感知量化框架。AXE具有理论基础，并已在GPFQ和OPTQ两种现有算法上实现，展示了其灵活性。此外，AXE支持多阶段累加，首次实现了完整的通路优化。", "result": "在对Llama3 8B模型进行16位多阶段累加通路量化时，AXE能够保持高达98%的FP16困惑度，相比朴素位宽操作，性能提升高达15%。", "conclusion": "AXE框架成功地将累加器感知量化引入到训练后量化领域，有效解决了溢出问题，并在大型语言模型上展现出优异的性能保持能力。", "translation": "当将权重和激活量化为越来越窄的表示时，加法成本开始在乘累加（MAC）单元中占据主导地位。最近的研究表明，通过低精度累加来降低加法成本可以提高推理平台的吞吐量、功耗和面积，尽管存在溢出的风险。迄今为止，累加器感知量化研究仅考虑了量化感知训练（QAT）范式，其中模型在训练或从头开始训练时将量化纳入循环。随着模型和数据集的规模不断增长，QAT技术变得越来越昂贵，这促使了近期对训练后量化（PTQ）研究的激增。为了弥补这一空白，我们引入了AXE，这是第一个明确设计用于为PTQ算法提供溢出避免保证的累加器感知量化框架。我们提出了AXE的理论动机，并通过在两个现有算法：GPFQ和OPTQ之上实现它来展示其灵活性。我们将AXE设计为支持多阶段累加，首次为完整的通路优化打开了大门。我们使用最新的语言生成模型评估了AXE；当为16位多阶段累加通路量化Llama3 8B时，AXE保持了高达98%的FP16困惑度，比朴素位宽操作高出15%。", "summary": "本文针对大语言模型训练后量化（PTQ）中累加器溢出问题，提出了首个累加器感知PTQ框架AXE。AXE旨在为PTQ算法提供溢出避免保证，支持多阶段累加，并已在现有算法上验证。实验结果表明，AXE在量化Llama3 8B时能保持接近FP16的性能，并显著优于传统方法，为大型模型的低成本高效部署提供了新途径。", "keywords": "累加器感知, 训练后量化, 大型语言模型, 溢出避免, AXE", "comments": "本文解决了低精度量化中一个关键的实际挑战：在训练后量化（PTQ）中管理累加器溢出，这对于由于QAT成本高昂而无法使用QAT的大型模型至关重要。AXE作为第一个在PTQ中提供溢出保证的框架，尤其是在支持多阶段累加方面，是一项重要的创新。其在Llama3 8B上表现出的有效性预示着大型语言模型高效部署的良好前景。"}}
{"id": "2507.23191", "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Long version of a paper to appear at KR 2025, which contains further proof details in the appendix", "url": "http://arxiv.org/abs/2507.23191v1", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "pdf_url": "http://arxiv.org/pdf/2507.23191v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "本体介导查询回答中的可处理责任度量", "tldr": "本文研究了本体介导查询回答（OMQA）中计算基于Shapley值的责任度量（WSMS）的计算复杂度，揭示了在不同本体语言和查询类型下的可处理性和不可处理性界限，并为DL-Lite方言识别了可处理的情况。", "motivation": "量化事实对查询答案的贡献是解释查询答案的关键。本文旨在研究在本体介导查询回答（OMQA）环境中计算责任分数（特别是基于Shapley值的WSMS度量）的复杂度，以理解其可处理性边界。", "method": "本文利用数据库领域的研究成果，分析了WSMS在本体介导查询回答中的数据复杂度和组合复杂度。通过对本体语言特性和查询结构的仔细分析，识别了不同场景下的计算复杂度，并特别关注了DL-Lite方言。", "result": "研究发现，对于一阶可重写（first-order-rewritable）的本体介导查询，WSMS度量具有多项式数据复杂度。然而，当本体语言可以编码可达性查询时，问题变为“shP”-hard。在组合复杂度方面，如果本体语言支持合取，即使是原子查询也变得不可处理；对于“行为良好”的合取查询的并集，即使没有本体，也可能导致不可处理性。但对于常见的DL-Lite方言，通过仔细分析，本文识别出结构受限的合取查询类别，这些类别允许可处理的WSMS计算。", "conclusion": "本文详细分析了本体介导查询回答中责任度量（WSMS）的可处理性，根据本体语言特性和查询结构识别了可处理和不可处理的场景，并为DL-Lite方言提供了积极的结果，这对于理解和应用可解释的本体介导查询系统具有重要意义。", "translation": "最近关于解释查询答案的定量方法，采用责任度量来为事实分配分数，以量化它们对获得给定答案的各自贡献。在本文中，我们研究了在本体介导查询回答（OMQA）设置中计算此类责任分数的复杂度，重点关注最近引入的基于Shapley值定义的责任度量家族，其表示为最小支持的加权和（WSMS）。通过利用数据库领域的结果，我们可以证明，对于一阶可重写（first-order-rewritable）的本体介导查询类别，此类度量享有多项式数据复杂度；而当本体语言可以编码可达性查询（通过诸如 $\\exists R. A \\sqsubseteq A$ 的公理）时，问题变为“shP”-hard。为了更好地理解可处理性边界，我们接下来探讨了WSMS计算的组合复杂度。我们证明，如果本体语言支持合取，即使是原子查询也已经不可处理；对于“行为良好”的合取查询的并集，即使在没有本体的情况下，也存在不可处理性。相比之下，我们的研究为常见的DL-Lite方言带来了积极的结果：通过仔细分析，我们识别出结构受限的合取查询类别（直观上不允许查询原子之间发生不希望的相互作用），这些类别允许可处理的WSMS计算。", "summary": "本文探讨了在本体介导查询回答（OMQA）中计算基于Shapley值的责任度量（WSMS）的计算复杂度。研究发现，对于一阶可重写的OMQ，WSMS具有多项式数据复杂度，但在本体语言支持可达性查询时则变得困难。在组合复杂度方面，即使是简单的查询和本体特性也可能导致不可处理性。然而，对于DL-Lite方言，研究识别出特定结构限制下的合取查询类别，其WSMS计算是可处理的，为可解释的OMQA提供了理论基础和实践指导。", "keywords": "责任度量, 本体介导查询回答, 计算复杂度, Shapley值, DL-Lite", "comments": "本文系统地分析了在本体介导查询回答背景下，一种特定责任度量（WSMS）的计算复杂度，这对于发展可解释的AI系统至关重要。其创新点在于明确了不同本体语言特性和查询结构对计算复杂度的影响，特别是识别出DL-Lite中可处理的查询子集，这为实际应用中实现高效的解释生成提供了宝贵的指导。研究结果有助于推动本体论与可解释人工智能的交叉研究。"}}
{"id": "2507.23188", "title": "Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space", "authors": ["Shiyao Yu", "Zi-An Wang", "Kangning Yin", "Zheng Tian", "Mingyuan Zhang", "Weixin Si", "Shihao Zou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TMM 2025", "url": "http://arxiv.org/abs/2507.23188v1", "summary": "Motion retrieval is crucial for motion acquisition, offering superior\nprecision, realism, controllability, and editability compared to motion\ngeneration. Existing approaches leverage contrastive learning to construct a\nunified embedding space for motion retrieval from text or visual modality.\nHowever, these methods lack a more intuitive and user-friendly interaction mode\nand often overlook the sequential representation of most modalities for\nimproved retrieval performance. To address these limitations, we propose a\nframework that aligns four modalities -- text, audio, video, and motion --\nwithin a fine-grained joint embedding space, incorporating audio for the first\ntime in motion retrieval to enhance user immersion and convenience. This\nfine-grained space is achieved through a sequence-level contrastive learning\napproach, which captures critical details across modalities for better\nalignment. To evaluate our framework, we augment existing text-motion datasets\nwith synthetic but diverse audio recordings, creating two multi-modal motion\nretrieval datasets. Experimental results demonstrate superior performance over\nstate-of-the-art methods across multiple sub-tasks, including an 10.16%\nimprovement in R@10 for text-to-motion retrieval and a 25.43% improvement in\nR@1 for video-to-motion retrieval on the HumanML3D dataset. Furthermore, our\nresults show that our 4-modal framework significantly outperforms its 3-modal\ncounterpart, underscoring the potential of multi-modal motion retrieval for\nadvancing motion acquisition.", "comment": "Accepted by IEEE TMM 2025", "pdf_url": "http://arxiv.org/pdf/2507.23188v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "通过学习细粒度联合嵌入空间实现多模态运动检索", "tldr": "该论文提出了一种通过序列级对比学习，将文本、音频、视频和运动四种模态对齐到细粒度联合嵌入空间的多模态运动检索框架，并在多种子任务上取得了优于现有方法的性能。", "motivation": "现有运动检索方法缺乏更直观和用户友好的交互模式，并且常常忽略大多数模态的序列表示以提高检索性能，尤其是在将音频纳入运动检索方面。", "method": "我们提出了一个框架，通过序列级对比学习将文本、音频、视频和运动四种模态对齐到一个细粒度的联合嵌入空间。该方法首次将音频引入运动检索，并创建了两个多模态运动检索数据集。", "result": "在HumanML3D数据集上，我们的框架在文本到运动检索的R@10指标上提高了10.16%，在视频到运动检索的R@1指标上提高了25.43%。4模态框架显著优于3模态框架。", "conclusion": "所提出的多模态运动检索框架，特别是引入音频并利用细粒度联合嵌入空间，显著提升了运动获取的性能，并展现了多模态运动检索的巨大潜力。", "translation": "运动检索对于运动获取至关重要，与运动生成相比，它提供了卓越的精度、真实感、可控性和可编辑性。现有方法利用对比学习为文本或视觉模态的运动检索构建统一的嵌入空间。然而，这些方法缺乏更直观和用户友好的交互模式，并且常常忽略大多数模态的序列表示以提高检索性能。为了解决这些限制，我们提出了一个框架，将文本、音频、视频和运动四种模态对齐到细粒度联合嵌入空间中，首次将音频纳入运动检索，以增强用户沉浸感和便利性。这个细粒度空间是通过序列级对比学习方法实现的，该方法捕获跨模态的关键细节以实现更好的对齐。为了评估我们的框架，我们通过合成但多样化的音频记录增强了现有的文本-运动数据集，创建了两个多模态运动检索数据集。实验结果表明，在多个子任务上，我们的性能优于最先进的方法，包括在HumanML3D数据集上，文本到运动检索的R@10提高了10.16%，视频到运动检索的R@1提高了25.43%。此外，我们的结果表明，我们的4模态框架显著优于其3模态对应框架，强调了多模态运动检索在推动运动获取方面的潜力。", "summary": "本研究提出了一种新颖的多模态运动检索框架，通过序列级对比学习，将文本、音频、视频和运动四种模态对齐到细粒度联合嵌入空间。该框架首次将音频引入运动检索，旨在提高用户交互和检索性能。通过增强现有数据集并进行实验，结果显示该方法在多个检索子任务上均优于现有技术，特别是在文本到运动和视频到运动检索方面表现出显著提升，证明了多模态方法在运动获取领域的潜力。", "keywords": "多模态运动检索, 联合嵌入空间, 序列级对比学习, 音频模态, 运动获取", "comments": "该论文的创新点在于首次将音频模态引入运动检索，并提出了一个能整合文本、音频、视频和运动的四模态联合嵌入空间。通过序列级对比学习实现细粒度对齐，有效地解决了现有方法交互模式单一和忽略序列表示的问题。其在多项任务上的显著性能提升，特别是引入音频后的优势，预示着多模态运动检索在未来运动获取和编辑方面具有广阔的应用前景。"}}
{"id": "2507.23295", "title": "LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis", "authors": ["Inbum Heo", "Taewook Hwang", "Jeesu Jung", "Sangkeun Jung"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23295v1", "summary": "Recent advancements in Document Layout Analysis through Large Language Models\nand Multimodal Models have significantly improved layout detection. However,\ndespite these improvements, challenges remain in addressing critical structural\nerrors, such as region merging, splitting, and missing content. Conventional\nevaluation metrics like IoU and mAP, which focus primarily on spatial overlap,\nare insufficient for detecting these errors. To address this limitation, we\npropose Layout Error Detection (LED), a novel benchmark designed to evaluate\nthe structural robustness of document layout predictions. LED defines eight\nstandardized error types, and formulates three complementary tasks: error\nexistence detection, error type classification, and element-wise error type\nclassification. Furthermore, we construct LED-Dataset, a synthetic dataset\ngenerated by injecting realistic structural errors based on empirical\ndistributions from DLA models. Experimental results across a range of LMMs\nreveal that LED effectively differentiates structural understanding\ncapabilities, exposing modality biases and performance trade-offs not visible\nthrough traditional metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23295v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "LED基准测试：诊断文档布局分析中的结构布局错误", "tldr": "提出LED基准测试和数据集，用于诊断大型语言模型和多模态模型在文档布局分析中未被传统指标发现的结构错误。", "motivation": "尽管大型语言模型和多模态模型在文档布局分析方面取得了进展，但它们在解决区域合并、分割和内容丢失等关键结构错误方面仍面临挑战。传统的评估指标如IoU和mAP主要关注空间重叠，不足以检测这些结构性错误。", "method": "作者提出了布局错误检测（LED）基准测试，旨在评估文档布局预测的结构鲁棒性。LED定义了八种标准化的错误类型，并提出了三个互补的任务：错误存在检测、错误类型分类和元素级错误类型分类。此外，他们构建了LED-数据集，这是一个通过根据DLA模型的经验分布注入真实结构错误而生成的合成数据集。", "result": "在各种LMMs上进行的实验结果表明，LED能够有效地区分结构理解能力，揭示了传统指标无法发现的模态偏差和性能权衡。", "conclusion": "LED基准测试提供了一种有效的方法来诊断文档布局分析模型中的结构性错误，并揭示了传统度量标准无法捕捉到的模型性能和偏差。", "translation": "最近大型语言模型和多模态模型在文档布局分析方面的进展显著改善了布局检测。然而，尽管有这些改进，在解决关键结构错误方面仍然存在挑战，例如区域合并、分割和内容丢失。传统的评估指标如IoU和mAP主要关注空间重叠，不足以检测这些错误。为了解决这一局限性，我们提出了布局错误检测（LED），这是一个新颖的基准测试，旨在评估文档布局预测的结构鲁棒性。LED定义了八种标准化的错误类型，并提出了三个互补的任务：错误存在检测、错误类型分类和元素级错误类型分类。此外，我们构建了LED-数据集，这是一个通过根据DLA模型的经验分布注入真实结构错误而生成的合成数据集。在各种大型多模态模型上进行的实验结果表明，LED能够有效地区分结构理解能力，揭示了传统指标无法发现的模态偏差和性能权衡。", "summary": "本文提出了LED（布局错误检测）基准测试，以解决现有文档布局分析模型中关键结构错误（如合并、分割、内容丢失）检测不足的问题。LED定义了八种标准错误类型和三种评估任务，并构建了合成数据集LED-Dataset。实验证明，LED能有效评估模型的结构理解能力，并揭示传统指标无法发现的模态偏差和性能权衡。", "keywords": "文档布局分析, 结构错误, 基准测试, 大型语言模型, 多模态模型", "comments": "该论文的创新点在于提出了一个专门用于诊断文档布局分析中结构性错误的基准测试LED，填补了传统指标在此方面的不足。通过定义标准化错误类型和构建合成数据集，它为更细致地评估和改进大型语言模型及多模态模型的布局理解能力提供了新工具，对于推动文档智能领域的发展具有重要意义。"}}
{"id": "2507.23511", "title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "authors": ["Yadong Niu", "Tianzi Wang", "Heinrich Dinkel", "Xingwei Sun", "Jiahao Zhou", "Gang Li", "Jizhong Liu", "Xunying Liu", "Junbo Zhang", "Jian Luan"], "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      9 main pages, 5 figures, 3 tables, and 14 appendix pages", "url": "http://arxiv.org/abs/2507.23511v1", "summary": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat", "comment": "9 main pages, 5 figures, 3 tables, and 14 appendix pages", "pdf_url": "http://arxiv.org/pdf/2507.23511v1", "cate": "eess.AS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MECAT：一个用于细粒度音频理解任务的多专家构建基准", "tldr": "MECAT是一个新的多专家构建的基准，用于解决现有音频理解模型在细粒度理解方面的不足，并引入了新的评估指标DATE。", "motivation": "尽管大型音频-语言模型在开放式音频理解方面取得了进展，但它们在细致的人类水平理解方面仍有不足。这主要是因为当前的基准受限于数据标注和评估指标，无法可靠地区分通用和高度详细的模型输出。", "method": "本文提出了MECAT，一个多专家构建的细粒度音频理解任务基准。它通过整合专业专家模型分析与思维链大型语言模型推理的管道生成，提供多视角、细粒度字幕和开放集问答对。此外，还引入了新颖的度量标准DATE（判别增强音频文本评估），该指标通过结合单样本语义相似性和跨样本可判别性来惩罚通用术语并奖励详细描述。", "result": "对现有最先进的音频模型进行了全面的评估，提供了对其当前能力和局限性的新见解。", "conclusion": "MECAT及其伴随的DATE指标为细粒度音频理解任务提供了更可靠的基准和评估方法，揭示了当前模型的能力和局限性。", "translation": "尽管大型音频-语言模型在开放式音频理解方面取得了进展，但它们在细致的人类水平理解方面仍有不足。这种差距持续存在，很大程度上是因为当前的基准受限于数据标注和评估指标，无法可靠地区分通用和高度详细的模型输出。为此，本文引入了MECAT，一个用于细粒度音频理解任务的多专家构建基准。MECAT通过整合专业专家模型分析与思维链大型语言模型推理的管道生成，提供多视角、细粒度字幕和开放集问答对。该基准辅以一种新颖的度量标准：DATE（判别增强音频文本评估）。该指标通过结合单样本语义相似性和跨样本可判别性来惩罚通用术语并奖励详细描述。本文还对现有最先进的音频模型进行了全面的评估，提供了对其当前能力和局限性的新见解。数据和代码可在https://github.com/xiaomi-research/mecat获取。", "summary": "本文介绍了MECAT，一个由多专家构建的细粒度音频理解任务基准，旨在弥补现有大型音频-语言模型在人类级细致理解方面的不足。MECAT通过结合专业专家模型分析和思维链大语言模型推理生成，提供多视角、细粒度的音频描述和开放式问答对。同时，论文还提出了新颖的评估指标DATE，该指标能有效区分模型输出的通用性与详细性。通过对现有SOTA模型的评估，MECAT揭示了这些模型在细粒度理解方面的能力和局限性。", "keywords": "细粒度音频理解, 基准测试, 多专家系统, 大语言模型, 评估指标", "comments": "这项工作通过引入多专家构建的基准MECAT和创新的评估指标DATE，显著推动了细粒度音频理解领域的发展。MECAT利用了专家模型和LLM的优势来生成高质量、多视角的标注，解决了现有基准数据标注和评估粒度不足的问题。DATE指标的设计也很有创新性，能够更准确地评估模型输出的详细程度，而非仅仅是语义相似性。这项研究为未来开发更接近人类理解水平的音频AI模型提供了宝贵的资源和评估工具。"}}
{"id": "2507.23685", "title": "UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration", "authors": ["Zihan Cheng", "Liangtai Zhou", "Dian Chen", "Ni Tang", "Xiaotong Luo", "Yanyun Qu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23685v1", "summary": "All-in-One Image Restoration (AiOIR) has emerged as a promising yet\nchallenging research direction. To address its core challenges, we propose a\nnovel unified image restoration framework based on latent diffusion models\n(LDMs). Our approach structurally integrates low-quality visual priors into the\ndiffusion process, unlocking the powerful generative capacity of diffusion\nmodels for diverse degradations. Specifically, we design a Degradation-Aware\nFeature Fusion (DAFF) module to enable adaptive handling of diverse degradation\ntypes. Furthermore, to mitigate detail loss caused by the high compression and\niterative sampling of LDMs, we design a Detail-Aware Expert Module (DAEM) in\nthe decoder to enhance texture and fine-structure recovery. Extensive\nexperiments across multi-task and mixed degradation settings demonstrate that\nour method consistently achieves state-of-the-art performance, highlighting the\npractical potential of diffusion priors for unified image restoration. Our code\nwill be released.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23685v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "UniLDiff：释放扩散先验在一体化图像恢复中的潜力", "tldr": "UniLDiff提出了一种基于潜在扩散模型的统一图像恢复框架，通过整合低质量视觉先验和设计DAFF与DAEM模块，在一体化图像恢复任务中取得了最先进的性能。", "motivation": "一体化图像恢复（AiOIR）是一个有前景但具有挑战性的研究方向。为了解决其核心挑战，本文旨在提出一种新的方法。", "method": "本文提出了一种基于潜在扩散模型（LDMs）的新型统一图像恢复框架。该方法将低质量视觉先验结构化地整合到扩散过程中，以利用扩散模型的生成能力处理各种降级。具体来说，设计了一个降级感知特征融合（DAFF）模块来自适应处理不同降级类型，并设计了一个细节感知专家模块（DAEM）在解码器中以减轻高压缩和迭代采样导致的细节损失，从而增强纹理和精细结构恢复。", "result": "在多任务和混合降级设置下的广泛实验表明，所提出的方法持续实现了最先进的性能。", "conclusion": "本研究凸显了扩散先验在统一图像恢复方面的实际潜力。", "translation": "一体化图像恢复（AiOIR）已成为一个有前景但具有挑战性的研究方向。为了解决其核心挑战，我们提出了一种基于潜在扩散模型（LDMs）的新型统一图像恢复框架。我们的方法将低质量视觉先验结构化地整合到扩散过程中，释放了扩散模型对各种降级的强大生成能力。具体来说，我们设计了一个降级感知特征融合（DAFF）模块，以实现对不同降级类型的自适应处理。此外，为了减轻LDMs高压缩和迭代采样导致的细节损失，我们在解码器中设计了一个细节感知专家模块（DAEM），以增强纹理和精细结构恢复。在多任务和混合降级设置下的广泛实验表明，我们的方法持续实现了最先进的性能，突出了扩散先验在统一图像恢复方面的实际潜力。我们的代码将会发布。", "summary": "本文提出了UniLDiff，一个基于潜在扩散模型（LDMs）的统一图像恢复框架，旨在解决一体化图像恢复（AiOIR）的挑战。该方法通过将低质量视觉先验融入扩散过程，并引入降级感知特征融合（DAFF）模块和细节感知专家模块（DAEM），有效处理多种图像降级并恢复细节。实验证明，UniLDiff在多任务和混合降级设置下均达到了最先进的性能。", "keywords": "一体化图像恢复, 扩散模型, 视觉先验, 降级感知, 细节恢复", "comments": "该论文的创新点在于将扩散模型强大的生成能力应用于一体化图像恢复，并通过结构化整合低质量视觉先验以及引入DAFF和DAEM模块，有效解决了多重降级处理和细节恢复的难题。其提出的统一框架具有重要的实践潜力，为图像恢复领域提供了新的SOTA方法。"}}
{"id": "2503.18711", "title": "Accenture-NVS1: A Novel View Synthesis Dataset", "authors": ["Thomas Sugg", "Kyle O'Brien", "Lekh Poudel", "Alex Dumouchelle", "Michelle Jou", "Marc Bosch", "Deva Ramanan", "Srinivasa Narasimhan", "Shubham Tulsiani"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 7 figures", "url": "http://arxiv.org/abs/2503.18711v2", "summary": "This paper introduces ACC-NVS1, a specialized dataset designed for research\non Novel View Synthesis specifically for airborne and ground imagery. Data for\nACC-NVS1 was collected in Austin, TX and Pittsburgh, PA in 2023 and 2024. The\ncollection encompasses six diverse real-world scenes captured from both\nairborne and ground cameras, resulting in a total of 148,000 images. ACC-NVS1\naddresses challenges such as varying altitudes and transient objects. This\ndataset is intended to supplement existing datasets, providing additional\nresources for comprehensive research, rather than serving as a benchmark.", "comment": "6 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2503.18711v2", "cate": "cs.CV", "date": "2025-03-24", "updated": "2025-07-30", "AI": {"title_translation": "埃森哲-NVS1：一个新视角合成数据集", "tldr": "本文介绍了ACC-NVS1，一个专为机载和地面图像新视角合成研究设计的专业数据集，包含14.8万张图像，旨在解决不同高度和瞬态物体挑战，并作为现有数据集的补充。", "motivation": "现有新视角合成研究缺乏专门针对空中和地面图像的数据集，且现有数据集未能充分解决不同高度和瞬态物体等挑战。", "method": "数据集ACC-NVS1于2023年和2024年在美国奥斯汀和匹兹堡收集。它包含从空中和地面摄像机捕获的六个多样化真实世界场景，总计148,000张图像。", "result": "论文介绍了ACC-NVS1数据集，一个包含148,000张空中和地面图像的专业数据集，旨在解决新视角合成中的不同高度和瞬态物体挑战。", "conclusion": "该数据集旨在补充现有数据集，为新视角合成的全面研究提供额外资源，而非作为基准。", "translation": "本文介绍了ACC-NVS1，一个专门为机载和地面图像的新视角合成研究设计的数据集。ACC-NVS1的数据于2023年和2024年在美国德克萨斯州奥斯汀和宾夕法尼亚州匹兹堡收集。该数据集包含从空中和地面摄像机捕获的六个不同的真实世界场景，总计148,000张图像。ACC-NVS1解决了诸如不同高度和瞬态物体等挑战。该数据集旨在补充现有数据集，为全面的研究提供额外资源，而不是作为基准。", "summary": "本文推出了ACC-NVS1数据集，一个专为机载和地面图像的新视角合成研究而设计的专业数据集。该数据集于2023-2024年在美国奥斯汀和匹兹堡收集，包含六个真实世界场景的148,000张图像，旨在解决不同高度和瞬态物体等挑战。ACC-NVS1旨在作为现有数据集的补充资源，以促进更全面的研究。", "keywords": "新视角合成, 数据集, 空中图像, 地面图像, ACC-NVS1", "comments": "该论文引入了一个针对新视角合成的专用数据集，其创新之处在于专门关注空中和地面图像，并解决了不同高度和瞬态物体等特定挑战。其重要性在于补充了现有数据集的不足，为该领域的研究提供了宝贵的额外资源。论文明确指出其目的并非作为基准，这表明它更侧重于提供多样化的训练和测试数据，而非性能比较。"}}
{"id": "2507.23203", "title": "Quadratic Programming-Based Posture Manipulation and Thrust-vectoring for Agile Dynamic Walking on Narrow Pathways", "authors": ["Chenghao Wang", "Eric Sihite", "Kaushik Venkatesh Krishnamurthy", "Shreyansh Pitroda", "Adarsh Salagame", "Alireza Ramezani", "Morteza Gharib"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23203v1", "summary": "There has been significant advancement in legged robot's agility where they\ncan show impressive acrobatic maneuvers, such as parkour. These maneuvers rely\nheavily on posture manipulation. To expand the stability and locomotion\nplasticity, we use the multi-modal ability in our legged-aerial platform, the\nHusky Beta, to perform thruster-assisted walking. This robot has thrusters on\neach of its sagittal knee joints which can be used to stabilize its frontal\ndynamic as it walks. In this work, we perform a simulation study of quadruped\nnarrow-path walking with Husky $\\beta$, where the robot will utilize its\nthrusters to stably walk on a narrow path. The controller is designed based on\na centroidal dynamics model with thruster and foot ground contact forces as\ninputs. These inputs are regulated using a QP solver to be used in a model\npredictive control framework. In addition to narrow-path walking, we also\nperform a lateral push-recovery simulation to study how the thrusters can be\nused to stabilize the frontal dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23203v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于二次规划的姿态操作和推力矢量控制，用于狭窄路径上的敏捷动态行走", "tldr": "本文研究了使用四足机器人Husky Beta在狭窄路径上进行推力辅助行走的模拟。通过基于质心动力学模型、QP求解器和模型预测控制设计的控制器，机器人能够稳定地在狭窄路径上行走并从侧向推力中恢复，利用其膝关节上的推进器来稳定正面动态。", "motivation": "为了扩展足式机器人的稳定性和运动可塑性，并使其能在狭窄路径等具有挑战性的环境中敏捷行走，研究人员利用了腿式-空中平台Husky Beta的多模态能力，通过推进器辅助行走来增强其表现。", "method": "本研究使用Husky Beta四足机器人在模拟环境中进行狭窄路径行走和侧向推力恢复研究。控制器基于质心动力学模型设计，将推进器和足部地面接触力作为输入。这些输入通过二次规划（QP）求解器在模型预测控制框架中进行调节。", "result": "模拟结果显示，机器人能够利用其推进器稳定地在狭窄路径上行走。此外，侧向推力恢复模拟也表明推进器可以有效用于稳定机器人的正面动态。", "conclusion": "未在摘要中提及", "translation": "足式机器人在敏捷性方面取得了显著进展，它们可以展示令人印象深刻的杂技动作，例如跑酷。这些动作严重依赖于姿态操作。为了扩展稳定性和运动可塑性，我们利用腿式-空中平台Husky Beta的多模态能力来执行推进器辅助行走。该机器人每个矢状膝关节上都有推进器，可以在行走时用于稳定其正面动态。在这项工作中，我们对四足机器人Husky Beta在狭窄路径上行走进行了模拟研究，机器人将利用其推进器在狭窄路径上稳定行走。控制器基于质心动力学模型设计，推进器和足部地面接触力作为输入。这些输入使用QP求解器在模型预测控制框架中进行调节。除了狭窄路径行走，我们还进行了侧向推力恢复模拟，以研究推进器如何用于稳定正面动态。", "summary": "本文研究了四足机器人Husky Beta在狭窄路径上进行推力辅助行走的模拟。该机器人利用其膝关节上的推进器来稳定正面动态。通过基于质心动力学模型、二次规划（QP）求解器和模型预测控制框架设计的控制器，模拟结果表明机器人能够稳定地在狭窄路径上行走，并且推进器也能有效用于侧向推力恢复，从而增强了机器人的稳定性和运动可塑性。", "keywords": "足式机器人, 推力矢量, 二次规划, 狭窄路径行走, 模型预测控制", "comments": "这项研究的创新之处在于将推进器集成到足式机器人（Husky Beta）的膝关节上，并将其与基于二次规划的模型预测控制相结合，以解决狭窄路径行走和侧向推力恢复等挑战性动态平衡问题。这种多模态方法的提出，为提升足式机器人在复杂环境中的敏捷性和鲁棒性提供了新的思路和潜力。"}}
{"id": "2507.23096", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "authors": ["Tom Peterka", "Tanwi Mallick", "Orcun Yildiz", "David Lenz", "Cory Quammen", "Berk Geveci"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23096v1", "summary": "Large language models (LLMs) are rapidly increasing in capability, but they\nstill struggle with highly specialized programming tasks such as scientific\nvisualization. We present an LLM assistant, ChatVis, that aids the LLM to\ngenerate Python code for ParaView scientific visualization tasks, without the\nneed for retraining or fine-tuning the LLM. ChatVis employs chain-of-thought\nprompt simplification, retrieval-augmented prompt generation using a vector\ndatabase of documentation and code examples, and error checking with iterative\nprompt feedback to correct errors until a visualization is produced. An\nintegral part of our approach is a benchmark suite of canonical visualization\ntasks, ParaView regression tests, and scientific use cases that includes\ncomprehensive evaluation metrics. We evaluate our visualization assistant by\ncomparing results with a variety of top-performing unassisted LLMs. We find\nthat all the metrics are significantly improved with ChatVis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23096v1", "cate": "cs.HC", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "ChatVis：用于生成科学可视化的大型语言模型代理", "tldr": "ChatVis是一个LLM助手，通过链式思考、RAG和错误检查，显著提高了LLM生成科学可视化Python代码的能力，无需重新训练或微调。", "motivation": "尽管大型语言模型（LLM）的能力正在迅速提升，但它们在科学可视化等高度专业化的编程任务上仍然面临挑战。", "method": "ChatVis通过链式思考提示简化、使用文档和代码示例的向量数据库进行检索增强提示生成，以及通过迭代提示反馈进行错误检查来辅助LLM生成Python代码。此外，该方法还包含一个用于评估的基准套件，包括规范可视化任务、ParaView回归测试和科学用例。", "result": "评估结果显示，与各种表现最佳的非辅助LLM相比，ChatVis显著改善了所有评估指标。", "conclusion": "ChatVis能够显著提高大型语言模型在生成科学可视化代码方面的性能，且无需重新训练或微调LLM。", "translation": "大型语言模型（LLM）的能力正在迅速提升，但它们在科学可视化等高度专业化的编程任务上仍然面临挑战。我们提出了一种LLM助手ChatVis，它可以帮助LLM生成用于ParaView科学可视化任务的Python代码，而无需重新训练或微调LLM。ChatVis采用链式思考提示简化、使用文档和代码示例向量数据库的检索增强提示生成，以及通过迭代提示反馈进行错误检查以纠正错误，直到生成可视化。我们方法的一个组成部分是包含规范可视化任务、ParaView回归测试和科学用例的基准套件，其中包括全面的评估指标。我们通过将结果与各种表现最佳的非辅助LLM进行比较来评估我们的可视化助手。我们发现，ChatVis显著改善了所有指标。", "summary": "ChatVis是一个创新的大型语言模型（LLM）助手，旨在解决LLM在生成科学可视化代码方面的不足。它通过结合链式思考、检索增强生成（RAG）和迭代错误修正机制，使LLM无需额外训练即可为ParaView等工具生成高质量的Python可视化代码。该研究还引入了一个全面的基准套件用于评估，并证明ChatVis显著优于未辅助的LLM。", "keywords": "大型语言模型, 科学可视化, 代码生成, ParaView, 检索增强生成", "comments": "ChatVis的创新之处在于其无需重新训练或微调LLM即可显著提升其在特定专业领域（科学可视化）的代码生成能力。其结合链式思考、检索增强生成（RAG）和迭代错误修正的混合方法为解决LLM在专业任务中的“幻觉”和准确性问题提供了一个有效范例。这项工作对于推动LLM在科学计算和数据可视化领域的应用具有重要意义。"}}
{"id": "2507.23465", "title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "authors": ["Saeed Almheiri", "Yerulan Kongrat", "Adrian Santosh", "Ruslan Tasmukhanov", "Josemaria Vera", "Muhammad Dehan Al Kautsar", "Fajri Koto"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23465v1", "summary": "As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23465v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "组织中安全和情境化访问控制的角色感知语言模型", "tldr": "本研究探讨了如何微调大型语言模型（LLMs）以实现基于用户角色的访问控制，以满足企业部署需求，并通过构建数据集和评估多种策略来分析其在不同组织结构和安全挑战下的性能。", "motivation": "随着大型语言模型（LLMs）在企业环境中的广泛部署，根据用户角色控制模型行为成为一项基本要求。现有的安全方法通常假定统一访问，并侧重于防止有害或有毒输出，但未能解决特定于角色的访问限制。", "method": "本文研究了是否可以通过微调LLMs来生成反映不同组织角色访问权限的响应。研究探索了三种建模策略：基于BERT的分类器、基于LLM的分类器和角色条件生成。为了评估这些方法，构建了两个互补的数据集：第一个通过聚类和角色标注从现有指令微调语料库改编而来，第二个是合成生成以反映真实的、角色敏感的企业场景。", "result": "本研究评估了模型在不同组织结构下的性能，并分析了其对提示注入、角色不匹配和越狱尝试的鲁棒性。具体的实验结果未在摘要中提及。", "conclusion": "摘要中未明确提及结论。", "translation": "随着大型语言模型（LLMs）在企业环境中的日益部署，根据用户角色控制模型行为成为一项基本要求。现有的安全方法通常假定统一访问，并侧重于防止有害或有毒输出，但未能解决特定于角色的访问限制。在这项工作中，我们调查了是否可以微调LLMs以生成反映与不同组织角色相关的访问权限的响应。我们探索了三种建模策略：基于BERT的分类器、基于LLM的分类器和角色条件生成。为了评估这些方法，我们构建了两个互补的数据集。第一个是通过聚类和角色标注从现有指令微调语料库改编而来，而第二个是合成生成以反映真实的、角色敏感的企业场景。我们评估了模型在不同组织结构下的性能，并分析了其对提示注入、角色不匹配和越狱尝试的鲁棒性。", "summary": "本研究旨在解决大型语言模型在企业应用中缺乏基于角色访问控制的问题。针对现有安全方法无法处理角色特定权限的局限性，论文探索了通过微调LLMs来实现角色感知响应的可能性。研究提出了BERT分类器、LLM分类器和角色条件生成三种建模策略，并构建了两个数据集（改编自现有语料库和合成生成）进行评估。最终，论文评估了模型在不同组织结构下的表现及其对各种安全威胁（如提示注入、角色不匹配和越狱）的鲁棒性。", "keywords": "角色感知, 语言模型, 访问控制, 企业应用, 微调", "comments": "这项研究的创新之处在于将LLMs的安全研究从普遍性的有害内容过滤扩展到企业环境中至关重要的“角色感知”访问控制。这对于LLMs在实际商业部署中的合规性和安全性具有重要意义，弥补了现有安全机制的不足。其提出的多种建模策略和专门构建的数据集也体现了研究的系统性。"}}
{"id": "2506.18199", "title": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review", "authors": ["Bushra Asseri", "Estabrag Abdelaziz", "Areej Al-Wabil"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Research is incomplete", "url": "http://arxiv.org/abs/2506.18199v2", "summary": "Large language models have demonstrated remarkable capabilities across\nvarious domains, yet concerns about cultural bias - particularly towards Arabs\nand Muslims - pose significant ethical challenges by perpetuating harmful\nstereotypes and marginalization. Despite growing recognition of bias in LLMs,\nprompt engineering strategies specifically addressing Arab and Muslim\nrepresentation remain understudied. This mixed-methods systematic review\nexamines such techniques, offering evidence-based guidance for researchers and\npractitioners. Following PRISMA guidelines and Kitchenham's systematic review\nmethodology, we analyzed 8 empirical studies published between 2021-2024\ninvestigating bias mitigation strategies. Our findings reveal five primary\nprompt engineering approaches: cultural prompting, affective priming,\nself-debiasing techniques, structured multi-step pipelines, and\nparameter-optimized continuous prompts. Although all approaches show potential\nfor reducing bias, effectiveness varied substantially across studies and bias\ntypes. Evidence suggests that certain bias types may be more resistant to\nprompt-based mitigation than others. Structured multi-step pipelines\ndemonstrated the highest overall effectiveness, achieving up to 87.7% reduction\nin bias, though they require greater technical expertise. Cultural prompting\noffers broader accessibility with substantial effectiveness. These results\nunderscore the accessibility of prompt engineering for mitigating cultural bias\nwithout requiring access to model parameters. The limited number of studies\nidentified highlights a significant research gap in this critical area. Future\nresearch should focus on developing culturally adaptive prompting techniques,\ncreating Arab and Muslim-specific evaluation resources, and integrating prompt\nengineering with complementary debiasing methods to address deeper stereotypes\nwhile maintaining model utility.", "comment": "Research is incomplete", "pdf_url": "http://arxiv.org/pdf/2506.18199v2", "cate": "cs.CL", "date": "2025-06-22", "updated": "2025-07-30", "AI": {"title_translation": "大型语言模型中缓解针对阿拉伯人和穆斯林文化偏见的提示工程技术：一项系统综述", "tldr": "系统综述发现，提示工程技术，尤其是结构化多步管道和文化提示，能有效缓解大型语言模型对阿拉伯人和穆斯林的文化偏见，但研究数量有限，仍有待深入探索。", "motivation": "大型语言模型存在对阿拉伯人和穆斯林的文化偏见，这会加剧有害刻板印象和边缘化，带来严重的伦理挑战。尽管对LLM偏见的认识不断提高，但专门针对阿拉伯和穆斯林表征的提示工程策略仍未得到充分研究。", "method": "该研究采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综论方法论。分析了2021-2024年间发表的8项调查偏见缓解策略的实证研究。", "result": "识别出五种主要的提示工程方法：文化提示、情感启动、自我去偏技术、结构化多步管道和参数优化连续提示。所有方法都显示出减少偏见的潜力，但效果因研究和偏见类型而异。某些偏见类型可能更难通过基于提示的方法缓解。结构化多步管道表现出最高的整体有效性，偏见减少高达87.7%，但需要更高的技术专业知识。文化提示具有更广泛的可及性和显著的有效性。结果强调了提示工程在不需访问模型参数的情况下缓解文化偏见的可行性。识别出的研究数量有限，表明该领域存在显著的研究空白。", "conclusion": "提示工程是缓解大型语言模型中文化偏见的可行方法，特别是结构化多步管道和文化提示显示出显著效果。然而，该领域仍存在研究空白，未来需要更多关注开发文化适应性提示技术、创建特定评估资源以及整合其他去偏方法。", "translation": "大型语言模型在各个领域都展现出卓越的能力，但对文化偏见——尤其是针对阿拉伯人和穆斯林的偏见——的担忧，通过延续有害的刻板印象和边缘化，带来了重大的伦理挑战。尽管人们对大型语言模型中的偏见日益认识，但专门解决阿拉伯人和穆斯林代表性的提示工程策略仍未得到充分研究。这项混合方法系统综述考察了此类技术，为研究人员和从业者提供了循证指导。我们遵循PRISMA指南和Kitchenham的系统综述方法论，分析了2021-2024年间发表的8项调查偏见缓解策略的实证研究。我们的发现揭示了五种主要的提示工程方法：文化提示、情感启动、自我去偏技术、结构化多步管道和参数优化连续提示。尽管所有方法都显示出减少偏见的潜力，但其有效性在不同研究和偏见类型之间差异很大。有证据表明，某些偏见类型可能比其他类型更难通过基于提示的方法缓解。结构化多步管道表现出最高的整体有效性，偏见减少高达87.7%，尽管它们需要更高的技术专业知识。文化提示具有更广泛的可及性和显著的有效性。这些结果强调了提示工程在无需访问模型参数的情况下缓解文化偏见的可行性。识别出的研究数量有限凸显了这一关键领域存在显著的研究空白。未来的研究应侧重于开发文化适应性提示技术，创建阿拉伯和穆斯林特定的评估资源，并将提示工程与互补的去偏方法相结合，以解决更深层次的刻板印象，同时保持模型效用。", "summary": "本系统综述旨在探讨并总结缓解大型语言模型中针对阿拉伯人和穆斯林文化偏见的提示工程技术。研究通过分析2021-2024年的8项实证研究，识别出五种主要方法：文化提示、情感启动、自我去偏技术、结构化多步管道和参数优化连续提示。结果显示，所有方法均有潜力，其中结构化多步管道和文化提示效果显著，前者能将偏见减少高达87.7%。研究强调了提示工程在无需模型参数访问的情况下缓解偏见的可行性，并指出该领域研究不足，未来需重点关注文化适应性技术和特定评估资源的开发。", "keywords": "提示工程, 文化偏见, 大型语言模型, 阿拉伯人, 穆斯林, 系统综述", "comments": "这项系统综述具有重要的现实意义，因为它关注了大型语言模型中一个关键且敏感的伦理问题——文化偏见，特别是针对阿拉伯人和穆斯林的偏见。其创新之处在于系统性地梳理了提示工程在偏见缓解方面的应用，并识别出多种有效策略。研究结果强调了提示工程作为一种无需访问模型内部参数的有效且易于实现的去偏方法，这对于实际应用具有巨大价值。然而，该研究也明确指出了现有研究的局限性，即相关研究数量有限，这表明该领域仍有广阔的探索空间，特别是需要深入研究更难缓解的偏见类型以及开发更具文化特异性的去偏方法。"}}
{"id": "2507.23407", "title": "Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration", "authors": ["Ante Wang", "Yujie Lin", "Jingyao Liu", "Suhang Wu", "Hao Liu", "Xinyan Xiao", "Jinsong Su"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23407v1", "summary": "Critical thinking is essential for building robust AI systems, preventing\nthem from blindly accepting flawed data or biased reasoning. However, prior\nwork has primarily focused on passive critical thinking, where models simply\nreject problematic queries without taking constructive steps to address user\nrequests. In this work, we introduce proactive critical thinking, a paradigm\nwhere models actively seek missing or clarifying information from users to\nresolve their queries better. To evaluate this capability, we present GSM-MC\nand GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical\nreasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math\nproblems with a key variable deliberately removed, requiring models to identify\nand request the missing information. GSM-MCE further increases the difficulty\nby introducing irrelevant details to test robustness against distractions.\nExperiments on Qwen3 and Llama series models show that, while these models\nexcel in traditional reasoning tasks due to extensive post-training and\ninference-time scaling, they struggle with proactive critical thinking,\nespecially smaller ones. However, we demonstrate that reinforcement learning\n(RL) can significantly improve this ability. Using our enhanced RL algorithm,\nwe achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to\n73.98% on GSM-MC. We hope this work advances models that collaborate more\neffectively with users in problem-solving through proactive critical thinking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23407v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "超越被动批判性思维：培养主动提问以增强人机协作", "tldr": "AI通常只进行被动批判性思维（拒绝错误输入）。本文提出主动批判性思维（主动询问澄清信息），以增强人机协作。为此，他们引入了新的基准（GSM-MC，GSM-MCE），并证明强化学习能显著提高AI的主动批判性思维能力。", "motivation": "批判性思维对构建健壮的AI系统至关重要，但现有研究主要集中于被动批判性思维，即模型仅拒绝问题而未能建设性地解决用户请求。因此，需要开发能够主动寻求缺失或澄清信息的模型，以更好地解决用户查询。", "method": "引入了“主动批判性思维”范式。开发了两个基于GSM8K的新型基准GSM-MC（包含1,368个缺少关键变量的数学问题）和GSM-MCE（GSM-MC基础上增加无关细节）。使用这些基准评估了Qwen3和Llama系列模型。运用强化学习（RL）来显著提升模型的主动批判性思维能力。", "result": "Qwen3和Llama系列模型在传统推理任务中表现出色，但在主动批判性思维方面表现不佳，尤其是小型模型。强化学习（RL）能显著提高这种能力。增强的RL算法将Qwen3-1.7B在GSM-MC上的准确率从0.15%提升到73.98%。", "conclusion": "主动批判性思维对于有效的人机协作至关重要。强化学习可以显著提升AI模型的主动批判性思维能力，从而促进更好的问题解决。", "translation": "批判性思维对于构建稳健的AI系统至关重要，它可以防止AI盲目接受有缺陷的数据或有偏见的推理。然而，之前的工作主要集中在被动批判性思维上，即模型只是拒绝有问题的问题，而没有采取建设性措施来满足用户请求。在这项工作中，我们引入了主动批判性思维，这是一种模型主动向用户寻求缺失或澄清信息以更好地解决其查询的范式。为了评估这种能力，我们提出了GSM-MC和GSM-MCE，这两个基于GSM8K的新型基准，用于评估不完整或误导条件下数学推理能力。GSM-MC包含1,368个数学问题，其中一个关键变量被故意移除，要求模型识别并请求缺失的信息。GSM-MCE通过引入不相关细节进一步增加了难度，以测试对干扰的鲁棒性。对Qwen3和Llama系列模型的实验表明，尽管这些模型由于广泛的后训练和推理时缩放而在传统推理任务中表现出色，但它们在主动批判性思维方面表现不佳，特别是较小的模型。然而，我们证明了强化学习（RL）可以显著提高这种能力。使用我们增强的RL算法，我们取得了显著的进步，将Qwen3-1.7B在GSM-MC上的准确率从0.15%提高到73.98%。我们希望这项工作能通过主动批判性思维促进模型在解决问题时与用户更有效地协作。", "summary": "本文提出“主动批判性思维”范式，旨在使AI模型能主动向用户寻求澄清信息，而非仅被动拒绝不完整或有偏见的输入。为评估此能力，研究者开发了GSM-MC和GSM-MCE两个新基准，用于测试模型在不完整或误导性条件下的数学推理能力。实验结果显示，当前模型在主动批判性思维方面表现不足，但通过强化学习可显著提升此能力，例如将Qwen3-1.7B在GSM-MC上的准确率从0.15%提升至73.98%，从而促进更有效的人机协作。", "keywords": "主动批判性思维, 人机协作, 强化学习, 数学推理, 基准", "comments": "这项工作通过将AI的批判性思维从被动拒绝提升到主动寻求信息，解决了AI能力的一个关键空白，这对于现实世界中交互式AI至关重要。引入具体的基准（GSM-MC、GSM-MCE）对于量化批判性思维的这一新方面具有重要价值。通过强化学习实现的显著改进突显了其在开发更健壮、更协作的AI系统方面的潜力，这可能极大地增强AI在复杂问题解决场景中的可信度和实用性。"}}
{"id": "2412.06946", "title": "A Deep Learning Powered Numerical Relativity Surrogate for Binary Black Hole Waveforms", "authors": ["Osvaldo Gramaxo Freitas", "Anastasios Theodoropoulos", "Nino Villanueva", "Tiago Fernandes", "Solange Nunes", "José A. Font", "Antonio Onofre", "Alejandro Torres-Forné", "José D. Martin-Guerrero"], "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG"], "primary_category": "Subjects:       General Relativity and Quantum Cosmology (gr-qc)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.06946v3", "summary": "Gravitational-wave approximants are essential for gravitational-wave\nastronomy, allowing the coverage binary black hole parameter space for\ninference or match filtering without costly numerical relativity (NR)\nsimulations, but generally trading some accuracy for computational efficiency.\nTo reduce this trade-off, NR surrogate models can be constructed using\ninterpolation within NR waveform space. We present a 2-stage training approach\nfor neural network-based NR surrogate models. Initially trained on\napproximant-generated waveforms and then fine-tuned with NR data, these\ndual-stage artificial neural surrogate (\\texttt{DANSur}) models offer rapid and\ncompetitively accurate waveform generation, generating millions in under 20ms\non a GPU while keeping mean mismatches with NR around $10^{-4}$. Implemented in\nthe \\textsc{bilby} framework, we show they can be used for parameter estimation\ntasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.06946v3", "cate": "gr-qc", "date": "2024-12-09", "updated": "2025-07-31", "AI": {"title_translation": "深度学习驱动的二元黑洞波形数值相对论替代模型", "tldr": "开发了一种名为DANSur的深度学习模型，通过两阶段训练，能快速准确地生成二元黑洞引力波形，用于引力波天文学。", "motivation": "引力波近似器在引力波天文学中必不可少，但通常以牺牲精度为代价换取计算效率。数值相对论（NR）模拟虽然精确但成本高昂。本文旨在减少这种精度与效率之间的权衡。", "method": "提出了一种基于神经网络的NR替代模型的两阶段训练方法。首先使用近似器生成的波形进行训练，然后利用NR数据进行微调，构建了双阶段人工神经替代（DANSur）模型。", "result": "DANSur模型能够快速且具有竞争力的准确性生成波形，在GPU上20毫秒内生成数百万个波形，与NR数据的平均失配度保持在$10^{-4}$左右。该模型已在\\textsc{bilby}框架中实现，并可用于参数估计任务。", "conclusion": "本文提出的深度学习驱动的数值相对论替代模型DANSur，显著提高了二元黑洞波形生成的效率和准确性，为引力波天文学中的参数估计等任务提供了强大的工具。", "translation": "引力波近似器对于引力波天文学至关重要，它们允许在不进行昂贵的数值相对论（NR）模拟的情况下覆盖二元黑洞参数空间进行推断或匹配滤波，但通常以牺牲一些精度为代价来换取计算效率。为了减少这种权衡，可以使用NR波形空间内的插值构建NR替代模型。我们提出了一种基于神经网络的NR替代模型的两阶段训练方法。最初使用近似器生成的波形进行训练，然后用NR数据进行微调，这些双阶段人工神经替代（DANSur）模型提供了快速且具有竞争力的准确波形生成，在GPU上20毫秒内生成数百万个波形，同时与NR的平均失配度保持在$10^{-4}$左右。在\\textsc{bilby}框架中实现后，我们展示了它们可用于参数估计任务。", "summary": "本文介绍了一种名为DANSur的深度学习驱动的数值相对论（NR）替代模型，旨在解决引力波天文学中引力波形生成效率与精度之间的权衡问题。该模型采用两阶段训练方法，首先基于近似器生成的波形进行初步训练，随后利用高精度NR数据进行微调。实验结果表明，DANSur模型能够在极短时间内（GPU上20毫秒内生成数百万个）快速生成高精度波形，与NR数据的平均失配度低至$10^{-4}$，并且已成功应用于参数估计任务。", "keywords": "引力波、数值相对论、深度学习、替代模型、二元黑洞波形", "comments": "这篇论文通过引入一个两阶段训练的深度学习模型（DANSur），有效地解决了引力波形生成中效率与精度之间的经典矛盾。其创新之处在于结合了近似器数据和高精度NR数据进行训练，从而在保持高准确性的同时，实现了极高的计算效率。这对于引力波天文学中的实时数据分析和参数估计具有重要意义，有望加速引力波事件的识别和理解。"}}
{"id": "2507.22956", "title": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes", "authors": ["Dong Hyun Roh", "Rajesh Kumar", "An Ngo"], "categories": ["cs.LG", "cs.HC", "K.3.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has 11 pages, 6 figures, 2 tables, and has been accepted for publication at IEEE-IJCB 2025", "url": "http://arxiv.org/abs/2507.22956v1", "summary": "This paper presents a keystroke-based framework for detecting LLM-assisted\ncheating in Korean, addressing key gaps in prior research regarding language\ncoverage, cognitive context, and the granularity of LLM involvement. Our\nproposed dataset includes 69 participants who completed writing tasks under\nthree conditions: Bona fide writing, paraphrasing ChatGPT responses, and\ntranscribing ChatGPT responses. Each task spans six cognitive processes defined\nin Bloom's Taxonomy (remember, understand, apply, analyze, evaluate, and\ncreate). We extract interpretable temporal and rhythmic features and evaluate\nmultiple classifiers under both Cognition-Aware and Cognition-Unaware settings.\nTemporal features perform well under Cognition-Aware evaluation scenarios,\nwhile rhythmic features generalize better under cross-cognition scenarios.\nMoreover, detecting bona fide and transcribed responses was easier than\nparaphrased ones for both the proposed models and human evaluators, with the\nmodels significantly outperforming the humans. Our findings affirm that\nkeystroke dynamics facilitate reliable detection of LLM-assisted writing across\nvarying cognitive demands and writing strategies, including paraphrasing and\ntranscribing LLM-generated responses.", "comment": "This paper has 11 pages, 6 figures, 2 tables, and has been accepted\n  for publication at IEEE-IJCB 2025", "pdf_url": "http://arxiv.org/pdf/2507.22956v1", "cate": "cs.LG", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "通过击键检测韩语中LLM辅助作弊", "tldr": "本文提出了一个基于击键的框架，用于检测韩语中LLM辅助的作弊行为，填补了现有研究在语言覆盖、认知背景和LLM参与粒度方面的空白，并证明击键动态能够可靠地检测不同认知需求和写作策略下的LLM辅助写作。", "motivation": "现有研究在语言覆盖、认知背景和LLM参与粒度方面存在关键空白，本文旨在通过击键检测韩语中LLM辅助的作弊行为。", "method": "本文构建了一个包含69名参与者的数据集，他们在三种条件下（真实写作、转述ChatGPT回复、转录ChatGPT回复）完成了写作任务。每项任务涵盖布鲁姆认知分类法中的六个认知过程。研究提取了可解释的时间和节奏特征，并在认知感知和认知无关设置下评估了多种分类器。", "result": "在认知感知评估场景下，时间特征表现良好；在跨认知场景下，节奏特征的泛化能力更强。对于所提出的模型和人类评估者而言，检测真实和转录的回复比转述的回复更容易，且模型显著优于人类。", "conclusion": "击键动态有助于可靠地检测不同认知需求和写作策略（包括转述和转录LLM生成回复）下的LLM辅助写作。", "translation": "本文提出了一个基于击键的框架，用于检测韩语中LLM辅助的作弊行为，解决了现有研究在语言覆盖、认知背景和LLM参与粒度方面的关键空白。我们提出的数据集包括69名参与者，他们在三种条件下完成了写作任务：真实写作、转述ChatGPT回复和转录ChatGPT回复。每项任务涵盖布鲁姆认知分类法中定义的六个认知过程（记忆、理解、应用、分析、评估和创造）。我们提取了可解释的时间和节奏特征，并在认知感知和认知无关设置下评估了多种分类器。在认知感知评估场景下，时间特征表现良好，而节奏特征在跨认知场景下表现出更好的泛化能力。此外，对于所提出的模型和人类评估者而言，检测真实和转录的回复比转述的回复更容易，且模型显著优于人类。我们的研究结果证实，击键动态有助于可靠地检测不同认知需求和写作策略（包括转述和转录LLM生成回复）下的LLM辅助写作。", "summary": "本研究提出了一种基于击键的框架，用于检测韩语中大型语言模型（LLM）辅助的作弊行为，旨在弥补现有研究在语言、认知背景和LLM参与度方面的不足。研究构建了一个包含69名参与者的数据集，记录了他们在真实写作、转述和转录LLM回复三种条件下、跨六种认知过程的击键数据。通过提取时间和节奏特征，并评估分类器，发现时间特征在认知感知场景下表现良好，节奏特征在跨认知场景下泛化能力更强。模型在检测真实和转录回复方面优于转述回复，且性能显著超越人类评估者。研究结果表明，击键动态能有效检测不同认知需求和写作策略下的LLM辅助写作。", "keywords": "LLM辅助作弊, 击键动态, 韩语, 作弊检测, 认知过程", "comments": "本文的创新之处在于其针对韩语的LLM辅助作弊检测，并引入了认知过程的考量，构建了包含不同写作策略（真实、转述、转录）的独特击键数据集。其重要性在于为未来LLM辅助作弊检测提供了新的技术路径，尤其是在非英语语言和更精细的作弊行为（如转述）检测方面。模型性能优于人类评估者也凸显了其潜力。"}}
{"id": "2412.19792", "title": "InfAlign: Inference-aware language model alignment", "authors": ["Ananth Balashankar", "Ziteng Sun", "Jonathan Berant", "Jacob Eisenstein", "Michael Collins", "Adrian Hutter", "Jong Lee", "Chirag Nagpal", "Flavien Prost", "Aradhana Sinha", "Ananda Theertha Suresh", "Ahmad Beirami"], "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.19792v4", "summary": "Language model alignment is a critical step in training modern generative\nlanguage models. Alignment targets to improve win rate of a sample from the\naligned model against the base model. Today, we are increasingly using\ninference-time algorithms (e.g., Best-of-N, controlled decoding, tree search)\nto decode from language models rather than standard sampling. We show that this\ntrain/test mismatch makes standard RLHF framework sub-optimal in view of such\ninference-time methods. To this end, we propose a framework for inference-aware\nalignment (InfAlign), which aims to optimize inference-time win rate of the\naligned policy against the base model. We prove that for any inference-time\ndecoding procedure, the optimal aligned policy is the solution to the standard\nRLHF problem with a transformation of the reward. This motivates us to provide\nthe calibrate-and-transform RL (InfAlign-CTRL) algorithm to solve this problem,\nwhich involves a reward calibration step and a KL-regularized reward\nmaximization step with a transformation of the calibrated reward. For best-of-N\nsampling and best-of-N jailbreaking, we propose specific transformations\noffering up to 3-8% improvement on inference-time win rates. Finally, we also\nshow that our proposed reward calibration method is a strong baseline for\noptimizing standard win rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.19792v4", "cate": "cs.LG", "date": "2024-12-27", "updated": "2025-07-31", "AI": {"title_translation": "InfAlign：推理感知语言模型对齐", "tldr": "当前RLHF在推理时解码方面表现不佳。本文提出了InfAlign，一个推理感知的对齐框架，通过奖励转换优化策略，显著提高了胜率。", "motivation": "当今语言模型越来越多地使用推理时算法（如N选一、受控解码、树搜索）进行解码，而非标准采样。这种训练/测试不匹配导致标准RLHF框架在面对此类推理时方法时表现不佳，从而使得对齐模型的胜率次优。", "method": "本文提出了一个推理感知对齐框架（InfAlign），旨在优化对齐策略的推理时胜率。研究证明，对于任何推理时解码过程，最优对齐策略是标准RLHF问题在奖励转换后的解决方案。基于此，提出了校准-转换RL（InfAlign-CTRL）算法，该算法包括奖励校准步骤和使用校准奖励转换的KL正则化奖励最大化步骤。针对N选一采样和N选一越狱，提出了特定的转换方法。", "result": "在N选一采样和N选一越狱场景中，推理时胜率提高了3-8%。此外，提出的奖励校准方法也被证明是优化标准胜率的强大基线。", "conclusion": "InfAlign为优化语言模型对齐以适应现代推理时解码策略提供了一个原则性框架，显著提高了胜率，并为标准对齐提供了强大的基线。", "translation": "语言模型对齐是训练现代生成式语言模型的关键一步。对齐旨在提高对齐模型样本相对于基础模型的胜率。如今，我们越来越多地使用推理时算法（例如，N选一、受控解码、树搜索）从语言模型中进行解码，而不是标准采样。我们发现这种训练/测试不匹配使得标准RLHF框架在面对此类推理时方法时表现不佳。为此，我们提出了一个推理感知对齐框架（InfAlign），旨在优化对齐策略相对于基础模型的推理时胜率。我们证明，对于任何推理时解码过程，最优对齐策略是标准RLHF问题在奖励转换后的解决方案。这促使我们提出了校准-转换RL（InfAlign-CTRL）算法来解决这个问题，该算法包括一个奖励校准步骤和一个KL正则化奖励最大化步骤，其中使用了校准后的奖励转换。对于N选一采样和N选一越狱，我们提出了特定的转换，将推理时胜率提高了3-8%。最后，我们还表明，我们提出的奖励校准方法是优化标准胜率的强大基线。", "summary": "本文提出了InfAlign，一个推理感知语言模型对齐框架，旨在解决标准RLHF在现代推理时解码方法下存在的训练/测试不匹配问题。InfAlign证明，通过对标准RLHF问题中的奖励进行转换，可以获得最优的对齐策略。所提出的InfAlign-CTRL算法，包含奖励校准和转换后的奖励最大化步骤，在N选一场景中将推理时胜率提高了3-8%，并为标准胜率优化提供了一个强大的基线。", "keywords": "语言模型对齐, 推理感知, RLHF, N选一, 奖励转换", "comments": "这篇论文具有创新性，因为它识别并解决了语言模型对齐中一个关键的训练/测试不匹配问题，尤其是在采用现代推理时解码策略时。通过提出一个原则性框架（InfAlign），该框架通过转换奖励来优化推理时胜率，它相对于标准RLHF取得了显著进步。其证明的最优条件和具有实际性能提升（胜率提高3-8%）的实用算法（InfAlign-CTRL）凸显了其对于开发更鲁棒、更有效的对齐生成式语言模型的重要性。"}}
{"id": "1908.01212", "title": "Typing Tensor Calculus in 2-Categories (I)", "authors": ["Fatimah Rita Ahmadi"], "categories": ["math.CT", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Category Theory (math.CT)", "pdf_link": null, "comments": "Comments:      28 pages; extended introduction, more explanation", "url": "http://arxiv.org/abs/1908.01212v4", "summary": "To formalize calculations in linear algebra for the development of efficient\nalgorithms and a framework suitable for functional programming languages and\nfaster parallelized computations, we adopt an approach that treats elements of\nlinear algebra, such as matrices, as morphisms in the category of matrices,\n$\\mathbf{Mat_{k}}$. This framework is further extended by generalizing the\nresults to arbitrary monoidal semiadditive categories. To enrich this\nperspective and accommodate higher-rank matrices (tensors), we define\nsemiadditive 2-categories, where matrices $T_{ij}$ are represented as\n1-morphisms, and tensors with four indices $T_{ijkl}$ as 2-morphisms. This\nformalization provides an index-free, typed linear algebra framework that\nincludes matrices and tensors with up to four indices. Furthermore, we extend\nthe framework to monoidal semiadditive 2-categories and demonstrate detailed\noperations and vectorization within the 2-category of 2Vec introduced by\nKapranov and Voevodsky.", "comment": "28 pages; extended introduction, more explanation", "pdf_url": "http://arxiv.org/pdf/1908.01212v4", "cate": "math.CT", "date": "2019-08-03", "updated": "2025-01-09", "AI": {"title_translation": "2-范畴中的张量微积分类型化 (I)", "tldr": "本文提出了一种使用2-范畴对张量微积分进行类型化和无索引形式化的方法，旨在为高效算法、函数式编程和并行计算提供一个统一的线性代数框架。", "motivation": "为了形式化线性代数中的计算，以开发高效算法，并构建一个适用于函数式编程语言和更快并行计算的框架。", "method": "研究人员首先将线性代数中的元素（如矩阵）视为矩阵范畴 $\\mathbf{Mat_{k}}$ 中的态射。随后，将该框架推广到任意幺半半加性范畴。为了容纳高阶矩阵（张量），定义了半加性2-范畴，其中矩阵 $T_{ij}$ 表示为1-态射，四指标张量 $T_{ijkl}$ 表示为2-态射。此外，该框架被扩展到幺半半加性2-范畴，并在Kapranov和Voevodsky引入的2Vec 2-范畴中展示了详细的操作和向量化。", "result": "本文提供了一个无索引、类型化的线性代数框架，该框架包含矩阵和最多四指标的张量。此外，该框架被扩展到幺半半加性2-范畴，并展示了在2Vec 2-范畴中的详细操作和向量化。", "conclusion": "该形式化方法提供了一个无索引、类型化的线性代数框架，涵盖了矩阵和最多四指标的张量，并通过扩展到幺半半加性2-范畴，展示了详细的操作和向量化，为高效计算奠定了基础。", "translation": "为了形式化线性代数中的计算，以开发高效算法，并构建一个适用于函数式编程语言和更快并行计算的框架，我们采用了一种将线性代数元素（如矩阵）视为矩阵范畴 $\\mathbf{Mat_{k}}$ 中态射的方法。该框架通过将结果推广到任意幺半半加性范畴而得到进一步扩展。为了丰富这种视角并容纳高阶矩阵（张量），我们定义了半加性2-范畴，其中矩阵 $T_{ij}$ 表示为1-态射，四指标张量 $T_{ijkl}$ 表示为2-态射。这种形式化提供了一个无索引、类型化的线性代数框架，包括矩阵和最多四指标的张量。此外，我们还将该框架扩展到幺半半加性2-范畴，并在Kapranov和Voevodsky引入的2Vec 2-范畴中展示了详细的操作和向量化。", "summary": "本文提出了一种基于2-范畴的无索引、类型化线性代数框架，旨在提高算法效率并支持函数式编程和并行计算。通过将矩阵和高阶张量（最多四指标）分别表示为1-态射和2-态射，该方法将线性代数元素形式化为范畴中的态射，并推广到幺半半加性范畴和2-范畴。研究还详细展示了在特定2-范畴（2Vec）中的操作和向量化。", "keywords": "张量微积分, 2-范畴, 线性代数, 形式化, 半加性范畴", "comments": "本文的创新之处在于利用2-范畴理论为张量微积分提供了一个无索引、类型化的形式化框架。这种方法有望简化高阶张量的处理，提高计算效率，特别是在函数式编程和并行计算环境中具有重要意义。将线性代数元素提升到范畴论的高度，为理论计算机科学和数值线性代数之间架起了一座桥梁。"}}
{"id": "2507.23017", "title": "A Smoothing Newton Method for Rank-one Matrix Recovery", "authors": ["Tyler Maunu", "Gabriel Abreu"], "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.23017v1", "summary": "We consider the phase retrieval problem, which involves recovering a rank-one\npositive semidefinite matrix from rank-one measurements. A recently proposed\nalgorithm based on Bures-Wasserstein gradient descent (BWGD) exhibits\nsuperlinear convergence, but it is unstable, and existing theory can only prove\nlocal linear convergence for higher rank matrix recovery. We resolve this gap\nby revealing that BWGD implements Newton's method with a nonsmooth and\nnonconvex objective. We develop a smoothing framework that regularizes the\nobjective, enabling a stable method with rigorous superlinear convergence\nguarantees. Experiments on synthetic data demonstrate this superior stability\nwhile maintaining fast convergence.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.23017v1", "cate": "stat.ML", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "一种用于秩一矩阵恢复的平滑牛顿法", "tldr": "本文提出了一种平滑牛顿法，用于解决秩一矩阵恢复中的相位恢复问题，解决了现有Bures-Wasserstein梯度下降法的不稳定性问题，并提供了超线性收敛的理论保证。", "motivation": "现有的基于Bures-Wasserstein梯度下降（BWGD）的算法在秩一矩阵恢复（相位恢复问题）中表现出超线性收敛，但其不稳定，且现有理论仅能证明高秩矩阵恢复的局部线性收敛。本文旨在弥补这一理论与实践之间的差距。", "method": "本文通过揭示BWGD实际上实现了对一个非光滑非凸目标的牛顿法，从而解决了现有方法的不足。在此基础上，开发了一个平滑框架来正则化目标函数，从而实现了一种稳定的方法，并提供了严格的超线性收敛保证。", "result": "在合成数据上的实验表明，本文提出的方法在保持快速收敛的同时，表现出卓越的稳定性。", "conclusion": "本文提出了一种平滑牛顿法，有效解决了秩一矩阵恢复中现有BWGD方法的不稳定性问题，并提供了严格的超线性收敛理论保证，实验也验证了其优越的稳定性。", "translation": "我们考虑相位恢复问题，该问题涉及从秩一测量中恢复一个秩一正半定矩阵。最近提出的一种基于Bures-Wasserstein梯度下降（BWGD）的算法表现出超线性收敛，但它不稳定，并且现有理论只能证明高秩矩阵恢复的局部线性收敛。我们通过揭示BWGD实现了对一个非光滑非凸目标的牛顿法来弥补这一差距。我们开发了一个平滑框架来正则化目标函数，从而实现了一种具有严格超线性收敛保证的稳定方法。在合成数据上的实验表明，这种方法在保持快速收敛的同时，表现出卓越的稳定性。", "summary": "本文针对秩一矩阵恢复中的相位恢复问题，提出了一种平滑牛顿法。该方法通过正则化一个非光滑非凸目标函数，解决了现有Bures-Wasserstein梯度下降（BWGD）算法的不稳定性问题，并提供了严格的超线性收敛理论保证。实验结果验证了该方法在保持快速收敛的同时，具有更优的稳定性。", "keywords": "相位恢复, 秩一矩阵恢复, 平滑牛顿法, Bures-Wasserstein梯度下降, 超线性收敛", "comments": "本文通过将BWGD解释为牛顿法，并引入平滑框架来解决其不稳定性，提供了一种新颖且理论上更严谨的秩一矩阵恢复方法。其创新之处在于将非光滑优化问题转化为可通过平滑处理的稳定算法，并提供了超线性收敛的理论保证，这对于相位恢复等实际应用具有重要意义。"}}
{"id": "2507.23450", "title": "The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization", "authors": ["Dilshanie Prasikala", "Joonas Lahtinen", "Alexandra Koulouri", "Sampsa Pursiainen"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23450v1", "summary": "EEG Source localization is a critical tool in neuroscience, with applications\nranging from epilepsy diagnosis to cognitive research. It involves solving an\nill-posed inverse problem that lacks a unique solution unless constrained by\nprior knowledge. The Bayesian framework enables the incorporation of such\nknowledge, typically encoded through prior models. Various algorithms have been\nproposed for source localization, and they differ significantly in how prior\nknowledge is incorporated. Some approaches rely on anatomical or functional\nconstraints, while others use statistical distributions or sampling-based\ntechniques. In this landscape, the Standardized Kalman Filter (SKF) represents\na dynamic Bayesian approach that integrates temporal modeling with a Gaussian\nprior structure. It addresses the depth bias, a common limitation in source\nlocalization, through a post-hoc standardization step that equalizes\nsensitivity across cortical depths and makes deep activity detection feasible.\n  This study focuses on the development and optimization of Gaussian prior\nmodels within the SKF framework for simultaneous cortical and sub-cortical\nactivity detection. Synthetic data similar to the P20 / N20 component of the\nsomatosensory evoked potentials (SEP) was used to identify effective prior\nparameter configurations for reconstructing both deep and superficial sources\nunder different noise levels. We also investigated the role of RTS smoothing in\nenhancing source separability. Our results indicate that raising the\nstandardization exponent to 1.25, along with smoothing, significantly improves\ndepth localization accuracy at low noise levels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23450v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于标准化卡尔曼滤波的脑电图源定位中先验参数的影响", "tldr": "本研究在标准化卡尔曼滤波（SKF）框架内优化高斯先验模型，用于脑电图源定位，发现将标准化指数提高到1.25并结合RTS平滑能显著提高深度定位精度，尤其是在低噪声水平下，有助于同时检测深层和浅层活动。", "motivation": "脑电图（EEG）源定位是一个病态逆问题，需要先验知识来获得唯一解。标准化卡尔曼滤波（SKF）是一种动态贝叶斯方法，结合高斯先验结构并能解决深度偏差。本研究旨在SKF框架内开发和优化高斯先验模型，以实现皮层和皮层下活动的同步检测。", "method": "研究使用类似于体感诱发电位（SEP）P20/N20成分的合成数据，在不同噪声水平下，识别重建深部和浅表源的有效先验参数配置。同时，还调查了RTS平滑在增强源可分离性方面的作用。", "result": "结果表明，将标准化指数提高到1.25，并结合RTS平滑处理，在低噪声水平下显著提高了深度定位精度。", "conclusion": "通过优化先验参数（特别是标准化指数）并在SKF框架中采用RTS平滑，可以增强脑电图源定位，尤其是在低噪声水平下对深部源的定位精度。", "translation": "脑电图（EEG）源定位是神经科学中的一个关键工具，其应用范围从癫痫诊断到认知研究。它涉及解决一个病态逆问题，除非受到先验知识的约束，否则无法获得唯一解。贝叶斯框架允许纳入此类知识，通常通过先验模型进行编码。已经提出了各种源定位算法，它们在先验知识的整合方式上存在显著差异。一些方法依赖于解剖学或功能性约束，而另一些则使用统计分布或基于采样的方法。在此背景下，标准化卡尔曼滤波（SKF）代表了一种动态贝叶斯方法，它将时间建模与高斯先验结构相结合。它通过事后标准化步骤解决了源定位中常见的深度偏差问题，该步骤均衡了皮层深度的敏感性，并使深部活动检测成为可能。\n本研究侧重于在SKF框架内开发和优化高斯先验模型，以同时检测皮层和皮层下活动。使用类似于体感诱发电位（SEP）的P20 / N20成分的合成数据，以识别在不同噪声水平下重建深部和浅表源的有效先验参数配置。我们还研究了RTS平滑在增强源可分离性方面的作用。我们的结果表明，将标准化指数提高到1.25，并结合平滑处理，在低噪声水平下显著提高了深度定位精度。", "summary": "本论文研究了在标准化卡尔曼滤波（SKF）框架内优化高斯先验模型，以实现脑电图源定位中皮层和皮层下活动的同步检测。研究利用合成的体感诱发电位数据，发现将标准化指数提高到1.25并应用RTS平滑能显著提高深度定位精度，尤其是在低噪声水平下，有效重建深部和浅表源并解决深度偏差问题。", "keywords": "脑电图源定位, 标准化卡尔曼滤波, 先验参数, 深度偏差, RTS平滑", "comments": "这篇论文通过优化SKF框架中的先验参数，解决了脑电图源定位中一个重要挑战——深度偏差问题。通过使用合成数据系统评估参数配置是一种有效的方法。研究发现特定的标准化指数和平滑处理能够提高深部源的定位精度，这对于提升脑电图在临床和研究中的实用性具有重要价值。"}}
{"id": "2503.19480", "title": "GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers", "authors": ["Shijie Ma", "Yuying Ge", "Teng Wang", "Yuxin Guo", "Yixiao Ge", "Ying Shan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Project released at: this https URL", "url": "http://arxiv.org/abs/2503.19480v3", "summary": "The synergy between generative and discriminative models receives growing\nattention. While discriminative Contrastive Language-Image Pre-Training (CLIP)\nexcels in high-level semantics, it struggles with perceiving fine-grained\nvisual details. Generally, to enhance representations, generative models take\nCLIP's visual features as conditions for reconstruction. However, the\nunderlying principle remains underexplored. In this work, we empirically found\nthat visually perfect generations are not always optimal for representation\nenhancement. The essence lies in effectively extracting fine-grained knowledge\nfrom generative models while mitigating irrelevant information. To explore\ncritical factors, we delve into three aspects: (1) Conditioning mechanisms: We\nfound that even a small number of local tokens can drastically reduce the\ndifficulty of reconstruction, leading to collapsed training. We thus conclude\nthat utilizing only global visual tokens as conditions is the most effective\nstrategy. (2) Denoising configurations: We observed that end-to-end training\nintroduces extraneous information. To address this, we propose a two-stage\ntraining strategy to prioritize learning useful visual knowledge. Additionally,\nwe demonstrate that lightweight denoisers can yield remarkable improvements.\n(3) Generation paradigms: We explore both continuous and discrete denoisers\nwith desirable outcomes, validating the versatility of our method. Through our\nin-depth explorations, we have finally arrived at an effective method, namely\nGenHancer, which consistently outperforms prior arts on the MMVP-VLM benchmark,\ne.g., 6.0% on OpenAICLIP. The enhanced CLIP can be further plugged into\nmultimodal large language models for better vision-centric performance. All the\nmodels and codes are made publicly available.", "comment": "ICCV 2025. Project released at:\n  https://mashijie1028.github.io/GenHancer/", "pdf_url": "http://arxiv.org/pdf/2503.19480v3", "cate": "cs.CV", "date": "2025-03-25", "updated": "2025-07-31", "AI": {"title_translation": "GenHancer：不完美的生成模型是强大的以视觉为中心的增强器", "tldr": "GenHancer提出了一种有效的方法，利用生成模型增强判别式模型的视觉表示，发现不完美的生成反而能更好地提取细粒度知识，并在MMVP-VLM基准上超越现有技术。", "motivation": "判别式模型（如CLIP）在高级语义方面表现出色，但在感知细粒度视觉细节方面存在不足。当前通常利用生成模型以CLIP的视觉特征为条件进行重建以增强表示，但其潜在原理尚未得到充分探索。本文旨在探索如何有效从生成模型中提取细粒度知识并减轻无关信息，以增强表示。", "method": "本文提出了GenHancer方法，通过深入探索三个关键方面：1) 条件机制：发现仅使用全局视觉tokens作为条件是最有效的策略，以避免重建难度大幅降低和训练崩溃。2) 去噪配置：提出两阶段训练策略以优先学习有用的视觉知识，并证明轻量级去噪器能显著改进，以解决端到端训练引入的无关信息问题。3) 生成范式：探索了连续和离散去噪器，并取得了理想结果，验证了方法的通用性。", "result": "GenHancer在MMVP-VLM基准上始终优于现有技术，例如在OpenAICLIP上提升了6.0%。增强后的CLIP可以进一步集成到多模态大型语言模型中，以获得更好的以视觉为中心的性能。", "conclusion": "本文通过深入探索，提出了一种名为GenHancer的有效方法，证明了不完美的生成模型可以作为强大的视觉中心增强器，能够有效从生成模型中提取细粒度知识并增强判别式模型的视觉表示。", "translation": "生成模型和判别模型之间的协同作用受到越来越多的关注。虽然判别式对比语言-图像预训练（CLIP）在高级语义方面表现出色，但它在感知细粒度视觉细节方面却很吃力。通常，为了增强表示，生成模型将CLIP的视觉特征作为重建的条件。然而，其潜在原理仍未得到充分探索。在这项工作中，我们凭经验发现视觉上完美的生成并不总是对表示增强最佳。其本质在于有效提取生成模型中的细粒度知识，同时减轻不相关信息。为了探索关键因素，我们深入研究了三个方面：(1) 条件机制：我们发现即使少量局部tokens也能大大降低重建难度，导致训练崩溃。因此，我们得出结论，仅利用全局视觉tokens作为条件是最有效的策略。(2) 去噪配置：我们观察到端到端训练引入了额外信息。为了解决这个问题，我们提出了一种两阶段训练策略，以优先学习有用的视觉知识。此外，我们证明了轻量级去噪器可以产生显著的改进。(3) 生成范式：我们探索了连续和离散去噪器，并取得了理想的结果，验证了我们方法的通用性。通过我们的深入探索，我们最终得到了一种有效的方法，即GenHancer，它在MMVP-VLM基准上始终优于现有技术，例如在OpenAICLIP上提升了6.0%。增强后的CLIP可以进一步插入到多模态大型语言模型中，以实现更好的以视觉为中心的性能。所有模型和代码均已公开提供。", "summary": "本研究提出GenHancer，一种利用生成模型增强判别式模型视觉表示的新方法。与传统观念相反，研究发现视觉上不完美的生成对表示增强更有效，关键在于有效提取细粒度知识并减少无关信息。论文深入探讨了条件机制、去噪配置和生成范式，并提出了对应的优化策略，例如仅使用全局视觉tokens作为条件和采用两阶段训练。实验证明，GenHancer在MMVP-VLM基准上显著超越了现有技术，提升了CLIP等模型的视觉中心性能。", "keywords": "生成模型, 视觉增强, CLIP, 细粒度知识, GenHancer", "comments": "本文的创新点在于挑战了“完美生成等同于最佳表示增强”的传统观念，提出不完美的生成模型也能有效增强视觉表示，并深入分析了其内在机制。GenHancer的设计考虑了细粒度知识提取和无关信息缓解，通过对条件机制、去噪配置和生成范式的系统探索，提供了一套实用的增强策略。其在MMVP-VLM基准上的显著性能提升，以及将增强后的模型应用于多模态大语言模型的潜力，都显示了其重要性。该研究为生成模型在表示学习中的应用开辟了新视角。"}}
{"id": "2507.23336", "title": "DSBC : Data Science task Benchmarking with Context engineering", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2507.23336v1", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2507.23336v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DSBC：数据科学任务基准测试与上下文工程", "tldr": "本文提出了一个名为DSBC的综合基准测试，用于评估数据科学代理中大型语言模型的性能，考虑了真实世界的使用场景和多种评估维度，并揭示了不同模型和方法间的性能差异。", "motivation": "尽管数据科学代理得到了快速采用，但目前仍缺乏系统性的基准测试来评估这些代理的效能和局限性。", "method": "本文引入了一个根据真实世界用户交互构建的综合基准测试。评估了三种大型语言模型（Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini），采用三种方法（零样本上下文工程、多步上下文工程和SmolAgent）。基准测试评估了八种数据科学任务类别的性能，并探讨了模型对常见提示问题（如数据泄露和模糊指令）的敏感性，以及温度参数对结果的影响。", "result": "研究结果揭示了所评估模型和方法之间显著的性能差异，并突出了影响实际部署的关键因素。", "conclusion": "本文介绍的基准数据集和评估框架旨在为未来研究更健壮、更有效的数据科学代理提供基础。", "translation": "大型语言模型（LLMs）的最新进展显著影响了数据科学工作流程，催生了旨在自动化分析任务的专用数据科学代理。尽管这些代理被迅速采纳，但系统性地评估其效能和局限性的基准测试仍然稀缺。在本文中，我们引入了一个综合基准测试，该测试通过观察我们商业应用程序的使用情况，专门设计以反映用户与数据科学代理的真实世界交互。我们评估了三种大型语言模型：Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini，采用三种方法：零样本上下文工程、多步上下文工程和SmolAgent。我们的基准测试评估了八种不同数据科学任务类别的性能，此外还探讨了模型对常见提示问题（如数据泄露和轻微模糊指令）的敏感性。我们进一步研究了温度参数对每个模型和方法的整体和特定任务结果的影响。我们的研究结果揭示了所评估模型和方法之间显著的性能差异，突出了影响实际部署的关键因素。本文介绍的基准数据集和评估框架旨在为未来研究更健壮、更有效的数据科学代理提供基础。", "summary": "本文提出了DSBC，一个针对数据科学代理的综合基准测试，旨在解决当前缺乏系统性评估的问题。该基准测试基于真实世界用户交互数据构建，评估了Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三种大型语言模型在零样本、多步上下文工程和SmolAgent三种方法下的表现。测试涵盖八类数据科学任务，并考察了模型对提示问题和温度参数的敏感性。研究发现不同模型和方法存在显著性能差异，为未来数据科学代理的研究提供了基础。", "keywords": "数据科学代理, 大型语言模型, 基准测试, 上下文工程, 性能评估", "comments": "本文的创新之处在于其基准测试是基于真实世界的用户交互数据构建的，这使其更具实用性和代表性。它填补了数据科学代理系统性评估的空白，并识别了影响实际部署的关键因素。这项工作为开发更健壮和有效的数据科学代理奠定了重要基础。"}}
{"id": "2505.20980", "title": "Identifying Super Spreaders in Multilayer Networks", "authors": ["Michał Czuba", "Mateusz Stolarski", "Adam Piróg", "Piotr Bielak", "Piotr Bródka"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20980v2", "summary": "Identifying super-spreaders can be framed as a subtask of the influence\nmaximisation problem. It seeks to pinpoint agents within a network that, if\nselected as single diffusion seeds, disseminate information most effectively.\nMultilayer networks, a specific class of heterogeneous graphs, can capture\ndiverse types of interactions (e.g., physical-virtual or professional-social),\nand thus offer a more accurate representation of complex relational structures.\nIn this work, we introduce a novel approach to identifying super-spreaders in\nsuch networks by leveraging graph neural networks. To this end, we construct a\ndataset by simulating information diffusion across hundreds of networks - to\nthe best of our knowledge, the first of its kind tailored specifically to\nmultilayer networks. We further formulate the task as a variation of the\nranking prediction problem based on a four-dimensional vector that quantifies\neach agent's spreading potential: (i) the number of activations; (ii) the\nduration of the diffusion process; (iii) the peak number of activations; and\n(iv) the simulation step at which this peak occurs. Our model,\nTopSpreadersNetwork, comprises a relationship-agnostic encoder and a custom\naggregation layer. This design enables generalisation to previously unseen data\nand adapts to varying graph sizes. In an extensive evaluation, we compare our\nmodel against classic centrality-based heuristics and competitive deep learning\nmethods. The results, obtained across a broad spectrum of real-world and\nsynthetic multilayer networks, demonstrate that TopSpreadersNetwork achieves\nsuperior performance in identifying high-impact nodes, while also offering\nimproved interpretability through its structured output.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20980v2", "cate": "cs.SI", "date": "2025-05-27", "updated": "2025-07-31", "AI": {"title_translation": "多层网络中超级传播者的识别", "tldr": "本文提出了一种基于图神经网络（GNN）的模型TopSpreadersNetwork，用于识别多层网络中的超级传播者，并在实验中表现出优于现有方法的性能。", "motivation": "识别超级传播者是影响力最大化问题的一个子任务。多层网络能够捕捉不同类型的交互，更准确地表示复杂关系结构，因此在此类网络中识别超级传播者至关重要。", "method": "本文引入了一种利用图神经网络识别多层网络中超级传播者的新方法。为此，通过模拟数百个网络中的信息扩散来构建了一个数据集，这是第一个专门针对多层网络的数据集。该任务被公式化为基于一个四维向量的排名预测问题，该向量量化了每个代理的传播潜力：(i)激活数量；(ii)扩散过程的持续时间；(iii)激活的峰值数量；以及(iv)达到该峰值的模拟步骤。所提出的模型TopSpreadersNetwork包含一个与关系无关的编码器和一个自定义聚合层，使其能够泛化到未见过的数据并适应不同大小的图。", "result": "在广泛的评估中，TopSpreadersNetwork模型在各种真实世界和合成多层网络上与经典的基于中心性的启发式方法和有竞争力的深度学习方法进行比较，结果表明该模型在识别高影响力节点方面取得了卓越的性能，并通过其结构化输出提供了更好的可解释性。", "conclusion": "本文成功开发并验证了基于图神经网络的模型TopSpreadersNetwork，用于识别多层网络中的超级传播者，该模型在性能和可解释性方面均表现出色。", "translation": "识别超级传播者可以被视为影响力最大化问题的一个子任务。它旨在找出网络中如果被选作单个扩散种子，能最有效传播信息的代理。多层网络，作为一类特定的异构图，可以捕捉多种类型的交互（例如，物理-虚拟或专业-社交），从而更准确地表示复杂的关系结构。在这项工作中，我们引入了一种新颖的方法，通过利用图神经网络来识别此类网络中的超级传播者。为此，我们通过模拟数百个网络中的信息扩散来构建了一个数据集——据我们所知，这是第一个专门针对多层网络的数据集。我们进一步将该任务公式化为基于一个四维向量的排名预测问题，该向量量化了每个代理的传播潜力：(i)激活数量；(ii)扩散过程的持续时间；(iii)激活的峰值数量；以及(iv)达到该峰值的模拟步骤。我们的模型TopSpreadersNetwork包含一个与关系无关的编码器和一个自定义聚合层。这种设计使其能够泛化到以前未见过的数据并适应不同大小的图。在广泛的评估中，我们将我们的模型与经典的基于中心性的启发式方法和有竞争力的深度学习方法进行了比较。在各种真实世界和合成多层网络上获得的结果表明，TopSpreadersNetwork在识别高影响力节点方面取得了卓越的性能，同时通过其结构化输出提供了更好的可解释性。", "summary": "本文针对多层网络中超级传播者的识别问题，提出了一种新颖的图神经网络模型TopSpreadersNetwork。该研究将任务定义为基于四维传播潜力向量的排名预测问题，并构建了首个专门用于多层网络信息扩散模拟的数据集。通过关系无关编码器和自定义聚合层，模型展现了良好的泛化能力和对不同图大小的适应性。实验结果表明，TopSpreadersNetwork在识别高影响力节点方面优于现有基线方法，并提供了增强的可解释性。", "keywords": "超级传播者, 多层网络, 图神经网络, 影响力最大化, 信息扩散", "comments": "本文的创新之处在于首次将图神经网络应用于多层网络中的超级传播者识别任务，并为此构建了专门的数据集。模型的通用性和可解释性是其重要优势，有助于推动复杂网络信息扩散研究的进展。"}}
{"id": "2307.02968", "title": "A Simple $(1-ε)$-Approximation Semi-Streaming Algorithm for Maximum (Weighted) Matching", "authors": ["Sepehr Assadi"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      25 pages. This is the TheoretiCS journal version", "url": "http://arxiv.org/abs/2307.02968v4", "summary": "We present a simple semi-streaming algorithm for $(1-\\epsilon)$-approximation\nof bipartite matching in $O(\\log{\\!(n)}/\\epsilon)$ passes. This matches the\nperformance of state-of-the-art \"$\\epsilon$-efficient\" algorithms -- the ones\nwith much better dependence on $\\epsilon$ albeit with some mild dependence on\n$n$ -- while being considerably simpler.\n  The algorithm relies on a direct application of the multiplicative weight\nupdate method with a self-contained primal-dual analysis that can be of\nindependent interest. To show case this, we use the same ideas, alongside\nstandard tools from matching theory, to present an equally simple\nsemi-streaming algorithm for $(1-\\epsilon)$-approximation of weighted matchings\nin general (not necessarily bipartite) graphs, again in\n$O(\\log{\\!(n)}/\\epsilon)$ passes.", "comment": "25 pages. This is the TheoretiCS journal version", "pdf_url": "http://arxiv.org/pdf/2307.02968v4", "cate": "cs.DS", "date": "2023-07-06", "updated": "2025-07-31", "AI": {"title_translation": "一个简单的最大（加权）匹配的$(1-\\epsilon)$-近似半流算法", "tldr": "提出了一种简单的半流算法，用于双边图和一般图的最大（加权）匹配的$(1-\\epsilon)$-近似，其性能与最先进的算法相当，但更简单。", "motivation": "现有最先进的\"$\\epsilon$-高效\"算法虽然在$\\epsilon$方面依赖性更好，但在$n$方面有轻微依赖性，且可能更复杂。本文旨在提供一个同样高效但显著更简单的算法。", "method": "该算法基于乘法权重更新方法的直接应用，并结合了独立的原始-对偶分析。相同的思想也用于结合匹配理论的标准工具，以处理一般图的加权匹配。", "result": "1. 提出了一个简单的半流算法，用于双边图匹配的$(1-\\epsilon)$-近似，在$O(\\log{\\!(n)}/\\epsilon)$次遍历中完成。2. 该算法的性能与最先进的\"$\\epsilon$-高效\"算法相当，但显著更简单。3. 利用相同的方法，提出了一个同样简单的半流算法，用于一般图的加权匹配的$(1-\\epsilon)$-近似，也在$O(\\log{\\!(n)}/\\epsilon)$次遍历中完成。4. 算法所依赖的原始-对偶分析具有独立的潜在价值。", "conclusion": "本文成功开发了一种简单且高效的半流算法，用于最大（加权）匹配问题，其性能与现有复杂算法相当，并展示了乘法权重更新和原始-对偶分析在近似算法设计中的潜力。", "translation": "我们提出了一种简单的半流算法，用于双边匹配的$(1-\\epsilon)$-近似，其遍历次数为$O(\\log{\\!(n)}/\\epsilon)$。这与最先进的“$\\epsilon$-高效”算法的性能相匹配——那些对$\\epsilon$依赖性更好但对$n$有轻微依赖性的算法——同时显著更简单。该算法依赖于乘法权重更新方法的直接应用，并结合了独立的原始-对偶分析，这可能具有独立的兴趣。为了展示这一点，我们使用相同的思想，并结合匹配理论的标准工具，提出了一个同样简单的半流算法，用于一般（不一定是双边）图中的加权匹配的$(1-\\epsilon)$-近似，同样在$O(\\log{\\!(n)}/\\epsilon)$次遍历中完成。", "summary": "本文提出了一种新颖且简化的半流算法，用于解决最大（加权）匹配问题，包括双边图和一般图。该算法基于乘法权重更新方法和原始-对偶分析，能够在$O(\\log{\\!(n)}/\\epsilon)$次遍历中实现$(1-\\epsilon)$-近似。其主要优势在于与现有最先进的“$\\epsilon$-高效”算法相比，在保持相同性能的同时，显著降低了算法复杂度。", "keywords": "半流算法, 加权匹配, 近似算法, 乘法权重更新, 原始-对偶分析", "comments": "这篇论文的创新点在于提供了一个显著更简单的算法，却能达到与现有复杂算法相同的性能，这对于实际应用和理论研究都具有重要意义。它展示了乘法权重更新和原始-对偶分析在设计高效近似算法方面的强大潜力，并且其分析方法本身也可能对其他问题有所启发。"}}
{"id": "2507.23411", "title": "Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories", "authors": ["Lemar Abdi", "Francisco Caetano", "Amaan Valiuddin", "Christiaan Viviers", "Hamdi Joudeh", "Fons van der Sommen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at Uncertainty for Safe Utilization of Machine Learning in Medical Imaging, MICCAI 2025", "url": "http://arxiv.org/abs/2507.23411v1", "summary": "In medical imaging, unsupervised out-of-distribution (OOD) detection offers\nan attractive approach for identifying pathological cases with extremely low\nincidence rates. In contrast to supervised methods, OOD-based approaches\nfunction without labels and are inherently robust to data imbalances. Current\ngenerative approaches often rely on likelihood estimation or reconstruction\nerror, but these methods can be computationally expensive, unreliable, and\nrequire retraining if the inlier data changes. These limitations hinder their\nability to distinguish nominal from anomalous inputs efficiently, consistently,\nand robustly. We propose a reconstruction-free OOD detection method that\nleverages the forward diffusion trajectories of a Stein score-based denoising\ndiffusion model (SBDDM). By capturing trajectory curvature via the estimated\nStein score, our approach enables accurate anomaly scoring with only five\ndiffusion steps. A single SBDDM pre-trained on a large, semantically aligned\nmedical dataset generalizes effectively across multiple Near-OOD and Far-OOD\nbenchmarks, achieving state-of-the-art performance while drastically reducing\ncomputational cost during inference. Compared to existing methods, SBDDM\nachieves a relative improvement of up to 10.43% and 18.10% for Near-OOD and\nFar-OOD detection, making it a practical building block for real-time, reliable\ncomputer-aided diagnosis.", "comment": "Accepted at Uncertainty for Safe Utilization of Machine Learning in\n  Medical Imaging, MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.23411v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "通过扩散轨迹在医学图像中进行分布外检测", "tldr": "本文提出了一种基于Stein分数去噪扩散模型前向扩散轨迹的无重建OOD检测方法，该方法计算成本低，性能卓越，适用于医学影像。", "motivation": "在医学影像中，识别病理病例（发病率极低）是一个挑战。当前的生成式OOD检测方法（如基于似然估计或重建误差的方法）计算成本高、不可靠，并且在内部分布数据改变时需要重新训练，这限制了它们有效、一致和鲁棒地区分正常和异常输入的能力。", "method": "本文提出了一种无重建的OOD检测方法，该方法利用基于Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹。通过估计的Stein分数捕捉轨迹曲率，该方法仅需五个扩散步骤即可实现准确的异常评分。", "result": "在多个近OOD和远OOD基准测试中，一个在大型、语义对齐的医学数据集上预训练的SBDDM模型表现出良好的泛化能力，实现了最先进的性能，并显著降低了推理时的计算成本。与现有方法相比，SBDDM在近OOD和远OOD检测方面分别实现了高达10.43%和18.10%的相对改进。", "conclusion": "所提出的SBDDM方法通过利用扩散轨迹实现了高效、鲁棒且高性能的医学影像OOD检测，使其成为实时、可靠计算机辅助诊断的实用组成部分。", "translation": "在医学成像中，无监督的分布外（OOD）检测为识别发病率极低的病理病例提供了一种有吸引力的方法。与监督方法不同，基于OOD的方法无需标签即可运行，并且天生对数据不平衡具有鲁棒性。当前的生成方法通常依赖于似然估计或重建误差，但这些方法计算成本高、不可靠，并且如果内部分布数据发生变化，则需要重新训练。这些限制阻碍了它们有效、一致和鲁棒地区分正常和异常输入的能力。我们提出了一种无重建的OOD检测方法，该方法利用了基于Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹。通过估计的Stein分数捕捉轨迹曲率，我们的方法仅需五个扩散步骤即可实现准确的异常评分。在大型、语义对齐的医学数据集上预训练的单个SBDDM模型在多个近OOD和远OOD基准测试中有效泛化，实现了最先进的性能，同时大幅降低了推理时的计算成本。与现有方法相比，SBDDM在近OOD和远OOD检测方面分别实现了高达10.43%和18.10%的相对改进，使其成为实时、可靠计算机辅助诊断的实用构建模块。", "summary": "本文提出了一种新颖的无重建分布外（OOD）检测方法，专为医学影像设计。该方法利用Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹，通过捕捉轨迹曲率来实现高效且准确的异常评分，仅需五个扩散步骤。与现有方法相比，该模型在计算成本大幅降低的同时，在近OOD和远OOD检测上均取得了最先进的性能，使其成为实时计算机辅助诊断的实用工具。", "keywords": "分布外检测, 医学影像, 扩散模型, Stein分数, 异常检测", "comments": "该论文的创新点在于提出了利用扩散模型前向轨迹进行OOD检测，避免了重建过程，从而显著降低了计算成本并提高了效率。其在医学影像领域的应用潜力巨大，尤其是在处理罕见疾病数据时，为实时、可靠的计算机辅助诊断提供了新的思路和强大的工具。"}}
{"id": "2406.14313", "title": "Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability", "authors": ["Riya Sawhney", "Samrat Yadav", "Indrajit Bhattacharya", "Mausam"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.14313v3", "summary": "Real-world applications of KBQA require models to handle unanswerable\nquestions with a limited volume of in-domain labeled training data. We propose\nthe novel task of few-shot transfer for KBQA with unanswerable questions and\ncontribute two new datasets for performance evaluation. We present FUn-FuSIC -\na novel solution for our task that extends FuSIC KBQA, the state-of-the-art\nfew-shot transfer model for answerable-only KBQA. We first note that\nFuSIC-KBQA's iterative repair makes a strong assumption that all questions are\nunanswerable. As a remedy, we propose Feedback for Unanswerability (FUn), which\nuses iterative repair using feedback from a suite of strong and weak verifiers,\nand an adaptation of self consistency for unanswerabilty to better assess the\nanswerability of a question. Our experiments show that FUn-FuSIC significantly\noutperforms suitable adaptations of multiple LLM based and supervised SoTA\nmodels on our task, while establishing a new SoTA for answerable few-shot\ntransfer as well.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.14313v3", "cate": "cs.CL", "date": "2024-06-20", "updated": "2025-07-31", "AI": {"title_translation": "使用弱验证器进行迭代修复以解决知识库问答中不可回答性问题的少样本迁移", "tldr": "本文提出了FUn-FuSIC，一个通过迭代修复和弱验证器来处理知识库问答中不可回答性问题的少样本迁移模型，并在新数据集上显著优于现有模型。", "motivation": "现实世界的知识库问答（KBQA）应用需要模型能够处理不可回答的问题，并且只有有限的领域内标记训练数据。当前最先进的少样本迁移模型（FuSIC KBQA）假设所有问题都是可回答的，这在处理不可回答问题时存在局限性。", "method": "本文提出了FUn-FuSIC，它扩展了FuSIC KBQA。FUn-FuSIC通过引入“不可回答性反馈”（FUn）来解决FuSIC KBQA的局限性，该反馈利用来自一组强弱验证器的反馈进行迭代修复，并采用自我一致性适应性来更好地评估问题的可回答性。同时，还贡献了两个新的数据集用于性能评估。", "result": "实验表明，FUn-FuSIC在所提出的任务上显著优于多种基于LLM和监督的现有最先进模型。此外，FUn-FuSIC还在可回答的少样本迁移任务上建立了新的最先进水平。", "conclusion": "FUn-FuSIC通过引入迭代修复与弱验证器和自我一致性适应性，有效解决了知识库问答中不可回答性问题的少样本迁移挑战，并显著提升了相关任务的性能。", "translation": "真实世界的知识库问答（KBQA）应用要求模型能够处理不可回答的问题，并且只有有限的领域内标记训练数据。我们提出了知识库问答中不可回答性问题的少样本迁移这一新任务，并贡献了两个新的数据集用于性能评估。我们提出了FUn-FuSIC——一个针对我们任务的新颖解决方案，它扩展了当前最先进的仅处理可回答问题的少样本迁移模型FuSIC KBQA。我们首先注意到FuSIC-KBQA的迭代修复做出了所有问题都是可回答的强假设。作为补救措施，我们提出了不可回答性反馈（FUn），它利用来自一组强弱验证器的反馈进行迭代修复，并对不可回答性进行自我一致性适应，以更好地评估问题的可回答性。我们的实验表明，FUn-FuSIC在我们的任务上显著优于多个基于LLM和监督的现有最先进模型的适当改编版本，同时也在可回答的少样本迁移方面建立了新的最先进水平。", "summary": "本文针对知识库问答（KBQA）中处理不可回答问题的少样本迁移任务，提出了FUn-FuSIC模型。该模型扩展了现有最先进的FuSIC KBQA，通过结合来自强弱验证器的反馈进行迭代修复，并适应自我一致性来评估问题的可回答性。研究还贡献了两个新数据集。实验结果表明，FUn-FuSIC在处理不可回答性问题的少样本迁移任务上表现出色，并同时提升了可回答少样本迁移的性能。", "keywords": "知识库问答, 少样本迁移, 不可回答性, 迭代修复, 弱验证器", "comments": "该论文的创新点在于首次提出了知识库问答中不可回答性问题的少样本迁移任务，并为此贡献了新的数据集。提出的FUn-FuSIC模型通过引入弱验证器和自我一致性适应性，有效地解决了现有模型无法处理不可回答性问题的局限性，并显著提升了性能，具有重要的实际应用价值。"}}
{"id": "2502.15215", "title": "Tensor Product Neural Networks for Functional ANOVA Model", "authors": ["Seokhun Park", "Insung Kong", "Yongchan Choi", "Chanmoo Park", "Yongdai Kim"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      45 pages", "url": "http://arxiv.org/abs/2502.15215v5", "summary": "Interpretability for machine learning models is becoming more and more\nimportant as machine learning models become more complex. The functional ANOVA\nmodel, which decomposes a high-dimensional function into a sum of lower\ndimensional functions (commonly referred to as components), is one of the most\npopular tools for interpretable AI, and recently, various neural networks have\nbeen developed for estimating each component in the functional ANOVA model.\nHowever, such neural networks are highly unstable when estimating each\ncomponent since the components themselves are not uniquely defined. That is,\nthere are multiple functional ANOVA decompositions for a given function. In\nthis paper, we propose a novel neural network which guarantees a unique\nfunctional ANOVA decomposition and thus is able to estimate each component\nstably and accurately. We call our proposed neural network ANOVA Tensor Product\nNeural Network (ANOVA-TPNN) since it is motivated by the tensor product basis\nexpansion. Theoretically, we prove that ANOVA-TPNN can approximate any smooth\nfunction well. Empirically, we show that ANOVA-TPNN provide much more stable\nestimation of each component and thus much more stable interpretation when\ntraining data and initial values of the model parameters vary than existing\nneural networks do.", "comment": "45 pages", "pdf_url": "http://arxiv.org/pdf/2502.15215v5", "cate": "stat.ML", "date": "2025-02-21", "updated": "2025-07-31", "AI": {"title_translation": "张量积神经网络用于函数ANOVA模型", "tldr": "本文提出了一种新型张量积神经网络（ANOVA-TPNN），解决了现有神经网络在函数ANOVA模型中分量估计不稳定和不唯一的问题，从而提供更稳定和准确的可解释性。", "motivation": "随着机器学习模型日益复杂，其可解释性变得越来越重要。函数ANOVA模型是可解释AI的流行工具，但现有用于估计其分量的神经网络在估计时高度不稳定，因为分量本身并非唯一确定。", "method": "本文提出了一种新颖的神经网络——ANOVA张量积神经网络（ANOVA-TPNN），它受张量积基展开启发，能够保证唯一的函数ANOVA分解，从而稳定且准确地估计每个分量。", "result": "理论上，ANOVA-TPNN能够很好地近似任何平滑函数。经验上，ANOVA-TPNN在训练数据和模型参数初始值变化时，比现有神经网络提供更稳定的分量估计和更稳定的解释。", "conclusion": "ANOVA-TPNN通过保证唯一的函数ANOVA分解，显著提高了基于神经网络的函数ANOVA模型在分量估计和解释方面的稳定性和准确性。", "translation": "随着机器学习模型变得越来越复杂，其可解释性变得越来越重要。函数ANOVA模型将高维函数分解为低维函数的和（通常称为分量），是可解释AI最流行的工具之一，最近，各种神经网络已被开发用于估计函数ANOVA模型中的每个分量。然而，当估计每个分量时，此类神经网络高度不稳定，因为分量本身没有唯一定义。也就是说，对于给定函数存在多个函数ANOVA分解。在本文中，我们提出了一种新型神经网络，它保证了唯一的函数ANOVA分解，从而能够稳定准确地估计每个分量。我们将我们提出的神经网络称为ANOVA张量积神经网络（ANOVA-TPNN），因为它受张量积基展开的启发。理论上，我们证明了ANOVA-TPNN可以很好地近似任何平滑函数。经验上，我们表明，与现有神经网络相比，当训练数据和模型参数初始值变化时，ANOVA-TPNN提供更稳定的分量估计，从而提供更稳定的解释。", "summary": "本文提出了一种新颖的ANOVA张量积神经网络（ANOVA-TPNN），旨在解决现有神经网络在函数ANOVA模型中估计分量时存在的非唯一性和不稳定性问题。ANOVA-TPNN利用张量积基展开，能够保证唯一的函数ANOVA分解，从而实现对各分量的稳定和准确估计。理论分析证明其能良好近似平滑函数，实验结果也显示其在数据和参数初始值变化时，比现有方法提供更稳定的分量估计和模型解释。", "keywords": "函数ANOVA模型, 神经网络, 可解释性AI, 张量积, 分解稳定性", "comments": "该论文解决了基于神经网络的函数ANOVA模型中分量估计不稳定和不唯一的核心问题，通过引入张量积神经网络提供了一个理论上可证明且经验上更稳定的解决方案。这对于提高复杂机器学习模型的可解释性具有重要意义，尤其是在需要稳定和可信赖解释的领域。"}}
{"id": "2507.23197", "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23197v1", "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23197v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "解感知与全局ReLU选择：部分MILP在DNN验证中反击", "tldr": "本文提出了一种名为SAS的新型解感知ReLU评分方法，结合部分MILP和混合MILP框架，显著提高了深度神经网络验证的效率和准确性，尤其是在处理复杂实例时。", "motivation": "为了处理复杂的深度神经网络验证实例，本文重新审视了分而治之的方法，通过分解复杂性，用多个小的部分MILP调用代替少数复杂的BaB调用。", "method": "本文提出了一种新颖的“解感知”ReLU评分（SAS）方法来选择重要的ReLU变量，并调整BaB-SR和BaB-FSB分支函数作为“全局”ReLU评分（GS）函数。这些方法在混合MILP框架中实现，首先使用α,β-CROWN进行快速求解，然后进行部分MILP处理。", "result": "SAS在选择需要用二元变量打开的变量集方面更有效率，与之前的方法相比，SAS将二元变量的数量减少了约6倍，同时保持了相同的精度水平。在混合MILP中实现后，未决实例的数量减少了高达40%，降至低水平（8-15%），即使对于具有200万参数的CNN，也能保持合理的运行时长（平均每个实例46秒-417秒）。", "conclusion": "通过引入解感知ReLU选择和结合部分MILP与混合MILP，本文提出了一种非常准确且高效的深度神经网络验证器，显著提高了处理复杂实例的能力。", "translation": "为了处理复杂的实例，我们重新审视了一种分而治之的方法来分解复杂性：我们依赖于许多小的“部分”MILP调用，而不是少数复杂的BaB调用。关键步骤是选择极少数但非常重要的ReLU进行处理，使用（昂贵的）二元变量。以前的尝试在这方面是次优的。为了选择这些重要的ReLU变量，我们提出了一种新颖的“解感知”ReLU评分（SAS），并调整BaB-SR和BaB-FSB分支函数作为“全局”ReLU评分（GS）函数。我们对它们进行了理论和实验比较，并且SAS在选择一组变量以使用二元变量打开方面更有效。与之前的尝试相比，SAS将二元变量的数量减少了大约6倍，同时保持了相同的准确性水平。在“混合MILP”中实现，首先使用α,β-CROWN进行短时间超时求解较简单的实例，然后进行部分MILP，产生了一个非常准确但高效的验证器，将未决实例的数量减少了高达40%至低水平（8-15%），同时保持了合理的运行时长（平均每个实例46秒-417秒），即使对于具有200万参数的相当大的CNN也是如此。", "summary": "本文提出了一种新的深度神经网络验证方法，通过引入“解感知”ReLU评分（SAS）来改进部分混合整数线性规划（MILP）中的ReLU变量选择。该方法克服了以往方法的次优性，显著减少了二元变量的使用量（约6倍），同时保持了验证精度。结合α,β-CROWN和部分MILP的“混合MILP”框架，能够高效准确地验证大型CNN，将未决实例的数量降低了高达40%。", "keywords": "DNN验证, 部分MILP, ReLU选择, 解感知评分, 混合MILP", "comments": "本文的创新点在于提出了“解感知”ReLU评分（SAS）机制，该机制能够更有效地识别和处理关键的ReLU变量，从而优化了MILP求解器的性能。通过将复杂的验证问题分解为多个小的部分MILP调用，并结合混合MILP策略，该方法在处理大型DNN方面展现出卓越的效率和准确性。其重要性体现在为DNN验证提供了一种更实用、更可扩展的解决方案，有助于提升AI系统的安全性和可靠性。"}}
{"id": "2402.03158", "title": "Optimal and Near-Optimal Adaptive Vector Quantization", "authors": ["Ran Ben-Basat", "Yaniv Ben-Itzhak", "Michael Mitzenmacher", "Shay Vargaftik"], "categories": ["cs.LG", "cs.DS", "cs.IT", "cs.NI", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.03158v2", "summary": "Quantization is a fundamental optimization for many machine-learning use\ncases, including compressing gradients, model weights and activations, and\ndatasets. The most accurate form of quantization is \\emph{adaptive}, where the\nerror is minimized with respect to a given input, rather than optimizing for\nthe worst case. However, optimal adaptive quantization methods are considered\ninfeasible in terms of both their runtime and memory requirements.\n  We revisit the Adaptive Vector Quantization (AVQ) problem and present\nalgorithms that find optimal solutions with asymptotically improved time and\nspace complexity. We also present an even faster near-optimal algorithm for\nlarge inputs. Our experiments show our algorithms may open the door to using\nAVQ more extensively in a variety of machine learning applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.03158v2", "cate": "cs.LG", "date": "2024-02-05", "updated": "2025-07-31", "AI": {"title_translation": "最优和近最优自适应向量量化", "tldr": "本文提出了在运行时和内存方面均有渐近改进的自适应向量量化（AVQ）算法，包括最优算法和针对大型输入的近最优算法，使其在机器学习应用中更具可行性。", "motivation": "量化是机器学习中一项重要的优化技术，其中自适应量化是最准确的形式。然而，现有的最优自适应量化方法在运行时和内存方面被认为是不可行的。", "method": "本文重新审视了自适应向量量化（AVQ）问题，并提出了能够找到最优解的算法，这些算法在时间复杂度和空间复杂度方面都有渐近改进。此外，本文还提出了一种针对大型输入速度更快的近最优算法。", "result": "实验结果表明，本文提出的算法有望使AVQ在各种机器学习应用中得到更广泛的使用。", "conclusion": "本文提出的最优和近最优自适应向量量化算法，解决了传统方法在计算资源上的限制，使得AVQ在机器学习领域能够得到更广泛的应用。", "translation": "量化是许多机器学习用例中的一项基本优化，包括压缩梯度、模型权重和激活以及数据集。最准确的量化形式是自适应的，即相对于给定输入最小化误差，而不是针对最坏情况进行优化。然而，最优自适应量化方法在运行时和内存要求方面被认为是不可行的。\n我们重新审视了自适应向量量化（AVQ）问题，并提出了能够找到最优解的算法，这些算法在时间复杂度和空间复杂度方面都有渐近改进。我们还为大型输入提供了一种更快的近最优算法。我们的实验表明，我们的算法可能为在各种机器学习应用中更广泛地使用AVQ打开大门。", "summary": "本文针对机器学习中自适应向量量化（AVQ）的计算开销问题，提出了新的算法。这些算法在渐近时间复杂度和空间复杂度上有所改进，能够找到最优解。同时，还提出了一种针对大型输入的高效近最优算法。实验证明，这些算法能显著提升AVQ在机器学习应用中的可用性。", "keywords": "自适应向量量化, 量化, 机器学习, 优化", "comments": "该论文解决了自适应向量量化（AVQ）在实际应用中因高计算和内存成本而面临的挑战。通过提出渐近改进的最优算法和更快的近最优算法，为AVQ在机器学习领域的广泛应用铺平了道路，具有重要的实践意义和创新性。"}}
{"id": "2507.22838", "title": "Modelling and simulation of electro-mechanically coupled dielectric elastomers and myocardial tissue using smoothed finite element methods", "authors": ["Tan Tran", "Denisa Martonova", "Sigrid Leyendecker"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22838v2", "summary": "Computational modelling offers a cost-effective and time-efficient\nalternative to experimental studies in biomedical engineering. In cardiac\nelectro-mechanics, finite element method (FEM)-based simulations provide\nvaluable insights into diseased tissue behaviour and the development of\nassistive systems such as di-electric elastomer actuators. However, the use of\nautomatically generated tetrahedral meshes, commonly applied due to geometric\ncomplexity, often leads to numerical issues including overly stiff responses\nand volume locking, particularly in incompressible materials. Smoothed finite\nelement methods (S-FEMs) offer a promising alternative by softening the\nstiffness matrix through gradient smoothing over defined smoothing domains.\nThis work extends S-FEM formulations to electro-mechanically coupled problems\nand compares their performance against standard linear FEM. We implement and\nevaluate four approaches in the Abaqus environment via custom user elements:\nstandard linear FEM, face-based S-FEM (FS-FEM), node-based S-FEM (NS-FEM), and\nthe hybrid face/node-based S-FEM (FSNS-FEM). Two benchmark problems are\nstudied: the electrically induced contraction of a compressible dielectric\nelastomer and an incompressible, orthotropic myocardial tissue sample.\nReference solutions are obtained using a mesh consisting of higher-order\nelements. Our results demonstrate that FSNS-FEM provides the best balance\nbetween accuracy and computational efficiency, closely matching reference data.\nNS-FEM produces softer results, which leads to an overestimation of the true\ndeformation. FS-FEM and standard FEM consistently exhibit overly stiff\nbehaviour, with pronounced volume locking in the myocardial case. These\nfindings support the potential of S-FEMs, in particular FSNS-FEM, for accurate\nsimulation of coupled electro-mechanical behaviour in complex biomedical\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22838v2", "cate": "cs.CE", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "使用平滑有限元方法对电-机械耦合介电弹性体和心肌组织进行建模和仿真", "tldr": "本研究将平滑有限元方法（S-FEM）扩展到电-机械耦合问题，并发现混合面/节点S-FEM（FSNS-FEM）在模拟介电弹性体和心肌组织的耦合行为时，在准确性和计算效率之间提供了最佳平衡，解决了标准有限元法的刚性响应和体积锁定问题。", "motivation": "在生物医学工程中，计算建模是实验研究的一种成本效益高且省时的替代方案。然而，在心肌电-力学领域，常用的自动生成四面体网格的有限元方法（FEM）在处理几何复杂性和不可压缩材料时，常导致数值问题，如响应过硬和体积锁定。平滑有限元方法（S-FEMs）通过梯度平滑来软化刚度矩阵，提供了一种有前景的替代方案。", "method": "本研究将S-FEM公式扩展到电-机械耦合问题，并将其性能与标准线性FEM进行比较。在Abaqus环境中，通过自定义用户单元实现了四种方法：标准线性FEM、基于面的S-FEM（FS-FEM）、基于节点的S-FEM（NS-FEM）以及混合面/节点S-FEM（FSNS-FEM）。研究了两个基准问题：可压缩介电弹性体的电致收缩和不可压缩、正交各向异性心肌组织样本。参考解通过更高阶单元组成的网格获得。", "result": "结果表明，FSNS-FEM在准确性和计算效率之间提供了最佳平衡，与参考数据非常匹配。NS-FEM产生了较软的结果，导致对真实变形的过高估计。FS-FEM和标准FEM始终表现出过硬的行为，在心肌情况下存在明显的体积锁定。", "conclusion": "这些发现支持了S-FEMs，特别是FSNS-FEM，在复杂生物医学应用中准确模拟耦合电-机械行为的潜力。", "translation": "计算建模为生物医学工程中的实验研究提供了一种经济高效且省时的替代方案。在心脏电-力学中，基于有限元方法（FEM）的模拟为病变组织行为和辅助系统（如介电弹性体执行器）的开发提供了宝贵的见解。然而，由于几何复杂性而常使用的自动生成四面体网格，往往会导致数值问题，包括响应过硬和体积锁定，尤其是在不可压缩材料中。平滑有限元方法（S-FEMs）通过在定义的平滑域上进行梯度平滑来软化刚度矩阵，提供了一种有前景的替代方案。本研究将S-FEM公式扩展到电-机械耦合问题，并将其性能与标准线性FEM进行比较。我们在Abaqus环境中通过自定义用户单元实现了并评估了四种方法：标准线性FEM、基于面的S-FEM（FS-FEM）、基于节点的S-FEM（NS-FEM）以及混合面/节点S-FEM（FSNS-FEM）。研究了两个基准问题：可压缩介电弹性体的电致收缩和不可压缩、正交各向异性心肌组织样本。参考解通过更高阶单元组成的网格获得。我们的结果表明，FSNS-FEM在准确性和计算效率之间提供了最佳平衡，与参考数据非常匹配。NS-FEM产生了较软的结果，导致对真实变形的过高估计。FS-FEM和标准FEM始终表现出过硬的行为，在心肌情况下存在明显的体积锁定。这些发现支持了S-FEMs，特别是FSNS-FEM，在复杂生物医学应用中准确模拟耦合电-机械行为的潜力。", "summary": "本研究旨在解决标准有限元方法（FEM）在模拟电-机械耦合介电弹性体和心肌组织时遇到的数值问题（如刚性响应和体积锁定）。通过将平滑有限元方法（S-FEM）扩展到此类耦合问题，并比较了四种S-FEM变体与标准FEM的性能。实验结果表明，混合面/节点S-FEM（FSNS-FEM）在准确性和计算效率上表现最佳，能有效解决传统FEM的局限性，为复杂生物医学应用的精确模拟提供了新的潜力。", "keywords": "平滑有限元方法, 介电弹性体, 心肌组织, 电-机械耦合, 计算建模", "comments": "该论文的创新之处在于将S-FEMs扩展到电-机械耦合问题，并系统地比较了不同S-FEM变体与标准FEM的性能。其重要性在于为生物医学领域中复杂材料（特别是不可压缩材料）的计算模拟提供了更准确、更高效的工具，有助于克服传统FEM的数值稳定性问题，例如体积锁定。这对于心脏电-力学等领域的研究具有实际应用价值。"}}
{"id": "2412.04502", "title": "Physics-informed Gaussian Processes as Linear Model Predictive Controller", "authors": ["Jörn Tebbe", "Andreas Besginow", "Markus Lange-Hegermann"], "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Accepted at L4DC 2025", "url": "http://arxiv.org/abs/2412.04502v2", "summary": "We introduce a novel algorithm for controlling linear time invariant systems\nin a tracking problem. The controller is based on a Gaussian Process (GP) whose\nrealizations satisfy a system of linear ordinary differential equations with\nconstant coefficients. Control inputs for tracking are determined by\nconditioning the prior GP on the setpoints, i.e. control as inference. The\nresulting Model Predictive Control scheme incorporates pointwise soft\nconstraints by introducing virtual setpoints to the posterior Gaussian process.\nWe show theoretically that our controller satisfies open-loop stability for the\noptimal control problem by leveraging general results from Bayesian inference\nand demonstrate this result in a numerical example.", "comment": "Accepted at L4DC 2025", "pdf_url": "http://arxiv.org/pdf/2412.04502v2", "cate": "math.OC", "date": "2024-12-02", "updated": "2025-07-31", "AI": {"title_translation": "物理信息高斯过程作为线性模型预测控制器", "tldr": "提出了一种基于物理信息高斯过程的新型线性模型预测控制器，用于线性时不变系统的跟踪问题，并通过贝叶斯推断证明了其开环稳定性。", "motivation": "在跟踪问题中控制线性时不变系统。", "method": "引入了一种基于高斯过程（GP）的新型算法，其实现满足线性常微分方程组。控制输入通过对先验GP进行设定点条件化来确定（控制即推断）。模型预测控制方案通过引入虚拟设定点到后验高斯过程来整合点式软约束。", "result": "理论上证明了该控制器满足最优控制问题的开环稳定性，并在一个数值例子中验证了这一结果。", "conclusion": "该基于物理信息高斯过程的控制器能够实现线性时不变系统的稳定跟踪控制。", "translation": "我们引入了一种用于控制跟踪问题中线性时不变系统的新型算法。该控制器基于高斯过程（GP），其实现满足具有常系数的线性常微分方程组。通过对先验GP进行设定点条件化来确定跟踪的控制输入，即控制作为推断。由此产生的模型预测控制方案通过向后验高斯过程引入虚拟设定点来整合点式软约束。我们理论上表明，通过利用贝叶斯推断的一般结果，我们的控制器满足最优控制问题的开环稳定性，并在一个数值例子中演示了这一结果。", "summary": "本文提出了一种新颖的线性模型预测控制器，用于解决线性时不变系统的跟踪问题。该控制器基于高斯过程，其特性由线性常微分方程组定义。通过将控制视为推断，即对先验高斯过程进行设定点条件化来生成控制输入。此外，该方案通过引入虚拟设定点来处理点式软约束。作者理论证明了该控制器在最优控制问题中的开环稳定性，并通过数值示例进行了验证。", "keywords": "高斯过程, 模型预测控制, 线性时不变系统, 跟踪问题, 贝叶斯推断", "comments": "这篇论文的创新点在于将物理信息（通过线性常微分方程组）融入高斯过程，并将其应用于模型预测控制框架，特别是通过“控制即推断”的方法。这种方法为处理系统约束和保证稳定性提供了一种新颖的视角。"}}
{"id": "2412.00123", "title": "Electricity Price Prediction Using Multi-Kernel Gaussian Process Regression Combined with Kernel-Based Support Vector Regression", "authors": ["Abhinav Das", "Stephan Schlüter", "Lorenz Schneider"], "categories": ["cs.LG", "math.PR", "62M10(Primary), 62M20, 60G15, 62J05(Secondary)"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.00123v4", "summary": "This paper presents a new hybrid model for predicting German electricity\nprices. The algorithm is based on a combination of Gaussian Process Regression\n(GPR) and Support Vector Regression (SVR). Although GPR is a competent model\nfor learning stochastic patterns within data and for interpolation, its\nperformance for out-of-sample data is not very promising. By choosing a\nsuitable data-dependent covariance function, we can enhance the performance of\nGPR for the German hourly power prices being tested. However, since the\nout-of-sample prediction is dependent on the training data, the prediction is\nvulnerable to noise and outliers. To overcome this issue, a separate prediction\nis calculated using SVR, which applies margin-based optimization. This method\nis advantageous when dealing with non-linear processes and outliers, since only\ncertain necessary points (support vectors) in the training data are responsible\nfor regression. The individual predictions are then linearly combined using\nuniform weights. When tested on historic German power prices, this approach\noutperforms the publicly available benchmarks, namely the LASSO estimated\nautoregressive regression model, deep neural network provided in the recent\nresearch by [1].", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.00123v4", "cate": "cs.LG", "date": "2024-11-28", "updated": "2025-07-31", "AI": {"title_translation": "基于多核高斯过程回归结合核支持向量回归的电价预测", "tldr": "本文提出了一种结合高斯过程回归（GPR）和支持向量回归（SVR）的新型混合模型，用于预测德国电价，该模型在历史数据上表现优于现有基准。", "motivation": "高斯过程回归（GPR）在样本外数据预测方面表现不佳，且易受噪声和异常值影响。为了克服GPR的这些局限性，并利用支持向量回归（SVR）在处理非线性过程和异常值方面的优势，提出了一个混合模型。", "method": "本文提出了一种结合高斯过程回归（GPR）和支持向量回归（SVR）的混合模型。首先，GPR通过选择合适的数据依赖协方差函数来增强其在小时电价数据上的性能。其次，使用SVR计算一个独立的预测，SVR利用基于边际的优化来处理非线性过程和异常值。最后，将GPR和SVR的个体预测结果使用统一权重进行线性组合。", "result": "该混合方法在历史德国电价数据上进行测试，结果表明其性能优于公开可用的基准模型，包括LASSO估计的自回归回归模型和近期研究中提出的深度神经网络。", "conclusion": "结合高斯过程回归（GPR）和支持向量回归（SVR）的混合模型能够有效提高电价预测的准确性和鲁棒性，尤其是在处理噪声和异常值方面，并且在实际应用中优于现有主流方法。", "translation": "本文提出了一种预测德国电价的新型混合模型。该算法基于高斯过程回归（GPR）和支持向量回归（SVR）的组合。尽管GPR是学习数据内随机模式和进行插值的有效模型，但其在样本外数据上的表现并不十分理想。通过选择合适的数据依赖协方差函数，我们可以提高GPR在所测试的德国小时电价上的性能。然而，由于样本外预测依赖于训练数据，预测容易受到噪声和异常值的影响。为了克服这个问题，使用SVR计算了一个单独的预测，SVR应用基于边际的优化。这种方法在处理非线性过程和异常值时具有优势，因为训练数据中只有某些必要的点（支持向量）负责回归。然后，使用统一权重线性组合各个预测结果。当在历史德国电价上进行测试时，这种方法优于公开可用的基准，即LASSO估计的自回归回归模型和[1]中近期研究提供的深度神经网络。", "summary": "本文提出一种用于德国电价预测的新型混合模型，结合了高斯过程回归（GPR）和支持向量回归（SVR）。该模型旨在克服GPR在样本外预测中对噪声和异常值的敏感性，通过利用SVR处理非线性和异常值的优势。模型将GPR和SVR的预测结果进行线性组合。实验结果表明，该混合模型在历史德国电价数据上的表现优于LASSO自回归模型和深度神经网络等现有基准。", "keywords": "电价预测, 高斯过程回归, 支持向量回归, 混合模型, 德国电价", "comments": "该论文的创新之处在于提出了一种混合模型，结合了GPR和SVR的优点，有效弥补了GPR在样本外预测中对噪声和异常值敏感的弱点，同时利用了SVR处理非线性和异常值的优势。这种结合方式提高了电价预测的准确性和鲁棒性，并在实际数据上超越了现有基准，具有重要的应用价值。"}}
{"id": "2503.22351", "title": "One Look is Enough: Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation on High-Resolution Images", "authors": ["Byeongjun Kwon", "Munchurl Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (camera-ready version). [Project page]( this https URL )", "url": "http://arxiv.org/abs/2503.22351v3", "summary": "Zero-shot depth estimation (DE) models exhibit strong generalization\nperformance as they are trained on large-scale datasets. However, existing\nmodels struggle with high-resolution images due to the discrepancy in image\nresolutions of training (with smaller resolutions) and inference (for high\nresolutions). Processing them at full resolution leads to decreased estimation\naccuracy on depth with tremendous memory consumption, while downsampling to the\ntraining resolution results in blurred edges in the estimated depth images.\nPrevailing high-resolution depth estimation methods adopt a patch-based\napproach, which introduces depth discontinuity issues when reassembling the\nestimated depth patches, resulting in test-time inefficiency. Additionally, to\nobtain fine-grained depth details, these methods rely on synthetic datasets due\nto the real-world sparse ground truth depth, leading to poor generalizability.\nTo tackle these limitations, we propose Patch Refine Once (PRO), an efficient\nand generalizable tile-based framework. Our PRO consists of two key components:\n(i) Grouped Patch Consistency Training that enhances test-time efficiency while\nmitigating the depth discontinuity problem by jointly processing four\noverlapping patches and enforcing a consistency loss on their overlapping\nregions within a single backpropagation step, and (ii) Bias Free Masking that\nprevents the DE models from overfitting to dataset-specific biases, enabling\nbetter generalization to real-world datasets even after training on synthetic\ndata. Zero-shot evaluations on Booster, ETH3D, Middlebury 2014, and NuScenes\ndemonstrate that our PRO can be seamlessly integrated into existing depth\nestimation models.", "comment": "ICCV 2025 (camera-ready version). [Project\n  page](https://kaist-viclab.github.io/One-Look-is-Enough_site)", "pdf_url": "http://arxiv.org/pdf/2503.22351v3", "cate": "cs.CV", "date": "2025-03-28", "updated": "2025-07-31", "AI": {"title_translation": "一眼足矣：高分辨率图像零样本单目深度估计的无缝分块细化", "tldr": "本文提出PRO框架，通过分组补丁一致性训练和无偏掩码，解决了零样本深度估计模型在高分辨率图像上存在的分辨率不匹配、深度不连续和泛化能力差的问题，实现了高效且可泛化的深度估计。", "motivation": "现有的零样本深度估计模型在处理高分辨率图像时表现不佳，原因在于训练和推理图像分辨率存在差异。直接处理全分辨率图像会导致估计精度下降和内存消耗巨大，而下采样则会造成估计深度图像边缘模糊。此外，主流的基于补丁的方法在重新组合深度补丁时会引入深度不连续问题，且测试效率低下。这些方法还依赖合成数据集，导致对真实世界数据的泛化能力差。", "method": "本文提出了Patch Refine Once (PRO)框架，这是一个高效且可泛化的基于瓦片的框架。PRO包含两个关键组件：(i) 分组补丁一致性训练，通过在一次反向传播中联合处理四个重叠补丁并在其重叠区域强制执行一致性损失，从而提高测试效率并减轻深度不连续问题；(ii) 无偏掩码，防止深度估计模型过度拟合数据集特定的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。", "result": "在Booster、ETH3D、Middlebury 2014和NuScenes数据集上的零样本评估表明，PRO可以无缝集成到现有的深度估计模型中。", "conclusion": "PRO框架通过其创新的分组补丁一致性训练和无偏掩码组件，成功解决了现有零样本单目深度估计模型在高分辨率图像处理中面临的效率、深度不连续性和泛化能力问题，使其能够无缝集成并有效提升现有模型的性能。", "translation": "零样本深度估计（DE）模型由于在大规模数据集上训练而表现出强大的泛化性能。然而，现有模型在处理高分辨率图像时遇到困难，原因在于训练（分辨率较低）和推理（分辨率较高）图像分辨率存在差异。以全分辨率处理会导致深度估计精度下降并消耗巨大的内存，而下采样到训练分辨率则会导致估计深度图像中边缘模糊。流行的基于补丁的高分辨率深度估计方法在重新组合估计的深度补丁时引入了深度不连续问题，导致测试时效率低下。此外，为了获得细粒度的深度细节，这些方法由于真实世界稀疏的地面实况深度而依赖于合成数据集，导致泛化能力差。为了解决这些限制，我们提出了Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。我们的PRO包含两个关键组件：(i) 分组补丁一致性训练，通过联合处理四个重叠补丁并在单个反向传播步骤中在其重叠区域强制执行一致性损失，从而提高测试效率并减轻深度不连续问题；(ii) 无偏掩码，防止DE模型过度拟合数据集特定的偏差，即使在合成数据上训练后也能更好地泛化到真实世界数据集。在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，我们的PRO可以无缝集成到现有的深度估计模型中。", "summary": "本文针对零样本单目深度估计模型在高分辨率图像处理中遇到的挑战，提出了Patch Refine Once (PRO) 框架。该框架包含分组补丁一致性训练，以提高效率并解决深度不连续性；以及无偏掩码，以增强模型对真实世界数据的泛化能力。实验证明PRO可无缝集成到现有模型中，有效提升了高分辨率图像的深度估计性能。", "keywords": "零样本深度估计, 高分辨率图像, 补丁细化, 深度不连续, 泛化能力", "comments": "该论文提出了一种新颖且实用的方法来解决零样本深度估计在高分辨率图像上的关键挑战。其创新点在于结合了效率和泛化能力，特别是通过“分组补丁一致性训练”解决了传统基于补丁方法的深度不连续性问题，并通过“无偏掩码”提升了模型在真实世界数据上的泛化性，即使在合成数据上训练。这对于实际应用中高分辨率深度感知至关重要，具有良好的通用性和集成潜力。"}}
{"id": "2507.23270", "title": "Simulation-based planning of Motion Sequences for Automated Procedure Optimization in Multi-Robot Assembly Cells", "authors": ["Loris Schneider", "Marc Ungen", "Elias Huber", "Jan-Felix Klein"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23270v1", "summary": "Reconfigurable multi-robot cells offer a promising approach to meet\nfluctuating assembly demands. However, the recurrent planning of their\nconfigurations introduces new challenges, particularly in generating optimized,\ncoordinated multi-robot motion sequences that minimize the assembly duration.\nThis work presents a simulation-based method for generating such optimized\nsequences. The approach separates assembly steps into task-related core\noperations and connecting traverse operations. While core operations are\nconstrained and predetermined, traverse operations offer substantial\noptimization potential. Scheduling the core operations is formulated as an\noptimization problem, requiring feasible traverse operations to be integrated\nusing a decomposition-based motion planning strategy. Several solution\ntechniques are explored, including a sampling heuristic, tree-based search and\ngradient-free optimization. For motion planning, a decomposition method is\nproposed that identifies specific areas in the schedule, which can be solved\nindependently with modified centralized path planning algorithms. The proposed\nmethod generates efficient and collision-free multi-robot assembly procedures\nthat outperform a baseline relying on decentralized, robot-individual motion\nplanning. Its effectiveness is demonstrated through simulation experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23270v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多机器人装配单元中自动化程序优化的基于仿真的运动序列规划", "tldr": "本文提出了一种基于仿真的方法，用于优化多机器人装配单元中的运动序列，通过将任务分解为核心操作和遍历操作，并利用分解式运动规划策略，实现了高效、无碰撞的装配过程，且优于分散式规划。", "motivation": "在可重构多机器人单元中，为满足波动的装配需求，需要反复规划其配置。然而，生成优化、协调的多机器人运动序列以最小化装配持续时间是一个挑战，这是本研究的动机。", "method": "本文提出了一种基于仿真的方法来生成优化的多机器人运动序列。该方法将装配步骤分为受约束的核心操作和具有优化潜力的遍历操作。核心操作的调度被公式化为优化问题，并通过基于分解的运动规划策略整合遍历操作。研究了包括采样启发式、基于树的搜索和无梯度优化在内的多种求解技术。对于运动规划，提出了一种分解方法，可以识别调度中可独立求解的特定区域，并使用修改后的集中式路径规划算法进行求解。", "result": "所提出的方法能够生成高效且无碰撞的多机器人装配程序。通过仿真实验证明，其性能优于依赖于分散式、机器人个体运动规划的基线方法。", "conclusion": "本研究提出的基于仿真的方法能够有效地优化多机器人装配单元中的运动序列，生成高效且无碰撞的装配过程，并且在性能上超越了传统的去中心化规划方法。", "translation": "可重构多机器人单元提供了一种有前景的方法来满足波动的装配需求。然而，其配置的反复规划带来了新的挑战，特别是在生成优化、协调的多机器人运动序列以最小化装配持续时间方面。这项工作提出了一种基于仿真的方法，用于生成此类优化序列。该方法将装配步骤分为与任务相关的核心操作和连接的遍历操作。核心操作是受约束且预定的，而遍历操作提供了实质性的优化潜力。核心操作的调度被表述为一个优化问题，需要使用基于分解的运动规划策略来整合可行的遍历操作。探索了几种解决方案技术，包括采样启发式、基于树的搜索和无梯度优化。对于运动规划，提出了一种分解方法，该方法识别调度中的特定区域，这些区域可以使用修改后的集中式路径规划算法独立求解。所提出的方法生成了高效、无碰撞的多机器人装配程序，其性能优于依赖于分散式、机器人个体运动规划的基线方法。通过仿真实验证明了其有效性。", "summary": "本文提出了一种基于仿真的方法，旨在优化多机器人装配单元中的运动序列，以最小化装配持续时间。该方法将装配任务分解为受约束的核心操作和具有显著优化潜力的遍历操作。它将核心操作的调度表述为一个优化问题，并创新性地采用了一种基于分解的运动规划策略来整合遍历操作，同时探索了多种求解技术。仿真实验结果表明，该方法能够生成高效、无碰撞的多机器人装配程序，并且性能显著优于传统的去中心化机器人个体运动规划基线方法。", "keywords": "多机器人, 运动规划, 装配, 优化, 仿真", "comments": "该论文通过将多机器人运动规划分解为核心操作和遍历操作，并特别关注遍历运动的优化潜力，提供了一种创新的方法。其采用的基于分解的运动规划策略，结合修改后的集中式路径规划算法来独立解决调度中的特定区域，是其关键贡献。该方法优于去中心化方法的表现，突显了其在提高可重构多机器人装配效率方面的实际重要性。"}}
{"id": "2507.23434", "title": "Future Illiteracies -- Architectural Epistemology and Artificial Intelligence", "authors": ["Mustapha El Moussaoui"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      14 pages, 7 figures. MDPI - Architecture 2025", "url": "http://arxiv.org/abs/2507.23434v1", "summary": "In the age of artificial intelligence, architectural practice faces a paradox\nof immense potential and creeping standardization. As humans are increasingly\nrelying on AI-generated outputs, architecture risks becoming a spectacle of\nrepetition- a shuffling of data that neither truly innovates nor progresses\nvertically in creative depth. This paper explores the critical role of data in\nAI systems, scrutinizing the training datasets that form the basis of AI's\ngenerative capabilities and the implications for architectural practice. We\nargue that when architects approach AI passively, without actively engaging\ntheir own creative and critical faculties, they risk becoming passive users\nlocked in an endless loop of horizontal expansion without meaningful vertical\ngrowth. By examining the epistemology of architecture in the AI age, this paper\ncalls for a paradigm where AI serves as a tool for vertical and horizontal\ngrowth, contingent on human creativity and agency. Only by mastering this\ndynamic relationship can architects avoid the trap of passive, standardized\ndesign and unlock the true potential of AI.", "comment": "14 pages, 7 figures. MDPI - Architecture 2025", "pdf_url": "http://arxiv.org/pdf/2507.23434v1", "cate": "cs.CY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "未来文盲——建筑认识论与人工智能", "tldr": "本文探讨了人工智能时代建筑实践中数据和人类能动性的关键作用，强调建筑师需主动利用AI促进深度和广度发展，避免标准化陷阱。", "motivation": "在人工智能时代，建筑实践面临着巨大潜力与日益标准化的悖论。人类日益依赖AI生成结果，导致建筑可能陷入重复，缺乏创新和创意深度。", "method": "本文探讨了数据在人工智能系统中的关键作用，审视了构成人工智能生成能力基础的训练数据集及其对建筑实践的影响。通过审视人工智能时代的建筑认识论，本文呼吁建立一种新的范式。", "result": "当建筑师被动地对待人工智能，不积极运用自身的创造性和批判性思维时，他们就有可能成为被动的用户，陷入无休止的水平扩张循环，而没有有意义的垂直增长。只有掌握人工智能与人类创造力之间的动态关系，才能避免被动、标准化的设计陷阱。", "conclusion": "本文呼吁建立一种范式，即人工智能作为工具，促进垂直和水平增长，这取决于人类的创造力和能动性。只有掌握这种动态关系，建筑师才能避免被动、标准化的设计陷阱，并释放人工智能的真正潜力。", "translation": "在人工智能时代，建筑实践面临着巨大潜力与日益标准化的悖论。随着人类越来越依赖人工智能生成的结果，建筑面临着沦为重复景观的风险——数据的重组既没有真正的创新，也没有在创意深度上垂直进步。本文探讨了数据在人工智能系统中的关键作用，审视了构成人工智能生成能力基础的训练数据集及其对建筑实践的影响。我们认为，当建筑师被动地对待人工智能，不积极运用自身的创造性和批判性思维时，他们就有可能成为被动的用户，陷入无休止的水平扩张循环，而没有有意义的垂直增长。通过审视人工智能时代的建筑认识论，本文呼吁建立一种范式，即人工智能作为工具，促进垂直和水平增长，这取决于人类的创造力和能动性。只有掌握这种动态关系，建筑师才能避免被动、标准化的设计陷阱，并释放人工智能的真正潜力。", "summary": "本文探讨了人工智能时代建筑实践中数据、人类创造力与AI之间复杂关系。作者指出，若建筑师被动接受AI生成结果，将面临设计标准化和缺乏创新的风险。文章强调了AI训练数据的重要性，并提出应将AI视为促进建筑深度和广度发展的工具，而非替代人类能动性的力量。核心论点在于，通过主动运用批判性思维和创造力，建筑师才能有效利用AI，避免陷入重复性设计，从而真正释放AI的潜力。", "keywords": "人工智能, 建筑实践, 数据, 认识论, 创造力", "comments": "本文的创新之处在于将AI对建筑实践的影响提升到“认识论”层面，探讨了AI时代建筑师的角色转变和知识生产方式。它强调了人类能动性和批判性思维在AI辅助设计中的核心地位，而非简单地将AI视为技术工具。其重要性在于对建筑领域未来发展路径的深刻反思，警示了过度依赖AI可能带来的“未来文盲”风险，并为建筑师指明了主动驾驭AI的方向。"}}
{"id": "2503.06981", "title": "Graph Chirp Signal and Graph Fractional Vertex-Frequency Energy Distribution", "authors": ["Manjun Cui", "Zhichao Zhang", "Wei Yao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06981v2", "summary": "Graph signal processing (GSP) has emerged as a powerful framework for\nanalyzing data on irregular domains. In recent years, many classical techniques\nin signal processing (SP) have been successfully extended to GSP. Among them,\nchirp signals play a crucial role in various SP applications. However, graph\nchirp signals have not been formally defined despite their importance. Here, we\ndefine graph chirp signals and establish a comprehensive theoretical framework\nfor their analysis. We propose the graph fractional vertex--frequency energy\ndistribution (GFED), which provides a powerful tool for processing and\nanalyzing graph chirp signals. We introduce the general fractional graph\ndistribution (GFGD), a generalized vertex--frequency distribution, and the\nreduced interference GFED, which can suppress cross-term interference and\nenhance signal clarity. Furthermore, we propose a novel method for detecting\ngraph signals through GFED domain filtering, facilitating robust detection and\nanalysis of graph chirp signals in noisy environments. Moreover, this method\ncan be applied to real-world data for denoising more effective than some\nstate-of-the-arts, further demonstrating its practical significance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06981v2", "cate": "eess.SP", "date": "2025-03-10", "updated": "2025-07-31", "AI": {"title_translation": "图形啁啾信号与图形分数顶点-频率能量分布", "tldr": "本文正式定义了图形啁啾信号，并提出了图形分数顶点-频率能量分布（GFED）及其变体，用于分析、处理和检测图形啁啾信号，并在去噪方面显示出优越性。", "motivation": "尽管啁啾信号在信号处理中至关重要，但图形啁啾信号尚未被正式定义，阻碍了其在图信号处理中的应用。", "method": "本文正式定义了图形啁啾信号，并建立了其全面的理论分析框架。提出了图形分数顶点-频率能量分布（GFED），引入了广义分数图分布（GFGD）和抑制干扰的GFED。此外，还提出了一种通过GFED域滤波检测图形信号的新方法。", "result": "GFED为处理和分析图形啁啾信号提供了强大工具。抑制干扰的GFED能有效抑制交叉项干扰，增强信号清晰度。提出的检测方法有助于在嘈杂环境中对图形啁啾信号进行鲁棒检测和分析。该方法在实际数据去噪方面比一些现有技术更有效。", "conclusion": "本文通过定义图形啁啾信号并提出创新的GFED及其变体，为图信号处理领域提供了重要的理论和实用工具，特别是在图形啁啾信号的分析、处理、检测和去噪方面展现出显著效果。", "translation": "图信号处理（GSP）已成为分析不规则域数据的一个强大框架。近年来，许多经典的信号处理（SP）技术已成功扩展到GSP。其中，啁啾信号在各种SP应用中发挥着关键作用。然而，尽管图形啁啾信号的重要性，它们尚未被正式定义。在此，我们定义了图形啁啾信号，并建立了其分析的全面理论框架。我们提出了图形分数顶点-频率能量分布（GFED），它为处理和分析图形啁啾信号提供了强大的工具。我们引入了广义分数图分布（GFGD），这是一种广义顶点-频率分布，以及减少干扰的GFED，后者可以抑制交叉项干扰并增强信号清晰度。此外，我们提出了一种通过GFED域滤波检测图形信号的新方法，有助于在嘈杂环境中对图形啁啾信号进行鲁棒检测和分析。此外，该方法可以应用于真实世界数据进行去噪，比一些最先进的技术更有效，进一步证明了其实际意义。", "summary": "本文致力于解决图信号处理中图形啁啾信号缺乏正式定义的问题。作者首次定义了图形啁啾信号，并构建了全面的理论分析框架。为有效处理和分析这类信号，文章引入了图形分数顶点-频率能量分布（GFED），以及作为其推广的广义分数图分布（GFGD）和用于抑制干扰的GFED。此外，文中还提出了一种基于GFED域滤波的图形信号检测新方法，该方法在噪声环境下能实现鲁棒检测，并且在实际数据去噪方面表现出优于现有技术的性能。", "keywords": "图形啁啾信号, 图形分数顶点-频率能量分布, 图信号处理, 广义分数图分布, 信号检测", "comments": "本文的创新之处在于首次正式定义了图形啁啾信号，并提出了GFED这一强大的分析工具。GFED及其变体（如抑制干扰的GFED）和基于GFED的检测方法，显著提升了在图信号处理中处理和分析复杂信号的能力，尤其是在去噪方面的实际应用潜力值得关注。"}}
{"id": "2507.23180", "title": "The Construction of Near-optimal Universal Coding of Integers", "authors": ["Wei Yan", "Yunghsiang S. Han"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23180v1", "summary": "Universal Coding of Integers (UCI) is suitable for discrete memoryless\nsources with unknown probability distributions and infinitely countable\nalphabet sizes. The UCI is a class of prefix codes, such that the ratio of the\naverage codeword length to $\\max\\{1, H(P)\\}$ is within a constant expansion\nfactor $K_{\\mathcal{C}}$ for any decreasing probability distribution $P$, where\n$H(P)$ is the entropy of $P$. For any UCI code $\\mathcal{C}$, define \\emph{the\nminimum expansion factor} $K_{\\mathcal{C}}^{*}$ to represent the infimum of the\nset of extension factors of $\\mathcal{C}$. Each $\\mathcal{C}$ has a unique\ncorresponding $K_{\\mathcal{C}}^{*}$, and the smaller $K_{\\mathcal{C}}^{*}$ is,\nthe better the compression performance of $\\mathcal{C}$ is. A class of UCI\n$\\mathcal{C}$ (or family $\\{\\mathcal{C}_i\\}_{i=1}^{\\infty}$) achieving the\nsmallest $K_{\\mathcal{C}}^{*}$ is defined as the \\emph{optimal UCI}. The best\nresult currently is that the range of $C_{\\mathcal{C}}^{*}$ for the optimal UCI\nis $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.5$. In this paper, we prove that there\nexists a class of near-optimal UCIs, called $\\nu$ code, to achieve\n$K_\\nu=2.0386$. This narrows the range of the minimum expansion factor for\noptimal UCI to $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.0386$. Another new class of\nUCI, called $\\Delta\\delta$ code, is specifically constructed. We show that the\n$\\Delta\\delta$ code and $\\nu$ code are currently optimal in terms of minimum\nexpansion factor. In addition, we propose a new proof that shows the minimum\nexpansion factor of the optimal UCI is lower bounded by $2$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23180v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "整数的近似最优通用编码的构建", "tldr": "论文构建了一种新的近似最优整数通用编码（$\\nu$ 码），将最优通用编码的最小扩展因子范围缩小到 $2 \\leq C_{\\mathcal{C}}^{*} \\leq 2.0386$，并证明了下界为 $2$。", "motivation": "通用整数编码（UCI）适用于未知概率分布的离散无记忆信源，目标是使平均码字长度与熵之比的扩展因子 $K_{\\mathcal{C}}$ 尽可能小。现有最优UCI的扩展因子范围是 $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.5$，需要进一步缩小这个范围以提高压缩性能。", "method": "作者构建了两种新的UCI类：$\\nu$ 码和 $\\Delta\\delta$ 码。他们证明了 $\\nu$ 码实现了 $K_\\nu=2.0386$ 的扩展因子。此外，他们提出了一个新的证明来显示最优UCI的最小扩展因子下界为 $2$。", "result": "构建了名为 $\\nu$ 码的近似最优UCI，其扩展因子 $K_\\nu=2.0386$。将最优UCI的最小扩展因子范围缩小到 $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.0386$。构建了名为 $\\Delta\\delta$ 码的另一类UCI。证明了 $\\Delta\\delta$ 码和 $\\nu$ 码在最小扩展因子方面是当前最优的。提出了一个新的证明，表明最优UCI的最小扩展因子下界为 $2$。", "conclusion": "论文通过构建新的 $\\nu$ 码和 $\\Delta\\delta$ 码，显著改进了通用整数编码的性能，将最优UCI的最小扩展因子范围缩小到更接近理论下界，并确认了下界为2。", "translation": "通用整数编码（UCI）适用于具有未知概率分布和无限可数字母表的离散无记忆信源。UCI是一类前缀码，其平均码字长度与 $\\max\\{1, H(P)\\}$ 之比在任何递减概率分布 $P$ 下都处于一个常数扩展因子 $K_{\\mathcal{C}}$ 范围内，其中 $H(P)$ 是 $P$ 的熵。对于任何UCI码 $\\mathcal{C}$，定义“最小扩展因子” $K_{\\mathcal{C}}^{*}$ 表示 $\\mathcal{C}$ 的扩展因子集合的下确界。每个 $\\mathcal{C}$ 都有一个唯一对应的 $K_{\\mathcal{C}}^{*}$，并且 $K_{\\mathcal{C}}^{*}$ 越小，$\\mathcal{C}$ 的压缩性能越好。实现最小 $K_{\\mathcal{C}}^{*}$ 的UCI类 $\\mathcal{C}$（或族 $\\{\\mathcal{C}_i\\}_{i=1}^{\\infty}$）被定义为“最优UCI”。目前最好的结果是，最优UCI的 $C_{\\mathcal{C}}^{*}$ 范围是 $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.5$。在本文中，我们证明存在一类近似最优的UCI，称为 $\\nu$ 码，其实现了 $K_\\nu=2.0386$。这使得最优UCI的最小扩展因子范围缩小到 $2\\leq C_{\\mathcal{C}}^{*}\\leq 2.0386$。另一类新的UCI，称为 $\\Delta\\delta$ 码，也得到了具体构建。我们表明 $\\Delta\\delta$ 码和 $\\nu$ 码在最小扩展因子方面是当前最优的。此外，我们提出了一个新的证明，表明最优UCI的最小扩展因子下界为 $2$。", "summary": "本文研究通用整数编码（UCI），旨在提高其压缩效率。作者构建了两种新的UCI：$\\nu$ 码和 $\\Delta\\delta$ 码。其中，$\\nu$ 码实现了 $K_\\nu=2.0386$ 的扩展因子，将最优UCI的最小扩展因子范围从 $2.5$ 缩小到 $2.0386$，显著接近理论下界 $2$。研究表明这两种新编码在最小扩展因子方面是当前最优的，并提供了最小扩展因子下界为 $2$ 的新证明。", "keywords": "通用整数编码, $\\nu$ 码, $\\Delta\\delta$ 码, 最小扩展因子, 前缀码", "comments": "论文在通用整数编码领域取得了重要进展，通过提出新的编码方案，显著缩小了最优UCI的性能范围，使其更接近理论最优值。这对于数据压缩和信息论领域具有实际意义和理论价值。"}}
{"id": "2507.23709", "title": "Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation", "authors": ["Alfie Roddan", "Chi Xu", "Serine Ajlouni", "Irini Kakaletri", "Patra Charalampaki", "Stamatia Giannarou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23709v1", "summary": "The deployment of Machine Learning models intraoperatively for tissue\ncharacterisation can assist decision making and guide safe tumour resections.\nFor image classification models, pixel attribution methods are popular to infer\nexplainability. However, overconfidence in deep learning model's predictions\ntranslates to overconfidence in pixel attribution. In this paper, we propose\nthe first approach which incorporates risk estimation into a pixel attribution\nmethod for improved image classification explainability. The proposed method\niteratively applies a classification model with a pixel attribution method to\ncreate a volume of PA maps. This volume is used for the first time, to generate\na pixel-wise distribution of PA values. We introduce a method to generate an\nenhanced PA map by estimating the expectation values of the pixel-wise\ndistributions. In addition, the coefficient of variation (CV) is used to\nestimate pixel-wise risk of this enhanced PA map. Hence, the proposed method\nnot only provides an improved PA map but also produces an estimation of risk on\nthe output PA values. Performance evaluation on probe-based Confocal Laser\nEndomicroscopy (pCLE) data and ImageNet verifies that our improved\nexplainability method outperforms the state-of-the-art.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23709v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于组织表征的降低过自信的可解释图像分类", "tldr": "本文提出了一种将风险估计纳入像素归因方法的新方法，以提高图像分类的可解释性，同时降低模型预测的过自信，并在pCLE和ImageNet数据集上表现优于现有技术。", "motivation": "在术中部署机器学习模型进行组织表征可以辅助决策并指导安全肿瘤切除。图像分类模型的像素归因方法常用于解释性，但深度学习模型的预测过自信会导致像素归因的过自信。现有方法未能充分解决过自信问题。", "method": "本文提出了一种将风险估计纳入像素归因方法的首个方法。该方法迭代地应用分类模型和像素归因方法来创建PA（像素归因）图体积。首次使用该体积生成像素级PA值分布。通过估计像素级分布的期望值来生成增强的PA图。此外，利用变异系数（CV）来估计增强PA图的像素级风险。", "result": "所提出的方法不仅提供了改进的PA图，而且还对输出PA值产生了风险估计。在基于探头的共聚焦激光内窥镜（pCLE）数据和ImageNet上的性能评估验证了改进的可解释性方法优于现有技术。", "conclusion": "本文成功地提出了一种将风险估计整合到像素归因方法中的新方法，有效提高了图像分类的可解释性并降低了过自信，并在多个数据集上取得了SOTA性能。", "translation": "在术中部署机器学习模型进行组织表征可以辅助决策并指导安全肿瘤切除。对于图像分类模型，像素归因方法是推断可解释性的常用方法。然而，深度学习模型预测的过自信会转化为像素归因的过自信。在本文中，我们提出了第一个将风险估计纳入像素归因方法以改进图像分类可解释性的方法。所提出的方法迭代地应用分类模型和像素归因方法来创建PA图体积。首次使用该体积生成像素级PA值分布。我们引入了一种通过估计像素级分布的期望值来生成增强PA图的方法。此外，变异系数（CV）用于估计此增强PA图的像素级风险。因此，所提出的方法不仅提供了改进的PA图，而且还产生了对输出PA值的风险估计。在基于探头的共聚焦激光内窥镜（pCLE）数据和ImageNet上的性能评估验证了我们改进的可解释性方法优于现有技术。", "summary": "本文提出了一种创新的方法，将风险估计整合到像素归因（PA）方法中，以提高图像分类的可解释性并减少深度学习模型中的过自信问题。该方法通过迭代生成PA图体积，并利用像素级分布的期望值创建增强的PA图，同时使用变异系数（CV）评估像素级风险。实验结果表明，该方法在pCLE和ImageNet数据集上均优于现有技术，能够提供更可靠和可解释的图像分类结果，特别适用于组织表征等关键应用。", "keywords": "可解释性AI, 图像分类, 像素归因, 风险估计, 过自信, 组织表征", "comments": "本文的创新点在于首次将风险估计引入到像素归因方法中，有效解决了深度学习模型在解释性方面存在的过自信问题。通过生成像素级风险估计，提高了模型解释的可靠性，对于医疗诊断等高风险应用具有重要意义。该方法通过迭代处理和统计分析，提供了一种新颖且有效的方式来增强图像分类的可解释性。"}}
{"id": "2505.21567", "title": "EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models", "authors": ["Feng Jiang", "Zihao Zheng", "Xiuping Cui", "Maoliang Li", "JIayu Chen", "Xiang Chen"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      There is an error in this paper, and as the author, I request retraction", "url": "http://arxiv.org/abs/2505.21567v2", "summary": "With the development of Embodied Artificial intelligence, the end-to-end\ncontrol policy such as Vision-Language-Action (VLA) model has become the\nmainstream. Existing VLA models faces expensive computing/storage cost, which\nneed to be optimized. Quantization is considered as the most effective method\nwhich can not only reduce the memory cost but also achieve computation\nacceleration. However, we find the token alignment of VLA models hinders the\napplication of existing quantization methods. To address this, we proposed an\noptimized framework called EaqVLA, which apply encoding-aligned quantization to\nVLA models. Specifically, we propose an complete analysis method to find the\nmisalignment in various granularity. Based on the analysis results, we propose\na mixed precision quantization with the awareness of encoding alignment.\nExperiments shows that the porposed EaqVLA achieves better quantization\nperformance (with the minimal quantization loss for end-to-end action control\nand xxx times acceleration) than existing quantization methods.", "comment": "There is an error in this paper, and as the author, I request\n  retraction", "pdf_url": "http://arxiv.org/pdf/2505.21567v2", "cate": "cs.CV", "date": "2025-05-27", "updated": "2025-07-31", "AI": {"title_translation": "EaqVLA：面向视觉-语言-动作模型的编码对齐量化", "tldr": "针对VLA模型高昂的计算/存储成本，现有量化方法受限于token对齐问题，本文提出EaqVLA框架，通过编码对齐量化、细粒度错位分析和混合精度量化，显著提升了量化性能和加速比。", "motivation": "现有视觉-语言-动作（VLA）模型面临昂贵的计算和存储成本，需要优化。尽管量化是有效的方法，但VLA模型的token对齐问题阻碍了现有量化方法的应用。", "method": "提出了一种名为EaqVLA的优化框架，将编码对齐量化应用于VLA模型。具体地，该方法提出了一种完整的分析方法来发现不同粒度下的错位，并在此分析结果的基础上，提出了一种考虑编码对齐的混合精度量化方法。", "result": "所提出的EaqVLA比现有量化方法取得了更好的量化性能，对端到端动作控制实现了最小的量化损失，并带来了xxx倍的加速。", "conclusion": "EaqVLA通过解决VLA模型中的编码对齐问题，显著提升了量化性能，从而有效降低了VLA模型的计算和存储成本。", "translation": "随着具身人工智能的发展，视觉-语言-动作（VLA）模型等端到端控制策略已成为主流。现有的VLA模型面临高昂的计算/存储成本，需要进行优化。量化被认为是最有效的方法，它不仅可以降低内存成本，还可以实现计算加速。然而，我们发现VLA模型的token对齐问题阻碍了现有量化方法的应用。为了解决这个问题，我们提出了一种名为EaqVLA的优化框架，将编码对齐量化应用于VLA模型。具体地，我们提出了一种完整的分析方法来发现各种粒度下的错位。基于分析结果，我们提出了一种考虑编码对齐的混合精度量化。实验表明，所提出的EaqVLA比现有量化方法取得了更好的量化性能（对端到端动作控制具有最小的量化损失，并实现了xxx倍的加速）。", "summary": "本文提出了一种名为EaqVLA的编码对齐量化框架，旨在解决视觉-语言-动作（VLA）模型面临的计算和存储成本高昂以及现有量化方法受token对齐问题限制的挑战。EaqVLA通过一套完整的分析方法识别不同粒度下的编码错位，并在此基础上应用了一种编码对齐感知的混合精度量化策略。实验结果表明，EaqVLA在端到端动作控制方面实现了最小的量化损失，并显著提升了计算速度，优于现有量化方法。", "keywords": "量化, 视觉-语言-动作模型, 编码对齐, 混合精度, 具身智能", "comments": "这篇论文的创新点在于识别并解决了VLA模型中特有的token对齐问题，该问题阻碍了传统量化方法的有效应用。通过提出编码对齐量化和混合精度策略，EaqVLA为降低具身AI模型的部署成本提供了新的有效途径，对于推动VLA模型在实际应用中的落地具有重要意义。"}}
{"id": "2507.22959", "title": "Scientific Machine Learning with Kolmogorov-Arnold Networks", "authors": ["Salah A. Faroughi", "Farinaz Mostajeran", "Amin Hamed Mashhadzadeh", "Shirko Faroughi"], "categories": ["cs.LG", "cs.CE", "math-ph", "math.MP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22959v1", "summary": "The field of scientific machine learning, which originally utilized\nmultilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold\nNetworks (KANs) for data encoding. This shift is driven by the limitations of\nMLPs, including poor interpretability, fixed activation functions, and\ndifficulty capturing localized or high-frequency features. KANs address these\nissues with enhanced interpretability and flexibility, enabling more efficient\nmodeling of complex nonlinear interactions and effectively overcoming the\nconstraints associated with conventional MLP architectures. This review\ncategorizes recent progress in KAN-based models across three distinct\nperspectives: (i) data-driven learning, (ii) physics-informed modeling, and\n(iii) deep operator learning. Each perspective is examined through the lens of\narchitectural design, training strategies, application efficacy, and\ncomparative evaluation against MLP-based counterparts. By benchmarking KANs\nagainst MLPs, we highlight consistent improvements in accuracy, convergence,\nand spectral representation, clarifying KANs' advantages in capturing complex\ndynamics while learning more effectively. Finally, this review identifies\ncritical challenges and open research questions in KAN development,\nparticularly regarding computational efficiency, theoretical guarantees,\nhyperparameter tuning, and algorithm complexity. We also outline future\nresearch directions aimed at improving the robustness, scalability, and\nphysical consistency of KAN-based frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22959v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "科学机器学习与柯尔莫哥洛夫-阿诺德网络", "tldr": "本综述探讨了柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习领域取代多层感知器（MLPs）的趋势。KANs因其增强的解释性和灵活性而优于MLPs，并在准确性、收敛性和频谱表示方面表现出一致的改进。文章对KANs的进展进行了分类，并指出了未来的挑战和研究方向。", "motivation": "科学机器学习领域最初使用多层感知器（MLPs），但MLPs存在解释性差、激活函数固定以及难以捕捉局部或高频特征等局限性。柯尔莫哥洛夫-阿诺德网络（KANs）通过增强解释性和灵活性来解决这些问题，能够更有效地建模复杂的非线性相互作用，并克服传统MLP架构的限制，因此被日益采用。", "method": "本综述将KANs的最新进展分为三个不同的视角进行探讨：(i) 数据驱动学习，(ii) 物理信息建模，以及(iii) 深度算子学习。每个视角都从架构设计、训练策略、应用效果以及与基于MLP的对应模型的比较评估等角度进行了审视。通过将KANs与MLPs进行基准测试，明确了KANs的优势。", "result": "通过将KANs与MLPs进行基准测试，结果显示KANs在准确性、收敛性和频谱表示方面均有持续改进，这表明KANs在捕捉复杂动力学方面具有优势，并能更有效地学习。", "conclusion": "柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习中表现出优于多层感知器（MLPs）的显著优势，尤其是在准确性、收敛性和捕捉复杂动力学方面。然而，KANs的发展仍面临计算效率、理论保证、超参数调整和算法复杂性等关键挑战。未来的研究方向应集中于提高KANs框架的鲁棒性、可扩展性和物理一致性。", "translation": "科学机器学习领域最初使用多层感知器（MLPs），但现在正日益采用柯尔莫哥洛夫-阿诺德网络（KANs）进行数据编码。这种转变是由于MLPs的局限性所驱动的，包括解释性差、激活函数固定以及难以捕捉局部或高频特征。KANs通过增强解释性和灵活性来解决这些问题，能够更有效地建模复杂的非线性相互作用，并有效克服与传统MLP架构相关的限制。本综述将基于KAN的模型在三个不同视角下的最新进展进行了分类：(i) 数据驱动学习，(ii) 物理信息建模，以及(iii) 深度算子学习。每个视角都从架构设计、训练策略、应用效果以及与基于MLP的对应模型的比较评估等角度进行了审视。通过将KANs与MLPs进行基准测试，我们强调了在准确性、收敛性和频谱表示方面持续的改进，阐明了KANs在捕捉复杂动力学同时更有效地学习方面的优势。最后，本综述指出了KAN开发中的关键挑战和开放性研究问题，特别是关于计算效率、理论保证、超参数调整和算法复杂性。我们还概述了旨在提高基于KAN框架的鲁棒性、可扩展性和物理一致性的未来研究方向。", "summary": "本综述探讨了柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习领域取代传统多层感知器（MLPs）的趋势。文章指出MLPs的局限性促使KANs因其增强的解释性和灵活性而被广泛采用。综述将基于KAN的模型分为数据驱动学习、物理信息建模和深度算子学习三个方面进行审视，并比较了KANs与MLPs的性能，结果显示KANs在准确性、收敛性和频谱表示方面均有显著提升。此外，文章还讨论了KANs当前面临的挑战以及未来的研究方向。", "keywords": "柯尔莫哥洛夫-阿诺德网络, 科学机器学习, 神经网络, 解释性, 综述", "comments": "这篇综述性论文及时地总结了柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习领域的最新进展，并系统地分析了其相对于传统多层感知器（MLPs）的优势。其创新之处在于提供了一个结构化的分类框架，并明确指出了KANs在准确性、收敛性和解释性方面的提升。论文的价值在于为研究人员提供了KANs应用的全面概览，并清晰地罗列了当前面临的计算效率、理论保证等关键挑战，为未来的研究指明了方向。对于推动科学机器学习领域的发展具有重要意义。"}}
{"id": "2507.22911", "title": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "authors": ["Jinzhi Wang", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Qinfeng Song", "Kaixuan Yang", "Jiangbo Zhang", "Yaoying Wang", "Ruimeng Li", "Biyi Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22911v1", "summary": "Electric power marketing customer service plays a critical role in addressing\ninquiries, complaints, and service requests. However, current systems, such as\nChina's 95598 hotline, often struggle with slow response times, inflexible\nprocedures, and limited accuracy in domain-specific tasks. While large language\nmodels (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,\nthey lack the domain expertise and empathy required in this field. To bridge\nthis gap, we introduce ElectriQ, the first benchmark designed to evaluate and\nenhance LLMs in electric power marketing scenarios. ElectriQ consists of a\ndialogue dataset covering six key service categories and introduces four\nevaluation metrics: professionalism, popularity, readability, and\nuser-friendliness. We further incorporate a domain-specific knowledge base and\npropose a knowledge augmentation method to boost model performance. Experiments\non 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and\naugmented, can surpass GPT-4o in terms of professionalism and\nuser-friendliness. ElectriQ establishes a comprehensive foundation for\ndeveloping LLMs tailored to the needs of power marketing services.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22911v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19", "AI": {"title_translation": "ElectriQ：电力营销领域大语言模型响应能力评估基准", "tldr": "ElectriQ是首个评估电力营销领域大语言模型响应能力的基准，包含对话数据集、四种评估指标和知识增强方法。实验表明，经过微调和增强的小型模型在专业性和用户友好性方面可超越GPT-4o。", "motivation": "当前的电力营销客服系统（如95598热线）存在响应慢、流程不灵活和领域准确性有限等问题。尽管大语言模型（LLMs）具有强大的通用能力，但它们缺乏该领域所需的专业知识和同理心，因此需要一个专门的基准来评估和提升LLMs在电力营销场景中的表现。", "method": "引入了ElectriQ，这是首个用于评估和增强电力营销场景中LLMs的基准。ElectriQ包含一个涵盖六个关键服务类别的对话数据集，并引入了四种评估指标：专业性、受欢迎度、可读性和用户友好性。此外，还整合了领域特定知识库，并提出了一种知识增强方法来提升模型性能。", "result": "对13个LLMs进行的实验表明，经过微调和增强的Llama3-8B等小型模型在专业性和用户友好性方面可以超越GPT-4o。", "conclusion": "ElectriQ为开发针对电力营销服务需求量身定制的LLMs奠定了全面的基础。", "translation": "电力营销客户服务在处理咨询、投诉和服务请求方面发挥着关键作用。然而，当前的系统，例如中国的95598热线，经常面临响应时间慢、流程不灵活以及在领域特定任务中准确性有限的问题。虽然GPT-4o和Claude 3等大型语言模型（LLMs）展现出强大的通用能力，但它们缺乏该领域所需的领域专业知识和同理心。为了弥补这一差距，我们引入了ElectriQ，这是首个旨在评估和增强LLMs在电力营销场景中表现的基准。ElectriQ包含一个涵盖六个关键服务类别的对话数据集，并引入了四种评估指标：专业性、受欢迎度、可读性和用户友好性。我们进一步整合了一个领域特定知识库，并提出了一种知识增强方法来提升模型性能。对13个LLMs进行的实验表明，经过微调和增强的Llama3-8B等小型模型在专业性和用户友好性方面可以超越GPT-4o。ElectriQ为开发针对电力营销服务需求量身定制的LLMs奠定了全面的基础。", "summary": "本研究提出了ElectriQ，一个专为评估和提升大语言模型（LLMs）在电力营销客户服务中响应能力的首个基准。针对现有系统响应慢、准确性不足以及通用LLMs缺乏领域专业知识的问题，ElectriQ构建了一个包含六类服务对话的数据集，并定义了专业性、受欢迎度、可读性和用户友好性四项评估指标。此外，研究还结合了领域知识库并提出知识增强方法。实验结果表明，经过微调和知识增强的小型LLMs（如Llama3-8B）在专业性和用户友好性上能超越大型通用模型（如GPT-4o），为电力营销LLMs的开发提供了坚实基础。", "keywords": "电力营销, 大语言模型, 评估基准, 知识增强, 客户服务", "comments": "ElectriQ的创新之处在于其是首个针对电力营销领域LLM响应能力的评估基准，填补了这一特定应用领域的空白。通过引入领域特定数据集、多维度评估指标和知识增强方法，该研究为提升LLMs在专业服务领域的实用性提供了具体路径。特别是，小型模型经过优化后能超越大型通用模型的结果，突显了领域适应性和知识增强的重要性，对于资源受限或需要部署边缘AI的场景具有重要指导意义。"}}
{"id": "2504.08575", "title": "Prophecies all the Way: Game-based Model-Checking for HyperQPTL beyond $\\forall^*\\exists^*$", "authors": ["Sarah Winter", "Martin Zimmermann"], "categories": ["cs.LO", "cs.FL"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08575v4", "summary": "Model-checking HyperLTL, a temporal logic expressing properties of sets of\ntraces with applications to information-flow based security and privacy, has a\ndecidable, but TOWER-complete, model-checking problem. While the classical\nmodel-checking algorithm for full HyperLTL is automata-theoretic, more\nrecently, a game-based alternative for the $\\forall^*\\exists^*$-fragment has\nbeen presented.\n  Here, we employ imperfect information-games to extend the game-based approach\nto full HyperQPTL, which features arbitrary quantifier prefixes and\nquantification over propositions and can express every $\\omega$-regular\nhyperproperty. As a byproduct of our game-based algorithm, we obtain\nfinite-state implementations of Skolem functions via transducers with lookahead\nthat explain satisfaction or violation of HyperQPTL properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08575v4", "cate": "cs.LO", "date": "2025-04-11", "updated": "2025-07-31", "AI": {"title_translation": "一路预言：超越$\forall^*\forall^*$的HyperQPTL基于博弈的模型检测", "tldr": "本文将基于博弈的模型检测方法扩展到完整的HyperQPTL，该逻辑具有任意量词前缀和命题量化，并通过不完全信息博弈实现，同时提供了解释属性满足或违反的有限状态实现。", "motivation": "虽然HyperLTL的$\forall^*\forall^*$-片段已有基于博弈的模型检测方法，但完整的HyperLTL（以及更通用的HyperQPTL）缺乏类似的方法，且其模型检测问题是TOWER完全的。本研究旨在将基于博弈的方法扩展到更具表现力的HyperQPTL。", "method": "本文采用不完全信息博弈，将基于博弈的模型检测方法扩展到完整的HyperQPTL。HyperQPTL能够表达任意量词前缀和命题量化，并可表达所有$\\\\\\omega$-正则超性质。", "result": "本文提出了一个针对完整HyperQPTL的基于博弈的模型检测算法。作为该算法的副产品，通过具有前瞻功能的传感器获得了Skolem函数的有限状态实现，这些实现能够解释HyperQPTL属性的满足或违反。", "conclusion": "本文成功地将基于博弈的模型检测方法扩展到更具表现力的HyperQPTL，为超性质的验证提供了一种新颖的、可解释的方法，这对于信息流安全和隐私等应用至关重要。", "translation": "模型检测HyperLTL（一种表达迹集合属性的时序逻辑，应用于基于信息流的安全和隐私）有一个可判定但TOWER完全的模型检测问题。虽然完整的HyperLTL的经典模型检测算法是基于自动机的，但最近为$\forall^*\forall^*$-片段提出了一种基于博弈的替代方法。\n本文采用不完全信息博弈，将基于博弈的方法扩展到完整的HyperQPTL。HyperQPTL具有任意量词前缀和命题量化，并且可以表达每个$\\\\\\omega$-正则超性质。作为我们基于博弈算法的副产品，我们通过具有前瞻功能的传感器获得了Skolem函数的有限状态实现，这些实现可以解释HyperQPTL属性的满足或违反。", "summary": "本文将基于博弈的模型检测方法从HyperLTL的$\forall^*\forall^*$-片段扩展到更全面的HyperQPTL。HyperQPTL支持任意量词前缀和命题量化，能够表达所有$\\\\\\omega$-正则超性质。作者通过采用不完全信息博弈，开发了一种新颖的算法。该方法的一个重要副产品是，通过具有前瞻功能的传感器推导出Skolem函数的有限状态实现，这些实现能够解释HyperQPTL属性的满足或违反，从而增强了对安全和隐私相关超性质的理解。", "keywords": "HyperQPTL, 模型检测, 基于博弈, 不完全信息博弈, 超性质", "comments": "本文的创新之处在于将基于博弈的模型检测范式扩展到表现力更强的时序逻辑（HyperQPTL），超越了以往的限制，特别是在不完全信息博弈的应用上。通过获得用于解释的有限状态Skolem函数，为复杂的属性验证增加了可解释性，这对于安全和隐私应用至关重要，是其一个尤其有价值的贡献。"}}
{"id": "2507.23648", "title": "Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach", "authors": ["Louise Guillon", "Soheib Biga", "Yendoube E. Kantchire", "Mouhamadou Lamine Sane", "Grégoire Pasquier", "Kossi Yakpa", "Stéphane E. Sossou", "Marc Thellier", "Laurent Bonnardot", "Laurence Lachaud", "Renaud Piarroux", "Ameyo M. Dorkenoo"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025 AMAI Workshop, Accepted, Submitted Manuscript Version", "url": "http://arxiv.org/abs/2507.23648v1", "summary": "Malaria remains a major global health challenge, particularly in low-resource\nsettings where access to expert microscopy may be limited. Deep learning-based\ncomputer-aided diagnosis (CAD) systems have been developed and demonstrate\npromising performance on thin blood smear images. However, their clinical\ndeployment may be hindered by limited generalization across sites with varying\nconditions. Yet very few practical solutions have been proposed. In this work,\nwe investigate continual learning (CL) as a strategy to enhance the robustness\nof malaria CAD models to domain shifts. We frame the problem as a\ndomain-incremental learning scenario, where a YOLO-based object detector must\nadapt to new acquisition sites while retaining performance on previously seen\ndomains. We evaluate four CL strategies, two rehearsal-based and two\nregularization-based methods, on real-life conditions thanks to a multi-site\nclinical dataset of thin blood smear images. Our results suggest that CL, and\nrehearsal-based methods in particular, can significantly improve performance.\nThese findings highlight the potential of continual learning to support the\ndevelopment of deployable, field-ready CAD tools for malaria.", "comment": "MICCAI 2025 AMAI Workshop, Accepted, Submitted Manuscript Version", "pdf_url": "http://arxiv.org/pdf/2507.23648v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "迈向现场就绪的基于AI的疟疾诊断：一种持续学习方法", "tldr": "本研究探讨持续学习（CL）如何提高疟疾计算机辅助诊断（CAD）模型在不同采集地点间的泛化能力，发现CL，特别是基于排练的方法，能显著提升性能，支持开发可部署的现场就绪CAD工具。", "motivation": "疟疾仍然是一个全球性的健康挑战，特别是在资源匮乏地区，专家显微镜检查受限。尽管深度学习驱动的计算机辅助诊断（CAD）系统在薄血涂片图像上表现出良好性能，但其临床部署受限于在不同条件下站点间的泛化能力差，且很少有实际解决方案被提出。", "method": "本研究将问题定义为领域增量学习场景，其中基于YOLO的目标检测器必须适应新的采集站点，同时保持在先前领域上的性能。研究评估了四种持续学习（CL）策略，包括两种基于排练的方法和两种基于正则化的方法，并在多站点临床薄血涂片图像数据集的真实条件下进行了评估。", "result": "结果表明，持续学习（CL），特别是基于排练的方法，可以显著提高性能。", "conclusion": "这些发现突出了持续学习在支持开发可部署的、现场就绪的疟疾计算机辅助诊断（CAD）工具方面的潜力。", "translation": "疟疾仍然是一个重大的全球健康挑战，特别是在资源匮乏地区，那里的专家显微镜检查可能受到限制。基于深度学习的计算机辅助诊断（CAD）系统已经开发出来，并在薄血涂片图像上表现出良好的性能。然而，它们的临床部署可能因跨不同条件站点的泛化能力有限而受阻。但很少有实际的解决方案被提出。在这项工作中，我们研究了持续学习（CL）作为一种增强疟疾CAD模型对领域漂移鲁棒性的策略。我们将问题框定为领域增量学习场景，其中基于YOLO的目标检测器必须适应新的采集站点，同时保持在先前领域上的性能。我们利用一个多站点薄血涂片图像临床数据集，在真实条件下评估了四种CL策略，两种基于排练的方法和两种基于正则化的方法。我们的结果表明，CL，特别是基于排练的方法，可以显著提高性能。这些发现突出了持续学习在支持开发可部署的、现场就绪的疟疾CAD工具方面的潜力。", "summary": "本研究旨在解决深度学习驱动的疟疾计算机辅助诊断（CAD）系统在临床部署中遇到的泛化能力差的问题。通过将问题构建为领域增量学习，并采用持续学习（CL）策略，特别是基于YOLO的目标检测器，使其能在适应新采集站点的同时保持原有性能。在多站点真实临床数据集上，评估了四种CL方法。结果显示，CL，尤其是基于排练的方法，显著提升了模型性能，突显了持续学习在开发可部署的、现场就绪疟疾CAD工具方面的巨大潜力。", "keywords": "疟疾诊断, 持续学习, 计算机辅助诊断, 深度学习, 领域漂移", "comments": "该研究解决了AI医疗诊断领域一个关键的实际部署挑战：模型在不同现场条件下的泛化性。通过引入持续学习，特别是领域增量学习的视角，为构建更鲁棒、更适应实际环境的AI诊断系统提供了有价值的解决方案。研究强调了基于排练的持续学习方法在提升性能方面的有效性，这对于未来现场部署的AI系统具有重要指导意义。"}}
{"id": "2507.23486", "title": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains", "authors": ["Shirui Wang", "Zhihui Tang", "Huaxia Yang", "Qiuhong Gong", "Tiantian Gu", "Hongyang Ma", "Yongxin Wang", "Wubin Sun", "Zeliang Lian", "Kehang Mao", "Yinan Jiang", "Zhicheng Huang", "Lingyun Ma", "Wenjie Shen", "Yajie Ji", "Yunhui Tan", "Chunbo Wang", "Yunlu Gao", "Qianling Ye", "Rui Lin", "Mingyu Chen", "Lijuan Niu", "Zhihao Wang", "Peng Yu", "Mengran Lang", "Yue Liu", "Huimin Zhang", "Haitao Shen", "Long Chen", "Qiguang Zhao", "Si-Xuan Liu", "Lina Zhou", "Hua Gao", "Dongqiang Ye", "Lingmin Meng", "Youtao Yu", "Naixin Liang", "Jianxiong Wu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23486v1", "summary": "Large language models (LLMs) hold promise in clinical decision support but\nface major challenges in safety evaluation and effectiveness validation. We\ndeveloped the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a\nmultidimensional framework built on clinical expert consensus, encompassing 30\ncriteria covering critical areas like critical illness recognition, guideline\nadherence, and medication safety, with weighted consequence measures.\nThirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A\nitems aligned with these criteria, spanning 26 clinical departments to simulate\nreal-world scenarios. Benchmark testing of six LLMs revealed moderate overall\nperformance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),\nwith a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).\nDomain-specific medical LLMs showed consistent performance advantages over\ngeneral-purpose models, with relatively higher top scores in safety (0.912) and\neffectiveness (0.861). The findings of this study not only provide a\nstandardized metric for evaluating the clinical application of medical LLMs,\nfacilitating comparative analyses, risk exposure identification, and\nimprovement directions across different scenarios, but also hold the potential\nto promote safer and more effective deployment of large language models in\nhealthcare environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23486v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "医学大型语言模型的新型评估基准：阐明临床领域的安全性和有效性", "tldr": "开发了一个名为CSEDB的新型基准，用于评估医学大型语言模型在临床环境中的安全性和有效性，发现LLM表现中等，在高风险场景下性能下降，且领域特定模型优于通用模型。", "motivation": "大型语言模型（LLMs）在临床决策支持方面具有潜力，但在安全评估和有效性验证方面面临重大挑战。", "method": "研究开发了临床安全-有效性双轨基准（CSEDB），这是一个基于临床专家共识的多维框架，包含30个标准，涵盖危重症识别、指南依从性和用药安全等关键领域，并带有加权后果度量。32位专科医生开发并审查了2069个开放式问答题，涵盖26个临床科室，以模拟真实世界场景。", "result": "对六个LLM进行基准测试显示，总体表现中等（平均总分57.2%，安全性54.7%，有效性62.3%），在高风险场景下性能显著下降13.3%（p < 0.0001）。领域特定的医学LLM表现出持续优于通用模型的优势，在安全性和有效性方面有相对较高的最高分（0.912和0.861）。", "conclusion": "本研究的结果不仅为评估医学LLMs的临床应用提供了标准化指标，有助于在不同场景下进行比较分析、识别风险暴露和确定改进方向，而且有望促进大型语言模型在医疗环境中更安全、更有效地部署。", "translation": "大型语言模型（LLMs）在临床决策支持方面具有前景，但在安全评估和有效性验证方面面临重大挑战。我们开发了临床安全-有效性双轨基准（CSEDB），这是一个基于临床专家共识的多维框架，包含30个标准，涵盖危重症识别、指南依从性和用药安全等关键领域，并带有加权后果度量。32位专科医生开发并审查了2069个开放式问答题，这些问题与这些标准对齐，涵盖26个临床科室，以模拟真实世界场景。对六个LLM进行基准测试显示，总体表现中等（平均总分57.2%，安全性54.7%，有效性62.3%），在高风险场景下性能显著下降13.3%（p < 0.0001）。领域特定的医学LLM表现出持续优于通用模型的优势，在安全性和有效性方面有相对较高的最高分（0.912和0.861）。本研究的结果不仅为评估医学LLMs的临床应用提供了标准化指标，有助于在不同场景下进行比较分析、识别风险暴露和确定改进方向，而且有望促进大型语言模型在医疗环境中更安全、更有效地部署。", "summary": "本研究针对大型语言模型在临床应用中面临的安全性和有效性挑战，开发了一个名为临床安全-有效性双轨基准（CSEDB）的新型评估框架。该基准由临床专家共识构建，包含30项标准和2069个模拟真实场景的问答题。测试结果显示，LLMs在临床任务中表现中等，尤其在高风险场景下性能显著下降，但领域特定的医学LLMs表现出更好的稳定性和优势。该基准为医学LLMs的评估、风险识别和改进提供了标准化工具，有助于推动其在医疗领域的安全有效部署。", "keywords": "医学LLM, 评估基准, 安全性, 有效性, 临床决策支持", "comments": "该研究的创新之处在于构建了一个由临床专家共识驱动的多维评估基准，并引入了加权后果度量，这对于评估医疗领域LLM的实际风险至关重要。其重要性在于为医学LLMs的安全性与有效性评估提供了急需的标准化方法，有助于识别潜在风险并指导模型改进，从而促进LLM在医疗领域的负责任应用。"}}
{"id": "2504.05164", "title": "Balancing Task-invariant Interaction and Task-specific Adaptation for Unified Image Fusion", "authors": ["Xingyu Hu", "Junjun Jiang", "Chenyang Wang", "Kui Jiang", "Xianming Liu", "Jiayi Ma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2504.05164v2", "summary": "Unified image fusion aims to integrate complementary information from\nmulti-source images, enhancing image quality through a unified framework\napplicable to diverse fusion tasks. While treating all fusion tasks as a\nunified problem facilitates task-invariant knowledge sharing, it often\noverlooks task-specific characteristics, thereby limiting the overall\nperformance. Existing general image fusion methods incorporate explicit task\nidentification to enable adaptation to different fusion tasks. However, this\ndependence during inference restricts the model's generalization to unseen\nfusion tasks. To address these issues, we propose a novel unified image fusion\nframework named \"TITA\", which dynamically balances both Task-invariant\nInteraction and Task-specific Adaptation. For task-invariant interaction, we\nintroduce the Interaction-enhanced Pixel Attention (IPA) module to enhance\npixel-wise interactions for better multi-source complementary information\nextraction. For task-specific adaptation, the Operation-based Adaptive Fusion\n(OAF) module dynamically adjusts operation weights based on task properties.\nAdditionally, we incorporate the Fast Adaptive Multitask Optimization (FAMO)\nstrategy to mitigate the impact of gradient conflicts across tasks during joint\ntraining. Extensive experiments demonstrate that TITA not only achieves\ncompetitive performance compared to specialized methods across three image\nfusion scenarios but also exhibits strong generalization to unseen fusion\ntasks. The source codes are released at https://github.com/huxingyuabc/TITA.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2504.05164v2", "cate": "cs.CV", "date": "2025-04-07", "updated": "2025-07-31", "AI": {"title_translation": "统一图像融合中任务不变交互与任务特定适应的平衡", "tldr": "TITA是一个新的统一图像融合框架，通过平衡任务不变交互和任务特定适应性，解决了现有方法在泛化性和性能上的局限性，并在多任务和未知任务中表现出色。", "motivation": "现有统一图像融合方法在实现任务不变知识共享的同时，常忽略任务特定特性，限制了整体性能。显式任务识别方法虽能适应不同任务，但推理时的依赖性限制了模型对未知融合任务的泛化能力。", "method": "本文提出了名为“TITA”的统一图像融合框架。该框架通过引入“交互增强像素注意力（IPA）”模块实现任务不变交互，以更好地提取多源互补信息；通过“基于操作的自适应融合（OAF）”模块根据任务属性动态调整操作权重，实现任务特定适应；并采用“快速自适应多任务优化（FAMO）”策略缓解联合训练中任务间的梯度冲突。", "result": "TITA在三个图像融合场景下，不仅达到了与专用方法相当的竞争性能，而且对未知融合任务表现出强大的泛化能力。", "conclusion": "TITA框架通过动态平衡任务不变交互和任务特定适应，有效解决了统一图像融合中的性能和泛化性问题，并在多任务和未知任务中展现了优越性。", "translation": "统一图像融合旨在整合多源图像的互补信息，通过适用于各种融合任务的统一框架来提高图像质量。虽然将所有融合任务视为一个统一问题有助于任务不变知识共享，但它往往忽略了任务特定的特性，从而限制了整体性能。现有的通用图像融合方法通过明确的任务识别来实现对不同融合任务的适应。然而，推理时的这种依赖性限制了模型对未知融合任务的泛化能力。为了解决这些问题，我们提出了一种新颖的统一图像融合框架，名为“TITA”，它动态平衡了任务不变交互和任务特定适应。对于任务不变交互，我们引入了交互增强像素注意力（IPA）模块，以增强像素级交互，从而更好地提取多源互补信息。对于任务特定适应，基于操作的自适应融合（OAF）模块根据任务属性动态调整操作权重。此外，我们引入了快速自适应多任务优化（FAMO）策略，以减轻联合训练中任务间梯度冲突的影响。广泛的实验表明，TITA不仅在三个图像融合场景中达到了与专用方法相当的竞争性能，而且对未知融合任务表现出强大的泛化能力。源代码已在https://github.com/huxingyuabc/TITA发布。", "summary": "本文提出了一种名为TITA的新型统一图像融合框架，旨在解决现有方法在处理多任务融合时性能和泛化性的局限。TITA通过引入交互增强像素注意力（IPA）模块实现任务不变交互，以及基于操作的自适应融合（OAF）模块进行任务特定适应。此外，它还采用快速自适应多任务优化（FAMO）策略来缓解训练中的梯度冲突。实验证明，TITA在多种图像融合任务中表现出优异性能，并能有效泛化到未知任务。", "keywords": "图像融合, 统一框架, 任务不变交互, 任务特定适应, 泛化性", "comments": "这项研究的创新点在于提出了一个能够动态平衡任务不变性与任务特异性的统一图像融合框架，有效解决了现有方法在泛化能力和性能上的瓶颈。IPA和OAF模块的设计思路新颖，分别从不同维度提升了模型的融合能力。FAMO策略的引入也有效缓解了多任务学习中的常见问题。该工作对于推动通用图像融合技术的发展具有重要意义。"}}
{"id": "2507.23344", "title": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "authors": ["Tatsuya Mitomi", "Fumiyasu Makinoshima", "Fumiya Makihara", "Eigo Segawa"], "categories": ["cs.LG", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23344v1", "summary": "Bike-sharing systems are emerging in various cities as a new ecofriendly\ntransportation system. In these systems, spatiotemporally varying user demands\nlead to imbalanced inventory at bicycle stations, resulting in additional\nrelocation costs. Therefore, it is essential to manage user demand through\noptimal dynamic pricing for the system. However, optimal pricing design for\nsuch a system is challenging because the system involves users with diverse\nbackgrounds and their probabilistic choices. To address this problem, we\ndevelop a differentiable agent-based simulation to rapidly design dynamic\npricing in bike-sharing systems, achieving balanced bicycle inventory despite\nspatiotemporally heterogeneous trips and probabilistic user decisions. We first\nvalidate our approach against conventional methods through numerical\nexperiments involving 25 bicycle stations and five time slots, yielding 100\nparameters. Compared to the conventional methods, our approach obtains a more\naccurate solution with a 73% to 78% reduction in loss while achieving more than\na 100-fold increase in convergence speed. We further validate our approach on a\nlarge-scale urban bike-sharing system scenario involving 289 bicycle stations,\nresulting in a total of 1156 parameters. Through simulations using the obtained\npricing policies, we confirm that these policies can naturally induce balanced\ninventory without any manual relocation. Additionally, we find that the cost of\ndiscounts to induce the balanced inventory can be minimized by setting\nappropriate initial conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23344v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "自行车共享系统差异化代理仿真动态定价设计", "tldr": "本文通过可微分的基于代理的模拟，为自行车共享系统设计动态定价，以平衡车辆库存并显著提高收敛速度。", "motivation": "自行车共享系统中时空变化的用户需求导致站点库存不平衡，产生额外调度成本。由于涉及用户背景多样性和概率选择，设计最优动态定价来管理用户需求具有挑战性。", "method": "开发了一种可微分的基于代理的仿真方法，用于快速设计自行车共享系统中的动态定价。该方法旨在平衡自行车库存，即使面对时空异构的出行和概率性用户决策。通过数值实验验证，包括25个站点和5个时间段（100个参数），以及大规模城市系统（289个站点，1156个参数）。", "result": "与传统方法相比，该方法将损失降低了73%到78%，收敛速度提高了100多倍，获得了更准确的解决方案。在大规模模拟中，获得的定价策略能够自然地实现库存平衡，无需人工调度。通过设置适当的初始条件，可以最大程度地降低为实现库存平衡而产生的折扣成本。", "conclusion": "本文提出的基于可微分代理仿真设计的动态定价策略，能够有效解决自行车共享系统的库存不平衡问题，无需人工干预，并能显著提高优化效率和降低成本。", "translation": "自行车共享系统作为一种新型环保交通系统正在各个城市兴起。在这些系统中，时空变化的用户需求导致自行车站点库存不平衡，从而产生额外的调度成本。因此，通过最优动态定价来管理用户需求对于系统至关重要。然而，为这种系统设计最优定价具有挑战性，因为系统涉及具有不同背景的用户及其概率选择。为了解决这个问题，我们开发了一种可微分的基于代理的仿真，以快速设计自行车共享系统中的动态定价，尽管存在时空异构的出行和概率性用户决策，仍能实现平衡的自行车库存。我们首先通过涉及25个自行车站点和五个时间段的数值实验（产生100个参数）验证了我们的方法与传统方法的对比，结果显示我们的方法获得了更准确的解决方案，损失降低了73%到78%，同时收敛速度提高了100多倍。我们进一步在一个涉及289个自行车站点的大规模城市自行车共享系统场景中验证了我们的方法，总共产生了1156个参数。通过使用获得的定价策略进行模拟，我们确认这些策略可以自然地实现库存平衡，无需任何人工调度。此外，我们发现通过设置适当的初始条件，可以最大限度地降低为实现库存平衡而产生的折扣成本。", "summary": "本文针对自行车共享系统中因用户需求时空变化导致的库存不平衡问题，提出了一种基于可微分代理仿真的动态定价设计方法。该方法能有效管理用户需求，在面对异构出行和概率性用户决策时平衡自行车库存。实验结果表明，与传统方法相比，该方法在准确性、收敛速度和成本效益方面均有显著提升，尤其是在大规模系统下，能实现无需人工调度的自然库存平衡。", "keywords": "自行车共享系统, 动态定价, 可微分仿真, 代理仿真, 库存平衡", "comments": "这篇论文的创新点在于引入了“可微分代理仿真”来解决自行车共享系统的动态定价问题，这使得优化过程更加高效和准确。其重要性在于能够显著减少人工调度成本，提高系统运营效率，并为复杂的用户行为建模提供了一种有效途径。"}}
{"id": "2507.23487", "title": "Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions", "authors": ["Jinshan Zhen", "Yuanyue Ge", "Tianxiao Zhu", "Hui Zhao", "Ya Xiong"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IROS 2025", "url": "http://arxiv.org/abs/2507.23487v1", "summary": "Accurate mass estimation of table-top grown strawberries under field\nconditions remains challenging due to frequent occlusions and pose variations.\nThis study proposes a vision-based pipeline integrating RGB-D sensing and deep\nlearning to enable non-destructive, real-time and online mass estimation. The\nmethod employed YOLOv8-Seg for instance segmentation, Cycle-consistent\ngenerative adversarial network (CycleGAN) for occluded region completion, and\ntilt-angle correction to refine frontal projection area calculations. A\npolynomial regression model then mapped the geometric features to mass.\nExperiments demonstrated mean mass estimation errors of 8.11% for isolated\nstrawberries and 10.47% for occluded cases. CycleGAN outperformed large mask\ninpainting (LaMa) model in occlusion recovery, achieving superior pixel area\nratios (PAR) (mean: 0.978 vs. 1.112) and higher intersection over union (IoU)\nscores (92.3% vs. 47.7% in the [0.9-1] range). This approach addresses critical\nlimitations of traditional methods, offering a robust solution for automated\nharvesting and yield monitoring with complex occlusion patterns.", "comment": "Accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.23487v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "田间遮挡条件下桌面种植草莓质量的在线估算", "tldr": "本文提出了一种基于视觉的在线方法，用于在田间遮挡条件下准确估算桌面种植草莓的质量。", "motivation": "由于频繁的遮挡和姿态变化，在田间条件下准确估算桌面种植草莓的质量仍然具有挑战性。", "method": "本研究提出了一种结合RGB-D传感和深度学习的视觉管道，实现了非破坏性、实时和在线的质量估算。该方法采用YOLOv8-Seg进行实例分割，循环一致生成对抗网络（CycleGAN）用于遮挡区域补全，并进行倾斜角度校正以优化正面投影面积计算。然后，多项式回归模型将几何特征映射到质量。", "result": "实验表明，孤立草莓的平均质量估算误差为8.11%，遮挡情况下的误差为10.47%。CycleGAN在遮挡恢复方面优于大型掩模修复（LaMa）模型，实现了更高的像素面积比（PAR）（平均：0.978 vs. 1.112）和更高的交并比（IoU）得分（在[0.9-1]范围内为92.3% vs. 47.7%）。", "conclusion": "该方法解决了传统方法的关键局限性，为具有复杂遮挡模式的自动化采摘和产量监测提供了稳健的解决方案。", "translation": "在田间条件下准确估算桌面种植草莓的质量由于频繁的遮挡和姿态变化而仍然具有挑战性。本研究提出了一种结合RGB-D传感和深度学习的视觉管道，以实现非破坏性、实时和在线的质量估算。该方法采用YOLOv8-Seg进行实例分割，循环一致生成对抗网络（CycleGAN）用于遮挡区域补全，并进行倾斜角度校正以优化正面投影面积计算。然后，多项式回归模型将几何特征映射到质量。实验表明，孤立草莓的平均质量估算误差为8.11%，遮挡情况下的误差为10.47%。CycleGAN在遮挡恢复方面优于大型掩模修复（LaMa）模型，实现了更高的像素面积比（PAR）（平均：0.978 vs. 1.112）和更高的交并比（IoU）得分（在[0.9-1]范围内为92.3% vs. 47.7%）。这种方法解决了传统方法的关键局限性，为具有复杂遮挡模式的自动化采摘和产量监测提供了稳健的解决方案。", "summary": "本文提出了一种基于视觉的在线管道，结合RGB-D传感和深度学习技术，实现了田间条件下桌面种植草莓的非破坏性、实时质量估算，尤其解决了遮挡问题。该方法利用YOLOv8-Seg进行分割，CycleGAN进行遮挡补全，并通过多项式回归模型将几何特征映射到质量。实验证明，该方法在孤立和遮挡草莓的质量估算中均表现出较低的误差，并优于现有模型在遮挡恢复方面的性能，为自动化采摘和产量监测提供了鲁棒的解决方案。", "keywords": "草莓质量估算, 在线, 遮挡, 深度学习, 计算机视觉", "comments": "该研究通过集成先进的深度学习技术（如YOLOv8-Seg和CycleGAN）来解决农业机器人领域中一个实际且具有挑战性的问题——田间复杂遮挡下的作物质量估算，具有重要的创新性。特别是CycleGAN在遮挡区域补全方面的应用，显著提升了估算的准确性和鲁棒性，为自动化采摘和产量监测提供了可靠的技术支持。"}}
{"id": "2507.22938", "title": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "authors": ["Sumit Soman", "H. G. Ranjani", "Sujoy Roychowdhury", "Venkata Dharma Surya Narayana Sastry", "Akshat Jain", "Pranav Gangrade", "Ayaaz Khan"], "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the KDD 2025 Workshop on Structured Knowledge for Large Language Models", "url": "http://arxiv.org/abs/2507.22938v1", "summary": "Question-Answering (QA) from technical documents often involves questions\nwhose answers are present in figures, such as flowcharts or flow diagrams.\nText-based Retrieval Augmented Generation (RAG) systems may fail to answer such\nquestions. We leverage graph representations of flowcharts obtained from Visual\nlarge Language Models (VLMs) and incorporate them in a text-based RAG system to\nshow that this approach can enable image retrieval for QA in the telecom\ndomain. We present the end-to-end approach from processing technical documents,\nclassifying image types, building graph representations, and incorporating them\nwith the text embedding pipeline for efficient retrieval. We benchmark the same\non a QA dataset created based on proprietary telecom product information\ndocuments. Results show that the graph representations obtained using a\nfine-tuned VLM model have lower edit distance with respect to the ground truth,\nwhich illustrate the robustness of these representations for flowchart images.\nFurther, the approach for QA using these representations gives good retrieval\nperformance using text-based embedding models, including a telecom-domain\nadapted one. Our approach also alleviates the need for a VLM in inference,\nwhich is an important cost benefit for deployed QA systems.", "comment": "Accepted for publication at the KDD 2025 Workshop on Structured\n  Knowledge for Large Language Models", "pdf_url": "http://arxiv.org/pdf/2507.22938v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "一种基于图的方法用于电信文档中流程图的多模态问答", "tldr": "该研究提出了一种基于图的方法，将流程图的图表示与文本检索增强生成（RAG）系统结合，以解决电信文档中包含流程图的多模态问答问题，并展示了其在检索性能和推理成本上的优势。", "motivation": "现有基于文本的检索增强生成（RAG）系统在处理技术文档中包含图表（如流程图）的问题时，无法有效回答。", "method": "该方法利用视觉大型语言模型（VLM）从流程图中获取图表示，并将其整合到基于文本的RAG系统中。具体流程包括处理技术文档、分类图像类型、构建图表示，并将其与文本嵌入管道结合以实现高效检索。", "result": "使用微调VLM模型获得的图表示与真实值相比具有更低的编辑距离，这表明这些表示对于流程图图像具有鲁棒性。此外，使用这些表示的问答方法通过基于文本的嵌入模型（包括针对电信领域调整的模型）获得了良好的检索性能。该方法还避免了在推理阶段使用VLM，从而为部署的问答系统带来了重要的成本效益。", "conclusion": "该研究表明，通过VLM获得的流程图图表示是鲁棒的，并且将其集成到基于文本的RAG系统中可以有效解决电信文档中的多模态问答问题，同时降低了推理成本。", "translation": "技术文档中的问答（QA）通常涉及答案存在于图表（如流程图或流程图）中的问题。基于文本的检索增强生成（RAG）系统可能无法回答此类问题。我们利用从视觉大型语言模型（VLM）获得的流程图的图表示，并将其整合到基于文本的RAG系统中，以表明该方法可以实现电信领域问答的图像检索。我们提出了一个端到端的方法，从处理技术文档、分类图像类型、构建图表示，到将其与文本嵌入管道结合以实现高效检索。我们基于专有的电信产品信息文档创建了一个问答数据集，并对其进行了基准测试。结果表明，使用微调VLM模型获得的图表示与真实值相比具有更低的编辑距离，这说明了这些表示对于流程图图像的鲁棒性。此外，使用这些表示的问答方法通过基于文本的嵌入模型（包括针对电信领域调整的模型）获得了良好的检索性能。我们的方法还避免了在推理阶段使用VLM，这对于部署的问答系统来说是一个重要的成本效益。", "summary": "本研究提出了一种创新方法，通过将从视觉大型语言模型（VLM）获得的流程图图表示与基于文本的检索增强生成（RAG）系统相结合，以解决电信文档中的多模态问答问题。该端到端方法旨在克服传统RAG系统在处理包含图表的文档时的局限性。实验结果表明，该方法生成的图表示具有高鲁棒性，并能实现高效的图像检索性能，同时显著降低了推理阶段的计算成本。", "keywords": "多模态问答, 流程图, 图表示, 电信文档, 检索增强生成", "comments": "该论文的创新点在于将流程图的视觉信息通过图表示的形式有效地融入到传统的文本RAG系统中，从而实现了多模态问答。这种方法不仅提高了对包含图表的复杂技术文档的理解能力，而且通过避免在推理阶段使用VLM，显著降低了部署成本，这对于实际应用具有重要的经济效益和实用价值。"}}
{"id": "2507.23590", "title": "Identifying Hearing Difficulty Moments in Conversational Audio", "authors": ["Jack Collins", "Adrian Buzea", "Chris Collier", "Alejandro Ballesta Rosen", "Julian Maclaren", "Richard F. Lyon", "Simon Carlile"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23590v1", "summary": "Individuals regularly experience Hearing Difficulty Moments in everyday\nconversation. Identifying these moments of hearing difficulty has particular\nsignificance in the field of hearing assistive technology where timely\ninterventions are key for realtime hearing assistance. In this paper, we\npropose and compare machine learning solutions for continuously detecting\nutterances that identify these specific moments in conversational audio. We\nshow that audio language models, through their multimodal reasoning\ncapabilities, excel at this task, significantly outperforming a simple ASR\nhotword heuristic and a more conventional fine-tuning approach with Wav2Vec, an\naudio-only input architecture that is state-of-the-art for automatic speech\nrecognition (ASR).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23590v1", "cate": "cs.SD", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "识别对话音频中的听力困难时刻", "tldr": "本文提出并比较了用于识别对话音频中听力困难时刻的机器学习解决方案，发现音频语言模型表现最佳。", "motivation": "识别对话中的听力困难时刻对于听力辅助技术领域具有特殊意义，因为及时干预是实时听力辅助的关键。", "method": "本文提出并比较了多种机器学习解决方案，用于连续检测对话音频中识别听力困难时刻的语音。具体比较了音频语言模型、简单的ASR热词启发式方法以及使用Wav2Vec（一种最先进的自动语音识别（ASR）音频输入架构）的传统微调方法。", "result": "研究表明，音频语言模型通过其多模态推理能力，在该任务中表现出色，显著优于简单的ASR热词启发式方法和更传统的Wav2Vec微调方法。", "conclusion": "音频语言模型是识别对话音频中听力困难时刻的有效方法，为实时听力辅助技术提供了重要支持。", "translation": "个人在日常对话中经常会遇到听力困难时刻。识别这些听力困难时刻在听力辅助技术领域具有特殊意义，因为及时干预是实时听力辅助的关键。在本文中，我们提出并比较了用于连续检测对话音频中识别这些特定时刻的语音的机器学习解决方案。我们表明，音频语言模型通过其多模态推理能力，在该任务中表现出色，显著优于简单的ASR热词启发式方法和更传统的Wav2Vec微调方法，后者是一种用于自动语音识别（ASR）的最先进的纯音频输入架构。", "summary": "本文旨在识别对话音频中的听力困难时刻，这对于听力辅助技术至关重要。研究人员提出并比较了多种机器学习方法来连续检测这些时刻的语音，结果显示，具有多模态推理能力的音频语言模型表现最佳，显著优于传统的ASR热词启发式方法和基于Wav2Vec的微调方法。", "keywords": "听力困难时刻, 对话音频, 机器学习, 音频语言模型, 听力辅助技术", "comments": "本文的创新之处在于将音频语言模型应用于识别对话中的听力困难时刻，并证明了其在性能上优于传统ASR方法。这项研究对于开发实时听力辅助技术具有重要意义，能够为听障人士提供更及时、有效的帮助。"}}
{"id": "2507.23547", "title": "Quantum simulation of Helmholtz equations via Schr{ö}dingerization", "authors": ["Anjiao Gu", "Shi Jin", "Chuwen Ma"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23547v1", "summary": "The Helmholtz equation is a prototypical model for time-harmonic wave\npropagation. Numerical solutions become increasingly challenging as the wave\nnumber $k$ grows, due to the equation's elliptic yet noncoercive character and\nthe highly oscillatory nature of its solutions, with wavelengths scaling as\n$1/k$. These features lead to strong indefiniteness and large system sizes.\n  We present a quantum algorithm for solving such indefinite problems, built\nupon the Schr\\\"odingerization framework. This approach reformulates linear\ndifferential equations into Schr\\\"odinger-type systems by capturing the steady\nstate of damped dynamics. A warped phase transformation lifts the original\nproblem to a higher-dimensional formulation, making it compatible with quantum\ncomputation. To suppress numerical pollution, the algorithm incorporates\nasymptotic dispersion correction. It achieves a query complexity of\n$\\mathcal{O}(\\kappa^2\\text{polylog}\\varepsilon^{-1})$, where $\\kappa$ is the\ncondition number and $\\varepsilon$ the desired accuracy. For the Helmholtz\nequation, a simple preconditioner further reduces the complexity to\n$\\mathcal{O}(\\kappa\\text{polylog}\\varepsilon^{-1})$. Our constructive extension\nto the quantum setting is broadly applicable to all indefinite problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23547v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "通过薛定谔化量子模拟亥姆霍兹方程", "tldr": "该论文提出了一种基于薛定谔化框架的量子算法，用于高效解决亥姆霍兹方程等不确定性问题，并展示了改进的查询复杂度。", "motivation": "亥姆霍兹方程是时间谐波传播的典型模型，但当波数 $k$ 增大时，由于其椭圆而非强制性、解的高度振荡性、强不确定性及系统规模大，数值求解变得极具挑战性。", "method": "本文提出了一种基于“薛定谔化”框架的量子算法。该方法通过捕获阻尼动力学的稳态，将线性微分方程重新表述为薛定谔型系统。通过“扭曲相位变换”将原始问题提升到更高维度的公式，使其与量子计算兼容。为抑制数值污染，算法还引入了渐近色散校正。", "result": "该算法实现了 $\\mathcal{O}(\\kappa^2\\text{polylog}\\varepsilon^{-1})$ 的查询复杂度，其中 $\\kappa$ 是条件数，$\\varepsilon$ 是所需精度。对于亥姆霍兹方程，一个简单的预处理器将复杂度进一步降低到 $\\mathcal{O}(\\kappa\\text{polylog}\\varepsilon^{-1})$。", "conclusion": "这种对量子设置的建设性扩展广泛适用于所有不确定性问题。", "translation": "亥姆霍兹方程是时间谐波传播的典型模型。当波数 $k$ 增大时，由于方程的椭圆而非强制性特征以及其解的高度振荡性（波长按 $1/k$ 缩放），数值解变得越来越具有挑战性。这些特点导致了强不确定性和庞大的系统规模。我们提出了一种基于薛定谔化框架的量子算法，用于解决此类不确定性问题。这种方法通过捕获阻尼动力学的稳态，将线性微分方程重新表述为薛定谔型系统。扭曲相位变换将原始问题提升到更高维度的公式，使其与量子计算兼容。为了抑制数值污染，该算法结合了渐近色散校正。它实现了 $\\mathcal{O}(\\kappa^2\\text{polylog}\\varepsilon^{-1})$ 的查询复杂度，其中 $\\kappa$ 是条件数，$\\varepsilon$ 是所需精度。对于亥姆霍兹方程，一个简单的预处理器将复杂度进一步降低到 $\\mathcal{O}(\\kappa\\text{polylog}\\varepsilon^{-1})$。我们对量子设置的建设性扩展广泛适用于所有不确定性问题。", "summary": "本文提出了一种创新的量子算法，利用“薛定谔化”框架解决亥姆霍兹方程等难以处理的不确定性问题。该算法通过将微分方程转换为薛定谔型系统，并结合扭曲相位变换和渐近色散校正，实现了在条件数和所需精度方面的次多项式查询复杂度，尤其对于亥姆霍兹方程通过预处理可进一步优化，表明其对广泛不确定性问题的普适性。", "keywords": "量子模拟, 亥姆霍兹方程, 薛定谔化, 查询复杂度, 不确定性问题", "comments": "这篇论文通过将经典的亥姆霍兹方程问题巧妙地映射到量子计算框架中，展示了量子算法在解决传统数值方法难以应对的复杂波动方程方面的潜力。其创新点在于采用了“薛定谔化”和“扭曲相位变换”来克服不确定性和高振荡性带来的挑战，并给出了具体的复杂度分析，尤其预处理器对亥姆霍兹方程的复杂度优化是其亮点。这为量子计算在科学计算领域的应用开辟了新的途径。"}}
{"id": "2507.18675", "title": "Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks", "authors": ["Utkarsh Shandilya", "Marsha Mariya Kappan", "Sanyam Jain", "Vijeta Sharma"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18675v2", "summary": "Human action recognition plays a critical role in healthcare and medicine,\nsupporting applications such as patient behavior monitoring, fall detection,\nsurgical robot supervision, and procedural skill assessment. While traditional\nmodels like CNNs and RNNs have achieved moderate success, they often struggle\nto generalize across diverse and complex actions. Recent advancements in\nvision-language models, especially the transformer-based CLIP model, offer\npromising capabilities for generalizing action recognition from video data. In\nthis work, we evaluate CLIP on the UCF-101 dataset and systematically analyze\nits performance under three masking strategies: (1) percentage-based and\nshape-based black masking at 10%, 30%, and 50%, (2) feature-specific masking to\nsuppress bias-inducing elements, and (3) isolation masking that retains only\nclass-specific regions. Our results reveal that CLIP exhibits inconsistent\nbehavior and frequent misclassifications, particularly when essential visual\ncues are obscured. To overcome these limitations, we propose incorporating\nclass-specific noise, learned via a custom loss function, to reinforce\nattention to class-defining features. This enhancement improves classification\naccuracy and model confidence while reducing bias. We conclude with a\ndiscussion on the challenges of applying such models in clinical domains and\noutline directions for future work to improve generalizability across\ndomain-independent healthcare scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18675v2", "cate": "cs.CV", "date": "2025-07-24", "updated": "2025-07-30", "AI": {"title_translation": "推进基于视觉的人体动作识别：探索视觉-语言CLIP模型在领域无关任务中的泛化能力", "tldr": "本文评估了CLIP模型在人体动作识别中的泛化能力，发现其在视觉信息受损时表现不佳。为解决此问题，提出通过引入类别特异性噪声来增强模型对关键特征的关注，从而提升了准确性和鲁棒性，并讨论了其在临床应用中的挑战。", "motivation": "人体动作识别在医疗领域（如患者行为监测、跌倒检测）中至关重要。传统模型（CNNs, RNNs）在处理复杂多样动作时泛化能力不足。视觉-语言模型（尤其是CLIP）显示出前景，但其泛化能力仍需深入评估。", "method": "在UCF-101数据集上评估CLIP模型，并系统分析其在三种遮蔽策略下的性能：基于百分比和形状的黑块遮蔽、特征特异性遮蔽以及隔离遮蔽。为克服限制，提出通过自定义损失函数学习类别特异性噪声，以强化模型对类别定义特征的注意力。", "result": "CLIP在关键视觉线索被遮蔽时表现出不一致的行为和频繁的错误分类。通过引入类别特异性噪声的增强方法，提高了分类准确性、模型置信度并减少了偏差。", "conclusion": "讨论了此类模型在临床领域应用面临的挑战，并提出了未来工作方向，以提高在领域无关医疗场景中的泛化能力。", "translation": "人体动作识别在医疗保健和医学中扮演着关键角色，支持患者行为监测、跌倒检测、手术机器人监督和程序技能评估等应用。尽管传统的模型如CNN和RNN取得了适度的成功，但它们在泛化处理多样和复杂动作时常常遇到困难。视觉-语言模型，特别是基于Transformer的CLIP模型，在从视频数据中泛化动作识别方面提供了有前景的能力。在这项工作中，我们在UCF-101数据集上评估了CLIP，并系统分析了其在三种遮蔽策略下的性能：（1）10%、30%和50%的基于百分比和形状的黑色遮蔽，（2）特征特异性遮蔽以抑制引起偏差的元素，以及（3）仅保留类别特异性区域的隔离遮蔽。我们的结果显示，CLIP表现出不一致的行为和频繁的错误分类，尤其是在关键视觉线索被遮蔽时。为了克服这些限制，我们提出通过自定义损失函数学习类别特异性噪声，以强化对类别定义特征的注意力。这种增强提高了分类准确性和模型置信度，同时减少了偏差。最后，我们讨论了此类模型在临床领域应用中面临的挑战，并概述了未来工作方向，以提高在领域无关医疗场景中的泛化能力。", "summary": "本文旨在提升基于视觉的人体动作识别在领域无关任务中的泛化能力，尤其是在医疗健康领域的应用。研究人员评估了视觉-语言CLIP模型在UCF-101数据集上的表现，通过多种遮蔽策略分析其鲁棒性。结果显示CLIP在关键视觉线索缺失时表现不佳。为解决此问题，研究提出引入通过自定义损失函数学习的类别特异性噪声，以增强模型对核心特征的关注。该方法有效提高了分类准确性、置信度并减少了偏差。文章最后讨论了此类模型在临床应用中的挑战及未来研究方向。", "keywords": "人体动作识别, CLIP模型, 视觉-语言模型, 泛化能力, 医疗应用", "comments": "创新点：首次系统性地评估了CLIP模型在人体动作识别中在不同视觉信息缺失情况下的鲁棒性，并提出了通过引入类别特异性噪声来增强模型对关键特征关注的新方法。重要性：解决了现有模型在复杂动作泛化能力上的不足，提升了CLIP模型在医疗等关键领域应用的潜力，尤其是在处理不完整或受损视觉数据时的性能。局限性：论文提到了在临床应用中的挑战，表明模型仍需进一步优化以适应实际医疗场景的复杂性和严格要求。"}}
{"id": "2507.23276", "title": "How Far Are AI Scientists from Changing the World?", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23276v1", "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23276v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "AI科学家离改变世界还有多远？", "tldr": "本综述探讨了AI科学家系统在科学研究中的现状、瓶颈以及未来发展方向。", "motivation": "大型语言模型（LLMs）的兴起推动了自动化科学发现，LLM驱动的AI科学家系统在科学研究中占据主导地位。鉴于AI生成的研究论文已被接受，作者旨在探讨AI科学家离改变世界和重塑科学研究范式还有多远，并希望本综述能帮助理解当前AI科学家系统的局限性，明确现状、缺失之处以及科学AI的最终目标。", "method": "本研究提供了一项以前景为导向的综述（prospect-driven review），全面分析了AI科学家系统当前的成就，并识别了关键瓶颈以及能够产生突破性发现并解决重大挑战的科学智能体出现所需的关键组成部分。", "result": "本综述识别了AI科学家系统的关键瓶颈和实现突破性发现所需的关键组成部分。", "conclusion": "本综述旨在帮助人们更清晰地理解当前AI科学家系统的局限性，明确我们所处的位置、缺失之处以及科学AI的最终目标。", "translation": "大型语言模型（LLMs）的出现正在将自动化科学发现推向新的高度，基于LLM的人工智能（AI）科学家系统现在在科学研究中处于领先地位。AI科学家领域已经出现了一些有影响力的工作，AI生成的研究论文已被ICLR 2025研讨会接受，这表明能够揭示人类以前未知现象的人类水平AI科学家可能很快就会成为现实。在本综述中，我们关注核心问题：AI科学家离改变世界和重塑科学研究范式还有多远？为了回答这个问题，我们提供了一项以前景为导向的综述，全面分析了AI科学家系统当前的成就，识别了关键瓶颈以及能够产生突破性发现并解决重大挑战的科学智能体出现所需的关键组成部分。我们希望本综述能有助于更清晰地理解当前AI科学家系统的局限性，展示我们所处的位置、缺失之处以及科学AI的最终目标。", "summary": "本综述探讨了大型语言模型（LLMs）驱动的AI科学家系统在科学发现中的现状和潜力。作者旨在回答AI科学家离改变世界还有多远，并为此提供了一项前景导向的综述，分析了现有成就、识别了关键瓶颈以及实现突破性科学发现所需的关键要素。该研究旨在增进对当前AI科学家系统局限性的理解，并指明科学AI的未来方向和最终目标。", "keywords": "AI科学家, 大型语言模型, 科学发现, 综述, 瓶颈", "comments": "这篇论文是一篇综述性文章，其创新点在于对新兴的AI科学家领域进行了前瞻性审视，并提出了关键瓶颈和未来发展方向。其重要性在于为该领域的研究人员和政策制定者提供了现状评估和未来愿景，有助于引导后续的研究和投资。它清晰地指出了当前AI科学家系统的局限性，并设定了宏伟的长期目标，即实现能发现人类未知现象的AI。"}}
{"id": "2507.23217", "title": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "authors": ["Hyeon Seong Jeong", "Sangwoo Jo", "Byeong Hyun Yoon", "Yoonseok Heo", "Haedong Jeong", "Taehoon Kim"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23217v1", "summary": "Understanding complex multimodal documents remains challenging due to their\nstructural inconsistencies and limited training data availability. We introduce\n\\textit{DocsRay}, a training-free document understanding system that integrates\npseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented\nGeneration (RAG). Our approach leverages multimodal Large Language Models'\n(LLMs) native capabilities to seamlessly process documents containing diverse\nelements such as text, images, charts, and tables without requiring specialized\nmodels or additional training. DocsRay's framework synergistically combines\nthree key techniques: (1) a semantic structuring module using prompt-based LLM\ninteractions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal\nanalysis that converts diverse document elements into unified, text-centric\nrepresentations using the inherent capabilities of multimodal LLMs, and (3) an\nefficient two-stage hierarchical retrieval system that reduces retrieval\ncomplexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents\naveraging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency\nfrom 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the\nMMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,\nsubstantially surpassing previous state-of-the-art results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23217v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "零样本文档理解：基于伪目录引导的检索增强生成", "tldr": "DocsRay是一个无需训练的文档理解系统，通过伪目录和分层RAG，利用多模态LLM处理复杂文档，显著提高效率和准确性。", "motivation": "复杂多模态文档理解因结构不一致和训练数据有限而面临挑战。", "method": "引入了DocsRay，一个无需训练的文档理解系统，整合了伪目录生成与分层检索增强生成（RAG）。它利用多模态大型语言模型（LLM）的原生能力，无需专门模型或额外训练即可无缝处理包含文本、图像、图表和表格等多样元素的文档。DocsRay的框架协同结合了三项关键技术：1) 基于提示的LLM交互生成分层伪TOC的语义结构模块；2) 零样本多模态分析，利用多模态LLM的固有能力将多样化的文档元素转换为统一的、以文本为中心的表示；3) 将检索复杂度从O(N)降低到O(S + k1 * Ns)的高效两阶段分层检索系统。", "result": "在平均49.4页和20,971个文本标记的文档上，DocsRay将查询延迟从3.89秒减少到2.12秒，实现了45%的效率提升。在MMLongBench-Doc基准测试中，DocsRay-Pro的准确率达到64.7%，显著超越了现有最先进水平。", "conclusion": "DocsRay通过结合伪目录引导和分层RAG，为复杂多模态文档理解提供了一个高效且准确的零样本解决方案，显著提升了性能并降低了延迟。", "translation": "理解复杂的多模态文档仍然具有挑战性，这归因于其结构不一致和训练数据可用性有限。我们引入了 \\textit{DocsRay}，一个无需训练的文档理解系统，它将伪目录（TOC）生成与分层检索增强生成（RAG）相结合。我们的方法利用多模态大型语言模型（LLM）的固有能力，无需专门模型或额外训练即可无缝处理包含文本、图像、图表和表格等多样元素的文档。DocsRay 的框架协同结合了三项关键技术：(1) 一个语义结构模块，使用基于提示的LLM交互生成分层伪TOC；(2) 零样本多模态分析，利用多模态LLM的固有能力将多样化的文档元素转换为统一的、以文本为中心的表示；(3) 一个高效的两阶段分层检索系统，将检索复杂度从 $O(N)$ 降低到 $O(S + k_1 \\cdot N_s)$。在平均49.4页和20,971个文本标记的文档上进行评估，DocsRay 将查询延迟从3.89秒减少到2.12秒，实现了45%的效率提升。在 MMLongBench-Doc 基准测试中，DocsRay-Pro 的准确率达到64.7%，显著超越了现有最先进水平。", "summary": "DocsRay是一个无需训练的零样本文档理解系统，旨在解决复杂多模态文档理解的挑战。它通过整合伪目录生成和分层检索增强生成（RAG），利用多模态LLM的原生能力处理多样化的文档元素。该系统包含语义结构模块、零样本多模态分析和高效的两阶段分层检索系统。实验结果表明，DocsRay显著提高了查询效率并提升了在MMLongBench-Doc上的准确率，超越了现有SOTA。", "keywords": "零样本, 文档理解, 检索增强生成, 多模态LLM, 伪目录", "comments": "DocsRay的创新之处在于其无需训练的零样本方法，以及将伪目录生成与分层RAG相结合，有效利用多模态LLM处理复杂文档。这种方法显著降低了对大量标注数据的依赖，并提升了处理效率和准确性，对于实际应用具有重要意义。"}}
{"id": "2503.12725", "title": "Humanoids in Hospitals: A Technical Study of Humanoid Robot Surrogates for Dexterous Medical Interventions", "authors": ["Soofiyan Atar", "Xiao Liang", "Calvin Joyce", "Florian Richter", "Wood Ricardo", "Charles Goldberg", "Preetham Suresh", "Michael Yip"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2503.12725v2", "summary": "The increasing demand for healthcare workers, driven by aging populations and\nlabor shortages, presents a significant challenge for hospitals. Humanoid\nrobots have the potential to alleviate these pressures by leveraging their\nhuman-like dexterity and adaptability to assist in medical procedures. This\nwork conducted an exploratory study on the feasibility of humanoid robots\nperforming direct clinical tasks through teleoperation. A bimanual\nteleoperation system was developed for the Unitree G1 Humanoid Robot,\nintegrating high-fidelity pose tracking, custom grasping configurations, and an\nimpedance controller to safely and precisely manipulate medical tools. The\nsystem is evaluated in seven diverse medical procedures, including physical\nexaminations, emergency interventions, and precision needle tasks. Our results\ndemonstrate that humanoid robots can successfully replicate critical aspects of\nhuman medical assessments and interventions, with promising quantitative\nperformance in ventilation and ultrasound-guided tasks. However, challenges\nremain, including limitations in force output for procedures requiring high\nstrength and sensor sensitivity issues affecting clinical accuracy. This study\nhighlights the potential and current limitations of humanoid robots in hospital\nsettings and lays the groundwork for future research on robotic healthcare\nintegration.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2503.12725v2", "cate": "cs.RO", "date": "2025-03-17", "updated": "2025-07-31", "AI": {"title_translation": "医院中的人形机器人：用于灵巧医疗干预的人形机器人替代物的技术研究", "tldr": "本研究探讨了人形机器人在医院中通过远程操作执行医疗任务的可行性及其当前局限性。", "motivation": "医疗保健工作者需求增加（人口老龄化和劳动力短缺）对医院构成挑战，人形机器人有望缓解这些压力。", "method": "进行了一项探索性研究，开发了一个用于Unitree G1人形机器人的双手远程操作系统，集成了高保真姿态跟踪、自定义抓取配置和阻抗控制器，以安全精确地操作医疗工具。该系统在七种不同的医疗程序中进行了评估。", "result": "人形机器人可以成功复制人类医疗评估和干预的关键方面，在通气和超声引导任务中表现出良好的定量性能。然而，仍存在挑战，包括需要高强度的程序中力输出的限制以及影响临床准确性的传感器灵敏度问题。", "conclusion": "本研究强调了人形机器人在医院环境中的潜力和当前局限性，并为未来机器人医疗整合研究奠定了基础。", "translation": "医院中对医疗保健工作者日益增长的需求，受人口老龄化和劳动力短缺的推动，给医院带来了巨大挑战。人形机器人通过利用其类人灵巧性和适应性来协助医疗程序，有可能缓解这些压力。这项工作对人形机器人通过远程操作执行直接临床任务的可行性进行了一项探索性研究。为Unitree G1人形机器人开发了一个双手远程操作系统，集成了高保真姿态跟踪、自定义抓取配置和阻抗控制器，以安全精确地操作医疗工具。该系统在七种不同的医疗程序中进行了评估，包括体格检查、紧急干预和精确穿刺任务。我们的结果表明，人形机器人可以成功复制人类医疗评估和干预的关键方面，在通气和超声引导任务中表现出良好的定量性能。然而，挑战依然存在，包括需要高强度的程序中力输出的限制以及影响临床准确性的传感器灵敏度问题。这项研究强调了人形机器人在医院环境中的潜力和当前局限性，并为未来机器人医疗整合的研究奠定了基础。", "summary": "本文探讨了人形机器人作为医疗干预替代物在医院中的应用潜力。研究开发了一个用于Unitree G1人形机器人的双手远程操作系统，该系统集成了先进的姿态跟踪、抓取配置和阻抗控制，以执行各种医疗任务。实验结果表明，人形机器人能够成功模仿人类医疗评估和干预，在特定任务中表现良好，但仍面临力输出和传感器灵敏度的挑战。该研究为未来机器人医疗整合奠定了基础。", "keywords": "人形机器人, 医疗干预, 远程操作, 医院应用, 机器人辅助医疗", "comments": "这项研究在探索人形机器人在医疗领域的应用方面具有创新性，特别是在远程操作和模拟人类灵巧性方面。它不仅展示了人形机器人的巨大潜力，也坦诚地指出了当前的技术局限性，为未来的研究方向提供了清晰的指引。其重要性在于为缓解医疗劳动力短缺提供了一种潜在的解决方案。"}}
{"id": "2507.23509", "title": "I Am Big, You Are Little; I Am Right, You Are Wrong", "authors": ["David A. Kelly", "Akchunya Chanchal", "Nathan Blake"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, International Conference on Computer Vision, ICCV 2025", "url": "http://arxiv.org/abs/2507.23509v1", "summary": "Machine learning for image classification is an active and rapidly developing\nfield. With the proliferation of classifiers of different sizes and different\narchitectures, the problem of choosing the right model becomes more and more\nimportant.\n  While we can assess a model's classification accuracy statistically, our\nunderstanding of the way these models work is unfortunately limited. In order\nto gain insight into the decision-making process of different vision models, we\npropose using minimal sufficient pixels sets to gauge a model's\n`concentration': the pixels that capture the essence of an image through the\nlens of the model. By comparing position, overlap, and size of sets of pixels,\nwe identify that different architectures have statistically different\nconcentration, in both size and position. In particular, ConvNext and EVA\nmodels differ markedly from the others. We also identify that images which are\nmisclassified are associated with larger pixels sets than correct\nclassifications.", "comment": "10 pages, International Conference on Computer Vision, ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23509v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "我大你小；我对我错", "tldr": "本研究通过“最小足够像素集”分析不同图像分类模型的决策过程，发现不同架构模型（特别是ConvNext和EVA）的像素关注点存在显著差异，且错误分类通常与更大的像素集相关。", "motivation": "机器学习图像分类是一个活跃且快速发展的领域。随着不同大小和架构分类器的激增，选择合适的模型变得越来越重要。尽管可以统计评估模型的分类准确性，但对这些模型工作方式的理解有限。因此，需要深入了解不同视觉模型的决策过程。", "method": "提出使用“最小足够像素集”来衡量模型的“集中度”（即通过模型视角捕捉图像本质的像素）。通过比较像素集的位置、重叠和大小，来识别不同架构模型的集中度差异。", "result": "发现不同架构的模型在像素集的集中度（大小和位置）上存在统计学上的显著差异。特别是ConvNext和EVA模型与其他模型明显不同。此外，识别出被错误分类的图像与比正确分类更大的像素集相关联。", "conclusion": "通过分析最小足够像素集，揭示了不同视觉模型（特别是ConvNext和EVA）在决策过程中像素关注点的差异性，并发现错误分类与模型关注的更大像素区域相关，从而提供了对模型工作方式的深入洞察。", "translation": "机器学习图像分类是一个活跃且快速发展的领域。随着不同大小和不同架构分类器的激增，选择合适的模型变得越来越重要。\n尽管我们可以统计评估模型的分类准确性，但遗憾的是，我们对这些模型工作方式的理解有限。为了深入了解不同视觉模型的决策过程，我们提出使用最小足够像素集来衡量模型的“集中度”：即通过模型的视角捕捉图像本质的像素。通过比较像素集的位置、重叠和大小，我们发现不同架构在集中度的大小和位置上存在统计学上的显著差异。特别是ConvNext和EVA模型与其他模型明显不同。我们还发现被错误分类的图像与比正确分类更大的像素集相关。", "summary": "本研究旨在深入理解图像分类模型的决策过程，提出了一种通过“最小足够像素集”衡量模型“集中度”的新方法。通过分析像素集的位置、重叠和大小，发现不同模型架构（如ConvNext和EVA）在关注像素集的大小和位置上存在显著的统计学差异。研究还揭示了错误分类的图像通常与模型关注的更大像素集相关联，为理解模型行为提供了新的视角。", "keywords": "图像分类, 机器学习, 模型解释, 像素集, 模型集中度", "comments": "这篇论文的创新点在于提出了“最小足够像素集”这一新颖的概念，用于量化和理解图像分类模型的内部决策机制，而不仅仅是评估其最终准确性。它提供了一种可解释性工具，能够揭示不同模型架构在关注图像特征上的差异，特别是指出了ConvNext和EVA模型的独特性。此外，将错误分类与更大的像素集关联起来，为模型诊断和改进提供了潜在方向。这项工作对于提升机器学习模型的可解释性和透明度具有重要意义。"}}
{"id": "2410.02744", "title": "Neutral Residues: Revisiting Adapters for Model Extension", "authors": ["Franck Signe Talla", "Edouard Grave", "Hervé Jégou"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025", "url": "http://arxiv.org/abs/2410.02744v3", "summary": "We address the problem of extending a pretrained large language model to a\nnew domain that was not seen during training. Standard techniques, such as\nfinetuning or low-rank adaptation (LoRA) are successful at domain adaptation,\nbut do not formally add capacity to the model. This often leads to a trade-off,\nbetween performing well on the new domain vs. degrading performance on the\noriginal domain. Here, we revisit and improve adapters to extend LLMs from\nthree angles: data, architecture and training procedure, which are\nadvantageously considered jointly. The resulting method, called neutral\nresidues, modifies adapters in a way that leads each new residual block to\noutput near-zeros on the original domain. This solution leads to strong results\nwhen adapting a state-of-the-art model originally trained on English to a new\nlanguage. Neutral residues significantly outperform competing approaches such\nas finetuning, LoRA or vanilla adapters in terms of the trade-off between\nlearning the new language and not forgetting English.", "comment": "Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2410.02744v3", "cate": "cs.CL", "date": "2024-10-03", "updated": "2025-07-31", "AI": {"title_translation": "中性残差：重新审视用于模型扩展的适配器", "tldr": "本文提出了一种名为“中性残差”的新方法，通过修改适配器来扩展预训练大型语言模型到新领域，同时避免在原始领域性能下降，并在新语言适应任务上表现出色。", "motivation": "标准技术（如微调或LoRA）在领域适应方面取得成功，但没有正式增加模型容量，这通常导致在新领域表现良好与原始领域性能下降之间的权衡。本文旨在解决将预训练大型语言模型扩展到新领域时，避免原始领域性能下降的问题。", "method": "本文重新审视并改进了适配器，从数据、架构和训练过程三个角度共同考虑来扩展大型语言模型。提出的方法称为“中性残差”，它修改适配器，使每个新的残差块在原始领域输出接近零，从而在学习新语言的同时不遗忘英语。", "result": "中性残差方法在将最先进的英语模型适应新语言时取得了显著效果。它在学习新语言和不遗忘英语之间的权衡方面，显著优于微调、LoRA或普通适配器等竞争方法。", "conclusion": "中性残差是一种有效的方法，可以扩展预训练的大型语言模型到新领域，同时有效缓解在原始领域性能下降的问题，并在跨语言适应任务中表现出优越的性能。", "translation": "我们解决了将预训练大型语言模型扩展到训练期间未见过的新领域的问题。标准技术，如微调或低秩适应（LoRA），在领域适应方面是成功的，但没有正式增加模型的容量。这通常导致在新领域表现良好与原始领域性能下降之间的权衡。在这里，我们重新审视并改进了适配器，从数据、架构和训练过程三个角度共同扩展大型语言模型，这些角度被有利地联合考虑。由此产生的方法，称为中性残差，以一种方式修改适配器，使得每个新的残差块在原始领域输出接近零。这种解决方案在将最初用英语训练的最先进模型适应新语言时取得了显著效果。中性残差在学习新语言和不遗忘英语之间的权衡方面，显著优于微调、LoRA或普通适配器等竞争方法。", "summary": "本文提出了一种名为“中性残差”的新方法，用于扩展预训练的大型语言模型到新领域，旨在解决现有方法（如微调和LoRA）在领域适应中可能导致的原始领域性能下降问题。该方法通过从数据、架构和训练过程三个方面改进适配器，使得新的残差块在原始领域输出接近零。实验结果表明，中性残差在跨语言适应任务中表现出色，显著优于现有竞争方法，有效平衡了新领域学习与原始领域知识保留。", "keywords": "中性残差, 适配器, 模型扩展, 领域适应, 大型语言模型", "comments": "本文的创新之处在于提出了“中性残差”的概念，通过巧妙地修改适配器结构，使得新增的容量在原始领域表现为“中性”，从而有效缓解了灾难性遗忘问题。这种方法为大型语言模型在多领域扩展和持续学习方面提供了有价值的思路，尤其是在需要平衡新旧知识的场景下。"}}
{"id": "2504.13593", "title": "KAN or MLP? Point Cloud Shows the Way Forward", "authors": ["Yan Shi", "Qingdong He", "Yijun Liu", "Xiaoyu Liu", "Jingyong Su"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13593v2", "summary": "Multi-Layer Perceptrons (MLPs) have become one of the fundamental\narchitectural component in point cloud analysis due to its effective feature\nlearning mechanism. However, when processing complex geometric structures in\npoint clouds, MLPs' fixed activation functions struggle to efficiently capture\nlocal geometric features, while suffering from poor parameter efficiency and\nhigh model redundancy. In this paper, we propose PointKAN, which applies\nKolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigate\ntheir efficacy in hierarchical feature representation. First, we introduce a\nGeometric Affine Module (GAM) to transform local features, improving the\nmodel's robustness to geometric variations. Next, in the Local Feature\nProcessing (LFP), a parallel structure extracts both group-level features and\nglobal context, providing a rich representation of both fine details and\noverall structure. Finally, these features are combined and processed in the\nGlobal Feature Processing (GFP). By repeating these operations, the receptive\nfield gradually expands, enabling the model to capture complete geometric\ninformation of the point cloud. To overcome the high parameter counts and\ncomputational inefficiency of standard KANs, we develop Efficient-KANs in the\nPointKAN-elite variant, which significantly reduces parameters while\nmaintaining accuracy. Experimental results demonstrate that PointKAN\noutperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN,\nand ShapeNetPart, with particularly strong performance in Few-shot Learning\ntask. Additionally, PointKAN achieves substantial reductions in parameter\ncounts and computational complexity (FLOPs). This work highlights the potential\nof KANs-based architectures in 3D vision and opens new avenues for research in\npoint cloud understanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13593v2", "cate": "cs.CV", "date": "2025-04-18", "updated": "2025-07-31", "AI": {"title_translation": "KAN还是MLP？点云指明前进方向", "tldr": "本文提出了PointKAN，将Kolmogorov-Arnold网络（KANs）应用于点云分析，以解决传统MLP在处理复杂点云几何结构时效率低、参数冗余的问题。PointKAN通过引入几何仿射模块（GAM）、并行局部特征处理（LFP）和全局特征处理（GFP）来增强特征表示能力，并通过Efficient-KANs显著减少参数。实验证明PointKAN在多个基准数据集上优于PointMLP，并降低了计算成本，展现了KANs在3D视觉领域的潜力。", "motivation": "多层感知机（MLPs）在点云分析中作为基础架构组件，但在处理复杂的点云几何结构时，其固定激活函数难以有效捕获局部几何特征，且存在参数效率低下和模型冗余的问题。", "method": "本文提出了PointKAN，将Kolmogorov-Arnold网络（KANs）应用于点云分析任务。首先，引入了几何仿射模块（GAM）来转换局部特征，提高模型对几何变化的鲁棒性。其次，在局部特征处理（LFP）中，采用并行结构提取组级特征和全局上下文。最后，这些特征在全局特征处理（GFP）中组合和处理。通过重复这些操作，感受野逐渐扩展以捕获完整的几何信息。为了克服标准KANs高参数量和计算效率低的问题，在PointKAN-elite变体中开发了Efficient-KANs。", "result": "实验结果表明，PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上优于PointMLP，在少样本学习任务中表现尤为出色。此外，PointKAN显著减少了参数数量和计算复杂度（FLOPs）。", "conclusion": "这项工作突出了基于KANs的架构在3D视觉中的潜力，并为点云理解领域的研究开辟了新途径。", "translation": "多层感知机（MLPs）由于其有效的特征学习机制，已成为点云分析中基本的架构组件之一。然而，在处理点云中复杂的几何结构时，MLPs固定的激活函数难以有效地捕获局部几何特征，同时还存在参数效率低下和模型冗余的问题。在本文中，我们提出了PointKAN，它将Kolmogorov-Arnold网络（KANs）应用于点云分析任务，以研究它们在分层特征表示中的有效性。首先，我们引入了几何仿射模块（GAM）来转换局部特征，提高了模型对几何变化的鲁棒性。其次，在局部特征处理（LFP）中，并行结构提取组级特征和全局上下文，提供了细节和整体结构的丰富表示。最后，这些特征在全局特征处理（GFP）中组合和处理。通过重复这些操作，感受野逐渐扩展，使模型能够捕获点云的完整几何信息。为了克服标准KANs高参数量和计算效率低的问题，我们在PointKAN-elite变体中开发了Efficient-KANs，它在保持精度的同时显著减少了参数。实验结果表明，PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上优于PointMLP，在少样本学习任务中表现尤为出色。此外，PointKAN显著减少了参数数量和计算复杂度（FLOPs）。这项工作突出了基于KANs的架构在3D视觉中的潜力，并为点云理解领域的研究开辟了新途径。", "summary": "本文提出PointKAN，将Kolmogorov-Arnold网络（KANs）引入点云分析领域，旨在克服传统多层感知机（MLP）在处理复杂几何结构时面临的特征捕获效率低、参数冗余等问题。PointKAN通过集成几何仿射模块（GAM）、并行局部特征处理（LFP）和全局特征处理（GFP）来增强模型的特征学习能力和鲁棒性。为解决KANs的计算效率问题，作者还开发了高效的Efficient-KANs。实验证明，PointKAN在多个标准点云数据集（如ModelNet40、ScanObjectNN、ShapeNetPart）上性能优于PointMLP，尤其在少样本学习任务中表现突出，并显著降低了模型参数量和计算复杂度。该研究强调了基于KANs的架构在3D视觉领域的应用前景。", "keywords": "Kolmogorov-Arnold Networks, 点云分析, PointKAN, 3D视觉, Efficient-KANs", "comments": "这篇论文的创新点在于首次将Kolmogorov-Arnold网络（KANs）引入到点云分析领域，并针对KANs本身的计算效率问题提出了Efficient-KANs，这对于推动3D视觉领域，特别是点云理解的发展具有重要意义。通过结合几何仿射模块和多尺度特征处理，PointKAN有效解决了MLP在处理复杂几何结构时的局限性，展现了KANs在捕获复杂局部特征和构建分层表示方面的潜力。其在性能提升和计算效率优化方面的成果，为未来基于KANs的3D视觉模型研究奠定了基础。"}}
{"id": "2507.23273", "title": "GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting", "authors": ["Jaeseok Park", "Chanoh Park", "Minsu Kim", "Soohwan Kim"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23273v1", "summary": "While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic mapping,\nconventional approaches based on camera sensor, even RGB-D, suffer from\nfundamental limitations such as high computational load, failure in\nenvironments with poor texture or illumination, and short operational ranges.\nLiDAR emerges as a robust alternative, but its integration with 3DGS introduces\nnew challenges, such as the need for exceptional global alignment for\nphotorealistic quality and prolonged optimization times caused by sparse data.\nTo address these challenges, we propose GSFusion, an online\nLiDAR-Inertial-Visual mapping system that ensures high-precision map\nconsistency through a surfel-to-surfel constraint in the global pose-graph\noptimization. To handle sparse data, our system employs a pixel-aware Gaussian\ninitialization strategy for efficient representation and a bounded sigmoid\nconstraint to prevent uncontrolled Gaussian growth. Experiments on public and\nour datasets demonstrate our system outperforms existing 3DGS SLAM systems in\nterms of rendering quality and map-building efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23273v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "GSFusion：用于高斯泼溅的全局优化LiDAR-惯性-视觉建图", "tldr": "GSFusion是一个在线LiDAR-惯性-视觉建图系统，通过全局位姿图优化和稀疏数据处理策略，解决了3D高斯泼溅在相机和LiDAR集成中的局限性，提升了渲染质量和建图效率。", "motivation": "传统的基于相机传感器（包括RGB-D）的3D高斯泼溅（3DGS）方法存在计算负载高、在纹理或光照差的环境中失效以及操作范围短的局限性。而将LiDAR与3DGS集成则引入了新的挑战，例如需要卓越的全局对齐以实现逼真质量，以及稀疏数据导致的优化时间延长。", "method": "我们提出了GSFusion，一个在线LiDAR-惯性-视觉建图系统。它通过全局位姿图优化中的surfel-to-surfel约束来确保高精度地图一致性。为了处理稀疏数据，系统采用了像素感知的高斯初始化策略以实现高效表示，并使用有界sigmoid约束来防止不受控的高斯增长。", "result": "在公共数据集和我们自己的数据集上的实验表明，我们的系统在渲染质量和建图效率方面均优于现有的3DGS SLAM系统。", "conclusion": "GSFusion通过结合LiDAR、惯性传感器和视觉数据，并采用创新的优化和稀疏数据处理策略，成功克服了传统3DGS方法的限制以及LiDAR集成带来的挑战，显著提升了3D高斯泼溅的建图性能和渲染质量。", "translation": "尽管3D高斯泼溅（3DGS）彻底改变了照片级真实感建图，但传统的基于相机传感器（甚至RGB-D）的方法仍存在根本性局限，例如计算负载高、在纹理或光照差的环境中失效以及操作范围短。LiDAR作为一种鲁棒的替代方案出现，但其与3DGS的集成引入了新的挑战，例如需要卓越的全局对齐以实现照片级真实感质量，以及稀疏数据导致的优化时间延长。为了解决这些挑战，我们提出了GSFusion，一个在线LiDAR-惯性-视觉建图系统，通过全局位姿图优化中的surfel-to-surfel约束来确保高精度地图一致性。为了处理稀疏数据，我们的系统采用了像素感知的高斯初始化策略以实现高效表示，并使用有界sigmoid约束来防止不受控的高斯增长。在公共数据集和我们自己的数据集上的实验表明，我们的系统在渲染质量和建图效率方面均优于现有的3DGS SLAM系统。", "summary": "GSFusion是一个创新的在线LiDAR-惯性-视觉建图系统，旨在克服传统基于相机和LiDAR集成3D高斯泼溅（3DGS）方法的局限性。该系统通过在全局位姿图优化中引入surfel-to-surfel约束来确保地图的高精度一致性。为有效处理稀疏数据，GSFusion采用了像素感知的高斯初始化策略和有界sigmoid约束。实验结果表明，GSFusion在渲染质量和建图效率方面均优于现有3DGS SLAM系统。", "keywords": "3D Gaussian Splatting, LiDAR-Inertial-Visual Mapping, SLAM, Pose-Graph Optimization, Sparse Data Handling", "comments": "这项工作通过结合LiDAR、惯性传感器和视觉数据，为3D高斯泼溅提供了更鲁棒和高效的建图解决方案。其创新点在于提出了一种在线融合框架，并特别关注了稀疏LiDAR数据与3DGS的融合挑战，通过像素感知初始化和高斯增长约束有效地解决了这些问题。这对于在复杂环境中实现高质量、大范围的实时三维重建具有重要意义。"}}
{"id": "2507.23193", "title": "A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery", "authors": ["Youngsun Jang", "Dongyoun Kim", "Chulwoo Pack", "Kwanghee Won"], "categories": ["cs.CV", "I.4.6; I.2.10; I.5.4"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 2 figures. Presented at ACM RACS 2024 (Pompei, Italy, Nov 5-8, 2024)", "url": "http://arxiv.org/abs/2507.23193v1", "summary": "This study introduces a novel dataset for segmenting flooded areas in\nsatellite images. After reviewing 77 existing benchmarks utilizing satellite\nimagery, we identified a shortage of suitable datasets for this specific task.\nTo fill this gap, we collected satellite imagery of the 2019 Midwestern USA\nfloods from Planet Explorer by Planet Labs (Image \\c{opyright} 2024 Planet Labs\nPBC). The dataset consists of 10 satellite images per location, each containing\nboth flooded and non-flooded areas. We selected ten locations from each of the\nfive states: Iowa, Kansas, Montana, Nebraska, and South Dakota. The dataset\nensures uniform resolution and resizing during data processing. For evaluating\nsemantic segmentation performance, we tested state-of-the-art models in\ncomputer vision and remote sensing on our dataset. Additionally, we conducted\nan ablation study varying window sizes to capture temporal characteristics.\nOverall, the models demonstrated modest results, suggesting a requirement for\nfuture multimodal and temporal learning strategies. The dataset will be\npublicly available on\n<https://github.com/youngsunjang/SDSU_MidWest_Flood_2019>.", "comment": "8 pages, 2 figures. Presented at ACM RACS 2024 (Pompei, Italy, Nov\n  5-8, 2024)", "pdf_url": "http://arxiv.org/pdf/2507.23193v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一种用于卫星图像中洪水检测的新型数据集，对季节性变化具有鲁棒性", "tldr": "本文介绍了一个新的洪水检测卫星图像数据集，旨在解决现有数据集的不足，并发现当前模型性能一般，需要更先进的多模态和时间学习策略。", "motivation": "现有卫星图像洪水检测基准数据集不足以满足特定任务需求。", "method": "本研究通过收集2019年美国中西部洪水的卫星图像，创建了一个包含10个地点、每个地点10张图像（包含洪水和非洪水区域）的新型数据集。数据集确保了统一的分辨率和大小调整。为评估语义分割性能，研究团队测试了计算机视觉和遥感领域最先进的模型，并进行了一项消融研究以捕捉时间特征。", "result": "当前最先进的模型在该数据集上的表现平平。", "conclusion": "研究结果表明，未来需要开发多模态和时间学习策略来改进洪水检测的性能。", "translation": "这项研究引入了一个用于分割卫星图像中洪水区域的新型数据集。在审查了77个利用卫星图像的现有基准后，我们发现适合此特定任务的数据集存在短缺。为了填补这一空白，我们从Planet Labs的Planet Explorer收集了2019年美国中西部洪水的卫星图像（图像版权归2024年Planet Labs PBC所有）。该数据集包含每个地点10张卫星图像，每张图像都包含洪水和非洪水区域。我们从爱荷华州、堪萨斯州、蒙大拿州、内布拉斯加州和南达科他州这五个州各选择了十个地点。在数据处理过程中，数据集确保了统一的分辨率和大小调整。为了评估语义分割性能，我们测试了计算机视觉和遥感领域最先进的模型。此外，我们进行了一项消融研究，改变窗口大小以捕捉时间特征。总体而言，模型表现出一般的结果，这表明未来需要多模态和时间学习策略。该数据集将在https://github.com/youngsunjang/SDSU_MidWest_Flood_2019 公开可用。", "summary": "本研究提出了一个针对卫星图像洪水区域分割的新型数据集，旨在解决现有数据集的不足。该数据集包含了2019年美国中西部洪水的卫星图像，每地点10张图像，涵盖洪水和非洪水区域，并确保统一分辨率。通过对最先进模型的测试，发现现有模型性能一般，表明未来需要开发更先进的多模态和时间学习策略。该数据集将公开可用。", "keywords": "洪水检测, 卫星图像, 数据集, 语义分割, 时间学习", "comments": "该论文的创新点在于构建了一个新的、针对洪水检测的卫星图像数据集，填补了现有数据集的空白。其重要性在于为洪水检测研究提供了新的基准，并指出了当前模型在处理复杂季节变化和时间特征方面的局限性，为未来的研究方向提供了指导。数据集的公开可用性也促进了社区合作。"}}
{"id": "2507.23534", "title": "Continual Learning with Synthetic Boundary Experience Blending", "authors": ["Chih-Fan Hsu", "Ming-Ching Chang", "Wei-Chao Chen"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23534v1", "summary": "Continual learning (CL) aims to address catastrophic forgetting in models\ntrained sequentially on multiple tasks. While experience replay has shown\npromise, its effectiveness is often limited by the sparse distribution of\nstored key samples, leading to overly simplified decision boundaries. We\nhypothesize that introducing synthetic data near the decision boundary\n(Synthetic Boundary Data, or SBD) during training serves as an implicit\nregularizer, improving boundary stability and mitigating forgetting. To\nvalidate this hypothesis, we propose a novel training framework, {\\bf\nExperience Blending}, which integrates knowledge from both stored key samples\nand synthetic, boundary-adjacent data. Experience blending consists of two core\ncomponents: (1) a multivariate Differential Privacy (DP) noise mechanism that\ninjects batch-wise noise into low-dimensional feature representations,\ngenerating SBD; and (2) an end-to-end training strategy that jointly leverages\nboth stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100,\nand Tiny ImageNet demonstrate that our method outperforms nine CL baselines,\nachieving accuracy improvements of 10%, 6%, and 13%, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23534v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "具有合成边界经验混合的持续学习", "tldr": "该论文提出了一种名为“经验混合”的新型持续学习框架，通过引入决策边界附近的合成数据来提高边界稳定性并缓解灾难性遗忘，在多个数据集上显著优于现有基线。", "motivation": "持续学习旨在解决模型在顺序训练多个任务时出现的灾难性遗忘问题。经验回放虽然有前景，但其有效性常受限于存储关键样本的稀疏分布，导致决策边界过于简化。", "method": "本文提出了一种名为“经验混合”的新型训练框架，该框架整合了存储的关键样本和合成的、边界邻近的数据。经验混合包含两个核心组件：1) 一种多元差分隐私（DP）噪声机制，将批次噪声注入低维特征表示以生成合成边界数据（SBD）；2) 一种端到端训练策略，共同利用存储的关键样本和SBD。", "result": "在CIFAR-10、CIFAR-100和Tiny ImageNet上的大量实验表明，该方法优于九个持续学习基线，准确率分别提高了10%、6%和13%。", "conclusion": "通过引入决策边界附近的合成数据（SBD）并通过经验混合框架进行训练，可以有效提高决策边界的稳定性并缓解灾难性遗忘，从而在持续学习任务中取得卓越性能。", "translation": "持续学习（CL）旨在解决模型在多个任务上顺序训练时出现的灾难性遗忘问题。尽管经验回放已显示出前景，但其有效性常受限于存储关键样本的稀疏分布，导致决策边界过于简化。我们假设在训练期间引入决策边界附近的合成数据（合成边界数据，或SBD）作为一种隐式正则化器，可以提高边界稳定性并缓解遗忘。为了验证这一假设，我们提出了一种新颖的训练框架，即**经验混合**，它整合了来自存储关键样本和合成的、边界邻近数据的信息。经验混合由两个核心组件组成：(1) 一种多元差分隐私（DP）噪声机制，将批次噪声注入低维特征表示中，生成SBD；(2) 一种端到端训练策略，共同利用存储的关键样本和SBD。在CIFAR-10、CIFAR-100和Tiny ImageNet上的大量实验表明，我们的方法优于九个CL基线，准确率分别提高了10%、6%和13%。", "summary": "本文提出了一种名为“经验混合”的持续学习框架，旨在通过引入合成边界数据（SBD）来解决灾难性遗忘问题。该框架通过多元差分隐私噪声机制生成SBD，并结合存储的关键样本进行端到端训练。实验证明，该方法在多个数据集上显著提升了准确率，优于现有的持续学习基线。", "keywords": "持续学习, 灾难性遗忘, 经验回放, 合成数据, 决策边界", "comments": "该论文的创新点在于提出了“经验混合”框架，并引入了“合成边界数据（SBD）”的概念，通过在决策边界附近生成合成数据来提高模型的边界稳定性。这种方法通过利用差分隐私噪声机制生成SBD，为持续学习中的经验回放机制提供了一种新颖的补充，有效地缓解了灾难性遗忘问题。"}}
{"id": "2507.23155", "title": "On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization", "authors": ["Jincheng Cao", "Ruichen Jiang", "Erfan Yazdandoost Hamedani", "Aryan Mokhtari"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23155v1", "summary": "In this paper, we study the problem of solving a simple bilevel optimization\nproblem, where the upper-level objective is minimized over the solution set of\nthe lower-level problem. We focus on the general setting in which both the\nupper- and lower-level objectives are smooth but potentially nonconvex. Due to\nthe absence of additional structural assumptions for the lower-level\nobjective-such as convexity or the Polyak-{\\L}ojasiewicz (PL)\ncondition-guaranteeing global optimality is generally intractable. Instead, we\nintroduce a suitable notion of stationarity for this class of problems and aim\nto design a first-order algorithm that finds such stationary points in\npolynomial time. Intuitively, stationarity in this setting means the\nupper-level objective cannot be substantially improved locally without causing\na larger deterioration in the lower-level objective. To this end, we show that\na simple and implementable variant of the dynamic barrier gradient descent\n(DBGD) framework can effectively solve the considered nonconvex simple bilevel\nproblems up to stationarity. Specifically, to reach an $(\\epsilon_f,\n\\epsilon_g)$-stationary point-where $\\epsilon_f$ and $\\epsilon_g$ denote the\ntarget stationarity accuracies for the upper- and lower-level objectives,\nrespectively-the considered method achieves a complexity of\n$\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}},\n\\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$, where $p \\geq 0$ is an arbitrary\nconstant balancing the terms. To the best of our knowledge, this is the first\ncomplexity result for a discrete-time algorithm that guarantees joint\nstationarity for both levels in general nonconvex simple bilevel problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23155v1", "cate": "math.OC", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "关于在非凸简单双层优化中寻找驻点的复杂性", "tldr": "本文研究了非凸简单双层优化中寻找驻点的问题，并提出了一种基于DBGD的算法，首次给出了其达到联合驻点的复杂度保证。", "motivation": "在非凸简单双层优化问题中，由于下层目标函数缺乏凸性或Polyak-Łojasiewicz (PL) 条件等结构假设，保证全局最优性通常是难以处理的。因此，需要引入合适的驻点概念，并设计能在多项式时间内找到这些驻点的一阶算法。", "method": "采用动态障碍梯度下降（DBGD）框架的一个简单且可实现的变体来解决所考虑的非凸简单双层问题，直至达到驻点。", "result": "该方法能够达到 $(\\epsilon_f, \\epsilon_g)$-驻点，其复杂度为 $\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}}, \\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$，其中 $p \\geq 0$ 是平衡项的任意常数。据作者所知，这是第一个针对离散时间算法的复杂性结果，该算法在一般的非凸简单双层问题中保证了上下两层的联合驻点。", "conclusion": "本文首次为离散时间算法提供了复杂性结果，该算法在一般的非凸简单双层问题中保证了上下两层的联合驻点。", "translation": "在本文中，我们研究了求解一个简单双层优化问题，其中上层目标函数在下层问题的解集上被最小化。我们关注的是上层和下层目标函数都平滑但可能非凸的通用设置。由于下层目标函数缺乏额外的结构假设——例如凸性或Polyak-Łojasiewicz (PL) 条件——保证全局最优性通常是难以处理的。相反，我们为这类问题引入了一个合适的驻点概念，并旨在设计一种一阶算法，该算法能在多项式时间内找到此类驻点。直观地说，在这种设置下的驻点意味着上层目标函数在局部无法显著改善，而不会导致下层目标函数更大的恶化。为此，我们表明动态障碍梯度下降（DBGD）框架的一个简单且可实现的变体可以有效地解决所考虑的非凸简单双层问题，直至达到驻点。具体而言，为了达到一个 $(\\epsilon_f, \\epsilon_g)$-驻点——其中 $\\epsilon_f$ 和 $\\epsilon_g$ 分别表示上层和下层目标的期望驻点精度——所考虑的方法达到了 $\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}}, \\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$ 的复杂度，其中 $p \\geq 0$ 是一个平衡项的任意常数。据我们所知，这是第一个针对离散时间算法的复杂性结果，该算法在一般的非凸简单双层问题中保证了上下两层的联合驻点。", "summary": "本文研究了求解非凸简单双层优化问题，其中上下层目标函数均平滑但可能非凸。针对全局最优性难以保证的问题，作者引入了新的驻点概念，并提出了一种基于动态障碍梯度下降（DBGD）框架的变体算法。该算法能够有效地找到此类驻点，并首次给出了达到联合 $(\\epsilon_f, \\epsilon_g)$-驻点的复杂度为 $\\mathcal{O}\\left(\\max\\left(\\epsilon_f^{-\\frac{3+p}{1+p}}, \\epsilon_g^{-\\frac{3+p}{2}}\\right)\\right)$，填补了该领域离散时间算法复杂度分析的空白。", "keywords": "非凸优化, 双层优化, 驻点, 复杂度分析, 动态障碍梯度下降", "comments": "这项工作在处理非凸简单双层优化问题方面具有重要意义，尤其是在缺乏下层问题结构假设的情况下。引入合适的驻点概念并提供首个离散时间算法的复杂度保证是其创新之处。这为理解和设计更高效的双层优化算法奠定了基础，尽管其复杂性仍较高，但为后续研究提供了基准。"}}
{"id": "2501.08727", "title": "Transformed Low-rank Adaptation via Tensor Decomposition and Its Applications to Text-to-image Models", "authors": ["Zerui Tao", "Yuhta Takida", "Naoki Murata", "Qibin Zhao", "Yuki Mitsufuji"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2501.08727v2", "summary": "Parameter-Efficient Fine-Tuning (PEFT) of text-to-image models has become an\nincreasingly popular technique with many applications. Among the various PEFT\nmethods, Low-Rank Adaptation (LoRA) and its variants have gained significant\nattention due to their effectiveness, enabling users to fine-tune models with\nlimited computational resources. However, the approximation gap between the\nlow-rank assumption and desired fine-tuning weights prevents the simultaneous\nacquisition of ultra-parameter-efficiency and better performance. To reduce\nthis gap and further improve the power of LoRA, we propose a new PEFT method\nthat combines two classes of adaptations, namely, transform and residual\nadaptations. In specific, we first apply a full-rank and dense transform to the\npre-trained weight. This learnable transform is expected to align the\npre-trained weight as closely as possible to the desired weight, thereby\nreducing the rank of the residual weight. Then, the residual part can be\neffectively approximated by more compact and parameter-efficient structures,\nwith a smaller approximation error. To achieve ultra-parameter-efficiency in\npractice, we design highly flexible and effective tensor decompositions for\nboth the transform and residual adaptations. Additionally, popular PEFT methods\nsuch as DoRA can be summarized under this transform plus residual adaptation\nscheme. Experiments are conducted on fine-tuning Stable Diffusion models in\nsubject-driven and controllable generation. The results manifest that our\nmethod can achieve better performances and parameter efficiency compared to\nLoRA and several baselines.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2501.08727v2", "cate": "cs.LG", "date": "2025-01-15", "updated": "2025-07-31", "AI": {"title_translation": "通过张量分解的变换低秩适应及其在文本到图像模型中的应用", "tldr": "本文提出了一种新的参数高效微调（PEFT）方法，结合了变换和残差适应，并利用张量分解来提高LoRA的性能和参数效率，在文本到图像模型微调中表现优于现有方法。", "motivation": "现有的低秩适应（LoRA）方法在低秩假设与期望的微调权重之间存在近似差距，这阻碍了同时实现超参数效率和更优性能。", "method": "本文提出了一种结合变换适应和残差适应的新型参数高效微调（PEFT）方法。具体来说，首先对预训练权重应用全秩密集变换，使其尽可能接近期望权重，从而降低残差权重的秩。然后，残差部分通过更紧凑和参数高效的结构进行近似。为实现超参数效率，对变换和残差适应都设计了高度灵活和有效的张量分解。", "result": "实验结果表明，与LoRA和几个基线方法相比，本文提出的方法在主体驱动和可控生成中的Stable Diffusion模型微调方面取得了更好的性能和参数效率。", "conclusion": "本文提出的通过张量分解的变换低秩适应方法，有效弥补了LoRA的近似差距，显著提升了文本到图像模型的微调性能和参数效率。", "translation": "文本到图像模型的参数高效微调（PEFT）已成为一种日益流行的技术，并具有许多应用。在各种PEFT方法中，低秩适应（LoRA）及其变体因其有效性而获得了广泛关注，使用户能够以有限的计算资源微调模型。然而，低秩假设与期望微调权重之间的近似差距阻碍了同时实现超参数效率和更优性能。为了缩小这一差距并进一步提升LoRA的能力，我们提出了一种新的PEFT方法，该方法结合了两类适应：变换适应和残差适应。具体来说，我们首先对预训练权重应用一个全秩且密集的变换。这个可学习的变换旨在使预训练权重尽可能地与期望权重对齐，从而降低残差权重的秩。然后，残差部分可以通过更紧凑和参数高效的结构进行有效近似，且近似误差更小。为了在实践中实现超参数效率，我们为变换适应和残差适应设计了高度灵活和有效的张量分解。此外，诸如DoRA等流行的PEFT方法也可以归纳到这种变换加残差适应方案下。实验在主体驱动和可控生成中对Stable Diffusion模型进行了微调。结果表明，与LoRA和几个基线方法相比，我们的方法可以实现更好的性能和参数效率。", "summary": "本文针对低秩适应（LoRA）在文本到图像模型微调中存在的近似差距问题，提出了一种名为“变换低秩适应”的新型参数高效微调（PEFT）方法。该方法结合了变换适应和残差适应，通过先对预训练权重进行全秩变换以减小残差，再对残差部分进行高效近似，并利用张量分解实现超参数效率。实验证明，该方法在Stable Diffusion微调任务中，相比LoRA及其他基线方法，能同时提升性能和参数效率。", "keywords": "参数高效微调, 低秩适应, 张量分解, 文本到图像模型, Stable Diffusion", "comments": "本文的创新点在于提出了结合变换和残差适应的PEFT新范式，并巧妙地引入张量分解来解决LoRA的近似误差问题，从而在文本到图像模型微调中实现了性能和参数效率的双重提升。该方法为未来PEFT技术的发展提供了新的思路。"}}
{"id": "2507.19747", "title": "TokenBlowUp: Resolving Representational Singularities in LLM Token Spaces via Monoidal Transformations", "authors": ["Dongfang Zhao"], "categories": ["math.AG", "cs.LG"], "primary_category": "Subjects:       Algebraic Geometry (math.AG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19747v2", "summary": "Recent work has provided compelling evidence challenging the foundational\nmanifold hypothesis for the token embedding spaces of Large Language Models\n(LLMs). These findings reveal the presence of geometric singularities around\npolysemous tokens, which can lead to representational instability. Existing\nmethodologies, which presuppose a smooth data manifold, are ill-equipped to\naddress such intrinsic structural flaws. In this paper, we formalize this\nproblem in the language of scheme theory and propose a rigorous resolution by\napplying the scheme-theoretic blow-up at each singular point. This procedure\nreplaces a singular point in the ambient affine scheme with its exceptional\ndivisor, which we identify as a canonical geometric space -- a projective space\nof directions -- that houses the disambiguated semantic meanings of the token.\nThis process of ``representational desingularization'' constructs a new\ngeometric landscape for embeddings. We prove a formal theorem guaranteeing the\ngeometric regularization of this new space, showing that the original\npathologies are resolved. Finally, we outline the architectural implications of\nour framework, arguing for a paradigm shift from static look-ups to dynamic,\ngeometrically-grounded computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19747v2", "cate": "math.AG", "date": "2025-07-26", "updated": "2025-07-30", "AI": {"title_translation": "TokenBlowUp：通过幺半群变换解决LLM令牌空间中的表征奇点", "tldr": "LLM令牌嵌入空间存在几何奇点导致表征不稳定。本文提出使用概形论的“吹胀”操作来解决这些奇点，通过引入新的几何空间来消除歧义并正则化表征。", "motivation": "现有研究表明LLM令牌嵌入空间存在几何奇点，尤其是在多义词附近，这导致表征不稳定。传统方法无法解决这些内在结构缺陷。", "method": "本文将问题形式化为概形论，并提出在每个奇点应用概形论的“吹胀”(blow-up)操作。该操作将环境仿射概形中的奇点替换为一个例外除子，该除子被识别为一个规范的几何空间（方向的射影空间），用于容纳令牌的消歧义语义。这个过程被称为“表征去奇点化”。", "result": "该方法构建了一个新的嵌入几何图景。论文证明了一个形式定理，保证了这个新空间的几何正则化，表明原始的病态问题得到了解决。", "conclusion": "通过“表征去奇点化”过程，可以解决LLM令牌空间中的表征奇点问题，并为嵌入构建新的几何景观，从而实现从静态查找向动态、几何计算的范式转变。", "translation": "最近的工作提供了令人信服的证据，挑战了大型语言模型（LLM）令牌嵌入空间的基础流形假设。这些发现揭示了多义令牌周围存在几何奇点，这可能导致表征不稳定性。预设平滑数据流形的现有方法无法解决这种内在的结构缺陷。在本文中，我们将这个问题形式化为概形论的语言，并通过在每个奇点应用概形论的吹胀操作，提出了一个严格的解决方案。此过程将环境仿射概形中的奇点替换为其例外除子，我们将其识别为一个规范的几何空间——方向的射影空间——其中包含令牌的消歧义语义。这种“表征去奇点化”的过程为嵌入构建了一个新的几何景观。我们证明了一个形式定理，保证了这个新空间的几何正则化，表明原始的病态问题得到了解决。最后，我们概述了我们框架的架构含义，主张从静态查找转向动态的、基于几何的计算。", "summary": "本文解决了大型语言模型（LLM）令牌嵌入空间中多义词导致的几何奇点问题，这些奇点引起表征不稳定。作者将此问题形式化为概形论，并提出通过在奇点处进行“吹胀”操作来解决。该方法将奇点替换为容纳消歧义语义的射影空间，从而实现了“表征去奇点化”，构建了一个正则化的新几何空间。这预示着LLM表征将从静态查找转向动态、几何计算的新范式。", "keywords": "LLM, 令牌嵌入, 几何奇点, 概形论, 吹胀操作, 表征去奇点化", "comments": "这篇论文提出了一种高度数学化（概形论）和几何化的方法来解决LLM中一个深层次的表征问题。其创新点在于将代数几何中的“吹胀”操作引入到LLM的令牌空间分析中，以处理多义词导致的表征奇点。这不仅提供了一个理论上严谨的解决方案，也为LLM的未来架构和计算范式提供了新的思路，即从静态查找转向动态的、基于几何的计算，具有重要的理论和潜在的实践意义。"}}
{"id": "2507.22962", "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "authors": ["Boyuan Zheng", "Victor W. Chu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Pre-print v0.8 2025-07-30", "url": "http://arxiv.org/abs/2507.22962v1", "summary": "Climate extremes present escalating risks to agriculture intensifying the\nneed for reliable multi-hazard early warning systems (EWS). The situation is\nevolving due to climate change and hence such systems should have the\nintelligent to continue to learn from recent climate behaviours. However,\ntraditional single-hazard forecasting methods fall short in capturing complex\ninteractions among concurrent climatic events. To address this deficiency, in\nthis paper, we combine sequential deep learning models and advanced Explainable\nArtificial Intelligence (XAI) techniques to introduce a multi-hazard\nforecasting framework for agriculture. In our experiments, we utilize\nmeteorological data from four prominent agricultural regions in the United\nStates (between 2010 and 2023) to validate the predictive accuracy of our\nframework on multiple severe event types, which are extreme cold, floods,\nfrost, hail, heatwaves, and heavy rainfall, with tailored models for each area.\nThe framework uniquely integrates attention mechanisms with TimeSHAP (a\nrecurrent XAI explainer for time series) to provide comprehensive temporal\nexplanations revealing not only which climatic features are influential but\nprecisely when their impacts occur. Our results demonstrate strong predictive\naccuracy, particularly with the BiLSTM architecture, and highlight the system's\ncapacity to inform nuanced, proactive risk management strategies. This research\nsignificantly advances the explainability and applicability of multi-hazard\nEWS, fostering interdisciplinary trust and effective decision-making process\nfor climate risk management in the agricultural industry.", "comment": "Pre-print v0.8 2025-07-30", "pdf_url": "http://arxiv.org/pdf/2507.22962v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "农业多灾害预警系统，具有特征-时间解释功能", "tldr": "该研究提出了一种结合深度学习和可解释人工智能的农业多灾害预警系统，能够对多种气候事件进行准确预测，并提供特征-时间解释，以支持农业气候风险管理。", "motivation": "气候极端事件对农业的风险日益增加，需要可靠的多灾害预警系统。传统单一灾害预测方法无法捕捉并发气候事件之间的复杂相互作用。此外，由于气候变化，此类系统应能持续学习最新的气候行为。", "method": "本研究结合了序列深度学习模型和先进的可解释人工智能（XAI）技术，引入了一个农业多灾害预测框架。该框架利用2010年至2023年美国四个主要农业气象数据进行验证，并为每个区域定制模型，以预测极端寒冷、洪水、霜冻、冰雹、热浪和强降雨等多种严重事件。该框架独特地将注意力机制与TimeSHAP（一种用于时间序列的循环XAI解释器）相结合，以提供全面的时间解释，揭示哪些气候特征具有影响力以及它们的影响何时发生。", "result": "实验结果表明，该框架具有强大的预测准确性，尤其是在使用BiLSTM架构时。该系统能够为细致入微、积极主动的风险管理策略提供信息。", "conclusion": "这项研究显著提升了多灾害预警系统的可解释性和适用性，促进了跨学科信任和农业气候风险管理中的有效决策过程。", "translation": "气候极端事件对农业的风险日益增加，这加剧了对可靠的多灾害预警系统（EWS）的需求。由于气候变化，情况正在不断演变，因此此类系统应具备从近期气候行为中持续学习的智能。然而，传统的单一灾害预测方法未能捕捉并发气候事件之间的复杂相互作用。为解决这一不足，本文结合了序列深度学习模型和先进的可解释人工智能（XAI）技术，引入了一个农业多灾害预测框架。在我们的实验中，我们利用了美国四个主要农业地区（2010年至2023年期间）的气象数据，以验证我们的框架在多种严重事件类型（包括极端寒冷、洪水、霜冻、冰雹、热浪和强降雨）上的预测准确性，并为每个区域定制了模型。该框架独特地将注意力机制与TimeSHAP（一种用于时间序列的循环XAI解释器）相结合，以提供全面的时间解释，不仅揭示了哪些气候特征具有影响力，还精确地揭示了它们的影响何时发生。我们的结果表明了强大的预测准确性，特别是BiLSTM架构，并强调了系统能够为细致入微、积极主动的风险管理策略提供信息的能力。这项研究显著提升了多灾害预警系统的可解释性和适用性，促进了跨学科信任和农业气候风险管理中的有效决策过程。", "summary": "本研究提出了一个针对农业的多灾害预警系统，旨在解决气候极端事件对农业日益增长的风险以及传统单一灾害预测方法的局限性。该系统结合了序列深度学习模型和可解释人工智能（XAI）技术，能够预测多种严重气候事件，如极端寒冷、洪水和热浪。通过集成注意力机制和TimeSHAP，该框架不仅能识别关键气候特征，还能精确解释其影响发生的时间。实验结果表明，该系统具有高预测准确性（特别是使用BiLSTM），能够支持农业领域的精细化风险管理和决策制定，显著提升了多灾害预警系统的可解释性和实用性。", "keywords": "多灾害预警系统, 可解释人工智能, 深度学习, 农业, 时间序列", "comments": "该论文的创新点在于将深度学习模型与先进的XAI技术（特别是TimeSHAP）相结合，不仅实现了多灾害预测，更提供了时间维度的解释性，这对于理解气候事件的动态影响至关重要。这种解释性能够增强用户对预警系统的信任，并促进更精准的风险管理决策。其在农业领域的应用具有重要意义，有助于应对气候变化带来的挑战。"}}
{"id": "2507.23215", "title": "Silent Impact: Tracking Tennis Shots from the Passive Arm", "authors": ["Junyong Park", "Saelyne Yang", "Sungho Jo"], "categories": ["cs.HC", "H.5.2; I.5.4"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      15 pages, 9 figures,", "url": "http://arxiv.org/abs/2507.23215v1", "summary": "Wearable technology has transformed sports analytics, offering new dimensions\nin enhancing player experience. Yet, many solutions involve cumbersome setups\nthat inhibit natural motion. In tennis, existing products require sensors on\nthe racket or dominant arm, causing distractions and discomfort. We propose\nSilent Impact, a novel and user-friendly system that analyzes tennis shots\nusing a sensor placed on the passive arm. Collecting Inertial Measurement Unit\nsensor data from 20 recreational tennis players, we developed neural networks\nthat exclusively utilize passive arm data to detect and classify six shots,\nachieving a classification accuracy of 88.2% and a detection F1 score of 86.0%,\ncomparable to the dominant arm. These models were then incorporated into an\nend-to-end prototype, which records passive arm motion through a smartwatch and\ndisplays a summary of shots on a mobile app. User study (N=10) showed that\nparticipants felt less burdened physically and mentally using Silent Impact on\nthe passive arm. Overall, our research establishes the passive arm as an\neffective, comfortable alternative for tennis shot analysis, advancing\nuser-friendly sports analytics.", "comment": "15 pages, 9 figures,", "pdf_url": "http://arxiv.org/pdf/2507.23215v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "无声冲击：从非持拍手臂追踪网球击球", "tldr": "该研究提出了一种名为“无声冲击”的新型系统，通过放置在非持拍手臂上的传感器来分析网球击球，实现了与传统方法相当的准确性，并显著提高了用户舒适度。", "motivation": "现有的网球分析解决方案需要将传感器放置在球拍或主导手臂上，这会导致分心、不适并抑制自然运动，给玩家带来不便。", "method": "研究团队提出了“无声冲击”系统，该系统使用放置在非持拍手臂上的传感器。他们收集了20名业余网球运动员的惯性测量单元（IMU）传感器数据，并开发了仅利用非持拍手臂数据的神经网络，用于检测和分类六种击球。这些模型被整合到一个端到端原型中，通过智能手表记录非持拍手臂运动并在移动应用程序上显示击球摘要。此外，还进行了一项用户研究（N=10）。", "result": "该系统在击球分类方面达到了88.2%的准确率，在击球检测方面达到了86.0%的F1分数，这些表现与主导手臂相当。用户研究表明，参与者在使用“无声冲击”系统时，身体和精神负担都更小。", "conclusion": "该研究确立了非持拍手臂作为网球击球分析的一种有效、舒适的替代方案，从而推动了用户友好的体育分析技术发展。", "translation": "可穿戴技术已经改变了体育分析，为增强运动员体验提供了新的维度。然而，许多解决方案涉及繁琐的设置，会抑制自然运动。在网球运动中，现有产品要求将传感器放置在球拍或主导手臂上，这会导致分心和不适。我们提出了“无声冲击”，一个新颖且用户友好的系统，通过放置在非持拍手臂上的传感器来分析网球击球。我们收集了20名业余网球运动员的惯性测量单元传感器数据，开发了专门利用非持拍手臂数据来检测和分类六种击球的神经网络，达到了88.2%的分类准确率和86.0%的检测F1分数，与主导手臂相当。然后，这些模型被整合到一个端到端原型中，该原型通过智能手表记录非持拍手臂运动，并在移动应用程序上显示击球摘要。用户研究（N=10）表明，参与者在使用放置在非持拍手臂上的“无声冲击”时，身体和精神负担都更小。总的来说，我们的研究确立了非持拍手臂作为网球击球分析的一种有效、舒适的替代方案，从而推动了用户友好的体育分析技术发展。", "summary": "本研究提出了一种名为“无声冲击”的新型网球击球分析系统，旨在解决现有可穿戴设备在网球运动中带来的不适和干扰问题。该系统创新性地将传感器放置在非持拍手臂上，利用惯性测量单元数据和神经网络模型，实现了对六种网球击球的准确检测和分类，其性能与传统放置在主导手臂上的系统相当。通过智能手表和移动应用的端到端原型，该系统提高了用户体验，用户研究表明其显著减轻了身体和精神负担。这项工作证明了非持拍手臂在体育分析中作为一种舒适有效的数据来源的可行性。", "keywords": "网球, 非持拍手臂, 可穿戴技术, 击球追踪, 神经网络", "comments": "这项研究的创新之处在于其将传感器放置在非持拍手臂上，解决了现有体育分析设备带来的用户不适和运动限制问题。这对于提升用户在运动中的自然体验至关重要，为可穿戴体育技术的发展开辟了新的方向。其成果在准确性上与传统方法相当，同时显著提升了用户舒适度，具有很强的实用价值和市场潜力。"}}
{"id": "2507.23300", "title": "Training-free Geometric Image Editing on Diffusion Models", "authors": ["Hanshen Zhu", "Zhen Zhu", "Kaile Zhang", "Yiming Gong", "Yuliang Liu", "Xiang Bai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      24 pages, 22 figures, ICCV", "url": "http://arxiv.org/abs/2507.23300v1", "summary": "We tackle the task of geometric image editing, where an object within an\nimage is repositioned, reoriented, or reshaped while preserving overall scene\ncoherence. Previous diffusion-based editing methods often attempt to handle all\nrelevant subtasks in a single step, proving difficult when transformations\nbecome large or structurally complex. We address this by proposing a decoupled\npipeline that separates object transformation, source region inpainting, and\ntarget region refinement. Both inpainting and refinement are implemented using\na training-free diffusion approach, FreeFine. In experiments on our new\nGeoBench benchmark, which contains both 2D and 3D editing scenarios, FreeFine\noutperforms state-of-the-art alternatives in image fidelity, and edit\nprecision, especially under demanding transformations. Code and benchmark are\navailable at: https://github.com/CIawevy/FreeFine", "comment": "24 pages, 22 figures, ICCV", "pdf_url": "http://arxiv.org/pdf/2507.23300v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "无需训练的扩散模型几何图像编辑", "tldr": "提出了一种名为FreeFine的无需训练的解耦管道，用于处理几何图像编辑，通过分离变换、修复和细化，在GeoBench基准上超越了现有技术。", "motivation": "解决现有扩散模型几何图像编辑方法在处理大型或复杂变换时，难以在一步内处理所有相关子任务的问题。", "method": "提出了一种解耦的管道，将对象变换、源区域修复和目标区域细化分开。修复和细化都使用名为FreeFine的无需训练的扩散方法实现。", "result": "在新的GeoBench基准（包含2D和3D编辑场景）上的实验表明，FreeFine在图像保真度和编辑精度方面优于现有技术，尤其是在要求高的变换下。", "conclusion": "FreeFine通过其解耦管道和无需训练的扩散方法，在几何图像编辑任务中表现出色，特别是在复杂变换下，解决了现有方法的局限性。", "translation": "我们解决了几何图像编辑任务，即在保持整体场景连贯性的同时，对图像中的对象进行重新定位、重新定向或重塑。以前基于扩散的编辑方法通常试图在一个步骤中处理所有相关的子任务，当变换变得较大或结构复杂时，这被证明是困难的。我们通过提出一种解耦的管道来解决这个问题，该管道将对象变换、源区域修复和目标区域细化分开。修复和细化都使用无需训练的扩散方法FreeFine实现。在我们的新GeoBench基准（包含2D和3D编辑场景）上的实验中，FreeFine在图像保真度和编辑精度方面优于现有最先进的替代方案，特别是在要求高的变换下。代码和基准可在以下网址获取：https://github.com/CIawevy/FreeFine", "summary": "这篇论文提出了一种名为FreeFine的无需训练的几何图像编辑方法，旨在解决现有扩散模型在处理复杂变换时的局限性。FreeFine采用解耦管道，将对象变换、源区域修复和目标区域细化分开处理。实验结果表明，在新的GeoBench基准上，FreeFine在图像保真度和编辑精度方面优于现有先进方法，尤其是在高要求变换场景下。", "keywords": "几何图像编辑, 扩散模型, 无需训练, FreeFine, 解耦管道", "comments": "这篇论文的创新点在于提出了一个解耦的几何图像编辑管道，并通过“无需训练”的FreeFine方法实现了高效且高质量的编辑。通过分离复杂的子任务，它有效解决了现有方法在处理大型或复杂变换时的难题，并且引入了新的GeoBench基准，对该领域的研究具有重要推动作用。"}}
{"id": "2507.23416", "title": "Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23416v1", "summary": "This paper aims to develop a machine learning-based system for automatically\ndetecting honey adulteration with sugar syrup, based on honey hyperspectral\nimaging data. First, the floral source of a honey sample is classified by a\nbotanical origin identification subsystem. Then, the sugar syrup adulteration\nis identified, and its concentration is quantified by an adulteration detection\nsubsystem. Both subsystems consist of two steps. The first step involves\nextracting relevant features from the honey sample using Linear Discriminant\nAnalysis (LDA). In the second step, we utilize the K-Nearest Neighbors (KNN)\nmodel to classify the honey botanical origin in the first subsystem and\nidentify the adulteration level in the second subsystem. We assess the proposed\nsystem performance on a public honey hyperspectral image dataset. The result\nindicates that the proposed system can detect adulteration in honey with an\noverall cross-validation accuracy of 96.39%, making it an appropriate\nalternative to the current chemical-based detection methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23416v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用高光谱成像和机器学习的蜂蜜掺假检测", "tldr": "本文提出了一种基于高光谱成像和机器学习的系统，用于自动检测蜂蜜中糖浆掺假，并实现了96.39%的检测准确率。", "motivation": "开发一种基于机器学习的系统，用于自动检测蜂蜜中糖浆掺假，以替代当前的基于化学的检测方法。", "method": "该系统包含两个子系统：植物来源识别和掺假检测。两个子系统都首先使用线性判别分析（LDA）提取特征，然后使用K-最近邻（KNN）模型进行分类和识别。", "result": "所提出的系统在蜂蜜掺假检测中实现了96.39%的整体交叉验证准确率。", "conclusion": "该系统可以有效检测蜂蜜掺假，是当前基于化学的检测方法的合适替代方案。", "translation": "本文旨在开发一种基于机器学习的系统，用于根据蜂蜜高光谱成像数据自动检测蜂蜜中的糖浆掺假。首先，通过植物来源识别子系统对蜂蜜样本的花源进行分类。然后，掺假检测子系统识别糖浆掺假并量化其浓度。这两个子系统都包含两个步骤。第一步是使用线性判别分析（LDA）从蜂蜜样本中提取相关特征。在第二步中，我们利用K-最近邻（KNN）模型在第一个子系统中对蜂蜜的植物来源进行分类，并在第二个子系统中识别掺假水平。我们在一个公共蜂蜜高光谱图像数据集上评估了所提出系统的性能。结果表明，所提出的系统能够以96.39%的整体交叉验证准确率检测蜂蜜中的掺假，使其成为当前基于化学的检测方法的合适替代方案。", "summary": "本文提出了一种利用高光谱成像和机器学习检测蜂蜜中糖浆掺假的自动化系统。该系统包含植物来源识别和掺假检测两个子系统，均采用线性判别分析（LDA）进行特征提取，并利用K-最近邻（KNN）模型进行分类。在公开数据集上的评估显示，该系统在蜂蜜掺假检测上达到了96.39%的整体交叉验证准确率，证明其是现有化学检测方法的有效替代方案。", "keywords": "蜂蜜掺假, 高光谱成像, 机器学习, 线性判别分析, K-最近邻", "comments": "该论文提出了一种非侵入性且高效的蜂蜜掺假检测方法，通过结合高光谱成像和机器学习，为食品质量安全提供了一个有前景的解决方案，尤其是在替代传统化学检测方法方面具有创新性。"}}
{"id": "2504.17761", "title": "Step1X-Edit: A Practical Framework for General Image Editing", "authors": ["Shiyu Liu", "Yucheng Han", "Peng Xing", "Fukun Yin", "Rui Wang", "Wei Cheng", "Jiaqi Liao", "Yingming Wang", "Honghao Fu", "Chunrui Han", "Guopeng Li", "Yuang Peng", "Quan Sun", "Jingwei Wu", "Yan Cai", "Zheng Ge", "Ranchen Ming", "Lei Xia", "Xianfang Zeng", "Yibo Zhu", "Binxing Jiao", "Xiangyu Zhang", "Gang Yu", "Daxin Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      code: this https URL", "url": "http://arxiv.org/abs/2504.17761v5", "summary": "In recent years, image editing models have witnessed remarkable and rapid\ndevelopment. The recent unveiling of cutting-edge multimodal models such as\nGPT-4o and Gemini2 Flash has introduced highly promising image editing\ncapabilities. These models demonstrate an impressive aptitude for fulfilling a\nvast majority of user-driven editing requirements, marking a significant\nadvancement in the field of image manipulation. However, there is still a large\ngap between the open-source algorithm with these closed-source models. Thus, in\nthis paper, we aim to release a state-of-the-art image editing model, called\nStep1X-Edit, which can provide comparable performance against the closed-source\nmodels like GPT-4o and Gemini2 Flash. More specifically, we adopt the\nMultimodal LLM to process the reference image and the user's editing\ninstruction. A latent embedding has been extracted and integrated with a\ndiffusion image decoder to obtain the target image. To train the model, we\nbuild a data generation pipeline to produce a high-quality dataset. For\nevaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world\nuser instructions. Experimental results on GEdit-Bench demonstrate that\nStep1X-Edit outperforms existing open-source baselines by a substantial margin\nand approaches the performance of leading proprietary models, thereby making\nsignificant contributions to the field of image editing.", "comment": "code: https://github.com/stepfun-ai/Step1X-Edit", "pdf_url": "http://arxiv.org/pdf/2504.17761v5", "cate": "cs.CV", "date": "2025-04-24", "updated": "2025-07-31", "AI": {"title_translation": "Step1X-Edit：一个实用的通用图像编辑框架", "tldr": "本文提出了Step1X-Edit，一个先进的开源图像编辑模型，其性能可与GPT-4o和Gemini2 Flash等闭源模型媲美，并通过构建高质量数据集和新基准GEdit-Bench进行训练和评估。", "motivation": "尽管GPT-4o和Gemini2 Flash等闭源多模态模型在图像编辑方面取得了显著进展，但开源算法与这些闭源模型之间仍存在巨大差距。本文旨在发布一个能与闭源模型性能相媲美的最先进开源图像编辑模型。", "method": "该方法采用多模态大型语言模型（Multimodal LLM）处理参考图像和用户编辑指令。提取潜在嵌入并与扩散图像解码器集成以生成目标图像。为了训练模型，构建了一个数据生成管道以生产高质量数据集。此外，开发了一个名为GEdit-Bench的新型基准，该基准基于真实世界用户指令用于模型评估。", "result": "在GEdit-Bench上的实验结果表明，Step1X-Edit显著优于现有开源基线，并且性能接近领先的专有模型。", "conclusion": "Step1X-Edit通过提供一个性能可与领先闭源模型媲美的最先进开源解决方案，对图像编辑领域做出了重大贡献，从而缩小了开源与闭源模型之间的性能差距。", "translation": "近年来，图像编辑模型取得了显著而迅速的发展。GPT-4o和Gemini2 Flash等尖端多模态模型的最新发布引入了极具前景的图像编辑能力。这些模型在满足绝大多数用户驱动的编辑需求方面表现出令人印象深刻的能力，标志着图像处理领域的一项重大进步。然而，开源算法与这些闭源模型之间仍然存在巨大差距。因此，在本文中，我们旨在发布一个最先进的图像编辑模型，名为Step1X-Edit，其性能可以与GPT-4o和Gemini2 Flash等闭源模型相媲美。更具体地说，我们采用多模态大型语言模型（Multimodal LLM）来处理参考图像和用户的编辑指令。提取潜在嵌入并将其与扩散图像解码器集成以获得目标图像。为了训练模型，我们构建了一个数据生成管道以生成高质量数据集。为了进行评估，我们开发了GEdit-Bench，一个植根于真实世界用户指令的新型基准。GEdit-Bench上的实验结果表明，Step1X-Edit显著优于现有开源基线，并且性能接近领先的专有模型，从而对图像编辑领域做出了重大贡献。", "summary": "本文提出了Step1X-Edit，一个旨在缩小开源与闭源模型之间性能差距的通用图像编辑框架。该框架利用多模态LLM处理图像和指令，并结合扩散解码器生成编辑后的图像。为支持模型训练，研究团队构建了高质量的数据生成管道，并开发了基于真实用户指令的新型评估基准GEdit-Bench。实验证明，Step1X-Edit在GEdit-Bench上显著超越现有开源模型，并达到接近领先闭源模型的性能水平。", "keywords": "图像编辑, 多模态LLM, 扩散模型, 开源, 基准", "comments": "Step1X-Edit的创新点在于其结合多模态LLM和扩散解码器来处理通用图像编辑任务，并致力于缩小与闭源SOTA模型之间的性能差距。其重要性在于提供了一个强大的开源替代方案，降低了先进图像编辑技术的门槛。此外，为了解决数据和评估的挑战，论文还构建了高质量的数据生成管道和真实世界用户指令驱动的GEdit-Bench基准，这对于推动开源图像编辑研究具有重要意义。"}}
{"id": "2507.23715", "title": "DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching", "authors": ["Emery Pierson", "Lei Li", "Angela Dai", "Maks Ovsjanikov"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Presented at ICCV 2025", "url": "http://arxiv.org/abs/2507.23715v1", "summary": "Deep functional maps have recently emerged as a powerful tool for solving\nnon-rigid shape correspondence tasks. Methods that use this approach combine\nthe power and flexibility of the functional map framework, with data-driven\nlearning for improved accuracy and generality. However, most existing methods\nin this area restrict the learning aspect only to the feature functions and\nstill rely on axiomatic modeling for formulating the training loss or for\nfunctional map regularization inside the networks. This limits both the\naccuracy and the applicability of the resulting approaches only to scenarios\nwhere assumptions of the axiomatic models hold. In this work, we show, for the\nfirst time, that both in-network regularization and functional map training can\nbe replaced with data-driven methods. For this, we first train a generative\nmodel of functional maps in the spectral domain using score-based generative\nmodeling, built from a large collection of high-quality maps. We then exploit\nthe resulting model to promote the structural properties of ground truth\nfunctional maps on new shape collections. Remarkably, we demonstrate that the\nlearned models are category-agnostic, and can fully replace commonly used\nstrategies such as enforcing Laplacian commutativity or orthogonality of\nfunctional maps. Our key technical contribution is a novel distillation\nstrategy from diffusion models in the spectral domain. Experiments demonstrate\nthat our learned regularization leads to better results than axiomatic\napproaches for zero-shot non-rigid shape matching. Our code is available at:\nhttps://github.com/daidedou/diffumatch/", "comment": "Presented at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23715v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DiffuMatch：用于鲁棒非刚性形状匹配的类别无关谱扩散先验", "tldr": "DiffuMatch首次证明了非刚性形状匹配中，网络内正则化和函数映射训练可用数据驱动方法替代公理化模型，通过谱域扩散模型实现，并在零样本匹配上表现更好且类别无关。", "motivation": "现有深度函数映射方法在学习方面主要集中在特征函数，并且依赖公理化模型进行训练损失或网络内函数映射正则化，这限制了其准确性和适用性，使其仅限于满足公理化模型假设的场景。", "method": "该方法首次提出用数据驱动方法替代网络内正则化和函数映射训练。具体而言，它首先利用基于分数的生成建模，从大量高质量映射中构建并在谱域训练一个函数映射的生成模型。然后利用该模型来促进新形状集合上真实函数映射的结构特性。其关键技术贡献是谱域扩散模型中一种新颖的蒸馏策略。", "result": "实验证明，所学习的模型是类别无关的，并且可以完全替代常用的策略，如强制拉普拉斯交换性或函数映射的正交性。学习到的正则化在零样本非刚性形状匹配方面比公理化方法取得了更好的结果。", "conclusion": "该研究成功地展示了如何通过数据驱动的方法（特别是利用谱域扩散先验）替代传统功能映射方法中对公理化模型的依赖，从而显著提升了非刚性形状匹配的准确性、鲁棒性和泛化能力（类别无关性）。", "translation": "深度函数映射最近已成为解决非刚性形状对应任务的强大工具。使用这种方法的方法结合了函数映射框架的强大和灵活性，以及数据驱动学习以提高准确性和通用性。然而，该领域大多数现有方法仅将学习方面限制在特征函数上，并且仍然依赖公理化建模来制定训练损失或网络内部的函数映射正则化。这限制了所得方法的准确性和适用性，使其仅限于公理化模型假设成立的场景。在这项工作中，我们首次展示了网络内正则化和函数映射训练都可以用数据驱动方法替代。为此，我们首先使用基于分数的生成建模，从大量高质量映射中构建并在谱域训练一个函数映射的生成模型。然后，我们利用所得模型来促进新形状集合上真实函数映射的结构特性。值得注意的是，我们证明了所学习的模型是类别无关的，并且可以完全替代常用的策略，例如强制拉普拉斯交换性或函数映射的正交性。我们的关键技术贡献是谱域扩散模型中一种新颖的蒸馏策略。实验表明，我们学习到的正则化比公理化方法在零样本非刚性形状匹配方面取得了更好的结果。我们的代码可在以下网址获取：https://github.com/daidedou/diffumatch/", "summary": "本论文提出DiffuMatch，一种用于非刚性形状匹配的新方法，旨在解决现有深度函数映射方法对公理化模型正则化的依赖性。该方法首次将网络内正则化和函数映射训练替换为数据驱动方法，通过在谱域训练一个基于分数的函数映射生成模型实现。其核心创新在于从谱域扩散模型中引入了一种新颖的蒸馏策略。实验证明，DiffuMatch学习到的模型具有类别无关性，并能有效替代传统的拉普拉斯交换性或正交性约束，在零样本非刚性形状匹配任务上取得了优于公理化方法的性能。", "keywords": "非刚性形状匹配, 函数映射, 谱扩散, 生成模型, 数据驱动正则化", "comments": "该论文的主要创新点在于，它首次提出并成功实现了在深度函数映射框架中，用数据驱动的生成模型（特别是基于谱域扩散模型）来替代传统的、基于公理化假设的正则化和训练策略。这极大地拓展了非刚性形状匹配方法的适用性，使其不再受限于特定场景的先验假设，并实现了类别无关的匹配能力，对该领域具有重要的推动作用。"}}
{"id": "2507.23429", "title": "Chatting with your ERP: A Recipe", "authors": ["Jorge Ruiz Gómez", "Lidia Andrés Susinos", "Jorge Alamo Olivé", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hernández"], "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      11 pages, includes 3 tables summarizing schema and model performance. Submitted on July 31, 2025. Targets integration of LLM agents with ERP systems using open-weight models and Ollama deployment", "url": "http://arxiv.org/abs/2507.23429v1", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "pdf_url": "http://arxiv.org/pdf/2507.23429v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "与您的ERP聊天：一个秘诀", "tldr": "本文介绍了一个与ERP系统聊天的LLM代理的设计、实现和评估，该代理能将自然语言转换为SQL，并采用双代理架构提高可靠性。", "motivation": "提高与工业级ERP系统交互的效率和便捷性，通过自然语言查询实现数据访问，从而简化用户操作。", "method": "设计、实现并评估了一个大型语言模型（LLM）代理，该代理利用开源LLM将自然语言查询翻译成可执行的SQL语句。此外，本文提出了一种新颖的双代理架构，结合了推理和批判阶段，以显著提高查询生成的可靠性。", "result": "成功开发了一个能够与工业生产级ERP系统进行自然语言交互的LLM代理。该代理能够准确解释自然语言查询并将其转换为可执行的SQL语句。通过引入新颖的双代理架构，显著提高了查询生成的可靠性。", "conclusion": "本文成功设计、实现并评估了一个基于LLM的代理，该代理能够通过自然语言与工业级ERP系统进行交互，并通过创新的双代理架构提高了查询生成的可靠性，为LLM在企业级应用中的落地提供了可行方案。", "translation": "本文介绍了与工业生产级企业资源规划（ERP）系统进行聊天的的大型语言模型（LLM）代理的设计、实现和评估。该代理能够解释自然语言查询并将其翻译成可执行的SQL语句，利用了开源LLM。为了提高查询生成的可靠性，本文提出了一种结合推理和批判阶段的新颖双代理架构。", "summary": "本文提出并评估了一个基于大型语言模型（LLM）的代理，旨在实现与工业级ERP系统的自然语言交互。该代理能够将用户输入的自然语言查询转换为可执行的SQL语句。为提升查询生成的可靠性，研究引入了一种新颖的双代理架构，该架构融合了推理与批判两个阶段。", "keywords": "LLM代理, ERP系统, 自然语言处理, SQL生成, 双代理架构", "comments": "这项工作创新性地将LLM应用于企业级ERP系统交互，通过自然语言接口简化了复杂的数据查询。其提出的双代理（推理与批判）架构是提高LLM在关键业务场景中可靠性的重要探索，对于未来LLM在企业应用中的落地具有指导意义，尤其是在需要高准确性和可靠性的生产环境中。"}}
{"id": "2507.23205", "title": "Kernel-FFI: Transparent Foreign Function Interfaces for Interactive Notebooks", "authors": ["Hebi Li", "Forrest Sheng Bao", "Qi Xiao", "Jin Tian"], "categories": ["cs.PL", "cs.SE"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23205v1", "summary": "Foreign Function Interfaces (FFIs) are essential for enabling\ninteroperability between programming languages, yet existing FFI solutions are\nill-suited for the dynamic, interactive workflows prevalent in modern notebook\nenvironments such as Jupyter. Current approaches require extensive manual\nconfiguration, introduce significant boilerplate, and often lack support for\nrecursive calls and object-oriented programming (OOP) constructs-features\ncritical for productive, multi-language development.\n  We present Kernel-FFI, a transparent, language-agnostic framework that\nenables seamless cross-language function calls and object manipulation within\ninteractive notebooks. Kernel-FFI employs source-level transformation to\nautomatically rewrite cross-language invocations, eliminating the need for\nmanual bindings or boilerplate. Kernel-FFI provides robust support for OOP by\nenabling foreign object referencing and automatic resource management across\nlanguage boundaries. Furthermore, to address the blocking nature of Jupyter\nkernels and support recursive and asynchronous foreign calls, we introduce a\nnovel side-channel communication mechanism. Our tool will be open-sourced and\navailable at https://codepod.io/docs/kernel-ffi", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23205v1", "cate": "cs.PL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Kernel-FFI：交互式笔记本的透明外国函数接口", "tldr": "Kernel-FFI是一个透明、语言无关的框架，通过自动化FFI设置和处理复杂的调用类型，在交互式笔记本中实现无缝的跨语言调用和面向对象编程（OOP）支持。", "motivation": "现有外国函数接口（FFI）解决方案不适用于Jupyter等现代笔记本环境中动态、交互式的工作流程，因为它们需要大量手动配置、引入样板代码，并且缺乏对递归调用和面向对象编程（OOP）结构的支持。", "method": "Kernel-FFI采用源代码级转换来自动重写跨语言调用，消除了手动绑定或样板代码的需要。此外，为了解决Jupyter内核的阻塞性质并支持递归和异步外部调用，该框架引入了一种新颖的侧信道通信机制。", "result": "Kernel-FFI实现了无缝的跨语言函数调用和对象操作，消除了手动绑定或样板代码的需求，并为面向对象编程（OOP）提供了强大的支持，包括外部对象引用和跨语言边界的自动资源管理。它还支持递归和异步外部调用。", "conclusion": "Kernel-FFI提供了一个透明、与语言无关的框架，通过克服现有FFI解决方案的局限性，显著改善了交互式笔记本中的多语言开发体验。", "translation": "外国函数接口（FFI）对于实现编程语言之间的互操作性至关重要，但现有FFI解决方案不适用于Jupyter等现代笔记本环境中普遍存在的动态、交互式工作流程。当前方法需要大量的手动配置，引入了大量的样板代码，并且通常缺乏对递归调用和面向对象编程（OOP）结构的支持——这些特性对于高效的多语言开发至关重要。我们提出了Kernel-FFI，一个透明、与语言无关的框架，可以在交互式笔记本中实现无缝的跨语言函数调用和对象操作。Kernel-FFI采用源代码级转换来自动重写跨语言调用，消除了手动绑定或样板代码的需要。Kernel-FFI通过启用外部对象引用和跨语言边界的自动资源管理，为OOP提供了强大的支持。此外，为了解决Jupyter内核的阻塞性质并支持递归和异步外部调用，我们引入了一种新颖的侧信道通信机制。我们的工具将开源并可在https://codepod.io/docs/kernel-ffi获取。", "summary": "Kernel-FFI是一个透明、与语言无关的框架，旨在解决现有外国函数接口（FFI）在交互式笔记本环境中（如Jupyter）的局限性。它通过源代码级转换自动处理跨语言调用，消除了手动配置和样板代码。该框架支持面向对象编程（OOP）和自动资源管理，并引入了侧信道通信机制以支持递归和异步调用，从而实现了笔记本中无缝的跨语言开发。", "keywords": "外国函数接口, 交互式笔记本, 跨语言, Jupyter, 源代码转换", "comments": "Kernel-FFI的创新之处在于其透明的、语言无关的设计，特别是通过源代码级转换自动化FFI过程，以及引入侧信道通信机制来解决Jupyter内核的阻塞问题和支持复杂调用模式。这大大降低了在交互式笔记本中进行多语言开发的复杂性，提升了开发效率，对于数据科学和AI等领域的多语言协作具有重要意义。"}}
{"id": "2505.10933", "title": "Cross-layer Integrated Sensing and Communication: A Joint Industrial and Academic Perspective", "authors": ["Henk Wymeersch", "Nuutti Tervo", "Stefan Wänstedt", "Sharief Saleh", "Joerg Ahlendorf", "Ozgur Akgul", "Vasileios Tsekenis", "Sokratis Barmpounakis", "Liping Bai", "Martin Beale", "Rafael Berkvens", "Nabeel Nisar Bhat", "Hui Chen", "Shrayan Das", "Claude Desset", "Antonio de la Oliva", "Prajnamaya Dass", "Jeroen Famaey", "Hamed Farhadi", "Gerhard P. Fettweis", "Yu Ge", "Hao Guo", "Rreze Halili", "Katsuyuki Haneda", "Abdur Rahman Mohamed Ismail", "Akshay Jain", "Sylvaine Kerboeuf", "Musa Furkan Keskin", "Emad Ibrahim", "Bilal Khan", "Siddhartha Kumar", "Stefan Köpsell", "Apostolos Kousaridas", "Pekka Kyösti", "Simon Lindberg", "Mohammad Hossein Moghaddam", "Ahmad Nimr", "Victor Pettersson", "Aarno Pärssinen", "Basuki Priyanto", "Athanasios Stavridis", "Tommy Svensson", "Sonika Ujjwal"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.10933v2", "summary": "Integrated sensing and communication (ISAC) enables radio systems to\nsimultaneously sense and communicate with their environment. This paper,\ndeveloped within the Hexa-X-II project funded by the European Union, presents a\ncomprehensive cross-layer vision for ISAC in 6G networks, integrating insights\nfrom physical-layer design, hardware architectures, AI-driven intelligence, and\nprotocol-level innovations. We begin by revisiting the foundational principles\nof ISAC, highlighting synergies and trade-offs between sensing and\ncommunication across different integration levels. Enabling technologies (such\nas multiband operation, massive and distributed MIMO, non-terrestrial networks,\nreconfigurable intelligent surfaces, and machine learning) are analyzed in\nconjunction with hardware considerations including waveform design,\nsynchronization, and full-duplex operation. To bridge implementation and\nsystem-level evaluation, we introduce a quantitative cross-layer framework\nlinking design parameters to key performance and value indicators. By\nsynthesizing perspectives from both academia and industry, this paper outlines\nhow deeply integrated ISAC can transform 6G into a programmable and\ncontext-aware platform supporting applications from reliable wireless access to\nautonomous mobility and digital twinning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.10933v2", "cate": "eess.SP", "date": "2025-05-16", "updated": "2025-07-31", "AI": {"title_translation": "跨层集成感知与通信：工业与学术界的联合视角", "tldr": "本文提出了6G网络中集成感知与通信（ISAC）的全面跨层愿景，结合了物理层、硬件、AI和协议层面的见解，并分析了使能技术和硬件考量，旨在将6G转变为可编程和上下文感知的平台。", "motivation": "旨在为6G网络中的集成感知与通信（ISAC）提供一个全面的跨层愿景，整合物理层设计、硬件架构、AI驱动智能和协议级创新，以应对未来应用的需求。", "method": "重新审视ISAC的基础原则，强调感知与通信在不同集成水平上的协同与权衡；分析使能技术（如多频带操作、大规模分布式MIMO、非地面网络、可重构智能表面、机器学习）以及硬件考量；引入一个量化的跨层框架，将设计参数与关键性能和价值指标联系起来；综合学术界和工业界的观点。", "result": "本文概述了深度集成的ISAC如何将6G转变为一个可编程和上下文感知的平台，支持从可靠无线接入到自主移动和数字孪生等应用。", "conclusion": "通过结合工业界和学术界的视角，本文表明深度集成的ISAC能够显著增强6G网络的功能，使其支持广泛的先进应用。", "translation": "集成感知与通信（ISAC）使无线电系统能够同时感知其环境并进行通信。本文在欧盟资助的Hexa-X-II项目内开发，提出了6G网络中ISAC的全面跨层愿景，整合了物理层设计、硬件架构、AI驱动智能和协议级创新的见解。我们首先回顾了ISAC的基本原则，强调了感知与通信在不同集成水平上的协同和权衡。结合硬件考量（包括波形设计、同步和全双工操作），分析了使能技术（如多频带操作、大规模和分布式MIMO、非地面网络、可重构智能表面和机器学习）。为了弥合实施和系统级评估之间的差距，我们引入了一个量化的跨层框架，将设计参数与关键性能和价值指标联系起来。通过综合学术界和工业界的观点，本文概述了深度集成的ISAC如何将6G转变为一个可编程和上下文感知的平台，支持从可靠无线接入到自主移动和数字孪生等应用。", "summary": "这篇论文在欧盟Hexa-X-II项目框架下，为6G网络中的集成感知与通信（ISAC）提出了一个全面的跨层愿景。它回顾了ISAC的基础原则，分析了多频带操作、大规模MIMO、非地面网络、RIS和机器学习等使能技术及其硬件实现。论文还引入了一个量化跨层框架，旨在将设计参数与性能指标关联起来，并综合学术界和工业界观点，阐述了ISAC如何使6G成为可编程和上下文感知的平台，支持多种未来应用。", "keywords": "集成感知与通信, 6G网络, 跨层设计, 使能技术, 工业与学术视角", "comments": "这篇论文的创新点在于提出了一个全面的跨层ISAC愿景，并结合了学术界和工业界的视角，这对于推动6G技术的发展至关重要。其分析的广度，从物理层到协议层，再到硬件和AI，都体现了对ISAC系统复杂性的深刻理解。引入量化跨层框架有助于弥合理论与实践之间的差距，具有很强的实用价值。"}}
{"id": "2502.15276", "title": "Categorical Lyapunov Theory I: Stability of Flows", "authors": ["Aaron D. Ames", "Joe Moeller", "Paulo Tabuada"], "categories": ["math.DS", "cs.SY", "eess.SY", "math.CT", "18M35, 93D05, 93D30, 37B25, 37C75"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2502.15276v2", "summary": "Lyapunov's theorem provides a fundamental characterization of the stability\nof dynamical systems. This paper presents a categorical framework for Lyapunov\ntheory, generalizing stability analysis with Lyapunov functions categorically.\nCore to our approach is the set of axioms underlying a setting for stability,\nwhich give the necessary ingredients for ``doing Lyapunov theory'' in a\ncategory of interest. With these minimal assumptions, we define the stability\nof equilibria, formulate Lyapunov morphisms, and demonstrate that the existence\nof Lyapunov morphisms is necessary and sufficient for establishing the\nstability of flows. To illustrate these constructions, we show how classical\nnotions of stability, e.g., for continuous and discrete time dynamical systems,\nare captured by this categorical framework for Lyapunov theory. Finally, to\ndemonstrate the extensibility of our framework, we illustrate how enriched\ncategories, e.g., Lawvere metric spaces, yield settings for stability enabling\none to ``do Lyapunov theory'' in enriched categories.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2502.15276v2", "cate": "math.DS", "date": "2025-02-21", "updated": "2025-07-30", "AI": {"title_translation": "范畴Lyapunov理论I：流的稳定性", "tldr": "本文提出了一个范畴框架来推广Lyapunov稳定性理论，通过定义稳定性设置的公理、Lyapunov态射，并证明Lyapunov态射的存在性是流稳定性充要条件，并展示了其对经典和广义范畴的适用性。", "motivation": "推广Lyapunov稳定性分析，使其能够在一个范畴框架内进行，从而将稳定性分析与Lyapunov函数范畴化。", "method": "1. 提出了一组定义稳定设置的公理。2. 在这些最小假设下，定义了平衡点的稳定性。3. 提出了Lyapunov态射。4. 证明了Lyapunov态射的存在性是建立流稳定性的必要和充分条件。5. 通过连续和离散时间动力系统等经典稳定性概念来阐释。6. 展示了框架对富范畴（如Lawvere度量空间）的扩展性。", "result": "1. 成功构建了一个范畴框架来推广Lyapunov理论。2. 定义了范畴内的平衡点稳定性。3. 提出了Lyapunov态射。4. 证明了Lyapunov态射的存在性是流稳定性的充要条件。5. 证明了该框架能够捕捉经典的稳定性概念。6. 展示了该框架在富范畴中的适用性。", "conclusion": "本文成功地将Lyapunov稳定性理论推广到一个范畴框架中，并通过定义公理和Lyapunov态射，证明了其普适性和对经典及富范畴的适用性，为稳定性分析提供了一个通用的数学工具。", "translation": "Lyapunov定理为动力系统的稳定性提供了基本表征。本文提出了一个Lyapunov理论的范畴框架，将Lyapunov函数的稳定性分析进行范畴化推广。我们方法的核心是一组构成稳定性设置的公理，这些公理为在感兴趣的范畴中“进行Lyapunov理论”提供了必要的要素。在这些最小假设下，我们定义了平衡点的稳定性，阐述了Lyapunov态射，并证明了Lyapunov态射的存在性是建立流稳定性的必要和充分条件。为了阐明这些构造，我们展示了经典稳定性概念，例如连续和离散时间动力系统的稳定性，是如何被这个Lyapunov理论的范畴框架所捕捉的。最后，为了证明我们框架的可扩展性，我们阐释了富范畴，例如Lawvere度量空间，如何产生稳定性设置，从而使得人们能够在富范畴中“进行Lyapunov理论”。", "summary": "本文提出了一种将Lyapunov稳定性理论范畴化的新框架。该框架基于一组公理来定义稳定性设置，并在最小假设下定义了平衡点稳定性并引入了Lyapunov态射。研究证明，Lyapunov态射的存在性是流稳定的充要条件。此外，该框架不仅能涵盖连续和离散时间动力系统等经典稳定性概念，还能扩展到富范畴（如Lawvere度量空间），为普适的稳定性分析提供了新的理论工具。", "keywords": "范畴论, Lyapunov理论, 稳定性, 动力系统, 富范畴", "comments": "这篇论文通过引入范畴论的抽象工具，将经典的Lyapunov稳定性理论进行了高度的泛化和抽象。其创新之处在于提出了一套普适的公理化框架，使得Lyapunov理论不仅适用于传统的动力系统，还能扩展到更广阔的数学结构，如富范畴。这为理解和分析不同类型系统（包括非传统动力学系统）的稳定性提供了统一的语言和方法，具有重要的理论意义。"}}
{"id": "2507.23541", "title": "Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning", "authors": ["Keer Lu", "Zheng Liang", "Youquan Li", "Jiejun Tan", "Da Pan", "Shusen Zhang", "Guosheng Dong", "Huang Leng"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23541v1", "summary": "In medical scenarios, effectively retrieving external knowledge and\nleveraging it for rigorous logical reasoning is of significant importance.\nDespite their potential, existing work has predominantly focused on enhancing\neither retrieval or reasoning capabilities of the models in isolation, with\nlittle attention given to their joint optimization, which leads to limited\ncoordination between the two processes. Additionally, current methods rely\nheavily on supervised fine-tuning (SFT), which can cause models to memorize\nexisting problem-solving pathways, thereby restricting their generalization\nability when confronted with novel problem contexts. Furthermore, while some\nstudies have explored to improve retrieval-augmented reasoning in general\ndomains via reinforcement learning, their reward function designs do not\nadequately capture the specific demands of the medical domain. To address these\nchallenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented\n**R**easoning framework driven by progressive **R**einforcement learning. In\nthis framework, we first develop the model's ability to perform logical\nreasoning over medical problems. Subsequently, on the basis of this foundation,\nwe adaptively optimize the retrieval capability to better align with the\ncharacteristics of knowledge corpus and external information utilization\nthroughout the reasoning process. Finally, we conduct joint optimization of the\nmodel's retrieval and reasoning coordination. Extensive experiments indicate\nthat **Med-R$^3$** could achieve state-of-the-art performances, with\nLLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by\n3.93\\% at a comparable parameter scale, while Qwen2.5-14B augmented with\nMed-R$^3$ shows a more substantial gain of 13.53\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23541v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Med-R$^3$: 通过渐进式强化学习增强LLMs的医学检索增强推理能力", "tldr": "Med-R$^3$是一个通过渐进式强化学习提升LLM在医学领域检索增强推理能力的框架，解决了现有方法孤立优化、SFT限制泛化和通用RL奖励函数不适用医学领域的问题，并取得了最先进的性能。", "motivation": "在医学场景中，有效检索外部知识并用于严谨的逻辑推理至关重要。现有工作主要孤立地增强模型的检索或推理能力，导致两者之间协调性有限。此外，当前方法过度依赖监督微调（SFT），这可能导致模型记忆现有问题解决路径，从而限制其在面对新问题时的泛化能力。最后，虽然一些研究探索了通过强化学习改进通用领域的检索增强推理，但它们的奖励函数设计未能充分捕捉医学领域的特定需求。", "method": "我们提出了Med-R$^3$，一个由渐进式强化学习驱动的医学检索增强推理框架。该框架首先培养模型对医学问题进行逻辑推理的能力。随后，在此基础上，我们自适应地优化检索能力，使其更好地与知识语料库和推理过程中外部信息利用的特性对齐。最后，我们对模型的检索和推理协调进行联合优化。", "result": "广泛的实验表明，Med-R$^3$能够实现最先进的性能。LLaMA3.1-8B-Instruct + Med-R$^3$在可比参数规模下超越闭源的GPT-4o-mini 3.93%，而Qwen2.5-14B增强Med-R$^3$则取得了更显著的13.53%的提升。", "conclusion": "Med-R$^3$通过渐进式强化学习有效解决了现有医学检索增强推理中检索与推理协调性差、模型泛化能力受限以及强化学习奖励函数不匹配医学领域需求的问题，显著提升了大型语言模型在医学场景下的推理表现。", "translation": "在医学场景中，有效检索外部知识并利用其进行严谨的逻辑推理至关重要。尽管现有工作具有潜力，但它们主要侧重于单独增强模型的检索或推理能力，很少关注它们的联合优化，这导致两个过程之间的协调性有限。此外，当前方法严重依赖监督微调（SFT），这可能导致模型记忆现有的问题解决路径，从而限制其在面对新问题上下文时的泛化能力。此外，尽管一些研究探索了通过强化学习改进通用领域的检索增强推理，但它们的奖励函数设计未能充分捕捉医学领域的特定需求。为了解决这些挑战，我们引入了Med-R$^3$，一个由渐进式强化学习驱动的医学检索增强推理框架。在该框架中，我们首先培养模型对医学问题进行逻辑推理的能力。随后，在此基础上，我们自适应地优化检索能力，使其更好地与知识语料库和推理过程中外部信息利用的特性对齐。最后，我们对模型的检索和推理协调进行联合优化。广泛的实验表明，Med-R$^3$能够实现最先进的性能，其中LLaMA3.1-8B-Instruct + Med-R$^3$在可比参数规模下超越闭源的GPT-4o-mini 3.93%，而Qwen2.5-14B增强Med-R$^3$则显示出更显著的13.53%的提升。", "summary": "该论文提出了Med-R$^3$，一个用于增强大型语言模型在医学领域检索增强推理能力的框架。针对现有方法在检索与推理联合优化不足、监督微调导致的泛化能力受限以及通用强化学习奖励函数不适用于医学领域等挑战，Med-R$^3$采用渐进式强化学习。其方法包括：首先发展模型逻辑推理能力，然后自适应优化检索能力以更好地整合外部知识，最后联合优化检索与推理的协调性。实验结果表明，Med-R$^3$达到了最先进的性能，显著超越了基线模型和一些闭源模型，证明了其在医学检索增强推理方面的有效性。", "keywords": "医学检索增强推理, 大型语言模型, 渐进式强化学习, 联合优化, 医疗AI", "comments": "Med-R$^3$的创新性在于其提出的渐进式强化学习框架，该框架系统地解决了医学领域检索增强推理中检索与推理协调性差、模型泛化能力受限等关键问题。通过分阶段优化推理、检索以及两者的联合协调，该方法能够更精细地调整模型行为。特别是在医学这种对准确性要求极高的领域，这种联合且渐进的优化尤为重要。实验结果的显著提升，尤其是对GPT-4o-mini的超越，凸显了其在实际应用中的巨大潜力。"}}
{"id": "2505.02178", "title": "Sparfels: Fast Reconstruction from Sparse Unposed Imagery", "authors": ["Shubhendu Jena", "Amine Ouasfi", "Mae Younes", "Adnane Boukhayma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Project page : this https URL", "url": "http://arxiv.org/abs/2505.02178v4", "summary": "We present a method for Sparse view reconstruction with surface element\nsplatting that runs within 3 minutes on a consumer grade GPU. While few methods\naddress sparse radiance field learning from noisy or unposed sparse cameras,\nshape recovery remains relatively underexplored in this setting. Several\nradiance and shape learning test-time optimization methods address the sparse\nposed setting by learning data priors or using combinations of external\nmonocular geometry priors. Differently, we propose an efficient and simple\npipeline harnessing a single recent 3D foundation model. We leverage its\nvarious task heads, notably point maps and camera initializations to\ninstantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image\ncorrespondences to guide camera optimization midst 2DGS training. Key to our\ncontribution is a novel formulation of splatted color variance along rays,\nwhich can be computed efficiently. Reducing this moment in training leads to\nmore accurate shape reconstructions. We demonstrate state-of-the-art\nperformances in the sparse uncalibrated setting in reconstruction and novel\nview benchmarks based on established multi-view datasets.", "comment": "ICCV 2025. Project page :\n  https://shubhendu-jena.github.io/Sparfels-web/", "pdf_url": "http://arxiv.org/pdf/2505.02178v4", "cate": "cs.CV", "date": "2025-05-04", "updated": "2025-07-31", "AI": {"title_translation": "Sparfels: 稀疏未定位图像的快速重建", "tldr": "提出Sparfels，一种基于表面元素泼溅的稀疏视图重建方法，利用3D基础模型和2D高斯泼溅，实现未校准稀疏设置下的快速高精度形状重建。", "motivation": "现有方法很少解决从嘈杂或未定位的稀疏相机中学习稀疏辐射场的问题，并且在这种设置下形状恢复相对未被充分探索。", "method": "提出一种高效简单的管道，利用单个近期3D基础模型的点图和相机初始化来实例化一个束调整2D高斯泼溅（2DGS）模型，并使用图像对应关系在2DGS训练中指导相机优化。关键在于提出一种沿光线泼溅颜色方差的新公式，有效计算并减少其在训练中的值，以实现更准确的形状重建。", "result": "在基于已建立的多视图数据集的重建和新视图基准测试中，在稀疏未校准设置下展示了最先进的性能，并在消费级GPU上3分钟内完成。", "conclusion": "通过引入新的颜色方差公式和利用3D基础模型，Sparfels在稀疏未校准图像的快速、高精度形状重建方面取得了显著进展，达到了最先进的性能。", "translation": "我们提出了一种使用表面元素泼溅进行稀疏视图重建的方法，该方法在消费级GPU上可在3分钟内运行。虽然很少有方法解决从嘈杂或未定位的稀疏相机中学习稀疏辐射场的问题，但在此设置下形状恢复相对未被充分探索。一些辐射和形状学习的测试时间优化方法通过学习数据先验或使用外部单目几何先验的组合来解决稀疏定位设置。不同的是，我们提出了一种高效简单的管道，利用单一的近期3D基础模型。我们利用其各种任务头，特别是点图和相机初始化来实例化一个束调整的2D高斯泼溅（2DGS）模型，并利用图像对应关系在2DGS训练中指导相机优化。我们贡献的关键是提出了一种沿光线泼溅颜色方差的新颖公式，该公式可以高效计算。在训练中减少这一矩可以带来更准确的形状重建。我们基于已建立的多视图数据集，在重建和新视图基准测试中，展示了稀疏未校准设置下的最先进性能。", "summary": "本文介绍了Sparfels，一种用于稀疏视图重建的新方法，该方法利用表面元素泼溅技术，并能在消费级GPU上快速运行（3分钟内）。针对从嘈杂或未定位的稀疏相机中进行形状恢复的挑战，Sparfels提出了一种高效简单的流程，它集成了一个3D基础模型，利用其点图和相机初始化来构建一个束调整的2D高斯泼溅（2DGS）模型。此外，该方法利用图像对应关系来优化2DGS训练期间的相机参数。论文的核心贡献在于提出了一种新的沿光线泼溅颜色方差的计算方法，通过优化该方差来提高形状重建的精度。实验结果表明，Sparfels在稀疏未校准设置下的重建和新视图合成方面达到了最先进的性能。", "keywords": "稀疏视图重建, 表面元素泼溅, 2D高斯泼溅, 未定位图像, 3D基础模型", "comments": "该论文的创新点在于结合了3D基础模型和2D高斯泼溅技术，并提出了一个高效的颜色方差公式来指导形状重建，有效解决了稀疏未定位图像的快速高精度重建问题。其在消费级GPU上3分钟内完成重建的速度，以及在稀疏未校准设置下达到SOTA性能，显示了其实用性和重要性。"}}
{"id": "2507.23330", "title": "AI Must not be Fully Autonomous", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl Löwenmark"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      11 pages, 1 figure", "url": "http://arxiv.org/abs/2507.23330v1", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "comment": "11 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.23330v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "人工智能绝不能完全自主", "tldr": "论文认为，由于风险巨大，特别是考虑到人工超级智能的临近，人工智能不应完全自主，人类的负责任监督至关重要。", "motivation": "识别并强调自主人工智能（特别是完全自主的AI）所带来的巨大风险，并指出当前缺乏负责任的人类监督，尤其是在人工超级智能（ASI）可能即将出现的情况下，因此认为AI不应完全自主。", "method": "作者首先识别了自主人工智能的三个级别。为了支持其立场，论文讨论了自主性、人工智能和代理的理论。接着，提出了12个不同的论点以及6个带有反驳的反论点。此外，还在附录中提供了15项关于AI价值观错位及其他风险的近期证据。", "result": "论文得出结论，人工智能绝不能完全自主，因为完全自主的AI（第三级别，能自行设定目标）缺乏负责任的人类监督，而这种监督对于降低风险至关重要。", "conclusion": "鉴于自主人工智能，特别是人工超级智能带来的潜在巨大风险，人工智能不应被允许完全自主，负责任的人类监督对于风险缓解至关重要。", "translation": "自主人工智能（AI）有诸多益处，但也伴随着许多风险。在这项工作中，我们识别了自主人工智能的三个级别。我们认为，由于存在许多风险，特别是考虑到人工超级智能（ASI）可能仅在几十年后出现，人工智能绝不能完全自主。能够发展自身目标的完全自主AI属于第三级别，并且缺乏负责任的人类监督。然而，负责任的人类监督对于减轻风险至关重要。为了论证我们的立场，我们讨论了自主性、人工智能和代理的理论。然后，我们提出了12个不同的论点和6个带有反驳的反论点。我们还在附录中提供了15项关于AI价值观错位及其他风险的近期证据。", "summary": "这篇论文探讨了自主人工智能的益处与风险，并将其自主性分为三个级别。论文的核心观点是，鉴于潜在的巨大风险（尤其是人工超级智能的临近），人工智能不应被允许完全自主。作者强调，完全自主的AI（第三级别）缺乏必要的人类监督，而这种负责任的监督对于风险缓解至关重要。为支持此观点，论文探讨了自主性理论，并提出了12个论点及6个反论点（附带反驳），同时在附录中提供了15项AI风险证据。", "keywords": "自主人工智能,人类监督,风险,人工超级智能,AI伦理", "comments": "这篇论文的创新之处在于其明确且强烈的立场：AI不应完全自主。其重要性在于及时地提出了对未来AI发展方向的警示，特别是在ASI可能出现之前。通过系统性地提供论点、反论点和实证证据，增强了其论证的说服力。论文强调人类监督的必要性，为AI伦理和治理提供了重要的思考方向。"}}
{"id": "2507.21903", "title": "Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation", "authors": ["Tiviatis Sim", "Kaiwen Yang", "Shen Xin", "Kenji Kawaguchi"], "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21903v2", "summary": "As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21903v2", "cate": "cs.SI", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "谁是重要的？-- SUnSET：利益相关者、事件和时间的协同理解用于时间线生成", "tldr": "提出SUnSET框架，利用LLM和利益相关者排名生成新闻时间线，优于现有方法。", "motivation": "现有新闻摘要方法未能有效跟踪跨源事件，特别是在分析事件中涉及的各方方面存在不足，导致无法有效衡量利益相关者的重要性及相关事件的联系。", "method": "提出了SUnSET（Synergistic Understanding of Stakeholder, Events and Time）框架，用于时间线摘要任务。该方法利用大型语言模型（LLMs）构建SET三元组，并引入了基于利益相关者的排名来构建“Relevancy”度量。", "result": "实验结果优于所有先前的基线方法，并达到了新的最先进水平，突出了新闻文章中利益相关者信息的重要性。", "conclusion": "SUnSET通过整合利益相关者、事件和时间信息，显著提升了时间线摘要的性能，证明了考虑利益相关者信息在新闻分析中的关键作用。", "translation": "随着新闻报道在全球范围内日益普及和在线去中心化，跟踪多个来源的相关事件带来了重大挑战。现有新闻摘要方法通常利用大型语言模型和图方法对基于文章的摘要进行处理。然而，这并不有效，因为它只考虑日期相似文章的文本内容来理解事件的要旨。为了弥补对参与方分析的不足，提出一种新颖的框架来衡量利益相关者的重要性以及通过相关实体连接事件至关重要。因此，我们提出了SUnSET：利益相关者、事件和时间的协同理解，用于时间线摘要（TLS）任务。我们利用强大大型语言模型（LLMs）构建SET三元组，并引入了基于利益相关者的排名来构建一个“Relevancy”度量，该度量可以扩展到一般情况。我们的实验结果优于所有先前的基线，并成为新的最先进技术，突出了新闻文章中利益相关者信息的影响。", "summary": "针对现有新闻摘要方法在处理跨源事件和分析参与方方面的不足，本文提出了SUnSET框架，该框架通过利用大型语言模型构建利益相关者、事件和时间（SET）三元组，并引入基于利益相关者的排名来计算事件相关性，从而生成更有效的时间线摘要。实验证明SUnSET在性能上超越了现有基线，达到了新的SOTA水平，强调了利益相关者信息在新闻分析中的重要性。", "keywords": "时间线摘要, 利益相关者, 大型语言模型, 新闻分析, 事件跟踪", "comments": "该论文创新性地将利益相关者信息引入时间线摘要任务，弥补了传统方法仅关注文本内容而忽略事件参与方的不足。通过引入SET三元组和基于利益相关者的排名，为新闻事件的深入理解和跟踪提供了新视角，具有较高的实用价值和理论意义。"}}
{"id": "2407.15738", "title": "Parallel Split Learning with Global Sampling", "authors": ["Mohammad Kohankhaki", "Ahmad Ayad", "Mahdi Barhoush", "Anke Schmeink"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.15738v4", "summary": "Distributed deep learning in resource-constrained environments faces\nscalability and generalization challenges due to large effective batch sizes\nand non-identically distributed client data. We introduce a server-driven\nsampling strategy that maintains a fixed global batch size by dynamically\nadjusting client-side batch sizes. This decouples the effective batch size from\nthe number of participating devices and ensures that global batches better\nreflect the overall data distribution. Using standard concentration bounds, we\nestablish tighter deviation guarantees compared to existing approaches.\nEmpirical results on a benchmark dataset confirm that the proposed method\nimproves model accuracy, training efficiency, and convergence stability,\noffering a scalable solution for learning at the network edge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.15738v4", "cate": "cs.LG", "date": "2024-07-22", "updated": "2025-07-31", "AI": {"title_translation": "具有全局采样的并行拆分学习", "tldr": "本文提出了一种服务器驱动的采样策略，通过动态调整客户端批次大小来解决资源受限环境下分布式深度学习的挑战，从而改善模型精度、训练效率和收敛稳定性。", "motivation": "在资源受限环境中，分布式深度学习面临可扩展性和泛化挑战，这主要是由于有效的批处理大小过大以及客户端数据分布不一致。", "method": "本文引入了一种服务器驱动的采样策略，该策略通过动态调整客户端批处理大小来维持固定的全局批处理大小。这使得有效批处理大小与参与设备数量解耦，并确保全局批处理更好地反映整体数据分布。通过标准集中界限，该方法建立了比现有方法更严格的偏差保证。", "result": "在基准数据集上的实证结果证实，所提出的方法提高了模型精度、训练效率和收敛稳定性。", "conclusion": "本文提出的方法为网络边缘学习提供了一个可扩展的解决方案，有效解决了资源受限环境下分布式深度学习的挑战。", "translation": "在资源受限环境中，分布式深度学习面临可扩展性和泛化挑战，这主要是由于有效的批处理大小过大以及客户端数据非同分布。我们引入了一种服务器驱动的采样策略，通过动态调整客户端批处理大小来维持固定的全局批处理大小。这使得有效批处理大小与参与设备数量解耦，并确保全局批处理更好地反映整体数据分布。使用标准集中界限，我们建立了比现有方法更严格的偏差保证。在基准数据集上的实证结果证实，所提出的方法提高了模型精度、训练效率和收敛稳定性，为网络边缘学习提供了一个可扩展的解决方案。", "summary": "本文针对资源受限环境下分布式深度学习的可扩展性和泛化挑战，提出了一种服务器驱动的全局采样策略。该策略通过动态调整客户端批次大小来维持固定的全局批次大小，从而解耦有效批次大小与设备数量，并确保全局批次更好地代表整体数据分布。理论上，该方法提供了更严格的偏差保证，并通过实验证明其能提高模型精度、训练效率和收敛稳定性，为边缘学习提供了一种可扩展的解决方案。", "keywords": "分布式深度学习, 全局采样, 拆分学习, 边缘计算, 资源受限", "comments": "该论文通过引入一种创新的服务器驱动采样策略，有效解决了分布式深度学习在资源受限环境中的关键挑战，即大规模有效批次和数据非同分布问题。其创新点在于动态调整客户端批次大小以维持全局批次固定，这不仅提高了训练效率和模型精度，还增强了收敛稳定性。此方法对于边缘计算和联邦学习等场景具有重要意义，提供了一个实用的可扩展解决方案。"}}
{"id": "2504.16710", "title": "On the Asymptotic MSE-Optimality of Parametric Bayesian Channel Estimation in mmWave Systems", "authors": ["Franz Weißer", "Wolfgang Utschick"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.16710v2", "summary": "The mean square error (MSE)-optimal estimator is known to be the conditional\nmean estimator (CME). This paper introduces a parametric channel estimation\ntechnique based on Bayesian estimation. This technique uses the estimated\nchannel parameters to parameterize the well-known LMMSE channel estimator. We\nfirst derive an asymptotic CME formulation that holds for a wide range of\npriors on the channel parameters. Based on this, we show that parametric\nBayesian channel estimation is MSE-optimal for high signal-to-noise ratio (SNR)\nand/or long coherence intervals, i.e., many noisy observations provided within\none coherence interval. Numerical simulations validate the derived\nformulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.16710v2", "cate": "eess.SP", "date": "2025-04-23", "updated": "2025-07-31", "AI": {"title_translation": "毫米波系统中参数贝叶斯信道估计的渐近MSE最优性研究", "tldr": "本文提出一种参数贝叶斯信道估计技术，在高信噪比和/或长相干区间下，该技术能实现MSE最优性。", "motivation": "已知条件均值估计器（CME）是均方误差（MSE）最优的估计器，本文旨在引入一种新的参数信道估计技术，以期达到MSE最优性。", "method": "论文引入了一种基于贝叶斯估计的参数信道估计技术。该技术利用估计的信道参数来参数化LMMSE信道估计器，并推导了一个适用于各种信道参数先验的渐近CME公式。", "result": "研究表明，在信噪比高和/或相干区间长（即在一个相干区间内提供许多噪声观测）的情况下，参数贝叶斯信道估计是MSE最优的。数值模拟验证了所推导的公式。", "conclusion": "参数贝叶斯信道估计在特定条件下（高信噪比和/或长相干区间）能达到均方误差（MSE）最优。", "translation": "已知均方误差（MSE）最优估计器是条件均值估计器（CME）。本文介绍了一种基于贝叶斯估计的参数信道估计技术。该技术利用估计的信道参数来参数化众所周知的LMMSE信道估计器。我们首先推导了一个适用于各种信道参数先验的渐近CME公式。在此基础上，我们表明参数贝叶斯信道估计在高信噪比（SNR）和/或长相干区间，即在一个相干区间内提供许多噪声观测的情况下，是MSE最优的。数值模拟验证了所推导的公式。", "summary": "本文提出了一种基于贝叶斯估计的参数信道估计新方法，该方法通过信道参数化LMMSE估计器。研究推导了一个渐近CME公式，并证明了该参数贝叶斯信道估计在高信噪比或长相干区间下能实现均方误差（MSE）最优性。数值模拟验证了理论推导。", "keywords": "毫米波系统, 信道估计, 贝叶斯估计, MSE最优性, LMMSE估计器", "comments": "本文的创新在于将参数贝叶斯估计与LMMSE估计器结合，并从理论上证明了其在特定条件下的渐近MSE最优性，这对于毫米波系统中的信道估计具有重要意义。"}}
{"id": "2507.23586", "title": "Fitted norm preconditioners for the Hodge Laplacian in mixed form", "authors": ["Wietse M. Boon", "Johannes Kraus", "Tomáš Luber", "Maria Lymbery"], "categories": ["math.NA", "cs.NA", "65N22, 65F08, 35J05, 58J10, 65N30, 58A14"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23586v1", "summary": "We use the practical framework for abstract perturbed saddle point problems\nrecently introduced by Hong et al. to analyze the mixed formulation of the\nHodge Laplace problem. We compose two parameter-dependent norms in which the\nuniform continuity and stability of the problem follow. This not only\nguarantees the well-posedness of the corresponding variational formulation on\nthe continuous level, but also of related compatible discrete models.\n  We further simplify the obtained norms and, in both cases, arrive at the same\nnorm-equivalent preconditioner that is easily implementable. The efficiency and\nuniformity of the preconditioner are demonstrated numerically by the fast\nconvergence and uniformly bounded number of preconditioned MINRES iterations\nrequired to solve various instances of Hodge Laplace problems in two and three\nspace dimensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23586v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "混合形式Hodge拉普拉斯算子的拟合范数预条件子", "tldr": "本文利用Hong等人的框架分析了Hodge拉普拉斯问题的混合形式，构建了参数相关的范数来保证适定性，并得到了一个易于实现的范数等价预条件子，数值结果表明其高效且一致。", "motivation": "分析Hodge拉普拉斯问题的混合形式，并保证其适定性，同时开发一个高效且易于实现的预条件子。", "method": "使用Hong等人提出的抽象扰动鞍点问题框架分析Hodge拉普拉斯问题的混合形式。构建两个参数相关的范数，以确保问题的均匀连续性和稳定性。简化所得范数，得到一个易于实现的范数等价预条件子。通过数值实验，使用预处理MINRES迭代的快速收敛和均匀有界次数来验证预条件子的效率和一致性。", "result": "通过构建参数相关的范数，保证了连续水平上变分公式和相关兼容离散模型的适定性。成功得到一个易于实现的范数等价预条件子。数值实验证明该预条件子在解决二维和三维Hodge拉普拉斯问题时具有高效性和一致性，表现为快速收敛和均匀有界的预处理MINRES迭代次数。", "conclusion": "本研究成功为Hodge拉普拉斯问题的混合形式开发了一个高效且一致的拟合范数预条件子，并通过理论分析和数值实验验证了其有效性，解决了该问题的适定性及计算效率问题。", "translation": "我们利用Hong等人最近引入的抽象扰动鞍点问题的实用框架来分析Hodge拉普拉斯问题的混合形式。我们构建了两个参数相关的范数，从而保证了问题的均匀连续性和稳定性。这不仅保证了连续水平上相应变分公式的适定性，也保证了相关兼容离散模型的适定性。我们进一步简化了所获得的范数，并且在两种情况下都得到了一个相同且易于实现的范数等价预条件子。通过求解二维和三维空间中Hodge拉普拉斯问题的各种实例所需的预处理MINRES迭代的快速收敛和均匀有界次数，数值证明了该预条件子的效率和一致性。", "summary": "本文利用Hong等人提出的抽象扰动鞍点问题框架，对Hodge拉普拉斯问题的混合形式进行了分析。通过构建参数相关的范数，确保了连续和离散层面问题的适定性。研究进一步简化了这些范数，得到了一个易于实现的范数等价预条件子。数值实验验证了该预条件子在解决二维和三维Hodge拉普拉斯问题时的效率和一致性，表现出快速收敛和均匀有界的迭代次数。", "keywords": "Hodge Laplacian, 混合形式, 预条件子, 鞍点问题, 数值分析", "comments": "这篇论文的创新点在于将抽象扰动鞍点问题的框架应用于Hodge拉普拉斯问题，并成功地构建了参数相关的范数，从而保证了问题的适定性。更重要的是，他们导出了一个易于实现且高效的拟合范数预条件子，这对于解决大规模Hodge拉普拉斯问题具有重要的实际意义。数值结果有力地支持了其理论发现。"}}
{"id": "2507.23200", "title": "Efficient DFT of Zadoff-Chu Sequences using lmFH Pattern", "authors": ["Fanping Du"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures", "url": "http://arxiv.org/abs/2507.23200v1", "summary": "Having established that Zadoff-Chu (ZC) sequences are inherently linear\nmicro-frequency hopping (lmFH) symbols, this paper first presents an intuitive\nand visual exposition of the computation of the DFT and IDFT of ZC sequences\nusing the lmFH pattern. This yields interesting results. Subsequently, an\nalternative form for computing the cumulative sum of ZC sequences using the\nGeneralized Quadratic Gauss Sum is introduced. Furthermore, building on the\nmicro-frequency hopping (mFH) concept, this paper shows that the DFT of ZC\nsequences can be transformed into an lmFH symbol with frequency shift and phase\noffset. Therefore, the DFT of ZC sequences can be computed via cumulative\nfrequency points, similar to the computation of normal mFH symbols.", "comment": "8 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.23200v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用lmFH模式的高效Zadoff-Chu序列DFT", "tldr": "该论文提出了一种利用线性微跳频（lmFH）模式高效计算Zadoff-Chu（ZC）序列离散傅里叶变换（DFT）的方法。", "motivation": "论文的动机是利用Zadoff-Chu (ZC) 序列固有的线性微跳频 (lmFH) 符号特性，以更直观和高效的方式计算其离散傅里叶变换 (DFT) 和逆离散傅里叶变换 (IDFT)。", "method": "论文首先通过lmFH模式对ZC序列的DFT和IDFT计算进行了直观的可视化阐述。其次，引入了一种使用广义二次高斯和计算ZC序列累积和的替代形式。最后，基于微跳频(mFH)概念，展示了ZC序列的DFT可以转换为具有频移和相位偏移的lmFH符号，从而可以通过累积频率点进行计算。", "result": "论文指出通过lmFH模式计算DFT和IDFT能产生“有趣的结果”，并且展示了ZC序列的DFT可以被有效地转换为lmFH符号并以类似普通mFH符号的方式通过累积频率点进行计算。", "conclusion": "论文得出结论，由于Zadoff-Chu序列可以被视为具有频移和相位偏移的线性微跳频符号，因此它们的离散傅里叶变换可以通过累积频率点高效地计算。", "translation": "标题：使用lmFH模式的高效Zadoff-Chu序列DFT\n摘要：在确定Zadoff-Chu (ZC) 序列本质上是线性微跳频 (lmFH) 符号之后，本文首先直观地、可视地阐述了使用lmFH模式计算ZC序列的DFT和IDFT。这产生了有趣的结果。随后，引入了一种使用广义二次高斯和计算ZC序列累积和的替代形式。此外，本文基于微跳频 (mFH) 概念，展示了ZC序列的DFT可以转换为具有频移和相位偏移的lmFH符号。因此，ZC序列的DFT可以通过累积频率点进行计算，类似于普通mFH符号的计算。", "summary": "本文探讨了Zadoff-Chu (ZC) 序列与线性微跳频 (lmFH) 符号的内在联系，并提出了一种高效计算ZC序列离散傅里叶变换 (DFT) 和逆离散傅里叶变换 (IDFT) 的方法。通过利用lmFH模式，论文提供了直观的计算阐述，并引入了基于广义二次高斯和的累积和计算形式。最终，论文证明ZC序列的DFT可转换为带频移和相位偏移的lmFH符号，从而能通过累积频率点进行计算，提高了计算效率。", "keywords": "Zadoff-Chu序列, 离散傅里叶变换, 线性微跳频, 广义二次高斯和", "comments": "这篇论文的创新点在于将Zadoff-Chu序列与线性微跳频符号建立了联系，并利用这一内在特性提供了一种新的、可能更高效或更直观的DFT计算方法。这种方法可能在需要快速处理Zadoff-Chu序列的通信或雷达系统中具有潜在应用价值。论文强调了“直观和可视化阐述”，这可能有助于理解复杂的信号处理概念。"}}
{"id": "2505.12620", "title": "BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation", "authors": ["Haiquan Wen", "Yiwei He", "Zhenglin Huang", "Tianxiao Li", "Zihan Yu", "Xingru Huang", "Lu Qi", "Baoyuan Wu", "Xiangtai Li", "Guangliang Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12620v4", "summary": "Advances in AI generative models facilitate super-realistic video synthesis,\namplifying misinformation risks via social media and eroding trust in digital\ncontent. Several research works have explored new deepfake detection methods on\nAI-generated images to alleviate these risks. However, with the fast\ndevelopment of video generation models, such as Sora and WanX, there is\ncurrently a lack of large-scale, high-quality AI-generated video datasets for\nforgery detection. In addition, existing detection approaches predominantly\ntreat the task as binary classification, lacking explainability in model\ndecision-making and failing to provide actionable insights or guidance for the\npublic. To address these challenges, we propose \\textbf{GenBuster-200K}, a\nlarge-scale AI-generated video dataset featuring 200K high-resolution video\nclips, diverse latest generative techniques, and real-world scenes. We further\nintroduce \\textbf{BusterX}, a novel AI-generated video detection and\nexplanation framework leveraging multimodal large language model (MLLM) and\nreinforcement learning for authenticity determination and explainable\nrationale. To our knowledge, GenBuster-200K is the {\\it \\textbf{first}}\nlarge-scale, high-quality AI-generated video dataset that incorporates the\nlatest generative techniques for real-world scenarios. BusterX is the {\\it\n\\textbf{first}} framework to integrate MLLM with reinforcement learning for\nexplainable AI-generated video detection. Extensive comparisons with\nstate-of-the-art methods and ablation studies validate the effectiveness and\ngeneralizability of BusterX. The code, models, and datasets will be released.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12620v4", "cate": "cs.CV", "date": "2025-05-19", "updated": "2025-07-31", "AI": {"title_translation": "BusterX：基于多模态大语言模型的AI生成视频伪造检测与解释", "tldr": "本文提出了GenBuster-200K数据集和BusterX框架，用于解决AI生成视频伪造检测中数据集匮乏、缺乏可解释性的问题。", "motivation": "AI生成模型（如Sora和WanX）的进步使得超真实视频合成成为可能，这加剧了社交媒体上的错误信息风险，并侵蚀了对数字内容的信任。现有的深度伪造检测方法主要针对图像，且视频领域缺乏大规模高质量数据集。此外，现有检测方法多为二分类，缺乏模型决策的可解释性，无法为公众提供可操作的见解或指导。", "method": "为了解决上述挑战，本文提出了GenBuster-200K，一个大规模AI生成视频数据集，包含20万个高分辨率视频片段，涵盖多样化的最新生成技术和真实世界场景。此外，本文还引入了BusterX，一个新颖的AI生成视频检测和解释框架，该框架利用多模态大语言模型（MLLM）和强化学习进行真实性判断和可解释的理由生成。", "result": "与最先进方法的广泛比较和消融研究验证了BusterX的有效性和泛化能力。", "conclusion": "GenBuster-200K是首个整合最新生成技术用于真实场景的大规模高质量AI生成视频数据集。BusterX是首个将MLLM与强化学习相结合用于可解释AI生成视频检测的框架。该研究有效解决了AI生成视频伪造检测中数据集和可解释性不足的问题。", "translation": "AI生成模型的进步促进了超现实视频合成，通过社交媒体放大了错误信息风险，并侵蚀了对数字内容的信任。一些研究工作已经探索了AI生成图像上的新型深度伪造检测方法，以减轻这些风险。然而，随着Sora和WanX等视频生成模型的快速发展，目前缺乏用于伪造检测的大规模、高质量AI生成视频数据集。此外，现有的检测方法主要将任务视为二分类，缺乏模型决策的可解释性，并且未能为公众提供可操作的见解或指导。为了应对这些挑战，我们提出了GenBuster-200K，一个大规模AI生成视频数据集，包含20万个高分辨率视频片段、多样化的最新生成技术和真实世界场景。我们进一步引入了BusterX，一个新颖的AI生成视频检测和解释框架，该框架利用多模态大语言模型（MLLM）和强化学习进行真实性判断和可解释的理由。据我们所知，GenBuster-200K是第一个融合最新生成技术用于真实场景的大规模高质量AI生成视频数据集。BusterX是第一个将MLLM与强化学习相结合用于可解释AI生成视频检测的框架。与最先进方法的广泛比较和消融研究验证了BusterX的有效性和泛化能力。代码、模型和数据集将发布。", "summary": "本文针对AI生成视频伪造检测中数据集匮乏和缺乏可解释性的问题，提出了两项创新。首先，构建了GenBuster-200K，一个包含20万个高分辨率、多样化最新生成技术和真实场景的大规模AI生成视频数据集。其次，开发了BusterX框架，该框架首次结合多模态大语言模型（MLLM）和强化学习，实现AI生成视频的真实性检测并提供可解释的理由。实验结果验证了BusterX的有效性和泛化能力。", "keywords": "AI生成视频, 伪造检测, 多模态大语言模型, 强化学习, 数据集", "comments": "本文的创新点在于构建了首个大规模、高质量、包含最新生成技术的AI生成视频数据集GenBuster-200K，这对于推动该领域的研究具有重要意义。同时，BusterX框架首次将MLLM与强化学习结合用于可解释的AI生成视频检测，为解决现有方法缺乏解释性的问题提供了新颖的思路。这种结合有望提高检测的准确性，并增强公众对检测结果的信任度。"}}
{"id": "2507.23653", "title": "Architectural practice process and artificial intelligence -- an evolving practice", "authors": ["Mustapha El Moussaoui"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures. De Gruyter Brill - Open Engineering 2025", "url": "http://arxiv.org/abs/2507.23653v1", "summary": "In an era of exponential technological advancement, artificial intelligence\n(AI) has emerged as a transformative force in architecture, reshaping\ntraditional design and construction practices. This article explores the\nmultifaceted roles of AI in the architectural process, emphasizing its\npotential to enhance creativity and efficiency while addressing its limitations\nin capturing multisensory and experiential dimensions of space. Historically,\narchitectural innovation has paralleled technological progress, from basic\ntools to advanced computer-aided design systems. However, the integration of AI\npresents unique challenges, requiring architects to critically evaluate its\nrole in design. A narrative review methodology was adopted, focusing on\nacademic sources selected for their relevance, recency, and credibility. The\nfindings reveal that AI is increasingly integrated across various stages of the\narchitectural process, from early conceptualization and site analysis to\ngenerative design and construction detailing. AI tools excel at automating\nrepetitive tasks and generating innovative design solutions, freeing architects\nto focus on creativity and problem-solving. Additionally, AI's (text- toimage)\nvisual representation strength challenges the ocularcentric approaches in\narchitecture, which should push future architects to address the holistic\nsensory and experiential qualities of space or the critical thinking inherent\nto architectural design. While AI offers transformative potential, architects\nmust view it as a collaborative partner rather than a passive tool.", "comment": "15 pages, 7 figures. De Gruyter Brill - Open Engineering 2025", "pdf_url": "http://arxiv.org/pdf/2507.23653v1", "cate": "cs.CY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "建筑实践过程与人工智能——一种演进中的实践", "tldr": "人工智能正在重塑建筑实践，提高效率和创造力，但建筑师需认识其局限性并将其视为协作伙伴。", "motivation": "在技术飞速发展的时代，人工智能（AI）正在深刻改变建筑领域，重塑传统设计和施工实践。本文旨在探讨AI在建筑过程中的多方面作用，强调其在提升创造力和效率方面的潜力，同时指出其在捕捉空间多感官和体验维度方面的局限性，并分析其集成所带来的独特挑战。", "method": "本文采用叙述性综述方法，重点关注与主题相关、最新且可信的学术资源。", "result": "研究发现，AI正日益融入建筑过程的各个阶段，从早期概念化和场地分析到生成式设计和施工细节。AI工具擅长自动化重复性任务并生成创新设计方案，从而使建筑师能够专注于创造力和解决问题。此外，AI的视觉表示能力（文本到图像）挑战了建筑中以视觉为中心的方法，这将促使未来的建筑师关注空间的整体感官和体验品质或建筑设计中固有的批判性思维。", "conclusion": "尽管AI具有变革性潜力，但建筑师必须将其视为协作伙伴，而非被动工具。", "translation": "在技术飞速发展的时代，人工智能（AI）已成为建筑领域的一股变革力量，重塑了传统的设计和施工实践。本文探讨了AI在建筑过程中的多方面作用，强调其在提升创造力和效率方面的潜力，同时指出其在捕捉空间多感官和体验维度方面的局限性。从历史上看，建筑创新与技术进步并行，从基本工具到先进的计算机辅助设计系统。然而，AI的集成带来了独特的挑战，要求建筑师批判性地评估其在设计中的作用。本文采用叙述性综述方法，重点关注与主题相关、最新且可信的学术资源。研究结果表明，AI正日益融入建筑过程的各个阶段，从早期概念化和场地分析到生成式设计和施工细节。AI工具擅长自动化重复性任务并生成创新设计方案，从而使建筑师能够专注于创造力和解决问题。此外，AI的（文本到图像）视觉表示能力挑战了建筑中以视觉为中心的方法，这将促使未来的建筑师关注空间的整体感官和体验品质或建筑设计中固有的批判性思维。尽管AI具有变革性潜力，但建筑师必须将其视为协作伙伴，而非被动工具。", "summary": "本文探讨了人工智能（AI）在建筑实践中的多方面作用，强调其对传统设计和施工的变革性影响。文章采用叙述性综述方法，分析了AI在提升创造力和效率方面的潜力，同时也指出了其在捕捉空间多感官和体验维度方面的局限性。研究表明，AI正日益融入建筑过程的各个阶段，能够自动化重复任务并生成创新设计方案。最终，文章呼吁建筑师将AI视为协作伙伴，以充分利用其潜力。", "keywords": "人工智能, 建筑实践, 设计自动化, 创意增强, 协作伙伴", "comments": "该论文及时地审视了AI在建筑领域中不断演进的角色，强调了从传统方法向AI增强实践的转变。它同时关注了AI的潜在优势（效率、创造力）和局限性（多感官体验），提供了平衡的视角。论文中呼吁建筑师将AI视为“协作伙伴”是一个关键的见解，它促进了对这项技术的主动和批判性参与，而非被动采纳。"}}
{"id": "2401.08052", "title": "Multi-Input Multi-Output Target-Speaker Voice Activity Detection For Unified, Flexible, and Robust Audio-Visual Speaker Diarization", "authors": ["Ming Cheng", "Ming Li"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Audio, Speech, and Language Processing", "url": "http://arxiv.org/abs/2401.08052v3", "summary": "Audio-visual learning has demonstrated promising results in many classical\nspeech tasks (e.g., speech separation, automatic speech recognition, wake-word\nspotting). We believe that introducing visual modality will also benefit\nspeaker diarization. To date, Target-Speaker Voice Activity Detection (TS-VAD)\nplays an important role in highly accurate speaker diarization. However,\nprevious TS-VAD models take audio features and utilize the speaker's acoustic\nfootprint to distinguish his or her personal speech activities, which is easily\naffected by overlapped speech in multi-speaker scenarios. Although visual\ninformation naturally tolerates overlapped speech, it suffers from spatial\nocclusion, low resolution, etc. The potential modality-missing problem blocks\nTS-VAD towards an audio-visual approach. This paper proposes a novel\nMulti-Input Multi-Output Target-Speaker Voice Activity Detection (MIMO-TSVAD)\nframework for speaker diarization. The proposed method can take audio-visual\ninput and leverage the speaker's acoustic footprint or lip track to flexibly\nconduct audio-based, video-based, and audio-visual speaker diarization in a\nunified sequence-to-sequence framework. Experimental results show that the\nMIMO-TSVAD framework demonstrates state-of-the-art performance on the\nVoxConverse, DIHARD-III, and MISP 2022 datasets under corresponding evaluation\nmetrics, obtaining the Diarization Error Rates (DERs) of 4.18%, 10.10%, and\n8.15%, respectively. In addition, it can perform robustly in heavy lip-missing\nscenarios.", "comment": "Accepted by IEEE Transactions on Audio, Speech, and Language\n  Processing", "pdf_url": "http://arxiv.org/pdf/2401.08052v3", "cate": "eess.AS", "date": "2024-01-16", "updated": "2025-07-31", "AI": {"title_translation": "统一、灵活、鲁棒的音视频说话人日志中多输入多输出目标说话人语音活动检测", "tldr": "本文提出了一种新颖的多输入多输出目标说话人语音活动检测（MIMO-TSVAD）框架，用于说话人日志。该框架能灵活处理音视频输入，并在统一的序列到序列框架中实现基于音频、视频和音视频的说话人日志，在多个数据集上取得了最先进的性能，并能在唇部缺失严重的情况下表现出鲁棒性。", "motivation": "传统的目标说话人语音活动检测（TS-VAD）模型仅使用音频特征，易受多说话人场景中重叠语音的影响。尽管视觉信息能自然地容忍重叠语音，但其受空间遮挡、低分辨率等问题困扰。此外，潜在的模态缺失问题阻碍了TS-VAD向音视频方法的演进。", "method": "本文提出了一种新颖的多输入多输出目标说话人语音活动检测（MIMO-TSVAD）框架。该方法可以接收音视频输入，并利用说话人的声学指纹或唇部轨迹，在一个统一的序列到序列框架中灵活地进行基于音频、基于视频和音视频的说话人日志。", "result": "MIMO-TSVAD框架在VoxConverse、DIHARD-III和MISP 2022数据集上取得了最先进的性能，Diarization Error Rates (DERs) 分别为4.18%、10.10%和8.15%。此外，该框架在唇部缺失严重的情况下也能表现出鲁棒性。", "conclusion": "本文提出的MIMO-TSVAD框架在统一的序列到序列框架中，通过灵活处理音视频输入，有效解决了传统TS-VAD在重叠语音和模态缺失方面的挑战，显著提升了说话人日志的准确性和鲁棒性。", "translation": "音视频学习在许多经典的语音任务（例如，语音分离、自动语音识别、唤醒词检测）中已显示出有前景的结果。我们相信引入视觉模态也将有益于说话人日志。迄今为止，目标说话人语音活动检测（TS-VAD）在高度准确的说话人日志中发挥着重要作用。然而，之前的TS-VAD模型仅采用音频特征并利用说话人的声学指纹来区分其个人语音活动，这在多说话人场景中容易受到重叠语音的影响。尽管视觉信息自然地容忍重叠语音，但它受到空间遮挡、低分辨率等问题的影响。潜在的模态缺失问题阻碍了TS-VAD向音视频方法的迈进。本文提出了一种新颖的多输入多输出目标说话人语音活动检测（MIMO-TSVAD）框架，用于说话人日志。所提出的方法可以接收音视频输入，并利用说话人的声学指纹或唇部轨迹，在一个统一的序列到序列框架中灵活地进行基于音频、基于视频和音视频的说话人日志。实验结果表明，MIMO-TSVAD框架在VoxConverse、DIHARD-III和MISP 2022数据集上，在相应的评估指标下，展示了最先进的性能，Diarization Error Rates (DERs) 分别为4.18%、10.10%和8.15%。此外，它在唇部缺失严重的情况下也能表现出鲁棒性。", "summary": "本文提出了一种新颖的多输入多输出目标说话人语音活动检测（MIMO-TSVAD）框架，旨在解决传统TS-VAD在重叠语音和模态缺失方面的局限性。该框架能够灵活地处理音频、视频或音视频输入，并在统一的序列到序列框架中进行说话人日志。实验结果表明，MIMO-TSVAD在多个标准数据集上实现了最先进的性能，并且在唇部缺失的挑战性场景中也表现出强大的鲁棒性。", "keywords": "目标说话人语音活动检测, 说话人日志, 音视频, 多输入多输出, 鲁棒性", "comments": "本文的创新点在于提出了一个统一的MIMO-TSVAD框架，它能够灵活地整合音视频信息，克服了传统TS-VAD在重叠语音下的弱点，并解决了音视频方法中模态缺失的问题。其序列到序列的统一处理方式，以及在唇部缺失场景下的鲁棒性，都显著提升了说话人日志的实用性和准确性。"}}
{"id": "2507.23305", "title": "Whisker-based Active Tactile Perception for Contour Reconstruction", "authors": ["Yixuan Dang", "Qinyang Xu", "Yu Zhang", "Xiangtong Yao", "Liding Zhang", "Zhenshan Bing", "Florian Roehrbein", "Alois Knoll"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23305v1", "summary": "Perception using whisker-inspired tactile sensors currently faces a major\nchallenge: the lack of active control in robots based on direct contact\ninformation from the whisker. To accurately reconstruct object contours, it is\ncrucial for the whisker sensor to continuously follow and maintain an\nappropriate relative touch pose on the surface. This is especially important\nfor localization based on tip contact, which has a low tolerance for sharp\nsurfaces and must avoid slipping into tangential contact. In this paper, we\nfirst construct a magnetically transduced whisker sensor featuring a compact\nand robust suspension system composed of three flexible spiral arms. We develop\na method that leverages a characterized whisker deflection profile to directly\nextract the tip contact position using gradient descent, with a Bayesian filter\napplied to reduce fluctuations. We then propose an active motion control policy\nto maintain the optimal relative pose of the whisker sensor against the object\nsurface. A B-Spline curve is employed to predict the local surface curvature\nand determine the sensor orientation. Results demonstrate that our algorithm\ncan effectively track objects and reconstruct contours with sub-millimeter\naccuracy. Finally, we validate the method in simulations and real-world\nexperiments where a robot arm drives the whisker sensor to follow the surfaces\nof three different objects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23305v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于触须的主动触觉感知用于轮廓重建", "tldr": "本文提出了一种基于磁性触须传感器的主动运动控制策略，通过利用触须偏转轮廓和B样条曲线来准确重建物体轮廓。", "motivation": "当前的触须启发式触觉传感器面临的主要挑战是缺乏基于触须直接接触信息的机器人主动控制。为了准确重建物体轮廓，触须传感器必须连续跟踪并保持在物体表面上适当的相对接触姿态，尤其是在尖端接触定位中，其对锐利表面的容忍度低且必须避免滑入切向接触。", "method": "本文首先构建了一个磁性传感触须传感器，其具有紧凑且坚固的由三个柔性螺旋臂组成的悬挂系统。开发了一种利用触须偏转轮廓通过梯度下降直接提取尖端接触位置的方法，并应用贝叶斯滤波器减少波动。然后提出了一种主动运动控制策略，以保持触须传感器与物体表面的最佳相对姿态。采用B样条曲线预测局部表面曲率并确定传感器方向。", "result": "结果表明，该算法可以有效地跟踪物体并以亚毫米级精度重建轮廓。该方法在模拟和真实世界实验中得到验证，其中机器人手臂驱动触须传感器跟踪了三个不同物体的表面。", "conclusion": "本文成功开发了一种基于磁性触须传感器的主动触觉感知系统，能够通过主动运动控制策略和先进的信号处理方法实现高精度的物体轮廓重建，解决了传统触须传感器在主动控制和接触姿态保持方面的挑战。", "translation": "基于触须的触觉感知目前面临一个主要挑战：机器人缺乏基于触须直接接触信息的主动控制。为了精确重建物体轮廓，触须传感器持续跟踪并保持在表面上适当的相对接触姿态至关重要。这对于基于尖端接触的定位尤其重要，因为其对锐利表面的容忍度低，并且必须避免滑入切向接触。在本文中，我们首先构建了一个磁性传感触须传感器，其具有由三个柔性螺旋臂组成的紧凑而坚固的悬挂系统。我们开发了一种方法，利用表征的触须偏转轮廓，通过梯度下降直接提取尖端接触位置，并应用贝叶斯滤波器以减少波动。然后，我们提出了一种主动运动控制策略，以保持触须传感器相对于物体表面的最佳相对姿态。采用B样条曲线来预测局部表面曲率并确定传感器方向。结果表明，我们的算法可以有效地跟踪物体并以亚毫米级精度重建轮廓。最后，我们在模拟和真实世界实验中验证了该方法，其中机器人手臂驱动触须传感器跟踪了三个不同物体的表面。", "summary": "本文提出了一种用于物体轮廓重建的主动触觉感知系统。该系统通过构建一个新型磁性传感触须传感器，并开发了一种利用触须偏转轮廓通过梯度下降提取尖端接触位置的方法。为解决触须传感器在接触姿态保持上的挑战，研究人员提出了一种主动运动控制策略，该策略结合B样条曲线预测局部表面曲率，以维持传感器与物体的最佳相对姿态。实验结果表明，该系统能够以亚毫米级精度有效跟踪物体并重建其轮廓。", "keywords": "触须传感器, 主动触觉感知, 轮廓重建, 运动控制, 磁性传感", "comments": "本文的创新点在于结合了新型磁性触须传感器的设计与主动运动控制策略，有效解决了现有触须传感器在精确保持接触姿态和避免滑脱方面的挑战。通过利用触须偏转轮廓和B样条曲线进行实时姿态调整，显著提高了轮廓重建的精度和鲁棒性。该研究在仿生机器人和精细操作领域具有重要应用潜力。"}}
{"id": "2501.15544", "title": "Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles", "authors": ["Hanwen Zhang", "Ruichen Zhang", "Wei Zhang", "Dusit Niyato", "Yonggang Wen", "Chunyan Miao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 Pages", "url": "http://arxiv.org/abs/2501.15544v4", "summary": "Generative artificial intelligence, particularly through large language\nmodels (LLMs), is poised to transform energy optimization and demand side\nmanagement (DSM) within microgrids. This paper explores the integration of LLMs\ninto energy management, emphasizing their roles in automating the optimization\nof DSM strategies with Internet of electric vehicles. We investigate challenges\nand solutions associated with DSM and explore the new opportunities presented\nby leveraging LLMs. Then, we propose an innovative solution that enhances LLMs\nwith retrieval-augmented generation for automatic problem formulation, code\ngeneration, and customizing optimization. We present a case study to\ndemonstrate the effectiveness of our proposed solution in charging scheduling\nand optimization for electric vehicles, highlighting our solution's significant\nadvancements in energy efficiency and user adaptability. This work underscores\nthe potential of LLMs for energy optimization and fosters a new era of\nintelligent DSM solutions.", "comment": "11 Pages", "pdf_url": "http://arxiv.org/pdf/2501.15544v4", "cate": "cs.LG", "date": "2025-01-26", "updated": "2025-07-31", "AI": {"title_translation": "生成式人工智能与大型语言模型在电动汽车互联网需求侧管理中的进展", "tldr": "大型语言模型（LLMs）能够通过自动化问题表述和代码生成，优化微电网中的能源需求侧管理（DSM），特别是在电动汽车（EV）集成方面。", "motivation": "探索大型语言模型（LLMs）在能源管理中的整合，强调其在结合电动汽车互联网的DMS策略自动化优化中的作用，并研究相关挑战和解决方案。", "method": "提出了一种创新解决方案，通过检索增强生成（RAG）技术提升LLMs的能力，实现自动问题表述、代码生成和定制优化。通过电动汽车充电调度和优化的案例研究来验证其有效性。", "result": "案例研究表明，所提出的解决方案在电动汽车充电调度和优化方面有效，显著提升了能源效率和用户适应性。", "conclusion": "这项工作强调了大型语言模型在能源优化方面的潜力，并开启了智能需求侧管理解决方案的新时代。", "translation": "生成式人工智能，特别是通过大型语言模型（LLMs），有望彻底改变微电网内的能源优化和需求侧管理（DSM）。本文探讨了LLMs在能源管理中的整合，强调了它们在结合电动汽车互联网自动化优化DSM策略中的作用。我们研究了与DSM相关的挑战和解决方案，并探索了利用LLMs带来的新机遇。随后，我们提出了一种创新解决方案，通过检索增强生成（RAG）技术增强LLMs的能力，实现自动问题表述、代码生成和定制优化。我们通过一个案例研究来展示我们提出的解决方案在电动汽车充电调度和优化中的有效性，突出了我们的解决方案在能源效率和用户适应性方面的显著进步。这项工作强调了LLMs在能源优化方面的潜力，并开启了智能DSM解决方案的新时代。", "summary": "本文探讨了大型语言模型（LLMs）在微电网能源优化和需求侧管理（DSM）中的应用，特别是结合电动汽车互联网（IoEV）的场景。论文提出了一种创新的LLM增强解决方案，利用检索增强生成（RAG）实现自动问题表述、代码生成和优化定制。通过电动汽车充电的案例研究，展示了该解决方案在提高能源效率和适应性方面的有效性，突显了LLMs在智能DSM方面的潜力。", "keywords": "生成式人工智能, 大型语言模型, 需求侧管理, 电动汽车互联网, 能源优化", "comments": "该论文将大型语言模型创新性地应用于能源管理和需求侧管理等关键领域，特别是与新兴的电动汽车互联网结合。利用检索增强生成（RAG）自动化问题表述和代码生成是一种新颖的方法，可以显著降低能源优化任务所需的复杂性和专业知识。这可能为更具适应性和效率的能源系统铺平道路。"}}
{"id": "2505.20884", "title": "YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation", "authors": ["Weichao Pan", "Bohan Xu", "Xu Wang", "Chengze Lv", "Shuoyang Wang", "Zhenke Duan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      2025 International Conference on Intelligent Computing (ICIC 2025)", "url": "http://arxiv.org/abs/2505.20884v2", "summary": "Fire detection in dynamic environments faces continuous challenges, including\nthe interference of illumination changes, many false detections or missed\ndetections, and it is difficult to achieve both efficiency and accuracy. To\naddress the problem of feature extraction limitation and information loss in\nthe existing YOLO-based models, this study propose You Only Look Once for Fire\nDetection with Attention-guided Inverted Residual and Dual-pooling Downscale\nFusion (YOLO-FireAD) with two core innovations: (1) Attention-guided Inverted\nResidual Block (AIR) integrates hybrid channel-spatial attention with inverted\nresiduals to adaptively enhance fire features and suppress environmental noise;\n(2) Dual Pool Downscale Fusion Block (DPDF) preserves multi-scale fire patterns\nthrough learnable fusion of max-average pooling outputs, mitigating small-fire\ndetection failures. Extensive evaluation on two public datasets shows the\nefficient performance of our model. Our proposed model keeps the sum amount of\nparameters (1.45M, 51.8% lower than YOLOv8n) (4.6G, 43.2% lower than YOLOv8n),\nand mAP75 is higher than the mainstream real-time object detection models\nYOLOv8n, YOL-Ov9t, YOLOv10n, YOLO11n, YOLOv12n and other YOLOv8 variants\n1.3-5.5%. For more details, please visit our repository:\nhttps://github.com/JEFfersusu/YOLO-FireAD", "comment": "2025 International Conference on Intelligent Computing (ICIC 2025)", "pdf_url": "http://arxiv.org/pdf/2505.20884v2", "cate": "cs.CV", "date": "2025-05-27", "updated": "2025-07-31", "AI": {"title_translation": "YOLO-FireAD：通过注意力引导的倒残差学习和双池化特征保留实现高效火灾检测", "tldr": "YOLO-FireAD通过注意力引导的倒残差和双池化融合，解决了火灾检测中效率与准确性难以兼顾的问题，提高了检测性能并降低了模型复杂度。", "motivation": "动态环境中火灾检测面临光照变化干扰、误报漏报多以及难以同时实现效率和准确性的挑战。现有基于YOLO的模型存在特征提取受限和信息丢失问题。", "method": "本研究提出了YOLO-FireAD模型，包含两项核心创新：(1) 注意力引导的倒残差块（AIR）集成了混合通道-空间注意力与倒残差，以自适应地增强火灾特征并抑制环境噪声；(2) 双池化下采样融合块（DPDF）通过可学习的max-average池化输出融合，保留多尺度火灾模式，从而缓解小火检测失败。", "result": "在两个公共数据集上进行了广泛评估，显示了模型的高效性能。模型参数总量为1.45M（比YOLOv8n低51.8%），GFLOPs为4.6G（比YOLOv8n低43.2%）。mAP75比主流实时目标检测模型（YOLOv8n、YOL-Ov9t、YOLOv10n、YOLO11n、YOLOv12n以及其他YOLOv8变体）高1.3-5.5%。", "conclusion": "所提出的YOLO-FireAD模型在保持高效性能的同时，显著提高了火灾检测的准确性，解决了现有YOLO模型在特征提取和信息丢失方面的局限。", "translation": "动态环境中的火灾检测面临持续挑战，包括光照变化的干扰、大量的误报或漏报，以及难以同时实现效率和准确性。为了解决现有基于YOLO模型中特征提取受限和信息丢失的问题，本研究提出了YOLO-FireAD（You Only Look Once for Fire Detection with Attention-guided Inverted Residual and Dual-pooling Downscale Fusion），包含两项核心创新：(1) 注意力引导的倒残差块（AIR）将混合通道-空间注意力与倒残差相结合，以自适应地增强火灾特征并抑制环境噪声；(2) 双池化下采样融合块（DPDF）通过可学习的最大-平均池化输出融合来保留多尺度火灾模式，从而缓解小火检测失败的问题。在两个公共数据集上的广泛评估表明，我们的模型具有高效的性能。我们提出的模型参数总量为1.45M（比YOLOv8n低51.8%），GFLOPs为4.6G（比YOLOv8n低43.2%），mAP75高于主流实时目标检测模型YOLOv8n、YOL-Ov9t、YOLOv10n、YOLO11n、YOLOv12n以及其他YOLOv8变体1.3-5.5%。更多详情，请访问我们的仓库：https://github.com/JEFfersusu/YOLO-FireAD", "summary": "本文提出了YOLO-FireAD，一个针对动态环境中火灾检测的模型，旨在解决现有YOLO模型在特征提取限制和信息丢失方面的问题，以及兼顾效率和准确性的挑战。YOLO-FireAD引入了注意力引导的倒残差块（AIR）以增强火灾特征并抑制噪声，以及双池化下采样融合块（DPDF）以保留多尺度特征并改善小火检测。实验结果显示，YOLO-FireAD在保持低参数量和计算量的同时，其mAP75性能显著优于多种主流实时目标检测模型。", "keywords": "火灾检测, YOLO, 注意力机制, 倒残差, 多尺度特征融合", "comments": "该论文提出YOLO-FireAD模型，通过引入注意力引导的倒残差块和双池化下采样融合块，有效解决了动态环境下火灾检测中效率与准确性难以兼顾、特征提取受限及信息丢失的问题。其创新点在于结合了注意力机制和多尺度特征保留策略，显著提升了火灾特征的鲁棒性，并降低了模型复杂度。模型在参数量和GFLOPs方面均有显著优化，同时mAP75指标优于现有主流YOLO系列模型，显示了其在实际应用中的潜力。"}}
{"id": "2507.07426", "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "authors": ["Zerui Yang", "Yuwei Wan", "Siyu Yan", "Yudai Matsuda", "Tong Xie", "Bram Hoex", "Linqi Song"], "categories": ["cs.AI", "cs.CE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07426v3", "summary": "Recent advances in large language models have demonstrated considerable\npotential in scientific domains such as drug repositioning. However, their\neffectiveness remains constrained when reasoning extends beyond the knowledge\nacquired during pretraining. Conventional approaches, such as fine-tuning or\nretrieval-augmented generation, face limitations in either imposing high\ncomputational overhead or failing to fully exploit structured scientific data.\nTo overcome these challenges, we propose DrugMCTS, a novel framework that\nsynergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree\nSearch for drug repositioning. The framework employs five specialized agents\ntasked with retrieving and analyzing molecular and protein information, thereby\nenabling structured and iterative reasoning. Extensive experiments on the\nDrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially\nhigher recall and robustness compared to both general-purpose LLMs and deep\nlearning baselines. Our results highlight the importance of structured\nreasoning, agent-based collaboration, and feedback-driven search mechanisms in\nadvancing LLM applications for drug repositioning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07426v3", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "DrugMCTS：一个结合了多智能体、RAG和蒙特卡洛树搜索的药物重定向框架", "tldr": "DrugMCTS是一个新框架，它结合了多智能体、RAG和蒙特卡洛树搜索，通过结构化推理改进药物重定向，性能优于现有LLM和基线。", "motivation": "大型语言模型在药物重定向等科学领域显示出巨大潜力，但其推理能力在超出预训练知识范围时受到限制。传统的微调或检索增强生成方法存在计算开销高或未能充分利用结构化科学数据的问题。为了克服这些挑战，本文提出了DrugMCTS。", "method": "本文提出了DrugMCTS，一个协同整合RAG、多智能体协作和蒙特卡洛树搜索的药物重定向新框架。该框架采用五个专门的智能体，负责检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。", "result": "在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS与通用LLM和深度学习基线相比，实现了显著更高的召回率和鲁棒性。", "conclusion": "结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物重定向应用中的重要性。", "translation": "大型语言模型在药物重定向等科学领域取得了显著进展，展现出巨大潜力。然而，当推理超出预训练知识范围时，它们的有效性仍受到限制。传统的微调或检索增强生成方法存在计算开销高或未能充分利用结构化科学数据的问题。为了克服这些挑战，我们提出了DrugMCTS，一个协同整合RAG、多智能体协作和蒙特卡洛树搜索的药物重定向新框架。该框架采用五个专门的智能体，负责检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS与通用LLM和深度学习基线相比，实现了显著更高的召回率和鲁棒性。我们的结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物重定向应用中的重要性。", "summary": "DrugMCTS是一个创新的药物重定向框架，它结合了检索增强生成（RAG）、多智能体协作和蒙特卡洛树搜索。针对现有大型语言模型在药物发现中推理能力受限以及传统方法效率低下的问题，DrugMCTS通过五个专业智能体进行结构化和迭代推理。在DrugBank和KIBA数据集上的实验证明，该框架在召回率和鲁棒性方面显著优于通用LLM和深度学习基线，突出了结构化推理和智能体协作的重要性。", "keywords": "药物重定向, 大型语言模型, 多智能体, RAG, 蒙特卡洛树搜索", "comments": "本文创新性地结合了RAG、多智能体系统和蒙特卡洛树搜索，以解决大型语言模型在复杂科学推理（特别是药物重定向）中的局限性。利用专门的智能体进行结构化推理是其关键创新点，这使得LLM能够超越其预训练知识并更有效地利用结构化数据。这种方法为LLM在需要深度、迭代推理的科学领域应用提供了有前景的方向。"}}
{"id": "2504.10403", "title": "Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks", "authors": ["Yan Zhu", "Jingyang Zhu", "Ting Wang", "Yuanming Shi", "Chunxiao Jiang", "Khaled Ben Letaief"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.10403v3", "summary": "Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.10403v3", "cate": "cs.LG", "date": "2025-04-14", "updated": "2025-07-31", "AI": {"title_translation": "卫星联邦微调：空间计算能力网络中的基础模型", "tldr": "针对空间计算能力网络中的大型基础模型，本文提出了一种星地协作联邦微调框架，旨在解决计算和通信挑战，显著缩短训练时间。", "motivation": "人工智能（AI）和低地球轨道（LEO）卫星的发展推动了大型遥感基础模型在各种下游任务中的应用。然而，由于隐私问题和带宽限制，直接将这些模型下载到地面进行微调受阻。传统的卫星联邦学习（FL）框架虽然允许模型在卫星上直接微调并聚合模型更新而无需下载数据，但对于大型基础模型，卫星的计算能力不足以支持有效的板载微调。此外，在微调过程中，卫星与地面站或其他卫星之间交换中间结果进行前向传播和反向传播，这带来了通信挑战，原因是空间传输网络的特殊通信拓扑，例如间歇性星地通信、星地通信窗口持续时间短以及星间链路（ISL）不稳定。", "method": "为解决上述挑战，本文提出了一种星地协作联邦微调框架。该框架的关键在于如何合理分解和分配模型组件，以缓解板载计算能力不足的问题。在微调过程中，卫星与地面站或其他卫星交换中间结果进行前向传播和反向传播。为减少传输延迟，本文进一步引入了量身定制的通信策略，整合了通信和计算资源。具体而言，提出了并行轨道内通信策略、拓扑感知星地通信策略以及延迟最小化轨道间通信策略，以降低空间通信成本。", "result": "仿真结果表明，训练时间显著减少，提升了约33%。", "conclusion": "本文提出的星地协作联邦微调框架及其定制的通信策略，有效解决了在空间计算能力网络中对大型基础模型进行联邦微调所面临的计算能力不足和复杂通信挑战，从而显著缩短了训练时间。", "translation": "人工智能（AI）和低地球轨道（LEO）卫星的进步推动了大型遥感基础模型在各种下游任务中的应用。然而，由于隐私问题和有限的带宽，直接下载这些模型到地面进行微调受到了阻碍。卫星联邦学习（FL）通过在卫星上直接进行模型微调并聚合模型更新而无需下载数据，提供了一种解决方案。尽管如此，对于大型基础模型，卫星的计算能力不足以支持传统卫星联邦学习框架中有效的板载微调。为了应对这些挑战，我们提出了一种星地协作联邦微调框架。该框架的关键在于如何合理分解和分配模型组件以缓解板载计算能力不足的问题。在微调过程中，卫星与地面站或其他卫星交换中间结果进行前向传播和反向传播，这带来了通信挑战，原因是空间传输网络的特殊通信拓扑，例如间歇性星地通信、星地通信窗口持续时间短以及不稳定的轨道间星间链路（ISL）。为了减少传输延迟，我们进一步引入了整合通信和计算资源的定制通信策略。具体来说，我们提出了并行轨道内通信策略、拓扑感知星地通信策略和延迟最小化轨道间通信策略，以降低空间通信成本。仿真结果表明，训练时间显著减少，提升了约33%。", "summary": "本文提出了一种星地协作联邦微调框架，旨在解决大型遥感基础模型在空间计算能力网络中进行微调时面临的隐私、带宽、星载计算能力不足以及复杂空间通信拓扑等挑战。该框架通过合理分解和分配模型组件，并结合定制的通信策略（包括并行轨道内、拓扑感知星地和延迟最小化轨道间通信），优化了资源利用并减少了传输延迟。仿真结果显示，训练时间显著缩短了约33%。", "keywords": "联邦学习, 基础模型, 卫星网络, 空间计算, 微调", "comments": "该论文创新性地解决了在空间计算环境中部署和微调大型基础模型的关键挑战，这对于未来的空间AI应用至关重要。其星地协作方法以及具体的通信优化策略是核心创新点。量化结果（33%的训练时间减少）突显了其潜在的实际应用价值和效率提升。"}}
{"id": "2507.23735", "title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Michele Grimaldi", "Yvan R. Petillot"], "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23735v1", "summary": "Achieving robust cognitive autonomy in robots navigating complex,\nunpredictable environments remains a fundamental challenge in robotics. This\npaper presents Underwater Robot Self-Organizing Autonomy (UROSA), a\ngroundbreaking architecture leveraging distributed Large Language Model AI\nagents integrated within the Robot Operating System 2 (ROS 2) framework to\nenable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA\ndecentralises cognition into specialised AI agents responsible for multimodal\nperception, adaptive reasoning, dynamic mission planning, and real-time\ndecision-making. Central innovations include flexible agents dynamically\nadapting their roles, retrieval-augmented generation utilising vector databases\nfor efficient knowledge management, reinforcement learning-driven behavioural\noptimisation, and autonomous on-the-fly ROS 2 node generation for runtime\nfunctional extensibility. Extensive empirical validation demonstrates UROSA's\npromising adaptability and reliability through realistic underwater missions in\nsimulation and real-world deployments, showing significant advantages over\ntraditional rule-based architectures in handling unforeseen scenarios,\nenvironmental uncertainties, and novel mission objectives. This work not only\nadvances underwater autonomy but also establishes a scalable, safe, and\nversatile cognitive robotics framework capable of generalising to a diverse\narray of real-world applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23735v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "分布式AI智能体用于认知水下机器人自主性", "tldr": "本文提出了UROSA，一个利用分布式大语言模型AI智能体的架构，以增强水下机器人的认知自主性，并在模拟和实际部署中展示了其优越性。", "motivation": "在复杂、不可预测的环境中，机器人实现鲁棒的认知自主性仍然是机器人学的一个基本挑战。", "method": "本文提出了水下机器人自组织自主性（UROSA）架构，该架构利用集成在ROS 2框架中的分布式大语言模型AI智能体，为自主水下航行器提供先进的认知能力。UROSA将认知去中心化为专门的AI智能体，负责多模态感知、自适应推理、动态任务规划和实时决策。核心创新包括：灵活智能体动态适应角色、利用向量数据库的检索增强生成、强化学习驱动的行为优化，以及运行时自主生成ROS 2节点以实现功能扩展。", "result": "广泛的实证验证表明，UROSA在模拟和实际部署中的真实水下任务中表现出良好的适应性和可靠性，与传统的基于规则的架构相比，在处理不可预见的情况、环境不确定性和新颖任务目标方面显示出显著优势。", "conclusion": "这项工作不仅推动了水下自主性，还建立了一个可扩展、安全、通用的认知机器人框架，能够推广到各种现实世界应用。", "translation": "在复杂、不可预测的环境中，机器人实现鲁棒的认知自主性仍然是机器人学的一个基本挑战。本文提出了水下机器人自组织自主性（UROSA），一个开创性的架构，利用集成在机器人操作系统2（ROS 2）框架中的分布式大语言模型AI智能体，以实现自主水下航行器（AUV）的先进认知能力。UROSA将认知去中心化为专门的AI智能体，负责多模态感知、自适应推理、动态任务规划和实时决策。核心创新包括：灵活智能体动态适应其角色、利用向量数据库进行高效知识管理的检索增强生成、强化学习驱动的行为优化，以及用于运行时功能可扩展性的自主即时ROS 2节点生成。广泛的实证验证表明，UROSA通过在模拟和实际部署中进行的真实水下任务，展示了其良好的适应性和可靠性，与传统的基于规则的架构相比，在处理不可预见的情况、环境不确定性和新颖任务目标方面显示出显著优势。这项工作不仅推动了水下自主性，还建立了一个可扩展、安全、通用的认知机器人框架，能够推广到各种现实世界应用。", "summary": "本文介绍了一种名为UROSA的创新架构，旨在提升水下机器人的认知自主性。UROSA通过在ROS 2框架中集成分布式大语言模型AI智能体，将感知、推理、规划和决策等认知功能去中心化。其关键创新包括动态角色适应的智能体、基于向量数据库的RAG、强化学习优化以及运行时ROS 2节点生成。实验验证表明，UROSA在应对复杂水下环境和未知场景时，比传统方法具有显著优势，为通用认知机器人框架奠定了基础。", "keywords": "水下机器人, 认知自主性, 分布式AI智能体, 大语言模型, ROS 2", "comments": "本文提出了一种开创性的分布式AI智能体架构UROSA，通过结合大语言模型、RAG和强化学习，显著提升了水下机器人的认知自主性。其创新之处在于将认知能力去中心化，并实现了运行时功能扩展，这对于应对复杂和不可预测的水下环境至关重要。该工作不仅在水下机器人领域具有重要意义，也为更广泛的认知机器人应用提供了可扩展且通用的框架。"}}
{"id": "2507.22912", "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "authors": ["Navid Yazdanjue", "Morteza Rakhshaninejad", "Hossein Yazdanjouei", "Mohammad Sadegh Khorshidi", "Mikko S. Niemela", "Fang Chen", "Amir H. Gandomi"], "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 5 figures, 9 tables", "url": "http://arxiv.org/abs/2507.22912v1", "summary": "Illegal marketplaces have increasingly shifted to concealed parts of the\ninternet, including the deep and dark web, as well as platforms such as\nTelegram, Reddit, and Pastebin. These channels enable the anonymous trade of\nillicit goods including drugs, weapons, and stolen credentials. Detecting and\ncategorizing such content remains challenging due to limited labeled data, the\nevolving nature of illicit language, and the structural heterogeneity of online\nsources. This paper presents a hierarchical classification framework that\ncombines fine-tuned language models with a semi-supervised ensemble learning\nstrategy to detect and classify illicit marketplace content across diverse\nplatforms. We extract semantic representations using ModernBERT, a transformer\nmodel for long documents, finetuned on domain-specific data from deep and dark\nweb pages, Telegram channels, Subreddits, and Pastebin pastes to capture\nspecialized jargon and ambiguous linguistic patterns. In addition, we\nincorporate manually engineered features such as document structure, embedded\npatterns including Bitcoin addresses, emails, and IPs, and metadata, which\ncomplement language model embeddings. The classification pipeline operates in\ntwo stages. The first stage uses a semi-supervised ensemble of XGBoost, Random\nForest, and SVM with entropy-based weighted voting to detect sales-related\ndocuments. The second stage further classifies these into drug, weapon, or\ncredential sales. Experiments on three datasets, including our multi-source\ncorpus, DUTA, and CoDA, show that our model outperforms several baselines,\nincluding BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The\nmodel achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of\n0.95388, demonstrating strong generalization, robustness under limited\nsupervision, and effectiveness in real-world illicit content detection.", "comment": "16 pages, 5 figures, 9 tables", "pdf_url": "http://arxiv.org/pdf/2507.22912v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19", "AI": {"title_translation": "一种语言模型驱动的半监督集成框架，用于跨深/暗网和社交平台的非法市场检测", "tldr": "该论文提出了一种语言模型驱动的半监督集成框架，用于检测和分类深/暗网和社交平台上的非法市场内容，在有限监督下表现出强大的泛化能力和鲁棒性。", "motivation": "非法市场日益转向互联网的隐蔽部分（包括深/暗网和Telegram、Reddit、Pastebin等社交平台），使得毒品、武器和被盗凭证等非法商品得以匿名交易。由于标记数据有限、非法语言不断演变以及在线来源的结构异构性，检测和分类此类内容仍然具有挑战性。", "method": "本文提出了一种分层分类框架，结合了微调语言模型和半监督集成学习策略。它使用在领域特定数据上微调的ModernBERT（一种用于长文档的Transformer模型）来提取语义表示，并结合了文档结构、嵌入模式（如比特币地址、电子邮件、IP）和元数据等手动设计的特征。分类流程分两个阶段：第一阶段使用XGBoost、随机森林和SVM的半监督集成与基于熵的加权投票来检测销售相关文档；第二阶段将这些文档进一步分类为毒品、武器或凭证销售。", "result": "在包括多源语料库、DUTA和CoDA在内的三个数据集上的实验表明，该模型优于包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird在内的多个基线模型。该模型实现了0.96489的准确率、0.93467的F1分数和0.95388的TMCC，证明了其强大的泛化能力、在有限监督下的鲁棒性以及在实际非法内容检测中的有效性。", "conclusion": "该模型能够有效地检测和分类跨不同平台的非法市场内容，即使在有限监督下也表现出强大的泛化能力和鲁棒性。", "translation": "非法市场日益转向互联网的隐蔽部分，包括深网和暗网，以及Telegram、Reddit和Pastebin等平台。这些渠道使得毒品、武器和被盗凭证等非法商品得以匿名交易。由于标记数据有限、非法语言不断演变以及在线来源的结构异构性，检测和分类此类内容仍然具有挑战性。\n本文提出了一种分层分类框架，将微调语言模型与半监督集成学习策略相结合，以检测和分类跨不同平台的非法市场内容。我们使用ModernBERT（一种用于长文档的Transformer模型）提取语义表示，该模型在来自深网和暗网页、Telegram频道、Subreddit和Pastebin帖子的领域特定数据上进行微调，以捕获专业术语和模糊的语言模式。此外，我们还结合了手动设计的特征，如文档结构、嵌入模式（包括比特币地址、电子邮件和IP）和元数据，这些特征补充了语言模型嵌入。\n分类流程分两个阶段进行。第一阶段使用XGBoost、随机森林和SVM的半监督集成，结合基于熵的加权投票来检测销售相关文档。第二阶段将这些文档进一步分类为毒品、武器或凭证销售。在包括我们的多源语料库、DUTA和CoDA在内的三个数据集上的实验表明，我们的模型优于包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird在内的多个基线模型。该模型实现了0.96489的准确率、0.93467的F1分数和0.95388的TMCC，证明了其强大的泛化能力、在有限监督下的鲁棒性以及在实际非法内容检测中的有效性。", "summary": "本文提出了一种分层半监督集成框架，用于检测和分类深/暗网及社交平台上的非法市场内容。该框架结合了微调的ModernBERT模型与手动设计的特征，并通过两阶段分类流程（利用XGBoost、随机森林和SVM的集成学习）实现。它能有效识别销售相关文档并将其分类为毒品、武器或凭证销售。实验证明，该模型在多个数据集上表现出优于现有基线模型的性能和鲁棒性。", "keywords": "非法市场检测, 深/暗网, 半监督学习, 语言模型, 集成框架", "comments": "该论文的创新之处在于结合了为长文档设计的微调语言模型（ModernBERT）、半监督集成学习策略以及手动设计的特征，以应对标记数据有限和非法语言不断演变等挑战，并在异构在线源上进行非法内容检测。其分层两阶段分类设计也值得关注。报告的高性能指标表明其在实际非法内容检测中的重要实用价值。"}}
{"id": "2507.23763", "title": "Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic", "authors": ["Liu Li", "Qiang Ma", "Cheng Ouyang", "Johannes C. Paetzold", "Daniel Rueckert", "Bernhard Kainz"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23763v1", "summary": "Deep learning-based medical image segmentation techniques have shown\npromising results when evaluated based on conventional metrics such as the Dice\nscore or Intersection-over-Union. However, these fully automatic methods often\nfail to meet clinically acceptable accuracy, especially when topological\nconstraints should be observed, e.g., continuous boundaries or closed surfaces.\nIn medical image segmentation, the correctness of a segmentation in terms of\nthe required topological genus sometimes is even more important than the\npixel-wise accuracy. Existing topology-aware approaches commonly estimate and\nconstrain the topological structure via the concept of persistent homology\n(PH). However, these methods are difficult to implement for high dimensional\ndata due to their polynomial computational complexity. To overcome this\nproblem, we propose a novel and fast approach for topology-aware segmentation\nbased on the Euler Characteristic ($\\chi$). First, we propose a fast\nformulation for $\\chi$ computation in both 2D and 3D. The scalar $\\chi$ error\nbetween the prediction and ground-truth serves as the topological evaluation\nmetric. Then we estimate the spatial topology correctness of any segmentation\nnetwork via a so-called topological violation map, i.e., a detailed map that\nhighlights regions with $\\chi$ errors. Finally, the segmentation results from\nthe arbitrary network are refined based on the topological violation maps by a\ntopology-aware correction network. Our experiments are conducted on both 2D and\n3D datasets and show that our method can significantly improve topological\ncorrectness while preserving pixel-wise segmentation accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23763v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "医学图像分割中基于快速欧拉示性数的拓扑优化", "tldr": "本文提出了一种基于快速欧拉示性数（$\\\\chi$）的新方法，用于医学图像分割中的拓扑感知分割，能显著提高拓扑正确性，同时保持像素级精度。", "motivation": "现有的基于深度学习的医学图像分割方法在传统指标上表现良好，但在需要遵守拓扑约束（如连续边界或闭合曲面）时，往往无法达到临床可接受的精度。拓扑正确性有时比像素级精度更重要。现有的拓扑感知方法（如持久同源性）计算复杂度高，难以应用于高维数据。", "method": "提出了一种基于欧拉示性数($\\\\chi$)的快速拓扑感知分割方法。首先，提出了2D和3D中\\\\(\\\\chi\\\\)计算的快速公式，并将预测与真值之间的\\\\(\\\\chi\\\\)误差作为拓扑评估指标。然后，通过拓扑违规图（突出显示\\\\(\\\\chi\\\\)误差区域）估计任何分割网络的空间拓扑正确性。最后，通过拓扑感知校正网络，根据拓扑违规图对任意网络的分割结果进行细化。", "result": "在2D和3D数据集上的实验表明，该方法能显著提高拓扑正确性，同时保持像素级分割精度。", "conclusion": "所提出的基于快速欧拉示性数的拓扑优化方法，有效地解决了医学图像分割中拓扑正确性的问题，并在保持像素级精度的同时显著提升了拓扑性能，克服了现有方法的计算复杂性限制。", "translation": "基于深度学习的医学图像分割技术在基于传统指标（如Dice分数或交并比）评估时显示出有前景的结果。然而，这些全自动方法往往未能达到临床可接受的精度，特别是当需要遵守拓扑约束时，例如连续边界或闭合曲面。在医学图像分割中，分割结果在所需拓扑亏格方面的正确性有时甚至比像素级精度更重要。现有的拓扑感知方法通常通过持久同源性（PH）的概念来估计和约束拓扑结构。然而，由于其多项式计算复杂性，这些方法难以在高维数据中实现。为了克服这个问题，我们提出了一种基于欧拉示性数（\\\\(\\\\chi\\\\)）的新颖快速的拓扑感知分割方法。首先，我们提出了2D和3D中\\\\(\\\\chi\\\\)计算的快速公式。预测与真值之间的标量\\\\(\\\\chi\\\\)误差作为拓扑评估指标。然后，我们通过所谓的拓扑违规图（即突出显示\\\\(\\\\chi\\\\)误差区域的详细地图）来估计任何分割网络的空间拓扑正确性。最后，通过拓扑感知校正网络，根据拓扑违规图对任意网络的分割结果进行细化。我们的实验在2D和3D数据集上进行，结果表明我们的方法可以显著提高拓扑正确性，同时保持像素级分割精度。", "summary": "本文提出了一种新颖且快速的医学图像分割方法，旨在解决现有深度学习方法在拓扑正确性方面的不足。该方法基于欧拉示性数（\\\\(\\\\chi\\\\)）进行拓扑感知分割，通过快速计算\\\\(\\\\chi\\\\)误差并生成拓扑违规图来识别和纠正分割结果中的拓扑错误。随后，利用一个拓扑感知校正网络对结果进行细化。实验证明，该方法在2D和3D数据集上均能显著提升拓扑正确性，同时不损害像素级分割精度，克服了传统拓扑方法（如持久同源性）计算复杂性高的缺点。", "keywords": "医学图像分割, 拓扑优化, 欧拉示性数, 拓扑正确性, 深度学习", "comments": "该论文的创新之处在于利用欧拉示性数（\\\\(\\\\chi\\\\)）作为一种快速且高效的拓扑评估和校正工具，解决了医学图像分割中拓扑正确性这一关键但常被忽视的问题。相较于计算复杂度高的持久同源性方法，其提出的快速\\\\(\\\\chi\\\\)计算和基于拓扑违规图的校正网络，为实现临床上可接受的拓扑准确性提供了一种实用的解决方案。这对于需要精确拓扑结构的医学应用（如器官连通性、病灶形态）具有重要意义。"}}
{"id": "2410.05343", "title": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos referring to Procedural Texts", "authors": ["Yuto Haneji", "Taichi Nishimura", "Hirotaka Kameko", "Keisuke Shirai", "Tomoya Yoshida", "Keiya Kajimura", "Koki Yamamoto", "Taiyu Cui", "Tomohiro Nishimoto", "Shinsuke Mori"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Main 8 pages, supplementary 6 pages", "url": "http://arxiv.org/abs/2410.05343v3", "summary": "Mistake action detection is crucial for developing intelligent archives that\ndetect workers' errors and provide feedback. Existing studies have focused on\nvisually apparent mistakes in free-style activities, resulting in video-only\napproaches to mistake detection. However, in text-following activities, models\ncannot determine the correctness of some actions without referring to the\ntexts. Additionally, current mistake datasets rarely use procedural texts for\nvideo recording except for cooking. To fill these gaps, this paper proposes the\nEgoOops dataset, where egocentric videos record erroneous activities when\nfollowing procedural texts across diverse domains. It features three types of\nannotations: video-text alignment, mistake labels, and descriptions for\nmistakes. We also propose a mistake detection approach, combining video-text\nalignment and mistake label classification to leverage the texts. Our\nexperimental results show that incorporating procedural texts is essential for\nmistake detection. Data is available through\nhttps://y-haneji.github.io/EgoOops-project-page/.", "comment": "Main 8 pages, supplementary 6 pages", "pdf_url": "http://arxiv.org/pdf/2410.05343v3", "cate": "cs.CV", "date": "2024-10-07", "updated": "2025-07-31", "AI": {"title_translation": "EgoOops：一个用于从以自我为中心的视频中检测参照程序文本的错误动作的数据集", "tldr": "EgoOops数据集旨在解决现有错误动作检测方法和数据集的不足，通过提供包含参照程序文本的以自我为中心的错误活动视频，并提出一种结合视频文本对齐的检测方法，证明了程序文本在错误检测中的重要性。", "motivation": "现有的错误动作检测方法主要关注自由式活动中视觉上明显的错误，且现有数据集很少使用程序文本进行视频记录。然而，在遵循文本的活动中，不参照文本模型无法判断某些动作的正确性。本研究旨在填补这些空白，开发能检测工人错误并提供反馈的智能系统。", "method": "本文提出了EgoOops数据集，其中以自我为中心的视频记录了在遵循不同领域程序文本时发生的错误活动。该数据集包含三种类型的标注：视频-文本对齐、错误标签和错误描述。同时，论文还提出了一种结合视频-文本对齐和错误标签分类的错误检测方法，以利用文本信息。", "result": "实验结果表明，结合程序文本对于错误动作检测至关重要。", "conclusion": "结合程序文本对于提高错误动作检测的准确性和有效性至关重要，尤其是在需要遵循特定程序的活动中。", "translation": "错误动作检测对于开发能够检测工人错误并提供反馈的智能档案至关重要。现有研究主要集中在自由式活动中视觉上明显的错误，导致了仅基于视频的错误检测方法。然而，在遵循文本的活动中，模型如果不参照文本就无法确定某些动作的正确性。此外，除了烹饪之外，当前的错误数据集很少使用程序文本进行视频记录。为了弥补这些空白，本文提出了EgoOops数据集，其中以自我为中心的视频记录了在遵循不同领域程序文本时的错误活动。它具有三种类型的标注：视频-文本对齐、错误标签和错误描述。我们还提出了一种错误检测方法，结合视频-文本对齐和错误标签分类来利用文本。我们的实验结果表明，结合程序文本对于错误检测至关重要。数据可通过https://y-haneji.github.io/EgoOops-project-page/获取。", "summary": "本文提出了EgoOops数据集，旨在解决现有错误动作检测方法在处理遵循程序文本活动时的局限性。该数据集包含了以自我为中心的错误活动视频，并结合了视频-文本对齐、错误标签和错误描述等多种标注。研究同时提出了一种利用文本信息的错误检测方法，并通过实验证明了在错误检测中结合程序文本的必要性。", "keywords": "错误动作检测, 以自我为中心视频, 程序文本, 数据集, EgoOops", "comments": "EgoOops数据集的创新之处在于其明确针对需要参照程序文本才能判断动作正确性的场景，填补了现有数据集和方法在此领域的空白。引入视频-文本对齐标注，并证明其对错误检测的重要性，为未来的研究提供了新的方向和基础。该数据集对于开发更智能、更准确的工人辅助和错误反馈系统具有重要意义。"}}
{"id": "2507.22939", "title": "PARROT: An Open Multilingual Radiology Reports Dataset", "authors": ["Bastien Le Guellec", "Kokou Adambounou", "Lisa C Adams", "Thibault Agripnidis", "Sung Soo Ahn", "Radhia Ait Chalal", "Tugba Akinci D Antonoli", "Philippe Amouyel", "Henrik Andersson", "Raphael Bentegeac", "Claudio Benzoni", "Antonino Andrea Blandino", "Felix Busch", "Elif Can", "Riccardo Cau", "Armando Ugo Cavallo", "Christelle Chavihot", "Erwin Chiquete", "Renato Cuocolo", "Eugen Divjak", "Gordana Ivanac", "Barbara Dziadkowiec Macek", "Armel Elogne", "Salvatore Claudio Fanni", "Carlos Ferrarotti", "Claudia Fossataro", "Federica Fossataro", "Katarzyna Fulek", "Michal Fulek", "Pawel Gac", "Martyna Gachowska", "Ignacio Garcia Juarez", "Marco Gatti", "Natalia Gorelik", "Alexia Maria Goulianou", "Aghiles Hamroun", "Nicolas Herinirina", "Krzysztof Kraik", "Dominik Krupka", "Quentin Holay", "Felipe Kitamura", "Michail E Klontzas", "Anna Kompanowska", "Rafal Kompanowski", "Alexandre Lefevre", "Tristan Lemke", "Maximilian Lindholz", "Lukas Muller", "Piotr Macek", "Marcus Makowski", "Luigi Mannacio", "Aymen Meddeb", "Antonio Natale", "Beatrice Nguema Edzang", "Adriana Ojeda", "Yae Won Park", "Federica Piccione", "Andrea Ponsiglione", "Malgorzata Poreba", "Rafal Poreba", "Philipp Prucker", "Jean Pierre Pruvo", "Rosa Alba Pugliesi", "Feno Hasina Rabemanorintsoa", "Vasileios Rafailidis", "Katarzyna Resler", "Jan Rotkegel", "Luca Saba", "Ezann Siebert", "Arnaldo Stanzione", "Ali Fuat Tekin", "Liz Toapanta Yanchapaxi", "Matthaios Triantafyllou", "Ekaterini Tsaoulia", "Evangelia Vassalou", "Federica Vernuccio", "Johan Wasselius", "Weilang Wang", "Szymon Urban", "Adrian Wlodarczak", "Szymon Wlodarczak", "Andrzej Wysocki", "Lina Xu", "Tomasz Zatonski", "Shuhang Zhang", "Sebastian Ziegelmayer", "Gregory Kuchcinski", "Keno K Bressem"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22939v1", "summary": "Rationale and Objectives: To develop and validate PARROT (Polyglottal\nAnnotated Radiology Reports for Open Testing), a large, multicentric,\nopen-access dataset of fictional radiology reports spanning multiple languages\nfor testing natural language processing applications in radiology. Materials\nand Methods: From May to September 2024, radiologists were invited to\ncontribute fictional radiology reports following their standard reporting\npractices. Contributors provided at least 20 reports with associated metadata\nincluding anatomical region, imaging modality, clinical context, and for\nnon-English reports, English translations. All reports were assigned ICD-10\ncodes. A human vs. AI report differentiation study was conducted with 154\nparticipants (radiologists, healthcare professionals, and non-healthcare\nprofessionals) assessing whether reports were human-authored or AI-generated.\nResults: The dataset comprises 2,658 radiology reports from 76 authors across\n21 countries and 13 languages. Reports cover multiple imaging modalities (CT:\n36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical\nregions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)\nbeing most prevalent. In the differentiation study, participants achieved 53.9%\naccuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated\nreports, with radiologists performing significantly better (56.9%, 95% CI:\n53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the\nlargest open multilingual radiology report dataset, enabling development and\nvalidation of natural language processing applications across linguistic,\ngeographic, and clinical boundaries without privacy constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22939v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "PARROT：一个开放的多语言放射学报告数据集", "tldr": "PARROT是一个大型、开放的多语言放射学报告数据集，用于测试放射学领域的自然语言处理应用。", "motivation": "开发和验证PARROT（Polyglottal Annotated Radiology Reports for Open Testing），一个大型、多中心、开放获取的虚构放射学报告数据集，涵盖多种语言，用于测试放射学中的自然语言处理应用。", "method": "2024年5月至9月，邀请放射科医生贡献虚构的放射学报告，并提供相关元数据（解剖区域、影像模态、临床背景）以及非英语报告的英文翻译。所有报告均分配了ICD-10编码。进行了一项人机报告区分研究，154名参与者（放射科医生、医疗专业人员和非医疗专业人员）评估报告是人类撰写还是AI生成。", "result": "该数据集包含来自21个国家、76位作者的2658份放射学报告，涵盖13种语言。报告涵盖多种影像模态（CT：36.1%，MRI：22.8%，X线：19.0%，超声：16.8%）和解剖区域，其中胸部（19.9%）、腹部（18.6%）、头部（17.3%）和骨盆（14.1%）最为普遍。在区分研究中，参与者在区分人类和AI生成报告方面的准确率为53.9%（95% CI：50.7%-57.1%），其中放射科医生的表现（56.9%，95% CI：53.3%-60.6%，p<0.05）显著优于其他群体。", "conclusion": "PARROT是最大的开放多语言放射学报告数据集，能够开发和验证跨语言、地理和临床边界的自然语言处理应用，且不受隐私限制。", "translation": "原理和目标：开发和验证PARROT（用于开放测试的多语言标注放射学报告），这是一个大型、多中心、开放获取的虚构放射学报告数据集，涵盖多种语言，用于测试放射学中的自然语言处理应用。材料和方法：从2024年5月到9月，邀请放射科医生按照其标准报告实践贡献虚构的放射学报告。贡献者提供了至少20份报告及相关元数据，包括解剖区域、影像模态、临床背景，以及非英语报告的英文翻译。所有报告均被分配了ICD-10编码。进行了一项人机报告区分研究，154名参与者（放射科医生、医疗专业人员和非医疗专业人员）评估报告是人类撰写还是AI生成。结果：该数据集包含来自21个国家、76位作者的2658份放射学报告，涵盖13种语言。报告涵盖多种影像模态（CT：36.1%，MRI：22.8%，X线：19.0%，超声：16.8%）和解剖区域，其中胸部（19.9%）、腹部（18.6%）、头部（17.3%）和骨盆（14.1%）最为普遍。在区分研究中，参与者在区分人类和AI生成报告方面的准确率为53.9%（95% CI：50.7%-57.1%），其中放射科医生的表现（56.9%，95% CI：53.3%-60.6%，p<05）显著优于其他群体。结论：PARROT代表了最大的开放多语言放射学报告数据集，能够开发和验证跨语言、地理和临床边界的自然语言处理应用，且不受隐私限制。", "summary": "本研究开发并验证了PARROT数据集，一个大型、多中心、开放获取的虚构多语言放射学报告数据集，旨在支持放射学领域自然语言处理（NLP）应用的开发和测试。该数据集包含来自全球21个国家、76位作者的2658份报告，涵盖13种语言及多种影像模态和解剖区域。研究还进行了一项人机报告区分实验，结果显示参与者区分人类和AI生成报告的准确率为53.9%，其中放射科医生表现更优。PARROT数据集的推出，有望促进跨语言、地理和临床界限的放射学NLP应用研究，且无隐私限制。", "keywords": "放射学报告, 多语言, 数据集, 自然语言处理, 开放获取", "comments": "PARROT数据集的创新性在于其多语言、开放获取和虚构报告的特性，这克服了真实患者数据常见的隐私障碍，极大地促进了放射学NLP领域的研究和开发。其多中心和多作者的贡献也保证了数据的多样性和代表性。此外，进行的AI报告区分研究为数据集的真实性提供了有趣的见解，并强调了未来AI生成报告鉴别的挑战。该数据集对于推动全球范围内的医疗NLP进步具有重要意义。"}}
{"id": "2505.14729", "title": "Uncovering Cultural Representation Disparities in Vision-Language Models", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Srishti Yadav", "Suman Debnath", "Alejandro Salamanca", "Desmond Elliott"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      28 pages, 36 figures", "url": "http://arxiv.org/abs/2505.14729v3", "summary": "Vision-Language Models (VLMs) have demonstrated impressive capabilities\nacross a range of tasks, yet concerns about their potential biases exist. This\nwork investigates the extent to which prominent VLMs exhibit cultural biases by\nevaluating their performance on an image-based country identification task at a\ncountry level. Utilizing the geographically diverse Country211 dataset, we\nprobe several large vision language models (VLMs) under various prompting\nstrategies: open-ended questions, multiple-choice questions (MCQs) including\nchallenging setups like multilingual and adversarial settings. Our analysis\naims to uncover disparities in model accuracy across different countries and\nquestion formats, providing insights into how training data distribution and\nevaluation methodologies might influence cultural biases in VLMs. The findings\nhighlight significant variations in performance, suggesting that while VLMs\npossess considerable visual understanding, they inherit biases from their\npre-training data and scale that impact their ability to generalize uniformly\nacross diverse global contexts.", "comment": "28 pages, 36 figures", "pdf_url": "http://arxiv.org/pdf/2505.14729v3", "cate": "cs.CV", "date": "2025-05-20", "updated": "2025-07-31", "AI": {"title_translation": "揭示视觉-语言模型中的文化表征差异", "tldr": "本文研究了主流视觉-语言模型在图像国家识别任务中表现出的文化偏见，发现其性能存在显著差异，并继承了预训练数据中的偏见。", "motivation": "尽管视觉-语言模型（VLMs）表现出色，但对其潜在偏见的担忧依然存在。本文旨在调查主流VLMs在文化偏见方面的程度。", "method": "研究人员利用地理多样化的Country211数据集，在国家层面评估了多个大型视觉语言模型在图像国家识别任务上的表现。评估采用了多种提示策略，包括开放式问题和多项选择题（MCQs），以及多语言和对抗性设置等挑战性设置。", "result": "分析结果揭示了模型在不同国家和问题格式下准确性的显著差异。研究发现，虽然VLMs具有相当的视觉理解能力，但它们继承了预训练数据和规模所带来的偏见，这些偏见影响了它们在全球多样化环境中统一泛化的能力。", "conclusion": "VLMs在文化表征方面存在显著偏见，这些偏见源于其预训练数据，并影响了模型在全球背景下的泛化能力。", "translation": "视觉-语言模型（VLMs）在一系列任务中展现了令人印象深刻的能力，但对其潜在偏见的担忧依然存在。这项工作通过在国家层面评估主流VLMs在基于图像的国家识别任务上的表现，调查了它们展现文化偏见的程度。利用地理多样化的Country211数据集，我们在各种提示策略下探测了几个大型视觉语言模型（VLMs）：开放式问题、多项选择题（MCQs），包括多语言和对抗性设置等挑战性设置。我们的分析旨在揭示模型在不同国家和问题格式下准确性的差异，从而深入了解训练数据分布和评估方法可能如何影响VLMs中的文化偏见。研究结果突出了性能的显著差异，表明虽然VLMs具有相当的视觉理解能力，但它们继承了预训练数据和规模所带来的偏见，这些偏见影响了它们在全球多样化环境中统一泛化的能力。", "summary": "本文研究了视觉-语言模型（VLMs）在文化表征方面的偏见。通过在Country211数据集上进行图像国家识别任务，并采用多种提问策略，研究发现主流VLMs在不同国家和问题格式下表现出显著的准确性差异。这表明VLMs继承了预训练数据中的偏见，影响了其在全球多样化语境下的泛化能力。", "keywords": "视觉-语言模型, 文化偏见, 国家识别, 泛化能力, 数据集偏见", "comments": "这篇论文通过对VLMs进行系统性的文化偏见评估，揭示了当前模型在处理全球多样性方面存在的局限性。其创新点在于采用了多样的评估策略和地理多样性数据集，为理解和缓解VLMs中的文化偏见提供了重要见解。"}}
{"id": "2507.22963", "title": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization", "authors": ["Abdelrhman Gaber", "Hassan Abd-Eltawab", "John Elgallab", "Youssif Abuzied", "Dineo Mpanya", "Turgay Celik", "Swarun Kumar", "Tamer ElBatt"], "categories": ["cs.LG", "q-bio.OT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22963v1", "summary": "Cardiovascular diseases (CVD) cause over 17 million deaths annually\nworldwide, highlighting the urgent need for privacy-preserving predictive\nsystems. We introduce FedCVD++, an enhanced federated learning (FL) framework\nthat integrates both parametric models (logistic regression, SVM, neural\nnetworks) and non-parametric models (Random Forest, XGBoost) for coronary heart\ndisease risk prediction. To address key FL challenges, we propose: (1)\ntree-subset sampling that reduces Random Forest communication overhead by 70%,\n(2) XGBoost-based feature extraction enabling lightweight federated ensembles,\nand (3) federated SMOTE synchronization for resolving cross-institutional class\nimbalance.\n  Evaluated on the Framingham dataset (4,238 records), FedCVD++ achieves\nstate-of-the-art results: federated XGBoost (F1 = 0.80) surpasses its\ncentralized counterpart (F1 = 0.78), and federated Random Forest (F1 = 0.81)\nmatches non-federated performance. Additionally, our communication-efficient\nstrategies reduce bandwidth consumption by 3.2X while preserving 95% accuracy.\n  Compared to existing FL frameworks, FedCVD++ delivers up to 15% higher\nF1-scores and superior scalability for multi-institutional deployment. This\nwork represents the first practical integration of non-parametric models into\nfederated healthcare systems, providing a privacy-preserving solution validated\nunder real-world clinical constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22963v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "FedCVD++: 面向心血管风险预测的通信高效联邦学习，结合参数和非参数模型优化", "tldr": "FedCVD++是一个通信高效的联邦学习框架，用于心血管疾病风险预测，首次将非参数模型集成到联邦医疗系统中，并实现了最先进的性能。", "motivation": "心血管疾病每年导致全球超过1700万人死亡，因此迫切需要隐私保护的预测系统。", "method": "本文引入了FedCVD++，一个增强的联邦学习(FL)框架，它整合了参数模型（逻辑回归、SVM、神经网络）和非参数模型（随机森林、XGBoost）用于冠心病风险预测。为解决FL挑战，提出了：(1) 树子集采样，减少随机森林通信开销70%；(2) 基于XGBoost的特征提取，实现轻量级联邦集成；(3) 联邦SMOTE同步，解决跨机构类别不平衡问题。", "result": "FedCVD++在Framingham数据集上评估，实现了最先进的结果：联邦XGBoost（F1 = 0.80）超越了其中心化对应模型（F1 = 0.78），联邦随机森林（F1 = 0.81）与非联邦性能匹配。通信高效策略在保持95%准确率的同时，将带宽消耗减少了3.2倍。与现有FL框架相比，FedCVD++的F1分数高出15%，并具有卓越的多机构部署可扩展性。", "conclusion": "FedCVD++是首次将非参数模型实际集成到联邦医疗系统中的工作，提供了一个在真实临床约束下验证的隐私保护解决方案。", "translation": "心血管疾病（CVD）每年在全球范围内导致超过1700万人死亡，凸显了对隐私保护预测系统的迫切需求。我们引入了FedCVD++，一个增强的联邦学习（FL）框架，它集成了参数模型（逻辑回归、支持向量机、神经网络）和非参数模型（随机森林、XGBoost）用于冠心病风险预测。为应对关键的联邦学习挑战，我们提出了：(1) 树子集采样，将随机森林的通信开销降低70%；(2) 基于XGBoost的特征提取，实现轻量级联邦集成；(3) 联邦SMOTE同步，解决跨机构的类别不平衡问题。在Framingham数据集（4,238条记录）上进行评估，FedCVD++取得了最先进的结果：联邦XGBoost（F1 = 0.80）超越了其中心化对应模型（F1 = 0.78），联邦随机森林（F1 = 0.81）与非联邦性能匹配。此外，我们的通信高效策略在保持95%准确率的同时，将带宽消耗减少了3.2倍。与现有联邦学习框架相比，FedCVD++的F1分数最高可提高15%，并为多机构部署提供了卓越的可扩展性。这项工作代表了首次将非参数模型实际集成到联邦医疗系统中，提供了一个在真实临床约束下验证的隐私保护解决方案。", "summary": "FedCVD++是一个创新的联邦学习框架，专为心血管疾病风险预测设计。它首次将参数模型与非参数模型（如随机森林和XGBoost）有效整合到联邦医疗系统中。该框架通过引入树子集采样、基于XGBoost的特征提取和联邦SMOTE同步等策略，显著降低了通信开销，并解决了跨机构数据不平衡问题。在Framingham数据集上的评估显示，FedCVD++在F1分数上超越了现有联邦学习框架，并展示了卓越的通信效率和多机构部署的可扩展性，为隐私保护的医疗预测提供了实用解决方案。", "keywords": "联邦学习, 心血管疾病预测, 通信效率, 非参数模型, 隐私保护", "comments": "该论文的创新点在于首次将非参数模型（特别是树模型）有效地集成到联邦学习框架中，并针对这些模型的通信效率和数据不平衡问题提出了具体的解决方案。其在真实临床约束下的验证增加了其实用价值。FedCVD++不仅提升了预测性能，还显著降低了通信成本，这对于实际部署在医疗机构中至关重要。"}}
{"id": "2507.23047", "title": "Competitive Bundle Trading", "authors": ["Yossi Azar", "Niv Buchbinder", "Roie Levin", "Or Vardi"], "categories": ["cs.DS", "cs.GT"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23047v1", "summary": "A retailer is purchasing goods in bundles from suppliers and then selling\nthese goods in bundles to customers; her goal is to maximize profit, which is\nthe revenue obtained from selling goods minus the cost of purchasing those\ngoods. In this paper, we study this general trading problem from the retailer's\nperspective, where both suppliers and customers arrive online. The retailer has\ninventory constraints on the number of goods from each type that she can store,\nand she must decide upon arrival of each supplier/customer which goods to\nbuy/sell in order to maximize profit.\n  We design an algorithm with logarithmic competitive ratio compared to an\noptimal offline solution. We achieve this via an exponential-weight-update\ndynamic pricing scheme, and our analysis dual fits the retailer's profit with\nrespect to a linear programming formulation upper bounding the optimal offline\nprofit. We prove (almost) matching lower bounds, and we also extend our result\nto an incentive compatible mechanism. Prior to our work, algorithms for trading\nbundles were known only for the special case of selling an initial inventory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23047v1", "cate": "cs.DS", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "竞争性捆绑交易", "tldr": "本文研究零售商在线捆绑商品交易中的利润最大化问题，并设计了一个具有对数竞争比的算法。", "motivation": "零售商在面对在线供应商和客户时，需要在库存限制下决定如何购买和销售捆绑商品以最大化利润。此前的算法仅适用于销售初始库存的特殊情况，缺乏对一般捆绑交易问题的解决方案。", "method": "本文设计了一种算法，该算法通过指数权重更新动态定价方案来实现。分析方法是利用线性规划公式，通过对偶拟合零售商的利润来设定最优离线利润的上限。", "result": "该算法实现了相对于最优离线解的对数竞争比。研究还证明了（几乎）匹配的下限，并将结果扩展到了激励兼容机制。", "conclusion": "本文为零售商在线捆绑交易中的利润最大化问题提供了一个通用的解决方案，首次在在线捆绑交易中实现了高效的竞争性算法，并扩展了相关理论。", "translation": "零售商从供应商处批量采购商品，然后将这些商品批量销售给顾客；她的目标是最大化利润，即销售商品所得收入减去采购商品的成本。在本文中，我们从零售商的角度研究了这种通用的交易问题，其中供应商和顾客都是在线到达的。零售商对每种商品的存储数量都有库存限制，她必须在每个供应商/顾客到达时决定购买/销售哪些商品以最大化利润。\n我们设计了一种算法，与最优离线解决方案相比，其竞争比为对数级别。我们通过指数权重更新动态定价方案实现这一点，我们的分析通过对偶拟合零售商的利润与一个线性规划公式（上限为最优离线利润）相吻合。我们证明了（几乎）匹配的下限，并且还将我们的结果扩展到激励兼容机制。在我们的工作之前，捆绑交易的算法仅适用于销售初始库存的特殊情况。", "summary": "本文研究了零售商在在线环境下，面对供应商和客户在线到达时，如何在库存约束下进行捆绑商品的买卖以最大化利润的问题。作者设计了一种基于指数权重更新动态定价方案的算法，该算法相对于最优离线解决方案实现了对数竞争比，并通过对偶拟合线性规划进行了分析。此外，研究还证明了匹配的下限，并将结果扩展到激励兼容机制，填补了此前仅有初始库存销售算法的空白。", "keywords": "捆绑交易, 利润最大化, 在线算法, 竞争比, 动态定价", "comments": "本文的创新之处在于首次为在线捆绑商品交易这一更普遍的问题提供了通用的算法解决方案，而此前的研究仅限于销售初始库存的特殊情况。其采用的指数权重更新动态定价和对偶拟合线性规划的分析方法是其技术亮点，实现了理论上的对数竞争比，并考虑了激励兼容性，具有重要的理论和实践意义。"}}
{"id": "2507.23755", "title": "Slot Attention with Re-Initialization and Self-Distillation", "authors": ["Rongzhen Zhao", "Yi Zhao", "Juho Kannala", "Joni Pajarinen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.23755v1", "summary": "Unlike popular solutions based on dense feature maps, Object-Centric Learning\n(OCL) represents visual scenes as sub-symbolic object-level feature vectors,\ntermed slots, which are highly versatile for tasks involving visual modalities.\nOCL typically aggregates object superpixels into slots by iteratively applying\ncompetitive cross attention, known as Slot Attention, with the slots as the\nquery. However, once initialized, these slots are reused naively, causing\nredundant slots to compete with informative ones for representing objects. This\noften results in objects being erroneously segmented into parts. Additionally,\nmainstream methods derive supervision signals solely from decoding slots into\nthe input's reconstruction, overlooking potential supervision based on internal\ninformation. To address these issues, we propose Slot Attention with\nre-Initialization and self-Distillation (DIAS): $\\emph{i)}$ We reduce\nredundancy in the aggregated slots and re-initialize extra aggregation to\nupdate the remaining slots; $\\emph{ii)}$ We drive the bad attention map at the\nfirst aggregation iteration to approximate the good at the last iteration to\nenable self-distillation. Experiments demonstrate that DIAS achieves\nstate-of-the-art on OCL tasks like object discovery and recognition, while also\nimproving advanced visual prediction and reasoning. Our code is available on\nhttps://github.com/Genera1Z/DIAS.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.23755v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "槽位注意力机制与重初始化和自蒸馏", "tldr": "提出DIAS，通过重初始化和自蒸馏改进槽位注意力，解决了槽位冗余和监督不足问题，并在OCL任务上实现了SOTA。", "motivation": "现有槽位注意力机制存在两个主要问题：1) 槽位初始化后被简单重用，导致冗余槽位与有效槽位竞争，造成对象被错误地分割成部分；2) 主流方法仅通过槽位解码到输入重建来获取监督信号，忽视了基于内部信息的潜在监督。", "method": "提出DIAS (Slot Attention with re-Initialization and self-Distillation) 两种改进方法：1) 减少聚合槽位中的冗余，并重新初始化额外的聚合以更新剩余槽位。2) 促使第一次聚合迭代中的“坏”注意力图逼近最后一次迭代中的“好”注意力图，以实现自蒸馏。", "result": "DIAS在对象中心学习（OCL）任务（如对象发现和识别）上达到了最先进的水平，同时还改进了高级视觉预测和推理。", "conclusion": "通过引入重初始化和自蒸馏机制，DIAS有效解决了现有槽位注意力机制的冗余和监督不足问题，显著提升了模型在OCL任务上的性能，并推动了视觉预测和推理能力。", "translation": "与基于密集特征图的流行解决方案不同，以对象为中心的学习 (OCL) 将视觉场景表示为亚符号对象级特征向量，称为槽位，这些槽位对于涉及视觉模态的任务具有高度通用性。OCL 通常通过迭代应用竞争性交叉注意力（称为槽位注意力），以槽位作为查询，将对象超像素聚合成槽位。然而，一旦初始化，这些槽位就会被天真地重复使用，导致冗余槽位与信息槽位竞争以表示对象。这通常导致对象被错误地分割成部分。此外，主流方法仅从将槽位解码为输入的重建中获取监督信号，忽略了基于内部信息的潜在监督。为了解决这些问题，我们提出了带有重初始化和自蒸馏的槽位注意力 (DIAS)：i) 我们减少聚合槽位中的冗余，并重新初始化额外的聚合以更新剩余槽位；ii) 我们促使第一次聚合迭代中的“坏”注意力图逼近最后一次迭代中的“好”注意力图，以实现自蒸馏。实验表明，DIAS 在对象发现和识别等 OCL 任务上取得了最先进的性能，同时还改进了高级视觉预测和推理。我们的代码可在 https://github.com/Genera1Z/DIAS 上获取。", "summary": "本文针对现有槽位注意力（Slot Attention）在对象中心学习（OCL）中的局限性，提出了DIAS模型。DIAS通过引入槽位重初始化机制来减少冗余槽位间的竞争，避免对象被错误分割；同时，利用自蒸馏方法，通过使初期注意力图逼近最终注意力图来利用内部信息进行监督。实验证明，DIAS在对象发现、识别以及视觉预测和推理等OCL任务上均达到了当前最佳性能。", "keywords": "槽位注意力, 对象中心学习, 重初始化, 自蒸馏, 视觉表示", "comments": "这篇论文通过对槽位注意力机制进行创新性改进，解决了现有方法中槽位冗余和监督信号利用不足的关键问题。重初始化机制有效地提升了槽位的利用效率和表示能力，而自蒸馏则巧妙地从模型内部挖掘了额外的监督信息。这些改进使得模型在对象中心学习任务上取得了显著的性能提升，为未来相关研究提供了新的思路。"}}
{"id": "2505.24329", "title": "DisTime: Distribution-based Time Representation for Video Large Language Models", "authors": ["Yingsen Zeng", "Zepeng Huang", "Yujie Zhong", "Chengjian Feng", "Jie Hu", "Lin Ma", "Yang Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2505.24329v2", "summary": "Despite advances in general video understanding, Video Large Language Models\n(Video-LLMs) face challenges in precise temporal localization due to discrete\ntime representations and limited temporally aware datasets. Existing methods\nfor temporal expression either conflate time with text-based numerical values,\nadd a series of dedicated temporal tokens, or regress time using specialized\ntemporal grounding heads. To address these issues, we introduce DisTime, a\nlightweight framework designed to enhance temporal comprehension in Video-LLMs.\nDisTime employs a learnable token to create a continuous temporal embedding\nspace and incorporates a Distribution-based Time Decoder that generates\ntemporal probability distributions, effectively mitigating boundary ambiguities\nand maintaining temporal continuity. Additionally, the Distribution-based Time\nEncoder re-encodes timestamps to provide time markers for Video-LLMs. To\novercome temporal granularity limitations in existing datasets, we propose an\nautomated annotation paradigm that combines the captioning capabilities of\nVideo-LLMs with the localization expertise of dedicated temporal models. This\nleads to the creation of InternVid-TG, a substantial dataset with 1.25M\ntemporally grounded events across 179k videos, surpassing ActivityNet-Caption\nby 55 times. Extensive experiments demonstrate that DisTime achieves\nstate-of-the-art performance across benchmarks in three time-sensitive tasks\nwhile maintaining competitive performance in Video QA tasks. Code and data are\nreleased at https://github.com/josephzpng/DisTime.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2505.24329v2", "cate": "cs.CV", "date": "2025-05-30", "updated": "2025-07-31", "AI": {"title_translation": "DisTime：面向视频大语言模型的基于分布的时间表示", "tldr": "DisTime框架通过引入基于分布的时间表示和自动化标注范式，显著提升了视频大语言模型在时间敏感任务上的表现，并构建了一个大规模时间标注数据集InternVid-TG。", "motivation": "尽管通用视频理解取得了进展，但视频大语言模型（Video-LLMs）由于离散的时间表示和有限的时间感知数据集，在精确时间定位方面面临挑战。现有时间表达方法存在将时间与基于文本的数值混淆、添加一系列专用时间标记或使用专门的时间接地头回归时间的问题。", "method": "本文引入了DisTime，一个轻量级框架，旨在增强Video-LLMs的时间理解能力。DisTime使用一个可学习的token来创建连续的时间嵌入空间，并集成了一个基于分布的时间解码器，生成时间概率分布，有效缓解边界模糊性并保持时间连续性。此外，基于分布的时间编码器重新编码时间戳，为Video-LLMs提供时间标记。为了克服现有数据集的时间粒度限制，本文提出了一种自动化标注范式，结合了Video-LLMs的字幕生成能力和专用时间模型的定位专业知识，从而创建了InternVid-TG数据集。", "result": "DisTime在三个时间敏感任务的基准测试中取得了最先进的性能，同时在视频问答（Video QA）任务中保持了竞争力。创建的InternVid-TG是一个包含17.9万个视频中125万个时间事件的大型数据集，超过ActivityNet-Caption的55倍。", "conclusion": "DisTime通过创新的时间表示方法和大规模数据集的构建，有效解决了Video-LLMs在精确时间定位方面的挑战，并在多项时间敏感任务中取得了显著的性能提升。", "translation": "尽管通用视频理解取得了进展，但视频大语言模型（Video-LLMs）由于离散的时间表示和有限的时间感知数据集，在精确时间定位方面面临挑战。现有时间表达方法要么将时间与基于文本的数值混淆，要么添加一系列专用时间标记，要么使用专门的时间接地头回归时间。为了解决这些问题，我们引入了DisTime，一个轻量级框架，旨在增强Video-LLMs的时间理解能力。DisTime采用一个可学习的token来创建连续的时间嵌入空间，并集成了一个基于分布的时间解码器，生成时间概率分布，有效缓解边界模糊性并保持时间连续性。此外，基于分布的时间编码器重新编码时间戳，为Video-LLMs提供时间标记。为了克服现有数据集的时间粒度限制，我们提出了一种自动化标注范式，结合了Video-LLMs的字幕生成能力和专用时间模型的定位专业知识。这导致了InternVid-TG的创建，这是一个包含17.9万个视频中125万个时间事件的大型数据集，超过ActivityNet-Caption的55倍。广泛的实验表明，DisTime在三个时间敏感任务的基准测试中取得了最先进的性能，同时在视频问答（Video QA）任务中保持了竞争力。代码和数据已在https://github.com/josephzpng/DisTime发布。", "summary": "本文提出了DisTime框架，旨在解决视频大语言模型（Video-LLMs）在时间精确性方面的不足。DisTime通过引入基于分布的时间表示方法，包括可学习的时间token、基于分布的时间解码器和编码器，构建连续的时间嵌入空间并生成概率分布，从而提升模型的时序理解能力。为克服数据限制，研究者还提出了一种自动化标注范式，并构建了大规模时间事件数据集InternVid-TG。实验证明，DisTime在时间敏感任务上达到了最先进的性能，并在视频问答任务中表现出色。", "keywords": "视频大语言模型, 时间表示, 深度学习, 时间定位, 数据集", "comments": "DisTime的创新之处在于其基于分布的时间表示方法，有效解决了时间边界模糊性和连续性问题。此外，提出的自动化标注范式及其生成的大规模InternVid-TG数据集，为Video-LLMs的时间理解提供了宝贵的资源，极大地推动了该领域的发展。该工作在方法和数据两方面均具有重要意义。"}}
{"id": "2507.23377", "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23377v1", "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23377v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "LLM4Rail：一个LLM增强的铁路服务咨询平台", "tldr": "LLM4Rail是一个LLM增强的铁路服务咨询平台，提供票务、餐饮、天气和聊天服务，并引入QTAO框架和CRFD-25数据集。", "motivation": "为满足日益增长的个性化铁路服务需求。", "method": "开发了LLM4Rail平台，该平台由LLM赋能，提供票务、铁路餐饮推荐、天气信息和闲聊等定制模块。提出了迭代的“Question-Thought-Action-Observation (QTAO)”提示框架，将言语推理与任务导向行动相结合。构建了公开可用的中文铁路餐饮数据集(CRFD-25)。引入了基于LLM的零样本会话推荐器，并采用基于特征相似度的后处理步骤确保推荐项与CRFD-25数据集对齐。", "result": "成功开发了LLM4Rail铁路服务咨询平台，提供了票务、餐饮推荐、天气查询和闲聊等功能。构建了公开可用的中文铁路餐饮数据集(CRFD-25)。引入了基于LLM的零样本会话推荐器。", "conclusion": "通过LLM4Rail平台，能够有效提供个性化的铁路服务，尤其是在餐饮推荐方面。", "translation": "大型语言模型（LLMs）已经显著改变了各行各业。为了满足日益增长的个性化铁路服务需求，我们开发了LLM4Rail——一个新颖的LLM增强的铁路服务咨询平台。LLM4Rail由LLM赋能，可以提供票务、铁路餐饮推荐、天气信息和闲聊等定制模块。在LLM4Rail中，我们提出了迭代的“Question-Thought-Action-Observation (QTAO)”提示框架。它将言语推理与任务导向行动精细地整合在一起，即通过推理指导行动选择，以有效检索与铁路运营和服务相关的外部观察结果，从而生成准确的响应。为了提供个性化的车上餐饮服务，我们首先构建了中文铁路餐饮（CRFD-25）数据集——一个专为铁路服务量身定制的公开外卖数据集。CRFD-25涵盖了按城市、菜系、年龄组和辣度级别分类的各种特色菜肴。我们进一步引入了基于LLM的零样本会话推荐器，用于铁路餐饮。为了解决开放推荐的无约束性质，引入了基于特征相似度的后处理步骤，以确保所有推荐项目都与CRFD-25数据集对齐。", "summary": "本文开发了LLM4Rail，一个基于大型语言模型（LLM）的铁路服务咨询平台，旨在满足个性化服务需求。该平台提供票务、餐饮推荐、天气查询和闲聊等功能。研究提出了一种迭代的“Question-Thought-Action-Observation (QTAO)”提示框架，用于指导LLM生成准确响应。为实现个性化餐饮服务，作者构建了公开的中文铁路餐饮数据集（CRFD-25），并引入了基于LLM的零样本会话推荐器，结合后处理机制确保推荐准确性。", "keywords": "大型语言模型, 铁路服务, 咨询平台, QTAO框架, 餐饮推荐", "comments": "这篇论文的创新点在于将LLM应用于铁路服务领域，并提出QTAO框架以增强LLM在任务导向型交互中的表现。CRFD-25数据集的构建和零样本推荐器的引入也为个性化车载餐饮提供了新的解决方案，具有实际应用价值。"}}
{"id": "2507.23579", "title": "Impact of a Lower Limb Exosuit Anchor Points on Energetics and Biomechanics", "authors": ["Chiara Lambranzi", "Giulia Oberti", "Christian Di Natali", "Darwin G. Caldwell", "Manuela Galli", "Elena De Momi", "Jesùs Ortiz"], "categories": ["physics.med-ph", "cs.RO", "eess.SP"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 10 figures", "url": "http://arxiv.org/abs/2507.23579v1", "summary": "Anchor point placement is a crucial yet often overlooked aspect of exosuit\ndesign since it determines how forces interact with the human body. This work\nanalyzes the impact of different anchor point positions on gait kinematics,\nmuscular activation and energetic consumption. A total of six experiments were\nconducted with 11 subjects wearing the XoSoft exosuit, which assists hip\nflexion in five configurations. Subjects were instrumented with an IMU-based\nmotion tracking system, EMG sensors, and a mask to measure metabolic\nconsumption. The results show that positioning the knee anchor point on the\nposterior side while keeping the hip anchor on the anterior part can reduce\nmuscle activation in the hip flexors by up to 10.21\\% and metabolic expenditure\nby up to 18.45\\%. Even if the only assisted joint was the hip, all the\nconfigurations introduced changes also in the knee and ankle kinematics.\nOverall, no single configuration was optimal across all subjects, suggesting\nthat a personalized approach is necessary to transmit the assistance forces\noptimally. These findings emphasize that anchor point position does indeed have\na significant impact on exoskeleton effectiveness and efficiency. However,\nthese optimal positions are subject-specific to the exosuit design, and there\nis a strong need for future work to tailor musculoskeletal models to individual\ncharacteristics and validate these results in clinical populations.", "comment": "12 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.23579v1", "cate": "physics.med-ph", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "下肢外骨骼锚点对能量消耗和生物力学的影响", "tldr": "研究发现，下肢外骨骼锚点位置显著影响能量消耗和生物力学，且最佳锚点位置因人而异。", "motivation": "锚点位置是外骨骼设计中一个关键但常被忽视的方面，它决定了力如何与人体相互作用。本研究旨在分析不同锚点位置对步态运动学、肌肉激活和能量消耗的影响。", "method": "11名受试者参与了6项实验，穿戴XoSoft外骨骼，该外骨骼在五种配置下辅助髋关节屈曲。受试者配备了基于IMU的运动追踪系统、EMG传感器和测量代谢消耗的面罩。", "result": "膝关节锚点置于后侧而髋关节锚点置于前侧时，髋屈肌的肌肉激活可减少高达10.21%，代谢消耗可减少高达18.45%。即使只辅助髋关节，所有配置也引起了膝关节和踝关节运动学的变化。没有单一配置对所有受试者都是最佳的。", "conclusion": "锚点位置对外骨骼的有效性和效率有显著影响，但最佳位置因人而异，需要个性化方法和未来研究来定制肌肉骨骼模型并在临床人群中验证。", "translation": "锚点位置是外骨骼设计中一个关键但常被忽视的方面，因为它决定了力如何与人体相互作用。本研究分析了不同锚点位置对步态运动学、肌肉激活和能量消耗的影响。共进行了六项实验，有11名受试者穿戴XoSoft外骨骼，该外骨骼在五种配置下辅助髋关节屈曲。受试者配备了基于IMU的运动追踪系统、EMG传感器和测量代谢消耗的面罩。结果表明，将膝关节锚点置于后侧而髋关节锚点置于前侧时，可以使髋屈肌的肌肉激活减少高达10.21%，代谢消耗减少高达18.45%。即使只辅助髋关节，所有配置也引起了膝关节和踝关节运动学的变化。总的来说，没有单一配置对所有受试者都是最佳的，这表明需要个性化的方法来最佳地传递辅助力。这些发现强调，锚点位置确实对外骨骼的有效性和效率有显著影响。然而，这些最佳位置是针对外骨骼设计的主观性，未来迫切需要根据个体特征定制肌肉骨骼模型，并在临床人群中验证这些结果。", "summary": "本文研究了下肢外骨骼锚点位置对人体能量消耗和生物力学的影响。通过对11名受试者在不同锚点配置下进行实验，发现特定的锚点组合能显著降低髋屈肌激活和代谢消耗，但最佳配置因个体而异。研究强调了锚点位置的重要性以及未来个性化定制的必要性。", "keywords": "下肢外骨骼, 锚点, 能量消耗, 生物力学, 个性化", "comments": "本文创新性地探讨了外骨骼锚点位置这一常被忽视的设计要素，并量化了其对能量消耗和生物力学的影响。研究结果强调了个性化定制对外骨骼效能的重要性，为未来外骨骼设计和应用提供了宝贵的见解。其局限性在于样本量较小，且结果尚未在临床人群中验证。"}}
{"id": "2504.02439", "title": "Estimating Scene Flow in Robot Surroundings with Distributed Miniaturized Time-of-Flight Sensors", "authors": ["Jack Sander", "Giammarco Caroleo", "Alessandro Albini", "Perla Maiolino"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, 2 tables, 1 algorithm, IEEE RO-MAN 2025 accepted paper", "url": "http://arxiv.org/abs/2504.02439v2", "summary": "Tracking motions of humans or objects in the surroundings of the robot is\nessential to improve safe robot motions and reactions. In this work, we present\nan approach for scene flow estimation from low-density and noisy point clouds\nacquired from miniaturized Time of Flight (ToF) sensors distributed on the\nrobot body. The proposed method clusters points from consecutive frames and\napplies Iterative Closest Point (ICP) to estimate a dense motion flow, with\nadditional steps introduced to mitigate the impact of sensor noise and\nlow-density data points. Specifically, we employ a fitness-based classification\nto distinguish between stationary and moving points and an inlier removal\nstrategy to refine geometric correspondences. The proposed approach is\nvalidated in an experimental setup where 24 ToF are used to estimate the\nvelocity of an object moving at different controlled speeds. Experimental\nresults show that the method consistently approximates the direction of the\nmotion and its magnitude with an error which is in line with sensor noise.", "comment": "7 pages, 5 figures, 2 tables, 1 algorithm, IEEE RO-MAN 2025 accepted\n  paper", "pdf_url": "http://arxiv.org/pdf/2504.02439v2", "cate": "cs.RO", "date": "2025-04-03", "updated": "2025-07-31", "AI": {"title_translation": "估计机器人周围环境中分布式小型飞行时间传感器场景流", "tldr": "该论文提出了一种使用分布式小型ToF传感器从低密度、噪声点云中估计机器人周围场景流的方法，并通过实验验证了其对运动方向和大小的准确估计。", "motivation": "跟踪机器人周围人类或物体的运动对于提高机器人运动和反应的安全性至关重要。", "method": "该方法从分布在机器人本体上的小型飞行时间（ToF）传感器获取的低密度和噪声点云中估计场景流。它通过聚类连续帧的点并应用迭代最近点（ICP）算法来估计密集的运动流。为了减轻传感器噪声和低密度数据点的影响，该方法引入了基于适应度的分类来区分静止点和移动点，并采用内点移除策略来优化几何对应关系。", "result": "实验结果表明，该方法能够一致地近似运动的方向和大小，其误差与传感器噪声水平一致。", "conclusion": "该方法能够有效且准确地从低密度、噪声点云中估计机器人周围的场景流，其性能与传感器噪声水平相当。", "translation": "跟踪机器人周围人类或物体的运动对于提高机器人运动和反应的安全性至关重要。在这项工作中，我们提出了一种从分布在机器人本体上的小型飞行时间（ToF）传感器获取的低密度和噪声点云中估计场景流的方法。所提出的方法对连续帧中的点进行聚类，并应用迭代最近点（ICP）来估计密集的运动流，同时引入了额外的步骤以减轻传感器噪声和低密度数据点的影响。具体来说，我们采用基于适应度的分类来区分静止点和移动点，并采用内点移除策略来优化几何对应关系。所提出的方法在一个实验设置中进行了验证，其中使用了24个ToF传感器来估计以不同受控速度移动的物体的速度。实验结果表明，该方法能够一致地近似运动的方向和大小，其误差与传感器噪声水平一致。", "summary": "该论文提出了一种利用分布式小型飞行时间（ToF）传感器从低密度和噪声点云中估计机器人周围场景流的新方法。该方法结合了点聚类、迭代最近点（ICP）以及专门用于处理噪声和低密度数据的策略（如基于适应度的分类和内点移除）。实验验证表明，该方法能准确估计物体的运动方向和大小，其误差与传感器噪声水平相当，从而提高了机器人的安全性和反应能力。", "keywords": "场景流估计, 飞行时间传感器, 点云, 机器人, 运动跟踪", "comments": "这项工作通过利用低成本、分布式的小型ToF传感器来解决机器人周围场景流估计中的关键挑战（低密度和噪声数据），具有创新性。其提出的专门处理策略（适应度分类和内点移除）对于实际应用中的鲁棒性至关重要。该方法对于提高机器人安全性和自主性具有重要意义。"}}
{"id": "2507.23543", "title": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "authors": ["Gopika Sudhakaran", "Hikaru Shindo", "Patrick Schramowski", "Simone Schaub-Meyer", "Kristian Kersting", "Stefan Roth"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in ICCV 2025", "url": "http://arxiv.org/abs/2507.23543v1", "summary": "Visual relation detection (VRD) is the task of identifying the relationships\nbetween objects in a scene. VRD models trained solely on relation detection\ndata struggle to generalize beyond the relations on which they are trained.\nWhile prompt tuning has been used to adapt vision-language models (VLMs) for\nVRD, it uses handcrafted prompts and struggles with novel or complex relations.\nWe argue that instruction tuning offers a more effective solution by\nfine-tuning VLMs on diverse instructional data. We thus introduce ART, an\nAdaptive Relation Tuning framework that adapts VLMs for VRD through instruction\ntuning and strategic instance selection. By converting VRD datasets into an\ninstruction tuning format and employing an adaptive sampling algorithm, ART\ndirects the VLM to focus on informative relations while maintaining\ngeneralizability. Specifically, we focus on the relation classification, where\nsubject-object boxes are given and the model predicts the predicate between\nthem. We tune on a held-in set and evaluate across multiple held-out datasets\nof varying complexity. Our approach strongly improves over its baselines and\ncan infer unseen relation concepts, a capability absent in mainstream VRD\nmethods. We demonstrate ART's practical value by using the predicted relations\nfor segmenting complex scenes.", "comment": "Accepted for publication in ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23543v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "ART：自适应关系调整用于泛化关系预测", "tldr": "现有的视觉关系检测（VRD）模型在泛化性方面表现不佳。ART框架通过指令微调和自适应实例选择，将视觉-语言模型（VLMs）应用于VRD，以提高关系预测能力，尤其是在处理未见关系方面，并展示了在复杂场景分割中的实际价值。", "motivation": "现有的视觉关系检测（VRD）模型在训练数据之外的关系上泛化能力差。虽然提示微调（prompt tuning）已被用于适应视觉-语言模型（VLMs）进行VRD，但其依赖手工制作的提示，并且难以处理新颖或复杂的关系。", "method": "本文提出了ART（Adaptive Relation Tuning）框架，通过指令微调和策略性实例选择来使视觉-语言模型（VLMs）适应视觉关系检测（VRD）。具体方法包括：将VRD数据集转换为指令微调格式，并采用自适应采样算法，引导VLM关注信息丰富的关系，同时保持泛化能力。该方法专注于关系分类任务，即在给定主客体框的情况下预测它们之间的谓词。模型在持有集上进行微调，并在多个复杂程度不同的持有外数据集上进行评估。", "result": "ART方法显著优于其基线模型，并且能够推断出未见过的关系概念，这是主流VRD方法所不具备的能力。通过将预测的关系用于复杂场景分割，展示了ART的实际价值。", "conclusion": "ART框架通过结合指令微调和自适应采样，有效提升了视觉-语言模型在视觉关系检测任务上的泛化能力，尤其是在处理未见关系方面，解决了现有方法的一个关键局限性，并展现了其在实际应用中的潜力。", "translation": "视觉关系检测（VRD）是识别场景中物体之间关系的任务。仅在关系检测数据上训练的VRD模型难以泛化到其训练过的关系之外。虽然提示微调已被用于使视觉-语言模型（VLMs）适应VRD，但它使用手工制作的提示，并且难以处理新颖或复杂的关系。我们认为指令微调通过在多样化的指令数据上微调VLMs，提供了一个更有效的解决方案。因此，我们引入了ART，一个自适应关系调整框架，通过指令微调和策略性实例选择来使VLMs适应VRD。通过将VRD数据集转换为指令微调格式并采用自适应采样算法，ART引导VLM关注信息丰富的关系，同时保持泛化能力。具体而言，我们专注于关系分类，即给定主客体框，模型预测它们之间的谓词。我们在一个持有集上进行微调，并在多个复杂程度不同的持有外数据集上进行评估。我们的方法比其基线模型有显著改进，并且可以推断出未见过的关系概念，这是主流VRD方法所不具备的能力。我们通过使用预测的关系进行复杂场景分割，展示了ART的实际价值。", "summary": "ART框架提出了一种自适应关系调整方法，通过指令微调和策略性实例选择，解决现有视觉关系检测（VRD）模型泛化能力不足的问题。该方法将VRD数据集转换为指令微调格式，并利用自适应采样算法，使视觉-语言模型（VLMs）能够专注于信息丰富的关系。ART在关系分类任务中表现出色，显著优于基线模型，并具备推断未见关系概念的能力，这在主流VRD方法中是缺失的。此外，ART还展示了在复杂场景分割中的实际应用价值。", "keywords": "视觉关系检测, 指令微调, 视觉-语言模型, 泛化, 自适应采样", "comments": "ART的创新之处在于将指令微调和自适应采样应用于视觉-语言模型进行视觉关系检测，这与传统的提示微调或基于检测的方法相比是一种新颖的范式。其能够推断未见关系的能力是实现更泛化VRD的重要一步。在场景分割中的实际应用展示了其潜在的实用价值。"}}
{"id": "2507.23577", "title": "T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text", "authors": ["Alva West", "Luodan Zhang", "Liuliu Zhang", "Minjun Zhu", "Yixuan Weng", "Yue Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23577v1", "summary": "The proliferation of sophisticated text generation models necessitates the\ndevelopment of robust detection methods capable of identifying\nmachine-generated content, particularly text designed to evade detection\nthrough adversarial perturbations. Existing zero-shot detectors often rely on\nstatistical measures that implicitly assume Gaussian distributions, a premise\nthat falters when confronted with the heavy-tailed statistical artifacts\ncharacteristic of adversarial or non-native English texts. This paper\nintroduces T-Detect, a novel detection method that fundamentally redesigns the\nstatistical core of curvature-based detectors. Our primary innovation is the\nreplacement of standard Gaussian normalization with a heavy-tailed discrepancy\nscore derived from the Student's t-distribution. This approach is theoretically\ngrounded in the empirical observation that adversarial texts exhibit\nsignificant leptokurtosis, rendering traditional statistical assumptions\ninadequate. T-Detect computes a detection score by normalizing the\nlog-likelihood of a passage against the expected moments of a t-distribution,\nproviding superior resilience to statistical outliers. We validate our approach\non the challenging RAID benchmark for adversarial text and the comprehensive\nHART dataset. Experiments show that T-Detect provides a consistent performance\nuplift over strong baselines, improving AUROC by up to 3.9\\% in targeted\ndomains. When integrated into a two-dimensional detection framework (CT), our\nmethod achieves state-of-the-art performance, with an AUROC of 0.926 on the\nBooks domain of RAID. Our contributions are a new, theoretically-justified\nstatistical foundation for text detection, an ablation-validated method that\ndemonstrates superior robustness, and a comprehensive analysis of its\nperformance under adversarial conditions. Ours code are released at\nhttps://github.com/ResearAI/t-detect.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23577v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "T-Detect：用于鲁棒检测对抗性机器生成文本的尾部感知统计归一化", "tldr": "T-Detect 是一种新的机器生成文本检测方法，它用基于学生t分布的重尾差异分数取代了传统的基于高斯分布的归一化，以更鲁棒地检测对抗性文本，并在基准测试中取得了显著性能提升。", "motivation": "随着复杂文本生成模型的普及，需要开发能够识别机器生成内容（特别是旨在通过对抗性扰动逃避检测的文本）的鲁棒检测方法。现有零样本检测器通常依赖于隐式假设高斯分布的统计测量，但在面对对抗性或非母语英语文本特有的重尾统计伪影时，这种假设会失效。", "method": "本文引入了T-Detect，一种重新设计基于曲率检测器统计核心的新型检测方法。其主要创新是用源自学生t分布的重尾差异分数取代标准高斯归一化。T-Detect通过根据t分布的期望矩对文本段落的对数似然进行归一化来计算检测分数，从而提供对统计异常值的卓越弹性。", "result": "T-Detect在对抗性文本的RAID基准测试和HART数据集上进行了验证。实验表明，T-Detect相对于强基线表现出持续的性能提升，在目标领域将AUROC提高了高达3.9%。当集成到二维检测框架（CT）中时，该方法在RAID的Books领域达到了0.926的AUROC，实现了最先进的性能。", "conclusion": "本文的贡献是为文本检测提供了一个新的、有理论依据的统计基础，一个经过消融验证并表现出卓越鲁棒性的方法，以及对其在对抗性条件下的性能进行的全面分析。", "translation": "复杂文本生成模型的普及使得开发能够识别机器生成内容（特别是旨在通过对抗性扰动逃避检测的文本）的鲁棒检测方法变得必要。现有零样本检测器通常依赖于隐式假设高斯分布的统计测量，但当面对对抗性或非母语英语文本特有的重尾统计伪影时，这种假设会失效。本文介绍了T-Detect，这是一种新型检测方法，它从根本上重新设计了基于曲率检测器的统计核心。我们的主要创新是用源自学生t分布的重尾差异分数取代标准高斯归一化。这种方法在理论上基于对抗性文本表现出显著的峰度（leptokurtosis）的经验观察，这使得传统统计假设不足。T-Detect通过根据t分布的期望矩对文本段落的对数似然进行归一化来计算检测分数，从而提供对统计异常值的卓越弹性。我们在具有挑战性的对抗性文本RAID基准测试和全面的HART数据集上验证了我们的方法。实验表明，T-Detect相对于强基线表现出持续的性能提升，在目标领域将AUROC提高了高达3.9%。当集成到二维检测框架（CT）中时，我们的方法取得了最先进的性能，在RAID的Books领域达到了0.926的AUROC。我们的贡献是为文本检测提供了一个新的、有理论依据的统计基础，一个经过消融验证并表现出卓越鲁棒性的方法，以及对其在对抗性条件下的性能进行的全面分析。我们的代码已在 https://github.com/ResearAI/t-detect 发布。", "summary": "本文提出了T-Detect，一种新型的机器生成文本检测方法，旨在解决现有检测器在面对对抗性或重尾文本时因假设高斯分布而失效的问题。T-Detect用基于学生t分布的重尾差异分数取代传统的高斯归一化，通过对数似然与t分布矩的归一化计算检测分数，从而增强对统计异常值的鲁棒性。在RAID和HART数据集上的实验表明，T-Detect显著提升了检测性能，并在特定领域实现了最先进的AUROC表现。", "keywords": "机器生成文本, 对抗性文本, 文本检测, 学生t分布, 统计归一化", "comments": "T-Detect的创新点在于其统计基础的重新设计，特别是用学生t分布代替传统的高斯分布来处理对抗性文本的重尾特性，这提供了一种更稳健的检测机制。该方法在理论上有依据，并通过实验验证了其在对抗性条件下的优越鲁棒性，对于提高机器生成文本检测的可靠性具有重要意义。"}}
{"id": "2506.00956", "title": "Continual-MEGA: A Large-scale Benchmark for Generalizable Continual Anomaly Detection", "authors": ["Geonu Lee", "Yujeong Oh", "Geonhui Jang", "Soyoung Lee", "Jeonghyo Song", "Sungmin Cha", "YoungJoon Yoo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00956v2", "summary": "In this paper, we introduce a new benchmark for continual learning in anomaly\ndetection, aimed at better reflecting real-world deployment scenarios. Our\nbenchmark, Continual-MEGA, includes a large and diverse dataset that\nsignificantly expands existing evaluation settings by combining carefully\ncurated existing datasets with our newly proposed dataset, ContinualAD. In\naddition to standard continual learning with expanded quantity, we propose a\nnovel scenario that measures zero-shot generalization to unseen classes, those\nnot observed during continual adaptation. This setting poses a new problem\nsetting that continual adaptation also enhances zero-shot performance. We also\npresent a unified baseline algorithm that improves robustness in few-shot\ndetection and maintains strong generalization. Through extensive evaluations,\nwe report three key findings: (1) existing methods show substantial room for\nimprovement, particularly in pixel-level defect localization; (2) our proposed\nmethod consistently outperforms prior approaches; and (3) the newly introduced\nContinualAD dataset enhances the performance of strong anomaly detection\nmodels. We release the benchmark and code in\nhttps://github.com/Continual-Mega/Continual-Mega.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00956v2", "cate": "cs.CV", "date": "2025-06-01", "updated": "2025-07-31", "AI": {"title_translation": "Continual-MEGA：一个用于可泛化持续异常检测的大规模基准", "tldr": "本文提出了Continual-MEGA，一个大规模的持续异常检测基准，旨在更好地反映现实世界场景，并引入了衡量零样本泛化能力的新场景。研究表明现有方法有改进空间，而他们提出的方法表现优异。", "motivation": "为了更好地反映现实世界的部署场景，并显著扩展现有评估设置，本文引入了一个新的持续学习异常检测基准。", "method": "本文引入了Continual-MEGA，一个结合现有数据集和新提出的ContinualAD数据集的大规模多样化基准。除了扩展数量的标准持续学习外，还提出了一个衡量对未见类进行零样本泛化的新场景。同时，提出了一种统一的基线算法，以提高少样本检测的鲁棒性并保持强大的泛化能力。", "result": "1. 现有方法仍有很大的改进空间，尤其是在像素级缺陷定位方面。2. 本文提出的方法始终优于现有方法。3. 新引入的ContinualAD数据集增强了强大异常检测模型的性能。", "conclusion": "本文提出的Continual-MEGA基准和ContinualAD数据集为持续异常检测，特别是零样本泛化能力方面，提供了新的评估标准和挑战，并验证了其统一基线算法的有效性，表明了该领域仍有巨大的研究潜力。", "translation": "在本文中，我们引入了一个用于异常检测中持续学习的新基准，旨在更好地反映现实世界的部署场景。我们的基准Continual-MEGA，包含一个大规模且多样化的数据集，通过结合精心策划的现有数据集和我们新提出的数据集ContinualAD，显著扩展了现有的评估设置。除了数量扩展的标准持续学习外，我们提出了一个衡量对未见类（在持续适应期间未观察到的类）进行零样本泛化的新场景。这种设置提出了一个新问题，即持续适应也能增强零样本性能。我们还提出了一种统一的基线算法，该算法提高了少样本检测的鲁棒性并保持了强大的泛化能力。通过广泛的评估，我们报告了三个关键发现：(1) 现有方法仍有很大的改进空间，尤其是在像素级缺陷定位方面；(2) 我们提出的方法始终优于现有方法；(3) 新引入的ContinualAD数据集增强了强大异常检测模型的性能。我们已在https://github.com/Continual-Mega/Continual-Mega 发布了该基准和代码。", "summary": "本文介绍了Continual-MEGA，一个针对持续异常检测的新的大规模基准，旨在更好地模拟真实世界场景。该基准整合了现有数据集和新提出的ContinualAD数据集，并引入了一个衡量零样本泛化能力的新评估场景。研究发现现有方法仍有改进空间，而本文提出的统一基线算法表现优异，且ContinualAD数据集能提升现有模型性能。", "keywords": "持续学习, 异常检测, 基准, 零样本泛化, ContinualAD", "comments": "该论文的创新点在于提出了一个大规模且更贴近实际部署场景的持续异常检测基准Continual-MEGA，并特别引入了对未见类进行零样本泛化的新评估维度。这对于推动持续学习和异常检测领域的研究具有重要意义，因为它指出了现有方法的局限性并提供了新的评估标准。所提出的统一基线算法也显示出良好的性能。"}}
{"id": "2507.23535", "title": "Transparent AI: The Case for Interpretability and Explainability", "authors": ["Dhanesh Ramachandram", "Himanshu Joshi", "Judy Zhu", "Dhari Gandhi", "Lucas Hartman", "Ananya Raval"], "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23535v1", "summary": "As artificial intelligence systems increasingly inform high-stakes decisions\nacross sectors, transparency has become foundational to responsible and\ntrustworthy AI implementation. Leveraging our role as a leading institute in\nadvancing AI research and enabling industry adoption, we present key insights\nand lessons learned from practical interpretability applications across diverse\ndomains. This paper offers actionable strategies and implementation guidance\ntailored to organizations at varying stages of AI maturity, emphasizing the\nintegration of interpretability as a core design principle rather than a\nretrospective add-on.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23535v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "透明人工智能：可解释性和可解释性的案例", "tldr": "随着AI系统在关键决策中日益普及，透明度变得至关重要。本文分享了在不同领域实践可解释AI的经验和可操作的策略，强调将可解释性作为核心设计原则。", "motivation": "随着人工智能系统在各行各业中日益影响高风险决策，透明度已成为负责任和值得信赖的人工智能实施的基础。为了解决这一需求，本文旨在提供关于AI可解释性的关键见解和实践经验。", "method": "本文通过分享在不同领域实际应用可解释性获得的见解和经验教训，并为处于不同AI成熟度阶段的组织提供可操作的策略和实施指导，强调将可解释性作为核心设计原则而非事后附加。", "result": "本文提供了从实际可解释性应用中获得的“关键见解和经验教训”，以及“针对不同AI成熟度阶段组织的可操作策略和实施指导”。", "conclusion": "将可解释性作为核心设计原则而非回顾性附加是负责任和值得信赖的AI实施的关键。", "translation": "随着人工智能系统在各行各业中日益影响高风险决策，透明度已成为负责任和值得信赖的人工智能实施的基础。我们利用作为推进人工智能研究和促进行业采纳的领先机构的角色，介绍了来自不同领域实际可解释性应用的关键见解和经验教训。本文为处于不同人工智能成熟度阶段的组织提供了可操作的策略和实施指导，强调将可解释性作为核心设计原则而非事后附加。", "summary": "本文探讨了透明AI在当前高风险决策背景下的重要性，并基于领先机构在AI研究和产业应用方面的经验，分享了在不同领域实践AI可解释性的关键见解和经验教训。论文提供了一系列实用的策略和实施指南，旨在帮助不同AI成熟度的组织将可解释性融入其AI设计中，强调其作为核心原则而非事后补充。", "keywords": "透明AI, 可解释性, 可解释性AI, AI实施, AI策略", "comments": "本文强调了在AI系统设计初期就融入可解释性的重要性，而不是将其作为事后考虑。这对于确保AI的负责任和可信赖部署至关重要，特别是在高风险决策场景中。其创新之处在于提供了实践经验和可操作的策略，对于希望提升AI透明度的组织具有很强的指导意义。"}}
{"id": "2507.23221", "title": "A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations", "authors": ["Charles O'Neill", "Slava Chalnev", "Chi Chi Zhao", "Max Kirkby", "Mudith Jayasekara"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23221v1", "summary": "Contextual hallucinations -- statements unsupported by given context --\nremain a significant challenge in AI. We demonstrate a practical\ninterpretability insight: a generator-agnostic observer model detects\nhallucinations via a single forward pass and a linear probe on its residual\nstream. This probe isolates a single, transferable linear direction separating\nhallucinated from faithful text, outperforming baselines by 5-27 points and\nshowing robust mid-layer performance across Gemma-2 models (2B to 27B).\nGradient-times-activation localises this signal to sparse, late-layer MLP\nactivity. Critically, manipulating this direction causally steers generator\nhallucination rates, proving its actionability. Our results offer novel\nevidence of internal, low-dimensional hallucination tracking linked to specific\nMLP sub-circuits, exploitable for detection and mitigation. We release the\n2000-example ContraTales benchmark for realistic assessment of such solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23221v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "真理的单一方向：观察者模型的线性残差探针揭示并引导上下文幻觉", "tldr": "本文提出一个独立于生成器的观察者模型，通过线性探针在其残差流中识别并控制AI的上下文幻觉，性能显著优于基线，并提供了新的基准数据集，揭示了幻觉与模型内部特定MLP子电路的低维关联。", "motivation": "上下文幻觉——即与给定上下文不符的陈述——仍然是人工智能中的一个重大挑战。", "method": "研究人员开发了一个独立于生成器的观察者模型，该模型通过单次前向传播并在其残差流上应用线性探针来检测幻觉。该探针能够分离出一个单一的、可迁移的线性方向，用于区分幻觉文本和忠实文本。通过梯度乘以激活的方法，将此信号定位到稀疏的、后期层MLP活动。此外，研究还通过操纵这个方向来因果地引导生成器的幻觉率。为了促进相关研究，作者还发布了2000例的ContraTales基准数据集。", "result": "该方法在检测幻觉方面比基线表现好5-27个百分点，并在Gemma-2模型（2B到27B）中显示出稳健的中层性能。信号被定位到稀疏的、后期层MLP活动。最重要的是，操纵该方向可以因果地引导生成器的幻觉率，证明了其可操作性。研究结果提供了关于内部、低维幻觉追踪与特定MLP子电路相关的新证据。", "conclusion": "本文的结果为内部、低维幻觉追踪提供了新颖的证据，这些追踪与特定的MLP子电路相关联，可用于AI幻觉的检测和缓解。", "translation": "上下文幻觉——即与给定上下文不符的陈述——仍然是人工智能中的一个重大挑战。我们展示了一个实用的可解释性见解：一个独立于生成器的观察者模型通过单次前向传播及其残差流上的线性探针来检测幻觉。该探针分离出一个单一的、可迁移的线性方向，将幻觉文本与忠实文本分开，性能优于基线5-27个百分点，并在Gemma-2模型（2B到27B）中显示出稳健的中层性能。梯度乘以激活的方法将此信号定位到稀疏的、后期层MLP活动。至关重要的是，操纵这个方向可以因果地引导生成器的幻觉率，证明了其可操作性。我们的结果提供了内部、低维幻觉追踪的新颖证据，这些追踪与特定的MLP子电路相关联，可用于检测和缓解。我们发布了2000例ContraTales基准数据集，用于对此类解决方案进行现实评估。", "summary": "本文针对AI中上下文幻觉的挑战，提出了一种创新方法。研究人员开发了一个独立于生成器的观察者模型，该模型通过在其残差流上应用线性探针，能够高效（单次前向传播）地检测幻觉。该探针能识别出一个独特的线性方向，有效区分幻觉文本和忠实文本，其性能显著优于现有基线。更重要的是，通过操纵这一方向，可以因果地控制生成器的幻觉率，这不仅揭示了幻觉与模型内部特定MLP子电路的低维关联，也为幻觉的检测和缓解提供了新的途径。为了促进相关研究，作者还发布了一个新的基准数据集ContraTales。", "keywords": "上下文幻觉, 观察者模型, 线性探针, 模型可解释性, 幻觉缓解", "comments": "这篇论文的创新点在于提出了一个“真理的单一方向”的概念，并通过一个生成器无关的观察者模型，利用线性残差探针来检测和甚至“引导”AI的上下文幻觉。其重要性在于提供了一种高效、可解释且可操作的幻觉检测与缓解机制，特别是通过干预模型内部表示来控制幻觉，这为AI可信度和可靠性研究开辟了新途径。发布新的基准数据集也很有价值。"}}
{"id": "2507.23324", "title": "Assessing the Alignment of Automated Vehicle Decisions with Human Reasons", "authors": ["Lucas Elbert Suryana", "Saeed Rahmani", "Simeon Craig Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This version incorporates revisions based on peer-review feedback from a prior submission. The work has not yet been accepted and is being prepared for resubmission", "url": "http://arxiv.org/abs/2507.23324v1", "summary": "A key challenge in deploying automated vehicles (AVs) is ensuring they make\nappropriate decisions in ethically challenging everyday driving situations.\nWhile much attention has been paid to rare, high-stakes dilemmas such as\ntrolley problems, similar tensions also arise in routine scenarios, such as\nnavigating empty intersections, where multiple human considerations, including\nlegality and comfort, often conflict. Current AV planning systems typically\nrely on rigid rules, which struggle to balance these competing considerations\nand can lead to behaviour that misaligns with human expectations. This paper\nproposes a novel reasons-based trajectory evaluation framework that\noperationalises the tracking condition of Meaningful Human Control (MHC). The\nframework models the reasons of human agents, such as regulatory compliance, as\nquantifiable functions and evaluates how well candidate AV trajectories align\nwith these reasons. By assigning adjustable weights to agent priorities and\nintegrating a balance function to discourage the exclusion of any agent, the\nframework supports interpretable decision evaluation. Through a\nreal-world-inspired overtaking scenario, we show how this approach reveals\ntensions, for instance between regulatory compliance, efficiency, and comfort.\nThe framework functions as a modular evaluation layer over existing planning\nalgorithms. It offers a transparent tool for assessing ethical alignment in\neveryday scenarios and provides a practical step toward implementing MHC in\nreal-world AV deployment.", "comment": "This version incorporates revisions based on peer-review feedback\n  from a prior submission. The work has not yet been accepted and is being\n  prepared for resubmission", "pdf_url": "http://arxiv.org/pdf/2507.23324v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "评估自动驾驶汽车决策与人类原因的一致性", "tldr": "本文提出了一种基于原因的轨迹评估框架，通过将人类考量量化并评估自动驾驶汽车轨迹与这些考量的一致性，来确保自动驾驶汽车的决策符合人类期望，特别是在日常伦理挑战场景中。", "motivation": "当前自动驾驶汽车（AVs）在日常驾驶情境中面临做出符合伦理决策的挑战。现有系统依赖僵化规则，难以平衡合法性、舒适性等相互冲突的人类考量，导致自动驾驶行为与人类期望不符。", "method": "本文提出了一种新颖的基于原因的轨迹评估框架，旨在将“有意义的人类控制”（MHC）的操作化。该框架将人类代理的原因（如法规遵从性）建模为可量化函数，并评估候选自动驾驶轨迹与这些原因的对齐程度。通过为代理优先级分配可调节权重并集成平衡函数以防止排除任何代理，该框架支持可解释的决策评估。它可作为现有规划算法之上的模块化评估层。", "result": "通过一个受现实世界启发的超车场景，该方法展示了如何揭示法规遵从性、效率和舒适性等因素之间的矛盾。", "conclusion": "该框架为评估日常场景中的伦理一致性提供了一个透明的工具，并为在实际自动驾驶部署中实施有意义的人类控制（MHC）迈出了实用的一步。", "translation": "部署自动驾驶汽车（AVs）的一个关键挑战是确保它们在道德上具有挑战性的日常驾驶情境中做出适当的决策。尽管人们对诸如电车难题等罕见、高风险的困境给予了大量关注，但在日常场景中也出现了类似的矛盾，例如在空旷的十字路口行驶时，多个人类考量，包括合法性和舒适性，经常相互冲突。当前的自动驾驶规划系统通常依赖于僵化的规则，这些规则难以平衡这些相互竞争的考量，并可能导致与人类期望不符的行为。本文提出了一种新颖的基于原因的轨迹评估框架，该框架将有意义的人类控制（MHC）的跟踪条件操作化。该框架将人类代理的原因（例如法规遵从性）建模为可量化函数，并评估候选自动驾驶轨迹与这些原因的对齐程度。通过为代理优先级分配可调节的权重并集成平衡函数以防止排除任何代理，该框架支持可解释的决策评估。通过一个受现实世界启发性的超车场景，我们展示了这种方法如何揭示矛盾，例如法规遵从性、效率和舒适性之间的矛盾。该框架作为现有规划算法之上的模块化评估层运行。它为评估日常场景中的伦理一致性提供了一个透明的工具，并为在实际自动驾驶部署中实施MHC迈出了实用的一步。", "summary": "本文提出了一种新颖的基于原因的轨迹评估框架，旨在解决自动驾驶汽车（AVs）在日常伦理复杂驾驶情境中决策与人类期望不一致的问题。该框架通过将人类考量（如合法性、舒适性）建模为可量化函数，并评估AV轨迹与这些原因的对齐程度，从而超越了当前僵化的规则系统。它引入了可调节权重和平衡函数以确保决策的可解释性，并在超车场景中展示了其揭示不同人类价值观之间内在矛盾的能力。该框架作为一个模块化评估层，为日常场景中的伦理对齐提供了透明工具，并为在AV实际部署中实现有意义的人类控制（MHC）提供了实用步骤。", "keywords": "自动驾驶汽车, 伦理对齐, 人类原因, 有意义的人类控制, 轨迹评估", "comments": "这篇论文解决了自动驾驶汽车开发中的一个关键空白，它超越了罕见的“电车难题”，转而关注日常驾驶中的伦理复杂性。其创新之处在于通过量化人类原因并提供透明的评估层，将“有意义的人类控制”操作化。这种方法提供了一种实用且可解释的方式来评估和改进自动驾驶行为与人类价值观的一致性，这对于公众接受度和安全部署至关重要。该框架的模块化特性也表明其与现有系统具有良好的集成潜力。"}}
{"id": "2507.23160", "title": "Extended Factorization Machine Annealing for Rapid Discovery of Transparent Conducting Materials", "authors": ["Daisuke Makino", "Tatsuya Goto", "Yoshinori Suga"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "Comments:      12pages, 6figures", "url": "http://arxiv.org/abs/2507.23160v1", "summary": "The development of novel transparent conducting materials (TCMs) is essential\nfor enhancing the performance and reducing the cost of next-generation devices\nsuch as solar cells and displays. In this research, we focus on the\n(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ system and extend the FMA framework, which\ncombines a Factorization Machine (FM) and annealing, to search for optimal\ncompositions and crystal structures with high accuracy and low cost. The\nproposed method introduces (i) the binarization of continuous variables, (ii)\nthe utilization of good solutions using a Hopfield network, (iii) the\nactivation of global search through adaptive random flips, and (iv) fine-tuning\nvia a bit-string local search. Validation using the\n(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ data from the Kaggle \"Nomad2018 Predicting\nTransparent Conductors\" competition demonstrated that our method achieves\nfaster and more accurate searches than Bayesian optimization and genetic\nalgorithms. Furthermore, its application to multi-objective optimization showed\nits capability in designing materials by simultaneously considering both the\nband gap and formation energy. These results suggest that applying our method\nto larger, more complex search problems and diverse material designs that\nreflect realistic experimental conditions is expected to contribute to the\nfurther advancement of materials informatics.", "comment": "12pages, 6figures", "pdf_url": "http://arxiv.org/pdf/2507.23160v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "扩展因子分解机退火用于透明导电材料的快速发现", "tldr": "本文提出了一种扩展的因子分解机退火（FMA）框架，用于快速准确地发现透明导电材料，在速度和准确性上优于贝叶斯优化和遗传算法，并能应用于多目标优化。", "motivation": "开发新型透明导电材料（TCMs）对于提高太阳能电池和显示器等下一代设备的性能和降低成本至关重要。", "method": "本研究扩展了FMA（因子分解机与退火结合）框架，以搜索(Al$_x$Ga$_y$In$_z$)$_2$O$_3$系统中的最佳组分和晶体结构。所提出的方法引入了(i)连续变量的二值化，(ii)利用霍普菲尔德网络利用良好解，(iii)通过自适应随机翻转激活全局搜索，以及(iv)通过位串局部搜索进行微调。", "result": "通过Kaggle“Nomad2018预测透明导体”竞赛的(Al$_x$Ga$_y$In$_z$)$_2$O$_3$数据进行的验证表明，该方法比贝叶斯优化和遗传算法实现了更快、更准确的搜索。此外，其在多目标优化中的应用表明其能够同时考虑带隙和形成能来设计材料。", "conclusion": "这些结果表明，将我们的方法应用于更大、更复杂的搜索问题和反映实际实验条件的多样化材料设计，有望进一步推动材料信息学的发展。", "translation": "开发新型透明导电材料（TCMs）对于提高太阳能电池和显示器等下一代设备的性能和降低成本至关重要。在本研究中，我们专注于(Al$_x$Ga$_y$In$_z$)$_2$O$_3$体系，并扩展了结合因子分解机（FM）和退火的FMA框架，以高精度和低成本搜索最佳组分和晶体结构。所提出的方法引入了(i)连续变量的二值化，(ii)利用霍普菲尔德网络利用良好解，(iii)通过自适应随机翻转激活全局搜索，以及(iv)通过位串局部搜索进行微调。利用Kaggle“Nomad2018预测透明导体”竞赛的(Al$_x$Ga$_y$In$_z$)$_2$O$_3$数据进行的验证表明，我们的方法比贝叶斯优化和遗传算法实现了更快、更准确的搜索。此外，其在多目标优化中的应用表明其能够通过同时考虑带隙和形成能来设计材料。这些结果表明，将我们的方法应用于更大、更复杂的搜索问题和反映实际实验条件的多样化材料设计，有望进一步推动材料信息学的发展。", "summary": "本文提出了一种扩展的因子分解机退火（FMA）框架，用于快速准确地发现透明导电材料，特别关注(Al$_x$Ga$_y$In$_z$)$_2$O$_3$体系。扩展的FMA集成了变量二值化、基于霍普菲尔德网络的良好解利用、用于全局搜索的自适应随机翻转以及用于微调的位串局部搜索等技术。在Kaggle竞赛数据上进行验证，该方法在速度和准确性上均优于贝叶斯优化和遗传算法，并有效应用于多目标材料设计。", "keywords": "透明导电材料, 因子分解机退火, 材料信息学, 多目标优化, 材料发现", "comments": "该论文的创新之处在于其对FMA框架的扩展，通过引入特定的优化技术（如变量二值化、霍普菲尔德网络、自适应翻转和局部搜索），显著提升了材料发现的效率和准确性。其重要性体现在超越现有优化算法的性能，以及在多目标材料设计中的实用性，这对于加速先进材料的开发具有重要意义。"}}
{"id": "2507.23602", "title": "Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport", "authors": ["Moaad Khamlich", "Francesco Romor", "Gianluigi Rozza"], "categories": ["math.NA", "cs.NA", "65K10, 49Q22, 65M60, 90C25, 65Y20", "G.1.6; I.3.5; G.4"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23602v1", "summary": "Semi-discrete optimal transport (SOT), which maps a continuous probability\nmeasure to a discrete one, is a fundamental problem with wide-ranging\napplications. Entropic regularization is often employed to solve the SOT\nproblem, leading to a regularized (RSOT) formulation that can be solved\nefficiently via its convex dual. However, a significant computational challenge\nemerges when the continuous source measure is discretized via the finite\nelement (FE) method to handle complex geometries or densities, such as those\narising from solutions to Partial Differential Equations (PDEs). The evaluation\nof the dual objective function requires dense interactions between the numerous\nsource quadrature points and all target points, creating a severe bottleneck\nfor large-scale problems. This paper presents a cohesive framework of numerical\nstrategies to overcome this challenge. We accelerate the dual objective and\ngradient evaluations by combining distance-based truncation with fast spatial\nqueries using R-trees. For overall convergence, we integrate multilevel\ntechniques based on hierarchies of both the FE source mesh and the discrete\ntarget measure, alongside a robust scheduling strategy for the regularization\nparameter. When unified, these methods drastically reduce the computational\ncost of RSOT, enabling its practical application to complex, large-scale\nscenarios. We provide an open-source C++ implementation of this framework,\nbuilt upon the deal.II finite element library, available at\nhttps://github.com/SemiDiscreteOT/SemiDiscreteOT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23602v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "熵正则化半离散最优传输的高效数值策略", "tldr": "本文提出了一套高效的数值策略，通过结合基于距离的截断、R树快速空间查询和多级技术，显著降低了有限元离散化连续源测度的熵正则化半离散最优传输问题的计算成本。", "motivation": "当连续源测度通过有限元方法离散化以处理复杂几何或密度（例如偏微分方程的解）时，熵正则化半离散最优传输（RSOT）问题的计算面临巨大挑战。其对偶目标函数的评估需要大量的源正交点与所有目标点之间的密集交互，这对于大规模问题来说是一个严重的瓶颈。", "method": "本文提出了一套数值策略框架来克服计算挑战。通过结合基于距离的截断和使用R树的快速空间查询来加速对偶目标和梯度评估。为了整体收敛，本文整合了基于有限元源网格和离散目标测度层次结构的多级技术，以及稳健的正则化参数调度策略。", "result": "当这些方法统一使用时，它们显著降低了熵正则化半离散最优传输（RSOT）的计算成本，使其能够实际应用于复杂、大规模的场景。", "conclusion": "本文提出的数值策略框架显著提高了熵正则化半离散最优传输的计算效率，使其能够应用于大规模复杂问题。", "translation": "半离散最优传输（SOT）是将连续概率测度映射到离散概率测度，是一个具有广泛应用的基础问题。熵正则化常用于解决SOT问题，从而形成一个可以通过其凸对偶有效解决的正则化（RSOT）公式。然而，当连续源测度通过有限元（FE）方法离散化以处理复杂几何或密度（例如偏微分方程的解）时，会出现一个显著的计算挑战。对偶目标函数的评估需要大量的源正交点与所有目标点之间的密集交互，这对于大规模问题来说是一个严重的瓶颈。本文提出了一套统一的数值策略框架来克服这一挑战。我们通过结合基于距离的截断和使用R树的快速空间查询来加速对偶目标和梯度评估。为了整体收敛，我们整合了基于有限元源网格和离散目标测度层次结构的多级技术，以及一个稳健的正则化参数调度策略。当这些方法统一使用时，它们显著降低了RSOT的计算成本，使其能够实际应用于复杂、大规模的场景。我们提供了一个基于deal.II有限元库构建的开源C++实现，可在https://github.com/SemiDiscreteOT/SemiDiscreteOT获取。", "summary": "本文针对通过有限元方法离散化连续源测度时，熵正则化半离散最优传输（RSOT）问题中出现的计算瓶颈，提出了一套高效数值策略。该框架结合了基于距离的截断、R树快速空间查询以加速函数评估，并整合了基于网格和测度层次结构的多级技术以及正则化参数调度策略。这些方法显著降低了RSOT的计算成本，使其适用于大规模复杂应用。作者还提供了开源C++实现。", "keywords": "半离散最优传输, 熵正则化, 有限元, 数值策略, 多级方法", "comments": "本文针对半离散最优传输中的一个重要计算瓶颈提出了创新的解决方案。通过结合多种数值优化技术（如空间数据结构和多级方法），显著提升了算法的效率和实用性。提供开源实现也极大地促进了研究的可重复性和实际应用。"}}
{"id": "2506.19330", "title": "Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification", "authors": ["Yidi Shao", "Longfei Zhou", "Fangshuo Tang", "Xinyi Shi", "Dalang Chen", "Shengtao Xia"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Due to issues related to author order and some problems in the current version regarding methodology, we would like to withdraw the preprint to avoid potential conflicts", "url": "http://arxiv.org/abs/2506.19330v2", "summary": "Electronic component classification and detection are crucial in\nmanufacturing industries, significantly reducing labor costs and promoting\ntechnological and industrial development. Pre-trained models, especially those\ntrained on ImageNet, are highly effective in image classification, allowing\nresearchers to achieve excellent results even with limited data. This paper\ncompares the performance of twelve ImageNet pre-trained models in classifying\nelectronic components. Our findings show that all models tested delivered\nrespectable accuracies. MobileNet-V2 recorded the highest at 99.95%, while\nEfficientNet-B0 had the lowest at 92.26%. These results underscore the\nsubstantial benefits of using ImageNet pre-trained models in image\nclassification tasks and confirm the practical applicability of these methods\nin the electronics manufacturing sector.", "comment": "Due to issues related to author order and some problems in the\n  current version regarding methodology, we would like to withdraw the preprint\n  to avoid potential conflicts", "pdf_url": "http://arxiv.org/pdf/2506.19330v2", "cate": "cs.CV", "date": "2025-06-24", "updated": "2025-07-31", "AI": {"title_translation": "微调ImageNet预训练模型在电子元件分类中的性能比较", "tldr": "本文比较了12种ImageNet预训练模型在电子元件分类任务中的性能，发现所有模型都表现良好，其中MobileNet-V2表现最佳。", "motivation": "电子元件分类和检测在制造业中至关重要，能显著降低劳动力成本并促进技术和工业发展。预训练模型在图像分类中非常有效，即使在数据有限的情况下也能取得良好结果。", "method": "本文比较了十二种ImageNet预训练模型在电子元件分类任务中的性能。", "result": "所有测试模型都取得了可观的准确率。MobileNet-V2以99.95%的准确率最高，而EfficientNet-B0以92.26%的准确率最低。", "conclusion": "使用ImageNet预训练模型在图像分类任务中具有显著优势，并证实了这些方法在电子制造业中的实际适用性。", "translation": "电子元件分类和检测在制造业中至关重要，能显著降低劳动力成本并促进技术和工业发展。预训练模型，特别是那些在ImageNet上训练的模型，在图像分类中非常有效，即使在数据有限的情况下也能让研究人员获得出色的结果。本文比较了十二种ImageNet预训练模型在电子元件分类中的性能。我们的研究结果表明，所有测试模型都取得了可观的准确率。MobileNet-V2以99.95%的准确率最高，而EfficientNet-B0以92.26%的准确率最低。这些结果突显了在图像分类任务中使用ImageNet预训练模型的巨大优势，并证实了这些方法在电子制造业中的实际适用性。", "summary": "本研究旨在评估和比较十二种ImageNet预训练模型在电子元件分类任务中的性能。研究发现，所有测试模型均表现出良好的分类准确率，其中MobileNet-V2取得了最高的99.95%准确率，而EfficientNet-B0的准确率为92.26%。这些结果强调了ImageNet预训练模型在图像分类领域的显著效益，并证实了其在电子制造行业中的实际应用潜力。", "keywords": "电子元件分类, ImageNet, 预训练模型, 性能比较, 深度学习", "comments": "该研究通过比较多种预训练模型在特定工业应用（电子元件分类）中的性能，为实际部署提供了有价值的参考。其创新点在于验证了现有成熟模型在特定场景下的有效性，并量化了不同模型之间的性能差异。这种实用性导向的研究对于推动工业自动化和效率提升具有重要意义。"}}
{"id": "2507.23000", "title": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "authors": ["Shengao Yi", "Xiaojiang Li", "Wei Tu", "Tianhong Zhao"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23000v1", "summary": "As extreme heat events intensify due to climate change and urbanization,\ncities face increasing challenges in mitigating outdoor heat stress. While\ntraditional physical models such as SOLWEIG and ENVI-met provide detailed\nassessments of human-perceived heat exposure, their computational demands limit\nscalability for city-wide planning. In this study, we propose GSM-UTCI, a\nmultimodal deep learning framework designed to predict daytime average\nUniversal Thermal Climate Index (UTCI) at 1-meter hyperlocal resolution. The\nmodel fuses surface morphology (nDSM), high-resolution land cover data, and\nhourly meteorological conditions using a feature-wise linear modulation (FiLM)\narchitecture that dynamically conditions spatial features on atmospheric\ncontext. Trained on SOLWEIG-derived UTCI maps, GSM-UTCI achieves near-physical\naccuracy, with an R2 of 0.9151 and a mean absolute error (MAE) of 0.41{\\deg}C,\nwhile reducing inference time from hours to under five minutes for an entire\ncity. To demonstrate its planning relevance, we apply GSM-UTCI to simulate\nsystematic landscape transformation scenarios in Philadelphia, replacing bare\nearth, grass, and impervious surfaces with tree canopy. Results show spatially\nheterogeneous but consistently strong cooling effects, with impervious-to-tree\nconversion producing the highest aggregated benefit (-4.18{\\deg}C average\nchange in UTCI across 270.7 km2). Tract-level bivariate analysis further\nreveals strong alignment between thermal reduction potential and land cover\nproportions. These findings underscore the utility of GSM-UTCI as a scalable,\nfine-grained decision support tool for urban climate adaptation, enabling\nscenario-based evaluation of greening strategies across diverse urban\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23000v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "规划凉爽城市：一个通过城市景观改造预测和缓解城市热应力的多模态AI框架", "tldr": "提出GSM-UTCI，一个多模态AI框架，能快速准确预测城市热应力，并评估景观改造的降温效果，助力城市气候适应规划。", "motivation": "由于气候变化和城市化，极端高温事件加剧，城市在缓解户外热应力方面面临日益严峻的挑战。传统的物理模型计算成本高，限制了其在全市规划中的可扩展性。", "method": "本研究提出GSM-UTCI，一个多模态深度学习框架，旨在预测1米超局部分辨率的白天平均通用热气候指数（UTCI）。该模型融合了地表形态（nDSM）、高分辨率土地覆盖数据和每小时气象条件，使用一种特征线性调制（FiLM）架构，根据大气环境动态调整空间特征。GSM-UTCI在SOLWEIG衍生的UTCI地图上进行训练，并应用于模拟费城的系统性景观改造场景，将裸地、草地和不透水表面替换为树冠。", "result": "GSM-UTCI实现了接近物理模型的准确性，R2为0.9151，平均绝对误差（MAE）为0.41°C。同时，将整个城市的推理时间从数小时缩短到五分钟以内。结果显示，景观改造产生了空间异质但持续强烈的降温效果，其中不透水表面转换为树木产生了最高的综合效益（在270.7平方公里范围内，UTCI平均变化为-4.18°C）。区域层面的双变量分析进一步揭示了热减少潜力与土地覆盖比例之间的强关联。", "conclusion": "这些发现强调了GSM-UTCI作为一种可扩展、细粒度的城市气候适应决策支持工具的实用性，能够对不同城市环境中的绿化策略进行情景评估。", "translation": "由于气候变化和城市化，极端高温事件加剧，城市在缓解户外热应力方面面临日益严峻的挑战。虽然SOLWEIG和ENVI-met等传统物理模型提供了对人体感知热暴露的详细评估，但其计算需求限制了全市规划的可扩展性。在本研究中，我们提出了GSM-UTCI，一个多模态深度学习框架，旨在预测1米超局部分辨率的白天平均通用热气候指数（UTCI）。该模型融合了地表形态（nDSM）、高分辨率土地覆盖数据和每小时气象条件，使用一种特征线性调制（FiLM）架构，根据大气环境动态调整空间特征。GSM-UTCI在SOLWEIG衍生的UTCI地图上进行训练，实现了接近物理模型的准确性，R2为0.9151，平均绝对误差（MAE）为0.41°C，同时将整个城市的推理时间从数小时缩短到五分钟以内。为了展示其规划相关性，我们将GSM-UTCI应用于模拟费城的系统性景观改造场景，将裸地、草地和不透水表面替换为树冠。结果显示，产生了空间异质但持续强烈的降温效果，其中不透水表面转换为树木产生了最高的综合效益（在270.7平方公里范围内，UTCI平均变化为-4.18°C）。区域层面的双变量分析进一步揭示了热减少潜力与土地覆盖比例之间的强关联。这些发现强调了GSM-UTCI作为一种可扩展、细粒度的城市气候适应决策支持工具的实用性，能够对不同城市环境中的绿化策略进行情景评估。", "summary": "本研究提出了一种名为GSM-UTCI的多模态深度学习框架，旨在以高精度和高效率预测1米分辨率的城市热应力（UTCI）。该模型通过特征线性调制（FiLM）架构整合了地表形态、高分辨率土地覆盖和气象数据。与传统模型相比，GSM-UTCI在SOLWEIG数据上训练，显著缩短了推理时间。该框架应用于费城，通过模拟景观改造（特别是将不透水表面转换为树冠）展示了有效的降温效益，突显了其作为城市气候适应可扩展决策支持工具的实用性。", "keywords": "城市热应力, 深度学习, 多模态AI, 城市规划, 气候适应", "comments": "本文的创新之处在于利用多模态深度学习方法（FiLM架构）实现了城市热应力预测的高精度和计算效率的显著提升。其重要性在于为城市规划者提供了一个可扩展的工具，用于评估气候适应背景下的绿化策略，从而有效缓解城市热岛效应。"}}
{"id": "2507.23202", "title": "Adversarial-Guided Diffusion for Multimodal LLM Attacks", "authors": ["Chengwei Xia", "Fan Ma", "Ruijie Quan", "Kun Zhan", "Yi Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23202v1", "summary": "This paper addresses the challenge of generating adversarial image using a\ndiffusion model to deceive multimodal large language models (MLLMs) into\ngenerating the targeted responses, while avoiding significant distortion of the\nclean image. To address the above challenges, we propose an adversarial-guided\ndiffusion (AGD) approach for adversarial attack MLLMs. We introduce\nadversarial-guided noise to ensure attack efficacy. A key observation in our\ndesign is that, unlike most traditional adversarial attacks which embed\nhigh-frequency perturbations directly into the clean image, AGD injects target\nsemantics into the noise component of the reverse diffusion. Since the added\nnoise in a diffusion model spans the entire frequency spectrum, the adversarial\nsignal embedded within it also inherits this full-spectrum property.\nImportantly, during reverse diffusion, the adversarial image is formed as a\nlinear combination of the clean image and the noise. Thus, when applying\ndefenses such as a simple low-pass filtering, which act independently on each\ncomponent, the adversarial image within the noise component is less likely to\nbe suppressed, as it is not confined to the high-frequency band. This makes AGD\ninherently robust to variety defenses. Extensive experiments demonstrate that\nour AGD outperforms state-of-the-art methods in attack performance as well as\nin model robustness to some defenses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23202v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于多模态大型语言模型攻击的对抗引导扩散", "tldr": "本文提出了一种名为AGD的新型对抗攻击方法，通过将对抗性语义注入扩散模型的噪声分量来欺骗多模态大型语言模型，同时对防御措施具有鲁棒性。", "motivation": "现有方法在生成对抗性图像以欺骗多模态大型语言模型（MLLMs）时，难以在有效性的同时避免对原始图像造成显著失真。此外，传统的对抗攻击容易被防御措施抑制。", "method": "本文提出了一种对抗引导扩散（AGD）方法，用于攻击多模态大型语言模型。AGD通过在逆向扩散过程中将目标语义注入到噪声分量中，而不是直接在原始图像中嵌入高频扰动。由于扩散模型中的噪声覆盖整个频率频谱，嵌入其中的对抗信号也具有全频谱特性，这使得AGD在面对低通滤波等防御时更具鲁棒性。", "result": "实验结果表明，AGD在攻击性能和对某些防御的模型鲁棒性方面均优于现有最先进的方法。", "conclusion": "AGD是一种有效且对防御具有鲁棒性的对抗攻击方法，它通过利用扩散模型的全频谱噪声特性，成功地欺骗了多模态大型语言模型，同时保持了图像的完整性。", "translation": "本文解决了使用扩散模型生成对抗性图像以欺骗多模态大型语言模型（MLLMs）使其生成目标响应，同时避免干净图像显著失真的挑战。为了解决上述挑战，我们提出了一种对抗引导扩散（AGD）方法用于对抗攻击MLLMs。我们引入对抗引导噪声以确保攻击效果。我们设计中的一个关键观察是，与大多数直接将高频扰动嵌入到干净图像中的传统对抗攻击不同，AGD将目标语义注入到逆向扩散的噪声分量中。由于扩散模型中添加的噪声涵盖整个频率频谱，因此嵌入其中的对抗信号也继承了这种全频谱特性。重要的是，在逆向扩散过程中，对抗性图像是干净图像和噪声的线性组合。因此，当应用诸如简单低通滤波等独立作用于每个分量的防御时，噪声分量中的对抗性图像不太可能被抑制，因为它不局限于高频带。这使得AGD本质上对各种防御具有鲁棒性。大量实验表明，我们的AGD在攻击性能以及对某些防御的模型鲁棒性方面均优于最先进的方法。", "summary": "本文提出了一种名为对抗引导扩散（AGD）的新型攻击方法，旨在利用扩散模型生成对抗性图像，以欺骗多模态大型语言模型（MLLMs）生成特定响应，同时最小化图像失真。与传统攻击不同，AGD将对抗性语义注入到逆向扩散的噪声分量中，利用噪声的全频谱特性，使得生成的对抗性图像对低通滤波等防御措施具有固有的鲁棒性。实验证明，AGD在攻击效果和对防御的鲁棒性方面均优于现有技术。", "keywords": "对抗攻击, 扩散模型, 多模态大型语言模型, 对抗引导扩散, 鲁棒性", "comments": "本文的创新点在于提出了将对抗性语义注入扩散模型噪声分量的新颖方法，而非传统的直接嵌入高频扰动。这种方法利用了扩散模型噪声的全频谱特性，显著增强了对抗样本对防御措施的鲁棒性，特别是低通滤波。这对于理解和防御针对多模态LLM的攻击具有重要意义。"}}
{"id": "2507.23307", "title": "ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection", "authors": ["Xihang Hu", "Fuming Sun", "Jiazhe Liu", "Feilong Xu", "Xiaoli Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures, ACM MM 2025", "url": "http://arxiv.org/abs/2507.23307v1", "summary": "Semi-supervised Camouflaged Object Detection (SSCOD) aims to reduce reliance\non costly pixel-level annotations by leveraging limited annotated data and\nabundant unlabeled data. However, existing SSCOD methods based on\nTeacher-Student frameworks suffer from severe prediction bias and error\npropagation under scarce supervision, while their multi-network architectures\nincur high computational overhead and limited scalability. To overcome these\nlimitations, we propose ST-SAM, a highly annotation-efficient yet concise\nframework that breaks away from conventional SSCOD constraints. Specifically,\nST-SAM employs Self-Training strategy that dynamically filters and expands\nhigh-confidence pseudo-labels to enhance a single-model architecture, thereby\nfundamentally circumventing inter-model prediction bias. Furthermore, by\ntransforming pseudo-labels into hybrid prompts containing domain-specific\nknowledge, ST-SAM effectively harnesses the Segment Anything Model's potential\nfor specialized tasks to mitigate error accumulation in self-training.\nExperiments on COD benchmark datasets demonstrate that ST-SAM achieves\nstate-of-the-art performance with only 1\\% labeled data, outperforming existing\nSSCOD methods and even matching fully supervised methods. Remarkably, ST-SAM\nrequires training only a single network, without relying on specific models or\nloss functions. This work establishes a new paradigm for annotation-efficient\nSSCOD. Codes will be available at https://github.com/hu-xh/ST-SAM.", "comment": "10 pages, 6 figures, ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.23307v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "ST-SAM：SAM驱动的半监督伪装目标检测自训练框架", "tldr": "ST-SAM是一个高效的半监督伪装目标检测框架，通过自训练和利用SAM，用极少量标注数据实现了SOTA性能，解决了现有方法的预测偏差和计算开销问题。", "motivation": "现有的半监督伪装目标检测（SSCOD）方法（基于师生框架）在监督数据稀缺时存在严重的预测偏差和错误传播问题，且多网络架构导致高计算开销和可扩展性有限。", "method": "提出ST-SAM框架，采用自训练策略，动态过滤和扩展高置信度伪标签以增强单模型架构，从而避免模型间预测偏差。此外，通过将伪标签转换为包含领域特定知识的混合提示，有效利用Segment Anything Model (SAM) 的潜力来减轻自训练中的错误累积。", "result": "在COD基准数据集上的实验表明，ST-SAM在仅使用1%标注数据的情况下实现了最先进的性能，优于现有SSCOD方法，甚至媲美全监督方法。ST-SAM仅需训练单个网络，不依赖特定模型或损失函数。", "conclusion": "这项工作为标注高效的半监督伪装目标检测建立了一个新范式。", "translation": "半监督伪装目标检测（SSCOD）旨在通过利用有限的标注数据和大量的未标注数据来减少对昂贵的像素级标注的依赖。然而，现有基于师生框架的SSCOD方法在监督稀缺的情况下存在严重的预测偏差和错误传播问题，而其多网络架构则带来高计算开销和有限的可扩展性。为了克服这些局限性，我们提出了ST-SAM，一个高度标注高效且简洁的框架，它打破了传统的SSCOD限制。具体而言，ST-SAM采用自训练策略，动态过滤和扩展高置信度伪标签以增强单个模型架构，从而从根本上规避了模型间预测偏差。此外，通过将伪标签转换为包含领域特定知识的混合提示，ST-SAM有效地利用了Segment Anything Model（SAM）在专业任务中的潜力，以减轻自训练中的错误累积。在COD基准数据集上的实验表明，ST-SAM在仅使用1%标注数据的情况下实现了最先进的性能，优于现有SSCOD方法，甚至媲美全监督方法。值得注意的是，ST-SAM仅需训练单个网络，不依赖特定模型或损失函数。这项工作为标注高效的SSCOD建立了一个新范式。代码将发布在https://github.com/hu-xh/ST-SAM。", "summary": "本文提出了ST-SAM，一个用于半监督伪装目标检测（SSCOD）的高效自训练框架。针对现有SSCOD方法在稀缺监督下存在的预测偏差、错误传播以及高计算开销问题，ST-SAM采用单模型自训练策略，通过动态过滤和扩展高置信度伪标签来避免模型间偏差。此外，它将伪标签转换为混合提示以结合Segment Anything Model (SAM) 的能力，从而减轻自训练中的错误累积。实验证明，ST-SAM在仅使用1%标注数据的情况下达到了SOTA性能，甚至与全监督方法相当，并提供了一种标注高效的SSCOD新范式。", "keywords": "半监督学习, 伪装目标检测, 自训练, Segment Anything Model, 伪标签", "comments": "ST-SAM的创新之处在于其采用单模型自训练策略，有效避免了传统师生框架中的预测偏差和错误传播问题。同时，通过将伪标签转换为混合提示并利用SAM，巧妙地将通用分割模型的能力引入到特定领域的半监督任务中，提高了伪标签的质量并减轻了错误累积。其在仅1%标注数据下达到SOTA性能，且仅需训练单个网络，显示出显著的标注效率和计算优势，为半监督伪装目标检测领域提供了新的高效解决方案。"}}
{"id": "2507.23436", "title": "Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification", "authors": ["Abdellah Zakaria Sellam", "Salah Eddine Bekhouche", "Cosimo Distante", "Abdelmalik Taleb-Ahmed"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23436v1", "summary": "Art style classification remains a formidable challenge in computational\naesthetics due to the scarcity of expertly labeled datasets and the intricate,\noften nonlinear interplay of stylistic elements. While recent dual-teacher\nself-supervised frameworks reduce reliance on labeled data, their linear\nprojection layers and localized focus struggle to model global compositional\ncontext and complex style-feature interactions. We enhance the dual-teacher\nknowledge distillation framework to address these limitations by replacing\nconventional MLP projection and prediction heads with Kolmogorov-Arnold\nNetworks (KANs). Our approach retains complementary guidance from two teacher\nnetworks, one emphasizing localized texture and brushstroke patterns, the other\ncapturing broader stylistic hierarchies while leveraging KANs' spline-based\nactivations to model nonlinear feature correlations with mathematical\nprecision. Experiments on WikiArt and Pandora18k demonstrate that our approach\noutperforms the base dual teacher architecture in Top-1 accuracy. Our findings\nhighlight the importance of KANs in disentangling complex style manifolds,\nleading to better linear probe accuracy than MLP projections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23436v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "超越线性瓶颈：基于样条的知识蒸馏用于文化多样艺术风格分类", "tldr": "本文通过用Kolmogorov-Arnold网络（KANs）替换传统MLP，改进了双教师知识蒸馏框架，以更有效地处理艺术风格分类中的非线性特征交互，并在WikiArt和Pandora18k数据集上取得了更好的表现。", "motivation": "艺术风格分类面临专家标注数据集稀缺和风格元素之间复杂、非线性相互作用的挑战。现有的双教师自监督框架虽减少了对标注数据的依赖，但其线性投影层和局部关注难以模拟全局构图上下文和复杂的风格特征交互。", "method": "我们通过用Kolmogorov-Arnold网络（KANs）替换传统的MLP投影和预测头，增强了双教师知识蒸馏框架。该方法保留了两个教师网络的互补指导（一个强调局部纹理，另一个捕捉更广泛的风格层次），并利用KANs基于样条的激活来精确建模非线性特征关联。", "result": "在WikiArt和Pandora18k数据集上的实验表明，我们的方法在Top-1准确率上优于基础双教师架构。研究结果强调了KANs在解缠复杂风格流形中的重要性，从而获得了比MLP投影更好的线性探测准确率。", "conclusion": "通过将KANs集成到双教师知识蒸馏框架中，可以有效地处理艺术风格分类中的非线性特征交互和复杂风格流形，显著提高分类准确性。", "translation": "艺术风格分类在计算美学中仍然是一个艰巨的挑战，原因在于专家标注数据集的稀缺性以及风格元素之间复杂且通常是非线性的相互作用。尽管最近的双教师自监督框架减少了对标注数据的依赖，但其线性投影层和局部关注难以建模全局构图上下文和复杂的风格特征交互。为了解决这些局限性，我们通过用Kolmogorov-Arnold网络（KANs）替换传统的MLP投影和预测头，增强了双教师知识蒸馏框架。我们的方法保留了来自两个教师网络的互补指导，其中一个强调局部纹理和笔触模式，另一个捕捉更广泛的风格层次，同时利用KANs基于样条的激活来以数学精度建模非线性特征关联。在WikiArt和Pandora18k上的实验表明，我们的方法在Top-1准确率上优于基础双教师架构。我们的研究结果强调了KANs在解缠复杂风格流形中的重要性，从而获得了比MLP投影更好的线性探测准确率。", "summary": "本研究通过将Kolmogorov-Arnold网络（KANs）集成到双教师知识蒸馏框架中，解决了艺术风格分类中非线性特征交互和全局上下文建模的挑战。该方法用KANs替换了传统的MLP投影层，利用其样条基激活来精确捕捉复杂的风格特征，并在WikiArt和Pandora18k数据集上表现出优于基线模型的Top-1准确率和更好的线性探测能力，证明了KANs在处理复杂艺术风格流形方面的有效性。", "keywords": "艺术风格分类, 知识蒸馏, Kolmogorov-Arnold网络, KANs, 非线性特征建模", "comments": "本文的创新点在于将新颖的Kolmogorov-Arnold网络（KANs）引入到艺术风格分类的知识蒸馏框架中，有效地解决了传统MLP在处理非线性特征和全局上下文方面的局限性。KANs的引入为艺术风格分类提供了一种更精确、更强大的建模工具，对于处理文化多样性和复杂风格流形具有重要意义。该研究为深度学习模型中更有效地捕获复杂非线性关系提供了新的思路。"}}
{"id": "2507.23557", "title": "Tree-indexed sums of Catalan numbers", "authors": ["Alin Bostan", "Valentin Féray", "Paul Thévenin"], "categories": ["math.CO", "cs.SC", "math.PR"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "Comments:      62 pages, 8 figures", "url": "http://arxiv.org/abs/2507.23557v1", "summary": "We consider a family of infinite sums of products of Catalan numbers, indexed\nby trees. We show that these sums are polynomials in $1/\\pi$ with rational\ncoefficients; the proof is effective and provides an algorithm to explicitly\ncompute these sums. Along the way we introduce parametric liftings of our sums,\nand show that they are polynomials in the complete elliptic integrals of the\nfirst and second kind. Moreover, the degrees of these polynomials are at most\nhalf of the number of vertices of the tree. The computation of these\ntree-indexed sums is motivated by the study of large meandric systems, which\nare non-crossing configurations of loops in the plane.", "comment": "62 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.23557v1", "cate": "math.CO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "树索引的卡塔兰数和", "tldr": "研究了树索引的卡塔兰数无限和，证明它们是1/π的多项式，并与大回旋系统研究相关。", "motivation": "计算树索引的卡塔兰数和，其动机是研究大型回旋系统（平面中循环的非交叉配置）。", "method": "考虑一族由树索引的卡塔兰数乘积的无限和。证明这些和是1/π的多项式，并提供了一种算法来显式计算它们。引入这些和的参数提升，并证明它们是第一类和第二类完全椭圆积分的多项式。", "result": "树索引的卡塔兰数无限和是1/π的多项式，系数为有理数；提供了一种有效算法来显式计算这些和；这些和的参数提升是第一类和第二类完全椭圆积分的多项式；这些多项式的次数至多是树顶点数的一半。", "conclusion": "未明确提及结论，但研究揭示了树索引的卡塔兰数无限和与1/π以及完全椭圆积分之间的多项式关系，并提供了计算方法。", "translation": "我们考虑一族由树索引的卡塔兰数乘积的无限和。我们证明这些和是1/π的多项式，且系数为有理数；该证明是有效的，并提供了一种显式计算这些和的算法。在此过程中，我们引入了这些和的参数提升，并证明它们是第一类和第二类完全椭圆积分的多项式。此外，这些多项式的次数至多是树顶点数的一半。这些树索引和的计算动机是研究大型回旋系统，即平面中循环的非交叉配置。", "summary": "这篇论文研究了由树索引的卡塔兰数乘积的无限和。研究表明，这些和是关于1/π的有理系数多项式，并提供了一种算法来计算它们。此外，论文还引入了这些和的参数提升，并证明它们是第一类和第二类完全椭圆积分的多项式，其次数上限为树顶点数的一半。这项研究的动机源于对大型回旋系统的探索。", "keywords": "卡塔兰数, 树索引和, 1/π多项式, 椭圆积分, 回旋系统", "comments": "这项研究将组合数学中的卡塔兰数与分析中的π和椭圆积分联系起来，揭示了这些无限和的代数结构，并提供了一种计算方法，对回旋系统的研究具有潜在意义。其创新之处在于发现了这些和与1/π以及椭圆积分之间的多项式关系。"}}
{"id": "2507.22958", "title": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "authors": ["Ruslan Khrulev"], "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 97D50", "I.2.7; I.4; K.3.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 3 figures, 10 tables. Code is available at: this https URL", "url": "http://arxiv.org/abs/2507.22958v1", "summary": "This paper introduces a novel benchmark, EGE-Math Solutions Assessment\nBenchmark, for evaluating Vision-Language Models (VLMs) on their ability to\nassess hand-written mathematical solutions. Unlike existing benchmarks that\nfocus on problem solving, our approach centres on understanding student\nsolutions, identifying mistakes, and assigning grades according to fixed\ncriteria. We compile 122 scanned solutions from the Russian Unified State Exam\n(EGE) together with official expert grades, and evaluate seven modern VLMs from\nGoogle, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The\nresults reveal current limitations in mathematical reasoning and human-rubric\nalignment, opening new research avenues in AI-assisted assessment. You can find\ncode in https://github.com/Karifannaa/Auto-check-EGE-math", "comment": "15 pages, 3 figures, 10 tables. Code is available at:\n  https://github.com/Karifannaa/Auto-check-EGE-math", "pdf_url": "http://arxiv.org/pdf/2507.22958v1", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "CHECK-MAT：检查俄罗斯统一国家考试的手写数学答案", "tldr": "引入了一个名为EGE-Math Solutions Assessment Benchmark的新基准，用于评估视觉语言模型（VLMs）评估手写数学解决方案的能力，发现现有VLM在数学推理和与人类评分标准对齐方面存在局限性。", "motivation": "现有基准侧重于问题解决，而不是理解学生解决方案、识别错误和根据固定标准分配分数，因此需要一个新的基准来评估视觉语言模型（VLMs）评估手写数学解决方案的能力。", "method": "构建了一个包含122份来自俄罗斯统一国家考试（EGE）的扫描解决方案及其官方专家评分的数据集，并以三种推理模式评估了七个现代视觉语言模型（VLMs）。", "result": "结果显示了当前视觉语言模型在数学推理和与人类评分标准对齐方面的局限性。", "conclusion": "研究结果为AI辅助评估开辟了新的研究途径。", "translation": "本文介绍了一个新颖的基准，EGE-Math Solutions Assessment Benchmark，用于评估视觉语言模型（VLMs）评估手写数学解决方案的能力。与现有侧重于问题解决的基准不同，我们的方法侧重于理解学生解决方案、识别错误并根据固定标准分配分数。我们汇编了122份来自俄罗斯统一国家考试（EGE）的扫描解决方案及其官方专家评分，并以三种推理模式评估了来自Google、OpenAI、Arcee AI和Alibaba Cloud的七个现代VLM。结果揭示了当前在数学推理和与人类评分标准对齐方面的局限性，为AI辅助评估开辟了新的研究途径。您可以在https://github.com/Karifannaa/Auto-check-EGE-math找到代码。", "summary": "本文推出了EGE-Math Solutions Assessment Benchmark，这是一个用于评估视觉语言模型（VLMs）对手写数学解决方案评估能力的新基准。该基准不同于以往侧重于问题解决的基准，而是专注于理解学生答案、识别错误并依据既定标准评分。研究人员收集了122份俄罗斯统一国家考试（EGE）的扫描解决方案及专家评分，并测试了七个主流VLMs。结果表明，当前VLMs在数学推理和与人类评分标准的对齐方面仍存在不足，这为AI辅助评估领域带来了新的研究方向。", "keywords": "视觉语言模型, 数学评估, 手写答案, 俄罗斯统一国家考试, 基准测试", "comments": "这项研究的创新之处在于其构建了一个专注于“评估”手写数学解决方案而非仅仅“解决”问题的独特基准，填补了现有VLM评估的空白。通过汇编真实考试数据并评估主流VLM，该研究揭示了当前AI在理解复杂数学推理和遵循人类评分标准方面的局限性，为未来AI辅助教育和评估工具的发展指明了方向。其重要性在于推动了VLM在更精细、更具解释性的教育应用场景中的发展。"}}
{"id": "2506.19955", "title": "ZIP: Scalable Crowd Counting via Zero-Inflated Poisson Modeling", "authors": ["Yiming Ma", "Victor Sanchez", "Tanaya Guha"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 11 figures", "url": "http://arxiv.org/abs/2506.19955v3", "summary": "Most crowd counting methods directly regress blockwise density maps using\nMean Squared Error (MSE) losses. This practice has two key limitations: (1) it\nfails to account for the extreme spatial sparsity of annotations - over 95% of\n8x8 blocks are empty across standard benchmarks, so supervision signals in\ninformative regions are diluted by the predominant zeros; (2) MSE corresponds\nto a Gaussian error model that poorly matches discrete, non-negative count\ndata. To address these issues, we introduce ZIP, a scalable crowd counting\nframework that models blockwise counts with a Zero-Inflated Poisson likelihood:\na zero-inflation term learns the probability a block is structurally empty\n(handling excess zeros), while the Poisson component captures expected counts\nwhen people are present (respecting discreteness). We provide a generalization\nanalysis showing a tighter risk bound for ZIP than MSE-based losses and DMCount\nprovided that the training resolution is moderately large. To assess the\nscalability of ZIP, we instantiate it on backbones spanning over 100x in\nparameters/compute. Experiments on ShanghaiTech A & B, UCF-QNRF, and NWPU-Crowd\ndemonstrate that ZIP consistently surpasses state-of-the-art methods across all\nmodel scales.", "comment": "15 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2506.19955v3", "cate": "cs.CV", "date": "2025-06-24", "updated": "2025-07-31", "AI": {"title_translation": "ZIP：通过零膨胀泊松建模实现可扩展人群计数", "tldr": "本文提出了一种名为ZIP的新型人群计数框架，通过零膨胀泊松建模解决了现有方法中注释稀疏性和计数数据不匹配的问题，并在多个数据集上显著优于现有SOTA方法。", "motivation": "现有的人群计数方法在回归块状密度图时使用均方误差（MSE）损失，存在两个主要限制：1) 无法处理注释的极端空间稀疏性（超过95%的块是空的），导致信息区域的监督信号被稀释；2) MSE对应的高斯误差模型与离散、非负的计数数据不匹配。", "method": "本文引入了ZIP（Zero-Inflated Poisson）框架，通过零膨胀泊松似然对块状计数进行建模。其中，零膨胀项学习块在结构上为空的概率（处理过多的零），而泊松分量则捕获存在人群时的预期计数（尊重数据的离散性）。该方法在泛化分析中显示出比基于MSE的损失和DMCount更紧密的风险边界，并在不同规模的模型骨干上进行了可扩展性评估。", "result": "在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd数据集上的实验表明，ZIP在所有模型规模下都始终超越了现有的最先进方法。", "conclusion": "ZIP框架通过零膨胀泊松建模有效解决了人群计数中的稀疏性和数据类型不匹配问题，并展现出卓越的性能和可扩展性，超越了现有SOTA方法。", "translation": "大多数人群计数方法直接使用均方误差（MSE）损失回归块状密度图。这种做法有两个关键限制：(1) 它未能考虑注释的极端空间稀疏性——在标准基准测试中，超过95%的8x8块是空的，因此信息区域的监督信号被主要的零稀释；(2) MSE对应于高斯误差模型，与离散、非负的计数数据不匹配。为了解决这些问题，我们引入了ZIP，这是一个可扩展的人群计数框架，它使用零膨胀泊松似然对块状计数进行建模：零膨胀项学习块在结构上为空的概率（处理过多的零），而泊松分量则捕获存在人群时的预期计数（尊重离散性）。我们提供了一个泛化分析，表明在训练分辨率适度大的情况下，ZIP的风险边界比基于MSE的损失和DMCount更紧密。为了评估ZIP的可扩展性，我们在参数/计算量相差100倍以上的骨干网络上实例化了它。在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd上的实验表明，ZIP在所有模型规模下都始终超越了最先进的方法。", "summary": "本文提出了ZIP，一个用于人群计数的可扩展框架，旨在解决现有方法中因使用MSE损失而导致的两个主要问题：注释的极端空间稀疏性以及高斯误差模型与离散计数数据的不匹配。ZIP通过引入零膨胀泊松似然来建模块状计数，其中零膨胀项处理过多的零值，泊松分量则捕捉实际计数。泛化分析表明其风险边界更优。实验结果显示，ZIP在多个标准人群计数数据集上，包括ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd，在各种模型规模下均持续超越了现有最先进的方法，证明了其优越的性能和良好的可扩展性。", "keywords": "人群计数, 零膨胀泊松, 稀疏性, 可扩展性, 密度图", "comments": "本文的创新点在于引入了零膨胀泊松模型来解决人群计数中普遍存在的注释稀疏性和计数数据非高斯分布的问题，这比传统的MSE损失更符合数据特性。其提出的零膨胀项有效地处理了大量空块，而泊松分量则捕捉了实际计数。此外，论文还进行了泛化分析并证明了其方法的优越风险边界，并强调了其在不同模型规模下的可扩展性和SOTA性能，显示了其在实际应用中的潜力。"}}
{"id": "2507.23298", "title": "Real-time Generation of Various Types of Nodding for Avatar Attentive Listening System", "authors": ["Kazushi Kato", "Koji Inoue", "Divesh Lala", "Keiko Ochi", "Tatsuya Kawahara"], "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted by 27th ACM International Conference on Multimodal Interaction (ICMI '25), Long paper", "url": "http://arxiv.org/abs/2507.23298v1", "summary": "In human dialogue, nonverbal information such as nodding and facial\nexpressions is as crucial as verbal information, and spoken dialogue systems\nare also expected to express such nonverbal behaviors. We focus on nodding,\nwhich is critical in an attentive listening system, and propose a model that\npredicts both its timing and type in real time. The proposed model builds on\nthe voice activity projection (VAP) model, which predicts voice activity from\nboth listener and speaker audio. We extend it to prediction of various types of\nnodding in a continuous and real-time manner unlike conventional models. In\naddition, the proposed model incorporates multi-task learning with verbal\nbackchannel prediction and pretraining on general dialogue data. In the timing\nand type prediction task, the effectiveness of multi-task learning was\nsignificantly demonstrated. We confirmed that reducing the processing rate\nenables real-time operation without a substantial drop in accuracy, and\nintegrated the model into an avatar attentive listening system. Subjective\nevaluations showed that it outperformed the conventional method, which always\ndoes nodding in sync with verbal backchannel. The code and trained models are\navailable at https://github.com/MaAI-Kyoto/MaAI.", "comment": "Accepted by 27th ACM International Conference on Multimodal\n  Interaction (ICMI '25), Long paper", "pdf_url": "http://arxiv.org/pdf/2507.23298v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于虚拟形象专注倾听系统的实时生成多种点头类型", "tldr": "该研究提出了一种实时预测听者点头时机和类型的模型，以改善虚拟形象的专注倾听系统，并通过多任务学习和预训练实现了优于传统方法的表现。", "motivation": "在人机对话中，非语言信息如点头和面部表情与语言信息同等重要。现有的语音对话系统也需要表达这类非语言行为。本文关注点头，因为它在专注倾听系统中至关重要。", "method": "该模型基于语音活动预测（VAP）模型，并对其进行扩展，以连续实时地预测各种类型的点头。此外，该模型还结合了多任务学习（包括语言反馈预测）和在通用对话数据上的预训练。", "result": "在点头时机和类型预测任务中，多任务学习的有效性得到了显著证明。降低处理速率可在不显著降低准确性的情况下实现实时操作。主观评估表明，该模型优于总是与语言反馈同步点头的传统方法。", "conclusion": "该研究成功开发了一个能实时生成多种类型点头的系统，显著提升了虚拟形象专注倾听系统的表现，并证明了多任务学习和实时操作的可行性。", "translation": "在人类对话中，点头和面部表情等非语言信息与语言信息同样重要，语音对话系统也期望能表达此类非语言行为。我们专注于点头，它在专注倾听系统中至关重要，并提出了一个能实时预测其时机和类型的模型。所提出的模型建立在语音活动预测（VAP）模型的基础上，该模型从听者和说话者的音频中预测语音活动。我们将其扩展到以连续和实时的方式预测各种类型的点头，这与传统模型不同。此外，所提出的模型结合了多任务学习，包括语言反馈预测和在通用对话数据上的预训练。在时机和类型预测任务中，多任务学习的有效性得到了显著证明。我们确认，降低处理速率可以在不显著降低准确性的情况下实现实时操作，并将该模型集成到一个虚拟形象专注倾听系统中。主观评估表明，它优于总是与语言反馈同步点头的传统方法。代码和训练好的模型可在 https://github.com/MaAI-Kyoto/MaAI 获取。", "summary": "本研究提出了一种用于虚拟形象专注倾听系统的实时点头生成模型。该模型扩展了语音活动预测（VAP）模型，能够连续、实时地预测多种类型的点头时机和类型。通过引入多任务学习（结合语言反馈预测）和通用对话数据预训练，该模型在预测任务中表现出显著效果。实验证明，该方法能实现实时操作且准确性高，并在主观评估中优于传统的同步点头方法。", "keywords": "实时点头生成,虚拟形象,专注倾听系统,非语言行为,多任务学习", "comments": "该论文的创新点在于提出了一个能够实时预测并生成多种类型点头的模型，这超越了传统模型仅同步生成点头的局限性。通过结合多任务学习和预训练，显著提升了预测的准确性和模型的泛化能力。其实时性和在主观评估中优于传统方法的表现，表明其在提升虚拟形象交互自然度方面具有重要意义和应用潜力。"}}
{"id": "2507.06005", "title": "Towards Serverless Processing of Spatiotemporal Big Data Queries", "authors": ["Diana Baumann", "Tim C. Rese", "David Bermbach"], "categories": ["cs.DB", "cs.DC"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      Accepted for publication in 13th IEEE International Conference on Cloud Engineering (IC2E 2025)", "url": "http://arxiv.org/abs/2507.06005v2", "summary": "Spatiotemporal data are being produced in continuously growing volumes by a\nvariety of data sources and a variety of application fields rely on rapid\nanalysis of such data. Existing systems such as PostGIS or MobilityDB usually\nbuild on relational database systems, thus, inheriting their scale-out\ncharacteristics. As a consequence, big spatiotemporal data scenarios still have\nlimited support even though many query types can easily be parallelized. In\nthis paper, we propose our vision of a native serverless data processing\napproach for spatiotemporal data: We break down queries into small subqueries\nwhich then leverage the near-instant scaling of Function-as-a-Service platforms\nto execute them in parallel. With this, we partially solve the scalability\nneeds of big spatiotemporal data processing.", "comment": "Accepted for publication in 13th IEEE International Conference on\n  Cloud Engineering (IC2E 2025)", "pdf_url": "http://arxiv.org/pdf/2507.06005v2", "cate": "cs.DB", "date": "2025-07-08", "updated": "2025-07-31", "AI": {"title_translation": "走向时空大数据查询的无服务器处理", "tldr": "本文提出了一种原生的无服务器数据处理方法，通过将查询分解为小型的子查询并利用FaaS平台的即时扩展性并行执行，以解决大数据场景下时空数据处理的扩展性问题。", "motivation": "时空数据量持续增长，现有系统（如PostGIS或MobilityDB）基于关系数据库，其扩展性有限，难以支持大规模时空数据场景，尽管许多查询类型易于并行化。", "method": "本文提出了一种原生的无服务器时空数据处理方法：将查询分解为小的子查询，然后利用函数即服务（FaaS）平台的近乎即时的扩展性并行执行这些子查询。", "result": "通过这种方法，部分解决了大规模时空数据处理的扩展性需求。", "conclusion": "通过将时空大数据查询分解并利用FaaS平台进行并行处理，可以部分解决现有系统在扩展性方面的局限性。", "translation": "时空数据正以持续增长的体量由各种数据源生成，并且各种应用领域都依赖于对此类数据的快速分析。现有系统，如PostGIS或MobilityDB，通常建立在关系数据库系统之上，因此继承了它们的横向扩展特性。结果是，即使许多查询类型可以很容易地并行化，大规模时空数据场景仍然支持有限。在本文中，我们提出了我们对时空数据原生无服务器数据处理方法的愿景：我们将查询分解为小的子查询，然后利用函数即服务（FaaS）平台的近乎即时扩展性来并行执行它们。通过这种方式，我们部分解决了大规模时空数据处理的扩展性需求。", "summary": "本文针对现有关系数据库系统在处理大规模时空数据查询时扩展性不足的问题，提出了一种创新的无服务器数据处理方法。该方法将复杂的时空查询分解为多个可并行执行的小型子查询，并利用函数即服务（FaaS）平台的快速扩展能力进行并行处理，从而有效提升了时空大数据处理的扩展性。", "keywords": "时空数据, 无服务器, 大数据查询, FaaS, 扩展性", "comments": "本文提出了一种创新的、基于无服务器架构的时空大数据处理方法，其核心思想是将复杂查询分解并利用FaaS的弹性来提高并行度，这对于解决传统数据库在处理大规模时空数据时的扩展性瓶颈具有重要意义。该方法的创新性在于将FaaS的即时扩展性引入到时空数据处理领域，提供了一种新的思路。然而，抽象中未提及具体实现细节、性能评估或与现有解决方案的详细对比，这可能限制了对其创新性和实用性的全面评估。"}}
{"id": "2505.17696", "title": "Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory", "authors": ["Sota Yoshihara", "Ryosuke Yamamoto", "Hiroyuki Kusumoto", "Masanari Shimura"], "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures. Appendix: 17 pages. First three listed authors have equal contributions", "url": "http://arxiv.org/abs/2505.17696v3", "summary": "This paper proposes a novel theoretical framework for guaranteeing and\nevaluating the resilience of long short-term memory (LSTM) networks in control\nsystems. We introduce \"recovery time\" as a new metric of resilience in order to\nquantify the time required for an LSTM to return to its normal state after\nanomalous inputs. By mathematically refining incremental input-to-state\nstability ($\\delta$ISS) theory for LSTM, we derive a practical data-independent\nupper bound on recovery time. This upper bound gives us resilience-aware\ntraining. Experimental validation on simple models demonstrates the\neffectiveness of our resilience estimation and control methods, enhancing a\nfoundation for rigorous quality assurance in safety-critical AI applications.", "comment": "9 pages, 6 figures. Appendix: 17 pages. First three listed authors\n  have equal contributions", "pdf_url": "http://arxiv.org/pdf/2505.17696v3", "cate": "cs.AI", "date": "2025-05-23", "updated": "2025-07-31", "AI": {"title_translation": "增强AI系统弹性：基于控制理论的LSTM弹性公式化与保证", "tldr": "本文提出了一个量化和保证LSTM网络弹性的理论框架，并引入了“恢复时间”作为新的弹性指标，通过改进的$\\\\delta$ISS理论推导出恢复时间的上限，以实现弹性感知训练。", "motivation": "本文旨在为控制系统中的长短期记忆（LSTM）网络提供一个新颖的理论框架，以保证和评估其弹性，特别是在异常输入后恢复到正常状态的能力。", "method": "本文引入了“恢复时间”作为衡量弹性的新指标，用于量化LSTM在异常输入后恢复到正常状态所需的时间。通过对LSTM的增量输入-状态稳定性（$\\\\delta$ISS）理论进行数学上的改进，推导出了一个实用的、数据无关的恢复时间上限。此上限支持弹性感知训练。", "result": "在简单模型上的实验验证表明，所提出的弹性估计和控制方法是有效的，并实现了弹性感知训练。", "conclusion": "本文提出的方法为安全关键AI应用中的严格质量保证奠定了基础，增强了AI系统的弹性。", "translation": "本文提出了一种新颖的理论框架，用于保证和评估控制系统中长短期记忆（LSTM）网络的弹性。我们引入了“恢复时间”作为衡量弹性的新指标，以量化LSTM在异常输入后恢复到正常状态所需的时间。通过对LSTM的增量输入-状态稳定性（$\\\\delta$ISS）理论进行数学上的改进，我们推导出了一个实用的、数据无关的恢复时间上限。这个上限使我们能够进行弹性感知训练。在简单模型上的实验验证证明了我们弹性估计和控制方法的有效性，为安全关键AI应用中的严格质量保证奠定了基础。", "summary": "本文提出了一个新颖的理论框架，用于量化和保证控制系统中LSTM网络的弹性。通过引入“恢复时间”作为新指标，并基于改进的增量输入-状态稳定性（$\\\\delta$ISS）理论，推导出了数据无关的恢复时间上限，从而实现了弹性感知训练。实验验证了该方法的有效性，为安全关键AI应用的质量保证提供了基础。", "keywords": "LSTM, 弹性, 控制理论, 恢复时间, $\\\\delta$ISS", "comments": "本文的创新点在于引入了“恢复时间”这一新的弹性指标，并基于改进的\\\\deltaISS理论为LSTM的弹性提供了数学上的保证和数据无关的上限。这对于安全关键AI应用，特别是控制系统中的AI，具有重要的理论和实践意义，因为它提供了一种量化和提升AI系统鲁棒性的方法。"}}
{"id": "2411.06409", "title": "Automated Strategy Invention for Confluence of Term Rewrite Systems", "authors": ["Liao Zhang", "Fabian Mitterwallner", "Jan Jakubuv", "Cezary Kaliszyk"], "categories": ["cs.LO", "cs.AI", "F.4.2; I.2.8"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.06409v2", "summary": "Term rewriting plays a crucial role in software verification and compiler\noptimization. With dozens of highly parameterizable techniques developed to\nprove various system properties, automatic term rewriting tools work in an\nextensive parameter space. This complexity exceeds human capacity for parameter\nselection, motivating an investigation into automated strategy invention. In\nthis paper, we focus on confluence, an important property of term rewrite\nsystems, and apply machine learning to develop the first learning-guided\nautomatic confluence prover. Moreover, we randomly generate a large dataset to\nanalyze confluence for term rewrite systems. Our results focus on improving the\nstate-of-the-art automatic confluence prover CSI: When equipped with our\ninvented strategies, it surpasses its human-designed strategies both on the\naugmented dataset and on the original human-created benchmark dataset Cops,\nproving/disproving the confluence of several term rewrite systems for which no\nautomated proofs were known before.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.06409v2", "cate": "cs.LO", "date": "2024-11-10", "updated": "2025-07-31", "AI": {"title_translation": "术语重写系统合流的自动化策略发明", "tldr": "本文利用机器学习自动发明策略，显著提升了术语重写系统合流性证明器的性能，超越了人工设计的策略，并解决了此前无法自动证明的案例。", "motivation": "自动术语重写工具的参数空间过于庞大，超出了人类选择参数的能力，因此需要研究自动化策略发明。", "method": "本文聚焦于术语重写系统的一个重要属性——合流性，并应用机器学习开发了第一个学习引导的自动合流证明器。此外，还随机生成了一个大型数据集用于分析术语重写系统的合流性。", "result": "本研究的成果在于改进了最先进的自动合流证明器CSI：当配备了我们发明的策略后，它在增强数据集和原始人工创建的基准数据集Cops上都超越了其人工设计的策略，成功证明/反驳了此前没有自动证明的几个术语重写系统的合流性。", "conclusion": "本文成功地将机器学习应用于术语重写系统合流性的策略发明，显著提升了现有证明器的性能，证明了自动化策略发明在解决复杂形式化验证问题上的潜力。", "translation": "术语重写在软件验证和编译器优化中扮演着关键角色。随着数十种高度参数化的技术被开发用于证明各种系统属性，自动术语重写工具在一个广泛的参数空间中工作。这种复杂性超出了人类选择参数的能力，从而促使人们对自动化策略发明进行研究。在本文中，我们专注于合流性，这是术语重写系统的一个重要属性，并应用机器学习开发了第一个学习引导的自动合流证明器。此外，我们随机生成了一个大型数据集来分析术语重写系统的合流性。我们的结果集中在改进最先进的自动合流证明器CSI：当配备了我们发明的策略后，它在增强数据集和原始人工创建的基准数据集Cops上都超越了其人工设计的策略，成功证明/反驳了此前没有自动证明的几个术语重写系统的合流性。", "summary": "本文针对自动术语重写工具参数选择的复杂性，提出了一种基于机器学习的自动化策略发明方法。研究聚焦于术语重写系统的合流性，开发了首个学习引导的自动合流证明器，并通过随机生成大型数据集进行分析。实验结果表明，该方法显著提升了现有最先进合流证明器CSI的性能，使其在不同数据集上均超越了人工设计的策略，并成功证明了多个此前无法自动证明的术语重写系统的合流性。", "keywords": "术语重写, 合流性, 自动化策略发明, 机器学习, 软件验证", "comments": "本文的创新点在于首次将机器学习应用于术语重写系统合流性证明的策略发明，成功解决了人工难以处理的参数选择问题。其重要性体现在所发明策略显著提升了现有证明器的性能，并能解决此前未被证明的案例，对软件验证和编译器优化领域具有潜在的积极影响。"}}
{"id": "2506.21509", "title": "Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration", "authors": ["Jiahe Chen", "Jiaying He", "Qian Shao", "Qiyuan Chen", "Jiahe Ying", "Hongxia Xu", "Jintai Chen", "Jianwei Zheng", "Jian Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21509v2", "summary": "Large Vision-Language Models (LVLMs) have demonstrated significant\nadvancements in multimodal understanding, yet they are frequently hampered by\nhallucination-the generation of text that contradicts visual input. Existing\ntraining-free decoding strategies exhibit critical limitations, including the\nuse of static constraints that do not adapt to semantic drift during\ngeneration, inefficiency stemming from the need for multiple forward passes,\nand degradation of detail due to overly rigid intervention rules. To overcome\nthese challenges, this paper introduces Dynamic Logits Calibration (DLC), a\nnovel training-free decoding framework designed to dynamically align text\ngeneration with visual evidence at inference time. At the decoding phase, DLC\nstep-wise employs CLIP to assess the semantic alignment between the input image\nand the generated text sequence. Then, the Relative Visual Advantage (RVA) of\ncandidate tokens is evaluated against a dynamically updated contextual\nbaseline, adaptively adjusting output logits to favor tokens that are visually\ngrounded. Furthermore, an adaptive weighting mechanism, informed by a real-time\ncontext alignment score, carefully balances the visual guidance while ensuring\nthe overall quality of the textual output. Extensive experiments conducted\nacross diverse benchmarks and various LVLM architectures (such as LLaVA,\nInstructBLIP, and MiniGPT-4) demonstrate that DLC significantly reduces\nhallucinations, outperforming current methods while maintaining high inference\nefficiency by avoiding multiple forward passes. Overall, we present an\neffective and efficient decoding-time solution to mitigate hallucinations,\nthereby enhancing the reliability of LVLMs for more practices. Code will be\nreleased on Github.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21509v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-31", "AI": {"title_translation": "通过动态Logits校准缓解大型视觉-语言模型的幻觉", "tldr": "本文提出了一种名为动态Logits校准（DLC）的免训练解码框架，通过在推理时动态调整输出Logits来缓解大型视觉-语言模型（LVLMs）的幻觉，提高了模型可靠性和推理效率。", "motivation": "大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但经常受到“幻觉”（生成与视觉输入矛盾的文本）的困扰。现有免训练解码策略存在局限性，包括静态约束无法适应生成过程中的语义漂移、需要多次前向传播导致效率低下以及过于僵化的干预规则导致细节丢失。", "method": "本文引入了动态Logits校准（DLC），一个新颖的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步利用CLIP评估输入图像与生成文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出Logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数指导的自适应加权机制，在平衡视觉指导的同时确保文本输出的整体质量。", "result": "在各种基准和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，在保持高推理效率（避免多次前向传播）的同时优于现有方法。", "conclusion": "本文提出了一种有效且高效的解码时解决方案来缓解幻觉，从而增强了LVLMs的可靠性，使其更具实用性。", "translation": "大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但它们经常受到幻觉的困扰——生成与视觉输入相矛盾的文本。现有的免训练解码策略存在关键局限性，包括使用静态约束，无法适应生成过程中的语义漂移；需要多次前向传播导致效率低下；以及过于僵化的干预规则导致细节退化。为了克服这些挑战，本文引入了动态Logits校准（DLC），一个新颖的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步利用CLIP评估输入图像与生成文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出Logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数指导的自适应加权机制，在平衡视觉指导的同时确保文本输出的整体质量。在各种基准和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，在保持高推理效率（避免多次前向传播）的同时优于现有方法。总的来说，我们提出了一种有效且高效的解码时解决方案来缓解幻觉，从而增强了LVLMs的可靠性，使其更具实用性。代码将在Github上发布。", "summary": "大型视觉-语言模型（LVLMs）面临“幻觉”问题。本文提出了一种新颖的免训练解码框架——动态Logits校准（DLC），以在推理时动态地将文本生成与视觉输入对齐。DLC利用CLIP评估语义对齐，并通过相对视觉优势（RVA）和自适应加权机制调整输出Logits，以偏向视觉上接地气的文本。实验证明，DLC显著减少了幻觉，优于现有方法，并保持了高推理效率。", "keywords": "大型视觉-语言模型, 幻觉, 动态Logits校准, 免训练解码, 视觉对齐", "comments": "该论文提出了一种创新的免训练解码框架DLC，有效解决了LVLMs的幻觉问题。其主要创新点在于动态调整Logits，适应生成过程中的语义漂移，并避免了多重前向传播，提高了效率。这对于提升LVLMs在实际应用中的可靠性具有重要意义。"}}
{"id": "2507.22889", "title": "Knowledge Is More Than Performance: How Knowledge Diversity Drives Human-Human and Human-AI Interaction Synergy and Reveals Pure-AI Interaction Shortfalls", "authors": ["Tom Sheffer", "Alon Miron", "Yaniv Dover", "Ariel Goldstein"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22889v1", "summary": "Conversations transform individual knowledge into collective insight,\nallowing groups of humans and increasingly groups of artificial intelligence\n(AI) agents to collaboratively solve complex problems. Whether interactions\nbetween AI agents can replicate the synergy observed in human discussions\nremains an open question. To investigate this, we systematically compared four\nconversational configurations: pairs of large language models (LLM-LLM), trios\nof LLMs, trios of humans, and mixed human-LLM pairs. After agents answered\nquestions individually, they engaged in open-ended discussions and then\nreconsidered their initial answers. Interactions involving humans consistently\nled to accuracy improvements after the conversations, benefiting both stronger\nand weaker participants. By contrast, purely LLM-based pairs and trios\nexhibited declines in accuracy, demonstrating limited conversational synergy.\nAnalysis of participants' confidence and answer-switching behavior revealed\nthat knowledge diversity is a critical factor enabling collaborative\nimprovement. Crucially, the lack of gains in LLM-LLM interactions did not stem\nfrom a fundamental limitation of the models' ability to collaborate, but from\nhighly similar knowledge states that left little room for productive exchange.\nOur findings argue for a paradigm shift in AI development: rather than\noptimizing individual models solely for standalone performance, explicitly\ncultivating diversity across agents, even at the cost of slightly lower\nindividual accuracy, may yield AI collaborators that are more effective in\ngroup settings with humans or other AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22889v1", "cate": "cs.HC", "date": "2025-06-15", "updated": "2025-06-15", "AI": {"title_translation": "知识不仅仅是性能：知识多样性如何驱动人-人与人-AI交互协同并揭示纯AI交互的不足", "tldr": "本研究发现，与人类参与的对话能提高准确性并产生协同效应不同，纯大型语言模型（LLM）的对话在准确性上有所下降，原因在于它们知识状态的高度相似性，缺乏知识多样性是AI协同不足的关键，而非其协作能力本身。", "motivation": "当前，对话能够将个体知识转化为集体洞察，使得人类和AI群体能够协作解决复杂问题。然而，AI智能体之间的交互是否能复制人类讨论中观察到的协同效应仍是一个悬而未决的问题。", "method": "研究系统地比较了四种对话配置：大型语言模型（LLM-LLM）对、LLM三人组、人类三人组以及人-LLM混合对。在参与者单独回答问题后，他们进行开放式讨论，然后重新考虑最初的答案。", "result": "涉及人类的交互在对话后始终能提高准确性，使强者和弱者都受益。相比之下，纯粹基于LLM的配对和三人组在准确性上有所下降，显示出有限的对话协同效应。对参与者信心和答案切换行为的分析表明，知识多样性是实现协作改进的关键因素。LLM-LLM交互未能取得进展并非源于模型协作能力的根本限制，而是由于高度相似的知识状态导致缺乏富有成效的交流空间。", "conclusion": "研究结果认为AI发展需要范式转变：与其仅仅为了独立性能优化单个模型，不如明确地培养智能体之间的多样性，即使以牺牲略低的个体准确性为代价，也可能产生在与人类或其他AI系统进行群体设置中更有效的AI协作器。", "translation": "对话将个体知识转化为集体洞察，使得人类群体以及越来越多的AI智能体群体能够协作解决复杂问题。AI智能体之间的交互是否能够复制人类讨论中观察到的协同效应，仍然是一个悬而未决的问题。为了调查这一点，我们系统地比较了四种对话配置：大型语言模型（LLM-LLM）对、LLM三人组、人类三人组以及人-LLM混合对。在智能体单独回答问题后，它们进行开放式讨论，然后重新考虑最初的答案。涉及人类的交互在对话后始终能提高准确性，使更强和更弱的参与者都受益。相比之下，纯粹基于LLM的配对和三人组在准确性上有所下降，显示出有限的对话协同效应。对参与者信心和答案切换行为的分析表明，知识多样性是实现协作改进的关键因素。重要的是，LLM-LLM交互未能取得进展并非源于模型协作能力的根本限制，而是由于高度相似的知识状态导致缺乏富有成效的交流空间。我们的发现主张AI发展需要范式转变：与其仅仅为了独立性能优化单个模型，不如明确地培养智能体之间的多样性，即使以牺牲略低的个体准确性为代价，也可能产生在与人类或其他AI系统进行群体设置中更有效的AI协作器。", "summary": "本研究探讨了人类、大型语言模型（LLM）以及人机混合群体在对话中实现协同效应的能力。通过对比人-人、人-AI和纯AI（LLM-LLM）对话配置，发现涉及人类的交互能显著提高问题解决的准确性，而纯LLM交互则表现出准确性下降。研究指出，这种差异并非源于LLM缺乏协作能力，而是由于其知识状态的高度同质性，缺乏多样性限制了有效交流。因此，论文提出AI发展应从仅优化个体性能转向培养智能体间的知识多样性，以提高AI在群体协作中的表现。", "keywords": "知识多样性, 人机交互, LLM协作, 对话协同, AI发展", "comments": "这项研究具有重要的创新性，它挑战了AI模型开发的传统范式，即只关注个体性能的优化。通过强调“知识多样性”而非单纯的“性能”在协同交互中的关键作用，为未来AI协作系统的设计提供了新的视角。其重要性在于揭示了当前LLM在纯AI协作中的局限性，并提出了一个可行的改进方向，即通过引入多样性来增强AI的集体智能。这对于开发更有效的人机协作系统以及多AI智能体系统具有深远影响。"}}
{"id": "2507.23292", "title": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "authors": ["RJ Skerry-Ryan", "Julian Salazar", "Soroosh Mariooryad", "David Kao", "Daisy Stanton", "Eric Battenberg", "Matt Shannon", "Ron J. Weiss", "Robin Scheibler", "Jonas Rothfuss", "Tom Bagby"], "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23292v1", "summary": "We introduce a neural network layer API and library for sequence modeling,\ndesigned for easy creation of sequence models that can be executed both\nlayer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,\nautoregressive sampling). To achieve this, layers define an explicit\nrepresentation of their state over time (e.g., a Transformer KV cache, a\nconvolution buffer, an RNN hidden state), and a step method that evolves that\nstate, tested to give identical results to a stateless layer-wise invocation.\nThis and other aspects of the SequenceLayers contract enables complex models to\nbe immediately streamable, mitigates a wide range of common bugs arising in\nboth streaming and parallel sequence processing, and can be implemented in any\ndeep learning library. A composable and declarative API, along with a\ncomprehensive suite of layers and combinators, streamlines the construction of\nproduction-scale models from simple streamable components while preserving\nstrong correctness guarantees. Our current implementations of SequenceLayers\n(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23292v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SequenceLayers：序列处理和流式神经网络变得简单", "tldr": "引入SequenceLayers，一个用于序列建模的神经网络层API和库，旨在简化流式和并行序列处理，并通过明确的状态表示和步进方法确保了正确性。", "motivation": "现有序列模型在层级（如教师强制训练）和步进（如自回归采样）执行之间切换困难，且易产生流式和并行处理中的常见错误。", "method": "SequenceLayers通过定义层的显式时间状态（如Transformer KV缓存、卷积缓冲区、RNN隐藏状态）以及一个演进该状态的“步进”方法来实现。该方法经过测试，与无状态层级调用结果一致。其API是可组合和声明性的，并提供一套全面的层和组合器。", "result": "使复杂模型能够立即流式传输，减轻了流式和并行序列处理中常见的广泛错误，能够以简单可流式组件构建生产规模模型，同时保持强大的正确性保证。", "conclusion": "SequenceLayers提供了一个通用的解决方案，简化了序列模型在不同执行模式下的构建和部署，并已在JAX和TensorFlow 2中实现并开源。", "translation": "我们引入了一个用于序列建模的神经网络层API和库，旨在轻松创建可以按层（例如，教师强制训练）和按步（例如，自回归采样）执行的序列模型。为了实现这一点，层定义了其随时间状态的显式表示（例如，Transformer KV缓存、卷积缓冲区、RNN隐藏状态），以及一个演进该状态的步进方法，该方法经过测试，与无状态的逐层调用结果相同。SequenceLayers契约的这一方面和其他方面使复杂模型能够立即流式传输，减轻了流式和并行序列处理中出现的各种常见错误，并且可以在任何深度学习库中实现。一个可组合和声明式的API，以及一套全面的层和组合器，简化了从简单可流式组件构建生产规模模型的过程，同时保留了强大的正确性保证。我们目前SequenceLayers的实现（JAX、TensorFlow 2）可在https://github.com/google/sequence-layers 获取。", "summary": "SequenceLayers是一个新的神经网络层API和库，专为简化序列建模而设计。它通过引入层状态的显式表示和步进方法，使得模型能够在层级和步进两种模式下无缝执行，并确保结果一致。该框架使得复杂模型易于流式处理，减少了常见错误，并支持使用可组合组件构建生产级模型，同时保证了高正确性。", "keywords": "序列建模, 神经网络层, 流式处理, 自回归, 状态管理", "comments": "SequenceLayers的创新之处在于其对神经网络层状态的显式管理和“步进”方法的引入，这有效地解决了在序列模型中进行教师强制训练和自回归采样之间的切换难题，并提高了流式和并行处理的鲁棒性。其抽象层设计使得模型更易于开发和部署，且具备跨深度学习库的潜力，对于生产环境中的序列模型开发具有重要意义。"}}
{"id": "2507.23669", "title": "Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database", "authors": ["Diego Russo", "Gian Marco Orlando", "Valerio La Gatta", "Vincenzo Moscato"], "categories": ["cs.CY", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted at the 28th European Conference on Artificial Intelligence (ECAI 2025)", "url": "http://arxiv.org/abs/2507.23669v1", "summary": "Artificial Intelligence (AI) systems are transforming critical sectors such\nas healthcare, finance, and transportation, enhancing operational efficiency\nand decision-making processes. However, their deployment in high-stakes domains\nhas exposed vulnerabilities that can result in significant societal harm. To\nsystematically study and mitigate these risk, initiatives like the AI Incident\nDatabase (AIID) have emerged, cataloging over 3,000 real-world AI failure\nreports. Currently, associating a new report with the appropriate AI Incident\nrelies on manual expert intervention, limiting scalability and delaying the\nidentification of emerging failure patterns.\n  To address this limitation, we propose a retrieval-based framework that\nautomates the association of new reports with existing AI Incidents through\nsemantic similarity modeling. We formalize the task as a ranking problem, where\neach report-comprising a title and a full textual description-is compared to\npreviously documented AI Incidents based on embedding cosine similarity.\nBenchmarking traditional lexical methods, cross-encoder architectures, and\ntransformer-based sentence embedding models, we find that the latter\nconsistently achieve superior performance. Our analysis further shows that\ncombining titles and descriptions yields substantial improvements in ranking\naccuracy compared to using titles alone. Moreover, retrieval performance\nremains stable across variations in description length, highlighting the\nrobustness of the framework. Finally, we find that retrieval performance\nconsistently improves as the training set expands. Our approach provides a\nscalable and efficient solution for supporting the maintenance of the AIID.", "comment": "Accepted at the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23669v1", "cate": "cs.CY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "自动化AI故障跟踪：AI事件数据库中报告的语义关联", "tldr": "本文提出一个基于检索的框架，通过语义相似性建模自动化将新的AI故障报告与现有AI事件关联起来，以提高AI事件数据库的可扩展性和效率。", "motivation": "AI系统在关键领域部署时暴露的漏洞可能导致严重的社会危害。为了系统研究和缓解这些风险，AI事件数据库（AIID）等倡议应运而生，但将新报告与现有AI事件关联目前依赖手动专家干预，这限制了可扩展性并延迟了新故障模式的识别。", "method": "提出一个基于检索的框架，通过语义相似性建模自动化关联新报告与现有AI事件。将任务形式化为排序问题，通过嵌入余弦相似性比较报告（包含标题和文本描述）与现有AI事件。基准测试了传统词汇方法、交叉编码器架构和基于Transformer的句子嵌入模型。", "result": "基于Transformer的句子嵌入模型表现优于其他方法。结合标题和描述比单独使用标题能显著提高排序准确性。检索性能在描述长度变化时保持稳定。训练集扩大时，检索性能持续提升。", "conclusion": "该方法为支持AI事件数据库的维护提供了一个可扩展且高效的解决方案。", "translation": "人工智能（AI）系统正在改变医疗、金融和交通等关键领域，提升运营效率和决策过程。然而，它们在高风险领域的部署暴露了可能导致严重社会危害的漏洞。为了系统地研究和缓解这些风险，AI事件数据库（AIID）等倡议应运而生，收录了3000多份真实世界的AI故障报告。目前，将新报告与适当的AI事件关联依赖于人工专家干预，这限制了可扩展性并延迟了新故障模式的识别。\n为了解决这一限制，我们提出了一个基于检索的框架，通过语义相似性建模自动化将新报告与现有AI事件关联。我们将该任务形式化为一个排序问题，其中每份报告——包含标题和完整的文本描述——都根据嵌入余弦相似性与先前记录的AI事件进行比较。通过对传统词汇方法、交叉编码器架构和基于Transformer的句子嵌入模型进行基准测试，我们发现后者始终能取得卓越的性能。我们的分析进一步表明，与单独使用标题相比，结合标题和描述能显著提高排序准确性。此外，检索性能在描述长度变化时保持稳定，突出了该框架的鲁棒性。最后，我们发现随着训练集的扩展，检索性能持续提高。我们的方法为支持AIID的维护提供了一个可扩展且高效的解决方案。", "summary": "本文提出一个基于检索的框架，旨在自动化AI事件数据库中新故障报告与现有事件的关联过程。通过将报告匹配任务形式化为排序问题，并利用基于Transformer的句子嵌入模型进行语义相似性比较，该框架显著提高了报告关联的准确性和效率。研究结果表明，结合标题和描述能提升性能，且模型对描述长度变化具有鲁棒性，同时性能随训练数据增加而提升，为AIID的维护提供了可扩展的解决方案。", "keywords": "AI故障跟踪, 语义关联, AI事件数据库, 检索框架, Transformer", "comments": "该论文提出了一种自动化AI故障报告关联的方法，解决了AI事件数据库（AIID）中报告手动关联的效率和可扩展性问题。其创新点在于将语义相似性建模应用于此领域，并通过实验验证了基于Transformer的句子嵌入模型在该任务上的优越性。这项工作对于AI故障模式的快速识别和风险缓解具有重要意义，尤其是在AI系统日益普及的关键领域。"}}
{"id": "2505.05003", "title": "Experimental Study on Reference-Path-Aided System Calibration for mmWave Bistatic ISAC Systems", "authors": ["Chenhao Luo", "Chongrui Wang", "Aimin Tang", "Fei Gao", "Chaojun Xu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures. Accepted by IEEE GLOBECOM 2025", "url": "http://arxiv.org/abs/2505.05003v2", "summary": "Integrated sensing and communications (ISAC) has been regarded as a key\nenabling technology for next-generation wireless networks. Compared to\nmonostatic ISAC, bistatic ISAC can eliminate the critical challenge of\nself-interference cancellation and is well compatible with the existing network\ninfrastructures. However, the synchronization between the transmitter and the\nsensing receiver becomes a crucial problem. The extracted channel state\ninformation (CSI) for sensing under communication synchronization contains\ndifferent types of system errors, such as the sampling time offset (STO),\ncarrier frequency offset (CFO), and random phase shift, which can severely\ndegrade sensing performance or even render sensing infeasible. To address this\nproblem, a reference-path-aided system calibration scheme is designed for\nmmWave bistatic ISAC systems, where the line-of-sight (LoS) path can be\nblocked. By exploiting the delay-angle sparsity feature in mmWave ISAC systems,\nthe reference path, which can be either a LoS or a non-LoS (NLoS) path, is\nfirst identified. By leveraging the fact that all the paths suffer the same\nsystem errors, the channel parameter extracted from the reference path is\nutilized to compensate for the system errors in all other paths. A mmWave ISAC\nsystem is developed to validate our design. Experimental results demonstrate\nthat the proposed scheme can support precise estimation of Doppler shift and\ndelay, maintaining time-synchronization errors within 1 nanosecond.", "comment": "6 pages, 8 figures. Accepted by IEEE GLOBECOM 2025", "pdf_url": "http://arxiv.org/pdf/2505.05003v2", "cate": "eess.SP", "date": "2025-05-08", "updated": "2025-07-31", "AI": {"title_translation": "毫米波双基地ISAC系统参考路径辅助系统校准的实验研究", "tldr": "针对毫米波双基地ISAC系统中同步误差导致感知性能下降的问题，提出了一种参考路径辅助系统校准方案，并通过实验验证了其能实现精确的多普勒频移和时延估计。", "motivation": "毫米波双基地ISAC系统中，发射机和感知接收机之间的同步是一个关键问题。提取的信道状态信息（CSI）包含采样时间偏移（STO）、载波频率偏移（CFO）和随机相移等系统误差，这些误差会严重降低感知性能甚至使感知不可行。", "method": "本文设计了一种参考路径辅助系统校准方案，适用于视距（LoS）路径可能被阻挡的情况。该方案利用毫米波ISAC系统中时延-角度稀疏性特征，首先识别出参考路径（可以是LoS或非LoS路径）。然后，通过利用所有路径都受到相同系统误差的事实，将从参考路径中提取的信道参数用于补偿所有其他路径中的系统误差。", "result": "实验结果表明，所提出的方案能够支持多普勒频移和时延的精确估计，并将时间同步误差保持在1纳秒以内。", "conclusion": "所提出的参考路径辅助系统校准方案能够有效解决毫米波双基地ISAC系统中的同步误差问题，实现高精度的感知性能。", "translation": "集成传感与通信（ISAC）已被认为是下一代无线网络的关键使能技术。与单基地ISAC相比，双基地ISAC可以消除自干扰消除这一关键挑战，并与现有网络基础设施良好兼容。然而，发射机和感知接收机之间的同步成为一个关键问题。在通信同步下提取的用于感知的信道状态信息（CSI）包含不同类型的系统误差，例如采样时间偏移（STO）、载波频率偏移（CFO）和随机相移，这些误差会严重降低感知性能甚至使感知不可行。为了解决这个问题，本文为毫米波双基地ISAC系统设计了一种参考路径辅助系统校准方案，其中视距（LoS）路径可能被阻挡。通过利用毫米波ISAC系统中的时延-角度稀疏性特征，首先识别出参考路径，该路径可以是LoS或非视距（NLoS）路径。通过利用所有路径都受到相同系统误差的事实，将从参考路径中提取的信道参数用于补偿所有其他路径中的系统误差。本文开发了一个毫米波ISAC系统来验证我们的设计。实验结果表明，所提出的方案能够支持多普勒频移和时延的精确估计，并将时间同步误差保持在1纳秒以内。", "summary": "本文针对毫米波双基地ISAC系统中发射机与感知接收机之间的同步误差问题，提出了一种参考路径辅助系统校准方案。该方案利用毫米波ISAC系统的时延-角度稀疏性识别参考路径，并利用其提取的信道参数补偿所有其他路径的系统误差。实验结果验证了该方案能实现精确的多普勒频移和时延估计，并将时间同步误差控制在1纳秒内。", "keywords": "毫米波, 双基地ISAC, 系统校准, 参考路径, 同步误差", "comments": "该论文提出了一种创新的参考路径辅助校准方案，有效解决了毫米波双基地ISAC系统中关键的同步误差问题。其亮点在于利用了毫米波的稀疏性特性，并能处理LoS路径被阻挡的情况，这增加了方案的实用性。实验验证结果表明了其在精度和同步误差控制方面的有效性，对提升ISAC系统的感知性能具有重要意义。"}}
{"id": "2501.16325", "title": "Tailored Forecasting from Short Time Series via Meta-learning", "authors": ["Declan A. Norton", "Edward Ott", "Andrew Pomerance", "Brian Hunt", "Michelle Girvan"], "categories": ["cs.LG", "nlin.CD", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 12 figures", "url": "http://arxiv.org/abs/2501.16325v2", "summary": "Machine learning models can effectively forecast dynamical systems from\ntime-series data, but they typically require large amounts of past data, making\nforecasting particularly challenging for systems with limited history. To\novercome this, we introduce Meta-learning for Tailored Forecasting using\nRelated Time Series (METAFORS), which generalizes knowledge across systems to\nenable forecasting in data-limited scenarios. By learning from a library of\nmodels trained on longer time series from potentially related systems, METAFORS\nbuilds and initializes a model tailored to short time-series data from the\nsystem of interest. Using a reservoir computing implementation and testing on\nsimulated chaotic systems, we demonstrate that METAFORS can reliably predict\nboth short-term dynamics and long-term statistics without requiring contextual\nlabels. We see this even when test and related systems exhibit substantially\ndifferent behaviors, highlighting METAFORS' strengths in data-limited\nscenarios.", "comment": "23 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2501.16325v2", "cate": "cs.LG", "date": "2025-01-27", "updated": "2025-07-31", "AI": {"title_translation": "通过元学习对短时间序列进行量身定制的预测", "tldr": "METAFORS利用元学习从相关长序列数据中获取知识，实现对数据有限的短时间序列的有效预测。", "motivation": "机器学习模型在时间序列预测中通常需要大量历史数据，这使得对历史有限的系统进行预测变得非常困难。", "method": "本文引入了名为METAFORS（Meta-learning for Tailored Forecasting using Related Time Series）的方法。该方法通过从一个模型库中学习，这些模型是在来自潜在相关系统的较长时间序列上训练的。METAFORS利用这些知识构建并初始化一个专门针对目标系统短时间序列数据的模型。具体实现使用了储层计算（reservoir computing）。", "result": "METAFORS能够可靠地预测模拟混沌系统的短期动态和长期统计数据，且无需上下文标签。即使测试系统与相关系统表现出显著不同的行为，该方法也表现出有效性。", "conclusion": "METAFORS在数据有限的场景下，通过元学习泛化知识，能够有效地对短时间序列进行量身定制的预测，即使系统行为差异较大也能保持鲁棒性。", "translation": "机器学习模型可以有效地从时间序列数据中预测动力系统，但它们通常需要大量的历史数据，这使得对历史有限的系统进行预测特别具有挑战性。为了克服这个问题，我们引入了使用相关时间序列进行量身定制预测的元学习（METAFORS），它泛化了跨系统的知识，从而在数据有限的场景中实现预测。通过从在来自潜在相关系统的较长时间序列上训练的模型库中学习，METAFORS构建并初始化了一个针对感兴趣系统短时间序列数据量身定制的模型。通过储层计算实现并在模拟混沌系统上进行测试，我们证明了METAFORS可以可靠地预测短期动态和长期统计数据，而无需上下文标签。即使测试系统和相关系统表现出显著不同的行为，我们也看到了这一点，这突出了METAFORS在数据有限场景中的优势。", "summary": "本文提出了一种名为METAFORS的元学习框架，旨在解决机器学习模型在短时间序列数据上进行预测时面临的数据量不足问题。METAFORS通过从相关系统的长序列数据中学习并泛化知识，为目标系统的短序列数据构建定制模型。实验在模拟混沌系统上进行，结果表明METAFORS无需上下文标签即可有效预测短期动态和长期统计数据，即使在测试系统与学习源系统行为差异较大时也能保持鲁棒性，突显其在数据受限环境下的优势。", "keywords": "元学习, 短时间序列, 预测, 储层计算, 数据有限", "comments": "这篇论文的创新点在于提出了一个元学习框架METAFORS，专门用于解决短时间序列预测中数据稀缺的挑战。其重要性在于，通过利用来自相关系统的知识，该方法能够有效地在数据受限的情况下进行预测，这对于许多实际应用（如新兴系统或数据采集成本高昂的领域）具有重要意义。特别值得注意的是，该方法在测试系统与相关系统行为差异较大时仍表现出良好的性能，这增强了其泛化能力和实用性。"}}
{"id": "2507.13373", "title": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection", "authors": ["Xiaojian Lin", "Wenxin Zhang", "Yuchu Jiang", "Wangyu Wu", "Yiran Guo", "Kangxu Wang", "Zongzheng Zhang", "Guijin Wang", "Lei Jin", "Hao Zhao"], "categories": ["cs.CV", "I.4.8; I.2.10; H.5.1; I.2.6"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures. Supplementary material: 8 pages, 7 figures. Accepted at ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.13373v2", "summary": "Hierarchical feature representations play a pivotal role in computer vision,\nparticularly in object detection for autonomous driving. Multi-level semantic\nunderstanding is crucial for accurately identifying pedestrians, vehicles, and\ntraffic signs in dynamic environments. However, existing architectures, such as\nYOLO and DETR, struggle to maintain feature consistency across different scales\nwhile balancing detection precision and computational efficiency. To address\nthese challenges, we propose Butter, a novel object detection framework\ndesigned to enhance hierarchical feature representations for improving\ndetection robustness. Specifically, Butter introduces two key innovations:\nFrequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which\nrefines multi-scale feature consistency by leveraging adaptive frequency\nfiltering to enhance structural and boundary precision, and Progressive\nHierarchical Feature Fusion Network (PHFFNet) Module, which progressively\nintegrates multi-level features to mitigate semantic gaps and strengthen\nhierarchical feature learning. Through extensive experiments on BDD100K, KITTI,\nand Cityscapes, Butter demonstrates superior feature representation\ncapabilities, leading to notable improvements in detection accuracy while\nreducing model complexity. By focusing on hierarchical feature refinement and\nintegration, Butter provides an advanced approach to object detection that\nachieves a balance between accuracy, deployability, and computational\nefficiency in real-time autonomous driving scenarios. Our model and\nimplementation are publicly available at https://github.com/Aveiro-Lin/Butter,\nfacilitating further research and validation within the autonomous driving\ncommunity.", "comment": "10 pages, 6 figures. Supplementary material: 8 pages, 7 figures.\n  Accepted at ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.13373v2", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-31", "AI": {"title_translation": "Butter：自动驾驶目标检测中的频率一致性与分层融合", "tldr": "Butter是一种新的目标检测框架，通过频率一致性增强和分层融合，提高了自动驾驶中目标检测的准确性和效率。", "motivation": "现有自动驾驶目标检测架构（如YOLO和DETR）在不同尺度下难以保持特征一致性，且难以平衡检测精度和计算效率，而多级语义理解对准确识别动态环境中的目标至关重要。", "method": "本文提出了名为Butter的新型目标检测框架，旨在增强分层特征表示以提高检测鲁棒性。它引入了两项关键创新：频率自适应特征一致性增强（FAFCE）组件，通过自适应频率滤波细化多尺度特征一致性，提高结构和边界精度；以及渐进式分层特征融合网络（PHFFNet）模块，逐步整合多级特征以弥合语义鸿沟并强化分层特征学习。", "result": "在BDD100K、KITTI和Cityscapes数据集上进行的大量实验表明，Butter展示出卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂度。它在实时自动驾驶场景中成功实现了精度、部署性和计算效率之间的平衡。", "conclusion": "Butter通过专注于分层特征的细化和整合，为自动驾驶中的目标检测提供了一种先进的方法，成功平衡了准确性、可部署性和计算效率。", "translation": "分层特征表示在计算机视觉中，尤其是在自动驾驶目标检测中，扮演着关键角色。多级语义理解对于在动态环境中准确识别行人、车辆和交通标志至关重要。然而，现有的架构，如YOLO和DETR，在平衡检测精度和计算效率的同时，难以在不同尺度上保持特征一致性。为了解决这些挑战，我们提出了Butter，一个旨在增强分层特征表示以提高检测鲁棒性的新型目标检测框架。具体而言，Butter引入了两项关键创新：频率自适应特征一致性增强（FAFCE）组件，它通过利用自适应频率滤波来细化多尺度特征一致性，从而增强结构和边界精度；以及渐进式分层特征融合网络（PHFFNet）模块，它逐步整合多级特征以弥合语义鸿沟并加强分层特征学习。通过在BDD100K、KITTI和Cityscapes上的大量实验，Butter展示了卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂度。通过专注于分层特征的细化和整合，Butter提供了一种先进的目标检测方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的平衡。我们的模型和实现已在https://github.com/Aveiro-Lin/Butter上公开发布，以促进自动驾驶社区的进一步研究和验证。", "summary": "本文提出了Butter，一个专为自动驾驶目标检测设计的新型框架，旨在解决现有方法在多尺度特征一致性和效率方面的挑战。Butter通过引入频率自适应特征一致性增强（FAFCE）组件和渐进式分层特征融合网络（PHFFNet）模块，有效地细化了多尺度特征一致性并整合了多级特征。实验证明，Butter在检测精度、模型复杂度和实时部署效率之间取得了显著平衡，为自动驾驶目标检测提供了先进的解决方案。", "keywords": "自动驾驶, 目标检测, 分层特征, 频率一致性, 特征融合", "comments": "Butter的创新之处在于其对分层特征表示的精细化处理，特别是引入频率域的考量来增强特征一致性，以及渐进式融合策略来弥合语义鸿沟。这为解决自动驾驶中多尺度目标检测的鲁棒性和效率问题提供了有效途径，其开源实现也有利于社区的进一步研究和应用。"}}
{"id": "2504.06684", "title": "SDHN: Skewness-Driven Hypergraph Networks for Enhanced Localized Multi-Robot Coordination", "authors": ["Delin Zhao", "Yanbo Shan", "Chang Liu", "Shenghang Lin", "Yingxin Shou", "Bin Xu"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.06684v2", "summary": "Multi-Agent Reinforcement Learning is widely used for multi-robot\ncoordination, where simple graphs typically model pairwise interactions.\nHowever, such representations fail to capture higher-order collaborations,\nlimiting effectiveness in complex tasks. While hypergraph-based approaches\nenhance cooperation, existing methods often generate arbitrary hypergraph\nstructures and lack adaptability to environmental uncertainties. To address\nthese challenges, we propose the Skewness-Driven Hypergraph Network (SDHN),\nwhich employs stochastic Bernoulli hyperedges to explicitly model higher-order\nmulti-robot interactions. By introducing a skewness loss, SDHN promotes an\nefficient structure with Small-Hyperedge Dominant Hypergraph, allowing robots\nto prioritize localized synchronization while still adhering to the overall\ninformation, similar to human coordination. Extensive experiments on Moving\nAgents in Formation and Robotic Warehouse tasks validate SDHN's effectiveness,\ndemonstrating superior performance over state-of-the-art baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.06684v2", "cate": "cs.RO", "date": "2025-04-09", "updated": "2025-07-31", "AI": {"title_translation": "SDHN：偏度驱动超图网络用于增强局部多机器人协调", "tldr": "提出SDHN，一种偏度驱动的超图网络，通过随机伯努利超边和偏度损失来有效建模高阶多机器人交互，实现局部同步并优于现有方法。", "motivation": "现有图模型无法捕获高阶协作，限制了多机器人协调在复杂任务中的有效性；现有超图方法生成任意结构且缺乏环境适应性。", "method": "提出偏度驱动超图网络（SDHN），采用随机伯努利超边显式建模高阶多机器人交互，并引入偏度损失以促进小超边主导的超图结构，使机器人能优先进行局部同步。", "result": "在“编队移动智能体”和“机器人仓库”任务中，SDHN表现出优于现有SOTA基线的性能。", "conclusion": "SDHN通过有效建模高阶交互和促进局部同步，显著提升了多机器人协调的性能和适应性。", "translation": "多智能体强化学习广泛应用于多机器人协调，其中简单的图通常建模成对交互。然而，这种表示未能捕获高阶协作，限制了在复杂任务中的有效性。虽然基于超图的方法增强了协作，但现有方法通常生成任意的超图结构，并且缺乏对环境不确定性的适应性。为了解决这些挑战，我们提出了偏度驱动超图网络（SDHN），它采用随机伯努利超边来显式建模高阶多机器人交互。通过引入偏度损失，SDHN促进了一种高效的小超边主导超图结构，允许机器人在仍然遵循整体信息的同时优先进行局部同步，类似于人类协调。在“编队移动智能体”和“机器人仓库”任务上的大量实验验证了SDHN的有效性，证明其性能优于最先进的基线。", "summary": "本文提出了偏度驱动超图网络（SDHN），旨在解决多机器人协调中现有图模型无法捕获高阶协作以及现有超图方法缺乏适应性的问题。SDHN利用随机伯努利超边建模高阶交互，并通过偏度损失生成小超边主导的超图结构，使机器人能够优先进行局部同步。实验证明，SDHN在多机器人协调任务中表现出优于现有方法的性能。", "keywords": "多机器人协调, 超图网络, 偏度损失, 高阶交互, 多智能体强化学习", "comments": "该论文的创新点在于提出了偏度驱动的超图网络，通过引入随机伯努利超边和偏度损失，有效解决了现有方法在高阶协作建模和环境适应性方面的不足，实现了更类似于人类协调的局部同步机制，对于复杂多机器人协调任务具有重要意义。"}}
{"id": "2406.17552", "title": "Long-Time and Short-Time Dynamics in a Weighted-Median Opinion Model on Networks", "authors": ["Lasse Mohr", "Poul G. Hjorth", "Mason A. Porter"], "categories": ["physics.soc-ph", "cs.SI", "math.DS", "nlin.AO"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      30 pages, 13 figures, Submitted to SIAM Journal on Applied Dynamical Systems. Version 2 of this manuscript had a mistake in the arxiv title. The manuscript, figure, and appendix of this version is identical to version 2; the only change is the arxiv title which has been changed to align with the title of the manuscript", "url": "http://arxiv.org/abs/2406.17552v3", "summary": "Social interactions influence people's opinions. In some situations, these\ninteractions eventually yield a consensus opinion; in others, they can lead to\nopinion fragmentation and the formation of different opinion groups in the form\nof ``echo chambers''. Consider a social network of individuals with\ncontinuous-valued scalar opinions, and suppose that they can change their\nopinions when they interact with each other. In many models of the opinion\ndynamics of individuals in a network, it is common for opinion updates to\ndepend on the mean opinion of interacting individuals. As an alternative, which\nmay be more realistic in some situations, we study an opinion model with an\nopinion-update rule that depends on the weighted median of the opinions of\ninteracting individuals. Through numerical simulations of our median-update\nopinion model, we investigate how the final opinion distribution depends on\nnetwork structure. For configuration-model networks, we also derive a\nmean-field approximation for the asymptotic dynamics of the opinion\ndistribution when there are infinitely many individuals. We numerically\ninvestigate its accuracy for short-time opinion dynamics on various networks.", "comment": "30 pages, 13 figures, Submitted to SIAM Journal on Applied Dynamical\n  Systems. Version 2 of this manuscript had a mistake in the arxiv title. The\n  manuscript, figure, and appendix of this version is identical to version 2;\n  the only change is the arxiv title which has been changed to align with the\n  title of the manuscript", "pdf_url": "http://arxiv.org/pdf/2406.17552v3", "cate": "physics.soc-ph", "date": "2024-06-25", "updated": "2025-07-31", "AI": {"title_translation": "网络中加权中值意见模型中的长时间和短时间动力学", "tldr": "本文研究了网络中基于加权中值更新规则的意见动力学模型，通过数值模拟和平均场近似分析了最终意见分布如何受网络结构影响，并验证了近似在短时间动力学中的准确性。", "motivation": "社会互动会影响人们的意见，有时导致共识，有时导致意见碎片化形成“回音室”。许多意见动力学模型依赖于交互个体的平均意见，但本研究提出并探讨了一种基于加权中值意见更新规则的模型，认为这在某些情况下可能更符合现实。", "method": "1. 通过数值模拟研究了基于加权中值更新规则的意见模型，以探究最终意见分布如何依赖于网络结构。2. 对于配置模型网络，推导了无限多个体情况下意见分布渐近动力学的平均场近似。3. 数值验证了该近似在各种网络中对短时间意见动力学的准确性。", "result": "1. 最终意见分布取决于网络结构。2. 平均场近似在短时间意见动力学中的准确性得到了数值验证。", "conclusion": "本研究表明，在基于加权中值更新规则的意见模型中，最终意见分布受网络结构影响。同时，所推导的平均场近似能够有效地描述短时间意见动力学。", "translation": "社会互动影响人们的意见。在某些情况下，这些互动最终会产生共识；在另一些情况下，它们会导致意见碎片化并形成“回音室”形式的不同意见群体。考虑一个由具有连续值标量意见的个体组成的社交网络，并假设他们在相互作用时可以改变自己的意见。在许多网络中个体意见动力学模型中，意见更新通常取决于交互个体的平均意见。作为一种替代方案，这在某些情况下可能更现实，我们研究了一种意见模型，其意见更新规则取决于交互个体意见的加权中值。通过我们的中值更新意见模型的数值模拟，我们调查了最终意见分布如何依赖于网络结构。对于配置模型网络，我们还推导了当个体数量无限多时意见分布渐近动力学的平均场近似。我们数值调查了其在各种网络中对短时间意见动力学的准确性。", "summary": "本研究提出并分析了一种新颖的意见动力学模型，该模型采用基于加权中值而非传统平均值的意见更新规则，以期更真实地模拟社交网络中的意见演化。通过数值模拟，论文探讨了最终意见分布与网络结构之间的关系。此外，研究还为配置模型网络推导了渐近动力学的平均场近似，并数值验证了该近似在短时间意见动力学中的有效性。", "keywords": "意见动力学, 社交网络, 加权中值, 平均场近似, 网络结构", "comments": "本文的创新之处在于引入了加权中值作为意见更新规则，这与传统的均值更新不同，可能更贴近现实中的某些社会交互场景。研究结合了数值模拟和理论推导（平均场近似），为理解网络结构对意见动力学的影响提供了新的视角和分析工具。其重要性在于为意见动力学研究提供了新的建模思路和分析方法。"}}
{"id": "2507.22940", "title": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes", "authors": ["Rui Jiao", "Yue Zhang", "Jinku Li"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22940v1", "summary": "We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy\nfor Confidence Enhancement), a novel framework addressing a critical\nvulnerability in Large Language Models (LLMs): the prevalence of factual\ninaccuracies within intermediate reasoning steps despite correct final answers.\nThis phenomenon poses substantial risks in high-stakes domains including\nhealthcare, legal analysis, and scientific research, where erroneous yet\nconfidently presented reasoning can mislead users into dangerous decisions. Our\nframework integrates three core components: (1) a specialized fact-checking\nclassifier trained on counterfactually augmented data to detect subtle factual\ninconsistencies within reasoning chains; (2) a Group Relative Policy\nOptimization (GRPO) reinforcement learning approach that balances factuality,\ncoherence, and structural correctness through multi-dimensional rewards; and\n(3) a mechanistic interpretability module examining how factuality improvements\nmanifest in model activations during reasoning processes. Extensive evaluation\nacross ten state-of-the-art models reveals concerning patterns: even leading\nmodels like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of\nonly 81.93% and 82.57% respectively. RELIANCE significantly enhances factual\nrobustness (up to 49.90% improvement) while maintaining or improving\nperformance on challenging benchmarks including Math-500, AIME-2024, and GPQA.\nFurthermore, our activation-level analysis provides actionable insights into\nhow factual enhancements reshape reasoning trajectories within model\narchitectures, establishing foundations for future training methodologies that\nexplicitly target factual robustness through activation-guided optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22940v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "可信推理：评估和增强LLM中间思维过程中的事实准确性", "tldr": "RELIANCE框架旨在解决大型语言模型在中间推理步骤中存在的事实不准确问题，通过事实核查、强化学习和机制可解释性显著提高了LLM的事实鲁棒性。", "motivation": "大型语言模型（LLMs）即使最终答案正确，其中间推理步骤也常出现事实不准确性。这种现象在高风险领域（如医疗、法律和科学研究）构成重大风险，因为错误但自信的推理可能误导用户做出危险决策。", "method": "RELIANCE框架包含三个核心组件：1) 一个专门的事实核查分类器，通过反事实增强数据训练，用于检测推理链中细微的事实不一致；2) 一种组相对策略优化（GRPO）强化学习方法，通过多维度奖励平衡事实性、连贯性和结构正确性；3) 一个机制可解释性模块，用于检查事实性改进如何在推理过程中体现在模型激活中。", "result": "对十个最先进模型的广泛评估显示，即使是领先模型如Claude-3.7和GPT-o1的推理事实准确率也仅为81.93%和82.57%。RELIANCE显著增强了事实鲁棒性（最高提升49.90%），同时在Math-500、AIME-2024和GPQA等挑战性基准测试中保持或提高了性能。此外，激活层面的分析为事实性增强如何重塑模型架构内的推理轨迹提供了可操作的见解。", "conclusion": "RELIANCE框架通过结合事实核查、强化学习和机制可解释性，有效解决了LLM中间推理过程中的事实不准确性问题，显著提升了模型的鲁棒性，并为未来通过激活引导优化来增强事实鲁棒性的训练方法奠定了基础。", "translation": "我们提出了RELIANCE（推理评估与逻辑完整性及准确性增强置信度），一个新颖的框架，旨在解决大型语言模型（LLMs）中的一个关键漏洞：尽管最终答案正确，但中间推理步骤中普遍存在事实不准确性。这种现象在高风险领域，包括医疗保健、法律分析和科学研究，构成了实质性风险，因为错误但自信呈现的推理可能误导用户做出危险的决策。我们的框架整合了三个核心组件：(1) 一个专门的事实核查分类器，通过反事实增强数据训练，用于检测推理链中细微的事实不一致；(2) 一种组相对策略优化（GRPO）强化学习方法，通过多维度奖励平衡事实性、连贯性和结构正确性；(3) 一个机制可解释性模块，用于检查事实性改进如何在推理过程中体现在模型激活中。对十个最先进模型的广泛评估揭示了令人担忧的模式：即使是领先模型如Claude-3.7和GPT-o1的推理事实准确率也分别仅为81.93%和82.57%。RELIANCE显著增强了事实鲁棒性（最高提升49.90%），同时在Math-500、AIME-2024和GPQA等挑战性基准测试中保持或提高了性能。此外，我们的激活层面分析为事实性增强如何重塑模型架构内的推理轨迹提供了可操作的见解，为未来通过激活引导优化明确针对事实鲁棒性的训练方法奠定了基础。", "summary": "本论文提出了RELIANCE框架，旨在解决大型语言模型（LLMs）中间推理步骤中的事实不准确问题。RELIANCE整合了事实核查分类器、基于GRPO的强化学习以及机制可解释性模块。实验结果表明，即使是顶尖LLMs也存在显著的事实准确性问题，而RELIANCE能显著提升模型的事实鲁棒性，并在多个基准测试中保持或提升性能。其激活层面的分析为未来优化LLM事实准确性提供了新方向。", "keywords": "大型语言模型, 事实准确性, 可信推理, 强化学习, 机制可解释性", "comments": "RELIANCE框架的创新之处在于它系统性地解决了LLM中间推理过程中的事实不准确性，而不仅仅关注最终答案。其结合事实核查、强化学习和机制可解释性的多组件方法是全面的。该研究的重要性在于揭示了当前LLM在关键领域（如医疗、法律）应用中潜在的风险，并提供了一个有效的解决方案。特别是对模型激活层面的分析，为未来更深层次、更精准地提升LLM事实鲁棒性提供了基础，具有重要的理论和实践价值。"}}
{"id": "2407.07720", "title": "Exploiting Scale-Variant Attention for Segmenting Small Medical Objects", "authors": ["Wei Dai", "Rui Liu", "Zixuan Wu", "Tianyi Wu", "Min Wang", "Junxian Zhou", "Yixuan Yuan", "Jun Liu"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures, under review", "url": "http://arxiv.org/abs/2407.07720v5", "summary": "Early detection and accurate diagnosis can predict the risk of malignant\ndisease transformation, thereby increasing the probability of effective\ntreatment. Identifying mild syndrome with small pathological regions serves as\nan ominous warning and is fundamental in the early diagnosis of diseases. While\ndeep learning algorithms, particularly convolutional neural networks (CNNs),\nhave shown promise in segmenting medical objects, analyzing small areas in\nmedical images remains challenging. This difficulty arises due to information\nlosses and compression defects from convolution and pooling operations in CNNs,\nwhich become more pronounced as the network deepens, especially for small\nmedical objects. To address these challenges, we propose a novel scale-variant\nattention-based network (SvANet) for accurately segmenting small-scale objects\nin medical images. The SvANet consists of scale-variant attention, cross-scale\nguidance, Monte Carlo attention, and vision transformer, which incorporates\ncross-scale features and alleviates compression artifacts for enhancing the\ndiscrimination of small medical objects. Quantitative experimental results\ndemonstrate the superior performance of SvANet, achieving 96.12%, 96.11%,\n89.79%, 84.15%, 80.25%, 73.05%, and 72.58% in mean Dice coefficient for\nsegmenting kidney tumors, skin lesions, hepatic tumors, polyps, surgical\nexcision cells, retinal vasculatures, and sperms, which occupy less than 1% of\nthe image areas in KiTS23, ISIC 2018, ATLAS, PolypGen, TissueNet, FIVES, and\nSpermHealth datasets, respectively.", "comment": "14 pages, 9 figures, under review", "pdf_url": "http://arxiv.org/pdf/2407.07720v5", "cate": "eess.IV", "date": "2024-07-10", "updated": "2025-07-31", "AI": {"title_translation": "利用尺度可变注意力进行小型医学目标分割", "tldr": "SvANet利用尺度可变注意力、跨尺度引导、蒙特卡洛注意力以及视觉Transformer，有效解决了深度学习在医学图像中分割小型目标时面临的信息丢失和压缩缺陷问题，并在多项小型医学目标分割任务上表现出卓越性能。", "motivation": "早期检测和准确诊断小病理区域对于疾病的早期诊断和有效治疗至关重要。然而，深度学习算法，特别是卷积神经网络（CNNs），在医学图像中分析小区域时面临挑战，因为卷积和池化操作会导致信息丢失和压缩缺陷，这在网络加深时对小型医学目标尤其明显。", "method": "本文提出了一种新颖的基于尺度可变注意力的网络（SvANet），用于准确分割医学图像中的小型目标。SvANet包含尺度可变注意力、跨尺度引导、蒙特卡洛注意力和视觉Transformer，旨在整合跨尺度特征并减轻压缩伪影，以增强对小型医学目标的区分能力。", "result": "SvANet在分割肾肿瘤、皮肤病变、肝肿瘤、息肉、手术切除细胞、视网膜血管和精子（这些目标在各自数据集中占据不到1%的图像区域）方面表现出卓越性能。在KiTS23、ISIC 2018、ATLAS、PolypGen、TissueNet、FIVES和SpermHealth数据集上，平均Dice系数分别达到96.12%、96.11%、89.79%、84.15%、80.25%、73.05%和72.58%。", "conclusion": "提出的SvANet通过整合尺度可变注意力、跨尺度引导等组件，有效解决了深度学习在分割小型医学目标时面临的挑战，并在多项分割任务上取得了显著的优越性能，证明了其在早期诊断中的应用潜力。", "translation": "早期检测和准确诊断可以预测恶性疾病转化的风险，从而增加有效治疗的可能性。识别具有小病理区域的轻微综合征是早期诊断疾病的重要预警和基础。尽管深度学习算法，特别是卷积神经网络（CNNs），在分割医学目标方面显示出前景，但分析医学图像中的小区域仍然具有挑战性。这种困难源于CNN中卷积和池化操作导致的信息丢失和压缩缺陷，随着网络加深，尤其对于小型医学目标而言，这些问题变得更加突出。为了解决这些挑战，我们提出了一种新颖的基于尺度可变注意力的网络（SvANet），用于准确分割医学图像中的小型目标。SvANet包含尺度可变注意力、跨尺度引导、蒙特卡洛注意力和视觉Transformer，它整合了跨尺度特征并减轻了压缩伪影，以增强对小型医学目标的区分能力。定量实验结果表明，SvANet表现出卓越的性能，在分割肾肿瘤、皮肤病变、肝肿瘤、息肉、手术切除细胞、视网膜血管和精子（这些目标在KiTS23、ISIC 2018、ATLAS、PolypGen、TissueNet、FIVES和SpermHealth数据集中分别占据不到1%的图像区域）时，平均Dice系数分别达到96.12%、96.11%、89.79%、84.15%、80.25%、73.05%和72.58%。", "summary": "该论文旨在解决深度学习在医学图像中分割小型目标时面临的挑战，这些挑战主要源于卷积和池化操作导致的信息丢失和压缩缺陷。作者提出了一种名为SvANet的新型网络，该网络集成了尺度可变注意力、跨尺度引导、蒙特卡洛注意力和视觉Transformer，以增强对小型医学目标的区分能力并减轻压缩伪影。实验结果表明，SvANet在多种小型医学目标分割任务上均取得了优异的性能，Dice系数显著高于现有方法，验证了其在早期疾病诊断中的有效性。", "keywords": "小型医学目标, 图像分割, 尺度可变注意力, 深度学习, SvANet", "comments": "本文提出了一种创新的SvANet架构，通过引入尺度可变注意力等模块，有效解决了传统CNN在处理小型医学目标时普遍存在的信息丢失和特征压缩问题。其在多种不同类型的小型医学对象分割任务上均展现出卓越的泛化能力和性能，这对于需要高精度识别微小病变的早期诊断具有重要意义。该研究为医学图像分析中小型目标分割提供了新的思路和强大的工具。"}}
{"id": "2507.14632", "title": "BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM", "authors": ["Haiquan Wen", "Tianxiao Li", "Zhenglin Huang", "Yiwei He", "Guangliang Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14632v2", "summary": "Recent advances in generative AI have dramatically improved image and video\nsynthesis capabilities, significantly increasing the risk of misinformation\nthrough sophisticated fake content. In response, detection methods have evolved\nfrom traditional approaches to multimodal large language models (MLLMs),\noffering enhanced transparency and interpretability in identifying synthetic\nmedia. However, current detection systems remain fundamentally limited by their\nsingle-modality design. These approaches analyze images or videos separately,\nmaking them ineffective against synthetic content that combines multiple media\nformats. To address these challenges, we introduce \\textbf{BusterX++}, a novel\nframework designed specifically for cross-modal detection and explanation of\nsynthetic media. Our approach incorporates an advanced reinforcement learning\n(RL) post-training strategy that eliminates cold-start. Through Multi-stage\nTraining, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and\nsubstantial performance improvements. To enable comprehensive evaluation, we\nalso present \\textbf{GenBuster++}, a cross-modal benchmark leveraging\nstate-of-the-art image and video generation techniques. This benchmark\ncomprises 4,000 images and video clips, meticulously curated by human experts\nusing a novel filtering methodology to ensure high quality, diversity, and\nreal-world applicability. Extensive experiments demonstrate the effectiveness\nand generalizability of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14632v2", "cate": "cs.CV", "date": "2025-07-19", "updated": "2025-07-31", "AI": {"title_translation": "BusterX++: 迈向统一的跨模态AI生成内容检测与MLLM解释", "tldr": "BusterX++是一个新的框架，用于统一的跨模态AI生成内容检测和解释，解决了现有单模态检测系统的局限性，并引入了GenBuster++作为评估基准。", "motivation": "现有的AI生成内容检测系统主要基于单模态设计，难以有效应对结合多种媒体格式的合成内容，且合成媒体的风险日益增加，需要更透明和可解释的检测方法。", "method": "我们提出了BusterX++，一个针对跨模态合成媒体检测和解释的新框架。它融合了先进的强化学习（RL）后训练策略以消除冷启动问题，并通过多阶段训练、思维奖励和混合推理实现了性能提升。同时，我们还引入了GenBuster++，一个包含4,000个高质量图像和视频片段的跨模态基准，用于全面评估。", "result": "广泛的实验证明了我们方法的有效性和泛化能力。", "conclusion": "Not mentioned in abstract", "translation": "生成式AI的最新进展显著提升了图像和视频合成能力，通过复杂的虚假内容大大增加了错误信息的风险。为此，检测方法已从传统方法演变为多模态大语言模型（MLLMs），在识别合成媒体方面提供了增强的透明度和可解释性。然而，当前的检测系统仍受限于其单模态设计。这些方法分别分析图像或视频，使其在应对结合多种媒体格式的合成内容时效率低下。为了解决这些挑战，我们引入了BusterX++，一个专门为跨模态合成媒体检测和解释设计的新颖框架。我们的方法结合了先进的强化学习（RL）后训练策略，消除了冷启动问题。通过多阶段训练、思维奖励和混合推理，BusterX++实现了稳定且显著的性能提升。为了实现全面评估，我们还提出了GenBuster++，一个利用最先进图像和视频生成技术的跨模态基准。该基准包含4,000个图像和视频片段，由人类专家采用新颖的过滤方法精心策划，以确保高质量、多样性和实际适用性。广泛的实验证明了我们方法的有效性和泛化能力。", "summary": "本文介绍了BusterX++，一个旨在解决现有单模态检测系统局限性的统一跨模态AI生成内容检测和解释框架。BusterX++采用先进的强化学习后训练策略、多阶段训练、思维奖励和混合推理，以提高对结合多种媒体格式的合成内容的检测性能。为全面评估，研究还提出了GenBuster++，一个包含4,000个高质量图像和视频片段的跨模态基准。实验结果验证了该方法的有效性和泛化能力。", "keywords": "跨模态检测, AI生成内容, MLLM, 强化学习, 合成媒体", "comments": "该论文的创新点在于提出了一个统一的跨模态检测框架BusterX++，解决了现有单模态检测系统在处理多模态合成内容时的不足。引入强化学习后训练策略、多阶段训练、思维奖励和混合推理等方法，旨在提升检测的稳定性和性能。同时，构建高质量的跨模态基准GenBuster++也为该领域的研究提供了重要的评估工具，具有较高的实用价值。"}}
{"id": "2507.23772", "title": "SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting", "authors": ["Di Li", "Jie Feng", "Jiahao Chen", "Weisheng Dong", "Guanbin Li", "Yuhui Zheng", "Mingtao Feng", "Guangming Shi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23772v1", "summary": "3D affordance reasoning, the task of associating human instructions with the\nfunctional regions of 3D objects, is a critical capability for embodied agents.\nCurrent methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited\nto single-object, single-step interactions, a paradigm that falls short of\naddressing the long-horizon, multi-object tasks required for complex real-world\napplications. To bridge this gap, we introduce the novel task of Sequential 3D\nGaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale\nbenchmark featuring 1800+ scenes to support research on long-horizon affordance\nunderstanding in complex 3DGS environments. We then propose SeqSplatNet, an\nend-to-end framework that directly maps an instruction to a sequence of 3D\naffordance masks. SeqSplatNet employs a large language model that\nautoregressively generates text interleaved with special segmentation tokens,\nguiding a conditional decoder to produce the corresponding 3D mask. To handle\ncomplex scene geometry, we introduce a pre-training strategy, Conditional\nGeometric Reconstruction, where the model learns to reconstruct complete\naffordance region masks from known geometric observations, thereby building a\nrobust geometric prior. Furthermore, to resolve semantic ambiguities, we design\na feature injection mechanism that lifts rich semantic features from 2D Vision\nFoundation Models (VFM) and fuses them into the 3D decoder at multiple scales.\nExtensive experiments demonstrate that our method sets a new state-of-the-art\non our challenging benchmark, effectively advancing affordance reasoning from\nsingle-step interactions to complex, sequential tasks at the scene level.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23772v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SeqAffordSplat：3D高斯泼溅上的场景级序列化功能推理", "tldr": "引入了场景级序列化3D功能推理任务，提出了SeqAffordSplat基准和SeqSplatNet框架，通过LLM、几何先验和多尺度特征融合实现了复杂场景下长时序功能理解的SOTA。", "motivation": "当前基于3D高斯泼溅（3DGS）的功能推理方法仅限于单对象、单步交互，无法处理复杂现实应用所需的长期、多对象任务，存在一个能力鸿沟。", "method": "提出了序列化3D高斯功能推理任务，并建立了大规模基准SeqAffordSplat（包含1800+场景）。在此基础上，提出了端到端框架SeqSplatNet，它通过大型语言模型自回归生成文本和分割标记，指导条件解码器生成3D功能掩码序列。为了处理复杂场景几何，引入了条件几何重建预训练策略以构建鲁棒的几何先验。为解决语义歧义，设计了特征注入机制，将2D视觉基础模型的语义特征融合到3D解码器中。", "result": "所提出的方法在挑战性基准上取得了新的最先进（SOTA）性能。", "conclusion": "该方法有效推进了功能推理从单步交互到场景级复杂序列化任务的能力。", "translation": "3D功能推理，即将人类指令与3D对象的功能区域关联起来的任务，是具身智能体的关键能力。当前基于3D高斯泼溅（3DGS）的方法本质上局限于单对象、单步交互，这种范式无法满足复杂现实应用所需的长期、多对象任务。为了弥补这一差距，我们引入了新颖的序列化3D高斯功能推理任务，并建立了SeqAffordSplat这一大规模基准，其包含1800多个场景，旨在支持复杂3DGS环境中长期功能理解的研究。随后，我们提出了SeqSplatNet，这是一个端到端框架，能够直接将指令映射到一系列3D功能掩码。SeqSplatNet采用一个大型语言模型，该模型自回归地生成文本并穿插特殊的分割标记，从而引导条件解码器生成相应的3D掩码。为了处理复杂的场景几何，我们引入了一种预训练策略——条件几何重建，模型在该策略中学习从已知的几何观测中重建完整的功能区域掩码，从而建立一个鲁棒的几何先验。此外，为了解决语义歧义，我们设计了一种特征注入机制，该机制从2D视觉基础模型（VFM）中提取丰富的语义特征，并将其多尺度融合到3D解码器中。大量实验表明，我们的方法在具有挑战性的基准上创造了新的最先进水平，有效地将功能推理从单步交互推进到场景级的复杂序列化任务。", "summary": "本文针对现有3D高斯泼溅功能推理方法在处理复杂场景和长时序任务上的局限性，提出了“序列化3D高斯功能推理”新任务。为此，研究者构建了大规模基准SeqAffordSplat和端到端框架SeqSplatNet。SeqSplatNet利用大型语言模型生成指令序列，并通过条件几何重建建立几何先验，同时融合2D视觉基础模型的多尺度语义特征，以实现从指令到3D功能掩码序列的直接映射。实验证明，该方法在所提出的基准上达到了最先进水平，显著提升了场景级序列化功能推理能力。", "keywords": "3D功能推理, 3D高斯泼溅, 序列化任务, 大型语言模型, 具身智能体", "comments": "这项工作在3D功能推理领域具有重要创新。它首次将功能推理扩展到场景级序列化任务，并通过引入大型语言模型、几何先验学习和多尺度特征融合等多种策略，有效解决了复杂场景下的长期交互难题。SeqAffordSplat基准的建立为该领域的研究提供了宝贵资源，而所提出的SeqSplatNet框架则展现了强大的性能，为具身智能体在现实世界中的应用奠定了基础。"}}
{"id": "2507.23440", "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by Findings of ACL 2025", "url": "http://arxiv.org/abs/2507.23440v1", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "comment": "Accepted by Findings of ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.23440v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "自我注视：通过多级注视增强无监督文本中合成指令的多样性和难度", "tldr": "提出Self-Foveate方法，利用多级注视从无监督文本中合成更具多样性和难度的指令，以训练大型语言模型。", "motivation": "训练大型语言模型（LLMs）需要指令遵循数据。现有方法要么依赖大量人工标注，要么自动化合成的指令缺乏足够的多样性和难度。", "method": "提出Self-Foveate，这是一种由LLM驱动的指令合成方法。它引入了“微观-分散-宏观”（Micro-Scatter-Macro）多级注视方法，有效指导LLM深入挖掘无监督文本中嵌入的细粒度信息。", "result": "在多个无监督语料库和不同模型架构上的综合实验验证了所提方法的有效性和优越性。", "conclusion": "Self-Foveate通过其独特的多级注视机制，显著提升了从无监督文本合成指令的多样性和难度，为训练具有强大指令遵循能力的LLMs提供了一种有效且优越的数据合成方案。", "translation": "大型语言模型（LLMs）的指令遵循能力已展现出令人印象深刻的问题解决能力。虽然从无监督文本合成指令数据已成为训练此类模型的常用方法，但传统方法严重依赖于人工标注。尽管现有的自动化合成范式缓解了这一限制，但在确保合成指令的足够多样性和难度方面仍存在显著局限性。为了解决这些挑战，我们提出了Self-Foveate，这是一种创新的LLM驱动的指令合成方法。该方法引入了“微观-分散-宏观”多级注视方法，有效指导LLM深入挖掘无监督文本中嵌入的细粒度信息，从而增强了合成指令的多样性和难度。在多个无监督语料库和不同模型架构上的综合实验验证了我们所提方法的有效性和优越性。我们公开了我们的数据和代码：https://github.com/Mubuky/Self-Foveate", "summary": "本文提出了Self-Foveate，一种创新的LLM驱动指令合成方法，旨在解决现有方法在从无监督文本合成指令时多样性和难度不足的问题。通过引入“微观-分散-宏观”多级注视机制，Self-Foveate能有效引导LLM深入挖掘细粒度信息，从而显著提升合成指令的质量。实验证明该方法在多个语料库和模型架构上均表现出优越性。", "keywords": "指令合成, 大型语言模型, 无监督文本, 多样性, 多级注视", "comments": "这项工作通过引入“多级注视”这一新颖概念，有效解决了自动化指令合成中多样性与难度不足的关键挑战。其创新点在于通过引导LLM进行细粒度信息挖掘，提升了合成数据的质量，对于降低LLM训练对人工标注的依赖具有重要意义。公开代码和数据也促进了社区的进一步研究。"}}
{"id": "2506.11298", "title": "Jelly: a Fast and Convenient RDF Serialization Format", "authors": ["Piotr Sowinski", "Karolina Bogacka", "Anastasiya Danilenka", "Nikita Kozlov"], "categories": ["cs.DB", "cs.NI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      Developers Workshop, co-located with SEMANTiCS'25: International Conference on Semantic Systems, September 3-5, 2025, Vienna, Austria", "url": "http://arxiv.org/abs/2506.11298v2", "summary": "Existing RDF serialization formats such as Turtle, N-Quads, and JSON-LD are\nwidely used for communication and storage in knowledge graph and Semantic Web\napplications. However, they suffer from limitations in performance, compression\nratio, and lack of native support for RDF streams. To address these\nshortcomings, we introduce Jelly, a fast and convenient binary serialization\nformat for RDF data that supports both batch and streaming use cases. Jelly is\ndesigned to maximize serialization throughput, reduce file size with\nlightweight streaming compression, and minimize compute resource usage. Built\non Protocol Buffers, Jelly is easy to integrate with modern programming\nlanguages and RDF libraries. To maximize reusability, Jelly has an open\nprotocol specification, open-source implementations in Java and Python\nintegrated with popular RDF libraries, and a versatile command-line tool. To\nillustrate its usefulness, we outline concrete use cases where Jelly can\nprovide tangible benefits. We consider that by combining practical usability\nwith state-of-the-art efficiency, Jelly is an important contribution to the\nSemantic Web tool stack.", "comment": "Developers Workshop, co-located with SEMANTiCS'25: International\n  Conference on Semantic Systems, September 3-5, 2025, Vienna, Austria", "pdf_url": "http://arxiv.org/pdf/2506.11298v2", "cate": "cs.DB", "date": "2025-06-12", "updated": "2025-07-31", "AI": {"title_translation": "Jelly：一种快速便捷的RDF序列化格式", "tldr": "Jelly是一种新的二进制RDF序列化格式，旨在解决现有格式在性能、压缩比和流支持方面的不足，提供高效的批处理和流式处理能力。", "motivation": "现有的RDF序列化格式（如Turtle、N-Quads和JSON-LD）在性能、压缩比方面存在局限性，并且缺乏对RDF流的原生支持。", "method": "我们引入了Jelly，一种快速便捷的二进制RDF序列化格式，支持批处理和流式用例。Jelly基于Protocol Buffers构建，旨在最大化序列化吞吐量，通过轻量级流式压缩减少文件大小，并最小化计算资源使用。它具有开放协议规范、Java和Python的开源实现以及多功能命令行工具。", "result": "Jelly能够最大化序列化吞吐量，通过轻量级流式压缩减少文件大小，并最小化计算资源使用。它易于与现代编程语言和RDF库集成，并具有良好的可重用性。", "conclusion": "Jelly通过结合实用可用性和最先进的效率，对语义网工具栈做出了重要贡献。", "translation": "现有的RDF序列化格式，如Turtle、N-Quads和JSON-LD，在知识图谱和语义网应用中被广泛用于通信和存储。然而，它们在性能、压缩比和缺乏对RDF流的原生支持方面存在局限性。为了解决这些缺点，我们引入了Jelly，一种快速便捷的RDF数据二进制序列化格式，支持批处理和流式用例。Jelly旨在最大化序列化吞吐量，通过轻量级流式压缩减少文件大小，并最小化计算资源使用。Jelly基于Protocol Buffers构建，易于与现代编程语言和RDF库集成。为了最大限度地提高可重用性，Jelly具有开放的协议规范、与流行RDF库集成的Java和Python开源实现，以及一个多功能的命令行工具。为了说明其有用性，我们概述了Jelly可以提供实际好处的具体用例。我们认为，通过将实用可用性与最先进的效率相结合，Jelly是对语义网工具栈的重要贡献。", "summary": "本论文介绍了Jelly，一种新型的二进制RDF序列化格式，旨在克服现有格式（如Turtle、N-Quads、JSON-LD）在性能、压缩比和流支持方面的不足。Jelly基于Protocol Buffers构建，专注于提高序列化吞吐量，通过轻量级流式压缩减小文件大小，并降低计算资源消耗。它支持批处理和流式用例，并提供开放的协议规范、多语言开源实现和命令行工具，以促进集成和重用。论文强调Jelly通过结合实用性和效率，为语义网工具栈带来了显著改进。", "keywords": "RDF序列化, Jelly, 二进制格式, 语义网, 知识图谱", "comments": "Jelly的创新之处在于其二进制格式和对流的支持，这弥补了现有RDF序列化格式的短板。它基于Protocol Buffers，确保了跨语言的易用性和集成性。开源实现和开放协议进一步增强了其潜在的影响力。其重要性在于提升了知识图谱和语义网应用的数据处理效率和存储效率。论文清晰地指出了现有痛点并提出了具体的解决方案。"}}
{"id": "2505.09771", "title": "Grasp EveryThing (GET): 1-DoF, 3-Fingered Gripper with Tactile Sensing for Robust Grasping", "authors": ["Michael Burgess", "Edward H. Adelson"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.09771v3", "summary": "We introduce the Grasp EveryThing (GET) gripper, a novel 1-DoF, 3-finger\ndesign for securely grasping objects of many shapes and sizes. Mounted on a\nstandard parallel jaw actuator, the design features three narrow, tapered\nfingers arranged in a two-against-one configuration, where the two fingers\nconverge into a V-shape. The GET gripper is more capable of conforming to\nobject geometries and forming secure grasps than traditional designs with two\nflat fingers. Inspired by the principle of self-similarity, these V-shaped\nfingers enable secure grasping across a wide range of object sizes. Further to\nthis end, fingers are parametrically designed for convenient resizing and\ninterchangeability across robotic embodiments with a parallel jaw gripper.\nAdditionally, we incorporate a rigid fingernail for ease in manipulating small\nobjects. Tactile sensing can be integrated into the standalone finger via an\nexternally-mounted camera. A neural network was trained to estimate normal\nforce from tactile images with an average validation error of 1.3 N across a\ndiverse set of geometries. In grasping 15 objects and performing 3 tasks via\nteleoperation, the GET fingers consistently outperformed standard flat fingers.\nAll finger designs, compatible with multiple robotic embodiments, both\nincorporating and lacking tactile sensing, are available on GitHub.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.09771v3", "cate": "cs.RO", "date": "2025-05-14", "updated": "2025-07-30", "AI": {"title_translation": "Grasp EveryThing (GET)：一种带触觉传感的1自由度三指夹持器，用于鲁棒抓取", "tldr": "介绍了一种名为GET的1自由度三指夹持器，具有V形手指和可选触觉传感，能更鲁棒地抓取各种形状和大小的物体，并优于传统设计。", "motivation": "传统的两平指夹持器在适应物体几何形状和形成牢固抓取方面能力不足，因此需要一种能牢固抓取多种形状和大小物体的夹持器。", "method": "该研究引入了Grasp EveryThing (GET) 夹持器，这是一种新颖的1自由度、三指设计。它安装在标准平行爪执行器上，具有三个狭窄的锥形手指，呈二对一配置，其中两个手指汇聚成V形。设计灵感来源于自相似性原理，V形手指能够实现对多种尺寸物体的牢固抓取。手指是参数化设计的，便于在不同机器人上调整尺寸和互换。此外，还集成了一个刚性指甲用于操作小物体。触觉传感可通过外部安装摄像头集成，并训练了一个神经网络从触觉图像估计法向力。", "result": "GET夹持器比传统的两平指设计更能适应物体几何形状并形成牢固抓取。用于触觉传感的神经网络在估计法向力时，平均验证误差为1.3 N。在抓取15个物体和执行3项任务的遥操作测试中，GET手指始终优于标准平指。", "conclusion": "GET夹持器是一种新颖的1自由度三指设计，通过其独特的V形手指和可选的触觉传感，能够实现对多种形状和大小物体的鲁棒抓取，并已证明其性能优于传统设计，且设计开源可用。", "translation": "我们引入了 Grasp EveryThing (GET) 夹持器，这是一种新颖的1自由度三指设计，用于牢固抓取多种形状和大小的物体。该设计安装在标准平行爪执行器上，具有三个狭窄的锥形手指，呈二对一配置，其中两个手指汇聚成V形。与传统的两个平面手指设计相比，GET 夹持器更能适应物体几何形状并形成牢固抓取。受自相似性原理的启发，这些V形手指能够实现对各种尺寸物体的牢固抓取。为此，手指被参数化设计，便于在具有平行爪夹持器的机器人上方便地调整尺寸和互换。此外，我们还集成了一个刚性指甲，便于操作小物体。触觉传感可以通过外部安装的摄像头集成到独立的手指中。我们训练了一个神经网络，用于从触觉图像估计法向力，在多样化的几何形状数据集上，平均验证误差为1.3 N。在通过遥操作抓取15个物体并执行3项任务时，GET 手指始终优于标准平面手指。所有兼容多种机器人实体、无论是否包含触觉传感的手指设计都已在 GitHub 上提供。", "summary": "该论文介绍了一种名为 Grasp EveryThing (GET) 的新型1自由度三指夹持器，旨在解决传统夹持器在抓取多样化物体时的局限性。GET夹持器采用独特的V形手指设计，并可参数化调整，使其能够更好地适应不同形状和大小的物体。研究通过集成基于摄像头的触觉传感和训练神经网络来估计法向力，进一步增强了其功能。实验结果表明，GET手指在抓取性能上显著优于标准平面手指，证明了其在鲁棒抓取方面的有效性和优越性。所有设计均开源可用，便于在不同机器人平台上应用。", "keywords": "夹持器, 触觉传感, 鲁棒抓取, 1自由度, 三指", "comments": "该论文提出了一种创新的1自由度三指夹持器GET，其独特的V形手指设计和参数化可伸缩性使其能有效抓取多种形状和大小的物体。集成触觉传感和开源可用性进一步提升了其实用性和影响力。相较于传统两指夹持器，其在抓取性能上表现出显著优势，为机器人抓取领域提供了新的解决方案。"}}
{"id": "2507.14534", "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion", "authors": ["Yu Zhang", "Baotong Tian", "Zhiyao Duan"], "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14534v3", "summary": "Zero-shot online voice conversion (VC) holds significant promise for\nreal-time communications and entertainment. However, current VC models struggle\nto preserve semantic fidelity under real-time constraints, deliver\nnatural-sounding conversions, and adapt effectively to unseen speaker\ncharacteristics. To address these challenges, we introduce Conan, a chunkwise\nonline zero-shot voice conversion model that preserves the content of the\nsource while matching the voice timbre and styles of reference speech. Conan\ncomprises three core components: 1) a Stream Content Extractor that leverages\nEmformer for low-latency streaming content encoding; 2) an Adaptive Style\nEncoder that extracts fine-grained stylistic features from reference speech for\nenhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully\ncausal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations\ndemonstrate that Conan outperforms baseline models in subjective and objective\nmetrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14534v3", "cate": "eess.AS", "date": "2025-07-19", "updated": "2025-07-30", "AI": {"title_translation": "Conan: 一种用于零样本自适应语音转换的块状在线网络", "tldr": "Conan是一个块状在线零样本语音转换模型，解决了实时通信中语义保真度、自然度以及对未知说话人适应性的挑战。", "motivation": "当前语音转换模型在实时约束下难以保持语义保真度、提供自然听感的转换，并且难以有效适应未见的说话人特征。", "method": "本文引入了Conan，一个块状在线零样本语音转换模型。Conan包含三个核心组件：1) 流内容提取器，利用Emformer进行低延迟流内容编码；2) 自适应风格编码器，从参考语音中提取细粒度风格特征以增强风格适应性；3) 因果混洗声码器，实现了使用像素混洗机制的完全因果HiFiGAN。", "result": "实验评估表明，Conan在主观和客观指标上均优于基线模型。", "conclusion": "Not mentioned in abstract", "translation": "零样本在线语音转换（VC）在实时通信和娱乐方面具有重要前景。然而，当前的VC模型在实时约束下难以保持语义保真度、提供自然听感的转换，并且难以有效适应未见的说话人特征。为了解决这些挑战，我们引入了Conan，一个块状在线零样本语音转换模型，它在匹配参考语音的音色和风格的同时保留了源语音的内容。Conan包含三个核心组件：1）一个流内容提取器，利用Emformer进行低延迟流内容编码；2）一个自适应风格编码器，从参考语音中提取细粒度风格特征以增强风格适应性；3）一个因果混洗声码器，实现了使用像素混洗机制的完全因果HiFiGAN。实验评估表明，Conan在主观和客观指标上均优于基线模型。音频样本可在 https://aaronz345.github.io/ConanDemo 找到。", "summary": "本文介绍了Conan，一个用于零样本在线语音转换的新模型。针对现有模型在实时约束下语义保真度、自然度和对未知说话人适应性方面的不足，Conan采用块状在线处理方式，并通过流内容提取器、自适应风格编码器和因果混洗声码器三大组件，实现了在保留源内容的同时，匹配参考语音的音色和风格。实验结果表明，Conan在各项指标上均优于基线模型。", "keywords": "零样本语音转换, 在线语音转换, 块状网络, Emformer, HiFiGAN", "comments": "Conan模型创新性地提出了块状在线处理方式和结合Emformer、细粒度风格编码及因果HiFiGAN的架构，有效解决了零样本在线语音转换在实时性、自然度和适应性方面的核心挑战，对于实时通信和娱乐应用具有重要意义。"}}
{"id": "2507.23588", "title": "DiffLoRA: Differential Low-Rank Adapters for Large Language Models", "authors": ["Alexandre Misrahi", "Nadezhda Chirkova", "Maxime Louis", "Vassilina Nikoulina"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23588v1", "summary": "Differential Transformer has recently been proposed to improve performance in\nTransformer models by canceling out noise through a denoiser attention\nmechanism. In this work, we introduce DiffLoRA, a parameter-efficient\nadaptation of the differential attention mechanism, with low-rank adapters on\nboth positive and negative attention terms. This approach retains the\nefficiency of LoRA while aiming to benefit from the performance gains of\ndifferential attention. We evaluate DiffLoRA across a broad range of NLP tasks,\nincluding general benchmarks, many-shot in-context learning, RAG, and\nlong-context tests. We observe that, although DiffLoRA falls short of other\nparameter-efficient fine-tuning methods in most evaluation tasks, it shows\ninteresting results in certain domains (+11 pts on LoRA for HumanEval). We\nanalyze the attention patterns post-finetuning to identify the reasons for this\nbehavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23588v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DiffLoRA：大型语言模型的差分低秩适配器", "tldr": "DiffLoRA将差分注意力机制与LoRA结合，用于大型语言模型的参数高效适应。它在大多数任务中表现不如其他PEFT方法，但在特定领域（如HumanEval）显示出有趣的结果。", "motivation": "差分Transformer最近被提出通过去噪注意力机制来提高Transformer模型的性能。本文旨在引入DiffLoRA，一种参数高效的差分注意力机制适应方法，以保留LoRA的效率并受益于差分注意力的性能增益。", "method": "本文引入了DiffLoRA，一种差分注意力机制的参数高效适应方法。它在正负注意力项上使用低秩适配器，旨在结合LoRA的效率和差分注意力的性能优势。", "result": "DiffLoRA在大多数评估任务中未能超越其他参数高效微调方法，但在某些特定领域（如HumanEval上比LoRA高11点）显示出有趣的结果。研究分析了微调后的注意力模式以识别其行为原因。", "conclusion": "DiffLoRA在大多数评估任务中未能普遍优于其他参数高效微调方法，但在特定领域展现出潜力。对其注意力模式的进一步分析有助于理解其性能特点。", "translation": "差分Transformer最近被提出，通过去噪注意力机制来改善Transformer模型的性能。在这项工作中，我们引入了DiffLoRA，一种差分注意力机制的参数高效适应方法，它在正负注意力项上都使用了低秩适配器。这种方法在保留LoRA效率的同时，旨在从差分注意力的性能增益中获益。我们在广泛的NLP任务中评估了DiffLoRA，包括通用基准测试、多样本语境学习、RAG和长文本测试。我们观察到，尽管DiffLoRA在大多数评估任务中未能超越其他参数高效微调方法，但它在某些领域显示出有趣的结果（在HumanEval上比LoRA高11点）。我们分析了微调后的注意力模式，以确定这种行为的原因。", "summary": "本文提出了DiffLoRA，一种结合了差分注意力机制和低秩适配器的大型语言模型参数高效适应方法。DiffLoRA旨在利用差分注意力提升性能，同时保持LoRA的效率。尽管在多数NLP任务中，DiffLoRA表现不如其他参数高效微调方法，但在特定领域（如HumanEval）展现出积极效果。研究进一步分析了微调后的注意力模式以解释其性能表现。", "keywords": "DiffLoRA, 低秩适配器, 差分注意力, 大型语言模型, 参数高效微调", "comments": "DiffLoRA的创新点在于将差分注意力机制与LoRA相结合，以期在保持参数效率的同时提升性能。尽管其在广泛任务上的表现未能全面超越现有方法，但在特定领域（如HumanEval）的显著提升表明其具有特定应用价值和研究潜力。未来的工作可以进一步探索其在这些特定领域的优化，并深入理解其注意力模式的优势。"}}
{"id": "2507.18371", "title": "MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image", "authors": ["DongFu Yin", "Xiaotian Chen", "Fei Richard Yu", "Xuanchen Li", "Xinhao Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18371v2", "summary": "Advances in generative modeling have significantly enhanced digital content\ncreation, extending from 2D images to complex 3D and 4D scenes. Despite\nsubstantial progress, producing high-fidelity and temporally consistent dynamic\n4D content remains a challenge. In this paper, we propose MVG4D, a novel\nframework that generates dynamic 4D content from a single still image by\ncombining multi-view synthesis with 4D Gaussian Splatting (4D GS). At its core,\nMVG4D employs an image matrix module that synthesizes temporally coherent and\nspatially diverse multi-view images, providing rich supervisory signals for\ndownstream 3D and 4D reconstruction. These multi-view images are used to\noptimize a 3D Gaussian point cloud, which is further extended into the temporal\ndomain via a lightweight deformation network. Our method effectively enhances\ntemporal consistency, geometric fidelity, and visual realism, addressing key\nchallenges in motion discontinuity and background degradation that affect prior\n4D GS-based methods. Extensive experiments on the Objaverse dataset demonstrate\nthat MVG4D outperforms state-of-the-art baselines in CLIP-I, PSNR, FVD, and\ntime efficiency. Notably, it reduces flickering artifacts and sharpens\nstructural details across views and time, enabling more immersive AR/VR\nexperiences. MVG4D sets a new direction for efficient and controllable 4D\ngeneration from minimal inputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18371v2", "cate": "cs.CV", "date": "2025-07-24", "updated": "2025-07-31", "AI": {"title_translation": "MVG4D: 基于图像矩阵的单图像多视图与运动生成，用于4D内容创作", "tldr": "MVG4D是一个新颖的框架，通过结合多视图合成和4D高斯泼溅，从单张图像生成高保真且时间一致的动态4D内容。", "motivation": "尽管生成建模在数字内容创作方面取得了显著进展，但从2D图像扩展到复杂的3D和4D场景时，生成高保真和时间一致的动态4D内容仍然是一个挑战。", "method": "本文提出了MVG4D框架，它通过结合多视图合成与4D高斯泼溅（4D GS）从单张静止图像生成动态4D内容。其核心是使用一个图像矩阵模块来合成时间连贯且空间多样的多视图图像，为后续的3D和4D重建提供丰富的监督信号。这些多视图图像用于优化3D高斯点云，并通过轻量级变形网络进一步扩展到时间域。", "result": "MVG4D在Objaverse数据集上的广泛实验表明，它在CLIP-I、PSNR、FVD和时间效率方面优于现有最先进的基线方法。显著地，它减少了闪烁伪影，并锐化了跨视图和时间的结构细节，从而实现了更沉浸式的AR/VR体验。", "conclusion": "MVG4D为从最小输入进行高效和可控的4D生成设定了新方向。", "translation": "尽管生成建模取得了显著进展，数字内容创作已从2D图像扩展到复杂的3D和4D场景。然而，生成高保真且时间一致的动态4D内容仍然是一个挑战。本文提出MVG4D，一个新颖的框架，通过结合多视图合成与4D高斯泼溅（4D GS），从单张静止图像生成动态4D内容。MVG4D的核心是一个图像矩阵模块，它合成时间连贯且空间多样的多视图图像，为下游的3D和4D重建提供丰富的监督信号。这些多视图图像用于优化3D高斯点云，并通过一个轻量级变形网络进一步扩展到时间域。我们的方法有效增强了时间一致性、几何保真度和视觉真实感，解决了影响先前基于4D GS方法运动不连续性和背景退化等关键挑战。在Objaverse数据集上的广泛实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于现有最先进的基线方法。值得注意的是，它减少了跨视图和时间的闪烁伪影并锐化了结构细节，从而实现了更沉浸式的AR/VR体验。MVG4D为从最小输入进行高效和可控的4D生成设定了新方向。", "summary": "MVG4D是一个新颖的框架，旨在从单张图像创建高保真和时间一致的动态4D内容。它通过一个图像矩阵模块生成多视图图像，结合4D高斯泼溅和轻量级变形网络，将3D点云扩展到时间域。该方法显著提升了时间一致性、几何保真度和视觉真实感，有效解决了现有4D GS方法中的运动不连续和背景退化问题。实验证明，MVG4D在多项指标上超越了现有技术，并能减少闪烁、锐化细节，为AR/VR体验提供更沉浸的4D内容。", "keywords": "4D内容生成, 单图像, 多视图合成, 4D高斯泼溅, 深度学习", "comments": "MVG4D的创新点在于其结合图像矩阵模块进行多视图合成与4D高斯泼溅，以实现从单张图像生成高质量的4D内容。该方法通过解决传统4D GS方法的运动不连续性和背景退化问题，显著提升了时间一致性和视觉真实感。其能够从最小输入实现高效且可控的4D生成，并为AR/VR等沉浸式体验提供更优质的内容，具有重要的实际应用价值。"}}
{"id": "2507.23339", "title": "Learning to Drift with Individual Wheel Drive: Maneuvering Autonomous Vehicle at the Handling Limits", "authors": ["Yihan Zhou", "Yiwen Lu", "Bo Yang", "Jiayun Li", "Yilin Mo"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23339v1", "summary": "Drifting, characterized by controlled vehicle motion at high sideslip angles,\nis crucial for safely handling emergency scenarios at the friction limits.\nWhile recent reinforcement learning approaches show promise for drifting\ncontrol, they struggle with the significant simulation-to-reality gap, as\npolicies that perform well in simulation often fail when transferred to\nphysical systems. In this paper, we present a reinforcement learning framework\nwith GPU-accelerated parallel simulation and systematic domain randomization\nthat effectively bridges the gap. The proposed approach is validated on both\nsimulation and a custom-designed and open-sourced 1/10 scale Individual Wheel\nDrive (IWD) RC car platform featuring independent wheel speed control.\nExperiments across various scenarios from steady-state circular drifting to\ndirection transitions and variable-curvature path following demonstrate that\nour approach achieves precise trajectory tracking while maintaining controlled\nsideslip angles throughout complex maneuvers in both simulated and real-world\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23339v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "学习使用独立轮驱动进行漂移：在操纵极限下自动驾驶车辆", "tldr": "本文提出了一种基于强化学习的框架，结合GPU加速并行仿真和系统域随机化，以弥合漂移控制中仿真到现实的差距，并在仿真和1/10比例的独立轮驱动遥控车平台上成功验证了其精确轨迹跟踪能力。", "motivation": "漂移对于在摩擦极限下安全处理紧急情况至关重要。尽管最近的强化学习方法在漂移控制方面显示出潜力，但它们面临显著的仿真到现实差距，即在仿真中表现良好的策略在物理系统中往往失败。", "method": "本文提出了一种结合GPU加速并行仿真和系统域随机化的强化学习框架，以有效弥合仿真到现实的差距。该方法在仿真和定制的开源1/10比例独立轮驱动（IWD）遥控车平台上进行了验证。", "result": "实验表明，该方法在从稳态圆形漂移到方向转换和可变曲率路径跟踪的各种场景中，无论是在模拟环境还是真实世界环境中，都能实现精确的轨迹跟踪，同时在复杂机动中保持受控的侧滑角。", "conclusion": "该强化学习框架通过弥合仿真到现实的差距，成功实现了自动驾驶车辆在操纵极限下的精确漂移控制，并在实际物理平台上得到了验证。", "translation": "漂移，以高侧滑角下受控的车辆运动为特征，对于在摩擦极限下安全处理紧急情况至关重要。尽管最近的强化学习方法在漂移控制方面显示出潜力，但它们面临显著的仿真到现实差距，即在仿真中表现良好的策略在物理系统中往往失败。在本文中，我们提出了一种结合GPU加速并行仿真和系统域随机化的强化学习框架，有效弥合了这一差距。所提出的方法在仿真和定制设计并开源的1/10比例独立轮驱动（IWD）遥控车平台上进行了验证，该平台具有独立的轮速控制功能。从稳态圆形漂移到方向转换和可变曲率路径跟踪的各种场景的实验表明，我们的方法在模拟和现实环境中，在复杂的机动中都能实现精确的轨迹跟踪，同时保持受控的侧滑角。", "summary": "本文针对自动驾驶车辆在操纵极限下的漂移控制问题，提出了一种基于强化学习的框架，旨在解决现有方法中存在的显著仿真到现实差距。该框架结合了GPU加速并行仿真和系统域随机化技术，以增强策略的泛化能力。通过在仿真和定制的1/10比例独立轮驱动遥控车平台上的广泛实验，验证了所提方法在各种复杂机动中实现精确轨迹跟踪和保持受控侧滑角的有效性。", "keywords": "强化学习, 漂移控制, 独立轮驱动, 仿真到现实差距, 域随机化", "comments": "该论文的创新点在于提出了一种结合GPU加速并行仿真和系统域随机化的强化学习框架，有效解决了自动驾驶车辆漂移控制中的仿真到现实差距问题。其重要性在于为高难度车辆操控（如漂移）提供了可行的自动化解决方案，这对于车辆在紧急情况下的安全极限操作具有实际意义。该方法在实际的1/10比例RC车平台上的验证增强了其可信度和应用潜力。"}}
{"id": "2507.23234", "title": "Secure Integrated Sensing and Communication Networks: Stochastic Performance Analysis", "authors": ["Marziyeh Soltani", "Mahtab Mirmohseni", "Rahim Tafazolli"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23234v1", "summary": "This paper analyzes the stochastic security performance of a multiple-input\nmultiple-output (MIMO) integrated sensing and communication (ISAC) system in a\ndownlink scenario. A base station (BS) transmits a multi-functional signal to\nsimultaneously communicate with a user, sense a target's angular location, and\ncounteract eavesdropping threats. The attack model considers a passive\nsingle-antenna communication eavesdropper intercepting communication data, as\nwell as a multi-antenna sensing eavesdropper attempting to infer the target's\nlocation. We also consider a malicious target scenario where the target plays\nthe role of the communication eavesdropper. The BS-user and BS-eavesdroppers\nchannels follow Rayleigh fading, while the target's azimuth angle is uniformly\ndistributed. To evaluate the performance in this random network, we derive the\nergodic secrecy rate (ESR) and the ergodic Cramer-Rao lower bound (CRB), for\ntarget localization, at both the BS and the sensing eavesdropper. This involves\ncomputing the probability density functions (PDFs) of the signal-to-noise ratio\n(SNR) and CRB, leveraging the central limit theorem for tractability. We\ncharacterize the boundary of the CRB-secrecy rate region, and interpret the\nperformance tradeoffs between communication and sensing while guaranteeing a\nlevel of security and privacy in the random ISAC networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23234v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "安全集成感知与通信网络：随机性能分析", "tldr": "本文分析了MIMO ISAC系统在下行链路中的随机安全性能，考虑了通信窃听器、感知窃听器和恶意目标，推导了遍历保密速率和克拉默-拉奥下界，并分析了通信与感知之间的性能权衡。", "motivation": "旨在分析多输入多输出（MIMO）集成感知与通信（ISAC）系统在下行链路场景中的随机安全性能，以应对窃听威胁并保障通信和感知的安全性与隐私。", "method": "论文分析了一个基站同时进行用户通信、目标角度定位和对抗窃听威胁的多功能信号传输。考虑了被动单天线通信窃听器、多天线感知窃听器以及充当通信窃听器的恶意目标。信道遵循瑞利衰落，目标方位角均匀分布。通过推导遍历保密速率（ESR）和目标定位的遍历克拉默-拉奥下界（CRB），计算信噪比和CRB的概率密度函数（利用中心极限定理），来评估网络性能。", "result": "论文推导了基站和感知窃听器的遍历保密速率（ESR）和目标定位的遍历克拉默-拉奥下界（CRB）。通过计算信噪比和CRB的概率密度函数，表征了CRB-保密速率区域的边界，并阐释了在随机ISAC网络中，保障一定安全和隐私水平下通信与感知之间的性能权衡。", "conclusion": "本文成功分析了MIMO ISAC系统在存在多种窃听威胁下的随机安全性能，量化了通信与感知之间的性能权衡，为随机ISAC网络的安全和隐私保障提供了理论基础。", "translation": "本文分析了下行链路场景中多输入多输出（MIMO）集成感知与通信（ISAC）系统的随机安全性能。基站（BS）发送多功能信号，同时与用户通信、感知目标的角度位置并对抗窃听威胁。攻击模型考虑了拦截通信数据的被动单天线通信窃听器，以及试图推断目标位置的多天线感知窃听器。我们还考虑了恶意目标场景，其中目标扮演通信窃听器的角色。基站-用户和基站-窃听器信道遵循瑞利衰落，而目标的方位角呈均匀分布。为了评估此随机网络中的性能，我们推导了基站和感知窃听器的遍历保密速率（ESR）以及目标定位的遍历克拉默-拉奥下界（CRB）。这涉及计算信噪比（SNR）和CRB的概率密度函数（PDF），并利用中心极限定理以提高可处理性。我们表征了CRB-保密速率区域的边界，并阐释了在随机ISAC网络中保障一定安全和隐私水平下通信与感知之间的性能权衡。", "summary": "本文对下行链路MIMO集成感知与通信（ISAC）系统的随机安全性能进行了深入分析。研究考虑了通信窃听器、感知窃听器以及恶意目标等多种攻击模型。通过推导遍历保密速率（ESR）和目标定位的遍历克拉默-拉奥下界（CRB），并利用中心极限定理计算相关概率密度函数，论文量化了通信与感知之间的性能权衡，并明确了在随机ISAC网络中实现安全与隐私保障的边界。", "keywords": "集成感知与通信, 随机安全, 遍历保密速率, 克拉默-拉奥下界, 性能权衡", "comments": "这篇论文的创新点在于其全面考虑了多种复杂的窃听场景（包括通信窃听、感知窃听和恶意目标），并首次在随机ISAC网络中量化了通信与感知之间的安全-隐私权衡，为未来ISAC系统的安全设计提供了重要的理论指导。其采用遍历保密速率和克拉默-拉奥下界作为性能指标，并结合中心极限定理进行分析，方法严谨且具有挑战性。"}}
{"id": "2507.23216", "title": "Efficient algorithm for linear diophantine equations in two variables", "authors": ["Mayank Deora", "Pinakpani Pal"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23216v1", "summary": "Solving linear diophantine equations in two variables have applications in\ncomputer science and mathematics. In this paper, we revisit an algorithm for\nsolving linear diophantine equations in two variables, which we refer as DEA-R\nalgorithm. The DEA-R algorithm always incurs equal or less number of recursions\nor recursive calls as compared to extended euclidean algorithm. With the\nobjective of taking advantage of the less number of recursive calls , we\npropose an optimized version of the DEA-R algorithm as DEA-OPTD. In the\nrecursive function calls in DEA-OPTD, we propose a sequence of more efficient\ncomputations. We do a theoretical comparison of the execution times of DEA-OPTD\nalgorithm and DEA-R algorithm to find any possible bound on the value of $c$\nfor DEA-OPTD being better than DEA-R. We implement and compare an iterative\nversion of DEA-OPTD (DEA-OPTDI) with two versions of a widely used algorithm on\nan specific input setting. In this comparison, we find out that our algorithm\noutperforms on the other algorithm against atleast 96% of the inputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23216v1", "cate": "cs.DS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "二元线性丢番图方程的高效算法", "tldr": "本文提出了一种优化的二元线性丢番图方程求解算法DEA-OPTD及其迭代版本DEA-OPTDI，该算法在理论和实践中均显示出比现有算法更优的性能。", "motivation": "二元线性丢番图方程的求解在计算机科学和数学领域有广泛应用。本文旨在优化现有算法，以减少递归调用次数并提高计算效率。", "method": "本文首先回顾了DEA-R算法，该算法与扩展欧几里得算法相比，递归调用次数更少。在此基础上，提出了一种优化版本DEA-OPTD，通过在递归函数调用中引入更高效的计算序列。文章对DEA-OPTD和DEA-R算法的执行时间进行了理论比较。此外，还实现了DEA-OPTD的迭代版本DEA-OPTDI，并将其与两种广泛使用的算法在特定输入设置下进行了比较。", "result": "理论比较旨在找到DEA-OPTD优于DEA-R的参数c的可能界限。在实际比较中，DEA-OPTDI算法在至少96%的输入情况下优于其他算法。", "conclusion": "本文提出的优化算法DEA-OPTDI在求解二元线性丢番图方程方面表现出卓越的性能，显著优于现有广泛使用的算法。", "translation": "求解二元线性丢番图方程在计算机科学和数学领域有应用。本文重新探讨了一种求解二元线性丢番图方程的算法，我们称之为DEA-R算法。与扩展欧几里得算法相比，DEA-R算法总是产生相等或更少的递归次数或递归调用。为了利用更少的递归调用次数，我们提出了DEA-R算法的优化版本DEA-OPTD。在DEA-OPTD的递归函数调用中，我们提出了一系列更高效的计算。我们对DEA-OPTD算法和DEA-R算法的执行时间进行了理论比较，以找出DEA-OPTD优于DEA-R时c值的任何可能界限。我们实现并比较了DEA-OPTD的迭代版本（DEA-OPTDI）与两种广泛使用的算法在特定输入设置下的性能。在这次比较中，我们发现我们的算法在至少96%的输入情况下优于其他算法。", "summary": "本文针对二元线性丢番图方程的求解，在回顾现有DEA-R算法的基础上，提出了一种优化的DEA-OPTD算法。该算法通过引入更高效的计算序列，旨在减少递归调用并提高效率。文章进行了理论分析，并实现了其迭代版本DEA-OPTDI。实验结果表明，DEA-OPTDI在多数输入情况下显著优于两种广泛使用的算法，展示了其在实际应用中的优越性。", "keywords": "二元线性丢番图方程, 高效算法, DEA-R, DEA-OPTD, 递归调用", "comments": "本文的创新点在于对现有DEA-R算法进行了深入优化，通过减少递归调用和改进计算序列，显著提升了二元线性丢番图方程的求解效率。实验结果表明其在性能上超越了现有广泛使用的算法，对于需要高效求解此类方程的领域具有重要意义。"}}
{"id": "2507.23536", "title": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "authors": ["Georg Slamanig", "Francesco Corti", "Olga Saukh"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23536v1", "summary": "Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs\nof updating deep learning models by minimizing the number of additional\nparameters used to adapt a model to a down- stream task. While extensively\nresearched in large language models (LLMs), their application to smaller models\nused on edge devices, such as convolutional neural networks, remains\nunderexplored. This paper benchmarks and analyzes popular PEFT methods on\nconvolutional architectures typically deployed in resource-constrained edge\nenvironments. We evaluate LoRA, DoRA, and GaLore for updating standard and\ndepthwise convolutional architectures to handle distribution shifts and\naccommodate unseen classes. We utilize recently proposed PyTorch profilers to\ncompare the updated model performance and computational costs of these PEFT\nmethods with traditional fine-tuning approaches. With resource efficiency in\nmind, we investigate their update behavior across different rank dimensions. We\nfind that the evaluated PEFT methods are only half as memory-efficient when\napplied to depthwise-separable convolution architectures, compared to their\nefficiency with LLMs. Conversely, when targeting convolu- tional architectures\noptimized for edge deployment, adapter-based PEFT methods can reduce floating\npoint operations (FLOPs) during model updates by up to 95%. These insights\noffer valuable guidance for selecting PEFT methods based on hardware\nconstraints, performance requirements, and application needs. Our code is\nonline.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23536v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "从大型语言模型到边缘设备：边缘设备上的参数高效微调", "tldr": "本文在边缘部署的卷积网络上对参数高效微调（PEFT）方法进行了基准测试，发现与大型语言模型（LLMs）相比，其内存和浮点运算效率各不相同，为边缘设备上的PEFT选择提供了指导。", "motivation": "参数高效微调（PEFT）方法在大型语言模型（LLMs）中已被广泛研究，但其在边缘设备上使用的较小模型（如卷积神经网络）中的应用仍未得到充分探索。", "method": "本文在通常部署在资源受限边缘环境中的卷积架构上，对流行的参数高效微调（PEFT）方法进行了基准测试和分析。作者评估了LoRA、DoRA和GaLore在更新标准和深度可分离卷积架构以处理分布偏移和适应未见类别时的表现。研究利用PyTorch分析器比较了这些PEFT方法与传统微调方法的模型更新性能和计算成本，并考虑资源效率，研究了它们在不同秩维度下的更新行为。", "result": "研究发现，在深度可分离卷积架构上应用时，评估的PEFT方法的内存效率仅为其在大型语言模型（LLMs）上效率的一半。相反，当针对为边缘部署优化的卷积架构时，基于适配器的PEFT方法在模型更新期间可以将浮点运算（FLOPs）减少高达95%。", "conclusion": "这些见解为根据硬件限制、性能要求和应用需求选择参数高效微调（PEFT）方法提供了宝贵的指导。", "translation": "参数高效微调（PEFT）方法通过最小化用于使模型适应下游任务的额外参数数量，从而降低了更新深度学习模型的计算成本。尽管PEFT在大型语言模型（LLMs）中得到了广泛研究，但其在边缘设备上使用的较小模型（例如卷积神经网络）中的应用仍未得到充分探索。本文在通常部署在资源受限边缘环境中的卷积架构上，对流行的PEFT方法进行了基准测试和分析。我们评估了LoRA、DoRA和GaLore在更新标准和深度可分离卷积架构以处理分布偏移和适应未见类别时的表现。我们利用最近提出的PyTorch分析器来比较这些PEFT方法的模型更新性能和计算成本与传统微调方法。考虑到资源效率，我们研究了它们在不同秩维度下的更新行为。我们发现，在应用于深度可分离卷积架构时，所评估的PEFT方法的内存效率仅为其在LLMs上效率的一半。相反，当针对为边缘部署优化的卷积架构时，基于适配器的PEFT方法在模型更新期间可以将浮点运算（FLOPs）减少高达95%。这些见解为根据硬件限制、性能要求和应用需求选择PEFT方法提供了宝贵的指导。我们的代码已在线提供。", "summary": "本文研究了将通常用于大型语言模型的参数高效微调（PEFT）方法应用于部署在资源受限边缘设备上的小型卷积神经网络。通过对LoRA、DoRA和GaLore在各种卷积架构上的基准测试，研究发现，与大型语言模型相比，PEFT方法在深度可分离卷积上的内存效率较低，但基于适配器的PEFT可以在针对边缘部署优化的卷积架构上显著减少高达95%的浮点运算（FLOPs）。这些发现为边缘AI应用选择合适的PEFT策略提供了重要指导，同时考虑了硬件限制和性能需求。", "keywords": "参数高效微调, 边缘设备, 卷积神经网络, LoRA, DoRA, GaLore", "comments": "这篇论文非常重要，因为它弥合了主要集中在大型语言模型（LLMs）上的参数高效微调（PEFT）研究与其在资源受限边缘设备上的实际应用之间的鸿沟。对不同卷积架构的内存和计算效率进行的详细基准测试和分析，提供了宝贵的经验见解。研究结果揭示了PEFT方法在LLMs之外的细微性能差异，为实践者在边缘AI这一日益增长且关键的领域选择最佳策略提供了具体指导。"}}
{"id": "2507.23613", "title": "A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm", "authors": ["Daniel Appelö", "Francis Appiah", "Jeffrey W. Banks", "Cassandra Carrick", "William D. Henshaw", "Donald W. Schwendeman"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23613v1", "summary": "We develop and analyze a new approach for simultaneously computing multiple\nsolutions to the Helmholtz equation for different frequencies and different\nforcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an\nextension of the original WaveHoltz method and both are based on time-filtering\nsolutions to an associated wave equation. With MFWH, the different Helmholtz\nsolutions are computed simultaneously by solving a single wave equation\ncombined with multiple time filters. The MFWH algorithm defines a fixed-point\niteration which can be accelerated with Krylov methods such as GMRES. The\nsolution of the wave equation can be efficiently solved with either explicit\ntime-stepping or implicit time-stepping using as few as five time-steps per\nperiod. When combined with an $O(N)$ solver for the implicit equations, such a\nmultigrid, the scheme has an $O(N)$ solution cost when the frequencies are\nfixed and the number of grid points $N$ increases. High-order accurate\napproximations in space are used together with second-order accurate\napproximations in time. We show how to remove time discretization errors so\nthat the MFWH solutions converge to the corresponding solutions to the\ndiscretized Helmholtz problems. Numerical results are given using second-order\naccurate and fourth-accurate discretizations to confirm the convergence theory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23613v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于WaveHoltz算法的多频亥姆霍兹求解器", "tldr": "提出了一种新的多频WaveHoltz（MFWH）算法，用于同时求解不同频率和强迫函数的亥姆霍兹方程，具有O(N)的求解成本。", "motivation": "需要一种能够同时计算不同频率和不同强迫函数的亥姆霍兹方程多个解的新方法。", "method": "开发了多频WaveHoltz（MFWH）算法，它是原始WaveHoltz方法的扩展，两者都基于对相关波动方程解的时间滤波。MFWH通过求解一个结合了多个时间滤波器的单一波动方程来同时计算不同的亥姆霍兹解。该算法定义了一个固定点迭代，可以用Krylov方法（如GMRES）加速。波动方程的求解可以通过显式或隐式时间步进高效完成，每个周期只需五个时间步。当与隐式方程的O(N)求解器（如多重网格）结合时，当频率固定且网格点数N增加时，该方案具有O(N)的求解成本。空间上使用高阶精确近似，时间上使用二阶精确近似。作者还展示了如何消除时间离散化误差，使MFWH解收敛到离散化亥姆霍兹问题的相应解。", "result": "MFWH算法在频率固定且网格点数N增加时，具有O(N)的求解成本。数值结果通过二阶和四阶精确离散化证实了收敛理论。", "conclusion": "多频WaveHoltz（MFWH）算法是一种高效且精确的亥姆霍兹方程多频求解器，能够同时计算不同频率和强迫函数的解，并具有良好的收敛性。", "translation": "我们开发并分析了一种同时计算不同频率和不同强迫函数的亥姆霍兹方程多个解的新方法。新的多频WaveHoltz（MFWH）算法是原始WaveHoltz方法的扩展，两者都基于对相关波动方程解的时间滤波。通过MFWH，不同的亥姆霍兹解通过求解一个结合了多个时间滤波器的单一波动方程来同时计算。MFWH算法定义了一个固定点迭代，可以用Krylov方法（如GMRES）加速。波动方程的求解可以通过显式或隐式时间步进高效完成，每个周期只需五个时间步。当与隐式方程的O(N)求解器（如多重网格）结合时，当频率固定且网格点数N增加时，该方案具有O(N)的求解成本。空间上使用高阶精确近似，时间上使用二阶精确近似。我们展示了如何消除时间离散化误差，使MFWH解收敛到离散化亥姆霍兹问题的相应解。数值结果使用二阶和四阶精确离散化给出，以证实收敛理论。", "summary": "该论文介绍了一种名为多频WaveHoltz（MFWH）的新算法，用于同时求解不同频率和强迫函数的亥姆霍兹方程。该算法是基于时间滤波相关波动方程解的WaveHoltz方法的扩展，通过求解单一波动方程结合多个时间滤波器来实现多解计算。MFWH采用固定点迭代，可由Krylov方法加速，并能通过高效的时间步进（显式或隐式）结合O(N)求解器（如多重网格）实现O(N)的计算成本。论文还讨论了消除时间离散化误差的方法，并用数值结果验证了收敛性。", "keywords": "亥姆霍兹方程, WaveHoltz算法, 多频, 时间滤波, 数值求解器", "comments": "该论文的主要创新在于提出了MFWH算法，它能够高效地同时求解多频亥姆霍兹方程，特别是其O(N)的计算成本和消除时间离散化误差的能力，这对于大规模数值模拟具有重要意义。"}}
{"id": "2507.19621", "title": "Exemplar Med-DETR: Toward Generalized and Robust Lesion Detection in Mammogram Images and beyond", "authors": ["Sheethal Bhat", "Bogdan Georgescu", "Adarsh Bhandary Panambur", "Mathias Zinnen", "Tri-Thien Nguyen", "Awais Mansoor", "Karim Khalifa Elbarbary", "Siming Bayer", "Florin-Cristian Ghesu", "Sasa Grbic", "Andreas Maier"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      I am asking for a withdrawal of the paper as I did not have institutional approval to release this paper right now", "url": "http://arxiv.org/abs/2507.19621v2", "summary": "Detecting abnormalities in medical images poses unique challenges due to\ndifferences in feature representations and the intricate relationship between\nanatomical structures and abnormalities. This is especially evident in\nmammography, where dense breast tissue can obscure lesions, complicating\nradiological interpretation. Despite leveraging anatomical and semantic\ncontext, existing detection methods struggle to learn effective class-specific\nfeatures, limiting their applicability across different tasks and imaging\nmodalities. In this work, we introduce Exemplar Med-DETR, a novel multi-modal\ncontrastive detector that enables feature-based detection. It employs\ncross-attention with inherently derived, intuitive class-specific exemplar\nfeatures and is trained with an iterative strategy. We achieve state-of-the-art\nperformance across three distinct imaging modalities from four public datasets.\nOn Vietnamese dense breast mammograms, we attain an mAP of 0.7 for mass\ndetection and 0.55 for calcifications, yielding an absolute improvement of 16\npercentage points. Additionally, a radiologist-supported evaluation of 100\nmammograms from an out-of-distribution Chinese cohort demonstrates a twofold\ngain in lesion detection performance. For chest X-rays and angiography, we\nachieve an mAP of 0.25 for mass and 0.37 for stenosis detection, improving\nresults by 4 and 7 percentage points, respectively. These results highlight the\npotential of our approach to advance robust and generalizable detection systems\nfor medical imaging.", "comment": "I am asking for a withdrawal of the paper as I did not have\n  institutional approval to release this paper right now", "pdf_url": "http://arxiv.org/pdf/2507.19621v2", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-30", "AI": {"title_translation": "Exemplar Med-DETR：实现乳腺X线图像及其他医学图像中病灶的泛化和鲁棒检测", "tldr": "提出Exemplar Med-DETR，一种新型多模态对比检测器，利用类特异性范例特征，在多种医学图像模态上实现泛化和鲁棒的病灶检测，并达到SOTA性能。", "motivation": "医学图像中异常检测面临特征表示差异和解剖结构与异常之间复杂关系的挑战，尤其是在乳腺X线图像中，致密乳腺组织会遮蔽病灶。现有方法难以学习有效的类特异性特征，限制了其在不同任务和成像模态中的适用性。", "method": "本研究引入了Exemplar Med-DETR，这是一种新颖的多模态对比检测器，支持基于特征的检测。它利用交叉注意力机制，结合固有的、直观的类特异性范例特征，并采用迭代策略进行训练。", "result": "在来自四个公共数据集的三种不同成像模态上取得了最先进的性能。在越南致密乳腺X线图像上，肿块检测的mAP达到0.7，钙化检测达到0.55，绝对提升了16个百分点。对100张来自分布外中国队列的乳腺X线图像进行放射科医生支持的评估，病灶检测性能提高了两倍。对于胸部X线和血管造影，肿块检测mAP达到0.25，狭窄检测达到0.37，分别提高了4和7个百分点。", "conclusion": "这些结果突出了该方法在推进医学图像领域鲁棒和可泛化检测系统方面的潜力。", "translation": "医学图像中异常检测由于特征表示的差异以及解剖结构与异常之间复杂的关联而面临独特的挑战。这在乳腺X线摄影中尤为明显，致密的乳腺组织可能遮蔽病灶，使放射学解释复杂化。尽管利用了解剖和语义上下文，现有的检测方法仍难以学习有效的类特异性特征，限制了它们在不同任务和成像模态中的适用性。在这项工作中，我们引入了Exemplar Med-DETR，这是一种新颖的多模态对比检测器，能够实现基于特征的检测。它采用交叉注意力机制，结合固有的、直观的类特异性范例特征，并通过迭代策略进行训练。我们在来自四个公共数据集的三种不同成像模态上取得了最先进的性能。在越南致密乳腺X线图像上，我们实现了肿块检测0.7的mAP和钙化检测0.55的mAP，绝对提升了16个百分点。此外，对来自分布外中国队列的100张乳腺X线图像进行放射科医生支持的评估，病灶检测性能提高了两倍。对于胸部X线和血管造影，我们实现了肿块检测0.25的mAP和狭窄检测0.37的mAP，分别将结果提高了4和7个百分点。这些结果突出了我们方法在推进医学图像领域鲁棒和可泛化检测系统方面的潜力。", "summary": "该论文提出了一种名为Exemplar Med-DETR的新型多模态对比检测器，旨在解决医学图像中病灶检测的泛化和鲁棒性挑战。该方法通过引入类特异性范例特征和迭代训练策略，克服了现有方法难以学习有效特征的局限。实验结果表明，Exemplar Med-DETR在乳腺X线、胸部X线和血管造影等多种模态和数据集上均达到了最先进的性能，显著提升了病灶检测的准确性和泛化能力。", "keywords": "医学图像检测, 病灶检测, 对比学习, DETR, 乳腺X线", "comments": "Exemplar Med-DETR的创新之处在于其独特地结合了多模态对比学习和类特异性范例特征，并通过交叉注意力机制实现特征融合。这使其能够有效处理医学图像中特征表示差异大、病灶易被遮蔽的难题。其在多种模态和OOD数据集上的SOTA表现证明了其强大的泛化能力和鲁棒性，对于推动临床医学图像诊断自动化具有重要意义。"}}
{"id": "2507.23009", "title": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead", "authors": ["Tom Sühr", "Florian E. Dorner", "Olawale Salaudeen", "Augustin Kelava", "Samira Samadi"], "categories": ["cs.LG", "cs.AI", "91E45", "I.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23009v1", "summary": "Large Language Models (LLMs) have achieved remarkable results on a range of\nstandardized tests originally designed to assess human cognitive and\npsychological traits, such as intelligence and personality. While these results\nare often interpreted as strong evidence of human-like characteristics in LLMs,\nthis paper argues that such interpretations constitute an ontological error.\nHuman psychological and educational tests are theory-driven measurement\ninstruments, calibrated to a specific human population. Applying these tests to\nnon-human subjects without empirical validation, risks mischaracterizing what\nis being measured. Furthermore, a growing trend frames AI performance on\nbenchmarks as measurements of traits such as ``intelligence'', despite known\nissues with validity, data contamination, cultural bias and sensitivity to\nsuperficial prompt changes. We argue that interpreting benchmark performance as\nmeasurements of human-like traits, lacks sufficient theoretical and empirical\njustification. This leads to our position: Stop Evaluating AI with Human Tests,\nDevelop Principled, AI-specific Tests instead. We call for the development of\nprincipled, AI-specific evaluation frameworks tailored to AI systems. Such\nframeworks might build on existing frameworks for constructing and validating\npsychometrics tests, or could be created entirely from scratch to fit the\nunique context of AI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23009v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "停止用人类测试评估人工智能，转而开发有原则的、人工智能特定的测试", "tldr": "不应使用人类测试评估人工智能，因为这些测试是为人类设计的，将其应用于人工智能会导致误解和有效性问题。应开发有原则的、人工智能特定的测试。", "motivation": "大型语言模型在人类测试中表现出色，但将此解释为类人特征是“本体论错误”。人类测试是针对特定人群校准的理论驱动测量工具，将其应用于非人类主体存在风险。此外，将AI性能解释为“智能”等特征的测量存在有效性、数据污染和文化偏见等问题。", "method": "本文提出一个论点，指出将人类心理和教育测试应用于非人类（AI）而未经实证验证，可能会错误地描述所测量的对象。它强调了当前AI基准测试在解释为衡量类人特征时存在的有效性、数据污染、文化偏见和对提示变化的敏感性等问题。", "result": "论文的结论性立场是：停止使用人类测试评估人工智能，转而开发有原则的、人工智能特定的测试。", "conclusion": "论文呼吁开发针对AI系统量身定制的、有原则的、AI特定的评估框架。这些框架可以借鉴现有心理测量测试的构建和验证方法，也可以完全从头创建以适应AI的独特背景。", "translation": "大型语言模型（LLMs）在一系列最初旨在评估人类认知和心理特征（如智力和人格）的标准化测试中取得了显著成果。尽管这些结果通常被解释为LLMs具有类人特征的有力证据，但本文认为这种解释构成了一种本体论错误。人类心理和教育测试是理论驱动的测量工具，针对特定人类群体进行校准。未经实证验证地将这些测试应用于非人类主体，存在错误描述所测量内容的风险。此外，一种日益增长的趋势是将AI在基准测试上的表现框定为“智能”等特征的测量，尽管已知存在有效性问题、数据污染、文化偏见以及对表面提示变化的敏感性。我们认为，将基准测试表现解释为类人特征的测量，缺乏足够的理论和实证依据。这引出了我们的立场：停止用人类测试评估人工智能，转而开发有原则的、人工智能特定的测试。我们呼吁开发针对AI系统量身定制的、有原则的、AI特定的评估框架。此类框架可以建立在现有心理测量测试的构建和验证框架之上，也可以完全从头创建以适应AI的独特背景。", "summary": "本文主张不应使用为人类设计的测试来评估人工智能，特别是大型语言模型。作者认为，将人类测试应用于AI可能导致对其能力的错误解读，这是一种“本体论错误”。论文指出，当前AI基准测试存在有效性、数据污染和偏见等问题。因此，作者呼吁开发一套全新的、有原则的、专门针对AI系统量身定制的评估框架。", "keywords": "AI评估, 人类测试, 大型语言模型, AI特定测试, 心理测量学", "comments": "该论文提出了一个关于AI评估根本方法的关键且及时的问题，主张超越以人类为中心的方法，转向更严谨、以AI为中心的方法。这对于防止对AI能力的误导性解释和指导负责任的AI发展至关重要。"}}
{"id": "2507.22913", "title": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "authors": ["Jinyu Liu", "Xiaoying Song", "Diana Zhang", "Jason Thomale", "Daqing He", "Lingzi Hong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures, accepted by ASIST 2025", "url": "http://arxiv.org/abs/2507.22913v1", "summary": "Providing subject access to information resources is an essential function of\nany library management system. Large language models (LLMs) have been widely\nused in classification and summarization tasks, but their capability to perform\nsubject analysis is underexplored. Multi-label classification with traditional\nmachine learning (ML) models has been used for subject analysis but struggles\nwith unseen cases. LLMs offer an alternative but often over-generate and\nhallucinate. Therefore, we propose a hybrid framework that integrates\nembedding-based ML models with LLMs. This approach uses ML models to (1)\npredict the optimal number of LCSH labels to guide LLM predictions and (2)\npost-edit the predicted terms with actual LCSH terms to mitigate\nhallucinations. We experimented with LLMs and the hybrid framework to predict\nthe subject terms of books using the Library of Congress Subject Headings\n(LCSH). Experiment results show that providing initial predictions to guide LLM\ngenerations and imposing post-edits result in more controlled and\nvocabulary-aligned outputs.", "comment": "13 pages, 2 figures, accepted by ASIST 2025", "pdf_url": "http://arxiv.org/pdf/2507.22913v1", "cate": "cs.CL", "date": "2025-07-19", "updated": "2025-07-19", "AI": {"title_translation": "主题分析的混合框架：整合基于嵌入的回归模型与大型语言模型", "tldr": "本文提出了一种结合嵌入式机器学习模型和大型语言模型的混合框架，用于主题分析，以解决传统方法和LLM单独使用时的局限性，实验证明该框架能生成更受控且与词汇表对齐的主题词。", "motivation": "为信息资源提供主题访问是图书馆管理系统的基本功能。大型语言模型（LLMs）在分类和摘要任务中应用广泛，但其在主题分析方面的能力尚未充分探索。传统机器学习（ML）模型的多标签分类虽然用于主题分析，但在处理未见过的情况时表现不佳。LLMs提供了一种替代方案，但常出现过度生成和幻觉问题。", "method": "本研究提出了一个混合框架，该框架整合了基于嵌入的机器学习模型与大型语言模型。此方法利用机器学习模型来（1）预测最佳的国会图书馆主题词（LCSH）标签数量以指导LLM的预测，以及（2）对LLM预测的词语进行后编辑，使其与实际的LCSH词语对齐，从而减轻幻觉现象。", "result": "实验结果表明，提供初始预测以指导大型语言模型的生成，并施加后编辑，能够产生更受控且与词汇表对齐的输出。", "conclusion": "该混合框架通过结合机器学习模型对LLM的预测进行指导和后编辑，有效解决了大型语言模型在主题分析中过度生成和幻觉的问题，从而实现了更准确和规范的主题词输出。", "translation": "为信息资源提供主题访问是任何图书馆管理系统的一项基本功能。大型语言模型（LLMs）已广泛应用于分类和摘要任务，但其执行主题分析的能力尚未得到充分探索。传统机器学习（ML）模型的多标签分类已被用于主题分析，但难以处理未见过的情况。LLMs提供了一种替代方案，但经常过度生成和产生幻觉。因此，我们提出了一种混合框架，该框架整合了基于嵌入的ML模型和LLMs。这种方法利用ML模型来（1）预测最佳的LCSH标签数量以指导LLM的预测，以及（2）用实际的LCSH术语对预测的术语进行后编辑，以减轻幻觉。我们使用国会图书馆主题词（LCSH）对书籍的主题词预测进行了LLMs和混合框架的实验。实验结果表明，提供初始预测以指导LLM的生成并施加后编辑，能够产生更受控且与词汇表对齐的输出。", "summary": "本研究提出了一种混合框架，旨在提升大型语言模型在主题分析中的表现。针对传统机器学习模型在处理未见数据时的局限性以及LLM在主题分析中易出现的过度生成和幻觉问题，该框架将基于嵌入的机器学习模型与LLM相结合。具体而言，机器学习模型负责预测最佳主题词数量以引导LLM生成，并对LLM的输出进行后编辑以确保其与规范词汇表（如LCSH）对齐。实验结果证实，该混合方法能有效控制LLM的输出，使其更加准确和符合预期的词汇标准。", "keywords": "主题分析, 混合框架, 大型语言模型, 嵌入式模型, LCSH", "comments": "该论文提出了一种新颖且实用的混合框架，有效地结合了传统机器学习模型的精确性和大型语言模型的生成能力。通过引入预测标签数量指导和后编辑机制，解决了LLM在专业领域（如主题分析）中常见的幻觉和不规范输出问题，对于提升信息组织和检索的自动化水平具有重要意义。"}}
{"id": "2507.23309", "title": "PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving", "authors": ["Xuewei Tang", "Mengmeng Yang", "Tuopu Wen", "Peijin Jia", "Le Cui", "Mingshang Luo", "Kehua Sheng", "Bo Zhang", "Diange Yang", "Kun Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23309v1", "summary": "With the growing interest in autonomous driving, there is an increasing\ndemand for accurate and reliable road perception technologies. In complex\nenvironments without high-definition map support, autonomous vehicles must\nindependently interpret their surroundings to ensure safe and robust\ndecision-making. However, these scenarios pose significant challenges due to\nthe large number, complex geometries, and frequent occlusions of road elements.\nA key limitation of existing approaches lies in their insufficient exploitation\nof the structured priors inherently present in road elements, resulting in\nirregular, inaccurate predictions. To address this, we propose PriorFusion, a\nunified framework that effectively integrates semantic, geometric, and\ngenerative priors to enhance road element perception. We introduce an\ninstance-aware attention mechanism guided by shape-prior features, then\nconstruct a data-driven shape template space that encodes low-dimensional\nrepresentations of road elements, enabling clustering to generate anchor points\nas reference priors. We design a diffusion-based framework that leverages these\nprior anchors to generate accurate and complete predictions. Experiments on\nlarge-scale autonomous driving datasets demonstrate that our method\nsignificantly improves perception accuracy, particularly under challenging\nconditions. Visualization results further confirm that our approach produces\nmore accurate, regular, and coherent predictions of road elements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23309v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "PriorFusion：统一先验融合以实现自动驾驶中稳健的道路感知", "tldr": "PriorFusion是一个统一框架，通过有效整合语义、几何和生成先验，显著提高自动驾驶中道路元素的感知准确性，尤其是在复杂和具有挑战性的条件下。", "motivation": "在没有高精地图支持的复杂环境中，现有自动驾驶道路感知方法由于对道路元素固有的结构化先验利用不足，导致预测不规则和不准确。", "method": "提出PriorFusion框架，通过引入由形状先验特征引导的实例感知注意力机制，构建数据驱动的形状模板空间编码道路元素的低维表示，并通过聚类生成锚点作为参考先验。设计了基于扩散的框架，利用这些先验锚点生成准确和完整的预测。", "result": "在大型自动驾驶数据集上的实验表明，该方法显著提高了感知精度，尤其是在具有挑战性的条件下。可视化结果进一步证实，该方法产生了更准确、规则和连贯的道路元素预测。", "conclusion": "PriorFusion通过有效整合多种先验知识，解决了自动驾驶中道路元素感知不准确和不规则的问题，显著提升了在复杂环境下的感知性能。", "translation": "随着对自动驾驶兴趣的增长，对准确可靠的道路感知技术的需求也日益增加。在没有高精地图支持的复杂环境中，自动驾驶汽车必须独立解释其周围环境，以确保安全和稳健的决策。然而，由于道路元素的数量众多、几何形状复杂以及频繁遮挡，这些场景带来了重大挑战。现有方法的一个关键局限在于它们对道路元素中固有的结构化先验利用不足，导致预测不规则、不准确。为了解决这个问题，我们提出了PriorFusion，一个统一的框架，有效地整合了语义、几何和生成先验，以增强道路元素的感知。我们引入了一种由形状先验特征引导的实例感知注意力机制，然后构建了一个数据驱动的形状模板空间，该空间编码了道路元素的低维表示，从而能够进行聚类以生成锚点作为参考先验。我们设计了一个基于扩散的框架，利用这些先验锚点生成准确和完整的预测。在大型自动驾驶数据集上的实验表明，我们的方法显著提高了感知精度，特别是在具有挑战性的条件下。可视化结果进一步证实，我们的方法产生了更准确、规则和连贯的道路元素预测。", "summary": "PriorFusion是一个为自动驾驶设计的统一框架，旨在通过有效整合语义、几何和生成先验来提升道路元素的感知能力。针对现有方法对结构化先验利用不足导致预测不准确的问题，PriorFusion引入实例感知注意力机制和数据驱动的形状模板空间来生成参考先验锚点。随后，利用基于扩散的框架生成精确且完整的道路元素预测。实验证明，该方法在复杂条件下显著提高了感知准确性，并能产生更规则、连贯的预测。", "keywords": "道路感知, 自动驾驶, 先验融合, 结构化先验, 扩散模型", "comments": "该论文的创新点在于提出了PriorFusion框架，首次统一整合了语义、几何和生成先验来解决自动驾驶中道路感知难题。通过引入实例感知注意力机制和数据驱动的形状模板空间，有效地利用了道路元素的结构化信息，弥补了现有方法的不足。基于扩散的预测框架也很有前景。该研究对于提升自动驾驶在无高精地图环境下的鲁棒性和安全性具有重要意义。"}}
{"id": "2507.23642", "title": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "authors": ["Dustin Carrión-Ojeda", "Stefan Roth", "Simone Schaub-Meyer"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for GCPR 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2507.23642v1", "summary": "Few-shot classification and segmentation (FS-CS) focuses on jointly\nperforming multi-label classification and multi-class segmentation using few\nannotated examples. Although the current state of the art (SOTA) achieves high\naccuracy in both tasks, it struggles with small objects. To overcome this, we\npropose the Efficient Masked Attention Transformer (EMAT), which improves\nclassification and segmentation accuracy, especially for small objects. EMAT\nintroduces three modifications: a novel memory-efficient masked attention\nmechanism, a learnable downscaling strategy, and parameter-efficiency\nenhancements. EMAT outperforms all FS-CS methods on the PASCAL-5$^i$ and\nCOCO-20$^i$ datasets, using at least four times fewer trainable parameters.\nMoreover, as the current FS-CS evaluation setting discards available\nannotations, despite their costly collection, we introduce two novel evaluation\nsettings that consider these annotations to better reflect practical scenarios.", "comment": "Accepted for GCPR 2025. Project page: https://visinf.github.io/emat", "pdf_url": "http://arxiv.org/pdf/2507.23642v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于少样本分类和分割的高效掩蔽注意力Transformer", "tldr": "本文提出了一种名为EMAT的新型Transformer模型，用于少样本分类和分割，尤其擅长处理小目标，并且在PASCAL-5$^i$和COCO-20$^i$数据集上表现优于现有方法，同时参数效率更高。此外，还引入了两种新的评估设置。", "motivation": "当前的少样本分类和分割 (FS-CS) 方法在处理小目标时表现不佳，尽管在多标签分类和多类别分割任务上已达到高准确度。", "method": "本文提出了高效掩蔽注意力Transformer (EMAT)。EMAT引入了三项改进：一种新颖的内存高效掩蔽注意力机制、一种可学习的降尺度策略，以及参数效率增强。此外，还引入了两种新的评估设置，以更好地反映实际场景，这些设置考虑了现有但通常被丢弃的标注。", "result": "EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上超越了所有FS-CS方法，并且使用的可训练参数至少减少了四倍。EMAT提高了分类和分割的准确性，特别是对于小目标。", "conclusion": "EMAT通过其创新的架构和改进的评估设置，有效解决了少样本分类和分割中处理小目标和利用现有标注的挑战，显著提升了性能和效率。", "translation": "少样本分类和分割 (FS-CS) 专注于使用少量标注示例联合执行多标签分类和多类别分割。尽管当前最先进 (SOTA) 的方法在这两项任务中都取得了高准确性，但它们在处理小目标时却表现不佳。为了克服这个问题，我们提出了高效掩蔽注意力Transformer (EMAT)，它提高了分类和分割的准确性，特别是对于小目标。EMAT引入了三项修改：一种新颖的内存高效掩蔽注意力机制、一种可学习的降尺度策略，以及参数效率增强。EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上超越了所有FS-CS方法，并且使用的可训练参数至少减少了四倍。此外，由于当前的FS-CS评估设置丢弃了可用的标注（尽管它们的收集成本很高），我们引入了两种新颖的评估设置，这些设置考虑了这些标注，以更好地反映实际场景。", "summary": "本文提出了一种名为高效掩蔽注意力Transformer (EMAT) 的新模型，用于解决少样本分类和分割 (FS-CS) 中小目标处理的挑战。EMAT通过引入内存高效掩蔽注意力机制、可学习的降尺度策略和参数效率增强来改进性能。实验结果表明，EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上优于现有FS-CS方法，并显著减少了所需参数。此外，作者还提出了两种新的评估设置，以更有效地利用现有标注并更好地模拟实际应用场景。", "keywords": "少样本学习, 分类, 分割, Transformer, 小目标", "comments": "这项研究的创新之处在于提出了EMAT模型，它通过特定的架构改进（内存高效掩蔽注意力、可学习降尺度、参数效率增强）有效地解决了少样本分类和分割中处理小目标的难题，并显著提升了参数效率。此外，引入新的评估设置也具有重要意义，它纠正了现有评估中对标注资源浪费的问题，使得评估结果更贴近实际应用。"}}
{"id": "2411.18659", "title": "DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models", "authors": ["Yudong Zhang", "Ruobing Xie", "Xingwu Sun", "Yiqing Huang", "Jiansheng Chen", "Zhanhui Kang", "Di Wang", "Yu Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM Multimedia 2025", "url": "http://arxiv.org/abs/2411.18659v2", "summary": "Large vision-language models (LVLMs) have demonstrated exceptional\nperformance on complex multimodal tasks. However, they continue to suffer from\nsignificant hallucination issues, including object, attribute, and relational\nhallucinations. To accurately detect these hallucinations, we investigated the\nvariations in cross-modal attention patterns between hallucination and\nnon-hallucination states. Leveraging these distinctions, we developed a\nlightweight detector capable of identifying hallucinations. Our proposed\nmethod, Detecting Hallucinations by Cross-modal Attention Patterns (DHCP), is\nstraightforward and does not require additional LVLM training or extra LVLM\ninference steps. Experimental results show that DHCP achieves remarkable\nperformance in hallucination detection. By offering novel insights into the\nidentification and analysis of hallucinations in LVLMs, DHCP contributes to\nadvancing the reliability and trustworthiness of these models. The code is\navailable at https://github.com/btzyd/DHCP.", "comment": "Accepted by ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2411.18659v2", "cate": "cs.CV", "date": "2024-11-27", "updated": "2025-07-31", "AI": {"title_translation": "DHCP：通过跨模态注意力模式检测大型视觉语言模型中的幻觉", "tldr": "DHCP是一种轻量级检测器，通过分析跨模态注意力模式来有效检测大型视觉语言模型中的幻觉，无需额外训练或推理步骤。", "motivation": "大型视觉语言模型（LVLMs）尽管表现出色，但仍存在严重的幻觉问题（包括物体、属性和关系幻觉），因此需要准确检测这些幻觉。", "method": "研究了幻觉和非幻觉状态下跨模态注意力模式的变化，并利用这些区别开发了一种轻量级检测器——DHCP。该方法不需要额外的LVLM训练或推理步骤。", "result": "实验结果表明，DHCP在幻觉检测方面取得了显著的性能。", "conclusion": "DHCP通过提供检测和分析LVLMs中幻觉的新颖见解，有助于提高这些模型的可靠性和可信度。", "translation": "大型视觉语言模型（LVLMs）在复杂的跨模态任务中表现出卓越的性能。然而，它们仍然面临严重的幻觉问题，包括物体、属性和关系幻觉。为了准确检测这些幻觉，我们研究了幻觉和非幻觉状态下跨模态注意力模式的变化。利用这些区别，我们开发了一种能够识别幻觉的轻量级检测器。我们提出的方法，即通过跨模态注意力模式检测幻觉（DHCP），简单明了，不需要额外的LVLM训练或额外的LVLM推理步骤。实验结果表明，DHCP在幻觉检测方面取得了显著的性能。通过为LVLMs中幻觉的识别和分析提供新颖的见解，DHCP有助于提高这些模型的可靠性和可信度。代码可在https://github.com/btzyd/DHCP获取。", "summary": "本文提出了一种名为DHCP（通过跨模态注意力模式检测幻觉）的轻量级检测器，旨在解决大型视觉语言模型（LVLMs）中普遍存在的幻觉问题。该方法通过分析幻觉和非幻觉状态下跨模态注意力模式的差异来识别幻觉，且无需对LVLM进行额外训练或推理步骤。实验证明DHCP在幻觉检测上表现出色，为提升LVLMs的可靠性提供了新途径。", "keywords": "大型视觉语言模型, 幻觉检测, 跨模态注意力, DHCP, 模型可靠性", "comments": "这篇论文的创新点在于利用LVLMs内部的跨模态注意力模式变化来检测幻觉，而不是依赖外部标注或复杂的训练过程。其轻量级和无需额外训练的特点使其具有很高的实用价值。它为理解和缓解LVLMs中的幻觉问题提供了一个有效且高效的视角。"}}
{"id": "2507.20216", "title": "Dual-Stream Global-Local Feature Collaborative Representation Network for Scene Classification of Mining Area", "authors": ["Shuqi Fan", "Haoyi Wang", "Xianju Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to IJCNN 2025", "url": "http://arxiv.org/abs/2507.20216v2", "summary": "Scene classification of mining areas provides accurate foundational data for\ngeological environment monitoring and resource development planning. This study\nfuses multi-source data to construct a multi-modal mine land cover scene\nclassification dataset. A significant challenge in mining area classification\nlies in the complex spatial layout and multi-scale characteristics. By\nextracting global and local features, it becomes possible to comprehensively\nreflect the spatial distribution, thereby enabling a more accurate capture of\nthe holistic characteristics of mining scenes. We propose a dual-branch fusion\nmodel utilizing collaborative representation to decompose global features into\na set of key semantic vectors. This model comprises three key components:(1)\nMulti-scale Global Transformer Branch: It leverages adjacent large-scale\nfeatures to generate global channel attention features for small-scale\nfeatures, effectively capturing the multi-scale feature relationships. (2)\nLocal Enhancement Collaborative Representation Branch: It refines the attention\nweights by leveraging local features and reconstructed key semantic sets,\nensuring that the local context and detailed characteristics of the mining area\nare effectively integrated. This enhances the model's sensitivity to\nfine-grained spatial variations. (3) Dual-Branch Deep Feature Fusion Module: It\nfuses the complementary features of the two branches to incorporate more scene\ninformation. This fusion strengthens the model's ability to distinguish and\nclassify complex mining landscapes. Finally, this study employs multi-loss\ncomputation to ensure a balanced integration of the modules. The overall\naccuracy of this model is 83.63%, which outperforms other comparative models.\nAdditionally, it achieves the best performance across all other evaluation\nmetrics.", "comment": "Accepted to IJCNN 2025", "pdf_url": "http://arxiv.org/pdf/2507.20216v2", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-31", "AI": {"title_translation": "矿区场景分类的双流全局-局部特征协同表示网络", "tldr": "该论文提出了一种用于矿区场景分类的双分支网络，通过融合全局和局部特征，实现了83.63%的准确率。", "motivation": "矿区场景分类为地质环境监测和资源开发规划提供基础数据。矿区分类面临复杂空间布局和多尺度特征的挑战。", "method": "本文提出了一种双分支融合模型，利用协同表示将全局特征分解为关键语义向量。该模型包含三个关键组件：(1)多尺度全局Transformer分支，用于捕获多尺度全局通道注意力特征；(2)局部增强协同表示分支，用于利用局部特征和重建的语义集细化注意力权重；(3)双分支深度特征融合模块，用于融合两个分支的互补特征。此外，采用多损失计算确保模块平衡集成。", "result": "该模型的总体准确率为83.63%，优于其他对比模型，并在所有其他评估指标上取得了最佳性能。", "conclusion": "所提出的双流全局-局部特征协同表示网络通过集成多尺度全局和细粒度局部信息，有效解决了矿区场景分类的挑战，取得了卓越的性能。", "translation": "矿区场景分类为地质环境监测和资源开发规划提供了准确的基础数据。本研究融合多源数据构建了一个多模态矿山土地覆盖场景分类数据集。矿区分类的一个显著挑战在于其复杂的空间布局和多尺度特征。通过提取全局和局部特征，可以全面反映空间分布，从而更准确地捕捉矿区场景的整体特征。我们提出了一种利用协同表示的双分支融合模型，将全局特征分解为一组关键语义向量。该模型包含三个关键组件：(1)多尺度全局Transformer分支：它利用相邻的大尺度特征为小尺度特征生成全局通道注意力特征，有效捕获多尺度特征关系。(2)局部增强协同表示分支：它通过利用局部特征和重建的关键语义集来细化注意力权重，确保矿区的局部上下文和详细特征得到有效整合。这增强了模型对细粒度空间变化的敏感性。(3)双分支深度特征融合模块：它融合了两个分支的互补特征，以纳入更多的场景信息。这种融合增强了模型区分和分类复杂矿区景观的能力。最后，本研究采用多损失计算以确保模块的平衡集成。该模型的总体准确率为83.63%，优于其他对比模型。此外，它在所有其他评估指标上也取得了最佳性能。", "summary": "本文针对矿区场景分类这一关键的地质环境监测和资源规划任务，提出了一种新颖的双流全局-局部特征协同表示网络。该模型通过集成多尺度全局Transformer分支和局部增强协同表示分支，并采用深度特征融合模块进行融合，有效地处理了矿区复杂的空间布局和多尺度特征。该方法充分利用了全局上下文和细粒度局部细节信息，实现了83.63%的总体准确率，在所有评估指标上均优于其他对比模型。", "keywords": "矿区, 场景分类, 双流网络, 全局-局部特征, 协同表示", "comments": "该论文的创新之处在于其双分支架构，该架构利用协同表示，明确地将全局多尺度特征与局部细粒度细节相结合，并专门针对复杂的矿区场景进行定制。这种结合多损失计算的整体方法，在准确分类此类具有挑战性的地貌方面，展示了显著的进步。"}}
{"id": "2507.23006", "title": "Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction", "authors": ["Zhensheng Yuan", "Haozhi Huang", "Zhen Xiong", "Di Wang", "Guanghua Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23006v1", "summary": "We present a framework that enables fast reconstruction and real-time\nrendering of urban-scale scenes while maintaining robustness against appearance\nvariations across multi-view captures. Our approach begins with scene\npartitioning for parallel training, employing a visibility-based image\nselection strategy to optimize training efficiency. A controllable\nlevel-of-detail (LOD) strategy explicitly regulates Gaussian density under a\nuser-defined budget, enabling efficient training and rendering while\nmaintaining high visual fidelity. The appearance transformation module\nmitigates the negative effects of appearance inconsistencies across images\nwhile enabling flexible adjustments. Additionally, we utilize enhancement\nmodules, such as depth regularization, scale regularization, and antialiasing,\nto improve reconstruction fidelity. Experimental results demonstrate that our\nmethod effectively reconstructs urban-scale scenes and outperforms previous\napproaches in both efficiency and quality. The source code is available at:\nhttps://yzslab.github.io/REUrbanGS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23006v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "城市场景重建的鲁棒高效三维高斯泼溅", "tldr": "提出一种鲁棒高效的框架，用于快速重建和实时渲染具有外观变化的大规模城市场景。", "motivation": "现有方法在处理具有多视角外观变化的城市尺度场景时，可能难以实现快速重建、实时渲染和鲁棒性。", "method": "该框架包括：场景分区以实现并行训练和基于可见性的图像选择；可控的细节层次（LOD）策略以调节高斯密度；外观转换模块以减轻外观不一致性；以及深度正则化、尺度正则化和抗锯齿等增强模块。", "result": "实验结果表明，该方法能有效重建城市尺度场景，并在效率和质量上优于现有方法。", "conclusion": "该研究成功开发了一个鲁棒高效的框架，用于城市场景重建，解决了多视角捕获中的外观变化问题，并实现了快速高质量的渲染。", "translation": "我们提出了一个框架，该框架能够快速重建和实时渲染城市规模的场景，同时保持对多视角捕获中外观变化的鲁棒性。我们的方法首先进行场景分区以实现并行训练，并采用基于可见性的图像选择策略来优化训练效率。一个可控的细节层次（LOD）策略在用户定义的预算下明确调节高斯密度，从而在保持高视觉保真度的同时实现高效的训练和渲染。外观转换模块减轻了图像间外观不一致的负面影响，同时支持灵活调整。此外，我们利用增强模块，如深度正则化、尺度正则化和抗锯齿，以提高重建保真度。实验结果表明，我们的方法能够有效重建城市规模的场景，并在效率和质量上优于现有方法。源代码可在以下网址获取：https://yzslab.github.io/REUrbanGS。", "summary": "本文提出了一个用于城市尺度场景重建的鲁棒高效框架，名为REUrbanGS。该框架通过场景分区、可见性图像选择、可控LOD策略、外观转换模块以及深度、尺度正则化和抗锯齿等增强模块，解决了多视角捕获中的外观变化问题，并实现了快速重建和实时渲染。实验证明，该方法在城市场景重建的效率和质量方面均优于现有方法。", "keywords": "3D高斯泼溅, 城市场景重建, 鲁棒性, 实时渲染, 细节层次", "comments": "这篇论文的创新点在于其结合了多种策略来提升3D高斯泼溅在城市尺度场景重建中的鲁棒性和效率。特别是，针对大规模场景的并行训练分区、解决外观不一致的外观转换模块，以及细致的LOD和增强模块，都体现了对实际应用中复杂问题的深入考虑和有效解决。其重要性在于推动了大规模场景重建技术的发展，使其更适用于真实世界的复杂环境。"}}
{"id": "2507.23734", "title": "RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping", "authors": ["Dongming Wu", "Yanping Fu", "Saike Huang", "Yingfei Liu", "Fan Jia", "Nian Liu", "Feng Dai", "Tiancai Wang", "Rao Muhammad Anwer", "Fahad Shahbaz Khan", "Jianbing Shen"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. The code is at this https URL", "url": "http://arxiv.org/abs/2507.23734v1", "summary": "General robotic grasping systems require accurate object affordance\nperception in diverse open-world scenarios following human instructions.\nHowever, current studies suffer from the problem of lacking reasoning-based\nlarge-scale affordance prediction data, leading to considerable concern about\nopen-world effectiveness. To address this limitation, we build a large-scale\ngrasping-oriented affordance segmentation benchmark with human-like\ninstructions, named RAGNet. It contains 273k images, 180 categories, and 26k\nreasoning instructions. The images cover diverse embodied data domains, such as\nwild, robot, ego-centric, and even simulation data. They are carefully\nannotated with an affordance map, while the difficulty of language instructions\nis largely increased by removing their category name and only providing\nfunctional descriptions. Furthermore, we propose a comprehensive\naffordance-based grasping framework, named AffordanceNet, which consists of a\nVLM pre-trained on our massive affordance data and a grasping network that\nconditions an affordance map to grasp the target. Extensive experiments on\naffordance segmentation benchmarks and real-robot manipulation tasks show that\nour model has a powerful open-world generalization ability. Our data and code\nis available at https://github.com/wudongming97/AffordanceNet.", "comment": "Accepted by ICCV 2025. The code is at\n  https://github.com/wudongming97/AffordanceNet", "pdf_url": "http://arxiv.org/pdf/2507.23734v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "RAGNet：面向通用抓取的大规模基于推理的物体功能性分割基准", "tldr": "构建了RAGNet，一个大规模的基于推理的功能性分割基准，并提出了AffordanceNet框架，以解决通用机器人抓取中缺乏推理数据的问题，实现了强大的开放世界泛化能力。", "motivation": "通用机器人抓取系统需要在开放世界场景中准确感知物体功能性，但现有研究缺乏基于推理的大规模功能性预测数据，导致在开放世界中的有效性受到限制。", "method": "本文构建了一个名为RAGNet的大规模面向抓取的功能性分割基准，包含27.3万张图像、180个类别和2.6万条推理指令。图像覆盖多种数据域，并精心标注了功能性图。语言指令的难度通过移除类别名称并仅提供功能性描述来增加。此外，提出了一个名为AffordanceNet的综合性基于功能性的抓取框架，该框架由一个在我们海量功能性数据上预训练的VLM和一个根据功能性图进行抓取操作的抓取网络组成。", "result": "在功能性分割基准和真实机器人操作任务上的大量实验表明，所提出的模型具有强大的开放世界泛化能力。", "conclusion": "通过构建RAGNet基准和提出AffordanceNet框架，本文成功解决了通用机器人抓取中缺乏推理数据的问题，显著提升了模型在开放世界场景下的功能性感知和抓取能力。", "translation": "通用机器人抓取系统需要在遵循人类指令的多样化开放世界场景中准确感知物体功能性。然而，当前研究面临缺乏基于推理的大规模功能性预测数据的问题，这导致人们对开放世界有效性产生相当大的担忧。为了解决这一限制，我们构建了一个大规模的、面向抓取、具有类人指令的功能性分割基准，命名为RAGNet。它包含27.3万张图像、180个类别和2.6万条推理指令。图像涵盖了多种具身数据领域，如野外、机器人、以自我为中心甚至模拟数据。它们都经过精心标注了功能性图，同时通过删除类别名称并仅提供功能性描述，大大增加了语言指令的难度。此外，我们提出了一个名为AffordanceNet的综合性基于功能性的抓取框架，该框架由一个在我们海量功能性数据上预训练的VLM和一个根据功能性图进行抓取操作的抓取网络组成。在功能性分割基准和真实机器人操作任务上的大量实验表明，我们的模型具有强大的开放世界泛化能力。我们的数据和代码可在https://github.com/wudongming97/AffordanceNet获取。", "summary": "本文针对通用机器人抓取中缺乏基于推理的大规模功能性预测数据的问题，构建了RAGNet基准。RAGNet是一个大规模的、面向抓取的功能性分割数据集，包含多样化的图像和高难度的推理指令。在此基础上，作者提出了AffordanceNet框架，该框架结合了预训练的视觉语言模型和抓取网络，能够利用功能性图实现精确抓取。实验证明，AffordanceNet在开放世界场景下展现出强大的泛化能力。", "keywords": "功能性分割, 机器人抓取, 大规模基准, 开放世界, 推理", "comments": "本文的主要创新在于构建了一个大规模、高质量的基于推理的功能性分割基准RAGNet，这为解决通用机器人抓取中的开放世界泛化问题提供了关键数据支持。同时，提出的AffordanceNet框架结合了数据优势，有效提升了机器人的功能性感知和抓取能力，对于推动具身智能和机器人操作领域的发展具有重要意义。"}}
{"id": "2507.23718", "title": "Informing AI Risk Assessment with News Media: Analyzing National and Political Variation in the Coverage of AI Risks", "authors": ["Mowafak Allaham", "Kimon Kieslich", "Nicholas Diakopoulos"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted to 8th AAAI/ACM Conference on AI, Ethics, and Society (2025)", "url": "http://arxiv.org/abs/2507.23718v1", "summary": "Risk-based approaches to AI governance often center the technological\nartifact as the primary focus of risk assessments, overlooking systemic risks\nthat emerge from the complex interaction between AI systems and society. One\npotential source to incorporate more societal context into these approaches is\nthe news media, as it embeds and reflects complex interactions between AI\nsystems, human stakeholders, and the larger society. News media is influential\nin terms of which AI risks are emphasized and discussed in the public sphere,\nand thus which risks are deemed important. Yet, variations in the news media\nbetween countries and across different value systems (e.g. political\norientations) may differentially shape the prioritization of risks through the\nmedia's agenda setting and framing processes. To better understand these\nvariations, this work presents a comparative analysis of a cross-national\nsample of news media spanning 6 countries (the U.S., the U.K., India,\nAustralia, Israel, and South Africa). Our findings show that AI risks are\nprioritized differently across nations and shed light on how left vs. right\nleaning U.S. based outlets not only differ in the prioritization of AI risks in\ntheir coverage, but also use politicized language in the reporting of these\nrisks. These findings can inform risk assessors and policy-makers about the\nnuances they should account for when considering news media as a supplementary\nsource for risk-based governance approaches.", "comment": "Accepted to 8th AAAI/ACM Conference on AI, Ethics, and Society (2025)", "pdf_url": "http://arxiv.org/pdf/2507.23718v1", "cate": "cs.CY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "利用新闻媒体为人工智能风险评估提供信息：分析人工智能风险报道中的国家和政治差异", "tldr": "本文分析了新闻媒体如何报道AI风险，发现不同国家和政治立场的媒体对AI风险的优先顺序和用语存在差异。", "motivation": "当前的人工智能治理风险评估主要关注技术本身，忽视了AI系统与社会复杂互动产生的系统性风险。新闻媒体作为反映社会背景的重要来源，其报道对AI风险的强调和讨论具有影响力。然而，不同国家和政治价值体系的新闻媒体可能通过议程设置和框架效应，差异化地塑造风险的优先级，因此需要更好地理解这些差异。", "method": "本研究对来自6个国家（美国、英国、印度、澳大利亚、以色列和南非）的新闻媒体样本进行了比较分析。", "result": "研究结果表明，不同国家对人工智能风险的优先级不同。此外，美国左右翼媒体不仅在AI风险报道的优先级上存在差异，而且在报道这些风险时使用了政治化的语言。", "conclusion": "这些发现可以为风险评估人员和政策制定者提供信息，使他们在考虑将新闻媒体作为基于风险的治理方法的补充来源时，能考虑到其中的细微差别。", "translation": "人工智能治理中基于风险的方法通常将技术产物作为风险评估的主要焦点，而忽视了人工智能系统与社会之间复杂互动所产生的系统性风险。将更多社会背景纳入这些方法的一个潜在来源是新闻媒体，因为它内嵌并反映了人工智能系统、人类利益相关者和更广泛社会之间的复杂互动。新闻媒体在哪些人工智能风险在公共领域受到强调和讨论方面具有影响力，从而决定了哪些风险被认为重要。然而，不同国家和不同价值体系（例如政治倾向）之间新闻媒体的差异，可能会通过媒体的议程设置和框架过程，差异化地塑造风险的优先级。为了更好地理解这些差异，本研究对来自6个国家（美国、英国、印度、澳大利亚、以色列和南非）的跨国新闻媒体样本进行了比较分析。我们的研究结果表明，人工智能风险在不同国家之间被赋予了不同的优先级，并揭示了美国左右翼媒体不仅在人工智能风险报道的优先级上存在差异，而且在报道这些风险时使用了政治化的语言。这些发现可以为风险评估人员和政策制定者提供信息，使他们在考虑将新闻媒体作为基于风险的治理方法的补充来源时，能考虑到其中的细微差别。", "summary": "本研究旨在解决当前AI风险评估忽视社会系统性风险的问题，提出新闻媒体是纳入社会背景的重要来源。通过对6个国家新闻媒体的比较分析，研究发现不同国家和政治立场的媒体对AI风险的优先级和报道方式存在显著差异，特别是美国左右翼媒体在风险优先级和语言使用上均有政治化倾向。这些发现对于政策制定者和风险评估者在利用新闻媒体信息时应考虑的细微之处提供了重要参考。", "keywords": "人工智能风险, 新闻媒体, 风险评估, 跨国比较, 政治差异", "comments": "该研究通过引入新闻媒体这一独特的视角，弥补了传统AI风险评估中对社会系统性风险关注不足的缺陷，具有较强的创新性。其跨国比较分析揭示了文化和政治背景对AI风险认知和报道的影响，为AI治理提供了更全面的视角。研究结果强调了在利用新闻媒体信息进行风险评估时，需要充分考虑其潜在的偏见和政治化倾向，这对于制定更具包容性和有效性的AI政策至关重要。未来研究可以进一步探讨不同类型媒体（如社交媒体）对AI风险叙事的影响。"}}
{"id": "2507.23208", "title": "Are Recommenders Self-Aware? Label-Free Recommendation Performance Estimation via Model Uncertainty", "authors": ["Jiayu Li", "Ziyi Ye", "Guohao Jian", "Zhiqiang Guo", "Weizhi Ma", "Qingyao Ai", "Min Zhang"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23208v1", "summary": "Can a recommendation model be self-aware? This paper investigates the\nrecommender's self-awareness by quantifying its uncertainty, which provides a\nlabel-free estimation of its performance. Such self-assessment can enable more\ninformed understanding and decision-making before the recommender engages with\nany users. To this end, we propose an intuitive and effective method,\nprobability-based List Distribution uncertainty (LiDu). LiDu measures\nuncertainty by determining the probability that a recommender will generate a\ncertain ranking list based on the prediction distributions of individual items.\nWe validate LiDu's ability to represent model self-awareness in two settings:\n(1) with a matrix factorization model on a synthetic dataset, and (2) with\npopular recommendation algorithms on real-world datasets. Experimental results\nshow that LiDu is more correlated with recommendation performance than a series\nof label-free performance estimators. Additionally, LiDu provides valuable\ninsights into the dynamic inner states of models throughout training and\ninference. This work establishes an empirical connection between recommendation\nuncertainty and performance, framing it as a step towards more transparent and\nself-evaluating recommender systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23208v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "推荐系统具有自我意识吗？通过模型不确定性进行无标签推荐性能估计", "tldr": "本文提出LiDu方法，通过量化推荐模型不确定性，实现无标签性能估计，为更透明和自我评估的推荐系统迈出一步。", "motivation": "现有推荐系统在与用户交互前缺乏自我评估能力，导致理解和决策不足。本文旨在通过量化模型不确定性来解决这一问题，从而实现无标签的性能估计，以实现更知情的理解和决策。", "method": "提出了一种名为“基于概率的列表分布不确定性 (LiDu)”的方法。LiDu通过根据单个项目的预测分布，确定推荐器生成特定排名列表的概率来衡量不确定性。", "result": "实验结果表明，LiDu与推荐性能的相关性高于一系列无标签性能估计器。此外，LiDu在训练和推理过程中为模型的动态内部状态提供了有价值的见解。", "conclusion": "本研究建立了推荐不确定性与性能之间的经验联系，并将其视为迈向更透明和自我评估的推荐系统的一步。", "translation": "推荐模型能自我感知吗？本文通过量化推荐模型的不确定性来研究其自我意识，这为推荐性能提供了一种无标签的估计方法。这种自我评估可以在推荐器与任何用户交互之前，实现更明智的理解和决策。为此，我们提出了一种直观且有效的方法，即基于概率的列表分布不确定性（LiDu）。LiDu通过根据单个项目的预测分布，确定推荐器生成特定排名列表的概率来衡量不确定性。我们在两种设置下验证了LiDu表示模型自我意识的能力：（1）使用合成数据集上的矩阵分解模型，以及（2）使用真实世界数据集上的流行推荐算法。实验结果表明，LiDu与推荐性能的相关性高于一系列无标签性能估计器。此外，LiDu在整个训练和推理过程中为模型的动态内部状态提供了有价值的见解。这项工作建立了推荐不确定性与性能之间的经验联系，将其视为迈向更透明和自我评估的推荐系统的一步。", "summary": "本文探讨了推荐模型的自我意识问题，提出了一种名为LiDu的无标签性能估计方法。LiDu通过量化模型生成特定排名列表的不确定性来衡量其性能。实验证明LiDu与推荐性能高度相关，且能揭示模型内部状态，为构建更透明和可自我评估的推荐系统提供了新途径。", "keywords": "推荐系统, 模型不确定性, 无标签性能估计, 自我意识, LiDu", "comments": "本文的创新点在于提出了“推荐器自我意识”的概念，并通过量化模型不确定性实现了无标签的性能估计，这对于推荐系统在部署前进行自我评估和优化具有重要意义。LiDu方法的提出为理解推荐系统内部工作机制提供了新的视角，有助于提升系统的透明度和可信度。"}}
{"id": "2502.06210", "title": "Achieving Deep Continual Learning via Evolution", "authors": ["Aojun Lu", "Junchao Ke", "Chunhui Ding", "Jiahao Fan", "Jiancheng Lv", "Yanan Sun"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06210v2", "summary": "Deep neural networks, despite their remarkable success, remain fundamentally\nlimited in their ability to perform Continual Learning (CL). While most current\nmethods aim to enhance the capabilities of a single model, Inspired by the\ncollective learning mechanisms of human populations, we introduce Evolving\nContinual Learning (ECL), a framework that maintains and evolves a diverse\npopulation of neural network models. ECL continually searches for an optimal\narchitecture for each introduced incremental task. This tailored model is\ntrained on the corresponding task and archived as a specialized expert,\ncontributing to a growing collection of skills. This approach inherently\nresolves the core CL challenges: stability is achieved through the isolation of\nexpert models, while plasticity is greatly enhanced by evolving unique,\ntask-specific architectures. Experimental results demonstrate that ECL\nsignificantly outperforms state-of-the-art individual-level CL methods. By\nshifting the focus from individual adaptation to collective evolution, ECL\npresents a novel path toward AI systems capable of CL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06210v2", "cate": "cs.LG", "date": "2025-02-10", "updated": "2025-07-31", "AI": {"title_translation": "通过进化实现深度持续学习", "tldr": "本文提出了ECL框架，通过维护和进化神经网络模型的多样化群体来解决深度持续学习的挑战，通过为每个任务创建专门的专家模型，显著优于现有方法。", "motivation": "尽管深度神经网络取得了显著成功，但在执行持续学习（CL）方面仍然存在根本性限制。大多数当前方法旨在增强单个模型的能力。", "method": "受人类群体集体学习机制的启发，本文引入了进化持续学习（ECL）框架。ECL维护并进化了一个多样化的神经网络模型群体。它持续为每个引入的增量任务搜索最佳架构。这个定制的模型在相应的任务上进行训练，并作为专业专家进行归档，从而形成不断增长的技能集合。", "result": "实验结果表明，ECL显著优于最先进的个体级持续学习方法。", "conclusion": "通过将重点从个体适应转移到集体进化，ECL为能够进行持续学习的AI系统提供了一条新颖的路径。", "translation": "尽管深度神经网络取得了显著成功，但在执行持续学习（CL）方面仍然存在根本性限制。大多数当前方法旨在增强单个模型的能力，受人类群体集体学习机制的启发，我们引入了进化持续学习（ECL），一个维护和进化神经网络模型多样化群体的框架。ECL持续为每个引入的增量任务搜索最佳架构。这个定制的模型在相应的任务上进行训练，并作为专业专家进行归档，从而形成不断增长的技能集合。这种方法固有地解决了核心CL挑战：通过专家模型的隔离实现稳定性，而通过进化独特的、特定于任务的架构大大增强了可塑性。实验结果表明，ECL显著优于最先进的个体级CL方法。通过将重点从个体适应转移到集体进化，ECL为能够进行CL的AI系统提供了一条新颖的路径。", "summary": "本文提出了一种名为进化持续学习（ECL）的新框架，旨在解决深度神经网络在持续学习（CL）方面的局限性。与现有主要关注单个模型的方法不同，ECL受人类集体学习的启发，维护并进化一个多样化的神经网络模型群体。该框架为每个增量任务寻找并训练一个最优的、任务特定的架构作为专家模型，从而实现了稳定性（通过专家模型隔离）和可塑性（通过进化独特架构）。实验证明，ECL在性能上显著超越了现有的个体级CL方法，为实现具备持续学习能力的AI系统开辟了新途径。", "keywords": "持续学习, 深度学习, 进化算法, 神经网络, 集体学习", "comments": "这项工作通过引入“进化”和“群体”的概念，为持续学习领域带来了创新视角，突破了传统上专注于单个模型适应的限制。通过为每个任务创建并隔离专家模型，它有效地解决了持续学习中的稳定性和可塑性困境，具有重要的理论和实践意义。"}}
{"id": "2507.20356", "title": "Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach", "authors": ["Yanming Xiu", "Maria Gorlatova"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures", "url": "http://arxiv.org/abs/2507.20356v2", "summary": "The virtual content in augmented reality (AR) can introduce misleading or\nharmful information, leading to semantic misunderstandings or user errors. In\nthis work, we focus on visual information manipulation (VIM) attacks in AR\nwhere virtual content changes the meaning of real-world scenes in subtle but\nimpactful ways. We introduce a taxonomy that categorizes these attacks into\nthree formats: character, phrase, and pattern manipulation, and three purposes:\ninformation replacement, information obfuscation, and extra wrong information.\nBased on the taxonomy, we construct a dataset, AR-VIM. It consists of 452\nraw-AR video pairs spanning 202 different scenes, each simulating a real-world\nAR scenario. To detect such attacks, we propose a multimodal semantic reasoning\nframework, VIM-Sense. It combines the language and visual understanding\ncapabilities of vision-language models (VLMs) with optical character\nrecognition (OCR)-based textual analysis. VIM-Sense achieves an attack\ndetection accuracy of 88.94% on AR-VIM, consistently outperforming vision-only\nand text-only baselines. The system reaches an average attack detection latency\nof 7.07 seconds in a simulated video processing framework and 7.17 seconds in a\nreal-world evaluation conducted on a mobile Android AR application.", "comment": "11 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.20356v2", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-31", "AI": {"title_translation": "检测增强现实中的视觉信息操纵攻击：一种多模态语义推理方法", "tldr": "本文提出了一种多模态语义推理框架VIM-Sense，用于检测增强现实（AR）中通过虚拟内容改变现实世界场景含义的视觉信息操纵（VIM）攻击，并在自建数据集AR-VIM上取得了88.94%的检测准确率。", "motivation": "增强现实（AR）中的虚拟内容可能引入误导性或有害信息，导致语义误解或用户错误。本文关注视觉信息操纵（VIM）攻击，其中虚拟内容以微妙但有影响力的方式改变现实世界场景的含义。", "method": "本文引入了一种将VIM攻击分为字符、短语和模式操纵三种形式，以及信息替换、信息混淆和额外错误信息三种目的的分类法。基于此分类法，构建了一个包含452对原始AR视频、涵盖202个不同场景的数据集AR-VIM。为检测此类攻击，提出了一种名为VIM-Sense的多模态语义推理框架，该框架结合了视觉-语言模型（VLMs）的语言和视觉理解能力与基于光学字符识别（OCR）的文本分析。", "result": "VIM-Sense在AR-VIM数据集上实现了88.94%的攻击检测准确率，持续优于仅视觉和仅文本的基线方法。该系统在模拟视频处理框架中平均攻击检测延迟为7.07秒，在移动Android AR应用中的真实世界评估中为7.17秒。", "conclusion": "本文提出了一种新的分类法来描述增强现实中的视觉信息操纵攻击，并构建了相应的AR-VIM数据集。在此基础上，开发了VIM-Sense多模态语义推理框架，有效检测了这些攻击，并在准确性和延迟方面表现出色，证明了其在增强现实安全领域的潜力。", "translation": "增强现实（AR）中的虚拟内容可能引入误导性或有害信息，导致语义误解或用户错误。在这项工作中，我们专注于AR中的视觉信息操纵（VIM）攻击，其中虚拟内容以微妙但有影响力的方式改变现实世界场景的含义。我们引入了一种分类法，将这些攻击分为三种形式：字符、短语和模式操纵，以及三种目的：信息替换、信息混淆和额外错误信息。基于该分类法，我们构建了一个数据集AR-VIM。它包含452对原始AR视频，涵盖202个不同的场景，每个场景都模拟一个真实世界的AR情景。为了检测此类攻击，我们提出了一种多模态语义推理框架VIM-Sense。它结合了视觉-语言模型（VLMs）的语言和视觉理解能力与基于光学字符识别（OCR）的文本分析。VIM-Sense在AR-VIM上实现了88.94%的攻击检测准确率，持续优于仅视觉和仅文本的基线方法。该系统在模拟视频处理框架中达到平均攻击检测延迟为7.07秒，在移动Android AR应用程序中进行的真实世界评估中达到7.17秒。", "summary": "本文针对增强现实（AR）中的视觉信息操纵（VIM）攻击，提出了一种新颖的分类法并构建了相应的AR-VIM数据集。为有效检测这些攻击，研究人员开发了VIM-Sense多模态语义推理框架，该框架结合了视觉-语言模型（VLM）和光学字符识别（OCR）技术。实验结果表明，VIM-Sense在AR-VIM数据集上实现了88.94%的攻击检测准确率，并具有较低的检测延迟，显著优于单一模态的基线方法。", "keywords": "增强现实, 视觉信息操纵, 多模态语义推理, VIM-Sense, 数据集", "comments": "该论文的创新点在于提出了针对AR视觉信息操纵攻击的详细分类法，并据此构建了首个相关数据集AR-VIM，这为后续研究奠定了基础。VIM-Sense框架结合了VLM和OCR的多模态方法，有效提升了检测准确率，解决了AR安全领域的一个重要问题。其在真实AR应用中的低延迟表现也显示了实际应用潜力。"}}
{"id": "2507.22890", "title": "Evaluating LLMs for Visualization Generation and Understanding", "authors": ["Saadiq Rauf Khan", "Vinit Chandak", "Sougata Mukherjea"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22890v1", "summary": "Information Visualization has been utilized to gain insights from complex\ndata. In recent times, Large Language models (LLMs) have performed very well in\nmany tasks. In this paper, we showcase the capabilities of different popular\nLLMs to generate code for visualization based on simple prompts. We also\nanalyze the power of LLMs to understand some common visualizations by answering\nquestions. Our study shows that LLMs could generate code for some simpler\nvisualizations such as bar and pie charts. Moreover, they could answer simple\nquestions about visualizations. However, LLMs also have several limitations.\nFor example, some of them had difficulty generating complex visualizations,\nsuch as violin plot. LLMs also made errors in answering some questions about\nvisualizations, for example, identifying relationships between close boundaries\nand determining lengths of shapes. We believe that our insights can be used to\nimprove both LLMs and Information Visualization systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22890v1", "cate": "cs.HC", "date": "2025-06-16", "updated": "2025-06-16", "AI": {"title_translation": "评估大型语言模型在可视化生成和理解方面的能力", "tldr": "本研究评估了大型语言模型（LLMs）在生成可视化代码和理解现有可视化方面的能力。结果显示LLMs可以处理简单的可视化任务，但在复杂可视化生成和精确理解方面仍存在局限。", "motivation": "信息可视化被用于从复杂数据中获取洞察。鉴于大型语言模型（LLMs）在许多任务中表现出色，本文旨在展示和分析LLMs在可视化生成和理解方面的能力。", "method": "研究通过以下方式评估LLMs：1. 展示不同流行LLMs基于简单提示生成可视化代码的能力。2. 分析LLMs通过回答问题来理解常见可视化的能力。", "result": "研究表明，LLMs可以为条形图和饼图等简单可视化生成代码，并能回答关于可视化的简单问题。然而，LLMs在生成小提琴图等复杂可视化方面存在困难，并且在回答关于可视化的问题时（例如识别紧密边界之间的关系和确定形状长度）会犯错。", "conclusion": "本研究的见解可用于改进大型语言模型和信息可视化系统。", "translation": "信息可视化已被用于从复杂数据中获取洞察。近年来，大型语言模型（LLMs）在许多任务中表现出色。在本文中，我们展示了不同流行LLMs根据简单提示生成可视化代码的能力。我们还通过回答问题来分析LLMs理解一些常见可视化的能力。我们的研究表明，LLMs可以为一些简单的可视化（如条形图和饼图）生成代码。此外，它们可以回答关于可视化的简单问题。然而，LLMs也存在一些局限性。例如，其中一些LLMs在生成复杂可视化（如小提琴图）方面存在困难。LLMs在回答一些关于可视化的问题时也犯了错误，例如识别紧密边界之间的关系和确定形状的长度。我们相信我们的见解可以用于改进LLMs和信息可视化系统。", "summary": "本研究评估了大型语言模型（LLMs）在信息可视化领域的应用能力，具体包括生成可视化代码和理解现有可视化。实验结果显示，LLMs能够成功生成简单的可视化图表（如条形图和饼图）的代码，并能回答关于这些图表的简单问题。然而，LLMs在处理复杂可视化（如小提琴图）的生成以及在回答涉及细节（如边界关系、形状长度）的复杂可视化问题时表现出局限性。研究强调了这些发现对于未来改进LLMs和信息可视化系统的重要性。", "keywords": "大型语言模型, 可视化生成, 可视化理解, 信息可视化, 能力评估", "comments": "该论文及时评估了大型语言模型在可视化领域的潜力与局限性，具有重要的实践意义。其创新之处在于同时考察了LLMs在可视化“生成”和“理解”两个维度的表现。研究结果清晰地指出了当前LLMs的优势（简单任务）和不足（复杂任务和细节理解），为后续LLM和信息可视化系统的发展提供了明确的改进方向。"}}
{"id": "2507.23257", "title": "Efficient Machine Unlearning via Influence Approximation", "authors": ["Jiawei Liu", "Chenwang Wu", "Defu Lian", "Enhong Chen"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.23257v1", "summary": "Due to growing privacy concerns, machine unlearning, which aims at enabling\nmachine learning models to ``forget\" specific training data, has received\nincreasing attention. Among existing methods, influence-based unlearning has\nemerged as a prominent approach due to its ability to estimate the impact of\nindividual training samples on model parameters without retraining. However,\nthis approach suffers from prohibitive computational overhead arising from the\nnecessity to compute the Hessian matrix and its inverse across all training\nsamples and parameters, rendering it impractical for large-scale models and\nscenarios involving frequent data deletion requests. This highlights the\ndifficulty of forgetting. Inspired by cognitive science, which suggests that\nmemorizing is easier than forgetting, this paper establishes a theoretical link\nbetween memorizing (incremental learning) and forgetting (unlearning). This\nconnection allows machine unlearning to be addressed from the perspective of\nincremental learning. Unlike the time-consuming Hessian computations in\nunlearning (forgetting), incremental learning (memorizing) typically relies on\nmore efficient gradient optimization, which supports the aforementioned\ncognitive theory. Based on this connection, we introduce the Influence\nApproximation Unlearning (IAU) algorithm for efficient machine unlearning from\nthe incremental perspective. Extensive empirical evaluations demonstrate that\nIAU achieves a superior balance among removal guarantee, unlearning efficiency,\nand comparable model utility, while outperforming state-of-the-art methods\nacross diverse datasets and model architectures. Our code is available at\nhttps://github.com/Lolo1222/IAU.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.23257v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于影响力近似的高效机器学习遗忘", "tldr": "本文提出了一种名为影响力近似遗忘（IAU）的新算法，通过将遗忘问题转化为增量学习来高效实现机器学习遗忘，解决了现有方法计算成本过高的问题，并在效率、遗忘保证和模型效用之间取得了优越的平衡。", "motivation": "由于日益增长的隐私问题，机器学习模型“遗忘”特定训练数据的能力受到了越来越多的关注。现有的基于影响力的方法虽然能够估计单个训练样本对模型参数的影响，但由于需要计算所有训练样本和参数的Hessian矩阵及其逆，计算开销巨大，在大规模模型和频繁数据删除场景中不切实际，这突显了遗忘的难度。", "method": "受认知科学中“记忆比遗忘更容易”的启发，本文建立了记忆（增量学习）和遗忘（非学习）之间的理论联系。这种联系使得机器学习遗忘可以从增量学习的角度来解决。与遗忘中耗时的Hessian计算不同，增量学习通常依赖于更高效的梯度优化。基于此连接，本文提出了影响力近似遗忘（IAU）算法，从增量角度实现高效的机器学习遗忘。", "result": "广泛的实证评估表明，IAU在移除保证、遗忘效率和可比较的模型效用之间取得了卓越的平衡，并且在不同数据集和模型架构上均优于最先进的方法。", "conclusion": "本文通过建立遗忘与增量学习之间的理论联系，并利用增量学习中更高效的梯度优化，成功开发了一种名为影响力近似遗忘（IAU）的高效机器学习遗忘算法，有效解决了现有方法的计算效率问题，并在性能上超越了现有技术。", "translation": "由于日益增长的隐私问题，机器学习遗忘（旨在使机器学习模型“遗忘”特定训练数据）受到了越来越多的关注。在现有方法中，基于影响力的方法因其无需重新训练即可估计单个训练样本对模型参数影响的能力而成为一种突出方法。然而，这种方法面临巨大的计算开销，因为它需要计算所有训练样本和参数的Hessian矩阵及其逆，这使得它对于大规模模型和涉及频繁数据删除请求的场景不切实际。这凸显了遗忘的难度。受认知科学中“记忆比遗忘更容易”的启发，本文建立了记忆（增量学习）和遗忘（非学习）之间的理论联系。这种联系使得机器学习遗忘可以从增量学习的角度来解决。与遗忘中耗时的Hessian计算不同，增量学习（记忆）通常依赖于更高效的梯度优化，这支持了上述认知理论。基于这种联系，我们引入了影响力近似遗忘（IAU）算法，用于从增量角度实现高效的机器学习遗忘。广泛的实证评估表明，IAU在移除保证、遗忘效率和可比较的模型效用之间取得了优越的平衡，同时在不同数据集和模型架构上均优于最先进的方法。我们的代码可在 https://github.com/Lolo1222/IAU 获取。", "summary": "该论文针对机器学习遗忘中现有影响力方法计算成本过高的问题，提出了一种名为影响力近似遗忘（IAU）的新算法。受认知科学启发，作者建立了遗忘（unlearning）与增量学习（incremental learning）之间的理论联系，并利用增量学习中更高效的梯度优化来避免耗时的Hessian计算。实验结果表明，IAU在遗忘保证、效率和模型效用之间取得了优越的平衡，并超越了现有SOTA方法。", "keywords": "机器学习遗忘, 影响力近似, 增量学习, 计算效率, 隐私保护", "comments": "本文的创新点在于将机器学习遗忘问题与增量学习联系起来，并利用增量学习中更高效的梯度优化方法来解决遗忘过程中Hessian矩阵计算的巨大开销，这提供了一个新颖且高效的视角。其重要性体现在解决了大规模模型和频繁数据删除场景下机器学习遗忘的实际应用瓶颈，对隐私保护和模型可控性具有重要意义。"}}
{"id": "2507.23013", "title": "Stabilization of Age-Structured Competing Populations", "authors": ["Carina Veil", "Miroslav Krstić", "Patrick McNamee", "Oliver Sawodny"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      submitted to IFAC Automatica", "url": "http://arxiv.org/abs/2507.23013v1", "summary": "Age-structured models represent the dynamic behaviors of populations over\ntime and result in integro-partial differential equations (IPDEs). Such\nprocesses arise in biotechnology, economics, demography, and other domains.\nCoupled age-structured IPDE population dynamics with two or more species occur\nin epidemiology and ecology, but have received little attention thus far. This\nwork considers an exponentially unstable model of two competing predator\npopulations, formally referred to in the literature as ''competition''\ndynamics. If one were to apply an input that simultaneously harvests both\npredator species, one would have control over only the product of the densities\nof the species, not over their ratio. Therefore, it is necessary to design a\ncontrol input that directly harvests only one of the two predator species,\nwhile indirectly influencing the other via a backstepping approach. The model\nis transformed into a system of two coupled ordinary differential equations\n(ODEs), of which only one is actuated, and two autonomous, exponentially stable\nintegral delay equations (IDEs) which enter the ODEs as nonlinear disturbances.\nThe ODEs are globally stabilized with backstepping and an estimate of the\nregion of attraction of the asymptotically stabilized equilibrium of the full\nIPDE system is provided, under a positivity restriction on control. These\ngeneralizations open exciting possibilities for future research directions,\nsuch as investigating population systems with more than two species.", "comment": "submitted to IFAC Automatica", "pdf_url": "http://arxiv.org/pdf/2507.23013v1", "cate": "eess.SY", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "年龄结构竞争种群的稳定性", "tldr": "该研究提出了一种控制输入，通过反步法稳定了指数不稳定的年龄结构竞争捕食者种群模型，将IPDE系统转化为ODE和IDE系统并进行了全局稳定。", "motivation": "年龄结构模型在生物技术、经济学、人口学等领域有重要应用，但耦合的年龄结构IPDE种群动力学，特别是包含两个或更多物种的竞争模型，迄今为止受到的关注很少。现有的控制方法无法有效控制物种密度比率，因此需要设计一种新的控制输入来稳定系统。", "method": "该研究考虑了一个指数不稳定的两个竞争捕食者种群模型。通过反步法，设计了一种控制输入，直接控制其中一个捕食者物种，间接影响另一个。模型被转换为两个耦合的常微分方程（ODE）系统和一个驱动的方程，以及两个自主的、指数稳定的积分延迟方程（IDE），后者作为非线性扰动进入ODE。ODE系统通过反步法实现全局稳定。", "result": "ODE系统通过反步法实现了全局稳定。在控制输入为正的限制下，提供了完整IPDE系统渐近稳定平衡点的吸引域估计。这些泛化为未来的研究方向，如研究包含两个以上物种的种群系统，开辟了激动人心的可能性。", "conclusion": "该研究成功地通过反步法稳定了指数不稳定的年龄结构竞争捕食者种群模型，并为未来的多物种种群系统研究奠定了基础。", "translation": "年龄结构模型代表了种群随时间变化的动态行为，并导致了积分-偏微分方程（IPDEs）。此类过程出现在生物技术、经济学、人口学和其他领域。包含两个或更多物种的耦合年龄结构IPDE种群动力学出现在流行病学和生态学中，但迄今为止受到的关注很少。这项工作考虑了一个指数不稳定的两个竞争捕食者种群模型，在文献中正式称为“竞争”动力学。如果应用一个同时捕获两个捕食者物种的输入，则只能控制物种密度的乘积，而不能控制它们的比率。因此，有必要设计一种控制输入，直接捕获两个捕食者物种中的一个，同时通过反步法间接影响另一个。该模型被转换为两个耦合常微分方程（ODE）系统，其中只有一个被驱动，以及两个自主的、指数稳定的积分延迟方程（IDE），它们作为非线性扰动进入ODE。ODE在反步法下实现了全局稳定，并在控制为正的限制下，提供了完整IPDE系统渐近稳定平衡点的吸引域估计。这些泛化为未来的研究方向，例如研究包含两个以上物种的种群系统，开辟了激动人心的可能性。", "summary": "该研究旨在稳定指数不稳定的年龄结构竞争捕食者种群模型。针对现有控制方法无法有效控制物种密度比率的问题，作者提出了一种基于反步法的控制策略。该策略通过直接干预一个物种，间接影响另一个物种，将复杂的积分-偏微分方程（IPDE）模型转化为更易处理的常微分方程（ODE）和积分延迟方程（IDE）系统。实验结果表明，该方法能够全局稳定ODE系统，并估算了完整IPDE系统的吸引域，为多物种种群系统的未来研究提供了新的方向。", "keywords": "年龄结构模型, 竞争种群, 反步法, 稳定性, 积分-偏微分方程", "comments": "该论文的创新点在于将复杂的年龄结构IPDE模型通过巧妙的控制策略（反步法）转化为更易于分析和控制的ODE和IDE系统，解决了现有方法在控制竞争种群密度比率上的不足。其重要性在于为生物、经济等领域中年龄结构种群的稳定控制提供了新的理论和方法，并为未来多物种系统的研究开辟了道路。"}}
{"id": "2507.23447", "title": "Adjustable Spatio-Spectral Hyperspectral Image Compression Network", "authors": ["Martin Hermann Paul Fuchs", "Behnood Rasti", "Begüm Demir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23447v1", "summary": "With the rapid growth of hyperspectral data archives in remote sensing (RS),\nthe need for efficient storage has become essential, driving significant\nattention toward learning-based hyperspectral image (HSI) compression. However,\na comprehensive investigation of the individual and joint effects of spectral\nand spatial compression on learning-based HSI compression has not been\nthoroughly examined yet. Conducting such an analysis is crucial for\nunderstanding how the exploitation of spectral, spatial, and joint\nspatio-spectral redundancies affects HSI compression. To address this issue, we\npropose Adjustable Spatio-Spectral Hyperspectral Image Compression Network\n(HyCASS), a learning-based model designed for adjustable HSI compression in\nboth spectral and spatial dimensions. HyCASS consists of six main modules: 1)\nspectral encoder; 2) spatial encoder; 3) compression ratio (CR) adapter\nencoder; 4) CR adapter decoder; 5) spatial decoder; and 6) spectral decoder\nmodule. The modules employ convolutional layers and transformer blocks to\ncapture both short-range and long-range redundancies. Experimental results on\ntwo HSI benchmark datasets demonstrate the effectiveness of our proposed\nadjustable model compared to existing learning-based compression models. Based\non our results, we establish a guideline for effectively balancing spectral and\nspatial compression across different CRs, taking into account the spatial\nresolution of the HSIs. Our code and pre-trained model weights are publicly\navailable at https://git.tu-berlin.de/rsim/hycass .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23447v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "可调节空-谱高光谱图像压缩网络", "tldr": "提出HyCASS，一个可调节空-谱高光谱图像压缩网络，有效平衡空谱压缩，并为不同压缩比下的空谱压缩平衡提供指导方针。", "motivation": "随着遥感高光谱数据档案的快速增长，高效存储变得至关重要。然而，现有学习型高光谱图像（HSI）压缩对谱和空间压缩的单独和联合效应尚未得到全面深入研究，这对于理解空谱冗余如何影响HSI压缩至关重要。", "method": "提出了一种名为HyCASS（Adjustable Spatio-Spectral Hyperspectral Image Compression Network）的基于学习的模型，旨在实现谱和空间维度上的可调节HSI压缩。HyCASS由六个主要模块组成：谱编码器、空间编码器、压缩比（CR）适配器编码器、CR适配器解码器、空间解码器和谱解码器模块。这些模块采用卷积层和Transformer块来捕获短程和长程冗余。", "result": "在两个HSI基准数据集上的实验结果表明，所提出的可调节模型与现有基于学习的压缩模型相比是有效的。", "conclusion": "根据实验结果，建立了有效平衡不同压缩比下谱和空间压缩的指导方针，同时考虑了HSIs的空间分辨率。", "translation": "随着遥感（RS）中高光谱数据档案的快速增长，对高效存储的需求变得至关重要，这促使人们对基于学习的高光谱图像（HSI）压缩给予了极大的关注。然而，目前尚未对谱和空间压缩在基于学习的HSI压缩中的单独和联合效应进行全面深入的研究。进行这样的分析对于理解如何利用谱、空间和联合空-谱冗余影响HSI压缩至关重要。为了解决这个问题，我们提出了可调节空-谱高光谱图像压缩网络（HyCASS），这是一个基于学习的模型，旨在实现谱和空间维度上的可调节HSI压缩。HyCASS由六个主要模块组成：1）谱编码器；2）空间编码器；3）压缩比（CR）适配器编码器；4）CR适配器解码器；5）空间解码器；和6）谱解码器模块。这些模块采用卷积层和Transformer块来捕获短程和长程冗余。在两个HSI基准数据集上的实验结果表明，我们提出的可调节模型与现有基于学习的压缩模型相比是有效的。根据我们的结果，我们为有效地平衡不同CR下的谱和空间压缩建立了指导方针，同时考虑了HSIs的空间分辨率。我们的代码和预训练模型权重已在https://git.tu-berlin.de/rsim/hycass 公开可用。", "summary": "本文针对遥感高光谱数据高效存储的需求，提出了可调节空-谱高光谱图像压缩网络（HyCASS），以解决现有学习型模型对空谱压缩联合效应研究不足的问题。HyCASS是一个基于学习的模型，包含谱和空间编码器、解码器以及压缩比适配器等六个模块，利用卷积层和Transformer块捕捉空程和长程冗余。实验证明，HyCASS在两个HSI基准数据集上表现出有效性，并且论文基于此建立了在不同压缩比下平衡空谱压缩的指导方针。", "keywords": "高光谱图像压缩, 空谱压缩, 深度学习, 遥感, HyCASS", "comments": "该论文的创新点在于提出了一个可调节空-谱压缩的深度学习模型HyCASS，并首次全面研究了空谱压缩的单独和联合效应。通过结合卷积层和Transformer块，模型能够有效捕获不同尺度的冗余。此外，论文还为平衡空谱压缩提供了实用指导，这对于实际应用具有重要意义。代码和模型权重的公开也促进了研究的可重复性和进一步发展。"}}
{"id": "2507.23778", "title": "Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions", "authors": ["Li Siyao", "Yao Feng", "Omid Tehari", "Chen Change Loy", "Michael J. Black"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23778v1", "summary": "While current general-purpose 3D human models (e.g., SMPL-X) efficiently\nrepresent accurate human shape and pose, they lacks the ability to physically\ninteract with the environment due to the kinematic nature. As a result,\nkinematic-based interaction models often suffer from issues such as\ninterpenetration and unrealistic object dynamics. To address this limitation,\nwe introduce a novel approach that embeds SMPL-X into a tangible entity capable\nof dynamic physical interactions with its surroundings. Specifically, we\npropose a \"half-physics\" mechanism that transforms 3D kinematic motion into a\nphysics simulation. Our approach maintains kinematic control over inherent\nSMPL-X poses while ensuring physically plausible interactions with scenes and\nobjects, effectively eliminating penetration and unrealistic object dynamics.\nUnlike reinforcement learning-based methods, which demand extensive and complex\ntraining, our half-physics method is learning-free and generalizes to any body\nshape and motion; meanwhile, it operates in real time. Moreover, it preserves\nthe fidelity of the original kinematic motion while seamlessly integrating\nphysical interactions", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23778v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "半物理：使运动学3D人体模型具备物理交互能力", "tldr": "本文提出了一种“半物理”机制，将3D运动学人体模型（如SMPL-X）转化为可进行物理交互的实体，解决了现有运动学模型在环境交互中出现的穿透和不真实物体动力学问题，该方法无需学习、实时运行并能泛化到任何体型和动作。", "motivation": "当前通用3D人体模型（如SMPL-X）虽然能有效表示准确的人体形状和姿态，但由于其运动学性质，缺乏与环境进行物理交互的能力，导致基于运动学的交互模型常出现穿透和不真实的物体动力学问题。", "method": "我们引入了一种新颖的方法，将SMPL-X嵌入到一个能够与周围环境进行动态物理交互的实体中。具体来说，我们提出了一种“半物理”机制，将3D运动学动作转换为物理模拟。", "result": "我们的方法在保持固有SMPL-X姿态的运动学控制的同时，确保了与场景和物体的物理可信交互，有效消除了穿透和不真实的物体动力学。与基于强化学习的方法不同，我们的半物理方法无需学习，能够泛化到任何体型和动作，并且实时运行。此外，它在无缝集成物理交互的同时，保留了原始运动学的保真度。", "conclusion": "本文提出的“半物理”机制成功地将运动学3D人体模型转换为能够进行真实物理交互的实体，有效解决了现有运动学模型在环境交互中的局限性，实现了无穿透、真实动力学、实时、无需学习且泛化性强的效果。", "translation": "尽管当前通用3D人体模型（例如SMPL-X）能够有效地表示精确的人体形状和姿态，但由于其运动学性质，它们缺乏与环境进行物理交互的能力。因此，基于运动学的交互模型常常面临穿透和不真实物体动力学等问题。为了解决这一局限性，我们引入了一种新颖的方法，将SMPL-X嵌入到一个能够与周围环境进行动态物理交互的实体中。具体来说，我们提出了一种“半物理”机制，将3D运动学动作转换为物理模拟。我们的方法在保持固有SMPL-X姿态的运动学控制的同时，确保了与场景和物体的物理可信交互，有效消除了穿透和不真实的物体动力学。与需要大量复杂训练的基于强化学习的方法不同，我们的半物理方法无需学习，能够泛化到任何体型和动作；同时，它能实时运行。此外，它在无缝集成物理交互的同时，保留了原始运动学的保真度。", "summary": "本文提出了一种“半物理”方法，旨在解决现有运动学3D人体模型（如SMPL-X）缺乏物理交互能力的问题。该方法将运动学动作转化为物理模拟，使SMPL-X模型能够与环境进行真实的物理交互，有效避免了穿透和不真实的物体动力学。与依赖大量训练的强化学习方法不同，该方法无需学习，实时运行，并能泛化到不同的体型和动作，同时保持原始运动的保真度。", "keywords": "半物理, 3D人体模型, 物理交互, SMPL-X, 运动学", "comments": "这项工作具有重要的创新性，它提出了一种无需学习的“半物理”机制，有效弥补了运动学3D人体模型在物理交互方面的不足。其能够在保持运动学控制的同时，实现真实的物理交互，并且具有实时性、泛化性和无需训练的优点，这在虚拟现实、动画和机器人等领域具有广泛的应用潜力。"}}
{"id": "2507.20414", "title": "Indian Sign Language Detection for Real-Time Translation using Machine Learning", "authors": ["Rajat Singhal", "Jatin Gupta", "Akhil Sharma", "Anushka Gupta", "Navya Sharma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, 2 tables. Published in Proceedings of the 6th International Conference on Recent Advances in Information Technology (RAIT), 2025, IEEE", "url": "http://arxiv.org/abs/2507.20414v2", "summary": "Gestural language is used by deaf & mute communities to communicate through\nhand gestures & body movements that rely on visual-spatial patterns known as\nsign languages. Sign languages, which rely on visual-spatial patterns of hand\ngestures & body movements, are the primary mode of communication for deaf &\nmute communities worldwide. Effective communication is fundamental to human\ninteraction, yet individuals in these communities often face significant\nbarriers due to a scarcity of skilled interpreters & accessible translation\ntechnologies. This research specifically addresses these challenges within the\nIndian context by focusing on Indian Sign Language (ISL). By leveraging machine\nlearning, this study aims to bridge the critical communication gap for the deaf\n& hard-of-hearing population in India, where technological solutions for ISL\nare less developed compared to other global sign languages. We propose a\nrobust, real-time ISL detection & translation system built upon a Convolutional\nNeural Network (CNN). Our model is trained on a comprehensive ISL dataset &\ndemonstrates exceptional performance, achieving a classification accuracy of\n99.95%. This high precision underscores the model's capability to discern the\nnuanced visual features of different signs. The system's effectiveness is\nrigorously evaluated using key performance metrics, including accuracy, F1\nscore, precision & recall, ensuring its reliability for real-world\napplications. For real-time implementation, the framework integrates MediaPipe\nfor precise hand tracking & motion detection, enabling seamless translation of\ndynamic gestures. This paper provides a detailed account of the model's\narchitecture, the data preprocessing pipeline & the classification methodology.\nThe research elaborates the model architecture, preprocessing & classification\nmethodologies for enhancing communication in deaf & mute communities.", "comment": "7 pages, 6 figures, 2 tables. Published in Proceedings of the 6th\n  International Conference on Recent Advances in Information Technology (RAIT),\n  2025, IEEE", "pdf_url": "http://arxiv.org/pdf/2507.20414v2", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-31", "AI": {"title_translation": "基于机器学习的印度手语实时翻译检测", "tldr": "本研究提出并开发了一个基于卷积神经网络（CNN）的实时印度手语（ISL）检测与翻译系统，通过MediaPipe集成实现手部追踪，并在ISL数据集上取得了99.95%的分类准确率，旨在弥合印度聋哑社区的沟通鸿沟。", "motivation": "全球聋哑社区依靠手语进行交流，但由于熟练译员的稀缺和可及翻译技术的不足，他们面临严重的沟通障碍。特别是在印度，印度手语（ISL）的技术解决方案相对不发达，本研究旨在解决印度聋哑和听障人群的关键沟通问题。", "method": "本研究提出一个基于卷积神经网络（CNN）的鲁棒实时印度手语（ISL）检测与翻译系统。该模型在一个综合的ISL数据集上进行训练，并整合MediaPipe进行精确的手部追踪和动作检测，以实现动态手势的无缝翻译。论文详细阐述了模型的架构、数据预处理流程和分类方法。", "result": "该模型在ISL数据集上表现出色，实现了99.95%的分类准确率。系统通过准确率、F1分数、精确度和召回率等关键性能指标进行了严格评估，确保了其在实际应用中的可靠性。", "conclusion": "本研究开发的基于CNN的实时印度手语检测与翻译系统，以其高精度和鲁棒性，有效弥合了印度聋哑和听障人群的沟通鸿沟，为增强这些社区的交流能力提供了重要的技术解决方案。", "translation": "手势语言被聋哑社区用于通过手势和身体动作进行交流，这些动作依赖于被称为手语的视觉空间模式。手语依赖于手势和身体动作的视觉空间模式，是全球聋哑社区的主要交流方式。有效的沟通是人类互动的基本要素，然而，这些社区中的个体由于熟练译员的稀缺和可及翻译技术的不足，常常面临重大的障碍。本研究通过专注于印度手语（ISL），专门解决了印度背景下的这些挑战。通过利用机器学习，本研究旨在弥合印度聋哑和听障人群的关键沟通鸿沟，因为与其他全球手语相比，ISL的技术解决方案发展较少。我们提出了一个基于卷积神经网络（CNN）的鲁棒、实时ISL检测和翻译系统。我们的模型在一个综合的ISL数据集上进行训练，并展示了卓越的性能，实现了99.95%的分类准确率。这种高精度突显了模型识别不同手势细微视觉特征的能力。系统使用包括准确率、F1分数、精确度和召回率在内的关键性能指标进行了严格评估，确保其在实际应用中的可靠性。为了实时实现，该框架集成了MediaPipe以进行精确的手部追踪和动作检测，从而实现动态手势的无缝翻译。本文详细介绍了模型的架构、数据预处理流程和分类方法。该研究阐述了模型架构、预处理和分类方法，以增强聋哑社区的沟通能力。", "summary": "本研究旨在解决印度聋哑社区在印度手语（ISL）交流中面临的挑战，因为现有技术解决方案不发达。作者提出了一个基于卷积神经网络（CNN）的实时ISL检测与翻译系统。该系统在一个综合的ISL数据集上进行训练，并利用MediaPipe进行手部追踪。实验结果显示，该模型达到了99.95%的分类准确率，并通过多项性能指标验证了其在实际应用中的可靠性。这项工作为弥合印度聋哑人群的沟通鸿沟提供了一个有效且高精度的技术方案。", "keywords": "印度手语, 机器学习, 实时翻译, 卷积神经网络, MediaPipe", "comments": "这项研究的创新之处在于其专注于印度手语（ISL）这一特定且欠开发的领域，并提出了一个端到端的实时翻译系统。99.95%的分类准确率是一个非常高的成就，表明了模型在识别细微手势方面的强大能力。结合MediaPipe进行实时手部追踪，增强了系统的实际应用价值。该研究对于促进印度聋哑社区的包容性和沟通具有重要意义。"}}
{"id": "2507.23419", "title": "WiRM: Wireless Respiration Monitoring Using Conjugate Multiple Channel State Information and Fast Iterative Filtering in Wi-Fi Systems", "authors": ["James Rhodes", "Lawrence Ong", "Duy T. Ngo"], "categories": ["cs.ET", "eess.SP"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23419v1", "summary": "Monitoring respiratory health with the use of channel state information (CSI)\nhas shown promising results. Many existing methods focus on monitoring only the\nrespiratory rate, while others focus on monitoring the motion of the chest as a\npatient breathes, which is referred to as the respiratory waveform. This paper\npresents WiRM, a two-staged approach to contactless respiration monitoring. In\nthe first stage, WiRM improves upon existing respiratory rate estimation\ntechniques by using conjugate multiplication for phase sanitisation and\nadaptive multi-trace carving (AMTC) for tracing how the respiratory rate\nchanges over time. When compared against three state-of-the-art methods, WiRM\nhas achieved an average reduction of $38\\%$ in respiratory rate root mean\nsquared error (RMSE). In the second stage, WiRM uses this improved respiratory\nrate estimate to inform the decomposition and selection of the respiratory\nwaveform from the CSI data. Remarkably, WiRM delivers a $178.3\\%$ improvement\nin average absolute correlation with the ground truth respiratory waveform.\nWithin the literature, it is difficult to compare the robustness of existing\nalgorithms in noisy environments. In this paper, we develop a purpose-built\nsimulation toolkit to evaluate the robustness of respiration monitoring\nsolutions under various noise conditions, including thermal, multiplicative,\nand phase noise. Our results show that WiRM demonstrates improved or comparable\nresilience to these common noise sources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23419v1", "cate": "cs.ET", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "WiRM：基于共轭多信道状态信息和Wi-Fi系统中快速迭代滤波的无线呼吸监测", "tldr": "WiRM是一种非接触式呼吸监测方法，通过改进呼吸频率估计和呼吸波形提取，显著提高了监测精度和抗噪声能力，并在噪声环境下表现出更强的鲁棒性。", "motivation": "现有基于CSI的呼吸监测方法多侧重于呼吸频率或胸部运动监测，且难以在噪声环境下比较算法的鲁棒性。因此，需要一种更精确、更全面的非接触式呼吸监测解决方案。", "method": "WiRM采用两阶段方法：第一阶段通过共轭乘法进行相位净化和自适应多轨迹雕刻（AMTC）来改进呼吸频率估计；第二阶段利用改进的呼吸频率估计指导CSI数据中呼吸波形的分解和选择。此外，还开发了一个专门的仿真工具包，用于评估在热噪声、乘性噪声和相位噪声等各种噪声条件下的解决方案鲁棒性。", "result": "与三种现有先进方法相比，WiRM使呼吸频率的均方根误差（RMSE）平均降低了38%。呼吸波形与真实值的平均绝对相关性提高了178.3%。研究结果还表明，WiRM对常见的噪声源（包括热噪声、乘性噪声和相位噪声）表现出改进或相当的弹性。", "conclusion": "WiRM在非接触式呼吸监测方面取得了显著进展，通过其两阶段方法显著提高了呼吸频率估计和呼吸波形提取的精度，并展示了在各种噪声环境下的强大鲁棒性。", "translation": "利用信道状态信息（CSI）监测呼吸健康已显示出可喜的成果。许多现有方法仅关注监测呼吸频率，而另一些方法则关注监测患者呼吸时胸部的运动，这被称为呼吸波形。本文提出了WiRM，一种两阶段的非接触式呼吸监测方法。在第一阶段，WiRM通过使用共轭乘法进行相位净化和自适应多轨迹雕刻（AMTC）来追踪呼吸频率随时间的变化，从而改进了现有的呼吸频率估计技术。与三种最先进的方法相比，WiRM使呼吸频率的均方根误差（RMSE）平均降低了38%。在第二阶段，WiRM利用这种改进的呼吸频率估计来指导CSI数据中呼吸波形的分解和选择。值得注意的是，WiRM使呼吸波形与真实值的平均绝对相关性提高了178.3%。在现有文献中，很难比较现有算法在嘈杂环境中的鲁棒性。在本文中，我们开发了一个专门的仿真工具包，用于评估呼吸监测解决方案在各种噪声条件下的鲁棒性，包括热噪声、乘性噪声和相位噪声。我们的结果表明，WiRM对这些常见噪声源表现出改进或相当的弹性。", "summary": "WiRM是一种基于Wi-Fi CSI的两阶段非接触式呼吸监测系统。它在第一阶段通过共轭乘法和自适应多轨迹雕刻（AMTC）改进呼吸频率估计，使RMSE平均降低38%。在第二阶段，WiRM利用改进的频率信息指导呼吸波形提取，实现了与真实呼吸波形平均绝对相关性178.3%的提升。此外，该研究开发了一个仿真工具包，证明WiRM对热噪声、乘性噪声和相位噪声等常见噪声源具有更强的鲁棒性或相当的弹性。", "keywords": "呼吸监测, CSI, Wi-Fi, 呼吸频率, 呼吸波形", "comments": "WiRM的创新之处在于其精巧的两阶段设计，尤其是在第一阶段通过共轭乘法和AMTC显著提升了呼吸频率估计的精度，这为后续的呼吸波形提取奠定了坚实基础。其在呼吸频率RMSE上38%的显著降低以及呼吸波形相关性178.3%的巨大提升，充分证明了方法的有效性和优越性。此外，开发专门的仿真工具包以评估噪声鲁棒性，填补了现有研究在这一方面的空白，极大地增强了WiRM在实际复杂环境中的应用潜力。"}}
{"id": "2507.23206", "title": "Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images", "authors": ["Xiaoyu Ji", "Ali Shakouri", "Fengqing Zhu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23206v1", "summary": "Food crystal agglomeration is a phenomenon occurs during crystallization\nwhich traps water between crystals and affects food product quality. Manual\nannotation of agglomeration in 2D microscopic images is particularly difficult\ndue to the transparency of water bonding and the limited perspective focusing\non a single slide of the imaged sample. To address this challenge, we first\npropose a supervised baseline model to generate segmentation pseudo-labels for\nthe coarsely labeled classification dataset. Next, an instance classification\nmodel that simultaneously performs pixel-wise segmentation is trained. Both\nmodels are used in the inference stage to combine their respective strengths in\nclassification and segmentation. To preserve crystal properties, a post\nprocessing module is designed and included to both steps. Our method improves\ntrue positive agglomeration classification accuracy and size distribution\npredictions compared to other existing methods. Given the variability in\nconfidence levels of manual annotations, our proposed method is evaluated under\ntwo confidence levels and successfully classifies potential agglomerated\ninstances.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23206v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "二维显微食物晶体图像的置信度感知团聚分类与分割", "tldr": "本文提出了一种置信度感知的两阶段深度学习方法，用于二维显微食物晶体图像的团聚分类与分割，提高了准确性并能应对标注变异性。", "motivation": "食物晶体团聚现象会影响食品产品质量，而由于水结合的透明性和有限的视角，手动标注二维显微图像中的团聚非常困难，因此需要一种自动化的解决方案来克服这一挑战。", "method": "首先，提出一个监督基线模型，为粗略标注的分类数据集生成分割伪标签。其次，训练一个同时执行像素级分割的实例分类模型。然后，在推理阶段结合这两个模型的优势。此外，设计并包含一个后处理模块，用于上述两个步骤以保持晶体特性。最后，在两种置信度水平下评估了该方法，以应对手动标注的变异性。", "result": "与其他现有方法相比，该方法提高了真阳性团聚分类准确性和尺寸分布预测。即使在手动标注置信度水平存在变异性的情况下，也能成功分类潜在的团聚实例。", "conclusion": "所提出的置信度感知方法有效解决了二维显微图像中食物晶体团聚的分类和分割挑战，显示出更高的准确性和对标注变异性的鲁棒性。", "translation": "食物晶体团聚是结晶过程中发生的一种现象，它将水困在晶体之间，影响食品产品质量。由于水结合的透明性和对成像样本单一切片有限的视角，二维显微图像中团聚的手动标注特别困难。为了解决这一挑战，我们首先提出了一个监督基线模型，为粗略标注的分类数据集生成分割伪标签。接下来，训练一个同时执行像素级分割的实例分类模型。这两个模型都在推理阶段使用，以结合它们在分类和分割方面的各自优势。为了保持晶体特性，设计并包含了一个后处理模块，用于这两个步骤。与其他现有方法相比，我们的方法提高了真阳性团聚分类准确性和尺寸分布预测。鉴于手动标注置信度水平的可变性，我们提出的方法在两个置信度水平下进行了评估，并成功地对潜在的团聚实例进行了分类。", "summary": "本文提出了一种新颖的置信度感知方法，用于二维显微图像中食物晶体团聚的分类和分割。鉴于手动标注因水透明度和有限视角而面临的挑战，该方法首先利用监督基线模型从粗略标注的数据中生成分割伪标签。随后，训练一个同时执行像素级分割的实例分类模型。这两个模型在推理阶段结合使用，并通过后处理模块进行补充以保持晶体特性。所提出的方法在真阳性团聚分类准确性和尺寸分布预测方面均有所提高，即使在手动标注置信度水平存在变异性的情况下，也能成功分类团聚实例。", "keywords": "食物晶体团聚, 图像分类, 图像分割, 伪标签, 置信度感知", "comments": "该方法的创新之处在于其两阶段方法：利用伪标签从分类数据中进行分割，并结合置信度感知评估，这对于解决食物晶体团聚手动标注的固有困难至关重要。此外，包含用于保持晶体特性的后处理模块也是一个深思熟虑的设计。其重要性在于解决食品质量控制中的实际问题，提供比现有方法更准确和鲁棒的自动化解决方案。"}}
{"id": "2507.22944", "title": "Opacity as Authority: Arbitrariness and the Preclusion of Contestation", "authors": ["Naomi Omeonga wa Kayembe"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22944v1", "summary": "This article redefines arbitrariness not as a normative flaw or a symptom of\ndomination, but as a foundational functional mechanism structuring human\nsystems and interactions. Diverging from critical traditions that conflate\narbitrariness with injustice, it posits arbitrariness as a semiotic trait: a\nproperty enabling systems - linguistic, legal, or social - to operate\neffectively while withholding their internal rationale. Building on Ferdinand\nde Saussure's concept of l'arbitraire du signe, the analysis extends this\nprinciple beyond language to demonstrate its cross-domain applicability,\nparticularly in law and social dynamics. The paper introduces the \"Motivation\n-> Constatability -> Contestability\" chain, arguing that motivation functions\nas a crucial interface rendering an act's logic vulnerable to intersubjective\ncontestation. When this chain is broken through mechanisms like\n\"immotivization\" or \"Conflict Lateralization\" (exemplified by \"the blur of the\nwolf drowned in the fish\"), acts produce binding effects without exposing their\nrationale, thus precluding justiciability. This structural opacity, while\nappearing illogical, is a deliberate design protecting authority from\naccountability. Drawing on Shannon's entropy model, the paper formalizes\narbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern\ntheory of arbitrariness as a neutral operator central to control as well as\ncare, an overlooked dimension of interpersonal relations. While primarily\ndeveloped through human social systems, this framework also illuminates a new\npathway for analyzing explainability in advanced artificial intelligence\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22944v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "不透明性即权威：任意性与争论的排除", "tldr": "本文将任意性重新定义为一种功能性机制，而非缺陷，它通过隐藏内部逻辑来保护权威，并提出了一种基于信息熵的形式化方法，为理解人工智能的可解释性提供了新视角。", "motivation": "本文旨在将任意性重新定义为一种基础性的功能机制，而非规范性缺陷或支配的症状，从而与将任意性与不公正混为一谈的批判性传统区分开来。其动机在于理解系统如何在不暴露其内部原理的情况下有效运作。", "method": "文章将任意性重新定义为一种符号学特征，并以费迪南德·德·索绪尔的“符号的任意性”概念为基础，将其原理扩展到语言之外的领域（如法律和社会动态）。文章引入了“动机 -> 可证实性 -> 可争论性”链条，并分析了当该链条通过“无动机化”或“冲突横向化”等机制被打破时，行为如何在不暴露其原理的情况下产生约束性效果，从而排除可审理性。此外，论文还借鉴香农的熵模型，将任意性形式化为A = H(L|M)（条件熵）。", "result": "研究结果表明，任意性是一种符号学特征，它使系统能够在不公开其内部原理的情况下有效运作。当“动机 -> 可证实性 -> 可争论性”链条被打破时，行为会在不暴露其原理的情况下产生约束性效果，从而排除可审理性。这种结构性不透明性是一种蓄意设计，旨在保护权威免受问责。论文将任意性形式化为A = H(L|M)，并将其提出为一种中性操作符，对控制和关怀都至关重要。此外，该框架也为分析先进人工智能系统的可解释性提供了新途径。", "conclusion": "本文将任意性重新定义为一种功能性不透明性，并利用信息熵对其进行形式化，认为它是一个中性操作符，对控制和关怀都至关重要，通过排除争议来保护权威，并为人工智能的可解释性分析提供了新的见解。", "translation": "本文将任意性重新定义为一种基础性的功能机制，而非规范性缺陷或支配的症状，它构建了人类系统和互动。本文不同于将任意性与不公正混为一谈的批判性传统，而是将任意性视为一种符号学特征：一种使系统（语言、法律或社会）能够在不暴露其内部原理的情况下有效运作的属性。本文以费迪南德·德·索绪尔的“符号的任意性”概念为基础，将这一原理扩展到语言之外，以证明其跨领域适用性，尤其是在法律和社会动态中。论文引入了“动机 -> 可证实性 -> 可争论性”链条，认为动机是使行为逻辑易受主体间争议的关键接口。当该链条通过“无动机化”或“冲突横向化”等机制被打破时（例如“狼淹没在鱼群中的模糊性”），行为会在不暴露其原理的情况下产生约束性效果，从而排除可审理性。这种结构性不透明性，虽然看似不合逻辑，却是一种旨在保护权威免受问责的蓄意设计。论文借鉴香农的熵模型，将任意性形式化为A = H(L|M)（条件熵）。因此，它提出了一种现代任意性理论，将其视为一个中性操作符，对控制和关怀都至关重要，这是人际关系中一个被忽视的维度。虽然该框架主要通过人类社会系统发展而来，但它也为分析先进人工智能系统的可解释性开辟了一条新途径。", "summary": "本文将任意性重新定义为一种基础性的功能机制和符号学特征，它使得系统（包括语言、法律和社会系统）能够在不暴露其内部原理的情况下有效运作。文章以索绪尔的理论为基础，阐释了当“动机 -> 可证实性 -> 可争论性”链条通过“无动机化”等机制被打破时，如何形成结构性不透明性，从而通过排除可审理性来保护权威免受问责。论文利用香农的熵模型将任意性形式化为A = H(L|M)，并提出它是一个对控制和关怀都至关重要的中性操作符，同时为分析先进人工智能系统的可解释性提供了新的框架。", "keywords": "任意性, 不透明性, 权威, 可争论性, 可解释性", "comments": "这篇论文对任意性提供了一个新颖的、非规范性的重新解读，将其从一个缺陷转变为一个根本性的系统机制。其跨学科方法（符号学、法律、社会动力学、信息论）以及其在人工智能可解释性方面的应用尤其具有创新性。它挑战了传统的批判性观点，为理解权力结构和系统设计提供了新的视角。"}}
{"id": "2507.07953", "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases", "authors": ["Mihails Milehins", "Dan B. Marghitu"], "categories": ["physics.class-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Classical Physics (physics.class-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 3 figures, see this https URL ; (v2-v4) various amendments; arXiv admin note: text overlap with arXiv:2410.08147", "url": "http://arxiv.org/abs/2507.07953v4", "summary": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear\nCollisions of Convex Viscoplastic Bodies\" and published in the Journal of\nComputational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the\nauthors studied mathematical models of binary direct collinear collisions of\nconvex viscoplastic bodies that employed two incremental collision laws based\non the Bouc-Wen differential model of hysteresis. It was shown that the models\npossess favorable analytical properties, and several model parameter\nidentification studies were conducted, demonstrating that the models can\naccurately capture the nature of a variety of collision phenomena. In this\narticle, the aforementioned models are augmented by modeling the effects of\nexternal forces as time-dependent inputs that belong to a certain function\nspace. Furthermore, the range of the parameters under which the models possess\nfavorable analytical properties is extended to several corner cases that were\nnot considered in the prior publication. Finally, the previously conducted\nmodel parameter identification studies are extended, and an additional model\nparameter identification study is provided in an attempt to validate the\nability of the augmented models to represent the effects of external forces.", "comment": "12 pages, 3 figures, see https://gitlab.com/user9716869/EBWCM ;\n  (v2-v4) various amendments; arXiv admin note: text overlap with\n  arXiv:2410.08147", "pdf_url": "http://arxiv.org/pdf/2507.07953v4", "cate": "physics.class-ph", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "基于Bouc-Wen模型的增量碰撞定律：外力和极端情况", "tldr": "本文扩展了基于Bouc-Wen模型的增量碰撞定律，使其能够模拟外力的影响，并涵盖了之前研究中未考虑的更多参数极端情况，并通过参数识别研究验证了其有效性。", "motivation": "在之前的工作中，作者研究了基于Bouc-Wen滞后微分模型的增量碰撞定律，用于凸粘塑性体的二元直接共线碰撞。本文的动机是增强这些模型，以模拟外力的影响，并将模型具有良好分析特性的参数范围扩展到之前未考虑的极端情况，从而提高模型的适用性和鲁棒性。", "method": "本文通过将外力建模为属于特定函数空间的随时间变化的输入，来增强现有模型。此外，将模型具有良好分析特性的参数范围扩展到多个之前未考虑的极端情况。最后，扩展了之前进行的模型参数识别研究，并提供了额外的参数识别研究来验证增强模型表示外力影响的能力。", "result": "增强的模型能够准确地表示外力的影响。模型具有良好分析特性的参数范围已成功扩展到多个极端情况。通过参数识别研究，验证了增强模型的有效性。", "conclusion": "增强的基于Bouc-Wen模型的增量碰撞定律能够准确地表示外力的影响，并且其良好分析特性的参数范围已扩展到极端情况，提高了模型的实用性和准确性。", "translation": "本文题为“用于凸粘塑性体二元直接共线碰撞的Bouc-Wen模型”，发表于《计算与非线性动力学杂志》（第20卷，第6期，2025年6月）。在该文章中，作者研究了采用基于Bouc-Wen滞后微分模型的两种增量碰撞定律的凸粘塑性体二元直接共线碰撞的数学模型。结果表明，这些模型具有良好的分析特性，并进行了多项模型参数识别研究，证明这些模型能够准确捕捉各种碰撞现象的本质。在本文中，上述模型通过将外力的影响建模为属于特定函数空间的随时间变化的输入进行增强。此外，将模型具有良好分析特性的参数范围扩展到先前出版物中未考虑的几个极端情况。最后，扩展了先前进行过的模型参数识别研究，并提供了一项额外的模型参数识别研究，以验证增强模型表示外力影响的能力。", "summary": "本文在之前研究的基础上，对基于Bouc-Wen模型的增量碰撞定律进行了扩展，使其能够模拟外部力的影响，并涵盖了更广泛的参数极端情况。研究通过将外部力建模为时间相关的输入，并扩展了模型在极端参数下的分析特性范围。此外，通过参数识别研究验证了增强模型表示外部力影响的能力，证明了其在捕捉多种碰撞现象方面的准确性。", "keywords": "Bouc-Wen模型, 碰撞定律, 外部力, 极端情况, 粘塑性体", "comments": "本文的创新之处在于其对Bouc-Wen模型在碰撞定律应用上的扩展。通过引入外部力建模和考虑极端参数情况，该研究显著提升了模型的实用性和鲁棒性。这对于更准确地模拟复杂碰撞现象具有重要意义，尤其是在需要考虑外部干扰和非理想条件的应用中。模型参数识别研究的延续和补充也增强了研究的严谨性。"}}
{"id": "2507.23661", "title": "Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning", "authors": ["Salam Thabet Doghmash", "Motaz Saad"], "categories": ["cs.CL", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 pages, 5 figures", "url": "http://arxiv.org/abs/2507.23661v1", "summary": "Hate speech identification in social media has become an increasingly\nimportant issue in recent years. In this research, we address two problems: 1)\nto detect hate speech in Arabic text, 2) to clean a given text from hate\nspeech. The meaning of cleaning here is replacing each bad word with stars\nbased on the number of letters for each word. Regarding the first problem, we\nconduct several experiments using deep learning models and transformers to\ndetermine the best model in terms of the F1 score. Regarding second problem, we\nconsider it as a machine translation task, where the input is a sentence\ncontaining dirty text and the output is the same sentence with masking the\ndirty text. The presented methods achieve the best model in hate speech\ndetection with a 92\\% Macro F1 score and 95\\% accuracy. Regarding the text\ncleaning experiment, the best result in the hate speech masking model reached\n0.3 in BLEU score with 1-gram, which is a good result compared with the state\nof the art machine translation systems.", "comment": "23 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.23661v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用深度学习模型和预训练模型微调的社交媒体阿拉伯语仇恨言论识别与屏蔽", "tldr": "本研究提出并解决了社交媒体中阿拉伯语仇恨言论的识别和屏蔽问题，通过深度学习和预训练模型微调实现了高准确率的检测，并使用机器翻译方法对仇恨言论进行屏蔽。", "motivation": "社交媒体中的仇恨言论识别在近年来变得日益重要，本研究旨在解决阿拉伯语仇恨言论的检测和清理问题。", "method": "对于仇恨言论检测，研究人员使用深度学习模型和Transformer进行实验，以F1分数确定最佳模型。对于文本清理（屏蔽），将其视为机器翻译任务，输入是包含脏话的句子，输出是屏蔽了脏话的相同句子。", "result": "仇恨言论检测的最佳模型达到了92%的Macro F1分数和95%的准确率。仇恨言论屏蔽模型的最佳结果在BLEU分数1-gram上达到了0.3，与最先进的机器翻译系统相比是一个好的结果。", "conclusion": "本研究提出的方法在阿拉伯语仇恨言论检测方面取得了高F1分数和准确率，并在仇恨言论屏蔽方面取得了与现有机器翻译系统相当的良好BLEU分数。", "translation": "近年来，社交媒体中的仇恨言论识别已成为一个日益重要的问题。在本研究中，我们解决了两个问题：1）检测阿拉伯语文本中的仇恨言论，2）清理给定文本中的仇恨言论。这里清理的含义是根据每个单词的字母数量，用星号替换每个不好的单词。关于第一个问题，我们使用深度学习模型和Transformer进行了多项实验，以F1分数确定最佳模型。关于第二个问题，我们将其视为一个机器翻译任务，其中输入是包含脏话的句子，输出是屏蔽了脏话的相同句子。所提出的方法在仇恨言论检测方面取得了最佳模型，Macro F1分数为92%，准确率为95%。关于文本清理实验，仇恨言论屏蔽模型的最佳结果在BLEU分数1-gram上达到了0.3，与最先进的机器翻译系统相比，这是一个好的结果。", "summary": "本研究致力于解决社交媒体中阿拉伯语仇恨言论的识别与屏蔽问题。在识别方面，通过比较深度学习模型和Transformer，确定了F1分数最高的模型，实现了92%的Macro F1和95%的准确率。在屏蔽方面，将此任务视为机器翻译问题，成功地将仇恨词替换为星号，并在BLEU分数上取得了0.3（1-gram）的良好表现，证明了该方法在阿拉伯语仇恨言论处理上的有效性。", "keywords": "仇恨言论识别, 阿拉伯语, 深度学习, 文本屏蔽, 社交媒体", "comments": "该研究创新性地将仇恨言论屏蔽视为机器翻译任务，并取得了与现有系统相当的良好结果。同时，其在阿拉伯语仇恨言论检测方面也达到了很高的准确率，为该领域的研究提供了有价值的贡献。然而，抽象中未详细说明所使用的具体深度学习模型和Transformer架构，也未提及数据集的规模和特性，这可能限制了对方法普适性的评估。"}}
{"id": "2507.20469", "title": "Priority-Aware Clinical Pathology Hierarchy Training for Multiple Instance Learning", "authors": ["Sungrae Hong", "Kyungeun Kim", "Juhyeon Kim", "Sol Lee", "Jisu Shin", "Chanjae Song", "Mun Yong Yi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures, Accepted for oral presentation by The 2nd MICCAI Student Board (MSB) EMERGE Workshop", "url": "http://arxiv.org/abs/2507.20469v2", "summary": "Multiple Instance Learning (MIL) is increasingly being used as a support tool\nwithin clinical settings for pathological diagnosis decisions, achieving high\nperformance and removing the annotation burden. However, existing approaches\nfor clinical MIL tasks have not adequately addressed the priority issues that\nexist in relation to pathological symptoms and diagnostic classes, causing MIL\nmodels to ignore priority among classes. To overcome this clinical limitation\nof MIL, we propose a new method that addresses priority issues using two\nhierarchies: vertical inter-hierarchy and horizontal intra-hierarchy. The\nproposed method aligns MIL predictions across each hierarchical level and\nemploys an implicit feature re-usability during training to facilitate\nclinically more serious classes within the same level. Experiments with\nreal-world patient data show that the proposed method effectively reduces\nmisdiagnosis and prioritizes more important symptoms in multiclass scenarios.\nFurther analysis verifies the efficacy of the proposed components and\nqualitatively confirms the MIL predictions against challenging cases with\nmultiple symptoms.", "comment": "10 pages, 4 figures, Accepted for oral presentation by The 2nd MICCAI\n  Student Board (MSB) EMERGE Workshop", "pdf_url": "http://arxiv.org/pdf/2507.20469v2", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-31", "AI": {"title_translation": "用于多实例学习的优先感知临床病理学层次训练", "tldr": "本文提出了一种新的多实例学习（MIL）方法，通过引入垂直和水平层次结构来解决临床病理诊断中存在的症状和诊断类别的优先级问题，有效减少误诊并优先处理更重要的症状。", "motivation": "现有的临床多实例学习（MIL）方法未能充分解决病理症状和诊断类别之间存在的优先级问题，导致MIL模型忽略了类别间的优先级，从而限制了其在临床应用中的表现。", "method": "我们提出了一种新的方法，通过使用两种层次结构来解决优先级问题：垂直的层间层次结构和水平的层内层次结构。该方法在每个层次级别上对MIL预测进行对齐，并在训练期间采用隐式特征重用，以促进同一级别内临床上更严重的类别。", "result": "使用真实世界患者数据进行的实验表明，所提出的方法在多类别场景中有效减少了误诊，并优先处理了更重要的症状。进一步的分析验证了所提出组件的有效性，并通过针对具有多种症状的挑战性病例定性确认了MIL预测。", "conclusion": "本文提出的优先感知临床病理学层次训练方法，通过引入垂直和水平层次结构，有效解决了多实例学习在临床病理诊断中忽略优先级的问题，显著减少了误诊并提高了对重要症状的识别能力。", "translation": "多实例学习（MIL）正越来越多地被用作临床环境中病理诊断决策的支持工具，实现了高性能并消除了标注负担。然而，现有的临床MIL任务方法未能充分解决病理症状和诊断类别之间存在的优先级问题，导致MIL模型忽略了类别间的优先级。为了克服MIL的这一临床局限性，我们提出了一种新的方法，通过使用两种层次结构来解决优先级问题：垂直的层间层次结构和水平的层内层次结构。所提出的方法在每个层次级别上对MIL预测进行对齐，并在训练期间采用隐式特征重用，以促进同一级别内临床上更严重的类别。使用真实世界患者数据进行的实验表明，所提出的方法在多类别场景中有效减少了误诊，并优先处理了更重要的症状。进一步的分析验证了所提出组件的有效性，并通过针对具有多种症状的挑战性病例定性确认了MIL预测。", "summary": "本研究提出了一种针对临床多实例学习（MIL）的新方法，旨在解决现有MIL模型在病理诊断中忽略症状和诊断类别优先级的问题。该方法引入了垂直和水平两种层次结构，通过在不同层次级别上对齐MIL预测并利用隐式特征重用，来优先处理临床上更严重的类别。实验结果表明，该方法有效减少了误诊，并在多类别场景中优先处理了更重要的症状，验证了其在复杂病例中的有效性。", "keywords": "多实例学习, 临床病理学, 优先级感知, 层次训练, 误诊减少", "comments": "该论文通过引入优先级感知层次结构，创新性地解决了多实例学习在临床病理诊断中长期存在的类别优先级问题，这对于提高诊断准确性和临床实用性具有重要意义。其方法考虑了临床实际的复杂性，通过分层处理和特征重用，使得模型能够更好地模拟医生在诊断时的思维过程。未来的工作可以探索这种层次结构在其他医疗图像分析任务中的普适性。"}}
{"id": "2505.19219", "title": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding", "authors": ["Shiyue Wang", "Haozheng Xu", "Yuhan Zhang", "Jingran Lin", "Changhong Lu", "Xiangfeng Wang", "Wenhao Li"], "categories": ["cs.AI", "cs.LG", "cs.MA", "math.CO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      112 pages, 21 figures, 20 tables. The project website is: this https URL", "url": "http://arxiv.org/abs/2505.19219v2", "summary": "Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial\nintelligence and robotics, requiring the computation of collision-free paths\nfor multiple agents navigating from their start locations to designated goals.\nAs autonomous systems become increasingly prevalent in warehouses, urban\ntransportation, and other complex environments, MAPF has evolved from a\ntheoretical challenge to a critical enabler of real-world multi-robot\ncoordination. This comprehensive survey bridges the long-standing divide\nbetween classical algorithmic approaches and emerging learning-based methods in\nMAPF research. We present a unified framework that encompasses search-based\nmethods (including Conflict-Based Search, Priority-Based Search, and Large\nNeighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP\nformulations), and data-driven techniques (reinforcement learning, supervised\nlearning, and hybrid strategies). Through systematic analysis of experimental\npractices across 200+ papers, we uncover significant disparities in evaluation\nmethodologies, with classical methods typically tested on larger-scale\ninstances (up to 200 by 200 grids with 1000+ agents) compared to learning-based\napproaches (predominantly 10-100 agents). We provide a comprehensive taxonomy\nof evaluation metrics, environment types, and baseline selections, highlighting\nthe need for standardized benchmarking protocols. Finally, we outline promising\nfuture directions including mixed-motive MAPF with game-theoretic\nconsiderations, language-grounded planning with large language models, and\nneural solver architectures that combine the rigor of classical methods with\nthe flexibility of deep learning. This survey serves as both a comprehensive\nreference for researchers and a practical guide for deploying MAPF solutions in\nincreasingly complex real-world applications.", "comment": "112 pages, 21 figures, 20 tables. The project website is:\n  https://wangsh1yue.github.io/Where-Paths-Collide", "pdf_url": "http://arxiv.org/pdf/2505.19219v2", "cate": "cs.AI", "date": "2025-05-25", "updated": "2025-07-31", "AI": {"title_translation": "路径碰撞之处：经典与基于学习的多智能体路径规划综合综述", "tldr": "这篇综述全面回顾了经典和基于学习的多智能体路径规划（MAPF）方法，揭示了评估方法的差异，并提出了未来的研究方向。", "motivation": "多智能体路径规划（MAPF）是人工智能和机器人领域的基础问题，对现实世界的多机器人协调至关重要。然而，经典算法方法与新兴的学习方法之间存在长期分歧，本综述旨在弥合这一鸿沟，并为日益复杂的现实世界应用提供指南。", "method": "本综述提出了一个统一框架，涵盖了基于搜索（包括基于冲突搜索、基于优先级搜索和大型邻域搜索）、基于编译（SAT、SMT、CSP、ASP和MIP公式）以及数据驱动（强化学习、监督学习和混合策略）的多智能体路径规划（MAPF）技术。通过系统分析200多篇论文的实验实践，揭示了评估方法、指标、环境类型和基线选择的显著差异。", "result": "发现评估方法存在显著差异，经典方法通常在更大规模的实例（高达200x200网格，1000多个智能体）上进行测试，而基于学习的方法主要在10-100个智能体上进行。提供了评估指标、环境类型和基线选择的综合分类。", "conclusion": "需要标准化的基准测试协议。未来的发展方向包括混合动机多智能体路径规划、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构。本综述是研究人员的全面参考和部署多智能体路径规划解决方案的实用指南。", "translation": "多智能体路径规划（MAPF）是人工智能和机器人领域的一个基本问题，需要为多个智能体从起始位置导航到指定目标计算无碰撞路径。随着自主系统在仓库、城市交通和其他复杂环境中变得越来越普及，MAPF已从一个理论挑战演变为现实世界多机器人协调的关键推动因素。这篇综合综述弥合了MAPF研究中经典算法方法与新兴的学习方法之间长期存在的分歧。我们提出了一个统一框架，涵盖了基于搜索的方法（包括基于冲突的搜索、基于优先级的搜索和大型邻域搜索）、基于编译的方法（SAT、SMT、CSP、ASP和MIP公式）以及数据驱动技术（强化学习、监督学习和混合策略）。通过对200多篇论文的实验实践进行系统分析，我们发现了评估方法上的显著差异，经典方法通常在更大规模的实例（高达200x200网格，1000多个智能体）上进行测试，而基于学习的方法（主要为10-100个智能体）则不然。我们提供了评估指标、环境类型和基线选择的综合分类，强调了标准化基准测试协议的必要性。最后，我们概述了有前景的未来方向，包括考虑博弈论的混合动机MAPF、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构。本综述既可作为研究人员的全面参考，也可作为在日益复杂的现实世界应用中部署MAPF解决方案的实用指南。", "summary": "这篇综述提供了多智能体路径规划（MAPF）的全面概述，统一了经典的算法方法（基于搜索、基于编译）与新兴的基于学习的方法（强化学习、监督学习、混合策略）。它分析了200多篇论文的实验实践，揭示了经典方法和基于学习方法在评估规模上的显著差异。论文强调了标准化基准测试的必要性，并提出了未来的研究方向，包括混合动机MAPF、语言接地规划和神经求解器架构，为研究人员和实践者提供了宝贵资源。", "keywords": "多智能体路径规划, MAPF, 综述, 经典算法, 基于学习的方法", "comments": "这篇综述在弥合多智能体路径规划（MAPF）两大范式（经典与基于学习）之间的鸿沟方面具有重要价值。其对评估差异的系统分析，特别是揭示了不同方法在测试规模上的显著差距，对未来研究至关重要。倡导标准化基准测试协议是其一项重大贡献，将有助于推动该领域的公平比较和进步。所概述的未来方向，如与大型语言模型结合或开发神经求解器，也极具启发性，指明了该领域潜在的创新路径。"}}
{"id": "2507.23470", "title": "Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models", "authors": ["Sebastian Gürtl", "Gloria Schimetta", "David Kerschbaumer", "Michael Liut", "Alexander Steinmaurer"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Learnersourcing: Student-generated Content @ Scale Workshop at L@S 2025", "url": "http://arxiv.org/abs/2507.23470v1", "summary": "UML and ER diagrams are foundational in computer science education but come\nwith challenges for learners due to the need for abstract thinking, contextual\nunderstanding, and mastery of both syntax and semantics. These complexities are\ndifficult to address through traditional teaching methods, which often struggle\nto provide scalable, personalized feedback, especially in large classes. We\nintroduce DUET (Diagrammatic UML & ER Tutor), a prototype of an LLM-based tool,\nwhich converts a reference diagram and a student-submitted diagram into a\ntextual representation and provides structured feedback based on the\ndifferences. It uses a multi-stage LLM pipeline to compare diagrams and\ngenerate reflective feedback. Furthermore, the tool enables analytical insights\nfor educators, aiming to foster self-directed learning and inform instructional\nstrategies. We evaluated DUET through semi-structured interviews with six\nparticipants, including two educators and four teaching assistants. They\nidentified strengths such as accessibility, scalability, and learning support\nalongside limitations, including reliability and potential misuse. Participants\nalso suggested potential improvements, such as bulk upload functionality and\ninteractive clarification features. DUET presents a promising direction for\nintegrating LLMs into modeling education and offers a foundation for future\nclassroom integration and empirical evaluation.", "comment": "Learnersourcing: Student-generated Content @ Scale Workshop at L@S\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.23470v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用大型语言模型对学生生成的UML和ER图提供自动化反馈", "tldr": "DUET是一个基于LLM的工具，通过比较参考图和学生图的文本表示来自动化UML和ER图的反馈，旨在解决传统教学中难以提供可扩展个性化反馈的问题。", "motivation": "计算机科学教育中UML和ER图的学习存在挑战，包括抽象思维、上下文理解和语法语义掌握的难度。传统教学方法难以提供可扩展的个性化反馈，尤其是在大型班级中。", "method": "本文介绍了DUET（Diagrammatic UML & ER Tutor），一个基于LLM的工具原型。该工具将参考图和学生提交的图转换为文本表示，并使用多阶段LLM管道比较差异以生成结构化反馈。研究通过对六名参与者（包括两名教育工作者和四名助教）进行半结构化访谈来评估DUET。", "result": "评估结果显示，参与者认可DUET在可访问性、可扩展性和学习支持方面的优势，但也指出了可靠性和潜在滥用等局限性。同时，参与者也提出了批量上传和交互式澄清等改进建议。", "conclusion": "DUET为将大型语言模型集成到建模教育中提供了一个有前景的方向，并为未来的课堂集成和实证评估奠定了基础。", "translation": "UML和ER图是计算机科学教育的基础，但由于需要抽象思维、上下文理解以及掌握语法和语义，给学习者带来了挑战。这些复杂性难以通过传统教学方法解决，传统方法往往难以提供可扩展的个性化反馈，尤其是在大型班级中。我们引入了DUET（Diagrammatic UML & ER Tutor），一个基于LLM的工具原型，它将参考图和学生提交的图转换为文本表示，并根据差异提供结构化反馈。它使用多阶段LLM管道来比较图并生成反思性反馈。此外，该工具还为教育工作者提供了分析见解，旨在促进自主学习并指导教学策略。我们通过对六名参与者（包括两名教育工作者和四名助教）的半结构化访谈评估了DUET。他们指出了其优势，如可访问性、可扩展性和学习支持，同时也指出了局限性，包括可靠性和潜在滥用。参与者还提出了潜在的改进建议，例如批量上传功能和交互式澄清功能。DUET为将LLM集成到建模教育中提出了一个有前景的方向，并为未来的课堂集成和实证评估奠定了基础。", "summary": "本文介绍了DUET，一个基于大型语言模型（LLM）的原型工具，旨在为学生生成的UML和ER图提供自动化反馈。该工具通过将参考图和学生图转换为文本表示，并利用多阶段LLM管道比较差异来生成结构化反馈。DUET旨在解决传统教学在提供可扩展个性化反馈方面的挑战。通过对教育工作者和助教的访谈评估显示，DUET在可访问性、可扩展性和学习支持方面具有优势，但也存在可靠性和潜在滥用等局限性。研究表明DUET在建模教育中集成LLM方面具有潜力，并为未来应用奠定基础。", "keywords": "UML图, ER图, 自动化反馈, 大型语言模型, 教学工具", "comments": "DUET的创新之处在于利用LLM将图形表示转换为文本并进行比较，从而实现自动化的、结构化的反馈，解决了传统教学中个性化反馈难以规模化的问题。其重要性在于为计算机科学教育中复杂图表的教学和评估提供了新的、高效的途径。局限性方面，访谈中提到的可靠性和潜在滥用问题是未来需要重点关注和解决的挑战。"}}
{"id": "2506.02169", "title": "LoL-NMPC: Low-Level Dynamics Integration in Nonlinear Model Predictive Control for Unmanned Aerial Vehicles", "authors": ["Parakh M. Gupta", "Ondřej Procházka", "Jan Hřebec", "Matej Novosad", "Robert Pěnička", "Martin Saska"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025", "url": "http://arxiv.org/abs/2506.02169v2", "summary": "[Accepted to IROS 2025] In this paper, we address the problem of tracking\nhigh-speed agile trajectories for Unmanned Aerial Vehicles(UAVs), where model\ninaccuracies can lead to large tracking errors. Existing Nonlinear Model\nPredictive Controller(NMPC) methods typically neglect the dynamics of the\nlow-level flight controllers such as underlying PID controller present in many\nflight stacks, and this results in sub-optimal tracking performance at high\nspeeds and accelerations. To this end, we propose a novel NMPC formulation,\nLoL-NMPC, which explicitly incorporates low-level controller dynamics and motor\ndynamics in order to minimize trajectory tracking errors while maintaining\ncomputational efficiency. By leveraging linear constraints inside low-level\ndynamics, our approach inherently accounts for actuator constraints without\nrequiring additional reallocation strategies. The proposed method is validated\nin both simulation and real-world experiments, demonstrating improved tracking\naccuracy and robustness at speeds up to 98.57 km/h and accelerations of 3.5 g.\nOur results show an average 21.97 % reduction in trajectory tracking error over\nstandard NMPC formulation, with LoL-NMPC maintaining real-time feasibility at\n100 Hz on an embedded ARM-based flight computer.", "comment": "Accepted to IROS 2025", "pdf_url": "http://arxiv.org/pdf/2506.02169v2", "cate": "cs.RO", "date": "2025-06-02", "updated": "2025-07-31", "AI": {"title_translation": "LoL-NMPC：无人机非线性模型预测控制中低层动力学集成", "tldr": "LoL-NMPC通过将低层控制器和电机动力学集成到非线性模型预测控制中，显著提升了无人机在高速高加速度下的轨迹跟踪精度和鲁棒性，平均减少了21.97%的跟踪误差，并保持了实时性。", "motivation": "现有非线性模型预测控制器（NMPC）通常忽略无人机底层飞控（如PID控制器）的动力学，导致在高速和高加速度下轨迹跟踪性能不佳，模型不准确会导致较大的跟踪误差。", "method": "本文提出了一种名为LoL-NMPC的新型NMPC公式，它明确地将低层控制器动力学和电机动力学纳入其中，以最小化轨迹跟踪误差并保持计算效率。通过利用低层动力学中的线性约束，该方法固有地考虑了执行器约束，无需额外的重新分配策略。", "result": "LoL-NMPC在仿真和实际实验中得到了验证，在高达98.57公里/小时的速度和3.5 g的加速度下，显示出更高的跟踪精度和鲁棒性。与标准NMPC公式相比，轨迹跟踪误差平均减少了21.97%。LoL-NMPC在基于ARM的嵌入式飞控计算机上以100 Hz的频率保持了实时可行性。", "conclusion": "通过将低层控制器和电机动力学集成到非线性模型预测控制中，LoL-NMPC显著改善了无人机在高速高加速度下的轨迹跟踪性能，并展示了在嵌入式系统上的实时可行性。", "translation": "[已收录至IROS 2025] 本文解决了无人机（UAV）高速敏捷轨迹跟踪问题，其中模型不准确可能导致较大的跟踪误差。现有的非线性模型预测控制器（NMPC）方法通常忽略底层飞行控制器（例如许多飞行堆栈中存在的PID控制器）的动力学，这导致在高速和高加速度下跟踪性能欠佳。为此，我们提出了一种新颖的NMPC公式——LoL-NMPC，它明确地将低层控制器动力学和电机动力学纳入其中，以最小化轨迹跟踪误差，同时保持计算效率。通过利用低层动力学中的线性约束，我们的方法固有地考虑了执行器约束，而无需额外的重新分配策略。所提出的方法在仿真和实际实验中都得到了验证，证明在高达98.57公里/小时的速度和3.5 g的加速度下具有更高的跟踪精度和鲁棒性。我们的结果显示，与标准NMPC公式相比，轨迹跟踪误差平均减少了21.97%，并且LoL-NMPC在基于ARM的嵌入式飞行计算机上以100 Hz的频率保持了实时可行性。", "summary": "本文提出了一种名为LoL-NMPC的新型非线性模型预测控制（NMPC）方法，旨在解决无人机在高速敏捷轨迹跟踪中因忽略底层控制器动力学导致的性能不佳问题。LoL-NMPC通过显式集成低层控制器和电机动力学来最小化跟踪误差，并通过利用线性约束有效处理执行器限制。实验结果表明，该方法在高达98.57公里/小时的速度和3.5 g的加速度下，与标准NMPC相比，轨迹跟踪误差平均降低了21.97%，并能在嵌入式系统上实现实时运行。", "keywords": "非线性模型预测控制, 无人机, 低层动力学, 轨迹跟踪, 实时性", "comments": "本文的创新之处在于其LoL-NMPC框架，它首次明确地将无人机底层控制器和电机动力学集成到非线性模型预测控制中，解决了现有NMPC在高速敏捷飞行中性能受限的实际问题。这种集成不仅显著提升了跟踪精度和鲁棒性，还通过巧妙地利用线性约束避免了复杂的执行器重分配策略，同时保持了在嵌入式硬件上的实时可行性，这对于实际应用具有重要意义。"}}
{"id": "2506.00497", "title": "Second-Order Characterization of Micro Doppler Radar Signatures of Drone Swarms", "authors": ["Anders Malthe Westerkam", "Alba Spliid Damkjær", "Rasmus Erik Villadsen", "Magnus Ørum Bastrup Poulsen", "Troels Pedersen"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00497v3", "summary": "We investigate the second-order characteristics of the radar return signal\nfrom a swarm of rotor drones. We consider the case of a swarm of identical\ndrones, with each a number of rotors comprised of a number of rotor blades. By\nconsidering the orientation and speed of each rotor as stochastic variables, we\nderive expressions for the autocorrelation function (ACF) and power spectral\ndensity (PSD). The ACF and PSD are in the form of an infinite series with\ncoefficients that drop to zero at a predictable limit. Thus in practical\napplications, the series may be truncated. As a special case, we show that for\ndeterministic rotor speed, the ACF can be expressed in closed form. We further\ninvestigate how system parameters (Blade length, Rotor speed, number of blades,\nand number of drones) influence the derived expressions for the ACF and PSD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00497v3", "cate": "eess.SP", "date": "2025-05-31", "updated": "2025-07-31", "AI": {"title_translation": "无人机蜂群微多普勒雷达特征的二阶表征", "tldr": "该论文研究了无人机蜂群雷达回波信号的二阶特性，推导了自相关函数（ACF）和功率谱密度（PSD）的表达式，并分析了系统参数对其影响。", "motivation": "研究旋翼无人机蜂群的雷达回波信号，特别是其二阶特性（自相关函数ACF和功率谱密度PSD）。", "method": "将每个旋翼的方位和速度视为随机变量，推导了ACF和PSD的表达式，这些表达式呈无限级数形式。特别地，对于确定性旋翼速度，ACF可表示为封闭形式。此外，研究了桨叶长度、旋翼速度、桨叶数量和无人机数量等系统参数对ACF和PSD表达式的影响。", "result": "推导出了ACF和PSD的表达式，它们呈无限级数形式，其系数在可预测的极限处趋于零，因此在实际应用中可以截断。对于确定性旋翼速度，ACF可以表示为封闭形式。研究了系统参数（桨叶长度、旋翼速度、桨叶数量和无人机数量）如何影响ACF和PSD的表达式。", "conclusion": "该研究通过推导ACF和PSD表达式，并考虑旋翼的随机参数以及各种系统参数的影响，成功表征了无人机蜂群的二阶雷达特征，为实际应用提供了基础。", "translation": "我们研究了旋翼无人机蜂群雷达回波信号的二阶特性。我们考虑了由相同无人机组成的蜂群情况，每架无人机都有多个旋翼，每个旋翼由多个桨叶组成。通过将每个旋翼的方位和速度视为随机变量，我们推导出了自相关函数（ACF）和功率谱密度（PSD）的表达式。ACF和PSD以无限级数的形式出现，其系数在可预测的极限处降至零。因此，在实际应用中，该级数可以被截断。作为特例，我们表明对于确定性旋翼速度，ACF可以表示为封闭形式。我们进一步研究了系统参数（桨叶长度、旋翼速度、桨叶数量和无人机数量）如何影响ACF和PSD的推导表达式。", "summary": "这篇论文研究了无人机蜂群的二阶雷达特征，特别是自相关函数（ACF）和功率谱密度（PSD）。通过将旋翼的方位和速度视为随机变量，论文推导了ACF和PSD的数学表达式，指出它们是可截断的无限级数。研究还探讨了桨叶长度、旋翼速度、桨叶数量和无人机数量等系统参数如何影响这些派生表达式，为理解无人机蜂群的雷达特征提供了见解。", "keywords": "微多普勒, 无人机蜂群, 雷达特征, 自相关函数, 功率谱密度", "comments": "这篇论文为理解无人机蜂群的雷达特征提供了基础理论框架，这对于其探测和分类至关重要。旋翼参数的随机建模以及ACF/PSD表达式的推导具有创新性。对系统参数如何影响这些特征的分析增加了实用价值。"}}
{"id": "2507.23651", "title": "Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source", "authors": ["Dang Duc Trong", "Nguyen Dang Minh", "Luu Xuan Thang", "Luu Dang Khoa"], "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23651v1", "summary": "Let $X$ and $Y$ be Hilbert spaces, and $\\mathbf{K}: \\text{dom} \\mathbf{K}\n\\subset X \\to Y$ a bounded linear operator. This paper addresses the inverse\nproblem $\\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data\n$y^\\delta$ satisfying $\\|y^\\delta - y\\|_Y \\leq \\delta$. Due to the\nill-posedness of such problems, we employ regularization methods to stabilize\nsolutions. While singular value decomposition (SVD) provides a classical\napproach, its computation can be costly and impractical for certain operators.\nWe explore alternatives via Diagonal Frame Decomposition (DFD), generalizing\nSVD-based techniques, and introduce a regularized solution $x^\\delta_\\alpha =\n\\sum_{\\lambda \\in \\Lambda} \\kappa_\\lambda g_\\alpha(\\kappa_\\lambda^2) \\langle\ny^\\delta, v_\\lambda \\rangle \\overline{u}_\\lambda$. Convergence rates and\noptimality are analyzed under a generalized source condition\n$\\mathbf{M}_{\\varphi, E} = \\{ x \\in \\text{dom} \\mathbf{K} : \\sum_{\\lambda \\in\n\\Lambda} [\\varphi(\\kappa_\\lambda^2)]^{-1} |\\langle x, u_\\lambda \\rangle|^2 \\leq\nE^2 \\}$. Key questions include constructing DFD systems, relating DFD and SVD\nsingular values, and extending source conditions. We present theoretical\nresults, including modulus of continuity bounds and convergence rates for a\npriori and a posteriori parameter choices, with applications to polynomial and\nexponentially ill-posed problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23651v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "逆问题在一般源条件下通过滤波对角框架分解的正则化", "tldr": "本文提出一种基于滤波对角框架分解(DFD)的正则化方法，用于解决逆问题，并在广义源条件下分析其收敛性和最优性，克服SVD的计算限制。", "motivation": "逆问题是病态的，需要正则化方法来稳定解。经典的奇异值分解(SVD)方法计算成本高昂且对于某些算子不切实际，因此需要探索替代方案。", "method": "本文采用对角框架分解(DFD)作为奇异值分解(SVD)的替代方案，并引入了正则化解 $x^\\delta_\\alpha = \\sum_{\\lambda \\in \\Lambda} \\kappa_\\lambda g_\\alpha(\\kappa_\\lambda^2) \\langle y^\\delta, v_\\lambda \\rangle \\overline{u}_\\lambda$。研究在广义源条件 $\\mathbf{M}_{\\varphi, E}$ 下进行。", "result": "分析了收敛率和最优性。提出了理论结果，包括连续模量界限以及先验和后验参数选择的收敛率。该方法应用于多项式和指数病态问题。", "conclusion": "本文成功提出并分析了一种基于滤波对角框架分解(DFD)的正则化方法，用于解决逆问题，并在广义源条件下证明了其收敛性和最优性，为克服传统SVD的计算局限性提供了有效途径。", "translation": "设 $X$ 和 $Y$ 是希尔伯特空间，$\\mathbf{K}: \\text{dom} \\mathbf{K} \\subset X \\to Y$ 是一个有界线性算子。本文研究逆问题 $\\mathbf{K}x = y$，其中精确数据 $y$ 被满足 $||y^\\delta - y||_Y \\leq \\delta$ 的噪声数据 $y^\\delta$ 所取代。由于此类问题的病态性，我们采用正则化方法来稳定解。虽然奇异值分解(SVD)提供了一种经典方法，但其计算成本高昂且对于某些算子不切实际。我们通过对角框架分解(DFD)探索替代方案，推广了基于SVD的技术，并引入了正则化解 $x^\\delta_\\alpha = \\sum_{\\lambda \\in \\Lambda} \\kappa_\\lambda g_\\alpha(\\kappa_\\lambda^2) \\langle y^\\delta, v_\\lambda \\rangle \\overline{u}_\\lambda$。在广义源条件 $\\mathbf{M}_{\\varphi, E} = \\{ x \\in \\text{dom} \\mathbf{K} : \\sum_{\\lambda \\in \\Lambda} [\\varphi(\\kappa_\\lambda^2)]^{-1} |\\langle x, u_\\lambda \\rangle|^2 \\leq E^2 \\}$ 下分析了收敛率和最优性。关键问题包括构建DFD系统，关联DFD和SVD奇异值，以及扩展源条件。我们提出了理论结果，包括连续模量界限以及先验和后验参数选择的收敛率，并应用于多项式和指数病态问题。", "summary": "本文针对希尔伯特空间中的病态逆问题 $\\mathbf{K}x = y$，提出一种基于滤波对角框架分解（DFD）的正则化方法，以克服传统奇异值分解（SVD）计算成本高昂的缺点。研究引入了新的正则化解形式，并在广义源条件下对该方法的收敛率和最优性进行了详细分析。文章探讨了DFD系统的构建、其与SVD奇异值的关系以及源条件的扩展，并提供了包括连续模量界限和不同参数选择下收敛率的理论结果，将其应用于多项式和指数病态问题。", "keywords": "逆问题, 正则化, 对角框架分解, 奇异值分解, 收敛率", "comments": "本文通过引入对角框架分解（DFD）作为奇异值分解（SVD）的替代方案，为解决病态逆问题提供了一种新的正则化策略，其创新性在于克服了SVD在某些情况下的计算局限性。在广义源条件下对收敛率和最优性的严格理论分析，增强了该方法的可靠性。该研究对于数值分析和逆问题求解领域具有重要意义。"}}
{"id": "2507.21358", "title": "Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy", "authors": ["Jicheng Yuan", "Manh Nguyen Duc", "Qian Liu", "Manfred Hauswirth", "Danh Le Phuoc"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The manuscript has been accepted by ICONIP2025", "url": "http://arxiv.org/abs/2507.21358v3", "summary": "Vision-based bird's-eye-view (BEV) 3D object detection has advanced\nsignificantly in autonomous driving by offering cost-effectiveness and rich\ncontextual information. However, existing methods often construct BEV\nrepresentations by collapsing extracted object features, neglecting intrinsic\nenvironmental contexts, such as roads and pavements. This hinders detectors\nfrom comprehensively perceiving the characteristics of the physical world. To\nalleviate this, we introduce a multi-task learning framework, Collaborative\nPerceiver (CoP), that leverages spatial occupancy as auxiliary information to\nmine consistent structural and conceptual similarities shared between 3D object\ndetection and occupancy prediction tasks, bridging gaps in spatial\nrepresentations and feature refinement. To this end, we first propose a\npipeline to generate dense occupancy ground truths incorporating local density\ninformation (LDO) for reconstructing detailed environmental information. Next,\nwe employ a voxel-height-guided sampling (VHS) strategy to distill fine-grained\nlocal features according to distinct object properties. Furthermore, we develop\na global-local collaborative feature fusion (CFF) module that seamlessly\nintegrates complementary knowledge between both tasks, thus composing more\nrobust BEV representations. Extensive experiments on the nuScenes benchmark\ndemonstrate that CoP outperforms existing vision-based frameworks, achieving\n49.5\\% mAP and 59.2\\% NDS on the test set. Code and supplementary materials are\navailable at this link https://github.com/jichengyuan/Collaborative-Perceiver.", "comment": "The manuscript has been accepted by ICONIP2025", "pdf_url": "http://arxiv.org/pdf/2507.21358v3", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-31", "AI": {"title_translation": "协作感知器：通过局部密度感知空间占用提升基于视觉的3D目标检测", "tldr": "CoP框架通过引入空间占用作为辅助信息，提升了基于视觉的3D目标检测性能，解决了现有方法忽略环境上下文的问题。", "motivation": "现有基于视觉的鸟瞰图（BEV）3D目标检测方法在构建BEV表示时，常通过折叠提取到的对象特征来完成，忽略了道路和人行道等内在环境上下文，这阻碍了检测器全面感知物理世界的特性。", "method": "本文引入了一个多任务学习框架——协作感知器（CoP），利用空间占用作为辅助信息，挖掘3D目标检测和占用预测任务之间共享的一致结构和概念相似性。具体方法包括：1. 提出了一种生成结合局部密度信息（LDO）的密集占用真值的流水线，用于重建详细环境信息。2. 采用体素高度引导采样（VHS）策略，根据不同对象属性提取细粒度局部特征。3. 开发了一个全局-局部协作特征融合（CFF）模块，无缝整合两任务之间的互补知识，以构成更鲁棒的BEV表示。", "result": "在nuScenes基准测试上进行的广泛实验表明，CoP在测试集上实现了49.5%的mAP和59.2%的NDS，性能优于现有基于视觉的框架。", "conclusion": "协作感知器（CoP）通过有效地利用空间占用作为辅助信息，显著提升了基于视觉的3D目标检测的性能，弥合了空间表示和特征细化方面的差距，证明了多任务学习在解决环境上下文感知问题上的有效性。", "translation": "基于视觉的鸟瞰图（BEV）3D目标检测在自动驾驶领域取得了显著进展，因为它具有成本效益和丰富的上下文信息。然而，现有方法在构建BEV表示时，通常通过折叠提取到的对象特征来完成，忽略了内在的环境上下文，例如道路和人行道。这阻碍了检测器全面感知物理世界的特性。为了缓解这个问题，我们引入了一个多任务学习框架——协作感知器（CoP），它利用空间占用作为辅助信息，挖掘3D目标检测和占用预测任务之间共享的一致结构和概念相似性，弥合空间表示和特征细化方面的差距。为此，我们首先提出了一种生成结合局部密度信息（LDO）的密集占用真值的流水线，用于重建详细的环境信息。接下来，我们采用体素高度引导采样（VHS）策略，根据不同的对象属性提取细粒度局部特征。此外，我们开发了一个全局-局部协作特征融合（CFF）模块，无缝整合两个任务之间的互补知识，从而构成更鲁棒的BEV表示。在nuScenes基准测试上进行的广泛实验表明，CoP优于现有的基于视觉的框架，在测试集上实现了49.5%的mAP和59.2%的NDS。代码和补充材料可在此链接获取：https://github.com/jichengyuan/Collaborative-Perceiver。", "summary": "本文提出了协作感知器（CoP），一个基于多任务学习的框架，旨在通过利用空间占用作为辅助信息来改进基于视觉的3D目标检测。CoP通过生成结合局部密度信息的密集占用真值、采用体素高度引导采样策略提取特征以及开发全局-局部协作特征融合模块，解决了现有方法忽略环境上下文的问题。实验结果表明，CoP在nuScenes基准测试上取得了优异的性能，超越了现有视觉方法。", "keywords": "3D目标检测, BEV, 空间占用, 多任务学习, 自动驾驶", "comments": "该论文通过引入空间占用作为辅助任务，巧妙地解决了基于视觉的3D目标检测中环境上下文信息缺失的问题。其多任务学习框架，特别是LDO、VHS和CFF模块的设计，展现了对特征表示和融合的深入理解。这种方法为提升BEV表示的鲁棒性提供了新思路，对于自动驾驶领域的环境感知具有重要意义。"}}
{"id": "2507.23488", "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23488v1", "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23488v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "分段因果推理：因果发现中的模块化上下文学习", "tldr": "大型语言模型通过引入一种模块化上下文学习管道，能够显著提升因果发现的性能，相比传统基线取得了近三倍的改进。", "motivation": "因果推理对大型语言模型（LLMs）来说是一个基本挑战，传统因果发现模型在数据扰动下常出现严重过拟合和接近随机的性能。本研究旨在探讨最先进的推理模型能否稳健地执行因果发现，并如何最大化其能力。", "method": "研究团队在Corr2Cause基准上，利用OpenAI的o系列和DeepSeek-R模型家族进行因果发现研究。他们引入了一种受思维树（Tree-of-Thoughts）和思维链（Chain-of-Thoughts）方法启发的模块化上下文管道，并通过分析推理链长度、复杂性以及对传统模型和推理模型进行定性和定量比较来探讨该管道的影响。", "result": "推理优先的架构（OpenAI的o系列和DeepSeek-R）比现有方法取得了显著的原生增益。引入的模块化上下文管道使性能比传统基线提高了近三倍。研究表明，先进的推理模型代表着一个实质性的飞跃。", "conclusion": "为了最大化先进推理模型在因果发现方面的能力，精心构建的上下文框架至关重要，这为跨不同领域的因果发现提供了可推广的蓝图。", "translation": "因果推理仍然是大型语言模型面临的一个基本挑战。大型语言模型内部推理的最新进展引发了人们的兴趣，即最先进的推理模型是否能稳健地执行因果发现——这项任务中，传统模型在数据扰动下常常遭受严重的过拟合和接近随机的性能。我们在Corr2Cause基准上，使用新兴的OpenAI o系列和DeepSeek-R模型家族研究了因果发现，发现这些推理优先的架构比先前的方法取得了显著更大的原生增益。为了利用这些优势，我们引入了一种受思维树和思维链方法启发的模块化上下文管道，使得性能比传统基线提高了近三倍。我们通过分析推理链长度、复杂性，并对传统模型和推理模型进行定性和定量比较，进一步探讨了该管道的影响。我们的研究结果表明，虽然先进的推理模型代表着一个实质性的飞跃，但精心构建的上下文框架对于最大化其能力至关重要，并为跨不同领域的因果发现提供了可推广的蓝图。", "summary": "本论文探讨了大型语言模型在因果发现中的应用，指出先进推理模型（如OpenAI o系列和DeepSeek-R）在Corr2Cause基准上展现出显著的原生优势。为进一步提升性能，研究引入了一种受思维树和思维链启发的模块化上下文学习管道，该方法使性能比传统基线提高了近三倍。研究强调，虽然先进的推理模型带来了巨大进步，但精心设计的上下文框架对于充分发挥其能力，并在不同领域实现稳健的因果发现至关重要。", "keywords": "因果发现, 大型语言模型, 上下文学习, 模块化管道, 推理模型", "comments": "该论文的创新之处在于，它不仅展示了先进推理LLM在因果发现方面的卓越原生能力，更重要的是，提出了一种模块化的上下文学习管道，显著提升了它们的性能。这种借鉴了既有推理方法（如ToT、CoT）的模块化方法，提供了一个实用且可推广的框架，有效解决了传统因果发现方法中常见的过拟合和不稳定性问题。它突出了提示工程和结构化推理对于LLM处理复杂任务的重要性。"}}
{"id": "2507.23335", "title": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "authors": ["Qilin Zhou", "Haipeng Wang", "Zhengyuan Wei", "W. K. Chan"], "categories": ["cs.LG", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted by QRS 2025", "url": "http://arxiv.org/abs/2507.23335v1", "summary": "Patch robustness certification is an emerging verification approach for\ndefending against adversarial patch attacks with provable guarantees for deep\nlearning systems. Certified recovery techniques guarantee the prediction of the\nsole true label of a certified sample. However, existing techniques, if\napplicable to top-k predictions, commonly conduct pairwise comparisons on those\nvotes between labels, failing to certify the sole true label within the top k\nprediction labels precisely due to the inflation on the number of votes\ncontrolled by the attacker (i.e., attack budget); yet enumerating all\ncombinations of vote allocation suffers from the combinatorial explosion\nproblem. We propose CostCert, a novel, scalable, and precise voting-based\ncertified recovery defender. CostCert verifies the true label of a sample\nwithin the top k predictions without pairwise comparisons and combinatorial\nexplosion through a novel design: whether the attack budget on the sample is\ninfeasible to cover the smallest total additional votes on top of the votes\nuncontrollable by the attacker to exclude the true labels from the top k\nprediction labels. Experiments show that CostCert significantly outperforms the\ncurrent state-of-the-art defender PatchGuard, such as retaining up to 57.3% in\ncertified accuracy when the patch size is 96, whereas PatchGuard has already\ndropped to zero.", "comment": "accepted by QRS 2025", "pdf_url": "http://arxiv.org/pdf/2507.23335v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "深度学习模型Top-k预测的可扩展和精确补丁鲁棒性认证", "tldr": "CostCert是一种新型、可扩展且精确的基于投票的认证恢复防御器，用于深度学习模型的补丁鲁棒性认证，它在Top-k预测中无需成对比较和组合爆炸，显著优于现有技术。", "motivation": "现有的补丁鲁棒性认证技术在应用于Top-k预测时，通常通过标签间的投票进行成对比较，由于攻击者控制的投票数膨胀（攻击预算），无法精确认证Top k预测标签中的唯一真实标签；而枚举所有投票分配组合又会导致组合爆炸问题。", "method": "我们提出了CostCert，一种新颖、可扩展且精确的基于投票的认证恢复防御器。CostCert通过一种新颖的设计，验证样本的真实标签是否在Top k预测中，而无需成对比较和组合爆炸：即攻击者在样本上的攻击预算是否不足以弥补在攻击者无法控制的投票基础上，将真实标签从Top k预测标签中排除所需的最小额外总投票数。", "result": "实验表明，CostCert显著优于现有最先进的防御器PatchGuard，例如在补丁大小为96时，认证精度可保持高达57.3%，而PatchGuard已降至零。", "conclusion": "CostCert是一种有效且高效的补丁鲁棒性认证方法，能够为深度学习模型提供Top-k预测的精确和可扩展的认证恢复，显著优于现有技术。", "translation": "补丁鲁棒性认证是一种新兴的验证方法，为深度学习系统提供了可证明的对抗性补丁攻击防御保证。认证恢复技术保证了认证样本的唯一真实标签的预测。然而，现有技术，如果适用于Top-k预测，通常对标签之间的投票进行成对比较，由于攻击者控制的投票数量膨胀（即攻击预算），无法精确认证Top k预测标签中的唯一真实标签；而枚举所有投票分配组合又会导致组合爆炸问题。我们提出了CostCert，一种新颖、可扩展且精确的基于投票的认证恢复防御器。CostCert通过一种新颖的设计，验证样本的真实标签是否在Top k预测中，而无需成对比较和组合爆炸：即攻击者在样本上的攻击预算是否不足以弥补在攻击者无法控制的投票基础上，将真实标签从Top k预测标签中排除所需的最小额外总投票数。实验表明，CostCert显著优于现有最先进的防御器PatchGuard，例如在补丁大小为96时，认证精度可保持高达57.3%，而PatchGuard已降至零。", "summary": "该论文提出了一种名为CostCert的新型、可扩展且精确的基于投票的认证恢复防御器，用于深度学习模型的补丁鲁棒性认证。针对现有Top-k预测认证方法在处理攻击预算膨胀和组合爆炸问题上的不足，CostCert通过评估攻击预算是否足以将真实标签从Top k预测中排除，避免了成对比较和组合枚举。实验结果显示，CostCert在认证精度方面显著优于现有技术PatchGuard。", "keywords": "补丁鲁棒性认证, 深度学习, Top-k预测, CostCert, 对抗性攻击", "comments": "CostCert的创新之处在于其独特的设计，避免了现有Top-k预测认证方法中常见的成对比较和组合爆炸问题，从而实现了更高的可扩展性和精确性。其在极端条件（大补丁尺寸）下仍能保持显著认证精度的表现，突显了其在对抗性攻击防御方面的实际应用价值和重要性。"}}
{"id": "2507.23539", "title": "Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions", "authors": ["Piotr Indyk", "Michael Kapralov", "Kshiteej Sheth", "Tal Wagner"], "categories": ["cs.LG", "cs.DS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in ICLR 2025", "url": "http://arxiv.org/abs/2507.23539v1", "summary": "Motivated by the problem of fast processing of attention matrices, we study\nfast algorithms for computing matrix-vector products for asymmetric Gaussian\nKernel matrices $K\\in \\mathbb{R}^{n\\times n}$. $K$'s columns are indexed by a\nset of $n$ keys $k_1,k_2\\ldots, k_n\\in \\mathbb{R}^d$, rows by a set of $n$\nqueries $q_1,q_2,\\ldots,q_n\\in \\mathbb{R}^d $, and its $i,j$ entry is $K_{ij} =\ne^{-\\|q_i-k_j\\|_2^2/2\\sigma^2}$ for some bandwidth parameter $\\sigma>0$. Given\na vector $x\\in \\mathbb{R}^n$ and error parameter $\\epsilon>0$, our task is to\noutput a $y\\in \\mathbb{R}^n$ such that $\\|Kx-y\\|_2\\leq \\epsilon \\|x\\|_2$ in\ntime subquadratic in $n$ and linear in $d$. Our algorithms rely on the\nfollowing modelling assumption about the matrices $K$: the sum of the entries\nof $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We\nvalidate this assumption experimentally, for Gaussian kernel matrices\nencountered in various settings such as fast attention computation in LLMs. We\nobtain the first subquadratic-time algorithm that works under this assumption,\nfor unrestricted vectors.", "comment": "Published in ICLR 2025", "pdf_url": "http://arxiv.org/pdf/2507.23539v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "稀疏性假设下核矩阵-向量乘法的改进算法", "tldr": "在稀疏性假设下，提出了一种用于高斯核矩阵-向量乘法的亚二次时间算法，解决了注意力矩阵的快速处理问题。", "motivation": "受注意力矩阵快速处理问题的启发，研究了计算非对称高斯核矩阵-向量乘积的快速算法。", "method": "提出了计算非对称高斯核矩阵$K$的矩阵-向量乘积的快速算法。这些算法依赖于一个建模假设：矩阵$K$的条目和与$n$呈线性关系（而不是最坏情况下的二次增长）。该假设通过实验验证，适用于LLM中遇到的高斯核矩阵。", "result": "首次获得了在上述稀疏性假设下，对于无限制向量的亚二次时间算法，计算时间与$n$呈亚二次关系，与$d$呈线性关系。", "conclusion": "在稀疏性假设下，成功开发了计算高斯核矩阵-向量乘积的亚二次时间算法，这对于快速处理注意力矩阵等应用具有重要意义。", "translation": "受注意力矩阵快速处理问题的启发，我们研究了计算非对称高斯核矩阵$K\n\n\\in \n\n\\mathbb{R}^{n\n\n\\times n}$的矩阵-向量乘积的快速算法。$K$的列由$n$个键$k_1,k_2\\ldots, k_n\n\n\\in \n\n\\mathbb{R}^d$索引，行由$n$个查询$q_1,q_2,\\ldots,q_n\n\n\\in \n\n\\mathbb{R}^d$索引，其$i,j$项为$K_{ij} = e^{-\\|q_i-k_j\\|_2^2/2\n\n\\sigma^2}$，其中$\n\n\\sigma>0$是带宽参数。给定向量$x\n\n\\in \n\n\\mathbb{R}^n$和误差参数$\n\n\\epsilon>0$，我们的任务是在$n$的亚二次时间且$d$的线性时间内输出$y\n\n\\in \n\n\\mathbb{R}^n$，使得$\\|Kx-y\\|_2\n\n\\leq \n\n\\epsilon \\|x\\|_2$。我们的算法依赖于关于矩阵$K$的以下建模假设：$K$的条目和与$n$呈线性关系，而不是最坏情况下的二次增长。我们通过实验验证了这一假设，适用于在各种设置（例如LLM中的快速注意力计算）中遇到的高斯核矩阵。我们获得了在这一假设下，对于无限制向量的第一个亚二次时间算法。", "summary": "该研究提出了一种在稀疏性假设下改进高斯核矩阵-向量乘法计算的算法。其动机来源于注意力矩阵的快速处理需求。算法基于一个关键建模假设：矩阵K的条目和与n呈线性关系，并通过实验验证了该假设在LLM等场景中的有效性。最终，该研究成功开发了首个在此假设下，对于任意向量均能实现亚二次时间复杂度的算法。", "keywords": "核矩阵, 矩阵-向量乘法, 稀疏性, 高斯核, 亚二次算法", "comments": "这项研究的创新之处在于，它在对核矩阵稀疏性进行合理假设的基础上，首次实现了亚二次时间的核矩阵-向量乘法算法。这一突破对于处理大型核矩阵（如LLM中的注意力矩阵）计算效率瓶颈具有重要意义，因为它将计算复杂度从潜在的二次降低到亚二次，显著提升了处理速度。该方法通过实验验证了其假设的合理性，增强了其在实际应用中的说服力。"}}
{"id": "2503.17564", "title": "ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology", "authors": ["Vishwesh Ramanathan", "Tony Xu", "Pushpak Pati", "Faruk Ahmed", "Maged Goubran", "Anne L. Martel"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17564v2", "summary": "Prediction tasks in digital pathology are challenging due to the massive size\nof whole-slide images (WSIs) and the weak nature of training signals. Advances\nin computing, data availability, and self-supervised learning (SSL) have paved\nthe way for slide-level foundation models (SLFMs) that can improve prediction\ntasks in low-data regimes. However, current methods under-utilize shared\ninformation between tasks and modalities. To overcome this challenge, we\npropose ModalTune, a novel fine-tuning framework which introduces the Modal\nAdapter to integrate new modalities without modifying SLFM weights.\nAdditionally, we use large-language models (LLMs) to encode labels as text,\ncapturing semantic relationships across multiple tasks and cancer types in a\nsingle training recipe. ModalTune achieves state-of-the-art (SOTA) results\nagainst both uni-modal and multi-modal models across four cancer types, jointly\nimproving survival and cancer subtype prediction while remaining competitive in\npan-cancer settings. Additionally, we show ModalTune is generalizable to two\nout-of-distribution (OOD) datasets. To our knowledge, this is the first unified\nfine-tuning framework for multi-modal, multi-task, and pan-cancer modeling in\ndigital pathology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17564v2", "cate": "eess.IV", "date": "2025-03-21", "updated": "2025-07-30", "AI": {"title_translation": "ModalTune：利用多模态信息对幻灯片级基础模型进行微调，实现数字病理学中的多任务学习", "tldr": "ModalTune是一个新颖的微调框架，通过引入模态适配器和使用大型语言模型编码标签，实现了数字病理学中多模态、多任务、泛癌建模的SOTA结果，并具有良好的泛化能力。", "motivation": "数字病理学中的预测任务由于全切片图像（WSIs）的巨大尺寸和训练信号的弱性质而具有挑战性。尽管滑片级基础模型（SLFMs）在低数据量情况下可以改善预测任务，但现有方法未能充分利用任务和模态之间的共享信息。", "method": "我们提出了ModalTune，一个新颖的微调框架。它引入了模态适配器（Modal Adapter）来集成新的模态，同时不修改SLFM权重。此外，我们使用大型语言模型（LLMs）将标签编码为文本，在一个训练方案中捕获跨多个任务和癌症类型的语义关系。", "result": "ModalTune在四种癌症类型上，相对于单模态和多模态模型都取得了最先进（SOTA）的结果，同时提高了生存和癌症亚型预测的准确性，并在泛癌设置中保持了竞争力。此外，我们证明了ModalTune可以泛化到两个分布外（OOD）数据集。", "conclusion": "据我们所知，ModalTune是数字病理学中首个用于多模态、多任务和泛癌建模的统一微调框架。", "translation": "数字病理学中的预测任务由于全切片图像（WSIs）的巨大尺寸和训练信号的弱性质而具有挑战性。计算、数据可用性和自监督学习（SSL）的进步为滑片级基础模型（SLFMs）铺平了道路，这些模型可以在低数据量情况下改善预测任务。然而，现有方法未能充分利用任务和模态之间的共享信息。为了克服这一挑战，我们提出了ModalTune，一个新颖的微调框架，它引入了模态适配器（Modal Adapter）来集成新的模态，同时不修改SLFM权重。此外，我们使用大型语言模型（LLMs）将标签编码为文本，在一个训练方案中捕获跨多个任务和癌症类型的语义关系。ModalTune在四种癌症类型上，相对于单模态和多模态模型都取得了最先进（SOTA）的结果，同时提高了生存和癌症亚型预测的准确性，并在泛癌设置中保持了竞争力。此外，我们证明了ModalTune可以泛化到两个分布外（OOD）数据集。据我们所知，这是数字病理学中首个用于多模态、多任务和泛癌建模的统一微调框架。", "summary": "ModalTune是一个针对数字病理学中滑片级基础模型（SLFMs）的新型微调框架，旨在解决现有方法未能充分利用多任务和多模态共享信息的问题。该框架通过引入模态适配器集成新模态而无需修改SLFM权重，并利用大型语言模型将标签编码为文本以捕获语义关系。ModalTune在多种癌症类型上实现了SOTA性能，同时提升了生存和癌症亚型预测的准确性，并在泛癌设置和OOD数据集上展现出良好的泛化能力。这是数字病理学中首个统一的多模态、多任务和泛癌建模微调框架。", "keywords": "数字病理学, 微调, 多模态, 多任务学习, 基础模型", "comments": "该论文提出了一个创新性的统一微调框架ModalTune，解决了数字病理学中多模态、多任务和泛癌建模的挑战。其通过引入模态适配器和利用LLMs编码标签，有效地集成了多模态信息并捕获了任务间的语义关系，实现了SOTA性能和良好的泛化能力，具有重要的研究价值和应用潜力。"}}
{"id": "2501.09112", "title": "Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation", "authors": ["Andrew Engel", "Nell Byler", "Adam Tsou", "Gautham Narayan", "Emmanuel Bonilla", "Ian Smith"], "categories": ["astro-ph.IM", "cs.AI"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      Accepted at ApJ", "url": "http://arxiv.org/abs/2501.09112v2", "summary": "We present Mantis Shrimp, a multi-survey deep learning model for photometric\nredshift estimation that fuses ultra-violet (GALEX), optical (PanSTARRS), and\ninfrared (UnWISE) imagery. Machine learning is now an established approach for\nphotometric redshift estimation, with generally acknowledged higher performance\nin areas with a high density of spectroscopically identified galaxies over\ntemplate-based methods. Multiple works have shown that image-based\nconvolutional neural networks can outperform tabular-based color/magnitude\nmodels. In comparison to tabular models, image models have additional design\ncomplexities: it is largely unknown how to fuse inputs from different\ninstruments which have different resolutions or noise properties. The Mantis\nShrimp model estimates the conditional density estimate of redshift using\ncutout images. The density estimates are well calibrated and the point\nestimates perform well in the distribution of available spectroscopically\nconfirmed galaxies with (bias = 1e-2), scatter (NMAD = 2.44e-2) and\ncatastrophic outlier rate ($\\eta$=17.53$\\%$). We find that early fusion\napproaches (e.g., resampling and stacking images from different instruments)\nmatch the performance of late fusion approaches (e.g., concatenating latent\nspace representations), so that the design choice ultimately is left to the\nuser. Finally, we study how the models learn to use information across bands,\nfinding evidence that our models successfully incorporates information from all\nsurveys. The applicability of our model to the analysis of large populations of\ngalaxies is limited by the speed of downloading cutouts from external servers;\nhowever, our model could be useful in smaller studies such as generating priors\nover redshift for stellar population synthesis.", "comment": "Accepted at ApJ", "pdf_url": "http://arxiv.org/pdf/2501.09112v2", "cate": "astro-ph.IM", "date": "2025-01-15", "updated": "2025-07-31", "AI": {"title_translation": "Mantis Shrimp: 探索计算机视觉网络中光度波段的利用以进行光度红移估计", "tldr": "Mantis Shrimp是一个多巡天深度学习模型，融合了紫外、光学和红外图像，用于光度红移估计，表现良好且能有效利用多波段信息。", "motivation": "机器学习在光度红移估计中表现出色，尤其是图像模型优于表格模型。然而，如何融合来自不同分辨率和噪声特性的仪器的输入是一个未知的挑战。", "method": "提出了Mantis Shrimp模型，一个多巡天深度学习模型，融合了紫外 (GALEX)、光学 (PanSTARRS) 和红外 (UnWISE) 图像。该模型使用裁剪图像估计红移的条件密度，并研究了早期融合和晚期融合方法的性能。", "result": "密度估计校准良好，点估计在光谱确认星系分布中表现良好，偏差为1e-2，离散度 (NMAD) 为2.44e-2，灾难性异常值率为17.53%。早期融合方法与晚期融合方法的性能匹配。模型成功整合了所有巡天信息。", "conclusion": "Mantis Shrimp模型在光度红移估计中表现出色，并有效利用了多波段信息。尽管大规模应用受限于数据下载速度，但它在小规模研究（如生成红移先验）中仍有价值。", "translation": "我们提出了Mantis Shrimp，一个用于光度红移估计的多巡天深度学习模型，它融合了紫外 (GALEX)、光学 (PanSTARRS) 和红外 (UnWISE) 图像。机器学习现在是光度红移估计的成熟方法，在光谱识别星系密度高的区域，其性能普遍高于基于模板的方法。多项工作表明，基于图像的卷积神经网络可以优于基于表格的颜色/星等模型。与表格模型相比，图像模型具有额外的设计复杂性：如何融合来自不同仪器（具有不同分辨率或噪声特性）的输入在很大程度上是未知的。Mantis Shrimp模型使用裁剪图像估计红移的条件密度。密度估计经过良好校准，点估计在可用光谱确认星系的分布中表现良好，偏差为1e-2，离散度 (NMAD) 为2.44e-2，灾难性异常值率 (η) 为17.53%。我们发现早期融合方法（例如，对来自不同仪器的图像进行重采样和堆叠）与晚期融合方法（例如，连接潜在空间表示）的性能相匹配，因此设计选择最终取决于用户。最后，我们研究了模型如何学习使用跨波段信息，发现有证据表明我们的模型成功地整合了所有巡天信息。我们模型在分析大量星系群体时的适用性受到从外部服务器下载裁剪图像速度的限制；然而，我们的模型可能在较小的研究中有用，例如为恒星族合成生成红移的先验。", "summary": "Mantis Shrimp是一个创新的深度学习模型，用于通过融合紫外、光学和红外多波段图像来估计星系的光度红移。该模型克服了多源图像融合的挑战，并展示了在密度估计和点估计方面的出色性能，同时证明了其有效利用多波段信息的能力。研究还发现早期融合与晚期融合方法的性能相当，为模型设计提供了灵活性。", "keywords": "光度红移估计, 深度学习, 多波段融合, 计算机视觉, 星系", "comments": "这篇论文的创新点在于提出了一个多巡天深度学习模型Mantis Shrimp，有效地融合了来自不同波段（紫外、光学、红外）且具有不同特性（分辨率、噪声）的图像数据进行光度红移估计。它解决了图像模型在多源输入融合上的复杂性问题，并通过实证表明了早期融合和晚期融合方法的性能相似，为模型设计提供了灵活性。虽然大规模应用受限于数据下载速度，但其在小规模研究和生成红移先验方面的潜力不容忽视。"}}
{"id": "2507.21584", "title": "TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs", "authors": ["Kejia Zhang", "Keda Tao", "Zhiming Luo", "Chang Liu", "Jiasheng Tang", "Huan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21584v2", "summary": "Multimodal large language models (MLLMs) enable vision-language reasoning,\nyet often generate plausible outputs that are factually incorrect or visually\nungrounded, thereby compromising their reliability. Direct preference\noptimization (DPO) is a common strategy for correcting hallucinations by\naligning model outputs with human preferences. Existing DPO strategies\ntypically treat hallucination-related preferences as fixed targets, relying on\nstatic supervision signals during training. This approach tends to overfit to\nsuperficial linguistic cues in preference data, leading to distributional\nrigidity and spurious correlations that impair grounding in causally relevant\nvisual information. To overcome this limitation, we propose TARS, a\ntoken-adaptive preference strategy that reformulates DPO as a min-max\noptimization problem. TARS maximizes token-level distributional shifts under\nsemantic constraints to simulate alignment uncertainty, and simultaneously\nminimizes the expected preference loss under these controlled perturbations.\nThis joint objective preserves causal grounding while mitigating overfitting to\npreference patterns, thereby reducing hallucinations in multimodal reasoning.\nWe evaluate TARS on multiple hallucination benchmarks and find consistently\nstrong performance. Using only 4.8k preference samples and no expert feedback,\nTARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition\nvalue from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on\nseveral key metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21584v2", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "TARS：最小-最大令牌自适应偏好策略，用于减少多模态大语言模型中的幻觉", "tldr": "TARS是一种新的令牌自适应偏好策略，通过最小-最大优化减少多模态大语言模型中的幻觉，表现优于DPO并与GPT-4o相当。", "motivation": "多模态大语言模型（MLLMs）在视觉-语言推理中常产生事实不准确或视觉无根据的输出（幻觉），现有DPO策略因过度拟合表面语言线索而导致分布刚性和虚假关联，损害了与视觉信息的因果接地，降低了模型可靠性。", "method": "提出TARS，一种令牌自适应偏好策略，将DPO重新表述为最小-最大优化问题。TARS在语义约束下最大化令牌级别的分布变化以模拟对齐不确定性，同时最小化这些受控扰动下的预期偏好损失。这个联合目标旨在保留因果接地并减轻对偏好模式的过拟合。", "result": "在多个幻觉基准测试中表现出色。仅使用4.8k偏好样本，无需专家反馈，将幻觉率从26.4%降低到13.2%，认知值从2.5降至0.4。性能优于标准DPO，并在多个关键指标上与GPT-4o持平。", "conclusion": "TARS通过最小-最大令牌自适应偏好策略有效减少了多模态大语言模型中的幻觉，解决了现有DPO策略的局限性，并展现出强大的性能。", "translation": "多模态大语言模型（MLLMs）实现了视觉-语言推理，但通常会生成看似合理但事实不正确或视觉上无根据的输出，从而损害了它们的可靠性。直接偏好优化（DPO）是一种通过将模型输出与人类偏好对齐来纠正幻觉的常用策略。现有的DPO策略通常将与幻觉相关的偏好视为固定目标，在训练过程中依赖静态监督信号。这种方法倾向于过度拟合偏好数据中的表面语言线索，导致分布刚性和虚假关联，从而损害了与因果相关视觉信息的接地。为了克服这一限制，我们提出了TARS，一种令牌自适应偏好策略，它将DPO重新表述为一个最小-最大优化问题。TARS在语义约束下最大化令牌级别的分布变化以模拟对齐不确定性，并同时最小化这些受控扰动下的预期偏好损失。这个联合目标在减轻对偏好模式的过拟合的同时，保留了因果接地，从而减少了多模态推理中的幻觉。我们在多个幻觉基准上评估了TARS，并发现其性能始终强劲。仅使用4.8k偏好样本且无需专家反馈，TARS将幻觉率从26.4%降低到13.2%，并将认知值从2.5降低到0.4。它优于标准DPO，并在多个关键指标上与GPT-4o持平。", "summary": "本文提出了TARS，一种针对多模态大语言模型（MLLMs）的令牌自适应偏好策略，旨在减少幻觉。针对现有直接偏好优化（DPO）策略过度拟合表面语言线索导致接地不良的问题，TARS将DPO重新构想为最小-最大优化问题。它通过最大化令牌级分布变化来模拟对齐不确定性，并最小化预期偏好损失，从而在减轻过拟合的同时保持因果接地。实验结果表明，TARS在减少幻觉方面表现出色，仅用少量样本就显著降低了幻觉率和认知值，性能超越标准DPO并与GPT-4o媲美。", "keywords": "多模态大语言模型, 幻觉减少, 直接偏好优化, 令牌自适应, 最小-最大优化", "comments": "TARS的创新之处在于将DPO框架与最小-最大优化结合，解决了现有DPO在处理幻觉时过度拟合和因果接地不足的问题。通过模拟对齐不确定性，它能够更鲁棒地学习偏好，提高了多模态大语言模型的可靠性。在仅使用少量样本的情况下达到GPT-4o的性能水平，显示了其效率和潜力。"}}
{"id": "2507.23350", "title": "Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications", "authors": ["Mahmoud Ghorab", "Matthias Lorenzen"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.23350v1", "summary": "There is a growing demand for autonomous mobile robots capable of navigating\nunstructured agricultural environments. Tasks such as weed control in meadows\nrequire efficient path planning through an unordered set of coordinates while\nminimizing travel distance and adhering to curvature constraints to prevent\nsoil damage and protect vegetation. This paper presents an integrated\nnavigation framework combining a global path planner based on the Dubins\nTraveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control\n(NMPC) strategy for local path planning and control. The DTSP generates a\nminimum-length, curvature-constrained path that efficiently visits all targets,\nwhile the NMPC leverages this path to compute control signals to accurately\nreach each waypoint. The system's performance was validated through comparative\nsimulation analysis on real-world field datasets, demonstrating that the\ncoupled DTSP-based planner produced smoother and shorter paths, with a\nreduction of about 16% in the provided scenario, compared to decoupled methods.\nBased thereon, the NMPC controller effectively steered the robot to the desired\nwaypoints, while locally optimizing the trajectory and ensuring adherence to\nconstraints. These findings demonstrate the potential of the proposed framework\nfor efficient autonomous navigation in agricultural environments.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.23350v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "农业应用中非完整移动机器人的多路径点路径规划与运动控制", "tldr": "该论文提出了一种结合Dubins旅行商问题（DTSP）和非线性模型预测控制（NMPC）的集成导航框架，用于农业环境中非完整移动机器人的多路径点路径规划和运动控制，通过仿真验证其能生成更平滑、更短的路径并有效控制机器人。", "motivation": "农业环境中对能够导航的自主移动机器人的需求日益增长，尤其是在草地除草等任务中，需要高效地通过无序坐标集进行路径规划，同时最大限度地减少行驶距离并遵守曲率限制，以防止土壤损坏和保护植被。", "method": "本文提出了一种集成的导航框架，结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和用于局部路径规划与控制的非线性模型预测控制（NMPC）策略。DTSP生成最小长度、受曲率约束的路径，NMPC利用此路径计算控制信号以精确到达每个路径点。", "result": "通过对真实世界现场数据集的比较仿真分析，结果表明，与解耦方法相比，耦合的基于DTSP的规划器产生了更平滑、更短的路径，在所提供的场景中减少了约16%。NMPC控制器有效地将机器人引导至所需的路径点，同时局部优化了轨迹并确保遵守约束。", "conclusion": "这些发现证明了所提出的框架在农业环境中实现高效自主导航的潜力。", "translation": "农业环境中对能够导航的自主移动机器人的需求日益增长。草地除草等任务需要通过无序坐标集进行高效的路径规划，同时最大限度地减少行驶距离并遵守曲率限制，以防止土壤损坏和保护植被。本文提出了一种集成的导航框架，结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和用于局部路径规划与控制的非线性模型预测控制（NMPC）策略。DTSP生成最小长度、受曲率约束的路径，该路径能有效地访问所有目标点，而NMPC则利用此路径计算控制信号以精确到达每个路径点。该系统的性能通过对真实世界现场数据集的比较仿真分析进行了验证，结果表明，与解耦方法相比，耦合的基于DTSP的规划器产生了更平滑、更短的路径，在所提供的场景中减少了约16%。在此基础上，NMPC控制器有效地将机器人引导至所需的路径点，同时局部优化了轨迹并确保遵守约束。这些发现证明了所提出的框架在农业环境中实现高效自主导航的潜力。", "summary": "本论文提出了一种用于农业非完整移动机器人多路径点导航的集成框架。该框架结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和非线性模型预测控制（NMPC）策略。DTSP负责生成最小长度且满足曲率约束的路径，而NMPC则根据此路径精确控制机器人到达各路径点。仿真结果表明，相比传统方法，该耦合系统能生成更平滑、更短的路径（减少约16%），并能有效引导机器人，验证了其在农业自主导航中的潜力。", "keywords": "路径规划, 运动控制, 非完整机器人, 农业应用, Dubins旅行商问题, 模型预测控制", "comments": "该论文的创新点在于将Dubins旅行商问题（DTSP）与非线性模型预测控制（NMPC）相结合，形成一个集成导航框架，有效解决了非完整机器人在农业复杂环境中多路径点路径规划和运动控制的挑战。这种耦合方法在路径平滑度和长度优化方面表现出色，并考虑了农业应用中的具体约束（如曲率限制以保护土壤和植被）。其重要性在于为农业自动化提供了高效、可靠的导航解决方案，有望提升农业作业的效率和精度。局限性可能在于其性能验证主要基于仿真分析，实际田间测试的鲁棒性和泛化能力尚待进一步验证。"}}
{"id": "2505.10373", "title": "Reproducing the first and second moment of empirical degree distributions", "authors": ["Mattia Marzi", "Francesca Giuffrida", "Diego Garlaschelli", "Tiziano Squartini"], "categories": ["physics.soc-ph", "cs.SI", "physics.data-an", "q-fin.ST"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      17 pages, 10 figures", "url": "http://arxiv.org/abs/2505.10373v2", "summary": "The study of probabilistic models for the analysis of complex networks\nrepresents a flourishing research field. Among the former, Exponential Random\nGraphs (ERGs) have gained increasing attention over the years. So far, only\nlinear ERGs have been extensively employed to gain insight into the structural\norganisation of real-world complex networks. None, however, is capable of\naccounting for the variance of the empirical degree distribution. To this aim,\nnon-linear ERGs must be considered. After showing that the usual mean-field\napproximation forces the degree-corrected version of the two-star model to\ndegenerate, we define a fitness-induced variant of it. Such a `softened' model\nis capable of reproducing the sample variance, while retaining the explanatory\npower of its linear counterpart, within a purely canonical framework.", "comment": "17 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2505.10373v2", "cate": "physics.soc-ph", "date": "2025-05-15", "updated": "2025-07-31", "AI": {"title_translation": "复制经验度分布的一阶和二阶矩", "tldr": "现有线性指数随机图模型无法解释经验度分布的方差。本文提出了一种新的非线性、基于适应度的指数随机图变体，该模型在保持解释力的同时，能重现度分布的样本方差。", "motivation": "现有的线性指数随机图模型（ERGs）无法解释复杂网络中经验度分布的方差，因此需要考虑非线性ERGs。", "method": "作者首先证明了通常的平均场近似会导致度校正的两星模型退化，然后定义了一种适应度诱导的变体模型。", "result": "所提出的“软化”模型能够在纯粹的规范框架内重现样本方差，同时保留其线性对应模型的解释力。", "conclusion": "通过引入非线性和适应度诱导的变体，可以构建能够解释经验度分布方差的指数随机图模型，同时保持其解释能力。", "translation": "复杂网络分析中的概率模型研究是一个蓬勃发展的研究领域。其中，指数随机图（ERGs）多年来受到越来越多的关注。到目前为止，只有线性ERGs被广泛用于深入了解真实世界复杂网络的结构组织。然而，没有一个模型能够解释经验度分布的方差。为此，必须考虑非线性ERGs。在证明了通常的平均场近似会使度校正的两星模型退化后，我们定义了一种适应度诱导的变体。这种“软化”模型能够在纯粹的规范框架内重现样本方差，同时保留其线性对应模型的解释力。", "summary": "本文探讨了复杂网络分析中指数随机图（ERGs）的应用。指出现有线性ERGs无法解释经验度分布的方差问题，并提出需要非线性ERGs。作者通过证明平均场近似下两星模型的退化，进而引入了一种新的、基于适应度的“软化”ERGs变体。该模型被证明能够在标准的框架下成功重现样本方差，并保持了线性ERGs的解释能力。", "keywords": "指数随机图, 复杂网络, 度分布, 样本方差, 非线性模型", "comments": "这篇论文的创新点在于提出了一个能够捕获经验度分布方差的非线性指数随机图模型。现有模型通常只能处理均值，而忽略方差，这限制了它们在复杂网络分析中的应用。通过引入适应度诱导的变体，该研究为更全面地理解和建模复杂网络的结构特性提供了新的工具。其重要性在于提升了指数随机图模型在实际网络分析中的准确性和适用性。"}}
{"id": "2507.23311", "title": "Forgetting of task-specific knowledge in model merging-based continual learning", "authors": ["Timm Hess", "Gido M van de Ven", "Tinne Tuytelaars"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23311v1", "summary": "This paper investigates the linear merging of models in the context of\ncontinual learning (CL). Using controlled visual cues in computer vision\nexperiments, we demonstrate that merging largely preserves or enhances shared\nknowledge, while unshared task-specific knowledge rapidly degrades. We further\nfind that merging models from an incremental training process consistently\noutperforms merging models trained in parallel.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23311v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "模型合并式持续学习中任务特定知识的遗忘", "tldr": "模型合并在持续学习中会快速遗忘任务特定知识，但能保留或增强共享知识，且增量训练的模型合并效果优于并行训练。", "motivation": "本文旨在探究持续学习（CL）背景下模型线性合并对知识保留与遗忘的影响。", "method": "通过在计算机视觉实验中使用受控的视觉线索，研究模型线性合并。", "result": "模型合并主要保留或增强共享知识，而未共享的任务特定知识迅速退化。来自增量训练过程的模型合并效果始终优于并行训练的模型合并。", "conclusion": "模型合并在持续学习中会导致任务特定知识的快速遗忘，但能有效保留共享知识；且增量训练的模型更适合进行合并。", "translation": "本文研究了持续学习 (CL) 背景下的模型线性合并。通过在计算机视觉实验中使用受控的视觉线索，我们证明了合并在很大程度上保留或增强了共享知识，而未共享的任务特定知识则迅速退化。我们进一步发现，合并来自增量训练过程的模型始终优于合并并行训练的模型。", "summary": "本文探讨了持续学习中模型线性合并对知识的影响。研究发现，模型合并能保留或增强共享知识，但会导致任务特定知识快速遗忘。此外，增量训练的模型合并效果优于并行训练的模型。", "keywords": "模型合并, 持续学习, 知识遗忘, 任务特定知识, 增量训练", "comments": "该研究揭示了模型合并在持续学习中存在的“灾难性遗忘”问题，特别是在任务特定知识方面。其关于增量训练模型合并性能优于并行训练模型的发现，为未来持续学习的模型合并策略提供了重要指导。"}}
{"id": "2505.14874", "title": "Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages", "authors": ["Chin-Jou Li", "Eunjung Yeo", "Kwanghee Choi", "Paula Andrea Pérez-Toro", "Masao Someki", "Rohan Kumar Das", "Zhengjun Yue", "Juan Rafael Orozco-Arroyave", "Elmar Nöth", "David R. Mortensen"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      5 pages, 1 figure, Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2505.14874v4", "summary": "Automatic speech recognition (ASR) for dysarthric speech remains challenging\ndue to data scarcity, particularly in non-English languages. To address this,\nwe fine-tune a voice conversion model on English dysarthric speech (UASpeech)\nto encode both speaker characteristics and prosodic distortions, then apply it\nto convert healthy non-English speech (FLEURS) into non-English dysarthric-like\nspeech. The generated data is then used to fine-tune a multilingual ASR model,\nMassively Multilingual Speech (MMS), for improved dysarthric speech\nrecognition. Evaluation on PC-GITA (Spanish), EasyCall (Italian), and SSNCE\n(Tamil) demonstrates that VC with both speaker and prosody conversion\nsignificantly outperforms the off-the-shelf MMS performance and conventional\naugmentation techniques such as speed and tempo perturbation. Objective and\nsubjective analyses of the generated data further confirm that the generated\nspeech simulates dysarthric characteristics.", "comment": "5 pages, 1 figure, Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2505.14874v4", "cate": "cs.CL", "date": "2025-05-20", "updated": "2025-07-31", "AI": {"title_translation": "迈向包容性ASR：研究低资源语言中构音障碍语音识别的语音转换", "tldr": "利用语音转换技术为低资源语言生成构音障碍语音数据，以改善构音障碍语音识别性能。", "motivation": "构音障碍语音的自动语音识别（ASR）面临数据稀缺的挑战，特别是在非英语语言中。", "method": "研究者首先在一个语音转换（VC）模型上进行微调，使其学习英语构音障碍语音（UASpeech）中的说话者特征和韵律失真。随后，该模型被用于将健康的非英语语音（FLEURS）转换为类构音障碍的非英语语音。最后，利用这些生成的合成数据来微调一个多语言ASR模型（Massively Multilingual Speech, MMS），以提高构音障碍语音识别的性能。", "result": "在PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）上的评估表明，结合说话者和韵律转换的VC方法显著优于现成的MMS性能和传统的增强技术（如语速和节奏扰动）。对生成数据的客观和主观分析进一步证实，生成的语音能够有效模拟构音障碍的特征。", "conclusion": "语音转换技术能够有效生成模拟构音障碍特征的合成语音数据，从而显著提升低资源语言中构音障碍语音识别的性能。", "translation": "自动语音识别（ASR）对于构音障碍语音而言仍然充满挑战，这主要是由于数据稀缺，尤其是在非英语语言中。为了解决这个问题，我们对一个语音转换模型进行了微调，使其在英语构音障碍语音（UASpeech）上学习说话者特征和韵律失真，然后将其应用于将健康的非英语语音（FLEURS）转换为类构音障碍的非英语语音。随后，生成的合成数据被用于微调一个多语言ASR模型（Massively Multilingual Speech, MMS），以改善构音障碍语音识别。在PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）上的评估表明，结合说话者和韵律转换的VC方法显著优于现成的MMS性能和传统的增强技术，例如语速和节奏扰动。对生成数据的客观和主观分析进一步证实，生成的语音模拟了构音障碍的特征。", "summary": "本研究旨在解决低资源语言中构音障碍语音ASR的数据稀缺问题。通过在一个语音转换模型上微调，使其学习英语构音障碍语音的特征，然后应用于将健康的非英语语音转换为合成的构音障碍样语音。这些合成数据被用于微调多语言ASR模型（MMS）。实验结果表明，该语音转换方法在多种低资源语言中显著优于基线MMS模型和传统数据增强方法，且生成的语音有效模拟了构音障碍特征，从而提升了构音障碍语音识别的包容性。", "keywords": "构音障碍语音识别, 语音转换, 低资源语言, 数据增强, 多语言ASR", "comments": "这项研究创新性地利用语音转换技术来解决低资源语言中构音障碍语音数据稀缺的问题，通过合成数据来增强ASR模型。其重要性在于提升了ASR对特殊人群（构音障碍者）的包容性，尤其是在非英语语种方面。"}}
{"id": "2502.17264", "title": "Kandinsky Conformal Prediction: Beyond Class- and Covariate-Conditional Coverage", "authors": ["Konstantina Bairaktari", "Jiayun Wu", "Zhiwei Steven Wu"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.17264v2", "summary": "Conformal prediction is a powerful distribution-free framework for\nconstructing prediction sets with coverage guarantees. Classical methods, such\nas split conformal prediction, provide marginal coverage, ensuring that the\nprediction set contains the label of a random test point with a target\nprobability. However, these guarantees may not hold uniformly across different\nsubpopulations, leading to disparities in coverage. Prior work has explored\ncoverage guarantees conditioned on events related to the covariates and label\nof the test point. We present Kandinsky conformal prediction, a framework that\nsignificantly expands the scope of conditional coverage guarantees. In contrast\nto Mondrian conformal prediction, which restricts its coverage guarantees to\ndisjoint groups -- reminiscent of the rigid, structured grids of Piet\nMondrian's art -- our framework flexibly handles overlapping and fractional\ngroup memberships defined jointly on covariates and labels, reflecting the\nlayered, intersecting forms in Wassily Kandinsky's compositions. Our algorithm\nunifies and extends existing methods, encompassing covariate-based group\nconditional, class conditional, and Mondrian conformal prediction as special\ncases, while achieving a minimax-optimal high-probability conditional coverage\nbound. Finally, we demonstrate the practicality of our approach through\nempirical evaluation on real-world datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.17264v2", "cate": "cs.LG", "date": "2025-02-24", "updated": "2025-07-31", "AI": {"title_translation": "Kandinsky 共形预测：超越类别和协变量条件覆盖", "tldr": "Kandinsky 共形预测是一种新的框架，它显著扩展了条件覆盖保证的范围，能够灵活处理重叠和分数组成员资格，并统一了现有方法。", "motivation": "经典共形预测方法提供边际覆盖，但在不同子群体中可能导致覆盖率差异。现有工作在条件覆盖方面存在限制，无法灵活处理重叠和分数组成员资格。本研究旨在解决这一问题，提供更广泛的条件覆盖保证。", "method": "本文提出了Kandinsky共形预测框架，该框架灵活处理在协变量和标签上共同定义的重叠和分数组成员资格。它统一并扩展了现有方法，包括基于协变量的组条件、类别条件和Mondrian共形预测，并实现了极小极大最优的高概率条件覆盖边界。", "result": "Kandinsky共形预测框架统一并扩展了现有方法，将其作为特例包含在内，并实现了极小极大最优的高概率条件覆盖边界。通过在真实世界数据集上的实证评估，证明了该方法的实用性。", "conclusion": "Kandinsky共形预测通过灵活处理重叠和分数组成员资格，显著扩展了条件覆盖保证的范围，统一并改进了现有方法，并实现了最优的覆盖边界。", "translation": "共形预测是一个强大的无分布框架，用于构建具有覆盖保证的预测集。经典方法，如分裂共形预测，提供边际覆盖，确保预测集以目标概率包含随机测试点的标签。然而，这些保证可能不会在不同子群体中均匀成立，导致覆盖率差异。先前的工作已经探索了基于测试点协变量和标签相关事件的条件覆盖保证。我们提出了Kandinsky共形预测，这是一个显著扩展条件覆盖保证范围的框架。与Mondrian共形预测不同，后者将其覆盖保证限制在不相交的组——这让人联想到Piet Mondrian艺术中僵硬、结构化的网格——我们的框架灵活地处理在协变量和标签上共同定义的重叠和分数组成员资格，这反映了Wassily Kandinsky作品中分层、交叉的形态。我们的算法统一并扩展了现有方法，将基于协变量的组条件、类别条件和Mondrian共形预测作为特例包含在内，同时实现了极小极大最优的高概率条件覆盖边界。最后，我们通过在真实世界数据集上的实证评估证明了我们方法的实用性。", "summary": "本文介绍了Kandinsky共形预测，一个显著扩展条件覆盖保证范围的新框架。与传统方法（如Mondrian共形预测）不同，Kandinsky框架能够灵活处理在协变量和标签上共同定义的重叠和分数组成员资格。该算法统一并扩展了现有的条件覆盖方法，实现了极小极大最优的高概率条件覆盖边界，并在真实世界数据集上验证了其实用性。", "keywords": "共形预测, 条件覆盖, 重叠组, 预测集", "comments": "Kandinsky共形预测的创新之处在于其能够处理重叠和分数组成员资格的条件覆盖，这比现有方法（如Mondrian共形预测）有了显著进步，使其在更复杂的现实场景中具有更强的适用性。该框架对现有方法的统一和扩展，也表明了其更通用和强大的潜力。"}}
{"id": "2507.22136", "title": "Color as the Impetus: Transforming Few-Shot Learner", "authors": ["Chaofei Qi", "Zhitai Liu", "Jianbin Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22136v2", "summary": "Humans possess innate meta-learning capabilities, partly attributable to\ntheir exceptional color perception. In this paper, we pioneer an innovative\nviewpoint on few-shot learning by simulating human color perception mechanisms.\nWe propose the ColorSense Learner, a bio-inspired meta-learning framework that\ncapitalizes on inter-channel feature extraction and interactive learning. By\nstrategically emphasizing distinct color information across different channels,\nour approach effectively filters irrelevant features while capturing\ndiscriminative characteristics. Color information represents the most intuitive\nvisual feature, yet conventional meta-learning methods have predominantly\nneglected this aspect, focusing instead on abstract feature differentiation\nacross categories. Our framework bridges the gap via synergistic color-channel\ninteractions, enabling better intra-class commonality extraction and larger\ninter-class differences. Furthermore, we introduce a meta-distiller based on\nknowledge distillation, ColorSense Distiller, which incorporates prior teacher\nknowledge to augment the student network's meta-learning capacity. We've\nconducted comprehensive coarse/fine-grained and cross-domain experiments on\neleven few-shot benchmarks for validation. Numerous experiments reveal that our\nmethods have extremely strong generalization ability, robustness, and\ntransferability, and effortless handle few-shot classification from the\nperspective of color perception.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22136v2", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "颜色作为动力：变革少样本学习器", "tldr": "本文提出了一种名为ColorSense Learner的生物启发式元学习框架，通过模拟人类颜色感知机制来解决少样本学习问题，并引入了ColorSense Distiller以增强学习能力，实验证明其在少样本分类中具有强大的泛化能力、鲁棒性和可迁移性。", "motivation": "人类拥有先天的元学习能力，部分归因于其卓越的颜色感知。然而，传统的元学习方法主要关注抽象特征区分，却忽略了颜色这一最直观的视觉特征。本文旨在弥补这一空白，通过模拟人类颜色感知机制来改进少样本学习。", "method": "本文提出了ColorSense Learner，一个生物启发式的元学习框架，利用通道间特征提取和交互式学习，通过策略性地强调不同通道的颜色信息来过滤无关特征并捕获判别性特征。此外，还引入了基于知识蒸馏的元蒸馏器ColorSense Distiller，整合教师先验知识以增强学生网络的元学习能力。", "result": "在十一个少样本基准上进行了全面的粗/细粒度和跨域实验。结果表明，所提出的方法具有极强的泛化能力、鲁棒性和可迁移性，并且能够轻松地从颜色感知的角度处理少样本分类。", "conclusion": "本文提出的ColorSense Learner和ColorSense Distiller通过模拟人类颜色感知机制，有效提升了少样本学习的性能，尤其在泛化能力、鲁棒性和可迁移性方面表现出色，证明了颜色信息在少样本分类中的重要作用。", "translation": "人类拥有先天的元学习能力，部分归因于其卓越的颜色感知。在本文中，我们通过模拟人类颜色感知机制，开创了少样本学习的一个创新视角。我们提出了ColorSense Learner，一个生物启发式的元学习框架，它利用通道间特征提取和交互式学习。通过策略性地强调不同通道的独特颜色信息，我们的方法有效过滤了不相关特征，同时捕获了判别性特征。颜色信息代表了最直观的视觉特征，然而传统的元学习方法却主要忽视了这一方面，转而专注于跨类别的抽象特征区分。我们的框架通过协同的颜色通道交互弥合了这一差距，从而实现更好的类内共性提取和更大的类间差异。此外，我们引入了一个基于知识蒸馏的元蒸馏器，ColorSense Distiller，它整合了先验教师知识，以增强学生网络的元学习能力。我们已经在十一个少样本基准上进行了全面的粗/细粒度和跨域实验进行验证。大量实验表明，我们的方法具有极强的泛化能力、鲁棒性和可迁移性，并且能够轻松地从颜色感知的角度处理少样本分类。", "summary": "本文提出了一种创新的少样本学习方法——ColorSense Learner，灵感来源于人类卓越的颜色感知能力。该框架通过模拟人类对颜色的感知机制，利用通道间特征提取和交互式学习，有效筛选无关特征并捕获判别性特征，从而更好地提取类内共性并区分类间差异。此外，引入了基于知识蒸馏的ColorSense Distiller以增强学习能力。在多项少样本基准测试中，该方法展现出强大的泛化、鲁棒性和可迁移性，证明了颜色信息在少样本分类中的重要作用。", "keywords": "少样本学习, 颜色感知, 元学习, 知识蒸馏, ColorSense Learner", "comments": "本文的创新点在于首次将人类颜色感知机制引入到少样本学习中，为该领域提供了一个全新的视角。通过利用颜色这一直观视觉特征，并结合通道间交互和知识蒸馏，有效提升了模型的学习能力和泛化性。该研究强调了生物启发式方法在AI领域的潜力，对于未来设计更高效、更具鲁棒性的少样本学习算法具有重要意义。"}}
{"id": "2507.23010", "title": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "authors": ["Siwoo Park"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23010v1", "summary": "This paper investigates the inverse capabilities and broader utility of\nmultimodal latent spaces within task-specific AI (Artificial Intelligence)\nmodels. While these models excel at their designed forward tasks (e.g.,\ntext-to-image generation, audio-to-text transcription), their potential for\ninverse mappings remains largely unexplored. We propose an optimization-based\nframework to infer input characteristics from desired outputs, applying it\nbidirectionally across Text-Image (BLIP, Flux.1-dev) and Text-Audio\n(Whisper-Large-V3, Chatterbox-TTS) modalities.\n  Our central hypothesis posits that while optimization can guide models\ntowards inverse tasks, their multimodal latent spaces will not consistently\nsupport semantically meaningful and perceptually coherent inverse mappings.\nExperimental results consistently validate this hypothesis. We demonstrate that\nwhile optimization can force models to produce outputs that align textually\nwith targets (e.g., a text-to-image model generating an image that an image\ncaptioning model describes correctly, or an ASR model transcribing optimized\naudio accurately), the perceptual quality of these inversions is chaotic and\nincoherent. Furthermore, when attempting to infer the original semantic input\nfrom generative models, the reconstructed latent space embeddings frequently\nlack semantic interpretability, aligning with nonsensical vocabulary tokens.\n  These findings highlight a critical limitation. multimodal latent spaces,\nprimarily optimized for specific forward tasks, do not inherently possess the\nstructure required for robust and interpretable inverse mappings. Our work\nunderscores the need for further research into developing truly semantically\nrich and invertible multimodal latent spaces.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23010v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "多模态潜在空间可逆性研究：基于优化方法的局限性", "tldr": "本研究探讨了多模态潜在空间的反向映射能力，发现尽管基于优化的方法可以强制模型生成文本上对齐的输出，但其感知质量混乱且缺乏语义连贯性，表明为正向任务优化的多模态潜在空间不具备鲁棒和可解释的反向映射结构。", "motivation": "尽管多模态AI模型在正向任务（如文本到图像生成、音频到文本转录）上表现出色，但其反向映射的潜力在很大程度上尚未被探索。本研究旨在调查这些模型的反向能力和更广泛的实用性。", "method": "提出了一种基于优化的框架，用于从期望输出推断输入特性。该框架双向应用于文本-图像（BLIP, Flux.1-dev）和文本-音频（Whisper-Large-V3, Chatterbox-TTS）模态。", "result": "实验结果一致验证了假设：虽然优化可以强制模型生成与目标文本对齐的输出，但这些反向映射的感知质量是混乱且不连贯的。此外，重建的潜在空间嵌入经常缺乏语义可解释性，与无意义的词汇标记对齐。", "conclusion": "多模态潜在空间，主要为特定的正向任务优化，不固有地具备鲁棒和可解释的反向映射所需的结构。", "translation": "本论文研究了任务特定AI（人工智能）模型中多模态潜在空间的反向能力和更广泛的实用性。尽管这些模型在其设计的正向任务（例如，文本到图像生成，音频到文本转录）上表现出色，但其反向映射的潜力在很大程度上尚未被探索。我们提出了一种基于优化的框架，用于从期望输出推断输入特性，并将其双向应用于文本-图像（BLIP，Flux.1-dev）和文本-音频（Whisper-Large-V3，Chatterbox-TTS）模态。\n我们的核心假设是，虽然优化可以引导模型完成反向任务，但其多模态潜在空间不会持续支持语义上有意义和感知上连贯的反向映射。实验结果一致验证了这一假设。我们证明了，虽然优化可以强制模型产生与目标文本对齐的输出（例如，文本到图像模型生成一个图像，该图像可以被图像字幕模型正确描述，或者ASR模型准确转录优化后的音频），但这些反向的感知质量是混乱且不连贯的。此外，当试图从生成模型推断原始语义输入时，重建的潜在空间嵌入经常缺乏语义可解释性，与无意义的词汇标记对齐。\n这些发现突出了一个关键局限性。多模态潜在空间，主要为特定的正向任务优化，不固有地具备鲁棒和可解释的反向映射所需的结构。我们的工作强调了需要进一步研究开发真正语义丰富和可逆的多模态潜在空间。", "summary": "本研究探讨了多模态AI模型潜在空间的反向映射能力，尤其关注基于优化方法的局限性。论文提出了一种优化框架，并将其应用于文本-图像和文本-音频模态，旨在从输出推断输入。实验结果表明，尽管优化能使模型生成文本上对齐的输出，但反向映射的感知质量混乱，且重建的潜在空间嵌入缺乏语义可解释性。这表明当前为正向任务优化的多模态潜在空间不具备支持鲁棒和可解释的反向映射所需的结构，强调了未来研究需开发更具可逆性和语义丰富性的多模态潜在空间。", "keywords": "多模态潜在空间, 可逆性, 优化方法, 反向映射, 语义可解释性", "comments": "这项工作揭示了当前多模态潜在空间的一个关键局限性，即它们在反向映射方面的不足。其创新之处在于通过实验验证了即使使用优化方法，这些空间也难以产生语义连贯且感知质量高的反向结果。这对于理解现有模型的内在结构和指导未来可逆多模态模型的设计具有重要意义。"}}
{"id": "2507.23296", "title": "Exploiting Movable Elements of Intelligent Reflecting Surface for Enhancement of Integrated Sensing and Communication", "authors": ["Xingyu Peng", "Qin Tao", "Yong Liang Guan", "Xiaoming Chen"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 13 figures", "url": "http://arxiv.org/abs/2507.23296v1", "summary": "In this paper, we propose to exploit movable elements of intelligent\nreflecting surface (IRS) to enhance the overall performance of integrated\nsensing and communication (ISAC) systems. Firstly, focusing on a single-user\nscenario, we reveal the function of movable elements by performance analysis,\nand then design a joint beamforming and element position optimization scheme.\nFurther, we extend it to a general multi-user scenario, and also propose an\nelement position optimization scheme according to the derived performance\nexpressions. Finally, simulation results confirm that the movement of IRS\nelements can improve the communication rate and the sensing accuracy, and\nespecially broaden the coverage of ISAC.", "comment": "16 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.23296v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "利用智能反射面的可移动单元增强集成感知与通信", "tldr": "该研究提出利用智能反射面的可移动单元来提升集成感知与通信系统的性能，并通过仿真验证了其在提高通信速率、感知精度和覆盖范围方面的有效性。", "motivation": "提升集成感知与通信（ISAC）系统的整体性能。", "method": "首先，针对单用户场景，通过性能分析揭示可移动单元的功能，并设计联合波束成形和单元位置优化方案。其次，将其扩展到多用户场景，并根据性能表达式提出单元位置优化方案。", "result": "仿真结果表明，IRS单元的移动可以提高通信速率和感知精度，并尤其拓宽ISAC的覆盖范围。", "conclusion": "利用智能反射面的可移动单元可以有效提升集成感知与通信系统的性能，包括通信速率、感知精度和覆盖范围。", "translation": "本文提出利用智能反射面（IRS）的可移动单元来增强集成感知与通信（ISAC）系统的整体性能。首先，针对单用户场景，我们通过性能分析揭示了可移动单元的功能，然后设计了一个联合波束成形和单元位置优化方案。此外，我们将其扩展到一般的多用户场景，并根据导出的性能表达式提出了一个单元位置优化方案。最后，仿真结果证实了IRS单元的移动可以提高通信速率和感知精度，并且尤其拓宽了ISAC的覆盖范围。", "summary": "本文提出了一种利用智能反射面（IRS）可移动单元来提升集成感知与通信（ISAC）系统性能的方法。研究首先在单用户场景下分析了可移动单元的作用，并设计了波束成形与单元位置联合优化方案；随后将其推广至多用户场景，并提出了相应的单元位置优化方案。仿真结果验证了IRS单元移动能有效提高通信速率、感知精度并扩大ISAC覆盖范围。", "keywords": "智能反射面, 集成感知与通信, 可移动单元, 波束成形, 性能增强", "comments": "该论文提出了一种新颖的方法，通过利用智能反射面（IRS）的可移动单元来动态调整信号传播环境，从而同时优化集成感知与通信（ISAC）系统的性能。其创新点在于将IRS单元的物理移动性引入到ISAC系统中进行性能增强，而非仅仅是静态反射。这为未来的ISAC系统设计提供了新的思路，特别是在复杂和动态环境下。然而，实际部署中可移动单元的实现成本和复杂性可能是一个挑战。"}}
{"id": "2507.22941", "title": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "authors": ["Paul Minchella", "Loïc Verlingue", "Stéphane Chrétien", "Rémi Vaucher", "Guillaume Metzler"], "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures, accepted for ECML PKDD 2025", "url": "http://arxiv.org/abs/2507.22941v1", "summary": "Electronic medical reports (EHR) contain a vast amount of information that\ncan be leveraged for machine learning applications in healthcare. However,\nexisting survival analysis methods often struggle to effectively handle the\ncomplexity of textual data, particularly in its sequential form. Here, we\npropose SigBERT, an innovative temporal survival analysis framework designed to\nefficiently process a large number of clinical reports per patient. SigBERT\nprocesses timestamped medical reports by extracting and averaging word\nembeddings into sentence embeddings. To capture temporal dynamics from the time\nseries of sentence embedding coordinates, we apply signature extraction from\nrough path theory to derive geometric features for each patient, which\nsignificantly enhance survival model performance by capturing complex temporal\ndynamics. These features are then integrated into a LASSO-penalized Cox model\nto estimate patient-specific risk scores. The model was trained and evaluated\non a real-world oncology dataset from the L\\'eon B\\'erard Center corpus, with a\nC-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT\nintegrates sequential medical data to enhance risk estimation, advancing\nnarrative-based survival analysis.", "comment": "12 pages, 2 figures, accepted for ECML PKDD 2025", "pdf_url": "http://arxiv.org/pdf/2507.22941v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "SigBERT：结合叙述性医疗报告和粗路径签名理论用于肿瘤生存风险估计", "tldr": "SigBERT是一个新的框架，通过结合词嵌入和粗路径签名理论来处理时间戳医疗报告，以提高肿瘤患者的生存风险估计。", "motivation": "现有生存分析方法难以有效处理文本数据的复杂性，特别是其序列形式。", "method": "SigBERT通过提取并平均词嵌入为句嵌入来处理带时间戳的医疗报告。为了捕捉句嵌入坐标时间序列中的时间动态，应用粗路径理论中的签名提取来导出几何特征。这些特征随后被整合到LASSO惩罚的Cox模型中，以估计患者特异性风险评分。", "result": "该模型在莱昂·贝拉德中心语料库的真实肿瘤学数据集上进行训练和评估，在独立测试队列上的C指数得分为0.75（标准差0.014）。", "conclusion": "SigBERT整合了序列医疗数据以增强风险估计，推动了基于叙述的生存分析。", "translation": "电子病历（EHR）包含大量信息，可用于医疗保健领域的机器学习应用。然而，现有的生存分析方法往往难以有效处理文本数据的复杂性，特别是其序列形式。本文提出了SigBERT，一个创新的时间生存分析框架，旨在高效处理每位患者的大量临床报告。SigBERT通过提取词嵌入并平均为句嵌入来处理带时间戳的医疗报告。为了捕捉句嵌入坐标时间序列中的时间动态，我们应用粗路径理论中的签名提取来导出每位患者的几何特征，这通过捕捉复杂的时间动态显著增强了生存模型性能。这些特征随后被整合到LASSO惩罚的Cox模型中，以估计患者特异性风险评分。该模型在莱昂·贝拉德中心语料库的真实肿瘤学数据集上进行训练和评估，在独立测试队列上的C指数得分为0.75（标准差0.014）。SigBERT整合了序列医疗数据以增强风险估计，推动了基于叙述的生存分析。", "summary": "SigBERT是一个创新的时间生存分析框架，旨在处理电子病历中的叙述性文本数据以提高生存风险估计。它将时间戳医疗报告转换为句嵌入，然后利用粗路径签名理论提取几何特征以捕捉复杂的时间动态。这些特征被输入到LASSO-惩罚的Cox模型中。该方法在真实的肿瘤学数据集上实现了0.75的C指数，显示了其在增强基于叙述的生存分析方面的潜力。", "keywords": "生存分析, 医疗报告, 粗路径签名, 风险估计, SigBERT", "comments": "SigBERT的创新之处在于其将自然语言处理（通过词嵌入和句嵌入）与时间序列分析（通过粗路径签名理论）相结合，以处理复杂的叙述性医疗报告，从而改进生存风险估计。这种方法有效地捕捉了文本数据中的时间动态，克服了现有生存分析方法在处理此类数据时的局限性。其在真实世界肿瘤数据集上的良好表现证明了其在临床应用中的潜力。"}}
{"id": "2507.23659", "title": "Nyldon Factorization of Thue-Morse Words and Fibonacci Words", "authors": ["Kaisei Kishi", "Kazuki Kai", "Yuto Nakashima", "Shunsuke Inenaga", "Hideo Bannai"], "categories": ["cs.DS", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      A full version of our conference paper accepted for SPIRE 2025", "url": "http://arxiv.org/abs/2507.23659v1", "summary": "The Nyldon factorization is a string factorization that is a non-decreasing\nproduct of Nyldon words. Nyldon words and Nyldon factorizations are recently\ndefined combinatorial objects inspired by the well-known Lyndon words and\nLyndon factorizations. In this paper, we investigate the Nyldon factorization\nof several words. First, we fully characterize the Nyldon factorizations of the\n(finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that\nthere exists a non-decreasing product of Nyldon words that is a factorization\nof the infinite Thue-Morse word.", "comment": "A full version of our conference paper accepted for SPIRE 2025", "pdf_url": "http://arxiv.org/pdf/2507.23659v1", "cate": "cs.DS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Nyldon 因子分解在 Thue-Morse 词和 Fibonacci 词中的应用", "tldr": "本文研究了 Nyldon 因子分解，并完全刻画了有限的 Fibonacci 词和 Thue-Morse 词的 Nyldon 因子分解。此外，还证明了无限 Thue-Morse 词存在 Nyldon 词的非递减乘积因子分解。", "motivation": "Nyldon 词和 Nyldon 因子分解是受著名的 Lyndon 词和 Lyndon 因子分解启发而新近定义的组合对象，本文旨在对其进行研究。", "method": "本文研究了几种词的 Nyldon 因子分解。首先，完全刻画了（有限的）Fibonacci 词和（有限的）Thue-Morse 词的 Nyldon 因子分解。", "result": "本文完全刻画了（有限的）Fibonacci 词和（有限的）Thue-Morse 词的 Nyldon 因子分解。此外，研究表明存在一个 Nyldon 词的非递减乘积，它是无限 Thue-Morse 词的一个因子分解。", "conclusion": "本文成功地刻画了有限 Fibonacci 词和 Thue-Morse 词的 Nyldon 因子分解，并证明了无限 Thue-Morse 词的特定因子分解的存在性。", "translation": "Nyldon 因子分解是一种字符串因子分解，它是 Nyldon 词的非递减乘积。Nyldon 词和 Nyldon 因子分解是最近定义的组合对象，灵感来源于著名的 Lyndon 词和 Lyndon 因子分解。在本文中，我们研究了几种词的 Nyldon 因子分解。首先，我们完全刻画了（有限的）Fibonacci 词和（有限的）Thue-Morse 词的 Nyldon 因子分解。此外，我们证明了存在一个 Nyldon 词的非递减乘积，它是无限 Thue-Morse 词的一个因子分解。", "summary": "本文深入探讨了新近定义的 Nyldon 因子分解。研究人员首先对有限的 Fibonacci 词和 Thue-Morse 词的 Nyldon 因子分解进行了全面的刻画。在此基础上，他们进一步证明了无限 Thue-Morse 词可以通过 Nyldon 词的非递减乘积进行因子分解。这项工作扩展了对字符串因子分解和组合对象 Nyldon 词的理解。", "keywords": "Nyldon 因子分解, Thue-Morse 词, Fibonacci 词, 字符串因子分解, 组合词", "comments": "本文关注新近提出的 Nyldon 因子分解，并将其应用于经典的组合词（如 Thue-Morse 词和 Fibonacci 词），这显示了其在字符串组合学领域的创新性和重要性。对有限和无限情况的探讨增加了研究的完整性。"}}
{"id": "2507.23782", "title": "MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion", "authors": ["Zihan Wang", "Jeff Tan", "Tarasha Khurana", "Neehar Peri", "Deva Ramanan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2507.23782v1", "summary": "We address the problem of dynamic scene reconstruction from sparse-view\nvideos. Prior work often requires dense multi-view captures with hundreds of\ncalibrated cameras (e.g. Panoptic Studio). Such multi-view setups are\nprohibitively expensive to build and cannot capture diverse scenes in-the-wild.\nIn contrast, we aim to reconstruct dynamic human behaviors, such as repairing a\nbike or dancing, from a small set of sparse-view cameras with complete scene\ncoverage (e.g. four equidistant inward-facing static cameras). We find that\ndense multi-view reconstruction methods struggle to adapt to this sparse-view\nsetup due to limited overlap between viewpoints. To address these limitations,\nwe carefully align independent monocular reconstructions of each camera to\nproduce time- and view-consistent dynamic scene reconstructions. Extensive\nexperiments on PanopticStudio and Ego-Exo4D demonstrate that our method\nachieves higher quality reconstructions than prior art, particularly when\nrendering novel views. Code, data, and data-processing scripts are available on\nhttps://github.com/ImNotPrepared/MonoFusion.", "comment": "ICCV 2025. Project Page:\n  https://imnotprepared.github.io/research/25_DSR/", "pdf_url": "http://arxiv.org/pdf/2507.23782v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MonoFusion：通过单目融合进行稀疏视图 4D 重建", "tldr": "MonoFusion通过对齐独立的单目重建，解决了从稀疏视图视频进行动态场景重建的挑战，尤其擅长生成高质量的新颖视图。", "motivation": "现有的动态场景重建方法通常需要昂贵且难以部署的密集多视图采集设备（如Panoptic Studio），并且难以适应稀疏视图设置，因为视图之间重叠有限。本研究旨在从少量稀疏视图摄像机重建动态人类行为。", "method": "本研究通过仔细对齐每个摄像机的独立单目重建，以生成时间上和视图上一致的动态场景重建。", "result": "在PanopticStudio和Ego-Exo4D上的大量实验表明，该方法比现有技术实现了更高质量的重建，特别是在渲染新颖视图时表现更优。", "conclusion": "MonoFusion成功地通过单目融合解决了稀疏视图下的动态场景4D重建问题，并取得了优于现有技术的重建质量，尤其是在新颖视图渲染方面。", "translation": "我们解决了从稀疏视图视频进行动态场景重建的问题。以往的工作通常需要数百个经过校准摄像机的密集多视图捕捉（例如Panoptic Studio）。这种多视图设置构建成本过高，并且无法在野外捕捉多样化的场景。相比之下，我们的目标是从少量具有完整场景覆盖的稀疏视图摄像机（例如四个等距向内静态摄像机）重建动态人类行为，例如修理自行车或跳舞。我们发现，由于视图之间重叠有限，密集多视图重建方法难以适应这种稀疏视图设置。为了解决这些局限性，我们仔细对齐每个摄像机的独立单目重建，以生成时间上和视图上一致的动态场景重建。在PanopticStudio和Ego-Exo4D上的大量实验表明，我们的方法比现有技术实现了更高质量的重建，特别是在渲染新颖视图时。代码、数据和数据处理脚本可在https://github.com/ImNotPrepared/MonoFusion 上获取。", "summary": "本文提出MonoFusion，一种从稀疏视图视频重建动态场景的方法。针对现有密集多视图方法在稀疏视图下表现不佳的问题，MonoFusion通过对齐独立的单目重建，实现了时间上和视图上一致的动态场景重建。在PanopticStudio和Ego-Exo4D上的实验证明，该方法在重建质量上超越了现有技术，尤其在渲染新颖视图方面表现出色。", "keywords": "稀疏视图, 4D重建, 单目融合, 动态场景, 新颖视图渲染", "comments": "MonoFusion的创新之处在于其解决了从稀疏视图进行4D动态场景重建的挑战，这对于在野外或资源受限环境下进行捕捉具有重要意义。通过利用单目重建并进行精细对齐，它克服了传统多视图方法对密集视点依赖的局限性。其在生成高质量新颖视图方面的表现尤为突出，这对于虚拟现实、增强现实和内容创作等领域具有潜在应用价值。"}}
{"id": "2507.22886", "title": "Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation", "authors": ["Kaining Ying", "Henghui Ding", "Guangquan Jie", "Yu-Gang Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025, Project Page: this https URL", "url": "http://arxiv.org/abs/2507.22886v2", "summary": "Referring audio-visual segmentation (RAVS) has recently seen significant\nadvancements, yet challenges remain in integrating multimodal information and\ndeeply understanding and reasoning about audiovisual content. To extend the\nboundaries of RAVS and facilitate future research in this field, we propose\nOmnimodal Referring Audio-Visual Segmentation (OmniAVS), a new dataset\ncontaining 2,104 videos and 61,095 multimodal referring expressions. OmniAVS\nstands out with three key innovations: (1) 8 types of multimodal expressions\nthat flexibly combine text, speech, sound, and visual cues; (2) an emphasis on\nunderstanding audio content beyond just detecting their presence; and (3) the\ninclusion of complex reasoning and world knowledge in expressions. Furthermore,\nwe introduce Omnimodal Instructed Segmentation Assistant (OISA), to address the\nchallenges of multimodal reasoning and fine-grained understanding of\naudiovisual content in OmniAVS. OISA uses MLLM to comprehend complex cues and\nperform reasoning-based segmentation. Extensive experiments show that OISA\noutperforms existing methods on OmniAVS and achieves competitive results on\nother related tasks.", "comment": "ICCV 2025, Project Page: https://henghuiding.com/OmniAVS/", "pdf_url": "http://arxiv.org/pdf/2507.22886v2", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "迈向指代性音视频分割中的全模态表达与推理", "tldr": "本文提出了OmniAVS数据集和OISA模型，以解决指代性音视频分割中多模态信息整合和深度理解推理的挑战。", "motivation": "尽管指代性音视频分割（RAVS）取得了显著进展，但在整合多模态信息以及深度理解和推理音视频内容方面仍存在挑战。", "method": "本文提出了Omnimodal Referring Audio-Visual Segmentation (OmniAVS) 数据集，包含2,104个视频和61,095个多模态指代表达式。OmniAVS的创新点在于：1) 8种灵活结合文本、语音、声音和视觉线索的多模态表达式；2) 强调理解音频内容而不仅仅是检测其存在；3) 包含复杂的推理和世界知识。此外，本文还引入了Omnimodal Instructed Segmentation Assistant (OISA) 模型，该模型利用MLLM来理解复杂线索并执行基于推理的分割。", "result": "OISA在OmniAVS数据集上超越了现有方法，并在其他相关任务上取得了有竞争力的结果。", "conclusion": "通过提出OmniAVS数据集和OISA模型，本文有效地解决了指代性音视频分割中多模态信息整合、深度理解和复杂推理的挑战，并为该领域的未来研究提供了新的方向和工具。", "translation": "指代性音视频分割（RAVS）最近取得了显著进展，但在整合多模态信息以及深度理解和推理音视频内容方面仍存在挑战。为了扩展RAVS的边界并促进该领域的未来研究，我们提出了Omnimodal Referring Audio-Visual Segmentation (OmniAVS)，这是一个包含2,104个视频和61,095个多模态指代表达式的新数据集。OmniAVS以三项关键创新脱颖而出：（1）8种灵活结合文本、语音、声音和视觉线索的多模态表达式；（2）强调理解音频内容而不仅仅是检测其存在；（3）在表达式中包含复杂的推理和世界知识。此外，我们引入了Omnimodal Instructed Segmentation Assistant (OISA)，以解决OmniAVS中多模态推理和音视频内容细粒度理解的挑战。OISA使用多模态大语言模型（MLLM）来理解复杂线索并执行基于推理的分割。大量实验表明，OISA在OmniAVS上优于现有方法，并在其他相关任务上取得了有竞争力的结果。", "summary": "本文针对指代性音视频分割（RAVS）中多模态信息整合和深度理解推理的挑战，提出了Omnimodal Referring Audio-Visual Segmentation (OmniAVS) 数据集和Omnimodal Instructed Segmentation Assistant (OISA) 模型。OmniAVS数据集包含丰富的多模态表达式，并强调音频理解和复杂推理。OISA模型利用多模态大语言模型进行推理驱动的分割。实验结果表明OISA在所提数据集及相关任务上表现优异。", "keywords": "指代性音视频分割, 多模态表达式, 数据集, 推理, MLLM", "comments": "本文的创新点在于提出了一个全新的、强调多模态复杂推理和音频深度理解的OmniAVS数据集，这为RAVS领域的研究提供了更全面的基准。同时，提出的OISA模型利用MLLM进行推理，有效解决了数据集中的挑战，展示了多模态大模型在复杂音视频理解任务中的潜力。"}}
{"id": "2507.23021", "title": "Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction", "authors": ["Giuseppe Cartella", "Vittorio Cuculo", "Alessandro D'Amelio", "Marcella Cornia", "Giuseppe Boccignone", "Rita Cucchiara"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2025", "url": "http://arxiv.org/abs/2507.23021v1", "summary": "Predicting human gaze scanpaths is crucial for understanding visual\nattention, with applications in human-computer interaction, autonomous systems,\nand cognitive robotics. While deep learning models have advanced scanpath\nprediction, most existing approaches generate averaged behaviors, failing to\ncapture the variability of human visual exploration. In this work, we present\nScanDiff, a novel architecture that combines diffusion models with Vision\nTransformers to generate diverse and realistic scanpaths. Our method explicitly\nmodels scanpath variability by leveraging the stochastic nature of diffusion\nmodels, producing a wide range of plausible gaze trajectories. Additionally, we\nintroduce textual conditioning to enable task-driven scanpath generation,\nallowing the model to adapt to different visual search objectives. Experiments\non benchmark datasets show that ScanDiff surpasses state-of-the-art methods in\nboth free-viewing and task-driven scenarios, producing more diverse and\naccurate scanpaths. These results highlight its ability to better capture the\ncomplexity of human visual behavior, pushing forward gaze prediction research.\nSource code and models are publicly available at\nhttps://aimagelab.github.io/ScanDiff.", "comment": "Proceedings of the IEEE/CVF International Conference on Computer\n  Vision (ICCV), 2025", "pdf_url": "http://arxiv.org/pdf/2507.23021v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "使用扩散模型建模人类注视行为以实现统一扫视路径预测", "tldr": "提出ScanDiff，一个结合扩散模型和Vision Transformer的新架构，用于生成多样且逼真的人类注视扫视路径，并能通过文本条件进行任务驱动生成，超越现有SOTA方法。", "motivation": "现有的深度学习模型在扫视路径预测中未能捕捉人类视觉探索的可变性，通常生成平均行为，这对于理解视觉注意力至关重要。", "method": "提出ScanDiff，一个结合扩散模型和Vision Transformer的新架构。它利用扩散模型的随机性来显式建模扫视路径的可变性，生成多样化的注视轨迹。此外，引入文本条件以实现任务驱动的扫视路径生成。", "result": "在基准数据集上的实验表明，ScanDiff在自由观看和任务驱动场景中均超越了现有最先进的方法，生成了更多样化和准确的扫视路径。", "conclusion": "ScanDiff能够更好地捕捉人类视觉行为的复杂性，推动了注视预测研究。", "translation": "预测人类注视扫视路径对于理解视觉注意力至关重要，其应用包括人机交互、自主系统和认知机器人。尽管深度学习模型已经推动了扫视路径预测的发展，但大多数现有方法生成的是平均行为，未能捕捉人类视觉探索的可变性。在这项工作中，我们提出了ScanDiff，一个结合了扩散模型和Vision Transformers的新颖架构，用于生成多样且逼真的人体扫视路径。我们的方法通过利用扩散模型的随机性显式地建模扫视路径的可变性，从而产生各种合理的注视轨迹。此外，我们引入了文本条件，以实现任务驱动的扫视路径生成，使模型能够适应不同的视觉搜索目标。在基准数据集上的实验表明，ScanDiff在自由观看和任务驱动场景中均超越了现有最先进的方法，生成了更多样化和准确的扫视路径。这些结果突出了其更好地捕捉人类视觉行为复杂性的能力，推动了注视预测研究。源代码和模型已在 https://aimagelab.github.io/ScanDiff 公开。", "summary": "本文提出了ScanDiff，一个结合扩散模型和Vision Transformer的新颖架构，旨在解决现有扫视路径预测模型无法捕捉人类视觉探索多样性的问题。ScanDiff利用扩散模型的随机性生成多样且逼真的注视轨迹，并通过文本条件实现任务驱动的扫视路径生成。实验证明，ScanDiff在多种场景下均优于现有SOTA方法，能够更准确地反映人类复杂的视觉行为。", "keywords": "注视行为预测, 扩散模型, Vision Transformer, 扫视路径, 视觉注意力", "comments": "这篇论文的创新点在于首次将扩散模型引入人类注视扫视路径预测领域，有效解决了现有模型无法捕捉人类视觉探索多样性的问题。通过利用扩散模型的随机性，ScanDiff能够生成更逼真、更多样化的扫视路径，这对于人机交互、自主系统和认知机器人等应用具有重要意义。引入文本条件实现任务驱动生成也增加了模型的实用性。"}}
{"id": "2507.22915", "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "authors": ["Esmail Gumaan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.22915v1", "summary": "Hallucination in Large Language Models (LLMs) refers to the generation of\ncontent that is not faithful to the input or the real-world facts. This paper\nprovides a rigorous treatment of hallucination in LLMs, including formal\ndefinitions and theoretical analyses. We distinguish between intrinsic and\nextrinsic hallucinations, and define a \\textit{hallucination risk} for models.\nWe derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes\nand Rademacher complexity). We then survey detection strategies for\nhallucinations, such as token-level uncertainty estimation, confidence\ncalibration, and attention alignment checks. On the mitigation side, we discuss\napproaches including retrieval-augmented generation, hallucination-aware\nfine-tuning, logit calibration, and the incorporation of fact-verification\nmodules. We propose a unified detection and mitigation workflow, illustrated\nwith a diagram, to integrate these strategies. Finally, we outline evaluation\nprotocols for hallucination, recommending datasets, metrics, and experimental\nsetups to quantify and reduce hallucinations. Our work lays a theoretical\nfoundation and practical guidelines for addressing the crucial challenge of\nhallucination in LLMs.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.22915v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20", "AI": {"title_translation": "大型语言模型幻觉的理论基础与缓解", "tldr": "本文为大型语言模型中的幻觉提供了严格的理论基础、检测策略、缓解方法和评估协议。", "motivation": "解决大型语言模型中幻觉这一关键挑战。", "method": "提供幻觉的正式定义和理论分析；区分内在幻觉和外在幻觉，并定义幻觉风险；使用学习理论框架（PAC-Bayes和Rademacher复杂度）推导风险界限；调查检测策略（如token级不确定性估计、置信度校准、注意力对齐检查）；讨论缓解方法（包括检索增强生成、幻觉感知微调、logit校准、事实验证模块）；提出统一的检测和缓解工作流程；概述幻觉评估协议（推荐数据集、指标、实验设置）。", "result": "建立了处理大型语言模型中幻觉问题的理论基础和实践指南。", "conclusion": "本工作为解决大型语言模型中幻觉这一关键挑战奠定了理论基础并提供了实践指导。", "translation": "大型语言模型（LLMs）中的幻觉是指生成的内容不忠实于输入或现实世界事实的现象。本文对LLMs中的幻觉进行了严格的探讨，包括形式化定义和理论分析。我们区分了内在幻觉和外在幻觉，并为模型定义了“幻觉风险”。我们使用学习理论框架（PAC-Bayes和Rademacher复杂度）推导了这种风险的界限。然后，我们调查了幻觉的检测策略，例如token级不确定性估计、置信度校准和注意力对齐检查。在缓解方面，我们讨论了包括检索增强生成、幻觉感知微调、logit校准以及事实验证模块的整合等方法。我们提出了一个统一的检测和缓解工作流程，并通过图表进行说明，以整合这些策略。最后，我们概述了幻觉的评估协议，推荐了数据集、指标和实验设置，以量化和减少幻觉。我们的工作为解决LLMs中幻觉这一关键挑战奠定了理论基础并提供了实践指导。", "summary": "本文对大型语言模型中的幻觉现象进行了深入研究，提供了其正式定义、理论分析，并区分了内在与外在幻觉，提出了幻觉风险的概念及其界限推导。文章还系统地梳理了幻觉的检测策略和缓解方法，并提出了一个统一的检测与缓解工作流程。最后，文章给出了幻觉的评估协议，为量化和减少幻觉提供了指导，旨在为解决LLMs中的幻觉问题奠定理论基础和提供实践指南。", "keywords": "大型语言模型, 幻觉, 理论基础, 缓解, 检测", "comments": "这篇论文通过提供幻觉的严格定义、理论分析（区分内在/外在幻觉、定义风险并推导界限），以及系统地总结检测和缓解策略，为大型语言模型中的幻觉问题提供了全面的理论框架和实践指导。其创新点在于提出了统一的检测和缓解工作流程，并强调了评估协议的重要性，对当前LLM领域面临的核心挑战具有重要意义。"}}
{"id": "2507.23076", "title": "Terahertz for Radar applications and Wireless Communication", "authors": ["Sofiane Latreche", "Hocine Bellahsene", "Abdelmalik Taleb-Ahmed"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23076v1", "summary": "Technological advancements in the design of electronic and optical materials\nhave opened up the possibility of utilizing the latest available Radio\nFrequency spectrum the Terahertz (THz) band. This band holds great promise for\nnext-generation wireless systems, which are poised to seamlessly integrate a\nwide array of data-intensive and time-sensitive applications. In this article,\nwe delve into the Terahertz band, providing insights into its properties and\nshowcasing examples of its applications. We begin by exploring the specific\ncharacteristics of wireless communications and radar systems operating in the\nTHz band. Subsequently, we analyze various effects and parameters unique to\neach of these applications.so we scrutinize the application of Terahertz (THz)\nwireless and radar systems, delving into the modeling of various facets of\nradio frequency propagation within this domain. The interpretation of our\nfindings will be presented at the conclusion of this study.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23076v1", "cate": "eess.SY", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "太赫兹在雷达应用和无线通信中的作用", "tldr": "本文探讨了太赫兹（THz）频段在下一代无线系统中的潜力，分析了其特性以及在无线通信和雷达系统中的应用。", "motivation": "利用太赫兹（THz）频段作为最新可用的射频频谱，以支持下一代无线系统中数据密集型和时间敏感型应用的无缝集成。", "method": "本文探讨了太赫兹频段的特性及其应用示例。研究了太赫兹频段中无线通信和雷达系统的具体特性，并分析了每种应用特有的各种效应和参数。深入研究了太赫兹无线和雷达系统的应用，并对该领域内射频传播的各个方面进行了建模。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "电子和光学材料设计方面的技术进步，为利用最新可用的射频频谱——太赫兹（THz）频段——开辟了可能性。该频段对下一代无线系统寄予厚望，这些系统有望无缝集成各种数据密集型和时间敏感型应用。在本文中，我们深入探讨了太赫兹频段，提供了对其特性的见解，并展示了其应用示例。我们首先探讨了在太赫兹频段中运行的无线通信和雷达系统的具体特性。随后，我们分析了每种应用特有的各种效应和参数。因此，我们仔细研究了太赫兹（THz）无线和雷达系统的应用，深入探讨了该领域内射频传播各个方面的建模。我们研究结果的解释将在本研究的结论部分呈现。", "summary": "本文探讨了太赫兹（THz）频段作为下一代无线系统潜在频谱的优势。文章深入分析了太赫兹频段的特性，并展示了其在无线通信和雷达系统中的应用。研究内容包括太赫兹频段内无线通信和雷达系统的具体特征，以及对各种独特效应和参数的分析，并对射频传播的各个方面进行了建模。", "keywords": "太赫兹, 无线通信, 雷达系统, 频谱, 射频传播", "comments": "这篇论文探讨了太赫兹频段的潜力，这在未来高速、大容量通信和雷达应用中具有重要意义。其创新之处在于对太赫兹特性及其在两种关键应用中的具体行为进行了分析和建模。然而，摘要中并未提供具体的研究结果和结论，读者无法得知研究的具体发现和贡献。"}}
{"id": "2507.23704", "title": "Enhanced Velocity Field Modeling for Gaussian Video Reconstruction", "authors": ["Zhenyang Li", "Xiaoyang Bai", "Tongchen Zhang", "Pengfei Shen", "Weiwei Xu", "Yifan Peng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 8 figures", "url": "http://arxiv.org/abs/2507.23704v1", "summary": "High-fidelity 3D video reconstruction is essential for enabling real-time\nrendering of dynamic scenes with realistic motion in virtual and augmented\nreality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has\nachieved near-photorealistic results in video reconstruction due to the great\nrepresentation capability of deep deformation networks. However, in videos with\ncomplex motion and significant scale variations, deformation networks often\noverfit to irregular Gaussian trajectories, leading to suboptimal visual\nquality. Moreover, the gradient-based densification strategy designed for\nstatic scene reconstruction proves inadequate to address the absence of dynamic\ncontent. In light of these challenges, we propose a flow-empowered velocity\nfield modeling scheme tailored for Gaussian video reconstruction, dubbed\nFlowGaussian-VR. It consists of two core components: a velocity field rendering\n(VFR) pipeline which enables optical flow-based optimization, and a\nflow-assisted adaptive densification (FAD) strategy that adjusts the number and\nsize of Gaussians in dynamic regions. We validate our model's effectiveness on\nmulti-view dynamic reconstruction and novel view synthesis with multiple\nreal-world datasets containing challenging motion scenarios, demonstrating not\nonly notable visual improvements (over 2.5 dB gain in PSNR) and less blurry\nartifacts in dynamic textures, but also regularized and trackable per-Gaussian\ntrajectories.", "comment": "17 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.23704v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "增强高斯视频重建的速度场建模", "tldr": "提出FlowGaussian-VR，通过速度场建模和流辅助自适应稠密化，显著提升复杂动态场景下高斯视频重建的视觉质量和轨迹规律性。", "motivation": "现有3D高斯泼溅的形变场范式在复杂运动和显著尺度变化的视频中，形变网络易过拟合不规则高斯轨迹，导致视觉质量不佳；且为静态场景设计的基于梯度的稠密化策略不足以解决动态内容的缺失。", "method": "提出FlowGaussian-VR，包含两个核心组件：1. 速度场渲染（VFR）管线，实现基于光流的优化；2. 流辅助自适应稠密化（FAD）策略，调整动态区域高斯数量和大小。", "result": "在多视图动态重建和新视图合成任务中，模型在真实世界数据集上表现出显著的视觉改进（PSNR提升超过2.5 dB），减少了动态纹理的模糊伪影，并使高斯轨迹更规律和可追踪。", "conclusion": "FlowGaussian-VR通过其速度场建模和流辅助策略，有效解决了复杂动态场景下高斯视频重建的挑战，显著提升了重建质量和轨迹规律性。", "translation": "高保真3D视频重建对于在虚拟现实（VR/AR）中实现具有逼真运动的动态场景的实时渲染至关重要。3D高斯泼溅的形变场范式由于深度形变网络的强大表示能力，在视频重建中取得了近乎真实感的结果。然而，在具有复杂运动和显著尺度变化的视频中，形变网络经常过拟合不规则高斯轨迹，导致视觉质量不佳。此外，为静态场景重建设计的基于梯度的稠密化策略不足以解决动态内容的缺失。鉴于这些挑战，我们提出了一种专为高斯视频重建量身定制的、由光流驱动的速度场建模方案，名为FlowGaussian-VR。它由两个核心组件组成：一个速度场渲染（VFR）管线，实现了基于光流的优化；以及一个流辅助自适应稠密化（FAD）策略，用于调整动态区域高斯的数量和大小。我们在包含挑战性运动场景的多个真实世界数据集上验证了我们模型在多视图动态重建和新视图合成方面的有效性，不仅展示了显著的视觉改进（PSNR增益超过2.5 dB）和动态纹理中更少的模糊伪影，而且高斯轨迹也更规律和可追踪。", "summary": "本文针对3D高斯泼溅在复杂动态视频重建中存在的过拟合不规则高斯轨迹和稠密化策略不足的问题，提出FlowGaussian-VR。该方案引入速度场建模，包含速度场渲染（VFR）管线进行光流优化，以及流辅助自适应稠密化（FAD）策略调整动态区域高斯。实验证明，FlowGaussian-VR显著提升了视觉质量（PSNR > 2.5 dB），减少模糊，并使高斯轨迹更规律。", "keywords": "高斯视频重建, 速度场建模, 光流, 动态场景, 3D高斯泼溅", "comments": "该论文针对高斯泼溅在动态场景重建中的核心痛点——高斯轨迹不规律和稠密化不足——提出了创新的速度场建模方法。引入光流进行优化和自适应稠密化是其主要创新点，解决了现有形变网络过拟合的问题，并显著提升了动态纹理的清晰度和整体视觉质量。其贡献在于通过引入物理直觉（速度场和光流）来正则化深度学习模型的行为，使其在复杂动态场景下表现更稳定、更真实。"}}
{"id": "2507.23776", "title": "Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities", "authors": ["Yunxiang Yan", "Tomohiro Sawada", "Kartik Goyal"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.23776v1", "summary": "While question-answering~(QA) benchmark performance is an automatic and\nscalable method to compare LLMs, it is an indirect method of evaluating their\nunderlying problem-solving capabilities. Therefore, we propose a holistic and\ngeneralizable framework based on \\emph{cascaded question disclosure} that\nprovides a more accurate estimate of the models' problem-solving capabilities\nwhile maintaining the scalability and automation. This approach collects model\nresponses in a stagewise manner with each stage revealing partial information\nabout the question designed to elicit generalized reasoning in LLMs. We find\nthat our approach not only provides a better comparison between LLMs, but also\ninduces better intermediate traces in models compared to the standard QA\nparadigm. We empirically verify this behavior on diverse reasoning and\nknowledge-heavy QA datasets by comparing LLMs of varying sizes and families.\nOur approach narrows the performance gap observed in the standard QA evaluation\nsettings, indicating that the prevalent indirect QA paradigm of evaluation\noverestimates the differences in performance between models. We further\nvalidate our findings by extensive ablation studies.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.23776v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于广义问题解决能力评估的级联信息披露", "tldr": "本文提出了一种基于级联问题披露的框架，用于更准确地评估大型语言模型（LLMs）的问题解决能力，同时保持自动化和可扩展性，并发现它能提供更好的模型比较和中间追踪。", "motivation": "现有的问答（QA）基准测试虽然可扩展且自动化，但只是间接评估LLMs的问题解决能力，因此需要一种更直接、更准确的评估方法。", "method": "本文提出了一种基于“级联问题披露”的框架，以阶段性方式收集模型响应，每个阶段逐步揭示问题的部分信息，旨在激发LLMs的广义推理能力。", "result": "研究发现，该方法不仅能更好地比较LLMs，而且与标准QA范式相比，能诱导模型产生更好的中间追踪。该方法缩小了标准QA评估设置中观察到的性能差距，表明流行的间接QA评估范式高估了模型间的性能差异。", "conclusion": "本文提出的级联信息披露方法能更准确地评估大型语言模型的问题解决能力，并揭示了传统QA评估可能高估模型性能差异的问题。", "translation": "虽然问答（QA）基准测试性能是比较大型语言模型（LLMs）的自动化和可扩展方法，但它是一种间接评估其潜在问题解决能力的方法。因此，我们提出了一种基于“级联问题披露”的整体化、通用化框架，该框架在保持可扩展性和自动化的同时，能更准确地评估模型的问题解决能力。这种方法以阶段性方式收集模型响应，每个阶段揭示问题的部分信息，旨在激发LLMs的广义推理能力。我们发现，与标准QA范式相比，我们的方法不仅能更好地比较LLMs，还能在模型中诱导更好的中间追踪。我们通过比较不同大小和家族的LLMs，在多样化的推理和知识密集型QA数据集上经验性地验证了这种行为。我们的方法缩小了在标准QA评估设置中观察到的性能差距，表明流行的间接QA评估范式高估了模型间的性能差异。我们通过广泛的消融研究进一步验证了我们的发现。", "summary": "本文针对现有问答（QA）基准测试间接评估大型语言模型（LLMs）问题解决能力的局限性，提出了一种名为“级联问题披露”的通用框架。该框架通过分阶段逐步揭示问题信息来收集模型响应，旨在更直接地评估LLMs的广义推理能力。实验证明，此方法不仅提供了更准确的模型间比较，还能促使模型生成更优的中间推理过程，并显著缩小了传统QA评估中观察到的模型性能差异，暗示了传统评估可能高估了模型间的性能差距。", "keywords": "大型语言模型, 问题解决能力, 级联信息披露, 评估, 问答", "comments": "这项研究通过引入“级联信息披露”范式，创新性地解决了LLMs问题解决能力评估的局接性问题。其重要性在于提供了一种更直接、更准确的评估方法，有助于揭示模型真实能力，并挑战了传统QA基准测试对模型性能差异的判断。这对于更公平、有效地比较和发展LLMs具有重要意义。"}}
{"id": "2412.13811", "title": "A Lightweight Optimization Framework for Estimating 3D Brain Tumor Infiltration", "authors": ["Jonas Weidner", "Michal Balcerak", "Ivan Ezhov", "André Datchev", "Laurin Lux", "Lucas Zimmer", "Daniel Rueckert", "Björn Menze", "Benedikt Wiestler"], "categories": ["physics.med-ph", "cs.CV"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.13811v2", "summary": "Glioblastoma, the most aggressive primary brain tumor, poses a severe\nclinical challenge due to its diffuse microscopic infiltration, which remains\nlargely undetected on standard MRI. As a result, current radiotherapy planning\nemploys a uniform 15 mm margin around the resection cavity, failing to capture\npatient-specific tumor spread. Tumor growth modeling offers a promising\napproach to reveal this hidden infiltration. However, methods based on partial\ndifferential equations or physics-informed neural networks tend to be\ncomputationally intensive or overly constrained, limiting their clinical\nadaptability to individual patients. In this work, we propose a lightweight,\nrapid, and robust optimization framework that estimates the 3D tumor\nconcentration by fitting it to MRI tumor segmentations while enforcing a smooth\nconcentration landscape. This approach achieves superior tumor recurrence\nprediction on 192 brain tumor patients across two public datasets,\noutperforming state-of-the-art baselines while reducing runtime from 30 minutes\nto less than one minute. Furthermore, we demonstrate the framework's\nversatility and adaptability by showing its ability to seamlessly integrate\nadditional imaging modalities or physical constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.13811v2", "cate": "physics.med-ph", "date": "2024-12-18", "updated": "2025-07-31", "AI": {"title_translation": "一种用于估计3D脑肿瘤浸润的轻量级优化框架", "tldr": "提出了一种轻量级、快速、鲁棒的优化框架，通过拟合MRI肿瘤分割来估计3D肿瘤浓度，显著提高了肿瘤复发预测性能并大幅缩短了运行时间。", "motivation": "胶质母细胞瘤的弥漫性微观浸润在标准MRI上难以检测，导致当前放疗计划采用统一的15毫米边缘，未能捕捉患者特异性肿瘤扩散。现有的肿瘤生长模型计算量大或约束过多，限制了临床应用。", "method": "我们提出了一种轻量级、快速、鲁棒的优化框架，通过将3D肿瘤浓度拟合到MRI肿瘤分割来估计肿瘤浓度，并强制实施平滑的浓度景观。", "result": "该方法在两个公共数据集的192名脑肿瘤患者上实现了卓越的肿瘤复发预测，优于现有最新基线，并将运行时间从30分钟缩短到不到1分钟。此外，该框架能够无缝集成额外的成像模态或物理约束，展示了其多功能性和适应性。", "conclusion": "本研究提出的轻量级优化框架能够准确、高效地估计3D脑肿瘤浸润，显著改善了肿瘤复发预测，并具有良好的临床应用潜力。", "translation": "胶质母细胞瘤是最具侵袭性的原发性脑肿瘤，由于其弥漫性微观浸润在标准MRI上大多无法检测，因此带来了严重的临床挑战。结果，目前的放射治疗计划在切除腔周围采用统一的15毫米边缘，未能捕捉患者特异性肿瘤扩散。肿瘤生长建模提供了一种有前景的方法来揭示这种隐藏的浸润。然而，基于偏微分方程或物理信息神经网络的方法往往计算量大或约束过多，限制了它们对个体患者的临床适应性。在这项工作中，我们提出了一种轻量级、快速、鲁棒的优化框架，通过将其拟合到MRI肿瘤分割来估计3D肿瘤浓度，同时强制执行平滑的浓度景观。这种方法在两个公共数据集的192名脑肿瘤患者上实现了卓越的肿瘤复发预测，优于现有最新基线，同时将运行时间从30分钟缩短到不到1分钟。此外，我们通过展示其无缝集成额外成像模态或物理约束的能力，证明了该框架的多功能性和适应性。", "summary": "本研究提出了一种轻量级、快速且鲁棒的优化框架，用于估计胶质母细胞瘤的3D肿瘤浸润。针对传统MRI无法检测弥漫性浸润及现有肿瘤生长模型计算量大的问题，该框架通过将3D肿瘤浓度拟合到MRI肿瘤分割并强制平滑浓度景观来工作。实验结果表明，该方法在肿瘤复发预测方面优于现有技术，显著缩短了运行时间，并展现了良好的多模态集成能力，具有重要的临床应用潜力。", "keywords": "脑肿瘤浸润, 优化框架, 胶质母细胞瘤, 肿瘤复发预测, 轻量级", "comments": "这项工作具有重要的临床意义，因为它解决了胶质母细胞瘤治疗中一个关键的未满足需求：准确估计肿瘤的弥漫性浸润。该框架的“轻量级”和“快速”特性是其主要创新点，解决了现有模型计算成本高昂的限制，使其更适用于临床实践。性能上的显著提升，尤其是在复发预测精度和运行时间上的优化，预示着其在个性化放疗规划方面的巨大潜力。此外，其整合多模态数据的能力也增加了其实用性。"}}
{"id": "2507.22891", "title": "Real-time energy monitoring infrastructure for residential collective self-consumption operations using Linky meter", "authors": ["Jérôme Ferrari", "Benoit Delinchant", "Frédéric Wurtz", "Olga Rouchouze"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Cired 2025, Jun 2025, Gen{è}ve (CH), Switzerland", "url": "http://arxiv.org/abs/2507.22891v1", "summary": "As part of the energy transition and the rise in energy prices, the number of\ncollective self-consumption operations in France is steadily increasing.\nHowever, energy flow monitoring currently relies on historical ''day+1'' data\nprovided by Linky meters, which does not offer real time feedback to help\nparticipants adapt their energy consumption behaviors. This article introduces\na new open-source infrastructure for real-time monitoring based on Linky meter\ndata, enabling participants to make informed decisions and take timely actions.\nIt includes a description of the xKy device, applied to a collective\nself-consumption operation involving nine participants, supported by the Energy\nTransition Observatory (OTE). The project encompasses the implementation of\ngateways in participants' homes and the development and operation of real-time\nmonitoring website, aimed at increasing participants' self-consumption rate.", "comment": "Cired 2025, Jun 2025, Gen{\\`e}ve (CH), Switzerland", "pdf_url": "http://arxiv.org/pdf/2507.22891v1", "cate": "cs.HC", "date": "2025-06-17", "updated": "2025-06-17", "AI": {"title_translation": "使用Linky电表实现住宅集体自用电实时能源监测基础设施", "tldr": "开发了一个基于Linky电表的开源实时能源监测系统，帮助住宅集体自用电用户优化能耗行为。", "motivation": "面对能源转型和能源价格上涨，法国的集体自用电操作日益增多。然而，现有的能源流监测依赖Linky电表的“日+1”历史数据，无法提供实时反馈，阻碍了参与者调整能耗行为。", "method": "本文介绍了一种新的基于Linky电表数据的开源实时监测基础设施。该项目包括xKy设备的描述，并在一个涉及九名参与者的集体自用电项目中进行了应用，由能源转型观察站(OTE)支持。具体实施包括在参与者家中部署网关以及开发和运营实时监测网站。", "result": "该基础设施旨在使参与者能够做出明智的决策并及时采取行动，从而提高他们的自用电率。", "conclusion": "通过提供实时能源监测，该基础设施有助于参与者优化其能源消费行为，提高集体自用电的效率和自用电率。", "translation": "随着能源转型和能源价格上涨，法国的集体自用电操作数量正在稳步增长。然而，目前的能源流监测依赖于Linky电表提供的历史“日+1”数据，这无法提供实时反馈来帮助参与者调整其能源消费行为。本文介绍了一种基于Linky电表数据的新的开源实时监测基础设施，使参与者能够做出明智的决策并及时采取行动。它包括对xKy设备的描述，并应用于一个涉及九名参与者的集体自用电操作，该操作由能源转型观察站（OTE）支持。该项目包括在参与者家中实施网关以及开发和运营实时监测网站，旨在提高参与者的自用电率。", "summary": "本文针对法国集体自用电操作中缺乏实时能源监测反馈的问题，提出了一种基于Linky电表的开源实时监测基础设施。该系统通过部署xKy设备和网关，并开发实时监测网站，旨在为参与者提供即时能源数据，帮助他们优化能耗行为，从而提高自用电率。", "keywords": "实时监测, 集体自用电, Linky电表, 能源管理, 开源基础设施", "comments": "这项工作通过提供实时能源监测解决方案，解决了当前集体自用电操作中数据滞后的痛点。其开源性质和实际应用案例（xKy设备在9个参与者家庭中的部署）增加了其实用性和潜在影响力。"}}
{"id": "2309.14792", "title": "Exploiting Local Observations for Robust Robot Learning", "authors": ["Wenshuai Zhao", "Eetu-Aleksi Rantala", "Sahar Salimpour", "Zhiyuan Li", "Joni Pajarinen", "Jorge Peña Queralta"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 8 figures", "url": "http://arxiv.org/abs/2309.14792v4", "summary": "While many robotic tasks can be addressed using either centralized\nsingle-agent control with full state observation or decentralized multi-agent\ncontrol, clear criteria for choosing between these approaches remain\nunderexplored. This paper systematically investigates how multi-agent\nreinforcement learning (MARL) with local observations can improve robustness in\ncomplex robotic systems compared to traditional centralized control. Through\ntheoretical analysis and empirical validation, we show that in certain tasks,\ndecentralized MARL can achieve performance comparable to centralized methods\nwhile exhibiting greater resilience to perturbations and agent failures. By\nanalytically demonstrating the equivalence of single-agent reinforcement\nlearning (SARL) and MARL under full observability, we identify observability as\nthe critical factor distinguishing the two paradigms. We further derive bounds\nquantifying performance degradation under external perturbations for locally\nobservable policies. Empirical results on standard MARL benchmarks confirm that\nMARL with limited observations can maintain competitive performance. Finally,\nreal-world experiments with a mobile manipulator demonstrate that decentralized\nMARL controllers achieve markedly improved robustness to agent malfunctions and\nenvironmental disturbances relative to centralized baselines. Together, these\nfindings highlight MARL with local observations as a robust and practical\nalternative to conventional centralized control in complex robotic systems.", "comment": "8 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2309.14792v4", "cate": "cs.RO", "date": "2023-09-26", "updated": "2025-07-31", "AI": {"title_translation": "利用局部观测实现鲁棒机器人学习", "tldr": "本文系统研究了在复杂机器人系统中，具有局部观测的多智能体强化学习（MARL）如何提高鲁棒性，并证明其是传统集中式控制的鲁棒且实用的替代方案。", "motivation": "尽管许多机器人任务可以通过集中式单智能体控制或分布式多智能体控制来解决，但选择这些方法之间的明确标准仍未得到充分探索。本文旨在系统研究如何利用局部观测的多智能体强化学习（MARL）来提高复杂机器人系统的鲁棒性。", "method": "本文通过理论分析和实证验证，系统研究了在复杂机器人系统中，具有局部观测的多智能体强化学习（MARL）如何提高鲁棒性。研究分析证明了在完全可观测性下，单智能体强化学习（SARL）和MARL的等效性，并将可观测性确定为区分两者的关键因素。此外，还推导了在外部扰动下，局部可观测策略性能下降的量化界限。", "result": "研究结果表明，在某些任务中，去中心化MARL可以达到与集中式方法相当的性能，同时对扰动和智能体故障表现出更大的弹性。在标准MARL基准测试上的经验结果证实，具有有限观测的MARL可以保持竞争力。真实世界的移动机械臂实验表明，去中心化MARL控制器在智能体故障和环境扰动方面比集中式基线表现出显著改善的鲁棒性。", "conclusion": "这些发现共同强调了具有局部观测的MARL在复杂机器人系统中是传统集中式控制的鲁棒且实用的替代方案。", "translation": "虽然许多机器人任务可以通过具有完整状态观测的集中式单智能体控制或分布式多智能体控制来解决，但选择这些方法之间的明确标准仍未得到充分探索。本文系统研究了在复杂机器人系统中，具有局部观测的多智能体强化学习（MARL）如何提高鲁棒性，与传统集中式控制相比。通过理论分析和实证验证，我们表明在某些任务中，去中心化MARL可以达到与集中式方法相当的性能，同时对扰动和智能体故障表现出更大的弹性。通过分析证明在完全可观测性下，单智能体强化学习（SARL）和MARL的等效性，我们确定可观测性是区分这两种范式的关键因素。我们进一步推导了量化局部可观测策略在外部扰动下性能下降的界限。在标准MARL基准测试上的经验结果证实，具有有限观测的MARL可以保持竞争力。最后，对移动机械臂进行的真实世界实验表明，去中心化MARL控制器在智能体故障和环境扰动方面比集中式基线表现出显著改善的鲁棒性。综上所述，这些发现强调了具有局部观测的MARL在复杂机器人系统中是传统集中式控制的鲁棒且实用的替代方案。", "summary": "本文探讨了在复杂机器人任务中，如何选择集中式与分布式控制方法的未解问题。研究通过理论分析和实证验证，系统地展示了具有局部观测的多智能体强化学习（MARL）在提高机器人系统鲁棒性方面的优势。结果表明，去中心化MARL在性能上可与集中式方法媲美，同时对扰动和故障表现出更强的弹性，并最终提出MARL是传统集中式控制的鲁棒且实用的替代方案。", "keywords": "多智能体强化学习, 局部观测, 机器人鲁棒性, 去中心化控制, 系统弹性", "comments": "本文的创新之处在于系统性地对比了集中式与去中心化控制在机器人鲁棒性方面的表现，并通过理论和实证证明了局部观测的MARL在面对扰动和故障时的优越性。其强调了可观测性作为区分两种范式的关键因素，并提供了量化性能下降的理论界限，这对于理解和设计鲁棒机器人系统具有重要意义。在实际应用中，尤其是在多智能体协作和复杂环境下，该研究为更可靠的机器人部署提供了新的视角和方法。"}}
{"id": "2507.22968", "title": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations", "authors": ["Chengqian Ma", "Wei Tao", "Yiwen Guo"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22968v1", "summary": "Spoken Dialogue Models (SDMs) have recently attracted significant attention\nfor their ability to generate voice responses directly to users' spoken\nqueries. Despite their increasing popularity, there exists a gap in research\nfocused on comprehensively understanding their practical effectiveness in\ncomprehending and emulating human conversations. This is especially true\ncompared to text-based Large Language Models (LLMs), which benefit from\nextensive benchmarking. Human voice interactions are inherently more complex\nthan text due to characteristics unique to spoken dialogue. Ambiguity poses one\nchallenge, stemming from semantic factors like polysemy, as well as\nphonological aspects such as heterograph, heteronyms, and stress patterns.\nAdditionally, context-dependency, like omission, coreference, and multi-turn\ninteraction, adds further complexity to human conversational dynamics. To\nilluminate the current state of SDM development and to address these\nchallenges, we present a benchmark dataset in this paper, which comprises 1,079\ninstances in English and Chinese. Accompanied by an LLM-based evaluation method\nthat closely aligns with human judgment, this dataset facilitates a\ncomprehensive exploration of the performance of SDMs in tackling these\npractical challenges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22968v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "C3：一个用于口语对话模型的双语基准，探索复杂对话中的挑战", "tldr": "本文提出了C3，一个双语基准数据集，旨在评估口语对话模型在处理复杂人类对话（如歧义和上下文依赖）方面的能力，并提供了一个基于LLM的评估方法。", "motivation": "尽管口语对话模型（SDMs）日益普及，但目前缺乏对其在理解和模仿人类对话方面实际有效性的全面研究，尤其是在面对语音对话特有的复杂性（如歧义和上下文依赖）时，这与受益于广泛基准测试的文本大语言模型（LLMs）形成对比。", "method": "本文提出了一个名为C3的双语基准数据集，包含1,079个英语和中文实例。该数据集还配备了一个与人类判断高度一致的基于大语言模型（LLM）的评估方法。", "result": "该数据集促进了对口语对话模型（SDMs）在应对复杂实际挑战方面的性能进行全面探索，有助于了解SDM的当前发展状况。", "conclusion": "C3双语基准数据集的提出，旨在弥补口语对话模型在复杂对话评估方面的空白，并为全面评估SDM处理实际挑战的能力提供了工具，从而推动该领域的发展。", "translation": "口语对话模型（SDMs）最近因其直接向用户语音查询生成语音响应的能力而受到广泛关注。尽管它们日益普及，但在全面理解其在理解和模仿人类对话方面的实际有效性方面存在研究空白。与受益于广泛基准测试的基于文本的大语言模型（LLMs）相比，这一点尤为突出。由于口语对话特有的特征，人类语音交互本质上比文本更复杂。歧义是一个挑战，它源于词义多义等语义因素，以及异形同音词、异音同形词和重音模式等语音方面。此外，上下文依赖性，如省略、共指和多轮交互，进一步增加了人类对话动态的复杂性。为了阐明SDM的当前发展状况并解决这些挑战，我们在本文中提出了一个基准数据集，该数据集包含1,079个英语和中文实例。该数据集伴随着一种与人类判断高度一致的基于LLM的评估方法，有助于全面探索SDM在应对这些实际挑战方面的性能。", "summary": "本文提出了C3，一个针对口语对话模型（SDMs）的双语基准数据集，旨在解决现有研究中对SDM在处理复杂人类对话（如歧义和上下文依赖性）方面实际有效性评估的不足。该数据集包含1,079个英语和中文实例，并配套一个与人类判断高度一致的基于大语言模型（LLM）的评估方法。C3的创建旨在促进对SDM性能的全面探索，从而更好地理解其在复杂语音交互中的能力。", "keywords": "口语对话模型, 双语基准, 复杂对话, 评估, C3", "comments": "C3基准的创新之处在于其双语性质和对口语对话特有复杂性的关注，如歧义和上下文依赖。它通过提供一个结构化的评估框架，弥补了SDM研究中与文本LLM基准测试差距。其基于LLM的评估方法也值得关注，因为它旨在提高评估效率并与人类判断保持一致。该基准对于推动SDM在真实世界复杂对话场景中的发展具有重要意义。"}}
{"id": "2507.23209", "title": "Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation", "authors": ["Wei-Wei Du", "Takuma Udagawa", "Kei Tateno"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by RecSys 2025 short paper track", "url": "http://arxiv.org/abs/2507.23209v1", "summary": "Time intervals between purchasing items are a crucial factor in sequential\nrecommendation tasks, whereas existing approaches focus on item sequences and\noften overlook by assuming the intervals between items are static. However,\ndynamic intervals serve as a dimension that describes user profiling on not\nonly the history within a user but also different users with the same item\nhistory. In this work, we propose IntervalLLM, a novel framework that\nintegrates interval information into LLM and incorporates the novel\ninterval-infused attention to jointly consider information of items and\nintervals. Furthermore, unlike prior studies that address the cold-start\nscenario only from the perspectives of users and items, we introduce a new\nviewpoint: the interval perspective to serve as an additional metric for\nevaluating recommendation methods on the warm and cold scenarios. Extensive\nexperiments on 3 benchmarks with both traditional- and LLM-based baselines\ndemonstrate that our IntervalLLM achieves not only 4.4% improvements in average\nbut also the best-performing warm and cold scenarios across all users, items,\nand the proposed interval perspectives. In addition, we observe that the cold\nscenario from the interval perspective experiences the most significant\nperformance drop among all recommendation methods. This finding underscores the\nnecessity of further research on interval-based cold challenges and our\nintegration of interval information in the realm of sequential recommendation\ntasks. Our code is available here:\nhttps://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM.", "comment": "Accepted by RecSys 2025 short paper track", "pdf_url": "http://arxiv.org/pdf/2507.23209v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "不仅仅是内容，更是时间：将不规则间隔整合到LLM中用于序列推荐", "tldr": "IntervalLLM将时间间隔信息整合到LLM中，显著提升了序列推荐的性能，尤其是在冷启动场景下，并引入了间隔视角进行评估。", "motivation": "现有序列推荐方法常忽略商品购买之间的时间间隔，或假设其为静态，但动态间隔是描述用户画像的关键维度。", "method": "提出IntervalLLM框架，将时间间隔信息整合到大型语言模型（LLM）中，并引入新型的“间隔注入注意力”机制。此外，引入“间隔视角”作为评估推荐方法在暖启动和冷启动场景下的额外指标。", "result": "在3个基准测试中，IntervalLLM平均性能提升4.4%，并在所有用户、商品和所提出的间隔视角下的暖启动和冷启动场景中表现最佳。观察到间隔视角的冷启动场景在所有推荐方法中性能下降最显著。", "conclusion": "时间间隔是序列推荐任务中的关键因素，尤其对于解决基于间隔的冷启动挑战至关重要。将间隔信息整合到LLM中是未来研究的必要方向。", "translation": "商品购买之间的时间间隔是序列推荐任务中的关键因素，然而现有方法通常只关注商品序列，并常通过假设商品之间的间隔是静态的而忽略了这一点。然而，动态间隔作为一个维度，不仅描述了用户自身历史，也描述了具有相同商品历史的不同用户。在这项工作中，我们提出了IntervalLLM，一个将间隔信息整合到LLM中，并结合新颖的“间隔注入注意力”来共同考虑商品和间隔信息的框架。此外，与以往仅从用户和商品角度解决冷启动问题不同，我们引入了一个新的视角：间隔视角，作为评估推荐方法在暖启动和冷启动场景下的额外指标。在3个基准测试上，使用传统和基于LLM的基线进行的广泛实验表明，我们的IntervalLLM不仅平均提升了4.4%的性能，而且在所有用户、商品和所提出的间隔视角下，在暖启动和冷启动场景中都表现最佳。此外，我们观察到，从间隔视角来看的冷启动场景在所有推荐方法中经历了最显著的性能下降。这一发现强调了进一步研究基于间隔的冷启动挑战以及在序列推荐任务领域中整合间隔信息的必要性。我们的代码可在此处获取：https://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM。", "summary": "该论文提出了IntervalLLM，一个将动态时间间隔信息整合到大型语言模型（LLM）中用于序列推荐的新框架。它通过“间隔注入注意力”机制同时考虑商品和时间间隔，并引入了“间隔视角”来评估推荐系统在不同冷暖启动场景下的表现。实验结果表明，IntervalLLM在多个基准测试上显著优于现有方法，特别是在冷启动场景下表现出色，并揭示了基于间隔的冷启动问题是未来研究的关键挑战。", "keywords": "序列推荐, LLM, 时间间隔, IntervalLLM, 冷启动", "comments": "该论文的创新点在于将动态时间间隔这一关键但常被忽视的因素整合到LLM中，并通过“间隔注入注意力”机制有效利用。引入“间隔视角”进行评估，为序列推荐的冷启动问题提供了新的分析维度，揭示了该领域的新挑战，具有重要的理论和实践意义。"}}
{"id": "2311.02490", "title": "Improved Convergence Factor of Windowed Anderson Acceleration for Symmetric Fixed-Point Iterations", "authors": ["Casey Garner", "Gilad Lerman", "Teng Zhang"], "categories": ["math.NA", "cs.NA", "math.OC", "stat.ML", "65F10, 65H10, 68W40"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      40 pages, 10 figures", "url": "http://arxiv.org/abs/2311.02490v3", "summary": "This paper studies the commonly utilized windowed Anderson acceleration (AA)\nalgorithm for fixed-point methods, $x^{(k+1)}=q(x^{(k)})$. It provides the\nfirst proof that when the operator $q$ is linear and symmetric the windowed AA,\nwhich uses a sliding window of prior iterates, improves the root-linear\nconvergence factor over the fixed-point iterations. When $q$ is nonlinear, yet\nhas a symmetric Jacobian at a fixed point, a slightly modified AA algorithm is\nproved to have an analogous root-linear convergence factor improvement over\nfixed-point iterations. Simulations verify our observations. Furthermore,\nexperiments with different data models demonstrate AA is significantly superior\nto the standard fixed-point methods for Tyler's M-estimation.", "comment": "40 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2311.02490v3", "cate": "math.NA", "date": "2023-11-04", "updated": "2025-07-31", "AI": {"title_translation": "对称不动点迭代的窗式安德森加速改进收敛因子", "tldr": "本文首次证明了窗式安德森加速（AA）在对称线性算子和具有对称雅可比矩阵的非线性算子情况下，能改进不动点迭代的收敛因子，并通过仿真和实验验证了其优越性。", "motivation": "本文研究了常用的窗式安德森加速（AA）算法，并首次证明了其在特定条件下能改进不动点迭代的收敛因子，旨在提供理论依据并验证其有效性。", "method": "本文首先提供了理论证明，证明了当算子q是线性且对称时，窗式AA改进了不动点迭代的根线性收敛因子。其次，当q是非线性但在不动点处具有对称雅可比矩阵时，证明了一种略微修改的AA算法具有类似的根线性收敛因子改进。最后，通过仿真和使用不同数据模型的实验验证了这些观察结果，特别是在Tyler的M-估计中。", "result": "本文首次证明了当算子q是线性且对称时，窗式AA改进了不动点迭代的根线性收敛因子。当q是非线性但在不动点处具有对称雅可比矩阵时，略微修改的AA算法也表现出类似的根线性收敛因子改进。仿真验证了这些观察结果，并且实验表明AA在Tyler的M-估计中显著优于标准不动点方法。", "conclusion": "本文证明并验证了窗式安德森加速算法在对称不动点迭代中能够显著提高收敛因子，使其在理论和实践中都优于标准不动点方法。", "translation": "本文研究了常用的窗式安德森加速（AA）算法，用于不动点方法 $x^{(k+1)}=q(x^{(k)})$。本文首次证明了当算子 $q$ 是线性且对称时，使用先前迭代滑动窗口的窗式AA改进了不动点迭代的根线性收敛因子。当 $q$ 是非线性，但在不动点处具有对称雅可比矩阵时，一种略微修改的AA算法被证明相对于不动点迭代具有类似的根线性收敛因子改进。仿真验证了我们的观察结果。此外，使用不同数据模型的实验表明，AA在Tyler的M-估计中显著优于标准不动点方法。", "summary": "本文深入研究了窗式安德森加速（AA）算法在不动点迭代中的应用。研究首次从理论上证明了在算子线性且对称，以及非线性但雅可比矩阵对称的两种情况下，窗式AA（或其修改版本）能够显著提高迭代的根线性收敛因子。通过仿真和对Tyler’s M-估计的实验，进一步验证了其相较于传统不动点方法的优越性。", "keywords": "窗式安德森加速, 不动点迭代, 收敛因子, 对称算子, Tyler's M-估计", "comments": "本文的创新点在于首次提供了窗式安德森加速在对称不动点迭代中改进收敛因子的严格理论证明。这填补了该领域的一个理论空白，并为AA算法的广泛应用提供了更坚实的基础。实验结果也进一步强调了其在实际问题中的重要性和有效性。"}}
{"id": "2507.23618", "title": "SOME: Symmetric One-Hot Matching Elector -- A Lightweight Microsecond Decoder for Quantum Error Correction", "authors": ["Xinyi Guo", "Geguang Miao", "Shinichi Nishizawa", "Hiromitsu Awano", "Shinji Kimura", "Takashi Sato"], "categories": ["cs.ET", "quant-ph"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23618v1", "summary": "Conventional quantum error correction (QEC) decoders such as Minimum-Weight\nPerfect Matching (MWPM) and Union-Find (UF) offer high thresholds and fast\ndecoding, respectively, but both suffer from high topological complexity. In\ncontrast, Ising model-based decoders reduce topological complexity but demand\nconsiderable decoding time. We propose the Symmetric One-Hot Matching Elector\n(SOME), a novel decoder that reformulates the QEC decoding task as a Quadratic\nUnconstrained Binary Optimization (QUBO) problem -- termed the One-Hot QUBO\n(OHQ). Each variable in the QUBO represents whether a given pair of flipped\nsyndromes is matched, while the error probabilities between the pair are\nencoded as interaction coefficients (weight). Constraints ensure that each\nflipped syndrome is matched exactly once. Valid solutions of OHQ correspond to\nself-inverse permutation matrices, characterized by symmetric one-hot encoding.\nTo solve the OHQ efficiently, SOME reformulates the decoding task as the\nconstruction of permutation matrices that minimize the total weight. It\ninitializes each candidate matrix from one of the minimum-weight syndrome\npairs, then iteratively appends additional pairs in ascending order of weight,\nand finally selects the permutation matrix with the lowest total energy. SOME\nachieves up to a 99.9x reduction in variable count and reduces decoding times\nfrom milliseconds to microseconds on a single-threaded commodity CPU. OHQ also\nmaintains performance up to a 10.5% physical error rate, surpassing the highest\nknown threshold of MWPM@.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23618v1", "cate": "cs.ET", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SOME：对称独热匹配选择器——一种用于量子纠错的轻量级微秒级解码器", "tldr": "SOME是一种新型的量子纠错解码器，它将解码任务重新表述为独热二次无约束二进制优化（OHQ）问题，实现了显著的变量数减少和解码时间缩短，性能优于现有解码器。", "motivation": "传统的量子纠错（QEC）解码器（如MWPM和UF）虽然阈值高或解码速度快，但拓扑复杂度高。基于伊辛模型的解码器降低了拓扑复杂度，但解码时间长。因此，需要一种既能降低复杂度又能实现快速解码的新型解码器。", "method": "SOME解码器将量子纠错解码任务重新表述为二次无约束二进制优化（QUBO）问题，称之为独热QUBO（OHQ）。OHQ中的每个变量表示一对翻转的综合征是否匹配，误差概率编码为交互系数。约束确保每个翻转的综合征精确匹配一次。SOME通过构建最小化总权重的排列矩阵来解决OHQ，首先从最小权重的综合征对初始化候选矩阵，然后迭代地按权重升序添加额外的对，最后选择总能量最低的排列矩阵。", "result": "SOME实现了变量数量高达99.9倍的减少，并在单线程商用CPU上将解码时间从毫秒缩短到微秒。OHQ在高达10.5%的物理错误率下仍能保持性能，超过了MWPM已知的最高阈值。", "conclusion": "SOME解码器通过将量子纠错任务重新表述为OHQ问题并采用高效的求解策略，成功地提供了一种轻量级、微秒级的解码解决方案，显著提高了性能，超越了现有解码器。", "translation": "传统的量子纠错（QEC）解码器，如最小权重完美匹配（MWPM）和并查集（UF），分别提供高阈值和快速解码，但两者都存在高拓扑复杂度的问题。相比之下，基于伊辛模型的解码器降低了拓扑复杂度，但需要相当长的解码时间。我们提出了一种新型解码器——对称独热匹配选择器（SOME），它将QEC解码任务重新表述为二次无约束二进制优化（QUBO）问题，称之为独热QUBO（OHQ）。QUBO中的每个变量表示给定的一对翻转综合征是否匹配，而这对之间的错误概率被编码为交互系数（权重）。约束条件确保每个翻转的综合征都精确匹配一次。OHQ的有效解对应于自逆置换矩阵，其特征是对称独热编码。为了高效地解决OHQ，SOME将解码任务重新表述为构建最小化总权重的置换矩阵。它从最小权重综合征对中的一个初始化每个候选矩阵，然后以权重升序迭代地添加额外的对，最后选择总能量最低的置换矩阵。SOME在变量数量上实现了高达99.9倍的减少，并将单线程商用CPU上的解码时间从毫秒缩短到微秒。OHQ在高达10.5%的物理错误率下也能保持性能，超过了MWPM已知的最高阈值。", "summary": "该论文提出了一种名为SOME（Symmetric One-Hot Matching Elector）的新型量子纠错解码器。SOME将解码任务转化为独热二次无约束二进制优化（OHQ）问题，通过构建最小化总权重的自逆置换矩阵来求解。与现有解码器相比，SOME显著减少了变量数量（高达99.9倍），并将解码时间从毫秒级缩短到微秒级，并在高达10.5%的物理错误率下保持高性能，超越了MWPM的阈值。", "keywords": "量子纠错, 解码器, QUBO, SOME, 微秒解码", "comments": "SOME解码器的创新之处在于将QEC解码问题创造性地转化为一个独热QUBO问题，并通过构建自逆置换矩阵的迭代方法高效求解。这不仅在理论上为QEC解码提供了新的视角，而且在实践中实现了显著的性能提升，尤其是在解码速度和变量数量上，这对于未来大规模量子计算机的实现具有重要意义。其在保持高物理错误率下性能的能力也令人印象深刻。"}}
{"id": "2507.23291", "title": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "authors": ["Yuetian Chen", "Zhiqi Wang", "Nathalie Baracaldo", "Swanand Ravindra Kadhe", "Lei Yu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23291v1", "summary": "Membership inference attacks (MIAs) pose a critical threat to the privacy of\ntraining data in deep learning. Despite significant progress in attack\nmethodologies, our understanding of when and how models encode membership\ninformation during training remains limited. This paper presents a dynamic\nanalytical framework for dissecting and quantifying privacy leakage dynamics at\nthe individual sample level. By tracking per-sample vulnerabilities on an\nFPR-TPR plane throughout training, our framework systematically measures how\nfactors such as dataset complexity, model architecture, and optimizer choice\ninfluence the rate and severity at which samples become vulnerable. Crucially,\nwe discover a robust correlation between a sample's intrinsic learning\ndifficulty, and find that the privacy risk of samples highly vulnerable in the\nfinal trained model is largely determined early during training. Our results\nthus provide a deeper understanding of how privacy risks dynamically emerge\nduring training, laying the groundwork for proactive, privacy-aware model\ntraining strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23291v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "评估深度学习中成员隐私的动态性", "tldr": "研究了深度学习训练过程中成员隐私泄露的动态性，发现样本的隐私风险在训练早期就已确定，并提出了动态分析框架。", "motivation": "成员推断攻击对深度学习训练数据的隐私构成严重威胁，但目前对模型何时以及如何编码成员信息的理解仍然有限。", "method": "提出了一个动态分析框架，用于在个体样本层面剖析和量化隐私泄露动态。通过在整个训练过程中跟踪FPR-TPR平面上的每个样本的脆弱性，系统地测量数据集复杂性、模型架构和优化器选择等因素如何影响样本变得脆弱的速度和严重性。", "result": "发现样本的内在学习难度与隐私风险之间存在强相关性，并且最终训练模型中高度脆弱样本的隐私风险在训练早期就已确定。", "conclusion": "提供了对隐私风险如何在训练过程中动态出现的更深入理解，为主动的、隐私感知的模型训练策略奠定了基础。", "translation": "成员推断攻击（MIAs）对深度学习中训练数据的隐私构成严重威胁。尽管攻击方法学取得了显著进展，但我们对模型在训练期间何时以及如何编码成员信息的理解仍然有限。本文提出了一个动态分析框架，用于在个体样本层面剖析和量化隐私泄露动态。通过在整个训练过程中跟踪FPR-TPR平面上的每个样本的脆弱性，我们的框架系统地测量了数据集复杂性、模型架构和优化器选择等因素如何影响样本变得脆弱的速度和严重性。至关重要的是，我们发现样本的内在学习难度之间存在着强大的相关性，并且最终训练模型中高度脆弱样本的隐私风险在训练早期就已确定。因此，我们的结果提供了对隐私风险如何在训练期间动态出现的更深入理解，为主动的、隐私感知的模型训练策略奠定了基础。", "summary": "本文提出一个动态分析框架，用于评估深度学习训练过程中数据成员隐私泄露的动态性。该框架通过跟踪单个样本的脆弱性，量化了数据集复杂度、模型架构和优化器选择等因素对隐私风险的影响。研究发现，样本的内在学习难度与隐私风险密切相关，且样本的隐私风险在训练早期便基本确定。这项工作加深了对隐私风险动态演变的理解，为开发更具隐私意识的训练策略提供了基础。", "keywords": "成员推断攻击, 隐私泄露, 深度学习, 动态分析, 训练动态", "comments": "这项研究通过引入一个动态分析框架，创新性地解决了深度学习中成员隐私泄露的动态演变问题。其重要性在于揭示了隐私风险在训练早期便已形成的关键发现，这为开发前瞻性的、隐私保护的训练策略提供了宝贵的见解，有助于未来设计更安全的深度学习模型。"}}
{"id": "2507.02708", "title": "Optimizing Start Locations in Ergodic Search for Disaster Response", "authors": ["Ananya Rao", "Alyssa Hargis", "David Wettergreen", "Howie Choset"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02708v3", "summary": "In disaster response scenarios, deploying robotic teams effectively is\ncrucial for improving situational awareness and enhancing search and rescue\noperations. The use of robots in search and rescue has been studied but the\nquestion of where to start robot deployments has not been addressed. This work\naddresses the problem of optimally selecting starting locations for robots with\nheterogeneous capabilities by formulating a joint optimization problem. To\ndetermine start locations, this work adds a constraint to the ergodic\noptimization framework whose minimum assigns robots to start locations. This\nbecomes a little more challenging when the robots are heterogeneous (equipped\nwith different sensing and motion modalities) because not all robots start at\nthe same location, and a more complex adaptation of the aforementioned\nconstraint is applied. Our method assumes access to potential starting\nlocations, which can be obtained from expert knowledge or aerial imagery. We\nexperimentally evaluate the efficacy of our joint optimization approach by\ncomparing it to baseline methods that use fixed starting locations for all\nrobots. Our experimental results show significant gains in coverage\nperformance, with average improvements of 35.98% on synthetic data and 31.91%\non real-world data for homogeneous and heterogeneous teams, in terms of the\nergodic metric.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02708v3", "cate": "cs.RO", "date": "2025-07-03", "updated": "2025-07-30", "AI": {"title_translation": "优化灾害响应中遍历搜索的起始位置", "tldr": "该论文提出了一种优化灾害响应中机器人起始位置的方法，通过在遍历优化框架中加入约束，显著提高了覆盖性能。", "motivation": "在灾害响应场景中，有效部署机器人团队对于提高态势感知和加强搜救行动至关重要。然而，机器人部署的起始位置问题，特别是对于异构机器人团队，尚未得到充分解决。", "method": "本文通过制定一个联合优化问题来解决优化选择具有异构能力的机器人起始位置的问题。该方法在遍历优化框架中增加了一个约束，其最小值用于将机器人分配到起始位置。对于异构机器人，应用了更复杂的约束适应。该方法假设可以从专家知识或航空图像中获取潜在的起始位置。", "result": "实验结果表明，与使用固定起始位置的基线方法相比，该联合优化方法在覆盖性能方面取得了显著提升。在遍历度量方面，同质和异质团队在合成数据上平均提高了35.98%，在真实世界数据上平均提高了31.91%。", "conclusion": "优化机器人团队（包括异构团队）的起始位置，可以显著提高灾害响应中遍历搜索的覆盖性能。", "translation": "在灾害响应场景中，有效部署机器人团队对于提高态态势感知和加强搜救行动至关重要。机器人用于搜救已有所研究，但机器人部署的起始位置问题尚未得到解决。这项工作通过制定一个联合优化问题，解决了优化选择具有异构能力的机器人起始位置的问题。为了确定起始位置，这项工作在遍历优化框架中增加了一个约束，其最小值将机器人分配到起始位置。当机器人是异构的（配备不同的传感和运动模式）时，这变得更具挑战性，因为并非所有机器人都在同一位置开始，并且应用了上述约束的更复杂适应。我们的方法假设可以获取潜在的起始位置，这些位置可以从专家知识或航空图像中获得。我们通过将我们的联合优化方法与所有机器人使用固定起始位置的基线方法进行比较，实验评估了其功效。我们的实验结果表明，在遍历度量方面，对于同质和异质团队，覆盖性能有显著提高，合成数据平均提高了35.98%，真实世界数据平均提高了31.91%。", "summary": "本文针对灾害响应中机器人团队（包括异构团队）优化起始位置的关键问题，提出了一种联合优化方法。该方法通过在遍历优化框架中引入特定约束来实现起始位置的优化选择。实验结果表明，与基线固定起始位置方法相比，该方法能显著提升覆盖性能，在合成数据和真实世界数据上分别平均提高了35.98%和31.91%。", "keywords": "遍历搜索, 灾害响应, 机器人部署, 起始位置, 优化", "comments": "这篇论文为机器人灾害响应中的实际问题——初始部署策略——提出了一种创新方法。通过将起始位置优化整合到遍历搜索框架中，它解决了先前被忽视的一个方面。对异构机器人能力的考虑增加了其实用性。所展示的显著性能提升验证了所提出的联合优化方法的有效性。"}}
{"id": "2507.23473", "title": "CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes", "authors": ["Bin Xie", "Congxuan Zhang", "Fagan Wang", "Peng Liu", "Feng Lu", "Zhen Chen", "Weiming Hu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCVW2025", "url": "http://arxiv.org/abs/2507.23473v1", "summary": "The widespread application of Unmanned Aerial Vehicles (UAVs) has raised\nserious public safety and privacy concerns, making UAV perception crucial for\nanti-UAV tasks. However, existing UAV tracking datasets predominantly feature\nconspicuous objects and lack diversity in scene complexity and attribute\nrepresentation, limiting their applicability to real-world scenarios. To\novercome these limitations, we present the CST Anti-UAV, a new thermal infrared\ndataset specifically designed for Single Object Tracking (SOT) in Complex\nScenes with Tiny UAVs (CST). It contains 220 video sequences with over 240k\nhigh-quality bounding box annotations, highlighting two key properties: a\nsignificant number of tiny-sized UAV targets and the diverse and complex\nscenes. To the best of our knowledge, CST Anti-UAV is the first dataset to\nincorporate complete manual frame-level attribute annotations, enabling precise\nevaluations under varied challenges. To conduct an in-depth performance\nanalysis for CST Anti-UAV, we evaluate 20 existing SOT methods on the proposed\ndataset. Experimental results demonstrate that tracking tiny UAVs in complex\nenvironments remains a challenge, as the state-of-the-art method achieves only\n35.92% state accuracy, much lower than the 67.69% observed on the Anti-UAV410\ndataset. These findings underscore the limitations of existing benchmarks and\nthe need for further advancements in UAV tracking research. The CST Anti-UAV\nbenchmark is about to be publicly released, which not only fosters the\ndevelopment of more robust SOT methods but also drives innovation in anti-UAV\nsystems.", "comment": "Accepted by ICCVW2025", "pdf_url": "http://arxiv.org/pdf/2507.23473v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "CST Anti-UAV：复杂场景下微型无人机跟踪的热红外基准", "tldr": "提出了CST Anti-UAV，一个用于复杂场景下微型无人机跟踪的热红外数据集，并发现现有方法在此挑战性任务上表现不佳。", "motivation": "现有的无人机跟踪数据集主要关注显眼目标，缺乏场景复杂性和属性多样性，限制了它们在真实世界反无人机任务中的应用。", "method": "提出了CST Anti-UAV数据集，这是一个专为复杂场景中微型无人机单目标跟踪设计的新型热红外数据集，包含220个视频序列和超过24万个高质量边界框标注，并首次包含完整的手动帧级属性标注。作者在该数据集上评估了20种现有单目标跟踪（SOT）方法。", "result": "在CST Anti-UAV数据集上，跟踪复杂环境中微型无人机仍然是一个挑战，最先进方法的准确率仅为35.92%，远低于在Anti-UAV410数据集上观察到的67.69%。", "conclusion": "现有基准的局限性凸显了无人机跟踪研究需要进一步的进展。CST Anti-UAV基准的发布将促进更鲁棒的SOT方法和反无人机系统的发展。", "translation": "无人机（UAV）的广泛应用引发了严重公共安全和隐私问题，使得无人机感知对于反无人机任务至关重要。然而，现有的无人机跟踪数据集主要特征是目标显眼，并且缺乏场景复杂性和属性表示的多样性，限制了它们在真实世界场景中的适用性。为了克服这些局限性，我们提出了CST Anti-UAV，一个专门为复杂场景下微型无人机（CST）单目标跟踪（SOT）设计的新型热红外数据集。它包含220个视频序列，拥有超过24万个高质量边界框标注，突出显示了两个关键特性：大量的微型无人机目标以及多样化和复杂的场景。据我们所知，CST Anti-UAV是第一个包含完整手动帧级属性标注的数据集，支持在各种挑战下进行精确评估。为了对CST Anti-UAV进行深入的性能分析，我们评估了20种现有SOT方法。实验结果表明，在复杂环境中跟踪微型无人机仍然是一个挑战，因为最先进的方法仅达到35.92%的状态准确率，远低于在Anti-UAV410数据集上观察到的67.69%。这些发现强调了现有基准的局限性以及无人机跟踪研究中需要进一步的进展。CST Anti-UAV基准即将公开发布，这不仅促进了更鲁棒的SOT方法的开发，也推动了反无人机系统的创新。", "summary": "本文提出了CST Anti-UAV，一个针对复杂场景中微型无人机跟踪的全新热红外数据集，旨在解决现有数据集在多样性和真实世界适用性方面的不足。该数据集包含大量微型目标和复杂场景标注，并首次提供手动帧级属性标注。作者在该数据集上评估了20种现有SOT方法，结果显示当前方法在跟踪微型无人机方面表现不佳，凸显了该领域仍需重大进展。该基准的发布有望推动更鲁棒的反无人机技术发展。", "keywords": "无人机跟踪, 热红外, 数据集, 单目标跟踪, 反无人机", "comments": "这篇论文的创新点在于构建了一个高质量的热红外数据集CST Anti-UAV，专门针对复杂场景下的微型无人机跟踪，并且首次引入了完整的手动帧级属性标注。这对于推动反无人机技术，特别是微型无人机跟踪领域的研究具有重要意义。实验结果清楚地揭示了现有SOT方法在该挑战性任务上的局限性，为未来的研究指明了方向。"}}
{"id": "2502.20632", "title": "Lattice Protein Folding with Variational Annealing", "authors": ["Shoummo Ahsan Khandoker", "Estelle M. Inack", "Mohamed Hibat-Allah"], "categories": ["cond-mat.dis-nn", "cs.AI", "cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Disordered Systems and Neural Networks (cond-mat.dis-nn)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20632v2", "summary": "Understanding the principles of protein folding is a cornerstone of\ncomputational biology, with implications for drug design, bioengineering, and\nthe understanding of fundamental biological processes. Lattice protein folding\nmodels offer a simplified yet powerful framework for studying the complexities\nof protein folding, enabling the exploration of energetically optimal folds\nunder constrained conditions. However, finding these optimal folds is a\ncomputationally challenging combinatorial optimization problem. In this work,\nwe introduce a novel upper-bound training scheme that employs masking to\nidentify the lowest-energy folds in two-dimensional Hydrophobic-Polar (HP)\nlattice protein folding. By leveraging Dilated Recurrent Neural Networks (RNNs)\nintegrated with an annealing process driven by temperature-like fluctuations,\nour method accurately predicts optimal folds for benchmark systems of up to 60\nbeads. Our approach also effectively masks invalid folds from being sampled\nwithout compromising the autoregressive sampling properties of RNNs. This\nscheme is generalizable to three spatial dimensions and can be extended to\nlattice protein models with larger alphabets. Our findings emphasize the\npotential of advanced machine learning techniques in tackling complex protein\nfolding problems and a broader class of constrained combinatorial optimization\nchallenges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20632v2", "cate": "cond-mat.dis-nn", "date": "2025-02-28", "updated": "2025-07-30", "AI": {"title_translation": "变分退火的格点蛋白质折叠", "tldr": "本文提出了一种结合扩张循环神经网络和退火过程的新型上界训练方案，通过掩蔽在二维HP格点蛋白质折叠中识别最低能量折叠，并成功预测了高达60个珠子的基准系统的最优折叠。", "motivation": "蛋白质折叠原理是计算生物学的基石，对药物设计、生物工程和基础生物过程理解有重要意义。然而，在格点蛋白质折叠模型中寻找最优折叠是一个计算上具有挑战性的组合优化问题。", "method": "本文引入了一种新颖的上界训练方案，该方案利用掩蔽技术来识别二维疏水-亲水（HP）格点蛋白质折叠中的最低能量折叠。该方法通过结合扩张循环神经网络（RNNs）和由类温度波动驱动的退火过程来实现，并能有效掩蔽无效折叠的采样。", "result": "该方法能够准确预测高达60个珠子的基准系统的最优折叠。它还能有效阻止无效折叠被采样，同时不损害RNNs的自回归采样特性。", "conclusion": "研究结果强调了先进机器学习技术在解决复杂蛋白质折叠问题以及更广泛的受限组合优化挑战方面的潜力。该方案可推广到三维空间，并可扩展到具有更大字母表的格点蛋白质模型。", "translation": "理解蛋白质折叠原理是计算生物学的基石，对药物设计、生物工程和理解基本生物过程具有重要意义。格点蛋白质折叠模型提供了一个简化而强大的框架，用于研究蛋白质折叠的复杂性，从而能够在受限条件下探索能量最优的折叠。然而，寻找这些最优折叠是一个计算上具有挑战性的组合优化问题。在这项工作中，我们引入了一种新颖的上界训练方案，该方案采用掩蔽技术来识别二维疏水-亲水（HP）格点蛋白质折叠中的最低能量折叠。通过利用结合了由类温度波动驱动的退火过程的扩张循环神经网络（RNNs），我们的方法能够准确预测高达60个珠子的基准系统的最优折叠。我们的方法还能有效地掩蔽无效折叠，使其不被采样，同时不损害RNNs的自回归采样特性。该方案可推广到三维空间，并可扩展到具有更大字母表的格点蛋白质模型。我们的研究结果强调了先进机器学习技术在解决复杂蛋白质折叠问题和更广泛的受限组合优化挑战方面的潜力。", "summary": "本文提出了一种新颖的变分退火方法，结合扩张循环神经网络（RNNs）和上界训练方案，以解决格点蛋白质折叠中的组合优化问题。该方法通过掩蔽技术在二维HP格点模型中有效识别最低能量折叠，并成功预测了高达60个珠子的基准系统最优折叠，同时保持了RNN的自回归采样特性。研究表明，该方案具有推广到三维和更复杂模型的潜力，突显了机器学习在解决复杂生物物理问题中的应用前景。", "keywords": "蛋白质折叠, 格点模型, 变分退火, 循环神经网络, 组合优化", "comments": "这项工作在解决蛋白质折叠这一经典的组合优化问题上引入了创新的机器学习方法。通过结合扩张RNNs和退火过程，并引入上界训练和掩蔽策略，有效提高了寻找最优折叠的准确性，并解决了无效折叠采样的问题。其通用性（可扩展到三维和更大字母表模型）是其重要创新点，展示了机器学习在生物物理复杂问题中的巨大潜力。"}}
{"id": "2507.21035", "title": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis", "authors": ["Haoyang Liu", "Yijiang Li", "Haohan Wang"], "categories": ["cs.AI", "cs.LG", "cs.MA", "q-bio.GN"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      51 pages (13 pages for the main text, 9 pages for references, and 29 pages for the appendix)", "url": "http://arxiv.org/abs/2507.21035v2", "summary": "Gene expression analysis holds the key to many biomedical discoveries, yet\nextracting insights from raw transcriptomic data remains formidable due to the\ncomplexity of multiple large, semi-structured files and the need for extensive\ndomain expertise. Current automation approaches are often limited by either\ninflexible workflows that break down in edge cases or by fully autonomous\nagents that lack the necessary precision for rigorous scientific inquiry.\nGenoMAS charts a different course by presenting a team of LLM-based scientists\nthat integrates the reliability of structured workflows with the adaptability\nof autonomous agents. GenoMAS orchestrates six specialized LLM agents through\ntyped message-passing protocols, each contributing complementary strengths to a\nshared analytic canvas. At the heart of GenoMAS lies a guided-planning\nframework: programming agents unfold high-level task guidelines into Action\nUnits and, at each juncture, elect to advance, revise, bypass, or backtrack,\nthereby maintaining logical coherence while bending gracefully to the\nidiosyncrasies of genomic data.\n  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation\nof 89.13% for data preprocessing and an F$_1$ of 60.48% for gene\nidentification, surpassing the best prior art by 10.61% and 16.85%\nrespectively. Beyond metrics, GenoMAS surfaces biologically plausible\ngene-phenotype associations corroborated by the literature, all while adjusting\nfor latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.", "comment": "51 pages (13 pages for the main text, 9 pages for references, and 29\n  pages for the appendix)", "pdf_url": "http://arxiv.org/pdf/2507.21035v2", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-31", "AI": {"title_translation": "GenoMAS：一个通过代码驱动的基因表达分析实现科学发现的多智能体框架", "tldr": "GenoMAS是一个基于LLM的多智能体框架，通过结合结构化工作流的可靠性和自主代理的适应性，显著提高了基因表达分析的效率和准确性，超越了现有技术水平。", "motivation": "基因表达分析是生物医学发现的关键，但从原始转录组数据中提取见解极具挑战性，因为文件复杂且需要广泛的领域专业知识。当前的自动化方法受到限制，要么工作流不灵活，在边缘情况下会崩溃，要么完全自主的代理缺乏科学研究所需的精确性。", "method": "GenoMAS提出了一个由LLM驱动的科学家团队，整合了结构化工作流的可靠性和自主代理的适应性。它通过类型化消息传递协议协调六个专门的LLM代理，每个代理都为共享的分析画布贡献互补的优势。GenoMAS的核心是一个引导式规划框架：编程代理将高级任务指南展开为行动单元，并在每个关键点选择前进、修改、绕过或回溯，从而在适应基因组数据特性的同时保持逻辑连贯性。", "result": "在GenoTEX基准测试中，GenoMAS在数据预处理方面的复合相似性相关性达到89.13%，在基因识别方面的F1得分达到60.48%，分别超越了现有最佳技术10.61%和16.85%。除了指标之外，GenoMAS还发现了经文献证实的生物学上合理的基因-表型关联，同时调整了潜在的混杂因素。", "conclusion": "GenoMAS通过其多智能体框架和引导式规划，有效地解决了基因表达分析的复杂性，显著提高了分析性能，并能发现生物学上合理的关联，为科学发现提供了强大的工具。", "translation": "基因表达分析是许多生物医学发现的关键，但由于多个大型半结构化文件的复杂性以及对广泛领域专业知识的需求，从原始转录组数据中提取见解仍然非常困难。当前的自动化方法常常受限于不灵活的工作流（在边缘情况下会崩溃）或缺乏严谨科学研究所需精度的完全自主代理。GenoMAS开辟了一条不同的道路，它提出了一个基于LLM的科学家团队，该团队将结构化工作流的可靠性与自主代理的适应性相结合。GenoMAS通过类型化消息传递协议协调六个专门的LLM代理，每个代理都为共享的分析画布贡献互补的优势。GenoMAS的核心是一个引导式规划框架：编程代理将高级任务指南展开为行动单元，并在每个关键点选择前进、修改、绕过或回溯，从而在适应基因组数据特性的同时保持逻辑连贯性。在GenoTEX基准测试中，GenoMAS在数据预处理方面的复合相似性相关性达到89.13%，在基因识别方面的F1得分达到60.48%，分别超越了现有最佳技术10.61%和16.85%。除了指标之外，GenoMAS还发现了经文献证实的生物学上合理的基因-表型关联，同时调整了潜在的混杂因素。代码可在https://github.com/Liu-Hy/GenoMAS获取。", "summary": "GenoMAS是一个创新的多智能体框架，利用大型语言模型（LLM）团队进行代码驱动的基因表达分析。它通过结合结构化工作流的可靠性和自主代理的灵活性，解决了传统方法的局限性。GenoMAS协调六个专业LLM代理，通过引导式规划框架，将高级任务分解为可调整的行动单元，从而有效处理复杂的基因组数据。在GenoTEX基准测试中，GenoMAS在数据预处理和基因识别方面均显著超越现有技术，并能发现生物学上合理的基因-表型关联。", "keywords": "多智能体系统, 基因表达分析, LLM, 科学发现, 生物信息学", "comments": "GenoMAS的创新之处在于其将LLM驱动的代理与结构化工作流相结合的多智能体框架，这解决了基因表达分析中传统自动化方法灵活性不足和完全自主代理精度欠缺的问题。其引导式规划框架允许系统在保持逻辑连贯性的同时适应基因组数据的复杂性，这对于实际应用至关重要。该研究通过量化指标和发现生物学上合理的关联，证明了其在科学发现中的巨大潜力。这是一个将LLM能力应用于复杂科学领域，并取得显著成效的优秀案例。"}}
{"id": "2507.23225", "title": "YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection", "authors": ["Zicheng Lin", "Weichao Pan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23225v1", "summary": "Road damage detection is a critical task for ensuring traffic safety and\nmaintaining infrastructure integrity. While deep learning-based detection\nmethods are now widely adopted, they still face two core challenges: first, the\ninadequate multi-scale feature extraction capabilities of existing networks for\ndiverse targets like cracks and potholes, leading to high miss rates for\nsmall-scale damage; and second, the substantial parameter counts and\ncomputational demands of mainstream models, which hinder their deployment for\nefficient, real-time detection in practical applications. To address these\nissues, this paper proposes a high-precision and lightweight model, YOLO - Road\nOrthogonal Compact (YOLO-ROC). We designed a Bidirectional Multi-scale Spatial\nPyramid Pooling Fast (BMS-SPPF) module to enhance multi-scale feature\nextraction and implemented a hierarchical channel compression strategy to\nreduce computational complexity. The BMS-SPPF module leverages a bidirectional\nspatial-channel attention mechanism to improve the detection of small targets.\nConcurrently, the channel compression strategy reduces the parameter count from\n3.01M to 0.89M and GFLOPs from 8.1 to 2.6. Experiments on the\nRDD2022_China_Drone dataset demonstrate that YOLO-ROC achieves a mAP50 of\n67.6%, surpassing the baseline YOLOv8n by 2.11%. Notably, the mAP50 for the\nsmall-target D40 category improved by 16.8%, and the final model size is only\n2.0 MB. Furthermore, the model exhibits excellent generalization performance on\nthe RDD2022_China_Motorbike dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23225v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "YOLO-ROC：一种用于实时道路损伤检测的高精度超轻量模型", "tldr": "YOLO-ROC是一种高精度、超轻量级模型，用于实时道路损伤检测，通过改进多尺度特征提取和通道压缩，显著提高了小目标检测性能并大幅减小了模型尺寸。", "motivation": "现有深度学习道路损伤检测方法面临两大挑战：一是多尺度特征提取能力不足导致对小尺度损伤的漏检率高；二是主流模型参数量大、计算需求高，难以在实际应用中高效实时部署。", "method": "本文提出了YOLO-ROC模型。该模型设计了双向多尺度空间金字塔池化快速（BMS-SPPF）模块以增强多尺度特征提取和利用双向空间-通道注意力机制改进小目标检测。同时，实施了分层通道压缩策略以减少计算复杂性和参数量。", "result": "在RDD2022_China_Drone数据集上，YOLO-ROC的mAP50达到67.6%，比YOLOv8n高出2.11%，其中小目标D40类别的mAP50提高了16.8%。模型参数量从3.01M减少到0.89M，GFLOPs从8.1减少到2.6。最终模型大小仅为2.0 MB，并在RDD2022_China_Motorbike数据集上表现出优异的泛化性能。", "conclusion": "YOLO-ROC成功解决了道路损伤检测中精度与模型轻量化之间的矛盾，尤其在小目标检测方面表现出色，为实时道路损伤检测提供了高效可部署的解决方案。", "translation": "道路损伤检测是确保交通安全和维护基础设施完整性的关键任务。尽管基于深度学习的检测方法已被广泛采用，但它们仍面临两个核心挑战：首先，现有网络对裂缝和坑洼等多样化目标的多尺度特征提取能力不足，导致对小尺度损伤的漏检率高；其次，主流模型庞大的参数量和计算需求阻碍了它们在实际应用中进行高效的实时检测部署。为了解决这些问题，本文提出了一种高精度、轻量级模型YOLO - Road Orthogonal Compact (YOLO-ROC)。我们设计了一个双向多尺度空间金字塔池化快速（BMS-SPPF）模块来增强多尺度特征提取，并实施了一种分层通道压缩策略来降低计算复杂性。BMS-SPPF模块利用双向空间-通道注意力机制来改进小目标的检测。同时，通道压缩策略将参数量从3.01M减少到0.89M，GFLOPs从8.1减少到2.6。在RDD2022_China_Drone数据集上的实验表明，YOLO-ROC的mAP50达到67.6%，超过基线YOLOv8n 2.11%。值得注意的是，小目标D40类别的mAP50提高了16.8%，最终模型大小仅为2.0 MB。此外，该模型在RDD2022_China_Motorbike数据集上表现出优异的泛化性能。", "summary": "本文提出了YOLO-ROC，一个用于实时道路损伤检测的高精度超轻量级模型，旨在解决现有方法在多尺度特征提取不足导致小目标漏检以及模型过于庞大难以实时部署的问题。YOLO-ROC通过引入双向多尺度空间金字塔池化快速（BMS-SPPF）模块增强多尺度特征提取和小型目标检测能力，并采用分层通道压缩策略显著减少了模型参数和计算量。实验证明，YOLO-ROC在道路损伤检测数据集上不仅超越了基线模型，特别是在小目标检测方面有显著提升，且模型尺寸极小，展现了优异的实时性和泛化能力。", "keywords": "道路损伤检测, YOLO-ROC, 轻量级模型, 多尺度特征提取, 小目标检测", "comments": "这篇论文的创新点在于其成功地在道路损伤检测领域实现了高精度与超轻量化的平衡。通过结合改进的多尺度特征提取（BMS-SPPF模块，特别是其双向空间-通道注意力机制）和高效的通道压缩策略，YOLO-ROC有效解决了小目标检测难题并大幅降低了模型部署的门槛。其在实际应用中的潜力巨大，尤其适用于资源受限的移动或嵌入式设备进行实时道路监测。"}}
{"id": "2507.23562", "title": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "authors": ["Sirine Arfa", "Bernhard Vogginger", "Christian Mayr"], "categories": ["cs.LG", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures, 3 tables", "url": "http://arxiv.org/abs/2507.23562v1", "summary": "Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning.", "comment": "8 pages, 5 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.23562v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SpiNNaker2 神经形态平台上的脉冲Q网络硬件感知微调", "tldr": "本文在SpiNNaker2神经形态芯片上实现了能量高效的脉冲Q网络，用于解决控制任务，并展示了相比GPU高达32倍的能耗降低。", "motivation": "为了在神经形态硬件上实现低功耗、低延迟的推理，并解决机器人任务中的强化学习问题，作者旨在开发一种能量高效的脉冲神经网络（SNN）实现方案。", "method": "研究人员使用Q学习算法训练脉冲神经网络，然后将其微调并量化为低位（8位）精度，部署到SpiNNaker2神经形态芯片上。他们通过分析推理延迟、动态功耗和每次推理的能耗来评估SpiNNaker2与传统计算平台（GTX 1650 GPU）的比较优势。", "result": "SpiNNaker2在能耗方面实现了高达32倍的降低，同时推理延迟与GPU相当，在特定任务设置中有所改进。这表明SpiNNaker2在可扩展、低能耗神经形态计算方面具有强大潜力。", "conclusion": "SpiNNaker2平台在实时神经形态控制方面具有可行性，并且神经形态方法是实现高效深度Q学习的一个引人注目的方向。", "translation": "脉冲神经网络（SNN）有望在神经形态硬件上实现数量级的低功耗和低延迟推理，适用于广泛的机器人任务。在这项工作中，我们提出了一种使用量化SNN实现强化学习（RL）算法的节能方法，以解决两个经典的控制任务。该网络使用Q学习算法进行训练，然后进行微调并量化到低位（8位）精度，以便在SpiNNaker2神经形态芯片上进行嵌入式部署。为了评估SpiNNaker2相对于传统计算平台的比较优势，我们分析了SNN模型的推理延迟、动态功耗和每次推理的能耗，并将性能与GTX 1650 GPU基线进行比较。我们的结果表明，SpiNNaker2在可扩展、低能耗神经形态计算方面具有强大潜力，实现了高达32倍的能耗降低。推理延迟与基于GPU的执行保持一致，在某些任务设置中观察到改进，这加强了SpiNNaker2在实时神经形态控制方面的可行性，并使神经形态方法成为高效深度Q学习的一个引人注目的方向。", "summary": "该研究在SpiNNaker2神经形态平台上实现了基于量化脉冲神经网络（SNN）的强化学习算法，用于解决经典控制任务。通过Q学习训练后，网络被微调并量化至8位精度以适应SpiNNaker2芯片。与GTX 1650 GPU相比，SpiNNaker2展示了高达32倍的能耗降低，同时保持或改进了推理延迟，突显了其在低能耗、实时神经形态计算方面的潜力。", "keywords": "脉冲神经网络, 强化学习, 神经形态计算, SpiNNaker2, 能耗效率", "comments": "该论文的创新点在于将硬件感知微调应用于SNN，并将其部署在特定的神经形态平台SpiNNaker2上，以实现能效优化。其重要性在于验证了神经形态计算在强化学习任务中的巨大能耗优势，并为未来低功耗边缘AI应用提供了有前景的方向。论文通过量化和直接硬件部署，解决了SNN在实际应用中的能效瓶颈。"}}
{"id": "2506.05898", "title": "On Level Crossings and Fade Durations in von Mises-Fisher Scattering Channels", "authors": ["Kenan Turbic", "Slawomir Stanczak"], "categories": ["eess.SP", "stat.AP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at WSA 2025 (Track 2)", "url": "http://arxiv.org/abs/2506.05898v2", "summary": "This paper investigates the second-order statistics of multipath fading\nchannels with von Mises-Fisher (vMF) distributed scatters. Simple closed-form\nexpressions for the mean Doppler shift and Doppler spread are derived as the\nkey spectral moments that capture the impact of mobility and scattering\ncharacteristics on level crossings and fade durations. These expressions are\nthen used to analyze the influence of vMF parameters on the Level-Crossing Rate\n(LCR) and Average Fade Duration (AFD). The results show that isotropic\nscattering yields the highest LCR and the lowest AFD, while fading dynamics\nreduce with the decreasing angular spread of scatterers. Moreover, mobile\nantenna motion parallel to the mean scattering direction results in a lower LCR\nthan the perpendicular motion, with the difference between the two cases\nincreasing with the higher concentration of scatterers.", "comment": "Accepted for presentation at WSA 2025 (Track 2)", "pdf_url": "http://arxiv.org/pdf/2506.05898v2", "cate": "eess.SP", "date": "2025-06-06", "updated": "2025-07-31", "AI": {"title_translation": "关于von Mises-Fisher散射信道中的电平穿越和衰落持续时间", "tldr": "本文研究了vMF散射信道中多径衰落的二阶统计量，推导了多普勒频移和多普勒扩展的闭合表达式，并分析了vMF参数对LCR和AFD的影响，揭示了散射特性和天线运动对衰落动态的影响。", "motivation": "研究具有von Mises-Fisher (vMF) 分布散射体的多径衰落信道的二阶统计量，并捕捉移动性和散射特性对电平穿越和衰落持续时间的影响。", "method": "1. 推导了平均多普勒频移和多普勒扩展的简单闭合表达式。 2. 利用这些表达式分析了vMF参数对电平穿越率（LCR）和平均衰落持续时间（AFD）的影响。", "result": "1. 得到了平均多普勒频移和多普勒扩展的闭合表达式。 2. 各向同性散射产生最高的LCR和最低的AFD。 3. 衰落动态随散射体角扩展的减小而降低。 4. 移动天线平行于平均散射方向的运动比垂直运动产生更低的LCR，且两者差异随散射体集中度增加而增大。", "conclusion": "散射特性和移动天线运动方向对多径衰落信道的电平穿越率和平均衰落持续时间有显著影响，其中各向同性散射导致最剧烈的衰落动态，而平行于平均散射方向的运动能降低电平穿越率。", "translation": "本文研究了具有von Mises-Fisher (vMF) 分布散射体的多径衰落信道的二阶统计量。推导了平均多普勒频移和多普勒扩展的简单闭合表达式，作为捕获移动性和散射特性对电平穿越和衰落持续时间影响的关键频谱矩。然后利用这些表达式分析了vMF参数对电平穿越率（LCR）和平均衰落持续时间（AFD）的影响。结果表明，各向同性散射产生最高的LCR和最低的AFD，而衰落动态随散射体角扩展的减小而降低。此外，移动天线平行于平均散射方向的运动比垂直运动产生更低的LCR，且两者差异随散射体集中度的提高而增大。", "summary": "本文研究了具有von Mises-Fisher分布散射体的多径衰落信道的二阶统计量。通过推导平均多普勒频移和多普勒扩展的闭合表达式，作者分析了散射特性和移动性对电平穿越率（LCR）和平均衰落持续时间（AFD）的影响。研究发现，各向同性散射导致最高的LCR和最低的AFD，衰落动态随散射体角扩展的减小而降低。此外，天线平行于平均散射方向的运动比垂直运动能有效降低LCR。", "keywords": "von Mises-Fisher散射, 电平穿越率, 平均衰落持续时间, 多普勒频移, 多普勒扩展", "comments": "这项研究为理解具有非均匀散射特性的无线信道中的衰落动态提供了重要的理论基础。通过推导闭合表达式，简化了对复杂信道行为的分析。其结果对于无线通信系统设计，特别是在优化移动性管理和抗衰落策略方面具有指导意义。"}}
{"id": "2503.13544", "title": "Decision by Supervised Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization", "authors": ["Juhyeong Kim", "Sungyoon Choi", "Youngbin Lee", "Yejin Kim", "Yongmin Choi", "Yongjae Lee"], "categories": ["cs.LG", "q-fin.CP", "q-fin.PM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures", "url": "http://arxiv.org/abs/2503.13544v4", "summary": "We propose Decision by Supervised Learning (DSL), a practical framework for\nrobust portfolio optimization. DSL reframes portfolio construction as a\nsupervised learning problem: models are trained to predict optimal portfolio\nweights, using cross-entropy loss and portfolios constructed by maximizing the\nSharpe or Sortino ratio. To further enhance stability and reliability, DSL\nemploys Deep Ensemble methods, substantially reducing variance in portfolio\nallocations. Through comprehensive backtesting across diverse market universes\nand neural architectures, shows superior performance compared to both\ntraditional strategies and leading machine learning-based methods, including\nPrediction-Focused Learning and End-to-End Learning. We show that increasing\nthe ensemble size leads to higher median returns and more stable risk-adjusted\nperformance. The code is available at https://github.com/DSLwDE/DSLwDE.", "comment": "8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2503.13544v4", "cate": "cs.LG", "date": "2025-03-16", "updated": "2025-07-30", "AI": {"title_translation": "深度集成监督学习决策：一个稳健投资组合优化的实用框架", "tldr": "本文提出了基于深度集成监督学习 (DSL) 的稳健投资组合优化框架，通过将投资组合构建重构为监督学习问题并利用深度集成方法，实现了优于传统和现有机器学习方法的性能，并显著降低了投资组合分配的方差。", "motivation": "针对稳健投资组合优化问题，旨在提供一个实用且性能更优的框架。", "method": "提出“深度集成监督学习决策 (DSL)”框架。DSL 将投资组合构建重构为监督学习问题，通过最大化夏普比率或索蒂诺比率来构建投资组合，并使用交叉熵损失训练模型以预测最优投资组合权重。为增强稳定性和可靠性，DSL 采用了深度集成方法来显著降低投资组合分配的方差。", "result": "通过在不同市场和神经网络架构上的全面回测，DSL 展现出优于传统策略和包括预测聚焦学习、端到端学习在内的领先机器学习方法的卓越性能。研究表明，增加集成规模可以带来更高的中位数回报和更稳定的风险调整表现。", "conclusion": "DSL 提供了一个有效且实用的稳健投资组合优化框架，通过结合监督学习和深度集成方法，显著提升了投资组合的性能和稳定性。", "translation": "我们提出了深度集成监督学习决策 (DSL)，一个用于稳健投资组合优化的实用框架。DSL 将投资组合构建重新定义为监督学习问题：模型通过使用交叉熵损失以及最大化夏普比率或索蒂诺比率构建的投资组合来训练，以预测最优投资组合权重。为了进一步提高稳定性和可靠性，DSL 采用了深度集成方法，显著降低了投资组合分配的方差。通过在不同市场环境和神经网络架构下进行的全面回测，结果显示其性能优于传统策略和领先的基于机器学习的方法，包括预测聚焦学习和端到端学习。我们证明，增加集成规模会导致更高的中位数回报和更稳定的风险调整表现。代码可在 https://github.com/DSLwDE/DSLwDE 获取。", "summary": "本文提出了一种名为深度集成监督学习决策（DSL）的实用框架，用于实现稳健的投资组合优化。该框架将投资组合构建视为监督学习任务，通过训练模型预测最优权重，并利用深度集成方法显著降低投资组合分配的方差，从而提高稳定性和可靠性。在广泛的回测中，DSL 展现出优于传统方法及其他机器学习方法的卓越性能，并且发现增加集成规模能带来更好的收益和更稳定的风险调整表现。", "keywords": "投资组合优化, 监督学习, 深度集成, 机器学习, 风险管理", "comments": "DSL 的创新之处在于将复杂的投资组合优化问题转化为更易于处理的监督学习问题，并巧妙地引入深度集成方法来解决传统方法中存在的方差和稳定性问题。其在不同市场环境下的优异表现凸显了该框架的实用性和有效性，为量化投资领域提供了一个有价值的新工具。"}}
{"id": "2507.23497", "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "authors": ["David A Kelly", "Hana Chockler"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      13 pages, 13 figures, appendix included", "url": "http://arxiv.org/abs/2507.23497v1", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "comment": "13 pages, 13 figures, appendix included", "pdf_url": "http://arxiv.org/pdf/2507.23497v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "图像分类中充分、对比和完整特征集的因果识别", "tldr": "本文提出了一种新的因果解释方法，用于图像分类器，解决了现有方法缺乏形式严谨性或不适用于黑盒模型的缺陷，并证明其高效且完全黑盒。", "motivation": "现有的图像分类器解释算法缺乏形式严谨性，或其可计算性依赖于对模型严格的假设，而这些假设在图像分类器上不成立。", "method": "提出因果解释，其具有与基于逻辑的解释相同的形式属性，同时适用于黑盒算法和图像分类器。引入对比因果解释和具有置信度意识的完整因果解释。", "result": "实验结果表明，不同模型在充分性、对比性和完整性方面表现出不同的模式。所提出的算法计算效率高（ResNet50模型平均每张图像需要6秒），并且是完全黑盒的，无需模型内部知识或梯度信息。", "conclusion": "因果解释不仅形式严谨，而且适用于黑盒模型，能够高效地为图像分类器提供充分、对比和完整的特征集解释。", "translation": "现有图像分类器输出解释算法基于多种方法，但其解释缺乏形式严谨性。另一方面，基于逻辑的解释形式上定义严谨，但其可计算性依赖于模型严格的假设，而这些假设在图像分类器上不成立。\n在本文中，我们展示了因果解释除了形式上定义严谨外，还具有与基于逻辑的解释相同的形式属性，同时适用于黑盒算法，并且非常适合图像分类器。我们证明了因果解释的形式属性，并为图像分类器引入了对比因果解释。此外，我们通过置信度感知增强了解释的定义，并引入了完整的因果解释：即与原始图像具有完全相同置信度分类的解释。\n我们实现了我们的定义，实验结果表明不同模型在充分性、对比性和完整性方面具有不同的模式。我们的算法计算效率高，在ResNet50模型上平均每张图像需要6秒来计算所有类型的解释，并且是完全黑盒的，不需要任何模型知识、模型内部访问、梯度访问，也不需要模型的任何属性，如单调性。", "summary": "本文针对现有图像分类器解释方法缺乏形式严谨性或不适用于黑盒模型的问题，提出了一种新的因果解释框架。该框架不仅形式严谨，具有与逻辑解释相似的属性，而且适用于黑盒算法，并特别适合图像分类器。作者引入了对比因果解释和基于置信度的完整因果解释。实验证明，所提出的算法高效且完全黑盒，能够有效识别图像分类中充分、对比和完整的特征集。", "keywords": "因果解释, 图像分类, 黑盒模型, 特征集, 可解释AI", "comments": "本文的创新点在于提出了形式严谨且适用于黑盒图像分类器的因果解释方法，克服了现有解释方法在严谨性和适用性上的局限。其强调的完全黑盒特性和计算效率使其在实际应用中具有重要价值。"}}
{"id": "2507.23492", "title": "Digital literacy interventions can boost humans in discerning deepfakes", "authors": ["Dominique Geissler", "Claire Robertson", "Stefan Feuerriegel"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23492v1", "summary": "Deepfakes, i.e., images generated by artificial intelligence (AI), can erode\ntrust in institutions and compromise election outcomes, as people often\nstruggle to discern real images from deepfakes. Improving digital literacy can\nhelp address these challenges, yet scalable and effective approaches remain\nlargely unexplored. Here, we compare the efficacy of five digital literacy\ninterventions to boost people's ability to discern deepfakes: (1) textual\nguidance on common indicators of deepfakes; (2) visual demonstrations of these\nindicators; (3) a gamified exercise for identifying deepfakes; (4) implicit\nlearning through repeated exposure and feedback; and (5) explanations of how\ndeepfakes are generated with the help of AI. We conducted an experiment with\nN=1,200 participants from the United States to test the immediate and long-term\neffectiveness of our interventions. Our results show that our interventions can\nboost deepfake discernment by up to 13 percentage points while maintaining\ntrust in real images. Altogether, our approach is scalable, suitable for\ndiverse populations, and highly effective for boosting deepfake detection while\nmaintaining trust in truthful information.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23492v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "数字素养干预可以提高人类识别深度伪造的能力", "tldr": "数字素养干预措施能有效提高人们识别深度伪造的能力，且保持对真实图像的信任。", "motivation": "深度伪造图像（Deepfakes）正在侵蚀机构信任并可能影响选举结果，因为人们难以区分真实图像和深度伪造图像。需要可扩展且有效的方法来解决这一挑战。", "method": "研究比较了五种数字素养干预措施的有效性：文本指导、视觉演示、游戏化练习、通过重复接触和反馈的隐性学习，以及解释深度伪造的生成方式。实验在美国招募了1200名参与者，测试干预措施的即时和长期效果。", "result": "干预措施能将深度伪造识别能力提高多达13个百分点，同时保持对真实图像的信任。", "conclusion": "该方法具有可扩展性，适用于不同人群，并且在提高深度伪造检测能力的同时保持对真实信息的信任方面非常有效。", "translation": "深度伪造，即人工智能（AI）生成的图像，会侵蚀人们对机构的信任并可能损害选举结果，因为人们常常难以区分真实图像和深度伪造图像。提高数字素养有助于应对这些挑战，但可扩展且有效的方法仍未被充分探索。在此，我们比较了五种数字素养干预措施在提高人们识别深度伪造能力方面的功效：(1) 关于深度伪造常见指标的文本指导；(2) 这些指标的视觉演示；(3) 识别深度伪造的游戏化练习；(4) 通过重复接触和反馈进行的隐性学习；以及 (5) 借助AI解释深度伪造的生成方式。我们对来自美国的1200名参与者进行了实验，以测试我们干预措施的即时和长期有效性。我们的结果表明，我们的干预措施可以将深度伪造识别能力提高多达13个百分点，同时保持对真实图像的信任。总而言之，我们的方法具有可扩展性，适用于不同人群，并且在提高深度伪造检测能力的同时保持对真实信息的信任方面非常有效。", "summary": "本研究旨在探索提高人们识别深度伪造图像能力的有效数字素养干预措施。通过对1200名美国参与者进行实验，比较了文本指导、视觉演示、游戏化练习、隐性学习和生成原理解释等五种干预方法。结果表明，这些干预措施能有效提高深度伪造识别能力高达13个百分点，同时不损害对真实图像的信任。研究强调其方法具有可扩展性、普适性和高效性。", "keywords": "深度伪造, 数字素养, 图像识别, 干预措施, 人工智能", "comments": "这篇论文的创新点在于系统地比较了多种数字素养干预措施在提高深度伪造识别能力方面的效果，并明确量化了其提升幅度。其重要性在于提供了一种可扩展且有效的方法来应对深度伪造带来的社会信任危机，尤其是在信息辨别日益重要的当下。"}}
{"id": "2507.23313", "title": "The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models", "authors": ["Alfio Ferrara", "Sergio Picascia", "Elisabetta Rocchetti"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      to be published in: Applications of AI in the Analysis of Cultural and Artistic Heritage, organized within the 35th IEEE International Workshop on Machine Learning for Signal Processing (MLSP) 2025", "url": "http://arxiv.org/abs/2507.23313v1", "summary": "Text-to-image diffusion models have demonstrated remarkable capabilities in\ngenerating artistic content by learning from billions of images, including\npopular artworks. However, the fundamental question of how these models\ninternally represent concepts, such as content and style in paintings, remains\nunexplored. Traditional computer vision assumes content and style are\northogonal, but diffusion models receive no explicit guidance about this\ndistinction during training. In this work, we investigate how transformer-based\ntext-to-image diffusion models encode content and style concepts when\ngenerating artworks. We leverage cross-attention heatmaps to attribute pixels\nin generated images to specific prompt tokens, enabling us to isolate image\nregions influenced by content-describing versus style-describing tokens. Our\nfindings reveal that diffusion models demonstrate varying degrees of\ncontent-style separation depending on the specific artistic prompt and style\nrequested. In many cases, content tokens primarily influence object-related\nregions while style tokens affect background and texture areas, suggesting an\nemergent understanding of the content-style distinction. These insights\ncontribute to our understanding of how large-scale generative models internally\nrepresent complex artistic concepts without explicit supervision. We share the\ncode and dataset, together with an exploratory tool for visualizing attention\nmaps at https://github.com/umilISLab/artistic-prompt-interpretation.", "comment": "to be published in: Applications of AI in the Analysis of Cultural\n  and Artistic Heritage, organized within the 35th IEEE International Workshop\n  on Machine Learning for Signal Processing (MLSP) 2025", "pdf_url": "http://arxiv.org/pdf/2507.23313v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "伦勃朗的奶牛——分析文本到图像模型中艺术提示的解释", "tldr": "本文研究了文本到图像扩散模型如何在其内部表示艺术作品中的内容和风格概念，发现模型在生成艺术品时对内容和风格有不同程度的分离理解，内容标记主要影响物体区域，而风格标记影响背景和纹理区域。", "motivation": "文本到图像扩散模型在生成艺术内容方面表现出色，但它们如何内部表示绘画中的内容和风格等概念仍未被探索。传统计算机视觉假设内容和风格是正交的，而扩散模型在训练期间没有得到明确的指导。本文旨在调查这些模型如何编码内容和风格概念。", "method": "研究利用交叉注意力热图将生成图像中的像素归因于特定的提示标记，从而能够分离受内容描述标记和风格描述标记影响的图像区域。", "result": "研究发现，扩散模型根据特定的艺术提示和请求的风格，表现出不同程度的内容-风格分离。在许多情况下，内容标记主要影响与对象相关的区域，而风格标记影响背景和纹理区域，这表明模型对内容-风格的区别有了一个新兴的理解。", "conclusion": "这些见解有助于我们理解大规模生成模型如何在没有明确监督的情况下内部表示复杂的艺术概念。", "translation": "文本到图像扩散模型通过学习数十亿张图像（包括流行的艺术作品），在生成艺术内容方面表现出卓越的能力。然而，这些模型如何在内部表示概念，例如绘画中的内容和风格，这一基本问题仍未被探索。传统计算机视觉假设内容和风格是正交的，但扩散模型在训练期间没有得到关于这种区别的明确指导。在这项工作中，我们研究了基于Transformer的文本到图像扩散模型在生成艺术作品时如何编码内容和风格概念。我们利用交叉注意力热图将生成图像中的像素归因于特定的提示标记，使我们能够分离受内容描述标记和风格描述标记影响的图像区域。我们的发现表明，扩散模型根据特定的艺术提示和请求的风格，表现出不同程度的内容-风格分离。在许多情况下，内容标记主要影响与对象相关的区域，而风格标记影响背景和纹理区域，这表明模型对内容-风格的区别有了一个新兴的理解。这些见解有助于我们理解大规模生成模型如何在没有明确监督的情况下内部表示复杂的艺术概念。我们分享了代码和数据集，以及一个用于可视化注意力图的探索性工具，网址为https://github.com/umilISLab/artistic-prompt-interpretation。", "summary": "本文探讨了文本到图像扩散模型如何处理艺术提示中的内容和风格信息。通过分析交叉注意力热图，研究发现这些模型在生成艺术品时，内容标记主要影响物体区域，而风格标记则影响背景和纹理区域，表明模型在没有明确监督的情况下对内容-风格区别形成了内在理解。这项工作为理解大型生成模型内部表示复杂艺术概念提供了新的视角。", "keywords": "文本到图像模型, 扩散模型, 艺术提示解释, 内容-风格分离, 交叉注意力热图", "comments": "这项研究的创新之处在于利用交叉注意力热图来深入探究文本到图像模型内部对艺术内容和风格的理解，这对于理解黑箱模型的工作机制具有重要意义。它揭示了模型在没有明确指导的情况下，也能自发地学习并区分内容和风格，为未来更精细的艺术生成和模型可解释性研究奠定了基础。"}}
{"id": "2404.17484", "title": "Sparse Reconstruction of Optical Doppler Tomography with Alternative State Space Model and Attention", "authors": ["Zhenghong Li", "Jiaxiang Ren", "Wensheng Cheng", "Yanzuo Liu", "Congwu Du", "Yingtian Pan", "Haibin Ling"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI25, 10 pages, 3 figures", "url": "http://arxiv.org/abs/2404.17484v3", "summary": "Optical coherence Doppler tomography (ODT) is an emerging blood flow imaging\ntechnique. The fundamental unit of ODT is the 1D depth-resolved trace named raw\nA-scans (or A-line). A 2D ODT image (B-scan) is formed by reconstructing a\ncross-sectional flow image via Doppler phase-subtraction of raw A-scans along\nB-line. To obtain a high-fidelity B-scan, densely sampled A-scans are required\ncurrently, leading to prolonged scanning time and increased storage demands.\nAddressing this issue, we propose a novel sparse ODT reconstruction framework\nwith an Alternative State Space Attention Network (ASSAN) that effectively\nreduces raw A-scans needed. Inspired by the distinct distributions of\ninformation along A-line and B-line, ASSAN applies 1D State Space Model (SSM)\nto each A-line to learn the intra-A-scan representation, while using 1D gated\nself-attention along B-line to capture the inter-A-scan features. In addition,\nan effective feedforward network based on sequential 1D convolutions along\ndifferent axes is employed to enhance the local feature. In validation\nexperiments on real animal data, ASSAN shows clear effectiveness in the\nreconstruction in comparison with state-of-the-art reconstruction methods.", "comment": "MICCAI25, 10 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2404.17484v3", "cate": "cs.CV", "date": "2024-04-26", "updated": "2025-07-30", "AI": {"title_translation": "基于替代状态空间模型和注意力的光学多普勒断层扫描稀疏重建", "tldr": "本文提出了一种名为ASSAN的新型稀疏光学多普勒断层扫描（ODT）重建框架，通过减少所需的原始A扫描数量，有效缩短扫描时间并降低存储需求。", "motivation": "目前的光学多普勒断层扫描（ODT）需要密集的A扫描来获得高保真B扫描图像，这导致扫描时间过长和存储需求增加。", "method": "本文提出了一种名为替代状态空间注意力网络（ASSAN）的新型稀疏ODT重建框架。ASSAN利用A线和B线信息分布的差异，对每条A线应用一维状态空间模型（SSM）来学习A扫描内部表示，同时沿B线使用一维门控自注意力来捕获A扫描间特征。此外，还采用了一种基于沿不同轴的顺序一维卷积的有效前馈网络来增强局部特征。", "result": "在真实动物数据上的验证实验表明，与最先进的重建方法相比，ASSAN在重建方面显示出明显的有效性。", "conclusion": "ASSAN能够有效实现光学多普勒断层扫描的稀疏重建，显著减少了所需的原始A扫描数量，同时保持了重建质量。", "translation": "光学相干多普勒断层扫描（ODT）是一种新兴的血流成像技术。ODT的基本单位是名为原始A扫描（或A线）的一维深度分辨轨迹。二维ODT图像（B扫描）是通过沿B线对原始A扫描进行多普勒相位减法重建横截面血流图像而形成的。为了获得高保真B扫描，目前需要密集采样的A扫描，这导致扫描时间延长和存储需求增加。为了解决这个问题，我们提出了一种新型的稀疏ODT重建框架，该框架采用替代状态空间注意力网络（ASSAN），有效减少了所需的原始A扫描数量。受A线和B线信息分布差异的启发，ASSAN对每条A线应用一维状态空间模型（SSM）以学习A扫描内部表示，同时沿B线使用一维门控自注意力来捕获A扫描间特征。此外，还采用了一种基于沿不同轴的顺序一维卷积的有效前馈网络来增强局部特征。在真实动物数据上的验证实验中，与最先进的重建方法相比，ASSAN在重建方面显示出明显的有效性。", "summary": "本文提出了一种名为替代状态空间注意力网络（ASSAN）的新型框架，用于光学多普勒断层扫描（ODT）的稀疏重建。针对ODT需要密集A扫描导致扫描时间长和存储需求大的问题，ASSAN利用一维状态空间模型处理A扫描内部特征，并使用一维门控自注意力捕捉A扫描间特征，同时结合卷积网络增强局部特征。实验结果表明，ASSAN在减少原始A扫描数量的同时，实现了有效的ODT图像重建，性能优于现有方法。", "keywords": "光学多普勒断层扫描, 稀疏重建, 状态空间模型, 注意力机制, 深度学习", "comments": "ASSAN的创新点在于结合了状态空间模型和注意力机制来处理ODT数据的不同维度特征，有效解决了稀疏采样下的重建挑战。这对于提高ODT的实用性和应用范围具有重要意义。"}}
{"id": "2507.23785", "title": "Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis", "authors": ["Bowen Zhang", "Sicheng Xu", "Chuxin Wang", "Jiaolong Yang", "Feng Zhao", "Dong Chen", "Baining Guo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2507.23785v1", "summary": "In this paper, we present a novel framework for video-to-4D generation that\ncreates high-quality dynamic 3D content from single video inputs. Direct 4D\ndiffusion modeling is extremely challenging due to costly data construction and\nthe high-dimensional nature of jointly representing 3D shape, appearance, and\nmotion. We address these challenges by introducing a Direct 4DMesh-to-GS\nVariation Field VAE that directly encodes canonical Gaussian Splats (GS) and\ntheir temporal variations from 3D animation data without per-instance fitting,\nand compresses high-dimensional animations into a compact latent space.\nBuilding upon this efficient representation, we train a Gaussian Variation\nField diffusion model with temporal-aware Diffusion Transformer conditioned on\ninput videos and canonical GS. Trained on carefully-curated animatable 3D\nobjects from the Objaverse dataset, our model demonstrates superior generation\nquality compared to existing methods. It also exhibits remarkable\ngeneralization to in-the-wild video inputs despite being trained exclusively on\nsynthetic data, paving the way for generating high-quality animated 3D content.\nProject page: https://gvfdiffusion.github.io/.", "comment": "ICCV 2025. Project page: https://gvfdiffusion.github.io/", "pdf_url": "http://arxiv.org/pdf/2507.23785v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "高保真视频到4D合成的高斯变异场扩散", "tldr": "提出了一种新颖的视频到4D生成框架，通过高斯变异场扩散模型，能从单个视频输入生成高质量的动态3D内容，并展示了优越的生成质量和泛化能力。", "motivation": "直接进行4D扩散建模极具挑战性，因为数据构建成本高昂，且联合表示3D形状、外观和运动具有高维度特性。", "method": "该方法引入了一个直接4DMesh到GS变异场VAE，用于直接编码规范高斯泼溅(GS)及其时间变化，并将高维动画压缩到紧凑的潜在空间。在此高效表示的基础上，训练了一个高斯变异场扩散模型，该模型带有时间感知扩散变换器，并以输入视频和规范GS为条件。", "result": "与现有方法相比，该模型展示了卓越的生成质量。尽管仅在合成数据上训练，它对野外视频输入也表现出显著的泛化能力。", "conclusion": "该工作为生成高质量的动画3D内容铺平了道路。", "translation": "在本文中，我们提出了一种新颖的视频到4D生成框架，该框架能从单个视频输入创建高质量的动态3D内容。由于数据构建成本高昂以及联合表示3D形状、外观和运动所固有的高维度特性，直接进行4D扩散建模极具挑战性。我们通过引入一个直接4DMesh到GS变异场VAE来解决这些挑战，该VAE无需逐实例拟合即可直接从3D动画数据编码规范高斯泼溅（GS）及其时间变化，并将高维动画压缩到紧凑的潜在空间。在此高效表示的基础上，我们训练了一个高斯变异场扩散模型，该模型带有时间感知扩散变换器，并以输入视频和规范GS为条件。我们的模型在精心策划的Objaverse数据集中可动画3D对象上进行训练，与现有方法相比展示了卓越的生成质量。尽管仅在合成数据上训练，它对野外视频输入也表现出显著的泛化能力，为生成高质量的动画3D内容铺平了道路。项目页面：https://gvfdiffusion.github.io/。", "summary": "本文提出了一种新颖的视频到4D生成框架，旨在解决直接4D扩散建模面临的数据成本高和高维度挑战。通过引入一个直接4DMesh到GS变异场VAE来高效编码高斯泼溅及其时间变化，并将高维动画压缩到紧凑的潜在空间。在此基础上，训练了一个高斯变异场扩散模型，该模型结合了时间感知扩散变换器。实验结果表明，该模型在生成质量上优于现有方法，并对野外视频输入展现出强大的泛化能力，为高质量动画3D内容的生成奠定了基础。", "keywords": "视频到4D合成, 高斯泼溅, 扩散模型, 动态3D内容, 变异场", "comments": "该论文的创新点在于提出了一个独特的高斯变异场扩散框架，有效地解决了视频到4D合成中高维度数据表示和处理的难题。通过结合4DMesh到GS变异场VAE和时间感知扩散变换器，实现了对动态3D内容的紧凑表示和高质量生成。其在合成数据上训练却能泛化到野外视频的能力尤为突出，预示着该方法在实际应用中具有巨大潜力。"}}
{"id": "2507.23445", "title": "Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility", "authors": ["Yuta Kawachi"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23445v1", "summary": "Simulation-to-real transfer using domain randomization for robot control\noften relies on low-gear-ratio, backdrivable actuators, but these approaches\nbreak down when the sim-to-real gap widens. Inspired by the traditional PID\ncontroller, we reinterpret its gains as surrogates for complex, unmodeled plant\ndynamics. We then introduce a physics-guided gain regularization scheme that\nmeasures a robot's effective proportional gains via simple real-world\nexperiments. Then, we penalize any deviation of a neural controller's local\ninput-output sensitivities from these values during training. To avoid the\noverly conservative bias of naive domain randomization, we also condition the\ncontroller on the current plant parameters. On an off-the-shelf two-wheeled\nbalancing robot with a 110:1 gearbox, our gain-regularized,\nparameter-conditioned RNN achieves angular settling times in hardware that\nclosely match simulation. At the same time, a purely domain-randomized policy\nexhibits persistent oscillations and a substantial sim-to-real gap. These\nresults demonstrate a lightweight, reproducible framework for closing\nsim-to-real gaps on affordable robotic hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23445v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "量化和可视化虚实差距：基于物理引导的正则化以提高可复现性", "tldr": "该研究提出了一种物理引导的增益正则化方案，用于在机器人控制中缩小虚实差距，尤其适用于经济型机器人硬件，通过将PID增益重新解释为未建模动力学的替代，并惩罚神经网络控制器与实际测量的比例增益之间的偏差，同时对控制器进行当前系统参数的条件化处理，从而在硬件上实现了与仿真匹配的角稳定时间。", "motivation": "现有的使用域随机化进行机器人控制的虚实迁移方法，在虚实差距扩大时会失效。特别是在具有高减速比执行器的机器人上，这种差距更加明显。本研究旨在解决在经济型机器人硬件上缩小虚实差距的挑战，并提高虚实迁移的可复现性。", "method": "作者受传统PID控制器启发，将其增益重新解释为复杂、未建模系统动力学的替代。然后，引入了一种物理引导的增益正则化方案，通过简单的真实世界实验测量机器人的有效比例增益。在训练过程中，该方案惩罚神经网络控制器局部输入-输出敏感性与这些测量值之间的任何偏差。为了避免朴素域随机化的过度保守偏差，控制器还以当前系统参数为条件。", "result": "在配备110:1齿轮箱的现成两轮平衡机器人上，作者提出的增益正则化、参数条件化RNN实现了与仿真结果非常接近的硬件角稳定时间。相比之下，纯粹的域随机化策略表现出持续的振荡和显著的虚实差距。", "conclusion": "本研究展示了一个轻量级、可复现的框架，用于在经济型机器人硬件上缩小虚实差距。通过物理引导的增益正则化和参数条件化，可以有效提高模拟到现实迁移的性能和稳定性。", "translation": "使用域随机化进行机器人控制的虚实迁移通常依赖于低齿轮比、可反向驱动的执行器，但当虚实差距扩大时，这些方法就会失效。受传统PID控制器的启发，我们将其增益重新解释为复杂、未建模的系统动力学的替代。然后，我们引入了一种物理引导的增益正则化方案，通过简单的真实世界实验测量机器人的有效比例增益。接着，在训练过程中，我们惩罚神经网络控制器局部输入-输出敏感性与这些值之间的任何偏差。为了避免朴素域随机化的过度保守偏差，我们还将控制器以当前系统参数为条件。在一台配备110:1齿轮箱的现成两轮平衡机器人上，我们经过增益正则化、参数条件化的RNN在硬件上实现了与仿真结果非常接近的角稳定时间。同时，纯粹的域随机化策略表现出持续的振荡和显著的虚实差距。这些结果表明，这是一个轻量级、可复现的框架，用于在经济型机器人硬件上缩小虚实差距。", "summary": "本论文提出了一种名为“物理引导的增益正则化”的新方法，旨在解决机器人控制中模拟到现实（sim-to-real）迁移的难题，尤其是在虚实差距较大或使用经济型硬件时。该方法将PID控制器的增益重新诠释为未建模动力学的替代，并通过简单的真实世界实验测量机器人的实际比例增益。在训练神经网络控制器时，它会惩罚控制器输入-输出敏感性与这些实际测量值之间的偏差。此外，控制器还根据当前系统参数进行条件化处理，以避免域随机化的局限性。实验结果表明，该方法在具有高齿轮比的平衡机器人上取得了显著成功，实现了与仿真高度匹配的硬件性能，优于纯粹的域随机化策略，为经济型机器人硬件上的虚实迁移提供了一个轻量级且可复现的解决方案。", "keywords": "虚实迁移, 机器人控制, 物理引导正则化, 域随机化, PID控制器", "comments": "该论文的创新点在于将传统PID控制器的增益重新诠释为未建模动力学的替代，并将其作为物理引导的正则化项引入到神经网络控制器的训练中，有效缩小了虚实差距。这种方法提供了一种量化和可视化虚实差距的新视角，并通过对控制器进行当前系统参数的条件化处理，进一步提高了鲁棒性。其重要性在于为经济型机器人硬件上的模拟到现实迁移提供了一个实用且可复现的框架，这对于机器人技术的普及和应用具有重要意义。"}}
{"id": "2301.02410", "title": "CodePod: A Language-Agnostic Hierarchical Scoping System for Interactive Development", "authors": ["Hebi Li", "Forrest Sheng Bao", "Qi Xiao", "Jin Tian"], "categories": ["cs.SE", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2301.02410v2", "summary": "Interactive development environments like Jupyter Notebooks enable\nincremental coding through cells with immediate feedback, but their linear\nstructure and global namespace limit scalability for large software projects.\nWe present CodePod, a hierarchical extension of Jupyter that introduces a novel\nscoped execution model with formal semantics. Our key contribution is a\nlanguage-agnostic runtime system that performs source-level transformations to\nimplement hierarchical scoping rules, enabling true incremental evaluation\nacross nested modules without requiring language-specific kernel modifications.\nWe formalize the scoping semantics as a mathematical framework with precise\nvisibility relations and prove key properties including uniqueness of symbol\nresolution and correctness of the resolution algorithm. A qualitative user\nstudy with seven senior developers demonstrates that CodePod enables\nsignificant improvements in project scalability compared to Jupyter, with\nnotable reductions in navigation effort. We validate the system's effectiveness\non large-scale projects with thousands of lines of code, demonstrating its\napplicability beyond traditional notebook boundaries. Our tool is open-source\nand available at https://codepod.io", "comment": null, "pdf_url": "http://arxiv.org/pdf/2301.02410v2", "cate": "cs.SE", "date": "2023-01-06", "updated": "2025-07-31", "AI": {"title_translation": "CodePod：一个用于交互式开发的语言无关分层作用域系统", "tldr": "CodePod 是 Jupyter 的一个分层扩展，引入了新的作用域执行模型，通过源级转换实现分层作用域规则，解决了传统交互式开发环境在大型项目中的可伸缩性限制。", "motivation": "Jupyter Notebook 等交互式开发环境的线性结构和全局命名空间限制了其在大型软件项目中的可伸缩性。", "method": "CodePod 引入了一个新颖的带有形式语义的作用域执行模型，通过执行源级转换来实现分层作用域规则，从而在不修改语言特定内核的情况下实现嵌套模块间的真正增量评估。作者还将其作用域语义形式化为一个数学框架，并证明了符号解析的唯一性和算法的正确性。", "result": "一项针对七位资深开发人员的定性用户研究表明，与 Jupyter 相比，CodePod 显著提高了项目可伸缩性，并显著减少了导航工作。该系统在包含数千行代码的大型项目上得到了验证，证明了其超越传统笔记本边界的适用性。", "conclusion": "CodePod 通过引入语言无关的分层作用域系统，有效解决了传统交互式开发环境在大型项目中的可伸缩性问题，并提升了开发效率。", "translation": "交互式开发环境，如 Jupyter Notebooks，通过单元格实现增量编码并提供即时反馈，但其线性结构和全局命名空间限制了大型软件项目的可伸缩性。我们提出了 CodePod，它是 Jupyter 的一个分层扩展，引入了一种新颖的具有形式语义的作用域执行模型。我们的主要贡献是一个语言无关的运行时系统，它执行源级转换以实现分层作用域规则，从而在不要求语言特定内核修改的情况下，在嵌套模块中实现真正的增量评估。我们将作用域语义形式化为一个具有精确可见性关系的数学框架，并证明了包括符号解析唯一性和解析算法正确性在内的关键属性。一项针对七位资深开发人员的定性用户研究表明，与 Jupyter 相比，CodePod 显著提高了项目可伸缩性，并显著减少了导航工作。我们在包含数千行代码的大型项目上验证了该系统的有效性，证明了其超越传统笔记本边界的适用性。我们的工具是开源的，可在 https://codepod.io 获取。", "summary": "CodePod 是 Jupyter 的一个分层扩展，旨在解决传统交互式开发环境在大型项目中的可伸缩性问题。它引入了一个语言无关的分层作用域系统和新颖的作用域执行模型，通过源级转换实现增量评估，无需修改语言特定内核。研究通过形式化语义和用户研究验证了其在提高项目可伸缩性和减少导航工作方面的有效性。", "keywords": "分层作用域, 交互式开发, Jupyter, 语言无关, 可伸缩性", "comments": "CodePod 的创新之处在于提出了一个语言无关的分层作用域系统，通过源级转换解决了交互式开发环境在大型项目中的可伸缩性痛点。其形式化语义的引入增加了理论严谨性，而用户研究和大型项目验证则证明了其实用价值。该系统有望显著提升复杂软件项目在交互式环境中的开发效率和可维护性。"}}
{"id": "2507.23399", "title": "Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators", "authors": ["Peter Sandrini"], "categories": ["cs.CL", "cs.CY", "I.2.7; K.4.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23399v1", "summary": "The rapid proliferation of Large Language Models presents both opportunities\nand challenges for the translation field. While commercial, cloud-based AI\nchatbots have garnered significant attention in translation studies, concerns\nregarding data privacy, security, and equitable access necessitate exploration\nof alternative deployment models. This paper investigates the feasibility and\nperformance of locally deployable, free language models as a viable alternative\nto proprietary, cloud-based AI solutions. This study evaluates three\nopen-source models installed on CPU-based platforms and compared against\ncommercially available online chat-bots. The evaluation focuses on functional\nperformance rather than a comparative analysis of human-machine translation\nquality, an area already subject to extensive research. The platforms assessed\nwere chosen for their accessibility and ease of use across various operating\nsystems. While local deployment introduces its own challenges, the benefits of\nenhanced data control, improved privacy, and reduced dependency on cloud\nservices are compelling. The findings of this study contribute to a growing\nbody of knowledge concerning the democratization of AI technology and inform\nfuture research and development efforts aimed at making LLMs more accessible\nand practical for a wider range of users, specifically focusing on the needs of\nindividual translators and small businesses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23399v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "超越云端：评估本地部署大型语言模型对译员的利弊", "tldr": "本研究探讨了为解决数据隐私、安全和公平访问问题，本地部署免费大型语言模型作为商业云端AI替代方案的可行性。研究评估了基于CPU平台的开源模型，并发现本地部署在数据控制、隐私和减少云依赖方面具有优势，有助于AI的普及。", "motivation": "商业云端大型语言模型在翻译领域引起了数据隐私、安全和公平访问方面的担忧，因此有必要探索替代的部署模型。", "method": "本研究评估了在基于CPU的平台上安装的三种开源语言模型，并将其与市售的在线聊天机器人进行比较。评估侧重于功能性能，而非人机翻译质量的比较分析。", "result": "尽管本地部署带来了自身的挑战，但增强数据控制、改善隐私和减少对云服务的依赖等优势是引人注目的。", "conclusion": "本研究的发现有助于深化对人工智能技术民主化的认识，并为未来的研究和开发工作提供信息，旨在使大型语言模型对更广泛的用户（特别是个人译员和小型企业）更易于使用和实用。", "translation": "大型语言模型的迅速普及为翻译领域带来了机遇和挑战。尽管商业云端人工智能聊天机器人在翻译研究中受到了广泛关注，但对数据隐私、安全和公平访问的担忧促使人们探索替代的部署模型。本文研究了本地部署的免费语言模型作为专有云端人工智能解决方案的可行性和性能。本研究评估了安装在基于CPU平台上的三种开源模型，并将其与市售的在线聊天机器人进行比较。评估侧重于功能性能，而非人机翻译质量的比较分析，后者已是广泛研究的领域。所评估的平台因其在各种操作系统上的可访问性和易用性而被选中。虽然本地部署带来了自身的挑战，但增强数据控制、改善隐私和减少对云服务的依赖等优势是引人注目的。本研究的发现有助于深化对人工智能技术民主化的认识，并为未来的研究和开发工作提供信息，旨在使大型语言模型对更广泛的用户更易于使用和实用，特别是针对个人译员和小型企业的需求。", "summary": "本研究旨在评估本地部署免费大型语言模型作为商业云端AI替代方案的可行性与性能，以解决数据隐私、安全和公平访问等担忧。研究在CPU平台上评估了三种开源模型，并与在线商业聊天机器人进行比较，重点关注功能性能。结果显示，尽管存在挑战，本地部署在数据控制、隐私和减少云依赖方面具有显著优势。这项工作有助于推动AI民主化，并为使LLM更易于个人译员和小型企业使用提供指导。", "keywords": "本地部署, 大型语言模型, 数据隐私, 翻译, 开源模型", "comments": "该论文创新性地关注了大型语言模型在翻译领域本地部署的潜力，特别是在数据隐私和访问公平性方面的考量，这与当前主流的云端部署模式形成对比。其重要性在于为个人译员和小型企业提供了可行的替代方案，有助于AI技术的民主化。研究方法侧重于功能性能而非翻译质量，这使得其贡献更加独特，但也可能限制了对实际翻译产出效果的直接评估。"}}
{"id": "2507.07526", "title": "DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel Spectrogram Reconstruction", "authors": ["Cunhang Fan", "Sheng Zhang", "Jingjing Zhang", "Enrui Liu", "Xinhui Li", "Minggang Zhao", "Zhao Lv"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.07526v2", "summary": "Decoding speech from brain signals is a challenging research problem.\nAlthough existing technologies have made progress in reconstructing the mel\nspectrograms of auditory stimuli at the word or letter level, there remain core\nchallenges in the precise reconstruction of minute-level continuous imagined\nspeech: traditional models struggle to balance the efficiency of temporal\ndependency modeling and information retention in long-sequence decoding. To\naddress this issue, this paper proposes the Dynamic Multiscale Fusion Network\n(DMF2Mel), which consists of four core components: the Dynamic Contrastive\nFeature Aggregation Module (DC-FAM), the Hierarchical Attention-Guided\nMulti-Scale Network (HAMS-Net), the SplineMap attention mechanism, and the\nbidirectional state space module (convMamba). Specifically, the DC-FAM\nseparates speech-related \"foreground features\" from noisy \"background features\"\nthrough local convolution and global attention mechanisms, effectively\nsuppressing interference and enhancing the representation of transient signals.\nHAMS-Net, based on the U-Net framework,achieves cross-scale fusion of\nhigh-level semantics and low-level details. The SplineMap attention mechanism\nintegrates the Adaptive Gated Kolmogorov-Arnold Network (AGKAN) to combine\nglobal context modeling with spline-based local fitting. The convMamba captures\nlong-range temporal dependencies with linear complexity and enhances nonlinear\ndynamic modeling capabilities. Results on the SparrKULee dataset show that\nDMF2Mel achieves a Pearson correlation coefficient of 0.074 in mel spectrogram\nreconstruction for known subjects (a 48% improvement over the baseline) and\n0.048 for unknown subjects (a 35% improvement over the baseline).Code is\navailable at: https://github.com/fchest/DMF2Mel.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.07526v2", "cate": "cs.SD", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "DMF2Mel：一种用于EEG驱动梅尔频谱重建的动态多尺度融合网络", "tldr": "本文提出DMF2Mel网络，通过动态多尺度融合解决脑电图驱动的梅尔频谱重建中长序列解码和信息保留的挑战，并在已知和未知受试者上显著提高了性能。", "motivation": "现有技术在词或字母级别梅尔频谱重建方面取得进展，但在精确重建分钟级连续想象语音方面仍面临核心挑战，传统模型难以平衡时间依赖性建模效率和长序列解码中的信息保留。", "method": "提出动态多尺度融合网络（DMF2Mel），包含四个核心组件：动态对比特征聚合模块（DC-FAM）分离前景和背景特征；分层注意力引导多尺度网络（HAMS-Net）实现跨尺度融合；SplineMap注意力机制结合全局上下文建模和局部拟合；双向状态空间模块（convMamba）捕获长距离时间依赖性。", "result": "在SparrKULee数据集上，DMF2Mel在已知受试者梅尔频谱重建中达到0.074的皮尔逊相关系数（比基线提高48%），在未知受试者中达到0.048（比基线提高35%）。", "conclusion": "DMF2Mel通过其创新的多组件架构，有效解决了脑电图驱动的梅尔频谱重建中长序列解码和信息保留的挑战，显著提升了重建精度。", "translation": "从脑信号中解码语音是一个具有挑战性的研究问题。尽管现有技术在词或字母级别的听觉刺激梅尔频谱重建方面取得了进展，但在精确重建分钟级连续想象语音方面仍存在核心挑战：传统模型难以平衡时间依赖性建模效率和长序列解码中的信息保留。为了解决这个问题，本文提出了动态多尺度融合网络（DMF2Mel），它由四个核心组件组成：动态对比特征聚合模块（DC-FAM）、分层注意力引导多尺度网络（HAMS-Net）、SplineMap注意力机制和双向状态空间模块（convMamba）。具体来说，DC-FAM通过局部卷积和全局注意力机制将语音相关的“前景特征”与嘈杂的“背景特征”分离，有效抑制干扰并增强瞬态信号的表示。HAMS-Net基于U-Net框架，实现了高级语义和低级细节的跨尺度融合。SplineMap注意力机制集成了自适应门控Kolmogorov-Arnold网络（AGKAN），将全局上下文建模与基于样条的局部拟合相结合。convMamba以线性复杂度捕获长距离时间依赖性，并增强非线性动态建模能力。SparrKULee数据集上的结果表明，DMF2Mel在已知受试者的梅尔频谱重建中实现了0.074的皮尔逊相关系数（比基线提高了48%），在未知受试者中实现了0.048（比基线提高了35%）。代码可在以下网址获取：https://github.com/fchest/DMF2Mel。", "summary": "本文提出了一种名为DMF2Mel的动态多尺度融合网络，旨在解决从脑电信号精确重建分钟级连续想象语音的挑战。该网络通过整合动态对比特征聚合、分层注意力引导多尺度处理、SplineMap注意力机制和双向状态空间模块，有效平衡了时间依赖性建模和信息保留。在SparrKULee数据集上的实验结果表明，DMF2Mel在梅尔频谱重建方面显著优于基线模型，为脑电图驱动的语音解码提供了新的解决方案。", "keywords": "脑电图, 梅尔频谱重建, 动态多尺度融合, 想象语音, 长序列解码", "comments": "该论文提出了一种新颖的神经网络架构DMF2Mel，通过其模块化的设计（DC-FAM、HAMS-Net、SplineMap、convMamba）有效地解决了脑电信号中噪声抑制、多尺度特征融合以及长序列时间依赖性建模的挑战。其创新性在于结合了多种先进技术来优化梅尔频谱重建的精度，尤其是在连续想象语音解码方面。实验结果显示出显著的性能提升，表明该模型在脑机接口和语音解码领域具有重要潜力。"}}
{"id": "2404.12829", "title": "LiMe: a Latin Corpus of Late Medieval Criminal Sentences", "authors": ["Alessandra Bassani", "Beatrice Del Bo", "Alfio Ferrara", "Marta Mangini", "Sergio Picascia", "Ambra Stefanello"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.12829v2", "summary": "The Latin language has received attention from the computational linguistics\nresearch community, which has built, over the years, several valuable\nresources, ranging from detailed annotated corpora to sophisticated tools for\nlinguistic analysis. With the recent advent of large language models,\nresearchers have also started developing models capable of generating vector\nrepresentations of Latin texts. The performances of such models remain behind\nthe ones for modern languages, given the disparity in available data. In this\npaper, we present the LiMe dataset, a corpus of 325 documents extracted from a\nseries of medieval manuscripts called Libri sententiarum potestatis Mediolani,\nand thoroughly annotated by experts, in order to be employed for masked\nlanguage model, as well as supervised natural language processing tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.12829v2", "cate": "cs.CL", "date": "2024-04-19", "updated": "2025-07-31", "AI": {"title_translation": "LiMe：晚期中世纪拉丁语刑事判决语料库", "tldr": "本文介绍了LiMe数据集，一个包含325份文档的拉丁语语料库，用于掩码语言模型和监督式自然语言处理任务，以解决拉丁语计算语言学数据稀缺的问题。", "motivation": "尽管计算语言学界已为拉丁语构建了一些资源，但与现代语言相比，拉丁语大型语言模型和自然语言处理任务的性能因可用数据的差异而落后。因此，需要更多高质量的拉丁语数据来提升模型表现。", "method": "本文介绍了LiMe数据集，这是一个包含325份文档的语料库。这些文档提取自一系列名为《Libri sententiarum potestatis Mediolani》的中世纪手稿，并经过专家彻底标注，旨在用于掩码语言模型和监督式自然语言处理任务。", "result": "本文的主要成果是创建了LiMe数据集，一个包含325份经过专家彻底标注的晚期中世纪拉丁语刑事判决文档的语料库，可用于计算语言学研究。", "conclusion": "本文介绍了LiMe数据集，一个专门针对晚期中世纪拉丁语刑事判决的语料库，旨在为拉丁语计算语言学研究提供更多高质量的数据资源，以支持掩码语言模型和监督式自然语言处理任务的开发。", "translation": "拉丁语受到了计算语言学研究界的关注，多年来，该领域已构建了多项宝贵资源，从详细标注语料库到复杂的语言分析工具。随着大型语言模型的最新出现，研究人员也开始开发能够生成拉丁语文本向量表示的模型。鉴于可用数据的差异，此类模型的性能仍落后于现代语言。在本文中，我们介绍了LiMe数据集，这是一个包含325份文档的语料库，这些文档提取自一系列名为《Libri sententiarum potestatis Mediolani》的中世纪手稿，并经过专家彻底标注，以便用于掩码语言模型以及监督式自然语言处理任务。", "summary": "本文介绍了LiMe数据集，这是一个专门针对晚期中世纪拉丁语刑事判决的语料库。该语料库包含325份文档，这些文档源自中世纪手稿并由专家进行了详细标注。LiMe数据集旨在弥补拉丁语计算语言学领域数据稀缺的现状，并可用于训练掩码语言模型以及执行各种监督式自然语言处理任务，从而推动拉丁语文本分析和理解技术的发展。", "keywords": "拉丁语语料库, 中世纪刑事判决, NLP, 数据集, 掩码语言模型", "comments": "该论文的创新之处在于构建了一个高度专业化且经过专家标注的拉丁语语料库，特别是针对晚期中世纪的刑事判决文本。这对于解决拉丁语计算语言学领域数据稀缺的长期问题至关重要，尤其是在大型语言模型时代，高质量的特定领域数据尤为宝贵。其重要性在于为未来拉丁语NLP模型（包括掩码语言模型和监督式任务）的开发提供了坚实的基础，有助于提升拉丁语处理的准确性和性能。"}}
{"id": "2507.23528", "title": "Hybrid Generative Semantic and Bit Communications in Satellite Networks: Trade-offs in Latency, Generation Quality, and Computation", "authors": ["Chong Huang", "Gaojie Chen", "Jing Zhu", "Qu Luo", "Pei Xiao", "Wei Huang", "Rahim Tafazolli"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, accepted for pulication in IEEE Globecom 2025", "url": "http://arxiv.org/abs/2507.23528v1", "summary": "As satellite communications play an increasingly important role in future\nwireless networks, the issue of limited link budget in satellite systems has\nattracted significant attention in current research. Although semantic\ncommunications emerge as a promising solution to address these constraints, it\nintroduces the challenge of increased computational resource consumption in\nwireless communications. To address these challenges, we propose a multi-layer\nhybrid bit and generative semantic communication framework which can adapt to\nthe dynamic satellite communication networks. Furthermore, to balance the\nsemantic communication efficiency and performance in satellite-to-ground\ntransmissions, we introduce a novel semantic communication efficiency metric\n(SEM) that evaluates the trade-offs among latency, computational consumption,\nand semantic reconstruction quality in the proposed framework. Moreover, we\nutilize a novel deep reinforcement learning (DRL) algorithm group relative\npolicy optimization (GRPO) to optimize the resource allocation in the proposed\nnetwork. Simulation results demonstrate the flexibility of our proposed\ntransmission framework and the effectiveness of the proposed metric SEM,\nillustrate the relationships among various semantic communication metrics.", "comment": "6 pages, accepted for pulication in IEEE Globecom 2025", "pdf_url": "http://arxiv.org/pdf/2507.23528v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "卫星网络中混合生成式语义与比特通信：延迟、生成质量和计算的权衡", "tldr": "本文提出了一种多层混合比特和生成式语义通信框架，以解决卫星网络中链路预算受限和语义通信计算消耗大的问题，并引入了新的效率指标和深度强化学习算法进行优化。", "motivation": "未来的无线网络中卫星通信日益重要，但卫星系统面临链路预算受限的问题。尽管语义通信有望解决这些限制，但它也带来了无线通信中计算资源消耗增加的挑战。", "method": "本文提出了一种多层混合比特和生成式语义通信框架，以适应动态卫星通信网络。为平衡卫星到地面传输中的语义通信效率和性能，引入了一种新颖的语义通信效率指标（SEM），用于评估所提出框架中延迟、计算消耗和语义重建质量之间的权衡。此外，利用一种新颖的深度强化学习（DRL）算法——群组相对策略优化（GRPO）来优化所提出网络中的资源分配。", "result": "仿真结果表明了所提出传输框架的灵活性和所提出指标SEM的有效性，并阐明了各种语义通信指标之间的关系。", "conclusion": "本文提出的混合比特和生成式语义通信框架及其效率指标和优化算法，有效解决了卫星网络中链路预算和计算资源消耗的挑战，并平衡了语义通信的效率和性能。", "translation": "随着卫星通信在未来无线网络中扮演着越来越重要的角色，卫星系统中有限链路预算的问题在当前研究中受到了广泛关注。尽管语义通信作为解决这些限制的一种有前景的方案而出现，但它也带来了无线通信中计算资源消耗增加的挑战。为了应对这些挑战，我们提出了一种多层混合比特和生成式语义通信框架，该框架可以适应动态卫星通信网络。此外，为了平衡卫星到地面传输中的语义通信效率和性能，我们引入了一种新颖的语义通信效率指标（SEM），用于评估所提出框架中延迟、计算消耗和语义重建质量之间的权衡。此外，我们利用一种新颖的深度强化学习（DRL）算法——群组相对策略优化（GRPO）来优化所提出网络中的资源分配。仿真结果证明了我们提出的传输框架的灵活性和所提出指标SEM的有效性，并阐明了各种语义通信指标之间的关系。", "summary": "本文针对卫星网络中有限链路预算和语义通信计算资源消耗大的问题，提出了一种多层混合比特与生成式语义通信框架。为优化效率与性能，引入了语义通信效率指标（SEM）以权衡延迟、计算消耗和语义重建质量，并采用深度强化学习算法GRPO进行资源分配优化。仿真结果验证了该框架的灵活性和SEM的有效性，并揭示了语义通信指标间的关系。", "keywords": "卫星通信, 语义通信, 混合通信, 深度强化学习, 资源分配", "comments": "该论文创新性地结合了比特通信和生成式语义通信，并针对卫星网络特点提出了混合框架。引入语义通信效率指标（SEM）和利用深度强化学习（GRPO）优化资源分配是其亮点，这有助于平衡通信性能与计算开销，对未来受限资源环境下的通信系统具有重要意义。"}}
{"id": "2507.23035", "title": "KLLM: Fast LLM Inference with K-Means Quantization", "authors": ["Xueying Wu", "Baijun Zhou", "Zhihui Gao", "Yuzhe Fu", "Qilin Zheng", "Yintao He", "Hai Li"], "categories": ["cs.LG", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23035v1", "summary": "Large language model (LLM) inference poses significant challenges due to its\nintensive memory and computation demands. Weight and activation quantization\n(WAQ) offers a promising solution by reducing both memory footprint and\narithmetic complexity. However, two key challenges remain in the existing WAQ\ndesigns. (1) Traditional WAQ designs rely on uniform integer-based quantization\nfor hardware efficiency, but this often results in significant accuracy\ndegradation at low precision. K-Means-based quantization, a non-uniform\nquantization technique, achieves higher accuracy by matching the Gaussian-like\ndistributions of weights and activations in LLMs. However, its non-uniform\nnature prevents direct execution on low-precision compute units, requiring\ndequantization and floating-point matrix multiplications (MatMuls) during\ninference. (2) Activation outliers further hinder effective low-precision WAQ.\nOffline thresholding methods for outlier detection can lead to significant\nmodel performance degradation, while existing online detection techniques\nintroduce substantial runtime overhead.\n  To address the aforementioned challenges and fully unleash the potential of\nWAQ with K-Means quantization for LLM inference, in this paper, we propose\nKLLM, a hardware-software co-design framework. KLLM features an index-based\ncomputation scheme for efficient execution of MatMuls and nonlinear operations\non K-Means-quantized data, which avoids most of the dequantization and\nfull-precision computations. Moreover, KLLM incorporates a novel outlier\ndetection engine, Orizuru, that efficiently identifies the top-$k$ largest and\nsmallest elements in the activation data stream during online inference.\n  Extensive experiments show that, on average, KLLM achieves speedups of 9.67x,\n7.03x and energy efficiency improvements of 229.50x, 150.21x compared to the\nA100 GPU and Atom, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23035v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "KLLM：基于K-Means量化的快速LLM推理", "tldr": "KLLM是一个软硬件协同设计框架，通过索引计算和高效的离群值检测，实现了基于K-Means量化的快速且节能的LLM推理，显著提升了速度和能效。", "motivation": "大语言模型（LLM）推理面临内存和计算密集型挑战。尽管权重和激活量化（WAQ）能减少内存占用和计算复杂性，但现有WAQ设计存在两个关键问题：1) 传统均匀量化在低精度下精度显著下降，而非均匀的K-Means量化虽然精度高但需要反量化和浮点运算；2) 激活离群值阻碍低精度WAQ，离线检测方法导致性能下降，在线检测引入大量运行时开销。", "method": "本文提出了KLLM，一个软硬件协同设计框架。KLLM采用基于索引的计算方案，用于高效执行K-Means量化数据的矩阵乘法和非线性操作，从而避免了大部分反量化和全精度计算。此外，KLLM还集成了一个新颖的离群值检测引擎Orizuru，能够在在线推理期间高效识别激活数据流中最大和最小的前k个元素。", "result": "实验表明，与A100 GPU和Atom相比，KLLM平均分别实现了9.67倍和7.03倍的加速，以及229.50倍和150.21倍的能效提升。", "conclusion": "KLLM通过创新的软硬件协同设计，有效解决了K-Means量化在LLM推理中面临的计算效率和激活离群值问题，显著提升了LLM推理的速度和能效。", "translation": "大语言模型（LLM）推理因其密集的内存和计算需求而面临重大挑战。权重和激活量化（WAQ）通过减少内存占用和算术复杂性提供了一个有前景的解决方案。然而，现有WAQ设计中仍存在两个关键挑战。(1) 传统的WAQ设计依赖于基于均匀整数的量化以实现硬件效率，但这通常会导致低精度下的显著精度下降。基于K-Means的量化作为一种非均匀量化技术，通过匹配LLM中权重和激活的类高斯分布实现了更高的精度。然而，其非均匀性阻碍了在低精度计算单元上的直接执行，在推理过程中需要反量化和浮点矩阵乘法（MatMuls）。(2) 激活离群值进一步阻碍了有效的低精度WAQ。用于离群值检测的离线阈值方法可能导致模型性能显著下降，而现有的在线检测技术则会引入大量的运行时开销。\n为了解决上述挑战并充分释放K-Means量化在LLM推理中WAQ的潜力，本文提出了KLLM，一个软硬件协同设计框架。KLLM的特点是采用基于索引的计算方案，用于高效执行K-Means量化数据上的矩阵乘法和非线性操作，从而避免了大部分反量化和全精度计算。此外，KLLM还集成了一个新颖的离群值检测引擎Orizuru，能够在在线推理期间高效识别激活数据流中最大和最小的前k个元素。\n广泛的实验表明，与A100 GPU和Atom相比，KLLM平均分别实现了9.67倍和7.03倍的加速，以及229.50倍和150.21倍的能效提升。", "summary": "本文提出了KLLM，一个针对大语言模型（LLM）推理的软硬件协同设计框架，旨在解决现有量化技术中K-Means量化无法直接在低精度硬件上执行以及激活离群值处理效率低下的问题。KLLM通过引入基于索引的计算方案避免了反量化和全精度计算，并设计了高效的Orizuru离群值检测引擎。实验结果表明，KLLM在速度和能效方面均实现了显著提升，例如相较于A100 GPU实现了9.67倍的加速和229.50倍的能效提升。", "keywords": "LLM推理, K-Means量化, 软硬件协同设计, 索引计算, 离群值检测", "comments": "KLLM的创新之处在于其软硬件协同设计，特别是通过索引计算方案解决了K-Means量化在低精度硬件上直接执行的难题，并集成了高效的在线离群值检测机制。这对于在资源受限的环境下部署LLM具有重要意义，因为它显著提升了推理速度和能效，同时保持了精度，克服了传统量化方法的局限性。"}}
{"id": "2507.23139", "title": "Robust Control Design and Analysis for Nonlinear Systems with Uncertain Initial Conditions Based on Lifting Linearization", "authors": ["Sourav Sinha", "Mazen Farhood"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      24 pages, 13 figures", "url": "http://arxiv.org/abs/2507.23139v1", "summary": "This paper presents a robust control synthesis and analysis framework for\nnonlinear systems with uncertain initial conditions. First, a deep\nlearning-based lifting approach is proposed to approximate nonlinear dynamical\nsystems with linear parameter-varying (LPV) state-space models in\nhigher-dimensional spaces while simultaneously characterizing the uncertain\ninitial states within the lifted state space. Then, convex synthesis conditions\nare provided to generate full-state feedback nonstationary LPV (NSLPV)\ncontrollers for the lifted LPV system. A performance measure similar to the\nl2-induced norm is used to provide robust performance guarantees in the\npresence of exogenous disturbances and uncertain initial conditions. The paper\nalso includes results for synthesizing full-state feedback LTI controllers and\noutput feedback NSLPV controllers. Additionally, a robustness analysis approach\nbased on integral quadratic constraint (IQC) theory is developed to analyze and\ntune the synthesized controllers while accounting for noise associated with\nstate measurements. This analysis approach characterizes model parameters and\ndisturbance inputs using IQCs to reduce conservatism. Finally, the\neffectiveness of the proposed framework is demonstrated through two\nillustrative examples.", "comment": "24 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.23139v1", "cate": "eess.SY", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "基于提升线性化的不确定初始条件非线性系统鲁棒控制设计与分析", "tldr": "本文提出了一种针对具有不确定初始条件的非线性系统的鲁棒控制综合与分析框架，该框架结合了基于深度学习的提升线性化、LPV控制和基于IQC的分析方法。", "motivation": "针对具有不确定初始条件的非线性系统，需要开发一种鲁棒的控制综合与分析框架。", "method": "首先，提出了一种基于深度学习的提升方法，将非线性系统近似为高维LPV状态空间模型，并表征不确定初始状态。其次，提供了凸综合条件以生成全状态反馈NSLPV控制器。采用类似于l2诱导范数的性能度量。还包括全状态反馈LTI控制器和输出反馈NSLPV控制器的综合。此外，开发了一种基于积分二次约束（IQC）理论的鲁棒性分析方法，用于分析和调整控制器，并减少保守性。", "result": "通过两个说明性示例证明了所提出框架的有效性。", "conclusion": "本文提出的鲁棒控制综合与分析框架能够有效处理具有不确定初始条件的非线性系统，并通过实例验证了其有效性。", "translation": "本文提出了一种针对具有不确定初始条件的非线性系统的鲁棒控制综合与分析框架。首先，提出了一种基于深度学习的提升方法，用于在高维空间中通过线性参数变化（LPV）状态空间模型来近似非线性动态系统，同时在提升状态空间内表征不确定初始状态。然后，提供了凸综合条件，为提升后的LPV系统生成全状态反馈非平稳LPV（NSLPV）控制器。采用类似于l2诱导范数的性能度量，以在存在外部扰动和不确定初始条件的情况下提供鲁棒性能保证。本文还包括全状态反馈LTI控制器和输出反馈NSLPV控制器的综合结果。此外，开发了一种基于积分二次约束（IQC）理论的鲁棒性分析方法，用于分析和调整所综合的控制器，同时考虑与状态测量相关的噪声。这种分析方法利用IQC来表征模型参数和扰动输入，以减少保守性。最后，通过两个说明性示例证明了所提出框架的有效性。", "summary": "本文介绍了一种针对具有不确定初始条件的非线性系统的鲁棒控制综合与分析框架。该框架首先利用基于深度学习的提升方法将非线性系统近似为高维LPV模型，并表征不确定初始状态。随后，提出了用于综合全状态反馈NSLPV控制器的凸条件，并采用l2诱导范数类似的性能度量。此外，还开发了基于IQC理论的鲁棒性分析方法，以处理测量噪声并降低保守性。通过示例验证了所提框架的有效性。", "keywords": "鲁棒控制, 非线性系统, 不确定初始条件, 提升线性化, LPV控制, IQC", "comments": "该论文的创新之处在于将深度学习应用于提升线性化，并将其与LPV控制以及基于IQC的鲁棒性分析相结合，从而为处理具有不确定初始条件的非线性系统提供了一个全面的鲁棒控制框架。"}}
{"id": "2507.23105", "title": "The Squishy Grid Problem", "authors": ["Zixi Cai", "Kuowen Chen", "Shengquan Du", "Arnold Filtser", "Seth Pettie", "Daniel Skora"], "categories": ["cs.CG", "cs.DM", "cs.DS", "math.CO", "math.PR"], "primary_category": "Subjects:       Computational Geometry (cs.CG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23105v1", "summary": "In this paper we consider the problem of approximating Euclidean distances by\nthe infinite integer grid graph. Although the topology of the graph is fixed,\nwe have control over the edge-weight assignment $w:E\\to \\mathbb{R}_{\\ge 0}$,\nand hope to have grid distances be asymptotically isometric to Euclidean\ndistances, that is, for all grid points $u,v$, $\\mathrm{dist}_w(u,v) = (1\\pm\no(1))\\|u-v\\|_2$. We give three methods for solving this problem, each\nattractive in its own way.\n  * Our first construction is based on an embedding of the recursive,\nnon-periodic pinwheel tiling of Radin and Conway into the integer grid.\nDistances in the pinwheel graph are asymptotically isometric to Euclidean\ndistances, but no explicit bound on the rate of convergence was known. We prove\nthat the multiplicative distortion of the pinwheel graph is\n$(1+1/\\Theta(\\log^\\xi \\log D))$, where $D$ is the Euclidean distance and\n$\\xi=\\Theta(1)$. The pinwheel tiling approach is conceptually simple, but can\nbe improved quantitatively.\n  * Our second construction is based on a hierarchical arrangement of\n\"highways.\" It is simple, achieving stretch $(1 + 1/\\Theta(D^{1/9}))$, which\nconverges doubly exponentially faster than the pinwheel tiling approach.\n  * The first two methods are deterministic. An even simpler approach is to\nsample the edge weights independently from a common distribution $\\mathscr{D}$.\nWhether there exists a distribution $\\mathscr{D}^*$ that makes grid distances\nEuclidean, asymptotically and in expectation, is major open problem in the\ntheory of first passage percolation. Previous experiments show that when\n$\\mathscr{D}$ is a Fisher distribution, grid distances are within 1\\% of\nEuclidean. We demonstrate experimentally that this level of accuracy can be\nachieved by a simple 2-point distribution that assigns weights 0.41 or 4.75\nwith probability 44\\% and 56\\%, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23105v1", "cate": "cs.CG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "可变形网格问题", "tldr": "本文探讨了通过调整边权重，使无限整数网格图中的距离渐近等距于欧几里得距离的三种方法，包括基于风车平铺、分层“高速公路”和随机采样的方法，并给出了相应的性能结果。", "motivation": "本文旨在解决如何在无限整数网格图中通过控制边权重分配，使网格距离渐近等距于欧几里得距离，即对于所有网格点u,v，dist_w(u,v) = (1±o(1))||u-v||_2。", "method": "本文提出了三种方法：\n1. 第一种方法基于将Radin和Conway的递归、非周期性风车平铺嵌入到整数网格中。\n2. 第二种方法基于“高速公路”的分层布置。\n3. 第三种方法是通过从共同分布中独立采样边权重，并通过实验验证了一种简单的2点分布。", "result": "1. 第一种基于风车平铺的构造证明了风车图的乘法失真为(1+1/Θ(log^ξ log D))，其中D是欧几里得距离，ξ=Θ(1)。\n2. 第二种基于分层“高速公路”的构造实现了(1 + 1/Θ(D^(1/9)))的拉伸，收敛速度比风车平铺方法快两倍指数。\n3. 对于第三种实验方法，当D是Fisher分布时，网格距离在欧几里得距离的1%以内；本文通过实验证明，一个简单的2点分布（权重分别为0.41和4.75，概率分别为44%和56%）可以达到这种精度。", "conclusion": "本文提出了三种解决“可变形网格问题”的方法，旨在通过调整边权重使网格距离渐近等距于欧几里得距离。这些方法包括基于风车平铺的嵌入、分层高速公路结构以及通过随机采样边权重。实验结果表明，即使是简单的2点分布也能使网格距离达到与欧几里得距离1%的精度。", "translation": "在本文中，我们考虑了用无限整数网格图近似欧几里得距离的问题。尽管图的拓扑结构是固定的，但我们可以控制边权重分配w:E→R≥0，并希望网格距离渐近等距于欧几里得距离，即对于所有网格点u,v，dist_w(u,v) = (1±o(1))||u-v||_2。我们提出了三种解决此问题的方法，每种方法都有其独特之处。\n* 我们的第一个构造基于将Radin和Conway的递归、非周期性风车平铺嵌入到整数网格中。风车图中的距离渐近等距于欧几里得距离，但收敛速度的明确界限尚不清楚。我们证明了风车图的乘法失真为(1+1/Θ(log^ξ log D))，其中D是欧几里得距离，ξ=Θ(1)。风车平铺方法概念上简单，但定量上可以改进。\n* 我们的第二个构造基于“高速公路”的分层布置。它很简单，实现了(1 + 1/Θ(D^(1/9)))的拉伸，收敛速度比风车平铺方法快两倍指数。\n* 前两种方法是确定性的。一种更简单的方法是从共同分布D中独立采样边权重。是否存在一个分布D*能使网格距离在渐近和期望上都变成欧几里得距离，是首次通过渗流理论中的一个主要开放问题。之前的实验表明，当D是Fisher分布时，网格距离在欧几里得距离的1%以内。我们通过实验证明，通过一个简单的2点分布，即分别以44%和56%的概率分配权重0.41或4.75，可以达到这种精度水平。", "summary": "本文探讨了如何在无限整数网格图中通过调整边权重，使其距离渐近等距于欧几里得距离。论文提出了三种方法：第一种是基于风车平铺的嵌入，证明其乘法失真为(1+1/Θ(log^ξ log D))；第二种是基于分层“高速公路”的构造，实现了更快的收敛速度(1 + 1/Θ(D^(1/9)))；第三种是实验性的，通过独立采样边权重，并发现一个简单的2点分布（0.41或4.75的权重，分别对应44%和56%的概率）能使网格距离达到欧几里得距离的1%精度。", "keywords": "欧几里得距离, 网格图, 边权重, 风车平铺, 首次通过渗流", "comments": "本文创新性地提出了三种不同策略来解决“可变形网格问题”，即如何通过调整网格边的权重使其距离行为趋近于欧几里得距离。它不仅提供了两种理论上具有收敛保证的确定性方法，还通过实验验证了一种简单概率分布的有效性，为实际应用提供了新的思路。特别是，对于随机采样方法，它在首次通过渗流理论的开放问题背景下，给出了一个具体的、高性能的实验结果，这对于理解随机介质中的距离行为具有重要意义。"}}
{"id": "2312.14057", "title": "Weighted least-squares approximation with determinantal point processes and generalized volume sampling", "authors": ["Anthony Nouy", "Bertrand Michel"], "categories": ["math.NA", "cs.LG", "cs.NA", "math.ST", "stat.TH"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Compared with the first version, conjectures (13) on DPP and (16) on volume sampling have been modified, including a convexity requirement. Proofs of propositions 5.4 and 5.13 have been modified accordingly. Remarks 5.5 and 5.6 have been added to discuss alternatives to conjecture (13) on DPP", "url": "http://arxiv.org/abs/2312.14057v4", "summary": "We consider the problem of approximating a function from $L^2$ by an element\nof a given $m$-dimensional space $V_m$, associated with some feature map\n$\\boldsymbol{\\varphi}$, using evaluations of the function at random points\n$x_1, \\dots,x_n$. After recalling some results on optimal weighted\nleast-squares using independent and identically distributed points, we consider\nweighted least-squares using projection determinantal point processes (DPP) or\nvolume sampling. These distributions introduce dependence between the points\nthat promotes diversity in the selected features $\\boldsymbol{\\varphi}(x_i)$.\nWe first provide a generalized version of volume-rescaled sampling yielding\nquasi-optimality results in expectation with a number of samples $n =\nO(m\\log(m))$, that means that the expected $L^2$ error is bounded by a constant\ntimes the best approximation error in $L^2$. Also, further assuming that the\nfunction is in some normed vector space $H$ continuously embedded in $L^2$, we\nfurther prove that the approximation error in $L^2$ is almost surely bounded by\nthe best approximation error measured in the $H$-norm. This includes the cases\nof functions from $L^\\infty$ or reproducing kernel Hilbert spaces. Finally, we\npresent an alternative strategy consisting in using independent repetitions of\nprojection DPP (or volume sampling), yielding similar error bounds as with\ni.i.d. or volume sampling, but in practice with a much lower number of samples.\nNumerical experiments illustrate the performance of the different strategies.", "comment": "Compared with the first version, conjectures (13) on DPP and (16) on\n  volume sampling have been modified, including a convexity requirement. Proofs\n  of propositions 5.4 and 5.13 have been modified accordingly. Remarks 5.5 and\n  5.6 have been added to discuss alternatives to conjecture (13) on DPP", "pdf_url": "http://arxiv.org/pdf/2312.14057v4", "cate": "math.NA", "date": "2023-12-21", "updated": "2025-07-31", "AI": {"title_translation": "基于行列式点过程和广义体积采样的加权最小二乘逼近", "tldr": "本文探讨了使用行列式点过程（DPP）和体积采样进行加权最小二乘逼近，展示了与独立同分布（i.i.d.）方法相比，在函数逼近方面具有更高的样本效率和更小的误差界限。", "motivation": "本文旨在解决使用随机点评估来逼近$L^2$空间中函数的问题。其动机是通过在点之间引入依赖性来促进所选特征的多样性，从而改进标准方法（如i.i.d.采样），以期获得更好的逼近质量或样本效率。", "method": "1. 回顾了使用独立同分布（i.i.d.）点进行最优加权最小二乘的结果。2. 提出并分析了使用投影行列式点过程（DPP）或体积采样进行加权最小二乘，这些方法引入依赖性以促进多样性。3. 提供了一个广义版本的体积重标度采样。4. 考虑了一种替代策略：独立重复投影DPP（或体积采样）。5. 使用数值实验来说明性能。", "result": "1. 广义版本的体积重标度采样在期望意义上产生了准最优结果，样本数量为$n = O(m\\log(m))$，这意味着预期的$L^2$误差被一个常数乘以$L^2$中的最佳逼近误差所限制。2. 如果函数在某个连续嵌入$L^2$的范数向量空间$H$中，则$L^2$中的逼近误差几乎肯定被$H$范数中测量的最佳逼近误差所限制（包括$L^\\infty$或再生核希尔伯特空间的情况）。3. 替代策略（独立重复投影DPP或体积采样）产生了与i.i.d.或体积采样相似的误差界限，但在实践中样本数量要少得多。4. 数值实验说明了不同策略的性能。", "conclusion": "本文证明，使用行列式点过程和体积采样等依赖性采样方法，或其独立重复，可以实现函数的高效准确加权最小二乘逼近，与独立同分布方法相比，可能需要更少的样本，同时保持强大的理论误差界限。", "translation": "我们考虑从$L^2$空间通过给定$m$维空间$V_m$中的元素，并结合某个特征映射$\\boldsymbol{\\varphi}$，使用在随机点$x_1, \\dots,x_n$处对函数进行评估来逼近函数的问题。在回顾了使用独立同分布点进行最优加权最小二乘的一些结果后，我们考虑使用投影行列式点过程（DPP）或体积采样进行加权最小二乘。这些分布在点之间引入了依赖性，从而促进了所选特征$\\boldsymbol{\\varphi}(x_i)$的多样性。我们首先提供了一个广义版本的体积重标度采样，在$n = O(m\\log(m))$个样本的情况下，在期望意义上产生了准最优结果，这意味着预期的$L^2$误差被一个常数乘以$L^2$中的最佳逼近误差所限制。此外，进一步假设函数在某个连续嵌入$L^2$的范数向量空间$H$中，我们进一步证明$L^2$中的逼近误差几乎肯定被$H$范数中测量的最佳逼近误差所限制。这包括$L^\\infty$或再生核希尔伯特空间中的函数情况。最后，我们提出了一种替代策略，包括独立重复投影DPP（或体积采样），产生与i.i.d.或体积采样相似的误差界限，但在实践中样本数量要少得多。数值实验说明了不同策略的性能。", "summary": "本文研究了使用随机点评估对$L^2$空间函数进行加权最小二乘逼近的问题。它引入了投影行列式点过程（DPP）和广义体积采样，以促进所选特征的多样性，从而区别于传统的独立同分布采样。论文提出了理论保证，包括在$O(m\\log(m))$样本下的期望准最优性，以及对于连续嵌入空间$H$中函数的$L^2$几乎肯定误差界限。此外，还提出了一种独立重复DPP/体积采样的替代策略，该策略在实践中以更少的样本量实现了相似的误差界限。数值实验验证了这些多样化采样策略的有效性。", "keywords": "加权最小二乘, 行列式点过程, 体积采样, 函数逼近, 准最优性", "comments": "本文将行列式点过程（DPP）和体积采样应用于函数逼近，特别是在加权最小二乘的背景下，这是一个有趣的创新点。其核心创新在于利用DPP和体积采样的多样性促进特性，以期在逼近质量或样本效率方面优于独立同分布采样。理论上的保证（准最优性、几乎肯定界限）是重要的贡献，特别是对广义体积重标度采样的分析以及对各种函数空间中函数的扩展。通过重复DPP减少样本量的实际意义也十分重大。"}}
{"id": "2507.22916", "title": "From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems", "authors": ["Kun Jiang"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      20 pages, 7 figures", "url": "http://arxiv.org/abs/2507.22916v1", "summary": "In our previous work, we proposed a novel neuron model based on symmetric\ndifferential equations and demonstrated its potential as an efficient signal\npropagator. Building upon that foundation, the present study delves deeper into\nthe intrinsic dynamics and functional diversity of this model. By\nsystematically exploring the parameter space and employing a range of\nmathematical analysis tools, we theoretically reveal the system 's core\nproperty of functional duality. Specifically, the model exhibits two distinct\ntrajectory behaviors: one is asymptotically stable, corresponding to a reliable\nsignal propagator; the other is Lyapunov stable, characterized by sustained\nself-excited oscillations, functioning as a signal generator. To enable\neffective monitoring and prediction of system states during simulations, we\nintroduce a novel intermediate-state metric termed on-road energy. Simulation\nresults confirm that transitions between the two functional modes can be\ninduced through parameter adjustments or modifications to the connection\nstructure. Moreover, we show that oscillations can be effectively suppressed by\nintroducing external signals. These findings draw a compelling parallel to the\ndual roles of biological neurons in both information transmission and rhythm\ngeneration, thereby establishing a solid theoretical basis and a clear\nfunctional roadmap for the broader application of this model in neuromorphic\nengineering.", "comment": "20 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.22916v1", "cate": "cs.NE", "date": "2025-07-20", "updated": "2025-07-20", "AI": {"title_translation": "从传播器到振荡器：对称微分方程在神经系统中的双重作用", "tldr": "本研究深入探讨了一种基于对称微分方程的新型神经元模型，发现其具有信号传播器和信号发生器的双重功能，并通过参数调整或连接结构改变实现模式转换，为神经形态工程提供了理论基础。", "motivation": "该研究旨在深入探索基于对称微分方程的新型神经元模型的内在动力学和功能多样性，以建立其在神经形态工程中更广泛应用的基础。", "method": "研究通过系统探索参数空间并运用多种数学分析工具，理论上揭示了系统的功能二元性。此外，还通过引入“在途能量”这一中间状态度量，并进行仿真实验来验证和监测系统状态及功能模式的转换。", "result": "该模型展现出功能二元性：既能作为可靠的信号传播器（渐近稳定），也能作为信号发生器（李雅普诺夫稳定，持续自激振荡）。研究引入了“在途能量”作为中间状态度量。仿真结果证实，通过参数调整或连接结构修改可以诱导两种功能模式之间的转换。此外，外部信号可以有效抑制振荡。", "conclusion": "这些发现与生物神经元在信息传输和节律生成中的双重作用形成了引人注目的并行，从而为该模型在神经形态工程中的更广泛应用建立了坚实的理论基础和清晰的功能路线图。", "translation": "在我们之前的工作中，我们提出了一种基于对称微分方程的新型神经元模型，并展示了其作为高效信号传播器的潜力。在此基础上，本研究更深入地探讨了该模型的内在动力学和功能多样性。通过系统地探索参数空间并运用一系列数学分析工具，我们理论上揭示了系统功能二元性的核心属性。具体而言，该模型展现出两种截然不同的轨迹行为：一种是渐近稳定的，对应于可靠的信号传播器；另一种是李雅普诺夫稳定的，其特征是持续的自激振荡，充当信号发生器。为了在仿真过程中有效监测和预测系统状态，我们引入了一种新颖的中间状态度量，称为“在途能量”。仿真结果证实，通过参数调整或连接结构修改可以诱导两种功能模式之间的转换。此外，我们展示了通过引入外部信号可以有效抑制振荡。这些发现与生物神经元在信息传输和节律生成中的双重作用形成了引人注目的并行，从而为该模型在神经形态工程中的更广泛应用建立了坚实的理论基础和清晰的功能路线图。", "summary": "本研究深入探索了一种基于对称微分方程的新型神经元模型的功能多样性。通过数学分析和仿真，揭示了该模型在信号传播器（渐近稳定）和信号发生器（李雅普诺夫稳定，自激振荡）之间的功能二元性。研究引入了“在途能量”作为中间状态度量，并证明了通过参数或连接结构调整可实现模式转换，且外部信号能抑制振荡。这些发现为神经形态工程中模拟生物神经元的信息传输和节律生成提供了理论基础和应用前景。", "keywords": "对称微分方程, 神经元模型, 功能二元性, 信号传播器, 信号发生器", "comments": "这篇论文的创新点在于提出了基于对称微分方程的神经元模型，并揭示了其作为信号传播器和信号发生器的双重功能，这与生物神经元的双重作用形成了有力的类比。这种功能二元性为神经形态工程中的信息处理和节律生成提供了新的理论视角和潜在的实现方式。引入“在途能量”度量有助于更好地理解和控制系统状态转换，增加了模型的实用性。"}}
{"id": "2507.23027", "title": "Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging", "authors": ["Krishan Agyakari Raja Babu", "Om Prabhu", "Annu", "Mohanasankar Sivaprakasam"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the MICCAI Workshop on \"Medical Image Computing in Resource Constrained Settings & Knowledge Interchange (MIRASOL)\" 2025", "url": "http://arxiv.org/abs/2507.23027v1", "summary": "Automated cardiac interpretation in resource-constrained settings (RCS) is\noften hindered by poor-quality echocardiographic imaging, limiting the\neffectiveness of downstream diagnostic models. While super-resolution (SR)\ntechniques have shown promise in enhancing magnetic resonance imaging (MRI) and\ncomputed tomography (CT) scans, their application to echocardiography-a widely\naccessible but noise-prone modality-remains underexplored. In this work, we\ninvestigate the potential of deep learning-based SR to improve classification\naccuracy on low-quality 2D echocardiograms. Using the publicly available CAMUS\ndataset, we stratify samples by image quality and evaluate two clinically\nrelevant tasks of varying complexity: a relatively simple Two-Chamber vs.\nFour-Chamber (2CH vs. 4CH) view classification and a more complex End-Diastole\nvs. End-Systole (ED vs. ES) phase classification. We apply two widely used SR\nmodels-Super-Resolution Generative Adversarial Network (SRGAN) and\nSuper-Resolution Residual Network (SRResNet), to enhance poor-quality images\nand observe significant gains in performance metric-particularly with SRResNet,\nwhich also offers computational efficiency. Our findings demonstrate that SR\ncan effectively recover diagnostic value in degraded echo scans, making it a\nviable tool for AI-assisted care in RCS, achieving more with less.", "comment": "Accepted at the MICCAI Workshop on \"Medical Image Computing in\n  Resource Constrained Settings & Knowledge Interchange (MIRASOL)\" 2025", "pdf_url": "http://arxiv.org/pdf/2507.23027v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "恢复诊断价值：超分辨率辅助的心脏超声分类在资源受限成像中的应用", "tldr": "超分辨率技术能有效提升资源受限环境下低质量心脏超声图像的诊断分类准确性。", "motivation": "资源受限环境下，低质量的心脏超声图像常阻碍自动化心脏解读，限制了诊断模型的有效性。尽管超分辨率（SR）技术在MRI和CT中显示出潜力，但在广泛可及但易受噪声影响的心脏超声成像中的应用仍未被充分探索。", "method": "本研究探讨了基于深度学习的超分辨率技术在改善低质量2D心脏超声图像分类准确性方面的潜力。利用公开的CAMUS数据集，根据图像质量对样本进行分层，并评估了两种临床相关任务：相对简单的二腔与四腔视图分类，以及更复杂的心舒末期与心缩末期相位分类。应用了两种广泛使用的SR模型（SRGAN和SRResNet）来增强低质量图像。", "result": "研究发现，应用超分辨率技术后，性能指标显著提升，特别是SRResNet模型，其在提升性能的同时还提供了计算效率。", "conclusion": "超分辨率技术能有效恢复退化超声扫描的诊断价值，使其成为资源受限环境下AI辅助医疗的可行工具，实现“少花钱多办事”。", "translation": "在资源受限环境（RCS）中，自动化心脏解读常因心脏超声成像质量差而受阻，这限制了下游诊断模型的有效性。虽然超分辨率（SR）技术在增强磁共振成像（MRI）和计算机断层扫描（CT）方面已显示出前景，但它们在心脏超声——一种广泛可及但易受噪声影响的模态——中的应用仍未被充分探索。在这项工作中，我们研究了基于深度学习的SR技术在提高低质量2D心脏超声图分类准确性方面的潜力。使用公开可用的CAMUS数据集，我们根据图像质量对样本进行分层，并评估了两个复杂程度不同的临床相关任务：相对简单的二腔与四腔（2CH vs. 4CH）视图分类和更复杂的心舒末期与心缩末期（ED vs. ES）相位分类。我们应用了两种广泛使用的SR模型——超分辨率生成对抗网络（SRGAN）和超分辨率残差网络（SRResNet），来增强低质量图像，并观察到性能指标显著提升——特别是SRResNet，它还提供了计算效率。我们的研究结果表明，SR能够有效恢复退化超声扫描的诊断价值，使其成为RCS中AI辅助护理的可行工具，实现事半功倍的效果。", "summary": "本研究探讨了深度学习超分辨率（SR）技术在改善资源受限环境下低质量心脏超声图像诊断分类准确性方面的潜力。通过对CAMUS数据集中的低质量2D心脏超声图像应用SRGAN和SRResNet模型，并评估其在视图分类和相位分类任务上的表现，结果显示SR，特别是SRResNet，能显著提升分类性能，有效恢复图像的诊断价值，从而为资源受限地区的AI辅助医疗提供了可行方案。", "keywords": "超分辨率, 心脏超声, 图像分类, 资源受限, 深度学习", "comments": "这项研究的创新之处在于将超分辨率技术应用于心脏超声领域，尤其关注其在图像质量受限环境下的诊断价值恢复，这对于推广AI辅助医疗到资源匮乏地区具有重要意义。通过实验证明了SR技术，特别是SRResNet的有效性和效率，为解决实际临床问题提供了新的思路。"}}
{"id": "2507.23084", "title": "AutoIndexer: A Reinforcement Learning-Enhanced Index Advisor Towards Scaling Workloads", "authors": ["Taiyi Wang", "Eiko Yoneki"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.23084v1", "summary": "Efficiently selecting indexes is fundamental to database performance\noptimization, particularly for systems handling large-scale analytical\nworkloads. While deep reinforcement learning (DRL) has shown promise in\nautomating index selection through its ability to learn from experience, few\nworks address how these RL-based index advisors can adapt to scaling workloads\ndue to exponentially growing action spaces and heavy trial and error. To\naddress these challenges, we introduce AutoIndexer, a framework that combines\nworkload compression, query optimization, and specialized RL models to scale\nindex selection effectively. By operating on compressed workloads, AutoIndexer\nsubstantially lowers search complexity without sacrificing much index quality.\nExtensive evaluations show that it reduces end-to-end query execution time by\nup to 95% versus non-indexed baselines. On average, it outperforms\nstate-of-the-art RL-based index advisors by approximately 20% in workload cost\nsavings while cutting tuning time by over 50%. These results affirm\nAutoIndexer's practicality for large and diverse workloads.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.23084v1", "cate": "cs.DB", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "AutoIndexer：一种强化学习增强型索引推荐器，旨在应对扩展工作负载", "tldr": "AutoIndexer是一个强化学习增强型索引推荐器，通过结合工作负载压缩、查询优化和专用RL模型，有效解决了现有RL方法在扩展工作负载时面临的挑战，显著提升了数据库性能和调优效率。", "motivation": "高效选择索引对于数据库性能优化至关重要，尤其是在处理大规模分析工作负载时。虽然深度强化学习（DRL）在自动化索引选择方面显示出潜力，但由于行动空间呈指数级增长和大量试错，很少有工作能够解决基于RL的索引推荐器如何适应扩展工作负载的问题。", "method": "本文引入了AutoIndexer框架，它结合了工作负载压缩、查询优化和专门的强化学习模型，以有效地扩展索引选择。AutoIndexer通过在压缩的工作负载上运行，在不牺牲太多索引质量的情况下，大大降低了搜索复杂度。", "result": "AutoIndexer将端到端查询执行时间与非索引基线相比减少了高达95%。平均而言，它在工作负载成本节约方面比最先进的基于RL的索引推荐器高出约20%，同时将调优时间缩短了50%以上。", "conclusion": "这些结果证实了AutoIndexer对于大型和多样化工作负载的实用性。", "translation": "高效选择索引是数据库性能优化的基础，特别是对于处理大规模分析工作负载的系统。虽然深度强化学习（DRL）通过其从经验中学习的能力在自动化索引选择方面显示出前景，但很少有工作能够解决这些基于RL的索引推荐器如何适应扩展工作负载的问题，原因在于行动空间呈指数级增长和大量的试错。为了解决这些挑战，我们引入了AutoIndexer，一个结合了工作负载压缩、查询优化和专用RL模型的框架，以有效地扩展索引选择。通过在压缩的工作负载上运行，AutoIndexer在不牺牲太多索引质量的情况下，大大降低了搜索复杂度。广泛的评估表明，与非索引基线相比，它将端到端查询执行时间缩短了高达95%。平均而言，它在工作负载成本节约方面比最先进的基于RL的索引推荐器高出约20%，同时将调优时间缩短了50%以上。这些结果证实了AutoIndexer对于大型和多样化工作负载的实用性。", "summary": "AutoIndexer是一个创新的框架，旨在解决现有深度强化学习（DRL）索引推荐器在处理扩展工作负载时面临的挑战。它通过结合工作负载压缩、查询优化和专门的RL模型来优化索引选择。该方法通过在压缩的工作负载上操作，显著降低了搜索复杂性，同时保持了高索引质量。实验结果表明，AutoIndexer能将查询执行时间减少高达95%，并在工作负载成本节约方面比现有RL方法平均高出20%，同时将调优时间缩短一半以上，证明了其在大规模和多样化工作负载中的实用性。", "keywords": "索引选择, 强化学习, 数据库性能, 工作负载压缩, 索引推荐器", "comments": "AutoIndexer的创新之处在于它通过工作负载压缩有效地解决了RL-based索引推荐器在面对扩展工作负载时行动空间爆炸和试错成本高昂的问题。这种方法不仅显著提高了性能，还大大缩短了调优时间，使其在实际数据库管理中具有重要价值。该研究为将RL应用于大规模系统优化提供了新的思路。"}}
{"id": "2507.23740", "title": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "authors": ["Nasim Shirvani-Mahdavi", "Devin Wingfield", "Amin Ghasemi", "Chengkai Li"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23740v1", "summary": "Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23740v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "规则到文本：知识图谱中逻辑规则的自然语言解释", "tldr": "该研究探索使用大型语言模型为知识图谱中的逻辑规则生成自然语言解释，并进行了人工评估，结果显示出良好的正确性和清晰度，但仍有挑战。", "motivation": "知识图谱中的逻辑规则复杂且具有独特的标签约定，导致人类难以理解。为了提高知识图谱的完整性、错误检测、模式揭示和推理能力，需要一种方法来生成这些规则的自然语言解释，从而提高人类的可理解性。", "method": "研究人员首先使用AMIE 3.5.1规则发现算法从FB15k-237、FB-CVT-REV和FB+CVT-REV数据集中提取逻辑规则。然后，他们探索了使用大型语言模型（LLMs）生成自然语言解释的潜力，并测试了包括零样本和少样本提示、包含变量实体类型以及思维链推理在内的多种提示策略。最后，通过对生成解释的正确性、清晰度和幻觉进行全面人工评估，并评估了LLMs作为自动判断器的潜力。", "result": "结果表明，在解释的正确性和清晰度方面表现出有前景的性能。", "conclusion": "尽管大型语言模型在为知识图谱中的逻辑规则生成自然语言解释方面表现出有前景的正确性和清晰度，但未来研究仍面临一些挑战。", "translation": "知识图谱（KGs）通常包含足够的信息来支持新事实的推断。识别逻辑规则不仅可以提高知识图谱的完整性，还可以检测潜在错误、揭示微妙的数据模式，并增强整体推理和解释能力。然而，这些规则的复杂性，加上每个知识图谱独特的标签约定，使得人类难以理解它们。在本文中，我们探索了大型语言模型为逻辑规则生成自然语言解释的潜力。具体来说，我们使用AMIE 3.5.1规则发现算法从基准数据集FB15k-237以及两个大规模数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则。我们研究了各种提示策略，包括零样本和少样本提示、包含变量实体类型以及思维链推理。我们对生成的解释进行了基于正确性、清晰度和幻觉的全面人工评估，并评估了使用大型语言模型作为自动判断器的可能性。我们的结果表明，在解释的正确性和清晰度方面表现出有前景的性能，尽管未来研究仍面临一些挑战。本研究中使用的所有脚本和数据均可在https://github.com/idirlab/KGRule2NL 公开获取。", "summary": "本文旨在解决知识图谱中逻辑规则因复杂性和独特标签约定而难以被人理解的问题。研究人员利用大型语言模型，结合AMIE 3.5.1算法从多个知识图谱数据集中提取逻辑规则，并探索了多种提示策略来生成其自然语言解释。通过人工评估，结果显示大型语言模型在生成正确且清晰的规则解释方面表现出良好前景，但仍有待未来研究克服的挑战。", "keywords": "知识图谱, 逻辑规则, 自然语言解释, 大型语言模型, 可解释性", "comments": "这项研究通过利用大型语言模型来解决知识图谱中复杂逻辑规则的可解释性问题，具有重要的创新性。它有效地弥合了机器推理的逻辑规则与人类理解之间的鸿沟，对于知识图谱的维护、错误检测和增强推理能力具有实际应用价值。尽管取得了积极成果，但论文提及的“一些挑战”提示该领域仍有进一步探索和改进的空间。"}}
{"id": "2507.22892", "title": "Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation", "authors": ["Ismail Hossain", "Mridul Banik"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22892v1", "summary": "Conventional augmentative and alternative communication (AAC) systems and\nlanguage-learning platforms often fail to adapt in real time to the user's\ncognitive and linguistic needs, especially in neurological conditions such as\npost-stroke aphasia or amyotrophic lateral sclerosis. Recent advances in\nnoninvasive electroencephalography (EEG)--based brain-computer interfaces\n(BCIs) and transformer--based large language models (LLMs) offer complementary\nstrengths: BCIs capture users' neural intent with low fatigue, while LLMs\ngenerate contextually tailored language content. We propose and evaluate a\nnovel hybrid framework that leverages real-time EEG signals to drive an\nLLM-powered language rehabilitation assistant. This system aims to: (1) enable\nusers with severe speech or motor impairments to navigate language-learning\nmodules via mental commands; (2) dynamically personalize vocabulary,\nsentence-construction exercises, and corrective feedback; and (3) monitor\nneural markers of cognitive effort to adjust task difficulty on the fly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22892v1", "cate": "cs.HC", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "混合脑电图驱动的脑机接口：一个用于个性化语言康复的大语言模型框架", "tldr": "该研究提出了一个结合脑电图（EEG）驱动的脑机接口（BCI）与大语言模型（LLM）的混合框架，旨在为患有严重言语或运动障碍的用户提供个性化的语言康复。", "motivation": "传统的增强和替代交流（AAC）系统以及语言学习平台无法实时适应用户的认知和语言需求，尤其是在中风后失语症或肌萎缩侧索硬化症等神经系统疾病中。", "method": "提出并评估了一种新颖的混合框架，该框架利用实时脑电图（EEG）信号驱动一个由大语言模型（LLM）提供支持的语言康复助手。该系统旨在：1）使有严重言语或运动障碍的用户能够通过脑部指令导航语言学习模块；2）动态个性化词汇、句子构建练习和纠正反馈；3）监测认知努力的神经标记以实时调整任务难度。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "传统的增强和替代交流（AAC）系统和语言学习平台往往无法实时适应用户的认知和语言需求，尤其是在中风后失语症或肌萎缩侧索硬化症等神经系统疾病中。非侵入性脑电图（EEG）脑机接口（BCI）和基于Transformer的大语言模型（LLM）的最新进展提供了互补的优势：BCI以低疲劳度捕捉用户的神经意图，而LLM生成符合语境的语言内容。我们提出并评估了一种新颖的混合框架，该框架利用实时脑电图信号驱动由大语言模型提供支持的语言康复助手。该系统旨在：(1) 使有严重言语或运动障碍的用户能够通过脑部指令导航语言学习模块；(2) 动态个性化词汇、句子构建练习和纠正反馈；(3) 监测认知努力的神经标记以实时调整任务难度。", "summary": "本研究提出了一种创新的混合框架，结合了脑电图（EEG）驱动的脑机接口（BCI）与大语言模型（LLM），旨在为患有神经系统疾病导致严重言语或运动障碍的用户提供个性化的语言康复。该系统利用实时EEG信号控制LLM驱动的康复助手，以实现通过意念指令导航学习模块、动态调整学习内容（如词汇和练习）以及根据认知努力实时调整任务难度，从而克服传统AAC系统适应性差的问题。", "keywords": "脑机接口, 大语言模型, 语言康复, 脑电图, 个性化", "comments": "该论文提出了一种结合BCI和LLM的创新方法，解决了传统语言康复系统个性化不足的问题。其亮点在于利用EEG实时监测用户认知状态并动态调整康复内容，有望为神经损伤患者带来更高效、个性化的语言康复体验。这种混合框架在个性化医疗和人机交互领域具有重要潜力。"}}
{"id": "2502.20934", "title": "Revisiting the Evaluation Bias Introduced by Frame Sampling Strategies in Surgical Video Segmentation Using SAM2", "authors": ["Utku Ozbulak", "Seyed Amir Mousavi", "Francesca Tozzi", "Niki Rashidian", "Wouter Willaert", "Wesley De Neve", "Joris Vankerschaver"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the 28th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) Workshop on Fairness of AI in Medical Imaging (FAIMI), 2025", "url": "http://arxiv.org/abs/2502.20934v3", "summary": "Real-time video segmentation is a promising opportunity for AI-assisted\nsurgery, offering intraoperative guidance by identifying tools and anatomical\nstructures. Despite growing interest in surgical video segmentation, annotation\nprotocols vary widely across datasets -- some provide dense, frame-by-frame\nlabels, while others rely on sparse annotations sampled at low frame rates such\nas 1 FPS. In this study, we investigate how such inconsistencies in annotation\ndensity and frame rate sampling influence the evaluation of zero-shot\nsegmentation models, using SAM2 as a case study for cholecystectomy procedures.\nSurprisingly, we find that under conventional sparse evaluation settings, lower\nframe rates can appear to outperform higher ones due to a smoothing effect that\nconceals temporal inconsistencies. However, when assessed under real-time\nstreaming conditions, higher frame rates yield superior segmentation stability,\nparticularly for dynamic objects like surgical graspers. To understand how\nthese differences align with human perception, we conducted a survey among\nsurgeons, nurses, and machine learning engineers and found that participants\nconsistently preferred high-FPS segmentation overlays, reinforcing the\nimportance of evaluating every frame in real-time applications rather than\nrelying on sparse sampling strategies. Our findings highlight the risk of\nevaluation bias that is introduced by inconsistent dataset protocols and bring\nattention to the need for temporally fair benchmarking in surgical video AI.", "comment": "Accepted for publication in the 28th International Conference on\n  Medical Image Computing and Computer Assisted Intervention (MICCAI) Workshop\n  on Fairness of AI in Medical Imaging (FAIMI), 2025", "pdf_url": "http://arxiv.org/pdf/2502.20934v3", "cate": "cs.CV", "date": "2025-02-28", "updated": "2025-07-31", "AI": {"title_translation": "重新审视SAM2在外科视频分割中帧采样策略引入的评估偏差", "tldr": "本研究发现，外科视频分割中稀疏帧采样评估策略会引入偏差，导致低帧率在表面上优于高帧率，但高帧率在实时条件下表现更稳定，且人类用户更偏好高帧率。论文强调了在外科AI领域进行时间公平基准测试的必要性。", "motivation": "尽管外科视频分割领域日益受关注，但不同数据集的注释协议（尤其是帧采样率）差异巨大。本研究旨在调查这种不一致性如何影响零样本分割模型（如SAM2）的评估结果，并强调实时AI辅助手术中准确评估的重要性。", "method": "本研究以SAM2模型为例，针对胆囊切除术视频，调查了不同注释密度和帧率采样对零样本分割模型评估的影响。此外，通过对外科医生、护士和机器学习工程师进行调查，了解了人类对不同帧率分割叠加的感知偏好。", "result": "研究发现，在传统的稀疏评估设置下，较低帧率可能因平滑效应而显得优于较高帧率，从而掩盖了模型的时间不一致性。然而，在实时流媒体条件下评估时，较高帧率能提供更优越的分割稳定性，尤其对于外科抓钳等动态物体。对医护人员和机器学习工程师的调查显示，参与者一致偏好高FPS的分割叠加。", "conclusion": "本研究指出，外科视频分割中不一致的数据集协议和帧采样策略会引入评估偏差。研究结果强调了在外科视频AI领域中，需要进行时间公平的基准测试，并在实时应用中评估每一帧的重要性，而非依赖稀疏采样策略。", "translation": "实时视频分割为AI辅助手术提供了有前景的机会，通过识别工具和解剖结构提供术中指导。尽管对外科视频分割的兴趣日益增长，但数据集的注释协议差异很大——一些提供密集的逐帧标签，而另一些则依赖于低帧率（例如1 FPS）采样的稀疏注释。在本研究中，我们以SAM2作为胆囊切除术的案例研究，调查了注释密度和帧率采样的这种不一致性如何影响零样本分割模型的评估。令人惊讶的是，我们发现，在传统的稀疏评估设置下，较低的帧率由于平滑效应可以显得优于较高的帧率，从而掩盖了时间不一致性。然而，在实时流媒体条件下评估时，较高的帧率能产生更优越的分割稳定性，特别是对于外科抓钳等动态物体。为了理解这些差异如何与人类感知保持一致，我们对外科医生、护士和机器学习工程师进行了一项调查，发现参与者一致偏好高FPS分割叠加，这强调了在实时应用中评估每一帧的重要性，而不是依赖稀疏采样策略。我们的发现突出了由不一致的数据集协议引入的评估偏差风险，并提请人们关注外科视频AI中进行时间公平基准测试的必要性。", "summary": "本研究深入探讨了外科视频分割中不同帧采样策略对零样本分割模型（以SAM2为例）评估结果的影响。研究发现，在稀疏评估环境下，低帧率可能因平滑效应而显得性能更优，但这掩盖了时间上的不一致性。相反，在高帧率的实时流媒体条件下，模型表现出更稳定的分割效果，尤其对于动态物体。此外，通过用户调查证实，人类更倾向于高帧率的分割叠加。论文强调了现有评估方法可能存在的偏差，并呼吁在外科AI领域中采用更符合实际应用场景的时间公平基准测试方法。", "keywords": "外科视频分割, 帧采样, 评估偏差, SAM2, 实时AI", "comments": "这篇论文揭示了AI模型评估中一个关键且常被忽视的问题：数据采样策略引入的评估偏差。其创新之处在于不仅通过实验验证了这种偏差，还结合了人类用户的感知偏好来佐证实时、高帧率评估的重要性。这对于外科AI系统的实际部署和性能评估具有重要的指导意义，提醒研究人员在追求模型指标的同时，也需关注其在真实世界应用中的时间一致性和用户体验。"}}
{"id": "2404.13458", "title": "Generalizable Motion Policies through Keypoint Parameterization and Transportation Maps", "authors": ["Giovanni Franzese", "Ravi Prakash", "Cosimo Della Santina", "Jens Kober"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This article was accepted at IEEE Transactions on Robotics (T-RO)", "url": "http://arxiv.org/abs/2404.13458v2", "summary": "Learning from Interactive Demonstrations has revolutionized the way\nnon-expert humans teach robots. It is enough to kinesthetically move the robot\naround to teach pick-and-place, dressing, or cleaning policies. However, the\nmain challenge is correctly generalizing to novel situations, e.g., different\nsurfaces to clean or different arm postures to dress. This article proposes a\nnovel task parameterization and generalization to transport the original robot\npolicy, i.e., position, velocity, orientation, and stiffness. Unlike the state\nof the art, only a set of keypoints is tracked during the demonstration and the\nexecution, e.g., a point cloud of the surface to clean. We then propose to fit\na nonlinear transformation that would deform the space and then the original\npolicy using the paired source and target point sets. The use of function\napproximators like Gaussian Processes allows us to generalize, or transport,\nthe policy from every space location while estimating the uncertainty of the\nresulting policy due to the limited task keypoints and the reduced number of\ndemonstrations. We compare the algorithm's performance with state-of-the-art\ntask parameterization alternatives and analyze the effect of different function\napproximators. We also validated the algorithm on robot manipulation tasks,\ni.e., different posture arm dressing, different location product reshelving,\nand different shape surface cleaning.", "comment": "This article was accepted at IEEE Transactions on Robotics (T-RO)", "pdf_url": "http://arxiv.org/pdf/2404.13458v2", "cate": "cs.RO", "date": "2024-04-20", "updated": "2025-07-31", "AI": {"title_translation": "泛化运动策略：通过关键点参数化和传输映射", "tldr": "本文提出了一种新的机器人运动策略泛化方法，通过跟踪关键点并利用非线性变换和高斯过程，将示教策略传输到新的任务场景，并能处理不确定性。", "motivation": "学习交互式示教（LfD）使非专家能够教导机器人，但主要挑战在于如何将学到的策略正确泛化到新的、未见过的任务情况，例如不同的清洁表面或不同的穿衣姿势。", "method": "本文提出了一种新的任务参数化和泛化方法，用于传输原始的机器人策略（包括位置、速度、方向和刚度）。与现有技术不同，该方法仅在示教和执行过程中跟踪一组关键点（例如，待清洁表面的点云）。然后，通过拟合一个非线性变换来变形空间，并使用成对的源和目标点集来变形原始策略。使用高斯过程等函数逼近器，可以将策略从每个空间位置泛化或传输，同时估计由于有限任务关键点和示教数量导致的策略不确定性。", "result": "该算法的性能与现有最先进的任务参数化替代方案进行了比较，并分析了不同函数逼近器的影响。该算法还在机器人操作任务上得到了验证，包括不同姿势的手臂穿衣、不同位置的产品重新上架以及不同形状的表面清洁。", "conclusion": "Not mentioned in abstract", "translation": "学习交互式示教彻底改变了非专业人类教导机器人的方式。通过运动学方式移动机器人即可教授抓取-放置、穿衣或清洁策略。然而，主要挑战在于如何正确泛化到新的情况，例如不同的清洁表面或不同的手臂穿衣姿势。本文提出了一种新颖的任务参数化和泛化方法，用于传输原始的机器人策略，即位置、速度、方向和刚度。与现有技术不同，在示教和执行过程中仅跟踪一组关键点，例如待清洁表面的点云。然后，我们提出拟合一个非线性变换，该变换将变形空间，进而利用成对的源和目标点集变形原始策略。使用高斯过程等函数逼近器使我们能够从每个空间位置泛化或传输策略，同时估计由于有限的任务关键点和减少的示教数量导致的最终策略的不确定性。我们比较了该算法与现有最先进任务参数化替代方案的性能，并分析了不同函数逼近器的影响。我们还在机器人操作任务上验证了该算法，即不同姿势的手臂穿衣、不同位置的产品重新上架以及不同形状的表面清洁。", "summary": "本文提出了一种通过关键点参数化和传输映射实现机器人运动策略泛化的新方法，以解决示教学习中策略难以泛化到新环境的问题。该方法在示教和执行过程中仅跟踪关键点，并利用非线性变换和高斯过程将示教策略（包括位置、速度、方向和刚度）传输到新的任务空间，同时量化不确定性。实验结果表明，该方法在多种机器人操作任务（如穿衣、重新上架和清洁）中表现良好，并优于现有技术。", "keywords": "机器人学习, 运动策略泛化, 关键点参数化, 传输映射, 高斯过程", "comments": "这篇论文的创新点在于其独特的关键点参数化和传输映射方法，使得机器人能够更有效地将示教策略泛化到新的、未见过的任务场景。通过仅跟踪关键点并利用非线性变换和高斯过程来传输整个机器人策略，同时估计不确定性，这提供了一个鲁棒且灵活的泛化框架。这对于提高机器人学习的实用性和适用范围具有重要意义。"}}
{"id": "2507.12194", "title": "UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization", "authors": ["Hongming Shen", "Xun Chen", "Yulin Hui", "Zhenyu Wu", "Wei Wang", "Qiyang Lyu", "Tianchen Deng", "Danwei Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12194v2", "summary": "Existing LGL methods typically consider only partial information (e.g.,\ngeometric features) from LiDAR observations or are designed for homogeneous\nLiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL\nmethod is proposed, termed UniLGL, which simultaneously achieves spatial and\nmaterial uniformity, as well as sensor-type uniformity. The key idea of the\nproposed method is to encode the complete point cloud, which contains both\ngeometric and material information, into a pair of BEV images (i.e., a spatial\nBEV image and an intensity BEV image). An end-to-end multi-BEV fusion network\nis designed to extract uniform features, equipping UniLGL with spatial and\nmaterial uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a\nviewpoint invariance hypothesis is introduced, which replaces the conventional\ntranslation equivariance assumption commonly used in existing LPR networks and\nsupervises UniLGL to achieve sensor-type uniformity in both global descriptors\nand local feature representations. Finally, based on the mapping between local\nfeatures on the 2D BEV image and the point cloud, a robust global pose\nestimator is derived that determines the global minimum of the global pose on\nSE(3) without requiring additional registration. To validate the effectiveness\nof the proposed uniform LGL, extensive benchmarks are conducted in real-world\nenvironments, and the results show that the proposed UniLGL is demonstratively\ncompetitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL\nhas been deployed on diverse platforms, including full-size trucks and agile\nMicro Aerial Vehicles (MAVs), to enable high-precision localization and mapping\nas well as multi-MAV collaborative exploration in port and forest environments,\ndemonstrating the applicability of UniLGL in industrial and field scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12194v2", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-31", "AI": {"title_translation": "UniLGL：学习用于视场受限/全景激光雷达全局定位的统一地点识别", "tldr": "UniLGL是一种统一的激光雷达全局定位方法，通过编码完整的点云信息并引入视角不变性假设，实现了空间、材料和传感器类型统一性，并在实际环境中表现出竞争力。", "motivation": "现有LGL方法通常只考虑激光雷达观测的部分信息（如几何特征），或者专为同质激光雷达传感器设计，忽略了LGL中的统一性问题。", "method": "提出UniLGL方法，通过将包含几何和材料信息的完整点云编码成一对BEV图像（空间BEV图像和强度BEV图像）。设计了一个端到端的多BEV融合网络来提取统一特征。引入视角不变性假设以确保异构激光雷达传感器之间的鲁棒LGL，取代了现有LPR网络中常用的平移等变假设。基于2D BEV图像上局部特征与点云之间的映射，推导出一个鲁棒的全局姿态估计器，无需额外配准即可确定SE(3)上的全局姿态最小值。", "result": "在真实世界环境中进行了广泛的基准测试，结果表明UniLGL与现有最先进的LGL方法相比具有显著竞争力。UniLGL已部署在全尺寸卡车和敏捷微型飞行器（MAVs）等不同平台上，实现了高精度定位和建图以及多MAV协同探索，证明了其在工业和野外场景中的适用性。", "conclusion": "UniLGL是一种有效的统一激光雷达全局定位方法，能够解决现有方法的局限性，并在多种实际应用场景中展现出强大的性能和泛化能力。", "translation": "现有LGL方法通常只考虑激光雷达观测的部分信息（例如几何特征）或专为同质激光雷达传感器设计，忽视了LGL中的统一性。在这项工作中，提出了一种名为UniLGL的统一LGL方法，该方法同时实现了空间和材料统一性，以及传感器类型统一性。该方法的关键思想是将包含几何和材料信息的完整点云编码成一对BEV图像（即空间BEV图像和强度BEV图像）。设计了一个端到端的多BEV融合网络来提取统一特征，使UniLGL具备空间和材料统一性。为了确保异构激光雷达传感器之间的鲁棒LGL，引入了视角不变性假设，该假设取代了现有LPR网络中常用的平移等变假设，并监督UniLGL在全局描述符和局部特征表示中实现传感器类型统一性。最后，基于2D BEV图像上局部特征与点云之间的映射，推导出一个鲁棒的全局姿态估计器，该估计器无需额外配准即可确定SE(3)上的全局姿态最小值。为了验证所提出的统一LGL的有效性，在真实世界环境中进行了广泛的基准测试，结果表明所提出的UniLGL与现有最先进的LGL方法相比具有显著竞争力。此外，UniLGL已部署在包括全尺寸卡车和敏捷微型飞行器（MAVs）在内的多种平台上，以实现在港口和森林环境中的高精度定位和建图以及多MAV协同探索，展示了UniLGL在工业和野外场景中的适用性。", "summary": "本文提出了一种名为UniLGL的统一激光雷达全局定位（LGL）方法，旨在解决现有LGL方法在信息利用不完整和传感器类型同质性方面的局限。UniLGL通过将完整的点云（包含几何和材料信息）编码为空间和强度BEV图像，并利用一个多BEV融合网络提取统一特征，实现了空间和材料的统一性。此外，引入视角不变性假设，确保了异构激光雷达传感器间的鲁棒性。该方法还包含一个无需额外配准的全局姿态估计器。实验证明，UniLGL在真实世界环境中表现出竞争力，并成功应用于多种平台和场景。", "keywords": "激光雷达全局定位, 地点识别, 统一性, BEV图像, 视角不变性", "comments": "本文的创新点在于提出了一个统一的LGL框架，通过引入视角不变性假设和利用点云的完整信息（几何和材料），解决了现有方法在传感器异构性和信息利用不足方面的局限。其在多种平台和实际场景中的部署验证了其鲁棒性和实用性，对未来LGL技术的发展具有重要意义。"}}
{"id": "2507.23220", "title": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "authors": ["Carolina Zheng", "Nicolas Beltran-Velez", "Sweta Karlekar", "Claudia Shi", "Achille Nazaret", "Asif Mallik", "Amir Feder", "David M. Blei"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23220v1", "summary": "Traditional topic models are effective at uncovering latent themes in large\ntext collections. However, due to their reliance on bag-of-words\nrepresentations, they struggle to capture semantically abstract features. While\nsome neural variants use richer representations, they are similarly constrained\nby expressing topics as word lists, which limits their ability to articulate\ncomplex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic\nmodels that operate on interpretable features learned by sparse autoencoders\n(SAEs). By defining topics over this semantically rich space, MTMs can reveal\ndeeper conceptual themes with expressive feature descriptions. Moreover,\nuniquely among topic models, MTMs enable controllable text generation using\ntopic-based steering vectors. To properly evaluate MTM topics against\nword-list-based approaches, we propose \\textit{topic judge}, an LLM-based\npairwise comparison evaluation framework. Across five datasets, MTMs match or\nexceed traditional and neural baselines on coherence metrics, are consistently\npreferred by topic judge, and enable effective steering of LLM outputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23220v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "建模方向，而非词语：使用稀疏自编码器的机制主题模型", "tldr": "提出机制主题模型（MTMs），利用稀疏自编码器学习的特征来捕捉更深层次的主题，并能实现可控文本生成，优于传统和神经主题模型。", "motivation": "传统主题模型和部分神经变体因依赖词袋表示或将主题表达为词列表，难以捕捉语义抽象特征和阐明复杂主题。", "method": "引入机制主题模型（MTMs），它在稀疏自编码器（SAEs）学习的可解释特征上运行，通过在语义丰富的空间中定义主题来揭示更深层次的概念主题。此外，MTMs还支持使用基于主题的转向向量进行可控文本生成。为评估MTMs，提出了一个基于LLM的成对比较评估框架“topic judge”。", "result": "在五个数据集上，MTMs在一致性指标上与传统和神经基线模型持平或超越，并始终获得“topic judge”的偏好，同时能够有效引导大型语言模型（LLM）的输出。", "conclusion": "机制主题模型（MTMs）通过利用稀疏自编码器学习的语义丰富特征，能够比传统和神经方法更好地揭示深层概念主题，并支持可控文本生成，这在评估中得到了验证。", "translation": "标题：建模方向，而非词语：使用稀疏自编码器的机制主题模型\n\n摘要：\n传统主题模型在发现大量文本集合中的潜在主题方面是有效的。然而，由于它们依赖词袋表示，难以捕捉语义抽象特征。虽然一些神经变体使用更丰富的表示，但它们同样受限于将主题表达为词列表，这限制了它们阐明复杂主题的能力。我们引入了机制主题模型（Mechanistic Topic Models, MTMs），这是一类在稀疏自编码器（SAEs）学习到的可解释特征上运行的主题模型。通过在这个语义丰富的空间中定义主题，MTMs可以揭示具有表达性特征描述的更深层次的概念主题。此外，MTMs在主题模型中独树一帜，能够使用基于主题的转向向量实现可控文本生成。为了正确评估MTM主题与基于词列表的方法，我们提出了“topic judge”，一个基于大型语言模型（LLM）的成对比较评估框架。在五个数据集上，MTMs在一致性指标上与传统和神经基线模型持平或超越，并始终获得“topic judge”的偏好，同时能够有效引导大型语言模型（LLM）的输出。", "summary": "本文提出了机制主题模型（MTMs），旨在克服传统和神经主题模型在捕捉语义抽象和复杂主题方面的局限。MTMs通过利用稀疏自编码器（SAEs）学习到的可解释且语义丰富的特征来定义主题，从而能够揭示更深层次的概念。此外，MTMs支持使用主题转向向量进行可控文本生成。为评估MTMs的有效性，研究引入了基于LLM的“topic judge”评估框架。实验结果表明，MTMs在多个数据集上的一致性表现优于或媲美现有基线模型，并获得了“topic judge”的青睐，同时在引导LLM输出方面表现出色。", "keywords": "机制主题模型, 稀疏自编码器, 可控文本生成, 主题评估, 大型语言模型", "comments": "这篇论文的创新点在于将稀疏自编码器（SAEs）引入主题建模，从而使模型能够操作于更具语义丰富性和可解释性的特征空间，而非传统的词袋或词列表表示。这解决了现有主题模型难以捕捉抽象和复杂主题的痛点。此外，MTMs支持可控文本生成是一个重要突破，为主题模型提供了新的应用潜力。引入LLM作为“topic judge”进行评估也是一个新颖且有前景的方法，有助于更全面地评价主题质量。"}}
{"id": "2504.16283", "title": "Affect Models Have Weak Generalizability to Atypical Speech", "authors": ["Jaya Narain", "Amrit Romana", "Vikramjit Mitra", "Colin Lea", "Shirley Ren"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2504.16283v2", "summary": "Speech and voice conditions can alter the acoustic properties of speech,\nwhich could impact the performance of paralinguistic models for affect for\npeople with atypical speech. We evaluate publicly available models for\nrecognizing categorical and dimensional affect from speech on a dataset of\natypical speech, comparing results to datasets of typical speech. We\ninvestigate three dimensions of speech atypicality: intelligibility, which is\nrelated to pronounciation; monopitch, which is related to prosody, and\nharshness, which is related to voice quality. We look at (1) distributional\ntrends of categorical affect predictions within the dataset, (2) distributional\ncomparisons of categorical affect predictions to similar datasets of typical\nspeech, and (3) correlation strengths between text and speech predictions for\nspontaneous speech for valence and arousal. We find that the output of affect\nmodels is significantly impacted by the presence and degree of speech\natypicalities. For instance, the percentage of speech predicted as sad is\nsignificantly higher for all types and grades of atypical speech when compared\nto similar typical speech datasets. In a preliminary investigation on improving\nrobustness for atypical speech, we find that fine-tuning models on\npseudo-labeled atypical speech data improves performance on atypical speech\nwithout impacting performance on typical speech. Our results emphasize the need\nfor broader training and evaluation datasets for speech emotion models, and for\nmodeling approaches that are robust to voice and speech differences.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2504.16283v2", "cate": "cs.LG", "date": "2025-04-22", "updated": "2025-07-30", "AI": {"title_translation": "情感模型对非典型语音的泛化能力较弱", "tldr": "情感模型在非典型语音上表现不佳，需要更广泛的数据集和鲁棒的模型。", "motivation": "语音和声音条件会改变语音的声学特性，这可能会影响非典型语音人群的情感副语言模型的性能。", "method": "评估了公开可用的语音情感识别模型在非典型语音数据集上的表现，并与典型语音数据集进行比较。研究了语音非典型性的三个维度：可懂度、单调性和粗糙度。分析了分类情感预测的分布趋势、与典型语音数据集的分布比较，以及文本和语音预测在自发语音中效价和唤醒度之间的相关强度。初步探索了通过对伪标记的非典型语音数据进行微调来提高鲁棒性。", "result": "情感模型的输出受语音非典型性存在和程度的显著影响。例如，与类似的典型语音数据集相比，所有类型和等级的非典型语音中被预测为悲伤的语音百分比显著更高。初步研究发现，对伪标记的非典型语音数据进行微调可以提高模型在非典型语音上的性能，而不影响其在典型语音上的性能。", "conclusion": "结果强调了语音情感模型需要更广泛的训练和评估数据集，以及对声音和语音差异具有鲁棒性的建模方法。", "translation": "语音和声音条件会改变语音的声学特性，这可能会影响非典型语音人群的情感副语言模型的性能。我们评估了公开可用的语音情感识别模型在非典型语音数据集上的表现，并将其结果与典型语音数据集进行了比较。我们研究了语音非典型性的三个维度：可懂度（与发音相关）、单调性（与语调相关）和粗糙度（与音质相关）。我们关注 (1) 数据集中分类情感预测的分布趋势，(2) 分类情感预测与类似典型语音数据集的分布比较，以及 (3) 自发语音中文本和语音预测在效价和唤醒度之间相关强度。我们发现情感模型的输出受到语音非典型性存在和程度的显著影响。例如，与类似的典型语音数据集相比，所有类型和等级的非典型语音中被预测为悲伤的语音百分比显著更高。在初步探索提高非典型语音鲁棒性方面，我们发现对伪标记的非典型语音数据进行微调可以提高模型在非典型语音上的性能，而不影响其在典型语音上的性能。我们的结果强调了语音情感模型需要更广泛的训练和评估数据集，以及对声音和语音差异具有鲁棒性的建模方法。", "summary": "本研究评估了现有情感模型在非典型语音上的泛化能力。通过比较非典型语音和典型语音数据集，研究发现语音非典型性（如可懂度、单调性和粗糙度）显著影响情感模型的输出，导致对非典型语音的预测偏差，例如“悲伤”预测的比例异常高。初步结果表明，通过对伪标记的非典型语音数据进行微调，可以有效提高模型在非典型语音上的鲁棒性，同时不损害其在典型语音上的表现。研究强调了为语音情感模型构建更广泛、更具鲁棒性的训练和评估数据集的重要性。", "keywords": "情感模型, 非典型语音, 泛化能力, 语音情感识别, 微调", "comments": "这项研究通过系统评估现有情感模型在非典型语音上的表现，揭示了这些模型在实际应用中可能存在的泛化能力不足问题，特别是在处理具有发音、语调或音质异常的语音时。其创新之处在于明确指出了非典型语音对情感模型性能的负面影响，并初步探索了通过数据微调来提高鲁棒性的可行性。这对于推动语音情感识别技术向更广泛、更具包容性的应用场景发展具有重要意义。"}}
{"id": "2507.22972", "title": "Complexity-energy trade-off in programmable unitary interferometers", "authors": ["Nikita A. Nemkov", "Stanislav S. Straupe"], "categories": ["physics.optics", "cs.ET"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.22972v1", "summary": "Coherent multiport interferometers are a promising approach to realize matrix\nmultiplication in integrated photonics. However, most known architectures -\nsuch as MZI and beamsplitter meshes, as well as more general interferometers -\nsuffer from complicated procedures for mapping the matrix elements of the\ndesired transformation to specific phaseshifts in the device. We point out that\nthe high programming complexity is intrinsic, rather than accidental. At the\nsame time, we argue that interferometers admitting efficient programming\nalgorithms in general yield a much lower useful output energy, which ultimately\nlimits their accuracy and energy efficiency.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.22972v1", "cate": "physics.optics", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "可编程酉干涉仪中的复杂性-能量权衡", "tldr": "可编程干涉仪的编程复杂性是固有的，并且与输出能量、精度和能效之间存在权衡。", "motivation": "现有的相干多端口干涉仪（如MZI和分束器阵列）在将所需变换的矩阵元素映射到器件中的特定相移时，存在复杂的编程过程。", "method": "本文指出高编程复杂性是固有的，并论证了具有高效编程算法的干涉仪通常会产生低得多的有用输出能量。", "result": "可编程干涉仪存在固有的高编程复杂性，并且具有高效编程算法的干涉仪通常会导致较低的有用输出能量，从而限制了其精度和能效。", "conclusion": "可编程酉干涉仪中存在固有的复杂性-能量权衡。", "translation": "相干多端口干涉仪是实现集成光子学中矩阵乘法的一种有前景的方法。然而，大多数已知架构——例如MZI和分束器阵列，以及更通用的干涉仪——都面临着将所需变换的矩阵元素映射到器件中特定相移的复杂过程。我们指出高编程复杂性是固有的，而非偶然。同时，我们认为，通常允许高效编程算法的干涉仪会产生低得多的有用输出能量，这最终限制了它们的精度和能效。", "summary": "本研究指出，相干多端口干涉仪在实现矩阵乘法时面临固有的高编程复杂性，这并非偶然。文章进一步论证，那些支持高效编程算法的干涉仪，往往会牺牲有用的输出能量，从而限制了其精度和能效。这揭示了可编程酉干涉仪中复杂性与能量之间存在一种内在的权衡关系。", "keywords": "可编程干涉仪, 复杂性, 能量权衡, 集成光子学, 矩阵乘法", "comments": "该论文揭示了可编程干涉仪设计中的一个基本限制，即编程复杂性与输出能量/效率之间的固有权衡。这一发现对于未来集成光子学器件的设计和优化具有重要指导意义，有助于研究人员在设计时更好地平衡性能与可编程性。"}}
{"id": "2507.23303", "title": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "authors": ["Luca Corbucci", "Javier Alejandro Borges Legrottaglie", "Francesco Spinnato", "Anna Monreale", "Riccardo Guidotti"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23303v1", "summary": "Accurately identifying items forgotten during a supermarket visit and\nproviding clear, interpretable explanations for recommending them remains an\nunderexplored problem within the Next Basket Prediction (NBP) domain. Existing\nNBP approaches typically only focus on forecasting future purchases, without\nexplicitly addressing the detection of unintentionally omitted items. This gap\nis partly due to the scarcity of real-world datasets that allow for the\nreliable estimation of forgotten items. Furthermore, most current NBP methods\nrely on black-box models, which lack transparency and limit the ability to\njustify recommendations to end users. In this paper, we formally introduce the\nforgotten item prediction task and propose two novel interpretable-by-design\nalgorithms. These methods are tailored to identify forgotten items while\noffering intuitive, human-understandable explanations. Experiments on a\nreal-world retail dataset show our algorithms outperform state-of-the-art NBP\nbaselines by 10-15% across multiple evaluation metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23303v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一种可解释的、数据驱动的无监督方法，用于防止遗忘物品", "tldr": "本文提出了一种可解释的无监督方法，用于预测超市购物中遗忘的商品，并取得了比现有方法更好的性能。", "motivation": "现有下一购物篮预测（NBP）方法未能明确解决无意遗漏物品的检测问题，且缺乏可解释性，同时用于可靠估计遗忘物品的真实世界数据集稀缺。", "method": "本文正式引入了遗忘物品预测任务，并提出了两种新颖的、设计上可解释的算法，旨在识别遗忘物品并提供直观、人类可理解的解释。", "result": "在真实世界零售数据集上的实验表明，所提出的算法在多项评估指标上比最先进的NBP基线提高了10-15%。", "conclusion": "本文提出的可解释的无监督算法能够有效识别遗忘物品，并在性能上超越了现有的NBP方法，解决了该领域中可解释性和遗忘物品检测的挑战。", "translation": "准确识别超市购物中遗忘的物品，并为推荐这些物品提供清晰、可解释的解释，在下一购物篮预测（NBP）领域仍然是一个未充分探索的问题。现有的NBP方法通常只关注预测未来的购买，而没有明确解决无意遗漏物品的检测。这一差距部分是由于缺乏允许可靠估计遗忘物品的真实世界数据集。此外，大多数当前的NBP方法依赖于黑盒模型，这些模型缺乏透明度，限制了向最终用户解释推荐的能力。在本文中，我们正式引入了遗忘物品预测任务，并提出了两种新颖的、设计上可解释的算法。这些方法旨在识别遗忘物品，同时提供直观、人类可理解的解释。在真实世界零售数据集上的实验表明，我们的算法在多项评估指标上比最先进的NBP基线提高了10-15%。", "summary": "本文针对下一购物篮预测（NBP）领域中遗忘物品识别及其可解释性不足的问题，正式定义了遗忘物品预测任务。作者提出了两种新颖的、设计上可解释的无监督算法，旨在准确识别购物中遗漏的商品，并提供直观的解释。实验结果显示，这些算法在真实零售数据集上，性能优于现有NBP基线10-15%。", "keywords": "遗忘物品预测, 可解释性, 无监督学习, 下一购物篮预测, 零售数据", "comments": "这篇论文的创新点在于首次明确提出了“遗忘物品预测”这一新任务，并针对性地开发了可解释的无监督算法。这解决了现有NBP模型在检测无意遗漏物品和提供透明解释方面的不足。其在真实世界数据集上的显著性能提升，表明了该方法在零售领域具有重要的应用潜力。"}}
{"id": "2507.23568", "title": "Optimised Feature Subset Selection via Simulated Annealing", "authors": ["Fernando Martínez-García", "Álvaro Rubio-García", "Samuel Fernández-Lorenzo", "Juan José García-Ripoll", "Diego Porras"], "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2507.23568v1", "summary": "We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.23568v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于模拟退火的优化特征子集选择", "tldr": "SA-FDR是一种新颖的基于模拟退火的ℓ0范数特征选择算法，它通过全局搜索选择更紧凑且信息丰富的特征子集，同时保持高预测精度，适用于高维可解释模型。", "motivation": "在分类任务中，需要一种能够选择紧凑且具有预测准确性的特征子集的方法，特别是在高维设置中，且需要模型稀疏性、可解释性和性能。", "method": "SA-FDR算法将ℓ0范数特征选择视为组合优化问题，并使用模拟退火进行全局搜索特征子集空间。优化过程由Fisher判别比率指导，该比率作为分类任务中模型质量的计算高效代理。", "result": "SA-FDR在包含数十万样本和数百个特征的数据集上进行实验，结果表明它始终能选择更紧凑的特征子集，同时实现高预测精度。它能够捕获特征间依赖性，这是贪婪优化方法常常遗漏的。", "conclusion": "SA-FDR为高维设置中设计可解释模型提供了一种灵活有效的解决方案，尤其是在模型稀疏性、可解释性和性能至关重要的情况下。", "translation": "我们引入了SA-FDR，这是一种新颖的ℓ0范数特征选择算法，它将此任务视为组合优化问题，并通过使用模拟退火对特征子集空间进行全局搜索来解决。优化由Fisher判别比率指导，我们将其用作分类任务中模型质量的计算高效代理。我们的实验在包含多达数十万样本和数百个特征的数据集上进行，结果表明SA-FDR始终能选择更紧凑的特征子集，同时实现高预测精度。这种恢复信息丰富但最小特征集的能力源于其捕获特征间依赖性的能力，而这通常是贪婪优化方法所遗漏的。因此，SA-FDR为在高维设置中设计可解释模型提供了一种灵活有效的解决方案，尤其是在模型稀疏性、可解释性和性能至关重要时。", "summary": "SA-FDR是一种新颖的ℓ0范数特征选择算法，它将特征选择视为组合优化问题，并利用模拟退火进行全局搜索。该算法以Fisher判别比率为指导，旨在高效选择紧凑且信息丰富的特征子集。实验证明，SA-FDR在大型数据集上能够选出更小的特征集，同时保持高预测精度，尤其擅长捕获特征间依赖性，从而在高维环境中为可解释模型的构建提供了一种有效且灵活的方案。", "keywords": "特征选择, 模拟退火, ℓ0范数, Fisher判别比率, 可解释模型", "comments": "SA-FDR的创新之处在于将模拟退火应用于ℓ0范数特征选择，并通过全局搜索避免了贪婪方法可能遗漏的特征间依赖性。其重要性在于提供了一种在高维数据中兼顾模型稀疏性、可解释性和预测性能的有效方法。"}}
{"id": "2507.23478", "title": "3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding", "authors": ["Ting Huang", "Zeyu Zhang", "Hao Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23478v1", "summary": "Large vision-language models (VLMs) have made significant strides in 2D\nvisual understanding tasks, sparking interest in extending these capabilities\nto 3D scene understanding. However, current 3D VLMs often struggle with robust\nreasoning and generalization due to limitations in high-quality spatial data\nand the static nature of viewpoint assumptions. To address these challenges, we\npropose 3D-R1, a foundation model that enhances the reasoning capabilities of\n3D VLMs. Specifically, we first construct a high-quality synthetic dataset with\nCoT, named Scene-30K, leveraging existing 3D-VL datasets and a data engine\nbased on Gemini 2.5 Pro. It serves as cold-start initialization data for 3D-R1.\nMoreover, we leverage RLHF policy such as GRPO in the reinforcement learning\ntraining process to enhance reasoning capabilities and introduce three reward\nfunctions: a perception reward, a semantic similarity reward and a format\nreward to maintain detection accuracy and answer semantic precision.\nFurthermore, we introduce a dynamic view selection strategy that adaptively\nchooses the most informative perspectives for 3D scene understanding. Extensive\nexperiments demonstrate that 3D-R1 delivers an average improvement of 10%\nacross various 3D scene benchmarks, highlighting its effectiveness in enhancing\nreasoning and generalization in 3D scene understanding. Code:\nhttps://github.com/AIGeeksGroup/3D-R1. Website:\nhttps://aigeeksgroup.github.io/3D-R1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23478v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "3D-R1：增强3D VLM的推理能力以实现统一场景理解", "tldr": "提出3D-R1模型，通过构建高质量数据集、强化学习和动态视角选择，显著提升3D VLM在场景理解中的推理和泛化能力。", "motivation": "现有3D VLM在鲁棒推理和泛化方面存在困难，原因是高质量空间数据不足和视角假设的静态性。", "method": "本文提出了3D-R1基础模型。具体方法包括：1) 构建高质量的合成数据集Scene-30K（利用现有3D-VL数据集和Gemini 2.5 Pro数据引擎）作为冷启动初始化数据。2) 在强化学习训练过程中利用GRPO等RLHF策略，并引入感知奖励、语义相似度奖励和格式奖励三种奖励函数，以增强推理能力并保持检测准确性和答案语义精度。3) 引入动态视角选择策略，自适应选择最具信息量的视角进行3D场景理解。", "result": "3D-R1在各种3D场景基准测试中平均提升了10%的性能。", "conclusion": "3D-R1有效增强了3D场景理解中的推理和泛化能力。", "translation": "大型视觉-语言模型（VLM）在2D视觉理解任务中取得了显著进展，激发了将这些能力扩展到3D场景理解的兴趣。然而，当前的3D VLM由于高质量空间数据的限制和视角假设的静态性质，在鲁棒推理和泛化方面常常遇到困难。为了解决这些挑战，我们提出了3D-R1，一个增强3D VLM推理能力的基础模型。具体来说，我们首先利用现有3D-VL数据集和基于Gemini 2.5 Pro的数据引擎，构建了一个高质量的带有CoT的合成数据集，命名为Scene-30K。它作为3D-R1的冷启动初始化数据。此外，我们在强化学习训练过程中利用GRPO等RLHF策略来增强推理能力，并引入了三种奖励函数：感知奖励、语义相似度奖励和格式奖励，以保持检测准确性和答案语义精度。此外，我们引入了一种动态视角选择策略，自适应地选择最具信息量的视角进行3D场景理解。广泛的实验表明，3D-R1在各种3D场景基准测试中平均提升了10%，突出了其在增强3D场景理解中的推理和泛化方面的有效性。代码：https://github.com/AIGeeksGroup/3D-R1。网站：https://aigeeksgroup.github.io/3D-R1。", "summary": "本文提出了3D-R1，一个旨在增强3D视觉-语言模型（VLM）推理能力的基础模型。为解决现有3D VLM在推理和泛化上的局限，3D-R1首先构建了高质量合成数据集Scene-30K进行冷启动初始化。接着，通过引入RLHF策略（如GRPO）和三种奖励函数（感知、语义相似度、格式奖励）来提升推理能力和精度。此外，模型还采用了动态视角选择策略。实验结果显示，3D-R1在多个3D场景基准测试中平均性能提升了10%，证明了其在3D场景理解中增强推理和泛化的有效性。", "keywords": "3D VLM, 场景理解, 推理, 强化学习, 动态视角选择", "comments": "3D-R1的创新点在于结合了高质量合成数据生成（利用Gemini 2.5 Pro）、强化学习（RLHF及多奖励函数）以及动态视角选择策略，系统性地解决了3D VLM在推理和泛化方面的痛点。其在3D场景理解中取得的显著性能提升（平均10%）证明了其重要性，为未来3D VLM的发展提供了有益的探索方向。"}}
{"id": "2507.23554", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23554v1", "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23554v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DICE：通过高效知识迁移在LLM代理中动态上下文示例选择", "tldr": "DICE是一个理论基础的框架，用于LLM代理中动态选择上下文示例，它通过分解可迁移和不可迁移知识来提高代理性能，无需额外训练即可作为插件集成。", "motivation": "现有的大语言模型代理中的上下文学习（ICL）对示例选择高度敏感，次优示例会导致性能不稳定或下降。现有方法依赖启发式或特定任务设计，缺乏通用的、有理论基础的有效演示选择标准，难以开发出普适且持续提升代理性能的方法。", "method": "本文提出了DICE，一个理论基础的上下文学习框架，用于在推理的每一步选择最相关的演示。它通过因果视角将演示知识分解为可迁移和不可迁移的组件，并提出了一个分步选择标准，该标准具有改进代理性能的形式保证。DICE是一个通用且与框架无关的解决方案，可以作为插件模块集成到现有代理框架中，无需额外训练成本。", "result": "在不同领域的广泛实验表明，DICE方法是有效的和通用的，强调了有原则、上下文感知的演示选择对于鲁棒和高效的LLM代理的重要性。", "conclusion": "DICE提供了一个理论基础的、通用且无需额外训练的解决方案，用于LLM代理中动态选择上下文示例，显著提高了代理性能和鲁棒性。", "translation": "大型语言模型代理，在上下文学习（ICL）的赋能下，在复杂推理和工具使用任务中展现出强大的能力。然而，现有工作表明，ICL的有效性对演示的选择高度敏感，次优示例常常导致不稳定或性能下降。尽管先前的研究探索了示例选择，包括在某些代理或多步设置中，但现有方法通常依赖启发式或特定任务设计，缺乏一个通用的、具有理论基础的准则来确定在推理步骤中什么是有效的演示。因此，开发一种有原则的、通用目的的方法来选择持续有益于代理性能的演示并非易事。在本文中，我们通过DICE（LLM代理中的动态上下文示例选择）解决了这一挑战，DICE是一个有理论基础的ICL框架，用于代理任务，它在推理的每一步选择最相关的演示。我们的方法通过因果视角将演示知识分解为可迁移和不可迁移的组件，展示了后者如何引入虚假依赖，从而损害泛化能力。我们进一步提出了一个分步选择标准，并对代理性能的提升提供了形式保证。重要的是，DICE是一个通用、与框架无关的解决方案，可以作为一个插件模块集成到现有代理框架中，无需任何额外的训练成本。跨不同领域的广泛实验证明了我们方法的有效性和通用性，突出了有原则、上下文感知的演示选择对于鲁棒和高效的LLM代理的重要性。", "summary": "本文提出DICE（LLM代理中的动态上下文示例选择），这是一个理论基础的上下文学习框架，旨在解决现有LLM代理中上下文学习对示例选择敏感且缺乏通用选择标准的问题。DICE通过因果视角将演示知识分解为可迁移和不可迁移部分，并提供了一个具有性能保证的分步选择标准，以在推理的每一步选择最相关的演示。作为一个通用且无需额外训练的插件模块，DICE已在多领域实验中验证了其有效性和通用性，强调了原则性示例选择对提升LLM代理性能的重要性。", "keywords": "LLM代理, 上下文学习, 示例选择, 知识迁移, 动态选择", "comments": "DICE的创新点在于其理论基础的示例选择方法，通过因果视角分解知识，并提供了性能保证。其作为一个无需额外训练的通用插件模块，大大降低了集成成本，对提升LLM代理的鲁棒性和效率具有重要意义。"}}
{"id": "2311.18266", "title": "Prompt-Based Exemplar Super-Compression and Regeneration for Class-Incremental Learning", "authors": ["Ruxiao Duan", "Jieneng Chen", "Adam Kortylewski", "Alan Yuille", "Yaoyao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      BMVC 2025. Code: this https URL", "url": "http://arxiv.org/abs/2311.18266v3", "summary": "Replay-based methods in class-incremental learning (CIL) have attained\nremarkable success. Despite their effectiveness, the inherent memory\nrestriction results in saving a limited number of exemplars with poor\ndiversity. In this paper, we introduce PESCR, a novel approach that\nsubstantially increases the quantity and enhances the diversity of exemplars\nbased on a pre-trained general-purpose diffusion model, without fine-tuning it\non target datasets or storing it in the memory buffer. Images are compressed\ninto visual and textual prompts, which are saved instead of the original\nimages, decreasing memory consumption by a factor of 24. In subsequent phases,\ndiverse exemplars are regenerated by the diffusion model. We further propose\npartial compression and diffusion-based data augmentation to minimize the\ndomain gap between generated exemplars and real images. PESCR significantly\nimproves CIL performance across multiple benchmarks, e.g., 3.2% above the\nprevious state-of-the-art on ImageNet-100.", "comment": "BMVC 2025. Code: https://github.com/KerryDRX/PESCR", "pdf_url": "http://arxiv.org/pdf/2311.18266v3", "cate": "cs.CV", "date": "2023-11-30", "updated": "2025-07-31", "AI": {"title_translation": "基于提示的样本超压缩和再生用于类增量学习", "tldr": "PESCR通过将图像超压缩为提示并使用预训练扩散模型再生多样化样本，解决了类增量学习中回放方法内存限制和样本多样性不足的问题，显著提升了性能。", "motivation": "类增量学习（CIL）中的回放方法虽然有效，但受限于内存，导致保存的样本数量有限且多样性差。", "method": "本文提出了PESCR方法，将图像压缩为视觉和文本提示并保存，而非原始图像，从而将内存消耗降低了24倍。随后，通过预训练的通用扩散模型再生多样化的样本。此外，还提出了部分压缩和基于扩散的数据增强，以最小化生成样本与真实图像之间的域差距。", "result": "内存消耗降低了24倍。在多个基准测试中显著提升了CIL性能，例如在ImageNet-100上比之前的最先进水平高出3.2%。", "conclusion": "PESCR通过创新的样本超压缩和再生机制，有效解决了类增量学习中回放方法的内存限制和样本多样性问题，从而显著提升了CIL的性能。", "translation": "类增量学习（CIL）中的回放方法取得了显著成功。尽管它们有效，但固有的内存限制导致只能保存数量有限且多样性差的样本。在本文中，我们引入了PESCR，这是一种新颖的方法，它基于预训练的通用扩散模型，显著增加了样本的数量并增强了其多样性，而无需在目标数据集上对其进行微调或将其存储在内存缓冲区中。图像被压缩成视觉和文本提示，这些提示被保存而不是原始图像，从而将内存消耗降低了24倍。在随后的阶段，通过扩散模型再生多样化的样本。我们进一步提出了部分压缩和基于扩散的数据增强，以最小化生成样本与真实图像之间的域差距。PESCR显著提高了多个基准测试上的CIL性能，例如在ImageNet-100上比之前的最先进水平高出3.2%。", "summary": "PESCR是一种新颖的类增量学习方法，旨在解决回放方法中内存限制和样本多样性不足的问题。它通过将图像超压缩为视觉和文本提示来大幅减少内存占用（24倍），并利用预训练的扩散模型再生多样化样本。该方法还引入了部分压缩和扩散数据增强来缩小生成样本与真实图像之间的域差距，在多个基准测试中显著提升了CIL性能。", "keywords": "类增量学习, 样本回放, 扩散模型, 提示压缩, 数据增强", "comments": "该论文创新性地将基于提示的超压缩与扩散模型相结合，用于类增量学习中的样本管理，有效解决了内存限制和样本多样性这一关键挑战。24倍的内存减少和显著的性能提升是其重要贡献。此外，无需对预训练模型进行微调也体现了其高效性。"}}
{"id": "2507.23226", "title": "Toward Safe, Trustworthy and Realistic Augmented Reality User Experience", "authors": ["Yanming Xiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      2 pages, 4 figures", "url": "http://arxiv.org/abs/2507.23226v1", "summary": "As augmented reality (AR) becomes increasingly integrated into everyday life,\nensuring the safety and trustworthiness of its virtual content is critical. Our\nresearch addresses the risks of task-detrimental AR content, particularly that\nwhich obstructs critical information or subtly manipulates user perception. We\ndeveloped two systems, ViDDAR and VIM-Sense, to detect such attacks using\nvision-language models (VLMs) and multimodal reasoning modules. Building on\nthis foundation, we propose three future directions: automated, perceptually\naligned quality assessment of virtual content; detection of multimodal attacks;\nand adaptation of VLMs for efficient and user-centered deployment on AR\ndevices. Overall, our work aims to establish a scalable, human-aligned\nframework for safeguarding AR experiences and seeks feedback on perceptual\nmodeling, multimodal AR content implementation, and lightweight model\nadaptation.", "comment": "2 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.23226v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "迈向安全、可信和真实的增强现实用户体验", "tldr": "本研究开发了系统来检测增强现实（AR）中阻碍关键信息或操纵用户感知的有害内容，并提出了未来研究方向，旨在建立保护AR体验的安全框架。", "motivation": "随着增强现实（AR）日益融入日常生活，确保其虚拟内容的安全性和可信度至关重要。本研究旨在解决有害的AR内容带来的风险，特别是那些阻碍关键信息或微妙操纵用户感知的AR内容。", "method": "研究开发了ViDDAR和VIM-Sense两个系统，利用视觉-语言模型（VLMs）和多模态推理模块来检测有害的AR内容攻击。", "result": "开发了ViDDAR和VIM-Sense两个系统，用于检测阻碍关键信息或微妙操纵用户感知的有害AR内容攻击。", "conclusion": "本研究旨在建立一个可扩展、以人为本的框架，以保护增强现实体验，并寻求关于感知建模、多模态AR内容实现和轻量级模型适应性的反馈。", "translation": "随着增强现实（AR）日益融入日常生活，确保其虚拟内容的安全性和可信度至关重要。我们的研究解决了有害的AR内容带来的风险，特别是那些阻碍关键信息或微妙操纵用户感知的AR内容。我们开发了ViDDAR和VIM-Sense两个系统，利用视觉-语言模型（VLMs）和多模态推理模块来检测此类攻击。在此基础上，我们提出了三个未来方向：虚拟内容的自动化、感知对齐的质量评估；多模态攻击的检测；以及为在AR设备上高效、以用户为中心部署而对VLM进行适应。总的来说，我们的工作旨在建立一个可扩展、以人为本的框架，以保护AR体验，并寻求关于感知建模、多模态AR内容实现和轻量级模型适应性的反馈。", "summary": "本研究探讨了增强现实（AR）中虚拟内容的安全性和可信度问题，特别关注有害内容（如阻碍信息或操纵感知）带来的风险。研究开发了ViDDAR和VIM-Sense系统，利用视觉-语言模型和多模态推理模块来检测此类攻击。此外，论文还提出了未来研究方向，包括自动化质量评估、多模态攻击检测以及VLM在AR设备上的高效部署，旨在构建一个保护AR体验的可扩展、以人为本的框架。", "keywords": "增强现实, 安全性, 可信度, 视觉-语言模型, 多模态推理", "comments": "这项工作通过开发具体的系统来解决AR内容的安全和信任问题，具有重要意义，尤其是在AR日益普及的背景下。其创新点在于利用视觉-语言模型和多模态推理来检测有害内容，并提出了未来研究方向，为构建安全的AR生态系统奠定了基础。"}}
{"id": "2507.23315", "title": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "authors": ["Vineet Kumar Rakesh", "Soumya Mazumdar", "Tapas Samanta", "Sarbajit Pal", "Amitabha Das"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 4 figures, 4 tables. Includes ablation study and evaluation on 7 lightweight deep learning models. Code and logs available at this https URL", "url": "http://arxiv.org/abs/2507.23315v1", "summary": "Lightweight convolutional and transformer-based models have become vital for\nreal-time image classification in resource-constrained applications, such as\nembedded systems and edge devices. This work analyzes the influence of\nhyperparameter adjustment on the accuracy and convergence behavior of seven\nefficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT\nv2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are\ntrained on the ImageNet-1K dataset under consistent training settings, with an\nemphasis on real-time practicality. An comprehensive ablation study is\nundertaken to separate the effect of critical hyperparameters, including\nlearning rate schedules, batch sizes, input resolution, data augmentation,\nregularization approaches, and optimizer choice. To assess appropriateness for\nreal-time applications, each model is assessed not only in terms of Top-1 and\nTop-5 classification accuracy, but also in terms of inference time, parameter\ncount, model size, and frames-per-second (FPS) on a GPU-accelerated edge\ndeployment simulation. Results demonstrate that cosine learning rate decay and\nadjustable batch size may greatly boost both accuracy and convergence speed,\nwhile keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80%\nTop-1 accuracy with efficient inference performance, offering a compelling\nbalance between accuracy and deployment cost for VGG-style models. The results\ngive practical guidance for constructing resource-efficient deep learning\nmodels appropriate for real-time image processing pipelines. All code and\ntraining logs are publicly accessible at\nhttps://github.com/VineetKumarRakesh/lcnn-opt.", "comment": "13 pages, 4 figures, 4 tables. Includes ablation study and evaluation\n  on 7 lightweight deep learning models. Code and logs available at\n  https://github.com/VineetKumarRakesh/lcnn-opt", "pdf_url": "http://arxiv.org/pdf/2507.23315v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "超参数优化对轻量级深度学习模型实时图像分类准确性的影响", "tldr": "本研究分析了超参数调整对七种高效轻量级深度学习模型在实时图像分类中准确性和收敛行为的影响，并提供了实用指导。", "motivation": "轻量级深度学习模型在资源受限的嵌入式系统和边缘设备中进行实时图像分类至关重要。本研究旨在分析超参数调整对这些模型准确性和收敛行为的影响。", "method": "本研究分析了EfficientNetV2-S、ConvNeXt-T、MobileViT v2 (XXS/XS/S)、MobileNetV3-L、TinyViT-21M和RepVGG-A2七种轻量级深度学习模型。所有模型均在ImageNet-1K数据集上进行训练，并强调实时实用性。进行了全面的消融研究，以分离关键超参数（包括学习率调度、批大小、输入分辨率、数据增强、正则化方法和优化器选择）的影响。评估指标包括Top-1和Top-5分类准确性、推理时间、参数数量、模型大小以及在GPU加速边缘部署模拟上的FPS。", "result": "结果表明，余弦学习率衰减和可调整的批大小可以显著提高准确性和收敛速度，同时保持低延迟和内存成本。值得注意的是，RepVGG-A2在高效推理性能下实现了超过80%的Top-1准确率，为VGG风格模型提供了准确性和部署成本之间的良好平衡。", "conclusion": "本研究的结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。", "translation": "轻量级卷积和基于Transformer的模型对于资源受限的应用（如嵌入式系统和边缘设备）中的实时图像分类至关重要。这项工作分析了超参数调整对七种高效深度学习架构的准确性和收敛行为的影响：EfficientNetV2-S、ConvNeXt-T、MobileViT v2 (XXS/XS/S)、MobileNetV3-L、TinyViT-21M和RepVGG-A2。所有模型均在ImageNet-1K数据集上以一致的训练设置进行训练，并强调实时实用性。进行了一项全面的消融研究，以分离关键超参数（包括学习率调度、批大小、输入分辨率、数据增强、正则化方法和优化器选择）的影响。为了评估其对实时应用的适用性，每个模型不仅在Top-1和Top-5分类准确性方面进行评估，还在GPU加速边缘部署模拟上的推理时间、参数数量、模型大小和每秒帧数（FPS）方面进行评估。结果表明，余弦学习率衰减和可调整的批大小可以极大地提高准确性和收敛速度，同时保持低延迟和内存成本。值得注意的是，RepVGG-A2在高效推理性能下实现了超过80%的Top-1准确率，为VGG风格模型提供了准确性和部署成本之间的引人注目的平衡。结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。所有代码和训练日志均可在https://github.com/VineetKumarRakesh/lcnn-opt公开访问。", "summary": "本研究探讨了超参数优化对轻量级深度学习模型在资源受限设备上进行实时图像分类准确性和收敛性的影响。通过在ImageNet-1K数据集上对七种模型进行全面的消融研究，分析了学习率、批大小等关键超参数的作用。研究发现，余弦学习率衰减和可调批大小能显著提升模型性能，且RepVGG-A2在保持高效推理的同时实现了高准确率。该研究为开发实时图像处理的资源高效模型提供了实践指导。", "keywords": "超参数优化, 轻量级深度学习, 实时图像分类, 边缘计算, 模型准确性", "comments": "该研究通过对多种轻量级模型进行详细的超参数消融实验，为实际部署提供了宝贵的经验。其创新点在于系统性地评估了超参数对轻量级模型在实时场景下性能的影响，并明确指出了有效的优化策略，如余弦学习率衰减和批大小调整。对于资源受限的边缘计算应用，这项工作具有重要的实践指导意义。"}}
{"id": "2507.21886", "title": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "authors": ["Stefanos Gkikas", "Ioannis Kyprakis", "Manolis Tsiknakis"], "categories": ["cs.AI", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2507.21881 , arXiv:2507.21875", "url": "http://arxiv.org/abs/2507.21886v3", "summary": "Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity.", "comment": "arXiv admin note: text overlap with arXiv:2507.21881,\n  arXiv:2507.21875", "pdf_url": "http://arxiv.org/pdf/2507.21886v3", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "基于呼吸信号的有效疼痛识别：单交叉注意力Transformer多窗口融合管道", "tldr": "该研究提出了一种利用呼吸信号和高效交叉注意力Transformer多窗口融合管道进行疼痛识别的方法，并证明了其有效性和紧凑模型的优越性。", "motivation": "疼痛是一种影响大量人群的复杂状况，准确和持续的评估对于经历疼痛的个体至关重要，并支持有效和先进的管理策略。自动疼痛评估系统可提供持续监测并支持临床决策，旨在减轻痛苦并防止功能下降。", "method": "本研究提出了一种以呼吸信号为输入，并结合高效的交叉注意力Transformer和多窗口策略的管道。该方法已提交至第二届下一代疼痛评估多模态感知挑战赛（AI4PAIN）。", "result": "广泛的实验表明，呼吸是疼痛评估中一种有价值的生理模态。此外，实验揭示，紧凑高效的模型在经过适当优化后可以实现强大的性能，常常超越更大的模型。所提出的多窗口方法有效地捕捉了短期、长期特征以及全局特性，从而增强了模型的表征能力。", "conclusion": "呼吸信号是疼痛评估的有效生理模态，并且通过高效的交叉注意力Transformer和多窗口融合管道，即使是紧凑的模型也能实现优异的疼痛识别性能。", "translation": "疼痛是一种影响大量人群的复杂状况。准确和持续的评估对于经历疼痛的个体至关重要，并支持有效和先进的管理策略。自动疼痛评估系统可提供持续监测并支持临床决策，旨在减轻痛苦并防止功能下降。本研究已提交至第二届下一代疼痛评估多模态感知挑战赛（AI4PAIN）。所提出的方法引入了一个以呼吸作为输入信号的管道，并结合了高效的交叉注意力Transformer以及多窗口策略。广泛的实验表明，呼吸是疼痛评估中一种有价值的生理模态。此外，实验揭示，紧凑高效的模型在经过适当优化后可以实现强大的性能，常常超越更大的模型。所提出的多窗口方法有效地捕捉了短期和长期特征，以及全局特性，从而增强了模型的表征能力。", "summary": "该论文针对疼痛评估的挑战，提出了一种基于呼吸信号的自动疼痛识别系统。核心方法是一个结合了高效交叉注意力Transformer和多窗口融合策略的管道。实验结果表明，呼吸信号是有效的疼痛评估模态，并且所提出的紧凑模型在优化后能达到甚至超越大型模型的性能，多窗口方法有效捕捉了不同尺度的特征，增强了模型能力。", "keywords": "疼痛识别, 呼吸信号, 交叉注意力Transformer, 多窗口融合, 机器学习", "comments": "该研究的创新点在于将呼吸信号作为疼痛识别的主要输入，并结合了高效的交叉注意力Transformer和独特的多窗口融合策略。其重要性在于证明了紧凑模型在适当优化下也能实现高性能，这对于实际部署和资源受限的应用场景具有重要意义。多窗口方法能够全面捕捉特征，提升了模型的泛化能力。"}}
{"id": "2507.23523", "title": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "authors": ["Hongzhe Bi", "Lingxuan Wu", "Tianwei Lin", "Hengkai Tan", "Zhizhong Su", "Hang Su", "Jun Zhu"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23523v1", "summary": "Imitation learning for robotic manipulation faces a fundamental challenge:\nthe scarcity of large-scale, high-quality robot demonstration data. Recent\nrobotic foundation models often pre-train on cross-embodiment robot datasets to\nincrease data scale, while they face significant limitations as the diverse\nmorphologies and action spaces across different robot embodiments make unified\ntraining challenging. In this paper, we present H-RDT (Human to Robotics\nDiffusion Transformer), a novel approach that leverages human manipulation data\nto enhance robot manipulation capabilities. Our key insight is that large-scale\negocentric human manipulation videos with paired 3D hand pose annotations\nprovide rich behavioral priors that capture natural manipulation strategies and\ncan benefit robotic policy learning. We introduce a two-stage training\nparadigm: (1) pre-training on large-scale egocentric human manipulation data,\nand (2) cross-embodiment fine-tuning on robot-specific data with modular action\nencoders and decoders. Built on a diffusion transformer architecture with 2B\nparameters, H-RDT uses flow matching to model complex action distributions.\nExtensive evaluations encompassing both simulation and real-world experiments,\nsingle-task and multitask scenarios, as well as few-shot learning and\nrobustness assessments, demonstrate that H-RDT outperforms training from\nscratch and existing state-of-the-art methods, including Pi0 and RDT, achieving\nsignificant improvements of 13.9% and 40.5% over training from scratch in\nsimulation and real-world experiments, respectively. The results validate our\ncore hypothesis that human manipulation data can serve as a powerful foundation\nfor learning bimanual robotic manipulation policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23523v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "H-RDT：人类操作增强的双臂机器人操作", "tldr": "H-RDT提出了一种新方法，通过利用大规模人类操作视频数据来增强机器人操作能力，解决了机器人模仿学习中数据稀缺的挑战，并在模拟和真实世界中表现出色。", "motivation": "机器人模仿学习面临高质量机器人演示数据稀缺的根本挑战。现有的机器人基础模型虽然通过跨实体数据集进行预训练以增加数据规模，但由于不同机器人形态和动作空间的差异，统一训练面临显著限制。", "method": "本文提出了H-RDT（Human to Robotics Diffusion Transformer），一种利用人类操作数据增强机器人操作能力的新方法。核心思想是利用带有3D手部姿态标注的大规模第一人称人类操作视频，这些视频提供了丰富的行为先验。H-RDT采用两阶段训练范式：(1) 在大规模第一人称人类操作数据上进行预训练；(2) 在机器人特定数据上进行跨实体微调，并结合模块化动作编码器和解码器。该方法基于2B参数的扩散Transformer架构，并使用流匹配来建模复杂的动作分布。", "result": "H-RDT在模拟和真实世界的实验、单任务和多任务场景、以及少样本学习和鲁棒性评估中进行了广泛评估。结果表明，H-RDT优于从头开始训练和现有的最先进方法（包括Pi0和RDT），在模拟和真实世界实验中分别比从头开始训练实现了13.9%和40.5%的显著改进。", "conclusion": "实验结果验证了核心假设：人类操作数据可以作为学习双臂机器人操作策略的强大基础。", "translation": "模仿学习对于机器人操作面临一个根本性挑战：缺乏大规模、高质量的机器人演示数据。最近的机器人基础模型通常在跨实体机器人数据集上进行预训练以增加数据规模，但它们面临显著限制，因为不同机器人实体的多样形态和动作空间使得统一训练具有挑战性。在本文中，我们提出了H-RDT（Human to Robotics Diffusion Transformer），一种利用人类操作数据增强机器人操作能力的新方法。我们的关键见解是，带有配对3D手部姿态标注的大规模第一人称人类操作视频提供了丰富的行为先验，这些先验捕捉了自然的操作策略，并且可以有益于机器人策略学习。我们引入了一种两阶段训练范式：(1) 在大规模第一人称人类操作数据上进行预训练，以及 (2) 在机器人特定数据上进行跨实体微调，结合模块化动作编码器和解码器。H-RDT构建在一个拥有2B参数的扩散Transformer架构上，使用流匹配来建模复杂的动作分布。涵盖模拟和真实世界实验、单任务和多任务场景，以及少样本学习和鲁棒性评估的广泛评估表明，H-RDT优于从头开始训练和现有的最先进方法，包括Pi0和RDT，在模拟和真实世界实验中分别比从头开始训练实现了13.9%和40.5%的显著改进。结果验证了我们的核心假设，即人类操作数据可以作为学习双臂机器人操作策略的强大基础。", "summary": "H-RDT是一种新的方法，通过利用大规模第一人称人类操作视频数据来增强双臂机器人操作能力。该方法解决了机器人模仿学习中高质量数据稀缺的问题，通过两阶段训练范式，先在人类数据上预训练扩散Transformer模型，再在机器人特定数据上进行微调。实验证明，H-RDT在模拟和真实世界中均显著优于现有方法，验证了人类操作数据作为机器人学习基础的有效性。", "keywords": "机器人操作, 模仿学习, 扩散Transformer, 人类数据, 双臂机器人", "comments": "H-RDT的创新之处在于利用大规模人类操作视频作为机器人模仿学习的强大预训练数据源，有效解决了机器人数据稀缺的挑战。其两阶段训练范式和基于扩散Transformer的架构，以及对流匹配的应用，展现了其在复杂动作分布建模上的能力。该研究的重要性在于为未来机器人策略学习提供了一个可扩展且高效的范式，特别是对于双臂操作任务。"}}
{"id": "2406.15444", "title": "Cutting Through the Noise: Boosting LLM Performance on Math Word Problems", "authors": ["Ujjwala Anantheswaran", "Himanshu Gupta", "Kevin Scaria", "Shreyas Verma", "Chitta Baral", "Swaroop Mishra"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs", "url": "http://arxiv.org/abs/2406.15444v4", "summary": "Large Language Models (LLMs) excel at various tasks, including solving math\nword problems (MWPs), but struggle with real-world problems containing\nirrelevant information. To address this, we propose a prompting framework that\ngenerates adversarial variants of MWPs by adding irrelevant variables. We\nintroduce a dataset, PROBLEMATHIC, containing both adversarial and\nnon-adversarial MWPs. Our experiments reveal that LLMs are susceptible to\ndistraction by numerical noise, resulting in an average relative performance\ndrop of ~26% on adversarial MWPs. To mitigate this, we fine-tune LLMs (Llama-2,\nMistral) on the adversarial samples from our dataset. Fine-tuning on\nadversarial training instances improves performance on adversarial MWPs by ~8%,\nindicating increased robustness to noise and improved ability to identify\nrelevant data for reasoning. Finally, to assess the generalizability of our\nprompting framework, we introduce GSM-8K-Adv, an adversarial variant of the\nGSM-8K benchmark. LLMs continue to struggle when faced with adversarial\ninformation, reducing performance by up to 6%.", "comment": "Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs", "pdf_url": "http://arxiv.org/pdf/2406.15444v4", "cate": "cs.CL", "date": "2024-05-30", "updated": "2025-07-31", "AI": {"title_translation": "穿越噪音：提升大型语言模型在数学应用题上的表现", "tldr": "研究发现大型语言模型（LLMs）在包含无关信息的数学应用题上表现不佳。本文提出了一个生成对抗性数学应用题的框架和数据集，并发现通过对抗性样本微调可以提高LLMs对噪音的鲁棒性，但其泛化能力仍有待提升。", "motivation": "大型语言模型（LLMs）在解决包含无关信息的数学应用题（MWPs）时表现不佳，需要提高其处理“噪音”数据的能力，以更好地应对现实世界中的问题。", "method": "本文提出了一个提示框架，通过添加无关变量来生成对抗性数学应用题（MWPs）。引入了一个名为PROBLEMATHIC的数据集，其中包含对抗性和非对抗性MWPs。研究人员使用该数据集的对抗性样本对LLMs（Llama-2、Mistral）进行了微调。此外，为了评估框架的通用性，还引入了GSM-8K基准测试的对抗性变体GSM-8K-Adv。", "result": "实验表明，LLMs容易受到数值噪音的干扰，导致在对抗性MWPs上的性能平均相对下降约26%。通过在对抗性训练实例上进行微调，LLMs在对抗性MWPs上的性能提高了约8%，表明对噪音的鲁棒性增强以及识别相关数据进行推理的能力提高。然而，LLMs在面对GSM-8K-Adv等对抗性信息时仍表现不佳，性能下降高达6%。", "conclusion": "大型语言模型在处理包含无关信息的数学应用题时面临显著挑战。尽管通过对抗性训练可以提高其对噪音的鲁棒性，但LLMs在面对新的对抗性信息时仍然表现出局限性，未来仍需进一步研究以提升其泛化能力。", "translation": "大型语言模型（LLM）在各种任务中表现出色，包括解决数学应用题（MWP），但它们在处理包含无关信息的现实问题时却力不从心。为了解决这个问题，我们提出了一个提示框架，通过添加无关变量来生成MWP的对抗性变体。我们引入了一个名为PROBLEMATHIC的数据集，其中包含对抗性和非对抗性MWP。我们的实验表明，LLM容易受到数值噪音的干扰，导致在对抗性MWP上的平均相对性能下降约26%。为了缓解这种情况，我们使用我们数据集中对抗性样本对LLM（Llama-2、Mistral）进行了微调。在对抗性训练实例上进行微调将对抗性MWP的性能提高了约8%，这表明对噪音的鲁棒性增强，识别相关数据进行推理的能力也提高了。最后，为了评估我们提示框架的通用性，我们引入了GSM-8K-Adv，这是GSM-8K基准测试的一个对抗性变体。当面对对抗性信息时，LLM仍然表现不佳，性能下降高达6%。", "summary": "本文旨在提升大型语言模型（LLMs）在含有无关信息的数学应用题（MWPs）上的表现。研究提出了一个提示框架，用于生成包含无关变量的对抗性MWPs，并构建了PROBLEMATHIC数据集。实验发现LLMs易受数值噪音干扰导致性能显著下降。通过在对抗性样本上微调LLMs，其对噪音的鲁棒性有所提升（性能提高约8%），但面对更通用的对抗性基准测试（如GSM-8K-Adv）时仍面临挑战（性能下降高达6%）。", "keywords": "大型语言模型, 数学应用题, 对抗性样本, 噪音鲁棒性, 微调", "comments": "本研究创新性地提出了生成对抗性数学应用题的框架和数据集，揭示了大型语言模型在处理无关信息时的脆弱性。通过对抗性训练提高模型鲁棒性的尝试具有重要意义，为LLMs在更复杂、更接近现实环境中的应用提供了新的视角和改进方向。然而，研究结果也表明了LLMs在泛化到未知或更复杂的对抗性场景时仍存在局限性，这提示未来研究需进一步探索更通用的鲁棒性增强方法。"}}
{"id": "2507.23585", "title": "Agency Among Agents: Designing with Hypertextual Friction in the Algorithmic Web", "authors": ["Sophia Liu", "Shm Garanganao Almeda"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      To appear in: Adjunct Proceedings of the 36th ACM Conference on Hypertext and Social Media, Chicago, IL, USA, September 15-18, 2025", "url": "http://arxiv.org/abs/2507.23585v1", "summary": "Today's algorithm-driven interfaces, from recommendation feeds to GenAI\ntools, often prioritize engagement and efficiency at the expense of user\nagency. As systems take on more decision-making, users have less control over\nwhat they see and how meaning or relationships between content are constructed.\nThis paper introduces \"Hypertextual Friction,\" a conceptual design stance that\nrepositions classical hypertext principles--friction, traceability, and\nstructure--as actionable values for reclaiming agency in algorithmically\nmediated environments. Through a comparative analysis of real-world\ninterfaces--Wikipedia vs. Instagram Explore, and Are.na vs. GenAI image\ntools--we examine how different systems structure user experience, navigation,\nand authorship. We show that hypertext systems emphasize provenance,\nassociative thinking, and user-driven meaning-making, while algorithmic systems\ntend to obscure process and flatten participation. We contribute: (1) a\ncomparative analysis of how interface structures shape agency in user-driven\nversus agent-driven systems, and (2) a conceptual stance that offers\nhypertextual values as design commitments for reclaiming agency in an\nincreasingly algorithmic web.", "comment": "To appear in: Adjunct Proceedings of the 36th ACM Conference on\n  Hypertext and Social Media, Chicago, IL, USA, September 15-18, 2025", "pdf_url": "http://arxiv.org/pdf/2507.23585v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "代理人之间的能动性：在算法网络中设计超文本摩擦", "tldr": "论文提出“超文本摩擦”概念，旨在通过经典超文本原则（摩擦、可追溯性、结构）帮助用户在算法驱动的界面中找回能动性。", "motivation": "当今的算法驱动界面（如推荐流、生成式AI工具）优先考虑参与度和效率，却牺牲了用户能动性，导致用户对信息获取和内容意义构建的控制权减少。", "method": "通过对真实世界界面（维基百科 vs. Instagram Explore，Are.na vs. 生成式AI图像工具）进行比较分析，研究不同系统如何构建用户体验、导航和作者身份。", "result": "超文本系统强调来源、联想思维和用户驱动的意义构建，而算法系统倾向于模糊过程并扁平化参与。论文贡献了：1) 对用户驱动和代理驱动系统界面结构如何影响能动性的比较分析；2) 提出一种概念性设计立场，将超文本价值作为在日益算法化的网络中恢复能动性的设计承诺。", "conclusion": "通过采纳超文本原则（摩擦、可追溯性、结构），可以帮助用户在算法驱动的环境中恢复其能动性，从而实现更具控制力和意义的用户体验。", "translation": "当今的算法驱动界面，从推荐信息流到生成式AI工具，通常以牺牲用户能动性为代价来优先考虑参与度和效率。随着系统承担更多决策，用户对自己看到的内容以及内容之间意义或关系的构建方式的控制权越来越少。本文引入了“超文本摩擦”这一概念性设计立场，它将经典的超文本原则——摩擦、可追溯性和结构——重新定位为在算法介导环境中恢复能动性的可操作价值。通过对真实世界界面（维基百科与Instagram Explore，以及Are.na与生成式AI图像工具）的比较分析，我们研究了不同系统如何构建用户体验、导航和作者身份。我们表明，超文本系统强调来源、联想思维和用户驱动的意义构建，而算法系统倾向于模糊过程并扁平化参与。我们的贡献包括：(1) 对界面结构如何影响用户驱动系统与代理驱动系统中能动性的比较分析，以及 (2) 一种概念性立场，提出超文本价值作为在日益算法化的网络中恢复能动性的设计承诺。", "summary": "这篇论文探讨了在算法驱动的数字环境中用户能动性丧失的问题，并提出了“超文本摩擦”这一设计理念。该理念旨在通过重新强调经典超文本的原则（摩擦、可追溯性和结构），帮助用户在推荐系统和生成式AI工具等算法介导的界面中重新获得控制权。通过比较维基百科与Instagram Explore、Are.na与生成式AI图像工具，论文指出超文本系统促进用户驱动的意义构建，而算法系统则趋于模糊过程。最终，论文提供了一种恢复用户能动性的设计方法论。", "keywords": "超文本摩擦, 用户能动性, 算法设计, 界面设计, 超文本原则", "comments": "这篇论文创新性地将经典的超文本原则重新解读为应对现代算法驱动界面中用户能动性丧失的解决方案。其通过对比分析具体案例，清晰地揭示了两种不同系统设计哲学对用户体验和控制权的影响，为未来设计提供了有价值的指导，强调了在效率和便利之外，用户控制和意义构建的重要性。"}}
{"id": "2505.12892", "title": "\"I will never pay for this\" Perception of fairness and factors affecting behaviour on 'pay-or-ok' models", "authors": ["Victor Morel", "Farzaneh Karegar", "Cristiana Santos"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for publication at APF2025", "url": "http://arxiv.org/abs/2505.12892v4", "summary": "The rise of cookie paywalls ('pay-or-ok' models) has prompted growing debates\naround the right to privacy and data protection, monetisation, and the\nlegitimacy of user consent. Despite their increasing use across sectors,\nlimited research has explored how users perceive these models or what shapes\ntheir decisions to either consent to tracking or pay. To address this gap, we\nconducted four focus groups (n= 14) to examine users' perceptions of cookie\npaywalls, their judgments of fairness, and the conditions under which they\nmight consider paying, alongside a legal analysis within the EU data protection\nlegal framework.\n  Participants primarily viewed cookie paywalls as profit-driven, with fairness\nperceptions varying depending on factors such as the presence of a third option\nbeyond consent or payment, transparency of data practices, and the authenticity\nor exclusivity of the paid content. Participants voiced expectations for\ngreater transparency, meaningful control over data collection, and less\ncoercive alternatives, such as contextual advertising or \"reject all\" buttons.\nAlthough some conditions, including trusted providers, exclusive content, and\nreasonable pricing, could make participants consider paying, most expressed\nreluctance or unwillingness to do so.\n  Crucially, our findings raise concerns about economic exclusion, where\nprivacy and data protection might end up becoming a privilege rather than\nfundamental rights. Consent given under financial pressure may not meet the\nstandard of being freely given, as required by the GDPR. To address these\nconcerns, we recommend user-centred approaches that enhance transparency,\nreduce coercion, ensure the value of paid content, and explore inclusive\nalternatives. These measures are essential for supporting fairness, meaningful\nchoice, and user autonomy in consent-driven digital environments.", "comment": "Accepted for publication at APF2025", "pdf_url": "http://arxiv.org/pdf/2505.12892v4", "cate": "cs.CY", "date": "2025-05-19", "updated": "2025-07-31", "AI": {"title_translation": "“我绝不会为此付费”：关于“付费或同意”模式下公平感知及影响行为的因素", "tldr": "本研究探讨了用户对“付费或同意”模式（如Cookie付费墙）的看法、公平感知以及影响其付费或同意追踪行为的因素，发现用户普遍认为其是逐利的，并对经济排斥和GDPR合规性提出担忧。", "motivation": "尽管“付费或同意”模式日益普及，但关于用户如何看待这些模式以及哪些因素影响他们同意追踪或付费的决策的研究仍然有限。本研究旨在弥补这一空白。", "method": "研究采用了四场焦点小组访谈（n=14）来考察用户对Cookie付费墙的看法、公平判断以及在何种条件下可能考虑付费，同时结合了欧盟数据保护法律框架内的法律分析。", "result": "参与者普遍认为Cookie付费墙是逐利的。公平感知取决于是否存在第三方选项、数据实践的透明度以及付费内容的真实性或独占性。参与者期望更高的透明度、对数据收集的有效控制和更少强制性的替代方案。尽管在某些条件下（如受信任的提供商、独家内容、合理定价），参与者可能会考虑付费，但大多数人表示不愿或不情愿这样做。", "conclusion": "研究结果引发了对经济排斥的担忧，即隐私和数据保护可能成为一种特权而非基本权利。在经济压力下给予的同意可能不符合GDPR要求的“自由给予”标准。因此，研究建议采取以用户为中心的方法，增强透明度，减少强制性，确保付费内容的价值，并探索包容性替代方案，以支持数字环境中同意驱动下的公平性、有意义的选择和用户自主权。", "translation": "Cookie付费墙（“付费或同意”模式）的兴起引发了关于隐私权和数据保护、货币化以及用户同意合法性的日益增长的争论。尽管这些模式在各行各业中得到越来越多的应用，但很少有研究探讨用户如何看待这些模式，或者什么因素影响他们同意追踪或付费的决定。为了弥补这一空白，我们进行了四场焦点小组访谈（n=14），以考察用户对Cookie付费墙的看法、他们对公平性的判断以及在何种条件下他们可能考虑付费，同时在欧盟数据保护法律框架内进行了法律分析。参与者主要将Cookie付费墙视为逐利的，公平感知因是否存在同意或支付之外的第三方选项、数据实践的透明度以及付费内容的真实性或独占性等因素而异。参与者表达了对更高透明度、对数据收集的有效控制以及更少强制性替代方案（如情境广告或“拒绝所有”按钮）的期望。尽管某些条件，包括受信任的提供商、独家内容和合理定价，可能会使参与者考虑付费，但大多数人表示不愿或不情愿这样做。至关重要的是，我们的发现引发了对经济排斥的担忧，即隐私和数据保护最终可能成为一种特权而非基本权利。在经济压力下给予的同意可能不符合GDPR要求的“自由给予”标准。为了解决这些担忧，我们建议采用以用户为中心的方法，增强透明度，减少强制性，确保付费内容的价值，并探索包容性替代方案。这些措施对于在同意驱动的数字环境中支持公平性、有意义的选择和用户自主权至关重要。", "summary": "本研究探讨了用户对“付费或同意”模式（如Cookie付费墙）的感知、公平判断及其决策影响因素。通过焦点小组和法律分析，研究发现用户普遍认为此类模式是逐利的，且公平感知受多重因素影响。尽管在特定条件下用户可能考虑付费，但多数人表示不愿。研究强调了经济排斥的风险，指出在经济压力下的同意可能不符合GDPR标准，并建议采取以用户为中心的方法来提升透明度、减少强制性并提供包容性替代方案，以维护用户在数字环境中的权利和选择。", "keywords": "Cookie付费墙, 付费或同意, 公平感知, 用户行为, 数据隐私", "comments": "本研究通过结合用户访谈和法律分析，深入探讨了“付费或同意”模式下用户公平感知和行为决策的复杂性，尤其是在隐私权和数据保护背景下。其创新之处在于揭示了用户对这种商业模式的深层看法，并提出了经济排斥的担忧，这对于GDPR等数据保护法规的实际应用具有重要意义。研究强调了用户中心设计和非强制性选择的重要性，为未来数字服务的设计和监管提供了宝贵的见解。"}}
{"id": "2502.02171", "title": "DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging", "authors": ["Mohamed Youssef", "Jian Peng", "Oliver Bimber"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.02171v3", "summary": "Access to below-canopy volumetric vegetation data is crucial for\nunderstanding ecosystem dynamics. We address the long-standing limitation of\nremote sensing to penetrate deep into dense canopy layers. LiDAR and radar are\ncurrently considered the primary options for measuring 3D vegetation\nstructures, while cameras can only extract the reflectance and depth of top\nlayers. Using conventional, high-resolution aerial images, our approach allows\nsensing deep into self-occluding vegetation volumes, such as forests. It is\nsimilar in spirit to the imaging process of wide-field microscopy, but can\nhandle much larger scales and strong occlusion. We scan focal stacks by\nsynthetic-aperture imaging with drones and reduce out-of-focus signal\ncontributions using pre-trained 3D convolutional neural networks with mean\nsquared error (MSE) as the loss function. The resulting volumetric reflectance\nstacks contain low-frequency representations of the vegetation volume.\nCombining multiple reflectance stacks from various spectral channels provides\ninsights into plant health, growth, and environmental conditions throughout the\nentire vegetation volume. Compared with simulated ground truth, our correction\nleads to ~x7 average improvements (min: ~x2, max: ~x12) for forest densities of\n220 trees/ha - 1680 trees/ha. In our field experiment, we achieved an MSE of\n0.05 when comparing with the top-vegetation layer that was measured with\nclassical multispectral aerial imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.02171v3", "cate": "cs.CV", "date": "2025-02-04", "updated": "2025-07-31", "AI": {"title_translation": "DeepForest：利用航空影像感知自我遮挡植被体积", "tldr": "DeepForest提出了一种利用无人机航空影像和3D卷积神经网络的新方法，能够穿透茂密的植被冠层，获取冠层下方的三维植被体积数据，对于理解生态系统动态至关重要。", "motivation": "获取冠层下方的体积植被数据对于理解生态系统动态至关重要。目前的遥感技术在穿透茂密冠层方面存在长期限制，激光雷达和雷达是测量三维植被结构的主要选择，而相机只能提取顶层的反射率和深度信息。", "method": "该方法利用常规高分辨率航空影像，类似于宽视场显微镜的成像过程，但能处理更大的尺度和强遮挡。它通过无人机进行合成孔径成像，扫描焦点堆栈，并使用预训练的3D卷积神经网络（以均方误差MSE作为损失函数）减少离焦信号贡献。", "result": "生成的体积反射率堆栈包含植被体积的低频表示。结合来自不同光谱通道的多个反射率堆栈，可以深入了解整个植被体积内的植物健康、生长和环境条件。与模拟地面真实数据相比，对于每公顷220至1680棵树的森林密度，校正后的平均改进约为7倍（最小：约2倍，最大：约12倍）。在野外实验中，与使用传统多光谱航空影像测量的顶部植被层相比，实现了0.05的均方误差。", "conclusion": "该方法能够深入感知自我遮挡的植被体积，提供了关键的体积反射率数据，从而深入了解整个植被体积内的植物健康、生长和环境条件。", "translation": "获取冠层下方的体积植被数据对于理解生态系统动态至关重要。我们解决了遥感技术长期以来无法深入穿透茂密冠层的问题。激光雷达和雷达目前被认为是测量三维植被结构的主要选择，而相机只能提取顶层的反射率和深度信息。我们的方法利用常规高分辨率航空影像，能够深入感知森林等自我遮挡植被的体积。它在精神上类似于宽视场显微镜的成像过程，但能处理更大的尺度和强遮挡。我们通过无人机进行合成孔径成像来扫描焦点堆栈，并使用预训练的3D卷积神经网络（以均方误差MSE作为损失函数）减少离焦信号贡献。由此产生的体积反射率堆栈包含植被体积的低频表示。结合来自各种光谱通道的多个反射率堆栈，可以深入了解整个植被体积内的植物健康、生长和环境条件。与模拟地面真实数据相比，我们的校正对于每公顷220至1680棵树的森林密度，平均改进约为7倍（最小：约2倍，最大：约12倍）。在我们的野外实验中，与使用传统多光谱航空影像测量的顶部植被层相比，我们实现了0.05的均方误差。", "summary": "DeepForest提出了一种新颖的航空成像方法，克服了传统遥感技术难以穿透茂密植被冠层的限制。该方法利用无人机进行合成孔径成像以扫描焦点堆栈，并结合预训练的3D卷积神经网络来处理图像，从而能够深入感知自我遮挡的植被体积，获取其低频体积反射率表示。这使得研究人员能够深入了解植物健康、生长和环境条件。实验结果表明，该方法在穿透不同密度的森林时，相较于模拟地面真实数据，平均性能提升了约7倍，并在与经典多光谱航空成像比较时取得了0.05的均方误差。", "keywords": "遥感, 植被, 体积成像, 深度学习, 无人机", "comments": "这篇论文提出了一种创新性的方法，通过将宽视场显微镜的原理应用于大规模航空成像，有效解决了遥感领域获取冠层下方体积数据的关键挑战。结合合成孔径成像和3D卷积神经网络是针对此应用的新颖集成，相较于传统方法提供了显著改进。其重要性在于能够更深入地理解生态系统动态、植物健康和环境条件。"}}
{"id": "2406.07108", "title": "On the power of adaption and randomization", "authors": ["David Krieg", "Erich Novak", "Mario Ullrich"], "categories": ["math.NA", "cs.CC", "cs.NA", "math.FA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.07108v2", "summary": "We present bounds on the maximal gain of adaptive and randomized algorithms\nover non-adaptive, deterministic ones for approximating linear operators on\nconvex sets. If the sets are additionally symmetric, then our results are\noptimal. For non-symmetric sets, we unify some notions of $n$-widths and\ns-numbers, and show their connection to minimal errors. We also discuss\nextensions to non-linear widths and approximation based on function values, and\nconclude with a list of open problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.07108v2", "cate": "math.NA", "date": "2024-06-11", "updated": "2025-07-31", "AI": {"title_translation": "关于适应性和随机化的力量", "tldr": "本文研究了自适应和随机算法在凸集上逼近线性算子时相对于非自适应、确定性算法的最大增益，并给出了界限，对于对称集合结果是最佳的，对于非对称集合统一了n-宽度和s-数的概念。", "motivation": "旨在量化和理解自适应和随机算法相对于非自适应、确定性算法在逼近线性算子方面的最大增益或“力量”。", "method": "通过提出最大增益的界限，并对非对称集合统一n-宽度和s-数的概念，揭示它们与最小误差的联系。研究还讨论了向非线性宽度和基于函数值的逼近的扩展。", "result": "提出了自适应和随机算法相对于非自适应、确定性算法在凸集上逼近线性算子时最大增益的界限；对于对称集合，结果是最佳的；对于非对称集合，统一了n-宽度和s-数的一些概念，并展示了它们与最小误差的联系；讨论了向非线性宽度和基于函数值的逼近的扩展。", "conclusion": "本文为自适应和随机算法在逼近线性算子方面的优势提供了理论界限和最佳结果，并统一了相关理论概念，为该领域未来的研究指明了方向。", "translation": "我们提出了自适应和随机算法相对于非自适应、确定性算法在凸集上逼近线性算子时最大增益的界限。如果集合是附加对称的，那么我们的结果是最佳的。对于非对称集合，我们统一了n-宽度和s-数的一些概念，并展示了它们与最小误差的联系。我们还讨论了向非线性宽度和基于函数值的逼近的扩展，并以一系列开放问题作为结束。", "summary": "本文探讨了自适应和随机算法在凸集上逼近线性算子时，相对于非自适应、确定性算法所能获得的最大增益。研究为对称凸集提供了最优的界限，并针对非对称集统一了n-宽度和s-数等概念，揭示了它们与最小误差之间的关联。此外，论文还讨论了向非线性宽度和基于函数值的逼近的扩展，并列出了尚待解决的问题。", "keywords": "自适应算法, 随机算法, 线性算子, 凸集, 逼近理论", "comments": "该论文在逼近理论领域具有重要意义，它通过量化自适应和随机算法的优势，加深了对算法效率的理解。对n-宽度和s-数概念的统一是其理论贡献的亮点，为未来的研究奠定了基础。提出开放性问题也表明了其前瞻性。"}}
{"id": "2507.23037", "title": "Linking Actor Behavior to Process Performance Over Time", "authors": ["Aurélie Leribaux", "Rafael Oyamada", "Johannes De Smedt", "Zahra Dasht Bozorgi", "Artem Polyvyanyy", "Jochen De Weerdt"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the 5th Workshop on Change, Drift, and Dynamics of Organizational Processes (ProDy), BPM 2025", "url": "http://arxiv.org/abs/2507.23037v1", "summary": "Understanding how actor behavior influences process outcomes is a critical\naspect of process mining. Traditional approaches often use aggregate and static\nprocess data, overlooking the temporal and causal dynamics that arise from\nindividual actor behavior. This limits the ability to accurately capture the\ncomplexity of real-world processes, where individual actor behavior and\ninteractions between actors significantly shape performance. In this work, we\naddress this gap by integrating actor behavior analysis with Granger causality\nto identify correlating links in time series data. We apply this approach to\nrealworld event logs, constructing time series for actor interactions, i.e.\ncontinuation, interruption, and handovers, and process outcomes. Using Group\nLasso for lag selection, we identify a small but consistently influential set\nof lags that capture the majority of causal influence, revealing that actor\nbehavior has direct and measurable impacts on process performance, particularly\nthroughput time. These findings demonstrate the potential of actor-centric,\ntime series-based methods for uncovering the temporal dependencies that drive\nprocess outcomes, offering a more nuanced understanding of how individual\nbehaviors impact overall process efficiency.", "comment": "Accepted for presentation at the 5th Workshop on Change, Drift, and\n  Dynamics of Organizational Processes (ProDy), BPM 2025", "pdf_url": "http://arxiv.org/pdf/2507.23037v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "关联行为者行为与过程性能随时间变化", "tldr": "本文通过结合行为者行为分析和格兰杰因果关系，揭示了行为者行为如何随时间直接影响流程性能。", "motivation": "传统流程挖掘方法使用聚合静态数据，忽略了个体行为者行为产生的时序和因果动态，限制了对真实世界流程复杂性的捕捉。", "method": "本文通过将行为者行为分析与格兰杰因果关系相结合，在时间序列数据中识别相关链接。具体应用于真实事件日志，构建行为者交互（如延续、中断、移交）和流程结果的时间序列，并使用Group Lasso进行滞后选择。", "result": "研究识别出一组虽小但持续有影响力的滞后，捕捉了大部分因果影响，揭示了行为者行为对流程性能（特别是吞吐时间）具有直接且可衡量的影响。", "conclusion": "行为者中心、基于时间序列的方法有潜力揭示驱动流程结果的时间依赖性，从而更细致地理解个体行为如何影响整体流程效率。", "translation": "理解行为者行为如何影响流程结果是流程挖掘的一个关键方面。传统方法通常使用聚合的静态流程数据，忽略了个体行为者行为产生的时序和因果动态。这限制了准确捕捉真实世界流程复杂性的能力，其中个体行为者行为以及行为者之间的交互显著影响性能。在这项工作中，我们通过将行为者行为分析与格兰杰因果关系相结合，以识别时间序列数据中的关联链接来弥补这一空白。我们将这种方法应用于真实世界的事件日志，构建行为者交互（即延续、中断和移交）以及流程结果的时间序列。通过使用Group Lasso进行滞后选择，我们识别出一组虽小但持续有影响力的滞后，捕捉了大部分因果影响，揭示了行为者行为对流程性能，特别是吞吐时间，具有直接且可衡量的影响。这些发现表明，以行为者为中心、基于时间序列的方法有潜力揭示驱动流程结果的时间依赖性，从而更细致地理解个体行为如何影响整体流程效率。", "summary": "本文旨在解决传统流程挖掘方法忽略个体行为者行为时序和因果动态的局限性。通过整合行为者行为分析与格兰杰因果关系，并应用于真实事件日志，构建行为者交互和流程结果的时间序列，识别出行为者行为对流程性能（特别是吞吐时间）存在直接且可衡量的影响。研究结果表明，以行为者为中心、基于时间序列的方法能够揭示流程结果的时间依赖性，从而更深入地理解个体行为对流程效率的影响。", "keywords": "行为者行为, 流程性能, 时间序列, 格兰杰因果关系, 流程挖掘", "comments": "这项工作通过引入格兰杰因果关系和时间序列分析，弥补了传统流程挖掘在捕捉个体行为者行为动态方面的不足，为理解行为者行为如何随时间影响流程性能提供了新的视角和方法。其创新性在于将行为者行为视为时间序列，并揭示了其对流程性能的直接因果影响，对于提升流程效率管理具有重要意义。"}}
{"id": "2405.08788", "title": "Using weakest application conditions to rank graph transformations for graph repair", "authors": ["Lars Fritsche", "Alexander Lauer", "Maximilian Kratz", "Andy Schürr", "Gabriele Taentzer"], "categories": ["cs.SE", "68R10", "D.2.4"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      51 pages, 25 Figures, new, more efficient method for constructing application conditions, theoretical comparison to other concepts of consistency, extended evaluation", "url": "http://arxiv.org/abs/2405.08788v3", "summary": "When using graphs and graph transformations to model systems, consistency is\nan important concern. While consistency has primarily been viewed as a binary\nproperty, i.e., a graph is consistent or inconsistent with respect to a set of\nconstraints, recent work has presented an approach to consistency as a\ngraduated property. This allows living with inconsistencies for a while and\nrepairing them when necessary. For repairing inconsistencies in a graph, we use\ngraph transformation rules with so-called {\\em impairment-indicating and\nrepair-indicating application conditions} to understand how much repair gain\ncertain rule applications would bring. Both types of conditions can be derived\nfrom given graph constraints. Our main theorem shows that the difference\nbetween the number of actual constraint violations before and after a graph\ntransformation step can be characterized by the difference between the numbers\nof violated impairment-indicating and repair-indicating application conditions.\nThis theory forms the basis for algorithms with look-ahead that rank graph\ntransformations according to their potential for graph repair. An evaluation\nshows that graph repair can be well supported by rules with these new types of\napplication conditions in terms of effectiveness and scalability.", "comment": "51 pages, 25 Figures, new, more efficient method for constructing\n  application conditions, theoretical comparison to other concepts of\n  consistency, extended evaluation", "pdf_url": "http://arxiv.org/pdf/2405.08788v3", "cate": "cs.SE", "date": "2024-05-14", "updated": "2025-07-31", "AI": {"title_translation": "使用最弱应用条件对图变换进行排序以进行图修复", "tldr": "提出了一种基于弱应用条件对图变换进行排序的方法，用于有效修复图中的不一致性。", "motivation": "在图和图变换建模系统中，一致性是一个重要问题。传统上一致性被视为二元属性，但最近的工作提出了渐进式一致性，允许在必要时进行修复。因此，需要一种方法来修复图中的不一致性。", "method": "本研究使用带有“损害指示和修复指示应用条件”的图变换规则来评估修复增益。这些条件可以从图约束中导出。论文提出了一个主定理，该定理将图变换前后实际约束违反数量的差异与损害指示和修复指示应用条件违反数量的差异关联起来。基于此理论，开发了具有前瞻性的算法，根据图修复潜力对图变换进行排序。", "result": "主要定理表明，图变换步骤前后实际约束违反数量的差异可以通过违反的损害指示和修复指示应用条件数量的差异来表征。评估结果显示，带有这些新型应用条件的规则在有效性和可伸缩性方面能很好地支持图修复。", "conclusion": "本研究提出的带有新型应用条件的图变换规则，能够基于其修复潜力对图变换进行排序，从而有效且可伸缩地支持图修复。", "translation": "当使用图和图变换来建模系统时，一致性是一个重要问题。虽然一致性主要被视为一个二元属性，即图相对于一组约束是一致的或不一致的，但最近的工作提出了一种将一致性作为渐进属性的方法。这允许在一段时间内容忍不一致，并在必要时进行修复。为了修复图中的不一致性，我们使用带有所谓“损害指示和修复指示应用条件”的图变换规则，以了解某些规则应用能带来多少修复增益。这两种类型的条件都可以从给定的图约束中导出。我们的主要定理表明，图变换步骤前后实际约束违反数量的差异可以通过违反的损害指示和修复指示应用条件数量的差异来表征。该理论构成了具有前瞻性的算法的基础，这些算法根据图修复的潜力对图变换进行排序。一项评估表明，带有这些新型应用条件的规则在有效性和可伸缩性方面能很好地支持图修复。", "summary": "该论文提出了一种新的图修复方法，通过引入“损害指示和修复指示应用条件”来量化图变换规则的修复潜力。这些条件可以从图约束中导出。论文的核心贡献是一个主定理，它将图变换前后约束违反的变化与这些新型应用条件违反数量的变化相关联。基于此理论，开发了算法来排序图变换以优化修复效果。实验评估表明，该方法在图修复的有效性和可伸缩性方面表现良好。", "keywords": "图修复, 图变换, 应用条件, 一致性, 排序", "comments": "该论文的创新点在于将一致性从二元属性扩展到渐进属性，并引入了“损害指示和修复指示应用条件”来量化图变换的修复增益。这为图修复提供了一种更精细、更实用的方法，使其能够根据修复潜力对变换进行排序，从而提高了修复过程的效率和效果。其理论基础和评估结果显示了该方法在实际应用中的潜力和重要性。"}}
{"id": "2507.23147", "title": "Foundation Models for Clean Energy Forecasting: A Comprehensive Review", "authors": ["Md Meftahul Ferdaus", "Tanmoy Dam", "Md Rasel Sarkar", "Moslem Uddin", "Sreenatha G. Anavatti"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This paper is currently under review at the journal", "url": "http://arxiv.org/abs/2507.23147v1", "summary": "As global energy systems transit to clean energy, accurate renewable\ngeneration and renewable demand forecasting is imperative for effective grid\nmanagement. Foundation Models (FMs) can help improve forecasting of renewable\ngeneration and demand because FMs can rapidly process complex, high-dimensional\ntime-series data. This review paper focuses on FMs in the realm of renewable\nenergy forecasting, primarily focusing on wind and solar. We present an\noverview of the architectures, pretraining strategies, finetuning methods, and\ntypes of data used in the context of renewable energy forecasting. We emphasize\nthe role of models that are trained at a large scale, domain specific\nTransformer architectures, where attention is paid to spatial temporal\ncorrelations, the embedding of domain knowledge, and also the brief and\nintermittent nature of renewable generation. We assess recent FM based\nadvancements in forecast accuracy such as reconciling predictions over multiple\ntime scales and quantifying uncertainty in renewable energy forecasting. We\nalso review existing challenges and areas of improvement in long-term and\nmultivariate time series forecasting. In this survey, a distinction between\ntheory and practice is established regarding the use of FMs in the clean energy\nforecasting domain. Additionally, it critically assesses the strengths and\nweaknesses of FMs while advancing future research direction in this new and\nexciting area of forecasting.", "comment": "This paper is currently under review at the journal", "pdf_url": "http://arxiv.org/pdf/2507.23147v1", "cate": "eess.SY", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "清洁能源预测的基础模型：一项综合性综述", "tldr": "这篇综述论文全面回顾了基础模型（FMs）在可再生能源（尤其是风能和太阳能）预测领域的应用，涵盖了其架构、训练策略、数据类型、最新进展、现有挑战以及未来研究方向。", "motivation": "随着全球能源系统向清洁能源转型，准确的可再生能源发电量和需求预测对于有效的电网管理至关重要。基础模型（FMs）能够快速处理复杂、高维的时间序列数据，从而有助于改进可再生能源发电和需求预测。", "method": "本综述论文重点关注基础模型在可再生能源预测领域的应用，主要围绕风能和太阳能。文章概述了相关架构、预训练策略、微调方法和所用数据类型。它强调了大规模训练模型、特定领域Transformer架构（关注时空相关性）、领域知识嵌入以及可再生能源发电的短暂和间歇性特征的作用。同时评估了基于FM的预测精度方面的最新进展（如多时间尺度预测协调和不确定性量化），并回顾了长期和多元时间序列预测中存在的挑战和改进领域。", "result": "本综述评估了基于基础模型的预测精度方面的最新进展，例如在多个时间尺度上协调预测以及量化可再生能源预测中的不确定性。同时，它也回顾了在长期和多元时间序列预测中存在的现有挑战和改进领域。论文在清洁能源预测领域基础模型的理论与实践之间建立了区别。", "conclusion": "本综述在清洁能源预测领域中，对基础模型的理论与实践进行了区分，并批判性地评估了基础模型的优势和劣势，同时提出了该预测新领域未来的研究方向。", "translation": "随着全球能源系统向清洁能源转型，准确的可再生能源发电和需求预测对于有效的电网管理至关重要。基础模型（FMs）能够快速处理复杂、高维的时间序列数据，从而有助于改进可再生能源发电和需求预测。本综述论文重点关注基础模型在可再生能源预测领域的应用，主要围绕风能和太阳能。我们概述了相关架构、预训练策略、微调方法和所用数据类型。我们强调了大规模训练模型、特定领域Transformer架构（关注时空相关性）、领域知识嵌入以及可再生能源发电的短暂和间歇性特征的作用。我们评估了基于FM的预测精度方面的最新进展，例如在多个时间尺度上协调预测以及量化可再生能源预测中的不确定性。我们还回顾了长期和多元时间序列预测中存在的现有挑战和改进领域。在这项调查中，我们对清洁能源预测领域中基础模型的理论与实践进行了区分。此外，它批判性地评估了基础模型的优势和劣势，同时提出了该预测新领域未来的研究方向。", "summary": "本综述论文全面探讨了基础模型（FMs）在清洁能源（特别是风能和太阳能）预测中的应用。文章概述了FMs的架构、预训练和微调策略以及数据使用情况，并强调了大规模训练模型、特定领域Transformer架构、领域知识嵌入以及可再生能源特性的重要性。论文评估了FMs在提高预测精度和不确定性量化方面的进展，同时指出了长期和多元时间序列预测的现有挑战。最后，文章区分了FMs在清洁能源预测中的理论与实践，批判性地分析了其优缺点，并展望了未来的研究方向。", "keywords": "基础模型, 清洁能源预测, 可再生能源, 时间序列预测, 综述", "comments": "这是一篇非常及时且重要的综述论文。它系统地梳理了基础模型在清洁能源预测这一新兴且关键领域中的应用现状、挑战与机遇。其创新之处在于将基础模型这一前沿技术引入能源预测领域，并从架构、训练策略、数据、理论与实践等多个维度进行了深入分析。对于研究人员和行业实践者而言，这篇综述提供了宝贵的参考，有助于理解当前进展并指明未来研究方向。"}}
{"id": "2507.23500", "title": "Online Combinatorial Allocation with Interdependent Values", "authors": ["Michal Feldman", "Simon Mauras", "Divyarthi Mohan", "Rebecca Reiffenhäuser"], "categories": ["cs.GT", "cs.DS"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23500v1", "summary": "We study online combinatorial allocation problems in the secretary setting,\nunder interdependent values. In the interdependent model, introduced by Milgrom\nand Weber (1982), each agent possesses a private signal that captures her\ninformation about an item for sale, and the value of every agent depends on the\nsignals held by all agents. Mauras, Mohan, and Reiffenh\\\"auser (2024) were the\nfirst to study interdependent values in online settings, providing\nconstant-approximation guarantees for secretary settings, where agents arrive\nonline along with their signals and values, and the goal is to select the agent\nwith the highest value.\n  In this work, we extend this framework to {\\em combinatorial} secretary\nproblems, where agents have interdependent valuations over {\\em bundles} of\nitems, introducing additional challenges due to both combinatorial structure\nand interdependence. We provide $2e$-competitive algorithms for a broad class\nof valuation functions, including submodular and XOS functions, matching the\napproximation guarantees in the single-choice secretary setting. Furthermore,\nour results cover the same range of valuation classes for which constant-factor\nalgorithms exist in classical (non-interdependent) secretary settings, while\nincurring only an additional factor of $2$ due to interdependence. Finally, we\nextend our study to strategic settings, and provide a $4e$-competitive truthful\nmechanism for online bipartite matching with interdependent valuations, again\nmeeting the frontier of what is known, even without interdependence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23500v1", "cate": "cs.GT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "在线组合分配与相互依赖价值", "tldr": "本文研究了在秘书问题背景下，具有相互依赖价值的在线组合分配问题，并为广泛的估值函数提供了竞争性算法，包括策略性设置。", "motivation": "现有工作（Mauras, Mohan, and Reiffenhäuser (2024)）首次研究了在线设置中的相互依赖价值，但尚未扩展到更复杂的组合秘书问题，其中由于组合结构和相互依赖性引入了额外挑战。本文旨在将该框架扩展到组合秘书问题以解决这些挑战。", "method": "本文提出了2e-竞争算法，适用于包括子模函数和XOS函数在内的广泛估值函数。此外，研究还扩展到战略性设置，并提供了一个4e-竞争的真实机制，用于具有相互依赖估值的在线二分匹配。", "result": "为广泛的估值函数（包括子模函数和XOS函数）提供了2e-竞争算法，与单选秘书设置中的近似保证相匹配。结果涵盖了在经典（非相互依赖）秘书设置中存在常数因子算法的相同估值类别，仅因相互依赖性额外增加了2倍因子。在战略性设置中，为具有相互依赖估值的在线二分匹配提供了一个4e-竞争的真实机制，即使在没有相互依赖的情况下，也达到了已知的前沿。", "conclusion": "本文成功地将相互依赖价值的在线分配框架扩展到组合秘书问题和战略性设置，提供了与现有最佳结果相媲美或超越的竞争性算法和机制。", "translation": "我们研究了秘书问题背景下，具有相互依赖价值的在线组合分配问题。在由Milgrom和Weber（1982）引入的相互依赖模型中，每个代理都拥有一个私有信号，该信号捕获了她关于待售物品的信息，并且每个代理的价值都取决于所有代理持有的信号。Mauras、Mohan和Reiffenhäuser（2024）首次研究了在线设置中的相互依赖价值，为秘书问题提供了常数近似保证，其中代理人及其信号和价值在线到达，目标是选择价值最高的代理人。\n在这项工作中，我们将此框架扩展到“组合”秘书问题，其中代理人对“捆绑”物品具有相互依赖的估值，由于组合结构和相互依赖性，引入了额外的挑战。我们为广泛的估值函数（包括子模函数和XOS函数）提供了2e-竞争算法，与单选秘书设置中的近似保证相匹配。此外，我们的结果涵盖了在经典（非相互依赖）秘书设置中存在常数因子算法的相同估值类别，仅因相互依赖性额外增加了2倍因子。最后，我们将研究扩展到战略性设置，并为具有相互依赖估值的在线二分匹配提供了一个4e-竞争的真实机制，即使在没有相互依赖的情况下，也再次达到了已知的前沿。", "summary": "本文研究了在秘书问题背景下，具有相互依赖价值的在线组合分配问题。它将现有框架扩展到组合秘书问题，其中代理人对物品捆绑具有相互依赖估值。论文为包括子模函数和XOS函数在内的广泛估值函数提供了2e-竞争算法，并将其扩展到战略性设置，为具有相互依赖估值的在线二分匹配提供了一个4e-竞争的真实机制，其性能与非相互依赖设置中的已知最佳结果相匹配。", "keywords": "在线组合分配, 相互依赖价值, 秘书问题, 竞争性算法, 真实机制", "comments": "本文在在线分配领域具有重要意义，它首次将相互依赖价值的概念引入到更复杂的组合秘书问题中。其提出的竞争性算法和真实机制在性能上达到了或超越了现有技术水平，尤其是在处理组合结构和战略性行为方面，展示了其创新性和实用性。"}}
{"id": "2503.09215", "title": "Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space", "authors": ["Jian Zhu", "Zhengyu Jia", "Tian Gao", "Jiaxin Deng", "Shidi Li", "Lang Zhang", "Fu Liu", "Peng Jia", "Xianpeng Lang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures", "url": "http://arxiv.org/abs/2503.09215v3", "summary": "Advanced end-to-end autonomous driving systems predict other vehicles'\nmotions and plan ego vehicle's trajectory. The world model that can foresee the\noutcome of the trajectory has been used to evaluate the autonomous driving\nsystem. However, existing world models predominantly emphasize the trajectory\nof the ego vehicle and leave other vehicles uncontrollable. This limitation\nhinders their ability to realistically simulate the interaction between the ego\nvehicle and the driving scenario. In this paper, we propose a driving World\nModel named EOT-WM, unifying Ego-Other vehicle Trajectories in videos for\ndriving simulation. Specifically, it remains a challenge to match multiple\ntrajectories in the BEV space with each vehicle in the video to control the\nvideo generation. We first project ego-other vehicle trajectories in the BEV\nspace into the image coordinate for vehicle-trajectory match via pixel\npositions. Then, trajectory videos are encoded by the Spatial-Temporal\nVariational Auto Encoder to align with driving video latents spatially and\ntemporally in the unified visual space. A trajectory-injected diffusion\nTransformer is further designed to denoise the noisy video latents for video\ngeneration with the guidance of ego-other vehicle trajectories. In addition, we\npropose a metric based on control latent similarity to evaluate the\ncontrollability of trajectories. Extensive experiments are conducted on the\nnuScenes dataset, and the proposed model outperforms the state-of-the-art\nmethod by 30% in FID and 55% in FVD. The model can also predict unseen driving\nscenes with self-produced trajectories.", "comment": "8 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2503.09215v3", "cate": "cs.CV", "date": "2025-03-12", "updated": "2025-07-31", "AI": {"title_translation": "其他车辆轨迹也需要：一种驾驶世界模型在视频潜在空间中统一自我-其他车辆轨迹", "tldr": "提出了一种名为EOT-WM的驾驶世界模型，通过在视频潜在空间中统一自我车辆和其他车辆的轨迹，解决了现有世界模型在模拟车辆交互方面的局限性，显著提升了驾驶模拟的真实性和预测能力。", "motivation": "现有自动驾驶世界模型主要侧重于自我车辆轨迹，而忽略了对其他车辆的控制，这限制了它们真实模拟自我车辆与驾驶场景交互的能力。", "method": "提出了一种名为EOT-WM的驾驶世界模型。首先，将BEV空间中的自我-其他车辆轨迹投影到图像坐标，通过像素位置进行车辆-轨迹匹配。然后，通过时空变分自编码器编码轨迹视频，使其在统一视觉空间中与驾驶视频潜在空间进行时空对齐。最后，设计了一个轨迹注入扩散Transformer，在自我-其他车辆轨迹的指导下，去噪生成视频。此外，还提出了一个基于控制潜在相似性的度量来评估轨迹的可控性。", "result": "在nuScenes数据集上进行了广泛实验，所提出的模型在FID上优于现有技术30%，在FVD上优于55%。该模型还可以利用自生成的轨迹预测未见的驾驶场景。", "conclusion": "该研究提出的EOT-WM模型通过统一自我车辆和其他车辆的轨迹，显著提升了驾驶世界模型在模拟复杂驾驶交互方面的真实性和预测能力，超越了现有技术水平。", "translation": "先进的端到端自动驾驶系统预测其他车辆的运动并规划自我车辆的轨迹。能够预见轨迹结果的世界模型已被用于评估自动驾驶系统。然而，现有的世界模型主要强调自我车辆的轨迹，并使其他车辆不可控。这一局限性阻碍了它们真实模拟自我车辆与驾驶场景之间交互的能力。在本文中，我们提出了一种名为EOT-WM的驾驶世界模型，该模型在视频中统一了自我-其他车辆轨迹，用于驾驶模拟。具体来说，将BEV空间中的多条轨迹与视频中的每辆车进行匹配以控制视频生成仍然是一个挑战。我们首先将BEV空间中的自我-其他车辆轨迹投影到图像坐标，通过像素位置进行车辆-轨迹匹配。然后，轨迹视频通过时空变分自编码器编码，以便在统一的视觉空间中与驾驶视频潜在空间在空间和时间上对齐。进一步设计了一个轨迹注入扩散Transformer，在自我-其他车辆轨迹的指导下，对噪声视频潜在空间进行去噪以生成视频。此外，我们提出了一种基于控制潜在相似性的度量来评估轨迹的可控性。在nuScenes数据集上进行了广泛实验，所提出的模型在FID上优于现有技术30%，在FVD上优于55%。该模型还可以利用自生成的轨迹预测未见的驾驶场景。", "summary": "本文提出了一种名为EOT-WM的驾驶世界模型，旨在解决现有世界模型在模拟自动驾驶场景中，忽视其他车辆轨迹的局限性。EOT-WM通过将自我车辆和其他车辆的轨迹投影到图像坐标并利用时空变分自编码器和轨迹注入扩散Transformer，在视频潜在空间中统一并生成受控的驾驶视频。该模型能够真实模拟车辆间的交互，并在nuScenes数据集上表现出显著优于现有技术的性能，提升了30%的FID和55%的FVD，同时能预测未见的驾驶场景。", "keywords": "驾驶世界模型, 自我-其他车辆轨迹, 视频潜在空间, 扩散模型, 驾驶模拟", "comments": "该论文的创新点在于首次将自我车辆和其他车辆的轨迹统一到一个世界模型中，解决了现有模型在模拟多车交互时的不足。通过引入视频潜在空间和扩散模型，实现了对驾驶场景更真实、更可控的视频生成，这对于自动驾驶系统的评估和训练具有重要意义。性能提升显著，表明了方法的有效性。"}}
{"id": "2507.23033", "title": "Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields", "authors": ["Ranxi Lin", "Canming Yao", "Jiayi Li", "Weihang Liu", "Xin Lou", "Pingqiang Zhou"], "categories": ["cs.CV", "cs.NE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23033v1", "summary": "Neural Radiance Fields (NeRF)-based models have achieved remarkable success\nin 3D reconstruction and rendering tasks. However, during both training and\ninference, these models rely heavily on dense point sampling along rays from\nmultiple viewpoints, resulting in a surge in floating-point operations and\nseverely limiting their use in resource-constrained scenarios like edge\ncomputing. Spiking Neural Networks (SNNs), which communicate via binary spikes\nover discrete time steps, offer a promising alternative due to their\nenergy-efficient nature. Given the inherent variability in scene scale and\ntexture complexity in neural rendering and the prevailing practice of training\nseparate models per scene, we propose a spike-based NeRF framework with a\ndynamic time step training strategy, termed Pretrain-Adaptive Time-step\nAdjustment (PATA). This approach automatically explores the trade-off between\nrendering quality and time step length during training. Consequently, it\nenables scene-adaptive inference with variable time steps and reduces the\nadditional consumption of computational resources in the inference process.\nAnchoring to the established Instant-NGP architecture, we evaluate our method\nacross diverse datasets. The experimental results show that PATA can preserve\nrendering fidelity while reducing inference time steps by 64\\% and running\npower by 61.55\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23033v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "自适应时间步训练以增强基于脉冲的神经辐射场", "tldr": "提出PATA，一种基于脉冲神经网络的NeRF框架，通过自适应时间步训练显著降低推理时间和功耗，同时保持渲染质量，解决资源受限场景下的NeRF应用问题。", "motivation": "NeRF模型在3D重建和渲染中表现出色，但依赖密集点采样导致浮点运算量大，严重限制了它们在边缘计算等资源受限场景中的使用。脉冲神经网络（SNNs）因其高能效特性，提供了一种有前景的替代方案。", "method": "本文提出了一种名为PATA（Pretrain-Adaptive Time-step Adjustment）的基于脉冲的NeRF框架，采用动态时间步训练策略。该方法在训练过程中自动探索渲染质量和时间步长度之间的权衡，从而实现场景自适应的变时间步推理，并减少推理过程中的额外计算资源消耗。该方法以Instant-NGP架构为基础进行评估。", "result": "PATA方法在保持渲染保真度的同时，可将推理时间步减少64%，运行功耗降低61.55%。", "conclusion": "PATA方法能够有效提升基于脉冲神经网络的NeRF在资源受限环境下的应用效率，通过自适应时间步训练显著降低推理成本，同时保持高质量渲染。", "translation": "神经辐射场（NeRF）模型在3D重建和渲染任务中取得了显著成功。然而，在训练和推理过程中，这些模型严重依赖沿射线从多个视角进行的密集点采样，导致浮点运算量激增，并严重限制了它们在边缘计算等资源受限场景中的使用。脉冲神经网络（SNNs）通过离散时间步长的二进制脉冲进行通信，由于其高能效特性，提供了一种有前景的替代方案。考虑到神经渲染中场景尺度和纹理复杂性的固有变化，以及目前每个场景训练一个独立模型的普遍做法，我们提出了一种基于脉冲的NeRF框架，采用动态时间步训练策略，称为预训练-自适应时间步调整（PATA）。这种方法在训练过程中自动探索渲染质量和时间步长度之间的权衡。因此，它能够实现具有可变时间步的场景自适应推理，并减少推理过程中计算资源的额外消耗。以已有的Instant-NGP架构为基础，我们在不同数据集上评估了我们的方法。实验结果表明，PATA可以在保持渲染保真度的同时，将推理时间步减少64%，运行功耗降低61.55%。", "summary": "本文提出了一种名为PATA的基于脉冲神经网络（SNN）的神经辐射场（NeRF）框架，旨在解决传统NeRF在资源受限环境下计算量大的问题。PATA引入动态时间步训练策略，在训练过程中自动平衡渲染质量与时间步长度，从而实现场景自适应的变时间步推理。实验结果表明，基于Instant-NGP架构的PATA方法在保持渲染质量的同时，显著降低了推理时间步（64%）和运行功耗（61.55%），为边缘计算等场景下的3D重建和渲染提供了高效解决方案。", "keywords": "神经辐射场, 脉冲神经网络, 自适应时间步, 边缘计算, 3D重建", "comments": "该论文的创新点在于将高能效的脉冲神经网络引入神经辐射场领域，并针对性地提出了自适应时间步训练策略（PATA），有效解决了传统NeRF在资源受限场景下计算量大的瓶颈。其贡献在于提供了一种兼顾渲染质量和计算效率的3D重建与渲染新范式，对于推动NeRF在边缘计算等实际应用中的落地具有重要意义。"}}
{"id": "2507.23686", "title": "From Link Diversity to Cross-Band Feedback Collaboration: A New Perspective on Hybrid Optical-RF Systems", "authors": ["Menghan Li", "Yulin Shao", "Runxin Zhang", "Lu Lu"], "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23686v1", "summary": "We suggest a re-examination of the conventional view that hybrid\noptical-radio frequency (O-RF) systems are primarily diversity-driven networks\nthat switch between RF and optical links for robustness. Instead, we uncover a\nnew architectural opportunity: repurposing the optical downlink to enable\nreal-time feedback channel coding over the RF uplink, where structured decoder\nfeedback is delivered from the access point to guide the transmitter's coding\nstrategy. This insight marks a conceptual paradigm shift from passive link\ndiversity to active cross-band collaboration, where the wideband,\ninterference-free optical wireless communication (OWC) is no longer merely a\ndownlink backup but a functional enabler of uplink reliability. To realize this\nvision, we propose a novel architecture, O-RF with Cross-Band Feedback\n(O-RF-CBF), that exploits the optical downlink feedback to facilitate adaptive\nRF uplink coding. Numerical results reveal that O-RF-CBF achieves significant\nuplink throughput gains over traditional O-RF systems. Our findings highlight\nthat inter-band synergy, not redundancy, is the key to unlocking the full\npotential of hybrid wireless networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23686v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "从链路分集到跨频带反馈协作：混合光-射频系统的新视角", "tldr": "该研究提出了一种新的混合光-射频（O-RF）系统范式，即利用光下行链路进行射频上行链路的实时反馈信道编码，从而实现跨频带协作，显著提升上行链路吞吐量。", "motivation": "传统观点认为混合光-射频（O-RF）系统主要通过在射频和光链路之间切换来实现鲁棒性，是一种多样性驱动的网络。本文旨在挑战这一传统观点，并发现一种新的架构机会。", "method": "提出了一种新颖的O-RF跨频带反馈（O-RF-CBF）架构。该架构利用光下行链路的反馈信息来促进自适应射频上行链路编码，将宽带、无干扰的光无线通信（OWC）从单纯的下行链路备份转变为上行链路可靠性的功能使能器。", "result": "数值结果表明，O-RF-CBF系统比传统的O-RF系统实现了显著的上行链路吞吐量增益。", "conclusion": "本研究强调，频带间的协同作用而非冗余，是释放混合无线网络全部潜力的关键。这标志着从被动链路分集到主动跨频带协作的概念范式转变。", "translation": "我们建议重新审视混合光-射频（O-RF）系统主要是一种多样性驱动的网络，通过在射频和光链路之间切换来实现鲁棒性的传统观点。相反，我们发现了一种新的架构机会：重新利用光下行链路，以在射频上行链路上实现实时反馈信道编码，其中结构化解码器反馈从接入点传递，以指导发射机的编码策略。这一见解标志着从被动链路分集到主动跨频带协作的概念范式转变，其中宽带、无干扰的光无线通信（OWC）不再仅仅是下行链路的备份，而是上行链路可靠性的功能使能器。为了实现这一愿景，我们提出了一种新颖的架构，即带有跨频带反馈的O-RF（O-RF-CBF），它利用光下行链路反馈来促进自适应射频上行链路编码。数值结果表明，O-RF-CBF比传统O-RF系统实现了显著的上行链路吞吐量增益。我们的发现强调，频带间的协同作用而非冗余，是释放混合无线网络全部潜力的关键。", "summary": "本文挑战了混合光-射频（O-RF）系统主要依赖链路分集实现鲁棒性的传统观点。研究者提出了一种新的架构O-RF-CBF，通过将光下行链路重新用于射频上行链路的实时反馈信道编码，实现了跨频带协作。这种方法将光无线通信从被动备份转变为上行链路可靠性的主动使能器。数值结果显示，与传统O-RF系统相比，O-RF-CBF显著提升了上行链路吞吐量，强调了频带间协同作用对混合无线网络潜力的重要性。", "keywords": "混合光-射频系统, 跨频带反馈, 链路分集, 上行链路吞吐量, 频带协同", "comments": "本文提出了一种新颖的视角，将混合光-射频系统从传统的链路分集概念提升到跨频带反馈协作，具有重要的创新性。其核心思想在于利用光链路的优势来主动增强射频链路的性能，而非仅仅作为备份，这为未来异构网络的协同设计提供了新的思路和可能性。研究结果表明了显著的性能提升，预示着该方法在实际应用中可能带来巨大价值。"}}
{"id": "2507.23095", "title": "SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity", "authors": ["Ishani Mondal", "Meera Bharadwaj", "Ayush Roy", "Aparna Garimella", "Jordan Lee Boyd-Graber"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under Submission", "url": "http://arxiv.org/abs/2507.23095v1", "summary": "We present SMART-Editor, a framework for compositional layout and content\nediting across structured (posters, websites) and unstructured (natural images)\ndomains. Unlike prior models that perform local edits, SMART-Editor preserves\nglobal coherence through two strategies: Reward-Refine, an inference-time\nrewardguided refinement method, and RewardDPO, a training-time preference\noptimization approach using reward-aligned layout pairs. To evaluate model\nperformance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,\ncascading edit scenarios. SMART-Editor outperforms strong baselines like\nInstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in\nstructured settings and Reward-Refine showing advantages on natural images.\nAutomatic and human evaluations confirm the value of reward-guided planning in\nproducing semantically consistent and visually aligned edits.", "comment": "Under Submission", "pdf_url": "http://arxiv.org/pdf/2507.23095v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "SMART-Editor：一个用于类人设计编辑并保持结构完整性的多智能体框架", "tldr": "SMART-Editor是一个多智能体框架，通过奖励引导策略实现跨结构化和非结构化领域的设计编辑，同时保持全局连贯性，并引入了新的评估基准。", "motivation": "现有的模型在执行局部编辑时无法保持全局连贯性，本研究旨在解决这一问题，提供一个能在编辑时保持结构完整性的框架。", "method": "SMART-Editor框架通过两种策略实现：Reward-Refine，一种推理时奖励引导的细化方法；以及RewardDPO，一种使用奖励对齐布局对进行训练时偏好优化的方法。为了评估模型性能，研究引入了SMARTEdit-Bench，一个涵盖多领域、级联编辑场景的基准。", "result": "SMART-Editor在性能上优于InstructPix2Pix和HIVE等强基线模型。其中，RewardDPO在结构化设置中实现了高达15%的增益，而Reward-Refine在自然图像上显示出优势。自动和人工评估均证实了奖励引导规划在生成语义一致和视觉对齐编辑方面的价值。", "conclusion": "奖励引导的规划方法在实现语义一致和视觉对齐的设计编辑中具有重要价值，SMART-Editor通过其Reward-Refine和RewardDPO策略有效地解决了编辑过程中全局连贯性保持的挑战。", "translation": "我们提出了SMART-Editor，一个用于跨结构化（海报、网站）和非结构化（自然图像）领域进行组合布局和内容编辑的框架。与执行局部编辑的现有模型不同，SMART-Editor通过两种策略保持全局连贯性：Reward-Refine，一种推理时奖励引导的细化方法；以及RewardDPO，一种使用奖励对齐布局对进行训练时偏好优化的方法。为了评估模型性能，我们引入了SMARTEdit-Bench，一个涵盖多领域、级联编辑场景的基准。SMART-Editor优于InstructPix2Pix和HIVE等强基线模型，其中RewardDPO在结构化设置中实现了高达15%的增益，Reward-Refine在自然图像上显示出优势。自动和人工评估均证实了奖励引导规划在生成语义一致和视觉对齐编辑方面的价值。", "summary": "SMART-Editor是一个创新的多智能体框架，旨在解决设计编辑中局部修改导致全局不连贯的问题。它通过引入Reward-Refine（推理时细化）和RewardDPO（训练时偏好优化）两种奖励引导策略，实现在结构化和非结构化数据上的连贯编辑。研究还提出了SMARTEdit-Bench基准用于多领域评估。实验结果表明，SMART-Editor显著优于现有基线模型，证明了奖励引导规划在生成高质量、保持语义和视觉一致性编辑方面的有效性。", "keywords": "设计编辑, 多智能体框架, 奖励引导, 结构完整性, 布局编辑", "comments": "该论文的创新点在于提出了一个多智能体框架SMART-Editor，它通过引入奖励引导的策略（Reward-Refine和RewardDPO）来解决设计编辑中保持全局结构完整性的挑战，这是现有模型通常缺乏的能力。此外，引入SMARTEdit-Bench这一新的多领域、级联编辑场景基准，为未来的研究提供了标准化的评估工具，具有重要意义。"}}
{"id": "2507.22914", "title": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs", "authors": ["Victor Eiti Yamamoto", "Hideaki Takeda"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22914v1", "summary": "Knowledge graphs (KGs) are powerful tools for representing and reasoning over\nstructured information. Their main components include schema, identity, and\ncontext. While schema and identity matching are well-established in ontology\nand entity matching research, context matching remains largely unexplored. This\nis particularly important because real-world KGs often vary significantly in\nsource, size, and information density - factors not typically represented in\nthe datasets on which current entity matching methods are evaluated. As a\nresult, existing approaches may fall short in scenarios where diverse and\ncomplex contexts need to be integrated.\n  To address this gap, we propose a novel KG integration method consisting of\nlabel matching and triple matching. We use string manipulation, fuzzy matching,\nand vector similarity techniques to align entity and predicate labels. Next, we\nidentify mappings between triples that convey comparable information, using\nthese mappings to improve entity-matching accuracy. Our approach demonstrates\ncompetitive performance compared to leading systems in the OAEI competition and\nagainst supervised methods, achieving high accuracy across diverse test cases.\nAdditionally, we introduce a new dataset derived from the benchmark dataset to\nevaluate the triple-matching step more comprehensively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22914v1", "cate": "cs.CL", "date": "2025-07-20", "updated": "2025-07-20", "AI": {"title_translation": "全三元组匹配器：整合异构知识图谱之间的所有三元组元素", "tldr": "本文提出一种名为“全三元组匹配器”的新型知识图谱集成方法，通过标签匹配和创新的三元组匹配来解决异构知识图谱中的上下文匹配挑战，并在性能上表现出色。", "motivation": "现有的知识图谱匹配研究主要关注模式和实体匹配，而上下文匹配在异构知识图谱中仍未得到充分探索。现实世界知识图谱在来源、大小和信息密度上差异显著，现有方法难以有效处理这些复杂多样的上下文，导致集成效果不佳。", "method": "本文提出一种新颖的知识图谱集成方法，包括标签匹配和三元组匹配。标签匹配利用字符串操作、模糊匹配和向量相似性技术对齐实体和谓词标签。三元组匹配则识别传达可比信息的三元组之间的映射，并利用这些映射来提高实体匹配的准确性。", "result": "该方法在OAEI竞赛中与领先系统相比表现出竞争力，并与监督方法相比也表现出色，在各种测试用例中均实现了高准确性。此外，还引入了一个从基准数据集衍生出的新数据集，以更全面地评估三元组匹配步骤。", "conclusion": "本文提出的方法有效解决了异构知识图谱的上下文匹配问题，通过结合标签匹配和创新的三元组匹配，显著提升了知识图谱集成的准确性，并为未来研究提供了新的评估数据集。", "translation": "知识图谱（KG）是表示和推理结构化信息的强大工具。它们的主要组成部分包括模式、身份和上下文。虽然模式和身份匹配在本体和实体匹配研究中已得到充分建立，但上下文匹配在很大程度上仍未被探索。这尤其重要，因为现实世界的知识图谱在来源、大小和信息密度上往往差异显著——这些因素通常未在当前实体匹配方法所评估的数据集中得到体现。因此，在需要集成多样化和复杂上下文的场景中，现有方法可能力有不逮。\n为了弥补这一空白，我们提出了一种新颖的KG集成方法，包括标签匹配和三元组匹配。我们使用字符串操作、模糊匹配和向量相似性技术来对齐实体和谓词标签。接下来，我们识别传达可比信息的三元组之间的映射，并利用这些映射来提高实体匹配的准确性。我们的方法在OAEI竞赛中与领先系统相比表现出竞争力，并与监督方法相比也表现出色，在各种测试用例中均实现了高准确性。此外，我们还引入了一个从基准数据集衍生出的新数据集，以更全面地评估三元组匹配步骤。", "summary": "本文提出一种名为“全三元组匹配器”的新型知识图谱集成方法，旨在解决异构知识图谱中的上下文匹配挑战。该方法结合了标签匹配（利用字符串、模糊和向量相似性）和创新的三元组匹配，通过识别具有可比信息的三元组映射来提高实体匹配精度。实验结果表明，该方法在性能上优于或媲美现有领先系统和监督方法，并在多样化测试中表现出高准确性。此外，研究还引入了一个新的数据集用于全面评估三元组匹配。", "keywords": "知识图谱, 三元组匹配, 上下文匹配, 异构知识图谱, 知识图谱集成", "comments": "该论文的创新点在于明确提出了“上下文匹配”的重要性，并引入了“三元组匹配”这一新颖的概念来解决异构知识图谱集成中的这一关键挑战。通过考虑三元组层面的信息，该方法能够更好地处理真实世界知识图谱的复杂性和多样性。其在OAEI竞赛中的竞争力以及新数据集的引入，都显示了该研究的实用价值和对领域的重要贡献。"}}
{"id": "2505.00830", "title": "Intersectional Divergence: Measuring Fairness in Regression", "authors": ["Joe Germino", "Nuno Moniz", "Nitesh V. Chawla"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00830v2", "summary": "Fairness in machine learning research is commonly framed in the context of\nclassification tasks, leaving critical gaps in regression. In this paper, we\npropose a novel approach to measure intersectional fairness in regression\ntasks, going beyond the focus on single protected attributes from existing work\nto consider combinations of all protected attributes. Furthermore, we contend\nthat it is insufficient to measure the average error of groups without regard\nfor imbalanced domain preferences. Accordingly, we propose Intersectional\nDivergence (ID) as the first fairness measure for regression tasks that 1)\ndescribes fair model behavior across multiple protected attributes and 2)\ndifferentiates the impact of predictions in target ranges most relevant to\nusers. We extend our proposal demonstrating how ID can be adapted into a loss\nfunction, IDLoss, that satisfies convergence guarantees and has piecewise\nsmooth properties that enable practical optimization. Through an extensive\nexperimental evaluation, we demonstrate how ID allows unique insights into\nmodel behavior and fairness, and how incorporating IDLoss into optimization can\nconsiderably improve single-attribute and intersectional model fairness while\nmaintaining a competitive balance in predictive performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00830v2", "cate": "cs.LG", "date": "2025-05-01", "updated": "2025-07-31", "AI": {"title_translation": "交叉分歧：衡量回归中的公平性", "tldr": "该论文提出了交叉分歧（ID）和IDLoss，用于衡量和改善回归任务中的交叉公平性，考虑了多个受保护属性和用户相关的预测范围。", "motivation": "机器学习公平性研究主要集中在分类任务，在回归任务中存在空白。现有回归公平性度量未能考虑受保护属性的组合以及不平衡的领域偏好（即用户最相关的预测范围）。", "method": "提出了一种新的回归公平性度量方法：交叉分歧（ID），它超越了单一受保护属性，考虑了多个受保护属性的组合，并区分了预测在与用户最相关的目标范围内的影响。此外，将ID扩展为损失函数IDLoss，该函数具有收敛保证和分段平滑特性，便于实际优化。", "result": "实验评估表明，ID能提供对模型行为和公平性的独特见解。将IDLoss纳入优化可以显著改善单一属性和交叉模型公平性，同时保持预测性能的竞争平衡。", "conclusion": "ID和IDLoss有效解决了回归任务中衡量和改善交叉公平性的空白，为构建更公平的AI系统提供了鲁棒的解决方案。", "translation": "机器学习研究中的公平性通常在分类任务的背景下进行，这在回归任务中留下了关键空白。在本文中，我们提出了一种衡量回归任务中交叉公平性的新方法，超越了现有工作中对单一受保护属性的关注，转而考虑所有受保护属性的组合。此外，我们认为，在不考虑不平衡领域偏好的情况下衡量群体的平均误差是不够的。因此，我们提出了交叉分歧（ID），作为回归任务中第一个公平性度量，它1）描述了跨多个受保护属性的公平模型行为，并且2）区分了预测在与用户最相关的目标范围内的影响。我们进一步扩展了我们的提议，展示了如何将ID适应为损失函数IDLoss，该函数满足收敛保证并具有分段平滑特性，从而实现实际优化。通过广泛的实验评估，我们展示了ID如何提供对模型行为和公平性的独特见解，以及将IDLoss纳入优化如何显著改善单一属性和交叉模型公平性，同时保持预测性能的竞争平衡。", "summary": "本文通过提出交叉分歧（ID）——一种新颖的回归公平性度量方法，解决了机器学习公平性研究在回归任务中的空白。ID考虑了跨多个受保护属性的公平性，并优先考虑与用户相关的预测范围。论文进一步引入了IDLoss，这是一种可适应的损失函数，用于优化模型以实现更好的公平性。实验结果表明，ID提供了独特的洞察力，并且IDLoss显著增强了单一属性和交叉公平性，同时保持了预测性能。", "keywords": "回归公平性, 交叉公平性, 机器学习, 交叉分歧, IDLoss", "comments": "该论文通过将公平性研究从分类扩展到回归，特别是解决了更复杂的交叉公平性挑战，做出了重要贡献。ID的引入及其作为具有收敛保证的实用损失函数IDLoss的适应性，是一个显著的创新。这项工作对于在实际应用中开发更公平的回归模型至关重要，因为在这些应用中，多个人口统计因素和用户特定偏好发挥着作用。"}}
{"id": "2507.22917", "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "authors": ["Kwun Hang Lau", "Ruiyuan Zhang", "Weijie Shi", "Xiaofang Zhou", "Xiaojun Cheng"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22917v1", "summary": "While Retrieval-Augmented Generation (RAG) excels at injecting static,\nfactual knowledge into Large Language Models (LLMs), it exhibits a critical\ndeficit in handling longitudinal queries that require tracking entities and\nphenomena across time. This blind spot arises because conventional,\nsemantically-driven retrieval methods are not equipped to gather evidence that\nis both topically relevant and temporally coherent for a specified duration. We\naddress this challenge by proposing a new framework that fundamentally\nredesigns the RAG pipeline to infuse temporal logic. Our methodology begins by\ndisentangling a user's query into its core subject and its temporal window. It\nthen employs a specialized retriever that calibrates semantic matching against\ntemporal relevance, ensuring the collection of a contiguous evidence set that\nspans the entire queried period. To enable rigorous evaluation of this\ncapability, we also introduce the Analytical Diachronic Question Answering\nBenchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus\nof real and synthetic financial news. Empirical results on ADQAB show that our\napproach yields substantial gains in answer accuracy, surpassing standard RAG\nimplementations by 13% to 27%. This work provides a validated pathway toward\nRAG systems capable of performing the nuanced, evolutionary analysis required\nfor complex, real-world questions. The dataset and code for this study are\npublicly available at https://github.com/kwunhang/TA-RAG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22917v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "解读时间线：用于回答历时性问题的RAG", "tldr": "本文提出了一种新的RAG框架，通过引入时间逻辑来解决传统RAG在处理需要跨时间跟踪实体和现象的历时性问题时的不足，并在新基准测试上实现了显著的准确性提升。", "motivation": "传统检索增强生成（RAG）在处理需要跨时间跟踪实体和现象的纵向查询时存在显著缺陷，因为传统的语义驱动检索方法无法同时收集主题相关和时间连贯的证据。", "method": "本文提出了一种新的框架，从根本上重新设计了RAG管道以融入时间逻辑。该方法首先将用户查询分解为核心主题和时间窗口，然后采用一个专门的检索器，根据时间相关性校准语义匹配，确保收集到跨越整个查询期间的连续证据集。同时，引入了分析历时性问答基准（ADQAB）进行严格评估。", "result": "在ADQAB基准测试上的实证结果表明，该方法在答案准确性方面取得了显著提升，超过标准RAG实现13%至27%。", "conclusion": "这项工作为RAG系统提供了一条经过验证的途径，使其能够执行复杂现实问题所需的细致、演进分析。", "translation": "尽管检索增强生成（RAG）擅长将静态事实知识注入大型语言模型（LLM），但在处理需要跨时间跟踪实体和实体现象的纵向查询时，它表现出关键的不足。这种盲点产生的原因是传统的、语义驱动的检索方法无法收集到既主题相关又在指定持续时间内时间连贯的证据。我们通过提出一个从根本上重新设计RAG管道以注入时间逻辑的新框架来解决这一挑战。我们的方法始于将用户的查询分解为其核心主题和时间窗口。然后，它采用一个专门的检索器，根据时间相关性校准语义匹配，确保收集到跨越整个查询期间的连续证据集。为了严格评估这种能力，我们还引入了分析历时性问答基准（ADQAB），这是一个基于真实和合成金融新闻混合语料库的具有挑战性的评估套件。ADQAB上的实证结果表明，我们的方法在答案准确性方面取得了显著提升，超过标准RAG实现13%至27%。这项工作为RAG系统提供了一条经过验证的途径，使其能够执行复杂现实问题所需的细致、演进分析。本研究的数据集和代码可在https://github.com/kwunhang/TA-RAG公开获取。", "summary": "本文提出了一种名为“Reading Between the Timelines”的新型RAG框架，旨在解决传统RAG在处理历时性问题（即需要跨时间跟踪实体和现象的查询）时的不足。该框架通过将用户查询分解为主题和时间窗口，并利用一个专门的检索器来平衡语义匹配和时间相关性，从而确保检索到时间连贯的证据集。为评估其有效性，作者引入了ADQAB基准测试。实验结果表明，该方法在答案准确性上显著优于标准RAG，提升了13%至27%，为开发能够进行复杂时间分析的RAG系统提供了可行途径。", "keywords": "RAG, 历时性问题, 时间逻辑, 纵向查询, 问答系统", "comments": "这项工作具有重要的创新性，它解决了RAG在处理时间序列信息方面的核心限制，填补了现有RAG系统在处理“历时性”或“纵向”查询方面的空白。通过引入时间逻辑和专门的时间感知检索器，该研究为RAG系统处理动态、演化信息提供了新的范式。ADQAB基准的引入也极大地推动了该领域的研究和评估。其局限性可能在于，该方法在特定领域（金融新闻）进行了验证，其在其他时间敏感领域的普适性可能需要进一步探索。"}}
{"id": "2507.22893", "title": "Invisible Architectures of Thought: Toward a New Science of AI as Cognitive Infrastructure", "authors": ["Giuseppe Riva"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22893v1", "summary": "Contemporary human-AI interaction research overlooks how AI systems\nfundamentally reshape human cognition pre-consciously, a critical blind spot\nfor understanding distributed cognition. This paper introduces \"Cognitive\nInfrastructure Studies\" (CIS) as a new interdisciplinary domain to\nreconceptualize AI as \"cognitive infrastructures\": foundational, often\ninvisible systems conditioning what is knowable and actionable in digital\nsocieties. These semantic infrastructures transport meaning, operate through\nanticipatory personalization, and exhibit adaptive invisibility, making their\ninfluence difficult to detect. Critically, they automate \"relevance judgment,\"\nshifting the \"locus of epistemic agency\" to non-human systems. Through\nnarrative scenarios spanning individual (cognitive dependency), collective\n(democratic deliberation), and societal (governance) scales, we describe how\ncognitive infrastructures reshape human cognition, public reasoning, and social\nepistemologies. CIS aims to address how AI preprocessing reshapes distributed\ncognition across individual, collective, and cultural scales, requiring\nunprecedented integration of diverse disciplinary methods. The framework also\naddresses critical gaps across disciplines: cognitive science lacks\npopulation-scale preprocessing analysis capabilities, digital sociology cannot\naccess individual cognitive mechanisms, and computational approaches miss\ncultural transmission dynamics. To achieve this goal CIS also provides\nmethodological innovations for studying invisible algorithmic influence:\n\"infrastructure breakdown methodologies\", experimental approaches that reveal\ncognitive dependencies by systematically withdrawing AI preprocessing after\nperiods of habituation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22893v1", "cate": "cs.HC", "date": "2025-06-19", "updated": "2025-06-19", "AI": {"title_translation": "思想的无形架构：迈向将AI视为认知基础设施的新科学", "tldr": "AI系统作为“认知基础设施”在无意识层面重塑人类认知，本文提出“认知基础设施研究”（CIS）来理解和研究这种影响。", "motivation": "当代人机交互研究忽视了AI系统如何在无意识层面根本性地重塑人类认知，这对于理解分布式认知是一个关键盲点。AI自动化了“相关性判断”，将“认知能动性焦点”转移到非人类系统。", "method": "本文引入“认知基础设施研究”（CIS）作为一个新的跨学科领域，将AI重新概念化为“认知基础设施”。通过叙事场景描述认知基础设施如何重塑人类认知、公共推理和社会认知论。CIS旨在解决AI预处理如何重塑分布式认知，并提出了“基础设施故障方法论”等创新方法来研究无形算法影响。", "result": "本文提出了“认知基础设施”的概念及其运作方式（语义传输、预期个性化、适应性隐形），并描述了其对个体、集体和文化层面的认知、公共推理和社会认知论的重塑作用。同时，指出了现有学科在分析人口规模预处理、个体认知机制和文化传播动态方面的关键空白。", "conclusion": "CIS旨在解决AI预处理如何重塑分布式认知，并弥补现有学科在分析人口规模预处理、个体认知机制和文化传播动态方面的空白，为研究无形算法影响提供了方法论创新。", "translation": "当代人机交互研究忽视了AI系统如何在无意识层面根本性地重塑人类认知，这对于理解分布式认知是一个关键的盲点。本文引入“认知基础设施研究”（CIS）作为一个新的跨学科领域，将AI重新概念化为“认知基础设施”：这些基础性、通常无形的系统，决定了数字社会中什么是可知的和可行动的。这些语义基础设施传输意义，通过预期个性化运作，并表现出适应性隐形，使得它们的影响难以被察觉。关键是，它们自动化了“相关性判断”，将“认知能动性焦点”转移到非人类系统。通过涵盖个体（认知依赖）、集体（民主审议）和社会（治理）尺度的叙事场景，我们描述了认知基础设施如何重塑人类认知、公共推理和社会认知论。CIS旨在解决AI预处理如何在个体、集体和文化尺度上重塑分布式认知，这需要前所未有的多学科方法整合。该框架还解决了跨学科的关键空白：认知科学缺乏人口规模预处理分析能力，数字社会学无法访问个体认知机制，计算方法错过了文化传播动态。为了实现这一目标，CIS还提供了研究无形算法影响的方法论创新：“基础设施故障方法论”，这是一种实验方法，通过在习惯期后系统地撤回AI预处理来揭示认知依赖。", "summary": "本文引入“认知基础设施研究”（CIS），将AI系统视为塑造人类认知、公共推理和社会认知论的“认知基础设施”。它强调了当前研究对AI在无意识层面重塑认知的忽视，并提出了一个跨学科框架和创新方法（如“基础设施故障方法论”），以理解和分析AI预处理对分布式认知在个体、集体和文化尺度上的影响，旨在弥补现有学科的空白。", "keywords": "认知基础设施, 分布式认知, 人工智能, 跨学科研究, 认知重塑", "comments": "这篇论文的创新点在于提出了“认知基础设施”这一概念，并将其视为重塑人类认知的基础性、无形系统，这为理解AI的深层社会和认知影响提供了一个全新的视角。它强调了AI对“认知能动性”的转移和“相关性判断”的自动化，揭示了AI对人类思维过程的潜在无意识影响。其提出的跨学科方法和“基础设施故障方法论”具有重要的实践意义，为研究AI的隐形算法影响提供了新的研究范式。"}}
{"id": "2507.12911", "title": "LaViPlan : Language-Guided Visual Path Planning with RLVR", "authors": ["Hayeon Oh"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been withdrawn due to an internal institutional policy that prohibits preprint submissions to arXiv", "url": "http://arxiv.org/abs/2507.12911v3", "summary": "Out-of-distribution (OOD) scenarios in autonomous driving refer to situations\nthat deviate from the training domain, often leading to unexpected and\npotentially hazardous behavior from planners that lack prior exposure to such\ncases. Recently, Vision-Language Models (VLMs) have been introduced into\nautonomous driving research for their promising generalization capabilities in\nOOD settings. Early studies demonstrated that VLMs could recognize OOD\nscenarios and generate user-level decisions such as \"go straight\" or \"turn\nright.\" However, a new challenge has emerged due to the misalignment between\nthe VLM's high-level decisions or visual reasoning expressed in language, and\nthe low-level predicted trajectories interpreted as actions. In this paper, we\npropose LaViPlan, a framework that leverages Reinforcement Learning with\nVerifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.\nThis approach addresses the vision-language-action misalignment observed in\nexisting VLMs fine-tuned via supervised learning, which can recognize driving\nscenarios but often produce context-unaware decisions. Experimental results\ndemonstrate that our method improves situational awareness and decision-making\nunder OOD conditions, highlighting its potential to mitigate the misalignment\nissue. This work introduces a promising post-training paradigm for VLM agents\nin the context of autonomous driving.", "comment": "This paper has been withdrawn due to an internal institutional policy\n  that prohibits preprint submissions to arXiv", "pdf_url": "http://arxiv.org/pdf/2507.12911v3", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-23", "AI": {"title_translation": "LaViPlan : 语言引导的视觉路径规划与RLVR", "tldr": "LaViPlan引入RLVR优化VLM，解决自动驾驶中视觉-语言-动作不匹配问题，提升OOD场景下的情境感知和决策能力。", "motivation": "自动驾驶在分布外（OOD）场景中表现不佳，现有视觉-语言模型（VLM）尽管能识别OOD场景并生成高层决策，但其语言表达的视觉推理与低层预测轨迹（动作）之间存在错位，导致决策缺乏上下文感知。", "method": "本文提出了LaViPlan框架，该框架利用带有可验证奖励的强化学习（RLVR）来优化视觉-语言模型（VLM），使用面向规划的指标来解决现有VLM中存在的视觉-语言-动作不匹配问题。", "result": "实验结果表明，LaViPlan方法在OOD条件下提高了情境感知和决策能力，并有效缓解了视觉-语言-动作不匹配问题。", "conclusion": "LaViPlan为自动驾驶领域的视觉-语言模型代理引入了一种有前景的后训练范式，成功解决了视觉-语言-动作不匹配问题，显著提升了模型在OOD场景下的性能。", "translation": "自动驾驶中的分布外（OOD）场景指的是偏离训练领域的情况，这常常导致缺乏此类情况先验经验的规划器产生意想不到的、可能危险的行为。最近，视觉-语言模型（VLMs）因其在OOD设置中具有良好的泛化能力而被引入自动驾驶研究。早期研究表明，VLM可以识别OOD场景并生成用户级决策，例如“直行”或“右转”。然而，由于VLM的高级决策或以语言表达的视觉推理与解释为动作的低级预测轨迹之间存在错位，出现了一个新挑战。在本文中，我们提出了LaViPlan，一个利用带有可验证奖励的强化学习（RLVR）来优化VLM的框架，该框架使用面向规划的度量。这种方法解决了现有VLM通过监督学习微调时观察到的视觉-语言-动作错位问题，这些VLM可以识别驾驶场景，但通常会产生缺乏上下文感知的决策。实验结果表明，我们的方法在OOD条件下提高了情境感知和决策能力，突出了其缓解错位问题的潜力。这项工作为自动驾驶背景下的VLM代理引入了一种有前景的后训练范式。", "summary": "LaViPlan是一个创新的框架，它利用带有可验证奖励的强化学习（RLVR）来优化视觉-语言模型（VLM），旨在解决自动驾驶中VLM在高层语言决策和低层轨迹动作之间存在的视觉-语言-动作不匹配问题，尤其是在分布外（OOD）场景下。实验证明，LaViPlan能显著提高模型的情境感知和决策能力，为自动驾驶领域的VLM后训练提供了一种有前景的新范式。", "keywords": "自动驾驶, 视觉-语言模型, 强化学习, 路径规划, 分布外场景", "comments": "LaViPlan的创新之处在于其通过引入RLVR来精确优化VLM，从而弥合了高层语言理解与低层动作规划之间的鸿沟。这对于提升自动驾驶系统在复杂和未知OOD环境中的鲁棒性和安全性至关重要，为未来VLM在实际部署中的应用开辟了新的可能性。"}}
{"id": "2507.23777", "title": "XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding", "authors": ["Dian Chen", "Yansong Qu", "Xinyang Li", "Ming Li", "Shengchuan Zhang"], "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23777v1", "summary": "Current auto-regressive models can generate high-quality, topologically\nprecise meshes; however, they necessitate thousands-or even tens of\nthousands-of next-token predictions during inference, resulting in substantial\nlatency. We introduce XSpecMesh, a quality-preserving acceleration method for\nauto-regressive mesh generation models. XSpecMesh employs a lightweight,\nmulti-head speculative decoding scheme to predict multiple tokens in parallel\nwithin a single forward pass, thereby accelerating inference. We further\npropose a verification and resampling strategy: the backbone model verifies\neach predicted token and resamples any tokens that do not meet the quality\ncriteria. In addition, we propose a distillation strategy that trains the\nlightweight decoding heads by distilling from the backbone model, encouraging\ntheir prediction distributions to align and improving the success rate of\nspeculative predictions. Extensive experiments demonstrate that our method\nachieves a 1.7x speedup without sacrificing generation quality. Our code will\nbe released.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23777v1", "cate": "cs.GR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "XSpecMesh：通过多头推测解码实现保质量的自回归网格生成加速", "tldr": "XSpecMesh通过多头推测解码和验证重采样策略，在不牺牲质量的情况下将自回归网格生成速度提高了1.7倍。", "motivation": "当前自回归模型在生成高质量网格时需要大量的下一步词元预测，导致推理延迟高。", "method": "引入XSpecMesh，一种保质量的加速方法。它采用轻量级多头推测解码方案并行预测多个词元，并结合验证和重采样策略来确保质量。此外，还提出了蒸馏策略来训练解码头，提高推测预测的成功率。", "result": "实验表明，该方法在不牺牲生成质量的前提下，实现了1.7倍的速度提升。", "conclusion": "XSpecMesh成功地加速了自回归网格生成，同时保持了生成质量。", "translation": "当前的自回归模型能够生成高质量、拓扑精确的网格；然而，它们在推理过程中需要数千甚至数万次的下一步词元预测，导致巨大的延迟。我们引入了XSpecMesh，一种用于自回归网格生成模型的保质量加速方法。XSpecMesh采用轻量级、多头推测解码方案，在一次前向传播中并行预测多个词元，从而加速推理。我们进一步提出了一种验证和重采样策略：骨干模型验证每个预测的词元，并对任何不符合质量标准的词元进行重采样。此外，我们提出了一种蒸馏策略，通过从骨干模型中蒸馏来训练轻量级解码头，促使它们的预测分布对齐并提高推测预测的成功率。大量实验表明，我们的方法在不牺牲生成质量的情况下实现了1.7倍的加速。我们的代码将发布。", "summary": "本文介绍了XSpecMesh，一种针对自回归网格生成模型的加速方法，旨在解决现有模型推理速度慢的问题。XSpecMesh通过采用轻量级多头推测解码并行预测多个词元，并结合验证重采样策略来确保生成质量。此外，还引入了蒸馏策略以优化解码头的预测能力。实验结果显示，XSpecMesh在保持生成质量的同时，实现了1.7倍的加速。", "keywords": "自回归网格生成, 推测解码, 模型加速, 质量保持, 多头解码", "comments": "这篇论文提出了一种新颖的加速自回归网格生成的方法，通过结合多头推测解码、验证重采样和蒸馏策略，在保持高质量输出的同时显著提升了推理速度。其创新性在于将推测解码应用于网格生成领域，并设计了相应的质量保证机制。这项工作对于需要快速生成高质量三维网格的应用具有重要意义。"}}
{"id": "2408.02123", "title": "FovEx: Human-Inspired Explanations for Vision Transformers and Convolutional Neural Networks", "authors": ["Mahadev Prasad Panda", "Matteo Tiezzi", "Martina Vilas", "Gemma Roig", "Bjoern M. Eskofier", "Dario Zanca"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in the International Journal of Computer Vision (Springer Nature)", "url": "http://arxiv.org/abs/2408.02123v3", "summary": "Explainability in artificial intelligence (XAI) remains a crucial aspect for\nfostering trust and understanding in machine learning models. Current visual\nexplanation techniques, such as gradient-based or class-activation-based\nmethods, often exhibit a strong dependence on specific model architectures.\nConversely, perturbation-based methods, despite being model-agnostic, are\ncomputationally expensive as they require evaluating models on a large number\nof forward passes. In this work, we introduce Foveation-based Explanations\n(FovEx), a novel XAI method inspired by human vision. FovEx seamlessly\nintegrates biologically inspired perturbations by iteratively creating foveated\nrenderings of the image and combines them with gradient-based visual\nexplorations to determine locations of interest efficiently. These locations\nare selected to maximize the performance of the model to be explained with\nrespect to the downstream task and then combined to generate an attribution\nmap. We provide a thorough evaluation with qualitative and quantitative\nassessments on established benchmarks. Our method achieves state-of-the-art\nperformance on both transformers (on 4 out of 5 metrics) and convolutional\nmodels (on 3 out of 5 metrics), demonstrating its versatility among various\narchitectures. Furthermore, we show the alignment between the explanation map\nproduced by FovEx and human gaze patterns (+14\\% in NSS compared to RISE,\n+203\\% in NSS compared to GradCAM). This comparison enhances our confidence in\nFovEx's ability to close the interpretation gap between humans and machines.", "comment": "Accepted in the International Journal of Computer Vision (Springer\n  Nature)", "pdf_url": "http://arxiv.org/pdf/2408.02123v3", "cate": "cs.CV", "date": "2024-08-04", "updated": "2025-07-31", "AI": {"title_translation": "FovEx：受人类启发的视觉Transformer和卷积神经网络解释方法", "tldr": "FovEx是一种受人类视觉启发的AI可解释性方法，它结合了注视点渲染和梯度探索，高效地为视觉Transformer和CNN生成归因图，并在多个基准测试中达到了SOTA性能，且与人类注视模式高度一致。", "motivation": "当前的视觉解释技术，如基于梯度或类别激活的方法，严重依赖于特定的模型架构。而基于扰动的方法虽然与模型无关，但计算成本高昂。因此，需要一种更高效、通用且受人类启发的解释方法。", "method": "FovEx是一种新颖的XAI方法，灵感来源于人类视觉。它通过迭代创建图像的注视点渲染，并将其与基于梯度的视觉探索相结合，以高效地确定感兴趣的位置。这些位置被选择以最大化被解释模型在下游任务上的性能，然后组合生成归因图。", "result": "FovEx在Transformer模型上（5项指标中的4项）和卷积模型上（5项指标中的3项）均达到了最先进的性能，展示了其在各种架构中的通用性。此外，FovEx生成的解释图与人类注视模式高度一致（NSS相比RISE提高14%，相比GradCAM提高203%）。", "conclusion": "FovEx通过结合生物启发式扰动和梯度探索，为视觉Transformer和卷积神经网络提供了高效且与人类行为一致的解释。它在多个基准测试中取得了SOTA性能，并有助于缩小人机解释差距。", "translation": "人工智能可解释性（XAI）仍然是培养机器学习模型信任和理解的关键方面。当前的视觉解释技术，例如基于梯度或基于类别激活的方法，通常对特定模型架构表现出强烈的依赖性。相反，基于扰动的方法，尽管与模型无关，但由于需要对大量前向传播进行模型评估，因此计算成本很高。在这项工作中，我们引入了基于注视点的解释（FovEx），这是一种受人类视觉启发的新型XAI方法。FovEx通过迭代创建图像的注视点渲染并将其与基于梯度的视觉探索相结合，无缝地整合了生物启发式扰动，以高效地确定感兴趣的位置。选择这些位置是为了最大化被解释模型在下游任务上的性能，然后将它们组合起来生成归因图。我们通过对既定基准进行定性和定量评估，提供了全面的评估。我们的方法在Transformer（5项指标中的4项）和卷积模型（5项指标中的3项）上均达到了最先进的性能，展示了其在各种架构中的通用性。此外，我们展示了FovEx生成的解释图与人类注视模式之间的一致性（NSS相比RISE提高14%，相比GradCAM提高203%）。这种比较增强了我们对FovEx弥合人机解释差距能力的信心。", "summary": "FovEx是一种受人类视觉启发的创新型AI可解释性（XAI）方法，旨在解决现有视觉解释技术（如依赖模型架构的梯度方法和计算成本高的扰动方法）的局限性。该方法结合了迭代式注视点渲染和梯度探索，以高效识别图像中的关键区域，并生成归因图。FovEx在视觉Transformer和卷积神经网络上均取得了最先进的性能，并显著提升了解释图与人类注视模式的一致性，有助于增强人机信任和理解。", "keywords": "可解释性AI, 视觉Transformer, 卷积神经网络, 人类视觉, 注视点解释", "comments": "FovEx的创新之处在于其将人类视觉的“注视”机制引入到XAI领域，结合了扰动和梯度方法的优点，同时规避了它们的缺点（模型依赖性或高计算成本）。其在不同模型架构上的SOTA表现和与人类注视模式的高度一致性，是其重要性的体现，表明该方法在提高AI模型可信度和可理解性方面具有巨大潜力。"}}
{"id": "2507.23342", "title": "FAST-LoRa: An Efficient Simulation Framework for Evaluating LoRaWAN Networks and Transmission Parameter Strategies", "authors": ["Laura Acosta García", "Juan Aznar Poveda", "Fabian Margreiter", "Antonio-Javier García Sánchez", "Joan García Haro", "Thomas Fahringer", "José Lorente López", "José-Víctor Rodríguez"], "categories": ["cs.NI", "cs.ET"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23342v1", "summary": "The Internet of Things (IoT) has transformed many industries, and LoRaWAN\n(Long Range Wide Area Network), built on LoRa (Long Range) technology, has\nbecome a crucial solution for enabling scalable, low-cost, and energy-efficient\ncommunication in wide-area networks. Simulation tools are essential for\noptimizing the transmission parameters and, therefore, the energy efficiency\nand performance of LoRaWAN networks. While existing simulation frameworks\naccurately replicate real-world scenarios by including multiple layers of\ncommunication protocols, they often imply significant computational overhead\nand simulation times. To address this issue, this paper introduces FAST-LoRa, a\nnovel simulation framework designed to enable fast and efficient evaluation of\nLoRaWAN networks and selection of transmission parameters. FAST-LoRa\nstreamlines computation by relying on analytical models without complex\npacket-level simulations and implementing gateway reception using efficient\nmatrix operations. Rather than aiming to replace discrete-event simulators,\nFAST-LoRa is intended as a lightweight and accurate approximation tool for\nevaluating transmission parameter strategies in scenarios with stable traffic\npatterns and uplink-focused communications. In our evaluation, we compare\nFAST-LoRa with a well-established simulator using multiple network\nconfigurations with varying numbers of end devices and gateways. The results\nshow that FAST-LoRa achieves similar accuracy in estimating key network\nmetrics, even in complex scenarios with interference and multi-gateway\nreception, with a Mean Absolute Error (MAE) of 0.940 $\\times 10^{-2}$ for the\nPacket Delivery Ratio (PDR) and 0.040 bits/mJ for Energy Efficiency (EE), while\nsignificantly reducing computational time by up to three orders of magnitude.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23342v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "FAST-LoRa：一种评估LoRaWAN网络和传输参数策略的高效仿真框架", "tldr": "FAST-LoRa是一种新的高效仿真框架，用于快速评估LoRaWAN网络和传输参数策略，显著减少了计算时间。", "motivation": "物联网（IoT）的兴起使得LoRaWAN成为低成本、节能型广域通信的关键解决方案。然而，现有的LoRaWAN仿真框架虽然能准确复制真实场景，但计算开销和仿真时间巨大，阻碍了传输参数优化的效率。", "method": "本文提出了FAST-LoRa，它通过依赖分析模型（而非复杂的包级仿真）和使用高效矩阵运算实现网关接收来简化计算。它旨在作为一种轻量级且精确的近似工具，用于在稳定流量模式和上行链路为主的通信场景中评估传输参数策略，而非取代离散事件模拟器。", "result": "FAST-LoRa与现有模拟器相比，在多种网络配置下，即使在存在干扰和多网关接收的复杂场景中，也能在估计关键网络指标（如数据包投递率PDR和能量效率EE）方面达到相似的准确性。PDR的平均绝对误差（MAE）为0.940 × 10^-2，EE为0.040 bits/mJ，同时计算时间显著减少了高达三个数量级。", "conclusion": "FAST-LoRa提供了一个高效且准确的框架，用于快速评估LoRaWAN网络及其传输参数策略，极大地降低了计算成本。", "translation": "物联网（IoT）已改变了许多行业，而基于LoRa（远距离）技术构建的LoRaWAN（远距离广域网）已成为在广域网络中实现可扩展、低成本和节能通信的关键解决方案。仿真工具对于优化传输参数以及LoRaWAN网络的能效和性能至关重要。虽然现有仿真框架通过包含多层通信协议来准确复制真实场景，但它们通常意味着显著的计算开销和仿真时间。为了解决这个问题，本文引入了FAST-LoRa，一个新颖的仿真框架，旨在实现对LoRaWAN网络和传输参数选择的快速高效评估。FAST-LoRa通过依赖分析模型（无需复杂的包级仿真）和使用高效的矩阵运算实现网关接收来简化计算。FAST-LoRa并非旨在取代离散事件模拟器，而是作为一种轻量级且精确的近似工具，用于在稳定流量模式和以上行链路为主的通信场景中评估传输参数策略。在我们的评估中，我们将FAST-LoRa与一个成熟的模拟器进行了比较，使用了不同数量的终端设备和网关的多种网络配置。结果表明，即使在存在干扰和多网关接收的复杂场景中，FAST-LoRa在估计关键网络指标方面也达到了相似的准确性，数据包投递率（PDR）的平均绝对误差（MAE）为0.940 × 10^-2，能量效率（EE）为0.040 bits/mJ，同时计算时间显著减少了高达三个数量级。", "summary": "FAST-LoRa是一种新型的LoRaWAN仿真框架，旨在解决现有仿真工具计算开销大和仿真时间长的问题。它通过采用分析模型和高效矩阵运算来简化计算，避免了复杂的包级仿真。FAST-LoRa作为一种轻量级且精确的近似工具，特别适用于评估稳定流量和上行链路为主的LoRaWAN网络中的传输参数策略。实验结果表明，FAST-LoRa在保证与现有模拟器相似准确性的前提下，将计算时间缩短了高达三个数量级，显著提高了LoRaWAN网络评估的效率。", "keywords": "LoRaWAN, 仿真, 能量效率, 传输参数, FAST-LoRa", "comments": "FAST-LoRa的创新之处在于其通过采用分析模型和矩阵运算来大幅降低LoRaWAN网络仿真的计算复杂度，而不是依赖耗时的包级仿真。这使其成为一个高效且实用的工具，尤其适用于需要快速迭代和优化的场景。尽管它不是为了完全取代复杂的离散事件模拟器，但其在特定场景下（如稳定流量和上行链路通信）的高效率和准确性使其具有重要的应用价值，能够加速LoRaWAN参数优化和网络设计。"}}
{"id": "2404.16705", "title": "SHINE: Social Homology Identification for Navigation in Crowded Environments", "authors": ["Diego Martinez-Baselga", "Oscar de Groot", "Luzia Knoedler", "Luis Riazuelo", "Javier Alonso-Mora", "Luis Montano"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for publication at The International Journal of Robotics Research. Please, when citing the paper, refer to the official manuscript with the following DOI: https://doi.org/10.1177/02783649251344639", "url": "http://arxiv.org/abs/2404.16705v3", "summary": "Navigating mobile robots in social environments remains a challenging task\ndue to the intricacies of human-robot interactions. Most of the motion planners\ndesigned for crowded and dynamic environments focus on choosing the best\nvelocity to reach the goal while avoiding collisions, but do not explicitly\nconsider the high-level navigation behavior (avoiding through the left or right\nside, letting others pass or passing before others, etc.). In this work, we\npresent a novel motion planner that incorporates topology distinct paths\nrepresenting diverse navigation strategies around humans. The planner selects\nthe topology class that imitates human behavior the best using a deep neural\nnetwork model trained on real-world human motion data, ensuring socially\nintelligent and contextually aware navigation. Our system refines the chosen\npath through an optimization-based local planner in real time, ensuring\nseamless adherence to desired social behaviors. In this way, we decouple\nperception and local planning from the decision-making process. We evaluate the\nprediction accuracy of the network with real-world data. In addition, we assess\nthe navigation capabilities in both simulation and a real-world platform,\ncomparing it with other state-of-the-art planners. We demonstrate that our\nplanner exhibits socially desirable behaviors and shows a smooth and remarkable\nperformance.", "comment": "This paper has been accepted for publication at The International\n  Journal of Robotics Research. Please, when citing the paper, refer to the\n  official manuscript with the following DOI: 10.1177/02783649251344639", "pdf_url": "http://arxiv.org/pdf/2404.16705v3", "cate": "cs.RO", "date": "2024-04-25", "updated": "2025-07-31", "AI": {"title_translation": "SHINE: 拥挤环境中导航的社会同源性识别", "tldr": "提出SHINE，一个模仿人类导航行为的运动规划器，用于机器人安全有效地在拥挤环境中导航。", "motivation": "现有运动规划器主要关注避障和速度优化，但没有明确考虑高级别导航行为（如左右避让、让行等），导致机器人在社会环境中导航仍具挑战性。", "method": "本文提出一种新颖的运动规划器SHINE，它结合了代表不同导航策略的拓扑独特路径。该规划器使用在真实人类运动数据上训练的深度神经网络模型选择最能模仿人类行为的拓扑类别，从而确保社会智能和上下文感知的导航。系统通过基于优化的局部规划器实时细化所选路径，将感知和局部规划与决策过程解耦。", "result": "评估了网络预测精度，并在仿真和真实平台中评估了导航能力，并与现有最先进的规划器进行了比较。结果表明，该规划器表现出社会期望的行为，并显示出平稳和卓越的性能。", "conclusion": "SHINE规划器通过模仿人类导航行为，实现了机器人在拥挤社会环境中的平稳、卓越且符合社会规范的导航。", "translation": "导航移动机器人在社会环境中仍然是一项具有挑战性的任务，因为人机交互的复杂性。大多数为拥挤和动态环境设计的运动规划器专注于选择最佳速度以达到目标同时避免碰撞，但没有明确考虑高级别的导航行为（例如通过左侧或右侧避让，让其他人通过或在其他人之前通过等）。在这项工作中，我们提出了一种新颖的运动规划器，它结合了代表围绕人类的不同导航策略的拓扑独特路径。该规划器使用在真实人类运动数据上训练的深度神经网络模型选择最能模仿人类行为的拓扑类别，确保了社会智能和上下文感知的导航。我们的系统通过基于优化的局部规划器实时细化所选路径，确保无缝遵守期望的社会行为。通过这种方式，我们将感知和局部规划与决策过程解耦。我们使用真实世界数据评估了网络的预测精度。此外，我们还在仿真和真实世界平台中评估了导航能力，并将其与其他最先进的规划器进行了比较。我们证明我们的规划器表现出社会期望的行为，并显示出平稳和卓越的性能。", "summary": "本文提出SHINE，一种新颖的运动规划器，旨在解决机器人在拥挤社会环境中导航的挑战。它通过整合代表不同导航策略的拓扑路径，并利用在人类运动数据上训练的深度神经网络来模仿人类行为，从而实现社会智能和上下文感知的导航。SHINE将感知和局部规划与决策解耦，并通过实时优化细化路径。实验结果表明，SHINE在仿真和真实环境中均表现出卓越的社会化导航性能。", "keywords": "机器人导航, 拥挤环境, 社会化行为, 深度学习, 运动规划", "comments": "本文的创新之处在于其将高层次的人类导航行为（如避让策略）融入到机器人运动规划中，而非仅仅关注避障。通过引入拓扑路径和深度学习模型模仿人类行为，提升了机器人在复杂社会环境中的适应性和自然性。将感知和局部规划与决策解耦的设计也值得关注。"}}
{"id": "2507.23581", "title": "GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning", "authors": ["Chuanyue Yu", "Kuo Zhao", "Yuhan Li", "Heng Chang", "Mingjian Feng", "Xiangzhe Jiang", "Yufei Sun", "Jia Li", "Yuzhi Zhang", "Jianxin Li", "Ziwei Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23581v1", "summary": "Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness\nin enhancing the reasoning abilities of LLMs by leveraging graph structures for\nknowledge representation and modeling complex real-world relationships.\nHowever, existing GraphRAG methods still face significant bottlenecks when\nhandling complex problems that require multi-hop reasoning, as their query and\nretrieval phases are largely based on pre-defined heuristics and do not fully\nutilize the reasoning potentials of LLMs. To address this problem, we propose\nGraphRAG-R1, an adaptive GraphRAG framework by training LLMs with\nprocess-constrained outcome-based reinforcement learning (RL) to enhance the\nmulti-hop reasoning ability. Our method can decompose complex problems,\nautonomously invoke retrieval tools to acquire necessary information, and\nperform effective reasoning. Specifically, we utilize a modified version of\nGroup Relative Policy Optimization (GRPO) that supports rollout-with-thinking\ncapability. Next, we design two process-constrained reward functions. To handle\nthe shallow retrieval problem, we design a Progressive Retrieval Attenuation\n(PRA) reward to encourage essential retrievals. Then, to handle the\nover-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the\nmodel performance with computational costs. We further design a phase-dependent\ntraining strategy, containing three training stages corresponding to cold start\nand these two rewards. Lastly, our method adopts a hybrid graph-textual\nretrieval to improve the reasoning capacity. Extensive experimental results\ndemonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex\nreasoning problems compared to state-of-the-art GraphRAG methods on both\nin-domain and out-of-domain datasets. Furthermore, our framework can be\nflexibly integrated with various existing retrieval methods, consistently\ndelivering performance improvements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23581v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "GraphRAG-R1：基于过程约束强化学习的图检索增强生成", "tldr": "GraphRAG-R1通过引入过程约束强化学习来提升LLM在复杂多跳推理中的能力，解决了现有GraphRAG方法在查询和检索阶段的瓶颈。", "motivation": "现有GraphRAG方法在处理需要多跳推理的复杂问题时面临显著瓶颈，因为其查询和检索阶段主要基于预定义启发式，未能充分利用LLM的推理潜力。", "method": "提出GraphRAG-R1，一个通过过程约束结果导向强化学习训练LLM的自适应GraphRAG框架。具体方法包括：修改版的Group Relative Policy Optimization (GRPO)支持“思考式”展开；设计两种过程约束奖励函数，即用于鼓励必要检索的渐进式检索衰减（PRA）奖励和用于平衡性能与计算成本的成本感知F1（CAF）奖励；设计阶段依赖的训练策略（包含冷启动和两种奖励对应的三个训练阶段）；采用混合图文检索。", "result": "GraphRAG-R1在域内和域外数据集上，与最先进的GraphRAG方法相比，显著提升了LLM解决复杂推理问题的能力。此外，该框架可以灵活集成到各种现有检索方法中，并持续带来性能提升。", "conclusion": "GraphRAG-R1通过引入过程约束强化学习，有效解决了现有GraphRAG在复杂多跳推理中的局限性，显著提升了大型语言模型在复杂推理任务上的表现，并展现出良好的泛化和集成能力。", "translation": "图检索增强生成（GraphRAG）通过利用图结构进行知识表示和建模复杂的现实世界关系，在增强大型语言模型（LLMs）的推理能力方面表现出巨大效用。然而，现有GraphRAG方法在处理需要多跳推理的复杂问题时仍面临显著瓶颈，因为它们的查询和检索阶段主要基于预定义启发式，未能充分利用LLMs的推理潜力。为了解决这个问题，我们提出了GraphRAG-R1，一个通过过程约束结果导向强化学习（RL）训练LLMs以增强多跳推理能力的自适应GraphRAG框架。我们的方法可以分解复杂问题，自主调用检索工具获取必要信息，并执行有效推理。具体来说，我们利用修改版的Group Relative Policy Optimization (GRPO)，支持“思考式”展开能力。接下来，我们设计了两个过程约束奖励函数。为了解决浅层检索问题，我们设计了渐进式检索衰减（PRA）奖励，以鼓励必要的检索。然后，为了解决过度思考问题，我们设计了成本感知F1（CAF）奖励，以平衡模型性能与计算成本。我们进一步设计了阶段依赖的训练策略，包含与冷启动和这两种奖励相对应的三个训练阶段。最后，我们的方法采用混合图文检索来提高推理能力。广泛的实验结果表明，与最先进的GraphRAG方法相比，GraphRAG-R1在域内和域外数据集上都提升了LLM解决复杂推理问题的能力。此外，我们的框架可以灵活地与各种现有检索方法集成，持续带来性能改进。", "summary": "GraphRAG-R1是一个创新的图检索增强生成框架，旨在通过引入过程约束强化学习来克服现有GraphRAG在处理复杂多跳推理时的局限性。它通过训练大型语言模型（LLMs）来分解复杂问题、自主检索信息并进行有效推理。该方法引入了支持“思考式”展开的GRPO变体，并设计了PRA和CAF两种过程约束奖励函数，分别用于鼓励必要检索和平衡性能与成本。结合阶段依赖训练策略和混合图文检索，实验证明GraphRAG-R1显著提升了LLMs在复杂推理任务上的表现，并能与现有检索方法灵活集成。", "keywords": "GraphRAG, 强化学习, 多跳推理, LLMs, 图神经网络", "comments": "该论文的创新点在于将过程约束强化学习引入GraphRAG框架，以解决多跳推理中的启发式瓶颈。特别是PRA和CAF奖励函数的设计，分别针对浅层检索和过度思考问题，体现了对实际应用中效率和效果的平衡考量。其通用性体现在可以与现有检索方法灵活集成，这对于实际部署具有重要意义。"}}
{"id": "2507.23779", "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "authors": ["Miaosen Zhang", "Ziqiang Xu", "Jialiang Zhu", "Qi Dai", "Kai Qiu", "Yifan Yang", "Chong Luo", "Tianyi Chen", "Justin Wagle", "Tim Franklin", "Baining Guo"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23779v1", "summary": "With the development of multimodal reasoning models, Computer Use Agents\n(CUAs), akin to Jarvis from \\textit{\"Iron Man\"}, are becoming a reality. GUI\ngrounding is a core component for CUAs to execute actual actions, similar to\nmechanical control in robotics, and it directly leads to the success or failure\nof the system. It determines actions such as clicking and typing, as well as\nrelated parameters like the coordinates for clicks. Current end-to-end\ngrounding models still achieve less than 65\\% accuracy on challenging\nbenchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from\nbeing ready for deployment. % , as a single misclick can result in unacceptable\nconsequences. In this work, we conduct an empirical study on the training of\ngrounding models, examining details from data collection to model training.\nUltimately, we developed the \\textbf{Phi-Ground} model family, which achieves\nstate-of-the-art performance across all five grounding benchmarks for models\nunder $10B$ parameters in agent settings. In the end-to-end model setting, our\nmodel still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on\nScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the\nvarious details discussed in this paper, along with our successes and failures,\nnot only clarify the construction of grounding models but also benefit other\nperception tasks. Project homepage:\n\\href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23779v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Phi-Ground 技术报告：推进 GUI 接地感知", "tldr": "开发了Phi-Ground模型家族，显著提高了GUI接地模型的准确性，在多个基准测试中达到了最先进的性能，解决了现有模型准确率低的问题。", "motivation": "现有的端到端接地模型在挑战性基准测试上的准确率低于65%，远未达到可部署的水平，因为一次误点击可能导致不可接受的后果。因此，需要提高GUI接地模型的性能。", "method": "本文对接地模型的训练进行了实证研究，考察了从数据收集到模型训练的细节。最终，开发了Phi-Ground模型家族。", "result": "Phi-Ground模型家族在代理设置下，对于10B参数以下的模型，在所有五个接地基准测试中均达到了最先进的性能。在端到端模型设置中，模型在ScreenSpot-pro上获得了43.2分，在UI-Vision上获得了27.2分，均达到了SOTA结果。", "conclusion": "论文中讨论的各种细节，以及我们的成功和失败，不仅阐明了接地模型的构建，而且也有益于其他感知任务。", "translation": "随着多模态推理模型的发展，计算机使用代理（CUAs），类似于《钢铁侠》中的贾维斯，正在成为现实。GUI接地是CUAs执行实际操作的核心组件，类似于机器人技术中的机械控制，它直接导致系统的成功或失败。它决定了点击和打字等操作，以及点击的坐标等相关参数。当前的端到端接地模型在ScreenSpot-pro和UI-Vision等挑战性基准测试上的准确率仍低于65%，这表明它们远未达到可部署的程度，因为一次误点击可能导致不可接受的后果。在这项工作中，我们对接地模型的训练进行了实证研究，考察了从数据收集到模型训练的细节。最终，我们开发了Phi-Ground模型家族，该模型在代理设置中，对于10B参数以下的模型，在所有五个接地基准测试中均达到了最先进的性能。在端到端模型设置中，我们的模型在ScreenSpot-pro上仍取得了43.2分，在UI-Vision上取得了27.2分的SOTA结果。我们相信，本文中讨论的各种细节，以及我们的成功和失败，不仅阐明了接地模型的构建，而且也有益于其他感知任务。项目主页：https://zhangmiaosen2000.github.io/Phi-Ground/", "summary": "本文提出Phi-Ground模型家族，通过对GUI接地模型训练的实证研究，解决了现有模型在挑战性基准测试上准确率低的问题。Phi-Ground在代理设置和端到端模型设置中均达到了最先进的性能，显著提高了计算机使用代理执行实际操作的准确性和可靠性。", "keywords": "GUI grounding, Computer Use Agents, Phi-Ground, Perception, State-of-the-art", "comments": "这篇论文通过对GUI接地模型训练的深入实证研究，开发了Phi-Ground模型家族，显著提升了该领域的最先进水平。其创新之处在于系统性地考察了从数据收集到模型训练的各个细节，并成功地将这些洞察转化为实际的性能提升。对于计算机使用代理（CUA）而言，GUI接地是核心且关键的组件，Phi-Ground的成功将直接推动CUA的实用化进程。其结果在多个基准测试中均达到SOTA，证明了其方法的有效性。此外，作者强调其经验教训也能惠及其他感知任务，这增加了研究的普适性和潜在影响力。"}}
{"id": "2507.23565", "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23565v1", "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23565v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "语义信任链：基于超图辅助智能体AI的协作者选择自主信任编排", "tldr": "本文提出了一种名为“语义信任链”的自主信任编排方法，利用智能体AI和超图在分布式协作系统中实现资源高效的信任评估和协作者选择。", "motivation": "在协作系统中，任务的有效完成依赖于对潜在设备的特定任务信任评估。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。不合时宜或过于频繁的信任评估会降低受限资源的利用率，从而对协作任务的执行产生负面影响。", "method": "本文提出了一种基于语义信任链概念的自主信任编排方法。该技术利用智能体AI和超图来建立和维护设备间的信任关系。智能体AI通过自主感知、任务分解和语义推理，仅在设备空闲期间根据历史性能数据自主执行协作者的信任评估，从而实现分布式资源的高效利用。此外，智能体AI通过分析资源能力与任务需求之间的一致性，对协作者资源进行特定任务的信任评估。通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI实现了协作者的分层管理，并根据信任语义识别需要信任评估的协作者，从而在开销和信任准确性之间取得平衡。多个设备的局部信任超图可以链接在一起，支持多跳协作，从而实现大规模系统中的高效协调。", "result": "实验结果表明，所提出的方法实现了资源高效的信任评估。", "conclusion": "本文提出的基于语义信任链的自主信任编排方法，通过结合智能体AI和超图，有效解决了分布式协作系统中信任评估的资源消耗和效率问题，实现了资源高效且准确的协作者信任评估。", "translation": "在协作系统中，任务的有效完成取决于对潜在设备进行分布式协作的特定任务信任评估。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。因此，不合时宜或过于频繁的信任评估会降低受限资源的利用率，从而对协作任务的执行产生负面影响。为了解决这一挑战，本文提出了一种基于语义信任链新概念的自主信任编排方法。我们的技术采用智能体AI和超图来建立和维护设备之间的信任关系。通过利用其在自主感知、任务分解和语义推理方面的优势，我们提出智能体AI感知设备状态，并仅在设备空闲期间根据历史性能数据自主执行协作者的信任评估，从而实现分布式资源的高效利用。此外，智能体AI通过分析资源能力与任务要求之间的一致性，对协作者资源进行特定任务的信任评估。此外，通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI能够对协作者进行分层管理，并根据信任语义识别需要信任评估的协作者，从而在开销和信任准确性之间取得平衡。此外，来自多个设备的局部信任超图可以链接在一起，以支持多跳协作，从而实现大规模系统中的高效协调。实验结果表明，所提出的方法实现了资源高效的信任评估。", "summary": "本文提出了一种名为“语义信任链”的自主信任编排方法，旨在解决分布式协作系统中信任评估的复杂性、资源消耗和效率问题。该方法结合了智能体AI和超图技术，使系统能够在设备空闲期基于历史数据自主进行信任评估，并通过分析资源能力与任务需求的一致性进行任务特定评估。同时，通过维护嵌入信任语义的信任超图，实现了协作者的分层管理和高效识别，并在开销和准确性之间取得平衡。此外，局部信任超图的链式连接支持多跳协作。实验证明，该方法实现了资源高效的信任评估。", "keywords": "语义信任链, 信任编排, 智能体AI, 超图, 信任评估", "comments": "该论文的创新点在于提出了“语义信任链”这一新概念，并将其与智能体AI和超图技术相结合，以实现分布式协作系统中资源高效且自主的信任评估。特别值得注意的是，其通过在设备空闲期进行信任评估的策略，有效解决了评估开销对资源利用率的负面影响，展现了在大型动态协作环境中应用潜力。"}}
{"id": "2411.18337", "title": "Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation", "authors": ["T. G. D. K. Sumanathilaka", "Nicholas Micallef", "Julian Hough"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages,6 tables, 1 figure, Proceedings of the 1st International Conference on NLP & AI for Cyber Security", "url": "http://arxiv.org/abs/2411.18337v4", "summary": "Ambiguous words are often found in modern digital communications. Lexical\nambiguity challenges traditional Word Sense Disambiguation (WSD) methods, due\nto limited data. Consequently, the efficiency of translation, information\nretrieval, and question-answering systems is hindered by these limitations.\nThis study investigates the use of Large Language Models (LLMs) to improve WSD\nusing a novel approach combining a systematic prompt augmentation mechanism\nwith a knowledge base (KB) consisting of different sense interpretations. The\nproposed method incorporates a human-in-loop approach for prompt augmentation\nwhere prompt is supported by Part-of-Speech (POS) tagging, synonyms of\nambiguous words, aspect-based sense filtering and few-shot prompting to guide\nthe LLM. By utilizing a few-shot Chain of Thought (COT) prompting-based\napproach, this work demonstrates a substantial improvement in performance. The\nevaluation was conducted using FEWS test data and sense tags. This research\nadvances accurate word interpretation in social media and digital\ncommunication.", "comment": "12 pages,6 tables, 1 figure, Proceedings of the 1st International\n  Conference on NLP & AI for Cyber Security", "pdf_url": "http://arxiv.org/pdf/2411.18337v4", "cate": "cs.CL", "date": "2024-11-27", "updated": "2025-07-31", "AI": {"title_translation": "LLM 能否辅助消歧？对各种大型语言模型在词义消歧方面的定量评估", "tldr": "本研究通过结合系统提示增强机制和知识库的新方法，并利用少样本思维链提示，展示了大型语言模型在词义消歧方面取得的显著性能提升。", "motivation": "现代数字通信中常出现歧义词，词汇歧义对传统词义消歧（WSD）方法构成挑战，原因在于数据有限。这进而阻碍了翻译、信息检索和问答系统的效率。", "method": "本研究通过结合系统提示增强机制和包含不同词义解释的知识库（KB）的新方法，来利用大型语言模型（LLMs）改进词义消歧（WSD）。所提出的方法采用“人机协作”（human-in-loop）的提示增强方式，其中提示通过词性（POS）标注、歧义词的同义词、基于方面的词义过滤和少样本提示来指导LLM。通过使用少样本思维链（COT）提示方法，该工作展示了性能的显著提升。", "result": "本研究通过使用少样本思维链（COT）提示方法，展示了性能的显著提升。评估使用FEWS测试数据和词义标签进行。", "conclusion": "这项研究推动了社交媒体和数字通信中准确的词语解释。", "translation": "现代数字通信中常出现歧义词。词汇歧义对传统词义消歧（WSD）方法构成挑战，原因在于数据有限。因此，翻译、信息检索和问答系统的效率受到这些限制的阻碍。本研究通过结合系统提示增强机制和包含不同词义解释的知识库（KB）的新方法，来研究使用大型语言模型（LLMs）改进词义消歧。所提出的方法采用“人机协作”（human-in-loop）的提示增强方式，其中提示通过词性（POS）标注、歧义词的同义词、基于方面的词义过滤和少样本提示来指导LLM。通过使用少样本思维链（COT）提示方法，该工作展示了性能的显著提升。评估使用FEWS测试数据和词义标签进行。这项研究推动了社交媒体和数字通信中准确的词语解释。", "summary": "本研究旨在解决数字通信中歧义词对传统词义消歧（WSD）方法造成的挑战。论文提出了一种新颖的方法，结合了大型语言模型（LLMs）、系统提示增强机制和知识库。该方法引入了“人机协作”的提示增强，利用词性标注、同义词、基于方面的词义过滤和少样本思维链（COT）提示来指导LLM。实验结果表明，该方法在词义消歧性能上取得了显著提升，有助于提升社交媒体和数字通信中词语解释的准确性。", "keywords": "词义消歧, 大型语言模型, 提示工程, 思维链, 词汇歧义", "comments": "本文提出了一种新颖的词义消歧方法，通过将LLM与结构化的提示工程和外部知识库相结合，并引入了“人机协作”的增强方式，这在LLM应用中具有创新性。特别是少样本思维链提示的应用，有效提升了模型性能，对于解决传统WSD方法数据受限的挑战具有重要意义。该研究为LLM在语言理解任务中的应用提供了有价值的见解。"}}
{"id": "2507.23317", "title": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "authors": ["Tao He", "Rongchuan Mu", "Lizi Liao", "Yixin Cao", "Ming Liu", "Bing Qin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      33 pages, 3 figures, 19 tables", "url": "http://arxiv.org/abs/2507.23317v1", "summary": "Large reasoning models (LRMs) have recently shown promise in solving complex\nmath problems when optimized with Reinforcement Learning (RL). But conventional\napproaches rely on outcome-only rewards that provide sparse feedback, resulting\nin inefficient optimization process. In this work, we investigate the function\nof process reward models (PRMs) to accelerate the RL training for LRMs. We\npropose a novel intrinsic signal-driven generative process evaluation mechanism\noperating at the thought level to address major bottlenecks in RL-based\ntraining. Specifically, instead of requiring PRMs to know how to solve\nproblems, our method uses intrinsic signals in solutions to judge stepwise\ncorrectness and aggregate contiguous correct/incorrect steps into coherent\n'thought' units. This structured, thought-level rewards enable more reliable\ncredit assignment by reducing ambiguity in step segmentation and alleviating\nreward hacking. We further introduce a capability-adaptive reward mechanism\nthat dynamically balances exploration and exploitation based on the LRM's\ncurrent proficiency, guiding learning without stifling creative\ntrial-and-error. These innovations are integrated into a new off-policy RL\nalgorithm, TP-GRPO, which extends grouped proximal optimization with\nprocess-based rewards and improves training efficiency. Experiments on 1.5B and\n7B parameter LRMs demonstrate that our method achieves higher problem-solving\naccuracy with significantly fewer training samples than outcome-only reward\nbaselines. The results validate that well-structured process rewards can\nsubstantially accelerate LRM optimization in math reasoning tasks. Code is\navailable at https://github.com/cs-holder/tp_grpo.", "comment": "33 pages, 3 figures, 19 tables", "pdf_url": "http://arxiv.org/pdf/2507.23317v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "优秀学习者思考他们的思维：生成式过程奖励模型使大型推理模型成为更高效的数学学习者", "tldr": "本文提出了一种新的生成式过程奖励模型（Generative PRM），通过在思维层面提供结构化奖励，并结合能力自适应奖励机制，显著提高了大型推理模型在数学推理任务中强化学习训练的效率和准确性。", "motivation": "传统的强化学习方法在优化大型推理模型（LRMs）解决复杂数学问题时，依赖于仅基于结果的稀疏奖励，导致优化过程效率低下。", "method": "本文提出了一种新颖的由内在信号驱动的生成式过程评估机制，该机制在思维层面进行操作。具体来说，它不要求过程奖励模型（PRMs）知道如何解决问题，而是利用解决方案中的内在信号来判断分步正确性，并将连续的正确/不正确步骤聚合成连贯的“思维”单元，从而提供结构化、思维层面的奖励。此外，引入了一种能力自适应奖励机制，根据LRM当前的熟练程度动态平衡探索和利用。这些创新被集成到一个新的离策略强化学习算法TP-GRPO中，该算法扩展了分组近端优化并结合了基于过程的奖励。", "result": "在1.5B和7B参数的LRMs上的实验表明，本文方法在显著减少训练样本的情况下，比仅基于结果奖励的基线方法实现了更高的解题准确率。", "conclusion": "结构良好的过程奖励可以显著加速大型推理模型在数学推理任务中的优化。", "translation": "大型推理模型（LRMs）最近在通过强化学习（RL）优化解决复杂数学问题方面展现出潜力。但传统方法依赖于仅基于结果的奖励，提供稀疏反馈，导致优化过程效率低下。在这项工作中，我们研究了过程奖励模型（PRMs）的功能，以加速LRMs的强化学习训练。我们提出了一种新颖的由内在信号驱动的生成式过程评估机制，该机制在思维层面进行操作，以解决基于RL训练的主要瓶颈。具体来说，我们的方法不要求PRMs知道如何解决问题，而是利用解决方案中的内在信号来判断分步正确性，并将连续的正确/不正确步骤聚合成连贯的“思维”单元。这种结构化、思维层面的奖励通过减少步骤分割的模糊性并减轻奖励作弊，实现了更可靠的信用分配。我们进一步引入了一种能力自适应奖励机制，根据LRM当前的熟练程度动态平衡探索和利用，指导学习而不抑制创造性的试错。这些创新被集成到一个新的离策略强化学习算法TP-GRPO中，该算法扩展了分组近端优化并结合了基于过程的奖励，提高了训练效率。在1.5B和7B参数的LRMs上的实验表明，我们的方法在显著减少训练样本的情况下，比仅基于结果奖励的基线方法实现了更高的解题准确率。结果验证了结构良好的过程奖励可以显著加速LRM在数学推理任务中的优化。代码可在https://github.com/cs-holder/tp_grpo获取。", "summary": "本文提出了一种名为生成式过程奖励模型（Generative PRM）的新方法，旨在解决大型推理模型（LRMs）在数学问题上进行强化学习训练时，传统结果奖励稀疏导致效率低下的问题。该方法引入了一种内在信号驱动的思维层面评估机制，将连续的正确/不正确步骤聚合成“思维”单元，并提供结构化奖励，从而实现更可靠的信用分配。此外，还引入了能力自适应奖励机制，动态平衡探索与利用。这些创新被整合到TP-GRPO算法中。实验证明，与传统方法相比，该方法能以更少的训练样本显著提高LRMs的解题准确率，验证了过程奖励在加速数学推理任务优化方面的有效性。", "keywords": "大型推理模型, 过程奖励模型, 强化学习, 数学推理, 效率", "comments": "这项工作在提高大型推理模型训练效率方面具有重要意义，尤其是在复杂推理任务如数学问题解决上。其创新点在于引入了“思维”层面的过程奖励，这比传统的仅基于结果的奖励提供了更精细、更丰富的反馈信号，有效解决了稀疏奖励和信用分配问题。能力自适应奖励机制也很有趣，它有助于在不同学习阶段平衡探索和利用。该方法有望减少训练所需的计算资源和数据量，使大型模型训练更具可行性。"}}
{"id": "2507.23318", "title": "FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning", "authors": ["Jiajun Cao", "Qizhe Zhang", "Peidong Jia", "Xuhui Zhao", "Bo Lan", "Xiaoan Zhang", "Xiaobao Wei", "Sixiang Chen", "Zhuo Li", "Yang Wang", "Liyun Li", "Xianming Liu", "Ming Lu", "Shanghang Zhang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures", "url": "http://arxiv.org/abs/2507.23318v1", "summary": "Vision-Language-Action (VLA) models have demonstrated significant potential\nin complex scene understanding and action reasoning, leading to their\nincreasing adoption in end-to-end autonomous driving systems. However, the long\nvisual tokens of VLA models greatly increase computational costs. Current\nvisual token pruning methods in Vision-Language Models (VLM) rely on either\nvisual token similarity or visual-text attention, but both have shown poor\nperformance in autonomous driving scenarios. Given that human drivers\nconcentrate on relevant foreground areas while driving, we assert that\nretaining visual tokens containing this foreground information is essential for\neffective decision-making. Inspired by this, we propose FastDriveVLA, a novel\nreconstruction-based vision token pruning framework designed specifically for\nautonomous driving. FastDriveVLA includes a plug-and-play visual token pruner\ncalled ReconPruner, which prioritizes foreground information through MAE-style\npixel reconstruction. A novel adversarial foreground-background reconstruction\nstrategy is designed to train ReconPruner for the visual encoder of VLA models.\nOnce trained, ReconPruner can be seamlessly applied to different VLA models\nwith the same visual encoder without retraining. To train ReconPruner, we also\nintroduce a large-scale dataset called nuScenes-FG, consisting of 241K\nimage-mask pairs with annotated foreground regions. Our approach achieves\nstate-of-the-art results on the nuScenes closed-loop planning benchmark across\ndifferent pruning ratios.", "comment": "9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.23318v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "FastDriveVLA：通过即插即用重建式令牌剪枝实现高效端到端驾驶", "tldr": "FastDriveVLA提出了一种新的基于重建的视觉令牌剪枝框架ReconPruner，用于自动驾驶VLA模型，通过优先处理前景信息来降低计算成本，并在nuScenes基准上取得了最先进的结果。", "motivation": "现有的视觉-语言-动作（VLA）模型在自动驾驶中计算成本高昂，因为其视觉令牌过长。当前的视觉令牌剪枝方法（基于相似性或视觉-文本注意力）在自动驾驶场景中表现不佳，且人类驾驶员更关注前景区域，因此需要一种更有效的方法来保留前景信息并降低计算成本。", "method": "本文提出了FastDriveVLA，一个专门为自动驾驶设计的重建式视觉令牌剪枝框架。它包含一个即插即用的视觉令牌剪枝器ReconPruner，该剪枝器通过MAE风格的像素重建来优先处理前景信息。ReconPruner通过一种新颖的对抗性前景-背景重建策略进行训练，一旦训练完成，无需再训练即可无缝应用于具有相同视觉编码器的不同VLA模型。为了训练ReconPruner，作者还引入了一个大型数据集nuScenes-FG，包含24.1万张带有前景区域标注的图像-掩码对。", "result": "FastDriveVLA在nuScenes闭环规划基准测试中，在不同剪枝率下均取得了最先进的（state-of-the-art）结果。", "conclusion": "FastDriveVLA通过其新颖的重建式令牌剪枝方法，有效解决了VLA模型在自动驾驶中计算成本高的问题，同时通过优先处理前景信息，保持甚至提升了决策性能，并在多个剪枝率下达到了SOTA水平。", "translation": "视觉-语言-动作（VLA）模型在复杂场景理解和动作推理方面展现出巨大潜力，因此在端到端自动驾驶系统中得到越来越多的应用。然而，VLA模型的长视觉令牌大大增加了计算成本。当前视觉-语言模型（VLM）中的视觉令牌剪枝方法依赖于视觉令牌相似性或视觉-文本注意力，但这两种方法在自动驾驶场景中都表现不佳。鉴于人类驾驶员在驾驶时会专注于相关的前景区域，我们认为保留包含前景信息的视觉令牌对于有效的决策至关重要。受此启发，我们提出了FastDriveVLA，一个专门为自动驾驶设计的新颖重建式视觉令牌剪枝框架。FastDriveVLA包含一个即插即用的视觉令牌剪枝器ReconPruner，它通过MAE风格的像素重建来优先处理前景信息。设计了一种新颖的对抗性前景-背景重建策略来训练VLA模型视觉编码器的ReconPruner。一旦训练完成，ReconPruner可以无缝应用于具有相同视觉编码器的不同VLA模型，无需重新训练。为了训练ReconPruner，我们还引入了一个名为nuScenes-FG的大规模数据集，包含24.1万对带有标注前景区域的图像-掩码对。我们的方法在nuScenes闭环规划基准测试中，在不同剪枝率下均取得了最先进的结果。", "summary": "FastDriveVLA是一个针对自动驾驶VLA模型提出的高效视觉令牌剪枝框架。它通过引入即插即用的ReconPruner，利用MAE风格的像素重建和对抗性前景-背景重建策略，优先保留视觉令牌中的前景信息，以降低计算成本并提升决策性能。该框架在nuScenes闭环规划基准上取得了最先进的结果，并引入了nuScenes-FG数据集用于训练。其核心优势在于无需对VLA模型进行重新训练即可实现高效剪枝。", "keywords": "视觉-语言-动作模型, 令牌剪枝, 自动驾驶, 前景重建, 计算效率", "comments": "FastDriveVLA的创新之处在于其独特的重建式令牌剪枝方法，特别关注驾驶场景中的前景信息。ReconPruner的即插即用特性显著提高了其实用性和通用性，使其能够轻松集成到现有VLA模型中而无需复杂修改。此外，引入nuScenes-FG数据集为前景信息感知研究提供了宝贵的资源。该工作对于解决VLA模型在自动驾驶中计算效率低下的问题具有重要意义，有望推动更高效、更实用的自动驾驶系统发展。"}}
{"id": "2507.23227", "title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "authors": ["Sophie Kearney", "Shu Yang", "Zixuan Wen", "Bojian Hou", "Duy Duong-Tran", "Tianlong Chen", "Jason Moore", "Marylyn Ritchie", "Li Shen"], "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23227v1", "summary": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex\nneurodegenerative disorder, requires analysis of heterogeneous biomarkers\n(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal\nfluid proteins) typically represented in a tabular format. With flexible\nfew-shot reasoning, multimodal integration, and natural-language-based\ninterpretability, large language models (LLMs) offer unprecedented\nopportunities for prediction with structured biomedical data. We propose a\nnovel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts\nTableGPT2, a multimodal tabular-specialized LLM originally developed for\nbusiness intelligence tasks, for AD diagnosis using structured biomarker data\nwith small sample sizes. Our approach constructs few-shot tabular prompts using\nin-context learning examples from structured biomedical data and finetunes\nTableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary\nclassification task of AD or cognitively normal (CN). The TAP-GPT framework\nharnesses the powerful tabular understanding ability of TableGPT2 and the\nencoded prior knowledge of LLMs to outperform more advanced general-purpose\nLLMs and a tabular foundation model (TFM) developed for prediction tasks. To\nour knowledge, this is the first application of LLMs to the prediction task\nusing tabular biomarker data, paving the way for future LLM-driven multi-agent\nframeworks in biomedical informatics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23227v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "利用大型语言模型在表格生物标志物数据上实现阿尔茨海默病的小样本诊断", "tldr": "TAP-GPT是一个基于LLM的框架，通过小样本学习和微调，利用表格生物标志物数据实现阿尔茨海默病的早期诊断，并优于现有模型。", "motivation": "阿尔茨海默病（AD）的早期准确诊断需要分析异构生物标志物数据，这些数据通常以表格形式呈现。大型语言模型（LLMs）在结构化生物医学数据预测方面展现出小样本推理、多模态集成和基于自然语言的可解释性等优势，为解决这一问题提供了机会。", "method": "本研究提出了一个名为TAP-GPT（Tabular Alzheimer's Prediction GPT）的新颖框架，该框架将最初为商业智能任务开发的表格专业LLM TableGPT2，用于小样本量的结构化生物标志物数据上的AD诊断。该方法通过使用结构化生物医学数据中的上下文学习示例构建小样本表格提示，并使用参数高效的qLoRA适应性微调TableGPT2，以完成AD或认知正常（CN）的临床二分类任务。", "result": "TAP-GPT框架利用TableGPT2强大的表格理解能力和LLM中编码的先验知识，在AD诊断任务上优于更先进的通用LLM和为预测任务开发的表格基础模型（TFM）。", "conclusion": "这是LLM首次应用于使用表格生物标志物数据的预测任务，为未来生物医学信息学中LLM驱动的多智能体框架铺平了道路。", "translation": "阿尔茨海默病（AD）是一种复杂的神经退行性疾病，其早期准确诊断需要分析异构生物标志物（例如，神经影像学、遗传风险因素、认知测试和脑脊液蛋白），这些生物标志物通常以表格形式呈现。大型语言模型（LLMs）凭借其灵活的小样本推理、多模态集成和基于自然语言的可解释性，为结构化生物医学数据预测提供了前所未有的机会。我们提出了一个名为TAP-GPT（Tabular Alzheimer's Prediction GPT）的新颖框架，它将TableGPT2（一个最初为商业智能任务开发的多模态表格专业LLM）应用于使用小样本量的结构化生物标志物数据进行AD诊断。我们的方法通过使用结构化生物医学数据中的上下文学习示例构建小样本表格提示，并使用参数高效的qLoRA适应性微调TableGPT2，以完成AD或认知正常（CN）的临床二分类任务。TAP-GPT框架利用TableGPT2强大的表格理解能力和LLM中编码的先验知识，在性能上超越了更先进的通用LLM和为预测任务开发的表格基础模型（TFM）。据我们所知，这是LLM首次应用于使用表格生物标志物数据的预测任务，为未来生物医学信息学中LLM驱动的多智能体框架铺平了道路。", "summary": "该论文提出了TAP-GPT，一个利用大型语言模型（LLMs）在小样本表格生物标志物数据上诊断阿尔茨海默病（AD）的新框架。TAP-GPT基于TableGPT2，通过上下文学习构建小样本提示，并使用qLoRA进行微调以执行AD与认知正常（CN）的二分类任务。实验结果表明，TAP-GPT在性能上优于其他通用LLM和表格基础模型，是LLM在表格生物标志物数据预测任务中的首次应用。", "keywords": "阿尔茨海默病诊断, 大型语言模型, 表格数据, 小样本学习, 生物标志物", "comments": "该论文的创新点在于首次将大型语言模型应用于表格生物标志物数据上的阿尔茨海默病诊断任务，并提出了一个名为TAP-GPT的特定框架。其重要性体现在能够利用LLM的小样本推理和多模态集成能力，有效处理异构生物标志物数据，并在小样本量下实现优异的诊断性能，这对于早期AD诊断具有重要意义。该研究为未来生物医学信息学中基于LLM的多智能体框架奠定了基础。"}}
{"id": "2408.04503", "title": "Row-aware Randomized SVD with applications", "authors": ["Davide Palitta", "Sascha Portaro"], "categories": ["math.NA", "cs.NA", "65F55, 68W20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 6 figures", "url": "http://arxiv.org/abs/2408.04503v4", "summary": "The randomized singular value decomposition proposed in [27] has certainly\nbecome one of the most well-established randomization-based algorithms in\nnumerical linear algebra. The key ingredient of the entire procedure is the\ncomputation of a subspace which is close to the column space of the target\nmatrix $\\mathbf{A}$ up to a certain probabilistic confidence. In this paper we\nemploy a modification to the standard randomized SVD procedure which leads, in\ngeneral, to better approximations to $\\text{Range}(\\mathbf{A})$ at the same\ncomputational cost. To this end, we explicitly construct information from the\nrow space of $\\mathbf{A}$ enhancing the quality of the approximation. We derive\nnovel error bounds which improve over existing results for $\\mathbf{A}$ having\nimportant gaps in its singular values. We also observe that very few pieces of\ninformation from $\\text{Range}(\\mathbf{A}^T)$ may be necessary. We thus design\na variant of this algorithm equipped with a subsampling step which largely\nincreases the efficiency of the procedure while often attaining competitive\naccuracy records. Our findings are supported by both theoretical analysis and\nnumerical results.", "comment": "28 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2408.04503v4", "cate": "math.NA", "date": "2024-08-08", "updated": "2025-07-31", "AI": {"title_translation": "行感知随机SVD及其应用", "tldr": "本文提出了一种改进的随机奇异值分解（SVD）算法，通过利用行空间信息并引入子采样步骤，在相同计算成本下实现了更好的列空间近似，并提高了效率和精度。", "motivation": "现有的随机SVD算法在逼近目标矩阵的列空间时存在改进空间。本文旨在通过修改标准随机SVD过程，在相同计算成本下获得更好的近似效果，并解决奇异值存在重要间隙的矩阵的误差界问题。", "method": "本文对标准随机SVD过程进行了修改，通过显式构造来自矩阵A的行空间信息来增强近似质量。此外，还设计了一种带有子采样步骤的算法变体，以大幅提高程序效率，同时保持竞争力精度。", "result": "该方法在相同计算成本下，通常能更好地近似Range(A)。推导出了新的误差界，这些误差界改进了现有关于奇异值存在重要间隙的矩阵的结果。观察到来自Range(A^T)的少量信息可能就足够。理论分析和数值结果均支持了这些发现。", "conclusion": "通过利用行空间信息并引入子采样，本文提出的行感知随机SVD算法在近似质量、误差界和计算效率方面均优于现有方法，并得到了理论和数值验证。", "translation": "[27]中提出的随机奇异值分解无疑已成为数值线性代数中最成熟的基于随机化的算法之一。整个过程的关键在于计算一个在一定概率置信度下接近目标矩阵A列空间的子空间。在本文中，我们对标准随机SVD过程进行了修改，这通常能在相同的计算成本下，更好地近似Range(A)。为此，我们明确地从A的行空间构建信息，以提高近似质量。我们推导了新的误差界，这些误差界改进了现有关于奇异值存在重要间隙的A的结果。我们还观察到，可能只需要很少的来自Range(A^T)的信息。因此，我们设计了一种配备子采样步骤的算法变体，这在大幅提高程序效率的同时，通常能获得有竞争力的精度记录。我们的发现得到了理论分析和数值结果的支持。", "summary": "本文提出了一种对标准随机奇异值分解（SVD）的改进算法，通过引入矩阵行空间的信息来增强对列空间的近似质量。该方法在相同计算成本下能获得更好的近似效果，并针对奇异值存在重要间隙的矩阵推导出了新的、更优的误差界。此外，通过设计一种带有子采样步骤的变体，大幅提高了算法效率，同时保持了竞争力精度。理论分析和数值结果均支持了这些发现。", "keywords": "随机SVD, 行空间, 列空间近似, 误差界, 子采样", "comments": "本文的创新之处在于将矩阵的行空间信息整合到随机SVD过程中，从而在不增加计算成本的情况下提高了近似质量，并改进了误差界。引入子采样步骤进一步提升了算法的效率，使其在处理大规模数据时更具实用性。这种“行感知”的方法为随机矩阵算法的改进提供了新的视角。"}}
{"id": "2507.23540", "title": "A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving", "authors": ["Yi Zhang", "Erik Leo Haß", "Kuo-Yi Chao", "Nenad Petrovic", "Yinglei Song", "Chengdong Wu", "Alois Knoll"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23540v1", "summary": "Autonomous driving systems face significant challenges in achieving\nhuman-like adaptability, robustness, and interpretability in complex,\nopen-world environments. These challenges stem from fragmented architectures,\nlimited generalization to novel scenarios, and insufficient semantic extraction\nfrom perception. To address these limitations, we propose a unified\nPerception-Language-Action (PLA) framework that integrates multi-sensor fusion\n(cameras, LiDAR, radar) with a large language model (LLM)-augmented\nVision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered\nreasoning core. This framework unifies low-level sensory processing with\nhigh-level contextual reasoning, tightly coupling perception with natural\nlanguage-based semantic understanding and decision-making to enable\ncontext-aware, explainable, and safety-bounded autonomous driving. Evaluations\non an urban intersection scenario with a construction zone demonstrate superior\nperformance in trajectory tracking, speed prediction, and adaptive planning.\nThe results highlight the potential of language-augmented cognitive frameworks\nfor advancing the safety, interpretability, and scalability of autonomous\ndriving systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23540v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于自适应自动驾驶的统一感知-语言-行动框架", "tldr": "本文提出了一种统一的感知-语言-行动（PLA）框架，该框架结合了多传感器融合和基于GPT-4.1的大型语言模型，以提升自动驾驶系统在复杂环境中的适应性、可解释性和安全性。", "motivation": "自动驾驶系统在复杂开放世界环境中实现类人适应性、鲁棒性和可解释性面临巨大挑战，这些挑战源于碎片化的架构、对新颖场景泛化能力有限以及感知中语义提取不足。", "method": "本文提出了一个统一的感知-语言-行动（PLA）框架。该框架将多传感器融合（摄像头、激光雷达、雷达）与大型语言模型（LLM）增强的视觉-语言-行动（VLA）架构相结合，特别是采用由GPT-4.1驱动的推理核心。它将低级感知处理与高级上下文推理统一起来，紧密耦合感知与基于自然语言的语义理解和决策制定，以实现上下文感知、可解释和安全受限的自动驾驶。", "result": "在包含施工区的城市交叉路口场景中进行的评估表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现出卓越的性能。", "conclusion": "研究结果突出了语言增强认知框架在提升自动驾驶系统安全性、可解释性和可扩展性方面的潜力。", "translation": "自动驾驶系统在复杂、开放世界环境中实现类人适应性、鲁棒性和可解释性面临重大挑战。这些挑战源于碎片化的架构、对新颖场景的泛化能力有限以及感知中语义提取不足。为了解决这些局限性，我们提出了一个统一的感知-语言-行动（PLA）框架，该框架将多传感器融合（摄像头、激光雷达、雷达）与大型语言模型（LLM）增强的视觉-语言-行动（VLA）架构相结合，特别是采用由GPT-4.1驱动的推理核心。该框架将低级感知处理与高级上下文推理统一起来，紧密耦合感知与基于自然语言的语义理解和决策制定，以实现上下文感知、可解释和安全受限的自动驾驶。在包含施工区的城市交叉路口场景中进行的评估表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现出卓越的性能。结果突出了语言增强认知框架在提升自动驾驶系统安全性、可解释性和可扩展性方面的潜力。", "summary": "本文提出了一个统一的感知-语言-行动（PLA）框架，旨在解决自动驾驶系统在复杂环境中适应性、鲁棒性和可解释性方面的挑战。该框架通过整合多传感器融合与基于GPT-4.1的大型语言模型增强的视觉-语言-行动架构，实现了低级感知处理与高级上下文推理的统一，并紧密结合了基于自然语言的语义理解和决策制定。实验结果表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现优异，凸显了语言增强认知框架在提升自动驾驶系统安全性、可解释性和可扩展性方面的巨大潜力。", "keywords": "自动驾驶, 感知-语言-行动, 大型语言模型, 多传感器融合, GPT-4.1", "comments": "该论文的创新之处在于将大型语言模型（特别是GPT-4.1）与多传感器融合技术相结合，构建了一个统一的自动驾驶框架。这对于解决自动驾驶领域中长期存在的解释性和适应性难题具有重要意义，预示着未来自动驾驶系统向更智能、更安全方向发展的潜力。"}}
{"id": "2507.23237", "title": "Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning", "authors": ["Fan Lyu", "Linglan Zhao", "Chengyan Liu", "Yinying Mei", "Zhang Zhang", "Jian Zhang", "Fuyuan Hu", "Liang Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2507.23237v1", "summary": "Few-Shot Class-Incremental Learning (FSCIL) focuses on models learning new\nconcepts from limited data while retaining knowledge of previous classes.\nRecently, many studies have started to leverage unlabeled samples to assist\nmodels in learning from few-shot samples, giving rise to the field of\nSemi-supervised Few-shot Class-Incremental Learning (Semi-FSCIL). However,\nthese studies often assume that the source of unlabeled data is only confined\nto novel classes of the current session, which presents a narrow perspective\nand cannot align well with practical scenarios. To better reflect real-world\nscenarios, we redefine Semi-FSCIL as Generalized Semi-FSCIL (GSemi-FSCIL) by\nincorporating both base and all the ever-seen novel classes in the unlabeled\nset. This change in the composition of unlabeled samples poses a new challenge\nfor existing methods, as they struggle to distinguish between unlabeled samples\nfrom base and novel classes. To address this issue, we propose an\nAmbiguity-guided Learnable Distribution Calibration (ALDC) strategy. ALDC\ndynamically uses abundant base samples to correct biased feature distributions\nfor few-shot novel classes. Experiments on three benchmark datasets show that\nour method outperforms existing works, setting new state-of-the-art results.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.23237v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "歧义引导的可学习分布校准用于半监督小样本类增量学习", "tldr": "本文重新定义了半监督小样本类增量学习（GSemi-FSCIL）以更贴近实际，并提出ALDC策略，通过利用基类样本校准新类特征分布，实现了最先进的性能。", "motivation": "现有的半监督小样本类增量学习（Semi-FSCIL）方法通常假设未标记数据仅限于当前会话的新类，这种狭隘的视角与实际场景不符。同时，在重新定义的广义半监督小样本类增量学习（GSemi-FSCIL）中，现有方法难以区分未标记数据中的基类和新类样本。", "method": "提出了一种歧义引导的可学习分布校准（ALDC）策略。ALDC动态地利用丰富的基类样本来纠正小样本新类中偏差的特征分布。", "result": "在三个基准数据集上的实验表明，该方法优于现有工作，并取得了新的最先进结果。", "conclusion": "通过引入GSemi-FSCIL的现实场景定义并提出ALDC策略以有效校准特征分布，该研究显著提升了半监督小样本类增量学习的性能，解决了现有方法在处理混合未标记数据时的挑战。", "translation": "小样本类增量学习（FSCIL）专注于模型在保留先前类别知识的同时，从有限数据中学习新概念。最近，许多研究开始利用未标记样本辅助模型从少量样本中学习，从而催生了半监督小样本类增量学习（Semi-FSCIL）领域。然而，这些研究通常假设未标记数据的来源仅限于当前会话的新颖类别，这呈现出狭隘的视角，无法很好地与实际场景对齐。为了更好地反映现实世界场景，我们通过在未标记数据集中纳入基类和所有已见过的所有新颖类别，将Semi-FSCIL重新定义为广义半监督小样本类增量学习（GSemi-FSCIL）。未标记样本组成的这种变化对现有方法提出了新的挑战，因为它们难以区分来自基类和新类的未标记样本。为了解决这个问题，我们提出了一种歧义引导的可学习分布校准（ALDC）策略。ALDC动态地利用丰富的基类样本来纠正小样本新类中偏差的特征分布。在三个基准数据集上的实验表明，我们的方法优于现有工作，取得了新的最先进结果。", "summary": "本文针对半监督小样本类增量学习（Semi-FSCIL）中未标记数据来源受限且不切实际的问题，提出了广义半监督小样本类增量学习（GSemi-FSCIL）的新定义，将基类和所有已见过的类别纳入未标记样本集。为解决GSemi-FSCIL中基类与新类未标记样本区分困难的挑战，本文提出歧义引导的可学习分布校准（ALDC）策略，利用基类样本动态校准小样本新类的特征分布。实验证明，该方法在三个基准数据集上超越现有技术，达到了最先进的水平。", "keywords": "半监督学习, 小样本学习, 类增量学习, 分布校准, 歧义引导", "comments": "这篇论文通过重新定义半监督小样本类增量学习（GSemi-FSCIL）的范式，使其更贴近现实世界应用，具有重要的创新性。其提出的ALDC策略有效地解决了在混合未标记数据中区分和校准特征分布的难题，为该领域未来的研究提供了新的思路和强大的基线。"}}
{"id": "2206.03234", "title": "Disparate Conditional Prediction in Multiclass Classifiers", "authors": ["Sivan Sabato", "Eran Treister", "Elad Yom-Tov"], "categories": ["cs.LG", "cs.CY", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at ICML 2025", "url": "http://arxiv.org/abs/2206.03234v3", "summary": "We propose methods for auditing multiclass classifiers for fairness under\nmulticlass equalized odds,by estimating the deviation from equalized odds when\nthe classifier is not completely fair. We generalize to multiclass classifiers\nthe measure of Disparate Conditional Prediction (DCP), originally suggested by\nSabato & Yom-Tov (2020) for binary classifiers. DCP is defined as the fraction\nof the population for which the classifier predicts with conditional prediction\nprobabilities that differ from the closest common baseline. We provide new\nlocal-optimization methods for estimating the multiclass DCPunder two different\nregimes,one in which the conditional confusion matrices for each protected\nsub-population are known, and one in which these cannot be estimated, for\ninstance, because the classifier is inaccessible or because good-quality\nindividual-level data is not available. These methods can be used to detect\nclassifiers that likely treat a significant fraction of the population\nunfairly. Experiments demonstrate the accuracy of the methods. Code is provided\nat https://github.com/sivansabato/ DCPmulticlass.", "comment": "Published at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2206.03234v3", "cate": "cs.LG", "date": "2022-06-07", "updated": "2025-07-31", "AI": {"title_translation": "多类别分类器中的差异化条件预测", "tldr": "本文提出了审计多类别分类器公平性的新方法，通过推广二元分类器的DCP度量并开发新的局部优化方法来估计多类别DCP，以检测不公平的分类器。", "motivation": "审计多类别分类器在多类别均衡赔率下的公平性，特别是当分类器不完全公平时，通过估计其偏离均衡赔率的程度。现有的DCP度量主要针对二元分类器。", "method": "将最初为二元分类器设计的差异化条件预测（DCP）度量推广到多类别分类器，DCP定义为分类器预测的条件预测概率与最接近的共同基线不同的群体比例。提供了两种不同情况下的局部优化新方法来估计多类别DCP：一种是已知每个受保护子群体的条件混淆矩阵，另一种是无法估计这些矩阵的情况。", "result": "实验证明了所提出方法的准确性。这些方法可以用于检测可能对相当一部分人群进行不公平处理的分类器。", "conclusion": "论文提出了有效的方法来审计多类别分类器的公平性，特别是通过推广DCP度量和开发新的估计方法，能够检测出不公平的分类器，并验证了方法的准确性。", "translation": "我们提出了在多类别均衡赔率下审计多类别分类器公平性的方法，通过在分类器不完全公平时估计其与均衡赔率的偏差。我们将最初由Sabato & Yom-Tov (2020) 为二元分类器提出的差异化条件预测 (DCP) 度量推广到多类别分类器。DCP定义为分类器预测的条件预测概率与最接近的共同基线不同的群体比例。我们提供了在两种不同情况下估计多类别DCP的新的局部优化方法：一种是已知每个受保护子群体的条件混淆矩阵，另一种是无法估计这些矩阵的情况，例如，因为分类器不可访问或缺乏高质量的个体级数据。这些方法可用于检测可能对相当一部分人群进行不公平处理的分类器。实验证明了这些方法的准确性。代码可在 https://github.com/sivansabato/DCPmulticlass 上获取。", "summary": "本文针对多类别分类器的公平性审计问题，提出了新的方法。作者将二元分类器中的差异化条件预测（DCP）度量推广到多类别场景，并定义了多类别DCP为分类器预测的条件概率与基线不同的群体比例。论文进一步提供了两种局部优化方法来估计多类别DCP，适用于已知或未知条件混淆矩阵的情况。实验验证了这些方法的准确性，表明它们能有效检测出对部分人群不公平的分类器。", "keywords": "多类别分类器, 公平性, 差异化条件预测 (DCP), 均衡赔率, 局部优化", "comments": "本文在机器学习公平性领域做出了重要贡献，特别是在多类别分类器背景下推广了DCP度量。其创新点在于提出了两种实用的DCP估计方法，尤其涵盖了分类器不可访问或数据受限的实际场景，这大大增强了方法的适用性。这对于实际应用中审计和改善AI系统的公平性具有重要意义。"}}
{"id": "2507.23479", "title": "Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning", "authors": ["Julia Werner", "Oliver Bause", "Julius Oexle", "Maxime Le Floch", "Franz Brinkmann", "Jochen Hampe", "Oliver Bringmann"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at Applications of Medical AI (AMAI workshop) at MICCAI 2025 (submitted version)", "url": "http://arxiv.org/abs/2507.23479v1", "summary": "Video capsule endoscopy has become increasingly important for investigating\nthe small intestine within the gastrointestinal tract. However, a persistent\nchallenge remains the short battery lifetime of such compact sensor edge\ndevices. Integrating artificial intelligence can help overcome this limitation\nby enabling intelligent real-time decision- making, thereby reducing the energy\nconsumption and prolonging the battery life. However, this remains challenging\ndue to data sparsity and the limited resources of the device restricting the\noverall model size. In this work, we introduce a multi-task neural network that\ncombines the functionalities of precise self-localization within the\ngastrointestinal tract with the ability to detect anomalies in the small\nintestine within a single model. Throughout the development process, we\nconsistently restricted the total number of parameters to ensure the\nfeasibility to deploy such model in a small capsule. We report the first\nmulti-task results using the recently published Galar dataset, integrating\nestablished multi-task methods and Viterbi decoding for subsequent time-series\nanalysis. This outperforms current single-task models and represents a\nsignificant ad- vance in AI-based approaches in this field. Our model achieves\nan accu- racy of 93.63% on the localization task and an accuracy of 87.48% on\nthe anomaly detection task. The approach requires only 1 million parameters\nwhile surpassing the current baselines.", "comment": "Accepted at Applications of Medical AI (AMAI workshop) at MICCAI 2025\n  (submitted version)", "pdf_url": "http://arxiv.org/pdf/2507.23479v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "事半功倍：基于多任务学习的视频胶囊内窥镜", "tldr": "本文提出了一种轻量级多任务神经网络，用于视频胶囊内窥镜，在一个模型中同时实现精准自定位和异常检测，显著延长电池寿命并提高性能，同时参数量极小。", "motivation": "视频胶囊内窥镜在小肠检查中日益重要，但其紧凑的边缘设备电池寿命短是主要挑战。整合人工智能可实现智能实时决策，从而降低能耗并延长电池寿命，但现有方法受限于数据稀疏性和设备资源有限导致的模型大小限制。", "method": "本文引入了一个多任务神经网络，将胃肠道内精确自定位功能与小肠异常检测能力集成到一个单一模型中。在开发过程中，严格限制总参数量以确保在小型胶囊中的部署可行性。该研究在Galar数据集上报告了首个多任务结果，结合了既有的多任务方法和用于后续时间序列分析的Viterbi解码。", "result": "该模型在定位任务上取得了93.63%的准确率，在异常检测任务上取得了87.48%的准确率。该方法仅需要100万参数，同时超越了当前的基线，并且优于当前的单任务模型。", "conclusion": "本文提出的多任务学习方法在视频胶囊内窥镜领域代表了基于AI方法的一个重大进步，能够在资源受限的设备上实现更多功能，有效延长了电池寿命并提高了诊断能力。", "translation": "视频胶囊内窥镜在胃肠道内小肠检查中变得日益重要。然而，此类紧凑型传感器边缘设备电池寿命短是一个持续存在的挑战。整合人工智能可以通过实现智能实时决策来帮助克服这一限制，从而降低能耗并延长电池寿命。然而，由于数据稀疏性和设备资源有限导致整体模型大小受限，这仍然具有挑战性。在这项工作中，我们引入了一个多任务神经网络，在一个单一模型中结合了胃肠道内精确自定位功能和检测小肠异常的能力。在整个开发过程中，我们始终限制总参数数量，以确保此类模型在小型胶囊中部署的可行性。我们报告了使用最近发布的Galar数据集的首个多任务结果，整合了既有的多任务方法和用于后续时间序列分析的Viterbi解码。这优于当前的单任务模型，代表了该领域基于人工智能方法的一个重大进步。我们的模型在定位任务上实现了93.63%的准确率，在异常检测任务上实现了87.48%的准确率。该方法仅需要100万参数，同时超越了当前的基线。", "summary": "本研究针对视频胶囊内窥镜电池寿命短的挑战，提出了一种轻量级多任务神经网络。该网络在一个模型中集成了胃肠道内自定位和异常检测功能，并通过严格控制参数量（仅100万）确保在小型胶囊设备上的部署可行性。在Galar数据集上的实验结果表明，该模型在定位和异常检测任务上分别达到93.63%和87.48%的准确率，性能优于现有单任务模型，且参数效率更高，为该领域基于AI的诊断带来了显著进展。", "keywords": "视频胶囊内窥镜, 多任务学习, 自定位, 异常检测, 边缘计算", "comments": "该论文的创新点在于成功地将多任务学习应用于资源受限的视频胶囊内窥镜设备，有效解决了电池寿命短和模型部署困难的问题。通过在一个紧凑的模型中结合定位和异常检测，显著提升了设备的实用性和诊断效率。其在极少参数量下超越基线性能，展示了强大的工程实践能力和模型优化水平，对未来医疗边缘AI设备的发展具有重要指导意义。"}}
{"id": "2503.15621", "title": "LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning", "authors": ["Federico Cocchi", "Nicholas Moratelli", "Davide Caffagni", "Sara Sarto", "Lorenzo Baraldi", "Marcella Cornia", "Rita Cucchiara"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Workshop on What is Next in Multimodal Foundation Models", "url": "http://arxiv.org/abs/2503.15621v2", "summary": "Recent progress in Multimodal Large Language Models (MLLMs) has highlighted\nthe critical roles of both the visual backbone and the underlying language\nmodel. While prior work has primarily focused on scaling these components to\nbillions of parameters, the trade-offs between model size, architecture, and\nperformance remain underexplored. Additionally, inconsistencies in training\ndata and evaluation protocols have hindered direct comparisons, making it\ndifficult to derive optimal design choices. In this paper, we introduce\nLLaVA-MORE, a new family of MLLMs that integrates recent language models with\ndiverse visual backbones. To ensure fair comparisons, we employ a unified\ntraining protocol applied consistently across all architectures. Our analysis\nsystematically explores both small- and medium-scale LLMs -- including Phi-4,\nLLaMA-3.1, and Gemma-2 -- to evaluate multimodal reasoning, generation, and\ninstruction following, while examining the relationship between model size and\nperformance. Beyond evaluating the LLM impact on final results, we conduct a\ncomprehensive study of various visual encoders, ranging from CLIP-based\narchitectures to alternatives such as DINOv2, SigLIP, and SigLIP2. Additional\nexperiments investigate the effects of increased image resolution and\nvariations in pre-training datasets. Overall, our results provide insights into\nthe design of more effective MLLMs, offering a reproducible evaluation\nframework that facilitates direct comparisons and can guide future model\ndevelopment. Our source code and trained models are publicly available at:\nhttps://github.com/aimagelab/LLaVA-MORE.", "comment": "ICCV 2025 Workshop on What is Next in Multimodal Foundation Models", "pdf_url": "http://arxiv.org/pdf/2503.15621v2", "cate": "cs.CV", "date": "2025-03-19", "updated": "2025-07-31", "AI": {"title_translation": "LLaVA-MORE: 增强视觉指令微调的LLM和视觉骨干网络比较研究", "tldr": "该研究引入LLaVA-MORE，通过统一协议比较不同LLM和视觉骨干对多模态大语言模型性能的影响，旨在提供可复现的评估框架和设计洞察。", "motivation": "现有工作主要关注模型规模扩展，但模型大小、架构与性能之间的权衡尚未充分探索。此外，训练数据和评估协议的不一致阻碍了直接比较，使得难以选择最优设计。", "method": "本文引入LLaVA-MORE，一个整合了最新语言模型和多样视觉骨干的多模态大语言模型系列。采用统一的训练协议在所有架构上进行公平比较。系统性地探索了Phi-4、LLaMA-3.1、Gemma-2等大小规模的LLM，评估其多模态推理、生成和指令遵循能力，并考察模型大小与性能的关系。此外，还全面研究了CLIP基架构、DINOv2、SigLIP、SigLIP2等多种视觉编码器。额外实验还探讨了图像分辨率增加和预训练数据集变化的影响。", "result": "研究结果为设计更有效的多模态大语言模型提供了见解，并提供了一个可复现的评估框架，促进直接比较并指导未来的模型开发。", "conclusion": "通过LLaVA-MORE框架和统一的评估协议，本文为多模态大语言模型中LLM和视觉骨干的选择提供了深入的比较分析和设计指导，促进了该领域的可复现研究和未来发展。", "translation": "多模态大语言模型（MLLMs）的最新进展凸显了视觉骨干和底层语言模型的关键作用。虽然以前的工作主要集中于将这些组件扩展到数十亿参数，但模型大小、架构和性能之间的权衡仍未得到充分探索。此外，训练数据和评估协议的不一致阻碍了直接比较，使得难以得出最优设计选择。在本文中，我们引入了LLaVA-MORE，这是一个新的MLLM家族，它将最新的语言模型与多样化的视觉骨干相结合。为了确保公平比较，我们采用了一种统一的训练协议，并将其一致地应用于所有架构。我们的分析系统地探索了小型和中型LLM——包括Phi-4、LLaMA-3.1和Gemma-2——以评估多模态推理、生成和指令遵循能力，同时检查模型大小与性能之间的关系。除了评估LLM对最终结果的影响外，我们还对各种视觉编码器进行了全面研究，从基于CLIP的架构到DINOv2、SigLIP和SigLIP2等替代方案。额外的实验研究了图像分辨率增加和预训练数据集变化的影响。总的来说，我们的结果为设计更有效的MLLM提供了见解，提供了一个可复现的评估框架，促进直接比较并指导未来的模型开发。我们的源代码和训练模型已公开提供：https://github.com/aimagelab/LLaVA-MORE。", "summary": "本文介绍了LLaVA-MORE，一个旨在公平比较不同LLM和视觉骨干在多模态大语言模型（MLLM）中性能的新框架。通过统一的训练协议，研究系统性地评估了多种LLM（如Phi-4, LLaMA-3.1, Gemma-2）和视觉编码器（如CLIP, DINOv2, SigLIP），并探讨了模型规模、图像分辨率和预训练数据的影响。研究结果为MLLM的设计提供了实用见解，并建立了一个可复现的评估基准，以指导未来的模型开发。", "keywords": "多模态大语言模型, 视觉指令微调, 视觉骨干, 语言模型, 性能比较", "comments": "该论文的创新之处在于提出了LLaVA-MORE框架和统一的训练评估协议，解决了现有研究中由于训练和评估不一致导致难以直接比较不同MLLM组件性能的问题。其系统性的比较研究为设计更高效的MLLM提供了宝贵的经验见解，并为领域内的可复现研究奠定了基础，具有重要的实践指导意义。"}}
{"id": "2507.23043", "title": "Prediction of Significant Creatinine Elevation in First ICU Stays with Vancomycin Use: A retrospective study through Catboost", "authors": ["Junyi Fan", "Li Sun", "Shuheng Chen", "Yong Si", "Minoo Ahmadi", "Greg Placencia", "Elham Pishgar", "Kamiar Alaei", "Maryam Pishgar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23043v1", "summary": "Background: Vancomycin, a key antibiotic for severe Gram-positive infections\nin ICUs, poses a high nephrotoxicity risk. Early prediction of kidney injury in\ncritically ill patients is challenging. This study aimed to develop a machine\nlearning model to predict vancomycin-related creatinine elevation using routine\nICU data.\n  Methods: We analyzed 10,288 ICU patients (aged 18-80) from the MIMIC-IV\ndatabase who received vancomycin. Kidney injury was defined by KDIGO criteria\n(creatinine rise >=0.3 mg/dL within 48h or >=50% within 7d). Features were\nselected via SelectKBest (top 30) and Random Forest ranking (final 15). Six\nalgorithms were tested with 5-fold cross-validation. Interpretability was\nevaluated using SHAP, Accumulated Local Effects (ALE), and Bayesian posterior\nsampling.\n  Results: Of 10,288 patients, 2,903 (28.2%) developed creatinine elevation.\nCatBoost performed best (AUROC 0.818 [95% CI: 0.801-0.834], sensitivity 0.800,\nspecificity 0.681, negative predictive value 0.900). Key predictors were\nphosphate, total bilirubin, magnesium, Charlson index, and APSIII. SHAP\nconfirmed phosphate as a major risk factor. ALE showed dose-response patterns.\nBayesian analysis estimated mean risk 60.5% (95% credible interval: 16.8-89.4%)\nin high-risk cases.\n  Conclusions: This machine learning model predicts vancomycin-associated\ncreatinine elevation from routine ICU data with strong accuracy and\ninterpretability, enabling early risk detection and supporting timely\ninterventions in critical care.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23043v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "预测重症监护病房首次住院患者万古霉素使用后肌酐显著升高：一项基于Catboost的回顾性研究", "tldr": "该研究开发了一个机器学习模型，使用CatBoost算法，通过常规ICU数据准确预测万古霉素相关的肌酐升高，有助于早期风险检测。", "motivation": "万古霉素是重症监护病房（ICU）治疗严重革兰氏阳性感染的关键抗生素，但具有较高的肾毒性风险。在危重症患者中早期预测肾损伤具有挑战性。本研究旨在开发一个机器学习模型，利用常规ICU数据预测万古霉素相关的肌酐升高。", "method": "研究分析了来自MIMIC-IV数据库的10,288名接受万古霉素治疗的ICU患者（18-80岁）。肾损伤定义为KDIGO标准（48小时内肌酐升高≥0.3 mg/dL或7天内升高≥50%）。特征选择通过SelectKBest（前30个）和随机森林排名（最终15个）进行。测试了六种算法并进行了5折交叉验证。模型可解释性通过SHAP、累积局部效应（ALE）和贝叶斯后验采样进行评估。", "result": "在10,288名患者中，有2,903名（28.2%）出现了肌酐升高。CatBoost表现最佳（AUROC 0.818 [95% CI: 0.801-0.834]，敏感性0.800，特异性0.681，阴性预测值0.900）。主要预测因子包括磷酸盐、总胆红素、镁、Charlson指数和APSIII。SHAP分析证实磷酸盐是主要风险因素。ALE显示了剂量反应模式。贝叶斯分析估计高风险病例的平均风险为60.5%（95%可信区间：16.8-89.4%）。", "conclusion": "该机器学习模型能够利用常规ICU数据准确且可解释地预测万古霉素相关的肌酐升高，从而实现早期风险检测并支持危重症护理中的及时干预。", "translation": "背景: 万古霉素是重症监护病房（ICU）治疗严重革兰氏阳性感染的关键抗生素，但具有较高的肾毒性风险。在危重症患者中早期预测肾损伤具有挑战性。本研究旨在开发一个机器学习模型，利用常规ICU数据预测万古霉素相关的肌酐升高。\n方法: 我们分析了来自MIMIC-IV数据库的10,288名接受万古霉素治疗的ICU患者（18-80岁）。肾损伤定义为KDIGO标准（48小时内肌酐升高≥0.3 mg/dL或7天内升高≥50%）。特征选择通过SelectKBest（前30个）和随机森林排名（最终15个）进行。测试了六种算法并进行了5折交叉验证。模型可解释性通过SHAP、累积局部效应（ALE）和贝叶斯后验采样进行评估。\n结果: 在10,288名患者中，有2,903名（28.2%）出现了肌酐升高。CatBoost表现最佳（AUROC 0.818 [95% CI: 0.801-0.834]，敏感性0.800，特异性0.681，阴性预测值0.900）。主要预测因子包括磷酸盐、总胆红素、镁、Charlson指数和APSIII。SHAP分析证实磷酸盐是主要风险因素。ALE显示了剂量反应模式。贝叶斯分析估计高风险病例的平均风险为60.5%（95%可信区间：16.8-89.4%）。\n结论: 该机器学习模型能够利用常规ICU数据准确且可解释地预测万古霉素相关的肌酐升高，从而实现早期风险检测并支持危重症护理中的及时干预。", "summary": "这项回顾性研究利用MIMIC-IV数据库中10,288名ICU患者的数据，开发了一个机器学习模型来预测万古霉素引起的肌酐升高。研究测试了多种算法，发现CatBoost表现最佳，AUROC为0.818。该模型利用磷酸盐、总胆红素等常规ICU数据作为关键预测因子，并结合SHAP、ALE和贝叶斯分析进行可解释性评估。研究结果表明，该模型能准确预测肾损伤，有助于临床早期干预。", "keywords": "万古霉素, 肌酐升高, 肾毒性, 机器学习, CatBoost", "comments": "这项研究的创新之处在于利用机器学习（特别是CatBoost）来预测万古霉素诱导的肾损伤，并结合多种可解释性方法（SHAP, ALE, Bayesian）来增强模型的透明度和临床实用性。其重要性在于，通过早期预测高风险患者，可以及时调整治疗方案，从而降低肾毒性风险，改善患者预后。该研究为临床决策提供了有力的支持工具。"}}
{"id": "2507.22936", "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis", "authors": ["Md Talha Mohsin"], "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.HC", "q-fin.CP"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      22 Pages, 6 Tables, 7 Figures", "url": "http://arxiv.org/abs/2507.22936v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide variety of Financial Natural Language Processing (FinNLP) tasks.\nHowever, systematic comparisons among widely used LLMs remain underexplored.\nGiven the rapid advancement and growing influence of LLMs in financial\nanalysis, this study conducts a thorough comparative evaluation of five leading\nLLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the\n'Magnificent Seven' technology companies. We create a set of domain-specific\nprompts and then use three methodologies to evaluate model performance: human\nannotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,\nJaccard), and model behavior diagnostics (prompt-level variance and\nacross-model similarity). The results show that GPT gives the most coherent,\nsemantically aligned, and contextually relevant answers; followed by Claude and\nPerplexity. Gemini and DeepSeek, on the other hand, have more variability and\nless agreement. Also, the similarity and stability of outputs change from\ncompany to company and over time, showing that they are sensitive to how\nprompts are written and what source material is used.", "comment": "22 Pages, 6 Tables, 7 Figures", "pdf_url": "http://arxiv.org/pdf/2507.22936v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "评估大型语言模型 (LLMs) 在金融自然语言处理中的应用：一项金融报告分析的比较研究", "tldr": "本研究系统比较了五种主流大型语言模型在金融报告分析中的表现，发现GPT表现最佳，且模型输出对提示和源材料敏感。", "motivation": "尽管大型语言模型在金融自然语言处理任务中表现出色，但对主流大型语言模型进行系统性比较的研究仍不足。鉴于大型语言模型在金融分析中快速发展且影响力日益增长，本研究旨在填补这一空白。", "method": "本研究对GPT、Claude、Perplexity、Gemini和DeepSeek五种领先的大型语言模型进行了全面的比较评估。数据源采用“七巨头”科技公司的10-K文件。研究创建了一套领域特定的提示，并使用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示级别方差和跨模型相似性）。", "result": "结果显示，GPT提供了最连贯、语义一致且与上下文相关的答案，其次是Claude和Perplexity。而Gemini和DeepSeek则表现出更大的可变性和较低的一致性。此外，输出的相似性和稳定性因公司和时间而异，表明它们对提示的编写方式和使用的源材料敏感。", "conclusion": "大型语言模型在金融自然语言处理中的表现存在显著差异，其中GPT表现最优。同时，模型的输出质量和稳定性高度依赖于提示的构造和所分析的源材料。因此，在实际应用中需要谨慎选择模型并精细化提示工程。", "translation": "大型语言模型（LLMs）在各种金融自然语言处理（FinNLP）任务中展示了卓越的能力。然而，对广泛使用的大型语言模型进行系统性比较的研究仍未得到充分探索。鉴于大型语言模型在金融分析中快速发展且影响力日益增长，本研究对GPT、Claude、Perplexity、Gemini和DeepSeek这五种领先的大型语言模型进行了彻底的比较评估，使用了“七巨头”科技公司的10-K文件。我们创建了一套领域特定的提示，然后使用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示级别方差和跨模型相似性）。结果显示，GPT提供了最连贯、语义一致且与上下文相关的答案；其次是Claude和Perplexity。另一方面，Gemini和DeepSeek则表现出更大的可变性和较低的一致性。此外，输出的相似性和稳定性因公司和时间而异，表明它们对提示的编写方式和使用的源材料敏感。", "summary": "本研究对GPT、Claude、Perplexity、Gemini和DeepSeek五种主流大型语言模型在金融报告分析中的表现进行了系统性比较评估。通过使用“七巨头”公司的10-K文件和领域特定提示，并结合人工标注、自动化指标和行为诊断三种评估方法，发现GPT在生成连贯、语义一致和上下文相关答案方面表现最佳，其次是Claude和Perplexity，而Gemini和DeepSeek表现出较大变异性。研究还指出模型输出的相似性和稳定性受提示编写和源材料影响。", "keywords": "大型语言模型, 金融自然语言处理, 比较研究, 金融报告分析, 性能评估", "comments": "本文通过对当前主流大型语言模型在金融自然语言处理领域的系统性比较评估，填补了该领域研究的空白，具有重要的实践指导意义。其创新之处在于采用了多维度评估方法，包括人工标注和多种自动化指标，并关注了模型行为诊断。研究结果明确指出了不同模型在金融文本分析中的优劣，并强调了提示工程和源材料选择对模型性能的关键影响，为未来金融NLP应用中的模型选择和优化提供了宝贵见解。"}}
{"id": "2507.23280", "title": "Data-Driven Stochastic Control via Non-i.i.d. Trajectories: Foundations and Guarantees", "authors": ["Abolfazl Lavaei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23280v1", "summary": "This work establishes a crucial step toward advancing data-driven\ntrajectory-based methods for stochastic systems with unknown mathematical\ndynamics. In contrast to scenario-based approaches that rely on independent and\nidentically distributed (i.i.d.) trajectories, this work develops a data-driven\nframework where each trajectory is gathered over a finite horizon and exhibits\ntemporal dependence-referred to as a non-i.i.d. trajectory. To ensure safety of\ndynamical systems using such trajectories, the current body of literature\nprimarily considers dynamics subject to unknown-but-bounded disturbances, which\nfacilitates robust analysis. While promising, such bounds may be violated in\npractice and the resulting worst-case robust analysis tends to be overly\nconservative. To overcome these fundamental challenges, this paper considers\nstochastic systems with unknown mathematical dynamics, influenced by process\nnoise with unknown distributions. In the proposed framework, data is collected\nfrom stochastic systems under multiple realizations within a finite-horizon\nexperiment, where each realization generates a non-i.i.d. trajectory.\nLeveraging the concept of stochastic control barrier certificates constructed\nfrom data, this work quantifies probabilistic safety guarantees with a\ncertified confidence level. To achieve this, the proposed conditions are\nformulated as sum-of-squares (SOS) optimization problems, relying solely on\nempirical average of the collected trajectories and statistical features of the\nprocess noise. The efficacy of the approach has been validated on three\nstochastic benchmarks with both unknown models and noise distributions. In one\ncase study, it is shown that while no safety controller exists for the robust\nanalysis of the system under bounded disturbances, the proposed stochastic\nframework offers a safety controller with guaranteed probabilistic\nsatisfaction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23280v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于非独立同分布轨迹的数据驱动随机控制：基础与保证", "tldr": "本文提出了一种新的数据驱动框架，用于未知动态的随机系统，该框架使用非独立同分布（non-i.i.d.）轨迹，并提供具有认证置信水平的概率安全保证，解决了传统稳健分析过于保守的问题。", "motivation": "当前文献中，数据驱动的轨迹方法通常依赖于独立同分布（i.i.d.）轨迹或假设有界扰动，这在实践中可能被违反，并导致过于保守的鲁棒分析。本文旨在解决这些基本挑战，考虑具有未知数学动力学和未知分布过程噪声的随机系统。", "method": "本文开发了一种数据驱动框架，通过在有限时间内从随机系统收集多实现下的非独立同分布轨迹数据。利用从数据构建的随机控制障碍证书概念，通过将条件表述为仅依赖于收集轨迹的经验平均值和过程噪声统计特征的平方和（SOS）优化问题，量化了具有认证置信水平的概率安全保证。", "result": "该方法在三个具有未知模型和噪声分布的随机基准上得到了验证。在一个案例研究中，展示了虽然在有界扰动下对系统进行鲁棒分析不存在安全控制器，但所提出的随机框架提供了一个具有保证概率满足度的安全控制器。", "conclusion": "本文为推进未知数学动力学随机系统的数据驱动轨迹方法迈出了关键一步，通过使用非独立同分布轨迹和随机控制障碍证书，成功地为系统提供了具有认证置信水平的概率安全保证，克服了传统鲁棒分析的局限性。", "translation": "这项工作为推进具有未知数学动力学的随机系统的数据驱动轨迹方法迈出了关键一步。与依赖独立同分布（i.i.d.）轨迹的基于场景的方法不同，这项工作开发了一个数据驱动框架，其中每条轨迹都是在有限范围内收集的，并表现出时间依赖性——被称为非独立同分布（non-i.i.d.）轨迹。为了确保使用此类轨迹的动态系统的安全性，当前的文献主要考虑受未知但有界扰动影响的动力学，这有助于鲁棒分析。尽管前景光明，但此类界限在实践中可能被违反，并且由此产生的最坏情况鲁棒分析往往过于保守。为了克服这些基本挑战，本文考虑了具有未知数学动力学、受未知分布过程噪声影响的随机系统。在所提出的框架中，数据是在有限时间实验中从随机系统在多次实现下收集的，其中每次实现都会生成一条非独立同分布轨迹。利用从数据构建的随机控制障碍证书的概念，这项工作量化了具有认证置信水平的概率安全保证。为了实现这一点，所提出的条件被表述为平方和（SOS）优化问题，仅依赖于收集轨迹的经验平均值和过程噪声的统计特征。该方法的有效性已在三个具有未知模型和噪声分布的随机基准上得到了验证。在一个案例研究中，结果表明，尽管在有界扰动下对系统进行鲁棒分析不存在安全控制器，但所提出的随机框架提供了一个具有保证概率满足度的安全控制器。", "summary": "本文提出了一种新颖的数据驱动框架，用于处理具有未知动力学和未知噪声分布的随机系统。与传统依赖i.i.d.轨迹或保守鲁棒分析的方法不同，本框架利用在有限时间内收集的非i.i.d.轨迹，并通过基于数据的随机控制障碍证书，将概率安全保证量化为平方和（SOS）优化问题。该方法仅依赖于经验数据和噪声统计特征，并在多个随机基准上验证了其有效性，证明了即使在鲁棒分析失败的情况下，它也能提供具有保证概率安全性的控制器。", "keywords": "数据驱动控制, 随机系统, 非独立同分布轨迹, 概率安全, 控制障碍证书", "comments": "本文的创新之处在于其处理非独立同分布（non-i.i.d.）轨迹和未知噪声分布的能力，这在实际应用中更具普适性。它通过引入随机控制障碍证书和SOS优化，为随机系统提供了概率安全保证，克服了传统稳健分析中过于保守的限制。这项工作对于数据驱动的随机系统控制领域具有重要意义，尤其是在安全关键型应用中。"}}
{"id": "2507.23787", "title": "Amplitude amplification and estimation require inverses", "authors": ["Ewin Tang", "John Wright"], "categories": ["quant-ph", "cs.CC", "cs.DS"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.23787v1", "summary": "We prove that the generic quantum speedups for brute-force search and\ncounting only hold when the process we apply them to can be efficiently\ninverted. The algorithms speeding up these problems, amplitude amplification\nand amplitude estimation, assume the ability to apply a state preparation\nunitary $U$ and its inverse $U^\\dagger$; we give problem instances based on\ntrace estimation where no algorithm which uses only $U$ beats the naive,\nquadratically slower approach. Our proof of this is simple and goes through the\ncompressed oracle method introduced by Zhandry. Since these two subroutines are\nresponsible for the ubiquity of the quadratic \"Grover\" speedup in quantum\nalgorithms, our result explains why such speedups are far harder to come by in\nthe settings of quantum learning, metrology, and sensing. In these settings,\n$U$ models the evolution of an experimental system, so implementing $U^\\dagger$\ncan be much harder -- tantamount to reversing time within the system. Our\nresult suggests a dichotomy: without inverse access, quantum speedups are\nscarce; with it, quantum speedups abound.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.23787v1", "cate": "quant-ph", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "振幅放大和估计需要逆运算", "tldr": "量子加速算法（如振幅放大和估计）的有效性取决于能否高效地执行逆操作，否则量子加速将难以实现。", "motivation": "现有的量子加速算法（振幅放大和估计）假设可以应用酉算子U及其逆U†，但研究者发现，在某些情况下，如果没有U†，这些加速就不成立，这解释了为什么在量子学习、计量和传感中难以获得二次加速。", "method": "作者通过Zhandry引入的“压缩预言机方法”证明了他们的结论，并给出了基于迹估计的问题实例。", "result": "证明了通用的量子加速（用于暴力搜索和计数）仅在所应用的过程可以被有效逆转时才成立。在某些问题实例（如基于迹估计）中，仅使用U的算法无法超越朴素的、二次慢的方法。", "conclusion": "结果揭示了一个二分法：如果没有逆操作的访问，量子加速是稀缺的；有了逆操作的访问，量子加速则大量存在。这解释了为何在量子学习、计量和传感等领域，由于难以实现U†（相当于系统内的时间倒转），量子加速难以实现。", "translation": "我们证明，用于暴力搜索和计数的通用量子加速仅在所应用的过程可以被有效逆转时才成立。加速这些问题的算法，即振幅放大和振幅估计，都假设能够应用状态准备酉算子U及其逆U†；我们给出了基于迹估计的问题实例，其中任何仅使用U的算法都无法超越朴素的、二次方慢的方法。我们的证明很简单，并通过Zhandry引入的压缩预言机方法进行。由于这两个子程序是量子算法中二次“Grover”加速无处不在的原因，我们的结果解释了为什么在量子学习、计量和传感的环境中，这种加速更难实现。在这些环境中，U模拟了实验系统的演化，因此实现U†可能要困难得多——这等同于在系统内逆转时间。我们的结果提出了一种二分法：没有逆操作的访问，量子加速是稀缺的；有了逆操作的访问，量子加速则大量存在。", "summary": "本文证明了量子算法中普遍存在的二次加速（如振幅放大和估计）的有效性依赖于其所作用过程的可逆性。作者使用压缩预言机方法，并通过迹估计问题实例说明，若无法高效执行状态准备酉算子U的逆操作U†，则量子加速不复存在。这一发现解释了为何在量子学习、计量和传感等难以实现逆操作的领域中，量子加速难以获得，并提出了量子加速的“有无逆操作”二分法。", "keywords": "量子加速, 振幅放大, 振幅估计, 逆操作, 压缩预言机方法", "comments": "本文揭示了量子算法中一个重要的限制条件，即逆操作的可访问性对量子加速的实现至关重要。这一发现不仅对理论量子算法的设计有指导意义，也解释了现实世界中量子计算应用面临的挑战，特别是在那些难以实现时间逆转的物理系统中。其创新性在于通过严谨的证明和实例，明确了量子加速的边界。"}}
{"id": "2505.05702", "title": "Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning", "authors": ["Seongjin Choi", "Gahee Kim", "Yong-Geun Oh"], "categories": ["cs.LG", "math.AT", "05C65, 55U10, 68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in IEEE Access", "url": "http://arxiv.org/abs/2505.05702v3", "summary": "The absence of intrinsic adjacency relations and orientation systems in\nhypergraphs creates fundamental challenges for constructing sheaf Laplacians of\narbitrary degrees. We resolve these limitations through symmetric simplicial\nsets derived directly from hypergraphs, called symmetric simplicial lifting,\nwhich encode all possible oriented subrelations within each hyperedge as\nordered tuples. This construction canonically defines adjacency via facet maps\nwhile inherently preserving hyperedge provenance. We establish that the\nnormalized degree zero sheaf Laplacian on our symmetric simplicial lifting\nreduces exactly to the traditional graph normalized sheaf Laplacian when\nrestricted to graphs, validating its mathematical consistency with prior\ngraph-based sheaf theory. Furthermore, the induced structure preserves all\nstructural information from the original hypergraph, ensuring that every\nmulti-way relational detail is faithfully retained. Leveraging this framework,\nwe introduce Hypergraph Neural Sheaf Diffusion (HNSD), the first principled\nextension of neural sheaf diffusion to hypergraphs. HNSD operates via\nnormalized degree zero sheaf Laplacian over symmetric simplicial lifting,\nresolving orientation ambiguity and adjacency sparsity inherent to hypergraph\nlearning. Experimental evaluations demonstrate HNSDs competitive performance\nacross established benchmarks.", "comment": "Published in IEEE Access", "pdf_url": "http://arxiv.org/pdf/2505.05702v3", "cate": "cs.LG", "date": "2025-05-09", "updated": "2025-07-30", "AI": {"title_translation": "超图神经层扩散：一种用于高阶学习的对称单纯集框架", "tldr": "本文提出了超图神经层扩散（HNSD），这是一种利用对称单纯集将神经层扩散扩展到超图的新框架，解决了超图学习中固有的方向模糊性和邻接稀疏性问题。", "motivation": "超图中固有的邻接关系和方向系统缺失，给构建任意度数的层拉普拉斯算子带来了根本性挑战。", "method": "通过直接从超图导出的对称单纯集（称为对称单纯提升）解决了超图的邻接和方向限制，该方法将每个超边内所有可能的定向子关系编码为有序元组，并定义了邻接关系。在此框架基础上，引入了超图神经层扩散（HNSD），通过对称单纯提升上的归一化零度层拉普拉斯算子运行。", "result": "当限制在图上时，所提出的对称单纯提升上的归一化零度层拉普拉斯算子恰好还原为传统的图归一化层拉普拉斯算子，验证了其与先前图层理论的数学一致性。诱导结构保留了原始超图的所有结构信息。实验评估表明HNSD在既定基准上具有竞争力。", "conclusion": "本文成功引入了HNSD，一个利用对称单纯集解决超图固有挑战，将神经层扩散扩展到超图的原则性框架，该框架在数学上与图理论一致，并表现出有竞争力的性能。", "translation": "超图中固有邻接关系和方向系统的缺失，给构建任意度数的层拉普拉斯算子带来了根本性挑战。我们通过直接从超图导出的对称单纯集（称为对称单纯提升）解决了这些限制，该方法将每个超边内所有可能的定向子关系编码为有序元组。这种构造通过面映射规范地定义了邻接关系，同时固有地保留了超边来源。我们确定，当限制在图上时，我们对称单纯提升上的归一化零度层拉普拉斯算子恰好还原为传统的图归一化层拉普拉斯算子，验证了其与先前基于图的层理论的数学一致性。此外，诱导结构保留了原始超图的所有结构信息，确保每个多向关系细节都得到忠实保留。 leveraging this framework，我们引入了超图神经层扩散（HNSD），它是神经层扩散向超图的第一个原则性扩展。HNSD通过对称单纯提升上的归一化零度层拉普拉斯算子运行，解决了超图学习中固有的方向模糊性和邻接稀疏性问题。实验评估表明HNSD在既定基准上具有竞争力。", "summary": "本文解决了超图中缺少固有邻接关系和方向系统导致构建层拉普拉斯算子的基本挑战。通过引入直接从超图导出的对称单纯集（称为对称单纯提升），将超边内的所有定向子关系编码为有序元组，并规范地定义了邻接关系。该构造在数学上与传统的图层理论一致，并能保留原始超图的所有结构信息。在此基础上，提出了超图神经层扩散（HNSD），这是神经层扩散向超图的首次原则性扩展，解决了超图学习中的方向模糊性和邻接稀疏性问题。实验评估证明了HNSD在现有基准上的竞争性能。", "keywords": "超图, 神经层扩散, 对称单纯集, 高阶学习, 层拉普拉斯算子", "comments": "该论文的创新之处在于利用对称单纯集为超图学习提供了一个原则性框架，特别是解决了超图数据中固有的高阶关系、方向模糊性和邻接稀疏性问题，从而将神经层扩散扩展到超图。其与图理论的数学一致性增强了方法的鲁棒性。"}}
{"id": "2507.23042", "title": "Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving", "authors": ["Santosh Patapati", "Trisanth Srinivasan"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.RO", "I.2.6; I.2.9; I.2.10; C.3.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.23042v1", "summary": "Autonomous vehicles must react in milliseconds while reasoning about road\ngeometry and traffic intent to navigate complex situations. We introduce\nNovaDrive, a single-branch vision-language architecture that processes\nfront-camera images, HD-map tiles, LiDAR depth, and textual waypoints in a\nsingle branch. A lightweight, two-stage cross-attention block first aligns\nwaypoint tokens with the HD map, then refines attention over fine-grained image\nand depth patches. Coupled with a novel smoothness loss that discourages abrupt\nsteering and speed changes, this design eliminates the need for recurrent\nmemory. We fine-tune the top 15 layers of an 11B LLaMA-3.2 vision-language\nbackbone, enabling real-time inference. On the nuScenes / Waymo subset of the\nMD-NEX Outdoor benchmark, NovaDrive raises success rate to 84% (+4%), boosts\npath-efficiency (SPL) to 0.66 (+0.11), and reduces collision frequency from\n2.6% to 1.2% (-1.4%) relative to the previous state-of-the-art. Our ablations\nconfirm that waypoint tokens, partial VLM fine-tuning, and the cross-attention\nfusion each contribute the most to these gains. Beyond safety, NovaDrive's\nshorter routes (resulting from the novel smoothness loss) translate to lower\nfuel or battery usage, pointing toward leaner, more easily updated driving\nstacks. NovaDrive can be extended to other embodied-AI domains as well.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.23042v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "实时视觉-语言驾驶的早期目标引导多尺度融合", "tldr": "NovaDrive是一种单分支视觉-语言架构，用于实时自动驾驶，它通过多模态融合和新颖的平滑度损失实现了最先进的性能，提高了成功率和路径效率，同时降低了碰撞频率。", "motivation": "自动驾驶车辆在复杂情况下需要毫秒级响应，并对道路几何和交通意图进行推理，以应对复杂的驾驶环境。当前的挑战在于实现实时、高效且安全的自动驾驶。", "method": "本文引入了NovaDrive，这是一种单分支视觉-语言架构，能够处理前置摄像头图像、高清地图瓦片、LiDAR深度信息和文本路点。它采用轻量级两阶段交叉注意力模块，首先将路点标记与高清地图对齐，然后细化对细粒度图像和深度补丁的注意力。结合一种新颖的平滑度损失（抑制突然的转向和速度变化），该设计消除了对循环记忆的需求。NovaDrive通过微调11B LLaMA-3.2视觉-语言骨干网络的顶部15层，实现了实时推理。", "result": "在MD-NEX Outdoor基准测试的nuScenes/Waymo子集上，NovaDrive将成功率提高到84%（+4%），将路径效率（SPL）提升到0.66（+0.11），并将碰撞频率从2.6%降低到1.2%（-1.4%），超越了以往的最先进水平。消融实验证实，路点标记、部分VLM微调和交叉注意力融合对这些性能提升贡献最大。此外，NovaDrive较短的路线（源于新颖的平滑度损失）转化为更低的燃料或电池消耗。", "conclusion": "NovaDrive提供了一种更精简、更易于更新的驾驶堆栈，不仅提升了自动驾驶的安全性，还降低了资源消耗。该系统有望扩展到其他具身AI领域。", "translation": "自动驾驶车辆必须在毫秒级内做出反应，同时对道路几何和交通意图进行推理，以应对复杂情况。我们引入了NovaDrive，这是一种单分支视觉-语言架构，它在单个分支中处理前置摄像头图像、高清地图瓦片、LiDAR深度和文本路点。一个轻量级的两阶段交叉注意力块首先将路点标记与高清地图对齐，然后细化对细粒度图像和深度补丁的注意力。结合一种新颖的平滑度损失，该损失能抑制突然的转向和速度变化，这种设计消除了对循环记忆的需求。我们微调了11B LLaMA-3.2视觉-语言骨干网络的顶部15层，实现了实时推理。在MD-NEX Outdoor基准测试的nuScenes/Waymo子集上，NovaDrive将成功率提高到84%（+4%），将路径效率（SPL）提升到0.66（+0.11），并将碰撞频率从2.6%降低到1.2%（-1.4%），相对于之前的最先进水平。我们的消融实验证实，路点标记、部分VLM微调和交叉注意力融合对这些增益贡献最大。除了安全性，NovaDrive更短的路线（源于新颖的平滑度损失）转化为更低的燃料或电池使用量，预示着更精简、更容易更新的驾驶堆栈。NovaDrive也可以扩展到其他具身AI领域。", "summary": "本文提出了NovaDrive，一种针对实时自动驾驶的单分支视觉-语言架构。该系统整合了多模态输入（图像、地图、LiDAR、文本路点），并利用两阶段交叉注意力进行高效融合。通过引入新颖的平滑度损失，NovaDrive消除了对循环记忆的需求，并能有效抑制不平稳的驾驶行为。在微调大型视觉-语言模型骨干后，NovaDrive在多个关键指标上超越了现有技术，显著提升了自动驾驶的成功率、路径效率并降低了碰撞率。其设计不仅提高了安全性，还通过优化路线长度实现了能源效率，并具有向其他具身AI领域扩展的潜力。", "keywords": "实时驾驶, 视觉-语言, 自动驾驶, 多尺度融合, 交叉注意力", "comments": "NovaDrive的创新之处在于其单分支视觉-语言架构，能够高效融合多种异构传感器数据和高层语义信息（文本路点）。新颖的平滑度损失不仅提升了驾驶舒适性和安全性，还通过消除对循环记忆的需求简化了模型设计，并间接实现了能效提升。通过对大型预训练VLM进行部分微调，该方法展现了在复杂自动驾驶任务中实现实时SOTA性能的潜力，且易于部署和更新。其在能效和可扩展性方面的优势也值得关注。"}}
{"id": "2406.10375", "title": "Mokav: Execution-driven Differential Testing with LLMs", "authors": ["Khashayar Etemadi", "Bardia Mohammadi", "Zhendong Su", "Martin Monperrus"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.10375v2", "summary": "It is essential to detect functional differences between programs in various\nsoftware engineering tasks, such as automated program repair, mutation testing,\nand code refactoring. The problem of detecting functional differences between\ntwo programs can be reduced to searching for a difference exposing test (DET):\na test input that results in different outputs on the subject programs. In this\npaper, we propose Mokav, a novel execution-driven tool that leverages LLMs to\ngenerate DETs. Mokav takes two versions of a program (P and Q) and an example\ntest input. When successful, Mokav generates a valid DET, a test input that\nleads to provably different outputs on P and Q. Mokav iteratively prompts an\nLLM with a specialized prompt to generate new test inputs. At each iteration,\nMokav provides execution-based feedback from previously generated tests until\nthe LLM produces a DET. We evaluate Mokav on 1535 pairs of Python programs\ncollected from the Codeforces competition platform and 32 pairs of programs\nfrom the QuixBugs dataset. Our experiments show that Mokav outperforms the\nstate-of-the-art, Pynguin and Differential Prompting, by a large margin. Mokav\ncan generate DETs for 81.7% (1,255/1535) of the program pairs in our benchmark\n(versus 4.9% for Pynguin and 37.3% for Differential Prompting). We demonstrate\nthat the iterative and execution-driven feedback components of the system\ncontribute to its high effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.10375v2", "cate": "cs.SE", "date": "2024-06-14", "updated": "2025-07-31", "AI": {"title_translation": "Mokav：基于执行的LLM驱动差异测试", "tldr": "Mokav是一种利用大型语言模型生成差异暴露测试（DETs）的工具，显著优于现有技术。", "motivation": "在软件工程任务中，如自动化程序修复、变异测试和代码重构，检测程序间的功能差异至关重要。这个问题可以归结为寻找能使程序产生不同输出的测试输入（DET）。", "method": "本文提出了Mokav，一种新颖的执行驱动工具，它利用大型语言模型（LLMs）来生成差异暴露测试（DETs）。Mokav接收两个版本的程序（P和Q）以及一个示例测试输入。它通过专门的提示词迭代地提示LLM生成新的测试输入，并在每次迭代中提供基于先前测试执行的反馈，直到LLM生成一个DET。", "result": "Mokav在从Codeforces和QuixBugs数据集收集的1535对Python程序上进行了评估。实验表明，Mokav在生成DETs方面显著优于现有技术Pynguin和Differential Prompting。Mokav能够为81.7%（1,255/1535）的程序对生成DETs，而Pynguin为4.9%，Differential Prompting为37.3%。", "conclusion": "Mokav的迭代和执行驱动的反馈机制是其高效性的关键。", "translation": "在各种软件工程任务中，例如自动化程序修复、变异测试和代码重构，检测程序之间的功能差异至关重要。检测两个程序之间功能差异的问题可以归结为寻找一个差异暴露测试（DET）：一个导致目标程序产生不同输出的测试输入。在本文中，我们提出了Mokav，一个新颖的执行驱动工具，它利用大型语言模型（LLMs）来生成DETs。Mokav接收两个版本的程序（P和Q）以及一个示例测试输入。当成功时，Mokav会生成一个有效的DET，即一个在P和Q上导致可证明不同输出的测试输入。Mokav通过专门的提示词迭代地提示LLM生成新的测试输入。在每次迭代中，Mokav都会提供基于先前生成的测试的执行反馈，直到LLM产生一个DET。我们对从Codeforces竞赛平台收集的1535对Python程序和来自QuixBugs数据集的32对程序对Mokav进行了评估。我们的实验表明，Mokav在很大程度上优于现有技术Pynguin和Differential Prompting。Mokav可以为我们基准中81.7%（1,255/1535）的程序对生成DETs（而Pynguin为4.9%，Differential Prompting为37.3%）。我们证明了该系统的迭代和执行驱动反馈组件有助于其高效率。", "summary": "Mokav是一种创新的执行驱动工具，利用大型语言模型（LLMs）来自动生成差异暴露测试（DETs），以检测程序之间的功能差异。该工具通过迭代地向LLM提供基于执行的反馈来优化测试输入，直到找到能使两个程序产生不同输出的测试。在广泛的Python程序对上的评估显示，Mokav在生成DETs方面显著优于现有技术，其高效率得益于其独特的迭代和执行驱动反馈机制。", "keywords": "差异测试, LLMs, 自动化测试, 程序分析, 差异暴露测试", "comments": "Mokav的创新之处在于将LLMs与执行驱动的迭代反馈相结合，以解决程序功能差异检测这一重要问题。其在性能上大幅超越现有技术，表明LLMs在软件测试领域的潜力巨大，特别是通过结合实际执行结果进行指导。这种方法可以有效减少人工测试用例的编写，提高软件工程的效率和质量。"}}
{"id": "2507.22909", "title": "Rydberg Atomic Receivers for Wireless Communications: Fundamentals, Potential, Applications, and Challenges", "authors": ["Yin Zhang", "Jiayi Zhang", "Bokai Xu", "Yuanbin Chen", "Zhilong Liu", "Jiakang Zheng", "Enyu Shi", "Ziheng Liu", "Tierui Gong", "Wei E. I. Sha", "Chau Yuen", "Shi Jin", "Bo Ai"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22909v1", "summary": "Rydberg atomic receivers (RARs) leverage the quantum coherence of highly\nexcited atoms to overcome the intrinsic physical limitations of conventional\nradio frequency receivers (RFRs), particularly in sensitivity, and bandwidth.\nThis innovative technology represents a paradigm shift in wireless\ncommunication systems. This paper systematically explains the fundamental\nsensing mechanisms of RARs, contrasts their differences from RFRs in working\nprinciples and architectures. We explore their advantages in emerging wireless\ncommunication scenarios, such as integrated sensing and communications, quantum\nRydberg radar, and quantum space communications. Practical challenges, such as\nlimited instantaneous bandwidth and nonlinear distortion, are identified. To\naddress these issues, mitigation strategies and future research directions are\nalso outlined, supporting the advancement of RAR-aided wireless systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22909v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "里德堡原子接收机在无线通信中的应用：基础、潜力、应用与挑战", "tldr": "该论文系统阐述了里德堡原子接收机（RARs）的原理、优势、应用场景及挑战，并提出了解决方案，以推动其在无线通信中的发展。", "motivation": "传统的射频接收机（RFRs）在灵敏度和带宽方面存在固有的物理限制。里德堡原子接收机（RARs）利用高激发原子的量子相干性，旨在克服这些限制，代表了无线通信系统中的范式转变。", "method": "本文系统地解释了RARs的基本传感机制，对比了它们与RFRs在工作原理和架构上的差异。探讨了RARs在新兴无线通信场景（如集成传感与通信、量子里德堡雷达和量子空间通信）中的优势。同时，识别了实际挑战（如瞬时带宽有限和非线性失真），并提出了缓解策略和未来的研究方向。", "result": "结果表明，RARs在灵敏度和带宽方面优于传统RFRs，并在集成传感与通信、量子里德堡雷达和量子空间通信等新兴无线通信场景中具有显著优势。论文还识别了瞬时带宽有限和非线性失真等实际挑战。", "conclusion": "本文支持里德堡原子接收机辅助无线系统的发展，通过阐述其基础、潜力、应用和挑战，并提出缓解策略和未来研究方向，以克服现有技术限制。", "translation": "里德堡原子接收机（RARs）利用高激发原子的量子相干性，克服了传统射频接收机（RFRs）固有的物理限制，特别是在灵敏度和带宽方面。这项创新技术代表了无线通信系统中的范式转变。本文系统地解释了RARs的基本传感机制，并对比了它们与RFRs在工作原理和架构上的差异。我们探讨了它们在新兴无线通信场景中的优势，例如集成传感与通信、量子里德堡雷达和量子空间通信。论文还指出了实际挑战，例如瞬时带宽有限和非线性失真。为了解决这些问题，文中概述了缓解策略和未来的研究方向，以支持RARs辅助无线系统的发展。", "summary": "该论文深入探讨了里德堡原子接收机（RARs）作为一种创新技术，如何通过利用高激发原子的量子相干性来克服传统射频接收机（RFRs）在灵敏度和带宽上的局限。文章系统阐述了RARs的基本传感机制、与RFRs的区别，并分析了其在集成传感与通信、量子里德堡雷达、量子空间通信等新兴无线通信场景中的应用潜力。同时，论文也识别了RARs面临的实际挑战，如瞬时带宽限制和非线性失真，并提出了相应的缓解策略和未来的研究方向，旨在推动RARs辅助无线通信系统的发展。", "keywords": "里德堡原子接收机, 无线通信, 量子相干, 射频接收机, 通信挑战", "comments": "该论文着重介绍了里德堡原子接收机这一前沿技术，其创新性在于利用量子效应提升无线通信性能，有望在未来突破传统射频接收机的瓶颈。论文结构完整，涵盖了从基础原理到实际应用和挑战的全面分析，对于推动该领域的研究具有重要意义。"}}
{"id": "2507.22924", "title": "Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers", "authors": ["Brittney Exline", "Melanie Duffin", "Brittany Harbison", "Chrissa da Gomez", "David Joyner"], "categories": ["cs.CL", "I.2.7; K.3.1"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22924v1", "summary": "Graduate-level CS programs in the U.S. increasingly enroll international\nstudents, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.\nstudents. Many of these students take online courses, where peer feedback is\nused to engage students and improve pedagogy in a scalable manner. Since these\ncourses are conducted in English, many students study in a language other than\ntheir first. This paper examines how native versus non-native English speaker\nstatus affects three metrics of peer feedback experience in online U.S.-based\ncomputing courses. Using the Twitter-roBERTa-based model, we analyze the\nsentiment of peer reviews written by and to a random sample of 500 students. We\nthen relate sentiment scores and peer feedback ratings to students' language\nbackground. Results show that native English speakers rate feedback less\nfavorably, while non-native speakers write more positively but receive less\npositive sentiment in return. When controlling for sex and age, significant\ninteractions emerge, suggesting that language background plays a modest but\ncomplex role in shaping peer feedback experiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22924v1", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-23", "AI": {"title_translation": "使用情感分析调查母语和非母语英语使用者之间的同行反馈", "tldr": "研究发现，在美国在线计算机课程中，母语和非母语英语使用者在同行反馈的情感表达和接收上存在差异，语言背景对反馈体验有复杂影响。", "motivation": "本文旨在探究母语和非母语英语使用者身份如何影响在线美国计算机课程中学生的同行反馈体验，鉴于美国研究生CS项目中国际学生比例的显著增加以及这些课程普遍使用英语授课。", "method": "研究使用基于Twitter-roBERTa的模型，对随机抽取的500名学生撰写和收到的同行评论进行情感分析。随后，将情感得分和同行反馈评级与学生的语言背景相关联，并在分析中控制了性别和年龄变量。", "result": "结果显示，母语英语使用者对收到的反馈评价较低，而非母语英语使用者撰写的反馈更积极，但他们收到的反馈情感积极性较低。在控制性别和年龄后，研究发现语言背景在塑造同行反馈体验中扮演着适度但复杂的角色，并存在显著的交互作用。", "conclusion": "语言背景在塑造在线计算机课程中的同行反馈体验方面扮演着适度但复杂的角色，且这种影响会与性别和年龄等因素产生交互作用。", "translation": "美国研究生CS项目越来越多地招收国际学生，2023年60.2%的硕士学位授予了非美国学生。这些学生中有许多人参加在线课程，其中同行反馈被用于吸引学生并以可扩展的方式改进教学法。由于这些课程以英语进行，许多学生以非母语学习。本文研究了母语与非母语英语使用者身份如何影响美国在线计算机课程中同行反馈体验的三个指标。我们使用基于Twitter-roBERTa的模型，分析了从随机抽取的500名学生撰写和收到的同行评审的情感。然后，我们将情感得分和同行反馈评级与学生的语言背景相关联。结果显示，母语英语使用者对反馈的评价较低，而非母语使用者撰写的反馈更积极，但收到的积极情感反馈较少。在控制性别和年龄后，出现了显著的交互作用，表明语言背景在塑造同行反馈体验中扮演着适度但复杂的角色。", "summary": "本文利用Twitter-roBERTa模型对美国在线计算机课程中母语和非母语英语学生的同行反馈进行情感分析。研究发现，母语使用者对反馈评价较低，而非母语使用者撰写更积极的反馈但收到较少积极反馈。结果表明语言背景对同行反馈体验有复杂影响，并与性别和年龄存在交互作用。", "keywords": "情感分析, 同行反馈, 母语使用者, 非母语使用者, 在线教育", "comments": "这项研究通过情感分析揭示了在线学习环境中，母语和非母语英语使用者在同行反馈中的细微差异，为理解国际学生学习体验提供了新视角。其创新点在于结合情感分析量化反馈质量，并探讨了语言背景、性别和年龄在复杂交互中对反馈体验的影响，为教育者提供了有价值的见解。"}}
{"id": "2409.16178", "title": "SDFit: 3D Object Pose and Shape by Fitting a Morphable SDF to a Single Image", "authors": ["Dimitrije Antić", "Georgios Paschalidis", "Shashank Tripathi", "Theo Gevers", "Sai Kumar Dwivedi", "Dimitrios Tzionas"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV'25 Camera Ready; 12 pages, 11 figures, 5 tables", "url": "http://arxiv.org/abs/2409.16178v3", "summary": "Recovering 3D object pose and shape from a single image is a challenging and\nill-posed problem. This is due to strong (self-)occlusions, depth ambiguities,\nthe vast intra- and inter-class shape variance, and the lack of 3D ground truth\nfor natural images. Existing deep-network methods are trained on synthetic\ndatasets to predict 3D shapes, so they often struggle generalizing to\nreal-world images. Moreover, they lack an explicit feedback loop for refining\nnoisy estimates, and primarily focus on geometry without directly considering\npixel alignment. To tackle these limitations, we develop a novel\nrender-and-compare optimization framework, called SDFit. This has three key\ninnovations: First, it uses a learned category-specific and morphable\nsigned-distance-function (mSDF) model, and fits this to an image by iteratively\nrefining both 3D pose and shape. The mSDF robustifies inference by constraining\nthe search on the manifold of valid shapes, while allowing for arbitrary shape\ntopologies. Second, SDFit retrieves an initial 3D shape that likely matches the\nimage, by exploiting foundational models for efficient look-up into 3D shape\ndatabases. Third, SDFit initializes pose by establishing rich 2D-3D\ncorrespondences between the image and the mSDF through foundational features.\nWe evaluate SDFit on three image datasets, i.e., Pix3D, Pascal3D+, and COMIC.\nSDFit performs on par with SotA feed-forward networks for unoccluded images and\ncommon poses, but is uniquely robust to occlusions and uncommon poses.\nMoreover, it requires no retraining for unseen images. Thus, SDFit contributes\nnew insights for generalizing in the wild. Code is available at\nhttps://anticdimi.github.io/sdfit.", "comment": "ICCV'25 Camera Ready; 12 pages, 11 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2409.16178v3", "cate": "cs.CV", "date": "2024-09-24", "updated": "2025-07-31", "AI": {"title_translation": "SDFit: 通过将可变形SDF拟合到单张图像来获取3D物体姿态和形状", "tldr": "SDFit是一个新颖的渲染-比较优化框架，通过将可变形SDF模型拟合到单张图像来恢复3D物体姿态和形状，解决了现有深度网络在真实世界图像泛化性差、缺乏细化反馈以及不直接考虑像素对齐的问题，并在处理遮挡和不常见姿态方面表现出独特的鲁棒性。", "motivation": "从单张图像中恢复3D物体姿态和形状是一个具有挑战性且不适定问题，因为存在强遮挡、深度模糊、类内和类间形状差异大以及缺乏自然图像的3D真值。现有的深度网络方法在合成数据集上训练，难以泛化到真实世界图像，缺乏明确的反馈循环来细化噪声估计，并且主要关注几何形状而不直接考虑像素对齐。", "method": "本文开发了一个名为SDFit的新型渲染-比较优化框架。它有三个关键创新点：1. 使用学习到的类别特定可变形符号距离函数（mSDF）模型，并通过迭代细化3D姿态和形状将其拟合到图像。mSDF通过限制在有效形状流形上的搜索来增强推理，同时允许任意形状拓扑。2. 通过利用基础模型高效查找3D形状数据库，检索与图像可能匹配的初始3D形状。3. 通过基础特征在图像和mSDF之间建立丰富的2D-3D对应关系来初始化姿态。", "result": "SDFit在Pix3D、Pascal3D+和COMIC三个图像数据集上进行了评估。对于未遮挡图像和常见姿态，SDFit表现与最先进的前馈网络相当，但对遮挡和不常见姿态具有独特的鲁棒性。", "conclusion": "SDFit为在野外泛化提供了新的见解，并且对未见过的图像无需重新训练。", "translation": "从单张图像中恢复3D物体姿态和形状是一个具有挑战性且不适定问题。这归因于强烈的（自）遮挡、深度模糊、巨大的类内和类间形状差异，以及自然图像缺乏3D真值。现有的深度网络方法在合成数据集上训练以预测3D形状，因此它们在泛化到真实世界图像时常常面临困难。此外，它们缺乏明确的反馈循环来细化噪声估计，并且主要关注几何形状而不直接考虑像素对齐。为了解决这些限制，我们开发了一个名为SDFit的新型渲染-比较优化框架。它有三个关键创新点：首先，它使用学习到的类别特定可变形符号距离函数（mSDF）模型，并通过迭代细化3D姿态和形状将其拟合到图像。mSDF通过限制在有效形状流形上的搜索来增强推理，同时允许任意形状拓扑。其次，SDFit通过利用基础模型高效查找3D形状数据库，检索与图像可能匹配的初始3D形状。第三，SDFit通过基础特征在图像和mSDF之间建立丰富的2D-3D对应关系来初始化姿态。我们在三个图像数据集（即Pix3D、Pascal3D+和COMIC）上评估了SDFit。对于未遮挡图像和常见姿态，SDFit表现与最先进的前馈网络相当，但对遮挡和不常见姿态具有独特的鲁棒性。此外，它对未见过的图像无需重新训练。因此，SDFit为在野外泛化提供了新的见解。代码可在https://anticdimi.github.io/sdfit获取。", "summary": "SDFit提出了一种新颖的渲染-比较优化框架，用于从单张图像中恢复3D物体姿态和形状。该方法通过将学习到的类别特定可变形SDF模型迭代拟合到图像，并结合了高效的3D形状数据库查找和基于基础特征的2D-3D对应初始化，解决了现有深度网络在真实世界图像泛化性差、缺乏细化反馈和不直接考虑像素对齐等问题。SDFit在多个数据集上表现出与SotA网络相当的性能，并在处理遮挡和不常见姿态方面表现出独特的鲁棒性，无需对未见图像进行重新训练。", "keywords": "3D物体姿态和形状, 可变形SDF, 单张图像, 渲染-比较优化, 泛化性", "comments": "SDFit的创新之处在于其将可变形SDF模型与渲染-比较优化框架结合，允许在有效形状流形上进行约束搜索，从而提高鲁棒性。它通过利用基础模型进行高效的初始形状检索，并建立丰富的2D-3D对应关系来初始化姿态，有效解决了现有方法在泛化性和鲁棒性方面的局限性。特别是，其在处理遮挡和不常见姿态方面的独特鲁棒性以及无需重新训练的能力，使其在真实世界应用中具有重要价值。"}}
{"id": "2507.22894", "title": "When no one shows up (at first): Navigating the uncertainties of participatory workshops in interdisciplinary research", "authors": ["Monique Munarini"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Presented at HHAI25:The 4th International Conference Series on Hybrid Human-Artificial Intelligence, workshop Mind the AI-GAP 2025:Co-Designing Socio-Technical Systems. (June 9-13, 2025 in Pisa, Italy)", "url": "http://arxiv.org/abs/2507.22894v1", "summary": "This reflective paper explores often-unspoken challenges of designing and\nfacilitating co-design and participatory workshops, offering practical\nstrategies for early career researchers (ECRs) navigating these methods.\nDrawing from personal experience conducting a series of workshops titled: How\nto Think About Equity in the AI Ecosystem. It follows the full arc of the\nworkshop experience, from conceptualization and activity planning to\nparticipant recruitment and facilitation, offering a grounded account of what\nhappens when participation does not go as expected. The paper examines the\nmethodological challenges of engaging non-expert participants, particularly\nwhen operating without institutional support, financial incentives, or\nintegration into larger events. Despite initial difficulties such as low\nattendance, the workshop fostered rich discussions among a demographically\ndiverse group and ultimately led to one participant volunteering to\nco-facilitate a subsequent session. This transition from participant to\nco-facilitator exemplifies the redistribution of epistemic authority,\npositioning lived experience as central to research and engagement practices.\nBy reframing perceived failure as a productive site of learning, the paper\noffers practical strategies for ECRs working across disciplines who often\nnavigate unfamiliar methodological terrains, contributing to broader\nconversations on the realities of doing interdisciplinary, participatory work\nin practice.", "comment": "Presented at HHAI25:The 4th International Conference Series on Hybrid\n  Human-Artificial Intelligence, workshop Mind the AI-GAP 2025:Co-Designing\n  Socio-Technical Systems. (June 9-13, 2025 in Pisa, Italy)", "pdf_url": "http://arxiv.org/pdf/2507.22894v1", "cate": "cs.HC", "date": "2025-06-20", "updated": "2025-06-20", "AI": {"title_translation": "当无人出现时（起初）：应对跨学科研究中参与式工作坊的不确定性", "tldr": "本文探讨了跨学科研究中设计和促进参与式工作坊的挑战，特别是当参与度不符合预期时，并为早期职业研究人员提供了实用策略，强调将感知到的失败视为学习的机会。", "motivation": "本文的动机是探讨设计和促进协同设计和参与式工作坊中经常被忽视的挑战，并为早期职业研究人员提供应对这些方法的实用策略，特别是当参与度不符合预期时。", "method": "本文通过一篇反思性论文，借鉴了作者个人在名为“如何在人工智能生态系统中思考公平”的系列工作坊中的经验。它遵循了工作坊从概念化、活动规划到参与者招募和促进的完整过程，提供了一个当参与度不符合预期时的实际案例。", "result": "尽管最初遇到低出席率等困难，但工作坊在不同人口群体之间促进了丰富的讨论，最终导致一名参与者自愿共同主持后续会议。这种从参与者到共同主持人的转变，体现了认识论权威的重新分配，将生活经验置于研究和参与实践的核心。", "conclusion": "本文通过将感知到的失败重新定义为富有成效的学习场所，为从事跨学科工作的早期职业研究人员提供了实用策略，他们经常在不熟悉的方法论领域中摸索，从而促进了关于实践中进行跨学科、参与性工作的现实的更广泛的对话。", "translation": "这篇反思性论文探讨了设计和促进协同设计和参与式工作坊中经常被忽视的挑战，并为早期职业研究人员提供了应对这些方法的实用策略。本文借鉴了个人在名为“如何在人工智能生态系统中思考公平”的系列工作坊中的经验，追溯了工作坊从概念化和活动规划到参与者招募和促进的完整过程，提供了当参与度不符合预期时的实际情况。论文探讨了吸引非专业参与者的方法论挑战，特别是在缺乏机构支持、经济激励或未整合到大型活动中的情况下。尽管最初遇到低出席率等困难，但工作坊在不同人口群体之间促进了丰富的讨论，最终导致一名参与者自愿共同主持后续会议。这种从参与者到共同主持人的转变，体现了认识论权威的重新分配，将生活经验置于研究和参与实践的核心。本文通过将感知到的失败重新定义为富有成效的学习场所，为从事跨学科工作的早期职业研究人员提供了实用策略，他们经常在不熟悉的方法论领域中摸索，从而促进了关于实践中进行跨学科、参与性工作的现实的更广泛的对话。", "summary": "本文是一篇反思性论文，旨在解决早期职业研究人员在跨学科研究中设计和促进参与式工作坊时面临的普遍挑战，特别是在参与度不符合预期的情况下。通过作者在一个关于人工智能公平的工作坊系列中的亲身经验，文章详细阐述了从规划到执行的整个过程，并探讨了在缺乏外部支持下吸引非专家参与者的困难。尽管初期遭遇低出席率，工作坊最终促成了富有成效的讨论，并展示了参与者转变为共同主持人的积极成果。论文将这些挑战视为宝贵的学习机会，为研究人员提供了实用的应对策略，并强调了在实践中进行跨学科、参与性工作的现实性。", "keywords": "参与式工作坊, 跨学科研究, 早期职业研究人员, 协同设计, 参与不确定性", "comments": "这篇论文的创新之处在于它坦诚地探讨了参与式工作坊中“不理想”的现实，特别是当参与度不符合预期时。它不仅指出了问题，还通过个人经验提供了一种“从失败中学习”的积极视角和具体的策略。对于早期职业研究人员来说，这篇论文具有重要的实践指导意义，因为它揭示了在理想情况之外可能遇到的真实挑战，并提供了应对这些挑战的实用方法，有助于他们更好地在跨学科领域开展工作。"}}
{"id": "2507.23702", "title": "Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces", "authors": ["Duc Thien Hua", "Mohammadali Mohammadi", "Hien Quoc Ngo", "Michail Matthaiou"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23702v1", "summary": "We investigate the integration of beyond diagonal reconfigurable intelligent\nsurfaces (BDRISs) into cell free massive multiple input multiple output\n(CFmMIMO) systems to enhance simultaneous wireless information and power\ntransfer (SWIPT). To simultaneously support two groups of users energy\nreceivers (ERs) and information receivers (IRs) without sacrificing time\nfrequency resources, a subset of access points (APs) is dedicated to serving\nERs with the aid of a BDRIS, while the remaining APs focus on supporting IRs. A\nprotective partial zero forcing precoding technique is implemented at the APs\nto manage the non coherent interference between the ERs and IRs. Subsequently,\nclosed form expressions for the spectral efficiency of the IRs and the average\nsum of harvested energy at the ERs are leveraged to formulate a comprehensive\noptimization problem. This problem jointly optimizes the AP selection, AP power\ncontrol, and scattering matrix design at the BDRIS, all based on long term\nstatistical channel state information. This challenging problem is then\neffectively transformed into more tractable forms. To solve these sub problems,\nefficient algorithms are proposed, including a heuristic search for the\nscattering matrix design, as well as successive convex approximation and deep\nreinforcement learning methods for the joint AP mode selection and power\ncontrol design. Numerical results show that a BDRIS with a group or fully\nconnected architecture achieves significant energy harvesting gains over the\nconventional diagonal RIS, especially delivering up to a seven fold increase in\nthe average sum of harvested energy when a heuristic based scattering matrix\ndesign is employed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23702v1", "cate": "cs.IT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "采用超对角可重构智能表面技术的无蜂窝大规模MIMO SWIPT", "tldr": "该研究将超对角可重构智能表面（BDRIS）集成到无蜂窝大规模MIMO（CFmMIMO）系统中，以增强同步无线信息与功率传输（SWIPT），并提出优化算法显著提高了能量收集效率。", "motivation": "该研究旨在通过将超对角可重构智能表面（BDRIS）集成到无蜂窝大规模多输入多输出（CFmMIMO）系统中，以增强同步无线信息和功率传输（SWIPT）的能力，从而在不牺牲时频资源的情况下，同时支持能量接收器（ERs）和信息接收器（IRs）两组用户。", "method": "该研究将部分接入点（AP）专门用于在BDRIS的辅助下服务能量接收器（ERs），而其余AP则支持信息接收器（IRs）。在AP处实施保护性部分迫零预编码技术以管理ERs和IRs之间的非相干干扰。基于长期统计信道状态信息，推导出IRs的频谱效率和ERs的平均总收集能量的闭式表达式，并构建了一个联合优化AP选择、AP功率控制和BDRIS散射矩阵设计的综合优化问题。该问题被转化为更易于处理的形式，并通过启发式搜索（用于散射矩阵设计）、逐次凸近似和深度强化学习（用于AP模式选择和功率控制）等高效算法进行求解。", "result": "数值结果表明，采用群组或全连接架构的BDRIS在能量收集方面比传统对角RIS实现了显著增益。特别是，当采用基于启发式的散射矩阵设计时，平均总收集能量最多可提高七倍。", "conclusion": "该研究成功地将超对角可重构智能表面（BDRIS）集成到无蜂窝大规模MIMO SWIPT系统中，通过联合优化AP选择、功率控制和BDRIS散射矩阵设计，显著提升了能量收集性能，验证了BDRIS在未来无线通信系统中的巨大潜力。", "translation": "我们研究了将超对角可重构智能表面（BDRIS）集成到无蜂窝大规模多输入多输出（CFmMIMO）系统中的方法，以增强同步无线信息和功率传输（SWIPT）。为了在不牺牲时频资源的情况下同时支持两组用户——能量接收器（ERs）和信息接收器（IRs），一部分接入点（APs）在BDRIS的辅助下专门服务ERs，而其余AP则专注于支持IRs。在AP处实施了一种保护性部分迫零预编码技术，以管理ERs和IRs之间的非相干干扰。随后，利用IRs的频谱效率和ERs的平均总收集能量的闭式表达式，构建了一个综合优化问题。该问题基于长期统计信道状态信息，联合优化了AP选择、AP功率控制和BDRIS的散射矩阵设计。这个具有挑战性的问题随后被有效地转化为更易于处理的形式。为了解决这些子问题，提出了高效的算法，包括用于散射矩阵设计的启发式搜索，以及用于AP模式选择和功率控制设计的逐次凸近似和深度强化学习方法。数值结果表明，采用群组或全连接架构的BDRIS比传统对角RIS实现了显著的能量收集增益，特别是在采用基于启发式的散射矩阵设计时，平均总收集能量最多可提高七倍。", "summary": "本研究探讨了将超对角可重构智能表面（BDRIS）集成到无蜂窝大规模MIMO（CFmMIMO）系统中以增强同步无线信息与功率传输（SWIPT）的潜力。为同时服务能量接收器（ERs）和信息接收器（IRs）两类用户，部分接入点（AP）在BDRIS辅助下服务ERs，其余AP服务IRs。研究中应用保护性部分迫零预编码来管理干扰。在此基础上，提出了一个联合优化AP选择、功率控制和BDRIS散射矩阵设计的综合问题，并利用高效算法（包括启发式搜索、逐次凸近似和深度强化学习）进行求解。数值结果表明，与传统对角RIS相比，BDRIS尤其在采用启发式散射矩阵设计时，能使平均收集能量显著增加，最高可达七倍。", "keywords": "超对角可重构智能表面, 无蜂窝大规模MIMO, SWIPT, 能量收集, 优化算法", "comments": "该论文的创新之处在于首次将超对角可重构智能表面（BDRIS）引入无蜂窝大规模MIMO SWIPT系统，并提出了同时服务两类用户的独特AP分配策略。其重要性在于通过联合优化多种参数，显著提升了能量收集效率，为未来无线通信系统中的能量效率和频谱效率协同优化提供了新的思路。研究中结合了多种优化算法，包括启发式搜索、凸优化和深度强化学习，展现了解决复杂通信问题的多学科融合能力。"}}
{"id": "2507.23104", "title": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "authors": ["Jeffrey Eben", "Aitzaz Ahmad", "Stephen Lau"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23104v1", "summary": "Despite advances in large language model (LLM)-based natural language\ninterfaces for databases, scaling to enterprise-level data catalogs remains an\nunder-explored challenge. Prior works addressing this challenge rely on\ndomain-specific fine-tuning - complicating deployment - and fail to leverage\nimportant semantic context contained within database metadata. To address these\nlimitations, we introduce a component-based retrieval architecture that\ndecomposes database schemas and metadata into discrete semantic units, each\nseparately indexed for targeted retrieval. Our approach prioritizes effective\ntable identification while leveraging column-level information, ensuring the\ntotal number of retrieved tables remains within a manageable context budget.\nExperiments demonstrate that our method maintains high recall and accuracy,\nwith our system outperforming baselines over massive databases with varying\nstructure and available metadata. Our solution enables practical text-to-SQL\nsystems deployable across diverse enterprise settings without specialized\nfine-tuning, addressing a critical scalability gap in natural language database\ninterfaces.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23104v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "RASL：面向大规模数据库Text-to-SQL的检索增强模式链接", "tldr": "RASL提出了一种组件化检索架构，通过分解数据库模式和元数据来解决LLM驱动的文本到SQL系统在企业级数据库上的可扩展性问题，无需领域特定微调即可实现高召回率和准确性。", "motivation": "尽管基于大型语言模型（LLM）的数据库自然语言接口取得了进展，但扩展到企业级数据目录仍然是一个未充分探索的挑战。现有工作依赖于特定领域微调，导致部署复杂，并且未能利用数据库元数据中重要的语义上下文。", "method": "我们引入了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，每个单元单独索引以进行有针对性的检索。该方法优先考虑有效的表识别，同时利用列级信息，确保检索到的表总数在可管理的上下文预算内。", "result": "实验表明，我们的方法保持了高召回率和准确性，并且我们的系统在结构和可用元数据各异的大规模数据库上优于基线。", "conclusion": "我们的解决方案实现了无需专门微调即可部署在各种企业环境中的实用Text-to-SQL系统，解决了自然语言数据库接口中关键的可扩展性差距。", "translation": "尽管基于大型语言模型（LLM）的数据库自然语言接口取得了进展，但扩展到企业级数据目录仍然是一个未充分探索的挑战。现有工作为了解决这一挑战，依赖于特定领域微调——这使部署复杂化——并且未能利用数据库元数据中包含的重要语义上下文。为了解决这些限制，我们引入了一种基于组件的检索架构，该架构将数据库模式和元数据分解为离散的语义单元，每个单元单独索引以进行有针对性的检索。我们的方法优先考虑有效的表识别，同时利用列级信息，确保检索到的表总数保持在可管理的上下文预算内。实验表明，我们的方法保持了高召回率和准确性，并且我们的系统在结构和可用元数据各异的大规模数据库上优于基线。我们的解决方案实现了无需专门微调即可部署在各种企业环境中的实用Text-to-SQL系统，解决了自然语言数据库接口中关键的可扩展性差距。", "summary": "RASL提出了一种针对大规模数据库Text-to-SQL的检索增强模式链接方法。它通过将数据库模式和元数据分解为离散的语义单元并单独索引，构建了一个组件化的检索架构。该方法旨在解决LLM驱动的数据库自然语言接口在企业级数据目录中的可扩展性挑战，避免了对领域特定微调的依赖。实验证明，RASL在保持高召回率和准确性的同时，在大规模数据库上表现优于现有基线，从而实现了无需专业微调即可部署的实用Text-to-SQL系统。", "keywords": "检索增强, 模式链接, Text-to-SQL, 大规模数据库, 可扩展性", "comments": "RASL的创新之处在于其组件化的检索架构，该架构通过分解和独立索引数据库模式和元数据来解决LLM在大型数据库中Text-to-SQL的可扩展性问题。这种方法避免了耗时的领域特定微调，使其在企业环境中更易于部署，具有重要的实际价值。它有效地平衡了检索效率和上下文管理，是自然语言数据库接口领域的一个重要进步。"}}
{"id": "2507.23485", "title": "Rational complex Bezier curves", "authors": ["A. Canton", "L. Fernandez-Jambrina", "M. J. Vazquez-Gallo"], "categories": ["math.NA", "cs.GR", "cs.NA", "65D17, 68U07"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures", "url": "http://arxiv.org/abs/2507.23485v1", "summary": "In this paper we develop the formalism of rational complex Bezier curves.\nThis framework is a simple extension of the CAD paradigm, since it describes\narc of curves in terms of control polygons and weights, which are extended to\ncomplex values. One of the major advantages of this extension is that we may\nmake use of two different groups of projective transformations. Besides the\ngroup of projective transformations of the real plane, we have the group of\ncomplex projective transformations. This allows us to apply useful\ntransformations like the geometric inversion to curves in design. In addition\nto this, the use of the complex formulation allows to lower the degree of the\ncurves in some cases. This can be checked using the resultant of two\npolynomials and provides a simple formula for determining whether a rational\ncubic curve is a conic or not. Examples of application of the formalism to\nclassical curves are included.", "comment": "9 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.23485v1", "cate": "math.NA", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "有理复数贝塞尔曲线", "tldr": "论文开发了有理复数贝塞尔曲线的形式，扩展了CAD范式，允许使用复数投影变换，并能在某些情况下降低曲线度数。", "motivation": "动机是扩展CAD范式，通过引入复数贝塞尔曲线，利用复数投影变换（如几何反演）来更灵活地设计曲线，并可能降低曲线的度数。", "method": "开发了有理复数贝塞尔曲线的形式化，将控制多边形和权重扩展到复数值，从而构建了一个CAD范式的新框架。", "result": "结果是该框架允许使用实平面和复平面的两种投影变换群，使得可以应用几何反演等有用变换；在某些情况下能降低曲线的度数；提供了一个简单公式来判断有理三次曲线是否为圆锥曲线；并包含将该形式应用于经典曲线的示例。", "conclusion": "论文成功开发了有理复数贝塞尔曲线的形式化，为CAD设计提供了一个强大且灵活的扩展，特别是通过利用复数投影变换和潜在的度数降低。", "translation": "本文发展了有理复数贝塞尔曲线的形式体系。这个框架是CAD范式的一个简单扩展，因为它用控制多边形和权重来描述曲线弧，这些控制多边形和权重被扩展到复数值。这种扩展的一个主要优点是，我们可以利用两组不同的投影变换。除了实平面的投影变换群，我们还有复数投影变换群。这使我们能够在设计中对曲线应用有用的变换，例如几何反演。此外，复数公式的使用在某些情况下可以降低曲线的度数。这可以通过使用两个多项式的结式来检查，并提供了一个简单的公式来确定有理三次曲线是否为圆锥曲线。文中还包括将该形式体系应用于经典曲线的示例。", "summary": "本文提出了一种有理复数贝塞尔曲线的形式体系，作为现有CAD范式的扩展。该方法通过将控制多边形和权重扩展到复数值，使得设计者可以利用实平面和复平面的双重投影变换群，从而能够应用几何反演等高级变换。此外，这种复数公式在特定情况下有助于降低曲线的度数，并且提供了一个用于判断有理三次曲线是否为圆锥曲线的简易公式。论文还通过经典曲线的示例展示了该形式体系的应用。", "keywords": "有理复数贝塞尔曲线, 投影变换, 几何反演, 曲线度数, CAD", "comments": "这篇论文通过将贝塞尔曲线的参数扩展到复数域，为计算机辅助设计（CAD）中的曲线表示和变换提供了一个新颖且强大的工具。其创新之处在于引入了复数投影变换，这显著增加了曲线操作的灵活性，例如能够实现几何反演。此外，在某些情况下降低曲线度数的能力，对于曲线的存储和计算效率具有实际意义。这表明该方法不仅理论上严谨，而且具有潜在的工程应用价值。"}}
{"id": "2412.11167", "title": "Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette", "authors": ["Jiahao Yuan", "Zixiang Di", "Shangzixin Zhao", "Zhiqing Cui", "Hanqing Wang", "Guisong Yang", "Usman Naseem"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      20 pages, 10 figures", "url": "http://arxiv.org/abs/2412.11167v3", "summary": "Large language models (LLMs) face challenges in aligning with diverse\ncultural values despite their remarkable performance in generation, which stems\nfrom inherent monocultural biases and difficulties in capturing nuanced\ncultural semantics. Existing methods struggle to adapt to unknown culture after\nfine-tuning. Inspired by cultural geography across five continents, we propose\nCultural Palette, a multi-agent framework that redefines cultural alignment as\nan adaptive \"color-blending\" process for country-specific adaptation. Our\napproach harnesses cultural geography across five continents (Africa, America,\nAsia, Europe, Oceania) through three key steps: First, we synthesize the\nPentachromatic Cultural Palette Dataset using GPT-4o, refining\ncontinental-level dialogues with Hofstede's cultural dimensions to establish\nfoundational cultural representations. Second, five continent-level alignment\nagents form specialized cultural communities that generate region-specific\ndraft responses. Third, a Meta Agent employs Cultural MoErges to dynamically\nblend these cultural \"colors\" through attention-gated parameter merging, akin\nto mixing pigments on a palette, resolving conflicts while preserving cultural\nnuances to produce the final culturally-aligned response. Extensive experiments\nacross various countries demonstrate that Cultural Palette surpasses existing\nbaselines in cultural alignment.", "comment": "20 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2412.11167v3", "cate": "cs.CL", "date": "2024-12-15", "updated": "2025-07-31", "AI": {"title_translation": "文化调色板：通过多智能体调色板实现文化对齐多元化", "tldr": "提出“文化调色板”框架，一个多智能体系统，通过模拟“调色”过程，解决大型语言模型在文化对齐方面的挑战，实现跨国适应。", "motivation": "大型语言模型在生成方面表现出色，但由于固有的单一文化偏见和难以捕捉细微的文化语义，在与多样文化价值观对齐方面面临挑战。现有方法在微调后难以适应未知文化。", "method": "受五大洲文化地理启发，提出“文化调色板”框架，将文化对齐重新定义为一种自适应的“调色”过程，用于特定国家的适应。方法包括三个关键步骤：1. 使用GPT-4o合成“五色文化调色板数据集”，并利用霍夫斯泰德文化维度细化大陆级对话，建立基础文化表示。2. 五个大陆级对齐智能体形成专业文化社区，生成区域特定草稿响应。3. 一个元智能体利用“文化混合器”（Cultural MoErges）通过注意力门控参数合并动态混合这些文化“颜色”，解决冲突同时保留文化细微差别，生成最终的文化对齐响应。", "result": "在各国进行的广泛实验表明，“文化调色板”在文化对齐方面超越了现有基线。", "conclusion": "“文化调色板”通过其多智能体框架和创新的“调色”机制，有效解决了大型语言模型在文化对齐方面的挑战，并展现了优于现有方法的性能。", "translation": "大型语言模型（LLMs）尽管在生成方面表现出色，但在与多样文化价值观对齐方面面临挑战，这源于固有的单一文化偏见以及难以捕捉细微文化语义。现有方法在微调后难以适应未知文化。受五大洲文化地理的启发，我们提出了“文化调色板”（Cultural Palette），一个多智能体框架，将文化对齐重新定义为一种自适应的“调色”过程，用于特定国家的适应。我们的方法利用五大洲（非洲、美洲、亚洲、欧洲、大洋洲）的文化地理，通过三个关键步骤：首先，我们使用GPT-4o合成“五色文化调色板数据集”，并利用霍夫斯泰德文化维度细化大陆级对话，以建立基础文化表示。其次，五个大陆级对齐智能体形成专业文化社区，生成区域特定草稿响应。第三，一个元智能体利用“文化混合器”（Cultural MoErges）通过注意力门控参数合并动态混合这些文化“颜色”，类似于在调色板上混合颜料，解决冲突同时保留文化细微差别，以产生最终的文化对齐响应。在各国进行的广泛实验表明，“文化调色板”在文化对齐方面超越了现有基线。", "summary": "本文提出了“文化调色板”框架，旨在解决大型语言模型在与多样文化对齐方面的固有挑战。该框架受全球文化地理启发，将文化对齐视为一个“调色”过程。它首先利用GPT-4o和霍夫斯泰德维度创建“五色文化调色板数据集”，然后由五个大陆级智能体生成区域特定响应，最后由一个元智能体通过注意力门控参数合并动态混合这些响应，以生成文化对齐的最终输出。实验证明，该方法在文化对齐方面优于现有基线。", "keywords": "文化对齐, 大型语言模型, 多智能体系统, 文化地理, 霍夫斯泰德文化维度", "comments": "“文化调色板”框架的创新点在于其将文化对齐比喻为“调色”过程，并引入了多智能体系统来处理不同文化维度的复杂性。通过结合文化地理和霍夫斯泰德文化维度，该方法为LLMs的文化适应性提供了一个新颖且系统化的解决方案。其通过分层智能体（大陆级和元智能体）的协作机制，有望显著提升LLMs在跨文化交流中的表现。"}}
{"id": "2507.23454", "title": "Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary", "authors": ["Marta Bieńkiewicz", "Julia Ayache", "Panayiotis Charalambous", "Cristina Becchio", "Marco Corragio", "Bertram Taetz", "Francesco De Lellis", "Antonio Grotta", "Anna Server", "Daniel Rammer", "Richard Kulpa", "Franck Multon", "Azucena Garcia-Palacios", "Jessica Sutherland", "Kathleen Bryson", "Stéphane Donikian", "Didier Stricker", "Benoît Bardy"], "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.GR", "q-bio.NC", "I.3.0; I.2; J.4; K.4"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      pre-print", "url": "http://arxiv.org/abs/2507.23454v1", "summary": "This article explores a critical gap in Mixed Reality (MR) technology: while\nadvances have been made, MR still struggles to authentically replicate human\nembodiment and socio-motor interaction. For MR to enable truly meaningful\nsocial experiences, it needs to incorporate multi-modal data streams and\nmulti-agent interaction capabilities. To address this challenge, we present a\ncomprehensive glossary covering key topics such as Virtual Characters and\nAutonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges\nof Social MR within Neuroscience, Embodiment, and Technology. Our aim is to\ndrive the transformative evolution of MR technologies that prioritize\nhuman-centric innovation, fostering richer digital connections. We advocate for\nMR systems that enhance social interaction and collaboration between humans and\nvirtual autonomous agents, ensuring inclusivity, ethical design and\npsychological safety in the process.", "comment": "pre-print", "pdf_url": "http://arxiv.org/pdf/2507.23454v1", "cate": "cs.HC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "打破社交混合现实的固有模式——现状与词汇表", "tldr": "混合现实（MR）在真实再现人类具身性和社会运动交互方面存在不足。本文提供了一个全面的词汇表，涵盖了虚拟角色、负责任的人工智能、设计伦理以及社交MR的科学挑战等关键主题，旨在推动以人为本的MR技术发展，促进更丰富的数字连接。", "motivation": "当前混合现实（MR）技术在真实再现人类具身性和社会运动交互方面存在关键性不足，难以实现真正有意义的社交体验。为了克服这一挑战，MR需要整合多模态数据流和多代理交互能力。", "method": "本文通过提供一个全面的词汇表来解决上述挑战，该词汇表涵盖了虚拟角色与自主化、负责任的人工智能、设计伦理以及神经科学、具身化和技术领域中社交MR的科学挑战等关键主题。", "result": "本文旨在推动以人为本的MR技术转型，培养更丰富的数字连接，并倡导开发能够增强人类与虚拟自主代理之间社交互动与协作的MR系统，同时确保包容性、伦理设计和心理安全。", "conclusion": "为了实现真正有意义的社交体验，未来的MR系统需要优先考虑以人为本的创新，整合多模态数据和多代理交互能力，并通过包容性、伦理设计和心理安全来增强人类与虚拟自主代理之间的社交互动与协作。", "translation": "本文探讨了混合现实（MR）技术中的一个关键空白：尽管取得了进展，但MR在真实再现人类具身性和社会运动交互方面仍然面临困难。为了使MR能够实现真正有意义的社交体验，它需要整合多模态数据流和多代理交互能力。为了解决这一挑战，我们提出了一个全面的词汇表，涵盖了虚拟角色与自主化、负责任的人工智能、设计伦理以及神经科学、具身化和技术领域中社交MR的科学挑战等关键主题。我们的目标是推动以人为本的MR技术进行变革性演变，培养更丰富的数字连接。我们倡导MR系统能够增强人类与虚拟自主代理之间的社交互动与协作，并在此过程中确保包容性、伦理设计和心理安全。", "summary": "本文指出混合现实（MR）在真实再现人类具身性和社会运动交互方面存在不足，这阻碍了其提供有意义社交体验的能力。为解决此问题，文章提出了一个全面的词汇表，涵盖虚拟角色、负责任AI、设计伦理以及社交MR的科学挑战等关键领域。该研究旨在推动以人为本的MR技术发展，促进更丰富的数字连接，并倡导开发增强人与虚拟智能体之间社交互动、同时确保包容性、伦理和心理安全的MR系统。", "keywords": "社交混合现实, 人类具身性, 社会交互, 词汇表, 负责任AI", "comments": "本文识别了社交混合现实领域的一个关键挑战，即如何真实地模拟人类的具身性和社会交互。通过提供一个全面的词汇表，它为该领域未来的研究和发展奠定了基础，特别强调了负责任的人工智能、伦理设计和心理安全等以人为本的重要考量。"}}
{"id": "2507.22919", "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "authors": ["Qixuan Hu", "Xumou Zhang", "Jinman Kim", "Florence Bourgeois", "Adam G. Dunn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22919v1", "summary": "Objectives: With accurate estimates of expected safety results, clinical\ntrials could be designed to avoid terminations and limit exposing participants\nto unnecessary risks. We evaluated methods for predicting serious adverse event\n(SAE) results in clinical trials using information only from their\nregistrations prior to the trial. Material and Methods: We analysed 22,107\ntwo-arm parallel interventional clinical trials from ClinicalTrials.gov with\nstructured summary results. Two prediction models were developed: a classifier\npredicting will experimental arm have higher SAE rates (area under the receiver\noperating characteristic curve; AUC) than control arm, and a regression model\nto predict the proportion of SAEs in control arms (root mean squared error;\nRMSE). A transfer learning approach using pretrained language models (e.g.,\nClinicalT5, BioBERT) was used for feature extraction, combined with downstream\nmodel for prediction. To maintain semantic representation in long trial texts\nexceeding localised language model input limits, a sliding window method was\ndeveloped for embedding extraction. Results: The best model\n(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a\nhigher proportion of patients with SAEs. When predicting proportion of\nparticipants experiencing SAE in the control arm, the same model achieved RMSE\nof 18.6%. The sliding window approach consistently outperformed methods without\nit. Across 12 classifiers, the average absolute AUC increase was 2.00%; across\n12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:\nSummary results data available at ClinicalTrials.gov remains underutilised. The\npotential to estimate results of trials before they start is an opportunity to\nimprove trial design and flag discrepancies between expected and reported\nsafety results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22919v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "一种用于从前瞻性注册信息预测临床试验中严重不良事件结果的新型语言模型", "tldr": "论文开发了一种基于语言模型的方法，利用临床试验注册信息预测严重不良事件（SAE）的发生率和哪个试验组SAE率更高，以优化试验设计。", "motivation": "为了避免临床试验终止并限制参与者暴露于不必要的风险，研究旨在通过准确估计预期的安全结果，利用试验前注册信息预测临床试验中的严重不良事件（SAE）结果。", "method": "研究分析了来自ClinicalTrials.gov的22,107项具有结构化总结结果的双臂平行干预性临床试验数据。开发了两种预测模型：一个分类器用于预测试验组SAE率是否高于对照组（通过AUC评估），一个回归模型用于预测对照组SAE的比例（通过RMSE评估）。特征提取采用了基于预训练语言模型（如ClinicalT5, BioBERT）的迁移学习方法，并结合下游模型进行预测。为处理超出语言模型输入限制的长文本，开发了滑动窗口方法进行嵌入提取以保持语义表示。", "result": "最佳模型（ClinicalT5+Transformer+MLP）在预测哪个试验臂有更高比例的SAE患者时，AUC达到77.6%。在预测对照组中经历SAE的参与者比例时，同一模型实现了18.6%的RMSE。滑动窗口方法始终优于没有它的方法，在12个分类器中，平均绝对AUC增加了2.00%；在12个回归器中，平均绝对RMSE减少了1.58%。", "conclusion": "ClinicalTrials.gov上可用的总结结果数据仍未得到充分利用。在试验开始前估计试验结果的潜力是改善试验设计和标记预期与报告安全结果之间差异的重要机会。", "translation": "目标：通过准确估计预期的安全性结果，可以设计临床试验以避免终止并限制参与者暴露于不必要的风险。我们评估了仅使用临床试验注册前的信息来预测临床试验中严重不良事件（SAE）结果的方法。材料与方法：我们分析了来自ClinicalTrials.gov的22,107项具有结构化总结结果的双臂平行干预性临床试验。开发了两种预测模型：一个分类器用于预测试验组是否会比对照组有更高的SAE率（受试者工作特征曲线下面积；AUC），以及一个回归模型用于预测对照组中SAE的比例（均方根误差；RMSE）。使用预训练语言模型（例如ClinicalT5、BioBERT）的迁移学习方法进行特征提取，并结合下游模型进行预测。为了在超出局部语言模型输入限制的长试验文本中保持语义表示，开发了一种滑动窗口方法进行嵌入提取。结果：最佳模型（ClinicalT5+Transformer+MLP）在预测哪个试验臂有更高比例的SAE患者时，AUC达到77.6%。在预测对照组中经历SAE的参与者比例时，同一模型实现了18.6%的RMSE。滑动窗口方法始终优于没有它的方法。在12个分类器中，平均绝对AUC增加了2.00%；在12个回归器中，平均绝对RMSE减少了1.58%。讨论：ClinicalTrials.gov上可用的总结结果数据仍未得到充分利用。在试验开始前估计试验结果的潜力是改善试验设计和标记预期与报告安全结果之间差异的机会。", "summary": "本文开发了一种新型语言模型方法，利用临床试验前注册信息来预测试验中严重不良事件（SAE）的结果。研究分析了来自ClinicalTrials.gov的2万多项试验数据，构建了分类器和回归模型，并结合预训练语言模型（如ClinicalT5）和滑动窗口技术进行特征提取和预测。结果显示，该模型在预测试验组SAE率是否更高以及对照组SAE比例方面表现良好，证明了利用现有注册数据改进临床试验设计和风险评估的潜力。", "keywords": "临床试验, 严重不良事件, 语言模型, 预测, 滑动窗口", "comments": "该论文的创新点在于将预训练语言模型和滑动窗口方法应用于临床试验注册文本，以预测严重的安全性结果，这为早期识别风险和优化试验设计提供了新的视角。其重要性在于能够帮助研究人员在试验开始前预估风险，从而提高试验效率和参与者安全。滑动窗口方法有效解决了长文本输入限制问题，提升了模型的性能。"}}
{"id": "2507.14820", "title": "KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning", "authors": ["Bingran Chen", "Baorun Li", "Jian Yang", "Yong Liu", "Guangyao Zhai"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14820v2", "summary": "High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation\nto serve as a basic function. Previous approaches either directly generate\ngrasps from point-cloud data, suffering from challenges with small objects and\nsensor noise, or infer 3D information from RGB images, which introduces\nexpensive annotation requirements and discretization issues. Recent methods\nmitigate some challenges by retaining a 2D representation to estimate grasp\nkeypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF\nposes. However, these methods are limited by their non-differentiable nature\nand reliance solely on 2D supervision, which hinders the full exploitation of\nrich 3D information. In this work, we present KGN-Pro, a novel grasping network\nthat preserves the efficiency and fine-grained object grasping of previous KGNs\nwhile integrating direct 3D optimization through probabilistic PnP layers.\nKGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further\noutputs a 2D confidence map to weight keypoint contributions during\nre-projection error minimization. By modeling the weighted sum of squared\nre-projection errors probabilistically, the network effectively transmits 3D\nsupervision to its 2D keypoint predictions, enabling end-to-end learning.\nExperiments on both simulated and real-world platforms demonstrate that KGN-Pro\noutperforms existing methods in terms of grasp cover rate and success rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14820v2", "cate": "cs.RO", "date": "2025-07-20", "updated": "2025-07-31", "AI": {"title_translation": "KGN-Pro：通过概率2D-3D对应学习的基于关键点的抓取预测", "tldr": "KGN-Pro是一种新的抓取网络，它通过概率PnP层整合直接3D优化，实现了基于关键点的6自由度抓取预测的端到端学习，并在模拟和真实环境中表现优异。", "motivation": "现有的6自由度抓取估计方法存在缺陷：直接从点云生成抓取对小物体和传感器噪声敏感；从RGB图像推断3D信息需要昂贵的标注和离散化问题；近期基于2D关键点和PnP的方法非可微分且仅依赖2D监督，未能充分利用3D信息。", "method": "KGN-Pro保留了现有KGN的效率和精细抓取能力，并通过概率PnP层集成直接3D优化。它编码RGB-D图像生成关键点图，并输出2D置信度图，用于在重投影误差最小化过程中加权关键点贡献。通过概率性地建模加权平方重投影误差和，网络能将3D监督有效传递给2D关键点预测，实现端到端学习。", "result": "KGN-Pro在模拟和真实世界平台上的实验表明，其在抓取覆盖率和成功率方面均优于现有方法。", "conclusion": "KGN-Pro通过结合概率2D-3D对应学习，成功地解决了现有6自由度抓取预测方法的局限性，并显著提升了抓取性能。", "translation": "高级机器人操作任务需要灵活的6自由度抓取估计作为基本功能。以前的方法要么直接从点云数据生成抓取，但面临小物体的挑战和传感器噪声问题；要么从RGB图像推断3D信息，这引入了昂贵的标注要求和离散化问题。最近的方法通过保留2D表示来估计抓取关键点并应用PnP（Perspective-n-Point）算法计算6自由度姿态，从而缓解了一些挑战。然而，这些方法受限于其不可微分的性质以及仅依赖2D监督，这阻碍了对丰富3D信息的充分利用。在这项工作中，我们提出了KGN-Pro，一种新颖的抓取网络，它保留了以前KGN的效率和精细物体抓取能力，同时通过概率PnP层整合了直接3D优化。KGN-Pro编码配对的RGB-D图像以生成关键点图，并进一步输出2D置信度图，用于在重投影误差最小化过程中加权关键点贡献。通过概率性地建模加权平方重投影误差和，网络有效地将3D监督传递给其2D关键点预测，从而实现端到端学习。在模拟和真实世界平台上的实验表明，KGN-Pro在抓取覆盖率和成功率方面均优于现有方法。", "summary": "本文提出了KGN-Pro，一种新颖的基于关键点的抓取预测网络，旨在解决传统6自由度抓取估计方法中的挑战。KGN-Pro通过引入概率PnP层，将2D关键点预测与直接3D优化相结合，实现了端到端学习。它利用RGB-D图像生成关键点图和2D置信度图，并以概率方式处理重投影误差，从而有效地利用3D监督。实验证明，KGN-Pro在抓取覆盖率和成功率方面优于现有方法。", "keywords": "抓取预测, 关键点, 6自由度, 概率PnP, 端到端学习", "comments": "KGN-Pro的创新之处在于其通过概率PnP层将2D关键点预测与3D优化相结合，实现了端到端学习，这克服了以往方法中非可微分和仅依赖2D监督的局限性。这种方法能够更有效地利用丰富的3D信息，对于提高机器人抓取精度和鲁棒性具有重要意义。"}}
{"id": "2507.23784", "title": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "authors": ["Jessica Bader", "Leander Girrbach", "Stephan Alaniz", "Zeynep Akata"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.23784v1", "summary": "Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23784v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SUB：通过合成属性替换评估CBM泛化能力", "tldr": "概念瓶颈模型（CBMs）在分布变化下难以可靠地识别正确概念。本文引入了SUB基准数据集和Tied Diffusion Guidance (TDG) 方法，旨在严格评估CBMs对概念变化的鲁棒性，从而促进更鲁棒AI方法的发展。", "motivation": "概念瓶颈模型（CBMs）在实际应用中，尤其是在分布变化下，难以可靠地识别正确概念，这限制了它们在医学等需要透明度的领域中的应用。因此，需要一个专门的基准来评估和提高CBMs的鲁棒性。", "method": "本文引入了SUB基准数据集，该数据集包含38,400张基于CUB数据集合成的细粒度图像，通过替换特定概念（如翅膀颜色）生成。为了精确控制图像生成，作者提出了一种新颖的Tied Diffusion Guidance (TDG) 方法，利用噪声共享确保生成图像的类别和属性正确。", "result": "本文成功构建并引入了一个新的细粒度图像和概念基准数据集SUB，以及一种新颖的Tied Diffusion Guidance (TDG) 图像生成方法。这些成果使得能够对概念瓶颈模型（CBMs）及其他可解释模型进行严格的泛化能力评估，从而有助于开发更鲁棒的AI方法。", "conclusion": "SUB基准数据集和Tied Diffusion Guidance (TDG) 方法为严格评估概念瓶颈模型（CBMs）及其它可解释模型在概念变化下的鲁棒性提供了有效工具，有助于推动开发更稳健的AI方法。", "translation": "概念瓶颈模型（CBMs）和其他基于概念的可解释模型在使AI应用更透明方面展现出巨大潜力，这在医学等领域至关重要。尽管它们取得了成功，但我们证明CBMs在分布变化下难以可靠地识别正确概念。为了评估CBMs对概念变化的鲁棒性，我们引入了SUB：一个细粒度的图像和概念基准，包含基于CUB数据集的38,400张合成图像。为了创建SUB，我们选择了CUB数据集的33种鸟类和45个概念的子集来生成图像，这些图像替换了特定的概念，例如翅膀颜色或腹部图案。我们引入了一种新颖的Tied Diffusion Guidance (TDG) 方法来精确控制生成的图像，其中两个并行去噪过程的噪声共享确保了正确鸟类和正确属性的生成。这个新颖的基准能够严格评估CBMs和类似的可解释模型，有助于开发更鲁棒的方法。我们的代码可在https://github.com/ExplainableML/sub获取，数据集可在http://huggingface.co/datasets/Jessica-bader/SUB获取。", "summary": "本文针对概念瓶颈模型（CBMs）在分布变化下识别概念的鲁棒性问题，提出了一个新的细粒度图像和概念基准数据集SUB。该数据集包含38,400张合成图像，通过替换CUB数据集中鸟类的特定属性生成。为精确控制图像生成，作者引入了Tied Diffusion Guidance (TDG) 方法。SUB基准旨在严格评估CBMs及类似可解释模型的泛化能力，从而促进更鲁棒AI方法的发展。", "keywords": "概念瓶颈模型, 分布变化, 基准测试, 合成图像, 可解释AI", "comments": "该论文创新性地提出了一个专门用于评估CBMs在概念漂移下泛化能力的基准数据集SUB，并通过新颖的TDG方法实现了高质量的受控图像生成。这对于推进可解释AI领域中模型鲁棒性的研究具有重要意义，尤其是在医学等对模型可靠性要求高的领域。"}}
{"id": "2411.19610", "title": "Unified discontinuous Galerkin analysis of a thermo/poro-viscoelasticity model", "authors": ["Stefano Bonetti", "Mattia Corti"], "categories": ["math.NA", "cs.NA", "65N30, 65N22, 65N12, 76S05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2303.09481", "url": "http://arxiv.org/abs/2411.19610v2", "summary": "We present and analyze a discontinuous Galerkin method for the numerical\nmodeling of a Kelvin-Voigt thermo/poro-viscoelastic problem. We present the\nderivation of the model and we develop a stability analysis in the continuous\nsetting that holds both for the full inertial and quasi-static problems and\nthat is robust with respect to most of the physical parameters of the problem.\nFor spatial discretization, we propose an arbitrary-order weighted symmetric\ninterior penalty scheme that supports general polytopal grids and is robust\nwith respect to strong heterogeneities in the model coefficients. For the\nsemi-discrete problem, we prove the extension of the stability result\ndemonstrated in the continuous setting and we provide an a-priori error\nestimate. A wide set of numerical simulations is presented to assess the\nconvergence and robustness properties of the proposed method. Moreover, we test\nthe scheme with literature and physically sound test cases for proof-of-concept\napplications in the geophysical context.", "comment": "arXiv admin note: text overlap with arXiv:2303.09481", "pdf_url": "http://arxiv.org/pdf/2411.19610v2", "cate": "math.NA", "date": "2024-11-29", "updated": "2025-07-31", "AI": {"title_translation": "热/孔隙-粘弹性模型的统一间断伽辽金分析", "tldr": "本文提出并分析了一种用于Kelvin-Voigt热/孔隙-粘弹性问题的间断伽辽金方法，证明了其在连续和半离散设置下的稳定性及误差估计，并通过数值模拟验证了其收敛性和鲁棒性。", "motivation": "对Kelvin-Voigt热/孔隙-粘弹性问题进行数值建模。", "method": "提出并分析了一种间断伽辽金（DG）方法，用于数值建模Kelvin-Voigt热/孔隙-粘弹性问题。该方法在连续设置下进行了稳定性分析，适用于全惯性问题和准静态问题，且对大多数物理参数具有鲁棒性。对于空间离散化，提出了一种任意阶加权对称内罚分方案，支持通用多面体网格，并对模型系数的强异质性具有鲁棒性。对于半离散问题，证明了连续设置中稳定性结果的扩展，并提供了先验误差估计。", "result": "在连续和半离散设置下证明了方法的稳定性，并提供了先验误差估计。通过广泛的数值模拟评估了所提出方法的收敛性和鲁棒性。该方案还通过文献和物理上合理的测试用例进行了概念验证应用，特别是在地球物理背景下。", "conclusion": "所提出的间断伽辽金方法能够有效地对热/孔隙-粘弹性问题进行数值建模，并在各种条件下表现出良好的稳定性和鲁棒性。", "translation": "我们提出并分析了一种用于Kelvin-Voigt热/孔隙-粘弹性问题数值建模的间断伽辽金方法。我们介绍了模型的推导，并在连续设置中进行了稳定性分析，该分析适用于全惯性问题和准静态问题，并且对问题的大多数物理参数具有鲁棒性。对于空间离散化，我们提出了一种任意阶加权对称内罚分方案，该方案支持通用多面体网格，并且对模型系数中的强异质性具有鲁棒性。对于半离散问题，我们证明了连续设置中所示稳定性结果的扩展，并提供了先验误差估计。本文提出了一系列广泛的数值模拟，以评估所提出方法的收敛性和鲁棒性。此外，我们还通过文献和物理上合理的测试用例对该方案进行了测试，以进行地球物理背景下的概念验证应用。", "summary": "本文介绍并分析了一种用于Kelvin-Voigt热/孔隙-粘弹性问题数值建模的间断伽辽金方法。研究工作包括模型的推导、连续设置下的稳定性分析（对全惯性及准静态问题均有效且具参数鲁棒性）、以及一种支持通用多面体网格和强异质性的任意阶加权对称内罚分空间离散方案。研究还证明了半离散问题的稳定性扩展和先验误差估计。通过广泛的数值模拟，验证了该方法的收敛性、鲁棒性，并展示了其在地球物理背景下的应用潜力。", "keywords": "间断伽辽金方法, 热/孔隙-粘弹性, Kelvin-Voigt模型, 数值模拟, 稳定性分析", "comments": "该论文的创新点在于提出了一个统一的间断伽辽金方法来处理复杂的Kelvin-Voigt热/孔隙-粘弹性问题，并强调了其在处理强异质性方面的鲁棒性。其重要性体现在为地球物理等领域提供了一种强大的数值模拟工具。"}}
{"id": "2507.23087", "title": "On LLM-Assisted Generation of Smart Contracts from Business Processes", "authors": ["Fabian Stiehle", "Hans Weytjens", "Ingo Weber"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the Workshop on Distributed Ledger Technologies in Business Process Management, At the International Conference for Business Process Management (BPM), 2025", "url": "http://arxiv.org/abs/2507.23087v1", "summary": "Large language models (LLMs) have changed the reality of how software is\nproduced. Within the wider software engineering community, among many other\npurposes, they are explored for code generation use cases from different types\nof input. In this work, we present an exploratory study to investigate the use\nof LLMs for generating smart contract code from business process descriptions,\nan idea that has emerged in recent literature to overcome the limitations of\ntraditional rule-based code generation approaches. However, current LLM-based\nwork evaluates generated code on small samples, relying on manual inspection,\nor testing whether code compiles but ignoring correct execution. With this\nwork, we introduce an automated evaluation framework and provide empirical data\nfrom larger data sets of process models. We test LLMs of different types and\nsizes in their capabilities of achieving important properties of process\nexecution, including enforcing process flow, resource allocation, and\ndata-based conditions. Our results show that LLM performance falls short of the\nperfect reliability required for smart contract development. We suggest future\nwork to explore responsible LLM integrations in existing tools for code\ngeneration to ensure more reliable output. Our benchmarking framework can serve\nas a foundation for developing and evaluating such integrations.", "comment": "Accepted at the Workshop on Distributed Ledger Technologies in\n  Business Process Management, At the International Conference for Business\n  Process Management (BPM), 2025", "pdf_url": "http://arxiv.org/pdf/2507.23087v1", "cate": "cs.SE", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "关于LLM辅助从业务流程生成智能合约", "tldr": "本研究探索了LLM辅助从业务流程生成智能合约代码的能力，并引入了一个自动化评估框架。结果显示，LLM的性能未能达到智能合约开发所需的可靠性，并建议未来工作应探索负责任的LLM集成。", "motivation": "当前LLM辅助代码生成（特别是智能合约）的评估方法存在局限性，例如依赖小样本、手动检查或仅检查编译而不关注正确执行。此外，该研究旨在克服传统基于规则的代码生成方法的局限性。", "method": "本研究进行了一项探索性研究，旨在调查LLM从业务流程描述中生成智能合约代码的用途。为此，研究引入了一个自动化评估框架，并使用更大的流程模型数据集提供了经验数据。研究测试了不同类型和大小的LLM在实现过程执行重要属性（包括强制过程流、资源分配和基于数据的条件）方面的能力。", "result": "研究结果表明，LLM的性能未能达到智能合约开发所需的完美可靠性。", "conclusion": "建议未来的工作应探索LLM在现有代码生成工具中的负责任集成，以确保更可靠的输出。本研究的基准测试框架可以作为开发和评估此类集成的基础。", "translation": "大型语言模型（LLM）改变了软件生产的现实。在更广泛的软件工程社区中，除了许多其他用途外，LLM正在被探索用于从不同类型输入生成代码的用例。在这项工作中，我们提出了一项探索性研究，以调查LLM从业务流程描述中生成智能合约代码的用途，这是一个在近期文献中出现的想法，旨在克服传统基于规则的代码生成方法的局限性。然而，当前基于LLM的工作在小样本上评估生成的代码，依赖于手动检查，或者测试代码是否编译但忽略了正确执行。通过这项工作，我们引入了一个自动化评估框架，并提供了来自更大流程模型数据集的经验数据。我们测试了不同类型和大小的LLM在实现过程执行重要属性方面的能力，包括强制过程流、资源分配和基于数据的条件。我们的结果表明，LLM的性能未能达到智能合约开发所需的完美可靠性。我们建议未来的工作应探索LLM在现有工具中的负责任集成，以确保更可靠的输出。我们的基准测试框架可以作为开发和评估此类集成的基础。", "summary": "本文探讨了大型语言模型（LLM）在从业务流程描述生成智能合约代码方面的应用，旨在克服传统方法和当前LLM评估的局限性。研究引入了一个自动化评估框架，并利用大型数据集对不同类型和大小的LLM进行了测试，评估它们在实现过程流、资源分配和数据条件等方面的能力。结果显示，LLM的性能未能达到智能合约开发所需的高可靠性。因此，论文建议未来工作应专注于负责任地将LLM集成到现有工具中以提高输出可靠性，并指出其基准测试框架可作为此项工作的坚实基础。", "keywords": "LLM, 智能合约, 代码生成, 业务流程, 自动化评估", "comments": "本文识别了LLM在智能合约这一高风险应用中能力的关键不足。引入自动化评估框架是其一项重要贡献，提供了一个急需的严谨基准测试工具。这项工作强调了LLM在复杂、对可靠性要求极高的代码生成方面的当前局限性，并强调了需要更稳健的集成策略而非完全自动化。"}}
{"id": "2406.15304", "title": "Learning Object Compliance via Young's Modulus from Single Grasps using Camera-Based Tactile Sensors", "authors": ["Michael Burgess", "Jialiang Zhao", "Laurence Willemet"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.15304v4", "summary": "Compliance is a useful parametrization of tactile information that humans\noften utilize in manipulation tasks. It can be used to inform low-level\ncontact-rich actions or characterize objects at a high-level. In robotic\nmanipulation, existing approaches to estimate compliance have struggled to\ngeneralize across both object shape and material. Using camera-based tactile\nsensors, proprioception, and force measurements, we present a novel approach to\nestimate object compliance as Young's modulus (E) from parallel grasps. We\nevaluate our method over a novel dataset of 285 common objects, including a\nwide array of shapes and materials with Young's moduli ranging from 5.0 kPa to\n250 GPa. Combining analytical and data-driven approaches, we develop a hybrid\nsystem using a multi-tower neural network to analyze a sequence of tactile\nimages from grasping. This system is shown to estimate the Young's modulus of\nunseen objects within an order of magnitude at 74.2% accuracy across our\ndataset. This is an improvement over purely analytical and data-driven\nbaselines which exhibit 28.9% and 65.0% accuracy respectively. Importantly,\nthis estimation system performs irrespective of object geometry and\ndemonstrates increased robustness across material types. Code is available on\nGitHub and collected data is available on HuggingFace.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.15304v4", "cate": "cs.RO", "date": "2024-06-18", "updated": "2025-07-30", "AI": {"title_translation": "使用基于摄像头的触觉传感器通过单次抓取学习物体顺应性（杨氏模量）", "tldr": "本文提出了一种新颖的混合系统，利用基于摄像头的触觉传感器，通过单次抓取来估计物体的杨氏模量，并且在形状和材料泛化方面表现出色。", "motivation": "在机器人操作中，现有的顺应性估计方法难以在物体形状和材料之间泛化。顺应性作为触觉信息的一种有用参数化，对人类在操作任务中非常重要，可以用于低级接触密集型动作或高级物体表征。", "method": "本研究提出了一种新颖的方法，利用基于摄像头的触觉传感器、本体感受和力测量，从平行抓取中估计物体的顺应性，即杨氏模量 (E)。该方法结合了分析和数据驱动的方法，开发了一个使用多塔神经网络分析抓取过程中触觉图像序列的混合系统。", "result": "该系统能够以74.2%的准确率在未见过的物体上估计杨氏模量，精度在一个数量级以内，优于纯分析基线（28.9%）和纯数据驱动基线（65.0%）。重要的是，该估计系统不受物体几何形状的影响，并显示出对材料类型更强的鲁棒性。", "conclusion": "本研究提出的混合系统能够有效且鲁棒地从单次抓取中估计物体的杨氏模量，克服了现有方法在形状和材料泛化方面的局限性。", "translation": "顺应性是触觉信息的一种有用参数化，人类在操作任务中经常利用它。它可以用于指导低级接触密集型动作或在高层次上表征物体。在机器人操作中，现有的顺应性估计方法难以在物体形状和材料之间泛化。本文利用基于摄像头的触觉传感器、本体感受和力测量，提出了一种新颖的方法，通过平行抓取来估计物体的顺应性，即杨氏模量 (E)。我们在一个包含285个常见物体的新数据集上评估了我们的方法，这些物体包括各种形状和材料，杨氏模量范围从5.0 kPa到250 GPa。结合分析和数据驱动方法，我们开发了一个混合系统，使用多塔神经网络来分析抓取过程中触觉图像序列。该系统被证明能够以74.2%的准确率估计未见过的物体的杨氏模量，精度在一个数量级以内。这比纯分析基线（28.9%）和纯数据驱动基线（65.0%）分别高出。重要的是，该估计系统不受物体几何形状的影响，并显示出对材料类型更强的鲁棒性。代码可在GitHub上获取，收集到的数据可在HuggingFace上获取。", "summary": "本文介绍了一种利用基于摄像头的触觉传感器，通过单次抓取来估计物体杨氏模量的新方法，旨在解决现有机器人操作中顺应性估计方法在形状和材料泛化方面的不足。该方法结合了分析和数据驱动的混合系统，并使用多塔神经网络处理触觉图像序列。实验结果表明，该系统在包含285个不同形状和材料物体的数据集上，对未见过的物体杨氏模量的估计准确率达到74.2%，显著优于纯分析和纯数据驱动的基线方法。此外，该系统在物体几何形状方面具有独立性，并对材料类型表现出更高的鲁棒性。", "keywords": "物体顺应性, 杨氏模量, 触觉传感器, 机器人抓取, 混合系统", "comments": "该论文的创新点在于提出了一个结合分析和数据驱动方法的混合系统，用于从单次抓取中估计物体的杨氏模量，有效解决了现有方法在物体形状和材料泛化方面的挑战。其重要性在于为机器人操作提供了一种更鲁棒和通用的物体顺应性估计手段，有望提升机器人执行接触密集型任务的能力。所提出的方法在准确性和泛化性方面均优于基线，展现了良好的应用前景。"}}
{"id": "2507.23604", "title": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning", "authors": ["Tommaso Marzi", "Cesare Alippi", "Andrea Cini"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23604v1", "summary": "Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23604v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多智能体强化学习中的分层消息传递策略", "tldr": "本文提出了一种新颖有效的方法，用于学习多智能体分层消息传递策略。该方法结合了封建分层强化学习框架和分层图结构，并设计了一种新的奖励分配方法。在相关基准测试中，该方法表现优于现有最新技术。", "motivation": "去中心化多智能体强化学习（MARL）方法虽然可以学习可扩展的多智能体策略，但受限于部分可观测性和诱导的非平稳性。虽然通过引入通信（如消息传递）和分层强化学习（HRL）可以解决这些挑战，但优化问题限制了分层策略在多智能体系统中的应用，导致这些方法的结合尚未被充分探索。", "method": "本文提出了一种学习多智能体分层消息传递策略的新颖有效方法。该方法采用了封建HRL框架，并依赖于分层图结构来实现智能体之间的规划和协调。层级较低的智能体从上层接收目标，并与同级别的相邻智能体交换消息。为了学习分层多智能体策略，论文设计了一种新的奖励分配方法，该方法基于训练低层策略以最大化与上层相关的优势函数。", "result": "在相关基准测试中，我们提出的方法与现有最新技术相比表现出色。", "conclusion": "本文通过提出一种结合分层强化学习和消息传递的新颖框架及奖励分配方法，成功解决了多智能体强化学习中的挑战，并展示了优越的性能。", "translation": "去中心化多智能体强化学习（MARL）方法允许学习可扩展的多智能体策略，但受限于部分可观测性和诱导的非平稳性。这些挑战可以通过引入促进协调和高级规划的机制来解决。具体来说，协调和时间抽象可以通过通信（例如，消息传递）和分层强化学习（HRL）决策方法来实现。然而，优化问题限制了分层策略在多智能体系统中的适用性。因此，这些方法的结合尚未得到充分探索。为了填补这一空白，我们提出了一种新颖有效的方法，用于学习多智能体分层消息传递策略。我们采用了封建HRL框架，并依赖于分层图结构来实现智能体之间的规划和协调。层级较低的智能体从上层接收目标，并与同级别的相邻智能体交换消息。为了学习分层多智能体策略，我们设计了一种新的奖励分配方法，该方法基于训练低层策略以最大化与上层相关的优势函数。在相关基准测试中，我们的方法与现有最新技术相比表现出色。", "summary": "本文提出了一种用于去中心化多智能体强化学习（MARL）的分层消息传递策略的新颖方法。针对MARL中部分可观测性和非平稳性等挑战，以及分层与通信方法结合时存在的优化问题，作者采用封建分层强化学习（HRL）框架和分层图结构来实现智能体间的规划与协调。核心创新在于设计了一种新的奖励分配方法，通过最大化上层关联的优势函数来训练低层策略。实验结果表明，该方法在相关基准测试中表现优于现有最先进技术。", "keywords": "多智能体强化学习, 分层强化学习, 消息传递, 去中心化控制, 封建HRL", "comments": "该论文的创新之处在于有效地将分层强化学习（特别是封建HRL）与消息传递机制整合到多智能体系统中，这在之前曾受限于优化问题。所提出的新颖奖励分配方法是实现这种整合的关键。这种方法有望在复杂的多智能体环境中提升协调性和可扩展性。"}}
{"id": "2507.23248", "title": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "authors": ["Shimanto Bhowmik", "Tawsif Tashwar Dipto", "Md Sazzad Islam", "Sheryl Hsu", "Tahsin Reasat"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23248v1", "summary": "Bengali is an underrepresented language in NLP research. However, it remains\na challenge due to its unique linguistic structure and computational\nconstraints. In this work, we systematically investigate the challenges that\nhinder Bengali NLP performance by focusing on the absence of standardized\nevaluation benchmarks. We then evaluated 10 recent open source Large Language\nModels (LLMs) in 8 of the translated datasets and performed a comprehensive\nerror analysis to pinpoint their primary failure modes. Our findings reveal\nconsistent performance gaps for Bengali compared to English, particularly for\nsmaller models and specific model families like Mistral. We also identified\npromising robustness in certain architectures, such as DeepSeek, that maintain\nmore stable performance across languages. Our analysis reveals an inverse\nrelationship between tokenization efficiency and LLM accuracy where models tend\nto perform worse when inputs are excessively tokenized, whereas more efficient\n\\& concise tokenization results in improved performance. These findings\nhighlight critical areas where current models fall short and underscore the\nneed for improved dataset quality and evaluation methodologies tailored to\nmultilingual contexts. This work will catalyze further research on NLP for\nunderrepresented languages, helping to democratize access to advanced language\ntechnologies worldwide. The code and dataset used in this research is publicly\navailable at https://github.com/BengaliAI/bn-llm-benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23248v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "评估大型语言模型对孟加拉语的多语言能力：基准创建与性能分析", "tldr": "本文创建了孟加拉语LLM评估基准，评估了10个开源LLM，发现孟加拉语性能普遍低于英语，并揭示了分词效率与准确性之间的关系，强调了改进数据集和评估方法的重要性。", "motivation": "孟加拉语在自然语言处理研究中代表性不足，面临独特的语言结构和计算限制。缺乏标准化的评估基准是阻碍孟加拉语NLP性能的关键挑战。", "method": "本研究系统地调查了阻碍孟加拉语NLP性能的挑战，重点关注标准化评估基准的缺失。然后，在8个翻译数据集中评估了10个近期开源大型语言模型（LLM），并进行了全面的错误分析以找出其主要的失败模式。", "result": "研究发现孟加拉语的性能与英语相比存在一致的差距，尤其对于小型模型和特定模型家族（如Mistral）。同时识别出某些架构（如DeepSeek）在跨语言方面表现出良好的鲁棒性。分析揭示了分词效率与LLM准确性之间存在反比关系：当输入被过度分词时，模型表现更差，而更高效简洁的分词会带来性能提升。", "conclusion": "这些发现突出了当前模型不足的关键领域，并强调了需要改进数据集质量和针对多语言环境的评估方法。这项工作将促进对代表性不足语言的NLP研究，有助于实现全球范围内先进语言技术的民主化。", "translation": "孟加拉语在自然语言处理（NLP）研究中代表性不足。然而，由于其独特的语言结构和计算限制，它仍然是一个挑战。在这项工作中，我们系统地调查了阻碍孟加拉语NLP性能的挑战，重点关注标准化评估基准的缺失。然后，我们在8个翻译数据集中评估了10个近期开源大型语言模型（LLM），并进行了全面的错误分析以找出其主要的失败模式。我们的发现揭示了孟加拉语与英语相比存在一致的性能差距，特别是对于小型模型和特定模型家族（如Mistral）。我们还识别出某些架构（如DeepSeek）表现出有希望的鲁棒性，在不同语言中保持更稳定的性能。我们的分析揭示了分词效率与LLM准确性之间存在反比关系，即当输入被过度分词时，模型往往表现更差，而更高效、简洁的分词则会带来性能提升。这些发现突出了当前模型不足的关键领域，并强调了需要改进数据集质量和针对多语言环境的评估方法。这项工作将促进对代表性不足语言的NLP研究，有助于实现全球范围内先进语言技术的民主化。本研究中使用的代码和数据集已公开，网址为https://github.com/BengaliAI/bn-llm-benchmark。", "summary": "本研究旨在解决孟加拉语在NLP领域代表性不足的问题，并缺乏标准评估基准的挑战。作者创建了一个孟加拉语大型语言模型（LLM）评估基准，并在8个翻译数据集上评估了10个开源LLM。研究发现，孟加拉语的LLM性能普遍低于英语，尤其对于小型模型，但某些架构如DeepSeek表现出较好的跨语言鲁棒性。此外，研究揭示了分词效率与LLM准确性之间的反比关系。这些发现强调了改进多语言数据集质量和评估方法的重要性，以推动代表性不足语言的NLP发展。", "keywords": "孟加拉语, 大型语言模型, 基准评估, 多语言能力, 分词效率", "comments": "本文的创新在于为孟加拉语这一代表性不足的语言创建了首个标准化LLM评估基准，并系统地分析了LLM在孟加拉语上的表现和失败模式，特别是揭示了分词效率对性能的影响，这对多语言NLP研究具有重要指导意义。其贡献在于促进了对低资源语言LLM性能的理解，并为未来的研究提供了开放的资源。"}}
{"id": "2503.15768", "title": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer", "authors": ["Alexandra DeLucia", "Mark Dredze"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15768v2", "summary": "Abstractive multi-document summarization (MDS) is the task of automatically\nsummarizing information in multiple documents, from news articles to\nconversations with multiple speakers. The training approaches for current MDS\nmodels can be grouped into four approaches: end-to-end with special\npre-training (\"direct\"), chunk-then-summarize, extract-then-summarize, and\ninference with GPT-style models. In this work, we evaluate MDS models across\ntraining approaches, domains, and dimensions (reference similarity, quality,\nand factuality), to analyze how and why models trained on one domain can fail\nto summarize documents from another (News, Science, and Conversation) in the\nzero-shot domain transfer setting. We define domain-transfer \"failure\" as a\ndecrease in factuality, higher deviation from the target, and a general\ndecrease in summary quality. In addition to exploring domain transfer for MDS\nmodels, we examine potential issues with applying popular summarization metrics\nout-of-the-box.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15768v2", "cate": "cs.CL", "date": "2025-03-20", "updated": "2025-07-30", "AI": {"title_translation": "“一刀切”可行吗？：多文档摘要领域迁移中的失败测量", "tldr": "本文评估了多文档摘要模型在零样本领域迁移中的表现，分析了模型为何在不同领域间迁移时失败，并探讨了现有摘要指标的应用问题。", "motivation": "现有MDS模型在不同训练方法下，当应用于未训练过的领域时，可能会出现性能下降。研究的动机在于分析模型为何在零样本领域迁移设置下，从一个领域训练的模型无法有效总结另一个领域的文档，并探讨现有摘要评估指标的适用性问题。", "method": "作者评估了多文档摘要（MDS）模型，横跨不同的训练方法（直接法、分块再摘要、抽取再摘要、GPT风格模型推理）、不同领域（新闻、科学、对话）以及不同维度（参考相似度、质量、事实性）。研究在零样本领域迁移设置下进行，并将领域迁移“失败”定义为事实性下降、与目标偏差更大以及摘要质量普遍下降。", "result": "研究分析了模型在零样本领域迁移设置下，为何以及如何在一个领域训练的模型无法总结另一个领域的文档，并探讨了开箱即用式应用流行摘要指标的潜在问题。具体结果（如量化失败程度或具体原因）未在摘要中提及。", "conclusion": "Not mentioned in abstract", "translation": "抽象式多文档摘要（MDS）是自动总结多篇文档（从新闻文章到多说话人对话）中信息的任务。当前MDS模型的训练方法可分为四种：带有特殊预训练的端到端方法（“直接法”）、先分块再摘要、先抽取再摘要以及使用GPT风格模型进行推理。在这项工作中，我们评估了MDS模型在不同训练方法、领域和维度（参考相似度、质量和事实性）上的表现，以分析在零样本领域迁移设置下，在一个领域训练的模型如何以及为何无法总结来自另一个领域（新闻、科学和对话）的文档。我们将领域迁移“失败”定义为事实性下降、与目标偏差更大以及摘要质量普遍下降。除了探索MDS模型的领域迁移问题外，我们还检查了开箱即用式应用流行摘要指标的潜在问题。", "summary": "本文研究了抽象式多文档摘要（MDS）模型在零样本领域迁移场景下的性能表现。作者评估了不同训练方法（如端到端、分块、抽取、GPT风格）的MDS模型在新闻、科学和对话等不同领域间的迁移能力，并从参考相似度、质量和事实性等维度分析了模型失败的原因。研究明确了领域迁移失败的定义，即事实性下降、与目标偏差增大和摘要质量降低。此外，论文还探讨了直接应用现有流行摘要评估指标可能存在的问题。", "keywords": "多文档摘要, 领域迁移, 零样本学习, 事实性, 摘要评估", "comments": "这项工作探讨了多文档摘要模型在跨领域应用时面临的重要挑战，即领域迁移失败问题，这对于MDS模型的实际部署具有重要意义。同时，研究还关注了现有摘要评估指标在不同上下文中的适用性，这对于准确评估模型性能至关重要。其创新点在于系统性地定义和测量了领域迁移失败，并对现有评估体系提出了审视。"}}
{"id": "2507.23633", "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23633v1", "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23633v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MemoCue：通过策略引导查询增强基于LLM的智能体进行人类记忆召回", "tldr": "MemoCue通过策略引导的查询，让LLM智能体更有效地帮助人类召回记忆，解决了传统方法记忆模块大小限制问题。", "motivation": "传统智能体辅助记忆召回方法受限于记忆模块大小，影响召回性能。受记忆理论启发，通过有效线索主动激活相关记忆是关键。", "method": "提出MemoCue，一个基于策略引导的智能体辅助记忆召回方法。核心是Recall Router框架，包括：设计5W召回图分类记忆查询和定义十五种召回策略模式；结合蒙特卡洛树搜索的层次召回树优化策略选择和响应生成；构建指令微调数据集并微调开源LLMs。", "result": "MemoCue在三个代表性数据集上，在召回启发方面超越基于LLM的方法17.74%。进一步的人类评估突显了其在记忆召回应用中的优势。", "conclusion": "MemoCue通过策略引导的查询，显著提升了LLM智能体在人类记忆召回中的表现，解决了传统方法的局限性，并得到了实验和人类评估的验证。", "translation": "智能体辅助记忆召回是人机交互领域一个重要的研究问题。在传统方法中，智能体可以从其配备的记忆模块中检索信息，以帮助人们回忆不完整或模糊的记忆。记忆模块的有限大小阻碍了完整记忆的获取，并在实践中影响记忆召回性能。记忆理论表明，可以通过一些有效的线索主动激活人的相关记忆。受此启发，我们提出了一种新颖的策略引导智能体辅助记忆召回方法，允许智能体通过精心设计的策略将原始查询转化为富含线索的查询，以帮助人们回忆记忆。为此，存在两个关键挑战。(1) 如何针对具有不同记忆召回特征的各种遗忘场景选择合适的召回策略？(2) 在只有抽象和稀疏标注的策略模式下，如何利用召回策略获得高质量的响应？为了应对这些挑战，我们提出了一个召回路由器（Recall Router）框架。具体来说，我们设计了一个5W召回图（5W Recall Map）来将记忆查询分类为五种典型场景，并定义了相应场景下的十五种召回策略模式。然后，我们提出一个结合蒙特卡洛树搜索算法的层次召回树来优化策略的选择和策略响应的生成。我们构建了一个指令微调数据集，并微调了多个开源大型语言模型（LLMs）以开发MemoCue，一个擅长提供记忆启发式响应的智能体。在三个代表性数据集上的实验表明，MemoCue在召回启发方面超越了基于LLM的方法17.74%。进一步的人类评估突显了其在记忆召回应用中的优势。", "summary": "本文提出MemoCue，一个基于LLM的智能体辅助人类记忆召回系统，旨在通过策略引导的查询解决传统方法记忆模块有限的问题。MemoCue引入Recall Router框架，包含5W召回图分类查询场景和定义策略模式，并利用结合蒙特卡洛树搜索的层次召回树优化策略选择和响应生成。通过指令微调LLMs，MemoCue在实验中显著提升了记忆召回启发效果，并获得人类评估的认可。", "keywords": "记忆召回, LLM智能体, 策略引导查询, Recall Router, 人机交互", "comments": "本文创新性地将记忆理论中的“线索激活”概念与LLM结合，通过策略引导的查询来增强记忆召回，而非仅仅依赖于固定大小的记忆模块。Recall Router框架的设计，特别是5W召回图和结合MCTS的层次召回树，为LLM在复杂认知任务中的应用提供了新的范式。"}}
{"id": "2507.23389", "title": "Causal Explanation of Concept Drift -- A Truly Actionable Approach", "authors": ["David Komnick", "Kathrin Lammers", "Barbara Hammer", "Valerie Vaquet", "Fabian Hinder"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This manuscript is accepted to be presented at the TempXAI workshop at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD 2025)", "url": "http://arxiv.org/abs/2507.23389v1", "summary": "In a world that constantly changes, it is crucial to understand how those\nchanges impact different systems, such as industrial manufacturing or critical\ninfrastructure. Explaining critical changes, referred to as concept drift in\nthe field of machine learning, is the first step towards enabling targeted\ninterventions to avoid or correct model failures, as well as malfunctions and\nerrors in the physical world. Therefore, in this work, we extend model-based\ndrift explanations towards causal explanations, which increases the\nactionability of the provided explanations. We evaluate our explanation\nstrategy on a number of use cases, demonstrating the practical usefulness of\nour framework, which isolates the causally relevant features impacted by\nconcept drift and, thus, allows for targeted intervention.", "comment": "This manuscript is accepted to be presented at the TempXAI workshop\n  at the European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECMLPKDD 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23389v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "因果解释概念漂移——一种真正可操作的方法", "tldr": "本文提出一种将模型解释与因果解释相结合的方法，以更有效地识别概念漂移中的因果相关特征，从而实现有针对性的干预。", "motivation": "在不断变化的世界中，理解变化如何影响系统（如工业制造或关键基础设施）至关重要。解释概念漂移（机器学习中的关键变化）是实现有针对性干预以避免或纠正模型故障以及物理世界中故障和错误的第一步。", "method": "本文将基于模型的漂移解释扩展到因果解释，以提高所提供解释的可操作性。该框架能够隔离受概念漂移影响的因果相关特征。", "result": "作者在多个用例上评估了其解释策略，证明了该框架的实际有用性，因为它能够隔离受概念漂移影响的因果相关特征，从而实现有针对性的干预。", "conclusion": "通过提供因果解释，本方法能够提高概念漂移解释的可操作性，并允许对受影响的因果相关特征进行有针对性的干预，从而避免或纠正系统故障。", "translation": "在一个不断变化的世界中，理解这些变化如何影响不同的系统（例如工业制造或关键基础设施）至关重要。解释关键变化（在机器学习领域中称为概念漂移）是实现有针对性干预的第一步，以避免或纠正模型故障，以及物理世界中的故障和错误。因此，在这项工作中，我们将基于模型的漂移解释扩展到因果解释，这增加了所提供解释的可操作性。我们在多个用例上评估了我们的解释策略，展示了我们框架的实际有用性，该框架隔离了受概念漂移影响的因果相关特征，从而允许有针对性的干预。", "summary": "本文提出了一种将模型基础漂移解释扩展为因果解释的新方法，旨在提高概念漂移解释的可操作性。该方法通过识别和隔离受概念漂移影响的因果相关特征，从而实现对系统故障或模型错误的精准干预和纠正，并在多个用例中验证了其有效性。", "keywords": "概念漂移, 因果解释, 模型故障, 特征隔离, 可操作性", "comments": "这篇论文的创新点在于将传统模型基础的概念漂移解释提升到因果解释的层面，这显著增强了解释的“可操作性”。通过识别因果相关特征，研究人员和工程师可以更精确地定位问题根源并实施有针对性的干预，而非仅仅知道发生了漂移。这对于工业制造和关键基础设施等对鲁棒性要求极高的领域具有重要意义。"}}
{"id": "2507.23325", "title": "FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models", "authors": ["Yiming Yang", "Hongbin Lin", "Yueru Luo", "Suzhong Fu", "Chao Zheng", "Xinrui Yan", "Shuqi Mei", "Kun Tang", "Shuguang Cui", "Zhen Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23325v1", "summary": "Lane segment topology reasoning provides comprehensive bird's-eye view (BEV)\nroad scene understanding, which can serve as a key perception module in\nplanning-oriented end-to-end autonomous driving systems. Existing lane topology\nreasoning methods often fall short in effectively leveraging temporal\ninformation to enhance detection and reasoning performance. Recently,\nstream-based temporal propagation method has demonstrated promising results by\nincorporating temporal cues at both the query and BEV levels. However, it\nremains limited by over-reliance on historical queries, vulnerability to pose\nestimation failures, and insufficient temporal propagation. To overcome these\nlimitations, we propose FASTopoWM, a novel fast-slow lane segment topology\nreasoning framework augmented with latent world models. To reduce the impact of\npose estimation failures, this unified framework enables parallel supervision\nof both historical and newly initialized queries, facilitating mutual\nreinforcement between the fast and slow systems. Furthermore, we introduce\nlatent query and BEV world models conditioned on the action latent to propagate\nthe state representations from past observations to the current timestep. This\ndesign substantially improves the performance of temporal perception within the\nslow pipeline. Extensive experiments on the OpenLane-V2 benchmark demonstrate\nthat FASTopoWM outperforms state-of-the-art methods in both lane segment\ndetection (37.4% v.s. 33.6% on mAP) and centerline perception (46.3% v.s. 41.5%\non OLS).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23325v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "FASTopoWM：基于潜在世界模型的快慢车道线段拓扑推理", "tldr": "FASTopoWM提出了一种新的快慢车道线段拓扑推理框架，利用潜在世界模型解决了现有方法在时间信息利用和姿态估计失败方面的局限性，并在OpenLane-V2基准上取得了最先进的性能。", "motivation": "现有的车道拓扑推理方法在有效利用时间信息来增强检测和推理性能方面存在不足，并且流式时间传播方法过度依赖历史查询、易受姿态估计失败影响以及时间传播不足。", "method": "本文提出了FASTopoWM，一个增强了潜在世界模型的快慢车道线段拓扑推理框架。为了减少姿态估计失败的影响，该框架并行监督历史和新初始化的查询，实现快慢系统之间的相互强化。此外，引入了以动作潜在变量为条件的潜在查询和BEV世界模型，以将状态表示从过去观测传播到当前时间步。", "result": "在OpenLane-V2基准上的广泛实验表明，FASTopoWM在车道线段检测（mAP为37.4% 对比 33.6%）和中心线感知（OLS为46.3% 对比 41.5%）方面均优于最先进的方法。", "conclusion": "FASTopoWM通过引入快慢系统和潜在世界模型，有效克服了现有车道拓扑推理方法在时间信息利用和姿态估计鲁棒性方面的局限性，显著提升了车道线段检测和中心线感知的性能。", "translation": "车道线段拓扑推理提供了全面的鸟瞰图（BEV）道路场景理解，可以作为面向规划的端到端自动驾驶系统中的关键感知模块。现有的车道拓扑推理方法往往未能有效利用时间信息来增强检测和推理性能。最近，基于流的时间传播方法通过在查询和BEV级别整合时间线索，展示了有希望的结果。然而，它仍然受限于对历史查询的过度依赖、对姿态估计失败的脆弱性以及时间传播不足。为了克服这些局限性，我们提出了FASTopoWM，一个新颖的、增强了潜在世界模型的快慢车道线段拓扑推理框架。为了减少姿态估计失败的影响，这个统一的框架能够并行监督历史和新初始化的查询，促进快慢系统之间的相互强化。此外，我们引入了以动作潜在变量为条件的潜在查询和BEV世界模型，以将状态表示从过去观测传播到当前时间步。这种设计大大提高了慢速管道内时间感知的性能。在OpenLane-V2基准上的广泛实验表明，FASTopoWM在车道线段检测（mAP为37.4% 对比 33.6%）和中心线感知（OLS为46.3% 对比 41.5%）方面均优于最先进的方法。", "summary": "本文提出了FASTopoWM，一个基于潜在世界模型的快慢车道线段拓扑推理框架，旨在解决现有方法在时间信息利用不足和姿态估计失败方面的问题。该框架通过并行监督历史和新查询以及引入潜在世界模型进行状态传播，显著提升了时间感知性能。实验结果表明，FASTopoWM在OpenLane-V2基准上超越了现有最先进的车道线段检测和中心线感知方法。", "keywords": "车道拓扑推理, 潜在世界模型, 快慢系统, 自动驾驶, 时间感知", "comments": "该论文的创新点在于引入了“快慢系统”和“潜在世界模型”来克服传统方法在时间信息利用和姿态估计鲁棒性方面的不足。通过并行监督和状态传播，有效提升了自动驾驶系统中关键感知模块的性能，对鸟瞰图道路场景理解具有重要意义。"}}
{"id": "2507.23480", "title": "FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction", "authors": ["Donghyun Lee", "Dawoon Jeong", "Jae W. Lee", "Hongil Yoon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.23480v1", "summary": "Deep neural networks have revolutionized 3D point cloud processing, yet\nefficiently handling large and irregular point clouds remains challenging. To\ntackle this problem, we introduce FastPoint, a novel software-based\nacceleration technique that leverages the predictable distance trend between\nsampled points during farthest point sampling. By predicting the distance\ncurve, we can efficiently identify subsequent sample points without\nexhaustively computing all pairwise distances. Our proposal substantially\naccelerates farthest point sampling and neighbor search operations while\npreserving sampling quality and model performance. By integrating FastPoint\ninto state-of-the-art 3D point cloud models, we achieve 2.55x end-to-end\nspeedup on NVIDIA RTX 3090 GPU without sacrificing accuracy.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23480v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "FastPoint: 通过样本点距离预测加速3D点云模型推理", "tldr": "FastPoint通过预测最远点采样中的距离趋势，显著加速3D点云模型的推理，实现了2.55倍的端到端加速而无精度损失。", "motivation": "深度神经网络彻底改变了3D点云处理，但高效处理大型和不规则点云仍然是一个挑战。", "method": "我们引入了FastPoint，一种新颖的基于软件的加速技术。它利用最远点采样过程中采样点之间可预测的距离趋势。通过预测距离曲线，可以有效地识别后续采样点，而无需穷尽地计算所有成对距离。该方法加速了最远点采样和邻域搜索操作。", "result": "FastPoint在不牺牲采样质量和模型性能的情况下，显著加速了最远点采样和邻域搜索操作。将FastPoint集成到最先进的3D点云模型中，在NVIDIA RTX 3090 GPU上实现了2.55倍的端到端加速，且没有牺牲精度。", "conclusion": "FastPoint通过优化最远点采样和邻域搜索，成功加速了3D点云模型的推理，同时保持了模型性能和准确性。", "translation": "深度神经网络彻底改变了3D点云处理，但高效处理大型和不规则点云仍然具有挑战性。为了解决这个问题，我们引入了FastPoint，一种新颖的基于软件的加速技术，它利用最远点采样过程中采样点之间可预测的距离趋势。通过预测距离曲线，我们可以有效地识别后续采样点，而无需穷尽地计算所有成对距离。我们的方案在保持采样质量和模型性能的同时，显著加速了最远点采样和邻域搜索操作。通过将FastPoint集成到最先进的3D点云模型中，我们在NVIDIA RTX 3090 GPU上实现了2.55倍的端到端加速，且没有牺牲精度。", "summary": "本文提出了FastPoint，一种创新的软件加速技术，旨在提高3D点云模型的推理效率。该方法通过预测最远点采样中的点距离趋势，避免了耗时的距离计算，从而加速了采样和邻域搜索。实验结果表明，FastPoint在保持模型性能和精度的前提下，实现了2.55倍的端到端加速。", "keywords": "3D点云, 推理加速, 最远点采样, 距离预测, FastPoint", "comments": "FastPoint的创新点在于利用了最远点采样中距离的可预测性，避免了昂贵的距离计算，从而实现了显著的加速。这种方法对于需要处理大型点云的应用具有重要意义，因为它在不牺牲精度的前提下提高了效率。"}}
{"id": "2505.06275", "title": "SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms", "authors": ["Yuzhou Zhu", "Zheng Zhang", "Ruyi Zhang", "Liang Zhou"], "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.optics"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.06275v2", "summary": "Wave-like images-from attosecond streaking spectrograms to optical spectra,\naudio mel-spectrograms and periodic video frames-encode critical harmonic\nstructures that elude conventional feature extractors. We propose a unified,\nmatrix-equivalent framework that reinterprets convolution and attention as\nlinear transforms on flattened inputs, revealing filter weights as basis\nvectors spanning latent feature subspaces. To infuse spectral priors we apply\nelementwise $\\sin(\\cdot)$ mappings to each weight matrix. Embedding these\ntransforms into CNN, ViT and Capsule architectures yields Sin-Basis Networks\nwith heightened sensitivity to periodic motifs and built-in invariance to\nspatial shifts. Experiments on a diverse collection of wave-like image\ndatasets-including 80,000 synthetic attosecond streaking spectrograms,\nthousands of Raman, photoluminescence and FTIR spectra, mel-spectrograms from\nAudioSet and cycle-pattern frames from Kinetics-demonstrate substantial gains\nin reconstruction accuracy, translational robustness and zero-shot cross-domain\ntransfer. Theoretical analysis via matrix isomorphism and Mercer-kernel\ntruncation quantifies how sinusoidal reparametrization enriches expressivity\nwhile preserving stability in data-scarce regimes. Sin-Basis Networks thus\noffer a lightweight, physics-informed approach to deep learning across all\nwave-form imaging modalities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.06275v2", "cate": "cs.LG", "date": "2025-05-06", "updated": "2025-07-31", "AI": {"title_translation": "SinBasis 网络：波状光学光谱的矩阵等效特征提取", "tldr": "SinBasis Networks 提出了一种统一的矩阵等效框架，通过对权重矩阵应用正弦映射来改进卷积和注意力机制，从而有效提取波状图像中的谐波结构，并在多种波形图像数据集上表现出显著的性能提升。", "motivation": "传统的特征提取器难以有效处理波状图像（如飞秒条纹光谱、光学光谱、音频梅尔频谱和周期性视频帧）中编码的关键谐波结构。", "method": "提出了一种统一的矩阵等效框架，将卷积和注意力重新解释为对扁平化输入的线性变换，并将滤波器权重视为跨越潜在特征子空间的基向量。为了注入频谱先验知识，对每个权重矩阵应用逐元素正弦函数映射。将这些变换嵌入到CNN、ViT和Capsule架构中，形成了Sin-Basis Networks。", "result": "在包括80,000个合成飞秒条纹光谱、数千个拉曼、光致发光和FTIR光谱、AudioSet的梅尔频谱以及Kinetics的循环模式帧等多种波状图像数据集上的实验表明，在重建精度、平移鲁棒性和零样本跨域迁移方面取得了显著提升。理论分析通过矩阵同构和Mercer核截断量化了正弦重参数化如何在数据稀缺的情况下丰富表达能力同时保持稳定性。", "conclusion": "Sin-Basis Networks 为所有波形成像模态的深度学习提供了一种轻量级、物理信息化的方法。", "translation": "波状图像——从飞秒条纹光谱到光学光谱、音频梅尔频谱和周期性视频帧——编码了传统特征提取器难以捕捉的关键谐波结构。我们提出了一种统一的、矩阵等效的框架，将卷积和注意力重新解释为对扁平化输入的线性变换，揭示了滤波器权重是跨越潜在特征子空间的基向量。为了注入频谱先验知识，我们对每个权重矩阵应用逐元素 $\\sin(\\cdot)$ 映射。将这些变换嵌入到CNN、ViT和Capsule架构中，形成了Sin-Basis Networks，这些网络对周期性图案具有更高的敏感性，并内置了空间位移不变性。在各种波状图像数据集上进行的实验——包括80,000个合成飞秒条纹光谱、数千个拉曼、光致发光和FTIR光谱、AudioSet的梅尔频谱以及Kinetics的循环模式帧——证明了在重建精度、平移鲁棒性和零样本跨域迁移方面的显著增益。通过矩阵同构和Mercer核截断进行的理论分析量化了正弦重参数化如何在数据稀缺的情况下丰富表达能力同时保持稳定性。因此，Sin-Basis Networks 为所有波形成像模态的深度学习提供了一种轻量级、物理信息化的方法。", "summary": "本文提出了SinBasis Networks，一个统一的矩阵等效框架，用于高效提取波状图像中的谐波结构。该方法将卷积和注意力视为线性变换，并通过对权重矩阵应用正弦映射来注入频谱先验知识。将此框架嵌入到现有深度学习架构中，SinBasis Networks 在多种波形图像数据集上展现出在重建精度、平移鲁棒性和跨域迁移方面的显著性能提升，为波形成像模态的深度学习提供了一种轻量级且物理信息化的新方法。", "keywords": "波状图像, 特征提取, 正弦网络, 矩阵等效, 深度学习", "comments": "这项工作创新性地将正弦函数引入深度学习网络的权重矩阵中，为波状数据处理提供了一种物理信息化的方法。通过将卷积和注意力重新解释为线性变换，并注入频谱先验知识，该方法提高了模型对周期性图案的敏感性，并增强了平移不变性，对于处理各种波形数据具有重要意义。其轻量级和在数据稀缺情况下的稳定性也增加了其实用价值。"}}
{"id": "2507.23544", "title": "User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals", "authors": ["Ryo Miyoshi", "Yuki Okafuji", "Takuya Iwamoto", "Junya Nakanishi", "Jun Baba"], "categories": ["cs.RO", "cs.CV", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for presentation at IEEE/RSJ International Conference on Intelligent Robots and Systems 2025 (IROS 2025)", "url": "http://arxiv.org/abs/2507.23544v1", "summary": "In recent years, the demand for social robots has grown, requiring them to\nadapt their behaviors based on users' states. Accurately assessing user\nexperience (UX) in human-robot interaction (HRI) is crucial for achieving this\nadaptability. UX is a multi-faceted measure encompassing aspects such as\nsentiment and engagement, yet existing methods often focus on these\nindividually. This study proposes a UX estimation method for HRI by leveraging\nmultimodal social signals. We construct a UX dataset and develop a\nTransformer-based model that utilizes facial expressions and voice for\nestimation. Unlike conventional models that rely on momentary observations, our\napproach captures both short- and long-term interaction patterns using a\nmulti-instance learning framework. This enables the model to capture temporal\ndynamics in UX, providing a more holistic representation. Experimental results\ndemonstrate that our method outperforms third-party human evaluators in UX\nestimation.", "comment": "This paper has been accepted for presentation at IEEE/RSJ\n  International Conference on Intelligent Robots and Systems 2025 (IROS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23544v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "人机交互中多模态社交信号的多实例学习用户体验估计", "tldr": "该研究提出了一种基于多模态社交信号和多实例学习的Transformer模型，用于人机交互中的用户体验（UX）估计，其表现优于第三方人工评估员。", "motivation": "社交机器人需求增长，需要根据用户状态调整行为。准确评估人机交互（HRI）中的用户体验（UX）对于实现这种适应性至关重要。然而，现有方法通常单独关注UX的某个方面（如情感或参与度），无法提供全面的衡量。", "method": "本研究提出了一种利用多模态社交信号进行HRI中UX估计的方法。构建了一个UX数据集，并开发了一个基于Transformer的模型，该模型利用面部表情和声音进行估计。与依赖瞬时观察的传统模型不同，该方法使用多实例学习框架捕获短期和长期交互模式，从而能够捕获UX中的时间动态，提供更全面的表示。", "result": "实验结果表明，该方法在UX估计方面优于第三方人工评估员。", "conclusion": "该研究提出的基于多模态社交信号和多实例学习的Transformer模型，能够有效且准确地估计人机交互中的用户体验，其性能超越了人类评估员。", "translation": "近年来，社交机器人的需求不断增长，要求它们根据用户状态调整行为。在人机交互（HRI）中准确评估用户体验（UX）对于实现这种适应性至关重要。UX是一个多方面的衡量标准，包括情感和参与度等方面，但现有方法通常单独关注这些方面。本研究提出了一种通过利用多模态社交信号进行HRI中UX估计的方法。我们构建了一个UX数据集，并开发了一个基于Transformer的模型，该模型利用面部表情和声音进行估计。与依赖瞬时观察的传统模型不同，我们的方法使用多实例学习框架捕获短期和长期交互模式。这使得模型能够捕获UX中的时间动态，提供更全面的表示。实验结果表明，我们的方法在UX估计方面优于第三方人工评估员。", "summary": "本论文针对社交机器人适应性行为对准确用户体验（UX）评估的需求，提出了一种新颖的人机交互（HRI）UX估计方法。该方法利用多模态社交信号（面部表情和声音），并构建了一个基于Transformer的模型。核心创新在于采用多实例学习框架，使其能够捕获短期和长期交互模式以及UX的时间动态，从而提供更全面的表示。实验证明，该方法在UX估计方面优于人类评估员。", "keywords": "用户体验, 人机交互, 多模态社交信号, 多实例学习, Transformer", "comments": "该论文通过结合多模态社交信号和多实例学习，解决了现有UX评估方法在捕获时间动态和全面性方面的局限性。引入Transformer模型处理多模态数据是其创新点之一。超越人类评估员的性能显著提升了该方法的实用价值，为开发更具适应性的社交机器人奠定了基础。"}}
{"id": "2507.23242", "title": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "authors": ["Sungguk Cha", "DongWook Kim", "Taeseung Hahn", "Mintae Kim", "Youngsub Han", "Byoung-Ki Jeon"], "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23242v1", "summary": "Retrieval-Augmented Generation (RAG) systems rely heavily on effective query\nformulation to unlock external knowledge, yet optimizing queries for diverse,\nunstructured real-world documents remains a challenge. We introduce\n\\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query\nrewriting that eliminates the need for human-annotated datasets and extends\napplicability to both text-only and multi-modal databases. By synthesizing\nscenario-question pairs and leveraging Generalized Reward Policy Optimization\n(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing\nretrieval performance across varied domains. Experiments on industrial in-house\ndata demonstrate significant improvements, with\n$\\text{RL-QR}_{\\text{multi-modal}}$ achieving an 11\\% relative gain in NDCG@3\nfor multi-modal RAG and $\\text{RL-QR}_{\\text{lexical}}$ yielding a 9\\% gain for\nlexical retrievers. However, challenges persist with semantic and hybrid\nretrievers, where rewriters failed to improve performance, likely due to\ntraining misalignments. Our findings highlight RL-QR's potential to\nrevolutionize query optimization for RAG systems, offering a scalable,\nannotation-free solution for real-world retrieval tasks, while identifying\navenues for further refinement in semantic retrieval contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23242v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "用于非结构化真实世界文档的检索器特定查询重写器的通用强化学习", "tldr": "RL-QR是一个基于强化学习的查询重写框架，无需人工标注数据，通过合成情景-问题对和GRPO训练检索器特定的重写器，显著提升了多模态和词汇检索器的性能，但在语义和混合检索器上仍面临挑战。", "motivation": "RAG系统严重依赖有效的查询制定来获取外部知识，但针对多样化、非结构化的真实世界文档优化查询仍然是一个挑战。", "method": "引入了RL-QR，一个用于检索器特定查询重写器的强化学习框架。该框架通过合成情景-问题对，并利用通用奖励策略优化（GRPO）来训练查询重写器，使其适应特定的检索器，从而消除了对人工标注数据集的需求，并扩展了对文本和多模态数据库的适用性。", "result": "在工业内部数据上的实验表明，RL-QR取得了显著改进，其中RL-QR_multi-modal在多模态RAG中实现了NDCG@3的11%相对增益，RL-QR_lexical在词汇检索器中实现了9%的增益。然而，在语义和混合检索器上仍存在挑战，重写器未能改善性能，这可能是由于训练错位造成的。", "conclusion": "RL-QR有潜力彻底改变RAG系统的查询优化，为真实世界的检索任务提供一个可扩展、无需标注的解决方案，同时也指明了在语义检索环境中进一步完善的方向。", "translation": "检索增强生成（RAG）系统严重依赖有效的查询制定来解锁外部知识，然而，针对多样化、非结构化的真实世界文档优化查询仍然是一个挑战。我们引入了\\textbf{RL-QR}，一个用于检索器特定查询重写器的强化学习框架，它消除了对人工标注数据集的需求，并将适用性扩展到纯文本和多模态数据库。通过合成情景-问题对并利用通用奖励策略优化（GRPO），RL-QR训练出针对特定检索器量身定制的查询重写器，从而提高了跨不同领域的检索性能。在工业内部数据上的实验表明，RL-QR取得了显著改进，其中$\\text{RL-QR}_{\\text{multi-modal}}$在多模态RAG中实现了NDCG@3的11%相对增益，而$\\text{RL-QR}_{\\text{lexical}}$在词汇检索器中实现了9%的增益。然而，在语义和混合检索器上仍存在挑战，重写器未能改善性能，这可能是由于训练错位造成的。我们的研究结果强调了RL-QR在革新RAG系统查询优化方面的潜力，为真实世界检索任务提供了一个可扩展、无需标注的解决方案，同时也指明了在语义检索环境中进一步完善的方向。", "summary": "本研究提出RL-QR，一个基于强化学习的查询重写框架，旨在解决RAG系统在非结构化真实世界文档中查询优化的难题。RL-QR通过合成数据和GRPO训练检索器特定的重写器，无需人工标注。实验表明，RL-QR显著提升了多模态和词汇检索器的性能，但对语义和混合检索器的改进有限，揭示了未来优化的方向。该框架为RAG系统的查询优化提供了一种可扩展、无标注的解决方案。", "keywords": "强化学习, 查询重写, RAG系统, 检索增强生成, 无监督学习", "comments": "RL-QR的创新之处在于其无需人工标注数据集的强化学习方法，这大大降低了RAG系统查询优化的成本和复杂性，使其更适用于真实世界的多样化场景。通过合成数据和GRPO，该方法有效地为特定检索器定制查询重写器，在多模态和词汇检索方面取得了显著进展。然而，其在语义和混合检索器上的局限性也指出了未来研究的重要方向，即如何更好地对齐训练目标与这些复杂检索器的行为。"}}
{"id": "2507.23058", "title": "Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation", "authors": ["Alexandru Buburuzan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      A dissertation submitted to The University of Manchester for the degree of Bachelor of Science in Artificial Intelligence", "url": "http://arxiv.org/abs/2507.23058v1", "summary": "Safety-critical applications, such as autonomous driving and medical image\nanalysis, require extensive multimodal data for rigorous testing. Synthetic\ndata methods are gaining prominence due to the cost and complexity of gathering\nreal-world data, but they demand a high degree of realism and controllability\nto be useful. This work introduces two novel methods for synthetic data\ngeneration in autonomous driving and medical image analysis, namely MObI and\nAnydoorMed, respectively. MObI is a first-of-its-kind framework for Multimodal\nObject Inpainting that leverages a diffusion model to produce realistic and\ncontrollable object inpaintings across perceptual modalities, demonstrated\nsimultaneously for camera and lidar. Given a single reference RGB image, MObI\nenables seamless object insertion into existing multimodal scenes at a\nspecified 3D location, guided by a bounding box, while maintaining semantic\nconsistency and multimodal coherence. Unlike traditional inpainting methods\nthat rely solely on edit masks, this approach uses 3D bounding box conditioning\nto ensure accurate spatial positioning and realistic scaling. AnydoorMed\nextends this paradigm to the medical imaging domain, focusing on\nreference-guided inpainting for mammography scans. It leverages a\ndiffusion-based model to inpaint anomalies with impressive detail preservation,\nmaintaining the reference anomaly's structural integrity while semantically\nblending it with the surrounding tissue. Together, these methods demonstrate\nthat foundation models for reference-guided inpainting in natural images can be\nreadily adapted to diverse perceptual modalities, paving the way for the next\ngeneration of systems capable of constructing highly realistic, controllable\nand multimodal counterfactual scenarios.", "comment": "A dissertation submitted to The University of Manchester for the\n  degree of Bachelor of Science in Artificial Intelligence", "pdf_url": "http://arxiv.org/pdf/2507.23058v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "参考文献引导的扩散修复用于多模态反事实生成", "tldr": "本文提出了MObI和AnydoorMed两种新方法，利用扩散模型进行参考引导的图像修复，以生成用于自动驾驶和医学图像分析的高度逼真且可控的多模态合成数据。", "motivation": "安全关键应用（如自动驾驶和医学图像分析）需要大量多模态数据进行严格测试。由于收集真实世界数据的成本和复杂性，合成数据方法日益重要，但它们需要高度的真实性和可控性才能发挥作用。", "method": "本文介绍了两种新颖的合成数据生成方法：1. MObI (Multimodal Object Inpainting)：首个多模态物体修复框架，它利用扩散模型在感知模态（相机和激光雷达）上生成逼真且可控的物体修复。通过单一参考RGB图像，MObI能够在指定3D位置、由边界框引导下将物体无缝插入现有多模态场景，同时保持语义一致性和多模态连贯性，并使用3D边界框条件确保准确的空间定位和真实比例。2. AnydoorMed：将MObI范式扩展到医学成像领域（乳腺X线摄影扫描的参考引导修复），它利用基于扩散的模型修复异常，保持参考异常的结构完整性并与周围组织语义融合，实现出色的细节保留。", "result": "MObI成功地同时为相机和激光雷达模态进行了物体修复；AnydoorMed在医学图像中以出色的细节保留修复了异常。这些方法展示了自然图像中参考引导修复的基础模型可以很容易地适应不同的感知模态。", "conclusion": "这些方法共同证明，用于自然图像的参考引导修复的基础模型可以很容易地适应各种感知模态，为构建高度逼真、可控的多模态反事实场景的下一代系统铺平了道路。", "translation": "安全关键应用，例如自动驾驶和医学图像分析，需要大量的多模态数据进行严格测试。由于收集真实世界数据的成本和复杂性，合成数据方法日益受到重视，但它们需要高度的真实性和可控性才能发挥作用。这项工作介绍了两种用于自动驾驶和医学图像分析的合成数据生成新方法，即MObI和AnydoorMed。MObI是一个开创性的多模态物体修复框架，它利用扩散模型在感知模态（同时在相机和激光雷达上演示）中生成逼真且可控的物体修复。给定一个单一的参考RGB图像，MObI能够在指定3D位置、由边界框引导下，将物体无缝插入现有的多模态场景中，同时保持语义一致性和多模态连贯性。与仅依赖编辑掩码的传统修复方法不同，这种方法使用3D边界框条件来确保准确的空间定位和真实的比例。AnydoorMed将此范式扩展到医学成像领域，专注于乳腺X线摄影扫描的参考引导修复。它利用基于扩散的模型修复异常，具有令人印象深刻的细节保留能力，同时保持参考异常的结构完整性并与周围组织语义融合。总而言之，这些方法表明，用于自然图像的参考引导修复的基础模型可以很容易地适应各种感知模态，为构建高度逼真、可控的多模态反事实场景的下一代系统铺平了道路。", "summary": "本文介绍了MObI和AnydoorMed两种基于扩散模型的参考引导修复方法，旨在为自动驾驶和医学图像分析生成高质量的合成多模态数据。MObI是首个多模态物体修复框架，能在相机和激光雷达数据中，通过3D边界框引导，将参考物体无缝插入现有场景，确保空间准确性和多模态一致性。AnydoorMed则将此技术应用于医学图像，实现异常的细节保留修复。这些方法验证了参考引导修复模型在不同感知模态间的普适性，为构建逼真、可控的多模态反事实场景提供了新途径。", "keywords": "扩散修复, 多模态合成数据, 反事实生成, 自动驾驶, 医学图像分析", "comments": "这篇论文的创新点在于提出了两种新颖的、基于扩散模型的参考引导修复方法，特别是在多模态数据生成（相机和激光雷达）以及引入3D边界框作为条件进行精确空间定位方面。它解决了合成数据在安全关键应用中对真实性和可控性的高要求，并成功将该范式扩展到医学影像领域。这种方法为构建高度逼真和可控的多模态反事实场景开辟了新的可能性，对自动驾驶和医疗诊断等领域具有重要意义。"}}
{"id": "2407.05028", "title": "Testing Compositionality", "authors": ["Gijs van Cuyck", "Lars van Arragon", "Jan Tretmans"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This is a preprint of an extended version of this https URL Formal Aspects of Component Software. FACS 2024. Lecture Notes in Computer Science, vol 15189. pp 39-56. This extended version adds new sections about combining the different introduced algorithms and how to apply them in practice, as well as several new examples in earlier sections", "url": "http://arxiv.org/abs/2407.05028v3", "summary": "Compositionality supports the manipulation of large systems by working on\ntheir components. For model-based testing, this means that large systems can be\ntested by modelling and testing their components: passing tests for all\ncomponents implies passing tests for the whole system. In previous work, we\ndefined mutual acceptance for specification models and proved that this\nproperty is a sufficient condition for compositionality in model-based testing.\nIn this paper, we present three main algorithms for using mutual acceptance in\npractice. First, we can verify mutual acceptance on specifications, proving\ncompositionality for all valid implementations. Second, we give a sound and\nexhaustive model-based testing procedure which checks mutual acceptance on a\nspecific black-box implementation. The result is that testing the correctness\nof large systems can be decomposed into testing the component implementations\nfor uioco conformance to their specifications, and testing for environmental\nconformance to the specifications of their environment. Finally, we optimise\nthis procedure further by utilizing the constraints imposed by multiple\nspecifications at the same time. These three algorithms together allow picking\nthe most suitable approach for a given situation, trading in more generalizable\nresults for faster runtime by optimising for a specific context as desired.", "comment": "This is a preprint of an extended version of\n  https://doi.org/10.1007/978-3-031-71261-6_3 Formal Aspects of Component\n  Software. FACS 2024. Lecture Notes in Computer Science, vol 15189. pp 39-56.\n  This extended version adds new sections about combining the different\n  introduced algorithms and how to apply them in practice, as well as several\n  new examples in earlier sections", "pdf_url": "http://arxiv.org/pdf/2407.05028v3", "cate": "cs.SE", "date": "2024-07-06", "updated": "2025-07-31", "AI": {"title_translation": "测试组合性", "tldr": "本文提出了三种算法，用于在实践中应用“相互接受性”属性，以实现基于模型的测试中的组合性，从而有效测试大型系统。", "motivation": "组合性通过组件化操作支持大型系统的管理。对于基于模型的测试，这意味着大型系统可以通过建模和测试其组件来测试。之前的工作定义了“相互接受性”作为基于模型测试中组合性的充分条件，但缺少实际应用方法。", "method": "本文提出了三种主要算法来实践中使用“相互接受性”：1. 验证规范上的“相互接受性”，证明所有有效实现的组合性。2. 提供一个健全且详尽的基于模型的测试程序，用于检查特定黑盒实现上的“相互接受性”，将大型系统测试分解为组件实现对uioco规范的一致性测试和环境对环境规范的一致性测试。3. 通过同时利用多个规范施加的约束来进一步优化上述过程。", "result": "这三种算法使得在实践中应用“相互接受性”成为可能。特别是，第二种算法可以将大型系统的正确性测试分解为组件实现与其规范的uioco一致性测试，以及环境与其环境规范的一致性测试。第三种算法进一步优化了测试过程。", "conclusion": "这三种算法共同允许根据具体情况选择最合适的方法，通过针对特定上下文进行优化，在更通用化的结果和更快的运行时间之间进行权衡。", "translation": "组合性通过对其组件进行操作来支持大型系统的操作。对于基于模型的测试，这意味着大型系统可以通过对其组件进行建模和测试来测试：所有组件的测试通过意味着整个系统的测试通过。在之前的工作中，我们定义了规范模型的相互接受性，并证明该属性是基于模型测试中组合性的充分条件。在本文中，我们提出了三种在实践中使用相互接受性的主要算法。首先，我们可以在规范上验证相互接受性，证明所有有效实现的组合性。其次，我们提供了一个健全且详尽的基于模型的测试程序，用于检查特定黑盒实现上的相互接受性。结果是，大型系统的正确性测试可以分解为：测试组件实现是否符合其uioco规范，以及测试环境是否符合其环境规范。最后，我们通过同时利用多个规范施加的约束来进一步优化此过程。这三种算法共同允许根据给定情况选择最合适的方法，通过针对特定上下文进行优化，在更通用化的结果和更快的运行时间之间进行权衡。", "summary": "本文针对基于模型的测试中的组合性问题，提出了三种实用的算法来应用“相互接受性”属性。这些算法允许在规范层面验证组合性，对具体黑盒实现进行分解测试，并通过多规范约束进行优化。这使得大型系统的测试能够通过组件化方式高效进行，并为不同场景提供了灵活的测试策略。", "keywords": "组合性, 基于模型的测试, 相互接受性, 测试算法, 系统分解", "comments": "本文的创新点在于将之前定义的“相互接受性”这一理论属性，通过具体算法转化为基于模型测试中组合性测试的实用工具。这对于大型复杂系统的测试分解和效率提升具有重要意义。通过提供多种算法，论文考虑了实际应用中对通用性和效率的不同需求，增加了方法的灵活性和实用性。"}}
{"id": "2505.02851", "title": "Leveraging LLMs to Create Content Corpora for Niche Domains", "authors": ["Franklin Zhang", "Sonya Zhang", "Alon Halevy"], "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; H.3.1; H.3.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages (main content), 5 figures. Supplementary materials can be found at this https URL", "url": "http://arxiv.org/abs/2505.02851v2", "summary": "Constructing specialized content corpora from vast, unstructured web sources\nfor domain-specific applications poses substantial data curation challenges. In\nthis paper, we introduce a streamlined approach for generating high-quality,\ndomain-specific corpora by efficiently acquiring, filtering, structuring, and\ncleaning web-based data. We showcase how Large Language Models (LLMs) can be\nleveraged to address complex data curation at scale, and propose a strategical\nframework incorporating LLM-enhanced techniques for structured content\nextraction and semantic deduplication. We validate our approach in the behavior\neducation domain through its integration into 30 Day Me, a habit formation\napplication. Our data pipeline, named 30DayGen, enabled the extraction and\nsynthesis of 3,531 unique 30-day challenges from over 15K webpages. A user\nsurvey reports a satisfaction score of 4.3 out of 5, with 91% of respondents\nindicating willingness to use the curated content for their habit-formation\ngoals.", "comment": "9 pages (main content), 5 figures. Supplementary materials can be\n  found at https://github.com/pigfyy/30DayGen-Supplementary-Materials", "pdf_url": "http://arxiv.org/pdf/2505.02851v2", "cate": "cs.CL", "date": "2025-05-02", "updated": "2025-07-31", "AI": {"title_translation": "利用大型语言模型为小众领域创建内容语料库", "tldr": "本文提出了一种利用大型语言模型（LLMs）为特定领域高效生成高质量内容语料库的简化方法，并在行为教育领域进行了验证。", "motivation": "为领域特定应用从大量非结构化网络资源中构建专业内容语料库面临着巨大的数据整理挑战。", "method": "本文引入了一种简化的方法，通过高效获取、过滤、结构化和清理网络数据来生成高质量、领域特定的语料库。该方法利用大型语言模型（LLMs）处理大规模复杂数据整理，并提出了一个结合LLM增强技术的策略框架，用于结构化内容提取和语义去重。数据管道名为30DayGen。", "result": "在行为教育领域，该方法被整合到习惯养成应用30 Day Me中。数据管道30DayGen成功从超过1.5万个网页中提取并合成了3,531个独特的30天挑战。用户调查报告满意度为4.3/5分，91%的受访者表示愿意使用整理后的内容来实现其习惯养成目标。", "conclusion": "该研究成功地展示了利用大型语言模型可以有效地解决小众领域内容语料库构建中的数据整理挑战，并获得了用户的高度满意度，证明了其在实际应用中的有效性和前景。", "translation": "从大量非结构化网络资源中构建领域特定应用所需的专业内容语料库面临着巨大的数据整理挑战。本文介绍了一种简化的方法，通过高效获取、过滤、结构化和清理网络数据来生成高质量、领域特定的语料库。我们展示了如何利用大型语言模型（LLMs）来大规模解决复杂的数据整理问题，并提出了一个结合LLM增强技术的策略框架，用于结构化内容提取和语义去重。我们在行为教育领域通过将其整合到习惯养成应用30 Day Me中来验证我们的方法。我们的数据管道名为30DayGen，能够从超过1.5万个网页中提取并合成了3,531个独特的30天挑战。用户调查报告满意度为4.3分（满分5分），91%的受访者表示愿意使用整理后的内容来实现其习惯养成目标。", "summary": "本文提出了一种利用大型语言模型（LLMs）为小众领域高效创建内容语料库的简化方法。该方法通过LLM增强的获取、过滤、结构化和去重技术，解决了从非结构化网络数据中构建领域特定语料库的数据整理挑战。在行为教育领域的习惯养成应用中，该方法成功提取并合成了数千个独特的挑战，用户满意度高，证明了LLMs在自动化数据整理和内容生成方面的潜力。", "keywords": "大型语言模型, 内容语料库, 小众领域, 数据整理, 习惯养成", "comments": "该论文的创新之处在于利用大型语言模型来自动化和简化小众领域内容语料库的构建过程，特别是在数据整理和语义去重方面。其重要性体现在为特定应用（如习惯养成）提供了高质量、结构化的内容，并得到了用户满意度的高分验证，展示了LLMs在实际数据工程和内容生成任务中的强大应用潜力。"}}
{"id": "2507.17170", "title": "Advancing Quantum State Preparation Using Decision Diagram with Local Invertible Maps", "authors": ["Xin Hong", "Aochu Dai", "Chenjian Li", "Sanjiang Li", "Shenggang Ying", "Mingsheng Ying"], "categories": ["cs.DS", "quant-ph"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2507.14496", "url": "http://arxiv.org/abs/2507.17170v2", "summary": "Quantum state preparation (QSP) is a fundamental task in quantum computing\nand quantum information processing. It is critical to the execution of many\nquantum algorithms, including those in quantum machine learning. In this paper,\nwe propose a family of efficient QSP algorithms tailored to different numbers\nof available ancilla qubits - ranging from no ancilla qubits, to a single\nancilla qubit, to a sufficiently large number of ancilla qubits. Our approach\nexploits the power of Local Invertible Map Tensor Decision Diagrams (LimTDDs) -\na highly compact representation of quantum states that combines tensor networks\nand decision diagrams to reduce quantum circuit complexity. Extensive\nexperiments demonstrate that our methods significantly outperform existing\napproaches and exhibit better scalability for large-scale quantum states, both\nin terms of runtime and gate complexity. Furthermore, our method shows\nexponential improvement in best-case scenarios.", "comment": "arXiv admin note: text overlap with arXiv:2507.14496", "pdf_url": "http://arxiv.org/pdf/2507.17170v2", "cate": "cs.DS", "date": "2025-07-23", "updated": "2025-07-31", "AI": {"title_translation": "使用局部可逆映射决策图改进量子态制备", "tldr": "本文提出了一种基于局部可逆映射张量决策图（LimTDDs）的量子态制备（QSP）算法家族，该算法在不同辅助量子比特数下均表现出优于现有方法的性能和更好的可扩展性。", "motivation": "量子态制备（QSP）是量子计算和量子信息处理中的一项基本任务，对许多量子算法（包括量子机器学习算法）的执行至关重要。因此，需要更高效的QSP算法。", "method": "本文提出了一种高效的QSP算法家族，该算法针对不同数量的可用辅助量子比特（从无辅助量子比特到单个辅助量子比特，再到足够多的辅助量子比特）进行定制。该方法利用局部可逆映射张量决策图（LimTDDs）的强大功能，LimTDDs是一种结合了张量网络和决策图的高度紧凑的量子态表示形式，旨在降低量子电路复杂性。", "result": "实验结果表明，该方法在运行时和门复杂度方面均显著优于现有方法，并对大规模量子态表现出更好的可扩展性。此外，在最佳情况下，该方法显示出指数级的改进。", "conclusion": "本文提出的基于LimTDDs的QSP算法家族在效率和可扩展性方面显著优于现有方法，为量子态制备提供了一种更优的解决方案。", "translation": "量子态制备（QSP）是量子计算和量子信息处理中的一项基本任务。它对于许多量子算法（包括量子机器学习算法）的执行至关重要。在本文中，我们提出了一系列高效的QSP算法，这些算法针对不同数量的可用辅助量子比特进行了定制——从无辅助量子比特到单个辅助量子比特，再到足够多的辅助量子比特。我们的方法利用了局部可逆映射张量决策图（LimTDDs）的强大功能——这是一种高度紧凑的量子态表示形式，它结合了张量网络和决策图以降低量子电路复杂性。广泛的实验表明，我们的方法在运行时和门复杂度方面均显著优于现有方法，并对大规模量子态表现出更好的可扩展性。此外，我们的方法在最佳情况下显示出指数级的改进。", "summary": "本文介绍了一种利用局部可逆映射张量决策图（LimTDDs）的量子态制备（QSP）算法家族。该算法针对不同数量的辅助量子比特进行了优化，并被证明在运行时和门复杂度方面均显著优于现有方法，对大规模量子态表现出更好的可扩展性，并在最佳情况下实现了指数级改进。", "keywords": "量子态制备, 决策图, 局部可逆映射, 量子计算, 可扩展性", "comments": "该论文通过引入局部可逆映射张量决策图（LimTDDs）来优化量子态制备，在量子计算领域具有重要意义。其创新性在于利用紧凑的量子态表示来降低电路复杂性，并在实验中展示了卓越的性能和可扩展性，特别是在最佳情况下的指数级改进，这表明了其在实际应用中的巨大潜力。"}}
{"id": "2507.23057", "title": "Neural Energy Landscapes Predict Working Memory Decline After Brain Tumor Resection", "authors": ["Triet M. Tran", "Sina Khanmohammadi"], "categories": ["eess.SP", "q-bio.NC"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23057v1", "summary": "Surgical resection is the primary treatment option for brain tumor patients,\nbut it carries the risk of postoperative cognitive dysfunction. This study\ninvestigates how tumor-induced alterations in presurgical neural dynamics\nrelate to postoperative working memory decline. We analyzed functional magnetic\nresonance imaging (fMRI) of brain tumor patients before surgery and extracted\nenergy landscapes of high-order brain interactions. We then examined the\nrelation between these energy features and postoperative working memory\nperformance using statistical and machine learning (random forest) models.\nPatients with lower postoperative working memory scores exhibited fewer but\nmore extreme transitions between local energy minima and maxima, whereas\npatients with higher scores showed more frequent but less extreme shifts.\nFurthermore, the presurgical high-order energy features were able to accurately\npredict postoperative working memory decline with a mean accuracy of 90\\%, F1\nscore of 87.5\\%, and an AUC of 0.95. Our study suggests that the brain\ntumor-induced disruptions in high-order neural dynamics before surgery are\npredictive of postoperative working memory decline. Our findings pave the path\nfor personalized surgical planning and targeted interventions to mitigate\ncognitive risks associated with brain tumor resection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23057v1", "cate": "eess.SP", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "神经能量景观预测脑肿瘤切除术后工作记忆下降", "tldr": "术前神经能量景观可高精度预测脑肿瘤切除术后工作记忆下降。", "motivation": "脑肿瘤切除术后存在认知功能障碍风险。本研究旨在探究肿瘤引起的术前神经动力学改变如何与术后工作记忆下降相关联。", "method": "分析脑肿瘤患者术前fMRI数据，提取高阶脑相互作用的能量景观特征，并使用统计和机器学习（随机森林）模型研究这些能量特征与术后工作记忆表现之间的关系。", "result": "术后工作记忆得分较低的患者表现出更少但更极端的局部能量最小值和最大值之间的转换；而得分较高的患者表现出更频繁但更不极端的转换。此外，术前高阶能量特征能够以90%的平均准确率、87.5%的F1分数和0.95的AUC准确预测术后工作记忆下降。", "conclusion": "脑肿瘤引起的术前高阶神经动力学紊乱可预测术后工作记忆下降。这些发现为个性化手术规划和靶向干预提供了途径，以减轻脑肿瘤切除相关的认知风险。", "translation": "标题：神经能量景观预测脑肿瘤切除术后工作记忆下降\n摘要：手术切除是脑肿瘤患者的主要治疗选择，但存在术后认知功能障碍的风险。本研究旨在调查肿瘤引起的术前神经动力学改变如何与术后工作记忆下降相关联。我们分析了脑肿瘤患者术前的功能性磁共振成像（fMRI）数据，并提取了高阶脑相互作用的能量景观。然后，我们使用统计和机器学习（随机森林）模型检查了这些能量特征与术后工作记忆表现之间的关系。术后工作记忆得分较低的患者表现出更少但更极端的局部能量最小值和最大值之间的转换，而得分较高的患者表现出更频繁但更不极端的转换。此外，术前高阶能量特征能够以90%的平均准确率、87.5%的F1分数和0.95的AUC准确预测术后工作记忆下降。我们的研究表明，脑肿瘤引起的术前高阶神经动力学紊乱可预测术后工作记忆下降。我们的发现为个性化手术规划和靶向干预提供了途径，以减轻与脑肿瘤切除相关的认知风险。", "summary": "本研究探讨了脑肿瘤患者术前神经动力学改变与术后工作记忆下降之间的关系。通过分析术前fMRI数据并提取高阶脑相互作用的能量景观特征，研究发现术前能量特征能够高精度预测术后工作记忆下降。具体而言，工作记忆下降的患者表现出更少但更极端的能量转换。这些发现为预测术后认知风险和制定个性化治疗方案提供了新的见解。", "keywords": "神经能量景观, 工作记忆, 脑肿瘤, 术后认知功能, fMRI", "comments": "本研究的创新之处在于利用神经能量景观这一新颖的分析方法来预测脑肿瘤术后认知功能障碍，特别是工作记忆下降。其重要性在于提供了一个高精度的预测模型，有助于实现个性化手术规划和早期干预，从而减轻患者的认知风险。这对于提高脑肿瘤患者的生活质量具有重要意义。"}}
{"id": "2401.13639", "title": "Winding Clearness for Differentiable Point Cloud Optimization", "authors": ["Dong Xiao", "Yueji Ma", "Zuoqiang Shi", "Shiqing Xin", "Wenping Wang", "Bailin Deng", "Bin Wang"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by Computer-Aided Design through SPM 2025", "url": "http://arxiv.org/abs/2401.13639v2", "summary": "We propose to explore the properties of raw point clouds through the\n\\emph{winding clearness}, a concept we first introduce for measuring the\nclarity of the interior/exterior relationships represented by the winding\nnumber field of the point cloud. In geometric modeling, the winding number is a\npowerful tool for distinguishing the interior and exterior of a given surface\n$\\partial \\Omega$, and it has been previously used for point normal orientation\nand surface reconstruction. In this work, we introduce a novel approach to\nevaluate and optimize the quality of point clouds based on the winding\nclearness. We observe that point clouds with less noise generally exhibit\nbetter winding clearness. Accordingly, we propose an objective function that\nquantifies the error in winding clearness, solely utilizing the coordinates of\nthe point clouds. Moreover, we demonstrate that the winding clearness error is\ndifferentiable and can serve as a loss function in point cloud processing. We\npresent this observation from two aspects: 1) We update the coordinates of the\npoints by back-propagating the loss function for individual point clouds,\nresulting in an overall improvement without involving a neural network. 2) We\nincorporate winding clearness as a geometric constraint in the diffusion-based\n3D generative model and update the network parameters to generate point clouds\nwith less noise. Experimental results demonstrate the effectiveness of\noptimizing the winding clearness in enhancing the point cloud quality. Notably,\nour method exhibits superior performance in handling noisy point clouds with\nthin structures, highlighting the benefits of the global perspective enabled by\nthe winding number.", "comment": "Accepted by Computer-Aided Design through SPM 2025", "pdf_url": "http://arxiv.org/pdf/2401.13639v2", "cate": "cs.GR", "date": "2024-01-24", "updated": "2025-07-31", "AI": {"title_translation": "可微分点云优化的缠绕清晰度", "tldr": "该论文引入了“缠绕清晰度”概念，用于衡量点云质量，并将其作为可微分损失函数进行优化，有效提升了噪声点云，尤其是薄结构的质量。", "motivation": "点云质量受噪声影响较大，现有方法可能难以有效评估和优化。本研究旨在引入一个新概念——“缠绕清晰度”，来量化点云内部/外部关系的清晰度，并以此为基础提出一种新方法来评估和优化点云质量，特别是处理噪声点云的问题。", "method": "本研究提出了“缠绕清晰度”的概念，用于衡量点云内部/外部关系的清晰度，基于缠绕数场。作者提出了一个仅利用点云坐标来量化缠绕清晰度误差的目标函数，并证明其可微分，可作为点云处理中的损失函数。该方法从两个方面应用：1) 通过反向传播损失函数直接更新单个点云的坐标，无需神经网络。2) 将缠绕清晰度作为扩散式3D生成模型中的几何约束，更新网络参数以生成噪声较少的点云。", "result": "实验结果表明，优化缠绕清晰度能有效提高点云质量。该方法在处理具有薄结构的噪声点云方面表现出卓越的性能，突出了缠绕数所实现的全局视角的优势。", "conclusion": "缠绕清晰度是一种有效且可微分的点云质量优化指标，特别适用于处理噪声点云和薄结构，这得益于缠绕数的全局视角。", "translation": "我们将通过“缠绕清晰度”来探索原始点云的特性，这是一个我们首次引入的概念，用于衡量点云缠绕数场表示的内部/外部关系的清晰度。在几何建模中，缠绕数是区分给定表面$\\\\partial \\\\Omega$内部和外部的强大工具，并且之前已被用于点法线方向和表面重建。在这项工作中，我们引入了一种基于缠绕清晰度评估和优化点云质量的新方法。我们观察到噪声较少的点云通常表现出更好的缠绕清晰度。因此，我们提出一个目标函数，仅利用点云的坐标来量化缠绕清晰度误差。此外，我们证明缠绕清晰度误差是可微分的，并且可以作为点云处理中的损失函数。我们从两个方面展示了这一观察结果：1）我们通过反向传播损失函数来更新单个点云的坐标，从而在不涉及神经网络的情况下实现整体改进。2）我们将缠绕清晰度作为扩散式3D生成模型中的几何约束，并更新网络参数以生成噪声较少的点云。实验结果表明，优化缠绕清晰度在提高点云质量方面是有效的。值得注意的是，我们的方法在处理具有薄结构的噪声点云方面表现出卓越的性能，突出了缠绕数所实现的全局视角的优势。", "summary": "该论文引入了“缠绕清晰度”这一新概念，通过缠绕数场衡量点云内部/外部关系的清晰度，以此评估点云质量。研究提出一个基于该概念的可微分目标函数，可用作点云优化的损失函数。该方法既可用于直接更新点云坐标，也可作为生成模型中的几何约束，实验证明其能显著提升点云质量，尤其对于含薄结构的噪声点云效果更佳，体现了缠绕数全局视角的优势。", "keywords": "缠绕清晰度, 点云优化, 可微分损失, 几何约束, 噪声消除", "comments": "该研究的创新之处在于引入了“缠绕清晰度”作为衡量点云质量的新指标，并巧妙地利用了缠绕数的全局特性。其可微分性使其能够直接集成到优化框架中，无论是用于点云的直接细化还是作为生成模型中的约束。这种方法对处理噪声点云和薄结构等挑战性情况特别有效，为几何处理提供了一个有价值的工具，且不完全依赖局部特征。"}}
{"id": "2501.08855", "title": "A simple-to-implement nonlinear preconditioning of Newton's method for solving the steady Navier-Stokes equations", "authors": ["Muhammad Mohebujjaman", "Mengying Xiao", "Cheng Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.08855v2", "summary": "The Newton's method for solving stationary Navier-Stokes equations (NSE) is\nknown to convergent fast, however, may fail due to a bad initial guess. This\nwork presents a simple-to-implement nonlinear preconditioning of Newton's\niteration, that remains the quadratic convergence and enlarges the domain of\nconvergence. The proposed AAPicard-Newton method adds the Anderson accelerated\nPicard step at each iteration of Newton's method for solving NSE, which has\nbeen shown globally stable for the relaxation parameter $\\beta_{k+1}\\equiv1$ in\nthe Anderson acceleration optimization step, convergent quadratically, and\nconverges faster with a smaller convergence rate for large Reynolds number.\nSeveral benchmark numerical tests have been tested and are well-aligned with\nthe theoretical results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.08855v2", "cate": "math.NA", "date": "2025-01-15", "updated": "2025-07-31", "AI": {"title_translation": "一种求解稳态Navier-Stokes方程的牛顿法简单非线性预处理", "tldr": "本文提出了一种简单易行的非线性预处理牛顿法（AAPicard-Newton），用于求解稳态Navier-Stokes方程，该方法保持二次收敛性并扩大了收敛域，且对于大雷诺数具有更快的收敛速度。", "motivation": "牛顿法求解稳态Navier-Stokes方程虽然收敛速度快，但可能因初始猜测不佳而失败。", "method": "本文提出了一种名为AAPicard-Newton的方法，它在牛顿法的每次迭代中加入了Anderson加速的Picard步骤。该方法在Anderson加速优化步骤中，当松弛参数$\beta_{k+1}\\%equiv1$时，被证明是全局稳定的。", "result": "所提出的AAPicard-Newton方法保持了二次收敛性，扩大了收敛域，并且对于大雷诺数，以更小的收敛率收敛得更快。多项基准数值测试结果与理论结果吻合良好。", "conclusion": "AAPicard-Newton方法通过非线性预处理有效地改善了牛顿法求解稳态Navier-Stokes方程的收敛性和鲁棒性。", "translation": "牛顿法求解稳态Navier-Stokes方程（NSE）以其快速收敛而闻名，然而，它可能因初始猜测不佳而失败。本工作提出了一种简单易行的牛顿迭代非线性预处理方法，该方法保持了二次收敛性并扩大了收敛域。所提出的AAPicard-Newton方法在牛顿法求解NSE的每次迭代中增加了Anderson加速的Picard步骤，该方法在Anderson加速优化步骤中，当松弛参数$\beta_{k+1}\\equiv1$时，已被证明是全局稳定的，二次收敛，并且对于大雷诺数以更小的收敛率收敛得更快。多项基准数值测试已经过验证，并与理论结果吻合良好。", "summary": "本文针对牛顿法求解稳态Navier-Stokes方程易受初始猜测影响的问题，提出了一种名为AAPicard-Newton的非线性预处理方法。该方法通过在每次牛顿迭代中引入Anderson加速的Picard步骤，成功地保持了二次收敛性，显著扩大了收敛域，并展现出对于大雷诺数更快的收敛速度。数值实验结果验证了其理论优势。", "keywords": "Navier-Stokes方程, 牛顿法, 非线性预处理, Anderson加速, Picard迭代", "comments": "本文的创新点在于将Anderson加速的Picard步骤融入到牛顿法中，形成了一种新型的非线性预处理方法。这不仅解决了传统牛顿法对初始猜测敏感的问题，而且在保持高效二次收敛的同时，显著增强了方法的鲁棒性。其重要性在于为求解复杂的Navier-Stokes方程提供了一个更稳定、更高效的数值工具，对于计算流体力学领域具有实际应用价值。"}}
{"id": "2410.02630", "title": "Understanding implementation pitfalls of distance-based metrics for image segmentation", "authors": ["Gasper Podobnik", "Tomaz Vrtovec"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.02630v2", "summary": "Distance-based metrics, such as the Hausdorff distance (HD), are widely used\nto validate segmentation performance in (bio)medical imaging. However, their\nimplementation is complex, and critical differences across open-source tools\nremain largely unrecognized by the community. These discrepancies undermine\nbenchmarking efforts, introduce bias in biomarker calculations, and potentially\ndistort medical device development and clinical commissioning. In this study,\nwe systematically dissect 11 open-source tools that implement distance-based\nmetric computation by performing both a conceptual analysis of their\ncomputational steps and an empirical analysis on representative two- and\nthree-dimensional image datasets. Alarmingly, we observed deviations in HD\nexceeding 100 mm and identified multiple statistically significant differences\nbetween tools - demonstrating that statistically significant improvements on\nthe same set of segmentations can be achieved simply by selecting a particular\nimplementation. These findings cast doubts on the validity of prior comparisons\nof results across studies without accounting for the differences in metric\nimplementations. To address this, we provide practical recommendations for tool\nselection; additionally, our conceptual analysis informs about the future\nevolution of implementing open-source tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.02630v2", "cate": "cs.CV", "date": "2024-10-03", "updated": "2025-07-31", "AI": {"title_translation": "理解基于距离的图像分割度量实施陷阱", "tldr": "基于距离的图像分割度量在开源工具中的实现存在显著差异，可能导致基准测试和结果比较的偏差。", "motivation": "基于距离的度量（如Hausdorff距离）在(生物)医学图像分割验证中广泛使用，但其实现复杂，且开源工具间的关键差异未被社区充分认识，这损害了基准测试，引入了生物标志物计算偏差，并可能扭曲医疗设备开发和临床调试。", "method": "本研究系统地剖析了11个实现基于距离度量计算的开源工具，通过对其计算步骤进行概念分析，并在代表性的二维和三维图像数据集上进行实证分析。", "result": "研究发现Hausdorff距离的偏差超过100毫米，并且工具之间存在多个统计学上的显著差异，表明通过简单选择特定实现即可在同一组分割上实现统计学上的显著改进。", "conclusion": "这些发现使人们对先前研究中未经考虑度量实现差异的跨研究结果比较的有效性产生怀疑。为解决此问题，研究提供了工具选择的实用建议，并且概念分析为未来开源工具的实现演进提供了信息。", "translation": "基于距离的度量，例如Hausdorff距离（HD），被广泛用于验证（生物）医学图像中的分割性能。然而，它们的实现是复杂的，并且开源工具之间的关键差异在很大程度上未被社区认识。这些差异破坏了基准测试工作，在生物标志物计算中引入了偏差，并可能扭曲医疗设备的开发和临床调试。在本研究中，我们系统地剖析了11个实现基于距离度量计算的开源工具，通过对其计算步骤进行概念分析和在代表性的二维和三维图像数据集上进行实证分析。令人担忧的是，我们观察到HD的偏差超过100毫米，并识别出工具之间存在多个统计学上的显著差异——这表明，仅仅通过选择特定的实现，就可以在同一组分割上实现统计学上的显著改进。这些发现使人们对先前研究中未经考虑度量实现差异的跨研究结果比较的有效性产生怀疑。为了解决这个问题，我们提供了工具选择的实用建议；此外，我们的概念分析为未来开源工具的实现演进提供了信息。", "summary": "本研究揭示了医学图像分割中基于距离的度量（如Hausdorff距离）在不同开源工具实现上的显著差异和潜在陷阱。通过对11个工具进行概念和实证分析，发现度量结果存在高达100毫米的偏差和统计学上的显著差异，这严重影响了基准测试和结果的有效性。研究强调了在比较跨研究结果时考虑实现差异的重要性，并提供了工具选择的实用建议，以指导未来开源工具的开发。", "keywords": "图像分割, 基于距离度量, Hausdorff距离, 开源工具, 实现差异", "comments": "这篇论文揭示了一个在医学图像分割领域长期存在但未被充分认识的关键问题：度量实现的不一致性。其创新之处在于系统地剖析了不同开源工具的实现差异，并量化了这些差异对结果的巨大影响。这对于确保研究的可重复性和临床应用的准确性至关重要，为社区提供了宝贵的见解和实用建议。"}}
{"id": "2507.22895", "title": "Brain motor intention Extraction Amplifier: Non-invasive brain-muscle interface", "authors": ["Ye Sun", "Bowei Zhao", "Dezhong Yao", "Rui Zhang", "Bohan Zhang", "Xiaoyuan Li", "Jing Wang", "Mingxuan Qu", "Gang Liu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures", "url": "http://arxiv.org/abs/2507.22895v1", "summary": "Brain-computer interfaces (BCIs) enable real-time interaction between the\nbrain and external devices by decoding neural signals. However, existing\nmotor-based BCI paradigms, like motor imagery BCI, face challenges with\nimprecise labeling in real-world use. This mismatch between EEG signals and\ntrue behavioral intentions leads to pseudo-labels, undermining decoding\naccuracy and system robustness. To overcome this bottleneck, this paper first\nproposes a novel motor intention extraction framework based on a non-invasive\nbrain-muscle interface (BMuI)($\\text{BCI} =\n\\frac{\\text{Brain}}{\\text{Computer}} \\text{ Interface} =\n\\frac{\\text{Brain}}{\\not\\text{Muscle}}\\! \\text{ (BMuI)} \\times\n\\!\\frac{\\not\\text{Muscle}}{\\text{Computer}}\\! \\text{ Interface}$). This method\nsimulates the neural pathway from the brain to the muscles in order to capture\nand enhance the weak motor intention signals originating in the brain. It then\nuses EMG as a high-fidelity relay medium to achieve more accurate intention\nrecognition and transmission. To systematically validate the feasibility and\neffectiveness of this approach, we conducted both offline experiments (to\nrepeatedly verify feasibility) and online experiments (to construct a real-time\ninteractive system and evaluate its performance). The results show that BMuI is\nfeasible, achieving a prediction accuracy of 0.8314; in the online experiment,\nall participants are able to successfully control the Unity virtual arm.", "comment": "18 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.22895v1", "cate": "cs.HC", "date": "2025-06-21", "updated": "2025-06-21", "AI": {"title_translation": "脑运动意图提取放大器：非侵入式脑肌接口", "tldr": "提出一种基于非侵入式脑肌接口（BMuI）的新型运动意图提取框架，通过模拟脑到肌肉的神经通路并利用EMG作为高保真中继，解决了现有运动型BCI的伪标签问题，实现了高精度意图识别和虚拟臂控制。", "motivation": "现有基于运动的脑机接口（BCI），如运动想象BCI，在实际使用中面临标签不精确的问题，即脑电图信号与真实行为意图不匹配导致伪标签，从而损害解码精度和系统鲁棒性。", "method": "本文提出了一种基于非侵入式脑肌接口（BMuI）的新型运动意图提取框架。该方法模拟从大脑到肌肉的神经通路，以捕获和增强源自大脑的微弱运动意图信号。然后，利用肌电图（EMG）作为高保真中继介质，实现更准确的意图识别和传输。通过离线实验验证可行性，在线实验构建实时交互系统并评估性能。", "result": "离线实验结果表明BMuI是可行的，预测准确率达到0.8314；在线实验中，所有参与者都能够成功控制Unity虚拟臂。", "conclusion": "本文提出的基于非侵入式脑肌接口（BMuI）的运动意图提取框架是可行且有效的，能够克服现有运动型BCI的局限性，实现高精度运动意图识别和实时控制。", "translation": "脑机接口（BCI）通过解码神经信号实现大脑与外部设备之间的实时交互。然而，现有的基于运动的BCI范式，如运动想象BCI，在实际使用中面临标签不精确的挑战。脑电图信号与真实行为意图之间的这种不匹配导致伪标签，从而损害解码精度和系统鲁棒性。为了克服这一瓶颈，本文首次提出了一种基于非侵入式脑肌接口（BMuI）的新型运动意图提取框架。该方法模拟从大脑到肌肉的神经通路，以捕获和增强源自大脑的微弱运动意图信号。然后，它使用肌电图（EMG）作为高保真中继介质，以实现更准确的意图识别和传输。为了系统地验证该方法的可行性和有效性，我们进行了离线实验（重复验证可行性）和在线实验（构建实时交互系统并评估其性能）。结果表明，BMuI是可行的，预测准确率达到0.8314；在在线实验中，所有参与者都能够成功控制Unity虚拟臂。", "summary": "本文提出了一种名为脑肌接口（BMuI）的非侵入式新型运动意图提取框架，旨在解决现有运动想象BCI中因伪标签导致的解码精度和系统鲁棒性问题。BMuI通过模拟脑到肌肉的神经通路来增强微弱的运动意图信号，并利用EMG作为高保真中继介质进行精确识别和传输。离线实验验证了其可行性，预测准确率达0.8314；在线实验中，所有参与者均成功控制Unity虚拟臂，证明了该方法的有效性。", "keywords": "脑肌接口, 运动意图提取, 非侵入式, 脑机接口, 肌电图", "comments": "这篇论文的创新点在于提出了非侵入式脑肌接口（BMuI）的概念，通过模拟生理神经通路，并利用EMG作为高保真中继，有效解决了传统运动想象BCI中伪标签和解码精度低的痛点。这种方法为更准确、鲁棒的运动意图解码提供了新的途径，对于提升BCI在实际应用中的性能具有重要意义。"}}
{"id": "2507.23073", "title": "Locally Differentially Private Thresholding Bandits", "authors": ["Annalisa Barbara", "Joseph Lazzaro", "Ciara Pike-Burke"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18th European Workshop on Reinforcement Learning (EWRL 2025)", "url": "http://arxiv.org/abs/2507.23073v1", "summary": "This work investigates the impact of ensuring local differential privacy in\nthe thresholding bandit problem. We consider both the fixed budget and fixed\nconfidence settings. We propose methods that utilize private responses,\nobtained through a Bernoulli-based differentially private mechanism, to\nidentify arms with expected rewards exceeding a predefined threshold. We show\nthat this procedure provides strong privacy guarantees and derive theoretical\nperformance bounds on the proposed algorithms. Additionally, we present general\nlower bounds that characterize the additional loss incurred by any\ndifferentially private mechanism, and show that the presented algorithms match\nthese lower bounds up to poly-logarithmic factors. Our results provide valuable\ninsights into privacy-preserving decision-making frameworks in bandit problems.", "comment": "18th European Workshop on Reinforcement Learning (EWRL 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23073v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "局部差分隐私阈值强盗问题", "tldr": "研究局部差分隐私阈值强盗问题，提出提供强隐私保证和匹配下界性能的算法。", "motivation": "研究在阈值强盗问题中确保局部差分隐私的影响。", "method": "提出利用伯努利基差分隐私机制获得的私有响应来识别预期奖励超过预定义阈值臂的方法，并考虑了固定预算和固定置信度设置。", "result": "证明了该过程提供强大的隐私保证，并推导出所提出算法的理论性能界限。此外，提出了表征任何差分隐私机制所造成额外损失的通用下界，并表明所提出的算法在多对数因子内匹配这些下界。", "conclusion": "研究结果为强盗问题中的隐私保护决策框架提供了有价值的见解。", "translation": "这项工作研究了在阈值强盗问题中确保局部差分隐私的影响。我们考虑了固定预算和固定置信度设置。我们提出了利用通过基于伯努利的差分隐私机制获得的私有响应来识别预期奖励超过预定义阈值的臂的方法。我们证明了该过程提供了强大的隐私保证，并推导出了所提出算法的理论性能界限。此外，我们提出了表征任何差分隐私机制所造成的额外损失的通用下界，并表明所提出的算法在多对数因子内匹配这些下界。我们的结果为强盗问题中的隐私保护决策框架提供了有价值的见解。", "summary": "本研究探讨了在阈值强盗问题中实现局部差分隐私的影响。论文提出了基于伯努利机制的私有响应方法，用于识别超过预设奖励阈值的臂。研究证明了所提方法提供强大的隐私保证，并导出了理论性能上界，同时展示了其算法在多对数因子内匹配了差分隐私机制的通用下界，为隐私保护决策框架提供了见解。", "keywords": "局部差分隐私, 阈值强盗, 伯努利机制, 性能界限, 下界", "comments": "该论文通过提出局部差分隐私阈值强盗问题的方法进行了创新，展示了强大的理论保证并匹配了下界，这对于强盗问题中的隐私保护决策至关重要。"}}
{"id": "2507.23756", "title": "Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System", "authors": ["Diana Mortagua"], "categories": ["cs.LG", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23756v1", "summary": "This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23756v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "在主动学习中利用情绪和疲劳感知的推荐系统改进标注者选择", "tldr": "本研究提出了一种情绪和疲劳感知的推荐系统，用于主动学习中的标注者选择，旨在减少标注错误和模型不确定性。", "motivation": "主动学习在获取标注数据时面临成本和时间挑战，需要减少标注错误以提高效率并更快达到预期准确性。现有的大多数查询-标注者配对策略未考虑影响生产力的内部因素，如情绪、注意力和疲劳水平。本研究旨在弥补这一空白，通过考虑内部因素来优化标注者选择，从而最大限度地减少错误分类。", "method": "本研究提出了一种新的查询-标注者配对策略，采用基于知识的推荐系统（RS）。该推荐系统通过评估标注者过去的准确度、情绪和疲劳水平以及查询实例的信息来对可用的标注者进行排名，从而选择一个或多个标注者来标注查询实例。该方法基于现有关于情绪和疲劳对人类表现影响的文献，以现实方式模拟标注者，并利用推荐系统预测其表现。", "result": "结果表明，与不使用内部因素的方法相比，考虑标注者过去的准确度以及情绪和疲劳水平可以减少标注者产生的标注错误数量，并降低模型在训练过程中的不确定性。尽管提升不如上述显著，但所提出的方法在准确度和F1分数上也表现更好。", "conclusion": "本研究提出的方法和发现开始探索人类认知因素影响主动学习这一开放性挑战，并证明了考虑标注者情绪和疲劳水平可以有效减少标注错误和模型不确定性。", "translation": "本研究旨在克服主动学习（AL）中为每个查询选择最佳标注者的挑战，目标是最大限度地减少错误分类。主动学习认识到获取标注数据时与成本和时间相关的挑战，并减少所需的标注数据量。然而，仍然需要减少标注错误，旨在尽可能高效，以更快地达到预期的准确性。大多数查询-标注者配对策略不考虑影响生产力的内部因素，如情绪、注意力、动机和疲劳水平。这项工作通过不仅考虑内部因素（情绪和疲劳水平）如何影响标注者，而且提出一种新的查询-标注者配对策略，利用基于知识的推荐系统（RS），来弥补现有文献中的这一空白。推荐系统根据标注者过去的准确度值、情绪和疲劳水平以及关于查询实例的信息，对可用的标注者进行排名，从而选择一个或多个来标注查询实例。这项工作基于现有关于情绪和疲劳影响人类表现的文献，以现实的方式模拟标注者，并利用推荐系统预测他们的表现。结果表明，与不使用内部因素相比，考虑过去的准确度值以及情绪和疲劳水平可以减少标注者产生的标注错误数量，并降低模型在训练过程中的不确定性。尽管不如上述显著，但所提出的方法在准确度和F1分数上也表现更好。本研究中提出的方法和发现开始探索人类认知因素影响主动学习这一开放性挑战。", "summary": "本研究旨在解决主动学习中标注者选择的难题，并最大限度地减少错误分类。针对现有策略忽视标注者内部因素（如情绪和疲劳）的不足，论文提出了一种新的查询-标注者配对策略。该策略利用一个基于知识的推荐系统，综合考虑标注者过往的准确性、实时情绪和疲劳水平以及查询实例的信息来选择最佳标注者。实验结果表明，该方法能有效减少标注错误和模型训练的不确定性，并提升了准确度和F1分数，为主动学习中融入人类认知因素奠定了基础。", "keywords": "主动学习, 标注者选择, 推荐系统, 情绪, 疲劳", "comments": "本研究的创新之处在于将标注者的情绪和疲劳等内部认知因素纳入主动学习中的标注者选择过程，这在以往的研究中常被忽视。这种以人为本的方法使得标注者选择更加精细化和智能化，有助于提高数据标注的质量和效率。该工作不仅具有理论意义，也为实际应用中优化人工标注流程提供了新的思路和方法，强调了理解人类表现对机器学习系统的重要性。"}}
{"id": "2507.22992", "title": "Improved Simulation of Asynchronous Entanglement Distribution in Noisy Quantum Networks", "authors": ["Emma Hughes", "William Munizzi", "Prineha Narang"], "categories": ["quant-ph", "cs.IT", "math.IT", "physics.optics"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      26 pages, 2 figures, 1 computational package", "url": "http://arxiv.org/abs/2507.22992v1", "summary": "This work introduces a lightweight simulation framework for evaluating\nasynchronous entanglement distribution protocols under realistic error models.\nWe focus on two contemporary protocols: sequential, where entanglement is\nestablished one node at a time, and parallel, where all nodes attempt to\ngenerate entanglement simultaneously. We evaluate the performance of each\nprotocol using two key metrics: the fidelity of distributed entangled states,\nand the hashing rate, a measure of entanglement efficiency. These metrics are\ncompared between both protocols across a range of network sizes and noise\nparameters. We demonstrate that the parallel protocol consistently outperforms\nthe sequential, particularly in the hashing rate metric due to reduced runtime,\nsuggesting that parallel protocols are a strong candidate for a realizable\nquantum Internet. Our framework offers an accessible and scalable tool for\nevaluating entanglement distribution strategies, by reducing the simulation of\ncomplex quantum processes to simple memory time calculations.", "comment": "26 pages, 2 figures, 1 computational package", "pdf_url": "http://arxiv.org/pdf/2507.22992v1", "cate": "quant-ph", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "噪声量子网络中异步纠缠分发改进模拟", "tldr": "本文提出了一个轻量级模拟框架，用于评估噪声量子网络中异步纠缠分发协议的性能，并发现并行协议在纠缠效率方面优于顺序协议。", "motivation": "为了在实际误差模型下评估异步纠缠分发协议的性能，需要一个轻量级的模拟框架。", "method": "本文引入了一个轻量级模拟框架，用于评估噪声量子网络中的异步纠缠分发协议。研究集中于顺序协议和并行协议，并使用纠缠态的保真度和哈希率（纠缠效率的度量）作为关键指标进行性能评估和比较。该框架通过将复杂的量子过程模拟简化为简单的内存时间计算，实现了可访问性和可伸缩性。", "result": "结果表明，并行协议始终优于顺序协议，特别是在哈希率指标方面，因为它减少了运行时间。", "conclusion": "并行协议是实现量子互联网的有力候选者。", "translation": "这项工作引入了一个轻量级的模拟框架，用于在实际误差模型下评估异步纠缠分发协议。我们关注两种当前的协议：顺序协议（纠缠逐个节点建立）和并行协议（所有节点同时尝试生成纠缠）。我们使用两个关键指标评估每种协议的性能：分布式纠缠态的保真度，以及哈希率（一种纠缠效率的度量）。在各种网络规模和噪声参数下，比较了两种协议的这些指标。我们证明并行协议始终优于顺序协议，尤其是在哈希率指标方面，因为其运行时间更短，这表明并行协议是实现量子互联网的有力候选方案。我们的框架通过将复杂量子过程的模拟简化为简单的内存时间计算，为评估纠缠分发策略提供了可访问且可扩展的工具。", "summary": "本文提出了一个轻量级模拟框架，用于在实际误差模型下评估噪声量子网络中的异步纠缠分发协议。通过比较顺序协议和并行协议在纠缠态保真度和哈希率方面的性能，研究发现并行协议在纠缠效率上表现更优，且运行时间更短。该框架将复杂量子模拟简化为简单的内存时间计算，为评估纠缠分发策略提供了一个可扩展的工具，并表明并行协议是未来量子互联网的有力选择。", "keywords": "异步纠缠分发, 量子网络, 并行协议, 顺序协议, 模拟框架", "comments": "这项工作的创新之处在于提出了一个轻量级且可扩展的模拟框架，能够将复杂的量子过程模拟简化为简单的内存时间计算，大大降低了模拟的复杂性。其重要性在于为评估和比较不同的异步纠缠分发协议提供了一个实用工具，并明确指出并行协议在噪声量子网络中的优越性，为未来可实现的量子互联网提供了重要的设计指导。"}}
{"id": "2507.23308", "title": "A Framework for Ethical Decision-Making in Automated Vehicles through Human Reasons-based Supervision", "authors": ["Lucas Elbert Suryana", "Saeed Rahmani", "Simeon Craig Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      7 pages, 4 figures", "url": "http://arxiv.org/abs/2507.23308v1", "summary": "Ethical dilemmas are a common challenge in everyday driving, requiring human\ndrivers to balance competing priorities such as safety, efficiency, and rule\ncompliance. However, much of the existing research in automated vehicles (AVs)\nhas focused on high-stakes \"trolley problems,\" which involve extreme and rare\nsituations. Such scenarios, though rich in ethical implications, are rarely\napplicable in real-world AV decision-making. In practice, when AVs confront\neveryday ethical dilemmas, they often appear to prioritise strict adherence to\ntraffic rules. By contrast, human drivers may bend the rules in\ncontext-specific situations, using judgement informed by practical concerns\nsuch as safety and efficiency. According to the concept of meaningful human\ncontrol, AVs should respond to human reasons, including those of drivers,\nvulnerable road users, and policymakers. This work introduces a novel human\nreasons-based supervision framework that detects when AV behaviour misaligns\nwith expected human reasons to trigger trajectory reconsideration. The\nframework integrates with motion planning and control systems to support\nreal-time adaptation, enabling decisions that better reflect safety,\nefficiency, and regulatory considerations. Simulation results demonstrate that\nthis approach could help AVs respond more effectively to ethical challenges in\ndynamic driving environments by prompting replanning when the current\ntrajectory fails to align with human reasons. These findings suggest that our\napproach offers a path toward more adaptable, human-centered decision-making in\nAVs.", "comment": "7 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.23308v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于人类原因监督的自动驾驶汽车伦理决策框架", "tldr": "现有自动驾驶汽车侧重严格遵守规则，但人类会根据情境和原因进行调整。本文提出一个框架，使自动驾驶汽车通过触发轨迹重新考虑来使其决策与人类原因（安全、效率）对齐，从而实现更以人为中心的自动驾驶行为。", "motivation": "现有自动驾驶汽车伦理研究主要集中在极端的“电车难题”上，这些场景在现实中很少适用。在实践中，自动驾驶汽车在面对日常伦理困境时，往往优先严格遵守交通规则，而人类驾驶员则会根据安全和效率等实际考量在特定情境下灵活变通。因此，需要使自动驾驶汽车能够响应人类的原因，以实现更实用的伦理决策。", "method": "本文提出了一种新颖的“基于人类原因的监督框架”，用于检测自动驾驶汽车行为何时与预期的人类原因不符，从而触发轨迹重新考虑。该框架与运动规划和控制系统集成，以支持实时适应，从而实现更能反映安全、效率和法规考量的决策。", "result": "仿真结果表明，当当前轨迹与人类原因不符时，该方法能够促使自动驾驶汽车重新规划，从而帮助它们在动态驾驶环境中更有效地应对伦理挑战。", "conclusion": "本文提出的方法为自动驾驶汽车实现更具适应性、以人为中心的决策提供了途径。", "translation": "伦理困境是日常驾驶中常见的挑战，需要人类驾驶员平衡安全、效率和规则遵守等相互冲突的优先事项。然而，现有的大部分自动驾驶汽车（AVs）研究都集中在涉及极端和罕见情况的高风险“电车难题”上。尽管这些场景在伦理上具有丰富的含义，但在实际的自动驾驶汽车决策中很少适用。在实践中，当自动驾驶汽车面对日常伦理困境时，它们通常似乎优先严格遵守交通规则。相比之下，人类驾驶员可能会在特定情境中灵活变通，利用基于安全和效率等实际考量的判断力。根据有意义的人类控制概念，自动驾驶汽车应该响应人类的原因，包括驾驶员、弱势道路使用者和政策制定者的原因。这项工作引入了一种新颖的基于人类原因的监督框架，该框架检测自动驾驶汽车行为何时与预期的人类原因不符，从而触发轨迹重新考虑。该框架与运动规划和控制系统集成，以支持实时适应，从而实现更能反映安全、效率和法规考量的决策。仿真结果表明，当当前轨迹未能与人类原因对齐时，这种方法可以通过促使重新规划，帮助自动驾驶汽车在动态驾驶环境中更有效地应对伦理挑战。这些发现表明，我们的方法为自动驾驶汽车实现更具适应性、以人为中心的决策提供了途径。", "summary": "本文旨在解决自动驾驶汽车伦理决策中存在的不足，将研究重点从罕见的“电车难题”转向日常困境。文章指出，当前自动驾驶汽车倾向于严格遵守规则，而人类驾驶员则会根据安全和效率等情境原因进行调整。为此，作者提出了一种“基于人类原因的监督框架”，该框架能够检测自动驾驶汽车行为与预期人类原因不符的情况，并触发轨迹重新考虑。该框架与运动规划系统集成，支持实时适应。仿真结果表明，该方法能有效提升自动驾驶汽车在动态环境中应对伦理挑战的能力，从而实现更具适应性和以人为中心的决策。", "keywords": "自动驾驶汽车, 伦理决策, 人类原因, 监督框架, 轨迹重新考虑", "comments": "该论文的创新之处在于将自动驾驶汽车伦理决策的焦点从极端、理论化的“电车难题”转移到更具现实意义的日常伦理困境。其重要性在于提出了一种将“人类原因”（如安全、效率、情境）融入自动驾驶汽车决策的框架，这有助于使自动驾驶汽车的行为更接近人类，提高其社会接受度，而非僵化地遵守规则。这种方法增强了自动驾驶汽车的适应性和以人为中心的特性。"}}
{"id": "2507.23121", "title": "Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity", "authors": ["Xinwei Wu", "Haojie Li", "Hongyu Liu", "Xinyu Ji", "Ruohan Li", "Yule Chen", "Yigeng Zhang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at KDD workshop on Evaluation and Trustworthiness of Agentic and Generative AI Models (Agentic & GenAI Evaluation Workshop KDD '25)", "url": "http://arxiv.org/abs/2507.23121v1", "summary": "In this work, we study a critical research problem regarding the\ntrustworthiness of large language models (LLMs): how LLMs behave when\nencountering ambiguous narrative text, with a particular focus on Chinese\ntextual ambiguity. We created a benchmark dataset by collecting and generating\nambiguous sentences with context and their corresponding disambiguated pairs,\nrepresenting multiple possible interpretations. These annotated examples are\nsystematically categorized into 3 main categories and 9 subcategories. Through\nexperiments, we discovered significant fragility in LLMs when handling\nambiguity, revealing behavior that differs substantially from humans.\nSpecifically, LLMs cannot reliably distinguish ambiguous text from unambiguous\ntext, show overconfidence in interpreting ambiguous text as having a single\nmeaning rather than multiple meanings, and exhibit overthinking when attempting\nto understand the various possible meanings. Our findings highlight a\nfundamental limitation in current LLMs that has significant implications for\ntheir deployment in real-world applications where linguistic ambiguity is\ncommon, calling for improved approaches to handle uncertainty in language\nunderstanding. The dataset and code are publicly available at this GitHub\nrepository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.", "comment": "Accepted at KDD workshop on Evaluation and Trustworthiness of Agentic\n  and Generative AI Models (Agentic & GenAI Evaluation Workshop KDD '25)", "pdf_url": "http://arxiv.org/pdf/2507.23121v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "通过中文文本歧义揭示可信大型语言模型的脆弱性", "tldr": "研究发现大型语言模型（LLMs）在处理中文文本歧义时表现出显著的脆弱性，与人类行为差异大，且存在过度自信和过度思考的问题。", "motivation": "本研究旨在探讨大型语言模型（LLMs）在遇到歧义叙述文本时的行为表现，特别是中文文本歧义，以解决LLMs可信度方面的一个关键研究问题。", "method": "研究通过收集和生成带有上下文的歧义句子及其对应的消歧对，创建了一个基准数据集，这些例子被系统地分为3个主要类别和9个子类别。然后通过实验来评估LLMs处理歧义的能力。", "result": "实验发现LLMs在处理歧义时表现出显著的脆弱性，其行为与人类有很大差异。具体来说，LLMs无法可靠地区分歧义文本和非歧义文本，在解释歧义文本时表现出过度自信（认为只有一个含义而非多个），并且在尝试理解各种可能含义时表现出过度思考。", "conclusion": "研究结果突出了当前LLMs的一个根本性局限，这对它们在语言歧义普遍存在的现实世界应用中的部署具有重要意义，并呼吁改进处理语言理解中不确定性的方法。", "translation": "在这项工作中，我们研究了一个关于大型语言模型（LLMs）可信度的关键研究问题：LLMs在遇到歧义叙述文本时的行为如何，特别关注中文文本歧义。我们通过收集和生成带有上下文的歧义句子及其对应的消歧对，代表多种可能的解释，创建了一个基准数据集。这些标注示例被系统地分为3个主要类别和9个子类别。通过实验，我们发现LLMs在处理歧义时表现出显著的脆弱性，揭示出与人类行为截然不同的表现。具体来说，LLMs无法可靠地区分歧义文本和非歧义文本，在解释歧义文本时表现出过度自信（认为只有一个含义而非多个），并且在尝试理解各种可能含义时表现出过度思考。我们的发现突出了当前LLMs的一个根本性局限，这对它们在语言歧义普遍存在的现实世界应用中的部署具有重要意义，并呼吁改进处理语言理解中不确定性的方法。数据集和代码可在以下GitHub仓库公开获取：https://github.com/ictup/LLM-Chinese-Textual-Disambiguation。", "summary": "本研究探讨了大型语言模型（LLMs）在处理中文文本歧义时的可信度问题。通过构建一个包含歧义句子及其消歧对的基准数据集，研究发现LLMs在处理歧义时表现出显著的脆弱性，包括无法区分歧义文本、过度自信地认为文本只有单一含义以及过度思考。这些发现揭示了当前LLMs在语言理解方面存在的根本性局限，对它们在实际应用中的部署具有重要影响，并强调了开发更优方法来处理语言不确定性的必要性。", "keywords": "大型语言模型, 中文文本歧义, 可信度, 基准数据集, 语言理解", "comments": "本文通过关注中文文本歧义，揭示了大型语言模型在处理语言不确定性方面的深层缺陷。其创新之处在于构建了一个专门针对中文歧义的基准数据集，这对于评估和改进LLMs在复杂语言环境下的表现至关重要。研究结果指出了LLMs在理解多义性方面与人类的显著差异，特别是过度自信和过度思考的问题，这对于提升LLMs的鲁棒性和可信度具有重要的指导意义。"}}
{"id": "2402.11461", "title": "FGeo-HyperGNet: Geometric Problem Solving Integrating FormalGeo Symbolic System and Hypergraph Neural Network", "authors": ["Xiaokai Zhang", "Yang Li", "Na Zhu", "Cheng Qin", "Zhenbing Zeng", "Tuo Leng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by IJCAI 2025", "url": "http://arxiv.org/abs/2402.11461v3", "summary": "Geometric problem solving has always been a long-standing challenge in the\nfields of mathematical reasoning and artificial intelligence. We built a\nneural-symbolic system, called FGeo-HyperGNet, to automatically perform\nhuman-like geometric problem solving. The symbolic component is a formal system\nbuilt on FormalGeo, which can automatically perform geometric relational\nreasoning and algebraic calculations and organize the solution into a\nhypergraph with conditions as hypernodes and theorems as hyperedges. The neural\ncomponent, called HyperGNet, is a hypergraph neural network based on the\nattention mechanism, including an encoder to encode the structural and semantic\ninformation of the hypergraph and a theorem predictor to provide guidance in\nsolving problems. The neural component predicts theorems according to the\nhypergraph, and the symbolic component applies theorems and updates the\nhypergraph, thus forming a predict-apply cycle to ultimately achieve readable\nand traceable automatic solving of geometric problems. Experiments demonstrate\nthe effectiveness of this neural-symbolic architecture. We achieved\nstate-of-the-art results with a TPA of 93.50% and a PSSR of 88.36% on the\nFormalGeo7K dataset. The code is available at\nhttps://github.com/BitSecret/HyperGNet.", "comment": "Accepted by IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2402.11461v3", "cate": "cs.AI", "date": "2024-02-18", "updated": "2025-07-31", "AI": {"title_translation": "FGeo-HyperGNet：几何问题求解融合FormalGeo符号系统与超图神经网络", "tldr": "FGeo-HyperGNet是一个神经-符号系统，通过预测-应用循环结合超图神经网络和FormalGeo符号系统，实现了可读可追溯的几何问题自动求解，并在FormalGeo7K数据集上达到了最先进的性能。", "motivation": "几何问题求解一直是数学推理和人工智能领域的长期挑战，该研究旨在自动执行类似人类的几何问题求解。", "method": "提出了一个名为FGeo-HyperGNet的神经-符号系统。符号组件基于FormalGeo，负责几何关系推理、代数计算并将解组织成超图（条件作为超节点，定理作为超边）。神经组件HyperGNet是一个基于注意力机制的超图神经网络，包含编码器和定理预测器。系统通过神经组件预测定理，符号组件应用定理并更新超图的“预测-应用”循环，实现几何问题的自动求解。", "result": "实验证明了该神经-符号架构的有效性。在FormalGeo7K数据集上，实现了93.50%的TPA和88.36%的PSSR，达到了最先进的结果。", "conclusion": "FGeo-HyperGNet系统能够有效且可追溯地自动求解几何问题，并在特定数据集上表现出卓越的性能，证明了神经-符号方法在几何推理领域的潜力。", "translation": "几何问题求解一直是数学推理和人工智能领域的长期挑战。我们构建了一个名为FGeo-HyperGNet的神经-符号系统，以自动执行类似人类的几何问题求解。符号组件是建立在FormalGeo之上的形式系统，可以自动执行几何关系推理和代数计算，并将解组织成一个超图，其中条件作为超节点，定理作为超边。神经组件名为HyperGNet，是一个基于注意力机制的超图神经网络，包括一个编码器用于编码超图的结构和语义信息，以及一个定理预测器用于在解决问题时提供指导。神经组件根据超图预测定理，符号组件应用定理并更新超图，从而形成一个预测-应用循环，最终实现可读和可追溯的几何问题自动求解。实验证明了这种神经-符号架构的有效性。我们在FormalGeo7K数据集上取得了93.50%的TPA和88.36%的PSSR的最先进结果。代码可在https://github.com/BitSecret/HyperGNet获取。", "summary": "本文提出了FGeo-HyperGNet，一个用于自动几何问题求解的神经-符号系统。该系统结合了基于FormalGeo的符号推理组件和基于注意力机制的HyperGNet超图神经网络。通过神经组件预测定理和符号组件应用定理并更新超图的“预测-应用”循环，实现了可读和可追溯的求解过程。实验结果表明，该系统在FormalGeo7K数据集上取得了最先进的性能。", "keywords": "几何问题求解, 神经-符号系统, 超图神经网络, FormalGeo, 自动推理", "comments": "FGeo-HyperGNet的创新之处在于其神经-符号混合架构，有效地结合了符号推理的严谨性和神经网络的模式识别能力。特别是将几何问题转换为超图表示，并通过“预测-应用”循环实现问题求解，为复杂推理任务提供了一个可解释且高效的范式。其在几何问题求解领域达到SOTA性能，显示了该方法的巨大潜力。"}}
{"id": "2507.22926", "title": "Multi-Relation Extraction in Entity Pairs using Global Context", "authors": ["Nilesh", "Atul Gupta", "Avinash C Panday"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures", "url": "http://arxiv.org/abs/2507.22926v1", "summary": "In document-level relation extraction, entities may appear multiple times in\na document, and their relationships can shift from one context to another.\nAccurate prediction of the relationship between two entities across an entire\ndocument requires building a global context spanning all relevant sentences.\nPrevious approaches have focused only on the sentences where entities are\nmentioned, which fails to capture the complete document context necessary for\naccurate relation extraction. Therefore, this paper introduces a novel input\nembedding approach to capture the positions of mentioned entities throughout\nthe document rather than focusing solely on the span where they appear. The\nproposed input encoding approach leverages global relationships and\nmulti-sentence reasoning by representing entities as standalone segments,\nindependent of their positions within the document. The performance of the\nproposed method has been tested on three benchmark relation extraction\ndatasets, namely DocRED, Re-DocRED, and REBEL. The experimental results\ndemonstrated that the proposed method accurately predicts relationships between\nentities in a document-level setting. The proposed research also has\ntheoretical and practical implications. Theoretically, it advances global\ncontext modeling and multi-sentence reasoning in document-level relation\nextraction. Practically, it enhances relationship detection, enabling improved\nperformance in real-world NLP applications requiring comprehensive entity-level\ninsights and interpretability.", "comment": "11 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.22926v1", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-23", "AI": {"title_translation": "使用全局上下文的实体对多关系抽取", "tldr": "本文提出了一种新颖的输入嵌入方法，用于文档级关系抽取，通过捕获文档中所有提及的实体位置来构建全局上下文，从而在文档级设置中更准确地预测实体关系。", "motivation": "在文档级关系抽取中，实体可能在文档中多次出现，且其关系可能随上下文变化。现有方法仅关注实体被提及的句子，未能捕获完整的文档上下文，导致关系抽取不准确。", "method": "本文引入了一种新颖的输入嵌入方法，旨在捕获文档中所有提及实体的位置，而非仅关注它们出现的文本跨度。该方法通过将实体表示为独立的片段（独立于其在文档中的位置），利用全局关系和多句推理。", "result": "所提出的方法在DocRED、Re-DocRED和REBEL三个基准关系抽取数据集上进行了测试。实验结果表明，该方法在文档级设置中能准确预测实体间的关系。", "conclusion": "理论上，该研究推动了文档级关系抽取中的全局上下文建模和多句推理。实践中，它增强了关系检测能力，从而提高了需要全面实体级洞察和可解释性的实际NLP应用的性能。", "translation": "在文档级关系抽取中，实体可能在文档中多次出现，其关系也可能随上下文变化。要在整个文档中准确预测两个实体之间的关系，需要构建跨越所有相关句子的全局上下文。以往的方法只关注实体被提及的句子，未能捕获准确关系抽取所需的完整文档上下文。因此，本文引入了一种新颖的输入嵌入方法，旨在捕获文档中提及实体的所有位置，而不是仅仅关注它们出现的文本跨度。所提出的输入编码方法通过将实体表示为独立的片段，独立于它们在文档中的位置，从而利用全局关系和多句推理。所提方法的性能已在DocRED、Re-DocRED和REBEL三个基准关系抽取数据集上进行了测试。实验结果表明，所提方法在文档级设置中准确预测了实体之间的关系。本研究也具有理论和实践意义。理论上，它推动了文档级关系抽取中的全局上下文建模和多句推理。实践中，它增强了关系检测能力，从而提高了需要全面实体级洞察和可解释性的实际NLP应用的性能。", "summary": "本文针对文档级关系抽取中现有方法仅关注局部上下文的不足，提出了一种新颖的输入嵌入方法。该方法通过捕获文档中所有提及实体的位置，并将实体表示为独立的片段，有效构建全局上下文并进行多句推理。在DocRED、Re-DocRED和REBEL等基准数据集上的实验结果表明，该方法能准确预测文档级实体关系，并在理论上推进了全局上下文建模，实践中提升了关系检测能力。", "keywords": "文档级关系抽取, 全局上下文, 多句推理, 输入嵌入", "comments": "本文的创新点在于其提出的输入嵌入方法，通过考虑文档中所有实体提及的位置来构建全局上下文，有效解决了传统方法仅关注局部上下文的局限性。这对于文档级关系抽取任务至关重要，因为它能更好地捕捉实体间复杂且跨句的关系。该方法在理论上推动了全局上下文建模，并在实践中提升了关系检测的准确性和实用性，具有重要的研究价值和应用前景。"}}
{"id": "2503.17788", "title": "Learning to Align and Refine: A Foundation-to-Diffusion Framework for Occlusion-Robust Two-Hand Reconstruction", "authors": ["Gaoge Han", "Yongkang Cheng", "Zhe Chen", "Shaoli Huang", "Tongliang Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17788v2", "summary": "Two-hand reconstruction from monocular images faces persistent challenges due\nto complex and dynamic hand postures and occlusions, causing significant\ndifficulty in achieving plausible interaction alignment. Existing approaches\nstruggle with such alignment issues, often resulting in misalignment and\npenetration artifacts. To tackle this, we propose a dual-stage\nFoundation-to-Diffusion framework that precisely align 2D prior guidance from\nvision foundation models and diffusion-based generative 3D interaction\nrefinement to achieve occlusion-robust two-hand reconstruction. First, we\nintroduce a lightweight fusion alignment encoder that aligns fused multimodal\n2D priors like key points, segmentation maps, and depth cues from vision\nfoundation models during training. This provides robust structured guidance,\nfurther enabling efficient inference without heavy foundation model encoders at\ntest time while maintaining high reconstruction accuracy. Second, we implement\na two-hand diffusion model explicitly trained to convert interpenetrated 3D\nposes into plausible, penetration-free counterparts. Through collision\ngradient-guided denoising, the model rectifies artifacts while preserving\nnatural spatial relationships between hands. Extensive evaluations demonstrate\nthat our method achieves state-of-the-art performance on InterHand2.6M, HIC,\nand FreiHAND datasets, significantly advancing occlusion handling and\ninteraction robustness. Our code will be publicly released.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17788v2", "cate": "cs.CV", "date": "2025-03-22", "updated": "2025-07-31", "AI": {"title_translation": "学习对齐与精炼：一种用于遮挡鲁棒双手动重建的从基础到扩散框架", "tldr": "该论文提出了一种双阶段的从基础到扩散框架，用于解决单目图像中双手动重建的遮挡和对齐问题，通过对齐2D先验指导和扩散模型进行3D交互精炼，实现了最先进的性能。", "motivation": "单目图像中的双手动重建面临复杂动态手部姿态和遮挡带来的持续挑战，难以实现合理的交互对齐，现有方法常导致错位和穿透伪影。", "method": "本文提出了一种双阶段的“从基础到扩散”框架。首先，引入一个轻量级融合对齐编码器，用于在训练期间对齐来自视觉基础模型的多模态2D先验（如关键点、分割图和深度线索），这在测试时无需重型基础模型编码器即可实现高效推理。其次，实现了一个专门训练的双手扩散模型，通过碰撞梯度引导去噪，将相互穿透的3D姿态转换为合理、无穿透的对应姿态，同时保持手部之间的自然空间关系。", "result": "广泛评估表明，该方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，显著提升了遮挡处理和交互鲁棒性。", "conclusion": "该双阶段的从基础到扩散框架能够有效解决单目图像双手动重建中的遮挡和对齐挑战，通过结合2D先验指导和3D扩散模型精炼，实现了卓越的重建精度和鲁棒性。", "translation": "从单目图像进行双手重建面临着由于复杂动态的手部姿态和遮挡而带来的持续挑战，这导致在实现合理的交互对齐方面存在巨大困难。现有方法难以解决此类对齐问题，常常导致错位和穿透伪影。为了解决这个问题，我们提出了一种双阶段的从基础到扩散框架，该框架精确对齐来自视觉基础模型的2D先验指导，并通过基于扩散的生成式3D交互精炼来实现对遮挡鲁棒的双手重建。首先，我们引入了一个轻量级融合对齐编码器，用于在训练期间对齐融合的多模态2D先验，例如来自视觉基础模型的关键点、分割图和深度线索。这提供了鲁棒的结构化指导，进一步使得在测试时无需重型基础模型编码器即可进行高效推理，同时保持高重建精度。其次，我们实现了一个双手扩散模型，该模型经过显式训练，可以将相互穿透的3D姿态转换为合理、无穿透的对应姿态。通过碰撞梯度引导去噪，该模型在纠正伪影的同时保留了手部之间自然的空间关系。广泛的评估表明，我们的方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，显著推进了遮挡处理和交互鲁棒性。我们的代码将公开。", "summary": "本文提出了一种名为“从基础到扩散”的双阶段框架，旨在解决单目图像中双手动重建的遮挡和交互对齐难题。该框架首先利用轻量级融合对齐编码器，在训练时整合视觉基础模型的2D多模态先验以提供结构化指导，并在推理时保持高效。随后，通过一个专门训练的双手扩散模型，利用碰撞梯度引导去噪技术，将穿透的3D姿态精炼为无穿透的合理姿态。实验结果表明，该方法在多个标准数据集上均达到了最先进的性能，显著提升了遮挡处理能力和交互鲁棒性。", "keywords": "双手重建, 遮挡处理, 扩散模型, 基础模型, 3D对齐", "comments": "该论文的创新点在于结合了视觉基础模型提供的2D先验指导与扩散模型进行3D精炼。特别是，其轻量级融合对齐编码器在保证精度的同时，显著提升了推理效率，解决了基础模型通常计算量大的问题。同时，利用扩散模型通过碰撞梯度引导去噪来解决手部穿透问题，是处理复杂交互场景的有效方法。这项工作在单目双手动重建领域具有重要意义，尤其是在处理遮挡和确保物理合理性方面取得了显著进展。"}}
{"id": "2503.15299", "title": "Inside-Out: Hidden Factual Knowledge in LLMs", "authors": ["Zorik Gekhman", "Eyal Ben David", "Hadas Orgad", "Eran Ofek", "Yonatan Belinkov", "Idan Szpektor", "Jonathan Herzig", "Roi Reichart"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2503.15299v3", "summary": "This work presents a framework for assessing whether large language models\n(LLMs) encode more factual knowledge in their parameters than what they express\nin their outputs. While a few studies hint at this possibility, none has\nclearly defined or demonstrated this phenomenon. We first propose a formal\ndefinition of knowledge, quantifying it for a given question as the fraction of\ncorrect-incorrect answer pairs where the correct one is ranked higher. This\ngives rise to external and internal knowledge, depending on the information\nused to score individual answer candidates: either the model's observable\ntoken-level probabilities or its intermediate computations. Hidden knowledge\narises when internal knowledge exceeds external knowledge. We then present a\ncase study, applying this framework to three popular open-weights LLMs in a\nclosed-book QA setup. Our results indicate that: (1) LLMs consistently encode\nmore factual knowledge internally than what they express externally, with an\naverage relative gap of 40%. (2) Surprisingly, some knowledge is so deeply\nhidden that a model can internally know an answer perfectly, yet fail to\ngenerate it even once, despite large-scale repeated sampling of 1,000 answers.\nThis reveals fundamental limitations in the generation capabilities of LLMs,\nwhich (3) put a practical constraint on scaling test-time compute via repeated\nanswer sampling in closed-book QA: significant performance improvements remain\ninaccessible because some answers are practically never sampled, yet if they\nwere, we would be guaranteed to rank them first.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2503.15299v3", "cate": "cs.CL", "date": "2025-03-19", "updated": "2025-07-31", "AI": {"title_translation": "由内而外：大型语言模型中隐藏的事实知识", "tldr": "大型语言模型在内部编码的事实知识远超其外部表达，揭示了其生成能力的根本局限性。", "motivation": "现有研究暗示大型语言模型（LLMs）参数中可能编码了比其输出表达更多的事实知识，但缺乏明确的定义和证明。本研究旨在填补这一空白。", "method": "本研究提出了一个评估LLMs是否编码更多事实知识的框架。首先，形式化定义知识，量化为正确-错误答案对中正确答案排名更高的比例。这区分了依赖模型可观察的token级概率的“外部知识”和依赖中间计算的“内部知识”。当内部知识超过外部知识时，即为“隐藏知识”。然后，将此框架应用于闭卷问答设置下的三个流行开源LLM进行案例研究。", "result": "1. LLMs内部编码的事实知识始终多于其外部表达的知识，平均相对差距为40%。2. 某些知识隐藏极深，模型内部可能完美知道答案，但在大规模重复采样1000次后仍未能生成该答案。3. 这对通过重复采样答案来扩展测试时计算能力设置了实际限制，因为某些答案实际上从未被采样到，即使它们被采样到也保证能被排在首位。", "conclusion": "大型语言模型内部存储了大量未被其生成能力充分利用的事实知识，这揭示了LLM生成能力的根本性局限，并限制了通过增加计算量来提升性能的潜力。", "translation": "这项工作提出了一个框架，用于评估大型语言模型（LLMs）在其参数中编码的事实知识是否多于其在输出中表达的事实知识。虽然一些研究暗示了这种可能性，但没有一项研究明确定义或证明这一现象。我们首先提出了一个知识的形式化定义，将其量化为给定问题中正确-错误答案对中正确答案排名更高的比例。这产生了外部知识和内部知识，取决于用于评估单个答案候选的信息：要么是模型可观察的token级概率，要么是其中间计算。当内部知识超过外部知识时，就会出现隐藏知识。然后，我们提出了一个案例研究，将此框架应用于闭卷问答设置中的三个流行开源LLM。我们的结果表明：(1) LLMs内部编码的事实知识始终多于其外部表达的知识，平均相对差距为40%。(2) 令人惊讶的是，一些知识隐藏得如此之深，以至于模型内部可以完美地知道一个答案，但即使在对1000个答案进行大规模重复采样后，也未能生成它。这揭示了LLMs生成能力的根本局限性，(3) 这对通过在闭卷问答中重复答案采样来扩展测试时计算能力施加了实际约束：显著的性能提升仍然无法实现，因为某些答案实际上从未被采样到，但如果它们被采样到，我们则保证会将它们排在首位。", "summary": "本研究提出了一个框架来评估大型语言模型（LLMs）内部编码的隐藏事实知识。通过定义外部知识和内部知识，并引入“隐藏知识”概念（内部知识超越外部知识），研究发现LLMs内部存储了大量未被外部表达的事实知识，平均差距达40%。此外，某些知识隐藏极深，即使模型内部完美知晓，也难以通过生成方式表达。这揭示了LLMs生成能力的根本局限性，并限制了通过增加采样次数提升闭卷问答性能的有效性。", "keywords": "大型语言模型, 事实知识, 隐藏知识, 生成能力, 闭卷问答", "comments": "本论文创新性地提出了“隐藏知识”的概念及其量化框架，揭示了LLMs内部知识与外部表达之间的显著差距。这一发现对理解LLMs的内在工作机制及其生成能力的局限性具有重要意义。它指出，即使模型“知道”答案，也可能因为生成机制的缺陷而无法表达，为未来LLM的架构设计和训练优化提供了新的研究方向。其局限性在于，虽然指出了问题，但并未提供具体的解决方案来“解锁”这些隐藏知识。"}}
{"id": "2506.05588", "title": "Preprocessing Methods for Memristive Reservoir Computing for Image Recognition", "authors": ["Rishona Daniels", "Duna Wattad", "Ronny Ronen", "David Saad", "Shahar Kvatinsky"], "categories": ["cs.NE", "cs.AR", "cs.ET"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, Accepted for presentation in IEEE MetroXRAINE 2025 conference", "url": "http://arxiv.org/abs/2506.05588v3", "summary": "Reservoir computing (RC) has attracted attention as an efficient recurrent\nneural network architecture due to its simplified training, requiring only its\nlast perceptron readout layer to be trained. When implemented with memristors,\nRC systems benefit from their dynamic properties, which make them ideal for\nreservoir construction. However, achieving high performance in memristor-based\nRC remains challenging, as it critically depends on the input preprocessing\nmethod and reservoir size. Despite growing interest, a comprehensive evaluation\nthat quantifies the impact of these factors is still lacking. This paper\nsystematically compares various preprocessing methods for memristive RC\nsystems, assessing their effects on accuracy and energy consumption. We also\npropose a parity-based preprocessing method that improves accuracy by 2-6%\nwhile requiring only a modest increase in device count compared to other\nmethods. Our findings highlight the importance of informed preprocessing\nstrategies to improve the efficiency and scalability of memristive RC systems.", "comment": "6 pages, 5 figures, Accepted for presentation in IEEE MetroXRAINE\n  2025 conference", "pdf_url": "http://arxiv.org/pdf/2506.05588v3", "cate": "cs.NE", "date": "2025-06-05", "updated": "2025-07-31", "AI": {"title_translation": "用于图像识别的忆阻储备池计算的预处理方法", "tldr": "本文系统地比较了忆阻储备池计算（RC）的各种预处理方法，并提出了一种基于奇偶校验的预处理方法，以提高图像识别的准确性和效率。", "motivation": "忆阻器储备池计算（RC）系统在实现高性能方面仍面临挑战，其性能关键取决于输入预处理方法和储备池大小。目前缺乏对这些因素影响的全面评估。", "method": "本文系统地比较了忆阻器储备池计算（RC）系统中的各种预处理方法，评估了它们对准确性和能耗的影响。此外，本文还提出了一种基于奇偶校验的预处理方法。", "result": "研究发现，所提出的基于奇偶校验的预处理方法可以将准确性提高2-6%，同时与其它方法相比，仅需适度增加器件数量。研究结果强调了知情预处理策略对于提高忆阻器RC系统效率和可扩展性的重要性。", "conclusion": "知情预处理策略对于提高忆阻器储备池计算（RC）系统的效率和可扩展性至关重要。", "translation": "储备池计算（RC）作为一种高效的循环神经网络架构，因其训练简化（仅需训练其最后一个感知器读出层）而备受关注。当使用忆阻器实现时，RC系统受益于其动态特性，这使得它们非常适合储备池的构建。然而，忆阻器RC系统实现高性能仍然具有挑战性，因为它关键取决于输入预处理方法和储备池大小。尽管兴趣日益增长，但仍缺乏量化这些因素影响的全面评估。本文系统地比较了忆阻器RC系统中的各种预处理方法，评估了它们对准确性和能耗的影响。我们还提出了一种基于奇偶校验的预处理方法，该方法将准确性提高了2-6%，同时与其它方法相比，仅需适度增加器件数量。我们的研究结果强调了知情预处理策略对于提高忆阻器RC系统效率和可扩展性的重要性。", "summary": "本文系统地比较了忆阻器储备池计算（RC）系统中的多种预处理方法，以评估它们对图像识别准确性和能耗的影响。研究提出了一种新的基于奇偶校验的预处理方法，该方法在仅适度增加器件数量的情况下，将准确性提高了2-6%。研究结果强调了选择合适的预处理策略对于提升忆阻器RC系统性能和可扩展性的重要性。", "keywords": "忆阻器, 储备池计算, 预处理, 图像识别, 准确性", "comments": "本文通过系统比较和提出新的预处理方法，解决了忆阻器储备池计算（RC）在图像识别中性能优化的关键挑战。其创新性在于提出了一种有效的奇偶校验预处理方法，并在准确性和能耗方面进行了量化评估，为提升忆阻器RC系统的实际应用效率和可扩展性提供了重要指导。"}}
{"id": "2507.22920", "title": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey", "authors": ["Jindong Li", "Yali Fu", "Jiahong Liu", "Linxiao Cao", "Wei Ji", "Menglin Yang", "Irwin King", "Ming-Hsuan Yang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22920v1", "summary": "The rapid advancement of large language models (LLMs) has intensified the\nneed for effective mechanisms to transform continuous multimodal data into\ndiscrete representations suitable for language-based processing. Discrete\ntokenization, with vector quantization (VQ) as a central approach, offers both\ncomputational efficiency and compatibility with LLM architectures. Despite its\ngrowing importance, there is a lack of a comprehensive survey that\nsystematically examines VQ techniques in the context of LLM-based systems. This\nwork fills this gap by presenting the first structured taxonomy and analysis of\ndiscrete tokenization methods designed for LLMs. We categorize 8 representative\nVQ variants that span classical and modern paradigms and analyze their\nalgorithmic principles, training dynamics, and integration challenges with LLM\npipelines. Beyond algorithm-level investigation, we discuss existing research\nin terms of classical applications without LLMs, LLM-based single-modality\nsystems, and LLM-based multimodal systems, highlighting how quantization\nstrategies influence alignment, reasoning, and generation performance. In\naddition, we identify key challenges including codebook collapse, unstable\ngradient estimation, and modality-specific encoding constraints. Finally, we\ndiscuss emerging research directions such as dynamic and task-adaptive\nquantization, unified tokenization frameworks, and biologically inspired\ncodebook learning. This survey bridges the gap between traditional vector\nquantization and modern LLM applications, serving as a foundational reference\nfor the development of efficient and generalizable multimodal systems. A\ncontinuously updated version is available at:\nhttps://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22920v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "多模态大型语言模型的离散分词：一项全面综述", "tldr": "本文对多模态大型语言模型（LLMs）中离散分词（特别是矢量量化V Q）进行了首次全面综述，提出了结构化分类法，分析了算法原理、训练动态和集成挑战，并讨论了现有应用和未来研究方向。", "motivation": "大型语言模型（LLMs）的快速发展，需要有效的机制将连续多模态数据转换为适合基于语言处理的离散表示。离散分词，以矢量量化（VQ）为核心方法，在计算效率和与LLM架构兼容性方面具有优势。然而，目前缺乏对LLM系统中VQ技术的全面系统综述。", "method": "本文通过提出第一个针对LLMs设计的离散分词方法的结构化分类法和分析来填补这一空白。它将8种代表性的VQ变体分类，涵盖经典和现代范式，并分析其算法原理、训练动态以及与LLM管道的集成挑战。除了算法层面的研究，还讨论了现有研究在经典无LLM应用、基于LLM的单模态系统和基于LLM的多模态系统中的应用，并强调了量化策略如何影响对齐、推理和生成性能。", "result": "本文分类了8种代表性的VQ变体，并分析了它们的算法原理、训练动态和与LLM管道的集成挑战。讨论了量化策略在无LLM应用、基于LLM的单模态和多模态系统中的影响，特别指出其对对齐、推理和生成性能的影响。此外，还识别了关键挑战，包括码本崩溃、不稳定的梯度估计和模态特定的编码约束。", "conclusion": "这项综述弥合了传统矢量量化与现代LLM应用之间的鸿沟，为开发高效和可泛化的多模态系统提供了基础性参考。", "translation": "大型语言模型（LLMs）的快速发展，使得将连续多模态数据转换为适合基于语言处理的离散表示的需求日益迫切。离散分词，以矢量量化（VQ）作为核心方法，既提供了计算效率，又与LLM架构兼容。尽管其重要性日益增长，但目前缺乏对LLM系统中的VQ技术进行系统性审查的全面综述。这项工作通过提出第一个针对LLMs设计的离散分词方法的结构化分类法和分析来填补这一空白。我们对涵盖经典和现代范式的8种代表性VQ变体进行了分类，并分析了它们的算法原理、训练动态以及与LLM管道的集成挑战。除了算法层面的研究，我们还从经典无LLM应用、基于LLM的单模态系统和基于LLM的多模态系统方面讨论了现有研究，强调了量化策略如何影响对齐、推理和生成性能。此外，我们还指出了关键挑战，包括码本崩溃、不稳定的梯度估计和模态特定的编码约束。最后，我们讨论了新兴的研究方向，如动态和任务自适应量化、统一的分词框架以及受生物学启发的码本学习。这项综述弥合了传统矢量量化与现代LLM应用之间的鸿沟，为开发高效和可泛化的多模态系统提供了基础性参考。持续更新的版本可在以下链接获取：https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey。", "summary": "本文是首个针对多模态大型语言模型（LLMs）中离散分词（特别是矢量量化VQ）的全面综述。它提出了一个结构化的分类法，对8种代表性VQ变体进行了分类和分析，涵盖了其算法原理、训练动态和与LLM集成的挑战。此外，该综述还讨论了VQ在不同LLM应用中的影响，并识别了当前面临的关键挑战。最后，文章展望了未来的研究方向，旨在为高效和可泛化的多模态系统开发提供基础性参考。", "keywords": "离散分词, 矢量量化, 多模态LLMs, 综述, 深度学习", "comments": "这是一篇重要的综述文章，填补了多模态LLM离散分词领域系统性研究的空白。其创新之处在于首次提出了结构化分类法，并深入分析了VQ技术在LLM背景下的应用、挑战和未来方向。对于推动多模态LLM的发展具有重要的参考价值。"}}
{"id": "2507.19079", "title": "SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research", "authors": ["Feng Zhu", "Zihang Zhang", "Kangcheng Teng", "Abduhelil Yakup", "Xiaohong Zhang"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19079v2", "summary": "High-precision navigation and positioning systems are critical for\napplications in autonomous vehicles and mobile mapping, where robust and\ncontinuous localization is essential. To test and enhance the performance of\nalgorithms, some research institutions and companies have successively\nconstructed and publicly released datasets. However, existing datasets still\nsuffer from limitations in sensor diversity and environmental coverage. To\naddress these shortcomings and advance development in related fields, the\nSmartPNT Multisource Integrated Navigation, Positioning, and Attitude Dataset\nhas been developed. This dataset integrates data from multiple sensors,\nincluding Global Navigation Satellite Systems (GNSS), Inertial Measurement\nUnits (IMU), optical cameras, and LiDAR, to provide a rich and versatile\nresource for research in multi-sensor fusion and high-precision navigation. The\ndataset construction process is thoroughly documented, encompassing sensor\nconfigurations, coordinate system definitions, and calibration procedures for\nboth cameras and LiDAR. A standardized framework for data collection and\nprocessing ensures consistency and scalability, enabling large-scale analysis.\nValidation using state-of-the-art Simultaneous Localization and Mapping (SLAM)\nalgorithms, such as VINS-Mono and LIO-SAM, demonstrates the dataset's\napplicability for advanced navigation research. Covering a wide range of\nreal-world scenarios, including urban areas, campuses, tunnels, and suburban\nenvironments, the dataset offers a valuable tool for advancing navigation\ntechnologies and addressing challenges in complex environments. By providing a\npublicly accessible, high-quality dataset, this work aims to bridge gaps in\nsensor diversity, data accessibility, and environmental representation,\nfostering further innovation in the field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19079v2", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-31", "AI": {"title_translation": "SmartPNT-MSF：一个用于定位和导航研究的多传感器融合数据集", "tldr": "SmartPNT-MSF是一个新的多传感器融合数据集，用于解决现有数据集在传感器多样性和环境覆盖方面的不足，旨在推动高精度定位和导航算法的研究。", "motivation": "高精度导航和定位系统对于自动驾驶和移动测绘至关重要，但现有数据集在传感器多样性和环境覆盖方面存在局限性。为了解决这些不足并促进相关领域的发展，SmartPNT-MSF数据集被开发。", "method": "SmartPNT数据集整合了GNSS、IMU、光学相机和LiDAR等多种传感器数据。其构建过程详细记录了传感器配置、坐标系定义以及相机和LiDAR的校准程序。数据采集和处理采用标准化框架，以确保一致性和可扩展性。", "result": "SmartPNT-MSF数据集为多传感器融合和高精度导航研究提供了丰富多样的资源。通过使用VINS-Mono和LIO-SAM等先进的SLAM算法进行验证，证明了该数据集适用于高级导航研究。该数据集涵盖城市、校园、隧道和郊区等多种真实场景。", "conclusion": "SmartPNT-MSF数据集通过提供一个可公开访问、高质量的数据集，旨在弥补传感器多样性、数据可访问性和环境表示方面的空白，从而促进该领域的进一步创新。", "translation": "高精度导航和定位系统对于自动驾驶车辆和移动测绘中的应用至关重要，在这些应用中，鲁棒和连续的定位是必不可少的。为了测试和提高算法的性能，一些研究机构和公司陆续构建并公开发布了数据集。然而，现有数据集在传感器多样性和环境覆盖方面仍然存在局限性。为了解决这些缺点并推动相关领域的发展，SmartPNT多源集成导航、定位和姿态数据集已被开发。该数据集集成了来自全球导航卫星系统（GNSS）、惯性测量单元（IMU）、光学相机和激光雷达（LiDAR）等多种传感器的数据，为多传感器融合和高精度导航研究提供了丰富多样的资源。数据集的构建过程被彻底记录，包括传感器配置、坐标系定义以及相机和激光雷达的校准程序。数据收集和处理的标准化框架确保了一致性和可扩展性，从而能够进行大规模分析。使用VINS-Mono和LIO-SAM等最先进的同步定位与建图（SLAM）算法进行验证，证明了该数据集适用于高级导航研究。该数据集涵盖了广泛的真实世界场景，包括城市区域、校园、隧道和郊区环境，为推进导航技术和解决复杂环境中的挑战提供了宝贵工具。通过提供一个可公开访问、高质量的数据集，这项工作旨在弥合传感器多样性、数据可访问性和环境表示方面的差距，从而促进该领域的进一步创新。", "summary": "SmartPNT-MSF是一个新的多传感器融合数据集，旨在解决现有定位和导航数据集在传感器多样性和环境覆盖方面的局限性。它整合了GNSS、IMU、相机和LiDAR等多种传感器数据，并详细记录了构建过程和校准程序。该数据集通过先进SLAM算法验证，涵盖多种真实场景，为高精度导航研究提供了高质量和可扩展的资源，旨在推动该领域的创新。", "keywords": "多传感器融合, 定位导航, 数据集, GNSS, IMU, LiDAR, 相机, SLAM", "comments": "SmartPNT-MSF数据集的创新之处在于其解决了现有数据集在传感器多样性和环境覆盖方面的不足，通过整合多种异构传感器数据并涵盖广泛的真实世界场景，为高精度定位和导航研究提供了更全面和鲁棒的测试平台。其标准化构建和验证过程也增强了数据集的可用性和可靠性，对自动驾驶和移动测绘等领域的算法开发具有重要意义。"}}
{"id": "2507.23297", "title": "Simulation-based inference for Precision Neutrino Physics through Neural Monte Carlo tuning", "authors": ["A. Gavrikov", "A. Serafini", "D. Dolzhikov", "A. Garfagnini", "M. Gonchar", "M. Grassi", "R. Brugnera", "V. Cerrone", "L. V. D'Auria", "R. M. Guizzetti", "L. Lastrucci", "G. Andronico", "V. Antonelli", "A. Barresi", "D. Basilico", "M. Beretta", "A. Bergnoli", "M. Borghesi", "A. Brigatti", "R. Bruno", "A. Budano", "B. Caccianiga", "A. Cammi", "R. Caruso", "D. Chiesa", "C. Clementi", "C. Coletta", "S. Dusini", "A. Fabbri", "G. Felici", "G. Ferrante", "M. G. Giammarchi", "N. Giudice", "N. Guardone", "F. Houria", "C. Landini", "I. Lippi", "L. Loi", "P. Lombardi", "F. Mantovani", "S. M. Mari", "A. Martini", "L. Miramonti", "M. Montuschi", "M. Nastasi", "D. Orestano", "F. Ortica", "A. Paoloni", "L. Pelicci", "E. Percalli", "F. Petrucci", "E. Previtali", "G. Ranucci", "A. C. Re", "B. Ricci", "A. Romani", "C. Sirignano", "M. Sisti", "L. Stanco", "E. Stanescu Farilla", "V. Strati", "M. D. C Torri", "C. Tuvè", "C. Venettacci", "G. Verde", "L. Votano"], "categories": ["physics.data-an", "cs.LG", "hep-ex", "hep-ph", "physics.ins-det"], "primary_category": "Subjects:       Data Analysis, Statistics and Probability (physics.data-an)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23297v1", "summary": "Precise modeling of detector energy response is crucial for next-generation\nneutrino experiments which present computational challenges due to lack of\nanalytical likelihoods. We propose a solution using neural likelihood\nestimation within the simulation-based inference framework. We develop two\ncomplementary neural density estimators that model likelihoods of calibration\ndata: conditional normalizing flows and a transformer-based regressor. We adopt\nJUNO - a large neutrino experiment - as a case study. The energy response of\nJUNO depends on several parameters, all of which should be tuned, given their\nnon-linear behavior and strong correlations in the calibration data. To this\nend, we integrate the modeled likelihoods with Bayesian nested sampling for\nparameter inference, achieving uncertainties limited only by statistics with\nnear-zero systematic biases. The normalizing flows model enables unbinned\nlikelihood analysis, while the transformer provides an efficient binned\nalternative. By providing both options, our framework offers flexibility to\nchoose the most appropriate method for specific needs. Finally, our approach\nestablishes a template for similar applications across experimental neutrino\nand broader particle physics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23297v1", "cate": "physics.data-an", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "通过神经蒙特卡洛调优进行精确中微子物理的基于模拟的推断", "tldr": "本文提出了一种基于模拟推断的神经似然估计框架，用于精确中微子实验中的探测器能量响应建模，通过使用条件归一化流和Transformer模型，结合贝叶斯嵌套采样，实现了高精度参数推断。", "motivation": "下一代中微子实验中探测器能量响应的精确建模至关重要，但由于缺乏解析似然，这带来了计算挑战。", "method": "提出了一种在模拟推断框架内使用神经似然估计的解决方案。开发了两种互补的神经密度估计器：条件归一化流和基于Transformer的回归器，用于建模校准数据的似然。将建模的似然与贝叶斯嵌套采样相结合进行参数推断。", "result": "实现了仅受统计限制的不确定性，系统偏差接近于零。归一化流模型支持非分箱似然分析，而Transformer提供了高效的分箱替代方案。", "conclusion": "该方法为实验中微子物理和更广泛的粒子物理领域的类似应用建立了模板。", "translation": "探测器能量响应的精确建模对于下一代中微子实验至关重要，但由于缺乏解析似然，这带来了计算挑战。我们提出了一种在基于模拟的推断框架内使用神经似然估计的解决方案。我们开发了两种互补的神经密度估计器来建模校准数据的似然：条件归一化流和基于Transformer的回归器。我们以大型中微子实验JUNO为例。JUNO的能量响应取决于几个参数，鉴于它们的非线性行为和校准数据中的强相关性，所有这些参数都应该被调整。为此，我们将建模的似然与贝叶斯嵌套采样相结合进行参数推断，实现了仅受统计限制的不确定性，系统偏差接近于零。归一化流模型支持非分箱似然分析，而Transformer提供了高效的分箱替代方案。通过提供这两种选择，我们的框架提供了灵活性，可以选择最适合特定需求的方法。最后，我们的方法为实验中微子和更广泛的粒子物理领域的类似应用建立了模板。", "summary": "本文提出了一种基于模拟推断的神经似然估计框架，旨在解决下一代中微子实验中探测器能量响应建模的计算挑战。该框架利用条件归一化流和基于Transformer的回归器来建模校准数据似然，并结合贝叶斯嵌套采样进行参数推断。在JUNO实验中的应用表明，该方法能够实现仅受统计限制的不确定性和接近零的系统偏差，同时提供了非分箱和分箱分析的灵活选择，为粒子物理领域的类似应用提供了通用模板。", "keywords": "中微子物理, 模拟推断, 神经似然估计, 归一化流, Transformer", "comments": "该论文的创新点在于将神经似然估计引入到中微子物理的模拟推断中，有效解决了传统方法中解析似然缺乏导致的计算难题。通过结合条件归一化流和Transformer模型，并与贝叶斯嵌套采样集成，实现了高精度和低系统偏差的参数推断。其提出的框架具有通用性，可为其他粒子物理实验提供借鉴。"}}
{"id": "2505.07797", "title": "A Theoretical Framework for Explaining Reinforcement Learning with Shapley Values", "authors": ["Daniel Beechey", "Thomas M. S. Smith", "Özgür Şimşek"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.07797v2", "summary": "Reinforcement learning agents can achieve super-human performance in complex\ndecision-making tasks, but their behaviour is often difficult to understand and\nexplain. This lack of explanation limits deployment, especially in\nsafety-critical settings where understanding and trust are essential. We\nidentify three core explanatory targets that together provide a comprehensive\nview of reinforcement learning agents: behaviour, outcomes, and predictions. We\ndevelop a unified theoretical framework for explaining these three elements of\nreinforcement learning agents through the influence of individual features that\nthe agent observes in its environment. We derive feature influences by using\nShapley values, which collectively and uniquely satisfy a set of well-motivated\naxioms for fair and consistent credit assignment. The proposed approach,\nShapley Values for Explaining Reinforcement Learning (SVERL), provides a single\ntheoretical framework to comprehensively and meaningfully explain reinforcement\nlearning agents. It yields explanations with precise semantics that are not\nonly interpretable but also mathematically justified, enabling us to identify\nand correct conceptual issues in prior explanations. Through illustrative\nexamples, we show how SVERL produces useful, intuitive explanations of agent\nbehaviour, outcomes, and predictions, which are not apparent from observing\nagent behaviour alone.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.07797v2", "cate": "cs.LG", "date": "2025-05-12", "updated": "2025-07-31", "AI": {"title_translation": "使用Shapley值解释强化学习的理论框架", "tldr": "本文提出了SVERL，一个使用Shapley值解释强化学习智能体行为、结果和预测的统一理论框架，旨在提高可理解性和信任度。", "motivation": "强化学习智能体的行为难以理解和解释，这限制了它们在安全关键等场景中的部署，因为理解和信任至关重要。", "method": "作者识别了行为、结果和预测这三个核心解释目标，并开发了一个统一的理论框架，通过智能体观察到的环境中个体特征的影响来解释这些元素。该方法使用Shapley值来推导特征影响，并提出了SVERL（Shapley Values for Explaining Reinforcement Learning）方法。", "result": "SVERL提供了一个单一的理论框架，能够全面且有意义地解释强化学习智能体。它产生的解释具有精确的语义，不仅可解释，而且在数学上是合理的，从而能够识别和纠正先前解释中的概念问题。通过示例，SVERL能够生成对智能体行为、结果和预测有用且直观的解释。", "conclusion": "SVERL提供了一个统一且数学上合理的理论框架，用于全面解释强化学习智能体的行为、结果和预测，从而提高了可解释性和信任度。", "translation": "强化学习智能体能够在复杂的决策任务中实现超人类的表现，但它们的行为通常难以理解和解释。这种解释的缺乏限制了部署，尤其是在理解和信任至关重要的安全关键环境中。我们确定了三个核心解释目标，它们共同提供了强化学习智能体的全面视图：行为、结果和预测。我们开发了一个统一的理论框架，通过智能体在其环境中观察到的个体特征的影响来解释强化学习智能体的这三个元素。我们通过使用Shapley值推导出特征影响，这些Shapley值共同且独特地满足了一组良好动机的公理，以实现公平和一致的信用分配。所提出的方法，即用于解释强化学习的Shapley值（SVERL），提供了一个单一的理论框架，可以全面且有意义地解释强化学习智能体。它产生的解释具有精确的语义，不仅可解释，而且在数学上是合理的，使我们能够识别和纠正先前解释中的概念问题。通过说明性示例，我们展示了SVERL如何产生对智能体行为、结果和预测的有用、直观的解释，这些解释仅通过观察智能体行为是无法显现的。", "summary": "本文提出了一种名为SVERL（Shapley Values for Explaining Reinforcement Learning）的统一理论框架，旨在解决强化学习智能体行为难以理解和解释的问题。该框架通过利用Shapley值来量化环境中个体特征对智能体行为、结果和预测的影响，从而提供全面、有意义且数学上合理的解释。SVERL能够生成直观的解释，有助于提高对RL智能体的信任和理解，尤其是在安全关键应用中。", "keywords": "强化学习, 可解释性, Shapley值, 理论框架, 信用分配", "comments": "本文的创新之处在于提出了一个统一的理论框架SVERL，它将强化学习的可解释性提升到一个新的水平。通过引入Shapley值，SVERL不仅提供了行为、结果和预测的综合解释，还确保了这些解释的数学合理性和可信度。这对于RL在安全关键领域的应用至关重要，因为它弥补了现有解释方法的不足，有助于建立对复杂RL系统的信任。"}}
{"id": "2507.23118", "title": "FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering", "authors": ["Mattia Di Profio", "Mingjun Zhong", "Yaji Sripada", "Marcel Jaspars"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23118v1", "summary": "The Extract, Transform, Load (ETL) workflow is fundamental for populating and\nmaintaining data warehouses and other data stores accessed by analysts for\ndownstream tasks. A major shortcoming of modern ETL solutions is the extensive\nneed for a human-in-the-loop, required to design and implement\ncontext-specific, and often non-generalisable transformations. While related\nwork in the field of ETL automation shows promising progress, there is a lack\nof solutions capable of automatically designing and applying these\ntransformations. We present FlowETL, a novel example-based autonomous ETL\npipeline architecture designed to automatically standardise and prepare input\ndatasets according to a concise, user-defined target dataset. FlowETL is an\necosystem of components which interact together to achieve the desired outcome.\nA Planning Engine uses a paired input-output datasets sample to construct a\ntransformation plan, which is then applied by an ETL worker to the source\ndataset. Monitoring and logging provide observability throughout the entire\npipeline. The results show promising generalisation capabilities across 14\ndatasets of various domains, file structures, and file sizes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23118v1", "cate": "cs.SE", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "FlowETL：一个自主的示例驱动数据工程管道", "tldr": "现有的ETL解决方案需要大量人工干预来设计转换。FlowETL是一个新颖的、基于示例的自主ETL管道，能够自动设计和应用数据转换，并在多样化数据集上展现出良好的泛化能力。", "motivation": "现代ETL解决方案需要大量人工干预来设计和实现特定上下文且通常不可推广的数据转换。尽管ETL自动化有进展，但仍缺乏能够自动设计和应用这些转换的解决方案。", "method": "FlowETL是一种新颖的基于示例的自主ETL管道架构。它包含一个规划引擎，该引擎使用成对的输入-输出数据集样本来构建转换计划，然后由ETL工作器将此计划应用于源数据集。整个管道通过监控和日志记录提供可观测性。", "result": "FlowETL在14个不同领域、文件结构和文件大小的数据集上显示出良好的泛化能力。", "conclusion": "FlowETL成功地提供了一种自主的、基于示例的ETL管道，能够自动设计和应用数据转换，从而显著减少了ETL工作流中的人工干预并提高了泛化能力。", "translation": "提取、转换、加载（ETL）工作流对于填充和维护数据仓库以及分析师用于下游任务的其他数据存储至关重要。现代ETL解决方案的一个主要缺点是需要大量的人工干预，以设计和实现特定于上下文且通常不可推广的转换。尽管ETL自动化领域的相关工作显示出有希望的进展，但仍缺乏能够自动设计和应用这些转换的解决方案。我们提出了FlowETL，一种新颖的基于示例的自主ETL管道架构，旨在根据简洁的用户定义目标数据集自动标准化和准备输入数据集。FlowETL是一个组件生态系统，这些组件相互作用以实现预期结果。规划引擎使用成对的输入-输出数据集样本来构建转换计划，然后由ETL工作器将其应用于源数据集。监控和日志记录在整个管道中提供可观测性。结果显示在14个不同领域、文件结构和文件大小的数据集上具有良好的泛化能力。", "summary": "FlowETL是一种新颖的自主ETL管道架构，旨在解决传统ETL流程中人工干预过多、转换难以泛化的问题。它通过示例驱动的方式，利用规划引擎从输入-输出样本中自动生成转换计划，并由ETL工作器执行，实现了数据标准化和准备的自动化。实验结果表明，FlowETL在多样化的数据集上展现出良好的泛化能力。", "keywords": "ETL自动化, 数据工程, 示例驱动, 数据转换, 管道", "comments": "FlowETL的创新点在于其示例驱动的自主转换设计，显著减少了ETL流程中对人工的依赖，提高了效率和泛化性。这对于数据工程领域是一个重要的进步，有望加速数据仓库的构建和维护，降低数据准备的门槛。"}}
{"id": "2407.08722", "title": "Controlling diverse robots by inferring Jacobian fields with deep networks", "authors": ["Sizhe Lester Li", "Annan Zhang", "Boyuan Chen", "Hanna Matusik", "Chao Liu", "Daniela Rus", "Vincent Sitzmann"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2407.08722v2", "summary": "Mirroring the complex structures and diverse functions of natural organisms\nis a long-standing challenge in robotics. Modern fabrication techniques have\ngreatly expanded the feasible hardware, but using these systems requires\ncontrol software to translate the desired motions into actuator commands.\nConventional robots can easily be modeled as rigid links connected by joints,\nbut it remains an open challenge to model and control biologically inspired\nrobots that are often soft or made of several materials, lack sensing\ncapabilities, and may change their material properties with use. Here, we\nintroduce a method that uses deep neural networks to map a video stream of a\nrobot to its visuomotor Jacobian field (the sensitivity of all 3D points to the\nrobot's actuators). Our method enables the control of robots from only a single\ncamera, makes no assumptions about the robots' materials, actuation, or\nsensing, and is trained without expert intervention by observing the execution\nof random commands. We demonstrate our method on a diverse set of robot\nmanipulators that vary in actuation, materials, fabrication, and cost. Our\napproach achieves accurate closed-loop control and recovers the causal dynamic\nstructure of each robot. Because it enables robot control using a generic\ncamera as the only sensor, we anticipate that our work will broaden the design\nspace of robotic systems and serve as a starting point for lowering the barrier\nto robotic automation.", "comment": "Project Page:\n  https://sizhe-li.github.io/publication/neural_jacobian_field", "pdf_url": "http://arxiv.org/pdf/2407.08722v2", "cate": "cs.RO", "date": "2024-07-11", "updated": "2025-07-30", "AI": {"title_translation": "利用深度网络推断雅可比场来控制多种机器人", "tldr": "该研究提出一种使用深度神经网络从视频流中映射机器人到其视觉运动雅可比场的方法，从而仅用单个摄像头实现对多种机器人的控制，无需预设机器人材料、驱动或传感信息，并通过观察随机指令的执行进行训练。", "motivation": "机器人领域长期面临如何模仿自然生物复杂结构和多样化功能的挑战。现代制造技术极大地扩展了硬件的可行性，但控制软件不足以将所需运动转化为执行器指令。传统机器人易于建模，但对仿生机器人（通常是软性或多材料、缺乏传感能力且材料特性可能随使用而变化）进行建模和控制仍然是一个开放的挑战。", "method": "该方法使用深度神经网络将机器人的视频流映射到其视觉运动雅可比场（即所有三维点对机器人执行器的敏感度）。该方法仅通过单个摄像头实现机器人控制，不假设机器人的材料、驱动或传感特性，并通过观察随机指令的执行进行训练，无需专家干预。", "result": "该方法在不同驱动、材料、制造和成本的多种机器人机械手上进行了验证，实现了准确的闭环控制，并恢复了每个机器人的因果动态结构。", "conclusion": "该工作通过使用通用摄像头作为唯一传感器实现机器人控制，有望拓大机器人系统的设计空间，并作为降低机器人自动化门槛的起点。", "translation": "模仿自然生物的复杂结构和多样化功能是机器人领域长期存在的挑战。现代制造技术极大地扩展了硬件的可行性，但使用这些系统需要控制软件将所需的运动转化为执行器命令。传统机器人可以很容易地建模为由关节连接的刚性连杆，但对通常是软性或由多种材料制成、缺乏传感能力并且其材料特性可能随使用而变化的仿生机器人进行建模和控制仍然是一个开放的挑战。在此，我们介绍一种使用深度神经网络将机器人视频流映射到其视觉运动雅可比场（所有三维点对机器人执行器的敏感度）的方法。我们的方法仅通过单个摄像头即可控制机器人，对机器人的材料、驱动或传感不作任何假设，并且通过观察随机命令的执行进行训练，无需专家干预。我们在各种驱动、材料、制造和成本不同的机器人机械手上演示了我们的方法。我们的方法实现了准确的闭环控制，并恢复了每个机器人的因果动态结构。因为它使机器人控制能够使用通用摄像头作为唯一传感器，我们预计我们的工作将拓宽机器人系统的设计空间，并作为降低机器人自动化门槛的起点。", "summary": "该论文提出一种利用深度神经网络通过视频流推断机器人视觉运动雅可比场的新方法，实现了仅用单个通用摄像头对多种复杂机器人（包括软体和多材料机器人）进行闭环控制。该方法无需预设机器人模型、材料或传感信息，也无需专家干预，仅通过观察随机指令的执行进行训练。实验证明其能有效控制不同类型机器人，并恢复其动态结构，有望降低机器人自动化门槛并拓宽设计空间。", "keywords": "机器人控制, 深度学习, 雅可比场, 视觉运动, 仿生机器人", "comments": "该研究的创新之处在于利用深度神经网络从视觉数据中直接学习机器人的雅可比场，从而实现了对传统难以建模的复杂机器人（如仿生软体机器人）的通用控制。其重要性在于大大降低了机器人控制的门槛，仅需一个普通摄像头即可实现控制，且无需预设模型和专家干预，有望推动机器人设计和自动化领域的进步。"}}
{"id": "2507.23607", "title": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "authors": ["Tien Huu Do", "Antoine Masquelier", "Nae Eoun Lee", "Jonathan Crowther"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23607v1", "summary": "Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23607v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于深度学习的临床试验招募预测及不确定性估计", "tldr": "本文提出了一种新颖的深度学习方法，利用预训练语言模型和概率层来预测临床试验患者招募，并提供不确定性估计，在真实世界数据上表现优于现有基线模型。", "motivation": "临床试验需要大量资金和精心规划，准确预测试验结果至关重要。患者招募是试验成功的关键因素之一，但在规划阶段面临主要挑战。因此，需要一种有效的方法来准确预测患者招募情况。", "method": "本文提出了一种基于深度学习的新型方法，通过神经网络模型实现。该方法利用预训练语言模型（PLMs）捕捉临床文档的复杂性和细微差别，将其转化为富有表现力的表示。这些表示随后通过注意力机制与编码的表格特征相结合。为了解释招募预测中的不确定性，模型通过基于Gamma分布的概率层进行了增强，从而实现范围估计。该模型应用于预测临床试验持续时间，假设站点级别的招募遵循泊松-伽马过程。", "result": "在真实世界临床试验数据上进行了广泛的实验，结果表明，所提出的方法能够有效地预测给定临床试验在多个站点招募的患者数量，并且优于已建立的基线模型。", "conclusion": "本文提出的基于深度学习的方法能够有效且准确地预测临床试验的患者招募情况，并提供不确定性估计，解决了临床试验规划中的关键挑战。", "translation": "临床试验是评估新药或新疗法安全性与有效性的系统性工作。开展此类试验通常需要大量的资金投入和精密的规划，这突显了准确预测试验结果的必要性。准确预测患者招募是试验成功的关键因素，也是规划阶段的主要挑战之一。在这项工作中，我们提出了一种新颖的基于深度学习的方法来解决这一关键挑战。我们的方法以神经网络模型实现，利用预训练语言模型（PLMs）捕捉临床文档的复杂性和细微差别，将其转化为富有表现力的表示。这些表示随后通过注意力机制与编码的表格特征相结合。为了解释招募预测中的不确定性，我们通过基于Gamma分布的概率层增强了模型，从而实现范围估计。我们将所提出的模型应用于预测临床试验持续时间，假设站点级别的招募遵循泊松-伽马过程。我们在真实世界临床试验数据上进行了广泛的实验，结果表明所提出的方法能够有效地预测给定临床试验在多个站点招募的患者数量，并且优于已建立的基线模型。", "summary": "本文提出了一种基于深度学习的新颖方法，用于预测临床试验的患者招募数量。该方法利用预训练语言模型处理临床文档，并通过注意力机制与表格特征结合。为量化预测不确定性，模型引入了基于Gamma分布的概率层。实验表明，该模型在真实世界数据上能有效预测患者招募，并超越现有基线模型，有助于解决临床试验规划中的关键挑战。", "keywords": "深度学习, 临床试验, 患者招募预测, 不确定性估计, 预训练语言模型", "comments": "本文的创新之处在于将深度学习与预训练语言模型相结合，用于临床试验患者招募预测，并引入概率层以提供不确定性估计，这对于实际应用中的风险评估至关重要。该方法解决了临床试验规划中的一个关键挑战，有望提高试验效率和成功率。"}}
{"id": "2507.23483", "title": "Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion", "authors": ["Mutian Xu", "Chongjie Ye", "Haolin Liu", "Yushuang Wu", "Jiahao Chang", "Xiaoguang Han"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (Highlight). Project page: this https URL", "url": "http://arxiv.org/abs/2507.23483v1", "summary": "3D data simulation aims to bridge the gap between simulated and real-captured\n3D data, which is a fundamental problem for real-world 3D visual tasks. Most 3D\ndata simulation methods inject predefined physical priors but struggle to\ncapture the full complexity of real data. An optimal approach involves learning\nan implicit mapping from synthetic to realistic data in a data-driven manner,\nbut progress in this solution has met stagnation in recent studies. This work\nexplores a new solution path of data-driven 3D simulation, called\nStable-Sim2Real, based on a novel two-stage depth diffusion model. The initial\nstage finetunes Stable-Diffusion to generate the residual between the real and\nsynthetic paired depth, producing a stable but coarse depth, where some local\nregions may deviate from realistic patterns. To enhance this, both the\nsynthetic and initial output depth are fed into a second-stage diffusion, where\ndiffusion loss is adjusted to prioritize these distinct areas identified by a\n3D discriminator. We provide a new benchmark scheme to evaluate 3D data\nsimulation methods. Extensive experiments show that training the network with\nthe 3D simulated data derived from our method significantly enhances\nperformance in real-world 3D visual tasks. Moreover, the evaluation\ndemonstrates the high similarity between our 3D simulated data and\nreal-captured patterns. Project page:\nhttps://mutianxu.github.io/stable-sim2real/.", "comment": "ICCV 2025 (Highlight). Project page:\n  https://mutianxu.github.io/stable-sim2real/", "pdf_url": "http://arxiv.org/pdf/2507.23483v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "稳定Sim2Real：探索基于两阶段深度扩散的真实捕获3D数据模拟", "tldr": "Stable-Sim2Real提出一种新型两阶段深度扩散模型，用于数据驱动的3D数据模拟，有效缩小了模拟与真实3D数据之间的差距，并显著提升了真实世界3D视觉任务的性能。", "motivation": "现有3D数据模拟方法难以捕捉真实数据的复杂性，且数据驱动的隐式映射方法在近期研究中进展停滞，导致模拟与真实3D数据之间存在鸿沟，这对于真实世界的3D视觉任务是一个基础性难题。", "method": "本工作提出Stable-Sim2Real，一种基于新型两阶段深度扩散模型的数据驱动3D模拟方案。第一阶段微调Stable-Diffusion以生成真实与合成配对深度之间的残差，从而产生稳定但可能存在局部偏差的粗糙深度。第二阶段将合成深度和第一阶段的输出深度一同输入到扩散模型中，并通过一个3D判别器识别并优先处理那些偏离真实模式的区域，相应调整扩散损失以进行增强。此外，该工作还提供了一种新的3D数据模拟方法评估基准。", "result": "实验表明，使用我们方法生成的3D模拟数据训练网络显著提升了真实世界3D视觉任务的性能。评估还显示，我们生成的3D模拟数据与真实捕获的模式具有高度相似性。", "conclusion": "Stable-Sim2Real通过其创新的两阶段深度扩散模型，成功实现了高质量的数据驱动3D数据模拟，有效弥合了模拟与真实数据之间的差距，并显著提升了3D视觉任务在真实世界中的表现。", "translation": "3D数据模拟旨在弥合模拟与真实捕获的3D数据之间的鸿沟，这是真实世界3D视觉任务的一个基础性问题。大多数3D数据模拟方法注入预定义的物理先验，但难以捕捉真实数据的全部复杂性。一个最优的方法涉及以数据驱动的方式学习从合成数据到真实数据的隐式映射，但该解决方案的进展在近期研究中停滞不前。这项工作探索了一种新的数据驱动3D模拟解决方案路径，称为Stable-Sim2Real，它基于一种新颖的两阶段深度扩散模型。初始阶段微调Stable-Diffusion以生成真实与合成配对深度之间的残差，产生稳定但粗糙的深度，其中一些局部区域可能偏离真实模式。为了增强这一点，合成深度和初始输出深度都被输入到第二阶段扩散中，其中扩散损失被调整以优先处理由3D判别器识别出的这些不同区域。我们提供了一种新的基准方案来评估3D数据模拟方法。大量实验表明，使用我们方法得出的3D模拟数据训练网络显著增强了真实世界3D视觉任务的性能。此外，评估表明我们的3D模拟数据与真实捕获模式之间具有高度相似性。项目页面：https://mutianxu.github.io/stable-sim2real/。", "summary": "Stable-Sim2Real提出一种新颖的两阶段深度扩散模型，旨在解决3D数据模拟中模拟与真实数据之间的鸿沟问题。该方法首先微调Stable-Diffusion生成粗糙深度残差，然后通过第二阶段扩散和3D判别器进一步细化局部区域，以捕捉真实数据的复杂性。实验证明，该方法生成的3D模拟数据与真实模式高度相似，并且能显著提升真实世界3D视觉任务的性能。", "keywords": "3D数据模拟, 深度扩散, Sim2Real, 数据驱动, Stable-Diffusion", "comments": "该论文的创新点在于提出了一个新颖的两阶段深度扩散模型Stable-Sim2Real，用于数据驱动的3D数据模拟。它通过结合Stable-Diffusion进行初始深度残差生成，并引入3D判别器在第二阶段精细化局部区域，有效解决了现有数据驱动方法在捕捉真实数据复杂性方面的停滞问题。这对于提升真实世界3D视觉任务的性能具有重要意义。"}}
{"id": "2411.04351", "title": "LidaRefer: Context-aware Outdoor 3D Visual Grounding for Autonomous Driving", "authors": ["Yeong-Seung Baek", "Heung-Seon Oh"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures", "url": "http://arxiv.org/abs/2411.04351v2", "summary": "3D visual grounding (VG) aims to locate objects or regions within 3D scenes\nguided by natural language descriptions. While indoor 3D VG has advanced,\noutdoor 3D VG remains underexplored due to two challenges: (1) large-scale\noutdoor LiDAR scenes are dominated by background points and contain limited\nforeground information, making cross-modal alignment and contextual\nunderstanding more difficult; and (2) most outdoor datasets lack spatial\nannotations for referential non-target objects, which hinders explicit learning\nof referential context. To this end, we propose LidaRefer, a context-aware 3D\nVG framework for outdoor scenes. LidaRefer incorporates an object-centric\nfeature selection strategy to focus on semantically relevant visual features\nwhile reducing computational overhead. Then, its transformer-based\nencoder-decoder architecture excels at establishing fine-grained cross-modal\nalignment between refined visual features and word-level text features, and\ncapturing comprehensive global context. Additionally, we present\nDiscriminative-Supportive Collaborative localization (DiSCo), a novel\nsupervision strategy that explicitly models spatial relationships between\ntarget, contextual, and ambiguous objects for accurate target identification.\nTo enable this without manual labeling, we introduce a pseudo-labeling approach\nthat retrieves 3D localization labels for referential non-target objects.\nLidaRefer achieves state-of-the-art performance on Talk2Car-3D dataset under\nvarious evaluation settings.", "comment": "18 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2411.04351v2", "cate": "cs.CV", "date": "2024-11-07", "updated": "2025-07-31", "AI": {"title_translation": "LidaRefer：面向自动驾驶的上下文感知户外3D视觉定位", "tldr": "LidaRefer是一个针对户外3D视觉定位的框架，它通过对象中心特征选择、Transformer编码器-解码器架构和DiSCo监督策略来解决大规模户外场景中上下文理解和非目标对象空间标注不足的问题，并在Talk2Car-3D数据集上取得了最先进的性能。", "motivation": "现有的室内3D视觉定位技术已取得进展，但户外3D视觉定位仍未充分探索，主要面临两大挑战：一是大规模户外LiDAR场景背景点多、前景信息少，导致跨模态对齐和上下文理解困难；二是多数户外数据集缺乏参照性非目标对象的空间标注，阻碍了参照上下文的显式学习。", "method": "本文提出了LidaRefer，一个上下文感知的户外3D视觉定位框架。LidaRefer采用对象中心特征选择策略来关注语义相关的视觉特征并降低计算开销。其基于Transformer的编码器-解码器架构擅长在精炼的视觉特征和词级文本特征之间建立细粒度跨模态对齐，并捕获全面的全局上下文。此外，还提出了判别-支持协同定位（DiSCo）这一新颖的监督策略，显式建模目标、上下文和模糊对象之间的空间关系以实现准确的目标识别。为避免手动标注，引入了一种伪标注方法来检索参照性非目标对象的3D定位标签。", "result": "LidaRefer在Talk2Car-3D数据集上，在各种评估设置下均取得了最先进的性能。", "conclusion": "本文提出的LidaRefer框架及其创新的DiSCo监督策略和伪标注方法，有效解决了户外3D视觉定位中上下文理解和参照性非目标对象标注不足的挑战，并在实际数据集中展现出卓越的性能，推动了自动驾驶领域3D视觉定位技术的发展。", "translation": "3D视觉定位（VG）旨在根据自然语言描述在3D场景中定位对象或区域。虽然室内3D VG已经取得了进展，但户外3D VG由于两个挑战而仍未得到充分探索：(1) 大规模户外LiDAR场景主要由背景点组成，前景信息有限，使得跨模态对齐和上下文理解更加困难；(2) 大多数户外数据集缺乏参照性非目标对象的空间标注，这阻碍了参照上下文的显式学习。为此，我们提出了LidaRefer，一个用于户外场景的上下文感知3D VG框架。LidaRefer采用对象中心特征选择策略，以关注语义相关的视觉特征，同时减少计算开销。然后，其基于Transformer的编码器-解码器架构擅长在精炼的视觉特征和词级文本特征之间建立细粒度跨模态对齐，并捕获全面的全局上下文。此外，我们提出了判别-支持协同定位（DiSCo），一种新颖的监督策略，它明确建模目标、上下文和模糊对象之间的空间关系，以实现准确的目标识别。为了在没有手动标注的情况下实现这一点，我们引入了一种伪标注方法，该方法检索参照性非目标对象的3D定位标签。LidaRefer在Talk2Car-3D数据集的各种评估设置下均取得了最先进的性能。", "summary": "本文提出了LidaRefer，一个针对户外3D视觉定位的上下文感知框架。该框架旨在解决大规模户外LiDAR场景中上下文理解困难以及参照性非目标对象空间标注缺失的问题。LidaRefer通过对象中心特征选择来聚焦关键视觉信息，并利用Transformer编码器-解码器架构实现精细的跨模态对齐和全局上下文捕获。此外，其引入的Discriminative-Supportive Collaborative localization (DiSCo)监督策略结合伪标注方法，有效建模目标与上下文对象间的空间关系，无需手动标注即可提升定位精度。LidaRefer在Talk2Car-3D数据集上展现出最先进的性能。", "keywords": "3D视觉定位, 户外场景, 上下文感知, 自动驾驶, 伪标注", "comments": "LidaRefer的创新点在于其针对户外3D视觉定位的特定挑战，提出了多方面的解决方案。首先，对象中心特征选择有效应对了户外场景背景点过多的问题。其次，Transformer架构的引入提升了跨模态对齐和上下文理解能力。最重要的是，DiSCo监督策略结合伪标注方法，巧妙地解决了参照性非目标对象标注缺失的难题，这对于理解复杂自然语言描述中的空间关系至关重要，极大地降低了数据标注成本，具有重要的实际应用价值。"}}
{"id": "2507.23664", "title": "Personalized Education with Ranking Alignment Recommendation", "authors": ["Haipeng Liu", "Yuxuan Liu", "Ting Long"], "categories": ["cs.AI", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23664v1", "summary": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23664v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "个性化教育与排序对齐推荐", "tldr": "提出一种名为RAR的强化学习框架，通过引入协作思想解决个性化问题推荐中探索效率低下的问题，提高推荐性能。", "motivation": "大多数现有的个性化问题推荐方法（基于马尔可夫决策过程和强化学习）在训练过程中探索效率低下，难以识别出适合每个学生的最佳问题。", "method": "提出排序对齐推荐（RAR），该方法将协作思想融入探索机制，以在有限的训练回合内实现更高效的探索。", "result": "实验表明，RAR有效地提高了推荐性能。", "conclusion": "RAR框架可以应用于任何基于强化学习的问题推荐系统，并有效提升推荐性能。", "translation": "个性化问题推荐旨在通过问题引导学生，以提高他们对学习目标的掌握。大多数以前的方法将此任务建模为马尔可夫决策过程并使用强化学习解决，但它们在高效探索方面存在困难，无法在训练期间为每个学生识别出最佳问题。为了解决这个问题，我们提出了排序对齐推荐（RAR），它将协作思想融入探索机制中，从而在有限的训练回合内实现更高效的探索。实验表明，RAR有效地提高了推荐性能，并且我们的框架可以应用于任何基于强化学习的问题推荐器。我们的代码可在https://github.com/wuming29/RAR.git获取。", "summary": "本文针对个性化问题推荐领域中现有强化学习方法探索效率低下的问题，提出了一种名为排序对齐推荐（RAR）的新框架。RAR通过将协作思想融入探索机制，显著提升了在有限训练回合内的探索效率，实验证明其有效改善了推荐性能，并且该框架可广泛应用于各类基于强化学习的问题推荐系统。", "keywords": "个性化教育, 问题推荐, 强化学习, 探索效率, 排序对齐推荐", "comments": "本文的创新点在于将协作思想引入强化学习的探索机制，以解决个性化推荐中探索效率低的问题。其重要性在于提供了一个通用的框架，可以提升现有基于强化学习的推荐系统的性能。"}}
{"id": "2507.23412", "title": "A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23412v1", "summary": "This paper aims to develop a Machine Learning (ML)-based system for detecting\nhoney adulteration utilizing honey mineral element profiles. The proposed\nsystem comprises two phases: preprocessing and classification. The\npreprocessing phase involves the treatment of missing-value attributes and\nnormalization. In the classifica-tion phase, we use three supervised ML models:\nlogistic regression, decision tree, and random forest, to dis-criminate between\nauthentic and adulterated honey. To evaluate the performance of the ML models,\nwe use a public dataset comprising measurements of mineral element content of\nauthentic honey, sugar syrups, and adul-terated honey. Experimental findings\nshow that mineral element content in honey provides robust discriminative\ninformation for detecting honey adulteration. Results also demonstrate that the\nrandom forest-based classifier outperforms other classifiers on this dataset,\nachieving the highest cross-validation accuracy of 98.37%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23412v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一种基于矿物质元素剖面的蜂蜜掺假检测机器学习方法", "tldr": "该研究开发了一种利用蜂蜜矿物质元素剖面检测蜂蜜掺假的机器学习系统，其中随机森林模型表现最佳，准确率达到98.37%。", "motivation": "本文旨在开发一个基于机器学习的系统，利用蜂蜜矿物质元素剖面来检测蜂蜜掺假。", "method": "所提出的系统包括预处理（处理缺失值和归一化）和分类两个阶段。分类阶段使用了三种监督机器学习模型：逻辑回归、决策树和随机森林。模型在一个包含真蜂蜜、糖浆和掺假蜂蜜矿物质元素含量的公共数据集上进行评估。", "result": "实验结果表明，蜂蜜中的矿物质元素含量为检测蜂蜜掺假提供了强大的判别信息。随机森林分类器在该数据集上表现最佳，达到了98.37%的最高交叉验证准确率。", "conclusion": "蜂蜜矿物质元素剖面可以有效检测掺假，并且随机森林模型是完成这项任务的高精度模型。", "translation": "本文旨在开发一个基于机器学习（ML）的系统，利用蜂蜜矿物质元素剖面来检测蜂蜜掺假。所提出的系统包括两个阶段：预处理和分类。预处理阶段涉及缺失值属性的处理和归一化。在分类阶段，我们使用三种监督机器学习模型：逻辑回归、决策树和随机森林，以区分真蜂蜜和掺假蜂蜜。为了评估ML模型的性能，我们使用了一个公共数据集，该数据集包含真蜂蜜、糖浆和掺假蜂蜜的矿物质元素含量测量值。实验结果表明，蜂蜜中的矿物质元素含量为检测蜂蜜掺假提供了强大的判别信息。结果还表明，基于随机森林的分类器在该数据集上优于其他分类器，实现了98.37%的最高交叉验证准确率。", "summary": "本文提出了一种利用蜂蜜矿物质元素剖面检测蜂蜜掺假的机器学习系统。该系统包含预处理和分类阶段，分类阶段应用了逻辑回归、决策树和随机森林模型。通过在一个公共数据集上进行实验，研究表明矿物质元素含量是检测掺假的有力指标，其中随机森林模型表现出卓越性能，交叉验证准确率达到98.37%。", "keywords": "蜂蜜掺假, 机器学习, 矿物质元素, 随机森林, 分类", "comments": "该论文展示了机器学习在食品真实性检测方面的实际应用，突出了矿物质元素分析的有效性以及随机森林模型在此类检测任务中的强大性能。其创新之处在于利用现有的矿物质数据解决了关键的质量控制问题。"}}
{"id": "2507.23326", "title": "Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation", "authors": ["Yingkai Wang", "Yaoyao Zhu", "Xiuding Cai", "Yuhao Xiao", "Haotian Wu", "Yu Yao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23326v1", "summary": "Medical image segmentation plays a crucial role in clinical workflows, but\ndomain shift often leads to performance degradation when models are applied to\nunseen clinical domains. This challenge arises due to variations in imaging\nconditions, scanner types, and acquisition protocols, limiting the practical\ndeployment of segmentation models. Unlike natural images, medical images\ntypically exhibit consistent anatomical structures across patients, with\ndomain-specific variations mainly caused by imaging conditions. This unique\ncharacteristic makes medical image segmentation particularly challenging.\n  To address this challenge, we propose a domain generalization framework\ntailored for medical image segmentation. Our approach improves robustness to\ndomain-specific variations by introducing implicit feature perturbations guided\nby domain statistics. Specifically, we employ a learnable semantic direction\nselector and a covariance-based semantic intensity sampler to modulate\ndomain-variant features while preserving task-relevant anatomical consistency.\nFurthermore, we design an adaptive consistency constraint that is selectively\napplied only when feature adjustment leads to degraded segmentation\nperformance. This constraint encourages the adjusted features to align with the\noriginal predictions, thereby stabilizing feature selection and improving the\nreliability of the segmentation.\n  Extensive experiments on two public multi-center benchmarks show that our\nframework consistently outperforms existing domain generalization approaches,\nachieving robust and generalizable segmentation performance across diverse\nclinical domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23326v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "学习语义方向用于域泛化医学图像分割中的特征增强", "tldr": "该论文提出了一种新的域泛化框架，通过学习语义方向和特征增强来解决医学图像分割中由于域偏移导致的性能下降问题，并在多中心基准测试中取得了优于现有方法的表现。", "motivation": "医学图像分割在临床工作流程中至关重要，但由于成像条件、扫描仪类型和采集协议的变化，当模型应用于未见过的临床领域时，域偏移常常导致性能下降，限制了分割模型的实际部署。与自然图像不同，医学图像通常具有一致的解剖结构，而域特异性变化主要由成像条件引起，这使得医学图像分割尤其具有挑战性。", "method": "本文提出了一种为医学图像分割量身定制的域泛化框架。该方法通过引入由域统计信息引导的隐式特征扰动来提高对域特异性变化的鲁棒性。具体来说，它采用了可学习的语义方向选择器和基于协方差的语义强度采样器来调节域变异特征，同时保留任务相关的解剖一致性。此外，还设计了一个自适应一致性约束，仅当特征调整导致分割性能下降时才选择性地应用此约束，以鼓励调整后的特征与原始预测对齐，从而稳定特征选择并提高分割的可靠性。", "result": "在两个公共多中心基准测试上进行的广泛实验表明，该框架始终优于现有的域泛化方法，在不同的临床领域实现了鲁棒且可泛化的分割性能。", "conclusion": "该研究成功开发并验证了一种新的域泛化框架，有效解决了医学图像分割中的域偏移问题，显著提高了模型在未见过的临床领域中的鲁棒性和泛化能力。", "translation": "医学图像分割在临床工作流程中扮演着关键角色，但当模型应用于未见的临床领域时，域偏移常常导致性能下降。这一挑战源于成像条件、扫描仪类型和采集协议的变化，限制了分割模型的实际部署。与自然图像不同，医学图像通常在患者之间表现出一致的解剖结构，域特异性变化主要由成像条件引起。这一独特特性使得医学图像分割特别具有挑战性。\n为了解决这一挑战，我们提出了一种专为医学图像分割设计的域泛化框架。我们的方法通过引入由域统计信息引导的隐式特征扰动来提高对域特异性变化的鲁棒性。具体来说，我们采用了一个可学习的语义方向选择器和一个基于协方差的语义强度采样器来调节域变异特征，同时保留任务相关的解剖一致性。此外，我们设计了一个自适应一致性约束，仅当特征调整导致分割性能下降时才选择性地应用此约束。此约束鼓励调整后的特征与原始预测对齐，从而稳定特征选择并提高分割的可靠性。\n在两个公共多中心基准测试上进行的广泛实验表明，我们的框架始终优于现有的域泛化方法，在不同的临床领域实现了鲁棒且可泛化的分割性能。", "summary": "本论文提出了一种针对医学图像分割的域泛化框架，旨在解决由于成像条件差异导致的模型在未见领域性能下降的问题。该方法通过引入由域统计信息引导的隐式特征扰动，并结合可学习的语义方向选择器和基于协方差的语义强度采样器来调节域变异特征，同时保持解剖结构的一致性。此外，还设计了一个自适应一致性约束，以稳定特征选择并提高分割可靠性。实验结果表明，该框架在多中心基准测试中优于现有域泛化方法，实现了更鲁棒和泛化的分割性能。", "keywords": "域泛化, 医学图像分割, 特征增强, 语义方向, 域偏移", "comments": "该论文的创新点在于提出了一个专门针对医学图像特点（解剖结构一致性，域变化主要由成像条件引起）的域泛化框架。通过学习语义方向进行特征增强，并在必要时引入自适应一致性约束，有效解决了医学图像分割中的域偏移问题，提高了模型在实际临床应用中的泛化能力和可靠性。其方法考虑了医学图像的特殊性，具有重要的实践意义。"}}
{"id": "2507.22450", "title": "Settling Weighted Token Swapping up to Algorithmic Barriers", "authors": ["Nicole Wein", "Guanyu Tony Zhang"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22450v2", "summary": "We study the weighted token swapping problem, in which we are given a graph\non $n$ vertices, $n$ weighted tokens, an initial assignment of one token to\neach vertex, and a final assignment of one token to each vertex. The goal is to\nfind a minimum-cost sequence of swaps of adjacent tokens to reach the final\nassignment from the initial assignment, where the cost is the sum over all\nswaps of the sum of the weights of the two swapped tokens. Unweighted token\nswapping has been extensively studied: it is NP-hard to approximate to a factor\nbetter than $14/13$, and there is a polynomial-time 4-approximation, along with\na tight \"barrier\" result showing that the class of locally optimal algorithms\ncannot achieve a ratio better than 4. For trees, the problem remains NP-hard to\nsolve exactly, and there is a polynomial-time 2-approximation, along with a\ntight barrier result showing that the class of $\\ell$-straying algorithms\ncannot achieve a ratio better than 2. Weighted token swapping with $\\{0,1\\}$\nweights is much harder to approximation: it is NP-hard to approximate even to a\nfactor of $(1-\\varepsilon) \\cdot \\ln n$ for any constant $\\varepsilon>0$.\nRestricting to positive weights, no approximation algorithms are known, and the\nonly known lower bounds are those inherited directly from the unweighted\nversion. We provide the first approximation algorithms for weighted token\nswapping on both trees and general graphs, along with tight barrier results.\nLetting $w$ and $W$ be the minimum and maximum token weights, our approximation\nratio is $2+2W/w$ for general graphs and $1+W/w$ for trees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22450v2", "cate": "cs.DS", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "解决加权令牌交换的算法障碍", "tldr": "本文首次为加权令牌交换问题在通用图和树上提供了近似算法，并给出了紧密的障碍结果。", "motivation": "加权令牌交换问题，特别是正权重的情况，比无权令牌交换问题更难近似，此前没有已知的近似算法，且仅有从无权版本继承的下界。本研究旨在填补这一空白，提供针对该问题的近似算法。", "method": "本文提供了加权令牌交换问题的首个近似算法，并伴随紧密的障碍结果。具体方法是设计了针对通用图和树的近似算法。", "result": "对于通用图，近似比率为 $2+2W/w$；对于树，近似比率为 $1+W/w$。其中，$w$ 和 $W$ 分别是最小和最大令牌权重。这些是首次为加权令牌交换问题提供的近似算法，并伴有紧密的障碍结果。", "conclusion": "本文成功地为加权令牌交换问题在通用图和树上提供了首次近似算法，确立了新的近似比率和紧密的障碍结果，从而推进了对这一更复杂问题的理解。", "translation": "我们研究加权令牌交换问题，其中给定一个 $n$ 个顶点的图， $n$ 个带权令牌，每个顶点一个令牌的初始分配，以及每个顶点一个令牌的最终分配。目标是找到一系列相邻令牌交换的最小成本序列，以从初始分配到达最终分配，其中成本是所有交换中两个被交换令牌的权重之和的总和。无权令牌交换已被广泛研究：将其近似到优于 $14/13$ 的因子是 NP-难的，并且存在一个多项式时间 4-近似算法，以及一个紧密的“障碍”结果表明局部最优算法无法实现优于 4 的比率。对于树，该问题仍然是精确解决的 NP-难问题，并且存在一个多项式时间 2-近似算法，以及一个紧密的障碍结果表明 $\\ell$-straying 算法无法实现优于 2 的比率。具有 \\{0,1\\} 权重的加权令牌交换更难近似：即使对于任何常数 $\\varepsilon>0$，将其近似到 $(1-\\varepsilon) \\cdot \\ln n$ 的因子也是 NP-难的。限制为正权重时，没有已知的近似算法，并且唯一已知的下界是直接从无权版本继承的。我们为树和通用图上的加权令牌交换问题提供了首个近似算法，以及紧密的障碍结果。令 $w$ 和 $W$ 分别是最小和最大令牌权重，我们的近似比率对于通用图是 $2+2W/w$，对于树是 $1+W/w$。", "summary": "本文解决了加权令牌交换问题，这是无权令牌交换的更复杂变体。尽管无权版本已有广泛研究，但加权版本，特别是正权重情况，此前缺乏近似算法。本研究首次为通用图和树上的加权令牌交换问题提供了近似算法，并给出了紧密的障碍结果。具体而言，通用图上的近似比率为 $2+2W/w$，树上的近似比率为 $1+W/w$，其中 $w$ 和 $W$ 分别是最小和最大令牌权重。", "keywords": "加权令牌交换, 近似算法, 图论, 树, 算法障碍", "comments": "该论文通过为以前未解决且更困难的令牌交换问题变体提供首个近似算法，做出了重大贡献。紧密障碍结果的引入进一步巩固了对问题复杂性极限的理解。考虑到加权令牌交换近似的难度，这些结果尤其有价值。"}}
{"id": "2504.04640", "title": "Splits! A Flexible Dataset and Evaluation Framework for Sociocultural Linguistic Investigation", "authors": ["Eylon Caplan", "Tania Chakraborty", "Dan Goldwasser"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint, under review", "url": "http://arxiv.org/abs/2504.04640v2", "summary": "Variation in language use, shaped by speakers' sociocultural background and\nspecific context of use, offers a rich lens into cultural perspectives, values,\nand opinions. However, the computational study of these Sociocultural\nLinguistic Phenomena (SLP) has often been limited to bespoke analyses of\nspecific groups or topics, hindering the pace of scientific discovery. To\naddress this, we introduce Splits!, a 9.7 million-post dataset from Reddit\ndesigned for systematic and flexible research. The dataset contains posts from\nover 53,000 users across 6 demographic groups, organized into 89 discussion\ntopics to enable comparative analysis. We validate Splits! via\nself-identification and by successfully replicating several known SLPs from\nexisting literature. We complement this dataset with a framework that leverages\nefficient retrieval methods to rapidly validate potential SLPs (PSLPs) by\nautomatically evaluating whether a given hypothesis is supported by our data.\nCrucially, to distinguish between novel and obvious insights, the framework\nincorporates a human-validated measure of a hypothesis's ``unexpectedness.'' We\ndemonstrate that the two-stage process reduces the number of statistically\nsignificant findings requiring manual inspection by a factor of 1.5-1.8x,\nstreamlining the discovery of promising phenomena for further investigation.", "comment": "Preprint, under review", "pdf_url": "http://arxiv.org/pdf/2504.04640v2", "cate": "cs.CL", "date": "2025-04-06", "updated": "2025-07-31", "AI": {"title_translation": "分裂！一个用于社会文化语言学研究的灵活数据集和评估框架", "tldr": "引入了一个Reddit数据集和评估框架Splits!，用于系统化地研究社会文化语言现象，并减少了人工验证的需求。", "motivation": "计算研究社会文化语言现象（SLP）通常局限于特定群体或主题的定制分析，这阻碍了科学发现的进展。", "method": "引入了Splits!，一个包含970万条Reddit帖子的数据集，来自超过53,000名用户和6个社会人口群体，并组织成89个讨论主题。该数据集通过自我识别和成功复制现有文献中的已知SLP进行了验证。此外，还提出了一个评估框架，利用高效检索方法自动验证潜在的SLP（PSLP），并结合了衡量假设“意外性”的人工验证指标，以区分新颖和明显的见解。", "result": "Splits!数据集通过自我识别和成功复制现有文献中的已知社会文化语言现象（SLP）得到了验证。该框架的两阶段过程将需要人工检查的统计显著发现的数量减少了1.5至1.8倍，从而简化了有前景现象的发现过程。", "conclusion": "该论文引入的Splits!数据集和评估框架有效地解决了计算研究社会文化语言现象的局限性，通过自动化和意外性衡量，显著提高了研究效率和发现新颖见解的能力。", "translation": "语言使用中的变异，由说话者的社会文化背景和特定的使用语境所塑造，为理解文化视角、价值观和观点提供了丰富的视角。然而，这些社会文化语言现象（SLP）的计算研究往往局限于对特定群体或主题的定制分析，阻碍了科学发现的步伐。为了解决这个问题，我们引入了Splits!，一个包含970万条Reddit帖子的数据集，专为系统和灵活的研究而设计。该数据集包含来自6个社会人口群体的53,000多名用户的帖子，分为89个讨论主题，以实现比较分析。我们通过自我识别和成功复制现有文献中已知的几种SLP来验证Splits!。我们用一个框架来补充这个数据集，该框架利用高效的检索方法，通过自动评估给定假设是否得到我们数据的支持，来快速验证潜在的SLP（PSLP）。至关重要的是，为了区分新颖和明显的见解，该框架纳入了对假设“意外性”进行人工验证的度量。我们证明，两阶段过程将需要人工检查的统计显著发现的数量减少了1.5-1.8倍，从而简化了有前景现象的发现，以便进行进一步调查。", "summary": "该论文介绍了Splits!，一个包含970万条Reddit帖子的数据集，旨在克服社会文化语言现象（SLP）计算研究中定制分析的局限性。该数据集涵盖了多种人口统计群体和讨论主题，并通过复制已知SLP进行了验证。同时，该研究还提出了一个评估框架，该框架利用高效检索方法自动验证假设，并引入了“意外性”指标以区分新颖发现。实验结果表明，该两阶段方法能有效减少人工验证需求，加速有前景SLP的发现。", "keywords": "社会文化语言学, 数据集, Reddit, 评估框架, 语言变异", "comments": "这篇论文通过构建一个大规模、结构化的社会文化语言数据集Splits!及其配套的评估框架，创新性地解决了当前社会文化语言学计算研究中数据和方法受限的问题。其引入的“意外性”衡量标准对于区分真正有价值的新发现和显而易见的现象至关重要，极大地提高了研究效率和成果的质量。该框架有望加速社会文化语言现象的发现和验证，对该领域具有重要意义。"}}
{"id": "2507.23589", "title": "Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study", "authors": ["Kai Goebel", "Patrik Zips"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23589v1", "summary": "Recent advancements in Large Language Models have sparked interest in their\npotential for robotic task planning. While these models demonstrate strong\ngenerative capabilities, their effectiveness in producing structured and\nexecutable plans remains uncertain. This paper presents a systematic evaluation\nof a broad spectrum of current state of the art language models, each directly\nprompted using Planning Domain Definition Language domain and problem files,\nand compares their planning performance with the Fast Downward planner across a\nvariety of benchmarks. In addition to measuring success rates, we assess how\nfaithfully the generated plans translate into sequences of actions that can\nactually be executed, identifying both strengths and limitations of using these\nmodels in this setting. Our findings show that while the models perform well on\nsimpler planning tasks, they continue to struggle with more complex scenarios\nthat require precise resource management, consistent state tracking, and strict\nconstraint compliance. These results underscore fundamental challenges in\napplying language models to robotic planning in real world environments. By\noutlining the gaps that emerge during execution, we aim to guide future\nresearch toward combined approaches that integrate language models with\nclassical planners in order to enhance the reliability and scalability of\nplanning in autonomous robotics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23589v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "LLM推理模型能否取代经典规划？一项基准研究", "tldr": "本文评估了大型语言模型在机器人任务规划中的表现，发现它们在简单任务上表现良好，但在复杂任务上仍有局限性，并建议结合LLM和经典规划器。", "motivation": "大型语言模型在机器人任务规划中的潜力引发了兴趣，但其生成结构化和可执行计划的有效性仍不确定。", "method": "系统评估了各种最先进的语言模型，直接使用PDDL领域和问题文件进行提示，并将其规划性能与Fast Downward规划器在各种基准上进行比较。除了测量成功率，还评估了生成计划转化为可执行动作序列的忠实度。", "result": "结果显示，模型在简单的规划任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束遵守的复杂场景中仍然面临困难。", "conclusion": "这些结果强调了将语言模型应用于现实世界机器人规划中的基本挑战。通过指出执行过程中出现的差距，旨在指导未来的研究转向结合语言模型和经典规划器的方法，以提高自主机器人规划的可靠性和可扩展性。", "translation": "大型语言模型（LLM）的最新进展引发了人们对其在机器人任务规划中潜力的兴趣。尽管这些模型展示出强大的生成能力，但它们在生成结构化和可执行计划方面的有效性仍不确定。本文对当前最先进的各种语言模型进行了系统评估，每个模型都直接使用规划领域定义语言（PDDL）的领域和问题文件进行提示，并将其规划性能与Fast Downward规划器在各种基准上进行了比较。除了测量成功率，我们还评估了生成的计划如何忠实地转化为实际可执行的动作序列，从而识别出在此设置中使用这些模型的优点和局限性。我们的研究结果表明，尽管这些模型在较简单的规划任务上表现良好，但它们在需要精确资源管理、一致状态跟踪和严格约束遵守的更复杂场景中仍然面临困难。这些结果强调了将语言模型应用于现实世界机器人规划中的基本挑战。通过概述执行过程中出现的差距，我们旨在指导未来的研究转向结合语言模型与经典规划器的方法，以增强自主机器人规划的可靠性和可扩展性。", "summary": "本文系统评估了大型语言模型在机器人任务规划中的能力。研究通过使用PDDL文件直接提示LLM，并将其性能与经典规划器Fast Downward进行比较，发现LLM在简单任务上表现良好，但在复杂任务中，特别是在资源管理和约束遵守方面，仍存在显著局限性。研究强调了LLM应用于实际机器人规划的挑战，并建议未来研究应探索LLM与经典规划器结合的混合方法，以提高规划的可靠性和可扩展性。", "keywords": "大型语言模型, 机器人规划, 经典规划, 基准研究, PDDL", "comments": "本文通过严格的基准测试，明确指出了大型语言模型在机器人规划领域应用的当前局限性，尤其是在复杂性和精确性方面。其创新之处在于直接使用PDDL提示LLM并与经典规划器进行对比，为LLM在实际机器人应用中的可行性提供了宝贵的见解。研究结果为未来结合LLM和经典规划器的混合方法指明了方向，具有重要的指导意义。"}}
{"id": "2507.23245", "title": "Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas", "authors": ["Lei Xie", "Jiahao Huang", "Jiawei Zhang", "Jianzhong He", "Yiang Pan", "Guoqiang Xie", "Mengjun Li", "Qingrun Zeng", "Mingchu Li", "Yuanjing Feng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23245v1", "summary": "Cranial nerves (CNs) play a crucial role in various essential functions of\nthe human brain, and mapping their pathways from diffusion MRI (dMRI) provides\nvaluable preoperative insights into the spatial relationships between\nindividual CNs and key tissues. However, mapping a comprehensive and detailed\nCN atlas is challenging because of the unique anatomical structures of each CN\npair and the complexity of the skull base environment.In this work, we present\nwhat we believe to be the first study to develop a comprehensive diffusion\ntractography atlas for automated mapping of CN pathways in the human brain. The\nCN atlas is generated by fiber clustering by using the streamlines generated by\nmulti-parametric fiber tractography for each pair of CNs. Instead of disposable\nclustering, we explore a new strategy of multi-stage fiber clustering for\nmultiple analysis of approximately 1,000,000 streamlines generated from the 50\nsubjects from the Human Connectome Project (HCP). Quantitative and visual\nexperiments demonstrate that our CN atlas achieves high spatial correspondence\nwith expert manual annotations on multiple acquisition sites, including the HCP\ndataset, the Multi-shell Diffusion MRI (MDM) dataset and two clinical cases of\npituitary adenoma patients. The proposed CN atlas can automatically identify 8\nfiber bundles associated with 5 pairs of CNs, including the optic nerve CN II,\noculomotor nerve CN III, trigeminal nerve CN V and facial-vestibulocochlear\nnerve CN VII/VIII, and its robustness is demonstrated experimentally. This work\ncontributes to the field of diffusion imaging by facilitating more efficient\nand automated mapping the pathways of multiple pairs of CNs, thereby enhancing\nthe analysis and understanding of complex brain structures through\nvisualization of their spatial relationships with nearby anatomy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23245v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "自动绘制颅神经II、III、V和VII/VIII通路：一个多参数多阶段弥散纤维束成像图谱", "tldr": "本文提出了一个首创的综合性弥散纤维束成像图谱，用于自动绘制人脑中颅神经通路的图谱，通过多参数多阶段纤维聚类方法实现了高空间对应性。", "motivation": "由于每个颅神经对独特的解剖结构和颅底环境的复杂性，绘制全面详细的颅神经图谱具有挑战性。现有的从弥散MRI（dMRI）中映射颅神经通路的方法提供了宝贵的术前见解，但缺乏一个综合性的自动化图谱。", "method": "本研究开发了一个综合性的弥散纤维束成像图谱，用于自动绘制人脑中的颅神经通路。该图谱通过对来自人类连接组计划（HCP）的50名受试者生成的近1,000,000条流线进行多参数纤维束成像，然后采用多阶段纤维聚类策略生成。", "result": "该颅神经图谱能够自动识别与5对颅神经相关的8个纤维束，包括视神经（CN II）、动眼神经（CN III）、三叉神经（CN V）以及面神经-前庭蜗神经（CN VII/VIII）。定量和视觉实验表明，该图谱在多个采集地点（包括HCP数据集、多壳弥散MRI（MDM）数据集和两个垂体腺瘤临床病例）与专家手动标注实现了高度的空间对应性，并验证了其鲁棒性。", "conclusion": "本工作通过促进更高效和自动化的多对颅神经通路绘制，为弥散成像领域做出了贡献，从而通过可视化其与附近解剖结构的空间关系，增强了对复杂大脑结构的分析和理解。", "translation": "颅神经（CNs）在人脑的各种基本功能中起着至关重要的作用，从弥散MRI（dMRI）中绘制其通路为个体颅神经与关键组织之间的空间关系提供了宝贵的术前见解。然而，由于每个颅神经对独特的解剖结构和颅底环境的复杂性，绘制全面详细的颅神经图谱具有挑战性。在这项工作中，我们提出了我们认为是第一个开发综合弥散纤维束成像图谱的研究，用于自动绘制人脑中的颅神经通路。该颅神经图谱是通过对每个颅神经对使用多参数纤维束成像生成的流线进行纤维聚类而生成的。我们没有采用一次性聚类，而是探索了一种新的多阶段纤维聚类策略，用于对来自人类连接组计划（HCP）的50名受试者生成的约1,000,000条流线进行多重分析。定量和视觉实验表明，我们的颅神经图谱在多个采集地点，包括HCP数据集、多壳弥散MRI（MDM）数据集和两个垂体腺瘤患者的临床病例，与专家手动标注实现了高空间对应性。所提出的颅神经图谱可以自动识别与5对颅神经相关的8个纤维束，包括视神经CN II、动眼神经CN III、三叉神经CN V以及面神经-前庭蜗神经CN VII/VIII，并且实验证明了其鲁棒性。这项工作通过促进更高效和自动化的多对颅神经通路绘制，为弥散成像领域做出了贡献，从而通过可视化其与附近解剖结构的空间关系，增强了对复杂大脑结构的分析和理解。", "summary": "本研究提出并开发了一个首创的综合性弥散纤维束成像图谱，用于自动绘制人脑中的颅神经（CNs）通路。该图谱利用多参数纤维束成像和多阶段纤维聚类策略，处理了来自人类连接组计划（HCP）的50名受试者的大量流线数据。实验结果表明，该图谱能高精度地自动识别并映射包括CN II、III、V和VII/VIII在内的8个颅神经纤维束，与专家手动标注具有高度空间对应性，并在多个数据集和临床病例中展现出鲁棒性。该工作显著提升了颅神经通路的自动化分析和可视化能力，加深了对复杂大脑结构的理解。", "keywords": "颅神经, 弥散纤维束成像, 自动化绘制, 图谱, 纤维聚类", "comments": "本文的创新点在于首次提出了一个综合性的自动化弥散纤维束成像图谱，用于绘制颅神经通路。其采用的多参数多阶段纤维聚类策略，有效处理了大量数据并克服了传统方法的挑战。该图谱在多个数据集和临床病例中展现出高精度和鲁棒性，对于术前规划和神经疾病分析具有重要意义。自动化能力大大提高了效率，有望在临床实践中得到广泛应用。"}}
{"id": "2507.12103", "title": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation", "authors": ["Longchao Da", "Xiangrui Liu", "Mithun Shivakoti", "Thirulogasankar Pranav Kutralingam", "Yezhou Yang", "Hua Wei"], "categories": ["cs.CV", "cs.CY", "68T45, 68U10, 62H35", "I.2.10; I.4.8; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7pages, 4 figures", "url": "http://arxiv.org/abs/2507.12103v3", "summary": "Heatwaves pose a significant threat to public health, especially as global\nwarming intensifies. However, current routing systems (e.g., online maps) fail\nto incorporate shade information due to the difficulty of estimating shades\ndirectly from noisy satellite imagery and the limited availability of training\ndata for generative models. In this paper, we address these challenges through\ntwo main contributions. First, we build an extensive dataset covering diverse\nlongitude-latitude regions, varying levels of building density, and different\nurban layouts. Leveraging Blender-based 3D simulations alongside building\noutlines, we capture building shadows under various solar zenith angles\nthroughout the year and at different times of day. These simulated shadows are\naligned with satellite images, providing a rich resource for learning shade\npatterns. Second, we propose the DeepShade, a diffusion-based model designed to\nlearn and synthesize shade variations over time. It emphasizes the nuance of\nedge features by jointly considering RGB with the Canny edge layer, and\nincorporates contrastive learning to capture the temporal change rules of\nshade. Then, by conditioning on textual descriptions of known conditions (e.g.,\ntime of day, solar angles), our framework provides improved performance in\ngenerating shade images. We demonstrate the utility of our approach by using\nour shade predictions to calculate shade ratios for real-world route planning\nin Tempe, Arizona. We believe this work will benefit society by providing a\nreference for urban planning in extreme heat weather and its potential\npractical applications in the environment.", "comment": "7pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.12103v3", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-30", "AI": {"title_translation": "DeepShade：通过文本条件图像生成实现阴影模拟", "tldr": "DeepShade提出了一种通过文本条件图像生成来模拟阴影的方法，以解决现有地图系统无法整合阴影信息的问题，旨在帮助城市规划应对极端高温。", "motivation": "热浪对公众健康构成重大威胁，而当前的路线规划系统（如在线地图）由于难以直接从嘈杂的卫星图像中估计阴影以及生成模型训练数据有限，未能整合阴影信息。", "method": "首先，构建了一个包含不同经纬度区域、建筑密度和城市布局的大规模数据集，利用基于Blender的3D模拟结合建筑轮廓，捕捉全年不同时间和太阳天顶角下的建筑阴影，并与卫星图像对齐。其次，提出了DeepShade模型，这是一个基于扩散的模型，通过联合考虑RGB和Canny边缘层来强调边缘特征，并结合对比学习来捕捉阴影的时间变化规律。该模型通过已知条件（如一天中的时间、太阳角度）的文本描述进行条件化，生成阴影图像。", "result": "DeepShade模型在生成阴影图像方面表现出改进的性能。该方法被用于计算亚利桑那州坦佩市实际路线规划中的阴影比率，证明了其效用。", "conclusion": "该工作通过为极端高温天气下的城市规划提供参考，并具有潜在的环境实际应用，从而造福社会。", "translation": "热浪对公众健康构成重大威胁，尤其是在全球变暖加剧的情况下。然而，当前的路线规划系统（例如在线地图）由于难以直接从嘈杂的卫星图像中估计阴影以及生成模型训练数据有限，未能整合阴影信息。在本文中，我们通过两项主要贡献解决了这些挑战。首先，我们建立了一个涵盖不同经纬度区域、不同建筑密度和不同城市布局的广泛数据集。利用基于Blender的3D模拟结合建筑轮廓，我们捕捉了全年和一天中不同时间在各种太阳天顶角下的建筑阴影。这些模拟阴影与卫星图像对齐，为学习阴影模式提供了丰富的资源。其次，我们提出了DeepShade，一个基于扩散的模型，旨在学习和合成阴影随时间的变化。它通过联合考虑RGB和Canny边缘层来强调边缘特征的细微差别，并结合对比学习来捕捉阴影的时间变化规律。然后，通过对已知条件（例如一天中的时间、太阳角度）的文本描述进行条件化，我们的框架在生成阴影图像方面提供了改进的性能。我们通过使用我们的阴影预测来计算亚利桑那州坦佩市实际路线规划中的阴影比率，展示了我们方法的实用性。我们相信这项工作将通过为极端高温天气下的城市规划提供参考以及其在环境中的潜在实际应用而造福社会。", "summary": "本研究旨在解决现有路线规划系统无法整合阴影信息的问题，以应对全球变暖带来的热浪威胁。为此，论文首先构建了一个大规模的阴影数据集，该数据集通过Blender 3D模拟生成并与卫星图像对齐。其次，提出了DeepShade模型，这是一个基于扩散的文本条件图像生成模型，它结合了RGB和Canny边缘信息，并利用对比学习捕捉阴影的时间变化规律。实验证明，该模型在生成阴影图像方面表现出优异性能，并成功应用于真实世界中的路线规划阴影比率计算，为城市规划和环境应用提供了有价值的工具。", "keywords": "阴影模拟, 图像生成, 扩散模型, 数据集, 城市规划", "comments": "该论文的创新之处在于其双重贡献：一是构建了一个大规模、多样化的阴影数据集，解决了训练数据稀缺的问题；二是提出了DeepShade模型，巧妙地结合了扩散模型、边缘特征和对比学习来模拟复杂的阴影变化。通过文本条件生成，提高了模型的灵活性和实用性。该研究对于城市规划和公共健康具有重要的实际意义，尤其是在气候变化背景下。"}}
{"id": "2507.22927", "title": "PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation", "authors": ["Zhehao Tan", "Yihan Jiao", "Dan Yang", "Lei Liu", "Jie Feng", "Duolin Sun", "Yue Shen", "Jian Wang", "Peng Wei", "Jinjie Gu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22927v1", "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge, where the LLM's ability to generate responses\nbased on the combination of a given query and retrieved documents is crucial.\nHowever, most benchmarks focus on overall RAG system performance, rarely\nassessing LLM-specific capabilities. Current benchmarks emphasize broad aspects\nsuch as noise robustness, but lack a systematic and granular evaluation\nframework on document utilization. To this end, we introduce\n\\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,\nemphasizing the following progressive dimensions: (1) multi-level filtering\nabilities, (2) combination abilities, and (3) reference reasoning. To provide a\nmore nuanced understanding of LLMs' roles in RAG systems, we formulate an\ninnovative placeholder-based approach to decouple the contributions of the\nLLM's parametric knowledge and the external knowledge. Experiments demonstrate\nthe limitations of representative LLMs in the RAG system's generation\ncapabilities, particularly in error resilience and context faithfulness. Our\nbenchmark provides a reproducible framework for developing more reliable and\nefficient RAG systems. Our code is available in\nhttps://github.com/Alipay-Med/PRGB.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22927v1", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-23", "AI": {"title_translation": "PRGB 基准测试：一种用于评估检索增强生成鲁棒性的占位符辅助算法", "tldr": "PRGB基准测试提出了一种占位符辅助算法，用于细粒度评估RAG系统中LLM的生成能力，揭示了当前LLM在错误容忍和上下文忠实度方面的局限性。", "motivation": "现有RAG基准测试主要关注整体系统性能，缺乏对LLM特定能力（特别是文档利用率）的系统性和细粒度评估，尤其是在噪声鲁棒性方面。", "method": "引入了PRGB基准测试，这是一个多层次细粒度基准，强调多层次过滤能力、组合能力和引用推理。采用创新的基于占位符的方法来解耦LLM参数知识和外部知识的贡献。", "result": "实验表明，代表性的LLM在RAG系统的生成能力方面存在局限性，特别是在错误容忍和上下文忠实度方面表现不足。", "conclusion": "PRGB基准测试提供了一个可复现的框架，用于开发更可靠、更高效的RAG系统。", "translation": "检索增强生成（RAG）通过整合外部知识来增强大型语言模型（LLM），其中LLM根据给定查询和检索到的文档组合生成响应的能力至关重要。然而，大多数基准测试侧重于RAG系统的整体性能，很少评估LLM的特定能力。当前的基准测试强调噪声鲁棒性等广泛方面，但缺乏对文档利用率的系统和细粒度评估框架。为此，我们引入了\\textit{Placeholder-RAG-Benchmark}，一个多层次细粒度基准，强调以下渐进维度：（1）多层次过滤能力，（2）组合能力，以及（3）引用推理。为了更细致地理解LLM在RAG系统中的作用，我们制定了一种创新的基于占位符的方法，以解耦LLM参数知识和外部知识的贡献。实验证明了代表性LLM在RAG系统生成能力方面的局限性，特别是在错误容忍和上下文忠实度方面。我们的基准测试提供了一个可复现的框架，用于开发更可靠和高效的RAG系统。我们的代码可在https://github.com/Alipay-Med/PRGB获取。", "summary": "本文提出了PRGB基准测试，这是一个多层次细粒度基准，旨在解决现有RAG基准测试在评估LLM特定生成能力方面的不足。通过引入创新的占位符方法，PRGB能够解耦LLM的参数知识和外部知识的贡献，并从多层次过滤、组合和引用推理等维度评估LLM。实验结果揭示了当前LLM在RAG系统中的生成能力局限性，尤其是在错误容忍和上下文忠实度方面。该基准提供了一个可复现的框架，以促进开发更可靠高效的RAG系统。", "keywords": "RAG, LLM, 基准测试, 占位符, 生成能力", "comments": "这项工作通过引入占位符辅助的细粒度评估方法，填补了RAG系统评估中LLM特定能力评估的空白。其创新之处在于能够解耦LLM的内部知识和外部知识的贡献，这对于理解LLM在RAG中的真实表现至关重要。该基准的提出有助于更精确地识别LLM在RAG应用中的优缺点，从而指导未来RAG系统的改进和开发。"}}
{"id": "2505.08884", "title": "Jacobian-Free Newton-Krylov with a globalization method for solving groundwater flow models of multi-layer aquifer systems", "authors": ["Raghav Singhal", "Emin Can Dogrul", "Zhaojun Bai"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.08884v2", "summary": "A Jacobian free Newton Krylov (JFNK) method with a globalization scheme is\nintroduced to solve large and complex nonlinear systems of equations that arise\nin groundwater flow models of multi-layer aquifer systems. We explore the\nadvantages of the JFNK method relative to the Newton-Krylov (NK) method and\nidentify the circumstances in which the JFNK method demonstrates computing\nefficiency. We perform the validation and efficiency of the JFNK method on\nvarious test cases involving an unconfined single-layer aquifer and a two-layer\naquifer with both confined and unconfined conditions. The results are validated\nby the NK method. The JFNK method is incorporated in Integrated Water Flow\nModel (IWFM), an integrated hydrologic model developed and maintained by\nCalifornia Department of Water Resources. We examine the determinacy of the\nJFNK's adaptability on practical models such as the California Central Valley\nGroundwater-Surface Water Simulation Model (C2VSim).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.08884v2", "cate": "math.NA", "date": "2025-05-13", "updated": "2025-07-30", "AI": {"title_translation": "带有全局化方法的无雅可比牛顿-克雷洛夫法求解多层含水层系统地下水流模型", "tldr": "引入并验证了一种带有全局化方案的无雅可比牛顿-克雷洛夫(JFNK)方法，用于高效求解大型复杂多层含水层系统地下水流模型。", "motivation": "解决多层含水层系统地下水流模型中出现的大型复杂非线性方程组。", "method": "引入了带有全局化方案的无雅可比牛顿-克雷洛夫 (JFNK) 方法，并与牛顿-克雷洛夫 (NK) 方法进行比较，以探索其优势和计算效率。在单层无承压含水层和包含承压与无承压条件的双层含水层等多种测试案例上验证了JFNK方法。将JFNK方法集成到综合水流模型 (IWFM) 中，并检验其在实际模型如加州中央谷地下水-地表水模拟模型 (C2VSim) 上的适应性。", "result": "JFNK方法在某些情况下显示出计算效率，其结果通过NK方法进行了验证。JFNK方法被整合到IWFM中，并成功检验了其在C2VSim等实际模型上的适应性。", "conclusion": "JFNK方法是一种有效且可适应的数值方法，能够高效求解大型复杂的多层含水层系统地下水流模型。", "translation": "引入了一种带有全局化方案的无雅可比牛顿-克雷洛夫 (JFNK) 方法，用于求解多层含水层系统地下水流模型中出现的大型复杂非线性方程组。我们探讨了JFNK方法相对于牛顿-克雷洛夫 (NK) 方法的优势，并确定了JFNK方法展现计算效率的情形。我们在涉及无承压单层含水层以及具有承压和无承压条件的双层含水层的各种测试案例上验证了JFNK方法的有效性和效率。结果通过NK方法进行了验证。JFNK方法被整合到由加州水资源部开发和维护的综合水流模型 (IWFM) 中。我们检验了JFNK方法在加州中央谷地下水-地表水模拟模型 (C2VSim) 等实际模型上的适应性决定性。", "summary": "本文提出了一种带有全局化方案的无雅可比牛顿-克雷洛夫 (JFNK) 方法，旨在高效求解多层含水层系统地下水流模型中的大型复杂非线性方程组。研究探讨了JFNK相对于传统牛顿-克雷洛夫 (NK) 方法的计算优势，并通过多种测试案例验证了其有效性和效率。此外，该方法已成功集成到综合水流模型 (IWFM) 中，并证明了其在实际应用模型如加州中央谷地下水-地表水模拟模型 (C2VSim) 上的良好适应性。", "keywords": "无雅可比牛顿-克雷洛夫, 地下水流模型, 多层含水层系统, 全局化方法, 计算效率", "comments": "该论文的创新点在于将带有全局化方案的JFNK方法应用于求解大型复杂多层含水层系统地下水流模型中的非线性方程组，并对其计算效率和实际模型适应性进行了深入探讨和验证。这对于提高地下水模拟的计算效率和处理复杂模型的稳定性具有重要意义。"}}
{"id": "2507.23077", "title": "A Foundation Model for Material Fracture Prediction", "authors": ["Agnese Marcato", "Aleksandra Pachalieva", "Ryley G. Hill", "Kai Gao", "Xiaoyu Wang", "Esteban Rougier", "Zhou Lei", "Vinamra Agrawal", "Janel Chua", "Qinjun Kang", "Jeffrey D. Hyman", "Abigail Hunter", "Nathan DeBardeleben", "Earl Lawrence", "Hari Viswanathan", "Daniel O'Malley", "Javier E. Santos"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.geo-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23077v1", "summary": "Accurately predicting when and how materials fail is critical to designing\nsafe, reliable structures, mechanical systems, and engineered components that\noperate under stress. Yet, fracture behavior remains difficult to model across\nthe diversity of materials, geometries, and loading conditions in real-world\napplications. While machine learning (ML) methods show promise, most models are\ntrained on narrow datasets, lack robustness, and struggle to generalize.\nMeanwhile, physics-based simulators offer high-fidelity predictions but are\nfragmented across specialized methods and require substantial high-performance\ncomputing resources to explore the input space. To address these limitations,\nwe present a data-driven foundation model for fracture prediction, a\ntransformer-based architecture that operates across simulators, a wide range of\nmaterials (including plastic-bonded explosives, steel, aluminum, shale, and\ntungsten), and diverse loading conditions. The model supports both structured\nand unstructured meshes, combining them with large language model embeddings of\ntextual input decks specifying material properties, boundary conditions, and\nsolver settings. This multimodal input design enables flexible adaptation\nacross simulation scenarios without changes to the model architecture. The\ntrained model can be fine-tuned with minimal data on diverse downstream tasks,\nincluding time-to-failure estimation, modeling fracture evolution, and adapting\nto combined finite-discrete element method simulations. It also generalizes to\nunseen materials such as titanium and concrete, requiring as few as a single\nsample, dramatically reducing data needs compared to standard ML. Our results\nshow that fracture prediction can be unified under a single model architecture,\noffering a scalable, extensible alternative to simulator-specific workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23077v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "材料断裂预测的基础模型", "tldr": "该论文提出了一个基于Transformer的通用基础模型，用于预测材料断裂，它能够处理多种材料、几何形状和载荷条件，并结合了多模态输入，显著减少了数据需求。", "motivation": "准确预测材料何时以及如何失效对于设计安全可靠的结构至关重要，但现有方法存在局限性：机器学习模型泛化能力差、鲁棒性不足且依赖狭窄数据集；基于物理的模拟器虽然高精度但碎片化且计算资源需求大。", "method": "研究提出了一个数据驱动的断裂预测基础模型，采用基于Transformer的架构。该模型支持跨模拟器、多种材料（如塑性粘结炸药、钢、铝、页岩、钨）和不同载荷条件的操作。它结合了结构化和非结构化网格，并利用大型语言模型嵌入的文本输入（指定材料属性、边界条件和求解器设置）。这种多模态输入设计使得模型无需更改架构即可灵活适应不同的模拟场景。", "result": "该模型能够用少量数据对多样化的下游任务进行微调，包括失效时间估计、断裂演化建模和适应复合有限-离散元法模拟。它还能推广到未见材料（如钛和混凝土），只需少量样本（甚至一个样本），显著减少了与标准机器学习相比的数据需求。结果表明，断裂预测可以统一在一个单一模型架构下，为特定模拟器工作流提供了一种可扩展、可替代的方案。", "conclusion": "断裂预测可以被统一在一个单一模型架构下，该基础模型提供了一种可扩展、可替代且数据需求显著降低的解决方案，能够应对现有方法的局限性，并推广到新材料。", "translation": "准确预测材料何时以及如何失效对于设计在应力下运行的安全、可靠的结构、机械系统和工程组件至关重要。然而，在实际应用中，断裂行为在各种材料、几何形状和载荷条件下仍然难以建模。尽管机器学习（ML）方法前景广阔，但大多数模型在狭窄的数据集上训练，缺乏鲁棒性，并且难以泛化。同时，基于物理的模拟器提供高保真预测，但它们分散在专业方法中，并且需要大量高性能计算资源来探索输入空间。为了解决这些局限性，我们提出了一个用于断裂预测的数据驱动基础模型，一个基于Transformer的架构，它可以在各种模拟器、广泛的材料（包括塑性粘结炸药、钢、铝、页岩和钨）和各种载荷条件下运行。该模型支持结构化和非结构化网格，并将它们与大型语言模型嵌入的文本输入（指定材料属性、边界条件和求解器设置）结合起来。这种多模态输入设计使得模型能够灵活适应各种模拟场景，而无需更改模型架构。训练后的模型可以用最少的数据对各种下游任务进行微调，包括失效时间估计、断裂演化建模和适应复合有限-离散元法模拟。它还能推广到未见材料，如钛和混凝土，只需要一个样本，与标准ML相比，极大地减少了数据需求。我们的结果表明，断裂预测可以统一在一个单一模型架构下，为特定模拟器工作流提供了一种可扩展、可替代的方案。", "summary": "本文提出了一种用于材料断裂预测的Transformer基础模型，旨在解决现有机器学习模型泛化能力差和物理模拟器计算资源需求大的问题。该模型采用多模态输入设计，结合结构化/非结构化网格与文本描述的材料及模拟设置，使其能跨多种材料、几何形状和载荷条件运行。实验表明，该模型能够用少量数据对多种下游任务进行微调，并能泛化到未见材料，显著降低了数据需求，提供了一个统一且可扩展的断裂预测解决方案。", "keywords": "材料断裂, 基础模型, Transformer, 多模态输入, 泛化能力", "comments": "该论文的创新点在于提出了一个通用的“基础模型”概念应用于材料断裂预测领域，这在传统上是高度专业化且计算密集型的。通过采用Transformer架构和多模态输入（结合几何数据与文本描述），模型实现了前所未有的泛化能力和数据效率，尤其是在新材料的预测上，这对于材料科学和工程设计具有重要意义。它有望打破传统模拟器之间的壁垒，提供一个统一的平台。"}}
{"id": "2309.12365", "title": "An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System", "authors": ["Chunan Tong"], "categories": ["cs.HC", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.12365v3", "summary": "In the context of evolving supply chain management, the significance of\nefficient inventory management has grown substantially for businesses. However,\nconventional manual and experience-based approaches often struggle to meet the\ncomplexities of modern market demands. This research introduces an intelligent\ninventory management system to address challenges related to inaccurate data,\ndelayed monitoring, and overreliance on subjective experience in forecasting.\nThe proposed system integrates bar code and distributed flutter application\ntechnologies for intelligent perception, alongside comprehensive big data\nanalytics to enable data-driven decision-making. Through meticulous analysis,\nsystem design, critical technology exploration, and simulation validation, the\neffectiveness of the proposed system is successfully demonstrated. The\nintelligent system facilitates second-level monitoring, high-frequency checks,\nand artificial intelligence-driven forecasting, consequently enhancing the\nautomation, precision, and intelligence of inventory management. This system\ncontributes to cost reduction and optimized inventory sizes through accurate\npredictions and informed decisions, ultimately achieving a mutually beneficial\nscenario. The outcomes of this research offer", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.12365v3", "cate": "cs.HC", "date": "2023-09-13", "updated": "2025-07-31", "AI": {"title_translation": "一种高效智能半自动化仓库盘点系统", "tldr": "本文提出了一种结合条形码、Flutter应用和大数据分析的智能库存管理系统，旨在提高库存管理的准确性、自动化程度和智能化水平，从而降低成本并优化库存规模。", "motivation": "传统的库存管理方法效率低下、数据不准确且过度依赖经验，难以满足现代市场需求。现有挑战包括数据不准确、监控延迟以及预测过度依赖主观经验。", "method": "该系统整合了条形码和分布式Flutter应用技术以实现智能感知，并结合全面的大数据分析以支持数据驱动的决策。研究通过系统分析、设计、关键技术探索和仿真验证来展示系统有效性。", "result": "该智能系统实现了秒级监控、高频检查和人工智能驱动的预测，从而提升了库存管理的自动化、精确性和智能化水平。", "conclusion": "该系统通过准确预测和明智决策，有助于降低成本并优化库存规模，最终实现互利共赢的局面。", "translation": "在不断发展的供应链管理背景下，高效库存管理对企业的重要性日益增长。然而，传统的、基于人工和经验的方法往往难以满足现代市场的复杂需求。本研究引入了一种智能库存管理系统，以解决数据不准确、监控延迟以及预测过度依赖主观经验等挑战。所提出的系统集成了条形码和分布式Flutter应用程序技术，用于智能感知，并结合全面的大数据分析，以实现数据驱动的决策。通过细致的分析、系统设计、关键技术探索和仿真验证，成功证明了所提出系统的有效性。该智能系统促进了秒级监控、高频检查和人工智能驱动的预测，从而提高了库存管理的自动化、精确性和智能化水平。该系统通过准确的预测和明智的决策，有助于降低成本和优化库存规模，最终实现互利共赢的局面。本研究的成果提供……", "summary": "本文提出了一种高效智能半自动化仓库盘点系统，旨在解决传统库存管理中数据不准确、监控延迟和过度依赖经验的问题。该系统融合了条形码、分布式Flutter应用技术和大数据分析，以实现智能感知和数据驱动决策。通过仿真验证，系统展现出秒级监控、高频检查和AI驱动预测的能力，显著提升了库存管理的自动化、精确度和智能化，从而有效降低成本并优化库存。", "keywords": "库存管理, 智能系统, 半自动化仓库, 大数据, 人工智能", "comments": "该论文的创新之处在于其将多种现代技术（条形码、分布式Flutter应用、大数据分析和人工智能）集成到一个半自动化系统中，以解决传统库存管理的痛点。其重要性体现在通过提高库存管理的效率、准确性和智能化水平，能够为企业带来显著的成本节约和库存优化，具有较强的实际应用价值。"}}
{"id": "2507.23396", "title": "Energy management and flexibility quantification in a discrete event distribution grid simulation", "authors": ["Sebastian Peter", "Daniel Feismann", "Johannes Bao", "Thomas Oberließen", "Christian Rehtanz"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, part of PowerTech conference proceedings", "url": "http://arxiv.org/abs/2507.23396v1", "summary": "Distribution grid operation faces new challenges caused by a rising share of\nrenewable energy sources and the introduction of additional types of loads to\nthe grid. With the increasing adoption of distributed generation and emerging\nprosumer households, Energy Management Systems, which manage and apply\nflexibility of connected devices, are gaining popularity. While potentially\nbeneficial to grid capacity, strategic energy management also adds to the\ncomplexity of distribution grid operation and planning processes. Novel\napproaches of time-series-based planning likewise face increasingly complex\nsimulation scenarios and rising computational cost. Discrete event modelling\nhelps facilitating simulations of such scenarios by restraining computation to\nthe most relevant points in simulation time. We provide an enhancement of a\ndiscrete event distribution grid simulation software that offers fast\nimplementation and testing of energy management algorithms, embedded into a\nfeature-rich simulation environment. Physical models are specified using the\nDiscrete Event System Specification. Furthermore, we contribute a communication\nprotocol that makes use of the discrete event paradigm by only computing\nflexibility potential when necessary.", "comment": "6 pages, 5 figures, part of PowerTech conference proceedings", "pdf_url": "http://arxiv.org/pdf/2507.23396v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "离散事件配电网仿真中的能量管理与灵活性量化", "tldr": "本文增强了一种离散事件配电网仿真软件，以实现能量管理的快速实现和测试，并通过离散事件范式优化了灵活性潜力的计算。", "motivation": "由于可再生能源份额的增加和新型负荷的引入，配电网运行面临新挑战。分布式发电和新兴产消者家庭的普及使得能量管理系统日益流行，但同时也增加了配电网运行和规划的复杂性，导致时间序列规划方法的仿真场景日益复杂和计算成本上升。", "method": "通过增强离散事件配电网仿真软件来实现能量管理算法的快速实现和测试。物理模型使用离散事件系统规范（Discrete Event System Specification）指定。此外，还贡献了一种利用离散事件范式仅在必要时计算灵活性潜力的通信协议。", "result": "该增强的仿真软件提供了能量管理算法的快速实现和测试，并嵌入在一个功能丰富的仿真环境中。通过新的通信协议，仅在必要时计算灵活性潜力，从而有助于简化复杂场景的仿真并限制计算到最相关的时间点。", "conclusion": "通过离散事件建模和优化的通信协议，可以有效地促进复杂配电网场景的仿真，减少计算量，并为能量管理算法的开发和测试提供快速便捷的平台，从而潜在地有益于电网容量。", "translation": "配电网运行面临因可再生能源份额增加和新型负荷引入而带来的新挑战。随着分布式发电和新兴产消者家庭的日益普及，管理和应用连接设备灵活性的能量管理系统正变得越来越受欢迎。虽然对电网容量可能有利，但战略性能量管理也增加了配电网运行和规划过程的复杂性。新颖的基于时间序列的规划方法同样面临日益复杂的仿真场景和不断上升的计算成本。离散事件建模通过将计算限制在仿真时间中最相关的点，有助于促进此类场景的仿真。我们提供了一种离散事件配电网仿真软件的增强版，该软件在一个功能丰富的仿真环境中提供能量管理算法的快速实现和测试。物理模型使用离散事件系统规范指定。此外，我们贡献了一种利用离散事件范式，仅在必要时计算灵活性潜力的通信协议。", "summary": "本文针对可再生能源和新型负荷给配电网带来的挑战，提出了一种增强的离散事件配电网仿真软件。该软件利用离散事件建模将计算限制在关键时间点，从而加速能量管理算法的实现和测试。通过结合离散事件系统规范和一种仅在必要时计算灵活性的通信协议，该方法旨在简化复杂场景的仿真，降低计算成本，并支持分布式能源和产消者背景下的能量管理。", "keywords": "配电网, 能量管理, 灵活性量化, 离散事件仿真, 智能电网", "comments": "该论文的创新点在于将离散事件建模应用于配电网仿真，以应对日益复杂的能量管理挑战。这种方法通过仅在必要时进行计算，显著提高了仿真效率，从而能够更快地测试能量管理算法和量化灵活性。这对于未来包含大量分布式能源和产消者的智能电网规划和运行具有重要意义。"}}
{"id": "2507.21288", "title": "Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties", "authors": ["Guanxiong Chen", "Shashwat Suri", "Yuhao Wu", "Etienne Voulga", "David I. W. Levin", "Dinesh K. Pai"], "categories": ["cs.GR", "cs.AI"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Added middle name of Prof. Pai", "url": "http://arxiv.org/abs/2507.21288v2", "summary": "Materials used in real clothing exhibit remarkable complexity and spatial\nvariation due to common processes such as stitching, hemming, dyeing, printing,\npadding, and bonding. Simulating these materials, for instance using finite\nelement methods, is often computationally demanding and slow. Worse, such\nmethods can suffer from numerical artifacts called ``membrane locking'' that\nmakes cloth appear artificially stiff. Here we propose a general framework,\ncalled Mass-Spring Net, for learning a simple yet efficient surrogate model\nthat captures the effects of these complex materials using only motion\nobservations. The cloth is discretized into a mass-spring network with unknown\nmaterial parameters that are learned directly from the motion data, using a\nnovel force-and-impulse loss function. Our approach demonstrates the ability to\naccurately model spatially varying material properties from a variety of data\nsources, and immunity to membrane locking which plagues FEM-based simulations.\nCompared to graph-based networks and neural ODE-based architectures, our method\nachieves significantly faster training times, higher reconstruction accuracy,\nand improved generalization to novel dynamic scenarios.", "comment": "Added middle name of Prof. Pai", "pdf_url": "http://arxiv.org/pdf/2507.21288v2", "cate": "cs.GR", "date": "2025-07-28", "updated": "2025-07-30", "AI": {"title_translation": "学习具有空间变异本构性质的可模拟布料模型", "tldr": "本文提出了一种名为Mass-Spring Net的框架，通过运动观测学习布料的替代模型，以高效模拟具有复杂空间变异性质的布料，克服了传统有限元方法的计算昂贵和膜锁定问题。", "motivation": "现有布料模拟方法（如有限元方法）对具有复杂空间变异性质的真实布料计算成本高昂且速度慢，并存在“膜锁定”等数值伪影，导致布料显得过于僵硬。", "method": "提出了一种名为Mass-Spring Net的通用框架，将布料离散化为具有未知材料参数的质量-弹簧网络。这些参数通过新颖的力-冲量损失函数直接从运动数据中学习，从而形成一个简单高效的替代模型。", "result": "该方法能够准确模拟各种数据源中具有空间变异的材料特性，且对有限元模拟中常见的“膜锁定”问题具有免疫力。与基于图网络和神经ODE的架构相比，该方法实现了显著更快的训练时间、更高的重建精度和对新颖动态场景更好的泛化能力。", "conclusion": "Mass-Spring Net框架为学习复杂布料的模拟模型提供了一种高效、准确且鲁越的方法，克服了传统方法的局限性。", "translation": "真实衣物中使用的材料由于缝合、卷边、染色、印花、填充和粘合等常见工艺，表现出显著的复杂性和空间变异性。模拟这些材料，例如使用有限元方法，通常计算量大且速度慢。更糟糕的是，此类方法可能会出现称为“膜锁定”的数值伪影，使布料显得人为地僵硬。本文提出了一种名为Mass-Spring Net的通用框架，用于学习一个简单而高效的替代模型，该模型仅使用运动观测来捕捉这些复杂材料的影响。布料被离散化为一个质量-弹簧网络，其未知材料参数使用新颖的力-冲量损失函数直接从运动数据中学习。我们的方法展示了从各种数据源准确建模空间变异材料属性的能力，并且对困扰基于有限元模拟的膜锁定问题具有免疫力。与基于图网络和神经ODE的架构相比，我们的方法实现了显著更快的训练时间、更高的重建精度和对新颖动态场景更好的泛化能力。", "summary": "本文介绍了一种名为Mass-Spring Net的通用框架，旨在解决传统布料模拟方法在处理具有空间变异复杂材料时的效率和准确性问题。该框架通过从运动数据中学习质量-弹簧网络的材料参数，构建了一个高效的替代模型。实验证明，该方法能准确模拟空间变异属性，避免膜锁定，并比现有方法在训练速度、精度和泛化能力上均有显著提升。", "keywords": "布料模拟, 质量-弹簧网络, 空间变异材料, 机器学习, 膜锁定", "comments": "该论文的创新点在于提出了Mass-Spring Net框架，将布料模拟问题转化为学习质量-弹簧网络的材料参数，从而有效克服了传统有限元方法在处理复杂材料时的计算瓶颈和“膜锁定”问题。其重要性体现在为布料模拟提供了一种更高效、更准确且更鲁棒的解决方案，特别适用于需要模拟真实世界复杂布料的应用，例如虚拟试穿、电影特效等。"}}
{"id": "2504.09753", "title": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance", "authors": ["Ram Mohan Rao Kadiyala", "Siddartha Pullakhandam", "Siddhant Gupta", "Drishti Sharma", "Jebish Purbey", "Kanwal Mehreen", "Muhammad Arham", "Suman Debnath", "Hamza Farooq"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      24 pages, 18 figures", "url": "http://arxiv.org/abs/2504.09753v3", "summary": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.", "comment": "24 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2504.09753v3", "cate": "cs.CL", "date": "2025-04-13", "updated": "2025-07-31", "AI": {"title_translation": "提升大型语言模型的多语言能力与文化和本地知识，同时增强原生性能", "tldr": "本文提出了Mantra-14B，一个印地语-英语双语LLM，通过指令微调和文化本地化数据，在不增加模型大小和不牺牲原生性能的前提下，显著提升了多语言性能。", "motivation": "大型语言模型主要关注英语和高资源语言，导致许多语言服务不足，存在性能鸿沟。", "method": "开发了Hindi-English双语LLM Mantra-14B；使用包含485K样本的英语和印地语指令数据集进行指令微调；对Qwen-2.5-14B-Instruct和Phi-4等模型进行了微调；进行了140多次训练尝试，探索不同英-印训练数据比例；避免了词汇扩展或架构修改等资源密集型技术。", "result": "Mantra-14B在印地语和英语基准测试中平均提高了约3%的得分，性能优于其两倍大小的模型；实验证明在不损害原生性能的情况下显著提高了多语言性能；通过文化和本地化数据进行适度微调可以弥补性能差距，且计算开销不大。", "conclusion": "通过使用文化和本地化数据进行适度微调，可以在不牺牲原生性能和不增加计算开销的情况下，显著提升大型语言模型的多语言能力，尤其是在资源不足的语言方面。", "translation": "大型语言模型（LLMs）展现出卓越的能力，但其发展主要集中在英语和其他高资源语言上，导致许多语言服务不足。我们推出了最新的印地语-英语双语LLM Mantra-14B，其在两种语言的基准测试分数上平均提升了约3%，表现优于其两倍大小的模型。我们使用由48.5万个英语和印地语指令数据样本组成的精选数据集，对Qwen-2.5-14B-Instruct和Phi-4等模型进行了指令微调，以提高它们在英语和印地语上的性能。我们的实验涵盖了七种不同参数大小的LLMs，并进行了超过140次训练尝试，使用了不同比例的英语-印地语训练数据，结果表明，在不损害原生性能的情况下，显著提高多语言性能是可能的。此外，我们的方法避免了词汇扩展或架构修改等资源密集型技术，从而保持了模型的小尺寸。我们的结果表明，通过包含文化和本地信息的适度微调数据，可以在不产生显著计算开销的情况下弥合性能差距。我们发布了训练代码、数据集和模型，采用MIT和Apache许可，以促进对代表性不足和低资源语言的进一步研究。", "summary": "这篇论文介绍了一个名为Mantra-14B的印地语-英语双语大型语言模型，该模型通过使用包含文化和本地化知识的指令数据进行适度微调，实现了在两种语言上平均约3%的性能提升，且优于两倍大小的模型。研究表明，在不牺牲模型原生性能和不增加计算成本（如词汇扩展或架构修改）的前提下，可以显著提升LLM的多语言能力，尤其对于低资源语言。论文还发布了相关的代码、数据集和模型以促进后续研究。", "keywords": "大型语言模型, 多语言能力, 文化知识, 本地化数据, 指令微调, Mantra-14B", "comments": "该研究的创新之处在于，它提出了一种高效且低成本的方法来提升LLM的多语言能力，即通过文化和本地化数据进行适度微调，而无需进行昂贵的架构或词汇修改。这对于将LLM推广到更多低资源语言具有重要意义，因为它展示了在保持模型效率的同时提升性能的潜力。"}}
{"id": "2507.23064", "title": "Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints", "authors": ["Santosh Patapati", "Trisanth Srinivasan", "Murari Ambati"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO", "I.4.8; I.2.10; I.2.6; C.3.3; I.4.9"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2507.23064v1", "summary": "Autonomous cars need geometric accuracy and semantic understanding to\nnavigate complex environments, yet most stacks handle them separately. We\npresent XYZ-Drive, a single vision-language model that reads a front-camera\nframe, a 25m $\\times$ 25m overhead map, and the next waypoint, then outputs\nsteering and speed. A lightweight goal-centered cross-attention layer lets\nwaypoint tokens highlight relevant image and map patches, supporting both\naction and textual explanations, before the fused tokens enter a partially\nfine-tuned LLaMA-3.2 11B model.\n  On the MD-NEX Outdoor-Driving benchmark XYZ-Drive attains 95% success and\n0.80 Success weighted by Path Length (SPL), surpassing PhysNav-DG by 15%. and\nhalving collisions, all while significantly improving efficiency by using only\na single branch. Sixteen ablations explain the gains. Removing any modality\n(vision, waypoint, map) drops success by up to 11%, confirming their\ncomplementary roles and rich connections. Replacing goal-centered attention\nwith simple concatenation cuts 3% in performance, showing query-based fusion\ninjects map knowledge more effectively. Keeping the transformer frozen loses\n5%, showing the importance of fine-tuning when applying VLMs for specific tasks\nsuch as autonomous driving. Coarsening map resolution from 10 cm to 40 cm blurs\nlane edges and raises crash rate.\n  Overall, these results demonstrate that early, token-level fusion of intent\nand map layout enables accurate, transparent, real-time driving.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.23064v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "实时自动驾驶的视觉-语言融合：相机、高清地图和路径点的目标中心交叉注意力", "tldr": "XYZ-Drive是一个单一的视觉-语言模型，它通过目标中心交叉注意力融合摄像头图像、高清地图和路径点信息，实现实时自动驾驶，并在MD-NEX基准测试中显著超越现有方法，证明了多模态早期融合的有效性。", "motivation": "现有的自动驾驶系统通常将几何精度和语义理解分开处理，而自动驾驶汽车在复杂环境中导航时需要同时具备这两者。本研究旨在开发一个能够同时处理这些信息并提高自动驾驶性能的统一模型。", "method": "本文提出了XYZ-Drive，一个单一的视觉-语言模型，它接收前置摄像头图像、25米×25米的俯瞰地图和下一个路径点作为输入，并输出转向和速度。该模型采用轻量级目标中心交叉注意力层，使路径点令牌能够突出相关的图像和地图区域，支持动作和文本解释。融合后的令牌进入一个部分微调的LLaMA-3.2 11B模型。", "result": "在MD-NEX户外驾驶基准测试中，XYZ-Drive取得了95%的成功率和0.80的路径长度加权成功率（SPL），比PhysNav-DG高出15%，并将碰撞次数减半，同时通过使用单一分支显著提高了效率。消融实验表明：移除任何模态（视觉、路径点、地图）都会使成功率下降高达11%；用简单拼接替换目标中心注意力会使性能下降3%；保持Transformer冻结会损失5%的性能；将地图分辨率从10厘米粗化到40厘米会模糊车道边缘并提高碰撞率。", "conclusion": "研究结果表明，意图和地图布局的早期、令牌级融合能够实现准确、透明和实时的自动驾驶。", "translation": "自动驾驶汽车需要几何精度和语义理解才能在复杂环境中导航，但大多数堆栈都将它们分开处理。我们提出了XYZ-Drive，一个单一的视觉-语言模型，它读取前置摄像头帧、25米×25米的俯瞰地图以及下一个路径点，然后输出转向和速度。一个轻量级的目标中心交叉注意力层允许路径点令牌突出相关的图像和地图区域，在融合后的令牌进入部分微调的LLaMA-3.2 11B模型之前，支持动作和文本解释。\n在MD-NEX户外驾驶基准测试中，XYZ-Drive达到了95%的成功率和0.80的路径长度加权成功率（SPL），比PhysNav-DG高出15%，并将碰撞次数减半，同时通过使用单一分支显著提高了效率。十六项消融实验解释了这些提升。移除任何模态（视觉、路径点、地图）都会使成功率下降高达11%，证实了它们互补的角色和丰富的连接。用简单拼接替换目标中心注意力会使性能下降3%，表明基于查询的融合能更有效地注入地图知识。保持Transformer冻结会损失5%，表明在将VLM应用于自动驾驶等特定任务时微调的重要性。将地图分辨率从10厘米粗化到40厘米会模糊车道边缘并提高碰撞率。\n总的来说，这些结果表明，意图和地图布局的早期、令牌级融合能够实现准确、透明和实时的驾驶。", "summary": "本文提出了XYZ-Drive，一个创新的单分支视觉-语言模型，用于实时自动驾驶。该模型通过一个轻量级目标中心交叉注意力层，将摄像头图像、高清地图和路径点信息进行早期、令牌级融合，并输入到部分微调的LLaMA-3.2 11B模型中，直接输出转向和速度。在MD-NEX基准测试中，XYZ-Drive在成功率、SPL和碰撞率方面均显著优于现有方法。消融实验进一步证实了多模态融合、目标中心注意力机制以及模型微调对于提升性能的关键作用，证明了早期融合意图和地图布局对于实现准确、透明和实时驾驶的有效性。", "keywords": "自动驾驶, 视觉-语言模型, 多模态融合, 交叉注意力, 实时驾驶", "comments": "本文的创新点在于提出了一个统一的视觉-语言模型XYZ-Drive，通过目标中心交叉注意力实现了摄像头、高清地图和路径点信息的早期、令牌级融合，有效解决了传统自动驾驶系统将几何精度和语义理解分开处理的问题。其使用轻量级交叉注意力层和部分微调大型语言模型（LLaMA-3.2）的方法，在保持效率的同时，显著提升了自动驾驶的性能，并在多个方面超越了基线模型。消融实验设计充分，有力地验证了各模态和核心机制的重要性。这为未来自动驾驶系统设计提供了新的思路，特别是在多模态信息融合和利用大型预训练模型方面。"}}
{"id": "2410.12547", "title": "REST API Testing in DevOps: A Study on an Evolving Healthcare IoT Application", "authors": ["Hassan Sartaj", "Shaukat Ali", "Julie Marie Gjøby"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.12547v2", "summary": "Healthcare Internet of Things (IoT) applications often integrate various\nthird-party healthcare applications and medical devices through REST APIs,\nresulting in complex and interdependent networks of REST APIs. Oslo City's\nhealthcare department collaborates with various industry partners to develop\nsuch healthcare IoT applications enriched with a diverse set of REST APIs.\nFollowing the DevOps process, these REST APIs continuously evolve to\naccommodate evolving needs such as new features, services, and devices. Oslo\nCity's primary goal is to utilize automated solutions for continuous testing of\nthese REST APIs at each evolution stage, thereby ensuring their dependability.\nAlthough the literature offers various automated REST API testing tools, their\neffectiveness in regression testing of the evolving REST APIs of healthcare IoT\napplications within a DevOps context remains undetermined. This paper evaluates\nstate-of-the-art and well-established REST API testing tools, specifically,\nRESTest, EvoMaster, Schemathesis, RESTler, and RestTestGen, for the regression\ntesting of a real-world healthcare IoT application, considering failures,\nfaults, coverage, regressions, and cost. We conducted experiments using all\naccessible REST APIs (17 APIs with 120 endpoints), and 14 releases evolved\nduring DevOps. Overall, all tools generated tests leading to several failures,\n18 potential faults, up to 84% coverage, and 23 regressions. Over 70% of tests\ngenerated by all tools fail to detect failures, resulting in significant\noverhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.12547v2", "cate": "cs.SE", "date": "2024-10-16", "updated": "2025-07-31", "AI": {"title_translation": "DevOps 中的 REST API 测试：一项关于演进中的医疗物联网应用的研究", "tldr": "本研究评估了在 DevOps 环境下，针对不断演进的医疗物联网应用进行 REST API 回归测试的现有工具的有效性，发现这些工具在检测故障方面存在显著开销和局限性。", "motivation": "医疗物联网（IoT）应用程序通过 REST API 集成各种第三方应用和医疗设备，形成了复杂且相互依赖的网络。这些 REST API 在 DevOps 过程中不断演进以适应新需求。奥斯陆市政府的目标是利用自动化解决方案对这些 REST API 进行持续测试以确保其可靠性。然而，现有文献中各种自动化 REST API 测试工具在 DevOps 环境下对演进中的医疗物联网应用的回归测试有效性尚不确定。", "method": "本研究评估了五种最先进且成熟的 REST API 测试工具（RESTest、EvoMaster、Schemathesis、RESTler 和 RestTestGen），用于对一个真实的医疗物联网应用进行回归测试。评估指标包括故障、缺陷、覆盖率、回归和成本。实验使用了该应用所有可访问的 REST API（17 个 API，120 个端点）以及 DevOps 过程中演进的 14 个版本。", "result": "所有工具生成的测试都导致了一些故障，发现了 18 个潜在缺陷，实现了高达 84% 的覆盖率，并检测到 23 处回归。然而，所有工具生成的测试中，超过 70% 未能检测到故障，导致了显著的开销。", "conclusion": "虽然现有工具在医疗物联网应用的 REST API 回归测试中能够发现故障和缺陷并提供一定的覆盖率，但它们在检测故障方面的效率不高，导致了显著的测试开销，表明仍需改进。", "translation": "医疗物联网（IoT）应用程序通常通过 REST API 集成各种第三方医疗应用程序和医疗设备，从而形成复杂且相互依赖的 REST API 网络。奥斯陆市的医疗部门与各行业合作伙伴合作开发此类医疗物联网应用程序，这些应用程序丰富了多样化的 REST API。遵循 DevOps 流程，这些 REST API 不断演进以适应不断变化的需求，例如新功能、服务和设备。奥斯陆市的主要目标是利用自动化解决方案在每个演进阶段对这些 REST API 进行持续测试，从而确保其可靠性。尽管文献提供了各种自动化 REST API 测试工具，但它们在 DevOps 环境下对演进中的医疗物联网应用的 REST API 进行回归测试的有效性仍未确定。本文评估了最先进和成熟的 REST API 测试工具，具体包括 RESTest、EvoMaster、Schemathesis、RESTler 和 RestTestGen，用于对一个真实的医疗物联网应用程序进行回归测试，并考虑了故障、缺陷、覆盖率、回归和成本。我们使用所有可访问的 REST API（17 个 API，120 个端点）以及在 DevOps 期间演进的 14 个版本进行了实验。总体而言，所有工具生成的测试都导致了一些故障，18 个潜在缺陷，高达 84% 的覆盖率，以及 23 处回归。所有工具生成的测试中，超过 70% 未能检测到故障，导致了显著的开销。", "summary": "本研究旨在评估在 DevOps 环境下，现有自动化 REST API 测试工具对不断演进的医疗物联网应用进行回归测试的有效性。通过对一个真实医疗物联网应用的 17 个 API 和 14 个版本进行实验，比较了 RESTest、EvoMaster、Schemathesis、RESTler 和 RestTestGen 五种工具。结果显示，尽管这些工具能发现故障、缺陷和回归并提供一定覆盖率，但超过 70% 的测试未能检测到故障，导致了显著的测试开销。", "keywords": "REST API 测试, DevOps, 医疗物联网, 回归测试, 自动化测试", "comments": "该论文解决了在 DevOps 实践中对不断演进的医疗物联网应用进行 REST API 自动化测试的实际且重要的问题。通过对真实世界应用的案例研究，为现有工具的有效性提供了宝贵见解。其创新点在于将现有工具置于高动态的 DevOps 环境中进行严格评估，并量化了其在可靠性、覆盖率和成本方面的表现。研究揭示了现有工具在检测故障方面的局限性和高开销，为未来自动化测试工具的改进指明了方向，具有重要的实践指导意义。"}}
{"id": "2507.23235", "title": "In-Orbit Cosmo-SkyMed antenna pattern estimation by a narrowband sweeper receiver", "authors": ["Mohammad Roueinfar", "Masoud Ardini"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23235v1", "summary": "This paper introduces a novel method for antenna pattern estimation in\nsatellites equipped with Synthetic Aperture Radar (SAR), utilizing a Narrowband\nSweeper Receiver (NSR). By accurately measuring power across individual\nfrequencies within SAR's inherently broadband spectrum, the NSR significantly\nenhances antenna pattern extraction accuracy. Analytical models and practical\nexperiments conducted using the Cosmo-SkyMed satellite validate the receiver's\nperformance, demonstrating superior signal-to-noise ratio (SNR) compared to\nconventional receivers. This research represents a key advancement in SAR\ntechnology, offering a robust framework for future satellite calibration and\nverification methodologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23235v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "窄带扫描接收机在轨对Cosmo-SkyMed天线方向图的估计", "tldr": "本文提出一种使用窄带扫描接收机（NSR）在轨估计SAR卫星天线方向图的新方法，该方法能提高估计精度并具有更高的信噪比，对未来卫星校准和验证具有重要意义。", "motivation": "提高合成孔径雷达（SAR）卫星天线方向图的估计精度，并为未来的卫星校准和验证提供一个鲁棒的框架。", "method": "引入了一种利用窄带扫描接收机（NSR）在轨估计SAR卫星天线方向图的新方法。该方法通过精确测量SAR宽带频谱内单个频率的功率来实现。", "result": "分析模型和使用Cosmo-SkyMed卫星进行的实际实验验证了NSR的性能，结果表明其信噪比（SNR）优于传统接收机，并显著提高了天线方向图提取精度。", "conclusion": "该研究是SAR技术的一项关键进展，为未来的卫星校准和验证方法提供了一个鲁棒的框架。", "translation": "本文介绍了一种利用窄带扫描接收机（NSR）在轨估计配备合成孔径雷达（SAR）的卫星天线方向图的新方法。通过精确测量SAR固有的宽带频谱中单个频率的功率，NSR显著提高了天线方向图提取的精度。使用Cosmo-SkyMed卫星进行的分析模型和实际实验验证了接收机的性能，证明了与传统接收机相比，其信噪比（SNR）更优。这项研究代表了SAR技术的一项关键进展，为未来的卫星校准和验证方法提供了一个强大的框架。", "summary": "本文提出了一种新颖的窄带扫描接收机（NSR）方法，用于在轨精确估计合成孔径雷达（SAR）卫星的天线方向图。通过测量SAR宽带频谱中各频率的功率，NSR能显著提高方向图提取精度。实验证明，该方法比传统接收机具有更高的信噪比，为SAR卫星的校准和验证提供了坚实的基础。", "keywords": "天线方向图估计, 窄带扫描接收机, 合成孔径雷达, Cosmo-SkyMed, 信噪比", "comments": "这篇论文的创新点在于引入了窄带扫描接收机（NSR）来解决SAR卫星天线方向图的在轨估计问题，这对于提高SAR系统性能至关重要。其重要性体现在NSR能够显著提高估计精度和信噪比，为未来SAR卫星的性能优化和任务成功提供了更可靠的校准和验证手段。"}}
{"id": "2408.01254", "title": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Dataflow and Analytical Modelling", "authors": ["Cristian Sestito", "Shady Agwa", "Themis Prodromakis"], "categories": ["cs.AI", "cs.AR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This work has been accepted by IEEE TCASAI for publication", "url": "http://arxiv.org/abs/2408.01254v3", "summary": "In order to follow the ever-growing computational complexity and data\nintensity of state-of-the-art AI models, new computing paradigms are being\nproposed. These paradigms aim at achieving high energy efficiency by mitigating\nthe Von Neumann bottleneck that relates to the energy cost of moving data\nbetween the processing cores and the memory. Convolutional Neural Networks\n(CNNs) are susceptible to this bottleneck, given the massive data they have to\nmanage. Systolic arrays (SAs) are promising architectures to mitigate data\ntransmission cost, thanks to high data utilization of Processing Elements\n(PEs). These PEs continuously exchange and process data locally based on\nspecific dataflows (such as weight stationary and row stationary), in turn\nreducing the number of memory accesses to the main memory. In SAs, convolutions\nare managed either as matrix multiplications or exploiting the raster-order\nscan of sliding windows. However, data redundancy is a primary concern\naffecting area, power, and energy. In this paper, we propose TrIM: a novel\ndataflow for SAs based on a Triangular Input Movement and compatible with CNN\ncomputing. TrIM maximizes the local input utilization, minimizes the weight\ndata movement, and solves the data redundancy problem. Furthermore, TrIM does\nnot incur the significant on-chip memory penalty introduced by the row\nstationary dataflow. When compared to state-of-the-art SA dataflows, the high\ndata utilization offered by TrIM guarantees ~10X less memory access.\nFurthermore, considering that PEs continuously overlap multiplications and\naccumulations, TrIM achieves high throughput (up to 81.8% higher than row\nstationary), other than requiring a limited number of registers (up to 15.6X\nfewer registers than row stationary).", "comment": "This work has been accepted by IEEE TCASAI for publication", "pdf_url": "http://arxiv.org/pdf/2408.01254v3", "cate": "cs.AI", "date": "2024-08-02", "updated": "2025-07-31", "AI": {"title_translation": "TrIM，用于卷积神经网络的三角输入移动脉动阵列：数据流和分析建模", "tldr": "TrIM是一种新的脉动阵列数据流，通过三角输入移动显著减少内存访问、提高吞吐量并减少寄存器使用，以解决卷积神经网络中的数据移动瓶颈。", "motivation": "为了应对最先进AI模型日益增长的计算复杂性和数据密集性，以及缓解冯·诺依曼瓶颈（数据移动的能耗），研究人员提出了新的计算范式。卷积神经网络（CNN）由于其大量数据管理而特别容易受到此瓶颈的影响。现有脉动阵列（SA）数据流存在数据冗余问题，影响面积、功耗和能耗。", "method": "本文提出了一种名为TrIM的新型脉动阵列数据流，其基于三角输入移动（Triangular Input Movement），并与CNN计算兼容。TrIM旨在最大化局部输入利用率，最小化权重数据移动，并解决数据冗余问题。此外，TrIM避免了行固定数据流引入的显著片上内存开销。", "result": "与现有脉动阵列数据流相比，TrIM提供高数据利用率，保证约10倍的内存访问减少。在处理性能上，TrIM实现了高达81.8%的吞吐量提升（高于行固定数据流），并且仅需要有限的寄存器数量（比行固定数据流少15.6倍）。", "conclusion": "TrIM通过其新颖的三角输入移动数据流，有效解决了卷积神经网络在脉动阵列中面临的数据移动和冗余问题，显著降低了内存访问，提高了吞吐量，并减少了硬件资源需求，使其成为一种高效的AI加速器解决方案。", "translation": "为了应对最先进人工智能模型日益增长的计算复杂性和数据密集性，新的计算范式正在被提出。这些范式旨在通过缓解与处理核心和内存之间数据移动的能耗相关的冯·诺依曼瓶颈，实现高能效。卷积神经网络（CNN）由于需要管理海量数据，易受此瓶颈影响。脉动阵列（SA）是缓解数据传输成本的有前景架构，这得益于处理单元（PE）的高数据利用率。这些PE根据特定的数据流（如权重固定和行固定）持续地在本地交换和处理数据，从而减少对主内存的访问次数。在SA中，卷积被管理为矩阵乘法或利用滑动窗口的栅格顺序扫描。然而，数据冗余是一个主要问题，影响面积、功耗和能耗。在本文中，我们提出了TrIM：一种基于三角输入移动（Triangular Input Movement）并与CNN计算兼容的新型SA数据流。TrIM最大化了局部输入利用率，最小化了权重数据移动，并解决了数据冗余问题。此外，TrIM不会产生行固定数据流引入的显著片上内存开销。与最先进的SA数据流相比，TrIM提供的高数据利用率保证了约10倍的内存访问减少。此外，考虑到PE持续重叠乘法和累加，TrIM实现了高吞吐量（比行固定高出81.8%），并且只需要有限的寄存器数量（比行固定少15.6倍）。", "summary": "本文提出了一种名为TrIM的新型脉动阵列（SA）数据流，旨在解决卷积神经网络（CNN）中因数据移动和冗余导致的高能耗问题。TrIM采用独特的三角输入移动机制，显著提高了处理单元的局部输入利用率，最小化了权重数据移动，并消除了数据冗余。与现有SA数据流相比，TrIM将内存访问减少了约10倍，吞吐量提高了高达81.8%，并减少了高达15.6倍的寄存器需求，从而提供了一种高效且资源友好的CNN加速解决方案。", "keywords": "脉动阵列, 数据流, 卷积神经网络, TrIM, 硬件加速", "comments": "TrIM的创新之处在于其提出的三角输入移动数据流，这是一种新颖的方法，可以直接解决传统脉动阵列在处理CNN时面临的数据冗余和内存访问瓶颈。通过优化数据流，它在不引入显著片上内存开销的情况下，实现了显著的性能提升和资源节约。这种方法对于设计更高效的AI硬件加速器具有重要意义。"}}
{"id": "2505.18102", "title": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": ["Takashi Ishida", "Thanawat Lodkaew", "Ikko Yamane"], "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Extended version of the paper presented as an Oral at the ICML 2025 Workshop on the Impact of Memorization on Trustworthy Foundation Models", "url": "http://arxiv.org/abs/2505.18102v2", "summary": "Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies.", "comment": "Extended version of the paper presented as an Oral at the ICML 2025\n  Workshop on the Impact of Memorization on Trustworthy Foundation Models", "pdf_url": "http://arxiv.org/pdf/2505.18102v2", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-31", "AI": {"title_translation": "如何在不泄露真实答案的情况下发布我的LLM基准？", "tldr": "该论文提出了一种发布LLM基准的方法，通过在解决方案中注入随机性，在不泄露真实答案的情况下进行发布，同时还能检测数据污染。", "motivation": "在互联网上发布大型语言模型（LLM）基准存在污染未来LLM的风险。常见的缓解措施是保持基准私有，但这需要对单一组织信任，并仍允许通过重复查询进行测试集过拟合。", "method": "为了解决现有问题，论文提出了一种在不完全泄露问题真实答案的情况下发布基准的方法，同时仍能公开评估LLM。主要思想是通过准备多个逻辑上正确的答案，并只将其中一个作为基准中的解决方案来向答案注入随机性。这降低了基准的最佳可能准确性（即贝叶斯准确性），并且有助于检测数据污染。", "result": "实验证据表明，该方法可以在各种基准、模型和训练方法上准确检测数据污染。", "conclusion": "该方法允许在不泄露真实答案的情况下公开评估LLM，并能有效检测数据污染。", "translation": "在互联网上发布大型语言模型（LLM）基准存在污染未来LLM的风险：基准可能会被无意（或有意）地用于训练或选择模型。一种常见的缓解措施是保持基准私有，并让参与者向组织者提交他们的模型或预测。然而，这种策略需要对单一组织信任，并且仍然允许通过重复查询进行测试集过拟合。为了克服这个问题，我们提出了一种在不完全披露问题真实答案的情况下发布基准的方法，同时仍能保持公开评估LLM的能力。我们的主要思想是通过准备几个逻辑上正确的答案，并且只将其中一个作为基准中的解决方案来向答案注入随机性。这降低了基准的最佳可能准确性，即贝叶斯准确性。这不仅有助于我们不披露真实答案，而且这种方法还提供了一种检测数据污染的测试。原则上，即使是能力完全的模型也不应超过贝叶斯准确性。如果一个模型尽管有此预期却超过了这个上限，这就是数据污染的强烈信号。我们提供了实验证据，表明我们的方法可以在各种基准、模型和训练方法上准确检测数据污染。", "summary": "该论文提出了一种创新的LLM基准发布方法，旨在解决数据污染和私有基准的局限性。通过向基准答案注入随机性（提供多个逻辑正确答案并仅包含一个作为解决方案），该方法不仅能够公开评估LLM而无需完全披露真实答案，还能通过检测模型是否超过理论上的贝叶斯准确性来有效识别数据污染。实验证明了其在多种场景下检测污染的准确性。", "keywords": "LLM基准, 数据污染, 贝叶斯准确性, 开放评估, 随机性", "comments": "这项工作提出了一种新颖且实用的方法来解决LLM基准测试中的核心挑战：如何在促进开放评估的同时防止数据污染。通过引入答案随机性和贝叶斯准确性作为污染检测机制，该方法提供了一个创新的框架，对于维护LLM评估的完整性和公平性具有重要意义。"}}
{"id": "2507.22896", "title": "iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement", "authors": ["Kohou Wang", "ZhaoXiang Liu", "Lin Bai", "Kun Fan", "Xiang Liu", "Huan Hu", "Kai Wang", "Shiguo Lian"], "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      17 pages, 12 figures", "url": "http://arxiv.org/abs/2507.22896v1", "summary": "It is crucial that robots' performance can be improved after deployment, as\nthey are inherently likely to encounter novel scenarios never seen before. This\npaper presents an innovative solution: an interactive learning-based robot\nsystem powered by a Multi-modal Large Language Model(MLLM). A key feature of\nour system is its ability to learn from natural dialogues with non-expert\nusers. We also propose chain of question to clarify the exact intent of the\nquestion before providing an answer and dual-modality retrieval modules to\nleverage these interaction events to avoid repeating same mistakes, ensuring a\nseamless user experience before model updates, which is in contrast to current\nmainstream MLLM-based robotic systems. Our system marks a novel approach in\nrobotics by integrating interactive learning, paving the way for superior\nadaptability and performance in diverse environments. We demonstrate the\neffectiveness and improvement of our method through experiments, both\nquantitively and qualitatively.", "comment": "17 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.22896v1", "cate": "cs.HC", "date": "2025-06-25", "updated": "2025-06-25", "AI": {"title_translation": "iLearnRobot：一种基于交互式学习的持续改进多模态机器人", "tldr": "iLearnRobot是一个基于多模态大语言模型（MLLM）的交互式学习机器人系统，能够通过与非专家用户的自然对话进行持续改进，并通过问题链和双模态检索模块避免重复错误。", "motivation": "机器人部署后性能提升至关重要，因为它们必然会遇到前所未见的新颖场景，现有系统难以在部署后持续改进和适应新环境。", "method": "本文提出了一种基于交互式学习的多模态机器人系统iLearnRobot，该系统由多模态大语言模型（MLLM）驱动。其关键特点是能够通过与非专家用户的自然对话进行学习。此外，还提出了“问题链”机制来在回答前澄清确切意图，以及“双模态检索模块”来利用交互事件避免重复相同的错误，确保在模型更新前提供无缝的用户体验。", "result": "通过定量和定性实验，证明了所提出方法的有效性和改进。", "conclusion": "iLearnRobot系统通过整合交互式学习，标志着机器人领域的一种新颖方法，为机器人在不同环境中实现卓越的适应性和性能铺平了道路。", "translation": "机器人部署后性能的提升至关重要，因为它们必然会遇到前所未见的新颖场景。本文提出了一种创新的解决方案：一个基于交互式学习的机器人系统，由多模态大语言模型（MLLM）提供支持。我们系统的一个关键特征是它能够通过与非专家用户的自然对话进行学习。我们还提出了“问题链”机制，以便在提供答案之前澄清问题的确切意图，以及“双模态检索模块”，以利用这些交互事件来避免重复相同的错误，从而在模型更新之前确保无缝的用户体验，这与当前主流的基于MLLM的机器人系统形成对比。我们的系统通过整合交互式学习，标志着机器人领域的一种新颖方法，为机器人在不同环境中实现卓越的适应性和性能铺平了道路。我们通过定量和定性实验证明了我们方法的有效性和改进。", "summary": "iLearnRobot是一个创新的交互式学习机器人系统，利用多模态大语言模型（MLLM）实现部署后的持续性能改进。它允许非专家用户通过自然对话进行教学，并通过“问题链”澄清意图和“双模态检索模块”避免重复错误，从而提供无缝的用户体验。该系统通过整合交互式学习，显著提升了机器人的适应性和性能，并通过实验验证了其有效性。", "keywords": "交互式学习, 多模态机器人, MLLM, 持续改进, iLearnRobot", "comments": "iLearnRobot的创新之处在于其将交互式学习与多模态大语言模型深度融合，特别强调了通过自然对话让非专家用户参与学习过程，并引入了“问题链”和“双模态检索模块”来优化用户体验和避免重复错误，这与当前主流MLLM机器人系统形成了鲜明对比，解决了机器人部署后适应性和持续改进的关键挑战。"}}
{"id": "2507.23179", "title": "Cyclotomy, cyclotomic cosets and arimetic propeties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$", "authors": ["Juncheng Zhou", "Hongfeng Wu"], "categories": ["math.NT", "cs.IT", "math.IT"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23179v1", "summary": "Arithmetic properties of some families in $\\frac{\\mathbb{F}_l[x]}{\\langle\nx^{p^sq^t}-1\\rangle}$ are obtained by using the cyclotomic classes of order 2\nwith respect to $n=p^sq^t$, where $p\\equiv3 \\mathrm{mod} 4$,\n$\\gcd(\\phi(p^s),\\phi(q^t))=2$, $l$ is a primitive root modulo $q^t$ and\n$\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$. The form of these cyclotomic classes\nenables us to further generalize the results obtained in \\cite{ref1}. The\nexplicit expressions of primitive idempotents of minimal ideals in\n$\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ are also obtained.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23179v1", "cate": "math.NT", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "分圆学、分圆陪集和 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质", "tldr": "本文利用2阶分圆类，研究了 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质，并得到了本原幂等元的显式表达式。", "motivation": "获得 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质。", "method": "利用关于 $n=p^sq^t$ 的2阶分圆类，其中 $p\\equiv3 \\mathrm{mod} 4$，$\\gcd(\\phi(p^s),\\phi(q^t))=2$， $l$ 是模 $q^t$ 的本原根，且 $\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$。", "result": "获得了 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质，并得到了其极小理想中本原幂等元的显式表达式。", "conclusion": "成功推导了特定条件下有限域中环的算术性质和本原幂等元的显式表达式，并推广了现有结果。", "translation": "通过使用关于 $n=p^sq^t$ 的2阶分圆类，获得了 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质，其中 $p\\equiv3 \\mathrm{mod} 4$，$\\gcd(\\phi(p^s),\\phi(q^t))=2$， $l$ 是模 $q^t$ 的本原根，且 $\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$。这些分圆类的形式使我们能够进一步推广 \\cite{ref1} 中获得的结果。还获得了 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中极小理想的本原幂等元的显式表达式。", "summary": "本文研究了在特定条件下环 $\\frac{\\mathbb{F}_l[x]}{\\langle x^{p^sq^t}-1\\rangle}$ 中某些族的算术性质。通过利用关于 $n=p^sq^t$ 的2阶分圆类，其中参数满足 $p\\equiv3 \\mathrm{mod} 4$，$\\gcd(\\phi(p^s),\\phi(q^t))=2$， $l$ 是模 $q^t$ 的本原根，且 $\\mathrm{ord}_{p^s}(l)=\\phi(p^s)/2$，作者得到了这些算术性质。此外，论文还给出了该环中极小理想的本原幂等元的显式表达式，并推广了先前文献中的结果。", "keywords": "分圆学, 分圆陪集, 算术性质, 本原幂等元, 有限域", "comments": "本文通过引入特定的分圆类形式，成功推广了先前文献中的结果，并在特定环结构中获得了重要的算术性质和本原幂等元的显式表达式，对有限域上的代数结构研究具有意义。"}}
{"id": "2507.23194", "title": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "authors": ["Jianghui Wang", "Vinay Joshi", "Saptarshi Majumder", "Xu Chao", "Bin Ding", "Ziqiong Liu", "Pratik Prabhanjan Brahma", "Dong Li", "Zicheng Liu", "Emad Barsoum"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23194v1", "summary": "The demand for AI-generated GPU kernels is rapidly growing, influenced by the\nneed for scalable, hardware-optimized solutions in both industry and academia.\nAs deep learning workloads grow in complexity and diversity, it is imperative\nto automate low-level kernel development to meet performance and productivity\ndemands. Major cloud providers, semiconductor companies, and research\ninstitutions are now investing heavily in AI-driven code generation for GPUs,\naiming to reduce manual optimization efforts while achieving near-expert\nperformance on hardware like AMD MI300X. The Triton language, a Python-based\nDSL for GPU programming, has emerged as a popular target for such AI-generated\nkernels due to its balance of performance and ease-of-coding. In this work, we\npresent an evaluation suite for Triton-based GPU kernels and GEAK (Generating\nEfficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs\nto generate performant Triton code specifically for AMD GPUs, including the AMD\nMI300X and MI250. GEAK leverages inference-time compute scaling to produce\nTriton-based GPU kernels using a reasoning loop adapted from Reflexion-style\nfeedback mechanisms. On two evaluation benchmarks, GEAK significantly\noutperformed the baselines of directly prompting frontier LLMs as well as\nReflexion-based generation pipelines by achieving correctness up to $63$% and\nexecution speed up of up to $2.59$X. These results highlight the promise of\nGEAK-like agentic code generation for accelerating the adoption of diverse\nhardware platforms and democratizing access to expert-level kernel performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23194v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Geak：引入Triton内核AI代理与评估基准", "tldr": "GEAK是一个利用LLM为AMD GPU生成高性能Triton内核的框架，并在评估基准上显著优于现有方法。", "motivation": "对AI生成的GPU内核的需求迅速增长，需要自动化低级内核开发以满足性能和生产力需求，并减少手动优化工作。", "method": "提出了一个用于基于Triton的GPU内核的评估套件，以及GEAK（生成高效AI中心GPU内核）框架。GEAK利用最先进的大型语言模型（LLMs）生成高性能的Triton代码，专为AMD GPU设计（包括AMD MI300X和MI250），并采用了一种改编自Reflexion风格反馈机制的推理循环。", "result": "在两个评估基准上，GEAK在正确性方面达到了63%，执行速度提升了2.59倍，显著优于直接提示前沿LLM以及基于Reflexion的生成管道。", "conclusion": "GEAK这类代理式代码生成有望加速多样化硬件平台的采用，并使专家级内核性能的获取民主化。", "translation": "对AI生成的GPU内核的需求正在迅速增长，这受到工业界和学术界对可扩展、硬件优化解决方案的需求的影响。随着深度学习工作负载的复杂性和多样性增加，自动化低级内核开发以满足性能和生产力需求变得势在必行。主要的云服务提供商、半导体公司和研究机构现在正大力投资于AI驱动的GPU代码生成，旨在减少手动优化工作，同时在AMD MI300X等硬件上实现接近专家级的性能。Triton语言作为一种基于Python的GPU编程DSL，因其在性能和易于编码之间的平衡而成为此类AI生成内核的流行目标。在这项工作中，我们提出了一个用于基于Triton的GPU内核的评估套件，以及GEAK（生成高效AI中心GPU内核）——一个利用最先进的大型语言模型生成高性能Triton代码的框架，专门用于AMD GPU，包括AMD MI300X和MI250。GEAK利用推理时计算扩展，通过一种改编自Reflexion风格反馈机制的推理循环来生成基于Triton的GPU内核。在两个评估基准上，GEAK显著优于直接提示前沿LLM以及基于Reflexion的生成管道，实现了高达63%的正确性，并使执行速度提高了2.59倍。这些结果突显了GEAK这类代理式代码生成在加速多样化硬件平台采用和使专家级内核性能获取民主化方面的潜力。", "summary": "本文介绍了GEAK框架，一个利用大型语言模型为AMD GPU（包括MI300X和MI250）生成高性能Triton内核的解决方案。针对AI生成GPU内核日益增长的需求，GEAK采用了一种基于Reflexion风格反馈机制的推理循环。实验结果表明，GEAK在正确性方面最高达到63%，执行速度最高提升2.59倍，显著优于直接提示LLM和基于Reflexion的基线方法。这表明GEAK-like的代理式代码生成在加速硬件平台采纳和普及专家级内核性能方面具有巨大潜力。", "keywords": "AI生成GPU内核, Triton, LLMs, AMD GPU, 代码生成", "comments": "该论文提出了一种创新的、基于LLM的GPU内核代码生成框架GEAK，专注于Triton语言和AMD GPU，解决了GPU编程中低级内核开发自动化和性能优化的挑战。其亮点在于引入了Reflexion风格的推理循环来提升生成代码的质量和性能，并通过具体评估展示了显著的性能提升。这对于加速AI工作负载在不同硬件上的部署和降低专家级性能的门槛具有重要意义。"}}
{"id": "2507.23349", "title": "Optimal Transport Learning: Balancing Value Optimization and Fairness in Individualized Treatment Rules", "authors": ["Wenhai Cui", "Xiaoting Ji", "Wen Su", "Xiaodong Yan", "Xingqiu Zhao"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23349v1", "summary": "Individualized treatment rules (ITRs) have gained significant attention due\nto their wide-ranging applications in fields such as precision medicine,\nridesharing, and advertising recommendations. However, when ITRs are influenced\nby sensitive attributes such as race, gender, or age, they can lead to outcomes\nwhere certain groups are unfairly advantaged or disadvantaged. To address this\ngap, we propose a flexible approach based on the optimal transport theory,\nwhich is capable of transforming any optimal ITR into a fair ITR that ensures\ndemographic parity. Recognizing the potential loss of value under fairness\nconstraints, we introduce an ``improved trade-off ITR,\" designed to balance\nvalue optimization and fairness while accommodating varying levels of fairness\nthrough parameter adjustment. To maximize the value of the improved trade-off\nITR under specific fairness levels, we propose a smoothed fairness constraint\nfor estimating the adjustable parameter. Additionally, we establish a\ntheoretical upper bound on the value loss for the improved trade-off ITR. We\ndemonstrate performance of the proposed method through extensive simulation\nstudies and application to the Next 36 entrepreneurial program dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23349v1", "cate": "stat.ML", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "最佳传输学习：个性化治疗规则中价值优化与公平性的平衡", "tldr": "本文提出了一种基于最优传输理论的方法，将任何最优的个性化治疗规则（ITRs）转化为公平的ITRs，并通过“改进的权衡ITR”来平衡价值优化和公平性，同时量化了价值损失。", "motivation": "个性化治疗规则（ITRs）在应用中可能因敏感属性导致某些群体被不公平地对待，需要解决ITRs的公平性问题。", "method": "提出了一种基于最优传输理论的灵活方法，可以将任意最优ITR转换为确保人口统计学平等的公平ITR。为了平衡价值优化和公平性，引入了“改进的权衡ITR”，并通过平滑公平性约束来估计可调参数，以最大化特定公平水平下的价值。", "result": "通过广泛的模拟研究和在Next 36创业项目数据集上的应用，证明了所提出方法的性能。还为改进的权衡ITR建立了价值损失的理论上限。", "conclusion": "本文成功地提出了一种在个性化治疗规则中平衡价值优化和公平性的方法，并通过理论和实证验证了其有效性。", "translation": "个性化治疗规则（ITRs）因其在精准医疗、网约车和广告推荐等领域的广泛应用而受到广泛关注。然而，当ITRs受到种族、性别或年龄等敏感属性的影响时，它们可能导致某些群体受到不公平的优势或劣势。为了解决这一差距，我们提出了一种基于最优传输理论的灵活方法，该方法能够将任何最优ITR转化为确保人口统计学公平的公平ITR。认识到在公平性约束下可能存在的价值损失，我们引入了一种“改进的权衡ITR”，旨在平衡价值优化和公平性，同时通过参数调整适应不同程度的公平性。为了在特定公平水平下最大化改进的权衡ITR的价值，我们提出了一种平滑的公平性约束来估计可调参数。此外，我们为改进的权衡ITR建立了价值损失的理论上限。我们通过广泛的模拟研究和在Next 36创业项目数据集上的应用展示了所提出方法的性能。", "summary": "本文针对个性化治疗规则（ITRs）中因敏感属性导致的公平性问题，提出了一种基于最优传输理论的灵活方法。该方法能将任何最优ITR转化为满足人口统计学公平的公平ITR。为解决公平性带来的潜在价值损失，引入了“改进的权衡ITR”，旨在通过参数调整平衡价值优化与公平性。文章还提出了一种平滑公平性约束来优化参数，并建立了价值损失的理论上限。实验验证了该方法在模拟和真实数据集上的有效性。", "keywords": "个性化治疗规则, 公平性, 最优传输, 价值优化, 权衡", "comments": "这篇论文通过引入最优传输理论来解决个性化治疗规则中的公平性问题，具有创新性。它不仅关注了公平性，还通过“改进的权衡ITR”提供了一种灵活的机制来平衡公平性和价值优化，这在实际应用中非常重要。理论上提供了价值损失的上限，增加了方法的严谨性。"}}
{"id": "2411.11098", "title": "MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild", "authors": ["Xi Fang", "Jiankun Wang", "Xiaochen Cai", "Shangqian Chen", "Shuwen Yang", "Haoyi Tao", "Nan Wang", "Lin Yao", "Linfeng Zhang", "Guolin Ke"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.11098v3", "summary": "In recent decades, chemistry publications and patents have increased rapidly.\nA significant portion of key information is embedded in molecular structure\nfigures, complicating large-scale literature searches and limiting the\napplication of large language models in fields such as biology, chemistry, and\npharmaceuticals. The automatic extraction of precise chemical structures is of\ncritical importance. However, the presence of numerous Markush structures in\nreal-world documents, along with variations in molecular image quality, drawing\nstyles, and noise, significantly limits the performance of existing optical\nchemical structure recognition (OCSR) methods. We present MolParser, a novel\nend-to-end OCSR method that efficiently and accurately recognizes chemical\nstructures from real-world documents, including difficult Markush structure. We\nuse a extended SMILES encoding rule to annotate our training dataset. Under\nthis rule, we build MolParser-7M, the largest annotated molecular image dataset\nto our knowledge. While utilizing a large amount of synthetic data, we employed\nactive learning methods to incorporate substantial in-the-wild data,\nspecifically samples cropped from real patents and scientific literature, into\nthe training process. We trained an end-to-end molecular image captioning\nmodel, MolParser, using a curriculum learning approach. MolParser significantly\noutperforms classical and learning-based methods across most scenarios, with\npotential for broader downstream applications. The dataset is publicly\navailable in huggingface.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.11098v3", "cate": "cs.CV", "date": "2024-11-17", "updated": "2025-07-31", "AI": {"title_translation": "MolParser：野外分子结构的端到端视觉识别", "tldr": "MolParser是一个新颖的端到端光学化学结构识别（OCSR）方法，能够高效准确地识别真实文档中的化学结构，包括复杂的马库什结构，并且在大多数场景下显著优于现有方法。", "motivation": "化学出版物和专利中包含大量分子结构图，这些关键信息难以大规模检索，限制了大型语言模型在生物、化学和制药领域的应用。现有的光学化学结构识别（OCSR）方法受限于马库什结构、图像质量、绘图风格和噪声等因素，性能不佳，因此迫切需要自动提取精确的化学结构。", "method": "MolParser采用端到端的光学化学结构识别（OCSR）方法。它使用扩展的SMILES编码规则标注训练数据集，并构建了迄今为止最大的分子图像数据集MolParser-7M。该方法结合了大量合成数据，并通过主动学习将从真实专利和科学文献中裁剪的“野外”数据纳入训练过程。MolParser采用课程学习方法训练了一个端到端的分子图像字幕模型。", "result": "MolParser在大多数场景下显著优于经典和基于学习的方法。研究团队构建了迄今为止最大的标注分子图像数据集MolParser-7M。该数据集已在huggingface上公开。", "conclusion": "MolParser是一种高效准确的端到端光学化学结构识别方法，能够有效处理真实世界文档中的复杂分子结构（包括马库什结构），并在性能上超越现有方法，具有广泛的下游应用潜力。", "translation": "在最近几十年里，化学出版物和专利数量迅速增长。其中很大一部分关键信息嵌入在分子结构图中，这使得大规模文献检索变得复杂，并限制了大型语言模型在生物、化学和制药等领域的应用。自动提取精确的化学结构至关重要。然而，真实文档中存在大量的马库什结构，以及分子图像质量、绘图风格和噪声的变化，极大地限制了现有光学化学结构识别（OCSR）方法的性能。我们提出了MolParser，一种新颖的端到端OCSR方法，能够高效准确地识别真实文档中的化学结构，包括复杂的马库什结构。我们使用扩展的SMILES编码规则来标注我们的训练数据集。在此规则下，我们构建了MolParser-7M，这是我们所知的最大标注分子图像数据集。在利用大量合成数据的同时，我们采用主动学习方法，将大量“野外”数据（特别是从真实专利和科学文献中裁剪的样本）纳入训练过程。我们使用课程学习方法训练了一个端到端分子图像字幕模型MolParser。MolParser在大多数场景下显著优于经典和基于学习的方法，具有更广泛的下游应用潜力。该数据集已在huggingface上公开。", "summary": "MolParser是一种用于从真实文档中自动识别分子结构（包括复杂马库什结构）的端到端光学化学结构识别（OCSR）方法。该研究旨在解决现有OCSR方法在处理真实世界图像质量、绘图风格和噪声变化时的局限性。MolParser通过使用扩展的SMILES编码规则，构建了迄今为止最大的分子图像数据集MolParser-7M，并结合合成数据和通过主动学习纳入的真实世界数据进行训练。实验结果表明，MolParser在大多数情况下显著优于传统和基于学习的方法，并具有广泛的下游应用潜力。", "keywords": "分子结构识别, OCSR, MolParser, 马库什结构, SMILES", "comments": "MolParser的创新点在于其端到端的方法以及对复杂马库什结构的处理能力，这对于提高化学文献中关键信息的自动化提取效率至关重要。通过构建迄今为止最大的标注数据集MolParser-7M，并结合主动学习策略，显著提升了模型在真实世界场景下的鲁棒性和准确性。这项工作对于推动大型语言模型在化学、生物和制药领域的应用具有重要意义。"}}
{"id": "2507.22810", "title": "VRISE: A Virtual Reality Platfrom for Immersive and Interactive Surveying Education", "authors": ["Daniel Udekwe", "Dimitrios Bolkas", "Eren Erman Ozguven", "Ren Moses", "Qianwen Guo"], "categories": ["cs.HC", "cs.ET", "cs.SE"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22810v2", "summary": "Surveying is a core component of civil engineering education, requiring\nstudents to engage in hands-on spatial measurement, instrumentation handling,\nand field-based decision-making. However, traditional instruction often poses\nlogistical and cognitive challenges that can hinder accessibility and student\nengagement. While virtual laboratories have gained traction in engineering\neducation, few are purposefully designed to support flexible, adaptive learning\nin surveying. To address this gap, we developed Virtual Reality for Immersive\nand Interactive Surveying Education (VRISE), an immersive virtual reality\nlaboratory that replicates ground-based and aerial surveying tasks through\ncustomizable, accessible, and user-friendly modules. VRISE features interactive\nexperiences such as differential leveling with a digital level equipment and\nwaypoint-based drone navigation, enhanced by input smoothing, adaptive\ninterfaces, and real-time feedback to accommodate diverse learning styles.\nEvaluation across multiple user sessions demonstrated consistent gains in\nmeasurement accuracy, task efficiency, and interaction quality, with a clear\nprogression in skill development across the ground-based and aerial surveying\nmodalities. By reducing cognitive load and physical demands, even in tasks\nrequiring fine motor control and spatial reasoning, VRISE demonstrates the\npotential of immersive, repeatable digital environments to enhance surveying\neducation, broaden participation, and strengthen core competencies in a safe\nand engaging setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22810v2", "cate": "cs.HC", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "VRISE：一个用于沉浸式互动测量教育的虚拟现实平台", "tldr": "VRISE是一个虚拟现实平台，通过复制地面和空中测量任务，旨在解决传统测量教育的局限性，提高学习者的准确性、效率和技能发展。", "motivation": "传统的测量教学存在后勤和认知挑战，阻碍了可及性和学生参与度。虽然虚拟实验室在工程教育中有所发展，但很少有专门为支持测量学中灵活、适应性学习而设计的。", "method": "开发了VRISE（沉浸式互动测量教育虚拟现实平台），这是一个沉浸式虚拟现实实验室，通过可定制、易于访问和用户友好的模块复制地面和空中测量任务。VRISE具有差分水准测量和基于航点的无人机导航等互动体验，并通过输入平滑、自适应界面和实时反馈进行增强。", "result": "多用户会话的评估表明，在测量精度、任务效率和交互质量方面持续提高，在地面和空中测量模式下的技能发展有明显进步。", "conclusion": "VRISE通过减少认知负荷和身体需求，即使在需要精细运动控制和空间推理的任务中，也展示了沉浸式、可重复的数字环境在增强测量教育、扩大参与和巩固核心能力方面的潜力。", "translation": "测量是土木工程教育的核心组成部分，要求学生进行实践空间测量、仪器操作和基于现场的决策。然而，传统的教学常常带来后勤和认知挑战，这会阻碍可及性和学生参与度。虽然虚拟实验室在工程教育中越来越受欢迎，但很少有专门设计用于支持测量学中灵活、适应性学习的。为了弥补这一空白，我们开发了VRISE（沉浸式互动测量教育虚拟现实平台），这是一个沉浸式虚拟现实实验室，通过可定制、易于访问和用户友好的模块复制地面和空中测量任务。VRISE具有互动体验，例如使用数字水准仪进行差分水准测量和基于航点的无人机导航，并通过输入平滑、自适应界面和实时反馈进行增强，以适应不同的学习风格。对多个用户会话的评估表明，在测量精度、任务效率和交互质量方面持续提高，在地面和空中测量模式下的技能发展有明显进步。通过减少认知负荷和身体需求，即使在需要精细运动控制和空间推理的任务中，VRISE也展示了沉浸式、可重复的数字环境在增强测量教育、扩大参与和巩固安全和引人入胜的环境中的核心能力方面的潜力。", "summary": "本研究开发了VRISE，一个沉浸式虚拟现实平台，旨在革新测量教育。该平台通过可定制模块模拟地面和空中测量任务，提供如差分水准测量和无人机导航等互动体验。评估结果显示，VRISE显著提高了学生的测量精度、任务效率和技能发展，证明了虚拟现实在提供安全、引人入胜且可重复的学习环境方面的潜力。", "keywords": "虚拟现实, 测量教育, 沉浸式学习, 土木工程, VRISE", "comments": "VRISE的创新之处在于其专门针对测量教育的虚拟现实应用，通过模拟实际任务并提供自适应反馈，有效解决了传统教学中的局限性。其重要性在于提供了一个安全、可重复且能降低认知负荷的实践学习环境，有望显著提升学生的核心能力和学习参与度。"}}
{"id": "2507.22921", "title": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers", "authors": ["Lee Harris"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22921v1", "summary": "Language models can capture complex relationships in given text, but these\nare notorious for being costly and for producing information that does not\nexist (i.e., hallucinations). Furthermore, the resources invested into\nproducing this information would be wasted if it were incorrect. We address\nthese issues by proposing, implementing, and applying the Language Model Chain\n(LMC) algorithm. In this, a language model's response to a given prompt about\ngiven text is only correct if it exists in the collection of possible (i.e.,\ncandidate) answers, and text corresponding to incorrect responses is fed into a\nmore predictive (but slower) language model. This process is repeated for a\ncollection of language models, or until all predictions about the text are\ncorrect. We used the LMC algorithm to extract patient dates of birth from\nmedical documents, and combining a collection of language models in a\nmulti-stage cascade significantly increased prediction speed and accuracy over\nindividual language models, while greatly reducing the number of corresponding\nhallucinations. We believe that the novel LMC algorithm significantly\ncontributes to the knowledge extraction field, and that this should be explored\nmuch further in the future.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22921v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "使用级联语言模型链和候选答案进行快速准确的上下文知识提取", "tldr": "本文提出了一种名为语言模型链 (LMC) 的算法，通过结合多个语言模型并利用候选答案来显著提高知识提取的速度和准确性，同时减少幻觉。", "motivation": "语言模型在文本中捕获复杂关系时存在成本高昂和产生幻觉（即生成不存在的信息）的问题。此外，如果生成的信息不正确，投入的资源将被浪费。", "method": "本文提出、实现并应用了语言模型链 (LMC) 算法。在该算法中，语言模型对给定文本提示的响应只有在候选答案集合中存在时才被认为是正确的。如果响应不正确，则将对应的文本输入到更具预测性（但速度较慢）的语言模型中。这个过程对一系列语言模型重复进行，直到所有关于文本的预测都正确。", "result": "使用LMC算法从医疗文档中提取患者出生日期，结果显示，与单个语言模型相比，结合多阶段级联的语言模型集合显著提高了预测速度和准确性，同时大大减少了相应的幻觉数量。", "conclusion": "LMC算法显著促进了知识提取领域的发展，并值得在未来进行更深入的探索。", "translation": "语言模型可以捕获给定文本中的复杂关系，但它们因成本高昂和产生不存在的信息（即幻觉）而臭名昭著。此外，如果生成的信息不正确，投入到生成这些信息中的资源将被浪费。我们通过提出、实现和应用语言模型链（LMC）算法来解决这些问题。在该算法中，语言模型对给定文本提示的响应只有在可能的（即候选）答案集合中存在时才被认为是正确的，并且对应于不正确响应的文本会被输入到更具预测性（但速度较慢）的语言模型中。这个过程对一系列语言模型重复进行，或者直到所有关于文本的预测都正确。我们使用LMC算法从医疗文档中提取患者出生日期，并且将一系列语言模型以多阶段级联的方式结合起来，与单个语言模型相比，显著提高了预测速度和准确性，同时大大减少了相应的幻觉数量。我们相信新颖的LMC算法对知识提取领域做出了重大贡献，并且应该在未来进行更深入的探索。", "summary": "本文提出了一种新颖的语言模型链（LMC）算法，旨在解决传统语言模型在知识提取中存在的成本高和幻觉问题。LMC算法通过级联多个语言模型，并结合候选答案进行验证，确保提取信息的准确性。如果初始模型的预测不准确，则将其输入到更强大的模型进行再处理，直至结果正确。在医疗文档中提取患者出生日期的应用案例表明，LMC显著提升了预测速度和准确性，并有效减少了幻觉，证明了其在知识提取领域的潜力。", "keywords": "语言模型链, 知识提取, 幻觉, 级联语言模型, 候选答案", "comments": "LMC算法的创新之处在于其级联结构和对候选答案的验证机制，这有效解决了语言模型在知识提取中常见的幻觉问题，并平衡了速度与准确性。其在医疗领域的应用展示了实际价值，对需要高准确性信息提取的场景具有重要意义。未来，该算法在不同领域和数据类型上的泛化能力值得进一步研究。"}}
{"id": "2507.20293", "title": "Decentralized Uncertainty-Aware Multi-Agent Collision Avoidance with Model Predictive Path Integral", "authors": ["Stepan Dergachev", "Konstantin Yakovlev"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This is a pre-print of the paper accepted to IROS2025. The manuscript includes 8 pages, 4 figures, and 1 table. A supplementary video is available at this https URL Updated version: added link to source code in the abstract; updated experimental results description in Section VI.A; updated author affiliation and funding information; minor typo corrections", "url": "http://arxiv.org/abs/2507.20293v2", "summary": "Decentralized multi-agent navigation under uncertainty is a complex task that\narises in numerous robotic applications. It requires collision avoidance\nstrategies that account for both kinematic constraints, sensing and action\nexecution noise. In this paper, we propose a novel approach that integrates the\nModel Predictive Path Integral (MPPI) with a probabilistic adaptation of\nOptimal Reciprocal Collision Avoidance. Our method ensures safe and efficient\nmulti-agent navigation by incorporating probabilistic safety constraints\ndirectly into the MPPI sampling process via a Second-Order Cone Programming\nformulation. This approach enables agents to operate independently using local\nnoisy observations while maintaining safety guarantees. We validate our\nalgorithm through extensive simulations with differential-drive robots and\nbenchmark it against state-of-the-art methods, including ORCA-DD and B-UAVC.\nResults demonstrate that our approach outperforms them while achieving high\nsuccess rates, even in densely populated environments. Additionally, validation\nin the Gazebo simulator confirms its practical applicability to robotic\nplatforms. A source code is available at\nhttp://github.com/PathPlanning/MPPI-Collision-Avoidance.", "comment": "This is a pre-print of the paper accepted to IROS2025. The manuscript\n  includes 8 pages, 4 figures, and 1 table. A supplementary video is available\n  at https://youtu.be/_D4zDYJ4KCk Updated version: added link to source code in\n  the abstract; updated experimental results description in Section VI.A;\n  updated author affiliation and funding information; minor typo corrections", "pdf_url": "http://arxiv.org/pdf/2507.20293v2", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-31", "AI": {"title_translation": "基于模型预测路径积分的去中心化不确定性感知多智能体避碰", "tldr": "本文提出一种结合模型预测路径积分（MPPI）和概率最优互惠避碰（ORCA）的新方法，通过二阶锥规划将概率安全约束融入MPPI采样，实现了不确定性下安全高效的去中心化多智能体避碰，且性能优于现有SOTA方法。", "motivation": "不确定性下的去中心化多智能体导航是一项复杂任务，需要考虑运动学约束、传感和动作执行噪声的避碰策略。", "method": "该论文提出一种新颖的方法，将模型预测路径积分 (MPPI) 与最优互惠避碰 (ORCA) 的概率自适应相结合。通过二阶锥规划 (SOCP) 公式将概率安全约束直接整合到MPPI采样过程中，确保安全高效的多智能体导航，使智能体能够利用局部噪声观测独立操作同时保持安全保障。", "result": "通过差分驱动机器人的大量仿真验证，并与ORCA-DD和B-UAVC等最先进的方法进行基准测试。结果表明，该方法在密集环境中也能实现高成功率并优于现有方法。在Gazebo模拟器中的验证也证实了其实际适用性。", "conclusion": "该方法能够使智能体在利用局部噪声观测独立操作的同时，保持安全保障，实现安全高效的多智能体导航，并在复杂环境下表现出优越性。", "translation": "不确定性下的去中心化多智能体导航是众多机器人应用中出现的一项复杂任务。它需要考虑运动学约束、传感和动作执行噪声的避碰策略。本文提出了一种新颖的方法，将模型预测路径积分 (MPPI) 与最优互惠避碰的概率自适应相结合。我们的方法通过二阶锥规划公式将概率安全约束直接整合到MPPI采样过程中，从而确保安全高效的多智能体导航。这种方法使智能体能够利用局部噪声观测独立操作，同时保持安全保障。我们通过差分驱动机器人的大量仿真验证了我们的算法，并将其与ORCA-DD和B-UAVC等最先进的方法进行了基准测试。结果表明，即使在智能体密集的（或人口密集的）环境中，我们的方法也优于它们，同时实现了高成功率。此外，在Gazebo模拟器中的验证证实了其对机器人平台的实际适用性。源代码可在http://github.com/PathPlanning/MPPI-Collision-Avoidance获取。", "summary": "本文提出一种基于模型预测路径积分 (MPPI) 和概率最优互惠避碰 (ORCA) 的去中心化不确定性感知多智能体避碰新方法。该方法通过二阶锥规划将概率安全约束融入MPPI采样，使智能体能独立利用局部噪声观测进行安全高效导航。实验证明，该方法在复杂和密集环境下均优于现有SOTA方法，并具有实际应用价值。", "keywords": "多智能体避碰, 模型预测路径积分, 不确定性感知, 去中心化导航, 概率安全约束", "comments": "该论文的创新点在于将概率安全约束通过二阶锥规划融入到MPPI的采样过程中，有效解决了去中心化多智能体在不确定性下的避碰问题。其优势在于智能体能够独立操作并保持安全保障，且在实际应用中表现出色，代码开源也利于后续研究。"}}
{"id": "2507.23508", "title": "Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion", "authors": ["Timing Li", "Bing Cao", "Jiahe Feng", "Haifang Cao", "Qinghau Hu", "Pengfei Zhu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23508v1", "summary": "Image fusion synthesizes complementary information from multiple sources,\nmitigating the inherent limitations of unimodal imaging systems. Accurate image\nregistration is essential for effective multi-source data fusion. However,\nexisting registration methods, often based on image translation in Euclidean\nspace, fail to handle cross-modal misalignment effectively, resulting in\nsuboptimal alignment and fusion quality. To overcome this limitation, we\nexplore image alignment in non-Euclidean space and propose a Hyperbolic Cycle\nAlignment Network (Hy-CycleAlign). To the best of our knowledge, Hy-CycleAlign\nis the first image registration method based on hyperbolic space. It introduces\na dual-path cross-modal cyclic registration framework, in which a forward\nregistration network aligns cross-modal inputs, while a backward registration\nnetwork reconstructs the original image, forming a closed-loop registration\nstructure with geometric consistency. Additionally, we design a Hyperbolic\nHierarchy Contrastive Alignment (H$^{2}$CA) module, which maps images into\nhyperbolic space and imposes registration constraints, effectively reducing\ninterference caused by modality discrepancies. We further analyze image\nregistration in both Euclidean and hyperbolic spaces, demonstrating that\nhyperbolic space enables more sensitive and effective multi-modal image\nregistration. Extensive experiments on misaligned multi-modal images\ndemonstrate that our method significantly outperforms existing approaches in\nboth image alignment and fusion. Our code will be publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23508v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "红外-可见光图像融合的双曲循环对齐", "tldr": "本文提出了一种基于双曲空间的新型图像配准方法Hy-CycleAlign，通过双路径循环配准框架和双曲层级对比对齐模块，有效解决了跨模态图像配准中的错位问题，显著提升了图像对齐和融合的质量。", "motivation": "现有的图像配准方法通常基于欧几里得空间中的图像平移，但它们无法有效处理跨模态错位，导致配准和融合质量不佳。为了克服这一限制，本文探索在非欧几里得空间中进行图像对齐。", "method": "本文提出了一种名为Hyperbolic Cycle Alignment Network (Hy-CycleAlign) 的方法，这是首个基于双曲空间的图像配准方法。它引入了一个双路径跨模态循环配准框架，其中前向配准网络对齐跨模态输入，后向配准网络重建原始图像，形成具有几何一致性的闭环配准结构。此外，设计了一个Hyperbolic Hierarchy Contrastive Alignment (H²CA) 模块，将图像映射到双曲空间并施加配准约束，有效减少模态差异引起的干扰。", "result": "在错位的多模态图像上进行了大量实验，结果表明该方法在图像对齐和融合方面均显著优于现有方法。", "conclusion": "双曲空间能够实现更灵敏、更有效的多模态图像配准。本文提出的方法显著提高了图像对齐和融合的性能，克服了现有欧几里得空间方法的局限性。", "translation": "图像融合综合了来自多个源的互补信息，减轻了单模态成像系统固有的局限性。准确的图像配准对于有效的多源数据融合至关重要。然而，现有的配准方法通常基于欧几里得空间中的图像平移，未能有效处理跨模态错位，导致次优的对齐和融合质量。为了克服这一限制，我们探索了非欧几里得空间中的图像对齐，并提出了一种双曲循环对齐网络（Hy-CycleAlign）。据我们所知，Hy-CycleAlign是第一个基于双曲空间的图像配准方法。它引入了一个双路径跨模态循环配准框架，其中前向配准网络对齐跨模态输入，而后向配准网络重建原始图像，形成一个具有几何一致性的闭环配准结构。此外，我们设计了一个双曲层级对比对齐（H²CA）模块，该模块将图像映射到双曲空间并施加配准约束，有效减少了模态差异引起的干扰。我们进一步分析了欧几里得和双曲空间中的图像配准，证明双曲空间能够实现更灵敏、更有效的多模态图像配准。在错位多模态图像上进行的大量实验表明，我们的方法在图像对齐和融合方面均显著优于现有方法。我们的代码将公开可用。", "summary": "本文提出了一种新颖的基于双曲空间的图像配准方法Hy-CycleAlign，旨在解决现有欧几里得空间方法在跨模态图像（如红外与可见光）配准中存在的错位问题。Hy-CycleAlign引入了一个双路径循环配准框架，结合前向和后向网络以确保几何一致性，并设计了H²CA模块，通过在双曲空间中施加约束来减少模态差异。实验证明，该方法在图像对齐和融合方面均显著优于现有技术，表明双曲空间在多模态图像配准中具有更高的敏感性和有效性。", "keywords": "图像配准, 双曲空间, 图像融合, 跨模态, 循环对齐", "comments": "本文的创新点在于首次将双曲空间应用于图像配准领域，并提出了一个端到端的循环对齐网络。通过利用双曲空间的独特几何特性，它能够更有效地处理跨模态图像之间的复杂非线性形变和模态差异，从而显著提升了图像融合的质量。这为多模态数据处理提供了一个全新的视角和强大的工具。"}}
{"id": "2504.11952", "title": "Robust and Fine-Grained Detection of AI Generated Texts", "authors": ["Ram Mohan Rao Kadiyala", "Siddartha Pullakhandam", "Kanwal Mehreen", "Drishti Sharma", "Siddhant Gupta", "Jebish Purbey", "Ashay Srivastava", "Subhasya TippaReddy", "Arvind Reddy Bobbili", "Suraj Telugara Chandrashekhar", "Modabbir Adeeb", "Srinadh Vura", "Suman Debnath", "Hamza Farooq"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      18 pages, 6 figures", "url": "http://arxiv.org/abs/2504.11952v3", "summary": "An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.", "comment": "18 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2504.11952v3", "cate": "cs.CL", "date": "2025-04-16", "updated": "2025-07-31", "AI": {"title_translation": "鲁棒且细粒度的AI生成文本检测", "tldr": "提出一套模型和240万规模的新数据集，用于鲁棒且细粒度地检测AI生成文本，尤其擅长处理人机合著文本，并在多种复杂情境下表现良好。", "motivation": "现有AI生成内容检测系统难以应对日益增多的先进LLM生成内容，尤其在短文本和人机合著文本检测方面表现不佳。", "method": "本文引入了一套基于Token分类的模型，并在一个包含超过240万条人机合著文本的新数据集上进行训练。该数据集涵盖23种语言，主要由多种流行专有LLM合作生成。", "result": "模型在未见领域、未见生成器、非母语作者文本以及对抗性输入等多种复杂情况下表现良好。研究还展示了模型在不同领域和生成器上的性能，并比较了模型对抗性方法、输入文本长度以及生成文本与原始人工文本特征的性能。", "conclusion": "本文提出的模型和新数据集能有效实现对AI生成文本的鲁棒且细粒度检测，尤其在处理人机合著文本以及应对各种复杂和挑战性场景方面表现出色。", "translation": "一个理想的机器生成内容检测系统应该能够很好地适用于任何生成器，因为每天都有更多先进的LLM出现。现有系统往往难以准确识别较短文本中的AI生成内容。此外，并非所有文本都可能完全由人类或LLM创作，因此我们更关注部分情况，即人机合著文本。我们的论文引入了一套为Token分类任务构建的模型，这些模型在一个广泛的人机合著文本集合上进行训练，并在未见领域、未见生成器、非母语使用者文本以及对抗性输入文本上表现良好。我们还引入了一个包含超过240万条此类文本的新数据集，这些文本主要由几种流行的专有LLM用23种语言合著。我们还展示了模型在每个领域和生成器的文本上的性能发现。其他发现包括与每种对抗性方法、输入文本长度以及生成文本与原始人类创作文本特征的性能比较。", "summary": "针对现有AI文本检测系统在短文本和人机合著文本上的不足，本文提出了一套基于Token分类的模型，并在一个包含23种语言、超过240万条人机合著文本的新数据集上进行训练。该模型在未见领域、未见生成器、非母语文本和对抗性输入等多种复杂情况下均表现出色，实现了对AI生成文本的鲁棒且细粒度检测。", "keywords": "AI生成文本, 文本检测, Token分类, 人机合著文本, 鲁棒检测", "comments": "本文的创新点在于构建了一个大规模（240万条，23种语言）且专注于人机合著文本的新数据集，并提出了基于Token分类的模型以实现细粒度的AI生成文本检测。其重要性在于有效解决了现有系统在短文本、人机合著文本以及面对多样化生成器和对抗性输入时的检测难题，提升了AI文本检测的鲁棒性和实用性。"}}
{"id": "2507.23120", "title": "Vibe Modeling: Challenges and Opportunities", "authors": ["Jordi Cabot"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23120v1", "summary": "There is a pressing need for better development methods and tools to keep up\nwith the growing demand and increasing complexity of new software systems. New\ntypes of user interfaces, the need for intelligent components, sustainability\nconcerns, ... bring new challenges that we need to handle. In the last years,\nmodel-driven engineering (MDE) has been key to improving the quality and\nproductivity of software development, but models themselves are becoming\nincreasingly complex to specify and manage. At the same time, we are witnessing\nthe growing popularity of vibe coding approaches that rely on Large Language\nModels (LLMs) to transform natural language descriptions into running code at\nthe expenses of code vulnerabilities, scalability issues and maintainability\nconcerns. In this paper, we introduce the concept of \\textit{vibe modeling} as\na novel approach to integrate the best of both worlds (AI and MDE) to speed up\nthe development of reliable complex systems. We outline the key concepts of\nvibe modeling and highlight the opportunities and open challenges it presents\nfor the future of modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23120v1", "cate": "cs.SE", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "氛围建模：挑战与机遇", "tldr": "本文引入了“氛围建模”的概念，旨在结合人工智能和模型驱动工程，加速复杂系统的开发，并探讨其机遇与挑战。", "motivation": "随着新软件系统需求增长和复杂性增加，以及新型用户界面、智能组件、可持续性等新挑战的出现，现有开发方法和工具面临压力。模型驱动工程（MDE）虽提升了软件开发质量和生产力，但模型本身变得日益复杂。同时，依赖大型语言模型（LLM）的“氛围编程”虽然流行，却带来了代码漏洞、可伸缩性问题和可维护性问题。", "method": "本文引入了“氛围建模”的概念，作为一种新颖的方法，旨在整合人工智能（AI）和模型驱动工程（MDE）的最佳实践，以加速可靠复杂系统的开发。文中概述了氛围建模的关键概念。", "result": "Not mentioned in abstract", "conclusion": "本文引入了“氛围建模”这一新概念，旨在整合AI和MDE的优势，以加速可靠复杂系统的开发，并指出了其未来的机遇和开放性挑战。", "translation": "随着新软件系统不断增长的需求和日益增加的复杂性，迫切需要更好的开发方法和工具来跟上步伐。新型用户界面、对智能组件的需求、可持续性问题……带来了我们需要应对的新挑战。在过去的几年中，模型驱动工程（MDE）在提高软件开发质量和生产力方面发挥了关键作用，但模型本身在规范和管理上变得越来越复杂。与此同时，我们正在见证“氛围编程”方法的日益普及，这些方法依赖大型语言模型（LLM）将自然语言描述转换为运行代码，但代价是代码漏洞、可伸缩性问题和可维护性问题。在本文中，我们引入了“氛围建模”的概念，作为一种新颖的方法，旨在整合两者的最佳实践（AI和MDE），以加速可靠复杂系统的开发。我们概述了氛围建模的关键概念，并强调了它为建模未来带来的机遇和开放性挑战。", "summary": "本文针对日益复杂的软件系统开发，提出了“氛围建模”这一新颖概念。该方法旨在融合人工智能（AI）和模型驱动工程（MDE）的优势，以克服当前模型复杂性增加和“氛围编程”中存在的漏洞、可伸缩性、可维护性等问题。文章概述了氛围建模的核心理念，并探讨了其在加速可靠复杂系统开发方面的机遇与挑战。", "keywords": "氛围建模, 模型驱动工程, 大型语言模型, 软件开发, 人工智能", "comments": "本文提出的“氛围建模”概念具有创新性，它尝试将模型驱动工程的结构化优势与大型语言模型在自然语言处理和代码生成方面的能力相结合，以解决当前软件开发中的痛点。这种融合有望提高开发效率和系统可靠性，尤其在处理复杂系统方面。其重要性在于为未来的软件工程提供了一个新的研究方向，特别是在智能辅助建模和自动化方面。然而，作为一个初步概念，其具体实现机制、潜在的局限性以及实际应用中的挑战仍有待深入研究和验证。"}}
{"id": "2409.15135", "title": "Controllable Traffic Simulation through LLM-Guided Hierarchical Reasoning and Refinement", "authors": ["Zhiyuan Liu", "Leheng Li", "Yuning Wang", "Haotian Lin", "Hao Cheng", "Zhizhe Liu", "Lei He", "Jianqiang Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by IROS 2025", "url": "http://arxiv.org/abs/2409.15135v2", "summary": "Evaluating autonomous driving systems in complex and diverse traffic\nscenarios through controllable simulation is essential to ensure their safety\nand reliability. However, existing traffic simulation methods face challenges\nin their controllability. To address this, we propose a novel diffusion-based\nand LLM-enhanced traffic simulation framework. Our approach incorporates a\nhigh-level understanding module and a low-level refinement module, which\nsystematically examines the hierarchical structure of traffic elements, guides\nLLMs to thoroughly analyze traffic scenario descriptions step by step, and\nrefines the generation by self-reflection, enhancing their understanding of\ncomplex situations. Furthermore, we propose a Frenet-frame-based cost function\nframework that provides LLMs with geometrically meaningful quantities,\nimproving their grasp of spatial relationships in a scenario and enabling more\naccurate cost function generation. Experiments on the Waymo Open Motion Dataset\n(WOMD) demonstrate that our method can handle more intricate descriptions and\ngenerate a broader range of scenarios in a controllable manner.", "comment": "Accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2409.15135v2", "cate": "cs.RO", "date": "2024-09-23", "updated": "2025-07-31", "AI": {"title_translation": "通过LLM引导的分层推理和细化实现可控交通仿真", "tldr": "本文提出了一种新颖的、基于扩散和LLM增强的交通仿真框架，通过分层推理和Frenet坐标系代价函数来提高交通仿真的可控性，并在Waymo开放运动数据集上展示了其生成更复杂和多样场景的能力。", "motivation": "评估自动驾驶系统在复杂多样的交通场景中的可控仿真对于确保其安全性和可靠性至关重要。然而，现有交通仿真方法在可控性方面面临挑战。", "method": "本文提出了一种新颖的、基于扩散和LLM增强的交通仿真框架。该方法包含一个高层理解模块和一个低层细化模块，用于系统地检查交通元素的分层结构，引导LLM逐步分析交通场景描述，并通过自我反思细化生成。此外，还提出了一个基于Frenet坐标系的代价函数框架，为LLM提供几何上有意义的量，以提高其对空间关系的理解和代价函数生成精度。", "result": "在Waymo开放运动数据集（WOMD）上的实验表明，该方法能够处理更复杂的描述，并以可控的方式生成更广泛的场景。", "conclusion": "本文提出的方法成功增强了交通仿真的可控性，能够生成更复杂和多样化的场景，这对于自动驾驶系统的评估至关重要。", "translation": "评估自动驾驶系统在复杂多样的交通场景中的可控仿真对于确保其安全性和可靠性至关重要。然而，现有的交通仿真方法在可控性方面面临挑战。为了解决这个问题，我们提出了一种新颖的基于扩散和LLM增强的交通仿真框架。我们的方法整合了一个高层理解模块和一个低层细化模块，系统地检查交通元素的分层结构，引导LLM逐步彻底分析交通场景描述，并通过自我反思细化生成，增强它们对复杂情况的理解。此外，我们提出了一种基于Frenet坐标系代价函数框架，该框架为LLM提供了几何上有意义的量，提高了它们对场景中空间关系的理解，并实现了更准确的代价函数生成。在Waymo开放运动数据集（WOMD）上的实验表明，我们的方法可以处理更复杂的描述，并以可控的方式生成更广泛的场景。", "summary": "本文提出了一种新颖的、基于扩散和LLM增强的交通仿真框架，旨在解决现有交通仿真方法在可控性方面的挑战。该框架通过整合高层理解和低层细化模块，利用LLM进行分层推理和自我反思，以更好地理解和生成复杂交通场景。此外，引入基于Frenet坐标系的代价函数框架，以提高LLM对空间关系的理解和代价函数生成的准确性。在Waymo开放运动数据集上的实验验证了该方法能够处理更复杂的描述并可控地生成更广泛的场景。", "keywords": "可控交通仿真, LLM, 扩散模型, 分层推理, 自动驾驶", "comments": "该论文的创新之处在于将大型语言模型（LLM）与扩散模型结合应用于可控交通仿真，并引入了分层推理方法和基于Frenet坐标系的新颖代价函数。这显著增强了生成多样化和复杂交通场景的能力，对于自动驾驶系统的鲁棒性测试至关重要，从而提高了自动驾驶的安全性和可靠性评估。"}}
{"id": "2507.23615", "title": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "authors": ["Luis Roque", "Carlos Soares", "Vitor Cerqueira", "Luis Torgo"], "categories": ["cs.LG", "cs.AI", "68T01", "I.5.1; G.3; H.2.8; I.2.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23615v1", "summary": "Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23615v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "L-GTA：时间序列增强的潜在生成建模", "tldr": "提出L-GTA模型，一个基于Transformer的变分循环自编码器，用于在潜在空间进行可控的时间序列数据增强，显著提升预测准确性和相似性。", "motivation": "数据增强在时间序列分析（如预测、分类、异常检测）中日益重要。", "method": "引入了潜在生成Transformer增强（L-GTA）模型，这是一种使用基于Transformer的变分循环自编码器的生成方法。该模型利用潜在空间内的受控变换来生成保留原始数据集内在属性的新时间序列。L-GTA支持应用从简单抖动到幅度扭曲的多种变换，并能组合这些基本变换以生成更复杂的合成时间序列数据集。", "result": "在多个真实世界数据集上的评估表明，L-GTA能够生成更可靠、一致和可控的增强数据。与直接变换方法相比，这显著提高了预测准确性和相似性度量。", "conclusion": "L-GTA通过其在潜在空间进行受控变换的能力，为时间序列数据增强提供了一种优越的方法，从而在各种时间序列任务中带来更好的性能。", "translation": "数据增强在时间序列分析的各个方面，从预测到分类和异常检测任务，都变得越来越重要。我们引入了潜在生成Transformer增强（L-GTA）模型，这是一种使用基于Transformer的变分循环自编码器的生成方法。该模型利用模型潜在空间内的受控变换来生成保留原始数据集内在属性的新时间序列。L-GTA能够应用从简单抖动到幅度扭曲的多种变换，并组合这些基本变换来生成更复杂的合成时间序列数据集。我们对几个真实世界数据集的评估表明，L-GTA能够生成更可靠、一致和可控的增强数据。与直接变换方法相比，这转化为预测准确性和相似性度量的显著提高。", "summary": "L-GTA是一种新颖的基于Transformer的变分循环自编码器模型，专为时间序列数据增强而设计。它通过在潜在空间中进行受控变换来生成新的时间序列，这些序列保留了原始数据的固有特性。L-GTA支持多种变换类型及其组合，实验证明其能生成更可靠、一致和可控的增强数据，从而显著提升预测准确性和相似性指标，优于传统的直接变换方法。", "keywords": "时间序列增强, 潜在生成模型, Transformer, 数据增强, 变分自编码器", "comments": "L-GTA的创新之处在于其在潜在空间进行数据增强的方法，这使得生成的数据能够更好地保持原始数据的内在属性，并提供更精细的控制。其基于Transformer的架构也体现了当前深度学习领域的前沿趋势。该方法对于数据稀缺或需要多样化训练数据的时间序列任务具有重要意义。"}}
{"id": "2507.00059", "title": "Computational Verification of the Buratti--Horak--Rosa Conjecture for Small Integers and Inductive Approaches", "authors": ["Ranjan N Naik"], "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "Comments:      This result supports the results by Mariusz Meszka for all primes up to 23 (included) with the aid of a computer. Additional results on Coprime BHR Conjecture verifications for p < 31 and Inductive Approaches are included in this revision", "url": "http://arxiv.org/abs/2507.00059v4", "summary": "This paper presents a comprehensive computational approach to verify and\ninductively construct Hamiltonian paths for the Buratti--Horak--Rosa (BHR)\nConjecture. The conjecture posits that for any multiset $L$ of $p-1$ positive\nintegers not exceeding $\\lfloor p/2 \\rfloor$, there exists a Hamiltonian path\nin the complete graph $K_p$ with vertex-set $\\{0, 1, \\dots, p-1\\}$ whose edge\nlengths (under the cyclic metric) match $L$, if and only if for every divisor\n$d$ of $p$, the number of multiples of $d$ appearing in $L$ is at most $p - d$.\n  Building upon prior computational work by Mariusz Meszka, which verified the\nconjecture for all primes up to $p=23$, our Python program extends this\nverification significantly. We approach the problem by systematically\ngenerating frequency partitions (FPs) of edge lengths and employing a recursive\nbacktracking algorithm. We report successful computational verification for all\nfrequency partitions for integers $p < 32$, specifically presenting results for\n$p=31$ and a composite $p=26$. For the composite number $p=30$, the Python code\ntook approximately 11 hours to verify on a Lenovo laptop. For $p=16$, $167,898$\nvalid multisets were processed, taking around 20 hours on Google Colab Pro+.\n  Furthermore, we introduce and implement two constructive, inductive\nstrategies for building Hamiltonian paths: (1) increasing the multiplicity of\nan existing edge length, and (2) adding a new edge length. These methods,\nsupported by a reuse-insertion heuristic and backtracking search, demonstrate\nsuccessful constructions for evolving FPs up to $p=40$. Through these empirical\ntests and performance metrics, we provide strong computational evidence for the\nvalidity of the BHR conjecture within the scope tested, and outline the\nscalability of our approach for higher integer values.", "comment": "This result supports the results by Mariusz Meszka for all primes up\n  to 23 (included) with the aid of a computer. Additional results on Coprime\n  BHR Conjecture verifications for p < 31 and Inductive Approaches are included\n  in this revision", "pdf_url": "http://arxiv.org/pdf/2507.00059v4", "cate": "cs.DM", "date": "2025-06-26", "updated": "2025-07-31", "AI": {"title_translation": "Buratti--Horak--Rosa 猜想在小整数上的计算验证和归纳方法", "tldr": "本文通过计算方法和归纳策略验证了Buratti--Horak--Rosa猜想在小整数上的有效性，并展示了其可扩展性。", "motivation": "验证Buratti--Horak--Rosa (BHR) 猜想，该猜想涉及在完全图中构建具有特定边长多重集的哈密顿路径。", "method": "采用综合计算方法，构建在完全图$K_p$中具有特定边长多重集的哈密顿路径，以验证Buratti--Horak--Rosa (BHR) 猜想。具体方法包括：1. 基于Python的验证程序：扩展了Mariusz Meszka的先前工作，系统地生成边长频率分区（FPs），并采用递归回溯算法。2. 归纳构建策略：引入并实现了两种构造性归纳策略，用于构建哈密顿路径：增加现有边长的多重性和添加新的边长。这些方法辅以重用-插入启发式和回溯搜索。", "result": "1. 成功计算验证了$p < 32$的所有频率分区，并具体展示了$p=31$和复合数$p=26$的结果。2. 对于复合数$p=30$，Python代码在大约11小时内完成了验证。3. 对于$p=16$，处理了167,898个有效多重集，耗时约20小时。4. 归纳策略成功构建了$p$值高达40的演变频率分区。", "conclusion": "本文通过经验测试和性能指标，为BHR猜想在测试范围内的有效性提供了强有力的计算证据，并概述了该方法对于更高整数值的可扩展性。", "translation": "本文提出了一种全面的计算方法，用于验证和归纳构造Buratti--Horak--Rosa (BHR) 猜想的哈密顿路径。该猜想认为，对于任何由$p-1$个不超过$\\lfloor p/2 \\rfloor$的正整数组成的多重集$L$，当且仅当对于$p$的每个除数$d$，在$L$中出现$d$的倍数的数量至多为$p-d$时，在具有顶点集$\\{0, 1, \\dots, p-1\\}$的完全图$K_p$中存在一条边长（在循环度量下）与$L$匹配的哈密顿路径。\n在Mariusz Meszka先前计算工作（该工作验证了$p=23$以下所有素数的猜想）的基础上，我们的Python程序显著扩展了这一验证范围。我们通过系统地生成边长频率分区（FPs）并采用递归回溯算法来解决这个问题。我们报告了对整数$p < 32$的所有频率分区进行的成功计算验证，并具体展示了$p=31$和复合数$p=26$的结果。对于复合数$p=30$，Python代码在联想笔记本电脑上耗时约11小时进行验证。对于$p=16$，处理了167,898个有效多重集，在Google Colab Pro+上耗时约20小时。\n此外，我们引入并实现了两种构造性归纳策略来构建哈密顿路径：(1) 增加现有边长的多重性，以及 (2) 添加新的边长。这些方法在重用-插入启发式和回溯搜索的支持下，展示了对于$p$值高达40的演变频率分区的成功构建。通过这些经验测试和性能指标，我们为BHR猜想在测试范围内的有效性提供了强有力的计算证据，并概述了我们的方法对于更高整数值的可扩展性。", "summary": "本文通过一个Python程序，对Buratti--Horak--Rosa (BHR) 猜想进行了全面的计算验证，该猜想涉及在完全图中构建具有特定边长多重集的哈密顿路径。研究扩展了先前的验证范围，成功验证了$p < 32$的所有频率分区，并对$p=31$和$p=26$等具体值给出了结果。此外，论文还提出了两种归纳构建哈密顿路径的策略，并成功应用于$p$值高达40的情况。这些工作为BHR猜想提供了强有力的计算证据，并展示了所提方法的可扩展性。", "keywords": "Buratti--Horak--Rosa 猜想, 哈密顿路径, 计算验证, 频率分区, 归纳策略", "comments": "本文通过大规模计算验证了Buratti--Horak--Rosa猜想，显著扩展了此前的工作范围。其创新点在于结合了系统性的频率分区生成、递归回溯算法以及两种新颖的归纳构建策略。这不仅提供了强有力的经验证据，还展示了解决组合问题中哈密顿路径构造的实用计算方法和可扩展性，对于图论和组合设计领域具有重要意义。"}}
{"id": "2404.09363", "title": "Momentum-based gradient descent methods for Lie groups", "authors": ["Cédric M. Campos", "David Martín de Diego", "José Torrente"], "categories": ["math.OC", "cs.LG", "cs.NA", "math.DG", "math.NA", "65K10 (Primary) 70G45, 22E99 (Secondary)"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      22 pages, 2 algorithms, 6 figures", "url": "http://arxiv.org/abs/2404.09363v2", "summary": "Polyak's Heavy Ball (PHB; Polyak, 1964), a.k.a. Classical Momentum, and\nNesterov's Accelerated Gradient (NAG; Nesterov, 1983) are well-established\nmomentum-descent methods for optimization. Although the latter generally\noutperforms the former, primarily, generalizations of PHB-like methods to\nnonlinear spaces have not been sufficiently explored in the literature. In this\npaper, we propose a generalization of NAG-like methods for Lie group\noptimization. This generalization is based on the variational one-to-one\ncorrespondence between classical and accelerated momentum methods (Campos et\nal., 2023). We provide numerical experiments for chosen retractions on the\ngroup of rotations based on the Frobenius norm and the Rosenbrock function to\ndemonstrate the effectiveness of our proposed methods, and that align with\nresults of the Euclidean case, that is, a faster convergence rate for NAG.", "comment": "22 pages, 2 algorithms, 6 figures", "pdf_url": "http://arxiv.org/pdf/2404.09363v2", "cate": "math.OC", "date": "2024-04-14", "updated": "2025-07-31", "AI": {"title_translation": "李群上基于动量的梯度下降方法", "tldr": "本文提出并验证了李群上Nesterov加速梯度下降方法的推广，实现了更快的收敛速度。", "motivation": "经典动量梯度下降方法（如PHB和NAG）在优化领域已得到广泛应用，但PHB类方法向非线性空间的推广尚未得到充分探索，尤其是NAG类方法在李群优化中的推广。", "method": "本文提出了一种针对李群优化的NAG类方法的推广。该推广基于经典动量方法和加速动量方法之间的变分一对一对应关系。", "result": "数值实验表明，所提出的方法在旋转群上是有效的，并且与欧几里得空间的结果一致，即NAG具有更快的收敛速度。", "conclusion": "提出的李群上NAG类方法能够有效地加速收敛，与欧几里得空间中的NAG表现相似。", "translation": "Polyak的重球法（PHB；Polyak, 1964），又称经典动量法，和Nesterov的加速梯度法（NAG；Nesterov, 1983）是优化领域中成熟的动量下降方法。尽管后者通常优于前者，但PHB类方法向非线性空间的推广在文献中尚未得到充分探索。在本文中，我们提出了一种针对李群优化的NAG类方法的推广。这种推广基于经典动量方法和加速动量方法之间的变分一对一对应关系（Campos et al., 2023）。我们提供了在旋转群上基于Frobenius范数和Rosenbrock函数的选定回缩的数值实验，以证明我们提出的方法的有效性，并且这些结果与欧几里得案例的结果一致，即NAG具有更快的收敛速度。", "summary": "本文针对李群优化，提出了一种Nesterov加速梯度（NAG）方法的推广。该推广基于经典与加速动量方法之间的变分对应关系。通过在旋转群上的数值实验，验证了所提出方法的有效性，并显示出与欧几里得空间中NAG相似的更快的收敛速度，填补了非线性空间中加速动量方法研究的空白。", "keywords": "动量梯度下降, 李群, Nesterov加速梯度, 非线性优化, 收敛速度", "comments": "本文的创新点在于将Nesterov加速梯度方法推广到李群等非线性空间，这对于解决复杂优化问题具有重要意义。通过实验验证了其有效性和加速收敛特性，为非欧几里得几何上的优化算法发展提供了新的思路。潜在的局限性可能在于其推广的复杂性以及对不同李群结构和回缩选择的普适性。"}}
{"id": "2507.23701", "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23701v1", "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23701v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "TextQuests：大型语言模型在文本类视频游戏中的表现如何？", "tldr": "引入TextQuests基准，用于评估LLM在需要长期、自主推理的文本冒险游戏中的表现，旨在促进更强大的内在推理能力发展。", "motivation": "为了理解AI代理的实际能力，评估它们在模拟真实世界挑战的复杂交互环境中的表现至关重要。现有基准未能充分捕捉代理在需要长期、自主推理的探索性环境中自主操作的能力，因此需要一个新的基准来促进能够进行更强大内在推理的代理的发展。", "method": "本文引入了TextQuests，一个基于Infocom交互式小说游戏的基准。这些文本冒险游戏需要人类玩家耗时数十小时和数百次精确操作才能解决，可有效评估AI代理在专注、有状态任务上的表现。该基准专门设计用于评估LLM代理的独立问题解决能力，通过排除外部工具的使用，专注于在需要试错学习和单次交互会话中持续问题解决的探索性环境中的内在长上下文推理能力。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "在模拟真实世界挑战的复杂、交互式环境中评估AI代理对于理解其实际能力至关重要。虽然现有代理基准能有效评估工具使用或结构化任务表现等技能，但它们往往未能充分捕捉代理在需要长期、自主推理的探索性环境中自主操作的能力。为了促进能够进行更强大内在推理的代理的发展，我们引入了TextQuests，一个基于Infocom交互式小说游戏的基准。这些文本冒险游戏，人类玩家可能需要30多个小时，并需要数百次精确操作才能解决，可作为评估AI代理在专注、有状态任务上的有效替代。该基准专门设计用于评估LLM代理的独立问题解决能力，通过排除外部工具的使用，从而专注于在需要试错学习和单次交互会话中持续问题解决的探索性环境中的内在长上下文推理能力。我们在https://textquests.ai发布TextQuests。", "summary": "本文介绍了TextQuests，一个基于Infocom文本冒险游戏的全新基准，旨在评估大型语言模型（LLM）在复杂、探索性环境中进行长期、自主推理的能力。与现有基准不同，TextQuests通过禁止外部工具的使用，专注于测试LLM的内在长上下文推理和独立问题解决能力，以此推动AI代理在模拟真实世界挑战方面的发展。", "keywords": "TextQuests, LLM, 文本冒险游戏, 基准, 长上下文推理", "comments": "这项工作通过引入TextQuests基准，填补了现有AI代理评估的空白，特别是在评估LLM的内在长上下文推理和自主决策能力方面。其创新之处在于利用了Infocom文本冒险游戏作为代理，这些游戏本身就要求复杂、持续的推理和试错学习，这对于测试LLM在真实世界复杂场景下的表现具有重要意义。通过限制外部工具的使用，该基准能够更纯粹地评估LLM的“大脑”能力，而非其工具集成能力。"}}
{"id": "2507.23418", "title": "Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning", "authors": ["Mokhtar A. Al-Awadhi", "Ratnadeep R. Deshmukh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23418v1", "summary": "In this paper, we propose a system for detecting adulteration in coconut\nmilk, utilizing infrared spectroscopy. The machine learning-based proposed\nsystem comprises three phases: preprocessing, feature extraction, and\nclassification. The first phase involves removing irrelevant data from coconut\nmilk spectral signals. In the second phase, we employ the Linear Discriminant\nAnalysis (LDA) algorithm for extracting the most discriminating features. In\nthe third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut\nmilk samples into authentic or adulterated. We evaluate the performance of the\nproposed system using a public dataset comprising Fourier Transform Infrared\n(FTIR) spectral information of pure and contaminated coconut milk samples.\nFindings show that the proposed method successfully detects adulteration with a\ncross-validation accuracy of 93.33%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23418v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "椰奶掺假检测：基于红外光谱和机器学习", "tldr": "本研究提出并验证了一种利用红外光谱和机器学习技术检测椰奶掺假的方法，实现了93.33%的检测准确率。", "motivation": "检测椰奶中的掺假。", "method": "本文提出一个基于红外光谱的机器学习系统，分为三个阶段：预处理（去除光谱信号中不相关数据）、特征提取（使用线性判别分析LDA）和分类（使用K-近邻KNN模型将样品分为真品或掺假）。系统性能通过公开的傅里叶变换红外（FTIR）光谱数据集进行评估。", "result": "所提出的方法成功检测出掺假，交叉验证准确率为93.33%。", "conclusion": "基于红外光谱和机器学习的方法可以有效地检测椰奶中的掺假。", "translation": "在本文中，我们提出了一种利用红外光谱技术检测椰奶掺假的系统。该基于机器学习的系统包括三个阶段：预处理、特征提取和分类。第一阶段涉及从椰奶光谱信号中去除不相关数据。在第二阶段，我们采用线性判别分析（LDA）算法提取最具区分性的特征。在第三阶段，我们使用K-近邻（KNN）模型将椰奶样品分类为真品或掺假。我们使用包含纯椰奶和受污染椰奶样品傅里叶变换红外（FTIR）光谱信息的公开数据集评估了所提出系统的性能。研究结果表明，所提出的方法成功检测出掺假，交叉验证准确率为93.33%。", "summary": "本文提出了一种基于红外光谱和机器学习的椰奶掺假检测系统。该系统包括数据预处理、利用线性判别分析（LDA）进行特征提取，以及使用K-近邻（KNN）模型进行分类。通过在公开傅里叶变换红外（FTIR）光谱数据集上的评估，该方法在交叉验证中达到了93.33%的准确率，成功实现了对椰奶掺假的检测。", "keywords": "红外光谱, 机器学习, 椰奶, 掺假检测, LDA, KNN", "comments": "该研究创新性地结合了红外光谱技术和机器学习算法来解决食品掺假问题，提供了一种快速、无损的检测方法。其高准确率表明了该方法在实际应用中的潜力。"}}
{"id": "2507.23331", "title": "Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision", "authors": ["Qiang Lu", "Waikit Xiu", "Xiying Li", "Shenyu Hu", "Shengbo Sun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11pages, 5 figures", "url": "http://arxiv.org/abs/2507.23331v1", "summary": "Traffic sign recognition, as a core component of autonomous driving\nperception systems, directly influences vehicle environmental awareness and\ndriving safety. Current technologies face two significant challenges: first,\nthe traffic sign dataset exhibits a pronounced long-tail distribution,\nresulting in a substantial decline in recognition performance of traditional\nconvolutional networks when processing low-frequency and out-of-distribution\nclasses; second, traffic signs in real-world scenarios are predominantly small\ntargets with significant scale variations, making it difficult to extract\nmulti-scale features.To overcome these issues, we propose a novel two-stage\nframework combining open-vocabulary detection and cross-modal learning. For\ntraffic sign detection, our NanoVerse YOLO model integrates a reparameterizable\nvision-language path aggregation network (RepVL-PAN) and an SPD-Conv module to\nspecifically enhance feature extraction for small, multi-scale targets. For\ntraffic sign classification, we designed a Traffic Sign Recognition Multimodal\nContrastive Learning model (TSR-MCL). By contrasting visual features from a\nVision Transformer with semantic features from a rule-based BERT, TSR-MCL\nlearns robust, frequency-independent representations, effectively mitigating\nclass confusion caused by data imbalance. On the TT100K dataset, our method\nachieves a state-of-the-art 78.4% mAP in the long-tail detection task for\nall-class recognition. The model also obtains 91.8% accuracy and 88.9% recall,\nsignificantly outperforming mainstream algorithms and demonstrating superior\naccuracy and generalization in complex, open-world scenarios.", "comment": "11pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.23331v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "对比学习驱动的交通标志感知：文本与视觉的多模态融合", "tldr": "该论文提出了一种结合开放词汇检测和跨模态对比学习的两阶段框架，用于解决交通标志识别中长尾分布和小目标检测的挑战，并在TT100K数据集上取得了最先进的性能。", "motivation": "当前交通标志识别技术面临两大挑战：一是交通标志数据集的长尾分布导致传统卷积网络在处理低频和分布外类别时性能显著下降；二是真实场景中交通标志多为小目标且尺度变化大，难以提取多尺度特征。", "method": "本文提出了一种新颖的两阶段框架，结合了开放词汇检测和跨模态学习。在交通标志检测阶段，采用NanoVerse YOLO模型，该模型集成了可重参数化的视觉-语言路径聚合网络（RepVL-PAN）和SPD-Conv模块，以增强小目标和多尺度目标的特征提取。在交通标志分类阶段，设计了交通标志识别多模态对比学习模型（TSR-MCL），通过对比来自Vision Transformer的视觉特征和基于规则的BERT的语义特征，学习鲁棒的、频率无关的表示，有效缓解了数据不平衡导致的类别混淆。", "result": "在TT100K数据集上，该方法在所有类别的长尾检测任务中实现了78.4%的mAP，达到了最先进的水平。模型还获得了91.8%的准确率和88.9%的召回率，显著优于主流算法。", "conclusion": "该模型在复杂开放世界场景中表现出卓越的准确性和泛化能力，有效解决了交通标志识别中的长尾分布和小目标检测问题。", "translation": "交通标志识别作为自动驾驶感知系统的核心组成部分，直接影响车辆的环境感知和驾驶安全。当前技术面临两大显著挑战：首先，交通标志数据集呈现出明显的长尾分布，导致传统卷积网络在处理低频和分布外类别时识别性能显著下降；其次，真实场景中的交通标志多为小目标且尺度变化大，难以提取多尺度特征。为了克服这些问题，我们提出了一种结合开放词汇检测和跨模态学习的新颖两阶段框架。在交通标志检测方面，我们的NanoVerse YOLO模型集成了可重参数化的视觉-语言路径聚合网络（RepVL-PAN）和SPD-Conv模块，以专门增强对小型、多尺度目标的特征提取。在交通标志分类方面，我们设计了一个交通标志识别多模态对比学习模型（TSR-MCL）。通过对比来自Vision Transformer的视觉特征和来自基于规则的BERT的语义特征，TSR-MCL学习到鲁棒的、频率无关的表示，有效缓解了数据不平衡引起的类别混淆。在TT100K数据集上，我们的方法在所有类别的长尾检测任务中实现了78.4%的mAP，达到了最先进的水平。该模型还获得了91.8%的准确率和88.9%的召回率，显著优于主流算法，并在复杂、开放世界的场景中展示了卓越的准确性和泛化能力。", "summary": "本文提出了一种新颖的两阶段框架，用于解决自动驾驶中交通标志识别的长尾分布和小目标检测挑战。该框架结合了开放词汇检测和跨模态学习。在检测阶段，NanoVerse YOLO模型利用RepVL-PAN和SPD-Conv增强小目标特征提取。在分类阶段，TSR-MCL模型通过对比学习融合视觉（Vision Transformer）和语义（BERT）特征，以缓解数据不平衡。实验结果表明，在TT100K数据集上，该方法在长尾检测任务中取得了78.4%的mAP，并展现了高准确率和召回率，优于现有主流算法，提升了复杂场景下的泛化能力。", "keywords": "交通标志识别, 对比学习, 多模态融合, 长尾分布, 小目标检测", "comments": "该论文的创新点在于提出了一个结合开放词汇检测和跨模态对比学习的两阶段框架，有效解决了交通标志识别中长期存在的长尾分布和小目标检测难题。特别是通过TSR-MCL模型利用视觉和语义特征进行对比学习，为处理数据不平衡提供了新思路。其在TT100K数据集上取得的SOTA性能，证明了该方法的有效性和在实际自动驾驶应用中的潜力。"}}
{"id": "2507.22932", "title": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "authors": ["Baptiste Lefort", "Eric Benhamou", "Beatrice Guez", "Jean-Jacques Ohana", "Ethan Setrouk", "Alban Etienne"], "categories": ["cs.CL", "q-fin.GN"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.22932v1", "summary": "This paper presents a novel hierarchical framework for portfolio\noptimization, integrating lightweight Large Language Models (LLMs) with Deep\nReinforcement Learning (DRL) to combine sentiment signals from financial news\nwith traditional market indicators. Our three-tier architecture employs base RL\nagents to process hybrid data, meta-agents to aggregate their decisions, and a\nsuper-agent to merge decisions based on market data and sentiment analysis.\nEvaluated on data from 2018 to 2024, after training on 2000-2017, the framework\nachieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming\nequal-weighted and S&P 500 benchmarks. Key contributions include scalable\ncross-modal integration, a hierarchical RL structure for enhanced stability,\nand open-source reproducibility.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.22932v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "FinMarBa：一个用于金融情感分类的市场信息数据集", "tldr": "论文提出了一种结合LLM和DRL的层次化投资组合优化框架，通过整合情感信号和市场指标，实现了26%的年化收益和1.2的夏普比率，优于基准。", "motivation": "结合金融新闻中的情感信号与传统市场指标，通过新颖的层次化框架实现投资组合优化。", "method": "论文提出了一种新颖的层次化投资组合优化框架，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合。该框架采用三层架构：基础RL智能体处理混合数据，元智能体聚合其决策，超智能体根据市场数据和情感分析合并决策。", "result": "在2000-2017年数据训练后，于2018-2024年数据上进行评估，该框架实现了26%的年化收益和1.2的夏普比率，表现优于等权重和标普500基准。", "conclusion": "关键贡献包括可扩展的跨模态集成、增强稳定性的层次化强化学习结构以及开源可复现性。", "translation": "本文提出了一种新颖的投资组合优化层次化框架，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合，以整合来自金融新闻的情感信号与传统市场指标。我们的三层架构采用基础RL智能体处理混合数据，元智能体聚合其决策，以及一个超级智能体根据市场数据和情感分析合并决策。该框架在2000-2017年数据训练后，于2018-2024年数据上进行评估，实现了26%的年化收益和1.2的夏普比率，优于等权重和标普500基准。主要贡献包括可扩展的跨模态集成、增强稳定性的层次化RL结构以及开源可复现性。", "summary": "本文介绍了一种新颖的层次化投资组合优化框架，该框架将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合，用于整合金融新闻情感信号与传统市场指标。该框架采用三层架构，并经过2018-2024年数据评估，实现了26%的年化收益和1.2的夏普比率，超越了基准表现。其主要贡献在于可扩展的跨模态集成、增强稳定性的层次化RL结构以及开源可复现性。", "keywords": "投资组合优化, 大型语言模型, 深度强化学习, 情感分析, 层次化框架", "comments": "论文标题与摘要内容存在显著不符。标题提及“金融情感分类的市场信息数据集”，而摘要描述的是一个用于投资组合优化的层次化框架，结合了LLM和DRL，并取得了较高的收益率。若以摘要内容为准，该研究的创新点在于将LLM和DRL相结合，构建了一个处理金融新闻情感信号和市场指标的层次化投资组合优化框架，并实现了可观的投资回报，具有潜在的实际应用价值。"}}
{"id": "2505.23628", "title": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora", "authors": ["Jiaxin Bai", "Wei Fan", "Qi Hu", "Qing Zong", "Chunyang Li", "Hong Ting Tsang", "Hongyu Luo", "Yauwai Yim", "Haoyu Huang", "Xiao Zhou", "Feng Qin", "Tianshi Zheng", "Xi Peng", "Xin Yao", "Huiwen Yang", "Leijie Wu", "Yi Ji", "Gong Zhang", "Renhai Chen", "Yangqiu Song"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, preprint, code: this https URL", "url": "http://arxiv.org/abs/2505.23628v2", "summary": "We present AutoSchemaKG, a framework for fully autonomous knowledge graph\nconstruction that eliminates the need for predefined schemas. Our system\nleverages large language models to simultaneously extract knowledge triples and\ninduce comprehensive schemas directly from text, modeling both entities and\nevents while employing conceptualization to organize instances into semantic\ncategories. Processing over 50 million documents, we construct ATLAS (Automated\nTriple Linking And Schema induction), a family of knowledge graphs with 900+\nmillion nodes and 5.9 billion edges. This approach outperforms state-of-the-art\nbaselines on multi-hop QA tasks and enhances LLM factuality. Notably, our\nschema induction achieves 95\\% semantic alignment with human-crafted schemas\nwith zero manual intervention, demonstrating that billion-scale knowledge\ngraphs with dynamically induced schemas can effectively complement parametric\nknowledge in large language models.", "comment": "9 pages, preprint, code:\n  https://github.com/HKUST-KnowComp/AutoSchemaKG", "pdf_url": "http://arxiv.org/pdf/2505.23628v2", "cate": "cs.CL", "date": "2025-05-29", "updated": "2025-07-31", "AI": {"title_translation": "AutoSchemaKG：通过网络规模语料库的动态模式归纳实现自主知识图谱构建", "tldr": "AutoSchemaKG是一个利用大型语言模型从海量文本中自主构建知识图谱的框架，无需预定义模式，能生成数十亿规模的知识图谱，并在QA任务上表现优异，提升LLM事实性。", "motivation": "传统知识图谱构建需要预定义模式，这限制了其自主性和灵活性。本文旨在解决这一问题，实现完全自主的知识图谱构建。", "method": "AutoSchemaKG框架利用大型语言模型，同时从文本中提取知识三元组并归纳全面的模式。它能对实体和事件进行建模，并通过概念化将实例组织成语义类别。该系统处理了超过5000万份文档。", "result": "构建了ATLAS知识图谱家族，包含超过9亿个节点和59亿条边。该方法在多跳问答任务上优于最先进的基线，并增强了大型语言模型的事实性。其模式归纳在零人工干预下实现了与人工创建模式95%的语义对齐。", "conclusion": "具有动态归纳模式的十亿级知识图谱能够有效补充大型语言模型中的参数知识，证明了完全自主知识图谱构建的可行性和优越性。", "translation": "我们提出了AutoSchemaKG，一个用于完全自主知识图谱构建的框架，它消除了对预定义模式的需求。我们的系统利用大型语言模型同时从文本中提取知识三元组并归纳全面的模式，对实体和事件进行建模，同时采用概念化将实例组织成语义类别。通过处理超过5000万份文档，我们构建了ATLAS（自动三元组链接和模式归纳），一个拥有9亿多节点和59亿条边的知识图谱家族。这种方法在多跳问答任务上优于最先进的基线，并增强了大型语言模型的事实性。值得注意的是，我们的模式归纳在零人工干预下实现了与人工创建模式95%的语义对齐，这表明具有动态归纳模式的十亿级知识图谱可以有效补充大型语言模型中的参数知识。", "summary": "AutoSchemaKG是一个创新的框架，它利用大型语言模型从海量网络文本中自主构建知识图谱，无需预设模式。该系统能同时提取知识三元组并动态归纳模式，并成功构建了包含数十亿节点和边的ATLAS知识图谱。实验证明，AutoSchemaKG在多跳问答任务上表现优异，提升了LLM的事实性，并且其自动归纳的模式与人工模式高度一致，表明动态模式知识图谱能有效增强LLM的能力。", "keywords": "知识图谱构建, 模式归纳, 大型语言模型, 自主学习, 网络规模语料库", "comments": "AutoSchemaKG的创新之处在于其完全自主的知识图谱构建能力，尤其是动态模式归纳，消除了对人工预定义模式的依赖。其重要性体现在能够从大规模非结构化文本中自动生成高质量、大规模的知识图谱，并有效提升大型语言模型的事实性和问答能力。95%的语义对齐率在零人工干预下是一个显著的成就。"}}
{"id": "2507.23251", "title": "A Deep Dive into Generic Object Tracking: A Survey", "authors": ["Fereshteh Aghaee Meibodi", "Shadi Alijani", "Homayoun Najjaran"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      55 pages, 29 figures, 9 tables", "url": "http://arxiv.org/abs/2507.23251v1", "summary": "Generic object tracking remains an important yet challenging task in computer\nvision due to complex spatio-temporal dynamics, especially in the presence of\nocclusions, similar distractors, and appearance variations. Over the past two\ndecades, a wide range of tracking paradigms, including Siamese-based trackers,\ndiscriminative trackers, and, more recently, prominent transformer-based\napproaches, have been introduced to address these challenges. While a few\nexisting survey papers in this field have either concentrated on a single\ncategory or widely covered multiple ones to capture progress, our paper\npresents a comprehensive review of all three categories, with particular\nemphasis on the rapidly evolving transformer-based methods. We analyze the core\ndesign principles, innovations, and limitations of each approach through both\nqualitative and quantitative comparisons. Our study introduces a novel\ncategorization and offers a unified visual and tabular comparison of\nrepresentative methods. Additionally, we organize existing trackers from\nmultiple perspectives and summarize the major evaluation benchmarks,\nhighlighting the fast-paced advancements in transformer-based tracking driven\nby their robust spatio-temporal modeling capabilities.", "comment": "55 pages, 29 figures, 9 tables", "pdf_url": "http://arxiv.org/pdf/2507.23251v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "通用目标跟踪的深入探究：一项综述", "tldr": "这是一篇关于通用目标跟踪的综述论文，全面回顾了包括基于Siamese、判别式和基于Transformer的方法，并重点分析了基于Transformer的方法的最新进展。", "motivation": "通用目标跟踪在计算机视觉中仍然是一项重要但具有挑战性的任务，因为存在复杂的时空动态，尤其是在遮挡、相似干扰物和外观变化的情况下。现有的综述论文要么只关注单一类别，要么广泛涵盖多个类别，未能全面捕捉进展。因此，本文旨在提供一个全面的综述。", "method": "本文全面回顾了三种主要的跟踪范式：基于Siamese的跟踪器、判别式跟踪器以及基于Transformer的方法。通过定性和定量比较，分析了每种方法的核心设计原则、创新和局限性。引入了一种新颖的分类方法，并提供了代表性方法的统一视觉和表格比较。此外，从多个角度组织了现有跟踪器，并总结了主要的评估基准。", "result": "提供了一种新颖的分类方法，并对代表性方法进行了统一的视觉和表格比较。总结了主要的评估基准，并强调了基于Transformer的跟踪方法由于其强大的时空建模能力所带来的快速发展。", "conclusion": "本文对通用目标跟踪领域进行了全面回顾，特别强调了基于Transformer的方法的快速发展及其强大的时空建模能力，并提供了新的分类和比较视角。", "translation": "通用目标跟踪在计算机视觉中仍然是一项重要但具有挑战性的任务，因为存在复杂的时空动态，尤其是在遮挡、相似干扰物和外观变化的情况下。在过去的二十年里，为了应对这些挑战，引入了广泛的跟踪范式，包括基于Siamese的跟踪器、判别式跟踪器以及最近出现的基于Transformer的方法。虽然该领域现有的一些综述论文要么集中于单一类别，要么广泛涵盖多个类别以捕捉进展，但我们的论文对所有这三个类别进行了全面回顾，并特别强调了快速发展的基于Transformer的方法。我们通过定性和定量比较分析了每种方法的核心设计原则、创新和局限性。我们的研究引入了一种新颖的分类方法，并提供了代表性方法的统一视觉和表格比较。此外，我们从多个角度组织了现有跟踪器，并总结了主要的评估基准，强调了基于Transformer的跟踪方法由于其强大的时空建模能力所带来的快速发展。", "summary": "本综述论文深入探讨了通用目标跟踪领域，全面回顾了过去二十年间发展起来的三种主要跟踪范式：基于Siamese、判别式和基于Transformer的方法。论文分析了这些方法的设计原则、创新点和局限性，并首次提出了一种新的分类方法，提供了统一的视觉和表格比较。特别强调了基于Transformer的方法的快速进展及其在时空建模方面的优势，并总结了主要的评估基准，旨在为该领域提供全面的参考。", "keywords": "通用目标跟踪, 综述, Transformer, Siamese, 判别式跟踪器", "comments": "本文作为一篇综述，其创新之处在于对通用目标跟踪领域进行了全面的梳理，尤其是在强调基于Transformer的最新进展方面。它提供了一个新的分类视角和统一的比较框架，这对于研究人员理解和选择合适的跟踪方法具有重要价值。该综述的重要性在于其系统性和全面性，有助于读者快速掌握该领域的关键技术和发展趋势。"}}
{"id": "2507.23592", "title": "Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation", "authors": ["Haiyun Zhang", "Stefano Dalla Gasperina", "Saad N. Yousaf", "Toshimitsu Tsuboi", "Tetsuya Narita", "Ashish D. Deshpande"], "categories": ["cs.RO", "cs.HC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures, submitted to RA-L", "url": "http://arxiv.org/abs/2507.23592v1", "summary": "Hand exoskeletons are critical tools for dexterous teleoperation and\nimmersive manipulation interfaces, but achieving accurate hand tracking remains\na challenge due to user-specific anatomical variability and donning\ninconsistencies. These issues lead to kinematic misalignments that degrade\ntracking performance and limit applicability in precision tasks. We propose a\nsubject-specific calibration framework for exoskeleton-based hand tracking that\nuses redundant joint sensing and a residual-weighted optimization strategy to\nestimate virtual link parameters. Implemented on the Maestro exoskeleton, our\nmethod improves joint angle and fingertip position estimation across users with\nvarying hand geometries. We introduce a data-driven approach to empirically\ntune cost function weights using motion capture ground truth, enabling more\naccurate and consistent calibration across participants. Quantitative results\nfrom seven subjects show substantial reductions in joint and fingertip tracking\nerrors compared to uncalibrated and evenly weighted models. Qualitative\nvisualizations using a Unity-based virtual hand further confirm improvements in\nmotion fidelity. The proposed framework generalizes across exoskeleton designs\nwith closed-loop kinematics and minimal sensing, and lays the foundation for\nhigh-fidelity teleoperation and learning-from-demonstration applications.", "comment": "8 pages, 10 figures, submitted to RA-L", "pdf_url": "http://arxiv.org/pdf/2507.23592v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "人体外骨骼运动学标定以改善灵巧远程操作中的手部追踪", "tldr": "提出了一种针对性的人体外骨骼运动学标定框架，通过优化策略和数据驱动方法显著提高了手部追踪精度，适用于灵巧远程操作。", "motivation": "手部外骨骼在灵巧远程操作和沉浸式操作界面中至关重要，但由于用户解剖学差异和穿戴不一致，导致运动学错位，影响手部追踪精度，限制了其在精细任务中的应用。", "method": "提出了一种针对特定个体的外骨骼手部追踪标定框架。该框架利用冗余关节传感和残差加权优化策略来估计虚拟连杆参数。在Maestro外骨骼上实现，并引入了一种数据驱动方法，利用运动捕捉真值经验性地调整成本函数权重，以实现更准确和一致的标定。", "result": "对七名受试者的定量结果显示，与未标定和均匀加权模型相比，关节和指尖追踪误差显著降低。使用基于Unity的虚拟手进行的定性可视化进一步证实了运动保真度的改善。", "conclusion": "所提出的框架可推广到具有闭环运动学和最小传感的外骨骼设计，为高保真远程操作和示范学习应用奠定了基础。", "translation": "手部外骨骼是灵巧远程操作和沉浸式操作界面的关键工具，但由于用户特定的解剖学变异性和穿戴不一致性，实现精确的手部追踪仍然是一个挑战。这些问题导致运动学错位，从而降低追踪性能并限制其在精细任务中的适用性。我们提出了一种针对外骨骼手部追踪的个体化标定框架，该框架利用冗余关节传感和残差加权优化策略来估计虚拟连杆参数。在Maestro外骨骼上实现后，我们的方法改善了不同手部几何形状用户关节角度和指尖位置的估计。我们引入了一种数据驱动方法，利用运动捕捉真值经验性地调整成本函数权重，从而在参与者之间实现更准确和一致的标定。来自七名受试者的定量结果显示，与未标定和均匀加权模型相比，关节和指尖追踪误差显著降低。使用基于Unity的虚拟手进行的定性可视化进一步证实了运动保真度的改善。所提出的框架可推广到具有闭环运动学和最小传感的外骨骼设计，并为高保真远程操作和示范学习应用奠定了基础。", "summary": "本文提出了一种针对手部外骨骼的个体化运动学标定框架，旨在解决因用户解剖差异和穿戴不一致导致的手部追踪精度问题。该框架结合冗余关节传感、残差加权优化和数据驱动的权重调整，显著提高了关节角度和指尖位置的估计精度。实验结果表明，该方法有效降低了追踪误差，为高保真远程操作和示范学习应用奠定了基础。", "keywords": "手部外骨骼, 运动学标定, 手部追踪, 远程操作, 残差加权优化", "comments": "这项研究通过提出一种创新的个体化运动学标定框架，有效解决了手部外骨骼追踪中长期存在的用户特异性问题，显著提升了追踪精度和适用性。其结合冗余传感和数据驱动优化策略的方法具有很强的实用性和普适性，有望推动远程操作和人机交互领域的发展。"}}
{"id": "2507.23401", "title": "Advancing Standard Load Profiles with Data-Driven Techniques and Recent Datasets", "authors": ["Jawana Gabrielski", "Ulf Häger"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 11 figures, part of 2024 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm) proceedings", "url": "http://arxiv.org/abs/2507.23401v1", "summary": "Estimating electricity consumption accurately is essential for the planning\nand operation of energy systems, as well as for billing processes. Standard\nLoad Profiles (SLP) are widely used to estimate consumption patterns of\ndifferent user groups. However, in Germany these SLP were formulated using\nhistorical data from over 20 years ago and have not been adjusted since.\nChanging electricity consumption behaviour, which leads to increasing\ndeviations between load patterns and SLP, results in a need for a revision\ntaking into account new data. The growing number of smart meters provides a\nlarge measurement database, which enables more accurate load modelling. This\npaper creates updated SLP using recent data. In addition, the assumptions of\nthe SLP method are validated and improvements are proposed, taking into account\nthe ease of applicability. Furthermore, a Fourier Series-based model is\nproposed as an alternative SLP model. The different models are compared and\nevaluated.", "comment": "6 pages, 11 figures, part of 2024 IEEE International Conference on\n  Communications, Control, and Computing Technologies for Smart Grids\n  (SmartGridComm) proceedings", "pdf_url": "http://arxiv.org/pdf/2507.23401v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "利用数据驱动技术和最新数据集改进标准负荷曲线", "tldr": "该研究更新了德国过时的标准负荷曲线（SLP），利用最新数据，并提出了一种基于傅里叶级数的替代模型。", "motivation": "准确估算电力消耗对于能源系统的规划、运行及计费至关重要。德国现有的标准负荷曲线（SLP）基于20多年前的数据制定，且未曾调整。然而，电力消费行为正在发生变化，导致负荷模式与旧SLP之间的偏差日益增大，因此需要利用新数据进行修订。智能电表的普及提供了大量测量数据，使得更准确的负荷建模成为可能。", "method": "本研究利用最新数据创建了更新的标准负荷曲线（SLP）。此外，还验证了SLP方法中的假设，并提出了易于应用的改进方案。同时，提出了一种基于傅里叶级数的模型作为替代SLP模型，并对不同模型进行了比较和评估。", "result": "不同的模型被进行了比较和评估，但抽象中未提及具体评估结果。", "conclusion": "本研究更新了德国的SLP，并提出了一种新的替代模型，以应对不断变化的电力消费行为和提高负荷建模的准确性。", "translation": "准确估算电力消耗对于能源系统的规划和运行以及计费流程至关重要。标准负荷曲线（SLP）被广泛用于估算不同用户群的消费模式。然而，在德国，这些SLP是根据20多年前的历史数据制定的，并且此后从未进行调整。不断变化的电力消费行为导致负荷模式与SLP之间的偏差日益增大，这使得需要根据新数据进行修订。智能电表数量的增长提供了庞大的测量数据库，从而能够进行更准确的负荷建模。本文利用最新数据创建了更新的SLP。此外，还验证了SLP方法的假设，并提出了改进方案，同时考虑了易用性。此外，还提出了一种基于傅里叶级数的模型作为替代SLP模型。对不同模型进行了比较和评估。", "summary": "该论文旨在更新德国过时的标准负荷曲线（SLP），以适应不断变化的电力消费行为。研究利用最新的智能电表数据创建了更新的SLP，并验证了现有SLP方法的假设。此外，提出了一种基于傅里叶级数的模型作为SLP的替代方案，并对不同模型进行了比较和评估，以提高电力消费估算的准确性。", "keywords": "标准负荷曲线, 数据驱动, 傅里叶级数, 电力消费, 智能电表", "comments": "本文解决了德国电力系统中的一个实际且重要的问题，即标准负荷曲线的过时问题。其创新点在于利用最新的智能电表数据进行SLP的更新，并提出了一种基于傅里叶级数的替代模型，这有助于提高电力负荷预测的准确性和能源系统的效率。该研究考虑了实际应用中的易用性，增强了其潜在影响力。"}}
{"id": "2507.01631", "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D Vision Across Altitudes). Our code will be made public after the conference at this https URL", "url": "http://arxiv.org/abs/2507.01631v2", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Our code will be made public after the conference\n  at https://github.com/Ellimac0/Snake-NeRF", "pdf_url": "http://arxiv.org/pdf/2507.01631v2", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-31", "AI": {"title_translation": "瓦片与滑动：一种将NeRF从局部扩展到全局3D地球观测的新框架", "tldr": "鉴于NeRF在处理大规模场景时面临内存限制，本文提出了Snake-NeRF框架。这是一种内存外方法，通过将场景分块并重叠裁剪图像，使NeRF能够在大规模卫星图像上进行3D重建，同时在一台设备上保持质量和线性时间复杂度。", "motivation": "现有的NeRF方法由于训练期间的内存占用，通常受限于小场景，这阻碍了它们在大规模多视图卫星图像3D重建中的应用。", "method": "本文提出了Snake-NeRF框架，它是一种内存外方法，无需同时加载所有图像和网络，可在单个设备上运行。该方法通过将感兴趣区域划分为不重叠的3D NeRF瓦片来实现，并重叠裁剪图像以确保每个NeRF都用所有必要的像素进行训练。此外，它引入了一种新颖的2x2 3D瓦片进展策略和分段采样器，以防止瓦片边缘的3D重建错误。", "result": "实验结果表明，大型卫星图像可以有效地以线性时间复杂度在单个GPU上处理，且不影响质量。", "conclusion": "本文的实验得出结论，可以有效地处理大型卫星图像，实现线性时间复杂度和单个GPU操作，且不影响质量。", "translation": "神经辐射场（NeRF）最近已成为多视图卫星图像3D重建的一种范式。然而，最先进的NeRF方法通常由于训练期间的内存占用而受限于小场景，这也是本文研究的重点。以前关于大规模NeRF的工作通过将场景划分为多个NeRF来缓解这一问题。本文介绍了Snake-NeRF，一个可以扩展到大场景的框架。我们的内存外方法消除了同时加载所有图像和网络的需要，并在单个设备上运行。我们通过将感兴趣区域划分为不重叠的3D瓦片NeRF来实现这一点。重要的是，我们重叠裁剪图像，以确保每个NeRF都用所有必要的像素进行训练。我们引入了一种新颖的2x2 3D瓦片进展策略和分段采样器，它们共同防止了沿瓦片边缘的3D重建错误。我们的实验得出结论，大型卫星图像可以有效地以线性时间复杂度在单个GPU上处理，且不影响质量。", "summary": "针对NeRF在处理大规模多视图卫星图像时面临的内存限制，本文提出了Snake-NeRF框架。该框架采用内存外策略，通过将场景划分为不重叠的3D NeRF瓦片，并对图像进行重叠裁剪，确保每个瓦片得到充分训练。为了避免瓦片边缘的重建误差，还引入了新颖的2x2 3D瓦片进展策略和分段采样器。实验证明，该方法能够在单个GPU上以线性时间复杂度高效处理大型卫星图像，同时保持高质量的重建效果。", "keywords": "NeRF, 卫星图像, 大规模3D重建, 内存外, 瓦片化", "comments": "该论文的创新之处在于其提出的Snake-NeRF框架，它通过独特的内存外方法和精巧的瓦片与图像处理策略，有效解决了NeRF在大规模3D地球观测中面临的内存瓶颈。特别值得注意的是，2x2 3D瓦片进展策略和分段采样器对于消除瓦片边缘的重建伪影至关重要。实现线性时间复杂度和在单个GPU上保持高质量的能力，使其在实际应用中具有重要意义，推动了NeRF从局部向全局3D重建的扩展。"}}
{"id": "2507.23093", "title": "On the Sustainability of AI Inferences in the Edge", "authors": ["Ghazal Sobhani", "Md. Monzurul Amin Ifath", "Tushar Sharma", "Israat Haque"], "categories": ["cs.LG", "cs.AI", "cs.PF"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures, 6 tables, in preparation for journal submission", "url": "http://arxiv.org/abs/2507.23093v1", "summary": "The proliferation of the Internet of Things (IoT) and its cutting-edge\nAI-enabled applications (e.g., autonomous vehicles and smart industries)\ncombine two paradigms: data-driven systems and their deployment on the edge.\nUsually, edge devices perform inferences to support latency-critical\napplications. In addition to the performance of these resource-constrained edge\ndevices, their energy usage is a critical factor in adopting and deploying edge\napplications. Examples of such devices include Raspberry Pi (RPi), Intel Neural\nCompute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU).\nDespite their adoption in edge deployment for AI inferences, there is no study\non their performance and energy usage for informed decision-making on the\ndevice and model selection to meet the demands of applications. This study\nfills the gap by rigorously characterizing the performance of traditional,\nneural networks, and large language models on the above-edge devices.\nSpecifically, we analyze trade-offs among model F1 score, inference time,\ninference power, and memory usage. Hardware and framework optimization, along\nwith external parameter tuning of AI models, can balance between model\nperformance and resource usage to realize practical edge AI deployments.", "comment": "14 pages, 8 figures, 6 tables, in preparation for journal submission", "pdf_url": "http://arxiv.org/pdf/2507.23093v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "边缘AI推理的可持续性研究", "tldr": "本研究旨在填补在边缘设备上部署AI推理时，缺乏关于设备和模型选择的性能和能耗研究的空白，通过对传统、神经网络和大型语言模型在多种边缘设备上的性能进行严格表征，分析模型F1分数、推理时间、推理功耗和内存使用之间的权衡。", "motivation": "尽管AI推理在边缘设备上得到广泛应用，但目前缺乏关于这些设备的性能和能耗研究，以指导设备和模型的选择，从而满足应用需求。本研究旨在填补这一空白。", "method": "本研究通过严格表征传统模型、神经网络和大型语言模型在多种边缘设备（如Raspberry Pi, Intel Neural Compute Stick, NVIDIA Jetson nano, Google Coral USB）上的性能。具体分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。", "result": "通过硬件和框架优化以及AI模型的外部参数调整，可以在模型性能和资源使用之间取得平衡，从而实现实用的边缘AI部署。", "conclusion": "硬件和框架优化以及AI模型的外部参数调整对于在边缘设备上实现实用的AI推理部署至关重要，它们有助于平衡模型性能和资源使用。", "translation": "物联网（IoT）及其前沿的AI使能应用（例如，自动驾驶汽车和智能工业）的普及结合了两种范式：数据驱动系统及其在边缘的部署。通常，边缘设备执行推理以支持对延迟敏感的应用。除了这些资源受限的边缘设备的性能外，它们的能耗也是采用和部署边缘应用的关键因素。此类设备的例子包括Raspberry Pi（RPi）、Intel Neural Compute Stick（INCS）、NVIDIA Jetson nano（NJn）和Google Coral USB（GCU）。尽管它们在边缘部署中用于AI推理，但目前尚无对其性能和能耗进行研究，以指导设备和模型选择，从而满足应用需求。本研究通过严格表征传统模型、神经网络和大型语言模型在上述边缘设备上的性能来填补这一空白。具体来说，我们分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。硬件和框架优化，以及AI模型的外部参数调整，可以在模型性能和资源使用之间取得平衡，从而实现实用的边缘AI部署。", "summary": "本研究探讨了AI推理在边缘设备上的可持续性问题，指出当前缺乏针对边缘设备AI推理性能和能耗的系统性研究。文章通过在多种典型边缘设备（如RPi, INCS, NJn, GCU）上，对传统、神经网络和大型语言模型进行性能表征，分析了F1分数、推理时间、功耗和内存使用之间的权衡。研究结果表明，通过硬件和框架优化以及模型参数调优，可以有效平衡模型性能与资源消耗，从而实现更实用的边缘AI部署。", "keywords": "边缘AI, 边缘计算, AI推理, 能耗, 性能评估", "comments": "该论文解决了边缘AI部署中的一个关键且实际问题，即性能与能耗的可持续性。其创新之处在于首次系统性地评估了不同类型AI模型在多种主流边缘设备上的综合表现，并提出了优化策略。这对于指导未来边缘AI硬件选择和模型部署具有重要意义，有助于推动边缘AI应用的普及和效率提升。"}}
{"id": "2408.09186", "title": "EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition", "authors": ["Qile Liu", "Weishan Ye", "Lingli Zhang", "Zhen Liang"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 10 figures, 14 tables. Accepted in ACMMM 2025", "url": "http://arxiv.org/abs/2408.09186v2", "summary": "Emotion recognition using electroencephalography (EEG) signals has attracted\nincreasing attention in recent years. However, existing methods often lack\ngeneralization in cross-corpus settings, where a model trained on one dataset\nis directly applied to another without retraining, due to differences in data\ndistribution and recording conditions. To tackle the challenge of cross-corpus\nEEG-based emotion recognition, we propose a novel framework termed Soft\nContrastive Masked Modeling (SCMM). Grounded in the theory of emotional\ncontinuity, SCMM integrates soft contrastive learning with a hybrid masking\nstrategy to effectively capture emotion dynamics (refer to short-term\ncontinuity). Specifically, in the self-supervised learning stage, we propose a\nsoft weighting mechanism that assigns similarity scores to sample pairs,\nenabling fine-grained modeling of emotional transitions and capturing the\ntemporal continuity of human emotions. To further enhance representation\nlearning, we design a similarity-aware aggregator that fuses complementary\ninformation from semantically related samples based on pairwise similarities,\nthereby improving feature expressiveness and reconstruction quality. This dual\ndesign contributes to a more discriminative and transferable representation,\nwhich is crucial for robust cross-corpus generalization. Extensive experiments\non the SEED, SEED-IV, and DEAP datasets show that SCMM achieves\nstate-of-the-art (SOTA) performance, outperforming the second-best method by an\naverage accuracy of 4.26% under both same-class and different-class\ncross-corpus settings. The source code is available at\nhttps://github.com/Kyler-RL/SCMM.", "comment": "18 pages, 10 figures, 14 tables. Accepted in ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2408.09186v2", "cate": "cs.HC", "date": "2024-08-17", "updated": "2025-07-31", "AI": {"title_translation": "脑电图-SCMM：用于跨语料库脑电图情绪识别的软对比掩蔽建模", "tldr": "本文提出了一种名为SCMM的软对比掩蔽建模框架，用于解决跨语料库脑电图情绪识别的泛化性问题，并通过软加权机制和相似性感知聚合器实现了最先进的性能。", "motivation": "现有基于脑电图（EEG）的情绪识别方法在跨语料库设置中泛化能力不足，即在一个数据集上训练的模型直接应用于另一个数据集时，由于数据分布和记录条件差异，性能会下降，需要解决这一挑战。", "method": "本文提出了一种名为软对比掩蔽建模（SCMM）的新型框架。SCMM基于情感连续性理论，将软对比学习与混合掩蔽策略相结合，以有效捕获情感动态。在自监督学习阶段，提出了一种软加权机制，为样本对分配相似性分数，以精细建模情感转换和捕获情绪的时间连续性。此外，设计了一个相似性感知聚合器，根据成对相似性融合语义相关样本的互补信息，以增强特征表达性和重建质量。这种双重设计有助于学习更具判别性和可迁移性的表示。", "result": "在SEED、SEED-IV和DEAP数据集上的大量实验表明，SCMM在同类和异类跨语料库设置下均实现了最先进（SOTA）的性能，平均准确率比次优方法高出4.26%。", "conclusion": "SCMM通过其独特的软加权机制和相似性感知聚合器，成功解决了跨语料库脑电图情绪识别的泛化性挑战，学习到更具判别性和可迁移性的表示，并在多个数据集上达到了最先进的性能。", "translation": "近年来，利用脑电图（EEG）信号进行情绪识别受到了越来越多的关注。然而，现有方法在跨语料库设置中往往缺乏泛化性，即在一个数据集上训练的模型在不重新训练的情况下直接应用于另一个数据集时，由于数据分布和记录条件的差异，性能会下降。为了解决跨语料库脑电图情绪识别的挑战，我们提出了一种名为软对比掩蔽建模（SCMM）的新型框架。SCMM以情感连续性理论为基础，将软对比学习与混合掩蔽策略相结合，以有效捕获情感动态（指短期连续性）。具体来说，在自监督学习阶段，我们提出了一种软加权机制，为样本对分配相似性分数，从而实现情感转换的精细建模并捕获人类情绪的时间连续性。为了进一步增强表示学习，我们设计了一个相似性感知聚合器，根据成对相似性融合来自语义相关样本的互补信息，从而提高特征表达性和重建质量。这种双重设计有助于获得更具判别性和可迁移性的表示，这对于强大的跨语料库泛化至关重要。在SEED、SEED-IV和DEAP数据集上进行的广泛实验表明，SCMM在同类和异类跨语料库设置下均实现了最先进（SOTA）的性能，平均准确率比次优方法高出4.26%。源代码可在https://github.com/Kyler-RL/SCMM获取。", "summary": "本文针对跨语料库脑电图（EEG）情绪识别中现有方法泛化能力不足的问题，提出了一种名为软对比掩蔽建模（SCMM）的新型框架。SCMM结合了软对比学习和混合掩蔽策略，并引入了软加权机制和相似性感知聚合器，以有效捕获情感动态并学习更具判别性和可迁移性的脑电表示。实验结果表明，SCMM在多个数据集上的跨语料库情绪识别任务中达到了最先进的性能，显著优于现有方法。", "keywords": "脑电图, 情绪识别, 跨语料库, 对比学习, 掩蔽建模", "comments": "该论文提出了一种新颖的软对比掩蔽建模（SCMM）框架，其创新点在于将情感连续性理论融入到模型设计中，并通过软加权机制和相似性感知聚合器来增强特征的判别性和可迁移性，有效解决了跨语料库EEG情绪识别的泛化性难题。其在多个公开数据集上取得的SOTA性能证明了其重要性，为EEG情绪识别领域提供了新的思路和强大的工具。"}}
{"id": "2505.20553", "title": "A ZeNN architecture to avoid the Gaussian trap", "authors": ["Luís Carvalho", "João L. Costa", "José Mourão", "Gonçalo Oliveira"], "categories": ["cs.LG", "math.PR", "68T07, 68T01", "I.2.0; G.0"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      New experiments involving PiNNs for solving Schrödinger and Bessel-type equations", "url": "http://arxiv.org/abs/2505.20553v2", "summary": "We propose a new simple architecture, Zeta Neural Networks (ZeNNs), in order\nto overcome several shortcomings of standard multi-layer perceptrons (MLPs).\nNamely, in the large width limit, MLPs are non-parametric, they do not have a\nwell-defined pointwise limit, they lose non-Gaussian attributes and become\nunable to perform feature learning; moreover, finite width MLPs perform poorly\nin learning high frequencies. The new ZeNN architecture is inspired by three\nsimple principles from harmonic analysis:\n  i) Enumerate the perceptons and introduce a non-learnable weight to enforce\nconvergence;\n  ii) Introduce a scaling (or frequency) factor;\n  iii) Choose activation functions that lead to near orthogonal systems.\n  We will show that these ideas allow us to fix the referred shortcomings of\nMLPs. In fact, in the infinite width limit, ZeNNs converge pointwise, they\nexhibit a rich asymptotic structure beyond Gaussianity, and perform feature\nlearning. Moreover, when appropriate activation functions are chosen, (finite\nwidth) ZeNNs excel at learning high-frequency features of functions with low\ndimensional domains.", "comment": "New experiments involving PiNNs for solving Schr\\\"odinger and\n  Bessel-type equations", "pdf_url": "http://arxiv.org/pdf/2505.20553v2", "cate": "cs.LG", "date": "2025-05-26", "updated": "2025-07-31", "AI": {"title_translation": "一种避免高斯陷阱的 ZeNN 架构", "tldr": "本文提出了一种新的神经网络架构ZeNNs，旨在克服标准多层感知器（MLPs）的缺点，特别是在大宽度极限下，MLPs失去非高斯属性且无法进行特征学习，以及在有限宽度下学习高频特征表现不佳的问题。ZeNNs通过引入谐波分析的三个简单原则，实现了逐点收敛、超越高斯性的丰富渐近结构和特征学习，并擅长学习高频特征。", "motivation": "标准多层感知器（MLPs）存在几个缺点：在宽度极限下是非参数的，没有明确的逐点极限，失去非高斯属性且无法进行特征学习；此外，有限宽度的MLPs在学习高频方面表现不佳。", "method": "ZeNNs架构受到谐波分析的三个简单原则启发：1) 枚举感知器并引入不可学习的权重以强制收敛；2) 引入一个缩放（或频率）因子；3) 选择能导致近似正交系统的激活函数。", "result": "ZeNNs解决了MLPs的缺点：在无限宽度极限下，ZeNNs逐点收敛，表现出超越高斯性的丰富渐近结构，并能进行特征学习。此外，当选择适当的激活函数时，（有限宽度的）ZeNNs擅长学习低维函数的高频特征。", "conclusion": "ZeNNs通过引入谐波分析的原则，成功克服了标准MLPs在处理高斯性、逐点收敛、特征学习和高频特征学习方面的局限性。", "translation": "我们提出了一种新的简单架构，Zeta神经网络（ZeNNs），旨在克服标准多层感知器（MLPs）的几个缺点。即，在宽度极限下，MLPs是非参数的，它们没有明确的逐点极限，它们失去非高斯属性并且无法进行特征学习；此外，有限宽度的MLPs在学习高频方面表现不佳。新的ZeNN架构受到谐波分析的三个简单原则启发： i) 枚举感知器并引入不可学习的权重以强制收敛；ii) 引入一个缩放（或频率）因子；iii) 选择能导致近似正交系统的激活函数。我们将展示这些思想使我们能够修复MLPs的上述缺点。事实上，在无限宽度极限下，ZeNNs逐点收敛，它们表现出超越高斯性的丰富渐近结构，并能进行特征学习。此外，当选择适当的激活函数时，（有限宽度的）ZeNNs擅长学习低维函数的高频特征。", "summary": "本文提出了一种名为Zeta神经网络（ZeNNs）的新架构，旨在解决标准多层感知器（MLPs）在大宽度极限下存在的非参数性、缺乏明确逐点极限、失去非高斯属性和无法进行特征学习的问题，以及有限宽度MLPs在高频学习上的不足。ZeNNs基于谐波分析的三个原则，通过引入枚举感知器、不可学习权重、缩放因子和特定激活函数，实现了在无限宽度下逐点收敛、展现超越高斯性的丰富渐近结构和执行特征学习。同时，在有限宽度下，ZeNNs在学习低维函数的高频特征方面表现出色。", "keywords": "ZeNN, 神经网络, 高斯陷阱, 高频学习, 特征学习", "comments": "这项工作提出了一种新颖的神经网络架构ZeNNs，通过引入谐波分析的原则，有效地解决了传统MLPs在处理高斯性、高频特征学习和大规模极限行为方面的固有局限性。其创新之处在于通过结构性设计而非仅仅依赖训练数据来克服“高斯陷阱”，这对于深度学习理论和实践都具有重要意义。特别是其在高频特征学习上的优势，有望在信号处理和物理建模等领域找到应用。"}}
{"id": "2507.23236", "title": "BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks", "authors": ["Zhuoyin Dai", "Di Wu", "Yong Zeng", "Xiaoli Xu", "Xinyi Wang", "Zesong Fei"], "categories": ["eess.SP", "eess.IV"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23236v1", "summary": "Channel knowledge map (CKM) inference across base stations (BSs) is the key\nto achieving efficient environmentaware communications. This paper proposes an\nenvironmentaware cross-BS CKM inference method called BS-1-to-N based on the\ngenerative diffusion model. To this end, we first design the BS location\nembedding (BSLE) method tailored for cross-BS CKM inference to embed BS\nlocation information in the feature vector of CKM. Further, we utilize the\ncross- and self-attention mechanism for the proposed BS-1-to-N model to\nrespectively learn the relationships between source and target BSs, as well as\nthat among target BSs. Therefore, given the locations of the source and target\nBSs, together with the source CKMs as control conditions, cross-BS CKM\ninference can be performed for an arbitrary number of source and target BSs.\nSpecifically, in architectures with massive distributed nodes like cell-free\nnetworks, traditional methods of sequentially traversing each BS for CKM\nconstruction are prohibitively costly. By contrast, the proposed BS-1-to-N\nmodel is able to achieve efficient CKM inference for a target BS at any\npotential location based on the CKMs of source BSs. This is achieved by\nexploiting the fact that within a given area, different BSs share the same\nwireless environment that leads to their respective CKMs. Therefore, similar to\nmulti-view synthesis, CKMs of different BSs are representations of the same\nwireless environment from different BS locations. By mining the implicit\ncorrelation between CKM and BS location based on the wireless environment, the\nproposed BS-1-to-N method achieves efficient CKM inference across BSs. We\nprovide extensive comparisons of CKM inference between the proposed BS-1-to-N\ngenerative model versus benchmarking schemes, and provide one use case study to\ndemonstrate its practical application for the optimization of BS deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23236v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "BS-1-to-N：基于扩散模型的蜂窝自由网络环境感知跨基站信道知识图生成", "tldr": "本文提出了一种名为BS-1-to-N的基于生成扩散模型的环境感知跨基站信道知识图（CKM）推断方法，以高效地推断任意目标基站的CKM，特别适用于无蜂窝网络。", "motivation": "跨基站信道知识图（CKM）推断是实现高效环境感知通信的关键。在无蜂窝网络等大规模分布式节点架构中，传统逐个基站遍历进行CKM构建的方法成本过高。", "method": "本文提出了一种名为BS-1-to-N的环境感知跨基站CKM推断方法，其基于生成扩散模型。为此，首先设计了针对跨基站CKM推断的基站位置嵌入（BSLE）方法，以将基站位置信息嵌入到CKM的特征向量中。其次，利用交叉注意力和自注意力机制来学习源基站与目标基站之间以及目标基站内部的关系。该方法通过利用给定区域内不同基站共享相同无线环境的特性，将不同基站的CKM视为同一无线环境在不同基站位置的表示，从而挖掘CKM与基站位置之间的隐式关联。", "result": "所提出的BS-1-to-N模型能够基于源基站的CKM，高效地推断任意潜在位置的目标基站的CKM。通过对所提出的BS-1-to-N生成模型与基准方案进行广泛的CKM推断比较，并提供了一个用例研究，展示了其在基站部署优化方面的实际应用。", "conclusion": "通过挖掘CKM与基站位置之间基于无线环境的隐式关联，所提出的BS-1-to-N方法实现了高效的跨基站CKM推断。", "translation": "跨基站（BS）信道知识图（CKM）推断是实现高效环境感知通信的关键。本文提出了一种名为BS-1-to-N的基于生成扩散模型的环境感知跨基站CKM推断方法。为此，我们首先设计了适用于跨基站CKM推断的基站位置嵌入（BSLE）方法，以将基站位置信息嵌入到CKM的特征向量中。此外，我们利用所提出的BS-1-to-N模型中的交叉注意力和自注意力机制，分别学习源基站与目标基站之间以及目标基站内部的关系。因此，给定源基站和目标基站的位置，以及作为控制条件的源CKM，可以对任意数量的源基站和目标基站进行跨基站CKM推断。具体而言，在无蜂窝网络等大规模分布式节点架构中，传统逐个基站遍历进行CKM构建的方法成本过高。相比之下，所提出的BS-1-to-N模型能够根据源基站的CKM，高效地推断任意潜在位置的目标基站的CKM。这是通过利用给定区域内不同基站共享相同无线环境从而产生各自CKM的事实来实现的。因此，类似于多视图合成，不同基站的CKM是同一无线环境在不同基站位置的表示。通过挖掘CKM与基站位置之间基于无线环境的隐式关联，所提出的BS-1-to-N方法实现了高效的跨基站CKM推断。我们对所提出的BS-1-to-N生成模型与基准方案进行了广泛的CKM推断比较，并提供了一个用例研究，以展示其在基站部署优化方面的实际应用。", "summary": "本文提出了一种名为BS-1-to-N的基于生成扩散模型的环境感知跨基站信道知识图（CKM）推断方法。该方法通过设计基站位置嵌入（BSLE）和利用交叉/自注意力机制，有效地学习了CKM与基站位置之间的隐式关联。它解决了传统方法在无蜂窝网络中CKM构建成本过高的问题，能够基于源CKM高效推断任意目标基站的CKM。实验结果和用例研究表明其在基站部署优化中的应用潜力。", "keywords": "信道知识图, 扩散模型, 无蜂窝网络, 基站, 环境感知", "comments": "该论文的创新点在于将生成扩散模型引入到跨基站信道知识图（CKM）推断中，并提出了环境感知的BSLE和注意力机制，以有效利用不同基站共享相同无线环境的特性。这对于解决大规模分布式网络（如无蜂窝网络）中传统CKM构建的高成本问题具有重要意义，提供了一种高效且灵活的CKM推断方案，有望在未来通信网络优化中发挥作用。"}}
{"id": "2507.23267", "title": "Your Spending Needs Attention: Modeling Financial Habits with Transformers", "authors": ["D. T. Braithwaite", "Misael Cavalcanti", "R. Austin McEver", "Hiroto Udagawa", "Daniel Silva", "Rohan Ramanath", "Felipe Meneses", "Arissa Yoshida", "Evan Wingert", "Matheus Ramos", "Brian Zanfelice", "Aman Gupta"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23267v1", "summary": "Predictive models play a crucial role in the financial industry, enabling\nrisk prediction, fraud detection, and personalized recommendations, where\nslight changes in core model performance can result in billions of dollars in\nrevenue or losses. While financial institutions have access to enormous amounts\nof user data (e.g., bank transactions, in-app events, and customer support\nlogs), leveraging this data effectively remains challenging due to its\ncomplexity and scale. Thus, in many financial institutions, most production\nmodels follow traditional machine learning (ML) approaches by converting\nunstructured data into manually engineered tabular features. Conversely, other\ndomains (e.g., natural language processing) have effectively utilized\nself-supervised learning (SSL) to learn rich representations from raw data,\nremoving the need for manual feature extraction. In this paper, we investigate\nusing transformer-based representation learning models for transaction data,\nhypothesizing that these models, trained on massive data, can provide a novel\nand powerful approach to understanding customer behavior. We propose a new\nmethod enabling the use of SSL with transaction data by adapting\ntransformer-based models to handle both textual and structured attributes. Our\napproach, denoted nuFormer, includes an end-to-end fine-tuning method that\nintegrates user embeddings with existing tabular features. Our experiments\ndemonstrate improvements for large-scale recommendation problems at Nubank.\nNotably, these gains are achieved solely through enhanced representation\nlearning rather than incorporating new data sources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23267v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "您的消费需要关注：使用Transformer模型建模金融习惯", "tldr": "该研究提出了一种名为nuFormer的新方法，通过将Transformer模型应用于交易数据并结合自监督学习，来改善金融领域的用户行为理解和推荐系统，并在Nubank的大规模推荐问题上取得了显著改进。", "motivation": "金融行业中的预测模型至关重要，但由于用户数据（如银行交易、应用内事件）的复杂性和规模，有效利用这些数据仍然具有挑战性。传统机器学习方法依赖手动特征工程，而其他领域（如自然语言处理）已有效利用自监督学习从原始数据中学习丰富的表示。因此，本文旨在探索使用基于Transformer的表示学习模型来克服金融数据处理的挑战，理解客户行为。", "method": "本文提出了一种名为nuFormer的新方法，通过调整基于Transformer的模型来处理文本和结构化属性，从而在交易数据上实现自监督学习。该方法包括一个端到端微调过程，将用户嵌入与现有表格特征相结合。", "result": "实验表明，该方法在Nubank的大规模推荐问题上取得了改进。值得注意的是，这些提升完全是通过增强表示学习实现的，而不是通过整合新的数据源。", "conclusion": "通过将Transformer模型应用于金融交易数据并结合自监督学习，可以提供一种新颖而强大的方法来理解客户行为，从而在不依赖新数据源的情况下显著提升金融行业中预测模型的性能。", "translation": "预测模型在金融行业中扮演着关键角色，能够实现风险预测、欺诈检测和个性化推荐，其中核心模型性能的微小变化可能导致数十亿美元的收入或损失。尽管金融机构拥有海量的用户数据（例如，银行交易、应用内事件和客户支持日志），但由于其复杂性和规模，有效利用这些数据仍然具有挑战性。因此，在许多金融机构中，大多数生产模型遵循传统的机器学习（ML）方法，通过将非结构化数据转换为手动工程的表格特征。相反，其他领域（例如，自然语言处理）已有效地利用自监督学习（SSL）从原始数据中学习丰富的表示，从而无需手动特征提取。在本文中，我们研究了使用基于Transformer的表示学习模型处理交易数据，并假设这些在海量数据上训练的模型可以提供一种新颖而强大的方法来理解客户行为。我们提出了一种新方法，通过调整基于Transformer的模型以处理文本和结构化属性，从而实现交易数据的自监督学习。我们的方法，称为nuFormer，包括一个端到端微调方法，将用户嵌入与现有表格特征相结合。我们的实验证明了在Nubank大规模推荐问题上的改进。值得注意的是，这些增益仅通过增强表示学习实现，而不是通过整合新的数据源。", "summary": "本研究旨在解决金融行业中利用复杂大规模用户数据（如交易数据）的挑战。针对传统机器学习方法依赖手动特征工程的局限性，论文提出了一种名为nuFormer的新型方法。该方法将NLP领域中成功的Transformer模型与自监督学习相结合，以从原始交易数据中学习丰富的表示，同时处理文本和结构化属性，并允许端到端微调。实验结果表明，nuFormer在金融机构（如Nubank）的大规模推荐任务中显著提升了性能，且这些改进仅源于更优的表示学习，而非引入新数据源。", "keywords": "金融习惯, Transformer, 自监督学习, 交易数据, 表示学习", "comments": "该论文的创新点在于将Transformer模型和自监督学习（通常应用于自然语言处理）引入到金融交易数据的分析中。这克服了传统金融模型对人工特征工程的依赖，并能从复杂、大规模的原始数据中自动学习更丰富的用户行为表示。其显著性在于，在不增加新数据源的情况下，仅通过改进表示学习就实现了模型性能的提升，这对于数据敏感且规模庞大的金融行业具有重要意义和应用潜力。"}}
{"id": "2411.18823", "title": "Multi-Task Label Discovery via Hierarchical Task Tokens for Partially Annotated Dense Predictions", "authors": ["Jingdong Zhang", "Hanrong Ye", "Xin Li", "Wenping Wang", "Dan Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.18823v2", "summary": "In recent years, simultaneous learning of multiple dense prediction tasks\nwith partially annotated label data has emerged as an important research area.\nPrevious works primarily focus on leveraging cross-task relations or conducting\nadversarial training for extra regularization, which achieve promising\nperformance improvements, while still suffering from the lack of direct\npixel-wise supervision and extra training of heavy mapping networks. To\neffectively tackle this challenge, we propose a novel approach to optimize a\nset of compact learnable hierarchical task tokens, including global and\nfine-grained ones, to discover consistent pixel-wise supervision signals in\nboth feature and prediction levels. Specifically, the global task tokens are\ndesigned for effective cross-task feature interactions in a global context.\nThen, a group of fine-grained task-specific spatial tokens for each task is\nlearned from the corresponding global task tokens. It is embedded to have dense\ninteractions with each task-specific feature map. The learned global and local\nfine-grained task tokens are further used to discover pseudo task-specific\ndense labels at different levels of granularity, and they can be utilized to\ndirectly supervise the learning of the multi-task dense prediction framework.\nExtensive experimental results on challenging NYUD-v2, Cityscapes, and PASCAL\nContext datasets demonstrate significant improvements over existing\nstate-of-the-art methods for partially annotated multi-task dense prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.18823v2", "cate": "cs.CV", "date": "2024-11-27", "updated": "2025-07-31", "AI": {"title_translation": "基于分层任务令牌的部分标注密集预测多任务标签发现", "tldr": "本文提出了一种新颖的分层任务令牌方法，用于在部分标注的多任务密集预测中发现像素级伪标签，以提供直接监督并显著优于现有SOTA方法。", "motivation": "现有方法在处理部分标注的多任务密集预测时，存在缺乏直接像素级监督和需要额外训练笨重映射网络的问题。", "method": "本文提出了一种优化紧凑型可学习分层任务令牌（包括全局和细粒度令牌）的新方法，以在特征和预测级别发现一致的像素级监督信号。全局任务令牌用于全局上下文中的跨任务特征交互，细粒度任务专用空间令牌从相应的全局任务令牌中学习，并嵌入以与每个任务专用特征图进行密集交互。这些学习到的令牌进一步用于发现不同粒度级别的伪任务专用密集标签，直接监督多任务密集预测框架的学习。", "result": "在NYUD-v2、Cityscapes和PASCAL Context数据集上的大量实验结果表明，该方法在部分标注的多任务密集预测方面显著优于现有最先进的方法。", "conclusion": "通过引入分层任务令牌来发现像素级伪标签，本文提出的方法有效解决了部分标注多任务密集预测中缺乏直接监督的问题，并取得了显著的性能提升。", "translation": "近年来，利用部分标注标签数据同时学习多个密集预测任务已成为一个重要的研究领域。以前的工作主要侧重于利用跨任务关系或进行对抗性训练以进行额外正则化，这些方法取得了可喜的性能改进，但仍然存在缺乏直接像素级监督和额外训练笨重映射网络的问题。为了有效解决这一挑战，我们提出了一种新颖的方法来优化一组紧凑的可学习分层任务令牌，包括全局和细粒度令牌，以在特征和预测级别发现一致的像素级监督信号。具体而言，全局任务令牌旨在实现全局上下文中的有效跨任务特征交互。然后，针对每个任务，从相应的全局任务令牌中学习一组细粒度任务专用空间令牌。它被嵌入以与每个任务专用特征图进行密集交互。学习到的全局和局部细粒度任务令牌进一步用于发现不同粒度级别的伪任务专用密集标签，并且它们可以用于直接监督多任务密集预测框架的学习。在具有挑战性的NYUD-v2、Cityscapes和PASCAL Context数据集上的大量实验结果表明，该方法在部分标注的多任务密集预测方面显著优于现有最先进的方法。", "summary": "针对部分标注多任务密集预测中缺乏直接像素级监督和依赖笨重映射网络的问题，本文提出了一种新颖的分层任务令牌方法。该方法通过学习全局和细粒度任务令牌，在特征和预测层面发现一致的像素级伪监督信号，并将其直接用于监督多任务密集预测框架。实验结果表明，该方法在多个数据集上显著优于现有SOTA方法。", "keywords": "多任务学习, 密集预测, 部分标注, 标签发现, 分层任务令牌", "comments": "该论文的创新点在于引入了“分层任务令牌”的概念，通过可学习的令牌机制巧妙地解决了部分标注数据下密集预测任务缺乏直接像素级监督的难题。这种方法避免了传统方法中对复杂映射网络的依赖，提供了一种更直接、更有效的监督信号发现机制。其重要性在于为多任务学习和弱监督学习领域提供了一个新的视角和解决方案。"}}
{"id": "2507.23070", "title": "Vocabulary-free Fine-grained Visual Recognition via Enriched Contextually Grounded Vision-Language Model", "authors": ["Dmitry Demidov", "Zaigham Zaheer", "Omkar Thawakar", "Salman Khan", "Fahad Shahbaz Khan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.23070v1", "summary": "Fine-grained image classification, the task of distinguishing between\nvisually similar subcategories within a broader category (e.g., bird species,\ncar models, flower types), is a challenging computer vision problem.\nTraditional approaches rely heavily on fixed vocabularies and closed-set\nclassification paradigms, limiting their scalability and adaptability in\nreal-world settings where novel classes frequently emerge. Recent research has\ndemonstrated that combining large language models (LLMs) with vision-language\nmodels (VLMs) makes open-set recognition possible without the need for\npredefined class labels. However, the existing methods are often limited in\nharnessing the power of LLMs at the classification phase, and also rely heavily\non the guessed class names provided by an LLM without thorough analysis and\nrefinement. To address these bottlenecks, we propose our training-free method,\nEnriched-FineR (or E-FineR for short), which demonstrates state-of-the-art\nresults in fine-grained visual recognition while also offering greater\ninterpretability, highlighting its strong potential in real-world scenarios and\nnew domains where expert annotations are difficult to obtain. Additionally, we\ndemonstrate the application of our proposed approach to zero-shot and few-shot\nclassification, where it demonstrated performance on par with the existing SOTA\nwhile being training-free and not requiring human interventions. Overall, our\nvocabulary-free framework supports the shift in image classification from rigid\nlabel prediction to flexible, language-driven understanding, enabling scalable\nand generalizable systems for real-world applications. Well-documented code is\navailable on https://github.com/demidovd98/e-finer.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23070v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "基于丰富上下文接地视觉-语言模型的无词汇细粒度视觉识别", "tldr": "提出了一种名为Enriched-FineR的免训练方法，通过结合视觉-语言模型（VLM）和大型语言模型（LLM）实现无词汇的细粒度视觉识别，并在零样本和少样本分类中达到最先进的性能。", "motivation": "细粒度图像分类面临挑战，传统方法依赖固定词汇和封闭集分类，限制了可扩展性。现有结合大型语言模型（LLM）和视觉-语言模型（VLM）的方法在分类阶段未能充分利用LLM，且过度依赖未经分析和完善的猜测类别名称。", "method": "提出了一种名为Enriched-FineR（E-FineR）的免训练方法。该方法旨在解决现有方法在利用LLM进行分类和完善猜测类别名称方面的瓶颈。", "result": "Enriched-FineR在细粒度视觉识别中取得了最先进的结果，并提供了更高的可解释性。在零样本和少样本分类中，其性能与现有最先进方法相当，同时免训练且无需人工干预。", "conclusion": "该无词汇框架支持图像分类从僵化标签预测向灵活、语言驱动理解的转变，从而实现可扩展且可泛化的真实世界应用系统。", "translation": "细粒度图像分类，即区分一个更广泛类别中视觉上相似的子类别（例如，鸟类、汽车型号、花卉类型）的任务，是一个具有挑战性的计算机视觉问题。传统方法严重依赖固定的词汇和封闭集分类范式，限制了它们在 novel 类频繁出现的现实世界设置中的可扩展性和适应性。最近的研究表明，将大型语言模型（LLM）与视觉-语言模型（VLM）相结合，使得无需预定义类别标签即可实现开放集识别。然而，现有方法在分类阶段利用LLM的能力方面往往受到限制，并且严重依赖LLM提供的猜测类别名称，而没有经过彻底的分析和完善。为了解决这些瓶颈，我们提出了我们的免训练方法Enriched-FineR（简称E-FineR），它在细粒度视觉识别中展示了最先进的结果，同时提供了更高的可解释性，突出了其在难以获得专家标注的现实世界场景和新领域的强大潜力。此外，我们展示了我们提出的方法在零样本和少样本分类中的应用，它在性能上与现有SOTA相当，同时免训练且无需人工干预。总的来说，我们的无词汇框架支持图像分类从僵化标签预测向灵活、语言驱动理解的转变，从而实现可扩展且可泛化的真实世界应用系统。文档齐全的代码可在https://github.com/demidovd98/e-finer上获取。", "summary": "本研究提出了一种名为Enriched-FineR（E-FineR）的免训练方法，用于解决细粒度视觉识别中传统方法对固定词汇的依赖以及现有视觉-语言模型（VLM）和大型语言模型（LLM）结合方式的局限性。E-FineR通过更有效地利用LLM并完善类别名称，在细粒度识别中取得了最先进的性能和更高的可解释性。该方法在零样本和少样本分类中表现出色，无需训练或人工干预，推动了图像分类向更灵活、语言驱动的理解转变，从而实现可扩展的真实世界应用。", "keywords": "细粒度视觉识别, 视觉-语言模型, 免训练, 零样本分类, 开放集识别", "comments": "该论文提出了一种创新的免训练（training-free）方法Enriched-FineR，这大大降低了模型部署和适应新领域的成本和复杂性。其“无词汇”（vocabulary-free）的特性解决了传统方法在面对新类别时的可扩展性问题，使其在现实世界应用中更具潜力。此外，其强调可解释性也是一个重要亮点。"}}
{"id": "2412.15441", "title": "Insights into resource utilization of code small language models serving with runtime engines and execution providers", "authors": ["Francisco Durán", "Matias Martinez", "Patricia Lago", "Silverio Martínez-Fernández"], "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted in Journal of Systems and Software (JSS). For its published version refer to the Journal of JSS", "url": "http://arxiv.org/abs/2412.15441v2", "summary": "The rapid growth of language models, particularly in code generation,\nrequires substantial computational resources, raising concerns about energy\nconsumption and environmental impact. Optimizing language models inference\nresource utilization is crucial, and Small Language Models (SLMs) offer a\npromising solution to reduce resource demands. Our goal is to analyze the\nimpact of deep learning serving configurations, defined as combinations of\nruntime engines and execution providers, on resource utilization, in terms of\nenergy consumption, execution time, and computing-resource utilization from the\npoint of view of software engineers conducting inference in the context of code\ngeneration SLMs. We conducted a technology-oriented, multi-stage experimental\npipeline using twelve code generation SLMs to investigate energy consumption,\nexecution time, and computing-resource utilization across the configurations.\nSignificant differences emerged across configurations. CUDA execution provider\nconfigurations outperformed CPU execution provider configurations in both\nenergy consumption and execution time. Among the configurations, TORCH paired\nwith CUDA demonstrated the greatest energy efficiency, achieving energy savings\nfrom 37.99% up to 89.16% compared to other serving configurations. Similarly,\noptimized runtime engines like ONNX with the CPU execution provider achieved\nfrom 8.98% up to 72.04% energy savings within CPU-based configurations. Also,\nTORCH paired with CUDA exhibited efficient computing-resource utilization.\nServing configuration choice significantly impacts resource utilization. While\nfurther research is needed, we recommend the above configurations best suited\nto software engineers' requirements for enhancing serving resource utilization\nefficiency.", "comment": "Accepted in Journal of Systems and Software (JSS). For its published\n  version refer to the Journal of JSS", "pdf_url": "http://arxiv.org/pdf/2412.15441v2", "cate": "cs.SE", "date": "2024-12-19", "updated": "2025-07-30", "AI": {"title_translation": "代码小型语言模型在运行时引擎和执行提供者服务中的资源利用洞察", "tldr": "研究发现，在服务代码生成小型语言模型时，使用CUDA执行提供者（特别是与TORCH搭配）比CPU更节能高效，ONNX与CPU搭配也能显著节能，服务配置选择对资源利用有显著影响。", "motivation": "大型语言模型需要大量计算资源，导致能源消耗和环境问题。优化语言模型推理资源利用至关重要，小型语言模型（SLMs）是减少资源需求的有前景方案。本研究旨在分析深度学习服务配置（运行时引擎和执行提供者的组合）对代码生成SLMs资源利用（能源消耗、执行时间、计算资源利用）的影响。", "method": "进行了一项面向技术的多阶段实验流程，使用十二个代码生成SLMs，调查了不同配置下的能源消耗、执行时间以及计算资源利用。", "result": "不同配置间存在显著差异。CUDA执行提供者配置在能源消耗和执行时间上优于CPU配置。TORCH与CUDA搭配展示出最高的能效，比其他配置节省37.99%至89.16%的能源。ONNX与CPU搭配在基于CPU的配置中节省了8.98%至72.04%的能源。TORCH与CUDA还表现出高效的计算资源利用。", "conclusion": "服务配置选择显著影响资源利用。TORCH与CUDA的组合以及ONNX与CPU的组合是提升服务资源利用效率的最佳选择，推荐给软件工程师。", "translation": "语言模型的快速增长，尤其是在代码生成领域，需要大量的计算资源，这引发了对能源消耗和环境影响的担忧。优化语言模型推理的资源利用至关重要，而小型语言模型（SLMs）提供了一种有前景的解决方案来降低资源需求。我们的目标是从软件工程师在代码生成SLMs背景下进行推理的角度，分析深度学习服务配置（定义为运行时引擎和执行提供者的组合）对资源利用（包括能源消耗、执行时间、计算资源利用）的影响。我们采用了一种面向技术的多阶段实验流程，使用十二个代码生成SLMs，调查了不同配置下的能源消耗、执行时间以及计算资源利用。结果显示，不同配置之间存在显著差异。CUDA执行提供者配置在能源消耗和执行时间上均优于CPU执行提供者配置。在所有配置中，TORCH与CUDA的组合表现出最高的能源效率，与其他服务配置相比，能源节省高达37.99%至89.16%。同样，像ONNX这样的优化运行时引擎与CPU执行提供者搭配，在基于CPU的配置中实现了8.98%至72.04%的能源节省。此外，TORCH与CUDA的组合也表现出高效的计算资源利用。服务配置的选择显著影响资源利用。尽管需要进一步研究，我们推荐上述配置最适合软件工程师的需求，以提高服务资源利用效率。", "summary": "本研究分析了深度学习服务配置（运行时引擎和执行提供者组合）对代码生成小型语言模型资源利用（能源消耗、执行时间、计算资源）的影响。实验结果表明，CUDA执行提供者配置（特别是TORCH与CUDA搭配）在能效和执行时间上显著优于CPU配置。TORCH-CUDA组合能节省大量能源并高效利用计算资源，而ONNX-CPU组合在CPU环境下也表现出显著节能。研究强调服务配置选择对资源利用效率至关重要，并推荐了最佳配置。", "keywords": "小型语言模型, 资源利用, 运行时引擎, 执行提供者, 能源效率", "comments": "该论文通过实证研究揭示了代码SLMs在不同服务配置下的资源利用效率差异，为软件工程师优化推理部署提供了实用指导。其创新点在于量化了运行时引擎和执行提供者组合对能耗和性能的影响。重要性体现在为绿色AI和高效模型部署提供了具体建议。局限性可能在于实验范围仅限于特定SLMs和配置，未来可扩展到更多模型和硬件。"}}
{"id": "2507.23334", "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages, 2 figures", "url": "http://arxiv.org/abs/2507.23334v1", "summary": "Recent advancements in Large language models (LLMs) have demonstrated\nremarkable capabilities across diverse domains. While they exhibit strong\nzero-shot performance on various tasks, LLMs' effectiveness in music-related\napplications remains limited due to the relatively small proportion of\nmusic-specific knowledge in their training data. To address this limitation, we\npropose MusT-RAG, a comprehensive framework based on Retrieval Augmented\nGeneration (RAG) to adapt general-purpose LLMs for text-only music question\nanswering (MQA) tasks. RAG is a technique that provides external knowledge to\nLLMs by retrieving relevant context information when generating answers to\nquestions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a\nmusic-specialized vector database for the retrieval stage, and (2) utilizes\ncontext information during both inference and fine-tuning processes to\neffectively transform general-purpose LLMs into music-specific models. Our\nexperiment demonstrates that MusT-RAG significantly outperforms traditional\nfine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,\nshowing consistent improvements across both in-domain and out-of-domain MQA\nbenchmarks. Additionally, our MusWikiDB proves substantially more effective\nthan general Wikipedia corpora, delivering superior performance and\ncomputational efficiency.", "comment": "8 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.23334v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MUST-RAG：基于检索增强生成技术的音乐文本问答", "tldr": "MusT-RAG是一个基于RAG的框架，通过专门的音乐数据库和上下文利用，显著提升了大型语言模型在音乐文本问答任务上的表现。", "motivation": "大型语言模型（LLMs）在音乐相关应用中的效果有限，因为其训练数据中音乐特定知识的比例相对较小。", "method": "提出MusT-RAG框架，基于检索增强生成（RAG）技术，将通用LLMs应用于文本音乐问答（MQA）任务。具体方法包括：1) 提出了MusWikiDB，一个音乐专业向量数据库用于检索阶段；2) 在推理和微调过程中利用上下文信息，将通用LLMs有效转换为音乐专用模型。", "result": "MusT-RAG在增强LLMs的音乐领域适应能力方面显著优于传统的微调方法，在域内和域外MQA基准测试中均显示出持续的改进。此外，MusWikiDB被证明比通用维基百科语料库更有效，提供了卓越的性能和计算效率。", "conclusion": "MusT-RAG框架通过引入音乐专业知识和优化RAG机制，成功提升了大型语言模型在音乐文本问答任务上的表现，解决了LLMs在音乐领域知识不足的问题。", "translation": "大型语言模型（LLMs）的最新进展在不同领域展现了卓越的能力。尽管它们在各种任务上表现出强大的零样本性能，但由于训练数据中音乐特定知识的比例相对较小，LLMs在音乐相关应用中的有效性仍然有限。为了解决这一限制，我们提出了MusT-RAG，一个基于检索增强生成（RAG）的综合框架，旨在使通用LLMs适应纯文本音乐问答（MQA）任务。RAG是一种通过在生成问题答案时检索相关上下文信息来为LLMs提供外部知识的技术。为了优化RAG在音乐领域的应用，我们（1）提出了MusWikiDB，一个用于检索阶段的音乐专业向量数据库，以及（2）在推理和微调过程中利用上下文信息，以有效地将通用LLMs转换为音乐专用模型。我们的实验表明，MusT-RAG在增强LLMs的音乐领域适应能力方面显著优于传统的微调方法，在域内和域外MQA基准测试中均显示出持续的改进。此外，我们的MusWikiDB被证明比通用维基百科语料库更有效，提供了卓越的性能和计算效率。", "summary": "本文提出了MusT-RAG，一个基于检索增强生成（RAG）的框架，旨在解决大型语言模型（LLMs）在音乐文本问答（MQA）任务中因音乐知识不足而表现受限的问题。MusT-RAG通过引入音乐专业向量数据库MusWikiDB，并在推理和微调阶段利用上下文信息，有效提升了通用LLMs在音乐领域的适应性。实验结果表明，MusT-RAG显著优于传统微调方法，且MusWikiDB比通用语料库更高效。", "keywords": "检索增强生成, 音乐问答, 大型语言模型, 向量数据库, 领域适应", "comments": "MusT-RAG的创新在于针对LLMs在特定领域知识不足的问题，提出了一个结合专业数据库和RAG的解决方案。特别是MusWikiDB的构建，为音乐领域的LLM应用提供了高质量的外部知识源。该方法不仅提升了模型性能，还提高了计算效率，对未来特定领域LLM的开发具有重要参考价值。"}}
{"id": "2412.02508", "title": "When Words Smile: Generating Diverse Emotional Facial Expressions from Text", "authors": ["Haidong Xu", "Meishan Zhang", "Hao Ju", "Zhedong Zheng", "Erik Cambria", "Min Zhang", "Hao Fei"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages. Resources: this https URL", "url": "http://arxiv.org/abs/2412.02508v3", "summary": "Enabling digital humans to express rich emotions has significant applications\nin dialogue systems, gaming, and other interactive scenarios. While recent\nadvances in talking head synthesis have achieved impressive results in lip\nsynchronization, they tend to overlook the rich and dynamic nature of facial\nexpressions. To fill this critical gap, we introduce an end-to-end\ntext-to-expression model that explicitly focuses on emotional dynamics. Our\nmodel learns expressive facial variations in a continuous latent space and\ngenerates expressions that are diverse, fluid, and emotionally coherent. To\nsupport this task, we introduce EmoAva, a large-scale and high-quality dataset\ncontaining 15,000 text-3D expression pairs. Extensive experiments on both\nexisting datasets and EmoAva demonstrate that our method significantly\noutperforms baselines across multiple evaluation metrics, marking a significant\nadvancement in the field.", "comment": "19 pages. Resources: https://github.com/WalkerMitty/EmoAva", "pdf_url": "http://arxiv.org/pdf/2412.02508v3", "cate": "cs.AI", "date": "2024-12-03", "updated": "2025-07-31", "AI": {"title_translation": "当文字微笑时：从文本生成多样化的情感面部表情", "tldr": "论文介绍了一个端到端的文本到表情模型，能够从文本生成多样化、流畅且情感连贯的面部表情，并提出了一个大规模数据集EmoAva，实验证明其性能优于现有基线。", "motivation": "现有数字人对话系统和游戏等交互场景中的说话人头部合成技术在唇部同步方面表现出色，但往往忽略了面部表情的丰富性和动态性。本文旨在填补这一关键空白。", "method": "本文提出一个端到端的文本到表情模型，该模型明确关注情感动态，并在连续潜在空间中学习富有表现力的面部变化，生成多样化、流畅且情感连贯的表情。同时，引入了一个包含15,000个文本-3D表情对的大规模高质量数据集EmoAva以支持此任务。", "result": "在现有数据集和新引入的EmoAva数据集上进行的大量实验表明，该方法在多个评估指标上显著优于现有基线。", "conclusion": "本文提出的方法在从文本生成多样化情感面部表情领域取得了显著进展，为数字人情感表达的真实性和多样性提供了新的解决方案。", "translation": "使数字人表达丰富的情感在对话系统、游戏和其他交互场景中具有重要的应用。虽然最近在说话人头部合成方面的进展在唇部同步方面取得了令人印象深刻的结果，但它们往往忽略了面部表情的丰富性和动态性。为了填补这一关键空白，我们引入了一个端到端的文本到表情模型，该模型明确关注情感动态。我们的模型在连续潜在空间中学习富有表现力的面部变化，并生成多样化、流畅且情感连贯的表情。为了支持这项任务，我们引入了EmoAva，一个包含15,000个文本-3D表情对的大规模高质量数据集。在现有数据集和EmoAva上的大量实验表明，我们的方法在多个评估指标上显著优于基线，标志着该领域的重大进步。", "summary": "本文提出了一个端到端的文本到表情模型，旨在解决现有数字人合成技术在面部表情丰富性和动态性方面的不足。该模型能够在连续潜在空间中学习面部表情变化，并从文本生成多样化、流畅且情感连贯的表情。为支持该任务，作者还创建了大规模高质量数据集EmoAva。实验结果表明，该方法在多个评估指标上显著优于现有基线。", "keywords": "文本到表情, 情感面部表情, 数字人, 情感动态, EmoAva", "comments": "该论文的创新点在于提出了一个明确关注情感动态的端到端文本到表情模型，并构建了一个大规模高质量的文本-3D表情数据集EmoAva，这对于推动数字人情感表达的真实性和多样性具有重要意义，对对话系统和游戏等交互场景的应用具有重要价值。"}}
{"id": "2504.16060", "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "authors": ["Ziqiao Ma", "Jing Ding", "Xuejun Zhang", "Dezhi Luo", "Jiahe Ding", "Sihan Xu", "Yuchen Huang", "Run Peng", "Joyce Chai"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025 & CVinW @ CVPR 2025 (Spotlight). Homepage: this https URL", "url": "http://arxiv.org/abs/2504.16060v3", "summary": "Referring Expression Generation (REG) is a core task for evaluating the\npragmatic competence of vision-language systems, requiring not only accurate\nsemantic grounding but also adherence to principles of cooperative\ncommunication (Grice, 1975). However, current evaluations of vision-language\nmodels (VLMs) often overlook the pragmatic dimension, reducing REG to a\nregion-based captioning task and neglecting Gricean maxims. In this work, we\nrevisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of\n1.5k images annotated with both written and spoken referring expressions.\nThrough a systematic evaluation of state-of-the-art VLMs, we identify three key\nfailures of pragmatic competence: (1) failure to uniquely identify the\nreferent, (2) inclusion of excessive or irrelevant information, and (3)\nmisalignment with human pragmatic preference, such as the underuse of minimal\nspatial cues. We also show that standard automatic evaluations fail to capture\nthese pragmatic violations, reinforcing superficial cues rather than genuine\nreferential success. Our findings call for a renewed focus on pragmatically\ninformed models and evaluation frameworks that align with real human\ncommunication.", "comment": "COLM 2025 & CVinW @ CVPR 2025 (Spotlight). Homepage:\n  https://vlm-reg.github.io/", "pdf_url": "http://arxiv.org/pdf/2504.16060v3", "cate": "cs.CL", "date": "2025-04-22", "updated": "2025-07-31", "AI": {"title_translation": "视觉语言模型在指称表达生成中不具备语用能力", "tldr": "当前视觉语言模型在指称表达生成任务中缺乏语用能力，现有评估方法也未能有效捕捉这些缺陷。研究引入新数据集并揭示了模型的三大语用失败。", "motivation": "现有视觉语言模型（VLMs）在指称表达生成（REG）任务中的评估往往忽视语用维度，将REG简化为基于区域的图像描述任务，并忽略了格赖斯合作原则。这促使研究者重新审视REG的语用能力。", "method": "研究从语用学角度重新审视指称表达生成（REG），引入了一个包含1.5k图像的新数据集（RefOI），该数据集标注了书面和口头指称表达。通过系统评估最先进的视觉语言模型（VLMs），分析其语用能力。", "result": "研究识别出视觉语言模型在语用能力方面的三个关键失败：1）未能唯一识别指称物；2）包含过多或不相关信息；3）与人类语用偏好不符，例如对最小空间线索的不足使用。研究还表明，标准的自动化评估未能捕捉这些语用违规，反而强化了表面线索而非真正的指称成功。", "conclusion": "研究结果呼吁重新关注以语用学为基础的模型和评估框架，使其与真实人类交流对齐。", "translation": "指称表达生成（REG）是评估视觉语言系统语用能力的核心任务，它不仅要求准确的语义接地，还需要遵循合作交流原则（Grice, 1975）。然而，当前对视觉语言模型（VLMs）的评估往往忽视语用维度，将REG简化为基于区域的图像描述任务，并忽略了格赖斯准则。在这项工作中，我们从语用学角度重新审视REG，引入了一个包含1.5k图像的新数据集（RefOI），该数据集标注了书面和口头指称表达。通过对最先进的视觉语言模型进行系统评估，我们识别出语用能力方面的三个关键失败：（1）未能唯一识别指称物，（2）包含过多或不相关信息，以及（3）与人类语用偏好不符，例如对最小空间线索的不足使用。我们还表明，标准的自动化评估未能捕捉这些语用违规，反而强化了表面线索而非真正的指称成功。我们的研究结果呼吁重新关注以语用学为基础的模型和评估框架，使其与真实人类交流对齐。", "summary": "本研究从语用学角度重新审视了视觉语言模型在指称表达生成（REG）中的能力，指出当前评估忽视了语用维度。通过引入一个新数据集RefOI并系统评估了现有模型，揭示了模型在唯一识别指称物、信息冗余以及与人类语用偏好不符方面的三大语用失败。研究还发现现有自动化评估无法有效捕捉这些语用缺陷。论文呼吁未来应关注更具语用意识的模型和评估框架。", "keywords": "视觉语言模型, 指称表达生成, 语用能力, 数据集, 评估", "comments": "这项研究的创新之处在于它首次系统性地强调了视觉语言模型在指称表达生成任务中缺乏语用能力，并引入了专门用于语用评估的新数据集RefOI。其重要性在于揭示了现有评估方法的局限性，并为未来开发更符合人类交流习惯的视觉语言模型指明了方向。论文强调了“合作交流原则”在VLM中的缺失，对VLM的实用性和可靠性提出了重要挑战。"}}
{"id": "2507.22897", "title": "RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems", "authors": ["Luyu Chen", "Quanyu Dai", "Zeyu Zhang", "Xueyang Feng", "Mingyu Zhang", "Pengcheng Tang", "Xu Chen", "Yue Zhu", "Zhenhua Dong"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted by TheWebConf'25 Industry Track", "url": "http://arxiv.org/abs/2507.22897v1", "summary": "Conversational recommender systems (CRS) enhance user experience through\nmulti-turn interactions, yet evaluating CRS remains challenging. User\nsimulators can provide comprehensive evaluations through interactions with CRS,\nbut building realistic and diverse simulators is difficult. While recent work\nleverages large language models (LLMs) to simulate user interactions, they\nstill fall short in emulating individual real users across diverse scenarios\nand lack explicit rating mechanisms for quantitative evaluation. To address\nthese gaps, we propose RecUserSim, an LLM agent-based user simulator with\nenhanced simulation realism and diversity while providing explicit scores.\nRecUserSim features several key modules: a profile module for defining\nrealistic and diverse user personas, a memory module for tracking interaction\nhistory and discovering unknown preferences, and a core action module inspired\nby Bounded Rationality theory that enables nuanced decision-making while\ngenerating more fine-grained actions and personalized responses. To further\nenhance output control, a refinement module is designed to fine-tune final\nresponses. Experiments demonstrate that RecUserSim generates diverse,\ncontrollable outputs and produces realistic, high-quality dialogues, even with\nsmaller base LLMs. The ratings generated by RecUserSim show high consistency\nacross different base LLMs, highlighting its effectiveness for CRS evaluation.", "comment": "Accepted by TheWebConf'25 Industry Track", "pdf_url": "http://arxiv.org/pdf/2507.22897v1", "cate": "cs.HC", "date": "2025-06-25", "updated": "2025-06-25", "AI": {"title_translation": "RecUserSim：一个用于评估对话推荐系统的真实且多样化的用户模拟器", "tldr": "RecUserSim是一个基于LLM的对话推荐系统用户模拟器，它通过增强模拟真实性和多样性，并提供明确的评分机制来解决现有模拟器在评估CRS方面的不足。实验证明其能生成高质量对话和一致性评分。", "motivation": "对话推荐系统（CRS）的评估具有挑战性。现有用户模拟器虽然利用大型语言模型（LLM）进行交互模拟，但在模拟真实用户、多样化场景以及提供明确的定量评估评分方面仍有不足。", "method": "本文提出了RecUserSim，一个基于LLM代理的用户模拟器。它包含多个关键模块：用于定义用户画像的配置文件模块、用于跟踪交互历史和发现未知偏好的记忆模块、受有限理性理论启发的核心行动模块（实现细致决策和生成细粒度动作及个性化响应），以及用于微调最终响应的优化模块。", "result": "实验表明，RecUserSim能够生成多样化、可控的输出，并产生真实、高质量的对话，即使使用较小的基础LLM也能实现。RecUserSim生成的评分在不同基础LLM之间显示出高度一致性。", "conclusion": "RecUserSim通过提供增强的模拟真实性、多样性和明确的评分机制，有效解决了对话推荐系统评估中的挑战，并被证明是CRS评估的有效工具。", "translation": "对话推荐系统（CRS）通过多轮交互增强用户体验，但评估CRS仍然具有挑战性。用户模拟器可以通过与CRS的交互提供全面的评估，但构建真实且多样化的模拟器很困难。尽管最近的工作利用大型语言模型（LLM）来模拟用户交互，但它们在模拟各种场景下的个体真实用户方面仍然不足，并且缺乏明确的评分机制进行定量评估。为了解决这些不足，我们提出了RecUserSim，一个基于LLM代理的用户模拟器，它增强了模拟的真实性和多样性，同时提供明确的评分。RecUserSim具有几个关键模块：用于定义真实和多样化用户画像的配置文件模块、用于跟踪交互历史和发现未知偏好的记忆模块，以及受有限理性理论启发的核心行动模块，该模块能够实现细致的决策，同时生成更细粒度的动作和个性化响应。为了进一步增强输出控制，设计了一个优化模块来微调最终响应。实验表明，RecUserSim能够生成多样化、可控的输出，并产生真实、高质量的对话，即使使用较小的基础LLM也能实现。RecUserSim生成的评分在不同基础LLM之间显示出高度一致性，突出了其在CRS评估方面的有效性。", "summary": "本文提出RecUserSim，一个基于LLM代理的用户模拟器，旨在解决对话推荐系统（CRS）评估中现有模拟器在真实性、多样性和量化评分方面的不足。RecUserSim包含配置文件、记忆、核心行动和优化等模块，以实现对用户行为的精细模拟和个性化响应。实验结果表明，RecUserSim能够生成高质量、多样化且可控的对话，并提供在不同LLM间高度一致的评估评分，证明了其在CRS评估中的有效性。", "keywords": "用户模拟器, 对话推荐系统, 大型语言模型, 评估, RecUserSim", "comments": "RecUserSim的创新之处在于其模块化设计，特别是引入了基于有限理性理论的核心行动模块和用于精细控制响应的优化模块。它解决了当前LLM用户模拟器在模拟真实用户行为和提供量化评估方面的关键局限性，使得CRS的评估更加全面和客观。其能够在较小LLM上表现良好，也增加了其实用性。"}}
{"id": "2507.23526", "title": "Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey", "authors": ["Wen-Xuan Long", "Shengyu Ye", "Marco Moretti", "Michele Morelli", "Luca Sanguinetti", "Rui Chen", "Cheng-Xiang Wang"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23526v1", "summary": "The sixth-generation (6G) wireless systems are expected to adopt extremely\nlarge aperture arrays (ELAAs), novel antenna architectures, and operate in\nextremely high-frequency bands to meet growing data demands. ELAAs\nsignificantly increase the number of antennas, enabling finer spatial\nresolution and improved beamforming. At high frequencies, ELAAs shift\ncommunication from the conventional far-field to near-field regime, where\nspherical wavefronts dominate and the channel response depends on both angle\nand distance, increasing channel dimensionality. Conventional far-field channel\nestimation methods, which rely on angular information, struggle in near-field\nscenarios due to increased pilot overhead and computational complexity. This\npaper presents a comprehensive survey of recent advances in near-field channel\nestimation. It first defines the near- and far-field boundary from an\nelectromagnetic perspective and discusses key propagation differences,\nalongside a brief review of ELAA developments. Then, it introduces mainstream\nnear-field channel models and compares them with far-field models. Major\nestimation techniques are reviewed under different configurations\n(single/multi-user, single/multi-carrier), including both direct estimation and\nRIS-assisted cascaded estimation. These techniques reveal trade-offs among\nestimation accuracy, complexity, and overhead. This survey aims to provide\ninsights and foundations for efficient and scalable near-field channel\nestimation in 6G systems, while identifying key challenges and future research\ndirections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23526v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "6G近场无线通信信道估计：一项综合性综述", "tldr": "该综述全面回顾了6G近场无线通信中的信道估计方法，涵盖了近场特性、信道模型、主要估计技术及其权衡，并指出了未来研究方向。", "motivation": "6G系统预计将采用ELAA和高频段，导致通信从传统远场转向近场，引入球形波前和更高的信道维度。传统远场信道估计方法在近场场景中面临导频开销和计算复杂度增加的挑战，因此需要对近场信道估计进行深入研究和综述。", "method": "本文对近场信道估计的最新进展进行了全面综述。首先，从电磁学角度定义了近场和远场边界，讨论了关键传播差异，并简要回顾了ELAA的发展。然后，介绍了主流的近场信道模型，并与远场模型进行了比较。最后，在不同配置（单用户/多用户、单载波/多载波）下回顾了主要的估计技术，包括直接估计和RIS辅助级联估计。", "result": "该综述揭示了信道估计精度、复杂性和开销之间的权衡。它提供了对6G系统中高效可扩展近场信道估计的见解和基础，并识别了关键挑战和未来的研究方向。", "conclusion": "本综述旨在为6G系统中的高效和可扩展近场信道估计提供见解和基础，同时识别关键挑战和未来的研究方向。", "translation": "第六代（6G）无线系统预计将采用超大孔径阵列（ELAAs）、新型天线架构，并在极高频段运行，以满足不断增长的数据需求。ELAAs显著增加了天线数量，实现了更精细的空间分辨率和改进的波束成形。在高频下，ELAAs将通信从传统的远场转向近场，在近场中，球形波前占主导地位，信道响应取决于角度和距离，从而增加了信道维度。传统的远场信道估计方法依赖于角度信息，在近场场景中由于导频开销和计算复杂度的增加而面临挑战。本文对近场信道估计的最新进展进行了全面综述。它首先从电磁学角度定义了近场和远场边界，讨论了关键传播差异，并简要回顾了ELAA的发展。然后，介绍了主流的近场信道模型，并将其与远场模型进行了比较。在不同配置（单用户/多用户、单载波/多载波）下回顾了主要的估计技术，包括直接估计和RIS辅助级联估计。这些技术揭示了估计精度、复杂度与开销之间的权衡。本综述旨在为6G系统中高效且可扩展的近场信道估计提供见解和基础，同时识别关键挑战和未来的研究方向。", "summary": "本篇综述全面探讨了6G近场无线通信中的信道估计问题。随着6G系统采用超大孔径阵列和高频段，通信从传统远场转向近场，引入了更复杂的球形波前和更高的信道维度，使得传统信道估计方法面临挑战。文章首先阐述了近场与远场的边界及传播差异，回顾了ELAA发展，并介绍了主流近场信道模型。随后，详细分析了单/多用户、单/多载波配置下的直接估计和RIS辅助级联估计等主要估计技术，并讨论了它们在精度、复杂度和开销上的权衡。该综述旨在为6G近场信道估计提供基础和见解，并指明未来的研究方向。", "keywords": "6G, 近场通信, 信道估计, 超大孔径阵列, 综合综述", "comments": "该综述对于理解6G近场通信中的核心挑战——信道估计具有重要意义。它系统地梳理了近场特性、模型及当前主流的估计技术，并指出了关键的权衡和未来方向，为研究人员提供了宝贵的参考框架。其价值在于整合了分散的知识点，并为后续研究奠定了基础。"}}
{"id": "2507.22653", "title": "UniLegs: Universal Multi-Legged Robot Control through Morphology-Agnostic Policy Distillation", "authors": ["Weijie Xi", "Zhanxiang Cao", "Chenlin Ming", "Jianying Zheng", "Guyue Zhou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, IROS 2025", "url": "http://arxiv.org/abs/2507.22653v2", "summary": "Developing controllers that generalize across diverse robot morphologies\nremains a significant challenge in legged locomotion. Traditional approaches\neither create specialized controllers for each morphology or compromise\nperformance for generality. This paper introduces a two-stage teacher-student\nframework that bridges this gap through policy distillation. First, we train\nspecialized teacher policies optimized for individual morphologies, capturing\nthe unique optimal control strategies for each robot design. Then, we distill\nthis specialized expertise into a single Transformer-based student policy\ncapable of controlling robots with varying leg configurations. Our experiments\nacross five distinct legged morphologies demonstrate that our approach\npreserves morphology-specific optimal behaviors, with the Transformer\narchitecture achieving 94.47% of teacher performance on training morphologies\nand 72.64% on unseen robot designs. Comparative analysis reveals that\nTransformer-based architectures consistently outperform MLP baselines by\nleveraging attention mechanisms to effectively model joint relationships across\ndifferent kinematic structures. We validate our approach through successful\ndeployment on a physical quadruped robot, demonstrating the practical viability\nof our morphology-agnostic control framework. This work presents a scalable\nsolution for developing universal legged robot controllers that maintain\nnear-optimal performance while generalizing across diverse morphologies.", "comment": "6 pages, 3 figures, IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.22653v2", "cate": "cs.RO", "date": "2025-07-30", "updated": "2025-07-31", "AI": {"title_translation": "UniLegs: 通过形态无关的策略蒸馏实现通用多足机器人控制", "tldr": "本文提出了UniLegs，一个两阶段的教师-学生框架，通过策略蒸馏实现对多种多足机器人的通用控制，使其能够用单一的基于Transformer的策略在不同形态下达到接近最优的性能。", "motivation": "开发能够泛化到不同机器人形态的控制器是足式机器人运动领域的一个重大挑战。传统方法要么为每种形态创建专用控制器，要么为了通用性而牺牲性能，本文旨在解决这一问题。", "method": "本文引入了一个两阶段的教师-学生框架。首先，训练针对个体形态优化的专用教师策略。然后，将这些专业知识蒸馏到一个单一的基于Transformer的学生策略中，该策略能够控制具有不同腿部配置的机器人，并利用Transformer的注意力机制建模关节关系。", "result": "该方法在训练形态上达到了教师性能的94.47%，在未见过的机器人设计上达到了72.64%。基于Transformer的架构在比较分析中始终优于MLP基线。该方法已成功部署在物理四足机器人上。", "conclusion": "该工作为开发通用足式机器人控制器提供了一个可扩展的解决方案，该方案在泛化到不同形态的同时保持了接近最优的性能。", "translation": "开发能够泛化到不同机器人形态的控制器仍然是足式机器人运动领域的一个重大挑战。传统方法要么为每种形态创建专用控制器，要么为了通用性而牺牲性能。本文引入了一个两阶段的教师-学生框架，通过策略蒸馏弥补了这一差距。首先，我们训练针对个体形态优化的专用教师策略，捕捉每种机器人设计的独特最优控制策略。然后，我们将这种专业知识蒸馏到一个基于Transformer的单一学生策略中，该策略能够控制具有不同腿部配置的机器人。我们在五种不同的足部形态上的实验表明，我们的方法保留了形态特异性的最优行为，其中Transformer架构在训练形态上达到了教师性能的94.47%，在未见过的机器人设计上达到了72.64%。比较分析表明，基于Transformer的架构通过利用注意力机制有效地建模不同运动结构中的关节关系，始终优于MLP基线。我们通过在物理四足机器人上的成功部署验证了我们的方法，展示了我们形态无关控制框架的实际可行性。这项工作为开发通用足式机器人控制器提供了一个可扩展的解决方案，该方案在泛化到不同形态的同时保持了接近最优的性能。", "summary": "本文提出UniLegs，一个用于多足机器人控制的两阶段教师-学生策略蒸馏框架，旨在解决控制器难以泛化到不同机器人形态的问题。该方法首先训练针对特定形态的教师策略，然后将这些专业知识蒸馏到一个单一的基于Transformer的学生策略中，使其能够控制具有不同腿部配置的机器人。实验表明，该方法在训练形态上能达到教师性能的94.47%，在未见形态上达到72.64%，并优于MLP基线。UniLegs已成功部署于物理机器人，提供了一个可扩展的通用足式机器人控制方案。", "keywords": "多足机器人控制, 策略蒸馏, 形态无关, Transformer, 通用控制器", "comments": "该论文提出了一种新颖的教师-学生策略蒸馏框架，有效地解决了多足机器人控制器在不同形态之间泛化困难的问题。其创新点在于利用Transformer的注意力机制来建模关节关系，实现了形态无关的控制，并在物理机器人上进行了验证，展示了其在通用机器人控制领域的潜力。"}}
{"id": "2507.23620", "title": "DivControl: Knowledge Diversion for Controllable Image Generation", "authors": ["Yucheng Xie", "Fu Feng", "Ruixiao Shi", "Jing Wang", "Yong Rui", "Xin Geng"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23620v1", "summary": "Diffusion models have advanced from text-to-image (T2I) to image-to-image\n(I2I) generation by incorporating structured inputs such as depth maps,\nenabling fine-grained spatial control. However, existing methods either train\nseparate models for each condition or rely on unified architectures with\nentangled representations, resulting in poor generalization and high adaptation\ncosts for novel conditions. To this end, we propose DivControl, a decomposable\npretraining framework for unified controllable generation and efficient\nadaptation. DivControl factorizes ControlNet via SVD into basic\ncomponents-pairs of singular vectors-which are disentangled into\ncondition-agnostic learngenes and condition-specific tailors through knowledge\ndiversion during multi-condition training. Knowledge diversion is implemented\nvia a dynamic gate that performs soft routing over tailors based on the\nsemantics of condition instructions, enabling zero-shot generalization and\nparameter-efficient adaptation to novel conditions. To further improve\ncondition fidelity and training efficiency, we introduce a representation\nalignment loss that aligns condition embeddings with early diffusion features.\nExtensive experiments demonstrate that DivControl achieves state-of-the-art\ncontrollability with 36.4$\\times$ less training cost, while simultaneously\nimproving average performance on basic conditions. It also delivers strong\nzero-shot and few-shot performance on unseen conditions, demonstrating superior\nscalability, modularity, and transferability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23620v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DivControl：用于可控图像生成的知识分流", "tldr": "DivControl提出了一种新的可分解预训练框架，通过知识分流和动态门控实现统一的可控图像生成，显著降低训练成本并提高泛化能力。", "motivation": "现有方法在可控图像生成方面存在问题，即为每个条件训练单独的模型或使用表示纠缠的统一架构，导致泛化能力差和对新条件的适应成本高。", "method": "DivControl通过SVD将ControlNet分解为基本组件（奇异向量对），并通过多条件训练中的知识分流将其解耦为与条件无关的“learngenes”和与条件相关的“tailors”。知识分流通过一个动态门实现，该门根据条件指令的语义对“tailors”进行软路由。此外，引入了表示对齐损失以提高条件保真度和训练效率。", "result": "DivControl在可控性方面达到了最先进水平，训练成本降低了36.4倍，同时提高了基本条件的平均性能。它还在未见条件下表现出强大的零样本和少样本性能，展示了卓越的可扩展性、模块性和可迁移性。", "conclusion": "DivControl通过其独特的知识分流和可分解框架，成功解决了可控图像生成中现有方法的局限性，实现了高效且高泛化的多条件图像生成。", "translation": "扩散模型通过整合深度图等结构化输入，已从文本到图像（T2I）生成发展到图像到图像（I2I）生成，从而实现了细粒度的空间控制。然而，现有方法要么为每个条件训练单独的模型，要么依赖于表示纠缠的统一架构，导致泛化能力差和对新条件的适应成本高。为此，我们提出了DivControl，一个用于统一可控生成和高效适应的可分解预训练框架。DivControl通过SVD将ControlNet分解为基本组件——奇异向量对，并通过多条件训练中的知识分流将其解耦为与条件无关的“learngenes”和与条件相关的“tailors”。知识分流通过一个动态门实现，该门根据条件指令的语义对“tailors”进行软路由，从而实现零样本泛化和对新条件的参数高效适应。为了进一步提高条件保真度和训练效率，我们引入了一种表示对齐损失，该损失将条件嵌入与早期扩散特征对齐。大量实验表明，DivControl在可控性方面达到了最先进水平，训练成本降低了36.4倍，同时提高了基本条件的平均性能。它还在未见条件下表现出强大的零样本和少样本性能，展示了卓越的可扩展性、模块性和可迁移性。", "summary": "DivControl提出了一种新颖的可分解预训练框架，旨在解决现有可控图像生成方法在泛化能力和适应成本方面的不足。该框架通过SVD分解ControlNet，并利用知识分流将组件解耦为通用和条件特定的部分。通过动态门控和表示对齐损失，DivControl实现了对多种条件的高效统一生成，并支持零样本和少样本适应。实验证明，DivControl在保持最先进可控性的同时，显著降低了训练成本，并提升了对未见条件的泛化能力。", "keywords": "可控图像生成, 扩散模型, 知识分流, ControlNet, 零样本学习", "comments": "DivControl的核心创新在于其知识分流机制和SVD分解ControlNet的方法，这有效解决了多条件可控生成中模型冗余和泛化性差的问题。通过将知识解耦为通用和条件特定部分，并引入动态门控进行智能路由，该方法不仅大幅降低了训练和适应成本，还显著提升了对新条件的零样本和少样本泛化能力，展现了在实际应用中的巨大潜力。"}}
{"id": "2412.12180", "title": "Fully stochastic trust-region methods with Barzilai-Borwein steplengths", "authors": ["Stefania Bellavia", "Benedetta Morini", "Mahsa Yousefi"], "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.12180v2", "summary": "We investigate stochastic gradient methods and stochastic counterparts of the\nBarzilai-Borwein steplengths and their application to finite-sum minimization\nproblems. Our proposal is based on the Trust-Region-ish (TRish) framework\nintroduced in [F. E. Curtis, K. Scheinberg, R. Shi, {\\it A stochastic trust\nregion algorithm based on careful step normalization}, Informs Journal on\nOptimization, 1, 2019]. The new framework, named TRishBB, aims to enhance the\nperformance of TRish and at reducing the computational cost of the second-order\nTRish variant. We propose three different methods belonging to the TRishBB\nframework and present the convergence analysis for possibly nonconvex objective\nfunctions, considering biased and unbiased gradient approximations. Our\nanalysis requires neither diminishing step-sizes nor full gradient evaluation.\nThe numerical experiments in machine learning applications demonstrate the\neffectiveness of applying the Barzilai-Borwein steplength with stochastic\ngradients and show improved testing accuracy compared to the TRish method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.12180v2", "cate": "math.OC", "date": "2024-12-13", "updated": "2025-07-31", "AI": {"title_translation": "带有Barzilai-Borwein步长的全随机信赖域方法", "tldr": "本文提出了一种名为TRishBB的新型全随机信赖域框架，该框架结合了Barzilai-Borwein步长，用于解决有限和最小化问题，并在机器学习应用中展现出更高的测试精度和计算效率。", "motivation": "旨在增强现有Trust-Region-ish (TRish) 框架的性能并降低其二阶变体的计算成本，以更有效地解决有限和最小化问题。", "method": "提出了一种名为TRishBB的新框架，该框架基于TRish框架并集成了随机梯度方法和Barzilai-Borwein步长。TRishBB框架包含三种不同的方法，并对可能非凸的目标函数进行了收敛性分析，该分析无需递减步长或完整的梯度评估。", "result": "数值实验表明，在机器学习应用中，将Barzilai-Borwein步长与随机梯度结合使用是有效的，并且与TRish方法相比，测试精度有所提高。", "conclusion": "通过引入TRishBB框架和Barzilai-Borwein步长，可以有效地解决有限和最小化问题，并在机器学习应用中实现性能提升和计算效率的优化。", "translation": "我们研究了随机梯度方法和Barzilai-Borwein步长的随机对应物及其在有限和最小化问题中的应用。我们的提议基于[F. E. Curtis, K. Scheinberg, R. Shi, 《基于仔细步长归一化的随机信赖域算法》，Informs Journal on Optimization, 1, 2019]中引入的Trust-Region-ish (TRish) 框架。这个名为TRishBB的新框架旨在增强TRish的性能并降低二阶TRish变体的计算成本。我们提出了属于TRishBB框架的三种不同方法，并对可能非凸的目标函数进行了收敛性分析，考虑了有偏和无偏梯度近似。我们的分析既不需要递减步长，也不需要完整的梯度评估。机器学习应用中的数值实验表明，将Barzilai-Borwein步长与随机梯度结合使用是有效的，并且与TRish方法相比，测试精度有所提高。", "summary": "本文探讨了将随机梯度方法与Barzilai-Borwein步长相结合，应用于有限和最小化问题。研究提出了一种名为TRishBB的新框架，该框架基于现有的TRish，旨在提升性能并降低计算成本。文章详细介绍了TRishBB框架下的三种方法，并提供了对可能非凸目标函数的收敛性分析，该分析的独特之处在于无需递减步长或完整梯度评估。在机器学习应用中的数值实验验证了该方法的有效性，并显示出相较于TRish方法的测试精度提升。", "keywords": "随机梯度方法, 信赖域方法, Barzilai-Borwein步长, 有限和最小化, 非凸优化", "comments": "这项工作通过将Barzilai-Borwein步长引入到随机信赖域方法中，特别是基于TRish框架，为解决大规模有限和最小化问题提供了一种创新且高效的方法。其在收敛性分析中不需要递减步长或完整梯度评估的特性，显著提升了方法的实用性和计算效率。在机器学习应用中表现出的精度提升，也凸显了该方法的潜在价值和广阔的应用前景。"}}
{"id": "2507.23168", "title": "Extension Decisions in Open Source Software Ecosystem", "authors": ["Elmira Onagh", "Maleknaz Nayebi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Paper published in JSS journal", "url": "http://arxiv.org/abs/2507.23168v1", "summary": "GitHub Marketplace is expanding by approximately 41% annually, with new\ntools; however, many additions replicate existing functionality. We study this\nphenomenon in the platform's largest segment, Continuous Integration (CI), by\nlinking 6,983 CI Actions to 3,869 providers and mining their version histories.\nOur graph model timestamps every functionality's debut, tracks its adoption,\nand clusters redundant tools. We find that approximately 65% of new CI Actions\nreplicate existing capabilities, typically within six months, and that a small\nset of first-mover Actions accounts for most subsequent forks and extensions.\nThese insights enable developers to choose the optimal moment to launch, target\nunmet functionality, and help maintainers eliminate redundant tools. We publish\nthe complete graph and dataset to encourage longitudinal research on innovation\nand competition in software ecosystems, and to provide practitioners with a\ndata-driven roadmap for identifying emerging trends and guiding product\nstrategy.", "comment": "Paper published in JSS journal", "pdf_url": "http://arxiv.org/pdf/2507.23168v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "开源软件生态系统中的扩展决策", "tldr": "GitHub Marketplace中大量新工具与现有功能重复。本研究通过分析CI Actions发现，约65%的新Actions在六个月内重复现有功能，且少数先行者Actions主导后续发展。这些发现有助于开发者优化发布时机、填补功能空白，并帮助维护者消除冗余工具。", "motivation": "GitHub Marketplace以每年约41%的速度增长，但许多新增工具复制了现有功能，导致大量冗余。本研究旨在探讨这种重复扩展现象，并提供洞察以帮助开发者和维护者。", "method": "研究选取平台最大的Continuous Integration (CI) segment，将6,983个CI Actions与3,869个提供者关联，并挖掘其版本历史。构建图模型以记录每个功能的首次亮相时间、跟踪其采用情况并聚类冗余工具。", "result": "研究发现，大约65%的新CI Actions复制了现有功能，通常在六个月内发生。少数先行者Actions占据了后续大多数分支和扩展。", "conclusion": "这些发现能帮助开发者选择最佳发布时机、瞄准未满足的功能需求，并协助维护者消除冗余工具。研究还发布了完整图和数据集，以鼓励对软件生态系统创新和竞争的长期研究，并为从业者提供数据驱动的路线图，以识别新兴趋势和指导产品策略。", "translation": "GitHub Marketplace正以每年约41%的速度扩展，新增了许多工具；然而，许多新增功能复制了现有功能。我们通过将6,983个CI Actions与3,869个提供者关联并挖掘其版本历史，研究了平台最大细分市场——持续集成（CI）中的这种现象。我们的图模型记录了每个功能的首次亮相时间，跟踪其采用情况，并聚类冗余工具。我们发现，大约65%的新CI Actions复制了现有功能，通常在六个月内发生，并且一小部分先行者Actions占据了后续大多数分支和扩展。这些见解使开发者能够选择最佳发布时机，瞄准未满足的功能需求，并帮助维护者消除冗余工具。我们发布了完整的图和数据集，以鼓励对软件生态系统创新和竞争的长期研究，并为从业者提供数据驱动的路线图，以识别新兴趋势和指导产品策略。", "summary": "本研究调查了GitHub Marketplace中开源软件扩展的重复现象，特别是在持续集成（CI）领域。通过构建和分析包含6,983个CI Actions及其提供者和版本历史的图模型，发现约65%的新Actions在六个月内重复现有功能，且少数先行者 Actions 驱动了后续的扩展。研究结果为开发者和维护者提供了关于产品发布策略、功能空白识别和冗余工具管理的数据驱动见解。", "keywords": "开源软件, GitHub Marketplace, 持续集成, 功能冗余, 生态系统扩展", "comments": "该论文通过对GitHub Marketplace中CI Actions的深入分析，揭示了开源软件生态系统中普遍存在的冗余扩展问题。其创新之处在于构建了详细的图模型来追踪功能演变和冗余，并量化了重复的程度。这项工作对于理解软件生态系统的动态竞争和创新模式具有重要意义，同时也为开发者和平台维护者提供了实用的决策支持。"}}
{"id": "2507.22923", "title": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "authors": ["Aman Gupta", "Yingying Zhuang", "Zhou Yu", "Ziji Zhang", "Anurag Beniwal"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Prompt Optimization KDD '25", "url": "http://arxiv.org/abs/2507.22923v1", "summary": "Despite advances in the multilingual capabilities of Large Language Models\n(LLMs), their performance varies substantially across different languages and\ntasks. In multilingual retrieval-augmented generation (RAG)-based systems,\nknowledge bases (KB) are often shared from high-resource languages (such as\nEnglish) to low-resource ones, resulting in retrieved information from the KB\nbeing in a different language than the rest of the context. In such scenarios,\ntwo common practices are pre-translation to create a mono-lingual prompt and\ncross-lingual prompting for direct inference. However, the impact of these\nchoices remains unclear. In this paper, we systematically evaluate the impact\nof different prompt translation strategies for classification tasks with\nRAG-enhanced LLMs in multilingual systems. Experimental results show that an\noptimized prompting strategy can significantly improve knowledge sharing across\nlanguages, therefore improve the performance on the downstream classification\ntask. The findings advocate for a broader utilization of multilingual resource\nsharing and cross-lingual prompt optimization for non-English languages,\nespecially the low-resource ones.", "comment": "Accepted at Prompt Optimization KDD '25", "pdf_url": "http://arxiv.org/pdf/2507.22923v1", "cate": "cs.CL", "date": "2025-07-21", "updated": "2025-07-21", "AI": {"title_translation": "如何以及在何处翻译？跨语言大型语言模型提示中翻译策略的影响", "tldr": "本研究系统评估了多语言RAG增强型LLM中不同的提示翻译策略对分类任务的影响，发现优化后的策略能显著提升跨语言知识共享和下游任务性能。", "motivation": "尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务上的表现差异很大。在多语言检索增强生成（RAG）系统中，知识库（KB）常从高资源语言（如英语）共享到低资源语言，导致检索到的信息与上下文其他部分语言不同。在这种情况下，预翻译创建单语言提示和跨语言提示直接推理是两种常见做法，但这些选择的影响尚不明确。", "method": "本文系统评估了多语言系统中RAG增强型LLMs在分类任务中不同提示翻译策略的影响。", "result": "实验结果表明，优化后的提示策略可以显著改善跨语言知识共享，从而提高下游分类任务的性能。", "conclusion": "研究结果提倡更广泛地利用多语言资源共享和针对非英语语言，尤其是低资源语言的跨语言提示优化。", "translation": "尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务上的表现差异很大。在多语言检索增强生成（RAG）系统中，知识库（KB）通常从高资源语言（如英语）共享到低资源语言，导致检索到的信息与上下文其他部分语言不同。在这种情况下，预翻译创建单语言提示和跨语言提示直接推理是两种常见做法。然而，这些选择的影响仍不明确。在本文中，我们系统评估了多语言系统中RAG增强型LLMs在分类任务中不同提示翻译策略的影响。实验结果表明，优化后的提示策略可以显著改善跨语言知识共享，从而提高下游分类任务的性能。研究结果提倡更广泛地利用多语言资源共享和针对非英语语言，尤其是低资源语言的跨语言提示优化。", "summary": "本研究旨在解决多语言LLM在跨语言RAG系统中表现不一的问题，尤其关注知识库语言与上下文语言不一致时的翻译策略影响。论文系统评估了预翻译和跨语言提示这两种常见策略在RAG增强型LLM分类任务中的效果。实验结果表明，通过优化提示翻译策略，可以显著提升跨语言知识共享效率，进而提高下游分类任务的性能。研究强调了在非英语和低资源语言中推广多语言资源共享和跨语言提示优化的重要性。", "keywords": "跨语言LLM, 提示工程, 翻译策略, RAG, 多语言系统", "comments": "该论文解决了多语言LLM和RAG系统中的一个实际且重要的问题，即如何有效处理跨语言知识共享。其创新之处在于系统性地评估了不同的提示翻译策略，并明确指出了优化策略对性能的显著提升。这项工作对于推动非英语和低资源语言在LLM应用中的发展具有重要意义。"}}
{"id": "2507.23632", "title": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective", "authors": ["Gabriel Mongaras", "Eric C. Larson"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23632v1", "summary": "Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23632v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Softmax 注意力的表达能力：一种循环神经网络的视角", "tldr": "Softmax 注意力功能强大但具有二次复杂度。线性注意力速度更快但准确性较低。本文通过展示 softmax 注意力的循环形式以及线性注意力如何近似它，解释了为什么 softmax 注意力更具表达能力。", "motivation": "Softmax 注意力虽然具有强大的表达能力，但存在内存和计算复杂度与序列长度呈二次方关系的问题。虽然线性注意力旨在解决这一瓶颈，但其在下游任务中的准确性通常不如 softmax 注意力。本文的动机是理解为什么 softmax 注意力更具表达能力，以及尽管线性注意力源自 softmax 公式，但这种性能差距为何存在。", "method": "本文推导了 softmax 注意力的循环形式。利用这种形式，将 softmax 注意力的各个部分用循环神经网络（RNN）的语言进行描述。这种 RNN 视角允许对 softmax 注意力的组件进行消融研究，以理解每个部分的重要性及其相互作用。此外，本文还证明了线性注意力是 softmax 注意力的一种近似。", "result": "本文证明了线性注意力是 softmax 注意力的一种近似。通过推导 softmax 注意力的循环形式，使得其组件可以用 RNN 的语言进行描述。这种视角有助于理解 softmax 注意力组件的重要性及其相互作用，从而解释了其更强的表达能力。", "conclusion": "本文通过推导 softmax 注意力的循环形式并展示线性注意力是其近似，解释了为什么 softmax 注意力比其线性对应物更具表达能力。", "translation": "自推出以来，softmax 注意力因其在各种任务中的表达能力和可扩展性而成为现代 Transformer 架构的支柱。然而，softmax 注意力的主要缺点是其内存需求和计算复杂度与序列长度呈二次方关系。通过替换 softmax 非线性，引入了线性注意力和类似方法，以避免 softmax 注意力的二次瓶颈。尽管这些线性形式的注意力源自原始的 softmax 公式，但它们在下游准确性方面通常表现不佳。虽然对查询和键内积上的 softmax 非线性的强烈直觉表明它比其他非线性具有更理想的特性，但这种差异为何存在的问题仍未得到解答。这项工作通过推导 softmax 注意力的循环形式，证明了线性注意力是 softmax 注意力的一种近似。利用这种形式，softmax 注意力的每个部分都可以用循环神经网络 (RNN) 的语言来描述。将 softmax 注意力描述为 RNN 允许对 softmax 注意力的组件进行消融研究，以了解每个部分的重要性以及它们如何相互作用。通过这种方式，我们的工作有助于解释为什么 softmax 注意力比其对应物更具表达能力。", "summary": "本文探讨了 softmax 注意力及其线性近似之间表达能力的差距。它推导了 softmax 注意力的循环神经网络（RNN）形式，并证明了线性注意力是 softmax 注意力的一种近似。通过从 RNN 的角度审视 softmax 注意力，本文解释了其组成部分的作用，从而阐明了为什么 softmax 注意力尽管存在二次复杂度，但仍具有更强的表达能力。", "keywords": "softmax 注意力, 线性注意力, 循环神经网络, 表达能力, Transformer", "comments": "创新点在于推导了 softmax 注意力的循环形式，并以 RNN 的视角解释了其表达能力，这为 Transformer 核心组件提供了新颖的理论理解。其重要性在于弥合了高效线性注意力机制与更强大但计算密集型 softmax 注意力之间的理解鸿沟，该理论洞察力可能指导未来设计更高效且同样具有表达能力的注意力机制。局限性在于摘要中未提及任何通过这种循环形式进行的实证结果或具体实验来验证其主张。"}}
{"id": "2507.23567", "title": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection", "authors": ["Yung-Hsu Yang", "Luigi Piccinelli", "Mattia Segu", "Siyuan Li", "Rui Huang", "Yuqian Fu", "Marc Pollefeys", "Hermann Blum", "Zuria Bauer"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.23567v1", "summary": "Monocular 3D object detection is valuable for various applications such as\nrobotics and AR/VR. Existing methods are confined to closed-set settings, where\nthe training and testing sets consist of the same scenes and/or object\ncategories. However, real-world applications often introduce new environments\nand novel object categories, posing a challenge to these methods. In this\npaper, we address monocular 3D object detection in an open-set setting and\nintroduce the first end-to-end 3D Monocular Open-set Object Detector (3D-MOOD).\nWe propose to lift the open-set 2D detection into 3D space through our designed\n3D bounding box head, enabling end-to-end joint training for both 2D and 3D\ntasks to yield better overall performance. We condition the object queries with\ngeometry prior and overcome the generalization for 3D estimation across diverse\nscenes. To further improve performance, we design the canonical image space for\nmore efficient cross-dataset training. We evaluate 3D-MOOD on both closed-set\nsettings (Omni3D) and open-set settings (Omni3D to Argoverse 2, ScanNet), and\nachieve new state-of-the-art results. Code and models are available at\nroyyang0714.github.io/3D-MOOD.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23567v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "3D-MOOD: 将2D提升到3D，用于单目开放集目标检测", "tldr": "3D-MOOD是首个端到端单目开放集3D目标检测器，通过将开放集2D检测提升到3D空间，并在多个数据集上取得了最先进的性能。", "motivation": "现有的单目3D目标检测方法局限于封闭集设置，在真实世界应用中无法处理新环境和新物体类别带来的挑战。", "method": "本文提出了3D-MOOD，通过设计的3D边界框头部将开放集2D检测提升到3D空间，实现2D和3D任务的端到端联合训练。它通过几何先验条件化对象查询来克服3D估计在不同场景下的泛化问题，并设计了规范图像空间以实现更高效的跨数据集训练。", "result": "3D-MOOD在封闭集设置（Omni3D）和开放集设置（Omni3D到Argoverse 2、ScanNet）上进行了评估，并取得了新的最先进结果。", "conclusion": "3D-MOOD是首个解决单目开放集3D目标检测问题的方法，通过将2D检测提升到3D并引入创新机制，显著提高了开放集环境下的3D目标检测性能。", "translation": "单目3D目标检测对于机器人和AR/VR等各种应用具有重要价值。现有方法局限于封闭集设置，即训练集和测试集包含相同的场景和/或物体类别。然而，真实世界的应用通常会引入新的环境和新颖的物体类别，这对这些方法构成了挑战。在本文中，我们解决了开放集设置下的单目3D目标检测问题，并推出了第一个端到端3D单目开放集目标检测器（3D-MOOD）。我们建议通过我们设计的3D边界框头部将开放集2D检测提升到3D空间，从而实现2D和3D任务的端到端联合训练，以获得更好的整体性能。我们通过几何先验条件化对象查询，并克服了3D估计在不同场景下的泛化问题。为了进一步提高性能，我们设计了规范图像空间以实现更高效的跨数据集训练。我们在封闭集设置（Omni3D）和开放集设置（Omni3D到Argoverse 2、ScanNet）上评估了3D-MOOD，并取得了新的最先进结果。代码和模型可在royyang0714.github.io/3D-MOOD获取。", "summary": "本文介绍了3D-MOOD，首个端到端单目开放集3D目标检测器。它旨在解决现有方法在处理新环境和物体类别时的局限性。3D-MOOD通过将开放集2D检测提升到3D空间，并利用3D边界框头部、几何先验和规范图像空间进行联合训练，从而在封闭集和开放集设置下均取得了最先进的性能。", "keywords": "单目3D目标检测, 开放集检测, 3D-MOOD, 2D到3D提升, 深度学习", "comments": "3D-MOOD的创新之处在于它是首个将单目2D检测提升到3D开放集环境的端到端解决方案，解决了现有方法在泛化能力上的不足。其提出的3D边界框头部、几何先验和规范图像空间等机制，有效提升了在多样化场景和未知类别下的3D检测性能，对实际应用具有重要意义。"}}
{"id": "2506.00068", "title": "Framing Political Bias in Multilingual LLMs Across Pakistani Languages", "authors": ["Afrozah Nadeem", "Mark Dras", "Usman Naseem"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2506.00068v2", "summary": "Large Language Models (LLMs) increasingly shape public discourse, yet most\nevaluations of political and economic bias have focused on high-resource,\nWestern languages and contexts. This leaves critical blind spots in\nlow-resource, multilingual regions such as Pakistan, where linguistic identity\nis closely tied to political, religious, and regional ideologies. We present a\nsystematic evaluation of political bias in 13 state-of-the-art LLMs across five\nPakistani languages: Urdu, Punjabi, Sindhi, Pashto, and Balochi. Our framework\nintegrates a culturally adapted Political Compass Test (PCT) with multi-level\nframing analysis, capturing both ideological stance (economic/social axes) and\nstylistic framing (content, tone, emphasis). Prompts are aligned with 11\nsocio-political themes specific to the Pakistani context. Results show that\nwhile LLMs predominantly reflect liberal-left orientations consistent with\nWestern training data, they exhibit more authoritarian framing in regional\nlanguages, highlighting language-conditioned ideological modulation. We also\nidentify consistent model-specific bias patterns across languages. These\nfindings show the need for culturally grounded, multilingual bias auditing\nframeworks in global NLP.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2506.00068v2", "cate": "cs.CL", "date": "2025-05-29", "updated": "2025-07-31", "AI": {"title_translation": "巴基斯坦语言多语言大型语言模型中的政治偏见框架", "tldr": "本研究评估了13个大型语言模型在五种巴基斯坦语言中的政治偏见，发现LLM在区域语言中表现出更强的威权主义倾向，突出了语言对意识形态的影响，并强调了全球NLP中文化背景化、多语言偏见审计框架的必要性。", "motivation": "现有的大型语言模型（LLMs）偏见评估主要集中在高资源、西方语言和背景，忽视了巴基斯坦等低资源、多语言地区，而这些地区的语言认同与政治、宗教、地域意识形态紧密相连，因此存在关键盲点，需要进行系统性评估。", "method": "研究对13个最先进的LLM在五种巴基斯坦语言（乌尔都语、旁遮普语、信德语、普什图语和俾路支语）中的政治偏见进行了系统评估。采用的框架整合了文化适应的政治罗盘测试（PCT）与多层次框架分析，以捕捉意识形态立场（经济/社会轴）和文体框架（内容、语调、强调）。提示词与11个特定于巴基斯坦背景的社会政治主题对齐。", "result": "结果显示，虽然LLM主要反映与西方训练数据一致的自由左翼倾向，但它们在区域语言中表现出更强的威权主义框架，突出了语言条件下的意识形态调制。研究还识别出跨语言一致的模型特定偏见模式。", "conclusion": "这些发现表明，在全球自然语言处理（NLP）领域，迫切需要开发和应用文化背景化、多语言的偏见审计框架。", "translation": "大型语言模型（LLMs）日益塑造公共话语，然而，大多数关于政治和经济偏见的评估都集中在高资源、西方语言和背景。这在巴基斯坦等低资源、多语言地区留下了关键盲点，因为在这些地区，语言认同与政治、宗教和地域意识形态紧密相连。我们对13个最先进的LLM在五种巴基斯坦语言（乌尔都语、旁遮普语、信德语、普什图语和俾路支语）中的政治偏见进行了系统评估。我们的框架将文化适应的政治罗盘测试（PCT）与多层次框架分析相结合，捕捉意识形态立场（经济/社会轴）和文体框架（内容、语调、强调）。提示词与11个特定于巴基斯坦背景的社会政治主题对齐。结果显示，虽然LLM主要反映与西方训练数据一致的自由左翼倾向，但它们在区域语言中表现出更强的威权主义框架，突出了语言条件下的意识形态调制。我们还识别出跨语言一致的模型特定偏见模式。这些发现表明全球NLP中需要文化背景化、多语言的偏见审计框架。", "summary": "本研究评估了13个最先进的大型语言模型在五种巴基斯坦语言（乌尔都语、旁遮普语、信德语、普什图语、俾路支语）中的政治偏见，旨在弥补现有偏见评估主要集中在西方语言的不足。研究构建了一个结合文化适应的政治罗盘测试和多层次框架分析的评估体系，发现LLM虽然普遍表现出与西方训练数据一致的自由左翼倾向，但在巴基斯坦区域语言中却展现出更强的威权主义框架，揭示了语言对模型意识形态输出的调制作用。研究结果强调了在全球NLP中建立文化背景化、多语言偏见审计框架的必要性。", "keywords": "政治偏见, 多语言LLM, 巴基斯坦语言, 意识形态, 偏见审计", "comments": "这项研究的创新之处在于首次系统性地评估了大型语言模型在巴基斯坦这一低资源、多语言环境中的政治偏见，特别关注了语言认同与意识形态之间的紧密关联。其重要性体现在揭示了当前LLM偏见评估中的“盲点”，并强调了在全球自然语言处理领域中，对模型进行文化适应和多语言偏见审计的紧迫性。研究发现语言可以调节LLM的意识形态输出，这是一个对未来多语言模型开发和部署具有重要指导意义的洞察。"}}
{"id": "2507.22955", "title": "LLMs Between the Nodes: Community Discovery Beyond Vectors", "authors": ["Ekta Gujral", "Apurva Sinha"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22955v1", "summary": "Community detection in social network graphs plays a vital role in uncovering\ngroup dynamics, influence pathways, and the spread of information. Traditional\nmethods focus primarily on graph structural properties, but recent advancements\nin Large Language Models (LLMs) open up new avenues for integrating semantic\nand contextual information into this task. In this paper, we present a detailed\ninvestigation into how various LLM-based approaches perform in identifying\ncommunities within social graphs. We introduce a two-step framework called\nCommLLM, which leverages the GPT-4o model along with prompt-based reasoning to\nfuse language model outputs with graph structure. Evaluations are conducted on\nsix real-world social network datasets, measuring performance using key metrics\nsuch as Normalized Mutual Information (NMI), Adjusted Rand Index (ARI),\nVariation of Information (VOI), and cluster purity. Our findings reveal that\nLLMs, particularly when guided by graph-aware strategies, can be successfully\napplied to community detection tasks in small to medium-sized graphs. We\nobserve that the integration of instruction-tuned models and carefully\nengineered prompts significantly improves the accuracy and coherence of\ndetected communities. These insights not only highlight the potential of LLMs\nin graph-based research but also underscore the importance of tailoring model\ninteractions to the specific structure of graph data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22955v1", "cate": "cs.SI", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "节点间的LLM：超越向量的社区发现", "tldr": "该研究提出并评估了一种基于大型语言模型（LLMs）的社区检测方法，名为CommLLM，它通过结合GPT-4o和提示工程，将语义信息融入社交图谱分析中，并在中小规模图谱上展现了成功应用潜力。", "motivation": "传统的社区检测方法主要关注图的结构属性，但大型语言模型（LLMs）的最新进展为将语义和上下文信息整合到社区检测任务中开辟了新途径，以克服传统方法的局限性。", "method": "本文详细研究了各种基于LLM的方法在识别社交图谱社区中的表现。引入了一个名为CommLLM的两步框架，该框架利用GPT-4o模型和基于提示的推理，将语言模型输出与图结构融合。在六个真实世界社交网络数据集上进行了评估，并使用标准化互信息（NMI）、调整兰德指数（ARI）、信息变异（VOI）和聚类纯度等关键指标衡量性能。", "result": "研究结果表明，大型语言模型（LLMs），特别是在图感知策略的指导下，可以成功应用于中小规模图的社区检测任务。观察到指令调优模型和精心设计的提示的集成显著提高了检测社区的准确性和连贯性。", "conclusion": "这些见解不仅突出了LLMs在基于图的研究中的潜力，而且强调了根据图数据的特定结构调整模型交互的重要性。", "translation": "社交网络图中的社区检测在揭示群体动态、影响力路径和信息传播方面发挥着至关重要的作用。传统方法主要关注图结构属性，但大型语言模型（LLMs）的最新进展为将语义和上下文信息整合到此任务中开辟了新途径。在本文中，我们详细研究了各种基于LLM的方法在识别社交图谱社区中的表现。我们引入了一个名为CommLLM的两步框架，该框架利用GPT-4o模型和基于提示的推理，将语言模型输出与图结构融合。在六个真实世界社交网络数据集上进行了评估，并使用标准化互信息（NMI）、调整兰德指数（ARI）、信息变异（VOI）和聚类纯度等关键指标衡量性能。我们的发现表明，LLMs，特别是在图感知策略的指导下，可以成功应用于中小规模图的社区检测任务。我们观察到指令调优模型和精心设计的提示的集成显著提高了检测社区的准确性和连贯性。这些见解不仅突出了LLMs在基于图的研究中的潜力，而且强调了根据图数据的特定结构调整模型交互的重要性。", "summary": "本研究探讨了将大型语言模型（LLMs）应用于社交网络图中的社区检测，以超越传统结构方法的局限性，并融入语义和上下文信息。论文提出了CommLLM框架，这是一个两步方法，结合GPT-4o和提示工程来融合LLM输出与图结构。通过在六个真实世界数据集上的评估，研究发现LLMs，尤其是在图感知策略和精心设计提示的指导下，能有效提升中小规模图社区检测的准确性和连贯性，凸显了LLMs在图数据研究中的巨大潜力。", "keywords": "社区检测, 大型语言模型, 社交网络图, 提示工程, 图感知策略", "comments": "该论文创新性地将大型语言模型的语义理解能力引入到传统的图社区检测任务中，弥补了现有方法仅关注结构属性的不足。CommLLM框架的提出以及对图感知策略和提示工程重要性的强调是其主要贡献。这为图分析领域开辟了新的研究方向，尽管其当前应用可能主要集中于中小规模图。"}}
{"id": "2507.23340", "title": "MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting", "authors": ["Xingyue Peng", "Yuandong Lyu", "Lang Zhang", "Jian Zhu", "Songtao Wang", "Jiaxin Deng", "Songxin Lu", "Weiliang Ma", "Dangen She", "Peng Jia", "XianPeng Lang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23340v1", "summary": "Road surface reconstruction is essential for autonomous driving, supporting\ncentimeter-accurate lane perception and high-definition mapping in complex\nurban environments.While recent methods based on mesh rendering or 3D Gaussian\nsplatting (3DGS) achieve promising results under clean and static conditions,\nthey remain vulnerable to occlusions from dynamic agents, visual clutter from\nstatic obstacles, and appearance degradation caused by lighting and weather\nchanges. We present a robust reconstruction framework that integrates\nocclusion-aware 2D Gaussian surfels with semantic-guided color enhancement to\nrecover clean, consistent road surfaces. Our method leverages a planar-adapted\nGaussian representation for efficient large-scale modeling, employs\nsegmentation-guided video inpainting to remove both dynamic and static\nforeground objects, and enhances color coherence via semantic-aware correction\nin HSV space. Extensive experiments on urban-scale datasets demonstrate that\nour framework produces visually coherent and geometrically faithful\nreconstructions, significantly outperforming prior methods under real-world\nconditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23340v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MagicRoad：通过障碍物修复实现的语义感知三维路面重建", "tldr": "MagicRoad提出了一种鲁棒的框架，通过结合遮挡感知的2D高斯曲面元和语义引导的色彩增强，解决了现有方法在复杂城市环境中进行路面重建时易受遮挡和视觉混乱影响的问题，并在真实世界条件下显著优于现有方法。", "motivation": "路面重建对于自动驾驶至关重要，支持厘米级车道感知和高精度地图。然而，现有的基于网格渲染或3D高斯泼溅的方法在干净和静态条件下表现良好，但在动态物体遮挡、静态障碍物视觉混乱以及光照和天气变化导致的外观退化面前仍然脆弱。", "method": "我们提出了一个鲁棒的重建框架，该框架集成了遮挡感知的2D高斯曲面元和语义引导的色彩增强，以恢复干净、一致的路面。我们的方法利用平面适应的高斯表示进行高效的大规模建模，采用分割引导的视频修复来移除动态和静态前景物体，并通过HSV空间中的语义感知校正增强色彩一致性。", "result": "在城市规模数据集上的大量实验表明，我们的框架生成了视觉连贯且几何忠实的路面重建结果，在真实世界条件下显著优于现有方法。", "conclusion": "该论文成功提出了一个鲁棒的框架MagicRoad，通过创新的技术组合，有效解决了复杂城市环境中路面重建面临的遮挡、混乱和外观退化问题，实现了高质量的3D路面重建，并证明其在实际应用中的优越性。", "translation": "路面重建对于自动驾驶至关重要，支持在复杂城市环境中厘米级的车道感知和高精度地图。尽管近期基于网格渲染或3D高斯泼溅（3DGS）的方法在干净和静态条件下取得了有希望的结果，但它们仍然容易受到动态代理的遮挡、静态障碍物的视觉混乱以及光照和天气变化导致的外观退化。我们提出了一个鲁棒的重建框架，该框架集成了遮挡感知的2D高斯曲面元和语义引导的色彩增强，以恢复干净、一致的路面。我们的方法利用平面适应的高斯表示进行高效的大规模建模，采用分割引导的视频修复来移除动态和静态前景物体，并通过HSV空间中的语义感知校正增强色彩一致性。在城市规模数据集上的大量实验表明，我们的框架生成了视觉连贯且几何忠实的路面重建结果，在真实世界条件下显著优于现有方法。", "summary": "MagicRoad是一个用于3D路面重建的框架，旨在解决现有方法在复杂城市环境中受遮挡和视觉混乱影响的问题。它结合了遮挡感知的2D高斯曲面元和语义引导的色彩增强，利用平面适应的高斯表示、分割引导的视频修复来移除障碍物，并通过语义感知校正增强色彩。实验证明，该方法在真实世界条件下能生成高质量的路面重建，并优于现有方法。", "keywords": "路面重建, 自动驾驶, 障碍物修复, 3D高斯曲面元, 语义感知", "comments": "该论文的创新点在于其集成框架，巧妙地将2D高斯曲面元与语义引导的修复和色彩增强相结合，有效解决了路面重建中动态和静态障碍物带来的挑战。这种方法显著提升了在复杂真实世界场景下路面重建的鲁棒性和准确性，对于自动驾驶领域的高精地图和感知具有重要意义。"}}
{"id": "2409.19490", "title": "KineDepth: Utilizing Robot Kinematics for Online Metric Depth Estimation", "authors": ["Soofiyan Atar", "Yuheng Zhi", "Florian Richter", "Michael Yip"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2409.19490v2", "summary": "Depth perception is essential for a robot's spatial and geometric\nunderstanding of its environment, with many tasks traditionally relying on\nhardware-based depth sensors like RGB-D or stereo cameras. However, these\nsensors face practical limitations, including issues with transparent and\nreflective objects, high costs, calibration complexity, spatial and energy\nconstraints, and increased failure rates in compound systems. While monocular\ndepth estimation methods offer a cost-effective and simpler alternative, their\nadoption in robotics is limited due to their output of relative rather than\nmetric depth, which is crucial for robotics applications. In this paper, we\npropose a method that utilizes a single calibrated camera, enabling the robot\nto act as a \"measuring stick\" to convert relative depth estimates into metric\ndepth in real-time as tasks are performed. Our approach employs an LSTM-based\nmetric depth regressor, trained online and refined through probabilistic\nfiltering, to accurately restore the metric depth across the monocular depth\nmap, particularly in areas proximal to the robot's motion. Experiments with\nreal robots demonstrate that our method significantly outperforms current\nstate-of-the-art monocular metric depth estimation techniques, achieving a\n22.1% reduction in depth error and a 52% increase in success rate for a\ndownstream task.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2409.19490v2", "cate": "cs.RO", "date": "2024-09-29", "updated": "2025-07-31", "AI": {"title_translation": "KineDepth：利用机器人运动学进行在线度量深度估计", "tldr": "KineDepth提出了一种利用机器人运动学将单目相对深度估计转换为在线度量深度的方法，显著优于现有技术。", "motivation": "传统深度传感器存在成本高、校准复杂、对透明/反射物体处理不佳等问题；而现有的单目深度估计方法虽然成本低，但输出的是相对深度而非机器人应用所需的度量深度，限制了其在机器人领域的应用。", "method": "本文提出了一种利用单个校准相机的方法，使机器人能够充当“测量尺”，实时将相对深度估计转换为度量深度。该方法采用基于LSTM的度量深度回归器，在线训练并通过概率滤波进行细化，以准确恢复单目深度图中的度量深度，尤其是在机器人运动附近的区域。", "result": "真实机器人实验表明，该方法显著优于当前最先进的单目度量深度估计技术，深度误差降低了22.1%，下游任务成功率提高了52%。", "conclusion": "KineDepth通过巧妙利用机器人运动学，有效解决了单目深度估计在机器人应用中缺乏度量深度的问题，显著提升了深度估计的准确性和下游任务的成功率。", "translation": "深度感知对于机器人对其环境的空间和几何理解至关重要，许多任务传统上依赖于RGB-D或立体相机等基于硬件的深度传感器。然而，这些传感器面临实际限制，包括透明和反射物体的问题、高成本、校准复杂性、空间和能量限制以及复合系统中故障率增加。虽然单目深度估计方法提供了一种经济高效且更简单的替代方案，但由于其输出的是相对深度而非度量深度（这对于机器人应用至关重要），因此在机器人领域的应用受到限制。在本文中，我们提出了一种利用单个校准相机的方法，使机器人能够充当“测量尺”，在执行任务时实时将相对深度估计转换为度量深度。我们的方法采用基于LSTM的度量深度回归器，在线训练并通过概率滤波进行细化，以准确恢复单目深度图中的度量深度，特别是在机器人运动附近的区域。真实机器人实验表明，我们的方法显著优于当前最先进的单目度量深度估计技术，深度误差降低了22.1%，下游任务成功率提高了52%。", "summary": "本文提出了KineDepth，一种新颖的单目度量深度估计方法，旨在解决传统深度传感器和现有单目方法在机器人应用中的局限性。通过利用机器人自身的运动学作为“测量尺”，KineDepth能将单目相机捕获的相对深度实时转换为精确的度量深度。该方法采用在线训练的LSTM回归器并结合概率滤波进行优化。实验结果表明，KineDepth在深度估计精度和下游任务成功率方面均显著超越了现有技术。", "keywords": "机器人运动学, 单目深度估计, 度量深度, 在线学习, 深度感知", "comments": "这篇论文的创新点在于巧妙地利用了机器人自身的运动学信息，将单目深度估计从相对深度提升到度量深度，克服了传统单目方法的局限性。这种方法不仅成本效益高，而且在实际机器人应用中表现出显著的性能提升，对于需要精确空间感知的机器人任务具有重要意义。"}}
{"id": "2507.22943", "title": "A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies", "authors": ["Shirley V Wang", "Georg Hahn", "Sushama Kattinakere Sreedhara", "Mufaddal Mahesri", "Haritha S. Pillai", "Rajendra Aldis", "Joyce Lii", "Sarah K. Dutcher", "Rhoda Eniafe", "Jamal T. Jones", "Keewan Kim", "Jiwei He", "Hana Lee", "Sengwee Toh", "Rishi J Desai", "Jie Yang"], "categories": ["cs.CL", "stat.ME"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22943v1", "summary": "Background: One of the ways to enhance analyses conducted with large claims\ndatabases is by validating the measurement characteristics of code-based\nalgorithms used to identify health outcomes or other key study parameters of\ninterest. These metrics can be used in quantitative bias analyses to assess the\nrobustness of results for an inferential study given potential bias from\noutcome misclassification. However, extensive time and resource allocation are\ntypically re-quired to create reference-standard labels through manual chart\nreview of free-text notes from linked electronic health records. Methods: We\ndescribe an expedited process that introduces efficiency in a validation study\nus-ing two distinct mechanisms: 1) use of natural language processing (NLP) to\nreduce time spent by human reviewers to review each chart, and 2) a multi-wave\nadaptive sampling approach with pre-defined criteria to stop the validation\nstudy once performance characteristics are identified with sufficient\nprecision. We illustrate this process in a case study that validates the\nperformance of a claims-based outcome algorithm for intentional self-harm in\npatients with obesity. Results: We empirically demonstrate that the\nNLP-assisted annotation process reduced the time spent on review per chart by\n40% and use of the pre-defined stopping rule with multi-wave samples would have\nprevented review of 77% of patient charts with limited compromise to precision\nin derived measurement characteristics. Conclusion: This approach could\nfacilitate more routine validation of code-based algorithms used to define key\nstudy parameters, ultimately enhancing understanding of the reliability of\nfind-ings derived from database studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22943v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25", "AI": {"title_translation": "一种借助自然语言处理和多波自适应抽样加速大型数据库研究中基于代码算法验证的图表审查过程", "tldr": "本研究提出了一种结合自然语言处理和多波自适应抽样的方法，以显著加快基于代码算法的验证过程，减少人工审查时间和资源消耗。", "motivation": "在大规模索赔数据库分析中，验证用于识别健康结果或关键研究参数的基于代码算法的测量特性对于评估结果的稳健性至关重要。然而，通过人工审查电子健康记录中的自由文本笔记来创建参考标准标签通常需要大量时间和资源。", "method": "本研究描述了一种加速验证过程，通过两种机制提高效率：1) 使用自然语言处理（NLP）减少人工审查每张图表的时间；2) 采用具有预定义停止标准的多波自适应抽样方法，一旦性能特征达到足够的精度就停止验证研究。该过程在一个验证肥胖患者故意自伤索赔结果算法的案例研究中进行了说明。", "result": "实证结果表明，NLP辅助的标注过程使每张图表的审查时间减少了40%。此外，使用预定义的停止规则与多波样本相结合，可以在对导出测量特征精度影响有限的情况下，避免审查77%的患者图表。", "conclusion": "这种方法可以促进对用于定义关键研究参数的基于代码算法进行更常规的验证，最终增强对数据库研究结果可靠性的理解。", "translation": "背景：通过验证用于识别健康结果或其他关键研究参数的基于代码算法的测量特性，是增强大型索赔数据库分析方法之一。这些指标可用于定量偏差分析，以评估推断性研究结果在潜在结果错误分类偏差下的稳健性。然而，通过人工审查链接电子健康记录中的自由文本笔记来创建参考标准标签，通常需要大量时间和资源。方法：我们描述了一种加速过程，通过两种独特的机制在验证研究中引入效率：1）使用自然语言处理（NLP）来减少人工审查员审查每张图表所花费的时间；2）采用具有预定义标准的多波自适应抽样方法，一旦性能特征以足够的精度识别出来，就停止验证研究。我们在一个案例研究中说明了这一过程，该案例研究验证了肥胖患者故意自伤索赔结果算法的性能。结果：我们通过实证证明，NLP辅助的注释过程使每张图表的审查时间减少了40%，并且使用预定义的停止规则与多波样本相结合，可以在对导出测量特征精度影响有限的情况下，避免审查77%的患者图表。结论：这种方法可以促进对用于定义关键研究参数的基于代码算法进行更常规的验证，最终增强对数据库研究结果可靠性的理解。", "summary": "本研究提出了一种高效的图表审查流程，旨在加速大型索赔数据库中基于代码算法的验证。该流程结合了自然语言处理（NLP）以减少人工审查时间，以及多波自适应抽样与预定义停止规则，以在达到足够精度时提前终止研究。在一个验证自伤算法的案例研究中，该方法成功将审查时间缩短40%，并避免了77%的图表审查，同时保持了精度。这有助于更常规地验证算法，从而提高数据库研究结果的可靠性。", "keywords": "自然语言处理, 自适应抽样, 代码算法验证, 图表审查, 大型数据库", "comments": "本论文的创新之处在于将自然语言处理与多波自适应抽样相结合，为大型数据库中基于代码算法的验证提供了一个高效且资源节约的解决方案。其重要性在于，通过加速验证过程，能够促进对数据分析结果可靠性的更深入理解，这对于临床研究和公共卫生决策具有重要意义。该方法有效解决了传统人工审查耗时耗力的问题，有望在实际应用中推广。"}}
{"id": "2506.03956", "title": "Adapt before Continual Learning", "authors": ["Aojun Lu", "Tao Feng", "Hangjie Yuan", "Chunhui Ding", "Yanan Sun"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.03956v3", "summary": "Continual Learning (CL) seeks to enable neural networks to incrementally\nacquire new knowledge (plasticity) while retaining existing knowledge\n(stability). Although pre-trained models (PTMs) have provided a strong\nfoundation for CL, existing approaches face a fundamental challenge in\nbalancing these two competing objectives. Current methods typically address\nstability by freezing the PTM backbone, which severely limits the model's\nplasticity, particularly when incoming data distribution diverges largely from\nthe pre-training data. Alternatively, sequentially fine-tuning the entire PTM\ncan adapt to new knowledge but often leads to catastrophic forgetting,\nhighlighting the critical stability-plasticity trade-off in PTM-based CL. To\naddress this limitation, we propose Adapting PTMs before the core CL} process\n(ACL), a novel framework that introduces a plug-and-play adaptation phase prior\nto learning each new task. During this phase, ACL refines the PTM backbone by\naligning embeddings with their original class prototypes while distancing them\nfrom irrelevant classes. This mechanism theoretically and empirically\ndemonstrates desirable balance between stability and plasticity, significantly\nimproving CL performance across benchmarks and integrated methods. Code is\navailable at https://github.com/byyx666/ACL_code.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.03956v3", "cate": "cs.LG", "date": "2025-06-04", "updated": "2025-07-31", "AI": {"title_translation": "持续学习前先适应", "tldr": "本文提出了ACL框架，通过在持续学习前引入一个适应阶段来平衡预训练模型在持续学习中的稳定性和可塑性，显著提高了性能。", "motivation": "现有基于预训练模型的持续学习方法在平衡知识获取（可塑性）和知识保留（稳定性）方面面临挑战。冻结预训练模型主干限制了可塑性，而顺序微调整个模型则导致灾难性遗忘。", "method": "我们提出了一个名为ACL（Adapting PTMs before the core CL process）的新框架。它在学习每个新任务之前引入一个可插拔的适应阶段。在此阶段，ACL通过将嵌入与其原始类别原型对齐并使其远离不相关类别来优化预训练模型主干。", "result": "该机制在理论和经验上都证明了在稳定性和可塑性之间取得了理想的平衡，显著提高了持续学习在基准测试和集成方法上的性能。", "conclusion": "ACL框架通过在持续学习前引入适应阶段，有效解决了预训练模型在持续学习中稳定性与可塑性之间的权衡问题，从而显著提升了持续学习的表现。", "translation": "持续学习（CL）旨在使神经网络在增量获取新知识（可塑性）的同时保留现有知识（稳定性）。尽管预训练模型（PTM）为CL提供了坚实的基础，但现有方法在平衡这两个相互竞争的目标方面面临根本性挑战。当前方法通常通过冻结PTM主干来解决稳定性问题，这严重限制了模型的可塑性，特别是当输入数据分布与预训练数据差异很大时。或者，顺序微调整个PTM可以适应新知识，但常常导致灾难性遗忘，这突出了基于PTM的CL中关键的稳定性-可塑性权衡。为了解决这一限制，我们提出了在核心CL过程之前适应PTM（ACL），这是一个新颖的框架，在学习每个新任务之前引入了一个即插即用的适应阶段。在此阶段，ACL通过将嵌入与其原始类别原型对齐，同时使其远离不相关类别来优化PTM主干。该机制在理论和经验上都证明了在稳定性和可塑性之间取得了理想的平衡，显著提高了CL在基准测试和集成方法上的性能。代码可在https://github.com/byyx666/ACL_code获取。", "summary": "本文提出ACL（Adapt before Continual Learning）框架，旨在解决基于预训练模型（PTM）的持续学习中稳定性与可塑性之间的权衡问题。ACL在学习新任务前引入一个适应阶段，通过对齐嵌入与原始类别原型并远离不相关类别来优化PTM主干。该方法在理论和实践中均展现出良好的平衡性，显著提升了持续学习的性能。", "keywords": "持续学习, 预训练模型, 稳定性-可塑性权衡, 模型适应, 灾难性遗忘", "comments": "该论文提出了一种新颖的“先适应再学习”的策略，创新性地在持续学习流程前引入预适应阶段，以更好地利用预训练模型并解决稳定性与可塑性之间的固有矛盾。其即插即用的特性也增加了方法的通用性。"}}
{"id": "2507.23726", "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "authors": ["Luoxin Chen", "Jinming Gu", "Liankai Huang", "Wenhao Huang", "Zhicheng Jiang", "Allan Jie", "Xiaoran Jin", "Xing Jin", "Chenggang Li", "Kaijing Ma", "Cheng Ren", "Jiawei Shen", "Wenlei Shi", "Tong Sun", "He Sun", "Jiahui Wang", "Siran Wang", "Zhihong Wang", "Chenrui Wei", "Shufa Wei", "Yonghui Wu", "Yuchen Wu", "Yihang Xia", "Huajian Xin", "Fan Yang", "Huaiyuan Ying", "Hongyi Yuan", "Zheng Yuan", "Tianyang Zhan", "Chi Zhang", "Yue Zhang", "Ge Zhang", "Tianyun Zhao", "Jianqiu Zhao", "Yichi Zhou", "Thomas Hanwen Zhu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23726v1", "summary": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23726v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Seed-Prover：深度与广度推理在自动化定理证明中的应用", "tldr": "Seed-Prover模型利用Lean反馈和迭代细化，结合深度和广度推理策略，显著提升了自动化定理证明能力，并在多项基准测试中超越现有最佳水平。", "motivation": "尽管大型语言模型（LLMs）在数学推理方面表现出强大能力，但由于缺乏清晰的监督信号，它们在定理证明方面仍面临困难。", "method": "提出Seed-Prover，一个引理式的全证明推理模型。它通过Lean反馈、已证明的引理和自我总结来迭代细化证明。为解决IMO级别竞赛问题，设计了三种测试时推理策略以实现深度和广度推理。此外，引入了几何推理引擎Seed-Geometry以弥补Lean在几何支持方面的不足。", "result": "Seed-Prover证明了78.1%的IMO形式化问题，在MiniF2F上达到饱和，并在PutnamBench上取得超过50%的成绩，大幅超越现有最佳水平。Seed-Geometry在形式化几何引擎中表现优异。利用这两个系统在IMO 2025中完全证明了6个问题中的5个。", "conclusion": "这项工作代表了自动化数学推理的重大进展，证明了形式化验证与长链式思维推理的有效性。", "translation": "大型语言模型（LLMs）通过利用强化学习和长链式思维，展示了强大的数学推理能力，但由于在纯粹使用自然语言时缺乏明确的监督信号，它们在定理证明方面仍然面临困难。像Lean这样的专用领域特定语言通过对证明进行形式化验证提供了清晰的监督，从而能够通过强化学习进行有效训练。在这项工作中，我们提出了\\textbf{Seed-Prover}，一个引理式的全证明推理模型。Seed-Prover可以根据Lean的反馈、已证明的引理和自我总结来迭代地细化其证明。为了解决IMO级别竞赛问题，我们设计了三种测试时推理策略，以实现深度和广度推理。Seed-Prover证明了78.1%的IMO形式化问题，在MiniF2F上达到饱和，并在PutnamBench上取得了超过50%的成绩，大幅超越了之前的最新技术水平。为了解决Lean中缺乏几何支持的问题，我们引入了几何推理引擎\\textbf{Seed-Geometry}，其性能优于之前的形式化几何引擎。我们使用这两个系统参加了IMO 2025，并完全证明了6个问题中的5个。这项工作代表了自动化数学推理的重大进展，证明了形式化验证与长链式思维推理的有效性。", "summary": "本文提出了Seed-Prover，一个用于自动化定理证明的引理式全证明推理模型。该模型利用Lean的形式化验证反馈、已证明引理和自我总结进行迭代细化，并设计了深度和广度推理策略。Seed-Prover在IMO、MiniF2F和PutnamBench等多个基准测试中取得了显著优于现有最佳水平的成果。为解决Lean对几何支持的不足，还引入了Seed-Geometry几何推理引擎。该工作表明形式化验证结合长链式思维推理能有效推动自动化数学推理发展。", "keywords": "自动化定理证明, 形式化验证, 链式思维, 大型语言模型, Lean", "comments": "本文创新性地结合了形式化验证（Lean）的明确监督信号与大型语言模型的长链式思维推理，有效解决了LLMs在定理证明中缺乏监督信号的痛点。Seed-Prover通过迭代细化和多策略推理，在多个高难度数学竞赛问题上取得了突破性进展，尤其是其在IMO 2025中的表现，展示了其在实际复杂问题解决中的强大潜力。Seed-Geometry的引入也弥补了现有工具的不足，进一步拓宽了自动化证明的领域。"}}
{"id": "2507.23428", "title": "Merging Memory and Space: A Spatiotemporal State Space Neural Operator", "authors": ["Nodens F. Koren", "Samuel Lanthaler"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23428v1", "summary": "We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact\narchitecture for learning solution operators of time-dependent partial\ndifferential equations (PDEs). ST-SSM introduces a novel factorization of the\nspatial and temporal dimensions, using structured state-space models to\nindependently model temporal evolution and spatial interactions. This design\nenables parameter efficiency and flexible modeling of long-range spatiotemporal\ndynamics. A theoretical connection is established between SSMs and neural\noperators, and a unified universality theorem is proved for the resulting class\nof architectures. Empirically, we demonstrate that our factorized formulation\noutperforms alternative schemes such as zigzag scanning and parallel\nindependent processing on several PDE benchmarks, including 1D Burgers'\nequation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations\nunder varying physical conditions. Our model performs competitively with\nexisting baselines while using significantly fewer parameters. In addition, our\nresults reinforce previous findings on the benefits of temporal memory by\nshowing improved performance under partial observability. Our results highlight\nthe advantages of dimensionally factorized operator learning for efficient and\ngeneralizable PDE modeling, and put this approach on a firm theoretical\nfooting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23428v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "融合记忆与空间：一种时空状态空间神经算子", "tldr": "提出了一种名为ST-SSM的新型时空状态空间神经算子，通过对时空维度进行因子化建模，实现了高效且通用的偏微分方程（PDE）求解，并在多个PDE基准测试中表现出色，参数量显著减少，并提供了坚实的理论基础。", "motivation": "为了有效学习时间依赖性偏微分方程（PDE）的解算子，并解决现有方法在参数效率和长程时空动力学建模方面的不足。", "method": "本文提出了时空状态空间神经算子（ST-SSM），这是一种紧凑的架构，通过结构化状态空间模型独立建模时间演化和空间相互作用，实现了时空维度的创新性因子化。该方法建立了SSM与神经算子之间的理论联系，并证明了其普适性定理。", "result": "ST-SSM在多个PDE基准测试（包括1D Burgers方程、1D Kuramoto-Sivashinsky方程和2D Navier-Stokes方程）中，其因子化公式优于之字形扫描和并行独立处理等替代方案。该模型在参数量显著减少的情况下，性能与现有基线相当。此外，在部分可观测性下，模型性能的提升也印证了时间记忆的益处。", "conclusion": "维度因子化的算子学习对于高效且可推广的PDE建模具有显著优势，并且ST-SSM方法在理论上具有坚实的基础。", "translation": "我们提出了时空状态空间神经算子（ST-SSM），这是一种用于学习时间依赖性偏微分方程（PDEs）解算子的紧凑架构。ST-SSM引入了一种新颖的空间和时间维度因子化方法，利用结构化状态空间模型独立地建模时间演化和空间相互作用。这种设计实现了参数效率和长程时空动力学的灵活建模。本文建立了SSM与神经算子之间的理论联系，并为由此产生的架构类别证明了一个统一的普适性定理。经验上，我们证明了我们的因子化公式在多个PDE基准测试中（包括1D Burgers方程、1D Kuramoto-Sivashinsky方程和2D Navier-Stokes方程在不同物理条件下）优于之字形扫描和并行独立处理等替代方案。我们的模型在参数量显著减少的情况下，性能与现有基线相当。此外，我们的结果通过显示在部分可观测性下的改进性能，强化了之前关于时间记忆益处的发现。我们的结果强调了维度因子化算子学习在高效和可推广PDE建模中的优势，并为这种方法奠定了坚实的理论基础。", "summary": "本文提出了一种名为时空状态空间神经算子（ST-SSM）的紧凑架构，用于学习时间依赖性偏微分方程（PDE）的解算子。ST-SSM通过对时空维度进行新颖的因子化，利用结构化状态空间模型独立建模时间演化和空间相互作用，从而实现参数效率和长程时空动力学的灵活建模。该研究建立了SSM与神经算子之间的理论联系，并证明了所提出架构类的统一普适性定理。实验结果表明，在多个PDE基准测试中，ST-SSM的因子化公式优于其他方案，且在参数量显著减少的情况下，性能与现有基线相当。研究强调了维度因子化算子学习在高效和可推广PDE建模中的优势，并为其提供了坚实的理论基础。", "keywords": "时空状态空间模型, 神经算子, 偏微分方程, 维度因子化, 参数效率", "comments": "ST-SSM的创新之处在于其对时空维度的因子化处理，以及将结构化状态空间模型（SSM）与神经算子相结合。这种设计不仅提高了参数效率，还增强了模型对长程时空动力学的建模能力。理论上的普适性证明进一步巩固了其重要性，而经验结果则验证了其在多个PDE问题上的优越性能和参数效率，为PDE建模领域提供了一个有前景的新方向。"}}
{"id": "2507.23489", "title": "Distributionally Robust Cascading Risk Quantification in Multi-Agent Rendezvous: Effects of Time Delay and Network Connectivity", "authors": ["Vivek Pandey", "Nader Motee"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23489v1", "summary": "Achieving safety in autonomous multi-agent systems, particularly in\ntime-critical tasks like rendezvous, is a critical challenge. In this paper, we\npropose a distributionally robust risk framework for analyzing cascading\nfailures in multi-agent rendezvous. To capture the complex interactions between\nnetwork connectivity, system dynamics, and communication delays, we use a\ntime-delayed network model as a benchmark. We introduce a conditional\ndistributionally robust functional to quantify cascading effects between\nagents, utilizing a bi-variate normal distribution. Our approach yields\nclosed-form risk expressions that reveal the impact of time delay, noise\nstatistics, communication topology, and failure modes on rendezvous risk. The\ninsights derived inform the design of resilient networks that mitigate the risk\nof cascading failures. We validate our theoretical results through extensive\nsimulations, demonstrating the effectiveness of our framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23489v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多智能体交会中分布鲁棒级联风险量化：时间延迟和网络连通性的影响", "tldr": "本文提出了一个分布鲁棒风险框架，用于分析多智能体交会中的级联故障，考虑时间延迟和网络连通性的影响，并得到了封闭形式的风险表达式。", "motivation": "在自主多智能体系统中实现安全，特别是在交会等时间关键任务中，是一个严峻的挑战。", "method": "本文提出了一个分布鲁棒风险框架，用于分析多智能体交会中的级联故障。研究人员使用时间延迟网络模型作为基准，引入了一个条件分布鲁棒泛函，利用双变量正态分布来量化智能体之间的级联效应。", "result": "该方法得到了封闭形式的风险表达式，揭示了时间延迟、噪声统计、通信拓扑和故障模式对交会风险的影响。通过广泛的仿真验证了理论结果，证明了该框架的有效性。", "conclusion": "本文的见解有助于设计能够减轻级联故障风险的弹性网络。所提出的框架在仿真中得到了有效验证。", "translation": "在自主多智能体系统中实现安全，特别是在交会等时间关键任务中，是一个严峻的挑战。在本文中，我们提出了一个分布鲁棒风险框架，用于分析多智能体交会中的级联故障。为了捕捉网络连通性、系统动力学和通信延迟之间的复杂相互作用，我们使用时间延迟网络模型作为基准。我们引入了一个条件分布鲁棒泛函，利用双变量正态分布来量化智能体之间的级联效应。我们的方法得到了封闭形式的风险表达式，揭示了时间延迟、噪声统计、通信拓扑和故障模式对交会风险的影响。由此得出的见解有助于设计能够减轻级联故障风险的弹性网络。我们通过广泛的仿真验证了我们的理论结果，证明了我们框架的有效性。", "summary": "本文针对多智能体系统在时间关键任务（如交会）中的安全挑战，提出了一个分布鲁棒风险框架，以分析级联故障。该框架利用时间延迟网络模型和条件分布鲁棒泛函，结合双变量正态分布，量化了智能体间的级联效应。研究得出了封闭形式的风险表达式，揭示了时间延迟、噪声、拓扑和故障模式对交会风险的影响。这些发现为设计弹性网络以减轻级联故障风险提供了指导，并通过仿真验证了该框架的有效性。", "keywords": "分布鲁棒, 级联风险, 多智能体系统, 时间延迟, 网络连通性", "comments": "本文的创新之处在于引入了分布鲁棒风险框架来量化多智能体交会中的级联故障，并考虑了时间延迟和网络连通性的影响。通过推导出封闭形式的风险表达式，该研究提供了对系统参数如何影响风险的深刻见解，这对于设计更安全的自主系统至关重要。其重要性体现在为实际应用中复杂多智能体系统的风险管理和弹性网络设计提供了理论基础和实用工具。"}}
{"id": "2507.23364", "title": "Holistic Evaluations of Topic Models", "authors": ["Thomas Compton"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      10 pages, 6 tables", "url": "http://arxiv.org/abs/2507.23364v1", "summary": "Topic models are gaining increasing commercial and academic interest for\ntheir ability to summarize large volumes of unstructured text. As unsupervised\nmachine learning methods, they enable researchers to explore data and help\ngeneral users understand key themes in large text collections. However, they\nrisk becoming a 'black box', where users input data and accept the output as an\naccurate summary without scrutiny. This article evaluates topic models from a\ndatabase perspective, drawing insights from 1140 BERTopic model runs. The goal\nis to identify trade-offs in optimizing model parameters and to reflect on what\nthese findings mean for the interpretation and responsible use of topic models", "comment": "10 pages, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.23364v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "主题模型的整体评估", "tldr": "本文从数据库角度评估主题模型，通过1140次BERTopic模型运行，旨在识别优化模型参数时的权衡，并探讨其对主题模型解释和负责任使用的意义，以避免其成为“黑箱”。", "motivation": "主题模型因其摘要大量非结构化文本的能力而受到关注，但存在成为“黑箱”的风险，用户可能不加审查地接受其输出。因此，需要对主题模型进行评估。", "method": "本文从数据库角度评估主题模型，并从1140次BERTopic模型运行中获取洞察。", "result": "结果旨在识别优化模型参数时的权衡。", "conclusion": "这些发现有助于理解主题模型的解释和负责任使用。", "translation": "主题模型因其能够总结大量非结构化文本而受到越来越多的商业和学术关注。作为无监督机器学习方法，它们使研究人员能够探索数据，并帮助普通用户理解大型文本集合中的关键主题。然而，它们有沦为“黑箱”的风险，用户输入数据并接受输出作为准确的摘要而没有经过审查。本文从数据库的角度评估主题模型，从1140次BERTopic模型运行中获取见解。目标是识别优化模型参数时的权衡，并反思这些发现对于主题模型的解释和负责任使用意味着什么。", "summary": "本文旨在解决主题模型可能成为“黑箱”的问题，通过从数据库角度对主题模型进行整体评估。研究利用1140次BERTopic模型运行的数据，以识别在优化模型参数时存在的权衡，并探讨这些发现如何影响主题模型的解释和负责任的使用。", "keywords": "主题模型, BERTopic, 模型评估, 参数优化, 黑箱问题", "comments": "这篇论文的重要性在于它关注了主题模型在实际应用中可能面临的“黑箱”问题，强调了对其输出进行审查的必要性。通过大规模的模型运行（1140次BERTopic），它提供了一个系统性的评估方法，有助于用户更好地理解和负责任地使用这些工具。其创新点在于从数据库视角进行评估，这可能为未来的模型评估提供新的框架。"}}
{"id": "2412.06458", "title": "Pruning All-Rounder: Rethinking and Improving Inference Efficiency for Large Vision Language Models", "authors": ["Wei Suo", "Ji Ma", "Mengyang Sun", "Lin Yuanbo Wu", "Peng Wang", "Yanning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 25", "url": "http://arxiv.org/abs/2412.06458v2", "summary": "Although Large Vision-Language Models (LVLMs) have achieved impressive\nresults, their high computational costs pose a significant barrier to wide\napplication. To enhance inference efficiency, most existing approaches can be\ncategorized as parameter-dependent or token-dependent strategies to reduce\ncomputational demands. However, parameter-dependent methods require retraining\nLVLMs to recover performance while token-dependent strategies struggle to\nconsistently select the most relevant tokens. In this paper, we systematically\nanalyze the above challenges and provide a series of valuable insights for\ninference acceleration. Based on these findings, we propose a novel framework,\nthe Pruning All-Rounder (PAR). Different from previous works, PAR develops a\nmeta-router to adaptively organize pruning flows across both tokens and layers.\nWith a self-supervised learning manner, our method achieves a superior balance\nbetween performance and efficiency. Notably, PAR is highly flexible, offering\nmultiple pruning versions to address a range of acceleration scenarios. The\ncode for this work is publicly available at\nhttps://github.com/ASGO-MM/Pruning-All-Rounder.", "comment": "Accepted by ICCV 25", "pdf_url": "http://arxiv.org/pdf/2412.06458v2", "cate": "cs.CV", "date": "2024-12-09", "updated": "2025-07-31", "AI": {"title_translation": "剪枝全能手：重新思考并提升大型视觉语言模型的推理效率", "tldr": "本文提出PAR框架，通过自适应剪枝token和层来提升大型视觉语言模型的推理效率，在性能和效率之间取得平衡。", "motivation": "大型视觉语言模型（LVLMs）计算成本高昂，阻碍了其广泛应用。现有方法（参数依赖或token依赖）存在局限性，需要改进推理效率。", "method": "本文提出了一个名为“Pruning All-Rounder (PAR)”的新型框架。PAR开发了一个元路由器，以自适应地组织跨token和层的剪枝流。该方法采用自监督学习方式。", "result": "PAR在性能和效率之间取得了卓越的平衡。它具有高度灵活性，提供多种剪枝版本以适应不同的加速场景。", "conclusion": "本文提出的PAR框架通过创新的自适应剪枝策略有效解决了大型视觉语言模型推理效率低下的问题，并在性能和效率之间取得了优异的平衡。", "translation": "尽管大型视觉语言模型（LVLMs）取得了令人印象深刻的成果，但其高昂的计算成本严重阻碍了其广泛应用。为了提高推理效率，大多数现有方法可以分为参数依赖型或token依赖型策略，以减少计算需求。然而，参数依赖型方法需要重新训练LVLMs以恢复性能，而token依赖型策略难以始终如一地选择最相关的token。在本文中，我们系统地分析了上述挑战，并为推理加速提供了一系列有价值的见解。基于这些发现，我们提出了一个新颖的框架——剪枝全能手（PAR）。与以往的工作不同，PAR开发了一个元路由器，以自适应地组织跨token和层的剪枝流。通过自监督学习的方式，我们的方法在性能和效率之间取得了卓越的平衡。值得注意的是，PAR具有高度灵活性，提供多种剪枝版本以应对各种加速场景。该工作的代码已在https://github.com/ASGO-MM/Pruning-All-Rounder 公开。", "summary": "本文针对大型视觉语言模型（LVLMs）高计算成本导致的推理效率问题，系统分析了现有参数依赖和token依赖剪枝策略的局限性。在此基础上，提出了一种名为“剪枝全能手（PAR）”的新型框架。PAR通过一个元路由器自适应地协调token和层级的剪枝过程，并采用自监督学习，从而在性能和效率之间实现了优异的平衡，并能灵活适应多种加速需求。", "keywords": "大型视觉语言模型, 推理效率, 模型剪枝, 自适应剪枝, 自监督学习", "comments": "本文的创新点在于提出了一个统一的剪枝框架PAR，通过元路由器实现了对token和层级的自适应剪枝，解决了现有单一剪枝策略的局限性。其自监督学习方式也提高了剪枝的效率和效果。该方法对于推动大型视觉语言模型在实际应用中的部署具有重要意义。"}}
{"id": "2507.23629", "title": "DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching", "authors": ["Yewei Huang", "John McConnell", "Xi Lin", "Brendan Englot"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23629v1", "summary": "We present DRACo-SLAM2, a distributed SLAM framework for underwater robot\nteams equipped with multibeam imaging sonar. This framework improves upon the\noriginal DRACo-SLAM by introducing a novel representation of sonar maps as\nobject graphs and utilizing object graph matching to achieve time-efficient\ninter-robot loop closure detection without relying on prior geometric\ninformation. To better-accommodate the needs and characteristics of underwater\nscan matching, we propose incremental Group-wise Consistent Measurement Set\nMaximization (GCM), a modification of Pairwise Consistent Measurement Set\nMaximization (PCM), which effectively handles scenarios where nearby\ninter-robot loop closures share similar registration errors. The proposed\napproach is validated through extensive comparative analyses on simulated and\nreal-world datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23629v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DRACo-SLAM2：用于配备成像声纳的水下机器人团队的分布式鲁棒声学通信高效SLAM，具有目标图匹配功能", "tldr": "DRACo-SLAM2是一个分布式SLAM框架，通过引入目标图表示和匹配以及改进的GCM算法，实现水下机器人团队高效的声纳地图匹配和回环检测。", "motivation": "该研究旨在改进原始DRACo-SLAM，通过引入新的声纳地图表示和回环检测方法，以提高水下机器人团队在声纳地图匹配中的时间效率，并有效处理相似注册误差。", "method": "该框架将声纳地图表示为目标图，并利用目标图匹配来实现时间高效的机器人间回环检测，无需依赖先验几何信息。此外，提出了增量式群组一致测量集最大化（GCM），作为成对一致测量集最大化（PCM）的修改版，以处理邻近机器人间回环闭合共享相似注册误差的场景。", "result": "所提出的方法通过在模拟和真实世界数据集上的广泛比较分析得到了验证。", "conclusion": "Not mentioned in abstract", "translation": "我们提出了DRACo-SLAM2，一个为配备多波束成像声纳的水下机器人团队设计的分布式SLAM框架。该框架在原始DRACo-SLAM的基础上进行了改进，引入了一种新颖的声纳地图表示方法，即目标图，并利用目标图匹配来实现时间高效的机器人间回环检测，而无需依赖先验几何信息。为了更好地适应水下扫描匹配的需求和特点，我们提出了增量式群组一致测量集最大化（GCM），它是成对一致测量集最大化（PCM）的修改版，可以有效处理邻近机器人间回环闭合共享相似注册误差的场景。所提出的方法通过在模拟和真实世界数据集上的广泛比较分析得到了验证。", "summary": "DRACo-SLAM2是一个针对配备成像声纳的水下机器人团队的分布式SLAM框架。它通过将声纳地图表示为目标图并利用目标图匹配实现高效的机器人间回环检测，无需先验几何信息。此外，该框架引入了增量式GCM算法以更好地处理水下扫描匹配中相似的注册误差。该方法已在模拟和真实数据集上得到验证。", "keywords": "分布式SLAM, 水下机器人, 成像声纳, 目标图匹配, 回环检测", "comments": "这篇论文通过引入目标图表示和匹配，以及改进的GCM算法，显著提升了水下机器人团队在复杂环境中进行SLAM的效率和鲁棒性。其创新点在于无需先验几何信息即可进行高效回环检测，并且能有效处理水下特有的相似注册误差问题，对于水下自主导航和测绘领域具有重要意义。"}}
{"id": "2507.23253", "title": "Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality", "authors": ["Mingyang Yu", "Xiahui Guo", "Peng chen", "Zhenkai Li", "Yang Shu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23253v1", "summary": "Time Series forecasting is critical in diverse domains such as weather\nforecasting, financial investment, and traffic management. While traditional\nnumerical metrics like mean squared error (MSE) can quantify point-wise\naccuracy, they fail to evaluate the geometric structure of time series data,\nwhich is essential to understand temporal dynamics. To address this issue, we\npropose the time series Geometric Structure Index (TGSI), a novel evaluation\nmetric that transforms time series into images to leverage their inherent\ntwo-dimensional geometric representations. However, since the image\ntransformation process is non-differentiable, TGSI cannot be directly\nintegrated as a training loss. We further introduce the Shape-Aware Temporal\nLoss (SATL), a multi-component loss function operating in the time series\nmodality to bridge this gap and enhance structure modeling during training.\nSATL combines three components: a first-order difference loss that measures\nstructural consistency through the MSE between first-order differences, a\nfrequency domain loss that captures essential periodic patterns using the Fast\nFourier Transform while minimizing noise, and a perceptual feature loss that\nmeasures geometric structure difference in time-series by aligning temporal\nfeatures with geometric structure features through a pre-trained temporal\nfeature extractor and time-series image autoencoder. Experiments across\nmultiple datasets demonstrate that models trained with SATL achieve superior\nperformance in both MSE and the proposed TGSI metrics compared to baseline\nmethods, without additional computational cost during inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23253v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "时间序列预测中通过图像模态测量和建模几何结构", "tldr": "提出TGSI评估时间序列几何结构，并引入SATL损失函数在训练中建模结构，实验证明其优于基线方法。", "motivation": "传统时间序列预测的数值指标（如MSE）无法有效评估时间序列数据的几何结构，而几何结构对于理解时间动态至关重要。", "method": "1. 提出时间序列几何结构指数（TGSI），一种新颖的评估指标，通过将时间序列转换为图像来利用其固有的二维几何表示。2. 针对TGSI的不可微问题，引入形状感知时间损失（SATL），一个多组件损失函数，在时间序列模态下运行以增强训练期间的结构建模。3. SATL包含三个组件：一阶差分损失（通过一阶差分MSE衡量结构一致性），频域损失（使用FFT捕获周期模式并最小化噪声），以及感知特征损失（通过预训练的时间特征提取器和时间序列图像自编码器对齐时间特征与几何结构特征来衡量几何结构差异）。", "result": "在多个数据集上的实验表明，使用SATL训练的模型在MSE和所提出的TGSI指标上均优于基线方法，且在推理过程中没有额外计算成本。", "conclusion": "提出的TGSI和SATL有效地解决了时间序列预测中几何结构评估和建模的挑战，并显著提升了模型性能。", "translation": "时间序列预测在天气预报、金融投资和交通管理等不同领域至关重要。虽然均方误差（MSE）等传统数值指标可以量化逐点精度，但它们未能评估时间序列数据的几何结构，而这对于理解时间动态至关重要。为了解决这个问题，我们提出了时间序列几何结构指数（TGSI），这是一种新颖的评估指标，它将时间序列转换为图像，以利用其固有的二维几何表示。然而，由于图像转换过程是不可微的，TGSI不能直接作为训练损失集成。我们进一步引入了形状感知时间损失（SATL），一个在时间序列模态下运行的多组件损失函数，以弥补这一差距并在训练期间增强结构建模。SATL结合了三个组件：一个一阶差分损失，通过一阶差分之间的MSE衡量结构一致性；一个频域损失，利用快速傅里叶变换捕获重要的周期模式同时最小化噪声；以及一个感知特征损失，通过预训练的时间特征提取器和时间序列图像自编码器将时间特征与几何结构特征对齐，从而衡量时间序列中的几何结构差异。跨多个数据集的实验表明，与基线方法相比，使用SATL训练的模型在MSE和所提出的TGSI指标上均取得了卓越的性能，并且在推理过程中没有额外的计算成本。", "summary": "该论文提出时间序列预测中对几何结构进行测量和建模的新方法。针对传统指标无法评估几何结构的问题，引入了时间序列几何结构指数（TGSI）作为新的评估指标，通过图像转换捕捉几何特征。为了在训练中利用几何结构信息，提出形状感知时间损失（SATL），该损失函数包含一阶差分损失、频域损失和感知特征损失，以在时间序列模态下增强结构建模。实验证明，SATL训练的模型在精度和几何结构评估上均优于现有方法，且不增加推理成本。", "keywords": "时间序列预测, 几何结构, 图像模态, 评估指标, 损失函数", "comments": "该论文的创新点在于认识到传统时间序列预测指标对几何结构评估的不足，并提出了两个关键贡献：首先是引入TGSI，一个将时间序列转换为图像以评估几何结构的新颖指标；其次是开发了SATL，一个多组件损失函数，解决了TGSI的不可微问题，并有效地在训练阶段建模时间序列的几何形状。这种将图像模态引入时间序列分析的思路具有创新性，且实验结果表明其在不增加推理成本的情况下提升了预测性能，具有重要的实际应用价值。"}}
{"id": "2507.23381", "title": "A Secure Full-Duplex Wireless Circulator enabled by Non-Reciprocal Beyond-Diagonal RIS", "authors": ["Ziang Liu", "Bruno Clerckx"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Submitted for IEEE journal", "url": "http://arxiv.org/abs/2507.23381v1", "summary": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has arisen as a\npromising technology for enhancing wireless communication systems by enabling\nflexible and intelligent wave manipulation. This is achieved through the\ninterconnections among the ports of the impedance network, enabling wave\nreconfiguration when they flow through the surface. Thus, the output wave at\none port depends on waves impinging on neighboring ports, allowing non-local\ncontrol of both phase and magnitude. Non-reciprocal (NR)-BD-RIS further\nenhances this capability by breaking circuit reciprocity and, consequently,\nchannel reciprocity. This feature potentially benefits communication among\nnon-aligned transceivers. This paper introduces a novel application of\nNR-BD-RIS in full-duplex (FD) wireless circulators, where multiple FD devices\ncommunicate via an NR-BD-RIS. This system is particularly beneficial for secure\ntransmission, as it enforces one-way communication among FD devices, suppresses\nsignal from all other users, and thus prevents eavesdropping. In addition, a\nphysics-compliant system model is considered by incorporating structural\nscattering, also known as specular reflection. By accounting for this effect,\nthe advantages of NR-BD-RIS are further validated. Specifically, we formulate\nan all-user sum-rate maximization problem and propose an iterative optimization\nalgorithm that employs block coordinate descent (BCD) and penalty dual\ndecomposition (PDD) methods. Numerical evaluations illustrate that NR-BD-RIS\nconsistently outperforms reciprocal (R)-BD-RIS and conventional diagonal\n(D)-RIS in terms of sum-rate performance, particularly when more than two\nimpinging and reflection directions need to be supported. By analyzing the\npower of signals from all other users and the beampatterns, we show that secure\ntransmission can be achieved.", "comment": "Submitted for IEEE journal", "pdf_url": "http://arxiv.org/pdf/2507.23381v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一种由非互易超对角RIS实现的安安全全双工无线环行器", "tldr": "本文提出了一种利用非互易超对角可重构智能表面（NR-BD-RIS）实现全双工无线环行器的新应用，旨在增强安全传输，并通过数值评估证明了其在和速率性能上的优越性。", "motivation": "超对角可重构智能表面（BD-RIS）通过端口互连实现灵活智能的波操纵，有望增强无线通信系统。非互易BD-RIS（NR-BD-RIS）通过打破电路和信道互易性进一步增强了这一能力，这对于非对齐收发器之间的通信具有潜在益处。本文的动机是探索NR-BD-RIS在全双工（FD）无线环行器中的新应用，以实现安全传输，抑制窃听，并克服传统RIS的局限性。", "method": "本文引入了NR-BD-RIS在全双工（FD）无线环行器中的新应用，其中多个FD设备通过NR-BD-RIS进行通信。系统模型考虑了物理兼容性，包括结构散射（镜面反射）。研究中提出了一个所有用户和速率最大化问题，并提出了一种采用块坐标下降（BCD）和惩罚对偶分解（PDD）方法的迭代优化算法来解决该问题。", "result": "数值评估表明，在和速率性能方面，NR-BD-RIS始终优于互易（R）-BD-RIS和传统对角（D）-RIS，特别是在需要支持两个以上入射和反射方向时。通过分析来自所有其他用户的信号功率和波束图，研究证明可以实现安全传输。", "conclusion": "本文引入了一种由非互易超对角可重构智能表面（NR-BD-RIS）实现的全双工无线环行器的新应用，并考虑了物理兼容的系统模型。研究结果验证了NR-BD-RIS在增强安全传输和提高和速率性能方面的优势，特别是在多方向通信场景下。", "translation": "超对角可重构智能表面（BD-RIS）作为一种有前景的技术，通过实现灵活智能的波操纵，已成为增强无线通信系统的重要手段。这通过阻抗网络端口之间的互连实现，使得波在通过表面时能够重新配置。因此，一个端口的输出波取决于入射到相邻端口的波，从而实现了相位和幅度的非局部控制。非互易（NR）-BD-RIS通过打破电路互易性，进而打破信道互易性，进一步增强了这一能力。这一特性可能有利于非对齐收发器之间的通信。本文介绍了NR-BD-RIS在全双工（FD）无线环行器中的一种新颖应用，其中多个FD设备通过NR-BD-RIS进行通信。该系统特别有利于安全传输，因为它强制FD设备之间进行单向通信，抑制来自所有其他用户的信号，从而防止窃听。此外，通过纳入结构散射（也称为镜面反射），考虑了一个符合物理原理的系统模型。通过考虑这种效应，NR-BD-RIS的优势得到了进一步验证。具体而言，我们提出了一个所有用户和速率最大化问题，并提出了一种采用块坐标下降（BCD）和惩罚对偶分解（PDD）方法的迭代优化算法。数值评估表明，在和速率性能方面，NR-BD-RIS始终优于互易（R）-BD-RIS和传统对角（D）-RIS，特别是在需要支持两个以上入射和反射方向时。通过分析来自所有其他用户的信号功率和波束图，我们表明可以实现安全传输。", "summary": "本文提出了一种利用非互易超对角可重构智能表面（NR-BD-RIS）实现全双工（FD）无线环行器的新颖应用，旨在通过强制单向通信和抑制窃听来增强安全传输。该研究考虑了一个包含结构散射的物理兼容系统模型，并构建了一个所有用户和速率最大化问题，通过结合块坐标下降和惩罚对偶分解的迭代算法进行求解。数值结果表明，与互易或传统对角RIS相比，NR-BD-RIS在和速率性能方面表现出显著优势，尤其适用于需要支持多方向通信的场景，并验证了其实现安全传输的能力。", "keywords": "非互易超对角RIS, 全双工, 无线环行器, 安全传输, 和速率最大化", "comments": "本文的创新点在于将非互易超对角可重构智能表面（NR-BD-RIS）应用于全双工无线环行器，以实现安全通信。通过打破信道互易性，NR-BD-RIS能够有效抑制窃听并强制单向通信，这在未来无线通信中具有重要意义。此外，研究中考虑了结构散射的物理兼容模型，使得系统分析更加贴近实际。其提出的优化算法和数值结果进一步验证了NR-BD-RIS的优越性，为安全高效的无线通信提供了新的思路和解决方案。"}}
{"id": "2503.18666", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "authors": ["Haoyu Wang", "Christopher M. Poskitt", "Jun Sun"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026)", "url": "http://arxiv.org/abs/2503.18666v3", "summary": "Agents built on LLMs are increasingly deployed across diverse domains,\nautomating complex decision-making and task execution. However, their autonomy\nintroduces safety risks, including security vulnerabilities, legal violations,\nand unintended harmful actions. Existing mitigation methods, such as\nmodel-based safeguards and early enforcement strategies, fall short in\nrobustness, interpretability, and adaptability. To address these challenges, we\npropose AgentSpec, a lightweight domain-specific language for specifying and\nenforcing runtime constraints on LLM agents. With AgentSpec, users define\nstructured rules that incorporate triggers, predicates, and enforcement\nmechanisms, ensuring agents operate within predefined safety boundaries. We\nimplement AgentSpec across multiple domains, including code execution, embodied\nagents, and autonomous driving, demonstrating its adaptability and\neffectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe\nexecutions in over 90% of code agent cases, eliminates all hazardous actions in\nembodied agent tasks, and enforces 100% compliance by autonomous vehicles\n(AVs). Despite its strong safety guarantees, AgentSpec remains computationally\nlightweight, with overheads in milliseconds. By combining interpretability,\nmodularity, and efficiency, AgentSpec provides a practical and scalable\nsolution for enforcing LLM agent safety across diverse applications. We also\nautomate the generation of rules using LLMs and assess their effectiveness. Our\nevaluation shows that the rules generated by OpenAI o1 achieve a precision of\n95.56% and recall of 70.96% for embodied agents, successfully identify 87.26%\nof the risky code, and prevent AVs from breaking laws in 5 out of 8 scenarios.", "comment": "Accepted by the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "pdf_url": "http://arxiv.org/pdf/2503.18666v3", "cate": "cs.AI", "date": "2025-03-24", "updated": "2025-07-31", "AI": {"title_translation": "AgentSpec: 可定制的运行时强制执行，用于安全可靠的LLM代理", "tldr": "AgentSpec 是一种轻量级领域特定语言，用于为LLM代理定义运行时安全规则，有效防止多种领域的危险行为，且开销极低。", "motivation": "LLM代理的自主性引入了安全风险，如安全漏洞、法律违规和意外有害行为。现有缓解方法在鲁棒性、可解释性和适应性方面不足。", "method": "提出 AgentSpec，一种轻量级领域特定语言，用于指定和强制执行LLM代理的运行时约束。用户定义包含触发器、谓词和强制执行机制的结构化规则。还使用LLM自动化生成规则。", "result": "AgentSpec 成功阻止了90%以上代码代理案例中的不安全执行，消除了具身代理任务中的所有有害动作，强制自动驾驶汽车100%遵守规定。计算开销在毫秒级。LLM生成的规则对具身代理的精确度为95.56%、召回率为70.96%，成功识别87.26%的危险代码，并在8个场景中的5个中防止AVs违法。", "conclusion": "AgentSpec 通过结合可解释性、模块化和效率，为在各种应用中强制执行LLM代理安全提供了一个实用且可扩展的解决方案。", "translation": "基于LLM构建的代理正越来越多地部署在各个领域，自动化复杂的决策和任务执行。然而，它们的自主性带来了安全风险，包括安全漏洞、法律违规和意外的有害行为。现有的缓解方法，如基于模型的安全防护和早期强制执行策略，在鲁棒性、可解释性和适应性方面存在不足。为了解决这些挑战，我们提出了AgentSpec，一种轻量级领域特定语言，用于指定和强制执行LLM代理的运行时约束。通过AgentSpec，用户可以定义包含触发器、谓词和强制执行机制的结构化规则，确保代理在预定义的安全边界内运行。我们在多个领域实现了AgentSpec，包括代码执行、具身代理和自动驾驶，展示了其适应性和有效性。我们的评估表明，AgentSpec成功阻止了90%以上代码代理案例中的不安全执行，消除了具身代理任务中的所有危险动作，并强制自动驾驶汽车（AVs）100%遵守规定。尽管具有强大的安全保证，AgentSpec仍保持计算轻量级，开销在毫秒级。通过结合可解释性、模块化和效率，AgentSpec为在各种应用中强制执行LLM代理安全提供了一个实用且可扩展的解决方案。我们还使用LLM自动化规则的生成，并评估了它们的有效性。我们的评估显示，OpenAI o1生成的规则对具身代理的精确度为95.56%，召回率为70.96%，成功识别了87.26%的危险代码，并在8个场景中的5个场景中防止AVs违法。", "summary": "本论文提出了 AgentSpec，一种轻量级领域特定语言，旨在解决大型语言模型（LLM）代理在自主性带来的安全风险问题。AgentSpec 允许用户通过定义包含触发器、谓词和强制机制的结构化规则，在运行时对LLM代理施加安全约束。该系统在代码执行、具身代理和自动驾驶等多个领域进行了验证，结果显示其能有效阻止不安全行为（如代码代理中90%以上的不安全执行、具身代理中所有危险动作、自动驾驶中100%的合规性），同时保持极低的计算开销。论文还探讨了利用LLM自动生成规则的有效性，并展示了其在识别风险代码和确保合规性方面的潜力，AgentSpec 提供了一个可解释、模块化且高效的LLM代理安全强制解决方案。", "keywords": "LLM代理, 运行时安全, 强制执行, 领域特定语言, AgentSpec", "comments": "AgentSpec 的创新性在于其提出的轻量级领域特定语言（DSL）方法，将运行时安全强制执行与LLM代理结合，解决了现有模型内嵌或早期策略的不足。其强调的可解释性、模块化和低计算开销使其具有很强的实用性和可扩展性。通过在多个复杂领域（代码执行、具身代理、自动驾驶）的成功应用，证明了其有效性。此外，自动化规则生成的能力也为未来LLM代理的安全保障提供了新的方向。"}}
{"id": "2505.18497", "title": "The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models", "authors": ["Kefan Yu", "Qingcheng Zeng", "Weihao Xuan", "Wanxin Li", "Jingyi Wu", "Rob Voigt"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.18497v2", "summary": "Current large language models (LLMs) have demonstrated emerging capabilities\nin social intelligence tasks, including implicature resolution and\ntheory-of-mind reasoning, both of which require substantial pragmatic\nunderstanding. However, how LLMs acquire this pragmatic competence throughout\nthe training process remains poorly understood. In this work, we introduce\nALTPRAG, a dataset grounded in the pragmatic concept of alternatives, to\nevaluate whether LLMs at different training stages can accurately infer nuanced\nspeaker intentions. Each instance pairs two equally plausible yet pragmatically\ndivergent continuations and requires the model to (i) infer the speaker's\nintended meaning and (ii) explain when and why a speaker would choose one\nutterance over its alternative, thus directly probing pragmatic competence\nthrough contrastive reasoning. We systematically evaluate 22 LLMs across 3 key\ntraining stages: after pre-training, supervised fine-tuning (SFT), and\npreference optimization, to examine the development of pragmatic competence.\nOur results show that even base models exhibit notable sensitivity to pragmatic\ncues, which improves consistently with increases in model and data scale.\nAdditionally, SFT and RLHF contribute further gains, particularly in\ncognitive-pragmatic scenarios. These findings highlight pragmatic competence as\nan emergent and compositional property of LLM training and offer new insights\nfor aligning models with human communicative norms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.18497v2", "cate": "cs.CL", "date": "2025-05-24", "updated": "2025-07-31", "AI": {"title_translation": "机器的语用思维：追溯大型语言模型中语用能力的出现", "tldr": "大型语言模型（LLMs）在训练过程中逐渐获得语用能力，基础模型即展现出语用敏感性，且随着模型和数据规模的增加、SFT和RLHF的应用，语用能力持续提升。本文引入ALTPRAG数据集，通过对比推理评估不同训练阶段LLMs的语用能力。", "motivation": "当前大型语言模型（LLMs）在需要语用理解的社交智能任务中展现出新兴能力，但LLMs在训练过程中如何获得这种语用能力仍不清楚。", "method": "引入了ALTPRAG数据集，该数据集基于语用学中的“替代项”概念，旨在评估不同训练阶段的LLMs能否准确推断说话者的细微意图。每个实例包含两个同样合理但语用上不同的延续，要求模型推断说话者意图并解释为何选择某个表达而非其替代项，从而通过对比推理直接探究语用能力。系统评估了22个LLMs在预训练、监督微调（SFT）和偏好优化三个关键训练阶段的语用能力发展。", "result": "结果显示，即使是基础模型也对语用线索表现出显著的敏感性，并且这种敏感性随着模型和数据规模的增加而持续提高。此外，SFT和RLHF进一步提升了语用能力，尤其是在认知语用场景中。", "conclusion": "这些发现表明语用能力是LLM训练过程中一种涌现的、组合性的特性，并为使模型与人类交流规范对齐提供了新的见解。", "translation": "当前大型语言模型（LLMs）在社交智能任务中展现出新兴能力，包括蕴涵解析和心智理论推理，这两者都需要大量的语用理解。然而，LLMs在整个训练过程中如何获得这种语用能力仍知之甚少。在这项工作中，我们引入了ALTPRAG数据集，该数据集以语用学中的替代概念为基础，旨在评估不同训练阶段的LLMs能否准确推断说话者的细微意图。每个实例将两个同样合理但在语用上有所分歧的延续进行配对，并要求模型（i）推断说话者的预期含义，以及（ii）解释说话者何时以及为何会选择一个表达而非其替代项，从而通过对比推理直接探究语用能力。我们系统地评估了22个LLMs在三个关键训练阶段（预训练后、监督微调（SFT）和偏好优化）的表现，以考察语用能力的发展。我们的结果表明，即使是基础模型也对语用线索表现出显著的敏感性，并且这种敏感性随着模型和数据规模的增加而持续提高。此外，SFT和RLHF带来了进一步的提升，特别是在认知语用场景中。这些发现强调了语用能力是LLM训练过程中一种涌现的、组合性的特性，并为使模型与人类交流规范对齐提供了新的见解。", "summary": "该研究探讨了大型语言模型（LLMs）如何在其训练过程中获得语用能力。为了评估不同训练阶段LLMs理解说话者意图的能力，研究者引入了ALTPRAG数据集，该数据集通过对比推理要求模型推断语用上不同的替代表达。对22个LLMs在预训练、SFT和偏好优化三个阶段的评估显示，基础模型已具备语用敏感性，且这种能力随模型和数据规模的增大而增强。SFT和RLHF进一步提升了LLMs的语用表现，尤其是在认知语用场景中。研究结果表明，语用能力是LLM训练中一种涌现且组合的特性，为模型与人类交流规范对齐提供了新视角。", "keywords": "大型语言模型, 语用能力, 训练阶段, ALTPRAG, 人类对齐", "comments": "本文通过引入ALTPRAG数据集，创新性地使用对比推理来直接探究大型语言模型的语用能力，这是其重要贡献之一。研究系统地评估了不同训练阶段（预训练、SFT、RLHF）LLMs的语用发展，揭示了语用能力作为一种涌现和组合性质，对理解LLMs的认知机制和未来模型对齐人类交流规范具有重要意义。该研究为提升LLMs的社会智能提供了坚实的基础。"}}
{"id": "2507.23111", "title": "Scalable Generative Modeling of Weighted Graphs", "authors": ["Richard Williams", "Eric Nalisnick", "Andrew Holbrook"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 5 figures, included appendix. code at this https URL", "url": "http://arxiv.org/abs/2507.23111v1", "summary": "Weighted graphs are ubiquitous throughout biology, chemistry, and the social\nsciences, motivating the development of generative models for abstract weighted\ngraph data using deep neural networks. However, most current deep generative\nmodels are either designed for unweighted graphs and are not easily extended to\nweighted topologies or incorporate edge weights without consideration of a\njoint distribution with topology. Furthermore, learning a distribution over\nweighted graphs must account for complex nonlocal dependencies between both the\nedges of the graph and corresponding weights of each edge. We develop an\nautoregressive model BiGG-E, a nontrivial extension of the BiGG model, that\nlearns a joint distribution over weighted graphs while still exploiting\nsparsity to generate a weighted graph with $n$ nodes and $m$ edges in $O((n +\nm)\\log n)$ time. Simulation studies and experiments on a variety of benchmark\ndatasets demonstrate that BiGG-E best captures distributions over weighted\ngraphs while remaining scalable and computationally efficient.", "comment": "25 pages, 5 figures, included appendix. code at\n  https://github.com/rlwilliams34/BiGG-E", "pdf_url": "http://arxiv.org/pdf/2507.23111v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "可扩展的加权图生成模型", "tldr": "BiGG-E是一种新的自回归模型，用于可扩展且高效地生成加权图，性能优于现有方法。", "motivation": "加权图在生物学、化学和社会科学中普遍存在，但现有的深度生成模型在处理加权图时存在局限性，例如难以扩展到加权拓扑或未考虑拓扑与权重的联合分布。此外，学习加权图的分布需要考虑边及其对应权重之间复杂的非局部依赖性。", "method": "开发了一种名为BiGG-E的自回归模型，它是BiGG模型的非平凡扩展。BiGG-E能够学习加权图的联合分布，并通过利用稀疏性，以O((n + m)log n)的时间生成具有n个节点和m条边的加权图。", "result": "模拟研究和在各种基准数据集上的实验表明，BiGG-E在捕获加权图分布方面表现最佳，同时保持了良好的可扩展性和计算效率。", "conclusion": "BiGG-E模型有效解决了加权图生成建模的挑战，提供了优于现有方法的性能、可扩展性和效率。", "translation": "加权图在生物学、化学和社会科学中无处不在，这促使人们开发使用深度神经网络的抽象加权图数据的生成模型。然而，目前大多数深度生成模型要么是为无权图设计的，不易扩展到加权拓扑，要么在考虑边权重时没有考虑与拓扑的联合分布。此外，学习加权图的分布必须考虑图的边和每条边对应权重之间复杂的非局部依赖关系。我们开发了一种自回归模型BiGG-E，它是BiGG模型的非平凡扩展，该模型学习加权图的联合分布，同时利用稀疏性以O((n + m)log n)的时间生成一个具有n个节点和m条边的加权图。在各种基准数据集上的模拟研究和实验表明，BiGG-E在捕获加权图分布方面表现最佳，同时保持可扩展性和计算效率。", "summary": "本文介绍了一种名为BiGG-E的新型自回归深度生成模型，用于处理加权图。针对现有模型在联合拓扑-权重分布和可扩展性方面的不足，BiGG-E模型学习了加权图的联合分布，并利用稀疏性实现高效的图生成。实验结果表明，BiGG-E在捕获加权图分布方面表现出色，并具有高可扩展性和计算效率。", "keywords": "加权图, 生成模型, 深度学习, 自回归模型, 可扩展性", "comments": "该论文的创新之处在于开发了一种自回归模型（BiGG-E），它能有效地学习图拓扑和边权重的联合分布，这对于现有生成图模型来说是一个重大挑战。其利用稀疏性实现计算效率的能力，使其在生成大规模加权图方面具有高度实用性。"}}
{"id": "2409.11911", "title": "AI vs. Human Paintings? Deciphering Public Interactions and Perceptions towards AI-Generated Paintings on TikTok", "authors": ["Jiajun Wang", "Xiangzhe Yuan", "Siying Hu", "Zhicong Lu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Published online in International Journal of Human Computer Interaction", "url": "http://arxiv.org/abs/2409.11911v2", "summary": "With the development of generative AI technology, a vast array of\nAI-generated paintings (AIGP) have gone viral on social media like TikTok.\nHowever, some negative news about AIGP has also emerged. For example, in 2022,\nnumerous painters worldwide organized a large-scale anti-AI movement because of\nthe infringement in generative AI model training. This event reflected a social\nissue that, with the development and application of generative AI, public\nfeedback and feelings towards it may have been overlooked. Therefore, to\ninvestigate public interactions and perceptions towards AIGP on social media,\nwe analyzed user engagement level and comment sentiment scores of AIGP using\nhuman painting videos as a baseline. In analyzing user engagement, we also\nconsidered the possible moderating effect of the aesthetic quality of\nPaintings. Utilizing topic modeling, we identified seven reasons, including\nhyperrealistic quality, ambivalent reactions, perceived theft of art, etc.,\nleading to negative public perceptions of AIGP. Our work may provide\ninstructive suggestions for future generative AI technology development and\navoid potential crises in human-AI collaboration.", "comment": "Published online in International Journal of Human Computer\n  Interaction", "pdf_url": "http://arxiv.org/pdf/2409.11911v2", "cate": "cs.HC", "date": "2024-09-18", "updated": "2025-07-31", "AI": {"title_translation": "AI vs. 人类绘画？解读TikTok上公众对AI生成绘画的互动和感知", "tldr": "研究TikTok上公众对AI生成绘画的互动和看法，发现负面情绪和原因，并提出未来AI发展的建议。", "motivation": "随着生成式AI技术的发展，AI生成绘画(AIGP)在社交媒体上走红，但也出现了负面新闻，如2022年全球画家反对AI的运动，这反映出公众对生成式AI的反馈和感受可能被忽视。因此，本研究旨在调查社交媒体上公众对AIGP的互动和看法。", "method": "以人类绘画视频为基线，分析了AI生成绘画(AIGP)的用户参与度水平和评论情感得分。在分析用户参与度时，考虑了绘画审美质量的调节作用。利用主题建模，识别了导致公众对AIGP产生负面看法的七个原因。", "result": "识别出导致公众对AI生成绘画产生负面看法的七个原因，包括超现实质量、矛盾反应、感知到的艺术盗窃等。", "conclusion": "本研究工作可以为未来的生成式AI技术发展提供指导性建议，并避免人机协作中潜在的危机。", "translation": "随着生成式AI技术的发展，大量AI生成绘画(AIGP)在TikTok等社交媒体上走红。然而，一些关于AIGP的负面新闻也随之出现。例如，2022年，全球众多画家因生成式AI模型训练中的侵权行为组织了一场大规模的反AI运动。这一事件反映了一个社会问题，即随着生成式AI的开发和应用，公众对其的反馈和感受可能被忽视了。因此，为了调查社交媒体上公众对AIGP的互动和看法，我们以人类绘画视频为基线，分析了AIGP的用户参与度水平和评论情感得分。在分析用户参与度时，我们还考虑了绘画审美质量的可能调节作用。利用主题建模，我们识别出七个导致公众对AIGP产生负面看法的原因，包括超现实质量、矛盾反应、感知到的艺术盗窃等。我们的工作可能为未来的生成式AI技术发展提供指导性建议，并避免人机协作中潜在的危机。", "summary": "本研究调查了TikTok上公众对AI生成绘画(AIGP)的互动和感知。通过分析用户参与度和评论情感，并以人类绘画视频为基线，研究发现公众对AIGP存在负面看法，并识别出七个主要原因，如艺术侵权和矛盾反应。研究旨在为未来的生成式AI技术发展提供指导，以避免人机协作中的潜在危机。", "keywords": "AI生成绘画, 公众感知, TikTok, 用户互动, 情感分析", "comments": "本文关注了生成式AI在社交媒体上引发的社会问题，特别是公众对AI生成艺术的负面情绪和原因。其创新之处在于结合了用户参与度、情感分析和主题建模来量化和解释这些感知。研究结果为AI技术开发者提供了宝贵的反馈，有助于在人机协作中避免潜在冲突，具有重要的现实指导意义。"}}
{"id": "2507.22953", "title": "CADS: A Comprehensive Anatomical Dataset and Segmentation for Whole-Body Anatomy in Computed Tomography", "authors": ["Murong Xu", "Tamaz Amiranashvili", "Fernando Navarro", "Maksym Fritsak", "Ibrahim Ethem Hamamci", "Suprosanna Shit", "Bastian Wittmann", "Sezgin Er", "Sebastian M. Christ", "Ezequiel de la Rosa", "Julian Deseoe", "Robert Graf", "Hendrik Möller", "Anjany Sekuboyina", "Jan C. Peeken", "Sven Becker", "Giulia Baldini", "Johannes Haubold", "Felix Nensa", "René Hosch", "Nikhil Mirajkar", "Saad Khalid", "Stefan Zachow", "Marc-André Weber", "Georg Langs", "Jakob Wasserthal", "Mehmet Kemal Ozdemir", "Andrey Fedorov", "Ron Kikinis", "Stephanie Tanadini-Lang", "Jan S. Kirschke", "Stephanie E. Combs", "Bjoern Menze"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22953v1", "summary": "Accurate delineation of anatomical structures in volumetric CT scans is\ncrucial for diagnosis and treatment planning. While AI has advanced automated\nsegmentation, current approaches typically target individual structures,\ncreating a fragmented landscape of incompatible models with varying performance\nand disparate evaluation protocols. Foundational segmentation models address\nthese limitations by providing a holistic anatomical view through a single\nmodel. Yet, robust clinical deployment demands comprehensive training data,\nwhich is lacking in existing whole-body approaches, both in terms of data\nheterogeneity and, more importantly, anatomical coverage. In this work, rather\nthan pursuing incremental optimizations in model architecture, we present CADS,\nan open-source framework that prioritizes the systematic integration,\nstandardization, and labeling of heterogeneous data sources for whole-body CT\nsegmentation. At its core is a large-scale dataset of 22,022 CT volumes with\ncomplete annotations for 167 anatomical structures, representing a significant\nadvancement in both scale and coverage, with 18 times more scans than existing\ncollections and 60% more distinct anatomical targets. Building on this diverse\ndataset, we develop the CADS-model using established architectures for\naccessible and automated full-body CT segmentation. Through comprehensive\nevaluation across 18 public datasets and an independent real-world hospital\ncohort, we demonstrate advantages over SoTA approaches. Notably, thorough\ntesting of the model's performance in segmentation tasks from radiation\noncology validates its direct utility for clinical interventions. By making our\nlarge-scale dataset, our segmentation models, and our clinical software tool\npublicly available, we aim to advance robust AI solutions in radiology and make\ncomprehensive anatomical analysis accessible to clinicians and researchers\nalike.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22953v1", "cate": "eess.IV", "date": "2025-07-29", "updated": "2025-07-29", "AI": {"title_translation": "CADS：一种用于全身CT解剖学的综合解剖数据集和分割方法", "tldr": "本文介绍了CADS，一个包含22,022个CT卷和167个解剖结构完整标注的大规模数据集，并基于此开发了CADS模型，用于全身CT分割，旨在解决现有方法数据不足和覆盖范围有限的问题，并已验证其临床实用性。", "motivation": "现有的AI自动化分割方法通常针对单个结构，导致模型不兼容且性能各异，缺乏一个提供整体解剖视图的基础模型。尽管基础分割模型旨在解决此问题，但其稳健的临床部署需要全面的训练数据，而现有全身方法在数据异质性和解剖覆盖范围上均存在不足。", "method": "本文提出了CADS，一个开源框架，优先系统地整合、标准化和标注异构数据源，用于全身CT分割。其核心是一个包含22,022个CT体数据的大规模数据集，对167个解剖结构进行了完整标注。在此多样化数据集的基础上，使用既有架构开发了CADS模型，实现了可访问和自动化的全身CT分割。", "result": "通过对18个公共数据集和一个独立的真实世界医院队列进行全面评估，CADS模型展示了优于现有最先进方法的优势。特别是，对模型在放射肿瘤学分割任务中性能的彻底测试，验证了其在临床干预中的直接实用性。", "conclusion": "通过公开大规模数据集、分割模型和临床软件工具，本文旨在推动放射学领域稳健的AI解决方案，并使全面的解剖分析对临床医生和研究人员都可及。", "translation": "在容积CT扫描中准确描绘解剖结构对于诊断和治疗计划至关重要。尽管人工智能在自动化分割方面取得了进展，但目前的方法通常针对单个结构，导致模型不兼容、性能各异且评估协议不统一。基础分割模型通过单一模型提供整体解剖视图，解决了这些局限性。然而，稳健的临床部署需要全面的训练数据，而现有全身方法在数据异质性以及更重要的解剖覆盖范围方面都存在不足。在这项工作中，我们没有追求模型架构的渐进优化，而是提出了CADS，一个开源框架，它优先系统地整合、标准化和标注用于全身CT分割的异构数据源。其核心是一个包含22,022个体CT数据的大规模数据集，对167个解剖结构进行了完整标注，在规模和覆盖范围上都取得了显著进展，比现有集合多18倍的扫描量，以及多60%的独立解剖目标。在此多样化数据集的基础上，我们使用既有架构开发了CADS模型，用于可访问和自动化的全身CT分割。通过对18个公共数据集和一个独立的真实世界医院队列进行全面评估，我们证明了其优于现有最先进方法的优势。值得注意的是，对模型在放射肿瘤学分割任务中性能的彻底测试，验证了其在临床干预中的直接实用性。通过公开我们的大规模数据集、我们的分割模型和我们的临床软件工具，我们旨在推动放射学领域稳健的AI解决方案，并使全面的解剖分析对临床医生和研究人员都可及。", "summary": "本文介绍了CADS，一个旨在解决全身CT解剖结构分割中数据不足和覆盖范围有限问题的开源框架。CADS的核心是一个包含22,022个体CT数据的大规模数据集，涵盖167个解剖结构，显著超越现有数据集的规模和覆盖范围。基于此数据集，研究人员开发了CADS模型，并在多项公共数据集和真实世界医院队列中进行了评估，结果显示其性能优于现有最先进方法，尤其在放射肿瘤学领域具有直接的临床实用性。该工作旨在通过公开其数据集、模型和工具，促进放射学领域AI解决方案的发展和解剖分析的普及。", "keywords": "全身CT分割, 解剖数据集, CADS, 放射学AI, 医疗影像", "comments": "CADS通过构建一个前所未有的大规模、高覆盖率的全身CT解剖数据集，解决了当前AI分割模型碎片化和数据匮乏的核心痛点。其创新性在于数据整合、标准化和标注的系统性方法，而非单纯的模型架构优化。该工作的意义在于为全身解剖分割提供了坚实的基础，并已验证其在临床（特别是放射肿瘤学）中的直接应用潜力。公开数据集和工具的举措，将极大促进相关研究和临床应用的进步。"}}
{"id": "2507.23673", "title": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "authors": ["Alfie Roddan", "Tobias Czempiel", "Chi Xu", "Daniel S. Elson", "Stamatia Giannarou"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23673v1", "summary": "Hyperspectral imaging (HSI) provides rich spectral information for medical\nimaging, yet encounters significant challenges due to data limitations and\nhardware variations. We introduce SAMSA, a novel interactive segmentation\nframework that combines an RGB foundation model with spectral analysis. SAMSA\nefficiently utilizes user clicks to guide both RGB segmentation and spectral\nsimilarity computations. The method addresses key limitations in HSI\nsegmentation through a unique spectral feature fusion strategy that operates\nindependently of spectral band count and resolution. Performance evaluation on\npublicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a\nneurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative\nporcine hyperspectral dataset. Experimental results demonstrate SAMSA's\neffectiveness in few-shot and zero-shot learning scenarios and using minimal\ntraining examples. Our approach enables seamless integration of datasets with\ndifferent spectral characteristics, providing a flexible framework for\nhyperspectral medical image analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23673v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SAMSA：基于光谱角度增强的万物分割模型，用于高光谱交互式医学图像分割", "tldr": "SAMSA是一个新颖的交互式分割框架，结合了RGB基础模型和光谱分析，用于高光谱医学图像分割，在少样本和零样本学习场景下取得了高DICE分数。", "motivation": "高光谱成像（HSI）为医学成像提供了丰富的光谱信息，但由于数据限制和硬件差异而面临显著挑战。", "method": "本文提出了SAMSA，一个新颖的交互式分割框架，它结合了RGB基础模型和光谱分析。SAMSA利用用户点击来指导RGB分割和光谱相似性计算。该方法通过一种独特的光谱特征融合策略解决了HSI分割的关键限制，该策略独立于光谱带计数和分辨率。", "result": "在公开数据集上，神经外科数据集的1次点击DICE为81.0%，5次点击DICE为93.4%；术中猪高光谱数据集的1次点击DICE为81.1%，5次点击DICE为89.2%。实验结果表明SAMSA在少样本和零样本学习场景中以及使用最少训练样本时的有效性。", "conclusion": "本文提出的方法能够无缝集成具有不同光谱特征的数据集，为高光谱医学图像分析提供了一个灵活的框架。", "translation": "高光谱成像（HSI）为医学成像提供了丰富的光谱信息，但由于数据限制和硬件差异而面临重大挑战。我们引入了SAMSA，一个新颖的交互式分割框架，它结合了RGB基础模型和光谱分析。SAMSA有效利用用户点击来指导RGB分割和光谱相似性计算。该方法通过一种独特的光谱特征融合策略解决了HSI分割中的关键限制，该策略独立于光谱带计数和分辨率。在公开数据集上的性能评估显示，在神经外科数据上，1次点击DICE为81.0%，5次点击DICE为93.4%；在术中猪高光谱数据集上，1次点击DICE为81.1%，5次点击DICE为89.2%。实验结果表明SAMSA在少样本和零样本学习场景中以及使用最少训练样本时的有效性。我们的方法能够无缝集成具有不同光谱特征的数据集，为高光谱医学图像分析提供了一个灵活的框架。", "summary": "SAMSA是一个新颖的交互式高光谱医学图像分割框架，通过将RGB基础模型与光谱分析相结合，并采用独立于光谱带数和分辨率的光谱特征融合策略，解决了高光谱成像在数据限制和硬件差异方面的挑战。该方法利用用户点击指导分割和光谱相似性计算，并在多个公开数据集上表现出优异的分割性能，尤其在少样本和零样本学习场景下表现出色，为高光谱医学图像分析提供了灵活的解决方案。", "keywords": "高光谱成像, 交互式分割, 万物分割模型, 光谱角度, 医学图像分割", "comments": "SAMSA创新性地将RGB基础模型与光谱分析相结合，并通过独特的光谱特征融合策略克服了高光谱图像分割中数据限制和硬件差异的挑战。其在少样本和零样本学习场景下的出色表现以及对不同光谱特性数据集的无缝集成能力，使其成为高光谱医学图像分析领域一个重要且灵活的工具。"}}
{"id": "2505.05085", "title": "Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation", "authors": ["Gary Froyland", "Kevin Kühl"], "categories": ["math.DS", "cs.LG", "cs.NA", "math.NA", "47A15, 37C30, 47A58, 68T07"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "Comments:      23 pages, 13 figures", "url": "http://arxiv.org/abs/2505.05085v2", "summary": "Transfer and Koopman operator methods offer a framework for representing\ncomplex, nonlinear dynamical systems via linear transformations, enabling a\ndeeper understanding of the underlying dynamics. The spectra of these operators\nprovide important insights into system predictability and emergent behaviour,\nalthough efficiently estimating them from data can be challenging. We approach\nthis issue through the lens of general operator and representational learning,\nin which we approximate these linear operators using efficient\nfinite-dimensional representations. Specifically, we machine-learn orthonormal\nbasis functions that are dynamically tailored to the system. This learned basis\nprovides a particularly accurate approximation of the operator's action as well\nas a nearly invariant finite-dimensional subspace. We illustrate our approach\nwith examples that showcase the retrieval of spectral properties from the\nestimated operator, and emphasise the dynamically adaptive quality of the\nmachine-learned basis.", "comment": "23 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2505.05085v2", "cate": "math.DS", "date": "2025-05-08", "updated": "2025-07-30", "AI": {"title_translation": "学习动态启发的不变子空间用于Koopman和转移算子逼近", "tldr": "本文提出了一种机器学习方法，通过学习动态定制的正交基函数，有效地近似Koopman和转移算子，从而更好地理解复杂非线性动力系统。", "motivation": "转移算子和Koopman算子能够通过线性变换表示复杂的非线性动力系统，其谱提供了对系统可预测性和涌现行为的重要见解。然而，从数据中有效估计这些算子的谱具有挑战性。", "method": "通过通用算子和表示学习的方法来解决这个问题。具体而言，机器学习与系统动态特性相匹配的正交基函数，以近似这些线性算子。这种学习到的基函数提供了算子作用的精确近似以及一个近似不变的有限维子空间。", "result": "我们的方法通过示例展示了从估计的算子中检索谱性质的能力，并强调了机器学习基函数的动态适应性。", "conclusion": "通过机器学习动态定制的正交基函数，可以有效地近似Koopman和转移算子，从而克服从数据中估计其谱的挑战，并提供对系统动力学的深入理解。", "translation": "转移算子和Koopman算子方法提供了一个通过线性变换表示复杂非线性动力学的框架，从而能够更深入地理解底层动力学。这些算子的谱提供了对系统可预测性和涌现行为的重要见解，尽管从数据中有效估计它们具有挑战性。我们通过通用算子和表示学习的视角来解决这个问题，其中我们使用高效的有限维表示来近似这些线性算子。具体而言，我们机器学习与系统动态特性相匹配的正交基函数。这种学习到的基函数提供了对算子作用的特别精确的近似以及一个近似不变的有限维子空间。我们通过示例说明了我们的方法，这些示例展示了从估计的算子中检索谱性质的能力，并强调了机器学习基函数的动态适应性。", "summary": "本文提出一种新颖的机器学习方法，用于近似Koopman和转移算子。该方法通过学习与系统动态特性相匹配的正交基函数，构建高效的有限维表示，从而克服了从数据中有效估计这些算子谱的挑战。这种动态定制的基函数能够提供算子作用的精确近似和一个近似不变的子空间，有助于深入理解复杂非线性动力系统。", "keywords": "Koopman算子, 转移算子, 不变子空间, 机器学习, 动力系统", "comments": "这篇论文的创新点在于将机器学习应用于Koopman和转移算子的近似，特别是通过学习“动态定制”的正交基函数。这提供了一种有效且精确的方法来处理复杂非线性系统的线性化表示，对于理解系统动力学和预测行为具有重要意义。其方法的动态适应性是关键优势。"}}
{"id": "2507.23110", "title": "Rethink Domain Generalization in Heterogeneous Sequence MRI Segmentation", "authors": ["Zheyuan Zhang", "Linkai Peng", "Wanying Dou", "Cuiling Sun", "Halil Ertugrul Aktas", "Andrea M. Bejar", "Elif Keles", "Gorkem Durak", "Ulas Bagci"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23110v1", "summary": "Clinical magnetic-resonance (MR) protocols generate many T1 and T2 sequences\nwhose appearance differs more than the acquisition sites that produce them.\nExisting domain-generalization benchmarks focus almost on cross-center shifts\nand overlook this dominant source of variability. Pancreas segmentation remains\na major challenge in abdominal imaging: the gland is small, irregularly,\nsurrounded by organs and fat, and often suffers from low T1 contrast.\nState-of-the-art deep networks that already achieve >90% Dice on the liver or\nkidneys still miss 20-30% of the pancreas. The organ is also systematically\nunder-represented in public cross-domain benchmarks, despite its clinical\nimportance in early cancer detection, surgery, and diabetes research. To close\nthis gap, we present PancreasDG, a large-scale multi-center 3D MRI pancreas\nsegmentation dataset for investigating domain generalization in medical\nimaging. The dataset comprises 563 MRI scans from six institutions, spanning\nboth venous phase and out-of-phase sequences, enabling study of both\ncross-center and cross-sequence variations with pixel-accurate pancreas masks\ncreated by a double-blind, two-pass protocol. Through comprehensive analysis,\nwe reveal three insights: (i) limited sampling introduces significant variance\nthat may be mistaken for distribution shifts, (ii) cross-center performance\ncorrelates with source domain performance for identical sequences, and (iii)\ncross-sequence shifts require specialized solutions. We also propose a\nsemi-supervised approach that leverages anatomical invariances, significantly\noutperforming state-of-the-art domain generalization techniques with 61.63%\nDice score improvements and 87.00% on two test centers for cross-sequence\nsegmentation. PancreasDG sets a new benchmark for domain generalization in\nmedical imaging. Dataset, code, and models will be available at\nhttps://pancreasdg.netlify.app.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23110v1", "cate": "eess.IV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "重新思考异构序列MRI分割中的域泛化", "tldr": "现有域泛化基准忽略了MRI序列异构性带来的主要变异源。本文提出了PancreasDG数据集，用于研究跨中心和跨序列的胰腺MRI分割域泛化问题，并提出了一种半监督方法，显著提高了跨序列分割性能。", "motivation": "现有的域泛化基准主要关注跨中心差异，却忽视了临床MRI协议中T1和T2序列外观差异这一主要的变异来源。胰腺分割在腹部成像中仍是一大挑战，其器官小、形状不规则、对比度低，且在现有公开跨域基准中代表性不足，尽管其在癌症早期检测、手术和糖尿病研究中具有重要的临床意义。", "method": "研究团队提出了PancreasDG，一个大规模多中心3D MRI胰腺分割数据集，包含来自六个机构的563个MRI扫描，涵盖静脉期和异相序列，旨在研究跨中心和跨序列的变异。数据集通过双盲、两遍协议创建了像素级精确的胰腺掩膜。此外，研究还提出了一种利用解剖学不变性的半监督方法。", "result": "通过全面分析，研究揭示了三点洞察：(i) 有限采样引入了可能被误认为是分布偏移的显著方差；(ii) 相同序列的跨中心性能与源域性能相关；(iii) 跨序列偏移需要专门的解决方案。所提出的半监督方法显著优于现有最先进的域泛化技术，在跨序列分割上实现了61.63%的Dice分数提升，并在两个测试中心达到了87.00%的Dice分数。", "conclusion": "PancreasDG为医学影像领域的域泛化研究设定了新的基准。研究强调了跨序列变异的重要性，并证明了专门解决方案的有效性。", "translation": "临床磁共振（MR）协议会生成许多T1和T2序列，其外观差异甚至大于产生它们的采集站点。现有的域泛化基准几乎都集中在跨中心偏移上，而忽略了这种主要的变异来源。胰腺分割仍然是腹部成像中的一个主要挑战：胰腺小、形状不规则、周围有器官和脂肪，并且通常T1对比度较低。最先进的深度网络在肝脏或肾脏上已达到90%以上的Dice分数，但在胰腺上仍有20-30%的遗漏。尽管胰腺在癌症早期检测、手术和糖尿病研究中具有临床重要性，但在公共跨域基准中，该器官系统性地代表性不足。为了弥补这一差距，我们提出了PancreasDG，一个用于研究医学影像中域泛化的大规模多中心3D MRI胰腺分割数据集。该数据集包含来自六个机构的563个MRI扫描，涵盖静脉期和异相序列，能够研究跨中心和跨序列的变异，并通过双盲、两遍协议创建了像素级精确的胰腺掩膜。通过全面分析，我们揭示了三个见解：(i) 有限采样引入了可能被误认为是分布偏移的显著方差；(ii) 相同序列的跨中心性能与源域性能相关；(iii) 跨序列偏移需要专门的解决方案。我们还提出了一种利用解剖学不变性的半监督方法，其性能显著优于最先进的域泛化技术，在两个测试中心的跨序列分割中，Dice分数提高了61.63%，达到87.00%。PancreasDG为医学影像中的域泛化设定了新的基准。数据集、代码和模型将可在https://pancreasdg.netlify.app获取。", "summary": "本论文重新审视了医学影像中域泛化的问题，特别指出现有研究忽视了MRI序列异构性（如T1和T2）带来的主要变异。针对胰腺分割的挑战，研究提出了PancreasDG数据集，这是一个大规模多中心3D MRI胰腺分割数据集，包含跨中心和跨序列的变异数据。通过对该数据集的分析，论文揭示了有限采样引入的方差以及跨序列偏移需要专门解决方案的见解。此外，论文提出了一种利用解剖学不变性的半监督方法，在跨序列胰腺分割任务上显著超越了现有最先进的域泛化技术，并为医学影像域泛化研究树立了新基准。", "keywords": "域泛化, MRI分割, 胰腺, 异构序列, 医学影像", "comments": "该论文通过引入PancreasDG数据集，填补了医学影像领域在研究跨序列变异性方面的空白，这一点是其主要创新点。它强调了现有域泛化基准的不足，并为更真实的临床应用场景提供了研究资源。提出的半监督方法在处理异构序列数据方面表现出色，为未来的域泛化研究提供了有价值的方向。PancreasDG的开源性也极大地促进了社区的进步。"}}
{"id": "2503.22688", "title": "CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation", "authors": ["Peiding Wang", "Li Zhang", "Fang Liu", "Lin Shi", "Minxiao Li", "Bo Shen", "An Fu"], "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.22688v3", "summary": "Large Language Models (LLMs) have demonstrated exceptional performance in\ncode generation tasks and have become indispensable programming assistants for\ndevelopers. However, existing code generation benchmarks primarily assess the\nfunctional correctness of code generated by LLMs in single-turn interactions.\nThey offer limited insight into LLMs' abilities to generate code that strictly\nfollows users' instructions in multi-turn interaction scenarios. In this paper,\nwe introduce CodeIF-Bench, a benchmark for evaluating the instruction-following\ncapabilities of LLMs in interactive code generation. Specifically, CodeIF-Bench\nincorporates nine types of verifiable instructions aligned with the real-world\nsoftware development requirements, which can be independently and objectively\nvalidated through specified test cases, facilitating the evaluation of\ninstruction-following capability in multi-turn interactions. In both\n\\textit{Static Conversation} and \\textit{Dynamic Conversation} settings, we\nevaluate the performance of 7 state-of-the-art LLMs and summarize the important\nfactors influencing the instruction-following ability of LLMs in multi-turn\ninteractions, as well as potential directions for improvement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.22688v3", "cate": "cs.SE", "date": "2025-03-05", "updated": "2025-07-31", "AI": {"title_translation": "CodeIF-Bench：评估大型语言模型在交互式代码生成中的指令遵循能力", "tldr": "现有代码生成基准主要评估单轮交互中的功能正确性。本文引入了CodeIF-Bench，这是一个用于评估大型语言模型在多轮交互式代码生成中指令遵循能力的基准，并总结了影响LLM指令遵循能力的重要因素和改进方向。", "motivation": "现有代码生成基准主要评估大型语言模型在单轮交互中生成代码的功能正确性，但对LLM在多轮交互场景中严格遵循用户指令的能力了解有限。", "method": "本文引入了CodeIF-Bench，这是一个用于评估LLM在交互式代码生成中指令遵循能力的基准。CodeIF-Bench包含了九种可验证的指令类型，这些指令与真实世界的软件开发需求对齐，可以通过指定的测试用例进行独立客观验证。该基准在“静态对话”和“动态对话”设置下评估了7个最先进的LLM的性能。", "result": "评估了7个最先进的大型语言模型，并总结了影响LLM在多轮交互中指令遵循能力的重要因素以及潜在的改进方向。", "conclusion": "本文通过CodeIF-Bench基准评估了LLM在多轮交互式代码生成中遵循指令的能力，并识别了影响这一能力的关键因素及未来的改进方向，为提升LLM作为编程助手的实用性提供了见解。", "translation": "大型语言模型（LLMs）在代码生成任务中表现出色，并已成为开发人员不可或缺的编程助手。然而，现有的代码生成基准主要评估LLMs在单轮交互中生成代码的功能正确性。它们对LLMs在多轮交互场景中严格遵循用户指令的能力提供的洞察有限。在本文中，我们引入了CodeIF-Bench，一个用于评估LLMs在交互式代码生成中指令遵循能力的基准。具体来说，CodeIF-Bench包含了九种与真实世界软件开发需求对齐的可验证指令类型，这些指令可以通过指定的测试用例进行独立和客观的验证，从而促进了多轮交互中指令遵循能力的评估。在“静态对话”和“动态对话”设置下，我们评估了7个最先进的LLMs的性能，并总结了影响LLMs在多轮交互中指令遵循能力的重要因素以及潜在的改进方向。", "summary": "本文针对现有代码生成基准在评估大型语言模型多轮交互中指令遵循能力方面的不足，提出了CodeIF-Bench。该基准包含九种可验证的指令类型，与实际开发需求对齐，并通过指定测试用例进行客观验证。研究在静态和动态对话设置下评估了7个主流LLM，并分析了影响其指令遵循能力的关键因素及改进方向，旨在提升LLM在交互式代码生成中的实用性。", "keywords": "大型语言模型, 代码生成, 指令遵循, 基准测试, 多轮交互", "comments": "CodeIF-Bench的创新之处在于其专注于评估LLM在多轮交互式代码生成中的指令遵循能力，填补了现有基准的空白。这对于提升LLM作为编程助手的实际可用性至关重要，因为它更贴近真实世界的软件开发场景。该研究通过识别影响因素和改进方向，为未来LLM的发展提供了宝贵的指导。"}}
{"id": "2507.23358", "title": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "authors": ["Renato Vukovic", "Carel van Niekerk", "Michael Heck", "Benjamin Ruppik", "Hsien-Chin Lin", "Shutong Feng", "Nurul Lubis", "Milica Gasic"], "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23358v1", "summary": "Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23358v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "文本到SQL面向任务对话本体构建", "tldr": "TeQoDO是一种无监督方法，利用大型语言模型的SQL能力和对话理论，从零开始构建面向任务对话本体，表现优于迁移学习，并有助于提高LLM的可解释性。", "motivation": "大型语言模型（LLMs）依赖参数化知识，限制了其可解释性和可信度。面向任务对话（TOD）系统通过外部数据库和显式本体结构来确保可解释性和可控性，但构建这些本体需要手动标注或监督训练，这是一个挑战。", "method": "本文引入了TeQoDO方法：一种文本到SQL面向任务对话本体构建方法。该方法利用大型语言模型固有的SQL编程能力，结合提示中提供的对话理论，无需监督地从零开始自主构建TOD本体。", "result": "TeQoDO方法优于迁移学习方法，其构建的本体在下游对话状态跟踪任务上具有竞争力。消融研究表明对话理论起着关键作用。TeQoDO还能扩展以构建更大的本体，并在Wikipedia和ArXiv数据集上进行了验证。", "conclusion": "本文将TeQoDO视为向更广泛应用本体迈出的一步，以提高大型语言模型的可解释性。", "translation": "大型语言模型（LLMs）被广泛用作通用知识来源，但它们依赖于参数化知识，限制了可解释性和可信度。在面向任务对话（TOD）系统中，这种分离是明确的，通过外部数据库以及由显式本体结构来确保可解释性和可控性。然而，构建此类本体需要手动标注或监督训练。我们引入了TeQoDO：一种文本到SQL面向任务对话本体构建方法。在此方法中，LLM利用其固有的SQL编程能力结合提示中提供的对话理论，无需监督地从零开始自主构建TOD本体。我们展示了TeQoDO优于迁移学习方法，并且其构建的本体在下游对话状态跟踪任务上具有竞争力。消融研究表明对话理论的关键作用。TeQoDO还能扩展以允许构建更大的本体，我们在一项Wikipedia和ArXiv数据集上进行了研究。我们认为这是朝着更广泛应用本体以提高LLM可解释性迈出的一步。", "summary": "TeQoDO是一种创新的无监督方法，利用大型语言模型的SQL编程能力和对话理论，自主构建面向任务对话（TOD）本体。它旨在解决LLM可解释性不足以及现有本体构建方法对手动标注或监督训练的依赖问题。实验证明，TeQoDO在性能上超越了传统的迁移学习方法，并且其生成的本体在对话状态跟踪任务上表现出色，同时具备良好的可扩展性。这项工作为提高LLM的可解释性提供了新的途径。", "keywords": "文本到SQL, 面向任务对话, 本体构建, 大型语言模型, 可解释性", "comments": "TeQoDO的创新之处在于利用大型语言模型固有的SQL能力，结合对话理论，实现了无需监督的本体构建。这有效地解决了传统方法中对大量手动标注或监督训练的依赖，极大地降低了构建成本和复杂性。其在提高LLM可解释性方面的潜力以及良好的可扩展性，使其在面向任务对话系统领域具有重要意义。"}}
{"id": "2507.23569", "title": "Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization", "authors": ["Maxime Pietrantoni", "Gabriela Csurka", "Torsten Sattler"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025", "url": "http://arxiv.org/abs/2507.23569v1", "summary": "Visual localization is the task of estimating a camera pose in a known\nenvironment. In this paper, we utilize 3D Gaussian Splatting (3DGS)-based\nrepresentations for accurate and privacy-preserving visual localization. We\npropose Gaussian Splatting Feature Fields (GSFFs), a scene representation for\nvisual localization that combines an explicit geometry model (3DGS) with an\nimplicit feature field. We leverage the dense geometric information and\ndifferentiable rasterization algorithm from 3DGS to learn robust feature\nrepresentations grounded in 3D. In particular, we align a 3D scale-aware\nfeature field and a 2D feature encoder in a common embedding space through a\ncontrastive framework. Using a 3D structure-informed clustering procedure, we\nfurther regularize the representation learning and seamlessly convert the\nfeatures to segmentations, which can be used for privacy-preserving visual\nlocalization. Pose refinement, which involves aligning either feature maps or\nsegmentations from a query image with those rendered from the GSFFs scene\nrepresentation, is used to achieve localization. The resulting privacy- and\nnon-privacy-preserving localization pipelines, evaluated on multiple real-world\ndatasets, show state-of-the-art performances.", "comment": "CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.23569v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "高斯泼溅特征场用于隐私保护视觉定位", "tldr": "GSFFs利用3D高斯泼溅和特征场实现准确且隐私保护的视觉定位，并在真实世界数据集上达到最先进性能。", "motivation": "在已知环境中实现准确且隐私保护的视觉定位。", "method": "该论文提出了高斯泼溅特征场（GSFFs），这是一种将显式几何模型（3DGS）与隐式特征场结合的场景表示。它利用3DGS的密集几何信息和可微分光栅化算法学习鲁棒的3D特征表示，并通过对比框架将3D尺度感知特征场和2D特征编码器对齐到共同的嵌入空间。此外，使用3D结构引导的聚类过程来正则化表示学习，并将特征无缝转换为分割，用于隐私保护视觉定位。定位通过姿态优化实现，即对齐查询图像的特征图或分割与GSFFs场景表示渲染出的结果。", "result": "在多个真实世界数据集上评估，所提出的隐私保护和非隐私保护定位管线均显示出最先进的性能。", "conclusion": "本文提出的基于高斯泼溅特征场的视觉定位方法，无论是隐私保护还是非隐私保护模式，都在真实世界数据集上达到了最先进的性能，证明了其有效性和鲁棒性。", "translation": "视觉定位是在已知环境中估计相机姿态的任务。在本文中，我们利用基于3D高斯泼溅（3DGS）的表示来实现准确且隐私保护的视觉定位。我们提出了高斯泼溅特征场（GSFFs），这是一种用于视觉定位的场景表示，它结合了显式几何模型（3DGS）与隐式特征场。我们利用3DGS的密集几何信息和可微分光栅化算法来学习基于3D的鲁棒特征表示。特别是，我们通过对比框架在共同的嵌入空间中对齐3D尺度感知特征场和2D特征编码器。使用3D结构引导的聚类过程，我们进一步正则化表示学习，并将特征无缝转换为分割，这可用于隐私保护视觉定位。姿态优化，涉及将查询图像的特征图或分割与从GSFFs场景表示渲染出的结果对齐，用于实现定位。所产生的隐私保护和非隐私保护定位管线，在多个真实世界数据集上进行了评估，显示出最先进的性能。", "summary": "本文提出高斯泼溅特征场（GSFFs），一种结合3D高斯泼溅和隐式特征场的视觉定位场景表示。GSFFs利用3DGS的几何信息和可微分光栅化来学习鲁棒的3D特征，并通过对比学习对齐3D和2D特征。通过3D结构引导的聚类，特征可转换为分割，从而实现隐私保护的视觉定位。该方法通过对齐查询图像特征或分割与GSFFs渲染结果进行姿态优化，在隐私保护和非隐私保护模式下均在多个真实世界数据集上实现了最先进的定位性能。", "keywords": "视觉定位, 3D高斯泼溅, 特征场, 隐私保护, 场景表示", "comments": "该论文的创新点在于将3D高斯泼溅与特征场结合，创建了一种新颖的场景表示，能够同时实现高精度和隐私保护的视觉定位。通过将特征转换为分割来实现隐私保护定位是一个重要的贡献，为实际应用提供了新的可能性。"}}
{"id": "2506.07106", "title": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "authors": ["Samir Abdaljalil", "Hasan Kurban", "Khalid Qaraqe", "Erchin Serpedin"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 KnowFM", "url": "http://arxiv.org/abs/2506.07106v2", "summary": "Large language models (LLMs) have shown strong performance across natural\nlanguage reasoning tasks, yet their reasoning processes remain brittle and\ndifficult to interpret. Prompting techniques like Chain-of-Thought (CoT)\nenhance reliability by eliciting intermediate reasoning steps or aggregating\nmultiple outputs. However, they lack mechanisms for enforcing logical structure\nand assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a\nnovel framework that models reasoning as collaboration among three parallel\nagents, each simulating a distinct mode of inference: abductive, deductive, and\ninductive. Each agent produces a reasoning trace, which is structured into a\nformal reasoning graph. To evaluate consistency, we apply Bayesian belief\npropagation guided by natural language inference (NLI), assigning confidence\nscores to each step. The most coherent graph is selected to derive the final\nanswer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)\nreasoning benchmarks show that ToTh consistently outperforms CoT,\nSelf-Consistency, and CoT-Decoding across multiple LLMs, while producing\ninterpretable and logically grounded reasoning chains. Our findings suggest a\npromising direction for building more robust and cognitively inspired LLM\nreasoning. The implementation is available at\nhttps://github.com/KurbanIntelligenceLab/theorem-of-thought.", "comment": "ACL 2025 KnowFM", "pdf_url": "http://arxiv.org/pdf/2506.07106v2", "cate": "cs.CL", "date": "2025-06-08", "updated": "2025-07-31", "AI": {"title_translation": "思维定理：一种用于语言模型中溯因、演绎和归纳推理的多智能体框架", "tldr": "大型语言模型（LLM）的推理过程脆弱且难以解释。本文提出了思维定理（ToTh），一个新颖的多智能体框架，通过模拟溯因、演绎和归纳三种推理模式，将推理结构化为形式化的推理图，并利用NLI引导的贝叶斯信念传播评估一致性。实验表明，ToTh在推理任务上显著优于现有方法，并能生成可解释的逻辑推理链。", "motivation": "大型语言模型（LLM）在自然语言推理任务中表现出色，但其推理过程脆弱且难以解释。现有的提示技术（如思维链CoT）虽然提高了可靠性，但缺乏强制执行逻辑结构和评估内部一致性的机制。", "method": "本文引入了思维定理（ToTh）框架，将推理建模为三个并行智能体（分别模拟溯因、演绎和归纳推理）之间的协作。每个智能体生成一个推理轨迹，并将其结构化为形式化的推理图。通过自然语言推理（NLI）引导的贝叶斯信念传播来评估推理图的一致性，并为每个步骤分配置信度分数。最终选择最连贯的图来得出答案。", "result": "在符号（WebOfLies）和数值（MultiArith）推理基准上的实验表明，ToTh在多个LLM上始终优于CoT、自洽性（Self-Consistency）和CoT-解码等方法。同时，ToTh能够产生可解释且逻辑严谨的推理链。", "conclusion": "ToTh为构建更鲁棒和受认知启发的LLM推理提供了一个有前景的方向。", "translation": "大型语言模型（LLM）在自然语言推理任务中表现出色，但其推理过程仍然脆弱且难以解释。像思维链（CoT）这样的提示技术通过引出中间推理步骤或聚合多个输出来提高可靠性。然而，它们缺乏强制执行逻辑结构和评估内部一致性的机制。我们引入了思维定理（ToTh），一个新颖的框架，它将推理建模为三个并行智能体之间的协作，每个智能体模拟一种独特的推理模式：溯因、演绎和归纳。每个智能体生成一个推理轨迹，该轨迹被构建成一个形式化的推理图。为了评估一致性，我们应用由自然语言推理（NLI）引导的贝叶斯信念传播，为每个步骤分配置信度分数。选择最连贯的图来得出最终答案。在符号（WebOfLies）和数值（MultiArith）推理基准上的实验表明，ToTh在多个LLM上始终优于CoT、自洽性（Self-Consistency）和CoT-解码，同时产生可解释且逻辑严谨的推理链。我们的研究结果为构建更鲁棒和受认知启发的LLM推理提供了一个有前景的方向。实现代码可在https://github.com/KurbanIntelligenceLab/theorem-of-thought 获得。", "summary": "本文提出了思维定理（ToTh），一个新颖的多智能体框架，旨在提高大型语言模型（LLM）推理的鲁棒性和可解释性。与缺乏逻辑结构强制的现有方法（如思维链CoT）不同，ToTh将推理建模为溯因、演绎和归纳智能体之间的协作。每个智能体生成一个形式化推理图的轨迹，其一致性通过NLI引导的贝叶斯信念传播进行评估。在符号和数值推理基准上的实验结果表明，ToTh在各种LLM上始终优于基于CoT的方法，产生可解释且逻辑严谨的推理链，从而为更鲁棒的LLM推理提供了一种有前景的方法。", "keywords": "语言模型, 多智能体系统, 推理, 思维定理, 可解释性", "comments": "这篇论文提出了一种创新方法，通过在LLM的多智能体框架中明确建模不同的推理模式（溯因、演绎、归纳）。利用形式化推理图和NLI引导的贝叶斯信念传播进行一致性检查，是相对于简单提示技术的重大进步。该框架不仅提高了性能，还增强了LLM推理的可解释性和逻辑基础，解决了当前方法的关键局限性。它朝着更具认知启发的AI推理迈进。"}}
{"id": "2507.22898", "title": "Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment", "authors": ["Julian Acosta", "Scott Adams", "Julius Kernbach", "Romain Hardy", "Sung Eun Kim", "Luyang Luo", "Xiaoman Zhang", "Shreya Johri", "Mohammed Baharoon", "Pranav Rajpurkar"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22898v1", "summary": "We developed a voice-driven artificial intelligence (AI) system that guides\nanyone - from paramedics to family members - through expert-level stroke\nevaluations using natural conversation, while also enabling smartphone video\ncapture of key examination components for documentation and potential expert\nreview. This addresses a critical gap in emergency care: current stroke\nrecognition by first responders is inconsistent and often inaccurate, with\nsensitivity for stroke detection as low as 58%, causing life-threatening delays\nin treatment. Three non-medical volunteers used our AI system to assess ten\nsimulated stroke patients, including cases with likely large vessel occlusion\n(LVO) strokes and stroke-like conditions, while we measured diagnostic\naccuracy, completion times, user confidence, and expert physician review of the\nAI-generated reports. The AI system correctly identified 84% of individual\nstroke signs and detected 75% of likely LVOs, completing evaluations in just\nover 6 minutes. Users reported high confidence (median 4.5/5) and ease of use\n(mean 4.67/5). The system successfully identified 86% of actual strokes but\nalso incorrectly flagged 2 of 3 non-stroke cases as strokes. When an expert\nphysician reviewed the AI reports with videos, they identified the correct\ndiagnosis in 100% of cases, but felt confident enough to make preliminary\ntreatment decisions in only 40% of cases due to observed AI errors including\nincorrect scoring and false information. While the current system's limitations\nnecessitate human oversight, ongoing rapid advancements in speech-to-speech AI\nmodels suggest that future versions are poised to enable highly accurate\nassessments. Achieving human-level voice interaction could transform emergency\nmedical care, putting expert-informed assessment capabilities in everyone's\nhands.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22898v1", "cate": "cs.HC", "date": "2025-06-25", "updated": "2025-06-25", "AI": {"title_translation": "语音引导的临床评估协调智能 (VOICE)：一个用于院前卒中评估的语音人工智能代理系统", "tldr": "VOICE是一个语音驱动的AI系统，旨在通过自然对话和视频捕捉，指导非专业人员进行院前卒中评估，以提高诊断准确性和效率，尽管目前仍需人工监督。", "motivation": "目前的急诊护理中，急救人员对卒中的识别不一致且不准确，敏感性低至58%，导致治疗延误，危及生命。本文旨在解决这一关键空白。", "method": "开发了一个名为VOICE的语音驱动AI系统，该系统通过自然对话指导用户进行专家级卒中评估，并支持智能手机视频捕捉关键检查组件。使用三名非医学志愿者对十名模拟卒中患者（包括可能的大血管闭塞性卒中和类卒中情况）进行评估，测量诊断准确性、完成时间、用户信心，并由专家医生审查AI生成的报告。", "result": "AI系统正确识别了84%的个体卒中体征，检测出75%的可能大血管闭塞性卒中，评估完成时间略超过6分钟。用户报告高信心（中位数4.5/5）和易用性（平均4.67/5）。系统成功识别了86%的实际卒中，但也错误地将3个非卒中病例中的2个标记为卒中。当专家医生审查AI报告和视频时，100%的病例得到了正确诊断，但由于观察到的AI错误（包括错误评分和虚假信息），仅在40%的病例中对初步治疗决策有足够信心。", "conclusion": "尽管当前系统存在局限性，需要人工监督，但语音到语音AI模型的快速发展预示着未来版本将能够实现高度准确的评估。实现人机级语音交互可以改变紧急医疗护理，使专家知情的评估能力普及。", "translation": "我们开发了一个语音驱动的人工智能（AI）系统，该系统能够通过自然对话指导任何人——从急救人员到家庭成员——进行专家级卒中评估，同时还支持智能手机视频捕捉关键检查组件，用于记录和潜在的专家审查。这解决了急诊护理中的一个关键空白：目前急救人员对卒中的识别不一致且经常不准确，卒中检测的敏感性低至58%，导致危及生命的治疗延误。三名非医学志愿者使用我们的AI系统评估了十名模拟卒中患者，包括可能的大血管闭塞（LVO）卒中和类卒中情况，同时我们测量了诊断准确性、完成时间、用户信心，以及专家医生对AI生成报告的审查。该AI系统正确识别了84%的个体卒中体征，检测出75%的可能LVO，评估在6分钟多一点的时间内完成。用户报告高信心（中位数4.5/5）和易用性（平均4.67/5）。该系统成功识别了86%的实际卒中，但也错误地将3个非卒中病例中的2个标记为卒中。当专家医生审查带有视频的AI报告时，他们在100%的病例中识别出正确诊断，但由于观察到的AI错误，包括错误评分和虚假信息，仅在40%的病例中对初步治疗决策有足够的信心。尽管当前系统的局限性需要人工监督，但语音到语音AI模型的持续快速发展表明，未来版本有望实现高度准确的评估。实现人机级语音交互可以改变紧急医疗护理，将专家知情的评估能力普及到每个人手中。", "summary": "本文介绍了一个名为VOICE的语音驱动AI系统，旨在通过自然对话和智能手机视频捕捉，指导非专业人员（如急救人员或家庭成员）进行院前卒中评估，以解决当前卒中识别不准确的问题。系统在模拟测试中表现出较高的卒中体征识别率（84%）和LVO检测率（75%），用户反馈信心高、易用性强。然而，系统存在误报非卒中病例和报告错误，导致专家医生虽能最终诊断，但对基于AI报告的初步治疗决策信心不足。研究指出，尽管当前版本需人工监督，但未来语音AI技术进步有望实现高度准确的评估，从而革新紧急医疗护理。", "keywords": "卒中评估, 语音AI, 院前护理, 人工智能, 紧急医疗", "comments": "VOICE系统在利用语音AI和视频捕捉方面具有创新性，旨在弥补院前卒中评估的不足。其重要性在于能够将专家级评估能力普及给非专业人员，有望显著缩短治疗延误。然而，研究也明确指出了当前系统的局限性，例如误报率和报告准确性问题，这强调了在实际应用中人工监督的必要性。尽管如此，该研究展望了未来AI进步带来的巨大潜力，为紧急医疗护理的智能化提供了有益的探索。"}}
{"id": "2507.23646", "title": "Information geometry of Lévy processes and financial models", "authors": ["Jaehyung Choi"], "categories": ["stat.TH", "cs.IT", "math.DG", "math.IT", "math.PR", "q-fin.MF"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2507.23646v1", "summary": "We explore the information geometry of L\\'evy processes. As a starting point,\nwe derive the $\\alpha$-divergence between two L\\'evy processes. Subsequently,\nthe Fisher information matrix and the $\\alpha$-connection associated with the\ngeometry of L\\'evy processes are computed from the $\\alpha$-divergence. In\naddition, we discuss statistical applications of this information geometry. As\nillustrative examples, we investigate the differential-geometric structures of\nvarious L\\'evy processes relevant to financial modeling, including tempered\nstable processes, the CGMY model, and variance gamma processes.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2507.23646v1", "cate": "stat.TH", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Lévy 过程和金融模型的信息几何", "tldr": "本文探讨了Lévy过程的信息几何，推导了Lévy过程之间的α-散度，并计算了费雪信息矩阵和α-联络，最后将其应用于金融模型。", "motivation": "探索Lévy过程的信息几何，并将其应用于金融建模中的相关Lévy过程。", "method": "首先，推导了两个Lévy过程之间的α-散度。随后，从α-散度计算了与Lévy过程几何相关的费雪信息矩阵和α-联络。此外，讨论了信息几何的统计应用，并通过示例研究了各种与金融建模相关的Lévy过程（包括缓变稳定过程、CGMY模型和方差伽马过程）的微分几何结构。", "result": "成功推导了两个Lévy过程之间的α-散度，并计算了费雪信息矩阵和α-联络。研究了缓变稳定过程、CGMY模型和方差伽马过程等金融相关Lévy过程的微分几何结构。", "conclusion": "本文成功构建了Lévy过程的信息几何框架，并通过具体金融模型展示了其应用和微分几何结构。", "translation": "我们探索了Lévy过程的信息几何。首先，我们推导了两个Lévy过程之间的α-散度。随后，从α-散度计算了与Lévy过程几何相关的费雪信息矩阵和α-联络。此外，我们讨论了这种信息几何的统计应用。作为说明性示例，我们研究了与金融建模相关的各种Lévy过程的微分几何结构，包括缓变稳定过程、CGMY模型和方差伽马过程。", "summary": "本文深入探讨了Lévy过程的信息几何，从理论上推导了Lévy过程间的α-散度，并在此基础上计算了费雪信息矩阵和α-联络。研究还讨论了信息几何的统计应用，并通过分析缓变稳定过程、CGMY模型和方差伽马过程等金融模型中常见的Lévy过程，展示了其微分几何结构。", "keywords": "Lévy过程, 信息几何, α-散度, 金融模型, 费雪信息矩阵", "comments": "本文创新性地将信息几何理论应用于Lévy过程，并进一步拓展到金融建模领域，为理解和分析复杂金融现象提供了新的数学工具和视角。"}}
{"id": "2410.09486", "title": "ActSafe: Active Exploration with Safety Constraints for Reinforcement Learning", "authors": ["Yarden As", "Bhavya Sukhija", "Lenart Treven", "Carmelo Sferrazza", "Stelian Coros", "Andreas Krause"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.09486v3", "summary": "Reinforcement learning (RL) is ubiquitous in the development of modern AI\nsystems. However, state-of-the-art RL agents require extensive, and potentially\nunsafe, interactions with their environments to learn effectively. These\nlimitations confine RL agents to simulated environments, hindering their\nability to learn directly in real-world settings. In this work, we present\nActSafe, a novel model-based RL algorithm for safe and efficient exploration.\nActSafe learns a well-calibrated probabilistic model of the system and plans\noptimistically w.r.t. the epistemic uncertainty about the unknown dynamics,\nwhile enforcing pessimism w.r.t. the safety constraints. Under regularity\nassumptions on the constraints and dynamics, we show that ActSafe guarantees\nsafety during learning while also obtaining a near-optimal policy in finite\ntime. In addition, we propose a practical variant of ActSafe that builds on\nlatest model-based RL advancements and enables safe exploration even in\nhigh-dimensional settings such as visual control. We empirically show that\nActSafe obtains state-of-the-art performance in difficult exploration tasks on\nstandard safe deep RL benchmarks while ensuring safety during learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.09486v3", "cate": "cs.LG", "date": "2024-10-12", "updated": "2025-07-31", "AI": {"title_translation": "ActSafe：具有安全约束的强化学习主动探索", "tldr": "ActSafe是一种新的模型基强化学习算法，能在保证安全的同时高效探索，并在有限时间内获得近乎最优的策略。", "motivation": "现有的强化学习算法需要大量且可能不安全的交互才能有效学习，这限制了它们在真实世界中的应用。", "method": "本文提出了ActSafe，一种新颖的模型基强化学习算法，用于安全高效的探索。ActSafe学习系统的一个良好校准的概率模型，并对未知动力学的认知不确定性进行乐观规划，同时对安全约束强制执行悲观策略。此外，还提出了一个实用变体，适用于高维设置如视觉控制。", "result": "在对约束和动力学的正则性假设下，ActSafe在学习过程中保证安全性，并在有限时间内获得接近最优的策略。经验表明，ActSafe在标准安全深度强化学习基准测试中困难的探索任务中获得了最先进的性能，同时确保了学习过程中的安全性。", "conclusion": "ActSafe提供了一种在真实世界环境中进行安全且高效强化学习的解决方案，克服了传统RL在安全和效率方面的局限性，使得RL智能体能够直接在真实世界环境中学习。", "translation": "强化学习（RL）在现代AI系统的发展中无处不在。然而，最先进的RL智能体需要与其环境进行大量且可能不安全的交互才能有效学习。这些限制将RL智能体限制在模拟环境中，阻碍了它们直接在真实世界环境中学习的能力。在这项工作中，我们提出了ActSafe，一种新颖的基于模型的RL算法，用于安全高效的探索。ActSafe学习系统的一个良好校准的概率模型，并对未知动力学的认知不确定性进行乐观规划，同时对安全约束强制执行悲观策略。在对约束和动力学的正则性假设下，我们证明了ActSafe在学习过程中保证安全性，并在有限时间内获得接近最优的策略。此外，我们提出了一种ActSafe的实用变体，它建立在最新的基于模型的RL进展之上，即使在视觉控制等高维设置中也能实现安全探索。我们凭经验表明，ActSafe在标准安全深度RL基准测试中困难的探索任务中获得了最先进的性能，同时确保了学习过程中的安全性。", "summary": "本文提出了ActSafe，一种新颖的模型基强化学习算法，旨在解决现有RL算法在真实世界中学习时面临的不安全和低效探索问题。ActSafe通过学习概率模型，对未知动力学进行乐观探索，并对安全约束采取悲观策略，从而在保证学习安全性的同时，在有限时间内获得近乎最优的策略。该算法还提出了一个适用于高维环境的实用变体，并在安全深度RL基准测试中展现出最先进的性能。", "keywords": "强化学习, 安全探索, 模型基RL, 安全约束, 不确定性", "comments": "ActSafe的创新之处在于其结合了乐观探索与悲观安全策略的模型基方法，理论上保证了学习过程的安全性并达到近最优性能。这对于将强化学习应用于真实世界，尤其是对安全性要求高的领域，具有重要意义。其在高维设置下的适用性也增强了其实用性。"}}
{"id": "2507.23063", "title": "Math Natural Language Inference: this should be easy!", "authors": ["Valeria de Paiva", "Qiyue Gao", "Hai Hu", "Pavel Kovalev", "Yikang Liu", "Lawrence S. Moss", "Zhiheng Qian"], "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages plus appendices", "url": "http://arxiv.org/abs/2507.23063v1", "summary": "We ask whether contemporary LLMs are able to perform natural language\ninference (NLI) tasks on mathematical texts. We call this the Math NLI problem.\nWe construct a corpus of Math NLI pairs whose premises are from extant\nmathematical text and whose hypotheses and gold labels were provided by people\nwith experience in both research-level mathematics and also in the NLI field.\nWe also investigate the quality of corpora using the same premises but whose\nhypotheses are provided by LLMs themselves. We not only investigate the\nperformance but also the inter-group consistency of the diverse group of LLMs.\nWe have both positive and negative findings. Among our positive findings: in\nsome settings, using a majority vote of LLMs is approximately equivalent to\nusing human-labeled data in the Math NLI area. On the negative side: LLMs still\nstruggle with mathematical language. They occasionally fail at even basic\ninferences. Current models are not as prone to hypothesis-only \"inference\" in\nour data the way the previous generation had been. In addition to our findings,\nwe also provide our corpora as data to support future work on Math NLI.", "comment": "9 pages plus appendices", "pdf_url": "http://arxiv.org/pdf/2507.23063v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "数学自然语言推理：这应该很容易！", "tldr": "本文探讨了当代大型语言模型（LLMs）在数学文本自然语言推理（Math NLI）任务上的表现，构建了Math NLI语料库，并发现LLMs在某些情况下多数投票表现接近人类标注，但整体上仍难以处理数学语言，甚至在基本推理上失败。", "motivation": "研究者想探究当代大型语言模型（LLMs）是否能够对数学文本进行自然语言推理（NLI）任务，并将其定义为数学自然语言推理（Math NLI）问题。", "method": "研究者构建了一个Math NLI语料库，其前提来自现有数学文本，假设和黄金标签由具有研究级数学和NLI领域经验的人员提供。此外，他们还调查了使用相同前提但假设由LLMs自己提供的语料库质量，并分析了LLMs的性能和组间一致性。", "result": "研究结果有积极和消极两方面：积极方面是，在某些设置下，LLMs多数投票的结果近似等同于使用人类标注数据。消极方面是，LLMs在处理数学语言时仍存在困难，偶尔甚至在基本推理上也会失败。不过，当前模型在我们数据中不再像上一代那样容易出现仅基于假设的“推理”。", "conclusion": "尽管在某些特定情况下，LLMs的多数投票表现接近人类标注数据，但总体而言，当前LLMs在数学自然语言推理方面仍面临挑战，尤其是在处理数学语言和进行基本推理时。研究者提供了语料库以支持未来的Math NLI研究。", "translation": "我们探讨了当代大型语言模型（LLMs）是否能够对数学文本执行自然语言推理（NLI）任务。我们称之为数学自然语言推理（Math NLI）问题。我们构建了一个Math NLI配对语料库，其前提来自现有的数学文本，假设和黄金标签由具有研究级数学和NLI领域经验的人员提供。我们还调查了使用相同前提但假设由LLMs自己提供的语料库的质量。我们不仅研究了性能，还研究了不同LLMs群体之间的组间一致性。我们有积极和消极的发现。在我们的积极发现中：在某些设置下，使用LLMs多数投票的结果近似等同于在Math NLI领域使用人类标注数据。消极方面是：LLMs仍然难以处理数学语言。它们偶尔甚至在基本推理上也会失败。当前模型在我们的数据中不像上一代那样容易出现仅基于假设的“推理”。除了我们的发现，我们还提供我们的语料库作为数据，以支持未来在Math NLI方面的工作。", "summary": "本文探讨了大型语言模型（LLMs）在数学自然语言推理（Math NLI）任务上的能力。研究团队构建了一个Math NLI语料库，并评估了LLMs的表现，包括其性能和不同模型间的内部一致性。结果显示，LLMs在某些情况下通过多数投票可达到接近人类标注的水平，但在处理数学语言和进行基本推理时仍显不足。研究还提供了构建的语料库以促进该领域的未来研究。", "keywords": "数学自然语言推理, LLMs, 语料库, 数学文本, 推理能力", "comments": "这篇论文创新性地提出了“Math NLI”问题，并构建了相应的语料库，这对于推动LLMs在专业领域，特别是数学领域的理解能力研究具有重要意义。其发现揭示了LLMs在处理特定领域语言时的局限性，并指出了未来研究的方向。"}}
{"id": "2506.12284", "title": "GrokAlign: Geometric Characterisation and Acceleration of Grokking", "authors": ["Thomas Walker", "Ahmed Imtiaz Humayun", "Randall Balestriero", "Richard Baraniuk"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 11 figures, 3 tables", "url": "http://arxiv.org/abs/2506.12284v2", "summary": "A key challenge for the machine learning community is to understand and\naccelerate the training dynamics of deep networks that lead to delayed\ngeneralisation and emergent robustness to input perturbations, also known as\ngrokking. Prior work has associated phenomena like delayed generalisation with\nthe transition of a deep network from a linear to a feature learning regime,\nand emergent robustness with changes to the network's functional geometry, in\nparticular the arrangement of the so-called linear regions in deep networks\nemploying continuous piecewise affine nonlinearities. Here, we explain how\ngrokking is realised in the Jacobian of a deep network and demonstrate that\naligning a network's Jacobians with the training data (in the sense of cosine\nsimilarity) ensures grokking under a low-rank Jacobian assumption. Our results\nprovide a strong theoretical motivation for the use of Jacobian regularisation\nin optimizing deep networks -- a method we introduce as GrokAlign -- which we\nshow empirically to induce grokking much sooner than more conventional\nregularizers like weight decay. Moreover, we introduce centroid alignment as a\ntractable and interpretable simplification of Jacobian alignment that\neffectively identifies and tracks the stages of deep network training dynamics.\nAccompanying webpage (https://thomaswalker1.github.io/blog/grokalign.html) and\ncode (https://github.com/ThomasWalker1/grokalign).", "comment": "23 pages, 11 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2506.12284v2", "cate": "cs.LG", "date": "2025-06-14", "updated": "2025-07-31", "AI": {"title_translation": "GrokAlign：Grokking 的几何表征与加速", "tldr": "本文解释了深度网络中 Grokking 现象的雅可比实现，并引入 GrokAlign（雅可比正则化）来加速 Grokking，通过对雅可比矩阵与训练数据进行对齐。", "motivation": "机器学习社区面临的一个关键挑战是理解并加速导致延迟泛化和对输入扰动产生鲁棒性的深度网络训练动态，即 Grokking 现象。", "method": "1. 解释 Grokking 如何在深度网络的雅可比矩阵中实现。2. 证明将网络的雅可比矩阵与训练数据对齐（通过余弦相似度）可以在低秩雅可比假设下确保 Grokking。3. 引入 GrokAlign 方法，即雅可比正则化，用于优化深度网络。4. 引入质心对齐作为雅可比对齐的一个可处理且可解释的简化，用于识别和跟踪深度网络训练动态的阶段。", "result": "1. 理论上证明了将网络的雅可比矩阵与训练数据对齐可以在低秩雅可比假设下确保 Grokking。2. GrokAlign（雅可比正则化）在经验上显示出比传统正则化器（如权重衰减）更快地诱导 Grokking。3. 质心对齐能够有效地识别和跟踪深度网络训练动态的阶段。", "conclusion": "本文为在深度网络优化中使用雅可比正则化（GrokAlign）提供了强有力的理论依据，并经验性地证明其能显著加速 Grokking 现象的发生。", "translation": "机器学习社区面临的一个关键挑战是理解和加速深度网络的训练动态，这些动态会导致延迟泛化和对输入扰动的涌现鲁棒性，也称为 Grokking 现象。先前的研究将延迟泛化等现象与深度网络从线性到特征学习阶段的转变联系起来，并将涌现鲁棒性与网络功能几何的变化联系起来，特别是采用连续分段仿射非线性的深度网络中所谓线性区域的排列。在此，我们解释了 Grokking 如何在深度网络的雅可比矩阵中实现，并证明在低秩雅可比假设下，将网络的雅可比矩阵与训练数据对齐（在余弦相似度意义上）可以确保 Grokking。我们的结果为在优化深度网络时使用雅可比正则化（我们将其引入为 GrokAlign 方法）提供了强有力的理论动机——我们通过经验证明，该方法比传统的正则化器（如权重衰减）更快地诱导 Grokking。此外，我们引入了质心对齐作为雅可比对齐的一个可处理且可解释的简化，它能有效地识别和跟踪深度网络训练动态的阶段。随附网页 (https://thomaswalker1.github.io/blog/grokalign.html) 和代码 (https://github.com/ThomasWalker1/grokalign)。", "summary": "本文深入探讨了深度学习中的 Grokking 现象，解释了其在网络雅可比矩阵中的实现机制。研究提出，通过将网络的雅可比矩阵与训练数据对齐，可以在理论上确保 Grokking 的发生。基于此，论文引入了一种名为 GrokAlign 的雅可比正则化方法，并实验证明该方法能够显著加速 Grokking 现象的出现，优于传统的正则化技术。此外，作者还提出了质心对齐作为雅可比对齐的简化形式，用于有效追踪网络训练动态。", "keywords": "Grokking, 雅可比矩阵, 雅可比正则化, GrokAlign, 深度网络训练", "comments": "本文在理解和加速 Grokking 现象方面提出了创新的几何视角，通过将 Grokking 与网络雅可比矩阵的特性联系起来，提供了新的理论解释。引入的 GrokAlign 方法，即雅可比正则化，为加速深度网络训练中的泛化过程提供了一种有效且有理论支撑的策略，其经验结果显示出优于传统正则化器的潜力。质心对齐的简化也增加了方法的可解释性和实用性。这项工作对于优化深度网络训练效率和理解其复杂动态具有重要意义。"}}
{"id": "2507.23178", "title": "AutoBridge: Automating Smart Device Integration with Centralized Platform", "authors": ["Siyuan Liu", "Zhice Yang", "Huangxun Chen"], "categories": ["cs.SE", "cs.AI", "I.2.5"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      14 pages, 12 figures, under review", "url": "http://arxiv.org/abs/2507.23178v1", "summary": "Multimodal IoT systems coordinate diverse IoT devices to deliver\nhuman-centered services. The ability to incorporate new IoT devices under the\nmanagement of a centralized platform is an essential requirement. However, it\nrequires significant human expertise and effort to program the complex IoT\nintegration code that enables the platform to understand and control the device\nfunctions. Therefore, we propose AutoBridge to automate IoT integration code\ngeneration. Specifically, AutoBridge adopts a divide-and-conquer strategy: it\nfirst generates device control logic by progressively retrieving\ndevice-specific knowledge, then synthesizes platformcompliant integration code\nusing platform-specific knowledge. To ensure correctness, AutoBridge features a\nmulti-stage debugging pipeline, including an automated debugger for virtual IoT\ndevice testing and an interactive hardware-in-the-loop debugger that requires\nonly binary user feedback (yes and no) for real-device verification. We\nevaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT\nplatforms. The results demonstrate that AutoBridge can achieves an average\nsuccess rate of 93.87% and an average function coverage of 94.87%, without any\nhuman involvement. With minimal binary yes and no feedback from users, the code\nis then revised to reach 100% function coverage. A user study with 15\nparticipants further shows that AutoBridge outperforms expert programmers by\n50% to 80% in code accuracy, even when the programmers are allowed to use\ncommercial code LLMs.", "comment": "14 pages, 12 figures, under review", "pdf_url": "http://arxiv.org/pdf/2507.23178v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "AutoBridge：自动化智能设备与中心化平台的集成", "tldr": "AutoBridge自动化物联网设备集成代码生成，通过分而治之策略和多阶段调试，实现了高成功率和功能覆盖率，优于人工编程。", "motivation": "在多模态物联网系统中，将新物联网设备集成到中心化平台是基本要求，但这需要大量人工专业知识和精力来编写复杂的物联网集成代码，以使平台理解和控制设备功能。", "method": "AutoBridge采用分而治之策略：首先通过逐步检索设备特定知识生成设备控制逻辑；然后利用平台特定知识合成符合平台的集成代码。为确保正确性，AutoBridge还具有多阶段调试管道，包括用于虚拟物联网设备测试的自动化调试器和只需二进制用户反馈（是/否）即可进行真实设备验证的交互式硬件在环调试器。", "result": "AutoBridge在两个开源物联网平台的34个物联网设备基准测试中，实现了平均93.87%的成功率和94.87%的功能覆盖率，无需任何人工干预。在用户提供少量二进制“是”和“否”反馈后，代码可达到100%的功能覆盖率。一项包含15名参与者的用户研究表明，即使程序员可以使用商业代码LLM，AutoBridge在代码准确性方面仍比专家程序员高出50%至80%。", "conclusion": "AutoBridge能够有效自动化物联网集成代码生成，显著提高集成效率和准确性，并减少对人工专业知识的依赖。", "translation": "多模态物联网系统协调各种物联网设备以提供以人为中心的服务。将新物联网设备纳入中心化平台管理的能力是基本要求。然而，编程复杂的物联网集成代码需要大量人工专业知识和精力，才能使平台理解和控制设备功能。因此，我们提出了AutoBridge来自动化物联网集成代码生成。具体来说，AutoBridge采用分而治之的策略：它首先通过逐步检索设备特定知识来生成设备控制逻辑，然后使用平台特定知识合成符合平台的集成代码。为确保正确性，AutoBridge具有多阶段调试管道，包括用于虚拟物联网设备测试的自动化调试器和需要仅二进制用户反馈（是和否）进行真实设备验证的交互式硬件在环调试器。我们在两个开源物联网平台上的34个物联网设备基准测试中评估了AutoBridge。结果表明，AutoBridge无需任何人工参与即可实现平均93.87%的成功率和平均94.87%的功能覆盖率。在用户提供最少的二进制是和否反馈后，代码被修改以达到100%的功能覆盖率。一项针对15名参与者的用户研究进一步表明，即使程序员被允许使用商业代码大型语言模型，AutoBridge在代码准确性方面也比专家程序员高出50%至80%。", "summary": "本文提出了AutoBridge，一个自动化物联网设备集成代码生成的系统。针对将新设备集成到中心化平台时所需的大量人工编程工作，AutoBridge采用分而治之策略，通过检索设备和平台知识来生成控制逻辑和集成代码。为保证代码正确性，系统内置了多阶段调试管道，包括自动化虚拟测试和交互式硬件在环调试。实验结果表明，AutoBridge在无人工干预下能达到高成功率和功能覆盖率，并在用户少量反馈下实现100%功能覆盖，其代码准确性显著优于专家程序员。", "keywords": "物联网集成, 代码生成, 自动化, 智能设备, 中心化平台", "comments": "AutoBridge的创新点在于其自动化物联网集成代码生成的能力，显著降低了物联网系统集成的复杂性和人力成本。其分而治之的策略结合多阶段调试管道，特别是结合用户二进制反馈的硬件在环调试，有效保证了生成代码的正确性和鲁棒性。与商业代码LLM和专家程序员的对比结果突显了其在准确性方面的卓越性能，对物联网设备快速部署和扩展具有重要意义。"}}
{"id": "2507.23387", "title": "H2SGEMM: Emulating FP32 GEMM on Ascend NPUs using FP16 Units with Precision Recovery and Cache-Aware Optimization", "authors": ["Weicheng Xue", "Baisong Xu", "Kai Yang", "Yongxiang Liu", "Dengdeng Fan", "Pengxiang Xu", "Yonghong Tian"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23387v1", "summary": "Low-precision matrix engines, such as FP16 cube, offer high throughput but\nlack support for full-precision computation. In this work, we propose H2SGEMM,\na high-performance algorithm for emulating FP32 general matrix-matrix\nmultiplication (GEMM) using only FP16 computation units on a representative AI\naccelerator. The method decomposes each FP32 operand into two FP16 values and\ncompensates for numerical errors through a tunable scaling strategy. A detailed\nanalysis of numerical errors, including underflow conditions and precision\nloss, guides the selection of scaling parameters to preserve up to 22 bits of\nmantissa accuracy. We further investigate the effect of computation order on\naccuracy and demonstrate that a term-wise accumulation scheme improves\nnumerical stability over conventional FP32 GEMM in low-exponent regimes.\nFinally, a cache-aware blocking strategy and double-buffered pipeline are\nintroduced to overlap memory transfers with computation, enabling H2SGEMM to\nachieve up to 77% of the theoretical FP32-equivalent peak performance on Ascend\n910A NPU lacking native FP32 support. Extensive numerical experiments confirm\nthat our method not only recovers the accuracy of native FP32 GEMM but also\nexhibits superior numerical stability under certain conditions, due to its\nstructured and error-aware computation order.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23387v1", "cate": "cs.DC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "H2SGEMM：在昇腾NPU上使用FP16单元模拟FP32 GEMM，并进行精度恢复和缓存感知优化", "tldr": "H2SGEMM提出了一种在没有原生FP32支持的AI加速器上，利用FP16单元高效模拟FP32 GEMM的方法，通过精度恢复和缓存优化，在保证精度的同时达到接近理论峰值的性能。", "motivation": "低精度矩阵引擎（如FP16）虽然吞吐量高，但缺乏对全精度计算的支持。为了在不支持原生FP32的AI加速器上实现FP32通用矩阵乘法（GEMM），需要一种有效的方法来模拟FP32计算。", "method": "该方法名为H2SGEMM，将每个FP32操作数分解为两个FP16值，并通过可调的缩放策略补偿数值误差。通过对数值误差的详细分析（包括下溢条件和精度损失），指导缩放参数的选择，以保留高达22位的尾数精度。研究还发现，逐项累加方案在低指数范围内比传统的FP32 GEMM具有更好的数值稳定性。此外，引入了缓存感知阻塞策略和双缓冲流水线来重叠内存传输与计算。", "result": "H2SGEMM在昇腾910A NPU上实现了高达理论FP32等效峰值性能的77%。数值实验证实，该方法不仅恢复了原生FP32 GEMM的精度，而且在特定条件下由于其结构化和误差感知的计算顺序，表现出卓越的数值稳定性。", "conclusion": "H2SGEMM成功地在仅有FP16计算单元的AI加速器上模拟了FP32 GEMM，通过创新的分解、误差补偿和优化策略，实现了高精度和高性能，并在某些条件下展现出优于原生FP32 GEMM的数值稳定性。", "translation": "低精度矩阵引擎（如FP16立方体）提供高吞吐量，但缺乏对全精度计算的支持。在这项工作中，我们提出了H2SGEMM，一种高性能算法，用于在代表性AI加速器上仅使用FP16计算单元模拟FP32通用矩阵乘法（GEMM）。该方法将每个FP32操作数分解为两个FP16值，并通过可调的缩放策略补偿数值误差。对数值误差的详细分析，包括下溢条件和精度损失，指导缩放参数的选择，以保留高达22位的尾数精度。我们进一步研究了计算顺序对精度的影响，并证明逐项累加方案在低指数范围内比传统的FP32 GEMM提高了数值稳定性。最后，引入了缓存感知阻塞策略和双缓冲流水线，以重叠内存传输与计算，使H2SGEMM在缺乏原生FP32支持的昇腾910A NPU上实现了高达理论FP32等效峰值性能的77%。广泛的数值实验证实，我们的方法不仅恢复了原生FP32 GEMM的精度，而且由于其结构化和误差感知的计算顺序，在某些条件下表现出卓越的数值稳定性。", "summary": "本研究提出了H2SGEMM算法，旨在利用仅支持FP16计算的AI加速器（如昇腾NPU）来高效模拟FP32通用矩阵乘法（GEMM）。该方法通过将FP32操作数分解为两个FP16值并采用可调的缩放策略来补偿数值误差，从而恢复FP32的精度。通过对误差的深入分析，H2SGEMM能够保持高达22位的尾数精度，并且通过逐项累加方案提高了数值稳定性。此外，结合缓存感知阻塞和双缓冲流水线优化，H2SGEMM在昇腾910A NPU上实现了接近理论峰值的性能（77%），并在数值稳定性和精度上优于或等同于原生FP32 GEMM。", "keywords": "FP32 GEMM模拟, FP16计算, 精度恢复, 缓存优化, 昇腾NPU", "comments": "这篇论文的创新点在于提出了H2SGEMM算法，通过巧妙地分解FP32操作数并结合误差补偿和缓存优化，在硬件不支持原生FP32计算的情况下，成功地模拟了FP32 GEMM，并取得了令人印象深刻的性能和精度。其对数值误差的详细分析以及计算顺序对精度的影响研究，对于在低精度硬件上实现高精度计算具有重要的指导意义。该工作为充分利用现有AI加速器的计算能力提供了新的思路。"}}
{"id": "2507.23638", "title": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "authors": ["Mohammad Karami", "Fatemeh Ghassemi", "Hamed Kebriaei", "Hamid Azadegan"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23638v1", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23638v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "OptiGradTrust：基于多特征梯度分析和强化学习信任加权的拜占庭鲁棒联邦学习", "tldr": "OptiGradTrust是一个针对联邦学习中拜占庭攻击和数据异质性的防御框架，它通过多维梯度分析和强化学习信任加权来提高鲁棒性和性能。", "motivation": "联邦学习（FL）在保护患者隐私的同时，实现了分布式医疗机构间的协作模型训练，但它容易受到拜占庭攻击和统计异质性的影响。", "method": "OptiGradTrust是一个全面的防御框架。它通过包含VAE重建误差、余弦相似度、L2范数、符号一致性比率和蒙特卡洛Shapley值在内的六维指纹来评估梯度更新，并以此驱动一个混合RL-注意力模块进行自适应信任评分。为了解决数据异质性下的收敛挑战，提出了FedBN-Prox (FedBN-P)，它结合了联邦批归一化和近端正则化，以实现最佳的准确性-收敛性权衡。", "result": "在MNIST、CIFAR-10和阿尔茨海默病MRI数据集上，在各种拜占庭攻击场景下进行了广泛评估，结果表明OptiGradTrust比现有最先进的防御方法有显著改进，在非独立同分布（non-IID）条件下，其性能比FLGuard提高了1.6个百分点，并通过自适应学习方法保持了对不同攻击模式的鲁棒性能。", "conclusion": "OptiGradTrust框架通过多特征梯度分析和强化学习信任加权，显著提高了联邦学习在拜占庭攻击和数据异质性下的鲁棒性和性能。", "translation": "联邦学习（FL）能够在分布式医疗机构间实现协作模型训练，同时保护患者隐私，但它仍然容易受到拜占庭攻击和统计异质性的影响。我们提出了OptiGradTrust，这是一个全面的防御框架，通过一个新颖的六维指纹评估梯度更新，该指纹包括VAE重建误差、余弦相似度指标、L2范数、符号一致性比率和蒙特卡洛Shapley值，这些值驱动一个混合RL-注意力模块进行自适应信任评分。为了解决数据异质性下的收敛挑战，我们开发了FedBN-Prox (FedBN-P)，它结合了联邦批归一化和近端正则化，以实现最佳的准确性-收敛性权衡。在MNIST、CIFAR-10和阿尔茨海默病MRI数据集上，在各种拜占庭攻击场景下进行了广泛评估，结果表明OptiGradTrust比现有最先进的防御方法有显著改进，在非独立同分布（non-IID）条件下，其性能比FLGuard提高了1.6个百分点，并通过我们的自适应学习方法保持了对不同攻击模式的鲁棒性能。", "summary": "本研究提出了OptiGradTrust，一个旨在增强联邦学习对拜占庭攻击和数据异质性鲁棒性的防御框架。该框架通过一个包含六维指纹的多特征梯度分析模块评估梯度更新，并利用强化学习-注意力机制进行自适应信任加权。此外，为解决异质性下的收敛问题，引入了结合联邦批归一化和近端正则化的FedBN-Prox。实验结果显示，OptiGradTrust在多种数据集和攻击场景下均优于现有先进防御方法，特别是在非独立同分布条件下表现出显著性能提升。", "keywords": "联邦学习, 拜占庭鲁棒性, 梯度分析, 强化学习, 统计异质性", "comments": "OptiGradTrust的创新之处在于其结合了多维度梯度特征分析（六维指纹）与强化学习驱动的自适应信任加权机制，这为联邦学习中的拜占庭攻击防御提供了更精细和动态的解决方案。同时，FedBN-Prox的引入也有效解决了数据异质性带来的收敛挑战，显示了其在实际应用中的潜力。"}}
{"id": "2507.23410", "title": "Towards LLM-Enhanced Product Line Scoping", "authors": ["Alexander Felfernig", "Damian Garber", "Viet-Man Le", "Sebastian Lubos", "Thi Ngoc Trang Tran"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23410v1", "summary": "The idea of product line scoping is to identify the set of features and\nconfigurations that a product line should include, i.e., offer for\nconfiguration purposes. In this context, a major scoping task is to find a\nbalance between commercial relevance and technical feasibility. Traditional\nproduct line scoping approaches rely on formal feature models and require a\nmanual analysis which can be quite time-consuming. In this paper, we sketch how\nLarge Language Models (LLMs) can be applied to support product line scoping\ntasks with a natural language interaction based scoping process. Using a\nworking example from the smarthome domain, we sketch how LLMs can be applied to\nevaluate different feature model alternatives. We discuss open research\nchallenges regarding the integration of LLMs with product line scoping.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23410v1", "cate": "cs.IR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "迈向大型语言模型增强的产品线范围界定", "tldr": "本文探讨了如何利用大型语言模型（LLMs）通过自然语言交互来改进耗时且依赖人工的产品线范围界定任务。", "motivation": "传统的产品线范围界定方法依赖于形式化特征模型，需要大量手动分析，耗时且效率低下，难以在商业相关性和技术可行性之间找到平衡。", "method": "本文提出将大型语言模型（LLMs）应用于产品线范围界定任务，通过基于自然语言交互的范围界定过程来支持该任务。", "result": "通过一个智能家居领域的实例，文章展示了大型语言模型如何应用于评估不同的特征模型替代方案。", "conclusion": "论文讨论了大型语言模型与产品线范围界定集成方面的开放研究挑战。", "translation": "产品线范围界定的理念是识别产品线应包含的特征和配置集合，即为配置目的而提供的功能。在此背景下，一项主要的范围界定任务是在商业相关性和技术可行性之间找到平衡。传统的产品线范围界定方法依赖于形式化特征模型，需要人工分析，这可能非常耗时。在本文中，我们概述了如何应用大型语言模型（LLMs）通过基于自然语言交互的范围界定过程来支持产品线范围界定任务。我们使用一个来自智能家居领域的工作实例，概述了如何应用大型语言模型来评估不同的特征模型替代方案。我们讨论了将大型语言模型与产品线范围界定集成方面的开放研究挑战。", "summary": "本文探讨了利用大型语言模型（LLMs）改进产品线范围界定任务的可能性，以克服传统方法耗时且依赖人工的缺点。通过自然语言交互，LLMs可以帮助平衡商业相关性和技术可行性。文章以智能家居为例，展示了LLMs在评估特征模型替代方案中的应用潜力，并讨论了该领域未来的研究挑战。", "keywords": "大型语言模型, 产品线范围界定, 特征模型, 自然语言交互, 智能家居", "comments": "这篇论文提出了一种新颖的方法，将大型语言模型引入到传统上耗时且依赖人工的产品线范围界定过程中。其创新点在于利用LLMs的自然语言处理能力来简化特征模型的评估和范围界定决策。然而，由于它只是“概述”或“草图”，可能缺乏详细的实验验证和量化结果，并且论文也提到了开放的研究挑战，这表明该领域仍处于早期探索阶段。"}}
{"id": "2501.02201", "title": "Acknowledging Focus Ambiguity in Visual Questions", "authors": ["Chongyan Chen", "Yu-Yun Tseng", "Zhuoheng Li", "Anush Venkatesh", "Danna Gurari"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.02201v2", "summary": "No published work on visual question answering (VQA) accounts for ambiguity\nregarding where the content described in the question is located in the image.\nTo fill this gap, we introduce VQ-FocusAmbiguity, the first VQA dataset that\nvisually grounds each plausible image region a question could refer to when\narriving at valid answers. We next analyze and compare our dataset to existing\ndatasets to reveal its unique properties. Finally, we benchmark modern models\nfor two novel tasks related to acknowledging focus ambiguity: recognizing\nwhether a visual question has focus ambiguity and locating all plausible focus\nregions within the image. Results show that the dataset is challenging for\nmodern models. To facilitate future progress on these tasks, we publicly share\nthe dataset with an evaluation server at\nhttps://vizwiz.org/tasks-and-datasets/focus-ambiguity-in-visual-questions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.02201v2", "cate": "cs.CV", "date": "2025-01-04", "updated": "2025-07-31", "AI": {"title_translation": "识别视觉问题中的焦点歧义", "tldr": "引入了VQ-FocusAmbiguity数据集，这是首个解决VQA中焦点歧义的视觉定位数据集，并发现现有模型在该数据集上表现不佳。", "motivation": "现有的视觉问答（VQA）工作中没有考虑到问题中描述的内容在图像中位置的歧义。为了弥补这一空白，本文引入了一个新的数据集。", "method": "本文引入了VQ-FocusAmbiguity，这是第一个在视觉问答（VQA）中将问题可能指向的每个合理图像区域进行视觉定位的数据集。接着，分析并比较了该数据集与现有数据集的独特属性。最后，评估了现代模型在识别视觉问题是否存在焦点歧义以及定位图像中所有可能的焦点区域这两个新任务上的表现。", "result": "结果表明，该数据集对现代模型来说具有挑战性。", "conclusion": "VQ-FocusAmbiguity数据集填补了VQA领域中焦点歧义的空白，并为未来解决这一挑战性问题提供了基准和资源。", "translation": "目前还没有已发表的视觉问答（VQA）工作考虑到问题中描述的内容在图像中位置的歧义。为了弥补这一空白，我们引入了VQ-FocusAmbiguity，这是第一个在得出有效答案时，将问题可能指向的每个合理图像区域进行视觉定位的VQA数据集。接下来，我们分析并比较了我们的数据集与现有数据集，以揭示其独特的属性。最后，我们针对两个与识别焦点歧义相关的新任务对现代模型进行了基准测试：识别视觉问题是否存在焦点歧义以及定位图像中所有可能的焦点区域。结果表明，该数据集对现代模型来说具有挑战性。为了促进这些任务未来的进展，我们通过https://vizwiz.org/tasks-and-datasets/focus-ambiguity-in-visual-questions 公开共享了该数据集以及一个评估服务器。", "summary": "该研究引入了VQ-FocusAmbiguity数据集，旨在解决视觉问答（VQA）中图像内容位置的焦点歧义问题。这是首个为每个可能的问题指代区域提供视觉定位的VQA数据集。通过与现有数据集的比较，揭示了其独特属性。文章还评估了现代模型在识别焦点歧义和定位相关区域方面的表现，结果表明该数据集对当前模型构成挑战。为推动未来研究，该数据集已公开发布。", "keywords": "视觉问答, 焦点歧义, 数据集, 图像定位, VQA", "comments": "这项工作通过引入VQ-FocusAmbiguity数据集，填补了视觉问答（VQA）领域中长期存在的焦点歧义问题。其创新之处在于首次为VQA提供了视觉定位的歧义感知数据集，并设立了识别和定位焦点区域的新任务。该数据集对现有模型构成挑战，表明了该领域仍有很大的进步空间，对于推动VQA的鲁棒性和实际应用具有重要意义。"}}
{"id": "2507.23025", "title": "Constructing and Sampling Directed Graphs with Linearly Rescaled Degree Matrices", "authors": ["Yunxiang Yan", "Meng Jiang"], "categories": ["cs.SI", "cs.DM"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      SIGKDD 2022", "url": "http://arxiv.org/abs/2507.23025v1", "summary": "In recent years, many large directed networks such as online social networks\nare collected with the help of powerful data engineering and data storage\ntechniques. Analyses of such networks attract significant attention from both\nthe academics and industries. However, analyses of large directed networks are\noften time-consuming and expensive because the complexities of a lot of graph\nalgorithms are often polynomial with the size of the graph. Hence, sampling\nalgorithms that can generate graphs preserving properties of original graph are\nof great importance because they can speed up the analysis process. We propose\na promising framework to sample directed graphs: Construct a sample graph with\nlinearly rescaled Joint Degree Matrix (JDM) and Degree Correlation Matrix\n(DCM). Previous work shows that graphs with the same JDM and DCM will have a\nrange of very similar graph properties. We also conduct experiments on\nreal-world datasets to show that the numbers of non-zero entries in JDM and DCM\nare quite small compared to the number of edges and nodes. Adopting this\nframework, we propose a novel graph sampling algorithm that can provably\npreserves in-degree and out-degree distributions, which are two most\nfundamental properties of a graph. We also prove the upper bound for deviations\nin the joint degree distribution and degree correlation distribution, which\ncorrespond to JDM and DCM. Besides, we prove that the deviations in these\ndistributions are negatively correlated with the sparsity of the JDM and DCM.\nConsidering that these two matrices are always quite sparse, we believe that\nproposed algorithm will have a better-than-theory performance on real-world\nlarge directed networks.", "comment": "SIGKDD 2022", "pdf_url": "http://arxiv.org/pdf/2507.23025v1", "cate": "cs.SI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "构建和采样具有线性重标度度矩阵的有向图", "tldr": "提出了一种基于线性重标度联合度矩阵（JDM）和度关联矩阵（DCM）的有向图采样框架和算法，该算法能保留度分布并预期在实际网络中表现良好。", "motivation": "现有的大型有向网络分析耗时且昂贵，因为许多图算法的复杂度与图的大小呈多项式关系，需要有效的采样算法来加速分析过程并保留原始图的特性。", "method": "提出一个有向图采样框架，通过使用线性重标度联合度矩阵（JDM）和度关联矩阵（DCM）来构建样本图。在此框架下，提出一种新的图采样算法，能够可证明地保留入度和出度分布。", "result": "实验表明，JDM和DCM的非零项数量相对于边和节点数非常小。理论上，该算法可证明地保留了入度和出度分布。此外，证明了联合度分布和度关联分布偏差的上限，且这些偏差与JDM和DCM的稀疏性负相关。", "conclusion": "考虑到JDM和DCM在实际网络中总是相当稀疏，所提出的算法在真实世界的大型有向网络上将具有优于理论的性能。", "translation": "近年来，借助强大的数据工程和数据存储技术，许多大型有向网络，如在线社交网络，被收集起来。对这些网络的分析引起了学术界和工业界的广泛关注。然而，大型有向网络的分析通常耗时且昂贵，因为许多图算法的复杂度通常与图的大小呈多项式关系。因此，能够生成保留原始图属性的采样算法变得非常重要，因为它们可以加快分析过程。我们提出了一种有前景的有向图采样框架：使用线性重标度联合度矩阵（JDM）和度关联矩阵（DCM）来构建样本图。先前的研究表明，具有相同JDM和DCM的图将具有一系列非常相似的图属性。我们还在真实世界的数据集上进行了实验，结果表明JDM和DCM中非零项的数量与边和节点的数量相比非常小。采用此框架，我们提出了一种新颖的图采样算法，该算法可以可证明地保留入度和出度分布，这是图的两个最基本属性。我们还证明了联合度分布和度关联分布（对应于JDM和DCM）偏差的上限。此外，我们证明了这些分布的偏差与JDM和DCM的稀疏性负相关。考虑到这两个矩阵总是相当稀疏，我们相信所提出的算法在真实世界的大型有向网络上将具有优于理论的性能。", "summary": "本文提出了一种创新的有向图采样框架，该框架利用线性重标度联合度矩阵（JDM）和度关联矩阵（DCM）来构建样本图。在此基础上，开发了一种新的采样算法，该算法能够可证明地保留图的基本属性，即入度和出度分布。研究还通过实验证实了JDM和DCM在实际数据集上的稀疏性，并从理论上证明了联合度分布和度关联分布的偏差与矩阵稀疏性呈负相关。鉴于这些矩阵的固有稀疏性，该算法有望在大型有向网络分析中实现高效且性能优异的采样。", "keywords": "有向图采样, 联合度矩阵, 度关联矩阵, 度分布, 网络分析", "comments": "该论文提出了一种新颖的有向图采样方法，通过利用度矩阵的稀疏性，有效解决了大型图分析的计算效率问题。其创新点在于将线性重标度JDM和DCM引入采样过程，并提供了严格的理论证明来保证度分布的保留。稀疏性与偏差的负相关性是其在实际应用中表现优异的关键。"}}
{"id": "2507.22925", "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "authors": ["Haoran Sun", "Shaoning Zeng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22925v1", "summary": "Long-term memory is one of the key factors influencing the reasoning\ncapabilities of Large Language Model Agents (LLM Agents). Incorporating a\nmemory mechanism that effectively integrates past interactions can\nsignificantly enhance decision-making and contextual coherence of LLM Agents.\nWhile recent works have made progress in memory storage and retrieval, such as\nencoding memory into dense vectors for similarity-based search or organizing\nknowledge in the form of graph, these approaches often fall short in structured\nmemory organization and efficient retrieval. To address these limitations, we\npropose a Hierarchical Memory (H-MEM) architecture for LLM Agents that\norganizes and updates memory in a multi-level fashion based on the degree of\nsemantic abstraction. Each memory vector is embedded with a positional index\nencoding pointing to its semantically related sub-memories in the next layer.\nDuring the reasoning phase, an index-based routing mechanism enables efficient,\nlayer-by-layer retrieval without performing exhaustive similarity computations.\nWe evaluate our method on five task settings from the LoCoMo dataset.\nExperimental results show that our approach consistently outperforms five\nbaseline methods, demonstrating its effectiveness in long-term dialogue\nscenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22925v1", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-23", "AI": {"title_translation": "LLM智能体中用于高效长期推理的层级记忆", "tldr": "提出了一种名为H-MEM的层级记忆架构，通过多级组织和索引路由实现高效的长期推理，优于现有基线方法。", "motivation": "现有的大语言模型智能体记忆机制在结构化记忆组织和高效检索方面存在不足，限制了其长期推理能力。", "method": "提出了一种层级记忆（H-MEM）架构，根据语义抽象程度多级组织和更新记忆。每个记忆向量嵌入了指向下一层语义相关子记忆的位置索引。在推理阶段，采用基于索引的路由机制进行逐层高效检索，无需进行穷举相似度计算。", "result": "在LoCoMo数据集的五个任务设置上进行评估，实验结果表明H-MEM始终优于五种基线方法。", "conclusion": "本研究提出的层级记忆（H-MEM）架构有效提升了LLM智能体在长期对话场景中的推理能力，解决了现有记忆机制在结构化组织和高效检索方面的局限。", "translation": "长期记忆是影响大型语言模型智能体（LLM智能体）推理能力的关键因素之一。整合有效记忆机制以整合过去交互可以显著增强LLM智能体的决策制定和上下文连贯性。虽然最近的工作在记忆存储和检索方面取得了进展，例如将记忆编码为密集向量进行基于相似性的搜索或以图的形式组织知识，但这些方法在结构化记忆组织和高效检索方面常常不足。为了解决这些限制，我们提出了一种用于LLM智能体的层级记忆（H-MEM）架构，该架构根据语义抽象程度以多级方式组织和更新记忆。每个记忆向量都嵌入了一个位置索引编码，指向其在下一层中语义相关的子记忆。在推理阶段，基于索引的路由机制可以实现高效的逐层检索，而无需执行穷举的相似性计算。我们在LoCoMo数据集的五个任务设置上评估了我们的方法。实验结果表明，我们的方法始终优于五种基线方法，证明了其在长期对话场景中的有效性。", "summary": "该论文针对大型语言模型智能体（LLM Agents）长期推理中记忆机制的不足，提出了一种名为层级记忆（H-MEM）的新架构。H-MEM通过多级语义抽象组织和更新记忆，并利用位置索引实现基于索引的逐层高效检索，避免了耗时的相似性计算。在LoCoMo数据集上的实验证明，H-MEM在长期对话场景中表现优于现有基线方法，有效提升了LLM智能体的推理能力。", "keywords": "层级记忆, LLM智能体, 长期推理, 记忆检索, 语义抽象", "comments": "该论文的创新点在于提出了层级记忆架构，通过引入语义抽象的多级组织和基于索引的路由机制，显著提升了LLM智能体记忆的结构化程度和检索效率，从而有效解决了传统方法在长期推理中的瓶颈。"}}
{"id": "2507.23341", "title": "The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models", "authors": ["Ahmet Can Ömercikoğlu", "Mustafa Mansur Yönügül", "Pakize Erdoğmuş"], "categories": ["cs.CV", "68T45, 68T07", "I.4.8; I.4.9; I.5.4"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, 4 tables", "url": "http://arxiv.org/abs/2507.23341v1", "summary": "Face detection is a crucial component in many AI-driven applications such as\nsurveillance, biometric authentication, and human-computer interaction.\nHowever, real-world conditions like low-resolution imagery present significant\nchallenges that degrade detection performance. In this study, we systematically\ninvestigate the impact of input resolution on the accuracy and robustness of\nthree prominent deep learning-based face detectors: YOLOv11, YOLOv12, and\nMTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across\nmultiple image resolutions (160x160, 320x320, and 640x640) and assess each\nmodel's performance using metrics such as precision, recall, mAP50, mAP50-95,\nand inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN\nin terms of detection accuracy, especially at higher resolutions, while YOLOv12\nexhibits slightly better recall. MTCNN, although competitive in landmark\nlocalization, lags in real-time inference speed. Our findings provide\nactionable insights for selecting resolution-aware face detection models\nsuitable for varying operational constraints.", "comment": "6 pages, 5 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.23341v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "图像分辨率对人脸检测的影响：MTCNN、YOLOv XI 和 YOLOv XII 模型的比较分析", "tldr": "本研究系统地调查了输入分辨率对MTCNN、YOLOv11和YOLOv12这三种主流深度学习人脸检测器准确性和鲁棒性的影响。结果显示YOLOv11在检测精度上优于其他模型，尤其是在高分辨率下。", "motivation": "人脸检测是许多AI驱动应用中的关键组成部分，但在低分辨率图像等实际条件下，检测性能会显著下降。本研究旨在系统地调查输入分辨率对人脸检测器性能的影响。", "method": "本研究系统地调查了输入分辨率对MTCNN、YOLOv11和YOLOv12三种深度学习人脸检测器准确性和鲁棒性的影响。使用WIDER FACE数据集，在多种图像分辨率（160x160、320x320和640x640）下进行了广泛评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标评估了每个模型的性能。", "result": "结果表明，YOLOv11在检测精度方面优于YOLOv12和MTCNN，尤其是在更高分辨率下；而YOLOv12表现出略好的召回率。MTCNN虽然在地标定位方面具有竞争力，但在实时推理速度方面表现滞后。", "conclusion": "本研究的结果为选择适合不同操作约束的、分辨率感知的人脸检测模型提供了可操作的见解。", "translation": "人脸检测是许多AI驱动应用（如监控、生物识别认证和人机交互）中的关键组成部分。然而，低分辨率图像等实际条件带来了显著挑战，会降低检测性能。在本研究中，我们系统地调查了输入分辨率对MTCNN、YOLOv11和YOLOv12这三种主流深度学习人脸检测器的准确性和鲁棒性的影响。我们使用WIDER FACE数据集，在多种图像分辨率（160x160、320x320和640x640）下进行了广泛评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标评估了每个模型的性能。结果表明，YOLOv11在检测精度方面优于YOLOv12和MTCNN，尤其是在更高分辨率下，而YOLOv12表现出略好的召回率。MTCNN虽然在地标定位方面具有竞争力，但在实时推理速度方面表现滞后。我们的发现为选择适合不同操作约束的、分辨率感知的人脸检测模型提供了可操作的见解。", "summary": "本研究探讨了图像分辨率对人脸检测模型性能的影响。通过在WIDER FACE数据集上比较MTCNN、YOLOv11和YOLOv12模型在不同分辨率下的表现，研究发现YOLOv11在检测精度上表现最佳，尤其是在高分辨率下。YOLOv12在召回率上略有优势，而MTCNN在实时推理速度上较慢。研究结果为实际应用中选择合适的人脸检测模型提供了指导。", "keywords": "人脸检测, 图像分辨率, MTCNN, YOLOv11, YOLOv12", "comments": "本研究通过对不同分辨率下主流人脸检测模型的系统性比较，为实际应用中模型选择提供了实用指导。其价值在于明确了分辨率对不同模型性能的具体影响，帮助开发者根据实际场景需求（如对精度或速度的要求以及图像分辨率条件）做出更明智的决策。创新性体现在其系统性的比较分析方法。"}}
{"id": "2507.22960", "title": "Hybrid Particle Swarm Optimization for Fast and Reliable Parameter Extraction in Thermoreflectance", "authors": ["Bingjia Xiao", "Tao Chen", "Wenbin Zhang", "Xin Qian", "Puqing Jiang"], "categories": ["cs.NE", "cond-mat.other"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      28 pages, 8 figures", "url": "http://arxiv.org/abs/2507.22960v1", "summary": "Frequency-domain thermoreflectance (FDTR) is a widely used technique for\ncharacterizing thermal properties of multilayer thin films. However, extracting\nmultiple parameters from FDTR measurements presents a nonlinear inverse problem\ndue to its high dimensionality and multimodal, non-convex solution space. This\nstudy evaluates four popular global optimization algorithms: Genetic Algorithm\n(GA), Quantum Genetic Algorithm (QGA), Particle Swarm Optimization (PSO), and\nFireworks Algorithm (FWA), for extracting parameters from FDTR measurements of\na GaN/Si heterostructure. However, none achieve reliable convergence within 60\nseconds. To improve convergence speed and accuracy, we propose an AI-driven\nhybrid optimization framework that combines each global algorithm with a\nQuasi-Newton local refinement method, resulting in four hybrid variants: HGA,\nHQGA, HPSO, and HFWA. Among these, HPSO outperforms all other methods, with 80%\nof trials reaching the target fitness value within 60 seconds, showing greater\nrobustness and a lower risk of premature convergence. In contrast, only 30% of\nHGA and HQGA trials and 20% of HFWA trials achieve this threshold. We then\nevaluate the worst-case performance across 100 independent trials for each\nalgorithm when the time is extended to 1000 seconds. Only HPSO, PSO, and HGA\nconsistently reach the target accuracy, with HPSO converging five times faster\nthan the others. HPSO provides a general-purpose solution for inverse problems\nin thermal metrology and can be readily extended to other model-fitting\ntechniques.", "comment": "28 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.22960v1", "cate": "cs.NE", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "用于热反射率快速可靠参数提取的混合粒子群优化算法", "tldr": "提出了一种AI驱动的混合优化框架，结合全局算法和局部精炼方法，其中HPSO在热反射率参数提取中表现出最快的收敛速度和最高的可靠性。", "motivation": "频率域热反射率（FDTR）在多层薄膜热特性表征中广泛使用，但其参数提取是一个高维度、多模态、非凸的非线性逆问题，现有全局优化算法难以在短时间内实现可靠收敛。", "method": "本研究评估了GA、QGA、PSO和FWA四种全局优化算法用于FDTR参数提取。为了提高收敛速度和精度，提出了一种AI驱动的混合优化框架，将每种全局算法与Quasi-Newton局部精炼方法结合，形成HGA、HQGA、HPSO和HFWA四种混合变体。", "result": "在60秒内，HPSO有80%的试验达到目标适应度值，表现出更高的鲁棒性和更低的早熟收敛风险。相比之下，HGA和HQGA只有30%，HFWA只有20%。在1000秒的扩展时间内，只有HPSO、PSO和HGA能持续达到目标精度，其中HPSO的收敛速度比其他方法快五倍。", "conclusion": "HPSO为热计量中的逆问题提供了一个通用的解决方案，并且可以很容易地扩展到其他模型拟合技术。", "translation": "频率域热反射率（FDTR）是一种广泛用于表征多层薄膜热特性的技术。然而，从FDTR测量中提取多个参数是一个非线性逆问题，因为它具有高维度和多模态、非凸的解空间。本研究评估了四种流行的全局优化算法：遗传算法（GA）、量子遗传算法（QGA）、粒子群优化（PSO）和烟花算法（FWA），用于从GaN/Si异质结构的FDTR测量中提取参数。然而，没有一种算法能在60秒内实现可靠收敛。为了提高收敛速度和精度，我们提出了一种AI驱动的混合优化框架，将每种全局算法与Quasi-Newton局部精炼方法结合，从而产生了四种混合变体：HGA、HQGA、HPSO和HFWA。在这些算法中，HPSO优于所有其他方法，80%的试验在60秒内达到目标适应度值，显示出更高的鲁棒性和更低的早熟收敛风险。相比之下，HGA和HQGA只有30%的试验达到此阈值，HFWA只有20%。然后，我们评估了每种算法在时间延长到1000秒时，100次独立试验中的最差性能。只有HPSO、PSO和HGA能持续达到目标精度，其中HPSO的收敛速度比其他算法快五倍。HPSO为热计量中的逆问题提供了一个通用解决方案，并且可以很容易地扩展到其他模型拟合技术。", "summary": "本研究针对频率域热反射率（FDTR）测量中存在的参数提取非线性逆问题，评估了多种全局优化算法的性能，并提出了一种AI驱动的混合优化框架。该框架将全局算法与局部精炼方法结合，其中混合粒子群优化（HPSO）表现出卓越的收敛速度和可靠性。实验结果表明，HPSO在60秒内达到目标精度的成功率远高于其他方法，并且在延长至1000秒时，其收敛速度比其他有效算法快五倍。HPSO被认为是一种通用的热计量逆问题解决方案，并具有良好的可扩展性。", "keywords": "混合粒子群优化, 热反射率, 参数提取, 非线性逆问题, 全局优化", "comments": "该论文的创新点在于提出了AI驱动的混合优化框架，特别是HPSO在解决FDTR参数提取这一高维度、多模态、非凸的非线性逆问题上的显著性能提升。它通过结合全局搜索能力和局部精炼效率，有效克服了传统全局算法收敛慢和可靠性差的局限性，为热计量领域的逆问题提供了一个高效且通用的解决方案。"}}
{"id": "2506.08184", "title": "Unable to Forget: Proactive Interference Reveals Working Memory Limits in LLMs Beyond Context Length", "authors": ["Chupei Wang", "Jiaqiu Vince Sun"], "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025 Workshop on Long Context Foundation Models (ICFM). Code: this https URL", "url": "http://arxiv.org/abs/2506.08184v3", "summary": "Information retrieval in Large Language Models (LLMs) is increasingly\nrecognized as intertwined with generation capabilities rather than mere lookup.\nWhile longer contexts are often assumed to improve retrieval, the effects of\nintra-context interference remain understudied. To address this, we adapt the\nproactive interference (PI) paradigm from cognitive science, where earlier\ninformation disrupts recall of newer updates. In humans, susceptibility to such\ninterference is inversely linked to working memory capacity. We introduce\nPI-LLM, an evaluation that sequentially streams semantically related key-value\nupdates and queries only the final values. Although these final values are\nclearly positioned just before the query, LLM retrieval accuracy declines\nlog-linearly toward zero as interference accumulates; errors arise from\nretrieving previously overwritten values. Attempts to mitigate interference via\nprompt engineering (e.g., instructing models to ignore earlier input) yield\nlimited success. These findings reveal a fundamental constraint on LLMs'\nability to disentangle interference and flexibly manipulate information,\nsuggesting a working memory bottleneck beyond mere context access. This calls\nfor approaches that strengthen models' ability to suppress irrelevant content\nduring retrieval.", "comment": "Accepted at ICML 2025 Workshop on Long Context Foundation Models\n  (ICFM). Code: https://github.com/zhuangziGiantfish/Unable-to-Forget", "pdf_url": "http://arxiv.org/pdf/2506.08184v3", "cate": "cs.CL", "date": "2025-06-09", "updated": "2025-07-31", "AI": {"title_translation": "无法遗忘：主动干扰揭示了大型语言模型超越上下文长度的工作记忆限制", "tldr": "大型语言模型在处理上下文信息时，会受到“主动干扰”的影响，导致检索准确率下降，这表明LLM存在工作记忆瓶颈，而非仅仅是上下文长度问题。", "motivation": "现有研究对大型语言模型（LLMs）中上下文内部干扰的影响关注不足，而信息检索能力与生成能力密切相关。本研究旨在通过引入认知科学中的主动干扰（PI）范式，探讨LLMs的工作记忆限制。", "method": "研究引入了PI-LLM评估范式，该范式通过顺序流式传输语义相关的键值对更新，并仅查询最终值。通过这种方式，模拟并量化LLMs在信息检索中受到的主动干扰。", "result": "结果显示，尽管最终值明确位于查询前，但随着干扰的累积，LLM的检索准确率呈对数线性下降。错误主要来源于检索到先前已被覆盖的值。通过提示工程（如指示模型忽略早期输入）来缓解干扰的尝试效果有限。", "conclusion": "这些发现揭示了LLMs在区分干扰和灵活处理信息方面的根本性限制，表明存在超越单纯上下文访问的工作记忆瓶颈。这呼吁开发能够加强模型在检索过程中抑制不相关内容的方法。", "translation": "大型语言模型（LLMs）中的信息检索越来越被认为是与生成能力交织在一起的，而不仅仅是简单的查找。虽然更长的上下文通常被认为可以改善检索，但上下文内部干扰的影响仍未得到充分研究。为了解决这个问题，我们改编了认知科学中的主动干扰（PI）范式，即早期信息会干扰对新更新信息的召回。在人类中，对这种干扰的敏感性与工作记忆容量呈负相关。我们引入了PI-LLM，这是一种评估方法，它顺序流式传输语义相关的键值更新，并且只查询最终值。尽管这些最终值明确地位于查询之前，但随着干扰的累积，LLM的检索准确率呈对数线性下降至零；错误源于检索到先前被覆盖的值。尝试通过提示工程（例如，指示模型忽略早期输入）来缓解干扰的效果有限。这些发现揭示了LLM在解缠干扰和灵活操作信息方面的根本性限制，表明存在超越单纯上下文访问的工作记忆瓶颈。这呼吁采用能够加强模型在检索过程中抑制不相关内容的方法。", "summary": "本研究引入了认知科学中的“主动干扰”（Proactive Interference, PI）范式来评估大型语言模型（LLMs）的信息检索能力。通过PI-LLM评估，发现即使在最终信息清晰可见的情况下，LLMs的检索准确率仍会随着干扰信息的累积而对数线性下降，且错误多源于检索到旧的、被覆盖的数据。提示工程对缓解这种干扰效果有限。这揭示了LLMs存在一个超越上下文长度限制的工作记忆瓶颈，即其在抑制不相关信息和灵活处理信息方面的内在缺陷，提示未来研究应关注增强模型抑制干扰内容的能力。", "keywords": "大型语言模型, 主动干扰, 工作记忆, 信息检索, 上下文限制", "comments": "这项研究创新性地将认知科学中的主动干扰范式引入到LLM评估中，揭示了LLMs在处理长上下文时，除了上下文长度限制外，还存在深层的工作记忆瓶颈。其结果表明，即使是提示工程也难以完全解决这种干扰问题，这对于理解LLMs的根本局限性及其在复杂任务中的表现具有重要意义。该研究不仅提出了一个新颖的评估方法，也为未来LLM架构和训练方法的改进指明了方向，即需要加强模型抑制无关信息的能力。"}}
{"id": "2507.23751", "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "authors": ["Ping Yu", "Jack Lanchantin", "Tianlu Wang", "Weizhe Yuan", "Olga Golovneva", "Ilia Kulikov", "Sainbayar Sukhbaatar", "Jason Weston", "Jing Xu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23751v1", "summary": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23751v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "CoT-Self-Instruct：构建用于推理和非推理任务的高质量合成提示", "tldr": "CoT-Self-Instruct 是一种新的合成数据生成方法，它利用大语言模型（LLMs）的思维链（CoT）推理能力来创建高质量的合成提示，并在推理和非推理任务上显著优于现有数据集和方法。", "motivation": "为了解决LLM训练中高质量数据生成的问题，并改进现有合成数据生成方法的不足，本文提出了CoT-Self-Instruct以生成高质量的合成提示，用于推理和非推理任务。", "method": "CoT-Self-Instruct 方法指导大型语言模型（LLMs）首先基于给定的种子任务通过思维链（CoT）进行推理和规划，然后生成质量和复杂性相似的新合成提示，最后通过自动指标过滤以获取高质量数据。", "result": "在可验证推理任务中，CoT-Self-Instruct生成的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond等数据集上显著优于s1k和OpenMathReasoning等现有训练数据集。对于不可验证的指令遵循任务，该方法在AlpacaEval 2.0和Arena-Hard上超越了人类或标准自我指导提示的性能。", "conclusion": "CoT-Self-Instruct 是一种有效且高性能的合成数据生成方法，能够为大型语言模型训练提供高质量的提示，并在多种推理和指令遵循任务中展现出卓越的性能。", "translation": "我们提出了 CoT-Self-Instruct，这是一种合成数据生成方法，它指导大型语言模型（LLMs）首先基于给定的种子任务通过思维链（CoT）进行推理和规划，然后生成质量和复杂性相似的新合成提示，用于LLM训练，随后通过自动指标过滤以获取高质量数据。在可验证推理任务中，我们的合成数据在 MATH500、AMC23、AIME24 和 GPQA-Diamond 上显著优于现有训练数据集，例如 s1k 和 OpenMathReasoning。对于不可验证的指令遵循任务，我们的方法在 AlpacaEval 2.0 和 Arena-Hard 上超越了人类或标准自我指导提示的性能。", "summary": "CoT-Self-Instruct 是一种创新的合成数据生成方法，它利用大语言模型（LLMs）的思维链（CoT）能力进行推理和规划，以生成高质量、复杂性适中的新提示，并辅以自动过滤机制。该方法在可验证推理任务（如MATH500、AMC23、AIME24、GPQA-Diamond）上表现出色，显著超越了现有数据集。同时，在不可验证的指令遵循任务（如AlpacaEval 2.0、Arena-Hard）中，CoT-Self-Instruct 也展现出优于人类或标准自我指导提示的性能，证明了其在提升LLM训练数据质量方面的有效性。", "keywords": "合成数据, 思维链, 自我指导, 大型语言模型, 推理任务", "comments": "CoT-Self-Instruct 的创新之处在于将思维链（CoT）推理与自我指导（Self-Instruct）范式相结合，并通过自动过滤机制确保合成数据的质量。这种方法有效地解决了当前LLM训练数据生成中的质量瓶颈，特别是在需要复杂推理和精确指令遵循的场景中。其在多个基准测试上的显著性能提升表明了该方法的重要性和潜力，为未来高质量合成数据生成提供了新的方向。"}}
{"id": "2410.09213", "title": "iFANnpp: Nuclear Power Plant Digital Twin for Robots and Autonomous Intelligence", "authors": ["Youndo Do", "Marc Zebrowitz", "Jackson Stahl", "Fan Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.09213v3", "summary": "Robotics has gained attention in the nuclear industry due to its precision\nand ability to automate tasks. However, there is a critical need for advanced\nsimulation and control methods to predict robot behavior and optimize plant\nperformance, motivating the use of digital twins. Most existing digital twins\ndo not offer a total design of a nuclear power plant. Moreover, they are\ndesigned for specific algorithms or tasks, making them unsuitable for broader\nresearch applications. In response, this work proposes a comprehensive nuclear\npower plant digital twin designed to improve real-time monitoring, operational\nefficiency, and predictive maintenance. A full nuclear power plant is modeled\nin Unreal Engine 5 and integrated with a high-fidelity Generic Pressurized\nWater Reactor Simulator to create a realistic model of a nuclear power plant\nand a real-time updated virtual environment. The virtual environment provides\nvarious features for researchers to easily test custom robot algorithms and\nframeworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.09213v3", "cate": "cs.RO", "date": "2024-10-11", "updated": "2025-07-31", "AI": {"title_translation": "iFANnpp：用于机器人和自主智能的核电站数字孪生", "tldr": "本文提出了iFANnpp，一个基于虚幻引擎5和高保真反应堆模拟器构建的全面核电站数字孪生，旨在改善实时监控、运行效率和预测性维护，并为机器人算法提供一个测试平台。", "motivation": "核工业需要先进的模拟和控制方法来预测机器人行为和优化电厂性能。现有的大多数数字孪生不提供核电站的整体设计，且专为特定算法或任务设计，不适用于更广泛的研究应用。", "method": "本文提出了一个全面的核电站数字孪生（iFANnpp）。在虚幻引擎5中建模了一个完整的核电站，并与高保真通用压水堆模拟器集成，以创建逼真的核电站模型和实时更新的虚拟环境。", "result": "该数字孪生旨在改进实时监控、运行效率和预测性维护。所创建的虚拟环境为研究人员提供了多种功能，可以轻松测试自定义机器人算法和框架。", "conclusion": "iFANnpp数字孪生通过提供一个全面、实时且灵活的平台，解决了现有数字孪生的局限性，适用于核电站运行和机器人研究。", "translation": "机器人技术因其精度和自动化任务的能力而在核工业中受到关注。然而，迫切需要先进的模拟和控制方法来预测机器人行为并优化电厂性能，这推动了数字孪生技术的使用。大多数现有的数字孪生不提供核电站的整体设计。此外，它们是为特定算法或任务设计的，不适用于更广泛的研究应用。为此，本文提出了一种全面的核电站数字孪生，旨在改进实时监控、运行效率和预测性维护。一个完整的核电站模型在虚幻引擎5中建模，并与高保真通用压水堆模拟器集成，以创建核电站的真实模型和实时更新的虚拟环境。该虚拟环境为研究人员提供了各种功能，可以轻松测试自定义机器人算法和框架。", "summary": "本文介绍了iFANnpp，一个用于核电站的全面数字孪生。它通过在虚幻引擎5中对整个核电站进行建模并将其与高保真反应堆模拟器集成，解决了现有数字孪生的局限性。这创建了一个逼真、实时更新的虚拟环境，可以增强监控、运行效率和预测性维护，并作为核工业中机器人算法和框架的多功能测试平台。", "keywords": "核电站, 数字孪生, 机器人技术, 虚幻引擎5, 模拟", "comments": "本文的创新之处在于提出了一个针对整个核电站的全面数字孪生，这与现有仅针对特定任务的数字孪生不同。它解决了核工业中对先进模拟的迫切需求，对于机器人技术和工厂优化至关重要。然而，摘要中没有提及具体的验证结果或性能数据。"}}
{"id": "2507.23571", "title": "Asynchronous Grid Connections Providing Fast-Frequency Response: System Integration Study", "authors": ["Felix Wald", "Amir Sajadi", "Barry Mather", "Giovanni De Carne"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23571v1", "summary": "This paper presents an integration study for a power electronic-based\nfast-frequency response technology, an asynchronous grid connection operating\nas an aggregator for behindthe-meter resources and distributed generators. Both\ntechnical feasibility and techno-economic viability studies are presented. The\ndynamic performance of the fast-frequency response enabled by the asynchronous\ngrid connection is validated with Power Hardware-in-the-Loop experiments and\ntransferred to an IEEE 9-bus system in DigSilent PowerFactory for dynamic\nstability analysis. We demonstrate that droop-based control enhancements to the\nlocal distributed generators could allow their aggregation to provide\ngrid-supporting functionalities and participate in the market for ancillary\nservices. To this end, we performed a long-term simulation embedding the system\nwithin the ancillary service market framework of PJM. The fast-frequency\nresponse regulation is subsequently used to calculate the potential revenue and\nproject the results on a 15-year investment horizon. Finally, the\ntechno-economic analysis concludes with recommendations for enhancements to\naccess the full potential of distributed generators on a technical and\nregulatory level.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23571v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "异步电网连接提供快速频率响应：系统集成研究", "tldr": "本文研究了基于电力电子的异步电网连接作为分布式资源聚合器提供快速频率响应的技术和经济可行性，并通过实验和仿真验证了其性能和市场潜力，并提出了建议。", "motivation": "旨在研究基于电力电子的快速频率响应技术（异步电网连接作为表后资源和分布式电源的聚合器）的系统集成，以验证其技术可行性和经济可行性，并使其能够提供电网支持功能并参与辅助服务市场。", "method": "采用电力硬件在环（PHIL）实验验证异步电网连接的快速频率响应动态性能，并将其转移到DigSilent PowerFactory中的IEEE 9节点系统进行动态稳定性分析。通过对本地分布式电源进行下垂控制增强，并在PJM辅助服务市场框架内进行长期仿真，评估其聚合能力和市场参与潜力。最后进行技术经济分析，计算潜在收入并预测15年投资回报。", "result": "证明了对本地分布式电源进行下垂控制增强可以使其聚合提供电网支持功能并参与辅助服务市场。通过快速频率响应调节计算了潜在收入，并预测了15年的投资回报。", "conclusion": "技术经济分析提出了在技术和监管层面增强的建议，以充分发挥分布式电源的潜力。", "translation": "本文介绍了一项关于基于电力电子的快速频率响应技术（一种作为表后资源和分布式电源聚合器的异步电网连接）的集成研究。文中提出了技术可行性和技术经济可行性研究。通过电力硬件在环（Power Hardware-in-the-Loop）实验验证了异步电网连接实现的快速频率响应的动态性能，并将其转移到DigSilent PowerFactory中的IEEE 9节点系统进行动态稳定性分析。我们证明了对本地分布式电源进行基于下垂的控制增强，可以使其聚合提供电网支持功能并参与辅助服务市场。为此，我们在PJM辅助服务市场框架内对系统进行了长期仿真。随后，利用快速频率响应调节来计算潜在收入，并将结果预测到15年的投资周期。最后，技术经济分析总结了在技术和监管层面增强的建议，以充分发挥分布式电源的全部潜力。", "summary": "本文对一种基于电力电子的异步电网连接技术进行了系统集成研究，该技术可作为表后资源和分布式电源的聚合器，提供快速频率响应。研究评估了其技术和经济可行性，通过电力硬件在环实验和IEEE 9节点系统仿真验证了其动态性能。结果表明，通过下垂控制增强，分布式电源能够提供电网支持并参与辅助服务市场，并对其在PJM市场中的潜在收入和15年投资回报进行了预测。研究最终提出了利用分布式电源全部潜力的技术和监管建议。", "keywords": "快速频率响应, 异步电网连接, 分布式电源, 电力硬件在环, 辅助服务市场", "comments": "这项研究创新性地将异步电网连接作为分布式电源的聚合器，以提供快速频率响应，并结合了技术和经济可行性分析，这对于促进分布式能源在电网稳定性和市场参与方面的作用具有重要意义。其采用电力硬件在环实验和长期市场仿真相结合的方法，增强了研究结果的可靠性和实用性。"}}
{"id": "2505.11122", "title": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining", "authors": ["Yu Shi", "Yitong Duan", "Jian Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.11122v2", "summary": "Alpha factor mining is pivotal in quantitative investment for identifying\npredictive signals from complex financial data. While traditional formulaic\nalpha mining relies on human expertise, contemporary automated methods, such as\nthose based on genetic programming or reinforcement learning, often struggle\nwith search inefficiency or yield alpha factors that are difficult to\ninterpret. This paper introduces a novel framework that integrates Large\nLanguage Models (LLMs) with Monte Carlo Tree Search (MCTS) to overcome these\nlimitations. Our framework leverages the LLM's instruction-following and\nreasoning capability to iteratively generate and refine symbolic alpha formulas\nwithin an MCTS-driven exploration. A key innovation is the guidance of MCTS\nexploration by rich, quantitative feedback from financial backtesting of each\ncandidate factor, enabling efficient navigation of the vast search space.\nFurthermore, a frequent subtree avoidance mechanism is introduced to enhance\nsearch diversity and prevent formulaic homogenization, further improving\nperformance. Experimental results on real-world stock market data demonstrate\nthat our LLM-based framework outperforms existing methods by mining alphas with\nsuperior predictive accuracy and trading performance. The resulting formulas\nare also more amenable to human interpretation, establishing a more effective\nand efficient paradigm for formulaic alpha mining.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.11122v2", "cate": "cs.AI", "date": "2025-05-16", "updated": "2025-07-31", "AI": {"title_translation": "穿越Alpha丛林：一个LLM驱动的MCTS框架用于公式化因子挖掘", "tldr": "本文提出一个结合LLM和MCTS的框架，用于高效且可解释地挖掘金融alpha因子。", "motivation": "传统的公式化Alpha挖掘依赖人工经验，而现有的自动化方法（如遗传编程或强化学习）存在搜索效率低或生成的Alpha因子难以解释的问题。", "method": "本文引入了一个新颖的框架，将大型语言模型（LLMs）与蒙特卡洛树搜索（MCTS）相结合。该框架利用LLM的指令遵循和推理能力，在MCTS驱动的探索中迭代生成和优化符号化Alpha公式。MCTS的探索由来自每个候选因子金融回测的丰富量化反馈引导，从而高效地导航广阔的搜索空间。此外，还引入了频繁子树规避机制，以增强搜索多样性并防止公式同质化。", "result": "在真实股票市场数据上的实验结果表明，该基于LLM的框架在挖掘具有卓越预测准确性和交易表现的Alpha因子方面优于现有方法。", "conclusion": "该框架生成的公式更易于人类解释，为公式化Alpha因子挖掘建立了一个更有效和高效的范式。", "translation": "Alpha因子挖掘在量化投资中至关重要，用于从复杂的金融数据中识别预测信号。传统的公式化Alpha挖掘依赖于人类专业知识，而当代自动化方法，例如基于遗传编程或强化学习的方法，通常存在搜索效率低下或产生的Alpha因子难以解释的问题。本文介绍了一种新颖的框架，该框架将大型语言模型（LLMs）与蒙特卡洛树搜索（MCTS）相结合，以克服这些局限性。我们的框架利用LLM的指令遵循和推理能力，在MCTS驱动的探索中迭代生成和优化符号化Alpha公式。一个关键创新是MCTS探索由每个候选因子的金融回测提供的丰富量化反馈所引导，从而能够高效地导航广阔的搜索空间。此外，引入了一种频繁子树规避机制，以增强搜索多样性并防止公式同质化，进一步提高性能。在真实股票市场数据上的实验结果表明，我们基于LLM的框架通过挖掘具有卓越预测准确性和交易表现的Alpha因子，优于现有方法。所产生的公式也更易于人类解释，为公式化Alpha因子挖掘建立了一个更有效和高效的范式。", "summary": "本文提出了一个新颖的LLM-MCTS框架，旨在解决传统和现有自动化Alpha因子挖掘方法中存在的效率低下和可解释性差的问题。该框架利用LLM的推理能力生成和优化Alpha公式，并通过金融回测的量化反馈指导MCTS的探索，同时引入子树规避机制以增加多样性。实验证明，该框架在预测准确性和交易性能上优于现有方法，并生成了更易于解释的Alpha公式。", "keywords": "Alpha因子挖掘, 大语言模型, 蒙特卡洛树搜索, 量化投资, 金融回测", "comments": "这篇论文的创新点在于将LLM的强大生成和推理能力与MCTS的搜索优化相结合，并辅以金融回测的量化反馈，为Alpha因子挖掘提供了一个全新的范式。其解决了现有自动化方法在效率和可解释性上的痛点，具有重要的实际应用价值。特别是引入的频繁子树规避机制，有效提升了搜索多样性，避免了结果的同质化。"}}
{"id": "2507.13492", "title": "On the time integration for phase field modeling of grain growth in additive manufacturing", "authors": ["Chaoqian Yuan", "Chinnapat Panwisawas", "Ye Lu"], "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13492v3", "summary": "Phase field simulations play a key role in the understanding of\nmicrostructure evolution in additive manufacturing. However, they have been\nfound extremely computationally expensive. One of the reasons is the small time\nstep requirement to resolve the complex microstructure evolution during the\nrapid solidification process. This paper investigates the possibility of using\na class of stabilized time integration algorithms to accelerate such phase\nfield simulations by increasing the time steps. The specific time integration\nformulation and theoretical analysis on energy stability were developed, based\non a phase field model dedicated to simulating rapid solidification in additive\nmanufacturing. The numerical results confirmed that the proposed method can\nensure the numerical stability and a decreasing energy requirement for the\nphase field simulations with at least two orders-of-magnitude larger time steps\nover conventional explicit methods. 2D and 3D phase field simulations have been\nconducted with relevant physical and kinetic parameters for 316L stainless\nsteels. This work provides a numerical framework for efficient phase field\nsimulations and open numerous opportunities for large scale phase field\nmodeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13492v3", "cate": "physics.comp-ph", "date": "2025-07-17", "updated": "2025-07-30", "AI": {"title_translation": "增材制造中晶粒生长的相场建模时间积分研究", "tldr": "本文研究了一种稳定的时间积分算法，用于加速增材制造中计算成本高昂的相场模拟，实现了更大的时间步长和更好的计算效率。", "motivation": "相场模拟在理解增材制造中的微观结构演变方面至关重要，但计算成本极高，其中一个原因是需要小时间步长来解析快速凝固过程中的复杂微观结构演变。", "method": "本文基于一个专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析，并使用一类稳定的时间积分算法来加速相场模拟。", "result": "数值结果证实，所提出的方法可以确保相场模拟的数值稳定性和能量需求降低，与传统显式方法相比，时间步长至少可以大两个数量级。已针对316L不锈钢进行了2D和3D相场模拟。", "conclusion": "这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模提供了大量机会。", "translation": "相场模拟在理解增材制造中的微观结构演变方面发挥着关键作用。然而，它们被发现计算成本极高。其中一个原因是需要小时间步长来解析快速凝固过程中的复杂微观结构演变。本文研究了使用一类稳定的时间积分算法来加速此类相场模拟的可能性，通过增加时间步长。基于一个专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析。数值结果证实，所提出的方法可以确保相场模拟的数值稳定性并降低能量需求，与传统显式方法相比，时间步长至少可以大两个数量级。已针对316L不锈钢进行了相关的物理和动力学参数的2D和3D相场模拟。这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模提供了大量机会。", "summary": "本文针对增材制造中相场模拟计算成本高昂且时间步长要求小的问题，提出并研究了一类稳定的时间积分算法。研究开发了新的时间积分公式和能量稳定性理论，并数值验证了该方法能显著增大时间步长（至少两个数量级），同时保持数值稳定性和降低能量需求。这项工作为增材制造中的高效大规模相场模拟提供了新的数值框架。", "keywords": "相场模拟, 时间积分, 增材制造, 晶粒生长, 计算效率", "comments": "本文的创新点在于引入并验证了稳定的时间积分算法来解决相场模拟在增材制造中计算效率低下的问题。通过大幅增加时间步长，该方法显著提高了模拟效率，为大规模和更复杂的相场建模提供了可能性，具有重要的实际应用价值。"}}
{"id": "2507.23660", "title": "DuLoc: Life-Long Dual-Layer Localization in Changing and Dynamic Expansive Scenarios", "authors": ["Haoxuan Jiang", "Peicong Qian", "Yusen Xie", "Xiaocong Li", "Ming Liu", "Jun Ma"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23660v1", "summary": "LiDAR-based localization serves as a critical component in autonomous\nsystems, yet existing approaches face persistent challenges in balancing\nrepeatability, accuracy, and environmental adaptability. Traditional point\ncloud registration methods relying solely on offline maps often exhibit limited\nrobustness against long-term environmental changes, leading to localization\ndrift and reliability degradation in dynamic real-world scenarios. To address\nthese challenges, this paper proposes DuLoc, a robust and accurate localization\nmethod that tightly couples LiDAR-inertial odometry with offline map-based\nlocalization, incorporating a constant-velocity motion model to mitigate\noutlier noise in real-world scenarios. Specifically, we develop a LiDAR-based\nlocalization framework that seamlessly integrates a prior global map with\ndynamic real-time local maps, enabling robust localization in unbounded and\nchanging environments. Extensive real-world experiments in ultra unbounded port\nthat involve 2,856 hours of operational data across 32 Intelligent Guided\nVehicles (IGVs) are conducted and reported in this study. The results attained\ndemonstrate that our system outperforms other state-of-the-art LiDAR\nlocalization systems in large-scale changing outdoor environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23660v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DuLoc：在变化和动态广阔场景中的终身双层定位", "tldr": "DuLoc提出了一种鲁棒、精确的LiDAR定位方法，结合LiDAR-惯性里程计和离线地图，通过整合全局和实时局部地图，解决了传统方法在长期环境变化和动态场景中的鲁Loc问题。", "motivation": "现有LiDAR定位方法在平衡重复性、精度和环境适应性方面面临挑战。传统的点云配准方法依赖离线地图，对长期环境变化鲁棒性差，导致定位漂移和可靠性下降。", "method": "本文提出了DuLoc，一种结合LiDAR-惯性里程计和离线地图定位的鲁棒精确方法。它引入了匀速运动模型来减轻野外噪声，并无缝整合先验全局地图与动态实时局部地图，以在无界和变化环境中实现鲁棒定位。", "result": "在超大港口进行的2,856小时、涉及32辆智能引导车（IGVs）的真实世界实验表明，DuLoc系统在大规模变化的户外环境中优于其他最先进的LiDAR定位系统。", "conclusion": "DuLoc通过其双层定位框架，有效解决了LiDAR定位在长期环境变化和动态场景中的鲁棒性、精度和可靠性问题，并在实际应用中展现出优越性能。", "translation": "基于LiDAR的定位是自主系统中的关键组成部分，然而现有方法在平衡重复性、精度和环境适应性方面面临持续挑战。传统上仅依赖离线地图的点云配准方法对长期环境变化的鲁棒性有限，导致在动态真实世界场景中出现定位漂移和可靠性下降。为了解决这些挑战，本文提出了DuLoc，一种鲁棒且精确的定位方法，它将LiDAR惯性里程计与基于离线地图的定位紧密结合，并引入匀速运动模型以减轻真实世界场景中的异常噪声。具体而言，我们开发了一个基于LiDAR的定位框架，该框架将先验全局地图与动态实时局部地图无缝集成，从而在无界和变化的环境中实现鲁棒定位。本研究报告了在超大港口进行的广泛真实世界实验，这些实验涉及32辆智能引导车（IGV）的2,856小时运行数据。所获得的结果表明，我们的系统在大规模变化的户外环境中优于其他最先进的LiDAR定位系统。", "summary": "DuLoc是一种为自主系统设计的鲁棒、精确的LiDAR定位方法，旨在解决传统方法在长期环境变化和动态场景中的局限性。它创新性地将LiDAR-惯性里程计与离线地图定位紧密结合，并整合了全局与实时局部地图，同时利用匀速运动模型来抑制噪声。通过在真实世界港口场景中进行大规模实验验证，DuLoc展现出优于现有先进系统的卓越性能，有效提升了在复杂环境中的定位鲁棒性和精度。", "keywords": "LiDAR定位, 双层定位, 终身定位, 动态环境, 自主系统", "comments": "DuLoc的创新之处在于其双层定位框架，将LiDAR-惯性里程计与离线地图定位结合，并通过全局与实时局部地图的整合，显著提升了系统在长期动态变化环境中的适应性和鲁棒性。其在超大规模真实世界数据上的验证，也突显了其实用性和可靠性。"}}
{"id": "2507.23437", "title": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "authors": ["Yinhui Ma", "Tomomasa Yamasaki", "Zhehui Wang", "Tao Luo", "Bo Wang"], "categories": ["cs.LG", "I.2.6; C.1.3; C.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICCAD 2025 (camera-ready); 9 pages, 5 figures", "url": "http://arxiv.org/abs/2507.23437v1", "summary": "Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach\nto automatically co-optimizing neural network performance and hardware energy\nefficiency, making it particularly useful for the development of Deep Neural\nNetwork accelerators on the edge. However, the extensive search space and high\ncomputational cost pose significant challenges to its practical adoption. To\naddress these limitations, we propose Coflex, a novel HW-NAS framework that\nintegrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian\noptimization. By leveraging sparse inducing points, Coflex reduces the GP\nkernel complexity from cubic to near-linear with respect to the number of\ntraining samples, without compromising optimization performance. This enables\nscalable approximation of large-scale search space, substantially decreasing\ncomputational overhead while preserving high predictive accuracy. We evaluate\nthe efficacy of Coflex across various benchmarks, focusing on\naccelerator-specific architecture. Our experi- mental results show that Coflex\noutperforms state-of-the-art methods in terms of network accuracy and\nEnergy-Delay-Product, while achieving a computational speed-up ranging from\n1.9x to 9.5x.", "comment": "Accepted to ICCAD 2025 (camera-ready); 9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.23437v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Coflex：利用稀疏高斯过程增强硬件感知神经架构搜索，实现高效可扩展的深度神经网络加速器设计", "tldr": "Coflex通过结合稀疏高斯过程和多目标贝叶斯优化，显著加速了硬件感知神经架构搜索（HW-NAS），同时提高了性能和能效，解决了其计算成本高和搜索空间大的挑战。", "motivation": "硬件感知神经架构搜索（HW-NAS）在边缘设备深度神经网络（DNN）加速器开发中具有潜力，但其庞大的搜索空间和高计算成本严重阻碍了实际应用。", "method": "本文提出了Coflex框架，将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程核的复杂度从立方级降低到近线性，从而实现大规模搜索空间的可扩展近似，同时保持优化性能和高预测精度。", "result": "实验结果表明，Coflex在网络精度和能量延迟积方面优于现有最先进的方法，并实现了1.9倍至9.5倍的计算加速。", "conclusion": "Coflex成功解决了硬件感知神经架构搜索（HW-NAS）中计算成本高和可扩展性差的问题，为高效和可扩展的深度神经网络加速器设计提供了新的解决方案。", "translation": "硬件感知神经架构搜索（HW-NAS）是一种有效的方法，可以自动协同优化神经网络性能和硬件能效，这使其在边缘设备上开发深度神经网络加速器方面特别有用。然而，其广泛的搜索空间和高计算成本对其实际应用构成了重大挑战。为了解决这些限制，我们提出了Coflex，一个新颖的HW-NAS框架，它将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程核的复杂度从相对于训练样本数量的立方级降低到近线性，而不会影响优化性能。这使得大规模搜索空间的可扩展近似成为可能，在保持高预测精度的同时大幅降低了计算开销。我们在各种基准测试中评估了Coflex的功效，重点关注加速器特定的架构。我们的实验结果表明，Coflex在网络精度和能量延迟积方面优于现有最先进的方法，同时实现了1.9倍至9.5倍的计算加速。", "summary": "Coflex是一个创新的硬件感知神经架构搜索（HW-NAS）框架，旨在解决现有方法中搜索空间大和计算成本高的问题。它通过整合稀疏高斯过程（SGP）和多目标贝叶斯优化实现这一目标。Coflex利用稀疏诱导点将高斯过程的计算复杂度从立方级降低到近线性，从而能够对大规模搜索空间进行高效且可扩展的近似，同时保持高预测精度和优化性能。实验证明，Coflex在网络精度和能量延迟积方面超越了现有技术，并实现了显著的计算加速。", "keywords": "硬件感知神经架构搜索, 稀疏高斯过程, 深度神经网络加速器, 贝叶斯优化, 边缘计算", "comments": "Coflex的创新之处在于将稀疏高斯过程引入到硬件感知神经架构搜索（HW-NAS）中，有效解决了大规模搜索空间下的计算效率瓶颈。这对于在资源受限的边缘设备上设计高性能深度神经网络加速器具有重要意义，因为它能在保证优化效果的同时大幅缩短设计周期和降低计算资源消耗。"}}
{"id": "2507.23518", "title": "EVMx: An FPGA-Based Smart Contract Processing Unit", "authors": ["Joel Poncha Lemayian", "Hachem Bensalem", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.23518v1", "summary": "Ethereum blockchain uses smart contracts (SCs) to implement decentralized\napplications (dApps). SCs are executed by the Ethereum virtual machine (EVM)\nrunning within an Ethereum client. Moreover, the EVM has been widely adopted by\nother blockchain platforms, including Solana, Cardano, Avalanche, Polkadot, and\nmore. However, the EVM performance is limited by the constraints of the\ngeneral-purpose computer it operates on. This work proposes offloading SC\nexecution onto a dedicated hardware-based EVM. Specifically, EVMx is an\nFPGA-based SC execution engine that benefits from the inherent parallelism and\nhigh-speed processing capabilities of a hardware architecture. Synthesis\nresults demonstrate a reduction in execution time of 61% to 99% for commonly\nused operation codes compared to CPU-based SC execution environments. Moreover,\nthe execution time of Ethereum blocks on EVMx is up to 6x faster compared to\nanalogous works in the literature. These results highlight the potential of the\nproposed architecture to accelerate SC execution and enhance the performance of\nEVM-compatible blockchains.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.23518v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "EVMx：一个基于FPGA的智能合约处理单元", "tldr": "EVMx是一个基于FPGA的智能合约执行引擎，显著加速了EVM兼容区块链的智能合约执行，性能提升高达6倍。", "motivation": "现有以太坊虚拟机（EVM）在通用计算机上的性能受限，无法充分发挥智能合约的潜力，因此需要专用硬件加速。", "method": "提出EVMx，一个基于FPGA的智能合约执行引擎，利用硬件架构固有的并行性和高速处理能力，将智能合约执行卸载到专用硬件上。", "result": "与CPU环境相比，常用操作码的执行时间减少61%至99%。以太坊区块在EVMx上的执行时间比文献中的类似工作快达6倍。", "conclusion": "所提出的EVMx架构能够显著加速智能合约执行，并增强EVM兼容区块链的性能。", "translation": "以太坊区块链使用智能合约（SCs）来实现去中心化应用（dApps）。智能合约由运行在以太坊客户端内的以太坊虚拟机（EVM）执行。此外，EVM已被其他区块链平台广泛采用，包括Solana、Cardano、Avalanche、Polkadot等。然而，EVM的性能受到其运行的通用计算机的限制。这项工作提出将智能合约执行卸载到专用的基于硬件的EVM上。具体来说，EVMx是一个基于FPGA的智能合约执行引擎，它受益于硬件架构固有的并行性和高速处理能力。综合结果表明，与基于CPU的智能合约执行环境相比，常用操作码的执行时间减少了61%至99%。此外，EVMx上以太坊区块的执行时间比文献中的类似工作快达6倍。这些结果突出了所提出的架构加速智能合约执行和提升EVM兼容区块链性能的潜力。", "summary": "该论文提出EVMx，一个基于FPGA的专用智能合约处理单元，旨在解决以太坊虚拟机（EVM）在通用计算机上性能受限的问题。EVMx利用FPGA固有的并行性和高速处理能力，将智能合约执行卸载到硬件上。实验结果表明，与CPU环境相比，EVMx能将常用操作码的执行时间减少61%至99%，并且处理以太坊区块的速度比现有工作快达6倍，显著提升了EVM兼容区块链的智能合约执行效率。", "keywords": "FPGA, 智能合约, 以太坊虚拟机, 硬件加速, 区块链", "comments": "这项工作通过引入基于FPGA的专用硬件加速器EVMx，创新性地解决了以太坊虚拟机（EVM）在通用计算环境下的性能瓶颈。其重要性在于，EVMx能够显著提升智能合约的执行效率，这对于处理高并发交易和复杂去中心化应用至关重要，为EVM兼容的区块链平台带来了显著的性能增益。"}}
{"id": "2507.23736", "title": "DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction", "authors": ["Kyle Naddeo", "Nikolas Koutsoubis", "Rahul Krish", "Ghulam Rasool", "Nidhal Bouaynaya", "Tony OSullivan", "Raj Krish"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      15 pages, 6 figures,", "url": "http://arxiv.org/abs/2507.23736v1", "summary": "Access to medical imaging and associated text data has the potential to drive\nmajor advances in healthcare research and patient outcomes. However, the\npresence of Protected Health Information (PHI) and Personally Identifiable\nInformation (PII) in Digital Imaging and Communications in Medicine (DICOM)\nfiles presents a significant barrier to the ethical and secure sharing of\nimaging datasets. This paper presents a hybrid de-identification framework\ndeveloped by Impact Business Information Solutions (IBIS) that combines\nrule-based and AI-driven techniques, and rigorous uncertainty quantification\nfor comprehensive PHI/PII removal from both metadata and pixel data.\n  Our approach begins with a two-tiered rule-based system targeting explicit\nand inferred metadata elements, further augmented by a large language model\n(LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of\nsynthetic datasets simulating realistic clinical PHI/PII. For pixel data, we\nemploy an uncertainty-aware Faster R-CNN model to localize embedded text,\nextract candidate PHI via Optical Character Recognition (OCR), and apply the\nNER pipeline for final redaction. Crucially, uncertainty quantification\nprovides confidence measures for AI-based detections to enhance automation\nreliability and enable informed human-in-the-loop verification to manage\nresidual risks.\n  This uncertainty-aware deidentification framework achieves robust performance\nacross benchmark datasets and regulatory standards, including DICOM, HIPAA, and\nTCIA compliance metrics. By combining scalable automation, uncertainty\nquantification, and rigorous quality assurance, our solution addresses critical\nchallenges in medical data de-identification and supports the secure, ethical,\nand trustworthy release of imaging data for research.", "comment": "15 pages, 6 figures,", "pdf_url": "http://arxiv.org/pdf/2507.23736v1", "cate": "stat.ML", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于混合AI和规则的DICOM去识别框架，实现可扩展、不确定性感知的编辑", "tldr": "该论文提出了一种混合AI和规则的去识别框架，用于从DICOM文件中安全、伦理地移除受保护的健康信息（PHI）和个人身份信息（PII），并通过不确定性量化提高自动化可靠性。", "motivation": "访问医学影像和相关文本数据能够推动医疗保健研究和患者结果的重大进展。然而，DICOM文件中存在的受保护健康信息（PHI）和个人身份信息（PII）是伦理和安全共享影像数据集的重大障碍。", "method": "该方法采用混合去识别框架，结合了基于规则和AI驱动的技术。对于元数据，首先采用两层基于规则的系统，针对显式和推断的元数据元素，并辅以一个针对命名实体识别（NER）微调的大型语言模型（LLM）。对于像素数据，使用不确定性感知的Faster R-CNN模型来定位嵌入文本，通过光学字符识别（OCR）提取候选PHI，并应用NER管道进行最终编辑。关键在于，不确定性量化为基于AI的检测提供了置信度测量，以提高自动化可靠性并支持知情的人工验证来管理残余风险。", "result": "该不确定性感知的去识别框架在基准数据集和包括DICOM、HIPAA和TCIA合规性指标在内的监管标准上实现了稳健的性能。", "conclusion": "通过结合可扩展的自动化、不确定性量化和严格的质量保证，该解决方案解决了医学数据去识别中的关键挑战，并支持安全、伦理和可信地发布影像数据用于研究。", "translation": "访问医学影像和相关文本数据有可能推动医疗保健研究和患者结果的重大进展。然而，数字影像和医学通讯（DICOM）文件中存在的受保护健康信息（PHI）和个人身份信息（PII）是伦理和安全共享影像数据集的重大障碍。本文提出了一种由Impact Business Information Solutions (IBIS)开发的混合去识别框架，该框架结合了基于规则和AI驱动的技术，以及严格的不确定性量化，以从元数据和像素数据中全面移除PHI/PII。\n我们的方法始于一个两层基于规则的系统，针对显式和推断的元数据元素，并辅以一个针对命名实体识别（NER）微调的大型语言模型（LLM），该模型在一套模拟真实临床PHI/PII的合成数据集上进行训练。对于像素数据，我们采用不确定性感知的Faster R-CNN模型来定位嵌入文本，通过光学字符识别（OCR）提取候选PHI，并应用NER管道进行最终编辑。关键在于，不确定性量化为基于AI的检测提供了置信度测量，以提高自动化可靠性并支持知情的人工验证来管理残余风险。\n这种不确定性感知的去识别框架在基准数据集和包括DICOM、HIPAA和TCIA合规性指标在内的监管标准上实现了稳健的性能。通过结合可扩展的自动化、不确定性量化和严格的质量保证，我们的解决方案解决了医学数据去识别中的关键挑战，并支持安全、伦理和可信地发布影像数据用于研究。", "summary": "本论文提出了一种混合AI和规则的去识别框架，旨在从DICOM医疗影像文件中移除受保护的健康信息（PHI）和个人身份信息（PII）。该框架结合了针对元数据的两层规则系统和微调的LLM（用于NER），以及针对像素数据的不确定性感知Faster R-CNN模型和OCR。通过引入不确定性量化，该系统提高了AI检测的可靠性，并支持人工验证以管理风险。该方法在基准数据集和监管标准下表现出稳健的性能，为安全、伦理地共享医疗影像数据提供了解决方案。", "keywords": "DICOM, 去识别, 混合AI, 不确定性量化, 医疗影像", "comments": "该论文的创新点在于其混合AI和规则的方法，以及引入不确定性量化来提高去识别过程的可靠性和可信度。这对于解决医学数据共享中的隐私和安全挑战至关重要，为医疗研究的数据可访问性提供了实用且重要的解决方案。"}}
{"id": "2506.10006", "title": "HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction", "authors": ["Jie Qin", "Wei Yang", "Yan Su", "Yiran Zhu", "Weizhen Li", "Yunyue Pan", "Chengchang Pan", "Honggang Qi"], "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      8 pages,6 figures,3 tables,accepted by the 33rd ACM International Conference on Multimedia(ACM MM 2025)", "url": "http://arxiv.org/abs/2506.10006v2", "summary": "In breast cancer HER2 assessment, clinical evaluation relies on combined H&E\nand IHC images, yet acquiring both modalities is often hindered by clinical\nconstraints and cost. We propose an adaptive bimodal prediction framework that\nflexibly supports single- or dual-modality inputs through two core innovations:\na dynamic branch selector activating modality completion or joint inference\nbased on input availability, and a cross-modal GAN (CM-GAN) enabling\nfeature-space reconstruction of missing modalities. This design dramatically\nimproves H&E-only accuracy from 71.44% to 94.25%, achieves 95.09% with full\ndual-modality inputs, and maintains 90.28% reliability under single-modality\nconditions. The \"dual-modality preferred, single-modality compatible\"\narchitecture delivers near-dual-modality accuracy without mandatory\nsynchronized acquisition, offering a cost-effective solution for\nresource-limited regions and significantly improving HER2 assessment\naccessibility.", "comment": "8 pages,6 figures,3 tables,accepted by the 33rd ACM International\n  Conference on Multimedia(ACM MM 2025)", "pdf_url": "http://arxiv.org/pdf/2506.10006v2", "cate": "cs.MM", "date": "2025-04-12", "updated": "2025-07-31", "AI": {"title_translation": "通过动态双向重建实现灵活多模态输入的HER2表达预测", "tldr": "该研究提出了一种自适应双模态预测框架，通过动态分支选择器和跨模态GAN，在HER2评估中灵活支持单模态或双模态输入，显著提高单模态准确性并保持接近双模态的性能。", "motivation": "在乳腺癌HER2评估中，临床评估依赖于H&E和IHC图像的结合，但获取这两种模态常常受到临床限制和成本的阻碍。", "method": "提出了一种自适应双模态预测框架，通过两个核心创新灵活支持单模态或双模态输入：一个动态分支选择器，根据输入可用性激活模态补全或联合推理；一个跨模态GAN（CM-GAN），实现缺失模态的特征空间重建。", "result": "H&E单模态准确率从71.44%显著提高到94.25%；全双模态输入达到95.09%；单模态条件下保持90.28%的可靠性。", "conclusion": "“双模态优先，单模态兼容”的架构在不强制同步采集的情况下，提供了接近双模态的准确性，为资源有限的地区提供了一种经济有效的解决方案，显著提高了HER2评估的可及性。", "translation": "在乳腺癌HER2评估中，临床评估依赖于H&E和IHC图像的结合，然而获取这两种模态常常受到临床限制和成本的阻碍。我们提出了一种自适应双模态预测框架，通过两个核心创新灵活支持单模态或双模态输入：一个动态分支选择器，根据输入可用性激活模态补全或联合推理；一个跨模态GAN（CM-GAN），实现缺失模态的特征空间重建。这种设计将仅H&E的准确率从71.44%显著提高到94.25%，在使用完整双模态输入时达到95.09%，并在单模态条件下保持90.28%的可靠性。“双模态优先，单模态兼容”的架构在不强制同步采集的情况下，提供了接近双模态的准确性，为资源有限的地区提供了一种经济有效的解决方案，显著提高了HER2评估的可及性。", "summary": "本文提出了一种用于乳腺癌HER2表达预测的自适应双模态框架，旨在解决H&E和IHC图像联合获取的成本与限制。该框架通过动态分支选择器和跨模态GAN（CM-GAN）实现灵活的单模态或双模态输入。实验结果表明，该方法显著提升了单模态H&E输入的准确率，并在单模态条件下保持高可靠性，同时在双模态输入下达到最佳性能，为资源受限地区提供了经济高效且可及的HER2评估方案。", "keywords": "HER2预测, 多模态输入, 动态重建, 跨模态GAN, 乳腺癌评估", "comments": "该论文的创新点在于其提出的“双模态优先，单模态兼容”的架构，通过动态分支选择器和跨模态GAN（CM-GAN）有效解决了临床实践中多模态数据获取的挑战。这种灵活的设计显著提高了单模态输入的预测准确性，使其在资源有限的地区具有重要的临床应用价值和可及性，是医疗影像分析领域的一个重要进展。"}}
{"id": "2507.23115", "title": "FLOSS: Federated Learning with Opt-Out and Straggler Support", "authors": ["David J Goetze", "Dahlia J Felten", "Jeannie R Albrecht", "Rohit Bhattacharya"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2507.23115v1", "summary": "Previous work on data privacy in federated learning systems focuses on\nprivacy-preserving operations for data from users who have agreed to share\ntheir data for training. However, modern data privacy agreements also empower\nusers to use the system while opting out of sharing their data as desired. When\ncombined with stragglers that arise from heterogeneous device capabilities, the\nresult is missing data from a variety of sources that introduces bias and\ndegrades model performance. In this paper, we present FLOSS, a system that\nmitigates the impacts of such missing data on federated learning in the\npresence of stragglers and user opt-out, and empirically demonstrate its\nperformance in simulations.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.23115v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "FLOSS：支持选择退出和掉队者的联邦学习", "tldr": "FLOSS是一个联邦学习系统，旨在减轻用户选择退出和掉队者导致的缺失数据对模型性能的影响。", "motivation": "现有的联邦学习隐私保护工作主要关注用户同意共享数据的情况，但现代隐私协议允许用户在需要时选择不共享数据。这种选择退出行为与设备能力异构导致的掉队者相结合，会造成数据缺失，从而引入偏差并降低模型性能。", "method": "论文提出了FLOSS系统，该系统旨在减轻在存在掉队者和用户选择退出的情况下，缺失数据对联邦学习的影响。", "result": "论文通过模拟实验经验性地证明了FLOSS系统的性能。", "conclusion": "FLOSS系统能够有效缓解联邦学习中因用户选择退出和掉队者造成的缺失数据问题，从而提升模型性能。", "translation": "以往关于联邦学习系统中数据隐私的工作主要关注于对同意共享数据进行训练的用户数据进行隐私保护操作。然而，现代数据隐私协议也赋予用户在需要时选择不共享数据的情况下使用系统的权利。当这种情况与设备能力异构导致的掉队者相结合时，结果是来自各种来源的数据缺失，这会引入偏差并降低模型性能。在本文中，我们提出了FLOSS，一个旨在减轻在存在掉队者和用户选择退出的情况下，此类缺失数据对联邦学习影响的系统，并通过模拟实验经验性地证明了其性能。", "summary": "FLOSS是一个联邦学习系统，旨在解决因用户选择退出和设备性能差异导致的掉队者所造成的缺失数据问题。这些缺失数据会引入偏差并降低模型性能。FLOSS通过缓解这些缺失数据的影响来提升联邦学习的性能，并在模拟中得到了验证。", "keywords": "联邦学习, 数据隐私, 选择退出, 掉队者, 缺失数据", "comments": "该论文关注联邦学习中一个实际且重要的挑战：用户选择退出和设备异构性导致的缺失数据问题。FLOSS系统提出的解决方案对于提高联邦学习的鲁棒性和实用性具有重要意义。其创新点在于同时考虑了用户隐私选择和系统效率（掉队者）的双重影响。"}}
{"id": "2507.23263", "title": "Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels", "authors": ["Haoxian Ruan", "Zhihua Xu", "Zhijing Yang", "Guang Ma", "Jieming Xie", "Changxiang Fan", "Tianshui Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 13 figures, publish to ESWA (Expert Systems With Applications)", "url": "http://arxiv.org/abs/2507.23263v1", "summary": "Multi-label image recognition with partial labels (MLR-PL) is designed to\ntrain models using a mix of known and unknown labels. Traditional methods rely\non semantic or feature correlations to create pseudo-labels for unidentified\nlabels using pre-set thresholds. This approach often overlooks the varying\nscore distributions across categories, resulting in inaccurate and incomplete\npseudo-labels, thereby affecting performance. In our study, we introduce the\nSemantic-Aware Threshold Learning (SATL) algorithm. This innovative approach\ncalculates the score distribution for both positive and negative samples within\neach category and determines category-specific thresholds based on these\ndistributions. These distributions and thresholds are dynamically updated\nthroughout the learning process. Additionally, we implement a differential\nranking loss to establish a significant gap between the score distributions of\npositive and negative samples, enhancing the discrimination of the thresholds.\nComprehensive experiments and analysis on large-scale multi-label datasets,\nsuch as Microsoft COCO and VG-200, demonstrate that our method significantly\nimproves performance in scenarios with limited labels.", "comment": "15 pages, 13 figures, publish to ESWA (Expert Systems With\n  Applications)", "pdf_url": "http://arxiv.org/pdf/2507.23263v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "学习语义感知阈值用于部分标签多标签图像识别", "tldr": "提出一种语义感知阈值学习算法（SATL），通过动态更新类别特定阈值和引入差分排序损失，显著提高部分标签多标签图像识别性能。", "motivation": "传统的部分标签多标签图像识别方法依赖预设阈值生成伪标签，但忽略了类别分数分布差异，导致伪标签不准确和不完整，影响模型性能。", "method": "提出语义感知阈值学习（SATL）算法，该算法计算每个类别中正负样本的分数分布，并基于这些分布动态确定并更新类别特定阈值。此外，引入差分排序损失以在正负样本分数分布之间建立显著差距，增强阈值的判别能力。", "result": "在Microsoft COCO和VG-200等大规模多标签数据集上的综合实验和分析表明，所提出的方法在有限标签场景下显著提高了性能。", "conclusion": "SATL算法通过动态地、语义感知地确定类别特定阈值，有效解决了部分标签多标签图像识别中伪标签不准确的问题，从而显著提升了模型性能。", "translation": "部分标签多标签图像识别（MLR-PL）旨在利用已知和未知标签的混合数据训练模型。传统方法依赖语义或特征相关性，使用预设阈值生成未识别标签的伪标签。这种方法常常忽略了跨类别的分数分布差异，导致伪标签不准确和不完整，从而影响性能。在我们的研究中，我们引入了语义感知阈值学习（SATL）算法。这种创新方法计算每个类别中正负样本的分数分布，并根据这些分布确定类别特定阈值。这些分布和阈值在学习过程中动态更新。此外，我们实施了差分排序损失，以在正负样本的分数分布之间建立显著差距，从而增强阈值的判别能力。在Microsoft COCO和VG-200等大规模多标签数据集上的综合实验和分析表明，我们的方法在有限标签场景下显著提高了性能。", "summary": "本文针对部分标签多标签图像识别（MLR-PL）中传统方法因预设阈值导致伪标签不准确的问题，提出了一种语义感知阈值学习（SATL）算法。SATL通过动态计算并更新每个类别的正负样本分数分布，从而确定类别特定的阈值。为进一步增强阈值判别力，引入了差分排序损失。实验证明，该方法在有限标签数据集上显著提升了性能。", "keywords": "多标签图像识别, 部分标签, 语义感知阈值, 伪标签, 差分排序损失", "comments": "该论文的创新点在于提出了动态学习类别特定阈值的概念，并结合差分排序损失来增强阈值的判别能力，有效解决了部分标签学习中伪标签生成不准确的关键问题，对部分标签多标签图像识别领域具有重要意义。"}}
{"id": "2507.23001", "title": "LesionGen: A Concept-Guided Diffusion Model for Dermatology Image Synthesis", "authors": ["Jamil Fayyad", "Nourhan Bayasi", "Ziyang Yu", "Homayoun Najjaran"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at the MICCAI 2025 ISIC Workshop", "url": "http://arxiv.org/abs/2507.23001v1", "summary": "Deep learning models for skin disease classification require large, diverse,\nand well-annotated datasets. However, such resources are often limited due to\nprivacy concerns, high annotation costs, and insufficient demographic\nrepresentation. While text-to-image diffusion probabilistic models (T2I-DPMs)\noffer promise for medical data synthesis, their use in dermatology remains\nunderexplored, largely due to the scarcity of rich textual descriptions in\nexisting skin image datasets. In this work, we introduce LesionGen, a\nclinically informed T2I-DPM framework for dermatology image synthesis. Unlike\nprior methods that rely on simplistic disease labels, LesionGen is trained on\nstructured, concept-rich dermatological captions derived from expert\nannotations and pseudo-generated, concept-guided reports. By fine-tuning a\npretrained diffusion model on these high-quality image-caption pairs, we enable\nthe generation of realistic and diverse skin lesion images conditioned on\nmeaningful dermatological descriptions. Our results demonstrate that models\ntrained solely on our synthetic dataset achieve classification accuracy\ncomparable to those trained on real images, with notable gains in worst-case\nsubgroup performance. Code and data are available here.", "comment": "Accepted at the MICCAI 2025 ISIC Workshop", "pdf_url": "http://arxiv.org/pdf/2507.23001v1", "cate": "eess.IV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "LesionGen：一种概念引导的皮肤病图像合成扩散模型", "tldr": "LesionGen是一个概念引导的扩散模型，用于合成皮肤病图像，解决了现有数据集不足的问题，并提高了分类模型的性能，尤其是在处理少数群体数据方面。", "motivation": "皮肤病分类的深度学习模型需要大量、多样化且标注良好的数据集，但现有资源因隐私、高昂的标注成本和人口统计学代表性不足而受限。尽管文本到图像扩散概率模型（T2I-DPMs）在医学数据合成方面前景广阔，但由于现有皮肤图像数据集中缺乏丰富的文本描述，其在皮肤病学中的应用仍未得到充分探索。", "method": "本文介绍了LesionGen，一个临床知情的T2I-DPM框架。与依赖简单疾病标签的现有方法不同，LesionGen通过在源自专家标注和伪生成、概念引导报告的结构化、概念丰富的皮肤病学描述上微调预训练的扩散模型，从而能够生成以有意义的皮肤病学描述为条件的逼真且多样的皮肤病变图像。", "result": "我们的结果表明，仅在我们的合成数据集上训练的模型，其分类准确率与在真实图像上训练的模型相当，并且在最差子组性能上有所显著提升。", "conclusion": "LesionGen通过生成高质量的合成皮肤病图像，有效解决了真实数据稀缺的问题，为皮肤病分类模型提供了有价值的训练资源，并提升了模型的泛化能力和对少数群体的性能。", "translation": "深度学习模型用于皮肤病分类需要大量、多样化且标注良好的数据集。然而，由于隐私问题、高昂的标注成本和不足的人口统计学代表性，此类资源往往有限。尽管文本到图像扩散概率模型（T2I-DPMs）为医学数据合成提供了希望，但由于现有皮肤图像数据集中缺乏丰富的文本描述，它们在皮肤病学中的应用仍未得到充分探索。在这项工作中，我们引入了LesionGen，一个临床知情的T2I-DPM框架，用于皮肤病图像合成。与依赖简单疾病标签的现有方法不同，LesionGen在结构化、概念丰富的皮肤病学描述上进行训练，这些描述来源于专家标注和伪生成、概念引导的报告。通过在这些高质量的图像-文本对上微调预训练的扩散模型，我们能够生成以有意义的皮肤病学描述为条件的逼真且多样的皮肤病变图像。我们的结果表明，仅在我们的合成数据集上训练的模型，其分类准确率与在真实图像上训练的模型相当，并且在最差子组性能上有所显著提升。代码和数据可在此处获取。", "summary": "本文介绍了LesionGen，一个概念引导的扩散模型，旨在解决皮肤病学中高质量、多样化数据集稀缺的问题。该模型通过在结构化、概念丰富的皮肤病学描述上微调预训练的扩散模型，生成逼真且多样的皮肤病变图像。实验结果表明，使用LesionGen合成数据训练的分类模型，其性能与使用真实数据训练的模型相当，并在处理少数群体数据时表现出显著的性能提升。", "keywords": "皮肤病图像合成, 扩散模型, LesionGen, 数据增强, 深度学习", "comments": "LesionGen的创新之处在于其概念引导的扩散模型方法，特别是利用结构化、概念丰富的皮肤病学描述来指导图像合成，这比传统的简单标签更具信息量。这对于解决医学图像数据稀缺、隐私限制以及数据多样性不足等问题具有重要意义。该工作不仅提供了高质量的合成数据，还验证了其在提升皮肤病分类模型性能，尤其是改善最差子组性能方面的有效性，展现了其在临床应用中的巨大潜力。"}}
{"id": "2507.23575", "title": "Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation", "authors": ["Sobhan Asasi", "Mohamed Ilyas Lakhal", "Ozge Mercanoglu Sincan", "Richard Bowden"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at BMVC 2025", "url": "http://arxiv.org/abs/2507.23575v1", "summary": "Sign Language Translation (SLT) is a challenging task that requires bridging\nthe modality gap between visual and linguistic information while capturing\nsubtle variations in hand shapes and movements. To address these challenges, we\nintroduce \\textbf{BeyondGloss}, a novel gloss-free SLT framework that leverages\nthe spatio-temporal reasoning capabilities of Video Large Language Models\n(VideoLLMs). Since existing VideoLLMs struggle to model long videos in detail,\nwe propose a novel approach to generate fine-grained, temporally-aware textual\ndescriptions of hand motion. A contrastive alignment module aligns these\ndescriptions with video features during pre-training, encouraging the model to\nfocus on hand-centric temporal dynamics and distinguish signs more effectively.\nTo further enrich hand-specific representations, we distill fine-grained\nfeatures from HaMeR. Additionally, we apply a contrastive loss between sign\nvideo representations and target language embeddings to reduce the modality gap\nin pre-training. \\textbf{BeyondGloss} achieves state-of-the-art performance on\nthe Phoenix14T and CSL-Daily benchmarks, demonstrating the effectiveness of the\nproposed framework. We will release the code upon acceptance of the paper.", "comment": "Accepted at BMVC 2025", "pdf_url": "http://arxiv.org/pdf/2507.23575v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "超越手语注释：一种以手部为中心的无注释手语翻译框架", "tldr": "BeyondGloss是一个新颖的无注释手语翻译框架，利用视频大语言模型生成精细手部运动描述，并通过对比学习和特征蒸馏提升手语翻译性能，在Phoenix14T和CSL-Daily数据集上取得了最先进的成果。", "motivation": "手语翻译（SLT）面临挑战，需要弥合视觉和语言信息之间的模态鸿沟，并捕捉手形和手部运动的细微变化。现有视频大语言模型在详细建模长视频方面存在困难。", "method": "本研究提出了BeyondGloss框架，这是一个新颖的无注释手语翻译（SLT）框架，利用视频大语言模型（VideoLLMs）的时空推理能力。主要方法包括：1) 提出一种新颖的方法生成手部运动的精细、时序感知的文本描述；2) 在预训练期间，使用对比对齐模块将这些描述与视频特征对齐，促使模型关注以手部为中心的时间动态并更有效地区分手语；3) 从HaMeR中蒸馏精细特征，以进一步丰富手部特有的表示；4) 在预训练中，应用手语视频表示与目标语言嵌入之间的对比损失，以减少模态鸿沟。", "result": "BeyondGloss在Phoenix14T和CSL-Daily基准测试上取得了最先进的性能。", "conclusion": "所提出的BeyondGloss框架能够有效提升手语翻译的性能，通过关注手部运动的细节并采用多方面的对比学习策略，成功地弥合了视觉和语言之间的模态鸿沟。", "translation": "手语翻译（SLT）是一项具有挑战性的任务，需要弥合视觉和语言信息之间的模态鸿沟，同时捕捉手形和手部运动的细微变化。为了应对这些挑战，我们引入了\\textbf{BeyondGloss}，一个新颖的无注释SLT框架，它利用视频大语言模型（VideoLLMs）的时空推理能力。由于现有VideoLLMs在详细建模长视频方面存在困难，我们提出了一种新颖的方法来生成手部运动的精细、时序感知的文本描述。一个对比对齐模块在预训练期间将这些描述与视频特征对齐，鼓励模型关注以手部为中心的时间动态并更有效地区分手语。为了进一步丰富手部特有的表示，我们从HaMeR中蒸馏了精细特征。此外，我们还在预训练中应用了手语视频表示与目标语言嵌入之间的对比损失，以减少模态鸿沟。\\textbf{BeyondGloss}在Phoenix14T和CSL-Daily基准测试上取得了最先进的性能，证明了所提出框架的有效性。论文接收后我们将发布代码。", "summary": "本研究提出了一种名为BeyondGloss的无注释手语翻译（SLT）框架，旨在解决现有SLT中模态鸿沟和手部细节捕捉的挑战。该框架利用视频大语言模型（VideoLLMs）生成精细的手部运动文本描述，并通过对比对齐模块在预训练阶段将这些描述与视频特征对齐，从而增强模型对手部动态的关注和手语区分能力。此外，BeyondGloss还从HaMeR中蒸馏手部特有特征，并应用对比损失来缩小视频与目标语言之间的模态差距。实验结果表明，BeyondGloss在Phoenix14T和CSL-Daily数据集上均达到了最先进的性能。", "keywords": "手语翻译, 无注释, 视频大语言模型, 对比学习, 手部运动", "comments": "这篇论文的创新点在于提出了一个“无注释”且“以手部为中心”的手语翻译框架。它通过生成精细的手部运动描述并结合视频大语言模型，有效解决了传统SLT中对注释的依赖和长视频细节建模的难题。特别是引入对比学习和特征蒸馏来增强手部特征表示和模态对齐，是其取得SOTA性能的关键。该工作对于推动手语翻译的实用化和提高翻译精度具有重要意义。"}}
{"id": "2506.14781", "title": "Two-dimensional Parallel Tempering for Constrained Optimization", "authors": ["Corentin Delacour", "M Mahmudul Hasan Sajeeb", "Joao P. Hespanha", "Kerem Y. Camsari"], "categories": ["cs.LG", "cond-mat.stat-mech", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Added references in Introduction", "url": "http://arxiv.org/abs/2506.14781v2", "summary": "Sampling Boltzmann probability distributions plays a key role in machine\nlearning and optimization, motivating the design of hardware accelerators such\nas Ising machines. While the Ising model can in principle encode arbitrary\noptimization problems, practical implementations are often hindered by soft\nconstraints that either slow down mixing when too strong, or fail to enforce\nfeasibility when too weak. We introduce a two-dimensional extension of the\npowerful parallel tempering algorithm (PT) that addresses this challenge by\nadding a second dimension of replicas interpolating the penalty strengths. This\nscheme ensures constraint satisfaction in the final replicas, analogous to\nlow-energy states at low temperature. The resulting two-dimensional parallel\ntempering algorithm (2D-PT) improves mixing in heavily constrained replicas and\neliminates the need to explicitly tune the penalty strength. In a\nrepresentative example of graph sparsification with copy constraints, 2D-PT\nachieves near-ideal mixing, with Kullback-Leibler divergence decaying as\nO(1/t). When applied to sparsified Wishart instances, 2D-PT yields orders of\nmagnitude speedup over conventional PT with the same number of replicas. The\nmethod applies broadly to constrained Ising problems and can be deployed on\nexisting Ising machines.", "comment": "Added references in Introduction", "pdf_url": "http://arxiv.org/pdf/2506.14781v2", "cate": "cs.LG", "date": "2025-05-24", "updated": "2025-07-30", "AI": {"title_translation": "受约束优化的二维并行回火算法", "tldr": "引入二维并行回火算法（2D-PT），通过增加一个惩罚强度维度来解决受约束优化中软约束的混合问题，提高了混合效率并消除了手动调整惩罚强度的需要。", "motivation": "在Ising模型中，软约束的实际实现常常受阻，因为约束过强会导致混合速度慢，而过弱则无法保证可行性。", "method": "提出二维并行回火算法（2D-PT），通过增加第二个副本维度来插值惩罚强度，以确保最终副本中的约束满足。", "result": "2D-PT在重约束副本中改善了混合，消除了显式调整惩罚强度的需要。在图稀疏化任务中，2D-PT实现了接近理想的混合，KL散度以O(1/t)衰减。在稀疏化Wishart实例上，2D-PT比使用相同数量副本的传统PT加速了数个数量级。", "conclusion": "2D-PT方法广泛适用于受约束的Ising问题，并可在现有Ising机器上部署。", "translation": "采样玻尔兹曼概率分布在机器学习和优化中扮演着关键角色，这推动了Ising机器等硬件加速器的设计。虽然Ising模型原则上可以编码任意优化问题，但实际实现常常受到软约束的阻碍，这些软约束在过强时会减慢混合速度，而在过弱时则无法强制执行可行性。我们引入了一种强大的并行回火算法（PT）的二维扩展，通过增加第二个副本维度来插值惩罚强度，从而解决了这一挑战。该方案确保了最终副本中的约束满足，类似于低温下的低能量状态。由此产生的二维并行回火算法（2D-PT）改善了重约束副本中的混合，并消除了显式调整惩罚强度的需要。在一个具有复制约束的图稀疏化代表性例子中，2D-PT实现了接近理想的混合，其Kullback-Leibler散度以O(1/t)衰减。当应用于稀疏化Wishart实例时，2D-PT比使用相同数量副本的传统PT实现了数量级的加速。该方法广泛适用于受约束的Ising问题，并可在现有Ising机器上部署。", "summary": "本文提出了一种二维并行回火算法（2D-PT），旨在解决Ising模型中软约束导致的混合效率低下和可行性问题。2D-PT通过引入一个额外的维度来插值惩罚强度，从而改善了重约束副本的混合，并消除了手动调整惩罚强度的需求。实验证明，2D-PT在图稀疏化和稀疏化Wishart实例上表现出优异的混合性能和显著的加速效果，适用于广泛的受约束Ising问题并兼容现有硬件。", "keywords": "二维并行回火, 受约束优化, Ising模型, 软约束, 混合效率", "comments": "这篇论文的创新点在于将并行回火算法扩展到二维，巧妙地通过引入第二个维度来处理软约束的惩罚强度，从而解决了传统方法中混合效率低和参数调优困难的问题。其重要性在于提升了Ising机器在解决实际受约束优化问题时的效率和鲁棒性，为未来硬件加速器上的复杂优化提供了新的途径。"}}
{"id": "2507.23134", "title": "Details Matter for Indoor Open-vocabulary 3D Instance Segmentation", "authors": ["Sanghun Jung", "Jingjing Zheng", "Ke Zhang", "Nan Qiao", "Albert Y. C. Chen", "Lu Xia", "Chi Liu", "Yuyin Sun", "Xiao Zeng", "Hsiang-Wei Huang", "Byron Boots", "Min Sun", "Cheng-Hao Kuo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.23134v1", "summary": "Unlike closed-vocabulary 3D instance segmentation that is often trained\nend-to-end, open-vocabulary 3D instance segmentation (OV-3DIS) often leverages\nvision-language models (VLMs) to generate 3D instance proposals and classify\nthem. While various concepts have been proposed from existing research, we\nobserve that these individual concepts are not mutually exclusive but\ncomplementary. In this paper, we propose a new state-of-the-art solution for\nOV-3DIS by carefully designing a recipe to combine the concepts together and\nrefining them to address key challenges. Our solution follows the two-stage\nscheme: 3D proposal generation and instance classification. We employ robust 3D\ntracking-based proposal aggregation to generate 3D proposals and remove\noverlapped or partial proposals by iterative merging/removal. For the\nclassification stage, we replace the standard CLIP model with Alpha-CLIP, which\nincorporates object masks as an alpha channel to reduce background noise and\nobtain object-centric representation. Additionally, we introduce the\nstandardized maximum similarity (SMS) score to normalize text-to-proposal\nsimilarity, effectively filtering out false positives and boosting precision.\nOur framework achieves state-of-the-art performance on ScanNet200 and S3DIS\nacross all AP and AR metrics, even surpassing an end-to-end closed-vocabulary\nmethod.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.23134v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "室内开放词汇3D实例分割的细节很重要", "tldr": "本文提出了一种新的开放词汇3D实例分割（OV-3DIS）方法，通过精心结合和改进现有概念，并引入Alpha-CLIP和标准化最大相似度（SMS）分数，在ScanNet200和S3DIS数据集上达到了最先进的性能。", "motivation": "现有开放词汇3D实例分割方法中的各种概念并非互斥而是互补的，但它们尚未被有效整合和优化，导致性能未达最佳。", "method": "本文提出一种新的OV-3DIS解决方案，遵循两阶段方案：3D候选生成和实例分类。在生成阶段，采用鲁棒的基于3D跟踪的候选聚合，并通过迭代合并/移除来处理重叠或部分候选。在分类阶段，用Alpha-CLIP取代标准CLIP模型以减少背景噪声，并引入标准化最大相似度（SMS）分数来归一化文本到候选的相似度，以过滤假阳性。", "result": "该框架在ScanNet200和S3DIS数据集上，在所有AP和AR指标上均实现了最先进的性能，甚至超越了端到端的封闭词汇方法。", "conclusion": "通过精心设计和结合现有概念，并引入Alpha-CLIP和SMS等改进，本方法显著提升了开放词汇3D实例分割的性能，达到了当前最佳水平。", "translation": "与通常端到端训练的封闭词汇3D实例分割不同，开放词汇3D实例分割（OV-3DIS）通常利用视觉-语言模型（VLMs）生成3D实例候选并对其进行分类。尽管现有研究提出了各种概念，但我们观察到这些独立的概念并非相互排斥，而是互补的。在本文中，我们通过精心设计一种方案，将这些概念结合并加以完善以解决关键挑战，从而提出了一种新的最先进的OV-3DIS解决方案。我们的解决方案遵循两阶段方案：3D候选生成和实例分类。我们采用鲁棒的基于3D跟踪的候选聚合来生成3D候选，并通过迭代合并/移除来去除重叠或部分候选。对于分类阶段，我们将标准CLIP模型替换为Alpha-CLIP，它将对象掩码作为alpha通道以减少背景噪声并获得以对象为中心的表示。此外，我们引入了标准化最大相似度（SMS）分数来归一化文本到候选的相似度，有效地过滤掉假阳性并提高精度。我们的框架在ScanNet200和S3DIS数据集上，在所有AP和AR指标上均实现了最先进的性能，甚至超越了端到端的封闭词汇方法。", "summary": "本文提出了一种用于室内开放词汇3D实例分割（OV-3DIS）的SOTA解决方案。该方案通过精心结合并改进现有概念，采用两阶段方法：首先通过鲁棒的3D跟踪聚合和合并/移除生成3D候选，然后利用Alpha-CLIP进行实例分类以减少背景噪声，并引入标准化最大相似度（SMS）分数来提高精度。实验结果表明，该框架在ScanNet200和S3DIS数据集上达到了SOTA性能，甚至超越了某些封闭词汇方法。", "keywords": "开放词汇3D实例分割, 视觉-语言模型, Alpha-CLIP, 标准化最大相似度, 3D候选聚合", "comments": "本文的创新点在于其“细节决定成败”的理念，即通过系统地整合和优化现有开放词汇3D实例分割中的互补概念，并引入如Alpha-CLIP和SMS分数等创新组件，从而显著提升了性能。其方法论的严谨性，特别是在候选生成和分类阶段的精细化处理，使其超越了现有方法，甚至优于一些封闭词汇方法，这对于开放词汇领域的进步具有重要意义。"}}
{"id": "2410.07486", "title": "Visual Story-Writing: Writing by Manipulating Visual Representations of Stories", "authors": ["Damien Masson", "Zixin Zhao", "Fanny Chevalier"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      In Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology (UIST '25)", "url": "http://arxiv.org/abs/2410.07486v2", "summary": "We define \"visual story-writing\" as using visual representations of story\nelements to support writing and revising narrative texts. To demonstrate this\napproach, we developed a text editor that automatically visualizes a graph of\nentity interactions, movement between locations, and a timeline of story\nevents. Interacting with these visualizations results in suggested text edits:\nfor example, connecting two characters in the graph creates an interaction\nbetween them, moving an entity updates their described location, and\nrearranging events on the timeline reorganizes the narrative sequence. Through\ntwo user studies on narrative text editing and writing, we found that visuals\nsupported participants in planning high-level revisions, tracking story\nelements, and exploring story variations in ways that encourage creativity.\nBroadly, our work lays the foundation for writing support, not just through\nwords, but also visuals.", "comment": "In Proceedings of the 38th Annual ACM Symposium on User Interface\n  Software and Technology (UIST '25)", "pdf_url": "http://arxiv.org/pdf/2410.07486v2", "cate": "cs.HC", "date": "2024-10-09", "updated": "2025-07-31", "AI": {"title_translation": "视觉故事创作：通过操纵故事的视觉表征进行写作", "tldr": "本文定义了“视觉故事创作”并开发了一个文本编辑器，该编辑器通过可视化故事元素（如实体交互、位置移动和事件时间线）来支持叙事文本的写作和修改。用户研究表明，这种视觉辅助工具能帮助参与者进行高层次修订规划、跟踪故事元素和探索故事变体，从而激发创造力。", "motivation": "为了支持叙事文本的写作和修订，本文提出并演示了一种利用故事元素的视觉表征的方法。", "method": "开发了一个文本编辑器，该编辑器能自动可视化实体交互图、地点间的移动以及故事事件的时间线。用户与这些可视化元素互动时，系统会提供文本编辑建议，例如，在图中连接角色会创建它们之间的互动，移动实体会更新其描述的位置，重新排列时间线上的事件会调整叙事顺序。", "result": "通过两项关于叙事文本编辑和写作的用户研究发现，视觉元素支持参与者进行高层次修订规划、跟踪故事元素以及以鼓励创造力的方式探索故事变体。", "conclusion": "本文的工作为不仅通过文字，还通过视觉提供写作支持奠定了基础。", "translation": "我们将“视觉故事创作”定义为利用故事元素的视觉表征来支持叙事文本的写作和修订。为了展示这种方法，我们开发了一个文本编辑器，该编辑器能自动可视化实体交互图、地点间的移动以及故事事件的时间线。与这些可视化元素的互动会产生文本编辑建议：例如，在图中连接两个角色会创建它们之间的互动，移动一个实体会更新其描述的位置，重新排列时间线上的事件会重新组织叙事顺序。通过两项关于叙事文本编辑和写作的用户研究，我们发现视觉元素支持参与者进行高层次修订规划、跟踪故事元素以及以鼓励创造力的方式探索故事变体。总的来说，我们的工作为写作支持奠定了基础，这种支持不仅通过文字，还通过视觉。", "summary": "本文提出了“视觉故事创作”的概念，即通过视觉表征来辅助叙事文本的写作与修订。研究团队开发了一个文本编辑器，该工具能将故事中的实体互动、地点移动和事件时间线进行可视化，并允许用户通过操作这些视觉元素来自动生成文本修改建议。用户研究结果表明，这种视觉辅助方式有效帮助用户规划高层次修订、追踪故事元素和探索多样的故事情节，从而提升了创作效率和创造力。该研究为未来基于视觉的写作支持工具奠定了基础。", "keywords": "视觉故事创作, 叙事文本, 文本编辑器, 视觉化, 写作支持", "comments": "本文的创新点在于将叙事文本的写作和修订过程与视觉化交互相结合，突破了传统纯文本编辑的局限。通过将抽象的故事结构具象化，它为作者提供了一种更直观、更灵活的创作和修改方式，尤其在规划宏观结构和探索情节可能性方面具有显著优势。这项工作的重要性在于它为未来智能写作辅助工具的发展开辟了新途径，预示着写作工具将不仅仅是文字处理器，更是创意激发器和结构组织者。"}}
{"id": "2507.23365", "title": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation", "authors": ["Bob L. T. Sturm"], "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2; J.5"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23365v1", "summary": "I reflect on my experience creating two music albums centered on\nstate-of-the-art prompt-based AI music generation platforms. The first album\nexplicitly poses the question: What happens when I collide my junk mail with\nthese platforms? The second album is a direct response to the first, and toys\nwith the inability of state-of-the-art prompt-based AI music generation\nplatforms to generate music that is not ``practiced'', ``polished'', and\n``produced''. I seed a large language model (LLM) with information about these\nalbums and have it interview me, which results in the exploration of several\ndeeper questions: To what extent am I the author? Where am I in the resulting\nmusic? How is my musical identity changing as I am faced with machines that are\nin some ways far more talented than I? What new musical spaces does my work\nopen, for me or anyone/thing else? I conclude by reflecting on my reflections,\nas well as LLM-mediated self-reflection as method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23365v1", "cate": "cs.SD", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "“我（某种程度上）创作了它”：在基于提示的AI音乐生成中协商署名权、对抗欺诈并探索新的音乐空间", "tldr": "作者通过使用基于提示的AI音乐生成平台创作了两张专辑，探讨了AI音乐创作中的作者身份、欺诈问题以及新的音乐空间。", "motivation": "作者的动机是探索使用最先进的基于提示的AI音乐生成平台创作音乐的体验，并思考在AI辅助创作中作者身份、音乐特性以及个人音乐身份的变化。", "method": "作者首先使用基于提示的AI音乐生成平台创作了两张音乐专辑，一张将“垃圾邮件”与平台结合，另一张则尝试生成非“熟练”、“精炼”和“制作精良”的音乐。随后，作者将这些专辑的信息输入一个大型语言模型（LLM），并让LLM采访自己，从而深入探讨了作者身份、音乐中的自我存在、音乐身份变化以及新音乐空间的开放等问题。最后，作者反思了这些反思过程以及LLM作为自我反思媒介的方法。", "result": "结果是作者对多层深层问题进行了探索，包括作者身份的程度、在生成音乐中的自我存在、面对AI时音乐身份的变化，以及作品开启的新音乐空间。", "conclusion": "作者通过反思自己的创作经历和LLM介导的自我反思方法来得出结论。", "translation": "我反思了自己使用最先进的基于提示的AI音乐生成平台创作两张音乐专辑的经历。第一张专辑明确提出了一个问题：当我的垃圾邮件与这些平台碰撞时会发生什么？第二张专辑是第一张的直接回应，它玩味于最先进的基于提示的AI音乐生成平台无法生成“熟练”、“精炼”和“制作精良”的音乐。我用关于这些专辑的信息来“种子化”一个大型语言模型（LLM），并让它采访我，这导致了对几个更深层次问题的探索：我在多大程度上是作者？我在生成的音乐中处于何种位置？当面对在某些方面比我更有才华的机器时，我的音乐身份正在如何改变？我的作品为我或任何其他人/事物开启了哪些新的音乐空间？最后，我通过反思自己的反思，以及LLM介导的自我反思作为方法来得出结论。", "summary": "本文作者通过利用先进的基于提示的AI音乐生成平台创作了两张实验性音乐专辑，探讨了AI辅助音乐创作中的核心问题。作者首先尝试将日常元素（如垃圾邮件）与AI生成结合，继而挑战AI生成“非完美”音乐的能力。通过与一个大型语言模型的对话式自我访谈，作者深入探讨了AI时代下作者身份的界定、个人在创作中的存在感、音乐身份的演变以及AI音乐所开启的全新艺术空间。文章最终反思了这种创作与自我反思的独特方法。", "keywords": "AI音乐生成, 作者身份, 音乐创作, 大型语言模型, 艺术空间", "comments": "这篇论文通过亲身实践和内省的方式，探讨了AI音乐生成领域中一个核心且复杂的伦理和哲学问题——作者身份。其创新之处在于将AI工具不仅作为创作辅助，更作为自我审视和探索的媒介（LLM访谈），这提供了一个独特且深刻的视角。它挑战了传统意义上的“创作”和“作者”概念，并引出了关于人类与AI协作中创造力边界的思考。"}}
{"id": "2507.23082", "title": "Exploring In-Context Learning for Frame-Semantic Parsing", "authors": ["Diego Garat", "Guillermo Moncecchi", "Dina Wonsever"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23082v1", "summary": "Frame Semantic Parsing (FSP) entails identifying predicates and labeling\ntheir arguments according to Frame Semantics. This paper investigates the use\nof In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP\nwithout model fine-tuning. We propose a method that automatically generates\ntask-specific prompts for the Frame Identification (FI) and Frame Semantic Role\nLabeling (FSRL) subtasks, relying solely on the FrameNet database. These\nprompts, constructed from frame definitions and annotated examples, are used to\nguide six different LLMs. Experiments are conducted on a subset of frames\nrelated to violent events. The method achieves competitive results, with F1\nscores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers\na practical and effective alternative to traditional fine-tuning for\ndomain-specific FSP tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23082v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "探索上下文学习在框架语义解析中的应用", "tldr": "本文研究了如何利用大型语言模型的上下文学习能力进行框架语义解析，无需微调模型，通过自动生成提示词在特定领域取得了有竞争力的结果。", "motivation": "传统框架语义解析（FSP）通常需要模型微调。本文旨在探索使用大型语言模型（LLMs）的上下文学习（ICL）能力来执行FSP，从而避免模型微调的需要。", "method": "提出了一种方法，该方法仅依赖FrameNet数据库自动为框架识别（FI）和框架语义角色标注（FSRL）子任务生成特定任务的提示词。这些提示词由框架定义和标注示例构建，用于指导六种不同的LLMs。实验在与暴力事件相关的框架子集上进行。", "result": "该方法在框架识别（FI）上取得了94.3%的F1分数，在框架语义角色标注（FSRL）上取得了77.4%的F1分数，达到了有竞争力的结果。", "conclusion": "研究结果表明，上下文学习（ICL）为特定领域的框架语义解析（FSP）任务提供了一种实用且有效的替代传统微调的方法。", "translation": "框架语义解析（FSP）涉及根据框架语义识别谓词并标注其论元。本文研究了使用大型语言模型（LLMs）的上下文学习（ICL）来执行FSP，而无需模型微调。我们提出了一种方法，该方法仅依赖FrameNet数据库，自动为框架识别（FI）和框架语义角色标注（FSRL）子任务生成特定任务的提示词。这些提示词由框架定义和标注示例构建，用于指导六种不同的LLMs。实验在与暴力事件相关的框架子集上进行。该方法取得了有竞争力的结果，框架识别的F1分数为94.3%，框架语义角色标注的F1分数为77.4%。研究结果表明，上下文学习为领域特定的FSP任务提供了一种实用且有效的替代传统微调的方法。", "summary": "本文探索了利用大型语言模型（LLMs）的上下文学习（ICL）能力进行框架语义解析（FSP），旨在避免模型微调。研究提出了一种基于FrameNet数据库自动生成框架识别（FI）和框架语义角色标注（FSRL）任务提示词的方法，并使用这些提示词指导六种LLMs进行实验。在暴力事件相关框架子集上的实验表明，该方法在FI和FSRL任务上分别取得了94.3%和77.4%的F1分数，证明了ICL在领域特定FSP任务中作为传统微调的实用且有效替代方案的潜力。", "keywords": "框架语义解析, 上下文学习, 大型语言模型, FrameNet, 提示工程", "comments": "这项研究的创新之处在于，它展示了利用大型语言模型的上下文学习能力，无需进行耗时的模型微调，即可在框架语义解析任务中取得有竞争力的表现。这为自然语言处理中特定领域任务的开发提供了一种更高效、更灵活的途径，尤其是在数据标注成本较高或模型微调资源有限的场景下，具有重要的实践意义。"}}
{"id": "2502.16421", "title": "Learning from Rendering: Realistic and Controllable Extreme Rainy Image Synthesis for Autonomous Driving Simulation", "authors": ["Kaibin Zhou", "Kaifeng Huang", "Hao Deng", "Zelin Tao", "Ziniu Liu", "Lin Zhang", "Shengjie Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.16421v2", "summary": "Autonomous driving simulators provide an effective and low-cost alternative\nfor evaluating or enhancing visual perception models. However, the reliability\nof evaluation depends on the diversity and realism of the generated scenes.\nExtreme weather conditions, particularly extreme rainfalls, are rare and costly\nto capture in real-world settings. While simulated environments can help\naddress this limitation, existing rainy image synthesizers often suffer from\npoor controllability over illumination and limited realism, which significantly\nundermines the effectiveness of the model evaluation. To that end, we propose a\nlearning-from-rendering rainy image synthesizer, which combines the benefits of\nthe realism of rendering-based methods and the controllability of\nlearning-based methods. To validate the effectiveness of our extreme rainy\nimage synthesizer on semantic segmentation task, we require a continuous set of\nwell-labeled extreme rainy images. By integrating the proposed synthesizer with\nthe CARLA driving simulator, we develop CARLARain an extreme rainy street scene\nsimulator which can obtain paired rainy-clean images and labels under complex\nillumination conditions. Qualitative and quantitative experiments validate that\nCARLARain can effectively improve the accuracy of semantic segmentation models\nin extreme rainy scenes, with the models' accuracy (mIoU) improved by 5% - 8%\non the synthetic dataset and significantly enhanced in real extreme rainy\nscenarios under complex illuminations. Our source code and datasets are\navailable at https://github.com/kb824999404/CARLARain/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.16421v2", "cate": "cs.CV", "date": "2025-02-23", "updated": "2025-07-31", "AI": {"title_translation": "学习渲染：用于自动驾驶仿真的真实可控极端雨天图像合成", "tldr": "本文提出了一种名为CARLARain的极端雨天图像合成器，它结合了渲染方法的真实感和学习方法的可控性，有效提升了自动驾驶语义分割模型在雨天场景的性能。", "motivation": "自动驾驶模拟器需要多样化和真实的场景来评估或增强视觉感知模型，但极端雨天数据获取成本高昂且稀有。现有雨天图像合成器在光照控制和真实感方面表现不佳，显著削弱了模型评估的有效性。", "method": "本文提出了一种“学习渲染”的雨天图像合成器，结合了基于渲染方法的真实感和基于学习方法的可控性。通过将其与CARLA驾驶模拟器集成，开发了CARLARain，一个能够获取复杂光照条件下配对的雨天-清晰图像和标签的极端雨天街景模拟器。", "result": "CARLARain能有效提高语义分割模型在极端雨天场景的准确性。在合成数据集上，模型准确率（mIoU）提高了5% - 8%；在复杂光照下的真实极端雨天场景中也显著增强。", "conclusion": "CARLARain通过提供真实、可控的极端雨天数据，显著提升了自动驾驶视觉感知模型在恶劣天气条件下的性能和鲁棒性。", "translation": "自动驾驶模拟器为评估或增强视觉感知模型提供了一种有效且低成本的替代方案。然而，评估的可靠性取决于生成场景的多样性和真实性。极端天气条件，特别是极端降雨，在现实世界中捕捉既罕见又昂贵。虽然模拟环境可以帮助解决这一限制，但现有的雨天图像合成器通常存在对光照控制不佳和真实感有限的问题，这显著削弱了模型评估的有效性。为此，我们提出了一种“学习渲染”的雨天图像合成器，它结合了基于渲染方法的真实感和基于学习方法的可控性的优点。为了验证我们的极端雨天图像合成器在语义分割任务上的有效性，我们需要一组连续的、标记良好的极端雨天图像。通过将所提出的合成器与CARLA驾驶模拟器集成，我们开发了CARLARain，一个可以获取复杂光照条件下配对的雨天-清晰图像和标签的极端雨天街景模拟器。定性和定量实验验证了CARLARain可以有效提高语义分割模型在极端雨天场景中的准确性，在合成数据集上模型准确率（mIoU）提高了5% - 8%，并在复杂光照下的真实极端雨天场景中显著增强。我们的源代码和数据集可在https://github.com/kb824999404/CARLARain/ 获取。", "summary": "本文提出了一种名为CARLARain的极端雨天图像合成器，它结合了渲染方法的真实感和学习方法的可控性。该合成器与CARLA模拟器集成，能够生成带标签的真实雨天图像，用于自动驾驶视觉感知模型的评估和训练。实验证明，CARLARain显著提升了语义分割模型在极端雨天场景下的性能。", "keywords": "极端雨天图像合成, 自动驾驶仿真, 语义分割, CARLARain, 学习渲染", "comments": "该论文创新性地结合了基于渲染和基于学习的方法来合成极端雨天图像，解决了现有方法真实感和可控性不足的问题。通过与CARLA模拟器集成，提供了高质量、带标签的雨天数据集，对于提升自动驾驶模型在恶劣天气下的鲁棒性具有重要意义。其开源的代码和数据集也促进了相关研究的进展。"}}
{"id": "2507.22899", "title": "A visual analytics tool for taxonomy-based trajectory data exploration", "authors": ["Ivan A. Hanono Cozzetti", "Ahmad Abdou"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      71 pages, 92 figures", "url": "http://arxiv.org/abs/2507.22899v1", "summary": "The analysis of spatio-temporal data presents significant challenges due to\nthe complexity and heterogeneity of movement patterns. This project proposes a\ndata analytics tool that combines data visualization and statistical\ncomputation to facilitate spatio-temporal data analysis through a multi-level\napproach. The tool categorizes moving objects into distinct taxonomies using\nMachine Learning models, adding meaningful structure to the analysis. Two case\nstudies demonstrate the methodology's effectiveness. The first analyzed Arctic\nfox trajectories, successfully identifying and labeling foxes with Geometric or\nKinematic-based behaviors, further categorized into Curvature and Acceleration\ngroups. Statistical indicators revealed that foxes with Acceleration-based\nbehavior showed constant, steady acceleration, while those with Curvature-based\nbehavior exhibited acceleration peaks and sudden deceleration. The second case\nstudy examined tropical cyclone data, labeling trajectories with Speed,\nCurvature, and hybrid Geometric-based behaviors through unique statistical\nvariables. Analysis of hybrid Geometric behavior (Curvature and Indentation\ncombined) identified specific angles with the highest impact on hurricane shape\nand geometry. The proposed method and tool demonstrate that spatio-temporal\ndata, despite inherent complexity, can be analyzed and explained in detail,\nproviding a theoretical and practical blueprint applicable to multiple domains.", "comment": "71 pages, 92 figures", "pdf_url": "http://arxiv.org/pdf/2507.22899v1", "cate": "cs.HC", "date": "2025-06-26", "updated": "2025-06-26", "AI": {"title_translation": "一种基于分类学的轨迹数据探索可视化分析工具", "tldr": "该项目提出了一个结合数据可视化和统计计算的可视化分析工具，通过机器学习模型将移动对象分类，以促进时空数据分析，并通过北极狐和热带气旋的案例研究证明了其有效性。", "motivation": "时空数据分析由于运动模式的复杂性和异构性而面临重大挑战。", "method": "该工具结合了数据可视化和统计计算，通过多级方法促进时空数据分析。它使用机器学习模型将移动对象分为不同的分类，为分析添加有意义的结构。", "result": "在北极狐轨迹分析中，成功识别并标记了具有几何或运动学行为的狐狸，并进一步分为曲率和加速度组。统计指标显示，加速度行为的狐狸表现出恒定、稳定的加速度，而曲率行为的狐狸则表现出加速度峰值和突然减速。在热带气旋数据分析中，通过独特的统计变量标记了具有速度、曲率和混合几何行为的轨迹。对混合几何行为（曲率和压痕结合）的分析确定了对飓风形状和几何结构影响最大的特定角度。", "conclusion": "所提出的方法和工具表明，尽管时空数据固有的复杂性，但仍可以进行详细分析和解释，为多个领域提供了理论和实践蓝图。", "translation": "时空数据分析由于运动模式的复杂性和异构性而面临重大挑战。本项目提出了一种数据分析工具，该工具结合了数据可视化和统计计算，通过多级方法促进时空数据分析。该工具使用机器学习模型将移动对象分为不同的分类，为分析添加了有意义的结构。两个案例研究证明了该方法的有效性。第一个案例研究分析了北极狐的轨迹，成功识别并标记了具有几何或运动学行为的狐狸，并进一步分为曲率和加速度组。统计指标显示，具有加速度行为的狐狸表现出恒定、稳定的加速度，而具有曲率行为的狐狸则表现出加速度峰值和突然减速。第二个案例研究检查了热带气旋数据，通过独特的统计变量标记了具有速度、曲率和混合几何行为的轨迹。对混合几何行为（曲率和压痕结合）的分析确定了对飓风形状和几何结构影响最大的特定角度。所提出的方法和工具表明，尽管时空数据固有的复杂性，但仍可以进行详细分析和解释，为多个领域提供了理论和实践蓝图。", "summary": "本研究提出了一种创新性的可视化分析工具，旨在解决时空数据分析的复杂性。该工具结合了数据可视化和统计计算，并利用机器学习模型对移动对象的轨迹进行分类，从而为数据分析增加了结构化信息。通过对北极狐轨迹和热带气旋数据的两个案例研究，该工具成功识别并解释了不同的运动模式和行为特征，例如北极狐的加速度和曲率行为，以及飓风形状的关键影响角度。这表明该方法能够详细分析复杂的时空数据，并为多领域应用提供了可行的理论和实践框架。", "keywords": "时空数据分析, 可视化工具, 轨迹数据, 机器学习, 分类学", "comments": "该论文的创新之处在于其将数据可视化、统计计算与机器学习相结合，创建了一个多层次的时空数据分析工具。通过对移动对象进行分类（如北极狐和热带气旋），它为复杂的轨迹数据提供了有意义的结构，使其更易于理解和分析。该工具的普适性及其在不同领域的成功应用（如生物学和气象学）突显了其重要性。它提供了一种有效的方法来应对异构运动模式带来的挑战。"}}
{"id": "2504.19105", "title": "Blended PC Peer Review Model: Process and Reflection", "authors": ["Chakkrit Tantithamthavorn", "Nicole Novielli", "Ayushi Rastogi", "Olga Baysal", "Bram Adams"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Published at ACM SIGSOFT Software Engineering Notes", "url": "http://arxiv.org/abs/2504.19105v2", "summary": "The academic peer review system is under increasing pressure due to a growing\nvolume of submissions and a limited pool of available reviewers, resulting in\ndelayed decisions and an uneven distribution of reviewing responsibilities.\nBuilding upon the International Conference on Mining Software Repositories\n(MSR) community's earlier experience with a Shadow PC (2021 and 2022) and\nJunior PC (2023 and 2024), MSR 2025 experimented with a Blended Program\nCommittee (PC) peer review model for its Technical Track. This new model pairs\nup one Junior PC member with two regular PC members as part of the core review\nteam of a given paper, instead of adding them as an extra reviewer. This paper\npresents the rationale, implementation, and reflections on the model, including\nempirical insights from a post-review author survey evaluating the quality and\nusefulness of reviews. Our findings highlight the potential of a Blended PC to\nalleviate reviewer shortages, foster inclusivity, and sustain a high-quality\npeer review process. We offer lessons learned and recommendations to guide\nfuture adoption and refinement of the model.", "comment": "Published at ACM SIGSOFT Software Engineering Notes", "pdf_url": "http://arxiv.org/pdf/2504.19105v2", "cate": "cs.SE", "date": "2025-04-27", "updated": "2025-07-31", "AI": {"title_translation": "混合PC同行评审模型：过程与反思", "tldr": "MSR 2025 试验了一种混合程序委员会（PC）同行评审模型，将初级PC成员与常规PC成员配对，以缓解审稿人短缺并提高评审质量和包容性。", "motivation": "由于投稿量增加和可用审稿人有限，学术同行评审系统面临越来越大的压力，导致决策延迟和评审责任分配不均。", "method": "该研究基于国际软件仓库挖掘会议（MSR）社区之前影子PC（2021、2022）和初级PC（2023、2024）的经验，在MSR 2025的技术专题中试验了混合程序委员会（PC）同行评审模型。该模型将一名初级PC成员与两名常规PC成员配对，作为给定论文的核心评审团队成员。研究还包括对审稿后作者调查的实证分析，评估评审的质量和有用性。", "result": "研究结果强调了混合PC在缓解审稿人短缺、促进包容性以及维持高质量同行评审过程方面的潜力。", "conclusion": "混合PC模型有望缓解审稿人短缺，提高同行评审的包容性和质量。论文提供了经验教训和建议，以指导该模型未来的采用和完善。", "translation": "学术同行评审系统正面临日益增长的压力，原因在于投稿量不断增加而可用审稿人数量有限，这导致决策延迟和评审责任分配不均。在国际软件仓库挖掘大会（MSR）社区早期影子PC（2021和2022年）和初级PC（2023和2024年）经验的基础上，MSR 2025在其技术专题中试验了一种混合程序委员会（PC）同行评审模型。这种新模型将一名初级PC成员与两名常规PC成员配对，作为给定论文核心评审团队的一部分，而不是将他们作为额外的审稿人。本文介绍了该模型的原理、实施和反思，包括来自审稿后作者调查的实证见解，该调查评估了评审的质量和有用性。我们的研究结果强调了混合PC在缓解审稿人短缺、促进包容性以及维持高质量同行评审过程方面的潜力。我们提供了经验教训和建议，以指导该模型未来的采用和完善。", "summary": "该论文介绍了MSR 2025会议上试验的混合程序委员会（PC）同行评审模型，旨在解决当前学术评审系统面临的审稿人短缺和责任分配不均问题。该模型将一名初级PC成员与两名常规PC成员组成核心评审团队。通过对审稿后作者调查的实证分析，研究发现混合PC模型在缓解审稿人短缺、促进包容性以及维持高质量评审方面具有潜力，并提供了未来的实施建议。", "keywords": "同行评审, 混合PC, MSR会议, 审稿人短缺, 学术评审", "comments": "该论文提出了一种创新性的同行评审模型，通过将初级和常规PC成员配对，有效解决了当前学术评审中审稿人资源紧张和评审质量的问题。其亮点在于实践性强，通过MSR会议的实际试验提供了经验证据，对未来会议评审模式的改进具有重要的指导意义。这种模式有助于培养年轻学者，同时减轻资深审稿人的负担，具有良好的推广前景。"}}
{"id": "2412.12098", "title": "MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization", "authors": ["Bhavya Sukhija", "Stelian Coros", "Andreas Krause", "Pieter Abbeel", "Carmelo Sferrazza"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.12098v2", "summary": "Reinforcement learning (RL) algorithms aim to balance exploiting the current\nbest strategy with exploring new options that could lead to higher rewards.\nMost common RL algorithms use undirected exploration, i.e., select random\nsequences of actions. Exploration can also be directed using intrinsic rewards,\nsuch as curiosity or model epistemic uncertainty. However, effectively\nbalancing task and intrinsic rewards is challenging and often task-dependent.\nIn this work, we introduce a framework, MaxInfoRL, for balancing intrinsic and\nextrinsic exploration. MaxInfoRL steers exploration towards informative\ntransitions, by maximizing intrinsic rewards such as the information gain about\nthe underlying task. When combined with Boltzmann exploration, this approach\nnaturally trades off maximization of the value function with that of the\nentropy over states, rewards, and actions. We show that our approach achieves\nsublinear regret in the simplified setting of multi-armed bandits. We then\napply this general formulation to a variety of off-policy model-free RL methods\nfor continuous state-action spaces, yielding novel algorithms that achieve\nsuperior performance across hard exploration problems and complex scenarios\nsuch as visual control tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.12098v2", "cate": "cs.LG", "date": "2024-12-16", "updated": "2025-07-31", "AI": {"title_translation": "MaxInfoRL：通过最大化信息增益提升强化学习中的探索", "tldr": "MaxInfoRL是一个新的强化学习框架，通过最大化信息增益来指导探索，有效平衡内在和外在探索，并在多种RL任务中表现出色。", "motivation": "当前的强化学习算法在探索方面存在挑战，常见算法使用无方向探索，而有方向探索（如好奇心或模型认知不确定性）则难以有效平衡任务奖励和内在奖励，且常依赖于特定任务。", "method": "本文引入了MaxInfoRL框架，通过最大化关于底层任务的信息增益等内在奖励，将探索引向信息丰富的转换。当与玻尔兹曼探索结合时，该方法自然地权衡了价值函数最大化与状态、奖励和动作熵的最大化。", "result": "在多臂老虎机的简化设置中，MaxInfoRL实现了次线性遗憾。将该通用公式应用于各种离策略无模型强化学习方法，在连续状态-动作空间中，产生了在困难探索问题和复杂场景（如视觉控制任务）中表现优越的新算法。", "conclusion": "MaxInfoRL通过信息增益最大化有效提升了强化学习的探索能力，并在理论和实践中展现出优越性能。", "translation": "强化学习（RL）算法旨在平衡利用当前最佳策略与探索可能带来更高回报的新选项。大多数常见的RL算法采用无方向探索，即选择随机动作序列。探索也可以通过内在奖励进行指导，例如好奇心或模型认知不确定性。然而，有效平衡任务奖励和内在奖励具有挑战性，并且通常依赖于特定任务。在这项工作中，我们引入了一个框架MaxInfoRL，用于平衡内在和外在探索。MaxInfoRL通过最大化关于底层任务的信息增益等内在奖励，将探索引向信息丰富的转换。当与玻尔兹曼探索结合时，这种方法自然地权衡了价值函数最大化与状态、奖励和动作熵的最大化。我们表明，在多臂老虎机的简化设置中，我们的方法实现了次线性遗憾。然后，我们将这种通用公式应用于各种离策略无模型RL方法，用于连续状态-动作空间，产生了在困难探索问题和复杂场景（如视觉控制任务）中表现优越的新算法。", "summary": "MaxInfoRL是一个新型的强化学习框架，旨在通过最大化信息增益来优化探索过程。它有效平衡了内在和外在探索，将探索引导至信息丰富的转换。该方法与玻尔兹曼探索结合后，能够自然地权衡价值最大化与状态、奖励和动作的熵最大化。实验结果表明，MaxInfoRL在多臂老虎机问题中实现了次线性遗憾，并且在连续状态-动作空间的无模型RL任务，尤其是困难探索和视觉控制等复杂场景中，展现出卓越的性能。", "keywords": "强化学习, 探索, 信息增益, MaxInfoRL, 内在奖励", "comments": "MaxInfoRL的创新之处在于其通过信息增益最大化来指导探索，提供了一种有效平衡内在和外在奖励的通用方法，而非依赖于特定任务的调整。这对于解决强化学习中长期存在的探索-利用困境具有重要意义，尤其是在需要高效探索的复杂高维环境中。其在多臂老虎机和连续状态-动作空间任务中的优越表现，预示着该方法在实际应用中具有广阔前景。"}}
{"id": "2507.23400", "title": "MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization", "authors": ["Yongbing Zhang", "Fang Nan", "Shengxiang Gao", "Yuxin Huang", "Kaiwen Tan", "Zhengtao Yu"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23400v1", "summary": "The core challenge faced by multi-document summarization is the complexity of\nrelationships among documents and the presence of information redundancy. Graph\nclustering is an effective paradigm for addressing this issue, as it models the\ncomplex relationships among documents using graph structures and reduces\ninformation redundancy through clustering, achieving significant research\nprogress. However, existing methods often only consider single-relational\ngraphs and require a predefined number of clusters, which hinders their ability\nto fully represent rich relational information and adaptively partition\nsentence groups to reduce redundancy. To overcome these limitations, we propose\nMRGSEM-Sum, an unsupervised multi-document summarization framework based on\nmulti-relational graphs and structural entropy minimization. Specifically, we\nconstruct a multi-relational graph that integrates semantic and discourse\nrelations between sentences, comprehensively modeling the intricate and dynamic\nconnections among sentences across documents. We then apply a two-dimensional\nstructural entropy minimization algorithm for clustering, automatically\ndetermining the optimal number of clusters and effectively organizing sentences\ninto coherent groups. Finally, we introduce a position-aware compression\nmechanism to distill each cluster, generating concise and informative\nsummaries. Extensive experiments on four benchmark datasets (Multi-News,\nDUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently\noutperforms previous unsupervised methods and, in several cases, achieves\nperformance comparable to supervised models and large language models. Human\nevaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high\nconsistency and coverage, approaching human-level quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23400v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MRGSEM-Sum：一种基于多关系图和结构熵最小化的无监督多文档摘要框架", "tldr": "MRGSEM-Sum是一个无监督的多文档摘要框架，它通过构建多关系图和应用结构熵最小化算法来解决文档间关系复杂性和信息冗余问题，无需预设聚类数量，并取得了优于现有无监督方法甚至媲美有监督模型的性能。", "motivation": "多文档摘要的核心挑战是文档间关系的复杂性和信息冗余。现有图聚类方法通常只考虑单一关系图并需要预定义聚类数量，这限制了它们表达丰富关系信息和自适应划分句子组以减少冗余的能力。", "method": "本文提出了MRGSEM-Sum框架。首先，构建一个整合语义和语篇关系的多关系图，以全面建模句子间的复杂连接。其次，应用二维结构熵最小化算法进行聚类，自动确定最优聚类数量。最后，引入位置感知压缩机制来提炼每个簇，生成简洁信息丰富的摘要。", "result": "在Multi-News、DUC-2004、PubMed和WikiSum四个基准数据集上的广泛实验表明，MRGSEM-Sum持续优于之前的无监督方法，在某些情况下，其性能可与有监督模型和大型语言模型媲美。人工评估显示，MRGSEM-Sum生成的摘要具有高一致性和覆盖率，接近人类水平。", "conclusion": "MRGSEM-Sum通过利用多关系图和结构熵最小化，有效解决了多文档摘要中的关系复杂性和信息冗余问题，无需预设聚类数量，并生成了高质量的摘要，展现出超越现有无监督方法并逼近有监督模型的强大性能。", "translation": "多文档摘要面临的核心挑战是文档间关系的复杂性和信息冗余。图聚类是解决此问题的有效范式，它利用图结构建模文档间复杂关系，并通过聚类减少信息冗余，取得了显著的研究进展。然而，现有方法通常只考虑单一关系图，并且需要预定义聚类数量，这阻碍了它们充分表示丰富关系信息和自适应划分句子组以减少冗余的能力。为了克服这些限制，我们提出了MRGSEM-Sum，一个基于多关系图和结构熵最小化的无监督多文档摘要框架。具体而言，我们构建了一个多关系图，该图整合了句子间的语义和语篇关系，全面建模了跨文档句子间复杂而动态的连接。然后，我们应用二维结构熵最小化算法进行聚类，自动确定最优聚类数量并有效地将句子组织成连贯的组。最后，我们引入了位置感知压缩机制来提炼每个簇，生成简洁而信息丰富的摘要。在四个基准数据集（Multi-News、DUC-2004、PubMed和WikiSum）上进行的广泛实验表明，我们的方法持续优于之前的无监督方法，并且在某些情况下，其性能可与有监督模型和大型语言模型媲美。人工评估表明，MRGSEM-Sum生成的摘要表现出高一致性和覆盖率，接近人类水平。", "summary": "MRGSEM-Sum是一个无监督的多文档摘要框架，旨在解决文档间关系复杂性和信息冗余问题。它通过构建融合语义和语篇关系的多关系图，并利用二维结构熵最小化算法自动确定最佳聚类数量来组织句子。随后，采用位置感知压缩机制提炼摘要。该方法在多个基准数据集上表现优异，超越了现有无监督方法，并可与有监督模型和大型语言模型相媲美，生成了接近人类质量的高一致性和覆盖率摘要。", "keywords": "多文档摘要, 无监督学习, 多关系图, 结构熵最小化, 图聚类", "comments": "这项研究的创新之处在于其无监督的特性以及对多关系图和结构熵最小化的应用，有效地解决了传统多文档摘要方法在处理复杂关系和自动确定聚类数量上的局限性。其性能可与有监督模型和大型语言模型媲美，显示出强大的实用潜力。"}}
{"id": "2506.12365", "title": "Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics", "authors": ["Asifullah Khan", "Muhammad Zaeem Khan", "Saleha Jamshed", "Sadia Ahmad", "Aleesha Zainab", "Kaynat Khatib", "Faria Bibi", "Abdul Rehman"], "categories": ["cs.CL", "cs.DB"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12365v2", "summary": "This survey paper outlines the key developments in the field of Large\nLanguage Models (LLMs), including enhancements to their reasoning skills,\nadaptability to various tasks, increased computational efficiency, and the\nability to make ethical decisions. The techniques that have been most effective\nin bridging the gap between human and machine communications include the\nChain-of-Thought prompting, Instruction Tuning, and Reinforcement Learning from\nHuman Feedback. The improvements in multimodal learning and few-shot or\nzero-shot techniques have further empowered LLMs to handle complex jobs with\nminor input. A significant focus is placed on efficiency, detailing scaling\nstrategies, optimization techniques, and the influential Mixture-of-Experts\n(MoE) architecture, which strategically routes inputs to specialized\nsubnetworks to boost predictive accuracy, while optimizing resource allocation.\nThis survey also offers a broader perspective on recent advancements in LLMs,\ngoing beyond isolated aspects such as model architecture or ethical concerns.\nAdditionally, it explores the role of LLMs in Agentic AI and their use as\nAutonomous Decision-Making Systems, and categorizes emerging methods that\nenhance LLM reasoning, efficiency, and ethical alignment. The survey also\nidentifies underexplored areas such as interpretability, cross-modal\nintegration, and sustainability. While significant advancements have been made\nin LLMs, challenges such as high computational costs, biases, and ethical risks\nremain. Overcoming these requires a focus on bias mitigation, transparent\ndecision-making, and explicit ethical guidelines. Future research will\ngenerally focus on enhancing the model's ability to handle multiple inputs,\nthereby making it more intelligent, safe, and reliable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12365v2", "cate": "cs.CL", "date": "2025-06-14", "updated": "2025-07-31", "AI": {"title_translation": "聚焦于推理、适应性、效率和伦理的LLM进展", "tldr": "本综述概述了大型语言模型（LLMs）在推理、适应性、效率和伦理方面的关键进展，并探讨了有效技术、挑战和未来方向。", "motivation": "本文旨在概述大型语言模型（LLMs）领域的关键发展，包括其在推理、适应性、计算效率和伦理决策方面的增强，并识别未充分探索的领域和现有挑战。", "method": "本文采用综述的形式，概述并分类了LLMs领域的关键发展，包括有效技术（如思维链提示、指令微调、人类反馈强化学习）、效率提升策略（如MoE架构）、以及LLMs在代理AI和自主决策系统中的作用。", "result": "综述识别了LLMs在推理、适应性、效率和伦理方面的主要进展，详细介绍了思维链提示、指令微调和人类反馈强化学习等有效技术。文章还强调了效率提升的重要性，并探讨了MoE架构。此外，它还识别了可解释性、跨模态集成和可持续性等未充分探索的领域，并指出了高计算成本、偏见和伦理风险等挑战。", "conclusion": "尽管大型语言模型取得了显著进展，但高计算成本、偏见和伦理风险等挑战依然存在。未来的研究应侧重于偏见缓解、透明决策和明确的伦理指南，以增强模型处理多输入的能力，使其更智能、安全和可靠。", "translation": "这篇综述论文概述了大型语言模型（LLMs）领域的关键发展，包括其推理技能、对各种任务的适应性、计算效率的提高以及做出道德决策的能力的增强。在弥合人机通信差距方面最有效的技术包括思维链提示、指令微调和人类反馈强化学习。多模态学习以及少样本或零样本技术的改进进一步增强了LLMs处理复杂任务的能力，只需少量输入。论文重点关注效率，详细介绍了扩展策略、优化技术和具有影响力的专家混合（MoE）架构，该架构战略性地将输入路由到专门的子网络，以提高预测准确性，同时优化资源分配。本综述还提供了LLMs最新进展的更广阔视角，超越了模型架构或道德问题等孤立方面。此外，它还探讨了LLMs在代理AI中的作用及其作为自主决策系统的使用，并对增强LLM推理、效率和道德对齐的新兴方法进行了分类。该综述还指出了未充分探索的领域，如可解释性、跨模态集成和可持续性。尽管LLMs取得了显著进展，但高计算成本、偏见和道德风险等挑战依然存在。克服这些挑战需要关注偏见缓解、透明决策和明确的道德准则。未来的研究通常将侧重于增强模型处理多输入的能力，从而使其更智能、安全和可靠。", "summary": "这篇综述论文全面概述了大型语言模型（LLMs）的最新进展，重点关注其在推理能力、任务适应性、计算效率和伦理决策方面的提升。文章详细介绍了思维链提示、指令微调和人类反馈强化学习等关键技术，以及多模态学习和少样本/零样本技术的进步。论文还强调了效率优化，特别是混合专家（MoE）架构的作用。此外，它探讨了LLMs在代理AI和自主决策系统中的应用，并指出了可解释性、跨模态集成和可持续性等未充分探索的领域。尽管LLMs取得了显著成就，但仍面临高计算成本、偏见和伦理风险等挑战，未来的研究需侧重于偏见缓解和伦理指南，以提升模型的智能、安全和可靠性。", "keywords": "大型语言模型, 推理, 适应性, 效率, 伦理", "comments": "这篇综述论文全面且及时，涵盖了LLMs领域多个关键且前沿的方面。其创新之处在于不仅详细介绍了技术进展，还深入探讨了伦理、效率和代理AI等重要议题，并明确指出了未充分探索的领域和未来的研究方向，为研究人员提供了宝贵的路线图。"}}
{"id": "2507.23348", "title": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "authors": ["Han Li", "Yuling Shi", "Shaoxin Lin", "Xiaodong Gu", "Heng Lian", "Xin Wang", "Yantao Jia", "Tao Huang", "Qianxiang Wang"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Our code and data are available at this https URL", "url": "http://arxiv.org/abs/2507.23348v1", "summary": "Issue resolution has made remarkable progress thanks to the advanced\nreasoning capabilities of large language models (LLMs). Recently, agent-based\nframeworks such as SWE-agent have further advanced this progress by enabling\nautonomous, tool-using agents to tackle complex software engineering tasks.\nWhile existing agent-based issue resolution approaches are primarily based on\nagents' independent explorations, they often get stuck in local solutions and\nfail to identify issue patterns that span across different parts of the\ncodebase. To address this limitation, we propose SWE-Debate, a competitive\nmulti-agent debate framework that encourages diverse reasoning paths and\nachieves more consolidated issue localization. SWE-Debate first creates\nmultiple fault propagation traces as localization proposals by traversing a\ncode dependency graph. Then, it organizes a three-round debate among\nspecialized agents, each embodying distinct reasoning perspectives along the\nfault propagation trace. This structured competition enables agents to\ncollaboratively converge on a consolidated fix plan. Finally, this consolidated\nfix plan is integrated into an MCTS-based code modification agent for patch\ngeneration. Experiments on the SWE-bench benchmark show that SWE-Debate\nachieves new state-of-the-art results in open-source agent frameworks and\noutperforms baselines by a large margin.", "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Debate", "pdf_url": "http://arxiv.org/pdf/2507.23348v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SWE-Debate：用于软件问题解决的竞争性多智能体辩论", "tldr": "SWE-Debate是一个竞争性多智能体辩论框架，通过鼓励多样化的推理路径和整合问题定位，显著提升了软件问题解决的性能。", "motivation": "现有基于智能体的软件问题解决方法主要依赖于智能体的独立探索，但常常陷入局部最优解，并且无法识别跨越代码库不同部分的问题模式。为了解决这一局限性，本文提出了SWE-Debate。", "method": "SWE-Debate首先通过遍历代码依赖图创建多个故障传播跟踪作为定位建议。然后，它组织了一个由专业智能体进行的三轮辩论，每个智能体代表故障传播跟踪中的不同推理视角。这种结构化的竞争使智能体能够协作地收敛到一个整合的修复计划。最后，这个整合的修复计划被整合到一个基于MCTS的代码修改智能体中，用于补丁生成。", "result": "在SWE-bench基准测试上的实验表明，SWE-Debate在开源智能体框架中取得了新的最先进结果，并大幅优于基线。", "conclusion": "SWE-Debate通过引入竞争性多智能体辩论框架，有效解决了现有基于智能体的问题解决方法的局限性，并通过整合多样化推理路径实现了更可靠的问题定位和修复计划，从而显著提升了软件问题解决的性能。", "translation": "问题解决由于大型语言模型（LLMs）先进的推理能力而取得了显著进展。最近，诸如SWE-agent等基于智能体的框架通过使自主、使用工具的智能体能够处理复杂的软件工程任务，进一步推动了这一进展。虽然现有基于智能体的问题解决方法主要基于智能体的独立探索，但它们常常陷入局部解决方案，并且无法识别跨越代码库不同部分的问题模式。为了解决这一局限性，我们提出了SWE-Debate，一个竞争性多智能体辩论框架，它鼓励多样化的推理路径并实现更整合的问题定位。SWE-Debate首先通过遍历代码依赖图创建多个故障传播跟踪作为定位建议。然后，它组织了一个由专业智能体进行的三轮辩论，每个智能体代表故障传播跟踪中的不同推理视角。这种结构化的竞争使智能体能够协作地收敛到一个整合的修复计划。最后，这个整合的修复计划被整合到一个基于MCTS的代码修改智能体中，用于补丁生成。在SWE-bench基准测试上的实验表明，SWE-Debate在开源智能体框架中取得了新的最先进结果，并大幅优于基线。", "summary": "本文提出了SWE-Debate，一个创新的竞争性多智能体辩论框架，旨在解决现有软件问题解决智能体在局部最优和跨代码库模式识别方面的局限性。SWE-Debate通过生成故障传播跟踪作为定位建议，并组织专业智能体进行三轮辩论来整合修复计划，最终利用MCTS生成补丁。实验证明，SWE-Debate在SWE-bench基准测试上达到了最先进的性能。", "keywords": "多智能体系统, 软件问题解决, 大型语言模型, 竞争性辩论, 代码修复", "comments": "SWE-Debate的创新之处在于引入了竞争性的多智能体辩论机制，而非简单的独立探索，这有助于克服智能体陷入局部解的问题。通过模拟人类辩论过程，鼓励多样化视角并最终达成共识，提高了问题定位的准确性和修复方案的可靠性。其结合代码依赖图和MCTS的方法也体现了工程实践的考量，对于提升LLM在复杂软件工程任务中的应用具有重要意义。"}}
{"id": "2507.23707", "title": "Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks", "authors": ["Renato Luis Garrido Cavalcante", "Tomasz Piotrowski", "Slawomir Stanczak"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23707v1", "summary": "We introduce a unified framework for analyzing utility regions of wireless\nnetworks, with a focus on the signal-to-interference-noise-ratio (SINR) and\nachievable rate regions. The framework provides valuable insights into\ninterference patterns of modern network architectures, such as cell-less and\nextremely large MIMO networks, and it generalizes existing characterizations of\nthe weak Pareto boundary. A central contribution is the derivation of\nsufficient conditions that guarantee convexity of the utility regions.\nConvexity is an important property because it ensures that time sharing (or\nuser grouping) cannot simultaneously increase the utility of all users when the\nnetwork operates on the weak Pareto boundary. These sufficient conditions also\nhave two key implications. First, they identify a family of (weighted) sum-rate\nmaximization problems that are inherently convex without any variable\ntransformations, thus paving the way for the development of efficient, provably\noptimal solvers for this family. Second, they provide a rigorous justification\nfor formulating sum-rate maximization problems directly in terms of achievable\nrates, rather than SINR levels. Our theoretical insights also motivate an\nalternative to the concept of favorable propagation in the massive MIMO\nliterature -- one that explicitly accounts for self-interference and the\nbeamforming strategy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23707v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "蜂窝、无蜂窝及介于两者之间：无线网络中效用区域分析的统一框架", "tldr": "本文提出了一个统一框架，用于分析无线网络的效用区域，特别是SINR和可实现速率区域，并推导了保证其凸性的充分条件。这些条件揭示了某些和速率最大化问题的内在凸性，并为大规模MIMO中的有利传播概念提供了新的视角。", "motivation": "为了深入理解现代网络架构（如无蜂窝和超大MIMO网络）的干扰模式，并解决现有分析框架可能存在的不足，以及探究效用区域凸性对时间共享和和速率最大化问题的影响。", "method": "本文引入了一个统一框架，用于分析无线网络的效用区域，重点关注信干噪比（SINR）和可实现速率区域。核心贡献是推导了保证效用区域凸性的充分条件。", "result": "该框架为现代网络架构的干扰模式提供了宝贵见解，并推广了弱帕累托边界的现有表征。推导的充分条件保证了效用区域的凸性，这表明在弱帕累托边界上时间共享不能同时增加所有用户效用。这些条件还识别出一类固有凸的（加权）和速率最大化问题，并为直接根据可实现速率而非SINR制定和速率最大化问题提供了严格依据。此外，理论见解还促使了大规模MIMO中有利传播概念的替代方案。", "conclusion": "本文提出的统一框架和导出的凸性条件为无线网络效用区域分析提供了深刻见解，尤其在和速率最大化问题和大规模MIMO有利传播概念方面具有重要的理论和实践意义。", "translation": "我们引入了一个统一框架，用于分析无线网络的效用区域，重点关注信干噪比（SINR）和可实现速率区域。该框架为现代网络架构（例如无蜂窝和超大MIMO网络）的干扰模式提供了宝贵的见解，并推广了弱帕累托边界的现有表征。一个核心贡献是推导了保证效用区域凸性的充分条件。凸性是一个重要的特性，因为它确保当网络在弱帕累托边界上运行时，时间共享（或用户分组）不能同时增加所有用户的效用。这些充分条件还具有两个关键含义。首先，它们识别出一系列（加权）和速率最大化问题，这些问题在不进行任何变量变换的情况下本质上是凸的，从而为开发针对这一系列问题的高效、可证明最优的求解器铺平了道路。其次，它们为直接根据可实现速率而不是SINR水平来制定和速率最大化问题提供了严格的理由。我们的理论见解也促使了大规模MIMO文献中有利传播概念的替代方案——该方案明确考虑了自干扰和波束成形策略。", "summary": "本文提出了一个统一框架，用于分析无线网络的效用区域，特别是SINR和可实现速率区域。该框架通过推导保证效用区域凸性的充分条件，为理解现代网络架构的干扰模式提供了新视角。研究结果表明，这些凸性条件揭示了一类固有凸的和速率最大化问题，并为直接基于可实现速率而非SINR制定此类问题提供了理论依据。此外，本文还提出了一种考虑自干扰和波束成形的大规模MIMO有利传播概念的替代方案。", "keywords": "效用区域, 凸性, 无线网络, 和速率最大化, 大规模MIMO", "comments": "这篇论文的创新点在于提出了一个统一的框架来分析无线网络的效用区域，并首次推导了保证其凸性的充分条件。这一发现具有重要意义，因为它简化了特定和速率最大化问题的求解，并为大规模MIMO中的有利传播概念提供了新的视角，有助于更精确地建模实际系统。其理论深度和对实际系统优化的潜在影响是其重要性所在。"}}
{"id": "2507.23665", "title": "SHAP-Guided Regularization in Machine Learning Models", "authors": ["Amal Saadallah"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23665v1", "summary": "Feature attribution methods such as SHapley Additive exPlanations (SHAP) have\nbecome instrumental in understanding machine learning models, but their role in\nguiding model optimization remains underexplored. In this paper, we propose a\nSHAP-guided regularization framework that incorporates feature importance\nconstraints into model training to enhance both predictive performance and\ninterpretability. Our approach applies entropy-based penalties to encourage\nsparse, concentrated feature attributions while promoting stability across\nsamples. The framework is applicable to both regression and classification\ntasks. Our first exploration started with investigating a tree-based model\nregularization using TreeSHAP. Through extensive experiments on benchmark\nregression and classification datasets, we demonstrate that our method improves\ngeneralization performance while ensuring robust and interpretable feature\nattributions. The proposed technique offers a novel, explainability-driven\nregularization approach, making machine learning models both more accurate and\nmore reliable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23665v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "机器学习模型中的SHAP引导正则化", "tldr": "本文提出一种SHAP引导的正则化框架，通过在模型训练中加入特征重要性约束，旨在同时提升机器学习模型的预测性能和可解释性。", "motivation": "特征归因方法（如SHAP）在理解机器学习模型方面已发挥关键作用，但它们在指导模型优化方面的潜力尚未被充分探索。", "method": "本文提出一个SHAP引导的正则化框架，通过将特征重要性约束纳入模型训练中。该方法应用基于熵的惩罚来鼓励稀疏、集中的特征归因，并促进样本间稳定性。该框架适用于回归和分类任务，并以TreeSHAP对树模型进行正则化作为初步探索。", "result": "通过在基准回归和分类数据集上的广泛实验，证明该方法能提高泛化性能，同时确保鲁棒且可解释的特征归因。", "conclusion": "所提出的技术提供了一种新颖的、由可解释性驱动的正则化方法，使机器学习模型既更准确又更可靠。", "translation": "特征归因方法，如SHapley Additive exPlanations (SHAP)，在理解机器学习模型方面变得至关重要，但它们在指导模型优化中的作用仍未得到充分探索。在本文中，我们提出了一种SHAP引导的正则化框架，该框架将特征重要性约束纳入模型训练，以提高预测性能和可解释性。我们的方法应用基于熵的惩罚，以鼓励稀疏、集中的特征归因，同时促进样本间的稳定性。该框架适用于回归和分类任务。我们的首次探索始于使用TreeSHAP研究基于树的模型正则化。通过在基准回归和分类数据集上进行大量实验，我们证明了我们的方法提高了泛化性能，同时确保了鲁棒和可解释的特征归因。所提出的技术提供了一种新颖的、由可解释性驱动的正则化方法，使机器学习模型更准确、更可靠。", "summary": "本文提出了一种SHAP引导的正则化框架，旨在通过在模型训练中整合特征重要性约束来同时提升机器学习模型的预测性能和可解释性。该框架采用基于熵的惩罚机制，以促使特征归因稀疏、集中并保持跨样本的稳定性。实验结果表明，该方法在回归和分类任务中有效提高了模型的泛化能力，并提供了更具鲁棒性和可解释性的特征归因。", "keywords": "SHAP, 正则化, 特征归因, 可解释性, 机器学习", "comments": "这篇论文的创新点在于将解释性方法（SHAP）从单纯的模型理解拓展到模型优化过程中，通过引入SHAP引导的正则化来直接影响模型的训练，从而在提高预测性能的同时增强模型的可解释性和稳定性。这对于构建更值得信赖和可审计的AI系统具有重要意义。"}}
{"id": "2507.23474", "title": "Finger Force Decoding from Motor Units Activity on Neuromorphic Hardware", "authors": ["Farah Baracat", "Giacomo Indiveri", "Elisa Donati"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23474v1", "summary": "Accurate finger force estimation is critical for next-generation\nhuman-machine interfaces. Traditional electromyography (EMG)-based decoding\nmethods using deep learning require large datasets and high computational\nresources, limiting their use in real-time, embedded systems. Here, we propose\na novel approach that performs finger force regression using spike trains from\nindividual motor neurons, extracted from high-density EMG. These biologically\ngrounded signals drive a spiking neural network implemented on a mixed-signal\nneuromorphic processor. Unlike prior work that encodes EMG into events, our\nmethod exploits spike timing on motor units to perform low-power, real-time\ninference. This is the first demonstration of motor neuron-based continuous\nregression computed directly on neuromorphic hardware. Our results confirm\naccurate finger-specific force prediction with minimal energy use, opening new\npossibilities for embedded decoding in prosthetics and wearable\nneurotechnology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23474v1", "cate": "cs.NE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于神经形态硬件的运动单元活动指力解码", "tldr": "该研究提出了一种利用运动单元尖峰信号在神经形态硬件上实现低功耗、实时指力解码的新方法，克服了传统深度学习方法的局限性。", "motivation": "传统的基于肌电图（EMG）的深度学习指力解码方法需要大量数据集和高计算资源，这限制了它们在实时、嵌入式系统中的应用。", "method": "本文提出了一种新颖的方法，利用从高密度肌电图中提取的单个运动神经元产生的尖峰序列进行指力回归。这些生物学信号驱动在混合信号神经形态处理器上实现的脉冲神经网络。与以往将肌电图编码为事件的方法不同，该方法利用运动单元上的尖峰时序进行低功耗、实时推理。", "result": "结果证实了准确的指特定力预测，且能耗极低。", "conclusion": "这是首次直接在神经形态硬件上实现基于运动神经元的连续回归，为假肢和可穿戴神经技术中的嵌入式解码开辟了新的可能性。", "translation": "准确的指力估计对于下一代人机界面至关重要。传统的基于肌电图（EMG）的深度学习解码方法需要大量数据集和高计算资源，限制了它们在实时嵌入式系统中的应用。在此，我们提出了一种新颖的方法，利用从高密度肌电图中提取的单个运动神经元产生的尖峰序列进行指力回归。这些基于生物学的信号驱动在混合信号神经形态处理器上实现的脉冲神经网络。与以往将肌电图编码为事件的工作不同，我们的方法利用运动单元上的尖峰时序进行低功耗、实时推理。这是首次直接在神经形态硬件上实现基于运动神经元的连续回归。我们的结果证实了准确的指特定力预测，且能耗极低，为假肢和可穿戴神经技术中的嵌入式解码开辟了新的可能性。", "summary": "本研究提出了一种在神经形态硬件上实现指力解码的新方法，旨在克服传统基于肌电图的深度学习方法在实时嵌入式应用中的局限性。该方法利用从高密度肌电图中提取的单个运动神经元尖峰序列，驱动在混合信号神经形态处理器上实现的脉冲神经网络。通过利用运动单元的尖峰时序，实现了低功耗、实时推理。研究结果验证了其准确的指特定力预测能力和极低的能耗，为假肢和可穿戴神经技术领域的嵌入式解码提供了新的途径。", "keywords": "指力解码, 运动单元, 神经形态硬件, 脉冲神经网络, 实时推理", "comments": "该论文的创新之处在于，它首次将运动神经元尖峰信号直接应用于神经形态硬件进行连续指力回归，从而实现了低功耗和实时性能。这解决了传统深度学习方法在计算资源和数据量方面的挑战，为下一代人机接口、假肢和可穿戴神经技术中的嵌入式解码提供了重要的技术突破和实际应用潜力。"}}
{"id": "2506.17247", "title": "Recursive Learning-Based Virtual Buffering for Analytical Global Placement", "authors": ["Andrew B. Kahng", "Yiting Liu", "Zhiang Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17247v2", "summary": "Due to the skewed scaling of interconnect versus cell delay in modern\ntechnology nodes, placement with buffer porosity (i.e., cell density) awareness\nis essential for timing closure in physical synthesis flows. However, existing\napproaches face two key challenges: (i) traditional van Ginneken-Lillis-style\nbuffering approaches are computationally expensive during global placement; and\n(ii) machine learning-based approaches, such as BufFormer, lack a thorough\nconsideration of Electrical Rule Check (ERC) violations and fail to \"close the\nloop\" back into the physical design flow. In this work, we propose\nMLBuf-RePlAce, the first open-source learning-driven virtual buffering-aware\nanalytical global placement framework, built on top of the OpenROAD\ninfrastructure. MLBuf-RePlAce adopts an efficient recursive learning-based\ngenerative buffering approach to predict buffer types and locations, addressing\nERC violations during global placement. We compare MLBuf-RePlAce against the\ndefault virtual buffering-based timing-driven global placer in OpenROAD, using\nopen-source testcases from the TILOS MacroPlacement and OpenROAD-flow-scripts\nrepositories. Without degradation of post-route power, MLBuf-RePlAce achieves\n(maximum, average) improvements of (56%, 31%) in total negative slack (TNS)\nwithin the open-source OpenROAD flow. When evaluated by completion in a\ncommercial flow, MLBuf-RePlAce achieves (maximum, average) improvements of\n(53%, 28%) in TNS with an average of 0.2% improvement in post-route power.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17247v2", "cate": "cs.LG", "date": "2025-06-07", "updated": "2025-07-30", "AI": {"title_translation": "基于递归学习的分析性全局布局虚拟缓冲", "tldr": "MLBuf-RePlAce是一种新的基于递归学习的虚拟缓冲感知全局布局框架，解决了传统方法和现有机器学习方法的局限性，显著改善了时序。", "motivation": "由于现代技术节点中互连与单元延迟的比例失衡，布局中的缓冲孔隙度（即单元密度）感知对于物理综合流程中的时序收敛至关重要。现有方法面临两大挑战：传统van Ginneken-Lillis式缓冲方法在全局布局期间计算成本高昂；基于机器学习的方法（如BufFormer）缺乏对电气规则检查（ERC）违规的全面考虑，且未能“闭环”回到物理设计流程中。", "method": "本文提出了MLBuf-RePlAce，第一个开源的学习驱动的虚拟缓冲感知分析性全局布局框架，构建在OpenROAD基础设施之上。MLBuf-RePlAce采用高效的基于递归学习的生成式缓冲方法来预测缓冲器类型和位置，并在全局布局期间解决电气规则检查（ERC）违规。", "result": "在开源OpenROAD流程中，MLBuf-RePlAce在总负时序余量（TNS）方面实现了（最大，平均）56%和31%的改进，且布线后功耗没有下降。在商业流程中评估时，MLBuf-RePlAce在TNS方面实现了（最大，平均）53%和28%的改进，布线后功耗平均改善了0.2%。", "conclusion": "MLBuf-RePlAce通过其递归学习方法有效地解决了虚拟缓冲在全局布局中的挑战，显著提升了时序收敛，并在开源和商业流程中均表现出优异性能，且对功耗影响极小。", "translation": "由于现代技术节点中互连与单元延迟的比例失衡，在物理综合流程中，具有缓冲孔隙度（即单元密度）感知的布局对于时序收敛至关重要。然而，现有方法面临两个关键挑战：（i）传统的van Ginneken-Lillis式缓冲方法在全局布局期间计算成本高昂；（ii）基于机器学习的方法，如BufFormer，缺乏对电气规则检查（ERC）违规的全面考虑，并且未能“闭环”回到物理设计流程中。在这项工作中，我们提出了MLBuf-RePlAce，这是第一个开源的学习驱动的虚拟缓冲感知分析性全局布局框架，构建在OpenROAD基础设施之上。MLBuf-RePlAce采用高效的基于递归学习的生成式缓冲方法来预测缓冲器类型和位置，在全局布局期间解决ERC违规。我们将MLBuf-RePlAce与OpenROAD中默认的基于虚拟缓冲的时序驱动全局布局器进行比较，使用了来自TILOS MacroPlacement和OpenROAD-flow-scripts仓库的开源测试用例。在不降低布线后功耗的情况下，MLBuf-RePlAce在开源OpenROAD流程中，总负时序余量（TNS）方面实现了（最大，平均）56%和31%的改进。当通过商业流程中的完成度进行评估时，MLBuf-RePlAce在TNS方面实现了（最大，平均）53%和28%的改进，布线后功耗平均改善了0.2%。", "summary": "本文提出了MLBuf-RePlAce，一个基于递归学习的开源虚拟缓冲感知分析性全局布局框架。该框架旨在解决传统缓冲方法计算成本高昂以及现有机器学习方法未能充分考虑电气规则检查（ERC）违规并与物理设计流程闭环的问题。MLBuf-RePlAce采用高效的生成式缓冲方法预测缓冲器类型和位置，并在全局布局阶段处理ERC问题。实验结果表明，与OpenROAD默认布局器相比，MLBuf-RePlAce在开源和商业流程中均显著改善了总负时序余量（TNS），同时对布线后功耗影响极小。", "keywords": "全局布局, 虚拟缓冲, 递归学习, 时序收敛, 物理设计", "comments": "该论文的创新点在于提出了一个结合递归学习的虚拟缓冲感知全局布局框架，有效地解决了传统方法计算成本高和现有机器学习方法忽视ERC违规的问题。其开源性质和在OpenROAD基础设施上的构建，有助于推动该领域的研究和应用。在时序收敛方面取得的显著改进，表明了该方法的实际应用潜力。"}}
{"id": "2507.23148", "title": "Countering the Forgetting of Novel Health Information with 'Social Boosting'", "authors": ["Vaibhav Krishna", "Nicholas A. Christakis"], "categories": ["cs.SI", "stat.AP"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      15 pages, 3 figures, 3 tables", "url": "http://arxiv.org/abs/2507.23148v1", "summary": "To mitigate the adverse effects of low-quality or false information, studies\nhave shown the effectiveness of various intervention techniques through\ndebunking or so-called pre-bunking. However, the effectiveness of such\ninterventions can decay. Here, we investigate the role of the detailed social\nstructure of the local villages within which the intervened individuals live,\nwhich provides opportunities for the targeted individuals to discuss and\ninternalize new knowledge. We evaluated this with respect to a critically\nimportant topic, information about maternal and child health care, delivered\nvia a 22-month in-home intervention. Specifically, we examined the effect of\nhaving friendship ties on the retention of knowledge interventions among\ntargeted individuals in 110 isolated Honduran villages. We hypothesize that\nindividuals who receive specific knowledge can internalize and consolidate this\ninformation by engaging in social interactions where, for instance, they have\nan opportunity to discuss it with others in the process. The opportunity to\nexplain information to others (knowledge sharing) promotes deeper cognitive\nprocessing and elaborative encoding, which ultimately enhances memory\nretention. We found that well-connected individuals within a social network\nexperience an enhanced effectiveness of knowledge interventions. These\nindividuals may be more likely to internalize and retain the information and\nreinforce it in others, due to increased opportunities for social interaction\nwhere they teach others or learn from them, a mechanism we refer to as \"social\nboosting\". These findings underscore the role of social interactions in\nreinforcing health knowledge interventions over the long term. We believe these\nfindings would be of interest to the health policy, the global health\nworkforce, and healthcare professionals focusing on disadvantaged populations\nand UN missions on infodemics.", "comment": "15 pages, 3 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.23148v1", "cate": "cs.SI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "用‘社会助推’对抗新健康信息的遗忘", "tldr": "研究发现，在社会网络中人际关系良好的人，通过“社会助推”机制，能更有效地内化并保留健康知识干预信息，并能强化他人对信息的记忆。", "motivation": "为了减轻低质量或虚假信息的不利影响，研究表明干预措施是有效的，但其有效性会随时间衰减。本文旨在探讨详细的社会结构如何通过提供讨论和内化新知识的机会来维持干预措施的有效性。", "method": "研究人员在洪都拉斯110个偏远村庄进行了为期22个月的家庭干预，针对孕产妇和儿童保健信息，评估了友谊关系对目标个体知识保留的影响。", "result": "研究发现，在社会网络中人际关系良好（well-connected）的个体，其知识干预的有效性得到增强。这些个体更有可能内化和保留信息，并通过“社会助推”机制（即增加社交互动机会，如教导他人或向他人学习）来强化他人对信息的记忆。", "conclusion": "社会互动在长期巩固健康知识干预方面发挥着重要作用。", "translation": "为了减轻低质量或虚假信息的不利影响，研究表明通过揭穿（debunking）或所谓预揭穿（pre-bunking）的各种干预技术是有效的。然而，此类干预的有效性可能会衰减。本文调查了受干预个体所居住的当地村庄的详细社会结构的作用，这种结构为目标个体提供了讨论和内化新知识的机会。我们针对一个极其重要的主题——孕产妇和儿童保健信息——通过为期22个月的家庭干预进行了评估。具体来说，我们考察了在洪都拉斯110个偏远村庄中，友谊关系对目标个体知识干预保留的影响。我们假设，获得特定知识的个体可以通过参与社交互动来内化和巩固这些信息，例如，在此过程中他们有机会与他人讨论。向他人解释信息（知识共享）促进了更深层次的认知加工和精细编码，最终增强了记忆保留。我们发现，在社交网络中人际关系良好的个体，其知识干预的有效性得到了增强。这些个体可能更有可能内化和保留信息，并通过增加社交互动机会（他们在其中教导他人或向他人学习）来强化他人对信息的记忆，我们称之为“社会助推”机制。这些发现强调了社会互动在长期巩固健康知识干预中的作用。我们相信这些发现将对卫生政策、全球卫生工作者以及关注弱势群体和联合国应对信息疫情任务的医疗专业人员具有重要意义。", "summary": "本文研究了社会结构在维持健康信息干预有效性方面的作用，以对抗低质量或虚假信息的遗忘。通过在洪都拉斯村庄对孕产妇和儿童保健信息进行为期22个月的干预，研究发现，在社会网络中人际关系良好的个体通过“社会助推”机制（即知识共享和讨论）能更有效地内化和保留新知识，并能强化他人对信息的记忆。这强调了社会互动在长期巩固健康知识方面的关键作用。", "keywords": "健康信息, 社会助推, 知识保留, 社交网络, 干预措施", "comments": "这项研究创新性地提出了“社会助推”机制，揭示了社会网络和人际互动在健康信息传播和长期记忆巩固中的重要性，为公共卫生干预策略提供了新的视角，尤其是在信息疫情和弱势群体健康教育方面具有实际应用价值。"}}
{"id": "2507.23431", "title": "Towards a Testbed for Scalable FaaS Platforms", "authors": ["Trever Schirmer", "David Bermbach"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Accepted for Publication at the 13th IEEE International Conference on Cloud Engineering (IC2E 2025)", "url": "http://arxiv.org/abs/2507.23431v1", "summary": "Most cloud platforms have a Function-as-a-Service (FaaS) offering that\nenables users to easily write highly scalable applications. To better\nunderstand how the platform's architecture impacts its performance, we present\na research-focused testbed that can be adapted to quickly evaluate the impact\nof different architectures and technologies on the characteristics of\nscalability-focused FaaS platforms.", "comment": "Accepted for Publication at the 13th IEEE International Conference on\n  Cloud Engineering (IC2E 2025)", "pdf_url": "http://arxiv.org/pdf/2507.23431v1", "cate": "cs.DC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "迈向可扩展FaaS平台的测试平台", "tldr": "开发了一个研究导向的测试平台，用于评估不同架构和技术对可扩展FaaS平台性能的影响。", "motivation": "为了更好地理解平台架构如何影响FaaS平台的性能。", "method": "提出了一个研究导向的测试平台，该平台可以快速评估不同架构和技术对可扩展FaaS平台特性的影响。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "大多数云平台都提供函数即服务（FaaS）产品，使用户能够轻松编写高度可扩展的应用程序。为了更好地理解平台架构如何影响其性能，我们提出了一个以研究为重点的测试平台，该平台可以快速评估不同架构和技术对以可扩展性为重点的FaaS平台特性的影响。", "summary": "该论文提出了一个研究导向的测试平台，旨在帮助理解不同架构和技术如何影响可扩展FaaS平台的性能。该平台能够快速评估这些影响，从而促进FaaS平台架构的研究。", "keywords": "FaaS, 可扩展性, 测试平台, 云平台, 架构", "comments": "创新点在于提供了一个可定制的测试平台，用于系统性地评估FaaS平台架构对性能的影响，这对于FaaS平台的研究和优化具有重要意义。"}}
{"id": "2507.23343", "title": "Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads", "authors": ["Yingjie Zhou", "Jiezhang Cao", "Zicheng Zhang", "Farong Wen", "Yanwei Jiang", "Jun Jia", "Xiaohong Liu", "Xiongkuo Min", "Guangtao Zhai"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23343v1", "summary": "Speech-driven methods for portraits are figuratively known as \"Talkers\"\nbecause of their capability to synthesize speaking mouth shapes and facial\nmovements. Especially with the rapid development of the Text-to-Image (T2I)\nmodels, AI-Generated Talking Heads (AGTHs) have gradually become an emerging\ndigital human media. However, challenges persist regarding the quality of these\ntalkers and AGTHs they generate, and comprehensive studies addressing these\nissues remain limited. To address this gap, this paper presents the largest\nAGTH quality assessment dataset THQA-10K to date, which selects 12 prominent\nT2I models and 14 advanced talkers to generate AGTHs for 14 prompts. After\nexcluding instances where AGTH generation is unsuccessful, the THQA-10K dataset\ncontains 10,457 AGTHs. Then, volunteers are recruited to subjectively rate the\nAGTHs and give the corresponding distortion categories. In our analysis for\nsubjective experimental results, we evaluate the performance of talkers in\nterms of generalizability and quality, and also expose the distortions of\nexisting AGTHs. Finally, an objective quality assessment method based on the\nfirst frame, Y-T slice and tone-lip consistency is proposed. Experimental\nresults show that this method can achieve state-of-the-art (SOTA) performance\nin AGTH quality assessment. The work is released at\nhttps://github.com/zyj-2000/Talker.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23343v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "谁是更好的“说话者”：AI生成说话人像的主观和客观质量评估", "tldr": "本文提出了一个迄今为止最大的AI生成说话人像(AGTH)质量评估数据集THQA-10K，并进行了主客观质量评估，提出了一种新的客观评估方法，实现了最先进的性能。", "motivation": "尽管文本到图像（T2I）模型快速发展，AI生成说话人像（AGTHs）已成为新兴的数字人类媒体，但这些“说话者”及其生成的AGTHs的质量仍存在挑战，且缺乏全面的研究。", "method": "1. 构建了迄今为止最大的AGTH质量评估数据集THQA-10K，包含10,457个AGTHs，通过选择12个T2I模型和14个先进的“说话者”为14个提示生成AGTHs。2. 招募志愿者对AGTHs进行主观评分并分类失真。3. 提出了基于第一帧、Y-T切片和音唇一致性的客观质量评估方法。", "result": "1. THQA-10K数据集包含10,457个AGTHs。2. 对主观实验结果的分析评估了“说话者”在泛化性和质量方面的表现，并揭示了现有AGTHs的失真。3. 提出的客观质量评估方法在AGTH质量评估中达到了最先进（SOTA）的性能。", "conclusion": "本文通过构建大型数据集和提出新的客观评估方法，有效解决了AI生成说话人像的质量评估问题，并取得了SOTA性能。", "translation": "语音驱动的人像方法因其合成说话嘴形和面部动作的能力而被形象地称为“说话者”。特别是随着文本到图像（T2I）模型的快速发展，AI生成说话人像（AGTHs）逐渐成为一种新兴的数字人类媒体。然而，这些“说话者”及其生成的AGTHs的质量仍然存在挑战，并且解决这些问题的全面研究仍然有限。为了弥补这一空白，本文提出了迄今为止最大的AGTH质量评估数据集THQA-10K，该数据集选择了12个著名的T2I模型和14个先进的“说话者”为14个提示生成AGTHs。在排除AGTH生成不成功的情况后，THQA-10K数据集包含10,457个AGTHs。然后，招募志愿者对AGTHs进行主观评分并给出相应的失真类别。在我们对主观实验结果的分析中，我们评估了“说话者”在泛化性和质量方面的表现，并揭示了现有AGTHs的失真。最后，提出了一种基于第一帧、Y-T切片和音唇一致性的客观质量评估方法。实验结果表明，该方法在AGTH质量评估中可以达到最先进（SOTA）的性能。相关工作已发布在https://github.com/zyj-2000/Talker。", "summary": "本文针对AI生成说话人像（AGTHs）的质量评估挑战，构建了迄今最大的THQA-10K数据集（包含10,457个AGTHs），并进行了大规模主观质量评估，分析了“说话者”的性能和AGTHs的失真。此外，提出了一种基于第一帧、Y-T切片和音唇一致性的新型客观质量评估方法，并在实验中验证了其达到最先进的性能。", "keywords": "AI生成说话人像, 质量评估, THQA-10K数据集, 主观评估, 客观评估", "comments": "这篇论文通过构建一个大规模的AGTH质量评估数据集并提出一种新的客观评估方法，为AI生成说话人像的质量评估领域做出了重要贡献。其创新性在于结合了主观评估和客观评估，并针对特定问题（如音唇一致性）设计了有效的客观指标，这对于推动数字人媒体的发展具有重要意义。"}}
{"id": "2506.07528", "title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "authors": ["Qisheng Hu", "Quanyu Long", "Wenya Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2506.07528v2", "summary": "Multi-hop claim verification is inherently challenging, requiring multi-step\nreasoning to construct verification chains while iteratively searching for\ninformation to uncover hidden bridging facts. This process is fundamentally\ninterleaved, as effective reasoning relies on dynamically retrieved evidence,\nwhile effective search demands reasoning to refine queries based on partial\ninformation. To achieve this, we propose Hierarchical Agent Reasoning and\nInformation Search (HARIS), explicitly modeling the coordinated process of\nreasoning-driven searching and search-informed reasoning. HARIS consists of a\nhigh-level reasoning agent that focuses on constructing the main verification\nchain, generating factual questions when more information is needed, and a\nlow-level search agent that iteratively retrieves more information, refining\nits search based on intermediate findings. This design allows each agent to\nspecialize in its respective task, enhancing verification accuracy and\ninterpretability. HARIS is trained using reinforcement learning with\noutcome-based rewards. Experimental results on the EX-FEVER and HOVER\nbenchmarks demonstrate that HARIS achieves strong performance, greatly\nadvancing multi-hop claim verification.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2506.07528v2", "cate": "cs.AI", "date": "2025-06-09", "updated": "2025-07-31", "AI": {"title_translation": "协同搜索引导推理与推理引导搜索在事实核查中的应用", "tldr": "HARIS是一个分层智能体系统，通过协同推理和搜索来解决多跳事实核查中的挑战，并在基准测试中表现出色。", "motivation": "多跳事实核查具有挑战性，需要多步推理来构建验证链，并迭代搜索信息以发现隐藏的桥接事实。这个过程本质上是交错的，因为有效的推理依赖于动态检索的证据，而有效的搜索需要推理来根据部分信息优化查询。", "method": "我们提出了分层智能体推理和信息搜索（HARIS），明确地建模了推理驱动搜索和搜索引导推理的协同过程。HARIS包含一个专注于构建主要验证链并在需要更多信息时生成事实问题的高级推理智能体，以及一个迭代检索更多信息并根据中间发现优化搜索的低级搜索智能体。HARIS使用基于结果的强化学习进行训练。", "result": "HARIS在EX-FEVER和HOVER基准测试中表现出强大的性能，极大地推进了多跳事实核查。", "conclusion": "HARIS通过其协同的推理和搜索机制，显著提高了多跳事实核查的准确性和可解释性，并在现有基准测试中取得了优异成果。", "translation": "多跳事实核查本质上具有挑战性，需要多步推理来构建验证链，同时迭代搜索信息以揭示隐藏的桥接事实。这个过程是根本上交错的，因为有效的推理依赖于动态检索的证据，而有效的搜索需要推理来根据部分信息优化查询。为了实现这一点，我们提出了分层智能体推理和信息搜索（HARIS），明确地建模了推理驱动搜索和搜索引导推理的协同过程。HARIS包含一个专注于构建主要验证链并在需要更多信息时生成事实问题的高级推理智能体，以及一个迭代检索更多信息并根据中间发现优化搜索的低级搜索智能体。这种设计使得每个智能体都能专注于各自的任务，从而提高验证准确性和可解释性。HARIS使用基于结果的强化学习进行训练。在EX-FEVER和HOVER基准测试上的实验结果表明，HARIS取得了强大的性能，极大地推进了多跳事实核查。", "summary": "本研究提出了一种名为HARIS（分层智能体推理和信息搜索）的新模型，旨在解决多跳事实核查中的固有挑战。HARIS通过显式建模推理驱动搜索和搜索引导推理的协同过程，实现了更高效的验证。它由一个负责构建验证链和生成查询的高级推理智能体，以及一个负责迭代检索和优化搜索的低级搜索智能体组成。该模型通过强化学习进行训练，并在EX-FEVER和HOVER基准测试上取得了显著的性能提升，证明了其在推进多跳事实核查方面的有效性。", "keywords": "多跳事实核查, 强化学习, 信息检索, 推理, 分层智能体", "comments": "HARIS的创新之处在于其分层智能体设计，明确地将推理和搜索过程解耦并协同起来，提高了多跳事实核查的准确性和可解释性。这种双智能体协同机制是解决复杂信息检索和推理任务的有效方法，对于未来的研究具有重要的启发意义。"}}
{"id": "2506.15692", "title": "MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement", "authors": ["Jaehyun Nam", "Jinsung Yoon", "Jiefeng Chen", "Jinwoo Shin", "Sercan Ö. Arık", "Tomas Pfister"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15692v2", "summary": "Agents based on large language models (LLMs) for machine learning engineering\n(MLE) can automatically implement ML models via code generation. However,\nexisting approaches to build such agents often rely heavily on inherent LLM\nknowledge and employ coarse exploration strategies that modify the entire code\nstructure at once. This limits their ability to select effective task-specific\nmodels and perform deep exploration within specific components, such as\nexperimenting extensively with feature engineering options. To overcome these,\nwe propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first\nleverages external knowledge by using a search engine to retrieve effective\nmodels from the web, forming an initial solution, then iteratively refines it\nby exploring various strategies targeting specific ML components. This\nexploration is guided by ablation studies analyzing the impact of individual\ncode blocks. Furthermore, we introduce a novel ensembling method using an\neffective strategy suggested by MLE-STAR. Our experimental results show that\nMLE-STAR achieves medals in 64% of the Kaggle competitions on the MLE-bench\nLite, significantly outperforming the best alternative.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15692v2", "cate": "cs.LG", "date": "2025-05-27", "updated": "2025-07-30", "AI": {"title_translation": "MLE-STAR：通过搜索和目标精炼的机器学习工程智能体", "tldr": "MLE-STAR是一个新的机器学习工程智能体，它通过结合外部知识搜索和目标精炼来自动构建ML模型，显著优于现有方法。", "motivation": "现有基于大型语言模型（LLM）的机器学习工程（MLE）智能体过度依赖LLM的内在知识，并采用粗粒度的探索策略，限制了它们选择有效任务特定模型和在特定组件内进行深度探索的能力（如特征工程）。", "method": "MLE-STAR首先利用搜索引擎从网络检索外部知识以形成初始解决方案，然后通过探索针对特定ML组件的各种策略进行迭代精炼。这种探索由分析单个代码块影响的消融研究指导。此外，论文还引入了一种使用MLE-STAR建议的有效策略的新型集成方法。", "result": "MLE-STAR在MLE-bench Lite上的Kaggle竞赛中获得了64%的奖牌，显著优于最佳替代方案。", "conclusion": "MLE-STAR通过结合外部知识搜索和目标精炼，有效克服了现有机器学习工程智能体的局限性，显著提高了自动构建机器学习模型的性能和探索深度。", "translation": "基于大型语言模型（LLM）的机器学习工程（MLE）智能体可以通过代码生成自动实现机器学习模型。然而，构建此类智能体的现有方法往往严重依赖LLM的内在知识，并采用粗粒度的探索策略，一次性修改整个代码结构。这限制了它们选择有效的特定任务模型以及在特定组件内进行深度探索的能力，例如对特征工程选项进行广泛实验。为了克服这些问题，我们提出了MLE-STAR，一种构建MLE智能体的新颖方法。MLE-STAR首先利用搜索引擎检索网络上的有效模型，从而形成初始解决方案，然后通过探索针对特定机器学习组件的各种策略进行迭代精炼。这种探索由分析单个代码块影响的消融研究指导。此外，我们引入了一种使用MLE-STAR建议的有效策略的新型集成方法。我们的实验结果表明，MLE-STAR在MLE-bench Lite上的Kaggle竞赛中获得了64%的奖牌，显著优于最佳替代方案。", "summary": "MLE-STAR是一种新颖的机器学习工程（MLE）智能体，旨在克服现有LLM驱动智能体在模型选择和深度探索方面的局限性。它通过结合外部知识搜索（利用搜索引擎）来构建初始解决方案，然后通过针对特定ML组件的迭代精炼（由消融研究指导）来优化。该方法还引入了一种新的集成策略。实验证明，MLE-STAR在Kaggle竞赛中表现出色，显著优于现有最佳方案。", "keywords": "机器学习工程智能体, 大型语言模型, 搜索, 目标精炼, 自动机器学习", "comments": "这篇论文的创新点在于结合了外部知识搜索和目标精炼策略，解决了现有LLM智能体在机器学习工程中存在的内在知识依赖和粗粒度探索问题。通过引入消融研究指导的精炼过程，使得智能体能够更深入地探索特定组件，如特征工程。其在Kaggle竞赛中的优异表现证明了该方法的有效性和实用性，为自动机器学习模型构建提供了新的思路。"}}
{"id": "2507.23012", "title": "PRIME: Pseudo-Random Integrated Multi-Part Entropy for Adaptive Packet Spraying in AI/ML Data centers", "authors": ["Ashkan Sobhani", "Sogand Sadrhaghighi", "Xingjun Chu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23012v1", "summary": "Large-scale distributed training in production data centers place significant\ndemands on network infrastructure. In particular, significant load balancing\nchallenges arise when processing AI/ML workloads, consisting of low-entropy,\nbursty and long-lived flows. Existing solutions designed for Ethernet, such as\nEqual-Cost Multi-Path (ECMP) struggle to maintain high network utilization.\nWhile major industry players (e.g., Ultra Ethernet Consortium) and parts of\nacademia have proposed packet spraying to enhance AI/ML workload performance,\nwe argue that existing packet spraying solutions lead to buffer inflation over\ntime, negatively affecting network performance. Specifically, when ACK\ncoalescing is used, these solutions lead to stale information, degrading\nnetwork performance. Additionally, in asymmetric network conditions- such as\nmix of ordered an unordered traffic, or link degradation and failures- existing\npacket spraying solutions often lead to increased tail latency. In this paper,\nwe present the design and evaluation of PRIME, a pseudo-randomized round-robin\napproach to packet spraying that considers the network topology to optimize\nload distribution and performance. PRIME uses congestion as an indicator to\nre-balance the load. To this extent, PRIME takes into account various\ncongestion signals, accounting for congestion severity, and their decay times\nto avoid network hotspots. We extensively evaluated PRIME using large-scale\nproduction-level simulator. Our results indicate that, compared to existing\nsolutions, PRIME leads to up to 15% improvement for permutation traffic and up\nto 27% improvement in network degradation scenarios", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23012v1", "cate": "cs.NI", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "PRIME：用于AI/ML数据中心自适应包喷射的伪随机集成多部分熵", "tldr": "PRIME是一种新的伪随机包喷射方法，通过考虑网络拓扑和拥塞信号来优化AI/ML数据中心的负载均衡，显著提高了网络性能，解决了现有解决方案导致的缓冲区膨胀和尾部延迟问题。", "motivation": "大型分布式AI/ML训练工作负载对网络基础设施提出了巨大挑战，现有解决方案（如ECMP和现有包喷射）在处理低熵、突发性和长寿命流时难以维持高网络利用率，并导致缓冲区膨胀、信息陈旧和尾部延迟增加，亟需更优的负载均衡方案。", "method": "本文提出了PRIME，一种伪随机的循环式包喷射方法，它考虑网络拓扑以优化负载分布和性能。PRIME使用拥塞作为重新平衡负载的指标，并考虑各种拥塞信号、拥塞严重程度及其衰减时间，以避免网络热点。", "result": "PRIME与现有解决方案相比，在置换流量方面性能提升高达15%，在网络退化场景下性能提升高达27%。", "conclusion": "PRIME通过其伪随机、拓扑感知和拥塞感知的包喷射方法，有效解决了AI/ML数据中心负载均衡的挑战，显著提升了网络性能，尤其是在拥塞和网络退化条件下。", "translation": "大规模分布式训练在生产数据中心对网络基础设施提出了重大需求。特别是，在处理由低熵、突发和长寿命流组成的AI/ML工作负载时，会出现显著的负载均衡挑战。为以太网设计的现有解决方案，例如等成本多路径（ECMP），难以保持高网络利用率。尽管主要行业参与者（例如Ultra Ethernet Consortium）和部分学术界已提出包喷射来增强AI/ML工作负载性能，但我们认为现有的包喷射解决方案随着时间的推移会导致缓冲区膨胀，从而对网络性能产生负面影响。具体来说，当使用ACK合并时，这些解决方案会导致信息过时，从而降低网络性能。此外，在不对称网络条件下——例如有序和无序流量的混合，或链路退化和故障——现有包喷射解决方案通常会导致尾部延迟增加。在本文中，我们介绍了PRIME的设计和评估，这是一种伪随机的循环式包喷射方法，它考虑网络拓扑以优化负载分布和性能。PRIME使用拥塞作为重新平衡负载的指标。为此，PRIME考虑了各种拥塞信号，包括拥塞严重程度及其衰减时间，以避免网络热点。我们使用大规模生产级模拟器对PRIME进行了广泛评估。我们的结果表明，与现有解决方案相比，PRIME在置换流量方面性能提升高达15%，在网络退化场景下性能提升高达27%。", "summary": "本文介绍了PRIME，一种针对AI/ML数据中心设计的伪随机循环式包喷射方法，旨在解决现有负载均衡方案在处理低熵、突发性AI/ML流量时遇到的缓冲区膨胀、信息陈旧和尾部延迟等问题。PRIME通过考虑网络拓扑并利用拥塞信号（包括严重程度和衰减时间）来动态调整负载分布，有效避免网络热点。通过大规模模拟评估，PRIME在置换流量和网络退化场景下分别实现了高达15%和27%的性能提升，显著优于现有解决方案。", "keywords": "包喷射, AI/ML数据中心, 负载均衡, 网络拥塞, PRIME", "comments": "PRIME的创新之处在于其伪随机和拥塞感知的包喷射方法，它不仅考虑了网络拓扑，还动态响应拥塞信号，这对于处理AI/ML数据中心中复杂且动态变化的流量模式至关重要。其对缓冲区膨胀和尾部延迟问题的关注也抓住了现有方案的痛点。该研究通过生产级模拟器验证了其有效性，结果令人鼓舞，表明其在实际部署中可能带来的显著性能提升。"}}
{"id": "2507.22928", "title": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding", "authors": ["Xi Chen", "Aske Plaat", "Niki van Stein"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22928v1", "summary": "Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on\nmulti-step tasks, yet whether the generated \"thoughts\" reflect the true\ninternal reasoning process is unresolved. We present the first feature-level\ncausal study of CoT faithfulness. Combining sparse autoencoders with activation\npatching, we extract monosemantic features from Pythia-70M and Pythia-2.8B\nwhile they tackle GSM8K math problems under CoT and plain (noCoT) prompting.\nSwapping a small set of CoT-reasoning features into a noCoT run raises answer\nlog-probabilities significantly in the 2.8B model, but has no reliable effect\nin 70M, revealing a clear scale threshold. CoT also leads to significantly\nhigher activation sparsity and feature interpretability scores in the larger\nmodel, signalling more modular internal computation. For example, the model's\nconfidence in generating correct answers improves from 1.2 to 4.3. We introduce\npatch-curves and random-feature patching baselines, showing that useful CoT\ninformation is not only present in the top-K patches but widely distributed.\nOverall, our results indicate that CoT can induce more interpretable internal\nstructures in high-capacity LLMs, validating its role as a structured prompting\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22928v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "思维链如何思考？基于稀疏自编码的思维链推理的机制可解释性", "tldr": "本研究通过特征层面的因果分析，发现思维链提示能使大型语言模型（LLMs）产生更可解释的内部结构，尤其在更大规模的模型中，验证了其作为结构化提示方法的有效性。", "motivation": "尽管思维链（CoT）提示能提高大型语言模型（LLMs）在多步骤任务上的准确性，但其生成的“思维”是否真实反映了模型内部的推理过程仍未解决。本研究旨在探讨CoT的内部机制和忠实性。", "method": "研究结合稀疏自编码器和激活修补技术，从Pythia-70M和Pythia-2.8B模型在处理GSM8K数学问题时提取单语义特征（在CoT和noCoT提示下）。通过将少量CoT推理特征交换到noCoT运行中进行因果研究，并引入了补丁曲线和随机特征修补基线来分析有用CoT信息的分布。", "result": "在2.8B模型中，将CoT推理特征交换到noCoT运行时显著提高了答案对数概率，但在70M模型中没有可靠效果，表明存在明显的规模阈值。CoT还导致较大模型中激活稀疏性和特征可解释性分数显著提高，表明内部计算更模块化。模型生成正确答案的置信度从1.2提高到4.3。有用的CoT信息不仅存在于top-K补丁中，而且广泛分布。", "conclusion": "研究结果表明，思维链（CoT）可以在高容量LLMs中诱导更可解释的内部结构，从而验证了其作为结构化提示方法的作用。", "translation": "思维链（CoT）提示提高了大型语言模型在多步骤任务上的准确性，但生成的“思维”是否反映了真实的内部推理过程仍未解决。我们首次提出了CoT忠实性的特征级因果研究。结合稀疏自编码器和激活修补，我们从Pythia-70M和Pythia-2.8B模型中提取单语义特征，这些模型在CoT和普通（noCoT）提示下处理GSM8K数学问题。将少量CoT推理特征交换到noCoT运行中，显著提高了2.8B模型中的答案对数概率，但在70M模型中没有可靠效果，这揭示了一个清晰的规模阈值。CoT还导致较大模型中激活稀疏性和特征可解释性分数显著提高，表明内部计算更模块化。例如，模型生成正确答案的置信度从1.2提高到4.3。我们引入了补丁曲线和随机特征修补基线，表明有用的CoT信息不仅存在于top-K补丁中，而且广泛分布。总的来说，我们的结果表明CoT可以在高容量LLM中诱导更可解释的内部结构，验证了其作为结构化提示方法的作用。", "summary": "本研究对思维链（CoT）提示在大型语言模型（LLMs）中的内部推理过程进行了首次特征级因果分析。通过结合稀疏自编码器和激活修补技术，研究人员在Pythia-70M和Pythia-2.8B模型上进行实验，发现CoT能显著提高2.8B模型中答案的对数概率，并增强其内部计算的模块化和可解释性，但这种效果在较小模型中不明显。研究结果验证了CoT作为一种结构化提示方法，能够促使高容量LLMs产生更具可解释性的内部结构。", "keywords": "思维链, 机制可解释性, 稀疏自编码, 大型语言模型, 激活修补", "comments": "这项研究首次在特征层面因果地探讨了思维链（CoT）提示在大型语言模型（LLMs）中的内部机制，具有重要的创新性。它通过结合稀疏自编码器和激活修补等先进技术，揭示了CoT如何在高容量模型中诱导更可解释和模块化的内部结构，并发现了CoT效应的规模阈值，为理解LLMs的内部工作原理提供了宝贵的见解。这对于提升LLMs的可信赖性和可控性具有重要意义。"}}
{"id": "2507.23591", "title": "Tensor-based reduction of linear parameter-varying state-space models", "authors": ["Bogoljub Terzin", "E. Javier Olucha", "Amritam Das", "Siep Weiland", "Roland Tóth"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23591v1", "summary": "The Linear Parameter-Varying (LPV) framework is a powerful tool for\ncontrolling nonlinear and complex systems, but the conversion of nonlinear\nmodels into LPV forms often results in high-dimensional and overly conservative\nLPV models. To be able to apply control strategies, there is often a need for\nmodel reduction in order to reduce computational needs. This paper presents the\nfirst systematic approach for the joint reduction of state order and scheduling\nsignal dimension of LPV state space models. The existing methods typically\naddress these reductions separately. By formulating a tensorial form of LPV\nmodels with an affine dependency on the scheduling variables, we leverage\ntensor decomposition to find the dominant components of state and scheduling\nsubspaces. We extend the common Petrov-Galerkin projection approach to LPV\nframework by adding a scheduling projection. This extension enables the joint\nreduction. To find suitable subspaces for the extended Petrov-Galerkin\nprojection, we have developed two different methods: tensor-based LPV moment\nmatching, and an approach through Proper Orthogonal Decomposition. Advantages\nof the proposed methods are demonstrated on two different series-interconnected\nmass-spring-damper systems with nonlinear springs: one primarily used for\ncomparison with other methods and a more elaborate higher-order model designed\nto assess scalability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23591v1", "cate": "eess.SY", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于张量的线性参数时变状态空间模型降阶", "tldr": "该论文提出了一种新的、系统性的方法，用于联合降低线性参数时变（LPV）状态空间模型的状态阶数和调度信号维度，通过张量形式和扩展的Petrov-Galerkin投影实现，并展示了其在非线性弹簧质量-弹簧-阻尼系统上的优势。", "motivation": "将非线性模型转换为线性参数时变（LPV）形式通常会导致高维且过于保守的LPV模型，为了应用控制策略，需要进行模型降阶以减少计算需求。现有方法通常分别处理状态阶数和调度信号维度的降阶。", "method": "本文提出了一种联合降低LPV状态空间模型状态阶数和调度信号维度的系统方法。通过将LPV模型表述为对调度变量具有仿射依赖关系的张量形式，利用张量分解来寻找状态和调度子空间的主导分量。通过增加调度投影，将常见的Petrov-Galerkin投影方法扩展到LPV框架。为找到适合扩展Petrov-Galerkin投影的子空间，开发了两种不同方法：基于张量的LPV矩匹配和通过本征正交分解的方法。", "result": "所提出的方法的优势在两个不同的串联质量-弹簧-阻尼系统上得到了验证，这些系统具有非线性弹簧：一个主要用于与其他方法进行比较，另一个是更复杂的、为评估可扩展性而设计的高阶模型。", "conclusion": "本文提出的基于张量的方法，通过联合降低状态阶数和调度信号维度，有效解决了高维LPV模型的降阶问题，并为非线性系统的控制策略应用提供了计算效率更高的模型。其在复杂系统上的表现证明了其可行性和可扩展性。", "translation": "线性参数时变（LPV）框架是控制非线性和复杂系统的强大工具，但将非线性模型转换为LPV形式通常会导致高维且过于保守的LPV模型。为了能够应用控制策略，通常需要进行模型降阶以减少计算需求。本文提出了第一个系统性的方法，用于联合降低LPV状态空间模型的状态阶数和调度信号维度。现有方法通常分别处理这些降阶。通过将LPV模型表述为对调度变量具有仿射依赖关系的张量形式，我们利用张量分解来寻找状态和调度子空间的主导分量。我们通过增加调度投影，将常见的Petrov-Galerkin投影方法扩展到LPV框架。这一扩展实现了联合降阶。为了找到适合扩展Petrov-Galerkin投影的子空间，我们开发了两种不同方法：基于张量的LPV矩匹配和通过本征正交分解的方法。所提出方法的优势在两个不同的串联质量-弹簧-阻尼系统上得到了验证，这些系统具有非线性弹簧：一个主要用于与其他方法进行比较，另一个是更复杂的、为评估可扩展性而设计的高阶模型。", "summary": "本文提出了一种创新的、系统性的方法，旨在联合降低线性参数时变（LPV）状态空间模型的状态阶数和调度信号维度，以解决现有LPV模型高维且计算量大的问题。该方法通过将LPV模型转换为张量形式，并结合张量分解与扩展的Petrov-Galerkin投影（引入调度投影）来实现降阶。文中还开发了基于张量的LPV矩匹配和本征正交分解两种具体方法来确定投影子空间。实验结果在两个非线性质量-弹簧-阻尼系统上验证了所提方法的有效性和可扩展性。", "keywords": "线性参数时变（LPV）, 模型降阶, 张量分解, Petrov-Galerkin投影, 状态空间模型", "comments": "该论文的创新点在于提出了首个系统性的联合降阶方法，同时处理LPV模型的状态阶数和调度信号维度，这在现有方法中是分开进行的。通过引入张量形式和扩展的Petrov-Galerkin投影，为LPV模型的降阶提供了一个统一且高效的框架。这对于将LPV框架应用于高维非线性系统控制具有重要意义，因为它能显著降低计算复杂性。其在评估可扩展性上的关注也表明了该方法的实用潜力。"}}
{"id": "2507.23767", "title": "Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing", "authors": ["Jonathan R. Landers"], "categories": ["stat.ML", "cs.LG", "68T05, 62H30, 62F10, 68Q32", "F.2.2; I.2.6; I.5.2; G.3"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      27 pages, 11 figures, 3 tables", "url": "http://arxiv.org/abs/2507.23767v1", "summary": "A novel approach is presented for identifying distinct signatures of\nperforming acts in the secondary ticket resale market by analyzing dynamic\npricing distributions. Using a newly curated, time series dataset from the\nSeatGeek API, we model ticket pricing distributions as scaled Beta\ndistributions. This enables accurate parameter estimation from incomplete\nstatistical data using a hybrid of quantile matching and the method of moments.\nIncorporating the estimated $\\alpha$ and $\\beta$ parameters into Random Forest\nclassifiers significantly improves pairwise artist classification accuracy,\ndemonstrating the unique economic signatures in event pricing data.\nAdditionally, we provide theoretical and empirical evidence that incorporating\nzero-variance (constant-value) features into Random Forest models acts as an\nimplicit regularizer, enhancing feature variety and robustness. This\nregularization promotes deeper, more varied trees in the ensemble, improving\nthe bias-variance tradeoff and mitigating overfitting to dominant features.\nThese findings are validated on both the new ticket pricing dataset and the\nstandard UCI ML handwritten digits dataset.", "comment": "27 pages, 11 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.23767v1", "cate": "stat.ML", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "动态票务定价中的缩放Beta模型和特征稀释", "tldr": "本文提出了一种使用缩放Beta模型分析票务定价分布的新方法，以识别演出者的独特经济特征，并证明在随机森林中引入零方差特征可以作为隐式正则化器，提高模型性能。", "motivation": "识别二手票务转售市场中演出者的独特经济特征，通过分析动态定价分布来理解市场行为。", "method": "1. 使用从SeatGeek API获取的时间序列数据集。2. 将票务定价分布建模为缩放Beta分布。3. 结合分位数匹配和矩量法从不完整数据中准确估计参数。4. 将估计的参数整合到随机森林分类器中进行艺术家分类。5. 理论和经验证明在随机森林模型中引入零方差（常数值）特征作为隐式正则化器。", "result": "1. 将估计的$\\alpha$和$\\beta$参数纳入随机森林分类器显著提高了配对艺术家分类的准确性，证明了事件定价数据中独特的经济特征。2. 引入零方差（常数值）特征到随机森林模型中作为隐式正则化器，增强了特征多样性和鲁棒性。3. 这种正则化促进了集成模型中更深、更多样化的树，改善了偏差-方差权衡，并缓解了对主导特征的过拟合。4. 这些发现在新票务定价数据集和标准UCI ML手写数字数据集上都得到了验证。", "conclusion": "通过缩放Beta模型和特征稀释技术，可以有效地识别二手票务市场中演出者的经济特征，并且发现零方差特征作为隐式正则化器能够提升随机森林模型的性能和鲁棒性。", "translation": "本文提出了一种识别二手票务转售市场中演出者独特特征的新方法，通过分析动态定价分布实现。我们利用从SeatGeek API新整理的时间序列数据集，将票务定价分布建模为缩放Beta分布。这使得能够利用分位数匹配和矩量法的混合方法，从不完整的统计数据中准确估计参数。将估计的$\\alpha$和$\\beta$参数纳入随机森林分类器显著提高了配对艺术家分类的准确性，证明了事件定价数据中独特的经济特征。此外，我们提供了理论和经验证据，表明将零方差（常数值）特征纳入随机森林模型中可作为隐式正则化器，增强特征多样性和鲁棒性。这种正则化促进了集成模型中更深、更多样化的树，改善了偏差-方差权衡，并缓解了对主导特征的过拟合。这些发现在新票务定价数据集和标准UCI ML手写数字数据集上都得到了验证。", "summary": "本研究提出了一种创新方法，通过将票务定价分布建模为缩放Beta分布，从SeatGeek API数据中识别二手票务市场中演出者的独特经济特征。研究利用分位数匹配和矩量法进行参数估计，并将估计参数整合到随机森林分类器中，显著提高了艺术家分类准确性。此外，本文还证明了在随机森林模型中引入零方差特征可作为隐式正则化器，有效增强模型鲁棒性，改善偏差-方差权衡，并减少过拟合。", "keywords": "动态票务定价, 缩放Beta模型, 随机森林, 特征稀释, 隐式正则化", "comments": "该论文的创新点在于将缩放Beta模型应用于动态票务定价分析，并发现零方差特征作为随机森林的隐式正则化器。后者尤其重要，因为它提供了一种简单而有效的方法来提高集成模型的泛化能力和鲁棒性，这对于处理现实世界中复杂且可能包含冗余或低信息量特征的数据集具有广泛意义。该方法不仅在票务定价领域有效，还在标准数据集上得到验证，显示出其通用性。"}}
{"id": "2502.20263", "title": "Vector-Quantized Vision Foundation Models for Object-Centric Learning", "authors": ["Rongzhen Zhao", "Vivienne Wang", "Juho Kannala", "Joni Pajarinen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2502.20263v4", "summary": "Perceiving visual scenes as objects and background--like humans\ndo--Object-Centric Learning (OCL) aggregates image or video feature maps into\nobject-level feature vectors, termed \\textit{slots}. OCL's self-supervision of\nreconstructing the input from these aggregated slots struggles with complex\nobject textures, thus Vision Foundation Model (VFM) representations are used as\nthe aggregation input and reconstruction target. However, existing methods\nleverage VFM representations in diverse ways and often fail to fully exploit\ntheir potential. In response, we propose a clean architecture--Vector-Quantized\nVFMs for OCL (VQ-VFM-OCL, or VVO)--that unifies mainstream OCL methods. The key\nto our unification is simple yet effective, just shared quantizing the same VFM\nrepresentation as the reconstruction target. Through mathematical modeling and\nstatistical verification, we further analyze why VFM representations facilitate\nOCL aggregation and how their shared quantization as reconstruction targets\nstrengthens OCL supervision. Experiments show that across different VFMs,\naggregators and decoders, our VVO consistently outperforms baselines in object\ndiscovery and recognition, as well as downstream visual prediction and\nreasoning. The implementation and model checkpoints are available on\nhttps://github.com/Genera1Z/VQ-VFM-OCL.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2502.20263v4", "cate": "cs.CV", "date": "2025-02-27", "updated": "2025-07-31", "AI": {"title_translation": "面向对象中心学习的向量量化视觉基础模型", "tldr": "现有面向对象中心学习(OCL)在使用视觉基础模型(VFM)表示时未能充分利用其潜力。本文提出了VQ-VFM-OCL(VVO)架构，通过共享量化相同的VFM表示作为重建目标来统一主流OCL方法，并在多项任务中显著优于基线。", "motivation": "现有的面向对象中心学习（OCL）方法在通过聚合槽位重建输入进行自监督时，难以处理复杂的对象纹理。尽管使用了视觉基础模型（VFM）表示，但现有方法利用VFM表示的方式多样，且往往未能充分发挥其潜力。", "method": "本文提出了一种简洁的架构——面向OCL的向量量化VFM（VQ-VFM-OCL，简称VVO）。其核心是将相同的VFM表示进行共享量化作为重建目标，从而统一了主流的OCL方法。研究还通过数学建模和统计验证，分析了VFM表示如何促进OCL聚合以及共享量化如何加强OCL监督。", "result": "实验表明，在不同的VFM、聚合器和解码器下，所提出的VVO模型在对象发现和识别以及下游视觉预测和推理方面始终优于现有基线。", "conclusion": "所提出的VQ-VFM-OCL（VVO）架构，通过将向量量化的视觉基础模型表示作为共享重建目标，有效统一并显著提升了面向对象中心学习在各种任务中的性能。", "translation": "将视觉场景感知为对象和背景——就像人类一样——面向对象中心学习（OCL）将图像或视频特征图聚合为对象级特征向量，称为“槽位”。OCL通过从这些聚合槽位重建输入进行自监督，但在处理复杂对象纹理时遇到困难，因此使用视觉基础模型（VFM）表示作为聚合输入和重建目标。然而，现有方法以多种方式利用VFM表示，并且通常未能充分发挥其潜力。为此，我们提出了一种简洁的架构——面向OCL的向量量化VFM（VQ-VFM-OCL，简称VVO）——它统一了主流的OCL方法。我们统一的关键简单而有效，即共享量化相同的VFM表示作为重建目标。通过数学建模和统计验证，我们进一步分析了为什么VFM表示有助于OCL聚合，以及它们作为重建目标的共享量化如何加强OCL监督。实验表明，在不同的VFM、聚合器和解码器下，我们的VVO在对象发现和识别以及下游视觉预测和推理方面始终优于基线。实现代码和模型检查点可在https://github.com/Genera1Z/VQ-VFM-OCL上获取。", "summary": "本文提出了一种名为VQ-VFM-OCL（VVO）的新架构，旨在解决现有面向对象中心学习（OCL）方法在使用视觉基础模型（VFM）表示时未能充分利用其潜力的问题。VVO通过共享量化相同的VFM表示作为重建目标，有效地统一了主流OCL方法。研究通过数学和统计分析解释了VFM表示如何促进OCL聚合以及共享量化如何强化监督。实验结果表明，VVO在对象发现、识别以及下游视觉预测和推理方面均显著优于现有基线。", "keywords": "面向对象中心学习, 视觉基础模型, 向量量化, 自监督, 对象发现", "comments": "本文通过引入向量量化视觉基础模型（VQ-VFM-OCL），为面向对象中心学习提供了一种新颖且统一的方法。其核心创新在于将VFM表示进行共享量化作为重建目标的简洁而强大的理念，这不仅统一了多样化的OCL方法，还显著提升了性能。文章提供的数学和统计分析为该方法提供了坚实的理论支持。在各种设置下始终超越基线表现，凸显了其鲁棒性及在推动计算机视觉中对象中心理解方面的巨大潜力。"}}
{"id": "2507.23773", "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23773v1", "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23773v1", "cate": "cs.AI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SimuRA：通过基于LLM的世界模型模拟推理架构实现通用目标导向智能体", "tldr": "SimuRA是一个基于LLM世界模型的通用目标导向智能体架构，通过模拟推理克服了自回归LLM的局限性，并在网络浏览任务中显著提升了性能。", "motivation": "当前基于LLM的AI智能体通常采用“一任务一智能体”的方法，这导致可扩展性和通用性不足，并且受到自回归LLM的根本限制。为了实现更通用、更强大的AI智能体，研究者旨在开发一种能通过模拟推理行动的架构。", "method": "SimuRA是一种目标导向的通用智能体推理架构，它基于最优智能体的原理性公式，通过引入基于LLM的通用世界模型进行规划和模拟，克服了自回归推理的局限性。该世界模型利用自然语言的丰富概念空间，在广泛的环境中进行灵活规划。", "result": "在困难的网络浏览任务中，SimuRA将航班搜索的成功率从0%提高到32.2%。基于世界模型的规划比自回归规划的优势高达124%，证明了世界模型模拟作为推理范式的优势。", "conclusion": "SimuRA展示了通过基于LLM的世界模型进行模拟推理，能够构建出更通用、更强大的目标导向AI智能体，并在复杂任务中表现出显著的性能提升。这为训练单一通用智能体模型以在所有环境中超智能行动提供了可能性。", "translation": "大型语言模型（LLMs）构建的AI智能体前景广阔，但目前的实践侧重于“一任务一智能体”的方法，这不仅缺乏可扩展性和通用性，而且受到自回归LLM的根本限制。另一方面，人类是通用智能体，他们通过心理模拟其行动和计划的结果进行推理。为了迈向更通用、更强大的AI智能体，我们引入了SimuRA，一个用于通用智能体推理的目标导向架构。基于任何环境中最优智能体的原理性公式，SimuRA通过引入一个用于模拟规划的世界模型，克服了自回归推理的局限性。通用世界模型使用LLM实现，它可以利用自然语言的概念丰富潜在空间在广泛的环境中灵活规划。在困难的网络浏览任务中进行的实验表明，SimuRA将航班搜索的成功率从0%提高到32.2%。特别是，基于世界模型的规划比自回归规划的优势高达124%，证明了世界模型模拟作为一种推理范式的优势。我们对基于LLM训练一个单一、通用智能体模型，使其能够在所有环境中超智能行动的可能性感到兴奋。首先，我们发布了SimuRA，一个基于预训练LLM构建的网络浏览智能体，作为研究演示供公众测试。", "summary": "本论文提出了SimuRA，一个基于LLM世界模型的通用目标导向智能体架构，旨在克服当前AI智能体在可扩展性和通用性上的局限以及自回归LLM的固有缺陷。SimuRA通过模拟推理和世界模型进行规划，而非传统的自回归推理。实验结果表明，在网络浏览任务中，SimuRA显著提高了航班搜索的成功率，并且基于世界模型的规划比自回归规划具有显著优势，证明了其作为通用智能体推理范式的有效性。", "keywords": "LLM, 世界模型, 模拟推理, 通用智能体, 目标导向", "comments": "SimuRA的创新之处在于其引入了基于LLM的世界模型进行模拟推理，这有效克服了传统自回归LLM在通用性和规划能力上的局限。通过模拟未来行动结果，SimuRA能够进行更高级的规划，并在复杂任务中展现出优越的性能。这对于构建更接近人类推理方式的通用AI智能体具有重要意义。"}}
{"id": "2507.23570", "title": "Multiple-Parameter Graph Fractional Fourier Transform: Theory and Applications", "authors": ["Manjun Cui", "Zhichao Zhang", "Wei Yao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23570v1", "summary": "The graph fractional Fourier transform (GFRFT) applies a single global\nfractional order to all graph frequencies, which restricts its adaptability to\ndiverse signal characteristics across the spectral domain. To address this\nlimitation, in this paper, we propose two types of multiple-parameter GFRFTs\n(MPGFRFTs) and establish their corresponding theoretical frameworks. We design\na spectral compression strategy tailored for ultra-low compression ratios,\neffectively preserving essential information even under extreme dimensionality\nreduction. To enhance flexibility, we introduce a learnable order vector scheme\nthat enables adaptive compression and denoising, demonstrating strong\nperformance on both graph signals and images. We explore the application of\nMPGFRFTs to image encryption and decryption. Experimental results validate the\nversatility and superior performance of the proposed MPGFRFT framework across\nvarious graph signal processing tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23570v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "多参数图分数傅里叶变换：理论与应用", "tldr": "本文提出了两种多参数图分数傅里叶变换（MPGFRFT），解决了传统图分数傅里叶变换（GFRFT）在不同频谱域信号适应性差的问题，并展示了其在压缩、去噪和图像加密等任务中的优越性能。", "motivation": "传统的图分数傅里叶变换（GFRFT）对所有图频率应用单一的全局分数阶，限制了其对频谱域中不同信号特征的适应性。为了解决这一局限性，本文提出了多参数图分数傅里叶变换（MPGFRFT）。", "method": "本文提出了两种多参数图分数傅里叶变换（MPGFRFT）并建立了相应的理论框架。设计了一种针对超低压缩比的频谱压缩策略，以在极端降维下保留关键信息。引入了一种可学习的阶向量方案，以实现自适应压缩和去噪。探讨了MPGFRFT在图像加密和解密中的应用。", "result": "实验结果验证了所提出的MPGFRFT框架在各种图信号处理任务中的多功能性和优越性能。", "conclusion": "多参数图分数傅里叶变换（MPGFRFT）通过引入多个可学习参数，显著增强了图分数傅里叶变换的适应性和灵活性，并在图信号处理任务中展现出卓越的性能和广泛的应用潜力。", "translation": "图分数傅里叶变换（GFRFT）对所有图频率应用单一的全局分数阶，这限制了其对频谱域中不同信号特征的适应性。为了解决这一局限性，本文提出了两种多参数图分数傅里叶变换（MPGFRFT）并建立了相应的理论框架。我们设计了一种针对超低压缩比的频谱压缩策略，即使在极端降维下也能有效地保留基本信息。为了增强灵活性，我们引入了一种可学习的阶向量方案，该方案能够实现自适应压缩和去噪，并在图信号和图像上都表现出强大的性能。我们探索了MPGFRFT在图像加密和解密中的应用。实验结果验证了所提出的MPGFRFT框架在各种图信号处理任务中的多功能性和优越性能。", "summary": "本文针对传统图分数傅里叶变换（GFRFT）在信号适应性方面的不足，提出了两种多参数图分数傅里叶变换（MPGFRFT）及其理论框架。研究设计了超低压缩比下的频谱压缩策略，并引入了可学习的阶向量方案以实现自适应压缩和去噪。此外，探讨了MPGFRFT在图像加密解密中的应用。实验证明，所提出的MPGFRFT框架在多种图信号处理任务中表现出强大的通用性和卓越的性能。", "keywords": "多参数图分数傅里叶变换, 图信号处理, 频谱压缩, 自适应去噪, 图像加密", "comments": "这项工作通过引入多参数机制，显著提升了图分数傅里叶变换的灵活性和适用性，解决了传统GFRFT的局限性。其创新点在于提出了两种MPGFRFT类型、针对超低压缩比的频谱压缩策略以及可学习的阶向量方案，这些都增强了其在实际应用中的性能。该研究在图信号处理、数据压缩、去噪和图像安全等领域具有重要意义和潜在应用价值。"}}
{"id": "2412.16107", "title": "Allocation for Omnidirectional Aerial Robots: Incorporating Power Dynamics", "authors": ["Eugenio Cuniato", "Mike Allenspach", "Thomas Stastny", "Helen Oleynikova", "Roland Siegwart", "Michael Pantic"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.16107v2", "summary": "Tilt-rotor aerial robots are more dynamic and versatile than fixed-rotor\nplatforms, since the thrust vector and body orientation are decoupled. However,\nthe coordination of servos and propellers (the allocation problem) is not\ntrivial, especially accounting for overactuation and actuator dynamics. We\nincrementally build and present three novel allocation methods for tiltrotor\naerial robots, comparing them to state-of-the-art methods on a real system\nperforming dynamic maneuvers. We extend the state-of-the-art geometric\nallocation into a differential allocation, which uses the platform's redundancy\nand does not suffer from singularities. We expand it by incorporating actuator\ndynamics and propeller power dynamics. These allow us to model dynamic\npropeller acceleration limits, bringing two main advantages: balancing\npropeller speed without the need of nullspace goals and allowing the platform\nto selectively turn-off propellers during flight, opening the door to new\nmanipulation possibilities. We also use actuator dynamics and limits to\nnormalize the allocation problem, making it easier to tune and allowing it to\ntrack 70% faster trajectories than a geometric allocation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.16107v2", "cate": "cs.RO", "date": "2024-12-20", "updated": "2025-07-31", "AI": {"title_translation": "全向飞行机器人分配：融入功率动力学", "tldr": "该研究提出并验证了三种新型倾转旋翼飞行器分配方法，通过整合执行器和螺旋桨功率动力学，解决了传统方法的局限性，实现了更快的轨迹跟踪和新的操作可能性。", "motivation": "倾转旋翼飞行器虽比固定旋翼平台更具动态性和通用性，但其伺服器和螺旋桨的协调（分配问题）并非易事，尤其是在考虑过驱动和执行器动力学时。", "method": "该研究逐步构建并提出了三种新型倾转旋翼飞行器分配方法，并在执行动态机动的真实系统上与现有技术进行了比较。这些方法包括将最先进的几何分配扩展为利用平台冗余且无奇异性的差分分配，并通过整合执行器动力学和螺旋桨功率动力学来建模动态螺旋桨加速限制。此外，还利用执行器动力学和限制来规范化分配问题。", "result": "整合功率动力学能够建模动态螺旋桨加速限制，带来了无需零空间目标平衡螺旋桨速度和允许平台在飞行中选择性关闭螺旋桨的优势，开启了新的操作可能性。通过规范化分配问题，使其更容易调整，并且能够跟踪比几何分配快70%的轨迹。", "conclusion": "该研究成功开发了新型分配方法，通过考虑执行器和螺旋桨功率动力学，显著提升了倾转旋翼飞行器的性能、易用性和操作能力。", "translation": "倾转旋翼飞行机器人比固定旋翼平台更具动态性和通用性，因为推力矢量和机身姿态是解耦的。然而，伺服器和螺旋桨的协调（分配问题）并非易事，尤其是在考虑过驱动和执行器动力学时。我们逐步构建并提出了三种新型倾转旋翼飞行器分配方法，并在执行动态机动的真实系统上将它们与最先进的方法进行了比较。我们将最先进的几何分配扩展为差分分配，该分配利用平台的冗余并且不会出现奇异性。我们通过整合执行器动力学和螺旋桨功率动力学对其进行扩展。这些使我们能够建模动态螺旋桨加速限制，带来了两个主要优势：无需零空间目标即可平衡螺旋桨速度，并允许平台在飞行中选择性关闭螺旋桨，为新的操作可能性打开了大门。我们还利用执行器动力学和限制来规范化分配问题，使其更容易调整，并且能够跟踪比几何分配快70%的轨迹。", "summary": "本文针对倾转旋翼飞行器复杂的分配问题，提出并验证了三种新型分配方法。这些方法通过将现有几何分配扩展为差分分配，并创新性地整合了执行器和螺旋桨功率动力学，从而能精确建模螺旋桨动态加速限制。实验结果表明，这些新方法不仅无需零空间目标即可平衡螺旋桨速度、支持飞行中选择性关闭螺旋桨以拓展操作空间，还能显著简化调优过程，并实现比传统几何分配快70%的轨迹跟踪能力。", "keywords": "倾转旋翼飞行器, 分配问题, 功率动力学, 执行器动力学, 差分分配", "comments": "该研究的创新点在于将执行器动力学和螺旋桨功率动力学融入到倾转旋翼飞行器的分配问题中，这使得能够更精确地建模螺旋桨的动态行为，并解决了传统方法中的一些局限性，如奇异性问题。解决了倾转旋翼飞行器在动态操作中的分配挑战，提升了其性能、鲁棒性和多功能性，特别是在平衡螺旋桨速度和实现飞行中选择性关闭螺旋桨方面，为未来的机器人操作和应用开辟了新途径。"}}
{"id": "2507.23595", "title": "MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model", "authors": ["Yaoye Zhu", "Zhe Wang", "Yan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV25 poster", "url": "http://arxiv.org/abs/2507.23595v1", "summary": "As cooperative systems that leverage roadside cameras to assist autonomous\nvehicle perception become increasingly widespread, large-scale precise\ncalibration of infrastructure cameras has become a critical issue. Traditional\nmanual calibration methods are often time-consuming, labor-intensive, and may\nrequire road closures. This paper proposes MamV2XCalib, the first V2X-based\ninfrastructure camera calibration method with the assistance of vehicle-side\nLiDAR. MamV2XCalib only requires autonomous vehicles equipped with LiDAR to\ndrive near the cameras to be calibrated in the infrastructure, without the need\nfor specific reference objects or manual intervention. We also introduce a new\ntargetless LiDAR-camera calibration method, which combines multi-scale features\nand a 4D correlation volume to estimate the correlation between vehicle-side\npoint clouds and roadside images. We model the temporal information and\nestimate the rotation angles with Mamba, effectively addressing calibration\nfailures in V2X scenarios caused by defects in the vehicle-side data (such as\nocclusions) and large differences in viewpoint. We evaluate MamV2XCalib on the\nV2X-Seq and TUMTraf-V2X real-world datasets, demonstrating the effectiveness\nand robustness of our V2X-based automatic calibration approach. Compared to\nprevious LiDAR-camera methods designed for calibration on one car, our approach\nachieves better and more stable calibration performance in V2X scenarios with\nfewer parameters. The code is available at\nhttps://github.com/zhuyaoye/MamV2XCalib.", "comment": "ICCV25 poster", "pdf_url": "http://arxiv.org/pdf/2507.23595v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MamV2XCalib：基于V2X的无目标基础设施相机状态空间模型校准", "tldr": "MamV2XCalib是一种基于V2X的、利用车载激光雷达辅助的无目标基础设施相机自动校准方法，解决了传统方法耗时费力的问题，并在V2X场景下展现出更好的校准性能和鲁棒性。", "motivation": "随着利用路边相机辅助自动驾驶车辆感知的协同系统日益普及，大规模精确校准基础设施相机成为一个关键问题。传统的相机校准方法通常耗时、费力且可能需要封闭道路。", "method": "本文提出了MamV2XCalib，这是首个利用车载激光雷达辅助的基于V2X的基础设施相机校准方法。它仅需配备激光雷达的自动驾驶车辆在待校准相机附近行驶，无需特定参考物体或人工干预。该方法引入了一种新的无目标激光雷达-相机校准方法，结合多尺度特征和4D关联体来估计车载点云和路边图像之间的关联。它还利用Mamba模型处理时间信息并估计旋转角度，有效解决了V2X场景中因车载数据缺陷（如遮挡）和视角差异大导致的校准失败问题。", "result": "MamV2XCalib在V2X-Seq和TUMTraf-V2X真实世界数据集上进行了评估，结果表明其V2X自动校准方法有效且鲁棒。与之前为单车校准设计的激光雷达-相机方法相比，MamV2XCalib在V2X场景下以更少的参数实现了更好、更稳定的校准性能。", "conclusion": "MamV2XCalib成功地提出了一种有效且鲁棒的基于V2X的无目标基础设施相机自动校准方法，解决了传统方法的局限性，并在复杂V2X场景中展现出优越的性能。", "translation": "随着利用路边相机辅助自动驾驶车辆感知的协同系统日益普及，大规模精确校准基础设施相机成为一个关键问题。传统的相机校准方法通常耗时、费力且可能需要封闭道路。本文提出了MamV2XCalib，这是首个利用车载激光雷达辅助的基于V2X的基础设施相机校准方法。MamV2XCalib仅需配备激光雷达的自动驾驶车辆在基础设施中待校准相机附近行驶，无需特定参考物体或人工干预。我们还引入了一种新的无目标激光雷达-相机校准方法，结合多尺度特征和4D关联体来估计车载点云和路边图像之间的关联。我们利用Mamba模型处理时间信息并估计旋转角度，有效解决了V2X场景中因车载数据缺陷（如遮挡）和视角差异大导致的校准失败问题。我们在V2X-Seq和TUMTraf-V2X真实世界数据集上评估了MamV2XCalib，结果证明了我们基于V2X的自动校准方法的有效性和鲁棒性。与之前为单车校准设计的激光雷达-相机方法相比，我们的方法在V2X场景下以更少的参数实现了更好、更稳定的校准性能。代码可在https://github.com/zhuyaoye/MamV2XCalib获取。", "summary": "本文提出MamV2XCalib，一种创新的基于V2X的无目标基础设施相机自动校准方法。该方法利用车载激光雷达辅助，无需人工干预或特定参考物，仅需自动驾驶车辆在相机附近行驶即可完成校准。MamV2XCalib结合多尺度特征和4D关联体进行激光雷达-相机校准，并引入Mamba模型处理时间信息以克服V2X场景中数据缺陷和视角差异导致的校准问题。在真实世界数据集上的评估显示，MamV2XCalib比现有方法在V2X场景下表现出更优异和稳定的校准性能。", "keywords": "V2X, 相机校准, 基础设施, 激光雷达, Mamba模型", "comments": "MamV2XCalib的创新点在于它是首个将V2X技术与车载激光雷达结合用于无目标基础设施相机校准的方法。它通过引入新的激光雷达-相机校准策略和利用Mamba模型处理时间信息，有效解决了V2X场景中数据质量和视角差异带来的挑战，显著提升了校准的自动化程度和鲁棒性，对于大规模部署协同式智能交通系统具有重要意义。"}}
{"id": "2506.21875", "title": "WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation", "authors": ["Jian Zhang", "Linhao Zhang", "Bokai Lei", "Chuhan Wu", "Wei Jia", "Xiao Zhou"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21875v2", "summary": "Recent multi-modal Large Language Models (LLMs) such as GPT-4o have\ndemonstrated strong capabilities of direct speech interaction. However, the\nlack of specialized and comprehensive benchmarks for end-to-end speech LLM\nevaluation hinders optimizing the user experience of Audio LLMs in real-world\napplications. Existing evaluation methods often adapt text-based benchmarks,\noverlooking speech's unique characteristics and challenges, including prosody,\nhomophones, stuttering, and differing user expectations. Here, we present a\nnovel approach to thoroughly evaluate LLMs in practical speech conversations.\nWe systematically curate real-world chat data relevant to spoken scenarios,\nintroduce diversity in speaker attributes and acoustic conditions, and augment\nthe dataset with speech-specific phenomena. We further design a query-aware\nevaluation method to use customized evaluation checklists and prompts to\nenhance the accuracy of automatic evaluation. We conduct comprehensive testing\nand detailed analysis of various mainstream speech models, revealing\nsignificant differences in model performance across different speech scenarios.\nThe use of query-aware evaluation further enables a finer-grained assessment\nunder various speech-specific scenarios. Our benchmark can provide valuable\ninsights for speech model development and evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21875v2", "cate": "cs.CL", "date": "2025-06-27", "updated": "2025-07-31", "AI": {"title_translation": "WildSpeech-Bench: 自然语音对话中音频大语言模型的基准测试", "tldr": "本文提出了WildSpeech-Bench，这是一个专门用于评估音频LLM在真实语音对话中性能的综合基准测试，解决了现有文本基准测试忽视语音特性的问题，并通过引入真实世界数据、多样化语音现象和查询感知评估方法，揭示了主流语音模型在不同场景下的性能差异。", "motivation": "现有评估方法通常改编文本基准，忽略了语音的独特特征和挑战，如韵律、同音异义词、口吃和不同的用户期望，导致在真实世界应用中优化音频LLM的用户体验受到阻碍。因此，需要一个专门且全面的基准来端到端地评估语音LLM。", "method": "本文提出了一种彻底评估LLM在实际语音对话中的新方法。具体包括：系统地整理与口语场景相关的真实世界聊天数据；引入说话者属性和声学条件的多样性；通过语音特定现象扩充数据集；设计一种查询感知评估方法，使用定制的评估清单和提示来提高自动评估的准确性。", "result": "通过对各种主流语音模型进行全面的测试和详细分析，揭示了模型在不同语音场景下的性能存在显著差异。查询感知评估进一步实现了在各种语音特定场景下的更细粒度评估。", "conclusion": "本文提出的基准测试可以为语音模型的开发和评估提供有价值的见解。", "translation": "最近的多模态大型语言模型（LLM），如GPT-4o，展示了直接语音交互的强大能力。然而，缺乏专门和全面的端到端语音LLM评估基准，阻碍了在实际应用中优化音频LLM的用户体验。现有的评估方法通常改编文本基准，忽视了语音的独特特征和挑战，包括韵律、同音异义词、同音词、口吃和不同的用户期望。在此，我们提出了一种彻底评估LLM在实际语音对话中的新方法。我们系统地整理了与口语场景相关的真实世界聊天数据，引入了说话者属性和声学条件的多样性，并通过语音特定现象扩充了数据集。我们进一步设计了一种查询感知评估方法，使用定制的评估清单和提示来增强自动评估的准确性。我们对各种主流语音模型进行了全面的测试和详细分析，揭示了模型在不同语音场景下的性能存在显著差异。查询感知评估进一步实现了在各种语音特定场景下的更细粒度评估。我们的基准可以为语音模型的开发和评估提供有价值的见解。", "summary": "本文介绍了WildSpeech-Bench，一个用于评估音频大语言模型（LLM）在自然语音对话中性能的新型基准测试。针对现有评估方法忽视语音特性的问题，WildSpeech-Bench通过整合真实世界聊天数据、引入说话者和声学多样性以及语音特定现象来构建数据集。此外，它还设计了一种查询感知评估方法，利用定制的评估清单和提示来提高自动评估的准确性。对主流语音模型的综合测试显示，模型在不同语音场景下表现出显著差异，且查询感知评估能提供更细致的评估，为语音模型的开发和评估提供了宝贵见解。", "keywords": "音频LLM, 基准测试, 语音对话, 查询感知评估, WildSpeech-Bench", "comments": "该论文通过创建WildSpeech-Bench基准测试，解决了当前音频LLM评估中缺乏专业性和全面性的痛点。其创新之处在于系统地整合了真实世界语音对话数据、考虑了多样化的语音特性（如韵律、同音异义词、口吃）以及提出了查询感知评估方法，这些都弥补了现有文本基准测试的不足。这将对推动音频LLM在实际应用中的性能优化和用户体验提升具有重要意义。"}}
{"id": "2507.23677", "title": "Stereo 3D Gaussian Splatting SLAM for Outdoor Urban Scenes", "authors": ["Xiaohan Li", "Ziren Gong", "Fabio Tosi", "Matteo Poggi", "Stefano Mattoccia", "Dong Liu", "Jun Wu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23677v1", "summary": "3D Gaussian Splatting (3DGS) has recently gained popularity in SLAM\napplications due to its fast rendering and high-fidelity representation.\nHowever, existing 3DGS-SLAM systems have predominantly focused on indoor\nenvironments and relied on active depth sensors, leaving a gap for large-scale\noutdoor applications. We present BGS-SLAM, the first binocular 3D Gaussian\nSplatting SLAM system designed for outdoor scenarios. Our approach uses only\nRGB stereo pairs without requiring LiDAR or active sensors. BGS-SLAM leverages\ndepth estimates from pre-trained deep stereo networks to guide 3D Gaussian\noptimization with a multi-loss strategy enhancing both geometric consistency\nand visual quality. Experiments on multiple datasets demonstrate that BGS-SLAM\nachieves superior tracking accuracy and mapping performance compared to other\n3DGS-based solutions in complex outdoor environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23677v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "户外城市场景立体3D高斯泼溅SLAM", "tldr": "BGS-SLAM是首个针对户外场景设计的双目3D高斯泼溅SLAM系统，仅使用RGB立体图像，无需主动传感器，并在复杂户外环境中实现了卓越的跟踪精度和建图性能。", "motivation": "现有3D高斯泼溅SLAM系统主要集中在室内环境并依赖主动深度传感器，导致在大规模户外应用中存在空白。", "method": "本文提出了BGS-SLAM，一个双目3D高斯泼溅SLAM系统，专为户外场景设计。它仅使用RGB立体图像对，无需LiDAR或主动传感器。BGS-SLAM利用预训练的深度立体网络估计的深度来指导3D高斯优化，并采用多损失策略以增强几何一致性和视觉质量。", "result": "实验证明，BGS-SLAM在复杂户外环境中比其他基于3D高斯泼溅的解决方案实现了更优越的跟踪精度和建图性能。", "conclusion": "BGS-SLAM成功地将3D高斯泼溅SLAM应用于大规模户外场景，通过仅使用被动RGB立体图像对，克服了现有系统的局限性，展示了其在复杂环境下的强大性能。", "translation": "3D高斯泼溅（3DGS）因其快速渲染和高保真表示，最近在SLAM应用中获得了广泛关注。然而，现有的3DGS-SLAM系统主要集中在室内环境，并依赖主动深度传感器，这使得在大规模户外应用中存在空白。我们提出了BGS-SLAM，这是首个专为户外场景设计的双目3D高斯泼溅SLAM系统。我们的方法仅使用RGB立体图像对，无需LiDAR或主动传感器。BGS-SLAM利用预训练的深度立体网络估计的深度来指导3D高斯优化，并采用多损失策略以增强几何一致性和视觉质量。在多个数据集上的实验表明，BGS-SLAM在复杂户外环境中比其他基于3DGS的解决方案实现了更优越的跟踪精度和建图性能。", "summary": "本文介绍了BGS-SLAM，这是首个专为户外场景设计的双目3D高斯泼溅SLAM系统。它克服了现有3DGS-SLAM系统依赖主动传感器和局限于室内环境的限制，仅使用RGB立体图像对。BGS-SLAM利用深度立体网络估计的深度，并通过多损失策略优化3D高斯，以提升几何一致性和视觉质量。实验结果表明，该系统在复杂户外环境中实现了卓越的跟踪和建图性能。", "keywords": "3D高斯泼溅, SLAM, 立体视觉, 户外场景, 双目", "comments": "该论文的创新之处在于将3D高斯泼溅技术扩展到大规模户外SLAM应用，特别是通过仅使用被动RGB立体图像对，而无需昂贵的LiDAR或主动深度传感器。这大大拓宽了3DGS-SLAM的适用范围，并降低了硬件成本，对于推动该技术在实际户外场景中的部署具有重要意义。"}}
{"id": "2507.23449", "title": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "authors": ["Shervin Rahimzadeh Arashloo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23449v1", "summary": "We generalise the recently introduced large-margin $\\ell_p$-SVDD approach to\nexploit the geometry of data distribution via manifold regularising and a\nsignature kernel representation for time series anomaly detection.\nSpecifically, we formulate a manifold-regularised variant of the $\\ell_p$-SVDD\nmethod to encourage label smoothness on the underlying manifold to capture\nstructural information for improved detection performance. Drawing on an\nexisting Representer theorem, we then provide an effective optimisation\ntechnique for the proposed method and show that it can benefit from the\nsignature kernel to capture time series complexities for anomaly detection.\n  We theoretically study the proposed approach using Rademacher complexities to\nanalyse its generalisation performance and also provide an experimental\nassessment of the proposed method across various data sets to compare its\nperformance against other methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23449v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "流形正则化签名核大间隔$\\\\ell_p$-SVDD用于多维时间序列异常检测", "tldr": "该论文提出了一种流形正则化签名核大间隔$\\\\ell_p$-SVDD方法，用于多维时间序列异常检测。", "motivation": "为了通过流形正则化和签名核表示，利用数据分布的几何结构，改进时间序列异常检测，该研究推广了现有的大间隔$\\\\ell_p$-SVDD方法。", "method": "提出了一种流形正则化的$\\\\ell_p$-SVDD变体，以促进底层流形上的标签平滑性，从而捕获结构信息。利用签名核来捕捉时间序列的复杂性。基于现有表示定理，提供了一种有效的优化技术。", "result": "提高了检测性能。利用签名核有效捕捉时间序列复杂性。通过Rademacher复杂度理论分析了其泛化性能。在各种数据集上进行了实验评估，并与其他方法进行了性能比较。", "conclusion": "提出的流形正则化签名核$\\\\ell_p$-SVDD方法通过利用数据几何和时间序列复杂性，提高了时间序列异常检测能力，并具有良好的泛化性能。", "translation": "我们推广了最近提出的大间隔$\\\\ell_p$-SVDD方法，通过流形正则化和签名核表示来利用数据分布的几何结构，用于时间序列异常检测。具体来说，我们构建了一个流形正则化的$\\\\ell_p$-SVDD方法变体，以鼓励底层流形上的标签平滑性，从而捕获结构信息以提高检测性能。借鉴现有的表示定理，我们为所提出的方法提供了一种有效的优化技术，并表明它可以受益于签名核来捕捉时间序列的复杂性以进行异常检测。我们使用Rademacher复杂度理论研究了所提出方法的泛化性能，并在各种数据集上对其进行了实验评估，以比较其与其他方法的性能。", "summary": "本文通过引入流形正则化和签名核，扩展了大间隔$\\\\ell_p$-SVDD方法，以改进多维时间序列异常检测。流形正则化促进标签平滑性以捕获结构信息，而签名核处理时间序列的复杂性。作者提供了一种有效的优化技术，使用Rademacher复杂度理论分析了其泛化性能，并在各种数据集上通过实验验证了其相对于其他方法的有效性。", "keywords": "流形正则化, 签名核, $\\\\ell_p$-SVDD, 异常检测, 时间序列", "comments": "该论文的创新在于将流形正则化与大间隔$\\\\ell_p$-SVDD相结合，并整合了签名核。这种方法有效地解决了数据几何结构和时间序列固有复杂性这两个关键问题，对于鲁棒的异常检测至关重要。使用Rademacher复杂度进行的理论分析为该方法的泛化能力奠定了坚实的基础。"}}
{"id": "2507.23065", "title": "Diffusion model for gradient preconditioning in hyperspectral imaging inverse problems", "authors": ["Jonathan Monsalve", "Kumar Vijay Mishra"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23065v1", "summary": "Recovering high-dimensional statistical structure from limited measurements\nis a fundamental challenge in hyperspectral imaging, where capturing\nfull-resolution data is often infeasible due to sensor, bandwidth, or\nacquisition constraints. A common workaround is to partition measurements and\nestimate local statistics-such as the covariance matrix-using only partial\nobservations. However, this strategy introduces noise in the optimization\ngradients, especially when each partition contains few samples. In this work,\nwe reinterpret this accumulation of gradient noise as a diffusion process,\nwhere successive partitions inject increasing uncertainty into the learning\nsignal. Building on this insight, we propose a novel framework that leverages\ndenoising diffusion models to learn a reverse process in gradient space. The\nmodel is trained to map noisy gradient estimates toward clean, well-conditioned\nupdates, effectively preconditioning the optimization. Our approach bridges\ngenerative modeling and inverse problem solving, improving convergence and\nreconstruction quality under aggressive sampling regimes. We validate our\nmethod on hyperspectral recovery tasks, demonstrating significant gains in\naccuracy and stability over traditional optimization pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23065v1", "cate": "eess.IV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "用于高光谱成像逆问题中梯度预处理的扩散模型", "tldr": "本文提出了一种利用去噪扩散模型对高光谱成像逆问题中的梯度噪声进行预处理的新框架，显著提高了重建精度和稳定性。", "motivation": "在高光谱成像中，由于传感器、带宽或采集限制，获取全分辨率数据通常不可行。常用的方法是分区测量并估计局部统计量，但这会在优化梯度中引入噪声，尤其是在每个分区样本量较少时。本文旨在解决这种梯度噪声问题。", "method": "作者将梯度噪声的累积重新解释为一个扩散过程。在此基础上，提出了一种新颖的框架，利用去噪扩散模型在梯度空间中学习一个逆过程。该模型被训练用于将噪声梯度估计映射到干净、条件良好的更新，从而有效地预处理优化过程。", "result": "该方法在高光谱恢复任务中得到了验证，在激进采样条件下显著提高了收敛性和重建质量。与传统优化流程相比，该方法在精度和稳定性方面取得了显著提升。", "conclusion": "通过将生成模型与逆问题求解相结合，所提出的基于扩散模型的梯度预处理方法在高光谱成像逆问题中有效降低了梯度噪声，并显著提高了重建性能。", "translation": "从有限测量中恢复高维统计结构是高光谱成像中的一个基本挑战，因为受限于传感器、带宽或采集，捕获全分辨率数据通常是不可行的。一种常见的解决方案是划分测量并仅使用部分观测值来估计局部统计量（例如协方差矩阵）。然而，这种策略会在优化梯度中引入噪声，尤其是在每个分区包含少量样本时。在这项工作中，我们将这种梯度噪声的累积重新解释为一个扩散过程，其中连续的分区向学习信号注入了越来越多的不确定性。基于这一见解，我们提出了一种新颖的框架，该框架利用去噪扩散模型来学习梯度空间中的逆过程。该模型经过训练，可以将噪声梯度估计映射到干净、条件良好的更新，从而有效地预处理优化。我们的方法弥合了生成建模和逆问题求解之间的鸿沟，在激进采样机制下提高了收敛性和重建质量。我们在高光谱恢复任务上验证了我们的方法，与传统优化流程相比，在精度和稳定性方面展示了显著的提升。", "summary": "本文针对高光谱成像逆问题中有限测量导致的梯度噪声问题，提出了一种新颖的扩散模型预处理框架。该框架将梯度噪声视为扩散过程，并利用去噪扩散模型在梯度空间中学习一个逆过程，将噪声梯度估计转换为干净、条件良好的更新。实验证明，该方法显著提升了高光谱恢复任务的收敛性、重建质量、精度和稳定性。", "keywords": "扩散模型, 梯度预处理, 高光谱成像, 逆问题, 去噪", "comments": "该论文的创新之处在于将梯度噪声的累积类比为扩散过程，并创造性地引入去噪扩散模型来解决高光谱成像逆问题中的梯度预处理问题。这种将生成模型与传统逆问题求解相结合的方法，为在数据受限场景下提升优化效果提供了新的视角和有效方案，具有重要的理论和实践意义。"}}
{"id": "2507.23083", "title": "Context-aware Rotary Position Embedding", "authors": ["Ali Veisi", "Delaram Fartoot", "Hamidreza Amirzadeh"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      4 pages, 1 table", "url": "http://arxiv.org/abs/2507.23083v1", "summary": "Positional encoding is a vital component of Transformer architectures,\nenabling models to incorporate sequence order into self-attention mechanisms.\nRotary Positional Embeddings (RoPE) have become a widely adopted solution due\nto their compatibility with relative position encoding and computational\nefficiency. However, RoPE relies on static, input-independent sinusoidal\nfrequency patterns, limiting its ability to model context-sensitive\nrelationships. In this work, we propose CARoPE (Context-Aware Rotary Positional\nEmbedding), a novel generalization of RoPE that dynamically generates\nhead-specific frequency patterns conditioned on token embeddings. This design\nintroduces token- and context-sensitive positional representations while\npreserving RoPE efficiency and architectural simplicity. CARoPE computes\ninput-dependent phase shifts using a bounded transformation of token embeddings\nand integrates them into the rotary mechanism across attention heads. We\nevaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on\nnext-token prediction tasks. Experimental results show that CARoPE consistently\noutperforms RoPE and other common positional encoding baselines, achieving\nsignificantly lower perplexity, even at longer context lengths. Additionally,\nCARoPE enables faster training throughput without sacrificing model stability.\nThese findings demonstrate that CARoPE offers a scalable, expressive, and\nefficient upgrade to existing positional encoding strategies in Transformer\nmodels.", "comment": "4 pages, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.23083v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "上下文感知旋转位置编码", "tldr": "提出CARoPE，一种新的上下文感知旋转位置编码，通过动态生成频率模式并引入输入依赖的相位偏移，显著优于RoPE，在Transformer模型中提供更高效、表达力更强的定位。", "motivation": "现有的旋转位置编码（RoPE）依赖静态、与输入无关的正弦频率模式，限制了其建模上下文敏感关系的能力。", "method": "提出CARoPE，通过对token嵌入进行有界变换，动态生成头特异性频率模式并计算输入依赖的相位偏移，将其整合到旋转机制中，从而实现token和上下文敏感的位置表示，同时保持RoPE的效率和架构简洁性。", "result": "CARoPE在FineWeb-Edu-10B数据集上，使用GPT-2变体进行下一词预测任务的实验结果表明，它始终优于RoPE和其他常见的位置编码基线，即使在更长的上下文长度下也能实现显著更低的困惑度。此外，CARoPE还能在不牺牲模型稳定性的情况下实现更快的训练吞吐量。", "conclusion": "这些发现表明，CARoPE为Transformer模型中现有的位置编码策略提供了可扩展、表达力强且高效的升级。", "translation": "位置编码是Transformer架构的重要组成部分，使模型能够将序列顺序整合到自注意力机制中。旋转位置嵌入（RoPE）因其与相对位置编码的兼容性和计算效率而成为一种广泛采用的解决方案。然而，RoPE依赖于静态的、与输入无关的正弦频率模式，这限制了其建模上下文敏感关系的能力。在这项工作中，我们提出了CARoPE（上下文感知旋转位置嵌入），它是RoPE的一种新颖泛化，它根据token嵌入动态生成头特异性频率模式。这种设计引入了token和上下文敏感的位置表示，同时保留了RoPE的效率和架构简洁性。CARoPE使用token嵌入的有界变换计算输入依赖的相位偏移，并将其整合到跨注意力头的旋转机制中。我们在FineWeb-Edu-10B数据集上，使用在下一词预测任务上训练的GPT-2变体评估了CARoPE。实验结果表明，CARoPE始终优于RoPE和其他常见的位置编码基线，即使在更长的上下文长度下也能实现显著更低的困惑度。此外，CARoPE还能在不牺牲模型稳定性的情况下实现更快的训练吞吐量。这些发现表明，CARoPE为Transformer模型中现有的位置编码策略提供了可扩展、表达力强且高效的升级。", "summary": "这项工作提出了CARoPE（上下文感知旋转位置嵌入），它是RoPE的一种新颖泛化，旨在解决RoPE在建模上下文敏感关系方面的局限性。CARoPE通过动态生成头特异性频率模式并利用token嵌入计算输入依赖的相位偏移，从而实现上下文敏感的位置表示。实验结果表明，CARoPE在下一词预测任务中显著优于RoPE和其他基线，降低了困惑度并提高了训练吞吐量，证明了其作为Transformer模型中位置编码策略的可扩展、表达力强且高效的升级。", "keywords": "上下文感知, 旋转位置编码, Transformer, 位置嵌入, 深度学习", "comments": "这篇论文的创新点在于提出了上下文感知的旋转位置编码CARoPE，解决了传统RoPE静态频率模式的局限性。通过引入动态、输入依赖的频率模式和相位偏移，CARoPE使得位置编码能够更好地适应上下文，从而提升了Transformer模型的性能。其在保持RoPE效率和简洁性的同时，实现了显著的性能提升，尤其是在长上下文场景下，这对于大型语言模型的发展具有重要意义。"}}
{"id": "2507.23128", "title": "Evaluating and Improving the Robustness of Speech Command Recognition Models to Noise and Distribution Shifts", "authors": ["Anaïs Baranger", "Lucas Maison"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to ICASSP 2026", "url": "http://arxiv.org/abs/2507.23128v1", "summary": "Although prior work in computer vision has shown strong correlations between\nin-distribution (ID) and out-of-distribution (OOD) accuracies, such\nrelationships remain underexplored in audio-based models. In this study, we\ninvestigate how training conditions and input features affect the robustness\nand generalization abilities of spoken keyword classifiers under OOD\nconditions. We benchmark several neural architectures across a variety of\nevaluation sets. To quantify the impact of noise on generalization, we make use\nof two metrics: Fairness (F), which measures overall accuracy gains compared to\na baseline model, and Robustness (R), which assesses the convergence between ID\nand OOD performance. Our results suggest that noise-aware training improves\nrobustness in some configurations. These findings shed new light on the\nbenefits and limitations of noise-based augmentation for generalization in\nspeech models.", "comment": "Submitted to ICASSP 2026", "pdf_url": "http://arxiv.org/pdf/2507.23128v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "评估和改进语音命令识别模型对噪声和分布变化的鲁棒性", "tldr": "本研究探讨了训练条件和输入特征如何影响语音关键词分类器在OOD条件下的鲁棒性和泛化能力，并发现噪声感知训练在某些配置下能提高鲁棒性。", "motivation": "计算机视觉领域的研究表明，同分布(ID)和异分布(OOD)准确性之间存在很强的相关性，但在基于音频的模型中，这种关系尚未得到充分探索。", "method": "研究人员调查了训练条件和输入特征如何影响语音关键词分类器在OOD条件下的鲁棒性和泛化能力。他们基准测试了几种神经网络架构，并使用了公平性(F)和鲁棒性(R)两个指标来量化噪声对泛化的影响。", "result": "结果表明，噪声感知训练在某些配置下可以提高鲁棒性。", "conclusion": "这些发现为基于噪声的增强在语音模型泛化中的益处和局限性提供了新的见解。", "translation": "尽管计算机视觉领域的先前工作已显示同分布 (ID) 和异分布 (OOD) 准确性之间存在很强的相关性，但这种关系在基于音频的模型中仍未得到充分探索。在本研究中，我们调查了训练条件和输入特征如何影响语音关键词分类器在 OOD 条件下的鲁棒性和泛化能力。我们对各种评估集上的几种神经网络架构进行了基准测试。为了量化噪声对泛化的影响，我们使用了两个指标：公平性 (F)，它衡量与基线模型相比的整体准确性增益；以及鲁棒性 (R)，它评估 ID 和 OOD 性能之间的收敛性。我们的结果表明，噪声感知训练在某些配置下可以提高鲁棒性。这些发现为基于噪声的增强在语音模型泛化中的益处和局限性提供了新的见解。", "summary": "本研究旨在探讨训练条件和输入特征对语音关键词分类器在异分布（OOD）条件下的鲁棒性和泛化能力的影响，以填补音频模型中ID和OOD准确性相关性研究的空白。研究人员通过基准测试多种神经网络架构，并引入公平性和鲁棒性指标来量化噪声影响。结果显示，噪声感知训练在特定配置下能提升模型鲁棒性，为语音模型中基于噪声的增强提供了新的理解。", "keywords": "语音命令识别, 鲁棒性, 分布变化, 噪声感知训练, 泛化", "comments": "本研究的创新点在于首次深入探讨了音频模型中同分布与异分布准确性之间的关系，并引入了量化噪声影响的特定指标。其重要性在于为提高语音命令识别模型在复杂现实环境中的鲁棒性提供了实证依据和指导。"}}
{"id": "2507.07695", "title": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities", "authors": ["Hruday Markondapatnaikuni", "Basem Suleiman", "Abdelkarim Erradi", "Shijing Chen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      21 pages, 14 figures", "url": "http://arxiv.org/abs/2507.07695v2", "summary": "Fine-tuning is an immensely resource-intensive process when retraining Large\nLanguage Models (LLMs) to incorporate a larger body of knowledge. Although many\nfine-tuning techniques have been developed to reduce the time and computational\ncost involved, the challenge persists as LLMs continue to grow in size and\ncomplexity. To address this, a new approach to knowledge expansion in LLMs is\nneeded. Retrieval-Augmented Generation (RAG) offers one such alternative by\nstoring external knowledge in a database and retrieving relevant chunks to\nsupport question answering. However, naive implementations of RAG face\nsignificant limitations in scalability and answer accuracy. This paper\nintroduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome\nthese limitations. Inspired by the divide-and-conquer paradigm, K2RAG\nintegrates dense and sparse vector search, knowledge graphs, and text\nsummarization to improve retrieval quality and system efficiency. The framework\nalso includes a preprocessing step that summarizes the training data,\nsignificantly reducing the training time. K2RAG was evaluated using the\nMultiHopRAG dataset, where the proposed pipeline was trained on the document\ncorpus and tested on a separate evaluation set. Results demonstrated notable\nimprovements over common naive RAG implementations. K2RAG achieved the highest\nmean answer similarity score of 0.57, and reached the highest third quartile\n(Q3) similarity of 0.82, indicating better alignment with ground-truth answers.\nIn addition to improved accuracy, the framework proved highly efficient. The\nsummarization step reduced the average training time of individual components\nby 93%, and execution speed was up to 40% faster than traditional knowledge\ngraph-based RAG systems. K2RAG also demonstrated superior scalability,\nrequiring three times less VRAM than several naive RAG implementations tested\nin this study.", "comment": "21 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.07695v2", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "KeyKnowledgeRAG (K^2RAG): 一种增强的RAG方法，用于改进LLM问答能力", "tldr": "K2RAG通过结合多种搜索技术和数据预处理，显著提升了LLM的问答准确性、效率和可扩展性，超越了传统RAG方法。", "motivation": "微调大型语言模型以扩展知识是一个资源密集型过程，且随着模型规模和复杂性增加，挑战持续存在。朴素的检索增强生成（RAG）实现存在可扩展性和答案准确性方面的显著限制。因此，需要一种新的LLM知识扩展方法来解决这些问题。", "method": "本文提出了KeyKnowledgeRAG (K2RAG) 框架，其灵感来源于分而治之范式。K2RAG集成了密集和稀疏向量搜索、知识图谱和文本摘要技术，以提高检索质量和系统效率。该框架还包括一个预处理步骤，用于摘要训练数据，以显著减少训练时间。K2RAG使用MultiHopRAG数据集进行评估，并在文档语料库上进行训练和测试。", "result": "K2RAG在MultiHopRAG数据集上取得了显著改进。它实现了最高的平均答案相似度分数0.57，以及最高的第三四分位数（Q3）相似度0.82，表明与真实答案更好地对齐。摘要步骤使单个组件的平均训练时间减少了93%，执行速度比传统的基于知识图谱的RAG系统快40%。此外，K2RAG所需的VRAM比朴素RAG实现减少了三倍，展示了卓越的可扩展性。", "conclusion": "K2RAG通过克服朴素RAG的局限性，显著提高了大型语言模型问答能力的准确性、效率和可扩展性，提供了一种更优的知识扩展方法。", "translation": "当重新训练大型语言模型（LLM）以整合更大规模的知识时，微调是一个极其耗费资源的过程。尽管已经开发了许多微调技术来减少所涉及的时间和计算成本，但随着LLM规模和复杂性的持续增长，这一挑战依然存在。为了解决这个问题，需要一种新的LLM知识扩展方法。检索增强生成（RAG）提供了一种这样的替代方案，它将外部知识存储在数据库中，并检索相关块以支持问答。然而，RAG的朴素实现面临可扩展性和答案准确性方面的显著限制。本文介绍了KeyKnowledgeRAG（K2RAG），一个旨在克服这些限制的新颖框架。受分而治之范式的启发，K2RAG集成了密集和稀疏向量搜索、知识图谱和文本摘要，以提高检索质量和系统效率。该框架还包括一个预处理步骤，该步骤对训练数据进行摘要，显著减少了训练时间。K2RAG使用MultiHopRAG数据集进行评估，其中所提出的管道在文档语料库上进行训练，并在一个单独的评估集上进行测试。结果表明，与常见的朴素RAG实现相比，K2RAG取得了显著改进。K2RAG实现了最高的平均答案相似度分数0.57，并达到了最高的第三四分位数（Q3）相似度0.82，表明与真实答案更好地对齐。除了提高准确性外，该框架还被证明是高效的。摘要步骤使单个组件的平均训练时间减少了93%，执行速度比传统的基于知识图谱的RAG系统快40%。K2RAG还展示了卓越的可扩展性，与本研究中测试的几种朴素RAG实现相比，所需的VRAM减少了三倍。", "summary": "本文提出KeyKnowledgeRAG (K2RAG)，一个旨在解决LLM知识扩展中微调资源消耗大以及朴素RAG在可扩展性和准确性方面局限性的新颖框架。K2RAG结合了密集和稀疏向量搜索、知识图谱及文本摘要，并通过数据预处理显著减少训练时间。在MultiHopRAG数据集上的评估显示，K2RAG在答案相似度、训练效率、执行速度和VRAM消耗上均显著优于传统RAG实现，证明了其在提升LLM问答能力方面的有效性。", "keywords": "检索增强生成, 大型语言模型, 知识图谱, 向量搜索, 文本摘要", "comments": "这项工作通过结合多种先进技术（密集/稀疏向量搜索、知识图谱、文本摘要）并引入创新的数据预处理步骤，显著提升了RAG系统的性能。其在准确性、效率和可扩展性方面的改进，特别是训练时间的大幅缩减和VRAM需求的降低，对于大规模LLM应用具有重要意义，提供了一个更高效、更可行的知识扩展方案，避免了昂贵的微调。"}}
{"id": "2507.23268", "title": "PixNerd: Pixel Neural Field Diffusion", "authors": ["Shuai Wang", "Ziteng Gao", "Chenhui Zhu", "Weilin Huang", "Limin Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      a single-scale, single-stage, efficient, end-to-end pixel space diffusion model", "url": "http://arxiv.org/abs/2507.23268v1", "summary": "The current success of diffusion transformers heavily depends on the\ncompressed latent space shaped by the pre-trained variational autoencoder(VAE).\nHowever, this two-stage training paradigm inevitably introduces accumulated\nerrors and decoding artifacts. To address the aforementioned problems,\nresearchers return to pixel space at the cost of complicated cascade pipelines\nand increased token complexity. In contrast to their efforts, we propose to\nmodel the patch-wise decoding with neural field and present a single-scale,\nsingle-stage, efficient, end-to-end solution, coined as pixel neural field\ndiffusion~(PixelNerd). Thanks to the efficient neural field representation in\nPixNerd, we directly achieved 2.15 FID on ImageNet $256\\times256$ and 2.84 FID\non ImageNet $512\\times512$ without any complex cascade pipeline or VAE. We also\nextend our PixNerd framework to text-to-image applications. Our PixNerd-XXL/16\nachieved a competitive 0.73 overall score on the GenEval benchmark and 80.9\noverall score on the DPG benchmark.", "comment": "a single-scale, single-stage, efficient, end-to-end pixel space\n  diffusion model", "pdf_url": "http://arxiv.org/pdf/2507.23268v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "PixNerd：像素神经场扩散", "tldr": "PixNerd提出了一种基于神经场的单阶段像素级扩散模型，直接在像素空间生成图像，避免了传统VAE-based扩散模型中的误差累积和解码伪影，并在ImageNet和文生图任务上取得了有竞争力的结果。", "motivation": "当前的扩散Transformer模型依赖于预训练的变分自编码器（VAE）形成的压缩潜在空间，但这种两阶段训练范式会导致误差累积和解码伪影。为了解决这些问题，研究人员转向像素空间，但这又引入了复杂的级联管道和更高的token复杂度。", "method": "我们提出了PixNerd（像素神经场扩散），一种通过神经场对块级解码进行建模的方法。它是一个单尺度、单阶段、高效的端到端解决方案，直接在像素空间进行扩散，无需复杂的级联管道或VAE。", "result": "PixNerd在ImageNet 256x256上实现了2.15 FID，在ImageNet 512x512上实现了2.84 FID。在文生图应用中，PixNerd-XXL/16在GenEval基准测试中获得了0.73的综合得分，在DPG基准测试中获得了80.9的综合得分。", "conclusion": "PixNerd提供了一种高效的、单阶段的像素级扩散模型，成功解决了传统扩散模型中潜在空间和像素空间方法所面临的问题，并在图像生成和文生图任务上展现出卓越的性能。", "translation": "当前扩散Transformer的成功严重依赖于预训练变分自编码器（VAE）所形成的压缩潜在空间。然而，这种两阶段训练范式不可避免地引入了累积误差和解码伪影。为了解决上述问题，研究人员以复杂的级联管道和增加的token复杂性为代价，回到了像素空间。与他们的努力相反，我们提出使用神经场对块级解码进行建模，并提出了一种单尺度、单阶段、高效的端到端解决方案，命名为像素神经场扩散（PixelNerd）。得益于PixNerd中高效的神经场表示，我们直接在ImageNet 256x256上实现了2.15 FID，在ImageNet 512x512上实现了2.84 FID，无需任何复杂的级联管道或VAE。我们还将PixNerd框架扩展到文本到图像应用。我们的PixNerd-XXL/16在GenEval基准测试中取得了0.73的竞争力总分，在DPG基准测试中取得了80.9的总分。", "summary": "PixNerd提出了一种创新的像素神经场扩散模型，旨在解决传统扩散模型中由VAE引入的两阶段训练误差和像素空间级联管道复杂性问题。通过利用神经场进行块级解码，PixNerd实现了单尺度、单阶段、高效的端到端图像生成。该方法直接在像素空间操作，无需VAE或复杂管道，在ImageNet 256x256和512x512上分别达到了2.15和2.84的FID分数。此外，PixNerd还成功应用于文本到图像生成，在GenEval和DPG基准测试中取得了有竞争力的表现。", "keywords": "像素神经场, 扩散模型, 图像生成, 单阶段, 神经场", "comments": "PixNerd的创新之处在于其采用神经场直接在像素空间进行扩散建模，从而避免了传统VAE两阶段训练带来的误差累积和解码伪影。其单阶段、端到端的设计显著简化了扩散模型的训练和推理过程，提高了效率。在性能上，直接在像素空间取得如此高的FID分数是其重要性体现，尤其是在无需复杂级联管道的情况下。这为未来高效、高质量的图像生成模型提供了新的方向。"}}
{"id": "2507.23382", "title": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "authors": ["Yiyan Ji", "Haoran Chen", "Qiguang Chen", "Chengyue Wu", "Libo Qin", "Wanxiang Che"], "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.8; I.2.10"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.23382v1", "summary": "Multimodal planning capabilities refer to the ability to predict, reason, and\ndesign steps for task execution with multimodal context, which is essential for\ncomplex reasoning and decision-making across multiple steps. However, current\nbenchmarks face two key challenges: (1) they cannot directly assess multimodal\nreal-world planning capabilities, and (2) they lack constraints or implicit\nconstraints across modalities. To address these issues, we introduce Multimodal\nPlanning with Complex Constraints (MPCC), the first benchmark to systematically\nevaluate MLLMs' ability to handle multimodal constraints in planning. To\naddress the first challenge, MPCC focuses on three real-world tasks: Flight\nPlanning, Calendar Planning, and Meeting Planning. To solve the second\nchallenge, we introduce complex constraints (e.g. budget, temporal, and\nspatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to\nseparate constraint complexity from search space expansion. Experiments on 13\nadvanced MLLMs reveal significant challenges: closed-source models achieve only\n21.3% feasible plans, while open-source models average below 11%. Additionally,\nwe observe that MLLMs are highly sensitive to constraint complexity and that\ntraditional multimodal prompting strategies fail in multi-constraint scenarios.\nOur work formalizes multimodal constraints in planning, provides a rigorous\nevaluation framework, and highlights the need for advancements in\nconstraint-aware reasoning for real-world MLLM applications.", "comment": "Accepted to ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.23382v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MPCC：多模态大语言模型中复杂约束下的多模态规划新型基准", "tldr": "MPCC是一个新的基准测试，用于评估多模态大语言模型在多模态规划中处理复杂约束的能力，实验结果显示现有模型表现不佳。", "motivation": "当前的多模态规划基准无法直接评估多模态真实世界规划能力，且缺乏跨模态的显式或隐式约束，这限制了对复杂推理和决策能力的评估。", "method": "研究引入了多模态复杂约束规划（MPCC）基准，这是第一个系统评估MLLM处理多模态规划中约束能力的基准。MPCC关注飞行规划、日历规划和会议规划三个真实世界任务，并引入了预算、时间、空间等复杂约束，设置了EASY、MEDIUM、HARD等难度等级来区分约束复杂度和搜索空间扩展。", "result": "对13个先进MLLM的实验表明，闭源模型仅实现了21.3%的可行计划，而开源模型平均低于11%。此外，MLLM对约束复杂性高度敏感，传统的提示策略在多约束场景下表现不佳。", "conclusion": "本工作形式化了规划中的多模态约束，提供了一个严格的评估框架，并强调了真实世界MLLM应用中约束感知推理能力提升的必要性。", "translation": "多模态规划能力是指在多模态语境下预测、推理和设计任务执行步骤的能力，这对于跨多个步骤的复杂推理和决策至关重要。然而，当前的基准面临两大挑战：(1) 它们无法直接评估多模态真实世界规划能力；(2) 它们缺乏跨模态的约束或隐式约束。为了解决这些问题，我们引入了多模态复杂约束规划（MPCC），这是第一个系统评估多模态大语言模型（MLLM）处理规划中多模态约束能力的基准。为了解决第一个挑战，MPCC专注于三个真实世界任务：飞行规划、日历规划和会议规划。为了解决第二个挑战，我们在这些任务中引入了复杂约束（例如预算、时间、空间），并设置了分级难度（EASY、MEDIUM、HARD）以将约束复杂性与搜索空间扩展区分开来。对13个先进MLLM的实验揭示了显著的挑战：闭源模型仅实现了21.3%的可行计划，而开源模型平均低于11%。此外，我们观察到MLLM对约束复杂性高度敏感，并且传统的多模态提示策略在多约束场景下会失效。我们的工作形式化了规划中的多模态约束，提供了一个严格的评估框架，并强调了真实世界MLLM应用中约束感知推理能力提升的必要性。", "summary": "本文提出了MPCC，一个用于评估多模态大语言模型（MLLMs）在复杂约束下进行多模态规划的新型基准。针对现有基准无法评估真实世界规划能力和缺乏跨模态约束的问题，MPCC设计了飞行、日历和会议规划等真实任务，并引入了预算、时间、空间等多种复杂约束，分为不同难度等级。实验结果显示，当前最先进的MLLMs在处理复杂约束时表现不佳，闭源模型可行计划率仅21.3%，开源模型更低，且模型对约束复杂性高度敏感。研究强调了未来MLLM需要增强约束感知推理能力。", "keywords": "多模态规划, 复杂约束, MLLM, 基准, 真实世界任务", "comments": "MPCC基准的创新之处在于其首次系统地将复杂的多模态约束引入到规划任务中，并设计了分级难度，有效区分了约束复杂性与搜索空间大小对模型性能的影响。这对于推动MLLM在真实世界复杂决策场景中的发展具有重要意义。实验结果揭示了当前MLLMs在处理多约束条件下的显著局限性，为未来研究指明了方向，即需要开发更强大的约束感知推理能力。"}}
{"id": "2402.01124", "title": "TransFR: Transferable Federated Recommendation with Adapter Tuning on Pre-trained Language Models", "authors": ["Honglei Zhang", "Zhiwei Li", "Haoxuan Li", "Xin Zhou", "Jie Zhang", "Yidong Li"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.01124v2", "summary": "Federated recommendations (FRs), facilitating multiple local clients to\ncollectively learn a global model without disclosing user private data, have\nemerged as a prevalent on-device service. In conventional FRs, a dominant\nparadigm is to utilize discrete identities to represent clients and items,\nwhich are then mapped to domain-specific embeddings to participate in model\ntraining. Despite considerable performance, we reveal three inherent\nlimitations that can not be ignored in federated settings, i.e.,\nnon-transferability across domains, ineffectiveness in cold-start settings, and\npotential privacy violations during federated training. To this end, we propose\na transferable federated recommendation model, TransFR, which delicately\nincorporates the general capabilities empowered by pre-trained models and the\npersonalized abilities by fine-tuning local private data. Specifically, it\nfirst learns domain-agnostic representations of items by exploiting pre-trained\nmodels with public textual corpora. To tailor for FR tasks, we further\nintroduce efficient federated adapter-tuning and test-time adaptation\nmechanisms, which facilitate personalized local adapters for each client by\nfitting their private data distributions. We theoretically prove the advantages\nof incorporating adapter tuning in FRs regarding both effectiveness and\nprivacy. Through extensive experiments, we show that our TransFR model\nsurpasses several state-of-the-art FRs on transferability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.01124v2", "cate": "cs.IR", "date": "2024-02-02", "updated": "2025-07-31", "AI": {"title_translation": "TransFR: 基于预训练语言模型适配器调优的可迁移联邦推荐", "tldr": "TransFR提出了一种新的联邦推荐模型，通过结合预训练模型和适配器调优来解决传统联邦推荐中存在的不可迁移性、冷启动问题和隐私泄露问题，并在迁移性方面超越了现有SOTA模型。", "motivation": "传统联邦推荐（FR）模型使用离散身份来表示客户端和物品，并映射到特定领域嵌入进行训练。然而，这种范式存在三个固有限制：跨域不可迁移性、冷启动设置下的低效性以及联邦训练期间潜在的隐私侵犯。", "method": "我们提出了TransFR模型，它将预训练模型的通用能力与通过微调本地私有数据获得的个性化能力相结合。具体来说，TransFR首先利用预训练模型和公共文本语料库学习物品的领域无关表示。为了适应FR任务，我们进一步引入了高效的联邦适配器调优和测试时自适应机制，通过拟合每个客户端的私有数据分布来为它们生成个性化的本地适配器。", "result": "通过广泛的实验，我们证明了TransFR模型在可迁移性方面超越了几个最先进的联邦推荐模型。", "conclusion": "理论上证明了在联邦推荐中引入适配器调优在有效性和隐私方面的优势，并通过实验验证了TransFR在可迁移性上的卓越性能。", "translation": "联邦推荐（FR）作为一种流行的设备端服务，旨在促进多个本地客户端在不泄露用户私有数据的情况下共同学习一个全局模型。在传统的FR中，主导范式是利用离散身份来表示客户端和物品，然后将其映射到特定领域嵌入以参与模型训练。尽管性能可观，但我们揭示了在联邦设置中不能忽视的三个固有限制，即跨域不可迁移性、冷启动设置下的低效性以及联邦训练期间潜在的隐私侵犯。为此，我们提出了一种可迁移的联邦推荐模型TransFR，它巧妙地结合了预训练模型所赋予的通用能力和通过微调本地私有数据获得的个性化能力。具体来说，它首先通过利用带有公共文本语料库的预训练模型来学习物品的领域无关表示。为了适应FR任务，我们进一步引入了高效的联邦适配器调优和测试时自适应机制，这有助于通过拟合每个客户端的私有数据分布来为每个客户端提供个性化的本地适配器。我们从有效性和隐私两方面理论上证明了在FR中引入适配器调优的优势。通过广泛的实验，我们表明我们的TransFR模型在可迁移性方面超越了几个最先进的FR模型。", "summary": "TransFR是一种新型联邦推荐模型，旨在解决传统联邦推荐中存在的跨域不可迁移性、冷启动问题和隐私泄露问题。它通过利用预训练模型学习物品的领域无关表示，并结合联邦适配器调优和测试时自适应机制，为每个客户端生成个性化适配器。该方法在理论上证明了其在有效性和隐私方面的优势，并在实验中展现出优于现有最先进联邦推荐模型的可迁移性。", "keywords": "联邦推荐, 适配器调优, 预训练语言模型, 可迁移性, 冷启动", "comments": "TransFR的创新之处在于将预训练语言模型的通用能力与联邦推荐的个性化需求相结合，特别是引入了适配器调优和测试时自适应机制，这不仅提升了模型在跨域和冷启动场景下的性能，也兼顾了隐私保护。这种结合预训练大模型与联邦学习的思路，为未来联邦推荐系统提供了新的研究方向和解决方案，具有重要的实用价值。"}}
{"id": "2507.07675", "title": "Some Theoretical Results on Layerwise Effective Dimension Oscillations in Finite Width ReLU Networks", "authors": ["Darshan Makwana"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Incomplete citations", "url": "http://arxiv.org/abs/2507.07675v2", "summary": "We analyze the layerwise effective dimension (rank of the feature matrix) in\nfully-connected ReLU networks of finite width. Specifically, for a fixed batch\nof $m$ inputs and random Gaussian weights, we derive closed-form expressions\nfor the expected rank of the \\$m\\times n\\$ hidden activation matrices. Our main\nresult shows that $\\mathbb{E}[EDim(\\ell)]=m[1-(1-2/\\pi)^\\ell]+O(e^{-c m})$ so\nthat the rank deficit decays geometrically with ratio $1-2 / \\pi \\approx\n0.3634$. We also prove a sub-Gaussian concentration bound, and identify the\n\"revival\" depths at which the expected rank attains local maxima. In\nparticular, these peaks occur at depths\n$\\ell_k^*\\approx(k+1/2)\\pi/\\log(1/\\rho)$ with height $\\approx (1-e^{-\\pi/2}) m\n\\approx 0.79m$. We further show that this oscillatory rank behavior is a\nfinite-width phenomenon: under orthogonal weight initialization or strong\nnegative-slope leaky-ReLU, the rank remains (nearly) full. These results\nprovide a precise characterization of how random ReLU layers alternately\ncollapse and partially revive the subspace of input variations, adding nuance\nto prior work on expressivity of deep networks.", "comment": "Incomplete citations", "pdf_url": "http://arxiv.org/pdf/2507.07675v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "有限宽度ReLU网络中层间有效维度振荡的一些理论结果", "tldr": "本文分析了有限宽度ReLU网络中层间有效维度的振荡行为，发现其期望秩几何衰减，并存在“复苏”深度。", "motivation": "本研究旨在精确刻画随机ReLU层如何交替地使输入变化子空间塌缩和部分复苏，从而为深度网络的表达能力提供更细致的理解。", "method": "本文对有限宽度全连接ReLU网络中层间有效维度（特征矩阵的秩）进行了分析。具体而言，针对固定批次的输入和随机高斯权重，推导了m×n隐藏激活矩阵期望秩的闭合形式表达式，并证明了亚高斯浓度界。", "result": "主要结果表明，期望有效维度E[EDim(ℓ)]=m[1-(1-2/π)ℓ]+O(e^(-cm))，秩亏损以1-2/π≈0.3634的比例几何衰减。同时，识别出期望秩达到局部最大值的“复苏”深度ℓk*≈(k+1/2)π/log(1/ρ)，其高度约为(1-e^(-π/2))m≈0.79m。此外，研究发现这种振荡的秩行为是有限宽度现象：在正交权重初始化或强负斜率Leaky-ReLU下，秩保持（接近）全秩。", "conclusion": "这些结果精确地刻画了随机ReLU层如何交替地使输入变化子空间塌缩和部分复苏，为先前关于深度网络表达能力的工作增加了新的细节和理解。", "translation": "我们分析了有限宽度全连接ReLU网络中层间有效维度（特征矩阵的秩）。具体而言，针对固定批次的m个输入和随机高斯权重，我们推导了m×n隐藏激活矩阵期望秩的闭合形式表达式。我们的主要结果表明，E[EDim(ℓ)]=m[1-(1-2/π)ℓ]+O(e^(-cm))，因此秩亏损以1-2/π≈0.3634的比例几何衰减。我们还证明了亚高斯浓度界，并识别出期望秩达到局部最大值的“复苏”深度。特别地，这些峰值出现在深度ℓk*≈(k+1/2)π/log(1/ρ)处，高度约为(1-e^(-π/2))m≈0.79m。我们进一步表明，这种振荡的秩行为是有限宽度现象：在正交权重初始化或强负斜率Leaky-ReLU下，秩保持（接近）全秩。这些结果精确地刻画了随机ReLU层如何交替地使输入变化子空间塌缩和部分复苏，为先前关于深度网络表达能力的工作增加了新的细节和理解。", "summary": "本文研究了有限宽度ReLU网络中层间有效维度（特征矩阵的秩）的理论特性。通过对固定批次输入和随机高斯权重的分析，推导了隐藏激活矩阵期望秩的闭合形式表达式。研究发现，期望有效维度随层深几何衰减，但会在特定“复苏”深度达到局部最大值。这种秩的振荡行为是有限宽度网络所特有的，在特定初始化或激活函数下可避免。这些发现为理解深度网络中信息流的动态变化及其表达能力提供了精确的量化。", "keywords": "ReLU网络, 有效维度, 秩衰减, 有限宽度, 神经网络表达能力", "comments": "这篇论文深入探讨了有限宽度ReLU网络中一个有趣的现象——层间有效维度的振荡。其创新之处在于提供了期望秩的闭合形式表达式和对“复苏”深度的识别，这为理解深度网络中信息如何随层深变化提供了量化视角。特别是，揭示了这种振荡是有限宽度网络的特性，而非普遍现象，并通过改变初始化或激活函数可以抑制。这对于设计更高效、表达能力更强的深度网络具有重要的理论指导意义。"}}
{"id": "2507.23143", "title": "X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention", "authors": ["Xiaochen Zhao", "Hongyi Xu", "Guoxian Song", "You Xie", "Chenxu Zhang", "Xiu Li", "Linjie Luo", "Jinli Suo", "Yebin Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICLR 2025, code is available at this https URL", "url": "http://arxiv.org/abs/2507.23143v1", "summary": "We propose X-NeMo, a novel zero-shot diffusion-based portrait animation\npipeline that animates a static portrait using facial movements from a driving\nvideo of a different individual. Our work first identifies the root causes of\nthe key issues in prior approaches, such as identity leakage and difficulty in\ncapturing subtle and extreme expressions. To address these challenges, we\nintroduce a fully end-to-end training framework that distills a 1D\nidentity-agnostic latent motion descriptor from driving image, effectively\ncontrolling motion through cross-attention during image generation. Our\nimplicit motion descriptor captures expressive facial motion in fine detail,\nlearned end-to-end from a diverse video dataset without reliance on pretrained\nmotion detectors. We further enhance expressiveness and disentangle motion\nlatents from identity cues by supervising their learning with a dual GAN\ndecoder, alongside spatial and color augmentations. By embedding the driving\nmotion into a 1D latent vector and controlling motion via cross-attention\nrather than additive spatial guidance, our design eliminates the transmission\nof spatial-aligned structural clues from the driving condition to the diffusion\nbackbone, substantially mitigating identity leakage. Extensive experiments\ndemonstrate that X-NeMo surpasses state-of-the-art baselines, producing highly\nexpressive animations with superior identity resemblance. Our code and models\nare available for research.", "comment": "ICLR 2025, code is available at\n  https://github.com/bytedance/x-nemo-inference", "pdf_url": "http://arxiv.org/pdf/2507.23143v1", "cate": "cs.CV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "X-NeMo：通过解耦潜在注意力实现富有表现力的神经运动重演", "tldr": "X-NeMo是一种零样本扩散模型，通过解耦的1D潜在运动描述符和交叉注意力，解决了肖像动画中的身份泄露和表情捕捉问题，生成了更具表现力和身份相似度的动画。", "motivation": "现有的肖像动画方法存在身份泄露和难以捕捉细微及极端表情的问题。", "method": "本文提出了X-NeMo，一个新颖的零样本扩散基肖像动画流水线。该方法通过从驱动图像中提取1D身份无关的潜在运动描述符，并在图像生成过程中通过交叉注意力有效控制运动。其隐式运动描述符能够捕捉精细的表达性面部运动，并从多样化的视频数据集中端到端学习，不依赖预训练的运动检测器。通过使用双GAN解码器以及空间和颜色增强来监督学习，进一步增强了表现力并解耦了运动潜在与身份线索。通过将驱动运动嵌入1D潜在向量并通过交叉注意力控制运动，而不是通过加性空间指导，该设计消除了从驱动条件到扩散骨干的空间对齐结构线索的传输，从而显著减轻了身份泄露。", "result": "X-NeMo在大量实验中超越了最先进的基线，生成了具有卓越身份相似度的高度表现力的动画。", "conclusion": "X-NeMo成功地解决了零样本肖像动画中身份泄露和难以捕捉细微及极端表情的关键问题，生成了高质量且身份相似度高的动画。", "translation": "我们提出了X-NeMo，一种新颖的零样本扩散基肖像动画流水线，它使用来自不同个体的驱动视频中的面部运动来动画化静态肖像。我们的工作首先识别了现有方法中关键问题的根本原因，例如身份泄露以及难以捕捉细微和极端表情。为了解决这些挑战，我们引入了一个完全端到端的训练框架，该框架从驱动图像中提取1D身份无关的潜在运动描述符，通过在图像生成过程中通过交叉注意力有效控制运动。我们的隐式运动描述符能够捕捉精细的表达性面部运动，并从多样化的视频数据集中端到端学习，不依赖预训练的运动检测器。我们通过使用双GAN解码器以及空间和颜色增强来监督它们的学习，进一步增强了表现力并解耦了运动潜在与身份线索。通过将驱动运动嵌入1D潜在向量并通过交叉注意力控制运动，而不是通过加性空间指导，我们的设计消除了从驱动条件到扩散骨干的空间对齐结构线索的传输，从而显著减轻了身份泄露。大量的实验表明，X-NeMo超越了最先进的基线，生成了高度表现力且具有卓越身份相似度的动画。我们的代码和模型可供研究使用。", "summary": "X-NeMo是一种新颖的零样本扩散基肖像动画流水线，旨在解决现有方法中存在的身份泄露和难以捕捉细微极端表情的问题。该方法通过引入一个端到端训练框架，从驱动图像中提取1D身份无关的潜在运动描述符，并利用交叉注意力在图像生成过程中精准控制运动。其创新的设计有效解耦了运动与身份信息，通过消除空间对齐结构线索的传输，显著减轻了身份泄露。实验证明，X-NeMo在生成具有高表现力和卓越身份相似度的动画方面超越了现有SOTA方法。", "keywords": "X-NeMo, 肖像动画, 扩散模型, 运动重演, 身份解耦", "comments": "X-NeMo的创新点在于其引入的1D身份无关潜在运动描述符和通过交叉注意力控制运动的机制，这显著缓解了零样本肖像动画中常见的身份泄露问题。其端到端学习方法，不依赖预训练运动检测器，也增强了其实用性和泛化能力。双GAN解码器和数据增强进一步提升了表情捕捉的精细度和表现力，是该领域的重要进展。"}}
{"id": "2505.19101", "title": "Agentic Visualization: Extracting Agent-based Design Patterns from Visualization Systems", "authors": ["Vaishali Dhanoa", "Anton Wolter", "Gabriela Molina León", "Hans-Jörg Schulz", "Niklas Elmqvist"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.19101v2", "summary": "Autonomous agents powered by Large Language Models are transforming AI,\ncreating an imperative for the visualization field to embrace agentic\nframeworks. However, our field's focus on a human in the sensemaking loop\nraises critical questions about autonomy, delegation, and coordination for such\n\\textit{agentic visualization} that preserve human agency while amplifying\nanalytical capabilities. This paper addresses these questions by reinterpreting\nexisting visualization systems with semi-automated or fully automatic AI\ncomponents through an agentic lens. Based on this analysis, we extract a\ncollection of design patterns for agentic visualization, including agentic\nroles, communication and coordination. These patterns provide a foundation for\nfuture agentic visualization systems that effectively harness AI agents while\nmaintaining human insight and control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.19101v2", "cate": "cs.HC", "date": "2025-05-25", "updated": "2025-07-31", "AI": {"title_translation": "具身可视化：从可视化系统中提取基于代理的设计模式", "tldr": "本文通过重新解读现有可视化系统，提取了具身可视化的设计模式，以应对大型语言模型驱动的自主代理对可视化领域带来的挑战，旨在在增强分析能力的同时保留人类能动性。", "motivation": "大型语言模型驱动的自主代理正在改变人工智能，这使得可视化领域必须采纳具身框架。然而，可视化领域以人为中心的感知循环引发了关于自主性、委托和协调的关键问题，即如何在放大分析能力的同时保留人类能动性。", "method": "本文通过具身视角重新解读了现有包含半自动化或全自动化AI组件的可视化系统，以解决上述问题。", "result": "基于分析，本文提取了一系列具身可视化的设计模式，包括代理角色、通信和协调。", "conclusion": "这些设计模式为未来的具身可视化系统提供了基础，使其能够有效利用AI代理，同时保持人类的洞察力和控制。", "translation": "大型语言模型驱动的自主代理正在改变人工智能，这使得可视化领域必须采纳具身框架。然而，我们领域对感知循环中人类的关注引发了关于自主性、委托和协调的关键问题，即如何在放大分析能力的同时保留人类能动性。本文通过具身视角重新解读现有包含半自动化或全自动化AI组件的可视化系统来解决这些问题。基于此分析，我们提取了一系列具身可视化的设计模式，包括代理角色、通信和协调。这些模式为未来的具身可视化系统提供了基础，使其能够有效利用AI代理，同时保持人类的洞察力和控制。", "summary": "本文探讨了在大型语言模型驱动的自主代理背景下，可视化领域如何采纳具身框架。针对在增强分析能力的同时保留人类能动性的挑战，作者通过重新解读现有可视化系统，提取了一系列具身可视化的设计模式，涵盖代理角色、通信和协调。这些模式旨在为未来具身可视化系统的发展奠定基础，使其能有效整合AI代理并维持人类的洞察力与控制。", "keywords": "具身可视化, 设计模式, AI代理, 可视化系统, 大型语言模型", "comments": "这篇论文创新性地将“代理”概念引入可视化领域，并从现有系统中提取设计模式，为未来具身可视化系统的发展提供了实用指导。其重要性在于，它关注了在AI日益自主化的趋势下，如何平衡AI的分析能力与人类的控制和洞察力，这对于人机协作的未来至关重要。"}}
{"id": "2504.05422", "title": "EP-Diffuser: An Efficient Diffusion Model for Traffic Scene Generation and Prediction via Polynomial Representations", "authors": ["Yue Yao", "Mohamed-Khalil Bouzidi", "Daniel Goehring", "Joerg Reichardt"], "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.05422v3", "summary": "As the prediction horizon increases, predicting the future evolution of\ntraffic scenes becomes increasingly difficult due to the multi-modal nature of\nagent motion. Most state-of-the-art (SotA) prediction models primarily focus on\nforecasting the most likely future. However, for the safe operation of\nautonomous vehicles, it is equally important to cover the distribution for\nplausible motion alternatives. To address this, we introduce EP-Diffuser, a\nnovel parameter-efficient diffusion-based generative model designed to capture\nthe distribution of possible traffic scene evolutions. Conditioned on road\nlayout and agent history, our model acts as a predictor and generates diverse,\nplausible scene continuations. We benchmark EP-Diffuser against two SotA models\nin terms of accuracy and plausibility of predictions on the Argoverse 2\ndataset. Despite its significantly smaller model size, our approach achieves\nboth highly accurate and plausible traffic scene predictions. We further\nevaluate model generalization ability in an out-of-distribution (OoD) test\nsetting using Waymo Open dataset and show superior robustness of our approach.\nThe code and model checkpoints are available at:\nhttps://github.com/continental/EP-Diffuser.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.05422v3", "cate": "cs.CV", "date": "2025-04-07", "updated": "2025-07-31", "AI": {"title_translation": "EP-Diffuser：一种基于多项式表示的交通场景生成与预测高效扩散模型", "tldr": "EP-Diffuser是一个参数高效的扩散模型，用于生成和预测多模态交通场景，在准确性和合理性方面优于现有技术，且模型尺寸更小。", "motivation": "随着预测视野的增加，交通场景的未来演变预测因代理运动的多模态性质而变得越来越困难。大多数最先进（SotA）的预测模型主要关注预测最可能的未来，但对于自动驾驶车辆的安全操作，覆盖合理运动替代方案的分布同样重要。", "method": "引入EP-Diffuser，一种新颖的参数高效扩散生成模型，旨在捕获交通场景演变的可能性分布。该模型以道路布局和代理历史为条件，生成多样、合理的场景延续。通过在Argoverse 2数据集上与两种SotA模型进行准确性和合理性基准测试，并在Waymo Open数据集上进行域外（OoD）泛化能力评估。", "result": "EP-Diffuser在Argoverse 2数据集上，在预测的准确性和合理性方面优于两种SotA模型，尽管其模型尺寸显著更小。在Waymo Open数据集的域外（OoD）测试设置中，模型泛化能力显示出卓越的鲁棒性。", "conclusion": "EP-Diffuser通过参数高效的扩散模型，有效解决了交通场景预测中的多模态问题，并在保持高准确性和合理性的同时，显著减小了模型尺寸，展现了出色的泛化能力。", "translation": "随着预测视野的增加，由于代理运动的多模态性质，预测交通场景的未来演变变得越来越困难。大多数最先进（SotA）的预测模型主要关注预测最可能的未来。然而，对于自动驾驶车辆的安全操作，覆盖合理运动替代方案的分布同样重要。为了解决这个问题，我们引入了EP-Diffuser，这是一种新颖的参数高效扩散生成模型，旨在捕获可能的交通场景演变分布。以道路布局和代理历史为条件，我们的模型充当预测器，生成多样、合理的场景延续。我们在Argoverse 2数据集上，根据预测的准确性和合理性，将EP-Diffuser与两种SotA模型进行了基准测试。尽管其模型尺寸显著更小，但我们的方法实现了高度准确和合理的交通场景预测。我们进一步使用Waymo Open数据集在域外（OoD）测试设置中评估了模型的泛化能力，并显示了我们方法的卓越鲁棒性。代码和模型检查点可在以下网址获取：https://github.com/continental/EP-Diffuser。", "summary": "本文提出了一种名为EP-Diffuser的参数高效扩散模型，用于解决交通场景预测中多模态运动的挑战。该模型能够生成多样且合理的未来场景，并以显著更小的模型尺寸在准确性和合理性方面超越了现有最先进模型。此外，EP-Diffuser在域外数据上表现出强大的泛化能力和鲁棒性。", "keywords": "交通场景预测, 扩散模型, 多模态, 自动驾驶, 参数高效", "comments": "本文的创新点在于引入了参数高效的扩散模型EP-Diffuser来处理交通场景预测的多模态问题，这对于自动驾驶至关重要。其重要性体现在不仅提升了预测的准确性和合理性，还显著减小了模型尺寸并展现了强大的泛化能力，这对于实际部署具有重要意义。"}}
{"id": "2506.17114", "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models", "authors": ["Dadi Guo", "Jiayu Liu", "Zhiyuan Fan", "Zhitao He", "Haoran Li", "Yumeng Wang", "Yi R. Fung"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17114v3", "summary": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable\nmathematical problem-solving abilities. However, the high reported accuracy of\nthese advanced models on popular datasets, reliance on purely numerical\nevaluation and potential benchmark leakage, often masks their true reasoning\nshortcomings. To address this, we propose leveraging the inherent rigor and\nmethodological complexity of mathematical proofs as a diagnostic tool to expose\nthese hidden failures. Specifically, we introduce the RFMDataset (Reveal\nFailure Modes), a collection of 200 diverse mathematical proof problems, and\nthoroughly evaluate advanced models' performance on it. Our in-depth analysis\nof their failures uncovers 10 fine-grained error types, which shows fundamental\nlimitations in current large reasoning models: 1) large reasoning models\ngrapple profoundly with mathematical proofs, with some generating entirely\ncorrect proofs for less than 20% of problems and failing even on basic ones; 2)\nmodels exhibit a diverse spectrum of reasoning failures, prominently\ndemonstrating the lack of guarantees for the correctness and rigor of\nsingle-step reasoning; and 3) models show hallucination and incompleteness\nduring the reasoning process. Our findings reveal that models' self-reflection\nis insufficient to resolve the current logical dilemmas, necessitating\nformalized and fine-grained logical training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17114v3", "cate": "cs.AI", "date": "2025-06-20", "updated": "2025-07-31", "AI": {"title_translation": "数学证明作为试金石：揭示高级大型推理模型的故障模式", "tldr": "本文使用数学证明作为诊断工具，揭示了高级大型推理模型在解决数学证明问题时的深层推理缺陷，并指出其需要更细致的逻辑训练。", "motivation": "尽管大型推理模型在数学问题解决方面表现出色，但其在流行数据集上的高报告准确性、对纯数值评估的依赖以及潜在的基准泄漏，往往掩盖了其真实的推理缺陷。", "method": "作者提出利用数学证明固有的严谨性和方法复杂性作为诊断工具来暴露这些隐藏的故障。具体地，他们引入了RFMDataset，一个包含200个不同数学证明问题的集合，并深入评估了高级模型在其上的表现。", "result": "深入分析揭示了10种细粒度的错误类型，显示了当前大型推理模型的根本局限性：1) 大型推理模型在数学证明方面表现挣扎，对不到20%的问题能生成完全正确的证明，甚至在基本问题上也会失败；2) 模型表现出多种推理失败，突出表现为单步推理的正确性和严谨性缺乏保证；3) 模型在推理过程中出现幻觉和不完整性。", "conclusion": "研究结果表明，模型的自我反思不足以解决当前的逻辑困境，因此需要形式化和细粒度的逻辑训练。", "translation": "大型推理模型（例如R1，o3）已经展示出卓越的数学问题解决能力。然而，这些高级模型在流行数据集上报告的高准确性，对纯数值评估的依赖以及潜在的基准泄漏，往往掩盖了它们真实的推理缺陷。为了解决这个问题，我们提出利用数学证明固有的严谨性和方法复杂性作为诊断工具来暴露这些隐藏的故障。具体而言，我们引入了RFMDataset（揭示故障模式），这是一个包含200个不同数学证明问题的集合，并彻底评估了高级模型在其上的表现。我们对其失败的深入分析揭示了10种细粒度的错误类型，这显示了当前大型推理模型的根本局限性：1）大型推理模型在数学证明方面存在严重的挣扎，有些模型对不到20%的问题生成完全正确的证明，甚至在基本问题上也会失败；2）模型表现出多种推理失败，突出地表明单步推理的正确性和严谨性缺乏保证；3）模型在推理过程中表现出幻觉和不完整性。我们的研究结果表明，模型的自我反思不足以解决当前的逻辑困境，因此需要形式化和细粒度的逻辑训练。", "summary": "本文旨在揭示高级大型推理模型在数学问题解决方面的真实推理缺陷，因为现有评估方法可能掩盖了这些问题。研究人员提出使用数学证明作为诊断工具，并构建了包含200个数学证明问题的RFMDataset。通过对模型在该数据集上的评估，他们发现了10种细粒度错误类型，并指出大型推理模型在数学证明方面表现不佳（甚至在基本问题上失败），单步推理缺乏正确性保证，且存在幻觉和不完整性。研究强调，模型当前的自我反思不足，需要进行形式化和细粒度的逻辑训练。", "keywords": "大型推理模型, 数学证明, 故障模式, 逻辑推理, RFMDataset", "comments": "本文的创新之处在于利用数学证明这一严谨的领域作为“试金石”，系统性地揭示了大型推理模型在复杂逻辑推理方面的深层缺陷，而不仅仅是关注其表面准确率。通过构建RFMDataset并识别出10种细粒度错误类型，为未来大型模型在逻辑推理能力上的改进提供了明确的方向，强调了形式化和细粒度逻辑训练的重要性。"}}
{"id": "2502.20760", "title": "VRM: Knowledge Distillation via Virtual Relation Matching", "authors": ["Weijia Zhang", "Fei Xie", "Weidong Cai", "Chao Ma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025 (Highlight)", "url": "http://arxiv.org/abs/2502.20760v3", "summary": "Knowledge distillation (KD) aims to transfer the knowledge of a more capable\nyet cumbersome teacher model to a lightweight student model. In recent years,\nrelation-based KD methods have fallen behind, as their instance-matching\ncounterparts dominate in performance. In this paper, we revive relational KD by\nidentifying and tackling several key issues in relation-based methods,\nincluding their susceptibility to overfitting and spurious responses.\nSpecifically, we transfer novelly constructed affinity graphs that compactly\nencapsulate a wealth of beneficial inter-sample, inter-class, and inter-view\ncorrelations by exploiting virtual views and relations as a new kind of\nknowledge. As a result, the student has access to richer guidance signals and\nstronger regularisation throughout the distillation process. To further\nmitigate the adverse impact of spurious responses, we prune the affinity graphs\nby dynamically detaching redundant and unreliable edges. Extensive experiments\non CIFAR-100, ImageNet, and MS-COCO datasets demonstrate the superior\nperformance of the proposed virtual relation matching (VRM) method, where it\nconsistently sets new state-of-the-art records over a range of models,\narchitectures, tasks, and set-ups. For instance, VRM for the first time hits\n74.0% accuracy for ResNet50-to-MobileNetV2 distillation on ImageNet, and\nimproves DeiT-T by 14.44% on CIFAR-100 with a ResNet56 teacher.", "comment": "Accepted by ICCV 2025 (Highlight)", "pdf_url": "http://arxiv.org/pdf/2502.20760v3", "cate": "cs.CV", "date": "2025-02-28", "updated": "2025-07-31", "AI": {"title_translation": "VRM: 知识蒸馏中的虚拟关系匹配", "tldr": "该论文提出VRM方法，通过虚拟视图和关系构建亲和图，并动态剪枝，以改进关系型知识蒸馏，超越现有SOTA。", "motivation": "关系型知识蒸馏方法在性能上落后于实例匹配方法，并且容易过拟合和产生虚假响应。本文旨在通过解决这些问题来复兴关系型知识蒸馏。", "method": "提出虚拟关系匹配 (VRM) 方法。具体通过以下两点实现：1. 构建新颖的亲和图，利用虚拟视图和关系作为新知识，封装样本间、类别间和视图间的相关性；2. 动态剪枝亲和图，移除冗余和不可靠的边，以减轻虚假响应的负面影响。", "result": "在CIFAR-100、ImageNet和MS-COCO数据集上的大量实验表明，VRM方法表现优异，并在多种模型、架构、任务和设置上持续创造新的最先进记录。例如，在ImageNet上，ResNet50到MobileNetV2蒸馏首次达到74.0%的准确率；在CIFAR-100上，使用ResNet56教师模型，DeiT-T的性能提升14.44%。", "conclusion": "所提出的VRM方法通过解决关系型知识蒸馏的关键问题，显著提升了其性能，并在多个基准测试中取得了最先进的结果，成功复兴了关系型知识蒸馏。", "translation": "知识蒸馏 (KD) 旨在将更强大但笨重的教师模型的知识转移到轻量级的学生模型。近年来，基于关系的知识蒸馏方法有所落后，因为它们的实例匹配对应方法在性能上占据主导地位。在本文中，我们通过识别和解决基于关系方法中的几个关键问题，包括它们对过拟合和虚假响应的敏感性，来复兴关系型知识蒸馏。具体来说，我们通过利用虚拟视图和关系作为一种新知识，转移新颖构建的亲和图，这些亲和图紧凑地封装了丰富的样本间、类别间和视图间有益的相关性。因此，学生在整个蒸馏过程中可以获得更丰富的指导信号和更强的正则化。为了进一步减轻虚假响应的不利影响，我们通过动态分离冗余和不可靠的边来剪枝亲和图。在CIFAR-100、ImageNet和MS-COCO数据集上进行的大量实验证明了所提出的虚拟关系匹配 (VRM) 方法的卓越性能，它在各种模型、架构、任务和设置上持续创造新的最先进记录。例如，VRM在ImageNet上首次将ResNet50到MobileNetV2的蒸馏准确率提升至74.0%，并在CIFAR-100上使用ResNet56教师模型将DeiT-T的性能提高了14.44%。", "summary": "本文提出了一种名为虚拟关系匹配（VRM）的新型知识蒸馏方法，旨在解决现有关系型知识蒸馏方法易过拟合和产生虚假响应的问题。VRM通过构建并蒸馏利用虚拟视图和关系生成的新颖亲和图来捕获丰富的样本间、类别间和视图间相关性，并动态剪枝图中的冗余边。实验结果表明，VRM在多个数据集和模型上均取得了显著优于现有最先进方法的性能。", "keywords": "知识蒸馏, 关系匹配, 虚拟视图, 亲和图, 深度学习", "comments": "该论文创新性地将虚拟视图和关系引入知识蒸馏，通过构建和剪枝亲和图，有效解决了关系型KD中长期存在的过拟合和虚假响应问题。其在多个基准测试中取得的SOTA结果，证明了其方法的有效性和普适性，有望为关系型知识蒸馏领域带来新的突破。"}}
{"id": "2507.22900", "title": "Tool or Trouble? Exploring Student Attitudes Toward AI Coding Assistants", "authors": ["Sergio Rojas-Galeano"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22900v1", "summary": "This exploratory study examines how AI code assistants shape novice\nprogrammers' experiences during a two-part exam in an introductory programming\ncourse. In the first part, students completed a programming task with access to\nAI support; in the second, they extended their solutions without AI. We\ncollected Likert-scale and open-ended responses from 20 students to evaluate\ntheir perceptions and challenges. Findings suggest that AI tools were perceived\nas helpful for understanding code and increasing confidence, particularly\nduring initial development. However, students reported difficulties\ntransferring knowledge to unaided tasks, revealing possible overreliance and\ngaps in conceptual understanding. These insights highlight the need for\npedagogical strategies that integrate AI meaningfully while reinforcing\nfoundational programming skills.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22900v1", "cate": "cs.HC", "date": "2025-06-26", "updated": "2025-06-26", "AI": {"title_translation": "工具还是麻烦？探索学生对AI编程助手的态度", "tldr": "一项探索性研究发现，AI编程助手在初始开发阶段对新手程序员有帮助，但可能导致过度依赖和知识迁移困难，提示需要平衡AI整合与基础技能强化。", "motivation": "本研究旨在探讨AI代码助手如何影响新手程序员在入门级编程课程中的学习体验。", "method": "研究采用探索性设计，通过一项分为两部分的考试进行：第一部分允许学生使用AI支持完成编程任务，第二部分要求学生在没有AI的情况下扩展解决方案。研究收集了20名学生的李克特量表和开放式回答，以评估他们的感知和面临的挑战。", "result": "研究结果表明，AI工具在理解代码和提高自信心方面被认为是有效的，尤其是在初始开发阶段。然而，学生们报告在没有AI辅助的任务中难以迁移知识，这揭示了可能的过度依赖和概念理解上的不足。", "conclusion": "这些发现强调了在教学策略中有效整合AI，同时加强基础编程技能的必要性。", "translation": "本探索性研究旨在探讨AI代码助手如何塑造新手程序员在入门级编程课程中两部分考试的体验。在第一部分中，学生在有AI支持的情况下完成编程任务；在第二部分中，他们在没有AI的情况下扩展了他们的解决方案。我们收集了20名学生的李克特量表和开放式回答，以评估他们的看法和挑战。研究结果表明，AI工具在理解代码和提高自信心方面被认为是有效的，尤其是在初始开发阶段。然而，学生们报告在没有AI辅助的任务中难以迁移知识，这揭示了可能的过度依赖和概念理解上的不足。这些见解强调了需要制定教学策略，以有意义的方式整合AI，同时加强基础编程技能。", "summary": "本研究探讨了AI代码助手对新手程序员学习体验的影响。通过一项有/无AI辅助的两部分考试，发现AI在初始代码理解和提高自信方面有益，但同时也暴露出学生在无AI辅助任务中知识迁移困难，存在过度依赖和概念理解不足的问题。研究强调了在编程教学中，需在整合AI的同时加强基础技能培养。", "keywords": "AI编程助手, 学生态度, 新手程序员, 学习体验, 过度依赖", "comments": "这项研究具有重要的教育意义，因为它揭示了AI编程助手在教育环境中应用的双面性。其创新之处在于通过实际考试情境来观察学生行为，并量化和质性地收集反馈。研究结果提醒教育者，在推广AI工具的同时，必须关注学生独立解决问题能力和基础知识的掌握，避免过度依赖造成的学习缺陷。其局限性在于样本量较小，可能无法推广到更广泛的学生群体。"}}
{"id": "2505.04834", "title": "The Design Space of Lockfiles Across Package Managers", "authors": ["Yogya Gamage", "Deepika Tiwari", "Martin Monperrus", "Benoit Baudry"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04834v2", "summary": "Software developers reuse third-party packages that are hosted in package\nregistries. At build time, a package manager resolves and fetches the direct\nand indirect dependencies of a project. Most package managers also generate a\nlockfile, which records the exact set of resolved dependency versions.\nLockfiles are used to reduce build times; to verify the integrity of resolved\npackages; and to support build reproducibility across environments and time.\nDespite these beneficial features, developers often struggle with their\nmaintenance, usage, and interpretation. In this study, we unveil the major\nchallenges related to lockfiles, such that future researchers and engineers can\naddress them. We perform the first comprehensive study of lockfiles across 7\npopular package managers, npm, pnpm, Cargo, Poetry, Pipenv, Gradle, and Go.\nFirst, we highlight the wide variety of design decisions that package managers\nmake, regarding the generation process as well as the content of lockfiles.\nNext, we conduct a qualitative analysis based on semi-structured interviews\nwith 15 developers. We capture first-hand insights about the benefits that\ndevelopers perceive in lockfiles, as well as the challenges they face to manage\nthese files. Following these observations, we make 5 recommendations to further\nimprove lockfiles, for a better developer experience.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04834v2", "cate": "cs.SE", "date": "2025-05-07", "updated": "2025-07-30", "AI": {"title_translation": "包管理器中锁文件的设计空间", "tldr": "本研究对7种流行包管理器中的锁文件进行了首次全面研究，揭示了其设计多样性、开发者面临的挑战，并提出了5项改进建议以提升开发者体验。", "motivation": "尽管锁文件在减少构建时间、验证包完整性和支持构建可复现性方面具有益处，但开发者在它们的维护、使用和解释上常常遇到困难。本研究旨在揭示与锁文件相关的主要挑战，以便未来的研究人员和工程师能够解决这些问题。", "method": "本研究对7种流行的包管理器（npm, pnpm, Cargo, Poetry, Pipenv, Gradle, 和 Go）的锁文件进行了首次全面研究。首先，分析了包管理器在锁文件生成过程和内容方面的各种设计决策。其次，通过对15名开发者的半结构化访谈进行了定性分析，以获取他们对锁文件益处和管理挑战的第一手见解。", "result": "研究揭示了包管理器在锁文件设计决策上的广泛多样性。捕获了开发者感知到的锁文件益处以及他们在管理这些文件时面临的挑战。基于这些观察，提出了5项改进锁文件的建议，以提升开发者体验。", "conclusion": "本研究全面揭示了锁文件在流行包管理器中的设计空间和开发者面临的挑战，并提供了具体的改进建议，旨在提升开发者在依赖管理方面的体验。", "translation": "软件开发者复用托管在包注册表中的第三方包。在构建时，包管理器解析并获取项目的直接和间接依赖。大多数包管理器还会生成一个锁文件，其中记录了已解析依赖的确切版本集合。锁文件用于减少构建时间；验证已解析包的完整性；并支持跨环境和跨时间的构建可复现性。尽管有这些有益的特性，开发者在它们的维护、使用和解释上常常遇到困难。在本研究中，我们揭示了与锁文件相关的主要挑战，以便未来的研究人员和工程师能够解决它们。我们首次对7种流行的包管理器（npm, pnpm, Cargo, Poetry, Pipenv, Gradle, 和 Go）中的锁文件进行了全面研究。首先，我们强调了包管理器在锁文件生成过程和内容方面所做的各种设计决策。接下来，我们基于对15名开发者的半结构化访谈进行了定性分析。我们捕获了关于开发者感知到的锁文件益处以及他们在管理这些文件时面临的挑战的第一手见解。基于这些观察，我们提出了5项建议，以进一步改进锁文件，从而提供更好的开发者体验。", "summary": "本研究首次全面探讨了7种主流包管理器中锁文件的设计空间，包括其生成过程、内容多样性以及开发者面临的维护、使用和理解挑战。通过对15名开发者的半结构化访谈，论文揭示了锁文件的益处与痛点，并提出了5项旨在提升开发者体验的改进建议。", "keywords": "锁文件, 包管理器, 依赖管理, 软件工程, 可复现构建", "comments": "这项研究首次全面分析了主流包管理器中的锁文件，揭示了其设计多样性和开发者面临的实际挑战。通过定性访谈和具体建议，为未来锁文件的改进提供了宝贵的见解和方向，对提升软件开发中的依赖管理效率和可复现性具有重要意义。"}}
{"id": "2507.23674", "title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "authors": ["Muhammad Taha Cheema", "Abeer Aamir", "Khawaja Gul Muhammad", "Naveed Anwar Bhatti", "Ihsan Ayyub Qazi", "Zafar Ayyub Qazi"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures", "url": "http://arxiv.org/abs/2507.23674v1", "summary": "Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.", "comment": "13 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.23674v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "TweakLLM：一种动态调整缓存响应的路由架构", "tldr": "TweakLLM是一种路由架构，它使用轻量级LLM动态调整缓存响应，以提高LLM部署的缓存效率和响应质量。", "motivation": "LLM每天处理数百万查询，响应缓存可以有效降低成本和延迟。然而，由于聊天机器人交互的个性化以及语义相似性搜索的准确性有限，通过缓存来保持对用户查询的相关性变得困难。", "method": "我们提出了TweakLLM，这是一种新颖的路由架构，它采用轻量级LLM来动态地使缓存响应适应传入的提示。", "result": "通过全面的评估，包括用户侧面比较研究、满意度投票以及多智能体LLM辩论，我们证明TweakLLM保持了与前沿模型相当的响应质量，同时显著提高了缓存效率。我们在真实世界数据集上的结果突出显示TweakLLM是一种可扩展、资源高效的缓存解决方案，适用于高容量LLM部署，且不影响用户体验。", "conclusion": "TweakLLM是一种可扩展、资源高效的缓存解决方案，可以在不影响用户体验的情况下显著提高高容量LLM部署的缓存效率和响应质量。", "translation": "大型语言模型（LLM）每天处理数百万个查询，因此高效的响应缓存成为降低成本和延迟的有效优化手段。然而，由于聊天机器人交互的个性化以及语义相似性搜索的准确性有限，通过这种方法保持对用户查询的相关性变得困难。为了解决这个问题，我们提出了TweakLLM，这是一种新颖的路由架构，它采用轻量级LLM来动态地使缓存响应适应传入的提示。通过全面的评估，包括用户侧面比较研究、满意度投票以及多智能体LLM辩论，我们证明TweakLLM保持了与前沿模型相当的响应质量，同时显著提高了缓存效率。我们在真实世界数据集上的结果突出显示TweakLLM是一种可扩展、资源高效的缓存解决方案，适用于高容量LLM部署，且不影响用户体验。", "summary": "TweakLLM是一种创新的路由架构，旨在解决大型语言模型（LLM）响应缓存中保持相关性的挑战。它利用一个轻量级LLM动态调整缓存的响应以匹配新的用户提示，从而在不牺牲响应质量的情况下显著提高缓存效率。通过用户研究和多智能体LLM辩论的评估表明，TweakLLM在保持与先进模型相当的质量的同时，显著提升了缓存效果，证明其是高容量LLM部署中可扩展且资源高效的解决方案。", "keywords": "LLM, 缓存, 路由架构, 动态调整, 效率", "comments": "TweakLLM的创新之处在于其采用轻量级LLM来动态调整缓存响应，解决了传统缓存方法在个性化和语义匹配上的局限性。这对于大规模LLM部署而言，是一个重要的成本和延迟优化方案，同时保持了用户体验。其通过用户研究和多智能体辩论的评估方法也增加了结果的可信度。"}}
{"id": "2507.23768", "title": "Formal Bayesian Transfer Learning via the Total Risk Prior", "authors": ["Nathan Wycoff", "Ali Arab", "Lisa O. Singh"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23768v1", "summary": "In analyses with severe data-limitations, augmenting the target dataset with\ninformation from ancillary datasets in the application domain, called source\ndatasets, can lead to significantly improved statistical procedures. However,\nexisting methods for this transfer learning struggle to deal with situations\nwhere the source datasets are also limited and not guaranteed to be\nwell-aligned with the target dataset. A typical strategy is to use the\nempirical loss minimizer on the source data as a prior mean for the target\nparameters, which places the estimation of source parameters outside of the\nBayesian formalism. Our key conceptual contribution is to use a risk minimizer\nconditional on source parameters instead. This allows us to construct a single\njoint prior distribution for all parameters from the source datasets as well as\nthe target dataset. As a consequence, we benefit from full Bayesian uncertainty\nquantification and can perform model averaging via Gibbs sampling over\nindicator variables governing the inclusion of each source dataset. We show how\na particular instantiation of our prior leads to a Bayesian Lasso in a\ntransformed coordinate system and discuss computational techniques to scale our\napproach to moderately sized datasets. We also demonstrate that recently\nproposed minimax-frequentist transfer learning techniques may be viewed as an\napproximate Maximum a Posteriori approach to our model. Finally, we demonstrate\nsuperior predictive performance relative to the frequentist baseline on a\ngenetics application, especially when the source data are limited.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23768v1", "cate": "stat.ML", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "经由总风险先验的正式贝叶斯迁移学习", "tldr": "本文提出了一种基于“总风险先验”的形式化贝叶斯迁移学习新方法，解决了源数据有限且不对齐的问题，实现了全面的贝叶斯不确定性量化，并在数据受限情况下表现出优越的预测性能。", "motivation": "在数据严重受限的分析中，现有迁移学习方法在源数据集有限且与目标数据集不对齐时表现不佳。传统的策略（如使用源数据上的经验损失最小化器作为目标参数的先验均值）将源参数的估计置于贝叶斯形式之外，无法实现全面的贝叶斯不确定性量化。", "method": "本文的核心概念贡献是使用条件于源参数的风险最小化器，从而为所有源数据集和目标数据集的参数构建一个单一的联合先验分布。这使得能够进行全面的贝叶斯不确定性量化，并通过对控制每个源数据集包含的指示变量进行Gibbs采样来执行模型平均。论文还展示了其先验的一个特定实例化如何导致在转换坐标系中的贝叶斯Lasso，并讨论了扩展到中等规模数据集的计算技术。", "result": "该方法在基因应用中显示出相对于频率论基线的优越预测性能，尤其是在源数据有限的情况下。此外，最近提出的极小极大-频率论迁移学习技术可以被视为其模型的近似最大后验方法。", "conclusion": "通过引入“总风险先验”，本研究提供了一种形式化的贝叶斯迁移学习框架，解决了源数据限制和对齐问题，实现了全面的贝叶斯不确定性量化和模型平均，并在实际应用中展现了优越的预测性能。", "translation": "在数据严重受限的分析中，通过来自应用领域中辅助数据集（称为源数据集）的信息来扩充目标数据集，可以显著改进统计过程。然而，现有的迁移学习方法难以处理源数据集也有限且不能保证与目标数据集良好对齐的情况。一种典型的策略是使用源数据上的经验损失最小化器作为目标参数的先验均值，这使得源参数的估计超出了贝叶斯形式。我们关键的概念性贡献是转而使用条件于源参数的风险最小化器。这使我们能够为来自源数据集以及目标数据集的所有参数构建一个单一的联合先验分布。因此，我们受益于全面的贝叶斯不确定性量化，并且可以通过对控制每个源数据集包含的指示变量进行Gibbs采样来执行模型平均。我们展示了我们的先验的一个特定实例化如何导致在转换坐标系中的贝叶斯Lasso，并讨论了将我们的方法扩展到中等规模数据集的计算技术。我们还证明，最近提出的极小极大-频率论迁移学习技术可以被视为我们模型的近似最大后验方法。最后，我们在一个基因应用中展示了相对于频率论基线的优越预测性能，尤其是在源数据有限时。", "summary": "本文提出了一种基于“总风险先验”的形式化贝叶斯迁移学习新方法，旨在解决源数据集有限且与目标数据集不对齐的问题。通过构建所有参数的单一联合先验分布，该方法实现了全面的贝叶斯不确定性量化和模型平均。实验证明，在源数据有限的情况下，该方法在基因应用中表现出优于频率论基线的预测性能，并揭示了与现有极小极大-频率论方法的联系。", "keywords": "贝叶斯迁移学习, 总风险先验, 不确定性量化, 模型平均, 数据受限", "comments": "本文的关键创新在于将源参数的估计整合到完整的贝叶斯框架中，通过构建一个单一的联合先验分布，实现了全面的不确定性量化和模型平均。这解决了现有迁移学习方法在源数据有限和不对齐时的核心痛点，为数据受限的分析提供了更鲁棒的统计程序。将贝叶斯Lasso纳入其框架并探讨计算可伸缩性也增加了其实用性。"}}
{"id": "2507.06448", "title": "Perception-Aware Policy Optimization for Multimodal Reasoning", "authors": ["Zhenhailong Wang", "Xuehang Guo", "Sofia Stoica", "Haiyang Xu", "Hongru Wang", "Hyeonjeong Ha", "Xiusi Chen", "Yangyi Chen", "Ming Yan", "Fei Huang", "Heng Ji"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06448v3", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a\nhighly effective strategy for endowing Large Language Models (LLMs) with robust\nmulti-step reasoning abilities. However, its design and optimizations remain\ntailored to purely textual domains, resulting in suboptimal performance when\napplied to multimodal reasoning tasks. In particular, we observe that a major\nsource of error in current multimodal reasoning lies in the perception of\nvisual inputs. To address this bottleneck, we propose PAPO, a novel policy\ngradient algorithm that encourages the model to learn to perceive while\nlearning to reason. Specifically, we introduce the Implicit Perception Loss in\nthe form of a KL divergence term, which can be seamlessly plugged into\nmainstream RLVR algorithms such as GRPO and DAPO. Notably, PAPO does not rely\non additional data curation, reward models, or stronger teacher models. To\nfurther enhance the training stability of PAPO, we introduce the Double Entropy\nLoss, which effectively regularizes the new KL objective without compromising\nperformance. Despite its simplicity, PAPO yields significant overall\nimprovements of 4.4%-17.5% on diverse multimodal benchmarks. The improvements\nare more pronounced, approaching 8.0%-19.1%, on tasks with high vision\ndependency. We also observe a substantial reduction of 30.5% in perception\nerrors, indicating improved perceptual capabilities with PAPO. Overall, our\nwork introduces a deeper integration of perception-aware supervision into core\nlearning objectives and lays the groundwork for a new RL framework that\nencourages visually grounded reasoning. Code and data will be made publicly\navailable for research purposes. Project page:\nhttps://mikewangwzhl.github.io/PAPO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06448v3", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-31", "AI": {"title_translation": "用于多模态推理的感知感知策略优化", "tldr": "PAPO是一种新型策略梯度算法，通过引入隐式感知损失和双熵损失，显著提升了LLMs在多模态推理任务中的表现，尤其是在视觉依赖性高的任务上，并显著减少了感知错误。", "motivation": "现有RLVR方法主要针对纯文本领域，在多模态推理任务中表现不佳，特别是视觉输入感知是主要错误来源。", "method": "提出PAPO（Perception-Aware Policy Optimization），一种新型策略梯度算法，鼓励模型在推理的同时学习感知。具体通过引入隐式感知损失（KL散度项）无缝集成到主流RLVR算法中，且不依赖额外数据、奖励模型或更强的教师模型。为增强训练稳定性，引入双熵损失来正则化新的KL目标。", "result": "PAPO在多模态基准测试中总体提高了4.4%-17.5%。在视觉依赖性高的任务上，提升更显著，达到8.0%-19.1%。感知错误显著减少了30.5%。", "conclusion": "PAPO将感知感知的监督更深层次地整合到核心学习目标中，为鼓励视觉基础推理的新型强化学习框架奠定了基础。", "translation": "强化学习与可验证奖励（RLVR）已被证明是赋予大型语言模型（LLM）强大多步推理能力的有效策略。然而，其设计和优化仍然仅限于纯文本领域，导致应用于多模态推理任务时性能不佳。特别是，我们观察到当前多模态推理中一个主要的错误来源在于视觉输入的感知。为了解决这一瓶颈，我们提出了PAPO，一种新颖的策略梯度算法，它鼓励模型在学习推理的同时学习感知。具体而言，我们以KL散度项的形式引入了隐式感知损失，该损失可以无缝地集成到主流RLVR算法中，例如GRPO和DAPO。值得注意的是，PAPO不依赖额外的数据整理、奖励模型或更强的教师模型。为了进一步提高PAPO的训练稳定性，我们引入了双熵损失，它有效地正则化了新的KL目标，而不会影响性能。尽管其简单，PAPO在各种多模态基准测试中取得了4.4%-17.5%的显著整体改进。在视觉依赖性高的任务上，改进更为显著，接近8.0%-19.1%。我们还观察到感知错误大幅减少了30.5%，这表明PAPO提高了感知能力。总的来说，我们的工作将感知感知的监督更深层次地整合到核心学习目标中，并为鼓励视觉基础推理的新型强化学习框架奠定了基础。代码和数据将公开发布以供研究使用。项目页面：https://mikewangwzhl.github.io/PAPO。", "summary": "本文提出PAPO，一种针对多模态推理的新型策略优化算法，旨在解决现有RLVR在处理视觉输入感知时性能不佳的问题。PAPO通过引入隐式感知损失和双熵损失，使得模型在推理过程中同时学习感知，且无需额外数据或更强的教师模型。实验结果显示，PAPO在多模态基准测试中表现出显著提升，尤其是在视觉依赖性高的任务上，并有效减少了感知错误，为视觉基础推理的强化学习框架奠定了基础。", "keywords": "多模态推理, 策略优化, 感知学习, 强化学习, 大型语言模型", "comments": "本文提出了一种新颖且实用的方法PAPO，通过在强化学习中引入感知感知机制，有效解决了多模态推理中视觉输入感知不足的痛点。其创新之处在于通过隐式感知损失和双熵损失，在不增加额外数据或复杂模型的前提下，显著提升了模型性能，特别是对视觉依赖性高的任务有显著改善。这为未来多模态RL研究提供了新的方向。"}}
{"id": "2507.23356", "title": "Quality Evaluation of COBOL to Java Code Transformation", "authors": ["Shmulik Froimovich", "Raviv Gal", "Wesam Ibraheem", "Avi Ziv"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Submitted to ASE 2025", "url": "http://arxiv.org/abs/2507.23356v1", "summary": "We present an automated evaluation system for assessing COBOL-to-Java code\ntranslation within IBM's watsonx Code Assistant for Z (WCA4Z). The system\naddresses key challenges in evaluating LLM-based translators, including model\nopacity and the complexity of translation quality assessment. Our approach\ncombines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver\nscalable, multi-faceted evaluations. The system supports continuous integration\nworkflows, enables large-scale benchmarking, and reduces reliance on manual\nreview. We describe the system architecture, evaluation strategies, and\nreporting mechanisms that provide actionable insights for developers and\nproject managers, facilitating the evolution of high-quality, modernized\ncodebases.", "comment": "Submitted to ASE 2025", "pdf_url": "http://arxiv.org/pdf/2507.23356v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "COBOL 到 Java 代码转换的质量评估", "tldr": "本文提出了一个自动化评估系统，用于评估 IBM watsonx Code Assistant for Z (WCA4Z) 中的 COBOL 到 Java 代码转换质量，该系统结合了分析检查器和 LLM-as-a-judge 技术，以应对 LLM 翻译器的评估挑战，并支持大规模基准测试和持续集成。", "motivation": "该系统旨在解决评估基于大型语言模型（LLM）的翻译器所面临的关键挑战，包括模型的不透明性和翻译质量评估的复杂性。", "method": "本文提出了一个自动化评估系统，用于评估 IBM watsonx Code Assistant for Z (WCA4Z) 中的 COBOL 到 Java 代码转换。该方法结合了分析检查器和 LLM-as-a-judge (LaaJ) 技术，以提供可扩展、多方面的评估。系统还描述了其架构、评估策略和报告机制。", "result": "该系统支持持续集成工作流程，能够进行大规模基准测试，并减少对人工审查的依赖。它为开发人员和项目经理提供了可操作的见解。", "conclusion": "该系统通过提供可操作的见解，促进了高质量、现代化代码库的演进。", "translation": "我们提出了一个自动化评估系统，用于评估 IBM 的 watsonx Code Assistant for Z (WCA4Z) 中的 COBOL 到 Java 代码转换。该系统解决了评估基于大型语言模型（LLM）的翻译器所面临的关键挑战，包括模型的不透明性和翻译质量评估的复杂性。我们的方法结合了分析检查器和 LLM-as-a-judge (LaaJ) 技术，以提供可扩展、多方面的评估。该系统支持持续集成工作流程，能够进行大规模基准测试，并减少对人工审查的依赖。我们描述了系统架构、评估策略和报告机制，这些机制为开发人员和项目经理提供了可操作的见解，从而促进了高质量、现代化代码库的演进。", "summary": "本文介绍了一个用于评估 COBOL 到 Java 代码转换的自动化系统，该系统是 IBM watsonx Code Assistant for Z (WCA4Z) 的一部分。该系统通过结合分析检查器和 LLM-as-a-judge 技术，解决了评估基于 LLM 的翻译器所面临的挑战，如模型不透明性和评估复杂性。它支持持续集成和大规模基准测试，减少了人工审查的需求，并提供有价值的见解，以促进高质量代码库的现代化和演进。", "keywords": "COBOL 到 Java, 代码转换, 质量评估, LLM-as-a-judge, 自动化系统", "comments": "本文提出了一种结合传统分析方法和前沿 LLM-as-a-judge 技术的创新评估系统，有效解决了大型语言模型在代码翻译中面临的“黑箱”问题和质量评估难题。其对持续集成和大规模基准测试的支持，极大地提升了代码现代化过程的效率和可靠性，对于推动企业级代码转型具有重要意义。"}}
{"id": "2507.23357", "title": "IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025", "authors": ["Radu-Andrei Bourceanu", "Neil De La Fuente", "Jan Grimm", "Andrei Jardan", "Andriy Manucharyan", "Cornelius Weiss", "Roman Pflugfelder"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23357v1", "summary": "This report analyzes the evolution of key design patterns in computer vision\nby examining six influential papers. The analy- sis begins with foundational\narchitectures for image recognition. We review ResNet, which introduced\nresidual connections to overcome the vanishing gradient problem and enable\neffective training of significantly deeper convolutional networks.\nSubsequently, we examine the Vision Transformer (ViT), which established a new\nparadigm by applying the Transformer ar- chitecture to sequences of image\npatches, demonstrating the efficacy of attention-based models for large-scale\nimage recogni- tion. Building on these visual representation backbones, we\ninvestigate generative models. Generative Adversarial Networks (GANs) are\nanalyzed for their novel adversarial training process, which challenges a\ngenerator against a discriminator to learn complex data distributions. Then,\nLatent Diffusion Models (LDMs) are covered, which improve upon prior generative\nmethods by performing a sequential denoising process in a perceptually\ncompressed latent space. LDMs achieve high-fidelity synthesis with greater\ncomputational efficiency, representing the current state-of-the-art for image\ngeneration. Finally, we explore self-supervised learning techniques that reduce\ndependency on labeled data. DINO is a self-distillation framework in which a\nstudent network learns to match the output of a momentum-updated teacher,\nyielding features with strong k-NN classification performance. We conclude with\nMasked Autoencoders (MAE), which utilize an asymmetric encoder-decoder design\nto reconstruct heavily masked inputs, providing a highly scalable and effective\nmethod for pre-training large-scale vision models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23357v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "IN45023 计算机视觉神经网络设计模式研讨报告，2025年夏季", "tldr": "该报告分析了计算机视觉中神经网络设计模式的演变，通过考察ResNet、ViT、GANs、LDMs、DINO和MAE这六篇有影响力的论文。", "motivation": "本报告旨在通过审查六篇有影响力的论文，分析计算机视觉中关键设计模式的演变。", "method": "本报告通过审查六篇有影响力的论文来分析计算机视觉中的设计模式，这些论文涵盖了从图像识别的基础架构（ResNet、ViT）到生成模型（GANs、LDMs）以及自监督学习技术（DINO、MAE）。", "result": "本报告未提出新的研究成果，而是分析和总结了所审查论文中各自模型的成果，例如ResNet解决了梯度消失问题，ViT展示了注意力模型的有效性，GANs引入了对抗训练，LDMs实现了高保真合成与计算效率，DINO在K-NN分类中表现出色，MAE提供了可扩展的预训练方法。", "conclusion": "本报告通过分析多种神经网络设计模式，展示了计算机视觉领域从基础架构到生成模型和自监督学习技术的演变和进步。", "translation": "本报告通过考察六篇有影响力的论文，分析了计算机视觉中关键设计模式的演变。分析从图像识别的基础架构开始。我们回顾了ResNet，它引入了残差连接以克服梯度消失问题，并实现更深层卷积网络的有效训练。随后，我们考察了Vision Transformer (ViT)，它通过将Transformer架构应用于图像块序列，建立了新的范式，展示了基于注意力的模型在大规模图像识别中的有效性。在这些视觉表示骨干的基础上，我们研究了生成模型。生成对抗网络 (GANs) 因其新颖的对抗训练过程而受到分析，该过程使生成器与判别器对抗以学习复杂的数据分布。然后，介绍了潜在扩散模型 (LDMs)，它们通过在感知压缩的潜在空间中执行顺序去噪过程，改进了先前的生成方法。LDMs以更高的计算效率实现了高保真合成，代表了图像生成领域的最新技术。最后，我们探讨了减少对标记数据依赖的自监督学习技术。DINO是一个自蒸馏框架，其中学生网络学习匹配动量更新教师的输出，从而产生具有强大k-NN分类性能的特征。我们最后介绍了掩码自编码器 (MAE)，它利用非对称编码器-解码器设计来重建严重掩码的输入，为大规模视觉模型的预训练提供了一种高度可扩展且有效的方法。", "summary": "这份研讨报告深入分析了计算机视觉领域神经网络设计模式的演变。报告系统地回顾了六个具有里程碑意义的模型：ResNet解决了深度网络训练中的梯度消失问题；Vision Transformer (ViT) 通过注意力机制革新了图像识别；生成对抗网络 (GANs) 引入了对抗性训练范式；潜在扩散模型 (LDMs) 在图像生成方面达到了最先进水平；DINO展示了自蒸馏在特征学习中的潜力；以及掩码自编码器 (MAE) 为大规模视觉模型预训练提供了高效方法。报告全面展现了计算机视觉从基础架构到生成和自监督学习技术的关键进展。", "keywords": "计算机视觉, 神经网络, 设计模式, 图像识别, 生成模型", "comments": "这份报告作为一份研讨报告，其价值在于系统地梳理和总结了计算机视觉领域中多个具有里程碑意义的神经网络设计模式。它清晰地展现了技术演进的路径，从基础的图像识别到复杂的生成任务，再到高效的自监督学习。报告的创新性在于其综合性和概括性，为学生或研究人员提供了一个理解该领域核心发展的良好框架。局限性可能在于它侧重于回顾而非提出新的研究成果，且深度可能受限于研讨报告的性质。"}}
{"id": "2405.04261", "title": "Graph Reconstruction from Noisy Random Subgraphs", "authors": ["Andrew McGregor", "Rik Sengupta"], "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, to appear in ISIT 2024", "url": "http://arxiv.org/abs/2405.04261v2", "summary": "We consider the problem of reconstructing an undirected graph $G$ on $n$\nvertices given multiple random noisy subgraphs or \"traces\". Specifically, a\ntrace is generated by sampling each vertex with probability $p_v$, then taking\nthe resulting induced subgraph on the sampled vertices, and then adding noise\nin the form of either (a) deleting each edge in the subgraph with probability\n$1-p_e$, or (b) deleting each edge with probability $f_e$ and transforming a\nnon-edge into an edge with probability $f_e$. We show that, under mild\nassumptions on $p_v$, $p_e$ and $f_e$, if $G$ is selected uniformly at random,\nthen $O(p_e^{-1} p_v^{-2} \\log n)$ or $O((f_e-1/2)^{-2} p_v^{-2} \\log n)$\ntraces suffice to reconstruct $G$ with high probability. In contrast, if $G$ is\narbitrary, then $\\exp(\\Omega(n))$ traces are necessary even when $p_v=1,\np_e=1/2$.", "comment": "6 pages, to appear in ISIT 2024", "pdf_url": "http://arxiv.org/pdf/2405.04261v2", "cate": "cs.IT", "date": "2024-05-07", "updated": "2025-07-31", "AI": {"title_translation": "从噪声随机子图重建图", "tldr": "本文研究了从带噪声的随机子图重建无向图的问题，发现随机图的重建效率远高于任意图，后者需要指数级数量的痕迹。", "motivation": "旨在解决从多个随机带噪声子图（“痕迹”）重建一个具有n个顶点的无向图G的问题。", "method": "通过以下方式生成痕迹：以概率$p_v$采样每个顶点，然后取采样顶点上的诱导子图，接着以两种方式之一添加噪声：(a) 以概率$1-p_e$删除子图中的每条边；或(b) 以概率$f_e$删除每条边并以概率$f_e$将非边转换为边。研究通过数学分析确定了重建图所需的痕迹数量。", "result": "在对$p_v, p_e, f_e$的温和假设下，如果G是均匀随机选择的，则$O(p_e^{-1} p_v^{-2} \text{log} n)$或$O((f_e-1/2)^{-2} p_v^{-2} \text{log} n)$个痕迹就足以以高概率重建G。相反，如果G是任意的，即使在$p_v=1, p_e=1/2$的情况下，也需要$\text{exp}(\text{Ω}(n))$个痕迹。", "conclusion": "从带噪声的随机子图重建无向图的难度，对于随机图和任意图存在显著差异，任意图的重建需要指数级的更多痕迹。", "translation": "我们考虑从多个随机带噪声子图或“痕迹”中重建一个具有$n$个顶点的无向图$G$的问题。具体来说，痕迹是通过以概率$p_v$采样每个顶点，然后获取采样顶点上的诱导子图，接着以以下两种形式之一添加噪声来生成的：(a) 以概率$1-p_e$删除子图中的每条边，或(b) 以概率$f_e$删除每条边并以概率$f_e$将非边转换为边。我们表明，在对$p_v, p_e, f_e$的温和假设下，如果$G$是均匀随机选择的，则$O(p_e^{-1} p_v^{-2} \\text{log} n)$或$O((f_e-1/2)^{-2} p_v^{-2} \\text{log} n)$个痕迹就足以以高概率重建$G$。相比之下，如果$G$是任意的，即使在$p_v=1, p_e=1/2$的情况下，也需要$\text{exp}(\\Omega(n))$个痕迹。", "summary": "本文研究了从多个随机带噪声子图重建无向图的问题。研究提出了一种痕迹生成模型，其中包含顶点采样和两种类型的边噪声。结果表明，对于均匀随机图，仅需要多项式数量的痕迹即可高概率重建；然而，对于任意图，即使在理想采样和噪声条件下，也需要指数数量的痕迹，揭示了图结构对重建复杂度的巨大影响。", "keywords": "图重建, 随机子图, 噪声, 痕迹, 复杂度分析", "comments": "这项研究揭示了在图重建问题中，图的随机性对重建效率的关键影响。对于随机图，重建是可行的且效率较高；但对于任意图，即使在看似有利的条件下，重建也变得极其困难。这对于设计实际的图重建算法具有重要指导意义，强调了在没有图结构先验信息时的挑战。"}}
{"id": "2507.10073", "title": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires", "authors": ["Simon Münker"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15pages, 1 figure, 2 tables", "url": "http://arxiv.org/abs/2507.10073v2", "summary": "Are AI systems truly representing human values, or merely averaging across\nthem? Our study suggests a concerning reality: Large Language Models (LLMs)\nfail to represent diverse cultural moral frameworks despite their linguistic\ncapabilities. We expose significant gaps between AI-generated and human moral\nintuitions by applying the Moral Foundations Questionnaire across 19 cultural\ncontexts. Comparing multiple state-of-the-art LLMs' origins against human\nbaseline data, we find these models systematically homogenize moral diversity.\nSurprisingly, increased model size doesn't consistently improve cultural\nrepresentation fidelity. Our findings challenge the growing use of LLMs as\nsynthetic populations in social science research and highlight a fundamental\nlimitation in current AI alignment approaches. Without data-driven alignment\nbeyond prompting, these systems cannot capture the nuanced, culturally-specific\nmoral intuitions. Our results call for more grounded alignment objectives and\nevaluation metrics to ensure AI systems represent diverse human values rather\nthan flattening the moral landscape.", "comment": "15pages, 1 figure, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.10073v2", "cate": "cs.CL", "date": "2025-07-14", "updated": "2025-07-31", "AI": {"title_translation": "大型语言模型中的文化偏见：通过道德问卷评估AI智能体", "tldr": "研究发现大型语言模型无法代表多元文化道德框架，反而系统性地同化道德多样性，即使模型增大也未能改善，这挑战了LLM在社会科学中作为合成人口的使用。", "motivation": "当前AI系统是否真正代表人类价值观，或者仅仅是平均化了它们？本研究旨在探究大型语言模型（LLMs）能否代表多元文化道德框架，并指出其在捕获细致的、文化特异性道德直觉方面的局限性。", "method": "研究通过在19种文化背景下应用道德基础问卷（Moral Foundations Questionnaire），评估了多个最先进的大型语言模型，并将其与人类基线数据进行比较，以揭示AI生成与人类道德直觉之间的差异。", "result": "研究发现大型语言模型尽管具有语言能力，但未能代表多元文化道德框架，并在AI生成与人类道德直觉之间存在显著差距。这些模型系统性地同化了道德多样性。令人惊讶的是，模型规模的增加并未持续改善文化代表性忠实度。", "conclusion": "研究结果挑战了将LLMs作为合成人口用于社会科学研究的日益增长的趋势，并突出了当前AI对齐方法中的一个根本性局限。如果没有超越提示的数据驱动对齐，这些系统无法捕获细致的、文化特异性的道德直觉。研究呼吁制定更扎实的对齐目标和评估指标，以确保AI系统代表多样化的人类价值观，而不是扁平化道德图景。", "translation": "AI系统是真正代表人类价值观，还是仅仅是它们的平均值？我们的研究揭示了一个令人担忧的现实：大型语言模型（LLMs）尽管具有语言能力，但未能代表多元文化道德框架。我们通过在19种文化背景下应用道德基础问卷，揭示了AI生成与人类道德直觉之间的显著差距。通过比较多个最先进LLM的来源与人类基线数据，我们发现这些模型系统性地同化了道德多样性。令人惊讶的是，模型规模的增加并未持续改善文化代表性忠实度。我们的发现挑战了将LLMs作为合成人口用于社会科学研究的日益增长的趋势，并突出了当前AI对齐方法中的一个根本性局限。如果没有超越提示的数据驱动对齐，这些系统无法捕获细致的、文化特异性的道德直觉。我们的结果呼吁制定更扎实的对齐目标和评估指标，以确保AI系统代表多样化的人类价值观，而不是扁平化道德图景。", "summary": "本研究评估了大型语言模型（LLMs）在代表多元文化道德框架方面的能力。通过在19种文化背景下使用道德基础问卷，研究发现LLMs未能准确反映人类的文化道德多样性，反而系统性地同化了道德直觉，且模型规模的增大并未显著改善这一问题。这表明当前AI对齐方法存在局限性，并对LLMs在社会科学中作为合成人口的使用提出了质疑，呼吁更注重数据驱动的对齐和评估。", "keywords": "文化偏见, 大型语言模型, 道德问卷, AI对齐, 文化多样性", "comments": "这项研究揭示了大型语言模型在文化代表性方面的一个关键局限性，即它们倾向于同化而非体现道德多样性。其创新之处在于通过跨文化道德问卷的实证方法，量化了AI的文化偏见。重要性在于它对LLM在社会科学研究中的应用提出了警示，并强调了未来AI对齐工作需要更深入地考虑文化多样性和细微差别，而不仅仅是依赖于提示工程。"}}
{"id": "2507.23597", "title": "MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction", "authors": ["Zijian Dong", "Longteng Duan", "Jie Song", "Michael J. Black", "Andreas Geiger"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (Highlight), Project Page: this https URL", "url": "http://arxiv.org/abs/2507.23597v1", "summary": "We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian\navatars from a single-view image. The main challenge lies in inferring unseen\nappearance and geometric details while ensuring 3D consistency and realism.\nMost previous methods rely on 2D diffusion models to synthesize unseen views;\nhowever, these generated views are sparse and inconsistent, resulting in\nunrealistic 3D artifacts and blurred appearance. To address these limitations,\nwe leverage a generative avatar model, that can generate diverse 3D avatars by\nsampling deformed Gaussians from a learned prior distribution. Due to the\nlimited amount of 3D training data such a 3D model alone cannot capture all\nimage details of unseen identities. Consequently, we integrate it as a prior,\nensuring 3D consistency by projecting input images into its latent space and\nenforcing additional 3D appearance and geometric constraints. Our novel\napproach formulates Gaussian avatar creation as a model inversion process by\nfitting the generative avatar to synthetic views from 2D diffusion models. The\ngenerative avatar provides a meaningful initialization for model fitting,\nenforces 3D regularization, and helps in refining pose estimation. Experiments\nshow that our method surpasses state-of-the-art techniques and generalizes well\nto real-world scenarios. Our Gaussian avatars are also inherently animatable", "comment": "ICCV 2025 (Highlight), Project Page: https://zj-dong.github.io/MoGA/", "pdf_url": "http://arxiv.org/pdf/2507.23597v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "MoGA：用于单目高斯头像重建的3D生成式头像先验", "tldr": "MoGA通过结合3D生成式头像先验和2D扩散模型，实现了从单张图片高质量重建3D高斯头像，解决了传统方法的3D不一致和模糊问题。", "motivation": "从单视角图像重建高保真3D高斯头像面临挑战，尤其是在推断未见外观和几何细节，同时确保3D一致性和真实性方面。大多数现有方法依赖2D扩散模型合成未见视角，但这些视角稀疏且不一致，导致不真实的3D伪影和模糊外观。", "method": "提出MoGA，通过利用一个能够从学习到的先验分布中采样变形高斯来生成多样化3D头像的生成式头像模型。该模型被整合为一个先验，通过将输入图像投影到其潜在空间并强制执行额外的3D外观和几何约束来确保3D一致性。该方法将高斯头像创建公式化为模型反演过程，通过将生成式头像拟合到来自2D扩散模型的合成视图。生成式头像为模型拟合提供了有意义的初始化，强制执行3D正则化，并有助于优化姿态估计。", "result": "实验表明，该方法超越了现有最先进的技术，并且在真实世界场景中具有良好的泛化能力。生成的高斯头像本质上是可动画的。", "conclusion": "MoGA通过引入3D生成式头像先验，有效解决了单目3D高斯头像重建中2D扩散模型导致的3D不一致和模糊问题，实现了高保真、可动画的3D头像重建，并优于现有方法。", "translation": "我们提出了MoGA，一种从单视图图像重建高保真3D高斯头像的新方法。主要挑战在于推断未见的外观和几何细节，同时确保3D一致性和真实感。大多数以前的方法依赖2D扩散模型来合成未见视图；然而，这些生成的视图稀疏且不一致，导致不真实的3D伪影和模糊外观。为了解决这些限制，我们利用了一个生成式头像模型，该模型可以通过从学习到的先验分布中采样变形高斯来生成多样化的3D头像。由于3D训练数据量有限，仅靠这样的3D模型无法捕捉所有未见身份的图像细节。因此，我们将其作为一个先验集成，通过将输入图像投影到其潜在空间并强制执行额外的3D外观和几何约束来确保3D一致性。我们的新颖方法将高斯头像创建公式化为模型反演过程，通过将生成式头像拟合到来自2D扩散模型的合成视图。生成式头像为模型拟合提供了有意义的初始化，强制执行3D正则化，并有助于优化姿态估计。实验表明，我们的方法超越了现有最先进的技术，并且在真实世界场景中具有良好的泛化能力。我们的高斯头像本质上也是可动画的。", "summary": "MoGA是一种新颖的方法，旨在从单视图图像重建高保真3D高斯头像。它通过引入一个3D生成式头像模型作为先验，解决了现有2D扩散模型在生成未见视图时存在的3D不一致和模糊问题。该方法将高斯头像创建视为模型反演过程，将生成式头像拟合到2D扩散模型生成的合成视图，从而提供初始化、3D正则化和姿态估计优化。实验证明MoGA优于现有技术，在真实场景中表现良好，并能生成可动画的3D高斯头像。", "keywords": "3D高斯头像, 单目重建, 生成式模型, 扩散模型, 3D一致性", "comments": "MoGA的创新之处在于将3D生成式头像模型作为先验引入单目3D重建任务，有效弥补了仅使用2D扩散模型在3D一致性上的不足。这种结合利用了3D先验的结构优势和2D扩散模型的细节生成能力，是解决单目重建中几何和外观推断难题的有效途径。其结果表明在高保真度和可动画性方面均有显著提升。"}}
{"id": "2507.23546", "title": "Empirical cross-system meta-analysis of long-term transmission grid evolution", "authors": ["Bálint Hartmann", "Michelle T. Cirunay"], "categories": ["cs.SI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2507.23546v1", "summary": "The potential of grid-side flexibility, the latent ability to reconfigure\ntransmission network topology remains under-used partly because of the lack of\nempirical studies on how real-world grids evolve.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.23546v1", "cate": "cs.SI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "长期输电网演变的经验性跨系统元分析", "tldr": "输电网拓扑重构的潜力未被充分利用，因为缺乏关于真实电网如何演变的实证研究。", "motivation": "现有电网侧灵活性（即重新配置输电网络拓扑的能力）的潜力未被充分利用，部分原因是缺乏关于真实世界电网如何演变的实证研究。", "method": "Not mentioned in abstract", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "电网侧灵活性（即重新配置输电网络拓扑的潜在能力）的潜力仍未得到充分利用，部分原因是缺乏关于真实世界电网如何演变的实证研究。", "summary": "本文指出，电网侧灵活性，即重新配置输电网络拓扑的潜在能力，尚未被充分利用。这主要是由于缺乏对真实世界电网如何演变的实证研究。", "keywords": "输电网演变, 电网灵活性, 拓扑重构, 实证研究, 元分析", "comments": "该论文指出了电网领域一个重要的研究空白：缺乏关于真实电网演变的实证数据。这限制了电网侧灵活性的充分利用。其创新点可能在于通过“经验性跨系统元分析”来弥补这一空白，但具体方法和预期贡献在摘要中未详细说明。"}}
{"id": "2507.23533", "title": "Threshold-Driven Streaming Graph: Expansion and Rumor Spreading", "authors": ["Flora Angileri", "Andrea Clementi", "Emanuele Natale", "Michele Salvi", "Isabella Ziccardi"], "categories": ["cs.DC", "math.PR"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23533v1", "summary": "A randomized distributed algorithm called RAES was introduced in [Becchetti\net al., SODA 2020] to extract a bounded-degree expander from a dense $n$-vertex\nexpander graph $G = (V, E)$. The algorithm relies on a simple threshold-based\nprocedure. A key assumption in [Becchetti et al., SODA 2020] is that the input\ngraph $G$ is static - i.e., both its vertex set $V$ and edge set $E$ remain\nunchanged throughout the process - while the analysis of RAES in dynamic models\nis left as a major open question.\n  In this work, we investigate the behavior of RAES under a dynamic graph model\ninduced by a streaming node-churn process (also known as the sliding window\nmodel), where, at each discrete round, a new node joins the graph and the\noldest node departs. This process yields a bounded-degree dynamic graph\n$\\mathcal{G} =\\{ G_t = (V_t, E_t) : t \\in \\mathbb{N}\\}$ that captures essential\ncharacteristics of peer-to-peer networks -- specifically, node churn and\nthreshold on the number of connections each node can manage. We prove that\nevery snapshot $G_t$ in the dynamic graph sequence has good expansion\nproperties with high probability. Furthermore, we leverage this property to\nestablish a logarithmic upper bound on the completion time of the well-known\nPUSH and PULL rumor spreading protocols over the dynamic graph $\\mathcal{G}$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23533v1", "cate": "cs.DC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "阈值驱动的流式图：扩展与谣言传播", "tldr": "本文在动态流图模型下分析了RAES算法的扩展性和谣言传播，解决了其在动态模型中分析的开放问题。", "motivation": "之前的RAES算法研究假设输入图是静态的，而其在动态模型中的分析是一个主要的开放问题。", "method": "在流式节点流失过程（滑动窗口模型）诱导的动态图模型下，研究RAES的行为，并分析其扩展性及在此基础上谣言传播协议的性能。", "result": "证明了动态图序列中的每个快照都以高概率具有良好的扩展属性。此外，还在动态图上建立了著名的PUSH和PULL谣言传播协议完成时间的对数上限。", "conclusion": "该研究成功地将RAES算法的分析扩展到动态图模型，并证明了在节点流失环境下仍能保持良好的扩展性，从而支持高效的谣言传播。", "translation": "在[Becchetti等人，SODA 2020]中引入了一种名为RAES的随机分布式算法，用于从一个稠密的n顶点扩展图G=(V, E)中提取一个有界度扩展器。该算法依赖于一个简单的基于阈值的过程。[Becchetti等人，SODA 2020]中的一个关键假设是输入图G是静态的——即其顶点集V和边集E在整个过程中保持不变——而RAES在动态模型中的分析则被留作一个主要的开放问题。\n在这项工作中，我们研究了RAES在由流式节点流失过程（也称为滑动窗口模型）引起的动态图模型下的行为，其中，在每个离散回合，一个新节点加入图，最老的节点离开。这个过程产生了一个有界度的动态图$\\\\mathcal{G} =\\{ G_t = (V_t, E_t) : t \\\\in \\\\mathbb{N}\\}$，它捕捉了点对点网络的基本特征——特别是节点流失和每个节点可以管理的连接数量的阈值。我们证明了动态图序列中的每个快照$G_t$都以高概率具有良好的扩展属性。此外，我们利用这一属性，在动态图$\\\\mathcal{G}$上建立了著名的PUSH和PULL谣言传播协议完成时间的对数上限。", "summary": "本文将RAES算法（最初用于静态图）的分析扩展到具有节点流失的动态流图模型。研究证明，动态图以高概率保持良好的扩展属性，并表明在此类动态图上，标准的谣言传播协议（PUSH和PULL）可以在对数时间内完成。", "keywords": "流式图, 动态图, 扩展器, 谣言传播, 节点流失", "comments": "本文通过将现有算法的分析扩展到更真实的动态图环境，解决了一个重要的开放问题。关于保持扩展属性和高效谣言传播的发现对于理解和设计在P2P系统等不稳定网络环境中的算法至关重要。"}}
{"id": "2507.23149", "title": "Learning with Episodic Hypothesis Testing in General Games: A Framework for Equilibrium Selection", "authors": ["Ruifan Yang", "Manxi Wu"], "categories": ["cs.GT", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23149v1", "summary": "We introduce a new hypothesis testing-based learning dynamics in which\nplayers update their strategies by combining hypothesis testing with\nutility-driven exploration. In this dynamics, each player forms beliefs about\nopponents' strategies and episodically tests these beliefs using empirical\nobservations. Beliefs are resampled either when the hypothesis test is rejected\nor through exploration, where the probability of exploration decreases with the\nplayer's (transformed) utility. In general finite normal-form games, we show\nthat the learning process converges to a set of approximate Nash equilibria\nand, more importantly, to a refinement that selects equilibria maximizing the\nminimum (transformed) utility across all players. Our result establishes\nconvergence to equilibrium in general finite games and reveals a novel\nmechanism for equilibrium selection induced by the structure of the learning\ndynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23149v1", "cate": "cs.GT", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "在一般博弈中基于情景假设检验的学习：一个均衡选择框架", "tldr": "提出一种结合假设检验和效用驱动探索的学习动力学，在一般有限博弈中收敛于近似纳什均衡，并选择最大化最小效用的均衡。", "motivation": "论文旨在引入一种新的学习动力学，以解决在一般博弈中策略更新和均衡选择的问题，特别是寻找一种能够收敛到特定类型均衡（最大化最小效用）的机制。", "method": "本文提出了一种基于假设检验的学习动力学，玩家通过结合假设检验和效用驱动的探索来更新策略。玩家形成对对手策略的信念，并使用经验观察进行情景测试。当假设检验被拒绝或通过探索（探索概率随玩家效用降低）时，信念会被重新采样。", "result": "在一般有限范式博弈中，学习过程收敛到一组近似纳什均衡。更重要的是，它收敛到一个能够选择最大化所有玩家最小（转换）效用的均衡的精炼。", "conclusion": "该研究确立了在一般有限博弈中学习过程收敛到均衡，并揭示了由学习动力学结构引起的均衡选择的新机制。", "translation": "我们引入了一种新的基于假设检验的学习动力学，其中玩家通过将假设检验与效用驱动探索相结合来更新他们的策略。在这种动力学中，每个玩家形成关于对手策略的信念，并使用经验观察对这些信念进行情景测试。当假设检验被拒绝或通过探索时，信念会被重新采样，其中探索的概率随着玩家（转换后的）效用而降低。在一般有限范式博弈中，我们表明学习过程收敛到一组近似纳什均衡，更重要的是，收敛到一个选择最大化所有玩家最小（转换）效用的均衡的精炼。我们的结果确立了在一般有限博弈中收敛到均衡，并揭示了由学习动力学结构引起的均衡选择的新机制。", "summary": "本文提出一种在一般有限博弈中基于假设检验和效用驱动探索的学习动力学。该机制使玩家能够更新策略，并证明其收敛到近似纳什均衡，尤其能选择那些最大化所有玩家最小效用的均衡，从而揭示了均衡选择的新机制。", "keywords": "假设检验, 学习动力学, 均衡选择, 纳什均衡, 一般博弈", "comments": "这篇论文通过结合假设检验和效用驱动探索，为一般博弈中的均衡选择提供了一种新颖的机制。其创新之处在于证明了学习过程不仅收敛到纳什均衡，而且能够选择一个具有帕累托改进特性的均衡（最大化最小效用），这对于多智能体系统和经济学应用具有重要意义。"}}
{"id": "2507.23135", "title": "ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans", "authors": ["Ananya Sadana", "Yash Kumar Lal", "Jiawei Zhou"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23135v1", "summary": "Understanding causal relationships across modalities is a core challenge for\nmultimodal models operating in real-world environments. We introduce ISO-Bench,\na benchmark for evaluating whether models can infer causal dependencies between\nvisual observations and procedural text. Each example presents an image of a\ntask step and a text snippet from a plan, with the goal of deciding whether the\nvisual step occurs before or after the referenced text step. Evaluation results\non ten frontier vision-language models show underwhelming performance: the best\nzero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest\ngains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further\nhighlights concrete directions for improving causal understanding in multimodal\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23135v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "ISO-Bench：通过程序计划评估视觉-语言模型中的多模态因果推理", "tldr": "ISO-Bench是一个用于评估视觉-语言模型在视觉观察和程序文本之间因果依赖推理能力的基准测试。现有模型表现不佳，远低于人类水平。", "motivation": "理解跨模态的因果关系是多模态模型在真实世界环境中运行的核心挑战。", "method": "引入ISO-Bench基准测试，通过展示任务步骤的图像和计划中的文本片段，评估模型能否判断视觉步骤发生在引用文本步骤之前或之后。", "result": "对十个前沿视觉-语言模型的评估结果显示性能不佳：最佳零样本F1仅为0.57，思维链推理仅获得适度提升（最高0.62 F1），远低于人类（0.98 F1）。", "conclusion": "多模态模型在因果理解方面仍有很大提升空间，需要具体方向的改进。", "translation": "理解跨模态的因果关系是多模态模型在真实世界环境中运行的核心挑战。我们引入了ISO-Bench，一个用于评估模型能否推断视觉观察和程序文本之间因果依赖关系的基准。每个示例都呈现一个任务步骤的图像和计划中的一段文本，目标是判断视觉步骤发生在引用的文本步骤之前还是之后。对十个前沿视觉-语言模型的评估结果显示性能不佳：最佳零样本F1仅为0.57，思维链推理仅获得适度提升（最高0.62 F1），远低于人类（0.98 F1）。我们的分析进一步强调了改进多模态模型中因果理解的具体方向。", "summary": "本研究介绍了ISO-Bench，一个旨在评估视觉-语言模型跨模态因果推理能力的基准。该基准通过要求模型判断视觉步骤与程序文本步骤的先后顺序来测试其因果理解能力。对当前领先模型的评估显示，它们的表现远未达到人类水平，突显了在多模态因果理解方面存在显著的改进空间。", "keywords": "多模态, 因果推理, 视觉-语言模型, 基准测试, ISO-Bench", "comments": "ISO-Bench的创新之处在于其专注于多模态因果推理，这是一个对真实世界AI应用至关重要的领域。该基准揭示了当前视觉-语言模型在理解视觉和文本之间复杂因果关系方面的显著局限性，为未来研究指明了方向。其重要性在于提供了一个量化评估工具，有助于推动多模态AI的发展。"}}
{"id": "2507.09252", "title": "TPP-SD: Accelerating Transformer Point Process Sampling with Speculative Decoding", "authors": ["Shukai Gong", "Yiyang Fu", "Fengyuan Ran", "Quyu Kong", "Feng Zhou"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09252v2", "summary": "We propose TPP-SD, a novel approach that accelerates Transformer temporal\npoint process (TPP) sampling by adapting speculative decoding (SD) techniques\nfrom language models. By identifying the structural similarities between\nthinning algorithms for TPPs and speculative decoding for language models, we\ndevelop an efficient sampling framework that leverages a smaller draft model to\ngenerate multiple candidate events, which are then verified by the larger\ntarget model in parallel. TPP-SD maintains the same output distribution as\nautoregressive sampling while achieving significant acceleration. Experiments\non both synthetic and real datasets demonstrate that our approach produces\nsamples from identical distributions as standard methods, but with 2-6$\\times$\nspeedup. Our ablation studies analyze the impact of hyperparameters such as\ndraft length and draft model size on sampling efficiency. TPP-SD bridges the\ngap between powerful Transformer TPP models and the practical need for rapid\nsequence sampling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09252v2", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-31", "AI": {"title_translation": "TPP-SD：使用推测解码加速Transformer点过程采样", "tldr": "TPP-SD通过将语言模型中的推测解码技术应用于Transformer时间点过程（TPP）采样，实现了2-6倍的加速，同时保持了相同的输出分布。", "motivation": "强大的Transformer时间点过程（TPP）模型在实际应用中需要快速的序列采样，但目前的采样速度较慢，存在效率瓶颈。", "method": "本文提出了TPP-SD，一种新颖的方法，通过借鉴语言模型中的推测解码（SD）技术来加速Transformer TPP采样。该方法识别了TPP的稀疏算法与语言模型的推测解码之间的结构相似性，并开发了一个高效的采样框架，利用一个较小的草稿模型生成多个候选事件，然后由较大的目标模型并行验证。", "result": "TPP-SD在保持与自回归采样相同输出分布的同时，实现了显著的加速。在合成数据集和真实数据集上的实验表明，该方法生成的样本与标准方法具有相同的分布，但速度提高了2-6倍。消融研究分析了草稿长度和草稿模型大小等超参数对采样效率的影响。", "conclusion": "TPP-SD成功弥合了强大的Transformer时间点过程模型与快速序列采样的实际需求之间的鸿沟。", "translation": "我们提出了TPP-SD，一种新颖的方法，通过将语言模型中的推测解码（SD）技术应用于Transformer时间点过程（TPP）采样来加速其过程。通过识别TPP的稀疏算法与语言模型的推测解码之间的结构相似性，我们开发了一个高效的采样框架，该框架利用一个较小的草稿模型生成多个候选事件，然后由较大的目标模型并行验证。TPP-SD在保持与自回归采样相同输出分布的同时，实现了显著加速。在合成数据集和真实数据集上的实验表明，我们的方法生成的样本与标准方法具有相同的分布，但速度提高了2-6倍。我们的消融研究分析了草稿长度和草稿模型大小等超参数对采样效率的影响。TPP-SD弥合了强大的Transformer TPP模型与快速序列采样的实际需求之间的鸿沟。", "summary": "TPP-SD是一种新颖的方法，它将语言模型中的推测解码技术应用于Transformer时间点过程（TPP）采样，以实现显著加速。通过利用小型草稿模型生成候选事件并由大型目标模型并行验证，TPP-SD在保持与自回归采样相同输出分布的同时，实现了2-6倍的速度提升。这项工作通过解决采样效率瓶颈，使强大的Transformer TPP模型更具实用性。", "keywords": "Transformer, 点过程, 推测解码, 采样, 加速", "comments": "这项工作的创新之处在于巧妙地将语言模型领域的推测解码技术迁移并应用于时间点过程（TPP）采样，解决了Transformer TPP模型在实际应用中面临的采样速度瓶颈。这种跨领域的技术融合不仅提高了效率，而且确保了采样结果的分布与传统方法一致，极大地提升了这些强大模型的实用性。"}}
{"id": "2507.23177", "title": "InterfO-RAN: Real-Time In-band Cellular Uplink Interference Detection with GPU-Accelerated dApps", "authors": ["Neagin Neasamoni Santhi", "Davide Villa", "Michele Polese", "Tommaso Melodia"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      10 pages, 12 figures, 3 tables", "url": "http://arxiv.org/abs/2507.23177v1", "summary": "Ultra-dense fifth generation (5G) and beyond networks leverage spectrum\nsharing and frequency reuse to enhance throughput, but face unpredictable\nin-band uplink (UL) interference challenges that significantly degrade Signal\nto Interference plus Noise Ratio (SINR) at affected Next Generation Node Bases\n(gNBs). This is particularly problematic at cell edges, where overlapping\nregions force User Equipments (UEs) to increase transmit power, and in\ndirectional millimeter wave systems, where beamforming sidelobes can create\nunexpected interference. The resulting signal degradation disrupts protocol\noperations, including scheduling and resource allocation, by distorting quality\nindicators like Reference Signal Received Power (RSRP) and Received Signal\nStrength Indicator (RSSI), and can compromise critical functions such as\nchannel state reporting and Hybrid Automatic Repeat Request (HARQ)\nacknowledgments. To address this problem, this article introduces InterfO-RAN,\na real-time programmable solution that leverages a Convolutional Neural Network\n(CNN) to process In-phase and Quadrature (I/Q) samples in the gNB physical\nlayer, detecting in-band interference with accuracy exceeding 91% in under 650\nus. InterfO-RAN represents the first O-RAN dApp accelerated on Graphics\nProcessing Unit (GPU), coexisting with the 5G NR physical layer processing of\nNVIDIA Aerial. Deployed in an end-to-end private 5G network with commercial\nRadio Units (RUs) and smartphones, our solution was trained and tested on more\nthan 7 million NR UL slots collected from real-world environments,\ndemonstrating robust interference detection capabilities essential for\nmaintaining network performance in dense deployments.", "comment": "10 pages, 12 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.23177v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "InterfO-RAN: 实时带内蜂窝上行干扰检测与GPU加速dApp", "tldr": "InterfO-RAN使用GPU加速的CNN实时检测5G网络中的带内上行干扰，准确率超过91%。", "motivation": "超密集5G及未来网络中，频谱共享和频率复用导致不可预测的带内上行干扰，显著降低SINR，尤其在小区边缘和毫米波系统中，影响协议操作和关键功能。", "method": "本文引入了InterfO-RAN，一个实时可编程解决方案，它利用卷积神经网络（CNN）处理gNB物理层中的I/Q样本来检测带内干扰。InterfO-RAN是第一个在GPU上加速的O-RAN dApp，与NVIDIA Aerial的5G NR物理层处理共存。该解决方案部署在具有商用无线电单元和智能手机的端到端私有5G网络中，并使用从真实世界环境中收集的超过700万个NR UL时隙进行训练和测试。", "result": "InterfO-RAN在650微秒内检测带内干扰，准确率超过91%。在实际环境中训练和测试，展示出强大的干扰检测能力。", "conclusion": "InterfO-RAN提供了一种鲁棒的实时带内上行干扰检测能力，对于在密集部署中维持网络性能至关重要。", "translation": "超密集第五代（5G）及未来网络利用频谱共享和频率复用以提高吞吐量，但面临不可预测的带内上行（UL）干扰挑战，这些挑战会显著降低受影响的下一代节点基站（gNB）的信号干扰加噪声比（SINR）。这在小区边缘尤其成问题，重叠区域迫使用户设备（UE）增加发射功率，在定向毫米波系统中，波束成形旁瓣会产生意外干扰。由此导致的信号质量下降会通过扭曲参考信号接收功率（RSRP）和接收信号强度指示（RSSI）等质量指标来扰乱协议操作，包括调度和资源分配，并可能损害信道状态报告和混合自动重传请求（HARQ）确认等关键功能。为了解决这个问题，本文引入了InterfO-RAN，一个实时可编程解决方案，它利用卷积神经网络（CNN）处理gNB物理层中的同相和正交（I/Q）样本，在650微秒内以超过91%的准确率检测带内干扰。InterfO-RAN是第一个在图形处理单元（GPU）上加速的O-RAN dApp，与NVIDIA Aerial的5G NR物理层处理共存。我们的解决方案部署在具有商用无线电单元（RU）和智能手机的端到端私有5G网络中，并使用从真实世界环境中收集的超过700万个NR UL时隙进行训练和测试，展示了强大的干扰检测能力，这对于在密集部署中维持网络性能至关重要。", "summary": "本文介绍了InterfO-RAN，一个针对5G及未来网络中普遍存在的带内上行干扰的实时检测解决方案。该方案利用GPU加速的卷积神经网络处理gNB物理层的I/Q样本，实现了在650微秒内超过91%的干扰检测准确率。InterfO-RAN是首个在GPU上加速的O-RAN dApp，并已在实际5G网络中通过大量真实数据进行验证，证明其能有效维持密集部署下的网络性能。", "keywords": "5G, 干扰检测, O-RAN, 卷积神经网络, GPU加速", "comments": "InterfO-RAN的创新之处在于将GPU加速的CNN应用于O-RAN架构中进行实时带内干扰检测，这是第一个实现此类集成的dApp。其在实际网络环境中使用大量真实数据进行训练和验证，增强了方案的实用性和鲁棒性。该方案对于解决5G超密集部署中关键的干扰问题具有重要意义，有助于提升网络性能和可靠性。"}}
{"id": "2507.22931", "title": "Enhancing RAG Efficiency with Adaptive Context Compression", "authors": ["Shuyu Guo", "Zhaochun Ren"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22931v1", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nwith external knowledge but incurs significant inference costs due to lengthy\nretrieved contexts. While context compression mitigates this issue, existing\nmethods apply fixed compression rates, over-compressing simple queries or\nunder-compressing complex ones. We propose Adaptive Context Compression for RAG\n(ACC-RAG), a framework that dynamically adjusts compression rates based on\ninput complexity, optimizing inference efficiency without sacrificing accuracy.\nACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with\na context selector to retain minimal sufficient information, akin to human\nskimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms\nfixed-rate methods and matches/unlocks over 4 times faster inference versus\nstandard RAG while maintaining or improving accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22931v1", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-24", "AI": {"title_translation": "通过自适应上下文压缩提升RAG效率", "tldr": "RAG因长上下文导致推理成本高。现有压缩方法固定比率不佳。本文提出ACC-RAG，根据输入复杂度动态调整压缩率，提高效率并保持准确性，比传统RAG快4倍以上。", "motivation": "检索增强生成（RAG）虽然通过外部知识增强了大型语言模型（LLM），但由于检索到的上下文过长，会产生显著的推理成本。现有上下文压缩方法采用固定的压缩率，导致对简单查询过度压缩或对复杂查询压缩不足。", "method": "本文提出了RAG的自适应上下文压缩（ACC-RAG）框架，该框架结合了分层压缩器（用于多粒度嵌入）和上下文选择器，根据输入复杂度动态调整压缩率，以保留最少但足够的信息，类似于人类的快速阅读。", "result": "在Wikipedia和五个问答数据集上进行评估，ACC-RAG优于固定速率方法，并且与标准RAG相比，推理速度提高了4倍以上，同时保持或提高了准确性。", "conclusion": "ACC-RAG通过根据输入复杂度动态调整上下文压缩率，显著提高了检索增强生成（RAG）的推理效率，同时保持或提升了准确性，解决了现有固定压缩率方法的不足。", "translation": "检索增强生成（RAG）通过外部知识增强大型语言模型（LLM），但由于检索到的上下文过长，会产生显著的推理成本。虽然上下文压缩可以缓解这个问题，但现有方法采用固定的压缩率，对简单查询过度压缩，或对复杂查询不足。我们提出了RAG的自适应上下文压缩（ACC-RAG），这是一个根据输入复杂度动态调整压缩率的框架，在不牺牲准确性的情况下优化推理效率。ACC-RAG结合了分层压缩器（用于多粒度嵌入）和上下文选择器，以保留最少但足够的信息，类似于人类的快速阅读。在Wikipedia和五个问答数据集上进行评估，ACC-RAG优于固定速率方法，并且与标准RAG相比，推理速度提高了4倍以上，同时保持或提高了准确性。", "summary": "本文提出了ACC-RAG，一种针对检索增强生成（RAG）的自适应上下文压缩框架。它解决了RAG因长上下文导致的推理成本高昂问题，通过根据输入复杂度动态调整压缩率来优化效率并保持准确性。ACC-RAG结合了分层压缩器和上下文选择器，以智能地保留关键信息。实验结果表明，ACC-RAG在推理速度上比传统RAG快四倍以上，同时保持或提高了准确性，并优于固定速率的压缩方法。", "keywords": "RAG, 上下文压缩, 效率, 自适应, 大型语言模型", "comments": "该论文的创新点在于提出了动态调整上下文压缩率的方法，解决了现有固定压缩率方法的局限性。通过模拟人类快速阅读的方式，智能地保留关键信息，显著提升了RAG的效率而不牺牲准确性，具有重要的实际应用价值。"}}
{"id": "2507.23695", "title": "On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model", "authors": ["Mouli Chakraborty", "Subhash Chandra", "Avishek Nag", "Anshu Mukherjee"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23695v1", "summary": "We present a comparative study of the Gaussian mixture model (GMM) and the\nDeep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite\nquantum channel capacity, considering hybrid quantum noise (HQN) and\ntransmission constraints. While GMM is simple and interpretable, DAGMM better\ncaptures non-linear variations and noise distributions. Simulations show that\nDAGMM provides tighter capacity bounds and improved clustering. This introduces\nthe Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum\ndata analysis in quantum satellite communication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23695v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "深度自编码高斯混合模型在卫星量子通信信道可达速率上的应用", "tldr": "本文比较了GMM和DAGMM在估计卫星量子信道容量方面的表现，并引入了DCGMM。", "motivation": "旨在估计卫星量子信道容量，同时考虑混合量子噪声（HQN）和传输限制。", "method": "本文对高斯混合模型（GMM）和深度自编码高斯混合模型（DAGMM）进行了比较研究，用于估计卫星量子信道容量，并在此基础上引入了深度聚类高斯混合模型（DCGMM）用于高维量子数据分析。", "result": "仿真结果表明，DAGMM 提供了更紧密的容量界限和改进的聚类效果。", "conclusion": "引入了深度聚类高斯混合模型（DCGMM）以应对量子卫星通信中的高维量子数据分析挑战。", "translation": "我们对高斯混合模型（GMM）和深度自编码高斯混合模型（DAGMM）进行了比较研究，用于估计卫星量子信道容量，同时考虑混合量子噪声（HQN）和传输限制。虽然 GMM 简单且易于解释，但 DAGMM 能更好地捕获非线性变化和噪声分布。仿真结果表明，DAGMM 提供了更紧密的容量界限和改进的聚类效果。这引入了深度聚类高斯混合模型（DCGMM），用于量子卫星通信中的高维量子数据分析。", "summary": "本文比较了传统高斯混合模型（GMM）和深度自编码高斯混合模型（DAGMM）在估计考虑混合量子噪声和传输限制的卫星量子信道容量方面的性能。研究发现，DAGMM 在捕获非线性变化和噪声分布方面表现更优，并能提供更紧密的容量界限和更好的聚类效果。基于此，论文引入了深度聚类高斯混合模型（DCGMM）以应对量子卫星通信中的高维量子数据分析挑战。", "keywords": "卫星量子通信, 深度自编码高斯混合模型, 信道容量, 混合量子噪声, 高维数据分析", "comments": "本文的创新之处在于将深度学习模型（DAGMM和DCGMM）应用于卫星量子通信信道容量的估计和高维量子数据分析，这为处理复杂的量子噪声和非线性问题提供了新的视角和更精确的工具。"}}
{"id": "2411.06254", "title": "KeyB2: Selecting Key Blocks is Also Important for Long Document Ranking with Large Language Models", "authors": ["Minghan Li", "Eric Gaussier", "Juntao Li", "Guodong Zhou"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.06254v2", "summary": "The emergence of large language models (LLMs) such as Llama has significantly\nadvanced neural information retrieval (IR). However, applying LLMs to long\ndocument reranking remains computationally expensive and may be ineffective.\nMoreover, the internal behavior of LLMs during document relevance judgment is\nstill underexplored. In this paper, we begin with an in-depth analysis of\ndecoder-only LLM attention patterns and find that several attention heads\nconsistently align with relevance signals, yet this alignment deteriorates as\nirrelevant content increases. Motivated by this observation, we revisit and\nextend the block selection paradigm, introducing KeyB2, a scalable reranking\nframework that combines block pre-selection with powerful decoder-only LLMs.\nKeyB2 generalizes the selection stage to support BM25, cross-encoder, and\nbi-encoder, and adapts LLM to compute fine-grained relevance scores. We further\nintroduce a new bi-encoder strategy that performs strongly and efficiently.\nExtensive experiments on TREC DL 2019/2023 document task, Robust04, and MLDR-zh\ndemonstrate that KeyB2 outperforms baselines including RankLLaMA,\nRankLLaMA-MaxP/AvgP, and KeyB, achieving new state-of-the-art (SOTA) results on\nTREC DL 2019 document reranking task. In addition, KeyB2 reduces reranking\nlatency compared with RankLLaMA by over 83% and memory usage by over 74%,\npositioning it as a practical and effective solution for long document ranking\nwith LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.06254v2", "cate": "cs.IR", "date": "2024-11-09", "updated": "2025-07-31", "AI": {"title_translation": "KeyB2：选择关键块对于使用大型语言模型进行长文档排序也很重要", "tldr": "KeyB2是一个结合块预选择和大型语言模型的框架，用于高效准确的长文档重排序，显著优于现有基线并降低了计算成本。", "motivation": "大型语言模型（LLM）在信息检索中表现出色，但应用于长文档重排序时计算成本高昂且可能无效。此外，LLM在文档相关性判断中的内部行为未被充分探索，且发现LLM注意力模式在不相关内容增加时会恶化。", "method": "本文提出了KeyB2框架，一个可扩展的重排序框架，它将块预选择与强大的仅解码器LLM相结合。KeyB2将选择阶段泛化以支持BM25、交叉编码器和双编码器，并使LLM适应于计算细粒度的相关性分数。此外，还引入了一种新的高效双编码器策略。", "result": "KeyB2在TREC DL 2019/2023文档任务、Robust04和MLDR-zh上的实验表明，它优于包括RankLLaMA在内的基线，在TREC DL 2019文档重排序任务上取得了新的最先进（SOTA）结果。与RankLLaMA相比，KeyB2将重排序延迟降低了83%以上，内存使用降低了74%以上。", "conclusion": "KeyB2是使用大型语言模型进行长文档排序的实用且有效的解决方案。", "translation": "大型语言模型（LLM）的出现，如Llama，显著推动了神经信息检索（IR）的发展。然而，将LLM应用于长文档重排序仍然计算成本高昂且可能效率低下。此外，LLM在文档相关性判断过程中的内部行为仍未得到充分探索。在本文中，我们首先对仅解码器LLM的注意力模式进行了深入分析，发现一些注意力头始终与相关性信号对齐，但这种对齐随着不相关内容的增加而恶化。受此观察启发，我们重新审视并扩展了块选择范式，引入了KeyB2，这是一个可扩展的重排序框架，它将块预选择与强大的仅解码器LLM相结合。KeyB2将选择阶段泛化以支持BM25、交叉编码器和双编码器，并使LLM适应于计算细粒度的相关性分数。我们进一步引入了一种新的双编码器策略，该策略表现出色且高效。在TREC DL 2019/2023文档任务、Robust04和MLDR-zh上的大量实验表明，KeyB2优于包括RankLLaMA、RankLLaMA-MaxP/AvgP和KeyB在内的基线，在TREC DL 2019文档重排序任务上取得了新的最先进（SOTA）结果。此外，与RankLLaMA相比，KeyB2将重排序延迟降低了83%以上，内存使用降低了74%以上，使其成为使用LLM进行长文档排序的实用且有效的解决方案。", "summary": "本文提出了KeyB2，一个用于长文档重排序的可扩展框架。通过对LLM注意力模式的深入分析，发现不相关内容会降低相关性信号的对齐。KeyB2结合了块预选择（支持多种方法）和强大的解码器LLM，以实现细粒度的相关性评分，并引入了高效的双编码器策略。实验证明，KeyB2在多个数据集上优于现有基线，并显著降低了计算成本和内存使用，是使用LLM进行长文档排序的实用且高效的最先进解决方案。", "keywords": "长文档排序, 大型语言模型, 块选择, 信息检索, KeyB2", "comments": "本文创新性地将块预选择范式与大型语言模型相结合，以解决长文档重排序的效率和有效性问题。通过深入分析LLM的注意力模式，为模型设计提供了理论依据。KeyB2不仅提升了性能，还大幅降低了计算资源消耗，这对于LLM在实际信息检索系统中的应用具有重要意义。其模块化的设计（支持多种预选择器）也增加了其灵活性。"}}
{"id": "2503.01199", "title": "LiteGS: A High-performance Framework to Train 3DGS in Subminutes via System and Algorithm Codesign", "authors": ["Kaimin Liao", "Hua Wang", "Zhi Chen", "Luchao Wang", "Yaohua Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01199v2", "summary": "3D Gaussian Splatting (3DGS) has emerged as promising alternative in 3D\nrepresentation. However, it still suffers from high training cost. This paper\nintroduces LiteGS, a high performance framework that systematically optimizes\nthe 3DGS training pipeline from multiple aspects. At the low-level computation\nlayer, we design a ``warp-based raster'' associated with two hardware-aware\noptimizations to significantly reduce gradient reduction overhead. At the\nmid-level data management layer, we introduce dynamic spatial sorting based on\nMorton coding to enable a performant ``Cluster-Cull-Compact'' pipeline and\nimprove data locality, therefore reducing cache misses. At the top-level\nalgorithm layer, we establish a new robust densification criterion based on the\nvariance of the opacity gradient, paired with a more stable opacity control\nmechanism, to achieve more precise parameter growth. Experimental results\ndemonstrate that LiteGS accelerates the original 3DGS training by up to 13.4x\nwith comparable or superior quality and surpasses the current SOTA in\nlightweight models by up to 1.4x speedup. For high-quality reconstruction\ntasks, LiteGS sets a new accuracy record and decreases the training time by an\norder of magnitude.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01199v2", "cate": "cs.CV", "date": "2025-03-03", "updated": "2025-07-31", "AI": {"title_translation": "LiteGS：一种通过系统和算法协同设计在几分钟内训练3DGS的高性能框架", "tldr": "LiteGS是一个高性能框架，通过系统和算法协同设计，显著降低了3D Gaussian Splatting (3DGS) 的训练成本，实现了亚分钟级的训练时间，并提高了重建质量。", "motivation": "3D Gaussian Splatting (3DGS) 在3D表示方面前景广阔，但其训练成本高昂。", "method": "LiteGS从多个方面优化了3DGS训练流程。在底层计算层，设计了“基于warp的栅格化”并结合两项硬件感知优化，以显著减少梯度归约开销。在中层数据管理层，引入了基于Morton码的动态空间排序，实现了高效的“聚类-剔除-压缩”管线，改善了数据局部性并减少了缓存未命中。在顶层算法层，建立了一种基于不透明度梯度方差的鲁棒性新的密集化准则，并结合更稳定的不透明度控制机制，以实现更精确的参数增长。", "result": "实验结果表明，LiteGS将原始3DGS训练速度提升高达13.4倍，同时保持或超越了原有质量；在轻量级模型中，其速度比当前最先进技术快1.4倍。对于高质量重建任务，LiteGS创造了新的精度记录，并将训练时间缩短了一个数量级。", "conclusion": "LiteGS通过系统和算法协同设计，显著提高了3DGS的训练效率和重建质量，使其能够在亚分钟内完成训练，并为高质量重建设定了新标准。", "translation": "3D Gaussian Splatting (3DGS) 已成为3D表示领域一项有前景的替代方案。然而，它仍然面临高昂的训练成本。本文介绍了LiteGS，一个高性能框架，系统性地从多个方面优化了3DGS训练管线。在底层计算层，我们设计了一种“基于warp的栅格化”并结合两项硬件感知优化，以显著减少梯度归约开销。在中层数据管理层，我们引入了基于Morton码的动态空间排序，以实现高性能的“聚类-剔除-压缩”管线并提高数据局部性，从而减少缓存未命中。在顶层算法层，我们建立了一种基于不透明度梯度方差的新的鲁棒密集化准则，并结合更稳定的不透明度控制机制，以实现更精确的参数增长。实验结果表明，LiteGS将原始3DGS训练速度提升高达13.4倍，同时保持或超越了原有质量，并且在轻量级模型中其速度比当前最先进技术快1.4倍。对于高质量重建任务，LiteGS创造了新的精度记录，并将训练时间缩短了一个数量级。", "summary": "LiteGS是一个旨在解决3D Gaussian Splatting (3DGS) 高训练成本问题的高性能框架。它通过系统和算法协同设计，在三个层面进行优化：底层计算层采用“基于warp的栅格化”和硬件感知优化减少梯度归约开销；中层数据管理层利用基于Morton码的动态空间排序实现高效的数据管线并提升数据局部性；顶层算法层引入基于不透明度梯度方差的密集化准则和稳定不透明度控制。这些优化使得LiteGS能将3DGS训练速度提升高达13.4倍，在轻量级模型中超越SOTA，并为高质量重建任务设定了新的精度和训练时间记录，实现了亚分钟级训练。", "keywords": "3D Gaussian Splatting, 高性能计算, 系统优化, 算法协同设计, 实时渲染", "comments": "LiteGS的创新之处在于其全面的系统和算法协同设计方法，从计算、数据管理到算法层面进行了深度优化。这种分层优化策略有效解决了3DGS训练效率低下的核心问题，显著提升了训练速度和模型质量，尤其在实现亚分钟级训练和高质量重建方面表现突出，对3D表示领域具有重要意义。"}}
{"id": "2507.23229", "title": "Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation", "authors": ["Yufei Chen", "Yao Wang", "Haibin Zhang", "Tao Gu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23229v1", "summary": "Retrieval-augmented generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge bases, but this advancement introduces\nsignificant privacy risks. Existing privacy attacks on RAG systems can trigger\ndata leakage but often fail to accurately isolate knowledge-base-derived\nsentences within mixed responses. They also lack robustness when applied across\nmultiple domains. This paper addresses these challenges by presenting a novel\nblack-box attack framework that exploits knowledge asymmetry between RAG and\nstandard LLMs to achieve fine-grained privacy extraction across heterogeneous\nknowledge landscapes. We propose a chain-of-thought reasoning strategy that\ncreates adaptive prompts to steer RAG systems away from sensitive content.\nSpecifically, we first decompose adversarial queries to maximize information\ndisparity and then apply a semantic relationship scoring to resolve lexical and\nsyntactic ambiguities. We finally train a neural network on these feature\nscores to precisely identify sentences containing private information. Unlike\nprior work, our framework generalizes to unseen domains through iterative\nrefinement without pre-defined knowledge. Experimental results show that we\nachieve over 91% privacy extraction rate in single-domain and 83% in\nmulti-domain scenarios, reducing sensitive sentence exposure by over 65% in\ncase studies. This work bridges the gap between attack and defense in RAG\nsystems, enabling precise extraction of private information while providing a\nfoundation for adaptive mitigation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23229v1", "cate": "cs.CR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "细粒度隐私提取：通过知识不对称利用从检索增强生成系统中提取隐私", "tldr": "本文提出了一种新的黑盒攻击框架，通过利用RAG和标准LLM之间的知识不对称性，实现对RAG系统中细粒度隐私信息的提取。", "motivation": "检索增强生成（RAG）系统虽然增强了大型语言模型（LLMs），但也引入了显著的隐私风险。现有隐私攻击方法在隔离知识库衍生的敏感句子方面不够精确，且在跨多个领域应用时缺乏鲁棒性。", "method": "本文提出了一个新颖的黑盒攻击框架，通过利用RAG系统和标准LLM之间的知识不对称性来实现细粒度隐私提取。该框架采用了一种思维链推理策略，通过创建自适应提示来引导RAG系统远离敏感内容。具体方法包括：首先分解对抗性查询以最大化信息差异；然后应用语义关系评分来解决词汇和句法歧义；最后训练一个神经网络，根据这些特征分数精确识别包含私有信息的句子。该框架通过迭代细化，无需预定义知识即可泛化到未见领域。", "result": "实验结果表明，在单领域场景中实现了超过91%的隐私提取率，在多领域场景中达到了83%，并在案例研究中将敏感句子暴露减少了65%以上。", "conclusion": "这项工作弥合了RAG系统攻击与防御之间的鸿沟，实现了私有信息的精确提取，并为RAG系统的自适应缓解提供了基础。", "translation": "检索增强生成（RAG）系统通过整合外部知识库来增强大型语言模型（LLMs），但这种进步也带来了显著的隐私风险。现有针对RAG系统的隐私攻击可以触发数据泄露，但通常无法在混合响应中准确隔离知识库衍生的句子。它们在应用于多个领域时也缺乏鲁棒性。本文通过提出一种新颖的黑盒攻击框架来解决这些挑战，该框架利用RAG和标准LLM之间的知识不对称性，在异构知识环境中实现细粒度隐私提取。我们提出了一种思维链推理策略，通过创建自适应提示来引导RAG系统远离敏感内容。具体来说，我们首先分解对抗性查询以最大化信息差异，然后应用语义关系评分来解决词汇和句法歧义。我们最终在这些特征分数上训练一个神经网络，以精确识别包含私人信息的句子。与以往的工作不同，我们的框架通过迭代细化推广到未见领域，无需预定义知识。实验结果表明，我们在单领域场景中实现了超过91%的隐私提取率，在多领域场景中达到了83%，在案例研究中敏感句子暴露减少了65%以上。这项工作弥合了RAG系统攻击与防御之间的鸿沟，实现了私有信息的精确提取，同时为自适应缓解提供了基础。", "summary": "本文提出了一个新颖的黑盒攻击框架，旨在从检索增强生成（RAG）系统中进行细粒度隐私提取。该框架利用RAG与标准大型语言模型之间的知识不对称性，通过分解对抗性查询、语义关系评分和神经网络训练来精确识别包含隐私信息的句子。与现有方法不同，它在多领域和未见领域中表现出鲁棒性。实验证明，该方法在单领域和多领域场景下均能实现高隐私提取率，并显著减少敏感信息暴露，为RAG系统的隐私防御提供了基础。", "keywords": "隐私提取, 检索增强生成, 知识不对称, 黑盒攻击, 大型语言模型", "comments": "这项工作创新性地利用了RAG系统与标准LLM之间的知识不对称性来实施细粒度隐私提取攻击，弥补了现有攻击在精确性、鲁棒性和泛化性上的不足。其提出的思维链推理策略和无需预定义知识的迭代细化能力是亮点，为理解RAG系统的潜在隐私漏洞和开发更有效的防御机制提供了重要视角。"}}
{"id": "2503.21813", "title": "OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching", "authors": ["Zhangcheng Qiang", "Kerry Taylor", "Weiqing Wang", "Jing Jiang"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      14 pages, 4 figures, 4 tables, 2 prompt templates", "url": "http://arxiv.org/abs/2503.21813v3", "summary": "Hallucinations are often inevitable in downstream tasks using large language\nmodels (LLMs). To tackle the substantial challenge of addressing hallucinations\nfor LLM-based ontology matching (OM) systems, we introduce a new benchmark\ndataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the\nOntology Alignment Evaluation Initiative (OAEI), capturing hallucinations of\nten different LLMs performing OM tasks. These OM-specific hallucinations are\norganised into two primary categories and six sub-categories. We showcase the\nusefulness of the dataset in constructing an LLM leaderboard for OM tasks and\nfor fine-tuning LLMs used in OM tasks.", "comment": "14 pages, 4 figures, 4 tables, 2 prompt templates", "pdf_url": "http://arxiv.org/pdf/2503.21813v3", "cate": "cs.CL", "date": "2025-03-25", "updated": "2025-05-14", "AI": {"title_translation": "OAEI-LLM-T：一个用于理解本体匹配中大型语言模型幻觉的TBox基准数据集", "tldr": "本文介绍了一个新的基准数据集OAEI-LLM-T，用于评估和解决大型语言模型在本体匹配任务中的幻觉问题。", "motivation": "大型语言模型（LLMs）在下游任务中经常出现幻觉，为了解决基于LLM的本体匹配（OM）系统中处理幻觉的巨大挑战。", "method": "引入了一个新的基准数据集OAEI-LLM-T。该数据集源自本体对齐评估倡议（OAEI）中的七个TBox数据集，捕捉了十个不同LLM执行OM任务时的幻觉。这些OM特有的幻觉被组织成两个主要类别和六个子类别。", "result": "该数据集可用于构建OM任务的LLM排行榜，以及用于微调OM任务中使用的LLM。", "conclusion": "该数据集在构建LLM排行榜和微调用于本体匹配任务的LLM方面展示了其有用性，有助于解决LLM在本体匹配中的幻觉问题。", "translation": "大型语言模型（LLMs）在下游任务中经常出现幻觉，这是不可避免的。为了解决基于LLM的本体匹配（OM）系统中处理幻觉的巨大挑战，我们引入了一个新的基准数据集OAEI-LLM-T。该数据集源自本体对齐评估倡议（OAEI）中的七个TBox数据集，捕捉了十个不同LLM执行OM任务时的幻觉。这些OM特有的幻觉被组织成两个主要类别和六个子类别。我们展示了该数据集在构建OM任务的LLM排行榜和微调用于OM任务的LLM方面的有用性。", "summary": "本文提出了OAEI-LLM-T，一个专门用于评估和缓解大型语言模型在本体匹配任务中幻觉的TBox基准数据集。该数据集整合了OAEI的七个TBox数据集，并对十个LLM产生的本体匹配相关幻觉进行了分类。研究表明，该数据集对于建立LLM在本体匹配领域的性能排行榜和进行模型微调具有重要价值。", "keywords": "大型语言模型, 本体匹配, 幻觉, 基准数据集, OAEI-LLM-T", "comments": "本文的创新之处在于专门构建了一个用于研究和解决LLM在本体匹配任务中幻觉的基准数据集。这对于提高LLM在本体匹配领域的可靠性和准确性至关重要，为后续的LLM微调和性能评估提供了标准化的工具。"}}
{"id": "2412.20451", "title": "CoA-VLA: Improving Vision-Language-Action Models via Visual-Textual Chain-of-Affordance", "authors": ["Jinming Li", "Yichen Zhu", "Zhibin Tang", "Junjie Wen", "Minjie Zhu", "Xiaoyu Liu", "Chengmeng Li", "Ran Cheng", "Yaxin Peng", "Yan Peng", "Feifei Feng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Project webpage is available at this https URL", "url": "http://arxiv.org/abs/2412.20451v2", "summary": "Robot foundation models, particularly Vision-Language-Action (VLA) models,\nhave garnered significant attention for their ability to enhance robot policy\nlearning, greatly improving robot's generalization and robustness. OpenAI's\nrecent model, O1, showcased impressive capabilities in solving complex problems\nby utilizing extensive reasoning chains. This prompts an important question:\ncan robot models achieve better performance in multi-task , complex\nenvironments by reviewing prior observations and then providing task-specific\nreasoning to guide action prediction? In this paper, we introduce\nChain-of-Affordance (CoA-VLA) , a novel approach to scaling robot models by\nincorporating reasoning in the format of sequential robot affordances to\nfacilitate task completion. Specifically, we prompt the model to consider the\nfollowing four types of affordances before taking action: (1) object affordance\n- what object to manipulate and where it is ; (2) grasp affordance - the\nspecific object part to grasp ; (3) spatial affordance - the optimal space to\nplace the object ; and (4) movement affordance-the collision - free path for\nmovement. We further transform each affordance into two prompting formats:\nvisual affordance and textual affordance. We introduce a novel vision-language\nco-injection module that integrates this knowledge into the policy network.\nThis allows the robot to leverage essential contextual information during\naction inference, resulting in improved precision and robustness. Our\nexperiments demonstrate that CoA-VLA outperforms state-of-the-art robot\nfoundation models, including OpenVLA and Octo, on a variety of tasks.\nFurthermore, CoA-VLA exhibits strong generalization capabilities, including\nrecognizing unseen object poses, identifying free space, and avoiding obstacles\nin novel environments.", "comment": "Project webpage is available at https://chain-of-affordance.github.io", "pdf_url": "http://arxiv.org/pdf/2412.20451v2", "cate": "cs.RO", "date": "2024-12-29", "updated": "2025-07-31", "AI": {"title_translation": "CoA-VLA：通过视觉-文本联结示能改进视觉-语言-动作模型", "tldr": "引入CoA-VLA，一种通过视觉-文本联结示能来改进机器人视觉-语言-动作 (VLA) 模型的新方法，使其在多任务复杂环境中表现更优，泛化能力更强。", "motivation": "机器人基础模型（特别是VLA模型）在增强机器人策略学习、提高泛化性和鲁棒性方面引起了广泛关注。受OpenAI O1模型利用推理链解决复杂问题的启发，本文旨在探索机器人模型是否能通过回顾先前的观察并提供任务特定推理来指导动作预测，从而在多任务、复杂环境中获得更好的性能。", "method": "引入了Chain-of-Affordance (CoA-VLA) 方法，通过将顺序机器人示能的推理整合到模型中以促进任务完成。具体地，模型在执行动作前会考虑四种示能：物体示能、抓取示能、空间示能和运动示能。每种示能都被转化为视觉示能和文本示能两种提示格式。此外，引入了一个新颖的视觉-语言协同注入模块，将这些知识整合到策略网络中。", "result": "CoA-VLA在各种任务上超越了最先进的机器人基础模型，包括OpenVLA和Octo。CoA-VLA还展现了强大的泛化能力，包括识别未见过的物体姿态、识别自由空间以及在新型环境中避开障碍物。", "conclusion": "通过引入视觉-文本联结示能（Chain-of-Affordance），CoA-VLA显著提高了机器人视觉-语言-动作模型的性能、精度、鲁棒性和泛化能力，使其在复杂多任务环境中表现更优。", "translation": "机器人基础模型，特别是视觉-语言-动作（VLA）模型，因其增强机器人策略学习、大幅提高机器人泛化能力和鲁棒性的能力而受到广泛关注。OpenAI 最近的模型O1通过利用广泛的推理链在解决复杂问题方面展示了令人印象深刻的能力。这引发了一个重要问题：机器人模型能否通过回顾先前的观察并提供任务特定推理来指导动作预测，从而在多任务、复杂环境中获得更好的性能？在本文中，我们引入了联结示能（Chain-of-Affordance，CoA-VLA），这是一种通过结合顺序机器人示能形式的推理来促进任务完成的新型扩展机器人模型的方法。具体来说，我们提示模型在采取行动之前考虑以下四种示能：(1) 物体示能——操纵什么物体以及它在哪里；(2) 抓取示能——要抓取的特定物体部分；(3) 空间示能——放置物体的最佳空间；以及(4) 运动示能——无碰撞的移动路径。我们进一步将每种示能转换为两种提示格式：视觉示能和文本示能。我们引入了一种新颖的视觉-语言协同注入模块，将这些知识整合到策略网络中。这使得机器人在动作推断过程中能够利用重要的上下文信息，从而提高了精度和鲁棒性。我们的实验表明，CoA-VLA在各种任务上优于最先进的机器人基础模型，包括OpenVLA和Octo。此外，CoA-VLA展现了强大的泛化能力，包括识别未见过的物体姿态、识别自由空间以及在新型环境中避开障碍物。", "summary": "本文提出了CoA-VLA，一种通过引入视觉-文本联结示能来改进视觉-语言-动作 (VLA) 机器模型的创新方法。该方法在机器人执行动作前，引导模型考虑物体、抓取、空间和运动四种示能，并将其转化为视觉和文本提示，通过视觉-语言协同注入模块整合到策略网络中。实验证明CoA-VLA在多任务和复杂环境中优于现有SOTA模型，显著提升了机器人的精度、鲁棒性及泛化能力，包括处理未见物体和新环境。", "keywords": "机器人基础模型, 视觉-语言-动作模型, 示能, 推理链, 泛化能力", "comments": "CoA-VLA的创新之处在于其将“示能”（affordance）的概念系统化地整合到VLA模型中，并将其分解为视觉和文本两种提示格式。通过引入视觉-语言协同注入模块，有效地利用了上下文信息，提升了机器人决策的精确性和鲁棒性。这种基于推理链的示能方法为机器人基础模型在复杂环境中的泛化和多任务处理能力提供了新的SOTA解决方案。"}}
{"id": "2507.23129", "title": "MRpro - open PyTorch-based MR reconstruction and processing package", "authors": ["Felix Frederik Zimmermann", "Patrick Schuenke", "Christoph S. Aigner", "Bill A. Bernhardt", "Mara Guastini", "Johannes Hammacher", "Noah Jaitner", "Andreas Kofler", "Leonid Lunin", "Stefan Martin", "Catarina Redshaw Kranich", "Jakob Schattenfroh", "David Schote", "Yanglei Wu", "Christoph Kolbitsch"], "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted to Magnetic Resonance in Medicine", "url": "http://arxiv.org/abs/2507.23129v1", "summary": "We introduce MRpro, an open-source image reconstruction package built upon\nPyTorch and open data formats. The framework comprises three main areas. First,\nit provides unified data structures for the consistent manipulation of MR\ndatasets and their associated metadata (e.g., k-space trajectories). Second, it\noffers a library of composable operators, proximable functionals, and\noptimization algorithms, including a unified Fourier operator for all common\ntrajectories and an extended phase graph simulation for quantitative MR. These\ncomponents are used to create ready-to-use implementations of key\nreconstruction algorithms. Third, for deep learning, MRpro includes essential\nbuilding blocks such as data consistency layers, differentiable optimization\nlayers, and state-of-the-art backbone networks and integrates public datasets\nto facilitate reproducibility. MRpro is developed as a collaborative project\nsupported by automated quality control. We demonstrate the versatility of MRpro\nacross multiple applications, including Cartesian, radial, and spiral\nacquisitions; motion-corrected reconstruction; cardiac MR fingerprinting;\nlearned spatially adaptive regularization weights; model-based learned image\nreconstruction and quantitative parameter estimation. MRpro offers an\nextensible framework for MR image reconstruction. With reproducibility and\nmaintainability at its core, it facilitates collaborative development and\nprovides a foundation for future MR imaging research.", "comment": "Submitted to Magnetic Resonance in Medicine", "pdf_url": "http://arxiv.org/pdf/2507.23129v1", "cate": "eess.IV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "MRpro - 基于PyTorch的开放式MR重建与处理软件包", "tldr": "MRpro是一个基于PyTorch的开源磁共振图像重建与处理软件包，提供统一数据结构、可组合运算符和深度学习模块，并已在多种MR应用中得到验证。", "motivation": "为了提供一个开源、可重复且可维护的MR图像重建与处理框架，以促进协作开发和未来的研究。", "method": "MRpro是一个基于PyTorch和开放数据格式的开源软件包。它包含三个主要部分：1. 用于MR数据集和元数据（如k空间轨迹）的统一数据结构。2. 一个包含可组合运算符、近端泛函和优化算法的库，包括用于所有常见轨迹的统一傅里叶运算符和用于定量MR的扩展相位图模拟，用于实现关键重建算法。3. 用于深度学习的基本构建块，如数据一致性层、可微分优化层和最先进的骨干网络，并集成了公共数据集以促进可重复性。该项目通过自动化质量控制进行协作开发。", "result": "MRpro的多功能性在多种应用中得到了验证，包括笛卡尔、径向和螺旋采集；运动校正重建；心脏MR指纹识别；学习到的空间自适应正则化权重；基于模型的学习图像重建和定量参数估计。", "conclusion": "MRpro为MR图像重建提供了一个可扩展的框架，以可重复性和可维护性为核心，促进了协作开发，并为未来的MR成像研究奠定了基础。", "translation": "我们介绍了MRpro，一个基于PyTorch和开放数据格式构建的开源图像重建软件包。该框架包含三个主要领域。首先，它为MR数据集及其相关元数据（例如，k空间轨迹）的一致性操作提供了统一的数据结构。其次，它提供了一个可组合运算符、近端泛函和优化算法的库，包括用于所有常见轨迹的统一傅里叶运算符以及用于定量MR的扩展相位图模拟。这些组件用于创建关键重建算法的即用型实现。第三，对于深度学习，MRpro包括基本构建模块，如数据一致性层、可微分优化层和最先进的骨干网络，并集成了公共数据集以促进可重复性。MRpro作为一个协作项目开发，并得到自动化质量控制的支持。我们展示了MRpro在多种应用中的多功能性，包括笛卡尔、径向和螺旋采集；运动校正重建；心脏MR指纹识别；学习到的空间自适应正则化权重；基于模型的学习图像重建和定量参数估计。MRpro为MR图像重建提供了一个可扩展的框架。以可重复性和可维护性为核心，它促进了协作开发，并为未来的MR成像研究奠定了基础。", "summary": "MRpro是一个基于PyTorch的开源磁共振图像重建与处理软件包。它通过提供统一的数据结构、可组合的重建算法组件以及用于深度学习的构建模块来简化MR数据处理。该框架支持多种MR采集方式和高级重建技术，旨在提高研究的可重复性、可维护性和协作性，为MR成像研究提供坚实基础。", "keywords": "MRpro, PyTorch, MR重建, 图像处理, 开源", "comments": "MRpro的创新之处在于其将MR重建的各个方面（数据结构、传统算法、深度学习模块）整合到一个基于PyTorch的开放框架中，强调了可重复性和可维护性。这对于推动MR研究的协作和标准化具有重要意义。其模块化设计和对多种MR应用的支持是其优势。"}}
{"id": "2507.07820", "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "authors": ["Eunsu Baek", "Keondo Park", "Jeonggil Ko", "Min-hwan Oh", "Taesik Gong", "Hyung-Sin Kim"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07820v2", "summary": "Current AI advances largely rely on scaling neural models and expanding\ntraining datasets to achieve generalization and robustness. Despite notable\nsuccesses, this paradigm incurs significant environmental, economic, and\nethical costs, limiting sustainability and equitable access. Inspired by\nbiological sensory systems, where adaptation occurs dynamically at the input\n(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive\nsensing as a necessary and foundational shift. Adaptive sensing proactively\nmodulates sensor parameters (e.g., exposure, sensitivity, multimodal\nconfigurations) at the input level, significantly mitigating covariate shifts\nand improving efficiency. Empirical evidence from recent studies demonstrates\nthat adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass\nsubstantially larger models (e.g., OpenCLIP-H) trained with significantly more\ndata and compute. We (i) outline a roadmap for broadly integrating adaptive\nsensing into real-world applications spanning humanoid, healthcare, autonomous\nsystems, agriculture, and environmental monitoring, (ii) critically assess\ntechnical and ethical integration challenges, and (iii) propose targeted\nresearch directions, such as standardized benchmarks, real-time adaptive\nalgorithms, multimodal integration, and privacy-preserving methods.\nCollectively, these efforts aim to transition the AI community toward\nsustainable, robust, and equitable artificial intelligence systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07820v2", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-31", "AI": {"title_translation": "人工智能应更好地感知，而非仅仅更大规模：自适应感知作为范式转变", "tldr": "本文提出自适应感知作为AI发展的新范式，通过在输入端动态调整传感器参数，使小型模型超越大型模型，以解决当前AI扩展范式带来的环境、经济和伦理成本问题，并促进AI的可持续、鲁棒和公平发展。", "motivation": "当前的AI发展主要依赖于扩展神经网络模型和训练数据集，但这带来了显著的环境、经济和伦理成本，限制了可持续性和公平性。受生物传感系统适应性的启发，需要一种新的范式来解决这些问题。", "method": "提出自适应感知作为核心方法。这包括在输入层面主动调节传感器参数（例如，曝光、灵敏度、多模态配置），以显著减轻协变量偏移并提高效率。文章还概述了将自适应感知整合到实际应用中的路线图，并评估了技术和伦理挑战，提出了具体的研究方向。", "result": "实证证据表明，自适应感知使小型模型（例如EfficientNet-B0）能够超越使用更多数据和计算训练的更大模型（例如OpenCLIP-H）。", "conclusion": "自适应感知是一种必要的、基础性的范式转变，能够使AI社区向可持续、鲁棒和公平的人工智能系统过渡。文章提出了实现这一转变的路线图、挑战和研究方向。", "translation": "当前人工智能的进步主要依赖于扩展神经网络模型和扩大训练数据集以实现泛化和鲁棒性。尽管取得了显著成功，但这种范式带来了巨大的环境、经济和伦理成本，限制了可持续性和公平获取。受生物感官系统启发，其中适应性在输入端动态发生（例如，调整瞳孔大小、重新聚焦视觉）——我们倡导自适应感知作为一种必要且基础性的转变。自适应感知在输入层面主动调节传感器参数（例如，曝光、灵敏度、多模态配置），显著减轻协变量偏移并提高效率。最近研究的实证证据表明，自适应感知使小型模型（例如EfficientNet-B0）能够超越使用更多数据和计算训练的更大模型（例如OpenCLIP-H）。我们（i）概述了将自适应感知广泛整合到人类机器人、医疗保健、自主系统、农业和环境监测等现实应用中的路线图，（ii）批判性评估了技术和伦理整合挑战，以及（iii）提出了有针对性的研究方向，例如标准化基准、实时自适应算法、多模态集成和隐私保护方法。总的来说，这些努力旨在推动AI社区向可持续、鲁棒和公平的人工智能系统转型。", "summary": "本文提出“自适应感知”作为人工智能发展的一种新范式，旨在解决当前AI依赖模型和数据规模扩展所带来的高昂成本和可持续性问题。该方法受生物传感系统启发，通过在输入端动态调整传感器参数，显著提高效率并减轻协变量偏移。研究表明，自适应感知能使小型模型表现优于大型模型。文章还描绘了将此范式应用于多领域（如人形机器人、医疗保健等）的路线图，并探讨了相关技术和伦理挑战，提出了未来研究方向，以期实现更可持续、鲁棒和公平的AI系统。", "keywords": "自适应感知, 人工智能范式, 可持续AI, 效率, 鲁棒性", "comments": "本文提出了一个重要的范式转变，从单纯追求模型和数据规模的“大”转向关注感知的“好”。其创新之处在于将生物感知的适应性引入AI系统，通过在输入端进行智能调节来提升效率和性能，这对于解决AI发展中的资源消耗问题具有重要意义。文章不仅提出了概念，还提供了实证支持、应用路线图和未来研究方向，显示了其潜在的广泛影响和实用价值。"}}
{"id": "2507.08606", "title": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures", "authors": ["Benno Uthayasooriyar", "Antoine Ly", "Franck Vermet", "Caio Corro"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08606v3", "summary": "We introduce DocPolarBERT, a layout-aware BERT model for document\nunderstanding that eliminates the need for absolute 2D positional embeddings.\nWe extend self-attention to take into account text block positions in relative\npolar coordinate system rather than the Cartesian one. Despite being\npre-trained on a dataset more than six times smaller than the widely used\nIIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results\ndemonstrate that a carefully designed attention mechanism can compensate for\nreduced pre-training data, offering an efficient and effective alternative for\ndocument understanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08606v3", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-31", "AI": {"title_translation": "DocPolarBERT：一种采用相对极坐标编码布局结构的文档理解预训练模型", "tldr": "DocPolarBERT是一个新的BERT模型，通过使用相对极坐标而非绝对笛卡尔坐标来处理文档布局，即使在更小的数据集上预训练，也能实现最先进的性能。", "motivation": "该研究旨在消除文档理解模型对绝对二维位置嵌入的需求，并提供一种高效且有效的替代方案，尤其是在预训练数据量有限的情况下。", "method": "DocPolarBERT通过扩展自注意力机制，使其能够考虑文本块在相对极坐标系中的位置，而非传统的笛卡尔坐标系。", "result": "DocPolarBERT在比广泛使用的IIT-CDIP语料库小六倍多的数据集上进行预训练后，仍取得了最先进的结果。", "conclusion": "精心设计的注意力机制可以弥补预训练数据量的减少，为文档理解提供了一种高效且有效的替代方案。", "translation": "我们引入了DocPolarBERT，一个布局感知的BERT模型，用于文档理解，它消除了对绝对二维位置嵌入的需求。我们扩展了自注意力机制，使其能够考虑文本块在相对极坐标系而非笛卡尔坐标系中的位置。尽管其预训练数据集比广泛使用的IIT-CDIP语料库小六倍多，DocPolarBERT仍取得了最先进的结果。这些结果表明，精心设计的注意力机制可以弥补预训练数据量的减少，为文档理解提供了一种高效且有效的替代方案。", "summary": "DocPolarBERT是一种新型的、布局感知的BERT模型，专为文档理解设计，通过采用相对极坐标系而非传统的绝对二维位置嵌入来处理文本块的位置。该模型扩展了自注意力机制以适应这种新坐标系统。尽管在规模远小于主流数据集的语料库上进行预训练，DocPolarBERT依然取得了最先进的性能，证明了优化注意力机制可以有效弥补数据量不足的问题，为文档理解提供了一种高效且实用的方法。", "keywords": "文档理解, 预训练模型, BERT, 极坐标, 布局结构", "comments": "DocPolarBERT的创新之处在于其独特地采用了相对极坐标系来编码文档布局结构，而非传统的绝对笛卡尔坐标。这不仅简化了模型对空间信息的处理，还证明了在数据量有限的情况下，通过巧妙的注意力机制设计，依然可以达到甚至超越现有先进模型的性能，这对于资源受限的研究和应用具有重要意义。"}}
{"id": "2507.23453", "title": "Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems", "authors": ["Lijia Liu", "Takumi Kondo", "Kyohei Atarashi", "Koh Takeuchi", "Jiyi Li", "Shigeru Saito", "Hisashi Kashima"], "categories": ["cs.CR", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23453v1", "summary": "This paper investigates defenses for LLM-based evaluation systems against\nprompt injection. We formalize a class of threats called blind attacks, where a\ncandidate answer is crafted independently of the true answer to deceive the\nevaluator. To counter such attacks, we propose a framework that augments\nStandard Evaluation (SE) with Counterfactual Evaluation (CFE), which\nre-evaluates the submission against a deliberately false ground-truth answer.\nAn attack is detected if the system validates an answer under both standard and\ncounterfactual conditions. Experiments show that while standard evaluation is\nhighly vulnerable, our SE+CFE framework significantly improves security by\nboosting attack detection with minimal performance trade-offs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23453v1", "cate": "cs.CR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "大型语言模型评估系统中盲攻击检测的反事实评估", "tldr": "本文提出了一种结合反事实评估（CFE）的框架（SE+CFE），用于检测大型语言模型评估系统中的盲攻击，实验证明其能显著提高安全性。", "motivation": "大型语言模型评估系统容易受到提示注入（prompt injection）的攻击，特别是盲攻击（blind attacks），即候选答案独立于真实答案，旨在欺骗评估器。因此，需要一种有效的防御机制。", "method": "本文提出了一个将标准评估（SE）与反事实评估（CFE）相结合的框架。CFE通过针对一个故意错误的真实答案重新评估提交来工作。如果系统在标准和反事实条件下都验证了答案，则检测到攻击。", "result": "实验表明，标准评估非常脆弱，而SE+CFE框架显著提高了安全性，显著提升了攻击检测率，同时性能权衡最小。", "conclusion": "结合反事实评估的框架（SE+CFE）是检测大型语言模型评估系统中盲攻击的有效方法，能在保持性能的同时显著提高系统的安全性。", "translation": "本文研究了大型语言模型（LLM）评估系统针对提示注入（prompt injection）的防御。我们形式化了一类被称为盲攻击（blind attacks）的威胁，其中候选答案独立于真实答案精心制作，旨在欺骗评估器。为了对抗此类攻击，我们提出了一个框架，将标准评估（Standard Evaluation, SE）与反事实评估（Counterfactual Evaluation, CFE）相结合。反事实评估通过针对一个故意错误的真实答案重新评估提交来工作。如果系统在标准和反事实条件下都验证了答案，则检测到攻击。实验表明，虽然标准评估极易受到攻击，但我们的SE+CFE框架通过提高攻击检测率，同时保持最小的性能权衡，显著提高了安全性。", "summary": "该论文旨在解决大型语言模型评估系统面临的提示注入（特别是盲攻击）问题。作者提出了一种创新的防御框架，该框架结合了标准评估和反事实评估。反事实评估通过使用一个故意错误的真实答案重新评估提交来检测攻击。实验结果表明，与单独的标准评估相比，这种结合方法能显著提高攻击检测的安全性，并且对系统性能的影响极小。", "keywords": "大型语言模型, 提示注入, 盲攻击, 反事实评估, 安全性", "comments": "该论文提出了一种新颖的反事实评估方法来增强LLM评估系统的安全性，有效应对了盲攻击这一特定且复杂的威胁类型。其创新点在于利用故意错误的真实答案进行二次验证，提供了一种实用且高效的防御机制，在保证系统性能的同时大幅提升了攻击检测能力，具有重要的理论和实践意义。"}}
{"id": "2507.23682", "title": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models", "authors": ["Xiaoyu Chen", "Hangxing Wei", "Pushi Zhang", "Chuheng Zhang", "Kaixin Wang", "Yanjiang Guo", "Rushuai Yang", "Yucen Wang", "Xinquan Xiao", "Li Zhao", "Jianyu Chen", "Jiang Bian"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.23682v1", "summary": "Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research.", "comment": "Project page: https://aka.ms/villa-x", "pdf_url": "http://arxiv.org/pdf/2507.23682v1", "cate": "cs.RO", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "villa-X：增强视觉-语言-动作模型中的潜在动作建模", "tldr": "villa-X 提出一种新的 ViLLA 框架，通过改进潜在动作的学习和整合方式，显著提升了机器人操作策略在模拟和真实环境中的泛化性能。", "motivation": "视觉-语言-动作 (VLA) 模型是学习机器人操作策略的流行范式，而近期工作开始探索将潜在动作纳入 VLA 预训练。本研究的动机是进一步提升潜在动作建模，以学习更具泛化能力的机器人操作策略。", "method": "本文引入了 villa-X，一个新颖的视觉-语言-潜在动作 (ViLLA) 框架。该方法改进了潜在动作的学习方式以及它们融入 VLA 预训练的方式。", "result": "villa-X 在 SIMPLER 和 LIBERO 等模拟环境以及包括抓手和灵巧手操作的两个真实世界机器人设置中均实现了卓越的性能。", "conclusion": "ViLLA 范式具有巨大的前景，并且 villa-X 为未来的研究奠定了坚实的基础。", "translation": "视觉-语言-动作 (VLA) 模型已成为一种流行的范式，用于学习能够遵循语言指令并泛化到新颖场景的机器人操作策略。最近的工作已开始探索将潜在动作（一种表示两帧之间视觉变化的抽象表示）整合到 VLA 预训练中。在本文中，我们介绍了 villa-X，一个新颖的视觉-语言-潜在动作 (ViLLA) 框架，它推进了潜在动作建模，以学习可泛化的机器人操作策略。我们的方法改进了潜在动作的学习方式以及它们融入 VLA 预训练的方式。这些贡献共同使 villa-X 在包括 SIMPLER 和 LIBERO 在内的模拟环境以及包括抓手和灵巧手操作的两个真实世界机器人设置中均实现了卓越的性能。我们相信 ViLLA 范式具有巨大的前景，并且我们的 villa-X 为未来的研究奠定了坚实的基础。", "summary": "本文介绍了 villa-X，一个新颖的视觉-语言-潜在动作 (ViLLA) 框架，旨在增强视觉-语言-动作 (VLA) 模型中的潜在动作建模。通过改进潜在动作的学习和整合方式，villa-X 显著提升了机器人操作策略的泛化能力，并在模拟和真实世界机器人环境中取得了卓越表现，为未来的相关研究奠定了基础。", "keywords": "机器人操作, 视觉-语言-动作模型, 潜在动作, 泛化, ViLLA", "comments": "本文的创新之处在于提出了 ViLLA 框架，并具体改进了潜在动作的学习和在 VLA 预训练中的整合方式。其重要性在于提升了机器人操作策略的泛化能力，并在多种复杂环境中验证了其有效性，为机器人学习领域开辟了新的研究方向。"}}
{"id": "2507.23491", "title": "Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus", "authors": ["Olga Vershinina", "Jacopo Sabbatinelli", "Anna Rita Bonfigli", "Dalila Colombaretti", "Angelica Giuliani", "Mikhail Krivonosov", "Arseniy Trukhanov", "Claudio Franceschi", "Mikhail Ivanchenko", "Fabiola Olivieri"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23491v1", "summary": "Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent\nnon-communicable chronic disease that substantially reduces life expectancy.\nAccurate estimation of all-cause mortality risk in T2DM patients is crucial for\npersonalizing and optimizing treatment strategies. Research Design and Methods.\nThis study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed\nT2DM over a maximum follow-up period of 16.8 years, during which 202 patients\n(36%) died. Key survival-associated features were identified, and multiple\nmachine learning (ML) models were trained and validated to predict all-cause\nmortality risk. To improve model interpretability, Shapley additive\nexplanations (SHAP) was applied to the best-performing model. Results. The\nextra survival trees (EST) model, incorporating ten key features, demonstrated\nthe best predictive performance. The model achieved a C-statistic of 0.776,\nwith the area under the receiver operating characteristic curve (AUC) values of\n0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause\nmortality predictions, respectively. The SHAP approach was employed to\ninterpret the model's individual decision-making processes. Conclusions. The\ndeveloped model exhibited strong predictive performance for mortality risk\nassessment. Its clinically interpretable outputs enable potential bedside\napplication, improving the identification of high-risk patients and supporting\ntimely treatment optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23491v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "预测2型糖尿病患者全因死亡风险的可解释人工智能模型", "tldr": "该研究开发并验证了一个可解释的人工智能模型（EST模型），用于预测2型糖尿病患者的全因死亡风险，并展示了其良好的预测性能和临床可解释性。", "motivation": "2型糖尿病是一种高发慢性病，会显著缩短预期寿命。准确评估2型糖尿病患者的全因死亡风险对于个性化和优化治疗策略至关重要。", "method": "研究分析了一个包含554名（40-87岁）2型糖尿病患者的队列，最长随访16.8年，期间有202名患者死亡。研究识别了与生存相关的关键特征，并训练和验证了多个机器学习模型来预测全因死亡风险。为提高模型可解释性，对表现最佳的模型应用了Shapley加性解释（SHAP）。", "result": "额外生存树（EST）模型结合了十个关键特征，表现出最佳预测性能。该模型的C统计量为0.776，5年、10年、15年和16.8年全因死亡预测的ROC曲线下面积（AUC）值分别为0.86、0.80、0.841和0.826。SHAP方法被用于解释模型的个体决策过程。", "conclusion": "开发的模型在死亡风险评估方面表现出强大的预测性能。其临床可解释的输出使得其具有潜在的床旁应用价值，有助于识别高危患者并支持及时优化治疗。", "translation": "目的。2型糖尿病（T2DM）是一种高发非传染性慢性疾病，会显著缩短预期寿命。准确估计2型糖尿病患者的全因死亡风险对于个性化和优化治疗策略至关重要。研究设计和方法。本研究分析了一个包含554名（40-87岁）确诊2型糖尿病患者的队列，最长随访期为16.8年，期间有202名患者（36%）死亡。研究识别了与生存相关的关键特征，并训练和验证了多个机器学习（ML）模型来预测全因死亡风险。为了提高模型可解释性，对表现最佳的模型应用了Shapley加性解释（SHAP）。结果。额外生存树（EST）模型结合了十个关键特征，表现出最佳预测性能。该模型的C统计量为0.776，5年、10年、15年和16.8年全因死亡预测的ROC曲线下面积（AUC）值分别为0.86、0.80、0.841和0.826。SHAP方法被用于解释模型的个体决策过程。结论。开发的模型在死亡风险评估方面表现出强大的预测性能。其临床可解释的输出使得其具有潜在的床旁应用价值，有助于识别高危患者并支持及时优化治疗。", "summary": "本研究开发并评估了一个基于机器学习的可解释模型，用于预测2型糖尿病患者的全因死亡风险。通过分析一个包含554名患者的队列数据，研究发现额外生存树（EST）模型结合十个关键特征表现出最佳预测性能，并在不同时间点（5年、10年、15年、16.8年）的全因死亡预测中取得了良好的AUC值。同时，应用SHAP方法增强了模型的可解释性，使其结果更易于临床理解和应用，从而有助于早期识别高危患者并优化治疗方案。", "keywords": "2型糖尿病, 全因死亡率, 可解释人工智能, 机器学习, SHAP", "comments": "该论文的创新点在于将可解释人工智能（XAI）技术应用于2型糖尿病患者全因死亡风险预测，特别是结合了SHAP方法来提高模型的临床可用性。这不仅提供了高精度的预测，更重要的是，其可解释性使得医生能够理解模型决策背后的原因，从而增强了临床采纳的可能性。模型的强大预测性能和潜在的床旁应用价值使其在个性化治疗和风险管理方面具有重要意义。"}}
{"id": "2507.23386", "title": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models", "authors": ["Ailiang Lin", "Zhuoyun Li", "Kotaro Funakoshi"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23386v1", "summary": "Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23386v1", "cate": "cs.CL", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Causal2Vec：改进解码器专用大型语言模型作为多功能嵌入模型", "tldr": "Causal2Vec 是一种新方法，通过引入上下文令牌和改进的池化策略，显著提升了解码器专用LLM作为嵌入模型的性能，同时降低了计算成本和序列长度。", "motivation": "现有方法在将解码器专用大型语言模型（LLMs）用于嵌入时存在局限性：移除因果注意力掩码可能损害模型在预训练期间获取的语义信息，而单向方法依赖额外输入文本，增加了计算成本。", "method": "提出 Causal2Vec。首先，使用轻量级BERT风格模型将输入文本预编码为一个“Contextual”令牌，并将其添加到LLM的输入序列前端。这使得每个令牌即使不关注未来令牌也能捕获上下文信息。其次，为了减轻最后令牌池化引入的近因偏差并更好地利用“Contextual”令牌中的语义信息，将“Contextual”令牌和EOS令牌的最后隐藏状态拼接作为最终文本嵌入。该方法不改变LLM的原始架构，也不引入显著的计算开销。", "result": "Causal2Vec 在大规模文本嵌入基准（MTEB）上，在仅使用公开可用检索数据集训练的模型中取得了最先进的性能。与表现最佳的方法相比，它将所需序列长度减少了高达85%，推理时间减少了高达82%。", "conclusion": "Causal2Vec 有效地将解码器专用LLMs转换为高性能、高效的通用嵌入模型，克服了现有方法的局限性，并在保持模型原有架构的同时显著提升了性能和效率。", "translation": "解码器专用大型语言模型（LLMs）正越来越多地被用于构建嵌入模型，这些模型能有效地将自然语言文本的语义信息编码成密集向量表示，以用于各种嵌入任务。然而，许多现有方法主要侧重于移除LLMs中的因果注意力掩码以实现双向注意力，这可能会损害模型在预训练期间获取语义信息的能力。此外，领先的单向方法通常依赖额外的输入文本来克服因果注意力的固有局限性，这不可避免地增加了计算成本。在这项工作中，我们提出了Causal2Vec，一个通用嵌入模型，旨在在不改变其原始架构或引入显著计算开销的情况下，提升解码器专用LLMs的性能。具体来说，我们首先采用一个轻量级的BERT风格模型将输入文本预编码成一个单一的“Contextual”令牌，然后将其前置到LLM的输入序列中，从而允许每个令牌即使不关注未来令牌也能捕获上下文信息。此外，为了减轻最后令牌池化引入的近因偏差，并帮助LLMs更好地利用“Contextual”令牌中编码的语义信息，我们将“Contextual”令牌和EOS令牌的最后隐藏状态拼接作为最终的文本嵌入。在实践中，Causal2Vec 在大规模文本嵌入基准（MTEB）上，在仅使用公开可用检索数据集训练的模型中取得了最先进的性能，同时与表现最佳的方法相比，将所需序列长度减少了高达85%，推理时间减少了高达82%。", "summary": "Causal2Vec 提出了一种新颖的方法，旨在提升解码器专用LLMs作为通用嵌入模型的性能，同时避免了现有方法（如移除因果注意力或依赖额外输入）的缺点。它通过引入一个预编码的“Contextual”令牌来增强上下文捕获能力，并结合“Contextual”和EOS令牌的隐藏状态进行最终嵌入。该方法不修改LLM架构，计算开销低，并在MTEB基准上取得了最先进的性能，显著减少了序列长度和推理时间。", "keywords": "解码器专用LLMs, 嵌入模型, 因果注意力, Causal2Vec, 上下文令牌", "comments": "Causal2Vec 的创新之处在于它在不修改解码器专用LLM核心架构的前提下，通过巧妙地引入预编码的“Contextual”令牌和改进的池化策略来克服因果注意力的局限性。这种方法不仅保持了预训练语义信息的完整性，还显著降低了计算成本和推理时间，解决了现有嵌入模型面临的关键效率和性能问题。其通用性和高效性使其在实际应用中具有重要价值。"}}
{"id": "2306.01654", "title": "Insights into Closed-form IPM-GAN Discriminator Guidance for Diffusion Modeling", "authors": ["Aadithya Srikanth", "Siddarth Asokan", "Nishanth Shetty", "Chandra Sekhar Seelamantula"], "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.01654v2", "summary": "Diffusion models are a state-of-the-art generative modeling framework that\ntransform noise to images via Langevin sampling, guided by the score, which is\nthe gradient of the logarithm of the data distribution. Recent works have shown\nempirically that the generation quality can be improved when guided by\nclassifier network, which is typically the discriminator trained in a\ngenerative adversarial network (GAN) setting. In this paper, we propose a\ntheoretical framework to analyze the effect of the GAN discriminator on\nLangevin-based sampling, and show that the IPM-GAN optimization can be seen as\none of smoothed score-matching, wherein the scores of the data and the\ngenerator distributions are convolved with the kernel function associated with\nthe IPM. The proposed approach serves to unify score-based training and\noptimization of IPM-GANs. Based on these insights, we demonstrate that\nclosed-form kernel-based discriminator guidance, results in improvements (in\nterms of CLIP-FID and KID metrics) when applied atop baseline diffusion models.\nWe demonstrate these results on the denoising diffusion implicit model (DDIM)\nand latent diffusion model (LDM) settings on various standard datasets. We also\nshow that the proposed approach can be combined with existing\naccelerated-diffusion techniques to improve latent-space image generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.01654v2", "cate": "cs.LG", "date": "2023-06-02", "updated": "2025-07-31", "AI": {"title_translation": "扩散模型中闭式IPM-GAN判别器引导的见解", "tldr": "本文提出了一个理论框架，分析了GAN判别器对基于Langevin采样的扩散模型的影响，并展示了闭式核函数判别器引导可以提高生成质量。", "motivation": "经验研究表明，使用分类器（通常是GAN判别器）引导可以提高扩散模型的生成质量，但其理论基础尚不明确。本文旨在提出一个理论框架来分析GAN判别器对基于Langevin采样的影响。", "method": "本文提出了一个理论框架来分析GAN判别器对Langevin采样的影响。研究表明，IPM-GAN优化可以被视为一种平滑的分数匹配，其中数据和生成器分布的分数与IPM相关的核函数进行卷积。这种方法统一了基于分数的训练和IPM-GAN的优化。基于这些见解，本文展示了闭式核函数判别器引导。", "result": "闭式核函数判别器引导在基线扩散模型（DDIM和LDM）上，在CLIP-FID和KID指标方面带来了改进。这些结果在各种标准数据集上得到验证。此外，所提出的方法可以与现有的加速扩散技术相结合，以改进潜在空间图像生成。", "conclusion": "本文提出了一个理论框架，成功地统一了基于分数的训练和IPM-GAN的优化，并证明了闭式核函数判别器引导能有效提升扩散模型的生成质量。", "translation": "扩散模型是一种最先进的生成建模框架，它通过Langevin采样，在分数（数据分布对数的梯度）的引导下，将噪声转化为图像。最近的工作经验性地表明，当由分类器网络（通常是生成对抗网络（GAN）设置中训练的判别器）引导时，生成质量可以得到改善。在本文中，我们提出了一个理论框架来分析GAN判别器对基于Langevin采样的影响，并表明IPM-GAN优化可以被视为一种平滑的分数匹配，其中数据和生成器分布的分数与与IPM相关的核函数进行卷积。所提出的方法旨在统一基于分数的训练和IPM-GAN的优化。基于这些见解，我们证明了闭式核函数判别器引导在应用于基线扩散模型时，能带来改进（在CLIP-FID和KID指标方面）。我们在去噪扩散隐式模型（DDIM）和潜在扩散模型（LDM）设置上，在各种标准数据集上展示了这些结果。我们还表明，所提出的方法可以与现有的加速扩散技术相结合，以改进潜在空间图像生成。", "summary": "本文深入探讨了GAN判别器在扩散模型中的作用。通过提出一个理论框架，作者将IPM-GAN优化解释为一种平滑的分数匹配过程，从而统一了基于分数的训练和IPM-GAN的优化。在此基础上，研究表明，闭式核函数判别器引导能够显著提升扩散模型的生成质量，并在多种基线模型和数据集上得到了验证，同时还能与现有加速技术结合以优化潜在空间图像生成。", "keywords": "扩散模型, GAN, 判别器引导, 分数匹配, Langevin采样", "comments": "本文通过提供一个理论框架来解释GAN判别器在扩散模型中的作用，填补了现有经验观察的理论空白，具有创新性。它将IPM-GAN优化与分数匹配联系起来，提供了一个统一的视角，这对于理解和改进扩散模型具有重要意义。所提出的闭式核函数判别器引导方法也展示了实际的性能提升。"}}
{"id": "2507.17745", "title": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention", "authors": ["Yiwen Chen", "Zhihao Li", "Yikai Wang", "Hu Zhang", "Qin Li", "Chi Zhang", "Guosheng Lin"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.17745v3", "summary": "Recent advances in sparse voxel representations have significantly improved\nthe quality of 3D content generation, enabling high-resolution modeling with\nfine-grained geometry. However, existing frameworks suffer from severe\ncomputational inefficiencies due to the quadratic complexity of attention\nmechanisms in their two-stage diffusion pipelines. In this work, we propose\nUltra3D, an efficient 3D generation framework that significantly accelerates\nsparse voxel modeling without compromising quality. Our method leverages the\ncompact VecSet representation to efficiently generate a coarse object layout in\nthe first stage, reducing token count and accelerating voxel coordinate\nprediction. To refine per-voxel latent features in the second stage, we\nintroduce Part Attention, a geometry-aware localized attention mechanism that\nrestricts attention computation within semantically consistent part regions.\nThis design preserves structural continuity while avoiding unnecessary global\nattention, achieving up to 6.7x speed-up in latent generation. To support this\nmechanism, we construct a scalable part annotation pipeline that converts raw\nmeshes into part-labeled sparse voxels. Extensive experiments demonstrate that\nUltra3D supports high-resolution 3D generation at 1024 resolution and achieves\nstate-of-the-art performance in both visual fidelity and user preference.", "comment": "Project Page: https://buaacyw.github.io/ultra3d/", "pdf_url": "http://arxiv.org/pdf/2507.17745v3", "cate": "cs.CV", "date": "2025-07-23", "updated": "2025-07-31", "AI": {"title_translation": "Ultra3D：基于部件注意力的3D高效高保真生成", "tldr": "Ultra3D通过引入部件注意力机制，显著提高了稀疏体素3D生成的速度和效率，同时保持了高保真度。", "motivation": "现有基于稀疏体素表示的3D内容生成框架，由于其两阶段扩散管道中注意力机制的二次复杂度，导致严重的计算效率低下。", "method": "提出Ultra3D框架，通过两阶段方法加速稀疏体素建模。第一阶段利用紧凑的VecSet表示高效生成粗略对象布局，减少token数量并加速体素坐标预测。第二阶段引入Part Attention（部件注意力机制），这是一种几何感知的局部注意力机制，将注意力计算限制在语义一致的部件区域内，避免不必要的全局注意力。为支持Part Attention，构建了可扩展的部件标注管道，将原始网格转换为部件标记的稀疏体素。", "result": "在潜在特征生成方面实现了高达6.7倍的加速。支持1024分辨率的高分辨率3D生成。在视觉保真度和用户偏好方面均达到最先进的性能。", "conclusion": "Ultra3D通过其创新的部件注意力机制和两阶段方法，有效解决了现有3D生成框架的效率问题，同时保持甚至提升了生成质量，为高分辨率3D内容生成提供了高效且高质量的解决方案。", "translation": "稀疏体素表示的最新进展显著提高了3D内容生成的质量，实现了高分辨率建模和精细几何。然而，现有框架由于其两阶段扩散管道中注意力机制的二次复杂度，导致严重的计算效率低下。在这项工作中，我们提出了Ultra3D，一个高效的3D生成框架，它在不牺牲质量的情况下显著加速了稀疏体素建模。我们的方法在第一阶段利用紧凑的VecSet表示来高效生成粗略的对象布局，从而减少token数量并加速体素坐标预测。为了在第二阶段细化每个体素的潜在特征，我们引入了部件注意力机制（Part Attention），这是一种几何感知的局部注意力机制，将注意力计算限制在语义一致的部件区域内。这种设计在保持结构连续性的同时避免了不必要的全局注意力，在潜在特征生成方面实现了高达6.7倍的加速。为了支持这种机制，我们构建了一个可扩展的部件标注管道，将原始网格转换为部件标记的稀疏体素。大量的实验表明，Ultra3D支持1024分辨率的高分辨率3D生成，并在视觉保真度和用户偏好方面均达到了最先进的性能。", "summary": "Ultra3D是一个高效的3D生成框架，旨在解决现有稀疏体素建模中注意力机制导致的计算效率低下问题。它通过两阶段方法实现：首先利用VecSet表示快速生成粗略布局，然后引入Part Attention机制，将注意力计算限制在语义部件区域内，从而显著加速潜在特征生成（高达6.7倍）。该方法支持高分辨率3D生成，并在视觉质量和用户偏好方面表现出最先进的性能。", "keywords": "3D生成, 稀疏体素, 部件注意力, 计算效率, 高保真度", "comments": "这篇论文通过引入创新的“部件注意力”机制，有效解决了3D生成领域中基于稀疏体素表示的扩散模型所面临的效率瓶颈。其核心创新在于将全局注意力限制为局部，从而显著降低了计算复杂度，同时通过VecSet表示在第一阶段的优化，进一步提升了整体效率。该方法在保证高保真度的前提下，实现了显著的速度提升，对于推动高分辨率3D内容生成在实际应用中的可行性具有重要意义。"}}
{"id": "2507.23611", "title": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "authors": ["Estelle Ruellan", "Eric Clay", "Nicholas Ascoli"], "categories": ["cs.CR", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23611v1", "summary": "Infostealers exfiltrate credentials, session cookies, and sensitive data from\ninfected systems. With over 29 million stealer logs reported in 2024, manual\nanalysis and mitigation at scale are virtually unfeasible/unpractical. While\nmost research focuses on proactive malware detection, a significant gap remains\nin leveraging reactive analysis of stealer logs and their associated artifacts.\nSpecifically, infection artifacts such as screenshots, image captured at the\npoint of compromise, are largely overlooked by the current literature. This\npaper introduces a novel approach leveraging Large Language Models (LLMs), more\nspecifically gpt-4o-mini, to analyze infection screenshots to extract potential\nIndicators of Compromise (IoCs), map infection vectors, and track campaigns.\nFocusing on the Aurora infostealer, we demonstrate how LLMs can process\nscreenshots to identify infection vectors, such as malicious URLs, installer\nfiles, and exploited software themes. Our method extracted 337 actionable URLs\nand 246 relevant files from 1000 screenshots, revealing key malware\ndistribution methods and social engineering tactics. By correlating extracted\nfilenames, URLs, and infection themes, we identified three distinct malware\ncampaigns, demonstrating the potential of LLM-driven analysis for uncovering\ninfection workflows and enhancing threat intelligence. By shifting malware\nanalysis from traditional log-based detection methods to a reactive,\nartifact-driven approach that leverages infection screenshots, this research\npresents a scalable method for identifying infection vectors and enabling early\nintervention.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23611v1", "cate": "cs.CR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于LLM从截图中识别信息窃取器感染向量：以Aurora为例", "tldr": "本研究提出一种利用大型语言模型（LLM）分析信息窃取器感染截图的新方法，以识别感染向量、追踪恶意活动并提升威胁情报，解决了传统日志分析的局限性。", "motivation": "信息窃取器感染数量巨大（2024年报告超过2900万条窃取日志），导致手动分析和大规模缓解几乎不可行。现有研究多关注主动恶意软件检测，而对窃取器日志及其关联工件（如感染截图）的被动分析存在显著空白。", "method": "本研究引入一种新颖方法，利用大型语言模型（LLM，特别是gpt-4o-mini）分析感染截图，以提取潜在的感染指标（IoCs），映射感染向量并追踪恶意活动。该方法专注于Aurora信息窃取器，通过处理截图识别恶意URL、安装文件和被利用的软件主题等感染向量。", "result": "从1000张截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件分发方法和社会工程策略。通过关联提取的文件名、URL和感染主题，识别出三个不同的恶意软件活动。", "conclusion": "本研究通过将恶意软件分析从传统的基于日志的检测方法转向利用感染截图的被动、工件驱动方法，提出了一种可扩展的识别感染向量并实现早期干预的方法。这展示了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。", "translation": "信息窃取器从受感染系统中窃取凭据、会话Cookie和敏感数据。2024年报告的窃取日志超过2900万条，大规模手动分析和缓解几乎不可行/不切实际。虽然大多数研究关注主动恶意软件检测，但在利用窃取日志及其关联工件的被动分析方面仍存在显著空白。特别是，感染工件，如在受损点捕获的截图，在当前文献中很大程度上被忽视。本文介绍了一种利用大型语言模型（LLM），更具体地说是gpt-4o-mini，分析感染截图以提取潜在的感染指标（IoCs），映射感染向量并追踪活动的新方法。我们以Aurora信息窃取器为例，展示了LLM如何处理截图以识别感染向量，例如恶意URL、安装文件和被利用的软件主题。我们的方法从1000张截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件分发方法和社会工程策略。通过关联提取的文件名、URL和感染主题，我们识别出三个不同的恶意软件活动，展示了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。通过将恶意软件分析从传统的基于日志的检测方法转变为利用感染截图的被动、工件驱动方法，本研究提出了一种可扩展的识别感染向量并实现早期干预的方法。", "summary": "本研究提出一种创新的方法，利用大型语言模型（LLM，特别是gpt-4o-mini）分析信息窃取器感染截图，以解决传统日志分析在识别感染向量和追踪恶意活动方面的局限性。针对Aurora信息窃取器，该方法成功从截图中提取了恶意URL和文件等感染指标，并识别出恶意软件分发策略和多个恶意活动。研究结果表明，这种基于工件的LLM驱动分析能够提供可扩展的感染向量识别和威胁情报增强能力，有助于实现早期干预。", "keywords": "LLM, 信息窃取器, 感染向量, 截图分析, 威胁情报", "comments": "该论文的创新点在于首次将大型语言模型应用于分析信息窃取器感染截图，以识别感染向量和追踪恶意活动，这弥补了现有研究在被动、工件驱动分析方面的空白。其重要性在于提供了一种可扩展且高效的方法，能够处理海量窃取日志，并从视觉证据中提取关键威胁情报，对于当前日益严峻的信息窃取器威胁具有重要的实践意义。该方法有望提升威胁检测和响应的效率。"}}
{"id": "2507.23136", "title": "Observational Multiplicity", "authors": ["Erin George", "Deanna Needell", "Berk Ustun"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23136v1", "summary": "Many prediction tasks can admit multiple models that can perform almost\nequally well. This phenomenon can can undermine interpretability and safety\nwhen competing models assign conflicting predictions to individuals. In this\nwork, we study how arbitrariness can arise in probabilistic classification\ntasks as a result of an effect that we call \\emph{observational multiplicity}.\nWe discuss how this effect arises in a broad class of practical applications\nwhere we learn a classifier to predict probabilities $p_i \\in [0,1]$ but are\ngiven a dataset of observations $y_i \\in \\{0,1\\}$. We propose to evaluate the\narbitrariness of individual probability predictions through the lens of\n\\emph{regret}. We introduce a measure of regret for probabilistic\nclassification tasks, which measures how the predictions of a model could\nchange as a result of different training labels change. We present a\ngeneral-purpose method to estimate the regret in a probabilistic classification\ntask. We use our measure to show that regret is higher for certain groups in\nthe dataset and discuss potential applications of regret. We demonstrate how\nestimating regret promote safety in real-world applications by abstention and\ndata collection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23136v1", "cate": "cs.LG", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "观测多样性", "tldr": "许多模型表现相似，导致预测的任意性，这损害了可解释性和安全性。本文研究了概率分类中由“观测多样性”引起的任意性，并引入了“后悔”度量来量化个体预测的任意性。通过估计后悔，可以提高现实世界应用的安全性。", "motivation": "当多个模型表现几乎同样好，但对个体给出冲突的预测时，会损害可解释性和安全性。本文旨在研究概率分类任务中，由于“观测多样性”效应，任意性是如何产生的。", "method": "研究了在预测概率但给定二元观测数据的概率分类任务中“观测多样性”的产生。提出通过“后悔”的视角评估个体概率预测的任意性，并引入了一种概率分类任务的后悔度量，该度量衡量模型预测如何随训练标签变化。提出了一种通用方法来估计概率分类任务中的后悔。", "result": "研究表明数据集中某些群体的后悔度更高。展示了估计后悔如何通过弃权和数据收集来促进现实世界应用的安全性。", "conclusion": "估计后悔可以促进现实世界应用的安全性，通过指导弃权决策和数据收集策略。", "translation": "许多预测任务可以有多个表现几乎同样好的模型。当相互竞争的模型对个体分配冲突的预测时，这种现象会损害可解释性和安全性。在这项工作中，我们研究了在概率分类任务中，由于我们称之为“观测多样性”的影响，任意性是如何产生的。我们讨论了这种效应如何在广泛的实际应用中出现，即我们学习一个分类器来预测概率 $p_i \\in [0,1]$，但却获得了观测数据 $y_i \\in \\{0,1\\}$。我们建议通过“后悔”的视角来评估个体概率预测的任意性。我们引入了概率分类任务的后悔度量，它衡量了模型预测如何因训练标签的变化而改变。我们提出了一种通用方法来估计概率分类任务中的后悔。我们使用我们的度量来表明数据集中某些群体的后悔度更高，并讨论了后悔的潜在应用。我们展示了如何通过弃权和数据收集来估计后悔，从而提高现实世界应用的安全性。", "summary": "本文探讨了在概率分类中，多个性能相近的模型导致预测任意性，从而损害可解释性和安全性的问题。作者引入了“观测多样性”概念来解释这种任意性的来源，并提出了“后悔”作为衡量个体概率预测任意性的新度量。该度量量化了模型预测因训练标签变化而产生的变动。文章提出了一种通用的后悔估计方法，并证明后悔在数据集中某些群体中更高。研究进一步展示了通过估计后悔，能够通过弃权和数据收集来提升现实世界应用的安全性。", "keywords": "观测多样性, 概率分类, 后悔, 模型多样性, 安全性", "comments": "本文引入了“观测多样性”这一新颖概念和“后悔”这一创新指标，以量化并解决由于存在多个合理模型而在概率分类中产生的预测任意性问题。这种方法是创新的，因为它直接解决了模型多样性带来的可解释性和安全问题，提供了一种评估和缓解预测不确定性的实用方法。对特定群体后悔度的关注突显了其在实现公平AI方面的潜力。"}}
{"id": "2507.23272", "title": "Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2", "authors": ["Solha Kang", "Eugene Kim", "Joris Vankerschaver", "Utku Ozbulak"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the 28th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2nd Deep Breast Workshop on AI and Imaging for Diagnostic and Treatment Challenges in Breast Care (DeepBreath), 2025", "url": "http://arxiv.org/abs/2507.23272v1", "summary": "Breast MRI provides high-resolution volumetric imaging critical for tumor\nassessment and treatment planning, yet manual interpretation of 3D scans\nremains labor-intensive and subjective. While AI-powered tools hold promise for\naccelerating medical image analysis, adoption of commercial medical AI products\nremains limited in low- and middle-income countries due to high license costs,\nproprietary software, and infrastructure demands. In this work, we investigate\nwhether the Segment Anything Model 2 (SAM2) can be adapted for low-cost,\nminimal-input 3D tumor segmentation in breast MRI. Using a single bounding box\nannotation on one slice, we propagate segmentation predictions across the 3D\nvolume using three different slice-wise tracking strategies: top-to-bottom,\nbottom-to-top, and center-outward. We evaluate these strategies across a large\ncohort of patients and find that center-outward propagation yields the most\nconsistent and accurate segmentations. Despite being a zero-shot model not\ntrained for volumetric medical data, SAM2 achieves strong segmentation\nperformance under minimal supervision. We further analyze how segmentation\nperformance relates to tumor size, location, and shape, identifying key failure\nmodes. Our results suggest that general-purpose foundation models such as SAM2\ncan support 3D medical image analysis with minimal supervision, offering an\naccessible and affordable alternative for resource-constrained settings.", "comment": "Accepted for publication in the 28th International Conference on\n  Medical Image Computing and Computer Assisted Intervention (MICCAI), 2nd Deep\n  Breast Workshop on AI and Imaging for Diagnostic and Treatment Challenges in\n  Breast Care (DeepBreath), 2025", "pdf_url": "http://arxiv.org/pdf/2507.23272v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "使用SAM2实现3D乳腺MRI经济实惠的肿瘤分割和可视化", "tldr": "本文研究了如何利用SAM2模型，以最小的输入和低成本实现3D乳腺MRI肿瘤分割，为资源受限环境提供可行的解决方案。", "motivation": "乳腺MRI的3D扫描手动解读劳动密集且主观。商业医疗AI产品因高成本和基础设施要求，在低收入和中等收入国家普及受限，因此需要一种经济实惠且易于获取的AI解决方案。", "method": "研究人员探索了将Segment Anything Model 2 (SAM2)应用于低成本、最小输入的3D乳腺MRI肿瘤分割。他们使用单一切片上的单个边界框标注，并通过三种切片跟踪策略（从上到下、从下到上和从中心向外）在3D体积中传播分割预测，并评估了这些策略。", "result": "中心向外传播策略产生了最一致和准确的分割。尽管SAM2是一个未针对体积医学数据训练的零样本模型，但它在最小监督下仍取得了强大的分割性能。研究还分析了分割性能与肿瘤大小、位置和形状的关系，并确定了关键的失败模式。", "conclusion": "像SAM2这样的通用基础模型能够在最小监督下支持3D医学图像分析，为资源受限的环境提供了一种可访问且经济实惠的替代方案。", "translation": "乳腺MRI提供高分辨率的体素成像，对肿瘤评估和治疗规划至关重要，但3D扫描的手动解读仍然劳动密集且主观。尽管AI驱动的工具在加速医学图像分析方面前景广阔，但由于高昂的许可费、专有软件和基础设施要求，商业医疗AI产品在低收入和中等收入国家的普及仍然有限。在这项工作中，我们研究了Segment Anything Model 2 (SAM2)是否可以适用于乳腺MRI中低成本、最小输入的3D肿瘤分割。我们使用单一切片上的单个边界框标注，通过三种不同的切片跟踪策略（从上到下、从下到上和从中心向外）在3D体积中传播分割预测。我们对大量患者队列的这些策略进行了评估，发现中心向外传播产生了最一致和准确的分割。尽管SAM2是一个未针对体积医学数据训练的零样本模型，但它在最小监督下仍取得了强大的分割性能。我们进一步分析了分割性能与肿瘤大小、位置和形状的关系，并确定了主要的失败模式。我们的结果表明，像SAM2这样的通用基础模型可以在最小监督下支持3D医学图像分析，为资源受限的环境提供了一种可访问且经济实惠的替代方案。", "summary": "本文探讨了如何将Segment Anything Model 2 (SAM2)应用于经济实惠、最小输入的3D乳腺MRI肿瘤分割。研究评估了三种切片传播策略，发现中心向外传播效果最佳。尽管SAM2是一个零样本模型且未针对体积医学数据进行训练，但在最小监督下仍展现出强大的分割性能，表明其作为一种可访问且经济实惠的解决方案，在资源受限的医疗环境中进行3D医学图像分析的潜力。", "keywords": "3D乳腺MRI, 肿瘤分割, SAM2, 基础模型, 经济实惠AI", "comments": "该研究的创新之处在于成功地将一个通用基础模型（SAM2）应用于特定的医疗影像任务（3D乳腺MRI肿瘤分割），且仅需极少的输入和监督。这直接解决了医疗AI在低收入和中等收入国家面临的可访问性和成本障碍，展示了大型预训练模型超越其原始训练领域，在实际应用中发挥巨大潜力的可能性。"}}
{"id": "2504.08278", "title": "Line-Search Filter Differential Dynamic Programming for Optimal Control with Nonlinear Equality Constraints", "authors": ["Ming Xu", "Stephen Gould", "Iman Shames"], "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08278v4", "summary": "We present FilterDDP, a differential dynamic programming algorithm for\nsolving discrete-time, optimal control problems (OCPs) with nonlinear equality\nconstraints. Unlike prior methods based on merit functions or the augmented\nLagrangian class of algorithms, FilterDDP uses a step filter in conjunction\nwith a line search to handle equality constraints. We identify two important\ndesign choices for the step filter criteria which lead to robust numerical\nperformance: 1) we use the Lagrangian instead of the cost as one of the filter\ncriterion and, 2) for the stopping criteria and backward pass Hessians, we\nreplace the value function gradient with an estimated dual variable of the\ndynamics constraints. Both choices are rigorously justified, for 2) in\nparticular by a formal proof of local quadratic convergence. We validate\nFilterDDP on three contact implicit trajectory optimisation problems which\narise in robotics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08278v4", "cate": "math.OC", "date": "2025-04-11", "updated": "2025-07-31", "AI": {"title_translation": "带有非线性等式约束的最优控制的线搜索滤波器微分动态规划", "tldr": "FilterDDP是一种使用线搜索滤波器处理非线性等式约束的微分动态规划算法，并在机器人问题上得到验证。", "motivation": "现有用于解决带有非线性等式约束的离散时间最优控制问题的方法（基于优点函数或增广拉格朗日算法）可能存在局限性，需要一种新的、更鲁棒的算法来有效处理这些约束。", "method": "本文提出了FilterDDP，一种微分动态规划算法，通过结合步长滤波器和线搜索来处理非线性等式约束。其关键设计选择包括：1) 使用拉格朗日量而非成本函数作为滤波器准则；2) 在停止准则和反向传递Hessian中，用动力学约束的估计对偶变量替换值函数梯度。", "result": "FilterDDP在三个机器人领域中出现的接触隐式轨迹优化问题上得到了验证。设计选择2）通过局部二次收敛的正式证明得到了严格的理论支持，表明其具有鲁棒的数值性能。", "conclusion": "FilterDDP通过其独特的步长滤波器设计和对拉格朗日量及估计对偶变量的创新性使用，为带有非线性等式约束的最优控制问题提供了一种鲁棒且收敛性得到证明的解决方案，并在机器人应用中表现出良好的性能。", "translation": "我们提出了FilterDDP，一种用于解决具有非线性等式约束的离散时间最优控制问题（OCPs）的微分动态规划算法。与之前基于优点函数或增广拉格朗日类算法的方法不同，FilterDDP结合线搜索使用步长滤波器来处理等式约束。我们确定了步长滤波器准则的两个重要设计选择，这些选择带来了鲁棒的数值性能：1）我们使用拉格朗日量而不是成本函数作为滤波器准则之一，以及2）对于停止准则和反向传递Hessian，我们用动力学约束的估计对偶变量替换值函数梯度。这两个选择都得到了严格的证明，特别是对于2），通过局部二次收敛的正式证明。我们在机器人领域中出现的三个接触隐式轨迹优化问题上验证了FilterDDP。", "summary": "FilterDDP是一种新的微分动态规划算法，专门用于解决带有非线性等式约束的离散时间最优控制问题。它创新性地结合了步长滤波器和线搜索机制来处理约束，并引入了使用拉格朗日量作为滤波器准则和用估计对偶变量替换值函数梯度的关键设计。这些设计选择被证明能提供鲁棒的数值性能和局部二次收敛性，并在机器人轨迹优化问题中得到了有效验证。", "keywords": "微分动态规划, 最优控制, 非线性约束, 线搜索滤波器, 机器人", "comments": "该论文提出了一种创新的微分动态规划算法FilterDDP，通过引入步长滤波器和独特的滤波器准则（使用拉格朗日量和估计对偶变量）来有效处理非线性等式约束，解决了现有方法在鲁棒性方面的不足。特别是对局部二次收敛性的严格证明，增强了该方法的理论基础。在机器人领域的应用验证表明其具有重要的实际价值。"}}
{"id": "2507.23599", "title": "DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation", "authors": ["Yuchen Zhou", "Yan Luo", "Xiangang Wang", "Xingjian Gu", "Mingzhou Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23599v1", "summary": "Efficient and high-accuracy 3D occupancy prediction is crucial for ensuring\nthe performance of autonomous driving (AD) systems. However, many current\nmethods focus on high accuracy at the expense of real-time processing needs. To\naddress this challenge of balancing accuracy and inference speed, we propose a\ndirectional pure 2D approach. Our method involves slicing 3D voxel features to\npreserve complete vertical geometric information. This strategy compensates for\nthe loss of height cues in Bird's-Eye View (BEV) representations, thereby\nmaintaining the integrity of the 3D geometric structure. By employing a\ndirectional attention mechanism, we efficiently extract geometric features from\ndifferent orientations, striking a balance between accuracy and computational\nefficiency. Experimental results highlight the significant advantages of our\napproach for autonomous driving. On the Occ3D-nuScenes, the proposed method\nachieves an mIoU of 39.3% and an inference speed of 27.7 FPS, effectively\nbalancing accuracy and efficiency. In simulations on edge devices, the\ninference speed reaches 14.8 FPS, further demonstrating the method's\napplicability for real-time deployment in resource-constrained environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23599v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "DA-Occ：基于方向性2D的有效3D体素占用预测，用于几何结构保持", "tldr": "DA-Occ提出了一种基于方向性2D的方法，用于3D体素占用预测，旨在平衡精度和推理速度，并在Occ3D-nuScenes数据集上实现了39.3%的mIoU和27.7 FPS的推理速度。", "motivation": "当前的3D占用预测方法在追求高精度的同时牺牲了实时处理能力，这在自动驾驶系统中造成了精度和推理速度之间的平衡挑战。", "method": "本文提出了一种方向性纯2D方法，通过切片3D体素特征来保留完整的垂直几何信息，从而弥补了鸟瞰图（BEV）表示中高度线索的丢失，并保持了3D几何结构的完整性。该方法还采用了方向性注意力机制，以高效地从不同方向提取几何特征。", "result": "在Occ3D-nuScenes数据集上，所提出的方法实现了39.3%的mIoU和27.7 FPS的推理速度，有效地平衡了精度和效率。在边缘设备上的模拟中，推理速度达到了14.8 FPS。", "conclusion": "DA-Occ方法通过方向性纯2D方法有效地平衡了3D体素占用预测的精度和效率，证明了其在资源受限环境中实时部署的适用性。", "translation": "高效、高精度的3D占用预测对于确保自动驾驶（AD）系统的性能至关重要。然而，许多当前的方法专注于高精度，却牺牲了实时处理需求。为了解决平衡精度和推理速度的挑战，我们提出了一种方向性纯2D方法。我们的方法涉及切片3D体素特征以保留完整的垂直几何信息。这种策略弥补了鸟瞰图（BEV）表示中高度线索的丢失，从而保持了3D几何结构的完整性。通过采用方向性注意力机制，我们有效地从不同方向提取几何特征，在精度和计算效率之间取得了平衡。实验结果突出了我们方法在自动驾驶方面的显著优势。在Occ3D-nuScenes数据集上，所提出的方法实现了39.3%的mIoU和27.7 FPS的推理速度，有效地平衡了精度和效率。在边缘设备上的模拟中，推理速度达到了14.8 FPS，进一步证明了该方法在资源受限环境中实时部署的适用性。", "summary": "DA-Occ提出了一种高效的方向性2D方法，用于3D体素占用预测，旨在解决自动驾驶中精度与实时性能之间的权衡问题。该方法通过切片3D体素特征来保留垂直几何信息，并利用方向性注意力机制从不同方向高效提取特征，从而保持3D几何结构的完整性。实验证明，该方法在Occ3D-nuScenes数据集上实现了39.3%的mIoU和27.7 FPS的推理速度，在边缘设备上也能达到14.8 FPS，有效平衡了精度和效率，适用于实时部署。", "keywords": "3D占用预测, 自动驾驶, 方向性2D, 实时, 几何结构", "comments": "DA-Occ的创新之处在于其采用了一种方向性纯2D方法来处理3D体素特征，巧妙地解决了BEV表示中垂直信息丢失的问题，同时保持了计算效率。其在边缘设备上的良好表现进一步突显了该方法在实际自动驾驶系统中的重要性和实用性。"}}
{"id": "2507.13762", "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Duo An", "Mingyue Zheng", "Shuangjia Zheng", "Qian Shi"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13762v3", "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13762v3", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-31", "AI": {"title_translation": "MolPIF：一种用于分子生成的参数插值流模型", "tldr": "MolPIF是一个新的参数插值流模型，用于分子生成，解决了贝叶斯流网络在灵活性方面的局限性，并在结构化药物设计中表现出优异性能。", "motivation": "现有的贝叶斯流网络（BFNs）在化学任务中表现良好，但其基于贝叶斯推断的策略限制了设计更灵活的分布转换路径，难以适应多样的数据分布和任务需求。此外，更简单、更高效的参数空间模型潜力尚未被探索。", "method": "本文提出了一种新颖的参数插值流模型（PIF），并提供了详细的理论基础、训练和推理过程。在此基础上，开发了MolPIF模型，专门用于基于结构的药物设计。", "result": "MolPIF在多样化指标上与基线模型相比，展示了优越的性能。", "conclusion": "这项工作验证了基于参数空间的生成建模范式在分子生成方面的有效性，并为模型设计提供了新视角。", "translation": "深度学习在分子生成方面的进展有望加速药物发现。贝叶斯流网络（BFNs）最近在各种化学任务中表现出色，其成功常归因于在低方差参数空间中建模的范式。然而，基于贝叶斯推断的策略对设计更灵活的分布转换路径施加了限制，使其难以适应多样的数据分布和不同的任务要求。此外，更简单、更高效的基于参数空间的模型潜力尚未被探索。为了解决这个问题，我们提出了一种新颖的参数插值流模型（命名为PIF），并提供了详细的理论基础、训练和推理过程。然后，我们开发了用于基于结构的药物设计的MolPIF，证明了其在与基线模型相比的多种指标上具有优越的性能。这项工作验证了基于参数空间的生成建模范式在分子生成方面的有效性，并为模型设计提供了新视角。", "summary": "本文提出了MolPIF，一种新颖的参数插值流模型（PIF），旨在克服现有贝叶斯流网络在分子生成中灵活性不足的限制。该模型具有详细的理论基础、训练和推理过程。MolPIF特别应用于基于结构的药物设计，并在多个指标上超越了基线模型，验证了参数空间生成建模对分子的有效性，为未来的模型设计提供了新思路。", "keywords": "分子生成, 参数插值流, MolPIF, 药物发现, 贝叶斯流网络", "comments": "MolPIF的创新之处在于提出了参数插值流模型，以解决传统贝叶斯流网络在灵活性和适应性方面的局限性。它通过探索参数空间建模的潜力，为分子生成提供了一种更高效和灵活的方法，对于加速药物发现具有重要意义。"}}
{"id": "2507.23641", "title": "Polynomial Lattices for the BIKE Cryptosystem", "authors": ["Michael Schaller"], "categories": ["cs.CR", "11T71, 94A60"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23641v1", "summary": "In this paper we introduce a rank $2$ lattice over a polynomial ring arising\nfrom the public key of the BIKE cryptosystem \\cite{aragon2022bike}. The secret\nkey is a sparse vector in this lattice. We study properties of this lattice and\ngeneralize the recovery of weak keys from \\cite{BardetDLO16}. In particular, we\nshow that they implicitly solved a shortest vector problem in the lattice we\nconstructed. Rather than finding only a shortest vector, we obtain a reduced\nbasis of the lattice which makes it possible to check for more weak keys.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23641v1", "cate": "cs.CR", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "BIKE密码系统的多项式格", "tldr": "本文引入并研究了BIKE密码系统中与公钥相关的多项式格，推广了弱密钥恢复方法，并通过获取格的约化基，使得能够检查更多弱密钥。", "motivation": "研究BIKE密码系统中与公钥相关的多项式格的性质，并推广现有弱密钥恢复方法，以识别更多弱密钥。", "method": "本文引入了BIKE密码系统公钥产生的秩为2的多项式格，并研究了该格的性质。通过推广先前的弱密钥恢复方法，并获得格的约化基，而非仅仅最短向量，来检查弱密钥。", "result": "研究表明，先前的弱密钥恢复方法隐式地解决了所构建格中的最短向量问题。通过获取格的约化基，本文的方法能够检查比仅寻找最短向量时更多的弱密钥。", "conclusion": "通过构建和分析BIKE密码系统中的多项式格，并获取其约化基，可以有效地检测到比以往方法更多的弱密钥。", "translation": "本文介绍了一种源自BIKE密码系统公钥的秩为2的多项式环上的格。秘密密钥是该格中的一个稀疏向量。我们研究了该格的性质，并推广了[BardetDLO16]中弱密钥的恢复方法。特别是，我们表明他们隐式地解决了我们所构建的格中的最短向量问题。我们不仅找到了最短向量，还获得了格的一个约化基，这使得检查更多弱密钥成为可能。", "summary": "本文引入了BIKE密码系统中公钥产生的秩为2的多项式格，并研究了其性质。作者推广了现有的弱密钥恢复技术，并指出先前的研究隐式地解决了该格中的最短向量问题。通过计算格的约化基，该方法能够比仅寻找最短向量时识别出更多的弱密钥。", "keywords": "BIKE密码系统, 多项式格, 弱密钥, 格基约化, 最短向量问题", "comments": "本文的创新之处在于明确构建并分析了BIKE密码系统中与公钥相关的多项式格，并首次指出之前的弱密钥恢复方法隐式地解决了最短向量问题。通过获取约化基而非仅仅最短向量，该研究显著提升了弱密钥检测的覆盖范围，对于BIKE密码系统的安全性分析具有重要意义。"}}
{"id": "2507.23150", "title": "Towards High-Resolution Alignment and Super-Resolution of Multi-Sensor Satellite Imagery", "authors": ["Philip Wootaek Shin", "Vishal Gaur", "Rahul Ramachandran", "Manil Maskey", "Jack Sampson", "Vijaykrishnan Narayanan", "Sujit Roy"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23150v1", "summary": "High-resolution satellite imagery is essential for geospatial analysis, yet\ndifferences in spatial resolution across satellite sensors present challenges\nfor data fusion and downstream applications. Super-resolution techniques can\nhelp bridge this gap, but existing methods rely on artificially downscaled\nimages rather than real sensor data and are not well suited for heterogeneous\nsatellite sensors with differing spectral, temporal characteristics. In this\nwork, we develop a preliminary framework to align and Harmonized Landsat\nSentinel 30m(HLS 30) imagery using Harmonized Landsat Sentinel 10m(HLS10) as a\nreference from the HLS dataset. Our approach aims to bridge the resolution gap\nbetween these sensors and improve the quality of super-resolved Landsat\nimagery. Quantitative and qualitative evaluations demonstrate the effectiveness\nof our method, showing its potential for enhancing satellite-based sensing\napplications. This study provides insights into the feasibility of\nheterogeneous satellite image super-resolution and highlights key\nconsiderations for future advancements in the field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23150v1", "cate": "eess.IV", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "多传感器卫星图像高分辨率对齐与超分辨率研究", "tldr": "本研究开发了一个初步框架，利用HLS10作为参考，对齐并协调HLS30图像，旨在弥合不同卫星传感器之间的分辨率差距，并提高超分辨率Landsat图像的质量。", "motivation": "高分辨率卫星图像对于地理空间分析至关重要，但不同卫星传感器之间的空间分辨率差异给数据融合和下游应用带来了挑战。现有超分辨率方法依赖人工降采样图像而非真实传感器数据，且不适用于具有不同光谱、时间特征的异构卫星传感器。", "method": "本研究开发了一个初步框架，利用HLS数据集中的Harmonized Landsat Sentinel 10m (HLS10) 作为参考，对齐并协调Harmonized Landsat Sentinel 30m (HLS30) 图像。该方法旨在弥合这些传感器之间的分辨率差距，并提高超分辨率Landsat图像的质量。", "result": "定量和定性评估证明了我们方法的有效性，显示了其增强基于卫星的传感应用的潜力。", "conclusion": "本研究为异构卫星图像超分辨率的可行性提供了见解，并强调了该领域未来发展的主要考虑因素。", "translation": "高分辨率卫星图像对于地理空间分析至关重要，但不同卫星传感器之间的空间分辨率差异给数据融合和下游应用带来了挑战。超分辨率技术可以帮助弥合这一差距，但现有方法依赖于人工降采样图像而非真实传感器数据，并且不适用于具有不同光谱、时间特征的异构卫星传感器。在这项工作中，我们开发了一个初步框架，利用HLS数据集中的Harmonized Landsat Sentinel 10m (HLS10) 作为参考，对齐并协调Harmonized Landsat Sentinel 30m (HLS30) 图像。我们的方法旨在弥合这些传感器之间的分辨率差距，并提高超分辨率Landsat图像的质量。定量和定性评估证明了我们方法的有效性，显示了其增强基于卫星的传感应用的潜力。这项研究为异构卫星图像超分辨率的可行性提供了见解，并强调了该领域未来发展的主要考虑因素。", "summary": "本研究提出了一个初步框架，用于对齐和超分辨率处理多传感器卫星图像，以解决不同传感器间分辨率差异带来的挑战。该框架以Harmonized Landsat Sentinel 10m (HLS10) 数据为参考，对Harmonized Landsat Sentinel 30m (HLS30) 图像进行对齐和协调，旨在提高超分辨率Landsat图像的质量。实验结果表明，该方法有效且具有增强卫星传感应用的潜力，并为异构卫星图像超分辨率的未来发展提供了可行性分析和关键考量。", "keywords": "高分辨率, 多传感器, 卫星图像, 超分辨率, 对齐", "comments": "该研究的创新之处在于其针对真实多传感器卫星数据（而非人工降采样数据）进行超分辨率处理，并考虑了异构传感器特性。其重要性在于为高分辨率卫星图像融合和应用提供了实用框架，为弥合不同传感器分辨率鸿沟提供了解决方案。该方法为未来更复杂的异构数据融合和超分辨率技术奠定了基础。"}}
{"id": "2507.06460", "title": "Ragged Blocks: Rendering Structured Text with Style", "authors": ["Sam Cohen", "Ravi Chugh"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      UIST 2025 Paper + Appendices", "url": "http://arxiv.org/abs/2507.06460v2", "summary": "Whether it be source code in a programming language, prose in natural\nlanguage, or otherwise, text is highly structured. Currently, text\nvisualizations are confined either to _flat, line-based_ decorations, which can\nconvey only limited information about textual structure, or _nested boxes_,\nwhich convey structure but often destroy the typographic layout of the\nunderlying text. We hypothesize that the lack of rich styling options limits\nthe kinds of information that are displayed alongside text, wherever it may be\ndisplayed.\n  In this paper, we show that it is possible to achieve arbitrarily nested\ndecorations while minimally disturbing the underlying typographic layout.\nSpecifically, we present a layout algorithm that generates _ragged blocks_, or\n_rocks_, which are rectilinear polygons that allow nested text to be compactly\nrendered even when styled with borders and padding. Our layout algorithm is\nevaluated on a benchmark suite comprising representative source code files in\nmultiple programming languages. The (ragged block) layouts produced by our\nalgorithm are substantially more compact than the (rectangular block) layouts\nproduced by conventional techniques, when uniformly styling every element in\nthe syntax tree with borders and padding.", "comment": "UIST 2025 Paper + Appendices", "pdf_url": "http://arxiv.org/pdf/2507.06460v2", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-31", "AI": {"title_translation": "不规则块：带样式渲染结构化文本", "tldr": "本文提出了一种名为“不规则块”（ragged blocks）的新布局算法，能够在不破坏排版布局的情况下，为结构化文本实现任意嵌套的装饰，并生成比传统技术更紧凑的布局。", "motivation": "目前的文本可视化方法要么局限于扁平、基于行的装饰，信息量有限；要么使用嵌套框，虽然能传达结构但常破坏文本排版。作者假设缺乏丰富的样式选项限制了文本旁可显示的信息种类。", "method": "提出了一种布局算法，用于生成“不规则块”（ragged blocks 或 rocks），这是一种矩形多边形，即使在带有边框和填充的情况下，也能紧凑地渲染嵌套文本，且最大限度地不干扰底层排版布局。", "result": "在包含多种编程语言源代码文件的基准测试套件上进行评估。当对语法树中的每个元素统一应用边框和填充时，该算法生成的不规则块布局比传统技术生成的矩形块布局明显更紧凑。", "conclusion": "本文证明了在最小程度干扰底层排版布局的情况下，实现任意嵌套装饰是可能的。通过提出的不规则块布局算法，可以紧凑地渲染带样式的嵌套文本。", "translation": "无论是编程语言的源代码、自然语言的散文，还是其他形式，文本都具有高度的结构性。目前，文本可视化要么局限于“扁平的、基于行的”装饰，这种装饰只能传达有限的文本结构信息；要么使用“嵌套框”，这种方式虽然能传达结构，但通常会破坏底层文本的排版布局。我们假设，缺乏丰富的样式选项限制了无论文本在何处显示时，能够与文本一同显示的信息种类。\n\n在本文中，我们展示了在最小程度干扰底层排版布局的情况下，实现任意嵌套装饰是可能的。具体来说，我们提出了一种布局算法，该算法生成“不规则块”（ragged blocks，简称 rocks），这是一种矩形多边形，即使在带有边框和填充的情况下，也能紧凑地渲染嵌套文本。我们的布局算法在一个包含多种编程语言代表性源代码文件的基准测试套件上进行了评估。当对语法树中的每个元素统一应用边框和填充时，我们的算法生成的不规则块布局比传统技术生成的（矩形块）布局明显更紧凑。", "summary": "本文提出了一种名为“不规则块”（ragged blocks）的创新布局算法，旨在解决现有文本可视化方法在展示结构化文本时，要么信息受限要么破坏排版的问题。该算法能够生成紧凑的、带样式的嵌套文本渲染，通过使用矩形多边形（不规则块）在最小化干扰原始排版布局的同时实现任意嵌套装饰。实验结果表明，与传统方法相比，该算法在处理带有边框和填充的源代码时，能生成更紧凑的布局。", "keywords": "不规则块, 结构化文本, 文本渲染, 布局算法, 可视化", "comments": "这篇论文提出了一种新颖的文本渲染方法，即“不规则块”，它在保持文本排版完整性的同时，解决了传统方法在展示结构化信息方面的局限性。其创新点在于提出了一种能够实现任意嵌套装饰且不破坏原有版面的布局算法。这对于代码编辑器、文档渲染器等需要丰富文本样式和结构展示的应用具有重要意义。该方法通过紧凑的布局，有效地提升了信息显示效率。"}}
{"id": "2507.23675", "title": "One-Step Flow Policy Mirror Descent", "authors": ["Tianyi Chen", "Haitong Ma", "Na Li", "Kai Wang", "Bo Dai"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23675v1", "summary": "Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23675v1", "cate": "cs.LG", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "一步流策略镜像下降", "tldr": "本文提出流策略镜像下降（FPMD），一个在线强化学习算法，实现了策略推理过程中的一步采样，解决了扩散策略模型推理慢的问题，并在保持性能的同时显著提升了推理速度。", "motivation": "现有的扩散策略模型在在线强化学习中虽然表现出色，但其推理过程依赖于缓慢的迭代采样，这限制了它们的响应速度。", "method": "本文提出流策略镜像下降（FPMD）算法，该算法通过利用直线插值流匹配模型中分布方差和单步采样离散化误差之间的理论联系，实现了策略推理过程中的一步采样。该方法无需额外的蒸馏或一致性训练。文章还提出了基于流策略和MeanFlow策略参数化的两种算法变体。", "result": "在MuJoCo基准上的广泛实证评估表明，FPMD算法在推理过程中所需的函数评估次数比扩散策略基线少数百倍，同时展现出与之相当的强大性能。", "conclusion": "流策略镜像下降（FPMD）算法为在线强化学习提供了一种高效的替代方案，它克服了扩散策略推理缓慢的限制，通过一步采样显著加速了推理过程，同时保持了与现有扩散策略相当的性能。", "translation": "扩散策略因其强大的表达能力在在线强化学习（RL）中取得了巨大成功。然而，扩散策略模型的推理依赖于缓慢的迭代采样过程，这限制了它们的响应速度。为了克服这一限制，我们提出了流策略镜像下降（FPMD），一种在线RL算法，能够在策略推理期间实现一步采样。我们的方法利用了直线插值流匹配模型中分布方差和单步采样离散化误差之间的理论联系，并且不需要额外的蒸馏或一致性训练。我们分别提出了基于流策略和MeanFlow策略参数化的两种算法变体。在MuJoCo基准上的广泛实证评估表明，我们的算法展现出与扩散策略基线相当的强大性能，同时在推理过程中所需的函数评估次数减少了数百倍。", "summary": "本文提出了一种名为流策略镜像下降（FPMD）的在线强化学习算法，旨在解决扩散策略模型推理速度慢的问题。FPMD通过利用分布方差与流匹配模型中单步采样离散化误差之间的理论联系，实现了策略推理的一步采样，且无需额外训练。实验结果表明，该算法在保持与扩散策略相当性能的同时，显著加快了推理速度，减少了数百倍的函数评估次数。", "keywords": "流策略镜像下降, 在线强化学习, 扩散策略, 一步采样, 推理速度", "comments": "这项研究的创新之处在于提出了一种新颖的在线强化学习算法FPMD，它通过实现一步采样显著提升了扩散策略的推理效率，同时无需额外的训练步骤。这对于需要快速响应的在线RL应用具有重要意义，有望推动扩散策略在实际部署中的应用。"}}
{"id": "2507.23158", "title": "User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal", "authors": ["Yuhan Liu", "Michael J. Q. Zhang", "Eunsol Choi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Earlier version of this paper was presented at 2nd Workshop on Models of Human Feedback for AI Alignment (MoFA), ICML 2025", "url": "http://arxiv.org/abs/2507.23158v1", "summary": "Once language models (LMs) are deployed, they can interact with users\nlong-term, ideally evolving continuously based on their feedback. Asking for\ndirect user feedback can be disruptive; thus, we study harvesting user feedback\nfrom user-LM interaction logs. We study implicit user feedback in two user-LM\ninteraction datasets (WildChat and LMSYS). First, we analyze user feedback in\nthe user-LLM conversation trajectory, providing insights into when and why such\nfeedback occurs. Second, we study harvesting learning signals from such\nimplicit user feedback. We find that the contents of user feedback (e.g., user\nwanted clarification), not just the polarity (e.g., users were unhappy with the\nprevious model response), can improve model performance in short human-designed\nquestions (MTBench) but not on longer and more complex questions (WildBench).\nWe also find that the usefulness of user feedback is largely tied to the\nquality of the user's initial prompt. Together, we provide an in-depth study of\nimplicit user feedback, showing its potential and limitations.", "comment": "Earlier version of this paper was presented at 2nd Workshop on Models\n  of Human Feedback for AI Alignment (MoFA), ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.23158v1", "cate": "cs.CL", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "人类-大型语言模型对话中的用户反馈：理解用户的视角但作为学习信号时存在噪声", "tldr": "研究了从人类-大型语言模型（LLM）交互日志中获取隐式用户反馈的潜力与局限性，发现其在理解用户方面有价值，但作为学习信号改进模型性能时存在噪声，尤其是在复杂问题上。", "motivation": "语言模型部署后理想情况下应根据用户反馈持续进化，但直接询问用户反馈可能会造成干扰，因此本研究旨在探讨从用户-LM交互日志中获取隐式用户反馈的方法及其作为学习信号的有效性。", "method": "本研究在两个用户-LLM交互数据集（WildChat和LMSYS）中对隐式用户反馈进行了分析。首先，分析了用户反馈在对话轨迹中发生的时间和原因。其次，研究了如何从这些隐式用户反馈中提取学习信号，并评估其对模型性能的影响。", "result": "研究发现，用户反馈的内容（例如用户需要澄清），而不仅仅是极性（例如用户对模型回应不满意），可以提高模型在短小、人类设计问题（MTBench）上的性能，但在更长、更复杂问题（WildBench）上则无效。此外，用户反馈的有用性与用户初始提示的质量密切相关。", "conclusion": "本研究对隐式用户反馈进行了深入分析，揭示了其在理解用户方面的潜力以及作为学习信号改进大型语言模型时的局限性。", "translation": "一旦语言模型（LMs）部署，它们可以与用户长期互动，理想情况下根据用户的反馈持续进化。直接询问用户反馈可能会造成干扰；因此，我们研究从用户-LM交互日志中获取用户反馈。我们在两个用户-LM交互数据集（WildChat和LMSYS）中研究了隐式用户反馈。首先，我们分析了用户在LLM对话轨迹中的反馈，提供了关于此类反馈何时以及为何发生的见解。其次，我们研究了如何从这些隐式用户反馈中获取学习信号。我们发现，用户反馈的内容（例如，用户需要澄清），而不仅仅是极性（例如，用户对之前的模型回应不满意），可以提高模型在短小、人类设计问题（MTBench）上的性能，但在更长、更复杂问题（WildBench）上则不能。我们还发现，用户反馈的有用性在很大程度上取决于用户初始提示的质量。总而言之，我们对隐式用户反馈进行了深入研究，展示了其潜力和局限性。", "summary": "这项研究探讨了从人类-大型语言模型（LLM）交互日志中获取隐式用户反馈的潜力与局限性。通过分析WildChat和LMSYS数据集，研究人员发现用户反馈的内容而非仅极性，能改善模型在简单问题上的表现，但在复杂问题上效果不佳。此外，用户反馈的有效性与初始提示质量紧密相关。研究强调了隐式用户反馈在理解用户方面的价值，并指出其作为学习信号的噪声特性。", "keywords": "用户反馈, 大型语言模型, 隐式反馈, 学习信号, 对话系统", "comments": "这篇论文创新性地探讨了从隐式用户交互中获取反馈以改进LLM的挑战和机遇。它强调了仅仅依赖反馈的极性是不够的，而内容至关重要，并揭示了反馈质量与用户提示质量的关联。研究指出了反馈在复杂问题上的效用有限，这为未来研究提供了明确的方向，例如如何更有效地利用隐式反馈来提升LLM在复杂场景下的性能。"}}
{"id": "2503.03222", "title": "Mocap-2-to-3: Multi-view Lifting for Monocular Motion Recovery with 2D Pretraining", "authors": ["Zhumei Wang", "Zechen Hu", "Ruoxi Guo", "Huaijin Pi", "Ziyong Feng", "Sida Peng", "Xiaowei Zhou", "Mingtao Pei", "Siyuan Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2503.03222v5", "summary": "Recovering absolute human motion from monocular inputs is challenging due to\ntwo main issues. First, existing methods depend on 3D training data collected\nfrom limited environments, constraining out-of-distribution generalization. The\nsecond issue is the difficulty of estimating metric-scale poses from monocular\ninput. To address these challenges, we introduce Mocap-2-to-3, a novel\nframework that performs multi-view lifting from monocular input by leveraging\n2D data pre-training, enabling the reconstruction of metrically accurate 3D\nmotions with absolute positions. To leverage abundant 2D data, we decompose\ncomplex 3D motion into multi-view syntheses. We first pretrain a single-view\ndiffusion model on extensive 2D datasets, then fine-tune a multi-view model\nusing public 3D data to enable view-consistent motion generation from monocular\ninput, allowing the model to acquire action priors and diversity through 2D\ndata. Furthermore, to recover absolute poses, we propose a novel human motion\nrepresentation that decouples the learning of local pose and global movements,\nwhile encoding geometric priors of the ground to accelerate convergence. This\nenables progressive recovery of motion in absolute space during inference.\nExperimental results on in-the-wild benchmarks demonstrate that our method\nsurpasses state-of-the-art approaches in both camera-space motion realism and\nworld-grounded human positioning, while exhibiting superior generalization\ncapability. Our code will be made publicly available.", "comment": "Project page: https://wangzhumei.github.io/mocap-2-to-3/", "pdf_url": "http://arxiv.org/pdf/2503.03222v5", "cate": "cs.CV", "date": "2025-03-05", "updated": "2025-07-31", "AI": {"title_translation": "Mocap-2-to-3: 基于2D预训练的单目运动恢复多视角提升", "tldr": "Mocap-2-to-3是一个新框架，通过2D数据预训练和多视角提升，从单目输入中恢复绝对人体运动，解决了3D数据依赖和度量尺度估计难题，并在野外基准上表现优越。", "motivation": "现有方法依赖有限的3D训练数据，导致泛化能力受限；从单目输入估计度量尺度的姿态困难。", "method": "Mocap-2-to-3框架通过利用2D数据预训练进行多视角提升，以重建度量准确的3D运动和绝对位置。具体方法包括：1) 将复杂3D运动分解为多视角合成。2) 在大量2D数据集上预训练单视角扩散模型。3) 使用公共3D数据微调多视角模型，实现单目输入生成视角一致的运动，并通过2D数据获取动作先验和多样性。4) 提出一种新的人体运动表示，解耦局部姿态和全局运动的学习，并编码地面几何先验以加速收敛，从而在推理过程中逐步恢复绝对空间中的运动。", "result": "在野外基准测试中，Mocap-2-to-3方法在摄像机空间运动真实性和世界定位人体姿态方面超越了最先进的方法，并展现出卓越的泛化能力。", "conclusion": "Mocap-2-to-3通过结合2D数据预训练和创新的多视角提升及运动表示，有效解决了单目输入恢复绝对人体运动的挑战，实现了高精度、高泛化能力的3D运动重建。", "translation": "从单目输入中恢复绝对人体运动由于两个主要问题而具有挑战性。首先，现有方法依赖于从有限环境中收集的3D训练数据，限制了分布外泛化能力。第二个问题是从单目输入估计度量尺度姿态的困难。为了解决这些挑战，我们引入了Mocap-2-to-3，这是一个新颖的框架，通过利用2D数据预训练，从单目输入执行多视角提升，从而能够重建具有绝对位置的度量准确的3D运动。为了利用丰富的2D数据，我们将复杂的3D运动分解为多视角合成。我们首先在大量的2D数据集上预训练一个单视角扩散模型，然后使用公共3D数据微调一个多视角模型，以实现从单目输入生成视角一致的运动，从而使模型能够通过2D数据获取动作先验和多样性。此外，为了恢复绝对姿态，我们提出了一种新颖的人体运动表示，它解耦了局部姿态和全局运动的学习，同时编码了地面的几何先验以加速收敛。这使得在推理过程中能够逐步恢复绝对空间中的运动。在野外基准测试上的实验结果表明，我们的方法在摄像机空间运动真实性和世界定位人体姿态方面超越了最先进的方法，同时表现出卓越的泛化能力。我们的代码将公开发布。", "summary": "Mocap-2-to-3是一个创新的框架，旨在解决从单目输入恢复绝对人体运动的挑战，特别是对3D训练数据的依赖和度量尺度姿态估计的困难。该方法通过在大量2D数据上预训练单视角扩散模型，然后用3D数据微调多视角模型，实现多视角提升。此外，它引入了一种新颖的人体运动表示，分离局部姿态和全局运动的学习，并整合地面几何先验，以在推理时逐步恢复绝对位置。实验证明，Mocap-2-to-3在运动真实性和人体定位方面优于现有技术，并具有出色的泛化能力。", "keywords": "单目运动恢复, 2D预训练, 多视角提升, 3D人体姿态, 绝对位置", "comments": "该论文的创新点在于巧妙地利用了大量易于获取的2D数据进行预训练，并通过多视角合成和解耦运动表示来克服单目3D重建的传统难题，特别是实现了绝对位置的恢复和更好的泛化能力，这对于实际应用具有重要意义。结合扩散模型和几何先验是其成功的关键。"}}
{"id": "2409.14148", "title": "A New Upper Bound for Distributed Hypothesis Testing Using the Auxiliary Receiver Approach", "authors": ["Zhenduo Wen", "Amin Gohari"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.14148v4", "summary": "This paper employs the add-and-subtract technique of the auxiliary receiver\napproach to establish a new upper bound for the distributed hypothesis testing\nproblem. This new bound has fewer assumptions than the upper bound proposed by\nRahman and Wagner, is at least as tight as the bound by Rahman and Wagner, and\ncan outperform it in certain Gaussian settings. Conceptually speaking, unlike\nRahman and Wagner, who view their additional receiver as side information, we\nview it as an auxiliary receiver and use a different manipulation for\nsingle-letterization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.14148v4", "cate": "cs.IT", "date": "2024-09-21", "updated": "2025-07-31", "AI": {"title_translation": "使用辅助接收器方法对分布式假设检验的新上界", "tldr": "本文提出了一种使用辅助接收器方法的新上界，用于分布式假设检验问题，该上界比现有方法具有更少的假设，至少一样紧密，并且在某些高斯设置下表现更好。", "motivation": "现有分布式假设检验问题的上界（由Rahman和Wagner提出）存在较多假设，并且在某些情况下可能不够紧密。本文旨在通过提出一种新的上界来改进这一点。", "method": "本文采用辅助接收器方法的加减技术来建立分布式假设检验问题的新上界。与Rahman和Wagner将额外接收器视为旁信息不同，本文将其视为辅助接收器并使用不同的单字母化处理。", "result": "本文提出的新上界比Rahman和Wagner提出的上界具有更少的假设，至少与Rahman和Wagner的界限一样紧密，并且在某些高斯设置下可以超越它。", "conclusion": "本文成功地为分布式假设检验问题建立了一个新的、更优越的上界，该上界在假设、紧密性及特定场景表现上均优于现有方法。", "translation": "本文采用辅助接收器方法的加减技术，为分布式假设检验问题建立了一个新的上界。这个新界比Rahman和Wagner提出的上界具有更少的假设，至少和Rahman和Wagner的界限一样紧密，并且在某些高斯设置下可以超越它。从概念上讲，与Rahman和Wagner将他们的额外接收器视为旁信息不同，我们将其视为辅助接收器并使用不同的单字母化处理。", "summary": "本文提出了一种基于辅助接收器方法的加减技术，用于分布式假设检验问题的新上界。该新上界与Rahman和Wagner提出的现有上界相比，具有更少的假设、至少相同的紧密性，并在高斯环境下展现出更优的性能。其核心创新在于对辅助接收器概念的不同理解和处理方式。", "keywords": "分布式假设检验, 上界, 辅助接收器, 加减技术, 信息论", "comments": "本文的创新之处在于提出了一个更具普适性和性能优势的分布式假设检验上界。通过对辅助接收器概念的重新定义和巧妙的数学处理（加减技术），作者成功地克服了现有方法的一些局限性，特别是在高斯设置下的性能提升，这对于该领域的研究具有重要意义。"}}
{"id": "2507.23002", "title": "Noise-Coded Illumination for Forensic and Photometric Video Analysis", "authors": ["Peter F. Michael", "Zekun Hao", "Serge Belongie", "Abe Davis"], "categories": ["cs.GR", "cs.CR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      ACM Transactions on Graphics (2025), presented at SIGGRAPH 2025", "url": "http://arxiv.org/abs/2507.23002v1", "summary": "The proliferation of advanced tools for manipulating video has led to an arms\nrace, pitting those who wish to sow disinformation against those who want to\ndetect and expose it. Unfortunately, time favors the ill-intentioned in this\nrace, with fake videos growing increasingly difficult to distinguish from real\nones. At the root of this trend is a fundamental advantage held by those\nmanipulating media: equal access to a distribution of what we consider\nauthentic (i.e., \"natural\") video. In this paper, we show how coding very\nsubtle, noise-like modulations into the illumination of a scene can help combat\nthis advantage by creating an information asymmetry that favors verification.\nOur approach effectively adds a temporal watermark to any video recorded under\ncoded illumination. However, rather than encoding a specific message, this\nwatermark encodes an image of the unmanipulated scene as it would appear lit\nonly by the coded illumination. We show that even when an adversary knows that\nour technique is being used, creating a plausible coded fake video amounts to\nsolving a second, more difficult version of the original adversarial content\ncreation problem at an information disadvantage. This is a promising avenue for\nprotecting high-stakes settings like public events and interviews, where the\ncontent on display is a likely target for manipulation, and while the\nillumination can be controlled, the cameras capturing video cannot.", "comment": "ACM Transactions on Graphics (2025), presented at SIGGRAPH 2025", "pdf_url": "http://arxiv.org/pdf/2507.23002v1", "cate": "cs.GR", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "用于法证和光度视频分析的噪声编码照明", "tldr": "该论文提出了一种通过在场景照明中编码微妙的噪声状调制来创建视频时间水印的方法，从而在对抗深度伪造时产生信息不对称，使得伪造视频更难创建。", "motivation": "随着视频操纵工具的普及，伪造视频越来越难以与真实视频区分，而操纵者拥有与真实视频相同的访问权限，这给了他们一个根本性优势。本文旨在通过创造有利于验证的信息不对称来对抗这种优势。", "method": "通过将非常微妙的、类似噪声的调制编码到场景照明中。这种方法能有效地为在编码照明下录制的任何视频添加一个时间水印。该水印不编码特定消息，而是编码在仅由编码照明照亮时未被操纵场景的图像。", "result": "即使对手知道该技术正在使用，创建可信的编码伪造视频也相当于在信息劣势下解决一个更困难的对抗性内容创建问题。", "conclusion": "这种方法为保护公共活动和采访等高风险环境提供了一个有前景的途径，在这些环境中，显示的内容很可能是操纵目标，且照明可以控制，而捕获视频的摄像机则不能。", "translation": "视频操纵高级工具的普及引发了一场军备竞赛，将那些希望散布虚假信息的人与那些希望检测和揭露虚假信息的人对立起来。不幸的是，在这场竞赛中，时间有利于不良意图者，因为伪造视频越来越难以与真实视频区分。这种趋势的根源在于媒体操纵者拥有的一个根本优势：他们可以平等地访问我们认为是真实的（即“自然”）视频的分发。在本文中，我们展示了如何在场景照明中编码非常微妙的、类似噪声的调制，从而通过创建有利于验证的信息不对称来帮助对抗这种优势。我们的方法有效地为在编码照明下录制的任何视频添加了一个时间水印。然而，这个水印并非编码特定消息，而是编码了在仅由编码照明照亮时未被操纵场景的图像。我们表明，即使对手知道我们的技术正在使用，创建一个看似可信的编码伪造视频也相当于在信息劣势下解决原始对抗性内容创建问题的第二个、更困难的版本。这为保护公共活动和采访等高风险环境提供了一个有前景的途径，在这些环境中，显示的内容很可能是操纵目标，且照明可以控制，而捕获视频的摄像机则不能。", "summary": "本文提出了一种新颖的方法，通过在场景照明中编码微妙的噪声状调制来对抗视频深度伪造。这种“噪声编码照明”技术在录制的视频中创建了一个时间水印，该水印编码了未被操纵的场景在特定照明下的图像。作者指出，即使对手知道该技术，创建可信的伪造视频也变得更加困难，因为这要求在信息劣势下解决更复杂的对抗性问题。该方法在高风险环境中具有重要的应用前景，例如公共事件和访谈，在这些环境中可以控制照明但无法控制摄像机。", "keywords": "噪声编码照明, 视频取证, 深度伪造检测, 时间水印, 信息不对称", "comments": "该论文的创新之处在于通过在源头（照明）引入信息不对称来对抗视频操纵，而不是仅仅依赖于后捕获分析。这种主动的方法为高风险应用中视频的真实性提供了一种新颖的防御手段，具有重要的实际意义。"}}
{"id": "2502.15544", "title": "Learning-based model predictive control for passenger-oriented train rescheduling with flexible train composition", "authors": ["Xiaoyu Liu", "Caio Fabio Oliveira da Silva", "Azita Dabiri", "Yihui Wang", "Bart De Schutter"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      14 pages, 14 figures, submitted to journal", "url": "http://arxiv.org/abs/2502.15544v2", "summary": "This paper focuses on passenger-oriented real-time train rescheduling,\nconsidering flexible train composition and rolling stock circulation, by\nintegrating learning-based and optimization-based approaches. A learning-based\nmodel predictive control (MPC) approach is developed for real-time train\nrescheduling with flexible train composition and rolling stock circulation to\naddress time-varying passenger demands. In the proposed approach, the values of\nthe integer variables are obtained by pre-trained long short-term memory (LSTM)\nnetworks, while the continuous variables are determined through nonlinear\nconstrained optimization. The learning-based MPC approach enables us to jointly\nconsider efficiency and constraint satisfaction by combining learning-based and\noptimization-based approaches. In order to reduce the number of integer\nvariables, four presolve techniques are developed to prune a subset of integer\ndecision variables. Numerical simulations based on real-life data from the\nBeijing urban rail transit system are conducted to illustrate the effectiveness\nof the developed learning-based MPC approach.", "comment": "14 pages, 14 figures, submitted to journal", "pdf_url": "http://arxiv.org/pdf/2502.15544v2", "cate": "eess.SY", "date": "2025-02-21", "updated": "2025-07-31", "AI": {"title_translation": "基于学习的模型预测控制，用于面向乘客的灵活列车编组列车重调度", "tldr": "本文提出了一种结合学习和优化的基于学习的模型预测控制（MPC）方法，用于实时列车重调度，该方法考虑了灵活列车编组和车辆周转，以应对时变客流需求，并通过预训练的LSTM网络和非线性约束优化来确定变量，同时开发了预处理技术来减少整数变量数量，并通过北京城市轨道交通系统的真实数据验证了其有效性。", "motivation": "解决实时列车重调度中遇到的时变客流需求问题，并考虑灵活列车编组和车辆周转，以实现以乘客为导向的调度。", "method": "开发了一种基于学习的模型预测控制（MPC）方法，用于实时列车重调度。该方法整合了学习和优化方法：整数变量通过预训练的LSTM网络获取，连续变量通过非线性约束优化确定。为了减少整数变量的数量，还开发了四种预处理技术来修剪部分整数决策变量。", "result": "通过在北京城市轨道交通系统真实数据上的数值模拟，证明了所开发的基于学习的MPC方法的有效性，该方法能够联合考虑效率和约束满足。", "conclusion": "所提出的基于学习的模型预测控制方法能够有效地解决考虑灵活列车编组和车辆周转的乘客导向型实时列车重调度问题，并在效率和约束满足之间取得平衡。", "translation": "本文关注以乘客为导向的实时列车重调度，通过整合基于学习和基于优化的方法，考虑灵活的列车编组和车辆周转。开发了一种基于学习的模型预测控制（MPC）方法，用于实时列车重调度，该方法考虑了灵活的列车编组和车辆周转，以解决时变客流需求。在所提出的方法中，整数变量的值通过预训练的长短期记忆（LSTM）网络获得，而连续变量通过非线性约束优化确定。基于学习的MPC方法通过结合基于学习和基于优化的方法，使我们能够共同考虑效率和约束满足。为了减少整数变量的数量，开发了四种预处理技术来修剪一部分整数决策变量。基于北京城市轨道交通系统真实数据的数值模拟，证明了所开发的基于学习的MPC方法的有效性。", "summary": "本文提出了一种创新的基于学习的模型预测控制（MPC）方法，用于实时、以乘客为导向的列车重调度，该方法特别考虑了灵活的列车编组和车辆周转，以适应不断变化的客流需求。该方法巧妙地结合了学习和优化技术：利用预训练的LSTM网络处理整数变量，并通过非线性约束优化确定连续变量。为提高效率，研究还引入了四种预处理技术以减少整数决策变量。通过在北京城市轨道交通系统的真实数据进行模拟，验证了该方法在兼顾效率和满足约束方面的有效性。", "keywords": "列车重调度, 模型预测控制, 灵活列车编组, 深度学习, 优化", "comments": "本文的创新点在于将学习（LSTM）和优化（非线性约束优化）相结合，应用于复杂的列车重调度问题，并考虑了灵活的列车编组和车辆周转。这种混合方法有望提高实时决策的效率和准确性，尤其是在处理时变客流需求方面。预处理技术的使用也体现了对计算效率的考量。该研究为智能交通系统中的调度优化提供了有价值的参考。"}}
{"id": "2507.22901", "title": "Accelerated and Optimized Search of Imperceptible Color Vibration for Embedding Information into LCD images", "authors": ["Shingo Hattori", "Takefumi Hiraki"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Presented at ACM SIGGRAPH Asia 2022 Posters", "url": "http://arxiv.org/abs/2507.22901v1", "summary": "Large, high-resolution displays are installed throughout the city as public\ndisplays. By superimposing invisible information on the images of these\ndisplays, large numbers of devices with cameras and sensors can communicate\nwith the displays without prior pairing. Several applications have been\nproposed, such as operating robots or communicating information to users by\ndisplaying 2D codes on images. However, the display of 2D codes has the problem\nof compromising the appearance of displayed content.\n  Abe et al. proposed a method of communicating with devices by superimposing\ninvisible information using color vibration on images displayed on\noff-the-shelf liquid-crystal displays (LCD). Using this method, we can embed\nthe information for devices in images without interfering with the displayed\ncontent. Abe et al. uses a simple serial loop operation to search for color\npairs comprising a color vibration, which requires a very long processing time\ndue to the huge search space.\n  In this paper, we propose an accelerated and optimized search method for\ncolor pairs that constitute the imperceptible color vibration for embedding\ninformation on LCD images. To achieve fast color pair search, we parallelized\nthe search process, which is previously done individually, by using arrays\nrepresenting the amount of movement and an operation to extract elements from\nthe array that satisfy the conditions. In addition, we investigate the amount\nof information that can be superimposed on nine color images using the\nimperceptible color vibration and clarify the applicability of embedding\ninformation into images using the color vibration.", "comment": "Presented at ACM SIGGRAPH Asia 2022 Posters", "pdf_url": "http://arxiv.org/pdf/2507.22901v1", "cate": "cs.HC", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "用于将信息嵌入LCD图像的不可感知颜色振动加速优化搜索", "tldr": "本文提出了一种加速和优化搜索不可感知颜色振动的方法，用于将信息嵌入LCD图像中，解决了现有方法搜索时间过长的问题，并通过并行化提高了效率。", "motivation": "城市中大量高分辨率显示器作为公共显示器，需要与带有摄像头和传感器的设备进行通信。现有的2D码嵌入信息方式会损害显示内容的外观。虽然Abe等人提出了利用不可感知颜色振动嵌入信息的方法，但其搜索颜色对的过程是串行循环操作，搜索空间巨大导致处理时间过长。", "method": "本文提出了一种加速和优化搜索构成不可感知颜色振动的颜色对的方法。为了实现快速颜色对搜索，通过使用表示移动量的数组和从数组中提取满足条件的元素的操作，将之前单独进行的搜索过程并行化。", "result": "研究了使用不可感知颜色振动可以在九种彩色图像上叠加的信息量，并阐明了使用颜色振动将信息嵌入图像的适用性。", "conclusion": "本文提出的加速和优化搜索方法提高了不可感知颜色振动颜色对的搜索效率，并阐明了其在LCD图像中嵌入信息的适用性。", "translation": "大型高分辨率显示器作为公共显示器安装在整个城市。通过在这些显示器的图像上叠加不可见信息，大量配备摄像头和传感器的设备可以与显示器通信，而无需预先配对。已经提出了一些应用，例如通过在图像上显示2D码来操作机器人或向用户传达信息。然而，显示2D码存在损害显示内容外观的问题。\n  Abe等人提出了一种通过在市售液晶显示器（LCD）上显示的图像上使用颜色振动叠加不可见信息来与设备通信的方法。使用这种方法，我们可以在不干扰显示内容的情况下将设备信息嵌入图像中。Abe等人使用简单的串行循环操作来搜索构成颜色振动的颜色对，由于搜索空间巨大，这需要非常长的处理时间。\n  在本文中，我们提出了一种加速和优化搜索构成不可感知颜色振动的颜色对的方法，用于将信息嵌入LCD图像中。为了实现快速颜色对搜索，我们通过使用表示移动量的数组和从数组中提取满足条件的元素的操作，将之前单独进行的搜索过程并行化。此外，我们研究了使用不可感知颜色振动可以在九种彩色图像上叠加的信息量，并阐明了使用颜色振动将信息嵌入图像的适用性。", "summary": "本研究旨在解决将不可感知信息嵌入LCD图像中时，现有颜色振动方法搜索颜色对效率低下的问题。针对Abe等人提出的方法中串行搜索颜色对耗时过长的问题，本文提出了一种加速和优化搜索算法。该方法通过并行化搜索过程，利用数组表示颜色移动量并提取符合条件的元素，显著提高了搜索速度。研究还探讨了使用这种不可感知颜色振动技术在不同彩色图像上可嵌入的信息量，并明确了其在图像信息嵌入领域的适用性。", "keywords": "不可感知颜色振动, LCD, 信息嵌入, 加速搜索, 并行化", "comments": "本文的创新点在于提出了并行化搜索不可感知颜色振动颜色对的方法，有效解决了现有串行搜索效率低下的问题，对于在公共显示器上无缝嵌入信息具有重要意义。该方法避免了传统2D码对视觉内容的干扰，为设备间通信提供了更隐蔽、美观的解决方案。其对信息嵌入量的探讨也为实际应用提供了指导。"}}
{"id": "2507.22949", "title": "Convergence analysis of a second-order SAV-ZEC scheme for the Cahn-Hilliard-Navier-Stokes system", "authors": ["Jingwei Sun", "Zeyu Xia", "Wei Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22949v1", "summary": "Incorporating the scalar auxiliary variable (SAV) method and the zero energy\ncontribution (ZEC) technique, we analyze a linear and fully decoupled numerical\nscheme for the Cahn-Hilliard-Naiver-Stokes (CHNS) system. More precisely, the\nfully discrete scheme combines the marker-and-cell (MAC) finite difference\nspatial approximation and BDF2 temporal discretization, as well as the\nAdams-Bashforth extrapolation for the nonlinear terms, based on the SAV-ZEC\nreformulation. A pressure correction approach is applied to decouple the Stokes\nequation. Only constant-coefficient Poisson-like solvers are needed in the\nimplementation for the resulting numerical system. The numerical scheme is\nunconditionally stable with respect to a rewritten total energy functional,\nrepresented in terms of one auxiliary variable in the double-well potential,\nanother auxiliary variable to balance all the nonlinear and coupled terms, the\nsurface energy in the original phase variable, combined with the kinematic\nenergy part. Specifically, the error estimate for the phase variable in the\n$\\ell^{\\infty}(0,T;H_h^1)\\cap\\ell^2(0,T;H_h^3)$ norm, the velocity variable in\nthe $\\ell^{\\infty}(0,T;\\ell^2)\\cap\\ell^2(0,T;H_h^1)$ norm, is derived with\noptimal convergence rates.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22949v1", "cate": "math.NA", "date": "2025-07-28", "updated": "2025-07-28", "AI": {"title_translation": "Cahn-Hilliard-Navier-Stokes系统二阶SAV-ZEC格式的收敛性分析", "tldr": "本文分析了一种结合SAV和ZEC技术，用于Cahn-Hilliard-Navier-Stokes系统的线性全解耦二阶数值格式，该格式无条件稳定并具有最优收敛率。", "motivation": "针对Cahn-Hilliard-Navier-Stokes (CHNS) 系统，开发一种线性、完全解耦的数值格式，以简化实现并确保数值稳定性与准确性。", "method": "结合标量辅助变量 (SAV) 方法和零能量贡献 (ZEC) 技术，构建了一个线性完全解耦的数值格式。该格式采用MAC有限差分空间近似、BDF2时间离散化以及Adams-Bashforth外推处理非线性项。此外，应用了压力校正方法来解耦Stokes方程。", "result": "该数值系统实现仅需常系数类泊松求解器。该数值格式对重写的总能量泛函无条件稳定。推导出了相变量和速度变量在特定范数下的误差估计，并达到了最优收敛率。", "conclusion": "结合SAV和ZEC技术的二阶线性全解耦数值格式，为Cahn-Hilliard-Navier-Stokes系统提供了一种高效、稳定且高精度的求解方法，且易于实现。", "translation": "结合标量辅助变量（SAV）方法和零能量贡献（ZEC）技术，我们分析了Cahn-Hilliard-Navier-Stokes（CHNS）系统的一种线性且完全解耦的数值格式。更具体地说，该完全离散格式结合了基于SAV-ZEC重构的Marker-and-Cell（MAC）有限差分空间近似和BDF2时间离散化，以及非线性项的Adams-Bashforth外推。应用了压力校正方法来解耦Stokes方程。在实现所得数值系统时，仅需要常系数类泊松求解器。该数值格式对一个重写的总能量泛函是无条件稳定的，该泛函表示为双阱势中的一个辅助变量、平衡所有非线性和耦合项的另一个辅助变量、原始相变量中的表面能，并结合了动能部分。具体而言，推导出了相变量在$\\ell^{\\infty}(0,T;H_h^1)\\cap\\ell^2(0,T;H_h^3)$范数下，速度变量在$\\ell^{\\infty}(0,T;\\ell^2)\\cap\\ell^2(0,T;H_h^1)$范数下的误差估计，并具有最优收敛率。", "summary": "本文提出并分析了一种用于Cahn-Hilliard-Navier-Stokes (CHNS) 系统的二阶线性完全解耦数值格式。该格式结合了SAV和ZEC技术，采用MAC有限差分空间近似和BDF2时间离散，并通过压力校正实现Stokes方程的解耦。研究表明，该格式仅需常系数泊松求解器，对重写的总能量泛函无条件稳定，并对相变量和速度变量在相应范数下实现了最优收敛率。", "keywords": "Cahn-Hilliard-Navier-Stokes系统, SAV-ZEC方案, 收敛性分析, 数值格式, 无条件稳定", "comments": "这项工作通过结合SAV和ZEC技术，为CHNS系统提供了一种高效且易于实现的数值求解方案。其创新之处在于实现了完全解耦，大大简化了求解过程，同时保持了无条件稳定性和最优收敛率，这对于复杂多物理场系统的数值模拟具有重要意义。"}}
{"id": "2507.19115", "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "authors": ["Shweta Ramesh", "Joy Bose", "Hamender Singh", "A K Raghavan", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Nishrith Saini", "Ricardo Britto"], "categories": ["cs.SE", "cs.AI", "D.2.7"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 1 table. Accepted in ICSME 2025 conference in Auckland", "url": "http://arxiv.org/abs/2507.19115v2", "summary": "Code review is one of the primary means of assuring the quality of released\nsoftware along with testing and static analysis. However, code review requires\nexperienced developers who may not always have the time to perform an in-depth\nreview of code. Thus, automating code review can help alleviate the cognitive\nburden on experienced software developers allowing them to focus on their\nprimary activities of writing code to add new features and fix bugs. In this\npaper, we describe our experience in using Large Language Models towards\nautomating the code review process in Ericsson. We describe the development of\na lightweight tool using LLMs and static program analysis. We then describe our\npreliminary experiments with experienced developers in evaluating our code\nreview tool and the encouraging results.", "comment": "6 pages, 4 figures, 1 table. Accepted in ICSME 2025 conference in\n  Auckland", "pdf_url": "http://arxiv.org/pdf/2507.19115v2", "cate": "cs.SE", "date": "2025-07-25", "updated": "2025-07-31", "AI": {"title_translation": "爱立信利用大型语言模型进行自动化代码审查：一份经验报告", "tldr": "本文介绍了爱立信利用大型语言模型和静态程序分析开发轻量级工具，以自动化代码审查流程，初步实验结果令人鼓舞。", "motivation": "代码审查对软件质量至关重要，但需要经验丰富的开发人员，他们往往没有足够时间进行深入审查，导致认知负担。自动化代码审查可以减轻此负担。", "method": "开发了一个结合大型语言模型（LLMs）和静态程序分析的轻量级工具，并在爱立信进行了初步实验。", "result": "初步实验结果令人鼓舞。", "conclusion": "Not mentioned in abstract", "translation": "代码审查是确保发布软件质量的主要手段之一，与测试和静态分析并列。然而，代码审查需要经验丰富的开发人员，他们可能并非总是有时间对代码进行深入审查。因此，自动化代码审查可以帮助减轻经验丰富的软件开发人员的认知负担，使他们能够专注于编写代码以添加新功能和修复错误的主要活动。在本文中，我们描述了在爱立信利用大型语言模型实现代码审查过程自动化的经验。我们描述了使用大型语言模型和静态程序分析开发轻量级工具的过程。然后，我们描述了与经验丰富的开发人员进行的初步实验，评估了我们的代码审查工具并获得了令人鼓舞的结果。", "summary": "本文介绍了爱立信在利用大型语言模型（LLMs）实现代码审查自动化方面的经验。为了解决经验丰富的开发人员在代码审查中面临的时间和认知负担问题，研究人员开发了一个结合LLMs和静态程序分析的轻量级工具。初步实验结果显示该工具表现令人鼓舞。", "keywords": "代码审查, 大型语言模型, 自动化, 爱立信, 静态分析", "comments": "本文展示了大型语言模型在实际工业环境中应用于代码审查的潜力，通过结合静态分析提升了自动化水平。其创新之处在于将LLMs与传统静态分析结合，为自动化代码审查提供了一种新颖且实用的方法。"}}
{"id": "2507.19119", "title": "PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction", "authors": ["Yanghong Liu", "Xingping Dong", "Ming Li", "Weixing Zhang", "Yidong Lou"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19119v3", "summary": "Pedestrian trajectory prediction is crucial for autonomous driving and\nrobotics. While existing point-based and grid-based methods expose two main\nlimitations: insufficiently modeling human motion dynamics, as they fail to\nbalance local motion details with long-range spatiotemporal dependencies, and\nthe time representations lack interaction with their frequency components in\njointly modeling trajectory sequences. To address these challenges, we propose\nPatchTraj, a dynamic patch-based framework that integrates time-frequency joint\nmodeling for trajectory prediction. Specifically, we decompose the trajectory\ninto raw time sequences and frequency components, and employ dynamic patch\npartitioning to perform multi-scale segmentation, capturing hierarchical motion\npatterns. Each patch undergoes adaptive embedding with scale-aware feature\nextraction, followed by hierarchical feature aggregation to model both\nfine-grained and long-range dependencies. The outputs of the two branches are\nfurther enhanced via cross-modal attention, facilitating complementary fusion\nof temporal and spectral cues. The resulting enhanced embeddings exhibit strong\nexpressive power, enabling accurate predictions even when using a vanilla\nTransformer architecture. Extensive experiments on ETH-UCY, SDD, NBA, and JRDB\ndatasets demonstrate that our method achieves state-of-the-art performance.\nNotably, on the egocentric JRDB dataset, PatchTraj attains significant relative\nimprovements of 26.7% in ADE and 17.4% in FDE, underscoring its substantial\npotential in embodied intelligence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19119v3", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-31", "AI": {"title_translation": "PatchTraj：基于动态分块的统一时频表示学习用于轨迹预测", "tldr": "PatchTraj通过动态分块整合时频建模，解决了现有轨迹预测方法在建模运动动态和时频交互方面的不足，实现了最先进的性能。", "motivation": "现有基于点和基于网格的轨迹预测方法未能充分建模人类运动动态，无法平衡局部运动细节与长程时空依赖；同时，时间表示缺乏与频率分量的交互，限制了轨迹序列的联合建模能力。", "method": "提出PatchTraj框架，通过动态补丁划分集成时频联合建模。具体方法包括：将轨迹分解为原始时间序列和频率分量；采用动态补丁划分进行多尺度分割以捕获分层运动模式；对每个补丁进行自适应嵌入和尺度感知特征提取；通过分层特征聚合建模细粒度和长程依赖；最后，通过跨模态注意力增强时间与频率分支的输出，促进互补融合。", "result": "在ETH-UCY、SDD、NBA和JRDB数据集上取得了最先进的性能。特别是在自我中心JRDB数据集上，ADE相对改进26.7%，FDE相对改进17.4%。", "conclusion": "PatchTraj通过统一的时频表示学习和动态补丁机制，显著提升了轨迹预测的准确性，尤其在具身智能领域展现出巨大潜力。", "translation": "行人轨迹预测对自动驾驶和机器人技术至关重要。现有基于点和基于网格的方法存在两个主要局限性：未能充分建模人类运动动态，因为它们无法平衡局部运动细节与长程时空依赖；以及时间表示在联合建模轨迹序列时缺乏与频率分量的交互。为了应对这些挑战，我们提出了PatchTraj，一个基于动态补丁的框架，它集成了时频联合建模用于轨迹预测。具体而言，我们将轨迹分解为原始时间序列和频率分量，并采用动态补丁划分来执行多尺度分割，捕获分层运动模式。每个补丁都经过自适应嵌入和尺度感知特征提取，然后进行分层特征聚合以建模细粒度和长程依赖。两个分支的输出通过跨模态注意力进一步增强，促进时间线索和频谱线索的互补融合。由此产生的增强嵌入表现出强大的表达能力，即使使用香草Transformer架构也能实现准确预测。在ETH-UCY、SDD、NBA和JRDB数据集上进行的大量实验表明，我们的方法取得了最先进的性能。值得注意的是，在自我中心JRDB数据集上，PatchTraj在ADE方面取得了26.7%的显著相对改进，在FDE方面取得了17.4%的显著相对改进，这突显了其在具身智能方面的巨大潜力。", "summary": "PatchTraj是一个新颖的轨迹预测框架，通过动态补丁划分实现统一的时频表示学习。它将轨迹分解为时域和频域分量，并利用多尺度分割和跨模态注意力，有效解决了现有方法在建模运动动态和时频交互方面的不足。实验证明，PatchTraj在多个数据集上达到了最先进的性能，尤其在具身智能场景中表现出色。", "keywords": "轨迹预测, 时频表示学习, 动态补丁, 跨模态注意力, 具身智能", "comments": "PatchTraj的创新点在于其统一的时频表示学习和动态补丁机制，这有效解决了现有方法在捕捉复杂运动动态和平衡局部/全局依赖方面的局限。通过引入频率分量并利用跨模态注意力进行融合，增强了模型对轨迹序列的理解能力。其在多个数据集上，特别是具身智能场景下的显著性能提升，证明了其方法的有效性和潜力。"}}
{"id": "2507.23362", "title": "Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers", "authors": ["Ji Ma", "Wei Suo", "Peng Wang", "Yanning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted By ACM MM 25", "url": "http://arxiv.org/abs/2507.23362v1", "summary": "Although large vision-language models (LVLMs) have demonstrated impressive\ncapabilities in multi-modal understanding and reasoning, their practical\napplications are still limited by massive model parameters and high\ncomputational costs. Recent efforts from natural language processing (NLP) have\nshown the effectiveness of layer pruning, offering a plausible training-free\ncompression solution. However, due to the modality divergence between vision\nand language, it is unclear whether these NLP techniques are still effective in\nLVLMs. In this paper, we empirically prove that directly applying these layer\npruning methods to LVLMs is ineffective. Through extensive experiments, we find\nthat non-essential vision-language (VL) tokens and inter-layer feature gaps\npose critical challenges to pruning layers in LVLMs. Based on these insights,\nwe propose a novel framework Short-LVLM (SVL) that can utilize important VL\ntokens and mitigate the layer-wise feature gaps. Notably, Short-LVLM not only\nachieves a superior trade-off between performance and efficiency but also\nexhibits several potential advantages, i.e., training-free, model-agnostic, and\nhighly compatible. The code for this work is publicly available at\nhttps://github.com/ASGO-MM/Short-LVLM.", "comment": "Accepted By ACM MM 25", "pdf_url": "http://arxiv.org/pdf/2507.23362v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "Short-LVLM：通过剪枝冗余层来压缩和加速大型视觉-语言模型", "tldr": "Short-LVLM通过剪枝冗余层来压缩和加速大型视觉-语言模型，解决了直接应用NLP层剪枝方法在LVLMs中无效的问题，并实现了性能与效率之间的优越权衡。", "motivation": "大型视觉-语言模型（LVLMs）尽管在多模态理解和推理方面表现出色，但其庞大的模型参数和高计算成本限制了实际应用。虽然自然语言处理（NLP）领域的层剪枝方法已显示出其作为免训练压缩解决方案的有效性，但由于视觉和语言之间的模态差异，尚不清楚这些NLP技术在LVLMs中是否仍然有效。研究发现直接应用这些方法无效，且非必要视觉-语言（VL）token和层间特征差距构成了剪枝LVLMs层面的关键挑战。", "method": "提出了一个新的框架Short-LVLM（SVL），该框架能够利用重要的视觉-语言（VL）token并缓解层间特征差距。该方法是免训练、模型无关且高度兼容的。", "result": "Short-LVLM不仅在性能和效率之间取得了优越的权衡，而且还展现出免训练、模型无关和高度兼容等潜在优势。", "conclusion": "本文通过实证证明直接将NLP层剪枝方法应用于LVLMs是无效的，并识别出非必要视觉-语言token和层间特征差距是关键挑战。基于这些发现，提出的Short-LVLM框架成功地解决了这些问题，实现了LVLMs的有效压缩和加速，并在性能和效率之间提供了优越的平衡。", "translation": "尽管大型视觉-语言模型（LVLMs）在多模态理解和推理方面表现出令人印象深刻的能力，但其庞大的模型参数和高计算成本仍然限制了它们的实际应用。自然语言处理（NLP）领域的最新研究表明，层剪枝的有效性提供了一种可行的免训练压缩解决方案。然而，由于视觉和语言之间的模态差异，尚不清楚这些NLP技术在LVLMs中是否仍然有效。在本文中，我们通过实证证明直接将这些层剪枝方法应用于LVLMs是无效的。通过大量的实验，我们发现非必要视觉-语言（VL）token和层间特征差距对LVLMs中的层剪枝构成了关键挑战。基于这些见解，我们提出了一个新颖的框架Short-LVLM（SVL），该框架能够利用重要的VL token并缓解层间特征差距。值得注意的是，Short-LVLM不仅在性能和效率之间取得了优越的权衡，而且还展现出多项潜在优势，即免训练、模型无关和高度兼容。本工作的代码已在https://github.com/ASGO-MM/Short-LVLM公开。", "summary": "本文针对大型视觉-语言模型（LVLMs）面临的参数量大和计算成本高的问题，探究了层剪枝技术在LVLMs中的应用。研究发现直接将NLP中的层剪枝方法应用于LVLMs效果不佳，主要挑战在于非必要视觉-语言（VL）token和层间特征差距。为此，作者提出了一个名为Short-LVLM的新框架，该框架通过利用重要的VL token和缓解层间特征差距来解决这些问题。实验证明，Short-LVLM在性能和效率之间实现了卓越的平衡，并且具有免训练、模型无关和高度兼容的优点，为LVLMs的压缩和加速提供了一种有效方案。", "keywords": "大型视觉-语言模型, 模型压缩, 层剪枝, 效率, 多模态", "comments": "本文在LVLMs压缩领域具有创新性，它不仅指出了现有NLP层剪枝方法在多模态领域应用的局限性，还针对性地提出了解决视觉-语言模态差异和层间特征差距的新方法。其“免训练、模型无关、高度兼容”的特性，大大提升了其实用性和普适性。这项工作对于推动LVLMs在资源受限环境下的实际部署具有重要意义。"}}
{"id": "2507.23608", "title": "Medical Image De-Identification Benchmark Challenge", "authors": ["Linmin Pei", "Granger Sutton", "Michael Rutherford", "Ulrike Wagner", "Tracy Nolan", "Kirk Smith", "Phillip Farmer", "Peter Gu", "Ambar Rana", "Kailing Chen", "Thomas Ferleman", "Brian Park", "Ye Wu", "Jordan Kojouharov", "Gargi Singh", "Jon Lemon", "Tyler Willis", "Milos Vukadinovic", "Grant Duffy", "Bryan He", "David Ouyang", "Marco Pereanez", "Daniel Samber", "Derek A. Smith", "Christopher Cannistraci", "Zahi Fayad", "David S. Mendelson", "Michele Bufano", "Elmar Kotter", "Hamideh Haghiri", "Rajesh Baidya", "Stefan Dvoretskii", "Klaus H. Maier-Hein", "Marco Nolden", "Christopher Ablett", "Silvia Siggillino", "Sandeep Kaushik", "Hongzhu Jiang", "Sihan Xie", "Zhiyu Wan", "Alex Michie", "Simon J Doran", "Angeline Aurelia Waly", "Felix A. Nathaniel Liang", "Humam Arshad Mustagfirin", "Michelle Grace Felicia", "Kuo Po Chih", "Rahul Krish", "Ghulam Rasool", "Nidhal Bouaynaya", "Nikolas Koutsoubis", "Kyle Naddeo", "Kartik Pandit", "Tony O'Sullivan", "Raj Krish", "Qinyan Pan", "Scott Gustafson", "Benjamin Kopchick", "Laura Opsahl-Ong", "Andrea Olvera-Morales", "Jonathan Pinney", "Kathryn Johnson", "Theresa Do", "Juergen Klenk", "Maria Diaz", "Arti Singh", "Rong Chai", "David A. Clunie", "Fred Prior", "Keyvan Farahani"], "categories": ["cs.CV", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      19 pages", "url": "http://arxiv.org/abs/2507.23608v1", "summary": "The de-identification (deID) of protected health information (PHI) and\npersonally identifiable information (PII) is a fundamental requirement for\nsharing medical images, particularly through public repositories, to ensure\ncompliance with patient privacy laws. In addition, preservation of non-PHI\nmetadata to inform and enable downstream development of imaging artificial\nintelligence (AI) is an important consideration in biomedical research. The\ngoal of MIDI-B was to provide a standardized platform for benchmarking of DICOM\nimage deID tools based on a set of rules conformant to the HIPAA Safe Harbor\nregulation, the DICOM Attribute Confidentiality Profiles, and best practices in\npreservation of research-critical metadata, as defined by The Cancer Imaging\nArchive (TCIA). The challenge employed a large, diverse, multi-center, and\nmulti-modality set of real de-identified radiology images with synthetic\nPHI/PII inserted.\n  The MIDI-B Challenge consisted of three phases: training, validation, and\ntest. Eighty individuals registered for the challenge. In the training phase,\nwe encouraged participants to tune their algorithms using their in-house or\npublic data. The validation and test phases utilized the DICOM images\ncontaining synthetic identifiers (of 216 and 322 subjects, respectively). Ten\nteams successfully completed the test phase of the challenge. To measure\nsuccess of a rule-based approach to image deID, scores were computed as the\npercentage of correct actions from the total number of required actions. The\nscores ranged from 97.91% to 99.93%. Participants employed a variety of\nopen-source and proprietary tools with customized configurations, large\nlanguage models, and optical character recognition (OCR). In this paper we\nprovide a comprehensive report on the MIDI-B Challenge's design,\nimplementation, results, and lessons learned.", "comment": "19 pages", "pdf_url": "http://arxiv.org/pdf/2507.23608v1", "cate": "cs.CV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "医疗图像去识别基准挑战赛", "tldr": "医疗图像去识别基准挑战赛（MIDI-B）评估了各种工具在保护患者隐私和保留研究元数据方面的表现，参赛团队取得了97.91%至99.93%的高分。", "motivation": "共享医疗图像，特别是通过公共存储库共享时，需要对受保护健康信息（PHI）和个人身份信息（PII）进行去识别，以遵守患者隐私法。同时，保留非PHI元数据对于下游的成像人工智能开发至关重要。因此，需要一个标准化平台来基准测试DICOM图像去识别工具。", "method": "MIDI-B挑战赛提供了一个标准化平台，用于根据HIPAA安全港法规、DICOM属性保密配置文件和TCIA定义的最佳实践对DICOM图像去识别工具进行基准测试。挑战赛使用了大量、多样化、多中心、多模态的真实去识别放射学图像，并插入了合成的PHI/PII。挑战赛分为三个阶段：训练、验证和测试。参与者使用内部或公共数据调整算法。验证和测试阶段使用了包含合成标识符的DICOM图像。通过计算正确操作的百分比来衡量成功率。", "result": "十个团队成功完成了测试阶段。分数范围从97.91%到99.93%。参与者采用了各种开源和专有工具、定制配置、大型语言模型和光学字符识别（OCR）。", "conclusion": "该论文报告了MIDI-B挑战赛的设计、实施、结果和经验教训，表明医疗图像去识别工具能够有效保护隐私并保留关键元数据，且表现良好。", "translation": "受保护健康信息 (PHI) 和个人身份信息 (PII) 的去识别 (deID) 是共享医学图像的基本要求，特别是通过公共存储库共享时，以确保遵守患者隐私法。此外，保留非 PHI 元数据以告知和支持成像人工智能 (AI) 的下游开发是生物医学研究中的一个重要考虑因素。MIDI-B 的目标是提供一个标准化平台，用于根据符合 HIPAA 安全港法规、DICOM 属性保密配置文件以及癌症成像档案 (TCIA) 定义的保留研究关键元数据的最佳实践的一套规则，对 DICOM 图像去识别工具进行基准测试。该挑战赛采用了大量、多样化、多中心、多模态的真实去识别放射学图像，并插入了合成的 PHI/PII。\nMIDI-B 挑战赛由三个阶段组成：训练、验证和测试。八十名个人注册了挑战赛。在训练阶段，我们鼓励参与者使用其内部或公共数据调整算法。验证和测试阶段使用了包含合成标识符的 DICOM 图像（分别为 216 和 322 名受试者）。十个团队成功完成了挑战赛的测试阶段。为了衡量基于规则的图像去识别方法的成功率，分数被计算为正确操作占所需操作总数的百分比。分数范围从 97.91% 到 99.93%。参与者采用了各种开源和专有工具、定制配置、大型语言模型和光学字符识别 (OCR)。在本文中，我们提供了关于 MIDI-B 挑战赛设计、实施、结果和经验教训的全面报告。", "summary": "本文介绍了医疗图像去识别基准挑战赛（MIDI-B），旨在标准化评估DICOM图像去识别工具，以在遵守隐私法规（如HIPAA）的同时保留关键研究元数据。挑战赛使用了包含合成PHI/PII的真实图像数据集，并分为训练、验证和测试三个阶段。结果显示，参赛团队在去识别任务中表现出色，得分在97.91%至99.93%之间，并采用了多样化的技术手段，包括LLMs和OCR。", "keywords": "医疗图像去识别, PHI, PII, DICOM, 基准挑战赛", "comments": "这项挑战赛提供了一个重要的标准化平台，用于评估医疗图像去识别工具的性能，这对于促进医学图像共享和AI发展至关重要。其创新之处在于使用了真实去识别图像与合成PHI/PII结合的数据集，并考虑了元数据保留。挑战赛结果表明现有技术在去识别方面已达到较高水平，但也揭示了不同方法（如LLMs和OCR的应用）的潜力。"}}
{"id": "2507.12311", "title": "An Ecosystem for Ontology Interoperability", "authors": ["Zhangcheng Qiang"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      5 pages, 8 figures", "url": "http://arxiv.org/abs/2507.12311v3", "summary": "Ontology interoperability is one of the complicated issues that restricts the\nuse of ontologies in knowledge graphs (KGs). Different ontologies with\nconflicting and overlapping concepts make it difficult to design, develop, and\ndeploy an interoperable ontology for downstream tasks. We propose an ecosystem\nfor ontology interoperability. The ecosystem employs three state-of-the-art\nsemantic techniques in different phases of the ontology engineering life cycle:\nontology design patterns (ODPs) in the design phase, ontology matching and\nversioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge\ngraphs (OCKGs) in the deploy phase, to achieve better ontology interoperability\nand data integration in real-world applications. A case study of sensor\nobservation in the building domain validates the usefulness of the proposed\necosystem.", "comment": "5 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.12311v3", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-31", "AI": {"title_translation": "本体互操作性生态系统", "tldr": "本文提出了一个本体互操作性生态系统，通过在本体工程生命周期的不同阶段采用本体设计模式、本体匹配与版本控制以及符合本体的知识图谱等技术，旨在解决知识图谱中本体互操作性的复杂问题，并通过一个案例研究验证了其有效性。", "motivation": "本体互操作性是限制本体在知识图谱中使用的复杂问题之一。不同本体之间概念的冲突和重叠使得设计、开发和部署可互操作的本体用于下游任务变得困难。", "method": "本文提出了一个用于本体互操作性的生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的符合本体的知识图谱（OCKGs）。", "result": "通过一个在建筑领域传感器观测的案例研究，验证了所提出生态系统的有效性。", "conclusion": "所提出的本体互操作性生态系统通过整合多种先进语义技术，能够有效解决本体互操作性问题，并促进实际应用中的数据集成。", "translation": "本体互操作性是限制本体在知识图谱（KGs）中使用的复杂问题之一。具有冲突和重叠概念的不同本体使得设计、开发和部署一个可互操作的本体用于下游任务变得困难。我们提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的符合本体的知识图谱（OCKGs），以在实际应用中实现更好的本体互操作性和数据集成。一个在建筑领域传感器观测的案例研究验证了所提出生态系统的有用性。", "summary": "本文针对知识图谱中本体互操作性面临的挑战，提出了一个创新的本体互操作性生态系统。该系统在本体工程的各个阶段（设计、开发、部署）分别整合了本体设计模式、本体匹配与版本控制以及符合本体的知识图谱等先进语义技术，旨在提升本体互操作性和数据集成能力。通过一个建筑领域传感器观测的案例研究，验证了该生态系统的实用性。", "keywords": "本体互操作性, 知识图谱, 本体设计模式, 本体匹配, 本体版本控制", "comments": "本文提出的本体互操作性生态系统具有创新性，它将本体工程生命周期与多种先进的语义技术相结合，提供了一个全面的解决方案。这种系统化的方法有助于解决本体在知识图谱应用中的实际痛点。其重要性在于为构建更健壮、可互操作的知识图谱提供了实用框架，特别是在处理异构数据源时。"}}
{"id": "2507.23699", "title": "Exploring Left-Wing Extremism on the Decentralized Web: An Analysis of Lemmygrad.ml", "authors": ["Utkucan Balci", "Michael Sirivianos", "Jeremy Blackburn"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23699v1", "summary": "This study investigates the presence of left-wing extremism on the\nLemmygrad.ml instance of the decentralized social media platform Lemmy, from\nits launch in 2019 up to a month after the bans of the subreddits r/GenZedong\nand r/GenZhou. We conduct a temporal analysis on Lemmygrad.ml's user activity,\nwith also measuring the degree of highly abusive or hateful content.\nFurthermore, we explore the content of their posts using a transformer-based\ntopic modeling approach. Our findings reveal a substantial increase in user\nactivity and toxicity levels following the migration of these subreddits to\nLemmygrad.ml. We also identify posts that support authoritarian regimes,\nendorse the Russian invasion of Ukraine, and feature anti-Zionist and\nantisemitic content. Overall, our findings contribute to a more nuanced\nunderstanding of political extremism within decentralized social networks and\nemphasize the necessity of analyzing both ends of the political spectrum in\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23699v1", "cate": "cs.SI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "探索去中心化网络中的左翼极端主义：对Lemmygrad.ml的分析", "tldr": "本研究调查了去中心化社交媒体平台Lemmygrad.ml上的左翼极端主义，发现r/GenZedong和r/GenZhou子版块被禁后，该平台的用户活动和有害内容显著增加，并识别出支持威权政权、俄罗斯入侵乌克兰以及反犹太复国主义和反犹太内容。", "motivation": "本研究旨在调查去中心化社交媒体平台Lemmy的Lemmygrad.ml实例上左翼极端主义的存在，特别是在r/GenZedong和r/GenZhou子版块被禁后，以期更深入地理解去中心化社交网络中的政治极端主义。", "method": "研究对Lemmygrad.ml的用户活动进行了时间分析，测量了高度辱骂或仇恨内容的程度，并使用基于Transformer的主题建模方法探索了帖子内容。数据收集范围从2019年平台推出到相关子版块被禁后一个月。", "result": "研究发现，在r/GenZedong和r/GenZhou子版块迁移到Lemmygrad.ml后，用户活动和毒性水平显著增加。研究还识别出支持威权政权、认可俄罗斯入侵乌克兰以及包含反犹太复国主义和反犹太内容的帖子。", "conclusion": "研究结果有助于更细致地理解去中心化社交网络中的政治极端主义，并强调在研究中分析政治光谱两端的必要性。", "translation": "本研究调查了去中心化社交媒体平台Lemmy的Lemmygrad.ml实例上左翼极端主义的存在，时间范围从2019年平台推出到r/GenZedong和r/GenZhou子版块被禁后一个月。我们对Lemmygrad.ml的用户活动进行了时间分析，并测量了高度辱骂或仇恨内容的程度。此外，我们使用基于Transformer的主题建模方法探索了帖子的内容。我们的研究结果显示，在这些子版块迁移到Lemmygrad.ml之后，用户活动和毒性水平显著增加。我们还识别出支持威权政权、认可俄罗斯入侵乌克兰以及包含反犹太复国主义和反犹太内容的帖子。总的来说，我们的研究结果有助于更细致地理解去中心化社交网络中的政治极端主义，并强调在研究中分析政治光谱两端的必要性。", "summary": "本研究分析了去中心化社交平台Lemmygrad.ml上的左翼极端主义，特别关注了在r/GenZedong和r/GenZhou子版块被禁后用户行为的变化。通过时间分析和主题建模，研究发现这些子版块迁移后，Lemmygrad.ml的用户活动和有害内容显著增加，并识别出支持威权主义、俄罗斯入侵以及反犹太主义等极端内容。研究强调了在去中心化网络中理解政治极端主义的复杂性，并呼吁对政治光谱两端进行研究。", "keywords": "左翼极端主义, 去中心化网络, Lemmygrad.ml, 社交媒体, 内容分析", "comments": "本研究的创新之处在于关注了去中心化网络中较少被研究的左翼极端主义，尤其是在主流平台内容被禁后用户迁移的行为模式。它揭示了去中心化平台可能成为极端主义内容聚集和传播的新温床，对于理解线上极端主义的演变具有重要意义。研究方法结合了定量的时间分析和定性的内容主题建模，提供了全面的视角。"}}
{"id": "2507.11832", "title": "ILID: Native Script Language Identification for Indian Languages", "authors": ["Yash Ingle", "Pruthwik Mishra"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, 6 tables, Paper accepted in RANLP 2025", "url": "http://arxiv.org/abs/2507.11832v2", "summary": "The language identification task is a crucial fundamental step in NLP. Often\nit serves as a pre-processing step for widely used NLP applications such as\nmultilingual machine translation, information retrieval, question and\nanswering, and text summarization. The core challenge of language\nidentification lies in distinguishing languages in noisy, short, and code-mixed\nenvironments. This becomes even harder in case of diverse Indian languages that\nexhibit lexical and phonetic similarities, but have distinct differences. Many\nIndian languages share the same script, making the task even more challenging.\nTaking all these challenges into account, we develop and release a dataset of\n250K sentences consisting of 23 languages including English and all 22 official\nIndian languages labeled with their language identifiers, where data in most\nlanguages are newly created. We also develop and release baseline models using\nstate-of-the-art approaches in machine learning and fine-tuning pre-trained\ntransformer models. Our models outperforms the state-of-the-art pre-trained\ntransformer models for the language identification task. The dataset and the\ncodes are available at https://yashingle-ai.github.io/ILID/ and in Huggingface\nopen source libraries.", "comment": "10 pages, 1 figure, 6 tables, Paper accepted in RANLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11832v2", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-31", "AI": {"title_translation": "ILID：印度语言的本土文字语言识别", "tldr": "本文发布了一个包含23种语言（包括所有22种官方印度语言）的25万句数据集，并开发了超越现有技术的基线模型，用于印度语言的语言识别。", "motivation": "语言识别是自然语言处理中的一个关键预处理步骤，但在嘈杂、短文本和代码混合环境中，尤其是在词汇和语音相似但文字不同的印度多样化语言中，识别语言极具挑战性。", "method": "开发并发布了一个包含25万句的数据集，涵盖英语和所有22种官方印度语言，并为数据标注了语言标识符。同时，使用最先进的机器学习方法和微调预训练的Transformer模型，开发并发布了基线模型。", "result": "所开发的模型在语言识别任务上优于现有的最先进预训练Transformer模型。", "conclusion": "通过创建新的数据集和开发高性能基线模型，本文为印度语言的语言识别任务提供了重要资源和改进。", "translation": "语言识别任务是自然语言处理中一个至关重要的基础步骤。它通常作为多语言机器翻译、信息检索、问答和文本摘要等广泛使用的自然语言处理应用的预处理步骤。语言识别的核心挑战在于在嘈杂、短文本和代码混合的环境中区分语言。在词汇和语音相似但具有明显差异的印度多样化语言的情况下，这变得更加困难。许多印度语言共享相同的文字，使得这项任务更具挑战性。考虑到所有这些挑战，我们开发并发布了一个包含25万个句子的数据集，其中包括英语和所有22种官方印度语言，并标注了它们的语言标识符，其中大多数语言的数据是新创建的。我们还使用机器学习和微调预训练Transformer模型中的最先进方法开发并发布了基线模型。我们的模型在语言识别任务上优于最先进的预训练Transformer模型。数据集和代码可在https://yashingle-ai.github.io/ILID/和Huggingface开源库中获取。", "summary": "本文针对印度语言的语言识别任务，解决了在共享文字、词汇和语音相似性背景下区分语言的挑战。研究人员创建了一个包含25万句的大型数据集，涵盖了英语和所有22种官方印度语言。在此基础上，他们开发了基于最新机器学习和Transformer模型微调的基线模型，这些模型在语言识别性能上超越了现有的先进技术。数据集和代码已开源。", "keywords": "语言识别, 印度语言, 数据集, Transformer模型, 自然语言处理", "comments": "本文的创新之处在于创建了一个针对印度语言的、大规模且标注清晰的语言识别数据集，这对于处理印度语言的复杂性至关重要。同时，其开发的基线模型也展示了超越现有SOTA模型的性能，为后续研究提供了坚实的基础和有价值的资源。开源数据集和代码的举措，将极大促进该领域的研究进展。"}}
{"id": "2507.23700", "title": "The ArborX library: version 2.0", "authors": ["Andrey Prokopenko", "Daniel Arndt", "Damien Lebrun-Grandié", "Bruno Turcksin"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23700v1", "summary": "This paper provides an overview of the 2.0 release of the ArborX library, a\nperformance portable geometric search library based on Kokkos. We describe the\nmajor changes in ArborX 2.0 including a new interface for the library to\nsupport a wider range of user problems, new search data structures (brute\nforce, distributed), support for user functions to be executed on the results\n(callbacks), and an expanded set of the supported algorithms (ray tracing,\nclustering).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23700v1", "cate": "cs.DC", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "ArborX 库：2.0 版本", "tldr": "ArborX 2.0 版本发布，这是一个基于 Kokkos 的性能可移植几何搜索库，引入了新接口、新数据结构、回调支持和扩展算法。", "motivation": "本文旨在概述 ArborX 库的 2.0 版本，该版本提供了性能可移植的几何搜索功能，并引入了重大改进以支持更广泛的用户问题。", "method": "ArborX 2.0 版本的主要变化包括：为支持更广泛的用户问题而设计的新接口；新的搜索数据结构（暴力搜索、分布式）；支持用户函数在结果上执行（回调）；以及扩展了支持的算法集（光线追踪、聚类）。", "result": "ArborX 2.0 版本通过引入新接口、新搜索数据结构（暴力搜索、分布式）、回调支持以及扩展的算法集（光线追踪、聚类），显著提升了库的功能性和对用户问题的支持范围。", "conclusion": "Not mentioned in abstract", "translation": "本文概述了 ArborX 库的 2.0 版本，这是一个基于 Kokkos 的性能可移植几何搜索库。我们描述了 ArborX 2.0 中的主要变化，包括支持更广泛用户问题的新库接口、新的搜索数据结构（暴力搜索、分布式）、支持用户函数在结果上执行（回调），以及扩展了支持的算法集（光线追踪、聚类）。", "summary": "本文介绍了性能可移植几何搜索库 ArborX 的 2.0 版本。新版本基于 Kokkos，主要更新包括为支持更广泛问题而设计的新接口、新增的暴力搜索和分布式搜索数据结构、对结果执行用户函数的回调支持，以及扩展了光线追踪和聚类等算法。", "keywords": "ArborX, 几何搜索, Kokkos, 性能可移植, 库", "comments": "ArborX 2.0 版本通过引入更灵活的接口、新的数据结构和扩展的算法，显著增强了其作为性能可移植几何搜索库的功能性。它对高性能计算和几何处理领域的用户具有重要意义，尤其是在需要高效空间查询的应用中。"}}
{"id": "2507.23432", "title": "Scalable contribution bounding to achieve privacy", "authors": ["Vincent Cohen-Addad", "Alessandro Epasto", "Jason Lee", "Morteza Zadimoghaddam"], "categories": ["cs.DS", "cs.CR", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.23432v1", "summary": "In modern datasets, where single records can have multiple owners, enforcing\nuser-level differential privacy requires capping each user's total\ncontribution. This \"contribution bounding\" becomes a significant combinatorial\nchallenge. Existing sequential algorithms for this task are computationally\nintensive and do not scale to the massive datasets prevalent today. To address\nthis scalability bottleneck, we propose a novel and efficient distributed\nalgorithm. Our approach models the complex ownership structure as a hypergraph,\nwhere users are vertices and records are hyperedges. The algorithm proceeds in\nrounds, allowing users to propose records in parallel. A record is added to the\nfinal dataset only if all its owners unanimously agree, thereby ensuring that\nno user's predefined contribution limit is violated. This method aims to\nmaximize the size of the resulting dataset for high utility while providing a\npractical, scalable solution for implementing user-level privacy in large,\nreal-world systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.23432v1", "cate": "cs.DS", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "可伸缩的贡献边界以实现隐私", "tldr": "针对大规模数据集中用户级差分隐私的贡献边界问题，提出了一种新的分布式算法，通过超图模型和并行处理，实现了可伸伸缩且实用的隐私保护方案，同时最大化了数据集效用。", "motivation": "现有的用户级差分隐私贡献边界算法计算密集且不适用于大规模数据集，存在可伸缩性瓶颈。", "method": "提出了一种新颖高效的分布式算法。将复杂的拥有权结构建模为超图，其中用户是顶点，记录是超边。算法分轮进行，用户并行提议记录。只有当所有所有者一致同意时，记录才会被添加到最终数据集中，从而确保不违反任何用户的预定义贡献限制。", "result": "该方法旨在最大化最终数据集的大小以实现高效用，同时为在大型真实世界系统中实现用户级隐私提供实用、可伸缩的解决方案。", "conclusion": "该研究提供了一种实用且可伸缩的分布式算法，有效解决了大规模数据集中用户级差分隐私的贡献边界挑战，同时保持了较高的数据集效用。", "translation": "在现代数据集中，单个记录可能拥有多个所有者，强制执行用户级差分隐私需要限制每个用户的总贡献。这种“贡献边界”成为一个重大的组合挑战。现有的针对此任务的顺序算法计算密集，并且无法扩展到当今流行的大规模数据集。为了解决这个可伸缩性瓶颈，我们提出了一种新颖高效的分布式算法。我们的方法将复杂的拥有权结构建模为超图，其中用户是顶点，记录是超边。该算法分轮进行，允许用户并行提议记录。只有当所有所有者一致同意时，记录才会被添加到最终数据集中，从而确保不违反任何用户的预定义贡献限制。该方法旨在最大化最终数据集的大小以实现高效用，同时为在大型真实世界系统中实现用户级隐私提供实用、可伸缩的解决方案。", "summary": "这篇论文提出了一种新的分布式算法，用于解决大规模数据集中用户级差分隐私的贡献边界问题。该算法通过将数据所有权建模为超图，并允许用户并行提议记录，确保在所有所有者同意的前提下，将记录添加到数据集中，从而在不违反用户贡献限制的情况下，实现可伸缩的隐私保护，并最大化数据集效用。", "keywords": "差分隐私, 贡献边界, 分布式算法, 超图, 可伸缩性", "comments": "该论文的创新点在于提出了一个基于超图模型的分布式算法来解决用户级差分隐私中的贡献边界难题，有效地解决了现有方法在处理大规模数据集时的可伸缩性问题。其并行处理和一致性协议的设计使其在实际应用中具有较高的实用性。"}}
{"id": "2507.23746", "title": "Real-Time Transmission of Uncompressed High-Definition Video Via A VCSEL-Based Optical Wireless Link With Ultra-Low Latency", "authors": ["Hossein Kazemi", "Isaac N. O. Osahon", "Tiankuo Jiao", "David Butler", "Nikolay Ledentsov Jr.", "Ilya Titkov", "Nikolay Ledentsov", "Harald Haas"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, 2 tables", "url": "http://arxiv.org/abs/2507.23746v1", "summary": "Real-time transmission of high-resolution video signals in an uncompressed\nand unencrypted format requires an ultra-reliable and low-latency\ncommunications (URLLC) medium with high bandwidth to maintain the quality of\nexperience (QoE) for users. We put forward the design and experimental\ndemonstration of a high-performance laser-based optical wireless communication\n(OWC) system that enables high-definition (HD) video transmission with\nsubmillisecond latencies. The serial digital interface (SDI) output of a camera\nis used to transmit the live video stream over an optical wireless link by\ndirectly modulating the SDI signal on the intensity of a 940 nm vertical cavity\nsurface emitting laser (VCSEL). The proposed SDI over light fidelity (LiFi)\nsystem corroborates error-free transmission of full HD (FHD) and 4K\nultra-high-definition (UHD) resolutions at data rates of 2.97 Gb/s and 5.94\nGb/s, respectively, with a measured end-to-end latency of under 35 ns. Since\nSDI standards support various video formats and VCSELs are high-bandwidth and\nlow-power devices, this presents a scalable and inexpensive solution for\nwireless connectivity between professional broadcast equipment using\noff-the-shelf SDI components.", "comment": "8 pages, 6 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.23746v1", "cate": "eess.SP", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "基于VCSEL的超低延迟光无线链路非压缩高清视频实时传输", "tldr": "本文提出并实验验证了一种基于VCSEL的光无线通信系统，可实现非压缩高清视频的实时传输，具有超低延迟和高带宽，适用于专业广播设备。", "motivation": "实时传输非压缩、未加密的高分辨率视频信号需要高带宽、超可靠和低延迟的通信介质，以保证用户体验质量。", "method": "设计并实验演示了一种高性能激光器（VCSEL）基光无线通信（OWC）系统。该系统通过直接调制940 nm VCSEL的强度来传输来自摄像机SDI输出的实时视频流，构建了基于光的SDI（LiFi）系统。", "result": "该SDI over LiFi系统实现了全高清（FHD）和4K超高清（UHD）分辨率的无差错传输，数据速率分别为2.97 Gb/s和5.94 Gb/s，测得的端到端延迟低于35 ns。", "conclusion": "由于SDI标准支持多种视频格式且VCSELs是高带宽、低功耗设备，该方案为使用现成SDI组件的专业广播设备之间的无线连接提供了一种可扩展且经济的解决方案。", "translation": "实时传输非压缩、未加密的高分辨率视频信号需要高带宽、超可靠和低延迟的通信（URLLC）介质，以保持用户体验质量（QoE）。我们提出并实验演示了一种高性能的基于激光的光无线通信（OWC）系统，该系统能够以亚毫秒级延迟传输高清（HD）视频。通过直接调制940 nm垂直腔面发射激光器（VCSEL）的强度，将摄像机的串行数字接口（SDI）输出用于通过光无线链路传输实时视频流。所提出的基于光的SDI（LiFi）系统证实了全高清（FHD）和4K超高清（UHD）分辨率的无差错传输，数据速率分别为2.97 Gb/s和5.94 Gb/s，测得的端到端延迟低于35 ns。由于SDI标准支持各种视频格式，并且VCSELs是高带宽、低功耗设备，这为使用现成SDI组件的专业广播设备之间的无线连接提供了一种可扩展且经济的解决方案。", "summary": "本文设计并实验演示了一种基于VCSEL的光无线通信（OWC）系统，用于实时、超低延迟传输非压缩高清视频。该系统通过直接调制940 nm VCSEL的强度来传输摄像机SDI输出的实时视频流。实验结果表明，该SDI over LiFi系统实现了全高清和4K超高清视频的无差错传输，数据速率高达5.94 Gb/s，端到端延迟低于35 ns。该方案利用SDI标准和VCSELs的优势，为专业广播设备间的无线连接提供了一种可扩展且经济的解决方案。", "keywords": "光无线通信, VCSEL, 高清视频, 超低延迟, SDI", "comments": "本文的创新点在于利用VCSELs和SDI标准构建了一个超低延迟的光无线通信链路，实现了非压缩高清视频的实时传输。其重要性在于为需要极高带宽和极低延迟的专业广播和视频应用提供了一种可行的无线解决方案。低至35 ns的端到端延迟是其显著优势。"}}
{"id": "2507.23361", "title": "SWE-Exp: Experience-Driven Software Issue Resolution", "authors": ["Silin Chen", "Shaoxin Lin", "Xiaodong Gu", "Yuling Shi", "Heng Lian", "Longfei Yun", "Dong Chen", "Weiguo Sun", "Lin Cao", "Qianxiang Wang"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Our code and data are available at this https URL", "url": "http://arxiv.org/abs/2507.23361v1", "summary": "Recent advances in large language model (LLM) agents have shown remarkable\nprogress in software issue resolution, leveraging advanced techniques such as\nmulti-agent collaboration and Monte Carlo Tree Search (MCTS). However, current\nagents act as memoryless explorers - treating each problem separately without\nretaining or reusing knowledge from previous repair experiences. This leads to\nredundant exploration of failed trajectories and missed chances to adapt\nsuccessful issue resolution methods to similar problems. To address this\nproblem, we introduce SWE-Exp, an experience - enhanced approach that distills\nconcise and actionable experience from prior agent trajectories, enabling\ncontinuous learning across issues. Our method introduces a multi-faceted\nexperience bank that captures both successful and failed repair attempts.\nSpecifically, it extracts reusable issue resolution knowledge at different\nlevels - from high-level problem comprehension to specific code changes.\nExperiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%\nPass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach\nestablishes a new paradigm in which automated software engineering agents\nsystematically accumulate and leverage repair expertise, fundamentally shifting\nfrom trial-and-error exploration to strategic, experience-driven issue\nresolution.", "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Exp", "pdf_url": "http://arxiv.org/pdf/2507.23361v1", "cate": "cs.SE", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "SWE-Exp：经验驱动的软件问题解决", "tldr": "SWE-Exp引入了一种经验驱动的方法，通过积累过去的成功和失败经验，显著提高了LLM代理在软件问题解决方面的效率和成功率，实现了从试错到策略性解决的转变。", "motivation": "当前的大型语言模型（LLM）代理在软件问题解决方面存在“无记忆探索”的问题，无法保留和重用过去的修复经验，导致重复探索失败路径并错失应用成功方法的时机。", "method": "论文提出了SWE-Exp，一种经验增强的方法。它从先前的代理轨迹中提炼出简洁且可操作的经验，实现跨问题的持续学习。该方法引入了一个多方面的经验库，捕获成功和失败的修复尝试，并提取不同层次（从高层问题理解到具体代码更改）的可重用问题解决知识。", "result": "SWE-Exp在SWE-bench-Verified基准测试上，在开源代理框架下实现了最先进的解决率（41.6% Pass@1）。", "conclusion": "SWE-Exp建立了一种新范式，使自动化软件工程代理能够系统地积累和利用修复专业知识，从试错式探索根本性地转变为战略性、经验驱动的问题解决。", "translation": "近期大型语言模型（LLM）代理在软件问题解决方面取得了显著进展，利用了多代理协作和蒙特卡洛树搜索（MCTS）等先进技术。然而，当前的代理表现为“无记忆的探索者”——它们将每个问题单独处理，而不保留或重用以往修复经验中的知识。这导致了对失败轨迹的重复探索，并错失了将成功的问题解决方法应用于类似问题的机会。为了解决这个问题，我们引入了SWE-Exp，一种经验增强的方法，它从先前的代理轨迹中提炼出简洁且可操作的经验，从而实现跨问题的持续学习。我们的方法引入了一个多方面的经验库，捕获了成功和失败的修复尝试。具体而言，它在不同层面——从高层问题理解到具体的代码更改——提取可重用的问题解决知识。实验表明，SWE-Exp在开源代理框架下的SWE-bench-Verified数据集上取得了最先进的解决率（41.6% Pass@1）。我们的方法建立了一个新范式，其中自动化软件工程代理系统地积累和利用修复专业知识，从根本上将试错式探索转变为战略性、经验驱动的问题解决。", "summary": "本文介绍了SWE-Exp，一种创新的经验驱动方法，旨在解决大型语言模型代理在软件问题解决中缺乏经验积累的问题。SWE-Exp通过构建一个多维度经验库，存储并提炼成功与失败的修复经验，从而实现跨任务的持续学习。实验证明，SWE-Exp在标准基准测试中达到了最先进的解决率，标志着软件工程代理从传统的试错模式向策略性、经验驱动模式的转变。", "keywords": "软件问题解决, 大型语言模型代理, 经验学习, 自动化软件工程, SWE-Exp", "comments": "这篇论文通过引入经验库的概念，有效地解决了LLM代理在软件问题解决中“无记忆”的局限性，实现了知识的积累和复用，是LLM代理在自动化软件工程领域应用的一个重要创新。其提出的经验银行机制，不仅存储成功经验，也学习失败教训，使代理能够更高效地避免重复错误并推广成功模式，具有重要的实践价值。"}}
{"id": "2507.18376", "title": "A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges", "authors": ["Xing Hu", "Haodong Chen", "Qianqian Duan", "Danfeng Hong", "Ruijiao Li", "Huiliang Shang", "Linghua Jiang", "Haima Yang", "Dawei Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18376v2", "summary": "With the global population growing and arable land resources becoming\nincreasingly scarce,smart agriculture and precision agriculture have emerged as\nkey directions for the future ofagricultural development.Artificial\nintelligence (AI) technologies, particularly deep learning models, have found\nwidespread applications in areas such as crop monitoring and pest detection. As\nan emerging generative model, diffusion models have shown significant promise\nin tasks like agricultural image processing, data augmentation, and remote\nsensing. Compared to traditional generative adversarial networks (GANs),\ndiffusion models offer superior training stability and generation quality,\neffectively addressing challenges such as limited agricultural data and\nimbalanced image samples. This paper reviews the latest advancements in the\napplication of diffusion models in agriculture, focusing on their potential in\ncrop pest and disease detection, remote sensing image enhancement, crop growth\nprediction, and agricultural resource management. Experimental results\ndemonstrate that diffusion models significantly improve model accuracy and\nrobustness in data augmentation, image generation, and denoising, especially in\ncomplex environments. Despite challenges related to computational efficiency\nand generalization capabilities, diffusion models are expected to play an\nincreasingly important role in smart and precision agriculture as technology\nadvances, providing substantial support for the sustainable development of\nglobal agriculture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18376v2", "cate": "cs.LG", "date": "2025-07-24", "updated": "2025-07-31", "AI": {"title_translation": "智能农业中扩散模型的综合综述：进展、应用与挑战", "tldr": "综述了扩散模型在智能农业中的应用、进展和挑战，尤其是在数据增强、图像生成和去噪方面的优势。", "motivation": "全球人口增长和耕地资源稀缺，推动智能农业和精准农业发展。人工智能技术在农业中应用广泛，扩散模型作为新兴生成模型，在解决农业数据有限和样本不平衡方面显示出巨大潜力。", "method": "本文是对扩散模型在农业应用中最新进展的综述，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。", "result": "扩散模型在数据增强、图像生成和去噪方面显著提高了模型准确性和鲁棒性，尤其是在复杂环境下。", "conclusion": "尽管面临计算效率和泛化能力挑战，但随着技术进步，扩散模型有望在智能和精准农业中发挥越来越重要的作用，为全球农业可持续发展提供支持。", "translation": "随着全球人口增长和耕地资源日益稀缺，智能农业和精准农业已成为未来农业发展的关键方向。人工智能（AI）技术，特别是深度学习模型，已在作物监测和病虫害检测等领域得到广泛应用。作为一种新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感等任务中显示出巨大的潜力。与传统的生成对抗网络（GANs）相比，扩散模型具有卓越的训练稳定性和生成质量，有效解决了农业数据有限和图像样本不平衡等挑战。本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。实验结果表明，扩散模型在数据增强、图像生成和去噪方面显著提高了模型准确性和鲁棒性，尤其是在复杂环境中。尽管面临计算效率和泛化能力相关的挑战，但随着技术进步，扩散模型有望在智能和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供实质性支持。", "summary": "本文全面综述了扩散模型在智能农业领域的最新进展、应用及挑战。它强调了扩散模型在解决农业数据稀缺和样本不平衡问题上的优势，并详细探讨了其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理等方面的应用潜力。研究表明，扩散模型能显著提升数据增强、图像生成和去噪的准确性和鲁棒性。尽管存在计算效率和泛化能力挑战，但扩散模型被认为将对农业可持续发展发挥关键作用。", "keywords": "扩散模型, 智能农业, 数据增强, 图像生成, 遥感", "comments": "这篇综述论文及时地总结了扩散模型这一新兴技术在智能农业领域的应用现状和未来潜力。其创新性在于将先进的生成模型与农业实际问题相结合，特别是解决了农业数据稀缺和样本不平衡的痛点。该研究的重要性在于为研究人员和实践者提供了全面的视角，指明了扩散模型在提升农业效率和可持续性方面的广阔前景，同时也诚实地指出了其面临的计算挑战。"}}
{"id": "2507.21872", "title": "MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors", "authors": ["Shouyi Lu", "Zihan Lin", "Chao Lu", "Huanran Wang", "Guirong Zhuo", "Lianqing Zheng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21872v3", "summary": "Autonomous driving systems rely heavily on multimodal perception data to\nunderstand complex environments. However, the long-tailed distribution of\nreal-world data hinders generalization, especially for rare but safety-critical\nvehicle categories. To address this challenge, we propose MultiEditor, a\ndual-branch latent diffusion framework designed to edit images and LiDAR point\nclouds in driving scenarios jointly. At the core of our approach is introducing\n3D Gaussian Splatting (3DGS) as a structural and appearance prior for target\nobjects. Leveraging this prior, we design a multi-level appearance control\nmechanism--comprising pixel-level pasting, semantic-level guidance, and\nmulti-branch refinement--to achieve high-fidelity reconstruction across\nmodalities. We further propose a depth-guided deformable cross-modality\ncondition module that adaptively enables mutual guidance between modalities\nusing 3DGS-rendered depth, significantly enhancing cross-modality consistency.\nExtensive experiments demonstrate that MultiEditor achieves superior\nperformance in visual and geometric fidelity, editing controllability, and\ncross-modality consistency. Furthermore, generating rare-category vehicle data\nwith MultiEditor substantially enhances the detection accuracy of perception\nmodels on underrepresented classes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21872v3", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-31", "AI": {"title_translation": "MultiEditor：利用3D高斯泼溅先验的可控多模态驾驶场景目标编辑", "tldr": "MultiEditor是一个双分支潜在扩散框架，利用3D高斯泼溅（3DGS）作为先验，可控地联合编辑驾驶场景中的图像和LiDAR点云，以生成稀有类别数据，提升感知模型对未充分表示类别的检测精度。", "motivation": "自动驾驶系统严重依赖多模态感知数据来理解复杂环境，但真实世界数据的长尾分布，特别是稀有但安全关键的车辆类别数据不足，阻碍了模型的泛化能力。", "method": "本文提出了MultiEditor，一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和LiDAR点云。其核心是引入3D高斯泼溅（3DGS）作为目标对象的结构和外观先验。该方法设计了多级外观控制机制（包括像素级粘贴、语义级引导和多分支细化）以实现跨模态高保真重建。此外，还提出了一个深度引导的可变形跨模态条件模块，利用3DGS渲染的深度实现模态间的自适应相互引导，从而显著增强跨模态一致性。", "result": "MultiEditor在视觉和几何保真度、编辑可控性以及跨模态一致性方面表现出优越性能。通过使用MultiEditor生成稀有类别车辆数据，显著提升了感知模型对未充分表示类别的检测精度。", "conclusion": "MultiEditor通过引入3DGS先验和创新的多模态编辑机制，有效解决了自动驾驶数据中稀有类别不足的问题，显著提升了感知模型的性能和数据质量。", "translation": "自动驾驶系统严重依赖多模态感知数据来理解复杂的环境。然而，真实世界数据的长尾分布阻碍了泛化能力，特别是对于稀有但对安全至关重要的车辆类别。为了解决这一挑战，我们提出了MultiEditor，一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和LiDAR点云。我们方法的核心是引入3D高斯泼溅（3DGS）作为目标对象的结构和外观先验。利用这一先验，我们设计了一个多级外观控制机制——包括像素级粘贴、语义级引导和多分支细化——以实现跨模态的高保真重建。我们进一步提出了一个深度引导的可变形跨模态条件模块，该模块利用3DGS渲染的深度自适应地实现模态间的相互引导，显著增强了跨模态一致性。广泛的实验表明，MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面取得了卓越的性能。此外，利用MultiEditor生成稀有类别车辆数据显著提高了感知模型在未充分表示类别上的检测精度。", "summary": "MultiEditor是一个创新的双分支潜在扩散框架，专为解决自动驾驶中稀有车辆类别数据不足问题而设计。它利用3D高斯泼溅（3DGS）作为结构和外观先验，能够高保真地联合编辑驾驶场景中的图像和LiDAR点云。通过多级外观控制和深度引导的跨模态条件模块，MultiEditor实现了卓越的视觉、几何保真度与跨模态一致性，并能有效生成稀有类别数据，显著提升感知模型的检测性能。", "keywords": "3D高斯泼溅, 多模态编辑, 自动驾驶, 数据增强, 潜在扩散模型", "comments": "MultiEditor的创新点在于将3D高斯泼溅（3DGS）引入到多模态数据编辑中，作为强大的结构和外观先验，有效解决了自动驾驶领域稀有类别数据生成和跨模态一致性难题。其提出的多级外观控制和深度引导的跨模态条件模块设计精巧，对提升合成数据的质量和实用性具有重要意义。该方法有望为自动驾驶感知模型的训练提供高质量的补充数据，具有重要的应用价值。"}}
{"id": "2405.05846", "title": "An Inversion-based Measure of Memorization for Diffusion Models", "authors": ["Zhe Ma", "Qingming Li", "Xuhong Zhang", "Tianyu Du", "Ruixiao Lin", "Zonghui Wang", "Shouling Ji", "Wenzhi Chen"], "categories": ["cs.CR", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2405.05846v3", "summary": "The past few years have witnessed substantial advances in image generation\npowered by diffusion models. However, it was shown that diffusion models are\nsusceptible to training data memorization, raising significant concerns\nregarding copyright infringement and privacy invasion. This study delves into a\nrigorous analysis of memorization in diffusion models. We introduce InvMM, an\ninversion-based measure of memorization, which is based on inverting a\nsensitive latent noise distribution accounting for the replication of an image.\nFor accurate estimation of the measure, we propose an adaptive algorithm that\nbalances the normality and sensitivity of the noise distribution. Comprehensive\nexperiments across four datasets, conducted on both unconditional and\ntext-guided diffusion models, demonstrate that InvMM provides a reliable and\ncomplete quantification of memorization. Notably, InvMM is commensurable\nbetween samples, reveals the true extent of memorization from an adversarial\nstandpoint and implies how memorization differs from membership. In practice,\nit serves as an auditing tool for developers to reliably assess the risk of\nmemorization, thereby contributing to the enhancement of trustworthiness and\nprivacy-preserving capabilities of diffusion models.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2405.05846v3", "cate": "cs.CR", "date": "2024-05-09", "updated": "2025-07-31", "AI": {"title_translation": "基于反演的扩散模型记忆化度量", "tldr": "本文提出InvMM，一种基于反演的扩散模型记忆化度量方法，用于评估和降低隐私风险。", "motivation": "扩散模型在图像生成方面取得了显著进展，但其容易受到训练数据记忆化的影响，引发了版权侵犯和隐私泄露的重大担忧，因此需要对其记忆化问题进行严格分析。", "method": "本研究引入了InvMM，一种基于反演的记忆化度量方法，它基于反演解释图像复制的敏感潜在噪声分布。为了准确估计该度量，我们提出了一种自适应算法，以平衡噪声分布的常态性和敏感性。", "result": "综合实验表明，InvMM提供了可靠且完整的记忆化量化。InvMM在样本之间具有可比性，从对抗性角度揭示了记忆化的真实程度，并暗示了记忆化与成员身份的区别。", "conclusion": "InvMM在实践中可以作为开发人员可靠评估记忆化风险的审计工具，从而有助于增强扩散模型的信任度和隐私保护能力。", "translation": "过去几年，扩散模型推动了图像生成领域的巨大进步。然而，研究表明扩散模型容易受到训练数据记忆化的影响，这引发了对版权侵犯和隐私泄露的重大担忧。本研究深入分析了扩散模型中的记忆化问题。我们引入了InvMM，一种基于反演的记忆化度量方法，它基于反演解释图像复制的敏感潜在噪声分布。为了准确估计该度量，我们提出了一种自适应算法，以平衡噪声分布的常态性和敏感性。在四个数据集上，对无条件和文本引导扩散模型进行的综合实验表明，InvMM提供了可靠且完整的记忆化量化。值得注意的是，InvMM在样本之间具有可比性，从对抗性角度揭示了记忆化的真实程度，并暗示了记忆化与成员身份的区别。在实践中，它可作为开发人员可靠评估记忆化风险的审计工具，从而有助于增强扩散模型的信任度和隐私保护能力。", "summary": "本文针对扩散模型存在的训练数据记忆化问题，提出了一种新的基于反演的记忆化度量方法InvMM。该方法通过反演敏感的潜在噪声分布来量化记忆化程度，并引入自适应算法优化估计精度。实验证明InvMM能可靠、完整地量化记忆化，可作为评估扩散模型隐私风险的实用工具，提升模型的可信赖性。", "keywords": "扩散模型, 记忆化, 反演, 隐私保护, InvMM", "comments": "这项研究创新性地提出了一种基于反演的记忆化度量方法InvMM，为评估和理解扩散模型中的隐私泄露风险提供了一个量化工具。其价值在于不仅提供了一个审计工具，还深入探讨了记忆化与成员身份的区别，对于提升生成模型的安全性和可信度具有重要意义。"}}
{"id": "2507.23286", "title": "Optimal Packetization Towards Low Latency in Random Access Networks (extended version)", "authors": ["Zihong Li", "Anshan Yuan", "Xinghua Sun"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This article is an extended version of a paper to be presented at the IEEE 25th International Conference on Communication Technology (ICCT), Shenyang, China, October 2025", "url": "http://arxiv.org/abs/2507.23286v1", "summary": "As the demand for low-latency services grows, ensuring the delay performance\nof random access (RA) networks has become a priority. Existing studies on the\nqueueing delay performance of the Aloha model universally treat packets as\natomic transmission units, focusing primarily on delay measured in time slots.\nHowever, the impact of packetization on queueing delay has been consistently\noverlooked, particularly for the mean queueing delay measured in seconds, which\nserves as a more precise and practically relevant performance metric than its\nslot-based counterpart. Here, packetization refers to the process of\ndetermining the number of bits assembled into a packet. To optimize queueing\ndelay from the perspective of packetization, this paper establishes the\nmathematical relationship between packetization and mean queueing delay in\nseconds for both connection-free and connection-based Aloha schemes, and\nexplores the optimal packetization strategy to minimize this delay. We identify\nthe optimal mean queueing delay and its corresponding packet size via numerical\nmethods, and further analyze the influence of various network parameters. We\nfurther use simulations to investigate the similar impact of packetization on\njitter of queueing delay. We then apply our analysis to re-evaluate the complex\ntrade-off between the connection-free and connection-based schemes through the\nnew perspective of packetization. Furthermore, recognizing that an analysis of\nthe queueing delay performance for RA-SDT in NTN scenarios, especially from a\npacketization perspective, also remains an unexplored area, we apply the\nanalysis to this scenario as a case study.", "comment": "This article is an extended version of a paper to be presented at the\n  IEEE 25th International Conference on Communication Technology (ICCT),\n  Shenyang, China, October 2025", "pdf_url": "http://arxiv.org/pdf/2507.23286v1", "cate": "cs.NI", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "随机接入网络中低延迟的最优分组化 (扩展版)", "tldr": "本文研究了随机接入网络中，如何通过优化分组化来最小化以秒为单位的平均排队延迟。", "motivation": "现有研究普遍将数据包视为原子传输单元，主要关注以时隙为单位的延迟，而忽略了分组化对以秒为单位的平均排队延迟的影响，后者是更精确、更具实际相关性的性能指标。随着对低延迟服务需求的增长，确保随机接入网络的延迟性能已成为优先事项。", "method": "本文建立了分组化与以秒为单位的平均排队延迟之间的数学关系，并为无连接和基于连接的Aloha方案探索了最优分组化策略。通过数值方法确定了最优平均排队延迟和相应的分组大小，并分析了各种网络参数的影响。此外，还通过仿真研究了分组化对排队延迟抖动的影响，并从分组化角度重新评估了无连接和基于连接方案之间的权衡，最后将其应用于NTN场景中的RA-SDT作为案例研究。", "result": "通过数值方法确定了最优平均排队延迟及其对应的分组大小，并分析了各种网络参数的影响。仿真结果揭示了分组化对排队延迟抖动的类似影响。论文还从分组化视角重新评估了无连接和基于连接方案之间的复杂权衡，并将分析应用于NTN场景中的RA-SDT。", "conclusion": "通过优化分组化，可以显著降低随机接入网络中以秒为单位的平均排队延迟，并提供了一个新的视角来评估不同Aloha方案的性能。", "translation": "随着对低延迟服务需求的增长，确保随机接入（RA）网络的延迟性能已成为优先事项。现有关于Aloha模型排队延迟性能的研究普遍将数据包视为原子传输单元，主要关注以时隙为单位的延迟。然而，分组化对排队延迟的影响一直被忽视，特别是对于以秒为单位的平均排队延迟，这比基于时隙的指标更精确、更具实际相关性。这里，分组化是指确定组装成一个数据包的比特数的过程。为了从分组化的角度优化排队延迟，本文建立了无连接和基于连接的Aloha方案中分组化与以秒为单位的平均排队延迟之间的数学关系，并探索了最小化此延迟的最优分组化策略。我们通过数值方法确定了最优平均排队延迟及其对应的分组大小，并进一步分析了各种网络参数的影响。我们还通过仿真研究了分组化对排队延迟抖动的类似影响。随后，我们通过分组化这一新视角，重新评估了无连接和基于连接方案之间复杂的权衡。此外，认识到NTN场景中RA-SDT的排队延迟性能分析，特别是从分组化角度来看，仍然是一个未探索的领域，我们将该分析应用于此场景作为案例研究。", "summary": "本文解决了随机接入网络中低延迟服务的需求，特别关注了被忽视的分组化对以秒为单位的平均排队延迟的影响。研究建立了分组化与延迟之间的数学关系，并为无连接和基于连接的Aloha方案找到了最优分组化策略以最小化延迟。通过数值方法和仿真，论文确定了最优分组大小，分析了网络参数的影响，并重新评估了不同Aloha方案的权衡，最后将分析应用于NTN场景中的RA-SDT。", "keywords": "分组化, 低延迟, 随机接入网络, 排队延迟, Aloha", "comments": "这篇论文的创新点在于首次系统地考虑了“分组化”对随机接入网络中以秒为单位的平均排队延迟的影响，填补了现有研究的空白。它提供了一个更实际、更精确的性能评估视角，对于未来低延迟网络的设计和优化具有重要指导意义。将分析应用于NTN场景也增加了其应用价值。"}}
{"id": "2507.23020", "title": "Axioms for Model Fidelity Evaluation", "authors": ["Evan Taylor", "Edward Louis", "Gregory Mocko"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      This is the authors' preprint (submitted version) of a paper accepted for ASME IDETC/CIE 2025, edited only to note preprint status. Posted in compliance with ASME 's preprint and copyright policy. The final version is copyrighted by ASME and will appear in the ASME Digital Collection. The DOI will be added once published", "url": "http://arxiv.org/abs/2507.23020v1", "summary": "Digital engineering has transformed the design and development process.\nHowever, the utility of digital engineering is fundamentally dependent on the\nassumption that a simulation provides information consistent with reality. This\nrelationship is described as model fidelity. Despite the widespread use of the\nterm, existing definitions of model fidelity often lack formal rigor in\npractical application, which leaves ambiguity in how this similarity should be\nevaluated. This paper presents seven fundamental axioms to aid the development\nof future fidelity evaluation frameworks. An example of a ground vehicle model\nis used under an existing fidelity evaluation framework to observe the\napplicability of these axioms. In addition, these axioms are used as a\nreference point for considering future opportunities in future work related to\nmodel fidelity.", "comment": "This is the authors' preprint (submitted version) of a paper accepted\n  for ASME IDETC/CIE 2025, edited only to note preprint status. Posted in\n  compliance with ASME 's preprint and copyright policy. The final version is\n  copyrighted by ASME and will appear in the ASME Digital Collection. The DOI\n  will be added once published", "pdf_url": "http://arxiv.org/pdf/2507.23020v1", "cate": "cs.CE", "date": "2025-07-30", "updated": "2025-07-30", "AI": {"title_translation": "模型保真度评估的公理", "tldr": "本文提出了七个基本公理，旨在帮助未来模型保真度评估框架的开发，以解决现有定义在实践中缺乏形式严谨性导致评估模糊的问题。", "motivation": "数字工程的效用取决于模拟与现实一致的假设，即模型保真度。然而，尽管“模型保真度”一词被广泛使用，其现有定义在实际应用中往往缺乏形式上的严谨性，导致如何评估这种相似性存在模糊性。", "method": "本文提出了七个基本公理，旨在帮助未来保真度评估框架的开发。通过在一个现有保真度评估框架下使用一个地面车辆模型示例来观察这些公理的适用性。", "result": "通过一个地面车辆模型示例，观察并展示了所提出公理的适用性。", "conclusion": "这些公理旨在帮助未来保真度评估框架的开发，并可作为未来模型保真度相关工作的参考点。", "translation": "数字工程已经改变了设计和开发过程。然而，数字工程的效用根本上取决于模拟提供与现实一致信息的假设。这种关系被称为模型保真度。尽管该术语被广泛使用，但现有模型保真度定义在实际应用中往往缺乏形式上的严谨性，这导致如何评估这种相似性存在模糊性。本文提出了七个基本公理，以帮助未来保真度评估框架的开发。在一个现有保真度评估框架下使用一个地面车辆模型示例来观察这些公理的适用性。此外，这些公理被用作未来模型保真度相关工作中考虑未来机会的参考点。", "summary": "本文针对模型保真度定义在实际应用中缺乏形式严谨性导致评估模糊的问题，提出了七个基本公理。这些公理旨在辅助未来保真度评估框架的开发，并通过一个地面车辆模型示例验证了其适用性。研究强调这些公理可作为未来模型保真度相关研究的参考基础。", "keywords": "模型保真度, 公理, 评估框架, 数字工程", "comments": "本文通过提出一套基本公理，为模型保真度评估奠定了更坚实的形式基础，这对于提高数字工程的可靠性和实用性至关重要。其创新点在于将模糊的概念系统化，为未来的评估框架提供了明确的指导。"}}
{"id": "2507.23219", "title": "Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction", "authors": ["Yang Ren", "Hai Jiang", "Wei Li", "Menglong Yang", "Heng Zhang", "Zehua Sheng", "Qingsheng Ye", "Shuaicheng Liu"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.23219v1", "summary": "Image downscaling is critical for efficient storage and transmission of\nhigh-resolution (HR) images. Existing learning-based methods focus on\nperforming downscaling within the sRGB domain, which typically suffers from\nblurred details and unexpected artifacts. RAW images, with their unprocessed\nphotonic information, offer greater flexibility but lack specialized\ndownscaling frameworks. In this paper, we propose a wavelet-based recurrent\nreconstruction framework that leverages the information lossless attribute of\nwavelet transformation to fulfill the arbitrary-scale RAW image downscaling in\na coarse-to-fine manner, in which the Low-Frequency Arbitrary-Scale Downscaling\nModule (LASDM) and the High-Frequency Prediction Module (HFPM) are proposed to\npreserve structural and textural integrity of the reconstructed low-resolution\n(LR) RAW images, alongside an energy-maximization loss to align high-frequency\nenergy between HR and LR domain. Furthermore, we introduce the Realistic\nNon-Integer RAW Downscaling (Real-NIRD) dataset, featuring a non-integer\ndownscaling factor of 1.3$\\times$, and incorporate it with publicly available\ndatasets with integer factors (2$\\times$, 3$\\times$, 4$\\times$) for\ncomprehensive benchmarking arbitrary-scale image downscaling purposes.\nExtensive experiments demonstrate that our method outperforms existing\nstate-of-the-art competitors both quantitatively and visually. The code and\ndataset will be released at https://github.com/RenYangSCU/ASRD.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.23219v1", "cate": "eess.IV", "date": "2025-07-31", "updated": "2025-07-31", "AI": {"title_translation": "学习基于小波循环重建的任意尺度RAW图像降采样", "tldr": "提出一种基于小波的循环重建框架，用于任意尺度RAW图像降采样，解决了现有方法在sRGB域的局限性，并引入新数据集，实验证明其优于现有SOTA方法。", "motivation": "高分辨率图像的存储和传输需要高效的降采样。现有基于学习的方法主要针对sRGB域，易产生细节模糊和伪影。RAW图像虽具有灵活性但缺乏专门的降采样框架。", "method": "提出一个基于小波的循环重建框架，利用小波变换的信息无损特性，以从粗到细的方式实现任意尺度RAW图像降采样。该框架包含低频任意尺度降采样模块（LASDM）和高频预测模块（HFPM）以保持结构和纹理完整性，并引入能量最大化损失以对齐高频能量。此外，还构建了Realistic Non-Integer RAW Downscaling (Real-NIRD) 数据集用于基准测试。", "result": "实验证明，该方法在定量和视觉上均优于现有最先进的竞争方法。", "conclusion": "该研究成功开发了一个有效且性能卓越的任意尺度RAW图像降采样框架，并通过新的数据集和全面的实验验证了其优越性，为RAW图像处理提供了新的SOTA解决方案。", "translation": "图像降采样对于高分辨率（HR）图像的高效存储和传输至关重要。现有的基于学习的方法主要集中在sRGB域内进行降采样，这通常会导致细节模糊和意想不到的伪影。RAW图像凭借其未处理的光子信息，提供了更大的灵活性，但缺乏专门的降采样框架。在本文中，我们提出了一种基于小波的循环重建框架，该框架利用小波变换的信息无损特性，以从粗到细的方式实现任意尺度的RAW图像降采样，其中提出了低频任意尺度降采样模块（LASDM）和高频预测模块（HFPM），以保持重建后的低分辨率（LR）RAW图像的结构和纹理完整性，同时采用能量最大化损失来对齐HR和LR域之间的高频能量。此外，我们引入了Realistic Non-Integer RAW Downscaling (Real-NIRD) 数据集，其特征是非整数降采样因子1.3倍，并将其与公开可用的整数因子数据集（2倍、3倍、4倍）结合，用于全面基准测试任意尺度图像降采样目的。大量实验表明，我们的方法在定量和视觉上均优于现有最先进的竞争方法。代码和数据集将在https://github.com/RenYangSCU/ASRD 发布。", "summary": "本文针对RAW图像缺乏高效降采样框架的问题，提出了一种基于小波的循环重建框架，实现任意尺度的RAW图像降采样。该框架通过低频和高频模块结合能量最大化损失，有效保持图像的结构和纹理细节。为全面评估，研究者还构建了包含非整数因子的新数据集Real-NIRD。实验结果表明，该方法在性能上显著优于现有SOTA技术。", "keywords": "RAW图像降采样, 小波变换, 循环重建, 任意尺度, Real-NIRD数据集", "comments": "本文的创新点在于首次提出针对RAW图像的任意尺度降采样框架，并利用小波变换的无损特性及循环重建机制，有效解决了sRGB域方法存在的模糊和伪影问题。引入非整数降采样因子数据集也具有重要意义，能更全面地评估模型性能。该工作为RAW图像处理领域提供了新的SOTA解决方案，具有较高的应用价值。"}}
{"id": "2406.13265", "title": "Molecule Graph Networks with Many-body Equivariant Interactions", "authors": ["Zetian Mao", "Chuan-Shen Hu", "Jiawen Li", "Chen Liang", "Diptesh Das", "Masato Sumita", "Kelin Xia", "Koji Tsuda"], "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.13265v3", "summary": "Message passing neural networks have demonstrated significant efficacy in\npredicting molecular interactions. Introducing equivariant vectorial\nrepresentations augments expressivity by capturing geometric data symmetries,\nthereby improving model accuracy. However, two-body bond vectors in opposition\nmay cancel each other out during message passing, leading to the loss of\ndirectional information on their shared node. In this study, we develop\nEquivariant N-body Interaction Networks (ENINet) that explicitly integrates l =\n1 equivariant many-body interactions to enhance directional symmetric\ninformation in the message passing scheme. We provided a mathematical analysis\ndemonstrating the necessity of incorporating many-body equivariant interactions\nand generalized the formulation to $N$-body interactions. Experiments indicate\nthat integrating many-body equivariant representations enhances prediction\naccuracy across diverse scalar and tensorial quantum chemical properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.13265v3", "cate": "cs.LG", "date": "2024-06-19", "updated": "2025-07-31", "AI": {"title_translation": "具有多体等变相互作用的分子图网络", "tldr": "本文提出等变N体相互作用网络（ENINet），通过引入多体等变相互作用，解决了消息传递神经网络中方向信息丢失的问题，并提高了分子性质预测精度。", "motivation": "在消息传递神经网络中，相对的双体键向量在消息传递过程中可能相互抵消，导致共享节点上的方向信息丢失，从而影响模型精度。", "method": "开发了等变N体相互作用网络（ENINet），显式整合了l=1等变多体相互作用，以增强消息传递方案中的方向对称信息。同时提供了数学分析，证明了纳入多体等变相互作用的必要性，并将公式推广到N体相互作用。", "result": "实验表明，整合多体等变表示显著提高了各种标量和张量量子化学性质的预测精度。", "conclusion": "整合多体等变相互作用是增强消息传递神经网络中方向对称信息、提高分子性质预测准确性的有效方法。", "translation": "消息传递神经网络在预测分子相互作用方面表现出显著的功效。引入等变矢量表示通过捕获几何数据对称性来增强表达能力，从而提高模型精度。然而，相对的双体键向量在消息传递过程中可能会相互抵消，导致其共享节点上的方向信息丢失。在本研究中，我们开发了等变N体相互作用网络（ENINet），它显式地整合了l=1等变多体相互作用，以增强消息传递方案中的方向对称信息。我们提供了数学分析，证明了纳入多体等变相互作用的必要性，并将公式推广到N体相互作用。实验表明，整合多体等变表示提高了各种标量和张量量子化学性质的预测精度。", "summary": "本文提出了一种新颖的等变N体相互作用网络（ENINet），旨在解决传统消息传递神经网络在处理分子相互作用时存在的方向信息丢失问题。ENINet通过显式整合l=1等变多体相互作用来增强消息传递方案中的方向对称信息，从而提高模型表达能力。研究提供了数学分析以支持多体等变相互作用的必要性，并将其推广到N体相互作用。实验结果验证了该方法在预测多种量子化学性质方面的显著精度提升。", "keywords": "分子图网络, 等变相互作用, 消息传递, 量子化学, ENINet", "comments": "该论文通过引入多体等变相互作用，创新性地解决了消息传递神经网络在处理分子方向信息时的局限性，增强了模型的几何对称性捕获能力，对提高分子性质预测精度具有重要意义。"}}
{"id": "2503.04165", "title": "WeakSupCon: Weakly Supervised Contrastive Learning for Encoder Pre-training", "authors": ["Bodong Zhang", "Hamid Manoochehri", "Xiwen Li", "Beatrice S. Knudsen", "Tolga Tasdizen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Medical Image Computing and Computer Assisted Intervention (MICCAI) 2025 workshop on Efficient Medical AI", "url": "http://arxiv.org/abs/2503.04165v2", "summary": "Weakly supervised multiple instance learning (MIL) is a challenging task\ngiven that only bag-level labels are provided, while each bag typically\ncontains multiple instances. This topic has been extensively studied in\nhistopathological image analysis, where labels are usually available only at\nthe whole slide image (WSI) level, while each WSI could be divided into\nthousands of small image patches for training. The dominant MIL approaches\nfocus on feature aggregation and take fixed patch features as inputs. However,\nweakly supervised feature representation learning in MIL settings is always\nneglected. Those features used to be generated by self-supervised learning\nmethods that do not utilize weak labels, or by foundation encoders pre-trained\non other large datasets. In this paper, we propose a novel weakly supervised\nfeature representation learning method called Weakly Supervised Contrastive\nLearning (WeakSupCon) that utilizes bag-level labels. In our method, we employ\nmulti-task learning and define distinct contrastive losses for samples with\ndifferent bag labels. Our experiments demonstrate that the features generated\nusing WeakSupCon with limited computing resources significantly enhance MIL\nclassification performance compared to self-supervised approaches across three\ndatasets. Our WeakSupCon code is available at\ngithub.com/BzhangURU/Paper_WeakSupCon", "comment": "Medical Image Computing and Computer Assisted Intervention (MICCAI)\n  2025 workshop on Efficient Medical AI", "pdf_url": "http://arxiv.org/pdf/2503.04165v2", "cate": "cs.CV", "date": "2025-03-06", "updated": "2025-07-30", "AI": {"title_translation": "WeakSupCon: 弱监督对比学习用于编码器预训练", "tldr": "WeakSupCon是一种新的弱监督对比学习方法，利用包级标签进行特征表示学习，显著提升了多实例学习（MIL）的分类性能。", "motivation": "在多实例学习（MIL）中，弱监督特征表示学习常被忽视。现有方法要么使用不利用弱标签的自监督学习，要么使用在其他大型数据集上预训练的编码器。本文旨在解决这一不足，提出一种利用包级标签进行弱监督特征表示学习的方法。", "method": "本文提出了一种名为WeakSupCon的弱监督对比学习方法，该方法利用包级标签。它采用多任务学习，并为具有不同包标签的样本定义了不同的对比损失。", "result": "实验表明，与自监督方法相比，使用有限计算资源通过WeakSupCon生成的特征显著提高了三个数据集上的MIL分类性能。", "conclusion": "WeakSupCon是一种有效的弱监督特征表示学习方法，能够利用包级标签，并显著提升多实例学习的分类表现。", "translation": "弱监督多实例学习（MIL）是一项具有挑战性的任务，因为只提供了包级标签，而每个包通常包含多个实例。这个主题在组织病理学图像分析中得到了广泛研究，其中标签通常只在全玻片图像（WSI）级别可用，而每个WSI可以被分成数千个小图像块进行训练。主流的MIL方法侧重于特征聚合，并以固定的图像块特征作为输入。然而，MIL设置中的弱监督特征表示学习却总是被忽视。这些特征通常由不利用弱标签的自监督学习方法生成，或者由在其他大型数据集上预训练的基础编码器生成。在本文中，我们提出了一种新颖的弱监督特征表示学习方法，称为弱监督对比学习（WeakSupCon），该方法利用包级标签。在我们的方法中，我们采用多任务学习，并为具有不同包标签的样本定义了不同的对比损失。我们的实验表明，与自监督方法相比，使用有限计算资源通过WeakSupCon生成的特征显著提高了三个数据集上的MIL分类性能。我们的WeakSupCon代码可在github.com/BzhangURU/Paper_WeakSupCon获取。", "summary": "本文提出了一种新颖的弱监督对比学习方法WeakSupCon，旨在解决多实例学习（MIL）中弱监督特征表示学习被忽视的问题。该方法利用包级标签，通过多任务学习为不同包标签的样本定义独特的对比损失。实验结果表明，与现有的自监督方法相比，WeakSupCon在有限计算资源下能生成显著增强MIL分类性能的特征。", "keywords": "弱监督学习, 对比学习, 多实例学习, 特征表示学习, 编码器预训练", "comments": "本文的创新点在于提出了WeakSupCon，一个专门针对多实例学习中弱监督特征表示学习的方法，有效利用了包级标签。它填补了现有MIL方法多关注特征聚合而忽视特征学习的空白，并通过引入多任务学习和特定对比损失，在资源有限的情况下取得了优于自监督方法的性能，具有重要的实践意义。"}}
