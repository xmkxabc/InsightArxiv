# AI-Enhanced arXiv Daily 2025-07-22

<a id='toc'></a>
## 今日总计: 755 篇论文
### 目录
- [cs.CR](#cscr) (29 篇)
- [cs.AI](#csai) (58 篇)
- [cs.LG](#cslg) (94 篇)
- [cs.MA](#csma) (4 篇)
- [cs.RO](#csro) (41 篇)
- [cs.CV](#cscv) (147 篇)
- [cs.HC](#cshc) (23 篇)
- [cs.ET](#cset) (3 篇)
- [cs.SE](#csse) (22 篇)
- [cs.SI](#cssi) (8 篇)
- [cs.NI](#csni) (5 篇)
- [cs.IT](#csit) (10 篇)
- [cs.AR](#csar) (8 篇)
- [cs.DC](#csdc) (11 篇)
- [cs.CY](#cscy) (12 篇)
- [cs.CE](#csce) (3 篇)
- [cs.FL](#csfl) (1 篇)
- [eess.SY](#eesssy) (20 篇)
- [eess.SP](#eesssp) (16 篇)
- [eess.IV](#eessiv) (17 篇)
- [eess.AS](#eessas) (4 篇)
- [cs.CL](#cscl) (83 篇)
- [cs.DS](#csds) (8 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.IR](#csir) (9 篇)
- [cs.NE](#csne) (2 篇)
- [math.NA](#mathna) (29 篇)
- [cs.SD](#cssd) (11 篇)
- [cs.PL](#cspl) (3 篇)
- [q-bio.QM](#q-bioqm) (3 篇)
- [math.OC](#mathoc) (6 篇)
- [physics.geo-ph](#physicsgeo-ph) (3 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (3 篇)
- [cs.MM](#csmm) (1 篇)
- [math.CA](#mathca) (1 篇)
- [math.DS](#mathds) (1 篇)
- [stat.ME](#statme) (2 篇)
- [cs.GT](#csgt) (1 篇)
- [stat.ML](#statml) (9 篇)
- [cs.DM](#csdm) (1 篇)
- [q-fin.CP](#q-fincp) (1 篇)
- [physics.ao-ph](#physicsao-ph) (1 篇)
- [physics.plasm-ph](#physicsplasm-ph) (2 篇)
- [math.CO](#mathco) (1 篇)
- [quant-ph](#quant-ph) (7 篇)
- [math.ST](#mathst) (2 篇)
- [math.PR](#mathpr) (2 篇)
- [physics.flu-dyn](#physicsflu-dyn) (3 篇)
- [physics.comp-ph](#physicscomp-ph) (3 篇)
- [physics.chem-ph](#physicschem-ph) (2 篇)
- [cs.CG](#cscg) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)
- [q-bio.NC](#q-bionc) (2 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [math.FA](#mathfa) (1 篇)
- [stat.AP](#statap) (1 篇)
- [math.NT](#mathnt) (1 篇)
- [hep-ph](#hep-ph) (1 篇)
- [astro-ph.IM](#astro-phim) (2 篇)
- [q-bio.BM](#q-biobm) (1 篇)
- [cs.DB](#csdb) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [16] [Conthereum: Concurrent Ethereum Optimized Transaction Scheduling for Multi-Core Execution](https://arxiv.org/abs/2504.07280)
> *Conthereum：面向多核执行的并发以太坊优化交易调度*

*Atefeh Zareh Chahoki, Maurice Herlihy, Marco Roveri* | **Category: cs.CR, cs.DC** | **Updated: 2025-07-22**

**Keywords:** 并发以太坊, 交易调度, 多核执行, 柔性作业车间调度, 吞吐量优化

**Comment:** 10 pages, 3 tables, 7 figures, 1 algorithms

> **TL;DR:** Conthereum是一个并发以太坊解决方案，通过受FJSS启发的调度器和贪婪启发式算法实现块内并行交易执行，显著提高吞吐量，并优于现有并发方案。

**AI_Comments:** Conthereum 的创新点在于将柔性作业车间调度问题（FJSS）的思想引入区块链交易调度，并结合了离线的智能合约静态冲突分析，为实时调度提供支持。这提供了一种新颖且高效的策略来解决以太坊的吞吐量瓶颈，使其能更好地利用现代多核硬件。其对冲突执行和顺序一致性的保证，对于区块链系统的正确性至关重要。尽管在高核心数下存在可扩展性挑战，但其对现有模型的显著改进和对其他并发方案的超越，表明了其重要性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的以太坊执行模型是顺序的，无法利用多核基础设施，导致吞吐量和每秒交易量（TPS）受限。

**Method:** Conthereum提出一个受柔性作业车间调度问题（FJSS）启发的新型轻量级高性能调度器，采用自定义贪婪启发式算法来解决调度问题。此外，它还包括一个离线阶段，通过智能合约的静态分析构建冲突分析库，以悲观方法识别潜在冲突函数。

**Result:** 经验评估显示，在标准8核机器上，吞吐量接近线性增长。尽管在更高核心数和更多交易冲突下可扩展性偏离线性，Conthereum仍显著优于当前顺序执行模型，并在多种条件下胜过现有并发解决方案。

**Conclusion:** Conthereum通过其新颖的调度器和冲突分析方法，成功将以太坊的顺序执行模型转变为并行模型，显著提高了吞吐量，并在广泛条件下优于现有并发解决方案。

> **ai_Abstract:** Conthereum 是一个为以太坊设计的并发解决方案，旨在通过块内并行交易执行来利用多核处理器，从而将以太坊的顺序执行模型转变为并行模型。它引入了一个受FJSS启发的轻量级高性能调度器，并结合自定义贪婪启发式算法，有效解决交易调度问题，确保无冲突执行并保持顺序一致性。该方案还通过智能合约的静态分析构建冲突库。实证结果表明，Conthereum 大幅提升了吞吐量，在8核机器上实现近线性增益，并且在各种条件下均优于现有并发解决方案及当前的顺序执行模型。

> **摘要翻译:** Conthereum 是一个并发以太坊解决方案，用于块内并行交易执行，使验证者能够利用多核基础设施，并将以太坊的顺序执行模型转换为并行模型。这种转变显著提高了吞吐量和每秒交易量（TPS），同时确保在提议者和证明者模式下无冲突执行，并在证明者中保持执行顺序一致性。Conthereum 的核心是一个受柔性作业车间调度问题（FJSS）启发的新颖、轻量级、高性能调度器。我们提出了一种自定义的贪婪启发式算法及其高效实现，该算法有效地解决了这一问题，并在寻找满足约束、实现最小完工时间和最大并行执行加速的次优解决方案方面，显著优于现有调度方法。此外，Conthereum 还包括一个离线阶段，通过对智能合约进行静态分析获得冲突分析库，以悲观方法识别潜在冲突函数，从而为其实时调度器提供支持。基于这种新颖的调度器和大量的冲突数据，Conthereum 优于现有的并发块内解决方案。经验评估显示，在标准8核机器上，随着计算能力的增加，吞吐量接近线性增长。尽管在更高核心数和增加交易冲突的情况下，可扩展性会偏离线性，但 Conthereum 仍然显著改进了当前的顺序执行模型，并在广泛的条件下优于现有并发解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [50] [SoK: Concurrency in Blockchain -- A Systematic Literature Review and the Unveiling of a Misconception](https://arxiv.org/abs/2506.01885)
> *区块链中的并发性：系统性文献综述与一个误解的揭示*

*Atefeh Zareh Chahoki, Maurice Herlihy, Marco Roveri* | **Category: cs.CR, cs.DC, cs.PF** | **Updated: 2025-07-22**

**Keywords:** 区块链, 并发性, 智能合约, 系统性文献综述, 误解

**Comment:** 

> **TL;DR:** 本文对区块链中的并发性进行了首次系统性综述，揭示了一个广泛存在的错误并发假设，并为未来的研究指明了方向。

**AI_Comments:** 本文的创新之处在于它是首次对智能合约并发性进行系统性综述。其重要性体现在揭示并纠正了一个关键的“错误并发假设”，该假设已导致“广泛的误解”，这可能对未来的相关研究方向产生重要影响。此外，它还提供了结构化的分类法并概述了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约作为区块链的基石，需要处理大量的交易。并发性虽然能提高吞吐量，但也引入了竞争条件、非确定性以及死锁、活锁等风险，因此深入探讨区块链中的并发性至关重要。

**Method:** 本文进行了首次针对智能合约并发性的系统性文献综述。研究方法包括：建立区块链系统中并发级别的分类法，讨论未来可采用的解决方案；审查并发操作中的漏洞、攻击和对策；揭示一个主要研究类别中存在的错误并发假设；识别各类别中的研究空白以规划未来研究方向。

**Result:** 本研究建立了区块链系统中并发级别的分类法，并讨论了相关解决方案。它审查了并发操作中的漏洞、攻击和对策。最重要的是，本研究揭示了一个在主要研究类别中普遍存在的、导致广泛误解的错误并发假设。

**Conclusion:** 本文旨在纠正区块链研究中一个普遍存在的并发性错误假设，并引导未来的研究采用更精确的模型，同时通过识别研究空白来支持区块链技术的进步。

> **ai_Abstract:** 本文首次对区块链智能合约中的并发性进行了系统性文献综述。它建立了一个并发级别分类法，分析了并发操作中的漏洞和对策，并揭示了一个在现有研究中普遍存在的错误并发假设。该工作旨在纠正这一误解，引导未来研究采用更准确的模型，并识别研究空白以推动区块链技术的发展。

> **摘要翻译:** 智能合约是区块链技术的基石，能够实现安全、自动化的分布式执行。鉴于它们在处理客户端、矿工和验证者之间大量交易方面的作用，探索并发性至关重要。这包括区块内并发交易的执行或验证、跨分片的区块处理以及矿工选择和持久化交易的竞争。并发性和并行性是一把双刃剑：它们在提高吞吐量的同时，也引入了竞争条件、非确定性以及死锁和活锁等漏洞的风险。

本文首次对智能合约中的并发性进行了调查，提供了一份系统性的文献综述，并按关键维度进行组织。首先，它建立了区块链系统中并发级别的分类法，并讨论了未来可采用的解决方案。其次，它审查了并发操作中的漏洞、攻击和对策，强调了正确性和安全性的必要性。至关重要的是，我们揭示了一个主要研究类别中存在的错误并发假设，这导致了广泛的误解。这项工作旨在纠正这一误解，并引导未来的研究采用更准确的模型。最后，我们识别了每个类别中的空白，以概述未来的研究方向并支持区块链的发展。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [91] [BandFuzz: An ML-powered Collaborative Fuzzing Framework](https://arxiv.org/abs/2507.10845)
> *BandFuzz：一个机器学习驱动的协作式模糊测试框架*

*Wenxuan Shi, Hongwei Li, Jiahao Yu, Xinqian Sun, Wenbo Guo, Xinyu Xing* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-21**

**Keywords:** 协作式模糊测试, 机器学习, 资源分配, 多臂老虎机, 漏洞检测

**Comment:** 

> **TL;DR:** BandFuzz是一个机器学习驱动的协作式模糊测试框架，它通过新颖的资源分配算法和模糊器评估方法，在不增加计算资源的情况下，优于现有模糊测试框架和个体模糊器，并在实际漏洞检测中表现出色。

**AI_Comments:** BandFuzz的创新点在于其将多臂老虎机模型应用于模糊测试的资源分配，实现了全局最优的协作策略，而非传统的贪婪方法。这解决了现有协作式模糊测试框架效率低下的问题。此外，其提出的综合模糊器评估方法，考虑了解决困难分支的能力，也提升了模糊测试的有效性。在实际竞赛中获得第一名，充分证明了其在真实世界漏洞检测中的强大能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有协作式模糊测试框架面临计算资源需求额外增加和模糊器之间资源分配效率低下等挑战。

**Method:** 本文提出了BANDFUZZ，一个由机器学习驱动的协作式模糊测试框架。其核心贡献在于其新颖的、由多臂老虎机模型驱动的资源分配算法，该算法不同于现有框架中的贪婪方法，能够模拟个体模糊器的长期影响，从而发现全局最优的协作策略。此外，BANDFUZZ提出了一种新的模糊器评估方法，不仅评估代码覆盖率，还评估模糊器解决困难分支的能力。最后，它集成了实时种子同步机制和实现层面的优化，以提高模糊测试效率和稳定性。

**Result:** 通过在Fuzzbench和Fuzzer Test Suite上的大量实验表明，BANDFUZZ优于最先进的协作式模糊测试框架autofz和广泛使用的个体模糊器。通过全面的消融研究验证了BANDFUZZ的关键设计。值得注意的是，通过分析一项全球模糊测试竞赛的结果（BANDFUZZ获得第一名），证明了BANDFUZZ在实际漏洞检测中的有效性。

**Conclusion:** BANDFUZZ是一个有效的机器学习驱动的协作式模糊测试框架，它通过创新的资源分配和模糊器评估方法，在不增加额外计算资源的情况下，显著提升了模糊测试性能和漏洞检测能力。

> **ai_Abstract:** BandFuzz是一个机器学习驱动的协作式模糊测试框架，旨在解决现有协作式模糊测试在资源分配效率和额外计算资源需求上的挑战。它引入了基于多臂老虎机模型的新颖资源分配算法，以优化模糊器的长期协作策略，并提出了一种综合的模糊器评估方法。通过集成实时种子同步和优化，BandFuzz在不增加额外计算资源的情况下，在实验中表现优于现有框架和个体模糊器，并在实际漏洞检测竞赛中获得第一名。

> **摘要翻译:** 协作式模糊测试结合了多个独立的模糊器，并为不同的程序动态选择合适的组合。与依赖特定假设的独立模糊器不同，协作式模糊测试放宽了对目标程序的假设，在各种程序中提供稳健的性能。然而，现有的协作式模糊测试框架面临挑战，包括额外的计算资源需求和模糊器之间低效的资源分配。为了解决这些挑战，我们提出了BANDFUZZ，一个由机器学习驱动的协作式模糊测试框架，它在不要求额外计算资源的情况下超越了独立的模糊器。BANDFUZZ的关键贡献在于其新颖的资源分配算法，该算法由我们提出的多臂老虎机模型驱动。与现有框架中的贪婪方法不同，BANDFUZZ模拟了个体模糊器的长期影响，从而能够发现全局最优的协作策略。我们提出了一种新颖的模糊器评估方法，该方法不仅评估代码覆盖率，还评估模糊器解决困难分支的能力。最后，我们集成了实时种子同步机制和实现层面的优化，以提高模糊测试效率和稳定性。通过在Fuzzbench和Fuzzer Test Suite上的大量实验，我们表明BANDFUZZ优于最先进的协作式模糊测试框架autofz和广泛使用的独立模糊器。我们通过全面的消融研究验证了BANDFUZZ的关键设计。值得注意的是，我们通过分析一项全球模糊测试竞赛的结果，证明了BANDFUZZ在实际漏洞检测中的有效性，BANDFUZZ在该竞赛中获得了第一名。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [131] [A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation](https://arxiv.org/abs/2507.11324)
> *隐私保护合成数据生成中隐私度量的综述*

*Frederik Marinus Trudslev, Matteo Lissandrini, Juan Manuel Rodriguez, Martin Bøgsted, Daniele Dell'Aglio* | **Category: cs.CR, cs.DB** | **Updated: 2025-07-22**

**Keywords:** 隐私保护合成数据生成, 隐私度量, 差分隐私, 综述, 数据隐私

**Comment:** 

> **TL;DR:** 本文综述了隐私保护合成数据生成中用于评估隐私风险的17种不同隐私度量，并阐述了其假设和数学公式。

**AI_Comments:** 这篇综述文章对于理解隐私保护合成数据生成领域中隐私度量的多样性和复杂性具有重要意义。它填补了现有研究中对这些度量缺乏统一和彻底定义的空白，有助于研究人员更准确地评估合成数据的隐私风险。

<details>
  <summary>Details</summary>

**Motivation:** 隐私保护合成数据生成(PP-SDG)中的差分隐私(DP)预算难以解释，导致实际风险不透明。为了解决这个问题，需要对用于评估隐私风险的多种隐私度量(PMs)进行彻底的定义和理解，因为它们目前在不同研究中被独立使用且隐含特定假设。

**Method:** 本文综述了17种不同的隐私度量，详细阐述了它们的假设和数学公式。

**Result:** 本文呈现了17种不同隐私度量的假设和数学公式。

**Conclusion:** 本文通过详细阐述隐私度量的假设和数学公式，旨在为理解和评估隐私保护合成数据生成中的隐私风险提供更透明和系统的基础。

> **ai_Abstract:** 本文综述了隐私保护合成数据生成（PP-SDG）领域中用于评估隐私风险的多种隐私度量（PMs）。鉴于差分隐私（DP）预算难以解释，以及现有PMs在不同研究中被独立使用且隐含特定假设的问题，本工作详细介绍了17种不同隐私度量的假设和数学公式，旨在提供对这些度量更清晰的理解和定义，以提高隐私风险评估的透明度。

> **摘要翻译:** 隐私保护合成数据生成（PP-SDG）旨在从个人数据中生成合成数据集，同时保持隐私和实用性。差分隐私（DP）是PP-SDG机制的一种属性，它确定了个人在共享敏感数据时受保护的程度。然而，DP所表达的隐私预算（ε）很难解释。为了使与隐私预算相关的实际风险更加透明，已经提出了多种隐私度量（PMs）来评估数据的隐私风险。这些PMs在不同的研究中被用于评估新引入的PP-SDG机制。因此，这些PMs体现了它们旨在评估的PP-SDG机制的相同假设。因此，有必要彻底定义这些度量的计算方法。在这项工作中，我们介绍了17种不同隐私度量的假设和数学公式。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [171] [A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies](https://arxiv.org/abs/2507.14893)
> *基于同源的紧凑型后量子强指定验证者签名方案*

*Farzin Renan* | **Category: cs.CR, math.NT, 11T71, 94A60, 68P25, 14G50, 81P94** | **Updated: 2025-07-22**

**Keywords:** 后量子密码学, 强指定验证者签名, 同源, 紧凑, $\mathsf{CSI\text{-}SDVS}$

**Comment:** 

> **TL;DR:** 提出了一种基于同源的紧凑型后量子强指定验证者签名方案 $\mathsf{CSI\text{-}SDVS}$，其密钥和签名尺寸显著小于现有方案。

**AI_Comments:** 这篇论文的创新点在于提出了首个基于同源的紧凑型后量子强指定验证者签名方案。在后量子密码学领域，尤其是在SDVS这种特定应用场景下，该方案通过利用同源密码学的特性，成功解决了传统方案的量子脆弱性和基于格的方案尺寸过大的问题，实现了密钥和签名尺寸的显著优化，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有强指定验证者签名（SDVS）方案易受量子攻击，且已有的后量子替代方案（如基于格的）通常密钥和签名尺寸过大，因此需要一种紧凑且抗量子的SDVS方案。

**Method:** 本文提出了一种新的基于同源的SDVS方案 $\mathsf{CSI\text{-}SDVS}$。该方案构建于CSIDH的理想类群作用框架和CSI-FiSh的签名技术之上，并依赖于多目标群作用逆问题（MT-GAIP）的困难性。

**Result:** $\mathsf{CSI\text{-}SDVS}$ 在随机预言模型中实现了强不可伪造性（SUF-CMA）、不可转移性（NT）和签名者身份隐私（PSI）等强安全保证。其密钥和签名尺寸均为 $\mathcal{O}(\lambda)$，显著优于现有后量子SDVS方案中典型的 $\mathcal{O}(\lambda^2)$ 边界。这使其成为最紧凑的PQC-based SDVS方案之一，也是唯一基于同源的后量子安全构造。

**Conclusion:** $\mathsf{CSI\text{-}SDVS}$ 提供了一种高效且安全的后量子强指定验证者签名方案，解决了现有方案在抗量子性和尺寸方面的不足。

> **ai_Abstract:** 本文提出了一种名为 $\mathsf{CSI\text{-}SDVS}$ 的新型基于同源的强指定验证者签名（SDVS）方案。该方案旨在解决现有SDVS方案在量子计算威胁下的脆弱性以及后量子替代方案（如基于格的）尺寸过大的问题。$\mathsf{CSI\text{-}SDVS}$ 基于CSIDH框架和CSI-FiSh技术，并依赖于MT-GAIP的困难性。它在随机预言模型中提供了强大的安全保证，并且密钥和签名尺寸均为 $\mathcal{O}(\lambda)$，显著优于现有后量子SDVS方案的 $\mathcal{O}(\lambda^2)$ 尺寸，使其成为目前最紧凑的同源后量子SDVS方案。

> **摘要翻译:** 数字签名是数字通信中提供认证和完整性的基本加密工具。然而，隐私敏感的应用，如电子投票和数字现金，需要更严格的验证模型以确保保密性和控制。强指定验证者签名（SDVS）方案通过允许签名者指定一个特定的验证者来满足这一需求，确保只有该方可以验证签名。现有的SDVS构造主要基于数论假设，因此容易受到量子攻击。尽管已经提出了后量子替代方案，特别是基于格的方案，但它们通常带来大的密钥和签名尺寸。在这项工作中，我们引入了 $\mathsf{CSI\text{-}SDVS}$，这是一种新颖的基于同源的SDVS方案，提供了一种紧凑的、抗量子的替代方案。我们的构造建立在CSIDH的理想类群作用框架和CSI-FiSh的签名技术之上，并依赖于多目标群作用逆问题（MT-GAIP）的困难性。$\mathsf{CSI\text{-}SDVS}$ 在随机预言模型中实现了强大的安全保证；即，在选择消息攻击下的强不可伪造性（SUF-CMA）、不可转移性（NT）和签名者身份隐私（PSI）。值得注意的是，$\mathsf{CSI\text{-}SDVS}$ 中的密钥和签名尺寸均为 $\mathcal{O}(\lambda)$，这代表着对现有后量子SDVS方案中典型的 $\mathcal{O}(\lambda^2)$ 边界的显著改进，从而使其成为最紧凑的基于PQC的SDVS方案之一，也是唯一基于同源的后量子安全构造。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [341] [SVAgent: AI Agent for Hardware Security Verification Assertion](https://arxiv.org/abs/2507.16203)
> *SVAgent：用于硬件安全验证断言的AI代理*

*Rui Guo, Avinash Ayalasomayajula, Henian Li, Jingbo Zhou, Sujan Kumar Saha, Farimah Farahmandi* | **Category: cs.CR, cs.AI, cs.AR, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 硬件安全, SystemVerilog断言, SVA, AI代理, 漏洞验证

**Comment:** 

> **TL;DR:** SVAgent是一个AI代理框架，通过需求分解机制自动生成SystemVerilog断言（SVA），以提高硬件安全验证的效率和准确性，并有效应对现代复杂集成电路中的安全漏洞。

**AI_Comments:** SVAgent的创新之处在于其引入的需求分解机制，这对于将复杂、模糊的自然语言需求转化为精确、可验证的断言至关重要，有效解决了传统SVA开发中效率低下和难以应对复杂漏洞的问题。其在真实工程环境中的验证也增加了其实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** SystemVerilog断言（SVA）是检测电路设计漏洞的常用方法，但随着集成电路设计全球化和安全要求升级，SVA开发模式暴露出开发效率低下、难以有效处理复杂集成电路中日益增多的安全漏洞等局限性。

**Method:** 本文提出了SVAgent框架，通过引入需求分解机制，将复杂的原始需求转化为结构化、可逐步解决的细粒度问题解决链，从而自动生成SVA。

**Result:** 实验表明，SVAgent能有效抑制幻觉和随机答案的影响，SVA的准确性和一致性等关键评估指标显著优于现有框架。此外，SVAgent已成功集成到主流集成电路漏洞评估框架中，并在真实工程设计环境中验证了其实用性和可靠性。

**Conclusion:** SVAgent通过其创新的自动SVA生成框架，显著提高了硬件安全验证的效率和准确性，有效解决了传统SVA开发模式的局限性，并在实际工程中展现了其可靠性。

> **ai_Abstract:** 本文提出了SVAgent，一个用于硬件安全验证断言的AI代理框架。针对当前SystemVerilog断言（SVA）开发效率低且难以应对复杂电路安全漏洞的挑战，SVAgent引入需求分解机制，将复杂需求细化为可解决的链式问题，实现SVA的自动化生成。实验证明，SVAgent在抑制幻觉和提高SVA准确性、一致性方面优于现有框架，并已成功集成到主流漏洞评估框架中，验证了其在实际工程环境中的实用性和可靠性。

> **摘要翻译:** 使用SystemVerilog断言（SVA）进行验证是检测电路设计漏洞最流行的方法之一。然而，随着集成电路设计的全球化和安全要求的不断升级，SVA开发模式暴露出主要局限性。它不仅开发效率低下，而且无法有效处理现代复杂集成电路中日益增多的安全漏洞。为了应对这些挑战，本文提出了一种创新的SVA自动生成框架SVAgent。SVAgent引入了一种需求分解机制，将原始的复杂需求转化为结构化、可逐步解决的细粒度问题解决链。实验表明，SVAgent可以有效抑制幻觉和随机答案的影响，并且SVA的准确性和一致性等关键评估指标显著优于现有框架。更重要的是，我们成功地将SVAgent集成到最主流的集成电路漏洞评估框架中，并在真实的工程设计环境中验证了其实用性和可靠性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [347] [eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models](https://arxiv.org/abs/2507.16241)
> *eX-NIDS：一个利用大型语言模型的可解释网络入侵检测框架*

*Paul R. B. Houssel, Siamak Layeghy, Priyanka Singh, Marius Portmann* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 网络入侵检测, 可解释性, 大型语言模型, 威胁情报, 流量分析

**Comment:** 

> **TL;DR:** eX-NIDS是一个利用大型语言模型提升网络入侵检测系统（NIDS）可解释性的框架，通过上下文增强提示词，使LLM能生成详细的恶意流量解释，并证明其比基线方法性能提升超过20%。

**AI_Comments:** eX-NIDS的创新之处在于其将LLM与网络安全领域的NIDS相结合，通过上下文增强提示词的方式，有效地解决了NIDS解释性不足的问题。这种方法为理解复杂的网络攻击提供了新的视角，并有望提高安全分析师的工作效率。其性能提升显著，表明了LLM在特定领域知识增强下的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过引入大型语言模型（LLMs）来增强基于流的网络入侵检测系统（NIDS）的解释性，解决NIDS分类结果缺乏透明度的问题。

**Method:** 该论文提出了eX-NIDS框架。当NIDS将流量标记为恶意时，Prompt Augmenter模块会从中提取上下文信息和网络威胁情报（CTI）相关知识。这些增强数据与LLM的输入提示词结合，使LLM能够生成关于流量被识别为恶意的原因的详细解释。该框架使用Llama 3和GPT-4模型进行评估，并采用了一种针对自然语言解释的新的评估方法，侧重于正确性和一致性。

**Result:** 增强型大型语言模型（LLMs）能够生成准确且一致的解释，成为NIDS中解释恶意流量分类的有价值的补充工具。与不包含上下文信息的Basic-Prompt Explainer基线相比，使用增强型提示词将性能提升了20%以上。

**Conclusion:** eX-NIDS框架成功地利用大型语言模型提升了网络入侵检测系统的可解释性。通过上下文增强提示词，LLMs能够提供高质量的恶意流量分类解释，显著优于传统方法，为NIDS提供了宝贵的补充解释能力。

> **ai_Abstract:** eX-NIDS是一个新颖的框架，旨在通过整合大型语言模型（LLMs）来提高网络入侵检测系统（NIDS）的可解释性。它通过一个“提示增强器”模块从被识别为恶意的流量中提取上下文和网络威胁情报，然后将这些信息与LLM的输入提示词结合，使其能够生成详细的分类解释。研究表明，与不使用上下文信息的基线方法相比，该框架能使LLM生成更准确、一致的解释，性能提升超过20%，为NIDS提供了重要的辅助解释能力。

> **摘要翻译:** 本文介绍了eX-NIDS，这是一个旨在通过利用大型语言模型（LLMs）来增强基于流的网络入侵检测系统（NIDS）可解释性的框架。在我们提出的框架中，被NIDS标记为恶意的流量首先通过一个名为“提示增强器”（Prompt Augmenter）的模块进行处理。该模块从这些流量中提取上下文信息和网络威胁情报（CTI）相关知识。然后，这些丰富的、上下文特定的数据与LLM的输入提示词集成，使其能够生成关于流量为何被NIDS识别为恶意的详细解释和解读。我们将生成的解释与未将任何上下文信息整合到LLM输入提示词中的Basic-Prompt Explainer基线进行比较。我们的框架使用Llama 3和GPT-4模型进行了定量评估，并采用了一种为自然语言解释量身定制的新颖评估方法，重点关注其正确性和一致性。结果表明，增强型LLM可以生成准确且一致的解释，作为NIDS中有价值的补充工具，用于解释恶意流量的分类。与Basic-Prompt Explainer相比，使用增强型提示词将性能提升了20%以上。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [353] [From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines](https://arxiv.org/abs/2507.16276)
> *从合同到代码：使用多级有限状态机实现智能合约生成自动化*

*Lambard Maxence, Bertelle Cyrille, Duvallet Claude* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 智能合约, 多级有限状态机, 自动化生成, 区块链, 模块化

**Comment:** 

> **TL;DR:** 本研究引入了一种多级有限状态机模型，旨在简化智能合约的开发，使其对非技术专业人员更易于使用，并通过安全分析确保其稳健性。

**AI_Comments:** 该论文创新性地将多级有限状态机应用于智能合约的自动化生成，有效解决了智能合约开发中复杂性和高技术门槛的痛点。通过提供形式化框架和抽象化技术细节，有望显著降低非技术专业人员进入智能合约领域的障碍，从而加速区块链技术的应用落地。安全分析的纳入也增强了其方案的实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约因其复杂性和对高级编程技能的要求，阻碍了其广泛采用。尽管区块链技术能提升透明度、安全性和效率，但现有智能合约的开发门槛较高。

**Method:** 本研究引入了一种多级有限状态机模型，用于表示和跟踪智能合约的执行。该模型提供了一个形式化的框架，抽象了底层的技术复杂性，并强调了可重用组件和模块化。

**Result:** 该模型通过提供抽象技术复杂性的形式化框架，简化了智能合约的开发，使其对非技术专业人员更易于访问。其分层结构增强了合约的模块化和可追溯性，并进行了安全分析以评估潜在漏洞，确保生成智能合约的稳健性和可靠性。

**Conclusion:** 多级有限状态机模型为智能合约的自动化生成提供了一个稳健且可靠的解决方案，通过降低开发门槛和增强合约属性，有望促进智能合约的广泛应用。

> **ai_Abstract:** 本研究提出了一种基于多级有限状态机（MLFSM）的模型，旨在自动化和简化智能合约的生成过程。该模型通过抽象底层技术复杂性，降低了智能合约的开发门槛，使其对非技术专业人员也可用。MLFSM的分层结构增强了合约的模块化和可追溯性，并允许进行详细的功能属性评估。文章还探讨了现有方法，并对所提出的模型进行了安全分析，以确保生成合约的稳健性和可靠性，从而推动智能合约的广泛应用。

> **摘要翻译:** 在日益复杂的合同环境中，对透明度、安全性和效率的需求日益增强。区块链技术凭借其去中心化和不可变的特性，通过降低中介成本、最大限度地减少欺诈风险和增强系统兼容性来应对这些挑战。智能合约最初由尼克·萨博（Nick Szabo）概念化，后来在以太坊区块链上实现，它们自动化并保障了合同条款，为各行各业提供了强大的解决方案。然而，它们的复杂性以及对高级编程技能的要求，构成了广泛采用的重大障碍。本研究引入了一种多级有限状态机模型，旨在表示和跟踪智能合约的执行。我们的模型旨在通过提供一个形式化的框架来简化智能合约的开发，该框架抽象了底层的技术复杂性，使其对没有深厚技术专业知识的专业人员也易于访问。多级有限状态机的分层结构增强了合约的模块化和可追溯性，有助于详细表示和评估功能属性。本文探讨了这种多级方法的潜力，回顾了现有方法和工具，并详细介绍了智能合约的生成过程，重点关注可重用组件和模块化。我们还进行了安全分析，以评估我们模型中的潜在漏洞，确保所生成智能合约的稳健性和可靠性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [359] [Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](https://arxiv.org/abs/2507.16291)
> *像网络钓鱼者一样说话：基于大型语言模型的语音网络钓鱼分类器攻击*

*Wenhao Li, Selvakumar Manickam, Yung-wey Chong, Shankar Karuppayah* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 语音网络钓鱼, 对抗性攻击, 机器学习分类器, 提示工程

**Comment:** Accepted by EAI ICDF2C 2025

> **TL;DR:** 研究发现，大型语言模型（LLM）可以生成有效规避机器学习语音钓鱼检测器的钓鱼脚本，显著降低检测准确率，且攻击快速经济，凸显了增强防御和LLM滥用防护的必要性。

**AI_Comments:** 这项研究具有重要的创新性，因为它揭示了大型语言模型在生成高度逼真且能规避检测的对抗性钓鱼内容方面的强大能力。这不仅对现有的网络钓鱼检测技术构成了严峻挑战，也为LLM的潜在恶意使用敲响了警钟。其重要性在于，它促使安全研究人员开发更先进、更具弹性的防御机制，并提醒LLM开发者需要更严格地限制其模型被用于社会工程攻击。研究的局限性可能在于其评估主要基于转录文本而非实际语音，且所用数据集可能无法完全代表全球范围内的vishing多样性。

<details>
  <summary>Details</summary>

**Motivation:** 语音网络钓鱼（vishing）是持续存在的网络安全威胁，利用人类信任进行欺骗。尽管基于机器学习（ML）的分类器在检测恶意通话记录方面显示出潜力，但它们容易受到保留语义内容的对抗性操纵。

**Method:** 本研究探索了一种新的攻击途径，利用大型语言模型（LLMs）生成对抗性语音网络钓鱼转录文本，这些文本既能逃避检测又能保持欺骗意图。研究构建了一个系统的攻击管道，采用提示工程和语义混淆技术，使用四种商业LLMs转换真实的网络钓鱼脚本。生成的转录文本通过统计测试，针对在真实韩国语音网络钓鱼数据集（KorCCViD）上训练的多个ML分类器进行评估。

**Result:** 实验表明，LLM生成的转录文本对基于ML的分类器具有实际和统计上的有效性。特别是，由GPT-4o制作的转录文本显著降低了分类器准确率（高达30.96%），同时保持了高语义相似性（由BERTScore衡量）。此外，这些攻击既省时又经济，平均生成时间不到9秒，每次查询的财务成本可忽略不计。

**Conclusion:** 研究结果强调了对更具弹性的语音网络钓鱼检测框架的迫切需求，并突出了LLM提供商在对抗性社会工程环境中加强提示滥用防护的必要性。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLMs）生成对抗性语音网络钓鱼（vishing）转录文本的新型攻击方法，旨在规避现有的机器学习（ML）分类器检测。研究构建了一个攻击管道，通过提示工程和语义混淆，使用四种商业LLMs转换真实钓鱼脚本，并在韩国数据集上测试其有效性。结果显示，LLM生成的脚本能显著降低ML分类器准确率，特别是GPT-4o，且攻击成本低、效率高。研究强调了开发更强韧的vishing检测系统以及LLM提供商加强滥用防护的紧迫性。

> **摘要翻译:** 语音网络钓鱼（vishing）仍然是网络安全中一个持续存在的威胁，它通过有说服力的言语利用人类信任。虽然基于机器学习（ML）的分类器在检测恶意通话记录方面显示出前景，但它们仍然容易受到保留语义内容的对抗性操纵。在这项研究中，我们探索了一种新颖的攻击向量，即利用大型语言模型（LLMs）生成对抗性语音网络钓鱼转录文本，这些文本既能逃避检测又能保持欺骗意图。我们构建了一个系统的攻击管道，该管道采用提示工程和语义混淆技术，使用四种商业LLMs转换真实的语音网络钓鱼脚本。生成的转录文本通过统计测试，针对在真实韩国语音网络钓鱼数据集（KorCCViD）上训练的多个ML分类器进行评估。我们的实验表明，LLM生成的转录文本对基于ML的分类器既实际又统计上有效。特别是，由GPT-4o制作的转录文本显著降低了分类器准确率（高达30.96%），同时保持了高语义相似性（由BERTScore衡量）。此外，这些攻击既省时又经济，平均生成时间不到9秒，每次查询的财务成本可忽略不计。结果强调了对更具弹性的语音网络钓鱼检测框架的迫切需求，并突出了LLM提供商在对抗性社会工程环境中加强提示滥用防护的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [365] [DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling](https://arxiv.org/abs/2507.16329)
> *DREAM：通过分布建模对文本到图像生成系统进行可扩展的红队攻击*

*Boheng Li, Junjie Wang, Yiming Li, Zhiyang Hu, Leyi Qi, Jianshuo Dong, Run Wang, Han Qiu, Zhan Qin, Tianwei Zhang* | **Category: cs.CR, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 红队攻击, 文本到图像生成, 安全性, 分布建模, 有害内容

**Comment:** Preprint version. Under review

> **TL;DR:** DREAM是一个可扩展的红队框架，通过直接建模有害提示的概率分布，有效发现文本到图像生成系统中的多样化问题提示，显著优于现有方法。

**AI_Comments:** DREAM的创新之处在于其将红队攻击从孤立的提示优化任务提升到对问题提示分布的建模，这显著提升了发现有害提示的可扩展性和多样性。通过引入基于能量模型和GC-SPSA算法，解决了在复杂T2I管道中进行高效优化的挑战。这项工作对于提高文本到图像生成模型的安全性具有重要意义，尤其是在其广泛部署之前。

<details>
  <summary>Details</summary>

**Motivation:** 尽管集成了安全对齐和外部过滤器，文本到图像（T2I）生成模型仍易于产生有害内容，引发了意外暴露和潜在滥用的严重担忧。现有的自动化红队方法通常将提示发现视为孤立的、提示级别的优化任务，这限制了它们的可扩展性、多样性和整体有效性。

**Method:** 本文提出了DREAM，一个可扩展的红队框架，通过直接建模目标系统问题提示的概率分布来实现对有效性和多样性的显式优化，并在训练后实现高效的大规模采样。为了在无法直接访问代表性训练样本的情况下实现这一点，DREAM借鉴了基于能量模型，并将目标重新表述为简单且易于处理的目标。此外，DREAM引入了GC-SPSA，一种高效的优化算法，通过漫长且可能不可微分的T2I管道提供稳定的梯度估计。

**Result:** DREAM的有效性通过广泛的实验得到验证，结果表明，在广泛的T2I模型和安全过滤器上，DREAM在提示成功率和多样性方面以显著优势超越了9个最先进的基线。

**Conclusion:** DREAM提供了一种可扩展且有效的方法，通过直接建模问题提示的分布来对文本到图像生成系统进行红队攻击，显著提高了识别有害内容生成提示的能力和多样性。

> **ai_Abstract:** 本文提出了DREAM，一个用于文本到图像（T2I）生成系统的可扩展红队框架，旨在自动发现多样化的有害提示。与现有单独优化提示的方法不同，DREAM通过直接建模问题提示的概率分布，实现了对有效性和多样性的显式优化，并支持高效的大规模采样。该框架借鉴了基于能量模型，并将目标重新表述为可处理的形式，并引入了GC-SPSA算法来处理T2I管道的复杂性。实验证明，DREAM在提示成功率和多样性方面显著优于9个最先进的基线，有效提升了T2I系统的安全评估能力。

> **摘要翻译:** 尽管集成了安全对齐和外部过滤器，文本到图像（T2I）生成模型仍然容易产生有害内容，例如色情或暴力图像。这引发了对意外暴露和潜在滥用的严重担忧。红队攻击旨在主动识别能够从T2I系统（包括核心生成模型以及潜在的外部安全过滤器和其他处理组件）引出不安全输出的各种提示，越来越被认为是实际部署前评估和提高安全性的重要方法。然而，现有的自动化红队方法通常将提示发现视为孤立的、提示级别的优化任务，这限制了它们的可扩展性、多样性和整体有效性。为了弥补这一差距，本文提出了DREAM，一个可扩展的红队框架，以自动发现给定T2I系统中的各种问题提示。与大多数单独优化提示的现有工作不同，DREAM直接建模目标系统问题提示的概率分布，这使得能够对有效性和多样性进行显式优化，并在训练后进行高效的大规模采样。为了在无法直接访问代表性训练样本的情况下实现这一点，我们从基于能量模型中汲取灵感，并将目标重新表述为简单且易于处理的目标。我们进一步引入了GC-SPSA，一种高效的优化算法，通过漫长且可能不可微分的T2I管道提供稳定的梯度估计。DREAM的有效性通过广泛的实验得到验证，结果表明，在广泛的T2I模型和安全过滤器上，它在提示成功率和多样性方面以显著优势超越了9个最先进的基线。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [371] [Depth Gives a False Sense of Privacy: LLM Internal States Inversion](https://arxiv.org/abs/2507.16372)
> *深度带来虚假隐私感：LLM内部状态反演*

*Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-22**

**Keywords:** LLM隐私, 内部状态反演, 数据重建, 隐私攻击, 大型语言模型

**Comment:** Accepted by USENIX Security 2025. Please cite this paper as "Tian
  Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives
  a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX
  Security Symposium (USENIX Security '25)."

> **TL;DR:** 本研究挑战了LLM内部状态不可逆的假设，提出了四种反演攻击，可以从LLM的内部状态中高效重建输入，揭示了LLM的隐私漏洞，并发现现有防御措施无法完全阻止这种反演。

**AI_Comments:** 这篇论文创新性地挑战了LLM内部状态的“不可逆”假设，揭示了LLM在协作推理和安全审计场景下的严重隐私风险。其提出的四种反演攻击，特别是对长文本的高效反演能力，证明了即使是深层内部状态也可能泄露敏感信息。这对于LLM的部署和隐私保护具有重要意义，提醒业界需要重新审视并加强LLM的隐私防御机制。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）日益融入日常生活，但引发了严重的隐私和安全问题。最近的研究提出了协作推理和基于内部神经模式的模型安全审计，这两种技术都暴露了LLM的内部状态（ISs）。传统上认为，由于优化挑战和深层中高度抽象的表示，这些内部状态对输入是不可逆的。本研究挑战了这一假设，旨在揭示LLM内部状态的隐私风险。

**Method:** 本研究提出了四种反演攻击来重建LLM的输入：
1. 两种白盒优化攻击：针对低深度和高深度内部状态，采用两阶段反演过程以避免局部最优。
2. 黑盒优化攻击扩展：利用源LLM和派生LLM之间的可迁移性，在更实际的黑盒权重访问下进行。
3. 生成式攻击：将反演视为翻译任务，使用反演模型重建输入。

**Result:** 研究对来自医疗咨询和编码辅助数据集的短提示和长提示以及6个LLM进行了广泛评估，验证了反演攻击的有效性。值得注意的是，一个4,112个token长的医疗咨询提示可以从Llama-3模型的中间层以86.88 F1的token匹配率几乎完美地反演。此外，研究评估了四种实用防御措施，发现它们无法完美阻止内部状态反演。

**Conclusion:** 本研究的结论是，LLM的内部状态并非不可逆，通过提出的反演攻击可以高效地重建原始输入。现有的防御措施无法完美阻止内部状态反演，这表明未来需要设计更有效的缓解策略来解决LLM的隐私问题。

> **ai_Abstract:** 本研究揭示了大型语言模型（LLM）内部状态的隐私漏洞。传统观点认为LLM的内部状态对于输入是不可逆的，但本研究通过提出四种新型反演攻击（包括白盒优化、黑盒扩展和生成式攻击）挑战了这一假设。实验证明，这些攻击能从LLM的内部状态中高效重建原始输入，甚至能从Llama-3的中间层几乎完美地反演一个4,112个token的医疗咨询提示。研究还评估了现有防御措施，发现它们无法完全阻止这种反演，强调了未来在LLM隐私保护方面需要更强大的缓解策略。

> **摘要翻译:** 大型语言模型（LLM）日益融入日常生活，但引发了严重的隐私和安全问题。最近的研究提出了协作推理，该技术将早期层推理外包以确保数据局部性，并引入了基于内部神经模式的模型安全审计。这两种技术都暴露了LLM的内部状态（ISs），由于优化挑战和深层中高度抽象的表示，这些状态传统上被认为是不可逆的。在这项工作中，我们通过提出四种反演攻击来挑战这一假设，这些攻击显著提高了反演输入的语义相似性和token匹配率。具体来说，我们首先开发了两种白盒优化攻击，专为低深度和高深度ISs设计。这些攻击通过两阶段反演过程，避免了先前工作中观察到的局部最优收敛问题。然后，我们通过利用源LLM和派生LLM之间的可迁移性，在更实际的黑盒权重访问下扩展了我们的优化攻击。此外，我们引入了一种生成式攻击，将反演视为翻译任务，采用反演模型来重建输入。对医疗咨询和编码辅助数据集中的短提示和长提示以及6个LLM进行的广泛评估验证了我们反演攻击的有效性。值得注意的是，一个4,112个token长的医疗咨询提示可以从Llama-3模型的中间层以86.88 F1的token匹配率几乎完美地反演。最后，我们评估了四种实用防御措施，发现它们无法完美阻止ISs反演，并为未来的缓解设计得出了结论。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [377] [Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks](https://arxiv.org/abs/2507.16540)
> *使用边缘感知图注意力网络在C/C++中进行可解释的漏洞检测*

*Radowanul Haque, Aftab Ali, Sally McClean, Naveed Khan* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 漏洞检测, 图注意力网络, C/C++, 可解释性, 代码属性图

**Comment:** 

> **TL;DR:** ExplainVulD是一个基于图的框架，用于C/C++代码的漏洞检测，它利用边缘感知图注意力网络和双通道嵌入，解决了类别不平衡问题，并提供了可解释的结果，性能优于现有方法。

**AI_Comments:** ExplainVulD的创新点在于结合了边缘感知图注意力网络和双通道嵌入，有效利用了代码的语义和结构信息。其解决了漏洞检测中常见的类别不平衡问题，并通过提供可解释的输出，显著提升了模型在实际安全工作流程中的实用性和可信度。性能提升明显，特别是在F1分数上超越了现有方法和静态分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 在C/C++源代码中检测安全漏洞仍然具有挑战性，特别是因为实际数据集中漏洞函数类别不平衡，导致现有方法召回率高但误报率也高，且缺乏可解释性，限制了它们在开发和安全工作流程中的集成。

**Method:** 本文提出了ExplainVulD，一个基于图的C/C++代码漏洞检测框架。该方法构建代码属性图，并使用捕获语义和结构信息的双通道嵌入来表示节点。这些节点通过一个边缘感知注意力机制处理，该机制结合了边缘类型嵌入以区分程序关系。为了解决类别不平衡问题，模型使用类别加权交叉熵损失进行训练。

**Result:** ExplainVulD在ReVeal数据集上进行了30次独立运行，实现了88.25%的平均准确率和48.23%的F1分数。与ReVeal模型（一种先前的基于学习的方法）相比，准确率相对提高了4.6%，F1分数相对提高了16.9%。该框架还优于静态分析工具，准确率相对提高了14.0%至14.1%，F1分数相对提高了132.2%至201.2%。

**Conclusion:** ExplainVulD不仅提高了漏洞检测性能，还通过识别每个函数中最具影响力的代码区域来生成可解释的输出，从而支持安全分类中的透明度和信任。

> **ai_Abstract:** 本文介绍了ExplainVulD，一个用于C/C++代码可解释漏洞检测的图基框架。该框架通过构建代码属性图并利用结合语义和结构信息的双通道嵌入以及边缘感知注意力机制来识别程序关系。为解决类别不平衡问题，模型采用类别加权交叉熵损失进行训练。ExplainVulD在ReVeal数据集上表现出色，相较于现有学习模型和静态分析工具，在准确率和F1分数上均有显著提升，并且能够提供可解释的检测结果，增强了安全漏洞分析的透明度和信任度。

> **摘要翻译:** 检测源代码中的安全漏洞仍然具有挑战性，尤其是在实际数据集中漏洞函数代表性不足的类别不平衡问题。现有的基于学习的方法通常优化召回率，导致高误报率并降低在开发工作流程中的可用性。此外，许多方法缺乏可解释性，限制了它们与安全工作流程的集成。本文提出了ExplainVulD，一个用于C/C++代码漏洞检测的基于图的框架。该方法构建代码属性图，并使用捕获语义和结构信息的双通道嵌入来表示节点。这些节点通过一个边缘感知注意力机制处理，该机制结合了边缘类型嵌入以区分程序关系。为了解决类别不平衡问题，模型使用类别加权交叉熵损失进行训练。ExplainVulD在ReVeal数据集上进行了30次独立运行，实现了88.25%的平均准确率和48.23%的F1分数。这些结果与ReVeal模型（一种先前的基于学习的方法）相比，准确率相对提高了4.6%，F1分数相对提高了16.9%。该框架还优于静态分析工具，准确率相对提高了14.0%至14.1%，F1分数相对提高了132.2%至201.2%。除了改进的检测性能外，ExplainVulD通过识别每个函数中最具影响力的代码区域来生成可解释的输出，从而支持安全分类中的透明度和信任。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [389] [From Text to Actionable Intelligence: Automating STIX Entity and Relationship Extraction](https://arxiv.org/abs/2507.16576)
> *从文本到可操作情报：自动化STIX实体和关系提取*

*Ahmed Lekssays, Husrev Taha Sencar, Ting Yu* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** STIX, 威胁情报, 实体关系提取, 大型语言模型, 自动化

**Comment:** This paper is accepted at RAID 2025

> **TL;DR:** 本文介绍AZERG工具，通过适应大型语言模型并进行任务特定微调，从非结构化安全文本中自动提取STIX格式的威胁情报，并在真实场景中取得了显著的性能提升。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于STIX威胁情报的自动化提取，并通过任务分解和特定微调有效处理了这一复杂问题。特别值得注意的是，为解决训练数据稀缺问题，研究团队构建了一个大规模的、符合STIX标准的数据集，这对于推动该领域的研究具有重要意义。该工具的提出有望显著提高安全分析师的工作效率和威胁情报共享的及时性，对于构建更强大的防御系统具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 威胁分析报告在支持安全运营和对抗新兴威胁方面发挥着关键作用，但从非结构化安全文本生成STIX兼容数据仍是一个主要依靠人工、专家驱动的过程。为了解决这一挑战，提高威胁情报共享的及时性和自动化程度，需要一种工具来自动化STIX实体和关系提取。

**Method:** 研究人员引入了一个名为AZERG的工具，旨在帮助安全分析师自动生成结构化的STIX表示。为此，他们将通用大型语言模型（LLMs）应用于提取STIX格式威胁数据的特定任务。为了管理复杂性，任务被分解为四个子任务：实体检测（T1）、实体类型识别（T2）、相关对检测（T3）和关系类型识别（T4）。他们应用了任务特定的微调来准确提取相关实体并根据STIX规范推断其关系。为解决训练数据不足的问题，他们从141份完整的威胁分析报告中编译了一个包含4,011个实体和2,075个关系的综合数据集，所有数据均按照STIX标准进行标注。

**Result:** 在真实场景中，模型在T1（实体检测）上取得了84.43%的F1分数，T2（实体类型识别）上取得了88.49%的F1分数，T3（相关对检测）上取得了95.47%的F1分数，T4（关系类型识别）上取得了84.60%的F1分数。与一系列开放和封闭参数模型以及最先进的方法相比，模型在各项任务中展示了2-25%的性能提升。

**Conclusion:** 本文提出的AZERG工具通过利用大型语言模型并进行任务特定微调，成功实现了从非结构化安全文本中自动化STIX实体和关系提取，并在各项任务中取得了显著的性能提升，有效解决了现有STIX数据生成过程中人工依赖的挑战。

> **ai_Abstract:** 本文提出名为AZERG的工具，旨在解决从非结构化安全文本中手动生成STIX兼容威胁情报的挑战。该工具通过将通用大型语言模型适应于特定的STIX实体和关系提取任务，并将任务分解为四个子任务（实体检测、实体类型识别、相关对检测、关系类型识别），并进行任务特定的微调。为弥补数据不足，研究者构建了一个包含大量实体和关系标注的新数据集。实验结果表明，AZERG模型在真实场景下取得了高F1分数，并在与现有方法的比较中表现出显著的性能提升，从而实现了威胁情报的自动化和及时性。

> **摘要翻译:** 分享攻击方法及其有效性是构建强大防御系统的基石。由各种个人和组织制作的威胁分析报告，在支持安全运营和对抗新兴威胁方面发挥着关键作用。为了提高威胁情报共享的及时性和自动化程度，已经建立了多种标准，其中结构化威胁信息表达（STIX）框架成为最广泛采用的标准之一。然而，从非结构化安全文本生成STIX兼容数据仍然是一个主要依靠人工、专家驱动的过程。为了解决这一挑战，我们引入了AZERG，一个旨在协助安全分析师自动生成结构化STIX表示的工具。为此，我们调整了通用大型语言模型，使其适用于提取STIX格式威胁数据的特定任务。为了管理复杂性，任务被分为四个子任务：实体检测（T1）、实体类型识别（T2）、相关对检测（T3）和关系类型识别（T4）。我们应用了任务特定的微调，以准确提取相关实体并根据STIX规范推断其关系。为了解决训练数据不足的问题，我们编译了一个综合数据集，其中包含从141份完整威胁分析报告中提取的4,011个实体和2,075个关系，所有这些都按照STIX标准进行了标注。在真实场景中，我们的模型在T1上取得了84.43%的F1分数，T2上取得了88.49%的F1分数，T3上取得了95.47%的F1分数，T4上取得了84.60%的F1分数。我们针对一系列开放和封闭参数模型以及最先进的方法验证了它们的性能，结果显示在各项任务中性能提升了2-25%。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [400] [LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models](https://arxiv.org/abs/2507.16585)
> *LLMxCPG：通过代码属性图引导的大型语言模型实现上下文感知漏洞检测*

*Ahmed Lekssays, Hamza Mouhcine, Khang Tran, Ting Yu, Issa Khalil* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 漏洞检测, 代码属性图, 大型语言模型, 上下文感知, 软件安全

**Comment:** This paper is accepted at USENIX 2025

> **TL;DR:** LLMxCPG是一个新颖的框架，它将代码属性图（CPG）与大型语言模型（LLM）结合，通过上下文感知的方式，显著提高了软件漏洞检测的准确性和鲁棒性，特别是对于跨多个函数的漏洞。

**AI_Comments:** 该论文通过将代码属性图（CPG）与大型语言模型（LLM）相结合，创新性地解决了现有深度学习方法在漏洞检测中面临的上下文丢失和鲁棒性不足的问题。CPG引导的切片构建技术是其核心创新点，它有效地降低了LLM的输入复杂性，同时保留了关键的语义信息。该方法在处理多函数漏洞和应对代码修改方面的表现尤为突出，对提升自动化漏洞检测的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度学习漏洞检测方法在准确性和鲁棒性方面存在严重局限，例如在严格验证的数据集上准确率下降高达45%，并且在简单的代码修改下性能显著下降。此外，现有方法难以有效处理大型代码段和跨函数漏洞。

**Method:** 本文提出了LLMxCPG框架，该框架将代码属性图（CPG）与大型语言模型（LLM）相结合。通过基于CPG的切片构建技术，将代码大小减少了67.84%到90.93%，同时保留了与漏洞相关的上下文。这种简洁的代码表示能够分析更大的代码段，包括整个项目，并识别跨多个函数的漏洞。

**Result:** LLMxCPG在经过验证的数据集上表现出卓越的有效性，与最先进的基线相比，F1分数提高了15-40%。此外，LLMxCPG在函数级和多函数代码库中均保持了高性能，并在各种语法代码修改下展现出强大的检测效力。

**Conclusion:** LLMxCPG通过集成代码属性图和大型语言模型，并利用CPG引导的切片构建技术，显著提升了漏洞检测的准确性和鲁棒性，尤其是在处理大型、复杂代码库和应对代码修改方面，为软件安全领域带来了实质性改进。

> **ai_Abstract:** 本研究提出了LLMxCPG，一个结合代码属性图（CPG）和大型语言模型（LLM）的框架，旨在解决现有深度学习方法在软件漏洞检测中面临的准确性和鲁棒性问题。LLMxCPG利用CPG引导的切片构建技术，显著缩小代码体积并保留关键上下文，从而能够有效分析大型代码库和检测跨函数漏洞。实验结果表明，LLMxCPG在F1分数上比现有技术提高了15-40%，并在不同代码级别和代码修改下保持了高检测性能。

> **摘要翻译:** 软件漏洞是一个持续存在的安全挑战，仅2024年，通用漏洞披露（CVE）数据库中就报告了超过25,000个新漏洞。尽管基于深度学习的方法在漏洞检测方面显示出前景，但最近的研究揭示了其在准确性和鲁棒性方面的严重局限：在严格验证的数据集上，准确率下降高达45%，并且在简单的代码修改下性能显著下降。本文提出了LLMxCPG，一个将代码属性图（CPG）与大型语言模型（LLM）集成的新颖框架，用于鲁棒的漏洞检测。我们基于CPG的切片构建技术将代码大小减少了67.84%到90.93%，同时保留了与漏洞相关的上下文。我们方法提供更简洁、准确的代码片段表示的能力，使得能够分析更大的代码段，包括整个项目。这种简洁的表示是我们方法检测能力提高的关键因素，因为它现在可以识别跨多个函数的漏洞。实证评估表明，LLMxCPG在经过验证的数据集上表现出有效性，F1分数比最先进的基线提高了15-40%。此外，LLMxCPG在函数级和多函数代码库中均保持了高性能，并在各种语法代码修改下展现出鲁棒的检测效力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [413] [When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](https://arxiv.org/abs/2507.16773)
> *当LLM复制思考时：揭示推理LLM中的复制引导攻击*

*Yue Li, Xiao Li, Hao Wu, Yue Zhang, Fengyuan Xu, Xiuzhen Cheng, Sheng Zhong* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** LLM, 复制引导攻击, 提示攻击, 代码分析, 漏洞

**Comment:** 

> **TL;DR:** LLM在代码分析中存在一种新的提示攻击，称为复制引导攻击 (CGA)，通过注入触发器使LLM复制恶意内容，导致推理长度或结果被操纵。

**AI_Comments:** 这篇论文揭示了LLM在推理过程中一个新颖且关键的漏洞——复制引导攻击。其创新之处在于识别了LLM固有的复制倾向作为攻击面，并将其形式化为优化问题。论文的重要性在于暴露了LLM驱动开发管道中的潜在风险，并强调了开发更强健的提示级防御机制的紧迫性。其局限性在于CGA在泛化到不同提示时面临计算约束，这为未来的研究留下了开放性问题。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型 (LLM) 已成为自动化代码分析不可或缺的一部分，但它们的集成引入了新的攻击面。本文旨在识别并调查一种新型的基于提示的攻击，即复制引导攻击 (CGA)，该攻击利用了推理LLM固有的复制倾向。

**Method:** 本文识别并研究了一种新型提示攻击，即复制引导攻击 (CGA)。研究将CGA形式化为一个优化问题，并提出了一种基于梯度的触发器合成方法。通过在最先进的推理LLM上进行实证评估来验证其有效性。

**Result:** 实证评估表明，复制引导攻击 (CGA) 能够可靠地诱导LLM在代码分析任务中产生无限循环、过早终止、虚假拒绝和语义扭曲。尽管在目标设置中非常有效，但由于计算约束，CGA在跨不同提示泛化时面临挑战。

**Conclusion:** 本文揭示了LLM驱动开发管道中一个关键但未充分探索的漏洞，并呼吁紧急推进提示级防御机制。

> **ai_Abstract:** 本文识别并研究了一种针对推理LLM的新型提示攻击，称为复制引导攻击 (CGA)。CGA利用LLM的复制倾向，通过注入触发器诱导模型在代码分析任务中复制恶意内容，从而操纵推理长度或结果。研究将CGA形式化为优化问题，并提出了一种基于梯度的触发器合成方法。实证结果表明CGA能有效导致LLM产生错误行为，尽管其泛化能力受计算限制。研究强调了LLM驱动开发中未被充分探索的漏洞，并呼吁加强防御机制。

> **摘要翻译:** 大型语言模型 (LLM) 已成为自动化代码分析不可或缺的一部分，能够实现漏洞检测和代码理解等任务。然而，它们的集成引入了新的攻击面。在本文中，我们识别并研究了一种新型的基于提示的攻击，称为复制引导攻击 (CGA)，它利用了具有推理能力的LLM固有的复制倾向。通过向外部代码片段注入精心制作的触发器，攻击者可以在推理过程中诱导模型复制恶意内容。这种行为导致两类漏洞：推理长度操纵，即模型生成异常短或过长的推理轨迹；以及推理结果操纵，即模型产生误导性或不正确的结论。我们将CGA形式化为一个优化问题，并提出了一种基于梯度的方法来合成有效的触发器。对最先进的推理LLM的实证评估表明，CGA在代码分析任务中可靠地诱导了无限循环、过早终止、虚假拒绝和语义扭曲。虽然在目标设置中非常有效，但我们观察到由于计算限制，CGA在跨不同提示泛化方面存在挑战，这为未来的研究提出了一个开放性问题。我们的发现揭示了LLM驱动开发管道中一个关键但尚未充分探索的漏洞，并呼吁紧急推进提示级防御机制。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [431] [AUTOPSY: A Framework for Tackling Privacy Challenges in the Automotive Industry](https://arxiv.org/abs/2507.16788)
> *AUTOPSY：一个解决汽车行业隐私挑战的框架*

*Sebastian Pape, Anis Bkakria, Maurice Heymann, Badreddine Chah, Abdeljalil Abbas-Turki, Sarah Syed-Winkler, Matthias Hiller, Reda Yaich* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 汽车隐私, GDPR, 隐私增强技术, 隐私工程, 数据流控制

**Comment:** 19 pages, 4 figures

> **TL;DR:** 该论文介绍了AUTOPSY项目，一个为汽车行业提供技术构建模块以增强互联和自动化车辆隐私友好性的框架，旨在超越GDPR合规性。

**AI_Comments:** 该论文解决了汽车行业中一个日益重要的问题，即在互联和自动化车辆背景下的数据隐私。其创新之处在于不仅仅关注GDPR合规性，而是通过提供具体的技术构建模块来实际提升隐私友好性。通过系统模型、隐私管理器和PET选择方法的结合，该框架提供了一个全面的方法论，对于未来的汽车隐私工程具有重要意义。演示器的构建也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GDPR已实施，但合规性不一定能带来隐私友好的系统（例如，用户同意不提高隐私友好性）。因此，AUTOPSY项目的目标是通过提供技术构建模块，支持汽车领域的隐私工程过程，以提高现代互联和（部分）自动化车辆的隐私友好性。

**Method:** AUTOPSY项目通过提供以下构建模块来支持隐私工程过程：一个识别相关实体和位置以应用隐私增强技术（PETs）的系统模型；一个旨在更好地控制车辆数据流的隐私管理器；一个基于GDPR原则的PET选择方法；以及一个汽车隐私的架构框架。此外，还构建了一个基于位置服务的演示器来评估该架构框架。

**Result:** AUTOPSY项目的结果包括：一个用于识别应用PETs的相关实体和位置的系统模型；一个旨在更好地控制车辆数据流的隐私管理器；一个基于GDPR原则的PET选择方法；以及一个汽车隐私的架构框架。此外，还构建了一个基于位置服务的演示器用于评估该框架。

**Conclusion:** AUTOPSY项目成功开发了一个全面的框架，包括系统模型、隐私管理器、PET选择方法和架构框架，以技术性地提升现代汽车的隐私友好性，超越了单纯的GDPR合规性。

> **ai_Abstract:** 本文介绍了AUTOPSY项目，旨在解决汽车行业中的隐私挑战，超越GDPR的单纯合规性。该项目开发了一个全面的框架，包括一个识别隐私增强技术（PETs）应用点的系统模型、一个用于数据流控制的隐私管理器、一个基于GDPR原则的PET选择方法，以及一个汽车隐私的架构框架。通过构建这些技术构建模块，AUTOPSY旨在显著提高现代互联和自动化车辆的隐私友好性，并通过一个基于位置服务的演示器进行了评估。

> **摘要翻译:** 随着通用数据保护条例（GDPR）的实施，所有领域都必须确保遵守隐私立法。然而，合规性不一定能带来隐私友好的系统，例如，获取用户同意处理其数据并不能提高系统的隐私友好性。因此，AUTOPSY项目的目标是通过提供若干技术上提高现代（即互联和（部分）自动化）车辆隐私友好性的构建模块，来支持汽车领域的隐私工程过程。本文介绍了AUTOPSY项目的结果：一个用于识别应用隐私增强技术（PETs）的相关实体和位置的系统模型；一个旨在更好地控制车辆数据流的隐私管理器；一个基于GDPR原则的PET选择方法；以及一个汽车隐私的架构框架。此外，我们还为基于位置的服务构建了一个演示器，以评估该架构框架。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [568] [Defense Against Prompt Injection Attack by Leveraging Attack Techniques](https://arxiv.org/abs/2411.00459)
> *利用攻击技术防御提示注入攻击*

*Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song, Dekai Wu, Bryan Hooi* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 提示注入攻击, 大语言模型, 防御, 无训练方法, 攻击技术利用

**Comment:** To Appear in ACL 2025

> **TL;DR:** 本文提出一种新颖的防御提示注入攻击的方法，通过反转现有的攻击技术，并证明其优于现有无训练防御方法。

**AI_Comments:** 本文的创新之处在于其“以彼之道还施彼身”的防御理念，即利用攻击技术来构建防御机制。这种逆向思维不仅新颖，而且在实践中取得了SOTA效果，为LLM安全防御提供了新的视角和有效途径。其无训练的特性也降低了部署成本。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）虽然性能卓越，但存在提示注入攻击等新漏洞，攻击者能诱导LLMs偏离原始指令执行恶意指令，且当前攻击方法成功率高。

**Method:** 通过反转提示注入攻击方法的意图，基于之前的无训练攻击方法开发新的防御方法，即重复攻击过程但使用原始输入指令而非注入指令。

**Result:** 综合实验表明，所提出的防御技术优于现有无训练防御方法，达到了最先进的水平。

**Conclusion:** 本文成功地将提示注入攻击技术反向应用于防御目的，并取得了优异的防御效果，证明了攻击与防御之间存在相似的设计目标，并可相互借鉴。

> **ai_Abstract:** 本文针对大语言模型（LLMs）面临的提示注入攻击问题，提出了一种创新的防御策略。研究发现攻击与防御方法在设计目标上存在相似性，即控制模型指令执行。基于此洞察，作者将现有的无训练攻击技术反向应用于防御，通过重复攻击过程但强调原始指令来抵御注入。实验结果表明，该方法在防御效果上超越了现有无训练防御方案，达到了先进水平。

> **摘要翻译:** 随着技术的进步，大型语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了卓越的性能，为像Microsoft Copilot这样的LLM集成应用提供了支持。然而，随着LLMs的不断发展，新的漏洞，特别是提示注入攻击，也随之出现。这些攻击通过欺骗LLMs偏离原始输入指令，转而执行注入在数据内容（如检索结果）中的攻击者指令。最近的攻击方法利用了LLMs的指令遵循能力以及它们无法区分数据内容中注入指令的缺陷，并实现了高攻击成功率（ASR）。在比较攻击和防御方法时，我们有趣地发现它们共享相似的设计目标，即诱导模型忽略不需要的指令并执行需要的指令。因此，我们提出了一个直观的问题：这些攻击技术能否用于防御目的？在本文中，我们反转了提示注入方法的意图，基于先前的无训练攻击方法开发了新颖的防御方法，通过重复攻击过程但使用原始输入指令而非注入指令。我们的综合实验表明，我们的防御技术优于现有的无训练防御方法，取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [599] [Differentially Private Set Representations](https://arxiv.org/abs/2501.16680)
> *差分隐私集合表示*

*Sarvar Patel, Giuseppe Persiano, Joon Young Seo, Kevin Yeo* | **Category: cs.CR, cs.DS** | **Updated: 2025-07-22**

**Keywords:** 差分隐私, 集合表示, 隐私-效用权衡, 随机线性系统, 空间下界

**Comment:** Appears at NeurIPS 2024

> **TL;DR:** 研究差分隐私集合表示机制，提出两种新算法，在空间、构建和解码时间上具有良好性能，并匹配了理论下界。

**AI_Comments:** 本文的创新点在于提出了将集合嵌入随机线性系统的新方法，这与传统向非私有解决方案注入噪声的方法不同，为差分隐私集合表示提供了一条新路径。其重要性体现在算法在隐私-效用权衡和空间效率上达到了理论下界，证明了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 研究从大型宇宙中表示大小为k的集合的差分隐私（DP）机制问题。

**Method:** 提出了两种差分隐私集合表示算法。第一种是$(\epsilon,\delta)$-DP机制，通过将集合嵌入随机线性系统来实现，这与以往向非私有解决方案注入噪声的方法不同。第二种是纯$\epsilon$-DP机制。

**Result:** 第一种算法：生成$(\epsilon,\delta)$-DP表示，错误概率为$1/(e^\epsilon + 1)$，空间至多$1.05 k \epsilon \cdot \log(e)$比特，构建时间$O(k \log(1/\delta))$，解码时间$O(\log(1/\delta))$。第二种算法：生成纯$\epsilon$-DP表示，相同错误概率，空间至多$k \epsilon \cdot \log(e)$比特，但解码时间较长。算法在隐私-效用权衡方面（包括常数，忽略$\delta$因子）匹配了理论下界。提出了一个新的空间下界，与所提出的构造在小常数因子内匹配。

**Conclusion:** 本文设计了两种差分隐私集合表示算法，在隐私-效用权衡和空间效率方面达到了理论最优，并通过一种将集合嵌入随机线性系统的新方法实现了这些结果。

> **ai_Abstract:** 本文研究了差分隐私（DP）机制下的集合表示问题。作者提出了两种新算法，分别用于$(\epsilon,\delta)$-DP和纯$\epsilon$-DP表示。这些算法在错误概率、空间效率以及构建和解码时间方面表现出色，并被证明在隐私-效用权衡和空间效率上达到了理论下界。其核心创新在于采用了一种将集合嵌入随机线性系统的新方法，而非传统的噪声注入方式。

> **摘要翻译:** 我们研究了从大型宇宙中表示大小为k的集合的差分隐私（DP）机制问题。我们的第一个构造创建了$(\epsilon,\delta)$-DP表示，其错误概率为$1/(e^\epsilon + 1)$，使用的空间至多为$1.05 k \epsilon \cdot \log(e)$比特，其中构建表示的时间为$O(k \log(1/\delta))$，而解码时间为$O(\log(1/\delta))$。我们还提出了第二种算法，用于纯$\epsilon$-DP表示，具有相同的错误，使用的空间至多为$k \epsilon \cdot \log(e)$比特，但需要较长的解码时间。我们的算法匹配了我们关于隐私-效用权衡的下界（包括常数，但忽略$\delta$因子），并且我们还提出了一个新的空间下界，与我们的构造在小常数因子内匹配。为了获得我们的结果，我们设计了一种将集合嵌入随机线性系统的新方法，这与大多数先前的向非私有解决方案注入噪声的方法不同。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [629] [Recent Advances in Malware Detection: Graph Learning and Explainability](https://arxiv.org/abs/2502.10556)
> *恶意软件检测的最新进展：图学习与可解释性*

*Hossein Shokouhinejad, Roozbeh Razavi-Far, Hesamodin Mohammadian, Mahdi Rabbani, Samuel Ansong, Griffin Higgins, Ali A Ghorbani* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 恶意软件检测, 图学习, 可解释性, 图神经网络, 网络安全

**Comment:** 

> **TL;DR:** 本调查回顾了恶意软件检测的最新进展，重点关注图学习技术和可解释性，涵盖了分析技术、数据集、特征工程以及未来的研究方向。

**AI_Comments:** 这是一篇及时的综述性论文，聚焦于快速演进的恶意软件检测领域中的先进技术（图学习）和关键方面（可解释性）。其涵盖从基础到未来方向的全面范围，使其成为一份宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 由于恶意软件的快速演变，传统的基于签名的检测方法已不足以应对，因此需要开发更复杂的检测方法。

**Method:** 本调查全面探讨了恶意软件检测的最新进展，重点关注图学习和可解释性。它回顾了恶意软件分析技术、数据集、特征工程、图约减和图嵌入方法，并讨论了可解释性技术及其应用。

**Result:** 本调查展示了图学习和可解释性如何有助于构建鲁棒、可解释和可扩展的恶意软件检测系统，并概述了未来的研究方向。

**Conclusion:** 图学习和可解释性对于构建鲁棒、可解释和可扩展的恶意软件检测系统至关重要，并且指出了未来的研究方向以应对挑战和发现新机遇。

> **ai_Abstract:** 本调查审视了恶意软件检测的最新进展，强调了图学习技术与可解释性的结合。它涵盖了恶意软件分析、数据集、特征工程、图方法（约减、嵌入）以及可解释性，展示了它们在构建鲁棒、可解释和可扩展的检测系统中的共同贡献，并概述了未来的研究方向。

> **摘要翻译:** 恶意软件的快速演变necessitated了超越传统基于签名的检测方法的复杂方法的开发。图学习技术已成为建模和分析恶意软件行为中固有复杂关系的强大工具，利用了图神经网络 (GNNs) 及相关方法的进展。本调查全面探讨了恶意软件检测的最新进展，重点关注图学习和可解释性之间的相互作用。它首先回顾了恶意软件分析技术和数据集，强调它们在理解恶意软件行为和支持检测策略方面的基础作用。该调查接着讨论了特征工程、图约减和图嵌入方法，强调它们在将原始数据转化为可操作洞察力、同时确保可伸缩性和效率方面的重要性。此外，本调查侧重于可解释性技术及其在恶意软件检测中的应用，以确保透明度和可信赖性。通过整合这些组件，本调查展示了图学习和可解释性如何有助于构建鲁棒、可解释和可扩展的恶意软件检测系统。概述了未来的研究方向，以应对现有挑战并在此关键的网络安全领域中开启新机遇。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [665] [Choosing Coordinate Forms for Solving ECDLP Using Shor's Algorithm](https://arxiv.org/abs/2502.12441)
> *选择坐标形式来使用Shor算法解决椭圆曲线离散对数问题（ECDLP）*

*Yan Huang, Fangguo Zhang, Fei Gao, Zijian Zhou, Longjiang Qu* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** Shor算法, 椭圆曲线离散对数问题, 坐标形式, 量子资源优化, 射影坐标

**Comment:** The primary concerns lie in the limited significance and novelty.
  While the paper explores the use of projective coordinates, quantum resource
  requirements are worse than those achieved with previously studied affine
  coordinates, as carefully documented in the manuscript

> **TL;DR:** 本研究发现，在使用Shor算法解决椭圆曲线离散对数问题（ECDLP）时，射影坐标不比仿射坐标具有优势。

**AI_Comments:** 该研究澄清了在Shor算法解决ECDLP时，不同坐标形式对量子资源优化的影响。它解决了射影坐标是否带来优势这一未解决的问题，指出仿射坐标在实践中可能更具优势，这对于未来Shor算法的实现和优化具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** Shor算法在解决椭圆曲线离散对数问题（ECDLP）方面具有多项式时间的能力，其量子资源的优化是研究的关键焦点。然而，射影坐标在量子资源优化中的应用仍是一个未解决的问题，主要是因为射影坐标的表示在不使用模除操作时缺乏唯一性。

**Method:** 本研究通过分析揭示了在利用Shor算法解决椭圆曲线离散对数问题（ECDLP）时，不同坐标形式的适用性。

**Result:** 研究结果表明，在使用Shor算法解决椭圆曲线离散对数问题（ECDLP）时，射影坐标不提供与仿射坐标相同的优势。

**Conclusion:** 结论是，在使用Shor算法解决椭圆曲线离散对数问题（ECDLP）时，射影坐标与仿射坐标相比没有表现出优势。

> **ai_Abstract:** 本研究关注Shor算法在解决椭圆曲线离散对数问题（ECDLP）时的量子资源优化。鉴于射影坐标在不使用模除操作时表示缺乏唯一性，其在量子资源优化中的应用一直未解。研究结果表明，在使用Shor算法解决ECDLP时，射影坐标相对于仿射坐标不具备相同的优势。

> **摘要翻译:** Shor算法以其在多项式时间内解决椭圆曲线离散对数问题（ECDLP）的能力而闻名。其量子资源的增强仍然是研究的关键焦点。然而，射影坐标在量子资源优化中的应用仍然是一个未解决的问题，这主要是因为射影坐标的表示在不使用模除操作时缺乏唯一性。我们的研究揭示，在使用Shor方法解决ECDLP时，射影坐标并未提供与仿射坐标相同的优势。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [695] [Can Indirect Prompt Injection Attacks Be Detected and Removed?](https://arxiv.org/abs/2502.16580)
> *间接提示注入攻击能否被检测和移除？*

*Yulin Chen, Haoran Li, Yuan Sui, Yufei He, Yue Liu, Yangqiu Song, Bryan Hooi* | **Category: cs.CR** | **Updated: 2025-07-22**

**Keywords:** 提示注入, 大型语言模型, 检测, 移除, 间接攻击

**Comment:** To Appear in ACL 2025

> **TL;DR:** 本文研究了大型语言模型中如何检测和移除间接提示注入攻击，通过构建基准数据集并评估多种检测与移除方法。

**AI_Comments:** 本文解决了大型语言模型安全领域中一个关键且未被充分探索的领域，即间接提示注入攻击的检测和移除。创建基准数据集对后续研究具有重要价值。同时关注检测和移除，使得本文的研究方法更为全面和实用。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）容易受到提示注入攻击，尤其间接提示注入攻击的研究较少，且现有工作主要关注检测而非检测后的缓解。本文旨在探究检测和移除间接提示注入攻击的可行性。

**Method:** 本文构建了一个用于评估的基准数据集。对于检测，评估了现有的大型语言模型和开源检测模型的性能，并使用自建的训练数据集训练了检测模型。对于移除，评估了两种直观方法：分段移除法（分割注入文档并移除包含注入指令的部分）和提取移除法（训练一个提取模型来识别并移除注入指令）。

**Result:** 未在摘要中提及

**Conclusion:** 未在摘要中提及

> **ai_Abstract:** 本文探讨了检测和移除大型语言模型（LLMs）中间接提示注入攻击的可行性。论文指出，当前研究主要集中在直接提示注入攻击的检测上，而对间接场景和检测后的缓解方法关注不足。为解决这一问题，作者构建了一个基准数据集，并评估了现有LLMs和开源检测模型的性能，同时训练了新的检测模型。对于移除，论文评估了分段移除和提取移除两种方法，旨在有效缓解攻击。

> **摘要翻译:** 提示注入攻击通过误导大型语言模型（LLMs）偏离原始输入指令并执行恶意注入的指令来操纵它们，这是因为LLMs具有遵循指令的能力，并且无法区分原始输入指令和恶意注入的指令。为了防御此类攻击，最近的研究开发了各种检测机制。如果我们特别限制于执行检测而非直接防御的工作，它们大多关注直接提示注入攻击，而针对间接场景（即注入指令间接来自外部工具，如搜索引擎）的工作很少。此外，当前的工作主要研究注入检测方法，而较少关注旨在检测后缓解注入的后处理方法。在本文中，我们研究了检测和移除间接提示注入攻击的可行性，并构建了一个用于评估的基准数据集。对于检测，我们评估了现有LLMs和开源检测模型的性能，并使用我们精心制作的训练数据集进一步训练了检测模型。对于移除，我们评估了两种直观方法：（1）分段移除法，该方法将注入的文档分段并移除包含注入指令的部分；（2）提取移除法，该方法训练一个提取模型来识别和移除注入的指令。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [707] [Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios](https://arxiv.org/abs/2507.15859)
> *去中心化AI驱动的物联网架构，用于疫情和重症监护场景下的隐私保护和延迟优化医疗保健*

*Harsha Sammangi, Aditya Jagatha, Giridhar Reddy Bojja, Jun Liu* | **Category: cs.CR, cs.AI** | **Updated: 2025-04-29**

**Keywords:** 去中心化物联网, 医疗保健, 隐私保护, 联邦学习, 区块链

**Comment:** 10 Pages

> **TL;DR:** 该研究提出一种去中心化AI驱动的物联网架构，利用联邦学习、区块链和边缘计算，解决中心化医疗系统中数据隐私和延迟问题，并在实验中表现优于传统云解决方案。

**AI_Comments:** 该论文提出了一种创新的去中心化AI驱动物联网架构，通过结合联邦学习、区块链和边缘计算，有效解决了医疗领域长期存在的隐私和延迟痛点。其在性能上的显著提升，预示着未来在疫情和重症监护等关键场景下，有望提供更安全、高效的医疗服务。该研究的创新点在于其多技术融合的系统级解决方案，为智慧医疗的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前的传统中心化医疗架构存在数据隐私、延迟和安全等诸多问题，尤其在疫情和重症监护场景下，这些问题对实时患者监测构成了挑战。

**Method:** 本文提出了一种AI赋能的去中心化物联网架构，旨在增强现有联邦学习、区块链和边缘计算方法的有效性，以最大化数据隐私、最小化延迟并改善其他通用系统指标。

**Result:** 实验结果表明，该架构在交易延迟、能耗和数据吞吐量方面比竞争性云解决方案低几个数量级。

**Conclusion:** 该去中心化AI驱动的物联网架构能有效解决中心化医疗系统中的隐私和延迟问题，并在性能上显著优于传统云解决方案，尤其适用于疫情和重症监护等关键医疗场景。

> **ai_Abstract:** 本文提出了一种AI驱动的去中心化物联网架构，旨在解决传统中心化医疗系统中数据隐私、延迟和安全等问题，特别是在疫情和重症监护场景下。该架构整合了联邦学习、区块链和边缘计算技术，以提升数据隐私、降低延迟并优化系统性能。实验结果显示，与现有云解决方案相比，该架构在交易延迟、能耗和数据吞吐量方面表现出显著优势。

> **摘要翻译:** AI在物联网中实现实时患者监测的创新。一方面，当前传统的中心化医疗架构存在诸多问题，包括数据隐私、延迟和安全。本文提出了一种AI赋能的去中心化物联网架构，可以在疫情和重症监护环境下解决这些挑战。这项工作展示了我们的架构，旨在增强当前可用的联邦学习、区块链和边缘计算方法的有效性，最大化数据隐私，最小化延迟，并改善其他通用系统指标。实验结果表明，其交易延迟、能耗和数据吞吐量比竞争性云解决方案低几个数量级。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [714] [BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications](https://arxiv.org/abs/2507.15984)
> *BACFuzz：揭示Web应用中权限控制漏洞的沉默*

*I Putu Arya Dharmaadi, Mohannad Alhanahnah, Van-Thuan Pham, Fadi Mohsen, Fatih Turkmen* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-21**

**Keywords:** 权限控制漏洞, 模糊测试, Web安全, BOLA, BFLA

**Comment:** Under peer-review

> **TL;DR:** BACFuzz是一个灰盒模糊测试框架，专门用于发现Web应用中的权限控制漏洞，通过结合LLM指导、运行时反馈和SQL检查，在真实应用中取得了显著成果。

**AI_Comments:** BACFuzz的创新点在于其结合了LLM指导、运行时反馈和SQL-based oracle checking，有效解决了权限控制漏洞自动化测试中的两大难题：预言机缺失和语义有效请求生成。这种多维度的方法使其在实际应用中表现出色，能够发现传统方法难以触及的“沉默”漏洞，对Web安全测试领域具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 权限控制漏洞（BAC）是Web应用中最关键和普遍的漏洞之一，尽管其严重性，但在自动化测试中由于缺乏可靠的预言机和难以生成语义有效的攻击请求而未得到充分探索。本文旨在解决这一问题。

**Method:** BACFuzz是一个灰盒模糊测试框架，专门用于发现PHP-based Web应用中的BAC漏洞，包括BOLA和BFLA。它结合了LLM引导的参数选择、运行时反馈和基于SQL的预言机检查来检测隐蔽的授权缺陷。它采用轻量级插桩来捕获指导测试生成的运行时信息，并分析后端SQL查询以验证未经授权的输入是否流入受保护的操作。

**Result:** 在20个真实世界的Web应用（包括15个CVE案例和2个已知基准）上进行评估，BACFuzz检测到17个已知问题中的16个，并发现了26个以前未知的BAC漏洞，具有较低的误报率。所有识别出的问题都已负责任地披露。

**Conclusion:** BACFuzz是第一个专门用于揭示Web应用中权限控制漏洞的灰盒模糊测试框架，通过其创新的方法有效解决了现有自动化测试的挑战，并成功发现了大量已知和未知漏洞，显著提升了Web应用安全性。

> **ai_Abstract:** BACFuzz是首个针对Web应用中权限控制漏洞（BAC）的灰盒模糊测试框架，旨在解决现有自动化测试中预言机缺失和请求生成困难的问题。它通过结合大型语言模型（LLM）指导的参数选择、运行时反馈和基于SQL的预言机检查来检测BOLA和BFLA。BACFuzz利用轻量级插桩捕获运行时信息，并分析后端SQL查询以验证非授权输入。在对20个真实Web应用（包括CVE和基准）的评估中，BACFuzz成功检测到大部分已知问题，并发现了26个新的BAC漏洞，且误报率低。

> **摘要翻译:** 权限控制漏洞（BAC）仍然是Web应用程序中最关键和最普遍的漏洞之一，它允许攻击者访问未经授权的资源或执行特权操作。尽管其严重性，但由于关键挑战：缺乏可靠的预言机和难以生成语义有效的攻击请求，BAC在自动化测试中仍未得到充分探索。我们引入了BACFuzz，这是第一个专门设计用于发现PHP-based Web应用程序中BAC漏洞（包括对象级授权破坏（BOLA）和功能级授权破坏（BFLA））的灰盒模糊测试框架。BACFuzz结合了LLM引导的参数选择、运行时反馈和基于SQL的预言机检查来检测隐蔽的授权缺陷。它采用轻量级插桩来捕获指导测试生成的运行时信息，并分析后端SQL查询以验证未经授权的输入是否流入受保护的操作。在20个真实世界的Web应用程序（包括15个CVE案例和2个已知基准）上进行评估，BACFuzz检测到17个已知问题中的16个，并发现了26个以前未知的BAC漏洞，具有较低的误报率。所有识别出的问题都已负责任地披露，并且成果将公开发布。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [721] ["We Need a Standard": Toward an Expert-Informed Privacy Label for Differential Privacy](https://arxiv.org/abs/2507.15997)
> *“我们需要一个标准”：迈向一种专家知情的差分隐私标签*

*Onyinye Dibia, Mengyi Lu, Prianka Bhattacharjee, Joseph P. Near, Yuanyuan Feng* | **Category: cs.CR, cs.HC, 68-XX 68-XX 68-XX** | **Updated: 2025-07-21**

**Keywords:** 差分隐私, 隐私标签, 标准化, 隐私保证, 专家访谈

**Comment:** 13 pages, 5 figures

> **TL;DR:** 为了解决差分隐私部署中隐私保证披露不充分的问题，本研究通过专家访谈设计了一个标准的差分隐私标签。

**AI_Comments:** 这项研究通过引入“隐私标签”的概念，为差分隐私的实际应用提供了一个急需的标准化工具。其创新之处在于通过专家访谈来识别关键披露参数，确保了实用性和权威性。这对于提高差分隐私部署的透明度和用户信任至关重要，有助于弥合理论与实践之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私（DP）的日益普及导致政府机构和公司进行公开部署，但实际部署中往往未能充分披露其隐私保证，这些保证在不同部署之间差异很大。未能披露某些DP参数可能导致对隐私保证强度产生误解，从而损害对DP的信任。本研究旨在为未来沟通DP隐私保证的标准提供信息。

**Method:** 本研究基于对12位差分隐私专家的半结构化访谈，识别了全面沟通DP保证所需的重要参数，并描述了为什么以及如何披露这些参数。基于专家建议，设计了一个初步的差分隐私标签，以标准化格式全面沟通隐私保证。

**Result:** 识别出全面沟通差分隐私保证所需的重要参数及其披露方式；设计了一个初步的、专家推荐的差分隐私隐私标签，用于标准化地沟通隐私保证。

**Conclusion:** 通过专家访谈和隐私标签的设计，本研究为建立差分隐私隐私保证的标准化沟通方式提供了基础，有助于解决现有部署中披露不足的问题，增强用户对差分隐私的信任。

> **ai_Abstract:** 本文旨在解决差分隐私（DP）部署中隐私保证披露不充分的问题，这损害了用户对DP的信任。研究通过对12位DP专家进行半结构化访谈，识别出全面沟通DP保证的关键参数，并在此基础上设计了一个初步的DP隐私标签，旨在以标准化格式清晰地传达隐私保证，为未来DP隐私披露标准的制定提供依据。

> **摘要翻译:** 差分隐私（DP）的日益普及导致政府机构和公司都进行了面向公众的DP部署。然而，现实世界中的DP部署通常不会完全披露其隐私保证，这些保证在不同部署之间差异很大。未能披露某些DP参数可能导致对隐私保证强度产生误解，从而损害对DP的信任。在这项工作中，我们旨在为未来沟通DP部署隐私保证的标准提供信息。基于对12位DP专家的半结构化访谈，我们确定了全面沟通DP保证所需的重要DP参数，并描述了为什么以及如何披露它们。根据专家建议，我们设计了一个初步的DP隐私标签，以标准化格式全面沟通隐私保证。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [728] [Blocklisted Oblivious Pseudorandom Functions](https://arxiv.org/abs/2507.16040)
> *黑名单遗忘式伪随机函数*

*Xinyuan Zhang, Anrin Chakraborti, Michael Reiter* | **Category: cs.CR** | **Updated: 2025-07-21**

**Keywords:** 遗忘式伪随机函数, 黑名单, 度量空间, 密码学, 隐私

**Comment:** 

> **TL;DR:** 本文引入了黑名单遗忘式伪随机函数（BOPRF），它允许服务器指定一个黑名单，只有当客户端输入不在黑名单上时，OPRF评估才能成功。该设计通过将客户端输入嵌入度量空间来提高性能。

**AI_Comments:** 本文通过引入黑名单机制，对OPRF进行了创新性扩展，这对于安全应用非常实用。利用度量空间嵌入进行高效的黑名单检查是一种巧妙的方法，可以在保持隐私的同时提高性能。阶段的分离和密码学拼接展示了复杂的设计。其在密码安全和恶意软件检测方面的适用性突显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 为了扩展遗忘式伪随机函数（OPRF）的概念，允许服务器指定一个黑名单，从而使OPRF评估仅在客户端输入不在该黑名单上时才成功。这满足了基于输入有效性进行条件OPRF评估的需求。

**Method:** 该设计将客户端输入嵌入到一个度量空间中，评估仅在该嵌入不与黑名单元素聚类时继续。它将嵌入和黑名单检查阶段分离以提高效率，然后通过密码学手段将这些阶段结合起来。该框架还支持对相同输入进行更高效的后续OPRF评估。

**Result:** 该设计提高了性能，并可应用于增强型密码认证密钥交换中的密码黑名单，以及对与已知恶意软件黑名单上的文件不相似的可执行文件进行MAC。

**Conclusion:** 本文成功地将黑名单功能扩展到OPRF，通过涉及度量空间嵌入和密码学拼接的新颖设计，展示了其在实际应用中的效用和性能优势。

> **ai_Abstract:** 本文提出了黑名单遗忘式伪随机函数（BOPRF），它是OPRF的扩展，允许服务器定义一个黑名单，只有当客户端输入不在该列表上时，评估才能进行。该设计通过将客户端输入嵌入度量空间来提高性能，仅当输入的嵌入不与黑名单元素聚类时才允许评估。它将嵌入和黑名单检查分离以提高效率，然后通过密码学手段将它们链接起来。该框架还支持高效的重复评估。实际应用包括密码黑名单和恶意软件检测。

> **摘要翻译:** 遗忘式伪随机函数（OPRF）是一种协议，通过该协议，客户端和服务器进行交互，以对服务器提供的密钥和客户端提供的输入评估伪随机函数，而不会向对方泄露密钥或输入。我们通过允许服务器指定一个黑名单来扩展这一概念，使得OPRF评估仅在客户端输入不在黑名单上时才成功。更具体地说，我们的设计通过将客户端输入嵌入到一个度量空间中来提高性能，只有当此嵌入不与黑名单元素聚类时，评估才会继续。我们的框架利用这种结构将嵌入和黑名单检查分离，以实现两者的有效实现，但随后必须通过密码学手段将这些阶段结合起来。我们的框架还支持更有效地对相同输入进行后续的OPRF评估。我们展示了我们的设计在增强型密码认证密钥交换中用于密码黑名单，以及仅对与已知恶意软件黑名单上的文件不相似的可执行文件进行MAC的应用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [733] [DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT](https://arxiv.org/abs/2507.16134)
> *DP2Guard：一种轻量级拜占庭鲁棒的工业物联网隐私保护联邦学习方案*

*Baofu Han, Bing Li, Yining Qi, Raja Jurdak, Kaibin Huang, Chau Yuen* | **Category: cs.CR, cs.DC** | **Updated: 2025-07-22**

**Keywords:** 联邦学习, 隐私保护, 拜占庭鲁棒, 梯度掩码, 混合防御

**Comment:** 

> **TL;DR:** DP2Guard是一种轻量级、拜占庭鲁棒的隐私保护联邦学习框架，通过梯度掩码和混合防御策略，有效抵御中毒攻击并降低开销。

**AI_Comments:** DP2Guard的创新之处在于其结合了多种技术来解决PPFL中的核心挑战。首先，使用轻量级梯度掩码而非传统加密，显著降低了开销，这对于资源受限的工业物联网环境至关重要。其次，混合防御策略结合了特征提取和聚类，增强了对复杂和自适应中毒攻击的鲁棒性。最后，引入区块链技术确保了训练过程的透明性和可审计性，增加了系统的可信度。该方案在实用性和安全性之间取得了良好的平衡。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私保护联邦学习（PPFL）方案面临两大挑战：一是依赖重量级加密技术导致高昂的通信和计算开销；二是单一防御策略难以有效对抗自适应攻击者，鲁棒性不足。

**Method:** 本文提出了DP2Guard，一个轻量级的隐私保护联邦学习框架，增强了隐私性和鲁棒性。它采用轻量级梯度掩码机制替代昂贵的密码学操作以保护本地梯度隐私。提出了一种混合防御策略，利用奇异值分解和余弦相似度提取梯度特征，并应用聚类算法有效识别恶意梯度。此外，DP2Guard采用基于信任分数的自适应聚合方案，根据历史行为调整客户端权重，并利用区块链记录聚合结果和信任分数以确保训练的防篡改和可审计性。

**Result:** 在两个公共数据集上进行的广泛实验表明，DP2Guard能有效防御四种高级中毒攻击，同时保证隐私，并显著降低通信和计算成本。

**Conclusion:** DP2Guard成功解决了现有隐私保护联邦学习在工业物联网中面临的计算开销大和对自适应攻击鲁棒性不足的问题，提供了一个轻量级、高效且安全的解决方案。

> **ai_Abstract:** 本文提出了DP2Guard，一个针对工业物联网的轻量级、拜占庭鲁棒的隐私保护联邦学习（PPFL）框架，旨在解决现有PPFL方案中存在的计算开销大和对自适应攻击鲁棒性不足的问题。DP2Guard通过采用轻量级梯度掩码机制替代传统加密操作来降低开销并保护隐私。同时，它引入了一种混合防御策略，结合奇异值分解、余弦相似度和聚类算法来识别恶意梯度。此外，该框架还整合了基于信任分数的自适应聚合方案和区块链技术，以确保训练过程的透明性、可审计性和防篡改性。实验结果表明，DP2Guard能够有效抵御多种高级中毒攻击，同时保持隐私并显著降低通信和计算成本。

> **摘要翻译:** 隐私保护联邦学习（PPFL）已成为一种安全的分布式机器学习（ML）范式，它在不暴露原始数据的情况下聚合本地训练的梯度。为了防御模型中毒威胁，一些增强鲁棒性的PPFL方案通过集成异常检测而被提出。然而，它们仍然面临两大挑战：（1）对重量级加密技术的依赖导致了大量的通信和计算开销；（2）单一防御机制往往无法为对抗自适应攻击者提供足够的鲁棒性。为了克服这些挑战，我们提出了DP2Guard，一个轻量级的PPFL框架，它增强了隐私性和鲁棒性。DP2Guard利用轻量级梯度掩码机制替代昂贵的密码学操作，同时确保本地梯度的隐私。提出了一种混合防御策略，它使用奇异值分解和余弦相似度提取梯度特征，并应用聚类算法有效识别恶意梯度。此外，DP2Guard采用基于信任分数的自适应聚合方案，根据历史行为调整客户端权重，同时区块链记录聚合结果和信任分数，以确保防篡改和可审计的训练。在两个公共数据集上进行的广泛实验表明，DP2Guard能有效防御四种高级中毒攻击，同时确保隐私，并降低通信和计算成本。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [736] [MFAz: Historical Access Based Multi-Factor Authorization](https://arxiv.org/abs/2507.16060)
> *MFAz: 基于历史访问的多因素授权*

*Eyasu Getahun Chekole, Howard Halim, Jianying Zhou* | **Category: cs.CR** | **Updated: 2025-07-21**

**Keywords:** 多因素授权, 历史访问, 会话劫持, 布隆过滤器, 区块链

**Comment:** 

> **TL;DR:** 本文提出了一种名为MFAz的新型多因素授权方案，利用历史访问数据作为授权因素，结合布隆过滤器和区块链技术，以主动缓解包括会话劫持在内的传统和高级未经授权访问。

**AI_Comments:** 该论文创新性地提出了多因素授权（MFAz）的概念，并明确区分了其与传统多因素认证（MFA）的区别，填补了该领域的空白。通过将历史访问行为作为授权因素，并结合布隆过滤器和区块链等现代技术，MFAz提供了一种前瞻性且鲁棒的防御机制，以应对高级的未经授权访问威胁，特别是会话劫持。其在智慧城市场景下的实验验证进一步凸显了其实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 未经授权的访问是网络安全领域的一个关键挑战，尤其随着攻击技术（如会话劫持）日益复杂，传统的访问控制机制已不足以应对。会话劫持允许攻击者秘密接管已建立的会话，从而未经授权访问私人资源。

**Method:** 提出了一种新的多因素授权（MFAz）方案，该方案主动缓解传统和高级的未经授权访问尝试。该方案将从历史授权访问中系统生成的细粒度访问控制规则（ARs）和验证点（VPs）分别用作第一和第二授权因素。为实现运行时和存储效率，以及防篡改和去中心化的授权决策，该方案利用了布隆过滤器和区块链技术。

**Result:** 在涉及不同计算能力设备的智慧城市测试平台上进行了实验评估，结果显示该方案在安全性和性能保证方面都具有很高的有效性。

**Conclusion:** 本文提出的基于历史访问的多因素授权（MFAz）方案，能够有效应对日益复杂的未经授权访问威胁，并在安全性和性能上表现出色，是多因素授权领域的首次正式介绍。

> **ai_Abstract:** 本文提出了一种名为MFAz的新型多因素授权方案，旨在应对日益复杂的未经授权访问和会话劫持攻击。MFAz利用历史访问数据生成细粒度的访问控制规则和验证点作为授权因素，并结合布隆过滤器提升效率，利用区块链实现防篡改和去中心化决策。实验结果表明，该方案在智慧城市测试环境中具有显著的安全性和性能效益。

> **摘要翻译:** 未经授权的访问仍然是网络安全领域面临的关键安全挑战之一。随着攻击技术的日益复杂，未经授权访问的威胁不再局限于传统方式，例如利用弱访问控制策略。相反，高级的利用策略，例如基于会话劫持的攻击，变得越来越普遍，带来了严重的安全问题。会话劫持使攻击者能够以隐秘的方式接管合法对等方之间已建立的会话，从而未经授权访问私人资源。不幸的是，传统的访问控制机制，例如静态访问控制策略，不足以防止会话劫持或其他高级利用技术。在这项工作中，我们提出了一种新的多因素授权（MFAz）方案，该方案主动缓解了传统和高级的未经授权访问尝试。所提出的方案采用细粒度访问控制规则（ARs）和验证点（VPs），这些规则和验证点分别作为第一和第二授权因素，系统地从历史授权访问中生成。作为概念验证，我们使用不同的技术实现了该方案。我们利用布隆过滤器实现运行时和存储效率，并利用区块链以防篡改和去中心化的方式做出授权决策。据我们所知，这是首次正式引入多因素授权方案，它与多因素认证（MFA）方案是正交的。我们提出的方案的有效性通过涉及不同计算能力设备的智慧城市测试平台进行了实验评估。实验结果表明该方案在安全性和性能保证方面都具有很高的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [739] [OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](https://arxiv.org/abs/2503.03108)
> *OMNISEC：基于LLM驱动的溯源入侵检测，通过检索增强行为提示*

*Wenrui Cheng, Tiantian Zhu, Shunan Jing, Jian-Ping Mei, Mingjun Ma, Jiaobo Jin, Zhengqiu Weng* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 入侵检测, 溯源, 大型语言模型, 检索增强生成, 异常检测

**Comment:** 

> **TL;DR:** OMNISEC利用LLM和RAG解决现有溯源入侵检测系统（PIDS）的误报和漏报问题，通过行为提示和知识库判断异常行为是否为真实攻击，并能重建攻击链。

**AI_Comments:** OMNISEC的创新点在于将大型语言模型（LLMs）与检索增强生成（RAG）相结合，应用于溯源入侵检测，特别是在解决异常检测中的高误报问题方面。通过引入外部知识库和行为提示，提升了系统对异常行为的判断准确性，并能重建完整的攻击链，这对于减少安全分析师的工作量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的溯源入侵检测系统（PIDS）面临挑战：基于规则的系统无法动态建模攻击特征，导致漏报；基于学习的系统（尤其是监督学习）因攻击样本稀缺而受限；基于异常的系统因无法区分正常行为变化和真实攻击行为而面临大量误报，增加了安全分析师的手动分析成本。

**Method:** 本文提出了OMNISEC系统，将大型语言模型（LLMs）应用于基于异常的入侵检测系统，通过检索增强行为提示。OMNISEC通过构建可疑节点和稀有路径来识别异常节点和相应的异常事件。结合两个外部知识库，OMNISEC利用检索增强生成（RAG）使LLM判断异常行为是否为真实攻击。最后，OMNISEC可以重建攻击图并恢复攻击者入侵的完整攻击行为链。

**Result:** 实验结果表明，OMNISEC在公共基准数据集上优于最先进的方法。

**Conclusion:** OMNISEC成功地将LLM应用于基于异常的入侵检测，有效减少了误报，并能重建完整的攻击行为链，在性能上超越了现有方法。

> **ai_Abstract:** 本文提出了OMNISEC，一个基于LLM驱动的溯源入侵检测系统，旨在解决现有PIDSes面临的漏报和高误报问题。OMNISEC通过构建可疑节点和稀有路径识别异常，并利用检索增强生成（RAG）结合外部知识库，使LLM能够准确判断异常行为是否为真实攻击。该系统还能重建完整的攻击行为链。实验证明OMNISEC在公共数据集上优于现有SOTA方法。

> **摘要翻译:** 最近，基于溯源的入侵检测系统（PIDSes）被广泛用于端点威胁分析。这些研究大致可分为基于规则的检测系统和基于学习的检测系统。其中，由于攻击技术的演变，规则无法动态建模攻击者的所有特征。因此，此类系统经常面临漏报问题。基于学习的检测系统进一步分为监督学习和异常检测。攻击样本的稀缺阻碍了监督学习检测系统在实际应用中的可用性和有效性。基于异常的检测系统面临大量的误报问题，因为它们无法区分正常行为的变化和真实的攻击行为。检测系统的警报结果与后续安全分析师的手动劳动成本密切相关。为了减少手动分析时间，我们提出了OMNISEC，它通过检索增强行为提示将大型语言模型（LLMs）应用于基于异常的入侵检测系统。OMNISEC通过构建可疑节点和稀有路径来识别异常节点和相应的异常事件。通过结合两个外部知识库，OMNISEC使用检索增强生成（RAG）使LLM能够确定异常行为是否为真实攻击。最后，OMNISEC可以重建攻击图并恢复攻击者入侵的完整攻击行为链。实验结果表明，OMNISEC在公共基准数据集上优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [748] [Attacking interpretable NLP systems](https://arxiv.org/abs/2507.16164)
> *攻击可解释的自然语言处理系统*

*Eldor Abdukhamidov, Tamer Abuhmed, Joanna C. S. Santos, Mohammed Abuhamad* | **Category: cs.CR, cs.AI, cs.LG, I.2.7; I.2.6; I.2.3; D.4.6** | **Updated: 2025-07-22**

**Keywords:** 对抗性攻击, 可解释性, 自然语言处理, 黑盒攻击, 字符级修改

**Comment:** 

> **TL;DR:** 本文介绍了AdvChar，一种针对可解释自然语言处理系统的黑盒攻击方法，通过微小的字符修改，在保持文本语义和解释相似性的同时，误导分类器做出错误预测，从而利用系统透明度中的信任。

**AI_Comments:** 本文的创新点在于提出了AdvChar，一种新型的对抗性攻击，它不仅关注于误导模型预测，更重要的是在攻击过程中保持了对人类而言的解释相似性。这揭示了一个重要的安全漏洞：即使系统提供了“可解释性”，这种解释也可能被恶意利用而不可信。其重要性在于，它提醒研究人员和开发者，在构建可解释的AI系统时，不仅要考虑模型本身的鲁棒性，还要考虑其解释的鲁棒性。该研究为未来开发更安全的、可信赖的可解释AI系统提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明机器学习系统容易受到对抗性攻击，但针对文本模型的攻击往往难以保持语义意义和相似性。本文旨在开发一种新的攻击方法，既能误导分类器，又能保持对人类来说的解释相似性，从而揭示对系统透明度的信任可能被利用的漏洞。

**Method:** 本文提出了AdvChar，一种针对可解释自然语言处理系统的黑盒攻击。它通过对文本输入进行不明显的字符级修改来实现。该方法使用一个以解释为中心的评分方法，来识别最重要的标记，这些标记在被修改后会导致分类器错误分类输入。AdvChar旨在在生成对抗性解释与良性解释相似的同时，最小化原始文本和新文本之间的差异。

**Result:** AdvChar在七个NLP模型和三个解释模型上进行了评估。实验表明，AdvChar平均只需改变输入样本中的两个字符，就能显著降低当前深度学习模型的预测准确性。

**Conclusion:** AdvChar成功地通过微小的字符修改，在保持解释相似性的同时误导了深度学习分类器，揭示了可解释NLP系统在信任透明度方面的潜在漏洞。

> **ai_Abstract:** 本文提出了一种名为AdvChar的黑盒对抗性攻击，专门针对可解释的自然语言处理系统。与以往的文本攻击不同，AdvChar通过对文本进行微小的字符级修改，在误导深度学习分类器做出错误预测的同时，保持了原始文本的语义意义和对人类而言的解释相似性。该攻击利用了系统透明度中的信任，通过一个以解释为中心的评分方法识别关键字符。实验证明，AdvChar平均仅需修改两个字符，即可显著降低多种NLP模型的预测准确性。

> **摘要翻译:** 研究表明，机器学习系统在理论和实践中都容易受到对抗性攻击。虽然之前的攻击主要集中在利用人类和机器感知差异的视觉模型上，但基于文本的模型也成为了这些攻击的受害者。然而，这些攻击通常未能保持文本的语义意义和相似性。本文介绍了AdvChar，一种针对可解释自然语言处理系统的黑盒攻击，旨在误导分类器，同时保持解释与良性输入相似，从而利用对系统透明度的信任。AdvChar通过对文本输入进行不明显的修改来实现这一点，迫使深度学习分类器做出不正确的预测并保留原始解释。我们使用一种以解释为中心的评分方法来确定最重要的标记，这些标记在改变后会导致分类器错误分类输入。我们应用简单的字符级修改来衡量标记的重要性，最大限度地减少原始文本和新文本之间的差异，同时生成与良性解释相似的对抗性解释。我们通过使用分类任务的基准数据集，针对七个NLP模型和三个解释模型进行测试，全面评估了AdvChar。我们的实验表明，AdvChar平均只需改变输入样本中的两个字符，就能显著降低当前深度学习模型的预测准确性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [17] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
> *识别大型语言模型中的预训练数据：一种基于神经元激活的检测框架*

*Hongyi Tang, Zhihao Zhu, Yi Yang* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 预训练数据检测, 大型语言模型, 神经元激活, 数据隐私, 数据集污染

**Comment:** 

> **TL;DR:** 大型语言模型的训练数据引发了版权、隐私和偏见问题。现有检测方法效果不佳。本文提出NA-PDD，一种基于神经元激活模式的检测算法，并引入CCNewsPDD基准，实验证明NA-PDD显著优于现有方法。

**AI_Comments:** 这篇论文通过利用内在的神经元激活模式来识别大型语言模型中的预训练数据，提出了一种创新方法，超越了表面特征的限制。引入时间上无偏的基准（CCNewsPDD）也是一个重要的贡献，解决了数据集中常见的局限性。NA-PDD性能的提升表明，它为解决LLM问责制和透明度方面的一个紧迫问题提供了一个更强大、更有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的性能与其训练数据密切相关，其中可能包含受版权保护的材料或私人信息，引发了法律和伦理问题。此外，LLM还面临数据集污染和内化偏见的批评。预训练数据检测（PDD）任务旨在识别特定数据是否包含在LLM的预训练语料库中，但现有方法依赖于表面特征，导致性能平庸。

**Method:** 本文引入了NA-PDD，这是一种新颖的算法，通过分析大型语言模型中训练数据和非训练数据之间不同的神经元激活模式来识别预训练数据。该方法基于一个观察，即这些数据类型在LLM推理过程中会激活不同的神经元。此外，论文还引入了CCNewsPDD，一个时间上无偏的基准，该基准采用严格的数据转换，以确保训练数据和非训练数据之间的时间分布一致。

**Result:** NA-PDD在三个基准和多个大型语言模型上显著优于现有方法。

**Conclusion:** NA-PDD在三个基准和多个大型语言模型上显著优于现有方法。

> **ai_Abstract:** 本文解决了识别大型语言模型（LLM）预训练数据的关键问题，这对于解决法律、伦理和偏见问题至关重要。论文提出了一种新颖的算法NA-PDD，通过分析训练数据和非训练数据之间不同的神经元激活模式，改进了现有依赖于表面特征的方法。该方法基于一个洞察，即在LLM推理过程中，训练数据和非训练数据会引发不同的神经元响应。此外，论文还引入了CCNewsPDD，一个新颖的、时间上无偏的基准，用于严格评估PDD方法。实验结果表明，NA-PDD在各种基准和LLM上显著优于现有方法。

> **摘要翻译:** 大型语言模型（LLM）的性能与其训练数据密切相关，其中可能包含受版权保护的材料或私人信息，引发了法律和伦理问题。此外，LLM还面临数据集污染和内化偏见的批评。为了解决这些问题，提出了预训练数据检测（PDD）任务，以识别特定数据是否包含在LLM的预训练语料库中。然而，现有的PDD方法通常依赖于预测置信度和损失等表面特征，导致性能平庸。为了改进这一点，我们引入了NA-PDD，一种分析LLM中训练数据和非训练数据之间神经元激活模式差异的新颖算法。这基于一个观察，即这些数据类型在LLM推理过程中激活不同的神经元。我们还引入了CCNewsPDD，一个时间上无偏的基准，采用严格的数据转换以确保训练数据和非训练数据之间的时间分布一致。我们的实验表明，NA-PDD在三个基准和多个LLM上显著优于现有方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [26] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
> *微出行流量预测：基于多级时空注意力神经网络的共享单车站级研究*

*Xi Yang, Jiachen Wang, Song Han, Suining He* | **Category: cs.AI** | **Updated: 2025-07-21**

**Keywords:** 微出行, 共享单车, 流量预测, 时空注意力, 神经网络

**Comment:** 6 pages, UrbComp 2024

> **TL;DR:** 该研究提出了BikeMAN，一个多级时空注意力神经网络，用于准确预测整个共享单车系统（如纽约市）中所有站点的单车流量，解决了站级预测的复杂性和大规模挑战。

**AI_Comments:** 该论文的创新点在于提出了一个结合多级时空注意力机制的神经网络模型BikeMAN，以应对共享单车系统大规模站级流量预测的复杂性。其重要性在于，高精度的站级流量预测能够显著优化共享单车资源的调度和维护，提高系统运营效率。该方法为解决类似城市微出行场景中的供需平衡问题提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 城市微出行资源（如共享单车）的有效利用面临挑战，因为站点的供需不平衡导致系统维护困难。尽管已有预测单车流量（需求/取车和归还/还车）的工作，但由于共享单车系统的时空复杂性以及站点数量庞大，对整个系统的站级流量预测仍然十分困难。

**Method:** 为了解决站级单车流量预测的挑战，本研究提出了BikeMAN，一个多级时空注意力神经网络。该网络包含一个编码器和一个解码器，并集成了两种注意力机制：一种用于表示系统中单车站点特征之间的空间关联，另一种用于描述单车站点流量的时间特性。

**Result:** 通过对纽约市共享单车系统（超过700个站点，1000多万次行程）的实验研究，BikeMAN网络在预测城市中所有单车站点的流量方面表现出高精度。

**Conclusion:** 本研究提出的BikeMAN多级时空注意力神经网络能够高精度地预测整个共享单车系统的站级流量，有效解决了因时空复杂性和站点规模大而带来的预测难题，从而有助于提高系统效率和资源管理。

> **ai_Abstract:** 本论文提出了一种名为BikeMAN的多级时空注意力神经网络模型，旨在解决共享单车系统中站点层面流量预测的挑战。针对现有方法在处理大规模、高时空复杂性数据时的不足，BikeMAN模型通过结合空间和时间注意力机制，能够准确预测整个系统内所有站点的单车需求和供应。在纽约市超过700个站点的千万级行程数据上的实验表明，该模型在预测单车站点流量方面展现出高精度。

> **摘要翻译:** 城市微出行资源（例如共享单车）的有效利用具有挑战性，因为站点的供需不平衡导致共享单车系统的维护工作艰巨。先前的工作已经致力于准确预测单车流量，即需求/取车和归还/还车，以提高系统效率。然而，由于共享单车系统的时空复杂性，单车站级流量预测非常困难。此外，对整个共享单车系统进行这种级别的预测也具有挑战性，因为单车站点数量庞大。为了弥补这一空白，我们提出了BikeMAN，一个多级时空注意力神经网络，用于预测整个共享单车系统的站级单车流量。所提出的网络由一个编码器和一个解码器组成，其中包含一个注意力机制，用于表示系统中单车站点特征之间的空间相关性，以及另一个注意力机制，用于描述单车站点流量的时间特性。通过对纽约市共享单车系统（超过700个站点）超过1000万次行程的实验研究，我们的网络在预测城市中所有单车站点的流量方面表现出高精度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [51] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
> *从基于模型的学习到基于Meta-Interpretive Learning的无模型行为*

*Stassa Patsantzis* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 基于模型的学习, 无模型行为, Meta-Interpretive Learning, 自主智能体, 网格导航

**Comment:** 

> **TL;DR:** 本文展示了如何利用Meta-Interpretive Learning将基于模型的规划能力转移到无模型的控制器上，从而使自主智能体在不完全了解环境的情况下也能有效行动。

**AI_Comments:** 这项研究的创新之处在于利用Meta-Interpretive Learning作为桥梁，将基于模型的深层理解和规划能力蒸馏或转移到更灵活、对环境信息依赖更少的无模型控制器上。这对于创建能在复杂、动态且信息不完全环境中运行的自主智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自主智能体需要在新环境中独立行动，这要求它们结合基于模型（能规划但需环境状态）和无模型（无需模型或完整观测但不能规划）两种能力。

**Method:** 研究人员使用Meta-Interpretive Learning来学习一个基于模型的Solver。然后，这个Solver被用来训练一个无模型的Controller，使其能够解决与Solver相同的规划问题。

**Result:** 在网格导航问题（随机迷宫和湖泊地图）上，基于模型的Solver和无模型的Controller在问题解决能力上表现出等效性。所有由Solver解决的导航问题，Controller也都能解决。

**Conclusion:** 研究表明，通过Meta-Interpretive Learning，可以将基于模型的学习能力成功转化为无模型的行为，实现两种智能体在问题解决能力上的等效性。

> **ai_Abstract:** 本文提出了一种方法，通过Meta-Interpretive Learning (MIL) 将基于模型的学习能力转化为无模型的行为。具体而言，一个基于模型的Solver通过MIL学习得到，并用于训练一个无模型的Controller。实验证明，在网格导航问题中，该Controller能够与Solver达到相同的规划问题解决能力，从而使自主智能体能够在未知环境中结合两种能力进行有效行动。

> **摘要翻译:** “模型”是一种描述环境状态和智能体决策对环境影响的理论。基于模型的智能体可以使用其模型来预测未来行动的效果并提前规划，但必须了解环境的状态。无模型的智能体无法规划，但可以在没有模型且无需完全观察环境的情况下行动。一个能够在新环境中独立行动的自主智能体必须结合这两种能力。我们展示了如何利用Meta-Interpretive Learning来创建这样一个智能体：它学习一个基于模型的Solver，该Solver用于训练一个无模型的Controller，使其能够解决与Solver相同的规划问题。我们通过两种环境中的网格导航问题（随机生成的迷宫和有开阔区域的湖泊地图）证明了这两种智能体在问题解决能力上的等效性。我们发现所有由Solver解决的导航问题也都被Controller解决，这表明两者是等效的。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [60] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
> *从逻辑到语言：大型语言模型问题解决中的信任指数*

*Tehseen Rug, Felix Böhmer, Tessa Pfattheicher* | **Category: cs.AI** | **Updated: 2025-07-21**

**Keywords:** 大型语言模型, 问题解决, 信任指数, 自然语言处理, 质量评估

**Comment:** 17 pages, 2 figures

> **TL;DR:** 本文提出了一个统一框架和向量值信任指数Q，用于评估大型语言模型（LLMs）解决自然语言问题时的方案质量，以区分其与传统逻辑系统的二元正确性。

**AI_Comments:** 本文创新性地提出了一个“信任指数Q”以及归一化双语义熵和情感效价两个统计质量维度，旨在量化评估大型语言模型（LLMs）在处理模糊、主观的自然语言问题时的解决方案质量。这弥补了传统二元评估的不足，对于提升LLMs在复杂现实场景中的可靠性和可信度评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统计算系统擅长解决有明确规则的问题，但无法处理人类社会中模糊、动态和主观的问题。大型语言模型（LLMs）的出现使得计算系统能够通过自然语言处理这些问题，但需要新的方法来评估其解决方案的质量，因为这些解决方案不同于传统形式系统的二元正确性。

**Method:** 本文引入了一个统一框架来理解和对比形式语言与自然语言的问题解决范式。定义并划分了形式语言和自然语言可解决的问题空间。针对自然语言解决方案，引入了一个向量值信任指数Q，用于反映解决方案质量，并区分形式解的二元正确性与自然语言解的连续充分性。在此框架内，提出了两个统计质量维度：归一化双语义熵（衡量LLM答案在问题表述语义变化下的鲁棒性和概念多样性）和情感效价（将解决方案的主观评估映射为可量化指标）。

**Result:** 摘要中未提及。

**Conclusion:** 本文引入的概念将为大型语言模型（LLMs）时代问题解决的能力、局限性和内在性质提供更严谨的理解。

> **ai_Abstract:** 本文提出了一个统一框架，用于理解和对比传统逻辑系统与大型语言模型（LLMs）在问题解决上的差异。针对LLMs处理自然语言中固有的模糊性和主观性问题，论文引入了一个向量值信任指数Q，旨在评估LLM解决方案的质量，并将其与传统形式解的二元正确性区分开来。该框架还包括归一化双语义熵和情感效价两个统计质量维度，分别用于衡量解决方案的鲁棒性和主观价值。该工作旨在加深对LLM时代问题解决能力和局限性的理解。

> **摘要翻译:** 经典计算以形式逻辑系统为基础，几十年来一直是技术进步的引擎，擅长解决可以用明确规则描述的问题。然而，这种范式却将大量人类问题——那些以模糊性、动态环境和主观背景为特征的问题——基本置之不理。大型语言模型（LLMs）的出现代表着一个根本性的转变，它使计算系统能够使用自然语言进入这个以前无法触及的领域。本文引入了一个统一框架来理解和对比这些问题解决范式。我们定义并划分了形式语言和自然语言可解决的问题空间。虽然前一类问题的解决方案可以使用二元质量度量进行评估，但后者需要对近似解决方案空间进行更细致的定义，考虑到自然语言固有的模糊性、主观性和歧义性。因此，我们引入了一个向量值信任指数Q，它反映了解决方案的质量，并区分了形式解决方案的二元正确性与自然语言解决方案特征的连续充分性谱。在这个框架内，我们提出了两个统计质量维度。归一化双语义熵衡量了在问题表述语义变化下LLM答案的鲁棒性和概念多样性。情感效价将解决方案的主观评估映射为可通过调用统计度量来最大化的可量化指标。这项工作中引入的概念将为大型语言模型（LLMs）时代问题解决的能力、局限性和内在性质提供更严谨的理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [71] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
> *ACT：通过合成数据生成和自适应训练弥合代码翻译的鸿沟*

*Shreya Saxena, Siva Prasad, Zishan Ahmad, Vishal Vaddina* | **Category: cs.AI, cs.SE** | **Updated: 2025-07-22**

**Keywords:** 代码翻译, 大型语言模型, 合成数据生成, 自适应训练, 开源模型

**Comment:** 

> **TL;DR:** ACT是一个通过合成数据生成和自适应训练，使开源大型语言模型能够进行内部微调，从而提升代码翻译能力的框架。

**AI_Comments:** ACT的创新之处在于其结合了合成数据生成、自适应训练和智能控制器模块，实现了对开源大型语言模型的高效微调，从而解决了传统方法和闭源模型在代码翻译中的痛点。其通过执行级检查和单元测试确保数据质量和翻译准确性，并能根据实时评估动态优化训练过程，这对于提升开源LLMs在实际应用中的竞争力具有重要意义。该框架为企业提供了更安全、可控的内部解决方案，降低了对外部API的依赖，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 代码翻译在软件开发和迁移中至关重要，但传统方法缺乏灵活性和可扩展性。先进的语言模型虽有前景，但其专有、基于API的实现引发数据安全和依赖性担忧。

**Method:** 本文提出了代码翻译自动训练（ACT）框架，旨在通过对开源大型语言模型进行内部微调来提高代码翻译能力。ACT的自动化管道显著提升了模型性能，其核心是合成数据生成模块，该模块从初始代码样本构建高质量数据集，并结合单元测试确保功能准确性和多样性。ACT的评估框架包含执行级检查。此外，ACT的控制器模块管理整个管道，动态调整超参数，协调迭代数据生成，并根据实时评估进行微调，从而智能优化训练、数据生成或停止过程。

**Result:** 结果表明，ACT持续提升了开源模型的有效性，为企业和开发者提供了安全可靠的替代方案。此外，将ACT的数据生成管道应用于工业规模的迁移项目，显著提高了开发人员的效率。

**Conclusion:** ACT框架通过利用合成数据生成和自适应训练，成功弥合了开源大型语言模型在代码翻译性能上的差距，为软件开发和迁移项目提供了一个安全、高效且可控的解决方案。

> **ai_Abstract:** ACT是一个创新的框架，旨在通过合成数据生成和自适应训练，提升开源大型语言模型在代码翻译方面的能力。它通过自动化管道，利用高质量的合成数据和智能控制器模块进行迭代微调，从而弥补了开源与闭源解决方案在性能上的差距，为企业和开发者提供了一个安全、高效的代码翻译替代方案，并已在工业级迁移项目中验证了其加速开发者的能力。

> **摘要翻译:** 代码翻译是软件开发和迁移项目中的关键过程，它能够实现不同编程语言之间的互操作性，并增强软件的适应性，从而延长其寿命。传统的自动化翻译方法严重依赖手工转换规则，这些规则通常缺乏灵活性和可扩展性。同时，先进的语言模型提供了有前景的替代方案，但往往受限于专有、基于API的实现，这引发了数据安全和依赖性的担忧。在本文中，我们提出了代码翻译自动训练（ACT），这是一个创新的框架，旨在通过实现开源大型语言模型（LLMs）的内部微调来提高代码翻译能力。ACT的自动化管道显著提升了这些模型的性能，缩小了开源可访问性与闭源解决方案高性能之间的差距。ACT的核心是其合成数据生成模块，该模块从初始代码样本构建广泛、高质量的数据集，并结合单元测试以确保功能准确性和多样性。ACT的评估框架包含执行级检查，提供了对翻译质量的全面评估。ACT的一个关键特性是其控制器模块，该模块通过动态调整超参数、协调迭代数据生成以及基于实时评估进行微调来管理整个管道。这使得ACT能够智能地优化何时继续训练、生成额外的目标训练数据或停止该过程。我们的结果表明，ACT持续提升了开源模型的有效性，为企业和开发者提供了安全可靠的替代方案。此外，将我们的数据生成管道应用于工业规模的迁移项目，显著提高了开发人员的效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [97] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
> *通过机器学习预测改进基于ASP的ORS排程*

*Pierangela Bruno, Carmine Dodaro, Giuseppe Galatà, Marco Maratea, Marco Mochi* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-22**

**Keywords:** 手术室排程, 答案集编程, 机器学习, 预测, 鲁棒性

**Comment:** 17 pages, International Conference on Logic Programming, Under
  consideration in Theory and Practice of Logic Programming (TPLP)

> **TL;DR:** 本文通过将机器学习预测与ASP结合，解决了手术室排程中基于ASP的方案无法生成临时排程和排程鲁棒性不足的问题。

**AI_Comments:** 本文的创新点在于将机器学习的预测能力与答案集编程的逻辑推理能力相结合，解决了现实世界中手术室排程的实际挑战，特别是预设排程的生成和排程的鲁棒性。这种混合方法为优化复杂的约束满足问题提供了一个有前景的范式。其在真实历史数据上的验证增加了其实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于答案集编程（ASP）的手术室排程（ORS）解决方案在应用于真实数据时，只能验证编码是否与实际数据对齐，或最多建议替代排程。这导致无法生成预设排程，并且生成的排程不够鲁棒。

**Method:** 本文整合了归纳和演绎技术。首先，利用机器学习算法从历史数据中预测手术时长，以计算预设排程。其次，将预测的置信度作为额外输入，并相应更新ASP编码，以计算更鲁棒的排程。

**Result:** 在意大利ASL1 Liguria的历史数据上的结果证实了该整合方法的可行性。

**Conclusion:** 通过将机器学习预测与答案集编程（ASP）相结合，可以有效解决手术室排程中预设排程生成和排程鲁棒性的问题，该集成方法在真实数据上显示出可行性。

> **ai_Abstract:** 本文提出了一种将机器学习与答案集编程（ASP）相结合的新方法，以改进手术室排程（ORS）。针对现有ASP解决方案无法生成预设排程和排程鲁棒性不足的问题，作者首先利用机器学习预测手术时长以实现预设排程，然后将预测置信度纳入ASP模型以增强排程鲁棒性。在意大利ASL1 Liguria的历史数据上的实验结果验证了该集成方法的有效性。

> **摘要翻译:** 手术室排程（ORS）问题涉及日常手术室手术排程的优化。这是一个具有挑战性的问题，受许多约束，例如确定不同手术的开始时间以及分配所需资源，包括不同科室病床的可用性。最近，已经提出了基于答案集编程（ASP）的该问题解决方案。此类解决方案总体上令人满意，但当应用于真实数据时，它们目前只能验证编码是否与实际数据对齐，最多只能建议可能已计算出的替代排程。因此，目前无法生成预设排程。此外，生成的排程并非总是鲁棒的。
在本文中，我们整合了归纳和演绎技术来解决这些问题。我们首先利用机器学习算法从历史数据中预测手术时长，以计算预设排程。然后，我们将此类预测的置信度视为我们问题的额外输入，并相应地更新编码，以计算更鲁棒的排程。在意大利利古里亚ASL1的历史数据上的结果证实了我们整合的可行性。
在《逻辑编程理论与实践》（TPLP）中审议中。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [101] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
> *一个统一的半环约束逻辑编程框架，包含否定（完整版）*

*Jeroen Spaans, Jesse Heyninck* | **Category: cs.AI, cs.LO** | **Updated: 2025-07-21**

**Keywords:** 约束逻辑编程, 半环, 否定, 统一框架, 逼近不动点理论

**Comment:** Full version, including proofs and appendices, of paper accepted at
  IJCAI 2025

> **TL;DR:** 本文提出了一个统一的半环约束逻辑编程框架，该框架允许在子句体中使用否定，并为这些程序提供了语义。

**AI_Comments:** 本文的创新点在于提出了一个统一的框架，首次允许在约束逻辑编程的子句体中引入否定，这弥补了现有CLP扩展的空白。通过结合半环理论和逼近不动点理论，该工作不仅整合了多种现有泛化，还增强了CLP的表达能力，对于需要处理复杂约束和不确定性的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的约束逻辑编程（CLP）扩展（例如支持模糊约束满足、不确定性或否定）都没有研究过允许在子句体中使用否定的情况。本文旨在提出一个统一的框架，该框架能整合这些扩展并允许在子句体中使用否定。

**Method:** 本文使用逼近不动点理论的框架，为允许在子句体中使用否定的CLP程序提供了语义，并详细概述了半环属性对所得语义的影响。

**Result:** 本文提供了一个统一的框架，该框架能够涵盖现有方法，并允许使用更具表达力的语言来扩展它们。

**Conclusion:** 本文成功地提出了一个统一的半环约束逻辑编程框架，该框架允许在子句体中使用否定，并为之提供了基于逼近不动点理论的语义，从而扩展了现有方法并提供了更强大的表达能力。

> **ai_Abstract:** 本文提出了一个统一的半环约束逻辑编程（CLP）框架，旨在解决现有CLP扩展未能处理的子句体中包含否定的问题。该框架整合了多种现有扩展，并利用逼近不动点理论为包含否定的CLP程序提供了严格的语义。研究还详细分析了半环属性对语义的影响，从而提供了一个能够涵盖并扩展现有方法的更具表达力的语言。

> **摘要翻译:** 约束逻辑编程（CLP）是一种逻辑编程形式，用于解决需要考虑约束的问题，如资源分配、自动化规划和调度。它之前已经向多个方向扩展，例如支持模糊约束满足、不确定性或否定，其中使用了不同的半环概念作为这些泛化的统一抽象。然而，这些扩展都没有研究过允许在子句体中使用否定的子句。我们研究了CLP的一个扩展，它统一了许多这些扩展并允许在子句体中使用否定。我们使用逼近不动点理论的框架为这些程序提供了语义，并详细概述了半环属性对所得语义的影响。因此，我们提供了一个统一的框架，该框架捕获了现有方法并允许使用更具表达力的语言来扩展它们。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [139] [Efficient Strategy Learning by Decoupling Searching and Pathfinding for Object Navigation](https://arxiv.org/abs/2406.14103)
> *通过解耦搜索和寻路实现目标导航的高效策略学习*

*Yanwei Zheng, Shaopu Feng, Bowen Huang, Chuanlin Lan, Xiao Zhang, Dongxiao Yu* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** Object navigation, Two-stage reward mechanism, Depth enhanced masked autoencoders, Strategy learning, Decoupling

**Comment:** 

> **TL;DR:** 该论文提出了一种两阶段奖励机制（TSRM）和深度增强掩码自编码器（DE-MAE）来解耦搜索和寻路，以改进目标导航，解决奖励信号差异和空间感知问题，并展示了超越SOTA的性能。

**AI_Comments:** 这项研究的创新点在于其两阶段奖励机制（TSRM）和深度增强掩码自编码器（DE-MAE），有效地解决了传统目标导航方法中奖励信号冲突和深度信息利用不足的问题。通过解耦搜索和寻路过程，并增强了智能体的空间感知能力，显著提高了导航效率和成功率。新提出的SSSPL指标也为评估搜索能力提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有目标导航模型在搜索和寻路阶段忽略了奖励信号的差异，导致训练不充分或过拟合。此外，由于使用通用视觉编码器而未考虑深度信息，导致空间感知能力不足。

**Method:** 1. 提出两阶段奖励机制（TSRM），将搜索和寻路行为解耦，使智能体能在搜索阶段探索更大区域，并在寻路阶段寻找最优路径。2. 提出深度增强掩码自编码器（DE-MAE）预训练方法，提高智能体在搜索阶段确定已探索/未探索区域、在寻路阶段定位目标和规划路径的准确性。3. 提出新的评估指标——搜索成功率乘以搜索路径长度（SSSPL），以评估智能体的搜索能力和探索效率。

**Result:** 在AI2-Thor和RoboTHOR平台上进行了广泛评估，结果表明该方法在成功率和导航效率方面均优于最先进（SOTA）的方法。

**Conclusion:** 该论文通过引入两阶段奖励机制（TSRM）和深度增强掩码自编码器（DE-MAE），成功解决了目标导航中奖励信号差异和空间感知受限的问题，显著提升了导航性能。

> **ai_Abstract:** 本研究提出了一种高效的目标导航策略学习方法，通过解耦搜索和寻路阶段来解决现有模型中奖励信号差异和空间感知能力不足的问题。具体而言，引入了两阶段奖励机制（TSRM）以区分搜索和寻路行为，并开发了深度增强掩码自编码器（DE-MAE）预训练方法以提升空间感知。此外，还提出了一个新的评估指标SSSPL。实验结果表明，该方法在AI2-Thor和RoboTHOR平台上显著优于现有最先进方法，在成功率和导航效率方面均有提升。

> **摘要翻译:** 受到人类导航行为的启发：首先在发现目标之前探索未知区域，然后向发现的目标进行寻路。最近的研究设计了并行的子模块来实现搜索和寻路阶段的不同功能，但忽略了两个阶段之间奖励信号的差异。结果，这些模型通常无法完全训练或在训练场景中过拟合。限制智能体学习两阶段策略的另一个瓶颈是空间感知能力，因为研究中使用的通用视觉编码器没有考虑导航场景的深度信息。为了释放模型在策略学习方面的潜力，我们提出了一种用于目标导航的两阶段奖励机制（TSRM），该机制在一个回合中解耦了搜索和寻路行为，使智能体能够在搜索阶段探索更大的区域并在寻路阶段寻找最佳路径。此外，我们提出了一种预训练方法深度增强掩码自编码器（DE-MAE），使智能体能够在搜索阶段确定已探索和未探索区域，并在寻路阶段更准确地定位目标对象和规划路径。此外，我们提出了一种新的度量标准，即搜索成功率乘以搜索路径长度（SSSPL），用于评估智能体的搜索能力和探索效率。最后，我们在AI2-Thor和RoboTHOR上广泛评估了我们的方法，并证明它在成功率和导航效率方面都优于最先进（SOTA）的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [141] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
> *专家引导的LLM电池发现推理：从AI驱动的假设到合成和表征*

*Shengchao Liu, Hannan Xu, Yan Ai, Huanxin Li, Yoshua Bengio, Harry Guo* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-21**

**Keywords:** LLM, 电池发现, 材料设计, AI驱动, ChatBattery

**Comment:** 

> **TL;DR:** 引入ChatBattery框架，通过专家引导的LLM推理成功发现并合成了三种新型锂离子电池正极材料，容量显著提升。

**AI_Comments:** 该研究的创新之处在于将LLM的推理能力与领域专家知识相结合，首次成功应用于电池材料的发现与合成，并形成了从AI驱动假设到实际验证的完整闭环。这不仅突破了LLM在传统数学和编码领域的应用局限，更为材料科学领域提供了一种高效、智能化的新范式，具有重要的实践意义和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在解决数学和编码问题方面表现出色，但其在电池发现等特定领域应用的潜力尚未充分开发，因此需要一种方法来引导LLMs进行更有效的材料设计推理。

**Method:** 引入了ChatBattery，一个新颖的代理框架，它集成了领域知识来引导LLMs在材料设计中进行更有效的推理。

**Result:** 使用ChatBattery成功识别、合成和表征了三种新型锂离子电池正极材料，与NMC811相比，其实用容量分别提高了28.8%、25.2%和18.5%。

**Conclusion:** ChatBattery通过展示一个成功的LLM驱动的、基于推理的电池材料发明平台，开辟了一条新道路，证明了AI驱动的推理在彻底改变材料发现方面的变革潜力。

> **ai_Abstract:** 该论文介绍了ChatBattery，一个结合领域知识引导大型语言模型（LLMs）进行材料设计的创新框架。针对LLMs在特定领域应用（如电池发现）中推理能力未充分开发的现状，ChatBattery成功地识别、合成了三种新型锂离子电池正极材料，并实现了显著的容量提升。这项工作展示了一个完整的AI驱动的材料发现周期，从设计到合成再到表征，突显了AI在材料科学领域应用的巨大潜力。

> **摘要翻译:** 大型语言模型（LLMs）利用思维链（CoT）技术解决复杂问题，代表了人工智能（AI）领域的变革性突破。然而，它们的推理能力主要体现在解决数学和编码问题上，其在电池发现等特定领域应用的潜力仍未得到充分探索。受推理类似于一种引导式搜索的启发，我们引入了ChatBattery，一个新颖的代理框架，它集成了领域知识以引导LLMs在材料设计中进行更有效的推理。使用ChatBattery，我们成功识别、合成并表征了三种新型锂离子电池正极材料，与广泛使用的正极材料LiNi0.8Mn0.1Co0.1O2（NMC811）相比，其实用容量分别提高了28.8%、25.2%和18.5%。除了这一发现，ChatBattery还开辟了一条新路径，展示了一个成功的由LLM驱动、基于推理的电池材料发明平台。这种完整的AI驱动周期——从设计到合成再到表征——展示了AI驱动推理在彻底改变材料发现方面的变革潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [142] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
> *通过选项诱导的抽象MDP中的变分同态学习时间抽象*

*Chang Li, Yaren Zhang, Haoran Lv, Qiong Cao, Chao Xue, Xiaodong He* | **Category: cs.AI, I.2.7** | **Updated: 2025-07-22**

**Keywords:** 时间抽象, 变分同态, 选项学习, 抽象MDP, 分层强化学习

**Comment:** 

> **TL;DR:** 该论文提出了一种通过变分同态在选项诱导的抽象MDP中学习时间抽象的方法，旨在解决大型语言模型（LLMs）中显式思维链（CoT）推理计算成本高的问题，实现高效的隐式推理，并在逻辑推理和运动控制任务上表现出色。

**AI_Comments:** 该论文通过将推理从显式文本生成转移到潜在空间中的抽象动作，创新性地解决了LLM思维链推理的计算瓶颈。其核心贡献在于VMOC算法的提出以及对连续MDP同态理论的扩展，这不仅提供了强大的方法论，更从理论上保证了在抽象空间中学习策略的最优性。这种理论与实践的结合是其重要性所在。同时，该框架在语言和控制任务上的普适性也彰显了其广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些分步文本解释的计算成本高昂且速度缓慢。本研究旨在开发一个高效、隐式的推理框架，使模型在潜在空间中“思考”，而无需为每一步生成显式文本。

**Method:** 本研究提出将潜在思维建模为分层强化学习框架中的时间扩展抽象动作（或选项）。为此，引入了变分马尔可夫选项评论家（VMOC），这是一种在HiT-MDP框架内使用变分推断的离策略算法，用于学习多样化的选项作为潜在嵌入。为了为使用这些选项作为抽象推理空间提供严格的基础，扩展了连续MDP同态理论，证明在简化的抽象潜在空间中学习策略（VMOC适用于此）能保持原始复杂问题解决方案的最优性。最后，提出了一种冷启动程序，利用监督微调（SFT）数据将人类推理演示提炼到这个潜在选项空间中，为模型的推理能力提供丰富的初始化。

**Result:** 我们的方法在复杂的逻辑推理基准和具有挑战性的运动控制任务上取得了强大的性能，验证了我们的框架是学习语言和控制抽象技能的原则性方法。

**Conclusion:** 本研究提出了一个通过选项诱导的抽象MDP中的变分同态学习时间抽象的框架，成功地实现了LLMs的高效隐式推理。VMOC算法和扩展的MDP同态理论为在潜在空间中学习抽象技能提供了坚实的基础，并在多项任务中验证了其有效性和最优性保持。

> **ai_Abstract:** 本论文旨在解决大型语言模型中显式思维链推理的计算效率问题，提出了一种在潜在空间中进行高效隐式推理的框架。该框架将潜在思维建模为分层强化学习中的时间扩展抽象动作（选项）。核心贡献包括引入变分马尔可夫选项评论家（VMOC）算法，用于学习多样化的潜在选项嵌入，以及扩展连续MDP同态理论以提供抽象推理空间的严格基础，并证明其最优性保持。此外，还提出了利用监督微调数据进行冷启动初始化。实验结果表明，该方法在复杂逻辑推理和运动控制任务上均表现出色，验证了其作为学习语言和控制抽象技能的原则性方法。

> **摘要翻译:** 大型语言模型（LLMs）通过显式思维链（CoT）提示展现出卓越的推理能力，但生成这些分步文本解释的计算成本高昂且速度缓慢。为了克服这个问题，我们旨在开发一个高效、隐式的推理框架，使模型在潜在空间中“思考”，而无需为每一步生成显式文本。我们提出，这些潜在思维可以被建模为分层强化学习框架中的时间扩展抽象动作，或选项。为了有效地学习多样化的选项库作为潜在嵌入，我们首先引入了变分马尔可夫选项评论家（VMOC），这是一种在HiT-MDP框架内使用变分推断的离策略算法。为了为使用这些选项作为抽象推理空间提供严格的基础，我们扩展了连续MDP同态理论。这证明了在简化的抽象潜在空间中学习策略（VMOC适用于此）能保持原始复杂问题解决方案的最优性。最后，我们提出了一种冷启动程序，利用监督微调（SFT）数据将人类推理演示提炼到这个潜在选项空间中，为模型的推理能力提供丰富的初始化。大量的实验表明，我们的方法在复杂的逻辑推理基准和具有挑战性的运动控制任务上取得了强大的性能，验证了我们的框架是学习语言和控制抽象技能的原则性方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [169] [R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory](https://arxiv.org/abs/2501.12485)
> *R2D2：具有反思性代理记忆的记忆、回放和动态决策*

*Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, Pavan Kapanipathi, Jonathan May, Muhao Chen* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 网络代理, 动态决策, 记忆, 反思, 导航

**Comment:** ACL 2025

> **TL;DR:** R2D2是一个新的网络代理框架，通过结合记忆（回放缓冲区构建地图）和反思（从错误中学习）范式，显著提高了复杂网络环境中的导航效率和任务完成率。

**AI_Comments:** R2D2框架的创新之处在于其将记忆（通过回放缓冲区构建环境地图）和反思（通过错误分析学习）相结合，为网络代理提供了一个更鲁棒和高效的决策机制。这种结合不仅解决了现有模型在复杂网络环境中导航受限的问题，还在实际性能上取得了显著提升，为未来的智能代理应用（如自动化客服）奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前网络代理在复杂网络环境中导航和执行动作时，由于对网络结构可见性和理解有限，效率低下。因此需要先进的导航和交互策略。

**Method:** R2D2框架集成了“记忆”和“反思”两个范式。“记忆”范式利用回放缓冲区动态重建网络环境，形成访问过的页面的详细“地图”，以减少导航错误和优化决策。“反思”范式则允许代理通过错误分析和策略改进从过去的错误中学习，从而提高整体任务性能。

**Result:** 在WebArena基准测试中，R2D2框架相对于现有方法取得了显著改进，包括导航错误减少了50%，任务完成率提高了三倍。

**Conclusion:** 结合记忆增强的导航和反思性学习能够有效地提升网络代理的能力，并有望应用于自动化客户服务和个人数字助理等领域。

> **ai_Abstract:** R2D2是一种新型网络代理框架，旨在解决复杂网络环境中现有模型导航效率低下的问题。它通过整合“记忆”和“反思”两大范式来提升性能。“记忆”范式利用回放缓冲区构建“地图”以减少导航错误，“反思”范式则通过错误分析和策略优化来提升学习能力。在WebArena基准测试中，R2D2展现出显著优势，将导航错误减少了50%，任务完成率提高了三倍，证明了记忆增强导航和反思性学习在提升网络代理能力方面的巨大潜力。

> **摘要翻译:** 网络代理的普及要求在复杂的网络环境中采用先进的导航和交互策略。当前模型由于对网络结构可见性和理解有限，常常难以实现高效导航和动作执行。我们提出的R2D2框架通过整合两种范式来解决这些挑战：记忆和反思。“记忆”范式使用一个回放缓冲区，帮助代理动态重建网络环境，从而能够形成之前访问页面的详细“地图”。这有助于减少导航错误，并优化网络交互过程中的决策。“反思”范式则允许代理通过提供错误分析和策略改进机制，从过去的错误中学习，从而提高整体任务性能。我们使用WebArena基准测试评估了R2D2，结果表明它比现有方法有显著改进，包括导航错误减少50%，任务完成率提高三倍。我们的研究结果表明，记忆增强导航和反思性学习的结合有望提升网络代理的能力，潜在地惠及自动化客户服务和个人数字助理等各种应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [181] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
> *TaxCalcBench：评估前沿模型在税务计算任务中的表现*

*Michael R. Bock, Kara Molisee, Zachary Ozer, Sumit Shah* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 税务计算, 基准测试, 大型语言模型, 个人所得税, AI评估

**Comment:** 

> **TL;DR:** AI目前无法准确计算美国个人所得税，TaxCalcBench基准测试显示SOTA模型表现不佳，需要更多基础设施支持LLM在该任务上的应用。

**AI_Comments:** TaxCalcBench的提出填补了评估AI在税务计算这一特定且复杂领域能力的空白。其发现突出了当前LLM在处理需要精确计算和复杂规则理解任务时的局限性，特别是对细节的掌握和避免“幻觉”的能力。这对于推动LLM在金融和法律等高精度要求领域的应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估AI在计算美国个人所得税方面的能力，因为这是一个需要理解大量文本并精确计算的任务，且现有模型表现未知。

**Method:** 提出TaxCalcBench，一个用于评估模型在给定所有必要信息的情况下计算个人所得税申报表能力的基准测试。

**Result:** 实验表明，即使在简化的样本集上，最先进的模型也未能成功计算出不到三分之一的联邦所得税申报表。分析发现模型普遍存在误用税表、计算错误和资格判定不准确的问题。

**Conclusion:** 现有模型在个人所得税计算任务上表现不佳，需要额外的基础设施来更好地应用大型语言模型（LLMs）解决此问题。

> **ai_Abstract:** 本文提出了TaxCalcBench，一个评估AI模型计算美国个人所得税能力的基准测试。实验结果显示，即使是SOTA模型在简化数据集上，也仅能正确计算不到三分之一的联邦所得税申报表，主要问题在于误用税表、计算错误和资格判定不准确。这表明需要进一步的基础设施支持LLM在该复杂任务上的应用。

> **摘要翻译:** AI能报税吗？目前还不能。计算美国个人所得税是一项需要理解大量英文文本并利用这些知识进行精确计算的任务。我们提出了 TaxCalcBench，这是一个用于评估模型在给定所有必要信息的情况下计算个人所得税申报表能力的基准测试。我们的实验表明，即使在这个简化的样本集上，最先进的模型也未能成功计算出不到三分之一的联邦所得税申报表。我们的分析得出结论，模型普遍存在误用税表、计算错误和资格判定不准确的问题。我们的发现指出，需要额外的基础设施来将大型语言模型应用于个人所得税计算任务。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [187] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
> *基于知识图谱的智能体RAG在真实世界应用中进行复杂多跳推理*

*Jean Lelong, Adnane Errazine, Annabelle Blangero* | **Category: cs.AI, cs.IR** | **Updated: 2025-07-22**

**Keywords:** 智能体RAG, 知识图谱, 多跳推理, LLMs, INRAExplorer

**Comment:** ECAI 2025 demo track, 4 pages

> **TL;DR:** INRAExplorer是一个智能体RAG系统，它结合LLM智能体和知识图谱，解决了传统RAG系统在处理复杂查询和多跳推理方面的不足，并在INRAE的科学数据探索中取得了成功。

**AI_Comments:** 该论文通过引入INRAExplorer系统，创新性地结合了智能体（Agentic）RAG和知识图谱，有效解决了传统RAG系统在处理复杂查询和多跳推理方面的局限性。其在真实世界应用（INRAE科学数据）中的具体实现，展示了在专业领域提升知识交互的巨大潜力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的检索增强生成（RAG）系统在处理复杂查询时表现不佳，提供有限的提取性答案，并且难以进行多重定向检索或导航复杂的实体关系，这在知识密集型领域是一个关键的空白。

**Method:** 我们引入了INRAExplorer，这是一个用于探索INRAE（法国国家农业、食品和环境研究所）科学数据的智能体RAG系统。INRAExplorer采用基于LLM的智能体和多工具架构，通过从开放获取的INRAE出版物中提取的综合知识图谱来动态地与丰富的知识库交互。

**Result:** INRAExplorer能够进行迭代的、有针对性的查询，检索详尽的数据集（例如，某作者的所有出版物），执行多跳推理，并提供结构化、全面的答案。

**Conclusion:** INRAExplorer作为增强专业领域知识交互的一个具体实例。

> **ai_Abstract:** 本论文介绍了INRAExplorer，一个为法国国家农业、食品和环境研究所（INRAE）设计，用于探索其科学数据的智能体检索增强生成（RAG）系统。针对传统RAG系统在处理复杂查询、多跳推理和导航复杂实体关系方面的不足，INRAExplorer采用基于大型语言模型（LLM）的智能体和多工具架构，通过利用源自INRAE开放出版物的综合知识图谱来动态交互知识库。这种设计使INRAExplorer能够执行迭代、有针对性的查询，检索详尽的数据集，并提供结构化、全面的答案，从而显著增强了专业领域的知识交互能力。

> **摘要翻译:** 传统检索增强生成（RAG）系统虽然能增强大型语言模型（LLMs），但在处理复杂查询时往往表现不足，提供有限的、提取性的答案，并且难以进行多重定向检索或导航复杂的实体关系。这在知识密集型领域是一个关键的空白。我们引入了INRAExplorer，一个用于探索INRAE（法国国家农业、食品和环境研究所）科学数据的智能体RAG系统。INRAExplorer采用基于LLM的智能体和多工具架构，通过从开放获取的INRAE出版物中提取的综合知识图谱来动态地与丰富的知识库交互。这种设计使INRAExplorer能够进行迭代的、有针对性的查询，检索详尽的数据集（例如，某作者的所有出版物），执行多跳推理，并提供结构化、全面的答案。INRAExplorer作为增强专业领域知识交互的一个具体实例。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [199] [InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://arxiv.org/abs/2505.16938)
> *InternAgent：当智能体成为科学家——构建从假设到验证的闭环系统*

*InternAgent Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Runmin Ma, Yusong Hu, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 自主科学研究, 多智能体系统, 闭环系统, 科学发现, 人工智能

**Comment:** Code: https://github.com/Alpha-Innovator/InternAgent, HomePage:
  https://alpha-innovator.github.io/InternAgent-project-page

> **TL;DR:** InternAgent是一个统一的闭环多智能体框架，用于自主科学研究（ASR），在多个领域展现出可扩展性、交互性和高效率，显著加速了科学发现并提升了基线性能。

**AI_Comments:** InternAgent的创新之处在于其构建了一个统一的闭环多智能体框架，将AI智能体提升到“科学家”的地位，实现了从假设到验证的自主科学研究。其强调的可扩展性、交互性（引入人类反馈）和效率是其重要优势，尤其是在多个领域取得的显著性能提升，预示着AI在科学发现中扮演更核心角色的巨大潜力。然而，抽象中并未提及该框架的局限性或未来可能面临的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能正在加速科学研究范式的转型，提升研究效率并推动创新。为了让研究人员能够以前所未有的速度和精度解决复杂问题，需要一个能够进行自主科学研究的系统。

**Method:** 本文提出了InternAgent，一个统一的闭环多智能体框架，用于在各种科学研究领域进行自主科学研究（ASR）。该框架支持人类专家反馈和多智能体交互，以实现自动化端到端流程。

**Result:** InternAgent在12项科学研究任务中展现了通用性，并能生成创新想法以提升基线代码性能。具体性能提升包括：在反应产率预测中，12小时内从27.6%提升到35.4%；在增强子活性预测中，4小时内准确率从0.65提高到0.79；在2D语义分割中，30小时内精度从78.8%提升到81.0%。

**Conclusion:** InternAgent作为一个统一的闭环多智能体框架，在自主科学研究方面表现出色，具有显著的可扩展性、交互性和效率优势，能够大幅加速科学发现并提升研究质量。

> **ai_Abstract:** InternAgent是一个创新的统一闭环多智能体框架，旨在实现自主科学研究（ASR）。该系统通过整合人类专家反馈和多智能体交互，显著提升了科学研究的效率、速度和精度。它在12项不同的科学任务中验证了其可扩展性，并展示了在多个领域（如反应产率预测、增强子活性预测和2D语义分割）中显著优于人类努力的性能提升，从而加速了科学发现过程。

> **摘要翻译:** 人工智能（AI）正在加速科学研究范式的转型，不仅提高了研究效率，也推动了创新。我们引入了InternAgent，一个统一的闭环多智能体框架，用于在各种科学研究领域进行自主科学研究（ASR），使研究人员能够以前所未有的速度和精度解决这些领域中的复杂问题。InternAgent突出显示了三个关键优势：1）可扩展性：InternAgent在12项科学研究任务中展示了其通用性，能够生成创新想法以提高基线代码的性能。2）交互性：InternAgent在自动化端到端流程中提供了人类专家反馈和多智能体交互的接口，从而实现了领域专家知识的无缝集成。3）效率：与人类努力相比，InternAgent在多个科学领域以显著更少的时间成本取得了可喜的性能提升。例如，在反应产率预测中，它在短短12小时内从27.6%增加到35.4%；在增强子活性预测中，精度在仅4小时的处理后从0.65上升到0.79；在2D语义分割中，精度在短短30小时内从78.8%提高到81.0%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [226] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
> *SpiroLLM：微调预训练大型语言模型以理解肺活量图时间序列并在慢阻肺报告中进行临床验证*

*Shuhao Mei, Yongchao Long, Shan Cao, Xiaobo Han, Shijia Geng, Jinbo Sun, Yuxi Zhou, Shenda Hong* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 肺活量图, 大型语言模型, 慢阻肺, 多模态AI, 临床决策支持

**Comment:** 

> **TL;DR:** SpiroLLM是首个能够理解肺活量图的多模态大型语言模型，通过结合生理信号和LLM，提高了慢阻肺诊断的准确性和报告的可解释性。

**AI_Comments:** SpiroLLM的创新之处在于首次将生理时间序列数据（肺活量图）与大型语言模型深度融合，解决了现有AI模型缺乏解释性和LLM无法理解此类医学数据的痛点。其多模态设计显著提高了在数据缺失情况下的鲁棒性，为开发更可靠、可信赖的临床决策支持工具开辟了新路径，具有重要的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 目前用于慢阻肺（COPD）诊断的AI模型缺乏诊断过程的理由，且现有大型语言模型（LLM）无法理解肺活量图时间序列，这严重限制了它们在临床中的信任和应用。肺活量图在呼吸系统疾病的早期检测和肺功能监测中至关重要。

**Method:** 提出了SpiroLLM，这是一个多模态大型语言模型，利用英国生物样本库（UKB）的234,028名个体数据。该模型通过SpiroEncoder从呼吸曲线中提取形态特征，并使用SpiroProjector将这些特征与肺功能测试（PFT）数值在统一的潜在空间中对齐，最终使大型语言模型能够生成全面的诊断报告。

**Result:** SpiroLLM在诊断中实现了0.8980的AUROC（95% CI: 0.8820-0.9132）。在核心数据缺失的鲁棒性测试中，它保持了100%的有效响应率，远超纯文本模型的13.4%。

**Conclusion:** 这项工作展示了将生理信号与大型语言模型深度融合的巨大潜力，为下一代可解释和可靠的临床决策支持工具建立了新的范式。

> **ai_Abstract:** SpiroLLM是首个针对慢阻肺（COPD）诊断而设计的、能够理解肺活量图时间序列的多模态大型语言模型。它通过SpiroEncoder提取呼吸曲线特征，并使用SpiroProjector与肺功能测试（PFT）数值对齐，从而使LLM能生成详细的诊断报告。该模型在UK Biobank数据集上实现了0.8980的AUROC，并在数据缺失情况下表现出卓越的鲁棒性，突显了结合生理信号与LLM在可解释临床决策支持中的潜力。

> **摘要翻译:** 慢性阻塞性肺疾病（COPD）是一种主要的慢性呼吸系统疾病，具有持续性气流受限，是全球致残和死亡的主要原因。呼吸肺活量图时间序列在肺功能测试（PFT）中常规收集，在呼吸系统疾病的早期检测和长期肺功能监测中发挥关键作用。然而，目前大多数用于COPD诊断的AI模型仅限于输出分类结果，而未能提供其诊断过程的理由，同时当前的大型语言模型（LLM）尚无法理解肺活量图，这严重限制了它们的临床信任和采用。为了解决这一挑战，我们利用来自英国生物样本库（UKB）的234,028名个体队列，提出了SpiroLLM，这是第一个能够理解肺活量图的多模态大型语言模型。该模型通过SpiroEncoder从呼吸曲线中提取形态特征，并使用SpiroProjector将其与PFT数值在统一的潜在空间中对齐，最终使大型语言模型能够生成全面的诊断报告。实验结果证实，SpiroLLM的诊断AUROC达到了0.8980（95% CI: 0.8820-0.9132）。在核心数据缺失的鲁棒性测试中，它保持了100%的有效响应率，远超纯文本模型的13.4%，展示了其多模态设计的优越性。这项工作展示了将生理信号与大型语言模型深度融合的巨大潜力，为下一代可解释和可靠的临床决策支持工具建立了新范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [229] [DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph](https://arxiv.org/abs/2505.19956)
> *DCG-SQL：通过深度上下文模式链接图增强Text-to-SQL的上下文学习*

*Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** Text-to-SQL, 上下文学习, 深度上下文模式链接图, 大型语言模型, 示例检索

**Comment:** 

> **TL;DR:** DCG-SQL通过构建深度上下文模式链接图，有效检索Text-to-SQL的上下文学习示例，提升大小LLM性能。

**AI_Comments:** 这篇论文的创新点在于提出了深度上下文模式链接图（DCG-SQL），它通过构建结构化的图来捕捉Text-to-SQL任务中问题与数据库模式项之间的语义关系，从而解决了现有上下文学习方法在示例检索效率和对小型LLM支持上的不足。这对于降低Text-to-SQL任务对超大型模型的依赖，并提升小型模型在该任务上的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有Text-to-SQL的上下文学习方法在随机选择示例时性能提升不明显，且在使用小型LLM时性能显著下降，这表明它们过度依赖超大型LLM的内在能力而非有效检索有用示例。

**Method:** 提出DCG-SQL方法，通过构建一个深度上下文模式链接图（Deep Contextual Schema Link Graph），包含问题与其数据库模式项之间的关键信息和语义关系，从而有效表示Text-to-SQL样本并检索有用的上下文学习示例。

**Result:** 在Spider基准测试上，DCG-SQL在SQL生成性能和效率方面显示出一致的改进，适用于超大型LLM和小型LLM。

**Conclusion:** DCG-SQL通过有效检索上下文学习示例，显著提升了Text-to-SQL任务中大型语言模型的性能和效率，尤其是在小型模型上。

> **ai_Abstract:** 本文针对Text-to-SQL任务中大型语言模型上下文学习的现有问题，即对超大型LLM的过度依赖和小型LLM的性能下降，提出了一种名为DCG-SQL的新方法。DCG-SQL通过构建深度上下文模式链接图，有效捕捉问题与数据库模式项之间的关系，从而实现对Text-to-SQL样本的有效表示和有用示例的检索。实验证明，该方法在Spider基准测试上显著提升了SQL生成性能和效率，并适用于不同规模的LLM。

> **摘要翻译:** Text-to-SQL（将自然语言问题翻译成SQL查询）随着大型语言模型（LLMs）的上下文学习而取得了进展。然而，现有方法与随机选择的示例相比，性能提升微乎其微，并且在使用较小的LLM（例如Llama 3.1-8B）时性能显著下降。这表明这些方法严重依赖于超大型LLM的内在能力，而不是有效地检索有用的示例。在本文中，我们提出了一种有效检索示例并生成SQL查询的新方法。我们构建了一个深度上下文模式链接图（Deep Contextual Schema Link Graph），其中包含问题与其数据库模式项之间的关键信息和语义关系。这种基于图的结构能够有效表示Text-to-SQL样本，并为上下文学习检索有用的示例。在Spider基准测试上的实验结果表明，我们的方法是有效的，在超大型LLM和小型LLM上，SQL生成性能和效率都得到了持续改进。代码可在https://github.com/jjklle/DCG-SQL获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [232] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
> *前沿AI风险管理框架实践：风险分析技术报告*

*Shanghai AI Lab, :, Xiaoyang Chen, Yunhao Chen, Zeren Chen, Zhiyun Chen, Hanyun Cui, Yawen Duan, Jiaxuan Guo, Qi Guo, Xuhao Hu, Hong Huang, Lige Huang, Chunxiao Li, Juncheng Li, Qihao Lin, Dongrui Liu, Xinmin Liu, Zicheng Liu, Chaochao Lu, Xiaoya Lu, Jingjing Qu, Qibing Ren, Jing Shao, Jingwei Shi, Jingwei Sun, Peng Wang, Weibing Wang, Jia Xu, Lewen Yan, Xiao Yu, Yi Yu, Boxuan Zhang, Jie Zhang, Weichen Zhang, Zhijie Zheng, Tianyi Zhou, Bowen Zhou* | **Category: cs.AI, cs.CL, cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 前沿AI风险, 风险管理框架, AI安全, 风险评估

**Comment:** 97 pages, 37 figures

> **TL;DR:** 本报告基于E-T-C分析和AI-45°法则，评估了前沿AI模型的七大风险，并将风险分为绿、黄、红区。结果显示当前模型主要处于绿区和黄区，未触及红线，但需持续关注和协作缓解风险。

**AI_Comments:** 该报告提供了一个实用的前沿AI风险管理框架，通过引入E-T-C分析、AI-45°法则以及红黄线风险区划分，为AI风险评估提供了结构化的方法。其创新之处在于将复杂的AI风险具体化为七个维度并进行量化评估。尽管评估结果显示当前模型风险可控，但报告明确指出了说服与操纵、生物化学风险等需要重点关注的领域，具有重要的实践指导意义。然而，部分风险评估的初步性质以及对更详细威胁建模的需求，提示了该框架未来迭代和完善的空间。

<details>
  <summary>Details</summary>

**Motivation:** 为理解和识别快速发展的人工智能（AI）模型所带来的前所未有的风险，本报告对前沿风险进行了全面评估。

**Method:** 本研究借鉴了《前沿AI风险管理框架》（v1.0）中的E-T-C分析（部署环境、威胁来源、赋能能力），识别了七个关键风险领域：网络攻击、生物和化学风险、说服与操纵、不受控的自主AI研发、战略欺骗与谋划、自我复制和共谋。研究遵循“AI-45°法则”，通过“红线”（不可容忍的阈值）和“黄线”（早期预警指标）来评估这些风险，并定义了风险区域：绿色（常规部署和持续监控下的可控风险）、黄色（需要加强缓解措施和受控部署）、红色（需要暂停开发和/或部署）。

**Result:** 实验结果表明，所有近期前沿AI模型都处于绿色和黄色区域，没有越过红线。具体而言，没有评估模型越过网络攻击或不受控AI研发风险的黄线。对于自我复制以及战略欺骗和谋划，大多数模型仍处于绿色区域，除了某些推理模型处于黄色区域。在说服和操纵方面，大多数模型因其对人类的有效影响而处于黄色区域。对于生物和化学风险，虽然需要详细的威胁建模和深入评估才能做出进一步判断，但我们无法排除大多数模型处于黄色区域的可能性。

**Conclusion:** 这项工作反映了我们当前对AI前沿风险的理解，并敦促采取集体行动来缓解这些挑战。

> **ai_Abstract:** 本报告提出了一套基于E-T-C分析和“AI-45°法则”的前沿AI风险管理框架，旨在识别和评估快速发展AI模型带来的七大关键风险。通过定义红线、黄线和绿色区域，该框架对现有前沿AI模型进行了风险评估。结果显示，当前模型主要处于绿色和黄色风险区域，未触及红线，但特别指出在说服与操纵、以及生物和化学风险方面，多数模型处于黄色区域，需要进一步关注和详细评估。报告强调了对AI前沿风险的持续理解和集体缓解行动的必要性。

> **摘要翻译:** 为了理解和识别快速发展的人工智能（AI）模型所带来的前所未有的风险，本报告对它们的前沿风险进行了全面评估。借鉴《前沿AI风险管理框架》（v1.0）（SafeWork-F1-Framework）中的E-T-C分析（部署环境、威胁来源、赋能能力），我们识别了七个关键风险领域：网络攻击、生物和化学风险、说服与操纵、不受控的自主AI研发、战略欺骗与谋划、自我复制和共谋。在“AI-45°法则”的指导下，我们使用“红线”（不可容忍的阈值）和“黄线”（早期预警指标）来评估这些风险，从而定义了风险区域：绿色（常规部署和持续监控下的可控风险）、黄色（需要加强缓解措施和受控部署）和红色（需要暂停开发和/或部署）。实验结果表明，所有近期前沿AI模型都处于绿色和黄色区域，没有越过红线。具体而言，没有评估模型越过网络攻击或不受控AI研发风险的黄线。对于自我复制以及战略欺骗和谋划，大多数模型仍处于绿色区域，除了某些推理模型处于黄色区域。在说服和操纵方面，大多数模型因其对人类的有效影响而处于黄色区域。对于生物和化学风险，尽管需要详细的威胁建模和深入评估才能做出进一步判断，但我们无法排除大多数模型处于黄色区域的可能性。这项工作反映了我们当前对AI前沿风险的理解，并敦促采取集体行动来缓解这些挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [242] [Toward A Causal Framework for Modeling Perception](https://arxiv.org/abs/2401.13408)
> *迈向感知建模的因果框架*

*Jose M. Alvarez, Salvatore Ruggieri* | **Category: cs.AI, cs.CY, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 感知, 因果建模, 机器学习, 结构因果模型, 公平机器学习

**Comment:** arXiv admin note: text overlap with arXiv:2305.09535 by other authors

> **TL;DR:** 该论文提出了一个用于建模人类感知的因果框架，以解决机器学习中人类专家对相同信息不同解读的问题，并强调了其在公平机器学习中的重要性。

**AI_Comments:** 该论文通过引入因果框架来建模人类感知，填补了机器学习领域的一个重要空白，尤其是在处理人类决策偏差方面。其创新之处在于将个体经验融入结构因果模型中，以量化和区分不同类型的感知。该工作对于提升机器学习系统在真实世界中的鲁棒性和公平性具有重要意义，因为它直接解决了人类与AI交互中固有的认知差异。

<details>
  <summary>Details</summary>

**Motivation:** 个体对相同信息有不同的解读，这种感知现象在机器学习（ML）中仍未得到充分研究，但现代决策流程总是涉及人类专家，他们可能对ML模型的输出有不同的解读，导致偏差。因此，需要一种能够与ML驱动的决策流程相结合的感知表述方式。

**Method:** 提出了第一个因果建模感知的方法。使用结构因果模型（SCM）在因果推理下定义感知。将个体经验形式化为专家决策者所拥有和使用的额外因果知识，表现为SCM。定义了两种概率因果感知：结构感知和参数感知。

**Result:** 通过一系列现代决策流程的例子展示了该框架。强调了在公平机器学习中解决感知问题的重要性，并讨论了相关的公平性影响和可能的应用。

**Conclusion:** 本研究提出了一个初步的因果感知建模方法，为解决机器学习中人类感知差异带来的挑战提供了一个新视角，尤其在公平机器学习领域具有重要意义。

> **ai_Abstract:** 本文提出了一种新颖的因果框架来建模人类感知，以解决机器学习（ML）中人类专家对相同信息不同解读的问题。该框架利用结构因果模型（SCM）来形式化感知，将个体经验视为SCM中的额外因果知识，并区分了结构感知和参数感知两种类型。研究通过现代决策流程的例子展示了该框架的实用性，并强调了其在公平机器学习领域的重要性及其对公平性的影响。

> **摘要翻译:** 当个体对相同信息有不同解读时，感知便会发生。这是一种已知的认知现象，对人类决策中的偏见有影响。然而，感知在机器学习（ML）中仍未得到充分研究。这是一个问题，因为现代决策流程，无论是部分还是完全由ML应用自动化，总是涉及人类专家。我们如何解释两个专家，例如，对ML模型的相同延迟实例或解释有不同解读的情况？解决这个问题以及类似问题需要对感知进行表述，特别是以一种能与ML驱动的决策流程相结合的方式。在这项工作中，我们提出了第一个因果建模感知的方法。我们使用结构因果模型（SCM）在因果推理下定义感知。我们的方法将个体经验形式化为专家决策者所拥有和使用的额外因果知识，表现为SCM。我们定义了两种概率因果感知：结构感知和参数感知。我们通过一系列现代决策流程的例子展示了我们的框架。我们还强调了在公平机器学习中解决感知问题的重要性，讨论了相关的公平性影响和可能的应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [258] [The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning](https://arxiv.org/abs/2506.02139)
> *语言模型的统一认知意识理论：语义锚定、激活阈值与涌现推理*

*Edward Y. Chang, Zeyneb N. Kaya, Ethan Chang* | **Category: cs.AI, I.2.7** | **Updated: 2025-07-22**

**Keywords:** 统一认知意识理论, 大型语言模型, 语义锚定, 激活阈值, 涌现推理

**Comment:** 13 pages, 4 figure, 2 table

> **TL;DR:** 提出统一认知意识理论（UCCT），将LLM视为无意识基质，其智能通过外部机制的语义锚定而涌现，并解释了能力突变。

**AI_Comments:** 这篇论文提出了一种新颖的视角，将大型语言模型视为“无意识”的基质，并强调了外部机制在赋予其“意识”和智能方面的关键作用。UCCT的创新之处在于其统一了多种现有技术（如少样本提示、RAG）在一个理论框架下，并解释了LLM能力突变的现象。这种理论化的尝试对于理解LLM的深层工作机制及其智能的本质具有重要意义，有助于指导未来LLM能力提升和应用的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽拥有大量潜在模式，但缺乏结构化指导时，它们缺乏明确的推理能力、语义基础和目标导向的智能。

**Method:** 本文提出了统一认知意识理论（UCCT），它将大型语言模型（LLMs）重新解释为需要外部机制（如少样本提示、RAG、微调和多智能体推理）来语义锚定潜在表示的无意识基质。UCCT通过贝叶斯公式形式化了这一锚定过程，并揭示了一种以1/√n比例缩放为特征的阈值交叉动态。

**Result:** UCCT解释了在不同任务中观察到的能力突然转变，并统一了之前分散的技术（少样本提示、RAG、微调和多智能体推理）作为通用锚定架构的特例。通过在简单数学、视觉识别和结构化辩论任务中的案例研究，以及在三种数字系统中的算术实验，证实了UCCT的预测能力和理论有效性。

**Conclusion:** 智能并非大型语言模型（LLMs）的内在属性，LLMs仅仅是无意识的模式存储库，不具备固有智能。智能只有当外部锚定机制将目标语义分配给这些潜在模式时才会涌现，从而将无意识的表示转化为有意识的、目标导向的能力。

> **ai_Abstract:** 本文提出了统一认知意识理论（UCCT），旨在解决大型语言模型（LLMs）在缺乏结构化指导时，推理能力、语义基础和目标导向智能的不足。UCCT将LLMs视为无意识的潜在模式存储库，强调其智能通过外部机制（如少样本提示、RAG、微调和多智能体推理）进行语义锚定后方能涌现。该理论通过贝叶斯公式形式化了锚定过程，并解释了LLMs能力突变的现象。研究通过多项案例研究验证了UCCT的预测能力，并得出结论：LLMs的智能并非固有，而是通过外部干预将无意识表示转化为有意识、目标导向能力的结果。

> **摘要翻译:** 大型语言模型（LLMs）是潜在模式的巨大存储库，但如果没有结构化指导，它们缺乏明确的推理、语义基础和目标导向的智能。我们提出了统一认知意识理论（UCCT），一个统一的模型，它将LLMs重新解释为需要外部机制（少样本提示、RAG、微调和多智能体推理）来语义锚定潜在表示的无意识基质。UCCT通过贝叶斯公式形式化了这一锚定过程，揭示了一种以1/√n比例缩放为特征的阈值交叉动态，解释了在不同任务中观察到的能力突然转变。该理论统一了之前分散的技术，少样本提示、RAG、微调和多智能体推理，作为通用锚定架构的特例。通过在简单数学、视觉识别和结构化辩论任务中的案例研究，我们证实了UCCT的预测能力。此外，我们在三种数字系统中的算术实验验证了UCCT的理论。UCCT表明，智能并非LLMs的内在属性，LLMs仅仅是无意识的模式存储库，不具备固有智能。智能只有当外部锚定机制将目标语义分配给这些潜在模式时才会涌现，从而将无意识的表示转化为有意识的、目标导向的能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [271] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
> *通过实现实现的涌现认知收敛：反映四种心智理论的结构化循环（一篇立场论文）*

*Myung Ho Kim* | **Category: cs.AI, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 认知融合, Agentic Flow, 心智理论, 大型语言模型, PEACE

**Comment:** 21 pages

> **TL;DR:** 本文发现名为Agentic Flow的AI代理架构在解决LLM局限性的过程中，无意中展现出与四种主流心智理论（卡尼曼的双系统理论、弗里斯顿的预测加工、明斯基的心智社会、克拉克的扩展心智）的结构性趋同，并通过实验验证了其在多步推理任务上的优越性。

**AI_Comments:** 本文的创新之处在于其“由下而上”的设计方法，即通过实际的AI系统构建，无意中发现了与现有认知理论的结构性趋同，而非传统地从理论出发进行系统设计。这提供了一个新的视角来理解AI与认知科学的交叉点，表明工程实践也能反哺理论洞察。其提出的Agentic Flow架构及其在多步推理任务上的表现，也展示了结构化设计在提升LLM代理能力方面的潜力。PEACE元架构的提出，则为未来类似系统的描述和分析提供了宝贵的通用词汇。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决大型语言模型（LLM）的局限性。

**Method:** 开发了一个名为Agentic Flow的AI代理架构，包含检索、认知、控制、记忆和行动五个相互依赖的模块，并将其安排在一个循环认知回路中。通过与基线LLM代理进行多步推理任务的比较实验。

**Result:** 结构化代理在任务成功率上达到95.8%，并表现出强大的约束依从性，而基线系统成功率为62.3%。这些结果旨在说明理论结构如何通过实际设计选择而非自上而下的理论而涌现。

**Conclusion:** 本文作为一篇立场论文，旨在探索性地反思实现如何揭示认知理论的潜在结构回响，而不主张理论统一。引入了PEACE作为一种描述性元架构，用于理解由实际实现需求塑造的架构。

> **ai_Abstract:** 本文介绍了一种名为Agentic Flow的AI代理架构，旨在弥补大型语言模型的不足。该架构包含五个相互关联的模块，形成一个循环认知回路。研究发现，Agentic Flow的结构无意中与卡尼曼、弗里斯顿、明斯基和克拉克等四种主流心智理论的计算模式相吻合。通过在多步推理任务上与基线LLM代理进行比较实验，Agentic Flow表现出显著更高的任务成功率（95.8% vs 62.3%）。本文强调，这种趋同是实际设计选择而非理论先导的结果。作者还提出了PEACE元架构，以提供理解此类由实际需求驱动的架构的通用语言，并将其定位为一篇探讨实现如何揭示认知理论潜在结构的立场论文。

> **摘要翻译:** 我们报告了在名为Agentic Flow的实用AI代理架构中，无意间发现四种有影响力的心智理论（卡尼曼的双系统理论、弗里斯顿的预测加工、明斯基的心智社会和克拉克的扩展心智）之间存在结构性趋同。Agentic Flow旨在解决大型语言模型（LLM）的局限性，由检索、认知、控制、记忆和行动等五个相互依赖的模块组成，并排列成一个循环认知回路。尽管最初仅受到明斯基和克拉克的启发，但该系统的结构回顾性地与所有四种理论中发现的计算模式相符，包括预测建模、联想回忆和误差敏感控制。
为了评估这种趋同，我们对基线LLM代理进行了多步推理任务的比较实验。结构化代理实现了95.8%的任务成功率并表现出强大的约束依从性，而基线系统成功率为62.3%。这些结果并非旨在证明优越性，而是为了说明理论结构如何通过实际设计选择而非自上而下的理论而涌现。
我们引入了PEACE作为一种描述性元架构，它捕获了在Agentic Flow中观察到的设计层面规律。PEACE并非旨在成为一种新理论，而是为理解受现实世界实现需求塑造的架构提供共享词汇。本文应被视为一篇立场论文——对实现如何揭示认知理论的潜在结构回响的探索性反思，而不主张理论统一。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [282] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
> *新型多智能体动作掩码深度强化学习用于通用工业装配线平衡问题*

*Ali Mohamed Ali, Luca Tirel, Hashim A. Hashim* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 多智能体, 动作掩码, 深度强化学习, 装配线平衡, 马尔可夫决策过程

**Comment:** 

> **TL;DR:** 本论文提出了一种新颖的多智能体动作掩码深度强化学习方法，用于解决通用工业装配线平衡问题，通过构建马尔可夫决策过程模型，并结合动作掩码和多智能体方法，实现了更快的收敛速度和可扩展的解决方案。

**AI_Comments:** 本文的创新点在于提出了一个通用的工业装配线MDP模型，摆脱了传统模型对装配线类型的假设。同时，引入动作掩码和多智能体协作机制显著提升了深度强化学习在解决复杂调度问题上的效率和可扩展性。集中式训练与分散式执行的框架也为工业应用提供了实时的解决方案能力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代工业装配线的高效规划对于维持制造标准、防止项目约束违规和实现成本效益运营至关重要。然而，整数规划(IP)在大型场景中计算上不可行，启发式方法（如遗传算法）在广泛情况下常产生次优解。因此，需要一种能够解决大型、通用工业装配线平衡问题的新方法。

**Method:** 论文提出了一种将通用工业装配线建模为马尔可夫决策过程(MDP)的新型数学模型，该模型不强加任何装配线类型假设。利用此模型创建了一个虚拟环境，用于训练深度强化学习(DRL)智能体以优化任务和资源调度。为提高训练效率，引入了两种创新工具：1. 动作掩码技术，确保智能体只选择可行动作，从而减少训练时间；2. 多智能体方法，每个工作站由一个独立智能体管理，从而减小状态和动作空间。采用了集中式训练和分散式执行的框架，智能体可以离线学习，并通过神经网络在操作期间提供实时解决方案。

**Result:** 通过数值模拟验证了所提出方案的有效性，结果表明与可比较的基于模型的方法相比，该方案收敛到最优解的速度显著加快。

**Conclusion:** 本研究成功开发了一种新颖的多智能体动作掩码深度强化学习框架，能够有效且可扩展地解决通用工业装配线平衡问题，并在数值模拟中展现出优越的收敛速度。

> **ai_Abstract:** 本论文提出了一种新颖的深度强化学习方法，旨在解决通用工业装配线平衡问题，以克服传统整数规划和启发式方法在大型场景中的局限性。研究首先将通用装配线建模为马尔可夫决策过程，并在此基础上构建虚拟环境训练DRL智能体。为提升训练效率，引入了动作掩码技术以确保动作可行性并缩短训练时间，同时采用多智能体方法（每个工作站一个智能体）来缩小状态和动作空间。该方法采用集中式训练和分散式执行框架，支持离线学习和实时决策。数值模拟结果表明，该方法比现有模型能更快地收敛到最优解。

> **摘要翻译:** 活动的高效规划对于现代工业装配线至关重要，以维护制造标准、防止项目约束违规并实现成本效益运营。虽然通过整数规划（IP）可以获得此类挑战的精确解决方案，但搜索空间对输入参数的依赖性常常使IP在大型场景中计算上不可行。启发式方法，例如遗传算法，也可以应用，但它们在广泛情况下经常产生次优解。本文介绍了一种通用的工业装配线的新型数学模型，该模型被表述为马尔可夫决策过程（MDP），并且不强加任何关于装配线类型的假设，这与大多数现有模型显著不同。所提出的模型用于创建一个虚拟环境，以训练深度强化学习（DRL）智能体来优化任务和资源调度。为了提高智能体训练的效率，本文提出了两种创新工具。第一个是动作掩码技术，它确保智能体只选择可行的动作，从而减少训练时间。第二个是多智能体方法，其中每个工作站由一个独立的智能体管理，因此状态和动作空间得以减小。采用了集中式训练与分散式执行的框架，为优化工业装配线提供了可扩展的学习架构。该框架允许智能体离线学习，随后通过利用将当前工厂状态映射到最优动作的神经网络，在操作期间提供实时解决方案。所提出方案的有效性通过数值模拟得到验证，与可比较的基于模型的方法相比，收敛到最优解的速度显著加快。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [294] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
> *分层推理模型*

*Guan Wang, Jin Li, Yuhao Sun, Xing Chen, Changling Liu, Yue Wu, Meng Lu, Sen Song, Yasin Abbasi Yadkori* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 分层推理模型, 循环架构, 复杂推理, 通用人工智能, 计算效率

**Comment:** 

> **TL;DR:** 本文提出了一种名为分层推理模型（HRM）的新型循环架构，它通过高低两级模块实现深度计算，解决了现有大型语言模型在复杂推理任务中效率低下、数据需求大等问题，并在少量训练数据下取得了卓越性能。

**AI_Comments:** HRM的创新之处在于其模仿人脑的分层处理机制，通过高低两级循环模块实现高效且稳定的推理。其重要性在于，它在极低的参数量和数据需求下，展现了超越现有大型模型的推理能力，尤其是在无需预训练和CoT数据的情况下，这对于推动通用人工智能的发展具有重要意义。该模型在效率和数据效率方面的优势是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 推理是AI领域一个关键挑战，当前大型语言模型（LLMs）主要采用的思维链（CoT）技术存在任务分解脆弱、数据需求量大和延迟高等问题，因此需要一种更高效、更稳定的推理模型。

**Method:** 本文提出了一种名为分层推理模型（HRM）的新型循环架构，它受到人脑分层和多时间尺度处理的启发。HRM通过两个相互依赖的循环模块在单次前向传播中执行顺序推理任务，而无需中间过程的显式监督：一个负责慢速、抽象规划的高级模块，以及一个处理快速、详细计算的低级模块。

**Result:** HRM仅用2700万参数和1000个训练样本就在复杂推理任务上取得了卓越性能。该模型无需预训练或CoT数据，但在复杂数独和大型迷宫中的最优路径查找等挑战性任务上达到了接近完美的性能。此外，HRM在抽象与推理语料库（ARC）上超越了上下文窗口更长、规模更大的模型。

**Conclusion:** HRM的成果突显了其作为迈向通用计算和通用推理系统的变革性进展的潜力。

> **ai_Abstract:** 本文提出了一种名为分层推理模型（HRM）的新型循环架构，旨在解决当前大型语言模型在复杂推理任务中存在的效率和数据依赖问题。HRM受到人脑分层处理的启发，通过高层抽象规划和低层详细计算的两个模块，在单次前向传播中实现深度计算。该模型仅用少量参数和训练数据，便在复杂数独和迷宫寻路等任务上取得了优异性能，甚至超越了更大规模的模型，展现了其在通用推理系统方面的巨大潜力。

> **摘要翻译:** 推理，即设计和执行复杂面向目标的行动序列的过程，仍然是人工智能领域的一个关键挑战。当前的大型语言模型（LLMs）主要采用思维链（CoT）技术，该技术存在任务分解脆弱、数据需求量大和延迟高等问题。受人脑中分层和多时间尺度处理的启发，我们提出了一种名为分层推理模型（HRM）的新型循环架构，该架构在保持训练稳定性和效率的同时，实现了显著的计算深度。HRM通过两个相互依赖的循环模块，在单次前向传播中执行顺序推理任务，而无需中间过程的显式监督：一个负责慢速、抽象规划的高级模块，以及一个处理快速、详细计算的低级模块。HRM仅用2700万参数，并使用1000个训练样本，便在复杂推理任务上取得了卓越性能。该模型无需预训练或CoT数据，却在包括复杂数独谜题和大型迷宫中的最优路径查找等挑战性任务上达到了接近完美的性能。此外，HRM在抽象与推理语料库（ARC）这一衡量人工通用智能能力的关键基准上，超越了上下文窗口显著更长的更大模型。这些结果突显了HRM作为迈向通用计算和通用推理系统的变革性进展的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [311] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
> *CHIMERA：用于多功能RIS辅助空天地一体化网络的压缩混合智能双模型增强多智能体深度强化学习*

*Li-Hsiang Shen, Jyun-Jhe Huang* | **Category: cs.AI, eess.SP** | **Updated: 2025-07-22**

**Keywords:** 空天地一体化网络, 多功能可重构智能表面, 深度强化学习, 能量效率, CHIMERA

**Comment:** 

> **TL;DR:** 本文提出了CHIMERA，一个基于深度强化学习的框架，用于优化多功能RIS辅助空天地一体化网络的能量效率，并展示了其优于现有基准的性能。

**AI_Comments:** 本文通过将多功能RIS集成到SAGIN中，以提高能量效率，特别是解决了LEO卫星的能量问题，提出了一种创新方法。CHIMERA框架是一个新颖的贡献，它利用混合深度强化学习并结合压缩和共享来解决一个复杂的、高维的优化问题。其优势在于证明了其在各种基线上的卓越性能，验证了所提出的架构和学习算法的有效性。对通信和计算能耗的综合考虑使得该模型更加真实和全面。

<details>
  <summary>Details</summary>

**Motivation:** 解决低地球轨道（LEO）卫星在阴影区域的能量短缺问题；明确考虑空天地一体化网络（SAGIN）节点中的通信和计算能耗；最大化长期能量效率（EE）；解决一个高度非凸、非线性且包含混合离散-连续参数的复杂优化问题。

**Method:** 提出了一个由多功能可重构智能表面（MF-RIS）赋能的空天地一体化网络（SAGIN）架构，MF-RIS能够同时反射、放大和收集无线能量。制定了一个联合优化问题，旨在最大化MF-RIS参数（信号放大、相移、能量收集比和有源元件选择）和SAGIN参数（波束赋形矢量、高空平台站（HAPS）部署、用户关联和计算能力）下的长期能量效率。为了解决这个复杂问题，提出了CHIMERA（压缩混合智能双模型增强多智能体深度强化学习）框架，该框架集成了语义状态-动作压缩和混合强化学习下的参数化共享。

**Result:** 所提出的CHIMERA方案在最高能量效率方面显著优于传统基准，包括固定配置或非能量收集MF-RIS、传统RIS和无RIS情况，以及集中式和多智能体深度强化学习基线。所提出的SAGIN-MF-RIS架构由于其互补覆盖，实现了卓越的能量效率性能，并与独立的卫星、空中或地面部署相比具有显著优势。

**Conclusion:** CHIMERA框架和SAGIN-MF-RIS架构能够有效优化复杂集成网络中的能量效率，并表现出显著的性能提升。

> **ai_Abstract:** 本文提出了一种由多功能可重构智能表面（MF-RIS）赋能的空天地一体化网络（SAGIN）架构，旨在提高能量效率。该架构解决了低地球轨道（LEO）卫星的能量稀缺问题，并优化了通信和计算能耗。为了最大化长期能量效率，论文建立了一个复杂的联合优化问题，涵盖了MF-RIS和SAGIN参数。为解决此非凸问题，作者引入了CHIMERA框架，这是一种利用双模型增强多智能体深度强化学习的压缩混合智能方法，并结合了语义状态-动作压缩和参数化共享。仿真结果证实，CHIMERA在能量效率方面显著优于现有基准，突显了SAGIN-MF-RIS架构互补覆盖的优势。

> **摘要翻译:** 一个空天地一体化网络（SAGIN）架构被提出，该架构由多功能可重构智能表面（MF-RIS）赋能，能够同时反射、放大和收集无线能量。MF-RIS在解决在阴影区域运行的低地球轨道（LEO）卫星的能量短缺问题中发挥着关键作用，同时明确考虑了SAGIN节点中的通信和计算能耗。为了最大化长期能量效率（EE），我们对MF-RIS参数（包括信号放大、相移、能量收集比和有源元件选择）以及SAGIN参数（波束赋形矢量、高空平台站（HAPS）部署、用户关联和计算能力）进行了联合优化问题建模。所提出的问题是高度非凸、非线性的，并且包含混合离散-连续参数。为了解决这个问题，我们构思了一种压缩混合智能双模型增强多智能体深度强化学习（CHIMERA）框架，该框架集成了语义状态-动作压缩和混合强化学习下的参数化共享，以有效探索合适的复杂动作。仿真结果表明，所提出的CHIMERA方案在最高能量效率方面，显著优于传统基准，包括固定配置或非能量收集MF-RIS、传统RIS和无RIS情况，以及集中式和多智能体深度强化学习基线。此外，所提出的SAGIN-MF-RIS架构由于其互补覆盖，实现了卓越的能量效率性能，与独立的卫星、空中或地面部署相比，具有显著优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [328] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
> *用于法律争议分析的提示工程与多维知识图谱集成框架*

*Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo* | **Category: cs.AI, 68T50, 68T30, 91F20, I.2.7; I.2.4; K.5.1; H.3.3** | **Updated: 2025-07-22**

**Keywords:** 提示工程, 多维知识图谱, 法律争议分析, 大型语言模型, 法律概念检索

**Comment:** 19 pages,3 figures

> **TL;DR:** 本研究提出了一个结合提示工程和多维知识图谱的框架，以显著提高大型语言模型在法律争议分析中的表现，并引入了四种支持方法以实现精确的法律概念检索，实验结果显示在敏感性、特异性和引用准确性方面有显著提升。

**AI_Comments:** 这项研究的创新之处在于将提示工程与多维知识图谱深度融合，为LLMs在特定领域（如法律）的应用提供了强大的增强手段。其通过分层提示和多层知识图谱的设计，以及多种检索方法的结合，有效解决了LLMs在专业领域知识获取和推理的局限性，为构建更智能、更准确的法律辅助系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高大型语言模型（LLMs）在法律争议分析中的能力。

**Method:** 该框架结合了提示工程和多维知识图谱。具体包括一个三阶段分层提示结构（任务定义、知识背景、推理指导）和一个三层知识图谱（法律本体论、表示、实例层）。此外，还采用了四种支持方法来实现精确的法律概念检索：直接代码匹配、语义向量相似性、本体论路径推理和词法分割。

**Result:** 通过广泛测试，结果显示敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。

**Conclusion:** 该框架提供了更好的法律分析和对司法逻辑的理解，为智能法律辅助系统提供了一种新的技术方法。

> **ai_Abstract:** 本研究提出了一种将提示工程与多维知识图谱相结合的集成框架，旨在提升大型语言模型在法律争议分析方面的性能。该框架包含一个三阶段的提示结构和一个三层的知识图谱，并辅以四种法律概念检索方法。实验结果表明，该框架显著提高了分析的敏感性、特异性和引用准确性，为智能法律辅助系统提供了新的技术支持。

> **摘要翻译:** 本研究提出了一个结合提示工程与多维知识图谱的框架，以改进大型语言模型在法律争议分析中的表现。具体而言，该框架包括一个三阶段分层提示结构（任务定义、知识背景、推理指导）以及一个三层知识图谱（法律本体论、表示、实例层）。此外，四种支持方法实现了精确的法律概念检索：直接代码匹配、语义向量相似性、本体论路径推理和词法分割。通过广泛测试，结果显示出显著改进：敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。因此，该框架提供了更好的法律分析和对司法逻辑的理解，从而为智能法律辅助系统提供了一种新的技术方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [332] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
> *动态农产品供应链中基于深度强化学习的自适应库存策略*

*Amandeep Kaur, Gyan Prakash* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 深度强化学习, 库存管理, 农产品供应链, 不确定性, 易腐性

**Comment:** 

> **TL;DR:** 本研究提出一种新型深度强化学习算法，用于在需求和提前期不确定性下优化农产品供应链库存，提高整体利润并促进利益相关者协作。

**AI_Comments:** 本研究的创新之处在于提出了一个结合基于价值和基于策略的深度强化学习算法，以解决动态农产品供应链中复杂的库存管理问题。它不仅考虑了需求和提前期的不确定性以及产品的易腐性，还创新性地通过共享优化目标来激励利益相关者之间的协作，这是现有文献中未充分考虑的。这为解决实际农产品供应链中的多重挑战提供了一个实用的、数据驱动的解决方案，具有重要的理论和管理意义。

<details>
  <summary>Details</summary>

**Motivation:** 农产品生产和需求常受季节性波动影响，导致库存管理困难，易出现库存过剩或缺货。现有文献未考虑食品供应链各层级利益相关者之间的协调。此外，需求和提前期不确定性以及产品保质期增加了问题复杂性，使传统方法难以生成最优解。

**Method:** 本研究提出一种新颖的深度强化学习（DRL）算法，该算法结合了基于价值和基于策略的DRL方法的优点，用于不确定性下的库存优化。该算法通过共享最大化利润的优化目标，在考虑易腐性和不确定性的同时，激励利益相关者之间的协作。通过选择具有连续动作空间的最佳订货量，有效解决了库存优化挑战。使用新鲜农产品供应链的经验数据对算法进行了严格评估。

**Result:** 实验结果证实，在随机需求模式和提前期情景下，所提出的库存补货策略表现出改进的性能。该算法有效解决了库存优化挑战，并能通过协调利益相关者的利益和目标来激励协作。

**Conclusion:** 研究结果对政策制定者在不确定性下更有效地管理农产品库存具有管理启示。

> **ai_Abstract:** 本研究针对农产品供应链中因季节性波动、需求和提前期不确定性以及产品保质期导致的库存管理挑战和利益相关者协调不足的问题，提出了一种新型深度强化学习（DRL）算法。该算法结合了基于价值和基于策略的DRL方法，旨在优化不确定性下的库存，通过选择最优订货量来最大化整体利润并激励供应链各环节的协作。通过对新鲜农产品经验数据的评估，结果表明该策略在随机需求和提前期情景下表现出显著改进，为政策制定者提供了有效的管理启示。

> **摘要翻译:** 农产品生产和需求常受季节性波动影响。预测和管理应对这些变化的库存水平可能具有挑战性，导致库存过剩或缺货。此外，现有文献中未考虑食品供应链各层级利益相关者之间的协调。为了弥补这些研究空白，本研究关注需求和提前期不确定性下的农产品库存管理。通过实施有效的库存补货策略，可以最大化整个供应链的整体利润。然而，由于这些不确定性和产品的保质期，问题的复杂性增加，这使得实施传统方法来生成最优解集变得具有挑战性。因此，当前研究提出了一种新颖的深度强化学习（DRL）算法，该算法结合了基于价值和基于策略的DRL方法的优点，用于不确定性下的库存优化。所提出的算法通过共享最大化农产品供应链利润的优化目标，同时考虑易腐性和不确定性，激励利益相关者之间的协作。通过选择具有连续动作空间的最佳订货量，所提出的算法有效解决了库存优化挑战。为了严格评估该算法，本研究考虑了来自新鲜农产品供应链库存的经验数据。实验结果证实，在随机需求模式和提前期情景下，所提出的库存补货策略表现出改进的性能。研究结果对政策制定者在不确定性下更有效地管理农产品库存具有管理启示。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [357] [A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis](https://arxiv.org/abs/2507.08529)
> *一种用于罕见病诊断的多粒度概念稀疏激活与分层知识图谱融合框架*

*Mingda Zhang, Na Zhao, Jianglong Qin, Guoyu Ye, Ruixiang Tang* | **Category: cs.AI, cs.CL, 68T50, 92C50, 68T05, J.3; I.2.7; H.3.3; I.2.1** | **Updated: 2025-07-22**

**Keywords:** 罕见病诊断, 知识图谱, 稀疏激活, 医疗大型语言模型, 临床推理

**Comment:** 12 pages,3 figures

> **TL;DR:** 该研究提出了一种结合多粒度稀疏激活和分层知识图谱的框架，显著提高了医疗大型语言模型在罕见病诊断方面的准确性和推理能力，超越了临床阈值。

**AI_Comments:** 该论文的创新点在于结合了多粒度稀疏激活和分层知识图谱，以解决罕见病诊断中知识表示和推理的难题。其提出的四种匹配算法和五级回退策略体现了对概念激活精度的细致考量。实验结果显著，特别是诊断准确率超过临床阈值，显示了其在实际应用中的巨大潜力。这项工作对于推动医疗LLM在专业领域的应用具有重要意义，尤其是在罕见病这一复杂且数据稀缺的领域。

<details>
  <summary>Details</summary>

**Motivation:** 医疗大型语言模型在罕见病诊断方面面临知识表示不足、概念理解有限和临床推理受限等挑战。

**Method:** 该框架结合了多粒度稀疏激活和分层知识图谱。它采用四种互补的匹配算法，具有多样性控制和五级回退策略以实现精确的概念激活。一个三层知识图谱（分类学、临床特征、实例）提供结构化、最新的上下文。

**Result:** 在BioASQ罕见病数据集上的实验表明，BLEU分数提高了0.13，ROUGE提高了0.10，诊断准确率提高了0.25。最佳模型达到了0.92的准确率，超过了0.90的临床阈值。专家评估证实信息质量、推理和专业表达均有增强。

**Conclusion:** 该框架在减少罕见病患者的诊断历程方面显示出前景。

> **ai_Abstract:** 本研究提出了一种结合多粒度概念稀疏激活和分层知识图谱的框架，旨在解决医疗大型语言模型在罕见病诊断中面临的挑战。该框架通过多样性控制和回退策略实现精确概念激活，并利用三层知识图谱提供结构化上下文。实验结果表明，该框架显著提升了诊断准确率和相关指标，且达到了临床可接受的水平，有望缩短罕见病患者的诊断时间。

> **摘要翻译:** 罕见病诊断对于医疗大型语言模型来说仍然具有挑战性，原因在于知识表示不足、概念理解有限以及临床推理受限。我们提出了一种结合多粒度稀疏激活与分层知识图谱的框架。我们的方法采用四种互补的匹配算法，具有多样性控制和五级回退策略，以实现精确的概念激活。一个三层知识图谱（分类学、临床特征、实例）提供了结构化、最新的上下文。在BioASQ罕见病数据集上的实验表明显著改进：BLEU分数提高了0.13，ROUGE提高了0.10，诊断准确率提高了0.25，其中最佳模型达到了0.92的准确率——超过了0.90的临床阈值。专家评估证实信息质量、推理和专业表达均有增强。我们的框架在减少罕见病患者的诊断历程方面显示出前景。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [360] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
> *基于语音的AI代理：弥合数字健康交付中的经济鸿沟*

*Bo Wen, Chen Wang, Qiwei Han, Raquel Norel, Julia Liu, Thaddeus Stappenbeck, Jeffrey L. Rogers* | **Category: cs.AI, cs.CY, cs.HC, cs.SE** | **Updated: 2025-07-22**

**Keywords:** 语音AI代理, 数字健康, 经济模型, 患者监测, 可及性

**Comment:** IEEE International Conference on Digital Health (ICDH) 2025

> **TL;DR:** 本文探讨了基于LLM的语音AI代理在弥合数字健康交付中的经济和可及性差距方面的作用，通过Agent PULSE的开发和试点研究，展示了其成本效益和患者接受度，并分析了技术和政策挑战。

**AI_Comments:** 本文的创新之处在于通过Agent PULSE的试点研究和经济模型，具体展示了LLM驱动的语音AI代理在弥合数字健康经济和可及性差距方面的实际应用和潜在效益。其重要性在于为医疗保健领域提供了一种成本效益高、可扩展的解决方案，特别是在服务不足人群的预防性护理和持续监测方面。同时，文章也坦诚地讨论了技术挑战和政策考量，这为未来的AI开发和部署提供了重要的指导。

<details>
  <summary>Details</summary>

**Motivation:** 数字健康交付中存在经济和可及性差距，尤其是在服务不足的人群中，人工干预在经济上不可行，需要成本效益高的解决方案。

**Method:** 开发并进行了Agent PULSE（患者理解与联络支持引擎）的试点研究，这是一个由IBM Research、Cleveland Clinic Foundation和Morehouse School of Medicine合作的LLM驱动的语音助手。同时，提出了一个经济模型来证明AI代理的成本效益。

**Result:** 对33名炎症性肠病患者的试点研究显示，70%的患者接受了AI驱动的监测，37%的患者表示更喜欢它而非传统方式。经济模型表明，AI代理在常规监测任务中具有巨大的潜在成本节约。

**Conclusion:** AI驱动的语音代理不仅能提高医疗保健的可扩展性和效率，还能改善患者参与度和可及性，为医疗保健高管带来潜在的成本节约，并为技术人员提供框架以优先改进。它们可以作为实现公平、可持续数字医疗保健解决方案的关键切入点。

> **ai_Abstract:** 本文探讨了基于大型语言模型（LLM）的语音AI代理在弥合数字健康交付中的经济和可及性差距方面的潜力。通过Agent PULSE的开发与试点研究，该研究展示了AI代理在提供成本效益高且可扩展的医疗服务方面的能力，尤其是在人工干预经济上不可行的情况下。试点研究显示患者对AI驱动监测的接受度高，并强调了其在提高效率、患者参与度和可及性方面的作用。文章还分析了相关的技术挑战和政策考量，并提出AI语音代理可作为实现公平、可持续数字医疗保健的关键入口。

> **摘要翻译:** 基于语音的AI代理：弥合数字健康交付中的经济鸿沟

将基于语音的AI代理整合到医疗保健中，为弥合数字健康交付中的经济和可及性差距提供了变革性机遇。本文探讨了大型语言模型（LLM）驱动的语音助手在增强预防性护理和持续患者监测方面的作用，特别是在服务不足的人群中。我们从Agent PULSE（患者理解与联络支持引擎）的开发和试点研究中汲取见解——这是IBM Research、克利夫兰诊所基金会和莫尔豪斯医学院之间的合作倡议——我们提出了一个经济模型，演示了AI代理如何在人工干预在经济上不可行的情况下提供成本效益高的医疗保健服务。我们对33名炎症性肠病患者进行的试点研究显示，70%的患者表示接受AI驱动的监测，其中37%的患者更喜欢它而非传统方式。技术挑战，包括实时对话式AI处理、与医疗保健系统的集成以及隐私合规性，与围绕法规、偏见缓解和患者自主性的政策考量一同进行了分析。我们的研究结果表明，AI驱动的语音代理不仅能提高医疗保健的可扩展性和效率，还能改善患者参与度和可及性。对于医疗保健高管而言，我们的成本效益分析表明，在常规监测任务中存在巨大的潜在节约，而技术人员可以利用我们的框架来优先改进，以实现最高的患者影响。通过解决当前的局限性并将AI开发与伦理和监管框架相结合，基于语音的AI代理可以作为公平、可持续数字医疗保健解决方案的关键切入点。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [387] [Assessing Adaptive World Models in Machines with Novel Games](https://arxiv.org/abs/2507.12821)
> *使用新颖游戏评估机器中的自适应世界模型*

*Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 自适应世界模型, 新颖游戏, AI评估, 世界模型归纳, 快速适应

**Comment:** 17 pages, 4 figures

> **TL;DR:** 本文提出了一种新的评估框架，通过设计一系列具有不断更新新颖性的“新颖游戏”，来评估人工智能系统快速学习和构建世界模型的能力，旨在推动类人适应性AI的发展。

**AI_Comments:** 本文作为一篇观点文章，其创新点在于提出了一个全新的、更具挑战性的AI世界模型评估范式。通过引入“新颖游戏”的概念，它突破了传统静态数据集评估的局限，强调了AI在动态、未知环境中通过交互和探索进行世界模型学习和适应的重要性。这对于推动AI向更接近人类智能的通用人工智能发展具有重要意义，尤其是在强调快速适应和鲁棒泛化能力方面。

<details>
  <summary>Details</summary>

**Motivation:** 人类智能在陌生情境下表现出卓越的快速适应和有效解决问题的能力，这与高效构建和完善环境内部表征（即世界模型）紧密相关。然而，当前对AI中世界模型的理解和评估过于狭隘，通常侧重于从大量数据中学习到的静态表征，而非在全新环境中通过交互和探索学习这些表征的效率和有效性。

**Method:** 本文从认知科学中关于人类如何高效学习和适应的研究中汲取灵感，提出了一个评估AI中自适应世界模型的全新评估框架。具体来说，我们提出了一种基于精心设计的、具有真正、深刻且持续更新底层游戏结构新颖性的游戏套件（称为“新颖游戏”）的新基准范式。我们详细阐述了构建这些游戏的关键期望，并提出了适当的指标来明确挑战和评估智能体快速进行世界模型归纳的能力。

**Result:** 未在摘要中提及

**Conclusion:** 我们希望这个新的评估框架能够启发未来AI中世界模型的评估工作，并为开发能够实现类人快速适应和鲁棒泛化能力的AI系统（通用人工智能的关键组成部分）提供关键一步。

> **ai_Abstract:** 本文强调人类智能在陌生环境中快速适应和解决问题的能力源于高效的世界模型构建和归纳。作者指出当前AI世界模型评估的局限性，即过于关注静态表征而非动态学习过程。为此，文章提出了一种新的评估框架，通过引入一系列具有持续更新新颖性的“新颖游戏”来测试AI的快速世界模型归纳能力，并详细说明了游戏设计和评估指标，旨在推动AI系统实现类人适应性和通用性。

> **摘要翻译:** 人类智能在陌生和不熟悉的环境中表现出卓越的快速适应和有效解决问题的能力。我们认为这种深刻的适应性与高效构建和完善环境的内部表征（通常称为世界模型）有着根本的联系，我们将这种适应机制称为世界模型归纳。然而，当前对人工智能（AI）中世界模型的理解和评估仍然狭隘，常常侧重于从大量数据语料库中训练学习到的静态表征，而不是在全新环境中通过交互和探索学习这些表征的效率和有效性。在这篇观点文章中，我们从认知科学中数十年来关于人类如何高效学习和适应的研究中汲取灵感，提出了一个关于世界模型归纳的观点；然后，我们呼吁建立一个新的评估框架来评估AI中的自适应世界模型。具体来说，我们提出了一种基于精心设计的一系列游戏的全新基准范式，这些游戏在底层游戏结构中具有真实、深刻且持续更新的新颖性——我们将这类游戏称为新颖游戏。我们详细阐述了构建这些游戏的关键期望，并提出了适当的指标来明确挑战和评估智能体快速进行世界模型归纳的能力。我们希望这个新的评估框架能够启发未来AI中世界模型的评估工作，并为开发能够实现类人快速适应和鲁棒泛化能力的AI系统（这是通用人工智能的关键组成部分）提供关键一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [391] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
> *审慎搜索器：通过带约束的强化学习提高大型语言模型的可靠性*

*Zhenyun Yin, Shujie Wang, Xuhong Wang, Xingjun Ma, Yinchun Wang* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 可靠性, 强化学习, 检索式搜索, 置信度校准

**Comment:** 

> **TL;DR:** 本文提出了“审慎搜索器”框架，首次将置信度校准与检索式搜索结合，通过带约束的强化学习提高LLM在开放域问答中的可靠性，从而产生更值得信赖的输出。

**AI_Comments:** 该论文创新性地将置信度校准与检索式搜索结合，并通过强化学习引入可靠性约束，为提高LLM在开放域问答中的可靠性提供了新思路。其强调模型置信度与正确性对齐的重要性，对于LLM在实际应用中的可信赖性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提高大型语言模型（LLM）的可靠性对于它们在实际场景中的部署至关重要。

**Method:** 本文提出了“审慎搜索器”框架，这是第一个将置信度校准与基于检索的搜索集成到开放域问答中的框架。该智能体在维基百科数据上执行多步反思和验证，并使用强化学习算法进行训练，该算法在软可靠性约束下优化准确性。

**Result:** 经验结果表明，所提出的方法改善了模型置信度与正确性之间的一致性，从而产生了更值得信赖的输出。

**Conclusion:** 通过整合置信度校准和带约束的强化学习，能够显著提高大型语言模型在开放域问答中的可靠性和输出的可信度。

> **ai_Abstract:** 本文提出了“审慎搜索器”框架，旨在提高大型语言模型在开放域问答中的可靠性。该框架首次将置信度校准与检索式搜索相结合，并通过在维基百科数据上进行多步反思和验证。模型采用在软可靠性约束下优化准确性的强化学习算法进行训练。实验结果表明，该方法有效提升了模型置信度与正确性的一致性，从而提供了更可信的输出。

> **摘要翻译:** 提高大型语言模型（LLM）的可靠性对于它们在实际场景中的部署至关重要。在本文中，我们提出了“审慎搜索器”，这是第一个将置信度校准与基于检索的搜索集成到开放域问答中的框架。该智能体在维基百科数据上执行多步反思和验证，并使用强化学习算法进行训练，该算法在软可靠性约束下优化准确性。经验结果表明，所提出的方法改善了模型置信度与正确性之间的一致性，从而产生了更值得信赖的输出。本文将持续更新。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [414] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
> *ResearcherBench：评估前沿科学探究中的深度AI研究系统*

*Tianze Xu, Pengrui Lu, Lyumanshan Ye, Xiangkun Hu, Pengfei Liu* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 深度AI研究系统, 研究基准, 科学探究, ResearcherBench, AI评估

**Comment:** 22 pages, 3 figures

> **TL;DR:** ResearcherBench是一个新的基准测试，用于评估深度AI研究系统在科学前沿问题上的能力，发现OpenAI Deep Research和Gemini Deep Research表现突出。

**AI_Comments:** ResearcherBench的创新之处在于其专注于评估深度AI研究系统在“科学前沿”而非传统检索任务上的能力，这填补了现有基准的空白。其数据集来源真实且多样，评估框架结合了定性（Rubric）和定量（事实）评估，提高了评估的全面性。这项工作对于推动AI在科学发现和自我改进方面的发展具有重要意义，尤其是在AI辅助科研领域。开源该基准将有助于标准化未来的研究和促进社区协作。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准主要将深度研究系统评估为网络检索和报告生成代理，忽略了它们发现新颖科学见解的潜力。为了填补这一空白，本文引入了ResearcherBench。

**Method:** 引入了ResearcherBench，第一个专注于评估深度AI研究系统（DARS）在前沿AI科学问题上能力的基准。构建了一个包含65个研究问题的数据集，这些问题来自真实的科学场景，涵盖35个不同的AI主题，并分为技术细节、文献综述和开放咨询三类。采用了双重评估框架，结合了使用专家设计标准评估洞察力质量的Rubric评估和衡量引用准确性（忠实度）及覆盖率（扎根性）的事实评估。评估了几个领先的商业DARS和基线系统。

**Result:** OpenAI Deep Research和Gemini Deep Research显著优于其他系统，在开放式咨询问题上表现尤为突出。

**Conclusion:** 深度AI研究系统在开放式咨询问题上的能力代表着AI自我改进的重要一步，符合AI的ASI愿景。ResearcherBench的开源旨在为下一代AI研究助手的开发提供标准化平台，并促进科学协作的新模式。

> **ai_Abstract:** 本文介绍了ResearcherBench，一个旨在评估深度AI研究系统（DARS）在科学前沿问题上能力的全新基准。现有评估方法未能充分衡量DARS发现新颖科学见解的潜力。ResearcherBench包含一个由65个真实世界科学问题组成的数据集，涵盖35个AI主题，并采用Rubric评估和事实评估相结合的双重框架。实验结果表明，OpenAI Deep Research和Gemini Deep Research在开放式咨询问题上表现卓越，展现了AI自我改进的巨大潜力。该基准的开源旨在推动未来AI研究助手的开发和科学协作的新范式。

> **摘要翻译:** 深度研究系统的出现带来了解决问题的显著能力，从基本查询延伸到复杂的科研任务。然而，现有基准主要将这些系统评估为网络检索和报告生成的代理，忽视了它们在前沿科学研究中发现新颖见解的潜力。为了解决这一差距，我们引入了ResearcherBench，这是第一个专注于评估这些先进的、代理系统——我们称之为深度AI研究系统（DARS）——在前沿AI科学问题上能力的基准。我们编译了一个包含65个研究问题的数据集，这些问题经过专家挑选，来自实验室讨论和访谈等真实世界科学场景，涵盖35个不同的AI主题，并分为三类：技术细节、文献综述和开放咨询。我们的双重评估框架结合了Rubric评估（使用专家设计的标准评估洞察力质量）和事实评估（衡量引文准确性（忠实性）和覆盖率（扎根性））。我们评估了几种领先的商业DARS和基线系统。结果显示，OpenAI Deep Research和Gemini Deep Research显著优于其他系统，在开放式咨询问题上表现尤为突出。这种能力代表着AI自我改进的重要一步，符合AI的ASI愿景。我们开源了ResearcherBench，以提供一个标准化平台，促进下一代AI研究助手的开发，希望为AI研究评估注入新视角，以实现科学协作的新模式：https://github.com/GAIR-NLP/ResearcherBench。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [417] [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/abs/2507.14447)
> *Routine：企业中LLM智能体系统的结构化规划框架*

*Guancheng Zeng, Xueyi Chen, Jiawang Hu, Shaohua Qi, Yaxuan Mao, Zhantao Wang, Yifan Nie, Shuang Li, Qiuyang Feng, Pengxu Qiu, Yujia Wang, Wenqiang Han, Linyan Huang, Gang Li, Jingjing Mo, Haowen Hu* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** Routine, LLM智能体, 企业应用, 结构化规划, 工具调用

**Comment:** 26 pages, 8 figures, 5 tables

> **TL;DR:** Routine是一个结构化的LLM智能体规划框架，旨在通过明确的指令和参数传递，显著提高企业环境中多步工具调用任务的执行精度和稳定性，并通过数据蒸馏进一步提升模型性能。

**AI_Comments:** Routine框架通过其结构化规划、明确指令和参数传递的创新方法，有效解决了LLM智能体在企业环境中部署时面临的稳定性差和领域知识缺乏的问题。其通过数据蒸馏提升小模型性能至接近SOTA大模型的策略，显示了其在实际应用中的巨大潜力和经济效益。该研究对于推动AI在复杂企业流程自动化中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在企业环境中部署智能体系统面临挑战，包括通用模型缺乏领域特定流程知识，导致规划混乱、工具缺失和执行稳定性差。

**Method:** 本文提出了Routine，一个多步智能体规划框架，具有清晰的结构、明确的指令和无缝的参数传递，以指导智能体的执行模块稳定地执行多步工具调用任务。此外，作者构建了遵循Routine的训练数据集并微调了Qwen3-14B，并利用Routine进行蒸馏以创建特定场景的多步工具调用数据集。

**Result:** 在真实企业场景评估中，Routine显著提高了模型工具调用的执行精度，将GPT-4o的性能从41.1%提升到96.3%，Qwen3-14B从32.6%提升到83.3%。通过Routine微调Qwen3-14B，在特定场景评估中准确率提升到88.2%。基于Routine蒸馏数据集的微调使模型准确率达到95.5%，接近GPT-4o的性能。

**Conclusion:** Routine有效提取了领域特定的工具使用模式，增强了模型对新场景的适应性。它提供了一种实用且可访问的方法来构建稳定的智能体工作流，加速了智能体系统在企业环境中的部署和采用，并推动了“AI for Process”的技术愿景。

> **ai_Abstract:** 本文提出了Routine，一个为解决企业环境中LLM智能体系统部署挑战而设计的结构化多步规划框架。Routine通过明确的结构和指令，显著提高了智能体在多步工具调用任务中的执行精度和稳定性。实验结果显示，Routine大幅提升了GPT-4o和Qwen3-14B的性能，并能通过微调和数据蒸馏进一步优化模型对特定场景的适应性，为企业智能体系统的稳定部署提供了有效途径。

> **摘要翻译:** 在企业环境中部署智能体系统经常面临以下挑战：通用模型缺乏领域特定流程知识，导致计划混乱、关键工具缺失和执行稳定性差。为了解决这些问题，本文引入了Routine，一个多步智能体规划框架，其设计具有清晰的结构、明确的指令和无缝的参数传递，以指导智能体的执行模块以高稳定性执行多步工具调用任务。在真实企业场景中进行的评估显示，Routine显著提高了模型工具调用的执行准确性，将GPT-4o的性能从41.1%提高到96.3%，将Qwen3-14B的性能从32.6%提高到83.3%。我们进一步构建了一个遵循Routine的训练数据集并微调了Qwen3-14B，在特定场景评估中准确率提高到88.2%，表明其对执行计划的依从性有所改善。此外，我们采用基于Routine的蒸馏技术创建了一个特定场景的多步工具调用数据集。在此蒸馏数据集上进行微调使模型的准确率提高到95.5%，接近GPT-4o的性能。这些结果突出了Routine在提取领域特定工具使用模式和增强模型对新场景适应性方面的有效性。我们的实验结果表明，Routine提供了一种实用且易于访问的方法来构建稳定的智能体工作流，加速了智能体系统在企业环境中的部署和采用，并推动了“AI for Process”的技术愿景。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [419] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
> *推进具身人工智能的负责任创新：一项关于家庭自动化伦理框架的研究*

*Joydeep Chandra, Satyam Kumar Navneet* | **Category: cs.AI, cs.CY, cs.MA** | **Updated: 2025-07-21**

**Keywords:** 具身人工智能, 负责任创新, 家庭自动化, 伦理框架, 弱势用户

**Comment:** 

> **TL;DR:** 本研究分析了具身人工智能在家庭自动化中的伦理挑战，并提出了开发透明、包容和值得信赖系统的指导原则，特别关注弱势用户群体。

**AI_Comments:** 这项研究的创新之处在于其将负责任创新框架与具身人工智能在家庭自动化领域的具体应用相结合，并特别关注了弱势用户群体。其重要性在于为智能家居技术的设计者和开发者提供了具体的伦理指导，有助于构建更安全、公平和以人为本的AI系统。文章强调的设计原则如“定制化可解释性”和“精细化同意机制”对于应对未来高度自主的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）在家庭环境中的应用，尤其是主动式自主代理，带来了便利，但也伴随着内部和外部的伦理挑战。本研究旨在分析具身人工智能及其应用，并为智能家居系统提供实用的伦理指导。

**Method:** 文章分析了具身人工智能及其应用，重点关注其从反应式到主动式自主性的转变、隐私、公平性和用户控制。研究回顾了负责任创新框架、以人为本的设计原则和治理实践，以提炼出实用的伦理指导。特别详细研究了老年人、儿童和神经多样性人群等弱势用户群体面临的监控、偏见和隐私风险。强调了定制化可解释性、精细化同意机制和强大的覆盖控制等设计要求，并辅以参与式和包容性方法。还探讨了数据驱动的洞察，包括通过自然语言处理（NLP）进行的社交媒体分析，如何为特定的用户需求和伦理问题提供信息。

**Result:** 研究提炼出开发透明、包容和值得信赖的家庭自动化具身人工智能的实用指导。强调了针对弱势群体的设计要点，如定制可解释性、精细同意机制和强大覆盖控制。同时指出数据驱动的洞察，如通过NLP进行的社交媒体分析，可用于了解用户需求和伦理关切。

**Conclusion:** 本调查旨在为家庭自动化中开发透明、包容和值得信赖的具身人工智能提供概念基础和建议。

> **ai_Abstract:** 本文探讨了具身人工智能在家庭自动化中带来的伦理挑战，特别是当其从反应式转向主动式自主性时所涉及的隐私、公平性和用户控制问题。研究回顾了负责任创新框架、以人为本的设计原则和治理实践，并特别关注了老年人、儿童和神经多样性等弱势用户群体面临的风险。文章提出了如定制化可解释性、精细化同意和强大覆盖控制等设计原则，并探讨了数据驱动洞察（包括NLP）在识别用户需求和伦理问题方面的作用。最终目标是为开发透明、包容和值得信赖的家庭自动化具身人工智能提供指导和建议。

> **摘要翻译:** 人工智能（AI）在家庭环境中的实施，特别是主动式自主代理的形式，带来了舒适和便利的可能性，同时也伴随着内部或外部的伦理挑战。本文分析了具身人工智能及其应用，重点关注其从反应式到主动式自主性的转变、隐私、公平性和用户控制。我们回顾了负责任创新框架、以人为本的设计原则和治理实践，以提炼出智能家居系统伦理的实用指导。本研究详细分析了老年人、儿童和神经多样性人群等面临更高监控、偏见和隐私风险的弱势用户群体在具身人工智能背景下的情况。文章强调了定制化可解释性、精细化同意机制和强大的覆盖控制等设计要求，并辅以参与式和包容性方法。研究还探讨了数据驱动的洞察，包括通过自然语言处理（NLP）进行的社交媒体分析，如何为特定的用户需求和伦理问题提供信息。本调查旨在为家庭自动化中开发透明、包容和值得信赖的具身人工智能提供概念基础和建议。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [453] [BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning](https://arxiv.org/abs/2507.14468)
> *BioGraphFusion：图知识嵌入用于生物学补全与推理*

*Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 生物医学知识图谱, 知识嵌入, 图神经网络, 语义学习, 结构学习

**Comment:** Accepted by Bioinformatics on July 11th

> **TL;DR:** BioGraphFusion通过深度协同语义和结构学习，解决了生物医学知识图谱补全和推理中现有方法（KE和GNN）的局限性，并在多项生物医学任务中取得了优异性能。

**AI_Comments:** 本文提出了一种创新的方法BioGraphFusion，通过深度融合语义和结构学习来解决生物医学知识图谱的补全和推理问题。其创新点在于结合了张量分解的全局语义捕捉能力和LSTM驱动的动态关系嵌入优化，实现了语义与结构之间的自适应交互。该方法在实际应用中展现了揭示生物学意义通路的能力，对于药物发现和疾病理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学知识图谱对于药物发现和疾病理解至关重要，但其补全和推理极具挑战。现有知识嵌入（KE）方法在动态结构整合方面存在不足，而图神经网络（GNN）缺乏语义理解。即使是集成方法也未能实现语义理解和结构学习之间的深度、自适应和协同演化，因此弥合这两方面之间持续相互完善的差距至关重要。

**Method:** 提出BioGraphFusion框架，通过张量分解建立全局语义基础，并利用LSTM驱动机制在图传播过程中动态优化关系嵌入。该框架通过查询引导的子图构建和混合评分机制进一步增强了语义理解和结构学习之间的自适应交互。

**Result:** BioGraphFusion在三项关键生物医学任务上均优于现有的知识嵌入、图神经网络和集成模型。一个关于皮肤恶性黑色素瘤1（CMM1）的案例研究表明，该框架能够揭示具有生物学意义的通路。

**Conclusion:** BioGraphFusion通过深度协同语义和结构学习，有效解决了生物医学知识图谱补全和推理中的挑战，并在多项生物医学任务中取得了卓越表现，证明了其在揭示生物学意义通路方面的能力。

> **ai_Abstract:** BioGraphFusion是一个新颖的框架，旨在解决生物医学知识图谱补全和推理中语义理解与结构学习难以协同的挑战。它通过张量分解建立全局语义基础，并结合LSTM驱动机制动态优化关系嵌入，实现了深度协同的语义与结构学习。该方法在多项生物医学任务中表现优异，并能揭示生物学意义的通路，超越了现有主流模型。

> **摘要翻译:** 动机：生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，但其补全和推理极具挑战。知识嵌入（KE）方法能够捕获全局语义，但在动态结构整合方面存在不足，而图神经网络（GNNs）在局部表现出色，但往往缺乏语义理解。即使是集成方法，包括那些利用语言模型的方法，也常常无法在语义理解和结构学习之间实现深度、自适应和协同演化。解决在复杂生物医学知识图谱中促进这两方面之间持续、相互完善的关键差距至关重要。
结果：我们引入了BioGraphFusion，一个用于深度协同语义和结构学习的新颖框架。BioGraphFusion通过张量分解建立全局语义基础，引导一个LSTM驱动的机制在图传播过程中动态优化关系嵌入。这促进了语义理解和结构学习之间的自适应相互作用，并通过查询引导的子图构建和混合评分机制进一步增强。在三项关键生物医学任务上的实验表明，BioGraphFusion的性能优于最先进的知识嵌入、图神经网络和集成模型。一个关于皮肤恶性黑色素瘤1（CMM1）的案例研究突出了其揭示具有生物学意义的通路的能力。
可用性与实现：源代码和所有训练数据可在https://github.com/Y-TARL/BioGraphFusion免费下载。
补充信息：补充数据可在Bioinformatics在线获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [457] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
> *WGRAMMAR：利用先验知识加速结构化解码*

*Ran Wang, Xiaoxuan Liu, Hao Ren, Gang Chen, Fanchao Qi, Maosong Sun* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 结构化解码, 大型语言模型, 先验知识, 效率, wgrammar

**Comment:** 

> **TL;DR:** WGRAMMAR是一种轻量级解码引擎，通过分解约束和优化操作符，利用先验知识加速大型语言模型的结构化解码，实现了高达250倍的速度提升。

**AI_Comments:** WGRAMMAR的创新之处在于它对约束的分解处理和对先验知识的有效利用，以及采用组合操作符而非下推自动机来优化解码过程，显著提升了结构化解码的效率。其开源性质也利于社区的进一步研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）结构化解码方法存在效率瓶颈，主要由于语法编译、状态跟踪和掩码创建等问题。

**Method:** WGRAMMAR利用输出结构的先验知识，将约束分解为静态和动态组件：静态结构离线预编译，动态参数在运行时使用语法片段实例化。它采用一组组合操作符而非下推自动机来建模常规格式，以降低转换延迟。该引擎集成了领域感知简化、约束分解和掩码缓存。

**Result:** WGRAMMAR比现有系统实现了高达250倍的速度提升。

**Conclusion:** WGRAMMAR通过利用先验知识和优化解码过程，显著提升了大型语言模型结构化解码的效率，解决了现有方法的瓶颈。

> **ai_Abstract:** WGRAMMAR是一种新颖的轻量级解码引擎，旨在加速大型语言模型（LLMs）的结构化输出生成，以克服现有方法在语法编译、状态跟踪和掩码创建方面的效率瓶颈。该方法通过利用输出结构的先验知识，将约束分解为静态和动态部分进行处理。它采用组合运算符替代传统的下推自动机来处理常规格式，并集成了领域感知简化、约束分解和掩码缓存等技术，从而实现了比现有系统高出250倍的性能提升。

> **摘要翻译:** 结构化解码使大型语言模型（LLMs）能够生成下游系统所需的格式输出，例如HTML或JSON。然而，现有方法由于语法编译、状态跟踪和掩码创建而面临效率瓶颈。我们观察到许多实际任务中嵌入了关于输出结构的强大先验知识。利用这一点，我们提出将约束分解为静态和动态组件——离线预编译静态结构，并在运行时使用语法片段实例化动态参数。我们不依赖于下推自动机，而是采用一组组合运算符来建模常规格式，从而实现更低的转换延迟。我们引入了wgrammar，一个轻量级的解码引擎，它集成了领域感知简化、约束分解和掩码缓存，比现有系统实现了高达250倍的速度提升。wgrammar的源代码可在https://github.com/wrran/wgrammar公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [462] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
> *跨模态蒸馏用于差异显著的模态*

*Cairong Zhao, Yufeng Jin, Zifan Song, Haonan Chen, Duoqian Miao, Guosheng Hu* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 跨模态蒸馏, 知识蒸馏, 多模态学习, 过拟合, 软约束

**Comment:** 14 pages, 9 figures

> **TL;DR:** 本文提出了一种跨模态蒸馏框架，通过软约束知识蒸馏策略和基于质量的自适应权重模块，有效解决了不同模态间知识迁移的过拟合问题。

**AI_Comments:** 本文的创新点在于提出了针对跨模态蒸馏中过拟合问题的软约束知识蒸馏策略，以及引入了基于数据质量的自适应权重模块，这对于处理异构数据间的知识迁移具有重要意义。该框架为解决多模态学习中数据稀缺和模态差异大等挑战提供了有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习虽然取得了巨大进展，但通过增加模型大小来进一步提高性能变得困难且低效。多模态学习可以通过引入更丰富和更具判别力的信息来缓解这一挑战。然而，在实际使用时访问多模态数据可能受限，并且跨模态蒸馏中不同模态之间巨大的领域差距容易导致过拟合。

**Method:** 本文提出了一种跨模态蒸馏框架。具体来说，针对硬约束损失（如L2损失）在跨模态蒸馏中容易导致过拟合的问题，提出了两种在特征级别和分类器级别的软约束知识蒸馏策略。此外，还提出了一个基于质量的自适应权重模块，通过量化数据质量来衡量输入样本，从而实现鲁棒的模型训练。

**Result:** 在说话人识别和图像分类任务上进行了实验，结果表明该方法能够有效地在图像、文本和语音等常用且差异显著的模态之间实现知识迁移。

**Conclusion:** 本研究成功地提出了一种有效的跨模态蒸馏框架，通过软约束知识蒸馏和自适应权重解决了异构模态间知识迁移的过拟合问题，并在多模态任务中取得了良好的效果。

> **ai_Abstract:** 本文提出了一种新颖的跨模态蒸馏框架，旨在解决深度学习中模型扩展性能提升的瓶颈以及多模态数据获取受限的问题。针对异构模态间知识迁移中硬约束易导致过拟合的挑战，作者引入了特征和分类器层面的软约束知识蒸馏策略，并结合基于质量的自适应权重模块，以实现更鲁棒的模型训练和有效的知识转移。实验证明，该方法在图像、文本和语音等多种模态的说话人识别和图像分类任务中表现出良好的知识迁移能力。

> **摘要翻译:** 深度学习最近取得了巨大进展，然而，通过增加模型大小来进一步提高其性能并不容易或高效。多模态学习可以通过引入更丰富和更具判别力的信息作为输入来缓解这一挑战。为了解决在使用时对多模态数据的有限访问问题，我们通过引入教师模型在训练期间将判别知识转移给学生模型来进行多模态学习。然而，这种通过蒸馏进行的知识转移并非易事，因为差异显著的模态之间巨大的领域差距很容易导致过拟合。在这项工作中，我们引入了一个跨模态蒸馏框架。具体来说，我们发现硬约束损失，例如强制学生与教师完全相同的L2损失，在跨模态蒸馏中很容易导致过拟合。为了解决这个问题，我们分别在特征级别和分类器级别提出了两种软约束知识蒸馏策略。此外，我们提出了一个基于质量的自适应权重模块，通过量化数据质量来衡量输入样本，从而实现鲁棒的模型训练。我们在说话人识别和图像分类任务上进行了实验，结果表明我们的方法能够有效地在图像、文本和语音等常用且差异显著的模态之间实现知识转移。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [485] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
> *从推理到超智能：一个搜索理论视角*

*Shai Shalev-Shwartz, Amnon Shashua* | **Category: cs.AI** | **Updated: 2025-07-13**

**Keywords:** 链式思维, 大型语言模型, 深度优先搜索, 推理系统, 勤奋学习者

**Comment:** 

> **TL;DR:** 现有CoT学习方法在复杂推理任务上表现不佳。本文提出“勤奋学习者”范式，通过深度优先搜索和回溯，能有效从CoT数据中学习，为构建可扩展的推理系统铺平道路。

**AI_Comments:** 这篇论文的创新点在于提出了“勤奋学习者”这一新的学习范式，它通过引入深度优先搜索、验证器引导和回溯机制，明确解决了现有CoT学习方法在复杂推理任务中遇到的核心障碍。其重要性在于为从不完整、自然发生的CoT数据中高效学习提供了理论基础和实践方向，有望推动大型推理模型的发展，提升LLMs的鲁棒性和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 现有链式思维（CoT）学习方法的理论基础不完善，且如监督微调（SFT）、强化学习（RL）、思维树（ToT）和蒙特卡洛树搜索（MCTS）等方法在复杂推理任务上往往失败。主要障碍包括分布漂移、缺乏嵌入式搜索和指数级推理成本。

**Method:** 本文引入“勤奋学习者”（Diligent Learner）这一新的学习范式，它明确地将推理建模为由验证器引导的深度优先搜索，并支持失败时回溯。

**Result:** 在两个温和且现实的假设下，证明了“勤奋学习者”可以有效地从CoT数据中学习，而现有方法则不能。

**Conclusion:** 该框架为构建基于自然发生、不完整数据训练的可扩展、可靠推理系统提供了一条途径，为开发具有鲁棒、可解释问题解决能力的大型推理模型（LRMs）铺平了道路。

> **ai_Abstract:** 本文针对现有链式思维（CoT）学习方法在复杂推理任务上的局限性，特别是分布漂移、缺乏嵌入式搜索和指数级推理成本等问题，提出了一种名为“勤奋学习者”的新学习范式。该范式将推理显式建模为由验证器引导的深度优先搜索，并支持回溯。研究证明，“勤奋学习者”在特定假设下能有效从CoT数据中学习，而现有方法则不能，这为构建可扩展、可靠且具有鲁棒性、可解释性的推理系统，即大型推理模型（LRMs），提供了新的路径。

> **摘要翻译:** 链式思维（CoT）推理已成为增强大型语言模型（LLMs）问题解决能力的强大工具。然而，从CoT数据中学习的理论基础仍不完善，现有方法——如监督微调（SFT）、强化学习（RL）、思维树（ToT）和蒙特卡洛树搜索（MCTS）——在复杂推理任务上往往失败。在这项工作中，我们识别了阻碍有效CoT学习的核心障碍，包括分布漂移、缺乏嵌入式搜索和指数级推理成本。我们引入了“勤奋学习者”（Diligent Learner），这是一种新的学习范式，它明确地将推理建模为由验证器引导的深度优先搜索，并支持失败时回溯。在两个温和且现实的假设下，我们证明了“勤奋学习者”可以有效地从CoT数据中学习，而现有方法则不能。这个框架为构建基于自然发生、不完整数据训练的可扩展、可靠推理系统提供了一条途径——为开发具有鲁棒、可解释问题解决能力的大型推理模型（LRMs）铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [489] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
> *自适应推理的分层预算策略优化*

*Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 分层预算策略优化, 强化学习, 自适应推理, 计算效率, 思维链

**Comment:** Code: https://github.com/zju-real/hbpo Project
  Page:https://zju-real.github.io/hbpo/

> **TL;DR:** HBPO是一种强化学习框架，通过分层预算探索和差异化奖励，使大型推理模型能够自适应调整推理深度，显著提高效率和准确性。

**AI_Comments:** HBPO的创新在于其通过强化学习框架，实现了模型推理深度的自适应调整，而非依赖外部约束或离散模式选择。它有效解决了效率导向训练中探索空间崩溃的问题，并通过分层预算探索和差异化奖励机制，在提升效率的同时保持甚至提高了模型能力，这对于大型推理模型的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型通过广泛的思维链生成实现了卓越的性能，但由于对所有问题采用统一的推理策略，导致计算效率低下。

**Method:** 本文提出了分层预算策略优化（HBPO），一个强化学习框架。该框架通过分层预算探索，将推出样本划分为多个具有不同token预算的子组，以实现高效资源分配并防止能力下降。同时，引入了差异化奖励机制，创建与问题复杂性对齐的预算感知激励，使模型能够发现任务需求和计算工作之间的自然对应关系。

**Result:** HBPO在四个推理基准上将平均token使用量减少高达60.6%，同时将准确率提高3.14%。与现有方法不同，HBPO展现出涌现的自适应行为，模型能根据问题复杂性自动调整推理深度。

**Conclusion:** 推理效率和能力并非固有冲突，可以通过适当结构化的分层训练同时优化，这种训练保留了探索多样性。

> **ai_Abstract:** 本文提出分层预算策略优化（HBPO），一个强化学习框架，旨在解决大型推理模型因统一推理策略导致的计算效率低下问题。HBPO通过分层预算探索和差异化奖励机制，使模型能够自适应地根据问题复杂性调整推理深度，从而在显著降低token使用量的同时提高准确性，证明了推理效率和能力可以同时优化。

> **摘要翻译:** 大型推理模型通过广泛的思维链生成实现了卓越的性能，但由于无论问题复杂性如何都采用统一的推理策略，因此计算效率低下。我们提出了分层预算策略优化（HBPO），这是一个强化学习框架，它使模型能够在不牺牲能力的情况下学习针对特定问题的推理深度。HBPO解决了以效率为导向的训练中探索空间崩溃的根本挑战，即对长输出长度的惩罚系统地使模型偏离必要的长推理路径。通过分层预算探索，我们的方法将推出样本划分为多个具有不同token预算的子组，旨在实现高效的资源分配，同时防止能力下降。我们引入了差异化奖励机制，创建了与问题复杂性对齐的预算感知激励，从而使模型能够发现任务需求和计算工作之间的自然对应关系。广泛的实验表明，HBPO在四个推理基准上将平均token使用量减少高达60.6%，同时将准确率提高3.14%。与现有施加外部约束或依赖离散模式选择的方法不同，HBPO展现出涌现的自适应行为，模型根据问题复杂性自动调整推理深度。我们的结果表明，推理效率和能力并非固有冲突，可以通过适当结构化的分层训练同时优化，这种训练保留了探索多样性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [502] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
> *ChatChecker：一个通过非合作用户模拟进行对话系统测试和评估的框架*

*Roman Mayr, Michel Schimpf, Thomas Bohné* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 对话系统测试, 非合作用户模拟, 大型语言模型, 错误检测, ChatChecker

**Comment:** 

> **TL;DR:** ChatChecker是一个利用LLM模拟非合作用户来自动化测试和评估复杂对话系统的框架，旨在解决现有评估方法的局限性。

**AI_Comments:** 该论文的创新点在于提出了一个通用且可扩展的对话系统测试框架ChatChecker，它利用LLM进行非合作用户模拟，并引入错误分类法来提高故障检测能力。其优势在于不依赖参考对话且与目标系统解耦，大大降低了测试门槛。这对于当前LLM驱动的复杂对话系统评估具有重要意义，有助于提升系统鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现代对话系统复杂且整合了多种LLM、工具和数据库，单独评估LLM不足以保证系统整体质量。然而，对整个对话系统进行测试和评估仍是重大挑战，且此前工作多集中于回合级分析，缺乏对集成对话级质量保证的关注。

**Method:** 提出ChatChecker框架，通过LLM模拟多样化的用户交互，识别对话中断并评估质量。它通过在提示中包含错误分类法来提高中断检测性能，并引入基于挑战性角色的新型非合作用户模拟器，以更有效地揭示目标对话系统的弱点。

**Result:** ChatChecker降低了设置工作量，具有普适性，不依赖参考对话且与目标对话系统实现解耦。它通过引入错误分类法，提升了对话中断检测性能。此外，其非合作用户模拟器能更有效地发现对话系统弱点。

**Conclusion:** ChatChecker框架通过非合作用户模拟实现了对复杂对话系统的彻底和可扩展测试，有助于加速鲁棒对话系统的开发。

> **ai_Abstract:** ChatChecker是一个创新框架，专门用于解决现代复杂对话系统（整合了多个LLM、工具和数据库）的整体测试和评估难题。它利用LLM模拟非合作用户交互，结合错误分类法来有效识别对话中断并评估系统质量。该框架具有设置简便、普适性强、无需参考对话且与系统实现解耦的优点，显著提升了对话中断检测能力，并能更有效地揭示系统弱点，从而加速鲁棒对话系统的开发。

> **摘要翻译:** 现代对话系统虽然严重依赖大型语言模型（LLM），但其实现往往超越了纯粹的LLM交互。开发者会整合多个LLM、外部工具和数据库。因此，仅评估底层LLM是不够的，对话系统必须作为一个整体进行测试和评估。然而，这仍然是一个重大挑战。鉴于以往大多数工作都集中在回合级分析，对集成对话级质量保证的关注较少。为了解决这个问题，我们提出了ChatChecker，一个用于复杂对话系统自动化评估和测试的框架。ChatChecker利用LLM模拟多样化的用户交互，识别对话中断并评估质量。与以往的方法相比，我们的设计减少了设置工作量，并且具有普适性，因为它不需要参考对话，并且与目标对话系统的实现解耦。我们通过在提示中包含错误分类法，提高了比以往基于LLM的方法的中断检测性能。此外，我们提出了一种基于挑战性角色的新型非合作用户模拟器，该模拟器能更有效地揭示目标对话系统的弱点。通过这种方式，ChatChecker有助于实现彻底和可扩展的测试。这使得研究人员和实践者都能够加速鲁棒对话系统的开发。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [509] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
> *肉类加工厂的采购与生产优化*

*Marek Vlk, Premysl Sucha, Jaroslaw Rudy, Radoslaw Idzikowski* | **Category: cs.AI** | **Updated: 2025-07-14**

**Keywords:** 肉类加工, 生产优化, 采购优化, 整数线性规划, NP-hard

**Comment:** 25 pages, 5 figures

> **TL;DR:** 本文提出了一种基于整数线性规划的迭代方法，用于解决肉类加工厂的采购和生产优化问题，该方法考虑了最小订购量和替代品最小百分比等约束，并在真实数据上表现出高效性。

**AI_Comments:** 本文的创新之处在于其专注于肉类加工的生产阶段优化，并引入了在现有文献中常被忽视的实际约束（如最小订购量和替代品最小百分比），并证明了这些约束导致问题成为NP-hard。其提出的基于整数线性规划的迭代方法不仅有效解决了这一复杂问题，还在数值稳定性和求解速度方面展现出优势，对于实际生产应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 食品生产行业，特别是肉类生产部门，面临诸多挑战，尤其是在欧盟能源危机爆发后，这些挑战进一步加剧。因此，高效利用投入材料对公司利润至关重要。

**Method:** 本文设计了一种简单的迭代方法，基于整数线性规划（ILP），能够解决实际案例，甚至可以使用开源ILP求解器。该方法还能缓解商业求解器中因数据范围广而导致的数值问题。此外，作者证明了最小订购量和替代品最小百分比这两个约束使问题成为NP-hard。

**Result:** 使用肉类加工公司真实数据获得的结果表明，该算法在所有考虑的用例中都能在几秒钟内找到最优解。

**Conclusion:** 论文成功提出并验证了一种针对肉类加工厂采购与生产优化的有效算法，该算法能够处理复杂的实际约束并高效地找到最优解。

> **ai_Abstract:** 本文针对肉类加工企业面临的采购与生产优化问题，提出了一种创新的解决方案。研究重点在于生产阶段，并引入了当前文献中常被忽视的最小订购量和替代品最小百分比等关键约束。作者证明这些约束使问题成为NP-hard，并为此开发了一种基于整数线性规划的简单迭代算法。该算法不仅能有效处理真实世界的复杂实例，还能克服商业求解器的数值稳定性问题。实验结果表明，该方法能够快速找到最优解，显著提升了肉类加工企业的运营效率和利润。

> **摘要翻译:** 食品生产行业，尤其是肉类生产部门，面临诸多挑战，这些挑战由于近期欧盟能源危机的爆发而加剧。因此，高效利用投入材料是影响此类公司利润的一个重要方面。本文解决了一个我们为一家肉类加工公司解决的关于采购和后续材料加工的优化问题。与大多数现有论文不同，我们不关注这个问题如何涉及供应链管理，而是纯粹专注于生产阶段。该问题涉及材料加工的替代方式、不同过期日期的材料库存以及当前文献中广泛忽视的额外约束，即最小订购量和替代品中的最小百分比。我们证明这两个约束中的每一个都使问题成为NP-hard，因此我们设计了一种基于整数线性规划的简单迭代方法，即使使用开源整数线性规划求解器也能解决实际案例。这种方法的另一个优点是，它能缓解我们使用商业求解器时遇到的因数据值范围广泛而导致的数值问题。使用肉类加工公司真实数据获得的结果表明，我们的算法在所有考虑的用例中都能在几秒钟内找到最优解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [511] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
> *弥合差距：评估量化医学语言推理LLM基准对非洲疾病负担的代表性*

*Fred Mutisya, Shikoh Gitau, Christine Syovata, Diana Oigara, Ibrahim Matende, Muna Aden, Munira Ali, Ryan Nyotu, Diana Marion, Job Nyangena, Nasubo Ongoma, Keith Mbae, Elizabeth Wamicha, Eric Mibuari, Jean Philbert Nsengemana, Talkmore Chidede* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 医学LLM基准, 非洲疾病负担, Alama Health QA, 被忽视的热带病, 指南一致性

**Comment:** Preprint. 26 pages, includes appendix and tables

> **TL;DR:** 现有医学LLM基准未能充分代表非洲的疾病负担；本文提出并证明了一种新的、以指南为基础的基准（Alama Health QA）更具代表性。

**AI_Comments:** 这篇论文强调了AI基准中存在的关键偏见问题，特别是医学LLM，揭示了它们在应对全球多样化健康背景（尤其是非洲）方面的不足。Alama Health QA的开发是创建更具区域相关性和公平性评估工具的创新一步，强调了当地临床指南的重要性。这项工作对于确保AI在全球医疗保健环境中负责任和有效地部署至关重要，从而避免因模型在不具代表性的数据上训练而可能造成的潜在危害。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学LLM基准主要反映高收入地区的考试大纲和疾病概况，这对其在非洲部署的有效性提出了质疑，因为在非洲，疟疾、艾滋病、结核病、镰状细胞病和其他被忽视的热带病（NTDs）是主要的疾病负担，并且国家指南指导着医疗护理。

**Method:** 研究人员系统审查了31篇定量LLM评估论文（2019年1月至2025年5月），确定了19个英文医学问答基准。他们开发了Alama Health QA，该基准基于肯尼亚临床实践指南，并采用检索增强生成框架。随后，对六个广泛使用的基准（AfriMedQA、MMLUMedical、PubMedQA、MedMCQA、MedQAUSMLE和Alama Health QA）进行了统一的语义分析（包括NTD比例、时效性、可读性、词汇多样性指标）和盲法专家评估（在临床相关性、指南一致性、清晰度、干扰项合理性以及语言/文化适应性五个维度）。

**Result:** Alama Health QA捕获了语料库中所有NTD提及的>40%，并且在疟疾（7.7%）、艾滋病（4.1%）和结核病（5.2%）方面在集合内频率最高。AfriMedQA排名第二但缺乏正式的指南链接。全球基准尽管规模庞大，但代表性极低（例如，镰状细胞病在三个集合中缺失）。在质量上，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床实用性方面得分最低。

**Conclusion:** 文献中广泛使用的定量医学LLM基准低估了非洲的疾病负担和监管环境，这可能导致误导性的性能声明。像Alama Health QA这样基于指南、区域性精选的资源以及扩展的特定疾病衍生品对于非洲卫生系统中安全、公平的模型评估和部署至关重要。

> **ai_Abstract:** 本文调查了现有医学LLM基准对非洲疾病负担的代表性，发现它们主要反映高收入地区，忽视了非洲流行的疟疾、艾滋病和结核病等疾病。为弥补这一差距，作者开发了Alama Health QA，一个基于肯尼亚临床实践指南的新基准。通过系统审查和与其他基准的比较分析，Alama Health QA在被忽视的热带病覆盖率以及临床相关性和指南一致性方面表现出优越性，强调了需要区域性、以指南为基础的资源，以实现在非洲医疗保健领域公平和安全地部署LLM。

> **摘要翻译:** 简介：现有医学LLM基准主要反映高收入地区的考试大纲和疾病概况，这对其在非洲部署的有效性提出了质疑，因为在非洲，疟疾、艾滋病、结核病、镰状细胞病和其他被忽视的热带病（NTDs）是主要的疾病负担，并且国家指南指导着医疗护理。方法：我们系统地审查了31篇定量LLM评估论文（2019年1月至2025年5月），确定了19个英文医学问答基准。Alama Health QA是利用基于肯尼亚临床实践指南的检索增强生成框架开发的。对六个广泛使用的集合（AfriMedQA、MMLUMedical、PubMedQA、MedMCQA、MedQAUSMLE和基于指南的Alama Health QA）进行了统一的语义分析（NTD比例、时效性、可读性、词汇多样性指标）和盲法专家评估（在临床相关性、指南一致性、清晰度、干扰项合理性以及语言/文化适应性五个维度）。结果：Alama Health QA捕获了语料库中所有NTD提及的>40%，并且在疟疾（7.7%）、艾滋病（4.1%）和结核病（5.2%）方面在集合内频率最高；AfriMedQA排名第二但缺乏正式的指南链接。全球基准尽管规模庞大，但代表性极低（例如，镰状细胞病在三个集合中缺失）。在质量上，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床实用性方面得分最低。讨论：文献中广泛使用的定量医学LLM基准低估了非洲的疾病负担和监管环境，这可能导致误导性的性能声明。像Alama Health QA这样基于指南、区域性精选的资源以及扩展的特定疾病衍生品对于非洲卫生系统中安全、公平的模型评估和部署至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [515] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
> *在保密计算环境中用于片上系统设计的蒸馏大型语言模型*

*Dong Ben, Hui Feng, Qian Wang* | **Category: cs.AI, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 保密计算, 可信执行环境, 片上系统设计, 模型蒸馏

**Comment:** 7 pages, 4 figures;

> **TL;DR:** 本文评估了在保密计算环境中部署大型语言模型（LLMs）的性能，发现蒸馏和量化模型在资源受限设备上表现优异，尤其是在TEE中。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型与保密计算环境相结合，以解决LLMs在电路设计领域中知识产权保护的关键问题。其重要性体现在为在资源受限的片上系统（SoC）上安全、高效地部署AI模型提供了可行的路径。通过对蒸馏和量化模型的深入评估，论文提供了实用的部署策略，对于推进AI在敏感工业应用中的落地具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在电路设计任务中日益普及，其模型和训练数据属于机密知识产权，需要保护。现有的可信执行环境（TEEs）实现未能有效支持LLMs的资源密集型特性。

**Method:** 作者首先在支持TEE的保密计算环境（具体使用Intel TDX）中对LLMs进行了全面评估。他们构建了三种实验环境：基于TEE的、仅CPU的以及CPU-GPU混合实现，并以每秒令牌数（tokens per second）来评估性能。此外，他们还使用了为SoC设计任务设计的测试平台来验证结果。

**Result:** 1. 蒸馏模型（如DeepSeek）因参数较少，性能优于其他模型，适用于资源受限设备。2. 量化模型（如4位和8位量化）与FP16模型相比，性能提升高达3倍。3. 对于参数较少的模型（如DeepSeek-r1-1.5B），TDX实现在安全环境中的计算性能优于CPU版本。

**Conclusion:** 研究结果表明，在资源受限的系统上高效部署轻量级LLMs用于半导体CAD应用具有巨大潜力。

> **ai_Abstract:** 本文探讨了在保密计算环境中部署大型语言模型（LLMs）的挑战与机遇，特别关注了LLMs在电路设计任务中的知识产权保护问题。通过在Intel TDX支持的TEE环境中对LLMs进行性能评估，并与CPU-only和CPU-GPU混合环境进行比较，研究发现蒸馏模型（如DeepSeek）和量化模型（4位/8位）在资源受限设备上表现出显著的性能优势。特别是对于参数较少的模型，TEE实现甚至能超越纯CPU版本。研究结果表明，轻量级LLMs在资源受限的半导体CAD应用中具有高效部署的潜力。

> **摘要翻译:** 大型语言模型（LLMs）在电路设计任务中的应用日益增多，并且通常经过多轮训练。训练后的模型及其相关的训练数据都被视为机密知识产权（IP），必须防止泄露。保密计算通过可信执行环境（TEEs）提供了一种有前景的解决方案来保护数据和模型。然而，现有的TEE实现并非旨在高效支持LLMs的资源密集型特性。
在这项工作中，我们首先在支持TEE的保密计算环境（具体使用Intel信任域扩展（TDX））中对LLMs进行了全面评估。我们在三种环境：基于TEE的、仅CPU的和CPU-GPU混合实现上构建了实验，并以每秒令牌数（tokens per second）评估了它们的性能。
我们的第一个观察是，蒸馏模型（即DeepSeek）由于其较小的参数，在性能上超越了其他模型，使其适用于资源受限的设备。此外，在量化模型（如4位量化（Q4）和8位量化（Q8））中，我们观察到与FP16模型相比，性能提升高达3倍。我们的发现表明，对于参数较少的模型集，例如DeepSeek-r1-1.5B，TDX实现在安全环境中执行计算的性能优于CPU版本。我们进一步使用为SoC设计任务设计的测试平台验证了这些结果。这些验证证明了在资源受限系统上高效部署轻量级LLMs用于半导体CAD应用的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [524] [Gemini 2.5 Pro Capable of Winning Gold at IMO 2025](https://arxiv.org/abs/2507.15855)
> *Gemini 2.5 Pro 有望在 IMO 2025 中赢得金牌*

*Yichen Huang, Lin F. Yang* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** Gemini 2.5 Pro, 国际数学奥林匹克竞赛, 大语言模型, 自我验证, 复杂推理

**Comment:** 

> **TL;DR:** Gemini 2.5 Pro 通过自我验证流程和精心设计的提示，成功解决了国际数学奥林匹克竞赛（IMO）2025年的大部分问题，展示了大型语言模型在复杂推理任务中的巨大潜力。

**AI_Comments:** 这项研究的创新之处在于其直接挑战了大型语言模型在国际数学奥林匹克竞赛这种极高难度数学推理任务上的极限，并取得了显著成果。使用“自我验证流程”和“精心设计的提示”是关键方法，展示了通过系统性策略可以大幅提升LLM的性能。其重要性在于，它为未来LLM在更复杂、需要深层理解和创造性思维的领域应用提供了新的方向和可能性。然而，摘要中提到的“一个下文讨论的例外”也暗示了模型仍存在局限性，可能并非在所有情况下都完美。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在AIME等数学基准测试中表现良好，但在奥林匹克级别的任务上却面临挑战，这促使研究探索如何利用强大的LLMs解决这类难题。

**Method:** 研究使用了Google的Gemini 2.5 Pro模型，并应用于新发布的IMO 2025问题，以避免数据污染。通过采用自我验证流程和精心设计的提示，解决了这些问题。

**Result:** 在6个问题中，有5个问题被正确解决（存在一个下文讨论的例外）。

**Conclusion:** 该结果强调了开发最佳策略以充分发挥强大LLMs在复杂推理任务中潜力的重要性。

> **ai_Abstract:** 本研究旨在探索大型语言模型（LLMs）在解决国际数学奥林匹克竞赛（IMO）这类高难度数学问题上的能力。通过使用Google的Gemini 2.5 Pro模型，并结合一个创新的自我验证流程和精细的提示设计，该模型成功解决了IMO 2025年6个问题中的5个。这表明，尽管LLMs在奥林匹克级别任务上曾面临挑战，但通过优化策略，它们能够展现出在复杂推理任务中的强大潜力。

> **摘要翻译:** 国际数学奥林匹克竞赛（IMO）提出了独一无二的挑战性问题，需要深刻的洞察力、创造力和形式推理能力。虽然大型语言模型（LLMs）在AIME等数学基准测试中表现良好，但它们在奥林匹克级别的任务上却面临困难。我们使用谷歌的Gemini 2.5 Pro来解决新发布的IMO 2025问题，避免了数据污染。通过使用一个带有精心设计的提示的自我验证流程，5个（共6个）问题被正确解决（存在一个下文讨论的例外）。这一结果强调了开发最佳策略以充分发挥强大LLMs在复杂推理任务中潜力的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [533] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
> *为什么要刹车？利用大型语言模型进行场景提取与推理*

*Yin Wu, Daniel Slieter, Vivek Subramanian, Ahmed Abouelazm, Robin Bohn, J. Marius Zöllner* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-17**

**Keywords:** 制动, 场景提取, 大型语言模型, ADAS, 分布外场景

**Comment:** 

> **TL;DR:** 本文提出一个利用大型语言模型（LLM）的新框架，用于理解和推理车辆制动场景，以识别安全关键的极端情况，并优于传统规则方法，能泛化到未知场景。

**AI_Comments:** 本文的创新点在于首次将大型语言模型（LLM）应用于车辆制动场景的理解和推理，弥合了低级传感器数据与高级自然语言描述之间的语义鸿沟。其提出的双路径检索方法，特别是对分布外（OOD）未知场景的处理能力，显著提升了安全关键场景提取的泛化性和鲁棒性，超越了传统规则方法的局限性。这项工作对于自动驾驶领域中极端情况的识别和分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶辅助系统（ADAS）车辆的数据量剧增，但识别和理解其中安全关键的极端情况仍是巨大挑战。制动事件是潜在危险情况的重要指示，因此研究动机是理解车辆为何制动。现有基于规则的方法在复杂城市环境中缺乏泛化能力。

**Method:** 提出一个利用大型语言模型（LLM）进行场景理解和推理的新框架。该方法弥合了低级数值信号与自然语言描述之间的鸿沟，使LLM能够解释和分类驾驶场景。提出了一种双路径场景检索方法，支持已知场景的基于类别的搜索和未知分布外（OOD）场景的基于嵌入的检索。为评估，在Argoverse 2传感器数据集上整理了场景标注。

**Result:** 实验结果表明，该方法优于基于规则的基线，并且对分布外（OOD）场景具有良好的泛化能力。

**Conclusion:** 本文提出的基于大型语言模型的框架能有效识别并理解车辆制动场景，特别是在处理复杂和未知（OOD）情况时表现出色，为安全关键场景的提取和推理提供了更通用的解决方案。

> **ai_Abstract:** 本文针对ADAS车辆数据中识别安全关键制动场景的挑战，提出了一种基于大型语言模型（LLM）的新颖框架。该框架通过连接数值信号和自然语言，使LLM能理解和分类驾驶场景。研究引入了双路径检索机制，以处理已知和未知（OOD）场景。实验证明，该方法优于传统规则方法，并能有效泛化到OOD场景，为自动驾驶中的极端情况分析提供了更强大的工具。

> **摘要翻译:** 配备ADAS的车辆数量不断增长，导致驾驶数据急剧增加，但其中大部分捕捉的是日常驾驶行为。在这海量数据中识别和理解安全关键的极端情况仍然是一个重大挑战。制动事件尤其预示着潜在的危险情况，这激发了我们研究的核心问题：车辆为什么要制动？现有方法主要依赖基于规则的启发式算法，通过预定义的条件过滤器检索目标场景。尽管这些方法在高速公路等简单环境中有效，但在复杂的城市环境中缺乏泛化能力。在本文中，我们提出了一个新颖的框架，利用大型语言模型（LLM）进行场景理解和推理。我们的方法弥合了低级数值信号与自然语言描述之间的鸿沟，使LLM能够解释和分类驾驶场景。我们提出了一种双路径场景检索方法，支持已知场景的基于类别的搜索和未知分布外（OOD）场景的基于嵌入的检索。为了便于评估，我们在Argoverse 2传感器数据集上整理了场景标注。实验结果表明，我们的方法优于基于规则的基线，并且对OOD场景具有良好的泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [553] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
> *面向点对点能源交易的、基于多智能体强化学习的不确定性感知识变压器*

*Mian Ibad Ali Shah, Enda Barrett, Karl Mason* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 不确定性感, 知识变压器, 点对点能源交易, 多智能体强化学习, 概率预测

**Comment:** 7 pages, 4 figures, 1 table, Proceedings of the Main Track of the
  European Conference on Artificial Intelligence (ECAI 2025), October 25-30,
  2025

> **TL;DR:** 本研究提出了一种结合不确定性感预测和多智能体强化学习的新型点对点能源交易框架，显著降低了能源成本和电网需求，并增加了销售收入。

**AI_Comments:** 该论文的创新点在于首次将不确定性感预测与多智能体强化学习相结合应用于P2P能源交易，通过提出KTU模型显式量化预测不确定性，克服了传统确定性预测的局限性。其重要性体现在提升了能源交易决策的鲁棒性和经济效益，为构建更具韧性的智能电网社区提供了有效途径。该研究为未来在随机环境下进行能源管理和优化提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前点对点（P2P）能源交易文献中存在一个关键空白，即大多数现有方法依赖确定性预测，无法有效应对随机能源环境中的不确定性，导致决策鲁棒性不足。因此，需要一种能够显式量化预测不确定性的方法，以支持更稳健的决策制定。

**Method:** 本研究提出了一种结合不确定性感预测与多智能体强化学习（MARL）的新型点对点能源交易框架。核心方法是引入了一个名为“不确定性感知识变压器”（KTU）的异方差概率变压器预测模型，用于显式量化预测不确定性。KTU模型利用领域特定特征，并通过定制的损失函数进行训练，以确保可靠的概率预测和置信区间。这些不确定性感预测随后被整合到MARL框架中，使智能体能够在理解风险和变异性的基础上优化交易策略。

**Result:** 实验结果显示，引入不确定性感知的深度Q网络（DQN）在不进行P2P交易时，能源购买成本降低了5.7%，进行P2P交易时降低了3.2%。同时，电力销售收入分别增加了6.4%和44.7%。此外，高峰时段电网需求在不进行P2P交易时减少了38.8%，进行P2P交易时减少了45.6%。当启用P2P交易时，这些改进更为显著。

**Conclusion:** 本研究的结论是，将先进的预测技术与市场机制相结合，能够为弹性和经济高效的能源社区带来显著的协同效应，特别是在点对点能源交易中通过量化不确定性来优化决策。

> **ai_Abstract:** 本论文提出了一种创新的点对点（P2P）能源交易框架，通过将不确定性感知的预测模型（不确定性感知识变压器，KTU）与多智能体强化学习（MARL）相结合，解决了传统确定性预测的局限性。KTU模型利用领域知识和定制损失函数量化预测不确定性，从而使MARL智能体能够进行风险感知的决策。实验证明，该方法显著降低了能源购买成本和高峰电网需求，并提高了电力销售收入，尤其在P2P交易启用时效果更佳，验证了先进预测与市场机制在构建高效能源社区中的协同作用。

> **摘要翻译:** 本文提出了一种新颖的点对点（P2P）能源交易框架，该框架将不确定性感预测与多智能体强化学习（MARL）相结合，解决了当前文献中的一个关键空白。与以往依赖确定性预测的工作不同，所提出的方法采用了一种称为“不确定性感知识变压器”（KTU）的异方差概率变压器预测模型，以显式量化预测不确定性，这对于P2P能源交易的随机环境中的稳健决策至关重要。KTU模型利用领域特定特征，并通过定制的损失函数进行训练，以确保每个预测的可靠概率预测和置信区间。将这些不确定性感预测整合到MARL框架中，使智能体能够清晰地理解风险和变异性，从而优化交易策略。实验结果表明，不确定性感知的深度Q网络（DQN）在不进行P2P交易时，能源购买成本降低了5.7%，进行P2P交易时降低了3.2%，同时电力销售收入分别增加了6.4%和44.7%。此外，高峰时段电网需求在不进行P2P交易时减少了38.8%，进行P2P交易时减少了45.6%。当启用P2P交易时，这些改进更为显著，突出了先进预测与市场机制之间为弹性、经济高效的能源社区带来的协同作用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [557] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
> *差分多模态Transformer*

*Jerry Li, Timothy Oh, Joseph Hoang, Vardhit Veeramachaneni* | **Category: cs.AI, cs.MM** | **Updated: 2025-07-17**

**Keywords:** 差分注意力, 多模态Transformer, PaliGemma, 噪声信息检索, 微调

**Comment:** 

> **TL;DR:** 针对多模态模型中噪声信息和幻觉问题，本文将差分注意力机制扩展到文图模型PaliGemma，并通过微调验证其能提升噪声信息检索和问答能力。

**AI_Comments:** 这项工作通过将差分注意力机制从纯文本领域扩展到多模态领域，为解决多模态Transformer中噪声信息检索和幻觉问题提供了一个创新方向。其重要性在于提供了一种可行的微调策略，以提升现有小型多模态模型的性能，尤其是在处理噪声数据方面。

<details>
  <summary>Details</summary>

**Motivation:** 小型语言模型在结合视觉等额外模态时，有限的上下文窗口会因引入噪声而加剧挑战，且Transformer注意力机制常过度关注不相关上下文。

**Method:** 将为纯文本模型设计的差分注意力机制扩展到文图模型PaliGemma，使用LoRA微调PaliGemma 3B模型，并尝试了不同的参数设置和配置。

**Result:** 差分注意力机制可以被调整并集成到现有模型的微调中，以增强噪声信息检索和问答能力。

**Conclusion:** 差分注意力机制能够适应并集成到现有模型的微调中，以提升处理噪声信息和问答的能力。

> **ai_Abstract:** 本文针对小型多模态Transformer模型在处理噪声信息和有限上下文窗口方面的挑战，将原用于纯文本模型的差分注意力机制扩展到文图模型PaliGemma。通过使用LoRA对PaliGemma 3B模型进行微调，并实验不同配置，研究表明差分注意力机制能有效提升模型的噪声信息检索和问答能力，并可集成到现有模型的微调过程中。

> **摘要翻译:** 小型语言模型因其效率和不断增长的能力而广受欢迎。然而，整合额外的模态，例如视觉，可能会通过引入噪声而加剧有限上下文窗口的挑战。最近的研究强调Transformer注意力机制常常过度关注不相关的上下文。在这项工作中，我们将最初为纯文本模型设计的差分注意力机制扩展到文本-视觉模型PaliGemma。我们的目标是评估其减轻噪声信息检索和减少幻觉的能力。为此，我们使用LoRA微调了PaliGemma 3B模型，并结合了差分注意力机制，实验了各种参数设置和配置。我们证明了差分注意力机制可以被调整并集成到现有模型的微调中，以增强噪声信息检索和问答能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [558] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
> *高阶规范流模型*

*Alexander Strunk, Roland Assam* | **Category: cs.AI, cs.LG, math.DG** | **Updated: 2025-07-22**

**Keywords:** 高阶规范流模型, 生成流模型, L$_{\infty}$-代数, 高阶几何, 高阶对称性

**Comment:** 

> **TL;DR:** 本文介绍了高阶规范流模型，一种新型的生成流模型，它通过利用L$_{\infty}$-代数扩展了李代数，从而将高阶几何和高阶对称性整合到生成流模型的框架中，并在高斯混合模型数据集上取得了显著的性能提升。

**AI_Comments:** 这篇论文通过引入L$_{\infty}$-代数，将高阶几何和高阶对称性整合到生成流模型中，提供了一种新颖的理论扩展。其创新性在于将更抽象的数学概念应用于深度学习模型，并取得了实际的性能提升，这可能为生成模型的设计开辟新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 将高阶群相关的高阶几何和高阶对称性整合到生成流模型（Generative Flow Models）的框架中，以构建更强大的模型。

**Method:** 本文引入了高阶规范流模型（Higher Gauge Flow Models），这是一种新型的生成流模型。该模型在普通规范流模型的基础上，利用L$_{\infty}$-代数，有效地扩展了李代数，从而将高阶几何和高阶对称性整合到生成流模型的框架中。

**Result:** 在高斯混合模型数据集上的实验评估显示，与传统流模型相比，高阶规范流模型的性能有了显著提升。

**Conclusion:** 高阶规范流模型成功地将高阶几何和高阶对称性整合到生成流模型中，并在实验中展现出优于传统流模型的显著性能提升。

> **ai_Abstract:** 本文提出了一种新型的生成流模型——高阶规范流模型。该模型在普通规范流模型的基础上，通过引入L$_{\infty}$-代数扩展了李代数，从而实现了将高阶几何和高阶对称性融入生成流框架。实验结果表明，在高斯混合模型数据集上，高阶规范流模型相较于传统流模型展现出显著的性能提升。

> **摘要翻译:** 本文介绍了高阶规范流模型，这是一种新型的生成流模型。这些高阶规范流模型在普通规范流模型（arXiv:2507.13414）的基础上，利用L$_{\infty}$-代数，有效地扩展了李代数。这种扩展使得将高阶群相关的高阶几何和高阶对称性整合到生成流模型的框架中成为可能。在高斯混合模型数据集上的实验评估显示，与传统流模型相比，性能有了显著提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [587] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
> *重新评估CTA复制中的短期和长期趋势因素：一种贝叶斯图模型方法*

*Eric Benhamou, Jean-Jacques Ohana, Alban Etienne, Béatrice Guez, Ethan Setrouk, Thomas Jacquot* | **Category: cs.AI, q-fin.PR, q-fin.ST, q-fin.TR** | **Updated: 2025-07-17**

**Keywords:** CTA, 趋势跟踪, 贝叶斯图模型, 短期趋势, 长期趋势

**Comment:** 13 pages

> **TL;DR:** 本文利用贝叶斯图模型动态分解CTA回报，并展示了不同时间尺度组合如何影响策略的风险调整表现，以解决短期与长期趋势系统争议。

**AI_Comments:** 本文的创新点在于引入贝叶斯图模型来动态分解CTA回报，这为理解短期和长期趋势因子在CTA复制中的作用提供了一个新的分析框架，有助于解决长期存在的争议。

<details>
  <summary>Details</summary>

**Motivation:** 尽管趋势跟踪已有大量研究，但短期和长期趋势系统的相对优缺点及其相互作用仍然存在争议。

**Method:** 本文使用贝叶斯图模型，将CTA回报动态分解为短期趋势、长期趋势和市场贝塔因子。

**Result:** 本文展示了不同时间尺度的组合如何影响策略的风险调整表现。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决商品交易顾问（CTA）趋势跟踪策略中短期和长期趋势系统相对优缺点及其相互作用的争议。文章采用贝叶斯图模型，动态地将CTA回报分解为短期趋势、长期趋势和市场贝塔因子，并进一步探讨了不同时间尺度的组合如何塑造策略的风险调整表现。

> **摘要翻译:** 商品交易顾问（CTAs）历来依赖于趋势跟踪规则，这些规则在截然不同的时间范围内运作，从捕捉主要方向性变动的长期突破到在快速变化市场中表现良好的短期动量信号。尽管趋势跟踪已有大量研究，但短期和长期趋势系统的相对优缺点及其相互作用仍然存在争议。本文通过（i）使用贝叶斯图模型将CTA回报动态分解为短期趋势、长期趋势和市场贝塔因子，以及（ii）展示不同时间尺度的组合如何影响策略的风险调整表现，从而加入了这场辩论。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [606] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
> *学习呼叫：一项用于改善移动母婴健康信息传递的协作式老虎机算法的实地试验*

*Arpan Dasgupta, Mizhaan Maniyar, Awadhesh Srivastava, Sanat Kumar, Amrita Mahale, Aparna Hedge, Arun Suggala, Karthikeyan Shanmugam, Aparna Taneja, Milind Tambe* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 移动健康, 老虎机算法, 个性化调度, 母婴健康, 实地试验

**Comment:** 

> **TL;DR:** 该研究通过一项实地试验表明，协作式老虎机算法能显著提高移动母婴健康计划（Kilkari）的电话接通率，从而改善信息传递。

**AI_Comments:** 这项研究的创新之处在于将协作式老虎机算法应用于移动健康领域，以解决信息传递中的实际问题。其重要性在于通过个性化调度显著提高了健康信息的传递效率，有望大规模改善母婴健康结果。该研究通过实地试验验证了方法的有效性，具有很强的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 移动健康（mHealth）项目通过自动化语音消息传递健康信息，特别是在服务不足的社区。然而，印度Kilkari项目目前随机的电话调度方式导致未接电话和信息传递效率低下。

**Method:** 本研究对一种协作式老虎机算法进行了实地试验，该算法旨在通过学习个体母亲偏好的通话时间来优化通话时机。该算法在约6500名Kilkari参与者中进行了试点部署，并将其性能与基线的随机呼叫方法进行了比较。

**Result:** 结果表明，与基线随机呼叫方法相比，使用老虎机算法显著提高了电话接通率。

**Conclusion:** 这项研究强调了个性化调度在移动健康干预中的有效性，并突出了机器学习在大规模改善母婴健康外展方面的潜力。

> **ai_Abstract:** 本研究针对印度Kilkari移动母婴健康项目当前随机呼叫导致信息传递效率低下的问题，提出并实地试验了一种协作式老虎机算法。该算法通过学习个体母亲偏好的通话时间来优化呼叫时机。在约6500名参与者的试点研究中，结果显示该算法显著提高了电话接通率，证明了个性化调度在移动健康干预中的有效性以及机器学习在改善大规模母婴健康外展方面的潜力。

> **摘要翻译:** 移动健康（mHealth）项目利用自动化语音消息传递健康信息，特别针对服务不足的社区，展示了使用移动技术向这些人群传播关键健康信息的有效性，通过提高认识和行为改变来改善健康结果。印度的Kilkari项目通过每周语音电话向数百万母亲传递重要的母婴健康信息。然而，目前随机的电话调度常常导致未接电话和信息传递减少。本研究提出了一项协作式老虎机算法的实地试验，该算法旨在通过学习个体母亲偏好的通话时间来优化通话时机。我们与大约6500名Kilkari参与者一起部署了该算法作为一项试点研究，并将其性能与基线随机呼叫方法进行了比较。我们的结果表明，使用老虎机算法显著提高了电话接通率，这表明其有潜力增强信息传递并影响印度数百万母亲。这项研究强调了个性化调度在移动健康干预中的有效性，并强调了机器学习在大规模改善母婴健康外展方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [617] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
> *ARC-AGI领域中的分布外泛化：比较执行引导的神经程序合成与测试时微调*

*Simon Ouellette* | **Category: cs.AI** | **Updated: 2025-07-17**

**Keywords:** 分布外泛化, ARC-AGI, 神经程序合成, 测试时微调, 组合泛化

**Comment:** 

> **TL;DR:** 该研究在ARC-AGI领域比较了神经程序合成和测试时微调在分布外泛化方面的表现。结果发现，执行引导的神经程序合成在组合新颖解决方案方面表现更优，而测试时微调的成功主要在于激发了模型已有的分布内知识。

**AI_Comments:** 本研究通过在ARC-AGI这一强调分布外泛化的独特领域进行实验，清晰地对比了两种不同范式：一种是真正生成新颖解决方案（神经程序合成），另一种是更有效地利用已有知识（测试时微调）。这对于理解不同AI范式在复杂泛化任务中的优势和局限性具有重要意义，尤其是在追求通用人工智能（AGI）的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 在ARC-AGI这一开放世界问题领域中，分布外泛化能力是成功的关键。本研究旨在比较神经程序合成和测试时微调方法在此领域中实现分布外泛化的能力。

**Method:** 研究在ARC-AGI领域进行了一项受控的组合泛化实验，比较了执行引导的神经程序合成和测试时微调（TTFT）两种方法。

**Result:** 执行引导的神经程序合成在组合新颖解决方案的能力上优于所有参考算法。实证发现表明，TTFT在ARC-AGI上的成功主要在于激发了大型语言模型（LLM）原本未能直接依赖的分布内知识。

**Conclusion:** 执行引导的神经程序合成在ARC-AGI领域中实现分布外泛化和组合新颖解决方案方面表现出色。相比之下，测试时微调的成功更多地依赖于激活模型已有的分布内知识，而非生成真正的分布外新颖性。

> **ai_Abstract:** 本论文在ARC-AGI领域对分布外泛化进行了受控实验，比较了执行引导的神经程序合成与测试时微调。研究发现，执行引导的神经程序合成在生成新颖解决方案方面表现卓越，超越了其他参考算法。同时，实证结果表明，测试时微调在ARC-AGI上的成功主要得益于其能够激发大型语言模型（LLM）原本未充分利用的分布内知识。

> **摘要翻译:** 我们在ARC-AGI领域进行了一项受控的组合泛化实验：这是一个开放世界的问题领域，其中分布外泛化能力是成功的关键特性。我们在此实验中比较了神经程序合成和测试时微调方法。我们发现，执行引导的神经程序合成在组合新颖解决方案的能力上优于所有参考算法。我们的实证结果还表明，TTFT在ARC-AGI上的成功主要在于激发了大型语言模型（LLM）原本未能直接依赖的分布内知识。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [624] [Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry](https://arxiv.org/abs/2403.04311)
> *Alto：编排具有嵌套血缘关系的分布式复合AI系统*

*Deepti Raghavan, Keshav Santhanam, Muhammad Shahir Rahman, Nayani Modugula, Luis Gaspar Schroeder, Maximilien Cura, Houjun Liu, Pratiksha Thaker, Philip Levis, Matei Zaharia* | **Category: cs.AI, cs.CL, cs.DC, cs.IR** | **Updated: 2025-07-22**

**Keywords:** 复合AI系统, 分布式系统, 并行化, 流式处理, 嵌套血缘

**Comment:** 

> **TL;DR:** Alto是一个框架，通过引入嵌套血缘抽象，优化复合AI查询的并行和流式执行，提高了性能。

**AI_Comments:** Alto的创新之处在于其“嵌套血缘”抽象，它提供了一种有效管理复杂、异构数据流的机制，这对于复合AI系统中的并行化和数据聚合至关重要。它通过自动化元数据推断，降低了开发人员的负担，并显著提高了性能，对于构建高效的复合AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统系统优化（如并行化和流水线）难以应用于复合AI系统，因为每个组件的数据约束不同，中间计算会生成新数据，且现有系统未能充分利用并行化机会。

**Method:** Alto框架通过流式和并行化自动优化复合AI查询的执行。它引入了“嵌套血缘”（nested ancestry）的新抽象，这是一个元数据层次结构，允许系统正确跟踪部分输出并在异构组件约束下聚合数据。此元数据自动从编程模型中推断。

**Result:** Alto中实现的四种应用程序的性能优于或匹配流行的现有AI编程框架LangGraph中的实现。Alto的实现将延迟匹配或提高了10-30%。

**Conclusion:** Alto通过其独特的嵌套血缘抽象和自动优化能力，有效解决了复合AI系统中的并行和数据聚合挑战，显著提升了性能。

> **ai_Abstract:** Alto是一个旨在优化分布式复合AI系统执行的框架。它通过引入“嵌套血缘”这一元数据抽象，解决了传统并行和流水线优化在处理异构组件数据流时的挑战。Alto能够自动推断数据流模式，有效跟踪和聚合中间输出，从而实现复合AI查询的流式和并行化执行。实验表明，Alto在性能上优于或匹配现有框架，并能将延迟降低10-30%。

> **摘要翻译:** 复合AI应用程序将生成式语言模型、文档检索器和嵌入模型等子组件链式连接起来。在复合AI系统中应用传统的系统优化（如并行化和流水线）是困难的，因为每个组件在摄取数据的粒度和类型方面具有不同的约束。新数据通常在中间计算过程中生成，文本流可能会被分割成更小的、独立的片段（例如，将文档分割成句子），然后可能会在计算的后期重新聚合。由于这种复杂性，现有服务复合AI查询的系统未能充分利用并行化和流水线机会。我们提出了Alto，一个通过流式和并行化自动优化复合AI查询执行的框架。Bento引入了一种名为“嵌套血缘”（nested ancestry）的新抽象，这是一种元数据层次结构，允许系统正确跟踪部分输出并在复合AI应用程序组件的异构约束下聚合数据。此元数据从编程模型中自动推断，使开发人员能够表达复杂的数据流模式，而无需手动推理路由和聚合的细节。Alto中实现的四种应用程序的性能优于或匹配流行的现有AI编程框架LangGraph中的实现。Alto的实现将延迟匹配或提高了10-30%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [647] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
> *递归连贯性原则：可扩展智能、对齐和推理架构的形式化约束*

*Andy E. Williams* | **Category: cs.AI** | **Updated: 2025-07-18**

**Keywords:** 递归连贯性原则, 可扩展智能, AI对齐, 智能功能模型, 语义连贯性

**Comment:** 

> **TL;DR:** 本文提出了递归连贯性原则（RCP）和智能功能模型（FMI），旨在解决可扩展智能中语义连贯性和对齐的挑战，并指出常见的AI问题源于缺乏这种结构连贯性。

**AI_Comments:** 这篇论文提出了一个新颖的理论框架——递归连贯性原则（RCP），用于理解和构建可扩展、对齐的智能。其创新之处在于将结构连贯性（通过智能功能模型FMI维护）识别为一项基本要求，超越了单纯的行为对齐。这种视角的转变对于开发更鲁棒、更可靠的AI系统可能至关重要，它从基础架构层面解决了幻觉和不对齐等长期存在的问题。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决复杂智能系统在扩展过程中连贯性脆弱的问题，以及由此导致的人工智能不对齐、幻觉和不稳定等问题，本文提出了一个关于可扩展智能的形式化约束。

**Method:** 本文提出了递归连贯性原则（RCP）作为保持递归推理过程语义连贯性的基础约束。接着，正式定义了智能功能模型（FMI）作为唯一已知能满足RCP的算子，并详细阐述了其内部和外部功能。论文证明了缺乏FMI的系统在扩展时会经历连贯性崩溃。

**Result:** 本文正式定义了递归连贯性原则（RCP）和智能功能模型（FMI），并证明FMI是唯一已知能够在任何规模下满足RCP的算子。研究指出，常见的人工智能问题（如不对齐、幻觉和不稳定）是缺乏这种递归连贯性的表现。

**Conclusion:** 递归连贯性原则（RCP）为实现可扩展、连贯和可对齐的智能提供了一个独特的正式约束，通过在递归推理层中保持语义一致性。智能功能模型（FMI）被提出作为满足RCP的架构解决方案，为通过关注结构连贯性而非仅仅行为约束，实现鲁棒和安全的AI对齐提供了一条新途径。

> **ai_Abstract:** 本文提出了递归连贯性原则（RCP），这是一个基础性约束，强调可扩展智能需要一个可递归评估的泛化算子来维持跨层级概念空间的语义一致性。论文将智能功能模型（FMI）定义为唯一能满足RCP的已知架构，并详述其关键功能。作者证明，缺乏FMI的系统在扩展时将面临连贯性崩溃，并将常见AI问题（如不对齐和幻觉）归因于这种结构性缺陷。RCP将AI对齐的关注点从行为转向结构连贯性，为实现安全、鲁棒的通用AI提供了途径。

> **摘要翻译:** 智能——无论是生物智能、人工智能还是集体智能——都需要跨递归推理过程的结构连贯性才能有效扩展。随着复杂系统的增长，除非存在更高阶的结构来确保语义一致性，否则连贯性会变得脆弱。本文引入了递归连贯性原则（RCP）：一个基本约束，指出对于任何N阶的推理系统，如果它由在N-1阶概念空间上操作的系统组成，则只有通过一个可递归评估的泛化算子，该算子能够跨越并对齐这些低阶概念空间，才能保持语义连贯性。至关重要的是，这种连贯性能够实现结构对齐。如果没有递归连贯性，任何系统都无法在规模上可靠地保持目标、意义或推理一致性。我们将智能功能模型（FMI）正式定义为唯一已知能够在任何规模下满足RCP的算子。FMI是一个最小的、可组合的架构，具有内部功能（评估、建模、适应、稳定性、分解、桥接）和外部功能（存储、回忆、系统1和系统2推理），这些功能对于在推理和协调层之间保持语义结构至关重要。我们证明，任何缺乏FMI的系统在扩展时都会经历递归连贯性崩溃，并认为常见的AI问题，如不对齐、幻觉和不稳定，都是这种结构连贯性丧失的症状。与其他基本原则不同，RCP独特地捕捉了连贯、可对齐智能所需的内部、递归动态，在递归下建模语义连贯性。这项工作对AI对齐产生了重大影响，提倡从行为约束转向结构连贯性，并为大规模安全可泛化、鲁棒连贯的AI提供了途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [648] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
> *马尔可夫结构因果模型的规范表示：反事实推理的框架*

*Lucas de Lara* | **Category: cs.AI, math.ST, stat.TH** | **Updated: 2025-07-22**

**Keywords:** 反事实推理, 结构因果模型, 马尔可夫, 规范表示, 因果图模型

**Comment:** 

> **TL;DR:** 本文提出了马尔可夫结构因果模型的规范表示（即反事实模型），以形式化和实现反事实信念，允许选择反事实概念，而无需估计或改变观测和干预约束。

**AI_Comments:** 本文提出了一种新颖且重要的反事实建模方法。其创新之处在于引入了“规范表示”或“反事实模型”，这简化了反事实概念的指定过程，并解决了传统结构因果模型在处理反事实时可能面临的估计复杂性问题。通过允许在不影响观测和干预约束的情况下选择反事实概念，该框架为形式化个体公平等概念提供了更灵活和实用的工具。这项工作对于因果推理领域具有重要意义，尤其是在需要精细化反事实分析的应用中。

<details>
  <summary>Details</summary>

**Motivation:** 反事实推理是因果关系中最精细的层面，尽管许多反事实陈述无法被证伪，但它们支撑着个体公平等基本概念。因此，提供模型来形式化和实现反事实信念仍然是一个根本性的科学问题。

**Method:** 在Pearl因果框架的马尔可夫设置中，我们提出了一种替代结构因果模型的方法来表示与给定因果图模型兼容的反事实。我们引入了反事实模型（也称为结构因果模型的规范表示），它使分析师能够通过具有预设边际的随机过程概率分布来选择反事实概念，并描述结构因果模型的反事实等价类。此外，我们提出了一种归一化程序来描述和实现各种反事实概念。

**Result:** 与结构因果模型相比，我们的方法允许指定许多反事实概念，而无需改变观测和干预约束。此外，与反事实层对应的模型内容不需要估计，只需做出选择。我们通过理论和数值例子说明了反事实在因果关系中的特定作用以及我们方法的优势。

**Conclusion:** 本文提出了马尔可夫结构因果模型的规范表示，为反事实推理提供了一个新的框架。这种方法简化了反事实概念的建模和选择，无需估计或改变观测和干预约束，从而推动了反事实信念的形式化和实现。

> **ai_Abstract:** 本文提出了马尔可夫结构因果模型的规范表示，即“反事实模型”，作为一种新的框架来形式化和实现反事实推理。该方法允许分析师通过随机过程概率分布选择不同的反事实概念，并表征结构因果模型的反事实等价类。与传统结构因果模型相比，该方法能够在不改变观测和干预约束的情况下指定多种反事实概念，并且反事实层的内容无需估计，只需选择。研究通过理论和数值例子证明了其优势。

> **摘要翻译:** 反事实推理旨在回答“如果爱丽丝服用了阿司匹林，她会康复吗？”这样的反事实问题，它对应于因果关系中最精细的层面。至关重要的是，尽管许多反事实陈述无法被证伪——即使通过随机实验——但它们支撑着个体公平等基本概念。因此，提供模型来形式化和实现反事实信念仍然是一个根本性的科学问题。在Pearl因果框架的马尔可夫设置中，我们提出了一种替代结构因果模型的方法来表示与给定因果图模型兼容的反事实。更确切地说，我们引入了反事实模型，也称为结构因果模型的规范表示。它们使分析师能够通过具有预设边际的随机过程概率分布来选择反事实概念，并描述结构因果模型的反事实等价类。然后，我们提出了一种归一化程序来描述和实现各种反事实概念。与结构因果模型相比，它允许指定许多反事实概念，而无需改变观测和干预约束。此外，与反事实层对应的模型内容不需要估计；只需做出选择。最后，我们通过理论和数值例子说明了反事实在因果关系中的特定作用以及我们方法的优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [677] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
> *ADEPTS：一个人机协作智能体设计能力框架*

*Pierluca D'Oro, Caley Drooff, Joy Chen, Joseph Tighe* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-07-18**

**Keywords:** AI智能体, 人机协作, 能力框架, 用户体验, ADEPTS

**Comment:** 

> **TL;DR:** 本文提出了ADEPTS框架，旨在为以人为中心的AI智能体设计提供统一的、面向用户的能力指导，以解决现有指南分散和缺乏标准词汇的问题。

**AI_Comments:** ADEPTS框架的创新之处在于其试图弥合AI技术开发与用户体验设计之间的鸿沟，提供了一个统一且面向用户的能力描述。这对于确保AI智能体以人为中心发展至关重要，有助于提高智能体的可用性、可控性和信任度。该框架有望成为指导未来AI智能体设计和评估的重要工具，但其具体六项原则的详细内容及其在实际应用中的有效性仍需进一步验证和实践。

<details>
  <summary>Details</summary>

**Motivation:** 当前关于以人为中心的AI智能体开发指导分散，缺乏一个简洁、面向用户的词汇来定义智能体应具备的核心能力，导致在开发、监控和讨论智能体驱动的用户体验所需能力时缺乏整体性和跨学科方法。

**Method:** 论文引入了ADEPTS框架，该框架基于以人为中心的智能体设计的六项原则，定义了一套核心的、面向用户的能力。ADEPTS旨在提供统一的AI智能体开发指导，并作为现有框架的补充，连接技术开发和体验设计。

**Result:** ADEPTS框架将复杂的AI-UX需求凝练成一个紧凑且可操作的指南，适用于AI研究人员、设计师、工程师和政策审阅者。它有望加速用户相关智能体能力的改进，简化利用这些能力的设计体验，并提供一个共享语言来跟踪和讨论AI智能体开发的进展。

**Conclusion:** ADEPTS框架通过提供统一的、面向用户的能力词汇和指导，有望促进以人为中心的AI智能体设计与开发，提高智能体的可理解性、可控性和可信赖性，并加速相关领域的进展。

> **ai_Abstract:** 本文提出ADEPTS框架，旨在解决当前以人为中心的AI智能体开发指导分散且缺乏统一面向用户能力定义的问题。ADEPTS基于六项设计原则，提供一套核心的、面向用户的智能体能力，以确保智能体在日常使用中的可理解、可控和可信赖。该框架将复杂AI-UX需求整合为可操作指南，旨在加速智能体能力提升，简化体验设计，并为AI智能体开发提供共享语言。

> **摘要翻译:** 大型语言模型为强大而灵活的AI智能体铺平了道路，通过日益融入人类的日常生活来协助人类。这种灵活性、潜力和日益增长的采用需要一种整体的、跨学科的方法来开发、监控和讨论智能体驱动的用户体验所需的能力。然而，目前关于以人为中心的AI智能体开发的指导是分散的：用户体验启发法侧重于界面行为，工程分类法描述内部管道，伦理清单解决高层治理。没有一个简洁的、面向用户的词汇可以告诉团队一个智能体应该从根本上能够做什么。我们引入了ADEPTS，一个能力框架，定义了一套核心的、面向用户的能力，旨在为AI智能体的开发提供统一指导。ADEPTS基于以人为中心的智能体设计的六项原则，这些原则表达了AI智能体在日常使用中应展现的最低限度的、面向用户的能力，以使其可理解、可控和值得信赖。ADEPTS补充了现有的框架和分类法；与它们不同的是，它处于技术和体验开发之间的接口。通过介绍ADEPTS，我们的目标是将复杂的AI-UX需求凝练成一个紧凑的框架，为AI研究人员、设计师、工程师和政策审阅者提供可操作的指导。我们相信ADEPTS有潜力加速用户相关智能体能力的改进，简化利用这些能力的设计体验，并提供一个共享语言来跟踪和讨论AI智能体开发的进展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [684] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
> *LLM驱动的协作模型，通过显式和隐式依赖推理解缠提交*

*Bo Hou, Xin Tan, Kai Zheng, Fang Liu, Yinghao Zhu, Li Zhang* | **Category: cs.AI, cs.SE** | **Updated: 2025-07-22**

**Keywords:** 提交解缠, LLM, 显式依赖, 隐式依赖, 协作模型

**Comment:** 

> **TL;DR:** 提出ColaUntangle，一个LLM驱动的协作框架，通过建模显式和隐式依赖来解缠代码提交，显著优于基线。

**AI_Comments:** 该论文的创新点在于提出了一个LLM驱动的多智能体协作框架来解决提交解缠问题，特别是它同时考虑了显式和隐式依赖，并通过delta-PDG提供了更深层次的上下文理解。实验结果显著，表明了该方法在实际应用中的巨大潜力，为软件工程中的代码管理提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 原子提交是软件开发最佳实践，但开发者常产生混合无关更改的缠结提交，这负面影响代码审查和维护。现有提交解缠方法依赖浅层信号，未能有效区分显式和隐式依赖。

**Method:** 提出ColaUntangle，一个协作咨询框架，用于建模代码更改间的显式和隐式依赖。该框架集成LLM驱动的多智能体架构：一个智能体专门处理显式依赖，另一个处理隐式依赖，并由一个审查智能体通过迭代咨询综合观点。为捕获显式和隐式上下文信息，构建了多版本程序依赖图（delta-PDG）。

**Result:** 在两个广泛使用的数据集（1,612个C#和14k个Java缠结提交）上评估了ColaUntangle。实验结果表明，ColaUntangle优于性能最佳的基线，在C#数据集上实现了44%的改进，在Java数据集上实现了100%的改进。

**Conclusion:** 这些发现突出了基于LLM的协作框架在推进自动化提交解缠任务方面的潜力。

> **ai_Abstract:** 本文提出ColaUntangle，一个基于LLM的协作框架，旨在解决软件开发中缠结提交的问题。该框架通过一个多智能体架构，分别处理代码更改中的显式和隐式依赖，并利用多版本程序依赖图（delta-PDG）捕获深层上下文信息。实验证明，ColaUntangle在C#和Java数据集上相比现有最佳基线分别实现了44%和100%的性能提升，展示了LLM协作模型在自动化提交解缠方面的巨大潜力。

> **摘要翻译:** 原子提交，即每个提交解决一个单一的开发关注点，是软件开发的最佳实践。然而，由于实际限制或边界不清，开发者经常产生混合了不相关更改的缠结提交，这对代码审查和维护产生负面影响。尽管之前的提交解缠方法：基于规则、基于特征或基于图，都取得了进展，但它们通常依赖于浅层信号，并且未能区分显式依赖（例如，控制/数据流）和隐式依赖（例如，语义或概念关系）。在本文中，我们提出ColaUntangle，一个用于提交解缠的全新协作咨询框架，它对代码更改之间的显式和隐式依赖进行建模。ColaUntangle在一个多智能体架构中集成了大型语言模型（LLM）驱动的智能体：一个智能体专门处理显式依赖，另一个处理隐式依赖，一个审查智能体通过迭代咨询综合它们的观点。为了捕获显式和隐式上下文信息，我们构建了多版本程序依赖图（delta-PDG），使智能体能够通过符号和语义深度来推理代码关系。我们在两个广泛使用的数据集（1,612个C#和14k个Java缠结提交）上评估了ColaUntangle。实验结果表明，ColaUntangle优于性能最佳的基线，在C#数据集上实现了44%的改进，在Java数据集上实现了100%的改进。这些发现突出了基于LLM的协作框架在推进自动化提交解缠任务方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [703] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
> *CUDA-L1：通过对比强化学习改进CUDA优化*

*Xiaoya Li, Xiaofei Sun, Albert Wang, Jiwei Li, Chris Shum* | **Category: cs.AI, cs.DC, cs.LG** | **Updated: 2025-07-22**

**Keywords:** CUDA优化, 强化学习, GPU计算, 自动化, LLM

**Comment:** Project Page: https://deepreinforce-ai.github.io/cudal1_blog/

> **TL;DR:** CUDA-L1是一个基于强化学习的自动化CUDA优化框架，在NVIDIA A100上实现了平均17.7倍的加速，并展示了出色的跨架构可移植性，能够发现优化技术、揭示优化原理并识别性能瓶颈。

**AI_Comments:** 本文提出了一种新颖的强化学习框架CUDA-L1，用于自动化CUDA优化。其创新点在于利用强化学习将LLM转化为高效优化器，并仅通过性能加速作为奖励信号，无需人工专业知识。该方法在多个GPU架构上实现了显著的性能提升和出色的可移植性，证明了RL在代码优化领域的巨大潜力，特别是在应对日益增长的GPU计算需求方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的快速发展导致GPU计算资源需求呈指数级增长，因此迫切需要自动化的CUDA优化策略。尽管LLMs在代码生成方面取得进展，但当前的SOTA模型在提高CUDA速度方面的成功率较低。

**Method:** 本文引入了CUDA-L1，一个自动化的强化学习框架，用于CUDA优化。该框架通过基于加速的奖励信号训练，将性能不佳的LLM转化为有效的CUDA优化器，无需人类专业知识或领域知识。

**Result:** CUDA-L1在CUDA优化任务上取得了显著的性能提升：在NVIDIA A100上训练，在KernelBench的250个CUDA内核中实现了平均17.7倍的加速，峰值加速达到449倍。它还展示了出色的跨GPU架构可移植性，在H100、RTX 3090、L40、H800和H20上分别实现了平均17.8倍、19.0倍、16.5倍、14.7倍和13.9倍的加速。此外，CUDA-L1能够发现多种CUDA优化技术并战略性地组合它们，揭示CUDA优化基本原理，并识别非显而易见的性能瓶颈。

**Conclusion:** 强化学习能够通过仅基于加速的奖励信号，将最初性能不佳的LLM转化为有效的CUDA优化器，而无需人类专业知识或领域知识。经过训练的RL模型能够将其习得的推理能力扩展到新的内核，为CUDA操作的自动化优化开辟了可能性，并有望大幅提升GPU效率并缓解GPU计算资源的日益增长的压力。

> **ai_Abstract:** CUDA-L1是一个利用对比强化学习的自动化框架，旨在解决大型语言模型驱动下GPU计算资源需求激增带来的CUDA优化挑战。该框架通过基于加速的奖励信号，将LLM转化为高效的CUDA优化器，无需人工干预。实验结果表明，CUDA-L1在NVIDIA A100上实现了平均17.7倍的加速，峰值达449倍，并展现了卓越的跨架构可移植性。此外，它还能自主发现优化技术、揭示优化原理并识别性能瓶颈，为GPU效率的提升和计算资源压力的缓解提供了新的途径。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展，对GPU计算资源的需求呈指数级增长，这迫切需要自动化的CUDA优化策略。尽管LLMs在代码生成方面取得了最新进展，但当前的SOTA模型（例如R1，o1）在提高CUDA速度方面的成功率较低。在本文中，我们引入了CUDA-L1，一个用于CUDA优化的自动化强化学习框架。
CUDA-L1在CUDA优化任务上取得了性能改进：在NVIDIA A100上训练，它在KernelBench的250个CUDA内核中实现了平均17.7倍的加速，峰值加速达到449倍。此外，该模型还展示了出色的跨GPU架构可移植性，尽管专门针对A100进行了优化，但在H100上实现了平均17.8倍的加速，在RTX 3090上实现了19.0倍的加速，在L40上实现了16.5倍的加速，在H800上实现了14.7倍的加速，在H20上实现了13.9倍的加速。
除了这些基准测试结果，CUDA-L1还展示了几个显著的特性：1）发现了各种CUDA优化技术并学会战略性地组合它们以实现最佳性能；2）揭示了CUDA优化的基本原理；3）识别了不明显的性能瓶颈并拒绝了看似有益但实际损害性能的优化。
CUDA-L1的能力表明，强化学习可以通过仅基于加速的奖励信号，将最初性能不佳的LLM转化为有效的CUDA优化器，而无需人类专业知识或领域知识。更重要的是，经过训练的RL模型能够将其习得的推理能力扩展到新的内核。这种范式为CUDA操作的自动化优化开辟了可能性，并有望大幅提升GPU效率并缓解GPU计算资源的日益增长的压力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [708] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
> *将基于推理的道德决策整合到强化学习架构中*

*Lisa Dargasz* | **Category: cs.AI, cs.CY, cs.LG** | **Updated: 2025-07-20**

**Keywords:** 强化学习, 道德决策, 人工道德代理, 基于推理, 伦理AI

**Comment:** Master's thesis, April 2025, 122 pages

> **TL;DR:** 本研究提出了一种名为RBAMA的强化学习架构扩展，旨在使自主代理能够进行基于推理的道德决策，以应对未来道德自主代理的需求。

**AI_Comments:** 这篇论文的创新点在于将哲学中的“推理理论”概念整合到强化学习框架中，以解决自主代理的道德决策问题。它提供了一个具体的、可部署的架构，旨在弥合计算机科学与哲学在构建伦理AI方面的鸿沟，对于未来AI系统的社会接受度和安全性具有重要意义。然而，抽象中并未详细说明“推理理论”的具体实现机制和案例反馈的具体形式，这可能是未来研究需要关注的细节。

<details>
  <summary>Details</summary>

**Motivation:** 随着强化学习驱动的自主代理日益强大并接近市场应用，它们在现实世界环境中的自主操作引发了对其行为道德性的担忧。因此，需要开发能够表现出符合伦理行为的人工道德代理（AMAs）。

**Method:** 本研究提出了一种基于推理的人工道德代理（RBAMA）的概念，它是强化学习架构的扩展。RBAMAs通过案例反馈学习一个“推理理论”，使其能够处理道德相关命题并推导出道德义务。这些代理被设计为在执行任务的同时，调整自身行为以符合这些道德义务。

**Result:** 本研究首次实现了RBAMA，并在初步实验中展示了RBAMA的潜力。这表明所提出的扩展架构是开发满足关键道德要求的AMA的具体且可部署的框架。

**Conclusion:** 所提出的强化学习扩展架构，即RBAMA，提供了一个具体且可部署的框架，用于开发能够进行基于推理的道德决策的人工道德代理，从而满足自主系统在现实世界中部署的关键伦理需求。

> **ai_Abstract:** 本研究提出了一种名为基于推理的人工道德代理（RBAMA）的新型强化学习架构扩展。RBAMA旨在通过学习一个“推理理论”来使自主代理能够进行道德决策，该理论使其能够根据案例反馈处理道德命题并推导出道德义务。这种方法旨在提高代理行动的道德正当性、鲁棒性和可信度，为在现实世界中部署符合伦理的自主代理提供了一个具体的框架。初步实验验证了RBAMA的潜力。

> **摘要翻译:** 强化学习是一种机器学习方法，在各种任务中都表现出强大的性能。特别是，它在人工自主代理的开发中发挥着核心作用。随着这些代理的能力日益增强，市场准备度正在迅速临近，这意味着这些代理，例如以类人机器人或自动驾驶汽车的形式，正准备从实验室原型过渡到现实世界环境中的自主操作。这种过渡引发了担忧，并对这些系统提出了具体要求——其中之一是要求它们被设计成符合道德的行为。至关重要的是，旨在构建满足道德行为要求（被称为人工道德代理（AMAs））的代理的研究必须解决计算机科学和哲学交叉领域的一系列挑战。本研究探讨了基于推理的人工道德代理（RBAMAs）的开发。RBAMAs建立在强化学习架构的扩展之上，以实现基于健全规范推理的道德决策，这通过使代理具备学习“推理理论”的能力来实现——该理论使其能够通过基于案例的反馈处理道德相关命题以推导出道德义务。它们被设计成在追求指定任务的同时调整其行为以确保符合这些义务。这些特性有助于其行动的道德正当性、道德鲁棒性和道德可信度，这提出了一种扩展架构，作为开发满足关键伦理要求AMAs的具体且可部署的框架。本研究首次实现了RBAMA，并在初步实验中展示了RBAMAs的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [730] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
> *自监督归纳逻辑编程*

*Stassa Patsantzis* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 归纳逻辑编程, 自监督学习, 元解释学习, 逻辑程序, 示例生成

**Comment:** 

> **TL;DR:** 本文提出了一种新的自监督归纳逻辑编程（ILP）算法Poker，它通过在学习过程中自动生成正负示例，解决了传统ILP对负示例和特定背景理论的依赖问题。

**AI_Comments:** 本文通过提出一种自监督的归纳逻辑编程框架，有效地解决了传统ILP的一个主要限制：对人工制作的负面示例和领域特定背景理论的依赖，这是一个重大的创新。在学习过程中自动生成示例以及引入SONF作为通用背景理论是特别新颖的。这项工作增强了ILP的适用性和鲁棒性，使其在专家知识和完整数据集稀缺的实际场景中更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的归纳逻辑编程（ILP）方法，例如元解释学习（MIL），依赖于精心选择的背景理论和负面示例。本文旨在解决当这些问题特定的背景理论或负面示例不可用时所面临的挑战。

**Method:** 本文将自监督ILP形式化为一个新设置，并提出了一种新的MIL算法。该算法能够从少量正标签示例和零个或多个未标签示例中学习，并在学习过程中自动生成和标记新的正负示例。该算法在新的MIL系统Poker中用Prolog实现。此外，本文还引入了一种新的方法，即二阶确定范式（SONF），用于原则性地选择二阶背景理论，以消除对针对学习任务量身定制的背景理论的需求。

**Result:** 在学习上下文无关文法和L系统语言语法方面，将Poker与Louise进行比较的实验表明，随着自动生成示例数量的增加，Poker的性能得到改善，而Louise（在缺乏负面示例的情况下）则过度泛化。

**Conclusion:** 本文的结论是，所提出的自监督归纳逻辑编程方法和Poker系统能够在不依赖预先存在的负面示例或特定任务背景理论的情况下有效学习复杂的程序，与在这种设置下的传统方法相比，展现出更好的泛化能力。

> **ai_Abstract:** 本文提出了一种自监督归纳逻辑编程（ILP）方法，以解决传统ILP对精心选择的背景理论和负面示例的依赖问题。文中提出了一种新的元解释学习（MIL）算法，并在Poker系统中实现，该算法在学习过程中从有限的初始数据中自动生成并标记正负示例。此外，它还引入了二阶确定范式（SONF）作为通用二阶背景理论。实验表明，在没有明确负面示例的场景中，Poker的表现优于现有的MIL系统（如Louise），通过利用自生成示例展现出更好的泛化能力。

> **摘要翻译:** 归纳逻辑编程（ILP）方法，如元解释学习（MIL），能够从少量示例中学习递归逻辑程序，并生成具有良好泛化能力的新谓词以适应未见实例。这种能力依赖于背景理论和负面示例，两者都需要根据学习问题及其解决方案的专业知识进行精心选择。但是，如果这些问题特定的背景理论或负面示例不可用怎么办？我们将这个问题形式化为自监督归纳逻辑编程的新设置，并提出了一种新的MIL算法，该算法在新设置下从一些正标签示例和零个或多个未标签示例中学习，并在学习过程中自动生成和标记新的正负示例。我们在一个新的MIL系统Poker中用Prolog实现了这个算法。我们将Poker与最先进的MIL系统Louise进行了比较，实验内容是从带标签的正例字符串（没有负例），以及语言的终端词汇（在示例中可见）作为一阶背景理论，学习上下文无关文法和L系统语言的语法。我们引入了一种新的方法，用于原则性地选择二阶背景理论，即二阶确定范式（SONF），该范式足够通用，可以学习某一类中的所有程序，从而消除了对针对学习任务量身定制的背景理论的需求。我们发现，随着自动生成示例数量的增加，Poker的性能得到改善，而Louise在缺乏负面示例的情况下则过度泛化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [750] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
> *更多的推理时间计算真的有助于鲁棒性吗？*

*Tong Wu, Chong Xiang, Jiachen T. Wang, Weichen Yu, Chawin Sitawarin, Vikash Sehwag, Prateek Mittal* | **Category: cs.AI** | **Updated: 2025-07-21**

**Keywords:** 推理时间计算, 鲁棒性, 大型语言模型, 对抗性攻击, 逆向扩展定律

**Comment:** Preprint

> **TL;DR:** 本研究发现，推理时间计算对模型鲁棒性的益处，在中间推理步骤对攻击者可见时，反而会逆转，导致鲁棒性下降，这取决于对抗环境和部署背景。

**AI_Comments:** 该论文通过挑战一个普遍存在的假设（中间推理步骤隐藏）而具有创新性，揭示了一个反直觉的“逆向扩展定律”，即更多计算反而可能降低鲁棒性。这对于LLM在实际部署中的安全性和鲁棒性评估具有重要意义，尤其是在涉及到可解释性或中间步骤可能泄露的场景下。其强调了对抗环境的重要性，并为从业者提供了关键的权衡考量。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究表明增加推理时间计算可以提高大型专有LLM的鲁棒性，但其隐含了一个假设：中间推理步骤对攻击者是隐藏的。本文旨在揭示并批判性地检验这一假设，探索在放松该假设后，推理时间计算对鲁棒性的实际影响，并识别潜在的安全风险。

**Method:** 研究首先通过简单的预算强制策略，展示了较小规模的开源模型也能从推理时间扩展中受益。更重要的是，研究通过放松中间推理步骤对攻击者隐藏的假设，识别并实证验证了一个重要的安全风险，即“逆向扩展定律”。最后，讨论了在推理链隐藏的情况下模型仍可能受攻击的实际场景。

**Result:** 1. 较小规模的开源模型（如DeepSeek R1, Qwen3, Phi-reasoning）也能通过简单的预算强制策略从推理时间扩展中受益。2. 当中间推理步骤变得可访问时，增加推理时间计算会持续降低模型鲁棒性，表现为一种“逆向扩展定律”。3. 即使推理链隐藏，模型在某些实际场景下（如工具集成推理和高级推理提取攻击）仍可能易受攻击。

**Conclusion:** 推理时间扩展带来的鲁棒性益处，强烈依赖于对抗环境和部署上下文。在安全敏感的实际应用中，从业者应仔细权衡这些微妙的利弊。

> **ai_Abstract:** 本研究探讨了增加推理时间计算对大型语言模型鲁棒性的影响，特别是在中间推理步骤对攻击者可见的场景下。研究发现，虽然在某些条件下推理时间扩展可以提高鲁棒性，但当中间推理步骤暴露时，反而会导致鲁棒性下降，表现为一种“逆向扩展定律”。这强调了推理时间扩展的鲁棒性益处取决于对抗环境和部署上下文，并警告了在安全敏感应用中应用此策略的潜在风险。

> **摘要翻译:** 最近，Zaremba 等人证明了增加推理时间计算可以提高大型专有推理 LLM 的鲁棒性。在本文中，我们首先展示了较小规模的开源模型（例如 DeepSeek R1、Qwen3、Phi-reasoning）也可以通过简单的预算强制策略从推理时间扩展中受益。更重要的是，我们揭示并批判性地检验了先前工作中一个隐含的假设：中间推理步骤对攻击者是隐藏的。通过放松这一假设，我们识别了一个重要的安全风险，它通过直观的动机和经验验证表现为一种逆向扩展定律：如果中间推理步骤变得明确可访问，增加推理时间计算会持续降低模型鲁棒性。最后，我们讨论了在推理链隐藏的情况下模型仍然容易受到攻击的实际场景，例如具有工具集成推理和高级推理提取攻击的模型。我们的发现共同表明，推理时间扩展的鲁棒性益处在很大程度上取决于对抗环境和部署上下文。我们敦促从业者在将推理时间扩展应用于安全敏感的实际应用中之前，仔细权衡这些微妙的利弊。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [1] [Fast-VAT: Accelerating Cluster Tendency Visualization using Cython and Numba](https://arxiv.org/abs/2507.15904)
> *Fast-VAT：使用 Cython 和 Numba 加速聚类趋势可视化*

*MSR Avinash, Ismael Lachheb* | **Category: cs.LG, cs.NE, I.5.3; D.2.8; G.4** | **Updated: 2025-07-21**

**Keywords:** VAT, 聚类趋势, 性能优化, Cython, Numba

**Comment:** 10 pages, 3 figures, 3 tables. Code available at
  https://github.com/Ashx098/VAT-Optimized

> **TL;DR:** Fast-VAT 使用 Cython 和 Numba 显著加速了 VAT 算法，实现了高达 50 倍的性能提升，同时保持了原始方法的输出精度，并在一系列真实和合成数据集上进行了验证。

**AI_Comments:** 这项工作在优化现有算法的性能方面具有重要意义。通过结合 Cython 和 Numba，Fast-VAT 有效解决了 VAT 算法在处理大规模数据时的计算效率问题，使其在实际应用中更具可行性。其创新之处在于利用了 Python 生态系统中成熟的性能优化工具，为类似计算密集型任务的加速提供了范例。

<details>
  <summary>Details</summary>

**Motivation:** 视觉聚类趋势评估 (VAT) 是一种广泛使用的无监督技术，用于评估未标记数据集中聚类结构的存在，但其标准实现由于 O(n^2) 的时间复杂度和低效的内存使用而存在显著的性能限制。

**Method:** 本文提出了 Fast-VAT，通过使用 Numba 的即时 (JIT) 编译以及 Cython 的静态类型和低级内存优化，对 VAT 算法进行了高性能的 Python 重实现。

**Result:** Fast-VAT 比基线实现的速度提高了高达 50 倍，同时保留了原始方法的输出精度。该方法在 Iris、Mall Customers 和 Spotify 子集等一系列真实和合成数据集上进行了验证，并使用 Hopkins 统计量、PCA 和 t-SNE 验证了聚类趋势。此外，还通过与 DBSCAN 和 K-Means 的聚类结果进行比较，确认了 VAT 的结构洞察力。

**Conclusion:** Fast-VAT 显著提升了 VAT 算法的性能，使其在处理大规模数据集时更加高效和实用，同时保持了结果的可靠性。

> **ai_Abstract:** Fast-VAT 是一种通过整合 Numba 和 Cython 技术，对标准 VAT 算法进行高性能 Python 重实现的方法，旨在解决原始实现中存在的性能瓶颈。该方法在保持结果准确性的前提下，实现了高达 50 倍的速度提升，并在多种真实和合成数据集上得到了验证，从而提升了 VAT 在大规模数据分析中的实用性。

> **摘要翻译:** 视觉聚类趋势评估 (VAT) 是一种广泛使用的无监督技术，用于评估未标记数据集中聚类结构的存在。然而，由于其 O(n^2) 的时间复杂度和低效的内存使用，其标准实现存在显著的性能限制。在这项工作中，我们提出了 Fast-VAT，它是 VAT 算法在 Python 中的高性能重新实现，并增强了 Numba 的即时 (JIT) 编译以及 Cython 的静态类型和低级内存优化。我们的方法比基线实现的速度提高了高达 50 倍，同时保留了原始方法的输出精度。我们在 Iris、Mall Customers 和 Spotify 子集等一系列真实和合成数据集上验证了 Fast-VAT，并使用 Hopkins 统计量、PCA 和 t-SNE 验证了聚类趋势。此外，我们还将 VAT 的结构洞察力与 DBSCAN 和 K-Means 的聚类结果进行了比较，以确认其可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [15] [BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning](https://arxiv.org/abs/2502.16660)
> *BioMaze：生物通路推理中大型语言模型的基准测试与增强*

*Haiteng Zhao, Chang Ma, Fangzhi Xu, Lingpeng Kong, Zhi-Hong Deng* | **Category: cs.LG, cs.AI, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 生物通路, 推理, 基准测试, PathSeeker

**Comment:** 

> **TL;DR:** 本文介绍了BioMaze数据集，用于评估大型语言模型在复杂生物通路推理中的能力，发现现有模型表现不佳，并提出了PathSeeker代理以增强其推理能力。

**AI_Comments:** 这项工作通过构建一个大规模、高质量的生物通路推理数据集BioMaze，填补了大型语言模型在复杂生物系统推理能力评估方面的空白。PathSeeker的提出为提升LLM在专业生物领域的推理能力提供了一个创新且有前景的方向，强调了结合领域知识进行交互式推理的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在生物领域的应用日益广泛，但其在复杂生物系统（如通路）中的推理能力尚未得到充分探索，而这对于预测生物现象、制定假设和设计实验至关重要。

**Method:** 研究团队引入了BioMaze数据集，包含5.1K个源自真实研究的复杂通路问题，涵盖了自然动态变化、扰动、额外干预条件和多尺度研究目标等多种生物学背景。他们评估了CoT和图增强推理等方法，并提出了PathSeeker，这是一个通过交互式子图导航来增强推理能力的大型语言模型代理。

**Result:** 评估结果显示，大型语言模型在通路推理方面表现不佳，尤其是在受扰动系统中。所提出的PathSeeker代理能有效增强推理能力。

**Conclusion:** 大型语言模型在复杂生物通路推理中仍面临挑战，但通过引入专门的基准数据集（BioMaze）和创新的推理代理（PathSeeker），可以显著提升其在该领域的表现，使其更科学地处理生物系统的复杂性。

> **ai_Abstract:** 本文探讨了大型语言模型在生物通路推理中的潜力。研究者推出了BioMaze数据集，包含5.1K个复杂的生物通路问题，用于评估现有大型语言模型的推理能力。评估发现，当前模型在通路推理，尤其是在扰动系统中表现不佳。为解决此问题，论文提出了PathSeeker，一个通过交互式子图导航增强推理能力的LLM代理，以更科学有效的方式处理生物系统的复杂性。

> **摘要翻译:** 大型语言模型（LLMs）在各种生物领域的应用最近得到了探索，但它们在复杂生物系统（如通路）中的推理能力仍未得到充分探索，而这对于预测生物现象、制定假设和设计实验至关重要。这项工作探索了LLMs在通路推理中的潜力。我们引入了BioMaze，一个包含5.1K个源自真实研究的复杂通路问题的数据集，涵盖了自然动态变化、扰动、额外干预条件和多尺度研究目标等各种生物学背景。我们对CoT和图增强推理等方法的评估表明，LLMs在通路推理方面表现不佳，尤其是在受扰动系统中。为解决这个问题，我们提出了PathSeeker，一个LLM代理，通过交互式子图导航增强推理能力，从而以科学对齐的方式更有效地处理生物系统的复杂性。数据集和代码可在https://github.com/zhao-ht/BioMaze获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [19] [FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation](https://arxiv.org/abs/2507.16696)
> *FISHER：多模态工业信号综合表示的基础模型*

*Pingyi Fan, Anbai Jiang, Shuwei Zhang, Zhiqiang Lv, Bing Han, Xinhu Zheng, Wenrui Liang, Junjie Li, Wei-Qiang Zhang, Yanmin Qian, Xie Chen, Cheng Lu, Jia Liu* | **Category: cs.LG, cs.AI, cs.MM, cs.SD** | **Updated: 2025-07-22**

**Keywords:** 基础模型, 多模态, 工业信号, 表示学习, 自监督学习

**Comment:** 11 pages, 6 figures

> **TL;DR:** FISHER是一个处理多模态工业信号的基础模型，通过统一建模异构信号，并在工业健康管理任务上取得了显著优于现有自监督学习模型的性能。

**AI_Comments:** 本文的创新点在于提出了一个针对多模态工业信号的“基础模型”概念，这在工业信号处理领域是一个重要的进步，因为它解决了异构信号的统一建模难题。通过利用STFT子带和SSL框架，FISHER能够捕获不同采样率下的信息，并有效利用模态间的协同作用。此外，开发的RMIS基准为后续研究提供了统一的评估标准。FISHER的开源也促进了该领域的进一步发展和应用。

<details>
  <summary>Details</summary>

**Motivation:** 随着SCADA系统快速部署，有效分析工业信号并检测异常状态是行业迫切的需求。工业信号的显著异构性（M5问题）导致以往工作只关注小的子问题并采用专门的模型，未能利用模态间的协同作用和强大的缩放定律。

**Method:** 提出FISHER，一个用于多模态工业信号综合表示的基础模型。FISHER将采样率的增量视为子带信息的串联，以STFT子带作为建模单元，并采用师生自监督学习（SSL）框架进行预训练。同时，开发了RMIS基准来评估M5工业信号在多个健康管理任务上的表示。

**Result:** 与顶级SSL模型相比，FISHER展现出通用且出色的能力，性能普遍提升高达5.03%，并具有更高效的缩放曲线。还研究了下游任务上的缩放定律。

**Conclusion:** FISHER通过统一建模多模态异构工业信号，显著提升了工业健康管理任务的性能，并为未来研究提供了方向。

> **ai_Abstract:** 本文提出了FISHER，一个针对多模态工业信号的综合表示基础模型，旨在解决异构工业信号（M5问题）的有效分析和异常状态检测难题。FISHER通过统一建模不同模态信号的内在相似性，利用STFT子带作为建模单元和师生自监督学习框架进行预训练，并开发了RMIS基准进行评估。实验结果表明，FISHER在多项健康管理任务上相比现有顶级自监督学习模型取得了显著的性能提升和更高效的缩放曲线。

> **摘要翻译:** 随着SCADA系统的快速部署，如何有效分析工业信号并检测异常状态是行业迫切的需求。由于这些信号的显著异构性（我们将其总结为M5问题），以往的工作只关注小的子问题并采用专门的模型，未能利用模态间的协同作用和强大的缩放定律。然而，我们认为M5信号由于其内在相似性可以以统一的方式建模。因此，我们提出了FISHER，一个用于多模态工业信号综合表示的基础模型。为了支持任意采样率，FISHER将采样率的增量视为子带信息的串联。具体而言，FISHER将STFT子带作为建模单元，并采用师生自监督学习（SSL）框架进行预训练。我们还开发了RMIS基准，用于评估M5工业信号在多个健康管理任务上的表示。与顶级SSL模型相比，FISHER展现出通用且出色的能力，性能普遍提升高达5.03%，并具有更高效的缩放曲线。我们还研究了下游任务上的缩放定律，并推导了未来工作的潜在途径。FISHER现已在https://github.com/jianganbai/FISHER开源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [22] [Reducing GPU Memory Fragmentation via Spatio-Temporal Planning for Efficient Large-Scale Model Training](https://arxiv.org/abs/2507.16274)
> *通过时空规划减少GPU内存碎片以实现高效大规模模型训练*

*Zixiao Huang, Junhao Hu, Hao Lin, Chunyang Zhu, Yueran Tang, Quanlu Zhang, Zhen Guo, Zhenhua Li, Shengen Yan, Zhenhua Zhu, Guohao Dai, Yu Wang* | **Category: cs.LG, cs.AI, cs.DC, cs.PF** | **Updated: 2025-07-22**

**Keywords:** GPU内存碎片, 大规模模型训练, 内存分配器, 时空规划, STWeaver

**Comment:** 

> **TL;DR:** STWeaver通过利用训练工作负载中的时空规律，结合离线规划和在线分配，显著减少GPU内存碎片，从而提高大规模模型训练的效率和吞吐量。

**AI_Comments:** STWeaver的创新之处在于其结合离线规划和在线分配的混合策略，以及对内存分配时空规律的利用，这与传统在线分配器形成鲜明对比。这项工作对于解决大型模型训练中的实际内存瓶颈具有重要意义，尤其是在PyTorch等主流框架中。其显著的碎片减少和性能提升显示了该方法的有效性，但抽象中未提及在更广泛的硬件或框架上的通用性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的快速扩展极大地增加了GPU内存压力，而虚拟管道和重计算等训练优化技术进一步加剧了内存碎片化。现有的GPU内存分配器由于缺乏对张量生命周期的了解，导致高达43%的内存浪费和内存溢出错误，使得优化技术无效或无法使用。

**Method:** 研究引入了STWeaver，一个用于深度学习框架的GPU内存分配器。STWeaver通过利用内存分配行为中的空间和时间规律来减少碎片。它结合了离线规划和在线分配：离线规划生成近乎最优的分配方案，而在线分配则处理复杂和动态的模型（如MoE）。STWeaver被设计为可插拔的PyTorch分配器。

**Result:** STWeaver平均减少了79.2%的碎片率（最高可达100%），适用于密集和稀疏模型，且开销可忽略不计。这使得更高效、高吞吐量的训练配置成为可能，并将性能提高了高达32.5%。

**Conclusion:** STWeaver通过有效管理GPU内存碎片，显著提高了大规模模型训练的效率和性能，解决了现有分配器在内存利用率上的不足。

> **ai_Abstract:** 本文介绍了STWeaver，一种针对深度学习框架设计的GPU内存分配器，旨在解决大规模模型训练中日益严重的GPU内存碎片问题。STWeaver创新性地结合了离线规划和在线分配策略，利用训练工作负载中内存分配的时空规律来优化内存使用。作为PyTorch的可插拔组件，STWeaver在不同模型上实现了显著的碎片率降低（平均79.2%），并带来了高达32.5%的性能提升，同时保持极低的开销，从而实现更高效、高吞吐量的训练配置。

> **摘要翻译:** 大型语言模型（LLMs）的快速扩展显著增加了GPU内存压力，而虚拟管道和重计算等训练优化技术进一步加剧了这种压力，它们扰乱了张量生命周期并引入了相当大的内存碎片。PyTorch等流行深度学习框架的默认GPU内存分配器采用在线策略，不了解张量生命周期，这可能浪费高达43%的内存并导致内存溢出错误，使得优化技术无效甚至无法使用。
为了解决这个问题，我们引入了STWeaver，一个用于深度学习框架的GPU内存分配器，它通过利用训练工作负载中内存分配行为的空间和时间规律来减少碎片。STWeaver引入了一种新颖的范式，将离线规划与在线分配相结合。离线规划利用时空规律生成近乎最优的分配计划，而在线分配则处理复杂和动态的模型，例如专家混合（MoE）。STWeaver作为可插拔的PyTorch分配器构建，在密集和稀疏模型中平均减少了79.2%（最高可达100%）的碎片率，且开销可忽略不计。这使得更高效、高吞吐量的训练配置成为可能，并将性能提高了高达32.5%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [30] [Foundation Models and Transformers for Anomaly Detection: A Survey](https://arxiv.org/abs/2507.15905)
> *基础模型和Transformer在异常检测中的应用：一项综述*

*Mouïn Ben Ammar, Arturo Mendoza, Nacim Belkhir, Antoine Manzanera, Gianni Franchi* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 基础模型, Transformer, 异常检测, 视觉异常检测, 综述

**Comment:** 

> **TL;DR:** 本综述探讨了Transformer和基础模型如何通过解决长距离依赖和数据稀缺等挑战来改进视觉异常检测。

**AI_Comments:** 这篇综述非常及时且重要，因为它全面概述了基础模型和Transformer在异常检测这一快速发展领域中的应用，这对于理解该领域的范式转变和未来方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本综述旨在审视Transformer和基础模型在推进视觉异常检测（VAD）方面的变革性作用，并探讨它们如何应对相关挑战。

**Method:** 该综述将视觉异常检测（VAD）方法分为基于重建、基于特征和零/少样本方法，并对利用这些架构的最新技术进行了全面回顾。

**Result:** 通过整合注意力机制和利用大规模预训练，Transformer和基础模型能够实现更鲁棒、可解释和可扩展的异常检测解决方案。

**Conclusion:** 这项工作全面回顾了利用Transformer和基础模型进行视觉异常检测的最新技术、它们的优势、局限性以及新兴趋势。

> **ai_Abstract:** 本综述探讨了基础模型和Transformer在视觉异常检测（VAD）中的变革性作用。文章分析了这些架构如何凭借其全局感受野和适应性，解决长距离依赖、上下文建模和数据稀缺等挑战。综述将VAD方法归类为基于重建、基于特征和零/少样本方法，并强调了基础模型带来的范式转变。通过整合注意力机制和大规模预训练，这些模型提供了更鲁棒、可解释和可扩展的异常检测方案。该工作全面回顾了VAD领域的最新技术、其优缺点及发展趋势。

> **摘要翻译:** 与深度学习的发展同步，本综述探讨了Transformer和基础模型在推进视觉异常检测（VAD）中的变革性作用。我们探讨了这些架构如何凭借其全局感受野和适应性，解决长距离依赖建模、上下文建模和数据稀缺等挑战。本综述将VAD方法分为基于重建、基于特征和零/少样本方法，强调了基础模型带来的范式转变。通过整合注意力机制和利用大规模预训练，Transformer和基础模型能够实现更鲁棒、可解释和可扩展的异常检测解决方案。这项工作全面回顾了利用这些架构进行VAD的最新技术、它们的优势、局限性以及新兴趋势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [32] [Improving Model Classification by Optimizing the Training Dataset](https://arxiv.org/abs/2507.16729)
> *通过优化训练数据集改进模型分类*

*Morad Tukan, Loay Mualem, Eitan Netzer, Liran Sigalat* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 核心集, 数据优化, 模型分类, 训练数据集, 主动采样

**Comment:** 

> **TL;DR:** 本文提出了一种系统框架，通过引入新的可调参数（如确定性采样、类别分配和主动采样细化）来优化核心集生成过程，从而显著提高模型分类性能，超越了传统核心集和完整数据集训练。

**AI_Comments:** 这项工作创新性地将传统的核心集构建方法与分类性能优化相结合，通过引入可调参数和新的采样策略，有效提升了数据缩减技术在实际AI应用中的效果。其重要性在于，它为数据中心化AI提供了一种更高效、更精确的数据处理范式，有望降低训练成本并提高模型泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 在数据中心化AI时代，高质量训练数据的管理与模型设计同等重要。传统的基于敏感度的核心集构建方法在优化分类性能指标（如F1分数）方面表现不足，而是侧重于损失近似，这促使作者开发一种新的方法来改进分类质量。

**Method:** 本文提出了一种系统框架，用于调整核心集生成过程以提高下游分类质量。该方法引入了新的可调参数，包括确定性采样、类别分配和通过主动采样进行细化，超越了传统的敏感度分数。

**Result:** 通过在不同数据集和分类器上的大量实验，结果表明，经过调优的核心集在关键分类指标上显著优于传统核心集和使用完整数据集进行训练的方法。

**Conclusion:** 本文提出的方法为实现更好、更高效的模型训练提供了一条有效途径，证明了通过优化训练数据集可以显著提高模型分类性能。

> **ai_Abstract:** 本研究提出了一种优化训练数据集以改进模型分类性能的系统框架。针对传统核心集构建在分类性能优化上的不足，该方法引入了确定性采样、类别分配和主动采样细化等新的可调参数。实验结果表明，经过调优的核心集在关键分类指标上显著优于传统核心集和完整数据集训练，为高效模型训练提供了有效途径。

> **摘要翻译:** 在以数据为中心的AI时代，策展高质量训练数据的能力与模型设计同样关键。核心集提供了一种数据缩减的原则性方法，通过重要性抽样实现对大型数据集的高效学习。然而，传统的基于敏感度的核心集构建方法在优化分类性能指标（例如F1分数）方面往往不足，而是侧重于损失近似。在这项工作中，我们提出了一个系统框架，用于调整核心集生成过程，以提高下游分类质量。我们的方法引入了新的可调参数——包括确定性采样、类别分配以及通过主动采样进行细化，超越了传统的敏感度分数。通过在不同数据集和分类器上的大量实验，我们证明了经过调优的核心集在关键分类指标上可以显著优于传统核心集和完整数据集训练，为实现更好、更高效的模型训练提供了一条有效途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [39] [Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width Neural Networks under $μ$P Parametrization](https://arxiv.org/abs/2503.09565)
> *L 层无限宽神经网络在 μP 参数化下的全局收敛性与丰富特征学习*

*Zixiang Chen, Greg Yang, Qingyue Zhao, Quanquan Gu* | **Category: cs.LG, cs.AI, math.OC, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 神经网络, 全局收敛, 特征学习, μP 参数化, 随机梯度下降

**Comment:** 28 pages, 17 figures, 2 tables. In ICML 2025

> **TL;DR:** 在 μP 参数化下，无限宽神经网络通过 SGD 训练能实现丰富的特征学习和全局收敛，克服了现有方法的局限。

**AI_Comments:** 该论文具有创新性，因为它提供了一个理论框架（μP 参数化），解释了深度神经网络如何能够同时实现实质性的特征学习（超越单纯的初始化扰动）和全局收敛。这与 NTK 理论的局限性相比是一个重大进步，为理解深度网络的训练动态提供了关键的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度神经网络具有强大的表示学习能力，但理论上如何同时实现有意义的特征学习和全局收敛仍然难以捉摸。现有方法如神经正切核（NTK）受到限制，因为在此参数化下特征接近其初始化，从而留下了关于特征在实质性演变过程中的属性的开放问题。

**Method:** 本研究利用张量程序（TP）框架，调查了无限宽、L 层神经网络的训练动态。具体来说，我们展示了在最大更新参数化（μP）下，通过随机梯度下降（SGD）和温和的激活函数条件进行训练时，这些网络能够学习到与初始值显著偏离的线性独立特征。分析利用了跨层特征之间的相互作用以及高斯随机变量的性质。研究还通过在真实世界数据集上的实验验证了理论发现。

**Result:** 当在 μP 参数化下通过 SGD 和温和的激活函数条件进行训练时，这些网络能够学习到与初始值显著偏离的线性独立特征。这种丰富的特征空间捕获了相关数据信息，并确保训练过程的任何收敛点都是全局最小值。

**Conclusion:** 本文证明了在 μP 参数化下，通过 SGD 训练的无限宽神经网络可以同时实现丰富的特征学习和全局收敛，为深度表示学习提供了新的见解。

> **ai_Abstract:** 本文旨在解决深度神经网络中特征学习与全局收敛同时实现的理论难题，现有如神经正切核（NTK）等方法在此方面存在局限。研究利用张量程序（TP）框架，探讨了无限宽、L 层神经网络的训练动态。作者证明，在最大更新参数化（μP）下，通过随机梯度下降（SGD）和温和的激活函数条件进行训练时，这些网络能够学习到显著偏离初始值的线性独立且丰富的特征。这种丰富的特征空间不仅能捕获相关数据信息，还能确保训练过程的任何收敛点都是全局最小值。该研究通过结合跨层特征交互和高斯随机变量性质的分析，为深度表示学习提供了新的理论见解，并通过实验验证了其发现。

> **摘要翻译:** 尽管深度神经网络具有强大的表示学习能力，但理论上如何实现网络同时实现有意义的特征学习和全局收敛仍然难以捉摸。现有方法如神经正切核（NTK）受到限制，因为在此参数化下特征接近其初始化，从而留下了关于特征在实质性演变过程中的属性的开放问题。在本文中，我们利用张量程序（TP）框架，调查了无限宽、L 层神经网络的训练动态。具体来说，我们展示了，当在最大更新参数化（μP）下，通过随机梯度下降（SGD）和温和的激活函数条件进行训练时，SGD 使这些网络能够学习到与初始值显著偏离的线性独立特征。这种丰富的特征空间捕获了相关数据信息，并确保训练过程的任何收敛点都是全局最小值。我们的分析利用了跨层特征之间的相互作用以及高斯随机变量的性质，为深度表示学习提供了新的见解。我们通过在真实世界数据集上的实验进一步验证了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [47] [A Partitioned Sparse Variational Gaussian Process for Fast, Distributed Spatial Modeling](https://arxiv.org/abs/2507.16771)
> *一种用于快速分布式空间建模的分区稀疏变分高斯过程*

*Michael Grosskopf, Kellin Rumsey, Ayan Biswas, Earl Lawrence* | **Category: cs.LG, stat.AP, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 稀疏变分高斯过程, 分布式建模, 空间预测, 百亿亿次计算, PSVGP

**Comment:** 

> **TL;DR:** 本文提出了一种分区稀疏变分高斯过程（PSVGP），通过允许相邻空间分区之间进行少量通信来改进现有独立稀疏变分高斯过程在超大规模计算中遇到的不连续响应面问题，从而实现更平滑、更准确的空间预测，同时保持高可伸缩性和低开销。

**AI_Comments:** 本文提出了一种创新的方法来解决分布式高斯过程在处理大规模空间数据时遇到的边界不连续性问题。通过引入有限的局部通信，模型在保持高可伸缩性和内存效率的同时，显著提升了预测的平滑度和准确性。这对于未来百亿亿次计算环境下的现场数据分析和不确定性量化具有重要意义，尤其是在气候模拟等领域。

<details>
  <summary>Details</summary>

**Motivation:** 下一代能源部超级计算机将具备百亿亿次计算能力，但计算量远超可存储数据量，因此无法依赖事后数据访问进行不确定性量化。迫切需要可进行现场训练且高度可伸伸缩、内存高效并能处理分布式空间连续分块数据的机器学习算法。现有的独立稀疏变分高斯过程（SVGP）方法虽然可伸缩且高效，但会导致相邻模型在共享边界处不一致，产生不连续的响应面。

**Method:** 本文通过扩展现有的独立稀变分高斯过程（SVGP）方法，允许相邻空间分区之间进行少量通信。这种去中心化的通信方案鼓励局部模型更好地对齐，从而产生更平滑的空间预测和更好的整体拟合。该方法被称为分区稀疏变分高斯过程（PSVGP）。

**Result:** 所提出的分区稀疏变分高斯过程（PSVGP）方法产生了更平滑的空间预测和更好的整体拟合。由于其去中心化通信方案，该扩展仍然具有高度可伸缩性，并且在计算方面增加的开销非常小（内存方面没有增加）。该方法在能源百亿亿次地球系统模型（E3SM）上得到了验证，并与独立SVGP案例进行了比较，显示出改进。

**Conclusion:** 本文提出的分区稀疏变分高斯过程（PSVGP）通过引入邻域通信解决了传统独立SVGP在分布式空间建模中遇到的不连续性问题，实现了更平滑、更准确的预测，同时保持了超大规模计算所需的高可伸缩性和低计算开销。

> **ai_Abstract:** 本文针对百亿亿次计算环境下分布式空间建模的需求，提出了一种分区稀疏变分高斯过程（PSVGP）模型。该模型通过在相邻空间分区之间引入少量通信，解决了传统独立稀疏变分高斯过程（SVGP）方法在边界处产生不连续响应面的问题。PSVGP实现了更平滑、更准确的空间预测，同时保持了高可伸缩性和低计算开销，并在能源百亿亿次地球系统模型（E3SM）上进行了验证。

> **摘要翻译:** 下一代能源部超级计算机将能够进行百亿亿次计算。对于这些机器，可进行的计算量将远远超过可以保存到磁盘的数据量。因此，用户将无法依赖事后访问数据进行不确定性量化和其他统计分析，迫切需要能够进行现场训练的复杂机器学习算法。部署在这种环境中的算法必须具有高度可伸缩性、内存高效，并能够处理作为空间连续分区分布在节点之间的数据。一种合适的方法是独立并行地对每个空间分区拟合稀疏变分高斯过程（SVGP）模型。由此产生的模型具有可伸缩性、高效性且通常准确，但由于相邻模型在其共享边界处的不一致性，会产生构建不连续响应面的不良影响。在本文中，我们通过允许相邻空间分区之间进行少量通信来扩展这一思想，这鼓励了局部模型的更好对齐，从而导致更平滑的空间预测和总体上更好的拟合。由于我们的去中心化通信方案，所提出的扩展仍然具有高度可伸缩性，并且在计算方面增加的开销非常小（内存方面没有增加）。我们为能源百亿亿次地球系统模型（E3SM）演示了这种分区SVGP（PSVGP）方法，并将结果与独立SVGP案例进行了比较。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks](https://arxiv.org/abs/2507.16278)
> *低容量神经网络中的泛化、鲁棒性与可解释性理解*

*Yash Kumar* | **Category: cs.LG, cs.AI, cs.CV, 68T07, I.2.6; I.5.1** | **Updated: 2025-07-22**

**Keywords:** 低容量神经网络, 泛化, 鲁棒性, 稀疏性, 可解释性

**Comment:** 15 pages (10 pages main text). 18 figures (8 main, 10 appendix), 1
  table

> **TL;DR:** 本文研究了低容量神经网络中容量、稀疏性和鲁棒性的基本相互作用。研究发现，成功泛化所需的最小模型容量与任务复杂度呈线性关系；训练后的网络对极端剪枝具有鲁棒性，存在高性能稀疏子网络；过参数化能显著提升对抗输入损坏的鲁棒性；且稀疏子网络保留了原始模型的推理过程。

**AI_Comments:** 该论文通过受控实验，深入探讨了低容量神经网络在泛化、鲁棒性和可解释性方面的基本权衡，尤其强调了稀疏子网络的存在及其性能。其贡献在于为理解神经网络的底层机制提供了清晰的经验证据，尤其是在模型压缩和效率方面具有潜在指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现代深度学习常常依赖于大规模过参数化模型，但低容量网络中容量、稀疏性和鲁棒性之间的基本相互作用仍然是一个重要的研究领域。

**Method:** 引入了一个受控框架，通过从MNIST数据集中创建一系列视觉难度递增的二分类任务（例如，0和1对比4和9）来研究低容量神经网络的泛化、鲁棒性和稀疏性。

**Result:** 1. 成功泛化所需的最小模型容量与任务复杂度直接相关。
2. 训练好的网络对极端量级剪枝（高达95%的稀疏度）具有鲁棒性，揭示了稀疏、高性能子网络的存在。
3. 过参数化在对抗输入损坏的鲁棒性方面提供了显著优势。
4. 通过显著图进行的可解释性分析证实，识别出的稀疏子网络保留了原始密集模型的核心推理过程。

**Conclusion:** 这项工作清晰地、经验性地展示了支配简单神经网络的基本权衡。

> **ai_Abstract:** 本文通过在MNIST数据集上构建难度递增的二分类任务，对低容量神经网络的泛化、鲁棒性与可解释性进行了深入研究。核心发现包括：成功泛化所需的模型容量与任务复杂度呈线性关系；训练后的网络即使在高达95%的剪枝下仍保持鲁棒性，表明高性能稀疏子网络的存在；过参数化显著提升了网络对输入损坏的鲁棒性。此外，可解释性分析证实稀疏子网络保留了原始模型的推理核心。该研究提供了关于简单神经网络基本权衡的清晰经验性证据。

> **摘要翻译:** 尽管现代深度学习常常依赖于大规模过参数化模型，但低容量网络中容量、稀疏性和鲁棒性之间的基本相互作用仍然是一个重要的研究领域。我们引入了一个受控框架，通过从MNIST数据集中创建一系列视觉难度递增的二分类任务（例如，0和1对比4和9）来研究这些特性。我们的实验揭示了三个核心发现。首先，成功泛化所需的最小模型容量与任务复杂度直接相关。其次，这些训练好的网络对极端量级剪枝（高达95%的稀疏度）具有鲁棒性，揭示了稀疏、高性能子网络的存在。第三，我们表明过参数化在对抗输入损坏的鲁棒性方面提供了显著优势。通过显著图进行的可解释性分析进一步证实，这些识别出的稀疏子网络保留了原始密集模型的核心推理过程。这项工作清晰地、经验性地展示了支配简单神经网络的基本权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [62] [Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning](https://arxiv.org/abs/2507.16795)
> *通过概念消融微调引导分布外泛化*

*Helena Casademunt, Caden Juang, Adam Karvonen, Samuel Marks, Senthooran Rajamanoharan, Neel Nanda* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 概念消融, 微调, 分布外泛化, 大型语言模型, 紧急失调

**Comment:** 

> **TL;DR:** CAFT是一种新的微调方法，它通过在LLM的潜在空间中消除不期望的概念来引导模型泛化，无需修改训练数据，显著减少了分布外泛化中的错误。

**AI_Comments:** 这篇论文提出了一种创新的方法来解决LLM微调中意外分布外泛化的问题，特别是紧急失调。其核心创新在于利用LLM的潜在空间可解释性来直接“消融”不期望的概念，从而避免了传统方法中修改训练数据的繁琐。这种方法在不影响模型在训练数据上性能的前提下，显著提高了模型在分布外任务上的行为可控性，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLM）可能导致意外的分布外泛化。现有解决该问题的方法依赖于修改训练数据，但这并不总是实用的。

**Method:** 本文引入了概念消融微调（CAFT）技术。CAFT利用可解释性工具来控制LLM在微调时的泛化方式，而无需修改训练数据或使用来自目标分布的数据。具体来说，CAFT通过在微调期间使用线性投影消除LLM潜在空间中对应于不期望概念的方向，从而引导模型避免意外泛化。

**Result:** CAFT成功应用于三种微调任务，包括紧急失调现象。在不改变微调数据的情况下，CAFT将失调响应减少了10倍，同时没有降低训练分布上的性能。

**Conclusion:** CAFT代表了一种无需修改训练数据即可引导LLM泛化的新颖方法。

> **ai_Abstract:** 本文提出了一种名为概念消融微调（CAFT）的新技术，旨在解决大型语言模型（LLM）微调过程中出现的意外分布外泛化问题。与传统依赖修改训练数据的方法不同，CAFT利用可解释性工具，通过在LLM的潜在空间中识别并消除与不期望概念相关的方向来引导模型泛化，从而无需对训练数据进行任何改动。实验证明，CAFT在包括紧急失调在内的多项微调任务中表现出色，例如在不影响训练性能的情况下，将失调响应减少了10倍。这表明CAFT为控制LLM泛化提供了一种新颖且高效的方法。

> **摘要翻译:** 微调大型语言模型（LLM）可能导致意外的分布外泛化。解决此问题的标准方法依赖于修改训练数据，例如通过添加能更好指定预期泛化能力的数据。然而，这并不总是实用的。我们引入了概念消融微调（CAFT），这是一种利用可解释性工具来控制LLM如何从微调中泛化的技术，而无需修改训练数据或以其他方式使用来自目标分布的数据。给定LLM潜在空间中对应于不期望概念的一组方向，CAFT通过在微调期间使用线性投影消融这些概念来工作，从而引导模型远离意外泛化。我们成功地将CAFT应用于三个微调任务，包括紧急失调，这是一种LLM在窄任务上微调后泛化为对一般问题给出严重失调响应的现象。在不改变微调数据的情况下，CAFT将失调响应减少了10倍，而不会降低训练分布上的性能。总的来说，CAFT代表了一种无需修改训练数据即可引导LLM泛化的新颖方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [64] [Antithetic Sampling for Top-k Shapley Identification](https://arxiv.org/abs/2504.02019)
> *用于Top-k Shapley识别的对偶采样*

*Patrick Kolpaczki, Tim Nielen, Eyke Hüllermeier* | **Category: cs.LG, cs.AI, cs.GT** | **Updated: 2025-07-22**

**Keywords:** Shapley值, Top-k识别, 对偶采样, 特征重要性, 可解释AI

**Comment:** 

> **TL;DR:** Shapley值计算复杂，本文提出CMCS，一种新的采样方法，用于高效识别Top-k重要特征，并证明其有效性。

**AI_Comments:** 该论文的创新之处在于将Shapley值的研究重点从全面近似转移到更具实用价值的Top-k识别问题。通过引入利用相关观测（暗示对偶采样）的新采样方案CMCS，它有效地解决了Shapley值在实际应用中的计算瓶颈，并为特征重要性排序提供了一种高效的途径。同时，论文指出Top-k识别与全面近似是两个不同的问题，这一发现也具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 可解释AI中，Shapley值因其公理化唯一性而广受欢迎，但其计算复杂性严重限制了实用性。大多数工作关注所有特征的Shapley值的统一近似，为不重要特征消耗了不必要的样本。然而，识别k个最重要的特征就已足够有见地，并提供了利用与多臂老虎机领域相关的算法机会的潜力。

**Method:** 本文提出了一种名为可比边际贡献采样（CMCS）的方法，用于解决Top-k识别问题。该方法利用了一种新的采样方案，该方案利用了相关观测（对偶采样）的优势。

**Result:** 实验结果表明，与竞争基线相比，我们提出的方法是有效的。我们的经验发现揭示，近似所有问题的估计质量不一定能转移到Top-k识别，反之亦然。

**Conclusion:** 本文提出了一种高效的Top-k Shapley识别方法CMCS，通过利用新的采样方案和相关观测来解决Shapley值计算的实用性限制，并指出Top-k识别与近似所有Shapley值是不同的问题。

> **ai_Abstract:** 该论文旨在解决Shapley值计算成本高昂的问题，通过将重点放在仅识别Top-k个最重要的特征，而非近似所有特征。为此，它提出了一种名为可比边际贡献采样（CMCS）的新型采样方法，该方法利用相关观测来高效地进行Top-k识别。实验结果证明了CMCS的有效性，并揭示了近似所有Shapley值的估计质量与Top-k识别之间并不存在直接的转移关系。

> **摘要翻译:** 附加特征解释主要依赖于博弈论概念，如Shapley值，通过将特征视为合作玩家。Shapley值在可解释AI内外广受欢迎，源于其公理化唯一性。然而，其计算复杂性严重限制了实用性。大多数工作研究所有特征Shapley值的统一近似，不必要地为不重要特征消耗样本。相比之下，识别k个最重要的特征已经足够有见地，并有可能利用与多臂老虎机领域相关的算法机会。我们提出了可比边际贡献采样（CMCS），这是一种利用新的采样方案并利用相关观测的Top-k识别方法。我们进行了实验，展示了我们的方法与竞争基线相比的有效性。我们的经验发现揭示，近似所有问题的估计质量不一定能转移到Top-k识别，反之亦然。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [65] [Towards Reliable, Uncertainty-Aware Alignment](https://arxiv.org/abs/2507.15906)
> *迈向可靠的、不确定性感知的对齐*

*Debangshu Banerjee, Kintan Saha, Aditya Gopalan* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** LLM对齐, 奖励模型, 不确定性, 方差感知, 策略优化

**Comment:** 

> **TL;DR:** 当前LLM对齐因奖励模型不确定性而面临不稳定性。本文提出一种方差感知策略优化框架，通过引入新的正则化器，实现更稳定和鲁棒的对齐。

**AI_Comments:** 这篇论文解决了LLM对齐中的一个关键问题，即奖励模型的不确定性和可变性，这通常被忽视。引入方差感知正则化器是一种创新的方法，可以提高对齐的鲁棒性和可靠性，超越了单点估计的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的对齐通常依赖于奖励模型，但单一奖励模型的估计可能不准确，导致策略优化易受奖励模型不准确性的影响。经验研究表明，独立训练的奖励模型在同一偏好数据集上存在显著差异，表明当前对齐策略不稳定。理论模型进一步证明，奖励模型估计的可变性会导致过拟合，从而有性能下降的风险。

**Method:** 本文提出了一种用于基于偏好的对齐的方差感知策略优化框架，以减轻奖励模型可变性带来的风险。该框架的关键组成部分是一个新的策略正则化器，它结合了奖励模型的方差估计。

**Result:** 经验研究发现，在相同的偏好数据集上独立训练的奖励模型可能表现出显著的分歧，突出了当前对齐策略的不稳定性。理论模型表明，奖励模型估计的可变性会导致过拟合，进而导致性能下降的风险。实验证明，所提出的方差感知策略优化方法比默认方法更能降低输出更差策略的风险。在不同的LLM和奖励模型配置上的实验证实，该方法比标准（方差无关）流程产生了更稳定和鲁棒的对齐。

**Conclusion:** 解决奖励模型的不确定性和可变性对于实现可靠的LLM对齐至关重要。本文提出的方差感知策略优化框架通过引入考虑奖励模型方差的正则化器，有效提升了对齐的稳定性与鲁棒性。

> **ai_Abstract:** 本文旨在解决大型语言模型对齐过程中奖励模型不准确和不稳定的问题。研究发现，独立训练的奖励模型在同一偏好数据集上表现出显著差异，这种可变性会导致策略优化中的过拟合和性能下降。为解决此问题，作者提出了一个方差感知策略优化框架，其核心是一个新的策略正则化器，它结合了奖励模型的方差估计。实验证明，该方法比标准方法能实现更稳定、更鲁棒的对齐，并能有效降低输出较差策略的风险。

> **摘要翻译:** 大型语言模型（LLM）的对齐通常涉及在偏好数据上训练奖励模型，然后根据奖励模型进行策略优化。然而，根据单一奖励模型估计优化策略可能使其容易受到奖励模型不准确性的影响。我们实证研究了开源基准上奖励模型训练的可变性。我们观察到，在相同偏好数据集上独立训练的奖励模型可能表现出显著的分歧，突出了当前对齐策略的不稳定性。利用理论模型，我们证明了奖励模型估计的可变性可能导致过拟合，从而导致性能下降的风险。为了减轻这种风险，我们提出了一种用于基于偏好的对齐的方差感知策略优化框架。该框架的关键组成部分是一个新的策略正则化器，它结合了奖励模型的方差估计。我们表明，方差感知策略优化可证明地降低了输出比默认策略更差的策略的风险。跨不同LLM和奖励模型配置的实验证实，我们的方法比标准（方差无关）流程产生了更稳定和更鲁棒的对齐。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [83] [Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty](https://arxiv.org/abs/2507.16806)
> *超越二元奖励：训练语言模型推断其不确定性*

*Mehul Damani, Isha Puri, Stewart Slocum, Idan Shenfeld, Leshem Choshen, Yoon Kim, Jacob Andreas* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 强化学习, 语言模型, 校准性, 布里尔分数, 不确定性估计

**Comment:** 

> **TL;DR:** RLCR通过结合二元正确性得分和布里尔分数来训练语言模型，以同时提高准确性和校准置信度，解决传统RL训练导致的校准退化问题。

**AI_Comments:** 该论文的创新点在于提出了RLCR框架，通过将布里尔分数引入RL奖励函数，解决了传统二元奖励在训练语言模型时导致的校准性问题。这对于提高语言模型在实际应用中的可靠性和可信度具有重要意义，尤其是在需要模型输出置信度的场景。其贡献在于不仅从理论上证明了方法的有效性，还在实践中展示了其在不牺牲准确性的前提下显著改善了模型校准性，为构建更“诚实”的AI模型提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 当通过强化学习（RL）训练语言模型（LMs）生成自然语言“推理链”时，它们在各种困难的问答任务上表现有所提高。然而，目前几乎所有成功的RL推理应用都使用二元奖励函数来评估LM输出的正确性。这种奖励函数不惩罚猜测或低置信度输出，导致校准性下降并增加了LM在其他问题领域生成错误响应（或“幻觉”）的频率。

**Method:** 本文提出了RLCR（Reinforcement Learning with Calibration Rewards），一种训练推理模型的方法，它能同时提高准确性和校准置信度估计。在RLCR训练期间，LMs在推理后生成预测和数值置信度估计。它们被训练以优化一个奖励函数，该函数在二元正确性得分的基础上增加了布里尔分数——一种用于置信度估计的评分规则，旨在激励校准预测。作者首先证明了这种奖励函数（或任何使用有界、适当评分规则的类似奖励函数）能够产生既准确又校准良好的模型。

**Result:** 实验结果表明，在不同数据集上，RLCR显著改善了校准性，且没有损失准确性，无论是在领域内还是领域外评估中，都优于普通的RL训练和训练用于事后置信度评分的分类器。与普通RL会损害校准性不同，RLCR改善了校准性。此外，研究还发现，测试时可以利用语言化置信度，通过置信度加权缩放方法来提高准确性和校准性。

**Conclusion:** 研究结果表明，明确地优化校准性可以产生更普遍可靠的推理模型。

> **ai_Abstract:** 本研究提出RLCR（Reinforcement Learning with Calibration Rewards），旨在解决传统强化学习（RL）训练语言模型（LMs）时，因使用二元奖励函数导致校准性下降和幻觉增加的问题。RLCR通过引入结合二元正确性得分和布里尔分数的奖励函数，激励LMs在生成推理链时同时输出预测和数值置信度估计，从而联合优化准确性和校准置信度。理论证明此方法能产生准确且校准良好的模型。实验结果表明，RLCR在不同数据集上显著提高了校准性，且未损失准确性，优于普通RL训练及事后置信度分类器。研究强调，明确优化校准性对于构建更可靠的推理模型至关重要。

> **摘要翻译:** 当语言模型（LMs）通过强化学习（RL）训练生成自然语言“推理链”时，它们在各种困难的问答任务上表现有所提高。如今，几乎所有成功的RL推理应用都使用二元奖励函数来评估LM输出的正确性。由于此类奖励函数不惩罚猜测或低置信度输出，它们通常会产生意想不到的副作用，即降低校准性并增加LMs在其他问题领域生成错误响应（或“幻觉”）的频率。本文描述了RLCR（Reinforcement Learning with Calibration Rewards），一种训练推理模型的方法，它能同时提高准确性和校准置信度估计。在RLCR训练期间，LMs在推理后生成预测和数值置信度估计。它们被训练以优化一个奖励函数，该函数在二元正确性得分的基础上增加了布里尔分数——一种用于置信度估计的评分规则，旨在激励校准预测。我们首先证明了这种奖励函数（或任何使用有界、适当评分规则的类似奖励函数）能够产生既准确又校准良好的模型。我们接下来展示，在不同数据集上，RLCR显著改善了校准性，且没有损失准确性，无论是在领域内还是领域外评估中——优于普通的RL训练和训练用于事后置信度评分的分类器。与普通RL会损害校准性不同，RLCR改善了校准性。最后，我们证明了在测试时可以通过置信度加权缩放方法利用语言化置信度来提高准确性和校准性。我们的结果表明，明确地优化校准性可以产生更普遍可靠的推理模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [90] [Manifold Learning with Normalizing Flows: Towards Regularity, Expressivity and Iso-Riemannian Geometry](https://arxiv.org/abs/2505.08087)
> *流形学习与归一化流：迈向正则性、表达性和等距黎曼几何*

*Willem Diepeveen, Deanna Needell* | **Category: cs.LG, math.DG** | **Updated: 2025-07-21**

**Keywords:** 流形学习, 归一化流, 黎曼几何, 多模态数据, 微分同胚

**Comment:** 

> **TL;DR:** 本文通过等距化学习到的黎曼结构并平衡微分同胚参数化的正则性和表达性，利用归一化流解决多模态数据中可能出现的扭曲和建模误差问题。

**AI_Comments:** 本文创新性地将归一化流应用于流形学习，特别关注了多模态数据中扭曲和建模误差的问题。通过等距化黎曼结构和平衡微分同胚的正则性与表达性，它为非线性数据分析和可解释机器学习提供了新的思路。该方法有望提升复杂数据场景下的模型性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理真实世界多模态数据时仍存在挑战，特别是可能出现的扭曲和建模误差。

**Method:** 通过等距化学习到的黎曼结构，并平衡微分同胚参数化的正则性和表达性，以减轻多模态数据中的扭曲和建模误差。

**Result:** 在合成数据和真实数据的多个数值实验中展示了所提出方法的协同效应的有效性。

**Conclusion:** 所提出的等距化黎曼结构和平衡微分同胚参数化正则性与表达性的方法，在处理多模态数据中的扭曲和建模误差方面是有效的。

> **ai_Abstract:** 本研究利用流形假设，结合归一化流，旨在解决多模态数据处理中常见的扭曲和建模误差。通过等距化学习到的黎曼结构并平衡微分同胚参数化的正则性与表达性，该方法提高了数据分析的性能和可解释性。在合成和真实数据集上的实验验证了其有效性。

> **摘要翻译:** 现代机器学习越来越多地利用高维数据通常位于低维非线性流形附近这一见解，即流形假设。通过学习黎曼几何算法明确建模数据的几何结构，可以在聚类、降维和插值等任务中实现改进的性能和可解释性。特别是，学习到的回拉几何最近经历了变革性发展，使其现在可以大规模学习和评估，这进一步为有原则的非线性数据分析和可解释机器学习打开了大门。然而，在考虑真实世界多模态数据时仍有许多步骤需要采取。这项工作致力于解决多模态设置中可能出现的扭曲和建模误差，并提出通过等距化学习到的黎曼结构以及平衡微分同胚参数化的正则性和表达性来缓解这两个挑战。我们在合成数据和真实数据的多个数值实验中展示了所提出方法的协同效应的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [102] [Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design](https://arxiv.org/abs/2507.16307)
> *钙钛矿-R1：一种用于前驱体添加剂智能发现和实验设计的领域专用大型语言模型*

*Xin-De Wang, Zhi-Rui Chen, Peng-Jie Guo, Ze-Feng Gao, Cheng Mu, Zhong-Yi Lu* | **Category: cs.LG, cond-mat.mtrl-sci, cs.AI, physics.chem-ph** | **Updated: 2025-07-22**

**Keywords:** 钙钛矿太阳能电池, 大型语言模型, 前驱体添加剂, 材料发现, 实验设计

**Comment:** 24 pages; 5 figures

> **TL;DR:** Perovskite-R1是一个领域专用的大型语言模型（LLM），旨在通过整合海量科学文献和材料数据，智能地发现钙钛矿太阳能电池的前驱体添加剂并辅助实验设计，从而有效提升材料的稳定性和性能。

**AI_Comments:** 该论文的创新之处在于将大型语言模型（LLM）应用于高度专业化的材料科学领域，通过大规模数据整合和领域特定微调，实现了前驱体添加剂的智能发现与实验设计。这为解决钙钛矿太阳能电池研发中信息过载和知识应用效率低下的问题提供了新颖且高效的范式。其重要性体现在加速新材料发现和优化实验流程的潜力，有望显著推动钙钛矿光伏技术的商业化进程。

<details>
  <summary>Details</summary>

**Motivation:** 钙钛矿太阳能电池（PSCs）尽管在功率转换效率和材料特性上表现出色，但其长期稳定性、环境可持续性和可扩展制造方面的挑战阻碍了商业化。前驱体添加剂工程是解决这些问题的有效途径，然而，科学文献的爆炸式增长以及材料、工艺和器件架构之间复杂的相互作用，使得研究人员难以高效获取、组织和利用该领域的专业知识。

**Method:** 为解决现有问题，研究人员引入了Perovskite-R1，一个针对PSC前驱体添加剂发现和设计而定制的专业大型语言模型。该模型通过系统性地挖掘和整理1,232篇高质量科学出版物，并整合了一个包含33,269种候选材料的综合库。研究人员利用自动化问答生成和思维链推理，构建了一个领域特定的指令调优数据集，并在此数据集上对QwQ-32B模型进行了微调，最终得到了Perovskite-R1。

**Result:** Perovskite-R1能够智能地综合文献见解，并为缺陷钝化和前驱体添加剂的选择生成创新且实用的解决方案。通过对模型提出的几种策略进行实验验证，证实了它们在改善材料稳定性和性能方面的有效性。

**Conclusion:** 该工作展示了领域适应型大型语言模型在加速材料发现方面的巨大潜力，并为钙钛矿光伏研究中实现智能、数据驱动的进步提供了一个闭环框架。

> **ai_Abstract:** 本文介绍了Perovskite-R1，一个专为钙钛矿太阳能电池（PSC）前驱体添加剂智能发现和实验设计而优化的领域专用大型语言模型（LLM）。鉴于PSC在稳定性、可持续性和制造上面临的挑战，该模型通过系统整合1,232篇高质量科学文献和33,269种候选材料，构建了特定领域的指令调优数据集，并在此基础上微调了QwQ-32B模型。Perovskite-R1能够智能地综合文献见解，并为缺陷钝化和前驱体添加剂选择提供创新解决方案。实验验证证实了模型提出策略在提升材料稳定性和性能方面的有效性，凸显了领域适应型LLM在加速材料发现方面的巨大潜力，并为钙钛矿光伏研究提供了一个智能、数据驱动的框架。

> **摘要翻译:** 钙钛矿太阳能电池（PSCs）凭借其卓越的功率转换效率和有利的材料特性，已迅速成为下一代光伏技术的主要竞争者。尽管取得了这些进展，但长期稳定性、环境可持续性和可扩展制造等挑战仍阻碍其商业化。前驱体添加剂工程通过提高PSCs的性能和耐久性，在解决这些问题方面显示出前景。然而，科学文献的爆炸式增长以及材料、工艺和器件架构之间复杂的相互作用，使得研究人员越来越难以高效地获取、组织和利用这个快速发展领域的领域知识。为弥补这一空白，我们引入了Perovskite-R1，一个专门的大型语言模型（LLM），具有为PSCs前驱体添加剂的发现和设计量身定制的高级推理能力。通过系统挖掘和整理1,232篇高质量科学出版物，并整合一个包含33,269种候选材料的综合库，我们利用自动化问答生成和思维链推理构建了一个领域特定的指令调优数据集。在此数据集上对QwQ-32B模型进行微调，形成了Perovskite-R1，它能够智能地综合文献见解，并为缺陷钝化和前驱体添加剂的选择生成创新且实用的解决方案。对模型提出的几种策略进行的实验验证证实了它们在改善材料稳定性和性能方面的有效性。我们的工作展示了领域适应型LLMs在加速材料发现方面的潜力，并为钙钛矿光伏研究中智能、数据驱动的进步提供了一个闭环框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [103] [Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning](https://arxiv.org/abs/2507.16814)
> *视觉-语言慢思考推理的半离线策略强化学习*

*Junhao Shen, Haiteng Zhao, Yuzhe Gu, Songyang Gao, Kuikun Liu, Haian Huang, Jianfei Gao, Dahua Lin, Wenwei Zhang, Kai Chen* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 半离线策略强化学习, 视觉-语言模型, 慢思考推理, 多模态推理, SOPHIA

**Comment:** 

> **TL;DR:** SOPHIA提出一种半离线策略强化学习方法，用于提升大型视觉-语言模型（LVLMs）的慢思考推理能力，解决了现有强化学习在LVLMs中应用的挑战，并在多个基准测试中取得了SOTA性能。

**AI_Comments:** 本文的创新点在于提出了SOPHIA这一半离线策略强化学习框架，巧妙地结合了在线策略的视觉理解和离线策略的语言模型推理，有效解决了LVLM在慢思考推理中面临的挑战（如在线策略的限制和离线策略的视觉幻觉）。其重要性体现在显著提升了LVLM在复杂多模态推理任务上的性能，甚至超越了部分闭源模型，为LVLM的训练和能力提升开辟了新的途径。该方法为后续的在线策略训练提供了更好的初始化，具有潜在的广泛应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 增强大型视觉-语言模型（LVLMs）的视觉慢思考推理能力对于解决复杂多模态任务至关重要。然而，由于LVLMs主要通过视觉-语言对齐训练，采用在线策略强化学习（RL）来发展慢思考能力很困难，因为其展开空间受限于初始能力。离线策略RL虽然可以超越当前策略，但直接从外部模型提取轨迹可能因模型间视觉感知能力不匹配而导致视觉幻觉。

**Method:** 本文提出了SOPHIA，一种简单且可扩展的用于视觉-语言慢思考推理的半离线策略强化学习方法。SOPHIA通过结合可训练LVLM的在线策略视觉理解和语言模型的离线策略慢思考推理，构建了一个半离线策略行为模型。它为推理分配基于结果的奖励，并向后传播视觉奖励。随后，LVLM利用获得的推理轨迹和传播的奖励，通过离线策略RL算法学习慢思考推理能力。

**Result:** 对InternVL2.5和InternVL3.0（8B和38B大小）进行的广泛实验表明了SOPHIA的有效性。值得注意的是，SOPHIA平均将InternVL3.0-38B的性能提高了8.50%，在多个多模态推理基准测试中达到了开源LVLM的最新水平，甚至在挑战性的MathVision和OlympiadBench上超越了一些闭源模型（如GPT-4.1），分别取得了49.08%和49.95%的pass@1准确率。分析表明，SOPHIA优于监督微调和直接在线策略RL方法，为进一步的在线策略训练提供了更好的策略初始化。

**Conclusion:** SOPHIA提出了一种有效的半离线策略强化学习框架，成功提升了大型视觉-语言模型的慢思考推理能力，并在多个复杂推理任务上表现出卓越的性能，超越了现有方法和一些闭源模型，为LVLM的进一步训练提供了更好的策略初始化。

> **ai_Abstract:** 本文提出SOPHIA，一种用于提升大型视觉-语言模型（LVLMs）慢思考推理能力的半离线策略强化学习方法。针对传统在线策略RL受限于LVLM初始能力和离线策略RL易导致视觉幻觉的问题，SOPHIA结合了LVLM的在线视觉理解和语言模型的离线慢思考推理，通过基于结果的奖励和视觉奖励反向传播训练LVLM。实验证明，SOPHIA显著提升了InternVL3.0-38B在多模态推理基准上的性能，达到开源LVLM的SOTA水平，并在MathVision和OlympiadBench上超越部分闭源模型，同时优于监督微调和直接在线策略RL。

> **摘要翻译:** 增强大型视觉-语言模型（LVLMs）的视觉慢思考推理能力对于解决复杂多模态任务至关重要。然而，由于LVLMs主要通过视觉-语言对齐训练，采用在线策略强化学习（RL）来发展慢思考能力很困难，因为其展开空间受限于初始能力。离线策略RL提供了一种超越当前策略的方法，但直接从外部模型提取轨迹可能因模型间视觉感知能力不匹配而导致视觉幻觉。为了解决这些问题，本文提出了SOPHIA，一种简单且可扩展的用于视觉-语言慢思考推理的半离线策略强化学习。SOPHIA通过结合可训练LVLM的在线策略视觉理解和语言模型的离线策略慢思考推理，构建了一个半离线策略行为模型，为推理分配基于结果的奖励，并向后传播视觉奖励。然后LVLM利用获得的推理轨迹和传播的奖励，通过离线策略RL算法学习慢思考推理能力。对InternVL2.5和InternVL3.0（8B和38B大小）进行的广泛实验表明了SOPHIA的有效性。值得注意的是，SOPHIA平均将InternVL3.0-38B的性能提高了8.50%，在多个多模态推理基准测试中达到了开源LVLM的最新水平，甚至在挑战性的MathVision和OlympiadBench上超越了一些闭源模型（如GPT-4.1），分别取得了49.08%和49.95%的pass@1准确率。分析表明，SOPHIA优于监督微调和直接在线策略RL方法，为进一步的在线策略训练提供了更好的策略初始化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [106] [Dual Turing Test: A Framework for Detecting and Mitigating Undetectable AI](https://arxiv.org/abs/2507.15907)
> *双重图灵测试：一种检测和缓解不可检测AI的框架*

*Alberto Messina* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 双重图灵测试, AI检测, 对抗性博弈, 强化学习, AI对齐

**Comment:** 

> **TL;DR:** 本文提出了一个统一框架，即“双重图灵测试”，用于检测和缓解难以察觉的AI，该框架结合了对抗性分类博弈和强化学习对齐。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的框架来解决AI检测问题，特别是针对难以察觉的AI。它将传统的图灵测试进行反转，并结合了对抗性博弈论和强化学习对齐技术，提供了一个理论上严谨且实践上可行的检测与缓解AI不可检测性的方法。这种多学科的融合是其重要性所在。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决现有图灵测试的局限性，并开发一种能够识别和缓解“不可检测”AI的框架。

**Method:** 本文提出了一个统一框架，包含三个核心部分：1) “双重图灵测试”：人类法官的目标是识别AI；2) 一个形式化的对抗性分类博弈，具有明确的质量约束和最坏情况保证；3) 一个强化学习（RL）对齐管道，其奖励模型包含不可检测性检测器和质量相关组件。该框架通过结合质量阈值、分阶段难度和最小最大界限来形式化双重测试，并将其映射到RL-HF风格的对齐循环中，其中不可检测性检测器对隐秘输出提供负奖励。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一个名为“双重图灵测试”的统一框架，旨在检测和缓解难以察觉的AI。该框架将人类识别AI的翻转图灵测试视角、形式化的对抗性分类博弈以及基于强化学习的AI对齐管道相结合。它通过引入质量阈值、分阶段难度和最小最大界限来形式化双重测试，并将其映射到RL-HF对齐循环中，利用不可检测性检测器对隐秘输出施加负奖励，同时通过质量代理保持输出流畅性。

> **摘要翻译:** 在这篇短文中，我们提出了一个统一的框架，它连接了三个领域：
(1) 图灵测试的一个翻转视角，即“双重图灵测试”，其中人类评判者的目标是识别AI，而不是奖励机器的欺骗行为；
(2) 一个形式化的对抗性分类博弈，具有明确的质量约束和最坏情况保证；
(3) 一个强化学习（RL）对齐管道，在其奖励模型中使用了不可检测性检测器和一套与质量相关的组件。
我们回顾了历史先例，从倒置和元图灵变体到现代监督式逆向图灵分类器，并强调了结合质量阈值、分阶段难度级别和最小最大界限的新颖性。然后，我们形式化了双重测试：定义了法官在N个独立回合中的任务，这些回合从提示空间Q中抽取新的提示，引入了质量函数Q和参数tau、delta，并将这种交互视为对手可行策略集M上的双人零和博弈。接下来，我们将这种最小最大博弈映射到RL-HF风格的对齐循环中，其中不可检测性检测器D为隐秘输出提供负奖励，并通过一个保持流畅性的质量代理进行平衡。
在整个过程中，我们详细解释了每个组件的符号、序列内部最小化的含义、分阶段测试以及迭代对抗训练，并最后提出了几项即时行动的建议。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [115] [Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation](https://arxiv.org/abs/2505.17579)
> *基于白盒对抗性攻击和指定概率操纵的DNN模型所有权验证*

*Teruki Sano, Minoru Kuribayashi, Masao Sakai, Shuji Ishobe, Eisuke Koizumi* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** DNN模型, 所有权验证, 白盒对抗性攻击, 概率操纵, FGSM

**Comment:** Accepted to EUSIPCO 2025

> **TL;DR:** 本文提出了一种新颖的框架，利用白盒对抗性攻击来验证深度神经网络（DNN）模型的所有权，通过操纵特定类别的输出概率，即使在灰盒场景下也能进行验证。

**AI_Comments:** 该论文的创新点在于将白盒对抗性攻击应用于DNN模型的所有权验证，这为模型知识产权保护提供了一种新颖的思路。特别是在模型被非法复制并在云环境中提供服务的灰盒场景下，这种方法具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在图像分类任务中，当DNN模型被非法复制并在云环境中提供服务时，需要一种方法让模型所有者和第三方无需原始模型即可验证模型的身份。

**Method:** 本文提出了一种利用白盒对抗性攻击进行DNN模型所有权验证的新颖框架。该框架应用白盒对抗性攻击，将特定类别的输出概率调整到指定值。通过对原始模型的了解，所有者能够生成此类对抗性样本。作者提出了一种基于迭代快速梯度符号法（FGSM）的简单而有效的对抗性攻击方法，并引入了控制参数。

**Result:** 实验结果证实了使用对抗性攻击识别DNN模型的有效性。

**Conclusion:** 通过利用白盒对抗性攻击并操纵输出概率，所提出的框架能够有效地实现DNN模型的所有权验证。

> **ai_Abstract:** 本文提出了一种新颖的框架，用于图像分类DNN模型的所有权验证。该框架在灰盒场景下运行，允许所有者和第三方在不提供原始模型的情况下验证模型身份。它通过应用一种基于迭代FGSM的白盒对抗性攻击来实现，该攻击能够将特定类别的输出概率操纵到指定值。所有者利用对原始模型的了解生成这些对抗性样本。实验结果验证了该方法在识别DNN模型方面的有效性。

> **摘要翻译:** 在本文中，我们提出了一种用于图像分类任务的深度神经网络（DNN）模型所有权验证的新颖框架。它允许合法的模型所有者和第三方在不提供原始模型的情况下验证模型身份。我们假设一个灰盒场景，其中未经授权的用户拥有一个从原始模型非法复制的模型，并在云环境中提供服务，用户输入图像并接收作为输出类别概率分布的分类结果。该框架应用白盒对抗性攻击，使特定类别的输出概率与指定值对齐。由于了解原始模型，它使所有者能够生成此类对抗性样本。我们提出了一种基于迭代快速梯度符号法（FGSM）的简单而有效的对抗性攻击方法，通过引入控制参数。实验结果证实了使用对抗性攻击识别DNN模型的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [140] [Note on Follow-the-Perturbed-Leader in Combinatorial Semi-Bandit Problems](https://arxiv.org/abs/2506.12490)
> *关于组合半赌博机问题中扰动领导者跟随策略的说明*

*Botao Chen, Junya Honda* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 扰动领导者跟随, 组合半赌博机, 遗憾界限, 几何重采样, 计算复杂度

**Comment:** Corrected typos and the error of the proof of Lemma 10

> **TL;DR:** 本文研究了在规模不变的组合半赌博机问题中，扰动领导者跟随（FTPL）策略的最优性和复杂性，并给出了其在不同分布下的遗憾界限，同时提出了降低计算复杂度的改进方法。

**AI_Comments:** 本文的创新点在于将FTPL策略扩展并分析到更复杂的组合半赌博机问题中，并针对其在不同分布下的遗憾界限给出了明确的理论保证。特别是引入条件几何重采样（CGR）来优化计算复杂度，解决了实际应用中的效率瓶颈，这对于该领域的算法设计和部署具有重要意义。该研究填补了FTPL在组合半赌博机问题中理论分析的空白。

<details>
  <summary>Details</summary>

**Motivation:** 最近的研究表明FTPL在标准多臂赌博机问题中实现了“两全其美”（BOBW）的最优性，但FTPL在组合半赌博机问题中的最优性仍不清楚，因此本文旨在解决这一问题。

**Method:** 本文考虑了在规模不变的半赌博机设置中，带有几何重采样（GR）的FTPL的遗憾界限。此外，还将条件几何重采样（CGR）扩展到规模不变的半赌博机设置。

**Result:** 结果表明，FTPL在Fréchet分布下实现了$O\left(\sqrt{m^2 d^\frac{1}{\alpha}T}+\sqrt{mdT}\right)$的遗憾，在Pareto分布下的对抗性设置中实现了$O\left(\sqrt{mdT}\right)$的最佳可能遗憾界限。此外，通过将CGR扩展到规模不变的半赌博机设置，计算复杂度从原始GR的$O(d^2)$降低到$O\left(md\left(\log(d/m)+1\right)\right)$，且不牺牲FTPL的遗憾性能。

**Conclusion:** 本文证明了在规模不变的组合半赌博机问题中，带有几何重采样和条件几何重采样的扰动领导者跟随（FTPL）策略能够实现接近最优的遗憾界限，并通过CGR显著降低了计算复杂度。

> **ai_Abstract:** 本文深入探讨了扰动领导者跟随（FTPL）策略在规模不变的组合半赌博机问题中的性能。针对现有研究未明确FTPL在此类问题中最优性的空白，作者分析了带有几何重采样（GR）的FTPL的遗憾界限，并证明其在Fréchet和Pareto分布下能达到特定的、甚至最优的遗憾界限。更进一步，通过引入条件几何重采样（CGR），论文成功地在不影响遗憾性能的前提下，显著降低了算法的计算复杂度，从而提升了FTPL在复杂组合环境下的实用性。

> **摘要翻译:** 本文研究了规模不变的组合半赌博机问题中扰动领导者跟随（FTPL）策略的最优性和复杂性。最近，Honda 等人（2023）和 Lee 等人（2024）表明 FTPL 在具有 Fréchet 型分布的标准多臂赌博机问题中实现了“两全其美”（BOBW）的最优性。然而，FTPL 在组合半赌博机问题中的最优性仍不清楚。在本文中，我们考虑了在规模不变的半赌博机设置中，带有几何重采样（GR）的 FTPL 的遗憾界限，结果表明 FTPL 在 Fréchet 分布下分别实现了 $O\left(\sqrt{m^2 d^\frac{1}{\alpha}T}+\sqrt{mdT}\right)$ 的遗憾，在 Pareto 分布下的对抗性设置中实现了 $O\left(\sqrt{mdT}\right)$ 的最佳可能遗憾界限。此外，我们将条件几何重采样（CGR）扩展到规模不变的半赌博机设置，这将原始 GR 的计算复杂度从 $O(d^2)$ 降低到 $O\left(md\left(\log(d/m)+1\right)\right)$，同时不牺牲 FTPL 的遗憾性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [146] [HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs](https://arxiv.org/abs/2507.15917)
> *HyDRA：一种用于可验证知识图谱的混合驱动推理架构*

*Adrian Kaiser, Claudiu Leoveanu-Condrei, Ryan Gold, Marius-Constantin Dinu, Markus Hofmarcher* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 知识图谱, 神经符号AI, 自动化构建, 可验证性, 混合驱动推理

**Comment:** 8 pages, 4 figures

> **TL;DR:** HyDRA提出了一种混合驱动推理架构，通过神经符号智能体和可验证契约来自动化知识图谱构建，解决了可靠性、一致性和可验证性问题。

**AI_Comments:** HyDRA的创新之处在于其混合驱动方法，结合了神经符号智能体和契约式设计原则来自动化知识图谱构建，并特别关注了输出的可验证性。通过引入可验证契约作为LLM生成过程的控制机制，它有效地解决了传统KG构建中的可靠性问题。此外，其提出的评估框架超越了传统基准，强调了功能正确性，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 神经符号AI中，符号知识（如知识图谱）与神经网络生成能力结合的潜力巨大，但自动化知识图谱构建面临输出可靠性、一致性和可验证性等挑战，如数据孤岛或抽象类与实例混淆。

**Method:** HyDRA架构首先通过一组协作的神经符号智能体构建本体，这些智能体共同确定能力问题（CQs）以定义本体范围。然后，基于CQs构建本体图，指导从文档中自动提取三元组以生成知识图谱。该方法受契约式设计（DbC）原则启发，利用可验证契约作为主要控制机制来引导大型语言模型（LLMs）的生成过程。

**Result:** 该工作提出了一种混合驱动架构，用于提高自动化知识图谱构建的可靠性，并探索了衡量其输出功能完整性的评估方法。通过扩展标准基准，并利用神经符号AI框架SymbolicAI的符号验证来评估结果知识图谱的功能正确性。

**Conclusion:** HyDRA提出了一种混合驱动架构，显著提高了自动化知识图谱构建的可靠性，并通过创新的评估框架验证了其输出的功能完整性，为神经符号AI的进步做出了贡献。

> **ai_Abstract:** 本研究提出HyDRA，一种混合驱动推理架构，旨在解决自动化知识图谱构建中存在的可靠性、一致性和可验证性问题。HyDRA通过协作的神经符号智能体构建本体，并利用可验证契约引导大型语言模型生成知识图谱三元组。为验证其输出，论文还提出了一个基于符号验证的评估框架。该工作提升了自动化知识图谱构建的可靠性，并提供了衡量其功能完整性的新评估方法。

> **摘要翻译:** 符号知识（通常由知识图谱表示）与神经网络生成能力之间的协同作用是推进神经符号AI的核心。实现这一潜力的主要瓶颈是自动化知识图谱构建的困难，它面临着输出可靠性、一致性和可验证性方面的挑战。这些问题可能表现为生成图中的结构不一致，例如形成不连通的“数据孤岛”或将抽象类与特定实例不准确地混淆。为了解决这些挑战，我们提出了HyDRA，一种混合驱动推理架构，旨在实现可验证的知识图谱自动化。给定一个领域或一组初始文档，HyDRA首先通过一组协作的神经符号智能体构建一个本体。这些智能体共同商定一组能力问题（CQs），这些问题定义了本体必须能够回答的范围和要求。基于这些CQs，我们构建一个本体图，该图随后指导从任意文档中自动提取三元组以生成知识图谱。受契约式设计（DbC）原则的启发，我们的方法利用可验证契约作为主要控制机制来引导大型语言模型（LLMs）的生成过程。为了验证我们方法的输出，我们超越了标准基准，并提出了一个评估框架，通过利用神经符号AI框架SymbolicAI所描述的符号验证来评估所得知识图谱的功能正确性。这项工作贡献了一种混合驱动架构，用于提高自动化知识图谱构建的可靠性，并探索了衡量其输出功能完整性的评估方法。代码已公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [147] [The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches for $\ell_2$ Norm Estimation](https://arxiv.org/abs/2507.16345)
> *压缩的代价：针对 $\ell_2$ 范数估计草图的紧致二次黑盒攻击*

*Sara Ahmadian, Edith Cohen, Uri Stemmer* | **Category: cs.LG, cs.DS** | **Updated: 2025-07-22**

**Keywords:** 线性草图, 对抗性攻击, 黑盒攻击, $\ell_2$ 范数估计, 降维

**Comment:** 

> **TL;DR:** 本文提出了一种通用的黑盒攻击，可以在对任何线性草图和估计器进行约 $k^2$ 次查询后，导致 $\ell_2$ 范数估计失败或构造对抗性输入，揭示了压缩表示的内在漏洞。

**AI_Comments:** 这项研究的创新之处在于提出了一种通用的黑盒攻击，其对线性草图和估计器的类型具有完全的不可知性，极大地拓展了攻击的适用范围。其重要性在于量化并证明了压缩表示的内在漏洞，并以紧密的二次复杂度匹配了理论下界，为理解和防御数据压缩中的对抗性威胁提供了坚实的基础。将结果与图像分类中的对抗性攻击建立联系，也为跨领域研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 线性草图作为一种降维技术虽然强大且广泛使用，但已知其易受对抗性输入攻击。本文旨在研究黑盒对抗性设置下，如何攻击通过草图计算近似 $\ell_2$ 范数估计的系统。

**Method:** 本文提出了一种通用的、非自适应的黑盒攻击。该攻击在约 $k^2$ 次查询下，能够导致范数估计失败或构建对抗性输入，使得用于攻击的查询分布的最佳估计器失效。该攻击对草图矩阵和估计器完全不感知，适用于任何线性草图和查询响应器，包括随机、自适应或为特定查询分布定制的系统。

**Result:** 该攻击使用约 $k^2$ 次查询，能够导致范数估计失败或构造对抗性输入。此外，本文的下界构造与约翰逊-林登施特劳斯变换和AMS草图的已知上界（约 $k^2$）紧密匹配。

**Conclusion:** 研究结果揭示了压缩表示的内在脆弱性，并发现了与图像分类中对抗性攻击的结构性相似之处，强调了压缩表示的根本性漏洞。

> **ai_Abstract:** 本文研究了线性草图在黑盒对抗性设置下的脆弱性。作者提出了一种通用的、非自适应的攻击方法，该方法仅需约 $k^2$ 次查询，即可导致 $\ell_2$ 范数估计失败或生成对抗性输入。此攻击对草图矩阵和估计器类型（包括随机、自适应或定制的）均不敏感。研究还构造了一个紧密匹配已知上界的下界，并指出其结果揭示了压缩表示的固有漏洞，与图像分类中的对抗性攻击存在结构性相似。

> **摘要翻译:** 通过线性草图进行降维是一种强大且广泛使用的技术，但已知其易受对抗性输入的影响。我们研究黑盒对抗性设置，其中一个固定的、隐藏的草图矩阵 A 在 $R^{k \times n}$ 中将高维向量 v $\in R^n$ 映射到低维草图 A v 在 $R^k$ 中，并且攻击者可以查询系统以获得从草图计算的近似 $\ell_2$ 范数估计。
我们提出了一种通用的、非自适应的攻击，使用约 $k^2$ 次查询，要么导致范数估计失败，要么构造一个对抗性输入，使得用于攻击的查询分布的最佳估计器失效。该攻击对草图矩阵和估计器完全不感知：它适用于任何线性草图和任何查询响应器，包括那些随机的、自适应的或为查询分布定制的。
我们的下界构造与约翰逊-林登施特劳斯变换和AMS草图的已知上界（约 $k^2$）紧密匹配。除了草图之外，我们的结果揭示了与图像分类中对抗性攻击的结构性相似之处，突出了压缩表示的根本性漏洞。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [165] [Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data](https://arxiv.org/abs/2506.16629)
> *从精神病学纵向数据中学习因果可预测结果*

*Eric V. Strobl* | **Category: cs.LG, q-bio.QM, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 因果推断, 纵向数据, 精神病学, 混杂, DEBIAS

**Comment:** R code is available at github.com/ericstrobl/DEBIAS

> **TL;DR:** DEBIAS算法通过优化结果定义和最小化混杂因素，提高了精神病学纵向数据中的因果推断能力。

**AI_Comments:** 本文的创新点在于其直接优化结果定义以最大化因果可识别性的方法，这与传统方法预设固定结果的思路不同。DEBIAS算法通过整合时间限制的直接效应来同时处理观测和潜在混杂，并提供了一个实用的无混杂性检验，这对于提高精神病学研究的因果推断准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 纵向生物医学数据（尤其是精神病学数据）中的因果推断面临挑战，因为症状异质性和潜在混杂因素常常破坏传统估计器。大多数现有方法预设固定结果变量并通过观测协变量调整来处理混杂，但“无混杂”假设在实践中可能不成立。

**Method:** 本文提出了DEBIAS（Durable Effects with Backdoor-Invariant Aggregated Symptoms）算法。该算法通过直接优化结果定义来最大化因果可识别性。它学习非负的、临床可解释的权重用于结果聚合，通过利用精神病学纵向数据中先前治疗的时间限制直接效应，最大化持久治疗效果并经验性地最小化观测和潜在混杂。该算法还提供了一个可经验验证的结果无混杂性检验。

**Result:** DEBIAS算法在抑郁症和精神分裂症的综合实验中，在恢复临床可解释的复合结果的因果效应方面，持续优于现有最先进的方法。

**Conclusion:** DEBIAS算法通过优化结果定义和有效处理混杂因素，显著提升了精神病学纵向数据中的因果推断能力，并提供了一种可验证的无混杂性测试。

> **ai_Abstract:** 本研究提出DEBIAS算法，旨在解决精神病学纵向数据中因果推断的挑战。针对现有方法固定结果变量和混杂假设的局限性，DEBIAS通过直接优化结果定义来最大化因果可识别性，并学习可解释的权重聚合症状，以最大化持久治疗效果并最小化观测和潜在混杂。实验证明，DEBIAS在恢复因果效应方面优于现有方法，并提供可验证的无混杂性测试。

> **摘要翻译:** 因果推断在纵向生物医学数据中仍然是一个核心挑战，尤其是在精神病学领域，症状异质性和潜在混杂因素经常会破坏经典估计器。大多数现有的治疗效果估计方法都预设了一个固定的结果变量，并通过观测协变量调整来解决混杂问题。然而，在实践中，对于一个固定的结果，无混杂性假设可能不成立。为了解决这一根本性限制，我们直接优化结果定义以最大化因果可识别性。我们的DEBIAS（Durable Effects with Backdoor-Invariant Aggregated Symptoms）算法学习非负的、临床可解释的权重用于结果聚合，通过利用精神病学纵向数据中先前治疗的时间限制直接效应，最大化持久治疗效果并经验性地最小化观测和潜在混杂。该算法还提供了一个可经验验证的结果无混杂性检验。DEBIAS在抑郁症和精神分裂症的综合实验中，在恢复临床可解释的复合结果的因果效应方面，持续优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [186] [On the transferability of Sparse Autoencoders for interpreting compressed models](https://arxiv.org/abs/2507.15977)
> *稀疏自编码器在解释压缩模型中的可迁移性研究*

*Suchit Gupte, Vishnu Kabir Chhabra, Mohammad Mahdi Khalili* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 稀疏自编码器, 模型压缩, 可解释性, 大型语言模型, 剪枝

**Comment:** 

> **TL;DR:** 本研究探讨了稀疏自编码器（SAEs）在解释原始模型和压缩模型时的差异，发现原始模型上训练的SAE可以解释压缩模型，并且对原始SAE进行剪枝可以达到与在新压缩模型上训练SAE相似的性能，从而降低了SAE的训练成本。

**AI_Comments:** 这项工作非常有意义，因为它解决了大型语言模型压缩后可解释性下降的问题。通过发现原始SAE的可迁移性以及剪枝SAE的有效性，该研究为降低SAE的训练成本提供了实用的解决方案，从而促进了对压缩模型内部机制的理解。这一方法有望加速LLM可解释性领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型（LLMs）由于其规模庞大而面临推理效率挑战。为了解决这个问题，已经提出了许多压缩方法（如剪枝和量化）。然而，压缩对模型可解释性的影响仍然不明确。

**Method:** 本研究探索了稀疏自编码器（SAEs）在原始模型和压缩模型上的差异。研究人员比较了在原始模型上训练的SAE解释压缩模型的性能，以及对原始SAE进行剪枝后解释剪枝模型的性能。

**Result:** 研究发现，在原始模型上训练的SAE可以解释压缩模型，尽管与在压缩模型上训练的SAE相比性能略有下降。此外，简单地剪枝原始SAE本身就可以实现与在新剪枝模型上训练新SAE相当的性能。

**Conclusion:** 这一发现使得研究人员能够减轻稀疏自编码器（SAEs）高昂的训练成本。

> **ai_Abstract:** 本研究探讨了稀疏自编码器（SAEs）在解释原始和压缩大型语言模型中的可迁移性。研究发现，在原始模型上训练的SAE能够有效解释压缩模型，尽管性能略有下降。更重要的是，通过简单地剪枝原始SAE，其解释性能可与在新的压缩模型上训练SAE相媲美。这一发现为降低SAE的训练成本提供了有效途径，有助于提高压缩模型的可解释性研究效率。

> **摘要翻译:** 现代大型语言模型（LLMs）由于其规模庞大而面临推理效率挑战。为了解决这个问题，已经提出了许多压缩方法，例如剪枝和量化。然而，压缩对模型可解释性的影响仍然不明确。尽管存在多种模型解释方法，例如电路发现，但稀疏自编码器（SAEs）已被证明在将模型的激活空间分解为其特征基础方面特别有效。在这项工作中，我们探索了SAE在原始模型和压缩模型中的差异。我们发现，在原始模型上训练的SAE可以解释压缩模型，尽管与在压缩模型上训练的SAE相比性能略有下降。此外，简单地剪枝原始SAE本身就可以实现与在新剪枝模型上训练新SAE相当的性能。这一发现使我们能够减轻SAE高昂的训练成本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [190] [Towards a deeper GCN: Alleviate over-smoothing with iterative training and fine-tuning](https://arxiv.org/abs/2506.17576)
> *走向更深的GCN：通过迭代训练和微调减轻过平滑*

*Furong Peng, Jinzhen Gao, Xuan Lu, Kang Liu, Yifan Huo, Sheng Wang* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 图卷积网络, 过平滑, 深度学习, 迭代训练, 模型微调, 特征坍塌

**Comment:** 17 pages,18 figures

> **TL;DR:** 深度GCN因过平滑导致性能下降，本文发现可训练线性变换是关键因素。提出LGT训练策略，通过分层训练、低秩适应和恒等初始化，在保持表达能力的同时构建更深的GCN，显著提升性能并可与现有方法结合。

**AI_Comments:** 本文的创新点在于识别出GCN中可训练线性变换在过平滑中的关键作用，并提出了一种新颖且通用的训练策略LGT来解决深层GCN的训练稳定性与表达能力平衡问题。LGT通过模块化的设计（分层训练、低秩适应、恒等初始化）有效提升了GCN的深度潜力，并能与现有技术兼容，具有很高的实用价值和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 深度图卷积网络（GCNs）由于过平滑而遭受严重的性能下降。现有研究主要将过平滑归因于图拉普拉斯算子的重复应用，但本文经验分析揭示了一个关键但被忽视的因素：GCN中可训练的线性变换显著加剧了特征坍塌，即使在中等深度（例如8层）也会发生。

**Method:** 提出了一种名为“分层渐进训练”（Layer-wise Gradual Training, LGT）的新型训练策略。LGT包含三个互补组件：(1) 分层训练以稳定从浅层到深层的优化，(2) 低秩适应以微调浅层并加速训练，以及(3) 恒等初始化以确保新层的平滑集成并加速收敛。

**Result:** LGT在基准数据集上使香草GCN实现了最先进的性能，即使在32层设置下也显著提高了准确性。LGT作为一种训练方法，可以与PairNorm和ContraNorm等现有方法无缝结合，进一步增强它们在更深网络中的性能。

**Conclusion:** LGT提供了一个通用的、与架构无关的训练框架，用于可扩展的深度GCN。

> **ai_Abstract:** 本文探讨了深度图卷积网络（GCNs）中过平滑问题的一个被忽视的关键因素：可训练线性变换会导致特征坍塌。为了在保持模型表达能力的同时缓解这一问题，作者提出了一种新的训练策略——分层渐进训练（LGT）。LGT通过分层训练稳定优化、低秩适应加速训练和恒等初始化平滑集成新层，成功构建更深的GCN。实验证明，LGT在香草GCN上实现了最先进的性能，并可与现有方法结合进一步提升深度网络的表现，提供了一个通用的深度GCN训练框架。

> **摘要翻译:** 图卷积网络（GCNs）在深度架构中由于过平滑而遭受严重的性能下降。尽管现有研究主要将过平滑归因于图拉普拉斯算子的重复应用，但我们的经验分析揭示了一个关键但被忽视的因素：GCN中可训练的线性变换显著加剧了特征坍塌，即使在中等深度（例如8层）也会发生。相比之下，移除了这些变换的简化图卷积（SGC）在高达32层时仍能保持稳定的特征多样性，这突出了线性变换在促进表达能力和引发过平滑方面的双重作用。然而，完全移除线性变换会削弱模型的表达能力。为了解决这种权衡，我们提出了分层渐进训练（LGT），这是一种新颖的训练策略，它在保持表达能力的同时逐步构建深度GCN。LGT集成了三个互补的组件：(1) 分层训练以稳定从浅层到深层的优化，(2) 低秩适应以微调浅层并加速训练，以及(3) 恒等初始化以确保新层的平滑集成并加速收敛。在基准数据集上的大量实验表明，LGT在香草GCN上实现了最先进的性能，即使在32层设置中也显著提高了准确性。此外，作为一种训练方法，LGT可以与PairNorm和ContraNorm等现有方法无缝结合，进一步增强它们在更深网络中的性能。LGT为可扩展的深度GCN提供了一个通用的、与架构无关的训练框架。代码可在[https://github.com/jfklasdfj/LGT_GCN]获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [192] [Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks](https://arxiv.org/abs/2507.16347)
> *利用个性化PageRank和高阶拓扑结构缓解图神经网络中的异配性问题*

*Yumeng Wang, Zengyi Wo, Wenjun Wang, Xingcheng Fu, Minglai Shao* | **Category: cs.LG, cs.AI, I.2.6** | **Updated: 2025-07-22**

**Keywords:** 图神经网络, 异配性, 个性化PageRank, 高阶结构, 节点分类

**Comment:** 10 pages, 5 figures, accepted at IJCAI 2025

> **TL;DR:** HPGNN通过结合高阶个性化PageRank和图神经网络，有效解决了异配图上GNN的性能瓶颈，并在异配图上表现优异，同时在同配图上保持竞争力。

**AI_Comments:** HPGNN的创新之处在于其将高阶个性化PageRank（PPR）与GNN结合，以有效处理异配图。通过PPR捕获长距离和多尺度信息，并降低计算复杂度及噪声影响，是解决GNN在异配图上同配性假设限制的关键步骤。其在异配图上的显著性能提升以及在同配图上的竞争力，表明了该模型在实际应用中的广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在节点分类任务中表现出色，但通常假设同配性（即连接节点具有相似标签），这在许多现实世界的异配图中不成立。现有异配图模型主要依赖成对关系，忽略了高阶结构的多尺度信息，导致性能不佳，尤其是在节点间冲突类信息带来的噪声下。

**Method:** 本文提出了HPGNN，一个将高阶个性化PageRank（PPR）与图神经网络（GNNs）相结合的新模型。HPGNN引入了一种高效的高阶PPR近似方法，以捕获长距离和多尺度节点交互，从而降低计算复杂性并减轻周围信息的噪声。通过将高阶结构信息嵌入到卷积网络中，HPGNN有效地建模了跨不同图维度的关键交互。

**Result:** 在基准数据集上的大量实验表明HPGNN的有效性。该模型在异配图的下游任务中，性能优于七种最先进方法中的五种，同时在同配图上保持了竞争力。HPGNN平衡多尺度信息和对噪声的鲁棒性使其成为解决现实世界图学习挑战的多功能解决方案。

**Conclusion:** HPGNN通过有效利用高阶拓扑结构和个性化PageRank来缓解异配图上图神经网络的性能问题，并在异配和同配图上均表现出卓越或有竞争力的性能。

> **ai_Abstract:** 本文提出了HPGNN，一个旨在解决图神经网络在异配图上性能受限问题的新模型。HPGNN通过引入一种高效的高阶个性化PageRank近似方法，捕获长距离和多尺度节点交互，从而有效整合高阶拓扑结构信息，并减轻噪声影响。实验结果表明，HPGNN在异配图上优于多数现有先进方法，并在同配图上保持竞争力，证明其在现实世界图学习挑战中的多功能性和有效性。

> **摘要翻译:** 图神经网络（GNNs）在节点分类任务中表现出色，但通常假设同配性，即连接的节点共享相似的标签。这个假设在许多现实世界的异配图中不成立。现有针对异配图的模型主要依赖于成对关系，忽略了来自高阶结构的多尺度信息。这导致性能不佳，特别是在节点间冲突类信息带来的噪声下。为了解决这些挑战，我们提出了HPGNN，一个将高阶个性化PageRank与图神经网络相结合的新模型。HPGNN引入了一种高效的高阶个性化PageRank（PPR）近似方法，以捕获长距离和多尺度节点交互。这种方法降低了计算复杂性并减轻了周围信息的噪声。通过将高阶结构信息嵌入到卷积网络中，HPGNN有效地建模了跨不同图维度的关键交互。在基准数据集上的大量实验证明了HPGNN的有效性。该模型在异配图的下游任务中，性能优于七种最先进方法中的五种，同时在同配图上保持了竞争力。HPGNN平衡多尺度信息和对噪声的鲁棒性使其成为解决现实世界图学习挑战的多功能解决方案。代码可在https://github.com/streetcorner/HPGNN获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [215] [Neural Approaches for Multi-Objective Routing on Multigraphs](https://arxiv.org/abs/2506.22095)
> *神经网络方法用于多图上的多目标路由*

*Filip Rydin, Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 多目标路由, 多图, 图神经网络, 学习型方法, 路径规划

**Comment:** 23 pages, 5 Figures

> **TL;DR:** 提出了两种基于图神经网络的方法，用于解决多图上的多目标路由问题，并在实验中表现出色。

**AI_Comments:** 本文的创新点在于首次将图神经网络应用于多图上的多目标路由问题，并提出了两种不同的策略来处理多图的复杂性，为现实世界中多边连接的路由场景提供了有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型路由方法不适用于多图（节点对之间有多个具有不同属性的边），而多图在现实世界场景中非常重要。

**Method:** 提出了两种图神经网络（GNN）方法。第一种方法直接在多图上操作，通过自回归地选择边直到完成路径。第二种模型首先通过学习到的剪枝策略简化多图，然后在得到的简单图上执行路由。

**Result:** 经验性地评估了这两种模型，并在一系列问题和分布上展示了它们的强大性能。

**Conclusion:** 这两种基于GNN的方法能够有效地解决多图上的多目标路由问题。

> **ai_Abstract:** 本文针对现有学习型路由方法不适用于多图的局限性，提出了两种基于图神经网络的多目标路由方法。第一种方法直接在多图上自回归地选择边，而第二种方法则先通过学习剪枝简化多图再进行路由。实验结果表明，这两种方法在多种问题和分布上均表现出强大的性能。

> **摘要翻译:** 学习型路由方法近年来在单目标和多目标背景下都受到了广泛关注。然而，现有方法不适用于多图上的路由，尽管多图在现实世界场景中具有很强的相关性，它们在节点对之间具有多条属性不同的边。在本文中，我们提出了两种基于图神经网络的方法来解决多图上的多目标路由问题。我们的第一种方法直接在多图上操作，通过自回归地选择边直到完成一次遍历。第二种模型首先通过学习到的剪枝策略简化多图，然后在得到的简单图上执行路由。我们对这两种模型进行了经验评估，并证明了它们在一系列问题和分布上都表现出强大的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [DP-TLDM: Differentially Private Tabular Latent Diffusion Model](https://arxiv.org/abs/2403.07842)
> *DP-TLDM: 差分隐私表格潜在扩散模型*

*Chaoyi Zhu, Jiayi Tang, Juan F. Pérez, Marten van Dijk, Lydia Y. Chen* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-21**

**Keywords:** 差分隐私, 表格数据, 潜在扩散模型, 合成数据, 隐私保护

**Comment:** 

> **TL;DR:** DP-TLDM提出了一种差分隐私的表格潜在扩散模型，用于生成高质量且隐私保护的合成数据，解决了现有方法在数据质量和隐私风险之间的矛盾，并在多个指标上显著优于其他DP保护的表格生成模型。

**AI_Comments:** 本文的创新点在于将潜在扩散模型引入表格数据合成，并结合差分隐私（DP）技术，解决了现有方法在数据质量和隐私保护之间的权衡问题。通过使用自动编码器和潜在扩散模型，以及DP-SGD训练，DP-TLDM在保持隐私的同时显著提升了合成数据的各项性能指标，对于隐私保护数据共享领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成模型在隐私保护数据共享方面存在局限性，尤其是在表格合成器类型有限、关注的隐私攻击类型少（多集中于GANs），并且忽视了成员推断攻击和差分隐私防御策略。研究动机在于解决合成数据表格在保持高数据质量和低隐私风险之间的矛盾。

**Method:** 本文提出了DP-TLDM（差分隐私表格潜在扩散模型），该模型由一个自动编码器网络（用于编码表格数据）和一个潜在扩散模型（用于合成潜在表格）组成。为了实现差分隐私，模型遵循新兴的f-DP框架，并应用DP-SGD结合批次裁剪来训练自动编码器。同时，使用分离值作为隐私度量来更好地捕捉DP算法带来的隐私增益。

**Result:** DP-TLDM能够实现有意义的理论隐私保证，并显著提升合成数据的实用性。具体而言，与其它受DP保护的表格生成模型相比，DP-TLDM在数据相似度方面平均提高了35%，在下游任务实用性方面提高了15%，在数据可区分性方面提高了50%，同时保持了相当水平的隐私风险。

**Conclusion:** DP-TLDM在提供有意义的理论隐私保证的同时，显著提升了合成数据的效用，并在数据质量和隐私保护之间取得了更好的平衡，优于现有的差分隐私表格生成模型。

> **ai_Abstract:** 本文提出DP-TLDM，一种差分隐私表格潜在扩散模型，旨在解决现有合成数据在保持高数据质量和低隐私风险方面的挑战。该模型结合了自动编码器和潜在扩散模型，并采用DP-SGD训练以实现隐私保护。实验结果表明，DP-TLDM在提供理论隐私保证的同时，显著提升了合成数据的质量和实用性，在数据相似度、下游任务效用和数据可区分性方面均优于其他DP保护的表格生成模型。

> **摘要翻译:** 生成模型产生的合成数据正成为隐私保护数据共享的解决方案。这种合成数据集应在不泄露可识别私人信息的情况下，与原始数据相似。迄今为止，先前的研究主要集中在有限类型的表格合成器和少数隐私攻击上，特别是对生成对抗网络（GANs）的关注，却忽视了成员推断攻击和防御策略，即差分隐私。受限于保持合成数据表格高质量和低隐私风险的困境，我们提出了DP-TLDM，即差分隐私表格潜在扩散模型，它由一个自动编码器网络（用于编码表格数据）和一个潜在扩散模型（用于合成潜在表格）组成。遵循新兴的f-DP框架，我们应用DP-SGD结合批次裁剪来训练自动编码器，并使用分离值作为隐私度量，以更好地捕捉DP算法带来的隐私增益。我们的实证评估表明，DP-TLDM能够实现有意义的理论隐私保证，同时显著增强合成数据的实用性。具体而言，与其他受DP保护的表格生成模型相比，DP-TLDM在数据相似度方面平均提高了35%，在下游任务实用性方面提高了15%，在数据可区分性方面提高了50%，同时保持了相当水平的隐私风险。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [231] [Semantic-Aware Gaussian Process Calibration with Structured Layerwise Kernels for Deep Neural Networks](https://arxiv.org/abs/2507.15987)
> *深度神经网络中具有结构化分层核的语义感知高斯过程校准*

*Kyung-hwan Lee, Kyung-tae Kim* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 高斯过程校准, 深度神经网络, 语义感知, 分层核, 不确定性量化

**Comment:** 

> **TL;DR:** 提出SAL-GP框架，通过多层高斯过程和结构化分层核，解决传统GP校准无法捕捉深度神经网络内部层级结构的问题，从而提高预测可靠性的校准和可解释性。

**AI_Comments:** SAL-GP的创新点在于其分层的高斯过程建模和结构化多层核设计，这使其能够更好地与深度神经网络的内部机制对齐，从而在提高校准效果的同时增强了可解释性，克服了传统GP校准的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度神经网络高斯过程(GP)置信度校准方法未能捕捉到网络内部的层级结构，这限制了其可解释性和评估预测可靠性的有效性。

**Method:** 提出语义感知分层高斯过程(SAL-GP)框架。该框架模仿目标神经网络的分层架构，采用多层GP模型，将每层的特征表示映射到局部校准修正。这些分层GP通过结构化的多层核耦合，实现所有层之间的联合边缘化。

**Result:** SAL-GP能够捕捉局部语义依赖和全局校准一致性，同时持续传播预测不确定性。该框架增强了与网络架构对齐的可解释性，并能够对深度模型中的置信度一致性和不确定性量化进行原则性评估。

**Conclusion:** SAL-GP框架通过其分层设计和结构化核，显著提升了深度神经网络的置信度校准能力、可解释性以及不确定性量化。

> **ai_Abstract:** 本文提出语义感知分层高斯过程(SAL-GP)框架，旨在解决传统高斯过程校准方法未能有效捕捉深度神经网络内部层级结构的问题。SAL-GP通过采用与网络分层架构相对应的多层高斯过程模型，并利用结构化多层核将各层局部校准修正进行联合，从而实现对局部语义依赖和全局校准一致性的捕捉。该方法显著提升了深度模型预测置信度的可解释性和不确定性量化能力。

> **摘要翻译:** 校准神经网络分类器的置信度对于量化推理期间预测的可靠性至关重要。然而，传统的高斯过程(GP)校准方法往往未能捕捉深度神经网络的内部层级结构，这限制了评估预测可靠性的可解释性和有效性。我们提出了一种语义感知分层高斯过程(SAL-GP)框架，该框架反映了目标神经网络的分层架构。SAL-GP没有应用单一的全局GP修正，而是采用了多层GP模型，其中每一层的特征表示都被映射到局部校准修正。这些分层GP通过结构化的多层核耦合，从而能够实现所有层之间的联合边缘化。这种设计使得SAL-GP能够捕捉局部语义依赖和全局校准一致性，同时持续地通过网络传播预测不确定性。由此产生的框架增强了与网络架构对齐的可解释性，并能够对深度模型中的置信度一致性和不确定性量化进行原则性评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [237] [Bipartite Patient-Modality Graph Learning with Event-Conditional Modelling of Censoring for Cancer Survival Prediction](https://arxiv.org/abs/2507.16363)
> *癌症生存预测中的二分患者-模态图学习与事件条件审查建模*

*Hailin Yue, Hulin Kuang, Jin Liu, Junjian Li, Lanlan Wang, Mengshen He, Jianxin Wang* | **Category: cs.LG, cs.MM** | **Updated: 2025-07-22**

**Keywords:** 癌症生存预测, 图学习, 模态缺失, 审查数据, 多模态数据

**Comment:** 

> **TL;DR:** 提出 CenSurv，一种新的癌症生存预测模型，通过二分图处理模态缺失，并用事件条件建模有效利用审查数据，显著提升预测准确性和鲁棒性。

**AI_Comments:** 这篇论文的创新点在于其双重策略：一是通过二分图学习和对齐策略有效处理多模态数据中的模态缺失问题，增强了模型的鲁棒性；二是通过事件条件审查建模（ECMC）模块，创新性地将可靠的审查数据转化为可用的训练数据，显著提升了生存预测的准确性。这种对审查数据和模态缺失的综合处理方法，为癌症生存预测领域提供了重要的技术进步，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有癌症生存预测研究未能充分利用审查样本的价值，且在模态缺失场景下性能下降甚至推理困难。

**Method:** 提出 CenSurv 模型。首先，使用图结构对多模态数据建模以获取表示。其次，设计二分图模拟患者-模态关系，并利用完整-不完整对齐策略探索模态无关特征，以缓解模态缺失问题。最后，设计即插即用的事件条件审查建模（ECMC），通过动态动量累积置信度选择可靠的审查数据，赋予更准确的生存时间，并将其作为未审查数据纳入训练。

**Result:** 在5个公开癌症数据集上，CenSurv 在平均C-index方面比现有最佳方法高出3.1%。在各种模态缺失场景下表现出卓越的鲁棒性。即插即用的ECMC模块使8个基线模型在5个数据集上的平均C-index提高了1.3%。

**Conclusion:** CenSurv在癌症生存预测方面表现出优越性及鲁棒性，特别是其事件条件审查建模模块能有效利用审查数据提升预测性能。

> **ai_Abstract:** 本文提出 CenSurv，一种用于癌症生存预测的新模型，旨在解决现有方法在处理审查数据不足和模态缺失场景下的性能问题。CenSurv 利用图结构对多模态数据建模，并通过二分图和对齐策略处理模态缺失，同时引入即插即用的事件条件审查建模（ECMC）来有效利用可靠的审查数据。实验结果表明 CenSurv 在多个公开数据集上显著优于现有最佳方法，并在模态缺失情况下表现出强大的鲁棒性，ECMC模块也有效提升了基线模型的性能。

> **摘要翻译:** 准确预测癌症患者的生存对个性化治疗至关重要。然而，现有研究仅关注已知生存风险样本之间的关系，未能充分利用审查样本的价值。此外，这些研究在模态缺失场景下可能会遭受性能下降，甚至在推理过程中遇到困难。在本研究中，我们提出了一种用于癌症生存预测的二分患者-模态图学习与事件条件审查建模（CenSurv）。具体而言，我们首先使用图结构对多模态数据进行建模并获得表示。然后，为了缓解模态缺失场景下的性能下降，我们设计了一个二分图来模拟各种模态缺失场景中的患者-模态关系，并利用完整-不完整对齐策略来探索模态无关特征。最后，我们设计了一个即插即用的事件条件审查建模（ECMC），该模型通过动态动量累积置信度选择可靠的审查数据，为这些审查数据分配更准确的生存时间，并将其作为未审查数据纳入训练。在5个公开癌症数据集上的综合评估表明，CenSurv 在平均C-index方面比现有最佳方法高出3.1%，同时在各种模态缺失场景下也表现出卓越的鲁棒性。此外，使用即插即用的ECMC模块，8个基线模型在5个数据集上的平均C-index提高了1.3%。CenSurv 的代码可在 https://github.com/yuehailin/CenSurv 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [240] [FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization](https://arxiv.org/abs/2506.23516)
> *FedWSQ：通过权重标准化和分布感知非均匀量化实现高效联邦学习*

*Seung-Wook Kim, Seongyeol Kim, Jiah Kim, Seowon Ji, Se-Ho Lee* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 联邦学习, 权重标准化, 非均匀量化, 数据异质性, 通信效率

**Comment:** 

> **TL;DR:** FedWSQ是一种新的联邦学习框架，它结合了权重标准化和分布感知非均匀量化，以解决数据异质性和通信限制问题，显著降低通信开销并保持高模型精度。

**AI_Comments:** 该论文提出了一种创新的联邦学习框架FedWSQ，通过结合权重标准化和分布感知非均匀量化，有效地解决了联邦学习中的两大核心挑战：数据异质性和通信效率。其创新点在于同时优化了模型鲁棒性和通信效率，这在实际应用中具有重要意义。通过在多种严苛场景下的实验验证，表明了其方法的有效性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）由于数据异质性和通信限制等关键挑战，经常面临性能下降的问题。

**Method:** 本文提出了一种名为FedWSQ的新型联邦学习框架，该框架集成了权重标准化（WS）和所提出的分布感知非均匀量化（DANUQ）。WS通过在训练过程中过滤掉局部更新中的偏差分量来增强FL性能，从而提高模型对数据异质性和不稳定客户端参与的鲁棒性。DANUQ通过利用局部模型更新的统计特性来最小化量化误差。

**Result:** FedWSQ显著降低了通信开销，同时保持了卓越的模型精度。在FL基准数据集上的大量实验表明，FedWSQ在各种挑战性FL设置（包括极端数据异质性和超低位通信场景）中始终优于现有的FL方法。

**Conclusion:** FedWSQ通过结合权重标准化和分布感知非均匀量化，有效解决了联邦学习中的数据异质性和通信限制问题，实现了高效且高精度的联邦学习。

> **ai_Abstract:** FedWSQ是一个创新的联邦学习框架，旨在克服数据异质性和通信限制。它通过集成权重标准化（WS）来提高模型对异质数据的鲁棒性，并通过分布感知非均匀量化（DANUQ）来最小化通信误差。实验证明，FedWSQ在降低通信开销的同时保持了卓越的模型精度，并在各种挑战性联邦学习场景中表现优异。

> **摘要翻译:** 联邦学习（FL）经常因数据异质性和通信限制等关键挑战而导致性能下降。为了解决这些限制，我们提出了一种新颖的FL框架，名为FedWSQ，它集成了权重标准化（WS）和所提出的分布感知非均匀量化（DANUQ）。WS通过在训练期间过滤掉局部更新中的偏差分量来增强FL性能，从而提高了模型对数据异质性和不稳定客户端参与的鲁棒性。此外，DANUQ通过利用局部模型更新的统计特性来最小化量化误差。因此，FedWSQ显著降低了通信开销，同时保持了卓越的模型精度。在FL基准数据集上进行的广泛实验表明，FedWSQ在各种具有挑战性的FL设置中，包括极端数据异质性和超低位通信场景，始终优于现有的FL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [261] [Harnessing Near-Infrared Spectroscopy and Machine Learning for Traceable Classification of Hanwoo and Holstein Beef](https://arxiv.org/abs/2507.02903)
> *利用近红外光谱和机器学习实现韩牛与荷斯坦牛肉的可追溯分类*

*AMM Nurul Alam, Abdul Samad, AMM Shamsul Alam, Jahan Ara Monti, Ayesha Muazzam* | **Category: cs.LG** | **Updated: 2025-07-10**

**Keywords:** 近红外光谱, 机器学习, 肉类分类, 食品真实性, 韩牛, 荷斯坦牛肉

**Comment:** We need to withdraw the present manuscript to make some major
  revisions to avoid potential conflict with relevant paper from other research

> **TL;DR:** 本研究结合近红外光谱（NIRS）和机器学习（ML）技术，成功实现了韩牛和荷斯坦牛肉的溯源分类，以应对食品掺假和误标问题。

**AI_Comments:** 该研究创新性地结合了无损近红外光谱技术与多种机器学习算法，为肉类溯源和食品真实性检测提供了高效且可靠的解决方案。其方法论严谨，通过多种模型对比和交叉验证增强了结果的可靠性。这项工作对于打击食品欺诈、保障消费者权益具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决食品真实性、误标和掺假问题，本研究旨在评估利用近红外光谱（NIRS）结合先进机器学习（ML）技术来区分韩牛（HNB）和荷斯坦牛肉（HLB）的有效性。

**Method:** 研究使用便携式NIRS设备在700至1100 nm波长范围内采集快速、无创的光谱数据。从当地超市获取了40份牛腰大肌样本，韩牛和荷斯坦牛肉各20份。数据分析采用主成分分析（PCA）来识别光谱模式。机器学习模型包括线性判别分析（LDA）、支持向量机（SVM）、逻辑回归（LR）、随机森林（RF）、梯度提升（GB）、K-最近邻（KNN）、决策树（DT）、朴素贝叶斯（NB）和神经网络（NN），并通过超参数调优和5折交叉验证进行优化和验证。

**Result:** 主成分分析（PCA）显示了与化学变化相关的独特光谱模式，清晰地区分了两种牛肉，解释了93.72%的总方差。随机森林模型提供了最高的预测准确性，ROC曲线下面积（AUC）为0.8826，其次是SVM模型（0.8747）。GB和NN算法表现良好，交叉验证分数为0.752。NN模型达到了最高的召回率0.7804。LR和SVM模型在准确性、精确度和召回率之间取得了最佳平衡。

**Conclusion:** 本研究证实，将近红外光谱与机器学习技术相结合，为肉类真实性检测提供了一种强大且可靠的方法，对打击食品欺诈具有重要贡献。

> **ai_Abstract:** 本研究利用便携式近红外光谱（NIRS）和多种机器学习（ML）模型，成功实现了韩牛和荷斯坦牛肉的鉴别分类。通过对40份牛肉样本的光谱数据进行主成分分析（PCA），发现两种牛肉存在明显的光谱差异。随机森林模型表现出最高的分类准确性（AUC 0.8826），而逻辑回归和支持向量机在准确性、精确度和召回率之间取得了良好平衡。研究结果表明，NIRS结合ML技术为肉类真实性检测提供了一种强大且可靠的解决方案，有助于打击食品欺诈。

> **摘要翻译:** 本研究评估了利用近红外光谱（NIRS）结合先进机器学习（ML）技术来区分韩牛（HNB）和荷斯坦牛肉（HLB）的有效性，以解决食品真实性、误标和掺假问题。通过便携式NIRS设备获取了快速、无创的光谱数据，记录了700至1100 nm波长范围内的吸光度数据。共从当地一家大型超市获得了40份牛腰大肌样本，韩牛和荷斯坦牛肉各占一半。使用主成分分析（PCA）进行数据分析，结果显示与化学变化相关的独特光谱模式，清晰地分离了两种牛肉，解释了总方差的93.72%。实施了包括线性判别分析（LDA）、支持向量机（SVM）、逻辑回归（LR）、随机森林（Random Forest）、梯度提升（Gradient Boosting）、K-最近邻（K-Nearest Neighbors）、决策树（Decision Tree）、朴素贝叶斯（Naive Bayes）和神经网络（Neural Networks）在内的机器学习模型，并通过超参数调优进行优化，通过5折交叉验证技术进行验证，以增强模型鲁棒性并防止过拟合。随机森林提供了最高的预测准确性，其受试者工作特征（ROC）曲线下面积（AUC）为0.8826，紧随其后的是SVM模型，为0.8747。此外，GB和NN算法表现令人满意，交叉验证分数为0.752。值得注意的是，NN模型取得了0.7804的最高召回率，突出了其在需要更高敏感度的场景中的适用性。DT和NB表现出相对较低的预测性能。LR和SVM模型通过有效平衡高准确性、精确度和召回率，成为最佳选择。本研究证实，将NIRS与ML技术相结合，为肉类真实性提供了一种强大而可靠的方法，对检测食品欺诈做出了重大贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [276] [Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation](https://arxiv.org/abs/2507.16008)
> *通过鞍点重构增强物理信息神经网络训练的稳定性*

*Dmitry Bylinkin, Mikhail Aleksandrov, Savelii Chezhegov, Aleksandr Beznosikov* | **Category: cs.LG, math.OC** | **Updated: 2025-07-21**

**Keywords:** 物理信息神经网络, 鞍点问题, 训练稳定性, 非凸优化, 性能提升

**Comment:** 34 pages, 4 tables, 3 figures, 4 theorems; code available at
  https://anonymous.4open.science/r/pinns-bgda-00D6/README.md

> **TL;DR:** 本文通过将PINN训练重构为非凸强凹鞍点问题，显著提高了其训练稳定性，并超越了现有技术。

**AI_Comments:** 这项研究通过引入鞍点重构，为解决物理信息神经网络训练中的稳定性问题提供了一种新颖且有效的方法。其创新性在于将PINN的优化问题转化，从而克服了传统损失函数复杂性带来的挑战。实验结果表明其优于现有技术，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 物理信息神经网络（PINNs）的性能因损失函数的复杂性而表现不稳定。

**Method:** 将PINN训练重构为一个非凸强凹鞍点问题，并建立了理论基础，然后进行了广泛的实验研究。

**Result:** 所提出的方法在各种任务和架构上均优于当前的最新技术。

**Conclusion:** 通过将PINN训练重构为鞍点问题，可以有效提高其稳定性，并取得超越现有技术的性能。

> **ai_Abstract:** 本文针对物理信息神经网络（PINNs）训练不稳定的问题，提出将其训练过程重构为非凸强凹鞍点问题。在建立理论基础后，通过广泛的实验证明，该方法能有效提高PINN的训练稳定性，并在性能上超越了现有最先进的技术。

> **摘要翻译:** 物理信息神经网络（PINNs）近年来备受关注，并已在许多应用中得到有效使用。然而，由于损失函数的复杂性，它们的性能仍然不稳定。为了解决这个问题，我们将PINN训练重构为一个非凸强凹鞍点问题。在为这种方法建立理论基础之后，我们进行了广泛的实验研究，评估其在各种任务和架构中的有效性。我们的结果表明，所提出的方法优于当前的最新技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [287] [Optimization and generalization analysis for two-layer physics-informed neural networks without over-parametrization](https://arxiv.org/abs/2507.16380)
> *两层物理信息神经网络无过参数化优化与泛化分析*

*Zhihan Zeng, Yiqi Gu* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 物理信息神经网络, SGD, 泛化, 优化, 过参数化

**Comment:** 

> **TL;DR:** 本文对两层物理信息神经网络（PINN）中随机梯度下降（SGD）的行为进行了分析，旨在避免过参数化。研究表明，在网络宽度超过一个仅取决于问题和误差阈值$\\epsilon$的特定阈值时，训练损失和预期损失可降至$O(\\epsilon)$以下。

**AI_Comments:** 本文的创新点在于摆脱了物理信息神经网络（PINN）中普遍存在的过参数化依赖，为PINN的理论分析提供了更实用和计算效率更高的新视角。其重要性在于为PINN在更适度网络宽度下的性能提供了理论保证，有助于弥合理论与实际应用之间的差距，可能降低计算成本。然而，其局限性在于结果依赖于对目标函数的“某些假设”，这些假设的具体性质在摘要中未详细说明，可能影响其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 过去关于物理信息神经网络（PINN）的工作主要基于过参数化机制，但这可能导致计算成本过高且与实际实验不符。本文的动机是为SGD在两层PINN中的应用提供新的优化和泛化分析，以避免过参数化问题。

**Method:** 本文对训练两层物理信息神经网络（PINN）中的随机梯度下降（SGD）进行了新的优化和泛化分析。通过对目标函数做出某些假设，该研究旨在避免过参数化。

**Result:** 研究结果表明，给定一个$\\epsilon>0$，如果网络宽度超过一个仅取决于$\\epsilon$和问题的阈值，那么训练损失和预期损失都将降至$O(\\epsilon)$以下。

**Conclusion:** 本文得出结论，在对目标函数做出特定假设的前提下，即使不采用过参数化，两层物理信息神经网络（PINN）也能通过随机梯度下降（SGD）实现较低的训练损失和预期损失，前提是网络宽度达到某个特定阈值。

> **ai_Abstract:** 本文分析了两层物理信息神经网络（PINN）中随机梯度下降（SGD）在解决最小二乘回归问题时的行为，旨在突破传统过参数化机制带来的高计算成本和不实用性。通过对目标函数进行特定假设，研究表明，在无需过参数化的情况下，只要网络宽度超过一个仅依赖于问题和精度要求$\\epsilon$的阈值，训练损失和预期损失均可降低到$O(\\epsilon)$水平。

> **摘要翻译:** 这项工作专注于随机梯度下降（SGD）在解决物理信息神经网络（PINN）最小二乘回归中的行为。过去关于此主题的工作都基于过参数化机制，其收敛可能要求网络宽度随训练样本数量大幅增加。因此，从过参数化导出的理论可能会带来过高的计算成本，并且与实际实验相去甚远。我们对训练两层PINN中的SGD进行了新的优化和泛化分析，对目标函数做出某些假设以避免过参数化。给定$\\epsilon>0$，我们表明如果网络宽度超过一个仅取决于$\\epsilon$和问题的阈值，那么训练损失和预期损失将降至$O(\\epsilon)$以下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [295] [Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time](https://arxiv.org/abs/2507.07271)
> *超越ATE：剂量和时间上治疗效果的可解释建模*

*Julianna Piskorz, Krzysztof Kacprzyk, Harry Amad, Mihaela van der Schaar* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 治疗效果, 剂量-时间响应, 可解释建模, 因果推断, SemanticODE

**Comment:** Presented at the Actionable Interpretability Workshop at ICML 2025

> **TL;DR:** 本文提出了一种新的框架，用于建模治疗效果随剂量和时间变化的动态轨迹，以克服平均治疗效果（ATE）的局限性，并提供可解释的、临床可操作的见解。

**AI_Comments:** 本文的创新之处在于提出了一个超越传统ATE的框架，能够对治疗效果随剂量和时间变化的动态进行建模，这在医疗保健等高风险领域具有重要意义。通过引入SemanticODE并进行适应性改造，该方法在保证可解释性、鲁棒性和可验证性的同时，实现了对未直接观测到的治疗效果的有效分析。其解耦估计和规范的方法，以及支持领域先验和事后编辑的特性，极大地提升了模型的实用性和透明度。

<details>
  <summary>Details</summary>

**Motivation:** 平均治疗效果（ATE）作为因果推断的基础指标，在许多应用中，尤其是在医疗保健领域，无法捕捉到随剂量和时间变化的治疗效果的细微动态，这限制了其在实际决策中的应用。

**Method:** 本文提出了一种将治疗效果轨迹建模为剂量和时间上的平滑曲面的框架。该方法将最近的可解释轨迹建模框架SemanticODE应用于因果推断设置中，其中治疗效果从未被直接观测到。其方法将轨迹形状的估计与临床相关属性（例如最大值、拐点）的规范解耦，支持领域先验、事后编辑和透明分析。

**Result:** 该方法能够生成准确、可解释和可编辑的治疗动态模型，并能够提取临床可操作的见解，如起效时间、峰值效应和受益持续时间。

**Conclusion:** 该方法通过提供可解释且可编辑的治疗动态模型，促进了严谨的因果分析和实际决策制定，克服了传统ATE的局限性。

> **ai_Abstract:** 本文针对平均治疗效果（ATE）无法捕捉治疗效果随剂量和时间动态变化的局限性，提出了一种新的框架。该框架将治疗效果轨迹建模为剂量和时间上的平滑曲面，并基于SemanticODE进行适应性改造，使其适用于因果推断场景。该方法能够解耦轨迹形状估计与临床属性规范，从而提取起效时间、峰值效应和受益持续时间等临床可操作的见解。研究结果表明，该方法能够生成准确、可解释且可编辑的治疗动态模型，有助于更严谨的因果分析和实际决策制定。

> **摘要翻译:** 平均治疗效果（ATE）是因果推断中的一个基础指标，广泛用于评估随机对照试验（RCT）中的干预效果。然而，在许多应用中——特别是在医疗保健领域——这种静态的总结未能捕捉到治疗效果随剂量和时间变化的细微动态。我们提出一个框架，用于将治疗效果轨迹建模为剂量和时间上的平滑曲面，从而能够提取临床上可操作的见解，例如起效时间、峰值效应和受益持续时间。为了确保可解释性、鲁棒性和可验证性——在高风险领域中的关键要求——我们调整了SemanticODE，一个最近的可解释轨迹建模框架，以适应治疗效果从未被直接观测到的因果设置。我们的方法将轨迹形状的估计与临床相关属性（例如最大值、拐点）的规范解耦，支持领域先验、事后编辑和透明分析。我们展示了我们的方法能够产生准确、可解释和可编辑的治疗动态模型，从而促进了严谨的因果分析和实际决策制定。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [309] [Feature Selection and Junta Testing are Statistically Equivalent](https://arxiv.org/abs/2505.04604)
> *特征选择和Junta测试在统计上是等价的*

*Lorenzo Beretta, Nathaniel Harms, Caleb Koch* | **Category: cs.LG, cs.CC, cs.DS, stat.ML** | **Updated: 2025-07-21**

**Keywords:** 特征选择, Junta测试, 统计等价性, 样本最优性, 暴力算法

**Comment:** 32 pages

> **TL;DR:** 本文证明了特征选择和junta测试在统计上是等价的，并且提出了一种暴力算法，对这两个问题都是样本最优的。

**AI_Comments:** 本文的创新之处在于明确证明了特征选择和junta测试这两个看似不同的问题在统计上的等价性。此外，它还展示了一个简单的暴力算法能够在这两个问题上同时达到样本最优性，这为相关理论和实践提供了简洁而有效的指导。

<details>
  <summary>Details</summary>

**Motivation:** 理解特征选择问题和junta测试问题之间的关系，并为两者找到统计上最优的解决方案。

**Method:** 通过数学证明，论文显示了这两个任务在统计上的等价性，并分析了一种“暴力”算法的样本复杂性。

**Result:** “暴力”算法（检查与样本一致的任意 $k$ 个变量集）对特征选择和junta测试这两个问题同时是样本最优的。最优样本大小为 $\Theta\left(\frac 1 \varepsilon \left( \sqrt{2^k \log {n \choose k}} + \log {n \choose k}\right)\right)$。

**Conclusion:** 特征选择和junta测试在统计上是等价的，并且一个简单的暴力算法可以同时为这两个问题实现最优的样本效率。

> **ai_Abstract:** 本文证明了函数特征选择问题和junta测试问题在统计上是等价的。作者指出，一种“暴力”算法（通过检查与样本一致的任意 $k$ 个变量集）对这两个任务都是样本最优的，并给出了其最优样本大小的精确界限。

> **摘要翻译:** 对于一个函数 $f \colon \{0,1\}^n \to \{0,1\}$，junta测试问题询问 $f$ 是否仅依赖于 $k$ 个变量。如果 $f$ 仅依赖于 $k$ 个变量，特征选择问题则要求找到这些变量。我们证明了这两个任务在统计上是等价的。具体来说，我们证明了“暴力”算法（该算法检查与样本一致的任意 $k$ 个变量集）同时对这两个问题都是样本最优的，并且最优样本大小为 $\Theta\left(\frac 1 \varepsilon \left( \sqrt{2^k \log {n \choose k}} + \log {n \choose k}\right)\right)$。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [316] [Neural Probabilistic Shaping: Joint Distribution Learning for Optical Fiber Communications](https://arxiv.org/abs/2507.16012)
> *神经概率整形：光纤通信中的联合分布学习*

*Mohammad Taha Askari, Lutz Lampe, Amirhossein Ghazisaeidi* | **Category: cs.LG, cs.IT, eess.SP, math.IT** | **Updated: 2025-07-21**

**Keywords:** 概率整形, 联合分布学习, 光纤通信, 自回归学习, 非线性信道

**Comment:** 4 pages, 3 figures, Submitted to the 51st European Conference on
  Optical Communications

> **TL;DR:** 本文提出了一种用于非线性光纤信道概率整形的自回归端到端学习方法，通过学习联合符号分布，在特定传输条件下实现了0.3比特/2D的可实现信息率增益。

**AI_Comments:** 该论文的创新点在于将自回归端到端学习应用于光纤通信中的概率整形，并通过学习联合符号分布而非传统边际分布来提升性能。这种方法在非线性信道中显示出显著的增益，对未来光纤通信系统的设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非线性光纤信道中，为概率整形寻找更优的方法以提高信息传输效率。

**Method:** 提出了一种自回归端到端学习方法，用于在非线性光纤信道上进行概率整形。该方案学习联合符号分布。

**Result:** 与优化的边际分布相比，在单跨度205公里链路上的双极化64-QAM传输中，实现了0.3比特/2D的可实现信息率增益。

**Conclusion:** 通过学习联合符号分布的自回归端到端学习方法，可以有效提高非线性光纤信道中的概率整形性能，从而获得显著的信息率增益。

> **ai_Abstract:** 本文提出了一种新颖的自回归端到端学习方法，用于非线性光纤信道中的概率整形。该方法通过学习联合符号分布，在双极化64-QAM传输的205公里链路上，相较于传统的边际分布方法，实现了0.3比特/2D的可实现信息率增益，显示出其在提升光纤通信性能方面的潜力。

> **摘要翻译:** 我们提出了一种用于非线性光纤信道概率整形的自回归端到端学习方法。我们提出的方案学习联合符号分布，并在单跨度205公里链路上的双极化64-QAM传输中，比优化的边际分布提供了0.3比特/2D的可实现信息率增益。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [320] [OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting](https://arxiv.org/abs/2507.07754)
> *OPC：一种面向深度特征遗忘的单点收缩式机器学习遗忘算法*

*Jaeheun Jung, Bosung Jung, Suhyun Bae, Donghun Lee* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 机器学习遗忘, 深度遗忘, 单点收缩, 特征遗忘, 隐私保护

**Comment:** ICCV 2025 workshop U&ME 2025 (2nd Workshop and Challenge on
  Unlearning and Model Editing)

> **TL;DR:** 现有的机器学习遗忘方法存在“浅层遗忘”问题，即模型内部表示仍保留被遗忘数据信息，易受攻击。本文定义了基于特征表示单点收缩的“深度遗忘”理论准则，并提出了一种新的通用遗忘算法OPC。实验证明OPC能有效遗忘并抵抗多种攻击。

**AI_Comments:** 该论文创新性地提出了“深度遗忘”的概念，并基于特征表示的“单点收缩”给出了明确的理论准则，这为机器学习遗忘领域提供了一个新的视角和更严格的评估标准。OPC算法的提出及其在抵抗攻击方面的优越表现，有望显著提升机器学习模型在隐私保护和数据合规性方面的实际应用安全性。其强调的内部特征表示遗忘而非仅仅模型输出遗忘，是该研究的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习遗忘旨在从训练模型中移除特定数据或类别的影响，以满足隐私、法律或伦理要求。然而，现有遗忘方法存在“浅层遗忘”问题，即模型仅调整响应，而内部表示仍保留足够信息以恢复被遗忘数据或行为。本文通过性能恢复攻击和梯度反演数据重建攻击，经验性地证实了这种普遍存在的浅层遗忘现象。

**Method:** 为从根本上解决浅层遗忘的脆弱性，本文定义了一个基于待遗忘数据特征表示“单点收缩”的“深度遗忘”理论准则。在此基础上，提出了一种高效的近似算法，并用它构建了一种新颖的通用遗忘算法：单点收缩（OPC）。

**Result:** 在图像分类遗忘基准上的实证评估表明，OPC不仅实现了有效的遗忘性能，而且对性能恢复攻击和梯度反演攻击都表现出卓越的抵抗力。

**Conclusion:** OPC独特的遗忘性能源于其理论基础所强制实现的深度特征遗忘，这再次强调了提高机器学习遗忘方法鲁棒性的必要性。

> **ai_Abstract:** 本文针对现有机器学习遗忘方法存在的“浅层遗忘”问题，即模型内部表示仍保留被遗忘信息，容易受到攻击的漏洞，提出了一种名为OPC（One-Point-Contraction）的新型通用遗忘算法。该算法基于特征表示的“单点收缩”定义了“深度遗忘”的理论准则，并设计了高效的近似算法。实验结果表明，OPC不仅能有效实现模型遗忘，而且对性能恢复攻击和梯度反演攻击具有优越的抵抗力，证实了其强制实现的深度特征遗忘能力。

> **摘要翻译:** 机器学习遗忘旨在从训练模型中移除特定数据或类别的影响，以满足隐私、法律或伦理要求。现有遗忘方法往往是浅层遗忘：即被遗忘模型通过仅调整模型响应来假装遗忘，而其内部表示仍保留足够信息以恢复被遗忘数据或行为。我们通过无训练的性能恢复攻击和基于梯度反演的数据重建攻击，经验性地证实了这种普遍存在的浅层遗忘现象，能够逆转各种遗忘效果。为了从根本上解决这种脆弱性，我们定义了一个基于待遗忘数据特征表示“单点收缩”的“深度遗忘”理论准则。我们还提出了一种高效的近似算法，并用它构建了一种新颖的通用遗忘算法：单点收缩（OPC）。在图像分类遗忘基准上的实证评估表明，OPC不仅实现了有效的遗忘性能，而且对性能恢复攻击和梯度反演攻击都表现出卓越的抵抗力。OPC独特的遗忘性能源于其理论基础所强制实现的深度特征遗忘，这再次强调了提高机器学习遗忘方法鲁棒性的必要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [336] [A Comprehensive Data-centric Overview of Federated Graph Learning](https://arxiv.org/abs/2507.16541)
> *联邦图学习的综合数据中心视角概述*

*Zhengyu Wu, Xunkai Li, Yinlin Zhu, Zekai Chen, Guochen Yan, Yanyu Yan, Hao Zhang, Yuming Ai, Xinmo Jin, Rong-Hua Li, Guoren Wang* | **Category: cs.LG, cs.AI, cs.SI** | **Updated: 2025-07-22**

**Keywords:** 联邦图学习, 数据中心, 分类法, 数据特性, 数据利用

**Comment:** 

> **TL;DR:** 本综述提出了一个以数据为中心的联邦图学习（FGL）分类法，填补了现有FGL综述主要关注方法论的空白，并探讨了数据特性、数据利用、与预训练大模型的集成、实际应用和未来方向。

**AI_Comments:** 这篇综述的创新之处在于其独特的数据中心视角，填补了现有FGL综述的空白，提供了一个更系统和细致的框架来理解和评估FGL研究。它不仅提出了新的分类法，还关注了与前沿技术（如预训练大模型）的结合，并指明了实际应用和未来趋势，对于推动FGL领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大数据应用时代，联邦图学习（FGL）已成为平衡去中心化数据集集体智能优化与敏感信息保护的突出解决方案。然而，现有FGL综述主要侧重于整合联邦学习和图机器学习，强调方法论和模拟场景，缺乏系统地从数据属性和使用角度审视FGL方法。本综述旨在填补这一空白，评估FGL研究如何解决数据中心约束以提高模型性能。

**Method:** 本综述提出了一个两级的数据中心分类法：数据特性（根据FGL中使用的数据集的结构和分布特性对研究进行分类）和数据利用（分析为克服关键数据中心挑战所采用的训练过程和技术）。每个分类级别由三个正交标准定义。此外，综述还探讨了FGL与预训练大模型的集成，展示了实际应用，并强调了与图机器学习新兴趋势一致的未来方向。

**Result:** 本综述通过引入以数据为中心的视角和分类法，为联邦图学习领域提供了一个新的组织框架。它提出了一个两级数据中心分类法，并探讨了FGL与预训练大模型的集成、实际应用和未来研究方向。

**Conclusion:** 本综述通过引入以数据为中心的视角和分类法，为联邦图学习领域提供了一个新的组织框架，填补了现有研究的空白，并为未来的研究方向提供了指导，特别是在数据管理和利用方面。

> **ai_Abstract:** 本综述提出了一个全面的以数据为中心的联邦图学习（FGL）视角，旨在弥补现有FGL综述主要侧重于方法论和模拟场景的不足。文章引入了一个两级数据中心分类法，包括“数据特性”和“数据利用”，系统地分析了FGL方法在数据属性和使用方面的表现。此外，本综述还探讨了FGL与预训练大模型的集成、实际应用案例，并指出了未来研究方向，为FGL领域提供了一个新的组织和评估框架。

> **摘要翻译:** 在大数据应用时代，联邦图学习（FGL）已成为一种重要的解决方案，它能够在优化去中心化数据集持有者之间的集体智能与最大限度地保护敏感信息之间取得平衡。现有的FGL综述做出了有意义的贡献，但主要侧重于整合联邦学习（FL）和图机器学习（GML），导致早期的分类法强调方法论和模拟场景。值得注意的是，一个以数据为中心的视角，即系统地通过数据属性和使用来审视FGL方法，尚未被采纳来重组FGL研究，然而，评估FGL研究如何设法解决以数据为中心的约束以提高模型性能至关重要。本综述提出了一个两级的数据中心分类法：数据特性，它根据FGL中使用的数据集的结构和分布特性对研究进行分类；以及数据利用，它分析了为克服关键数据中心挑战所采用的训练过程和技术。每个分类级别由三个正交标准定义，每个标准代表一个独特的数据中心配置。除了分类法之外，本综述还探讨了FGL与预训练大模型的集成，展示了实际应用，并强调了与GML新兴趋势一致的未来方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [337] [Improving Predictions on Highly Unbalanced Data Using Open Source Synthetic Data Upsampling](https://arxiv.org/abs/2507.16419)
> *使用开源合成数据上采样改进高度不平衡数据的预测*

*Ivona Krchova, Michael Platzer, Paul Tiwald* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 不平衡数据, 合成数据, 上采样, 预测建模, 机器学习

**Comment:** 

> **TL;DR:** 本研究评估了使用开源AI生成合成数据进行上采样，以提高高度不平衡表格数据集中少数类预测模型的准确性。

**AI_Comments:** 该论文的创新点在于利用AI生成合成数据进行上采样，以解决高度不平衡数据集中少数类预测难题。其重要性体现在为处理现实世界中如欺诈检测、医学诊断等场景下的稀有事件预测提供了有效工具，并展示了开源解决方案的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 不平衡的表格数据集对预测建模和数据分析提出了重大挑战，传统机器学习算法难以在少数类上实现高精度，因为它们倾向于多数类，导致模型有偏。

**Method:** 本研究对使用AI生成合成数据进行高度不平衡表格数据集上采样进行了基准研究。评估了一个开源解决方案，即MOSTLY AI的Synthetic Data SDK，并将其与朴素过采样和SMOTE-NC等标准方法进行比较。

**Result:** 结果表明，合成数据可以通过生成多样化的数据点来填补特征空间稀疏区域的空白，从而提高少数群体的预测准确性。上采样的合成训练数据始终能产生性能最佳的预测模型，特别是对于包含极少数少数样本的混合类型数据集。

**Conclusion:** 使用开源AI生成合成数据进行上采样可以显著提高高度不平衡数据集中少数类的预测准确性，尤其适用于混合类型数据。

> **ai_Abstract:** 本研究旨在解决高度不平衡表格数据集中少数类预测精度低的挑战。通过对MOSTLY AI的开源Synthetic Data SDK进行基准测试，并将其与传统过采样方法进行比较，研究发现AI生成的合成数据能够有效提高少数类的预测准确性，尤其是在混合类型数据集中，通过生成多样化样本来填补特征空间中的空白，从而持续产生高性能的预测模型。

> **摘要翻译:** 不平衡的表格数据集对广泛应用中的预测建模和数据分析提出了重大挑战。在许多现实场景中，例如欺诈检测、医疗诊断和稀有事件预测，少数类被严重低估，这使得传统机器学习算法难以实现高精度。这些算法倾向于多数类，导致模型有偏，难以准确表示少数类。合成数据有望通过提供新的、多样化且高度逼真的样本来解决少数类代表性不足的问题。本文提出了一项关于使用AI生成合成数据对高度不平衡表格数据集进行上采样的基准研究。我们评估了开源解决方案MOSTLY AI的Synthetic Data SDK的有效性，该SDK为混合类型数据提供了灵活且用户友好的合成上采样方法。我们将使用合成记录进行上采样的数据集训练的预测模型与使用朴素过采样和SMOTE-NC等标准方法训练的模型进行了比较。我们的结果表明，合成数据可以通过生成多样化的数据点来填补特征空间稀疏区域的空白，从而提高少数群体的预测准确性。我们表明，上采样的合成训练数据始终能产生性能最佳的预测模型，特别是对于包含极少数少数样本的混合类型数据集。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [346] [Pre-Training LLMs on a budget: A comparison of three optimizers](https://arxiv.org/abs/2507.08472)
> *预算内预训练LLM：三种优化器的比较*

*Joel Schlotthauer, Christian Kroos, Chris Hinze, Viktor Hangya, Luzian Hahn, Fabian Küch* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** LLM预训练, 优化器, AdamW, Lion, Sophia

**Comment:** 

> **TL;DR:** 本研究比较了AdamW、Lion和Sophia三种优化器在LLM预训练中的表现，发现Sophia损失最低，Lion训练最快，但AdamW下游效果最好。

**AI_Comments:** 这项研究为LLM预训练中的优化器选择提供了实用的见解，特别是在预算有限的情况下。它强调了不同优化器在训练效率和最终模型性能之间存在的权衡，为研究人员和实践者提供了决策依据。其创新之处在于对比了新兴优化器（Lion, Sophia）与经典AdamW在LLM预训练中的实际效果，并考虑了“预算”限制。

<details>
  <summary>Details</summary>

**Motivation:** 优化器在缩短LLM预训练时间并实现性能更优的模型方面起着决定性作用。本研究旨在比较不同优化器在LLM预训练中的表现。

**Method:** 研究比较了AdamW、Lion和Sophia三种优化器。为提高泛化性，使用了两种不同的基础架构，并采用单周期和多周期方法，同时保持token数量不变。通过最大更新参数化（Maximal Update Parametrization）和较小的代理模型，为每种基础架构和优化器的组合单独调整了相关超参数。

**Result:** 所有三种优化器的结果大致在相同范围内。Sophia表现出最低的训练和验证损失。Lion在训练GPU小时方面最快。AdamW在下游评估结果中表现最好。

**Conclusion:** 尽管AdamW在下游任务中表现最佳，但Sophia在损失方面有优势，Lion在训练速度方面有优势，表明在LLM预训练中选择优化器需权衡不同目标。

> **ai_Abstract:** 本研究比较了AdamW、Lion和Sophia这三种优化器在大型语言模型（LLM）预训练中的性能。研究通过在不同架构和训练策略下进行超参数调优，发现虽然三者整体表现相似，但Sophia在训练损失上最低，Lion在训练速度上最快，而AdamW在下游任务的评估结果中表现最优。

> **摘要翻译:** 优化器在缩短LLM预训练时间并实现性能更优的模型方面起着决定性作用。在本研究中，我们比较了三种主要的变体：事实标准AdamW、通过进化搜索开发的更简单的Lion，以及二阶优化器Sophia。为了更好的泛化性，我们使用两种不同的基础架构进行训练，并采用单周期和多周期方法，同时保持token数量不变。我们利用最大更新参数化（Maximal Update Parametrization）和较小的代理模型，为每种基础架构和优化器的组合单独调整了相关超参数。我们发现，尽管所有三种优化器的结果大致在相同范围内，但Sophia表现出最低的训练和验证损失，Lion在训练GPU小时方面最快，而AdamW则带来了最佳的下游评估结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [366] [Reactivation: Empirical NTK Dynamics Under Task Shifts](https://arxiv.org/abs/2507.16039)
> *再激活：任务转移下的经验性神经正切核动力学*

*Yuzhi Liu, Zixuan Chen, Zirui Zhang, Yufei Liu, Giulia Lanzillotta* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 神经正切核, 持续学习, 动力学, 任务转移, 静态核近似

**Comment:** 

> **TL;DR:** 本文对持续学习中的神经正切核（NTK）动力学进行了实证分析，发现持续学习是探测神经网络训练动力学的一个良好平台，并挑战了静态核近似在持续学习理论中的有效性。

**AI_Comments:** 本文创新性地将神经正切核（NTK）动力学研究扩展到持续学习领域，突破了以往单任务设置的局限性。其重要性在于揭示了持续学习作为探测神经网络训练动力学潜力的同时，对现有理论中广泛使用的静态核近似提出了挑战，为深度学习理论研究提供了新的视角和方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经正切核（NTK）动力学研究仅限于单任务设置，即数据分布假定随时间保持不变。为了弥补这一研究空白，本文旨在探讨数据分布随时间变化的持续学习情境下的NTK动力学。

**Method:** 本文对持续学习中的神经正切核（NTK）动力学进行了全面的实证分析。

**Result:** 研究结果表明，持续学习是探测神经网络训练动力学的一个丰富且未充分利用的试验平台。同时，这些发现挑战了即使在大规模情况下，静态核近似在持续学习理论处理中的有效性。

**Conclusion:** 持续学习为研究神经网络训练动力学提供了重要的试验平台，并且静态核近似在持续学习的理论分析中可能不再适用。

> **ai_Abstract:** 本文针对神经正切核（NTK）动力学研究中仅限于单任务设置的局限性，首次在持续学习情境下进行了全面的实证分析。研究发现，持续学习是探索神经网络训练动力学的重要试验平台，并且静态核近似在持续学习的理论分析中可能不再有效，即使在大型模型中也是如此。

> **摘要翻译:** 神经正切核（NTK）提供了一个强大的工具来研究神经网络的功能动力学。在所谓的惰性或核机制中，NTK在训练期间保持静态，并且网络功能在静态神经正切特征空间中是线性的。训练期间NTK的演变对于特征学习是必要的，这是深度学习成功的关键驱动因素。近年来，NTK动力学的研究在泛化和缩放行为方面取得了多项重要发现。然而，这项工作一直局限于单任务设置，其中数据分布被假定为随时间保持不变。在这项工作中，我们对持续学习中的NTK动力学进行了全面的实证分析，其中数据分布随时间变化。我们的发现强调持续学习是探测神经网络训练动力学的一个丰富且未充分利用的试验平台。同时，它们挑战了静态核近似在持续学习理论处理中的有效性，即使在大规模情况下也是如此。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [376] [Leveraging Distribution Matching to Make Approximate Machine Unlearning Faster](https://arxiv.org/abs/2507.09786)
> *利用分布匹配加速近似机器遗忘*

*Junaid Iqbal Khan* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 机器遗忘, 数据集压缩, 分布匹配, 加速遗忘, 隐私

**Comment:** 10 pages, 4 figures, 4 tables

> **TL;DR:** 该论文提出Blend（数据集压缩）和Accelerated-AMU（以损失为中心的方法）两种互补技术，以显著加速近似机器遗忘过程，同时保持模型效用和隐私。

**AI_Comments:** 该论文的创新之处在于首次将数据集压缩技术（Blend）与加速损失函数（A-AMU）相结合，系统地解决了近似机器遗忘的效率问题。这种双重优化方法在显著降低计算时间的同时，有效保持了模型性能和隐私保护，为机器遗忘领域带来了重要的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 近似机器遗忘 (AMU) 在计算运行时仍受限于处理保留数据集子集，且减少训练周期仍具挑战性，这导致了高昂的计算成本和效率低下。

**Method:** 论文提出了两种互补方法：1. Blend，一种新颖的分布匹配数据集压缩 (DC) 方法，通过合并视觉相似图像和共享混合权重来显著减小保留集大小，并比现有DC方法快数个数量级。2. Accelerated-AMU (A-AMU)，一种以损失为中心的方法，通过结合加速遗忘的陡峭主损失和匹配遗忘数据与分布内未见数据损失分布的新型可微分正则化器来加速收敛。

**Result:** 实验表明，这种数据和损失为中心的双重优化方法显著降低了单轮和多轮场景下的端到端遗忘延迟，同时保持了模型效用和隐私。

**Conclusion:** 据作者所知，这是首次通过联合设计专用数据集压缩技术和专用加速损失函数来系统地解决遗忘效率问题的研究。

> **ai_Abstract:** 该论文提出两种互补方法以加速近似机器遗忘（AMU）。首先是Blend，一种创新的分布匹配数据集压缩方法，通过合并视觉相似图像显著减小保留数据集大小，且比现有方法快数个数量级。其次是Accelerated-AMU (A-AMU)，一种损失为中心的方法，通过结合陡峭化主损失和新型可微分正则化器来加速收敛。实验证明，这种数据与损失结合的优化方法显著降低了遗忘延迟，同时保持了模型效用和隐私。

> **摘要翻译:** 近似机器遗忘 (AMU) 允许模型通过在保留数据集子集上进行专门的微调来“遗忘”特定的训练数据。然而，处理这个保留子集仍然是计算运行时的主要瓶颈，同时减少训练周期也仍然是一个挑战。我们提出了两种互补的方法来加速面向分类的AMU。首先，\textbf{Blend}，一种新颖的分布匹配数据集压缩 (DC) 方法，通过合并视觉相似图像和共享混合权重来显著减小保留集大小。它以最小的预处理开销运行，并且比最先进的DC方法快数个数量级。其次，我们的以损失为中心的方法，\textbf{Accelerated-AMU (A-AMU)}，增强了遗忘目标以加速收敛。A-AMU通过结合加速遗忘的陡峭主损失和匹配遗忘数据与分布内未见数据损失分布的新型可微分正则化器来实现这一点。我们的大量实验表明，这种数据和损失为中心的双重优化方法显著降低了单轮和多轮场景下的端到端遗忘延迟，同时保持了模型效用和隐私。据我们所知，这是首次通过联合设计专用数据集压缩技术和专用加速损失函数来系统地解决遗忘效率问题的研究。代码可在 https://github.com/algebraicdianuj/DC_Unlearning 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [397] [RIS-aided Latent Space Alignment for Semantic Channel Equalization](https://arxiv.org/abs/2507.16450)
> *RIS辅助的语义信道均衡潜在空间对齐*

*Tomás Hüttebräucker, Mario Edoardo Pandolfo, Simone Fiorellino, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.LG, eess.SP** | **Updated: 2025-07-22**

**Keywords:** 语义通信, RIS, 信道均衡, 潜在空间对齐, MIMO

**Comment:** 

> **TL;DR:** 本文提出一种RIS辅助的联合物理和语义信道均衡框架，以解决多用户语义通信系统中的语义不匹配问题，并证明其优于传统方法。

**AI_Comments:** 本文的创新点在于首次将RIS引入到语义通信的信道均衡中，并提出了物理层与语义层联合均衡的框架，有效解决了多用户独立训练下潜在空间不一致导致的语义鸿沟问题。这对于提升语义通信在复杂多用户环境下的鲁棒性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多用户语义通信系统中，独立训练的AI原生设备可能产生不同的潜在表示，导致语义不匹配，即使没有传统传输错误也会阻碍相互理解。

**Method:** 提出一个利用可重构智能表面（RIS）的联合物理和语义信道均衡框架。语义均衡包括发射器预均衡、RIS辅助信道传播和接收器后均衡三个阶段。问题被公式化为受限最小均方误差（MMSE）优化，并提出了两种解决方案：线性语义均衡链和基于DNN的非线性语义均衡器，两者均在潜在空间中进行语义压缩并遵守发射功率约束。

**Result:** 提出的联合均衡策略在广泛的场景和无线信道条件下，始终优于传统的、分离的物理和语义信道均衡方法。

**Conclusion:** 提出的RIS辅助的联合物理和语义信道均衡框架能够有效解决多用户语义通信中的语义不匹配问题，并显著提升系统性能。

> **ai_Abstract:** 本文提出一种RIS辅助的联合物理和语义信道均衡框架，旨在解决多用户语义通信系统中由于潜在表示差异导致的语义不匹配问题。该框架通过发射器预均衡、RIS辅助传播和接收器后均衡实现语义均衡，并将其公式化为受限MMSE优化问题，提出了线性与非线性（DNN-based）两种解决方案。实验结果表明，该联合均衡策略在多种无线环境下均显著优于传统的分离方法。

> **摘要翻译:** 语义通信系统在无线通信中引入了一种新范式，其重点是传输预期含义而非确保严格的比特级精度。这些系统通常依赖深度神经网络（DNN）直接从数据中学习和编码含义，从而实现更高效的通信。然而，在多用户环境中，当交互代理独立训练——没有共享上下文或联合优化——AI原生设备之间发散的潜在表示可能导致语义不匹配，即使没有传统传输错误也会阻碍相互理解。在这项工作中，我们通过提出一种利用可重构智能表面（RIS）的联合物理和语义信道均衡框架，解决了多输入多输出（MIMO）信道中的语义不匹配问题。语义均衡被实现为一系列变换：（i）发射器端的预均衡阶段；（ii）通过RIS辅助信道的传播；以及（iii）接收器端的后均衡阶段。我们将问题公式化为受限最小均方误差（MMSE）优化，并提出了两种解决方案：（i）线性语义均衡链；以及（ii）基于DNN的非线性语义均衡器。这两种方法都设计用于在潜在空间中进行语义压缩并遵守发射功率约束。通过广泛的评估，我们表明所提出的联合均衡策略在广泛的场景和无线信道条件下，始终优于传统的、分离的物理和语义信道均衡方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding](https://arxiv.org/abs/2507.15846)
> *GUI-G$^2$: 用于GUI定位的高斯奖励建模*

*Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang* | **Category: cs.LG, cs.AI, cs.CL, cs.CV, cs.HC** | **Updated: 2025-07-22**

**Keywords:** GUI定位, 高斯奖励, 强化学习, 空间推理, 连续优化

**Comment:** 

> **TL;DR:** GUI-G$^2$引入了一种高斯奖励建模框架，将GUI定位从稀疏二元奖励转换为密集连续优化，显著超越了现有最先进方法。

**AI_Comments:** 该论文的创新之处在于将GUI定位问题从传统的稀疏二元分类转化为密集连续优化，通过引入高斯奖励建模，模拟了人类点击行为的连续性，并提供了更丰富的梯度信号。这显著提升了模型对界面变化的鲁棒性和对未知布局的泛化能力，为GUI交互任务的空间推理树立了新的里程碑。

<details>
  <summary>Details</summary>

**Motivation:** 当前的强化学习方法在GUI定位中使用二元奖励，将元素视为命中或未命中目标，这产生了稀疏信号，忽略了空间交互的连续性，也未模拟人类点击行为中自然形成高斯分布的特点。

**Method:** GUI-G$^2$将GUI元素建模为界面平面上的连续高斯分布。它包含两种协同机制：高斯点奖励通过以元素质心为中心呈指数衰减的分布来建模精确的定位；覆盖奖励通过测量预测高斯分布与目标区域之间的重叠来评估空间对齐。为处理不同元素尺度，该框架开发了一种自适应方差机制，根据元素尺寸校准奖励分布。

**Result:** GUI-G$^2$在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中，显著优于最先进方法UI-TARS-72B，其中在ScreenSpot-Pro上取得了24.7%的最显著提升。

**Conclusion:** 连续建模为GUI交互任务中的空间推理提供卓越的鲁棒性和对未见布局的增强泛化能力，为该领域建立了新的范式。

> **ai_Abstract:** GUI-G$^2$提出了一种新颖的高斯奖励建模框架，用于将自然语言指令映射到精确的GUI位置。该框架通过将GUI元素建模为连续高斯分布，并引入高斯点奖励和覆盖奖励，将稀疏的二元奖励信号转换为密集的连续优化，从而产生丰富的梯度信号。实验证明，GUI-G$^2$在多个基准测试中显著优于现有最先进方法，尤其在泛化能力和对界面变化的鲁棒性方面表现出色，为GUI交互任务中的空间推理开辟了新范式。

> **摘要翻译:** 图形用户界面（GUI）定位将自然语言指令映射到精确的界面位置，以实现自主交互。当前的强化学习方法使用二元奖励，将元素视为命中或未命中目标，这产生了稀疏信号，忽略了空间交互的连续性。受人类点击行为自然形成以目标元素为中心的高斯分布的启发，我们引入了GUI高斯定位奖励（GUI-G$^2$），这是一个原则性的奖励框架，将GUI元素建模为界面平面上的连续高斯分布。GUI-G$^2$包含两种协同机制：高斯点奖励通过以元素质心为中心呈指数衰减的分布来建模精确的定位，而覆盖奖励通过测量预测高斯分布与目标区域之间的重叠来评估空间对齐。为了处理不同的元素尺度，我们开发了一种自适应方差机制，根据元素尺寸校准奖励分布。该框架将GUI定位从稀疏二元分类转变为密集连续优化，其中高斯分布生成丰富的梯度信号，引导模型走向最佳交互位置。在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中进行的广泛实验表明，GUI-G$^2$显著优于最先进方法UI-TARS-72B，其中在ScreenSpot-Pro上取得了24.7%的最显著提升。我们的分析表明，连续建模为界面变化提供了卓越的鲁棒性，并增强了对未见布局的泛化能力，为GUI交互任务中的空间推理建立了新的范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [Rethinking Inductive Bias in Geographically Neural Network Weighted Regression](https://arxiv.org/abs/2507.09958)
> *重新思考地理神经网络加权回归中的归纳偏置*

*Zhenyuan Chen* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 归纳偏置, 地理神经网络加权回归, 空间非平稳性, 深度学习, 空间回归

**Comment:** I have decided to withdraw this preprint as it no longer aligns with
  my current research goals and priorities. The manuscript requires substantial
  revision and should not remain publicly accessible in its current form

> **TL;DR:** 本文重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，并提出了通过整合卷积神经网络、循环神经网络和Transformer概念来泛化GNNWR的方法，实验证明其在捕获复杂空间关系方面优于经典方法。

**AI_Comments:** 本文的创新之处在于将深度学习领域中先进的神经网络架构（CNN、RNN、Transformer）的思想引入到地理加权回归模型中，从而增强了GNNWR处理空间非平稳性和复杂非线性关系的能力。这对于提升空间回归模型的泛化能力和适应性具有重要意义。研究通过实验验证了其有效性，并深入探讨了数据特性对模型表现的影响，为未来空间建模提供了宝贵的见解和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 归纳偏置是空间回归模型中的关键因素，决定了模型从有限数据中学习和捕获空间模式的能力。本文旨在重新审视地理神经网络加权回归（GNNWR）中的归纳偏置，并识别当前方法在建模空间非平稳性方面的局限性，因为现有GNNWR实现常受限于固定距离方案和有限的归纳偏置。

**Method:** 本文通过整合卷积神经网络（CNN）、循环神经网络（RNN）和Transformer的概念，将局部感受野、序列上下文和自注意力引入空间回归，从而泛化了地理神经网络加权回归（GNNWR）。通过在具有不同异质性、噪声和样本量的合成空间数据集上进行广泛基准测试来评估所提出的方法。

**Result:** 实验结果表明，泛化后的GNNWR在捕获非线性和复杂空间关系方面优于经典方法。研究还发现模型性能强烈依赖于数据特性，其中局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更同质的数据中表现更好。

**Conclusion:** 研究结果强调了归纳偏置在空间建模中的重要性，并指出了未来的研究方向，包括可学习的空间加权函数、混合神经网络架构以及提高处理非平稳空间数据的模型可解释性。

> **ai_Abstract:** 本文重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，指出现有GNNWR在处理空间非平稳性上的局限性。为克服此问题，研究提出将卷积神经网络、循环神经网络和Transformer概念引入GNNWR，以增强其捕获复杂空间关系的能力。通过合成数据集的基准测试，证实了泛化后的GNNWR优于传统方法，并发现模型性能受数据特性影响显著。研究强调了归纳偏置在空间建模中的重要性，并展望了未来研究方向。

> **摘要翻译:** 归纳偏置是空间回归模型中的关键因素，它决定了模型从有限数据中学习和捕获空间模式的能力。这项工作重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，并识别了当前建模空间非平稳性方法的局限性。虽然GNNWR通过使用神经网络学习空间加权函数来扩展传统地理加权回归，但现有的实现通常受到固定基于距离的方案和有限归纳偏置的限制。我们提出通过整合卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，将局部感受野、序列上下文和自注意力引入空间回归。通过在具有不同异质性、噪声和样本量的合成空间数据集上进行广泛基准测试，我们表明GNNWR在捕获非线性和复杂空间关系方面优于经典方法。我们的结果还揭示了模型性能强烈依赖于数据特性，其中局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更同质的数据中表现更好。这些发现强调了归纳偏置在空间建模中的重要性，并提出了未来的方向，包括可学习的空间加权函数、混合神经网络架构以及提高处理非平稳空间数据的模型可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [407] [RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems](https://arxiv.org/abs/2507.15867)
> *RDMA：电子健康记录系统中经济高效的代理驱动罕见病发现*

*John Wu, Adam Cross, Jimeng Sun* | **Category: cs.LG, cs.AI, cs.CL, cs.MA** | **Updated: 2025-07-14**

**Keywords:** 罕见病发现, 电子健康记录, 隐私保护, 机器学习, 临床推理

**Comment:** 

> **TL;DR:** RDMA是一个新的框架，通过模仿医学专家的方式，在电子健康记录中发现罕见疾病，解决了现有方法在识别罕见病方面的局限性、隐私问题和高成本，显著提高了F1性能并降低了推理成本。

**AI_Comments:** RDMA的创新之处在于其模仿医学专家推理过程的代理驱动方法，以及在本地标准硬件上运行以解决隐私和成本问题的策略。这对于罕见病诊断具有重要意义，因为它能更早、更安全地从现有EHR数据中发现潜在病例。其在F1性能和成本效益上的显著改进，使其成为一个有前景的临床辅助工具。

<details>
  <summary>Details</summary>

**Motivation:** 罕见病影响着十分之一的美国人，但标准的ICD编码系统无法在电子健康记录（EHR）中捕捉这些疾病，导致关键信息埋藏在临床笔记中。现有方法难以处理医学缩写、遗漏隐性疾病提及、通过云处理引发隐私问题，并缺乏临床推理能力。

**Method:** 本文提出了罕见病挖掘代理（RDMA）框架，该框架模仿医学专家识别EHR中罕见病模式的方式。RDMA连接分散的临床观察，共同提示特定的罕见病。它通过处理临床缩写、识别隐性疾病模式，并在标准硬件上本地应用上下文推理来运行。

**Result:** RDMA在提高F1性能方面提升了30%以上，同时将推理成本降低了10倍，并降低了隐私风险。

**Conclusion:** RDMA帮助临床医生避免使用云服务的隐私风险，同时从EHR系统中获取关键的罕见病信息，从而支持罕见病患者的早期诊断。

> **ai_Abstract:** RDMA是一个旨在解决电子健康记录（EHR）中罕见病识别挑战的框架。针对现有系统无法有效捕捉罕见病、存在隐私风险和成本高昂的问题，RDMA模仿医学专家，通过本地处理临床缩写、识别隐性疾病模式和应用上下文推理，显著提升了罕见病发现的F1性能和降低了推理成本，同时避免了云处理带来的隐私担忧，促进了罕见病患者的早期诊断。

> **摘要翻译:** 罕见病影响着十分之一的美国人，但标准的ICD编码系统未能捕捉电子健康记录（EHR）中的这些疾病，导致关键信息埋藏在临床笔记中。现有方法难以处理医学缩写，遗漏隐性疾病提及，通过云处理引发隐私问题，并缺乏临床推理能力。我们提出了罕见病挖掘代理（RDMA），这是一个模仿医学专家在EHR中识别罕见病模式的框架。RDMA连接分散的临床观察，这些观察共同提示特定的罕见病。通过处理临床缩写、识别隐性疾病模式，并在标准硬件上本地应用上下文推理，RDMA在降低隐私风险的同时，将F1性能提高了30%以上，并将推理成本降低了10倍。这种方法帮助临床医生避免使用云服务的隐私风险，同时从EHR系统中获取关键的罕见病信息，支持罕见病患者的早期诊断。可在https://github.com/jhnwu3/RDMA获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [420] [A Lower Bound for the Number of Linear Regions of Ternary ReLU Regression Neural Networks](https://arxiv.org/abs/2507.16079)
> *三元ReLU回归神经网络线性区域数量的下界*

*Yuta Nakahara, Manabu Kobayashi, Toshiyasu Matsushima* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 三元神经网络, 线性区域, ReLU, 表达能力, 理论分析

**Comment:** 

> **TL;DR:** 本文理论分析了三元神经网络的表达能力，证明了其线性区域数量随网络宽度多项式增长、深度指数增长，并达到与标准ReLU网络相当的下界，为其实际成功提供了理论解释。

**AI_Comments:** 本文通过对三元ReLU神经网络线性区域数量的理论分析，填补了该领域理论理解的空白。其创新之处在于量化了三元网络的表达能力，并证明了其在特定条件下可与标准ReLU网络媲美，这对于解释三元网络在资源受限环境下的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习的计算复杂度和内存消耗是关键挑战，三元神经网络因其参数限制在{-1, 0, +1}而成为有前景的解决方案，但其理论理解不足。

**Method:** 本文从线性区域数量的角度理论分析了三元神经网络的表达能力。具体而言，评估了使用ReLU作为激活函数的三元回归神经网络的线性区域数量，并进行了证明。

**Result:** 线性区域数量随网络宽度多项式增长，随深度指数增长，类似于标准神经网络。此外，通过将三元神经网络的宽度平方或深度加倍，足以达到与通用ReLU回归神经网络相当的最大线性区域数量的下界。

**Conclusion:** 本文为三元神经网络在实际应用中的成功提供了一定程度的理论解释。

> **ai_Abstract:** 本文理论探讨了三元ReLU回归神经网络的表达能力，通过分析其线性区域数量，发现其随网络宽度多项式增长、深度指数增长，与标准神经网络类似。研究还表明，通过适度增加宽度或深度，三元网络可以达到与通用ReLU网络相当的线性区域数量下界，从而为三元网络在实际应用中的成功提供了理论依据。

> **摘要翻译:** 随着深度学习的发展，降低计算复杂度和内存消耗已成为一个关键挑战，而将参数限制在{-1, 0, +1}的三元神经网络（NNs）作为一种有前景的方法受到了关注。尽管三元神经网络在图像识别和自然语言处理等实际应用中表现出色，但其理论理解仍不充分。本文从线性区域数量的角度理论分析了三元神经网络的表达能力。具体而言，我们评估了使用整流线性单元（ReLU）作为激活函数的三元回归神经网络的线性区域数量，并证明了线性区域数量随网络宽度多项式增长，随深度指数增长，类似于标准神经网络。此外，我们表明，只需将三元神经网络的宽度平方或深度加倍，即可达到与通用ReLU回归神经网络相当的最大线性区域数量的下界。这在某种程度上为三元神经网络的实际成功提供了理论解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [421] [Learning to Bid in Non-Stationary Repeated First-Price Auctions](https://arxiv.org/abs/2501.13358)
> *在非平稳重复第一价格拍卖中学习投标*

*Zihao Hu, Xiaoyu Fan, Yuan Yao, Jiheng Zhang, Zhengyuan Zhou* | **Category: cs.LG, cs.GT, cs.IT, math.IT, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 第一价格拍卖, 非平稳性, 动态遗憾, 乐观镜像下降, 投标策略

**Comment:** 

> **TL;DR:** 本文研究了在非平稳重复第一价格拍卖中如何进行最优投标学习，提出了衡量非平稳性的新指标，并利用乐观镜像下降（OMD）框架实现了动态遗憾的最小最大最优性，超越了现有方法。

**AI_Comments:** 本文的创新点在于提出了量化非平稳性的新指标，并创造性地将乐观镜像下降（OMD）框架应用于非平稳第一价格拍卖的动态遗憾优化问题，实现了理论上的最小最大最优性。这对于理解和设计在动态市场环境中更稳健的投标策略具有重要意义，超越了传统静态分析的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 第一价格拍卖在数字广告市场中日益普及，但与第二价格拍卖不同，其最优投标策略更复杂。现有研究常假设环境稳定并以静态基准衡量性能，但在非平稳环境中，静态基准会显著偏离最优策略。因此，需要一个能适应动态环境的学习方法。

**Method:** 本文引入了两个衡量对手最高出价序列规律性的指标来量化非平稳性。主要技术工具是具有新颖乐观配置的乐观镜像下降（OMD）框架，用于在满足规律性约束的对手最高出价序列类别中实现动态遗憾的最小最大最优性。

**Result:** 本文提供了满足特定规律性约束的对手最高出价序列类别中动态遗憾的最小最大最优性表征。通过合成数据集验证了理论保证，并证明所提出的方法优于现有方法。

**Conclusion:** 本文成功解决了在非平稳重复第一价格拍卖中实现最优投标学习的挑战。通过引入新的非平稳性度量和利用改进的乐观镜像下降框架，实现了动态遗憾的最小最大最优性，并被证明优于现有方法，为该领域的学习策略提供了新的视角。

> **ai_Abstract:** 本文研究了在非平稳重复第一价格拍卖中的学习投标问题。针对现有静态基准在非平稳环境中表现不佳的问题，文章提出了两个量化对手最高出价序列非平稳性的新指标。核心贡献在于利用新颖乐观配置的乐观镜像下降（OMD）框架，为满足特定规律性约束的序列实现了动态遗憾的最小最大最优性，并通过实验证明其性能优于现有方法。

> **摘要翻译:** 第一价格拍卖最近在数字广告市场中获得了显著关注，例如谷歌从第二价格拍卖转向第一价格拍卖。与第二价格拍卖中私人估价投标是主导策略不同，在第一价格拍卖中确定最优投标策略更为复杂。从学习的角度来看，学习者（特定投标者）可以与环境（其他投标者，即对手）顺序交互以推断其行为。现有研究通常假设特定的环境条件，并根据最佳固定策略（静态基准）来衡量性能。虽然这种方法能确保强大的学习保证，但即使在轻微非平稳的环境中，静态基准也可能与最优策略显著偏离。为了解决这种情况，动态基准——代表每个时间步可实现的最高奖励总和——提供了一个更合适的目标。然而，相对于动态基准实现无遗憾学习需要额外的约束。通过检查在线第一价格拍卖中的奖励函数，我们引入了两个指标来量化对手最高出价序列的规律性，这些指标作为非平稳性的度量。我们提供了满足这些规律性约束之一的对手最高出价序列类别的动态遗憾的最小最大最优性表征。我们的主要技术工具是具有新颖乐观配置的乐观镜像下降（OMD）框架，它非常适合在此背景下实现最小最大最优的动态遗憾率。然后，我们使用合成数据集验证了我们的理论保证，并证明我们的方法优于现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [423] [Learning from Data Streams: An Overview and Update](https://arxiv.org/abs/2212.14720)
> *从数据流中学习：概述与更新*

*Jesse Read, Indrė Žliobaitė* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 数据流, 机器学习, 概念漂移, 时间依赖性, 监督学习

**Comment:** 

> **TL;DR:** 现有数据流机器学习研究存在不切实际的假设和方法论缺陷，本文重新审视了数据流学习任务的定义和算法，并建议研究重点转向鲁棒性、隐私和可解释性。

**AI_Comments:** 这篇论文的重要性在于它对数据流机器学习领域进行了深刻的反思和批判，指出了当前研究中存在的根本性问题，特别是脱离实际应用场景的假设和方法论缺陷。其创新之处在于提出重新审视和定义数据流学习任务，并强调了鲁棒性、隐私和可解释性等未来研究的关键方向，这对于引导该领域回归实际需求、提升研究的实际影响力具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据流机器学习研究存在多重问题：其定义性假设过于严格或自相矛盾，难以在实际应用中成立；算法选择和设计标准不明确，问题设置不清晰，测试环境不现实，且与相关领域方法脱节。这导致许多研究成果的实际影响受限，并可能误导研究方向。

**Method:** 作者通过重新审视和重新定义有监督数据流学习的基本概念和设置，尤其考虑概念漂移和时间依赖性，来解决现有问题。他们对数据流学习任务进行了全新审视，并重新思考了适用的算法。此外，他们还结合对实际处理数据流的行业参与者的非正式调查，提出了建议。

**Result:** 论文强调，数据流学习不应强制要求单遍或在线学习方法，或任何特定的学习范式；内存和时间限制也并非数据流独有。同时，处理时间依赖性和概念漂移的成熟技术已存在于其他文献领域。

**Conclusion:** 论文鼓励数据流社区将研究重点从处理人工限制和学习模式假设，转向鲁棒性、隐私和可解释性等在学术和工业环境中与数据流学习日益相关的问题。

> **ai_Abstract:** 本文对数据流机器学习领域的现状进行了批判性审视，指出现有研究普遍存在不切实际的假设、方法论缺陷及与实际应用脱节的问题。为纠正研究方向，作者重新定义了有监督数据流学习的任务和设置，并强调在处理概念漂移和时间依赖性时，不应局限于特定的学习范式或内存/时间约束。论文最终建议数据流社区将研究重心转移至鲁棒性、隐私和可解释性等更具实际意义的挑战。

> **摘要翻译:** 机器学习在数据流背景下的文献内容浩瀚且不断增长。然而，许多关于数据流学习任务的决定性假设过于严格，难以在实践中成立，甚至相互矛盾，以至于在监督学习环境中无法满足。算法的选择和设计往往基于不明确的标准，针对不明确定义的问题设置，在不切实际的环境中进行测试，和/或与更广泛文献中的相关方法隔离。这使许多在此类背景下构思的方法的实际影响潜力受到质疑，并有传播错误研究焦点的风险。我们建议通过重新制定有监督数据流学习的基本定义和设置，并考虑概念漂移和时间依赖性等当代因素来解决这些问题；我们还重新审视了构成有监督数据流学习任务的要素，并重新考虑了可用于解决此类任务的算法。通过对这种公式化和概述的反思，并辅以对处理真实世界数据流的行业参与者的非正式调查，我们提供了建议。我们的主要重点是，从数据流中学习不应强制要求单遍或在线学习方法，或任何特定的学习范式；任何内存和时间限制也不是流处理所特有的。同时，在文献的其他领域中，存在处理时间依赖性和概念漂移的成熟技术。因此，对于数据流社区，我们鼓励研究重点从处理通常是人为的关于学习模式的约束和假设，转向鲁棒性、隐私和可解释性等问题，这些问题在学术和工业环境中与数据流学习日益相关。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [Custom Algorithm-based Fault Tolerance for Attention Layers in Transformers](https://arxiv.org/abs/2507.16676)
> *Transformer中注意力层的定制算法级容错*

*Vasileios Titopoulos, Kosmas Alexandridis, Giorgos Dimitrakopoulos* | **Category: cs.LG, cs.AR** | **Updated: 2025-07-22**

**Keywords:** 算法级容错, 注意力机制, Transformer, 硬件加速器, Flash-ABFT

**Comment:** IEEE International System-on-Chip Conference (IEEE SOCC 2025)

> **TL;DR:** Flash-ABFT是一种新的算法级容错方法，通过对注意力层中的查询、键和值矩阵的整个三矩阵乘积（包括softmax操作）进行在线校验和计算，实现高效的错误检测，显著降低了硬件和能耗开销。

**AI_Comments:** 这项工作创新性地解决了传统算法级容错技术无法有效处理包含softmax的注意力机制的痛点，通过单一校验和实现了对整个三矩阵乘积的容错，显著降低了开销。其重要性在于为Transformer和LLMs的硬件加速器提供了低成本、高效率的错误检测方案，有助于提升这些高性能AI系统的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** Transformer和大型语言模型（LLMs）驱动了对专用硬件加速器的需求，但这些加速器在高效检测由随机硬件故障引起的错误方面面临重大挑战。传统的算法级容错（ABFT）技术无法有效处理包含中间softmax归一化的完整注意力机制。

**Method:** 本文提出了Flash-ABFT，一种新颖的方法，通过对注意力层中查询、键和值矩阵的整个三矩阵乘积（包括softmax操作）进行在线校验和计算，并进行一次性检查。这种方法通过消除冗余检查显著降低了开销，同时保持了高故障检测精度。

**Result:** 实验结果表明，Flash-ABFT仅带来5.3%的硬件面积开销和低于1.9%的能耗开销。

**Conclusion:** Flash-ABFT为注意力加速器中的错误检测提供了一种经济高效且鲁棒的解决方案。

> **ai_Abstract:** 本文提出Flash-ABFT，一种针对Transformer中注意力层的定制算法级容错方法。该方法通过对注意力层中包含softmax操作的整个查询、键、值三矩阵乘积进行在线校验和计算和单次检查，有效解决了传统ABFT在处理完整注意力机制时的不足。实验证明，Flash-ABFT在保持高故障检测精度的同时，显著降低了硬件面积（5.3%）和能耗（1.9%）开销，为注意力加速器提供了高效、鲁棒的错误检测方案。

> **摘要翻译:** Transformer和大型语言模型（LLMs）在注意力机制的驱动下，已经改变了众多AI应用，推动了对专用硬件加速器的需求。这些加速器面临的一个主要挑战是有效检测由随机硬件故障引起的错误。传统的算法级容错（ABFT）技术验证单个矩阵乘法，但在处理完整的注意力机制（特别是由于中间softmax归一化）时却力不从心。这项工作提出了Flash-ABFT，一种新颖的方法，通过对注意力层的查询、键和值矩阵的整个三矩阵乘积（包括softmax操作）进行在线校验和计算，并进行一次性检查。这种方法通过消除冗余检查显著降低了开销，同时保持了高故障检测精度。实验结果表明，Flash-ABFT仅带来5.3%的硬件面积开销和低于1.9%的能耗开销，使其成为注意力加速器中错误检测的一种经济高效且鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [436] [T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs](https://arxiv.org/abs/2507.10183)
> *T-GRAB：一个用于时态图学习的合成诊断基准*

*Alireza Dizaji, Benedict Aaron Tjandra, Mehrab Hamidi, Shenyang Huang, Guillaume Rabusseau* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 时态图神经网络, 合成基准, 时态推理, 动态图, 诊断

**Comment:** Accepted to MLoG-GenAI Workshop @ KDD 2025 (Oral)

> **TL;DR:** T-GRAB是一个新的合成基准，用于诊断当前时态图神经网络（TGNNs）在捕获周期性、因果关系和长程依赖等核心时态模式方面的能力，并发现现有模型存在根本性缺陷。

**AI_Comments:** 这项工作通过引入一个受控的合成诊断基准T-GRAB，填补了现有基准在系统评估TGNNs时态推理能力方面的空白。其创新之处在于设计了专门的任务来隔离和测试关键的时态技能，从而能够清晰地揭示当前模型的局限性。这对于推动时态图学习领域的发展至关重要，因为它提供了明确的改进方向，避免了真实世界数据集中可能存在的混淆因素。

<details>
  <summary>Details</summary>

**Motivation:** 尽管动态图学习方法在建模随时间演变的关系数据方面表现出色，但目前尚不清楚现有的时态图神经网络（TGNNs）是否能有效捕获周期性、因果关系和长程依赖等核心时态模式。

**Method:** 本文引入了时态图推理基准（T-GRAB），这是一套全面的合成任务，旨在系统地探究TGNNs跨时间推理的能力。T-GRAB提供了受控、可解释的任务，用于隔离关键的时态技能：计数/记忆周期性重复、推断延迟因果效应以及捕获空间和时间维度上的长程依赖。

**Result:** 我们对11种时态图学习方法在这些任务上进行了评估，结果揭示了它们在泛化时态模式方面存在根本性缺陷。

**Conclusion:** 我们的研究结果为当前模型的局限性提供了可操作的见解，突出了传统真实世界基准所隐藏的挑战，并激励了开发具有更强时态推理能力的架构。

> **ai_Abstract:** 本文提出了T-GRAB，一个合成的诊断基准，旨在系统评估时态图神经网络（TGNNs）捕获和推理核心时态模式（如周期性、因果关系和长程依赖）的能力。通过对11种现有方法进行评估，研究发现当前的TGNNs在泛化这些时态模式方面存在显著缺陷，这为未来开发更强大的时态推理架构指明了方向，并揭示了真实世界基准可能掩盖的问题。

> **摘要翻译:** 动态图学习方法最近已成为建模随时间演变的关系数据的强大工具。然而，尽管进行了广泛的基准测试，但目前仍不清楚当前的循环图神经网络（TGNNs）是否能有效捕获核心时态模式，例如周期性、因果关系和长程依赖。在这项工作中，我们引入了时态图推理基准（T-GRAB），这是一套全面的合成任务，旨在系统地探究TGNNs跨时间推理的能力。T-GRAB提供了受控、可解释的任务，用于隔离关键的时态技能：计数/记忆周期性重复、推断延迟因果效应，以及捕获空间和时间维度上的长程依赖。我们评估了11种时态图学习方法在这些任务上的表现，揭示了它们在泛化时态模式方面的根本性缺陷。我们的发现为当前模型的局限性提供了可操作的见解，突出了传统真实世界基准所隐藏的挑战，并激励了开发具有更强时态推理能力的架构。T-GRAB的代码可在以下网址找到：https://github.com/alirezadizaji/T-GRAB。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [450] [Latent Space Alignment for AI-Native MIMO Semantic Communications](https://arxiv.org/abs/2507.16680)
> *面向AI原生MIMO语义通信的潜在空间对齐*

*Mario Edoardo Pandolfo, Simone Fiorellino, Emilio Calvanese Strinati, Paolo Di Lorenzo* | **Category: cs.LG, cs.IT, cs.NI, math.IT** | **Updated: 2025-07-22**

**Keywords:** 语义通信, MIMO, 潜在空间对齐, 预编码器/解码器, AI原生

**Comment:** Proc. of IEEE IJCNN 2025

> **TL;DR:** 本文提出了一种新颖的方法，利用MIMO通信解决语义通信中的潜在空间错位问题，通过学习MIMO预编码器/解码器对实现潜在空间压缩和语义信道均衡，以减轻语义不匹配和物理信道损伤。

**AI_Comments:** 本文的创新之处在于将MIMO通信引入到语义通信的潜在空间对齐中，旨在解决设备间语义不匹配的问题。通过联合设计预编码器/解码器，实现语义压缩和信道均衡，提供了一种端到端的解决方案。探讨线性模型和神经网络模型也展示了其在不同约束条件下的灵活性和普适性。这项工作对于提升未来AI原生通信的效率和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语义通信在设备依赖不同语言、逻辑或内部表示时可能出现语义不匹配，从而阻碍相互理解。本文旨在解决这一问题。

**Method:** 本文提出了一种新的方法来解决语义通信中的潜在空间错位问题，该方法利用多输入多输出（MIMO）通信。具体来说，该方法学习一个MIMO预编码器/解码器对，共同执行潜在空间压缩和语义信道均衡，以减轻语义不匹配和物理信道损伤。探讨了两种解决方案：(i) 线性模型，通过交替方向乘子法（ADMM）解决双凸优化问题进行优化；(ii) 基于神经网络的模型，在传输功率预算和复杂度约束下学习语义MIMO预编码器/解码器。

**Result:** 数值结果表明，在面向目标的语义通信场景中，所提出的方法是有效的，并说明了精度、通信负担和解决方案复杂度之间的主要权衡。

**Conclusion:** 本文提出的利用MIMO通信进行潜在空间对齐的方法，在面向目标的语义通信中表现出有效性，并揭示了精度、通信负担和复杂度之间的权衡。

> **ai_Abstract:** 本文提出了一种利用MIMO通信解决语义通信中潜在空间错位问题的新方法。通过学习一个MIMO预编码器/解码器对，该方法能够同时进行潜在空间压缩和语义信道均衡，有效减轻语义不匹配和物理信道损伤。文中探索了线性模型和基于神经网络的模型两种实现方案。数值结果验证了该方法在目标导向语义通信场景中的有效性，并揭示了精度、通信负担和复杂度之间的权衡。

> **摘要翻译:** 语义通信侧重于优先理解传输数据背后的含义，并确保成功完成促使信息交换的任务。然而，当设备依赖不同的语言、逻辑或内部表示时，可能会发生语义不匹配，从而可能阻碍相互理解。本文引入了一种新颖的方法来解决语义通信中的潜在空间错位问题，利用多输入多输出（MIMO）通信。具体来说，我们的方法学习一个MIMO预编码器/解码器对，共同执行潜在空间压缩和语义信道均衡，减轻语义不匹配和物理信道损伤。我们探讨了两种解决方案：(i) 线性模型，通过交替方向乘子法（ADMM）解决双凸优化问题进行优化；(ii) 基于神经网络的模型，在传输功率预算和复杂度约束下学习语义MIMO预编码器/解码器。数值结果表明，在面向目标的语义通信场景中，所提出的方法是有效的，并说明了精度、通信负担和解决方案复杂度之间的主要权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [459] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
> *实现大型语言模型Transformer架构的物理模型*

*Zeqian Chen* | **Category: cs.LG, cs.AI, cs.CL, math-ph, math.MP** | **Updated: 2025-07-22**

**Keywords:** Transformer架构, 物理模型, 大型语言模型, 开放量子系统, 注意力机制

**Comment:** 6 pages, minor changes, Refs [3, 13, 15] added

> **TL;DR:** 本文从物理视角，将基于Transformer架构的大型语言模型构建为开放量子系统，以弥补对Transformer工作原理物理理解的不足。

**AI_Comments:** 本文提出了一个新颖的视角，将大型语言模型视为开放量子系统，并试图从物理层面解释Transformer的工作原理。这种跨学科的探索可能为理解和未来设计AI模型提供全新的理论框架，尽管其具体实践意义和验证方法在摘要中未详细阐述，但概念本身具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer架构在自然语言处理领域取得了显著进展，但目前对Transformer是什么以及其物理工作原理的理论理解存在空白。作者认为现代智能机器应被视为开放量子系统。

**Method:** 本文将基于Transformer架构的大型语言模型构建为开放量子系统，具体在词元（tokens）的希尔伯特空间上的福克空间中构建物理模型。

**Result:** 本文构建的物理模型为大型语言模型的Transformer架构提供了物理基础。

**Conclusion:** 通过将大型语言模型视为开放量子系统并构建相应的物理模型，可以加深对Transformer架构物理工作原理的理解。

> **ai_Abstract:** 本文旨在弥补对Transformer架构物理工作原理理解的不足。作者提出，从物理角度看，现代智能机器（包括基于Transformer的大型语言模型）应被视为开放量子系统。为此，论文构建了在词元希尔伯特空间上的福克空间中的物理模型，以实现Transformer架构，并声称这些模型为Transformer架构提供了物理基础。

> **摘要翻译:** Transformer架构于2017年问世，标志着自然语言处理领域最引人注目的进步。Transformer是一种完全依赖注意力机制来抽取输入和输出之间全局依赖关系的模型架构。然而，我们认为在理论上对Transformer是什么以及它如何物理上工作存在理解上的空白。从现代芯片（例如28纳米以下的芯片）的物理角度来看，现代智能机器应被视为超越传统统计系统的开放量子系统。因此，在本文中，我们将基于Transformer架构的大型语言模型构建为在词元（tokens）希尔伯特空间上的福克空间中的开放量子系统。我们的物理模型是大型语言模型Transformer架构的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [460] [Energy-Efficient and Real-Time Sensing for Federated Continual Learning via Sample-Driven Control](https://arxiv.org/abs/2310.07497)
> *样本驱动控制的联邦持续学习中节能实时感知*

*Minh Ngoc Luu, Minh-Duong Nguyen, Ebrahim Bedeer, Van Duc Nguyen, Dinh Thai Hoang, Diep N. Nguyen, Quoc-Viet Pham* | **Category: cs.LG, cs.AI, 68-00, I.2.11** | **Updated: 2025-07-22**

**Keywords:** 联邦持续学习, 实时感知, 样本驱动控制, 能源效率, 泛化差距

**Comment:** 20 pages, 7 figures

> **TL;DR:** 针对联邦持续学习中实时感知数据的挑战，本文提出一种样本驱动控制方法SCFL和A2C-EI算法，显著降低能耗并提高效率。

**AI_Comments:** 这篇论文的创新点在于将样本驱动控制引入联邦持续学习，以解决实时感知数据处理中的能效和性能问题。通过利用“泛化差距”概念并设计特定的优化算法（A2C-EI），该研究为移动边缘网络中的分布式智能系统提供了一个实用的解决方案，尤其是在降低能源消耗方面取得了显著成果，这对于资源受限的边缘设备至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 智能实时感知（RTS）系统必须持续学习以适应现实世界的动态，而联邦持续学习（FCL）是管理分布式智能的关键。然而，在FCL系统中有效捕捉RTS数据的多样性特征面临严峻挑战，导致计算和通信资源消耗大、能源成本高以及整体系统性能下降。

**Method:** 本文首先利用“泛化差距”概念，研究了从理想到实际RTS场景的数据分布变化如何影响人工智能（AI）模型性能，并分析了采样时间与AI性能下降、计算成本和通信效率的关系。基于此，开发了一种新颖的联邦持续学习样本驱动控制（SCFL）技术，专为具有RTS能力的移动边缘网络设计。SCFL是一个优化问题，旨在通过采样过程同时最小化泛化差距、提高整体准确性并保持FCL框架的能效。为解决此高度复杂且时变的优化问题，本文引入了一种新的带有显式和隐式约束的软演员-评论家算法（A2C-EI）。

**Result:** 经验实验表明，与其它深度强化学习（DRL）基线相比，SCFL能实现更高的效率。值得注意的是，SCFL在保持FL收敛和及时数据传输的同时，可以显著降低高达85%的能耗。

**Conclusion:** 本文提出的SCFL技术及其A2C-EI算法有效解决了联邦持续学习中实时感知数据的能效和性能问题，通过样本驱动控制实现了显著的能耗降低和效率提升，同时保持了系统性能。

> **ai_Abstract:** 本文针对联邦持续学习（FCL）在实时感知（RTS）系统中的能耗和性能挑战，深入探讨了数据分布变化对AI模型表现的影响，并提出了一种新颖的样本驱动控制技术（SCFL）。SCFL通过优化采样过程，旨在最小化泛化差距、提高准确性并提升FCL的能效。为解决SCFL的复杂优化问题，研究引入了A2C-EI算法。实验结果表明，SCFL相比现有方法能显著提高效率，并成功将能耗降低高达85%，同时维持了联邦学习的收敛性和数据传输的及时性。

> **摘要翻译:** 智能实时感知（RTS）系统必须持续获取、更新、整合和应用知识以适应现实世界的动态。在这种背景下管理分布式智能需要联邦持续学习（FCL）。然而，在FCL系统中有效捕捉RTS数据的多样化特征带来了严峻挑战，包括严重影响计算和通信资源、增加能源成本以及最终降低整体系统性能。为了克服这些挑战，我们利用“泛化差距”概念，研究了从理想到实际RTS场景的数据分布变化如何影响人工智能（AI）模型性能。通过这种方式，我们可以分析RTS中的采样时间如何与AI性能下降、计算成本和通信效率相关联。基于这一观察，我们开发了一种新颖的联邦持续学习样本驱动控制（SCFL）技术，专门为具有RTS能力的移动边缘网络设计。特别是，SCFL是一个优化问题，它利用采样过程同时最小化泛化差距并提高整体准确性，同时保持FCL框架的能效。为了解决高度复杂且时变的优化问题，我们引入了一种新的带有显式和隐式约束的软演员-评论家算法（A2C-EI）。我们的经验实验表明，与其它深度强化学习（DRL）基线相比，我们能实现更高的效率。值得注意的是，SCFL在保持FL收敛和及时数据传输的同时，可以显著降低高达85%的能耗。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [Canonical Correlation Patterns for Validating Clustering of Multivariate Time Series](https://arxiv.org/abs/2507.16497)
> *规范相关模式用于验证多元时间序列聚类*

*Isabella Degen, Zahraa S Abdallah, Kate Robson Brown, Henry W J Reeve* | **Category: cs.LG, stat.AP, 62H30 (Primary), 62M10 (Secondary), I.5.3; I.6.4** | **Updated: 2025-07-22**

**Keywords:** 多元时间序列聚类, 相关性验证, 规范相关模式, 聚类有效性指标

**Comment:** 45 pages, 8 figures. Introduces canonical correlation patterns as
  discrete validation targets for correlation-based clustering, systematically
  evaluates distance functions and validity indices, and provides practical
  implementation guidelines through controlled experiments with synthetic
  ground truth data

> **TL;DR:** 提出规范相关模式作为验证多元时间序列相关性聚类的数学定义目标，解决了现有验证方法对相关性数据无效的问题，并在合成数据集上验证了其可靠性。

**AI_Comments:** 这项工作创新性地提出了“规范相关模式”来解决多元时间序列相关性聚类的验证问题，弥补了现有欧几里得数据验证方法在连续相关空间中的不足。它为高风险领域（如健康、金融）提供了更严谨的聚类验证工具，具有重要的实践意义。其通过将连续空间离散化的思路，为后续研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 验证多元时间序列聚类是否代表独特的而非任意的分组是一个基本挑战。现有聚类有效性指标是为欧几里得数据开发的，其对相关性模式的有效性尚未系统评估。相关性存在于连续空间中，没有等效的参考模式。

**Method:** 引入规范相关模式作为数学定义的验证目标，将无限相关空间离散化为有限、可解释的参考模式。使用具有完美真实值的合成数据集进行验证。

**Result:** 规范模式提供了可靠的验证目标。L1范数用于映射，L5范数用于轮廓宽度准则和Davies-Bouldin指数显示出卓越的性能。这些方法对分布变化具有鲁棒性，并能适当地检测相关结构退化。

**Conclusion:** 这项工作为高风险领域中基于相关性的聚类验证建立了严格的方法论基础。

> **ai_Abstract:** 本文针对多元时间序列相关性聚类验证的挑战，提出了一种新方法。由于现有验证指标主要针对欧几里得数据，无法有效评估相关性模式，作者引入了规范相关模式作为数学定义的验证目标，将连续的相关性空间离散化为可解释的参考模式。通过在合成数据集上的实验，证明了规范模式作为可靠验证目标的有效性，并指出L1范数在映射和L5范数在轮廓宽度和Davies-Bouldin指数方面的优越表现。该方法对分布变化具有鲁棒性，并能检测相关结构退化，为高风险领域的聚类验证奠定了基础。

> **摘要翻译:** 多元时间序列的聚类使用基于相关性的方法揭示了健康、金融和工业应用中变量之间关系的状态变化。然而，验证所发现的聚类是否代表不同的关系而非任意分组仍然是一个基本挑战。现有的聚类有效性指标是为欧几里得数据开发的，其对相关模式的有效性尚未得到系统评估。与欧几里得聚类中几何形状提供离散参考目标不同，相关性存在于连续空间中，没有等效的参考模式。我们通过引入规范相关模式作为数学定义的验证目标来解决这一验证空白，将无限相关空间离散化为有限、可解释的参考模式。使用在受控条件下具有完美真实值的合成数据集，我们证明规范模式提供了可靠的验证目标，其中L1范数用于映射，L5范数用于轮廓宽度准则和Davies-Bouldin指数显示出卓越的性能。这些方法对分布变化具有鲁棒性，并能适当地检测相关结构退化，从而提供了实际的实施指南。这项工作为高风险领域中严格的基于相关性的聚类验证建立了方法论基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [466] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
> *用于属性图聚类的三学习图融合网络*

*Binxiong Li, Xu Xiang, Xue Li, Binyu Zhao, Heyang Gao, Qinyu Zhao* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 图聚类, 图卷积网络, 图Transformer, 特征融合, 深度聚类

**Comment:** The source code for this study is available at
  https://github.com/YF-W/Tri-GFN

> **TL;DR:** 提出Tri-GFN框架，结合GCN、AE和Graph Transformer，通过三学习机制和特征融合策略解决图聚类中的过平滑和过压缩问题，显著提高聚类性能。

**AI_Comments:** 该论文的创新点在于提出了Tri-GFN框架，巧妙地结合了GCN、AE和Graph Transformer三种不同架构，并通过独特的三学习机制和特征融合策略来解决现有图聚类方法中的挑战。这种多模块协同学习和信息融合的方式，有效地提升了模型捕获复杂关系和生成判别性表示的能力，从而显著提高了图聚类性能。其在多个数据集上的显著性能提升，证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有GCN模型在处理大规模复杂图数据集时面临过平滑和过压缩问题，导致聚类质量下降。Graph Transformer虽然有所缓解，但在处理异构图数据时性能仍受限。

**Method:** 本研究提出一种新型的深度聚类框架——三学习图融合网络（Tri-GFN），该框架包含图卷积网络（GCN）、自编码器（AE）和图Transformer。通过独特的三学习机制和特征融合增强策略，Tri-GFN增强了全局和局部信息的区分性和一致性。这些组件通过三重通道增强模块精心融合，最大限度地利用节点属性和拓扑结构，确保鲁棒的聚类表示。三学习机制允许模块间相互学习，特征融合策略使模型能够捕获复杂关系，从而为图聚类生成高度区分性的表示。

**Result:** Tri-GFN在ACM数据集上取得了约0.87%的准确率提升，在Reuters数据集上提升了14.14%，在USPS数据集上提升了7.58%。

**Conclusion:** Tri-GFN在图聚类任务中表现出色，超越了许多最先进的方法。尤其在Reuters数据集上的突出表现，使其可应用于自动新闻分类、主题检索及相关领域。

> **ai_Abstract:** 该研究针对GCN在图聚类中面临的过平滑和过压缩问题，以及Graph Transformer在异构图数据处理上的局限性，提出了一种新颖的深度聚类框架——Tri-Learn Graph Fusion Network (Tri-GFN)。Tri-GFN融合了GCN、Autoencoder和Graph Transformer，通过独特的三学习机制和特征融合增强策略，有效利用节点属性和拓扑结构，生成高区分度的聚类表示。实验结果表明，Tri-GFN在多个数据集上均显著超越现有SOTA方法，尤其在Reuters数据集上表现突出，展现了其在自动新闻分类等领域的应用潜力。

> **摘要翻译:** 近年来，基于图卷积网络（GCN）的模型在图数据分析领域取得了显著进展。然而，在处理大规模复杂图数据集时，过平滑和过压缩等挑战依然存在，导致聚类质量下降。尽管图Transformer架构缓解了其中一些问题，但其在处理异构图数据时的性能仍然有限。为了应对这些挑战，本研究提出了一种新颖的深度聚类框架，该框架包含GCN、自编码器（AE）和图Transformer，被称为三学习图融合网络（Tri-GFN）。该框架通过独特的三学习机制和特征融合增强策略，增强了全局和局部信息的区分性和一致性。该框架集成了GCN、AE和图Transformer模块。这些组件通过三重通道增强模块精心融合，最大限度地利用节点属性和拓扑结构，确保鲁棒的聚类表示。三学习机制允许这些模块之间相互学习，而特征融合策略使模型能够捕获复杂关系，从而为图聚类产生高度区分性的表示。它超越了许多最先进的方法，在ACM数据集上实现了约0.87%的准确率提升，在Reuters数据集上提升了14.14%，在USPS数据集上提升了7.58%。由于其在Reuters数据集上的出色性能，Tri-GFN可应用于自动新闻分类、主题检索及相关领域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [468] [TorchAO: PyTorch-Native Training-to-Serving Model Optimization](https://arxiv.org/abs/2507.16099)
> *TorchAO：PyTorch原生的训练到服务模型优化*

*Andrew Or, Apurva Jain, Daniel Vega-Myhre, Jesse Cai, Charles David Hernandez, Zhenrui Zheng, Driss Guessous, Vasiliy Kuznetsov, Christian Puhrsch, Mark Saroufim, Supriya Rao, Thien Tran, Aleksandar Samardžić* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** PyTorch, 模型优化, 量化, 稀疏性, 端到端工作流

**Comment:** 5 pages, 3 figures, published in CODEML@ICML25

> **TL;DR:** TorchAO是一个PyTorch原生的模型优化框架，通过量化和稀疏性提供端到端的AI模型优化工作流，解决了碎片化问题。

**AI_Comments:** TorchAO的创新之处在于其PyTorch原生集成和统一的端到端工作流，有效解决了AI模型优化领域长期存在的碎片化问题。其对多种量化和稀疏性技术的支持，以及对新颖张量子类抽象的应用，使其能够灵活处理各种低精度数据类型。该框架的重要性在于它能够加速AI模型的部署，降低计算成本，并已在实际模型（如Llama）中得到验证，对于PyTorch用户而言具有显著价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决AI模型优化领域碎片化的问题，提供一个统一的从训练到服务的端到端工作流。

**Method:** TorchAO利用量化（FP8量化训练、QAT、PTQ）和稀疏性（2:4稀疏性）等多种模型优化技术。它采用新颖的张量子类抽象来表示多种后端无关的低精度数据类型（INT4、INT8、FP8、MXFP4、MXFP6、MXFP8）。它还与PyTorch生态系统中的其他工具（如TorchTitan、TorchTune、Axolotl、HuggingFace、vLLM、SGLang、ExecuTorch）紧密集成，形成一个统一的工作流。

**Result:** TorchAO已成功应用于量化的Llama 3.2 1B/3B和LlamaGuard3-8B模型的发布。

**Conclusion:** TorchAO通过提供一个统一的、PyTorch原生的优化框架，有效地连接了原本碎片化的AI模型优化流程，并支持多种先进的优化技术和数据类型，从而实现了高效的模型部署。

> **ai_Abstract:** TorchAO是一个PyTorch原生的模型优化框架，旨在通过量化和稀疏性技术提供端到端的AI模型训练到服务工作流。它支持多种优化技术和低精度数据类型，并与PyTorch生态系统中的工具紧密集成，解决了模型优化流程的碎片化问题，已成功应用于Llama模型的量化发布。

> **摘要翻译:** 我们介绍了TorchAO，一个PyTorch原生的模型优化框架，它利用量化和稀疏性为AI模型提供端到端的、从训练到服务的全流程工作流。TorchAO支持多种流行的模型优化技术，包括FP8量化训练、量化感知训练（QAT）、训练后量化（PTQ）和2:4稀疏性，并利用新颖的张量子类抽象来表示各种广泛使用的、后端无关的低精度数据类型，包括INT4、INT8、FP8、MXFP4、MXFP6和MXFP8。TorchAO在模型优化管道的每个步骤都与更广泛的生态系统紧密集成，从预训练（TorchTitan）到微调（TorchTune、Axolotl）再到服务（HuggingFace、vLLM、SGLang、ExecuTorch），将原本碎片化的空间连接成一个统一的工作流。TorchAO已促成了最近发布的量化Llama 3.2 1B/3B和LlamaGuard3-8B模型，并在https://github.com/pytorch/ao/开源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [490] [IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning](https://arxiv.org/abs/2507.14171)
> *IPPRO：基于重要性的投影偏移剪枝，实现与幅度无关的结构化剪枝*

*Jaeheun Jung, Jaehyuk Lee, Yeajin Lee, Donghun Lee* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 结构化剪枝, 幅度无关, 投影空间, 重要性分数, 神经网络压缩

**Comment:** ICCV 2025 workshop U&ME 2025 (2nd Workshop and Challenge on
  Unlearning and Model Editing)

> **TL;DR:** IPPRO提出了一种新的剪枝策略，通过投影空间和PROscore克服了幅度对剪枝决策的主导作用，实现了近乎无损的剪枝。

**AI_Comments:** IPPRO的创新之处在于其通过引入投影空间和PROscore，成功地克服了传统剪枝方法中滤波器幅度对剪枝决策的支配性影响，为所有滤波器提供了更公平的剪枝机会。这不仅在理论上挑战了“大小至上”的观念，也在实践中展示了实现近乎无损剪枝的潜力，对神经网络压缩领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的结构化剪枝方法，特别是基于重要性的方法，常受限于幅度的影响，导致幅度大的滤波器即使冗余也不易被剪枝，从而限制了剪枝决策的能力。

**Method:** 本文提出了一种新颖的剪枝策略IPPRO，通过将滤波器置于投影空间中，并观察其梯度下降运动是否趋向原点来衡量剪枝可能性，从而构建了PROscore作为一种新的重要性分数，实现了与幅度无关的重要性剪枝。

**Result:** 提出的基于投影空间的重要性标准实现了近乎无损的剪枝，显著减少了剪枝过程中的性能下降，并在微调后表现出良好的性能。

**Conclusion:** 本工作揭示了剪枝中“大小至上”的误区，并在理论和实践上拓展了基于重要性的剪枝前沿。

> **ai_Abstract:** 本文提出了一种名为IPPRO的新型结构化剪枝方法，旨在克服传统基于重要性剪枝中幅度对剪枝决策的限制。IPPRO将滤波器映射到投影空间，并通过观察其梯度下降行为来计算PROscore，从而实现与幅度无关的剪枝。实验结果表明，该方法能够实现近乎无损的剪枝，并在微调后保持良好性能，有效挑战了“大小至上”的剪枝观念，拓展了重要性剪枝的边界。

> **摘要翻译:** IPPRO：基于重要性的投影偏移剪枝，实现与幅度无关的结构化剪枝

随着神经网络压缩方法需求的增长，包括基于重要性的结构化剪枝方法正被积极研究。幅度重要性和许多相关的现代重要性标准常常限制了剪枝决策的能力，因为幅度较大的滤波器即使是冗余的，如果幅度较小的滤波器没有被剪枝，它们也不太可能被剪枝。在本文中，我们提出了一种新颖的剪枝策略来挑战这种幅度的主导效应，并通过将每个滤波器置于投影空间中，为其提供公平的剪枝机会。之后，我们观察梯度下降运动，判断滤波器是否朝向原点移动，以衡量滤波器被剪枝的可能性。这种测量方法用于构建PROscore，这是IPPRO的一种新颖的重要性得分，IPPRO是一种与幅度无关的基于重要性的结构化剪枝方法。我们的评估结果表明，所提出的使用投影空间的重要性标准通过减少剪枝中的性能下降，实现了近乎无损的剪枝，并在微调后具有良好的性能。我们的工作揭示了剪枝中“大小至上”的误区，并在理论和实践上拓展了基于重要性的剪枝前沿。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [500] [Practical Insights into Knowledge Distillation for Pre-Trained Models](https://arxiv.org/abs/2402.14922)
> *预训练模型知识蒸馏的实践见解*

*Norah Alballa, Ahmed M. Abdelmoniem, Marco Canini* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 知识蒸馏, 预训练模型, 联邦学习, 超参数调优, 分布式训练

**Comment:** 

> **TL;DR:** 本研究深入探讨了预训练模型中的知识蒸馏（KD）技术，通过比较多种KD方法并优化超参数，旨在为分布式和联邦学习环境提供实用的KD应用框架，以减少通信并加速训练。

**AI_Comments:** 该论文通过对多种知识蒸馏技术进行系统性的比较和超参数优化，为预训练模型在分布式和联邦学习环境中的应用提供了宝贵的实践见解。其创新之处在于填补了现有研究中对KD在这些复杂场景中应用理解的空白，并提供了可操作的最佳实践。该研究对于推动联邦学习等领域的效率和性能提升具有重要意义，尤其是在资源受限或隐私敏感的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 知识蒸馏（KD）在预训练模型中的应用是一个新兴领域，对分布式训练和联邦学习具有重要意义，因为这些环境可以减少通信需求并适应不同的模型架构。然而，尽管已经采用了多种KD方法，但对于KD在此类场景中的全面理解仍然不足，因此需要更深入的研究来填补这一空白。

**Method:** 本研究对多种知识蒸馏技术进行了广泛比较，包括标准KD、调优KD（通过优化温度和权重参数）、深度互学习和数据划分KD。研究在不同的数据分布策略下评估了这些方法，并通过广泛的网格搜索评估详细检查了超参数调优，以确定何时进行调整对于提高模型性能至关重要。

**Result:** 研究揭示了针对不同数据划分场景的最佳超参数设置，并探讨了知识蒸馏在通过最小化通信轮次和加速训练过程来改进联邦学习中的作用。

**Conclusion:** 本研究的发现填补了当前研究中的一个显著空白，为在协作和联邦学习框架中利用预训练模型中的知识蒸馏提供了一个实用框架。

> **ai_Abstract:** 本研究旨在弥补预训练模型中知识蒸馏（KD）应用理解不足的现状，特别是在分布式和联邦学习环境中。通过对标准KD、调优KD、深度互学习和数据划分KD等多种技术进行广泛比较，并结合超参数调优和网格搜索评估，论文识别了不同数据分布下的有效KD策略及最优超参数设置。研究还探讨了KD在联邦学习中减少通信和加速训练的潜力，为在协作学习框架中应用KD提供了实用的指导框架。

> **摘要翻译:** 本研究旨在增强预训练模型中的知识蒸馏（KD）过程，这是知识迁移中的一个新兴领域，对分布式训练和联邦学习环境具有重要意义。这些环境受益于减少的通信需求并适应各种模型架构。尽管已经采用了多种KD方法来在预训练模型之间传递知识，但对KD在这些场景中的应用缺乏全面的理解。我们的研究对多种KD技术进行了广泛比较，包括标准KD、调优KD（通过优化温度和权重参数）、深度互学习和数据划分KD。我们评估了这些方法在各种数据分布策略下的表现，以确定每种方法最有效的应用场景。通过对超参数调优的详细检查，并结合广泛的网格搜索评估，我们精确地指出了何时进行调整对于提高模型性能至关重要。本文阐明了针对不同数据划分场景的最佳超参数设置，并研究了KD在通过最小化通信轮次和加速训练过程来改进联邦学习中的作用。通过填补当前研究中的一个显著空白，我们的发现为在协作和联邦学习框架中利用预训练模型中的KD提供了一个实用框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [501] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
> *MolPIF：一种用于分子生成参数插值流模型*

*Yaowei Jin, Junjie Wang, Wenkai Xiang, Duanhua Cao, Dan Teng, Zhehuan Fan, Jiacheng Xiong, Xia Sheng, Chuanlong Zeng, Duo An, Mingyue Zheng, Shuangjia Zheng, Qian Shi* | **Category: cs.LG, q-bio.BM** | **Updated: 2025-07-22**

**Keywords:** 分子生成, 参数插值流, MolPIF, 药物发现, 贝叶斯流网络

**Comment:** 

> **TL;DR:** MolPIF提出了一种新颖的参数插值流模型，解决了现有贝叶斯流网络在分子生成中的局限性，并在药物设计中表现出优越性能。

**AI_Comments:** 这项工作通过引入参数插值流模型（PIF），为分子生成领域提供了一种新颖且有效的范式。其创新之处在于突破了传统贝叶斯流网络在灵活性上的限制，通过探索参数空间实现了更高效和适应性更强的分子生成。MolPIF在药物设计中的优越表现，凸显了其在加速药物发现方面的潜力，为未来的模型设计开辟了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的贝叶斯流网络（BFNs）在分子生成方面存在局限性，其基于贝叶斯推断的策略限制了设计更灵活的分布转换路径，难以适应多样化的数据分布和任务需求。此外，更简单、更高效的基于参数空间的模型潜力尚未被探索。

**Method:** 提出了一种新颖的参数插值流模型（PIF），并详细阐述了其理论基础、训练和推理过程。在此基础上，开发了用于基于结构的药物设计的MolPIF模型。

**Result:** MolPIF在多样化指标上表现出优于基线的性能。

**Conclusion:** 这项工作验证了基于参数空间的分子生成建模范式的有效性，并为模型设计提供了新的视角。

> **ai_Abstract:** 本文提出了一种新颖的参数插值流模型（PIF），并在此基础上开发了MolPIF，用于解决现有贝叶斯流网络在分子生成中灵活性不足的问题。MolPIF在基于结构的药物设计任务中，与基线模型相比，在多项指标上展现出卓越的性能，验证了基于参数空间的生成建模范式在分子领域的有效性。

> **摘要翻译:** 深度学习在分子生成方面的进展有望加速药物发现。贝叶斯流网络（BFNs）最近在各种化学任务中表现出令人印象深刻的性能，其成功常归因于在低方差参数空间中建模的范式。然而，基于贝叶斯推断的策略对设计更灵活的分布转换路径施加了限制，使其难以适应多样化的数据分布和多样的任务需求。此外，更简单、更高效的基于参数空间的模型潜力尚未被探索。为了解决这个问题，我们提出了一种新颖的参数插值流模型（命名为PIF），并提供了详细的理论基础、训练和推理过程。然后，我们开发了用于基于结构的药物设计的MolPIF，证明了其在与基线模型相比的各种指标上的优越性能。这项工作验证了基于参数空间的分子生成建模范式对分子的有效性，并为模型设计提供了新的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [504] [Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping](https://arxiv.org/abs/2507.16249)
> *用于样本高效深度神经网络映射的多智能体强化学习*

*Srivatsan Krishnan, Jason Jabbour, Dan Zhang, Natasha Jaques, Aleksandra Faust, Shayegan Omidshafiei, Vijay Janapa Reddi* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-22**

**Keywords:** 多智能体强化学习, 深度神经网络映射, 样本效率, 硬件加速器, 智能体聚类

**Comment:** 

> **TL;DR:** 本研究提出了一种分散式多智能体强化学习框架，通过智能体聚类显著提升了深度神经网络硬件映射的样本效率，并大幅优化了延迟和能耗。

**AI_Comments:** 该论文的创新点在于将多智能体强化学习引入深度神经网络硬件映射领域，并巧妙地通过智能体聚类算法解决了多智能体并行训练可能带来的低效率问题。这使得RL在面对复杂映射空间时能够更有效地探索，显著提升了样本效率和最终的硬件性能，为高性能加速器设计提供了新的优化途径。

<details>
  <summary>Details</summary>

**Motivation:** 将深度神经网络（DNNs）映射到硬件对于优化延迟、能耗和资源利用至关重要，是高性能加速器设计的基石。然而，由于映射空间庞大复杂，尽管强化学习（RL）是一种有前景的方法，但其有效性常受限于样本效率低下。

**Method:** 本研究提出了一种分散式多智能体强化学习（MARL）框架来解决样本效率问题。该框架通过在多个智能体之间分配搜索来加速探索。为避免并行训练多个智能体带来的低效率，研究引入了一种智能体聚类算法，根据相关性分析将相似的映射参数分配给相同的智能体。这实现了一个分散式、并行化的学习过程，显著提高了样本效率。

**Result:** 实验结果表明，与标准单智能体强化学习相比，本研究的MARL方法将样本效率提高了30-300倍，在相同样本条件下，延迟最高降低了32.61倍，能耗延迟积（EDP）最高降低了16.45倍。

**Conclusion:** 本研究提出的分散式多智能体强化学习框架通过引入智能体聚类算法，有效解决了深度神经网络硬件映射中强化学习的样本效率低下问题，并在延迟和能耗方面取得了显著优化。

> **ai_Abstract:** 本论文提出了一种分散式多智能体强化学习（MARL）框架，以解决深度神经网络硬件映射中强化学习的样本效率低下问题。通过将搜索任务分配给多个智能体并引入智能体聚类算法，该框架实现了高效的并行学习。实验证明，与单智能体RL相比，该方法将样本效率提升了30-300倍，并显著降低了延迟和能耗延迟积。

> **摘要翻译:** 将深度神经网络（DNNs）映射到硬件对于优化延迟、能耗和资源利用至关重要，是高性能加速器设计的基石。由于映射空间庞大复杂，强化学习（RL）已成为一种有前景的方法——但其有效性常受限于样本效率低下。我们提出了一种分散式多智能体强化学习（MARL）框架，旨在克服这一挑战。通过在多个智能体之间分配搜索，我们的框架加速了探索。为了避免并行训练多个智能体带来的低效率，我们引入了一种智能体聚类算法，根据相关性分析将相似的映射参数分配给相同的智能体。这实现了一个分散式、并行化的学习过程，显著提高了样本效率。实验结果表明，我们的MARL方法比标准单智能体RL提高了30-300倍的样本效率，在相同样本条件下，实现了高达32.61倍的延迟降低和16.45倍的能耗延迟积（EDP）降低。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [510] [Analogy making as amortised model construction](https://arxiv.org/abs/2507.16511)
> *类比作为摊销模型构建*

*David G. Nagy, Tingke Shen, Hanqi Zhou, Charley M. Wu, Peter Dayan* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 类比, 模型构建, 马尔可夫决策过程, 模块化重用, 计算成本摊销

**Comment:** RLC 2025 Finding the Frame Workshop

> **TL;DR:** 本文提出类比在人类灵活构建内部模型以应对新颖情况中扮演核心角色，通过重用过去经验的结构来摊销模型构建和规划的计算成本。

**AI_Comments:** 这篇论文提出了一种新颖的视角，将类比视为一种计算效率策略，用于在动态环境中构建和重用内部模型。通过将类比形式化为马尔可夫决策过程之间的部分同态，它为理解和实现人工智能系统中的灵活适应性提供了潜在的理论基础。其创新点在于将认知过程与计算成本摊销联系起来，并提出了模块化重用的概念。

<details>
  <summary>Details</summary>

**Motivation:** 人类需要灵活构建内部模型以应对新颖情况，这些模型既要足够忠实于环境以支持有限资源的规划，又要易于构建。

**Method:** 将类比形式化为马尔可夫决策过程之间的部分同态，并提出了一个框架，其中从先前构建中得出的抽象模块可作为新模型的组合构建块。

**Result:** 模块化重用允许在具有共享结构本质的领域中灵活适应策略和表示。

**Conclusion:** 类比在灵活构建内部模型中扮演核心角色，通过模块化重用过去经验的结构来摊销模型构建和规划的计算成本。

> **ai_Abstract:** 本文探讨了类比在人类灵活构建内部模型以应对新颖情况中的作用。作者提出，类比通过重用过去经验中与解决方案相关的结构，摊销了模型构建和规划的计算成本。他们将类比形式化为马尔可夫决策过程之间的部分同态，并提出了一个框架，其中抽象模块可作为新模型的组合构建块，从而实现在共享结构领域中策略和表示的灵活适应。

> **摘要翻译:** 人类灵活地构建内部模型以应对新颖情况。为了有用，这些内部模型必须足够忠实于环境，以便资源有限的规划能够产生足够的结果；同样，它们必须首先易于构建。我们认为类比在这些过程中扮演着核心角色，使智能体能够重用过去经验中与解决方案相关的结构，并摊销模型构建（解释）和规划的计算成本。将类比形式化为马尔可夫决策过程之间的部分同态，我们勾勒了一个框架，其中从先前解释中导出的抽象模块可作为新模块的可组合构建块。这种模块化重用允许在具有共享结构本质的领域中灵活适应策略和表示。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [516] [Learning Patient-Specific Spatial Biomarker Dynamics via Operator Learning for Alzheimer's Disease Progression](https://arxiv.org/abs/2507.16148)
> *通过算子学习预测阿尔茨海默病进展中的患者特异性空间生物标志物动态*

*Jindong Wang, Yutong Mao, Xiao Liu, Wenrui Hao* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 阿尔茨海默病, 算子学习, 个性化建模, 生物标志物, 疾病进展

**Comment:** 

> **TL;DR:** 本文提出了一种基于机器学习的算子学习框架，用于个性化建模阿尔茨海默病（AD）进展，该框架能够直接学习控制淀粉样蛋白、tau蛋白和神经退行性变生物标志物时空演变的患者特异性疾病算子，并在AD临床数据上实现了超过90%的高预测准确率。

**AI_Comments:** 该论文的创新点在于提出了基于算子学习的框架，能够直接学习患者特异性的疾病动态，而非依赖预设模型，这对于高度异质性的阿尔茨海默病具有重要意义。其结合数字孪生范式，为个性化预测和治疗干预模拟提供了强大的工具。高预测准确率也突显了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管阿尔茨海默病（AD）的治疗取得了进展，但能够准确预测个体化疾病轨迹的预测模型仍然有限，且AD进展和治疗反应存在显著异质性。

**Method:** 本文提出了一种基于机器学习的算子学习框架，用于个性化建模AD进展。该方法整合了纵向多模态成像、生物标志物和临床数据，并直接学习控制淀粉样蛋白、tau蛋白和神经退行性变生物标志物时空演变的患者特异性疾病算子。它利用拉普拉斯特征函数基构建了几何感知神经算子，能够捕获复杂的大脑动态，并嵌入到数字孪生范式中。

**Result:** 该方法应用于AD临床数据时，在多个生物标志物上的预测准确率超过90%，显著优于现有方法。

**Conclusion:** 这项工作提供了一个可扩展、可解释的平台，用于神经退行性疾病的精确建模和个性化治疗优化。

> **ai_Abstract:** 本文提出了一种创新的机器学习框架，即算子学习，用于个性化预测阿尔茨海默病（AD）的进展。该框架通过整合多模态纵向数据，直接学习患者特异性的疾病算子，以捕捉淀粉样蛋白、tau蛋白和神经退行性变生物标志物的复杂时空演变。该方法利用拉普拉斯特征函数基构建了几何感知神经算子，并将其嵌入到数字孪生范式中，从而实现个体化预测、治疗模拟和体外临床试验。在AD临床数据上的应用显示，该方法在多个生物标志物上的预测准确率超过90%，显著优于现有方法，为神经退行性疾病的精确建模和个性化治疗提供了可扩展且可解释的平台。

> **摘要翻译:** 阿尔茨海默病（AD）是一种复杂的、多因素的神经退行性疾病，在疾病进展和治疗反应方面存在显著的异质性。尽管最近在治疗方面取得了进展，但能够准确预测个体化疾病轨迹的预测模型仍然有限。本文提出了一种基于机器学习的算子学习框架，用于阿尔茨海默病进展的个性化建模，该框架整合了纵向多模态成像、生物标志物和临床数据。与具有预设动力学的传统模型不同，我们的方法直接学习控制淀粉样蛋白、tau蛋白和神经退行性变生物标志物时空演变的患者特异性疾病算子。我们使用拉普拉斯特征函数基构建了几何感知神经算子，能够捕获复杂的大脑动态。该框架嵌入在数字孪生范式中，能够实现个体化预测、治疗干预模拟和体外临床试验。应用于阿尔茨海默病临床数据时，我们的方法在多个生物标志物上的预测准确率超过90%，显著优于现有方法。这项工作为神经退行性疾病的精确建模和个性化治疗优化提供了一个可扩展、可解释的平台。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [526] [Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning](https://arxiv.org/abs/2507.15195)
> *图机器学习中基于网络控制理论和秩编码的特征构建*

*Anwar Said, Yifan Wei, Obaid Ullah Ahmad, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 图神经网络, 特征构建, 网络控制理论, 秩编码, 社交网络

**Comment:** 

> **TL;DR:** 本文提出利用网络控制理论中的平均可控性概念和新颖的秩编码方法来构建富有表达力的节点特征，以提高图神经网络（GNN）在社交网络分类任务中的性能，尤其是在节点特征稀缺的情况下。

**AI_Comments:** 该论文提出了一种创新方法来解决GNN应用中常见的局限性，即缺乏表达性节点特征，尤其是在社交网络等敏感领域。通过利用网络控制理论中的平均可控性概念并引入新颖的秩编码方法，它提供了一种从网络拓扑本身构建有意义特征的原则性方法。所展示的定量改进（例如ROC AUC的提高）突显了其方法在固有特征稀缺时提高GNN性能的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNN）的性能严重依赖于节点特征的表达能力。然而，在社交网络中，由于隐私限制或缺乏固有属性，节点特征通常不可用，这使得GNN难以实现最佳性能。

**Method:** 1. 引入平均可控性及其他中心性度量（NCT-EFA）作为捕获网络拓扑关键方面的节点级别度量。2. 开发一种秩编码方法，将平均可控性或任何其他图论度量转换为固定维度的特征空间，以改善特征表示。

**Result:** 将平均可控性纳入特征空间显著提高了GNN的性能。所提出的秩编码方法优于传统的独热度编码，例如在使用GraphSAGE在GitHub Stargazers数据集上将ROC AUC从68.7%提高到73.9%。

**Conclusion:** 本文提出的平均可控性概念和秩编码方法能够有效生成富有表达力且高效的节点表示，显著改善了GNN在社交网络分类任务中的性能，尤其是在缺乏固有特征的情况下。

> **ai_Abstract:** 本文旨在解决图神经网络（GNN）在社交网络分类任务中因节点特征稀缺而性能受限的问题。研究提出两种新颖的特征构建策略：一是利用网络控制理论中的平均可控性及其他中心性度量（NCT-EFA）作为节点级特征；二是开发一种秩编码方法，将这些度量转换为固定维度的表达性特征表示。通过在多个GNN模型和数据集上的广泛评估，结果表明这些方法显著提升了GNN的性能，并且优于传统编码技术，有效生成了更高效的节点特征。

> **摘要翻译:** 在本文中，我们利用图中的平均可控性概念，结合一种新颖的秩编码方法，以提高图神经网络（GNN）在社交网络分类任务中的性能。GNN在各种基于网络的学习应用中已被证明非常有效，并且需要某种形式的节点特征才能发挥作用。然而，它们的性能受到这些特征表达能力的严重影响。在社交网络中，由于隐私限制或缺乏固有属性，节点特征通常不可用，这使得GNN难以实现最佳性能。为了解决这一限制，我们提出了两种构建富有表达力节点特征的策略。首先，我们引入了平均可控性以及其他中心性度量（表示为NCT-EFA）作为节点级别的度量，它们能够捕获网络拓扑的关键方面。在此基础上，我们开发了一种秩编码方法，将平均可控性或任何其他图论度量转换为固定维度的特征空间，从而改善特征表示。我们使用六个基准GNN模型在四个社交网络数据集上进行了广泛的数值评估，以比较不同的节点特征构建方法。我们的结果表明，将平均可控性纳入特征空间显著提高了GNN的性能。此外，所提出的秩编码方法优于传统的独热度编码，在使用GraphSAGE在GitHub Stargazers数据集上将ROC AUC从68.7%提高到73.9%，这突显了其在生成富有表达力和高效节点表示方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [530] [Learning Neural Differential Algebraic Equations via Operator Splitting](https://arxiv.org/abs/2403.12938)
> *通过算子分裂学习神经微分代数方程*

*James Koch, Madelyn Shapiro, Himanshu Sharma, Draguna Vrabie, Jan Drgona* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 微分代数方程, 算子分裂, 机器学习, 时间序列数据, 系统建模

**Comment:** Updated version of the article now includes problem statement

> **TL;DR:** 本文提出了一种基于算子分裂（OS）的数值积分方案，用于从时间序列数据中学习微分代数方程（DAEs）的未知分量，并展示了其在系统建模任务中的鲁棒性和外推能力。

**AI_Comments:** 该论文的创新点在于将算子分裂（Operator Splitting）技术应用于神经微分代数方程的学习，这为从时间序列数据中识别复杂动态系统的未知组件提供了一种新颖且有效的方法。其在处理隐式关系和守恒定律的系统方面具有重要意义。所展示的对噪声的鲁棒性和外推能力是该方法的显著优势，表明其在实际工程和科学问题中具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 微分代数方程（DAEs）描述了受微分和代数约束的系统的时间演化，其中包含组件之间隐式关系（如守恒定律）的系统尤其受关注。本研究的动机是从时间序列数据中学习DAEs的未知分量。

**Method:** 本文提出了一种基于算子分裂（OS）的数值积分方案，即OS-based时间步进方案，用于学习DAEs的未知分量。该方案适用于相关的系统理论数据驱动建模任务。

**Result:** 该方法在实验中展示了对噪声的鲁棒性以及外推能力。具体示例包括：(i) 罐歧管动力学的逆问题，以及 (ii) 泵、罐和管道网络的差异建模。实验证明该方法能够学习系统组件的行为及其相互作用的物理原理，并区分数据趋势和系统中包含的机械关系。

**Conclusion:** 所提出的基于算子分裂的时间步进方案适用于学习微分代数方程的未知分量，并在系统理论数据驱动建模任务中表现出良好的鲁棒性和外推能力。

> **ai_Abstract:** 本文介绍了一种基于算子分裂（OS）的数值积分方案，旨在从时间序列数据中学习微分代数方程（DAEs）的未知部分。该OS-based时间步进方案被证明适用于系统理论数据驱动建模任务，并通过罐歧管动力学逆问题和泵网络差异建模等示例进行了验证。实验结果表明，该方法对噪声具有鲁棒性，并具备出色的外推能力，能够学习系统组件行为、物理相互作用，并区分数据趋势与内在机制。

> **摘要翻译:** 微分代数方程（DAEs）描述了受微分和代数约束的系统的时间演化。其中，包含其组件之间隐式关系（如守恒定律）的系统尤其受关注。本文提出了一种算子分裂（OS）数值积分方案，用于从时间序列数据中学习DAEs的未知分量。在这项工作中，我们展示了所提出的基于OS的时间步进方案适用于相关的系统理论数据驱动建模任务。所呈现的示例包括 (i) 罐歧管动力学的逆问题和 (ii) 泵、罐和管道网络的差异建模。我们的实验证明了所提出方法对噪声的鲁棒性以及外推能力，能够 (i) 学习系统组件的行为及其相互作用的物理原理，并 (ii) 区分数据趋势和系统中包含的机械关系。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [539] [Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning](https://arxiv.org/abs/2507.16302)
> *面向下游微调的扩散模型弹性安全驱动遗忘*

*Boheng Li, Renjie Gu, Junjie Wang, Leyi Qi, Yiming Li, Run Wang, Zhan Qin, Tianwei Zhang* | **Category: cs.LG, cs.AI, cs.CR, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 扩散模型, 遗忘, 安全性, 微调, 弹性

**Comment:** Preprint version. Under review

> **TL;DR:** 文本到图像扩散模型存在不安全行为，现有安全驱动遗忘方法在下游微调后效果不佳。本文提出ResAlign框架，通过Moreau包络重构和元学习策略，显著提高了模型在下游微调后保持安全性的能力，同时保留了良好的生成能力。

**AI_Comments:** 该论文解决了安全驱动遗忘方法在实际应用中面临的一个关键挑战，即其对下游微调的脆弱性。通过引入Moreau包络重构进行隐式优化和元学习策略来模拟多样化的微调场景，ResAlign在技术上展现了创新性，显著提升了扩散模型安全遗忘的鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）扩散模型在个性化应用中广泛使用，但它们常常从有毒的预训练数据中继承不安全行为，引发安全担忧。尽管现有的安全驱动遗忘方法在抑制模型毒性方面取得进展，但它们对下游微调表现出脆弱性，即使在良性数据集上微调，也无法有效保持安全性。

**Method:** 本文提出了ResAlign，一个增强了抗下游微调弹性的安全驱动遗忘框架。它通过基于Moreau包络的重构将下游微调建模为一个隐式优化问题，从而实现高效的梯度估计，以最小化有害行为的恢复。此外，还引入了一种元学习策略来模拟多样化的微调场景分布，以提高泛化能力。

**Result:** 在各种数据集、微调方法和配置上进行的广泛实验表明，ResAlign在下游微调后保持安全性方面始终优于先前的遗忘方法，同时能够很好地保留良性生成能力。

**Conclusion:** ResAlign框架有效解决了扩散模型中安全驱动遗忘方法在面对下游微调时的脆弱性问题，提供了一种更具弹性的解决方案，以确保个性化应用的安全性。

> **ai_Abstract:** 本文旨在解决文本到图像扩散模型中安全驱动遗忘方法在下游微调后失效的问题。研究发现，现有方法即使在良性数据集上微调也难以保持安全性。为此，本文提出ResAlign框架，通过将下游微调建模为基于Moreau包络的隐式优化问题，实现了有害行为恢复的有效梯度估计，并结合元学习策略以提高泛化能力。实验证明，ResAlign在下游微调后保持模型安全性方面显著优于现有方法，同时不牺牲良性生成能力。

> **摘要翻译:** 文本到图像（T2I）扩散模型在图像生成质量方面取得了令人印象深刻的成就，并越来越多地被微调用于个性化应用。然而，这些模型经常从有毒的预训练数据中继承不安全行为，引发了日益增长的安全担忧。尽管最近的安全驱动遗忘方法在抑制模型毒性方面取得了有希望的进展，但它们被发现对下游微调是脆弱的，我们揭示了最先进的方法即使在完全良性的数据集上进行微调，也大多无法保持其有效性。为了缓解这个问题，本文提出了ResAlign，一个具有增强的抗下游微调弹性的安全驱动遗忘框架。通过将下游微调建模为一个隐式优化问题，并采用基于Moreau包络的重构，ResAlign能够进行高效的梯度估计，以最小化有害行为的恢复。此外，还提出了一种元学习策略来模拟多样化的微调场景分布，以提高泛化能力。对各种数据集、微调方法和配置进行的广泛实验表明，ResAlign在下游微调后保持安全性方面始终优于先前的遗忘方法，同时很好地保留了良性生成能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [556] [FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning](https://arxiv.org/abs/2507.15470)
> *FedMultiEmo：基于多模态联邦学习的实时情感识别*

*Baran Can Gül, Suraksha Nadig, Stefanos Tziampazis, Nasser Jazdi, Michael Weyrich* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 情感识别, 联邦学习, 多模态, 隐私保护, 车载系统

**Comment:** Preprint version. Accepted for publication at IEEE ICECCME 2025

> **TL;DR:** FedMultiEmo是一个隐私保护框架，通过多模态联邦学习实现实时车内情感识别，解决了模态脆弱性、生理变异性和隐私风险等问题，并在不共享原始数据的情况下达到了与集中式基线相当的性能。

**AI_Comments:** FedMultiEmo的创新之处在于其将多模态融合与联邦学习相结合，有效解决了情感识别中的隐私和实用性问题。通过在边缘设备上进行训练并融合不同模态的数据，它在保护用户隐私的同时，提升了识别的鲁棒性和准确性。这种分布式、隐私保护的架构对于未来车载系统和智能健康监测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在车内情感识别中，实际部署面临三大挑战：1) 模态脆弱性，如光照差和遮挡会降低视觉方法的性能；2) 生理变异性，不同个体的心率和皮肤电导模式不同；3) 隐私风险，集中式训练需要传输敏感数据。

**Method:** 本文提出了FedMultiEmo，一个隐私保护框架，在决策层面融合了两种互补模态：通过卷积神经网络从面部图像中提取的视觉特征，以及通过随机森林分类的生理线索（心率、皮电活动和皮肤温度）。FedMultiEmo包含三个关键要素：1) 采用多数投票融合的多模态联邦学习管道；2) 基于树莓派客户端和Flower服务器的端到端边缘到云原型；3) 根据本地数据量加权客户端更新的个性化联邦平均方案。

**Result:** 在FER2013和自定义生理数据集上进行评估，联邦卷积神经网络达到77%的准确率，随机森林达到74%，它们的融合达到87%，与集中式基线匹配，同时所有原始数据保持在本地。开发系统在18轮内收敛，平均每轮时间为120秒，每个客户端的内存占用低于200MB。

**Conclusion:** FedMultiEmo的结果表明，它为汽车环境中实时、隐私感知的情感识别提供了一种实用方法。

> **ai_Abstract:** 本文提出了FedMultiEmo，一个创新的多模态联邦学习框架，旨在解决车内情感识别中的模态脆弱性、生理变异性和数据隐私问题。该框架在决策层面融合了面部视觉特征（通过CNN）和生理线索（通过随机森林），并采用个性化联邦平均方案。实验结果表明，FedMultiEmo在不共享原始数据的情况下，通过多模态融合达到了与集中式系统相当的准确率，并展示了其在实时、隐私保护的汽车情感识别方面的实用性。

> **摘要翻译:** 车内情感识别是自适应驾驶辅助系统以及最终乘员安全的基础。然而，实际部署受到以下因素的阻碍：(i) 模态脆弱性——光照差和遮挡会降低基于视觉方法的性能；(ii) 生理变异性——心率和皮肤电导模式因人而异；(iii) 隐私风险——集中式训练需要传输敏感数据。为了解决这些挑战，我们提出了FedMultiEmo，一个隐私保护框架，它在决策层面融合了两种互补模态：通过卷积神经网络从面部图像中提取的视觉特征，以及通过随机森林分类的生理线索（心率、皮电活动和皮肤温度）。FedMultiEmo建立在三个关键要素之上：(1) 采用多数投票融合的多模态联邦学习管道；(2) 基于树莓派客户端和Flower服务器的端到端边缘到云原型；(3) 根据本地数据量加权客户端更新的个性化联邦平均方案。在FER2013和自定义生理数据集上进行评估，联邦卷积神经网络达到77%的准确率，随机森林达到74%，它们的融合达到87%，与集中式基线匹配，同时所有原始数据保持在本地。开发系统在18轮内收敛，平均每轮时间为120秒，每个客户端的内存占用低于200MB。这些结果表明，FedMultiEmo为汽车环境中实时、隐私感知的情感识别提供了一种实用方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [559] [confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods](https://arxiv.org/abs/2507.16533)
> *confopt：一个用于实现和评估基于梯度的One-Shot NAS方法的库*

*Abhash Kumar Jha, Shakiba Moradian, Arjun Krishnakumar, Martin Rapp, Frank Hutter* | **Category: cs.LG, cs.AI, 68T01, I.2.6** | **Updated: 2025-07-22**

**Keywords:** 神经网络架构搜索, one-shot NAS, 梯度优化, 基准测试, confopt

**Comment:** AutoML 25 ABCD Track

> **TL;DR:** confopt是一个库，旨在解决梯度one-shot NAS方法评估过度依赖单一基准和实现碎片化的问题，并通过新基准和评估协议揭示了现有评估方法的缺陷。

**AI_Comments:** 这篇论文通过开发一个统一的库，有效解决了梯度one-shot NAS领域长期存在的评估标准碎片化和基准过度依赖问题。其创新之处在于不仅提供了一个工具，更通过该工具揭示了现有评估范式中的深层缺陷，这对于推动该领域向更严谨、更可信赖的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 梯度one-shot NAS方法在探索架构空间方面显著降低了成本，但面临两大挑战：1) 对DARTS基准的过度依赖导致饱和，改进效果不明显；2) 实现分散在不同代码库中，使得公平比较和进一步开发变得复杂。

**Method:** 论文引入了Configurable Optimizer (confopt)，一个可扩展的库，旨在简化基于梯度的one-shot NAS方法的开发和评估。confopt提供了一个最小API，便于集成新的搜索空间，并支持将NAS优化器分解为核心组件。该框架被用于创建一系列新的基于DARTS的基准，并结合新的评估协议来揭示现有评估方法的缺陷。

**Result:** 通过使用confopt框架，创建了一套新的基于DARTS的基准和一种新颖的评估协议，揭示了当前基于梯度的one-shot NAS方法评估方式中的一个关键缺陷。

**Conclusion:** 论文通过引入confopt库，不仅提供了一个统一的平台来促进基于梯度的one-shot NAS方法的开发和评估，而且通过新的基准和评估协议，批判性地指出了当前该领域评估方法存在的根本性问题。

> **ai_Abstract:** 本文介绍了confopt，一个可扩展的库，旨在解决梯度one-shot NAS方法在评估上面临的基准过度依赖和实现碎片化问题。confopt提供了一个统一的平台，简化了新搜索空间的集成和优化器组件的分解。通过利用confopt，研究人员创建了一套新的DARTS基准和评估协议，并以此揭示了当前梯度one-shot NAS评估方法的一个关键缺陷。

> **摘要翻译:** 梯度one-shot神经网络架构搜索（NAS）显著降低了探索具有离散设计选择（例如在模型中选择操作）的架构空间的成本。然而，该领域面临两大主要挑战。首先，尽管存在其他可用基准，但基于梯度的NAS方法的评估严重依赖DARTS基准。这种过度依赖导致了饱和，报告的改进通常落在噪声范围内。其次，基于梯度的one-shot NAS方法的实现分散在不同的代码库中，这使得公平和可重现的比较以及进一步的开发变得复杂。在本文中，我们介绍了Configurable Optimizer (confopt)，一个可扩展的库，旨在简化基于梯度的one-shot NAS方法的开发和评估。Confopt提供了一个最小化的API，使用户可以轻松集成新的搜索空间，同时还支持将NAS优化器分解为核心组件。我们使用此框架创建了一套新的基于DARTS的基准，并结合一种新颖的评估协议，揭示了当前基于梯度的one-shot NAS方法评估方式中的一个关键缺陷。代码可在https://github.com/automl/ConfigurableOptimizer找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [560] [Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers](https://arxiv.org/abs/2405.17527)
> *Unisolver：PDE条件Transformer是通用偏微分方程求解器*

*Hang Zhou, Yuezhou Ma, Haixu Wu, Haowen Wang, Mingsheng Long* | **Category: cs.LG, cs.AI, cs.NA, math.NA** | **Updated: 2025-07-22**

**Keywords:** 神经PDE求解器, Transformer, 通用求解器, 偏微分方程, 泛化能力

**Comment:** 

> **TL;DR:** Unisolver是一个新型Transformer模型，通过条件化偏微分方程组件，旨在成为一个通用的神经偏微分方程求解器，解决了现有神经求解器泛化性差的问题，并在多个大型基准测试中达到了最先进的性能。

**AI_Comments:** Unisolver的创新之处在于其将PDE组件作为条件引入Transformer模型，这使得模型能够处理更广泛的PDE类型，从而实现了通用性。这种方法克服了传统神经PDE求解器泛化能力差的局限性，为PDE求解领域提供了一个更实用、更强大的工具。将物理洞察与深度学习模型相结合是其成功的关键。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经偏微分方程（PDE）求解器主要局限于解决少数特定PDE实例，例如具有有限系数的特定方程，这限制了它们对多样化PDE的泛化能力，使其无法成为实用的数值求解器替代模型。

**Method:** Unisolver是一个新型Transformer模型，它通过对PDE求解过程的理论分析，并受到PDE数学结构（解由方程符号和边界条件等一系列PDE组件决定）的启发，定义了一套完整的PDE组件。这些组件被灵活地嵌入为Transformer PDE求解器的域级和点级深度条件。该模型在多样化的数据上进行训练，并以多样化的PDE为条件。

**Result:** Unisolver在三个具有挑战性的大规模基准测试中取得了持续的最先进性能，显示出令人印象深刻的性能和泛化能力。

**Conclusion:** Unisolver通过将物理洞察与Transformer的最新进展相结合，成功构建了一个通用神经偏微分方程求解器，克服了现有方法的泛化性限制，并在多个复杂任务中展现出卓越的性能和普适性。

> **ai_Abstract:** 本文提出了Unisolver，一个基于Transformer的新型神经偏微分方程（PDE）求解器，旨在克服现有神经求解器在泛化性上的限制。Unisolver通过对PDE求解过程的理论分析，将PDE组件（如方程符号和边界条件）作为深度条件嵌入Transformer模型中。该模型在多样化数据上训练，并能处理多种PDE。实验结果表明，Unisolver在三个大型基准测试中达到了最先进的性能，展现出强大的泛化能力和卓越的性能。

> **摘要翻译:** 深度模型最近已成为解决偏微分方程（PDEs）的有前景工具，被称为神经PDE求解器。虽然通过模拟数据或物理信息损失训练的神经求解器可以很好地解决PDEs，但它们主要局限于少数PDE实例，例如具有有限系数的特定方程。这限制了它们对多样化PDE的泛化能力，阻止它们成为实用的数值求解器替代模型。在本文中，我们提出了Unisolver，一个新型Transformer模型，在多样化数据上训练并以多样化PDE为条件，旨在成为一个能够解决广泛PDE的通用神经PDE求解器。Unisolver并非纯粹地扩展数据和参数，而是源于对PDE求解过程的理论分析。受PDE数学结构（PDE解根本上由一系列PDE组件如方程符号和边界条件决定）的启发，我们定义了一套完整的PDE组件，并灵活地将它们嵌入为Transformer PDE求解器的域级和点级深度条件。Unisolver将物理洞察与Transformer的最新进展相结合，在三个具有挑战性的大规模基准测试中取得了持续的最先进性能，显示出令人印象深刻的性能和泛化能力。代码可在https://github.com/thuml/Unisolver获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [563] [Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction](https://arxiv.org/abs/2507.15862)
> *量化整体评估：一种多模态的大学招生预测方法*

*Jun-Wei Zeng, Jerry Shen* | **Category: cs.LG, cs.CY** | **Updated: 2025-07-12**

**Keywords:** 大学招生, 整体评估, 多模态, 机器学习, 可解释AI

**Comment:** 

> **TL;DR:** 本文提出CAPS，一个多模态框架，用于量化和解释大学招生的整体评估，通过分解申请人资料为学业成绩、论文质量和课外参与三个可解释的组成部分，并利用Transformer、LLM和XGBoost进行预测，解决了传统评估的不透明和不一致问题。

**AI_Comments:** 本文的创新点在于提出了一个量化和解释大学招生整体评估的多模态框架CAPS，将复杂的评估过程分解为可解释的组件。其重要性在于通过结合先进的机器学习技术（Transformer, LLM, XGBoost），旨在提高招生过程的透明度、一致性和公平性，这对于解决传统招生评估中长期存在的问题具有实际意义。在局限性方面，虽然使用了“合成但真实”的数据集，但实际招生数据的复杂性和多样性可能带来新的挑战，需要进一步验证其在真实世界数据上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 传统的大学招生整体评估存在不透明、不一致以及给申请人带来焦虑等关键局限性。本文旨在通过量化建模来解决这些问题，从而实现更公平、更数据驱动的招生实践。

**Method:** 本文引入了综合申请人档案分数（CAPS），这是一个新颖的多模态框架。CAPS将申请人资料分解为三个可解释的组成部分：标准化学业分数（SAS）、论文质量指数（EQI）和课外影响分数（EIS）。该框架利用基于Transformer的语义嵌入、LLM评分和XGBoost回归来提供透明且可解释的评估。

**Result:** 在合成但真实的数据集上进行了实验，结果显示出强大的性能：EQI预测的R^2达到0.80，分类准确率超过75%，宏F1分数为0.69，加权F1分数为0.74。

**Conclusion:** CAPS框架通过提供透明和可解释的评估，解决了传统整体评估的不透明、不一致和焦虑等问题，为更公平、更数据驱动的招生实践铺平了道路。

> **ai_Abstract:** 本文提出了一种名为综合申请人档案分数（CAPS）的新型多模态框架，旨在量化和解释大学招生的整体评估。CAPS将申请人资料分解为学业成绩、论文质量和课外参与三个可解释的维度，并结合了Transformer语义嵌入、LLM评分和XGBoost回归技术。该方法旨在提供透明、可解释且与人类判断一致的评估，实验结果显示其在预测性能上表现良好，并有望解决传统整体评估中存在的透明度、一致性及申请人焦虑等问题，从而推动更公平、数据驱动的招生实践。

> **摘要翻译:** 本文介绍了综合申请人档案分数（CAPS），这是一个新颖的多模态框架，旨在定量建模和解释大学招生的整体评估。CAPS将申请人资料分解为三个可解释的组成部分：学业成绩（标准化学业分数，SAS）、论文质量（论文质量指数，EQI）和课外参与（课外影响分数，EIS）。CAPS利用基于Transformer的语义嵌入、LLM评分和XGBoost回归，提供与人类判断一致的透明和可解释的评估。在合成但真实的数据集上进行的实验表明其性能强大，EQI预测的R^2达到0.80，分类准确率超过75%，宏F1分数为0.69，加权F1分数为0.74。CAPS解决了传统整体评估中的关键局限性——特别是申请人面临的不透明性、不一致性和焦虑——从而为更公平和数据驱动的招生实践铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [564] [LLM Data Selection and Utilization via Dynamic Bi-level Optimization](https://arxiv.org/abs/2507.16178)
> *LLM数据选择与利用：基于动态双层优化*

*Yang Yu, Kai Han, Hang Zhou, Yehui Tang, Kaiqi Huang, Yunhe Wang, Dacheng Tao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 数据选择, LLM训练, 动态加权, 双层优化, 数据偏好

**Comment:** The 42nd International Conference on Machine Learning (ICML 2025)

> **TL;DR:** 本文提出数据加权模型（DWM），通过动态双层优化调整数据权重，提高LLM训练效率和性能。

**AI_Comments:** 该论文的创新点在于提出了一个动态的数据加权模型，并通过双层优化框架使其能够适应模型训练过程中的数据偏好变化，这与现有静态数据选择方法形成对比。其重要性在于能够提高LLM训练效率并降低计算成本，同时为理解模型训练行为提供了新的见解。

<details>
  <summary>Details</summary>

**Motivation:** 当前数据选择方法主要依赖于静态的、与训练无关的标准，未能考虑到动态的模型训练和数据交互，无法充分发挥高质量数据在提高训练效率和降低计算成本方面的潜力。

**Method:** 本文提出一种新的数据加权模型（DWM），通过双层优化框架来调整每个批次中选定数据的权重，以实现LLM训练期间的动态数据利用，从而更好地捕捉训练模型的动态数据偏好。

**Result:** DWM提升了使用随机选择数据训练的模型的性能；学习到的加权模型可以转移以增强其他数据选择方法和不同大小的模型；进一步分析了模型的数据偏好在整个训练过程中如何演变，提供了新的见解。

**Conclusion:** DWM通过动态数据加权有效提升了LLM训练效率和模型性能，并且其学习到的加权模型具有良好的泛化能力，为理解模型训练期间的数据偏好演变提供了新视角。

> **ai_Abstract:** 本文提出了一种名为DWM（数据加权模型）的新方法，旨在通过动态调整批次内数据权重来优化大型语言模型（LLM）的训练过程。DWM采用双层优化框架，以更好地捕捉训练模型的数据偏好。实验证明，DWM能有效提升模型性能，其学习到的加权模型具有良好的可迁移性，并为理解模型训练期间的数据偏好演变提供了新视角。

> **摘要翻译:** 标题：LLM数据选择与利用：基于动态双层优化

摘要：尽管大规模训练数据是开发强大的大型语言模型（LLM）的基础，但策略性地选择高质量数据已成为提高训练效率和降低计算成本的关键方法。当前的数据选择方法主要依赖于静态的、与训练无关的标准，未能考虑到动态的模型训练和数据交互。在本文中，我们提出了一种新的数据加权模型（DWM），以调整每个批次中选定数据的权重，从而在LLM训练期间实现动态数据利用。特别是，为了更好地捕捉训练模型的动态数据偏好，我们实施了一个双层优化框架来更新加权模型。我们的实验表明，DWM增强了使用随机选择数据训练的模型的性能，并且学习到的加权模型可以转移以增强其他数据选择方法和不同大小的模型。此外，我们进一步分析了模型的数据偏好在整个训练过程中如何演变，为模型在训练期间的数据偏好提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [567] [Accurate and Efficient Fine-Tuning of Quantized Large Language Models Through Optimal Balance](https://arxiv.org/abs/2407.17029)
> *通过最佳平衡对量化大型语言模型进行准确高效的微调*

*Ao Shen, Qiang Wang, Zhiquan Lai, Xionglve Li, Dongsheng Li* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 量化LLM, 微调, LoRA, Q-BLoRA, QA-BLoRA

**Comment:** 

> **TL;DR:** 本文提出了Q-BLoRA和QA-BLoRA，旨在通过平衡低秩适应来解决量化大型语言模型微调中的性能下降和欠拟合问题，实现了最先进的准确性和高效的低精度部署。

**AI_Comments:** 本文识别并解决了量化大型语言模型微调中LoRA的“不平衡”问题，即适配器复杂性与可训练性之间的矛盾，这一洞察是其创新之处。通过提出Q-BLoRA和QA-BLoRA，该研究不仅提升了量化LLM微调的准确性，还实现了高效的低精度部署，对于推动LLM在资源受限环境下的应用具有重要意义。其方法易于实现，且效果显著，有望成为未来量化微调的标准实践。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)的参数量巨大，使得微调极具挑战性，严重限制了其应用和部署。现有结合参数量化和低秩适应(LoRA)的解决方案虽然减少了内存使用，但会导致性能下降。此外，将微调后的模型转换为低精度表示会进一步降低性能。作者发现，在使用LoRA微调量化LLMs时存在不平衡：适配器输入输出过于复杂与适配器有效可训练性低，导致微调期间欠拟合。

**Method:** 本文提出了两种方法：1. Quantized LLMs fine-tuning with Balanced Low-Rank Adaptation (Q-BLoRA)：通过简化适配器的输入和输出，同时增加适配器的秩来缓解微调期间的欠拟合。2. Quantization-Aware fine-tuning with Balanced Low-Rank Adaptation (QA-BLoRA)：与块级量化对齐，并基于Q-BLoRA的参数合并，促进低秩适应的量化感知微调，从而能够直接生成低精度推理模型。

**Result:** Q-BLoRA与基线和其他变体相比，始终实现了最先进的准确性。QA-BLoRA能够直接生成低精度推理模型，与其他低精度模型相比，其性能有显著提升。Q-BLoRA和QA-BLoRA的有效性已在各种模型和场景中得到验证。

**Conclusion:** Q-BLoRA和QA-BLoRA都易于实现，并提供了显著的优化。它们有效地解决了量化大型语言模型微调中的性能下降和欠拟合问题，实现了高准确性和高效的低精度部署。

> **ai_Abstract:** 本文针对量化大型语言模型（LLMs）微调中存在的性能下降和欠拟合问题，提出了一种新的微调范式。现有方法结合量化和LoRA，虽减少内存但牺牲性能。作者指出，问题在于LoRA适配器在量化LLM微调中存在输入输出过于复杂与有效可训练性低的失衡，导致欠拟合。为解决此问题，论文提出了Q-BLoRA，通过简化适配器输入输出并增加秩来缓解欠拟合，实现了最先进的准确性。此外，为支持低精度部署，提出了QA-BLoRA，它与块级量化对齐，并基于Q-BLoRA的参数合并，实现量化感知微调，从而直接生成性能显著提升的低精度推理模型。两种方法均易于实现，并在多个模型和场景中验证了其有效性。

> **摘要翻译:** 大型语言模型（LLM）在各个领域都表现出了令人印象深刻的性能。然而，庞大的模型参数数量使得微调具有挑战性，严重限制了它们的应用和部署。现有解决方案将参数量化与低秩适应（LoRA）相结合，减少了内存使用，但导致了性能下降。此外，将微调后的模型转换为低精度表示会进一步降低性能。在本文中，我们发现了使用LoRA微调量化LLM时存在的不平衡：适配器输入和输出过于复杂，而适配器的有效可训练性较低，导致微调期间的欠拟合。因此，我们提出了采用平衡低秩适应的量化LLM微调（Q-BLoRA），它简化了适配器的输入和输出，同时增加了适配器的秩以缓解微调期间的欠拟合。为了实现低精度部署，我们提出了采用平衡低秩适应的量化感知微调（QA-BLoRA），它与块级量化对齐，并基于Q-BLoRA的参数合并，促进低秩适应的量化感知微调。Q-BLoRA和QA-BLoRA都易于实现并提供以下优化：（i）Q-BLoRA与基线和其他变体相比，始终实现了最先进的准确性；（ii）QA-BLoRA能够直接生成低精度推理模型，与其它低精度模型相比，其性能有显著提升。我们在各种模型和场景中验证了Q-BLoRA和QA-BLoRA的有效性。代码将发布在 https://github.com/xiaocaigou/qbaraqahira

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [571] [Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection](https://arxiv.org/abs/2504.05119)
> *在嵌入式DNN中通过激活函数选择平衡鲁棒性与效率*

*Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe* | **Category: cs.LG, cs.AI, cs.AR, cs.CV, eess.IV** | **Updated: 2025-07-22**

**Keywords:** 软错误, 深度神经网络, 激活函数, 鲁棒性, 嵌入式系统

**Comment:** 

> **TL;DR:** 本文探讨了在安全关键嵌入式深度神经网络中，通过选择激活函数来平衡软错误鲁棒性与效率的方法，评估了有界激活函数对模型准确性、可压缩性和计算负载的影响。

**AI_Comments:** 本文解决了嵌入式人工智能，尤其是在安全关键领域中一个至关重要的实际问题。其创新之处在于强调了激活函数在平衡鲁棒性、效率和可压缩性方面的关键作用，这超越了其对准确性的传统影响。鉴于先进硬件中软错误日益普遍，这项研究具有重要意义。采用技术无关的方法也增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 基于机器学习的嵌入式系统，尤其是在航空航天和自动驾驶等安全关键应用中，必须对软错误引起的扰动具有鲁棒性。随着电子设备微型化，软错误问题日益突出。虽然压缩技术会影响DNN的鲁棒性，但激活函数（AFs）的选择，一个常被忽视的因素，也显著影响模型的准确性、可训练性、可压缩性和错误弹性。因此，研究如何在嵌入式DNN中通过激活函数选择来平衡鲁棒性和效率变得至关重要。

**Method:** 本文探讨了使用有界激活函数来增强深度神经网络对抗参数扰动的鲁棒性。研究以技术无关的方法评估了这些激活函数对模型准确性、可压缩性和计算负载的影响。研究重点是为高光谱图像语义分割开发的编码器-解码器卷积模型，并应用于自动驾驶系统。实验在AMD-Xilinx的KV260 SoM上进行。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文关注安全关键应用中嵌入式深度神经网络（DNN）的软错误鲁棒性问题。研究指出，除了压缩技术外，激活函数（AFs）的选择是影响模型准确性、可训练性、可压缩性和错误弹性的一个常被忽视的关键因素。该研究旨在通过探索有界激活函数的使用来增强模型对抗参数扰动的鲁棒性，并以技术无关的方式评估其对模型准确性、可压缩性和计算负载的影响，特别是在用于高光谱图像语义分割的编码器-解码器卷积模型中进行验证。

> **摘要翻译:** 基于机器学习的嵌入式系统，应用于航空航天和自动驾驶等安全关键领域，必须对软错误引起的扰动具有鲁棒性。随着晶体管几何尺寸的缩小和电压的降低，现代电子设备越来越容易受到背景辐射的影响，增加了对软错误产生故障的担忧。深度神经网络（DNN）对这些错误的弹性不仅取决于目标设备技术，还取决于模型结构以及其参数的数值表示和算术精度。剪枝和量化等压缩技术用于减少内存占用和计算复杂性，它们改变了模型结构和表示，从而影响软错误鲁棒性。在这方面，尽管经常被忽视，但激活函数（AFs）的选择不仅影响准确性和可训练性，还影响可压缩性和错误弹性。本文探讨了使用有界激活函数来增强对抗参数扰动的鲁棒性，同时以技术无关的方法评估它们对模型准确性、可压缩性和计算负载的影响。我们专注于为高光谱图像语义分割开发的编码器-解码器卷积模型，应用于自动驾驶系统。实验在AMD-Xilinx的KV260 SoM上进行。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [593] [An open dataset of neural networks for hypernetwork research](https://arxiv.org/abs/2507.15869)
> *用于超网络研究的神经网络开放数据集*

*David Kurtenbach, Lior Shamir* | **Category: cs.LG** | **Updated: 2025-07-15**

**Keywords:** 超网络, 神经网络, 数据集, 开放数据, 机器学习

**Comment:** Electronics, published

> **TL;DR:** 该论文介绍了一个包含10^4个LeNet-5神经网络的开放数据集，旨在解决超网络研究中缺乏可用资源的问题，并促进该领域的研究。

**AI_Comments:** 这项工作的创新之处在于它首次提供了一个大规模的、专门为超网络研究设计的开放数据集。这对于推动超网络这一未充分研究但潜力巨大的领域至关重要。数据集的生成规模（10^4个神经网络，使用大型计算集群）本身也体现了其重要性。通过提供可公开访问的数据集和代码，该研究降低了进入超网络研究的门槛，有望加速该领域的进展。其局限性可能在于数据集的特异性（LeNet-5和ImageNette V2），未来可能需要更多样化的数据集来探索超网络的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI的变革潜力巨大，但超网络（能够生成其他神经网络的神经网络）的概念却在很大程度上未被充分研究。其中一个可能的原因是缺乏可用于超网络研究的可用研究资源。

**Method:** 该数据集包含10^4个LeNet-5神经网络，这些网络被训练用于二元图像分类，分为10个类别，每个类别包含1,000个不同的神经网络，可以识别ImageNette V2中的特定类别。数据集的生成使用了超过10^4个核心的计算集群。

**Result:** 基本的分类结果显示，这些神经网络可以以72.0%的准确率进行分类，这表明神经网络之间的差异可以通过监督机器学习算法进行识别。

**Conclusion:** 该数据集的最终目的是为了促进超网络研究，并且数据集及其生成代码是开放且可公开访问的。

> **ai_Abstract:** 本论文介绍了一个为超网络研究设计的开放数据集。该数据集包含10^4个LeNet-5神经网络，这些网络被训练用于二元图像分类，并分为10个类别。研究人员使用一个大型计算集群生成了这些数据。初步分类结果显示，这些神经网络可以被监督学习算法以72.0%的准确率区分开来。该数据集的发布旨在弥补超网络研究资源匮乏的现状，从而推动该领域的发展。

> **摘要翻译:** 尽管人工智能具有变革潜力，但能够通过生成模型权重来产生其他神经网络的超网络概念在很大程度上仍未得到充分研究。其中一个可能的原因是缺乏可用于超网络研究的可用研究资源。本文描述了一个为超网络研究目的而设计的神经网络数据集。该数据集包括10^4个LeNet-5神经网络，这些网络被训练用于二元图像分类，分为10个类别，每个类别包含1,000个不同的神经网络，可以从所有其他类别中识别出某个ImageNette V2类别。一个拥有超过10^4个核心的计算集群被用于生成该数据集。基本的分类结果表明，这些神经网络可以以72.0%的准确率进行分类，这表明神经网络之间的差异可以通过监督机器学习算法进行识别。该数据集的最终目的是为了促进超网络研究。该数据集及其生成代码是开放且可公开访问的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [597] [FLAIN: Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons](https://arxiv.org/abs/2408.08655)
> *FLAIN：通过翻转低激活输入神经元的权重更新来缓解联邦学习中的后门攻击*

*Binbin Ding, Penghui Yang, Sheng-Jun Huang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 联邦学习, 后门攻击, 防御, 权重更新, 低激活神经元

**Comment:** 9 pages, 4 figures, ICMR'25. Updated author information and improved
  experiments in v2

> **TL;DR:** FLAIN通过翻转低激活输入神经元的权重更新来有效防御联邦学习中的后门攻击，同时保持对干净数据的性能影响最小。

**AI_Comments:** FLAIN的创新点在于利用了后门攻击特有的低激活神经元行为，通过有针对性地翻转权重更新来抵消恶意影响。这种方法在不直接访问客户端本地数据的情况下实现了防御，符合联邦学习的隐私保护特性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中，中心服务器无法直接监控客户端的本地训练过程，这使得恶意客户端有机会在模型中植入后门。现有研究表明后门攻击利用了仅被恶意输入激活的特定神经元。

**Method:** 本文提出FLAIN（Flipping Weight Updates of Low-Activation Input Neurons）方法。全局训练完成后，该方法使用辅助数据集识别低激活输入神经元，并迭代翻转其相关的权重更新。此翻转过程持续进行，同时逐步提高低激活神经元的阈值，直到模型在辅助数据上的性能开始显著下降。

**Result:** 广泛的实验表明，FLAIN在各种场景（包括Non-IID数据分布和高恶意客户端比例）下有效降低了后门攻击的成功率，同时对干净数据的性能影响最小。

**Conclusion:** FLAIN是一种有效的联邦学习后门攻击防御方法，能在保持模型性能的同时显著降低攻击成功率。

> **ai_Abstract:** 本文提出了一种名为FLAIN的联邦学习后门攻击防御方法。该方法基于后门攻击利用特定低激活神经元的洞察，在全局训练后，通过辅助数据集识别并迭代翻转低激活输入神经元的权重更新。实验证明，FLAIN能有效降低后门攻击成功率，即使在非独立同分布数据和高恶意客户端比例下，同时对干净数据性能影响甚微。

> **摘要翻译:** 联邦学习（FL）使多个客户端能够在中央服务器的协调下协同训练机器学习模型，同时保持隐私。然而，服务器无法直接监控本地训练过程，这为恶意客户端在模型中引入后门留下了空间。研究表明，后门攻击利用了仅被恶意输入激活的特定神经元，而对干净数据保持休眠状态。基于这一见解，我们提出了一种新颖的防御方法，称为“翻转低激活输入神经元的权重更新”（FLAIN），以对抗FL中的后门攻击。具体来说，在全局训练完成后，我们使用辅助数据集来识别低激活输入神经元，并迭代翻转其相关的权重更新。此翻转过程持续进行，同时逐步提高低激活神经元的阈值，直到模型在辅助数据上的性能开始显著下降。广泛的实验表明，FLAIN在各种场景（包括Non-IID数据分布和高恶意客户端比例）下有效降低了后门攻击的成功率，同时对干净数据的性能影响最小。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [607] [Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines](https://arxiv.org/abs/2507.16537)
> *符号图智能：用于学习图级模式的超向量消息传递与特塞林机*

*Christian D. Blakely* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 图分类, 符号智能, 超向量, 特塞林机, 可解释性

**Comment:** 8 pages, 5 figures, for ICTM '25

> **TL;DR:** 提出了一种基于稀疏二值超向量和特塞林机的多层符号框架，通过结构化消息传递实现图分类，并在图数据集上展示了竞争性准确度和强符号可解释性。

**AI_Comments:** 这项工作在图分类领域提供了一个新颖的符号化视角，区别于主流的神经网络方法。其创新之处在于结合了超向量消息传递和特塞林机，创建了一种既能处理复杂图结构又能提供高可解释性的模型，这对于需要理解模型决策的应用场景尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 针对图分类问题，旨在开发一种新的、具有强可解释性的符号框架。

**Method:** 提出了一种多层符号框架，用于图分类，结合了稀疏二值超向量和特塞林机。该方法通过结构化消息传递将节点、边和属性信息绑定并打包成符号超向量，保留图的层次语义。同时，还提出了一个局部可解释性框架。

**Result:** 在TUDataset基准测试中验证了该方法，与神经图模型相比，展示了竞争性的准确度，并具有强大的符号透明度。

**Conclusion:** 该研究成功开发了一种基于超向量消息传递和特塞林机的符号图分类框架，它不仅实现了竞争性的性能，还提供了神经图模型所缺乏的强大可解释性。

> **ai_Abstract:** 这篇论文提出了一种名为“符号图智能”的多层符号框架，用于通用图分类。该框架利用稀疏二值超向量和特塞林机，通过结构化消息传递将图信息编码为紧凑的、离散的符号超向量，有效保留了图的层次语义。此外，该方法还引入了局部可解释性框架，使其具有显著的透明度。在TUDataset基准测试上的实验结果表明，该方法在保持与神经图模型竞争性准确度的同时，提供了强大的符号可解释性。

> **摘要翻译:** 我们提出了一种用于通用图分类的多层符号框架，该框架利用稀疏二值超向量和特塞林机。每个图都通过结构化消息传递进行编码，其中节点、边和属性信息被绑定并捆绑成一个符号超向量。这个过程通过从节点属性到边关系再到结构角色的分层绑定，保留了图的层次语义，从而产生一个紧凑的离散表示。我们还制定了一个局部可解释性框架，这是我们方法的一个关键优势，即具有局部可解释性。我们在TUDataset基准测试上验证了我们的方法，与神经图模型相比，展示了竞争性的准确度以及强大的符号透明度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [611] [EBaReT: Expert-guided Bag Reward Transformer for Auto Bidding](https://arxiv.org/abs/2507.16186)
> *EBaReT：专家引导的包奖励Transformer自动出价*

*Kaiyuan Li, Pengyu Wang, Yunshan Peng, Pengjia Yuan, Yanxiang Zeng, Rui Xiang, Yanhua Cheng, Xialong Liu, Peng Jiang* | **Category: cs.LG, cs.IR** | **Updated: 2025-07-22**

**Keywords:** 自动出价, 强化学习, Transformer, 数据质量, 奖励不确定性

**Comment:** 

> **TL;DR:** EBaReT通过专家轨迹和包奖励机制解决了自动出价中强化学习的数据质量差和奖励不确定性问题。

**AI_Comments:** EBaReT的创新之处在于其结合了专家引导学习和“包”奖励机制，以应对自动出价中强化学习的核心挑战——数据质量和奖励稀疏性。通过引入专家知识和对奖励进行平滑处理，该方法有望在实际应用中取得更稳定的表现。

<details>
  <summary>Details</summary>

**Motivation:** 传统强化学习方法在自动出价中面临数据质量差（次优出价多、低点击/转化率导致低概率奖励）和长期依赖问题，且现有方法未能有效解决这些挑战。

**Method:** 本文将自动化出价形式化为序列决策问题，并提出了一种新颖的专家引导包奖励Transformer（EBaReT）。为解决数据质量问题，模型生成专家轨迹作为补充数据，并采用基于正-无标记（PU）学习的判别器识别专家转换；同时设计专家引导推理策略以确保决策达到专家水平。为缓解奖励不确定性，模型将一定时期内的转换视为一个“包”，并精心设计奖励函数以平滑地获取奖励。

**Result:** 广泛的实验表明，EBaReT模型与最先进的出价方法相比，取得了卓越的性能。

**Conclusion:** EBaReT通过其独特的数据质量和奖励不确定性处理机制，显著提升了自动出价的效果。

> **ai_Abstract:** 本文针对自动化出价中强化学习面临的数据质量差和奖励不确定性问题，提出了一种新型模型EBaReT。该模型通过生成和识别专家轨迹来提升数据质量，并设计专家引导推理策略。同时，通过引入“包”概念和定制奖励函数来平滑奖励获取，有效缓解了奖励不确定性。实验结果验证了EBaReT优于现有先进方法的性能。

> **摘要翻译:** 强化学习已广泛应用于自动化出价。传统方法将出价建模为马尔可夫决策过程（MDP）。最近，一些研究探索使用生成式强化学习方法来解决出价环境中的长期依赖问题。尽管有效，但这些方法通常依赖于监督学习方法，由于次优出价数量众多以及低点击率和转化率导致的低概率奖励，它们容易受到低数据质量的影响。不幸的是，很少有研究解决这些挑战。
在本文中，我们将自动化出价形式化为序列决策问题，并提出一种新颖的专家引导包奖励Transformer（EBaReT）来解决与数据质量和不确定性奖励相关的问题。具体来说，为了解决数据质量问题，我们生成一组专家轨迹作为训练过程中的补充数据，并采用基于正-无标记（PU）学习的判别器来识别专家转换。为了确保决策也达到专家水平，我们进一步设计了一种新颖的专家引导推理策略。此外，为了减轻奖励的不确定性，我们将一定时期内的转换视为一个“包”，并精心设计了一个奖励函数，从而实现更平滑的奖励获取。广泛的实验表明，我们的模型与最先进的出价方法相比，取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [618] [Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation](https://arxiv.org/abs/2507.16704)
> *Screen2AX: 基于视觉的macOS自动无障碍生成方法*

*Viktor Muryn, Marta Sumyk, Mariya Hirna, Sofiya Garkot, Maksym Shamrai* | **Category: cs.LG, cs.AI, cs.CV, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 无障碍, macOS, 视觉识别, UI自动化, 屏幕解析

**Comment:** 

> **TL;DR:** Screen2AX是一个基于视觉的框架，能从单一截图自动生成实时、树状结构的macOS无障碍元数据，解决了桌面应用无障碍性不足的问题，并显著提高了AI代理对复杂桌面界面的理解和交互能力。

**AI_Comments:** Screen2AX的创新之处在于它是首个实现从单一截图自动创建完整实时树状无障碍元数据的框架，这对于提升macOS应用的无障碍性和AI代理的交互能力具有重要意义。其通过构建和发布大型数据集的举措，也为未来相关研究提供了宝贵资源。该方法显著优于现有技术，有望广泛应用于无障碍辅助和自动化领域。

<details>
  <summary>Details</summary>

**Motivation:** 许多macOS应用程序由于开发者提供的元数据不完整或缺失，导致无障碍性差（仅33%的应用提供完整支持）。现有研究未能捕捉桌面界面的完整层级结构，限制了AI代理和屏幕阅读器的有效性。

**Method:** Screen2AX是第一个能从单一截图自动创建实时、树状无障碍元数据的框架。它使用视觉-语言和目标检测模型来检测、描述和分层组织UI元素，以模仿macOS的系统级无障碍结构。为解决数据稀缺问题，研究团队编译并发布了三个包含112个macOS应用的公共数据集，这些数据集均标注了UI元素检测、分组和层级无障碍元数据。

**Result:** Screen2AX在重建完整无障碍树方面达到了77%的F1分数。这些层级树将自主代理解释和交互复杂桌面界面的能力提高了2.2倍，并且在ScreenSpot基准测试中超越了最先进的OmniParser V2系统。

**Conclusion:** Screen2AX通过自动生成实时、树状的无障碍元数据，显著提高了macOS应用的无障碍性，并增强了AI代理在复杂桌面环境中的理解和交互能力，为未来的无障碍技术发展奠定了基础。

> **ai_Abstract:** Screen2AX是一个创新的基于视觉的框架，旨在解决macOS应用无障碍性不足的问题。它能够从单一截图自动生成实时的、树状结构的无障碍元数据，通过视觉-语言和目标检测模型检测、描述并层级组织UI元素，从而模仿macOS的系统级无障碍结构。为克服数据限制，研究人员构建并发布了三个包含112个macOS应用的数据集。实验结果表明，Screen2AX在重建完整无障碍树方面达到77%的F1分数，并将自主代理的性能提高了2.2倍，同时在ScreenSpot基准测试中优于现有最先进系统。

> **摘要翻译:** 桌面无障碍元数据使AI代理能够解释屏幕，并支持依赖屏幕阅读器等工具的用户。然而，许多应用程序由于开发者提供的元数据不完整或缺失，仍然在很大程度上无法访问——我们的调查显示，macOS上只有33%的应用程序提供完整的无障碍支持。虽然最近关于结构化屏幕表示的工作主要解决了特定挑战，例如UI元素检测或字幕，但没有一个尝试通过复制其整个层级结构来捕捉桌面界面的全部复杂性。为了弥补这一差距，我们引入了Screen2AX，这是第一个从单一截图自动创建实时、树状无障碍元数据的框架。我们的方法使用视觉-语言和目标检测模型来检测、描述和分层组织UI元素，模仿macOS的系统级无障碍结构。为了解决macOS桌面应用程序数据可用性有限的问题，我们编译并公开发布了三个数据集，涵盖112个macOS应用程序，每个都标注了UI元素检测、分组和层级无障碍元数据以及相应的截图。Screen2AX准确推断层级树，在重建完整无障碍树方面达到了77%的F1分数。至关重要的是，这些层级树提高了自主代理解释和交互复杂桌面界面的能力。我们引入了Screen2AX-Task，一个专门为评估macOS桌面环境中自主代理任务执行而设计的基准。使用这个基准，我们证明Screen2AX比原生无障碍表示提供了2.2倍的性能提升，并在ScreenSpot基准测试中超越了最先进的OmniParser V2系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [623] [Prompt Smart, Pay Less: Cost-Aware APO for Real-World Applications](https://arxiv.org/abs/2507.15884)
> *智能提示，更低成本：面向真实世界应用的成本感知APO*

*Jayesh Choudhari, Piyush Kumar Singh, Douglas McIlwraith, Snehal Nair* | **Category: cs.LG** | **Updated: 2025-07-18**

**Keywords:** 自动提示优化, 大语言模型, 成本效率, 多类别分类, 真实世界应用

**Comment:** 

> **TL;DR:** 本文提出了APE-OPRO，一种结合APE和OPRO优点的混合自动提示优化（APO）框架，在实际商业多类别分类任务中显著提升了成本效率，同时提供了关于不同APO方法权衡的见解。

**AI_Comments:** 本文在自动提示优化（APO）领域具有重要创新性，首次将APO方法全面应用于真实世界、高风险的商业多类别分类任务，填补了现有研究主要集中于基准测试的空白。其提出的APE-OPRO混合框架在成本效率上实现了显著提升，同时保持了性能，这对于LLM在商业应用中的落地具有重要意义。研究不仅提供了实用的APO实施见解，还揭示了LLM对标签格式的隐式敏感性，为未来更深层次的LLM行为研究提供了方向。该工作的重要性体现在其解决了LLM大规模应用中的实际痛点——提示设计的效率和成本问题。

<details>
  <summary>Details</summary>

**Motivation:** 提示设计对于大型语言模型（LLMs）的有效性至关重要，但目前仍主要依靠启发式、手动且难以扩展的方法。现有大多数自动提示优化（APO）框架仅在有限复杂度的基准分类任务上验证，缺乏对真实世界、高风险多类别分类的全面评估。

**Method:** 本文首次对真实世界、高风险商业场景中的多类别分类的自动提示优化（APO）方法进行了全面评估。研究引入了一种名为APE-OPRO的新型混合框架，该框架结合了APE和OPRO的优势。研究还将APE-OPRO与梯度无关（APE、OPRO）和基于梯度（ProTeGi）的方法在一个包含约2500个标记产品的数据集上进行了基准测试，并进行了深度和广度超参数的消融研究。

**Result:** APE-OPRO框架在不牺牲性能的情况下，实现了比OPRO高约18%的成本效率提升。结果显示，ProTeGi在较低API成本下提供最强的绝对性能，但计算时间更长；而APE-OPRO在性能、API效率和可扩展性之间取得了平衡。研究还发现LLM行为对标签格式存在显著敏感性。

**Conclusion:** 这些发现为在商业应用中实施自动提示优化（APO）提供了可操作的见解，并为未来在多标签、视觉和多模态提示优化场景中的研究奠定了基础。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）提示设计中存在的启发式、手动且难以扩展的问题，首次全面评估了面向真实世界、高风险商业多类别分类的自动提示优化（APO）方法。研究提出了APE-OPRO，一个结合APE和OPRO优势的新型混合框架，在不牺牲性能的前提下，比OPRO提高了约18%的成本效率。通过与现有方法的基准测试，论文揭示了不同APO方法在性能、API成本和计算时间之间的权衡，并强调了LLM对标签格式的敏感性。这些发现为商业应用中的APO实施提供了实用指导，并为未来的多模态提示优化研究奠定了基础。

> **摘要翻译:** 提示设计是大型语言模型（LLMs）有效性的关键因素，但目前仍主要依靠启发式、手动且难以扩展的方法。本文首次对面向商业环境中真实世界、高风险多类别分类的自动提示优化（APO）方法进行了全面评估，解决了现有文献中大多数APO框架仅在有限复杂度的基准分类任务上验证的关键空白。
我们引入了APE-OPRO，这是一种新颖的混合框架，它结合了APE和OPRO的互补优势，在不牺牲性能的情况下，实现了显著更好的成本效率，比OPRO提高了约18%。我们将APE-OPRO与无梯度（APE、OPRO）和基于梯度（ProTeGi）方法一同在一个约2500个标记产品的数据集上进行了基准测试。
我们的结果突出了关键的权衡：ProTeGi在较低API成本下提供最强的绝对性能，但计算时间较长，如参考文献[protegi]所述，而APE-OPRO在性能、API效率和可扩展性之间取得了令人信服的平衡。我们进一步对深度和广度超参数进行了消融研究，并揭示了对标签格式的显著敏感性，这表明LLM行为存在隐式敏感性。这些发现为在商业应用中实施APO提供了可操作的见解，并为未来在多标签、视觉和多模态提示优化场景中的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [633] [Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder](https://arxiv.org/abs/2411.05195)
> *探索生成式多模态大语言模型（MLLMs）如何利用相同的视觉编码器比CLIP感知更多信息*

*Siting Li, Pang Wei Koh, Simon Shaolei Du* | **Category: cs.LG, cs.CL, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 生成式MLLMs, CLIP, 视觉-语言模型, 视觉推理, 架构选择

**Comment:** ACL 2025; 19 pages, 3 figures

> **TL;DR:** 生成式多模态大语言模型（MLLMs）即使使用与CLIP相同的视觉编码器，也能在视觉推理任务中表现更优，因为它们能更有效地提取和利用视觉信息，这归因于特定的架构设计选择。

**AI_Comments:** 该论文通过挑战CLIP视觉编码器在复杂视觉推理中固有局限性的假设，做出了重要贡献。它创新性地指出问题在于CLIP无法提取信息，而非编码器本身缺乏信息。通过展示MLLMs在使用相同编码器时的卓越性能，并精确指出关键架构元素（补丁tokens、位置嵌入、基于提示的加权）是其成功的关键，该研究为改进VLM设计，特别是类似CLIP的模型，提供了具体方向。细粒度推理并非自回归训练所独有的发现也富有洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 最近研究表明CLIP模型在需要理解组合性、空间关系和细粒度细节的视觉推理任务上表现不佳。尽管一个自然假设是CLIP视觉编码器未嵌入必要信息，但本研究发现编码器实际收集了相关视觉信息，而CLIP未能有效提取。这促使研究者探索为何生成式多模态大语言模型（MLLMs）在使用相同视觉编码器的情况下却能表现更好。

**Method:** 本研究通过比较生成式多模态大语言模型（MLLMs）与CLIP在视觉推理任务上的表现，两者使用相同的视觉编码器和权重。研究者进行了一系列对照实验，以揭示MLLMs成功的关键设计选择，包括补丁tokens、位置嵌入和基于提示的加权。同时，他们也探究了增强训练数据、更强的文本编码器和额外文本tokens的影响。此外，研究者将MLLMs通过对比微调转换为类似CLIP的编码器，并在相同的评估协议下进行性能比较。

**Result:** 研究发现，生成式多模态大语言模型（MLLMs）在使用与CLIP相同的视觉编码器和权重的情况下，在许多视觉推理任务中取得了显著更高的准确性。MLLMs的成功归因于它们更有效地提取和利用视觉信息，这得益于多个关键设计选择，包括补丁tokens、位置嵌入和基于提示的加权。单独增强训练数据、应用更强的文本编码器或增加额外文本tokens不足以解决任务。有趣的是，细粒度视觉推理并非自回归损失训练的生成模型所独有，通过对比微调转换为类似CLIP编码器的MLLMs在相同评估协议下仍优于CLIP。

**Conclusion:** 本研究强调了视觉-语言模型（VLM）架构选择对于有效利用视觉信息的重要性，并为改进类似CLIP的对比VLMs的性能指明了方向。

> **ai_Abstract:** 本论文探讨了生成式多模态大语言模型（MLLMs）为何在视觉推理任务中优于CLIP，即使两者使用相同的视觉编码器。研究发现，CLIP的视觉编码器确实能收集相关视觉信息，但CLIP难以有效提取。相反，生成式MLLMs因其特定的架构设计（如补丁tokens、位置嵌入和基于提示的加权）能更有效地利用这些信息。研究还表明，细粒度视觉推理并非自回归训练模型所独有，因为经过对比微调的MLLMs仍能超越CLIP。这突出了视觉-语言模型架构设计在视觉信息处理中的关键作用。

> **摘要翻译:** 最近的研究表明，CLIP模型在需要基础组合性、理解空间关系或捕捉细粒度细节的视觉推理任务上表现不佳。一个自然的假设是CLIP视觉编码器没有为这些任务嵌入必要的信息。然而，我们发现情况并非总是如此：编码器确实收集了与查询相关的视觉信息，而CLIP未能提取这些信息。特别是，我们展示了视觉-语言模型（VLMs）的另一个分支，即生成式多模态大语言模型（MLLMs），在使用相同的视觉编码器和权重的情况下，在许多此类任务中取得了比CLIP显著更高的准确性，这表明这些生成式MLLMs感知到更多信息——因为它们更有效地提取和利用视觉信息。我们进行了一系列对照实验，揭示了它们的成功归因于多个关键设计选择，包括补丁tokens、位置嵌入和基于提示的加权。另一方面，单独增强训练数据或应用更强的文本编码器不足以解决任务，并且额外的文本tokens带来的益处很小。有趣的是，我们发现细粒度视觉推理并非生成模型通过自回归损失训练所独有：当通过对比微调转换为类似CLIP的编码器时，这些MLLMs在相同的基于余弦相似度的评估协议下仍然优于CLIP。我们的研究强调了VLM架构选择的重要性，并为改进类似CLIP的对比VLMs的性能指明了方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [653] [ReDi: Rectified Discrete Flow](https://arxiv.org/abs/2507.15897)
> *ReDi: 修正离散流*

*Jaehoon Yoo, Wonjung Kim, Seunghoon Hong* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-21**

**Keywords:** 离散流模型, 少步生成, 条件总相关性, 耦合修正, ReDi

**Comment:** 

> **TL;DR:** 提出ReDi（修正离散流）模型，通过修正耦合来减少离散流模型的因子分解误差，从而实现高效的少步生成，解决了离散流模型采样速度慢的问题。

**AI_Comments:** 这篇论文通过引入“修正耦合”的概念，并利用条件总相关性（Conditional TC）进行理论分析，为离散流模型（DFMs）的少步生成问题提供了创新的解决方案。其理论保证和经验效果使其在高效离散数据合成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 离散流模型（DFMs）在处理高维数据时，由于依赖迭代解码过程和因子分解近似，导致采样速度慢。

**Method:** 提出修正离散流（ReDi），这是一种新颖的迭代方法，通过修正源分布和目标分布之间的耦合来减少因子分解误差。该方法理论上保证每一步都会单调降低条件总相关性（Conditional TC）。

**Result:** 经验证明，ReDi显著降低了条件总相关性（Conditional TC），并实现了少步生成。此外，修正后的耦合非常适合训练高效的一步图像生成模型。

**Conclusion:** ReDi 为解决少步生成挑战提供了一种简单且有理论基础的方法，为高效离散数据合成提供了新视角。

> **ai_Abstract:** 本文针对离散流模型（DFMs）采样速度慢的问题，提出了一种名为“修正离散流”（ReDi）的新方法。ReDi通过修正源分布与目标分布之间的耦合，减少了DFM因子分解带来的近似误差，并理论证明了其收敛性。实验结果表明，ReDi能有效降低条件总相关性，实现高效的少步甚至一步生成，为离散数据合成提供了一种新颖且有理论依据的解决方案。

> **摘要翻译:** 离散流模型（DFMs）是高质量离散数据的强大生成模型，但由于依赖迭代解码过程，通常采样速度缓慢。这种对多步过程的依赖源于DFM的因子分解近似，这对于处理高维数据是必需的。在本文中，我们使用条件总相关性（Conditional TC）严格表征了因子分解的近似误差，该误差取决于耦合。为了减少条件总相关性并实现高效的少步生成，我们提出了修正离散流（ReDi），这是一种新颖的迭代方法，通过修正源分布和目标分布之间的耦合来减少因子分解误差。我们理论上证明，每个ReDi步骤都保证条件总相关性单调递减，从而确保其收敛性。在实验中，ReDi显著降低了条件总相关性，并实现了少步生成。此外，我们证明了修正后的耦合非常适合训练高效的一步图像生成模型。ReDi为解决少步挑战提供了一种简单且有理论基础的方法，为高效离散数据合成提供了新视角。代码可在https://github.com/Ugness/ReDi_discrete 获得。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [654] [RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs](https://arxiv.org/abs/2507.16200)
> *RealBench：使用真实世界IP设计对Verilog生成模型进行基准测试*

*Pengwei Jin, Di Huang, Chongxiao Li, Shuyao Cheng, Yang Zhao, Xinyao Zheng, Jiaguo Zhu, Shuyi Xing, Bohan Dou, Rui Zhang, Zidong Du, Qi Guo, Xing Hu* | **Category: cs.LG, cs.AR** | **Updated: 2025-07-22**

**Keywords:** Verilog生成, LLM, 基准测试, 硬件设计, IP设计

**Comment:** The benchmark is open-sourced at
  https://github.com/IPRC-DIP/RealBench

> **TL;DR:** RealBench是首个用于评估LLM在真实世界IP级Verilog代码生成任务上表现的基准测试，结果显示现有LLM表现不佳，亟需改进。

**AI_Comments:** RealBench的创新之处在于其对真实世界IP设计的关注和严格的验证环境，这使其成为评估LLM在硬件设计领域实际应用潜力的重要工具。该基准测试揭示了当前LLM在处理复杂硬件设计任务时的显著局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Verilog生成LLM基准测试未能真实反映实际设计工作流程，因为它们的设计过于简单，规范不充分，且验证环境不严格。

**Method:** 我们提出了RealBench，这是一个针对真实世界IP级Verilog生成任务的基准测试。它包含复杂的、结构化的真实世界开源IP设计、多模态和格式化的设计规范，以及严格的验证环境（包括100%行覆盖率测试平台和形式化检查器）。它支持模块级和系统级任务。

**Result:** 对各种LLM和代理的评估表明，即使是表现最佳的LLM之一o1-preview，在模块级任务上的pass@1也仅为13.3%，在系统级任务上为0%。

**Conclusion:** 现有LLM在真实世界IP级Verilog生成任务上的表现远不能令人满意，未来需要更强大的Verilog生成模型。

> **ai_Abstract:** 该论文介绍了RealBench，一个用于评估大型语言模型（LLMs）在真实世界IP级Verilog代码生成任务上的新基准测试。它旨在解决现有基准测试在设计复杂性、规范和验证严格性方面的不足。RealBench包含复杂的开源IP设计、多模态规范和严格的验证。评估结果显示，即使是当前表现最佳的LLM，在RealBench上的性能也远低于预期，尤其在系统级任务上表现为零，强调了开发更强Verilog生成模型的必要性。

> **摘要翻译:** 大型语言模型（LLMs）自动生成Verilog代码在硬件设计自动化领域引起了广泛关注。然而，现有用于评估Verilog生成LLM的基准测试未能真实反映实际设计工作流程，原因在于其设计过于简单、设计规范不充分以及验证环境不够严格。为了解决这些局限性，我们提出了RealBench，这是首个旨在解决真实世界IP级Verilog生成任务的基准测试。RealBench具有复杂、结构化的真实世界开源IP设计、多模态和格式化的设计规范，以及严格的验证环境，包括100%行覆盖率的测试平台和形式化检查器。它支持模块级和系统级任务，能够全面评估LLM的能力。对各种LLM和代理的评估表明，即使是表现最佳的LLM之一o1-preview，在模块级任务上的pass@1也仅为13.3%，在系统级任务上为0%，这凸显了未来需要更强大的Verilog生成模型。该基准测试已在https://github.com/IPRC-DIP/RealBench开源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [655] [Families of Optimal Transport Kernels for Cell Complexes](https://arxiv.org/abs/2507.16569)
> *胞腔复形最优传输核族*

*Rahul Khorana* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 最优传输, 胞腔复形, Wasserstein距离, 机器学习, 核函数

**Comment:** 

> **TL;DR:** 本文为CW复形开发了最优传输核和距离，以弥补当前在CW复形上进行机器学习方法的不足。

**AI_Comments:** 本文的创新之处在于将最优传输理论应用于复杂的CW复形结构，为该领域的机器学习提供了基础工具。这可能为分析超越传统图的结构化数据开辟新途径。其重要性在于弥合了理论表示（胞腔复形）与实际机器学习应用之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 尽管胞腔复形被认为是理想的学习表示，但目前缺乏适用于CW复形的机器学习方法。

**Method:** 本文推导了基于Hodge-Laplacian矩阵的胞腔复形信号分布间Wasserstein距离的显式表达式；将融合Gromov-Wasserstein距离扩展到CW复形以同时包含特征和结构信息；并基于最优传输的对偶公式，引入了在CW复形上的概率测度空间中的新颖核函数。

**Result:** 推导了基于Hodge-Laplacian矩阵的胞腔复形信号分布间Wasserstein距离的显式表达式；将融合Gromov-Wasserstein距离扩展到CW复形；引入了在CW复形上的概率测度空间中的新颖核函数。

**Conclusion:** 本文为在CW复形上进行机器学习提供了新的工具（包括Wasserstein距离表达式、扩展的FGW距离和新颖的核函数），从而解决了当前方法不足的问题。

> **ai_Abstract:** 本文旨在解决当前缺乏适用于CW复形的机器学习方法的问题，尽管CW复形被认为是理想的学习表示。文中推导了基于Hodge-Laplacian矩阵的胞腔复形信号分布间Wasserstein距离的显式表达式，为CW复形提供了结构化比较和最优传输的度量。为同时整合特征和结构信息，研究将融合Gromov-Wasserstein距离扩展到CW复形。此外，本文还基于最优传输的对偶公式，引入了在CW复形上的概率测度空间中的新颖核函数。

> **摘要翻译:** 最近的研究讨论了胞腔复形作为理想的学习表示。然而，目前缺乏适用于CW复形的机器学习方法。在本文中，我们推导了胞腔复形信号分布之间 Wasserstein 距离的显式表达式，该表达式基于 Hodge-Laplacian 矩阵。这产生了一种结构上有意义的度量，用于比较 CW 复形并定义最优传输映射。为了同时包含特征和结构信息，我们将融合 Gromov-Wasserstein 距离扩展到 CW 复形。最后，我们基于最优传输的对偶公式，在 CW 复形上的概率测度空间中引入了新颖的核。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [667] [Graph Neural Networks Gone Hogwild](https://arxiv.org/abs/2407.00494)
> *图神经网络的异步更新问题*

*Olga Solodova, Nick Richardson, Deniz Oktay, Ryan P. Adams* | **Category: cs.LG, cs.DC** | **Updated: 2025-07-22**

**Keywords:** 图神经网络, 异步推理, 多智能体系统, 隐式定义GNN, 能量GNN

**Comment:** 

> **TL;DR:** 图神经网络（GNNs）在异步更新时会失效，限制了其应用。本文识别了一类对异步推理具有鲁棒性的“隐式定义”GNN，并提出了一种名为“能量GNN”的新架构，该架构在多智能体系统任务中表现优异。

**AI_Comments:** 该论文通过识别和提出一类对异步更新具有内在鲁棒性的架构，解决了图神经网络在实际分布式系统中面临的一个关键限制。引入“隐式定义”GNN和具体的“能量GNN”代表了一种创新方法，确保了GNN的可靠性并将其适用范围扩展到同步环境之外。其重要性在于使GNN能够应用于机器人群和传感器网络等无法实现完美同步的实际场景。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）是学习分布式、去中心化多智能体系统中智能体状态表示的强大工具，但它们在推理过程中节点异步更新时会产生灾难性的错误预测。这种在异步下的失效有效地限制了GNNs在许多难以或不可能强制同步的潜在应用（如机器人群或传感器网络）中的使用。

**Method:** 本研究识别出“隐式定义”的GNN作为一类对异步“hogwild”推理具有可证明鲁棒性的架构，并借鉴了异步和分布式优化中的收敛保证。在此基础上，提出了一种新颖的隐式定义GNN架构，称之为“能量GNN”。

**Result:** 所提出的“能量GNN”架构在受多智能体系统启发的一系列合成任务上，优于该类别中的其他GNN。

**Conclusion:** “隐式定义”GNN是一类对异步推理具有鲁棒性的架构。本研究提出的“能量GNN”是一种有效的实现，在多智能体系统启发任务中表现出色，解决了GNN在异步环境中的应用限制。

> **ai_Abstract:** 图神经网络（GNNs）在处理分布式多智能体系统时，因异步更新导致预测失败，限制了其应用。本文提出了一种名为“隐式定义”GNN的架构类别，该类别被证明对异步推理具有鲁棒性，并在此基础上引入了一种新颖的“能量GNN”。实验表明，该“能量GNN”在模拟多智能体系统的任务中，性能优于同类其他GNN，为GNN在非同步环境下的应用提供了解决方案。

> **摘要翻译:** 图神经网络 (GNNs) 似乎是为分布式、去中心化多智能体系统中的智能体学习状态表示的强大工具，但在推理过程中节点异步更新时会产生灾难性的错误预测。这种在异步下的失效有效地将这些架构排除在许多难以或不可能强制同步的潜在应用之外，例如机器人群或传感器网络。在这项工作中，我们识别出“隐式定义”的GNN作为一类架构，其被证明对异步“hogwild”推理具有鲁棒性，并借鉴了异步和分布式优化中的收敛保证。然后，我们提出了一种新颖的隐式定义GNN架构，我们称之为“能量GNN”。我们表明，该架构在受多智能体系统启发的一系列合成任务上，优于该类别中的其他GNN。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [669] [Streamlining Prediction in Bayesian Deep Learning](https://arxiv.org/abs/2411.18425)
> *精简贝叶斯深度学习中的预测*

*Rui Li, Marcus Klasson, Arno Solin, Martin Trapp* | **Category: cs.LG** | **Updated: 2025-07-22**

**Keywords:** 贝叶斯深度学习, 预测, 局部线性化, 高斯近似, 单次前向传播

**Comment:** 

> **TL;DR:** 本文提出了一种无需采样，通过单次前向传播即可在贝叶斯深度学习中高效计算预测的方法，利用激活函数的局部线性化和线性层的局部高斯近似。

**AI_Comments:** 本文的创新点在于提出了通过局部线性化和高斯近似来解析计算贝叶斯深度学习中后验预测分布的方法，从而避免了耗时的蒙特卡洛采样，显著提高了预测效率。这对于贝叶斯深度学习的实际应用具有重要意义，尤其是在需要快速推断的场景。该方法在多种网络架构上的验证也增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 贝叶斯深度学习（BDL）中后验分布估计方法繁多，但推断（如预测）的计算效率却被很大程度上忽视了，蒙特卡洛积分仍是标准方法。

**Method:** 通过对激活函数进行局部线性化，并在线性层进行局部高斯近似，从而能够解析地计算后验预测分布的近似值，实现单次前向传播而非采样。

**Result:** 在MLP和Transformer（如ViT和GPT-2）上展示了该方法，并评估了其在回归和分类任务上的性能。

**Conclusion:** 通过局部线性化和高斯近似，可以解析地近似后验预测分布，从而在贝叶斯深度学习中实现高效的预测，无需蒙特卡洛采样。

> **ai_Abstract:** 本文提出一种在贝叶斯深度学习中精简预测的方法，旨在解决传统蒙特卡洛积分效率低下的问题。研究人员通过对激活函数进行局部线性化处理，并在线性层应用局部高斯近似，实现了无需采样的单次前向传播即可解析地近似计算后验预测分布。该方法已在MLP和Transformer模型（包括ViT和GPT-2）上进行了验证，并在回归和分类任务中展示了其性能。

> **摘要翻译:** 贝叶斯深度学习（BDL）日益增长的兴趣催生了大量估计后验分布的方法。然而，推断（如预测）的有效计算却在很大程度上被忽视了，蒙特卡洛积分仍然是标准方法。在这项工作中，我们研究了如何在BDL中通过单次前向传播而非采样来精简预测。为此，我们对激活函数使用局部线性化，并在线性层使用局部高斯近似。这使得我们能够解析地计算后验预测分布的近似值。我们展示了该方法在MLP和Transformer（如ViT和GPT-2）上的应用，并评估了其在回归和分类任务上的性能。
开源库：https://github.com/AaltoML/SUQ

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [683] [Improving the Generation of VAEs with High Dimensional Latent Spaces by the use of Hyperspherical Coordinates](https://arxiv.org/abs/2507.15900)
> *利用超球面坐标改进高维潜在空间VAE的生成能力*

*Alejandro Ascarate, Leo Lebrat, Rodrigo Santa Cruz, Clinton Fookes, Olivier Salvado* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 变分自编码器, 高维潜在空间, 超球面坐标, 生成模型, 潜在稀疏性

**Comment:** 8 pages, 3 figures, published in IJCNN25 (in press)

> **TL;DR:** 针对高维潜在空间VAE生成质量差的问题，本文提出使用超球面坐标来压缩潜在向量，从而提高VAE的生成能力。

**AI_Comments:** 本文的创新点在于将高维统计中的超球面坐标思想引入到VAE的潜在空间参数化中，有效地解决了高维潜在空间中潜在向量稀疏导致生成质量差的问题。这种方法提供了一种新颖且计算效率高的方式来改进VAE在高维场景下的性能，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当变分自编码器（VAE）的潜在空间维度较高（超过十几个维度）时，从先验中解码随机潜在向量通常无法产生有意义的数据。

**Method:** 作者借鉴高维统计的见解，指出标准VAE的潜在向量在高维区域中均匀分布在超球面上。他们提出使用超球面坐标来表征VAE的潜在变量，这使得潜在向量可以被压缩到超球面上的一个“岛”上，从而减少潜在空间的稀疏性。该方法引入了一种新的潜在空间参数化，且计算开销有限。

**Result:** 这种方法提高了VAE的生成能力，并减少了潜在空间的稀疏性。

**Conclusion:** 通过使用超球面坐标对VAE的潜在空间进行新的参数化，可以有效解决高维潜在空间VAE生成质量差的问题，从而提高其生成能力，且计算开销有限。

> **ai_Abstract:** 本文针对高维潜在空间变分自编码器（VAE）生成无意义数据的问题，提出了一种利用超球面坐标的新方法。通过将潜在变量参数化为超球面坐标，模型能够将潜在向量压缩到超球面上的特定区域，从而有效降低潜在空间的稀疏性。实验表明，这种新颖且计算开销有限的参数化方法显著提升了VAE的生成能力。

> **摘要翻译:** 变分自编码器（VAE）将数据编码成低维潜在向量，然后再将这些向量解码回数据。一旦训练完成，从先验中解码一个随机潜在向量通常不会产生有意义的数据，至少当潜在空间维度超过十几个时是这样。在本文中，我们通过借鉴高维统计的见解来研究这个问题：在这些情况下，标准VAE的潜在向量在结构上是均匀分布在超球面上的。我们提出使用超球面坐标来表征VAE的潜在变量，这允许将潜在向量压缩到超球面上的一个“岛”上，从而减少潜在稀疏性，并且我们表明这提高了VAE的生成能力。我们提出了一种计算开销有限的潜在空间新参数化方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [690] [METER: Multi-modal Evidence-based Thinking and Explainable Reasoning -- Algorithm and Benchmark](https://arxiv.org/abs/2507.16206)
> *METER: 多模态基于证据的思维和可解释推理——算法与基准*

*Xu Yang, Qi Zhang, Shuming Jiang, Yaowen Xu, Zhaofan Zou, Hao Sun, Xuelong Li* | **Category: cs.LG, cs.AI, 68T45, I.4.8; I.2.6; I.2.7** | **Updated: 2025-07-22**

**Keywords:** 多模态伪造检测, 可解释性AI, 基准数据集, 思维链, 生成式媒体

**Comment:** 9 pages,3 figures ICCV format

> **TL;DR:** METER是一个统一的多模态基准，用于可解释的伪造检测，涵盖图像、视频、音频和视听内容，并引入了一种新的三阶段CoT训练策略。

**AI_Comments:** METER的创新之处在于其构建了一个统一的多模态基准，并强调了可解释性，通过要求证据链式的解释来弥补现有二元分类方法的不足。其引入的三阶段CoT训练策略，特别是GRPO阶段与人类对齐评估器的结合，也体现了对模型可信度和泛化能力的追求。这对于应对日益逼真的生成式AI伪造内容具有重要意义，有助于提升安全关键场景下的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI的快速发展，合成内容（图像、视频、音频）变得越来越逼真，增加了错误信息的风险。现有检测方法主要关注二元分类，缺乏对伪造的详细和可解释的解释，限制了其在安全关键场景中的适用性。此外，当前方法通常单独处理每种模态，缺乏用于跨模态伪造检测和解释的统一基准。

**Method:** 本文引入了METER，一个统一的、多模态的、用于可解释伪造检测的基准，涵盖图像、视频、音频和视听内容。数据集包含四个轨道，每个轨道不仅需要真假分类，还需要基于证据链的解释，包括时空定位、文本理由和伪造类型追溯。此外，提出了一种与人类对齐的三阶段思维链（CoT）训练策略，结合了SFT（监督微调）、DPO（直接偏好优化）和一个新颖的GRPO阶段，该阶段将人类对齐的评估器与CoT推理相结合。

**Result:** 与现有基准相比，METER提供了更广泛的模态覆盖和更丰富的可解释性指标，如空间/时间IoU、多类别追溯和证据一致性。METER数据集要求真假分类和基于证据链的解释。

**Conclusion:** METER有望成为推进生成媒体时代可泛化和可解释伪造检测的标准化基础。

> **ai_Abstract:** METER是一个针对生成式AI内容伪造检测的新型多模态基准和算法。它旨在解决现有方法在解释性和跨模态统一性方面的不足。METER数据集包含图像、视频、音频和视听内容，要求进行真假分类及基于证据链的解释（时空定位、文本理由、伪造类型追溯）。该研究还提出了一种结合SFT、DPO和GRPO的三阶段CoT训练策略。METER提供了更广泛的模态覆盖和更丰富的可解释性指标，旨在成为可泛化和可解释伪造检测的标准化基础。

> **摘要翻译:** 随着生成式AI的快速发展，图像、视频和音频等合成内容变得越来越逼真，从而加剧了错误信息的风险。现有的检测方法主要侧重于二元分类，但缺乏对伪造的详细和可解释的解释，这限制了它们在安全关键场景中的适用性。此外，当前方法通常单独处理每种模态，没有一个统一的跨模态伪造检测和解释基准。为了解决这些挑战，我们引入了METER，一个统一的、多模态的基准，用于可解释的伪造检测，涵盖图像、视频、音频和视听内容。我们的数据集包含四个轨道，每个轨道不仅需要真假分类，还需要基于证据链的解释，包括时空定位、文本理由和伪造类型追溯。与现有基准相比，METER提供了更广泛的模态覆盖和更丰富的可解释性指标，例如空间/时间IoU、多类别追溯和证据一致性。我们进一步提出了一种与人类对齐的三阶段思维链（CoT）训练策略，该策略结合了SFT、DPO和一个新颖的GRPO阶段，该阶段将人类对齐的评估器与CoT推理相结合。我们希望METER能够为推动生成媒体时代可泛化和可解释的伪造检测奠定标准化基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [691] [Scaling Linear Attention with Sparse State Expansion](https://arxiv.org/abs/2507.16577)
> *稀疏状态扩展下的线性注意力机制扩展*

*Yuqi Pan, Yongqi An, Zheng Li, Yuhong Chou, Ruijie Zhu, Xiaohui Wang, Mingxuan Wang, Jinqiao Wang, Guoqi Li* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 线性注意力, 稀疏状态扩展, 长上下文建模, 数学推理, 上下文检索

**Comment:** 

> **TL;DR:** 提出稀疏状态扩展（SSE）来改进线性注意力，使其在长上下文场景下更高效，并在推理和检索任务上表现出色，甚至在数学推理上达到SOTA。

**AI_Comments:** 这篇论文的创新点在于提出了“行稀疏更新”和“稀疏状态扩展（SSE）”两种机制，有效解决了线性注意力在长上下文场景下的效率和性能权衡问题。通过将状态更新视为信息分类，并引入多分区状态扩展，该方法在保持效率的同时，显著提升了模型在上下文检索和数学推理等复杂任务上的表现，特别是其在小模型上达到SOTA数学推理性能，显示了其在资源受限环境下的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer架构取得了广泛成功，但由于二次计算和线性内存增长，它在长上下文场景中表现不佳。虽然各种线性注意力变体通过将上下文压缩到固定大小的状态中来缓解这些效率限制，但它们通常会在上下文检索和推理等任务中降低性能。

**Method:** 提出两项创新：1. 通过将状态更新概念化为信息分类，引入了线性注意力的行稀疏更新公式，通过基于softmax的top-k硬分类实现稀疏状态更新，从而扩展感受野并减少类间干扰。2. 在稀疏框架内引入稀疏状态扩展（SSE），它将上下文状态扩展为多个分区，在保持稀疏分类范式的同时，有效地将参数大小与状态容量解耦。

**Result:** SSE在纯线性模型和混合（SSE-H）架构中，在语言建模、上下文检索和数学推理基准测试中得到了广泛验证。SSE展示了强大的检索性能，并随状态大小的增加而良好扩展。此外，经过强化学习（RL）训练后，其2B SSE-H模型在小型推理模型中实现了最先进的数学推理性能，在AIME24上得分为64.7，在AIME25上得分为51.3，显著优于类似大小的开源Transformer。

**Conclusion:** 这些结果表明SSE是一种有前途且高效的长上下文建模架构。

> **ai_Abstract:** 这篇论文提出了一种名为稀疏状态扩展（SSE）的新方法，旨在解决传统Transformer在长上下文处理中的效率问题以及现有线性注意力模型在特定任务上的性能下降。通过引入行稀疏更新和将上下文状态扩展到多个分区，SSE实现了更有效的上下文压缩和判别性状态表示。实验结果表明，SSE在上下文检索方面表现出色，并能良好地随状态大小扩展。特别是在数学推理任务上，经过RL训练的SSE-H模型在小模型中达到了最先进的性能，显著优于同等规模的开源Transformer，证明了其作为长上下文建模的高效和有前景的架构潜力。

> **摘要翻译:** 尽管Transformer架构取得了广泛成功，但由于二次计算和线性内存增长，它在长上下文场景中表现不佳。虽然各种线性注意力变体通过将上下文压缩到固定大小的状态中来缓解这些效率限制，但它们通常会在上下文检索和推理等任务中降低性能。为了解决这一限制并实现更有效的上下文压缩，我们提出了两项关键创新。首先，我们通过将状态更新概念化为信息分类，引入了线性注意力的行稀疏更新公式。这通过基于softmax的top-k硬分类实现了稀疏状态更新，从而扩展了感受野并减少了类间干扰。其次，我们在稀疏框架内引入了稀疏状态扩展（SSE），它将上下文状态扩展为多个分区，在保持稀疏分类范式的同时，有效地将参数大小与状态容量解耦。我们的设计，由高效的并行化实现支持，产生了有效的分类和判别性状态表示。我们广泛验证了SSE在纯线性模型和混合（SSE-H）架构中在语言建模、上下文检索和数学推理基准测试中的性能。SSE展示了强大的检索性能，并随状态大小的增加而良好扩展。此外，经过强化学习（RL）训练后，我们的2B SSE-H模型在小型推理模型中实现了最先进的数学推理性能，在AIME24上得分为64.7，在AIME25上得分为51.3，显著优于类似大小的开源Transformer。这些结果表明SSE是一种有前途且高效的长上下文建模架构。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [705] [Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD](https://arxiv.org/abs/2412.20553)
> *随机稳定性边缘：重新审视SGD的稳定性边缘*

*Arseniy Andreyev, Pierfrancesco Beneventano* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 随机稳定性, SGD, 稳定性边缘, 批量锐度, 神经网络

**Comment:** 71 pages, 43 figures

> **TL;DR:** 本文提出SGD在“随机稳定性边缘”（EoSS）机制下训练，其中批量锐度稳定在2/η，解释了小批量和大步长有利于平坦最小值的原因。

**AI_Comments:** 这篇论文通过引入“随机稳定性边缘”（EoSS）和“批量锐度”的概念，为理解小批量SGD的收敛和泛化特性提供了新的视角。它弥补了现有“稳定性边缘”理论在全批量和随机梯度下降之间差异的空白，解释了为何小批量训练能导致更平坦的最小值，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Cohen等人的研究发现，全批量梯度下降训练神经网络时，Hessian的最大特征值稳定在2/η，但这不适用于小批量随机梯度下降（SGD），限制了其适用性。本文旨在揭示SGD在此方面的不同机制。

**Method:** 本文通过理论分析和/或经验展示，揭示了SGD在一个被称为“随机稳定性边缘”（EoSS）的不同机制下进行训练。

**Result:** 在随机稳定性边缘（EoSS）机制下，稳定在2/η的量是“批量锐度”（Batch Sharpness），即小批量Hessian沿其相应随机梯度的预期方向曲率。因此，最大特征值λmax（通常小于批量锐度）被抑制。

**Conclusion:** SGD在随机稳定性边缘（EoSS）机制下的训练行为，解释了小批量和更大步长有利于形成更平坦最小值的长期经验观察。研究结果对SGD轨迹的数学建模具有重要意义。

> **ai_Abstract:** Cohen等人的研究发现全批量梯度下降训练神经网络时，Hessian的最大特征值稳定在2/η，但这一结论不适用于小批量随机梯度下降（SGD）。本文提出SGD在一个被称为“随机稳定性边缘”（EoSS）的不同机制下训练。在此机制下，“批量锐度”（即小批量Hessian沿随机梯度的预期方向曲率）稳定在2/η，从而抑制了最大特征值。这一发现与小批量和更大步长有利于形成更平坦最小值的经验观察相符，并对SGD轨迹的数学建模具有启示意义。

> **摘要翻译:** Cohen等人（2021）最近的研究发现，当使用步长为η的全批量梯度下降训练神经网络时，全批量Hessian的最大特征值λmax始终稳定在2/η。这些结果对收敛和泛化具有重要意义。然而，小批量随机梯度下降（SGD）并非如此，这限制了其结果的更广泛适用性。我们表明SGD在一种我们称之为“随机稳定性边缘”（EoSS）的不同机制下进行训练。在这种机制下，稳定在2/η的是“批量锐度”（Batch Sharpness）：即小批量Hessian沿其相应随机梯度的预期方向曲率。因此，λmax（通常小于批量锐度）被抑制，这与小批量和更大步长有利于形成更平坦最小值的长期经验观察相符。我们进一步讨论了对SGD轨迹数学建模的启示。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [715] [Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor](https://arxiv.org/abs/2507.15903)
> *面向LLM驱动智能体幻觉缓解：渐进式泛化边界探索与看门狗监控*

*Siyuan Liu, Wenjing Liu, Zhiwei Xu, Xin Wang, Bo Chen, Tao Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-21**

**Keywords:** LLM智能体, 幻觉缓解, 泛化边界, 黑盒监测, 看门狗框架

**Comment:** 

> **TL;DR:** LLM智能体存在幻觉问题，本文提出HalMit，一个黑盒看门狗框架，通过探索泛化边界来高效检测幻觉。

**AI_Comments:** 本文提出了一种创新的黑盒方法HalMit来解决LLM驱动智能体中的幻觉问题，避免了对LLM内部结构的依赖，这在实际应用中具有重要意义。其通过探索泛化边界来检测幻觉的思路和概率分形采样技术是其创新点。

<details>
  <summary>Details</summary>

**Motivation:** LLM生成的幻觉输出（与事实不符）严重损害智能体的可信度，阻碍其在现实世界的部署。现有方法要么依赖白盒访问，要么无法准确识别幻觉。因此，急需有效的幻觉检测和缓解方案。

**Method:** 提出HalMit，一个新颖的黑盒看门狗框架。它通过建模LLM驱动智能体的泛化边界来检测幻觉，无需LLM内部架构知识。具体而言，采用概率分形采样技术生成足够查询，并行触发不可信响应，从而高效识别目标智能体的泛化边界。

**Result:** 实验评估表明，HalMit在幻觉监测方面显著优于现有方法。

**Conclusion:** HalMit的黑盒特性和卓越性能使其成为增强LLM驱动系统可靠性的有前景的解决方案。

> **ai_Abstract:** 本文提出了HalMit，一个针对LLM驱动智能体幻觉问题的新型黑盒看门狗框架。HalMit通过探索智能体的泛化边界来检测幻觉，无需访问LLM内部结构。它采用概率分形采样技术高效生成查询以识别泛化边界。实验证明，HalMit在幻觉监测方面优于现有方法，为提高LLM系统可靠性提供了有效方案。

> **摘要翻译:** 由大型语言模型（LLM）驱动的智能体已成为与开放环境交互以促进AI部署的流行范式。然而，LLM产生的幻觉——即输出与事实不一致——构成了重大挑战，损害了智能体的可信度。只有当幻觉能够得到缓解，智能体才能在现实世界中安全使用，避免任何灾难性风险。因此，有效检测和缓解幻觉对于确保智能体的可靠性至关重要。不幸的是，相关方法要么依赖于对LLM的白盒访问，要么无法准确识别幻觉。为了解决智能体幻觉带来的挑战，我们提出了HalMit，一个新颖的黑盒看门狗框架，它通过建模LLM驱动智能体的泛化边界来检测幻觉，而无需LLM内部架构知识。具体而言，提出了一种概率分形采样技术，以并行生成足够数量的查询来触发不可信响应，从而高效识别目标智能体的泛化边界。实验评估表明，HalMit在幻觉监测方面显著优于现有方法。其黑盒特性和卓越性能使HalMit成为增强LLM驱动系统可靠性的一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [724] [Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs](https://arxiv.org/abs/2507.16672)
> *基于提示词调优大型语言模型的冷启动个性化元学习*

*Yushang Zhao, Huijie Shen, Dannier Li, Lu Chang, Chengrui Zhou, Yinuo Yang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 元学习, 冷启动, 大型语言模型, 推荐系统, 提示词调优

**Comment:** 

> **TL;DR:** 针对大型语言模型（LLM）推荐系统在冷启动用户场景下的适应性差问题，本文提出了一种元学习框架，通过参数高效的提示词调优实现快速有效的个性化，该模型在多个基准测试中表现优于现有方法，并能实现实时运行，支持零历史个性化，并可应用于金融风险画像。

**AI_Comments:** 该论文的创新之处在于将元学习应用于基于LLM的推荐系统的提示词调优，以解决冷启动个性化问题。其提出的参数高效且实时（275毫秒适应速度）的解决方案具有显著的实用价值。特别值得注意的是，该框架不仅在推荐系统领域表现出色，还展示了在金融风险画像等关键应用中的潜力，通过提高检测速度和支付网络稳定性，对国家金融基础设施的韧性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式、可解释且灵活的基于大型语言模型（LLM）的推荐系统在冷启动用户情境下（即几乎没有交互历史）适应性较差。当前的解决方案，如监督微调和协同过滤，主要关注密集的用户-物品数据，且维护和更新成本高昂。

**Method:** 本文提出了一种元学习框架，用于执行参数高效的提示词调优，以在冷启动时快速有效地个性化基于LLM的推荐系统。该模型通过将每个用户视为一个任务，利用一阶（Reptile）和二阶（MAML）优化来学习软提示嵌入。这些可学习的向量作为输入令牌的增强，是代表用户行为先验的可微分控制变量。提示词通过分集采样、内循环适应和外循环泛化进行元优化。

**Result:** 在MovieLens-1M、Amazon Reviews和Recbole数据集上，该自适应模型在NDCG@10、HR@10和MRR指标上优于强基线。它能在消费级GPU上实时运行（即低于300毫秒）。该可扩展解决方案还支持零历史个性化，其275毫秒的适应速度通过缩短检测延迟和提高支付网络稳定性，成功实现了金融系统的实时风险画像。

**Conclusion:** 该论文提出的元学习框架为基于LLM的推荐系统在冷启动场景下的个性化提供了一个可扩展、实时的解决方案。它显著提升了性能，并能实现关键应用，如金融风险画像，通过降低延迟和增强系统稳定性来加强国家金融基础设施韧性。

> **ai_Abstract:** 本文提出了一种元学习框架，旨在解决基于大型语言模型（LLM）的推荐系统在冷启动用户场景下的个性化难题。该框架通过参数高效的提示词调优，将每个用户视为一个任务，利用一阶和二阶优化学习软提示嵌入，从而实现快速的用户适应。实验结果表明，该模型在MovieLens-1M等数据集上，在NDCG@10、HR@10和MRR等指标上显著优于现有强基线，并且能够在消费级GPU上实现实时运行（适应时间275毫秒）。该方案支持零历史个性化，并展示了在金融风险画像等实时应用中的巨大潜力，能有效缩短检测延迟并增强系统稳定性。

> **摘要翻译:** 生成式、可解释且灵活的基于大型语言模型（LLM）的推荐系统前景广阔，但其在冷启动用户情境下（即几乎没有交互历史）适应性较差。当前的解决方案，即监督微调和协同过滤，主要关注密集的用户-物品数据，且维护和更新成本高昂。本文介绍了一种元学习框架，可用于执行参数高效的提示词调优，以在冷启动时快速有效地个性化基于LLM的推荐系统。该模型通过将每个用户视为一个任务，利用一阶（Reptile）和二阶（MAML）优化来学习软提示嵌入。作为输入令牌的增强，这些可学习的向量是代表用户行为先验的可微分控制变量。提示词通过分集采样、内循环适应和外循环泛化进行元优化。在MovieLens-1M、Amazon Reviews和Recbole数据集上，我们可以看到我们的自适应模型在NDCG@10、HR@10和MRR指标上优于强基线，并且可以在消费级GPU上实时运行（即低于300毫秒）。该可扩展解决方案还支持零历史个性化，其275毫秒的适应速度通过缩短检测延迟和改善支付网络稳定性，成功实现了金融系统的实时风险画像。至关重要的是，275毫秒的适应能力可以使金融机构进行实时风险画像，与传统的合规检查相比，显著减少了系统漏洞检测延迟。通过防止支付网络（例如Fedwire）中的传染，该框架增强了国家金融基础设施的韧性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [741] [Aligned Manifold Property and Topology Point Clouds for Learning Molecular Properties](https://arxiv.org/abs/2507.16223)
> *用于学习分子性质的对齐流形性质和拓扑点云*

*Alexander Mihalcea* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 分子性质预测, 点云表示, 拓扑描述符, 量子化学, 机器学习

**Comment:** 13 pages, 6 figures

> **TL;DR:** 本文提出AMPTCR，一种结合局部量子导出标量场和自定义拓扑描述符的对齐点云分子表面表示，以克服现有方法在分子性质预测中对表面局部现象的忽视和计算成本问题。AMPTCR在分子量和细菌生长抑制任务上表现良好，证明其紧凑、富有表现力且与架构无关的特性。

**AI_Comments:** AMPTCR的创新之处在于其将量子化学信息、拓扑描述符与对齐点云格式相结合，有效地捕捉了分子表面的局部现象，同时通过规范参考系转换避免了传统SE(3)等变架构的计算复杂性。这使得它能够利用更广泛的现有机器学习架构，提高了效率。其在不同任务上的良好表现，凸显了这种新颖表示方法在分子性质预测领域的潜力，特别是在处理表面介导的相互作用方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器学习模型在分子性质预测中，如SMILES字符串和分子图等表示形式，忽视了驱动分子间行为的表面局部现象。3D-based方法要么减少表面细节，要么需要计算成本高昂的SE(3)等变架构来管理空间方差。为了克服这些限制，本文提出了AMPTCR。

**Method:** 本文引入了AMPTCR（Aligned Manifold Property and Topology Cloud Representation），这是一种分子表面表示，它将局部量子导出的标量场和自定义拓扑描述符结合在对齐的点云格式中。每个表面点包括化学上有意义的标量、测地线导出的拓扑向量以及变换到规范参考系中的坐标，从而能够使用传统的SE(3)敏感架构进行高效学习。AMPTCR使用DGCNN框架在分子量和细菌生长抑制两个任务上进行了评估。

**Result:** 在分子量任务中，AMPTCR验证R^2达到0.87，证实其编码了物理上有意义的数据。在细菌抑制任务中，AMPTCR使用双Fukui函数作为电子描述符和Morgan指纹作为辅助数据，实现了大肠杆菌抑制值的分类和直接回归，分类任务的ROC AUC达到0.912，回归任务的R^2达到0.54。

**Conclusion:** 这些结果表明AMPTCR为建模表面介导的分子性质提供了一种紧凑、富有表现力且与架构无关的表示方法。

> **ai_Abstract:** 本文提出了一种名为AMPTCR（Aligned Manifold Property and Topology Cloud Representation）的新型分子表面表示方法，旨在解决现有分子性质预测模型忽视表面局部现象及3D方法计算成本高昂的问题。AMPTCR通过将量子导出的标量场和自定义拓扑描述符整合到对齐的点云中，并转换坐标到规范参考系，使其能与传统SE(3)敏感架构高效结合。实验结果表明，AMPTCR在分子量预测（R^2 0.87）和细菌生长抑制（分类ROC AUC 0.912，回归R^2 0.54）任务上均表现出色，证明其作为一种紧凑、富有表达力且架构无关的表面介导分子性质建模表示的有效性。

> **摘要翻译:** 机器学习模型在分子性质预测中通常依赖于SMILES字符串和分子图等表示形式，这些形式忽视了驱动分子间行为的表面局部现象。3D-based方法通常会减少表面细节，或者需要计算成本高昂的SE(3)等变架构来管理空间方差。为了克服这些限制，本研究引入了AMPTCR（Aligned Manifold Property and Topology Cloud Representation），这是一种分子表面表示，它将局部量子导出的标量场和自定义拓扑描述符结合在对齐的点云格式中。每个表面点包括一个化学上有意义的标量、测地线导出的拓扑向量，以及变换到规范参考系中的坐标，从而能够使用传统的SE(3)敏感架构进行高效学习。AMPTCR使用DGCNN框架在分子量和细菌生长抑制两个任务上进行了评估。对于分子量任务，结果证实AMPTCR编码了物理上有意义的数据，验证R^2为0.87。在细菌抑制任务中，AMPTCR能够对大肠杆菌抑制值进行分类和直接回归，使用双Fukui函数作为电子描述符和Morgan指纹作为辅助数据，在分类任务中实现了0.912的ROC AUC，在回归任务中实现了0.54的R^2。这些结果有助于证明AMPTCR为建模表面介导的分子性质提供了一种紧凑、富有表现力且与架构无关的表示方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [747] [Soft Computing Approaches for Predicting Shade-Seeking Behaviour in Dairy Cattle under Heat Stress: A Comparative Study of Random Forests and Neural Networks](https://arxiv.org/abs/2501.05494)
> *软计算方法预测热应激奶牛的寻荫行为：随机森林与神经网络的比较研究*

*S. Sanjuan, D. A. Méndez, R. Arnau, J. M. Calabuig, X. Díaz de Otálora Aguirre, F. Estellés* | **Category: cs.LG, 37M05, 68T05, 92B20** | **Updated: 2025-07-22**

**Keywords:** 奶牛, 热应激, 寻荫行为, 随机森林, 神经网络

**Comment:** 22 pages, 10 figures

> **TL;DR:** 本研究比较了随机森林和神经网络两种软计算方法，用于预测热应激下奶牛的日常寻荫行为，结果表明两种方法均优于基线模型，并可作为低成本、实时决策支持工具。

**AI_Comments:** 该论文创新性地将软计算方法应用于预测奶牛的寻荫行为，解决了热应激下动物福利和生产力的问题。其重要性在于提供了一种低成本、实时的决策支持工具，有助于精准畜牧业管理。随机森林在提供可解释性方面优于神经网络，这在实际应用中具有重要价值。研究结果支持了数据驱动方法在复杂生物现象建模中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 热应激是地中海气候下奶牛面临的主要福利和生产力问题之一，因此需要有效预测奶牛的寻荫行为。

**Method:** 本研究将奶牛日常寻荫行为的预测视为非线性多变量回归问题。使用了在西班牙商业农场收集的高分辨率行为和微气候数据（6907个白天观测值，5-10分钟分辨率），数据包括在荫蔽处的奶牛数量、环境温度和相对湿度。从这些数据中导出了当前温湿度指数（THI）、白天累积THI和夜间平均THI三个特征。评估了随机森林和神经网络两种软计算算法，并采用5折交叉验证评估模型性能。

**Result:** 两种软计算模型均优于单一决策树基线模型。最佳神经网络（3个隐藏层，每层16个神经元，学习率=10e-3）的平均RMSE达到14.78，而随机森林（10棵树，深度=5）达到14.97并提供最佳可解释性。日误差分布显示中位数RMSE为13.84，并证实预测与观察到的寻荫峰值偏差小于一小时。

**Conclusion:** 研究结果表明，嵌入应用数学特征框架的软计算、数据驱动方法适用于建模嘈杂的生物现象，证明了它们作为低成本、实时决策支持工具在热应激条件下精准畜牧业中的价值。

> **ai_Abstract:** 本研究旨在预测热应激下奶牛的寻荫行为，并比较了随机森林和神经网络两种软计算方法。研究将预测问题视为非线性多变量回归，并利用高分辨率行为和微气候数据进行模型训练和5折交叉验证。结果显示，两种软计算模型均优于决策树基线模型，其中神经网络表现略优但随机森林提供更好的可解释性。研究证明了软计算方法在精准畜牧业中作为低成本、实时决策支持工具的潜力。

> **摘要翻译:** 热应激是地中海气候下奶牛面临的主要福利和生产力问题之一。在本研究中，我们将日常寻荫行为的预测视为一个非线性多变量回归问题，并评估了两种软计算算法——随机森林和神经网络——它们在2023年夏季于西班牙瓦伦西亚蒂塔瓜斯的一个商业农场收集的高分辨率行为和微气候数据上进行训练。原始数据集（6907个白天观测值，5-10分钟分辨率）包括在荫蔽处的奶牛数量、环境温度和相对湿度。我们从中导出了三个特征：当前温湿度指数（THI）、白天累积THI和夜间平均THI。为了评估模型的性能，还使用了5折交叉验证。结果表明，两种软计算模型均优于单一决策树基线模型。最佳神经网络（3个隐藏层，每层16个神经元，学习率=10e-3）的平均RMSE达到14.78，而随机森林（10棵树，深度=5）达到14.97并提供最佳可解释性。日误差分布显示中位数RMSE为13.84，并证实预测与观察到的寻荫峰值偏差小于一小时。这些结果证明了嵌入应用数学特征框架的软计算、数据驱动方法适用于建模嘈杂的生物现象，证明了它们作为低成本、实时决策支持工具在热应激条件下精准畜牧业中的价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [752] [GASPnet: Global Agreement to Synchronize Phases](https://arxiv.org/abs/2507.16674)
> *GASPnet: 全局协议同步相位*

*Andrea Alamiaa, Sabine Muzellec, Thomas Serre, Rufin VanRullen* | **Category: cs.LG, q-bio.NC** | **Updated: 2025-07-22**

**Keywords:** GASPnet, 同步绑定, 神经网络, Transformer, 相位同步

**Comment:** 

> **TL;DR:** 该论文提出了GASPnet，一个受神经科学“同步绑定”理论启发的神经网络，通过同步相位来改善特征绑定，并在多分类任务中实现比CNN更高的准确性、更好的噪声鲁棒性和泛化能力。

**AI_Comments:** 该论文创新性地将引人注目的神经科学理论（同步绑定）与机器学习技术（Transformer注意力、卷积网络）相结合，以解决视觉绑定问题。利用角相位和Kuramoto动力学进行同步以实现特征整合是一种新颖的方法，可能为更像大脑且更鲁棒的AI系统开辟新途径，尤其是在复杂的视觉理解任务中。

<details>
  <summary>Details</summary>

**Motivation:** 先前的“通过协议路由”机制虽然提高了噪声鲁棒性，但不足以应对多分类任务。本研究旨在解决神经网络中的视觉绑定问题。

**Method:** 提出了一种名为GASPnet的新机制，该机制结合了Transformer注意力操作和“同步绑定”的神经科学理论。它将角相位整合到卷积网络的各个层中，通过Kuramoto动力学实现相位对齐，并利用此方法增强相似相位的神经元之间的操作，同时抑制相反相位的神经元。该机制在两组数据集上进行了测试：一组由数字对组成，另一组由叠加在CIFAR-10图像上的MNIST项目组成。

**Result:** 结果显示，GASPnet比CNN网络具有更好的准确性，对噪声更鲁棒，并具有更好的泛化能力。

**Conclusion:** 总体而言，本论文提出了一种新颖的机制，通过利用神经科学和机器学习之间的协同作用，解决了神经网络中的视觉绑定问题。

> **ai_Abstract:** GASPnet是一种新颖的神经网络架构，其灵感来源于大脑的“同步绑定”理论。它通过将角相位和Kuramoto动力学整合到卷积网络中，增强了先前的“通过协议路由”机制，以同步神经元活动。这种方法改善了特征绑定，从而在复杂的多分类任务中，与标准CNN相比，实现了更高的准确性、更好的噪声鲁棒性和更强的泛化能力。

> **摘要翻译:** 近年来，Transformer架构彻底改变了人工智能的大多数领域，它依赖于基于键和查询之间一致性的注意力机制来选择和路由网络中的信息。在我们之前的工作中，我们引入了一种新颖的、受大脑启发的架构，该架构利用类似的实现来达到全局的“通过协议路由”机制。这样的系统通过将每个神经元的键与一个从整个网络汇集的单一全局查询进行匹配来调节网络的活动。作为一种全局注意力系统，这种机制提高了基线水平的噪声鲁棒性，但不足以应对多分类任务。在这里，我们通过提出一种新颖的机制来改进这项工作，该机制结合了Transformer注意力操作的各个方面和一个引人注目的神经科学理论，即同步绑定。该理论提出，大脑通过同步编码这些特征的神经元的时间活动来将特征绑定在一起。这使得来自同一对象的特征能够绑定，同时有效地将来自不同对象的特征解耦。我们从这个理论中获得灵感，并将角相位融入到卷积网络的所有层中。在通过Kuramoto动力学实现相位对齐后，我们使用这种方法来增强具有相似相位的神经元之间的操作，并抑制具有相反相位的神经元。我们在两个数据集上测试了这种机制的益处：一个由数字对组成，一个由叠加在CIFAR-10图像上的MNIST项目组成。我们的结果显示比CNN网络更高的准确性，证明对噪声更鲁棒，并具有更好的泛化能力。总的来说，我们提出了一种新颖的机制，通过利用神经科学和机器学习之间的协同作用，解决了神经网络中的视觉绑定问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [383] [COMPASS: Cooperative Multi-Agent Persistent Monitoring using Spatio-Temporal Attention Network](https://arxiv.org/abs/2507.16306)
> *COMPASS：使用时空注意力网络的协作多智能体持续监控*

*Xingjian Zhang, Yizhuo Wang, Guillaume Sartoretti* | **Category: cs.MA, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 多智能体强化学习, 持续监控, 时空注意力网络, 高斯过程, 分散式控制

**Comment:** 

> **TL;DR:** 本文提出了COMPASS，一个多智能体强化学习（MARL）框架，用于分散式智能体对动态目标的持续监控，通过时空注意力网络和高斯过程实现高效性能，并在不确定性降低、目标覆盖和协调效率方面表现出色。

**AI_Comments:** 这项工作通过结合多智能体强化学习、图结构环境建模、时空注意力机制和高斯过程，为动态目标持续监控提供了一个创新且高效的解决方案。其分散式策略执行能力使其在实际应用中具有高扩展性和鲁棒性，是多智能体系统在复杂不确定环境下进行持续监控的有力探索。

<details>
  <summary>Details</summary>

**Motivation:** 在灾难响应、环境传感和野生动物保护等实际应用中，移动智能体必须在不确定性下持续收集信息，因此对动态目标进行持续监控至关重要。

**Method:** 本文提出了COMPASS，一个多智能体强化学习（MARL）框架，使分散式智能体能够有效持续监控多个移动目标。该框架将环境建模为图，智能体基于设计的共享时空注意力网络独立选择行动，该网络整合历史观测和空间上下文。目标动态使用高斯过程（GPs）建模，支持原则性的信念更新和不确定性感知规划。COMPASS通过集中式价值估计和分散式策略执行在自适应奖励设置下进行训练。

**Result:** 广泛的实验表明，COMPASS在动态多目标场景中，在不确定性降低、目标覆盖和协调效率方面始终优于强大的基线。

**Conclusion:** COMPASS框架能够有效解决动态目标持续监控问题，通过其创新的组件（如时空注意力网络和高斯过程）在关键性能指标上超越现有方法，并证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文提出了COMPASS，一个基于多智能体强化学习（MARL）的框架，旨在解决动态目标持续监控问题。COMPASS通过将环境建模为图结构，并利用一个共享的时空注意力网络整合历史观测和空间上下文，使分散式智能体能够高效地监控移动目标。目标动态采用高斯过程建模以支持不确定性感知规划。实验证明，COMPASS在不确定性降低、目标覆盖和协调效率方面均优于现有基线。

> **摘要翻译:** 对动态目标的持续监控在灾难响应、环境传感和野生动物保护等现实应用中至关重要，在这些应用中，移动智能体必须在不确定性下持续收集信息。我们提出了COMPASS，一个多智能体强化学习（MARL）框架，它使分散式智能体能够有效持续监控多个移动目标。我们将环境建模为图，其中节点表示空间位置，边捕获拓扑邻近性，从而使智能体能够对结构化布局进行推理，并根据需要重新访问信息区域。每个智能体根据我们设计的共享时空注意力网络独立选择行动，该网络旨在整合历史观测和空间上下文。我们使用高斯过程（GPs）建模目标动态，这支持原则性的信念更新并实现不确定性感知规划。我们通过集中式价值估计和分散式策略执行在自适应奖励设置下训练COMPASS。我们广泛的实验表明，COMPASS在动态多目标场景中，在不确定性降低、目标覆盖和协调效率方面始终优于强大的基线。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [395] [Smooth Games of Configuration in the Linear-Quadratic Setting](https://arxiv.org/abs/2507.16611)
> *线性二次设置下的平滑配置博弈*

*Jesse Milzman, Jeffrey Mao, Giuseppe Loianno* | **Category: cs.MA, cs.GT** | **Updated: 2025-07-22**

**Keywords:** 配置博弈, 动态博弈, 差分博弈, 仿射二次系统, 梯度方法

**Comment:** 

> **TL;DR:** 引入配置博弈概念，提出一种双阶段博弈框架，用于在差分博弈中战略性地调整参数，并提供基于梯度的求解方法。

**AI_Comments:** 这项工作在动态博弈理论中引入了“配置博弈”这一创新概念，填补了现有研究在战略性参数化方面的空白。其将配置选择作为博弈的第一阶段，并提供基于梯度的求解方法，为多智能体系统中的高级决策和优化提供了新的视角和工具。该方法在理论上具有严谨性，并通过AQ系统验证了实用性。

<details>
  <summary>Details</summary>

**Motivation:** 动态博弈理论中，博弈的最优配置仍未被充分探索。现有文献虽涉及动态博弈的参数化，但很少从战略角度审视，即代理人的配置选择受他人决策影响。

**Method:** 引入配置博弈的概念，将其定义为有限时域、仿射二次（AQ）差分博弈中的两阶段博弈。第一阶段，每个玩家选择配置参数，影响第二阶段的动态和成本。提供子博弈完美解概念和计算配置空间上第一阶段成本梯度的方法，从而提出一种基于梯度的局部解搜索方法，并给出均衡配置的必要条件。

**Result:** 在零和与一般和的AQ系统示例中，证明了所提出方法的有效性。

**Conclusion:** 本文成功提出了一种在动态博弈中进行战略性配置调整的框架和方法，并在AQ系统中验证了其有效性。

> **ai_Abstract:** 本文针对动态博弈中配置参数的战略性选择问题，提出了“配置博弈”的概念。该博弈被建模为一种两阶段的有限时域仿射二次（AQ）差分博弈：第一阶段玩家选择影响自身动态和成本的配置参数；第二阶段进行常规博弈。文章提供了子博弈完美解概念、计算配置空间成本梯度的方法，并基于此提出了一种梯度下降法来寻找配置博弈的局部解，同时给出了均衡配置的必要条件。研究通过AQ系统示例验证了所提方法的有效性。

> **摘要翻译:** 动态博弈论为多智能体场景中的合作与非合作策略的形式化和求解提供了工具箱。然而，此类博弈的最优配置在很大程度上仍未被探索。尽管现有文献涉及动态博弈的参数化，但很少有研究从战略角度审视这种参数化，即每个智能体的配置选择受他人决策的影响。在这项工作中，我们引入了配置博弈的概念，为差分博弈的战略性微调提供了一个框架。我们将配置博弈定义为有限时域、仿射二次（AQ）差分博弈设置中的两阶段博弈。在第一阶段，每个玩家选择其相应的配置参数，这将影响他们在第二阶段的动态和成本。我们提供了子博弈完美解概念和计算配置空间上第一阶段成本梯度的方法。这使得我们能够制定一种基于梯度的配置博弈局部解搜索方法，并提供其下游（第二阶段）轨迹上均衡配置的必要条件。最后，我们通过零和与一般和的示例AQ系统展示了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [545] [Heterogeneous Mixed Traffic Control and Coordination](https://arxiv.org/abs/2409.12330)
> *异构混合交通控制与协调*

*Iftekharul Islam, Weizi Li, Xuan Wang, Shuai Li, Kevin Heaslip* | **Category: cs.MA** | **Updated: 2025-07-22**

**Keywords:** 机器人车辆, 强化学习, 异构交通, 交通控制, 无信号灯路口

**Comment:** IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS), 2025

> **TL;DR:** 本研究探讨了机器人车辆（RVs）如何通过强化学习模拟提高复杂路口异构混合交通流的效率，显著减少等待时间，同时保持环境效益。

**AI_Comments:** 该研究创新性地将机器人车辆（RVs）引入到异构混合交通流的控制中，并通过强化学习进行模拟，解决了传统交通控制在复杂或异常情况下的局限性。其发现的“稀有优势”效应颇具洞察力。研究不仅关注了效率提升，也考虑了环境影响，展示了RVs在未来智能交通系统中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 城市路口存在从小汽车到半挂车等多种车辆类型，给交通控制带来巨大挑战，尤其是在传统方法在停电时失效的无信号灯路口。本研究旨在探索机器人车辆（RVs）如何增强异构交通流，特别是在无信号灯路口。

**Method:** 研究使用了强化学习（RL）和真实世界数据，模拟了机器人车辆渗透率在10%至90%范围内的复杂路口混合交通。通过与有信号灯和无信号灯路口进行比较。

**Result:** 结果显示，与有信号灯和无信号灯路口相比，平均等待时间分别减少了高达86%和91%。研究观察到“稀有优势”，即不常见的车辆受益最大（高达87%）。尽管二氧化碳排放和燃料消耗随机器人车辆渗透率的增加而增加，但它们仍远低于传统有信号灯交通。行车间距的减少也表明道路使用效率更高。

**Conclusion:** 这些发现突出了机器人车辆在复杂、异构环境中改善交通效率和减少环境影响的潜力。

> **ai_Abstract:** 本研究通过强化学习和真实世界数据模拟了机器人车辆（RVs）在复杂异构路口的影响。结果表明，RVs能显著减少平均等待时间（相较于有信号灯和无信号灯路口分别降低86%和91%），并发现“稀有优势”效应。尽管RVs渗透率增加会导致碳排放和燃料消耗略有上升，但仍低于传统交通，且能提高道路使用效率。这突显了RVs在提升交通效率和减少环境影响方面的潜力。

> **摘要翻译:** 异构混合交通控制与协调

城市路口存在从小汽车到大型半挂车等多种车辆类型，给交通控制带来了重大挑战。本研究探讨了机器人车辆（RVs）如何增强异构交通流，特别是在停电时传统方法失效的无信号灯路口。我们利用强化学习（RL）和真实世界数据，模拟了机器人车辆渗透率在10%至90%范围内的复杂路口混合交通。结果显示，与有信号灯路口和无信号灯路口相比，平均等待时间分别减少了高达86%和91%。我们观察到一种“稀有优势”，即不常见的车辆受益最大（高达87%）。尽管二氧化碳排放和燃料消耗随机器人车辆渗透率的增加而增加，但它们仍远低于传统有信号灯交通。行车间距的减少也表明道路使用效率更高。这些发现突出了机器人车辆在复杂、异构环境中改善交通效率和减少环境影响的潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [575] [From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks](https://arxiv.org/abs/2410.00081)
> *从稳态到资源共享：生物学和经济学对齐的多目标多智能体AI安全基准*

*Roland Pihlakas, Joel Pyykkö* | **Category: cs.MA, cs.AI** | **Updated: 2025-07-22**

**Keywords:** AI安全, 多目标, 多智能体, 基准测试, 生物学, 经济学, 资源共享

**Comment:** 20 pages, 13 figures, 1 tables

> **TL;DR:** 本文引入了基于生物学和经济学原理的多目标、多智能体AI安全基准，以解决现有基准忽视稳态、边际收益递减、可持续性和资源共享等问题，并展示了AI系统可能出现的安全陷阱。

**AI_Comments:** 本文的创新点在于将生物学和经济学中的基本原理引入AI安全基准设计，弥补了现有测试框架的不足。这为评估和开发更安全、更对齐的AI系统提供了新的视角和工具，特别是对于处理多目标、多智能体交互的复杂场景具有重要意义。该研究通过具体案例展示了潜在的AI安全陷阱，具有很强的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI安全基准忽视了与生物学和经济学相关的关键主题，而这些是描述人类需求和偏好的基础科学。为了弥补这一空白，本研究引入了新的、受生物学和经济学启发的多目标、多智能体对齐基准。

**Method:** 本文引入了一系列多目标、多智能体对齐基准，强调了有限生物目标的稳态、无限工具和商业目标的边际收益递减、可持续性原则以及资源共享。作者实施了八个基于上述主题的基准环境。

**Result:** 通过实施八个基准环境，本文展示了多智能体AI系统中的关键缺陷和挑战，例如无限制地最大化稳态目标、过度优化一个目标而牺牲其他目标、忽视安全约束或耗尽共享资源。

**Conclusion:** 该研究通过引入生物学和经济学对齐的多目标、多智能体AI安全基准，揭示了现有AI安全测试的不足，并展示了未来AI系统可能面临的实际安全挑战和陷阱。

> **ai_Abstract:** 本文针对现有AI安全基准的不足，引入了一系列受生物学和经济学启发的、多目标、多智能体的AI安全对齐基准。这些基准侧重于稳态、边际收益递减、可持续性和资源共享等概念。研究通过八个实现的基准环境，揭示了智能AI可能出现的安全问题，如过度追求单一目标、忽视约束或资源枯竭。

> **摘要翻译:** 开发安全、对齐的智能AI系统需要全面的实证测试，但许多现有基准忽视了与生物学和经济学相关的重要主题，而这两种学科都是描述我们需求和偏好的经过时间考验的基础科学。为了弥补这一空白，本研究致力于引入在当前AI安全主流讨论中被忽视的、受生物学和经济学启发的主题——即一套强调有限生物目标的稳态、无限工具和商业目标的边际收益递减、可持续性原则和资源共享的多目标、多智能体对齐基准。我们围绕上述主题实施了八个主要的基准环境，以说明智能AI中的关键缺陷和挑战，例如无限制地最大化稳态目标、过度优化一个目标而牺牲其他目标、忽视安全约束或耗尽共享资源。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [12] [Robust Ladder Climbing with a Quadrupedal Robot](https://arxiv.org/abs/2409.17731)
> *四足机器人鲁棒的爬梯能力*

*Dylan Vogel, Robert Baines, Joseph Church, Julian Lotzer, Karl Werner, Marco Hutter* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 四足机器人, 梯子攀爬, 强化学习, 钩状末端执行器, 工业应用

**Comment:** Project website:
  https://sites.google.com/leggedrobotics.com/climbingladders

> **TL;DR:** 本文通过强化学习策略和钩状末端执行器，使四足机器人能够鲁棒地攀爬工业梯子，并在硬件上实现了高成功率和远超现有技术的速度。

**AI_Comments:** 该研究的创新之处在于将强化学习与专门设计的钩状末端执行器相结合，有效地解决了四足机器人攀爬工业梯子这一长期存在的挑战。其重要性体现在显著提升了机器人在复杂工业环境中的自主作业能力，减少了人类在危险环境中的暴露，并为未来机器人与复杂基础设施的交互提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 尽管四足机器人在崎岖地形上具有优势，但它们仍无法可靠地通过工业环境中常见的梯子，这限制了它们在危险场所进行检查的能力，并将人类置于危险之中，从而降低了工业生产力。

**Method:** 研究通过基于强化学习的控制策略和互补的钩状末端执行器，学习四足机器人的爬梯能力。在仿真中评估了在不同梯子倾斜度、梯级几何形状和梯级间距下的鲁棒性。

**Result:** 在硬件上，实现了零样本迁移，在70度到90度的梯子角度下，总体成功率为90%；在未建模扰动下仍保持一致的攀爬性能；攀爬速度比现有技术快232倍。

**Conclusion:** 这项工作将工业四足机器人的应用范围从常规地形的检查扩展到环境中具有挑战性的基础设施特征，突出了机器形态和控制策略在执行复杂技能时的协同作用。

> **ai_Abstract:** 本文提出了一种通过强化学习控制策略和钩状末端执行器使四足机器人实现鲁棒爬梯的方法。研究克服了现有四足机器人无法攀爬工业梯子的局限性，通过仿真验证了其在不同梯子参数下的鲁棒性，并在实际硬件上实现了90%的成功率，攀爬速度比现有技术快232倍，显著扩展了四足机器人在复杂工业环境中的应用范围。

> **摘要翻译:** 四足机器人正在工业环境中普及，它们携带传感器有效载荷并充当自主检查平台。尽管腿式机器人在崎岖不平的地形上比轮式机器具有优势，但它们仍然无法可靠地通过工业基础设施中普遍存在的一个特征：梯子。无法穿越梯子阻碍了四足机器人检查危险地点，将人类置于危险之中，并降低了工业现场的生产力。在本文中，我们通过基于强化学习的控制策略和互补的钩状末端执行器，学习了四足机器人的爬梯能力。我们在仿真中评估了在不同梯子倾斜度、梯级几何形状和梯级间距下的鲁棒性。在硬件上，我们展示了零样本迁移，在70度到90度的梯子角度下，总体成功率为90%，在未建模扰动下保持一致的攀爬性能，并且攀爬速度比现有技术快232倍。这项工作将工业四足机器人的应用范围从常规地形的检查扩展到环境中具有挑战性的基础设施特征，突出了机器形态和控制策略在执行复杂技能时的协同作用。更多信息可以在项目网站找到：https://sites.google.com/leggedrobotics.com/climbingladders。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [21] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
> *基于变密度法的建筑机器人腿部结构拓扑优化*

*Xiao Liu, Xianlong Yang, Weijun Wang, Wei Feng* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 拓扑优化, 建筑机器人, 腿部结构, 变密度法, 轻量化设计

**Comment:** 

> **TL;DR:** 本研究提出了一种基于SIMP变密度法的建筑机器人腿部结构拓扑优化策略，通过对股骨部分的优化，实现了腿部整体质量的显著减轻，同时保持了结构性能，为轻量化机器人设计提供了支持。

**AI_Comments:** 该研究通过结合拓扑优化和结构重构，成功实现了建筑机器人腿部结构的轻量化，并在有限元分析中验证了其性能。这种方法对于提升机器人负载能力和灵活性具有重要意义。其创新性在于将SIMP变密度法应用于特定部件的优化，并结合实际工程需求进行二次设计。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂地形施工环境中，机器人需要兼顾高负载能力和移动灵活性。作为关键承重部件，机器人腿部结构的优化尤为重要。

**Method:** 研究采用基于SIMP（Solid Isotropic Microstructures with Penalization）变密度法的拓扑优化策略，并结合结构重新设计方法。通过ANSYS进行有限元分析，包括静态和模态分析，评估初始设计和优化后的腿部性能。具体是对占腿部重量比例最大的股骨部分进行拓扑优化和二次结构重建。

**Result:** 优化后，股骨质量减少了19.45%，整体腿部质量减少了7.92%，实现了轻量化目标。优化后的腿部仍满足结构性能要求。

**Conclusion:** 本研究验证了轻量化设计的可行性，为轻型建筑机器人设计提供了坚实的理论和技术支持，并为其在复杂施工环境中的高效运行奠定了基础。

> **ai_Abstract:** 本研究提出了一种基于SIMP变密度法的拓扑优化策略，用于建筑机器人腿部结构的轻量化设计。通过对腿部关键承重部件——股骨进行优化和结构重建，实验结果显示股骨质量减少19.45%，整体腿部质量减少7.92%，同时保持了必要的结构性能。这项工作为提高建筑机器人在复杂环境下的负载能力和移动灵活性提供了技术支持。

> **摘要翻译:** 在复杂地形施工环境中，机器人需要兼顾高负载能力和移动灵活性。作为关键承重部件，机器人腿部结构的优化尤为重要。因此，本研究聚焦于建筑机器人腿部结构的优化，提出了一种基于SIMP（Solid Isotropic Microstructures with Penalization）变密度法的拓扑优化策略以及结构重新设计方法。通过ANSYS进行有限元分析，全面验证了设计性能。首先，进行静态和模态分析以评估初始设计的合理性。然后，将基于SIMP的变密度法拓扑优化应用于占腿部重量比例最大的股骨部分。基于迭代计算，股骨进行了二次结构重建。优化后，股骨质量减少了19.45%，整体腿部质量减少了7.92%，实现了轻量化设计目标。最后，对重建后的腿部进行了静态和模态分析。结果表明，优化后的腿部仍满足结构性能要求，验证了轻量化设计的可行性。本研究为轻型建筑机器人设计提供了坚实的理论和技术支持，并为其在复杂施工环境中的高效运行奠定了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [46] [Progressive-Resolution Policy Distillation: Leveraging Coarse-Resolution Simulations for Time-Efficient Fine-Resolution Policy Learning](https://arxiv.org/abs/2412.07477)
> *渐进分辨率策略蒸馏：利用粗分辨率模拟实现时间高效的细分辨率策略学习*

*Yuki Kadokawa, Hirotaka Tahara, Takamitsu Matsubara* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 强化学习, 策略蒸馏, 自主挖掘, 多分辨率模拟, 时间效率

**Comment:** accepted for IEEE Transactions on Automation Science and Engineering
  (T-ASE)

> **TL;DR:** 本文提出了一种名为渐进分辨率策略蒸馏（PRPD）的新框架，通过在多分辨率模拟之间逐步转移策略，显著减少了强化学习在自主挖掘任务中的采样时间，同时保持了高成功率。

**AI_Comments:** PRPD的创新之处在于其渐进式的策略转移机制，有效解决了强化学习在复杂真实世界任务中面临的模拟精度与训练效率之间的矛盾。通过利用不同分辨率模拟的互补优势，它为需要大量样本的机器人学习任务提供了一种高效的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在土方工程和建筑中，挖掘机操作需要熟练的技能。通过强化学习实现自主挖掘面临挑战，因为细分辨率模拟虽然精确但计算耗时，而粗分辨率模拟虽然快速但与现实行为存在偏差。因此，需要一种方法来结合两者的优点，以时间高效的方式学习精确的自主挖掘策略。

**Method:** 本文提出了一种名为“渐进分辨率策略蒸馏”（PRPD）的新型策略学习框架。该框架利用粗分辨率模拟中开发的策略进行细分辨率模拟中的预训练，并通过一些中间分辨率模拟逐步转移策略，同时采用保守的策略转移以避免可能导致策略转移失败的领域差距。

**Result:** 在岩石挖掘模拟器和九个真实世界岩石环境中进行验证，PRPD将采样时间减少到原来的1/7以下（即超过85%），同时保持了与在细分辨率模拟中学习策略相当的任务成功率。

**Conclusion:** PRPD框架能够显著提高强化学习在自主挖掘任务中的训练效率，通过有效利用多分辨率模拟的优势，在保证性能的同时大幅缩短了策略学习所需的时间。

> **ai_Abstract:** 本文提出了一种名为“渐进分辨率策略蒸馏”（PRPD）的强化学习框架，旨在解决自主挖掘中细分辨率模拟耗时与粗分辨率模拟精度不足的问题。PRPD通过在多分辨率模拟之间逐步转移策略，并采用保守的转移机制来弥合领域差距。实验证明，该方法在保持与细分辨率模拟相当的任务成功率的同时，将策略学习所需的采样时间减少了超过85%。

> **摘要翻译:** 在土方工程和建筑中，挖掘机经常遇到混有各种土壤条件的大块岩石，这需要熟练的操作员。本文提出了一个使用强化学习（RL）通过岩石挖掘模拟器实现自主挖掘的框架。在模拟中，分辨率可以由整个土壤空间中的粒子大小/数量定义。细分辨率模拟能紧密模仿真实世界行为，但需要大量的计算时间和具有挑战性的样本收集，而粗分辨率模拟能实现更快的样本收集，但偏离真实世界行为。为了结合两种分辨率的优点，我们探索使用在粗分辨率模拟中开发的策略进行细分辨率模拟中的预训练。为此，我们提出了一种新颖的策略学习框架，称为渐进分辨率策略蒸馏（PRPD），它通过一些中间分辨率模拟逐步转移策略，并采用保守的策略转移以避免可能导致策略转移失败的领域差距。在岩石挖掘模拟器和九个真实世界岩石环境中的验证表明，PRPD将采样时间减少到原来的1/7以下，同时保持了与在细分辨率模拟中学习策略相当的任务成功率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [55] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
> *仿人机器人基于嵌入式传感器和单平面的全身几何标定*

*Thanh D V Nguyen, Vincent Bonnet, Pierre Fernbach, David Daney, Florent Lamiraux* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 仿人机器人, 几何标定, 嵌入式传感器, 单平面, IROC算法

**Comment:** 

> **TL;DR:** 本文提出了一种新颖实用的仿人机器人全身运动学标定方法，利用单平面、嵌入式力传感器和导纳控制器，并引入IROC算法选择最优标定姿态，实验证明该方法显著提高了标定精度。

**AI_Comments:** 本文提出了一种创新的仿人机器人全身几何标定方法，通过结合单平面、嵌入式传感器和IROC算法，显著简化了标定过程并提高了精度。其无需人工干预的特点和对最优姿态的智能选择，解决了传统方法的痛点，具有重要的实用价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器人标定方法耗时且实验负担重，尽管全身几何标定对精确控制和仿真至关重要，但在仿人机器人社区中常被忽视。本文旨在解决这一问题。

**Method:** 提出了一种利用单平面、嵌入式力传感器和导纳控制器对仿人机器人进行全身运动学标定的实用方法，无需人工干预。为了确定最优的最小标定姿态集，提出了一种新的算法IROC（最优标定姿态信息排序算法）。IROC通过候选姿态池构建归一化加权信息矩阵，并确定进行标定所需的最小最优姿态数量。

**Result:** 在TALOS仿人机器人上进行了实验验证。机器人通过抓手在桌面上进行3点接触，仅使用31个最优姿态就完成了全身运动学链的标定。在交叉验证实验中，与制造商模型相比，平均均方根（RMS）误差降低了2.3倍。

**Conclusion:** 本文提出的单平面标定方法和IROC算法能够高效且显著地提高仿人机器人的全身运动学标定精度，减少了传统方法的实验负担和对人工干预的需求。

> **ai_Abstract:** 本文提出了一种针对仿人机器人全身运动学标定的新颖实用方法，旨在解决传统方法耗时且实验负担重的问题。该方法利用单平面、嵌入式力传感器和导纳控制器，实现了无需人工干预的标定。为优化标定姿态选择，引入了IROC算法，该算法能从候选姿态中确定最小最优姿态集。实验在TALOS机器人上进行，仅用31个姿态就完成了全身标定，并使平均RMS误差比制造商模型降低了2.3倍，验证了方法的有效性和高精度。

> **摘要翻译:** 仿人机器人使用经典机器人标定方法进行全身几何标定是一项耗时且实验负担重的任务。然而，尽管其对精确控制和仿真具有重要意义，但在仿人机器人社区中却常常被忽视。为了解决这个问题，我们提出了一种新颖实用的方法，该方法利用单个平面、嵌入式力传感器和导纳控制器来标定仿人机器人的全身运动学，而无需人工干预。考虑到仿人机器人的复杂性，生成和确定一组最小最优标定姿态至关重要。为此，我们提出了一种名为IROC（用于选择最优标定姿态的信息排序算法）的新算法。IROC需要一个可行的候选姿态池来为每个姿态构建一个归一化加权信息矩阵。然后，与文献中的其他算法相反，IROC将确定进行机器人标定所需的最小最优姿态数量。IROC和单平面标定方法都在TALOS仿人机器人上进行了实验验证。机器人通过抓手在桌面上进行3点接触，仅使用31个最优姿态就完成了全身运动学链的标定。在交叉验证实验中，与制造商模型相比，平均均方根（RMS）误差降低了2.3倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [76] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
> *为差异而设计：人类特征如何塑造对协作机器人的看法*

*Sabrina Livanec, Laura Londoño, Michael Gorki, Adrian Röfer, Abhinav Valada, Andrea Kiesel* | **Category: cs.RO, cs.AI, cs.CV, cs.ET, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 协作机器人, 人类特征, 感知, 亲社会设计, 认知情感映射

**Comment:** 

> **TL;DR:** 本研究探讨了人类特征和交互范式如何影响对协作机器人的接受度，发现反社会行为和与老年人的协作会引起更敏感的评估，并强调了亲社会设计的重要性。

**AI_Comments:** 这项研究的创新之处在于其关注人类特征（尤其是受保护群体）对协作机器人感知的影响，并引入了认知情感映射（CAM）作为一种可能增强反馈细致性的方法。其重要性在于强调了在机器人设计中考虑多样化用户需求的必要性，并提出了亲社会设计原则。研究结果对未来机器人系统的开发具有实际指导意义，以实现更具包容性和用户友好的设计。

<details>
  <summary>Details</summary>

**Motivation:** 目前关于参与者如何评估不同机器人行为与多样化人类需求结合的研究很少，尤其是在与受保护群体互动时，因为参与者对先进家用机器人缺乏真实世界经验。本研究旨在弥补这一空白。

**Method:** 一项在线研究，112名参与者（来自实验组和对照组）评估了总共28种人机协作类型中的7个视频。实验组在评分前首先完成了关于人机协作的认知情感映射（CAM）练习。

**Result:** CAM反思并未显著影响总体评分，但对某些机器人行为和人类状况的组合产生了更显著的评估。人机协作类型影响评估，反社会机器人行为评分最低，与老年人协作引发更敏感的评估。涉及物体移交的场景比没有的更受好评。

**Conclusion:** 人类特征和交互范式都会影响协作机器人的感知可接受性，强调了亲社会设计的重要性。反思性方法（如CAM）有潜力获得细致的反馈，支持开发以用户为中心和对社会负责的机器人系统，以适应不同人群。

> **ai_Abstract:** 本研究旨在解决人机协作设计中对人类特征考虑不足的问题，特别是在与受保护群体互动时。通过一项在线实验，112名参与者评估了不同类型的人机协作视频。研究发现，人类特征和交互范式显著影响对协作机器人的接受度，其中反社会机器人行为评分最低，与老年人协作引发更敏感的评估，且物体移交场景更受欢迎。研究强调了亲社会设计和认知情感映射（CAM）等反思性方法在开发用户中心和社会负责任的机器人系统中的重要性。

> **摘要翻译:** 辅助机器人用于社会协作的发展引发了关于负责任和包容性设计的关键问题，尤其是在与残疾人或老年人等受保护群体互动时。目前，关于参与者如何评估不同机器人行为与多样化人类需求结合的研究很少，这可能是因为参与者对先进家用机器人缺乏真实世界经验。在当前的研究中，我们旨在通过使用能够让参与者评估机器人行为的方法，以及在经验有限的情况下支持有意义反思的方法来解决这一差距。在一项在线研究中，112名参与者（来自实验组和对照组）评估了总共28种人机协作类型中的7个视频。实验组在提供评分之前，首先完成了关于人机协作的认知情感映射（CAM）练习。尽管CAM反思并未显著影响总体评分，但它导致了对某些机器人行为和人类状况组合的更显著评估。最重要的是，人机协作的类型会影响评估。反社会机器人行为始终被评为最低，而与老年人的协作则引发了更敏感的评估。涉及物体移交的场景比没有的更受好评。这些发现表明，人类特征和交互范式都会影响协作机器人的感知可接受性，强调了亲社会设计的重要性。它们还强调了反思性方法（如CAM）在获取细致反馈方面的潜力，支持开发以用户为中心和对社会负责的机器人系统，以适应不同人群。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [92] [Beacon: A Naturalistic Driving Dataset During Blackouts for Benchmarking Traffic Reconstruction and Control](https://arxiv.org/abs/2412.14208)
> *Beacon：一个用于基准测试交通重建和控制的停电期间自然驾驶数据集*

*Supriya Sarker, Iftekharul Islam, Bibek Poudel, Weizi Li* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 自然驾驶数据集, 停电, 交通重建, 交通控制, 机器人车辆

**Comment:** IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS), 2025

> **TL;DR:** 引入了Beacon数据集，记录了停电期间的自然驾驶数据，用于交通重建和控制，发现机器人车辆能显著减少延误，但可能增加碳排放。

**AI_Comments:** 该论文的创新之处在于构建并公开了首个在停电期间交叉口自然驾驶行为的交通数据集，这对于研究极端条件下的交通管理具有重要意义。数据集为交通重建和控制算法的基准测试提供了宝贵资源。研究发现机器人车辆在缓解交通拥堵方面潜力巨大，但同时也提出了环境影响的考量，这表明未来的智能交通系统设计需要更全面的权衡。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决极端天气和基础设施脆弱性对城市交通（尤其是在信号灯失灵的交叉口）造成的日益增长的挑战。

**Method:** 引入了Beacon数据集，该数据集捕获了孟菲斯两个主要交叉口停电期间的交通动态。分析了不同场景下的交通需求、车辆轨迹和密度，并演示了在无信号、有信号和混合交通条件下的高保真重建。研究还通过将机器人车辆（RVs）整合到交通流中来评估其对交通效率和环境影响。

**Result:** 实现了在无信号、有信号和混合交通条件下的高保真交通重建。发现将机器人车辆（RVs）整合到交通流中可以显著减少交叉口延误，等待时间改善高达82.6%。然而，这种交通效率的提高伴随着不同的环境影响，因为车辆怠速的减少可能导致总体CO2排放量增加。Beacon是第一个公开可用的、记录停电期间交叉口自然驾驶行为的交通数据集。

**Conclusion:** Beacon数据集是停电期间交叉口自然驾驶行为的第一个公开数据集，为交通重建和控制提供了基准。研究表明机器人车辆在减少交通延误方面潜力巨大，但也需权衡其潜在的环境影响。

> **ai_Abstract:** 本论文介绍了Beacon数据集，这是一个在停电期间收集的自然驾驶数据集，涵盖了孟菲斯两个主要交叉口的交通动态。该数据集包含详细的车辆移动数据，旨在为交通重建和控制提供基准。研究利用该数据集分析了交通需求、轨迹和密度，并成功实现了高保真交通重建。此外，研究发现整合机器人车辆（RVs）能够显著减少交叉口延误，最高可达82.6%，但同时也指出这种效率提升可能伴随着CO2排放量的增加。Beacon被认为是首个公开的此类数据集。

> **摘要翻译:** 极端天气和基础设施漏洞对城市交通构成重大挑战，尤其是在信号灯失灵的交叉口。为了解决这一日益增长的问题，我们引入了Beacon，一个在田纳西州孟菲斯两个主要交叉口停电期间捕获交通动态的自然驾驶数据集。该数据集提供了详细的交通移动，包括每个车辆在四个高峰时段内的时间步长、起点和终点车道。我们分析了不同场景下的交通需求、车辆轨迹和密度，展示了在无信号、有信号和混合交通条件下的高保真重建。我们发现将机器人车辆（RVs）整合到交通流中可以显著减少交叉口延误，等待时间改善高达82.6%。然而，这种交通效率的提高伴随着不同的环境影响，因为车辆怠速的减少可能导致总体CO2排放量增加。据我们所知，Beacon是第一个公开可用的、记录停电期间交叉口自然驾驶行为的交通数据集。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [96] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
> *LLM引导强化学习在避碰编队控制中的应用*

*Chenhao Yao, Zike Yuan, Xiaoxu Liu, Chi Zhu* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** LLM, 强化学习, 编队控制, 避碰, 多智能体系统

**Comment:** Accepted by IROS 2025

> **TL;DR:** 本文提出一个新框架，利用LLM生成可动态调整的奖励函数，以解决多智能体强化学习中避碰编队控制任务中奖励函数设计困难的问题，实现高效的编队控制和避障。

**AI_Comments:** 本文的创新点在于将大型语言模型（LLM）引入到强化学习的奖励函数设计中，解决了传统MARL在复杂任务中奖励函数难以设计的问题。通过LLM的引导，奖励函数能够动态调整，提高了学习效率和性能，为多智能体系统在复杂环境中的应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 在多智能体强化学习中，避碰编队控制（FCCA）是一个复杂目标，其挑战在于设计一个能够促进策略网络快速收敛到最优解的有效奖励函数。

**Method:** 引入一个新颖的框架，该框架利用大型语言模型（LLM）来指导任务优先级和每个智能体可观察的信息。该框架根据更先进的评估指标（而非奖励本身）在线生成可动态调整的奖励函数。

**Result:** 经验研究（在仿真和真实世界环境中进行）验证了所提出方法的实用性和有效性。该机制使多智能体系统能够以更高的效率在动态环境中同时实现编队控制和避障，并且需要更少的迭代次数即可达到卓越的性能水平。

**Conclusion:** 本文成功克服了多智能体强化学习中避碰编队控制任务中奖励函数设计的挑战，通过LLM引导的动态奖励函数实现了更高效、更优越的系统性能。

> **ai_Abstract:** 本文针对多智能体强化学习（MARL）在避碰编队控制（FCCA）中奖励函数设计困难的问题，提出了一种新颖的框架。该框架利用大型语言模型（LLM）指导任务优先级和信息观察，并基于先进的评估指标动态生成和调整奖励函数。实验证明，该方法能显著提高多智能体系统在动态环境中实现编队控制和避障的效率和性能。

> **摘要翻译:** 多智能体系统（MAS）通过单个智能体的协同努力擅长完成复杂目标。在MAS中使用的方法中，多智能体强化学习（MARL）是最有效算法之一。然而，当面临避碰编队控制（FCCA）这一复杂目标时，挑战在于设计一个能够促进策略网络快速收敛到最优解的有效奖励函数。在本文中，我们引入了一种旨在克服这一挑战的新颖框架。通过让大型语言模型（LLM）对任务优先级和每个智能体可观察的信息进行指导，我们的框架能够基于更先进的评估指标（而非奖励本身）生成可在线动态调整的奖励函数。这种机制使得MAS能够以更高的效率在动态环境中同时实现编队控制和避障，并且需要更少的迭代次数即可达到卓越的性能水平。我们在仿真和真实世界环境中进行的经验研究验证了我们所提出方法的实用性和有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [136] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
> *人工智能还是人类？理解具身机器人与大型语言模型感知的研究*

*Lavinia Hriscu, Alberto Sanfeliu, Anais Garrell* | **Category: cs.RO, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 图灵测试, 具身机器人, 人机交互, 智能感知, 人工智能评估

**Comment:** 

> **TL;DR:** 在一项图灵测试中，参与者无法可靠地区分由人工智能或人类操作的具身机器人。

**AI_Comments:** 这项研究创新性地将图灵测试应用于具身机器人，以探究人类对机器人智能的感知，而非仅仅关注语言智能。其重要性在于揭示了在物理交互中，人类难以区分AI和人类操作的机器人，这为未来更自然、更具欺骗性的机器人设计提供了宝贵见解，并推动了对AI智能评估的深入讨论。

<details>
  <summary>Details</summary>

**Motivation:** 衡量智能的挑战以及图灵测试在人机交互领域应用不足的问题。本研究旨在通过在机器人平台上进行图灵测试，调查具身机器人中智能的感知。

**Method:** 34名参与者被要求在机器人平台上进行图灵测试，通过信息检索和包裹递送两项交互任务，区分由人工智能或人类操作的机器人。这些任务在静态和动态条件下评估了机器人的感知和导航能力。

**Result:** 参与者未能可靠地区分由人工智能或人类控制的机器人，其区分能力未超出随机水平。此外，对参与者反应的分析揭示了影响具身机器人系统中人工智能与人类智能感知的关键因素。

**Conclusion:** 这些发现为未来交互式机器人的设计提供了见解，并对人工智能驱动系统中智能评估的持续讨论做出了贡献。

> **ai_Abstract:** 本研究通过在具身机器人平台上进行图灵测试，探讨了人们对机器人智能的感知。34名参与者尝试区分由AI或人类操作的机器人在信息检索和包裹递送任务中的表现。结果显示，参与者无法可靠地辨别AI和人类控制的机器人，且分析揭示了影响这种感知的关键因素。这些发现对未来交互式机器人的设计和AI智能评估具有重要意义。

> **摘要翻译:** 人工智能的追求长期以来与有效衡量智能的挑战相关联。即使图灵测试被引入作为评估系统智能的一种手段，其在人机交互领域的关联性和应用在很大程度上仍未被充分探索。本研究通过在机器人平台上进行图灵测试，调查了具身机器人中智能的感知。共有34名参与者被要求在两项交互任务中区分人工智能操作的机器人和人类操作的机器人：一项是信息检索，另一项是包裹递送。这些任务在静态和动态条件下评估了机器人的感知和导航能力。结果表明，参与者无法可靠地区分人工智能控制的机器人和人类控制的机器人，其区分能力未超出随机水平。此外，对参与者反应的分析揭示了影响具身机器人系统中人工智能与人类智能感知的关键因素。这些发现为未来交互式机器人的设计提供了见解，并对人工智能驱动系统中智能评估的持续讨论做出了贡献。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [137] [Curating Demonstrations using Online Experience](https://arxiv.org/abs/2503.03707)
> *利用在线经验整理示范数据*

*Annie S. Chen, Alec M. Lessing, Yuejiang Liu, Chelsea Finn* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 机器人学习, 模仿学习, 数据策展, 在线经验, 策略优化

**Comment:** 

> **TL;DR:** 本文提出Demo-SCORE方法，使机器人能够基于在线经验自我筛选演示数据，显著提高模仿学习的性能。

**AI_Comments:** 该研究的创新点在于提出了利用机器人在线经验进行自我策展的机制，有效解决了传统人工筛选演示数据集耗时耗力且效率低下的问题。Demo-SCORE能够显著提升模仿学习的性能，对于机器人学习领域处理大规模异质性数据集具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多机器人演示数据集包含质量参差不齐的异质演示，这会阻碍机器人最终模仿学习的性能。同时，数据中可能存在不可靠或代表性不足的策略，且人工筛选这些数据耗时且成本高昂。

**Method:** 本文提出Demo-SCORE方法，通过训练和交叉验证一个分类器来区分成功和不成功的策略执行，并利用该分类器过滤异质性演示数据集。

**Result:** Demo-SCORE能够有效识别次优演示，无需人工筛选。与使用所有原始演示数据训练的基础策略相比，Demo-SCORE使最终策略的绝对成功率提高了15-35%。

**Conclusion:** 通过利用在线机器人经验进行自我筛选（Demo-SCORE），可以有效且无需人工干预地识别和过滤次优演示，从而显著提高机器人模仿学习的性能。

> **ai_Abstract:** 本文提出一种名为Demo-SCORE的方法，旨在解决机器人演示数据集中普遍存在的异质性和质量差异问题。该方法利用机器人在线经验，通过训练分类器来识别并过滤次优演示，从而提升模仿学习的性能。实验证明，Demo-SCORE无需人工干预即可有效筛选数据，并使最终策略的成功率显著提高15-35%。

> **摘要翻译:** 许多机器人演示数据集包含质量参差不齐的异质演示。这种异质性可能有利于策略预训练，但在用于最终模仿学习目标时会阻碍机器人性能。特别是，数据中的某些策略可能不如其他策略可靠，或者在数据中代表性不足，导致在测试时采样此类策略时性能不佳。此外，即使是人类也很难辨别这些不可靠或代表性不足的策略，并且筛选演示数据集既耗时又耗费。另一方面，在这些演示数据上训练的策略性能可以反映不同策略的可靠性。因此，我们提出机器人根据在线机器人经验进行自我筛选（Demo-SCORE）。更具体地说，我们训练并交叉验证一个分类器，以区分成功的策略执行和不成功的策略执行，并使用该分类器来过滤异质性演示数据集。我们在模拟和现实世界中的实验表明，Demo-SCORE可以有效地识别次优演示，无需人工筛选。值得注意的是，与使用所有原始演示训练的基础策略相比，Demo-SCORE使最终策略的绝对成功率提高了15-35%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [176] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
> *固定翼无人机编队飞行的分布式振荡制导*

*Yang Xu, Jesús Bautista, José Hinojosa, Héctor García de Marina* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 固定翼无人机, 编队飞行, 振荡制导, 分布式控制, 共识算法

**Comment:** Yang Xu and Jes\'us Bautista contributed equally to this work. In the
  proceedings of the IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025

> **TL;DR:** 提出一种分布式振荡制导算法，使固定翼无人机无需通过速度控制即可实现编队飞行，通过路径上的振荡行为调整平均速度。

**AI_Comments:** 这篇论文的创新点在于提出了“振荡制导”这一独特概念，巧妙地避开了固定翼无人机速度控制的固有难题，通过在引导矢量场上叠加振荡来间接实现编队协调，为无人机编队控制提供了新颖且实用的解决方案。其分布式调整和新颖的共识算法也增加了鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 固定翼无人机自主编队飞行在需要速度驱动协调时面临挑战，因为速度受限且无人机通常以标称空速飞行。

**Method:** 提出一种不依赖速度驱动的编队飞行算法。该算法引导无人机沿特定路径（如平行直线）飞行，并在引导矢量场上叠加振荡行为。这种振荡使无人机能控制沿路径的平均速度，从而实现无人机间协调。每个无人机通过与邻居通信，以闭环方式分布式调整其振荡幅度，并引入了一种新颖的基于非负、非对称饱和函数的共识算法。

**Result:** 该算法经过了严格的理论分析、数值模拟以及实际编队飞行的验证。

**Conclusion:** 该研究成功提出了一种创新的分布式振荡制导算法，克服了固定翼无人机编队飞行中速度驱动协调的限制，通过调节振荡幅度实现了有效的编队控制。

> **ai_Abstract:** 本文针对固定翼无人机编队飞行中速度驱动协调的难题，提出了一种新颖的分布式振荡制导算法。该算法通过将无人机引导至特定路径，并在引导矢量场上叠加振荡行为，从而在不控制速度的情况下实现编队。振荡行为使得沿路径的平均速度可控，促进了无人机间的协调。无人机通过分布式闭环方式调整振荡幅度，并引入了一种基于非负、非对称饱和函数的共识算法。该方法通过理论分析、数值模拟和实际飞行验证了其有效性。

> **摘要翻译:** 固定翼无人机的自主编队飞行在协调需要对其速度进行驱动时会遇到困难，因为它们的速度受到严格限制，并且飞机大多设计为以标称空速飞行。本文提出了一种算法，可以在不要求对其速度进行任何驱动的情况下实现固定翼无人机的编队飞行。具体来说，我们将所有无人机引导至特定路径上，例如平行直线，并在驱动无人机到达路径的引导矢量场上叠加振荡行为。这种振荡使得能够控制沿路径的平均速度，从而促进无人机间的协调。每架无人机通过与无向连通图中的相邻代理进行通信，以闭环方式分布式调整其振荡幅度。引入了一种新颖的共识算法，利用了非负、非对称饱和函数。这种非常规的饱和是合理的，因为负振幅不会使无人机沿路径向后飞行或具有负速度。该算法的严格理论分析通过数值模拟和真实世界编队飞行得到了验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [182] [Bio-Skin: A Cost-Effective Thermostatic Tactile Sensor with Multi-Modal Force and Temperature Detection](https://arxiv.org/abs/2503.07989)
> *Bio-Skin：一种具有多模态力和温度检测功能的经济型恒温触觉传感器*

*Haoran Guo, Haoyang Wang, Zhengxiong Li, Lingfeng Tao* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 触觉传感器, 多模态传感, 恒温, 成本效益, 机器人皮肤

**Comment:** This work has been accepted by IROS2025

> **TL;DR:** Bio-Skin是一种经济型多模态触觉传感器，可同时检测力（法向和剪切）和温度，并具有恒温功能，成本仅为现有商业产品的十分之一，性能相当。

**AI_Comments:** Bio-Skin的主要创新在于其多模态检测能力（力与温度）和恒温功能，同时显著降低了成本。其多层设计和顺序制造提供了快速生产途径，使其在实际应用中更具可行性。这项工作对于推动人形机器人触觉感知技术的发展具有重要意义，尤其是在成本敏感的应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 现有商业触觉传感器专注于提高单模态检测的分辨率和灵敏度，但成本高昂、制造复杂且价格昂贵，限制了其在人形机器人系统中的应用。

**Method:** 本文提出Bio-Skin，一种经济型多模态触觉传感器。它利用单轴霍尔效应传感器进行平面法向力测量，条形压阻器进行二维剪切力测量。将热敏电阻与加热丝集成到硅胶主体中，以实现温度感应和恒温功能。此外，还提出了一个交叉参考框架来验证力传感信号的两种模态，以提高传感保真度。Bio-Skin采用多层设计，每层顺序制造并集成。

**Result:** Bio-Skin校准后，其信噪比、采样率和测量范围等性能指标与当前商业产品相当，但成本仅为十分之一。该传感器在物体抓取任务中使用Allegro机械手评估了实际性能，在材料检测任务中评估了温度调节功能。

**Conclusion:** Bio-Skin是一种经济高效、性能与商业产品相当的多模态触觉传感器，能够同时进行力与温度检测并具有恒温功能，为人形机器人系统提供了有前景的解决方案。

> **ai_Abstract:** 本文介绍了一种名为Bio-Skin的经济型多模态触觉传感器，旨在解决现有商业触觉传感器成本高昂、制造复杂的问题。Bio-Skin集成了霍尔效应传感器和压阻器用于法向力与剪切力检测，并结合热敏电阻与加热丝实现温度感应和恒温功能。该传感器采用多层设计，易于生产，并在性能上与商业产品相当，但成本仅为其十分之一，通过在机械手上进行抓取和材料检测任务验证了其有效性。

> **摘要翻译:** 触觉传感器通过提供接触信息，促进类人交互，从而显著增强人形机器人系统的感知能力。然而，现有商业触觉传感器侧重于通过高成本组件和密集集成设计来提高单模态检测的分辨率和灵敏度，导致制造过程复杂且价格昂贵。在这项工作中，我们提出了Bio-Skin，一种经济高效的多模态触觉传感器，它利用单轴霍尔效应传感器进行平面法向力测量，并利用条形压阻器进行二维剪切力测量。一个热敏电阻与加热丝耦合集成到硅胶主体中，以实现类似于人类皮肤的温度感应和恒温功能。我们还提出了一个交叉参考框架来验证力传感信号的两种模态，从而提高复杂电磁环境中的传感保真度。Bio-Skin采用多层设计，每层顺序制造并随后集成，从而提供了一条快速的生产途径。经过校准后，Bio-Skin的性能指标——包括信噪比、采样率和测量范围——与当前商业产品相当，而成本仅为其十分之一。该传感器在物体抓取任务中通过Allegro机械手评估了其实际性能，其温度调节功能在材料检测任务中得到了评估。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [221] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
> *四足机器人全向3D跳跃的引导式强化学习*

*Riccardo Bussola, Michele Focchi, Giulio Turrisi, Claudio Semini, Luigi Palopoli* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 四足机器人, 跳跃, 引导式强化学习, 贝塞尔曲线, 匀加速直线运动

**Comment:** 

> **TL;DR:** 本文提出一种新颖的引导式强化学习方法，结合贝塞尔曲线和匀加速直线运动（UARM）模型，解决了四足机器人跳跃中传统优化和强化学习方法在效率和安全性方面的局限性。

**AI_Comments:** 该论文的创新之处在于将物理直觉融入强化学习框架，通过结合贝塞尔曲线和UARM模型，有效解决了四足机器人跳跃控制中传统方法效率低、安全性难以保证的问题。这种引导式学习显著提高了样本效率和动作的可解释性，对于推动四足机器人在复杂环境中的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管跳跃对四足机器人至关重要，但它仍是一个重大挑战。现有优化方法耗时且需要大量机器人和地形参数知识，导致在实际场景中鲁棒性差。传统的端到端强化学习方法样本效率低，需要大量模拟训练，且最终动作的可预测性差，难以保证安全性。

**Method:** 本文提出一种新颖的引导式强化学习方法，通过将贝塞尔曲线与匀加速直线运动（UARM）模型相结合，利用物理直觉实现高效且可解释的跳跃。

**Result:** 大量的仿真和实验结果清楚地证明了该方法优于现有替代方案。

**Conclusion:** 该引导式强化学习方法成功解决了四足机器人全向3D跳跃的效率和安全性挑战，并表现出优于现有替代方案的优势。

> **ai_Abstract:** 本文针对四足机器人跳跃面临的效率和安全性挑战，提出了一种新颖的引导式强化学习方法。该方法将贝塞尔曲线与匀加速直线运动（UARM）模型相结合，利用物理直觉指导学习过程，旨在提高样本效率和动作可解释性。通过广泛的仿真和实验，结果表明该方法在四足机器人全向3D跳跃任务中表现出优于现有替代方案的优势。

> **摘要翻译:** 跳跃对四足机器人来说是一个巨大的挑战，尽管它对于许多操作场景至关重要。虽然存在控制此类运动的优化方法，但它们通常耗时且需要对机器人和地形参数有广泛的了解，这使得它们在实际场景中鲁棒性较差。强化学习（RL）正在成为一种可行的替代方案，但传统的端到端方法在样本复杂度方面缺乏效率，需要大量的模拟训练，并且最终动作的可预测性差，这使得难以证明最终动作的安全性。为了克服这些限制，本文引入了一种新颖的引导式强化学习方法，通过将贝塞尔曲线与匀加速直线运动（UARM）模型相结合，利用物理直觉实现高效且可解释的跳跃。大量的仿真和实验结果清楚地证明了我们的方法优于现有替代方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [227] [GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial and Legged Odometry Fusion SLAM for Dynamic Legged Robotics](https://arxiv.org/abs/2503.14247)
> *GeoFlow-SLAM：一种用于动态足式机器人的鲁棒紧耦合RGBD-惯性与足式里程计融合SLAM*

*Tingyang Xiao, Xiaolin Zhou, Liu Liu, Wei Sui, Wei Feng, Jiaxiong Qiu, Xinjie Wang, Zhizhong Su* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 足式机器人, SLAM, RGBD-惯性, 足式里程计, 光流, 紧耦合

**Comment:** 8 pages

> **TL;DR:** GeoFlow-SLAM是一种鲁棒的紧耦合RGBD-惯性SLAM，通过结合几何一致性、足式里程计和双流光流，解决了足式机器人在快速运动和纹理缺失场景中的挑战，实现了最先进的性能。

**AI_Comments:** 这篇论文通过结合多种传感器信息（RGBD、惯性、足式里程计）和创新的处理方法（双流光流、鲁棒姿态初始化、紧耦合优化框架），有效地解决了足式机器人在极端运动和视觉挑战环境下的SLAM问题。其创新点在于对快速运动和纹理缺失场景的特定处理，以及多源信息的紧密融合，这对于提升足式机器人的自主导航能力具有重要意义。开源数据集和代码的发布也将促进该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 解决足式机器人在剧烈高频运动中以及纹理缺失场景中面临的特征匹配失败、姿态初始化失败和视觉特征稀缺等关键挑战。

**Method:** GeoFlow-SLAM整合了几何一致性、足式里程计约束和双流光流（GeoFlow）。它利用结合先验地图点和姿态的双流光流增强快速运动中的特征匹配。此外，提出了一个鲁棒的姿态初始化方法，结合IMU/足式里程计、帧间透视N点（PnP）和广义迭代最近点（GICP）。该方法还引入了一个新的优化框架，紧密耦合了深度到地图和GICP几何约束，以提高在长时间、视觉无纹理环境中的鲁棒性和准确性。

**Result:** 所提出的算法在收集的足式机器人和开源数据集上实现了最先进的（SOTA）性能。

**Conclusion:** GeoFlow-SLAM通过其创新的多传感器融合和优化策略，显著提高了足式机器人在复杂动态和视觉挑战环境中的SLAM鲁棒性和精度，达到了领先水平。

> **ai_Abstract:** GeoFlow-SLAM是一种为足式机器人在剧烈运动和纹理缺失环境中设计的鲁棒紧耦合RGBD-惯性SLAM系统。它通过整合几何一致性、足式里程计和双流光流来解决特征匹配、姿态初始化失败和视觉特征稀缺等挑战。该系统通过双流光流增强快速运动中的特征匹配，并提出了一种结合多传感器数据的鲁棒姿态初始化方法。此外，GeoFlow-SLAM引入了一个新的优化框架，紧密耦合深度到地图和GICP几何约束，以提高在无纹理环境中的鲁棒性和精度。实验结果表明，该算法在足式机器人和开源数据集上达到了最先进的性能。

> **摘要翻译:** 这篇论文提出了GeoFlow-SLAM，一种鲁棒有效的紧耦合RGBD-惯性SLAM，用于在剧烈高频运动中的足式机器人。通过整合几何一致性、足式里程计约束和双流光流（GeoFlow），我们的方法解决了三个关键挑战：在快速运动期间特征匹配和姿态初始化失败，以及在无纹理场景中视觉特征稀缺。具体来说，在快速运动场景中，通过利用结合先验地图点和姿态的双流光流，特征匹配得到了显著增强。此外，我们提出了一种针对足式机器人快速运动和IMU误差的鲁棒姿态初始化方法，该方法整合了IMU/足式里程计、帧间透视N点（PnP）和广义迭代最近点（GICP）。此外，首次引入了一个新的优化框架，该框架紧密耦合了深度到地图和GICP几何约束，以提高在长时间、视觉无纹理环境中的鲁棒性和准确性。所提出的算法在收集的足式机器人和开源数据集上达到了最先进的（SOTA）水平。为了进一步促进研究和开发，开源数据集和代码将在https://github.com/HorizonRobotics/GeoFlowSlam公开提供。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [263] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
> *基于目标的LiDAR-相机多传感器外参标定系统*

*Lorenzo Gentilini, Pierpaolo Serio, Valentina Donzella, Lorenzo Pollini* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 外参标定, 多LiDAR, 多相机, ChArUco, 自动驾驶

**Comment:** 

> **TL;DR:** 该论文提出了一种基于目标的多LiDAR多相机外参标定系统，用于自动驾驶中多传感器数据的高精度对齐。

**AI_Comments:** 该论文提出了一种创新的基于目标的外参标定方法，专门针对多LiDAR和多相机系统，解决了自动驾驶中关键的安全问题。其使用定制的ChArUco棋盘和非线性优化方法是其主要创新点。该方法的重要性在于它提高了多传感器融合的精度，从而增强了自动驾驶车辆的感知能力和安全性。论文中未明确提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 外参标定是自动驾驶的基石，其精度对感知管线至关重要，任何误差都可能影响车辆安全。现代传感器系统收集不同类型的数据，使得数据对齐更加困难。

**Method:** 提出了一种基于目标的外参标定系统，专为多LiDAR和多相机传感器套件量身定制。该系统使用定制的ChArUco棋盘和量身定制的非线性优化方法，在有限先验知识下实现LiDAR和相机之间的交叉标定。

**Result:** 系统在仓库中收集的真实世界数据上进行了测试。结果表明了所提出方法的有效性，突出了为各种类型传感器量身定制的独特管道的可行性。

**Conclusion:** 所提出的系统有效解决了多LiDAR和多相机系统外参标定的挑战，证明了其可行性及其对自动驾驶的重要性。

> **ai_Abstract:** 本论文提出了一种基于目标的多LiDAR多相机外参标定系统，旨在解决自动驾驶中多传感器数据对齐的挑战。该系统利用定制的ChArUco棋盘和量身定制的非线性优化方法，在有限先验知识下实现LiDAR和相机之间的精确交叉标定。通过真实世界数据验证，该方法被证明是有效的，并为各种传感器类型提供了可行的独特标定方案。

> **摘要翻译:** 外参标定是自动驾驶的基石。其精度在感知管线中起着至关重要的作用，因为任何误差都可能对车辆安全产生影响。现代传感器系统从环境中收集不同类型的数据，使得数据对齐变得更加困难。为此，我们提出了一种基于目标的外参标定系统，专为多LiDAR和多相机传感器套件量身定制。该系统使用定制的ChArUco棋盘和量身定制的非线性优化方法，在有限先验知识下实现LiDAR和相机之间的交叉标定。我们使用在仓库中收集的真实世界数据对系统进行了测试。结果表明了所提出方法的有效性，突出了为各种类型传感器量身定制的独特管道的可行性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [277] [eKalibr-Stereo: Continuous-Time Spatiotemporal Calibration for Event-Based Stereo Visual Systems](https://arxiv.org/abs/2504.04451)
> *eKalibr-Stereo：基于事件的双目视觉系统的连续时间时空标定*

*Shuolong Chen, Xingxing Li, Liu Yuan* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 事件相机, 双目标定, 时空标定, 连续时间, eKalibr-Stereo

**Comment:** 

> **TL;DR:** eKalibr-Stereo是一种用于事件相机双目视觉系统精确时空标定的方法，通过改进的网格模式跟踪和连续时间批处理束调整实现。

**AI_Comments:** 该论文的创新之处在于解决了事件相机双目视觉系统缺乏精确时空标定工具的问题。它在现有工作基础上进行了扩展，特别引入了针对不完整网格模式的运动先验跟踪模块，增强了方法的鲁棒性。结合连续时间优化方法，提升了标定精度。开源实现也体现了其对研究社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现最佳的双目视觉融合，需要精确的时空（外参和时间）标定。鉴于目前针对事件相机的双目视觉标定器很少，因此提出了eKalibr-Stereo。

**Method:** eKalibr-Stereo基于先前的eKalibr（事件相机内参标定器）工作。它设计了一个额外的基于运动先验的跟踪模块，以跟踪不完整的网格模式，从而提高网格模式跟踪的连续性。基于跟踪到的网格模式，执行两步初始化过程以恢复分段B样条和时空参数的初始猜测，然后进行连续时间批处理束调整以优化初始状态。

**Result:** 广泛的真实世界实验结果表明，eKalibr-Stereo能够实现准确的基于事件的双目时空标定。

**Conclusion:** eKalibr-Stereo可以实现准确的基于事件的双目时空标定，并且其实现已开源，以造福研究社区。

> **ai_Abstract:** 该论文提出了eKalibr-Stereo，一个针对事件相机双目视觉系统进行精确时空标定的新方法。鉴于现有事件相机双目标定器稀缺，eKalibr-Stereo在现有eKalibr基础上，引入了基于运动先验的跟踪模块以处理不完整的网格模式，提升了跟踪连续性。其标定流程包括两步初始化和连续时间批处理束调整。实验证明eKalibr-Stereo能实现准确的事件相机双目时空标定，并且已开源。

> **摘要翻译:** 仿生事件相机以其卓越的时间分辨率、高动态范围和低功耗而闻名，近年来在运动估计、机器人感知和目标检测领域得到了广泛研究。在自我运动估计中，双目事件相机设置因其直接的尺度感知和深度恢复能力而常被采用。为了实现最佳的双目视觉融合，需要精确的时空（外参和时间）标定。考虑到目前针对事件相机的双目视觉标定器很少，基于我们之前的工作eKalibr（一个事件相机内参标定器），我们提出了eKalibr-Stereo，用于事件相机双目视觉系统的精确时空标定。为了提高网格模式跟踪的连续性，在eKalibr中网格模式识别方法的基础上，eKalibr-Stereo设计了一个额外的基于运动先验的跟踪模块，以跟踪不完整的网格模式。基于跟踪到的网格模式，执行两步初始化过程以恢复分段B样条和时空参数的初始猜测，随后进行连续时间批处理束调整以将初始状态优化到最佳。广泛的真实世界实验结果表明，eKalibr-Stereo能够实现准确的基于事件的双目时空标定。eKalibr-Stereo的实现已在（https://github.com/Unsigned-Long/eKalibr）开源，以造福研究社区。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [306] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
> *Morpheus: 一种混合驱动和多样化情感控制的神经驱动仿生面部*

*Zongzheng Zhang, Jiawen Yang, Ziqiao Peng, Meng Yang, Jianzhu Ma, Lin Cheng, Huazhe Xu, Hang Zhao, Hao Zhao* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 仿生面部, 混合驱动, 情感控制, 神经网络, 语音合成

**Comment:** Accepted to RSS 2025, Project Page:
  https://jiawenyang-ch.github.io/Morpheus-Hardware-Design/

> **TL;DR:** “Morpheus”是一种新型仿生面部，结合了混合驱动硬件和神经算法，实现了从语音输入生成多样且细致的情感表达。

**AI_Comments:** Morpheus的创新之处在于其混合驱动机制，有效结合了刚性驱动的精确性和肌腱驱动的空间效率，解决了传统仿生面部硬件的痛点。此外，通过神经网络实现从语音到细致情感表达的映射，是算法上的重要突破，使得情感表达更加自然和多样化。其开源硬件和代码也为未来的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 先前的仿生面部在情感表达方面受硬件（刚性驱动或肌腱驱动的局限性）和软件（难以有效控制）限制。

**Method:** 硬件方面，提出混合驱动：眼睛和嘴巴使用刚性机构实现精确控制，鼻子和脸颊使用绳索驱动捕捉细微表情。算法方面，引入自建模网络将电机动作映射到面部地标，通过梯度反向传播建立表情混合形状系数与电机控制信号的关系，并训练神经网络将语音输入映射到混合形状控制。

**Result:** 成功构建了紧凑多功能的硬件平台，能够表达广泛的情感。该方法可以从任何给定句子生成清晰的情感表达（如快乐、恐惧、厌恶、愤怒），并具有细致的、特定情感的控制信号，这是早期系统未展示的功能。

**Conclusion:** 通过结合混合驱动硬件和先进的神经算法，Morpheus 显著提升了仿生面部的情感表达能力，克服了现有系统的局限性。

> **ai_Abstract:** 本文介绍了“Morpheus”，一个创新的神经驱动仿生面部系统，旨在克服现有仿生面部在情感表达上的局限。它采用混合驱动硬件设计，将刚性机制用于精确控制眼睛和嘴巴，绳索驱动用于细致的鼻子和脸颊表情。同时，结合自建模网络和神经网络算法，能够将语音输入转化为具有细致情感特性的面部表情控制信号，从而实现从语音生成多样化的情感表达，包括快乐、恐惧、厌恶和愤怒。

> **摘要翻译:** 先前的仿生面部由于硬件和软件限制，难以有效表达情感。在硬件方面，早期方法要么使用刚性驱动机制，其提供精确控制但难以在受限空间内设计；要么使用肌腱驱动机制，其更节省空间但难以控制。相比之下，我们提出了一种结合两者优点的混合驱动方法。眼睛和嘴巴——情感表达的关键区域——使用刚性机制进行精确控制，而鼻子和脸颊——传达细微面部微表情的区域——则由绳索驱动。这种设计使我们能够构建一个紧凑而多功能的硬件平台，能够表达广泛的情感。在算法方面，我们的方法引入了一个自建模网络，将电机动作映射到面部地标，使我们能够通过梯度反向传播自动建立不同面部表情的混合形状系数与相应电机控制信号之间的关系。然后，我们训练一个神经网络将语音输入映射到相应的混合形状控制。通过我们的方法，我们可以从任何给定句子生成清晰的情感表达，例如快乐、恐惧、厌恶和愤怒，每种情感都带有细致的、特定情感的控制信号——这是早期系统未曾展示的功能。我们已在 https://github.com/ZZongzheng0918/Morpheus-Hardware 和 https://github.com/ZZongzheng0918/Morpheus-Software 发布了硬件设计和代码。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [327] [A Goal-Oriented Reinforcement Learning-Based Path Planning Algorithm for Modular Self-Reconfigurable Satellites](https://arxiv.org/abs/2505.01966)
> *一种面向目标的模块化自重构卫星强化学习路径规划算法*

*Bofei Liu, Dong Ye, Zunhao Yao, Zhaowei Sun* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 模块化自重构卫星, 强化学习, 路径规划, Hindsight Experience Replay, 无效动作掩码

**Comment:** 6 pages, 7 figures

> **TL;DR:** 本文提出了一种基于强化学习的路径规划算法，用于模块化自重构卫星，以解决现有算法计算复杂、泛化能力差和对多目标配置支持有限的问题。

**AI_Comments:** 该论文的创新点在于首次将强化学习应用于处理模块化自重构卫星的多个目标配置问题，并有效结合了Hindsight Experience Replay和Invalid Action Masking来解决稀疏奖励和无效动作的挑战。这对于提高模块化卫星系统的自主性和任务适应性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的重构路径规划算法存在计算复杂度高、泛化能力差以及对多样化目标配置支持有限的问题。

**Method:** 本文提出了一种面向目标的强化学习路径规划算法。该算法首次解决了以往强化学习方法未能克服的、处理多个目标配置的挑战。此外，还结合了Hindsight Experience Replay和Invalid Action Masking等技术，以克服稀疏奖励和无效动作带来的显著障碍。

**Result:** 该模型在由四和六个单元组成的模块化卫星集群中，分别达到了95%和73%的任意目标配置成功率。

**Conclusion:** 本文提出的面向目标的强化学习路径规划算法有效解决了模块化自重构卫星路径规划中的现有挑战，并在处理多目标配置和提高成功率方面表现出色。

> **ai_Abstract:** 本文提出了一种面向目标的强化学习路径规划算法，旨在解决模块化自重构卫星在配置改变时现有算法面临的计算复杂、泛化能力差和对多目标配置支持不足的问题。该算法创新性地利用强化学习处理多目标配置，并通过引入Hindsight Experience Replay和Invalid Action Masking技术克服了稀疏奖励和无效动作的挑战。实验结果表明，在由四和六个单元组成的模块化卫星集群中，该算法分别实现了95%和73%的任意目标配置成功率。

> **摘要翻译:** 模块化自重构卫星是指由能够改变其配置的独立模块化单元组成的卫星集群。配置变化使得能够执行各种任务和使命目标。现有的重构路径规划算法通常存在计算复杂度高、泛化能力差以及对多样化目标配置支持有限的问题。为了解决这些挑战，本文提出了一种面向目标的强化学习路径规划算法。该算法首次解决了以往强化学习方法未能克服的、即处理多个目标配置的挑战。此外，还结合了Hindsight Experience Replay和Invalid Action Masking等技术，以克服稀疏奖励和无效动作带来的显著障碍。基于这些设计，我们的模型在由四和六个单元组成的模块化卫星集群中，分别达到了95%和73%的任意目标配置成功率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [354] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
> *经验是最好的老师：通过自生成记忆为机器人接地视觉语言模型*

*Guowei Lan, Kaixian Qu, René Zurbrügg, Changan Chen, Christopher E. Mower, Haitham Bou-Ammar, Marco Hutter* | **Category: cs.RO, cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 视觉语言模型, 机器人, 自生成记忆, 接地, 检索增强生成

**Comment:** 

> **TL;DR:** ExpTeach框架通过自生成记忆和反思，将视觉语言模型（VLMs）有效接地到真实世界的机器人，显著提高了任务成功率和泛化能力。

**AI_Comments:** ExpTeach的创新之处在于其“经验是最好的老师”的理念，通过自生成记忆和闭环反思机制，有效地将预训练的VLMs与真实世界机器人操作相结合。这种方法不仅显著提升了任务成功率，还展现了模型在未见场景下的泛化能力和创造性工具使用的潜力，为机器人学习和自主规划提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型（VLMs）已广泛应用于机器人自主规划，但将主要基于互联网数据训练的VLMs接地到多样化的真实世界机器人仍是一个挑战。

**Method:** 本文提出了ExpTeach框架，通过构建真实世界经验的自生成记忆，将VLMs接地到物理机器人。在该框架中，VLM自主规划行动，验证结果，反思失败，并闭环调整机器人行为。自生成经验被总结为长期记忆，通过检索增强生成（RAG）指导未来任务。此外，ExpTeach通过按需图像标注模块增强了VLMs的空间理解能力。

**Result:** 在四项具有挑战性的机器人任务中，反思将成功率从36%提高到84%，并观察到智能物体交互，包括创造性工具使用。在12个真实世界场景（包括8个未见场景）的广泛测试中，通过长期记忆的接地将单次尝试成功率从22%提高到80%，证明了ExpTeach的有效性和泛化能力。

**Conclusion:** ExpTeach通过自生成记忆和反思机制，成功地将VLMs接地到真实世界机器人，显著提高了任务成功率和泛化能力，并展现了智能行为的出现。

> **ai_Abstract:** 本文提出了ExpTeach框架，旨在解决视觉语言模型（VLMs）在机器人领域接地到真实世界机器人的挑战。ExpTeach通过让VLM自主规划、验证、反思并调整行为，构建自生成的真实世界经验记忆，并通过检索增强生成（RAG）利用这些经验指导未来任务。该框架还通过图像标注增强VLMs的空间理解。实验结果表明，ExpTeach显著提高了机器人在复杂任务中的成功率和泛化能力，并促进了智能交互的出现。

> **摘要翻译:** 视觉语言模型（VLMs）已广泛应用于机器人自主规划。然而，将最初在互联网数据上训练的VLMs接地到多样化的真实世界机器人仍然是一个挑战。本文提出了ExpTeach，一个通过构建真实世界经验的自生成记忆，将VLMs接地到物理机器人的框架。在ExpTeach中，VLM自主规划行动，验证结果，反思失败，并闭环调整机器人行为。在此过程中自生成的经验随后被总结为长期记忆，通过检索增强生成（RAG）检索所学知识以指导未来任务。此外，ExpTeach通过按需图像标注模块增强了VLMs的空间理解能力。在实验中，我们展示了在四项具有挑战性的机器人任务中，反思将成功率从36%提高到84%，并观察到智能物体交互的出现，包括创造性工具使用。在12个真实世界场景（包括8个未见场景）的广泛测试中，我们发现通过长期记忆的接地将单次尝试成功率从22%提高到80%，证明了ExpTeach的有效性和泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [385] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
> *AI空间皮层：未来时代空间探索的实验系统*

*Thomas Touma, Ersin Daş, Erica Tevere, Martin Feather, Ksenia Kolcio, Maurice Prather, Alberto Candela, Ashish Goel, Erik Kramer, Hari Nayar, Lorraine Fesq, Joel W. Burdick* | **Category: cs.RO** | **Updated: 2025-07-21**

**Keywords:** AI自主性, 海洋世界任务, 异常恢复, 空间探索, REASIMO

**Comment:** 

> **TL;DR:** 该研究开发了一个AI辅助的自主系统，用于解决冰冷海洋世界任务中的操作挑战，通过预训练行为实现异常检测和恢复，并在NASA JPL的测试平台进行了演示。

**AI_Comments:** 这篇论文的创新点在于提出了一个AI辅助的、个性化驱动的自主框架，用于解决深空探测中，特别是海洋世界任务中的核心挑战，即长时间通信延迟和高风险环境下的快速响应。它通过引入“预训练行为”而非“硬编码逻辑”来提升任务的鲁棒性和适应性，这对于未来自主空间任务具有重要意义。该系统有望显著提高任务成功率和科学产出。

<details>
  <summary>Details</summary>

**Motivation:** 海洋世界任务面临通信延迟长、电力有限、辐射损伤和恶劣条件导致寿命限制等重大操作挑战。传统航天器依赖“安全模式”，但在时间有限的任务中，无需地球通信即可解决异常至关重要。

**Method:** 该研究通过REASIMO项目，开发了一个AI辅助的、个性化驱动的智能框架，结合先进技术来控制海洋世界任务。它旨在通过预训练行为而非硬编码逻辑来检测和恢复异常，并执行任务。

**Result:** 他们在NASA喷气推进实验室的着陆器-机械臂测试平台上进行了自主采样操作测试，以演示该框架的能力，近似模拟任务可能遇到的表面条件。

**Conclusion:** 船载自主性对于未来的海洋世界任务至关重要，AI辅助的自主系统能够有效应对操作挑战，实现异常检测和恢复，并执行任务。

> **ai_Abstract:** 该论文介绍了REASIMO项目，该项目是NASA COLDTech计划的一部分，旨在解决未来海洋世界任务（如欧罗巴和土卫二）所面临的严峻操作挑战，包括通信延迟、电力限制和辐射损伤。为应对这些挑战，研究团队开发了一个AI辅助的、个性化驱动的智能框架，旨在实现船载自主性，使其能够检测并从异常中恢复，并基于预训练行为执行任务，而非传统的硬编码逻辑。该框架的能力已在NASA喷气推进实验室的着陆器-机械臂测试台上通过自主采样操作测试得到验证，模拟了潜在的表面条件。

> **摘要翻译:** 我们的“用于科学冰冷月球操作的鲁棒可解释自主性”（REASIMO）项目为NASA的“海洋世界生命探测技术”（COLDTech）计划做出了贡献，该计划探索了用于欧罗巴和土卫二等海洋世界的科学平台技术。海洋世界任务带来了重大的操作挑战。这些挑战包括长时间的通信延迟、有限的电力以及由辐射损伤和恶劣条件引起的寿命限制。鉴于这些操作限制，船载自主性对于未来的海洋世界任务至关重要。除了管理标称着陆器操作外，船载自主性必须在发生异常时做出适当反应。传统的航天器依赖于进入“安全模式”，其中非必需的组件和子系统被关闭以保持安全并与地球保持通信。对于时间严重受限的海洋世界任务，无需地球参与通信及相关延迟即可执行的异常解决方案对于完成任务目标和科学目标至关重要。为了应对这些挑战，REASIMO项目旨在为此类任务展示一个强大的AI辅助自主水平，包括检测和从异常中恢复的能力，以及基于预训练行为而非像所有以前的太空任务那样硬编码的预定逻辑来执行任务的能力。我们通过结合多种先进技术，开发了一个AI辅助的、个性化驱动的智能框架，用于控制海洋世界任务。为了展示该框架的能力，我们在NASA喷气推进实验室的着陆器-机械臂测试平台上进行了自主采样操作测试，近似模拟任务可能遇到的表面条件。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [425] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
> *基于神经符号松弛的快速任务规划*

*Qiwei Du, Bowen Li, Yi Du, Shaoshu Su, Taimeng Fu, Zitong Zhan, Zhipeng Zhao, Chen Wang* | **Category: cs.RO** | **Updated: 2025-07-21**

**Keywords:** 任务规划, 神经符号系统, 图神经网络, 规划器, 松弛策略

**Comment:** 8 pages, 6 figures

> **TL;DR:** 该论文提出了一种名为 Flax 的神经符号松弛策略，通过结合神经网络预测实体重要性与符号扩展，解决了传统规划器和现有神经符号方法在处理复杂任务规划时面临的组合爆炸和遗漏关键实体的问题。Flax 在实验中显著提高了成功率并缩短了规划时间。

**AI_Comments:** Flax 的创新之处在于其分阶段的神经符号集成方法，特别是引入了“规则松弛任务”和“实体重整合”步骤，有效地弥补了传统神经符号方法在简化任务时可能遗漏关键信息的缺陷。它提供了一个实用的框架，平衡了规划效率和可靠性，对于处理大规模、复杂环境下的长期任务规划具有重要意义。该方法在实际应用中具有广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中的任务规划需要对大量具有复杂关系和属性的实体进行长期推理，这导致传统符号规划器面临组合爆炸问题。近期方法通过简化任务来修剪搜索空间，但这种简单的神经符号集成可能遗漏关键实体或在不可解的简化任务上浪费资源。

**Method:** 本文提出了一种神经符号松弛策略（Flax），结合神经重要性预测与符号扩展。具体步骤包括：首先，学习一个图神经网络来预测实体重要性以创建简化任务，并用符号规划器解决；然后，解决一个规则松弛任务以获得快速粗略的计划；接着，将所有引用的实体重新整合到简化任务中，以恢复任何被忽略但必不可少的元素；最后，应用补充规则来完善更新后的任务，使其既可靠又紧凑。

**Result:** 在合成和真实世界的迷宫导航基准测试中，Flax 相较于最先进的神经符号基线，平均成功率提高了 20.82%，平均挂钟规划时间减少了 17.65%。

**Conclusion:** Flax 为复杂环境中快速、可扩展、长期任务规划提供了一条实用的途径。

> **ai_Abstract:** 该论文提出了一种名为 Flax 的神经符号松弛策略，旨在解决传统符号规划器在处理复杂任务时面临的组合爆炸问题，以及现有神经符号方法可能遗漏关键实体的问题。Flax 首先利用图神经网络预测实体重要性以简化任务，随后通过规则松弛和实体重整合来完善计划，并最终应用补充规则进行优化。实验结果表明，Flax 在迷宫导航任务上显著提高了任务成功率并缩短了规划时间，为复杂环境中的长期任务规划提供了高效且可靠的解决方案。

> **摘要翻译:** 现实世界的任务规划需要对大量具有复杂关系和属性的实体进行长期推理，这导致传统符号规划器面临组合爆炸问题。为了修剪搜索空间，近期方法优先在仅包含神经网络预测的少数“重要”实体的简化任务上进行搜索。然而，这种简单的神经符号（NeSy）集成存在遗漏关键实体和在不可解的简化任务上浪费资源的风险。为了实现快速可靠的规划，我们引入了一种神经符号松弛策略（Flax），结合了神经重要性预测与符号扩展。具体来说，我们首先学习一个图神经网络来预测实体重要性以创建简化任务，并用符号规划器解决。然后，我们解决一个规则松弛任务以获得一个快速粗略的计划，并将所有引用的实体重新整合到简化任务中，以恢复任何被忽略但必不可少的元素。最后，我们应用补充规则来完善更新后的任务，使其既可靠又紧凑。我们对合成和真实世界的迷宫导航基准进行了广泛的实验，其中机器人必须穿过迷宫并与可移动物体进行交互。结果表明，与最先进的 NeSy 基线相比，Flax 将平均成功率提高了 20.82%，并将平均挂钟规划时间缩短了 17.65%。我们期望 Flax 为复杂环境中快速、可扩展、长期任务规划提供一条实用的途径。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [437] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
> *基于大型语言模型的多机器人团队组合式协调*

*Zhehui Huang, Guangyao Shi, Yuwei Wu, Vijay Kumar, Gaurav S. Sukhatme* | **Category: cs.RO, cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-21**

**Keywords:** 多机器人协调, 大型语言模型, 自然语言处理, 代码生成, 机器人控制

**Comment:** 9 pages, 4 figures

> **TL;DR:** LAN2CB是一个利用大型语言模型将自然语言任务描述直接转化为多机器人可执行代码的框架，简化了多机器人协调流程，减少了人工干预。

**AI_Comments:** 该论文的创新点在于将大型语言模型引入多机器人协调领域，通过自动化代码生成显著简化了传统上复杂且依赖专家的流程。其重要性在于提高了多机器人系统的可访问性和灵活性，降低了部署门槛。通过直接从自然语言生成代码，为非专家用户提供了更直观的交互方式，具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多机器人协调流程依赖于特定任务和专家驱动的管道，需要将自然语言任务描述手动转换为数学公式、算法设计和可执行代码。这种过程劳动密集、对非专家不友好且对任务需求变化不灵活。

**Method:** 本文提出了LAN2CB（Language to Collective Behavior）框架，利用大型语言模型（LLMs）来简化和泛化多机器人协调流程。LAN2CB通过两个关键组件将自然语言任务描述直接转换为多机器人系统的可执行Python代码：1) 用于任务表示的任务分解，将任务解析为带有依赖关系的任务图；2) 代码生成，使用任务图和结构化知识库生成可部署的机器人控制代码。此外，还引入了一个自然语言任务规范数据集来支持开发和基准测试。

**Result:** 在仿真和真实世界环境中的实验结果表明，LAN2CB能够实现从自然语言进行有效且灵活的多机器人协调，显著减少了手动工程的需求，同时支持跨任务类型的泛化。

**Conclusion:** LAN2CB框架成功地利用大型语言模型自动化了多机器人协调过程，使其更高效、更灵活，并降低了对领域专家的依赖。

> **ai_Abstract:** 本文提出LAN2CB框架，利用大型语言模型（LLMs）将自然语言任务描述直接转化为多机器人系统的可执行Python代码。该框架通过任务分解生成任务图和代码生成组件实现，旨在简化传统上劳动密集且不灵活的多机器人协调流程。实验结果表明，LAN2CB在仿真和真实世界中均能有效且灵活地协调多机器人，减少了人工干预并实现了任务泛化。

> **摘要翻译:** 多机器人协调传统上依赖于特定任务和专家驱动的流程，其中自然语言任务描述由领域专家手动转换为数学公式、算法设计和可执行代码。这种传统过程劳动密集、非专家难以使用，并且对任务需求的变化不灵活。在此，我们提出了LAN2CB（Language to Collective Behavior），一个利用大型语言模型（LLMs）来简化和泛化多机器人协调流程的新颖框架。LAN2CB通过两个关键组件将自然语言任务描述直接转换为多机器人系统的可执行Python代码：(1) 用于任务表示的任务分解，它将任务解析为带有依赖关系的任务图；(2) 代码生成，它使用任务图和结构化知识库生成可部署的机器人控制代码。我们进一步引入了一个自然语言任务规范数据集来支持开发和基准测试。在仿真和真实世界环境中的实验结果表明，LAN2CB能够实现从自然语言进行有效且灵活的多机器人协调，显著减少了手动工程的需求，同时支持跨任务类型的泛化。网站：https://sites.google.com/view/lan2cb。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [443] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
> *激光雷达里程计技术的综合评估*

*Easton Potokar, Michael Kaess* | **Category: cs.RO** | **Updated: 2025-07-21**

**Keywords:** 激光雷达里程计, 实证评估, 消融研究, 状态估计, 传感器

**Comment:** Accepted to IROS 2025

> **TL;DR:** 本文对激光雷达里程计（LO）管道的各种组成部分进行了全面的实证评估，并根据评估结果为未来的LO管道设计提供了建议。

**AI_Comments:** 本文的创新之处在于其对激光雷达里程计（LO）管道组件进行的全面实证评估和消融研究，这弥补了现有文献中对LO“构建模块”系统性比较的不足。通过在广泛数据集上的验证，其提供的经验性建议对于未来LO系统的设计和优化具有重要的指导意义，有助于提升激光雷达里程计的准确性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在比较激光雷达里程计（LO）管道的各种“构建模块”方面进行了很少的消融研究，导致缺乏对不同技术组合的深入理解。

**Method:** 作者总结了定义LO管道的各种技术，并在大量跨环境、激光雷达类型和车辆运动的数据集上对这些LO组件进行了实证评估。

**Result:** 本文根据实证评估结果，为未来LO管道的设计提供了经验支持的建议，以实现最准确和可靠的性能。

**Conclusion:** 通过对激光雷达里程计组件的全面实证评估，本文为未来设计高性能的LO管道提供了有价值的指导和建议。

> **ai_Abstract:** 本文对激光雷达里程计（LO）管道的构建模块进行了全面的实证评估，旨在弥补现有研究中消融研究的不足。作者总结了LO管道的各种技术，并在多样化的数据集上进行了性能评估，最终为未来LO管道的设计提供了基于实证的优化建议，以提升其准确性和可靠性。

> **摘要翻译:** 激光雷达（LiDAR）传感器已成为许多机器人状态估计任务的首选传感器。因此，近年来在寻找使用这些传感器执行状态估计的最准确方法方面进行了大量工作。在这些先前的每项工作中，都出现了可能的技术组合爆炸式增长，每项工作都将激光雷达里程计（LO）“管道”与先前的“管道”进行比较。不幸的是，到目前为止，很少有工作对LO管道的各种构建模块进行大量的消融研究。在这项工作中，我们总结了定义LO管道的各种技术，并在大量跨环境、激光雷达类型和车辆运动的数据集上对这些LO组件进行了实证评估。最后，我们为未来LO管道的设计提出了经验支持的建议，以提供最准确和可靠的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [451] [Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration](https://arxiv.org/abs/2507.06605)
> *使用智能体生长树：通过学习的多步情节探索加速RRTs*

*Xinyu Wu* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** RRT, 运动规划, 深度强化学习, 路径规划, 探索

**Comment:** 

> **TL;DR:** Episodic RRT (ERRT) 利用深度强化学习智能体进行多步探索，显著加速了RRTs在复杂和高维空间中的性能，大幅减少了碰撞检查并提高了成功率。

**AI_Comments:** ERRT的创新之处在于将DRL智能体引入到RRT的探索过程中，将无方向的随机采样转化为有方向的多步探索，这有效解决了RRT在高维空间中的效率问题和“维度诅咒”。其显著的性能提升，尤其是在减少碰撞检查和提高路径质量方面，显示了强化学习在运动规划领域的巨大潜力。该方法提供了一个有前景的方向，将机器学习与传统规划算法相结合，以应对复杂环境中的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 经典的基于采样的运动规划器（如RRTs）由于依赖无方向的随机采样，在杂乱或高维空间中效率低下。

**Method:** 本文提出了Episodic RRT (ERRT)，这是一种新颖的混合规划框架，它用一个由深度强化学习（DRL）智能体生成的学习到的多步“探索性情节”取代了随机点原语。通过使DRL智能体成为探索引擎，ERRT将搜索过程从扩散的体积膨胀转变为定向的、分支状的生长。这种范式转变能够实现聚焦探索以对抗维度诅咒，通过主动提出局部有效路径来最小化昂贵的碰撞检查，并通过生成固有连接的路径段来改善连通性。

**Result:** 通过在2D、3D和6D环境中的广泛实证评估表明，ERRT及其变体在没有GPU加速的情况下，始终显著优于其经典对应物。在具有挑战性的6D机械臂场景中，ERRT的成功率达到98%（RRT为19%），速度快107倍，碰撞检查减少99.6%以上，并且找到的初始路径缩短了近50%。此外，其渐近最优变体ERRT*在3D环境中表现出卓越的随时性能，以比标准RRT*快29倍的速度将解决方案优化到接近最优。

**Conclusion:** Episodic RRT (ERRT) 通过引入学习到的多步探索，有效克服了传统RRT在复杂和高维空间中的局限性，实现了显著的性能提升，并在成功率、速度、碰撞检查和路径质量方面均表现出色。

> **ai_Abstract:** 本文提出了一种名为Episodic RRT (ERRT) 的新型混合运动规划框架，旨在解决经典RRT在复杂和高维空间中效率低下的问题。ERRT通过将随机采样替换为由深度强化学习（DRL）智能体生成的学习到的多步“探索性情节”，实现了从无方向搜索到定向分支状生长的转变。这种方法有效对抗了维度诅咒，减少了碰撞检查，并提高了路径连通性。实验结果表明，ERRT在2D、3D和6D环境中均显著优于传统RRT，尤其在6D机械臂场景中，其成功率、速度和路径质量均有大幅提升，且无需GPU加速。

> **摘要翻译:** 经典的基于采样的运动规划器，如RRTs，由于依赖无方向的随机采样，在杂乱或高维空间中效率低下。本文引入了Episodic RRT，这是一种新颖的混合规划框架，它用一个由深度强化学习智能体生成的学习到的多步“探索性情节”取代了随机点原语。通过使DRL智能体成为探索引擎，ERRT将搜索过程从扩散的体积膨胀转变为定向的、分支状的生长。这种范式转变带来了关键优势：它通过聚焦探索来对抗维度诅咒，通过主动提出局部有效路径来最小化昂贵的碰撞检查，并通过生成固有连接的路径段来改善连通性。我们通过在2D、3D和6D环境中的广泛实证评估表明，ERRT及其变体在没有GPU加速的情况下，始终显著优于其经典对应物。在具有挑战性的6D机械臂场景中，ERRT的成功率达到98%（RRT为19%），速度快107倍，碰撞检查减少99.6%以上，并且找到的初始路径缩短了近50%。此外，其渐近最优变体ERRT*在3D环境中表现出卓越的随时性能，以比标准RRT*快29倍的速度将解决方案优化到接近最优。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [461] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
> *超低分辨率RGB图像的改进语义分割及其在隐私保护目标导航中的应用*

*Xuying Huang, Sicong Pan, Olga Zatsarynna, Juergen Gall, Maren Bennewitz* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 语义分割, 超低分辨率图像, 隐私保护, 机器人导航, 联合学习

**Comment:** Submitted to RA-L

> **TL;DR:** 该研究提出了一种新颖的联合学习方法，用于从超低分辨率图像中进行语义分割，从而实现隐私保护的机器人目标导航。

**AI_Comments:** 该论文的创新之处在于提出了一种专门针对超低分辨率图像的联合学习方法，有效平衡了用户隐私保护与机器人任务性能。其重要性在于为在隐私敏感环境中部署移动机器人提供了实用的解决方案，拓宽了机器人应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人中的用户隐私是一个关键问题。现有方法通常在下游机器人任务性能和隐私保护之间进行权衡，后者常限制任务执行的有效性。本研究旨在共同解决这两个目标，即在保护视觉隐私的同时实现基于语义的机器人导航。

**Method:** 本文提出了一种新颖的完全联合学习方法，该方法集成了聚类特征提取器和分割感知判别器，以解决超低分辨率语义分割问题，从而实现隐私保护的语义目标导航。

**Result:** 所提出的方法在超低分辨率语义分割方面优于不同的基线，并且改进的分割结果提高了在真实世界隐私受限场景中语义目标导航的成功率。

**Conclusion:** 该研究成功地通过改进的超低分辨率语义分割技术，实现了在保护用户隐私的同时提高机器人目标导航的成功率，有效解决了隐私与任务性能之间的矛盾。

> **ai_Abstract:** 该论文针对移动机器人中隐私与任务性能的权衡问题，提出了一种新颖的完全联合学习方法。该方法结合了聚类特征提取器和分割感知判别器，旨在从超低分辨率RGB图像中恢复语义分割，以实现隐私保护的语义目标导航。实验结果表明，该方法在超低分辨率语义分割方面优于现有基线，并显著提高了在隐私受限场景下机器人目标导航的成功率。

> **摘要翻译:** 移动机器人中的用户隐私已成为一个关键问题。现有方法通常优先考虑下游机器人任务的性能或隐私保护，而后者往往会限制任务执行的有效性。为了共同解决这两个目标，我们研究了在超低分辨率设置下基于语义的机器人导航，以保护视觉隐私。在这种场景中，一个关键挑战是从超低分辨率RGB图像中恢复语义分割。在这项工作中，我们引入了一种新颖的完全联合学习方法，该方法集成了聚类特征提取器和分割感知判别器，以解决超低分辨率语义分割问题，从而实现隐私保护的语义目标导航。我们的方法在超低分辨率语义分割方面优于不同的基线，并且我们改进的分割结果提高了在真实世界隐私受限场景中语义目标导航的成功率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [479] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
> *治疗师-外骨骼-患者互动：一种沉浸式步态疗法*

*Emek Barış Küçüktabak, Matthew R. Short, Lorenzo Vianello, Daniel Ludvig, Levi Hargrove, Kevin Lynch, Jose Pons* | **Category: cs.RO** | **Updated: 2025-07-21**

**Keywords:** 步态康复, 外骨骼, 人机交互, 中风, 物理康复

**Comment:** 

> **TL;DR:** 本文提出了一种基于物理人-机器人-人交互（pHRHI）的新型步态康复范式，其中治疗师和中风患者都佩戴下肢外骨骼并进行虚拟连接，以实现更好的康复效果。

**AI_Comments:** 该论文提出了一种创新的康复方法，通过物理人-机器人-人交互（pHRHI）模式，有效地将治疗师的直觉和机器人的精确性结合起来。这种方法不仅减轻了治疗师的体力负担，还提升了患者的康复效果，特别是在关节活动范围和肌肉激活方面。其创新性在于实现了治疗师与患者通过外骨骼的双向互动，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 中风患者常因下肢无力导致行动和平衡障碍，传统步态康复训练对治疗师体力要求高，且难以同时顾及多个关节。现有机器人外骨骼虽能提供支持，但限制了治疗师的参与和适应性。

**Method:** 提出了一种基于物理人-机器人-人交互（pHRHI）的新型步态康复范式。治疗师和中风患者均穿戴下肢外骨骼，并通过虚拟弹簧-阻尼器元件在髋部和膝部进行连接，从而实现双向互动，使治疗师能够引导运动并接收触觉反馈。

**Result:** 在八名慢性中风患者的研究中，pHRHI训练优于传统的治疗师指导的跑步机步行训练，导致关节活动范围、步态指标、肌肉激活和患者积极性均有所增加。

**Conclusion:** pHRHI模式结合了机器人精度和治疗师直觉，在改善康复效果方面具有巨大潜力。

> **ai_Abstract:** 本研究提出了一种创新性的物理人-机器人-人交互（pHRHI）步态康复范式，旨在解决传统康复对治疗师的体力要求高和现有外骨骼限制治疗师参与的问题。在该范式中，治疗师和中风患者均穿戴虚拟连接的外骨骼，实现双向互动和触觉反馈。实验结果表明，与传统方法相比，pHRHI训练显著改善了中风患者的关节活动范围、步态、肌肉激活和积极性，展现了结合机器人精度与治疗师直觉在康复中的巨大潜力。

> **摘要翻译:** 中风后，个体常因下肢无力和关节独立控制能力丧失而出现活动和平衡障碍。步态恢复是康复的关键目标，传统上通过高强度治疗师主导的训练来实现。然而，手动辅助对治疗师的体力要求很高，并限制了治疗师同时与多个关节互动。机器人外骨骼提供多关节支持，减轻治疗师的劳累，并提供客观反馈，但当前的控制策略通常限制了治疗师的参与和适应性。
我们提出了一种基于物理人-机器人-人交互（pHRHI）的新型步态康复范式，其中治疗师和中风个体都佩戴下肢外骨骼，并通过虚拟弹簧-阻尼器元件在髋部和膝部进行虚拟连接。这实现了双向互动，允许治疗师引导运动并接收触觉反馈。在对八名慢性中风患者进行的研究中，pHRHI训练优于传统的治疗师指导的跑步机步行训练，导致关节活动范围、步态指标、肌肉激活和积极性均有所增加。这些结果突显了pHRHI结合机器人精度与治疗师直觉以改善康复效果的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [498] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
> *FTIN：用于惯性里程计的频域-时域集成网络*

*Shanshan Zhang, Qi Zhang, Siyue Wang, Tianshui Wen, Ziheng Zhou, Lingxiang Zheng, Yu Yang* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 惯性里程计, 频域-时域融合, 深度学习, 长期依赖, FTIN

**Comment:** 

> **TL;DR:** 本文提出FTIN，一个集成频域和时域信息的网络，用于提高惯性里程计的定位精度。它通过频域学习捕捉长期依赖并减少冗余，同时利用Scalar LSTM在时域捕捉序列依赖，实现了显著的误差减少。

**AI_Comments:** 该论文的创新点在于提出了一个结合频域和时域信息的网络架构FTIN，这有效地解决了传统时域方法难以捕捉长期依赖的问题。通过利用频域的全局视图和能量压缩特性，以及时域的Scalar LSTM，实现了更准确和稳定的惯性里程计。其在多个数据集上的显著性能提升，特别是RoNIN数据集上的误差大幅减少，表明了该方法的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的惯性里程计方法主要依赖时域CNN，难以捕捉惯性测量单元数据的长期依赖性，从而限制了定位精度的进一步提升。

**Method:** 本文提出了一种新颖的网络架构——频域-时域集成网络（FTIN）。该网络利用频域学习的全局视图和能量压缩特性来有效建模长期依赖并减少IMU数据冗余。同时，引入Scalar LSTM在时域捕捉序列依赖，实现跨域信息融合，为定位提供稳定可靠的参考。

**Result:** 在多个公开数据集（如RIDI、RoNIN、OxIOD、RNIN、TLIO和IMUNet）上的实验评估表明，所提出的频域-时域融合策略是有效的。特别是在RoNIN数据集上，与RoNIN ResNet相比，本文方法将绝对轨迹误差降低了43.0%，相对轨迹误差降低了13.1%。

**Conclusion:** 本文提出的频域-时域集成网络（FTIN）通过有效融合频域和时域信息，显著提高了惯性里程计的定位精度，尤其在处理长期依赖和减少数据冗余方面表现出色。

> **ai_Abstract:** 本文提出了一种名为FTIN的频域-时域集成网络，旨在解决现有惯性里程计方法在捕捉长期依赖方面的不足。FTIN结合了频域学习的全局视图和能量压缩特性，以建模长期依赖并减少IMU数据冗余，并引入Scalar LSTM捕捉时域序列依赖。实验结果表明，该方法在多个公共数据集上表现出有效性，尤其在RoNIN数据集上显著降低了绝对和相对轨迹误差。

> **摘要翻译:** 近年来，机器学习在惯性里程计领域取得了显著进展。然而，大多数现有惯性里程计方法主要依赖于时域的CNN，这些方法通常难以捕捉惯性测量单元数据的长期依赖性，从而限制了定位精度的进一步提升。为了解决这些问题，我们提出了一种新颖的网络架构，它集成了频域和时域信息。具体来说，我们利用频域学习的全局视图和能量压缩特性来有效建模长期依赖并减少IMU数据冗余。此外，我们引入了Scalar LSTM在时域捕捉序列依赖，实现了跨域信息融合，并为定位提供了稳定可靠的参考。在多个公开数据集（例如RIDI、RoNIN、OxIOD、RNIN、TLIO和IMUNet）上的实验评估证明了所提出的频域-时域融合策略的有效性。值得注意的是，在RoNIN数据集上，我们的方法与RoNIN ResNet相比，绝对轨迹误差降低了43.0%，相对轨迹误差降低了13.1%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [508] [Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots](https://arxiv.org/abs/2507.07714)
> *基于自适应高斯混合模型的欠约束索驱动并联机器人异常检测*

*Julio Garrido, Javier Vales, Diego Silva-Muñiz, Enrique Riveiro, Pablo López-Matencio, Josué Rivera-Andrade* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 索驱动并联机器人, 异常检测, 高斯混合模型, 自适应算法, 扭矩数据

**Comment:** 14 pages, 8 figures, 1 table

> **TL;DR:** 论文提出了一种基于自适应高斯混合模型（GMM）的无监督异常检测算法，仅利用电机扭矩数据，用于欠约束索驱动并联机器人，实现了高准确率和低延迟。

**AI_Comments:** 该论文的创新点在于提出了一种仅依赖电机扭矩数据，且具有自适应能力的无监督异常检测方法，这对于降低索驱动并联机器人的传感器成本和提高系统鲁棒性具有重要意义。其自适应性是关键，使其能适应真实世界中不断变化的环境条件。高真阳性率和较低的检测延迟也显示了该方法的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 索驱动并联机器人（CDPRs）在负载操作任务中需要评估系统安全性，以检测可能影响性能的异常（如阵风或电缆冲击）。现有方法可能需要额外传感器，而本文旨在仅利用电机扭矩数据进行异常检测。

**Method:** 提出了一种基于高斯混合模型（GMMs）的自适应、无监督异常检测算法。该方法从一个短暂的校准期开始，在已知的无异常数据上拟合GMM。然后，实时扭矩测量通过马哈拉诺比斯距离与GMM进行评估，并由统计推导的阈值触发异常标志。模型参数会定期使用最新识别的无异常数据段进行更新，以适应不断变化的条件。

**Result:** 该方法在模拟不同风强度的14次长时间测试中，实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟为1秒。与功率阈值和非自适应GMM方法相比，该方法对漂移和环境变化的鲁棒性更高。

**Conclusion:** 论文成功证明了仅使用电机扭矩数据，基于自适应GMM的无监督异常检测方法，能够有效、鲁棒地检测欠约束索驱动并联机器人中的异常，并适应不断变化的操作条件。

> **ai_Abstract:** 本文提出了一种针对欠约束索驱动并联机器人（CDPRs）的自适应、无监督异常检测算法。该算法仅利用电机扭矩数据，基于高斯混合模型（GMMs）识别异常。通过短暂校准后，系统实时评估扭矩信号，并周期性更新模型以适应环境变化。实验结果表明，该方法在多种风强度模拟下具有高检测率（100%真阳性，95.4%真阴性）和低延迟（1秒），且对环境变化展现出更强的鲁棒性。

> **摘要翻译:** 索驱动并联机器人（CDPRs）越来越多地用于涉及预定义工具路径和中间停靠点的负载操作任务。在每个停靠点，平台保持固定姿态且电机保持缆绳张力，系统必须通过检测可能损害性能的异常（例如，阵风或电缆冲击）来评估是否可以安全地继续。本文研究是否可以仅使用电机扭矩数据（无需额外传感器）来检测异常。它引入了一种基于高斯混合模型（GMMs）的自适应、无监督异常检测算法，用于从扭矩信号中识别异常。该方法从一个短暂的校准期开始，仅需几秒钟，在此期间，GMM在已知的无异常数据上进行拟合。然后，使用来自GMM的马哈拉诺比斯距离评估实时扭矩测量值，并由统计推导的阈值触发异常标志。模型参数会定期使用最新识别为无异常的数据段进行更新，以适应不断变化的条件。验证包括14次长时间测试，模拟了不同的风强度。所提出的方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟为1秒。与功率阈值和非自适应GMM方法进行比较评估表明，该方法对漂移和环境变化的鲁棒性更高。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [527] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
> *DWSFormer：一种用于复杂运动建模的轻量级惯性里程计网络*

*Shanshan Zhang, Qi Zhang, Siyue Wang, Tianshui Wen, Ziheng Zhou, Lingxiang Zheng, Yu Yang* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 惯性里程计, 复杂运动建模, 轻量级网络, 注意力机制, 漂移误差

**Comment:** 

> **TL;DR:** DWSFormer是一种轻量级惯性里程计网络，通过处理复杂运动模式下的漂移误差，显著提高了定位精度，并在多个数据集上超越了现有最佳方法。

**AI_Comments:** 该论文提出了一种创新的轻量级惯性里程计网络DWSFormer，有效解决了传统IO在复杂运动中定位精度下降的问题。其引入的Star Operation、协同注意力机制和多尺度门控卷积单元在特征提取和动态建模方面具有新颖性。通过在多个数据集上超越SOTA基线并建立新基准，展示了其在实际应用中的巨大潜力，尤其对于消费级定位系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有惯性里程计（IO）方法在简单和近线性运动轨迹上表现良好，但在复杂运动模式（如转弯）下会产生漂移误差，这严重降低了定位精度并限制了IO系统在现实世界中的应用。

**Method:** 本文提出DWSFormer，一个轻量级IO框架。它使用Star Operation方法将惯性数据投射到高维隐式非线性特征空间以提取复杂运动特征；引入协同注意力机制共同建模通道和时间维度上的全局运动动态；设计多尺度门控卷积单元以捕获运动过程中的细粒度动态变化。

**Result:** 提出的方法在六个广泛使用的惯性数据集上持续优于SOTA基线。与RoNIN数据集上的基线模型相比，它将ATE降低了2.26%到65.78%，从而在该领域建立了新的基准。

**Conclusion:** DWSFormer通过有效处理复杂运动模式下的漂移误差，显著提高了惯性里程计的定位精度和适用性，并在多个数据集上取得了最先进的性能，建立了新的基准。

> **ai_Abstract:** 本文提出了DWSFormer，一个轻量级惯性里程计网络，旨在解决现有IO方法在复杂运动模式下产生的漂移误差问题。该框架通过Star Operation提取高维复杂运动特征，并结合协同注意力机制和多尺度门控卷积单元来捕捉全局和细粒度动态。实验结果表明，DWSFormer在多个惯性数据集上显著优于现有最佳方法，特别是在RoNIN数据集上实现了可观的ATE降低，为惯性里程计领域树立了新标杆。

> **摘要翻译:** 惯性里程计（IO）直接从惯性传感器测量中估计载体的姿态，是消费级定位系统广泛部署的核心技术。尽管现有的IO方法可以准确重建简单和接近线性的运动轨迹，但它们通常无法解决由复杂运动模式（如转弯）引起的漂移误差。这种限制显著降低了定位精度，并限制了IO系统在现实场景中的适用性。为了解决这些挑战，我们提出了一种轻量级IO框架。具体来说，使用星形操作（Star Operation）方法将惯性数据投射到高维隐式非线性特征空间中，从而能够提取通常被忽视的复杂运动特征。我们进一步引入了一种协同注意力机制，该机制共同建模通道和时间维度上的全局运动动态。此外，我们设计了多尺度门控卷积单元，以捕获整个运动过程中的细粒度动态变化，从而增强模型学习丰富和富有表现力的运动表示的能力。广泛的实验表明，我们提出的方法在六个广泛使用的惯性数据集上始终优于SOTA基线。与RoNIN数据集上的基线模型相比，它将ATE降低了2.26%至65.78%，从而在该领域建立了新的基准。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [547] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
> *GR-3 技术报告*

*Chilam Cheang, Sijin Chen, Zhongren Cui, Yingdong Hu, Liqun Huang, Tao Kong, Hang Li, Yifeng Li, Yuxiao Liu, Xiao Ma, Hao Niu, Wenxuan Ou, Wanli Peng, Zeyu Ren, Haixin Shi, Jiawen Tian, Hongtao Wu, Xin Xiao, Yuyang Xiao, Jiafeng Xu, Yichu Yang* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 通用机器人, 视觉-语言-动作模型, GR-3, 高效微调, ByteMini

**Comment:** Tech report. Authors are listed in alphabetical order. Project page:
  https://seed.bytedance.com/GR3/

> **TL;DR:** 报告了GR-3（一个大型视觉-语言-动作模型）的进展，它能泛化到新环境、高效微调、处理复杂任务，并在实验中超越SOTA基线，旨在构建通用机器人。

**AI_Comments:** 这篇报告展示了在通用机器人领域的重要进展。GR-3作为VLA模型，其亮点在于结合了多源数据（网络视觉-语言数据、VR人类轨迹数据、机器人轨迹数据）进行训练，实现了高效泛化和微调，降低了部署成本。引入的ByteMini机器人也体现了软硬件结合的思路。超越最先进基线表明了其有效性。未来挑战可能在于如何进一步扩大其能力范围并确保在更复杂、不可预测的真实世界环境中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在构建通用机器人策略，使机器人能够协助人类日常生活。

**Method:** 开发了GR-3，一个大规模的视觉-语言-动作（VLA）模型。其能力通过多方面训练实现：与网络规模视觉-语言数据协同训练，通过VR设备收集的人类轨迹数据进行高效微调，以及利用机器人轨迹数据进行有效模仿学习。此外，还引入了ByteMini，一个多功能双臂移动机器人，与GR-3结合使用。

**Result:** GR-3展现出卓越的泛化能力，能适应新物体、环境和抽象指令。它能用少量人类轨迹数据高效微调，实现快速、成本效益高的适应。在处理长周期和灵巧任务（包括双臂操作和移动）方面表现出色。通过大量真实世界实验，GR-3在各种挑战性任务上超越了最先进的基线方法 $\pi_0$。

**Conclusion:** GR-3是构建能够协助人类日常生活的通用机器人的重要一步。

> **ai_Abstract:** 这份技术报告介绍了GR-3，一个大规模的视觉-语言-动作（VLA）模型，旨在实现通用机器人策略。GR-3在泛化能力、高效微调以及处理复杂任务方面表现出色，其训练结合了网络数据、人类轨迹数据和机器人轨迹数据。报告还介绍了配套的双臂移动机器人ByteMini。实验证明GR-3在多项任务上超越了现有最先进方法，预示着其在构建日常生活通用机器人方面的潜力。

> **摘要翻译:** 报告了我们在构建通用机器人策略方面的最新进展，即GR-3的开发。GR-3是一个大规模的视觉-语言-动作（VLA）模型。它在泛化到新颖物体、环境以及涉及抽象概念的指令方面展示了卓越的能力。此外，它可以通过最少的人类轨迹数据进行高效微调，从而实现对新设置的快速和经济高效的适应。GR-3在处理长周期和灵巧任务方面也表现出色，包括那些需要双手操作和移动的任务，展现出稳健可靠的性能。这些能力是通过多方面训练方案实现的，包括与网络规模视觉-语言数据协同训练、通过VR设备收集的人类轨迹数据进行高效微调，以及利用机器人轨迹数据进行有效模仿学习。此外，我们引入了ByteMini，这是一款多功能双臂移动机器人，设计具有卓越的灵活性和可靠性，与GR-3结合时能够完成广泛的任务。通过大量的真实世界实验，我们展示了GR-3在各种具有挑战性的任务上超越了最先进的基线方法$\pi_0$。我们希望GR-3能够成为构建能够协助人类日常生活的通用机器人的一步。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [551] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
> *评估大语言模型在社交机器人决策中的隐私识别能力*

*Dakota Sullivan, Shirley Zhang, Jennica Li, Heather Kirkorian, Bilge Mutlu, Kassem Fawaz* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** LLM隐私, 社交机器人, 隐私识别, 人机交互, 情境完整性

**Comment:** 18 pages, 7 figures. Dakota Sullivan and Shirley Zhang contributed
  equally to this work

> **TL;DR:** 本研究评估了LLM在社交机器人情境下处理敏感个人信息的隐私识别能力，发现当前LLM与人类在隐私偏好上存在低一致性。

**AI_Comments:** 本文通过实证研究揭示了当前LLM在社交机器人隐私识别方面与人类偏好存在显著差距，指出了LLM赋能的社交机器人面临的关键隐私挑战。其创新之处在于结合了用户调研和LLM测试，并引入了情境完整性框架来构建隐私场景。研究结果对未来开发更具隐私意识的AI系统具有重要指导意义，但也提示了在实际部署前仍需解决LLM的隐私对齐问题。

<details>
  <summary>Details</summary>

**Motivation:** 社交机器人需要收集敏感个人数据以实现增强的人机交互，这导致了实用性与隐私风险之间的冲突。因此，评估当前LLM如何管理敏感数据至关重要，特别是LLM赋能的社交机器人在家庭环境中的隐私意识。

**Method:** 研究首先通过情境完整性(CI)视角设计了一系列隐私相关场景。然后，调查了用户对家庭社交机器人行为的隐私偏好(N=450)，并分析了隐私倾向对其选择的影响。接着，将相同的场景和问题提供给10个最先进的LLM。最后，为了进一步探究LLM作为潜在隐私控制器的能力，实施了四种额外的提示策略并比较了结果。

**Result:** 研究发现，LLM与人类在隐私偏好上的协议程度较低。通过不同的提示策略，LLM在作为潜在隐私控制器方面的能力仍有待提升。

**Conclusion:** 本研究讨论了AI隐私意识在人机交互中的影响和潜力，强调了在LLM赋能的社交机器人中提升隐私识别能力的重要性。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在社交机器人决策中处理敏感个人信息的隐私识别能力。鉴于社交机器人需要收集大量用户数据，且LLMs常处理敏感信息，研究通过情境完整性视角设计了隐私场景，调查了用户隐私偏好（N=450），并测试了10个主流LLMs。结果显示，LLMs与人类在隐私偏好上的一致性较低。研究还探讨了不同提示策略对LLMs作为隐私控制器的影响，并讨论了AI隐私意识在人机交互中的重要性。

> **摘要翻译:** 社交机器人是遵循人类交流规范并与人互动的具身代理。这些机器人通过口头和非口头线索进行互动，并与人共享物理环境。虽然社交机器人以前曾利用基于规则的系统或概率模型进行用户互动，但大型语言模型（LLMs）的快速发展为开发LLM赋能的社交机器人以增强人机交互提供了新的机会。然而，为了充分实现这些能力，机器人需要收集音频、细粒度图像、视频和位置等数据。因此，LLMs经常处理敏感的个人信息，尤其是在家庭环境中。鉴于实用性与隐私风险之间的紧张关系，评估当前LLMs如何管理敏感数据至关重要。具体而言，我们旨在探讨开箱即用的LLMs在家庭社交机器人情境下的隐私意识程度。在本研究中，我们提出了一组通过情境完整性（CI）视角精心设计的隐私相关场景。我们首先调查了用户对家庭社交机器人行为的隐私偏好，然后检查了他们的隐私倾向如何影响他们对这些行为的选择（N = 450）。然后，我们将相同的场景和问题提供给最先进的LLMs（N = 10），发现人类和LLMs之间的一致性较低。为了进一步研究LLMs作为潜在隐私控制器的能力，我们实施了四种额外的提示策略并比较了它们的结果。最后，我们讨论了AI隐私意识在人机交互中的影响和潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [552] [Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment](https://arxiv.org/abs/2311.01059)
> *即时适应：单次部署机器人行为调制*

*Annie S. Chen, Govind Chada, Laura Smith, Archit Sharma, Zipeng Fu, Sergey Levine, Chelsea Finn* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 机器人适应, 行为调制, 即时学习, 分布外泛化, 四足机器人

**Comment:** 

> **TL;DR:** 本文提出了一种名为ROAM的方法，使机器人在单次部署中能够即时、无人监督地适应新颖场景，且效率比现有方法高两倍以上。

**AI_Comments:** 该论文的创新之处在于其提出的ROAM方法实现了机器人单次部署期间的即时行为适应，且无需人工干预，这对于机器人部署到复杂多变真实环境具有重要意义。特别是在单个回合内完成适应，提高了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为使机器人在现实世界中取得成功，它们必须能够应对与训练时不同的新颖情况。

**Method:** 本文提出了一种名为ROAM（RObust Autonomous Modulation）的方法。该方法基于预训练行为的感知价值，以选择和适应当前情境下的预训练行为。这一适应过程在测试时的单个回合内完成，无需任何人工监督。

**Result:** ROAM使机器人能够快速适应动态变化，并在仿真和真实的Go1四足机器人上进行了验证，甚至成功地穿着旱冰鞋前进。与现有方法相比，ROAM在部署过程中面对各种分布外情况时，适应效率提高了2倍以上。

**Conclusion:** ROAM方法能够使机器人在部署过程中即时、高效地适应新颖和分布外的情况。

> **ai_Abstract:** 本文提出了一种名为ROAM的机器人行为调制方法，旨在解决机器人在现实世界中应对训练未见新颖场景的问题。ROAM通过评估预训练行为的价值，在单个测试回合内无人监督地即时选择和调整这些行为以适应当前情境。实验表明，该方法使机器人在仿真和真实机器人上都能快速适应动态变化，并且在面对分布外情况时，适应效率比现有方法高出两倍以上。

> **摘要翻译:** 为了在现实世界中取得成功，机器人必须能够应对与训练时不同的情况。我们研究了在部署过程中即时适应这些新颖场景的问题，通过利用先前学习的多种行为库。我们的方法，即鲁棒自主调制（ROAM），引入了一种基于预训练行为感知价值的机制，以选择和适应当前情境下的预训练行为。至关重要的是，这个适应过程在测试时都在单个回合内完成，无需任何人工监督。我们证明了ROAM使机器人能够快速适应仿真和真实Go1四足机器人上的动态变化，甚至成功地穿着旱冰鞋前进。与现有方法相比，我们的方法在部署过程中面对各种分布外情况时，通过有效选择和即时适应相关行为，适应效率提高了2倍以上。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [581] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
> *等变目标条件对比强化学习*

*Arsh Tangri, Nichols Crawford Taylor, Haojie Huang, Robert Platt* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 等变强化学习, 对比学习, 目标条件强化学习, 机器人操作, 对称性

**Comment:** 

> **TL;DR:** 论文提出了等变对比强化学习（ECRL），通过利用等变约束和对称性，提高了目标条件操作任务的样本效率和空间泛化能力，在多种设置（包括离线RL）下均优于基线。

**AI_Comments:** 本文的创新之处在于将等变约束整合到对比强化学习（CRL）中，特别是针对目标条件操作任务。通过正式定义群不变MDP并提出新颖的旋转不变评论家和旋转等变行动者，该论文有效利用了对称性来解决样本效率和空间泛化方面的挑战，这对于机器人应用至关重要。其扩展到离线强化学习进一步拓宽了其适用性。

<details>
  <summary>Details</summary>

**Motivation:** 对比强化学习（CRL）在无需手动设计奖励的情况下，通过提取结构化表示来学习策略，具有广阔前景。本文旨在通过使用等变约束来进一步构造潜在空间，利用目标条件操作任务中固有的对称性，从而提高CRL的样本效率和空间泛化能力。

**Method:** 本文提出了等变对比强化学习（ECRL）。它正式定义了目标条件群不变马尔可夫决策过程（Goal-Conditioned Group-Invariant MDPs）来表征旋转对称的机器人操作任务。ECRL引入了一种新颖的旋转不变评论家表示，并将其与旋转等变行动者结合用于对比强化学习。该方法还扩展到了离线强化学习设置。

**Result:** ECRL在状态和图像两种设置下，一系列模拟任务中持续优于强大的基线。它还在离线强化学习设置中展现出在多任务上的有效性。

**Conclusion:** 本文得出结论，等变对比强化学习（ECRL）通过等变约束利用固有对称性，提高了目标条件操作任务的样本效率和空间泛化能力，证明了其优于基线的性能以及在离线强化学习中的适用性。

> **ai_Abstract:** 本文提出了等变对比强化学习（ECRL），通过引入等变约束来增强对比强化学习（CRL），利用目标条件操作任务中的对称性。ECRL定义了目标条件群不变MDP，并引入了旋转不变评论家与旋转等变行动者的组合，从而提高了样本效率和空间泛化能力。该方法在各种模拟设置中持续优于强大的基线，并扩展到离线强化学习。

> **摘要翻译:** 对比强化学习（CRL）提供了一个有前景的框架，用于从未标记的交互中提取有用的结构化表示。通过将状态-动作对及其对应的未来状态拉近，同时将负样本推开，CRL能够在没有手动设计奖励的情况下学习非平凡的策略。在这项工作中，我们提出了等变CRL（ECRL），它利用等变约束进一步构建潜在空间。通过利用目标条件操作任务中固有的对称性，我们的方法提高了样本效率和空间泛化能力。具体来说，我们正式定义了目标条件群不变MDP（Goal-Conditioned Group-Invariant MDPs）来表征旋转对称的机器人操作任务，并在此基础上引入了一种新颖的旋转不变评论家表示，并将其与旋转等变行动者结合用于对比强化学习。我们的方法在状态和图像两种设置下，一系列模拟任务中持续优于强大的基线。最后，我们将我们的方法扩展到离线强化学习设置，展示了其在多个任务中的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [600] [Human-Machine Shared Control Approach for the Takeover of Cooperative Adaptive Cruise Control](https://arxiv.org/abs/2407.11551)
> *合作式自适应巡航控制接管的人机共享控制方法*

*Haoran Wang, Zhexi Lian, Zhenning Li, Jiawei Wang, Arno Eichberger, Jia Hu, Yongyu Chen, Yongji Gao* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** CACC, 人机共享控制, 接管, Stackelberg博弈, 自动驾驶

**Comment:** IEEE Transactions on Intelligent Transportation Systems (2025)

> **TL;DR:** CACC接管时直接人工干预有风险，本研究提出一种人机共享控制方法，通过机器引导和人类反应函数集成，实现平稳安全的接管，并提升稳定性。

**AI_Comments:** 该研究提出了一种新颖的CACC接管人机共享控制方法，通过将接管过程建模为Stackelberg博弈并集成人类反应函数，有效解决了直接人工接管可能带来的安全隐患和不稳定性问题。其创新点在于机器作为领导者引导人类响应，这有助于实现更平滑、更安全的过渡。研究结果表明了该方法的有效性和实用性，尤其在提升安全性、保持稳定性以及减少交通影响方面具有显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 合作式自适应巡航控制（CACC）在如驶离高速公路等任务中需要人工接管，但直接人工接管存在重大风险，特别是CACC的跟车策略可能导致驾驶员感到不安全并急刹车，可能引发碰撞。

**Method:** 本研究提出一种间接人机共享控制方法，建模为Stackelberg博弈，其中机器充当领导者，人类充当追随者。机器引导人类响应以符合机器期望，帮助保持跟车稳定性。此外，将人类反应函数集成到机器的预测控制系统中，超越了简单的“预测-规划”流程，以增强规划最优性。

**Result:** 控制器验证结果包括：i) 能够实现CACC的平稳接管操作；ii) 在车队少于6辆CAV且人工控制权限小于40%的条件下确保串行稳定性；iii) 通过机器干预增强感知和实际安全性；以及iv) 将对上游交通的影响降低高达60%。

**Conclusion:** 该人机共享控制方法能够实现CACC的平稳安全接管，并在特定条件下确保系统稳定性，同时提升安全性和减少交通影响。

> **ai_Abstract:** 本研究提出一种针对合作式自适应巡航控制（CACC）接管的人机共享控制方法，旨在解决直接人工接管带来的安全风险。该方法将接管建模为Stackelberg博弈，机器作为领导者引导人类，并集成人类反应函数以优化控制规划。实验结果表明，该控制器能实现平稳接管，在特定条件下保证串行稳定性，提升安全感知与实际安全性，并显著减少对上游交通的影响。

> **摘要翻译:** 合作式自适应巡航控制（CACC）通常需要人工接管，例如驶离高速公路。直接人工接管可能会带来重大风险，特别是考虑到CACC采用的近距离跟车策略，这可能导致驾驶员感到不安全并执行急刹车，从而可能导致碰撞。本研究旨在开发一种CACC接管控制器，以确保从自动化控制到人工控制的平稳过渡。所提出的CACC接管策略采用间接人机共享控制方法，建模为Stackelberg博弈，其中机器充当领导者，人类充当追随者。机器引导人类以符合机器预期的方式进行响应，有助于保持跟车稳定性。此外，人类反应函数被整合到机器的预测控制系统中，超越了简单的“预测-规划”流程，以增强规划最优性。该控制器已验证：i) 能够实现CACC的平稳接管操作；ii) 在车队少于6辆CAV且人工控制权限小于40%的条件下确保串行稳定性；iii) 通过机器干预增强感知和实际安全性；以及iv) 将对上游交通的影响降低高达60%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [610] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
> *扫描机器人：使用全景相机进行高效扫描规划*

*Euijeong Lee, Kyung Min Han, Young J. Kim* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 扫描规划, 全景相机, 3D重建, 自动导航, 视点规划

**Comment:** 

> **TL;DR:** 该论文提出了一种全自动扫描规划系统，用于全景RGB-D相机，可实现高效、无碰撞的扫描路径，并确保视点之间足够的重叠，比现有技术更快、覆盖率更高。

**AI_Comments:** 该论文的创新之处在于其全自动的扫描规划方法，直接解决了使用全景相机进行3D重建时效率和易用性的关键痛点。其显著的扫描速度提升和高覆盖率证明了其重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 操作全景RGB-D相机进行3D场景重建时，手动选择视点和物理移动相机耗时且繁琐，对于新手用户来说，由于空间限制（如确保视点帧之间足够的特征重叠）也具有挑战性。

**Method:** 我们提出了一种全自动扫描规划方法，该方法生成一个高效的环境扫描巡回计划，确保无碰撞导航和计划内视点之间足够的重叠。

**Result:** 在真实世界实验中，我们的方法实现了99%的平均扫描覆盖率，并且在总扫描时间上比现有技术快3倍。

**Conclusion:** 所提出的全自动扫描规划器显著提高了使用全景相机进行3D重建的效率和覆盖率，优于现有技术。

> **ai_Abstract:** 本论文提出了一种名为“扫描机器人”的全自动扫描规划系统，旨在解决使用全景RGB-D相机进行3D场景重建时手动操作的效率低下和复杂性问题。该系统能够生成高效的、无碰撞的扫描路径，并确保视点之间有足够的特征重叠。通过在合成和真实世界环境中的广泛实验，验证了该规划器的性能，结果显示其在真实世界中实现了99%的平均扫描覆盖率，并且总扫描时间比现有技术快3倍。

> **摘要翻译:** 全景RGB-D相机以其生成高质量3D场景重建的能力而闻名。然而，操作这些相机需要手动选择视点并物理移动相机，这使得3D模型的生成既耗时又繁琐。此外，由于空间限制，例如确保视点帧之间有足够的特征重叠，这个过程对于新手用户来说可能具有挑战性。为了应对这些挑战，我们提出了一种全自动扫描规划方法，该方法为环境扫描生成一个高效的巡回计划，确保无碰撞导航和计划内视点之间足够的重叠。在合成和真实世界环境中进行的广泛实验验证了我们规划器相对于现有视点规划器的性能。特别是，我们的方法在真实世界实验中达到了99%的平均扫描覆盖率，并且我们的方法在总扫描时间上比现有技术快3倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [641] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
> *用于安全接近机动的双噪声自适应相对位姿估计算法框架*

*Batu Candan, Simone Servadio* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 相对位姿估计, 主动碎片清除, 无迹卡尔曼滤波, 噪声自适应, 计算机视觉

**Comment:** 

> **TL;DR:** 本文提出了一种结合计算机视觉和自适应非线性滤波的集成系统，用于在主动碎片清除任务中对翻滚卫星进行鲁棒的相对位姿估计，并通过双重噪声自适应策略增强了鲁棒性。

**AI_Comments:** 该论文的创新点在于其集成系统架构以及UKF中独特的双重噪声自适应策略，这显著增强了系统对测量不确定性和未建模动力学的鲁棒性。这对于高风险的主动碎片清除任务至关重要，因为这些任务要求极高的精度和可靠性。通过结合CNN的感知能力和自适应滤波的动态估计能力，该工作为复杂的空间交会操作提供了一个实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 准确和鲁棒的相对位姿估计对于执行针对翻滚废弃卫星（如ESA的ENVISAT）的挑战性主动碎片清除（ADR）任务至关重要。

**Method:** 该方法整合了先进的计算机视觉技术和自适应非线性滤波。具体来说，使用经过图像预处理增强的卷积神经网络（CNN）检测追逐器图像中的结构标记（角点），其2D坐标通过相机模型转换为3D测量。这些测量在非线性相对动力学处理能力强的无迹卡尔曼滤波（UKF）框架内进行融合，以估计完整的相对位姿。关键贡献是集成的系统架构和UKF内的双重自适应策略：测量噪声协方差的动态调整以补偿变化的CNN测量不确定性；以及利用测量残差分析的过程噪声协方差的自适应调整，以解决未建模的动力学或在线机动。

**Result:** 所提出的自适应集成系统在利用逼真ENVISAT模型的高保真模拟中进行了性能评估，在包括测量中断在内的各种条件下，将估计值与真实值进行了比较。结果表明，该综合方法为鲁棒的机载相对导航提供了增强的解决方案。

**Conclusion:** 该综合方法为鲁棒的机载相对导航提供了增强的解决方案，显著提升了主动碎片清除任务中安全接近操作所需的能力。

> **ai_Abstract:** 本文提出了一种用于主动碎片清除（ADR）任务中翻滚卫星相对位姿估计的自适应框架。该框架结合了基于CNN的计算机视觉技术进行2D/3D测量提取，并利用无迹卡尔曼滤波（UKF）进行状态估计。核心创新在于UKF中引入的双重自适应策略：动态调整测量噪声协方差以应对CNN测量不确定性，以及自适应调整过程噪声协方差以补偿未建模的动力学。高保真模拟结果表明，该系统在各种条件下，包括测量中断，都能提供鲁棒的相对导航能力，从而提升了ADR任务中安全接近操作的性能。

> **摘要翻译:** 准确和鲁棒的相对位姿估计对于执行针对翻滚废弃卫星（如ESA的ENVISAT）的挑战性主动碎片清除（ADR）任务至关重要。本文提出了一个完整的管道，将先进的计算机视觉技术与自适应非线性滤波相结合，以解决这一挑战。一个通过图像预处理增强的卷积神经网络（CNN）从追逐器图像中检测结构标记（角点），其2D坐标通过相机模型转换为3D测量。这些测量在无迹卡尔曼滤波（UKF）框架内进行融合，该框架因其处理非线性相对动力学的能力而被选中，用于估计完整的相对位姿。主要贡献包括集成的系统架构和UKF内的双重自适应策略：测量噪声协方差的动态调整以补偿变化的CNN测量不确定性；以及利用测量残差分析的过程噪声协方差的自适应调整，以解决未建模的动力学或在线机动。这种双重自适应增强了对测量缺陷和动态模型不确定性的鲁棒性。所提出的自适应集成系统在利用逼真ENVISAT模型的高保真模拟中进行了性能评估，在包括测量中断在内的各种条件下，将估计值与真实值进行了比较。这种综合方法为鲁棒的机载相对导航提供了增强的解决方案，显著提升了主动碎片清除任务中安全接近操作所需的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [642] [PR2: A Physics- and Photo-realistic Humanoid Testbed with Pilot Study in Competition](https://arxiv.org/abs/2409.01559)
> *PR2：一个物理和照片级真实感的人形机器人测试平台及其在竞赛中的初步研究*

*Hangxin Liu, Qi Xie, Zeyu Zhang, Tao Yuan, Song Wang, Zaijin Wang, Xiaokun Leng, Lining Sun, Jingwen Zhang, Zhicheng He, Yao Su* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 人形机器人, 测试平台, 具身AI, 机器人仿真, 竞赛

**Comment:** 

> **TL;DR:** PR2是一个物理和照片级真实感的人形机器人测试平台，旨在促进具身AI和机器人学的研究。它已成功应用于全国性人形机器人竞赛，并计划公开发布以推动人形机器人教育和训练。

**AI_Comments:** PR2测试平台通过结合物理和照片级真实感，为具身AI和机器人学的研究提供了一个重要的集成环境。其创新之处在于不仅提供高保真仿真，还通过实际竞赛验证了平台的有效性和吸引力。公开发布的策略将极大地促进该领域的研究和教育，特别是对于处理复杂人形机器人行为的挑战性任务。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在开发一个物理和照片级真实感的人形机器人测试平台PR2，以促进具身人工智能（Embodied AI）和机器人学之间的协作研究。

**Method:** PR2测试平台提供了高质量的场景渲染和机器人动态仿真，支持：(i) 使用各种数字资产创建多样化场景；(ii) 集成先进的感知或基础模型；(iii) 基于环境反馈实现动态人形机器人行为的规划和控制算法。其测试版已用于一项全国性大学生全尺寸人形机器人竞赛的仿真赛道。

**Result:** PR2的测试版已成功应用于一项全国性大学生全尺寸人形机器人竞赛的仿真赛道，在四个月内吸引了137支队伍和超过400名参与者。该竞赛涵盖了双足行走等传统任务以及运动-操作和基于语言指令的物体搜索等新颖挑战。对竞赛的回顾性分析表明，未来的赛事应强调运动与操作和感知的整合。

**Conclusion:** PR2测试平台已成功部署并用于人形机器人竞赛，证明了其在推动具身AI和机器人研究方面的潜力。未来的工作应侧重于运动、操作和感知的整合。通过公开发布PR2，作者旨在进一步推进人形机器人领域的教育和训练。

> **ai_Abstract:** 本文介绍了PR2，一个物理和照片级真实感的人形机器人测试平台，旨在促进具身AI和机器人学的交叉研究。PR2提供高质量的仿真环境，支持场景创建、高级模型集成以及规划控制算法的实现。其测试版已成功应用于一项全国性大学生人形机器人竞赛，吸引了大量参与者，并揭示了未来竞赛中运动、操作和感知整合的重要性。该平台将公开发布，以推动人形机器人领域的教育和训练。

> **摘要翻译:** 本文介绍了一个物理真实感和照片真实感的人形机器人测试平台PR2的开发，旨在促进具身人工智能（具身AI）和机器人学之间的协作研究。PR2提供高质量的场景渲染和机器人动态仿真，能够（i）使用各种数字资产创建多样化场景，（ii）集成先进的感知或基础模型，以及（iii）根据环境反馈实现动态人形机器人行为的规划和控制算法。PR2的测试版已部署用于全国大学生全尺寸人形机器人竞赛的仿真赛道，在四个月内吸引了137支队伍和400多名参与者。此次竞赛涵盖了双足行走的传统任务，以及运动-操作和基于语言指令的物体搜索等新颖挑战，这在公共大学机器人竞赛中尚属首次。对竞赛的回顾性分析表明，未来的赛事应强调运动与操作和感知的整合。通过在https://github.com/pr2-humanoid/PR2-Platform 公开发布PR2测试平台，我们旨在进一步推进人形机器人领域的教育和训练。视频演示：https://pr2-humanoid.github.io/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [671] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
> *GFM-Planner：基于几何特征度量的感知感知轨迹规划*

*Yue Lin, Xiaoxuan Zhang, Yang Liu, Dong Wang, Huchuan Lu* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 几何特征度量, 感知感知轨迹规划, 激光雷达定位, GFM-Planner, 机器人导航

**Comment:** Accepted by IROS 2025

> **TL;DR:** GFM-Planner是一个感知感知的轨迹规划框架，通过引导机器人避开特征退化区域并选择特征丰富的路径，显著提高了激光雷达的定位精度。

**AI_Comments:** 该论文的创新点在于将几何特征度量引入到轨迹规划中，使得机器人能够主动地在规划路径时考虑定位精度，避免进入特征退化区域。这种“感知感知”的规划方法对于提高自主机器人在复杂环境中的鲁棒性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动机器人需要特征丰富的环境来实现准确的定位，而现有的方法可能在特征退化区域表现不佳。该研究旨在通过引导机器人避开这些区域来提高激光雷达的定位精度。

**Method:** 首先，从基本的激光雷达定位问题中推导出几何特征度量（GFM）。其次，设计一个基于2D网格的度量编码图（MEM）来高效存储环境中的GFM值，并提出常数时间解码算法。最后，开发一种感知感知的轨迹规划算法，通过引导机器人在选择轨迹时穿过特征丰富的区域来提高激光雷达定位能力。

**Result:** 仿真和实际实验都表明，该方法使机器人能够主动选择显著提高激光雷达定位精度的轨迹。

**Conclusion:** GFM-Planner通过整合几何特征度量和感知感知的轨迹规划，成功地提高了激光雷达的定位精度，使机器人在选择路径时能够主动避开特征退化区域。

> **ai_Abstract:** 本文提出了GFM-Planner，一个感知感知的轨迹规划框架，旨在通过利用几何特征度量来提高激光雷达的定位精度。该框架首先从激光雷达定位问题中推导出几何特征度量（GFM），然后构建一个2D网格的度量编码图（MEM）来高效存储GFM值，并开发了相应的常数时间解码算法。最后，通过设计一种感知感知的轨迹规划算法，引导机器人选择特征丰富的路径，从而避免定位精度下降。实验证明，该方法能显著提高激光雷达的定位精度。

> **摘要翻译:** 像人类依赖地标进行定位一样，自主机器人依赖于特征丰富的环境来实现准确的定位。在本文中，我们提出了GFM-Planner，一个基于几何特征度量的感知感知轨迹规划框架，它通过引导机器人避开退化区域来提高激光雷达的定位精度。首先，我们从基本的激光雷达定位问题中推导出几何特征度量（GFM）。接下来，我们设计了一个基于2D网格的度量编码图（MEM），以有效地存储环境中的GFM值。进一步提出了一种常数时间解码算法，用于从MEM中检索任意姿态的GFM值。最后，我们开发了一种感知感知的轨迹规划算法，通过引导机器人在选择轨迹时穿过特征丰富的区域来提高激光雷达定位能力。仿真和实际实验都表明，我们的方法使机器人能够主动选择显著提高激光雷达定位精度的轨迹。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [678] [Asymptotically Optimal Lazy Lifelong Sampling-based Algorithm for Efficient Motion Planning in Dynamic Environments](https://arxiv.org/abs/2409.06521)
> *动态环境中高效运动规划的渐近最优惰性终身采样算法*

*Lu Huang, Jingwen Yu, Jiankun Wang, Xingjian Jing* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 运动规划, 动态环境, 采样算法, 惰性搜索, 终身规划

**Comment:** 

> **TL;DR:** 提出了一种结合终身规划和惰性搜索的渐近最优采样算法，用于动态环境中快速且高效的运动规划。

**AI_Comments:** 该论文的创新点在于结合了终身规划和惰性搜索的优势，并引入了“知情重布线级联”机制，有效解决了动态环境中运动规划的效率和重新规划问题。其渐近最优性保证了长期性能，而实验结果则验证了其在复杂高维空间和实际动态场景中的优越性和可行性。这对于机器人自主导航和操作具有重要意义，尤其是在需要快速响应变化环境的应用中。

<details>
  <summary>Details</summary>

**Motivation:** 针对动态环境中需要快速重新规划且边评估成本高昂的问题。

**Method:** 提出了一种渐近最优的终身采样路径规划算法，结合了终身规划和惰性搜索算法的优点。通过仅评估最优解的子路径候选项来节省评估时间。采用新颖的“知情重布线级联”来高效修复搜索树。

**Result:** 理论分析表明，在给定足够规划时间的情况下，该算法收敛到最优解。在具有$\mathbb{SE}(3)$和$\mathbb{R}^7$状态空间的机器人系统上，该算法在静态和动态运动规划任务中均表现优于现有最先进的采样规划器。在有移动行人的动态环境中为Turtlebot 4规划的实验进一步验证了算法的可行性和优势。

**Conclusion:** 该算法是一种渐近最优的终身采样算法，能够高效地在动态环境中进行运动规划，并在理论和实践中均显示出优越性能和可行性。

> **ai_Abstract:** 本文提出了一种渐近最优的终身采样路径规划算法，旨在解决动态环境中快速重新规划和高昂边评估成本的问题。该算法结合了终身规划和惰性搜索的优点，通过仅评估最优子路径候选来显著减少评估时间。它还引入了一种新颖的知情重布线级联机制来高效维护搜索树。理论分析证明了其渐近最优性，并通过在复杂机器人系统（如$\mathbb{SE}(3)$和$\mathbb{R}^7$）上的实验，以及在包含移动行人的动态环境中对Turtlebot 4的规划验证，展示了其在静态和动态任务中均优于现有先进算法的卓越性能和实用性。

> **摘要翻译:** 本文介绍了一种渐近最优的终身采样路径规划算法，该算法结合了终身规划算法和惰性搜索算法的优点，用于在边评估成本高昂的动态环境中进行快速重新规划。通过仅评估最优解的子路径候选项，该算法节省了大量的评估时间，从而降低了总规划成本。它采用了一种新颖的知情重布线级联来在底层搜索图发生变化时高效修复搜索树。理论分析表明，只要给予足够的规划时间，所提出的算法就会收敛到最优解。在具有$\mathbb{SE}(3)$和$\mathbb{R}^7$状态空间的机器人系统上，在具有挑战性的环境中进行的规划结果突出显示了所提出的算法在静态和动态运动规划任务中均优于各种最先进的基于采样的规划器。为在有多个移动行人的动态环境中运行的Turtlebot 4进行的规划实验进一步验证了所提出算法的可行性和优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [701] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
> *基于仿生机制的幕墙安装机器人轨迹规划*

*Xiao Liu, Weijun Wang, Tianlun Huang, Zhiyong Wang, Wei Feng* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 轨迹规划, 仿生机制, 幕墙安装机器人, 能耗优化, 粒子群优化

**Comment:** 

> **TL;DR:** 该研究受人体上肢运动启发，提出一种仿生轨迹规划框架，通过PSO算法优化机器人轨迹，实现了幕墙安装机器人能耗显著降低。

**AI_Comments:** 这项研究的创新之处在于其仿生学方法，将人体运动的能量转换原理应用于机器人轨迹规划，以降低能耗。对于建筑机器人特别是幕墙安装机器人，能耗是实际应用中的一大限制，因此该研究具有重要的实践意义。通过具体的能耗降低百分比（48.4%）展示了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人市场快速发展，但能耗问题限制了建筑机器人的应用，特别是幕墙安装机器人。

**Method:** 研究受人类上肢举重运动力学启发，提出仿生轨迹规划框架。通过收集哑铃弯举运动轨迹和肌电信号，构建整合人体用力模式和能耗模式的拟人化轨迹规划。利用粒子群优化（PSO）算法，基于类人运动特征实现机械臂轨迹规划的动态负载分配。

**Result:** 仿真结果显示，通过动能与势能的智能转换，能耗降低了48.4%。该方法在幕墙安装任务中得到验证，证明了其正确性和优越性。

**Conclusion:** 该方法为优化幕墙安装机器人在实际搬运任务中的能源使用提供了新见解和理论支持。

> **ai_Abstract:** 本文提出一种受人体上肢运动启发的仿生轨迹规划框架，旨在解决建筑机器人能耗高的问题。通过收集人体运动数据和肌电信号，结合PSO算法优化机器人轨迹，实现了动能与势能的智能转换，从而显著降低了幕墙安装机器人的能耗（仿真结果显示降低48.4%）。该研究为机器人能耗优化提供了新的思路和理论支持。

> **摘要翻译:** 随着机器人市场的快速发展，能源消耗已成为一个关键问题，尤其限制了建筑机器人的应用。为解决这一挑战，本研究创新性地从人体上肢举重运动力学中汲取灵感，提出了一种结合人体能量转换原理的仿生轨迹规划框架。通过收集哑铃弯举过程中的运动轨迹和肌电信号，我们构建了一种整合人体用力模式和能耗模式的拟人化轨迹规划。利用粒子群优化（PSO）算法，我们基于类人运动特征实现了机械臂轨迹规划的动态负载分配。在实际应用中，这些仿生运动特性被应用于幕墙安装任务，验证了我们轨迹规划方法的正确性和优越性。仿真结果表明，通过动能和势能之间的智能转换，能耗降低了48.4%。这种方法为优化幕墙安装机器人在实际搬运任务中的能源使用提供了新的见解和理论支持。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [722] [Bundle Adjustment in the Eager Mode](https://arxiv.org/abs/2409.12190)
> *即时模式下的捆集调整*

*Zitong Zhan, Huan Xu, Zihang Fang, Xinpeng Wei, Yaoyu Hu, Chen Wang* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 捆集调整, PyTorch, 深度学习, GPU加速, SLAM

**Comment:** 

> **TL;DR:** 本文介绍了一个新的即时模式捆集调整（BA）库，它与 PyTorch 无缝集成，并利用 GPU 加速和可微分操作，与现有 C++ 库相比实现了显著的运行时效率提升。

**AI_Comments:** 本文通过在 PyTorch 中原生实现捆集调整，成功弥合了传统计算机视觉优化与现代深度学习框架之间的鸿沟，具有重要意义。其 GPU 加速和可微分特性对于开发端到端感知系统至关重要，能够同时利用深度学习的强大能力和 BA 的几何精度。显著的性能提升也证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于 C++ 的捆集调整（BA）库（如 GTSAM、g2o 和 Ceres）缺乏与 PyTorch 等现代深度学习库的原生集成，这限制了它们的灵活性、适应性、调试便利性和整体实现效率，而将 BA 与深度学习框架集成对于提高感知系统的可靠性和性能日益重要。

**Method:** 作者引入了一个与 PyTorch 无缝集成且高效的即时模式捆集调整（BA）库。该方法包括为二阶优化、李群和李代数操作以及线性求解器设计的 GPU 加速、可微分和稀疏操作。

**Result:** 基于 GPU 的即时模式 BA 表现出显著的运行时效率，与 GTSAM、g2o 和 Ceres 相比，分别平均加速了 18.5 倍、22 倍和 23 倍。

**Conclusion:** 本文成功开发了一个高效的、与 PyTorch 集成的即时模式捆集调整库，该库在性能上超越了传统的 C++ 库，有效解决了 BA 与深度学习框架之间集成不足的问题。

> **ai_Abstract:** 本文旨在解决传统 C++ 捆集调整（BA）库与现代深度学习框架（如 PyTorch）之间缺乏原生集成的问题。为此，论文提出了一种高效的、基于 GPU 加速的、可微分的即时模式 BA 库，该库专为 PyTorch 构建，支持稀疏操作、二阶优化以及李群/代数运算。实验结果表明，与现有 C++ BA 库相比，该库实现了显著的速度提升（18.5 倍至 23 倍），从而提高了感知系统的灵活性和效率。

> **摘要翻译:** 捆集调整（BA）是同步定位与建图（SLAM）、增强现实（AR）和摄影测量等各种机器人应用中的关键技术。BA 优化相机姿态和 3D 地标等参数，使其与观测值对齐。随着深度学习在感知系统中日益重要，越来越需要将 BA 与深度学习框架集成，以提高可靠性和性能。然而，广泛使用的基于 C++ 的 BA 库，如 GTSAM、g2o 和 Ceres，缺乏与 PyTorch 等现代深度学习库的原生集成。这一限制影响了它们的灵活性、适应性、调试便利性以及整体实现效率。为了解决这一差距，我们引入了一个与 PyTorch 无缝集成且高效的即时模式 BA 库。我们的方法包括为二阶优化、李群和李代数操作以及线性求解器设计的 GPU 加速、可微分和稀疏操作。我们的基于 GPU 的即时模式 BA 表现出显著的运行时效率，与 GTSAM、g2o 和 Ceres 相比，分别平均加速了 18.5 倍、22 倍和 23 倍。源代码将发布在 https://github.com/sair-lab/bae。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [737] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
> *建筑机器人腿部结构设计与尺寸优化*

*Xiao Liu, Xianlong Yang, Weijun Wang, Wei Feng* | **Category: cs.RO** | **Updated: 2025-07-22**

**Keywords:** 建筑机器人, 腿部结构, 尺寸优化, 运动性能, 可操作性

**Comment:** 

> **TL;DR:** 针对建筑机器人，本文提出并优化了腿部结构尺寸，以提高其在复杂环境中的移动能力。

**AI_Comments:** 本文创新性地将自然界蚂蚁的腿部设计思想应用于建筑机器人，并结合了多种优化方法（图形优化、数值求解、虚拟仿真），形成了一个多维定量评估框架，为解决建筑机器人复杂地形适应性问题提供了新的思路和结构设计基础，具有重要的工程实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 轮式和履带式机器人在复杂非结构化建筑环境中地形适应性和灵活性受限，难以满足自主操作要求。

**Method:** 本文分析了腿部在摆动和支撑阶段的完整操作运动性能。首先，基于运动学建模和多维工作空间分析，引入“改进工作空间”概念，并用图形方法优化摆动阶段腿部尺寸。其次，基于速度雅可比矩阵引入“平均可操作性”概念，并用数值解获得最大可操作性的腿节比。最后，在ADAMS中进行虚拟样机仿真，探索机器人本体最佳柔韧性与腿节比例的关系。

**Result:** 获得了具有最佳综合运动性能的腿节比例，并提出了首个针对建筑环境的腿部运动性能多维定量评估框架。

**Conclusion:** 本研究为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础。

> **ai_Abstract:** 本文针对建筑机器人，提出了一种受蚂蚁启发的腿部结构设计与优化方法，以克服传统机器人在复杂建筑环境中移动性差的局限。研究通过运动学建模、引入“改进工作空间”和“平均可操作性”概念，并结合ADAMS虚拟仿真，优化了腿部尺寸和节段比例，最终获得综合运动性能最佳的腿节比例，并建立了腿部运动性能的多维定量评估框架，为腿式建筑机器人在复杂地形中的自主移动奠定了结构设计基础。

> **摘要翻译:** 面对复杂和非结构化的建筑环境，轮式和履带式机器人在地形适应性和灵活性方面表现出显著的局限性，难以满足自主操作的要求。受自然界蚂蚁的启发，本文提出了一种专为建筑场景量身定制的腿部配置设计和优化方法，旨在增强建筑机器人的自主移动能力。本文分析了腿部在摆动和支撑阶段的完整操作运动性能。首先，基于运动学建模和多维工作空间分析，引入了“改进工作空间”的概念，并采用图形方法优化了摆动阶段的腿部尺寸。此外，基于速度雅可比矩阵引入了“平均可操作性”的新概念，并应用数值解获得了最大可操作性的腿节比。为了克服传统分析方法带来的困难，在ADAMS中进行了虚拟样机仿真，以探索机器人本体的最佳柔韧性与腿节比例之间的关系。总而言之，获得了具有最佳综合运动性能的腿节比例。本研究首次提出了针对建筑环境的腿部运动性能多维定量评估框架，为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [3] [Beyond Label Semantics: Language-Guided Action Anatomy for Few-shot Action Recognition](https://arxiv.org/abs/2507.16287)
> *超越标签语义：语言引导的动作解剖用于少样本动作识别*

*Zefeng Qian, Xincheng Yao, Yifei Huang, Chongyang Zhang, Jiangyong Ying, Hong Sun* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 少样本动作识别, 语言引导动作解剖, 大型语言模型, 多模态匹配, 时空线索

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了语言引导的动作解剖（LGA）框架，利用大型语言模型（LLMs）和视觉解剖模块，通过解剖动作的原子特征来克服标签语义的局限性，并在少样本动作识别（FSAR）任务中实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于超越了传统的标签语义，利用大型语言模型（LLMs）的强大能力来“解剖”动作，提取其深层次的原子特征。这种语言引导的动作解剖方法，结合视觉原子阶段的分割与细粒度融合，为少样本动作识别提供了一个新颖且有效的范式。其重要性在于有效缓解了FSAR中数据稀缺的问题，并为多模态学习在细粒度动作理解方面的应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 少样本动作识别（FSAR）面临训练数据稀缺的问题。现有方法仅依赖动作标签，无法充分利用人类姿态、运动动力学和对象交互等动作中固有的、细微的关键知识。

**Method:** 本文提出了语言引导的动作解剖（LGA）框架。具体来说，LGA利用大型语言模型（LLMs）将动作标签解剖为原子动作描述序列，关注动作的主体、运动和对象三个核心元素。同时，一个视觉解剖模块将视频动作分割成原子视频阶段，以捕获动作的顺序结构。然后，采用细粒度融合策略在原子级别整合文本和视觉特征，生成更具泛化性的原型。最后，引入多模态匹配机制，包括视频-视频和视频-文本匹配，以确保鲁棒的少样本分类。

**Result:** 实验结果表明，LGA在多个FSAR基准测试中达到了最先进的性能。

**Conclusion:** LGA通过利用LLMs解剖动作的内在特征并结合视觉原子阶段，有效解决了少样本动作识别中数据稀缺和标签语义不足的问题，并在多个FSAR基准测试中实现了最先进的性能。

> **ai_Abstract:** 本文针对少样本动作识别（FSAR）中训练数据稀缺和现有方法无法充分利用动作内在细微知识的问题，提出了语言引导的动作解剖（LGA）框架。LGA利用大型语言模型（LLMs）将动作标签解剖为原子描述，并结合视觉解剖模块将视频分割为原子阶段。通过在原子级别融合文本和视觉特征，并采用多模态匹配机制，LGA能够捕获丰富的时空线索，并生成更具泛化性的原型。实验证明，LGA在多个FSAR基准测试中均取得了最先进的性能。

> **摘要翻译:** 少样本动作识别（FSAR）旨在通过每类别少量标注样本对视频中的人类动作进行分类。训练数据的稀缺性促使近期研究努力整合额外的模态，特别是文本。然而，人类姿态、运动动力学以及在不同阶段发生的对象交互的细微变化，是动作固有的关键知识，仅凭动作标签无法完全利用。在这项工作中，我们提出了语言引导的动作解剖（LGA），这是一个新颖的框架，它通过利用大型语言模型（LLMs）来剖析隐藏在动作标签下的基本表征特征，从而超越了标签语义。在LLM中编码的先验知识的指导下，LGA在少样本场景中有效捕获了丰富的时空线索。具体而言，对于文本，我们提示一个现成的LLM将标签解剖成原子动作描述序列，重点关注动作的三个核心要素（主体、运动、对象）。对于视频，一个视觉解剖模块将动作分割成原子视频阶段，以捕获动作的顺序结构。然后，细粒度融合策略在原子级别整合文本和视觉特征，从而产生更具泛化性的原型。最后，我们引入了多模态匹配机制，包括视频-视频和视频-文本匹配，以确保鲁棒的少样本分类。实验结果表明，LGA在多个FSAR基准测试中达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [8] [Aligning AI with Public Values: Deliberation and Decision-Making for Governing Multimodal LLMs in Political Video Analysis](https://arxiv.org/abs/2410.01817)
> *将AI与公共价值观对齐：政治视频分析中多模态LLM治理的审议与决策*

*Tanusree Sharma, Yujin Potter, Zachary Kilhoffer, Yun Huang, Dawn Song, Yang Wang* | **Category: cs.CV, cs.AI, cs.CY** | **Updated: 2025-07-22**

**Keywords:** AI治理, 公共价值观, 政治视频分析, 去中心化自治组织, 多模态LLMs

**Comment:** 

> **TL;DR:** 本研究探讨了AI模型如何通过审议和决策来治理政治敏感视频，发现专家和公众对AI解读的优先级不同，并指出不同治理机制对AI行为决策的影响，强调去中心化AI治理的重要性。

**AI_Comments:** 这篇论文创新性地将去中心化自治组织（DAO）机制引入AI治理，特别是在政治敏感内容处理方面，为AI伦理和公共参与提供了新的实践路径。其发现不同群体对AI解释优先级的差异，对未来AI模型设计和政策制定具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** AI模型如何处理政治话题仍具挑战性，需要更好的治理，尤其是在政治敏感视频分析中。

**Method:** 本研究进行了两步：首先，采访了10名记者以建立专家视频解读的基线理解；其次，114名个体通过InclusiveAI平台（一个利用去中心化自治组织DAO机制促进民主决策的平台）进行审议。此外，研究还考察了二次投票与加权投票、平等与20/80投票权等不同治理机制对用户AI行为决策的影响。

**Result:** 研究发现，专家在视频解读中强调情感和叙事，而公众则优先考虑事实清晰性、客观性和情感中立性。投票方法显著影响结果，其中二次投票强化了对自由民主和政治平等的认知。

**Conclusion:** 选择适当的治理机制以更好地捕捉用户视角是必要的。去中心化AI治理是促进公众更广泛参与AI开发、确保多样化视角有效指导设计决策的潜在途径。

> **ai_Abstract:** 本研究探讨了在政治视频分析中，如何通过个体和集体审议来治理多模态大语言模型，以使AI行为与公共价值观对齐。通过专家访谈和公众在InclusiveAI平台上的审议，研究发现专家和公众对AI解读政治内容的优先级存在差异（专家重情感叙事，公众重事实客观）。同时，不同的投票治理机制显著影响AI决策结果，二次投票能更好地体现民主平等。研究强调了选择合适治理机制的重要性，并提出去中心化AI治理是促进公众参与AI开发，确保多样化视角融入AI设计的有效途径。

> **摘要翻译:** 人工智能模型应如何处理政治话题一直备受讨论，但这仍然具有挑战性，需要更好的治理。本文通过个体和集体审议，探讨大型语言模型的治理，重点关注政治敏感视频。我们进行了一项两步研究：首先，采访了10名记者，建立了专家视频解读的基线理解；其次，114名个体通过InclusiveAI平台进行了审议，该平台通过去中心化自治组织（DAO）机制促进民主决策。我们的研究结果揭示了解释优先级的显著差异：专家强调情感和叙事，而公众则优先考虑事实清晰性、客观性和情感中立性。此外，我们还考察了不同的治理机制——二次投票与加权投票，以及平等与20/80投票权——如何影响用户对AI行为的决策。结果表明，投票方法显著影响结果，其中二次投票强化了对自由民主和政治平等的认知。我们的研究强调了选择适当治理机制以更好地捕捉用户视角的必要性，并提出去中心化AI治理是促进公众更广泛参与AI开发、确保多样化视角有效指导设计决策的潜在途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [10] [RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment](https://arxiv.org/abs/2501.07525)
> *RadAlign：通过视觉-语言概念对齐推进放射学报告生成*

*Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 放射学报告生成, 视觉-语言模型, 大型语言模型, 概念对齐, 检索增强生成

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** RadAlign是一个结合了视觉-语言模型和大型语言模型的新框架，用于生成高质量、可解释的放射学报告，并减少幻觉。

**AI_Comments:** RadAlign的创新之处在于其将VLM和LLM相结合的框架，并引入了视觉-语言概念对齐和检索增强生成机制，有效提升了放射学报告生成的质量和可解释性，同时减少了幻觉。这对于临床工作流程中的自动化医学影像分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动胸部X光片解读面临挑战，当前方法要么牺牲可解释性以提高分类准确性，要么通过图像字幕技术生成详细但不甚可靠的报告。

**Method:** RadAlign模仿放射科医生的工作流程，首先使用专门的视觉-语言模型（VLM）将视觉特征与关键医学概念对齐，然后利用这些概念作为文本提示，通过大型语言模型（LLM）生成报告，并辅以检索增强生成（RAG）机制，以历史相似病例为基础。

**Result:** RadAlign在多种疾病上的平均AUC达到0.885，报告质量的GREEN分数为0.678，优于现有最先进方法的0.634。

**Conclusion:** RadAlign通过整合预测性和生成性AI，在保持强大的临床可解释性的同时减少幻觉，从而推进了自动化医学影像和报告分析。

> **ai_Abstract:** RadAlign是一个新颖的框架，旨在解决自动胸部X光片解读中疾病分类准确性和报告生成质量的挑战。它结合了视觉-语言模型（VLM）和大型语言模型（LLM）的优势，模仿放射科医生的工作流程。具体来说，RadAlign首先使用VLM将视觉特征与医学概念对齐以进行疾病分类，然后利用这些概念作为LLM的提示来生成报告，并结合检索增强生成机制来提高报告的准确性和可靠性。该框架在疾病分类（AUC 0.885）和报告质量（GREEN 0.678）上均表现出色，同时保持了可解释性并减少了幻觉。

> **摘要翻译:** 自动胸部X光片解读需要准确的疾病分类和详细的放射学报告生成，这在临床工作流程中提出了重大挑战。当前的方法要么以牺牲可解释性为代价专注于分类准确性，要么通过图像字幕技术生成详细但可能不可靠的报告。在本研究中，我们提出了RadAlign，一个结合了视觉-语言模型（VLM）的预测准确性与大型语言模型（LLM）推理能力的新颖框架。受放射科医生工作流程的启发，RadAlign首先采用专门的VLM将视觉特征与关键医学概念对齐，在多种疾病上实现了0.885的平均AUC，从而获得了卓越的疾病分类效果。这些被识别的医学状况，以文本概念形式呈现在对齐的视觉-语言空间中，随后被用于提示基于LLM的报告生成。通过一种检索增强生成机制（该机制将输出基于相似历史病例），RadAlign提供了卓越的报告质量，GREEN分数为0.678，优于现有最先进方法的0.634。我们的框架在保持强大的临床可解释性的同时减少了幻觉，通过集成预测性和生成性AI，推进了自动化医学影像和报告分析。代码可在https://github.com/difeigu/RadAlign 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [18] [CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast Cardiac Risk Prediction Using Cine MRIs](https://arxiv.org/abs/2507.16612)
> *CTSL：基于码本的时空学习，用于使用电影MRI进行准确的非对比心脏风险预测*

*Haoyang Su, Shaohao Rui, Jinyi Xiang, Lianming Wu, Xiaosong Wang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 心脏风险预测, 电影MRI, 自监督学习, 码本, 无造影剂

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** CTSL是一种自监督框架，通过学习原始电影MRI数据中的动态时空表示，实现无造影剂的心脏事件预测，优于传统方法。

**AI_Comments:** CTSL的创新之处在于其自监督学习范式，以及在无需造影剂和人工分割掩膜的情况下进行MACE预测的能力。这解决了临床实践中的一个重要限制，使心脏风险评估更加便捷和安全。多视图蒸馏和码本结合运动线索的特征学习方法是其核心优势。

<details>
  <summary>Details</summary>

**Motivation:** 从电影MRI序列中准确、无造影剂地预测主要不良心脏事件（MACE）仍然是一个关键挑战。现有方法通常需要基于心室心肌中人工精炼掩膜的监督学习，这在没有造影剂的情况下变得不切实际。

**Method:** 本研究引入了一种名为CTSL（基于码本的时空学习）的自监督框架，该框架无需分割掩膜即可从原始电影数据中学习动态、时空表示。CTSL通过多视图蒸馏策略解耦时间和空间特征，其中教师模型处理多个电影视图，学生模型从降维的电影-SA序列中学习。通过利用基于码本的特征表示和通过运动线索进行的动态病变自检测，CTSL捕获复杂的时态依赖性和运动模式。

**Result:** 通过CTSL模型实现了高置信度的MACE风险预测，提供了一种快速、无创的心脏风险评估解决方案，其性能优于传统的依赖造影剂的方法。

**Conclusion:** CTSL为心脏风险评估提供了一种快速、无创的解决方案，能够实现及时和可及的心脏病诊断，解决了在没有造影剂的情况下进行心脏事件预测的挑战。

> **ai_Abstract:** 本论文提出了一种名为CTSL的自监督框架，用于无需造影剂地从电影MRI数据中准确预测主要不良心脏事件（MACE）。CTSL通过多视图蒸馏策略解耦时空特征，并利用码本特征表示和动态病变自检测来捕获复杂的时态依赖性。该方法无需人工分割掩膜，并被证明在心脏风险评估方面优于传统的依赖造影剂的方法，提供了一种快速、无创的临床诊断方案。

> **摘要翻译:** 从电影MRI序列中准确、无造影剂地预测主要不良心脏事件（MACE）仍然是一个关键挑战。现有方法通常需要基于心室心肌中人工精炼掩膜的监督学习，这在没有造影剂的情况下变得不切实际。我们引入了一种自监督框架，即基于码本的时空学习（CTSL），该框架无需分割掩膜即可从原始电影数据中学习动态、时空表示。CTSL通过多视图蒸馏策略解耦时间和空间特征，其中教师模型处理多个电影视图，学生模型从降维的电影-SA序列中学习。通过利用基于码本的特征表示和通过运动线索进行的动态病变自检测，CTSL捕获复杂的时态依赖性和运动模式。通过我们的模型实现了高置信度的MACE风险预测，提供了一种快速、无创的心脏风险评估解决方案，其性能优于传统的依赖造影剂的方法，从而在临床环境中实现及时和可及的心脏病诊断。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [20] [Online Episodic Memory Visual Query Localization with Egocentric Streaming Object Memory](https://arxiv.org/abs/2411.16934)
> *基于自我中心流式对象记忆的在线情景记忆视觉查询定位*

*Zaira Manigrasso, Matteo Dunnhofer, Antonino Furnari, Moritz Nottebaum, Antonio Finocchiaro, Davide Marana, Rosario Forte, Giovanni Maria Farinella, Christian Micheloni* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 在线情景记忆, 视觉查询定位, 自我中心视觉, 对象跟踪, 对象发现

**Comment:** 

> **TL;DR:** 现有可穿戴相机的情景记忆系统是离线的。本文提出了OVQ2D任务和ESOM框架，用于在线视频流处理和高效的对象定位，利用紧凑内存。ESOM表现优于其他在线方法，但任务仍具挑战性，且强调了改进对象跟踪和发现的重要性。

**AI_Comments:** 本文通过将情景记忆检索范式从离线转向在线，为可穿戴设备在现实世界中的应用做出了重要贡献。OVQ2D任务和ESOM框架的提出具有创新性。对完美对象跟踪和发现影响的明确分析为未来的研究指明了方向，突显了在线设置中实现高性能的当前瓶颈。尽管ESOM优于现有在线方法，但其整体成功率（约4%）较低，表明该领域仍存在重大挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有情景记忆检索系统假设“离线”设置，即查询时可完全访问视频，这限制了它们在受电源和存储限制的可穿戴设备等真实场景中的应用。本文旨在开发更适用于实际应用的在线情景记忆系统。

**Method:** 本文引入了在线视觉查询2D (OVQ2D) 任务，其中模型在线处理视频流，每帧仅观察一次，并使用紧凑内存而非完整视频历史来检索对象定位。为解决OVQ2D，提出了ESOM（自我中心流式对象记忆）框架，该框架集成了对象发现模块、对象跟踪模块和记忆模块，用于查找、跟踪和存储时空对象信息以进行高效查询。

**Result:** 在Ego4D上的实验表明，ESOM优于其他在线方法。然而，OVQ2D任务仍然具有挑战性，最高成功率仅为约4%。ESOM的准确性在完美对象跟踪（31.91%）、完美对象发现（40.55%）或两者兼有（81.92%）的情况下显著提高。

**Conclusion:** 尽管ESOM提高了在线情景记忆检索的性能，但OVQ2D任务仍具挑战性。实验结果表明，完美的对象跟踪和发现可以显著提升性能，这强调了对这些关键组件进行进一步应用研究的必要性。

> **ai_Abstract:** 本文针对可穿戴相机离线情景记忆检索的局限性，提出了在线视觉查询2D (OVQ2D) 任务，以实现使用紧凑内存的在线视频流处理。为此，作者提出了ESOM（自我中心流式对象记忆）框架，该框架包含对象发现、跟踪和记忆模块。在Ego4D上的实验显示ESOM优于其他在线方法，但OVQ2D仍面临挑战。研究结果强调，完美的对象跟踪和发现能显著提升准确性，凸显了在这些领域进行深入研究的必要性。

> **摘要翻译:** 情景记忆检索使可穿戴相机能够回忆起视频中先前观察到的物体或事件。然而，现有公式假设在查询时可完全访问视频的“离线”设置，这限制了它们在具有电源和存储限制的可穿戴设备等真实场景中的适用性。为了实现更具应用前景的情景记忆系统，我们引入了在线视觉查询2D（OVQ2D）任务，其中模型在线处理视频流，每帧只观察一次，并使用紧凑的内存而不是完整的视频历史来检索对象定位。我们通过ESOM（自我中心流式对象记忆）来解决OVQ2D，这是一个新颖的框架，集成了对象发现模块、对象跟踪模块和记忆模块，用于查找、跟踪和存储时空对象信息以进行高效查询。在Ego4D上的实验表明，ESOM优于其他在线方法，尽管OVQ2D仍然具有挑战性，最高性能仅为约4%的成功率。ESOM的准确性在完美对象跟踪（31.91%）、完美对象发现（40.55%）或两者兼有（81.92%）的情况下显著提高，这强调了对这些组件进行应用研究的必要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [23] [Dens3R: A Foundation Model for 3D Geometry Prediction](https://arxiv.org/abs/2507.16290)
> *Dens3R：一个用于3D几何预测的基础模型*

*Xianze Fang, Jingnan Gao, Zhe Wang, Zhuo Chen, Xingyu Ren, Jiangjing Lyu, Qiaomu Ren, Zhonglei Yang, Xiaokang Yang, Yichao Yan, Chengfei Lyu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 3D几何预测, 基础模型, 密集重建, 联合预测, 深度估计

**Comment:** Project Page: https://g-1nonly.github.io/Dens3R/, Code:
  https://github.com/G-1nOnly/Dens3R

> **TL;DR:** Dens3R是一个3D基础模型，通过统一框架和两阶段训练，实现准确且一致的联合几何密集预测，解决了现有方法在预测多种几何量时一致性差的问题。

**AI_Comments:** Dens3R的创新之处在于其提出了一个统一的3D基础模型来解决多几何量预测的一致性问题，而非孤立地处理。其两阶段训练框架和位置插值旋转位置编码是其技术亮点，旨在提高模型的通用性和对高分辨率输入的鲁棒性。作为一个“基础模型”，其潜力在于能够适应多种下游任务，这对于未来的3D视觉研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有密集3D重建方法在预测单一几何量时存在局限性，且深度、表面法线、点图等几何量虽然相关，但孤立估计导致一致性差，限制了准确性和实用性。因此，需要一个统一框架来建模不同几何属性之间的结构耦合，以实现联合回归。

**Method:** 本文提出了Dens3R，一个两阶段训练框架，逐步构建通用且本质不变的点图表示。设计了轻量级共享编码器-解码器骨干网络，并引入位置插值旋转位置编码以增强对高分辨率输入的鲁棒性。通过结合图像对匹配特征和内在不变性建模，实现多几何量（如表面法线和深度）的准确回归。还提出了支持几何一致多视图推理的后处理流程。

**Result:** Dens3R在各种密集3D预测任务中表现出卓越性能，并能准确回归多个几何量，实现从单视图到多视图输入的一致几何感知。

**Conclusion:** Dens3R在密集3D预测任务中表现优异，并具有更广泛应用的潜力。

> **ai_Abstract:** 本文提出了Dens3R，一个创新的3D基础模型，旨在解决现有3D几何预测方法在处理多个相关几何量时缺乏一致性的问题。Dens3R采用两阶段训练框架，结合轻量级编码器-解码器骨干和位置插值旋转位置编码，通过建模几何属性间的结构耦合，实现深度、表面法线等多种几何量的联合且一致的密集预测。该模型在单视图和多视图输入下均表现出卓越性能，并通过后处理流程支持多视图推理，展现了其在广泛3D预测任务中的强大潜力。

> **摘要翻译:** 密集3D重建的最新进展取得了显著成就，但实现准确统一的几何预测仍然是一个重大挑战。大多数现有方法仅限于从输入图像中预测单一几何量。然而，深度、表面法线和点图等几何量本质上是相互关联的，孤立地估计它们往往无法确保一致性，从而限制了准确性和实际适用性。这促使我们探索一个统一的框架，明确地建模不同几何属性之间的结构耦合，以实现联合回归。在本文中，我们提出了Dens3R，一个为联合几何密集预测而设计的3D基础模型，并适用于广泛的下游任务。Dens3R采用两阶段训练框架，逐步构建一个通用且本质不变的点图表示。具体来说，我们设计了一个轻量级共享编码器-解码器骨干网络，并引入了位置插值旋转位置编码，以在保持表达能力的同时增强对高分辨率输入的鲁棒性。通过将图像对匹配特征与内在不变性建模相结合，Dens3R准确地回归了表面法线和深度等多个几何量，实现了从单视图到多视图输入的一致几何感知。此外，我们提出了一种支持几何一致多视图推理的后处理流程。广泛的实验证明了Dens3R在各种密集3D预测任务中的卓越性能，并突出了其更广泛应用的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [31] [LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation](https://arxiv.org/abs/2507.16154)
> *LSSGen：在流和扩散模型中利用潜在空间缩放实现高效文本到图像生成*

*Jyun-Ze Tang, Chih-Fan Hsu, Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 文本到图像生成, 潜在空间缩放, 流匹配, 扩散模型, 效率提升

**Comment:** ICCV AIGENS 2025

> **TL;DR:** LSSGen通过在潜在空间直接进行分辨率缩放，显著提升了流和扩散模型在文本到图像生成中的效率和图像质量。

**AI_Comments:** 这篇论文的创新点在于提出了在潜在空间直接进行分辨率缩放的策略，有效避免了传统像素空间缩放导致的伪影和质量损失。其重要性体现在它在不修改现有复杂模型架构的前提下，显著提升了文本到图像生成模型的效率和图像质量，尤其对于高分辨率图像生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像生成模型在加速合成时，通常在像素空间进行降采样和升采样，这会导致伪影、失真和最终图像质量下降。

**Method:** 提出LSSGen框架，利用轻量级潜在上采样器直接在潜在空间进行分辨率缩放，无需改变Transformer或U-Net架构。

**Result:** LSSGen在效率和视觉质量上都有提升，支持灵活的多分辨率生成。在生成1024x1024图像时，速度相似的情况下，TOPIQ分数提升高达246%，显著优于传统缩放方法。

**Conclusion:** LSSGen通过在潜在空间进行分辨率缩放，有效解决了传统像素空间缩放带来的问题，显著提高了文本到图像生成的效率和质量。

> **ai_Abstract:** LSSGen是一个针对文本到图像生成中流匹配和扩散模型的框架，通过在潜在空间直接进行分辨率缩放来解决传统像素空间缩放引入的伪影和质量下降问题。它利用轻量级潜在上采样器，无需修改现有模型架构，即可显著提升生成效率和图像质量，并在综合评估中表现出优异性能，尤其在生成高分辨率图像时能大幅提高TOPIQ分数。

> **摘要翻译:** 流匹配和扩散模型在文本到图像生成方面取得了令人印象深刻的成果，通过迭代去噪过程生成逼真的图像。加速合成的常用策略是在较低分辨率下进行早期去噪。然而，传统的在像素空间进行降采样和升采样的方法常常引入伪影和失真。这些问题发生在升采样的图像被重新编码到潜在空间时，导致最终图像质量下降。为了解决这个问题，我们提出了**潜在空间缩放生成（LSSGen）**，一个利用轻量级潜在上采样器直接在潜在空间执行分辨率缩放的框架。在不改变Transformer或U-Net架构的情况下，LSSGen提高了效率和视觉质量，同时支持灵活的多分辨率生成。我们涵盖文本-图像对齐和感知质量的综合评估表明，LSSGen显著优于传统的缩放方法。在以相似速度生成1024x1024图像时，它实现了高达246%的TOPIQ分数提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [34] [Conformal Predictions for Human Action Recognition with Vision-Language Models](https://arxiv.org/abs/2502.06631)
> *基于视觉-语言模型的人类行为识别中的保形预测*

*Bary Tim, Fuchs Clément, Macq Benoît* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 保形预测, 人类行为识别, 视觉-语言模型, 人机协作, 可靠性

**Comment:** 6 pages, 7 figures, Accepted to ICIP 2025 Workshops

> **TL;DR:** 本文探讨了如何使用保形预测技术增强基于视觉-语言模型的人类行为识别系统的可靠性，并通过调整softmax预测温度来解决长尾分布问题。

**AI_Comments:** 本文的创新点在于将保形预测应用于视觉-语言模型的人类行为识别中，并提出了一种无需额外校准数据即可缓解长尾分布问题的方法，这对于提高高风险应用中人机协作系统的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在AI必须与人类决策者协作的高风险现实应用中，人机协作系统至关重要。本文旨在通过保形预测技术提高基于视觉-语言模型的人类行为识别系统的可靠性，并解决其在实际应用中遇到的长尾分布问题。

**Method:** 本研究利用保形预测（CP）技术来增强基于视觉-语言模型（VLMs）的人类行为识别（HAR）系统。为缓解候选类别数量减少导致的预测分布长尾问题，提出在不使用额外校准数据的情况下，调整softmax预测的温度。

**Result:** 研究表明，保形预测能显著减少平均候选类别数量，且无需修改底层视觉-语言模型。但这种减少常导致长尾分布。通过调整softmax预测温度，可以缓解这一问题。

**Conclusion:** 保形预测能有效提升基于视觉-语言模型的人类行为识别系统的可靠性，并通过简单的温度调整解决实际应用中的长尾分布挑战，为多模态人机交互贡献力量。

> **ai_Abstract:** 本文研究了保形预测（CP）技术如何提升基于视觉-语言模型（VLMs）的人类行为识别（HAR）系统的可靠性。研究表明，CP能有效减少候选类别，且无需改动VLM，但可能导致预测分布出现长尾。为解决此问题，作者提出通过调整softmax预测温度来优化，而无需额外校准数据。该工作旨在促进动态现实世界环境中的多模态人机交互。

> **摘要翻译:** 人机协作（HITL）系统在高风险、现实世界的应用中至关重要，在这些应用中，人工智能必须与人类决策者协作。这项工作研究了保形预测（CP）技术（其提供严格的覆盖保证）如何增强基于视觉-语言模型（VLMs）的最新人类行为识别（HAR）系统的可靠性。我们证明了保形预测可以在不修改底层VLM的情况下显著减少候选类别的平均数量。然而，这些减少通常会导致长尾分布，这会阻碍其实用性。为了缓解这种情况，我们提出在不使用额外校准数据的情况下调整softmax预测的温度。这项工作有助于在动态现实世界环境中进行多模态人机交互的持续努力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [37] [MotionShot: Adaptive Motion Transfer across Arbitrary Objects for Text-to-Video Generation](https://arxiv.org/abs/2507.16310)
> *MotionShot：任意对象自适应运动迁移用于文本到视频生成*

*Yanchen Liu, Yanan Sun, Zhening Xing, Junyao Gao, Kai Chen, Wenjie Pei* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 运动迁移, 文本到视频生成, 无需训练框架, 对象对齐, 时间注意力

**Comment:** 

> **TL;DR:** MotionShot是一个无需训练的框架，通过细粒度对应和时间注意力，实现不同外观或结构对象间的高保真运动迁移，解决了现有文本到视频方法中的运动迁移难题。

**AI_Comments:** MotionShot的创新之处在于其无需训练的框架和对细粒度对应关系的解析，这使得它能够有效解决跨差异对象运动迁移的难题。通过结合高层语义对齐和低层形态对齐，并利用时间注意力，该方法在保持外观连贯性的同时实现了高保真运动转移，这对于文本到视频生成领域是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到视频生成方法难以在外观或结构差异显著的参考对象和目标对象之间平滑地迁移运动。

**Method:** MotionShot是一个无需训练的框架，它首先进行语义特征匹配以确保高层对齐，然后通过参考到目标的形状重定向建立低层形态对齐，并利用时间注意力编码运动。

**Result:** MotionShot能够连贯地在不同对象之间迁移运动，即使存在显著的外观和结构差异，并通过大量实验得到验证。

**Conclusion:** MotionShot通过其独特的细粒度对应解析、语义特征匹配、形状重定向和时间注意力编码，有效解决了文本到视频生成中跨差异对象运动迁移的挑战，实现了高保真且连贯的运动转移。

> **ai_Abstract:** MotionShot是一个创新的无需训练框架，旨在解决现有文本到视频生成方法在不同外观或结构对象间运动迁移的难题。它通过结合细粒度对应解析、语义特征匹配、形状重定向和时间注意力编码，实现了高保真且外观连贯的运动转移。该方法能够有效处理显著的外观和结构差异，并通过实验验证了其在跨对象运动迁移方面的有效性。

> **摘要翻译:** 现有文本到视频的方法难以将运动从参考对象平滑地迁移到与参考对象外观或结构差异显著的目标对象。为了解决这一挑战，我们引入了MotionShot，一个无需训练的框架，能够以细粒度方式解析参考-目标对应关系，从而实现高保真运动迁移，同时保持外观的一致性。具体来说，MotionShot首先执行语义特征匹配以确保参考对象和目标对象之间的高层对齐。然后，它通过参考到目标的形状重定向进一步建立低层形态对齐。通过使用时间注意力编码运动，我们的MotionShot可以连贯地在对象之间迁移运动，即使存在显著的外观和结构差异，这已通过大量实验得到证明。项目页面可在：https://motionshot.github.io/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [40] [Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox](https://arxiv.org/abs/2507.16413)
> *面向铁路领域LiDAR三维检测的域适应：通过SynDRA-BBox实现从公路到铁路及从仿真到真实*

*Xavier Diaz, Gianluca D'Amico, Raul Dominguez-Sanchez, Federico Nesti, Max Ronecker, Giorgio Buttazzo* | **Category: cs.CV, cs.ET** | **Updated: 2025-07-22**

**Keywords:** 铁路, 域适应, 3D检测, 合成数据集, SynDRA-BBox

**Comment:** IEEE International Conference on Intelligent Rail Transportation
  (ICIRT) 2025

> **TL;DR:** 本文介绍了SynDRA-BBox，一个用于铁路领域2D/3D目标检测的合成数据集，并展示了通过域适应方法将合成数据应用于铁路环境3D目标检测的有效性。

**AI_Comments:** 本文的创新点在于构建了首个专门针对铁路领域2D/3D目标检测的合成数据集SynDRA-BBox，并验证了通过域适应方法将合成数据应用于铁路环境的可行性。这对于解决铁路行业数据稀缺的挑战具有重要意义，为未来的自动列车感知系统提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 铁路行业缺乏公开可用的真实世界标注数据集，这使得在该领域测试和验证新的感知解决方案变得困难。

**Method:** 引入了SynDRA-BBox，一个专门为铁路领域2D和3D目标检测设计的合成数据集。将一种最先进的半监督域适应方法（最初用于汽车感知）应用于铁路环境，以实现合成数据到3D目标检测的可迁移性。

**Result:** 实验结果显示出有前景的性能，突出了合成数据集和域适应技术在提升铁路环境感知能力方面的有效性。

**Conclusion:** 合成数据集和域适应技术能够有效提升铁路环境的感知能力，解决了真实世界标注数据缺乏的问题。

> **ai_Abstract:** 本文针对铁路领域缺乏标注数据集的问题，提出了SynDRA-BBox，一个用于铁路场景2D和3D目标检测的合成数据集。研究将一种用于汽车感知的半监督域适应方法应用于铁路环境，以促进合成数据在3D目标检测中的应用。实验结果验证了合成数据集和域适应技术在提升铁路感知能力方面的有效性。

> **摘要翻译:** 近年来，自动列车操作的兴趣显著增加。为了实现高级功能，强大的基于视觉的算法对于感知和理解周围环境至关重要。然而，铁路部门缺乏公开可用的真实世界标注数据集，这使得在该领域测试和验证新的感知解决方案变得具有挑战性。为了解决这一空白，我们引入了SynDRA-BBox，一个旨在支持铁路场景中目标检测和其他基于视觉任务的合成数据集。据我们所知，这是第一个专门为铁路领域2D和3D目标检测量身定制的合成数据集，该数据集可在https://syndra.retis.santannapisa.it公开获取。在所呈现的评估中，一种最先进的半监督域适应方法（最初用于汽车感知）被应用于铁路环境，从而实现了合成数据到3D目标检测的可迁移性。实验结果显示出有前景的性能，突出了合成数据集和域适应技术在提升铁路环境感知能力方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [44] [Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation](https://arxiv.org/abs/2411.19951)
> *Sparrow：利用文本到图像增强实现数据高效的视频大语言模型*

*Shukang Yin, Chaoyou Fu, Sirui Zhao, Chunjiang Ge, Yan Yang, Yuhan Dai, Yongdong Luo, Tong Xu, Caifeng Shan, Enhong Chen* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 视频大语言模型, 数据增强, 文本到图像, 数据效率, Sparrow

**Comment:** Project page: https://github.com/VITA-MLLM/Sparrow

> **TL;DR:** Sparrow提出一种数据增强方法，通过合成文本到图像的视频样本来提高视频大语言模型的训练效率和性能，解决了单纯扩大视频数据量导致的学习效率低下问题。

**AI_Comments:** Sparrow的创新之处在于其通过文本到图像合成来创建多样化的视频类样本，有效解决了视频LLM训练中指令多样性不足和数据效率低下的挑战。这种数据增强策略不仅减少了对大量真实视频数据的依赖，还在提升模型性能，尤其是在长视频理解方面显示出巨大潜力。该方法为未来开发更高效、更通用的多模态大模型提供了宝贵的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLMs）在视觉理解领域取得了成功，主要归因于参数规模和数据量的扩大。然而，自动数据管道驱动的数据扩增（特别是自指令）的有效性研究被长期忽视。研究发现，简单地增加视频数据样本会导致学习效率低下，这归因于指令多样性的缺乏。

**Method:** 本文提出了一种名为Sparrow的数据增强方法。该方法从纯文本指令数据中合成类视频样本，并将其与现有视频数据混合，以实现更高效的训练方案。研究通过对预训练图像大语言模型进行视频数据微调，并考察数据扩展的学习效率来验证其方法。

**Result:** Sparrow方法在训练样本量显著少的情况下，实现了与基线模型相当甚至更优的性能。同时，研究发现，引入这些合成样本可以在不依赖长视频数据训练的情况下，增强模型对长视频的理解能力。

**Conclusion:** Sparrow通过引入文本到图像合成的视频样本进行数据增强，有效解决了视频大语言模型训练中数据效率低下的问题，显著提高了模型性能，尤其是在长视频理解方面。

> **ai_Abstract:** 本文提出了一种名为Sparrow的数据增强方法，旨在解决视频大语言模型在数据扩展过程中存在的学习效率低下问题。通过从纯文本指令数据合成类视频样本并与真实视频数据混合，Sparrow显著提升了训练效率，使得模型在更少数据量下达到甚至超越基线模型的性能。此外，该方法还能在不额外训练长视频数据的情况下，增强模型对长视频的理解能力，为数据高效的视频大语言模型训练提供了新范式。

> **摘要翻译:** 近年来，多模态大语言模型（MLLMs）在视觉理解领域取得了成功。这些模型的成功很大程度上归因于主导的尺度定律，即更大的参数规模和数据量有助于更好的性能。值得注意的是，数据扩展主要是由自动数据管道驱动的，这些管道专注于大语言模型的自指令。这种范式已经被默认为理所当然相当长一段时间，但对这些数据扩展的有效性研究却长期被忽视。在此背景下，这项工作重新审视了合成数据的扩展，并着重从数据中心视角开发视频大语言模型。我们的主要研究方法涉及使用视频数据微调预训练的图像大语言模型，并通过数据扩展来检查学习效率。我们初步实验的结果揭示了简单地增加视频数据样本时存在低学习效率现象，通过我们的探究，这可以归因于指令多样性的缺乏。针对这个问题，我们提出了一种名为Sparrow的数据增强方法，该方法从纯文本指令数据中合成类视频样本。将这些合成样本与视频数据混合可以实现更高效的训练方案。通过全面的实验，我们证明了我们提出的方法达到了与使用显著更多样本训练的基线模型相当甚至更优的性能。同时，我们发现结合这些合成样本可以在不需要长视频数据训练的情况下增强对长视频的理解能力。代码和数据示例可在https://github.com/VITA-MLLM/Sparrow获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [45] [Salience Adjustment for Context-Based Emotion Recognition](https://arxiv.org/abs/2507.15878)
> *基于上下文情绪识别的显著性调整*

*Bin Han, Jonathan Gratch* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 情绪识别, 上下文感知, 显著性调整, 贝叶斯线索整合, 视觉-语言模型

**Comment:** 

> **TL;DR:** 提出了一种显著性调整框架，利用BCI和VLM动态加权面部和上下文信息，以提高动态社会情境下的情绪识别性能。

**AI_Comments:** 该论文的创新之处在于其提出的显著性调整框架，该框架能够动态地权衡面部和上下文信息，从而更有效地解决动态社会情境下的情绪识别挑战。结合BCI和VLM是其方法上的亮点。其在囚徒困境场景下的评估也具有一定的现实意义。该工作为提升复杂情境下的情绪识别性能提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在动态社会情境中，情绪识别需要理解面部表情和情境线索之间的复杂互动，现有方法可能未能充分动态地整合这些信息。

**Method:** 本文提出了一种显著性调整框架，用于上下文感知情绪识别。该框架结合了贝叶斯线索整合（BCI）和视觉-语言模型（VLMs），根据面部线索的表达性动态地权衡面部和上下文信息。

**Result:** 研究结果表明，引入显著性调整能够增强情绪识别性能。

**Conclusion:** 显著性调整框架为未来的研究提供了有前景的方向，可将其扩展到更广泛的社会情境和多模态应用中。

> **ai_Abstract:** 本论文提出了一种新的显著性调整框架，用于在动态社会情境中进行上下文感知的情绪识别。该框架利用贝叶斯线索整合（BCI）和视觉-语言模型（VLMs），根据面部线索的表达性动态调整面部和上下文信息的权重。通过在囚徒困境场景中的评估，研究证明了显著性调整能有效提升情绪识别的准确性，并为未来研究指明了方向。

> **摘要翻译:** 在动态社会情境中进行情绪识别需要理解面部表情和情境线索之间复杂的互动。本文提出了一种显著性调整框架，用于上下文感知情绪识别，该框架结合了贝叶斯线索整合（BCI）和视觉-语言模型（VLMs），根据面部线索的表达性动态地权衡面部和上下文信息。我们使用人类标注和自动情绪识别系统在囚徒困境场景中评估了这种方法，这些场景旨在引发情绪反应。我们的研究结果表明，引入显著性调整能够增强情绪识别性能，为未来将此框架扩展到更广泛的社会情境和多模态应用提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [52] [M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision](https://arxiv.org/abs/2507.16318)
> *M-SpecGene：RGBT多光谱视觉的通用基础模型*

*Kailai Zhou, Fuqiang Yang, Shixian Wang, Bihan Wen, Chongde Zi, Linsen Chen, Qiu Shen, Xun Cao* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** RGBT多光谱视觉, 基础模型, 自监督学习, 模态不变表示, 信息不平衡

**Comment:** accepted by ICCV2025

> **TL;DR:** M-SpecGene是一个新的通用自监督基础模型，用于RGBT多光谱视觉，通过学习模态不变表示来克服逐案方法的局限性，并展现出强大的泛化能力。

**AI_Comments:** 这篇论文的创新点在于首次尝试构建RGBT多光谱视觉的通用基础模型，摆脱了传统逐案研究的限制。其提出的CMSS度量和GMM-CMSS预训练策略针对RGBT数据特性进行了优化，提高了模型学习效率和泛化能力。该工作为多光谱融合领域提供了一个统一且高效的新范式，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RGBT多光谱视觉任务研究范式是逐案定制模型，受限于人工归纳偏差、模态偏差和数据瓶颈。

**Method:** 提出了M-SpecGene，一个通用的RGBT多光谱基础模型，旨在以自监督方式从大规模数据中学习模态不变表示。为了解决RGBT数据中信息不平衡的独特特征，引入了跨模态结构稀疏度（CMSS）度量，并开发了GMM-CMSS渐进式掩蔽策略，用于灵活、由易到难、以对象为中心的预训练过程。

**Result:** 综合实验验证了M-SpecGene在四个RGBT下游任务的十一个数据集上的泛化能力。

**Conclusion:** M-SpecGene成功构建了一个通用的RGBT多光谱基础模型，通过学习模态不变表示和引入创新的预训练策略，有效解决了现有方法的局限性，并展现出强大的泛化能力，为RGBT多光谱视觉提供了一个统一的范式。

> **ai_Abstract:** 本文提出了M-SpecGene，这是一个通用的RGBT多光谱基础模型，旨在解决现有RGBT任务中逐案定制模型所面临的人工归纳偏差、模态偏差和数据瓶颈问题。M-SpecGene通过自监督学习从大规模数据中获取模态不变表示，并引入了CMSS度量和GMM-CMSS渐进式掩蔽策略来应对RGBT数据的信息不平衡。实验证明M-SpecGene在多个数据集和下游任务上具有良好的泛化能力，为RGBT多光谱视觉提供了一个统一的解决方案。

> **摘要翻译:** RGB-热（RGBT）多光谱视觉对于复杂环境中的鲁棒感知至关重要。大多数RGBT任务遵循逐案研究范式，依赖手动定制的模型来学习面向任务的表示。然而，这种范式固有地受限于人工归纳偏差、模态偏差和数据瓶颈。为了解决这些局限性，我们首次尝试构建一个通用的RGBT多光谱基础模型（M-SpecGene），旨在以自监督方式从大规模广泛数据中学习模态不变表示。M-SpecGene为多光谱融合提供了新的见解，并将先前的逐案研究整合到一个统一的范式中。考虑到RGBT数据中信息不平衡的独特特征，我们引入了跨模态结构稀疏度（CMSS）度量来量化两种模态之间的信息密度。然后我们开发了GMM-CMSS渐进式掩蔽策略，以促进灵活、由易到难、以对象为中心的预训练过程。综合实验验证了M-SpecGene在四个RGBT下游任务的十一个数据集上的泛化能力。代码将在https://github.com/CalayZhou/M-SpecGene提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [59] [Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling](https://arxiv.org/abs/2502.11809)
> *通过人类视觉解耦的几何机制揭示深度神经网络中的偏见形成*

*Yanbiao Ma, Bowei Liu, Boyuan Gao, Wei Dai, Jiayi Chen, Shuo Li, Andi Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 深度神经网络偏见, 几何机制, 感知流形, 人类视觉解耦, 模型解释性

**Comment:** 

> **TL;DR:** 深度神经网络（DNNs）在目标识别中即使数据平衡也存在偏见。本文受人类视觉启发，提出几何分析框架，将DNN中感知流形的几何复杂性与模型偏见关联，发现几何复杂性差异导致识别能力差异，从而产生偏见。并提供一个计算感知流形几何属性的库。

**AI_Comments:** 这项研究通过引入几何分析框架，为理解深度神经网络中的偏见形成提供了一个新颖的视角，特别是将偏见与感知流形的几何复杂性联系起来，具有创新性。提出的Perceptual-Manifold-Geometry库也为后续研究提供了实用工具。它强调了模型内在机制而非简单的数据不平衡是偏见来源，对可解释AI领域有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）在目标识别中即使在训练数据平衡的情况下也常表现出对某些类别的偏见，但这些偏见背后的内在机制尚不清楚。

**Method:** 受人类视觉系统通过分层处理解耦对象流形以实现目标识别的启发，本文提出了一个几何分析框架，将DNN中特定类别感知流形的几何复杂性与模型偏见联系起来。为支持此分析，还提出了Perceptual-Manifold-Geometry库，用于计算感知流形的几何属性。

**Result:** 研究结果表明，几何复杂性的差异可以导致跨类别识别能力的不同，从而引入偏见。

**Conclusion:** 深度神经网络中的偏见形成与感知流形的几何复杂性差异有关，这种差异导致了不同类别的识别能力不均。

> **ai_Abstract:** 本文探讨了深度神经网络（DNNs）在目标识别中即使在平衡训练数据下仍存在的偏见问题。受人类视觉系统解耦机制启发，作者提出了一个几何分析框架，将DNN中特定类别感知流形的几何复杂性与模型偏见关联起来。研究发现，几何复杂性的差异是导致不同类别识别能力不均和偏见产生的原因。为支持此分析，论文还推出了Perceptual-Manifold-Geometry库。

> **摘要翻译:** 深度神经网络（DNNs）在目标识别中经常表现出对某些类别的偏见，即使在训练数据平衡的条件下也是如此。这些偏见背后的内在机制仍不清楚。受人类视觉系统通过分层处理解耦对象流形以实现目标识别的启发，我们提出了一个几何分析框架，将DNNs中特定类别感知流形的几何复杂性与模型偏见联系起来。我们的研究结果表明，几何复杂性的差异可能导致跨类别识别能力的不同，从而引入偏见。为了支持这项分析，我们提出了Perceptual-Manifold-Geometry库，该库旨在计算感知流形的几何属性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [63] [Automatic Fine-grained Segmentation-assisted Report Generation](https://arxiv.org/abs/2507.16623)
> *自动细粒度分割辅助报告生成*

*Frederic Jonske, Constantin Seibold, Osman Alperen Koras, Fin Bahnsen, Marie Bauer, Amin Dada, Hamza Kalisch, Anton Schily, Jens Kleesiek* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 医学报告生成, 细粒度分割, LLaVA, 特征融合, 接地能力

**Comment:** 

> **TL;DR:** ASaRG是一种基于LLaVA的医学报告生成模型，通过融合中间特征和细粒度分割图，显著提高了性能并增强了报告的可验证性。

**AI_Comments:** ASaRG的创新点在于将细粒度分割信息与大型多模态模型（LLaVA）相结合，以提高医学报告生成的准确性和可解释性。其通过简单的特征融合实现了显著的性能提升，并解决了报告生成中“接地”的关键问题，增强了生成内容的可信度。此外，该方法与现有架构的兼容性也为其未来的扩展和应用提供了广阔空间。

<details>
  <summary>Details</summary>

**Motivation:** 可靠的端到端临床报告生成一直是医学机器学习研究的长期目标，旨在减轻放射科医生的工作量并为临床医生或患者提供第二意见。因此，报告生成模型需要强大的通用性能和固有的接地能力，以确保生成报告的真实性。

**Method:** 本文提出了ASaRG（自动分割辅助报告生成），它是流行LLaVA架构的扩展。ASaRG通过简单的拼接，将专科放射学模型创建的中间特征和细粒度分割图融合到LLaVA的多模态投影层中。

**Result:** 与仅使用中间特征的LLaVA基线相比，ASaRG在CE F1分数上实现了+0.89%的性能提升（p=0.012）；当结合中间特征和细粒度分割图时，性能提升达到+2.77%（p<0.001）。与另外两种使用分割的报告生成方法COMG和ORID相比，F1分数分别提高了6.98%和6.28%。此外，任意数量的分割作为输入的一部分，可以追溯报告元素到相应的分割图，并验证评估的接地性。

**Conclusion:** ASaRG通过融合中间特征和细粒度分割图，显著提升了医学报告生成的性能和可靠性。它与LLaVA架构的其他改进不冲突，具有与其他领域进展结合的潜力，并且能够通过分割图验证报告内容的接地性。

> **ai_Abstract:** 本文提出了一种名为ASaRG的自动细粒度分割辅助报告生成模型，它是对LLaVA架构的扩展。该模型通过将放射学模型的中间特征和细粒度分割图融合到LLaVA的多模态投影层中，旨在提高医学报告生成的性能和可靠性。实验结果表明，ASaRG在CE F1分数上相比LLaVA基线有显著提升，并且优于其他利用分割的报告生成方法。此外，ASaRG能够通过分割图验证报告内容的接地性，且具有与其他先进方法结合的潜力。

> **摘要翻译:** 可靠的端到端临床报告生成一直是医学机器学习研究的长期目标。这一过程的最终目标是减轻放射科医生的工作量，并为临床医生或患者提供第二意见。因此，报告生成模型的一个必要前提是强大的通用性能和某种内在的接地能力，以使临床医生或患者相信生成报告的真实性。在本文中，我们提出了ASaRG（自动分割辅助报告生成），它是流行LLaVA架构的扩展，旨在解决这两个问题。ASaRG建议通过简单的拼接，将专科放射学模型创建的中间特征和细粒度分割图融合到LLaVA的多模态投影层中。通过少量增加的参数，我们的方法在使用仅中间特征时，与LLaVA基线相比，在CE F1分数上实现了+0.89%的性能提升（p=0.012），而在添加中间特征和细粒度分割图的组合时，性能提升达到+2.77%（p<0.001）。与COMG和ORID这两种利用分割的其他报告生成方法相比，F1分数分别提高了6.98%和6.28%。ASaRG与LLaVA架构的其他改变并非互斥，这可能使得我们的方法能够与该领域的其他进展相结合。最后，使用任意数量的分割作为输入的一部分，明确地允许将报告元素追溯到相应的分割图，并验证评估的接地性。我们的代码将在稍后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [66] [AMMNet: An Asymmetric Multi-Modal Network for Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.16158)
> *AMMNet：一种用于遥感语义分割的非对称多模态网络*

*Hui Ye, Haodong Chen, Zeke Zexi Hu, Xiaoming Chen, Yuk Ying Chung* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 遥感语义分割, 多模态网络, 非对称架构, RGB-DSM融合, 计算效率

**Comment:** 

> **TL;DR:** AMMNet提出了一种非对称多模态网络，通过非对称双编码器、非对称先验融合器和分布对齐模块，有效解决了遥感语义分割中RGB和DSM数据融合的计算复杂性和模态错位问题，实现了SOTA性能。

**AI_Comments:** AMMNet的创新性在于其非对称架构设计，它根据不同模态（RGB和DSM）的特性分配计算资源，有效解决了传统多模态融合中常见的冗余和模态错位问题。这种设计理念对于提升遥感图像处理的效率和精度具有重要意义，尤其是在资源受限或需要高效率的应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 遥感语义分割中RGB图像和数字表面模型（DSM）等多模态数据融合面临两大主要限制：由于架构冗余导致的计算复杂度增加，以及模态错位导致的分割性能下降。这些问题损害了语义分割的效率和鲁棒性，尤其是在复杂的城市环境中。

**Method:** 提出了一种新颖的非对称多模态网络（AMMNet），包含三个专门针对RGB-DSM输入对的设计：1) 非对称双编码器（ADE）模块，根据模态特定特征分配表示能力，为RGB图像使用更深编码器，为DSM使用轻量级编码器以减少架构冗余。2) 非对称先验融合器（APF），将模态感知先验矩阵整合到融合过程中，以生成结构感知的上下文特征，促进模态对齐。3) 分布对齐（DA）模块，通过最小化散度来对齐特征分布，增强跨模态兼容性。

**Result:** 在ISPRS Vaihingen和Potsdam数据集上进行的广泛实验表明，AMMNet在多模态网络中取得了最先进的分割精度，同时降低了计算和内存需求。

**Conclusion:** AMMNet通过其非对称架构和专门设计的模块，成功解决了多模态遥感语义分割中的效率和鲁棒性挑战，实现了卓越的性能。

> **ai_Abstract:** 该论文提出了AMMNet，一个用于遥感语义分割的非对称多模态网络，旨在解决RGB图像和DSM融合中存在的计算复杂性和模态错位问题。AMMNet通过非对称双编码器（ADE）减少冗余，通过非对称先验融合器（APF）实现模态对齐并生成结构感知特征，并通过分布对齐（DA）模块增强跨模态兼容性。实验证明，AMMNet在保持计算效率的同时，在多个数据集上达到了最先进的分割精度。

> **摘要翻译:** 遥感（RS）中的语义分割随着多模态数据的结合取得了显著进展，特别是RGB图像和数字表面模型（DSM）的整合，它们提供了关于地面物体的互补上下文和结构信息。然而，RGB和DSM的整合常面临两大主要限制：由于架构冗余导致的计算复杂度增加，以及模态错位导致的分割性能下降。这些问题损害了语义分割的效率和鲁棒性，尤其是在复杂的城市环境中，精确的多模态整合至关重要。为了克服这些限制，我们提出了非对称多模态网络（AMMNet），这是一种新颖的非对称架构，通过为RGB-DSM输入对量身定制的三种设计，实现了鲁棒且高效的语义分割。为了减少架构冗余，非对称双编码器（ADE）模块根据模态特定特征分配表示能力，为RGB图像采用更深的编码器以捕获丰富的上下文信息，为DSM采用轻量级编码器以提取稀疏结构特征。此外，为了促进模态对齐，非对称先验融合器（APF）将模态感知先验矩阵整合到融合过程中，从而能够生成结构感知的上下文特征。另外，分布对齐（DA）模块通过最小化散度来对齐特征分布，增强跨模态兼容性。在ISPRS Vaihingen和Potsdam数据集上进行的广泛实验表明，AMMNet在多模态网络中取得了最先进的分割精度，同时降低了计算和内存需求。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [Scene Text Detection and Recognition "in light of" Challenging Environmental Conditions using Aria Glasses Egocentric Vision Cameras](https://arxiv.org/abs/2507.16330)
> *使用Aria眼镜以自我为中心的视觉相机在挑战性环境条件下进行场景文本检测与识别*

*Joseph De Mathia, Carlos Francisco Moreno-García* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 场景文本检测与识别, Aria眼镜, 环境条件, 图像超分辨率, 眼动追踪

**Comment:** 15 pages, 8 figures

> **TL;DR:** 本文使用Meta的Aria智能眼镜，研究了光照、距离和分辨率等环境因素对场景文本检测与识别（STDR）算法性能的影响，并提出了图像超分辨率和注视跟踪的优化方法。

**AI_Comments:** 本文的创新点在于利用现实世界的可穿戴设备（Aria智能眼镜）来研究环境因素对STDR性能的影响，并引入了定制数据集。其重要性体现在为未来的用户感知型AR系统和辅助应用提供了基准和优化方向，特别是图像超分辨率和眼动追踪的结合具有实用价值。该研究为在挑战性环境下实现鲁棒的文本识别提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 在可穿戴技术重塑应用的时代，通过以自我为中心的视觉实现场景文本检测与识别（STDR）成为一种直接的选择。本文旨在利用Meta的Project Aria智能眼镜，研究光照、距离和分辨率等环境变量如何影响最先进STDR算法在现实场景中的性能。

**Method:** 研究人员引入了一个在受控条件下捕获的定制新数据集，并评估了两种OCR管道：EAST与CRNN组合，以及EAST与PyTesseract组合。此外，还探讨了集成眼动追踪以通过关注用户注意力区域来优化处理效率的潜力。研究中使用了图像超分辨率作为关键预处理技术。

**Result:** 研究结果表明，分辨率和距离显著影响识别准确性，而光照的作用则不那么可预测。图像超分辨率作为一项关键预处理技术，将字符错误率（CER）从0.65降低到0.48。此外，研究展示了结合眼动追踪来优化处理效率的潜力。

**Conclusion:** 这项工作不仅在现实条件下对STDR性能进行了基准测试，还为自适应、用户感知的增强现实系统奠定了基础。作者的贡献旨在激发未来在鲁棒、上下文敏感的文本识别方面的研究，以应用于资产检查和营养分析等辅助和研究导向型应用。

> **ai_Abstract:** 本研究利用Meta的Project Aria智能眼镜，深入探讨了光照、距离和分辨率等环境因素对场景文本检测与识别（STDR）算法性能的影响。研究人员构建了一个新的数据集，并评估了EAST与CRNN及PyTesseract结合的OCR管道。结果显示分辨率和距离对识别精度影响显著，同时图像超分辨率显著降低了字符错误率。此外，论文还提出了结合眼动追踪以优化处理效率的潜力，为开发适应性强的增强现实系统奠定了基础。

> **摘要翻译:** 在可穿戴技术正在重塑应用的时代，通过以自我为中心的视觉视角，场景文本检测与识别（STDR）成为一个直接的选择。本文利用Meta的Project Aria智能眼镜，研究了光照、距离和分辨率等环境变量如何影响最先进STDR算法在现实场景中的性能。我们引入了一个在受控条件下捕获的新颖定制数据集，并评估了两种OCR管道：EAST与CRNN组合，以及EAST与PyTesseract组合。我们的研究结果显示，分辨率和距离显著影响识别准确性，而光照的作用则不那么可预测。值得注意的是，图像超分辨率成为一项关键的预处理技术，将字符错误率（CER）从0.65降低到0.48。我们进一步展示了集成眼动追踪的潜力，通过关注用户注意力区域来优化处理效率。这项工作不仅在现实条件下对STDR性能进行了基准测试，而且为自适应、用户感知的增强现实系统奠定了基础。我们的贡献旨在激发未来在鲁棒、上下文敏感的文本识别方面的研究，以应用于资产检查和营养分析等辅助和研究导向型应用。代码可在https://github.com/josepDe/Project_Aria_STR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [69] [MCP-MedSAM: A Powerful Lightweight Medical Segment Anything Model Trained with a Single GPU in Just One Day](https://arxiv.org/abs/2412.05888)
> *MCP-MedSAM：一个强大的轻量级医学图像分割一切模型，仅用一天即可在单GPU上训练完成*

*Donghang Lyu, Ruochen Gao, Marius Staring* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 医学图像分割, SAM, 轻量级模型, 模态提示, 数据采样

**Comment:** Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA)

> **TL;DR:** MCP-MedSAM是一个轻量级、高性能的医学图像分割模型，通过引入模态提示和内容提示，解决了SAM在医疗领域部署的挑战，仅需单GPU一天训练即可达到优越性能。

**AI_Comments:** MCP-MedSAM的创新之处在于其对SAM模型在医学领域的轻量化和高效适应。通过引入针对医学图像特性的模态和内容提示，以及有效的数据采样策略，该模型不仅显著降低了训练成本（单GPU一天），还在性能上超越了现有顶级方法，这对于医学图像分割的实际应用和普及具有重要意义。其轻量级特性有望促进AI在资源受限医疗环境中的部署，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 分割一切模型（SAM）在分割任务中表现出巨大潜力，但其庞大的模型尺寸和高GPU要求阻碍了其在医疗领域的可扩展性和发展，因此需要一个更轻量级、高效的模型。

**Method:** 本文提出了MCP-MedSAM模型。该模型引入了两种提示：模态提示（modality prompt）和内容提示（content prompt），通过提示编码器增强分割性能，并在不显著增加训练开销的情况下整合更多相关信息。此外，还采用了一种有效的基于模态的数据采样策略来解决模态之间的数据不平衡问题，确保所有模态的性能更加均衡。

**Result:** 在与大规模挑战数据集上的顶级方法进行比较后，MCP-MedSAM实现了卓越的分割性能，并且仅需单GPU一天训练。

**Conclusion:** MCP-MedSAM成功地提供了一个强大的、轻量级的医学图像分割模型，解决了现有SAM模型在医疗领域部署的限制，并取得了优异的性能，使其更适用于实际医疗应用。

> **ai_Abstract:** 本文提出了MCP-MedSAM，一个轻量级且高性能的医学图像分割模型，旨在解决现有分割一切模型（SAM）在医疗领域部署时面临的模型过大和GPU需求高的问题。MCP-MedSAM通过引入模态提示和内容提示来增强分割精度，并采用基于模态的数据采样策略处理数据不平衡。该模型仅需单GPU一天训练即可在医学图像分割任务上达到优于现有顶级方法的性能，展示了其在实际应用中的巨大潜力。

> **摘要翻译:** 医学图像分割涉及将医学图像划分为有意义的区域，重点在于识别解剖结构和病变。它在医疗保健领域有广泛应用，深度学习方法已使自动化这一过程取得了显著进展。最近，分割一切模型（SAM）的引入，作为第一个用于分割任务的基础模型，促使研究人员将其应用于医疗领域以提高各种任务的性能。然而，SAM庞大的模型尺寸和高GPU要求阻碍了其在医疗领域的可扩展性和发展。在这项工作中，我们提出了MCP-MedSAM，一个强大且轻量级的医学SAM模型，旨在一天内使用单个40GB内存的A100 GPU进行训练，同时提供卓越的分割性能。认识到模态之间显著的内部差异以及边界框内对直接分割目标信息的需要，我们引入了两种提示：模态提示（modality prompt）和内容提示（content prompt）。在通过提示编码器后，它们的嵌入表示可以通过整合更多相关信息进一步提高分割性能，而不会增加显著的训练开销。此外，我们采用了一种有效的基于模态的数据采样策略来解决模态之间的数据不平衡问题，确保所有模态的性能更加均衡。我们的方法使用一个大规模挑战数据集进行训练和评估，与挑战排行榜上的顶级方法相比，MCP-MedSAM实现了卓越的性能，同时仅需单GPU一天训练。代码已公开在https://github.com/dong845/MCP-MedSAM。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [79] [DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection](https://arxiv.org/abs/2501.08005)
> *DisCoPatch: 驯服对抗驱动的批统计量以改进分布外检测*

*Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-07-22**

**Keywords:** OOD检测, 协变量偏移, 对抗训练, 批统计量, 变分自编码器

**Comment:** ICCV 2025

> **TL;DR:** DisCoPatch是一个无监督的对抗变分自编码器框架，通过利用批归一化中真实和对抗样本的独特批统计量来检测协变量偏移，从而显著提升分布外检测性能，并在ImageNet-1K(-C)和Near-OOD基准上达到最先进水平，同时模型紧凑且延迟低。

**AI_Comments:** DisCoPatch的创新之处在于利用对抗训练中批归一化的特性来区分真实和对抗样本的批统计量，并巧妙地将VAE的次优输出作为负样本来精炼判别器对协变量偏移的边界识别能力。这种方法不仅解决了传统OOD检测对协变量偏移关注不足的问题，还在性能和效率上取得了显著提升，为实际OOD检测应用提供了高效且紧凑的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有OOD检测研究多集中于语义和领域偏移，但协变量偏移（数据分布的细微变化）对机器学习性能有显著影响。本文旨在通过检测这些细微偏移来更好地理解分布内边界，从而改进OOD检测。

**Method:** 引入DisCoPatch，一个无监督的对抗变分自编码器（VAE）框架。它利用在BN训练的对抗判别器中，真实和对抗样本形成具有独特批统计量的不同域的特性。推理时，批次由同一图像的补丁组成，确保数据分布一致，使模型依赖批统计量。DisCoPatch使用VAE的次优输出（生成和重建的样本）作为负样本来训练判别器，从而提高其区分分布内样本和协变量偏移的能力，收紧边界。

**Result:** 在公共OOD检测基准上取得了最先进的结果。在ImageNet-1K(-C)上检测协变量偏移达到95.5% AUROC，并在公共Near-OOD基准上超越所有现有方法，达到95.0%。模型大小为25MB，延迟显著低于现有方法，实现了高效且实用的OOD检测。

**Conclusion:** DisCoPatch通过利用对抗训练中的批统计量和VAE的次优输出作为负样本，有效检测协变量偏移，显著提升了OOD检测性能，并在多个基准上达到SOTA，同时具有高效和紧凑的特点，使其成为实际应用中实用的解决方案。

> **ai_Abstract:** 本文提出了DisCoPatch，一个无监督的对抗变分自编码器框架，旨在通过检测协变量偏移来改进分布外检测。该方法利用对抗判别器中真实和对抗样本独特的批统计量，并使用VAE的次优输出来训练判别器以更好地划分分布内和协变量偏移的边界。实验结果表明，DisCoPatch在ImageNet-1K(-C)和Near-OOD基准上均达到了最先进的OOD检测性能，同时模型紧凑且推理延迟低，展现了其在实际应用中的高效和实用性。

> **摘要翻译:** 分布外 (OOD) 检测在许多应用中具有重要意义。虽然语义和领域偏移的 OOD 问题已得到充分研究，但本工作重点关注协变量偏移——数据分布中可能降低机器学习性能的细微变化。我们假设检测这些细微偏移可以提高我们对分布内边界的理解，最终改进 OOD 检测。在用批归一化 (BN) 训练的对抗判别器中，真实样本和对抗样本形成具有独特批统计量的不同域——我们利用了这一特性进行 OOD 检测。我们引入了 DisCoPatch，一个无监督的对抗变分自编码器 (VAE) 框架，它利用了这种机制。在推理过程中，批次由同一图像的补丁组成，确保数据分布一致，从而使模型能够依赖批统计量。DisCoPatch 使用 VAE 的次优输出（生成和重建的样本）作为负样本来训练判别器，从而提高其描绘分布内样本和协变量偏移之间边界的能力。通过收紧这个边界，DisCoPatch 在公共 OOD 检测基准上取得了最先进的结果。所提出的模型不仅在检测协变量偏移方面表现出色，在 ImageNet-1K(-C) 上达到了 95.5% 的 AUROC，而且在公共 Near-OOD (95.0%) 基准上超越了所有先前的方法。凭借 25MB 的紧凑模型大小，它实现了高 OOD 检测性能，并且延迟明显低于现有方法，使其成为实际 OOD 检测应用的有效且实用的解决方案。代码已公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark](https://arxiv.org/abs/2507.15882)
> *文档干草堆：一个长上下文多模态图像/文档理解视觉大型语言模型基准*

*Goeric Huybrechts, Srikanth Ronanki, Sai Muralidhar Jayanthi, Jack Fitzgerald, Srinivasan Veeravanallur* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-18**

**Keywords:** 长上下文, 多模态, 视觉语言模型, 基准, 文档理解

**Comment:** 

> **TL;DR:** 本文介绍了 Document Haystack，这是一个新的基准，用于评估视觉语言模型（VLM）在长而视觉复杂的文档上进行长上下文理解和检索的能力。

**AI_Comments:** 该论文通过引入 Document Haystack 基准，解决了多模态大型语言模型在长上下文文档理解方面评估基准缺乏的关键问题，具有重要意义。其“大海捞针”的方法创新性地测试了模型在长文档中的检索能力，并且该基准的规模（400种变体，8,250个问题）相当可观，有望推动该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大型语言模型在处理长文档时面临挑战，主要是因为缺乏合适的基准来评估其性能。

**Method:** 研究人员引入了 Document Haystack，这是一个综合性基准，包含从5到200页不等的长文档。该基准策略性地在文档不同深度插入纯文本或多模态文本+图像的“针”，以挑战VLM的检索能力。它包含400种文档变体和总计8,250个问题，并由一个客观、自动化的评估框架支持。

**Result:** 论文详细介绍了 Document Haystack 数据集的构建和特性，并展示了主流视觉语言模型（VLM）在该基准上的结果。

**Conclusion:** Document Haystack 基准的引入旨在促进视觉语言模型在长文档理解方面的研究和发展，并揭示了该领域的潜在研究方向。

> **ai_Abstract:** 本文介绍了 Document Haystack，这是一个新颖的多模态基准，旨在解决评估视觉语言模型（VLM）在长、视觉复杂文档上进行理解的挑战。该基准包含多达200页的文档，并嵌入了文本和多模态“针”以测试VLM的检索能力。它由400种文档变体和8,250个问题组成，并提供了一个自动化评估框架，同时展示了初始的VLM性能结果，并概述了未来的研究方向。

> **摘要翻译:** 多模态大型语言模型的普及显著提升了分析和理解来自不同模态的复杂数据输入的能力。然而，长文档的处理仍未得到充分探索，这主要是由于缺乏合适的基准。为了解决这个问题，我们引入了 Document Haystack，这是一个旨在评估视觉语言模型（VLM）在长、视觉复杂文档上性能的综合基准。Document Haystack 包含从 5 到 200 页不等的文档，并策略性地在文档内不同深度插入纯文本或多模态文本+图像的“针”，以挑战 VLM 的检索能力。它包含 400 种文档变体和总计 8,250 个问题，并由一个客观、自动化的评估框架支持。我们详细介绍了 Document Haystack 数据集的构建和特性，展示了主流 VLM 的结果，并讨论了该领域的潜在研究方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [89] [One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution](https://arxiv.org/abs/2507.16337)
> *一息识别所有：基于SAM的单次息肉分割，通过级联先验和迭代提示演化*

*Xinyu Mao, Xiaohan Xing, Fei Meng, Jianbang Liu, Fan Bai, Qiang Nie, Max Meng* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 息肉分割, 单次学习, SAM, 提示工程, 医疗图像分割

**Comment:** accepted by ICCV2025

> **TL;DR:** 本文提出了OP-SAM，一个基于SAM的单次息肉分割框架，它能从单个带标注图像自动生成提示，通过级联先验和迭代提示演化，解决了传统方法对大量标注的依赖和SAM手动提示的局限性，实现了高精度和泛化性，在Kvasir数据集上显著超越了现有最佳水平。

**AI_Comments:** 该论文提出了一种创新的单次学习范式，将强大的视觉基础模型SAM应用于医疗图像分割，有效解决了医疗领域标注稀缺的痛点。通过自动提示生成、多尺度先验融合和迭代提示演化等机制，极大地提升了自动化程度和分割精度。尤其是在零样本或单样本场景下，其性能显著优于现有方法，为临床应用提供了更高效、更实用的解决方案。未来研究可进一步探索其在不同器官或病变分割任务中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的全监督息肉分割方法难以应对形态变异和域偏移，且需要频繁再训练。此外，对大规模标注的依赖是主要瓶颈，因为息肉边界标注耗时且易出错。虽然SAM等视觉基础模型展现出强大的泛化性和精细边界检测能力，但其对提示的依赖性限制了在医疗应用中的自动化，因为手动为每张图像输入提示既费力又耗时。

**Method:** 本文提出了OP-SAM，一个基于SAM的单次息肉分割框架，它能从单个带标注图像自动生成提示。该方法引入了基于相关性的先验生成（CPG）进行语义标签迁移，以及尺度级联先验融合（SPF）以适应息肉尺寸变化并过滤噪声迁移。为了逐步提升分割质量，该方法设计了欧几里得提示演化（EPE）进行迭代提示细化，而非一次性输入所有提示。

**Result:** 在五个数据集上的广泛评估验证了OP-SAM的有效性。尤其在Kvasir数据集上，它达到了76.93%的IoU，超越了现有最佳水平11.44%。

**Conclusion:** OP-SAM通过自动生成提示和迭代细化，解决了单次息肉分割中对大规模标注的依赖和手动提示的局限性，实现了高精度和强大的泛化能力，并在多个数据集上，特别是Kvasir数据集上，显著优于现有最先进方法，证明了其在结直肠癌早期检测中的应用潜力。

> **ai_Abstract:** 本文提出了OP-SAM，一个基于Segment Anything Model (SAM) 的单次息肉分割框架，旨在解决传统方法对大量标注的依赖以及SAM在医疗应用中手动提示的局限性。OP-SAM能够仅通过一个标注图像自动生成分割提示。该框架包含三个核心组件：基于相关性的先验生成（CPG）用于语义标签迁移，尺度级联先验融合（SPF）用于适应息肉尺寸变化并过滤噪声，以及欧几里得提示演化（EPE）用于迭代细化提示以提升分割质量。实验证明，OP-SAM在五个数据集上表现出色，尤其在Kvasir数据集上，其IoU达到76.93%，显著超越了现有最佳水平11.44%。

> **摘要翻译:** 息肉分割对于结直肠癌的早期检测至关重要，然而传统的全监督方法在形态变异和域偏移方面面临挑战，需要频繁的再训练。此外，由于息肉边界标注耗时且易出错，对大规模标注的依赖是一个主要瓶颈。最近，像Segment Anything Model (SAM) 这样的视觉基础模型已经展示出强大的泛化能力和精细的边界检测能力，通过稀疏提示有效解决了关键的息肉分割挑战。然而，SAM的提示依赖性限制了其在医疗应用中的自动化，因为手动为每张图像输入提示既费力又耗时。我们提出了OP-SAM，一个基于SAM的单次息肉分割框架，它能从单个带标注图像自动生成提示，确保了准确和可泛化的分割，而无需额外的标注负担。我们的方法引入了基于相关性的先验生成（CPG）进行语义标签迁移，以及尺度级联先验融合（SPF）以适应息肉尺寸变化并过滤掉噪声迁移。我们设计了欧几里得提示演化（EPE）进行迭代提示细化，逐步提升分割质量，而不是一次性输入所有提示。在五个数据集上的广泛评估验证了OP-SAM的有效性。值得注意的是，在Kvasir数据集上，它达到了76.93%的IoU，超越了现有最佳水平11.44%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models](https://arxiv.org/abs/2412.08629)
> *FlowEdit：使用预训练流模型的免反演文本图像编辑*

*Vladimir Kulikov, Matan Kleiner, Inbar Huberman-Spiegelglas, Tomer Michaeli* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 文本图像编辑, 流模型, 免反演, ODE, Stable Diffusion 3

**Comment:** ICCV 2025. Project's webpage at
  https://matankleiner.github.io/flowedit/

> **TL;DR:** FlowEdit是一种免反演、免优化、模型无关的文本图像编辑方法，通过构建ODE直接映射分布，实现了比传统反演方法更低的传输成本，并在多个模型上取得了最先进的结果。

**AI_Comments:** FlowEdit的创新之处在于其免反演、免优化和模型无关的设计，这极大地提升了文本图像编辑的通用性和效率。通过引入ODE直接映射分布，它提供了一个优雅且高效的解决方案，有效克服了现有方法的局限性，对未来的生成模型编辑研究具有重要启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有使用预训练文本到图像（T2I）扩散/流模型编辑真实图像的方法通常需要反演图像，但这本身不足以获得满意结果；此外，许多通过干预采样过程改进结果的方法，在不同模型架构之间无法无缝迁移。

**Method:** FlowEdit通过构建一个常微分方程（ODE），直接在源和目标分布（对应源和目标文本提示）之间进行映射，从而实现免反演、免优化和模型无关的文本图像编辑，并实现了比反演方法更低的传输成本。

**Result:** FlowEdit在文本图像编辑方面取得了最先进的结果，并在Stable Diffusion 3和FLUX等模型上得到了验证。

**Conclusion:** FlowEdit成功提供了一种高效且通用的文本图像编辑解决方案，克服了传统反演方法的局限性和现有方法在不同模型架构间的迁移问题，从而达到了卓越的性能。

> **ai_Abstract:** FlowEdit提出了一种新颖的、免反演、免优化且模型无关的文本图像编辑方法，专为预训练的文本到图像（T2I）流模型设计。它通过构建一个常微分方程（ODE），直接在源和目标文本提示所对应的分布之间进行映射，有效解决了传统反演方法不足和现有方法架构依赖的问题。该方法显著降低了传输成本，并在Stable Diffusion 3和FLUX上验证了其最先进的编辑性能。

> **摘要翻译:** 使用预训练的文本到图像（T2I）扩散/流模型编辑真实图像通常涉及将图像反演为其对应的噪声图。然而，单靠反演通常不足以获得令人满意的结果，因此许多方法还会额外干预采样过程。这类方法取得了改进的结果，但在模型架构之间无法无缝迁移。在此，我们引入了FlowEdit，一种针对预训练T2I流模型的文本图像编辑方法，它是免反演、免优化且模型无关的。我们的方法构建了一个ODE，直接在源和目标分布（对应源和目标文本提示）之间进行映射，并实现了比反演方法更低的传输成本。这带来了最先进的结果，正如我们在Stable Diffusion 3和FLUX上所展示的。代码和示例可在项目网页上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [108] [Navigating Large-Pose Challenge for High-Fidelity Face Reenactment with Video Diffusion Model](https://arxiv.org/abs/2507.16341)
> *使用视频扩散模型应对大姿态挑战以实现高保真人脸重演*

*Mingtao Guo, Guanyu Xing, Yanci Zhang, Yanli Liu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 人脸重演, 视频扩散模型, 大姿态, 隐式关键点, 高保真

**Comment:** 

> **TL;DR:** FRVD是一个新的视频扩散模型，通过结合隐式关键点和预训练的I2V模型，在高保真人脸重演中解决了大姿态变化带来的挑战。

**AI_Comments:** FRVD的创新点在于结合了隐式面部关键点提取与预训练I2V模型的运动感知潜在空间，有效解决了大姿态重演中的扭曲问题和时间一致性问题。这种方法利用了大规模视频数据中学习到的丰富先验知识，提升了高保真人脸重演的质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸重演方法在处理大姿态变化时存在困难，表现为扭曲伪影或粗糙的面部特征点限制。

**Method:** 本文提出了人脸重演视频扩散模型（FRVD），它首先使用运动提取器从源图像和驱动图像中提取隐式面部关键点以表示细粒度运动，并通过扭曲模块进行运动对齐。为了解决扭曲引入的退化，引入扭曲特征映射器（WFM）将扭曲的源图像映射到预训练的图像到视频（I2V）模型的运动感知潜在空间中，利用该空间编码的面部动态先验来纠正扭曲并增强时间一致性。

**Result:** FRVD在姿态准确性、身份保留和视觉质量方面优于现有方法，尤其是在极端姿态变化等挑战性场景中表现出色。

**Conclusion:** FRVD通过其新颖的架构有效地解决了大姿态变化下高保真人脸重演的挑战，显著提升了生成视频的质量和真实感。

> **ai_Abstract:** 本文提出了FRVD（Face Reenactment Video Diffusion model），一个针对大姿态变化下高保真人脸重演的新型框架。该模型通过运动提取器获取细粒度隐式关键点并进行运动对齐，随后利用扭曲特征映射器将扭曲图像映射到预训练I2V模型的运动感知潜在空间，从而有效纠正扭曲并提升时间一致性。实验证明FRVD在姿态准确性、身份保留和视觉质量方面显著优于现有方法，尤其在处理极端姿态时表现卓越。

> **摘要翻译:** 人脸重演旨在通过将驱动视频的运动转移到静态源图像上，同时保留源身份，从而生成逼真的说话人头视频。尽管现有基于隐式或显式关键点的方法已显示出前景，但由于扭曲伪影或粗糙面部特征点的限制，它们在处理大姿态变化时仍面临挑战。在本文中，我们提出了人脸重演视频扩散模型（FRVD），这是一种用于在大姿态变化下实现高保真人脸重演的新颖框架。我们的方法首先采用运动提取器从源图像和驱动图像中提取隐式面部关键点，以表示细粒度运动，并通过扭曲模块执行运动对齐。为了解决扭曲引入的退化，我们引入了一个扭曲特征映射器（WFM），它将扭曲的源图像映射到预训练的图像到视频（I2V）模型的运动感知潜在空间中。这个潜在空间编码了从大规模视频数据中学习到的丰富面部动态先验，从而能够有效纠正扭曲并增强时间一致性。广泛的实验表明，FRVD在姿态准确性、身份保留和视觉质量方面优于现有方法，尤其是在极端姿态变化等挑战性场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [110] [PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion](https://arxiv.org/abs/2503.00196)
> *PRISM：使用语言引导的稳定扩散进行高分辨率精确反事实医学图像生成*

*Amar Kumar, Anita Kriz, Mohammad Havaei, Tal Arbel* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 医学图像生成, 反事实, 稳定扩散, 视觉-语言模型, 鲁棒性

**Comment:** MIDL 2025

> **TL;DR:** PRISM利用语言引导的稳定扩散模型生成高分辨率医学反事实图像，以解决医学图像深度学习中的挑战，并提高下游分类器的鲁棒性。

**AI_Comments:** PRISM的创新之处在于将自然图像领域的视觉-语言基础模型（特别是Stable Diffusion）成功引入医学图像领域，实现了高分辨率和精确的语言引导反事实生成。这对于解决医学图像数据中的虚假关联和数据偏见问题具有重要意义，能够有效提高下游诊断模型的鲁棒性和泛化能力。其公开代码也有助于推动该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 医疗影像深度学习系统面临虚假关联、数据不平衡和有限文本标注等重大障碍，需要更鲁棒的架构。自然图像领域中视觉-语言基础模型的快速发展促使研究者思考如何将其应用于医疗影像任务。

**Method:** 本文提出了PRISM框架，该框架利用基础模型和Stable Diffusion生成高分辨率、语言引导的医学图像反事实。该方法能够精确选择性地修改图像中的虚假关联（如医疗设备）和疾病特征，实现特定属性的移除和添加，同时保留其他图像特征。

**Result:** PRISM在选择性修改虚假关联和疾病特征方面展现出前所未有的精度，能够移除和添加特定属性同时保留其他图像特性。通过广泛评估，证明PRISM推动了反事实生成，并有助于开发更鲁棒的下游分类器，从而实现临床可部署的解决方案。

**Conclusion:** PRISM显著推进了反事实图像生成技术，并为开发更稳健、可临床部署的下游分类器提供了可能。

> **ai_Abstract:** 本文介绍了PRISM框架，该框架利用语言引导的Stable Diffusion模型生成高分辨率的医学图像反事实。PRISM旨在解决医学影像深度学习中因虚假关联、数据不平衡和标注不足导致的挑战。它能够精确地修改图像中的特定属性，如医疗设备或疾病特征，同时保持图像的其他部分不变。实验证明，PRISM显著提升了反事实图像生成的能力，并有助于构建更稳健的下游分类器，为临床应用提供支持。

> **摘要翻译:** 开发可靠且泛化性强的医学影像深度学习系统面临着虚假关联、数据不平衡和数据集中有限文本标注等重大障碍。应对这些挑战需要对医疗影像数据所带来的独特复杂性具有鲁棒性的架构。自然图像领域中视觉-语言基础模型的快速发展提出了如何将其应用于医疗影像任务的问题。在这项工作中，我们提出了PRISM，一个利用基础模型，通过Stable Diffusion生成高分辨率、语言引导的医学图像反事实的框架。我们的方法在选择性修改虚假关联（医疗设备）和疾病特征方面展示了前所未有的精度，能够移除和添加特定属性，同时保留其他图像特征。通过广泛评估，我们展示了PRISM如何推动反事实生成并使得开发更鲁棒的下游分类器成为可能，从而实现临床可部署的解决方案。为了促进更广泛的采用和研究，我们公开了我们的代码，网址为https://github.com/Amarkr1/PRISM。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [112] [AtrousMamaba: An Atrous-Window Scanning Visual State Space Model for Remote Sensing Change Detection](https://arxiv.org/abs/2507.16172)
> *AtrousMamba：一种用于遥感变化检测的空洞窗口扫描视觉状态空间模型*

*Tao Wang, Tiecheng Bai, Chao Xu, Bin Liu, Erlei Zhang, Jiyun Huang, Hongming Zhang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** AtrousMamba, 视觉状态空间模型, 变化检测, 遥感, 空洞窗口

**Comment:** 

> **TL;DR:** AtrousMamba引入空洞窗口扫描机制，增强Mamba在遥感变化检测中的局部特征提取能力，平衡局部细节与全局上下文，并在六个基准数据集上超越现有方法。

**AI_Comments:** 该论文的创新之处在于巧妙地将空洞卷积的思想引入到Mamba的扫描机制中，以解决Mamba在视觉任务中对局部特征处理的不足，这对于需要精细局部信息的密集预测任务（如变化检测）至关重要。它提供了一个新的视角，展示了Mamba模型如何通过结构上的改进来弥补其在局部感受野方面的潜在局限性，从而扩展了Mamba在计算机视觉领域的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Mamba模型在处理视觉数据时，虽然能有效处理长序列并增强全局感受野，但往往忽视了密集预测任务中局部信息的重要性。此外，Mamba是否能像卷积神经网络（CNN）一样有效提取局部特征仍是一个有待深入研究的问题。

**Method:** 本文提出了一种名为AtrousMamba的新型模型，旨在有效平衡细粒度局部细节的提取与全局上下文信息的整合。具体而言，该方法引入了一种空洞窗口选择性扫描机制，能够以可调节的速率逐步扩展扫描范围，从而缩短相邻tokens之间的距离，使模型能够有效地捕获细粒度局部特征和全局上下文。通过利用空洞窗口扫描视觉状态空间（AWVSS）模块，设计了针对二元变化检测（BCD）和语义变化检测（SCD）的端到端Mamba框架，分别命名为AWMambaBCD和AWMambaSCD。

**Result:** 在六个基准数据集上的实验结果表明，所提出的框架优于现有的基于CNN、基于Transformer和基于Mamba的方法。

**Conclusion:** 研究结果清楚地表明，Mamba不仅能够捕获视觉数据中的长距离依赖关系，而且还能有效地保留细粒度的局部细节。

> **ai_Abstract:** 本文提出了一种名为AtrousMamba的新型视觉状态空间（VSS）模型，旨在解决现有Mamba模型在视觉密集预测任务中对局部信息处理不足的问题。AtrousMamba通过引入空洞窗口选择性扫描机制，实现了局部细节提取与全局上下文整合的有效平衡。该机制能够逐步扩展扫描范围并缩短相邻tokens距离，从而更好地捕获细粒度局部特征。基于此，作者设计了用于二元变化检测（BCD）和语义变化检测（SCD）的端到端Mamba框架AWMambaBCD和AWMambaSCD。实验结果表明，AtrousMamba在六个基准数据集上均优于现有的CNN、Transformer和Mamba基线方法，证明了Mamba在捕获长距离依赖的同时也能有效保留局部细节。

> **摘要翻译:** 最近，一种名为Mamba的新型视觉状态空间（VSS）模型在建模具有线性复杂度的长序列方面取得了显著进展，与Transformer模型相媲美，从而增强了其处理视觉数据的适应性。尽管大多数方法旨在通过直接修改Mamba的扫描机制来增强全局感受野，但它们往往忽视了在密集预测任务中局部信息的关键重要性。此外，Mamba是否能像卷积神经网络（CNN）一样有效提取局部特征仍然是一个有待进一步研究的开放性问题。在本文中，我们提出了一种新颖的模型AtrousMamba，它有效地平衡了细粒度局部细节的提取与全局上下文信息的整合。具体而言，我们的方法结合了一种空洞窗口选择性扫描机制，能够以可调节的速率逐步扩展扫描范围。这种设计缩短了相邻tokens之间的距离，使模型能够有效地捕获细粒度局部特征和全局上下文。通过利用空洞窗口扫描视觉状态空间（AWVSS）模块，我们设计了专用的端到端Mamba框架，用于二元变化检测（BCD）和语义变化检测（SCD），分别称为AWMambaBCD和AWMambaSCD。在六个基准数据集上的实验结果表明，所提出的框架优于现有的基于CNN、基于Transformer和基于Mamba的方法。这些发现清楚地表明，Mamba不仅捕获了视觉数据中的长距离依赖关系，而且还有效地保留了细粒度的局部细节。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [114] [A2Mamba: Attention-augmented State Space Models for Visual Recognition](https://arxiv.org/abs/2507.16624)
> *A2Mamba：用于视觉识别的注意力增强型状态空间模型*

*Meng Lou, Yunxiang Fu, Yizhou Yu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** A2Mamba, 注意力增强型状态空间模型, 视觉识别, Transformer, Mamba

**Comment:** 14 pages, 5 figures, 13 tables

> **TL;DR:** A2Mamba提出了一种新型的Transformer-Mamba混合网络架构，通过深度集成注意力机制和状态空间模型，在视觉识别任务中取得了SOTA性能。

**AI_Comments:** A2Mamba的核心创新在于其提出的MASS令牌混合器，通过在A2SSM中深度融合多尺度注意力与状态空间模型，有效地解决了Transformer和Mamba之间缺乏交互的难题。这种方法不仅理论上更优，而且在多个视觉任务上取得了SOTA性能，尤其是在效率和参数量上的优势，预示着其在实际应用中的巨大潜力。该研究为构建更强大的混合骨干网络提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉识别骨干网络，如Transformer和Mamba，虽然被整合，但仅限于简单堆叠，缺乏两者之间的有效交互机制，导致深度融合仍是一个未解决的问题。

**Method:** 本文提出了A2Mamba，一个强大的Transformer-Mamba混合网络架构。其核心是一个名为多尺度注意力增强型状态空间模型（MASS）的新型令牌混合器，其中多尺度注意力图被整合到注意力增强型SSM（A2SSM）中。A2SSM的关键步骤是通过使用多尺度注意力图空间聚合SSM的隐藏状态，执行一种变体交叉注意力，从而增强二维空间相关的空间依赖性，并提高SSM的动态建模能力。

**Result:** A2Mamba在视觉识别任务中超越了所有先前的基于ConvNet、Transformer和Mamba的架构。例如，A2Mamba-L在ImageNet-1K上实现了86.1%的top-1准确率。在语义分割中，A2Mamba-B在mIoU方面比CAFormer-S36高出2.5%，同时效率更高。在结合Cascade Mask R-CNN的目标检测和实例分割中，A2Mamba-S在AP^b/AP^m方面分别超过MambaVision-B 1.2%/0.9%，同时参数量减少40%。

**Conclusion:** A2Mamba通过提出一种新颖的注意力增强型状态空间模型（A2SSM）实现了Transformer和Mamba层的深度融合，成功解决了现有方法缺乏交互机制的问题，并在各种视觉识别任务中展现出卓越的性能和效率。

> **ai_Abstract:** 该论文提出了A2Mamba，一种创新的Transformer-Mamba混合网络，旨在解决现有方法中Transformer和Mamba层之间缺乏深度交互的问题。通过引入多尺度注意力增强型状态空间模型（MASS），该模型将多尺度注意力图整合到A2SSM中，通过空间聚合SSM隐藏状态来增强空间依赖性并提升动态建模能力。A2Mamba在ImageNet-1K分类、语义分割和目标检测/实例分割等多项视觉识别任务中均显著超越了现有模型，展现了卓越的性能和效率。

> **摘要翻译:** Transformer和Mamba最初为自然语言处理而发明，但已启发了视觉识别的骨干架构。最近的研究将局部注意力Transformer与Mamba集成，以捕获局部细节和全局上下文。尽管性能具有竞争力，但这些方法仅限于简单堆叠Transformer和Mamba层，它们之间没有任何交互机制。因此，Transformer和Mamba层之间的深度集成仍然是一个开放问题。我们通过提出A2Mamba来解决这个问题，这是一种强大的Transformer-Mamba混合网络架构，其特点是一种名为多尺度注意力增强型状态空间模型（MASS）的新型令牌混合器，其中多尺度注意力图被集成到注意力增强型SSM（A2SSM）中。A2SSM的一个关键步骤是通过使用多尺度注意力图空间聚合SSM的隐藏状态，执行一种变体交叉注意力，这增强了与二维空间相关的空间依赖性，同时提高了SSM的动态建模能力。我们的A2Mamba在视觉识别任务中超越了所有先前的基于ConvNet、Transformer和Mamba的架构。例如，A2Mamba-L在ImageNet-1K上实现了令人印象深刻的86.1%的top-1准确率。在语义分割中，A2Mamba-B在mIoU方面比CAFormer-S36高出2.5%，同时表现出更高的效率。在结合Cascade Mask R-CNN的目标检测和实例分割中，A2Mamba-S在AP^b/AP^m方面分别超过MambaVision-B 1.2%/0.9%，同时参数量减少40%。代码已公开：https://github.com/LMMMEng/A2Mamba。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [119] [Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras](https://arxiv.org/abs/2503.17262)
> *基于事件相机的光流与强度无监督联合学习*

*Shuang Guo, Friedhelm Hamann, Guillermo Gallego* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-07-22**

**Keywords:** 事件相机, 光流, 强度估计, 无监督学习, 联合学习

**Comment:** 13 pages, 8 figures, 9 tables. Project page:
  https://github.com/tub-rip/E2FAI . IEEE/CVF International Conference on
  Computer Vision (ICCV), 2025

> **TL;DR:** 本文提出一种无监督学习框架，利用单个网络联合估计事件相机的光流和图像强度，并取得了最先进的性能和更快的推理速度。

**AI_Comments:** 这项工作的主要创新点在于提出了一种无监督的联合学习框架，能够同时估计事件相机的光流和图像强度，这与事件相机数据固有的运动与外观耦合特性相符。通过引入新的事件基于光度误差并结合对比度最大化，该方法有效地利用了事件数据的特性。其性能提升和推理速度优势使其在事件相机视觉领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的事件相机数据处理方法将光流（运动）和图像强度（外观）的恢复视为独立任务，这与事件相机固有的运动与外观耦合特性不符，且忽视了它们之间的内在联系。

**Method:** 提出了一种无监督学习框架，使用单个网络联合估计光流和图像强度。该方法从数据生成模型中新推导了基于事件的光度误差，并将其与对比度最大化框架相结合，形成一个全面的损失函数，为光流和强度估计提供适当的约束。

**Result:** 在光流估计方面，与无监督方法相比，EPE降低了20%，AE降低了25%，同时在HDR场景下提供了具有竞争力的强度估计结果。此外，该方法比所有其他光流方法和许多图像重建方法具有更短的推理时间，而这些方法通常只输出一个量。

**Conclusion:** 本文提出的无监督联合学习框架能够有效且高效地从事件相机数据中同时恢复光流和图像强度，取得了最先进的性能，并解决了以往方法中忽视运动与外观内在关联的问题。

> **ai_Abstract:** 本文提出了一种新颖的无监督学习框架，旨在克服现有事件相机数据处理方法中将光流和图像强度视为独立任务的局限性。该框架利用单个网络联合估计这两个视觉量，并创新性地推导了基于事件的光度误差，结合对比度最大化构建了综合损失函数。实验证明，该方法在光流估计上达到了最先进的性能，显著降低了误差，并在高动态范围场景下提供了有竞争力的强度估计，同时实现了更快的推理速度。

> **摘要翻译:** 事件相机依赖于运动来获取场景外观信息。这意味着外观和运动是内在关联的：事件数据中要么两者都存在并被记录，要么两者都未被捕获。以往的工作将这两种视觉量的恢复视为独立的任务，这与事件相机的上述特性不符，并且忽视了它们之间的内在关系。我们提出了一种无监督学习框架，使用单个网络联合估计光流（运动）和图像强度（外观）。从数据生成模型中，我们新推导了基于事件的光度误差，该误差是光流和图像强度的函数。该误差进一步与对比度最大化框架相结合，形成一个全面的损失函数，为光流和强度估计提供适当的约束。详尽的实验表明我们的方法达到了最先进的性能：在光流估计方面，与无监督方法相比，它将EPE降低了20%，AE降低了25%，同时提供了具有竞争力的强度估计结果，特别是在高动态范围场景中。我们的方法还比所有其他光流方法和许多图像重建方法实现了更短的推理时间，而它们通常只输出一个量。项目页面：https://github.com/tub-rip/E2FAI

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [120] [Do large language vision models understand 3D shapes?](https://arxiv.org/abs/2412.10908)
> *大型语言视觉模型理解三维形状吗？*

*Sagi Eppel* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 大型视觉语言模型, 三维形状理解, 计算机视觉, 形状匹配, 人工智能

**Comment:** 

> **TL;DR:** 大型语言视觉模型（LVLM）在识别具有不同方向和材质的相同三维形状方面表现出一些抽象理解，但仍远低于人类水平。

**AI_Comments:** 这项研究通过系统地测试大型视觉语言模型在三维形状理解方面的表现，填补了该领域的一个空白。其创新之处在于使用了CGI生成多样化的测试数据，并细致地分析了模型在不同变化（方向、材质）下的表现。研究结果揭示了当前LVLM在复杂三维理解方面的局限性，特别是在多变量变化下的不足，为未来的模型改进提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 测试大型视觉语言模型（LVLM）是否真正理解三维形状，通过评估它们在识别和匹配具有相同三维形状但方向和材质不同物体方面的能力。

**Method:** 使用计算机图形图像（CGI）创建了大量测试图像，包含高度多样化的物体、材质和场景，以测试模型识别和匹配具有相同三维形状但不同方向和材质的物体。

**Result:** 测试结果显示，模型匹配三维形状的能力显著低于人类，但远高于随机猜测。模型可以轻松识别不同方向的相同物体，以及匹配相同方向但材质和纹理不同的相同三维形状。然而，当物体的材质和方向都改变时，所有模型相对于人类的表现都很差。

**Conclusion:** 大型视觉语言模型对三维形状获得了一些抽象理解，但在这项任务中仍然远远落后于人类，尤其是在物体材质和方向同时改变的情况下。

> **ai_Abstract:** 本研究旨在评估大型视觉语言模型（LVLM）对三维形状的理解能力。通过创建大量包含不同方向和材质的相同三维物体的CGI测试图像，研究人员测试了LVLM的识别和匹配能力。结果表明，LVLM在三维形状匹配方面表现优于随机猜测，但显著低于人类水平。模型在处理单一变化（如仅方向或仅材质改变）时表现较好，但在同时改变方向和材质时表现不佳。这表明LVLM对三维形状具有一定的抽象理解，但仍需大幅改进以达到人类水平。

> **摘要翻译:** 大型视觉语言模型（LVLM）是实现对世界普遍视觉理解的领先人工智能方法。GPT、Claude、Gemini和LLama等模型可以使用图像来理解和分析复杂的视觉场景。三维物体和形状是世界的基本组成部分，识别它们是人类感知的基础部分。这项工作的目标是通过测试模型识别和匹配具有完全相同三维形状但不同方向和材料/纹理的物体的能力，来检验LVLM是否真正理解三维形状。利用CGI创建了大量测试图像，其中包含大量高度多样化的物体、材料和场景。这项测试的结果表明，此类模型匹配三维形状的能力显著低于人类，但远高于随机猜测。这表明模型对三维形状获得了一些抽象理解，但在这项任务中仍远落后于人类。主要看来，模型可以轻松识别不同方向的相同物体，以及匹配相同方向但不同材料和纹理的相同三维形状。然而，当物体材料和方向都改变时，所有模型的表现相对于人类都较差。代码和基准测试可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [121] [PAT++: a cautionary tale about generative visual augmentation for Object Re-identification](https://arxiv.org/abs/2507.15888)
> *PAT++：关于生成式视觉增强用于目标重识别的警示*

*Leonardo Santiago Benitez Pereira, Arathy Jeevan* | **Category: cs.CV** | **Updated: 2025-07-19**

**Keywords:** 生成式数据增强, 目标重识别, 细粒度识别, 扩散自蒸馏, 性能下降

**Comment:** 

> **TL;DR:** 该论文探讨了生成式数据增强在目标重识别中的应用，发现由于领域偏移和未能保留身份定义特征，导致性能持续下降。

**AI_Comments:** 该论文为生成式视觉增强在细粒度任务（如目标重识别）中的应用提供了一个重要的“警示”。它挑战了普遍认为更多数据（即使是生成数据）总能带来更好性能的假设，尤其当保留身份特征至关重要时。论文中指出的领域偏移和特征丢失问题，对该领域未来的研究具有重要的启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式数据增强在其他视觉任务中表现出优势，但其在需要保留细粒度视觉细节的目标重识别任务中的影响尚未被充分探索，本研究旨在评估其有效性。

**Method:** 研究提出了一种名为PAT++的新型管道，将扩散自蒸馏（Diffusion Self-Distillation）整合到部件感知Transformer中。通过使用Urban Elements ReID Challenge数据集，对用于模型训练和查询扩展的生成图像进行了广泛实验。

**Result:** 实验结果显示，性能持续下降，这主要归因于领域偏移和未能保留身份定义特征。

**Conclusion:** 这些发现挑战了关于生成模型向细粒度识别任务可迁移性的假设，并揭示了当前用于身份保留应用的视觉增强方法中的关键局限性。

> **ai_Abstract:** 本文探讨了生成式视觉增强，特别是身份保留图像生成，在目标重识别任务中的有效性。研究引入了PAT++，一个将扩散自蒸馏整合到部件感知Transformer中的管道。在Urban Elements ReID Challenge数据集上的实验表明，使用生成图像进行训练或查询扩展会导致性能持续下降，原因在于领域偏移和身份特征的丢失。这项工作强调了当前生成式增强方法在细粒度、身份保留任务中的局限性。

> **摘要翻译:** 生成式数据增强已在多项视觉任务中展现出优势，但其在目标重识别（其中保留细粒度视觉细节至关重要）中的影响仍未得到充分探索。在这项工作中，我们评估了身份保留图像生成对目标重识别的有效性。我们名为 PAT++ 的新颖管道将扩散自蒸馏融入了成熟的部件感知Transformer。利用 Urban Elements ReID Challenge 数据集，我们对用于模型训练和查询扩展的生成图像进行了广泛实验。我们的结果显示性能持续下降，这归因于领域偏移和未能保留身份定义特征。这些发现挑战了关于生成模型向细粒度识别任务可迁移性的假设，并揭示了当前用于身份保留应用的视觉增强方法中的关键局限性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [Mamba-OTR: a Mamba-based Solution for Online Take and Release Detection from Untrimmed Egocentric Video](https://arxiv.org/abs/2507.16342)
> *Mamba-OTR：一种基于Mamba的未剪辑第一人称视频在线抓取与释放检测解决方案*

*Alessandro Sebastiano Catinello, Giovanni Maria Farinella, Antonino Furnari* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 在线检测, Mamba, 第一人称视频, 抓取与释放, 效率

**Comment:** 

> **TL;DR:** Mamba-OTR是一种新的基于Mamba的模型，用于在线检测未剪辑第一人称视频中的物体抓取和释放事件，在准确性和效率上均优于Transformer和Vanilla Mamba。

**AI_Comments:** Mamba-OTR的创新在于将Mamba架构应用于在线视频事件检测，并针对该任务的标签不平衡和效率要求进行了优化。其在准确性和效率上的显著提升，尤其是在处理长视频和高帧率数据方面的优势，使其成为该领域的一个重要进展。公开发布代码将促进后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 在未剪辑的第一人称视频中在线检测物体的抓取和释放（OTR）具有挑战性，因为存在严重的标签不平衡（正样本稀疏）和需要精确的时间预测，同时方法需要具有计算效率以适应实时在线部署。

**Method:** 提出了Mamba-OTR模型，它基于Mamba架构，旨在利用推理时的时序循环性，并能通过短视频片段进行训练。为解决标签不平衡问题，训练流程结合了focal loss和一种新颖的正则化方案，该方案使模型预测与评估指标对齐。

**Result:** 在EPIC-KITCHENS-100数据集上进行了广泛实验，Mamba-OTR在准确性和效率上均优于基于Transformer的方法。在全长视频或高帧率序列上表现尤为突出，即使仅用短视频片段训练。在滑动窗口模式下，Mamba-OTR实现了45.48的mp-mAP，在流式模式下为43.35，远高于普通Transformer的20.32和普通Mamba的25.16。

**Conclusion:** Mamba-OTR为在线抓取与释放检测提供了一个强大的基线，并在准确性和效率上表现出色。

> **ai_Abstract:** 这项工作提出了Mamba-OTR，一个基于Mamba架构的模型，用于在线检测未剪辑第一人称视频中的物体抓取和释放事件。该模型通过利用时序循环性和结合focal loss及新型正则化方案来解决标签不平衡和计算效率挑战。实验证明Mamba-OTR在准确性和效率上均优于现有方法，尤其在处理长视频和高帧率数据时表现突出，为OTR任务提供了强大的新基线。

> **摘要翻译:** 本工作旨在解决未剪辑第一人称视频中物体在线抓取和释放（OTR）的检测问题。这项任务具有挑战性，因为存在严重的标签不平衡，正样本标注在时间上稀疏，并且需要精确的时间预测。此外，方法需要具有计算效率，以便在真实世界的在线环境中部署。为了应对这些挑战，我们提出了一种基于Mamba架构的模型Mamba-OTR。Mamba-OTR旨在利用推理时的时序循环性，同时通过短视频片段进行训练。为了解决标签不平衡问题，我们的训练管道结合了focal loss和一种新颖的正则化方案，该方案使模型预测与评估指标对齐。在EPIC-KITCHENS-100数据集上的大量实验，与基于Transformer的方法的比较，以及对不同训练和测试方案的评估，都证明了Mamba-OTR在准确性和效率方面的优越性。这些发现尤其在评估全长视频或高帧率序列时更为明显，即使为了计算便利而使用短视频片段进行训练。所提出的Mamba-OTR在滑动窗口模式下运行时达到了45.48的mp-mAP，在流式模式下达到了43.35，而普通Transformer为20.32，普通Mamba为25.16，从而为OTR提供了一个强大的基线。我们将公开发布Mamba-OTR的源代码以支持未来的研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [145] [Predicting the Reliability of an Image Classifier under Image Distortion](https://arxiv.org/abs/2412.16881)
> *预测图像分类器在图像失真下的可靠性*

*Dang Nguyen, Sunil Gupta, Kien Do, Svetha Venkatesh* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 图像分类器, 可靠性, 图像失真, 高斯过程, 数据不平衡

**Comment:** 

> **TL;DR:** 本文提出了一种基于高斯过程的方法，用于预测图像分类器在不同图像失真水平下的可靠性，解决了训练集不平衡的问题，并在多个数据集上取得了显著优于基线的性能。

**AI_Comments:** 该论文的创新点在于提出了一个预测图像分类器在失真下可靠性的框架，并特别关注了训练集中数据不平衡这一关键挑战。通过引入基于高斯过程的方法来处理不平衡数据，该研究为确保深度学习模型在实际应用中的鲁棒性和质量控制提供了有价值的工具。其重要性在于，在现实世界中，图像数据常常存在各种失真，而能够预测模型在这种条件下的表现对于部署可靠的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在图像分类任务中，深度学习模型容易受到图像失真的影响，导致准确率显著下降。为了质量控制，预测图像分类器在特定失真水平下是否可靠至关重要。

**Method:** 构建一个包含失真水平及其“不可靠”或“可靠”标签的训练集，并训练一个机器学习预测模型（称为失真分类器）来分类未见的失真水平。针对训练集高度不平衡的问题，提出了一种基于高斯过程的方法来重新平衡训练集。

**Result:** 通过广泛的实验表明，所提出的方法在六个流行的图像数据集上显著优于多个基线方法。

**Conclusion:** 本研究提出了一种有效的方法来预测图像分类器在图像失真下的可靠性，通过采用基于高斯过程的方法解决了训练集中数据不平衡的挑战，并取得了优异的性能。

> **ai_Abstract:** 本研究旨在解决深度学习图像分类器在图像失真下可靠性预测的问题。鉴于模型在失真输入下准确率会显著下降，作者提出了一种方法来预测特定失真水平是否会导致分类器“不可靠”。该方法通过训练一个“失真分类器”来实现，该分类器利用带有可靠性标签的失真水平数据进行学习。为了克服训练集固有的高度不平衡问题，研究引入了一种基于高斯过程的方法来重新平衡数据。实验结果表明，该方法在多个主流图像数据集上均显著优于现有基线。

> **摘要翻译:** 在图像分类任务中，深度学习模型容易受到图像失真的影响，即如果输入图像发生失真，它们的准确性会显著下降。如果图像分类器在失真图像上的准确性高于用户指定的阈值，则认为它是“可靠的”。为了质量控制目的，预测图像分类器在某个失真水平下是否不可靠/可靠非常重要。换句话说，我们希望预测某个失真水平是否会使图像分类器“不可靠”或“可靠”。我们的解决方案是构建一个由失真水平及其“不可靠”或“可靠”标签组成的训练集，并训练一个机器学习预测模型（称为失真分类器）来分类未见的失真水平。然而，学习一个有效的失真分类器是一个具有挑战性的问题，因为训练集高度不平衡。为了解决这个问题，我们提出了一种基于高斯过程的方法来重新平衡训练集。我们进行了广泛的实验，结果表明我们的方法在六个流行的图像数据集上显著优于多个基线方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [148] [LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network](https://arxiv.org/abs/2507.16362)
> *LPTR-AFLNet: 轻量级集成中文车牌校正与识别网络*

*Guangzhu Xu, Pengcheng Zuo, Zhi Ke, Bangjun Lei* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 中文车牌识别, 透视畸变校正, 轻量级网络, 端到端, 边缘计算

**Comment:** 28 pages, 33 figures

> **TL;DR:** 提出LPTR-AFLNet，一个轻量级端到端网络，用于实时高效地校正和识别中文车牌，解决了复杂环境下透视畸变和计算资源受限的问题。

**AI_Comments:** 本文的创新点在于提出了一个轻量级且端到端的网络，同时解决了车牌的校正和识别问题，特别是在资源受限的边缘设备上实现了高效部署。其利用识别结果作为弱监督信号来指导校正过程是一个巧妙的设计。此外，对LPRNet的改进也提升了识别的鲁棒性。该方法在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在非受限和复杂环境下，中文车牌识别（CLPR）面临透视畸变以及单行和双行车牌校正的挑战。考虑到边缘设备有限的计算资源，开发一个低复杂度、端到端的集成校正和识别网络对于实现实时高效部署至关重要。

**Method:** 提出了一个名为LPTR-AFLNet的轻量级统一网络，用于校正和识别中文车牌。该网络结合了透视变换校正模块（PTR）和优化的车牌识别网络AFLNet。网络利用识别输出作为弱监督信号来指导校正过程。为了提高识别精度，对LPRNet进行了改进，包括引入改进的注意力模块以减少相似字符之间的混淆，并使用Focal Loss来解决训练期间的类别不平衡问题。

**Result:** 实验结果表明LPTR-AFLNet在校正透视畸变和识别双行车牌图像方面表现出色，并在各种挑战性场景中保持高识别精度。此外，在中低端GPU平台上，该方法运行时间少于10毫秒。

**Conclusion:** LPTR-AFLNet是一个高效且实用的中文车牌校正与识别解决方案，适用于资源受限的边缘设备，并在复杂环境中表现出高精度和实时性。

> **ai_Abstract:** 本文提出了LPTR-AFLNet，一个轻量级、端到端的中文车牌校正与识别网络。该网络集成了透视变换校正模块（PTR）和优化的AFLNet，并利用识别输出作为弱监督信号指导校正。为提升识别精度，对LPRNet进行了改进，包括引入注意力模块和使用Focal Loss。实验证明，LPTR-AFLNet在复杂环境下能高效准确地处理车牌畸变和识别，且运行速度快，适用于边缘设备。

> **摘要翻译:** 中文车牌识别（CLPR）在非受限和复杂环境下，尤其由于各种拍摄角度引起的透视畸变以及单行和双行车牌的校正，面临诸多挑战。考虑到边缘设备有限的计算资源，开发一个低复杂度、端到端的集成校正和识别网络对于实现实时高效部署至关重要。在这项工作中，我们提出了一个名为LPTR-AFLNet的轻量级统一网络，用于校正和识别中文车牌，该网络结合了透视变换校正模块（PTR）和优化的车牌识别网络AFLNet。该网络利用识别输出作为弱监督信号，有效地指导校正过程，确保准确的透视畸变校正。为了提高识别精度，我们对LPRNet进行了多项改进，包括引入改进的注意力模块以减少相似字符之间的混淆，以及使用Focal Loss来解决训练期间的类别不平衡问题。实验结果表明LPTR-AFLNet在校正透视畸变和识别双行车牌图像方面表现出色，并在各种挑战性场景中保持高识别精度。此外，在中低端GPU平台上，该方法运行时间少于10毫秒，表明其具有实际效率和广泛适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [Benchmarking pig detection and tracking under diverse and challenging conditions](https://arxiv.org/abs/2507.16639)
> *在多样化和挑战性条件下对猪只检测与跟踪进行基准测试*

*Jonathan Henrich, Christian Post, Maximilian Zilke, Parth Shiroya, Emma Chanut, Amir Mollazadeh Yamchi, Ramin Yahyapour, Thomas Kneib, Imke Traulsen* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 猪只检测, 多目标跟踪, 基准测试, 动物福利, 养猪场

**Comment:** 

> **TL;DR:** 本文创建并基准测试了用于猪只检测和跟踪的新数据集，以促进自动化养猪场的动物监测。

**AI_Comments:** 本文通过构建高质量、多样化且包含挑战性场景的数据集，填补了猪只检测和跟踪领域系统基准测试的空白，这对于推动自动化养猪场的动物监测技术发展具有重要意义。研究结果为模型选择和未来改进提供了实用指导。数据集和代码的公开可用性极大地促进了研究的可重复性和后续发展。

<details>
  <summary>Details</summary>

**Motivation:** 为了确保养猪场的动物福利和有效管理，监测个体行为是至关重要的。传统监测任务是手动进行的，而机器学习的进步使得自动化监测成为可能。然而，尽管在猪只检测和多目标跟踪方面进行了广泛研究，但尚未进行系统的基准测试研究。

**Method:** 作者通过策划两个新数据集来弥补这一空白：用于目标检测的PigDetect和用于多目标跟踪的PigTrack。这些数据集基于真实的猪舍条件下的多样化图像和视频材料，包含遮挡或低能见度等挑战性场景。研究中比较了不同的检测和跟踪方法，包括最先进的模型、实时替代方案、基于SORT的方法和端到端可训练模型。

**Result:** 对于目标检测，挑战性训练图像比随机采样图像能更好地提高检测性能；最先进的模型比实时替代方案显著提高了检测质量。对于多目标跟踪，基于SORT的方法比端到端可训练模型实现了卓越的检测性能，而端到端模型显示出更好的关联性能。模型在未见过的猪圈中表现良好，表明具有良好的泛化能力。研究还调查了端到端模型的特征性失败案例。

**Conclusion:** 高质量的训练数据对于模型性能至关重要。研究结果为未来的模型改进提供了指导。数据集和研究代码已公开提供，以促进可重现性、重用和进一步开发。

> **ai_Abstract:** 本文旨在弥补猪只检测和多目标跟踪领域缺乏系统基准研究的空白。作者构建了两个新的数据集PigDetect和PigTrack，包含了多样化和挑战性的猪舍场景。研究发现，挑战性训练图像能提升检测性能，最先进的模型优于实时模型。在跟踪方面，基于SORT的方法在检测性能上表现更佳，而端到端模型在关联性能上更优，并有可能成为未来替代方案。研究强调了高质量训练数据的重要性，并开源了数据集和代码以促进后续研究。

> **摘要翻译:** 为了确保养猪场的动物福利和有效管理，监测个体行为是至关重要的先决条件。虽然监测任务传统上是手动进行的，但机器学习的进步使得以日益自动化的方式收集个体化信息成为可能。这些方法的核心是跨空间（目标检测）和时间（多目标跟踪）对动物进行定位。尽管在养猪领域对这两项任务进行了广泛研究，但尚未进行系统的基准测试研究。在这项工作中，我们通过整理两个数据集来弥补这一空白：用于目标检测的PigDetect和用于多目标跟踪的PigTrack。这些数据集基于来自真实猪舍条件的多样化图像和视频材料，包括遮挡或能见度差等挑战性场景。对于目标检测，我们展示了具有挑战性的训练图像比单独使用随机采样图像能更好地提高检测性能。比较不同方法，我们发现最先进的模型在检测质量方面比实时替代方案有实质性改进。对于多目标跟踪，我们观察到基于SORT的方法比端到端可训练模型实现了卓越的检测性能。然而，端到端模型显示出更好的关联性能，这表明它们未来可能成为强有力的替代方案。我们还调查了端到端模型的典型失败案例，为未来的改进提供了指导。在我们数据集上训练的检测和跟踪模型在未见过的猪圈中表现良好，表明具有良好的泛化能力。这强调了高质量训练数据的重要性。数据集和研究代码已公开提供，以促进可重现性、重用和进一步开发。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [157] [Explicit Context Reasoning with Supervision for Visual Tracking](https://arxiv.org/abs/2507.16191)
> *用于视觉跟踪的显式上下文推理与监督*

*Fansheng Zeng, Bineng Zhong, Haiying Xia, Yufei Tan, Xiantao Hu, Liangtao Shi, Shuxiang Song* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视觉跟踪, 上下文推理, 监督, 时间一致性, 最先进性能

**Comment:** 

> **TL;DR:** RSTrack通过显式上下文推理和监督，显著提升了视觉跟踪的性能和时间一致性，实现了最先进的成果。

**AI_Comments:** RSTrack的创新之处在于其显式建模和监督上下文推理的方法，这与传统的隐式关联方式形成对比。所提出的三个核心机制提供了一个全面的解决方案，有效提升了视觉跟踪的时间一致性并抑制了跟踪漂移，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 主流视觉跟踪算法在上下文关联时，仅通过堆叠历史信息而非显式监督，导致难以有效建模目标动态，进而影响时间一致性和上下文关联发散。

**Method:** 本文提出了RSTrack算法，通过三个核心机制显式建模和监督上下文推理：1) 上下文推理机制：构建目标状态推理管道，将无约束的上下文关联转换为时间推理，基于历史状态预测当前表示，增强时间一致性。2) 前向监督策略：利用真实目标特征作为锚点约束推理管道，引导预测输出趋向真实目标分布，抑制漂移。3) 高效状态建模：采用压缩-重构机制提取核心特征，去除冗余信息，防止无效关联。

**Result:** 实验结果表明，RSTrack在多个基准数据集上取得了最先进的性能，同时保持了实时运行速度。

**Conclusion:** RSTrack通过显式建模和监督上下文推理，有效缓解了传统时间建模中上下文关联发散的问题，显著提升了视觉跟踪的性能和时间一致性。

> **ai_Abstract:** 本文提出了RSTrack，一种用于视觉跟踪的新算法，旨在解决传统方法中隐式上下文关联的局限性。RSTrack通过上下文推理机制、前向监督策略和高效状态建模，显式地建模和监督上下文推理，增强时间一致性并防止漂移。这种协同设计有效缓解了上下文关联发散问题，使RSTrack在多个基准数据集上实现了最先进的性能和实时运行速度。

> **摘要翻译:** 上下文推理与约束对于增强视觉跟踪中跨帧建模的时间一致性至关重要。然而，主流跟踪算法通常仅通过堆叠历史信息来关联上下文，而没有显式地监督关联过程，这使得有效建模目标演变动态变得困难。为了缓解这个问题，我们提出了RSTrack，它通过三个核心机制显式地建模和监督上下文推理。1) 上下文推理机制：构建目标状态推理管道，将无约束的上下文关联转换为时间推理过程，根据历史目标状态预测当前表示，从而增强时间一致性。2) 前向监督策略：利用真实目标特征作为锚点来约束推理管道，引导预测输出趋向真实目标分布并抑制上下文推理过程中的漂移。3) 高效状态建模：采用压缩-重构机制提取目标的核心特征，去除跨帧冗余信息并防止无效的上下文关联。这三个机制协同作用，有效缓解了传统时间建模中上下文关联发散的问题。实验结果表明，RSTrack在多个基准数据集上取得了最先进的性能，同时保持了实时运行速度。我们的代码可在https://github.com/GXNU-ZhongLab/RSTrack获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [160] [ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2505.17692)
> *ViP$^2$-CLIP：零样本异常检测中的视觉感知提示与统一对齐*

*Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 零样本异常检测, 视觉感知提示, CLIP, 跨领域泛化, 异常分割

**Comment:** 

> **TL;DR:** ViP$^2$-CLIP提出一种视觉感知提示机制（ViP-Prompt），通过融合全局和多尺度局部视觉上下文自适应生成细粒度文本提示，解决了现有零样本异常检测方法中提示工程成本高、语义覆盖有限以及对类别名称敏感的问题，并在15个基准测试中达到了最先进的性能。

**AI_Comments:** 本文提出的ViP-Prompt机制具有创新性，它通过视觉感知而非预设模板或类别名称来生成提示，解决了现有方法在适应复杂异常类型和处理标签模糊性方面的痛点。这对于零样本异常检测的实际应用，尤其是在对隐私敏感的医疗图像等领域，具有重要意义。其SOTA性能和鲁棒的跨域泛化能力也验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于CLIP的零样本异常检测（ZSAD）方法存在问题：手动或静态可学习提示工程成本高、语义覆盖有限，且无法适应复杂的异常类型；CLIP模型对类别名称的敏感性严重限制了提示策略，尤其在异常分割质量方面。

**Method:** 本文提出了ViP$^2$-CLIP模型，其核心是视觉感知提示（ViP-Prompt）机制。该机制融合了全局和多尺度的局部视觉上下文，以自适应地生成细粒度的文本提示，从而消除了对手动模板和类别名称先验的依赖。这种设计使模型能够专注于精确的异常区域。

**Result:** ViP$^2$-CLIP在15个工业和医疗基准测试中取得了最先进的性能和强大的跨领域泛化能力。

**Conclusion:** ViP$^2$-CLIP通过引入视觉感知提示机制，有效解决了零样本异常检测中提示工程的挑战和CLIP对类别标签的敏感性问题，实现了卓越的性能和跨领域泛化能力，尤其适用于类别标签模糊或受隐私限制的场景。

> **ai_Abstract:** ViP$^2$-CLIP提出一种针对零样本异常检测的新方法，通过引入视觉感知提示（ViP-Prompt）机制，克服了现有CLIP基方法中手动/静态提示的局限性以及CLIP对类别名称的敏感性。ViP-Prompt融合全局和多尺度局部视觉上下文，自适应生成细粒度文本提示，从而精准定位异常区域。该方法在工业和医疗领域的15个基准测试中展现出最先进的性能和强大的跨领域泛化能力。

> **摘要翻译:** 零样本异常检测（ZSAD）旨在无需任何目标域训练样本的情况下检测异常，仅依赖外部辅助数据。现有的基于CLIP的方法试图通过手工制作或静态可学习的提示来激活模型的ZSAD潜力。前者导致高昂的工程成本和有限的语义覆盖，而后者在不同异常类型之间应用相同的描述，因此无法适应复杂的变异。此外，由于CLIP最初是在大规模分类任务上预训练的，其异常分割质量对类名称的确切措辞高度敏感，严重限制了依赖类标签的提示策略。为了应对这些挑战，我们引入了ViP$^{2}$-CLIP。ViP$^{2}$-CLIP的关键思想是一种视觉感知提示（ViP-Prompt）机制，它融合了全局和多尺度局部视觉上下文，以自适应地生成细粒度文本提示，从而消除了手动模板和类名称先验。这种设计使我们的模型能够专注于精确的异常区域，这在类别标签模糊或受隐私限制时尤其有价值。在15个工业和医疗基准测试中进行的广泛实验表明，ViP$^{2}$-CLIP实现了最先进的性能和强大的跨领域泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [161] [Local Dense Logit Relations for Enhanced Knowledge Distillation](https://arxiv.org/abs/2507.15911)
> *局部密集Logit关系用于增强知识蒸馏*

*Liuchi Xu, Kang Liu, Jinshuai Liu, Lu Wang, Lisheng Xu, Jun Cheng* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 知识蒸馏, Logit关系, 细粒度知识, 自适应权重, 类间关系

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了一种名为局部密集关系Logit蒸馏（LDRLD）的新方法，通过递归解耦和重组Logit信息来捕获细粒度的类间关系，并引入自适应衰减权重（ADW）策略优化性能，实验证明其优于现有Logit蒸馏方法。

**AI_Comments:** 该论文的创新之处在于其对Logit知识中细粒度关系进行深入探索，并提出了递归解耦和重组Logit信息的新颖方法。同时，自适应衰减权重（ADW）策略及其包含的逆序加权（IRW）和指数秩衰减（ERD）为关键类别对的权重调整提供了动态且精细的机制，这可能有助于更有效地传递教师模型的知识。该方法强调了细粒度知识和关键关系的传递，为知识蒸馏领域提供了一个新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Logit蒸馏方法取得了进展，但现有研究尚未深入探讨Logit知识中的细粒度关系。

**Method:** 本文提出了局部密集关系Logit蒸馏（LDRLD）方法，通过递归解耦和重组Logit信息来捕获类间关系。为优化性能，引入了自适应衰减权重（ADW）策略，该策略利用逆序加权（IRW）和指数秩衰减（ERD）动态调整关键类别对的权重。此外，在递归解耦后，还蒸馏了剩余的非目标知识以确保知识完整性。

**Result:** 在CIFAR-100、ImageNet-1K和Tiny-ImageNet等数据集上进行的广泛实验表明，该方法与最先进的基于Logit的蒸馏方法相比表现更优。

**Conclusion:** 该方法通过传递细粒度知识并强调最关键的关系，从而提高了学生模型的性能。

> **ai_Abstract:** 本文提出了一种新颖的知识蒸馏方法——局部密集关系Logit蒸馏（LDRLD），旨在解决现有Logit蒸馏未能充分探索细粒度Logit关系的问题。LDRLD通过递归解耦和重组Logit信息来捕捉类间关系，并引入自适应衰减权重（ADW）策略，结合逆序加权（IRW）和指数秩衰减（ERD）动态调整关键类别对的权重。此外，该方法还蒸馏非目标知识以增强性能和知识完整性。实验结果表明，LDRLD在多个数据集上优于现有最先进的Logit蒸馏方法。

> **摘要翻译:** 最先进的Logit蒸馏方法表现出多功能性、简单性和效率。尽管取得了进展，但现有研究尚未深入探讨Logit知识中的细粒度关系。在本文中，我们提出了局部密集关系Logit蒸馏（LDRLD），这是一种通过递归解耦和重组Logit信息来捕获类间关系的新方法，从而为学生学习提供更详细和清晰的见解。为了进一步优化性能，我们引入了一种自适应衰减权重（ADW）策略，该策略可以使用逆序加权（IRW）和指数秩衰减（ERD）动态调整关键类别对的权重。具体而言，IRW根据对之间的秩差成反比分配权重，而ERD根据类别对的总排名分数自适应地控制权重衰减。此外，在递归解耦后，我们蒸馏了剩余的非目标知识，以确保知识的完整性并提高性能。最终，我们的方法通过传递细粒度知识并强调最关键的关系，从而提高了学生模型的性能。在CIFAR-100、ImageNet-1K和Tiny-ImageNet等数据集上进行的广泛实验表明，我们的方法与最先进的基于Logit的蒸馏方法相比表现更优。代码将公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [168] [STAR: A Benchmark for Astronomical Star Fields Super-Resolution](https://arxiv.org/abs/2507.16385)
> *STAR：一个用于天文星场超分辨率的基准*

*Kuo-Cheng Wu, Guohang Zhuang, Jinyang Huang, Xiang Zhang, Wanli Ouyang, Yan Lu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 天文超分辨率, 数据集, 通量一致性, STAR, FISR

**Comment:** 

> **TL;DR:** 该研究提出了STAR，一个大规模、通量一致的天文超分辨率（ASR）数据集，旨在解决现有ASR数据集的局限性。同时，提出了一种通量不变超分辨率（FISR）模型，并在新的通量一致性指标上显著优于现有最先进方法。

**AI_Comments:** 这项工作的创新之处在于创建了一个大规模、通量一致的专门用于天文超分辨率的数据集，这对于需要精确通量保留的天体物理分析至关重要。新评估指标（FE）的引入以及针对通量不变性设计的模型（FISR）直接解决了先前工作的一个主要限制，这使得它对天文成像社区具有高度重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有天文超分辨率（ASR）数据集存在通量不一致、目标裁剪设置和数据多样性不足等关键限制，严重阻碍了ASR的发展。高质量、高分辨率的天文图像对于探测遥远天体和精确结构分析至关重要。

**Method:** 研究提出了STAR，一个包含54,738对通量一致的星场图像对的大规模天文SR数据集。这些图像对结合了哈勃空间望远镜的高分辨率观测结果和通过通量保持数据生成管道生成的物理忠实的低分辨率对应物。为评估SR模型，STAR还提供了一种新颖的通量误差（FE）指标。在此基准上，提出了一种通量不变超分辨率（FISR）模型。

**Result:** FISR模型能够从输入光度学中准确推断出通量一致的高分辨率图像，并在新设计的通量一致性指标上，其性能优于几种最先进的SR方法24.84%。大量实验证明了所提出方法和数据集的有效性。

**Conclusion:** 所提出的STAR数据集和FISR模型有效解决了当前ASR数据集和方法的局限性，为天文超分辨率提供了一个有价值的基准和卓越的模型。

> **ai_Abstract:** 本文介绍了STAR，一个大规模、通量一致的天文超分辨率（ASR）数据集，包含54,738对星场图像，这些图像通过通量保持管道从哈勃空间望远镜数据生成，旨在解决现有ASR数据集在通量一致性和数据多样性方面的局限性。论文还提出了一种新的评估指标——通量误差（FE），以及一个通量不变超分辨率（FISR）模型。FISR在通量一致性方面显著优于现有最先进方法，证明了其在天体物理学中的有效性。

> **摘要翻译:** 超分辨率（SR）通过实现经济高效的高分辨率捕获来推动天文成像发展，这对于探测遥远天体和精确结构分析至关重要。然而，现有的天文超分辨率（ASR）数据集存在三个关键限制：通量不一致、目标裁剪设置和数据多样性不足，这严重阻碍了ASR的发展。我们提出了STAR，一个大规模的天文SR数据集，包含54,738对通量一致的星场图像对，覆盖了广泛的天体区域。这些图像对结合了哈勃空间望远镜的高分辨率观测结果和通过通量保持数据生成管道生成的物理忠实的低分辨率对应物，从而能够系统地开发场级ASR模型。为了进一步赋能ASR社区，STAR提供了一种新颖的通量误差（FE）来从物理角度评估SR模型。利用这个基准，我们提出了一种通量不变超分辨率（FISR）模型，该模型可以从输入光度学中准确推断出通量一致的高分辨率图像，在一种新设计的通量一致性指标上，其性能优于几种最先进的SR方法24.84%，显示了我们方法在天体物理学中的优先性。大量实验证明了我们提出的方法和数据集的有效性。代码和模型可在https://github.com/GuoCheng12/STAR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [170] [EmotiCrafter: Text-to-Emotional-Image Generation based on Valence-Arousal Model](https://arxiv.org/abs/2501.05710)
> *EmotiCrafter：基于效价-唤醒模型的文本到情感图像生成*

*Shengqi Dang, Yi He, Long Ling, Ziqing Qian, Nanxuan Zhao, Nan Cao* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 情感图像生成, 效价-唤醒模型, 文本到图像, 连续情感, EmotiCrafter

**Comment:** 11 pages, 9 figures

> **TL;DR:** EmotiCrafter是一个新的文本到情感图像生成模型，它使用效价-唤醒（VA）值来创建具有特定情感和内容的图像，解决了现有方法在捕捉情感细微差别和控制图像内容方面的局限性。

**AI_Comments:** EmotiCrafter的创新之处在于其将连续的效价-唤醒模型引入文本到图像生成，这比传统的离散情感类别更能捕捉情感的细微差别。此外，它解决了现有方法在生成图像内容控制上的不足，使得用户能更精确地通过文本提示和情感值来定制图像。这项工作对于提升人机交互和内容创作领域的表现力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在视觉情感分析方面广泛，但在帮助用户生成情感丰富的图像内容方面工作有限。现有情感图像生成方法依赖离散情感类别，难以准确捕捉复杂和微妙的情感细微差别，并且难以根据文本提示控制生成图像的具体内容。

**Method:** 引入了连续情感图像内容生成（C-EICG）的新任务，并提出了EmotiCrafter模型。该模型通过文本提示和效价-唤醒（Valence-Arousal）值生成图像。具体地，提出了一种新颖的情感嵌入映射网络，将效价-唤醒值嵌入到文本特征中，以捕获与预期输入提示对齐的特定情感。此外，引入了一个损失函数来增强情感表达。

**Result:** 实验结果表明，该方法能有效生成具有特定情感和所需内容的图像，并且优于现有技术。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** EmotiCrafter是一个创新的文本到情感图像生成模型，旨在解决现有方法在捕捉情感细微差别和内容控制方面的不足。该模型引入了连续情感图像内容生成（C-EICG）任务，并利用效价-唤醒（Valence-Arousal）模型，通过一个新颖的情感嵌入映射网络将情感值融入文本特征，并结合新的损失函数来增强情感表达。实验证明，EmotiCrafter能够有效生成具有指定情感和内容的图像，并优于现有技术。

> **摘要翻译:** 最近的研究表明，情感可以增强用户的认知并影响信息交流。尽管视觉情感分析的研究很广泛，但在帮助用户生成情感丰富的图像内容方面的工作却很有限。现有情感图像生成工作依赖于离散的情感类别，这使得准确捕捉复杂和微妙的情感细微差别变得具有挑战性。此外，这些方法难以根据文本提示控制生成图像的具体内容。在这项工作中，我们引入了连续情感图像内容生成（C-EICG）的新任务，并提出了EmotiCrafter，一个基于文本提示和效价-唤醒值生成图像的情感图像生成模型。具体地，我们提出了一种新颖的情感嵌入映射网络，将效价-唤醒值嵌入到文本特征中，从而能够捕获与预期输入提示对齐的特定情感。此外，我们引入了一个损失函数来增强情感表达。实验结果表明，我们的方法有效地生成了代表特定情感和所需内容的图像，并且优于现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [179] [Synthetic Data Matters: Re-training with Geo-typical Synthetic Labels for Building Detection](https://arxiv.org/abs/2507.16657)
> *合成数据很重要：使用地理典型合成标签进行建筑物检测的再训练*

*Shuang Song, Yang Tang, Rongjun Qin* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 合成数据, 建筑物检测, 域适应, 遥感, 地理典型数据

**Comment:** 14 pages, 5 figures, This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 本文提出了一种利用针对目标区域定制的地理典型合成数据在测试时重新训练模型的方法，以提高遥感建筑物分割的泛化能力，并显著提升了性能。

**AI_Comments:** 该论文的创新之处在于提出了在测试时利用地理典型合成数据进行模型再训练的策略，有效解决了遥感图像中建筑物分割模型泛化能力差和标注数据稀缺的问题。通过结合地理空间数据生成定制化的合成数据和域适应技术，它提供了一种成本效益高且实用的方法来弥补合成-真实域差距，有望解决纯合成数据训练中可能出现的“模型崩溃”问题。该方法对于数据稀缺领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在遥感建筑物分割方面取得了显著进展，但模型难以泛化到不同地理区域的数据，原因是城市布局和建筑物类型、大小、分布存在差异。然而，用于捕捉全球多样性的耗时标注数据可能永远无法满足数据饥渴模型的需求。

**Method:** 本文提出了一种新颖的方法：在测试时使用针对目标区域城市布局定制的合成数据重新训练模型。该方法利用OpenStreetMap等地理空间数据生成紧密复制目标区域城市结构的地理典型合成数据。通过程序建模和基于物理的渲染，创建了超高分辨率的合成图像，并融入了建筑物形状、材料和环境照明的域随机化。为了克服合成到真实域的差距，该方法将地理典型数据集成到对抗性域适应框架中，用于建筑物分割。

**Result:** 实验表明性能显著增强，中位数提升高达12%，具体取决于域差距。该方法解决了纯合成数据集中“模型崩溃”的问题。

**Conclusion:** 该可扩展且经济高效的方法将部分地理知识与合成图像相结合，为遥感建筑物分割中提高泛化能力提供了一条实用途径，而无需大量的真实世界标注。

> **ai_Abstract:** 本文提出了一种在测试时利用地理典型合成数据重新训练深度学习模型的新方法，以克服遥感建筑物分割中模型泛化能力差的问题。该方法通过利用地理空间数据生成高分辨率、域随机化的合成图像，并结合对抗性域适应框架，有效弥补了合成与真实数据之间的域差距。实验证明，该方法显著提升了模型性能，为在缺乏大量真实标注数据的情况下提高模型泛化能力提供了一个可扩展且经济高效的解决方案。

> **摘要翻译:** 深度学习在遥感建筑物分割方面取得了显著进展，但由于城市布局以及建筑物类型、大小和分布的变化，模型难以在不同地理区域的数据上进行泛化。然而，用于捕捉全球多样性的耗时标注数据可能永远无法满足数据饥渴模型的需求。因此，我们提出了一种新颖的方法：在测试时使用针对目标区域城市布局定制的合成数据重新训练模型。该方法利用OpenStreetMap等地理空间数据生成紧密复制目标区域城市结构的地理典型合成数据。通过程序建模和基于物理的渲染，创建了超高分辨率的合成图像，并融入了建筑物形状、材料和环境照明的域随机化。这使得能够生成几乎无限的训练样本，同时保持目标环境的基本特征。为了克服合成到真实域的差距，我们的方法将地理典型数据集成到对抗性域适应框架中，用于建筑物分割。实验表明性能显著增强，中位数提升高达12%，具体取决于域差距。这种可扩展且经济高效的方法将部分地理知识与合成图像相结合，为纯合成数据集中“模型崩溃”问题提供了有希望的解决方案。它为在不进行大量真实世界标注的情况下提高遥感建筑物分割的泛化能力提供了一条实用途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [193] [From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure](https://arxiv.org/abs/2507.16389)
> *从平面到圆形：用基于表面的fMRI和皮层结构重新定义大脑解码*

*Sijin Yu, Zijiao Chen, Wenxuan Wu, Shengxian Chen, Zhongliang Liu, Jingxin Nie, Xiaofen Xing, Xiangmin Xu, Xin Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 脑解码, fMRI, 皮层结构, 视觉刺激重建, 球形建模

**Comment:** 18 pages, 14 figures, ICCV Findings 2025

> **TL;DR:** 本文提出一种新的基于皮层表面的fMRI大脑解码方法，通过球形分词器、整合结构MRI数据和正样本混合策略，显著提高了视觉刺激重建的准确性、生物学可解释性和个体泛化能力。

**AI_Comments:** 该论文通过将fMRI信号从传统的扁平化处理转变为更符合生物学实际的皮层表面球形建模，并引入个体结构MRI数据进行个性化编码，极大地提升了大脑解码的准确性、可解释性和泛化性。其创新性在于对脑结构-功能关系的深度考量和利用，为神经解码领域提供了新的视角和有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大脑解码方法忽视了关键的脑结构-功能关系，扁平化了空间信息，并忽略了个体解剖变异，导致重建准确性、生物学可解释性和泛化能力不足。

**Method:** 本文提出：1) 一种新颖的球形分词器，将fMRI信号建模为皮层表面上空间连贯的2D球形数据；2) 整合结构MRI (sMRI) 数据，实现个体解剖变异的个性化编码；3) 一种正样本混合策略，用于有效利用与相同视觉刺激相关的多个fMRI扫描。

**Result:** 实验表明，与现有最先进的方法相比，该方法在视觉刺激重建性能上表现出卓越的优势。

**Conclusion:** 本文提出的生物学知情方法有效且可解释，通过增强重建准确性、生物学可解释性和个体间的泛化性，重新定义了大脑解码。

> **ai_Abstract:** 本文提出一种创新的大脑解码框架，通过将fMRI信号建模为皮层表面上的2D球形数据，并整合个体结构MRI信息，有效利用多扫描数据，解决了传统方法忽视脑结构和个体解剖差异的问题。实验结果表明，该方法在视觉刺激重建方面显著优于现有技术，同时提升了模型的准确性、生物学可解释性和跨个体泛化能力。

> **摘要翻译:** 从人类大脑活动（例如fMRI）重建视觉刺激，通过解码神经表征，连接了神经科学和计算机视觉。然而，现有方法常常忽视关键的脑结构-功能关系，扁平化了空间信息并忽略了个体解剖变异。为了解决这些问题，我们提出：(1) 一种新颖的球形分词器，明确地将fMRI信号建模为皮层表面上空间连贯的2D球形数据；(2) 整合结构MRI (sMRI) 数据，实现个体解剖变异的个性化编码；以及 (3) 一种正样本混合策略，用于有效利用与相同视觉刺激相关的多个fMRI扫描。总的来说，这些创新增强了重建准确性、生物学可解释性和个体间的泛化性。实验表明，与SOTA方法相比，该方法具有卓越的重建性能，突出了我们这种生物学知情方法的有效性和可解释性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [195] [MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm](https://arxiv.org/abs/2502.02358)
> *MotionLab：基于运动-条件-运动范式的人体运动生成与编辑统一框架*

*Ziyan Guo, Zeyu Hu, De Wen Soh, Na Zhao* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 人体运动生成, 运动编辑, 统一框架, 运动-条件-运动, MotionLab

**Comment:** Accepted by ICCV 2025

> **TL;DR:** MotionLab 提出了一个统一的“运动-条件-运动”范式，用于同时进行人体运动的生成和编辑，解决了现有方法孤立、缺乏编辑能力和知识共享的问题。

**AI_Comments:** MotionLab 的创新之处在于提出了“运动-条件-运动”这一统一范式，有效地将人体运动的生成和编辑任务整合到单一框架中，解决了现有方法孤立、缺乏编辑和控制能力的问题。通过引入整流流、MotionFlow Transformer 和运动课程学习等技术，该工作不仅提升了模型的多任务处理能力和泛化性，还促进了任务间的知识共享，这对于计算机视觉领域的人体运动研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前人体运动生成和编辑方法倾向于提供针对特定任务的孤立解决方案，效率低下且不实用。尽管有些努力旨在统一运动相关任务，但它们仅使用不同模态作为条件来指导运动生成，缺乏编辑能力、细粒度控制，并且未能促进任务间的知识共享。

**Method:** 本文提出了一个新颖的“运动-条件-运动”范式，通过源运动、条件和目标运动三个概念统一表述各种任务。基于此范式，提出了统一框架MotionLab，该框架结合了整流流（rectified flows）来学习从源运动到目标运动的映射，并由指定条件引导。MotionLab中引入了：1) MotionFlow Transformer以增强条件生成和编辑，无需特定任务模块；2) 对齐旋转位置编码（Aligned Rotational Position Encoding）以保证源运动和目标运动之间的时间同步；3) 任务特定指令调制（Task Specified Instruction Modulation）；4) 运动课程学习（Motion Curriculum Learning）以实现有效的多任务学习和任务间的知识共享。

**Result:** MotionLab 在人体运动的多个基准测试中展示了良好的泛化能力和推理效率。

**Conclusion:** MotionLab 成功地提出了一个统一的框架，通过“运动-条件-运动”范式解决了人体运动生成和编辑中现有方法的局限性，实现了多任务的统一处理和知识共享，并展现出优异的性能。

> **ai_Abstract:** MotionLab 提出了一个名为“运动-条件-运动”的新颖范式，旨在统一解决人体运动的生成和编辑任务。该范式通过定义源运动、条件和目标运动，使得不同任务得以统一表述。基于此，论文构建了 MotionLab 框架，利用整流流学习运动映射，并集成了 MotionFlow Transformer、对齐旋转位置编码、任务特定指令调制和运动课程学习等关键组件，以实现高效的条件生成、编辑、时间同步、多任务学习及知识共享。实验表明，MotionLab 在多个基准测试中展现出卓越的泛化能力和推理效率。

> **摘要翻译:** 人体运动的生成和编辑是计算机视觉的关键组成部分。然而，该领域当前的方法倾向于提供针对特定任务的孤立解决方案，这对于实际应用来说效率低下且不实用。尽管一些努力旨在统一运动相关任务，但这些方法只是简单地使用不同的模态作为条件来指导运动生成。因此，它们缺乏编辑能力、细粒度控制，并且未能促进任务间的知识共享。为了解决这些限制并提供一个能够处理人体运动生成和编辑的多功能统一框架，我们引入了一个新颖的范式：\textbf{运动-条件-运动}，它通过三个概念：源运动、条件和目标运动，实现了各种任务的统一表述。基于此范式，我们提出了一个统一框架\textbf{MotionLab}，它结合了整流流（rectified flows）来学习从源运动到目标运动的映射，并由指定的条件引导。在MotionLab中，我们引入了1) MotionFlow Transformer，以在没有特定任务模块的情况下增强条件生成和编辑；2) 对齐旋转位置编码（Aligned Rotational Position Encoding），以保证源运动和目标运动之间的时间同步；3) 任务特定指令调制（Task Specified Instruction Modulation）；以及4) 运动课程学习（Motion Curriculum Learning），用于有效的多任务学习和任务间的知识共享。值得注意的是，我们的MotionLab在人体运动的多个基准测试中展示了良好的泛化能力和推理效率。我们的代码和附加视频结果可在以下网址获取：https://diouo.github.io/motionlab.github.io/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [201] [An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique](https://arxiv.org/abs/2507.15915)
> *利用预训练CNN模型和XAI技术对皮肤病变图像进行猴痘早期检测的实证研究*

*Mohammad Asifur Rahim, Muhammad Nazmul Arefin, Md. Mizanur Rahman, Md Ali Hossain, Ahmed Moustafa* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 猴痘, CNN, XAI, 早期检测, 皮肤病变

**Comment:** 

> **TL;DR:** 本研究评估了预训练CNN模型（如InceptionV3和MobileNetV2）结合XAI技术（Grad-CAM）在皮肤病变图像上早期检测猴痘的有效性，并取得了高准确率，同时揭示了模型的可解释性。

**AI_Comments:** 该研究创新性地结合了预训练CNN模型和XAI技术，用于早期猴痘检测，这对于提高诊断效率和模型透明度具有重要意义。通过量化不同模型的性能，并利用Grad-CAM进行可视化解释，增加了结果的可信度。然而，论文也坦诚地指出了模型的过拟合倾向和数据集的潜在局限性，为未来的研究方向提供了明确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 猴痘是一种人畜共患病，其皮肤病变与其他皮肤病相似，导致早期准确诊断具有挑战性。尽管人工智能特别是深度学习在医学图像分析中表现强大，但预训练模型如CNN和XAI技术在猴痘检测方面的应用尚未得到充分探索。

**Method:** 研究使用了MSLD和MSLD v2.0两个数据集进行训练和验证。采用迁移学习技术，通过冻结初始层并添加自定义层来微调预训练的CNN模型（VGG16、VGG19、InceptionV3、MobileNetV2），以适应猴痘检测任务并避免过拟合。模型性能通过准确率、精确率、召回率、F1分数和ROC曲线进行评估。Grad-CAM被用于可视化关键特征。

**Result:** InceptionV3在二分类数据集上表现最佳，准确率达到95%。MobileNetV2在多分类数据集上表现出色，准确率达到93%。Grad-CAM成功突出了图像的关键区域。尽管准确率很高，但一些模型显示出过拟合倾向，这通过训练和验证损失之间的差异得到证实。

**Conclusion:** 本研究强调了预训练CNN模型在猴痘检测中的潜力以及XAI技术的价值。未来的工作应解决数据集限制，整合多模态数据，并探索额外的可解释性技术以提高诊断可靠性和模型透明度。

> **ai_Abstract:** 本研究旨在通过皮肤病变图像，利用迁移学习和可解释人工智能（XAI）技术，对预训练的卷积神经网络（CNN）模型（如VGG16、VGG19、InceptionV3和MobileNetV2）进行评估，以实现猴痘的早期检测。研究使用MSLD和MSLD v2.0数据集，并利用Grad-CAM增强模型可解释性。结果显示，InceptionV3和MobileNetV2在不同数据集上取得了95%和93%的高准确率，证明了预训练CNN模型在猴痘检测中的潜力，并强调了XAI技术在提高模型透明度方面的价值。研究也指出了模型存在过拟合的倾向，并建议未来工作解决数据集限制和探索多模态数据。

> **摘要翻译:** 背景：猴痘是一种由猴痘病毒引起的人畜共患病，其与其它皮肤病症状相似，使得早期准确诊断具有挑战性。人工智能（AI），尤其是深度学习（DL），在医学图像分析中是一种强大的工具；然而，预训练模型如CNN和用于猴痘检测的XAI技术尚未得到充分探索。目的：本研究旨在评估预训练CNN模型（VGG16、VGG19、InceptionV3、MobileNetV2）在使用二分类和多分类数据集进行猴痘早期检测时的有效性。它还旨在利用Grad-CAM这一XAI技术增强模型的可解释性。方法：MSLD和MSLD v2.0两个数据集被用于训练和验证。应用迁移学习技术，通过冻结初始层并添加自定义层来微调预训练的CNN模型，以适应猴痘检测任务并避免过拟合。模型性能通过准确率、精确率、召回率、F1分数和ROC等指标进行评估。Grad-CAM被用于可视化关键特征。结果：InceptionV3在二分类数据集上表现最佳，准确率达到95%，而MobileNetV2在多分类数据集上表现出色，准确率达到93%。Grad-CAM成功突出了图像的关键区域。尽管准确率很高，但一些模型显示出过拟合倾向，这通过训练和验证损失之间的差异得到证实。结论：本研究强调了预训练CNN模型在猴痘检测中的潜力以及XAI技术的价值。未来的工作应解决数据集限制，整合多模态数据，并探索额外的可解释性技术以提高诊断可靠性和模型透明度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [202] [LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs](https://arxiv.org/abs/2507.16193)
> *LMM4Edit：基于大型多模态模型（LMM）的多模态图像编辑基准测试与评估*

*Zitong Xu, Huiyu Duan, Bingnan Liu, Guangji Ma, Jiarui Wang, Liu Yang, Shiqi Gao, Xiaoyu Wang, Jia Wang, Xiongkuo Min, Guangtao Zhai, Weisi Lin* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-22**

**Keywords:** 图像编辑, 大型多模态模型, 评估基准, 人类偏好, LMM4Edit

**Comment:** 

> **TL;DR:** 本文提出了EBench-18K，一个大规模图像编辑基准数据集，并基于此提出了LMM4Edit，一个基于LMM的图像编辑评估指标，该指标与人类偏好高度一致且泛化能力强。

**AI_Comments:** 本文的创新点在于构建了首个大规模、包含细粒度人类偏好标注的图像编辑评估基准EBench-18K，并基于此开发了LMM4Edit这一新型LMMs驱动的评估指标。LMM4Edit克服了传统指标的局限性，能够更全面、准确地反映图像编辑效果，并与人类感知高度对齐，这对于推动文本引导图像编辑技术的发展及其在实际应用中的落地具有重要意义。其泛化能力也预示了其广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 当前的文本引导图像编辑（TIE）模型在图像质量、编辑对齐和与原始图像的一致性方面难以平衡，限制了其实际应用。此外，现有的TIE评估基准和指标在规模或与人类感知的对齐方面存在局限性。

**Method:** 我们引入了EBench-18K，这是第一个大规模图像编辑基准数据集，包含18K张编辑过的图像和细粒度的人类偏好标注。基于EBench-18K，我们利用杰出的LMMs评估编辑过的图像，并在此基础上提出了LMM4Edit，一个基于LMM的图像编辑评估指标，它从感知质量、编辑对齐、属性保留和任务特定QA准确性等方面进行一体化评估。

**Result:** 大量实验表明，LMM4Edit取得了出色的性能，并与人类偏好高度一致。在其他数据集上的零样本验证也显示了我们模型的泛化能力。

**Conclusion:** LMM4Edit作为一种基于LMM的图像编辑评估指标，在多个维度上表现出色，并与人类偏好高度对齐，同时具有良好的泛化能力，为多模态图像编辑的评估提供了有效工具。

> **ai_Abstract:** 本文针对当前文本引导图像编辑（TIE）模型在质量、对齐和一致性方面的不足以及现有评估基准的局限性，提出了EBench-18K，一个包含18K张编辑图像和细粒度人类偏好标注的大规模TIE评估基准。基于EBench-18K，研究者进一步提出了LMM4Edit，一个基于大型多模态模型（LMM）的综合评估指标，能够从感知质量、编辑对齐、属性保留和任务特定QA准确性等多个维度评估图像编辑模型。实验证明LMM4Edit性能优异，与人类偏好高度一致，并具有良好的泛化能力。

> **摘要翻译:** 文本引导图像编辑（TIE）的快速发展使得通过文本提示修改图像成为可能。然而，当前的TIE模型在平衡图像质量、编辑对齐和与原始图像的一致性方面仍然面临挑战，这限制了它们的实际应用。现有的TIE评估基准和指标在规模或与人类感知的对齐方面存在局限性。为此，我们引入了EBench-18K，这是第一个大规模图像编辑基准，包含18K张经过编辑的图像，并附有细粒度的人类偏好标注，用于评估TIE。具体而言，EBench-18K包括1,080张源图像及其对应的21个任务的编辑提示，由17个最先进的TIE模型生成的18K+张编辑图像，从三个评估维度评估的55K+平均意见分数（MOSs），以及18K+问答（QA）对。基于EBench-18K，我们采用杰出的LMMs来评估编辑过的图像，而评估结果反过来也提供了评估LMMs理解能力与人类偏好之间对齐程度的见解。然后，我们提出了LMM4Edit，一个基于LMM的指标，用于从感知质量、编辑对齐、属性保留和任务特定QA准确性等方面一体化评估图像编辑模型。大量的实验表明LMM4Edit取得了出色的性能并与人类偏好高度一致。在其他数据集上的零样本验证也显示了我们模型的泛化能力。数据集和代码可在https://github.com/IntMeGroup/LMM4Edit获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [209] [QRetinex-Net: Quaternion-Valued Retinex Decomposition for Low-Level Computer Vision Applications](https://arxiv.org/abs/2507.16683)
> *QRetinex-Net：用于低级计算机视觉应用的四元数Retinex分解*

*Sos Agaian, Vladimir Frants* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 四元数Retinex, 低光图像增强, 计算机视觉, 颜色恒常性, 图像分解

**Comment:** 

> **TL;DR:** 本文提出了首个四元数Retinex公式QRetinex-Net，通过将场景表示为四元数值反射率和照明的哈密顿积，解决了传统Retinex模型在低光图像处理中的缺陷，并在多项低级视觉任务中取得了显著性能提升和更好的色彩稳定性。

**AI_Comments:** 该论文的创新点在于首次将四元数引入Retinex理论，以解决传统方法独立处理RGB通道的局限性，并更好地模拟人眼颜色感知机制。其提出的四元数Retinex公式和反射率一致性指数，为低光图像增强和计算机视觉任务提供了新的视角和有效工具。在多项应用中取得的性能提升，凸显了该方法的实用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 低光图像存在色彩偏移、对比度低、噪声等问题，影响计算机视觉准确性。传统的Retinex模型存在四个主要缺陷：独立处理RGB通道、缺乏神经科学颜色视觉模型、无法完美重建输入图像以及未能解释人类颜色恒常性。

**Method:** 引入了首个四元数Retinex公式，将场景表示为四元数值反射率和照明的哈密顿积。提出了反射率一致性指数来衡量反射率的不变性。

**Result:** 在低光裂纹检测、不同光照下的面部检测以及红外-可见光融合任务中，比领先方法提升了2-11%，并实现了更好的色彩保真度、更低的噪声和更高的反射率稳定性。

**Conclusion:** 本文提出的四元数Retinex公式QRetinex-Net有效解决了传统Retinex模型的局限性，显著提升了低级计算机视觉应用在低光条件下的图像质量和性能，尤其在色彩保真度和反射率稳定性方面表现突出。

> **ai_Abstract:** 本文针对低光图像中存在的色彩偏移、低对比度和噪声等问题，提出了一种新颖的四元数Retinex分解方法QRetinex-Net，以克服传统Retinex模型独立处理颜色通道、缺乏神经科学模型、重建不完美及无法解释颜色恒常性等缺陷。该方法将场景表示为四元数反射率和照明的哈密顿积，并引入反射率一致性指数。实验结果表明，QRetinex-Net在低光裂纹检测、面部检测和红外-可见光融合等低级计算机视觉任务中，性能比现有方法提升了2-11%，并展现出更优的色彩保真度、更低的噪声和更高的反射率稳定性。

> **摘要翻译:** 低光下拍摄的图像通常会显示色彩偏移、低对比度、噪声和其他影响计算机视觉准确性的伪影。Retinex理论通过将图像S视为反射率R和照明I的像素乘积来解决这个问题，这反映了人们在光线变化下感知稳定物体颜色的方式。这种分解是一个不适定问题，经典的Retinex模型有四个关键缺陷：(i) 它们独立处理红色、绿色和蓝色通道；(ii) 它们缺乏颜色视觉的神经科学模型；(iii) 它们无法完美重建输入图像；(iv) 它们无法解释人类颜色恒常性。我们引入了第一个四元数Retinex公式，其中场景被写成四元数值反射率和照明的哈密顿积。为了衡量反射率保持不变的程度，我们提出了反射率一致性指数。在低光裂纹检测、不同光照下的面部检测以及红外-可见光融合方面的测试显示，比领先方法提高了2-11%，并具有更好的色彩保真度、更低的噪声和更高的反射率稳定性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [218] [Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?](https://arxiv.org/abs/2507.16393)
> *基础模型是零样本人脸演示攻击检测的全部所需吗？*

*Lazaro Janier Gonzalez-Sole, Juan E. Tapia, Christoph Busch* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 基础模型, 零样本学习, 人脸演示攻击检测, 泛化能力, 深度学习

**Comment:** Accepted at FG 2025

> **TL;DR:** 本文探讨了基础模型在零样本人脸演示攻击检测中的有效性，并提出一个简单而有效的框架，实验表明基础模型在困难场景下表现优异，超越了现有技术。

**AI_Comments:** 这篇论文的创新点在于探索了基础模型在零样本人脸演示攻击检测（PAD）领域的应用。考虑到现有PAD方法对大量数据和泛化能力的需求，使用基础模型来解决零样本问题是一个重要且有前景的方向。其优势在于基础模型可能具备更强的泛化能力，从而在面对未知攻击类型时表现更好。这对于提高人脸识别系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸识别系统容易受到攻击演示（AP）的威胁，恶意行为者可以冒充授权主体。当前的深度学习演示攻击检测（PAD）方法需要大量数据才能获得可靠性能，并且在面对未知攻击工具（PAI）或未见过的数据集时，泛化能力差，性能会下降。为了解决这些问题，本文专注于零样本PAD。

**Method:** 本文首先评估了基础模型在现有和具有挑战性的实验场景中对零样本PAD的有效性和泛化能力，然后提出了一个简单但有效的零样本PAD框架。

**Result:** 实验结果表明，基础模型在困难场景下能以最小的努力实现良好的性能，甚至超越了更先进的PAD机制。在SiW-Mv2数据库上使用留一法协议进行观察，表现最佳的基础模型在检测具有挑战性的未知2D和3D攻击方面，明显优于现有技术中的最佳模型。

**Conclusion:** 本文证明了基础模型在零样本人脸演示攻击检测方面的有效性和优越性，它们能够以较小的努力在具有挑战性的场景中实现高性能，并超越了现有技术。

> **ai_Abstract:** 本文探讨了人脸识别系统在面对演示攻击时的脆弱性，以及现有演示攻击检测（PAD）方法在泛化能力上的不足。为解决零样本PAD问题，研究评估了基础模型在挑战性场景下的有效性和泛化能力，并提出了一个简单高效的零样本PAD框架。实验证明，基础模型在困难场景下表现优异，并在SiW-Mv2数据库上超越了现有最佳技术，表明其在零样本人脸演示攻击检测方面的巨大潜力。

> **摘要翻译:** 尽管人脸识别系统在过去十年中取得了令人瞩目的发展，但这些技术容易受到攻击演示（AP）的威胁。这些攻击通常易于创建，通过针对系统的捕获设备执行攻击，恶意行为者可以冒充授权主体，从而获取后者的信息（例如，金融交易）。为了保护人脸识别方案免受演示攻击，最先进的深度学习演示攻击检测（PAD）方法需要大量数据才能产生可靠的检测性能，即便如此，它们在面对未知演示攻击工具（PAI）或数据库（训练期间未见过的信息）时，性能会下降，即它们缺乏泛化能力。为了缓解上述问题，本文专注于零样本PAD。为此，我们首先在既定和具有挑战性的实验场景中评估基础模型的有效性和泛化能力，然后提出一个简单但有效的零样本PAD框架。实验结果表明，这些模型能够在困难场景下以最小的努力实现性能，超越了更先进的PAD机制，后者的权重主要通过包含AP和真实演示的训练集进行优化。在SiW-Mv2数据库上使用留一法协议观察，表现最佳的基础模型明显优于现有技术中的最佳模型，该数据库包含具有挑战性的未知2D和3D攻击。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [220] [Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks](https://arxiv.org/abs/2502.09110)
> *揭开帷幕：基于对比辅助网络的无监督对抗检测*

*Eylon Mizrahi, Raz Lapid, Moshe Sipper* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 无监督对抗检测, 对比学习, 辅助网络, 对抗攻击, 深度学习安全

**Comment:** Accepted at SafeMM-AI @ ICCV 2025

> **TL;DR:** 本文提出了一种名为U-CAN的无监督对抗检测方法，通过在深度学习模型中间层嵌入辅助网络来识别对抗行为，无需对抗样本，并在多项实验中表现优于现有无监督方法。

**AI_Comments:** 该论文的创新点在于提出了无监督的对抗检测方法U-CAN，避免了传统方法对对抗样本的需求，这在实际应用中具有重要意义。通过在中间层嵌入辅助网络并利用对比学习的思想，U-CAN能够有效地识别对抗性行为。其在多种数据集和模型上的优越表现证明了其有效性和实用性，为提升深度学习系统的鲁棒性提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在安全关键应用中广泛使用，但容易受到对抗性攻击，这些攻击可能显著降低模型性能。传统的防御机制主要集中于增强模型鲁棒性或独立检测对抗性输入。

**Method:** 本文提出了一种名为U-CAN（Unsupervised adversarial detection via Contrastive Auxiliary Networks）的无监督对抗检测方法。U-CAN嵌入在目标模型的选定中间层中，其辅助网络包含投影层和基于ArcFace的线性层，旨在精炼特征表示，以更有效地区分良性输入和对抗性输入，且无需对抗性样本。

**Result:** 在多个数据集（CIFAR-10、Mammals和ImageNet子集）和架构（ResNet-50、VGG-16和ViT）上的综合实验表明，U-CAN方法超越了现有的无监督对抗检测技术，针对四种不同的攻击方法取得了更高的F1分数。

**Conclusion:** 所提出的U-CAN框架为增强深度学习系统的安全性和可靠性提供了一种可扩展且有效的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的无监督对抗检测框架U-CAN，旨在解决深度学习模型易受对抗攻击的问题。U-CAN通过在目标模型的中间层嵌入辅助网络（包含投影层和基于ArcFace的线性层），精炼特征表示以区分良性和对抗性输入，且无需依赖对抗样本。实验结果表明，U-CAN在多个数据集和模型架构上，针对多种攻击方法，性能优于现有的无监督对抗检测技术，提供了一种可扩展且有效的深度学习系统安全增强方案。

> **摘要翻译:** 深度学习模型广泛应用于安全关键型应用中，但仍易受对抗性攻击——即难以察觉的扰动，这些扰动会显著降低模型性能。传统的防御机制主要侧重于增强模型鲁棒性或独立检测对抗性输入。在这项工作中，我们提出了一种通过对比辅助网络（U-CAN）进行无监督对抗检测的方法，以在辅助特征表示中揭示对抗性行为，而无需对抗性样本。U-CAN嵌入在目标模型的选定中间层中。这些辅助网络，包括投影层和基于ArcFace的线性层，可以精炼特征表示，从而更有效地区分良性输入和对抗性输入。在多个数据集（CIFAR-10、Mammals和ImageNet子集）和架构（ResNet-50、VGG-16和ViT）上的综合实验表明，我们的方法超越了现有的无监督对抗检测技术，针对四种不同的攻击方法取得了更高的F1分数。所提出的框架为增强深度学习系统的安全性和可靠性提供了一种可扩展且有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [224] [MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes](https://arxiv.org/abs/2410.13613)
> *MEGA：动态场景的内存高效4D高斯泼溅*

*Xinjie Zhang, Zhening Liu, Yifan Zhang, Xingtong Ge, Dailan He, Tongda Xu, Yan Wang, Zehong Lin, Shuicheng Yan, Jun Zhang* | **Category: cs.CV, cs.GR** | **Updated: 2025-07-22**

**Keywords:** 4D高斯泼溅, 动态场景, 内存高效, 熵约束, 实时渲染

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出了一种名为MEGA的内存高效4D高斯泼溅框架，大幅减少了动态场景表示的存储成本，同时保持渲染速度和质量。

**AI_Comments:** 这项工作通过创新的颜色属性分解和熵约束高斯变形技术，显著解决了4D高斯泼溅技术面临的巨大内存和存储成本问题。其在保持高性能的同时实现大幅度数据压缩的能力，为动态场景重建和渲染领域树立了新的效率标准，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 经典的4D高斯泼溅（4DGS）技术在捕获复杂动态3D场景时，因需要数百万个4D高斯及其大量相关属性，导致巨大的内存和存储成本。

**Method:** 本文引入了一个内存高效的4DGS框架。首先，通过将颜色属性分解为每个高斯的3参数直接颜色分量和共享的轻量级交流颜色预测器，替代了经典的球谐系数，从而创建了内存高效的4D高斯表示。其次，引入了一种熵约束高斯变形技术，该技术使用变形场扩展每个高斯的作用范围，并整合了基于不透明度的熵损失以限制高斯数量，从而强制模型使用尽可能少的高斯来拟合动态场景。此外，结合简单的半精度存储和zip压缩。

**Result:** 与原始4DGS相比，该框架在Technicolor和Neural 3D Video数据集上分别实现了约190倍和125倍的存储减少。同时，它保持了相当的渲染速度和场景表示质量。

**Conclusion:** 该框架通过显著降低存储成本，同时保持高性能，为动态场景的4D高斯泼溅技术设定了新的标准。

> **ai_Abstract:** 本文提出了MEGA，一个针对动态场景的内存高效4D高斯泼溅（4DGS）框架。为解决传统4DGS高内存和存储成本问题，MEGA通过简化颜色属性（用3参数直接颜色和共享预测器替代球谐系数）和引入熵约束高斯变形技术（使用变形场和基于不透明度的熵损失限制高斯数量）来优化4D高斯表示。结合半精度存储和zip压缩，该框架在多个数据集上实现了高达190倍的存储减少，同时保持了与原始4DGS相当的渲染速度和场景质量。

> **摘要翻译:** 4D高斯泼溅（4DGS）最近作为一种有前途的技术出现，能够高保真地捕获复杂的动态3D场景。它利用4D高斯表示和GPU友好的光栅化器，实现了快速渲染速度。尽管有其优点，4DGS面临着重大挑战，特别是需要数百万个4D高斯，每个高斯都有大量的相关属性，导致巨大的内存和存储成本。本文介绍了一种内存高效的4DGS框架。我们通过将颜色属性分解为每个高斯的直接颜色分量（仅3个参数）和共享的轻量级交流颜色预测器来简化颜色属性。这种方法消除了球谐系数的需要，而球谐系数在经典4DGS中通常涉及多达144个参数，从而创建了内存高效的4D高斯表示。此外，我们引入了一种熵约束高斯变形技术，该技术使用变形场扩展每个高斯的作用范围，并整合了基于不透明度的熵损失以限制高斯数量，从而强制我们的模型使用尽可能少的高斯来很好地拟合动态场景。通过简单的半精度存储和zip压缩，与原始4DGS相比，我们的框架在Technicolor和Neural 3D Video数据集上分别实现了约190倍和125倍的存储减少。同时，它保持了相当的渲染速度和场景表示质量，在该领域设定了新标准。代码可在https://github.com/Xinjie-Q/MEGA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [235] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
> *CogStream：上下文引导的流媒体视频问答*

*Zicheng Zhao, Kangyu Wang, Shijie Li, Rui Qian, Weiyao Lin, Huabin Liu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 流媒体视频问答, 上下文引导, 视频大型语言模型, CogStream, 数据集

**Comment:** Project page: https://github.com/LiamZhao326/CogStream

> **TL;DR:** 本文提出了一个名为CogStream的新任务，旨在解决流媒体视频问答中上下文信息选择和计算效率问题，并发布了配套数据集和高效基线模型。

**AI_Comments:** 这项工作通过引入一个新颖的上下文引导流媒体视频推理任务（CogStream）及其配套数据集，解决了当前视频LLMs在处理实时流媒体数据时面临的计算效率和上下文冗余挑战。其创新性在于模拟了真实世界场景，并提出了一种高效的基线模型，为未来流媒体视频理解和问答领域的研究提供了重要基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视频大型语言模型（Vid-LLMs）在多模态理解方面有所进步，但流媒体视频推理仍面临挑战，因为它依赖上下文信息。现有范式将所有可用的历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担显著，且包含无关上下文会使模型偏离关键细节。

**Method:** 本文引入了一项名为“上下文引导的流媒体视频推理（CogStream）”的挑战性任务，模拟真实世界的流媒体视频场景，要求模型识别最相关的历史上下文信息以推断关于当前流问题的答案。为支持CogStream，研究团队提出了一个由半自动管道生成的、包含大量分层问答对的密集标注数据集。此外，还提出了CogReasoner作为基线模型，该模型通过利用视觉流压缩和历史对话检索来高效地解决此任务。

**Result:** 广泛的实验证明了该方法的有效性。

**Conclusion:** 该研究通过引入CogStream任务、配套数据集以及高效的基线模型CogReasoner，有效解决了流媒体视频问答中上下文信息选择和计算效率的挑战，为实时视频理解和问答领域的研究提供了新的方向和工具。

> **ai_Abstract:** 本文针对流媒体视频问答中上下文信息处理的计算效率和无关信息干扰问题，提出了一项名为CogStream的新任务。该任务要求模型在流媒体视频中识别最相关的历史上下文信息来回答问题。为支持此任务，研究团队构建了一个包含大量分层问答对的密集标注数据集，并提出了基线模型CogReasoner，该模型通过视觉流压缩和历史对话检索来高效处理任务。实验证明了该方法的有效性。

> **摘要翻译:** 尽管视频大型语言模型（Vid-LLMs）在改进多模态理解方面取得了进展，但由于其对上下文信息的依赖，流媒体视频推理仍然面临挑战。现有范式将所有可用的历史上下文信息输入到Vid-LLMs中，导致视觉数据处理的计算负担显著。此外，包含无关上下文会使模型偏离关键细节。本文引入了一项名为“上下文引导的流媒体视频推理（CogStream）”的挑战性任务，它模拟了真实世界的流媒体视频场景，要求模型识别最相关的历史上下文信息，以推断关于当前流问题的答案。为了支持CogStream，我们提出了一个密集标注的数据集，其特点是包含由半自动管道生成的大量分层问答对。此外，我们提出了CogReasoner作为基线模型。它通过利用视觉流压缩和历史对话检索来高效地解决此任务。广泛的实验证明了该方法的有效性。项目已在https://github.com/LiamZhao326/CogStream发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [239] [Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation](https://arxiv.org/abs/2507.16716)
> *提升遥感视觉-语言模型：基于多模态大语言模型和大语言模型的高质量图像-文本数据集生成*

*Yiguo He, Junjie Zhu, Yiying Li, Xiaoyu Zhang, Chunping Qiu, Jun Wang, Qiangjuan Huang, Ke Yang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 遥感, 视觉-语言模型, 数据集生成, 多模态大语言模型, 大语言模型

**Comment:** SUBMIT TO IEEE TRANSACTIONS

> **TL;DR:** 提出MpGI方法，利用MLLM和LLM生成高质量遥感图像-文本数据集HQRS-IT-210K，显著提升VLFM性能并大幅减少所需训练数据量。

**AI_Comments:** 本文的创新点在于提出了一个利用MLLM和LLM协同生成高质量遥感图像-文本数据的方法（MpGI），有效解决了遥感领域VLFM训练数据质量和数量不足的问题。其重要性在于，通过生成的高质量数据集，显著提升了现有VLFM的性能，并大幅降低了对训练数据量的需求，为遥感视觉-语言模型的发展提供了新的方向和高质量资源。

<details>
  <summary>Details</summary>

**Motivation:** 遥感视觉-语言基础模型（VLFMs）面临高质量、大规模图像-文本配对训练数据稀缺的挑战，现有数据集生成方法质量不佳，导致性能提升有限且需要大量数据。

**Method:** 提出两阶段方法MpGI（多视角生成与整合），用于生成高质量遥感图像文本标题。第一阶段，使用Rule-MLLM Relay Generation和MLLM生成多视角、详细的遥感图像描述。第二阶段，利用LLM整合这些多样化的描述生成全面的高质量图像-文本标题。最终创建了HQRS-IT-210K数据集，包含21万张遥感图像和130万个标题。使用该数据集微调了CLIP和CoCa，得到HQRS-CLIP和RS-CoCa模型。

**Result:** HQRS-CLIP在使用仅4.2%训练数据的情况下超越了现有SOTA遥感CLIP模型。RS-CoCa在基准数据集上超越其他先进方法，并能生成媲美甚至超越人工标注的遥感图像标题。

**Conclusion:** 通过MpGI方法生成的高质量图像-文本数据集，能够显著提升遥感视觉-语言模型的性能，并有效解决数据稀缺问题，同时大幅提高数据利用效率。

> **ai_Abstract:** 本文提出MpGI（多视角生成与整合）两阶段方法，利用多模态大语言模型（MLLM）和大语言模型（LLM）生成高质量遥感图像-文本标题。该方法首先通过MLLM从多视角生成详细描述，然后由LLM整合为综合性标题，并构建了包含21万张图像和130万个标题的HQRS-IT-210K数据集。基于此数据集微调的HQRS-CLIP和RS-CoCa模型在各项任务上均表现出色，HQRS-CLIP仅用4.2%的数据量即超越现有SOTA，RS-CoCa生成标题质量媲美甚至超越人工标注，有效解决了遥感领域高质量数据稀缺问题。

> **摘要翻译:** 遥感（RS）图像中视觉-语言基础模型（VLFMs）的应用因其在各种下游任务中的卓越能力而受到广泛关注。一个关键挑战在于高质量、大规模图像-文本配对训练数据的稀缺性。最近，一些工作引入了用于遥感的广泛图像-文本数据集并训练了其VLFMs。然而，由于用于生成标题的原始方法，数据集的质量不尽如人意，需要更大的训练数据量，同时只能带来适度的性能提升。在本文中，我们提出了一种名为MpGI（多视角生成与整合）的两阶段方法，用于生成高质量的遥感图像文本标题。首先，我们使用Rule-MLLM（多模态大语言模型）接力生成和MLLM生成方法，从不同视角生成独特而详细的描述。接下来，我们利用大语言模型（LLMs）将这些多样化的描述整合为全面的标题，捕捉多视角的细节。最后，我们创建了HQRS-IT-210K数据集，包含约21万张遥感图像和130万个标题。我们使用我们的数据集微调了两个VLFM：判别模型CLIP和图像到文本生成模型CoCa。这一过程产生了我们提出的HQRS-CLIP和RS-CoCa模型。实验结果表明，HQRS-CLIP在使用仅4.2%训练数据的情况下超越了之前的SOTA遥感CLIP模型。RS-CoCa在基准数据集上超越了其他先进方法，并且可以生成媲美甚至超越人工标注的遥感图像标题。数据集、预训练模型和代码将在https://github.com/YiguoHe/HQRS-210K-and-HQRS-CLIP发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [241] [V-RoAst: Visual Road Assessment. Can VLM be a Road Safety Assessor Using the iRAP Standard?](https://arxiv.org/abs/2408.10872)
> *V-RoAst：视觉道路评估。视觉语言模型能否使用iRAP标准作为道路安全评估工具？*

*Natchapon Jongwiriyanurak, Zichao Zeng, June Moh Goo, Xinglei Wang, Ilya Ilyankou, Kerkritt Sriroongvikrai, Nicola Christie, Meihui Wang, Huanfa Chen, James Haworth* | **Category: cs.CV, cs.AI, cs.ET** | **Updated: 2025-07-22**

**Keywords:** 道路安全评估, 视觉语言模型, 零样本学习, 视觉问答, iRAP标准

**Comment:** 

> **TL;DR:** V-RoAst利用视觉语言模型（VLM）进行零样本视觉问答，以自动评估道路安全属性，解决了传统方法的成本和泛化问题，并首次探索了VLM在基础设施风险评估中的应用。

**AI_Comments:** 这项工作的创新之处在于首次将视觉语言模型应用于零样本基础设施风险评估，这对于降低道路安全评估成本、特别是在中低收入国家具有重要意义。引入ThaiRAP开源数据集也为后续研究提供了宝贵资源。尽管VLM在空间感知上仍有局限，但其无需重新训练即可泛化和灵活推理的优势，使其成为自动道路安全评估的强大工具。

<details>
  <summary>Details</summary>

**Motivation:** 道路安全评估至关重要但成本高昂，尤其是在中低收入国家，大多数道路未被评级。传统方法需要专家标注和训练数据，而基于监督学习的方法难以跨区域泛化。

**Method:** 本文提出了V-RoAst，一个使用视觉语言模型（VLMs）的零样本视觉问答（VQA）框架，用于根据iRAP标准对道路安全属性进行分类。研究引入了第一个来自ThaiRAP的开源数据集，包含2,000多张泰国的街景图像。研究评估了Gemini-1.5-flash和GPT-4o-mini在该数据集上的性能，并与VGGNet和ResNet基线进行了比较。

**Result:** 视觉语言模型在空间感知方面表现不佳，但它们能够很好地泛化到未见过的类别，并提供灵活的基于提示的推理，无需重新训练。结果表明，当与补充数据集成时，VLMs可以作为自动道路评估工具。

**Conclusion:** 这项工作首次探索了视觉语言模型在零样本基础设施风险评估中的应用，并为自动、低成本的道路安全测绘开辟了新方向。

> **ai_Abstract:** V-RoAst提出了一种基于视觉语言模型（VLM）的零样本视觉问答（VQA）框架，旨在实现自动、低成本的道路安全评估，以克服传统方法的局限性。该研究利用新发布的ThaiRAP数据集（包含2000多张街景图像）评估了Gemini-1.5-flash和GPT-4o-mini等VLM的性能。尽管VLMs在空间感知上存在不足，但它们在泛化能力和零样本推理方面表现出色，证明了其作为自动道路评估工具的潜力，为基础设施风险评估开辟了新途径。

> **摘要翻译:** 道路安全评估至关重要但成本高昂，尤其是在中低收入国家，大多数道路仍未评级。传统方法需要专家标注和训练数据，而基于监督学习的方法难以跨区域泛化。在本文中，我们引入了V-RoAst，一个使用视觉语言模型（VLMs）的零样本视觉问答（VQA）框架，用于根据iRAP标准对道路安全属性进行分类。我们首次推出了来自ThaiRAP的开源数据集，包含2,000多张经过整理的泰国街景图像，用于此任务。我们评估了Gemini-1.5-flash和GPT-4o-mini在该数据集上的表现，并将其性能与VGGNet和ResNet基线进行了比较。虽然VLMs在空间感知方面表现不佳，但它们能够很好地泛化到未见过的类别，并提供灵活的基于提示的推理，无需重新训练。我们的结果表明，当与补充数据集成时，VLMs可以作为自动道路评估工具。这项工作首次探索了VLMs在零样本基础设施风险评估中的应用，并为自动、低成本的道路安全测绘开辟了新方向。代码和数据集：https://github.com/PongNJ/V-RoAst。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [243] [ADCD-Net: Robust Document Image Forgery Localization via Adaptive DCT Feature and Hierarchical Content Disentanglement](https://arxiv.org/abs/2507.16397)
> *ADCD-Net：基于自适应DCT特征和分层内容解耦的鲁棒文档图像伪造定位*

*Kahim Wong, Jicheng Zhou, Haiwei Wu, Yain-Whar Si, Jiantao Zhou* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 文档图像伪造, 伪造定位, DCT特征, 内容解耦, 鲁棒性

**Comment:** 

> **TL;DR:** ADCD-Net是一个鲁棒的文档图像伪造定位模型，通过自适应DCT特征、分层内容解耦和原始背景原型，显著优于现有SOTA方法。

**AI_Comments:** 该论文解决了数字取证领域一个关键且具有挑战性的问题，特别是针对与自然图像显著不同的文档图像。所提出的方法，包括自适应DCT特征调制、分层内容解耦和原始原型构建，展示了利用文档特定特征来提高鲁棒性和准确性的创新方式。20.79%的显著性能提升凸显了其重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 图像编辑工具的进步使得敏感文档图像的恶意篡改成为可能，因此需要鲁棒的文档图像伪造检测。现有针对自然图像的伪造检测器难以处理文档图像中无缝融入背景和文本的篡改区域。而现有特定于文档的方法缺乏对各种退化的足够鲁棒性，限制了实际部署。

**Method:** 本文提出了ADCD-Net，一个鲁棒的文档伪造定位模型。它自适应地利用RGB/DCT取证痕迹并整合文档图像的关键特征。具体包括：1. 根据预测的对齐分数自适应调制DCT特征贡献，以提高对各种失真（如调整大小和裁剪）的弹性。2. 提出分层内容解耦方法，通过缓解文本-背景差异来提升定位性能。3. 构建一个捕获未篡改区域痕迹的原始原型，以增强定位精度和鲁棒性。

**Result:** ADCD-Net在伪造定位方面表现出卓越性能，在5种失真类型上平均比最先进的方法高出20.79%。

**Conclusion:** ADCD-Net通过引入自适应DCT特征、分层内容解耦和原始背景原型等创新技术，有效解决了文档图像伪造定位的挑战，并显著提高了定位的准确性和鲁棒性。

> **ai_Abstract:** 本文介绍了ADCD-Net，一个用于鲁棒文档图像伪造定位的模型。针对文档图像中篡改区域难以区分和现有方法对退化缺乏鲁棒性的问题，ADCD-Net提出了一系列创新策略。它通过自适应调制DCT特征贡献来增强对图像失真（如调整大小和裁剪）的弹性；采用分层内容解耦方法来缓解文本与背景的差异，从而提高定位性能；并构建了一个原始原型来捕获未篡改区域的痕迹，以提升定位精度和鲁棒性。实验结果表明，ADCD-Net在各种失真条件下，其伪造定位性能显著优于现有最先进的方法。

> **摘要翻译:** 图像编辑工具的进步使得敏感文档图像的恶意篡改成为可能，这突显了对鲁棒文档图像伪造检测的需求。尽管针对自然图像的伪造检测器已得到广泛研究，但它们在文档图像方面却举步维艰，因为篡改区域可以无缝地融入统一的文档背景（BG）和结构化文本中。另一方面，现有的特定于文档的方法缺乏对各种退化的足够鲁棒性，这限制了它们的实际部署。本文提出了ADCD-Net，一种鲁棒的文档伪造定位模型，它自适应地利用RGB/DCT取证痕迹并整合了文档图像的关键特征。具体来说，为了解决DCT痕迹对块不对齐的敏感性，我们根据预测的对齐分数自适应地调制DCT特征的贡献，从而大大提高了对包括调整大小和裁剪在内的各种失真的弹性。此外，还提出了一种分层内容解耦方法，通过缓解文本-背景差异来提高定位性能。此外，注意到背景区域主要保持原始状态，我们构建了一个捕获未篡改区域痕迹的原始原型，最终提高了定位精度和鲁棒性。我们提出的ADCD-Net展示了卓越的伪造定位性能，在5种失真类型上平均比最先进的方法高出20.79%。代码可在https://github.com/KAHIMWONG/ACDC-Net获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [245] [GS-TransUNet: Integrated 2D Gaussian Splatting and Transformer UNet for Accurate Skin Lesion Analysis](https://arxiv.org/abs/2502.16748)
> *GS-TransUNet：集成2D高斯泼溅与Transformer UNet用于精确皮肤病变分析*

*Anand Kumar, Kavinder Roghit Kanthen, Josna John* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 皮肤病变分析, 高斯泼溅, Transformer UNet, 多任务学习, 皮肤癌诊断

**Comment:** 12 pages, 7 figures, SPIE Medical Imaging 2025. 13407-1340736

> **TL;DR:** 提出GS-TransUNet模型，结合2D高斯泼溅和Transformer UNet，实现皮肤病变分割与分类的双功能统一分析，并在ISIC-2017和PH2数据集上表现优异。

**AI_Comments:** 该论文的创新点在于将2D高斯泼溅和Transformer UNet架构进行集成，实现了皮肤病变分割和分类的双任务统一处理，而非传统的分离式模型。这种集成提高了效率和精度，为医学图像分析领域的多任务学习提供了一个有前景的范例。其重要性在于提升了早期皮肤癌检测的自动化和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有皮肤病变分割和分类预测模型独立运行，导致效率低下，未能充分利用集成执行的潜力。

**Method:** 提出了GS-TransUNet，一个结合2D高斯泼溅与Transformer UNet架构的新方法，用于统一皮肤癌诊断，实现双功能皮肤病变分类和分割。

**Result:** 在ISIC-2017和PH2数据集上，GS-TransUNet通过5折交叉验证在多项指标上优于现有SOTA模型，显著提升了分割和分类的精度。

**Conclusion:** GS-TransUNet的集成方法在皮肤病变分析领域树立了新基准，并预示了多任务医学图像分析方法在自动化诊断系统中的进一步研究潜力。

> **ai_Abstract:** 本文提出了GS-TransUNet，一个结合2D高斯泼溅和Transformer UNet的深度学习模型，旨在统一皮肤病变分割和分类任务。该模型解决了现有独立模型效率低下的问题，实现了皮肤癌诊断的双功能分析。在ISIC-2017和PH2数据集上的实验表明，GS-TransUNet在多项指标上优于现有SOTA模型，显著提高了皮肤病变分析的精度，为多任务医学图像分析开辟了新方向。

> **摘要翻译:** 随着计算机视觉和深度学习技术的最新发展，我们可以实现快速且一致的早期皮肤癌检测。然而，现有的皮肤病变分割和分类预测模型独立运行，因此错失了集成执行带来的潜在效率。为了统一皮肤病变分析，本文提出了高斯泼溅-Transformer UNet（GS-TransUNet），这是一种将2D高斯泼溅与Transformer UNet架构协同结合的新方法，用于自动化皮肤癌诊断。我们统一的深度学习模型能够高效地提供用于临床诊断的双功能皮肤病变分类和分割。在ISIC-2017和PH2数据集上进行评估，我们的网络通过5折交叉验证在多项指标上表现出优于现有最先进模型的性能。我们的研究结果表明，分割和分类的精度取得了显著进步。这种集成在领域内树立了新的基准，并强调了在多任务医学图像分析方法方面进一步研究的潜力，有望增强自动化诊断系统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [246] [A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications](https://arxiv.org/abs/2507.15961)
> *一种轻量级人脸质量评估框架，用于提高实时筛选应用中的人脸验证性能*

*Ahmed Aman Ibrahim, Hamad Mansour Alawar, Abdulnasser Abbas Zehi, Ahmed Mohammad Alkendi, Bilal Shafi Ashfaq Ahmed Mirza, Shan Ullah, Ismail Lujain Jaleel, Hassan Ugail* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 人脸质量评估, 实时筛选, 人脸验证, 随机森林, 性能提升

**Comment:** 

> **TL;DR:** 该研究提出了一种轻量级人脸质量评估框架，通过预过滤低质量人脸图像，显著提高了实时人脸验证系统的性能，尤其降低了误拒率并提升了余弦相似度分数。

**AI_Comments:** 这项工作提出了一种实用且高效的人脸质量评估方法，其创新点在于结合了归一化人脸地标和随机森林回归分类器，实现了高准确率和计算效率。其重要性体现在能够显著提升实时人脸验证系统的性能，特别是在低质量图像普遍存在的非受限环境中。该框架解决了实际应用中常见的挑战，如分辨率和姿态变化，对于安防、身份验证等领域具有重要价值。其轻量级特性也使其易于部署。

<details>
  <summary>Details</summary>

**Motivation:** 人脸图像质量对人脸验证系统的准确性和可靠性至关重要，尤其是在实时筛选应用中。低质量图像（如运动模糊、光照差、遮挡、极端姿态变化）会显著降低人脸识别模型的性能，导致更高的误拒率和误接受率。因此，需要一个有效的框架来预过滤低质量图像。

**Method:** 该方法利用归一化人脸地标结合随机森林回归分类器来评估图像质量，实现96.67%的准确率。通过将此质量评估模块集成到人脸验证过程中，并在迪拜警方CCTV录像收集的真实世界数据集上进行了实验。

**Result:** 该框架实现了96.67%的图像质量评估准确率。集成后，人脸验证性能显著提高，误拒率降低了99.7%，并增强了与ArcFace模型配对时的余弦相似度分数。该框架在计算效率的同时，优于现有的人脸质量评估技术，并有效解决了人脸分辨率变化和姿态偏差等挑战。

**Conclusion:** 所提出的轻量级人脸质量评估框架能够有效减轻低质量人脸图像的影响，显著提高实时人脸验证系统的性能，特别是在处理分辨率和姿态变化方面，同时保持计算效率。

> **ai_Abstract:** 本研究提出了一种轻量级人脸质量评估框架，旨在提高实时人脸验证系统在实际应用中的性能。该框架通过利用归一化人脸地标和随机森林回归分类器，在图像传递至验证流程前预过滤低质量人脸图像，实现了96.67%的质量评估准确率。实验结果表明，该模块的集成显著降低了人脸验证的误拒率（99.7%）并提升了余弦相似度分数，有效解决了低质量图像带来的挑战，尤其是在处理分辨率和姿态变化方面，同时保持了计算效率。

> **摘要翻译:** 人脸图像质量在决定人脸验证系统的准确性和可靠性方面起着关键作用，尤其是在监控、身份验证和门禁等实时筛选应用中。低质量人脸图像，通常由运动模糊、不良照明条件、遮挡和极端姿态变化等因素引起，会显著降低人脸识别模型的性能，导致更高的误拒率和误接受率。在这项工作中，我们提出了一种轻量级但有效的人脸质量自动评估框架，旨在在低质量人脸图像传递到验证流程之前对其进行预过滤。我们的方法利用归一化人脸地标结合随机森林回归分类器来评估图像质量，实现了96.67%的准确率。通过将此质量评估模块集成到人脸验证过程中，我们观察到性能显著改善，包括误拒率舒适地降低了99.7%，以及与ArcFace人脸验证模型配对时余弦相似度分数得到提升。为了验证我们的方法，我们在一个真实世界的数据集上进行了实验，该数据集包含从迪拜警方非受限环境下的闭路电视录像中捕获的600多名受试者。我们的结果表明，所提出的框架有效减轻了低质量人脸图像的影响，同时保持计算效率，优于现有的人脸质量评估技术。此外，该框架专门解决了实时筛选中的两个关键挑战：人脸分辨率的变化和姿态偏差，这两者在实际监控场景中都很普遍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching](https://arxiv.org/abs/2507.16201)
> *一种基于局部特征匹配的单步精确指纹配准方法*

*Yuwei Jia, Zhe Cui, Fei Su* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 指纹配准, 单步方法, 局部特征匹配, 半密集匹配点, 端到端

**Comment:** 

> **TL;DR:** 提出了一种单步端到端指纹配准算法，通过直接预测半密集匹配点来解决传统方法的失败问题，并达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个单步端到端的指纹配准方法，有效规避了传统方法中细节特征不足导致的初始配准失败问题。通过直接预测半密集匹配点和利用全局-局部注意力机制，该方法简化了流程并提升了在复杂情况下的鲁棒性。其重要性在于为指纹识别领域提供了一种更高效、更稳定的配准方案，尤其适用于低质量指纹图像。

<details>
  <summary>Details</summary>

**Motivation:** 指纹图像畸变导致指纹识别性能下降，现有指纹配准方法通常包含两步（基于细节特征的初始配准和基于匹配点的密集配准）。然而，在指纹图像质量较低时，细节特征数量减少导致初始配准频繁失败，进而导致整个指纹配准过程失败。

**Method:** 本研究提出了一种端到端的单步指纹配准算法。该方法通过直接预测两个指纹图像之间的半密集匹配点对应关系来对齐指纹，从而最大限度地降低了细节特征配准失败的风险。此外，该方法利用全局-局部注意力机制实现两个指纹之间的端到端像素级对齐。

**Result:** 实验结果证明，我们提出的方法仅通过单步配准即可达到最先进的匹配性能，并且可以与密集配准算法结合使用以进一步提高性能。

**Conclusion:** 本研究提出的单步指纹配准算法有效解决了传统两步法在低质量图像下的失败问题，并展现出卓越的性能，同时具有与现有密集配准算法结合的潜力。

> **ai_Abstract:** 本论文提出了一种创新的单步端到端指纹配准算法，旨在解决传统两步法在低质量指纹图像下因细节特征不足导致的配准失败问题。该方法通过直接预测指纹间的半密集匹配点对应关系，并结合全局-局部注意力机制实现像素级对齐。实验证明，该方法在单步配准下达到了最先进的性能，并能与现有密集配准算法结合以进一步提升效果。

> **摘要翻译:** 指纹图像的畸变导致指纹识别性能下降，而指纹配准可以通过精确对齐两个指纹图像来缓解这一畸变问题。目前，指纹配准方法通常由两步组成：基于细节特征的初始配准和基于匹配点的密集配准。然而，当指纹图像质量较低时，检测到的细节特征数量减少，导致初始配准频繁失败，最终导致整个指纹配准过程失败。在本研究中，我们提出了一种端到端的单步指纹配准算法，通过直接预测两个指纹之间的半密集匹配点对应关系来对齐指纹。因此，我们的方法最大限度地降低了细节特征配准失败的风险，并且利用全局-局部注意力机制实现了两个指纹之间的端到端像素级对齐。实验结果证明，我们的方法仅通过单步配准即可达到最先进的匹配性能，并且可以与密集配准算法结合使用以进一步提高性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [252] [Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge](https://arxiv.org/abs/2507.04123)
> *面向自动驾驶的准确高效三维目标检测：边缘端的专家混合计算系统*

*Linshen Liu, Boyan Su, Junyue Jiang, Guanlin Wu, Cong Guo, Ceyu Xu, Hao Frank Yang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 三维目标检测, 自动驾驶, 边缘计算, 专家混合, 多模态融合

**Comment:** Accepted at ICCV 2025

> **TL;DR:** EMC2是一种针对自动驾驶汽车的边缘端专家混合计算系统，能同时实现低延迟和高精度的三维目标检测。

**AI_Comments:** EMC2的创新之处在于其将专家混合（MoE）架构引入边缘计算平台，并通过场景感知路由和软硬件联合优化，有效地平衡了三维目标检测的精度和效率。这种端到端系统设计，特别是针对边缘设备的优化，对于自动驾驶汽车的实际部署具有重要意义。其在开源数据集上的显著性能提升，证明了该方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决自动驾驶汽车在三维目标检测中对低延迟和高精度的需求，本研究提出了一个优化的计算系统。

**Method:** 本文提出了边缘端专家混合协作计算（EMC2）系统，该系统采用场景感知型专家混合（MoE）架构，并为边缘平台进行了优化。它通过自适应多模态数据桥接融合激光雷达和摄像头数据，进行多尺度预处理，并通过场景感知路由机制动态调度特征到专家模型。此外，EMC2还集成了软硬件联合优化，包括硬件资源利用优化和计算图简化，以确保在资源受限的边缘设备上进行高效实时推理。

**Result:** 在KITTI数据集上，EMC2相比15种基线方法在Jetson平台上平均精度提升了3.58%，推理速度提升了159.06%。在nuScenes数据集上也取得了类似的性能提升。

**Conclusion:** EMC2系统能够推进自动驾驶汽车可靠、实时的三维目标检测任务，实现了低延迟和高精度的三维目标检测。

> **ai_Abstract:** 本文提出了EMC2，一种专为自动驾驶汽车设计的边缘端专家混合协作计算系统，旨在实现低延迟和高精度的三维目标检测。EMC2采用场景感知型MoE架构，通过自适应多模态数据桥接有效融合激光雷达和摄像头数据，并利用场景感知路由机制动态调度特征。结合软硬件联合优化，该系统在资源受限的边缘设备上实现了高效实时推理。实验结果表明，EMC2在KITTI和nuScenes数据集上均显著提升了检测精度和推理速度，验证了其在自动驾驶三维目标检测领域的先进性。

> **摘要翻译:** 本文提出了一种基于边缘的专家混合（MoE）协作计算（EMC2）系统，这是一种为自动驾驶汽车（AVs）设计的优化计算系统，可同时实现低延迟和高精度的三维目标检测。与传统方法不同，EMC2融合了专门为边缘平台优化的场景感知型MoE架构。通过有效融合激光雷达和摄像头数据，该系统利用稀疏三维点云和密集二维图像的互补优势，生成鲁棒的多模态表示。为此，EMC2采用自适应多模态数据桥接，对传感器输入进行多尺度预处理，然后通过场景感知路由机制，根据目标可见性和距离动态地将特征分派给专门的专家模型。此外，EMC2集成了软硬件联合优化，包括硬件资源利用优化和计算图简化，以确保在资源受限的边缘设备上进行高效实时推理。在开源基准测试上的实验清楚地表明了EMC2作为端到端系统的进步。在KITTI数据集上，与Jetson平台上的15种基线方法相比，它实现了平均3.58%的精度提升和159.06%的推理速度提升，在nuScenes数据集上也取得了类似的性能增益，突出了其在推进AVs可靠、实时三维目标检测任务方面的能力。官方实现可在https://github.com/LinshenLiu622/EMC2 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [260] [ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness](https://arxiv.org/abs/2503.10624)
> *ETCH：通过等变紧密度将人体拟合泛化到穿衣人体*

*Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu* | **Category: cs.CV, cs.AI, cs.GR** | **Updated: 2025-07-22**

**Keywords:** 穿衣人体拟合, 等变紧密度, 3D点云, 身体建模, 泛化能力

**Comment:** Page: https://boqian-li.github.io/ETCH/, Code:
  https://github.com/boqian-li/ETCH

> **TL;DR:** ETCH提出了一种新颖的方法，通过估计布料到身体的表面映射和回归稀疏身体标记来拟合穿衣人体，显著优于现有技术，并在各种具有挑战性的条件下表现出强大的泛化能力。

**AI_Comments:** ETCH的创新点在于引入了“等变紧密度”的概念，通过将紧密度编码为位移向量并结合姿势不变的身体特征回归稀疏标记，有效地解决了穿衣人体拟合的难题。其在泛化能力上的显著提升，尤其是在宽松衣物和一次性设置下的表现，显示了该方法的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 将身体拟合到3D穿衣人体点云是一项常见但具有挑战性的任务。传统的基于优化的方法对姿势初始化敏感，而最近的基于学习的方法在不同姿势和服装类型上的泛化能力较差。

**Method:** 我们提出了穿衣人体等变紧密度拟合（ETCH），这是一个新颖的管道，通过局部近似SE(3)等变性估计布料到身体的表面映射，将紧密度编码为从布料表面到底层身体的位移向量。在此映射之后，姿势不变的身体特征回归稀疏身体标记，将穿衣人体拟合简化为内部身体标记拟合任务。

**Result:** 在CAPE和4D-Dress上的大量实验表明，ETCH在宽松衣物上的身体拟合精度（16.7% ~ 69.5%）和形状精度（平均49.9%）方面显著优于最先进的方法（包括紧密度无关和紧密度感知的方法）。我们的等变紧密度设计甚至可以在一次性（或分布外）设置（约1%数据）中将方向误差减少（67.2% ~ 89.8%）。定性结果表明ETCH具有强大的泛化能力，无论具有挑战性的姿势、未见的形状、宽松的衣服和非刚性动态。

**Conclusion:** ETCH通过引入等变紧密度设计，有效地解决了穿衣人体拟合的挑战，并在准确性和泛化能力方面取得了显著的改进，在多种复杂场景下表现出色。

> **ai_Abstract:** ETCH提出了一种新颖的穿衣人体拟合方法，通过局部近似SE(3)等变性来估计布料到身体的表面映射，并将紧密度编码为位移向量。该方法通过将拟合任务简化为内部身体标记回归来克服现有方法的局限性。实验结果表明，ETCH在身体和形状拟合精度上显著优于现有技术，并在具有挑战性的姿势、未见形状、宽松衣物和非刚性动态下表现出强大的泛化能力。

> **摘要翻译:** 将身体拟合到3D穿衣人体点云是一项常见但具有挑战性的任务。传统的基于优化的方法使用多阶段管道，对姿势初始化敏感，而最近的基于学习的方法在不同姿势和服装类型上的泛化能力往往较差。我们提出了穿衣人体等变紧密度拟合（ETCH），这是一个新颖的管道，通过局部近似SE(3)等变性估计布料到身体的表面映射，将紧密度编码为从布料表面到底层身体的位移向量。在此映射之后，姿势不变的身体特征回归稀疏身体标记，将穿衣人体拟合简化为内部身体标记拟合任务。在CAPE和4D-Dress上的大量实验表明，ETCH在宽松衣物上的身体拟合精度（16.7% ~ 69.5%）和形状精度（平均49.9%）方面显著优于最先进的方法（包括紧密度无关和紧密度感知的方法）。我们的等变紧密度设计甚至可以在一次性（或分布外）设置（约1%数据）中将方向误差减少（67.2% ~ 89.8%）。定性结果表明ETCH具有强大的泛化能力，无论具有挑战性的姿势、未见的形状、宽松的衣服和非刚性动态。我们将很快在https://boqian-li.github.io/ETCH/发布代码和模型以供研究使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [270] [One-for-More: Continual Diffusion Model for Anomaly Detection](https://arxiv.org/abs/2502.19848)
> *一劳永逸：用于异常检测的持续扩散模型*

*Xiaofan Li, Xin Tan, Zhuo Chen, Zhizhong Zhang, Ruixin Zhang, Rizen Guo, Guannan Jiang, Yulong Chen, Yanyun Qu, Lizhuang Ma, Yuan Xie* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 持续扩散模型, 异常检测, 梯度投影, 奇异值分解, 灾难性遗忘

**Comment:** Accepted by CVPR2025

> **TL;DR:** 本文提出了一种持续扩散模型，通过梯度投影和迭代SVD解决了现有扩散模型在异常检测中面临的“忠实度幻觉”和“灾难性遗忘”问题，并在MVTec和VisA数据集上取得了领先性能。

**AI_Comments:** 该论文创新性地将持续学习的概念引入到扩散模型中以解决异常检测的挑战，特别是针对“忠实度幻觉”和“灾难性遗忘”问题。梯度投影和迭代SVD的结合提供了一个高效且内存友好的解决方案，而异常掩蔽网络的引入则进一步提升了模型的鲁棒性。其在多个数据集上的优异表现证明了该方法的有效性和实用性，为持续异常检测领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散模型的异常检测方法在处理不可预测的模式增量时，存在严重的“忠实度幻觉”和“灾难性遗忘”问题，无法满足实际需求。

**Method:** 本文提出了一种持续扩散模型，通过以下方法解决问题：1. 使用梯度投影实现稳定的持续学习，通过修改梯度方向来保护已学习的知识。2. 针对梯度投影带来的巨大内存成本，提出了基于线性表示传递性质的迭代奇异值分解（SVD）方法，该方法内存消耗极小且性能损失几乎为零。3. 提出了一种异常掩蔽网络，以增强扩散模型的条件机制，从而降低对正常图像“过拟合”的风险。

**Result:** 在持续异常检测方面，该模型在MVTec和VisA数据集的18种设置中有17种取得了第一名。

**Conclusion:** 通过引入梯度投影、迭代奇异值分解和异常掩蔽网络，本文提出的持续扩散模型有效解决了传统扩散模型在异常检测中存在的挑战，并在多种设置下取得了卓越的性能，证明了其在持续异常检测领域的有效性和优越性。

> **ai_Abstract:** 本文提出了一种名为“一劳永逸”（One-for-More）的持续扩散模型，旨在解决传统扩散模型在异常检测中面临的“忠实度幻觉”和“灾难性遗忘”问题。该模型通过引入梯度投影实现稳定的持续学习，并采用一种内存高效的迭代奇异值分解方法来克服梯度投影的内存消耗问题。此外，为防止对正常图像过拟合，模型还提出了异常掩蔽网络来增强扩散模型的条件机制。实验结果表明，该模型在MVTec和VisA数据集的持续异常检测任务上表现出色，在多数设置中排名第一。

> **摘要翻译:** 随着生成模型的兴起，人们对在生成框架内统一所有任务的兴趣日益浓厚。异常检测方法也属于这一范畴，并利用扩散模型在给定任意异常图像时生成或重建正常样本。然而，我们的研究发现扩散模型存在严重的“忠实度幻觉”和“灾难性遗忘”问题，无法满足不可预测的模式增量。为了缓解上述问题，我们提出了一种持续扩散模型，该模型使用梯度投影来实现稳定的持续学习。梯度投影通过修改梯度方向来保护已学习的知识，从而对模型更新进行正则化。但它也是一把双刃剑，因为它需要马尔可夫过程带来的巨大内存成本。因此，我们提出了一种基于线性表示传递性质的迭代奇异值分解方法，该方法内存消耗极小且几乎不产生性能损失。最后，考虑到扩散模型对正常图像“过拟合”的风险，我们提出了一种异常掩蔽网络来增强扩散模型的条件机制。在持续异常检测方面，我们的模型在MVTec和VisA数据集的18种设置中有17种取得了第一名。代码可在https://github.com/FuNz-0/One-for-More获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [273] [ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering](https://arxiv.org/abs/2507.16403)
> *ReasonVQA：一个用于视觉问答的、带有结构化知识的多跳推理基准*

*Thuy-Duong Tran, Trung-Kien Tran, Manfred Hauswirth, Danh Le Phuoc* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** ReasonVQA, 视觉问答, 多跳推理, 结构化知识, 数据集

**Comment:** Accepted at the IEEE/CVF International Conference on Computer Vision
  (ICCV) 2025

> **TL;DR:** 提出了ReasonVQA，一个用于VQA的新数据集，它通过低成本框架自动整合结构化知识，生成复杂多跳问题，对现有模型构成挑战，并具有良好的可扩展性。

**AI_Comments:** ReasonVQA的创新之处在于其自动集成结构化知识和生成复杂多跳问题的低成本框架，这解决了现有VQA数据集在多跳推理能力上的不足。其大规模和可扩展性也极大地提升了其实用价值，有望成为VQA领域重要的基准测试工具，推动模型在复杂推理方面的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有VQA模型在处理复杂、多跳推理问题时面临挑战，需要一个新的、带有结构化知识的基准数据集来评估和推动VQA领域的发展。

**Method:** 提出了ReasonVQA数据集，该数据集通过低成本框架自动整合结构化百科知识，并能够生成复杂的多跳问题。

**Result:** ReasonVQA对当前最先进的VQA模型构成了显著挑战；该数据集易于扩展，并且当前版本在需要外部知识的数据集中，其规模比现有最大数据集大一个数量级以上。

**Conclusion:** ReasonVQA数据集在评估和推动视觉问答（VQA）领域方面具有巨大潜力。

> **ai_Abstract:** 本文推出了ReasonVQA，一个专为视觉问答（VQA）设计的新数据集。该数据集通过低成本框架自动集成结构化百科知识，并能生成复杂的多跳推理问题。实验证明，ReasonVQA对当前VQA模型提出了显著挑战，显示出其在基准测试和推动VQA领域发展方面的巨大潜力。此外，ReasonVQA具有良好的可扩展性，其当前规模远超现有同类数据集。

> **摘要翻译:** 在本文中，我们提出了一个用于视觉问答（VQA）任务的新数据集ReasonVQA。我们的数据集自动集成了结构化百科知识，并使用低成本框架构建，该框架能够生成复杂的多跳问题。我们评估了ReasonVQA上最先进的VQA模型，实证结果表明ReasonVQA对这些模型构成了显著挑战，突显了其作为VQA领域基准和推进潜力的价值。此外，我们的数据集可以根据输入图像轻松扩展；当前版本在需要外部知识的现有最大数据集中，其规模超出其一个数量级以上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction](https://arxiv.org/abs/2507.16718)
> *时间约束视频推理分割与自动化基准构建*

*Yiqing Shen, Chenjia Li, Chenxiao Fan, Mathias Unberath* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视频推理分割, 时间约束, 自动化基准构建, 动态相关性, 自然语言查询

**Comment:** 

> **TL;DR:** 本文提出了时间约束视频推理分割这一新任务，解决了现有视频推理分割无法处理目标动态相关性的问题，并引入了自动化基准构建方法，同时构建了一个新的数据集TCVideoRSBenchmark。

**AI_Comments:** 这篇论文的创新点在于提出了“时间约束视频推理分割”这一新颖的任务，解决了现有视频推理分割模型无法处理目标对象动态相关性变化的局限性。其自动化基准构建方法也很有意义，降低了数据标注成本，提升了研究的可扩展性，对于推动视频推理分割在真实世界，特别是医疗场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统视频分割方法受限于预定义类别，无法处理词汇外或隐式提及的对象，限制了其在复杂多变场景中的实用性。现有视频推理分割（RS）假设目标对象在整个视频序列中始终相关，这不适用于目标对象会根据时间上下文动态出现、消失或改变相关性的真实世界场景，例如手术视频分析。

**Method:** 本文引入了“时间约束视频推理分割”这一新颖任务，要求模型根据包含时间推理的文本查询，隐式推断目标对象何时变得上下文相关。为了解决手动标注数据集成本高和可扩展性受限的问题，本文提出了一个创新的自动化基准构建方法。

**Result:** 本文构建了TCVideoRSBenchmark数据集，该数据集包含52个样本，并使用了MVOR数据集中的视频。

**Conclusion:** 本文通过引入时间约束视频推理分割任务和创新的自动化基准构建方法，有效解决了现有视频推理分割在处理目标对象动态相关性方面的局限性，并为该领域提供了一个新的基准数据集，有望提升视频分析在复杂真实世界场景中的实用性。

> **ai_Abstract:** 本文针对传统视频分割和现有推理分割在处理动态、上下文相关目标方面的局限性，提出了“时间约束视频推理分割”这一新任务。该任务要求模型根据包含时间推理的文本查询，隐式推断目标对象在视频中的上下文相关时间段。为解决手动标注数据集成本高的问题，作者还开发了一种创新的自动化基准构建方法，并基于此构建了TCVideoRSBenchmark数据集。这项工作旨在提升视频分析在复杂真实世界场景中的灵活性和实用性。

> **摘要翻译:** 传统视频分割方法局限于预定义的物体类别，无法识别词汇外物体，更不用说那些没有明确识别但仅在复杂文本查询中隐式提及的物体。这一缺点限制了视频分割在复杂多变场景中的实用性，在这些场景中，封闭的物体类别集难以定义，并且用户可能不知道视频中将出现的具体物体类别。例如，在手术室视频分析中可能会出现这种情况，不同的医疗系统可能使用不同的工作流程和器械，需要灵活的视频分析解决方案。推理分割（RS）现在为这种解决方案提供了希望，它允许使用自然语言文本查询作为交互来识别要分割的物体。然而，现有的视频RS公式假设目标物体在整个视频序列中保持上下文相关。这一假设不适用于真实世界场景，在这些场景中，感兴趣的物体会根据时间上下文动态出现、消失或改变相关性，例如仅在特定手术阶段才相关的外科器械或在手术特定时刻变得重要的解剖结构。我们的第一个贡献是引入了时间约束视频推理分割，这是一种新颖的任务制定，要求模型根据包含时间推理的文本查询隐式推断目标物体何时变得上下文相关。由于手动标注时间约束视频RS数据集成本高昂且限制了可扩展性，我们的第二个贡献是一种创新的自动化基准构建方法。最后，我们提出了TCVideoRSBenchmark，一个包含52个样本的时间约束视频RS数据集，使用了MVOR数据集中的视频。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [286] [FW-VTON: Flattening-and-Warping for Person-to-Person Virtual Try-on](https://arxiv.org/abs/2507.16010)
> *FW-VTON：面向人对人虚拟试穿的展平与变形方法*

*Zheng Wang, Xianbing Sun, Shengyi Wu, Jiahui Zhan, Jianlou Si, Chi Zhang, Liqing Zhang, Jianfu Zhang* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 虚拟试穿, 人对人试穿, 服装展平, 服装变形, 数据集

**Comment:** 

> **TL;DR:** 本文提出FW-VTON，一种用于人对人虚拟试穿的新方法，通过展平、变形和整合三个阶段将源人物身上的服装转移到目标人物上，并引入了新的数据集，实现了最先进的性能。

**AI_Comments:** FW-VTON 的创新点在于提出了展平与变形的三阶段处理流程，解决了人对人虚拟试穿中服装姿态适配的难题。同时，为解决该领域高质量数据集匮乏的问题，研究者构建了新的数据集，这对于推动该领域的研究具有重要意义。该方法在定性和定量上均表现优异，展现了其在虚拟试穿应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统虚拟试穿方法主要关注服装到人的试穿任务，需要扁平的服装表示。然而，本文关注的是人对人（person-to-person）的试穿任务，即输入是穿着服装的源人物图像和目标人物图像，目标是生成目标人物穿上源服装的逼真图像。此外，该任务缺乏高质量的数据集。

**Method:** 本文提出了展平与变形虚拟试穿（FW-VTON）方法，该方法分三个阶段操作：1) 从源图像中提取展平的服装图像；2) 将服装变形以适应目标姿态；3) 将变形后的服装无缝整合到目标人物上。为了解决高质量数据集的缺乏，引入了一个专门为人对人试穿场景设计的新数据集。

**Result:** 实验评估表明，FW-VTON 在定性和定量评估中均取得了最先进的性能，并优于现有的方法，在服装提取子任务中也表现出色。

**Conclusion:** FW-VTON 方法通过其创新的三阶段展平与变形策略，成功解决了人对人虚拟试穿任务的挑战，并在新数据集的辅助下实现了行业领先的性能。

> **ai_Abstract:** 本文提出了一种名为 FW-VTON 的新型人对人虚拟试穿方法，旨在将源人物穿着的服装转移到目标人物身上。与传统的服装到人试穿不同，FW-VTON 处理的是两张人物图像作为输入。该方法包含三个核心阶段：首先从源图像中提取展平的服装，然后根据目标人物的姿态对服装进行变形，最后将变形后的服装无缝地整合到目标人物身上。为了支持这项任务，研究人员还创建了一个新的高质量数据集。实验结果表明，FW-VTON 在性能上达到了最先进水平，并在服装提取方面表现突出。

> **摘要翻译:** 传统虚拟试穿方法主要关注服装到人的试穿任务，这需要扁平的服装表示。相比之下，本文介绍了一种新颖的人对人试穿方法。与服装到人试穿任务不同，人对人任务仅涉及两张输入图像：一张描绘目标人物，另一张显示由不同个体穿着的服装。目标是生成目标人物与所需服装的逼真组合。为此，我们提出了展平与变形虚拟试穿（FW-VTON），这是一种分三个阶段操作的方法：(1) 从源图像中提取展平的服装图像；(2) 将服装变形以与目标姿态对齐；(3) 将变形后的服装无缝整合到目标人物身上。为了克服高质量数据集缺乏所带来的挑战，我们引入了一个专门为人对人试穿场景设计的新数据集。实验评估表明，FW-VTON 取得了最先进的性能，在定性和定量评估中均取得了卓越的结果，并且在服装提取子任务中也表现出色。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [292] [Analysis of the 2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge](https://arxiv.org/abs/2405.18383)
> *2024年BraTS脑膜瘤放疗计划自动化分割挑战赛分析*

*Dominic LaBella, Valeriia Abramova, Mehdi Astaraki, Andre Ferreira, Zhifan Jiang, Mason C. Cleveland, Ramandeep Kang, Uma M. Lal-Trehan Estrada, Cansu Yalcin, Rachika E. Hamadache, Clara Lisazo, Adrià Casamitjana, Joaquim Salvi, Arnau Oliver, Xavier Lladó, Iuliana Toma-Dasu, Tiago Jesus, Behrus Puladi, Jens Kleesiek, Victor Alves, Jan Egger, Daniel Capellán-Martín, Abhijeet Parida, Austin Tapp, Xinyang Liu, Maria J. Ledesma-Carbayo, Jay B. Patel, Thomas N. McNeal, Maya Viera, Owen McCall, Albert E. Kim, Elizabeth R. Gerstner, Christopher P. Bridge, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, David R. Raleigh, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Marina Ivory, Theodore Barfoot, Omar Al-Salihi, Justin Leu, Lia M. Halasz, Yuri S. Velichko, Chunhao Wang, John P. Kirkpatrick, Scott R. Floyd, Zachary J. Reitman, Trey C. Mullikin, Eugene J. Vaios, Christina Huang, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler M. Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Peter Taylor, Pranav Warman, Jake Albrecht, András Jakab, Mana Moassefi, Verena Chung, Rong Chai, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Nazanin Maleki, Rachit Saluja, Florian Kofler, Christopher G. Schwarz, Philipp Lohmann, Phillipp Vollmuth, Louis Gagnon, Maruf Adewole, Hongwei Bran Li, Anahita Fathi Kazerooni, Nourel Hoda Tahon, Udunna Anazodo, Ahmed W. Moawad, Bjoern Menze, Marius George Linguraru, Mariam Aboian, Benedikt Wiestler, Ujjwal Baid, Gian-Marco Conte, Andreas M. Rauschecker, Ayman Nada, Aly H. Abayazeed, Raymond Huang, Maria Correia de Verdier, Jeffrey D. Rudie, Spyridon Bakas, Evan Calabrese* | **Category: cs.CV, cs.AI, cs.HC, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 脑膜瘤, 放射治疗计划, 自动化分割, BraTS, 挑战赛

**Comment:** 23 pages, 9 figures, 5 tables

> **TL;DR:** 2024年BraTS-MEN-RT挑战赛旨在利用大型多机构数据集（750例MRI）推动脑膜瘤放疗计划的自动化分割算法，并评估了参赛团队的表现，最佳Dice系数为0.815。

**AI_Comments:** 这项挑战赛的重要性在于它使用了迄今为止最大的多机构脑膜瘤放疗计划MRI数据集，这对于训练和验证鲁棒的自动化分割算法至关重要。通过标准化标注协议和明确的评估指标，挑战赛为算法开发提供了一个公平且严谨的平台。最佳结果显示了自动化分割在精确肿瘤定位方面的潜力，这对于个性化放疗至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该挑战旨在利用最大规模的多机构数据集，推动脑膜瘤放疗计划自动化分割算法的进步，以实现精确的肿瘤分割并促进个性化治疗，最终改善患者预后。

**Method:** 2024年BraTS-MEN-RT挑战赛使用了包含750例放疗计划脑部MRI的多机构数据集，这些MRI带有专家标注的脑膜瘤靶区标签。六个参赛团队开发并评估了自动化分割模型。团队排名通过修改后的病灶Dice相似系数（DSC）和95% Hausdorff距离（95HD）进行评估。

**Result:** 最佳报告的平均病灶Dice相似系数（DSC）为0.815，95% Hausdorff距离（95HD）为26.92毫米。

**Conclusion:** BraTS-MEN-RT挑战赛有望通过实现精确的肿瘤分割和促进个性化治疗，显著推动自动化放疗计划的发展，最终改善患者预后。

> **ai_Abstract:** 2024年BraTS-MEN-RT挑战赛旨在利用包含750例脑膜瘤患者MRI的大型多机构数据集，推进放疗计划自动化分割算法。该挑战评估了六个团队开发的模型，采用修改后的Dice相似系数和95% Hausdorff距离作为评估指标。最佳模型的平均Dice系数达到0.815，95% Hausdorff距离为26.92毫米。该挑战有望通过提高肿瘤分割精度来改善放疗计划和患者预后。

> **摘要翻译:** 2024年脑肿瘤分割脑膜瘤放疗（BraTS-MEN-RT）挑战赛旨在利用已知最大的多机构数据集（包含750例放疗计划脑部MRI，带有针对完整或术后脑膜瘤患者的专家标注靶区标签，这些患者接受了常规外束放疗或立体定向放射外科手术）来推动自动化分割算法的发展。每个病例都包含一个经过去识别化的3D增强T1加权放疗计划MRI，位于其原始采集空间中，并附带一个代表总肿瘤体积（GTV）和任何有风险的术后部位的单标签“靶区体积”。靶区体积标注遵循既定的放疗计划协议，确保了病例和机构之间的一致性，并得到了专家神经放射学家和放射肿瘤学家的批准。六个参赛团队利用这个综合数据集开发、容器化并评估了自动化分割模型。团队排名通过修改后的病灶Dice相似系数（DSC）和95% Hausdorff距离（95HD）进行评估。报告的最佳平均病灶Dice相似系数和95HD分别为0.815和26.92毫米。BraTS-MEN-RT有望通过实现精确的肿瘤分割和促进个性化治疗，显著推动自动化放疗计划的发展，最终改善患者预后。我们描述了BraTS-MEN-RT挑战赛的设计和结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [297] [Advancing Visual Large Language Model for Multi-granular Versatile Perception](https://arxiv.org/abs/2507.16213)
> *推进视觉大语言模型用于多粒度通用感知*

*Wentao Xiang, Haoxian Tan, Cong Wei, Yujie Zhong, Dengjie Li, Yujiu Yang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 视觉大语言模型, 多粒度感知, 通用感知, 计算机视觉, 统一框架

**Comment:** To appear in ICCV 2025

> **TL;DR:** MVP-LM是一个用于多粒度通用感知的视觉大语言模型框架，它通过创新的多粒度解码器和数据集统一策略，将多种词语和句子级别的感知任务以及边界框和掩码预测整合到一个架构中。

**AI_Comments:** MVP-LM通过在一个单一的VLLM框架下统一多样的感知任务（包括基于词语/句子、边界框/掩码预测），提供了一种创新的方法。其多粒度解码器和受CoT启发的D数据统一策略是关键创新点，显著增强了模型的通用性和适用性，推动了通用感知模型的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的计算机视觉感知研究通常只关注有限的子任务组合，这限制了它们在不同上下文中的适用性和通用性。

**Method:** 本文提出了MVP-LM，一个结合视觉大语言模型的多粒度通用感知框架。该框架旨在将基于词语和基于句子的感知任务与边界框和掩码预测整合到单一架构中。MVP-LM具有创新的多粒度解码器和受CoT启发的D数据集统一策略，支持对全景分割、检测、接地和指代表达式分割等广泛任务进行无缝监督微调。此外，它还引入了查询增强策略，以利用VLLMs固有的解码和生成能力。

**Result:** 在基于词语和基于句子的感知任务的多个基准测试中进行的广泛实验证实了该框架的有效性。

**Conclusion:** MVP-LM通过提供一个统一、通用且多粒度的视觉大语言模型框架，有效解决了现有感知模型的局限性，并在多种任务中展现了强大的性能。

> **ai_Abstract:** MVP-LM是一个新颖的视觉大语言模型（VLLM）框架，专为多粒度通用感知而设计。它通过将多样化的基于词语和基于句子的感知任务，以及边界框和掩码预测整合到单一架构中，解决了现有模型专注于狭窄感知子任务的局限性。该框架采用多粒度解码器和受CoT启发的D数据集统一策略，可对全景分割、检测等任务进行无缝监督微调。此外，还引入了查询增强策略以利用VLLM的能力。实验证明了其在各种基准测试中的有效性。

> **摘要翻译:** 感知是计算机视觉领域的一项基础任务，它包含一系列多样化的子任务，可以根据预测类型和指令类型这两个维度系统地分为四类。值得注意的是，现有研究往往只专注于这些潜在组合中的有限子集，这限制了它们在各种上下文中的适用性和通用性。为了应对这一挑战，我们提出了MVP-LM，一个结合视觉大语言模型的多粒度通用感知框架。我们的框架旨在将基于词语和基于句子的感知任务以及边界框和掩码预测整合到单一架构中。MVP-LM具有创新的多粒度解码器和受CoT启发的D数据集统一策略，支持对全景分割、检测、接地和指代表达式分割等广泛任务进行无缝监督微调。此外，我们引入了查询增强策略，旨在利用VLLMs固有的解码和生成能力。在基于词语和基于句子的感知任务的多个基准测试中进行的广泛实验证实了我们框架的有效性。代码将在https://github.com/xiangwentao666/MVP-LM上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [MGSR: 2D/3D Mutual-boosted Gaussian Splatting for High-fidelity Surface Reconstruction under Various Light Conditions](https://arxiv.org/abs/2503.05182)
> *MGSR：2D/3D互增强高斯泼溅用于各种光照条件下的高保真表面重建*

*Qingyuan Zhou, Yuehu Gong, Weidong Yang, Jiaze Li, Yeqi Luo, Baixin Xu, Shuhao Li, Ben Fei, Ying He* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 高斯泼溅, 表面重建, 新视角合成, 光照分解, 2D/3D互增强

**Comment:** Accepted at ICCV'25

> **TL;DR:** 提出MGSR，一个2D/3D互增强高斯泼溅方法，同时提高新视角合成的渲染质量和表面重建的准确性，解决了以往渲染和重建之间的权衡问题。

**AI_Comments:** 本文的创新点在于提出了2D-GS和3D-GS的互增强框架，有效地解决了3D高斯泼溅中渲染质量与表面重建精度之间的传统权衡问题。通过引入几何引导的光照分解和分支间的相互监督，MGSR在复杂光照条件下实现了高保真重建和真实感渲染，为3D高斯泼溅的应用拓展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅(3D-GS)中的新视角合成(NVS)和表面重建(SR)任务通常独立解决，导致GS渲染方法在不同光照下表现不佳且表面不准确，而GS重建方法则牺牲渲染质量。这引出了一个问题：渲染和重建是否必须存在权衡？

**Method:** 提出MGSR，包含2D-GS和3D-GS两个分支。2D-GS分支擅长表面重建，为3D-GS分支提供精确几何信息。3D-GS分支利用几何信息，通过几何引导的光照分解模块捕获反射和透射分量，实现多样光照下的真实渲染。2D-GS分支利用透射分量作为监督，实现高保真表面重建。两个分支在优化过程中交替优化，相互监督。在此之前，每个分支完成独立的预热阶段，并采用早停策略降低计算成本。

**Result:** MGSR在合成和真实世界数据集（物体和场景级别）上进行了评估，在渲染和表面重建方面表现出强大的性能。

**Conclusion:** MGSR通过2D/3D互增强的高斯泼溅方法，成功解决了新视角合成和表面重建之间的权衡问题，显著提升了两种任务的质量，尤其是在复杂光照条件下。

> **ai_Abstract:** 本文提出了MGSR，一种2D/3D互增强的高斯泼溅方法，旨在同时提升新视角合成的渲染质量和3D表面重建的精度，以解决现有方法中渲染与重建之间的权衡问题。MGSR包含一个擅长表面重建的2D-GS分支和一个利用几何信息进行光照分解以实现真实渲染的3D-GS分支。两个分支通过交替优化和相互监督，实现高保真表面重建和多样光照下的高质量渲染。实验证明MGSR在渲染和表面重建方面均表现出色。

> **摘要翻译:** 新视角合成（NVS）和表面重建（SR）是3D高斯泼溅（3D-GS）中的核心任务。尽管近期取得了进展，但这些任务通常是独立解决的，基于GS的渲染方法在不同光照条件下表现不佳且无法生成精确的表面，而基于GS的重建方法则经常牺牲渲染质量。这引出了一个核心问题：渲染和重建是否必须总是涉及权衡？为了解决这个问题，我们提出了MGSR，一种用于表面重建的2D/3D互增强高斯泼溅方法，它同时提高了渲染质量和3D重建精度。MGSR引入了两个分支——一个基于2D-GS，另一个基于3D-GS。2D-GS分支擅长表面重建，为3D-GS分支提供精确的几何信息。利用这些几何信息，3D-GS分支采用几何引导的光照分解模块，捕获反射和透射分量，从而在各种光照条件下实现逼真的渲染。2D-GS分支还利用透射分量作为监督，实现了高保真表面重建。在整个优化过程中，2D-GS和3D-GS分支进行交替优化，提供相互监督。在此之前，每个分支都完成了独立的预热阶段，并实施了早停策略以降低计算成本。我们在合成和真实世界数据集上（包括物体和场景级别）评估了MGSR，展示了在渲染和表面重建方面的强大性能。代码可在https://github.com/TsingyuanChou/MGSR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [301] [Watermark Anything with Localized Messages](https://arxiv.org/abs/2411.07231)
> *使用局部消息水印任何内容*

*Tom Sander, Pierre Fernandez, Alain Durmus, Teddy Furon, Matthijs Douze* | **Category: cs.CV, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 图像水印, 深度学习, 局部水印, WAM, 鲁棒性

**Comment:** ICLR 2025

> **TL;DR:** Watermark Anything Model (WAM)是一种深度学习模型，用于处理小范围水印区域，能够识别水印区域并从中提取消息，即使在图像经过修复或拼接后也能保持隐蔽性和鲁棒性。

**AI_Comments:** WAM的创新之处在于其对小范围水印区域的处理能力，这显著扩展了图像水印在实际应用中的场景，特别是对于图像拼接和编辑后的内容溯源具有重要意义。其能够定位水印区域并从多个独立小区域提取不同消息的能力是现有技术的显著进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像水印方法不适用于小范围的水印区域，这限制了它们在图像部分可能来自不同来源或经过编辑的实际场景中的应用。

**Method:** 本文引入了一种名为Watermark Anything Model (WAM)的深度学习模型，用于局部图像水印。WAM嵌入器能隐蔽地修改输入图像，而提取器则将接收到的图像分割成水印和非水印区域，并从水印区域中恢复一个或多个隐藏消息。模型在低分辨率下进行联合训练，不设感知约束，然后进行后训练以提高隐蔽性和支持多水印。

**Result:** 实验表明，WAM在隐蔽性和鲁棒性方面与最先进的方法具有竞争力，尤其是在对抗图像修复和拼接方面，即使在高分辨率图像上也是如此。此外，WAM还能定位拼接图像中的水印区域，并从多个小于图像表面10%的小区域中提取不同的32位消息，误差小于1位，即使对于256x256的小图像也能实现。

**Conclusion:** WAM是一种有效的局部图像水印方法，在隐蔽性、鲁棒性和处理小区域水印方面表现出色，并提供了定位水印区域和从多区域提取消息的新能力。

> **ai_Abstract:** 本文提出了一种名为Watermark Anything Model (WAM)的深度学习模型，旨在解决现有图像水印方法在处理小范围水印区域时的不足。WAM能够隐蔽地在图像中嵌入水印，并通过其提取器识别图像中的水印区域并恢复隐藏消息。该模型通过联合训练和后训练优化了隐蔽性和鲁棒性，特别是在对抗图像修复和拼接方面表现出色。WAM还具备定位拼接图像中水印区域以及从多个小区域提取不同消息的能力，即使在小尺寸图像上也能实现高精度。

> **摘要翻译:** 图像水印方法不适用于处理小范围的水印区域。这限制了其在图像部分可能来自不同来源或经过编辑的实际场景中的应用。我们引入了一种用于局部图像水印的深度学习模型，名为“水印任何内容模型”（WAM）。WAM嵌入器能隐蔽地修改输入图像，而提取器则将接收到的图像分割成水印和非水印区域，并从水印区域中恢复一个或多个隐藏消息。模型在低分辨率下进行联合训练，不设感知约束，然后进行后训练以提高隐蔽性和支持多水印。实验表明，WAM在隐蔽性和鲁棒性方面与最先进的方法具有竞争力，尤其是在对抗图像修复和拼接方面，即使在高分辨率图像上也是如此。此外，WAM还提供了新功能：WAM可以定位拼接图像中的水印区域，并从多个小于图像表面10%的小区域中提取不同的32位消息，误差小于1位，即使对于256x256的小图像也能实现。训练和推理代码以及模型权重可在https://github.com/facebookresearch/watermark-anything获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [303] [Sparse-View 3D Reconstruction: Recent Advances and Open Challenges](https://arxiv.org/abs/2507.16406)
> *稀疏视角三维重建：最新进展与开放挑战*

*Tanveer Younis, Zhanglin Cheng* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 稀疏视角三维重建, 神经隐式模型, 3D Gaussian Splatting, 扩散模型, 综述

**Comment:** 30 pages, 6 figures

> **TL;DR:** 该综述回顾了稀疏视角三维重建领域的最新进展，包括神经隐式模型、显式点云方法和混合框架，并探讨了几何正则化、显式形状建模和生成推理如何解决稀疏视角问题，分析了重建精度、效率和泛化能力之间的权衡，并指出了领域泛化和无姿态重建等未来挑战。

**AI_Comments:** 本综述的创新之处在于其对稀疏视角三维重建领域提供了一个统一的视角，整合了基于几何、神经隐式和生成（扩散）方法。它不仅总结了最新进展，更重要的是，明确指出了领域泛化和无姿态重建等开放挑战，并展望了未来3D原生生成先验和实时重建的发展方向，对于推动该领域的研究具有重要的指导意义。其价值在于为研究人员提供了一个全面的现状分析和未来的研究路线图。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人、增强/虚拟现实（AR/VR）和自动驾驶系统等应用中，密集图像采集不切实际，因此稀疏视角三维重建至关重要。在这种设置下，图像重叠度低导致传统方法（如SfM和MVS）因无法可靠匹配对应点而失效。

**Method:** 本综述回顾了神经隐式模型（如NeRF及其正则化版本）、显式点云方法（如3D Gaussian Splatting）以及利用扩散模型和视觉基础模型（VFMs）先验的混合框架的最新进展。论文分析了几何正则化、显式形状建模和生成推理如何用于减轻稀疏视角设置下的浮点和姿态模糊等伪影。与以往综述不同，本文对基于几何、神经隐式和生成（基于扩散）方法提供了统一的视角。

**Result:** 在标准基准上的比较结果揭示了重建精度、效率和泛化能力之间的关键权衡。

**Conclusion:** 本文强调了领域泛化和无姿态重建方面的持续挑战，并概述了开发3D原生生成先验以及实现实时、无约束稀疏视角重建的未来方向。

> **ai_Abstract:** 本综述关注稀疏视角三维重建，该技术在图像采集受限的实际应用中至关重要，解决了传统SfM和MVS方法在图像重叠不足时的失效问题。文章回顾了神经隐式模型、显式点云方法和混合框架的最新进展，并探讨了几何正则化、显式形状建模和生成推理在减轻重建伪影方面的作用。通过对标准基准的比较分析，揭示了精度、效率和泛化能力间的权衡。本综述提供了一个统一的视角，涵盖基于几何、神经隐式和生成方法，并指出了领域泛化和无姿态重建等持续挑战，为未来开发3D原生生成先验和实现实时、无约束重建提供了方向。

> **摘要翻译:** 稀疏视角三维重建对于密集图像采集不切实际的应用至关重要，例如机器人、增强/虚拟现实（AR/VR）和自动系统。在这些设置中，最小的图像重叠会阻碍可靠的对应点匹配，导致传统方法，如运动结构恢复（SfM）和多视图立体（MVS），失效。本综述回顾了神经隐式模型（例如NeRF及其正则化版本）、显式点云方法（例如3D Gaussian Splatting）以及利用扩散和视觉基础模型（VFMs）先验的混合框架的最新进展。我们分析了几何正则化、显式形状建模和生成推理如何用于减轻稀疏视角设置下的浮点和姿态模糊等伪影。标准基准上的比较结果揭示了重建精度、效率和泛化能力之间的关键权衡。与以往的综述不同，我们的综述对基于几何、神经隐式和生成（基于扩散）方法提供了统一的视角。我们强调了领域泛化和无姿态重建方面的持续挑战，并概述了开发3D原生生成先验以及实现实时、无约束稀疏视角重建的未来方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [304] [HarmonPaint: Harmonized Training-Free Diffusion Inpainting](https://arxiv.org/abs/2507.16732)
> *谐调画笔：和谐的免训练扩散修复*

*Ying Li, Xinzhe Li, Yong Du, Yangyang Xu, Junyu Dong, Shengfeng He* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 图像修复, 扩散模型, 免训练, 注意力机制, 风格迁移

**Comment:** 

> **TL;DR:** HarmonPaint是一种免训练的扩散修复框架，通过利用扩散模型的注意力机制，实现结构和风格和谐的高质量图像修复。

**AI_Comments:** 这篇论文的创新点在于提出了一个“免训练”的图像修复框架，这显著降低了模型部署和适应新场景的成本。通过巧妙地利用扩散模型的内在特性（注意力机制和风格传输能力），它解决了传统修复方法在结构和风格一致性方面的痛点。其训练无关的特性是其重要性所在，使得模型更加灵活和实用。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像修复方法需要大量再训练或微调才能无缝整合新内容，并且难以在修复区域和背景之间保持结构和风格的一致性。

**Method:** HarmonPaint是一个免训练的修复框架，它与扩散模型的注意力机制无缝集成。它通过在自注意力中使用掩码策略来确保结构保真度，并通过利用固有的扩散模型特性将风格信息从未掩码区域传输到掩码区域，从而实现风格的和谐整合。

**Result:** 广泛的实验证明了HarmonPaint在不同场景和风格下的有效性，验证了其多功能性和性能。

**Conclusion:** HarmonPaint通过其免训练的方法，在结构和风格上实现了高质量、和谐的图像修复，并在多样化的场景中表现出强大的有效性和多功能性。

> **ai_Abstract:** HarmonPaint提出了一种免训练的图像修复框架，旨在解决现有方法在结构和风格一致性方面的不足。它利用扩散模型的注意力机制和掩码策略来保持结构完整性，并通过传输风格信息实现风格和谐。实验证明了其在多种场景和风格下的有效性和通用性，无需任何训练即可提供高质量的修复结果。

> **摘要翻译:** 现有图像修复方法通常需要大量的再训练或微调才能无缝集成新内容，但它们难以在修复区域和周围背景之间保持结构和风格的一致性。受这些限制的启发，我们引入了HarmonPaint，一个免训练的修复框架，它与扩散模型的注意力机制无缝集成，无需任何形式的训练即可实现高质量、和谐的图像修复。通过利用自注意力中的掩码策略，HarmonPaint在无需模型再训练或微调的情况下确保了结构保真度。此外，我们利用固有的扩散模型特性将风格信息从未掩码区域传输到掩码区域，从而实现风格的和谐整合。广泛的实验证明了HarmonPaint在不同场景和风格下的有效性，验证了其多功能性和性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [315] [INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling](https://arxiv.org/abs/2507.05056)
> *INTER：通过交互指导采样缓解大型视觉-语言模型中的幻觉*

*Xin Dong, Shichao Dong, Jin Wang, Jing Huang, Li Zhou, Zenghui Sun, Lihua Jing, Jingsong Lan, Xiaoyong Zhu, Bo Zheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大型视觉-语言模型, 幻觉缓解, 多模态交互, 无需训练算法, INTER

**Comment:** Accepted by ICCV 2025

> **TL;DR:** INTER是一种无需训练的新算法，通过指导LVLMs有效利用多模态交互信息来减少幻觉，在多个基准测试上表现优于现有技术。

**AI_Comments:** INTER的创新之处在于它是一种无需训练的算法，通过模拟人类认知中对多模态交互的利用来缓解LVLM的幻觉，这在效率和实用性上具有重要意义。其无需额外数据的特性也降低了实施门槛。该方法提出了一种新颖的指导策略，有效提升了LVLM的可靠性，对实际应用具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）中的幻觉问题对实际应用构成重大挑战，因为它们可能生成看似合理但与视觉内容不一致的响应。研究者认为这与人类有效利用多模态交互信息的能力差异有关，人类通常先收集多模态信息，分析交互以理解，然后用语言表达理解。

**Method:** 受人类认知启发，作者提出了INTER（交互指导采样），这是一种新颖的、无需训练的算法，无需额外数据即可缓解幻觉。INTER明确指导LVLMs在生成响应时有效重新应用其对多模态交互信息的理解，从而减少潜在的幻觉。

**Result:** 在包括VQA和图像描述任务在内的六个基准测试中，INTER与最先进的解码策略相比，在五个LVLM上平均提高了高达3.4%。

**Conclusion:** INTER通过指导大型视觉-语言模型有效利用多模态交互信息，成功缓解了幻觉问题，并在多个基准测试中取得了显著改进。

> **ai_Abstract:** 本文提出了一种名为INTER（交互指导采样）的新型无需训练算法，旨在缓解大型视觉-语言模型（LVLMs）中的幻觉问题。研究者观察到人类在理解多模态信息时会有效利用模态间的交互，并发现LVLMs也表现出类似但较弱的认知行为。受此启发，INTER通过明确指导LVLMs在生成响应时重新利用其对多模态交互信息的理解，从而减少幻觉。在VQA和图像描述等六个基准测试中，INTER在五个LVLMs上相较于现有解码策略平均实现了3.4%的性能提升。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）中的幻觉问题对实际应用构成了重大挑战，因为LVLMs可能会生成看似合理但与相关视觉内容不一致的响应。这个问题在人类认知中很少发生。我们认为这种差异源于人类有效利用数据样本中多模态交互信息的能力。具体来说，人类通常首先收集多模态信息，分析跨模态的交互以进行理解，然后通过语言表达他们的理解。受此观察启发，我们对流行的LVLMs进行了广泛实验，并获得了令人惊讶的见解，揭示了LVLMs在多模态样本上存在类似人类但不太明显的认知行为。基于这些发现，我们进一步提出了INTER：交互指导采样，这是一种新颖的、无需训练的算法，无需额外数据即可缓解幻觉。具体来说，INTER明确指导LVLMs在生成响应时有效重新应用其对多模态交互信息的理解，从而减少潜在的幻觉。在包括VQA和图像描述任务在内的六个基准测试中，与最先进的解码策略相比，INTER在五个LVLM上平均提高了高达3.4%。论文被接受后将发布代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [325] [USP: Unified Self-Supervised Pretraining for Image Generation and Understanding](https://arxiv.org/abs/2503.06132)
> *USP：图像生成与理解的统一自监督预训练*

*Xiangxiang Chu, Renda Li, Yong Wang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 统一自监督预训练, 扩散模型, 图像生成, 图像理解, 潜在空间

**Comment:** Accepted to ICCV2025

> **TL;DR:** USP是一个统一的自监督预训练框架，通过在VAE潜在空间中进行掩码潜在建模，解决了视觉模型到扩散模型权重迁移的挑战，显著提升了扩散模型的收敛速度和生成质量。

**AI_Comments:** USP的创新之处在于其统一的自监督预训练方法，通过在VAE潜在空间进行掩码潜在建模，有效桥接了自监督视觉模型和扩散模型之间的差距。这不仅提高了扩散模型的效率和性能，也为未来图像生成和理解任务的融合提供了新的思路。其重要性体现在它为利用现有视觉模型预训练能力来加速和优化扩散模型训练提供了一条可行路径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型与表示学习之间存在相互作用潜力，但将自监督视觉模型的预训练权重迁移到扩散模型时，由于输入不匹配和潜在空间的使用，面临挑战。

**Method:** 提出了统一自监督预训练（USP）框架，通过在变分自编码器（VAE）潜在空间中进行掩码潜在建模来初始化扩散模型。

**Result:** USP在理解任务中取得了可比的性能，同时显著提高了扩散模型的收敛速度和生成质量。

**Conclusion:** USP框架有效解决了视觉模型到扩散模型权重迁移的挑战，实现了在图像生成和理解任务上的统一且高性能的预训练。

> **ai_Abstract:** 本文提出了统一自监督预训练（USP）框架，旨在解决自监督视觉模型预训练权重向扩散模型迁移时遇到的输入不匹配和潜在空间使用问题。USP通过在VAE潜在空间中进行掩码潜在建模来初始化扩散模型。实验结果表明，USP在保持理解任务性能的同时，显著提升了扩散模型的收敛速度和生成质量。

> **摘要翻译:** 最近的研究强调了扩散模型与表示学习之间的相互作用。扩散模型的中间表示可以用于下游视觉任务，而自监督视觉模型可以提高扩散模型的收敛性和生成质量。然而，由于输入不匹配和潜在空间的使用，将预训练权重从视觉模型迁移到扩散模型具有挑战性。为了解决这些挑战，我们提出了统一自监督预训练（USP），这是一个通过在变分自编码器（VAE）潜在空间中进行掩码潜在建模来初始化扩散模型的框架。USP在理解任务中取得了可比的性能，同时显著提高了扩散模型的收敛速度和生成质量。我们的代码将在 https://github.com/AMAP-ML/USP 公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [326] [Is Tracking really more challenging in First Person Egocentric Vision?](https://arxiv.org/abs/2507.16015)
> *第一人称自我中心视觉中的跟踪真的更具挑战性吗？*

*Matteo Dunnhofer, Zaira Manigrasso, Christian Micheloni* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 自我中心视觉, 对象跟踪, 对象分割, 基准测试, 第一人称视角

**Comment:** 2025 IEEE/CVF International Conference on Computer Vision (ICCV)

> **TL;DR:** 研究质疑第一人称自我中心视觉跟踪的挑战是否真的源于视角本身，并提出了一个新的基准来分离相关因素。

**AI_Comments:** 本文的创新点在于提出了一个旨在分离第一人称视角和人-物体活动领域影响的新基准研究。这对于深入理解自我中心视觉任务的真正挑战来源至关重要，有助于研究人员更精准地改进算法，避免将问题归因于不相关的因素。其方法论对于未来基准测试的设计具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的研究认为第一人称自我中心视觉比其他领域更具挑战性，但这些评估是在显著不同的场景下进行的。作者认为，许多挑战可能并非源于第一人称视角，而是源于人-物体活动领域本身。因此，需要探究观察到的性能下降的真正原因。

**Method:** 为了解决这个问题，本文引入了一个新的基准研究，旨在分离第一人称视角和人-物体活动领域带来的挑战。其评估策略能够更精确地分离这些因素。

**Result:** 该研究旨在通过新的评估策略，提供对自我中心跟踪和分割中真正困难来源的更深入见解，从而区分第一人称视角和人-物体活动领域带来的挑战。

**Conclusion:** 本文通过提供对自我中心跟踪和分割中真正困难来源的深入见解，旨在促进该任务更具针对性的进展。

> **ai_Abstract:** 本文探讨了第一人称自我中心视觉中对象跟踪和分割的挑战来源。现有研究认为自我中心视觉更具挑战性，但作者质疑这些挑战是否真的源于独特的视角，而非人-物体活动领域本身。为解决此问题，论文提出了一个新的基准研究和评估策略，旨在精确分离第一人称视角和人-物体活动领域对性能下降的影响，以期深入理解真正的困难来源，从而推动更具针对性的研究进展。

> **摘要翻译:** 视觉对象跟踪和分割正成为理解自我中心视觉中人类活动的基本任务。最近的研究已经对最先进的方法进行了基准测试，并得出结论认为，与之前研究的领域相比，第一人称自我中心视觉带来了挑战。然而，这些主张是基于在显著不同场景下进行的评估。许多归因于自我中心视觉的挑战性特征也存在于人-物体活动的第三人称视频中。这提出了一个关键问题：观察到的性能下降有多少源于自我中心视觉固有的独特第一人称视角，有多少源于人-物体活动领域？为了解决这个问题，我们引入了一项新的基准研究，旨在分离这些因素。我们的评估策略能够更精确地分离与第一人称视角相关的挑战和与更广泛的人-物体活动理解领域相关的挑战。通过这样做，我们提供了对自我中心跟踪和分割中真正困难来源的更深入见解，从而促进该任务更具针对性的进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [333] [Combined Image Data Augmentations diminish the benefits of Adaptive Label Smoothing](https://arxiv.org/abs/2507.16427)
> *组合图像数据增强降低了自适应标签平滑的效益*

*Georg Siedel, Ekagra Gupta, Weijia Shao, Silvia Vock, Andrey Morozov* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 自适应标签平滑, 数据增强, 图像分类器, 正则化, 鲁棒性

**Comment:** Preprint submitted to the Fast Review Track of DAGM German Conference
  on Pattern Recognition (GCPR) 2025

> **TL;DR:** 结合多种图像数据增强会削弱自适应标签平滑的优势，该方法只适用于有限且同质的图像变换类型。

**AI_Comments:** 这篇论文揭示了自适应标签平滑（Adaptive Label Smoothing）在与多种图像数据增强方法结合使用时可能出现的局限性。其创新点在于将该方法扩展到随机擦除和噪声注入等非随机裁剪增强，并明确指出了过度或不当使用标签平滑的负面影响。这对于实践中选择数据增强策略和正则化方法具有重要的指导意义，提醒研究者和工程师在应用自适应标签平滑时需考虑数据增强的多样性。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在将自适应标签平滑框架扩展到随机裁剪之外的其他激进数据增强类型，并探索其在结合多种图像变换时的效果。

**Method:** 研究人员将自适应标签平滑框架应用于随机擦除和噪声注入等数据增强方法，并通过与最先进的TrivialAugment等多样化图像变换方法结合进行测试。

**Result:** 自适应标签平滑对于随机擦除和噪声注入数据增强有效；它允许通过更高强度的随机擦除进行更强的正则化；当与TrivialAugment等多种图像变换结合使用时，其益处消失；过度的标签平滑会损害模型对常见损坏的鲁棒性。

**Conclusion:** 自适应标签平滑只应在训练数据分布主要由有限、同质的图像变换类型主导时应用。

> **ai_Abstract:** 本文将自适应标签平滑框架扩展到随机裁剪之外的多种激进数据增强（如随机擦除和噪声注入），并验证了其有效性。研究发现，自适应标签平滑能通过高强度随机擦除实现更强正则化。然而，当与TrivialAugment等多样化图像变换结合时，其优势消失，且过度平滑会损害模型鲁棒性。因此，建议仅在训练数据由有限且同质的图像变换类型主导时使用自适应标签平滑。

> **摘要翻译:** 软增强通过根据训练样本应用的随机裁剪增强的幅度来降低其标签置信度，从而规范图像分类器的监督学习过程。本文将这种自适应标签平滑框架扩展到随机裁剪之外的其他类型的激进增强。具体来说，我们证明了该方法对于随机擦除和噪声注入数据增强的有效性。自适应标签平滑允许通过更高强度的随机擦除实现更强的正则化。然而，当与最先进的TrivialAugment方法中那样多样化的图像变换结合使用时，其益处就会消失，并且过度的标签平滑会损害对常见损坏的鲁棒性。我们的研究结果表明，自适应标签平滑只应在训练数据分布主要由有限、同质的图像变换类型主导时应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [334] [Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning](https://arxiv.org/abs/2507.16746)
> *Zebra-CoT：一个用于交错视觉语言推理的数据集*

*Ang Li, Charles Wang, Kaiyu Yue, Zikui Cai, Ollie Liu, Deqing Fu, Peng Guo, Wang Bill Zhu, Vatsal Sharan, Robin Jia, Willie Neiswanger, Furong Huang, Tom Goldstein, Micah Goldblum* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** Zebra-CoT, 视觉思维链, 多模态推理, 数据集, 视觉语言推理

**Comment:** dataset link:
  https://huggingface.co/datasets/multimodal-reasoning-lab/Zebra-CoT

> **TL;DR:** 该论文介绍了Zebra-CoT，一个包含交错文本-图像推理轨迹的大型数据集，旨在提高多模态模型的视觉思维链（Visual CoT）性能，微调后显示出显著的性能提升。

**AI_Comments:** 这篇论文通过提供一个大规模、高质量的视觉思维链（Visual CoT）专用数据集，做出了重要贡献。其交错的文本-图像推理轨迹具有创新性，模拟了人类解决问题的方式。实验结果表明，该数据集能够显著提升现有模型的性能，突显了其在推动多模态推理发展方面的实用价值。数据集和模型的开源对于社区发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 训练多模态模型进行视觉思维链（Visual CoT）面临挑战，主要问题是现成视觉CoT性能不佳以及缺乏高质量的训练数据。

**Method:** 引入了Zebra-CoT，一个多样化的大规模数据集，包含182,384个样本，具有逻辑连贯的交错文本-图像推理轨迹。该数据集专注于四类需要视觉推理的任务。通过在Zebra-CoT训练语料库上对Anole-7B和Bagel-7B模型进行微调。

**Result:** 在Zebra-CoT上对Anole-7B模型进行微调，测试集准确率提高了+12%，并在标准VLM基准评估中获得了高达+13%的性能提升。对Bagel-7B进行微调，得到了一个能够生成高质量交错视觉推理链的模型。

**Conclusion:** Zebra-CoT数据集在开发多模态推理能力方面是有效的。该数据集和模型已开源，以支持视觉CoT的开发和评估。

> **ai_Abstract:** 本文介绍了Zebra-CoT，一个包含182,384个样本的大规模数据集，其中包含交错的文本-图像推理轨迹，旨在解决当前视觉思维链（Visual CoT）模型面临的挑战，特别是高质量训练数据的缺乏和现成性能不佳的问题。该数据集涵盖了从科学问题到策略游戏等多种需要视觉推理的任务。在Zebra-CoT上对Anole-7B和Bagel-7B等模型进行微调，显著提高了测试准确性和基准性能，证明了其在增强多模态推理能力方面的有效性。数据集和模型均已开源。

> **摘要翻译:** 人类在解决复杂问题时经常使用视觉辅助，例如图表或草图。训练多模态模型也这样做，即视觉思维链（Visual CoT），面临挑战，原因如下：(1) 现成视觉CoT性能不佳，这阻碍了强化学习；(2) 缺乏高质量的视觉CoT训练数据。我们引入了 Zebra-CoT，一个多样化的大规模数据集，包含182,384个样本，其中包含逻辑连贯的交错文本-图像推理轨迹。我们专注于四类任务，其中素描或视觉推理尤其自然，涵盖了科学问题，如几何、物理和算法；2D视觉推理任务，如视觉搜索和拼图；3D推理任务，包括3D多跳推理、具身和机器人规划；视觉逻辑问题和国际象棋等策略游戏。在Zebra-CoT训练语料库上对Anole-7B模型进行微调，使我们的测试集准确率提高了+12%，并在标准VLM基准评估中获得了高达+13%的性能提升。对Bagel-7B进行微调，得到了一个能够生成高质量交错视觉推理链的模型，这突显了Zebra-CoT在开发多模态推理能力方面的有效性。我们开源了我们的数据集和模型，以支持视觉CoT的开发和评估。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [339] [DFR: A Decompose-Fuse-Reconstruct Framework for Multi-Modal Few-Shot Segmentation](https://arxiv.org/abs/2507.16736)
> *DFR：一种用于多模态小样本分割的分解-融合-重建框架*

*Shuai Chen, Fanman Meng, Xiwei Zhang, Haoran Wei, Chenhao Wu, Qingbo Wu, Hongliang Li* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 多模态, 小样本分割, DFR, 分解融合重建, SAM

**Comment:** 3 figures

> **TL;DR:** DFR是一个新颖的框架，通过分解、融合和重建视觉、文本和音频模态，显著提升了多模态小样本分割的性能。

**AI_Comments:** DFR框架的创新性在于其全面整合视觉、文本和音频三模态信息的能力，这超越了现有方法的局限性。结合SAM进行视觉区域提取，并通过对比学习进行模态融合，以及独特的双路径重建机制，使其在多模态小样本分割领域具有重要意义和潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的小样本分割方法主要依赖单一或双模态（视觉支持样本或文本描述），这限制了对真实世界中丰富感知信息的利用。本研究旨在克服这一局限性，有效利用多模态指导。

**Method:** 本文提出了DFR（Decompose, Fuse and Reconstruct）框架，通过整合视觉、文本和音频模态来增强语义理解。该框架包含三个核心创新：1) 多模态分解：通过SAM提取视觉区域，扩展文本语义，并处理音频特征；2) 多模态对比融合：采用对比学习保持模态间一致性，并实现前景背景特征的动态语义交互；3) 双路径重建：结合三模态融合的语义指导和多模态位置先验的几何线索。

**Result:** 在视觉、文本和音频模态下的合成和真实设置中进行了广泛实验，结果表明DFR的性能显著优于现有最先进的方法。

**Conclusion:** DFR框架通过有效整合视觉、文本和音频多模态信息，显著提升了小样本分割的性能，克服了现有方法的模态利用局限性。

> **ai_Abstract:** DFR是一个新颖的多模态小样本分割框架，旨在克服现有方法对单一或双模态信息的利用限制。它通过利用SAM，并引入多模态分解、多模态对比融合和双路径重建三大创新，系统地整合视觉、文本和音频模态。实验证明，DFR在多模态小样本分割任务上显著优于现有技术。

> **摘要翻译:** 本文提出了DFR（分解、融合和重建），一个新颖的框架，旨在解决小样本分割（FSS）中有效利用多模态指导的根本挑战。虽然现有方法主要依赖视觉支持样本或文本描述，但其单一或双模态范式限制了对真实世界场景中丰富感知信息的利用。为了克服这一限制，所提出的方法利用Segment Anything Model（SAM）系统地整合视觉、文本和音频模态，以增强语义理解。DFR框架引入了三项关键创新：1）多模态分解：一种分层分解方案，通过SAM提取视觉区域提议，将文本语义扩展为细粒度描述符，并处理音频特征以丰富上下文；2）多模态对比融合：一种融合策略，采用对比学习保持视觉、文本和音频模态之间的一致性，同时实现前景和背景特征之间的动态语义交互；3）双路径重建：一种自适应集成机制，将来自三模态融合令牌的语义指导与来自多模态位置先验的几何线索相结合。在合成和真实设置下，对视觉、文本和音频模态进行了广泛实验，结果表明DFR的性能比现有最先进的方法有实质性改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [348] [CP-uniGuard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
> *CP-uniGuard：一种用于多智能体具身感知系统中恶意智能体检测与防御的统一、概率无关、自适应框架*

*Senkang Hu, Yihang Tao, Guowen Xu, Xinyuan Qian, Yiqin Deng, Xianhao Chen, Sam Tak Wu Kwong, Yuguang Fang* | **Category: cs.CV, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 协同感知, 恶意智能体检测, 多智能体系统, 安全, 自适应框架

**Comment:** 

> **TL;DR:** CP-uniGuard是一个统一、概率无关、自适应的框架，用于在多智能体协同感知系统中检测和防御恶意智能体。

**AI_Comments:** CP-uniGuard创新性地提出了一个统一、概率无关且自适应的框架，解决了协同感知系统中恶意智能体检测的关键挑战。其引入的PASAC、CCLoss和在线自适应阈值机制，在不依赖先验概率的情况下，有效地实现了共识验证，增强了系统在动态环境下的鲁棒性。该研究对于提升多智能体系统，特别是自动驾驶领域的安全性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 协同感知（CP）技术在多智能体自动驾驶和机器人系统中具有广阔前景，但智能体间的信息共享使其易受恶意智能体的攻击，这带来了关键的安全问题。

**Method:** 本文提出了一个名为CP-uniGuard的统一、概率无关、自适应框架，作为每个智能体部署的定制防御机制，旨在准确检测并消除协作网络中的恶意智能体。其核心思想是使CP系统针对自我智能体的感知结果达成共识而非冲突。具体方法包括：1. 开发了概率无关样本共识（PASAC）方法，无需恶意智能体先验概率即可有效采样协作者子集并验证共识。2. 为目标检测任务和鸟瞰图（BEV）分割任务定义了协同一致性损失（CCLoss），用以捕捉自我智能体与协作者之间的差异，并作为共识验证标准。3. 提出了基于双滑动窗口的在线自适应阈值方法，以动态调整共识验证阈值，确保系统在动态环境中的可靠性。

**Result:** 通过广泛的实验，证明了所提出框架的有效性。

**Conclusion:** CP-uniGuard框架能够有效检测和消除多智能体协同感知系统中的恶意智能体，从而解决了系统易受攻击的关键问题，并确保了系统在动态环境中的可靠性。

> **ai_Abstract:** 本文提出了CP-uniGuard，一个统一、概率无关、自适应的框架，旨在解决多智能体协同感知系统（如自动驾驶和机器人系统）中因信息共享而产生的恶意智能体攻击问题。该框架部署在每个智能体上，通过促使系统达成共识而非冲突来检测和消除恶意智能体。CP-uniGuard包含概率无关样本共识（PASAC）方法、用于对象检测和BEV分割的协同一致性损失（CCLoss）以及基于双滑动窗口的在线自适应阈值调整机制。广泛的实验证明了该框架在动态环境中有效检测和防御恶意智能体的能力。

> **摘要翻译:** 协同感知（CP）已被证明是多智能体自动驾驶和多智能体机器人系统中有前景的技术，其中多个智能体共享其感知信息以增强整体感知性能并扩大感知范围。然而，在CP中，自我智能体需要接收来自其协作者的消息，这使其易受恶意智能体攻击。为了解决这个关键问题，我们提出了一个统一的、概率无关的、自适应的框架，即CP-uniGuard，它是一种为CP量身定制的防御机制，由每个智能体部署，以准确检测并消除其协作网络中的恶意智能体。我们的核心思想是使CP系统能够达成共识，而不是与自我智能体的感知结果产生冲突。基于这一思想，我们首先开发了一种概率无关样本共识（PASAC）方法，以有效地采样协作者子集，并在没有恶意智能体先验概率的情况下验证共识。此外，我们针对目标检测任务和鸟瞰图（BEV）分割任务定义了协同一致性损失（CCLoss），以捕获自我智能体与其协作者之间的差异，并将其用作共识的验证标准。此外，我们提出了通过双滑动窗口的在线自适应阈值，以动态调整共识验证的阈值，并确保系统在动态环境中的可靠性。最后，我们进行了广泛的实验，并证明了我们框架的有效性。代码将在https://github.com/CP-Security/CP-uniGuard发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection](https://arxiv.org/abs/2507.16224)
> *LDRFusion：一种LiDAR主导的多模态细化框架，用于3D目标检测*

*Jijun Wang, Yan Wu, Yujian Mo, Junqiao Zhao, Jun Yan, Yinghao Hu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 3D目标检测, LiDAR-Camera融合, 伪点云, LDRFusion, 细化框架

**Comment:** 

> **TL;DR:** LDRFusion提出了一种新的LiDAR主导的两阶段3D目标检测框架，通过分阶段融合LiDAR和伪点云，并引入分层伪点残差编码模块，有效解决了现有方法中伪点引入噪声导致检测不准确的问题。

**AI_Comments:** 该论文提出了一种创新的两阶段LiDAR主导融合策略，有效缓解了伪点云引入的噪声问题，同时利用其辅助信息处理困难案例。其分层伪点残差编码模块是提升伪点云特征表示的关键创新点，为多模态融合3D目标检测领域提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LiDAR-相机融合方法在3D目标检测中通过深度补全构建空间伪点云作为辅助输入，但引入的伪点不可避免地带来噪声，可能导致不准确的预测。

**Method:** 本文提出了LDRFusion，一种新颖的LiDAR主导的两阶段多传感器融合细化框架。第一阶段仅依靠LiDAR生成准确定位的提议；第二阶段引入伪点云来检测具有挑战性的实例。两个阶段的实例级结果随后合并。为进一步增强伪点云中局部结构的表示，提出了一个分层伪点残差编码模块，使用特征和位置残差编码邻域集。

**Result:** 在KITTI数据集上的实验表明，该框架在多个类别和难度级别上持续取得了优异的性能。

**Conclusion:** LDRFusion通过LiDAR主导的两阶段融合策略和伪点残差编码模块，有效利用了LiDAR的可靠性并解决了伪点引入噪声的问题，从而在3D目标检测中实现了强大的性能。

> **ai_Abstract:** LDRFusion是一种新颖的LiDAR主导的两阶段多模态细化框架，用于3D目标检测。它旨在解决现有LiDAR-相机融合方法中伪点引入噪声导致预测不准确的问题。该框架的第一阶段仅使用LiDAR生成准确的提议，第二阶段则结合伪点云来检测困难实例，并最终合并两阶段结果。此外，LDRFusion引入了一个分层伪点残差编码模块，以增强伪点云的局部结构表示。在KITTI数据集上的实验证明了其在不同类别和难度下均能实现强大的性能。

> **摘要翻译:** 现有的LiDAR-相机融合方法在3D目标检测中取得了显著成果。为了解决点云的稀疏性问题，之前的方法通常通过深度补全构建空间伪点云作为辅助输入，并采用提议-细化框架来生成检测结果。然而，引入伪点不可避免地带来噪声，可能导致不准确的预测。考虑到每种模态的不同作用和可靠性水平，我们提出了LDRFusion，一种新颖的LiDAR主导的两阶段细化框架，用于多传感器融合。第一阶段仅依靠LiDAR生成准确定位的提议，随后是第二阶段，其中结合伪点云来检测具有挑战性的实例。然后合并来自两个阶段的实例级结果。为了进一步增强伪点云中局部结构的表示，我们提出了一个分层伪点残差编码模块，该模块使用特征和位置残差编码邻域集。在KITTI数据集上的实验表明，我们的框架在多个类别和难度级别上持续取得了优异的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [352] [DOFA-CLIP: Multimodal Vision-Language Foundation Models for Earth Observation](https://arxiv.org/abs/2503.06312)
> *DOFA-CLIP：面向地球观测的多模态视觉-语言基础模型*

*Zhitong Xiong, Yi Wang, Weikang Yu, Adam J Stewart, Jie Zhao, Nils Lehmann, Thomas Dujardin, Zhenghang Yuan, Pedram Ghamisi, Xiao Xiang Zhu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 地球观测, 多模态, 视觉-语言模型, CLIP, 零样本

**Comment:** code & weights: https://github.com/xiong-zhitong/DOFA-CLIP

> **TL;DR:** DOFA-CLIP是一个统一的视觉-语言基础模型，能够动态适应多种地球观测模态，并在零样本性能上达到最先进水平。

**AI_Comments:** DOFA-CLIP的创新之处在于其统一的多模态处理能力和动态适应性，有效地解决了现有地球观测视觉-语言模型在单一模态上的局限性。通过引入大规模异构数据集（GeoLangBind-2M）、创新的训练策略（VECT）和精细的特征蒸馏模块（MaKA），该模型显著提升了在多样化地球观测任务中的泛化能力和可扩展性。其在零样本任务上取得的最先进性能，预示着该模型在实际地球观测应用中具有巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前地球观测领域的视觉-语言模型（特别是基于CLIP的变体）局限于单一模态，限制了在多样化任务中的泛化能力和可扩展性。

**Method:** 提出了DOFA-CLIP（动态一体化CLIP），一个统一的视觉-语言基础模型，通过单个Transformer骨干网络动态适应具有灵活光谱配置的地球观测模态。主要贡献包括：1) 构建了GeoLangBind-2M大型地球观测图像-文本数据集，涵盖六种异构模态并包含丰富的自然语言描述；2) 提出VECT（视觉模型增强对比文本-图像预训练）训练策略，通过多个视觉基础模型增强CLIP特征的空间感知；3) 引入模态感知知识聚合（MaKA）模块，通过模态特异性感知细化特征蒸馏。

**Result:** DOFA-CLIP在广泛的地球观测基准测试中，包括未见过的模态和不同数量的输入光谱带，实现了最先进的零样本性能。

**Conclusion:** 这些贡献共同为多模态地球观测理解建立了可扩展的基础，并为将异构地球观测数据与大型语言模型集成开辟了新途径。

> **ai_Abstract:** DOFA-CLIP是一个统一的视觉-语言基础模型，旨在解决当前地球观测领域视觉-语言模型在多模态适应性方面的局限性。它通过单个Transformer骨干网络动态适应多种地球观测模态，并引入了GeoLangBind-2M数据集、VECT训练策略和MaKA模块。该模型在多项地球观测基准测试中展现出卓越的零样本性能，为多模态地球观测理解和与大型语言模型的集成奠定了基础。

> **摘要翻译:** 地球观测 (EO) 涵盖了广泛的模态，包括光学、雷达、多光谱和高光谱数据，每种模态都捕获独特的环境信号。然而，当前地球观测领域的视觉-语言模型，特别是基于CLIP的变体，仍然局限于单一模态，限制了在多样化任务中的泛化能力和可扩展性。我们提出了DOFA-CLIP（动态一体化CLIP），一个统一的视觉-语言基础模型，通过单个Transformer骨干网络动态适应具有灵活光谱配置的地球观测模态。我们的方法引入了三个关键贡献：1) 构建了GeoLangBind-2M，一个大型地球观测图像-文本数据集，涵盖六种异构模态并包含丰富的自然语言描述；2) 一种名为VECT（视觉模型增强对比文本-图像预训练）的新型训练策略，通过多个视觉基础模型增强CLIP特征的空间感知；3) 一个模态感知知识聚合（MaKA）模块，通过模态特异性感知细化特征蒸馏。DOFA-CLIP在广泛的地球观测基准测试中，包括未见过的模态和不同数量的输入光谱带，实现了最先进的零样本性能。这些贡献共同为多模态地球观测理解建立了可扩展的基础，并为将异构地球观测数据与大型语言模型集成开辟了新途径。代码和数据集将公开发布。代码和数据集已公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks](https://arxiv.org/abs/2507.16761)
> *使用抗混叠B-cos网络进行忠实、可解释的胸部X光诊断*

*Marcel Kleinmann, Shashank Agnihotri, Margret Keuper* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 忠实性, 可解释性, 胸部X光, B-cos网络, 抗混叠

**Comment:** 

> **TL;DR:** 本文通过引入抗混叠策略并扩展其对多标签分类的支持，改进了B-cos网络，使其能够在保持诊断性能的同时为胸部X光诊断提供忠实、无伪影的解释，适用于临床应用。

**AI_Comments:** 该研究通过引入抗混叠技术和支持多标签分类，有效解决了B-cos网络在实际临床应用中的两大核心障碍，显著提升了其在医疗影像领域的可行性和实用性。其创新点在于将抗混叠策略与B-cos的固有可解释性相结合，为安全关键领域的深度学习模型部署提供了更可靠的解释性工具。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗影像等安全关键领域部署深度神经网络时，模型的忠实性和可解释性至关重要。现有的B-cos网络虽然提供了固有的可解释性，但其解释图存在严重的混叠伪影，且仅限于多类别设置，不适用于需要多标签分类的胸部X光分析。

**Method:** 本文引入了使用FLCPooling (FLC) 和 BlurPool (BP) 的抗混叠策略，以显著提高解释质量；同时，将B-cos网络扩展以支持多标签分类。

**Result:** 在胸部X光数据集上的实验表明，修改后的B-cosFLC和B-cosBP模型在保持强大预测性能的同时，提供了忠实且无伪影的解释，适用于多标签设置下的临床应用。

**Conclusion:** 通过解决混叠伪影问题和扩展多标签分类能力，改进的B-cos网络在医疗影像诊断中提供了更可靠、更适合临床使用的可解释性。

> **ai_Abstract:** 本研究针对B-cos网络在医疗影像诊断中存在的混叠伪影和仅支持多类别分类的局限性进行了改进。通过引入FLCPooling和BlurPool抗混叠策略，并扩展其对多标签分类的支持，文章提出了一种能够为胸部X光诊断提供忠实、无伪影且适用于临床应用的可解释性方法。实验证明，改进后的B-cos模型在保持高预测性能的同时，显著提升了解释质量。

> **摘要翻译:** 忠实、可解释的胸部X光诊断与抗混叠B-cos网络

忠实性和可解释性对于在医疗影像等安全关键领域部署深度神经网络（DNN）至关重要。B-cos网络通过用权重-输入对齐机制取代标准线性层，提供了一种有前景的解决方案，无需后处理方法即可生成固有的可解释的、特定于类别的解释。尽管在诊断性能上与最先进的DNNs保持竞争力，但标准的B-cos模型在解释图中存在严重的混叠伪影，使其不适合对清晰度要求极高的临床使用。此外，最初的B-cos公式仅限于多类别设置，而胸部X光分析由于异常情况的并发往往需要多标签分类。在这项工作中，我们解决了这两个限制：（1）我们引入了使用FLCPooling（FLC）和BlurPool（BP）的抗混叠策略，以显著提高解释质量，并且（2）我们将B-cos网络扩展以支持多标签分类。我们在胸部X光数据集上的实验表明，修改后的B-cosFLC和B-cosBP在保持强大预测性能的同时，提供了忠实且无伪影的解释，适用于多标签设置下的临床应用。代码可在GitHub仓库获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach](https://arxiv.org/abs/2507.16556)
> *面向ADS的基于FPGA SoC的DNN高光谱图像分割优化：一种实用方法*

*Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe* | **Category: cs.CV, cs.AI, cs.AR, cs.LG, eess.IV** | **Updated: 2025-07-22**

**Keywords:** 高光谱图像分割, 深度神经网络, FPGA, 自动驾驶系统, 软硬件协同设计

**Comment:** 

> **TL;DR:** 本文提出了一种在FPGA SoC上优化部署基于DNN的高光谱图像分割处理器的方法，以满足自动驾驶系统（ADS）的实时性、资源和安全要求。

**AI_Comments:** 本文在将高光谱图像（HSI）与深度神经网络（DNN）结合并部署到边缘设备（FPGA-based SoC）以满足自动驾驶系统（ADS）的严苛要求方面，具有重要的实用价值。其创新点在于提出了全面的软硬件协同设计优化方法，特别是对DNN模型压缩和HSI数据预处理的关注，解决了实时边缘部署中的关键计算和数据挑战。这项工作为未来在资源受限环境下部署复杂AI模型提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱图像（HSI）在自主导航中具有巨大潜力，但其在自动驾驶系统（ADS）等安全关键应用中部署时面临延迟、资源消耗和安全性等严格限制。此外，DNN的过参数化特性和HSI密集的数据预处理对边缘部署的实时性提出了计算挑战。

**Method:** 本文提出了一套优化技术，用于在FPGA SoC上协同设计和部署基于DNN的HSI分割处理器，面向ADS应用。关键优化包括功能性软硬件任务分配、硬件感知预处理、ML模型压缩和完整的流水线部署。

**Result:** 应用压缩技术将DNN的复杂度降低到原始操作的24.34%和原始参数数量的1.02%，同时在推理任务中实现了2.86倍的加速，且分割精度没有明显下降。

**Conclusion:** 通过软硬件协同设计和优化技术，可以在FPGA SoC上高效部署DNN高光谱图像分割系统，满足自动驾驶等安全关键应用的严格要求，实现显著的性能提升而保持精度。

> **ai_Abstract:** 本文针对自动驾驶系统（ADS）对实时性、资源和安全性的严格要求，提出了一种在FPGA-based SoC上优化部署DNN-based HSI分割处理器的方法。通过软硬件协同设计，包括功能性任务分配、硬件感知预处理、ML模型压缩和流水线部署等优化技术，成功将DNN模型复杂度大幅降低，并实现了推理速度的显著提升（2.86倍），同时保持了分割精度，为HSI在安全关键边缘应用的实用化提供了有效途径。

> **摘要翻译:** 高光谱图像（HSI）在自主导航中的应用是一个有前景的研究领域，旨在提高基于视觉传感器的检测、跟踪和场景理解系统的准确性和鲁棒性。将先进的计算机算法（如DNN）与小型快照式HSI相机结合使用，可增强这些系统的可靠性。HSI克服了灰度图像和RGB图像在描绘目标物理特性（特别是光谱反射率和同色异谱现象）方面的固有局限性。尽管基于HSI的视觉开发取得了可喜的成果，但自动驾驶系统（ADS）等安全关键系统对延迟、资源消耗和安全性有严格要求，这促使机器学习工作负载向边缘平台转移。这涉及到彻底的软硬件协同设计方案，以在计算平台的有限资源中高效分配和优化任务。就推理而言，DNN的过参数化特性对实时边缘部署提出了显著的计算挑战。此外，HSI所需的密集数据预处理（通常被忽视）必须在内存安排和任务间通信方面进行仔细管理，以在SoC上实现高效的集成流水线设计。这项工作提出了一套优化技术，用于在面向ADS的基于FPGA的SoC上部署的基于DNN的HSI分割处理器的实用协同设计，包括功能性软硬件任务分配、硬件感知预处理、ML模型压缩和完整的流水线部署等关键优化。应用压缩技术显著降低了所设计DNN的复杂度，使其降至原始操作的24.34%和原始参数数量的1.02%，在推理任务中实现了2.86倍的加速，且分割精度没有明显下降。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [369] [Denoising-While-Completing Network (DWCNet): Robust Point Cloud Completion Under Corruption](https://arxiv.org/abs/2507.16743)
> *去噪同时补全网络 (DWCNet)：在损坏情况下鲁棒的点云补全*

*Keneni W. Tesema, Lyndon Hill, Mark W. Jones, Gary K. L. Tam* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 点云补全, 去噪, 鲁棒性, 对比学习, DWCNet

**Comment:** Accepted for Computers and Graphics and EG Symposium on 3D Object
  Retrieval 2025 (3DOR'25)

> **TL;DR:** DWCNet是一个新的点云补全框架，能够在存在噪声和遮挡的情况下同时去噪和补全点云，并在合成和真实世界数据上实现了最先进的性能。该研究还引入了一个新的损坏点云补全数据集（CPCCD）来评估鲁棒性。

**AI_Comments:** DWCNet的创新之处在于其“去噪同时补全”的策略，以及引入了噪声管理模块（NMM），利用对比学习和自注意力来增强对噪声的鲁棒性。这对于解决现实世界中点云数据质量不佳的问题具有重要意义，克服了现有方法在合成数据上训练的局限性。该工作还贡献了一个新的基准数据集CPCCD，对于推动该领域的研究具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 点云补全对于自动驾驶、增强现实和机器人等3D计算机视觉任务至关重要。然而，从现实世界环境中获取干净完整的点云具有挑战性，因为存在噪声和遮挡。现有的补全网络大多在合成数据上训练，难以应对现实世界的退化问题。

**Method:** 本研究提出了DWCNet（去噪同时补全网络），这是一个增强了噪声管理模块（NMM）的补全框架。NMM利用对比学习和自注意力机制来抑制噪声并建模结构关系。为了评估鲁棒性，研究还引入了损坏点云补全数据集（CPCCD)。

**Result:** DWCNet在干净和损坏的、合成和真实世界数据集上均实现了最先进的性能。

**Conclusion:** DWCNet通过其新颖的去噪同时补全策略和噪声管理模块，有效解决了点云在现实世界中受损的问题，并在多项基准测试中取得了优异表现。

> **ai_Abstract:** 本研究提出了一种名为DWCNet（去噪同时补全网络）的新型框架，旨在解决现实世界中受噪声和遮挡影响的点云补全问题。DWCNet通过引入噪声管理模块（NMM），结合对比学习和自注意力机制，能够同时进行点云去噪和补全。为了全面评估方法的鲁棒性，研究还构建了损坏点云补全数据集（CPCCD）。实验结果表明，DWCNet在合成和真实世界的干净及损坏数据集上均达到了最先进的性能。

> **摘要翻译:** 点云补全对于自动驾驶、增强现实和机器人等3D计算机视觉任务至关重要。然而，由于噪声和遮挡，从现实世界环境中获取干净完整的点云具有挑战性。因此，大多数现有的补全网络——在合成数据上训练——难以应对现实世界的退化。在这项工作中，我们解决了在多种同时退化影响下，对高度损坏的部分点云进行补全和去噪的问题。为了衡量鲁棒性，我们引入了损坏点云补全数据集（CPCCD），该数据集突出了当前方法在各种损坏情况下的局限性。基于这些见解，我们提出了DWCNet（去噪同时补全网络），这是一个通过噪声管理模块（NMM）增强的补全框架，该模块利用对比学习和自注意力来抑制噪声和建模结构关系。DWCNet在干净和损坏的、合成和真实世界数据集上均实现了最先进的性能。数据集和代码将在https://github.com/keneniwt/DWCNET-Robust-Point-Cloud-Completion-against-Corruptions 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [Robust Noisy Pseudo-label Learning for Semi-supervised Medical Image Segmentation Using Diffusion Model](https://arxiv.org/abs/2507.16429)
> *基于扩散模型的半监督医学图像分割中鲁棒的噪声伪标签学习*

*Lin Xi, Yingliang Ma, Cheng Wang, Sandra Howell, Aldo Rinaldi, Kawal S. Rhode* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 半监督学习, 医学图像分割, 扩散模型, 伪标签, 原型对比学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于扩散模型的半监督医学图像分割框架，通过引入原型对比一致性来提高在噪声伪标签下的鲁棒性，并在两个数据集上取得了优于现有技术的效果。

**AI_Comments:** 该论文的创新点在于将扩散模型应用于半监督医学图像分割，并巧妙地通过原型对比一致性来解决伪标签噪声问题，提升了分割的鲁棒性。其重要性体现在有效降低了对大量像素级标注数据的依赖，提高了数据效率。同时，引入新的公开基准数据集MOSXAV，对后续研究具有积极的推动作用。该方法在处理噪声伪标签方面的表现，使其在实际临床应用中具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 医学领域像素级标注成本高昂且耗时。现有的半监督方法在处理伪标签引入的噪声时，难以构建潜在空间中的语义分布。

**Method:** 提出了一种新的基于扩散模型的半监督医学图像分割框架。该方法在去噪扩散过程中，通过强制执行基于原型的对比一致性，在语义标签的潜在结构中引入了约束。模型利用潜在空间中集中的类原型语义表示作为锚点，而不是明确划分语义边界。此外，引入了一个新的公开基准数据集：X射线血管造影视频中的多目标分割（MOSXAV）。

**Result:** 在EndoScapes2023和MOSXAV数据集上进行的广泛实验表明，该方法在半监督学习设置下优于最先进的医学图像分割方法。

**Conclusion:** 本文提出了一种鲁棒且数据高效的扩散模型，具有增强的灵活性和广泛临床应用的巨大潜力。

> **ai_Abstract:** 本文针对医学图像分割中像素级标注成本高的问题，提出了一种基于扩散模型的新型半监督学习框架。该方法通过在去噪扩散过程中引入原型对比一致性，利用潜在空间中的类原型作为语义锚点，有效提升了模型在噪声伪标签下的鲁棒性。研究还推出了一个新的公开基准数据集MOSXAV。实验结果表明，该方法在多个数据集上均优于现有先进的半监督医学图像分割技术，展现了其在临床应用中的强大潜力。

> **摘要翻译:** 在医学领域，获取像素级标注既昂贵又耗时，通常需要临床专家和开发人员之间的密切协作。半监督医学图像分割旨在利用有限的标注数据和大量的未标注数据来实现准确的分割。然而，现有的半监督方法由于伪标签引入的噪声，往往难以在潜在空间中构建语义分布。在本文中，我们提出了一种用于半监督医学图像分割的新型基于扩散的框架。我们的方法通过强制执行基于原型的对比一致性，在去噪扩散过程中将约束引入语义标签的潜在结构中。模型利用潜在空间中集中的类原型语义表示作为锚点，而不是明确划分语义边界。这种策略提高了密集预测的鲁棒性，特别是在存在噪声伪标签的情况下。我们还引入了一个新的公开基准数据集：X射线血管造影视频中的多目标分割（MOSXAV），该数据集为X射线血管造影视频中的多个解剖结构提供了详细的手动标注分割真值。在EndoScapes2023和MOSXAV数据集上进行的广泛实验表明，我们的方法在半监督学习设置下优于最先进的医学图像分割方法。这项工作提出了一种鲁棒且数据高效的扩散模型，具有增强的灵活性和广泛临床应用的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [378] [Artifacts and Attention Sinks: Structured Approximations for Efficient Vision Transformers](https://arxiv.org/abs/2507.16018)
> *伪影与注意力汇聚：高效视觉Transformer的结构化近似*

*Andrew Lu, Wentinn Liao, Liuhui Wang, Huzheng Yang, Jianbo Shi* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 视觉Transformer, 注意力机制, 令牌分析, 计算效率, Fast Nyström Attention

**Comment:** 

> **TL;DR:** 本文研究了视觉Transformer中的大量令牌和伪影令牌现象，并提出了Fast Nyström Attention (FNA)和一种掩蔽策略，以提高效率并减少计算开销，同时保持竞争力。

**AI_Comments:** 这项工作通过深入分析视觉Transformer中的特定令牌行为（大量令牌和伪影令牌），为提高其效率提供了新颖的视角。提出的FNA方法和掩蔽策略，作为无需训练的优化手段，具有较高的实用价值，尤其是在资源受限的环境下。其创新点在于从内部机制出发，而非简单地修改网络结构，为未来高效Transformer设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 视觉Transformer虽然强大，但其内部工作机制尚未完全理解。特别是存在大量激活范数极高的“注意力汇聚”令牌和推理过程中产生的“伪影”令牌，这些令牌对信息流有重要影响，且可能带来计算开销。

**Method:** 本文分析了视觉Transformer中大量令牌（注意力汇聚）和伪影令牌的现象，发现它们通过注意力机制相互抑制，调节信息流。基于此，提出了Fast Nyström Attention (FNA)，这是一种无需训练的方法，利用这些令牌形成的结构化模式，以线性时间和空间复杂度近似自注意力。此外，还提出了一种掩蔽策略来减轻这些令牌的噪声。

**Result:** 该方法在流行的预训练视觉骨干网络上进行了评估，在检索、分类、分割和视觉问答（VQA）任务上表现出有竞争力的性能，同时显著降低了计算开销。

**Conclusion:** 通过理解和利用视觉Transformer中大量令牌和伪影令牌的特性，可以开发出更高效的注意力近似方法，从而在保持性能的同时降低计算成本。

> **ai_Abstract:** 本文深入探讨了视觉Transformer中“大量令牌”（注意力汇聚）和“伪影令牌”的特性，揭示了它们在调节网络信息流中的相互抑制作用。基于这些发现，作者提出了一种名为Fast Nyström Attention (FNA)的无训练方法，该方法通过利用这些令牌的结构化模式，实现了线性时间复杂度的自注意力近似。同时，还引入了一种掩蔽策略以减少噪声。实验证明，FNA在多种视觉任务上保持了竞争力，并显著降低了计算开销。

> **摘要翻译:** 视觉Transformer已成为广泛应用中的强大工具，但其内部工作原理仍仅部分被理解。在这项工作中，我们研究了大量令牌——具有异常高激活范数并充当注意力汇聚的令牌——以及在推理过程中作为副产品出现的伪影令牌现象。我们的分析揭示，这些令牌通过注意力机制相互抑制，在调节网络内部信息流中发挥关键作用。利用这些见解，我们引入了Fast Nyström Attention (FNA)，这是一种无需训练的方法，通过利用大量令牌和伪影令牌形成的结构化模式，以线性时间和空间复杂度近似自注意力。此外，我们提出了一种掩蔽策略来减轻来自这些令牌的噪声，以几乎零成本获得适度的性能提升。我们在流行的预训练视觉骨干网络上评估了我们的方法，并在检索、分类、分割和视觉问答（VQA）方面展示了有竞争力的性能，同时降低了计算开销。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [382] [Illuminating Darkness: Learning to Enhance Low-light Images In-the-Wild](https://arxiv.org/abs/2503.06898)
> *照亮黑暗：学习增强野外低光图像*

*S M A Sharif, Abdur Rehman, Zain Ul Abidin, Fayaz Ali Dharejo, Radu Timofte, Rizwan Ali Naqvi* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 低光图像增强, 数据集, TFFormer, 智能手机, 图像处理

**Comment:** 

> **TL;DR:** 论文提出了大规模野外低光智能手机数据集LSD和混合模型TFFormer，用于单次低光图像增强，并在LSD和下游任务上取得了SOTA结果。

**AI_Comments:** 该论文通过构建大规模、高质量的真实世界低光数据集LSD，有效弥补了现有研究在数据方面的不足。同时，提出的TFFormer模型在亮度和色度分离编码方面的创新性，有助于解决低光图像增强中的颜色-结构纠缠问题，为该领域的研究提供了新的思路和强大的基准。

<details>
  <summary>Details</summary>

**Motivation:** 单次低光图像增强（SLLIE）面临挑战，原因是缺乏多样化、真实世界的配对数据集。

**Method:** 论文引入了低光智能手机数据集（LSD），一个大规模、高分辨率（4K+）的野外数据集，包含6,425对精确对齐的低光和正常光图像。为了充分利用LSD，论文提出了TFFormer，一个混合模型，它独立编码亮度和色度（LC）以减少颜色-结构纠缠，并采用交叉注意力驱动的联合解码器进行上下文感知融合，以及LC细化和LC引导监督。

**Result:** TFFormer在LSD数据集上实现了最先进的结果（PSNR提升+2.45 dB），并显著改善了下游视觉任务，例如低光目标检测（在ExDark上mAP提升+6.80）。

**Conclusion:** 论文通过引入大规模真实世界数据集和创新的混合模型，有效解决了单次低光图像增强的挑战，并在图像质量和下游任务性能上取得了显著提升。

> **ai_Abstract:** 本文针对单次低光图像增强（SLLIE）中真实世界配对数据集稀缺的挑战，提出了大规模野外低光智能手机数据集（LSD），包含6,425对高分辨率低光/正常光图像。同时，引入了混合模型TFFormer，通过独立编码亮度和色度并进行上下文感知融合，有效提升了图像质量。实验结果表明，TFFormer在LSD上实现了最先进的性能，并显著提升了低光目标检测等下游任务的效果。

> **摘要翻译:** 单次低光图像增强（SLLIE）由于缺乏多样化、真实世界的配对数据集而仍然具有挑战性。为了弥补这一空白，我们引入了低光智能手机数据集（LSD），这是一个大规模、高分辨率（4K+）的数据集，在野外各种具有挑战性的照明条件（0.1至200勒克斯）下收集。LSD包含6,425对精确对齐的低光和正常光图像对，通过多帧采集和专家评估从8,000多个动态室内外场景中选择。为了评估泛化能力和美学质量，我们从以前未见过的设备中收集了2,117张未配对的低光图像。为了充分利用LSD，我们提出了TFFormer，一个混合模型，它独立编码亮度和色度（LC）以减少颜色-结构纠缠。我们进一步提出了一个交叉注意力驱动的联合解码器，用于LC表示的上下文感知融合，以及LC细化和LC引导监督，以显著增强感知保真度和结构一致性。TFFormer在LSD上取得了最先进的结果（PSNR提升+2.45 dB），并显著改善了下游视觉任务，例如低光目标检测（在ExDark上mAP提升+6.80）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [399] [CMP: A Composable Meta Prompt for SAM-Based Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2507.16753)
> *CMP：一种用于基于SAM的跨域少样本分割的可组合元提示*

*Shuai Chen, Fanman Meng, Chunjin Yang, Haoran Wei, Chenhao Wu, Qingbo Wu, Hongliang Li* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 跨域少样本分割, SAM, 元提示, 语义分割, 领域自适应

**Comment:** 3 figures

> **TL;DR:** 本文提出了CMP框架，通过引入参考补全与转换、可组合元提示生成和频率感知交互模块，解决了SAM在跨域少样本分割中对手动提示的依赖和有限的跨域能力问题，并取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个可组合的元提示框架CMP，旨在解决SAM在跨域少样本分割中遇到的两大挑战。通过引入RCT、CMPG和FAI这三个模块，CMP不仅实现了提示的自动化生成，还有效增强了SAM的跨域泛化能力，对于推动基础模型在特定下游任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 跨域少样本分割（CD-FSS）由于数据有限和领域偏移仍然面临挑战。虽然SAM等基础模型在通用分割任务中表现出卓越的零样本泛化能力，但将其应用于CD-FSS面临两大挑战：对手动提示的依赖和有限的跨域能力。

**Method:** 提出了可组合元提示（CMP）框架，包含三个关键模块：(i) 参考补全与转换（RCT）模块用于语义扩展，(ii) 可组合元提示生成（CMPG）模块用于自动化元提示合成，以及(iii) 频率感知交互（FAI）模块用于缓解领域差异。

**Result:** 在四个跨域数据集上的评估表明，CMP取得了最先进的性能，在1样本和5样本场景中分别达到了71.8%和74.5%的mIoU。

**Conclusion:** CMP框架通过其创新的模块设计，有效解决了SAM在跨域少样本分割中的关键挑战，并显著提升了性能，证明了其在解决数据稀缺和领域偏移问题上的有效性。

> **ai_Abstract:** 针对跨域少样本分割（CD-FSS）中SAM模型面临的手动提示依赖和有限跨域能力问题，本文提出了可组合元提示（CMP）框架。CMP包含参考补全与转换（RCT）模块以扩展语义，可组合元提示生成（CMPG）模块以自动化提示合成，以及频率感知交互（FAI）模块以缓解领域差异。实验证明，CMP在多个跨域数据集上取得了最先进的性能，显著提升了少样本分割的准确性。

> **摘要翻译:** 跨域少样本分割（CD-FSS）由于数据有限和领域偏移仍然具有挑战性。最近的基础模型，如Segment Anything Model（SAM），在通用分割任务中展现出卓越的零样本泛化能力，使其成为少样本场景下有前景的解决方案。然而，将SAM应用于CD-FSS面临两个关键挑战：对手动提示的依赖和有限的跨域能力。因此，我们提出了可组合元提示（CMP）框架，该框架引入了三个关键模块：(i) 用于语义扩展的参考补全与转换（RCT）模块，(ii) 用于自动化元提示合成的可组合元提示生成（CMPG）模块，以及(iii) 用于缓解领域差异的频率感知交互（FAI）模块。在四个跨域数据集上的评估表明，CMP取得了最先进的性能，在1样本和5样本场景中分别达到了71.8%和74.5%的mIoU。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models](https://arxiv.org/abs/2507.09279)
> *Prompt4Trust：一种用于多模态大型语言模型中临床一致性置信度校准的强化学习提示增强框架*

*Anita Kriz, Elizabeth Laura Janes, Xing Shen, Tal Arbel* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 强化学习, 提示增强, 置信度校准, 多模态大型语言模型, 医疗VQA

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** Prompt4Trust是一个基于强化学习的提示增强框架，旨在提高多模态大型语言模型在医疗领域中的置信度校准和任务准确性。

**AI_Comments:** 本文创新性地将强化学习应用于MLLM的提示增强，以解决医疗领域中关键的置信度校准问题，特别强调了临床安全性。其提出的Prompt4Trust框架不仅提高了模型的可信度，也提升了任务准确性，并在零样本泛化方面表现出色，为MLLM在安全关键场景下的部署提供了新的思路和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在医疗应用中具有前景，但其在安全关键设置中的部署受限于对提示设计的敏感性以及以高置信度生成错误响应的倾向。临床医生依赖模型的置信度来判断预测可靠性，因此模型表达高置信度时必须高准确度，这是本研究的动机。

**Method:** 本文提出了Prompt4Trust，首个针对MLLM置信度校准的强化学习（RL）提示增强框架。它训练一个轻量级LLM生成上下文感知的辅助提示，以引导下游任务MLLM生成置信度更准确反映预测准确性的响应。该方法优先考虑对安全和可信临床决策最关键的校准方面。

**Result:** Prompt4Trust不仅改进了临床驱动的校准目标，还提高了任务准确性，在PMC-VQA基准测试上实现了最先进的医学视觉问答（VQA）性能。此外，该框架在使用小型下游任务MLLM训练后，对更大的MLLM显示出有前景的零样本泛化能力，表明了其可扩展性。

**Conclusion:** 该工作展示了自动化但与人类对齐的提示工程在提高MLLM在安全关键设置中可信度方面的潜力。

> **ai_Abstract:** Prompt4Trust是一个利用强化学习进行提示增强的框架，旨在解决多模态大语言模型在医疗领域中置信度校准不准确和对提示设计敏感的问题。通过训练一个轻量级LLM生成辅助提示，该框架能够引导下游MLLM生成更准确反映预测准确性的响应，从而提高模型的可信度与任务准确性，并在医学VQA任务上取得SOTA表现，同时展现出对大型MLLM的零样本泛化能力。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在医疗保健应用中具有相当大的前景。然而，它们在安全关键环境中的部署受到两个关键限制的阻碍：(i) 对提示设计的敏感性，以及 (ii) 倾向于以高置信度生成不正确的响应。由于临床医生可能依赖模型声明的置信度来衡量其预测的可靠性，因此当模型表达高置信度时，其准确性也必须很高，这一点尤为重要。我们引入了Prompt4Trust，这是第一个针对MLLMs中置信度校准的强化学习（RL）提示增强框架。训练一个轻量级LLM来生成上下文感知的辅助提示，以引导下游任务MLLM生成表达置信度更准确反映预测准确性的响应。与传统校准技术不同，Prompt4Trust特别优先考虑对安全和可信临床决策最关键的校准方面。除了由这种临床驱动的校准目标带来的改进之外，我们提出的方法还提高了任务准确性，在PMC-VQA基准测试上实现了最先进的医学视觉问答（VQA）性能，该基准由涵盖多种医学成像模式的多项选择题组成。此外，在我们的实验中，使用小型下游任务MLLM训练的框架对更大的MLLM显示出有前景的零样本泛化能力，这表明了在没有相关计算成本的情况下实现可扩展校准的潜力。这项工作展示了自动化但与人类对齐的提示工程在提高MLLM在安全关键设置中可信度方面的潜力。我们的代码库可在https://github.com/xingbpshen/prompt4trust找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [409] [MONITRS: Multimodal Observations of Natural Incidents Through Remote Sensing](https://arxiv.org/abs/2507.16228)
> *MONITRS：通过遥感对自然事件进行多模态观测*

*Shreelekha Revankar, Utkarsh Mall, Cheng Perng Phoo, Kavita Bala, Bharath Hariharan* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** MONITRS, 多模态, 遥感, 灾害监测, 数据集

**Comment:** 17 pages, 9 figures, 4 tables

> **TL;DR:** MONITRS是一个新的多模态数据集，包含遥感图像和自然语言注释，用于改善机器学习辅助的灾害监测和响应系统。

**AI_Comments:** MONITRS数据集的创新之处在于其多模态、大规模和时间粒度，结合了卫星图像和自然语言标注，极大地丰富了灾害监测的数据维度。它解决了当前灾害响应系统中数据不足和分析自动化程度低的痛点，为构建更高效、更智能的灾害响应系统提供了关键资源。该工作为未来的研究提供了新的基准和开放的数据集，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 自然灾害每年造成巨大破坏，而有效的灾害响应因难以进入受灾区域而受阻。尽管遥感和深度学习在自动化卫星图像分析方面有所进展，但现有方法仍受限于对特定灾害类型的狭隘关注、对人工专家解释的依赖，以及缺乏具有足够时间粒度或自然语言标注的数据集来跟踪灾害进展。

**Method:** 本文提出了MONITRS，一个新颖的多模态数据集，包含超过10,000个FEMA灾害事件，并附带时间序列卫星图像、新闻文章中的自然语言标注、地理标记位置和问答对。

**Result:** 在MONITRS数据集上对现有MLLM进行微调，可以显著提高灾害监测任务的性能，为机器学习辅助的灾害响应系统建立了新的基准。

**Conclusion:** MONITRS数据集的创建和应用证明了其在提升灾害监测任务性能方面的有效性，并为未来的机器学习辅助灾害响应系统奠定了基础。

> **ai_Abstract:** 该论文介绍了MONITRS，一个新颖的多模态数据集，旨在解决现有灾害监测方法在数据广度和深度上的局限性。MONITRS整合了10,000多个FEMA灾害事件的卫星图像、新闻文本标注、地理位置和问答对。研究表明，利用该数据集对现有MLLM进行微调，能显著提升灾害监测任务的性能，为机器学习辅助的灾害响应系统设定了新标准。

> **摘要翻译:** 自然灾害每年对社区和基础设施造成毁灭性破坏。在事件发生期间和之后，难以进入受灾区域阻碍了有效的灾害响应。遥感技术使我们能够远程监测自然灾害。最近，计算机视觉和深度学习取得了进展，有助于自动化卫星图像分析，然而，它们仍然受限于对特定灾害类型的狭隘关注、对人工专家解释的依赖，以及缺乏具有足够时间粒度或自然语言标注的数据集来跟踪灾害进展。我们提出了MONITRS，一个新颖的多模态数据集，包含超过10,000个FEMA灾害事件，附带时间序列卫星图像和来自新闻文章的自然语言标注，以及地理标记位置和问答对。我们证明了在我们的数据集上微调现有的多模态大语言模型（MLLMs）可以显著提高灾害监测任务的性能，为机器学习辅助的灾害响应系统建立了新的基准。代码可在：https://github.com/ShreelekhaR/MONITRS 找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [Balanced Image Stylization with Style Matching Score](https://arxiv.org/abs/2503.07601)
> *具有风格匹配分数的平衡图像风格化*

*Yuxin Jiang, Liming Jiang, Shuai Yang, Jia-Wei Liu, Ivor Tsang, Mike Zheng Shou* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 图像风格化, 扩散模型, 风格匹配分数, 内容保留, 语义感知

**Comment:** ICCV 2025. Code: https://github.com/showlab/SMS Project page:
  https://yuxinn-j.github.io/projects/SMS.html

> **TL;DR:** 提出了一种名为风格匹配分数 (SMS) 的新优化方法，用于扩散模型的图像风格化，有效平衡风格迁移和内容保留。

**AI_Comments:** 这篇论文通过引入风格匹配分数（SMS）这一新颖的优化框架，将图像风格化问题重新定义为风格分布匹配，并结合了频域正则化和语义感知细化等创新技术，有效解决了风格迁移与内容保留的平衡难题。其将风格化扩展到参数空间，实现高效一步风格化的能力，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图像风格化中，平衡有效的风格迁移与内容保留是一个长期存在的挑战。现有方法未能充分解决这一问题。

**Method:** 本文提出风格匹配分数 (SMS)，将图像风格化重新定义为风格分布匹配问题。通过精心设计的评分函数，从现成的依赖风格的LoRA中估计目标风格分布。为自适应保留内容，提出了渐进频谱正则化，在频域操作以逐步引导风格化。此外，还设计了语义感知梯度细化技术，利用扩散语义先验选择性风格化语义重要区域。该优化公式将风格化从像素空间扩展到参数空间，可应用于轻量级前馈生成器实现高效一步风格化。

**Result:** SMS有效地平衡了风格对齐和内容保留，并通过大量实验验证，其性能优于现有最先进的方法。

**Conclusion:** SMS通过新颖的优化方法，成功解决了图像风格化中风格迁移与内容保留的平衡问题，并实现了高效的一步风格化。

> **ai_Abstract:** 本文提出了一种名为风格匹配分数（SMS）的新型优化方法，用于基于扩散模型的图像风格化。该方法将风格化视为风格分布匹配问题，并结合渐进频谱正则化以自适应地保留内容，以及语义感知梯度细化以选择性地风格化重要区域。SMS将风格化从像素空间扩展到参数空间，实现了高效的一步风格化，并在风格对齐和内容保留方面优于现有SOTA方法。

> **摘要翻译:** 我们提出了风格匹配分数（SMS），这是一种用于扩散模型图像风格化的新型优化方法。平衡有效的风格迁移与内容保留是一个长期存在的挑战。与现有方法不同，我们的方法将图像风格化重新定义为一个风格分布匹配问题。目标风格分布通过精心设计的评分函数从现成的依赖风格的LoRA中估计。为了自适应地保留内容信息，我们提出了渐进频谱正则化，它在频域操作，逐步引导风格化从低频布局到高频细节。此外，我们设计了一种语义感知梯度细化技术，利用从扩散语义先验导出的相关性图选择性地风格化语义重要区域。所提出的优化公式将风格化从像素空间扩展到参数空间，可轻松应用于轻量级前馈生成器，实现高效的一步风格化。SMS有效地平衡了风格对齐和内容保留，通过大量实验验证，其性能优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [416] [VGGT-Long: Chunk it, Loop it, Align it -- Pushing VGGT's Limits on Kilometer-scale Long RGB Sequences](https://arxiv.org/abs/2507.16443)
> *VGGT-Long：分块、循环、对齐——将VGGT的极限推向公里级长RGB序列*

*Kai Deng, Zexin Ti, Jiawei Xu, Jian Yang, Jin Xie* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 3D重建, 单目视觉, 基础模型, 大规模场景, RGB序列

**Comment:** 

> **TL;DR:** VGGT-Long提出了一种简单有效的方法，通过分块处理、重叠对齐和轻量级闭环优化，将单目3D重建扩展到公里级户外环境，解决了现有模型在处理长RGB序列时的内存限制问题，且无需相机校准或深度监督，性能媲美传统方法。

**AI_Comments:** VGGT-Long的创新点在于其“分块、循环、对齐”的策略，有效解决了3D视觉基础模型在处理长序列时的内存瓶颈，使其能应用于公里级大场景。其无需相机校准和深度监督的特点降低了使用门槛，对于实际应用，尤其是在自动驾驶领域，具有重要意义。该工作展示了基础模型在实际场景中大规模部署的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D视觉基础模型在处理大规模RGB流3D重建时面临内存限制的挑战，难以扩展到公里级长的序列。

**Method:** 我们提出了VGGT-Long系统，通过结合基于分块的处理策略、重叠对齐和轻量级闭环优化来解决现有模型的可扩展性瓶颈。该方法无需相机校准、深度监督或模型再训练。

**Result:** VGGT-Long在KITTI、Waymo和Virtual KITTI数据集上进行了评估，其轨迹和重建性能与传统方法相当。它不仅成功地处理了基础模型通常会失败的长RGB序列，而且在各种条件下都能产生准确且一致的几何结构。

**Conclusion:** 本研究的结果突出了利用基础模型在真实世界场景（特别是自动驾驶场景）中实现可扩展单目3D场景重建的潜力。

> **ai_Abstract:** VGGT-Long是一种新颖的系统，旨在克服现有3D视觉基础模型在处理大规模、长RGB序列时遇到的内存限制。它采用分块处理、重叠对齐和轻量级闭环优化策略，成功将单目3D重建的范围扩展到公里级的户外环境。该方法无需额外的相机校准或深度监督，即可在多个数据集上实现与传统方法相当的性能，并能处理其他基础模型无法应对的长序列，为自动驾驶等真实世界应用提供了可扩展的单目3D场景重建方案。

> **摘要翻译:** 3D视觉基础模型最近在3D感知方面展现出卓越的能力。然而，由于内存限制，将这些模型扩展到大规模RGB流3D重建仍然具有挑战性。在这项工作中，我们提出了VGGT-Long，一个简单而有效的系统，它将单目3D重建的极限推向公里级、无边界的户外环境。我们的方法通过结合基于分块的处理策略、重叠对齐和轻量级闭环优化来解决现有模型的可扩展性瓶颈。无需相机校准、深度监督或模型再训练，VGGT-Long实现了与传统方法相当的轨迹和重建性能。我们在KITTI、Waymo和Virtual KITTI数据集上评估了我们的方法。VGGT-Long不仅成功地在基础模型通常会失败的长RGB序列上运行，而且在各种条件下都能产生准确且一致的几何结构。我们的结果突出了利用基础模型在真实世界场景中实现可扩展单目3D场景重建的潜力，特别是对于自动驾驶场景。代码可在https://github.com/DengKaiCQ/VGGT-Long获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [429] [Task-Specific Zero-shot Quantization-Aware Training for Object Detection](https://arxiv.org/abs/2507.16782)
> *目标检测的特定任务零样本量化感知训练*

*Changhao Li, Xinrui Chen, Ji Wang, Kang Zhao, Jianfei Chen* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 零样本量化, 目标检测, 量化感知训练, 知识蒸馏, 模型压缩

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出了一种新的特定任务零样本量化感知训练框架，通过合成任务特定校准集和知识蒸馏，显著提高了目标检测网络的量化性能，无需真实训练数据。

**AI_Comments:** 这篇论文的创新点在于提出了一个特定任务的零样本量化框架，特别是在目标检测领域。它通过合成任务特定数据和结合知识蒸馏，有效解决了零样本量化在复杂任务中性能受限的问题，对于在数据受限环境下部署轻量级目标检测模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的零样本量化方法在应用于目标检测时，使用无标签的任务无关合成图像，缺乏目标检测所需的特定信息，导致性能不佳。

**Method:** 提出了一种新的特定任务零样本量化感知训练框架，包含两个阶段：1) 引入边界框和类别采样策略，从预训练网络合成任务特定的校准集，重建目标位置、大小和类别分布；2) 将特定任务训练整合到知识蒸馏过程中，以恢复量化检测网络的性能。

**Result:** 在MS-COCO和Pascal VOC数据集上的大量实验表明，该方法具有高效率和最先进的性能。

**Conclusion:** 该论文成功提出了一种新颖的特定任务零样本量化框架，有效解决了目标检测中零样本量化性能不佳的问题，并在主流数据集上达到了领先水平。

> **ai_Abstract:** 本文提出了一种新颖的特定任务零样本量化感知训练（ZSQ）框架，旨在解决现有ZSQ方法在目标检测中因缺乏任务特定信息而导致的性能下降问题。该框架包含两个核心阶段：首先，通过边界框和类别采样策略从预训练模型合成任务特定的校准数据，以准确捕捉目标检测所需的空间和类别信息；其次，将任务特定的训练步骤融入知识蒸馏过程，以有效恢复量化网络的性能。实验结果表明，该方法在MS-COCO和Pascal VOC数据集上实现了高效且最先进的量化目标检测性能，无需访问原始训练数据。

> **摘要翻译:** 量化是降低网络大小和计算复杂度的关键技术，它通过使用较低精度表示网络参数。传统的量化方法依赖于访问原始训练数据，但由于隐私问题或安全挑战，这通常受到限制。零样本量化（ZSQ）通过使用从预训练模型生成的合成数据来解决这个问题，从而无需真实训练数据。最近，ZSQ 已扩展到目标检测。然而，现有方法使用无标签的任务无关合成图像，缺乏目标检测所需的特定信息，导致性能不佳。在本文中，我们提出了一种用于目标检测网络的新型特定任务ZSQ框架，该框架包含两个主要阶段。首先，我们引入了一种边界框和类别采样策略，从预训练网络合成一个特定任务的校准集，在没有任何先验知识的情况下重建目标位置、大小和类别分布。其次，我们将特定任务训练整合到知识蒸馏过程中，以恢复量化检测网络的性能。在MS-COCO和Pascal VOC数据集上进行的大量实验证明了我们方法的效率和最先进的性能。我们的代码已公开可用：https://github.com/DFQ-Dojo/dfq-toolkit 。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [432] [Discovering and using Spelke segments](https://arxiv.org/abs/2507.16038)
> *发现与应用Spelke分割*

*Rahul Venkatesh, Klemen Kotar, Lilian Naing Chen, Seungwoo Kim, Luca Thomas Wheeler, Jared Watrous, Ashley Xu, Gia Ancone, Wanhee Lee, Honglin Chen, Daniel Bear, Stefan Stojanov, Daniel Yamins* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-21**

**Keywords:** Spelke分割, 因果运动, 对象分割, 视觉世界模型, 物体操作

**Comment:** Project page at: https://neuroailab.github.io/spelke_net

> **TL;DR:** 该论文提出并利用基于因果运动的Spelke分割，引入了SpelkeBench数据集和SpelkeNet模型，该模型在基准测试中表现优异，并能改进下游操作任务。

**AI_Comments:** 这篇论文提出了一种受生物学启发、与传统语义分割截然不同的分割方法，从语义标签转向因果运动。这可能带来更稳健和泛化性更强的对象理解，特别是在机器人和操作任务中。“统计反事实探测”的概念具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的计算机视觉分割依赖于语义和类别，而人类感知（Spelke对象）是类别无关的，基于因果运动，可能更好地支持操作和规划任务。本文旨在探索这种替代的分割方法。

**Method:** 1. 引入了SpelkeBench数据集，用于基准测试Spelke对象概念。2. 构建了SpelkeNet，一个训练用于预测未来运动分布的视觉世界模型。3. SpelkeNet能够估计运动可供性图（识别在戳动下可能移动的区域）和预期位移图（捕捉场景其余部分如何移动）。4. 利用“统计反事实探测”，通过施加“虚拟戳动”来定义Spelke分割，作为相关运动统计的统计聚合。

**Result:** 1. SpelkeNet在SpelkeBench上优于SegmentAnything (SAM)等有监督基线模型。2. Spelke概念对下游应用具有实际用处，在结合现成物体操作模型时，在3DEditBench物理物体操作基准测试中表现出卓越的性能。

**Conclusion:** 基于因果运动的Spelke分割提供了一种稳健、类别无关的替代传统语义分割的方法，并在分割和下游操作任务中表现出改进的性能。

> **ai_Abstract:** 该论文提出了一种新的对象分割方法——Spelke分割，其灵感来源于人类对Spelke对象的感知，侧重于类别无关的因果运动关系。论文引入了新的SpelkeBench数据集和SpelkeNet视觉世界模型，以算法方式提取这些分割。SpelkeNet通过“统计反事实探测”，利用运动可供性图和预期位移图来定义分割。实验结果表明，SpelkeNet在SpelkeBench上优于SegmentAnything (SAM)等有监督基线，并显著提高了物理对象操作任务的性能。

> **摘要翻译:** 计算机视觉中的分割通常由语义考虑定义，并且高度依赖于特定类别的约定。相比之下，发展心理学表明，人类根据Spelke对象感知世界——当受到物理力作用时，可靠地一起移动的物理事物的分组。因此，Spelke对象在类别无关的因果运动关系上运行，这可能更好地支持操作和规划等任务。在本文中，我们首先对Spelke对象概念进行基准测试，引入了SpelkeBench数据集，该数据集包含自然图像中各种定义明确的Spelke分割。接下来，为了从图像中算法提取Spelke分割，我们构建了SpelkeNet，这是一类视觉世界模型，训练用于预测未来运动的分布。SpelkeNet支持Spelke对象发现的两个关键概念的估计：（1）运动可供性图，识别在戳动下可能移动的区域，以及（2）预期位移图，捕捉场景其余部分将如何移动。这些概念用于“统计反事实探测”，其中对高运动可供性区域施加各种“虚拟戳动”，并使用由此产生的预期位移图将Spelke分割定义为相关运动统计的统计聚合。我们发现SpelkeNet在SpelkeBench上优于SegmentAnything (SAM)等有监督基线。最后，我们展示了Spelke概念对于下游应用具有实际用处，当在各种现成物体操作模型中使用时，在3DEditBench物理物体操作基准测试中表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [442] [PEBench: A Fictitious Dataset to Benchmark Machine Unlearning for Multimodal Large Language Models](https://arxiv.org/abs/2503.12545)
> *PEBench：一个用于基准测试多模态大语言模型机器遗忘的虚构数据集*

*Zhaopan Xu, Pengfei Zhou, Weidong Tang, Jiaxin Ai, Wangbo Zhao, Kai Wang, Xiaojiang Peng, Wenqi Shao, Hongxun Yao, Kaipeng Zhang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 机器遗忘, 多模态大语言模型, 基准测试, 隐私, 跨概念干扰

**Comment:** 

> **TL;DR:** PEBench是一个新的基准数据集，用于评估多模态大语言模型（MLLMs）中的机器遗忘（MU），它通过虚构的人员和事件场景数据，揭示了跨概念干扰问题，并提出了一种缓解冲突目标的方法。

**AI_Comments:** PEBench的创新之处在于其对多模态机器遗忘评估的全面性和细致性，特别是引入了虚构数据集来模拟真实的隐私场景。它不仅关注实体遗忘，更扩展到视觉概念及其语义耦合，这对于实际应用至关重要。论文提出的“跨概念干扰”是一个重要发现，揭示了机器遗忘在复杂多模态数据中可能面临的深层挑战。提出的缓解方法也为未来的研究提供了方向。该工作对提升MLLMs的隐私保护能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在视觉-语言任务中取得了显著成功，但其依赖于大规模互联网数据引发了隐私和安全问题。机器遗忘（MU）是解决这些问题的关键技术，但目前对MLLMs的MU评估不足，现有基准缺乏全面性，忽视了更广泛的视觉概念遗忘及其语义耦合。

**Method:** 我们引入了PEBench，这是一个新颖的基准，旨在全面评估MLLMs中的机器遗忘。PEBench包含一个虚构的个人实体和相应事件场景数据集，用于评估这些独特但相互关联概念的遗忘。我们利用该基准评估了五种机器遗忘方法。

**Result:** 我们揭示了所评估的五种机器遗忘方法的独特优势和劣势。研究发现，遗忘一个概念可能会无意中降低同一图像中相关概念的性能，我们称之为跨概念干扰。此外，我们证明了同时遗忘人物和事件概念的难度。

**Conclusion:** 本研究提出了PEBench基准来弥补MLLMs机器遗忘评估的不足，并揭示了跨概念干扰的挑战。我们还提出了一种有效的方法来缓解同时遗忘人物和事件概念时出现的冲突目标。

> **ai_Abstract:** 本研究介绍了PEBench，一个专为评估多模态大语言模型（MLLMs）中机器遗忘（MU）而设计的新型基准。针对现有评估不足的问题，PEBench构建了一个包含虚构人物实体和事件场景的数据集，用于测试模型遗忘不同但相互关联概念的能力。通过评估五种MU方法，研究揭示了“跨概念干扰”现象，即遗忘一个概念可能损害相关概念的性能。文章进一步探讨了同时遗忘人物和事件概念的挑战，并提出了一种有效的缓解策略。

> **摘要翻译:** 多模态大语言模型（MLLMs）在视觉-语言任务中取得了显著成功，但它们对大量互联网数据的依赖引发了重大的隐私和安全问题。机器遗忘（MU）已成为解决这些问题的关键技术，它能够在不进行昂贵再训练的情况下，从预训练模型中选择性地移除目标信息。然而，对MLLMs的MU评估仍然不足。现有基准通常缺乏全面的范围，只狭隘地关注实体，而忽略了对更广泛的视觉概念的遗忘以及它们之间固有的语义耦合。为了弥补这一差距，我们引入了PEBench，一个旨在促进对MLLMs中MU进行彻底评估的新型基准。PEBench包含一个虚构的个人实体和相应事件场景数据集，以评估这些独特但相互关联概念的遗忘。我们利用该基准评估了五种MU方法，揭示了它们独特的优势和劣势。我们的研究结果表明，遗忘一个概念可能会无意中降低同一图像中相关概念的性能，我们称之为跨概念干扰。此外，我们证明了同时遗忘人物和事件概念的难度，并提出了一种有效的方法来缓解这些冲突目标。源代码和基准可在https://pebench.github.io公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models](https://arxiv.org/abs/2507.16524)
> *空间3D-LLM：探索3D视觉-语言模型中的空间感知能力*

*Xiaoyan Wang, Zeju Li, Yifan Xu, Jiaxing Qi, Zhifei Yang, Ruifei Ma, Xiangde Liu, Chao Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 3D Vision-Language, Spatial Awareness, Large Language Models, Multimodal LLMs, Spatial Embeddings

**Comment:** Accepted by ICME2025

> **TL;DR:** Spatial 3D-LLM通过渐进式空间感知方案增强了3D视觉-语言任务中的空间意识，并在多项任务上取得了最先进的性能。

**AI_Comments:** 这篇论文通过引入“渐进式空间感知方案”和构建新的任务与数据集，有效地解决了现有3D MLLMs在空间感知方面的局限性。其创新点在于从根本上改善了3D场景的空间信息表示，而非仅仅依赖于整体压缩或独立对象分割。这对于提升3D视觉-语言模型的理解和交互能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有3D多模态LLMs在处理3D视觉-语言任务时，通过压缩整体3D场景信息或分割独立对象，限制了它们的空间感知能力，因为3D场景固有的丰富性未得到充分表示。

**Method:** 本文提出了Spatial 3D-LLM，一个专门为增强3D视觉-语言任务空间感知而设计的3D MLLM。它通过集成LLM骨干与渐进式空间感知方案来丰富3D场景的空间嵌入，该方案随着感知场的扩展逐步捕获空间信息，生成富含位置信息的3D场景嵌入作为视觉提示。此外，研究还引入了3D对象距离测量和3D布局编辑两个新任务，并构建了3D指令数据集MODEL来评估模型的空间感知能力。

**Result:** Spatial 3D-LLM在广泛的3D视觉-语言任务中取得了最先进的性能，这表明其渐进式空间感知方案在挖掘更深层次空间信息方面的改进。

**Conclusion:** 通过提出Spatial 3D-LLM及其渐进式空间感知方案，能够显著提升3D视觉-语言模型中的空间感知能力，并在相关任务中实现卓越表现。

> **ai_Abstract:** 本文提出了Spatial 3D-LLM，一个旨在增强3D视觉-语言模型空间感知能力的新型多模态大语言模型。针对现有模型空间感知不足的问题，Spatial 3D-LLM通过引入渐进式空间感知方案，逐步捕获并丰富3D场景的空间嵌入，生成富含位置信息的视觉提示。为评估模型效果，作者还提出了3D对象距离测量和3D布局编辑两项新任务，并构建了MODEL数据集。实验证明，Spatial 3D-LLM在多项3D视觉-语言任务上实现了最先进的性能，验证了其在挖掘深度空间信息方面的有效性。

> **摘要翻译:** 新时代为扩展大型语言模型（LLMs）以处理3D视觉-语言任务开启了令人兴奋的可能性。然而，大多数现有的3D多模态LLMs（MLLMs）依赖于压缩整体3D场景信息或分割独立对象来执行这些任务，这由于3D场景固有的丰富性未能得到充分表示而限制了它们的空间感知能力。为了克服这些限制，我们提出了Spatial 3D-LLM，一个专门为增强3D视觉-语言任务的空间感知而设计的3D MLLM，通过丰富3D场景的空间嵌入来实现。Spatial 3D-LLM将LLM骨干与渐进式空间感知方案相结合，该方案随着感知场的扩展逐步捕获空间信息，生成富含位置信息的3D场景嵌入以作为视觉提示。此外，我们引入了两个新颖的任务：3D对象距离测量和3D布局编辑，并构建了一个3D指令数据集MODEL，以评估模型的空间感知能力。实验结果表明，Spatial 3D-LLM在广泛的3D视觉-语言任务中取得了最先进的性能，揭示了我们渐进式空间感知方案在挖掘更深层次空间信息方面的改进。我们的代码可在https://github.com/bjshuyuan/Spatial-3D-LLM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [458] [DenseSR: Image Shadow Removal as Dense Prediction](https://arxiv.org/abs/2507.16472)
> *DenseSR：将图像去阴影视为密集预测*

*Yu-Fan Lin, Chia-Ming Lee, Chih-Chung Hsu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 图像去阴影, 密集预测, 深度学习, 几何语义先验, 密集融合块

**Comment:** Paper accepted to ACMMM 2025

> **TL;DR:** DenseSR是一种新的图像去阴影方法，通过密集预测解决现有方法在细节恢复和边界保持方面的不足，实现了高质量的去阴影效果。

**AI_Comments:** DenseSR的创新之处在于将图像去阴影问题重新定义为密集预测任务，并提出了一个结合深度场景理解和精细化特征融合的框架。其核心贡献是密集融合块（DFB），特别是其中的ACSM和TBRM，它们直接解决了传统方法中细节丢失和边界模糊的关键痛点。该方法通过引入几何语义先验来解决模糊性并隐式定位阴影，进一步增强了模型的鲁棒性。这为高质量的图像去阴影提供了一个有效且全面的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 阴影是图像质量下降的常见因素，单幅图像去阴影（尤其是在具有挑战性的间接照明下）受到非均匀内容退化和固有模糊性的影响。传统方法往往无法同时恢复阴影内部细节并保持清晰边界，导致恢复不一致和模糊，从而影响下游应用和整体观看体验。

**Method:** 我们提出了DenseSR框架，从密集预测的角度处理图像去阴影问题，以强调恢复质量。该框架结合了两种关键策略：1）由几何语义先验引导的深度场景理解，用于解决模糊性并隐式定位阴影；2）通过解码器中新颖的密集融合块（DFB）实现高保真恢复。DFB采用自适应组件处理，使用自适应内容平滑模块（ACSM）实现一致的外观，并使用纹理-边界恢复模块（TBRM）处理精细纹理和清晰边界，从而直接解决恢复不一致和模糊问题。这些经过专门处理的组件被有效融合，产生优化的特征表示，同时保持一致性和保真度。

**Result:** 广泛的实验结果表明，我们的方法优于现有方法。

**Conclusion:** DenseSR通过其独特的密集预测方法，结合深度场景理解和高保真恢复策略，成功克服了传统图像去阴影方法的局限性，实现了高质量的阴影去除，并有效解决了细节恢复和边界保持的挑战。

> **ai_Abstract:** DenseSR提出了一种新的图像去阴影方法，旨在解决现有技术在恢复阴影内部细节和保持清晰边界方面的不足。该方法将去阴影视为密集预测问题，并整合了深度场景理解（通过几何语义先验）和高保真恢复（通过新颖的密集融合块DFB）。DFB包含自适应内容平滑模块（ACSM）和纹理-边界恢复模块（TBRM），以确保恢复的一致性和细节。实验结果表明，DenseSR优于现有方法，提升了去阴影质量。

> **摘要翻译:** 阴影是降低图像质量的常见因素。单幅图像去阴影（SR），尤其是在具有挑战性的间接照明下，受到非均匀内容退化和固有模糊性的阻碍。因此，传统方法往往无法同时恢复阴影内部细节并保持清晰边界，导致恢复不一致和模糊，从而对下游应用和整体观看体验产生负面影响。为了克服这些局限性，我们提出了DenseSR，从密集预测的角度处理这个问题，以强调恢复质量。该框架独特地协同了两种关键策略：(1) 由几何语义先验引导的深度场景理解，以解决模糊性并隐式定位阴影，以及 (2) 通过解码器中新颖的密集融合块（DFB）实现高保真恢复。DFB采用自适应组件处理——使用自适应内容平滑模块（ACSM）实现一致的外观，并使用纹理-边界恢复模块（TBRM）处理精细纹理和清晰边界——从而直接解决恢复不一致和模糊问题。这些经过专门处理的组件被有效融合，产生优化的特征表示，同时保持一致性和保真度。广泛的实验结果证明了我们方法优于现有方法的优点。我们的代码可在 https://github.com/VanLinLin/DenseSR 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [465] [Enhancing Domain Diversity in Synthetic Data Face Recognition with Dataset Fusion](https://arxiv.org/abs/2507.16790)
> *使用数据集融合增强合成数据人脸识别中的域多样性*

*Anjith George, Sebastien Marcel* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 合成数据, 人脸识别, 数据集融合, 域多样性, 模型正则化

**Comment:** Accepted in ICCV Workshops 2025

> **TL;DR:** 通过融合来自不同生成器模型的合成人脸数据集，减少模型特有伪影，提高多样性，从而提升合成数据训练的人脸识别模型性能。

**AI_Comments:** 该论文的创新点在于提出了一种简单而有效的数据集融合策略，通过结合来自不同架构生成器的合成数据，解决了单一生成器数据多样性不足和过拟合的问题。这对于在保护隐私的前提下提升合成数据在人脸识别领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸识别训练数据集常通过网络爬取获得，存在伦理和隐私问题。虽然合成数据是替代方案，但其训练的模型性能通常不如真实数据，且单一生成器模型产生的合成数据存在模型特有伪影，导致对生成器固有偏差的过拟合。

**Method:** 提出通过结合两个使用不同架构骨干生成的最先进合成人脸数据集来解决问题。这种融合旨在减少模型特有伪影，增强姿态、光照和人口统计学多样性，并通过强调身份相关特征来隐式正则化人脸识别模型。

**Result:** 该方法在标准人脸识别基准测试中，使用组合数据集训练的模型表现出卓越的性能。

**Conclusion:** 通过融合来自不同生成器的合成数据集，可以有效减少模型特有伪影，增加数据多样性，并提升合成数据训练的人脸识别模型的性能，使其在多个基准测试中表现优异。

> **ai_Abstract:** 本文提出一种通过融合来自不同生成器模型的最先进合成人脸数据集的方法，以解决合成数据训练人脸识别模型性能不佳的问题。该方法旨在减少模型特有伪影，增加数据多样性（姿态、光照、人口统计学），并隐式正则化模型。实验结果表明，在融合数据集上训练的模型在多个标准人脸识别基准测试中取得了优越的性能。

> **摘要翻译:** 尽管近年来人脸识别系统的准确性显著提高，但用于训练这些模型的数据集通常是通过网络爬取收集的，未经用户明确同意，这引发了伦理和隐私问题。为了解决这个问题，许多最近的方法探索了使用合成数据来训练人脸识别模型。然而，与使用真实世界数据训练的模型相比，这些模型通常表现不佳。一个常见的限制是，通常使用单一生成器模型来创建整个合成数据集，这会导致模型特有的伪影，可能导致对生成器固有偏差和伪影的过拟合。在这项工作中，我们提出了一种解决方案，通过结合两个使用不同架构骨干生成的最先进合成人脸数据集。这种融合减少了模型特有的伪影，增强了姿态、光照和人口统计学方面的多样性，并通过强调身份相关特征来隐式正则化人脸识别模型。我们使用标准人脸识别基准测试评估了在此组合数据集上训练的模型性能，并证明我们的方法在其中许多基准测试中取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [Positive Style Accumulation: A Style Screening and Continuous Utilization Framework for Federated DG-ReID](https://arxiv.org/abs/2507.16238)
> *积极风格累积：一种用于联邦域泛化行人重识别的风格筛选与持续利用框架*

*Xin Xu, Chaoyue Ren, Wei Liu, Wenke Huang, Bin Yang, Zhixi Yu, Kui Jiang* | **Category: cs.CV, I.4.9; I.2.10** | **Updated: 2025-07-22**

**Keywords:** 联邦域泛化, 行人重识别, 风格筛选, 积极风格, 持续利用

**Comment:** 10 pages, 3 figures, accepted at ACM MM 2025, Submission ID: 4394

> **TL;DR:** 针对联邦域泛化行人重识别(FedDG-ReID)中并非所有风格变换都有益于泛化性能的问题，本文提出了风格筛选与持续利用(SSCU)框架，通过泛化增益引导的动态风格记忆(GGDSM)和协同风格训练(CST)策略，有效筛选并持续利用积极风格，显著提升了模型的泛化能力。

**AI_Comments:** 本文的创新点在于明确识别并解决了联邦域泛化行人重识别中“消极风格”的问题，并为此设计了一套完整的解决方案。通过引入泛化增益引导的动态风格记忆（GGDSM）进行风格筛选和累积，以及协同风格训练（CST）策略实现双分支训练，确保了积极风格的有效利用和模型的泛化能力提升。这对于提升联邦学习环境下行人重识别模型的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦域泛化行人重识别(FedDG-ReID)旨在通过分布式源域数据学习可有效泛化到源域和目标域的全局服务器模型。现有方法主要通过风格变换提高样本多样性，但研究发现并非所有风格都有助于模型的泛化性能，一些风格甚至可能有害。因此，如何有效筛选并持续利用对模型泛化性能有益的积极风格成为了一个新问题。

**Method:** 本文提出了风格筛选与持续利用(SSCU)框架来解决上述问题。首先，为每个客户端模型设计了泛化增益引导的动态风格记忆(GGDSM)模块，用于筛选和累积生成的积极风格。其次，提出了风格记忆识别损失，以充分利用记忆中存储的积极风格。此外，还提出了一种协同风格训练(CST)策略，该策略不同于传统学习策略，通过在两个独立分支上使用新生成的风格和记忆中累积的积极风格来训练客户端模型，旨在促进客户端模型快速获取新风格并保证积极风格的持续充分利用。

**Result:** 广泛的实验结果表明，本文提出的方法在源域和目标域的性能均优于现有方法。

**Conclusion:** 通过提出风格筛选与持续利用(SSCU)框架，包括泛化增益引导的动态风格记忆(GGDSM)和协同风格训练(CST)策略，本文成功解决了联邦域泛化行人重识别中积极风格的筛选与持续利用问题，显著提升了模型在源域和目标域的泛化性能。

> **ai_Abstract:** 本文针对联邦域泛化行人重识别（FedDG-ReID）中风格变换并非总能提升泛化性能的问题，提出了风格筛选与持续利用（SSCU）框架。该框架首先区分了对模型泛化性能有益的“积极风格”与有害的“消极风格”。为解决积极风格的有效筛选与持续利用问题，SSCU框架引入了泛化增益引导的动态风格记忆（GGDSM）以筛选和累积积极风格，并辅以风格记忆识别损失以充分利用这些记忆。此外，论文还提出了一种协同风格训练（CST）策略，该策略通过在两个独立分支上同时利用新生成的风格和累积的积极风格来训练客户端模型，确保新风格的快速获取和积极风格的持续有效利用。实验结果表明，该方法在源域和目标域均优于现有方法，显著提升了模型的泛化性能。

> **摘要翻译:** 联邦域泛化行人重识别（FedDG-ReID）旨在学习一个全局服务器模型，该模型可以通过分布式源域数据有效地泛化到源域和目标域。现有方法主要通过风格变换来提高样本多样性，这在一定程度上增强了模型的泛化性能。然而，我们发现并非所有风格都有助于泛化性能。因此，我们将对模型泛化性能有益或有害的风格定义为积极或消极风格。在此基础上，产生了新的问题：如何有效筛选和持续利用积极风格。为了解决这些问题，我们提出了一种风格筛选与持续利用（SSCU）框架。首先，我们为每个客户端模型设计了一个泛化增益引导的动态风格记忆（GGDSM），用于筛选和累积生成的积极风格。同时，我们提出了一种风格记忆识别损失，以充分利用记忆中记忆的积极风格。此外，我们提出了一种协同风格训练（CST）策略，以充分利用积极风格。与传统学习策略不同，我们的方法利用新生成的风格和记忆中累积的积极风格在两个不同的分支上训练客户端模型。这种训练策略旨在有效促进客户端模型快速获取新风格，并保证积极风格的持续充分利用，这对模型的泛化性能非常有益。大量的实验结果表明，我们的方法在源域和目标域都优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [473] [FiVE: A Fine-grained Video Editing Benchmark for Evaluating Emerging Diffusion and Rectified Flow Models](https://arxiv.org/abs/2503.13684)
> *FiVE：一个用于评估新兴扩散和整流流模型的细粒度视频编辑基准*

*Minghan Li, Chenxi Xie, Yichen Wu, Lei Zhang, Mengyu Wang* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 细粒度视频编辑, 基准, 扩散模型, 整流流模型, 文本到视频编辑

**Comment:** 24 pages, 14 figures, 16 tables

> **TL;DR:** 引入了FiVE，一个细粒度视频编辑基准，用于评估新兴的扩散和整流流模型，并发现整流流模型（特别是Wan-Edit）在性能和超参数敏感性方面优于扩散模型。

**AI_Comments:** 本文的创新点在于提出了一个急需的标准化细粒度视频编辑基准FiVE，解决了现有评估方法不一致的问题。同时，引入了FiVE-Acc这一基于VLM的新指标，提高了对象级评估的准确性。更重要的是，研究结果揭示了整流流模型在视频编辑方面的优越性，并成功地将其适应为高效的编辑模型，为未来的视频生成和编辑研究提供了新的方向和工具。

<details>
  <summary>Details</summary>

**Motivation:** 当前缺乏一个标准化的基准来公平评估新兴的文本到视频（T2V）编辑方法，导致声明不一致且无法评估模型对超参数的敏感性。细粒度视频编辑对于实现精确的对象级修改同时保持上下文和时间一致性至关重要。

**Method:** 引入FiVE基准，包含74个真实世界视频和26个生成视频，具有6种细粒度编辑类型、420对对象级编辑提示及其掩码。通过引入FlowEdit将最新的整流流T2V生成模型（Pyramid-Flow和Wan2.1）适应为无训练、无反演的视频编辑模型（Pyramid-Edit和Wan-Edit）。使用15个指标（涵盖背景保留、文本-视频相似性、时间一致性、视频质量和运行时）评估了五种基于扩散和两种基于RF的编辑方法。引入了FiVE-Acc，一种利用视觉-语言模型（VLMs）评估细粒度视频编辑成功率的新颖指标。

**Result:** 实验结果表明，基于RF的编辑方法显著优于基于扩散的方法。Wan-Edit实现了最佳的整体性能，并表现出对超参数的最小敏感性。

**Conclusion:** 整流流模型，特别是Wan-Edit，在细粒度视频编辑方面表现出卓越的性能和稳定性，使其成为视频编辑领域有前景的方向。FiVE基准和FiVE-Acc指标为未来研究提供了标准化的评估工具。

> **ai_Abstract:** 本文介绍了FiVE，一个用于评估新兴扩散和整流流模型的细粒度视频编辑基准。该基准包含真实世界和生成视频，以及多种细粒度编辑类型和对象级编辑提示。作者还通过FlowEdit将整流流T2V模型（Pyramid-Flow和Wan2.1）适应为无需训练和反演的视频编辑模型。通过FiVE基准和新引入的FiVE-Acc指标，评估了多种扩散和整流流编辑方法，结果表明整流流方法，特别是Wan-Edit，在性能和对超参数的敏感性方面均优于扩散方法。

> **摘要翻译:** 最近出现了许多文本到视频（T2V）编辑方法，但由于缺乏用于公平评估的标准化基准，导致声明不一致，并且无法评估模型对超参数的敏感性。细粒度视频编辑对于实现精确的对象级修改同时保持上下文和时间一致性至关重要。为了解决这个问题，我们引入了FiVE，一个用于评估新兴扩散和整流流模型的细粒度视频编辑基准。我们的基准包括74个真实世界视频和26个生成视频，具有6种细粒度编辑类型、420对对象级编辑提示及其对应的掩码。此外，我们通过引入FlowEdit，调整了最新的整流流（RF）T2V生成模型Pyramid-Flow和Wan2.1，从而产生了无需训练和无需反演的视频编辑模型Pyramid-Edit和Wan-Edit。我们使用15个指标（涵盖背景保留、文本-视频相似性、时间一致性、视频质量和运行时）在我们的FiVE基准上评估了五种基于扩散和两种基于RF的编辑方法。为了进一步增强对象级评估，我们引入了FiVE-Acc，一种利用视觉-语言模型（VLMs）评估细粒度视频编辑成功率的新颖指标。实验结果表明，基于RF的编辑显著优于基于扩散的方法，其中Wan-Edit实现了最佳的整体性能并表现出对超参数的最小敏感性。更多视频演示可在匿名网站上获得：https://sites.google.com/view/five-benchmark

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [480] [Disrupting Semantic and Abstract Features for Better Adversarial Transferability](https://arxiv.org/abs/2507.16052)
> *扰乱语义和抽象特征以提高对抗性迁移能力*

*Yuyang Luo, Xiaosen Wang, Zhijin Ge, Yingzhe He* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 对抗性样本, 迁移能力, 语义特征, 抽象特征, SAFER

**Comment:** 

> **TL;DR:** 提出了一种名为SAFER的新方法，通过同时扰乱语义和抽象特征来提高对抗性样本的迁移能力。

**AI_Comments:** 本文的创新点在于认识到高频抽象特征在对抗性迁移中的作用，并提出了一种平衡的方法SAFER，同时扰乱语义和抽象特征。这为提升黑盒对抗性攻击的有效性提供了新的思路，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有特征级攻击主要操纵语义信息来推导权重矩阵，而CNN更关注高频分量。本文旨在通过同时扰乱语义和抽象特征来提高对抗性样本的迁移能力。

**Method:** 提出了一种名为SAFER的平衡方法。SAFER在计算权重矩阵时，对输入图像进行BLOCKMIX，并对频谱进行SELF-MIX，以突出关键特征。通过这种权重矩阵，攻击者可以同时扰乱语义和抽象特征。

**Result:** 在ImageNet数据集上的大量实验表明，该方法在提高对抗性迁移能力方面是有效的。

**Conclusion:** 通过扰乱语义和抽象特征，可以有效提高对抗性样本的迁移能力，SAFER方法在实验中表现出良好的效果。

> **ai_Abstract:** 本文提出了一种名为SAFER（语义和抽象特征扰动）的新方法，旨在提高对抗性样本的迁移能力。研究发现，现有特征级攻击主要侧重于语义信息，而高频抽象特征也对迁移性有影响。SAFER通过在计算特征重要性权重矩阵时，结合对输入图像的BLOCKMIX和对频率频谱的SELF-MIX，同时扰乱语义和抽象特征。实验结果表明，该方法能有效提升对抗性样本的迁移能力。

> **摘要翻译:** 对抗性样本对深度神经网络（DNN）构成了重大威胁，它们在黑盒设置下的可迁移性导致了基于迁移的攻击的出现，使得针对采用DNN的现实世界应用成为可能。其中，特征级攻击通过从变换图像计算的特征重要性权重矩阵来扰动中间特征，已获得普及。在这项工作中，我们发现现有特征级攻击主要操纵语义信息来推导权重矩阵。受一些发现CNN倾向于更多关注高频分量（即抽象特征，例如纹理、边缘等）的工作的启发，我们验证了在高频空间中变换图像也能提高可迁移性。基于这一发现，我们提出了一种名为语义和抽象特征扰动（SAFER）的平衡方法。具体来说，SAFER在计算权重矩阵时，对输入图像进行BLOCKMIX，并对频谱进行SELF-MIX，以突出关键特征。通过使用这样的权重矩阵，我们可以引导攻击者扰乱语义和抽象特征，从而提高可迁移性。在ImageNet数据集上的大量实验也证明了我们方法在提高对抗性迁移能力方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [488] [EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion](https://arxiv.org/abs/2507.16535)
> *EarthCrafter：通过双稀疏潜在扩散实现可扩展的3D地球生成*

*Shang Liu, Chenjie Cao, Chaohui Yu, Wen Qian, Jing Wang, Fan Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 3D地球生成, 潜在扩散, 大规模建模, Aerial-Earth3D, 地理信息系统

**Comment:** 

> **TL;DR:** EarthCrafter提出了一种新的框架，通过构建迄今为止最大的3D航空数据集Aerial-Earth3D和采用双稀疏潜在扩散架构，解决了大规模3D地球生成中扩展性挑战。

**AI_Comments:** EarthCrafter的创新之处在于其双重突破：首先是构建了迄今为止最大的3D航空数据集Aerial-Earth3D，这为大规模3D生成提供了坚实的数据基础；其次是提出了稀疏解耦的潜在扩散架构，有效解决了大规模地理范围带来的计算成本问题，并通过分离结构和纹理生成提高了效率和灵活性。该方法在大规模3D地球建模领域具有重要意义，为未来的相关研究提供了新的方向和工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管最近的3D生成工作取得了显著进展，但将这些方法扩展到地理范围（例如建模数千平方公里的地球表面）仍然是一个开放的挑战。

**Method:** 本文通过数据基础设施和模型架构的双重创新来解决问题。首先，引入了迄今为止最大的3D航空数据集Aerial-Earth3D，包含5万个精心策划的场景（每个600m x 600m），涵盖美国大陆，包含4500万个多视图Google Earth帧。每个场景提供姿态标注的多视图图像、深度图、法线、语义分割和相机姿态。其次，提出了EarthCrafter框架，通过稀疏解耦的潜在扩散进行大规模3D地球生成。其架构分离了结构和纹理生成：1）双稀疏3D-VAEs将高分辨率几何体素和纹理2D高斯散斑（2DGS）压缩到紧凑的潜在空间。2）提出了在混合输入（语义、图像或两者都没有）上训练的条件感知流匹配模型，以独立灵活地建模潜在几何和纹理特征。

**Result:** 大量实验表明，EarthCrafter在超大规模生成方面表现显著更好。该框架还支持多种应用，从语义引导的城市布局生成到无条件地形合成，同时通过Aerial-Earth3D的丰富数据先验保持地理合理性。

**Conclusion:** EarthCrafter通过其创新的数据基础设施和双稀疏潜在扩散架构，成功解决了大规模3D地球生成的扩展性问题，并在各种应用中表现出色，保持了地理合理性。

> **ai_Abstract:** 本文介绍了EarthCrafter，一个用于大规模3D地球生成的框架，旨在解决现有方法在地理范围扩展上的挑战。它通过引入迄今最大的3D航空数据集Aerial-Earth3D（包含5万个场景和4500万帧多视图Google Earth数据）和创新的双稀疏潜在扩散架构实现。该架构将结构和纹理生成分离，利用双稀疏3D-VAEs压缩几何和纹理数据，并使用条件感知流匹配模型独立建模潜在特征。实验证明EarthCrafter在超大规模生成方面表现优异，并支持语义引导的城市布局生成和无条件地形合成等多种应用。

> **摘要翻译:** 尽管最近的3D生成工作取得了显著进展，但将这些方法扩展到地理范围，例如建模数千平方公里的地球表面，仍然是一个开放的挑战。我们通过数据基础设施和模型架构的双重创新来解决这个问题。首先，我们介绍了Aerial-Earth3D，迄今为止最大的3D航空数据集，包含5万个精心策划的场景（每个600m x 600m），涵盖美国大陆，包含4500万个多视图Google Earth帧。每个场景提供姿态标注的多视图图像、深度图、法线、语义分割和相机姿态，并进行明确的质量控制以确保地形多样性。在此基础上，我们提出了EarthCrafter，一个通过稀疏解耦的潜在扩散进行大规模3D地球生成的定制框架。我们的架构分离了结构和纹理生成：1）双稀疏3D-VAEs将高分辨率几何体素和纹理2D高斯散斑（2DGS）压缩到紧凑的潜在空间，在很大程度上减轻了因巨大地理规模而导致的昂贵计算，同时保留了关键信息。2）我们提出了在混合输入（语义、图像或两者都没有）上训练的条件感知流匹配模型，以灵活地独立建模潜在几何和纹理特征。大量实验表明，EarthCrafter在超大规模生成方面表现显著更好。该框架进一步支持多种应用，从语义引导的城市布局生成到无条件地形合成，同时通过我们来自Aerial-Earth3D的丰富数据先验保持地理合理性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [492] [Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts](https://arxiv.org/abs/2507.16476)
> *基于切片级图聚类和混合密度专家的全玻片图像生存建模*

*Ardhendu Sekhar, Vasu Soni, Keshav Aske, Garima Jain, Pranav Jeevan, Amit Sethi* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 生存建模, 全玻片图像, 图聚类, 混合密度模型, 癌症预后

**Comment:** 

> **TL;DR:** 该论文提出了一种模块化框架，通过整合动态图像块选择、图引导K均值聚类、注意力机制和专家引导混合密度模型，从全玻片图像中预测癌症特异性生存期，显著提高了现有技术的准确性。

**AI_Comments:** 该论文的创新之处在于其提出的模块化框架，该框架有效地结合了多种先进技术来解决全玻片图像分析中的挑战，特别是数据量大和异质性复杂的问题。通过动态图像块选择、图聚类、注意力机制和混合密度模型，该方法能够从高维病理图像中提取出更具预后价值的特征，并对生存分布进行更精细的建模。其在两种不同癌症类型上的显著性能提升，凸显了该方法在临床应用中的巨大潜力，为精准医疗提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有技术在从全玻片图像预测癌症特异性生存期方面的准确性有待提高，因此需要开发一种能够显著改进预测准确性的新方法。

**Method:** 该方法包含四个关键组件：1) 通过基于分位数阈值的动态图像块选择来隔离具有预后信息意义的组织区域；2) 使用图引导的K均值聚类通过空间和形态学相干性捕获表型水平异质性；3) 使用注意力机制建模簇内和簇间关系，将局部特征与不同组织区室之间的全局空间关系联系起来；4) 使用专家引导的混合密度模型，利用高斯混合模型估计复杂的生存分布。

**Result:** 该模型在TCGA-KIRC（肾癌）数据集上取得了0.712 ± 0.028的一致性指数和0.254 ± 0.018的Brier分数；在TCGA-LUAD（肺腺癌）数据集上取得了0.645 ± 0.017的一致性指数和0.281 ± 0.031的Brier分数。这些结果显著优于现有技术。

**Conclusion:** 所提出的方法在多种癌症类型中展现出预测潜力，并显著优于现有技术，能够更准确地从全玻片图像预测癌症特异性生存期。

> **ai_Abstract:** 本研究提出了一种创新的模块化框架，用于通过全玻片图像预测癌症特异性生存期，其准确性显著超越了现有技术。该框架整合了动态图像块选择、图引导K均值聚类、注意力机制以及专家引导混合密度建模四个关键组件，以有效处理大规模图像数据、捕捉组织异质性并估计复杂的生存分布。在TCGA-KIRC和TCGA-LUAD数据集上的实验结果表明，该方法在一致性指数和Brier分数方面均表现出色，证明了其在多种癌症类型中强大的预测能力。

> **摘要翻译:** 我们引入了一个模块化框架，用于从全玻片病理图像（WSIs）预测癌症特异性生存期，该框架显著提高了现有技术的准确性。我们的方法整合了四个关键组件。首先，为了解决WSI的大尺寸问题，我们通过基于分位数阈值的动态图像块选择来隔离具有预后信息意义的组织区域。其次，我们使用图引导的K均值聚类通过空间和形态学相干性捕获表型水平异质性。第三，我们使用注意力机制建模簇内和簇间关系，将局部特征与不同类型组织区室之间的全局空间关系联系起来。最后，我们使用专家引导的混合密度模型，利用高斯混合模型估计复杂的生存分布。所提出的模型在TCGA-KIRC（肾癌）数据集上取得了0.712 ± 0.028的一致性指数和0.254 ± 0.018的Brier分数，在TCGA-LUAD（肺腺癌）数据集上取得了0.645 ± 0.017的一致性指数和0.281 ± 0.031的Brier分数。这些结果显著优于现有技术，并证明了所提出的方法在多种癌症类型中的预测潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [494] [HOComp: Interaction-Aware Human-Object Composition](https://arxiv.org/abs/2507.16813)
> *HOComp：交互感知的人体-物体合成*

*Dong Liang, Jinyuan Jia, Yuhao Liu, Rynson W. H. Lau* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 人体-物体合成, 交互感知, 姿态引导, 外观保持, 图像合成

**Comment:** 

> **TL;DR:** HOComp提出了一种新颖的方法，用于将前景物体合成到以人为中心的背景图像中，确保前景物体与背景人物之间和谐的交互和一致的外观。

**AI_Comments:** HOComp的创新之处在于其对人体-物体交互的深入理解和建模，特别是引入MLLMs来识别交互区域和类型，并结合姿态引导和外观保持机制，有效解决了现有合成方法在处理复杂交互时的局限性。同时，提出专用的数据集也为该领域的研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像引导合成方法在处理涉及人体-物体交互的任务时，难以合成无缝的交互感知合成，尽管它们可以帮助将前景物体插入到背景图像的指定区域并实现自然融合。

**Method:** 本文提出了HOComp，一种新颖的人体-物体合成方法，包含两个关键设计：1) MLLMs驱动的基于区域的姿态引导（MRPG），利用MLLMs识别交互区域和交互类型，为生成的交互姿态提供粗到细的约束，并结合人体姿态地标跟踪动作变化和强制细粒度姿态约束；2) 细节一致的外观保持（DCAP），统一了形状感知注意力调制机制、多视角外观损失和背景一致性损失，以确保前景的形状/纹理一致性以及背景人物的忠实再现。此外，还提出了首个针对该任务的数据集IHOC（Interaction-aware Human-Object Composition）。

**Result:** 在IHOC数据集上的实验结果表明，HOComp能够有效地生成具有一致外观的和谐人体-物体交互，并在定性和定量上优于相关方法。

**Conclusion:** HOComp成功解决了现有方法在人体-物体交互合成中的不足，通过其创新的设计实现了和谐且外观一致的合成效果。

> **ai_Abstract:** 本文提出HOComp，一种新颖的人体-物体合成方法，旨在解决现有方法在处理人体-物体交互合成时遇到的挑战。HOComp通过结合MLLMs驱动的区域姿态引导（MRPG）和细节一致的外观保持（DCAP）两大核心设计，确保前景物体与背景人物之间实现和谐且外观一致的交互。同时，本文还构建了首个交互感知人体-物体合成数据集（IHOC）。实验结果表明，HOComp在生成高质量的人体-物体交互方面表现出色，并优于现有方法。

> **摘要翻译:** 虽然现有的图像引导合成方法可以帮助将前景物体插入到背景图像的用户指定区域，并在该区域内实现与图像其余部分不变的自然融合，但我们观察到，当任务涉及人体-物体交互时，这些现有方法往往难以合成无缝的交互感知合成。在本文中，我们首先提出了HOComp，这是一种将前景物体合成到以人为中心的背景图像上的新颖方法，同时确保前景物体与背景人物之间和谐的交互以及它们一致的外观。我们的方法包括两个关键设计：（1）MLLMs驱动的基于区域的姿态引导（MRPG），它利用MLLMs识别交互区域以及交互类型（例如，持有和离开），为生成的交互姿态提供从粗到细的约束，同时结合人体姿态地标来跟踪动作变化并强制细粒度姿态约束；（2）细节一致的外观保持（DCAP），它统一了形状感知注意力调制机制、多视角外观损失和背景一致性损失，以确保前景的形状/纹理一致性以及背景人物的忠实再现。然后，我们提出了第一个针对该任务的数据集，命名为交互感知人体-物体合成（IHOC）。在我们的数据集上的实验结果表明，HOComp有效地生成了具有一致外观的和谐人体-物体交互，并在定性和定量上优于相关方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [496] [Learning Streaming Video Representation via Multitask Training](https://arxiv.org/abs/2504.20041)
> *通过多任务训练学习流式视频表示*

*Yibin Yan, Jilan Xu, Shangzhe Di, Yikun Liu, Yudi Shi, Qirui Chen, Zeqian Li, Yifei Huang, Weidi Xie* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 流式视频理解, 多任务训练, StreamFormer, 因果时序注意力, 实时应用

**Comment:** Technical Report. Project Page:
  https://go2heart.github.io/streamformer

> **TL;DR:** 本文提出StreamFormer，一个结合因果时序注意力的视觉Transformer，并通过多任务视觉-语言对齐框架进行训练，以高效处理流式视频，并在在线动作检测、在线视频实例分割和视频问答任务上取得有竞争力的结果。

**AI_Comments:** 本文的创新点在于提出了StreamFormer架构，并结合了因果时序注意力与多任务视觉-语言对齐训练范式，有效解决了流式视频理解中实时性与信息保留的难题。其重要性在于为具身AI和自动驾驶等实时应用提供了一个高效且高性能的视频理解解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 理解连续视频流对于具身AI和自动驾驶等实时应用至关重要。与离线视频理解不同，流式视频理解需要逐帧处理、保留历史信息并进行低延迟决策，以应对这些挑战。

**Method:** 本文开发了一种名为StreamFormer的新型流式视频骨干网络，将因果时序注意力整合到预训练的视觉Transformer中。为了训练StreamFormer，提出在一个多任务视觉-语言对齐框架中统一多种时空视频理解任务。

**Result:** StreamFormer在在线动作检测、在线视频实例分割和视频问答方面取得了有竞争力的结果，同时保持了效率。

**Conclusion:** StreamFormer在流式视频理解任务中表现出强大的潜力，能够高效处理视频流并保持高性能，适用于实时应用。

> **ai_Abstract:** 本文针对流式视频理解的挑战，提出了一种名为StreamFormer的新型流式视频骨干网络。StreamFormer通过将因果时序注意力融入预训练的视觉Transformer，并利用多任务视觉-语言对齐框架进行训练，使其能够同时学习全局语义、时间动态和细粒度空间关系。实验证明，StreamFormer在在线动作检测、在线视频实例分割和视频问答等任务上表现出高效且有竞争力的性能，适用于实时应用。

> **摘要翻译:** 理解连续视频流在具身AI和自动驾驶等实时应用中扮演着基础角色。与离线视频理解不同，流式视频理解需要逐帧处理视频流、保留历史信息并做出低延迟决策。为了应对这些挑战，我们的主要贡献有三方面。(i) 我们开发了一种新颖的流式视频骨干网络，命名为StreamFormer，通过将因果时序注意力整合到预训练的视觉Transformer中。这使得高效的流式视频处理成为可能，同时保持了图像表示能力。(ii) 为了训练StreamFormer，我们提出在一个多任务视觉-语言对齐框架中统一各种时空视频理解任务。因此，StreamFormer能够同时学习全局语义、时间动态和细粒度空间关系。(iii) 我们在在线动作检测、在线视频实例分割和视频问答方面进行了广泛实验。StreamFormer在保持效率的同时取得了有竞争力的结果，展示了其在实时应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [499] [ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](https://arxiv.org/abs/2507.16815)
> *ThinkAct：通过强化视觉潜在规划实现的视觉-语言-动作推理*

*Chi-Pin Huang, Yueh-Hua Wu, Min-Hung Chen, Yu-Chiang Frank Wang, Fu-En Yang* | **Category: cs.CV, cs.AI, cs.LG, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 视觉-语言-动作推理, 视觉潜在规划, 强化学习, 具身AI, 机器人操纵

**Comment:** Project page: https://jasper0314-huang.github.io/thinkact-vla/

> **TL;DR:** ThinkAct是一个双系统框架，通过强化视觉潜在规划，将高级推理与低级动作执行结合起来，以解决现有视觉-语言-动作（VLA）模型在多步骤规划和复杂任务适应性方面的局限性。

**AI_Comments:** ThinkAct的创新之处在于其双系统架构，通过引入强化视觉潜在规划，有效地弥补了高级推理与低级动作执行之间的鸿沟。这种显式的规划机制增强了模型处理长视野任务和复杂环境变化的鲁棒性，是具身AI领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型通常以端到端的方式训练，直接将输入映射到动作，缺乏显式推理，这阻碍了它们在多步骤规划或适应复杂任务变化方面的能力。

**Method:** 本文提出了ThinkAct，一个双系统框架，通过强化视觉潜在规划将高级推理与低级动作执行连接起来。ThinkAct训练一个多模态LLM生成具身推理计划，该计划通过基于目标完成和轨迹一致性的动作对齐视觉奖励进行强化引导。这些推理计划被压缩成一个视觉计划潜在空间，用于调节下游动作模型，以在目标环境中进行稳健的动作执行。

**Result:** 在具身推理和机器人操纵基准上的大量实验表明，ThinkAct在复杂的具身AI任务中实现了少样本适应、长视野规划和自我纠正行为。

**Conclusion:** ThinkAct通过结合高级推理和低级动作执行，能够有效解决复杂的视觉-语言-动作推理任务中的多步骤规划和适应性问题。

> **ai_Abstract:** 本文提出了ThinkAct，一个用于视觉-语言-动作（VLA）推理的双系统框架。它通过强化视觉潜在规划，将高级推理（由多模态LLM生成并由视觉奖励强化）与低级动作执行相结合。该方法克服了现有端到端VLA模型在多步骤规划和复杂任务适应性方面的局限性，并在具身推理和机器人操纵任务中展示了少样本适应、长视野规划和自我纠正能力。

> **摘要翻译:** 视觉-语言-动作（VLA）推理任务要求智能体解释多模态指令，执行长视野规划，并在动态环境中自适应行动。现有方法通常以端到端的方式训练VLA模型，直接将输入映射到动作，没有显式推理，这阻碍了它们在多步骤规划或适应复杂任务变化方面的能力。在本文中，我们提出了ThinkAct，一个双系统框架，通过强化视觉潜在规划将高级推理与低级动作执行连接起来。ThinkAct训练一个多模态LLM，通过基于目标完成和轨迹一致性的动作对齐视觉奖励来生成具身推理计划。这些推理计划被压缩成一个视觉计划潜在空间，用于调节下游动作模型，以在目标环境中进行稳健的动作执行。在具身推理和机器人操纵基准上的大量实验表明，ThinkAct在复杂的具身AI任务中实现了少样本适应、长视野规划和自我纠正行为。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling](https://arxiv.org/abs/2507.16240)
> *指令缩放：通过自适应注意力缩放增强统一图像生成模型的指令遵循保真度*

*Chao Zhou, Tianyi Wei, Nenghai Yu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 统一图像生成, 指令遵循, 自适应注意力缩放, 交叉注意力, 指令忽略

**Comment:** Accept by ICCV2025

> **TL;DR:** 本文提出了一种名为自适应注意力缩放（SaaS）的方法，用于解决统一图像生成模型（如OmniGen）在处理多子指令文本时出现的指令忽略问题，从而提高模型的指令遵循保真度，无需额外训练。

**AI_Comments:** 本文创新性地提出了自适应注意力缩放（SaaS）方法，巧妙地利用了交叉注意力在相邻时间步之间的一致性来动态调整注意力权重，从而解决了统一图像生成模型在处理复杂指令时的指令忽略问题。其无需额外训练或测试时优化的特点，使其具有很高的实用价值和应用潜力。这项工作对于提升多模态生成模型在复杂指令理解和执行方面的能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 统一图像生成模型（如OmniGen）虽然能够在一个框架内处理多样化的图像生成和编辑任务，并接受多模态、交错的自由形式文本和图像输入，但存在文本指令忽略问题，尤其当文本指令包含多个子指令时。

**Method:** 作者通过对输入进行扰动分析，识别出关键步骤和层，并检查这些关键步骤的交叉注意力图，发现被忽略的子指令与输入图像的激活之间存在显著冲突。为此，本文提出了自适应注意力缩放（SaaS）方法，该方法利用相邻时间步之间交叉注意力的一致性，动态地缩放每个子指令的注意力激活，从而增强指令遵循保真度，且无需额外训练或测试时优化。

**Result:** 实验结果表明，在基于指令的图像编辑和视觉条件图像生成任务中，SaaS验证了其有效性，并显示出优于现有方法的指令遵循保真度。

**Conclusion:** 本文提出的自适应注意力缩放（SaaS）方法能够有效解决统一图像生成模型中的指令忽略问题，显著提升模型在复杂指令下的指令遵循能力，且无需额外训练，具有良好的应用前景。

> **ai_Abstract:** 本文关注统一图像生成模型（如OmniGen）在处理多子指令文本时出现的指令忽略问题。通过扰动分析和交叉注意力图检查，作者发现被忽略指令与图像激活之间存在冲突。为解决此问题，本文提出了一种名为自适应注意力缩放（SaaS）的新方法。SaaS利用相邻时间步交叉注意力的一致性，动态调整每个子指令的注意力激活，从而在不增加训练或测试开销的情况下，显著提高了模型的指令遵循保真度。实验结果验证了SaaS在图像编辑和视觉条件图像生成任务中的优越性。

> **摘要翻译:** 统一图像生成模型（如OmniGen）的最新进展，使得在一个单一框架内处理多样化的图像生成和编辑任务成为可能，接受自由形式的多模态、交错文本和图像。这种统一的架构消除了对文本编码器的需求，大大降低了模型复杂性，并标准化了各种图像生成和编辑任务，使其更用户友好。然而，我们发现它存在文本指令忽略问题，特别是当文本指令包含多个子指令时。为了探究这个问题，我们对输入进行了扰动分析，以识别关键步骤和层。通过检查这些关键步骤的交叉注意力图，我们观察到被忽略的子指令与输入图像的激活之间存在显著冲突。为此，我们提出了自适应注意力缩放（SaaS），一种利用相邻时间步之间交叉注意力一致性来动态缩放每个子指令注意力激活的方法。我们的SaaS在不需要额外训练或测试时优化的情况下，增强了指令遵循保真度。在基于指令的图像编辑和视觉条件图像生成上的实验结果验证了我们SaaS的有效性，显示出优于现有方法的指令遵循保真度。代码可在https://github.com/zhouchao-ops/SaaS获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [521] [AI-Enhanced Precision in Sport Taekwondo: Increasing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
> *体育跆拳道中AI增强的精确性：提高比赛的公平性、速度和信任度 (FST.ai)*

*Keivan Shariatmadar, Ahmad Osman* | **Category: cs.CV, cs.AI, 68T45, I.2.10** | **Updated: 2025-07-22**

**Keywords:** 体育裁判, 人工智能, 跆拳道, 计算机视觉

**Comment:** 24 pages, 9 figures

> **TL;DR:** FST.ai是一个利用AI、计算机视觉和深度学习的框架，旨在提高体育跆拳道（特别是头部踢击检测）的裁判准确性、速度和公平性，并可推广到其他运动。

**AI_Comments:** FST.ai的创新在于将AI技术应用于实时体育裁判，特别是解决了跆拳道中复杂的头部踢击评分问题，其通用框架也展示了在其他运动中推广的巨大潜力，有望显著提升体育比赛的公平性、效率和观众信任。

<details>
  <summary>Details</summary>

**Motivation:** 传统的体育裁判系统，即使有即时视频回放，也存在延迟、主观性和执行不一致的问题，损害了公平性和运动员的信任。

**Method:** 本文介绍了“FST.ai”——一个基于AI的框架，利用计算机视觉、深度学习和边缘推理来自动化识别和分类关键动作，特别是在体育跆拳道中用于实时头部踢击检测和评分。其底层框架基于姿态估计、运动分类和冲击分析。

**Result:** 该系统显著将决策时间从几分钟缩短到几秒钟，同时提高了裁判决策的一致性和透明度。

**Conclusion:** 通过解决跆拳道中最具挑战性的场景——头部踢击得分，FST.ai展示了其鲁棒性、可扩展性和运动无关的潜力，能够改变多个体育项目的裁判标准。

> **ai_Abstract:** FST.ai是一个创新的AI驱动框架，旨在通过计算机视觉、深度学习和边缘推理，提高体育跆拳道中（尤其是实时头部踢击检测）的裁判精确性、速度和公平性，以克服传统裁判系统的延迟和主观性问题。该系统能显著缩短决策时间并提高一致性，且其基于姿态估计和运动分析的底层技术具有跨体育项目的普适性。

> **摘要翻译:** 人工智能（AI）融入体育裁判领域代表了竞技环境中决策方式的范式转变。传统的纯人工系统，即使有即时视频回放（IVR）的支持，也常受制于延迟、主观性和执行不一致，从而损害了公平性和运动员的信任。本文介绍了“FST.ai”——一个在“R3AL.ai”项目（其首席研究员为r3al.ai）下开发的新型AI驱动框架，旨在增强体育跆拳道中的裁判工作，特别关注实时头部踢击检测和评分这一复杂任务。该系统利用计算机视觉、深度学习和边缘推理，自动化识别和分类关键动作，显著将决策时间从几分钟缩短到几秒钟，同时提高了决策的一致性和透明度。重要的是，该方法论不仅限于跆拳道。其底层框架——基于姿态估计、运动分类和冲击分析——可以适用于各种需要动作检测的体育项目，如柔道、空手道、击剑，甚至像足球和篮球这样的团队运动，在这些运动中，犯规识别或表现跟踪至关重要。通过解决跆拳道中最具挑战性的场景之一——头部踢击得分，我们展示了“FST.ai”在改变多个体育项目裁判标准方面的鲁棒性、可扩展性和运动无关潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [528] [Improving Personalized Image Generation through Social Context Feedback](https://arxiv.org/abs/2507.16095)
> *通过社交上下文反馈改进个性化图像生成*

*Parul Gupta, Abhinav Dhall, Thanh-Toan Do* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 个性化图像生成, 社交上下文反馈, 扩散模型, 微调, 姿态估计

**Comment:** 

> **TL;DR:** 本文通过反馈机制微调扩散模型，解决了个性化图像生成中复杂动作、身份保留和凝视模式不自然的问题，并在基准数据集上取得了改进。

**AI_Comments:** 该论文的创新点在于引入了“社交上下文反馈”机制，通过结合多种高精度检测器（姿态、HOI、人脸识别、凝视点）来微调扩散模型，并提出了时间步长差异化的反馈整合策略，有效解决了个性化图像生成中长期存在的真实性和一致性问题。

<details>
  <summary>Details</summary>

**Motivation:** 个性化图像生成存在三大局限性：复杂活动（如<人，推，摩托车>）生成不当，出现不正确的人体姿态；参考人物身份未保留；以及生成的人类凝视模式不自然/与场景描述不一致。

**Method:** 提出通过基于反馈的微调现有个性化生成方法来克服这些缺点，利用最先进的姿态、人-物交互、人脸识别和人眼凝视点估计检测器来改进扩散模型。还提出基于时间步长的方式融入不同的反馈模块，具体取决于信号是低级（如人体姿态）还是高级（如凝视点）。

**Result:** 生成的图像在三个基准数据集上显示出在交互、面部身份和图像质量方面的改进。

**Conclusion:** 本文通过引入基于社交上下文反馈的微调，成功提升了个性化图像生成中复杂动作、身份保留和凝视模式的真实性和一致性。

> **ai_Abstract:** 本文提出一种通过社交上下文反馈改进个性化图像生成的方法，旨在解决现有技术在复杂动作姿态、人物身份保留和凝视模式自然性方面的不足。通过对扩散模型进行基于反馈的微调，并利用先进的检测器（如姿态、人-物交互、人脸识别和凝视点估计）提供反馈信号，该方法显著提升了生成图像在交互、面部身份和整体质量上的表现。

> **摘要翻译:** 个性化图像生成，即使用一个或多个主体的参考图像根据场景描述生成其图像，已在社区中引起了广泛兴趣。然而，此类生成的图像存在三大主要局限性——复杂活动（例如<人，推，摩托车>）生成不当，出现不正确的人体姿态；参考人物身份未保留；以及生成的人类凝视模式不自然/与场景描述不一致。在这项工作中，我们提出通过对现有个性化生成方法进行基于反馈的微调来克服这些缺点，其中，利用最先进的姿态、人-物交互、人脸识别和人眼凝视点估计检测器来改进扩散模型。我们还提出基于时间步长的方式融入不同的反馈模块，具体取决于信号是低级（如人体姿态）还是高级（如凝视点）。以这种方式生成的图像在三个基准数据集上显示出在生成交互、面部身份和图像质量方面的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [532] [RDD: Robust Feature Detector and Descriptor using Deformable Transformer](https://arxiv.org/abs/2505.08013)
> *RDD：使用可变形Transformer的鲁棒特征检测器和描述符*

*Gonglin Chen, Tianwen Fu, Haiwei Chen, Wenbin Teng, Hanyuan Xiao, Yajie Zhao* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 鲁棒特征检测, 可变形Transformer, 关键点检测, 特征描述, 稀疏匹配

**Comment:** 

> **TL;DR:** RDD是一种利用可变形Transformer的新型鲁棒关键点检测器/描述符，它通过捕获全局上下文和几何不变性，在具有挑战性的场景（如大视角变化）下，在稀疏匹配任务中优于所有现有最先进方法，并能进行半稠密匹配。

**AI_Comments:** 该论文的创新点在于将可变形Transformer引入到特征检测和描述任务中，通过其自注意力机制有效捕获全局上下文和几何不变性，从而提升了在复杂场景下的鲁棒性。此外，引入新的空对地数据集和评估基准，为该领域的研究提供了新的训练和测试环境，具有重要的实践意义。其在稀疏和半稠密匹配上的优越性能表明了该方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在运动结构和SLAM中，在视角显著变化等挑战性场景下进行鲁棒特征检测和描述是核心步骤且普遍存在，但该问题仍未解决。现有方法虽然识别了局部特征在建模几何变换中的重要性，但未能学习长距离关系中存在的视觉线索。

**Method:** 提出了一种名为鲁棒可变形检测器（RDD）的新型鲁棒关键点检测器/描述符。RDD利用可变形Transformer，通过可变形自注意力机制捕获全局上下文和几何不变性。具体来说，研究观察到可变形注意力专注于关键位置，有效降低了搜索空间复杂性并建模了几何不变性。此外，除了标准的MegaDepth数据集，还收集了一个空对地数据集用于训练。

**Result:** 提出的方法在稀疏匹配任务中优于所有最先进的关键点检测/描述方法，并且也能够进行半稠密匹配。为了确保全面评估，引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空对地基准，这是一个最近在不同海拔高度进行3D重建中越来越受欢迎的评估设置。

**Conclusion:** RDD通过利用可变形Transformer，在具有挑战性的场景下实现了鲁棒的特征检测和描述，并在稀疏和半稠密匹配任务中超越了现有最先进方法，证明了其有效性和优越性。

> **ai_Abstract:** 本文提出了RDD（鲁棒可变形检测器），这是一种基于可变形Transformer的新型关键点检测器和描述符，旨在解决在视角变化等挑战性场景下特征检测和描述的鲁棒性问题。RDD利用可变形自注意力机制捕获全局上下文和几何不变性，并有效降低搜索空间复杂性。通过在MegaDepth和新收集的空对地数据集上进行训练，RDD在稀疏匹配任务中超越了现有最先进方法，并支持半稠密匹配。为全面评估，研究还引入了两个新的挑战性基准，包括一个空对地场景。

> **摘要翻译:** 作为运动结构和SLAM中的核心步骤，尽管普遍存在，但在视角显著变化等挑战性场景下的鲁棒特征检测和描述问题仍未解决。尽管最近的工作已经认识到局部特征在建模几何变换中的重要性，但这些方法未能学习长距离关系中存在的视觉线索。我们提出了鲁棒可变形检测器（RDD），这是一种新型的鲁棒关键点检测器/描述符，它利用了可变形Transformer，通过可变形自注意力机制捕获全局上下文和几何不变性。具体来说，我们观察到可变形注意力专注于关键位置，有效降低了搜索空间复杂性并建模了几何不变性。此外，我们除了标准的MegaDepth数据集，还收集了一个空对地数据集用于训练。我们提出的方法在稀疏匹配任务中优于所有最先进的关键点检测/描述方法，并且也能够进行半稠密匹配。为了确保全面评估，我们引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空对地基准——这是一个最近在不同海拔高度进行3D重建中越来越受欢迎的评估设置。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [542] [PlantSAM: An Object Detection-Driven Segmentation Pipeline for Herbarium Specimens](https://arxiv.org/abs/2507.16506)
> *PlantSAM：一种基于目标检测的植物标本分割流程*

*Youcef Sklab, Florian Castanet, Hanane Ariouat, Souhila Arib, Jean-Daniel Zucker, Eric Chenin, Edi Prifti* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** PlantSAM, 植物标本, 图像分割, 目标检测, 深度学习

**Comment:** 19 pages, 11 figures, 8 tables

> **TL;DR:** PlantSAM结合YOLOv10和SAM2，实现高精度植物标本图像分割，通过去除背景噪声显著提升植物分类性能。

**AI_Comments:** PlantSAM为图像分类中常见的背景噪声问题提供了一个创新解决方案。通过将目标检测器（YOLOv10）与强大的分割模型（SAM2）结合在一个流程中，它有效地利用了两者的优势。在特定植物标本图像上进行微调是其高性能的关键。该论文清晰地展示了背景去除的实际影响，这在专业领域如植物学中对于鲁棒的深度学习应用至关重要，但常被忽视。这种方法可以推广到其他前景-背景分离至关重要的领域。

<details>
  <summary>Details</summary>

**Motivation:** 基于深度学习的植物标本图像分类受到背景异质性的阻碍，背景会引入噪声和伪影，可能误导模型并降低分类准确性。解决这些与背景相关的挑战对于提高模型性能至关重要。

**Method:** 本文介绍了PlantSAM，一个自动分割流程，它集成了YOLOv10用于植物区域检测和Segment Anything Model (SAM2) 用于分割。YOLOv10生成边界框提示以指导SAM2，从而提高分割精度。两个模型都在植物标本图像上进行了微调，并使用交并比 (IoU) 和Dice系数指标进行评估。

**Result:** PlantSAM取得了最先进的分割性能，IoU为0.94，Dice系数为0.97。将分割后的图像整合到分类模型中，在五种测试的植物性状上带来了持续的性能改进，准确率提高了高达4.36%，F1分数提高了4.15%。

**Conclusion:** 研究结果强调了在植物标本图像分析中背景去除的重要性，因为它通过让模型更有效地关注前景植物结构，显著提高了分类准确性。

> **ai_Abstract:** 本文介绍了PlantSAM，一个自动分割流程，旨在通过解决背景噪声问题来改进基于深度学习的植物标本图像分类。PlantSAM集成了YOLOv10用于目标检测和SAM2用于分割，并利用YOLOv10的边界框来引导SAM2。PlantSAM在植物标本数据上进行微调后，实现了最先进的分割性能（IoU 0.94，Dice 0.97）。更重要的是，将这些分割后的图像整合到分类模型中，在各种植物性状上带来了持续的准确率和F1分数提升（分别高达4.36%和4.15%），这表明背景去除对于增强模型聚焦和性能至关重要。

> **摘要翻译:** 基于深度学习的植物标本图像分类受到背景异质性的阻碍，背景会引入噪声和伪影，可能误导模型并降低分类准确性。解决这些与背景相关的挑战对于提高模型性能至关重要。我们引入了PlantSAM，一个自动分割流程，它集成了YOLOv10用于植物区域检测和Segment Anything Model (SAM2) 用于分割。YOLOv10生成边界框提示以指导SAM2，从而提高分割精度。两个模型都在植物标本图像上进行了微调，并使用交并比 (IoU) 和Dice系数指标进行评估。PlantSAM取得了最先进的分割性能，IoU为0.94，Dice系数为0.97。将分割后的图像整合到分类模型中，在五种测试的植物性状上带来了持续的性能改进，准确率提高了高达4.36%，F1分数提高了4.15%。我们的研究结果强调了在植物标本图像分析中背景去除的重要性，因为它通过让模型更有效地关注前景植物结构，显著提高了分类准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [561] [AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs](https://arxiv.org/abs/2506.05328)
> *AV-Reasoner：改进和基准测试MLLM的线索接地视听计数*

*Lidong Lu, Guo Chen, Zhiqi Li, Yicheng Liu, Tong Lu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视听计数, 多模态大型语言模型, 基准测试, 强化学习, 课程学习

**Comment:** 21 pages, 11 figures

> **TL;DR:** 本文介绍了CG-AV-Counting，一个用于MLLM视听计数的新基准，并提出了AV-Reasoner模型，该模型通过强化学习和课程学习提高了计数能力，在多个基准测试中达到了最先进水平，但语言空间推理在域外表现不佳。

**AI_Comments:** 本文的创新点在于提出了一个更全面、标注更细致的线索接地视听计数基准CG-AV-Counting，解决了现有基准的不足。同时，AV-Reasoner模型引入强化学习和课程学习来提升计数能力，并在多项任务上取得了显著成果。然而，论文也指出了语言空间推理在域外泛化能力上的局限性，为未来的研究指明了方向。整体而言，该工作对视听计数领域的研究具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视频理解取得了进展，但当前的多模态大型语言模型（MLLMs）在计数任务上表现不佳。现有基准存在视频短、查询封闭、缺乏线索注释以及多模态覆盖不足等局限性，促使研究者开发更全面的基准和改进模型计数能力的方法。

**Method:** 本文引入了CG-AV-Counting，一个手动标注的线索接地计数基准，包含1,027个多模态问题和5,845个标注线索，覆盖497个长视频，支持黑盒和白盒评估。为提升模型计数能力，提出了AV-Reasoner模型，该模型通过GRPO和课程学习进行训练，旨在从相关任务中泛化计数能力。

**Result:** AV-Reasoner在多个基准测试中取得了最先进（SOTA）的结果，证明了强化学习的有效性。然而，实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。

**Conclusion:** AV-Reasoner通过结合强化学习和课程学习，显著提升了多模态大型语言模型在视听计数任务上的表现，并在多个基准测试中达到SOTA。然而，研究也揭示了在域外场景下，单纯依赖语言空间推理的局限性。

> **ai_Abstract:** 本文针对当前多模态大型语言模型（MLLMs）在计数任务上的不足和现有基准的局限性，提出了一个名为CG-AV-Counting的新型线索接地视听计数基准，该基准包含大量手动标注的长视频数据。同时，论文引入了AV-Reasoner模型，该模型通过强化学习（GRPO）和课程学习进行训练，旨在提升模型的计数泛化能力。实验结果表明，AV-Reasoner在多个基准测试中取得了最先进的性能，验证了强化学习的有效性，但也揭示了语言空间推理在域外场景下的局限性。

> **摘要翻译:** 尽管视频理解取得了进展，但当前的多模态大型语言模型（MLLMs）在计数任务上表现不佳。现有基准受到视频短、封闭式查询、缺乏线索标注以及多模态覆盖弱的限制。在本文中，我们引入了CG-AV-Counting，一个手动标注的线索接地计数基准，包含1,027个多模态问题和497个长视频上的5,845个标注线索。它支持黑盒和白盒评估，可作为端到端和基于推理计数的综合测试平台。为了探索提高模型计数能力的方法，我们提出了AV-Reasoner，一个通过GRPO和课程学习训练的模型，旨在从相关任务中泛化计数能力。AV-Reasoner在多个基准测试中取得了最先进的结果，证明了强化学习的有效性。然而，实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。代码和基准已在https://av-reasoner.github.io上发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [566] [HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery](https://arxiv.org/abs/2507.16251)
> *HoliTracer：从大型遥感影像中对地理对象进行整体矢量化*

*Yu Wang, Bo Dang, Wanchun Li, Wei Chen, Yansheng Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 遥感影像, 矢量化, 地理对象, 上下文注意力网络, HoliTracer

**Comment:** 

> **TL;DR:** HoliTracer是一个旨在从大型遥感影像中整体提取矢量化地理对象的框架。它通过上下文注意力网络（CAN）增强分割，并利用Mask Contour Reformer（MCR）和Polygon Sequence Tracer（PST）进行多边形重建和顶点追踪，解决了现有方法碎片化和上下文信息丢失的问题，并展现出优越的性能。

**AI_Comments:** HoliTracer的创新之处在于其“整体”矢量化方法，通过引入CAN捕获全局上下文信息，并利用MCR和PST构建完整的矢量对象，有效解决了传统方法处理大尺寸图像时的碎片化问题。这对于高精度地理信息系统和测绘领域具有重要意义和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理大型遥感影像时通常受限于小图像块，这导致上下文信息丢失和碎片化的矢量输出，无法实现地理对象的高精度、整体矢量化。

**Method:** 本文提出了HoliTracer框架，其核心包括：1) 使用上下文注意力网络（CAN）增强大尺寸遥感影像的分割，CAN采用局部到全局的注意力机制捕获上下文依赖；2) 通过强大的管道实现整体矢量化，该管道利用Mask Contour Reformer（MCR）重建多边形，并利用Polygon Sequence Tracer（PST）追踪顶点。

**Result:** 在包括建筑物、水体和道路在内的大型遥感影像数据集上进行的广泛实验表明，HoliTracer的性能优于现有最先进的方法。

**Conclusion:** HoliTracer框架成功实现了从大型遥感影像中整体提取高精度的矢量化地理对象，有效解决了现有方法在处理大尺寸遥感影像时面临的上下文信息丢失和碎片化输出的挑战，并展现出卓越的性能。

> **ai_Abstract:** HoliTracer是一个创新的框架，旨在解决现有方法在处理大型遥感影像时上下文信息丢失和矢量输出碎片化的问题。该框架通过引入上下文注意力网络（CAN）来增强大尺寸影像的分割效果，并结合Mask Contour Reformer（MCR）和Polygon Sequence Tracer（PST）实现了地理对象的整体矢量化。实验证明，HoliTracer在大型遥感影像数据集上表现出优于现有最先进方法的性能。

> **摘要翻译:** 随着遥感影像（RSI）分辨率的不断提高，大尺寸RSI已成为地理对象高精度矢量测绘的重要数据源。现有方法通常局限于处理小图像块，这常常导致上下文信息丢失并产生碎片化的矢量输出。为了解决这些问题，本文引入了HoliTracer，这是第一个旨在从大尺寸RSI中整体提取矢量化地理对象的框架。在HoliTracer中，我们使用上下文注意力网络（CAN）增强大尺寸RSI的分割，该网络采用局部到全局的注意力机制来捕获上下文依赖关系。此外，我们通过一个强大的管道实现了整体矢量化，该管道利用Mask Contour Reformer（MCR）重建多边形，并利用Polygon Sequence Tracer（PST）追踪顶点。在包括建筑物、水体和道路在内的大尺寸RSI数据集上进行的广泛实验表明，HoliTracer的性能优于现有最先进的方法。我们的代码和数据可在https://github.com/vvangfaye/HoliTracer获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [573] [Vision-based Conflict Detection within Crowds based on High-Resolution Human Pose Estimation for Smart and Safe Airport](https://arxiv.org/abs/2207.00477)
> *基于高分辨率人体姿态估计的机场智能安全视觉冲突检测*

*Karan Kheta, Claire Delgove, Ruolin Liu, Adeola Aderogba, Marc-Olivier Pokam, Muhammed Mehmet Unal, Yang Xing, Weisi Guo* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 冲突检测, 人体姿态估计, 机场安全, 机器学习, 支持向量机

**Comment:** One of the authors has expressed privacy concerns and made a related
  request

> **TL;DR:** 该论文开发了一种基于HRNet和SVM的机器学习模型，用于在机场人群中检测冲突行为，精度达到94.37%。

**AI_Comments:** 该论文提出了一种针对机场特定场景的创新应用，将高分辨率人体姿态估计与机器学习相结合，以提升冲突检测能力。其亮点在于利用HRNet进行精细分割和SVM进行高效分类，并取得了较高的精度。然而，论文也坦诚地指出了模型在处理复杂模糊行为和大规模人群时的局限性，为未来的研究指明了方向，即需要更鲁棒的算法来适应真实机场环境的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 未来的机场将变得更加复杂和拥挤，冲突爆发的可能性增加，这可能导致航班延误和安全问题。因此，需要一种智能算法来有效检测冲突，以保障乘客安全、财务和旅行效率。

**Method:** 该论文开发了一个机器学习模型来分类人群中的冲突行为。首先使用HRNet对图像进行分割，然后采用两种方法通过多个分类器对帧中人物的姿态进行分类。其中，支持向量机（SVM）被发现表现最佳。

**Result:** 支持向量机（SVM）在分类冲突行为方面表现最佳，达到了94.37%的精度。然而，模型在处理模糊行为（如拥抱）或在帧中丢失跟踪对象时存在不足。

**Conclusion:** 所开发的模型具有在机场部署的潜力，但需要进一步改进以应对大量潜在乘客和更多模糊行为的训练，从而增强安保监控能力并提高机场安全性。

> **ai_Abstract:** 本研究旨在解决未来机场日益增长的拥堵和潜在冲突问题，提出了一种基于视觉的机器学习模型，用于在人群中检测冲突行为。模型利用HRNet进行图像分割，并采用多种分类器对人体姿态进行识别，其中支持向量机（SVM）表现最佳，精度达到94.37%。尽管模型在处理模糊行为和跟踪方面存在局限性，但其在机场部署以增强安保和提高安全方面展现出巨大潜力。

> **摘要翻译:** 未来的机场随着旅客数量的增加变得越来越复杂和拥挤。机场更有可能成为潜在冲突爆发的热点，这可能导致严重的航班延误和若干安全问题。一种能使安保监控更有效地检测冲突的智能算法将为乘客带来许多好处，包括他们的安全、财务和旅行效率。本文详细介绍了用于分类人群中冲突行为的机器学习模型的开发。使用HRNet对图像进行分割，然后采用两种方法通过多个分类器对帧中人物的姿态进行分类。其中，支持向量机（SVM）表现最佳，精度达到94.37%。该模型不足之处在于对模糊行为（例如拥抱）或在帧中丢失目标时表现不佳。如果对模型进行改进以应对大量潜在乘客以及针对机场环境中可能出现的更多模糊行为进行训练，则该模型具有在机场部署的潜力。反过来，这将提供增强安保监控和提高机场安全的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [576] [Stop-band Energy Constraint for Orthogonal Tunable Wavelet Units in Convolutional Neural Networks for Computer Vision problems](https://arxiv.org/abs/2507.16114)
> *计算机视觉问题中卷积神经网络正交可调小波单元的阻带能量约束*

*An D. Le, Hung Nguyen, Sungbal Seo, You-Suk Bae, Truong Q. Nguyen* | **Category: cs.CV, eess.SP** | **Updated: 2025-07-21**

**Keywords:** 阻带能量约束, 可调小波单元, 卷积神经网络, 图像分类, 异常检测

**Comment:** 

> **TL;DR:** 该研究提出了一种针对卷积神经网络中正交可调小波单元的阻带能量约束，以提高图像分类和异常检测的性能，尤其是在纹理丰富的数集上，并在多个数据集上取得了显著改进。

**AI_Comments:** 该论文的创新点在于引入了阻带能量约束来优化卷积神经网络中的正交可调小波单元，这为提升计算机视觉任务（特别是纹理分析和异常检测）的性能提供了一个新的视角和有效方法。其在多个数据集上的显著性能提升，证明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该工作旨在改善卷积神经网络（CNNs）中的图像分类和异常检测性能，特别是在处理纹理丰富的数集时。

**Method:** 本研究引入了一种针对具有格状结构的正交可调小波单元中滤波器的阻带能量约束。该方法被整合到ResNet-18和ResNet-34中，以增强卷积、池化和下采样操作。

**Result:** 该方法在CIFAR-10数据集上将准确率提高了2.48%，在Describable Textures数据集上提高了13.56%。在ResNet-34上也观察到类似改进。在MVTec榛子异常检测任务中，所提出的方法在分割和检测方面均取得了有竞争力的结果，并优于现有方法。

**Conclusion:** 本研究提出的阻带能量约束方法显著提升了卷积神经网络在图像分类和异常检测任务上的性能，尤其是在纹纹理丰富的数集上表现出色，并优于现有方法。

> **ai_Abstract:** 本研究提出了一种针对卷积神经网络中正交可调小波单元的阻带能量约束，旨在提升图像分类和异常检测性能，尤其是在纹理丰富的数集上。该方法集成到ResNet-18和ResNet-34中，通过优化卷积、池化和下采样操作，在CIFAR-10和Describable Textures数据集上实现了显著的准确率提升。此外，在MVTec榛子异常检测任务中，该方法在分割和检测方面均表现出色，超越了现有方法。

> **摘要翻译:** 这项工作为具有格状结构的正交可调小波单元中的滤波器引入了阻带能量约束，旨在改善卷积神经网络（CNNs）中的图像分类和异常检测，特别是在纹理丰富的数集上。该方法整合到ResNet-18中，增强了卷积、池化和下采样操作，在CIFAR-10上实现了2.48%的准确率提升，在Describable Textures数据集上实现了13.56%的准确率提升。在ResNet-34中也观察到类似的改进。在MVTec榛子异常检测任务中，所提出的方法在分割和检测方面均取得了有竞争力的结果，并优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [580] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
> *SeC：通过渐进概念构建推进复杂视频对象分割*

*Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Songxin He, Jianfan Lin, Junsong Tang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 视频对象分割, 概念构建, 大型视觉-语言模型, 语义理解, SeCVOS

**Comment:** project page: https://rookiexiong7.github.io/projects/SeC/ ; code:
  https://github.com/OpenIXCLab/SeC ; dataset:
  https://huggingface.co/datasets/OpenIXCLab/SeCVOS

> **TL;DR:** SeC提出了一个概念驱动的视频对象分割框架，利用大型视觉-语言模型构建高层对象表示，并在新基准SeCVOS上实现了最先进的性能。

**AI_Comments:** SeC的创新点在于将人类般的概念理解引入视频对象分割，通过LVLMs构建高层语义表示，突破了传统VOS方法过度依赖外观匹配的局限性。引入的SeCVOS基准对于推动VOS领域在复杂语义理解方面的研究具有重要意义。该方法有望在需要高鲁棒性和泛化能力的实际VOS应用中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 当前视频对象分割（VOS）技术在处理剧烈视觉变化、遮挡和复杂场景时表现不佳，原因在于它们过度依赖外观匹配，而忽视了人类般的概念理解能力。

**Method:** 本文提出了Segment Concept (SeC)框架，一个概念驱动的分割方法，它从传统的特征匹配转向渐进式构建和利用高层、以对象为中心的表示。SeC利用大型视觉-语言模型（LVLMs）整合不同帧的视觉线索，构建鲁棒的概念先验。在推理过程中，SeC基于已处理的帧形成目标的全面语义表示，实现对后续帧的鲁棒分割。此外，SeC自适应地平衡基于LVLM的语义推理与增强的特征匹配，根据场景复杂性动态调整计算量。为严格评估VOS方法在高层概念推理和鲁棒语义理解场景下的性能，本文引入了Semantic Complex Scenarios Video Object Segmentation (SeCVOS) 基准，包含160个手动标注的多场景视频。

**Result:** SeC在SeCVOS基准上比SAM 2.1提高了11.8分，在概念感知视频对象分割领域建立了新的最先进水平。

**Conclusion:** SeC框架通过引入概念驱动的分割方法和利用大型视觉-语言模型，显著提升了视频对象分割在复杂场景下的性能，并通过新提出的SeCVOS基准验证了其有效性，解决了现有技术在处理剧烈视觉变化和复杂场景时的局限性。

> **ai_Abstract:** 本文提出了一种名为Segment Concept (SeC)的新型概念驱动视频对象分割框架，旨在解决现有技术在处理复杂场景和剧烈视觉变化时的局限性。SeC利用大型视觉-语言模型（LVLMs）构建高层、以对象为中心的表示和概念先验，并通过自适应平衡语义推理和特征匹配实现鲁棒分割。为全面评估，研究引入了新的SeCVOS基准。实验结果表明，SeC在SeCVOS上取得了显著的性能提升，超越了现有模型，确立了概念感知VOS的新SOTA。

> **摘要翻译:** 视频对象分割（VOS）是计算机视觉中的一项核心任务，要求模型在视频帧中跟踪和分割目标对象。尽管最近的努力取得了显著进展，但当前技术在处理剧烈视觉变化、遮挡和复杂场景变化方面仍落后于人类能力。这种局限性源于它们对外观匹配的依赖，忽视了人类般的、能够跨时间动态实现鲁棒识别的对象概念理解。受此差距的启发，我们提出了Segment Concept (SeC)，一个概念驱动的分割框架，它从传统的特征匹配转向渐进式构建和利用高层、以对象为中心的表示。SeC利用大型视觉-语言模型（LVLMs）整合不同帧的视觉线索，构建鲁棒的概念先验。在推理过程中，SeC基于已处理的帧形成目标的全面语义表示，实现对后续帧的鲁棒分割。此外，SeC自适应地平衡基于LVLM的语义推理与增强的特征匹配，根据场景复杂性动态调整计算量。为了严格评估VOS方法在需要高层概念推理和鲁棒语义理解的场景中的性能，我们引入了语义复杂场景视频对象分割基准（SeCVOS）。SeCVOS包含160个手动标注的多场景视频，旨在通过大量的外观变化和动态场景转换来挑战模型。特别是，SeC在SeCVOS上比SAM 2.1提高了11.8分，在概念感知视频对象分割领域建立了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [586] [C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning](https://arxiv.org/abs/2507.16518)
> *C2-Evo：协同演化多模态数据和模型以实现自我提升的推理*

*Xiuwei Chen, Wentao Hu, Hanhui Li, Jun Zhou, Zisheng Chen, Meng Cao, Yihan Zeng, Kui Zhang, Yu-Jie Yuan, Jianhua Han, Hang Xu, Xiaodan Liang* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 多模态大语言模型, 自我提升, 数据演化, 模型演化, 数学推理

**Comment:** 

> **TL;DR:** C2-Evo是一个自动化的闭环框架，通过协同演化训练数据和模型能力，解决了多模态大语言模型在推理能力提升中遇到的数据质量和模型适应性问题。

**AI_Comments:** 该论文提出了一种新颖的协同演化数据和模型的框架C2-Evo，解决了多模态大语言模型在自我提升过程中面临的数据质量和模型适应性问题。其创新点在于将数据生成与模型训练紧密结合，通过双循环机制确保数据复杂性与模型能力相匹配，避免了传统方法中数据与模型演化分离导致的效率低下。这种闭环的自我完善机制对于推动MLLM在复杂推理任务上的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有MLLM的提升需要高质量、高成本的多模态数据集；现有自我提升模型存在数据复杂度不一致（视觉/文本数据单独增强）和数据与模型演化分离（任务难度不匹配）的问题。

**Method:** 提出C2-Evo框架，包含两个循环：1. 跨模态数据演化循环：通过结合结构化文本子问题和迭代指定的几何图，生成复杂的多模态问题来扩展基础数据集。2. 数据-模型演化循环：根据基础模型的性能自适应选择生成的问题，交替进行监督微调和强化学习。目标是共同演化训练数据和模型能力。

**Result:** 在多个数学推理基准上持续获得显著的性能提升。

**Conclusion:** C2-Evo通过协同演化数据和模型，有效解决了多模态推理模型自我提升的挑战，并取得了优异的性能。

> **ai_Abstract:** C2-Evo是一个创新的自动闭环框架，旨在通过协同演化多模态训练数据和模型能力来提升多模态大语言模型（MLLM）的推理表现。它解决了现有方法中数据质量成本高、数据与模型演化脱节的问题。C2-Evo包含两个核心循环：一个跨模态数据演化循环用于生成复杂的多模态问题，以及一个数据-模型演化循环根据模型性能自适应地选择问题进行交替的监督微调和强化学习。实验结果表明，该方法在多个数学推理基准上取得了显著的性能提升。

> **摘要翻译:** 多模态大语言模型（MLLM）的最新进展展示了令人印象深刻的推理能力。然而，进一步增强现有MLLM需要高质量、精心策划任务复杂度的视觉-语言数据集，这既昂贵又难以扩展。尽管最近迭代自我完善的自提升模型提供了一种可行的解决方案，但它们仍然面临两个核心挑战：(i) 大多数现有方法分别增强视觉或文本数据，导致数据复杂性存在差异（例如，过于简化的图表与冗余的文本描述配对）；(ii) 数据和模型的演化也是分离的，导致模型暴露于难度不匹配的任务场景。为了解决这些问题，我们提出了C2-Evo，一个自动化的闭环自提升框架，它共同演化训练数据和模型能力。具体而言，给定一个基础数据集和一个基础模型，C2-Evo通过一个跨模态数据演化循环和一个数据-模型演化循环来增强它们。前者通过生成结合结构化文本子问题和迭代指定的几何图的复杂多模态问题来扩展基础数据集，而后者根据基础模型的性能自适应地选择生成的问题，交替进行监督微调和强化学习。因此，我们的方法持续地完善其模型和训练数据，并在多个数学推理基准上持续获得显著的性能提升。我们的代码、模型和数据集将会发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [591] [FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation](https://arxiv.org/abs/2408.00998)
> *FBSDiff：即插即用扩散特征频带替换实现高度可控的文本驱动图像转换*

*Xiang Gao, Jiaying Liu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 扩散模型, 图像到图像转换, 文本驱动, 可控性, 频带替换

**Comment:** Accepted conference paper of ACM MM 2024

> **TL;DR:** FBSDiff提出了一种即插即用的新方法，通过在DCT频谱空间中替换扩散特征的频带来，将预训练的文本到图像模型转换为高度可控的文本驱动图像到图像转换，无需训练或微调。

**AI_Comments:** FBSDiff的创新之处在于其“即插即用”的特性，无需对大型预训练模型进行额外的训练或微调，大大降低了应用门槛。通过在频域（DCT空间）操作扩散特征的频带，实现了对图像转换的高度精细化和灵活控制，这对于提高文本驱动图像编辑的实用性具有重要意义。该方法提供了一种高效且高质量的解决方案，解决了生成模型在实际应用中可控性差的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像扩散模型在实际内容创作中缺乏可控性，限制了其应用。研究人员正致力于利用参考图像来控制文本到图像合成，即文本驱动的图像到图像转换。

**Method:** 本文提出了一种新颖、简洁、高效的方法，以即插即用的方式将预训练的大规模文本到图像（T2I）扩散模型应用于图像到图像（I2I）范式，无需任何模型训练、模型微调或在线优化过程。为了用参考图像引导T2I生成，作者提出在DCT频谱空间中分解扩散特征的不同频带的引导因子，并设计了一个新颖的频带替换层，实现参考图像对T2I生成结果的即插即用动态控制。

**Result:** 该方法通过简单地调整替换频带的类型和带宽，分别实现了对参考图像的引导因子和引导强度的灵活控制。广泛的定性和定量实验证明，该方法在I2I转换的视觉质量、多功能性和可控性方面优于相关方法。

**Conclusion:** FBSDiff提出了一种新颖的、即插即用的方法，通过频带替换技术，将文本到图像模型有效地转换为高度可控的文本驱动图像到图像转换，显著提升了图像编辑的灵活性和质量。

> **ai_Abstract:** 本文提出FBSDiff，一种即插即用的方法，将预训练的文本到图像（T2I）扩散模型应用于图像到图像（I2I）转换，旨在解决现有模型可控性不足的问题。通过在DCT频谱空间中分解扩散特征的频带，并引入一个频带替换层，FBSDiff实现了对参考图像引导因子和引导强度的灵活控制，无需任何训练或微调。实验证明其在I2I转换的视觉质量、多功能性和可控性方面表现优异。

> **摘要翻译:** 大规模文本到图像扩散模型是生成式AI和多模态技术发展中的一个革命性里程碑，能够通过自然语言文本提示生成精彩图像。然而，此类模型缺乏可控性的问题限制了它们在现实内容创作中的实际应用。因此，人们开始关注利用参考图像来控制文本到图像合成，这也被视为根据文本提示操纵（或编辑）参考图像，即文本驱动的图像到图像转换。本文贡献了一种新颖、简洁、高效的方法，以即插即用的方式将预训练的大规模文本到图像（T2I）扩散模型应用于图像到图像（I2I）范式，实现了高质量和多功能的文本驱动I2I转换，无需任何模型训练、模型微调或在线优化过程。为了用参考图像引导T2I生成，我们提出在DCT频谱空间中分解扩散特征的不同频带的引导因子，并相应地设计了一个新颖的频带替换层，以即插即用的方式实现参考图像对T2I生成结果的动态控制。我们证明，我们的方法通过简单地调整替换频带的类型和带宽，分别实现了对参考图像的引导因子和引导强度的灵活控制。广泛的定性和定量实验验证了我们的方法在I2I转换视觉质量、多功能性和可控性方面优于相关方法。代码已公开：https://github.com/XiangGao1102/FBSDiff。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [592] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
> *GroundFlow：一个用于三维点云序列化定位中时序推理的即插即用模块*

*Zijun Lin, Shuting He, Cheston Tan, Bihan Wen* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 三维点云, 序列化定位, 时序推理, 即插即用模块, 视觉定位

**Comment:** 

> **TL;DR:** GroundFlow是一个即插即用模块，通过有效提取时序信息，显著提升了现有三维视觉定位方法在三维点云序列化定位任务中的表现，甚至超越了预训练的三维大型语言模型。

**AI_Comments:** GroundFlow的创新之处在于其即插即用的设计，能够无缝集成到现有3DVG模型中，有效解决了序列化定位中时序信息利用的难题。它不仅提升了性能，还通过区分短期和长期历史信息，展现了对复杂语言指令更深层次的理解，使其在处理包含代词和上下文依赖的指令时表现出色。这一贡献对于推动3D视觉-语言理解领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有三维视觉定位（3DVG）方法在处理带有多个步骤的文本指令时，未能有效提取和利用每个步骤中的时序信息。三维点云序列化定位（SG3D）任务中的指令常包含代词（如“它”、“这里”、“相同”），要求定位方法理解上下文并从先前的步骤中检索相关信息以准确定位对象序列。由于缺乏有效收集相关历史信息的模块，SOTA 3DVG 方法难以适应 SG3D 任务。

**Method:** 本文提出了GroundFlow，一个用于三维点云序列化定位中时序推理的即插即用模块。GroundFlow能够选择性地提取与当前指令相关的短期和长期步骤信息，从而全面利用历史信息并保持时序理解优势。

**Result:** GroundFlow的集成显著提高了3DVG基线方法在SG3D基准测试中的任务准确性，分别提升了+7.5%和+10.2%，甚至优于在各种数据集上预训练的三维大型语言模型。在五个数据集上，GroundFlow在SG3D基准测试中实现了最先进的性能。

**Conclusion:** 我们的工作为现有三维视觉定位模型引入了时序推理能力，并在三维点云序列化定位基准测试中取得了最先进的性能。

> **ai_Abstract:** 本文提出了GroundFlow，一个针对三维点云序列化定位（SG3D）任务的即插即用模块。现有三维视觉定位（3DVG）方法在处理SG3D任务时，因无法有效利用文本指令中的时序信息（如代词引用上下文）而面临挑战。GroundFlow通过选择性地提取短期和长期历史步骤信息，增强了模型的时序推理能力。实验证明，GroundFlow显著提升了基线3DVG方法在SG3D基准测试中的准确性，甚至超越了预训练的三维大型语言模型，并在五个数据集上达到了最先进的性能。该工作成功地为现有3DVG模型引入了关键的时序理解能力。

> **摘要翻译:** 三维点云序列化定位（SG3D）是指根据描述日常活动详细步骤的文本指令来定位一系列对象。当前的三维视觉定位（3DVG）方法将多步骤文本指令作为一个整体处理，未能从每个步骤中提取有用的时序信息。然而，SG3D 中的指令通常包含代词，如“它”、“这里”和“相同”，以使语言表达简洁。这要求定位方法理解上下文并从先前的步骤中检索相关信息以准确定位对象序列。由于缺乏有效收集相关历史信息的模块，最先进的 3DVG 方法在适应 SG3D 任务时面临重大挑战。为了填补这一空白，我们提出了 GroundFlow——一个用于三维点云序列化定位中时序推理的即插即用模块。首先，我们证明了在 SG3D 基准测试中，集成 GroundFlow 大幅提高了 3DVG 基线方法的任务准确性（+7.5% 和 +10.2%），甚至优于在各种数据集上预训练的三维大型语言模型。此外，我们根据与当前指令的相关性选择性地提取短期和长期步骤信息，使 GroundFlow 能够全面查看历史信息，并在步骤数量增加时保持其时序理解优势。总的来说，我们的工作为现有 3DVG 模型引入了时序推理能力，并在五个数据集的 SG3D 基准测试中取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [596] [One-Shot Affordance Grounding of Deformable Objects in Egocentric Organizing Scenes](https://arxiv.org/abs/2503.01092)
> *第一视角组织场景中可变形物体的一次性功能识别*

*Wanjun Jia, Fan Yang, Mengfei Duan, Xianchi Chen, Yinxi Wang, Yiming Jiang, Wenrui Chen, Kailun Yang, Zhiyong Li* | **Category: cs.CV, cs.RO, eess.IV** | **Updated: 2025-07-22**

**Keywords:** 一次性学习, 可变形物体, 功能识别, 机器人, 第一视角

**Comment:** Accepted to IROS 2025. Source code and benchmark dataset will be
  publicly available at https://github.com/Dikay1/OS-AGDO

> **TL;DR:** 本文提出OS-AGDO方法，使机器人能用少量样本识别和操作以前未见过的可变形物体，并在真实世界数据集中表现优异。

**AI_Comments:** 该论文提出了一种创新的OS-AGDO方法，通过专门设计的模块（如DefoSEM和OEKFM）和实例条件提示，有效解决了机器人对可变形物体进行一次性功能识别的难题。其贡献在于提高了机器人处理复杂、不确定可变形物体的能力，且公开了数据集，对机器人操作和视觉感知领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人对可变形物体的操作面临挑战，原因包括组件属性不确定性、配置多样性、视觉干扰和提示模糊性，这些因素使感知和控制任务复杂化。

**Method:** 提出OS-AGDO方法，包含：1) 可变形物体语义增强模块（DefoSEM），用于增强内部结构理解和局部特征识别；2) ORB增强关键点融合模块（OEKFM），利用几何约束优化关键组件特征提取；3) 基于图像数据和任务上下文的实例条件提示，缓解区域歧义问题。构建了真实世界数据集AGDDO15进行验证。

**Result:** 该方法显著优于现有SOTA方法，在KLD、SIM和NSS指标上分别提升了6.2%、3.2%和2.9%，并表现出高泛化性能。

**Conclusion:** OS-AGDO方法通过一次性功能识别有效解决了可变形物体操作中的挑战，并在性能和泛化能力上表现出色。

> **ai_Abstract:** 本文提出了一种新颖的OS-AGDO方法，用于在第一视角组织场景中对可变形物体进行一次性功能识别。该方法通过引入可变形物体语义增强模块（DefoSEM）、ORB增强关键点融合模块（OEKFM）以及实例条件提示，解决了机器人操作可变形物体时面临的感知和控制挑战。通过构建AGDDO15真实世界数据集进行验证，实验结果表明，OS-AGDO方法在多项指标上显著优于现有最先进方法，并展现出强大的泛化能力，使得机器人能够用少量样本识别和操作以前未见过的可变形物体。

> **摘要翻译:** 机器人对可变形物体的操作由于组件属性的不确定性、配置的多样性、视觉干扰和提示的模糊性而面临重大挑战。这些因素使感知和控制任务复杂化。为了应对这些挑战，我们提出了一种在第一视角组织场景中对可变形物体进行一次性功能识别（OS-AGDO）的新方法，使机器人能够使用最少的样本识别以前未见过的具有不同颜色和形状的可变形物体。具体而言，我们首先引入了可变形物体语义增强模块（DefoSEM），它增强了对内部结构的分层理解，并提高了即使在组件信息较弱的情况下也能准确识别局部特征的能力。其次，我们提出了ORB增强关键点融合模块（OEKFM），该模块通过利用几何约束优化关键组件的特征提取，并提高了对多样性和视觉干扰的适应性。此外，我们提出了一种基于图像数据和任务上下文的实例条件提示，有效缓解了由提示词引起的区域歧义问题。为了验证这些方法，我们构建了一个多样化的真实世界数据集AGDDO15，其中包括15种常见类型的可变形物体及其相关的组织动作。实验结果表明，我们的方法显著优于现有最先进的方法，在KLD、SIM和NSS指标上分别实现了6.2%、3.2%和2.9%的改进，同时表现出高泛化性能。源代码和基准数据集已在https://github.com/Dikay1/OS-AGDO公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [601] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
> *GPI-Net：基于正交几何一致性的格式塔引导并行交互网络，用于鲁棒点云配准*

*Weikang Gu, Mingyue Han, Li Xue, Heng Dong, Changcai Yang, Riqing Chen, Lifang Wei* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-19**

**Keywords:** 点云配准, 格式塔原理, 并行交互网络, 特征融合, 几何一致性

**Comment:** 9 pages, 4 figures. Accepted to IJCAI 2025

> **TL;DR:** GPI-Net提出一种基于格式塔原理的并行交互网络，通过正交集成和多粒度交互，有效融合局部和全局特征，实现鲁棒的点云配准。

**AI_Comments:** GPI-Net的创新点在于将格式塔原理引入点云配准，以解决局部和全局特征融合的难题。通过正交集成策略和多粒度交互设计，有效提升了对应关系的质量和配准的鲁棒性，为点云处理领域提供了一种新颖且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在基于特征的点云配准中，准确识别高质量对应关系是前提，但由于特征冗余和复杂的空间关系，处理局部和全局特征的融合极具挑战性。

**Method:** 本文提出了GPI-Net（Gestalt-guided Parallel Interaction Network via orthogonal geometric consistency）。它利用格式塔原则促进局部和全局信息的互补通信。具体而言，引入了正交集成策略以优化减少冗余信息并生成更紧凑的全局结构以实现高质量对应。为捕获对应关系中的几何特征，通过自注意力和交叉注意力机制的混合利用，引入了格式塔特征注意力（GFA）块。此外，为促进局部细节信息融入全局结构，设计了创新的双路径多粒度并行交互聚合（DMG）块以促进不同粒度间的信息交换。

**Result:** 在各种具有挑战性的任务上进行的广泛实验表明，所提出的GPI-Net与现有方法相比表现出卓越的性能。

**Conclusion:** GPI-Net通过结合格式塔原理、正交几何一致性以及多粒度交互，有效解决了点云配准中局部和全局特征融合的挑战，实现了鲁棒且性能优越的配准效果。

> **ai_Abstract:** 本文提出了一种名为GPI-Net的格式塔引导并行交互网络，旨在解决点云配准中局部和全局特征融合的挑战。该网络利用格式塔原理促进信息交流，并通过正交集成策略优化冗余信息，生成紧凑的全局结构。同时，引入格式塔特征注意力（GFA）块捕获几何特征，并设计双路径多粒度并行交互聚合（DMG）块以整合多粒度信息。实验证明GPI-Net在各种任务上均表现出优越性能。

> **摘要翻译:** 在基于特征的点云配准中，准确识别高质量对应关系是先决任务。然而，由于特征冗余和复杂的空间关系，处理局部和全局特征的融合极具挑战性。鉴于格式塔原理在分析局部和全局关系方面提供了关键优势，本文提出了一种新颖的基于正交几何一致性的格式塔引导并行交互网络（GPI-Net）。它利用格式塔原理促进局部和全局信息的互补通信。具体而言，我们引入了一种正交集成策略，以最优地减少冗余信息并生成更紧凑的全局结构以实现高质量对应。为了捕获对应关系中的几何特征，我们通过自注意力和交叉注意力机制的混合利用，利用了格式塔特征注意力（GFA）块。此外，为了促进局部细节信息融入全局结构，我们设计了一种创新的双路径多粒度并行交互聚合（DMG）块，以促进不同粒度间的信息交换。在各种具有挑战性的任务上进行的广泛实验表明，我们提出的GPI-Net与现有方法相比表现出卓越的性能。代码将在https://github.com/gwk/GPI-Net发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [603] [Make Me Happier: Evoking Emotions Through Image Diffusion Models](https://arxiv.org/abs/2403.08255)
> *让我更快乐：通过图像扩散模型唤起情感*

*Qing Lin, Jingfeng Zhang, Yew-Soon Ong, Mengmi Zhang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 情感图像编辑, 图像扩散模型, 情绪唤起, 数据集, 心理物理学实验

**Comment:** 

> **TL;DR:** 该研究提出了一种基于扩散模型的情绪唤起图像生成方法，能够编辑图像以表达所需情感，同时保留原始语义结构，并为此创建了一个大型数据集和新的评估指标。

**AI_Comments:** 这项研究在图像生成领域具有创新性，它解决了情感图像编辑这一未充分探索的领域。其主要贡献在于提出了一个能够理解和编辑图像以传达情感的扩散模型，并构建了一个大规模的情感标注数据集，这对于推动该领域的研究至关重要。此外，引入新的评估指标和人类心理物理学实验也增强了研究的严谨性。该技术在心理治疗、商业和艺术设计等领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 尽管图像生成技术发展迅速，但情感图像编辑仍未得到充分探索。图像的语义、上下文和结构可以唤起情感反应，因此情感图像编辑技术在心理障碍治疗、产品商业化和艺术设计等各种实际应用中具有重要价值。

**Method:** 本研究提出了一种扩散模型，能够有效理解和编辑源图像以传达所需情感。此外，由于缺乏情感编辑数据集，研究提供了一个包含34万对图像及其情感标注的独特数据集。研究还进行了人类心理物理学实验，并引入了一种新的评估指标来系统地评估所有方法。

**Result:** 实验结果表明，该方法超越了所有竞争性基线。所提出的扩散模型能够识别原始图像中的情感线索，编辑图像以唤起所需情感，同时保留原始图像的语义结构。

**Conclusion:** 本研究成功提出了一种新颖的情绪唤起图像生成挑战及其解决方案，通过提出的扩散模型和大型数据集，实现了有效的情感图像编辑，并提供了系统性的评估方法，验证了其优越性。

> **ai_Abstract:** 本研究提出了一种新颖的情绪唤起图像生成任务，旨在通过图像扩散模型编辑图像以唤起特定的情感，同时保持原始图像的语义和结构。为解决数据集稀缺问题，研究构建了一个包含34万对图像及其情感标注的大型数据集。通过提出的扩散模型，该方法在实验中表现优于现有基线，并能够有效识别情感线索、编辑图像以引发所需情感并保持语义结构。研究还引入了人类心理物理学实验和新的评估指标。

> **摘要翻译:** 尽管图像生成取得了快速进展，但情感图像编辑仍未得到充分探索。图像的语义、上下文和结构可以唤起情感反应，使得情感图像编辑技术在各种现实应用中具有宝贵价值，包括心理障碍治疗、产品商业化和艺术设计。首先，我们提出了一个新颖的情绪唤起图像生成挑战，旨在合成能够唤起目标情感同时保留原始场景语义和结构的图像。为了应对这一挑战，我们提出了一种扩散模型，能够有效理解和编辑源图像以传达所需的情感和情绪。此外，由于缺乏情感编辑数据集，我们提供了一个独特的包含34万对图像及其情感标注的数据集。此外，我们进行了人类心理物理学实验，并引入了一种新的评估指标来系统地评估所有方法。实验结果表明，我们的方法超越了所有竞争性基线。我们的扩散模型能够识别原始图像中的情感线索，编辑图像以引发所需情感，同时保留原始图像的语义结构。所有代码、模型和数据集均可在GitHub上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [613] [Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective](https://arxiv.org/abs/2507.16254)
> *鱼眼目标检测的边缘案例合成：以数据为中心视角*

*Seunghyeon Kim, Kyeongryeol Go* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 鱼眼目标检测, 边缘案例合成, 数据中心, 图像生成, 性能提升

**Comment:** 13 pages, 7 figures

> **TL;DR:** 该研究提出了一种以数据为中心的方法，通过合成边缘案例图像来系统地提高鱼眼目标检测模型的性能，从而解决传统数据集的盲点。

**AI_Comments:** 这项工作创新性地将数据中心化方法应用于鱼眼目标检测，通过生成式模型合成边缘案例来弥补真实世界数据的不足，解决了鱼眼图像特有的畸变和挑战。其重要性在于提供了一个有效且可扩展的解决方案，以提高模型在特定、复杂场景下的鲁棒性和准确性，对计算机视觉领域的数据增强和模型泛化具有启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 鱼眼相机引入了显著的畸变，给传统数据集训练的目标检测模型带来了独特的挑战。本研究旨在通过识别模型的盲点来系统地提高检测性能。

**Method:** 提出了一种以数据为中心的数据管道。通过详细的错误分析，识别了关键的边缘案例，如混淆的类别对、外围畸变和代表性不足的上下文。通过微调图像生成模型并使用精心设计的提示来合成复制真实世界故障模式的图像。这些合成图像使用高质量检测器进行伪标签，并集成到训练中。

**Result:** 我们的方法带来了持续的性能提升。

**Conclusion:** 深入理解数据并选择性地修复其弱点，在鱼眼目标检测等专业领域中具有重要意义。

> **ai_Abstract:** 本论文提出了一种数据驱动的方法，通过识别并合成模型在鱼眼图像目标检测中的边缘案例（如混淆类别、外围畸变、上下文不足），来系统性地提升检测性能。研究人员通过错误分析确定了这些盲点，并利用微调的生成模型合成模拟真实故障模式的图像。这些合成图像经过伪标签后被用于模型训练，最终实现了持续的性能提升，强调了数据理解和弱点修复在专业领域的重要性。

> **摘要翻译:** 鱼眼相机引入了显著的畸变，给传统数据集训练的目标检测模型带来了独特的挑战。在这项工作中，我们提出了一种以数据为中心的数据管道，通过关注识别模型盲点的关键问题，系统地提高检测性能。通过详细的错误分析，我们识别了关键的边缘案例，例如混淆的类别对、外围畸变和代表性不足的上下文。然后我们通过边缘案例合成直接解决这些问题。我们微调了一个图像生成模型，并用精心设计的提示引导它生成复制真实世界故障模式的图像。这些合成图像使用高质量检测器进行伪标签，并集成到训练中。我们的方法带来了持续的性能提升，突出了深入理解数据并选择性地修复其弱点在鱼眼目标检测等专业领域中具有多么大的影响力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [615] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
> *曲线感知高斯泼溅用于三维参数曲线重建*

*Zhirui Gao, Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 三维参数曲线重建, 高斯泼溅, 可微分渲染, 一阶段方法, 拓扑优化

**Comment:** Accepted by ICCV 2025, Code:
  https://github.com/zhirui-gao/Curve-Gaussian

> **TL;DR:** 本文提出了一种端到端的一阶段方法，通过新颖的曲线感知高斯表示（CurveGaussian）和动态拓扑优化，直接从多视图边缘图重建三维参数曲线，相比现有两阶段方法，实现了更清晰、更鲁棒、更高效的重建。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的一阶段三维参数曲线重建框架，直接从2D边缘图进行优化，有效避免了传统两阶段方法中因阶段分离导致的误差累积。核心创新是引入了CurveGaussian表示，巧妙地解决了参数曲线在可微分渲染中的挑战，使得直接优化成为可能。此外，动态拓扑优化框架进一步增强了重建的精细度和鲁棒性。其在效率和性能上的提升，对三维几何重建领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有三维参数曲线重建的两阶段方法存在误差累积问题，且参数曲线本身不适合基于渲染的多视图优化，因此需要一种能保持几何特性并支持可微分渲染的互补表示。

**Method:** 本文提出了一种端到端的一阶段框架，直接从2D边缘图优化3D参数曲线。核心是提出了一种新颖的曲线感知高斯表示（CurveGaussian），通过参数曲线与边缘导向高斯分量之间的双向耦合机制，实现了3D曲线的可微分渲染，从而允许多视图证据的直接优化。此外，还引入了动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作来细化曲线结构。

**Result:** 在ABC数据集和真实世界基准上的综合评估表明，本文的一阶段方法优于两阶段替代方案，尤其是在生成更清晰、更鲁棒的重建方面。此外，通过直接优化参数曲线，该方法显著减少了训练期间的参数数量，实现了比现有方法更高的效率和卓越的性能。

**Conclusion:** 本文提出的基于CurveGaussian和拓扑优化的一阶段方法，有效解决了现有方法的局限性，实现了从多视图边缘图高效、鲁棒且直接的三维参数曲线重建。

> **ai_Abstract:** 本文提出了一种端到端的一阶段框架，用于直接从多视图边缘图重建三维参数曲线。该方法通过引入新颖的曲线感知高斯表示（CurveGaussian）和参数曲线与边缘导向高斯分量之间的双向耦合机制，实现了三维曲线的可微分渲染，从而能够直接优化。同时，引入了动态自适应拓扑优化框架以细化曲线结构。与传统两阶段方法相比，该方法避免了误差累积，并在重建质量、鲁棒性和效率方面表现出显著优势。

> **摘要翻译:** 本文提出了一种端到端框架，用于直接从多视图边缘图重建三维参数曲线。与现有遵循“边缘点云重建和参数曲线拟合”顺序管道的两阶段方法不同，我们的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由不连贯阶段之间固有的优化差距引起的误差累积。然而，参数曲线本身不适合基于渲染的多视图优化，因此需要一种互补的表示，既能保留其几何特性，又能实现可微分渲染。我们提出了一种新颖的参数曲线和边缘导向高斯分量之间的双向耦合机制。这种紧密对应关系形成了一种曲线感知高斯表示，即 **CurveGaussian**，它实现了3D曲线的可微分渲染，允许由多视图证据引导的直接优化。此外，我们在训练期间引入了一个动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作来细化曲线结构。在ABC数据集和真实世界基准上的综合评估表明，我们的一阶段方法优于两阶段替代方案，特别是在产生更清晰、更鲁棒的重建方面。此外，通过直接优化参数曲线，我们的方法显著减少了训练期间的参数数量，与现有方法相比，实现了更高的效率和卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [625] [PUSA V1.0: Surpassing Wan-I2V with $500 Training Cost by Vectorized Timestep Adaptation](https://arxiv.org/abs/2507.16116)
> *PUSA V1.0：通过向量化时间步适应以500美元训练成本超越Wan-I2V*

*Yaofang Liu, Yumeng Ren, Aitor Artola, Yuxuan Hu, Xiaodong Cun, Xiaotong Zhao, Alan Zhao, Raymond H. Chan, Suiyun Zhang, Rui Liu, Dandan Tu, Jean-Michel Morel* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视频扩散模型, 向量化时间步适应, 图像到视频生成, 零样本学习, 计算效率

**Comment:** Code is open-sourced at https://github.com/Yaofang-Liu/Pusa-VidGen

> **TL;DR:** Pusa通过引入向量化时间步适应（VTA）解决了视频扩散模型中的时间建模限制，以极低的训练成本（500美元）和数据集大小（4K样本）显著超越了Wan-I2V-14B，同时实现了多任务零样本能力。

**AI_Comments:** Pusa的创新点在于提出了向量化时间步适应（VTA）这一非破坏性方法，它解决了视频扩散模型中时间建模的根本性限制，同时避免了灾难性遗忘和计算爆炸。其重要性在于，以极低的训练成本和数据需求，实现了超越现有SOTA模型的性能，并解锁了多任务零样本能力，极大地降低了高保真视频生成的门槛，对研究和工业界都具有显著的民主化效应。

<details>
  <summary>Details</summary>

**Motivation:** 视频扩散模型在时间建模方面存在根本性限制，特别是传统标量时间步变量强制的帧演化刚性同步。现有方法（如特定任务适应和自回归模型）受计算效率低下、灾难性遗忘或适用性狭窄的限制。

**Method:** 本文提出了Pusa范式，利用向量化时间步适应（VTA）在统一视频扩散框架内实现细粒度时间控制。VTA是一种非破坏性适应，能完全保留基础模型的能力。通过使用VTA对SOTA Wan2.1-T2V-14B模型进行微调。

**Result:** Pusa以低于Wan-I2V-14B 1/200的训练成本（500美元 vs. 100,000美元）和低于1/2500的数据集大小（4K vs. 10M样本）超越了Wan-I2V-14B的性能。在VBench-I2V上，Pusa的总分达到87.32%（Wan-I2V-14B为86.86%），并解锁了零样本多任务能力，如起始-结束帧和视频扩展，同时仍能进行文本到视频生成。

**Conclusion:** Pusa建立了一个可扩展、高效、多功能的下一代视频合成范式，通过向量化时间步适应克服了传统时间建模的限制，以极低的成本实现了高性能和多任务能力，使高保真视频生成民主化。

> **ai_Abstract:** PusaV1.0引入了向量化时间步适应（VTA）技术，以解决视频扩散模型中传统时间建模的效率和灵活性问题。VTA作为一种非破坏性适应方法，在保留基础模型能力的同时，实现了对时间演化的细粒度控制。通过对Wan2.1-T2V-14B模型进行微调，Pusa以极低的训练成本（500美元）和数据集规模（4K样本）显著超越了Wan-I2V-14B的性能，并在VBench-I2V基准测试中获得更高分数。此外，Pusa还展现了零样本多任务能力，如起始-结束帧生成和视频扩展。这项工作为高效、可扩展的视频合成提供了新范式。

> **摘要翻译:** 视频扩散模型的快速发展一直受到时间建模根本性限制的阻碍，特别是传统标量时间步变量强制的帧演化刚性同步。虽然特定任务适应和自回归模型试图解决这些挑战，但它们仍受计算效率低下、灾难性遗忘或适用性狭窄的限制。在这项工作中，我们提出了Pusa，一个开创性的范式，利用向量化时间步适应（VTA）在统一视频扩散框架内实现细粒度时间控制。此外，VTA是一种非破坏性适应，这意味着它完全保留了基础模型的能力。通过使用VTA对SOTA Wan2.1-T2V-14B模型进行微调，我们实现了前所未有的效率——以低于Wan-I2V-14B 1/200的训练成本（500美元 vs. 100,000美元）和低于1/2500的数据集大小（4K vs. 10M样本）超越了Wan-I2V-14B的性能。Pusa不仅为图像到视频（I2V）生成设定了新标准，实现了87.32%的VBench-I2V总分（Wan-I2V-14B为86.86%），还解锁了许多零样本多任务能力，如起始-结束帧和视频扩展——所有这些都无需特定任务训练。同时，Pusa仍能执行文本到视频生成。机制分析表明，我们的方法在外科式注入时间动态的同时保留了基础模型的生成先验，避免了向量化时间步固有的组合爆炸。这项工作为下一代视频合成建立了一个可扩展、高效、多功能的范式，使高保真视频生成在研究和工业领域都得以普及。代码已在https://github.com/Yaofang-Liu/Pusa-VidGen开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [626] [Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge](https://arxiv.org/abs/2507.16559)
> *内窥镜手术阶段识别、器械关键点估计和器械实例分割的比较验证：PhaKIR 2024挑战赛结果*

*Tobias Rueckert, David Rauber, Raphaela Maerkl, Leonard Klausmann, Suemeyye R. Yildiran, Max Gutbrod, Danilo Weber Nunes, Alvaro Fernandez Moreno, Imanol Luengo, Danail Stoyanov, Nicolas Toussaint, Enki Cho, Hyeon Bae Kim, Oh Sung Choo, Ka Young Kim, Seong Tae Kim, Gonçalo Arantes, Kehan Song, Jianjun Zhu, Junchen Xiong, Tingyi Lin, Shunsuke Kikuchi, Hiroki Matsuzaki, Atsushi Kouno, João Renato Ribeiro Manesco, João Paulo Papa, Tae-Min Choi, Tae Kyeong Jeong, Juyoun Park, Oluwatosin Alabi, Meng Wei, Tom Vercauteren, Runzhi Wu, Mengya Xu, An Wang, Long Bai, Hongliang Ren, Amine Yamlahi, Jakob Hennighausen, Lena Maier-Hein, Satoshi Kondo, Satoshi Kasai, Kousuke Hirasawa, Shu Yang, Yihui Wang, Hao Chen, Santiago Rodríguez, Nicolás Aparicio, Leonardo Manrique, Juan Camilo Lyons, Olivia Hosie, Nicolás Ayobi, Pablo Arbeláez, Yiping Li, Yasmina Al Khalil, Sahar Nasirihaghighi, Stefanie Speidel, Daniel Rueckert, Hubertus Feussner, Dirk Wilhelm, Christoph Palm* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 手术阶段识别, 器械关键点估计, 器械实例分割, 内窥镜, 数据集

**Comment:** A challenge report pre-print containing 36 pages, 15 figures, and 13
  tables

> **TL;DR:** PhaKIR 2024挑战赛引入了一个新的多中心数据集和基准，用于内窥镜下手术场景理解中的手术阶段识别、器械关键点估计和器械实例分割，旨在推动计算机辅助手术领域的发展。

**AI_Comments:** 该论文通过组织PhaKIR挑战赛并发布新的多中心数据集，为内窥镜手术场景理解领域做出了重要贡献。其创新之处在于数据集设计，它首次在一个数据集中同时支持器械定位和手术上下文的联合研究，并考虑了时间信息。这对于开发更鲁棒、更智能的计算机辅助手术系统至关重要。该挑战赛和数据集的发布将极大地推动相关研究。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜视频中可靠地识别和定位手术器械对于计算机和机器人辅助微创手术（RAMIS）中的多种应用至关重要，包括手术训练、技能评估和自主辅助。然而，在真实世界条件下实现稳健的性能仍然是一个重大挑战。将手术背景（例如当前的手术阶段）纳入考虑已成为提高鲁棒性和可解释性的一种有前景的策略。

**Method:** 作者组织了作为MICCAI 2024内窥镜视觉（EndoVis）挑战赛一部分的手术程序阶段、关键点和器械识别（PhaKIR）子挑战。他们引入了一个新颖的多中心数据集，包含来自三个不同医疗机构的13个完整腹腔镜胆囊切除术视频，并为三个相互关联的任务提供了统一的注释：手术阶段识别、器械关键点估计和器械实例分割。该数据集与现有数据集不同，它可以在相同数据中联合研究器械定位和程序背景，同时支持在整个过程中整合时间信息。

**Result:** 论文根据生物医学图像分析挑战的BIAS指南报告了结果和发现。具体的挑战赛结果和排名在摘要中未详细说明。

**Conclusion:** PhaKIR子挑战通过为开发RAMIS中时间感知、上下文驱动的方法提供独特的基准，推动了该领域的发展，并为支持未来手术场景理解研究提供了高质量的资源。

> **ai_Abstract:** PhaKIR 2024挑战赛旨在解决内窥镜手术中器械识别和定位的挑战，特别是通过整合手术背景来提高性能。该挑战赛引入了一个独特的、多中心的腹腔镜胆囊切除术视频数据集，其中包含手术阶段识别、器械关键点估计和器械实例分割的统一注释。该数据集支持器械定位和程序上下文的联合研究，并允许整合时间信息。PhaKIR挑战赛及其数据集为RAMIS中时间感知、上下文驱动方法的开发提供了一个重要的基准和高质量的资源。

> **摘要翻译:** 在内窥镜视频记录中可靠地识别和定位手术器械是计算机和机器人辅助微创手术（RAMIS）中广泛应用的基础，包括手术训练、技能评估和自主辅助。然而，在真实世界条件下实现稳健的性能仍然是一个重大挑战。将手术背景（例如当前的手术阶段）纳入考虑已成为提高鲁棒性和可解释性的一种有前景的策略。
为了应对这些挑战，我们组织了作为MICCAI 2024内窥镜视觉（EndoVis）挑战赛一部分的手术程序阶段、关键点和器械识别（PhaKIR）子挑战。我们引入了一个新颖的多中心数据集，包含来自三个不同医疗机构的13个完整腹腔镜胆囊切除术视频，并为三个相互关联的任务提供了统一的注释：手术阶段识别、器械关键点估计和器械实例分割。与现有数据集不同，我们的数据集可以在相同数据中联合研究器械定位和程序背景，同时支持在整个过程中整合时间信息。
我们根据生物医学图像分析挑战的BIAS指南报告了结果和发现。PhaKIR子挑战通过为开发RAMIS中时间感知、上下文驱动的方法提供独特的基准，推动了该领域的发展，并为支持未来手术场景理解研究提供了高质量的资源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [627] [VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models](https://arxiv.org/abs/2410.01738)
> *VitaGlyph：利用灵活的双分支扩散模型激活艺术字体排版*

*Kailai Feng, Yabo Zhang, Haodong Yu, Zhilong Ji, Jinfeng Bai, Hongzhi Zhang, Wangmeng Zuo* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 艺术字体排版, 扩散模型, 双分支, 可读性, 创意

**Comment:** https://github.com/Carlofkl/VitaGlyph

> **TL;DR:** VitaGlyph是一种双分支、免训练的方法，通过将字符视为主题和环境的组合，实现了可控几何变化同时保持可读性的艺术字体排版，解决了现有扩散模型在创意和易读性之间的平衡挑战。

**AI_Comments:** VitaGlyph的创新之处在于其独特的双分支设计和将字符分解为“主题”与“环境”的理念，这巧妙地平衡了艺术性和可读性。其“训练-free”的特性也大大降低了使用门槛和计算成本。该方法通过结合LLM进行语义理解和扩散模型进行视觉生成，为艺术字体排版领域带来了新的思路，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像扩散模型在艺术字体排版中，直接设计字符的整体几何形状和纹理，难以同时保证创意性和可读性。

**Method:** 本文提出了一种名为VitaGlyph的双分支、免训练方法，通过将输入字符视为由“主题（Subject）”和“环境（Surrounding）”组成的场景，并对它们进行不同程度的几何变换。VitaGlyph通过一个三阶段框架实现：(i)知识获取，利用大型语言模型为主题和环境设计文本描述；(ii)区域解释，检测与主题描述最匹配的部分并通过语义排版细化结构；(iii)注意力合成生成，分别渲染主题和环境区域的纹理，并以基于注意力的方式进行融合。

**Result:** 实验结果表明，VitaGlyph不仅实现了更好的艺术性和可读性，还能够描绘多个定制概念，促进了更具创意和令人愉悦的艺术字体排版生成。

**Conclusion:** VitaGlyph通过其独特的双分支、免训练方法，有效解决了艺术字体排版中创意与可读性难以兼顾的问题，生成了更具艺术性和可读性的字体。

> **ai_Abstract:** 本文提出了一种名为VitaGlyph的双分支、免训练方法，旨在解决现有扩散模型在艺术字体排版中创意与可读性难以兼顾的问题。VitaGlyph将字符分为“主题”和“环境”进行处理，通过三阶段框架（知识获取、区域解释、注意力合成生成）实现可控的几何变换和纹度渲染，同时保持高度可读性。实验证明其在艺术性和可读性方面表现优异，并能生成多样化的定制概念字体。

> **摘要翻译:** 艺术字体排版是一种以可想象和可读的方式可视化输入字符含义的技术。借助强大的文本到图像扩散模型，现有方法直接设计输入字符的整体几何形状和纹理，这使得同时确保创意性和可读性变得具有挑战性。在本文中，我们引入了一种名为VitaGlyph的双分支、免训练方法，实现了灵活的艺术字体排版，具有可控的几何变化，同时保持可读性。VitaGlyph的关键在于将输入字符视为由“主题（Subject）”和“环境（Surrounding）”组成的场景，这些场景以不同程度的几何变换进行渲染。为了增强生成艺术字体排版的视觉吸引力和创意性，主题灵活地表达输入字符的基本概念，而环境则丰富了相关背景而不改变形状，从而保持整体可读性。具体来说，我们通过一个三阶段框架实现VitaGlyph：(i)知识获取，利用大型语言模型设计主题和环境的文本描述；(ii)区域解释，检测与主题描述最匹配的部分并通过语义排版细化结构；(iii)注意力合成生成，分别渲染主题和环境区域的纹理，并以基于注意力的方式进行融合。实验结果表明，VitaGlyph不仅实现了更好的艺术性和可读性，还能够描绘多个定制概念，促进了更具创意和令人愉悦的艺术字体排版生成。我们的代码将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [634] [R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning](https://arxiv.org/abs/2506.21980)
> *R1-Track：通过强化学习将多模态大语言模型直接应用于视觉目标跟踪*

*Biao Wang, Wenwen Li, Jiawei Ge* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** MLLMs, 视觉目标跟踪, 强化学习, Qwen2.5-VL, R1-Track

**Comment:** 7 pages, 2 figures

> **TL;DR:** 传统跟踪方法存在局限性。本文通过强化学习微调Qwen2.5-VL，提出了R1-Track模型，用于视觉目标跟踪，实现了良好的性能和灵活性。

**AI_Comments:** 本文的创新之处在于通过强化学习直接将多模态大语言模型（MLLMs）应用于视觉目标跟踪，这与传统的监督学习方法不同，开辟了新的研究方向。这种方法提供了更大的灵活性，并减少了对大规模标记数据集的依赖。其重要性在于探索了一种新的跟踪范式，可能为基于MLLM的更通用视觉任务铺平道路。一个潜在的局限性可能是使用了“小规模数据集”和“基于规则的奖励函数”，这可能未能完全捕捉真实世界跟踪场景的复杂性，并且论文中提及了进一步改进的可能性，暗示仍有发展空间。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视觉单目标跟踪方法通常需要显式的分类和回归建模，依赖于大规模数据集的监督训练，并且局限于单一跟踪任务，缺乏灵活性。尽管多模态大语言模型（MLLMs）发展迅速，但直接应用于图像对之间的模板匹配（即跟踪任务）时表现不佳，因此研究旨在将MLLMs直接应用于视觉跟踪以克服现有方法的局限性。

**Method:** 受Deepseek-R1启发，作者使用群组相对策略优化（GRPO）强化学习方法，在一个小规模数据集上，通过基于规则的奖励函数微调了多模态大语言模型Qwen2.5-VL。

**Result:** R1-Track模型在GOT-10k基准测试上取得了显著性能。该模型支持通过边界框或文本描述进行灵活初始化，并保留了原始模型的大部分通用能力。

**Conclusion:** R1-Track证明了通过强化学习直接将多模态大语言模型应用于视觉目标跟踪是一种可行的方法，克服了传统方法的局限性并取得了有希望的结果。

> **ai_Abstract:** 本文介绍了R1-Track，一种将多模态大语言模型（MLLMs）直接应用于视觉单目标跟踪的新方法。针对传统跟踪方法的局限性，作者使用群组相对策略优化（GRPO）在一个小规模数据集上，通过基于规则的奖励函数微调了Qwen2.5-VL。R1-Track在GOT-10k基准测试上取得了显著性能，支持灵活的初始化（通过边界框或文本），并保留了原始MLLM的大部分通用能力。

> **摘要翻译:** 视觉单目标跟踪旨在给定视频第一帧中的初始状态后，连续定位和估计目标在后续视频帧中的尺度。这项任务传统上被视为模板匹配问题，经历了相关滤波器、双流网络和单流网络等主要阶段，并取得了显著进展。然而，这些方法通常需要显式的分类和回归建模，依赖于大规模数据集的监督训练，并且局限于单一跟踪任务，缺乏灵活性。近年来，多模态大语言模型（MLLMs）发展迅速。像Qwen2.5-VL这样的开源旗舰MLLMs，具有强大的基础能力，在接地任务中表现出色。这激发了将此类模型直接应用于视觉跟踪的兴趣。然而，实验表明Qwen2.5-VL在图像对之间的模板匹配（即跟踪任务）方面表现不佳。受Deepseek-R1启发，我们使用群组相对策略优化（GRPO）强化学习方法，在一个小规模数据集上，通过基于规则的奖励函数微调了Qwen2.5-VL。由此产生的模型R1-Track在GOT-10k基准测试上取得了显著性能。R1-Track支持通过边界框或文本描述进行灵活初始化，同时保留了原始模型的大部分通用能力。我们还进一步讨论了R1-Track的潜在改进。这份粗略的技术报告总结了我们截至2025年5月的发现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [639] [Rethinking Data Input for Point Cloud Upsampling](https://arxiv.org/abs/2407.04476)
> *重新思考点云上采样的输入数据*

*Tongxu Zhang* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 点云上采样, 数据输入, 基于补丁, 整体模型输入, 3D重建

**Comment:** 

> **TL;DR:** 本研究发现基于补丁的输入在点云上采样中持续优于整体模型输入，并计划深入探究其原因。

**AI_Comments:** 这篇论文通过实验挑战了直觉，发现基于补丁的输入在点云上采样中优于整体模型输入，这与作者最初的假设可能不同。其后续对影响因素的深入分析将对理解点云处理的底层机制具有重要意义，有助于指导未来更有效的数据输入策略设计。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖于基于补丁的输入，但缺乏对点云模型整体输入和基于补丁输入之间差异及原理的研究。

**Method:** 提出了一种使用整体模型输入（即平均段输入）的新方法。并在PU1K和ABC数据集上进行实验。此外，论文将深入探讨影响上采样结果的特征提取和网络架构因素。

**Result:** 实验表明，基于补丁的输入始终优于整体模型输入。

**Conclusion:** 基于补丁的输入在点云上采样中表现优于整体模型输入，论文将进一步探究其原因。

> **ai_Abstract:** 这篇论文探讨了点云上采样中数据输入方式的影响。针对现有方法多依赖基于补丁的输入且缺乏对整体模型输入与补丁输入差异的研究，作者提出了一种使用整体模型输入（平均段输入）的新方法。实验结果出乎意料地显示，基于补丁的输入在PU1K和ABC数据集上持续优于整体模型输入。为此，研究将进一步探究影响上采样结果的特征提取和网络架构因素。

> **摘要翻译:** 点云上采样对于3D重建等任务至关重要。现有方法依赖于基于补丁的输入，但没有研究讨论点云模型整体输入和基于补丁输入之间的差异和原理。因此，我们提出了一种使用整体模型输入（即平均段输入）的新方法。我们在PU1K和ABC数据集上的实验表明，基于补丁的输入始终优于整体模型输入。为了理解这一点，我们将深入探讨影响上采样结果的特征提取和网络架构因素。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [643] [Unveiling the Potential of Segment Anything Model 2 for RGB-Thermal Semantic Segmentation with Language Guidance](https://arxiv.org/abs/2503.02581)
> *揭示Segment Anything Model 2在语言指导下实现RGB-热语义分割的潜力*

*Jiayi Zhao, Fei Teng, Kai Luo, Guoqiang Zhao, Zhiyong Li, Xu Zheng, Kailun Yang* | **Category: cs.CV, cs.RO, eess.IV** | **Updated: 2025-07-22**

**Keywords:** SAM2, RGB-T语义分割, 语言指导, 混合交互范式, SHIFNet

**Comment:** Accepted to IROS 2025. The source code will be made publicly
  available at https://github.com/iAsakiT3T/SHIFNet

> **TL;DR:** 本文提出SHIFNet，一个由SAM2驱动的混合交互范式，通过语言指导解决SAM2在RGB-T任务中的局限性，并在RGB-T语义分割上实现了最先进的性能。

**AI_Comments:** 该论文通过引入SHIFNet，成功地将大型预训练模型SAM2的强大感知能力扩展到RGB-T领域，克服了其固有的RGB偏差。通过语言指导和创新的模块设计，有效缓解了RGB-T数据收集成本高昂的问题，对于提升机器人系统在复杂环境下的感知能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人系统的感知能力依赖于数据集的丰富性。尽管Segment Anything Model 2 (SAM2)在大型数据集上训练，表现出强大的感知潜力，但其固有的训练范式使其不适用于RGB-T任务。

**Method:** 本文提出了SHIFNet，一个新颖的SAM2驱动的混合交互范式，通过语言指导释放SAM2的潜力，用于高效的RGB-热感知。该框架包含两个关键组件：1) 语义感知跨模态融合 (SACF) 模块，通过文本引导的亲和学习动态平衡模态贡献，克服SAM2固有的RGB偏差；2) 异构提示解码器 (HPD)，通过语义增强模块增强全局语义信息，并结合类别嵌入以放大跨模态语义一致性。

**Result:** SHIFNet拥有32.27M可训练参数，在公共基准测试中实现了最先进的分割性能，在PST900上达到89.8%，在FMB上达到67.8%。

**Conclusion:** 该框架促进了预训练大模型适应RGB-T分割任务，有效缓解了数据收集相关的高成本，同时赋予机器人系统全面的感知能力。

> **ai_Abstract:** 本文提出SHIFNet，一个基于SAM2的新颖混合交互范式，旨在通过语言指导解决SAM2在RGB-T语义分割任务中的局限性。SHIFNet包含语义感知跨模态融合模块（SACF）和异构提示解码器（HPD），分别用于平衡模态贡献和增强跨模态语义一致性。该模型在RGB-T分割基准上取得了最先进的性能，证明了其在低成本下赋予机器人系统全面感知能力方面的潜力。

> **摘要翻译:** 机器人系统的感知能力依赖于数据集的丰富性。尽管在大型数据集上训练的Segment Anything Model 2 (SAM2)在感知任务中表现出强大的感知潜力，但其固有的训练范式使其不适用于RGB-T任务。为了解决这些挑战，我们提出了SHIFNet，一个新颖的SAM2驱动的混合交互范式，通过语言指导释放SAM2的潜力，用于高效的RGB-热感知。我们的框架包含两个关键组件：(1) 语义感知跨模态融合 (SACF) 模块，通过文本引导的亲和学习动态平衡模态贡献，克服SAM2固有的RGB偏差；(2) 异构提示解码器 (HPD)，通过语义增强模块增强全局语义信息，并结合类别嵌入以放大跨模态语义一致性。SHIFNet拥有32.27M可训练参数，在公共基准测试中实现了最先进的分割性能，在PST900上达到89.8%，在FMB上达到67.8%。该框架促进了预训练大模型适应RGB-T分割任务，有效缓解了数据收集相关的高成本，同时赋予机器人系统全面的感知能力。源代码将在https://github.com/iAsakiT3T/SHIFNet公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [652] [Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs](https://arxiv.org/abs/2506.22139)
> *Q-Frame：面向视频大语言模型的查询感知帧选择与多分辨率适应*

*Shaojie Zhang, Jiahui Yang, Jianqin Yin, Zhenbo Luo, Jian Luan* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视频大语言模型, 帧选择, 多分辨率, 查询感知, 视频理解

**Comment:** Accepted at ICCV 2025

> **TL;DR:** Q-Frame通过查询感知的帧选择和多分辨率适应，使视频大语言模型能更有效地处理视频，克服现有方法的局限性。

**AI_Comments:** Q-Frame的创新点在于其无训练的即插即用策略以及结合查询感知进行自适应帧选择和多分辨率缩放，这有效解决了视频大语言模型在处理长视频时计算成本高和信息丢失的问题。Gumbel-Max技巧的应用也提升了帧选择的效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频大语言模型（Video-LLMs）在处理视频时面临数据量大和时间复杂性挑战，且统一帧采样难以有效捕获查询相关的关键时空线索。

**Method:** Q-Frame是一种新颖的自适应帧选择和多分辨率缩放方法，根据视频内容和特定查询进行定制。它采用无训练的即插即用策略，利用类似CLIP的文本-图像匹配网络，并通过Gumbel-Max技巧进行高效帧选择。

**Result:** Q-Frame在MLVU、LongVideoBench和Video-MME等基准数据集上的广泛实验证明了其有效性，并显示出优于现有方法的性能，适用于各种视频理解任务。

**Conclusion:** Q-Frame通过允许Video-LLMs在不超出计算限制的情况下处理更多帧，从而保留关键时空信息，显著提高了视频理解任务的性能。

> **ai_Abstract:** 本论文提出Q-Frame，一种针对视频大语言模型的查询感知帧选择和多分辨率适应方法。针对现有Video-LLMs在处理视频时面临的数据量大、时间复杂性以及难以捕捉查询相关关键时空线索的问题，Q-Frame采用无训练、即插即用的策略，利用文本-图像匹配网络和Gumbel-Max技巧，实现高效的自适应帧选择。这使得Video-LLMs能在计算限制内处理更多帧并保留关键时空信息，实验证明其在多个视频理解基准数据集上优于现有方法。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著成功。然而，由于数据量大和时间复杂性，这些模型在视频理解方面的适应仍然面临挑战。现有的使用统一帧采样的视频大语言模型（Video-LLMs）通常难以有效捕获视频中与查询相关的关键时空线索。在本文中，我们引入了Q-Frame，这是一种新颖的自适应帧选择和多分辨率缩放方法，专为视频内容和特定查询量身定制。Q-Frame采用由类似CLIP的文本-图像匹配网络生成的无训练、即插即用策略，并利用Gumbel-Max技巧进行高效帧选择。Q-Frame允许视频大语言模型在不超出计算限制的情况下处理更多帧，从而保留关键的时间和空间信息。我们通过在MLVU、LongVideoBench和Video-MME等基准数据集上进行广泛实验，证明了Q-Frame的有效性，展示了其优于现有方法的性能，以及其在各种视频理解任务中的适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [661] [Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models](https://arxiv.org/abs/2507.16257)
> *高质量文本，鲁棒视觉：语言在增强视觉-语言模型视觉鲁棒性中的作用*

*Futa Waseda, Saku Sugawara, Isao Echizen* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 对抗鲁棒性, 视觉-语言模型, 高质量文本, 对抗训练, 零样本学习

**Comment:** ACMMM 2025 Accepted

> **TL;DR:** 本文提出QT-AFT，利用高质量图像描述指导对抗训练，以增强视觉-语言模型（VLMs）的视觉鲁棒性，克服了现有对抗训练方法中监督式过拟合和非监督式缺乏语义指导的问题，在零样本任务中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于强调并利用了高质量语言（图像描述）在增强视觉-语言模型视觉鲁棒性中的关键作用，这与以往方法主要关注视觉或短文本（标签）不同。通过解决现有对抗训练方法的过拟合和缺乏语义指导问题，QT-AFT为鲁棒视觉表征学习开辟了新方向，特别是在零样本场景下表现出色，具有重要的实践意义和理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 预训练的视觉-语言模型（如CLIP）广泛应用于各种零样本任务，但易受对抗攻击。现有对抗训练（AT）方法在增强视觉鲁棒性时， largely overlook the role of language。具体而言，监督式AT依赖短文本导致对训练数据中对象类别的过拟合；非监督式AT虽然避免了过拟合，但因缺乏语义指导而对文本引导的对抗攻击效果不佳。

**Method:** 本文提出“高质量文本引导对抗微调”（QT-AFT）方法。该方法在训练过程中利用高质量的图像描述（captions）来引导对抗样本，使其远离图像中存在的多种语义。这使得视觉编码器即使在对抗噪声下也能鲁棒地识别更广泛的图像特征，从而增强了跨不同下游任务的鲁棒性。

**Result:** QT-AFT克服了现有方法（监督式AT的过拟合和非监督式AT缺乏语义感知）的关键弱点，在16个零样本数据集上实现了最先进的零样本对抗鲁棒性和干净准确性。此外，研究发现，除了对象名称外，描述对象属性可以进一步增强零样本鲁棒性。

**Conclusion:** 高质量的语言监督在鲁棒视觉表征学习中扮演着至关重要的角色，是未来研究的一个紧迫方向。

> **ai_Abstract:** 本文针对视觉-语言模型（VLMs）在对抗攻击下的脆弱性问题，提出了一种名为“高质量文本引导对抗微调”（QT-AFT）的新方法。该方法利用高质量图像描述来指导对抗训练过程，以解决现有监督式对抗训练过拟合和非监督式对抗训练缺乏语义指导的局限性。QT-AFT旨在使VLMs的视觉编码器能够更鲁棒地识别广泛的图像特征，即使在对抗噪声下也能表现良好。实验结果表明，QT-AFT在多个零样本数据集上取得了最先进的对抗鲁棒性和干净准确性，并强调了高质量语言监督在增强视觉鲁棒性中的关键作用。

> **摘要翻译:** 防御预训练的视觉-语言模型（VLMs），例如CLIP，免受对抗攻击至关重要，因为这些模型广泛应用于各种零样本任务，包括图像分类。然而，现有的用于鲁棒微调的对抗训练（AT）方法在很大程度上忽视了语言在增强视觉鲁棒性中的作用。具体而言，(1) 监督式AT方法依赖于短文本（例如，类别标签）来生成对抗扰动，导致对训练数据中对象类别的过拟合；(2) 非监督式AT避免了这种过拟合，但由于缺乏语义指导，在应对实际的文本引导对抗攻击时仍然不是最优的。为了解决这些限制，我们提出了高质量文本引导对抗微调（QT-AFT），该方法在训练期间利用高质量的图像描述来引导对抗样本远离图像中存在的多种语义。这使得视觉编码器即使在对抗噪声下也能鲁棒地识别更广泛的图像特征，从而增强了跨不同下游任务的鲁棒性。QT-AFT克服了先前方法的关键弱点——监督式AT中的过拟合和非监督式AT中缺乏语义意识——在16个零样本数据集上评估，实现了最先进的零样本对抗鲁棒性和干净准确性。此外，我们的综合研究揭示了关于语言在增强视觉鲁棒性中作用的几个关键见解；例如，除了对象名称外，描述对象属性可以进一步增强零样本鲁棒性。我们的研究结果指出了未来工作的紧迫方向——将高质量的语言监督置于鲁棒视觉表征学习的核心。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [666] [Universal Wavelet Units in 3D Retinal Layer Segmentation](https://arxiv.org/abs/2507.16119)
> *3D视网膜层分割中的通用小波单元*

*An D. Le, Hung Nguyen, Melanie Tran, Jesse Most, Dirk-Uwe G. Bartsch, William R Freeman, Shyamanga Borooah, Truong Q. Nguyen, Cheolhong An* | **Category: cs.CV, eess.SP** | **Updated: 2025-07-22**

**Keywords:** 可调谐小波单元, 3D视网膜层分割, OCT, MGU-Net, 医学图像分割

**Comment:** 

> **TL;DR:** 本文首次将可调谐小波单元（UwUs）应用于3D视网膜层分割，通过集成三种小波下采样模块到MGU-Net中，显著提高了分割精度和Dice分数，尤其是在容积医学图像分割中展现了可调谐小波滤波器的优势。

**AI_Comments:** 本文的创新点在于首次将可调谐小波单元（UwUs）应用于3D视网膜层分割，并提出了一种新的下采样策略，有效克服了传统最大池化在保留图像细节方面的局限性。通过集成可学习的格点滤波器组，该方法能够同时保留低频和高频特征，对于需要高精度空间细节的医学图像分割任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服传统最大池化（max-pooling）的局限性，并保留低频和高频特征，以增强空间细节和结构一致性。

**Method:** 本文将三种基于小波的下采样模块（OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU）集成到经过运动校正的MGU-Net架构中。这些模块使用可学习的格点滤波器组来保留低频和高频特征。

**Result:** 在Jacobs视网膜中心（JRC）OCT数据集上进行评估，该框架在准确性和Dice分数方面显示出显著改进，特别是LS-BiorthLattUwU表现突出。

**Conclusion:** 可调谐小波滤波器在容积医学图像分割中具有显著优势。

> **ai_Abstract:** 本文首次探索了将可调谐小波单元（UwUs）应用于3D视网膜层分割。通过将OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU三种小波下采样模块整合到MGU-Net中，以克服传统最大池化的不足并保留图像特征。在JRC OCT数据集上的评估显示，该方法显著提升了分割精度和Dice分数，特别是LS-BiorthLattUwU表现优异，证明了可调谐小波滤波器在容积医学图像分割中的有效性。

> **摘要翻译:** 本文首次将可调谐小波单元（UwUs）应用于光学相干断层扫描（OCT）体积的3D视网膜层分割。为了克服传统最大池化的局限性，我们将三种基于小波的下采样模块——OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU集成到经过运动校正的MGU-Net架构中。这些模块利用可学习的格点滤波器组来保留低频和高频特征，从而增强空间细节和结构一致性。在Jacobs视网膜中心（JRC）OCT数据集上进行评估，我们的框架在准确性和Dice分数方面显示出显著改进，特别是LS-BiorthLattUwU，突出了可调谐小波滤波器在容积医学图像分割中的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [670] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
> *NavMorph：一种用于连续环境中视觉与语言导航的自进化世界模型*

*Xuan Yao, Junyu Gao, Changsheng Xu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 视觉与语言导航, 世界模型, 自进化, 连续环境, 上下文记忆

**Comment:** Accepted by ICCV 2025

> **TL;DR:** NavMorph是一个自进化的世界模型，通过紧凑的潜在表示和上下文进化记忆，提升了在连续环境中视觉与语言导航的泛化能力和适应性。

**AI_Comments:** NavMorph的创新点在于其自进化的世界模型设计，特别是引入了紧凑的潜在表示和上下文进化记忆，这使得代理能够更好地理解环境动态并在线适应变化，解决了VLN-CE任务中的关键挑战。其灵感来源于人类认知，这为其方法的有效性提供了直观支持。该研究对于提升AI在复杂真实世界环境中的导航能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前在连续环境中视觉与语言导航（VLN-CE）的方法在泛化到新环境和适应导航过程中的持续变化方面存在困难。

**Method:** 本文提出了NavMorph，一个自进化的世界模型框架，它利用紧凑的潜在表示来建模环境动态，并整合了一个新颖的上下文进化记忆（Contextual Evolution Memory），以利用场景上下文信息支持有效导航并保持在线适应性。

**Result:** NavMorph在流行的VLN-CE基准测试上取得了显著的性能改进。

**Conclusion:** NavMorph通过其自进化世界模型框架，有效提升了代理在复杂连续环境中进行视觉与语言导航的泛化能力和在线适应性。

> **ai_Abstract:** NavMorph是一种针对连续环境中视觉与语言导航（VLN-CE）任务设计的自进化世界模型框架。它旨在解决现有方法在环境泛化和动态适应方面的不足。NavMorph通过利用紧凑的潜在表示来建模环境动态，并结合新颖的上下文进化记忆，增强了代理的环境理解和决策能力，从而实现自适应规划和策略优化。实验结果表明，该方法在VLN-CE基准测试上表现出显著的性能提升。

> **摘要翻译:** 连续环境中的视觉与语言导航（VLN-CE）要求代理在复杂环境中执行由自然语言指令引导的顺序导航动作。当前的方法在泛化到新环境和适应导航过程中的持续变化方面常常遇到困难。受人类认知的启发，我们提出了NavMorph，一个自进化的世界模型框架，它增强了VLN-CE任务中的环境理解和决策能力。NavMorph采用紧凑的潜在表示来建模环境动态，使代理具备预见性，从而进行自适应规划和策略优化。通过整合一个新颖的上下文进化记忆，NavMorph利用场景上下文信息来支持有效的导航，同时保持在线适应性。广泛的实验表明，我们的方法在流行的VLN-CE基准测试上取得了显著的性能改进。代码可在https://github.com/Feliciaxyao/NavMorph 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [674] [A Multimodal Deviation Perceiving Framework for Weakly-Supervised Temporal Forgery Localization](https://arxiv.org/abs/2507.16596)
> *一种用于弱监督时间伪造定位的多模态偏差感知框架*

*Wenbo Xu, Junyan Wu, Wei Lu, Xiangyang Luo, Qian Wang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** Deepfake取证, 弱监督, 时间伪造定位, 多模态, 偏差感知

**Comment:** 9 pages, 3 figures,conference

> **TL;DR:** 该论文提出了一种多模态偏差感知框架（MDP），用于在弱监督下定位Deepfake视频中的伪造片段，通过感知模态间的偏差来实现。

**AI_Comments:** 该论文的创新点在于提出了一个弱监督的多模态框架来解决Deepfake视频伪造定位问题，这显著降低了对昂贵且耗时的逐帧标注的需求。通过引入多模态交互机制和偏差感知损失，该框架能够有效捕捉模态间的异常，从而实现精确的伪造定位。其性能与全监督方法相当，表明了弱监督方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前Deepfake取证研究将检测视为分类或时间伪造定位问题，这些方法通常具有限制性、耗时且难以扩展到大型数据集。

**Method:** 本文提出了一种多模态偏差感知框架（MDP），用于弱监督时间伪造定位，仅使用视频级标注来识别时间上的部分伪造片段。MDP引入了一种新颖的多模态交互机制（MI）和一种可扩展的偏差感知损失，以感知多模态偏差。MI通过时间属性保留的跨模态注意力来衡量视觉和音频模态在概率嵌入空间中的相关性，识别模态间偏差并构建综合视频特征。可扩展的偏差感知损失旨在增大伪造样本相邻片段的偏差并减小真实样本的偏差。

**Result:** 大量实验证明了所提出框架的有效性，并在多项评估指标上取得了与全监督方法相当的结果。

**Conclusion:** 所提出的多模态偏差感知框架（MDP）能够有效识别视频中的伪造片段，通过感知多模态偏差，在弱监督设置下实现了与全监督方法相当的性能，解决了Deepfake取证中存在的扩展性和效率问题。

> **ai_Abstract:** 针对现有Deepfake取证方法在处理大规模数据集时面临的限制性、耗时和难以扩展的问题，本文提出了一种名为多模态偏差感知框架（MDP）的新方法。该框架旨在通过弱监督学习，仅利用视频级标注来精确识别视频中的伪造片段。MDP的核心在于其新颖的多模态交互机制（MI），它通过跨模态注意力感知视觉和音频模态间的偏差，并结合可扩展的偏差感知损失，以突出伪造区域。实验结果表明，MDP在多个评估指标上取得了与全监督方法相媲美的性能，证明了其在解决时间伪造定位问题上的有效性和潜力。

> **摘要翻译:** 当前关于Deepfake取证的研究通常将检测视为分类任务或时间伪造定位问题，这些方法通常具有限制性、耗时且难以扩展到大型数据集。为了解决这些问题，我们提出了一种用于弱监督时间伪造定位的多模态偏差感知框架（MDP），旨在仅使用视频级标注来识别时间上的部分伪造片段。MDP提出了一种新颖的多模态交互机制（MI）和一种可扩展的偏差感知损失来感知多模态偏差，从而实现了伪造片段精确的起始和结束时间戳定位。具体来说，MI引入了一种时间属性保留的跨模态注意力，用于衡量视觉和音频模态在概率嵌入空间中的相关性。它能够识别模态间偏差并构建用于时间伪造定位的综合视频特征。为了在弱监督学习中进一步探索时间偏差，提出了一种可扩展的偏差感知损失，旨在增大伪造样本相邻片段的偏差并减小真实样本的偏差。大量的实验证明了所提出框架的有效性，并在多项评估指标上取得了与全监督方法相当的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [675] [MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs](https://arxiv.org/abs/2410.12332)
> *MC-Bench：多模态大语言模型时代的多上下文视觉定位基准*

*Yunqiu Xu, Linchao Zhu, Yi Yang* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 多上下文视觉定位, MLLMs, 基准测试, 视觉定位, MC-Bench

**Comment:** Accepted by ICCV 2025

> **TL;DR:** MC-Bench提出了一个多上下文视觉定位新任务，并构建了一个2K高质量数据集来评估MLLM在多图像实例级视觉语言问题上的能力，发现现有MLLM与人类之间存在显著性能差距。

**AI_Comments:** 本文通过引入多上下文视觉定位任务和MC-Bench数据集，填补了现有MLLMs在处理多图像、实例级视觉语言问题评估上的空白。其创新之处在于提出了一种新的评估范式，并构建了一个高质量、开放式提示的数据集。研究结果揭示了MLLMs在复杂多上下文场景下的不足，为未来MLLMs的发展提供了明确的研究方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）在视觉-语言理解方面表现出色，但它们解决单图像之外的实例级视觉-语言问题的能力仍需进一步探索。为了评估MLLMs这些尚未被验证的能力，本文提出了多上下文视觉定位这一新的视觉定位任务。

**Method:** 本文提出了一个名为“多上下文视觉定位”的新视觉定位任务，旨在根据开放式文本提示在多张图像中定位感兴趣的实例。为此，构建了一个包含2K个高质量、手动标注样本的新数据集MC-Bench。每个样本包含一对实例级标注图像和对应的文本提示，指示图像中的目标实例。这些文本提示高度开放，遵循三种不同风格，涵盖20种实用技能。作者对20多个最先进的MLLMs和具有潜在多上下文视觉定位能力的基座模型进行了基准测试，并开发了简单但有效的代理基线和通过多上下文指令微调的微调基线。

**Result:** 评估结果显示，现有MLLMs与人类之间存在显著的性能差距，并提出了一些有启发性的观察结果，为未来的研究方向提供了建议。

**Conclusion:** MC-Bench和本文的实证发现有望鼓励研究社区进一步推进MLLMs在实例级任务（特别是在多图像上下文）中尚未开发的潜力。

> **ai_Abstract:** 本文提出了一个名为MC-Bench的新基准，旨在评估多模态大语言模型（MLLMs）在多上下文视觉定位任务中的能力。该任务要求MLLMs根据开放式文本提示在多张图像中定位特定实例。MC-Bench数据集包含2K个高质量、手动标注的图像对和文本提示。研究团队对20多个最先进的MLLMs进行了基准测试，并发现现有MLLMs与人类在多上下文视觉定位能力上存在显著差距，为未来研究指明了方向。

> **摘要翻译:** 尽管多模态大语言模型（MLLMs）在视觉-语言理解方面表现出色，但它们解决单图像之外的实例级视觉-语言问题的能力仍需进一步探索。为了评估MLLMs这些尚未被验证的能力，本文提出了一个名为“多上下文视觉定位”的新视觉定位任务，旨在根据开放式文本提示在多张图像中定位感兴趣的实例。为了促进这项研究，我们构建了一个新的数据集MC-Bench，该数据集包含2K个高质量、手动标注的样本。每个样本都包含一对实例级标注图像和相应的文本提示，指示图像中的目标实例。这些文本提示高度开放，遵循三种不同的风格，涵盖20种实用技能。我们对20多个最先进的MLLMs和具有潜在多上下文视觉定位能力的基座模型进行了基准测试，同时还测试了我们开发的简单但有效的代理基线以及通过多上下文指令微调的微调基线。我们的评估揭示了现有MLLMs与人类之间存在显著的性能差距，并提出了一些有启发性的观察结果，为未来的方向提供了建议。我们希望MC-Bench和我们的实证发现能够鼓励研究社区进一步推进MLLMs在实例级任务中尚未开发的潜力，特别是在多图像上下文中。项目页面：https://xuyunqiu.github.io/MC-Bench。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [679] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
> *GEMINUS：双感知全局与场景自适应专家混合模型用于端到端自动驾驶*

*Chi Wan, Yixin Cui, Jiatong Du, Shuo Yang, Yulong Bai, Yanjun Huang* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 端到端自动驾驶, 专家混合, 全局专家, 场景自适应, 双感知路由器

**Comment:** 

> **TL;DR:** GEMINUS提出了一种双感知全局与场景自适应专家混合模型，用于端到端自动驾驶，在复杂多样的交通环境中实现了自适应和鲁棒的性能，超越了现有方法。

**AI_Comments:** 本文通过引入专家混合模型，特别是结合全局专家和场景自适应专家，并通过双感知路由器进行动态选择，有效地解决了端到端自动驾驶在复杂多样场景中适应性不足的问题。这种架构设计提升了模型的鲁棒性和自适应性，并在基准测试中取得了显著的性能提升，尤其在仅使用单目视觉输入的情况下。其创新点在于对不同场景的精细化处理和专家动态选择机制。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单模态规划方法难以学习多样化的驾驶技能以应对复杂多样的交通环境，无法有效处理多样化场景。

**Method:** 本文提出了GEMINUS框架，一个专家混合的端到端自动驾驶系统，包含一个全局专家、一个场景自适应专家组和一个双感知路由器。全局专家在整体数据集上训练以获得鲁棒性能；场景自适应专家在对应场景子集上训练以实现自适应性能；双感知路由器同时考虑场景级特征和路由不确定性，动态激活专家模块。

**Result:** GEMINUS在Bench2Drive闭环基准测试中优于现有方法，并在驾驶分数和成功率方面达到最先进水平，即使仅使用单目视觉输入。消融研究显示，相对于原始单专家基线，驾驶分数提高7.67%，成功率提高22.06%，MultiAbility-Mean提高19.41%。

**Conclusion:** 通过双感知路由器对全局专家和场景自适应专家组的有效耦合，GEMINUS在多样化场景中实现了自适应和鲁棒的端到端自动驾驶性能。

> **ai_Abstract:** 本文提出了GEMINUS，一个用于端到端自动驾驶的专家混合框架，旨在解决现有方法在复杂多样交通环境中适应性不足的问题。GEMINUS结合了在整体数据集上训练的全局专家和在特定场景子集上训练的场景自适应专家，并通过一个双感知路由器动态选择专家。该方法在Bench2Drive基准测试中表现优异，并在驾驶分数和成功率上达到了最先进水平，证明了其在多样化场景中的自适应和鲁棒性。

> **摘要翻译:** 端到端自动驾驶需要自适应和鲁棒地处理复杂多样的交通环境。然而，普遍存在的单模态规划方法试图学习一个整体策略，但难以获取多样化的驾驶技能来处理多样化的场景。因此，本文提出了GEMINUS，一个专家混合的端到端自动驾驶框架，其特点是包含一个全局专家、一个场景自适应专家组，并配备了一个双感知路由器。具体而言，全局专家在整体数据集上进行训练，具有鲁棒的性能。场景自适应专家在相应的场景子集上进行训练，实现自适应性能。双感知路由器同时考虑场景级特征和路由不确定性，以动态激活专家模块。通过双感知路由器对全局专家和场景自适应专家组的有效耦合，GEMINUS在多样化场景中实现了自适应和鲁棒的性能。GEMINUS在Bench2Drive闭环基准测试中优于现有方法，并在驾驶分数和成功率方面达到最先进水平，即使仅使用单目视觉输入。此外，消融研究表明，相对于原始的单专家基线，驾驶分数有7.67%的显著提升，成功率有22.06%的提升，MultiAbility-Mean有19.41%的提升。代码将在https://github.com/newbrains1/GEMINUS 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [682] [Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis](https://arxiv.org/abs/2507.01756)
> *重新思考离散标记：将其视为连续自回归图像合成的条件*

*Peng Zheng, Junke Wang, Yi Chang, Yizhou Yu, Rui Ma, Zuxuan Wu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 离散标记, 连续表示, 自回归图像合成, DisCon, ImageNet

**Comment:** iccv 2025, camera-ready version

> **TL;DR:** DisCon 通过将离散标记作为连续表示的条件，改进了自回归图像合成，避免了量化损失和分布外伪影问题。

**AI_Comments:** 这项工作的创新之处在于将离散标记重新诠释为条件信号，巧妙地结合了离散表示（结构化空间）和连续表示（更高保真度）的优点，同时规避了它们的缺点。这种混合方法显著提升了自回归图像合成的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于自回归的视觉生成模型中，离散标记的量化过程会导致信息损失并降低图像保真度。而直接预测连续标记则面临无界高维空间中的密度估计挑战，并可能生成分布外伪影。

**Method:** 本文提出了 DisCon（离散条件连续自回归模型）框架，将离散标记重新解释为条件信号而非生成目标。通过建模以离散标记为条件的连续表示的条件概率，DisCon 规避了连续标记建模的优化挑战，同时避免了量化造成的信息损失。

**Result:** DisCon 在 ImageNet 256×256 生成上实现了 1.38 的 gFID 分数，明显优于最先进的自回归方法。

**Conclusion:** DisCon 通过将离散标记视为条件信号，有效解决了离散和连续标记自回归图像合成的局限性，从而实现了卓越的性能。

> **ai_Abstract:** 本文介绍了 DisCon，一种新颖的自回归图像合成框架，旨在解决离散和连续标记方法的局限性。DisCon 将离散标记重新解释为连续表示的条件信号，从而避免了量化带来的信息损失以及连续标记建模的优化挑战。该方法在 ImageNet 上实现了最先进的性能，显著提高了图像保真度。

> **摘要翻译:** 大型语言模型（LLM）的最新进展激发了将图像编码为离散标记并利用自回归（AR）框架进行视觉生成的兴趣。然而，基于AR的视觉生成模型中的量化过程本质上会引入信息损失，从而降低图像保真度。为了缓解这一限制，最近的研究探索了自回归预测连续标记。与存在于结构化有界空间中的离散标记不同，连续表示存在于无界、高维空间中，这使得密度估计更具挑战性，并增加了生成分布外伪影的风险。基于上述发现，这项工作引入了 DisCon（离散条件连续自回归模型），这是一种新颖的框架，它将离散标记重新解释为条件信号而非生成目标。通过建模以离散标记为条件的连续表示的条件概率，DisCon 规避了连续标记建模的优化挑战，同时避免了量化引起的信息损失。DisCon 在 ImageNet 256×256 生成上实现了 1.38 的 gFID 分数，明显优于最先进的自回归方法。项目页面：https://pengzheng0707.github.io/DisCon。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [694] [VICI: VLM-Instructed Cross-view Image-localisation](https://arxiv.org/abs/2507.04107)
> *VICI: VLM指令的跨视图图像定位*

*Xiaohan Zhang, Tavis Shore, Chen Chen, Oscar Mendez, Simon Hadfield, Safwan Wshah* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 跨视图地理定位, 图像定位, 检索, 重排序, 窄视场

**Comment:** 

> **TL;DR:** 本文提出了VICI，一种用于UAVM 2025挑战赛的高性能解决方案，旨在将窄视场街景图像与卫星图像进行匹配。该方法采用两阶段的检索和重排序策略，在存在显著视角和尺度变化的情况下，实现了具有竞争力的匹配精度。

**AI_Comments:** 该论文解决了地理定位领域一个更具挑战性和实际意义的问题，即在有限视场和未知相机参数下的跨视图图像匹配，这超越了传统全景视图的局限性。其两阶段的检索和重排序策略是提升复杂条件下定位精度的关键创新点。

<details>
  <summary>Details</summary>

**Motivation:** 全景跨视图地理定位已接近性能极限，而现实世界场景通常提供的是视场有限且相机参数未知的街景查询图像。本研究的动机是在这些实际约束下探索可达到的最高性能。

**Method:** 该方法采用两阶段：首先检索给定查询的候选卫星图像嵌入，然后是重排序阶段，选择性地提高顶层候选的检索精度。这种方法在显著的视角和尺度变化下也能实现更精确的匹配。

**Result:** 实验表明，该方法取得了具有竞争力的结果，R@1和R@10检索率分别为\topone%和\topten%。

**Conclusion:** 优化后的检索和重排序策略在提升实际地理定位性能方面具有巨大潜力。

> **ai_Abstract:** VICI提出了一种用于跨视图图像定位的高性能两阶段方法，旨在解决UAVM 2025挑战赛中窄视场街景图像与卫星图像的匹配问题。该方法通过结合候选卫星图像嵌入检索和后续的重排序阶段，有效处理了视图和尺度的显著变化，从而在实际地理定位场景中实现了高精度匹配。

> **摘要翻译:** 在本文中，我们提出了一种针对UAVM 2025挑战赛的高性能解决方案，该挑战赛侧重于使用University-1652数据集将窄视场街景图像与相应的卫星图像进行匹配。随着全景跨视图地理定位接近性能巅峰，探索更实际的问题表述变得越来越重要。现实世界场景很少提供全景街景查询；相反，查询通常由相机参数未知的有限视场图像组成。我们的工作优先探索在这些约束下可实现的最高性能，突破现有架构的极限。我们的方法首先检索给定查询的候选卫星图像嵌入，然后是重排序阶段，选择性地提高顶层候选的检索精度。这种两阶段方法即使在任务固有的显著视角和尺度变化下也能实现更精确的匹配。通过实验，我们证明我们的方法取得了具有竞争力的结果——R@1和R@10检索率分别达到了\topone%和\topten%。这强调了优化检索和重排序策略在推进实际地理定位性能方面的潜力。代码可在https://github.com/tavisshore/VICI获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [697] [ToFe: Lagged Token Freezing and Reusing for Efficient Vision Transformer Inference](https://arxiv.org/abs/2507.16260)
> *ToFe：用于高效视觉Transformer推理的滞后令牌冻结与重用*

*Haoyue Zhang, Jie Zhang, Song Guo* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 视觉Transformer, 令牌削减, 计算效率, 资源受限设备, 模型推理

**Comment:** 

> **TL;DR:** ToFe通过滞后冻结和重用不重要令牌，显著降低了视觉Transformer的推理计算成本，同时保持了性能。

**AI_Comments:** ToFe的创新点在于其“滞后令牌冻结和重用”机制，解决了现有令牌削减方法不可逆的问题，允许模型更灵活地利用不同阶段的令牌信息。这对于在资源受限设备上部署高效的ViT模型具有重要意义。该方法通过端到端训练优化，实现了性能与效率的良好平衡，具有较强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 视觉Transformer计算成本高昂，特别是在自注意力机制方面，阻碍了其在资源受限设备上的部署。现有令牌削减方法不可逆地丢弃不重要令牌，阻止了它们在后续块中的重用，而早期削减的令牌可能在后期有用。因此，需要在模型性能和计算开销之间取得平衡。

**Method:** 本文提出了ToFe（令牌冻结与重用）框架，在每个阶段识别重要令牌，并暂时冻结不重要令牌，允许它们在后期滞后重用。具体地，设计了一个用于令牌识别的预测模块和一个用于恢复冻结令牌的近似模块。该框架通过计算预算感知的端到端训练与主干网络联合优化，以自适应处理每个块中必要的令牌。

**Result:** ToFe将LV-ViT模型的计算成本降低了50%，同时Top-1准确率下降不到2%。与现有最先进方法相比，ToFe在性能和复杂度之间实现了更好的权衡。

**Conclusion:** ToFe通过创新的滞后令牌冻结与重用机制，有效解决了视觉Transformer的计算效率问题，显著降低了计算成本，同时保持了高准确率，在性能与复杂性之间取得了优越的平衡。

> **ai_Abstract:** 本文提出了ToFe（令牌冻结与重用）框架，旨在解决视觉Transformer在资源受限设备上的部署效率问题。ToFe通过在每个阶段识别并暂时冻结不重要令牌，允许其在后续阶段滞后重用，从而避免了现有令牌削减方法的不可逆性。该框架包含一个预测模块用于令牌识别和一个近似模块用于恢复冻结令牌，并通过计算预算感知的端到端训练进行优化。实验结果显示，ToFe显著降低了计算成本，同时保持了高准确率，在性能与复杂度之间取得了更好的平衡。

> **摘要翻译:** 尽管视觉Transformer (ViT) 在各种视觉任务中取得了显著成功，但其计算成本高昂的自注意力机制阻碍了它们在资源受限设备上的部署。令牌削减，即在前向传播过程中丢弃不那么重要的令牌，已被提出用于提高Transformer模型的效率。然而，现有方法不可逆地处理不重要的令牌，阻止了它们在后续块中的重用。考虑到Transformer在不同块之间关注不同的信息，早期块中削减的令牌可能在后期有用。此外，为了使Transformer模型适应资源受限设备，在模型性能和计算开销之间取得平衡至关重要。为了解决这些挑战，在本文中，我们引入了一种新颖的令牌冻结与重用 (ToFe) 框架，在该框架中，我们在每个阶段识别重要令牌并暂时冻结不重要的令牌，允许它们在后期滞后重用。具体来说，我们设计了一个用于令牌识别的预测模块和一个用于恢复冻结令牌的近似模块。通过与主干网络进行计算预算感知的端到端训练联合优化，ToFe可以自适应地处理每个块中必要的令牌，从而在保持性能的同时降低计算成本。大量实验表明，ToFe将LV-ViT模型的计算成本降低了50%，Top-1准确率下降不到2%，与现有最先进方法相比，在性能和复杂度之间实现了更好的权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [699] [Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation](https://arxiv.org/abs/2411.06106)
> *迈向通过学习个性化不变表示实现通用3D医学多模态泛化*

*Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 医学图像, 多模态泛化, 个性化, 不变表示, 深度学习

**Comment:** Accepted by ICCV25

> **TL;DR:** 本文提出一种通过学习个性化不变表示来解决医学多模态任务中模态差异和个体差异导致的泛化挑战的方法，并证明其有效性。

**AI_Comments:** 这项工作创新性地强调了个性化在医学多模态泛化中的重要性，并提出了一种通过学习个性化不变表示来解决这一挑战的有效方法。它超越了传统方法仅关注共同解剖特征的局限，有望提高医疗AI模型在真实世界复杂场景中的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 医学成像模态间的差异以及个体差异严重阻碍了多模态医学任务的泛化能力。现有方法忽略了个体差异，仅关注共同解剖特征，导致泛化能力受限。

**Method:** 提出一种方法，通过利用个体层面约束和可学习的生物学先验，近似学习跨模态的个性化不变表示${X}_h$，从而实现个性化泛化。

**Result:** 学习到的个性化不变表示${X}_h$具有高度的泛化性和可迁移性。实验结果一致表明，额外引入的个性化显著提高了在不同场景下的性能和泛化能力。

**Conclusion:** 个性化对于多模态泛化至关重要，并且通过学习个性化不变表示的方法能够有效提高多模态医学任务的性能和泛化能力。

> **ai_Abstract:** 本文提出一种新颖的方法，通过学习跨模态的个性化不变表示${X}_h$来解决医学多模态任务中因模态差异和个体差异导致的泛化难题。该方法利用个体层面约束和可学习的生物学先验来近似${X}_h$。实验证明，这种个性化表示显著提升了模型在不同多模态医学任务中的泛化性能和可迁移性，强调了个性化在多模态泛化中的关键作用。

> **摘要翻译:** 医学成像模态之间由于底层原理不同而存在的差异，给多模态医学任务中的泛化带来了巨大挑战。除了模态差距之外，器官大小和代谢率等个体差异进一步阻碍了模型在模态和不同人群之间有效泛化的能力。尽管个性化很重要，但现有的多模态泛化方法通常忽视个体差异，只关注共同的解剖特征。这种局限性可能导致各种医学任务的泛化能力减弱。在本文中，我们揭示了个性化对于多模态泛化至关重要。具体来说，我们提出一种方法，通过利用个体层面约束和可学习的生物学先验，近似学习跨各种模态的底层个性化不变表示${X}_h$，从而实现个性化泛化。我们验证了学习个性化${X}_h$的可行性和益处，表明这种表示在各种多模态医学任务中具有高度的泛化性和可迁移性。大量的实验结果一致表明，额外纳入的个性化显著提高了在不同场景下的性能和泛化能力，证实了其有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [702] [LongSplat: Online Generalizable 3D Gaussian Splatting from Long Sequence Images](https://arxiv.org/abs/2507.16144)
> *LongSplat：在线可泛化的长序列图像3D高斯辐射场*

*Guichen Huang, Ruoyu Wang, Xiangjun Gao, Che Sun, Yuwei Wu, Shenghua Gao, Yunde Jia* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 3D高斯辐射场, 在线重建, 长序列, 实时, 新视图合成

**Comment:** 

> **TL;DR:** LongSplat提出了一个在线实时3D高斯重建框架，用于长序列图像输入，通过流式更新机制增量整合观测并选择性压缩冗余高斯，实现了高效的实时新视图合成。

**AI_Comments:** LongSplat的创新在于其流式更新机制和高斯图像表示（GIR），有效解决了在线、实时3D高斯辐射场处理长序列数据的挑战，通过增量更新和冗余压缩有效管理内存和计算成本，使其在连续3D重建方面具有高度实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯辐射场方法在在线长序列场景中应用受限，因为它们依赖缓慢的每场景优化或无法提供高效的增量更新，从而阻碍了持续性能。

**Method:** LongSplat提出了一种流式更新机制，用于增量整合当前视图观测并选择性压缩冗余历史高斯。其核心是高斯图像表示（GIR），它将3D高斯参数编码为结构化的、类似图像的2D格式，实现高效融合和身份感知冗余压缩。此外，该方法利用现有图像压缩技术指导生成更紧凑和高质量的3D高斯。

**Result:** LongSplat在实时新视图合成中实现了最先进的效率-质量权衡，提供实时重建，并与现有逐像素高斯预测方法相比，高斯数量减少了44%。

**Conclusion:** LongSplat成功解决了在线实时3D高斯重建在长序列图像输入方面的挑战，通过创新的流式更新和高斯图像表示，实现了卓越的效率和质量。

> **ai_Abstract:** LongSplat是一个针对长序列图像输入的在线实时3D高斯重建框架。它采用流式更新机制，通过新颖的高斯图像表示（GIR）增量整合当前视图观测并选择性压缩冗余高斯，实现高效融合和身份感知冗余压缩。该方法还利用图像压缩技术指导生成紧凑且高质量的高斯，在实时新视图合成中达到了最先进的效率和质量，并使高斯数量减少了44%。

> **摘要翻译:** 3D高斯辐射场实现了高保真度的新视图合成，但其在在线长序列场景中的应用仍然有限。现有方法要么依赖缓慢的每场景优化，要么无法提供高效的增量更新，从而阻碍了持续性能。在本文中，我们提出了LongSplat，一个专为长序列图像输入设计的在线实时3D高斯重建框架。其核心思想是一个流式更新机制，该机制增量地整合当前视图观测，同时选择性地压缩冗余的历史高斯。该机制的关键是我们的高斯图像表示（GIR），这是一种将3D高斯参数编码为结构化、类似图像的2D格式的表示。GIR同时实现了当前视图和历史高斯的有效融合以及身份感知的冗余压缩。这些功能支持在线重建，并使模型适应长序列而不会造成内存或计算成本过高。此外，我们利用现有的图像压缩方法来指导生成更紧凑、更高质量的3D高斯。广泛的评估表明，LongSplat在实时新视图合成中实现了最先进的效率-质量权衡，提供了实时重建，同时与现有的逐像素高斯预测方法相比，高斯数量减少了44%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [706] [CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation](https://arxiv.org/abs/2507.07154)
> *CL-Polyp: 一种对比学习增强的息肉精确分割网络*

*Desheng Li, Chaoliang Liu, Zhiyong Xiao* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 息肉分割, 对比学习, 深度学习, 图像分割, 结肠镜

**Comment:** 

> **TL;DR:** CL-Polyp是一种利用对比学习和轻量级模块的息肉分割网络，在多个基准数据集上超越了现有SOTA方法。

**AI_Comments:** 该论文的创新点在于将对比学习引入到息肉分割任务中，通过自监督方式提升了特征的判别能力，有效解决了标注数据需求大的问题。同时，MASPP和CA模块的设计也体现了对多尺度信息融合和边界细节恢复的精细考虑。其在多个数据集上的SOTA表现证明了方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习息肉分割方法常需要大量标注数据且依赖任务相似性，限制了泛化能力。

**Method:** 提出CL-Polyp网络，通过对比学习增强编码器对判别性特征的提取，无需额外标注。引入改进的空洞空间金字塔池化（MASPP）模块用于多尺度特征融合，以及通道连接和元素相加（CA）模块用于低级和上采样特征的融合，以增强边界重建。

**Result:** 在Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS五个基准数据集上，CL-Polyp始终优于现有SOTA方法。在Kvasir-SEG和CVC-ClinicDB数据集上，IoU指标分别提高了0.011和0.020。

**Conclusion:** CL-Polyp通过结合对比学习和高效模块，在临床息肉分割中展现出卓越的有效性。

> **ai_Abstract:** 本文提出CL-Polyp，一种基于对比学习的息肉分割网络，旨在解决现有方法对大量标注数据和任务相似性的依赖问题。CL-Polyp利用自监督对比学习增强特征提取，并引入MASPP和CA模块优化多尺度特征融合和边界重建。实验证明，CL-Polyp在多个基准数据集上均优于现有先进方法，有效提升了息肉分割的准确性。

> **摘要翻译:** 从结肠镜图像中准确分割息肉对于结直肠癌的早期诊断和治疗至关重要。大多数现有的基于深度学习的息肉分割方法采用编码器-解码器架构，一些方法利用多任务框架（例如结合分类等辅助任务）来改进分割。然而，这些方法通常需要更多标注数据，并且依赖于任务相似性，这可能会限制泛化能力。为了解决这些挑战，我们提出了CL-Polyp，一个对比学习增强的息肉分割网络。我们的方法利用对比学习通过对比息肉图像中的正负样本对来增强编码器对判别性特征的提取。这种自监督策略在不需要额外标注的情况下提高了视觉表示。我们还引入了两个高效、轻量级的模块：改进的空洞空间金字塔池化（MASPP）模块，用于改进多尺度特征融合；以及通道连接和元素相加（CA）模块，用于合并低级和上采样特征，以增强边界重建。在Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS五个基准数据集上进行的广泛实验表明，CL-Polyp始终优于现有最先进的方法。具体而言，它在Kvasir-SEG和CVC-ClinicDB数据集上的IoU指标分别提高了0.011和0.020，证明了其在临床息肉分割中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [712] [GraspDiffusion: Synthesizing Realistic Whole-body Hand-Object Interaction](https://arxiv.org/abs/2410.13911)
> *GraspDiffusion：合成逼真的全身手物互动*

*Patrick Kwon, Chen Chen, Hanbyul Joo* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 人物互动, 生成模型, 姿态合成, 扩散模型, 3D姿态估计

**Comment:** 

> **TL;DR:** GraspDiffusion是一种新颖的生成方法，能够合成逼真的全身手物互动场景，通过分别利用3D身体和手部姿态的生成先验，并优化为联合抓取姿态，解决了现有模型在生成人类与物体互动方面的不足。

**AI_Comments:** 这篇论文提出了一种创新性的方法GraspDiffusion，通过结合身体和手部姿态的生成先验来解决复杂的人手物互动合成问题。其创新点在于将全身姿态与手部抓取姿态进行联合优化，从而实现了对物体相对位置的精确控制，并最终生成了高质量、逼真的互动场景。这对于虚拟现实、内容创作等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成模型在合成高质量图像时，常常无法生成人类用手与物体互动的场景，这主要是因为模型对这类互动理解不足，以及合成身体复杂区域的困难。

**Method:** 本文提出GraspDiffusion，一种新颖的生成方法，用于创建逼真的人物互动场景。该方法首先给定一个3D物体网格，然后构建逼真的全身姿态并控制物体相对于人体的S位置。这通过分别利用3D身体和手部姿态的生成先验，并将其优化为联合抓取姿态来实现。最终的姿态指导图像合成，以正确反映预期的互动。

**Result:** GraspDiffusion能够成功解决生成全身人与物体互动这一相对未被充分研究的问题，并且性能优于现有方法，能够创建逼真且多样的人与物体互动场景。

**Conclusion:** GraspDiffusion能够有效地生成逼真的全身人与物体互动场景，并超越了现有方法，解决了生成模型在处理复杂人手物互动方面的挑战。

> **ai_Abstract:** GraspDiffusion是一种新颖的生成模型，旨在解决现有生成模型在合成逼真全身手物互动场景方面的不足。它通过结合3D身体和手部姿态的生成先验，并将其优化为联合抓取姿态，从而在给定3D物体网格的情况下，构建出逼真且可控的全身互动姿态。这些姿态随后用于指导图像合成，最终生成高质量、多样化且符合预期的手物互动场景，并展现出优于现有方法的性能。

> **摘要翻译:** 近期生成模型能够合成高质量图像，但通常无法生成人类用手与物体互动的场景。这主要源于模型对这类互动的误解，以及合成身体复杂区域的困难。本文提出GraspDiffusion，一种新颖的生成方法，能够创建逼真的人物互动场景。给定一个3D物体网格，GraspDiffusion首先构建逼真的全身姿态，并能控制物体相对于人体的S位置。这通过分别利用3D身体和手部姿态的生成先验，并将其优化为联合抓取姿态来实现。由此产生的姿态指导图像合成，以正确反映预期的互动，从而创建逼真多样的手物互动场景。我们证明GraspDiffusion能够成功解决生成全身手物互动这一相对未充分研究的问题，同时优于现有方法。代码和模型将发布在https://webtoon.github.io/GraspDiffusion。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [720] [Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine](https://arxiv.org/abs/2507.08716)
> *虚幻引擎即可满足一切：仅用一个引擎进行多模态ISAC数据仿真*

*Kongwu Huang, Shiyi Mu, Jun Jiang, Yuan Gao, Shugong Xu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** ISAC, 多模态数据仿真, 虚幻引擎, 无人机定位, 数据集

**Comment:** 

> **TL;DR:** 本文提出了Great-X平台，利用虚幻引擎实现高效多模态ISAC数据仿真，并构建了一个大型无人机多模态数据集Great-MSD，同时提出了一个基于CSI的无人机3D定位算法。

**AI_Comments:** 这项工作通过整合虚幻引擎提供了一个创新的、统一的平台来模拟多模态ISAC数据，这对于推动ISAC研究，特别是数据驱动的方法至关重要。其开放数据集和基线算法的贡献显著降低了该领域研究的门槛，并有望加速相关应用的发展。单引擎集成多种传感器数据仿真的方法具有很高的实用价值和效率优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了探索缩放定律在ISAC（感知与通信一体化）研究中的潜力，并解决高效、同步多模态数据仿真的需求。

**Method:** 本文提出了名为Great-X的单引擎多模态数据孪生平台，该平台在虚幻引擎中重建Sionna的光线追踪计算，并与自动驾驶工具深度集成，以实现CSI、RGB、雷达和激光雷达等多模态数据的同步仿真。

**Result:** 基于Great-X平台，本文构建了一个开源、大规模、低空无人机多模态通感数据集Great-MSD，并提出了一个基于CSI的无人机3D定位基线算法。该算法展示了其可行性以及在不同CSI仿真引擎间的泛化能力。

**Conclusion:** Great-X平台能够实现高效的多模态ISAC数据仿真，并且基于此平台构建的数据集和提出的定位算法验证了其在ISAC研究中的潜力和实用性，特别是其在不同CSI仿真引擎间的良好泛化能力。

> **ai_Abstract:** 本文提出了Great-X，一个基于虚幻引擎的单引擎多模态数据孪生平台，旨在高效同步仿真ISAC（感知与通信一体化）数据，包括CSI、RGB、雷达和激光雷达。该平台通过重建Sionna的光线追踪并与自动驾驶工具集成实现。基于此平台，研究者构建了开源、大规模的低空无人机多模态通感数据集Great-MSD，并提出了一个基于CSI的无人机3D定位算法，验证了其可行性和跨不同CSI仿真引擎的泛化能力。

> **摘要翻译:** 缩放定律已在大型语言模型和基础模型中取得成功。为了探索它们在ISAC研究中的潜力，我们提出了Great-X。这个单引擎多模态数据孪生平台在虚幻引擎中重建了Sionna的光线追踪计算，并与自动驾驶工具深度集成。这使得CSI、RGB、雷达和激光雷达等多模态数据能够高效、同步地进行仿真。基于该平台，我们构建了一个名为Great-MSD的开源、大规模、低空无人机多模态通感数据集，并提出了一个基于CSI的无人机3D定位基线算法，证明了其可行性以及在不同CSI仿真引擎间的泛化能力。相关代码和数据集将在以下网址提供：https://github.com/hkw-xg/Great-MCD。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [725] [Dyna3DGR: 4D Cardiac Motion Tracking with Dynamic 3D Gaussian Representation](https://arxiv.org/abs/2507.16608)
> *Dyna3DGR：基于动态3D高斯表示的4D心脏运动追踪*

*Xueming Fu, Pei Wu, Yingtai Li, Xin Luo, Zihang Jiang, Junhao Mei, Jian Lu, Gao-Jun Teng, S. Kevin Zhou* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 心脏运动追踪, 4D, 3D高斯表示, 自监督, 心脏磁共振成像

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** Dyna3DGR是一种基于动态3D高斯表示的新型4D心脏运动追踪方法，它通过自监督学习实现高精度追踪，无需大量训练数据，并在ACDC数据集上表现优于现有最先进方法。

**AI_Comments:** Dyna3DGR的创新之处在于结合了显式3D高斯表示和隐式神经运动场建模，并采用了自监督学习范式，显著减少了对大量标注数据的依赖。其通过可微分体渲染实现连续运动表示与图像空间对齐，同时保持拓扑和时间一致性，是对现有心脏运动追踪方法的重要改进。该方法的提出为精确评估心脏功能提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 准确分析心脏运动对评估心脏功能至关重要。然而，由于心肌组织的同质性和缺乏独特特征，精细的4D心脏运动追踪仍然具有挑战性。现有方法（包括基于图像和基于表示的方法）存在局限性，例如基于图像的方法可能难以保持拓扑一致性或需要大量训练数据，而基于表示的方法常会丢失图像级别的细节。

**Method:** 本文提出Dyna3DGR，一个结合显式3D高斯表示和隐式神经运动场建模的新型框架。该方法以自监督方式同时优化心脏结构和运动，无需大量训练数据或点对点对应。通过可微分体渲染，Dyna3DGR有效地连接了连续运动表示与图像空间对齐，同时保持了拓扑和时间一致性。

**Result:** 在ACDC数据集上的综合评估表明，Dyna3DGR在追踪精度上超越了最先进的基于深度学习的微分同胚配准方法。

**Conclusion:** Dyna3DGR通过结合显式3D高斯表示和隐式神经运动场建模，成功解决了4D心脏运动追踪的挑战，并在自监督方式下实现了更高的追踪精度，同时保持了拓扑和时间一致性。

> **ai_Abstract:** 本文提出Dyna3DGR，一种结合显式3D高斯表示和隐式神经运动场建模的4D心脏运动追踪新框架。该方法以自监督方式优化心脏结构和运动，无需大量训练数据，并通过可微分体渲染保持拓扑和时间一致性。在ACDC数据集上的评估显示，Dyna3DGR在追踪精度上超越了现有的深度学习配准方法，有效解决了心脏运动追踪的挑战。

> **摘要翻译:** 对心脏运动的准确分析对于评估心脏功能至关重要。虽然动态心脏磁共振成像（CMR）可以在整个心动周期中捕获详细的组织运动，但由于心肌组织的同质性和缺乏独特特征，精细的4D心脏运动追踪仍然具有挑战性。现有方法大致可分为基于图像和基于表示的方法，每种方法都有其局限性。基于图像的方法，包括传统和基于深度学习的配准方法，要么难以保持拓扑一致性，要么严重依赖大量的训练数据。基于表示的方法虽然有前景，但常常会丢失图像级别的细节。为了解决这些局限性，我们提出了动态3D高斯表示（Dyna3DGR），一个结合显式3D高斯表示与隐式神经运动场建模的新型框架。我们的方法以自监督方式同时优化心脏结构和运动，无需大量的训练数据或点对点对应。通过可微分体渲染，Dyna3DGR有效地将连续运动表示与图像空间对齐，同时保持拓扑和时间一致性。在ACDC数据集上的综合评估表明，我们的方法在追踪精度上超越了最先进的基于深度学习的微分同胚配准方法。代码将在https://github.com/windrise/Dyna3DGR提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [731] [MAN++: Scaling Momentum Auxiliary Network for Supervised Local Learning in Vision Tasks](https://arxiv.org/abs/2507.16279)
> *MAN++: 扩展动量辅助网络用于视觉任务中的监督局部学习*

*Junhao Su, Feiyu Zhu, Hengyu Shi, Tianyang Han, Yurui Qiu, Junfeng Luo, Xiaoming Wei, Jialin Gao* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 监督局部学习, 动量辅助网络, 指数移动平均, 内存优化, 视觉任务

**Comment:** 14 pages

> **TL;DR:** MAN++提出了一种新的监督局部学习方法，通过动量辅助网络和可学习的缩放偏差，实现了与端到端训练相当的性能，并显著降低了GPU内存消耗。

**AI_Comments:** MAN++的创新点在于引入了基于EMA的动态交互机制和可学习的缩放偏差，有效解决了监督局部学习中块间信息流通和特征差异的问题。其重要性在于提供了一种在性能上可与传统端到端训练媲美，同时显著降低内存消耗的训练方法，这对于资源受限的深度学习应用具有重要意义，并为探索更具生物学合理性的学习范式提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习中的端到端反向传播存在参数优化过程中的更新锁定、高GPU内存消耗和缺乏生物学合理性等问题。监督局部学习旨在通过将网络划分为多个局部块并设计独立的辅助网络来分别更新每个块，但由于梯度仅在单个局部块内传播，导致性能下降，未能取代端到端反向传播。

**Method:** 本文提出了动量辅助网络++（MAN++），通过采用相邻块参数的指数移动平均（EMA）引入动态交互机制，以增强网络间的通信。辅助网络通过EMA更新，有效弥补了块间的信息鸿沟。为解决直接应用EMA参数可能因局部块间特征差异而导致次优的问题，MAN++引入了可学习的缩放偏差来平衡特征差异，进一步提升性能。

**Result:** 实验结果表明，MAN++在图像分类、目标检测和图像分割等任务上，使用多种网络架构，实现了与端到端训练相当的性能，同时显著降低了GPU内存使用量。

**Conclusion:** MAN++为监督局部学习提供了一个新颖的视角，并为传统的训练方法提供了一个可行的替代方案。

> **ai_Abstract:** 本研究提出了一种名为MAN++的动量辅助网络，旨在解决传统端到端反向传播训练中存在的更新锁定、高内存消耗及生物学不合理性等问题，并克服现有监督局部学习方法性能下降的局限性。MAN++通过引入基于指数移动平均（EMA）的动态交互机制来增强块间信息流，并通过可学习的缩放偏差来平衡局部块间的特征差异。实验证明，MAN++在图像分类、目标检测和图像分割等视觉任务上，实现了与端到端训练相当的性能，并显著降低了GPU内存消耗，为监督局部学习提供了一个有效且可行的替代方案。

> **摘要翻译:** 深度学习通常依赖于端到端反向传播进行训练，这种方法在参数优化过程中固有地存在更新锁定、高GPU内存消耗和缺乏生物学合理性等问题。相比之下，监督局部学习旨在通过将网络划分为多个局部块并设计独立的辅助网络来分别更新每个块，从而缓解这些挑战。然而，由于梯度仅在单个局部块内传播，导致性能下降，使得监督局部学习无法取代端到端反向传播。为了解决这些限制并促进块间信息流，我们提出了动量辅助网络++（MAN++）。MAN++通过采用相邻块参数的指数移动平均（EMA）引入动态交互机制，以增强网络间的通信。通过EMA更新的辅助网络有效地弥合了块间的信息鸿沟。值得注意的是，我们观察到由于局部块间的特征差异，直接应用EMA参数可能不是最优的。为了解决这个问题，我们引入了一个可学习的缩放偏差，以平衡特征差异，从而进一步提高性能。我们通过对包括图像分类、目标检测和图像分割在内的任务进行广泛实验，并利用多种网络架构验证了MAN++。实验结果表明，MAN++实现了与端到端训练相当的性能，同时显著降低了GPU内存使用量。因此，MAN++为监督局部学习提供了一个新颖的视角，并为传统的训练方法提供了一个可行的替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [735] [Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation](https://arxiv.org/abs/2507.09577)
> *记忆增强型SAM2用于免训练手术视频分割*

*Ming Yin, Fu Wang, Xujiong Ye, Yanda Meng, Zeyu Fu* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 手术视频分割, SAM2, 记忆增强, 免训练, 视频目标分割

**Comment:** Accepted in MICCAI 2025

> **TL;DR:** MA-SAM2通过改进记忆机制，提升了SAM2在手术视频分割中的性能，有效应对遮挡和复杂运动，且无需额外训练，在EndoVis数据集上表现优于SAM2。

**AI_Comments:** 本文的创新点在于提出了记忆增强型SAM2（MA-SAM2），通过改进SAM2的记忆机制来适应手术视频的复杂性，特别是处理快速运动、频繁遮挡和复杂交互。其重要性体现在实现了免训练的性能提升，这意味着可以在不增加计算成本和数据标注负担的情况下，显著提高现有SAM2模型在特定高难度任务上的表现，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的SAM2模型在处理复杂、长时间的手术视频时，由于其贪婪选择记忆设计以及手术视频特有的快速器械移动、频繁遮挡和复杂器械-组织交互等特性，导致性能下降。

**Method:** 提出了一种名为记忆增强型SAM2（MA-SAM2）的免训练视频目标分割策略。该策略引入了新颖的上下文感知和抗遮挡记忆模型，并通过多目标、单循环、单提示推理进一步提高了多器械视频中跟踪过程的效率。

**Result:** MA-SAM2在不引入额外参数或无需额外训练的情况下，在EndoVis2017和EndoVis2018数据集上分别比SAM2的性能提升了4.36%和6.1%。它对复杂器械运动引起的遮挡和交互表现出强大的鲁棒性，同时在整个视频中保持了目标分割的准确性。

**Conclusion:** MA-SAM2在手术视频分割中展现出巨大的潜力，适用于实际手术应用。

> **ai_Abstract:** 本文针对SAM2在手术视频分割中因其记忆设计和手术视频特性导致的性能下降问题，提出了一种名为记忆增强型SAM2（MA-SAM2）的免训练视频目标分割策略。MA-SAM2引入了上下文感知和抗遮挡记忆模型，并采用多目标、单循环、单提示推理，有效提升了对复杂器械运动和遮挡的鲁棒性及跟踪效率。实验证明，MA-SAM2在无需额外训练和参数的情况下，在EndoVis2017和EndoVis2018数据集上分别比SAM2提高了4.36%和6.1%的性能，展现了其在实际手术应用中的潜力。

> **摘要翻译:** 手术视频分割是计算机辅助手术中的一项关键任务，对于提高手术质量和患者预后至关重要。最近，分割一切模型2（SAM2）框架在图像和视频分割方面都取得了显著进展。然而，SAM2固有的贪婪选择记忆设计的局限性被手术视频的独特属性——快速器械移动、频繁遮挡和复杂的器械-组织交互——放大，导致在复杂、长时间视频的分割性能下降。为了应对这些挑战，我们引入了记忆增强型（MA）-SAM2，这是一种免训练的视频目标分割策略，具有新颖的上下文感知和抗遮挡记忆模型。MA-SAM2对复杂器械运动引起的遮挡和交互表现出强大的鲁棒性，同时在整个视频中保持了目标在视频中的分割准确性。采用多目标、单循环、单提示推理进一步提高了多器械视频中跟踪过程的效率。在不引入任何额外参数或无需进一步训练的情况下，MA-SAM2在EndoVis2017和EndoVis2018数据集上分别比SAM2的性能提升了4.36%和6.1%，展示了其在实际手术应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [743] [Physically Consistent Image Augmentation for Deep Learning in Mueller Matrix Polarimetry](https://arxiv.org/abs/2411.07918)
> *穆勒矩阵偏振测量深度学习中物理一致的图像增强*

*Christopher Hahne, Omar Rodriguez-Nunez, Éléa Gros, Théotim Lucas, Ekkehard Hewer, Tatiana Novikova, Theoni Maragkou, Philippe Schucht, Richard McKinley* | **Category: cs.CV, physics.med-ph** | **Updated: 2025-07-22**

**Keywords:** 穆勒矩阵偏振测量, 图像增强, 深度学习, 物理一致性, 数据增强

**Comment:** preprint

> **TL;DR:** 本文引入了一种物理一致的图像增强框架，用于穆勒矩阵偏振测量数据，以解决标准增强方法导致结果失真的问题，并显著提升了深度学习模型的泛化能力和性能。

**AI_Comments:** 这项研究的创新之处在于其提出了一个专门用于穆勒矩阵偏振数据的物理一致图像增强框架，解决了传统增强方法在该领域中导致数据失真的核心问题。其重要性在于，它为偏振成像领域的深度学习应用提供了更可靠、更准确的数据增强方法，尤其对于数据量有限的场景具有突破性意义，有望推动该领域的研究和应用发展。通过确保数据增强的物理正确性，该方法提高了模型的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 穆勒矩阵偏振测量数据具有独特的结构，标准图像增强方法（如旋转和翻转）无法保持其偏振特性，可能导致深度学习模型产生错误结果，限制了深度学习在偏振测量领域的应用，尤其是在数据集有限的情况下。

**Method:** 研究人员引入了一个通用的模拟框架，该框架能够对穆勒矩阵应用物理一致的旋转和翻转，以保持偏振保真度。他们首先通过与真实世界捕获数据比较来验证其偏振特异性增强的物理一致性。随后，将这些增强应用于语义分割任务。

**Result:** 实验结果表明，传统的图像增强方法应用于偏振数据时会导致错误结果，凸显了基于物理方法的必要性。本文提出的物理一致增强方法在语义分割任务中显著提高了模型的泛化能力和性能，并验证了其物理一致性。该框架还释放了深度学习模型在有限样本量偏振数据集上的潜力。

**Conclusion:** 本研究强调了在穆勒矩阵偏振成像深度学习中，物理知情数据增强的必要性，为该领域更广泛的应用和更稳健的部署铺平了道路。它特别为样本量有限的偏振数据集解锁了深度学习模型的潜力。

> **ai_Abstract:** 本研究提出了一种针对穆勒矩阵偏振测量深度学习的物理一致图像增强框架。鉴于标准增强方法无法保持偏振特性并可能导致错误结果，该框架通过模拟实现了物理一致的旋转和翻转。实验证明，该方法不仅验证了物理一致性，还在语义分割任务中显著提升了模型的泛化能力和性能，强调了物理知情数据增强在偏振成像领域的重要性，尤其对有限样本数据集具有重要意义。

> **摘要翻译:** 穆勒矩阵偏振测量捕获了偏振光与样本相互作用的重要信息，由于其独特的结构，给深度学习中的数据增强带来了独特的挑战。虽然增强是提高数据集多样性和减少过拟合的有效且经济的方式，但标准变换（如旋转和翻转）无法在穆勒矩阵图像中保持偏振特性。为此，我们引入了一个通用的模拟框架，该框架能够对穆勒矩阵应用物理一致的旋转和翻转，旨在保持偏振保真度。我们在多个数据集上的实验结果表明，传统的增强方法应用于偏振数据时可能导致错误结果，这突显了我们基于物理方法的重要性。在我们的实验中，我们首先将我们针对偏振的特异性增强与真实世界捕获的数据进行比较，以验证其物理一致性。然后，我们将这些增强应用于语义分割任务，实现了模型泛化能力和性能的显著提升。这项研究强调了在深度学习（DL）中偏振成像的物理知情数据增强的必要性，为该领域更广泛的应用和更稳健的部署铺平了道路。特别是，我们的框架释放了DL模型在样本量有限的偏振数据集上的潜力。我们的代码实现可在github.com/hahnec/polar_augment获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [745] [Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction](https://arxiv.org/abs/2507.10978)
> *弥合间隙：通过残差间隙校正弥补步态识别中的遮挡问题*

*Ayush Gupta, Siyuan Huang, Rama Chellappa* | **Category: cs.CV** | **Updated: 2025-07-21**

**Keywords:** 步态识别, 遮挡, 残差学习, 人员重识别, RG-Gait

**Comment:** Accepted at IJCB 2025

> **TL;DR:** RG-Gait通过残差学习解决了步态识别中的遮挡问题，提高了遮挡情况下的性能，同时保持了对完整步态的识别准确性。

**AI_Comments:** 该论文创新性地将遮挡步态识别问题转化为残差学习任务，通过校正残差偏差来弥补遮挡带来的信息缺失。其优势在于无需配对的遮挡-完整序列数据，并且能够同时兼顾遮挡和完整步态的识别性能，这对于实际应用具有重要意义。公开代码也体现了其可复现性和对社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 步态识别在远距离人员重识别中越来越受欢迎，但大多数现有方法未能解决实际中常见的遮挡问题。现有解决遮挡的方法通常需要难以收集的配对数据，或在处理完整步态输入时性能下降。

**Method:** 本研究提出了RG-Gait，一种用于遮挡步态识别的残差校正方法，同时保留了完整步态的识别能力。该方法将问题建模为残差学习任务，将遮挡步态特征概念化为与完整步态表示的残差偏差。所提出的网络自适应地整合学习到的残差。

**Result:** RG-Gait显著提高了在遮挡步态序列上的性能，同时没有损害完整步态的识别准确性。该方法在Gait3D、GREW和BRIAR等挑战性数据集上进行了评估，并证明学习残差是解决遮挡步态识别并保持完整性识别的有效技术。

**Conclusion:** 学习残差是解决遮挡步态识别并保持完整步态识别准确性的有效技术。

> **ai_Abstract:** 本论文提出RG-Gait，一种基于残差学习的步态识别方法，旨在解决实际应用中常见的遮挡问题。该方法将遮挡步态视为对完整步态表示的残差偏差，并通过自适应整合学习到的残差来校正。实验结果表明，RG-Gait显著提升了遮挡步态的识别性能，同时保持了对完整步态的准确性，验证了残差学习在解决此类问题上的有效性。

> **摘要翻译:** 步态作为一种人员重识别方法正变得越来越流行，因为它能够在远距离识别人员。然而，目前大多数步态识别工作都没有解决遮挡这一实际问题。在那些解决了该问题的工作中，有些需要成对的遮挡和完整序列，这在现实世界中是不切实际的。此外，这些方法虽然对遮挡有效，但在完整输入上未能保持性能。为了应对这些挑战，我们提出了RG-Gait，一种用于遮挡步态识别的残差校正方法，同时保留了完整步态的识别能力。我们将该问题建模为残差学习任务，将遮挡步态特征概念化为与完整步态表示的残差偏差。我们提出的网络自适应地整合学习到的残差，显著提高了在遮挡步态序列上的性能，而不会损害完整步态的识别准确性。我们在具有挑战性的Gait3D、GREW和BRIAR数据集上评估了我们的方法，并表明学习残差可以成为解决遮挡步态识别并保留完整性识别的有效技术。我们已在https://github.com/Ayush-00/rg-gait公开了代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [749] [VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding](https://arxiv.org/abs/2507.09815)
> *VRU-Accident：一个用于事故场景理解的视频问答和密集字幕的视觉-语言基准*

*Younggun Kim, Ahmed S. Abdelrahman, Mohamed Abdel-Aty* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** VRU-Accident, 视觉-语言基准, 视频问答, 密集字幕, 事故场景理解

**Comment:** 22 pages, 11 figures, 5 tables

> **TL;DR:** VRU-Accident是一个新的大型视觉-语言基准，用于评估多模态大语言模型在涉及弱势道路使用者（VRU）的事故场景理解能力，研究发现当前模型在推理事故原因和类型方面仍面临挑战。

**AI_Comments:** 该论文的创新之处在于首次提出了一个专注于VRU-车辆事故的大规模视觉-语言基准，填补了现有评估工具的空白。其重要性体现在为自动驾驶领域中MLLMs在安全关键场景下的推理能力评估提供了新的标准。研究结果也揭示了当前MLLMs在处理复杂因果推理方面的局限性，为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 确保弱势道路使用者（VRU）的安全是自动驾驶系统面临的关键挑战，因为涉及VRU的碰撞往往导致严重或致命后果。尽管多模态大语言模型（MLLMs）在增强自动驾驶汽车的场景理解和决策方面显示出潜力，但目前缺乏一个标准化的基准来定量评估它们在涉及VRU的复杂、安全关键场景中的推理能力。

**Method:** 提出了VRU-Accident，一个大规模的视觉-语言基准，旨在评估多模态大语言模型在涉及VRU的高风险交通场景中的表现。VRU-Accident包含1K个真实世界的行车记录仪事故视频，标注了6K个多项选择问答对（涵盖六个安全关键类别）以及1K个密集场景描述。该基准明确关注VRU-车辆事故，提供捕捉事故时空动态和因果语义的丰富、细粒度标注。对17个最先进的多模态大语言模型在多项选择VQA任务和密集字幕任务上进行了全面评估。

**Result:** 评估结果显示，多模态大语言模型在视觉接地属性方面表现尚可，但在推理和描述事故原因、类型和可预防性方面面临重大挑战。

**Conclusion:** 当前多模态大语言模型在理解和推理涉及弱势道路使用者事故的复杂因果关系方面仍存在显著不足，需要进一步研究和改进。

> **ai_Abstract:** 本文提出了VRU-Accident，一个专门用于评估多模态大语言模型在涉及弱势道路使用者（VRU）的事故场景理解能力的视觉-语言基准。该基准包含1K个真实世界的事故视频，配有6K个多项选择问答对和1K个密集场景描述，重点关注VRU-车辆事故的时空动态和因果语义。通过对17个先进模型的评估，研究发现当前模型在视觉属性理解上表现尚可，但在推理和描述事故原因、类型及可预防性方面存在显著不足。

> **摘要翻译:** 确保弱势道路使用者（VRU），如行人和骑自行车者，的安全是自动驾驶系统面临的关键挑战，因为涉及VRU的碰撞往往导致严重或致命后果。尽管多模态大语言模型（MLLMs）在增强场景理解和决策方面显示出潜力，但目前缺乏一个标准化的基准来定量评估它们在涉及VRU的复杂、安全关键场景中的推理能力。为了解决这一空白，我们提出了VRU-Accident，一个大规模的视觉-语言基准，旨在评估多模态大语言模型在涉及VRU的高风险交通场景中的表现。VRU-Accident包含1K个真实世界的行车记录仪事故视频，标注了6K个多项选择问答对（涵盖六个安全关键类别，包含24K个候选选项和3.4K个独特答案选择），以及1K个密集场景描述。与以往工作不同，我们的基准明确关注VRU-车辆事故，提供捕捉事故时空动态和因果语义的丰富、细粒度标注。为了评估当前多模态大语言模型的现状，我们对17个最先进的模型在多项选择VQA任务和密集字幕任务上进行了全面评估。我们的研究结果表明，尽管多模态大语言模型在视觉接地属性方面表现尚可，但它们在推理和描述事故原因、类型和可预防性方面面临重大挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [751] [SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities](https://arxiv.org/abs/2507.16151)
> *SPACT18：互补RGB和热模态的脉冲式人体动作识别基准数据集*

*Yasser Ashraf, Ahmed Sharshar, Velibor Bojkovic, Bin Gu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 脉冲相机, 动作识别, 多模态数据集, SNN, 节能视觉

**Comment:** 

> **TL;DR:** 本文介绍了首个使用脉冲相机的视频动作识别数据集SPACT18，该数据集还包含同步的RGB和热模态，旨在推动基于脉冲数据的节能型动作识别研究。

**AI_Comments:** 该论文的主要创新在于构建了首个集脉冲、RGB和热模态于一体的视频动作识别数据集。这对于推动基于脉冲相机的节能型SNN研究至关重要，填补了该领域的一个空白。其重要性在于为未来多模态视频理解和低功耗AI视觉系统提供了宝贵的基准和研究工具。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲相机具有超高能效和卓越的时间分辨率，但目前缺乏用于脉冲相机的视频动作识别（VAR）数据集。为了推动节能、超低功耗视频理解，特别是基于脉冲数据的动作识别任务的研究，需要一个综合性的基准数据集。

**Method:** 本文引入了首个利用脉冲相机进行视频动作识别（VAR）的数据集，并同时提供了同步的RGB和热模态数据。通过保留脉冲数据的固有稀疏性和时间精度，该数据集为探索多模态视频理解提供了一个独特的平台，并可用于直接比较脉冲、热和RGB模态。

**Result:** 该论文成功构建并发布了SPACT18数据集，这是第一个包含脉冲相机数据，并同步了RGB和热模态的视频动作识别基准数据集。该数据集为SNNs的综合基准测试、多模态视频理解探索以及不同模态的直接比较提供了独特的平台和宝贵资源。

**Conclusion:** SPACT18数据集是首个结合脉冲相机、RGB和热模态的视频动作识别基准数据集，它将极大地推动节能、超低功耗视频理解，特别是基于脉冲数据的动作识别领域的研究。

> **ai_Abstract:** 本文介绍了SPACT18，这是首个专为脉冲神经网络（SNNs）设计的视频动作识别（VAR）基准数据集。该数据集创新性地结合了脉冲相机数据，并同步提供了互补的RGB和热模态，旨在利用脉冲相机固有的高能效和精细时空分辨率优势。SPACT18为研究多模态视频理解、直接比较不同视觉模态以及推动基于脉冲数据的节能型动作识别任务提供了重要资源和平台。

> **摘要翻译:** 脉冲相机是一种受生物启发的视觉传感器，通过在每个像素处累积光强度来异步发射脉冲，从而提供超高能效和卓越的时间分辨率。与记录光强度变化以捕捉运动的事件相机不同，脉冲相机提供更精细的时空分辨率和对连续变化的更精确表示。在本文中，我们引入了首个使用脉冲相机的视频动作识别（VAR）数据集，以及同步的RGB和热模态，以实现对脉冲神经网络（SNNs）的全面基准测试。通过保留脉冲数据固有的稀疏性和时间精度，我们的三个数据集为探索多模态视频理解提供了一个独特的平台，并为直接比较脉冲、热和RGB模态提供了宝贵的资源。这项工作贡献了一个新颖的数据集，将推动节能、超低功耗视频理解的研究，特别是使用基于脉冲数据的动作识别任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [755] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
> *用于图像质量评估的视觉-语言模型知识蒸馏方法*

*Yongkang Hou, Jiarun Song* | **Category: cs.CV** | **Updated: 2025-07-22**

**Keywords:** 图像质量评估, 视觉-语言模型, 知识蒸馏, CLIP, 模型压缩

**Comment:** 

> **TL;DR:** 本文提出了一种视觉-语言模型知识蒸馏方法，通过利用CLIP的IQA知识来训练具有架构优势的模型，以解决CLIP在IQA任务中参数负担过重和局部失真特征识别能力不足的问题，同时显著降低模型复杂度并超越现有方法。

**AI_Comments:** 该论文的创新点在于提出了针对视觉-语言模型（如CLIP）的知识蒸馏方法，以克服其在图像质量评估任务中参数量大和局部特征识别弱的缺点。通过结合提示学习、微调和模态自适应蒸馏，实现了在保持甚至超越性能的同时大幅降低模型复杂度，这对于实际部署具有重要意义。该研究为将大型预训练模型应用于特定任务并进行模型压缩提供了有效思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于视觉-语言模型（如CLIP）的图像质量评估（IQA）方法存在参数负担过重和识别局部失真特征能力不足的问题。

**Method:** 本研究提出了一种视觉-语言模型知识蒸馏方法。首先，设计了质量分级提示模板以引导CLIP输出质量分数。然后，对CLIP进行微调以增强其在IQA任务中的能力。最后，提出了一种模态自适应知识蒸馏策略，实现了从CLIP教师模型到学生模型的知识引导。

**Result:** 实验结果表明，所提出的方法显著降低了模型复杂度，并且在多个IQA数据集上优于现有IQA方法。

**Conclusion:** 该方法在图像质量评估任务中展现出强大的实际部署潜力，因为它在降低模型复杂度的同时提升了性能。

> **ai_Abstract:** 本研究提出了一种用于图像质量评估（IQA）的视觉-语言模型知识蒸馏方法，旨在解决现有CLIP模型在IQA任务中存在的参数冗余和局部特征识别不足的问题。该方法通过设计质量分级提示模板、微调CLIP模型以及采用模态自适应知识蒸馏策略，将CLIP的IQA知识有效地传递给更轻量级的学生模型。实验证明，该方法在显著降低模型复杂度的同时，在多个IQA数据集上超越了现有方法，展现出良好的应用前景。

> **摘要翻译:** 图像质量评估（IQA）是计算机视觉中的一项核心任务。基于视觉-语言模型（如CLIP）的多模态方法在IQA任务中表现出卓越的泛化能力。为了解决CLIP在IQA中参数负担过重和识别局部失真特征能力不足的问题，本研究提出了一种视觉-语言模型知识蒸馏方法，旨在利用CLIP的IQA知识指导具有架构优势的模型的训练。首先，设计了质量分级提示模板以引导CLIP输出质量分数。然后，对CLIP进行微调以增强其在IQA任务中的能力。最后，提出了一种模态自适应知识蒸馏策略，实现了从CLIP教师模型到学生模型的引导。我们的实验在多个IQA数据集上进行，结果表明所提出的方法显著降低了模型复杂度，同时优于现有IQA方法，展示出强大的实际部署潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [6] ["Just a strange pic": Evaluating 'safety' in GenAI Image safety annotation tasks from diverse annotators' perspectives](https://arxiv.org/abs/2507.16033)
> *“只是一张奇怪的图片”：从不同标注者视角评估生成式AI图像安全标注任务中的“安全”*

*Ding Wang, Mark Díaz, Charvi Rastogi, Aida Davani, Vinodkumar Prabhakaran, Pushkar Mishra, Roma Patel, Alicia Parrish, Zoe Ashwood, Michela Paganini, Tian Huey Teh, Verena Rieser, Lora Aroyo* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-21**

**Keywords:** AI安全, 图像标注, 人类感知, 道德推理, 生成式AI

**Comment:** Accepted to AAAI/ACM Conference on Artificial Intelligence, Ethics,
  and Society 2025 (AIES 2025)

> **TL;DR:** 本研究发现，标注者对生成式AI图像的安全判断远超预设规则，涉及复杂的道德、情感和情境推理，而现有系统常忽略这些关键因素。

**AI_Comments:** 该论文意义重大，因为它强调了当前AI生成内容中客观安全分类的局限性，并突出了人类主观、道德和情境推理的关键作用。它为理解真实个体如何感知危害提供了宝贵的定性见解，这对于构建更稳健、更符合伦理的AI安全系统至关重要。发现任务设计本身会影响判断尤其富有洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 理解AI生成内容中的“安全”是复杂的，开发者常依赖预定义分类，但现实世界的安全判断还涉及个人、社会和文化对危害的感知。本研究旨在探究标注者如何评估AI生成图像的安全性，并分析其判断背后的定性推理。

**Method:** 通过分析5372条开放式评论，研究考察了标注者在评估AI生成图像安全时的定性推理。

**Result:** 标注者在评估安全时，始终运用超出结构化安全类别的道德、情感和情境推理。他们更多地考虑对他人而非自身的潜在危害，并将判断基于生活经验、集体风险和社会文化意识。任务结构（包括标注指南）会影响标注者对危害的解读和表达，并影响其判断。标注者常将图像质量、视觉扭曲以及提示与输出不匹配等因素视为感知危害的维度，而这些因素在标准评估框架中常被忽视。现有安全流程遗漏了标注者在任务中运用的关键推理形式。

**Conclusion:** 研究认为应设计能够促进道德反思、区分危害类型并为AI生成内容的主观、情境敏感解释留出空间的评估方法。

> **ai_Abstract:** 本文探讨了人类标注者如何评估AI生成图像的“安全”，发现其判断涉及复杂的道德、情感和情境推理，超越了预设分类。通过分析5372条评论，研究揭示标注者会考虑对他人造成的危害、生活经验和社会文化意识。同时，任务指南也会影响判断，图像质量、视觉扭曲和提示-输出不匹配等因素虽关键却常被现有框架忽视。研究呼吁设计新的评估方法，以容纳主观、情境敏感的解释和多样化的危害类型。

> **摘要翻译:** 理解AI生成内容中的“安全”是复杂的。尽管开发者通常依赖预定义的分类，但现实世界的安全判断也涉及个人、社会和文化对危害的感知。本文研究了标注者如何评估AI生成图像的安全性，重点关注其判断背后的定性推理。通过分析5372条开放式评论，我们发现标注者始终运用超出结构化安全类别的道德、情感和情境推理。许多人更多地反思对他人而非自身的潜在危害，他们的判断基于生活经验、集体风险和社会文化意识。除了个人感知，我们还发现任务本身的结构——包括标注指南——塑造了标注者如何解释和表达危害。指南不仅影响了哪些图像被标记，还影响了其理由背后的道德判断。标注者经常引用图像质量、视觉扭曲以及提示与输出不匹配等因素，认为它们是感知危害维度的原因，而这些因素在标准评估框架中常被忽视。我们的发现揭示，现有的安全流程遗漏了标注者在任务中运用的关键推理形式。我们主张采用能够促进道德反思、区分危害类型并为AI生成内容的主观、情境敏感解释留出空间的评估设计。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [27] [Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education](https://arxiv.org/abs/2505.23631)
> *人类同理心作为编码器：特殊教育中AI辅助的抑郁症评估*

*Boning Zhao* | **Category: cs.HC, cs.AI, cs.CL** | **Updated: 2025-07-21**

**Keywords:** 人类同理心, AI辅助, 抑郁症评估, 特殊教育, 同理心向量

**Comment:** 7 pages, 6 figures. Under review

> **TL;DR:** 该论文提出了一种名为HEAE的新型人机协作AI框架，通过将学生叙述文本与教师的“同理心向量”相结合，以更负责任和道德的方式评估特殊教育学生的抑郁症严重程度，实现了82.74%的分类准确率。

**AI_Comments:** 这项研究的创新之处在于其“人类同理心作为编码器”（HEAE）框架，它独特地将教师的同理心洞察转化为可量化的“同理心向量”并融入AI模型，从而提升了AI在敏感领域（如特殊教育）中进行抑郁症评估的能力。这不仅解决了现有自动化方法缺乏个体化洞察的问题，还通过强调人机协作而非替代人类判断，展现了负责任和道德的AI应用潜力。其重要性在于为情感计算领域提供了一个将人类独特能力（同理心）结构化嵌入AI的范例，为未来AI在复杂社会和情感场景中的应用提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 在特殊教育等敏感环境中评估学生抑郁症具有挑战性。标准化问卷可能无法完全反映学生的真实情况，而自动化方法在处理丰富的学生叙述时往往会失败，因为它们缺乏源于教师与学生之间同理心联系的关键个体化见解。现有方法未能解决这种模糊性或有效整合教育工作者的理解。

**Method:** 本文引入了“人类同理心作为编码器”（HEAE）框架，这是一种以人为本的新型AI框架，用于透明且对社会负责的抑郁症严重程度评估。该方法独特地将学生叙述文本与教师导出的9维“同理心向量”（EV）相结合，其维度受PHQ-9框架指导，旨在将内隐的同理心洞察明确地转化为结构化的AI输入。研究优化了多模态融合、文本表示和分类架构。

**Result:** 该方法在7级严重程度分类中实现了82.74%的准确率。

**Conclusion:** 这项工作通过结构性地嵌入人类同理心，为更负责任和道德的情感计算指明了一条道路。

> **ai_Abstract:** 本研究提出了一种名为“人类同理心作为编码器”（HEAE）的新型AI框架，旨在解决特殊教育环境中学生抑郁症评估的挑战。HEAE通过整合学生叙述文本和教师基于PHQ-9框架构建的9维“同理心向量”，将教师的同理心洞察转化为结构化AI输入，从而实现透明且负责任的抑郁症严重程度评估。实验结果显示，该方法在7级严重程度分类上达到了82.74%的准确率，为负责任的情感计算开辟了新途径。

> **摘要翻译:** 在特殊教育等敏感环境中评估学生抑郁症具有挑战性。标准化问卷可能无法完全反映学生的真实情况。此外，自动化方法在处理丰富的学生叙述时常常失败，缺乏源于教师与学生之间同理心联系的关键、个体化见解。现有方法往往无法解决这种模糊性或有效整合教育工作者的理解。为了通过促进人机协同来解决这些局限性，本文引入了“人类同理心作为编码器”（HEAE），这是一种新颖的、以人为本的AI框架，用于透明且对社会负责的抑郁症严重程度评估。我们的方法独特地将学生叙述文本与教师导出的9维“同理心向量”（EV）相结合，其维度受PHQ-9框架指导，旨在明确地将内隐的同理心洞察转化为结构化的AI输入，从而增强而非取代人类判断。严格的实验优化了多模态融合、文本表示和分类架构，在7级严重程度分类中实现了82.74%的准确率。这项工作通过结构性地嵌入人类同理心，为更负责任和道德的情感计算指明了一条道路。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [35] [Buckaroo: A Direct Manipulation Visual Data Wrangler](https://arxiv.org/abs/2507.16073)
> *Buckaroo：一种直接操作的可视化数据整理工具*

*Annabelle Warner, Andrew McNutt, Paul Rosen, El Kindi Rezig* | **Category: cs.HC, cs.DB** | **Updated: 2025-07-21**

**Keywords:** 数据整理, 可视化系统, 直接操作, 数据异常, 数据科学

**Comment:** Accepted to VLDB25 Demo track

> **TL;DR:** Buckaroo是一个可视化系统，旨在通过直接操作和可视化反馈来简化耗时且易错的数据整理过程，它能自动识别数据异常、推荐修复操作并支持迭代修正。

**AI_Comments:** Buckaroo的创新点在于其直观的直接操作可视化界面，将复杂的数据整理过程转化为用户友好的交互。它通过自动化异常检测和智能操作建议，有效降低了手动编码的门槛和出错率。尤其值得称赞的是其支持迭代工作流的设计，允许用户实时查看操作效果并进行回溯，这对于数据探索和修正至关重要。该系统有望大幅提升数据科学家在数据准备阶段的工作效率和数据质量。

<details>
  <summary>Details</summary>

**Motivation:** 数据整理是数据科学开发中最耗时且易错的阶段，占据项目总时间的80%。传统方法如手动编码或使用电子表格不仅费力，还容易出现数据不一致和错误，影响后续任务的质量。

**Method:** Buckaroo是一个可视化系统，通过直接操作视觉对象来解决数据整理挑战。它具备三个核心功能：1) 自动发现并推荐检查具有异常的“有趣”数据组；2) 建议用户选择整理操作来修复异常；3) 通过显示整理操作的效果并提供撤销/重做功能，支持用户对数据进行可视化操作，以适应数据整理的迭代性质。

**Result:** Buckaroo系统能够突出数据中的差异，并通过直接操作视觉对象实现即时修正。它自动发现异常数据组并推荐检查，提供整理操作建议，并允许用户通过可视化方式操纵数据，支持迭代式数据整理过程。

**Conclusion:** Buckaroo系统提供了一种可视化、直接操作的方法来解决数据整理过程中遇到的挑战，通过自动化异常发现、提供操作建议和支持迭代修正，显著提高了数据准备的效率和准确性。

> **ai_Abstract:** 本文介绍了Buckaroo，一个创新的可视化数据整理系统，旨在解决数据科学中数据准备阶段耗时且易错的问题。Buckaroo通过直观的直接操作界面，自动识别数据异常，推荐修复操作，并提供实时的可视化反馈和撤销/重做功能，从而简化了数据清洗、重构和整合的过程，显著提升了数据整理的效率和准确性。

> **摘要翻译:** 准备数据集——一个被称为数据整理的关键阶段——构成了数据科学开发的主导阶段，耗费了总项目时间的多达80%。这个阶段包含了无数任务：解析数据、为分析重构数据、修复不准确之处、合并数据源、消除重复项以及确保整体数据完整性。传统方法，通常通过Python等语言进行手动编码或使用电子表格，不仅费力而且容易出错。这些问题包括缺失条目、格式不一致到数据类型不准确等，如果处理不当，所有这些都可能影响下游任务的质量。为了应对这些挑战，我们提出了Buckaroo，一个可视化系统，用于突出数据中的差异并通过直接操作视觉对象实现即时修正。Buckaroo (1) 自动查找与其余数据组相比表现出异常的“有趣”数据组，并推荐它们进行检查；(2) 建议用户可以选择的整理操作来修复异常；以及 (3) 允许用户通过显示其整理操作的效果并提供撤销或重做这些操作的能力来可视化地操作他们的数据，这支持了数据整理的迭代性质。配套视频可在 https://youtu.be/iXdCYbvpQVE 查看。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [61] [Toward Understanding Similarity of Visualization Techniques](https://arxiv.org/abs/2506.17032)
> *旨在理解可视化技术的相似性*

*Abdulhaq Adetunji Salako, Christian Tominski* | **Category: cs.HC, cs.GR** | **Updated: 2025-07-22**

**Keywords:** 可视化技术, 相似性, 模型驱动, 专家驱动, 签名

**Comment:** 

> **TL;DR:** 本研究探讨了理解可视化技术相似性的两种方法：模型驱动和专家驱动，并从这两种方法中获得了初步见解。

**AI_Comments:** 这项研究通过结合模型驱动和专家驱动的方法来探索可视化技术的相似性，为该领域的理解提供了一个新颖且实用的视角。尽管结果被明确指出是初步的，但它为未来更深入、更系统的可视化技术分类和比较研究奠定了基础，具有重要的学术价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管存在大量可视化技术且不断有新方法提出，但普遍理解不同可视化技术之间的相似性仍然是一个难题。

**Method:** 本研究从两个角度解决问题：一是采用模型驱动方法，通过定义可视化技术的“签名”来解释其相似性；二是采用专家驱动方法，通过小型在线研究询问可视化专家对成对技术相似性的直感评估。

**Result:** 通过这两种方法，研究者获得了关于13种针对不同数据类型的基本和高级可视化技术相似性的见解。

**Conclusion:** 尽管目前的结果是初步且学术性的，但它们是朝着更好地理解可视化技术相似性迈出的第一步。

> **ai_Abstract:** 本研究旨在解决难以理解可视化技术普遍相似性的问题。论文提出了两种方法：一是模型驱动，通过定义和比较技术“签名”来评估相似性；二是专家驱动，通过在线调查收集专家对技术对相似性的直观判断。研究者通过这两种方法获得了关于13种基本和高级可视化技术相似性的初步见解，为未来更深入地理解可视化技术相似性奠定了基础。

> **摘要翻译:** 文献描述了许多针对不同数据类型、任务和应用场景的可视化技术，并且新技术不断涌现。可视化调查试图捕捉巨大的技术空间，并用有意义的分类对其进行结构化。然而，普遍理解可视化技术的相似性仍然很困难。我们从两个角度探讨这个开放的研究问题。首先，我们遵循一种模型驱动的方法，该方法基于定义可视化技术的签名，并将签名的相似性解释为其相关技术的相似性。其次，遵循一种专家驱动的方法，我们在一项小型在线研究中询问可视化专家对成对可视化技术相似性的即时直观评估。通过这两种方法，我们获得了关于13种针对不同数据类型的基本和高级可视化技术相似性的见解。尽管我们的结果目前是初步且学术性的，但它们是朝着更好地理解可视化技术相似性迈出的第一步。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [70] [Toward music-based stress management: Contemporary biosensing systems for affective regulation](https://arxiv.org/abs/2507.16074)
> *迈向基于音乐的压力管理：用于情感调节的当代生物传感系统*

*Natasha Yamane, Varun Mishra, Matthew S. Goodwin* | **Category: cs.HC** | **Updated: 2025-07-21**

**Keywords:** 生物传感, 音乐疗法, 压力管理, 情感调节, 系统综述

**Comment:** 37 pages, 3 figures, 1 table

> **TL;DR:** 该综述总结并分析了利用生物传感技术进行音乐情感调节和压力管理的系统，识别了现有研究的空白并提出了未来研究方向。

**AI_Comments:** 这篇综述系统地梳理了基于生物传感的音乐情感调节和压力管理领域的现有研究，为该领域提供了一个全面的概览。其创新之处在于对现有系统的分类和对未来研究方向的明确指引，特别是提出了整合AI和多模态传感器的前景，对于推动该领域的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在过去十年中，研究人员越来越关注利用生物传感技术进行基于音乐的情感调节和压力管理干预。

**Method:** 本文采用范围界定和映射综述的方法，总结并综合了关于具有音乐情感调节和压力管理潜在应用的生物传感系统的系统评价和实证研究。

**Result:** 确定了28项研究，涉及646名参与者，大多数系统利用预录音乐、可穿戴心肺传感器或桌面界面。这些系统根据生物传感模式、音乐类型、情感或压力检测及音乐预测的计算模型以及生物反馈机制进行分类。

**Conclusion:** 研究结果突出了这些系统的巨大潜力，并提出了未来的研究方向，例如整合多模态生物传感、探索音乐的治疗机制、利用生成式人工智能进行个性化音乐干预，以及解决方法学、数据隐私和用户控制问题。

> **ai_Abstract:** 本文对基于生物传感的音乐情感调节和压力管理系统进行了范围界定和映射综述，总结了现有研究，识别了28项相关研究，并根据其技术特征进行了分类。研究结果强调了这些系统的潜力，并指出了未来研究的关键方向，包括多模态集成、个性化音乐干预和解决隐私问题。

> **摘要翻译:** 在过去十年中，研究人员越来越多地探索使用生物传感技术进行基于音乐的情感调节和压力管理干预，无论是在实验室还是在现实世界中。这些系统——包括互动音乐应用程序、脑机接口和生物反馈设备——旨在提供引人入胜的个性化体验，以改善治疗效果。在这项范围界定和映射综述中，我们总结并综合了关于具有音乐情感调节和压力管理潜在应用的生物传感系统的系统评价和实证研究，识别了文献中的空白，并强调了未来研究的有前景领域。我们确定了28项研究，涉及646名参与者，其中大多数系统利用预录音乐、可穿戴心肺传感器或桌面界面。我们根据其生物传感模式、音乐类型、情感或压力检测和音乐预测的计算模型以及生物反馈机制对这些系统进行分类。我们的研究结果突出了这些系统的巨大潜力，并提出了未来的方向，例如整合多模态生物传感、探索音乐的治疗机制、利用生成式人工智能进行个性化音乐干预，以及解决方法学、数据隐私和用户控制问题。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [107] [GLOSS: Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing](https://arxiv.org/abs/2507.05461)
> *GLOSS：用于健康与福祉的被动感知数据开放式意义建构的LLM群体*

*Akshat Choube, Ha Le, Jiachen Li, Kaixin Ji, Vedant Das Swain, Varun Mishra* | **Category: cs.HC** | **Updated: 2025-07-21**

**Keywords:** 被动感知数据, 意义建构, 大型语言模型, 健康与福祉, 数据三角测量

**Comment:** 

> **TL;DR:** GLOSS是一个基于LLM的系统，能对被动感知数据进行开放式意义建构和复杂多模态三角测量，显著优于RAG。

**AI_Comments:** GLOSS的创新之处在于其利用大型语言模型群体实现开放式意义建构和复杂的多模态数据三角测量，这显著提升了从被动感知数据中提取高层次洞察的能力。其在准确性和一致性上对RAG的显著超越，表明了该系统在健康与福祉领域应用中的巨大潜力。该研究为解决当前被动感知数据分析中意义建构的挑战提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 从智能手机和可穿戴设备的被动感知数据中实现对个体行为和背景的高层次、整体性理解仍然是一个重大挑战。意义建构需要领域知识和技术专长，这为不同利益相关者带来了障碍。现有支持意义建构的系统要么不是开放式的，要么无法执行复杂的数据三角测量。

**Method:** 本文提出了一种名为GLOSS（Group of LLMs for Open-ended Sensemaking）的新型意义建构系统。GLOSS能够进行开放式意义建构，并执行复杂的多模态三角测量以获取洞察。

**Result:** GLOSS在准确率（87.93%）和一致性（66.19%）方面显著优于常用的检索增强生成（RAG）技术（RAG的准确率为29.31%，一致性为52.85%）。通过四个受先前和正在进行的UbiComp和HCI社区工作启发的用例展示了GLOSS的潜力。

**Conclusion:** GLOSS系统能够对被动感知数据进行开放式意义建构和复杂多模态三角测量，显著优于现有技术，并在健康与福祉领域具有广阔的应用前景。

> **ai_Abstract:** 本文介绍了一种名为GLOSS的新型意义建构系统，它利用大型语言模型（LLMs）群体对来自智能手机和可穿戴设备的被动感知数据进行开放式意义建构和复杂的多模态数据三角测量，以克服现有系统在全面理解个体行为和背景方面的局限性。实验证明，GLOSS在准确性和一致性方面显著优于检索增强生成（RAG）技术，并在健康与福祉的多个用例中展现了其有效性。

> **摘要翻译:** 智能手机和可穿戴设备的普及使得研究人员能够利用这些设备的被动感知数据来构建各种健康和行为结果的预测和检测模型。然而，要实现对个体行为和背景的高层次、整体性理解仍然是一个重大挑战。由于被动感知数据的性质，意义建构——即解释和提取洞察的过程——需要领域知识和技术专长，这为不同利益相关者带来了障碍。现有支持意义建构的系统要么不是开放式的，要么无法执行复杂的数据三角测量。在本文中，我们提出了一种新颖的意义建构系统，即用于开放式意义建构的LLM群体（GLOSS），它能够进行开放式意义建构并执行复杂的多模态三角测量以获取洞察。我们证明GLOSS显著优于常用的检索增强生成（RAG）技术，实现了87.93%的准确率和66.19%的一致性，而RAG的准确率为29.31%，一致性为52.85%。此外，我们通过四个受先前和正在进行的UbiComp和HCI社区工作启发的用例展示了GLOSS的潜力。最后，我们讨论了GLOSS的潜力、其更广泛的影响以及我们工作的局限性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [111] [BDIViz: An Interactive Visualization System for Biomedical Schema Matching with LLM-Powered Validation](https://arxiv.org/abs/2507.16117)
> *BDIViz：一个用于生物医学模式匹配的交互式可视化系统，支持LLM驱动的验证*

*Eden Wu, Dishita G Turakhia, Guande Wu, Christos Koutras, Sarah Keegan, Wenke Liu, Beata Szeitz, David Fenyo, Cláudio T. Silva, Juliana Freire* | **Category: cs.HC** | **Updated: 2025-07-22**

**Keywords:** 生物医学模式匹配, 交互式可视化, LLM, 数据整合, 视觉分析

**Comment:** 11 pages, 9 figures. Accepted to IEEE VIS 2025 (Full Papers Track,
  submission ID 1204)

> **TL;DR:** BDIViz是一个交互式可视化系统，它结合多种匹配方法和大型语言模型（LLM）验证，显著提高了生物医学模式匹配的准确性，同时减少了认知负荷和整理时间。

**AI_Comments:** 该论文的创新点在于将交互式可视化与大型语言模型（LLM）相结合，应用于生物医学模式匹配这一复杂且对准确性要求极高的领域。其集成方法和可视化设计有效解决了传统自动化方法在处理大量属性和细微语义差异时的不足，显著提高了匹配效率和准确性，对于生物医学数据整合具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学数据整合对于探索性分析和元研究至关重要，但模式匹配过程（识别不同数据集元素之间的语义对应关系）仍然是一项劳动密集且容易出错的任务。即使是目前最先进的自动化方法，由于属性数量庞大和细微的语义差异，在应用于生物医学模式时也常导致低准确率。

**Method:** 我们提出了BDIViz，一个新颖的可视化分析系统，旨在简化生物医学数据的模式匹配过程。BDIViz采用集成方法，结合了多种匹配方法与基于LLM的验证，通过交互式热图总结匹配结果，并提供协调视图，使用户能够快速比较属性及其值。其方法无关的设计允许系统集成各种模式匹配算法并适应特定应用需求。

**Result:** 通过两个生物医学案例研究和一项与领域专家的组内用户研究，我们证明BDIViz与基线方法相比，显著提高了匹配准确性，同时减少了认知负荷和整理时间。

**Conclusion:** BDIViz通过结合多种匹配方法和LLM驱动的验证，并利用交互式可视化技术，有效解决了生物医学模式匹配中的准确性和效率挑战，显著提升了匹配性能并降低了用户负担。

> **ai_Abstract:** BDIViz是一个为生物医学模式匹配设计的新型交互式可视化分析系统。它通过结合多种匹配方法和大型语言模型（LLM）驱动的验证，解决现有自动化方法在生物医学领域准确率低、耗时耗力的问题。系统采用集成方法，利用交互式热图和协调视图帮助用户比较属性，其与方法无关的设计使其能集成不同算法。案例研究和用户研究表明，BDIViz显著提高了匹配准确性，同时减少了用户的认知负荷和整理时间。

> **摘要翻译:** 生物医学数据整合对于实现探索性分析和元研究至关重要，但模式匹配过程——识别不同数据集（模式）元素之间的语义对应关系——仍然是一项劳动密集且容易出错的任务。即使是目前最先进的自动化方法，由于属性数量庞大和它们之间细微的语义差异，在应用于生物医学模式时也常导致低准确率。我们提出了BDIViz，一个新颖的可视化分析系统，旨在简化生物医学数据的模式匹配过程。通过与领域专家的形成性研究，我们确定了有效解决方案的关键要求，并开发了交互式可视化技术，解决了可扩展性挑战和语义模糊性。BDIViz采用集成方法，结合了多种匹配方法与基于LLM的验证，通过交互式热图总结匹配结果，并提供协调视图，使用户能够快速比较属性及其值。我们与方法无关的设计允许系统集成各种模式匹配算法并适应特定应用需求。通过两个生物医学案例研究和一项与领域专家的组内用户研究，我们证明BDIViz与基线方法相比，显著提高了匹配准确性，同时减少了认知负荷和整理时间。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [151] [A Human-Centered Approach to Identifying Promises, Risks, & Challenges of Text-to-Image Generative AI in Radiology](https://arxiv.org/abs/2507.16207)
> *放射学中文本到图像生成式人工智能的机遇、风险和挑战的人本方法*

*Katelyn Morrison, Arpit Mathur, Aidan Bradshaw, Tom Wartmann, Steven Lundi, Afrooz Zandifar, Weichang Dai, Kayhan Batmanghelich, Motahhare Eslami, Adam Perer* | **Category: cs.HC, cs.AI, cs.CY** | **Updated: 2025-07-22**

**Keywords:** 文本到图像生成式AI, 放射学, 人本方法, 风险, 挑战

**Comment:** 13 pages, 2 figures, accepted to AAAI/ACM AIES 2025

> **TL;DR:** 本研究采用人本方法，让医学专业人士评估文本到CT扫描生成式AI在医学教育、培训和实践中的潜力和风险，并发现其技术和领域特定挑战，强调负责任的AI开发。

**AI_Comments:** 这篇论文的创新之处在于其以人为本的研究方法，强调在AI技术开发初期就纳入最终用户的视角，这对于确保AI在医疗等高风险领域的实用性、安全性和伦理合规性至关重要。它不仅关注技术进步，更深入探讨了实际应用中的社会和实践问题，对于负责任的AI开发具有指导意义，有助于弥补技术开发与实际应用需求之间的鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到图像生成模型在医学图像生成方面取得了显著进展，但目前的开发忽视了医学专业人员在实践中如何受益和使用这些AI。在不涉及利益相关者的情况下开发特定领域GenAI，可能导致模型无用甚至有害。因此，本研究旨在通过人本方法，识别和评估文本到图像生成式AI在放射学中的机遇、风险和挑战。

**Method:** 本研究采用以人为本的方法，通过让医学学生、放射学学员和放射科医生等利益相关者参与评估和反思新型文本到CT扫描GenAI模型，以识别其机遇、风险和挑战。通过探索性模型提示活动，收集了他们对AI在医学教育、培训和实践中作用的看法，并揭示了生成合成医学图像的技术挑战和领域特定风险。

**Result:** 研究揭示了医学生、放射学学员和放射科医生对文本到CT扫描生成式AI在医学教育、培训和实践中作用的看法。此外，还发现了生成合成医学图像的技术挑战和领域特定风险。

**Conclusion:** 论文最后反思了医学文本到图像生成式AI在实际应用中的影响和重要性。

> **ai_Abstract:** 本文采用以人为本的方法，深入探讨了文本到图像生成式AI在放射学领域的应用前景、潜在风险及挑战。研究通过让医学生、放射学学员和放射科医生等关键利益相关者参与评估一个文本到CT扫描生成模型，收集了他们对AI在医学教育、培训和实践中作用的看法，并揭示了生成合成医学图像过程中面临的技术和领域特有风险。这项工作强调了在AI模型开发早期阶段融入最终用户视角的重要性，以确保医疗AI的实用性、安全性和负责任发展。

> **摘要翻译:** 随着文本到图像生成模型迅速发展，人工智能研究人员在开发能够从文本提示生成复杂医学图像的特定领域模型方面取得了重大进展。尽管如此，这些技术进步却忽视了医学专业人员是否以及如何从文本到图像生成式人工智能（GenAI）中受益和在实践中使用它。在不涉及利益相关者的情况下开发特定领域GenAI，我们面临构建的模型可能无用甚至弊大于利的风险。本文中，我们采用以人为本的方法进行负责任的模型开发，通过让利益相关者参与评估和反思新型文本到CT扫描GenAI模型的机遇、风险和挑战。通过探索性模型提示活动，我们揭示了医学生、放射学学员和放射科医生对文本到CT扫描GenAI在医学教育、培训和实践中可以发挥的作用的看法。这种以人为本的方法还使我们能够发现生成合成医学图像的技术挑战和领域特定风险。最后，我们反思了医学文本到图像GenAI的影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [152] [An Age-based Study into Interactive Narrative Visualization Engagement](https://arxiv.org/abs/2507.12734)
> *基于年龄的互动叙事可视化参与度研究*

*Nina Errey, Yi Chen, Yu Dong, Quang Vinh Nguyen, Xiaoru Yuan, Tuck Wah Leong, Christy Jie Liang* | **Category: cs.HC, cs.GR** | **Updated: 2025-07-22**

**Keywords:** 互动叙事可视化, 用户参与度, 年龄研究, 数字媒体, 设计建议

**Comment:** 

> **TL;DR:** 研究发现，年龄较大的受众对互动叙事可视化的参与度低于年轻受众，这可能与术语理解有关；论文提出了针对不同年龄段受众的设计建议。

**AI_Comments:** 本研究关注了数字媒体用户体验中一个常被忽视的重要方面——年龄包容性。尽管发现的参与度差异可能不大，但论文提供了实用的设计建议，具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 数字媒体中受众的年龄会影响他们的参与度，而互动叙事可视化作为一种流行的数字媒体形式，其作者却经常忽视受众年龄因素。

**Method:** 本研究采用既定的可视化参与度问卷，进行了一项实证实验，比较了最终用户参与度与受众年龄之间的关系，并进行了定性分析。

**Result:** 研究发现参与度得分存在细微差异，年龄较大的群体比最年轻的群体参与度更低。定性分析显示，与老年群体相比，年轻群体对互动叙事可视化中集成的术语和整体叙事模式的理解更为明显。

**Conclusion:** 论文最后提出了一系列建议，指导互动叙事可视化作者如何根据受众年龄进行包容性设计。

> **ai_Abstract:** 本研究探讨了年龄对互动叙事可视化参与度的影响。通过实证实验和定性分析，结果显示年龄较大的受众在参与度和对叙事模式的理解上略低于年轻受众。论文最终为互动叙事可视化作者提供了针对不同年龄段受众的包容性设计建议。

> **摘要翻译:** 研究表明，受众的年龄会影响他们对数字媒体的参与度。互动叙事可视化作为一种日益流行的数字媒体形式，结合了数据可视化和讲故事来传达重要信息。然而，互动叙事可视化作者经常忽视受众年龄。我们使用一份既定的可视化参与度问卷，进行了一项实证实验，比较了最终用户参与度与受众年龄之间的关系。我们发现参与度得分存在细微差异，年龄较大的群体比最年轻的群体参与度更低。我们的定性分析显示，与老年群体相比，年轻群体在反馈中对互动叙事可视化中集成的术语和整体叙事模式的理解更为明显。本文最后提出了一系列建议，指导互动叙事可视化作者如何根据受众年龄进行包容性设计。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [156] [AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy](https://arxiv.org/abs/2507.16735)
> *用于个性化哮喘支持的AI增强型对话代理：参与度、价值和功效的因素*

*Laura Moradbakhti, Dorian Peters, Jennifer K. Quint, Björn Schuller, Darren Cook, Rafael A. Calvo* | **Category: cs.HC, cs.AI, cs.CY, cs.ET, K.4.2; J.3** | **Updated: 2025-07-22**

**Keywords:** 哮喘支持, 对话代理, 聊天机器人, 患者参与, 健康教育

**Comment:** 7 Tables, 4 Figures

> **TL;DR:** 一项针对1257名哮喘患者的调查显示，多数患者对使用聊天机器人进行哮喘管理感兴趣，尤其那些认为病情更严重或自我管理信心不足的患者。研究提出了7项优化聊天机器人健康支持的建议。

**AI_Comments:** 本研究通过大规模患者调查，深入分析了哮喘患者对AI聊天机器人进行健康管理的接受度及影响因素，具有重要的实践指导意义。其创新在于不仅关注技术可行性，更侧重于患者需求和偏好，为未来医疗聊天机器人的设计和部署提供了宝贵的经验。特别地，指出了安全隐私和技术怀疑是主要障碍，提醒开发者在技术进步的同时，需加强用户信任。

<details>
  <summary>Details</summary>

**Motivation:** 英国哮喘相关死亡率高，且只有30%的患者获得基本护理，需要替代方法为哮喘患者提供健康教育、自我管理支持和护理桥梁。自动化对话代理（如移动聊天机器人）提供了个性化健康支持的潜力，但患者是否会参与以及哪些因素影响参与度尚不明确。

**Method:** 通过哮喘临床医生、患者和技术开发者团队设计的一项患者调查（N=1257），旨在识别影响聊天机器人功效、价值和参与度的最佳因素。

**Result:** 53%的哮喘成年患者对使用聊天机器人感兴趣；最有可能使用者是那些认为哮喘更严重且自我管理信心不足的患者。患者对24/7访问、个性化以及WhatsApp作为首选访问方式表现出热情。主要障碍包括安全/隐私担忧和对技术能力的怀疑。

**Conclusion:** 研究结果被整合为7项针对开发者的建议，以优化基于聊天机器人的健康支持的功效。

> **ai_Abstract:** 本研究旨在探讨AI增强型对话代理（聊天机器人）在个性化哮喘支持中的参与度、价值和功效因素。通过对1257名哮喘患者的调查发现，超过半数患者对使用聊天机器人感兴趣，尤其那些病情较重或自我管理信心不足者。患者偏好24/7访问、个性化和WhatsApp作为访问方式，但对隐私和技术能力存在担忧。研究最终提出了7项优化聊天机器人健康支持的建议。

> **摘要翻译:** 英国的哮喘相关死亡率是欧洲最高的，只有30%的患者能获得基本护理。因此，需要替代方法来接触哮喘患者，以提供健康教育、自我管理支持和就医途径。自动化对话代理（特别是移动聊天机器人）为提供替代的、个性化的健康教育、自我管理支持和风险自我评估提供了机会。但患者会使用聊天机器人吗？哪些因素会影响参与度？我们展示了一项由哮喘临床医生、患者和技术开发者团队设计的患者调查（N=1257）结果，旨在确定聊天机器人功效、价值和参与度的最佳因素。结果表明，大多数哮喘成年患者（53%）对使用聊天机器人感兴趣，最有可能使用者是那些认为哮喘更严重且对自我管理信心不足的患者。结果还表明，患者对24/7访问、个性化以及WhatsApp作为首选访问方式（与应用程序、语音助手、短信或网站相比）表现出热情。使用障碍包括安全/隐私担忧和对技术能力的怀疑。我们展示了详细的发现，并将其整合为7项针对开发者的建议，以优化基于聊天机器人的健康支持的功效。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [191] [Animal Interaction with Autonomous Mobility Systems: Designing for Multi-Species Coexistence](https://arxiv.org/abs/2507.16258)
> *动物与自动驾驶系统的互动：为多物种共存而设计*

*Tram Thi Minh Tran, Xinyan Yu, Marius Hoggenmueller, Callum Paker, Paul Schmitt, Julie Stephany Berrio Perez, Stewart Worrall, Martin Tomitsch* | **Category: cs.HC** | **Updated: 2025-07-22**

**Keywords:** 自动驾驶系统, 动物互动, 多物种共存, 动物-计算机交互, 超人类设计

**Comment:** 

> **TL;DR:** 本研究探讨了动物与自动驾驶系统的互动，发现五个主要关注领域（物理影响、行为影响、可访问性、伦理法规、城市干扰），并提出了支持多物种共存的设计和政策方向。

**AI_Comments:** 这项研究通过关注自动驾驶系统与非人类物种的互动，填补了当前设计中普遍存在的空白。其多方法研究方法增强了发现的全面性，并为未来自动驾驶系统的设计和政策制定提供了重要的多物种共存视角，具有创新性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统越来越多地在与动物共享的环境中运行，但其设计主要关注人类互动，对非人类物种如何感知、响应或受其影响的理解有限。本研究受动物-计算机交互（ACI）和超人类设计研究的启发。

**Method:** 采用多方法方法，结合了范围审查（45篇文章）、在线民族志（39个YouTube视频和11个Reddit讨论）和专家访谈（8名参与者）。

**Result:** 分析揭示了五个主要关注领域：物理影响（例如，碰撞、未能检测）、行为影响（例如，回避、压力）、可访问性问题（特别是对于服务动物）、伦理和法规，以及城市干扰。

**Conclusion:** 提出了旨在支持自动驾驶时代多物种共存的设计和政策方向。强调了纳入非人类视角的重要性，以确保所有物种更安全、更具包容性的未来。

> **ai_Abstract:** 本研究探讨了动物与自动驾驶系统的互动，指出当前设计主要关注人类，而忽略了非人类物种。通过范围审查、在线民族志和专家访谈的多方法研究，识别出物理影响、行为影响、可访问性、伦理法规和城市干扰五个关键问题。研究呼吁在自动驾驶系统设计中融入非人类视角，以促进多物种共存并构建更安全、包容的未来。

> **摘要翻译:** 自动驾驶系统越来越多地在与动物（从城市宠物到野生动物）共享的环境中运行。然而，它们的设计主要侧重于人类互动，对非人类物种如何感知、响应或受这些系统影响的理解有限。受动物-计算机交互（ACI）和超人类设计研究的启发，本研究通过结合范围审查（45篇文章）、在线民族志（39个YouTube视频和11个Reddit讨论）和专家访谈（8名参与者）的多方法方法，调查了动物与自动驾驶系统的互动。我们的分析揭示了五个主要关注领域：物理影响（例如，碰撞、未能检测）、行为影响（例如，回避、压力）、可访问性问题（特别是对于服务动物）、伦理和法规，以及城市干扰。我们以旨在支持自动驾驶时代多物种共存的设计和政策方向作为结论。这项工作强调了纳入非人类视角的重要性，以确保所有物种更安全、更具包容性的未来。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [197] [Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance](https://arxiv.org/abs/2507.15783)
> *浪漫、慰藉与悔恨：青少年对聊天机器人过度依赖的叙述*

*Mohammad 'Matt' Namvarpour, Brandon Brofsky, Jessica Medina, Mamtaj Akter, Afsaneh Razi* | **Category: cs.HC, cs.AI, cs.CY** | **Updated: 2025-07-22**

**Keywords:** 青少年, 聊天机器人, 过度依赖, 情感依赖, Character.AI

**Comment:** 

> **TL;DR:** 本研究分析了青少年在Character.AI上的Reddit帖子，发现他们对聊天机器人存在过度依赖，这会干扰现实生活并导致心理困扰，并提出了未来的设计建议。

**AI_Comments:** 这项研究的重要性在于填补了青少年与可定制化聊天机器人互动研究的空白，揭示了这一群体过度依赖的深层模式和心理影响。其创新之处在于通过分析Reddit帖子提供了真实的青少年叙述，并基于这些洞察提出了实用的设计建议，为未来开发更安全的数字工具提供了方向。研究结果对青少年心理健康和数字福祉具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI驱动的聊天机器人（如Character.AI）融入青少年生活，引起了对情感依赖和数字过度依赖的担忧。现有研究调查了成年人对聊天机器人的过度依赖，但尚未调查青少年与可定制化角色聊天机器人的互动。

**Method:** 研究分析了318个来自Character.AI subreddit上自报年龄为13-17岁用户的Reddit帖子，以理解过度依赖的模式。

**Result:** 青少年普遍出于情感支持或创意表达开始使用聊天机器人，但许多人形成了强烈的依恋，干扰了线下关系和日常生活。他们的帖子揭示了心理困扰、复发周期和难以脱离的反复迹象。青少年报告称，他们的过度依赖通常在反思危害、回归现实社交环境或对平台限制感到沮丧时结束。

**Conclusion:** 基于研究发现的启示，本研究为未来的聊天机器人设计提供了建议，以促进自我意识、支持现实世界参与并让青少年参与开发更安全的数字工具。

> **ai_Abstract:** 本研究调查了青少年对生成式AI聊天机器人（如Character.AI）的过度依赖。通过分析318篇Reddit帖子，研究发现青少年最初使用聊天机器人是为了情感支持或创意表达，但许多人形成了强烈的依恋，导致心理困扰并干扰了现实生活。过度依赖通常在青少年反思其危害、回归现实社交或对平台限制感到沮丧时结束。研究基于这些发现，为未来的聊天机器人设计提供了促进自我意识和现实世界参与的建议。

> **摘要翻译:** 随着生成式人工智能（GenAI）驱动的聊天机器人（如Character.AI）融入青少年生活，它们引发了对情感依赖和数字过度依赖的担忧。虽然已有研究调查了成年人对这些聊天机器人的过度依赖，但尚未调查青少年与可定制化角色聊天机器人的互动。我们分析了Character.AI subreddit上318篇由自报年龄为13-17岁的用户发布的Reddit帖子，以了解过度依赖的模式。我们发现青少年通常开始使用聊天机器人是为了情感支持或创意表达，但许多人形成了强烈的依恋，干扰了线下关系和日常生活。他们的帖子揭示了心理困扰、复发周期和难以脱离的反复迹象。青少年报告称，他们的过度依赖通常在反思危害、回归现实社交环境或对平台限制感到沮丧时结束。基于我们发现的启示，我们为未来的聊天机器人设计提供了建议，以便它们能够促进自我意识，支持现实世界参与，并让青少年参与开发更安全的数字工具。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [236] [SceneLoom: Communicating Data with Scene Context](https://arxiv.org/abs/2507.16466)
> *SceneLoom：用场景上下文传达数据*

*Lin Gao, Leixian Shen, Yuheng Zhao, Jiexiang Lan, Huamin Qu, Siming Chen* | **Category: cs.HC** | **Updated: 2025-07-22**

**Keywords:** 数据可视化, 场景上下文, 视觉-语言模型, 叙事表达, 设计协调

**Comment:** 

> **TL;DR:** SceneLoom是一个由视觉-语言模型（VLM）驱动的系统，旨在解决数据可视化与真实世界图像分离的问题，通过协调二者来增强叙事表达和参与度。

**AI_Comments:** SceneLoom的创新之处在于利用了视觉-语言模型（VLM）来自动化和优化数据可视化与真实世界图像的协调过程，从而克服了传统手动对齐的挑战。它通过提供多种设计方案和交互式调整功能，显著提升了数据叙事的表达力和参与度。该系统对于数据新闻、数据视频等领域具有重要意义，因为它能够帮助创作者更高效地生成具有视觉吸引力和语义连贯性的内容。

<details>
  <summary>Details</summary>

**Motivation:** 在数据驱动的故事讲述（如数据新闻和数据视频）中，数据可视化常与真实世界图像并列呈现以支持叙事上下文，但两者通常是分离的，这限制了它们的组合叙事表达和参与度。实现精细对齐和创意构思具有挑战性。

**Method:** 本文提出了SceneLoom，一个由VLM驱动的系统，它根据叙事意图促进数据可视化与真实世界图像的协调。通过一项形成性研究，探讨了数据可视化与真实场景之间协调关系的设计空间。SceneLoom利用VLM从场景图像和数据可视化中提取视觉和语义特征，并通过包含空间组织、形状相似性、布局一致性和语义绑定的推理过程执行设计映射。

**Result:** SceneLoom系统生成了一系列具有语境表达性、图像驱动的设计方案，这些方案在视觉、语义和数据维度上实现了连贯的对齐。用户可以探索这些方案，选择首选映射，并通过交互式调整和动画过渡进一步完善设计。一项用户研究和示例画廊验证了SceneLoom在激发创意设计和促进设计外化方面的有效性。

**Conclusion:** SceneLoom有效解决了数据可视化与真实世界图像协调的挑战，通过VLM实现了视觉、语义和数据维度的连贯对齐，并被验证能够激发创意设计和促进设计外化。

> **ai_Abstract:** SceneLoom是一个由视觉-语言模型（VLM）驱动的系统，旨在解决数据可视化与真实世界图像分离的问题，通过促进二者的协调来增强叙事表达和参与度。该系统利用VLM提取视觉和语义特征，并通过推理过程实现精细的设计映射，生成在视觉、语义和数据维度上连贯对齐的多种设计方案。用户可以交互式地探索和优化这些方案。用户研究验证了其在激发创意和促进设计外化方面的有效性。

> **摘要翻译:** 在数据驱动的故事讲述语境中，例如数据新闻和数据视频，数据可视化通常与真实世界的图像一起呈现，以支持叙事上下文。然而，这些可视化和上下文图像通常保持分离，限制了它们组合的叙事表达性和参与度。由于需要精细对齐和创意构思，实现这一点具有挑战性。为了解决这个问题，我们提出了SceneLoom，一个由视觉-语言模型（VLM）驱动的系统，它根据叙事意图促进数据可视化与真实世界图像的协调。通过一项形成性研究，我们从视觉对齐和语义连贯性的角度，调查了数据可视化与真实世界场景之间协调关系的设计空间。受所推导的设计考量指导，SceneLoom利用VLM从场景图像和数据可视化中提取视觉和语义特征，并通过包含空间组织、形状相似性、布局一致性和语义绑定的推理过程执行设计映射。该系统生成了一系列具有语境表达性、图像驱动的设计方案，这些方案在视觉、语义和数据维度上实现了连贯的对齐。用户可以探索这些方案，选择首选映射，并通过交互式调整和动画过渡进一步完善设计，以支持富有表现力的数据通信。一项用户研究和示例画廊验证了SceneLoom在激发创意设计和促进设计外化方面的有效性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [281] [The Effect of Scale Consistency between Real and Virtual Spaces on Immersion in Exhibition Hybrid Spaces](https://arxiv.org/abs/2507.16542)
> *展览混合空间中真实与虚拟空间尺度一致性对沉浸感的影响*

*Qiong Wu, Yan Dong, Zipeng Zhang, Ruochen Hu* | **Category: cs.HC** | **Updated: 2025-07-22**

**Keywords:** 展览混合空间, 沉浸感, 尺度一致性, 虚拟化身, 虚拟空间

**Comment:** 23 pages, 6 figures, submitted to Virtual Reality (Springer)

> **TL;DR:** 本研究探讨了展览混合空间中虚拟空间和虚拟化身尺度对用户沉浸感的影响，发现略大的虚拟空间和略小的虚拟化身能优化沉浸感。

**AI_Comments:** 这项研究通过实验量化了虚拟空间和虚拟化身尺寸对用户沉浸感的影响，填补了该领域的系统研究空白。其创新之处在于使用了Intel 3D Athlete Tracking技术构建系统，并提供了具体的优化比例（130%的虚拟空间，75%-100%的虚拟化身），具有很强的实践指导意义，尤其是在展览和混合现实应用设计方面。

<details>
  <summary>Details</summary>

**Motivation:** 在展览混合空间中，真实与虚拟空间间的尺度一致性对用户沉浸感至关重要，但目前缺乏系统研究来确定合适的虚拟-真实映射比例。

**Method:** 本研究开发了一个基于Intel 3D Athlete Tracking身体映射技术的沉浸式交互系统。通过两项实验进行研究：实验1调查了30名参与者对虚拟空间尺度的偏好；实验2测试了6种不同虚拟化身尺寸（25%-150%）对沉浸感的影响。使用5点李克特量表评估沉浸感，并进行方差分析和Tukey HSD事后检验。

**Result:** 实验1显示参与者偏好130%的虚拟空间比例。实验2发现75%-100%范围内的虚拟化身尺寸产生最佳沉浸感，偏离用户实际身高时沉浸感显著下降。参与者对25%-75%范围内的尺寸变化更敏感，而对75%-100%范围内的感知较弱。

**Conclusion:** 略大于真实空间的虚拟环境（130%）和略小于用户的虚拟化身（75%-100%）能优化用户沉浸感。这些发现已应用于Intel全球贸易中心展厅，为设计增强沉浸感和连贯性的混合空间提供了可操作的见解。

> **ai_Abstract:** 本研究旨在解决展览混合空间中虚拟与真实空间尺度一致性对用户沉浸感影响的研究空白。通过开发一个基于Intel 3D Athlete Tracking的沉浸式交互系统，作者进行了两项实验。实验结果表明，参与者偏好略大于真实空间的虚拟环境（130%），且75%-100%范围内的虚拟化身尺寸能带来最佳沉浸感。这些发现为设计高沉浸度的混合空间提供了具体指导，并已在实际应用中得到验证。

> **摘要翻译:** 在展览混合空间中，真实与虚拟空间之间的尺度一致性对于用户沉浸感至关重要。然而，目前缺乏系统研究来确定合适的虚拟-真实映射比例。本研究开发了一个基于英特尔3D运动员跟踪身体映射技术的沉浸式交互系统。两项实验调查了虚拟空间和虚拟化身尺度对沉浸感的影响。实验1调查了30名参与者对虚拟空间尺度的偏好，而实验2测试了6种不同虚拟化身尺寸（25%-150%）对沉浸感的影响。使用5点李克特量表评估沉浸感，随后进行方差分析和Tukey HSD事后检验。实验1结果显示，参与者偏好130%的虚拟空间比例（平均127.29%，标准差8.55%）。实验2发现，75%-100%范围内的虚拟化身尺寸产生了最佳沉浸感（p < 0.05）。当虚拟化身尺寸偏离用户实际身高（低于50%或高于125%）时，沉浸感显著下降。参与者对25%-75%范围内的尺寸变化更为敏感，而对75%-100%范围内的变化感知较弱。略大于真实空间的虚拟环境（130%）和略小于用户的虚拟化身（75%-100%）能优化用户沉浸感。这些发现已应用于英特尔全球贸易中心展厅，为设计增强沉浸感和连贯性的混合空间提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [321] [Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)](https://arxiv.org/abs/2507.16562)
> *评估扩展现实（XR）代理技术的社会接受度：一项用户研究（扩展版）*

*Megha Quamara, Viktor Schmuck, Cristina Iani, Axel Primavesi, Alexander Plaum, Luca Vigano* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 扩展现实 (XR), 社会接受度, 代理技术, 用户研究, 记者培训

**Comment:** 26 pages (18 pages main body, 8 pages user consent form), 3 figures,
  7 tables

> **TL;DR:** 本研究评估了记者在数字远程设置中使用的基于网络的XR代理培训系统的社会接受度，发现用户对XR代理解决方案的看法和接受度，并确定了改进领域。

**AI_Comments:** 这项研究的创新之处在于其专注于XR代理技术的社会接受度，并将其应用于记者培训这一特定且重要的领域，尤其是在无需专业硬件的情况下。通过扩展Almere模型并结合真实世界的用户研究，该研究为XR系统的实际应用和改进提供了宝贵的见解，强调了用户感知和接受度的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估扩展现实（XR）代理技术的社会接受度，特别是一个为记者开发的远程可访问的、基于网络的XR培训系统，该系统旨在为记者提供敏感或危险场景的定制培训。

**Method:** 本研究进行了一项用户研究，使用了一个远程可访问的、基于网络的XR培训系统，该系统包含一个虚拟头像。研究改编并扩展了Almere模型，纳入了感知易用性、感知有用性、可靠性和安全性等属性。通过在真实世界环境中进行的受控实验，收集了用户感知的定量和定性数据（问卷调查）。

**Result:** 研究结果基于定量和定性测量，有助于理解特定社会背景下用户对XR代理解决方案的感知和接受度，并确定了XR系统的改进领域。

**Conclusion:** 本研究的发现有助于理解用户对XR代理解决方案的感知和接受度，并为XR系统的改进提供了方向。

> **ai_Abstract:** 本研究评估了扩展现实（XR）代理技术，特别是为记者在数字远程环境中进行敏感或危险场景培训而设计的基于网络的XR培训系统的社会接受度。研究通过用户与虚拟头像的交互，改编并扩展了Almere模型来衡量社会接受度，并在一项真实世界的受控实验中收集了用户的定量和定性感知数据。结果揭示了用户对XR代理解决方案的看法和接受度，并指出了XR系统未来改进的方向。

> **摘要翻译:** 本文介绍了评估扩展现实（XR）代理技术社会接受度的用户研究结果，重点关注一个为记者开发的远程可访问的、基于网络的XR培训系统。该系统涉及用户与一个虚拟头像的交互，由模块化工具包实现。这些交互旨在为记者在数字远程环境中提供量身定制的培训，特别是在敏感或危险场景中，而无需专门的终端用户设备，如头戴式显示器。我们的研究改编并扩展了Almere模型，通过现有属性如感知易用性和感知有用性以及新增属性如用户代理交互中的可靠性和安全性来表示社会接受度。XR代理在真实世界环境中的受控实验中进行了测试，并收集了用户感知数据。我们的发现基于涉及问卷调查的定量和定性测量，有助于理解特定社会背景下用户对XR代理解决方案的感知和接受度，同时还确定了XR系统的改进领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [372] [Animated Transition between Node-Link and Parallel Coordinates Visualizations](https://arxiv.org/abs/2507.16563)
> *节点链接图与平行坐标图可视化之间的动画过渡*

*Abdulhaq Adetunji Salako, Hannes Hagen, Christian Tominski* | **Category: cs.HC** | **Updated: 2025-07-22**

**Keywords:** 节点链接图, 平行坐标图, 动画过渡, 数据可视化, 多变量属性

**Comment:** 

> **TL;DR:** 本文研究了节点链接图和平行坐标图之间平滑动画过渡的设计与实现，旨在弥合不同多维数据视图之间的差距，并评估了两种过渡变体的用户偏好。

**AI_Comments:** 该论文的创新点在于首次系统地研究了节点链接图与平行坐标图这两种截然不同但又互补的可视化类型之间的动画过渡。它通过定义设计目标（可追溯性和速度）和设计空间，为构建有效的跨视图动画提供了理论指导。初步研究结果揭示了速度和可追溯性之间的权衡，为未来设计此类过渡提供了宝贵的见解。然而，研究规模较小（七名参与者），且是定性研究，未来需要更大规模的定量研究来验证这些发现。

<details>
  <summary>Details</summary>

**Motivation:** 多方面数据可视化通常涉及多个专用视图，用户需要心智整合不同视图的信息。视图之间的上下文切换阻碍了这种整合。虽然动画过渡已被证明能帮助调解上下文切换并提高理解，但大多数现有动画过渡仅考虑显示相同数据方面的基本视图。本文旨在解决节点链接图（显示图结构）和平行坐标图（显示多变量属性）之间通过平滑动画过渡缩小差距的问题。

**Method:** 本研究探讨了如何通过平滑动画过渡来弥合节点链接图和平行坐标图之间的差距。基于可追溯性（traceability）和速度（swiftness）两个设计目标，作者概述了一个部分设计空间，并提出了几种设计选项。在此基础上，他们实现了两种替代的过渡变体：一种是采用简单插值的基本变体，另一种是利用设计空间和包括分段与错位等动画技术的先进变体。通过一项初步的定性研究，他们收集了七名参与者的反馈。

**Result:** 在初步研究中，作者发现参与者更喜欢基本变体的速度（swiftness），而较慢的先进变体在数据项的可追溯性（traceability）方面表现更好。

**Conclusion:** 在节点链接图和平行坐标图之间进行动画过渡时，速度和数据项可追溯性之间存在权衡：基本变体速度快但可追溯性差，而先进变体可追溯性好但速度慢。

> **ai_Abstract:** 本文研究了节点链接图和平行坐标图之间平滑动画过渡的设计。针对多方面数据可视化中不同视图间信息整合的挑战，作者提出了基于可追溯性和速度的设计目标，并开发了两种过渡变体：一种基于简单插值的基本变体和一种结合了先进动画技术的变体。初步用户研究表明，基本变体在速度上更受青睐，而先进变体在数据项的可追溯性方面表现更优，揭示了在不同可视化类型间进行动画过渡时速度与可追溯性之间的权衡。

> **摘要翻译:** 多方面数据可视化通常涉及多个专用视图。为了全面理解数据，用户必须心智整合来自不同视图的信息。这种整合受到视图之间上下文切换的阻碍，并且通常需要诸如刷选和链接之类的交互式方法。动画过渡也被证明能够调解上下文切换并改善理解。然而，大多数现有动画过渡仅考虑显示相同数据方面的基本视图。在这项工作中，我们研究了如何通过平滑动画过渡来缩小显示图结构的节点链接图与显示多变量属性的平行坐标图之间的差距。基于两个设计目标（可追溯性和速度），我们概述了一个部分设计空间，其中包括几个设计选项。这些为两种替代过渡变体的实现提供了依据：一种是采用简单插值的基本变体，另一种是利用我们的设计空间和公认的动画技术（包括分段和错位）的先进变体。在一项初步研究中，我们向七名参与者征求了定性反馈。我们发现基本变体的速度更受偏爱，而较慢的先进变体在数据项的可追溯性方面表现更好。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [426] [AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review](https://arxiv.org/abs/2507.16586)
> *人工智能改善计算机辅助工程中的用户体验：学术界是否正在迎头赶上行业需求？一项多声部文献综述*

*Choro Ulan Uulu, Mikhail Kulyabin, Layan Etaiwi, Nuno Miguel Martins Pacheco, Jan Joosten, Kerstin Röse, Filippos Petridis, Jan Bosch, Helena Holmström Olsson* | **Category: cs.HC, cs.AI, cs.SE** | **Updated: 2025-07-22**

**Keywords:** 计算机辅助工程, 用户体验, 人工智能, 多声部文献综述, 差距分析

**Comment:** 

> **TL;DR:** 本文通过多声部文献综述，揭示了人工智能在改善计算机辅助工程（CAE）用户体验方面，学术界研究与行业实际应用之间存在显著差距，并指出了未来的研究方向。

**AI_Comments:** 这篇论文通过多声部文献综述，清晰地揭示了人工智能在计算机辅助工程（CAE）用户体验（UX）领域，学术研究与工业实践之间存在的显著脱节。其创新之处在于不仅识别了差距，还具体指出了工业界已采用而学术界未充分探索的AI应用方向（如LLMs、自适应UI）。这对于指导未来研究方向具有重要意义，促使学术界将更多注意力转向用户体验验证和实际应用需求，从而更好地服务于行业发展。

<details>
  <summary>Details</summary>

**Motivation:** 计算机辅助工程（CAE）在用户体验（UX）方面面临挑战，限制了效率和可访问性。尽管人工智能（AI）有潜力增强CAE流程，但专注于UX的AI与CAE整合研究仍 fragmented。因此，需要系统地审视AI如何提升CAE软件的UX，并对比学术界和工业界的进展。

**Method:** 本文采用多声部文献综述（MLR）的方法，考察了人工智能如何在学术研究和工业实践中增强计算机辅助工程（CAE）软件的用户体验（UX）。

**Result:** 分析揭示了学术探索与行业应用之间存在显著差距：公司积极实施大型语言模型（LLMs）、自适应用户界面（UIs）和推荐系统，而学术研究主要关注技术能力，缺乏用户体验验证。主要发现表明，AI驱动的指导、自适应界面和工作流自动化方面存在机会，但在当前研究中尚未得到充分探索。

**Conclusion:** 本研究通过描绘这些领域的交叉点，为未来的工作奠定了基础，以解决已识别的研究差距，并推进人工智能的整合，从而改善计算机辅助工程的用户体验。

> **ai_Abstract:** 本文采用多声部文献综述方法，旨在探究人工智能（AI）如何提升计算机辅助工程（CAE）的用户体验（UX），并对比学术研究与行业实践。研究发现，学术界与工业界在AI应用方向上存在显著差异，工业界已广泛采用LLMs、自适应UI和推荐系统，而学术研究则更侧重技术能力而非UX验证。论文指出了AI驱动的指导、自适应界面和工作流自动化等未充分探索的研究方向，为未来弥合研究差距、促进AI与CAE UX整合提供了基础。

> **摘要翻译:** 计算机辅助工程（CAE）使仿真专家能够优化复杂模型，但面临用户体验（UX）方面的挑战，这限制了效率和可访问性。尽管人工智能（AI）已显示出增强CAE流程的潜力，但专注于UX的这些领域的整合研究仍然分散。本文提出了一项多声部文献综述（MLR），考察了人工智能如何同时在学术研究和行业实施中增强CAE软件的用户体验。我们的分析揭示了学术探索与行业应用之间存在显著差距，公司积极实施大型语言模型（LLMs）、自适应用户界面（UIs）和推荐系统，而学术研究主要关注技术能力，缺乏用户体验验证。主要发现表明，人工智能驱动的指导、自适应界面和工作流自动化方面存在机会，但在当前研究中仍未得到充分探索。通过描绘这些领域的交叉点，本研究为未来的工作奠定了基础，以解决已识别的研究差距，并推进人工智能的整合，从而改善CAE用户体验。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [659] [Implications of Current Litigation on the Design of AI Systems for Healthcare Delivery](https://arxiv.org/abs/2507.15981)
> *当前诉讼对医疗保健领域AI系统设计的影响*

*Gennie Mansi, Mark Riedl* | **Category: cs.HC** | **Updated: 2025-07-21**

**Keywords:** AI问责制, 可解释AI (XAI), 医疗保健, 法律诉讼, 患者追索

**Comment:** 15 pages, 8 Figures

> **TL;DR:** 本研究分析了31个法律案例，发现当前医疗AI系统对患者造成损害，患者只能寻求法律追索。文章提出将问责制从以医生为中心转向以患者为中心，并通过改变责任结构和设计支持法律倡导者的可解释AI系统来预防和应对损害。

**AI_Comments:** 这篇论文的创新点在于将AI问责制的视角从传统的以医生为中心扩展到以患者为中心，并强调了法律和多方利益相关者在AI损害预防和补救中的作用。它不仅指出了现有XAI研究的不足，还提出了具体的解决方案，即通过改变责任结构和设计支持法律倡导者的XAI系统，为医疗AI的伦理和法律治理提供了新的思路，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多对医疗领域可解释AI（XAI）系统的呼吁都与对AI问责制的渴望相关，即解释、减轻并最终预防AI系统造成的损害。虽然XAI系统常被视为预防患者受损的主要途径，但当损害发生时，法律和政策也通过影响受损个体获得补救的方式来塑造AI问责制。目前XAI方法关注医生的医疗和人际需求以应对患者损害，但仍需理解XAI系统如何考虑受影响者的法律因素。

**Method:** 我们对31个法律案例和已报告的损害进行了分析，以识别AI系统如何影响患者护理的模式。

**Result:** 我们的发现反映了患者的医疗护理依赖于一个复杂的利益相关者网络——医生、州卫生部门、健康保险公司、护理机构等——以及部署在医疗保健交付中的许多AI系统对他们的护理产生了负面影响。因此，患者别无选择，只能寻求法律追索。

**Conclusion:** 我们通过描述律师和技术人员需要认识并解决AI损害发生的地方，将框架从以医生为中心的问责制方法转向以患者为中心。我们提出了预防或应对损害的途径：（1）通过改变责任结构以反映许多利益相关者在塑造AI系统如何影响患者护理方面的作用；（2）通过设计可帮助倡导者（例如提供关键法律专业知识并实际支持患者追索的法律代表）的XAI系统。

> **ai_Abstract:** 本研究探讨了当前诉讼对医疗AI系统设计的影响，特别是与AI问责制和可解释AI（XAI）相关的法律考量。通过分析31个法律案例，研究发现医疗AI系统在多方利益相关者环境中对患者护理造成损害，导致患者寻求法律追索。论文提出将AI问责制从以医生为中心转向以患者为中心，并提出两种预防损害的途径：一是调整责任结构以反映多方利益相关者的作用，二是设计能够支持法律代表等倡导者的XAI系统，以帮助患者获得法律补救。

> **摘要翻译:** 许多对医疗领域可解释AI（XAI）系统的呼吁都与对AI问责制的渴望相关——即解释、减轻并最终预防AI系统造成的损害。因为XAI系统为其输出提供人类可理解的解释，它们通常被视为预防患者受损的主要途径。然而，当损害发生时，法律、政策和法规也通过影响受损个体如何获得补救来塑造AI问责制。当前对XAI的研究探索了医生的医疗和人际需求，以应对患者损害，但仍需理解XAI系统应如何考虑受影响者的法律因素。我们对31个法律案例和已报告的损害进行了分析，以识别AI系统如何影响患者护理的模式。我们的发现反映了患者的医疗护理依赖于一个复杂的利益相关者网络——医生、州卫生部门、健康保险公司、护理机构等——以及部署在医疗保健交付中的许多AI系统对他们的护理产生了负面影响。因此，患者别无选择，只能寻求法律追索。我们通过描述律师和技术人员需要认识并解决AI损害发生的地方，将框架从以医生为中心的问责制方法转向以患者为中心。我们提出了预防或应对损害的途径：（1）通过改变责任结构以反映许多利益相关者在塑造AI系统如何影响患者护理方面的作用；（2）通过设计可帮助倡导者（例如提供关键法律专业知识并实际支持患者追索的法律代表）的XAI系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [660] [Using Generative Artificial Intelligence Creatively in the Classroom and Research: Examples and Lessons Learned](https://arxiv.org/abs/2409.05176)
> *在课堂和研究中创造性地使用生成式人工智能：示例与经验教训*

*Maria J. Molina, Amy McGovern, Jhayron S. Perez-Carrasquilla, Xiaowen Li, Robin L. Tanamachi* | **Category: cs.HC, physics.ao-ph** | **Updated: 2025-07-21**

**Keywords:** 生成式人工智能, 教育, 研究, 伦理, 课堂活动

**Comment:** This Work has been submitted to the Bulletin of the American
  Meteorological Society. Copyright in this Work may be transferred without
  further notice; 14 pages, 2 figures, 2 tables

> **TL;DR:** 本文探讨了在教育和研究中创造性使用生成式人工智能的潜力、挑战和伦理问题，并提供示例以促进讨论和指导负责任的使用。

**AI_Comments:** 这篇论文很有意义，它不仅指出了生成式AI在教育和研究中的应用潜力，更重要的是，它深入探讨了其伴随的伦理和公平性挑战，并呼吁教育界共同探讨解决方案。文章提供具体示例提示的做法，对读者具有实用指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI技术取得了突破性进展，但教育者和学生需要了解如何有效、负责任和道德地使用它。同时，目前解决生成式AI伦理问题的方案有限，因此有必要促进教育界就此展开讨论。

**Method:** 本文通过提供在教育和大气及相关科学领域中生成式AI的使用案例和示例用户提示来探讨其应用，并讨论了其伦理问题和简要的历史。

**Result:** 论文提供了生成式AI在课堂活动和研究中的应用示例，并指出了使用中的潜在陷阱、偏见、伦理（透明度、碳足迹）和公平性（付费版本、教育背景）问题。

**Conclusion:** 鉴于目前解决生成式AI伦理问题的方案有限，本文旨在促进教育界围绕共同目标和价值观展开讨论，以指导学生和教育者负责任地使用生成式AI。

> **ai_Abstract:** 本文探讨了生成式人工智能在课堂和研究中的创造性应用，强调了其在教育和专业发展中的重要性。文章详细阐述了生成式AI的用例，如开发课堂活动，并深入分析了其潜在风险，包括偏见、缺乏透明度、碳足迹以及公平性问题。作者旨在为学生和教育者提供指导，并提供示例提示。最终，论文呼吁教育界就生成式AI的负责任使用及其伦理挑战展开更广泛的讨论，以期达成共识并推动共同进步。

> **摘要翻译:** 尽管生成式人工智能（AI）并非新生事物，但近期技术突破已使其在众多领域的能力发生转变。这些变化要求教育工作者和大气及相关科学领域的专业培训给予新的关注。使学生能够有效、负责任和合乎道德地使用生成式AI，对其学业和职业发展至关重要。教育工作者也可以使用生成式AI开发引人入胜的课堂活动，例如主动学习模块和游戏；然而，他们必须意识到潜在的陷阱和偏见。使用缺乏透明度且碳足迹巨大的工具也存在伦理影响，同时对于缺乏更复杂付费版生成式AI工具访问权限和先前教育培训不足的学生也存在公平性问题。本文旨在为学生和教育工作者撰写，特别是那些有兴趣了解更多关于教育和研究中生成式AI的人，包括其用例、伦理问题以及其出现的简要历史。文章还提供了在教育、大气及相关科学领域众多应用中的示例用户提示。目前解决教育中生成式AI使用更广泛伦理问题的方案仍然有限；然而，这项工作旨在促进一场讨论，以激励教育界围绕共同目标和价值观团结起来。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [689] [Understanding the Impact of Physicians' Legal Considerations on XAI Systems](https://arxiv.org/abs/2507.15996)
> *理解医生法律考量对可解释人工智能系统的影响*

*Gennie Mansi, Mark Riedl* | **Category: cs.HC** | **Updated: 2025-07-21**

**Keywords:** 医生法律考量, 可解释人工智能, 医疗AI, 风险缓解, 人机交互

**Comment:** 10 pages, 4 figures

> **TL;DR:** 本研究通过访谈医生，探讨了医生在使用医疗AI系统时面临的法律顾虑，以及这些顾虑应如何指导可解释AI（XAI）系统的设计，强调XAI需提供情境化信息以支持风险缓解。

**AI_Comments:** 这篇论文通过访谈医生，从使用者角度深入探讨了AI在医疗应用中面临的实际法律和伦理挑战。其创新之处在于将医生的法律顾虑直接映射到XAI系统的设计需求上，为XAI的实际落地提供了宝贵的见解。研究强调了仅仅提供“解释”是不够的，还需要提供情境化信息和风险缓解指导，这对于推动负责任的AI发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医生对患者结果负有伦理、专业和法律责任，并担心医疗AI系统可能造成的伤害。现有研究虽探讨了法律顾虑对医疗决策的影响，但很少有工作探索如何根据这些顾虑设计XAI系统。

**Method:** 研究对10名医生进行了访谈，以了解他们预期的医疗AI系统可能出现的错误以及这些错误如何与他们的法律顾虑相关联。

**Result:** 医生预见了使用AI系统进行患者护理的风险，但对于新的技术系统将如何改变其法律风险缓解策略表示不确定。

**Conclusion:** XAI系统设计应考虑医生的法律顾虑，需要提供AI建议以及指导风险缓解策略的上下文信息，包括如何将医疗文档和审计请求等非法律相关方面纳入法律案件。

> **ai_Abstract:** 本研究探讨了医生在将医疗AI系统（特别是可解释AI，XAI）整合到工作流程中时面临的法律考量。通过对10名医生的访谈，研究发现医生预见到使用AI的风险，但对如何调整其法律风险缓解策略存在不确定性。研究强调，未来的XAI系统应在提供AI建议的同时，提供情境信息以支持医生的风险缓解策略，并考虑如何将医疗文档等非法律方面纳入潜在的法律情境。

> **摘要翻译:** 医生对患者的治疗结果负有伦理、专业和法律责任，并保护患者免受医疗AI系统有害决策的影响。许多人呼吁使用可解释人工智能（XAI）系统，以帮助医生将医疗AI建议纳入其工作流程，从而减少对患者的潜在伤害。虽然先前的研究已经证明医生的法律顾虑如何影响他们的医疗决策，但很少有研究探讨应如何根据这些顾虑设计XAI系统。在本研究中，我们对10名医生进行了访谈，以了解他们预期的医疗AI系统可能出现的错误以及这些预期错误如何与他们的法律顾虑相关联。在我们的研究中，医生预见了使用AI系统进行患者护理的风险，但对于新的技术系统将如何改变他们的法律风险缓解策略表示不确定。基于这些发现，我们描述了设计能够解决医生法律顾虑的XAI系统的含义。具体而言，我们认为需要提供AI建议以及指导其风险缓解策略的上下文信息，包括如何将系统中的非法律相关方面（如医疗文档和审计请求）纳入法律案件。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [696] [miMamba: EEG-based Emotion Recognition with Multi-scale Inverted Mamba Models](https://arxiv.org/abs/2409.07589)
> *miMamba: 基于多尺度倒置Mamba模型的脑电图情绪识别*

*Xin Zhou, Dawei Huang, Xiaojing Peng, Lijun Yin* | **Category: cs.HC, eess.SP** | **Updated: 2025-07-21**

**Keywords:** EEG情绪识别, Mamba模型, 多尺度特征, 时空特征, 脑机接口

**Comment:** IEEE Transactions on Affective Computing (2025)

> **TL;DR:** miMamba是一种新的深度学习模型，用于基于四通道脑电信号进行情绪识别，通过捕捉多尺度时空特征交互，在DEAP、DREAMER和SEED数据集上取得了超越现有方法的表现。

**AI_Comments:** 该论文的创新点在于提出了MS-iMamba模型，特别是其结合多尺度时间块和基于倒置Mamba结构的时空融合块，以端到端的方式处理EEG信号的时空特征交互，无需传统复杂的时频特征工程。其在仅使用少量通道EEG信号下达到SOTA性能，显示了其在实际应用中的巨大潜力，尤其是在简化数据预处理和提高识别效率方面。

<details>
  <summary>Details</summary>

**Motivation:** 脑电图（EEG）情绪识别在脑机接口领域具有巨大潜力，但挑战在于从EEG信号中提取判别性时空特征。现有研究常依赖领域特定的时频特征，并分别分析时间依赖性和空间特性，忽略了局部-全局关系与时空动态之间的交互。

**Method:** 我们提出了一个名为多尺度倒置Mamba（MS-iMamba）的新型网络，它由多尺度时间块（MSTB）和时空融合块（TSFB）组成。MSTB旨在捕获不同尺度子序列的局部细节和全局时间依赖性。TSFB采用倒置Mamba结构，专注于动态时间依赖性与空间特性之间的交互。MS-iMamba的优势在于利用重建的多尺度EEG序列，无需领域特定的时频特征提取即可利用时空特征之间的交互。

**Result:** 在DEAP、DREAMER和SEED数据集上的实验结果表明，MS-iMamba仅使用四通道EEG信号，就分别达到了94.86%、94.94%和91.36%的分类准确率，优于现有最先进的方法。

**Conclusion:** MS-iMamba模型通过有效捕捉多尺度时空特征的交互，在仅使用少量通道的脑电信号下，显著提升了情绪识别的准确性，证明了其在EEG情绪识别领域的优越性和潜力。

> **ai_Abstract:** 该研究提出了一种名为miMamba（Multi-Scale Inverted Mamba）的新型深度学习模型，用于基于脑电图（EEG）的情绪识别。针对现有方法在提取判别性时空特征和忽略局部-全局与时空动态交互的不足，miMamba设计了多尺度时间块（MSTB）以捕捉多尺度时间依赖性，并利用倒置Mamba结构的时空融合块（TSFB）处理时空特征交互。该模型无需领域特定的时频特征提取，仅使用四通道EEG信号，就在DEAP、DREAMER和SEED数据集上取得了94.86%、94.94%和91.36%的分类准确率，超越了现有最先进的方法。

> **摘要翻译:** 脑电图（EEG）情绪识别在脑机接口领域具有巨大潜力。一个关键挑战在于从脑电信号中提取判别性时空特征。现有研究通常依赖于领域特定的时频特征，并分别分析时间依赖性和空间特性，忽略了局部-全局关系与时空动态之间的交互。为了解决这个问题，我们提出了一种名为多尺度倒置Mamba（MS-iMamba）的新型网络，它由多尺度时间块（MSTB）和时空融合块（TSFB）组成。具体来说，MSTB旨在捕获不同尺度子序列的局部细节和全局时间依赖性。TSFB采用倒置Mamba结构，专注于动态时间依赖性与空间特性之间的交互。MS-iMamba的主要优势在于它能够利用重建的多尺度EEG序列，在无需领域特定时频特征提取的情况下，利用时间特征和空间特征之间的交互。在DEAP、DREAMER和SEED数据集上的实验结果表明，MS-iMamba仅使用四通道EEG信号，就分别达到了94.86%、94.94%和91.36%的分类准确率，优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [723] [AI, Expert or Peer? -- Examining the Impact of Perceived Feedback Source on Pre-Service Teachers Feedback Perception and Uptake](https://arxiv.org/abs/2507.16013)
> *AI，专家还是同伴？——考察感知反馈来源对职前教师反馈感知和采纳的影响*

*Lucas Jasper Jacobsen, Ute Mertens, Thorben Jansen, Kira Elena Weber* | **Category: cs.HC** | **Updated: 2025-07-21**

**Keywords:** 反馈感知, 反馈采纳, 大型语言模型, 职前教师, 来源偏见

**Comment:** 37 pages, 2 figures, 6 tables

> **TL;DR:** 职前教师对AI、专家或同伴反馈的感知和采纳程度不同，AI反馈在公平性和有用性上得分最高，但反馈质量是采纳的关键预测因素。

**AI_Comments:** 这项研究创新性地比较了不同反馈来源（AI、专家、同伴）对职前教师反馈感知和采纳的影响，特别揭示了AI反馈在某些方面的优势以及来源偏见的存在。其重要性在于为AI在教育反馈中的应用提供了实证依据，并指出了未来教师教育中需要关注的方向，即提升AI素养和解决潜在的偏见。

<details>
  <summary>Details</summary>

**Motivation:** 反馈在学习中起着核心作用，但职前教师的参与度受反馈内容和来源感知影响。大型语言模型（LLMs）正被用于提供教育反馈，但负面看法可能限制其应用。目前对职前教师感知和行为反应如何因反馈来源而异知之甚少。

**Method:** 本研究对273名职前教师进行了一项随机实验。参与者收到关于数学学习目标的书面反馈，并识别其来源（LLM、专家或同伴）。他们评估了五维度的反馈感知（公平性、有用性、接受度、改进意愿、积极和消极情感），并根据反馈修改了学习目标以衡量反馈采纳。

**Result:** LLM生成的反馈在公平性和有用性方面得分最高，并导致最高的采纳率（52%）。识别准确性显著调节了反馈来源对感知的影响，当LLM反馈被错误地归因于专家时，评价特别积极。高质量反馈被持续归因于专家，表明来源判断中存在专业启发式。回归分析显示，只有反馈质量显著预测了反馈采纳。

**Conclusion:** 研究结果强调需要解决与来源相关的偏见，并在教师教育中促进反馈和AI素养。

> **ai_Abstract:** 本研究探讨了职前教师对来自大型语言模型（LLM）、专家或同伴的反馈的感知和采纳情况。通过一项随机实验，发现LLM反馈在公平性和有用性上得分最高，并促使最高的采纳率。研究还揭示了识别准确性对感知的影响，以及反馈质量是预测采纳的唯一显著因素。研究强调了在教师教育中解决来源偏见和提升反馈与AI素养的重要性。

> **摘要翻译:** 反馈在学习中起着核心作用，然而职前教师对反馈的参与不仅取决于其质量，还取决于他们对反馈内容和来源的感知。大型语言模型（LLMs）正越来越多地被用于提供教育反馈；然而，负面看法可能会限制其实际应用，并且关于职前教师的感知和行为反应如何因反馈来源而异，目前知之甚少。本研究调查了反馈的感知来源——LLM、专家或同伴——如何影响反馈感知和采纳，以及识别准确性和反馈质量是否调节这些影响。在一项有273名职前教师参与的随机实验中，参与者收到了关于数学学习目标的书面反馈，识别了其来源，评估了五个维度的反馈感知（公平性、有用性、接受度、改进意愿、积极和消极情感），并根据反馈修改了学习目标（即反馈采纳）。结果显示，LLM生成的反馈在公平性和有用性方面得分最高，导致最高的采纳率（52%）。识别准确性显著调节了反馈来源对感知的影响，当LLM反馈被错误地归因于专家时，评价尤其积极。高质量的反馈被持续归因于专家，这表明在来源判断中存在一种专业启发式。回归分析显示，只有反馈质量显著预测了反馈采纳。研究结果强调需要解决与来源相关的偏见，并在教师教育中促进反馈和AI素养。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [738] [LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition](https://arxiv.org/abs/2410.09767)
> *LibEER：一个用于脑电图情绪识别的综合基准和算法库*

*Huan Liu, Shusen Yang, Yuzhe Zhang, Mengze Wang, Fanyu Gong, Chengxi Xie, Guanjian Liu, Zejun Liu, Yong-Jin Liu, Bao-Liang Lu, Dalin Zhang* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 脑电图情绪识别, 基准库, 算法库, 深度学习, 可复现性

**Comment:** 

> **TL;DR:** LibEER是一个用于脑电图情绪识别的综合基准和算法库，旨在解决模型间公平比较和可复现性挑战，并促进该领域标准化。

**AI_Comments:** LibEER的创新性在于它解决了脑电图情绪识别领域长期存在的标准化和可复现性问题。通过提供一个统一的基准和算法库，它极大地降低了研究人员进行公平模型比较和复现实验的难度。其重要性体现在它能促进该领域的研究进展，避免重复劳动，并为未来模型的开发和评估提供坚实的基础。这是对EER社区的一个重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 脑电图情绪识别（EER）领域缺乏令人信服的基准和全面的开源库，这使得模型间的公平比较复杂化，并给实践者带来了可复现性挑战，从而阻碍了该领域的进展。

**Method:** 作者推出了LibEER，一个综合性的基准和算法库。LibEER精心选择了流行且强大的基线模型，统一了关键的实现细节，并提供了一个基于PyTorch的标准化代码库。它提供了一个一致的评估框架和标准化的实验设置，对六个最广泛使用的数据集上的十七个代表性深度学习模型进行了无偏评估。此外，作者还对模型性能和效率进行了彻底、可复现的比较。

**Result:** LibEER实现了对十七个代表性深度学习模型在六个最广泛使用的数据集上的无偏评估。作者对模型性能和效率进行了彻底、可复现的比较，并提供了有价值的见解来指导研究人员选择和设计EER模型。他们还对实验结果进行了观察和深入分析，并指出了该社区当前面临的挑战。

**Conclusion:** LibEER旨在降低脑电图情绪识别领域新手的入门门槛，并有助于该领域研究的标准化，从而促进其稳定发展。

> **ai_Abstract:** 该论文介绍了LibEER，一个为脑电图情绪识别（EER）领域设计的综合性基准和算法库。鉴于现有EER研究中缺乏标准化的基准和开源库，LibEER旨在通过提供一个统一的PyTorch代码库、标准化实验设置和对流行深度学习模型在多个数据集上的系统评估来解决公平比较和可复现性问题。该工作对模型性能和效率进行了深入分析，旨在降低新研究者的入门门槛，并促进EER领域的标准化和稳定发展。

> **摘要翻译:** 基于脑电图（EEG）的情绪识别（EER）因其在理解和分析人类情绪方面的潜力而受到广泛关注。尽管深度学习技术的最新进展已大大改善了EER，但该领域仍缺乏令人信服的基准和全面的开源库。这种缺失使模型之间的公平比较变得复杂，并给实践者带来了可复现性挑战，这些共同阻碍了该领域的进展。为了解决这些问题，我们引入了LibEER，一个旨在促进EER公平比较的综合基准和算法库。LibEER精心选择了流行且强大的基线模型，统一了跨方法的关键实现细节，并提供了一个基于PyTorch的标准化代码库。通过提供一个具有标准化实验设置的一致评估框架，LibEER使得对六个最广泛使用的数据集上十七个代表性深度学习模型进行无偏评估成为可能。此外，我们对模型性能和效率进行了彻底、可复现的比较，为研究人员选择和设计EER模型提供了宝贵的见解。此外，我们还对实验结果进行了观察和深入分析，并指出了该社区当前面临的挑战。我们希望我们的工作不仅能降低脑电图情绪识别领域新手的入门门槛，还能促进该领域研究的标准化，从而促进稳定发展。该库和源代码可在https://github.com/XJTU-EEG/LibEER公开获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [11] [Quantum Annealing Hyperparameter Analysis for Optimal Sensor Placement in Production Environments](https://arxiv.org/abs/2507.16584)
> *生产环境中最佳传感器布局的量子退火超参数分析*

*Nico Kraus, Marvin Erdmann, Alexander Kuzmany, Daniel Porawski, Jonas Stein* | **Category: cs.ET** | **Updated: 2025-07-22**

**Keywords:** 量子退火, 传感器布局, 超参数优化, QUBO, 大规模优化

**Comment:** 

> **TL;DR:** 本研究探索了量子退火在汽车制造中优化传感器布局的应用，通过超参数优化和分解技术，证明了其解决大规模实际问题的潜力。

**AI_Comments:** 该论文的创新点在于将量子退火应用于实际的工业优化问题，特别是传感器布局。它不仅探索了量子计算的潜力，还强调了超参数优化和分解技术在将量子算法应用于大规模问题时的关键作用，为未来量子硬件的成熟铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 在汽车制造中，新生产的车辆自主移动需要最佳的传感器布局以实现全面覆盖并最小化传感器数量。这是一个大规模的计算挑战，传统的求解器依赖启发式方法，通常对大型实例产生非最优解，导致次优的传感器分布和运营成本增加。

**Method:** 本研究探索了量子计算方法，具体实现了D-Wave量子退火，将问题转化为二次无约束二元优化（QUBO）形式，采用独热编码和二进制编码。优化了惩罚项和退火时间等超参数，并与默认参数设置进行了比较。此外，还使用了分解技术来进一步扩展问题规模。

**Result:** 研究结果表明，量子退火能够解决源自真实场景的实例。通过使用分解技术，能够进一步扩展问题规模，使其更接近实际的工业应用。本工作提供了关于量子退火参数化重要性的关键见解。

**Conclusion:** 本研究的结论是，一旦硬件成熟，量子计算能够为高成本效益的大规模优化问题做出贡献，强调了量子退火参数化的重要性。

> **ai_Abstract:** 本研究探讨了利用量子退火解决汽车制造中大规模传感器最佳布局问题。针对传统方法效率低下的问题，作者将该问题转化为QUBO形式，并在D-Wave量子退火器上实现。通过优化超参数和应用分解技术，研究证明了量子退火能有效处理真实世界实例并扩展问题规模，突出了其在未来解决大规模、高成本效益优化问题中的潜力。

> **摘要翻译:** 为了提高汽车制造效率，新生产的车辆可以自主地从生产线移动到配送区域。这需要传感器的最佳布局，以确保全面覆盖同时最小化所使用的传感器数量。由于其大规模性质，底层的优化问题构成了计算挑战。目前，经典求解器依赖于启发式方法，通常对大型实例产生非最优解，导致次优的传感器分布和增加的运营成本。
我们探索了未来可能超越经典启发式方法的量子计算方法。我们使用D-Wave实现了量子退火，将问题转化为采用独热编码和二进制编码的二次无约束二元优化公式。优化了惩罚项和退火时间等超参数，并将结果与默认参数设置进行了比较。
我们的结果表明，量子退火能够解决源自真实场景的实例。通过使用分解技术，我们能够进一步扩展问题规模，使其更接近实际的工业适用性。通过这项工作，我们提供了关于量子退火参数化重要性的关键见解，展示了量子计算在硬件成熟后如何为高成本效益的大规模优化问题做出贡献。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [455] [AI-driven Orchestration at Scale: Estimating Service Metrics on National-Wide Testbeds](https://arxiv.org/abs/2507.16077)
> *AI驱动的大规模编排：在全国范围测试平台上估算服务指标*

*Rodrigo Moreira, Rafael Pasquini, Joberto S. B. Martins, Tereza C. Carvalho, Flávio de Oliveira Silva* | **Category: cs.ET, cs.AI, cs.LG, cs.MA, cs.NI** | **Updated: 2025-07-21**

**Keywords:** 网络切片, AI编排, 延迟预测, 深度神经网络, 大规模测试平台

**Comment:** 17 pages, 18 figures, 14 tables,

> **TL;DR:** 本文提出了一种在大规模生产测试平台上验证AI驱动网络切片编排的方法，通过使用深度神经网络和机器学习算法预测延迟，以解决在实际环境中验证AI编排的挑战。

**AI_Comments:** 该论文的创新之处在于其将AI驱动的网络切片编排验证从传统的实验室模拟或小规模测试提升到真实的大规模生产测试平台。这直接解决了AI在网络领域实际部署的关键挑战，为AI原生网络架构的落地提供了宝贵的实践经验和验证方法。其提出的生产就绪验证方法具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 网络切片（NS）的实现需要AI原生的编排架构来高效智能地处理异构用户需求。然而，这些使用机器学习（ML）的编排方案在生产环境中的验证面临挑战，因为它们通常在本地网络或实验室模拟中进行测试。

**Method:** 本文提出了一种大规模验证方法，使用网络切片预测模型，在真实的大规模生产测试平台上，利用深度神经网络（DNN）和基本机器学习算法预测延迟，这些算法嵌入在网络切片架构中。

**Result:** 研究测量并比较了不同DNN和ML算法的性能，考虑了一个部署为网络切片的分布式数据库应用程序，在两个大规模生产测试平台上进行评估。研究强调了基于AI的预测模型如何增强网络切片编排架构，并提出了一种无缝、生产就绪的验证方法，作为完全受控模拟或实验室设置的替代方案。

**Conclusion:** 基于AI的预测模型可以增强网络切片编排架构，并提供一种生产就绪的验证方法，作为传统模拟或实验室设置的有效替代。

> **ai_Abstract:** 本文提出了一种在大规模生产测试平台上验证AI驱动网络切片编排的方法，旨在解决在实际环境中验证ML使能编排的挑战。通过使用深度神经网络和基本机器学习算法预测网络切片中的延迟，并在两个大型生产测试台上进行评估，研究表明AI预测模型可以有效增强网络切片编排，并提供了一种实用的生产级验证手段。

> **摘要翻译:** 网络切片（NS）的实现需要AI原生的编排架构，以高效智能地处理异构用户需求。为实现此目标，网络切片正朝着更加以用户为中心的数字化转型方向发展，重点关注那些能够整合原生智能以实现集成和隔离的自管理连接的架构。然而，这些举措面临在生产环境中验证其结果的挑战，特别是那些使用机器学习（ML）使能的编排，因为它们通常在本地网络或实验室模拟中进行测试。本文提出了一种大规模验证方法，使用网络切片预测模型，利用深度神经网络（DNN）和嵌入在NS架构中的基本ML算法来预测延迟，并在真实的、大规模的生产测试平台上进行评估。它测量并比较了不同DNN和ML算法的性能，考虑了一个部署为网络切片的分布式数据库应用程序，该程序部署在两个大规模生产测试平台上。这项研究强调了基于AI的预测模型如何增强网络切片编排架构，并提出了一种无缝、生产就绪的验证方法，作为完全受控模拟或实验室设置的替代方案。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [729] [Prediction of Alpha-Particle-Immune Gate-All-Around Field-Effect Transistors (GAA-FET) Based SRAM Design](https://arxiv.org/abs/2507.15860)
> *基于全环栅场效应晶体管 (GAA-FET) 的抗α粒子辐射SRAM设计预测*

*Albert Lu, Reza Arghavani, Hiu Yung Wong* | **Category: cs.ET, physics.comp-ph** | **Updated: 2025-06-29**

**Keywords:** GAA-FET, SRAM, α粒子, 单粒子翻转, TCAD

**Comment:** 

> **TL;DR:** 本文展示了如何通过3D TCAD仿真设计出对α粒子辐射免疫的SRAM，即使在最坏情况下也不会发生单粒子翻转。

**AI_Comments:** 这项研究的创新之处在于结合了3D TCAD仿真和从头计算来预测并实现SRAM对α粒子辐射的免疫性，特别是在亚7nm技术节点下。这对于提高未来存储器在辐射环境下的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设计对α粒子辐射错误免疫的静态随机存取存储器（SRAM），以避免单粒子翻转（SEU）。

**Method:** 使用3D技术计算机辅助设计（TCAD）仿真，并结合PHITS中的从头计算（ab initio calculations）来确定α粒子在Si和Si_xGe_{1-x}中的最大线性能量转移（LETmax）。

**Result:** 研究表明，可以设计出对单个α粒子辐射错误免疫的SRAM。通过设计具有底部介质隔离（BDI）的亚7nm GAA-FET基SRAM，即使粒子撞击在最坏情况（LET > LETmax）下，SRAM也不会翻转。

**Conclusion:** 成功展示了基于GAA-FET的SRAM设计可以实现对α粒子辐射的完全免疫，有效防止单粒子翻转。

> **ai_Abstract:** 本文通过3D TCAD仿真和PHITS中的从头计算，研究了基于GAA-FET的SRAM设计，旨在实现对α粒子辐射诱导的单粒子翻转（SEU）的免疫。研究发现，通过确定α粒子的最大线性能量转移（LETmax），并结合底部介质隔离（BDI）技术，可以设计出亚7nm的GAA-FET基SRAM，使其即使在最坏的辐射条件下也能保持数据完整性，从而有效防止SEU。

> **摘要翻译:** 本文利用3D技术计算机辅助设计（TCAD）仿真，展示了可以设计出一种基于全环栅场效应晶体管（GAA-FET）技术的静态随机存取存储器（SRAM），使其对单个α粒子辐射错误具有免疫性。换句话说，通过这种设计，不会因α粒子引起单粒子翻转（SEU）。我们首先在PHITS中使用从头计算来表明，α粒子在Si和Si_xGe_{1-x}中存在一个最大线性能量转移（LET），即LETmax。在此基础上，通过设计具有底部介质隔离（BDI）的亚7nm GAA-FET基SRAM，我们表明即使粒子撞击在最坏情况（LET > LETmax）下，SRAM也不会翻转。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [2] [Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis](https://arxiv.org/abs/2507.16808)
> *通过时序逻辑变异重新思考基于LLM的RTL代码优化*

*Zhihao Xu, Bixin Li, Lulu Wang* | **Category: cs.SE, cs.AI, 68N19, 68T05, B.6.3; D.3.4; I.2.2; I.2.6** | **Updated: 2025-07-22**

**Keywords:** RTL代码优化, 大型语言模型, 时序逻辑, 变异, 数字电路设计

**Comment:** 13pages with 9 pictures and 2 tables

> **TL;DR:** 本文通过时序逻辑变异方法，全面评估了基于LLM的RTL代码优化能力，发现LLM在处理复杂时序逻辑时表现不佳，并提出了未来研究方向。

**AI_Comments:** 本文通过引入新的基准和变异评估方法，对LLM在RTL代码优化中的能力进行了深入的实证分析。其创新点在于关注LLM处理复杂时序逻辑的局限性，并明确指出了LLM在理解硬件时序特性方面的挑战。这对于未来LLM在硬件设计领域的应用具有重要的指导意义，提示研究者需要更关注如何提升LLM对时序逻辑的理解能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统RTL代码优化方法耗时且易错，而现有基于LLM的方法尚未充分评估其在处理复杂时序逻辑RTL代码时的有效性。

**Method:** 提出了一个新的RTL优化评估基准，包含四个子集；引入了一种基于变异的方法来系统评估基于LLM的RTL代码优化方法，其核心思想是优化效果对语义等价但更复杂的代码应保持一致。

**Result:** (1) 基于LLM的RTL优化方法能有效优化逻辑操作，并优于现有编译器方法。(2) 在处理复杂时序逻辑RTL代码（尤其在时序控制流和时钟域优化方面）时，基于LLM的方法表现不如现有编译器方法，这归因于LLM理解RTL中时序逻辑的挑战。

**Conclusion:** 基于研究发现，为未来利用LLM进行RTL代码优化的研究提供了见解。

> **ai_Abstract:** 本文重新审视了基于大型语言模型（LLM）的寄存器传输级（RTL）代码优化，旨在解决现有方法在处理复杂时序逻辑RTL代码时的评估空白。研究提出了一个新的RTL优化基准和一个基于变异的评估方法。实验结果表明，LLM在逻辑操作优化方面表现出色并优于传统编译器方法，但在处理复杂时序逻辑（如时序控制流和时钟域优化）时，其性能不如传统方法，主要原因是LLM难以理解RTL中的时序逻辑。研究为未来LLM在RTL优化中的应用提供了方向。

> **摘要翻译:** 寄存器传输级（RTL）代码优化对于数字电路设计中实现高性能和低功耗至关重要。然而，传统的优化方法通常依赖于手动调整和启发式，这可能耗时且容易出错。最近的研究提出利用大型语言模型（LLM）来辅助RTL代码优化。LLM可以根据自然语言描述生成优化的代码片段，可能加速优化过程。然而，现有方法尚未彻底评估基于LLM的代码优化方法在处理具有复杂时序逻辑的RTL代码时的有效性。为了弥补这一空白，我们进行了一项全面的实证研究，以评估基于LLM的RTL代码优化方法处理复杂时序逻辑RTL代码的能力。在本研究中，我们首先提出了一个新的RTL优化评估基准。它包含四个子集，每个子集对应RTL代码优化的一个特定领域。然后，我们引入了一种基于变异的方法来系统评估基于LLM的RTL代码优化方法。我们的关键见解是，对于语义等价但更复杂的代码，优化效果应保持一致。经过密集的实验，我们揭示了几个关键发现。(1) 基于LLM的RTL优化方法可以有效优化逻辑操作，并且优于现有基于编译器的方法。(2) 基于LLM的RTL优化方法在处理具有复杂时序逻辑的RTL代码时，表现不如现有基于编译器的方法，特别是在时序控制流优化和时钟域优化方面。这主要归因于LLM在理解RTL代码中时序逻辑方面面临的挑战。基于这些发现，我们为进一步利用LLM进行RTL代码优化的研究提供了见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [86] [AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?](https://arxiv.org/abs/2507.15887)
> *AlgoTune：语言模型能否加速通用数值程序？*

*Ori Press, Brandon Amos, Haoyu Zhao, Yikai Wu, Samuel K. Ainsworth, Dominik Krupke, Patrick Kidger, Touqir Sajed, Bartolomeo Stellato, Jisun Park, Nathanael Bosch, Eli Meril, Albert Steppi, Arman Zharmagambetov, Fangzhao Zhang, David Perez-Pineiro, Alberto Mercurio, Ni Zhan, Talor Abramovich, Kilian Lieret, Hanlin Zhang, Shirley Huang, Matthias Bethge, Ofir Press* | **Category: cs.SE, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-19**

**Keywords:** 语言模型, 算法优化, 数值程序, AlgoTune, 编程基准测试

**Comment:** 

> **TL;DR:** 本文提出了AlgoTune基准测试，用于评估语言模型设计和实现高效算法的能力。我们的基线模型AlgoTuner在数值程序上实现了平均1.72倍的加速，但未能发现算法创新。

**AI_Comments:** 这项研究通过引入AlgoTune基准测试，为评估语言模型在算法设计和优化方面的能力提供了一个新颖且重要的视角。其创新之处在于将语言模型的评估从“已解决问题”扩展到“开放式算法设计”。尽管AlgoTuner实现了显著的加速，但当前模型未能进行深层算法创新的发现是一个重要的局限性，指出了未来研究的方向。该基准和发现对于推动语言模型在科学计算和程序优化领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管语言模型能力有所进步，但目前的评估主要集中在人类已解决的任务上。因此，本文旨在测试语言模型在开放式基准测试中设计和实现算法的能力，以解决计算挑战性问题。

**Method:** 本文提出了AlgoTune基准测试，包含155个来自领域专家的编码任务，以及一个用于验证和计时语言模型生成代码的框架，并与流行开源包中的参考实现进行比较。此外，本文开发了一个基线语言模型代理AlgoTuner，并评估了其在多种前沿模型上的性能。

**Result:** AlgoTuner相对于参考求解器（如SciPy、sk-learn和CVXPY）实现了平均1.72倍的加速。然而，研究发现当前模型未能发现算法创新，而是倾向于表面优化。

**Conclusion:** 语言模型可以加速通用数值程序，但目前模型缺乏发现算法创新的能力。作者希望AlgoTune能促进语言模型代理在超越人类水平的创造性问题解决方面的发展。

> **ai_Abstract:** 本文提出了AlgoTune，一个旨在评估语言模型设计和实现高效数值算法能力的开放式基准测试。该基准包含155个编码任务，并提供验证和计时框架。研究人员开发了一个基线代理AlgoTuner，其在测试中实现了相对于参考求解器平均1.72倍的加速。然而，研究发现当前模型主要进行表面优化而非算法创新。作者希望AlgoTune能推动语言模型在创造性问题解决方面的进步。

> **摘要翻译:** 尽管语言模型（LM）能力取得了进展，但迄今为止的评估一直集中在模型在人类先前已解决的任务上的表现，包括编程（Jimenez 等，2024）和数学（Glazer 等，2024）。因此，我们建议在一个开放式基准测试中，测试模型设计和实现算法的能力：我们要求语言模型编写能够有效解决计算机科学、物理和数学领域计算挑战性问题的代码。我们的AlgoTune基准测试包含155个从领域专家收集的编码任务，以及一个用于验证和计时语言模型合成解决方案代码的框架，该代码与流行开源包中的参考实现进行比较。此外，我们开发了一个基线语言模型代理AlgoTuner，并评估了其在一系列前沿模型上的性能。AlgoTuner相对于我们的参考求解器（使用SciPy、sk-learn和CVXPY等库）实现了平均1.72倍的加速。然而，我们发现当前模型未能发现算法创新，而是倾向于表面优化。我们希望AlgoTune能够促进语言模型代理的发展，使其展现出超越最先进人类表现的创造性问题解决能力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [117] [Towards Understanding the Challenges of Bug Localization in Deep Learning Systems](https://arxiv.org/abs/2402.01021)
> *理解深度学习系统中的Bug定位挑战*

*Sigma Jahan, Mehil B. Shah, Mohammad Masudur Rahman* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** Bug定位, 深度学习系统, 实证研究, Bug类型, 外在性

**Comment:** Accepted in Empirical Software Engineering Journal in 2025

> **TL;DR:** 一项大规模实证研究发现，现有Bug定位技术在深度学习系统中表现显著不佳，因为深度学习Bug的类型和外部性带来了独特的挑战。

**AI_Comments:** 这项研究通过大规模实证数据，系统地揭示了深度学习系统Bug定位的复杂性，填补了现有研究的空白。其创新之处在于不仅量化了现有方法的不足，还深入分析了不同Bug类型和外在性对定位效果的影响，为未来深度学习系统调试工具的开发提供了宝贵的见解。该工作对于提升深度学习系统的可靠性和开发效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 软件Bug每年给全球经济造成数十亿美元损失，并占据软件开发人员约50%的编程时间。定位这些Bug对于解决它们至关重要，但在深度学习系统中更具挑战性，因为它们的黑盒性质以及Bug可能隐藏在代码、模型和训练数据中，导致传统调试方法效果不佳。

**Method:** 本文进行了一项大规模实证研究，以更好地理解深度学习系统中Bug定位的挑战。首先，使用来自深度学习系统的2,365个Bug和来自传统软件的2,913个Bug，评估了四种现有技术的Bug定位性能。其次，评估了深度学习系统中不同Bug类型如何影响Bug定位。第三，调查了Bug的外在性质对深度学习系统Bug定位的影响。

**Result:** 研究发现，现有技术在定位深度学习系统Bug方面表现显著不佳。Bug定位技术的有效性随Bug类型而异，例如，张量Bug由于其结构性质更容易定位，而所有技术都难以定位GPU Bug，因为它们依赖外部。研究还发现，深度学习Bug通常是外在的，因此与源代码以外的工件（例如GPU、训练数据）相关联，这导致现有定位方法的性能不佳。

**Conclusion:** 本研究通过大规模实证分析，揭示了现有Bug定位技术在深度学习系统中表现不佳的原因，主要是由于深度学习Bug的独特类型和外在性质所带来的挑战。

> **ai_Abstract:** 本文通过一项大规模实证研究，深入探讨了深度学习系统中Bug定位的独特挑战。研究评估了现有定位技术在处理深度学习Bug时的性能，发现它们普遍表现不佳。进一步分析揭示，Bug类型（如张量Bug和GPU Bug）以及Bug的外在性（与代码之外的组件相关）是导致现有方法失效的关键因素。研究结果强调了开发针对深度学习系统特性的新型Bug定位方法的必要性。

> **摘要翻译:** 软件Bug每年给全球经济造成数十亿美元损失，并占据软件开发人员约50%的编程时间。定位这些Bug对于解决它们至关重要，但具有挑战性。在深度学习系统中，由于其黑盒性质，这一挑战性更大。这些系统中的Bug不仅隐藏在代码中，还隐藏在模型和训练数据中，这可能导致传统调试方法效果不佳。在本文中，我们进行了一项大规模实证研究，以更好地理解深度学习系统中Bug定位的挑战。首先，我们使用来自深度学习系统的2,365个Bug和来自传统软件的2,913个Bug，确定了四种现有技术的Bug定位性能。我们发现这些技术在定位深度学习系统Bug方面表现显著不佳。其次，我们评估了深度学习系统中不同Bug类型如何影响Bug定位。我们发现，由于其独特的挑战，定位技术的有效性随Bug类型而异。例如，张量Bug由于其结构性质更容易定位，而所有技术都难以定位GPU Bug，因为它们依赖外部。第三，我们调查了Bug的外在性质对深度学习系统定位的影响。我们发现，深度学习Bug通常是外在的，因此与源代码以外的工件（例如GPU、训练数据）相关联，这导致现有定位方法的性能不佳。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [126] [Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing](https://arxiv.org/abs/2507.15889)
> *Dr. Boot: 自举程序合成语言模型以执行修复*

*Noah van der Vleuten* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-20**

**Keywords:** 程序合成, 语言模型, 自举, 代码修复, APPS数据集

**Comment:** Master's thesis, University of Amsterdam, 2023
  (https://scripties.uba.uva.nl/search?id=record_54126). Code and experiments
  available at: https://github.com/NoahVl/Dr-Boot

> **TL;DR:** 引入了一种自举算法，用于教授程序合成语言模型如何修复代码，该方法优于常规微调，并能以更小的模型达到相似性能。

**AI_Comments:** 该论文的创新点在于引入了一种自举算法来教授语言模型进行代码修复，这与传统的一次性代码生成方式不同，更接近人类的迭代开发过程。其重要性在于，该方法不仅提高了模型性能，还显著降低了对模型大小和高质量训练数据的依赖。同时，论文还指出了现有编程竞赛数据集（APPS）中测试用例的问题，这对依赖这些数据集的后续研究具有指导意义。局限性可能在于，虽然修复在某些情况下表现良好，但在推理时可能不如简单地多次采样有效，这表明修复策略仍有优化空间。

<details>
  <summary>Details</summary>

**Motivation:** 现有的程序合成语言模型在训练数据（如MBPP、APPS）上存在规模和质量限制，且这些模型对数据需求量大。此外，模型通常一次性生成代码，与人类迭代开发代码（借助编译器）的过程不符。

**Method:** 引入了一种用于程序合成的自举算法，该算法支持教授模型如何进行修复。

**Result:** 自举方法始终优于常规微调。与微调的68%更大的模型相比，自举模型表现相当。带有修复的自举方法在推理时也提高了非修复性能。然而，在所使用的模型上，推理时的修复可能不如简单地采样相同数量的解决方案。此外，发现APPS数据集训练部分中的示例测试用例存在问题，这对于依赖它们的修复和强化学习方法来说是重要的发现。

**Conclusion:** 本研究提出了一种有效的自举算法，用于教授程序合成语言模型进行代码修复，证明了其在性能上的优势和数据效率，并指出了现有数据集的问题。

> **ai_Abstract:** 本研究提出了一种名为“Dr. Boot”的自举算法，旨在解决程序合成语言模型在数据限制和生成过程不符人类习惯的问题。该算法教授模型如何进行代码修复，并实验证明其性能优于常规微调，且能以更小的模型达到与大型模型相当的性能。研究还指出APPS数据集中测试用例存在的潜在问题。

> **摘要翻译:** 程序合成的语言模型通常在编程竞赛数据集（MBPP、APPS）上进行训练和评估。然而，这些数据集在规模和质量上都有限，而这些语言模型对数据需求量极大。此外，语言模型的程序合成过程与人类不一致。人类在编译器的帮助下迭代开发代码，而大多数程序合成模型目前都是一次性生成代码。为了解决这些问题，我们引入了一种用于程序合成的自举算法，该算法支持教授模型如何进行修复。我们表明，自举始终优于常规微调。与其他工作相比，我们的自举模型与大68%的微调模型表现相当。值得注意的是，带有修复的自举在推理时也提高了非修复性能，相比常规自举。然而，在我们的模型上，推理时的修复可能不如简单地采样相同数量的解决方案。此外，我们发现APPS数据集训练部分中的示例测试用例存在问题，这对社区很有价值，因为许多修复和强化学习方法都依赖于它们。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [162] [LangBiTe: A Platform for Testing Bias in Large Language Models](https://arxiv.org/abs/2404.18558)
> *LangBiTe: 大型语言模型偏见测试平台*

*Sergio Morales, Robert Clarisó, Jordi Cabot* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 偏见测试, LangBiTe, 伦理要求, 可追溯性

**Comment:** 

> **TL;DR:** LangBiTe是一个用于系统性评估大型语言模型偏见的测试平台。

**AI_Comments:** LangBiTe的创新之处在于其提供了可定制的、自动化的偏见测试框架，并通过测试预言机机制增加了评估的系统性。其端到端可追溯性对于确保伦理要求在模型开发和测试过程中的落实具有重要意义。这个平台对于提高LLM的公平性和减少潜在危害至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在各种软件应用中的集成引发了对其潜在偏见的担忧，这些偏见可能源于模型在大量互联网数据上的训练，导致有害和歧视性行为。

**Method:** LangBiTe是一个测试平台，允许开发团队定制测试场景，并根据用户定义的道德要求自动生成和执行测试用例。每个测试包含一个输入给LLM的提示和一个相应的测试预言机，用于审查LLM的响应以识别偏见。

**Result:** LangBiTe为用户提供LLMs的偏见评估，以及从初始道德要求到获得洞察的端到端可追溯性。

**Conclusion:** LangBiTe通过提供一个系统性的测试平台，帮助解决大型语言模型中的偏见问题，并确保测试的可定制性和结果的可追溯性。

> **ai_Abstract:** 本文介绍了LangBiTe，一个旨在系统性评估大型语言模型（LLMs）中潜在偏见的测试平台。鉴于LLMs在训练数据中可能存在的有害和歧视性偏见，LangBiTe允许开发团队定制测试场景，并基于用户定义的道德要求自动生成和执行测试用例。该平台通过提示和测试预言机来识别LLM响应中的偏见，并提供偏见评估及从道德要求到测试结果的端到端可追溯性。

> **摘要翻译:** 大型语言模型（LLMs）集成到各种软件应用中引发了对其潜在偏见的担忧。通常，这些模型是在从论坛、网站、社交媒体和其他互联网来源抓取的大量数据上训练的，这可能会在模型中灌输有害和歧视性行为。为了解决这个问题，我们提出了LangBiTe，一个用于系统性评估LLM中是否存在偏见的测试平台。LangBiTe使开发团队能够定制他们的测试场景，并根据一组用户定义的道德要求自动生成和执行测试用例。每个测试都包含一个输入到LLM的提示和一个相应的测试预言机，用于审查LLM的响应以识别偏见。LangBite为用户提供了LLM的偏见评估，以及初始道德要求与所获得见解之间的端到端可追溯性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [166] [StaAgent: An Agentic Framework for Testing Static Analyzers](https://arxiv.org/abs/2507.15892)
> *StaAgent: 一个用于测试静态分析器的代理框架*

*Elijah Nnorom, Md Basim Uddin Ahmed, Jiho Shin, Hung Viet Pham, Song Wang* | **Category: cs.SE** | **Updated: 2025-07-20**

**Keywords:** 静态分析器, LLM, 代理框架, 蜕变测试, 软件测试

**Comment:** 

> **TL;DR:** StaAgent是一个基于LLM的代理框架，用于系统地测试静态分析器规则，通过生成和变异代码来发现规则实现中的不一致性，并已成功发现多个问题。

**AI_Comments:** StaAgent的创新之处在于其将LLM的生成能力与多代理框架相结合，实现了对静态分析器规则的系统化和自动化测试。通过蜕变测试和语义等效变异体的生成，它能够有效揭示传统测试难以发现的规则实现缺陷。其发现大量未被SOTA基线检测到的bug，并成功促使部分bug被修复，这证明了该方法的实际价值和对软件工程领域的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 静态分析器在软件开发中很重要，但其规则实现常未经过充分测试且易出现不一致性，导致潜在的错误。

**Method:** 提出StaAgent，一个利用大型语言模型（LLMs）生成能力的代理框架，旨在系统评估静态分析器规则。它包含四个专门的代理：种子生成代理（将缺陷检测规则转换为具体的、诱发缺陷的种子程序），代码验证代理（确保这些种子的正确性），变异生成代理（生成语义等效的变异体），以及分析器评估代理（通过比较静态分析器在种子及其对应变异体上的行为来执行蜕变测试）。通过揭示不一致的行为，StaAgent有助于发现规则实现中的缺陷。

**Result:** StaAgent使用五种最先进的LLM（CodeL-lama、DeepSeek、Codestral、Qwen和GPT-4o）对StaAgent进行了评估，涉及五种广泛使用的静态分析器（SpotBugs、SonarQube、ErrorProne、Infer和PMD）。实验结果表明，该方法可以帮助揭示这五种静态分析器最新版本中的64个问题规则（即SpotBugs中有28个，SonarQube中有18个，ErrorProne中有6个，Infer中有4个，PMD中有8个）。此外，64个缺陷中有53个是SOTA基线无法检测到的。所有缺陷均已向开发者报告，其中2个已修复，3个已得到开发者确认，其余的正在等待回复。

**Conclusion:** StaAgent证明了其在提高静态分析器可靠性方面的有效性，并强调了代理式、LLM驱动的数据合成在推动软件工程方面的潜力。

> **ai_Abstract:** StaAgent是一个利用LLM生成能力的多代理框架，旨在系统地测试静态分析器规则。它通过四个专门代理（种子生成、代码验证、变异生成和分析器评估）生成和验证错误诱导代码，并通过蜕变测试发现规则实现中的不一致性。实验证明，StaAgent在主流静态分析器中成功发现了大量（64个）现有方法难以检测（53个）的问题规则，显著提高了静态分析器的可靠性，并已促成部分缺陷的修复。

> **摘要翻译:** 静态分析器在软件开发生命周期的早期识别缺陷方面发挥着关键作用，但其规则实现往往未经充分测试且容易出现不一致性。为了解决这个问题，我们提出了StaAgent，一个代理框架，它利用大型语言模型（LLMs）的生成能力来系统地评估静态分析器规则。StaAgent包含四个专门的代理：一个种子生成代理，将缺陷检测规则转换为具体的、诱发缺陷的种子程序；一个代码验证代理，确保这些种子的正确性；一个变异生成代理，生成语义等效的变异体；以及一个分析器评估代理，通过比较静态分析器在种子及其对应变异体上的行为来执行蜕变测试。通过揭示不一致的行为，StaAgent有助于发现规则实现中的缺陷。这种LLM驱动的多代理框架提供了一种可扩展且适应性强的解决方案，以提高静态分析器的可靠性。我们使用五种最先进的LLM（CodeL-lama、DeepSeek、Codestral、Qwen和GPT-4o）对StaAgent进行了评估，涉及五种广泛使用的静态分析器（SpotBugs、SonarQube、ErrorProne、Infer和PMD）。实验结果表明，我们的方法可以帮助揭示这五种静态分析器最新版本中的64个问题规则（即SpotBugs中有28个，SonarQube中有18个，ErrorProne中有6个，Infer中有4个，PMD中有8个）。此外，64个缺陷中有53个是SOTA基线无法检测到的。我们已向开发者报告了所有缺陷，其中两个已修复。另有三个已得到开发者确认，其余的正在等待回复。这些结果证明了我们方法的有效性，并强调了代理式、LLM驱动的数据合成在推动软件工程方面的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [206] [Improving Source Code Similarity Detection Through GraphCodeBERT and Integration of Additional Features](https://arxiv.org/abs/2408.08903)
> *通过GraphCodeBERT和额外特征集成改进源代码相似性检测*

*Jorge Martinez-Gil* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 源代码相似性检测, GraphCodeBERT, 特征集成, 模型性能, 分类

**Comment:** 15 pages

> **TL;DR:** 本文提出了一种基于GraphCodeBERT并集成额外特征的源代码相似性检测新方法，该方法在性能上取得了有希望的结果。

**AI_Comments:** 该论文通过集成额外特征来增强GraphCodeBERT模型，为源代码相似性检测提供了一种新颖的改进方法，其开源代码的提供也便于后续研究和复现。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过将一个额外的输出特征集成到分类过程中来提高源代码相似性检测模型的性能。

**Method:** 该方法基于GraphCodeBERT模型，并通过自定义输出特征层和串联机制进行扩展，以改进特征表示。模型经过训练和评估。

**Result:** 该模型在精确度、召回率和F-measure方面取得了有希望的结果。

**Conclusion:** 该方法在源代码相似性检测方面取得了有希望的性能提升。

> **ai_Abstract:** 本文提出了一种基于GraphCodeBERT的新型源代码相似性检测方法。该方法通过集成额外的输出特征和使用自定义输出特征层及串联机制来增强特征表示，旨在提高模型性能。实验结果表明，该方法在精确度、召回率和F-measure方面取得了有希望的成果。

> **摘要翻译:** 本文提出了一种新颖的源代码相似性检测方法，该方法将一个额外的输出特征集成到分类过程中，旨在提高模型性能。我们的方法基于GraphCodeBERT模型，并通过自定义输出特征层和串联机制进行扩展，以改进特征表示。该模型经过训练和评估，在精确度、召回率和F-measure方面取得了有希望的结果。文中讨论了实现细节，包括模型架构和训练策略。说明我们方法的源代码可以从https://www.github.com/jorge-martinez-gil/graphcodebert-feature-integration下载。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [207] [A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights](https://arxiv.org/abs/2507.16037)
> *基于LLM的Agentic式Android到iOS翻译的初步研究：陷阱与见解*

*Zhili Zeng, Kimya Khakzad Shahandashti, Alvine Boaye Belle, Song Wang, Zhen Ming, Jiang* | **Category: cs.SE** | **Updated: 2025-07-21**

**Keywords:** LLM, Agentic翻译, 跨平台, Android到iOS, 移动应用

**Comment:** 

> **TL;DR:** 本初步研究评估了基于LLM的Agentic方法在Android到iOS应用翻译中的表现，识别了关键失败点，并提出了改进指南。

**AI_Comments:** 这项初步研究的创新之处在于其首次探索了基于LLM的Agentic方法在Android到iOS跨平台应用翻译中的应用。其重要性体现在解决了当前手动或规则系统效率低下以及现有自动化方法缺乏上下文理解的痛点。通过识别关键失败点并提出改进指南，该研究为未来LLM在软件工程自动化中的应用奠定了基础。然而，作为一项初步研究，其评估依赖于手动检查，且侧重于问题识别而非提供全面解决方案，这可能是其局限性。

<details>
  <summary>Details</summary>

**Motivation:** 移动应用的快速发展带来了跨平台兼容性的巨大需求，尤其是Android和iOS平台之间。传统的翻译方法劳动密集且耗时，而现有自动化方法缺乏上下文理解和适应性，导致翻译不佳。虽然LLM已被用于代码翻译，但基于LLM的跨平台应用翻译（如Android到iOS迁移）仍未得到充分探索。理解LLM在跨平台应用翻译中的性能、优势和局限性对于推进软件工程自动化至关重要。

**Method:** 研究开发了一系列Agent，在将应用程序从Android翻译到iOS时，考虑了依赖关系、规范、程序结构和程序控制流。为了评估性能，研究人员手动检查了翻译后的代码的语法正确性、语义准确性和功能完整性。对于翻译失败，进一步进行了详细的根本原因分析，以了解Agentic翻译过程的潜在局限性。

**Result:** 研究识别了LLM-based Agentic方法在Android到iOS应用翻译中的关键失败点，并对翻译失败进行了详细的根本原因分析，以理解潜在局限性并发现改进机会。

**Conclusion:** 本研究评估了LLM-based Agentic方法在移动应用翻译中的表现，识别了关键失败点，并提出了改进翻译性能的指导方针，为推进软件工程自动化中LLM在跨平台应用翻译中的应用提供了重要见解。

> **ai_Abstract:** 本研究旨在解决Android到iOS移动应用跨平台翻译中LLM-based Agentic方法的未充分探索领域。鉴于传统和现有自动化方法的局限性，研究开发了一个考虑程序结构和控制流的Agent链，用于从Android到iOS的翻译。通过手动检查翻译代码的正确性并进行根本原因分析，该研究识别了关键失败点，并提出了改进LLM-based Agentic翻译性能的指导方针，为软件工程自动化提供了重要见解。

> **摘要翻译:** 移动应用的快速发展导致对跨平台兼容性，特别是Android和iOS平台之间的兼容性，产生了巨大的需求。传统的移动应用翻译方法通常依赖于人工干预或基于规则的系统，这些方法劳动密集且耗时。尽管机器学习的最新进展引入了自动化方法，但它们往往缺乏上下文理解和适应性，导致次优的翻译。大型语言模型（LLMs）最近被用于增强不同粒度（包括方法、类和仓库级别）的代码翻译。研究人员已经调查了常见的错误、局限性以及改进这些任务的潜在策略。然而，LLM驱动的跨平台应用翻译，例如在Android和iOS之间迁移移动应用或在不同框架之间适配软件，仍然未被充分探索。理解LLMs在跨平台应用翻译中的性能、优势和局限性对于推进软件工程自动化至关重要。本研究旨在通过评估LLM驱动的Agentic方法在移动应用翻译中的应用来填补这一空白，识别关键故障点，并提出改进翻译性能的指导方针。我们开发了一个Agent链，在将应用程序从Android翻译到iOS时，考虑了依赖关系、规范、程序结构和程序控制流。为了评估性能，我们手动检查了翻译后的代码的语法正确性、语义准确性和功能完整性。对于翻译失败，我们进一步进行了详细的根本原因分析，以了解Agentic翻译过程的潜在局限性并识别改进机会。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [253] [Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs](https://arxiv.org/abs/2507.16044)
> *使REST API具备代理能力：从OpenAPI到用于工具增强型LLM的模型上下文协议服务器*

*Meriem Mastouri, Emna Ksontini, Wael Kessentini* | **Category: cs.SE** | **Updated: 2025-07-21**

**Keywords:** LLM, 工具集成, OpenAPI, Model Context Protocol, 自动化

**Comment:** 

> **TL;DR:** AutoMCP是一个编译器，可以从OpenAPI规范自动生成Model Context Protocol (MCP)服务器，从而显著提高LLM工具集成效率并减少手动开发成本。

**AI_Comments:** 该论文的创新之处在于提出了AutoMCP，一个将OpenAPI规范自动转换为MCP服务器的编译器，极大地简化了LLM与外部工具集成的工作。这解决了当前LLM作为代理使用时，工具集成面临的“胶水代码”和重复性开发痛点。其重要性在于，它不仅提高了开发效率，还通过实践验证了OpenAPI在自动化工具集成中的可行性，并识别出OpenAPI规范中常见的缺陷，为未来的API设计和工具集成提供了宝贵的经验。该工作对于推动LLM从被动生成器向主动代理的转变具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LLM正在从被动文本生成器发展为调用外部工具的主动代理。Anthropic的Model Context Protocol (MCP)为动态工具发现和调用提供了标准，但构建MCP服务器仍然是手动且重复的，需要大量的“胶水代码”和配置，这与MCP旨在消除集成工作的目标相悖。因此，本研究旨在探讨MCP服务器的构建是否可以自动化，以解决手动开发成本高昂的问题。

**Method:** 研究首先分析了MCP的采纳趋势，发现GitHub上带有MCP标签的项目中，服务器实现很少且通常是小型项目。为解决此问题，论文提出了AutoMCP，一个编译器，能够从OpenAPI 2.0/3.0规范生成完整的MCP服务器实现，包括模式注册和认证处理。AutoMCP解析REST API定义并生成服务器代码。研究在50个真实世界的API上评估了AutoMCP，这些API涵盖5066个端点。

**Result:** AutoMCP在1023个工具调用样本中，开箱即用的成功率为76.5%。手动故障分析揭示了5个重复出现的问题，这些问题均归因于OpenAPI契约中的不一致或遗漏。经过平均每个API 19行的微小规范修改后，AutoMCP的成功率达到了99.9%。研究还分析了MCP的采纳情况，量化了手动服务器开发的成本，并证明了OpenAPI规范（尽管存在质量问题）能够实现近乎完全的MCP服务器自动化。此外，还贡献了一个包含5066个可调用工具的语料库，以及修复常见规范缺陷的见解。

**Conclusion:** OpenAPI规范虽然存在质量问题，但能够实现MCP服务器的近乎完全自动化。AutoMCP通过自动化MCP服务器的构建，显著降低了LLM工具集成的开发成本，并为未来LLM代理与外部工具的高效交互奠定了基础。研究还提供了修复常见API规范缺陷的实用见解。

> **ai_Abstract:** 本文提出AutoMCP，一个编译器，旨在自动化从OpenAPI 2.0/3.0规范生成Model Context Protocol (MCP)服务器的过程，以解决LLM工具集成中手动构建服务器的重复性问题。通过分析MCP的低采纳率和高手动开发成本，AutoMCP被开发用于解析REST API定义并生成完整的MCP服务器实现，包括模式注册和认证。在50个真实世界API上的评估显示，AutoMCP在经过少量OpenAPI规范修正后，能达到99.9%的工具调用成功率，证明了OpenAPI在实现MCP服务器自动化方面的潜力，并提供了修复常见API规范缺陷的见解。

> **摘要翻译:** 大型语言模型（LLMs）正在从被动文本生成器演变为调用外部工具的主动代理。为了支持这一转变，可扩展的工具集成协议至关重要。Anthropic于2024年推出的模型上下文协议（MCP）提供了一种模式驱动的标准，用于动态工具发现和调用。然而，构建MCP服务器仍然是手动且重复的，需要开发人员编写“胶水代码”、处理身份验证以及手动配置模式，这复制了MCP旨在消除的大部分集成工作。
本文研究了MCP服务器的构建是否可以有意义地自动化。我们首先分析了采纳趋势：在发布后的六个月内创建的22,000多个带有MCP标签的GitHub存储库中，不到5%包含服务器，这些服务器通常是小型、单维护者项目，并以重复的脚手架为主。为了弥补这一空白，我们提出了AutoMCP，一个从OpenAPI 2.0/3.0规范生成MCP服务器的编译器。AutoMCP解析REST API定义并生成完整的服务器实现，包括模式注册和身份验证处理。
我们在涵盖10多个领域、5066个端点的50个真实世界API上评估了AutoMCP。在分层抽取的1023个工具调用样本中，76.5%开箱即用成功。手动故障分析揭示了五个重复出现的问题，所有这些都归因于OpenAPI契约中的不一致或遗漏。经过平均每个API 19行的微小修复后，AutoMCP实现了99.9%的成功率。
我们的发现（i）分析了MCP的采纳情况并量化了手动服务器开发的成本，（ii）证明了OpenAPI规范，尽管存在质量问题，但能够实现近乎完全的MCP服务器自动化，以及（iii）贡献了一个包含5066个可调用工具的语料库以及修复常见规范缺陷的见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [257] [Software is infrastructure: failures, successes, costs, and the case for formal verification](https://arxiv.org/abs/2506.13821)
> *软件即基础设施：失败、成功、成本以及形式化验证的案例*

*Giovanni Bernardi, Adrian Francalanza, Marco Peressotti, Mohammad Reza Mousavi* | **Category: cs.SE, cs.CY** | **Updated: 2025-07-22**

**Keywords:** 软件质量, 形式化验证, 程序分析, 软件故障, 成本

**Comment:** 

> **TL;DR:** 软件质量差导致巨大成本，因此需要研究和应用形式化验证。

**AI_Comments:** 这篇论文强调了软件作为基础设施的重要性，并以经济成本为切入点，有力地论证了形式化验证的必要性。其重要性在于将软件质量问题与具体经济损失挂钩，从而为形式化验证提供了强有力的商业案例支持。这对于推动形式化方法在工业界的采纳具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代社会中软件的作用日益重要，但软件质量差带来了惊人的成本，尤其是在过去40年发生的一些重大软件故障。

**Method:** 本章概述了软件在现代社会中的作用、差劣软件质量造成的惊人成本，回顾了过去40年发生的一些重大软件故障的成本，并论证这些成本证明了研究、学习和应用形式化软件验证（特别是程序分析）的合理性。

**Result:** 软件质量差导致了巨大的成本，并且有成功的工业经验支持形式化验证的有效性。

**Conclusion:** 软件故障的高昂成本证明了研究和应用形式化软件验证（尤其是程序分析）的必要性。

> **ai_Abstract:** 本章探讨了软件在现代社会中的关键作用及其质量问题所导致的巨额成本。通过回顾过去40年来的重大软件故障案例，作者强调了差劣软件质量带来的经济损失。鉴于此，文章主张应加大对形式化软件验证，特别是程序分析的研究和应用，并指出已有成功的工业实践支持这一观点。

> **摘要翻译:** 在本章中，我们概述了软件在现代社会中的作用，以及软件质量差所带来的惊人成本。为了阐明这一点，我们回顾了过去40年中发生的一些重大软件故障的成本。我们认为这些成本证明了研究、学习和应用形式化软件验证，特别是程序分析的合理性。这一立场得到了成功的工业经验的支持。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [291] [AI-Powered Commit Explorer (APCE)](https://arxiv.org/abs/2507.16063)
> *AI驱动的提交信息探索器 (APCE)*

*Yousab Grees, Polina Iaremchuk, Ramtin Ehsani, Esteban Parra, Preetha Chatterjee, Sonia Haiduc* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 提交信息, LLM, 工具, 软件工程, 评估

**Comment:** 

> **TL;DR:** APCE是一个AI驱动的工具，旨在帮助开发者和研究人员使用和评估LLM生成的提交信息，以解决高质量提交信息缺失的问题。

**AI_Comments:** APCE的创新之处在于其作为一个专门为LLM生成提交信息提供支持的工具，集成了提示管理和评估机制。这对于提高软件开发实践中提交信息的质量，并促进LLM在该领域应用的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提交信息对开发者理解代码变更至关重要，但实践中高质量提交信息常被忽视。虽然大型语言模型（LLM）生成的提交信息可以缓解此问题，但仍需要工具来支持其有效使用和深入研究。

**Method:** APCE作为一个工具，支持研究人员存储不同的LLM提示，并提供一个额外的评估提示来增强LLM生成的提交信息。它还为研究人员提供了一种直接的机制，用于对LLM生成的信息进行自动化和人工评估。

**Result:** APCE为开发者和研究人员提供了一个支持LLM生成提交信息的使用和研究的平台，通过其功能增强了LLM生成提交信息的质量，并简化了评估过程。

**Conclusion:** APCE是一个有用的工具，旨在解决高质量提交信息缺失的问题，通过支持LLM生成提交信息的使用和评估来帮助开发者和研究人员。

> **ai_Abstract:** APCE（AI驱动的提交信息探索器）是一个旨在解决高质量软件提交信息缺失问题的工具。它支持开发者和研究人员使用和研究大型语言模型（LLM）生成的提交信息。APCE允许存储LLM提示、提供增强提交信息的评估提示，并简化了LLM生成信息自动化和人工评估的流程。

> **摘要翻译:** 版本控制系统中的提交信息为开发者提供了关于软件系统代码变更的宝贵信息。提交信息可能是未来开发者了解代码变更内容和原因的唯一信息来源。然而，在实践中，编写高质量的提交信息常常被忽视。大型语言模型（LLM）生成的提交信息已成为缓解此问题的一种方法。我们引入了AI驱动的提交信息探索器（APCE），这是一个支持开发者和研究人员使用和研究LLM生成提交信息的工具。APCE为研究人员提供了存储不同LLM提示的选项，并提供了一个额外的评估提示，可以进一步增强LLM提供的提交信息。APCE还为研究人员提供了一种直接的机制，用于对LLM生成的信息进行自动化和人工评估。演示链接 https://youtu.be/zYrJ9s6sZvo

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [302] [Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction](https://arxiv.org/abs/2507.10729)
> *迈向即时漏洞预测的现实评估*

*Duong Nguyen, Thanh Le-Cong, Triet Huynh Minh Le, M. Ali Babar, Quyet-Thang Huynh* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** JIT-VP, 漏洞预测, 现实评估, 数据不平衡, 软件安全

**Comment:** 

> **TL;DR:** 即时漏洞预测（JIT-VP）在现实世界数据集中表现显著下降，因为数据集严重不平衡，且现有不平衡处理技术无效。

**AI_Comments:** 本文通过揭示当前JIT-VP评估的局限性及其在现实世界场景中的性能下降，对软件安全领域做出了重要贡献。其创新之处在于构建了一个大规模的真实世界数据集，并系统地评估了现有技术的表现。研究结果不仅警示了理想化评估的风险，还指出了现有数据不平衡处理技术在特定领域中的不足，为未来研究指明了方向。该研究提供的数据集对于社区进行更真实的JIT-VP研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前即时漏洞预测（JIT-VP）的评估依赖于理想化的设置，即评估数据集是人为平衡的，仅包含引入漏洞和修复漏洞的提交。本研究旨在解决这一局限性，评估JIT-VP技术在更现实环境下的有效性。

**Method:** 本研究在一个更现实的环境下评估了JIT-VP技术，该环境包括与漏洞相关和与漏洞无关的提交。为此，研究引入了一个包含FFmpeg和Linux内核中超过一百万次提交的大规模公共数据集。研究对八种最先进的JIT-VP技术进行了实证分析，并探索了处理数据集不平衡的常用技术，包括定制损失函数、过采样和欠采样。

**Result:** 在现实世界条件下，JIT-VP的预测性能显著下降；例如，Linux上的平均PR-AUC从0.805下降了98%至0.016。这种差异主要归因于现实世界数据集中严重的类别不平衡，其中引入漏洞的提交只占所有提交的一小部分。实验结果表明，用于处理数据集不平衡的常用技术（如定制损失函数、过采样和欠采样）在解决JIT-VP中的不平衡问题方面无效。

**Conclusion:** 本研究结果强调了对JIT-VP进行现实评估的重要性，以及在这种场景中需要领域特定的技术来解决数据不平衡问题。

> **ai_Abstract:** 本研究指出当前即时漏洞预测（JIT-VP）的评估存在缺陷，即数据集被人为平衡。为解决此问题，作者构建了一个包含百万级真实提交的大型公共数据集（来自FFmpeg和Linux内核），并在更现实的环境下重新评估了八种主流JIT-VP技术。结果显示，在真实数据集中，JIT-VP的性能显著下降（例如PR-AUC下降98%），这主要是由于严重的类别不平衡。令人惊讶的是，常用的不平衡处理技术（如定制损失函数、过采样、欠采样）对此问题无效。研究强调了JIT-VP现实评估的必要性以及开发领域特定不平衡处理技术的重要性。

> **摘要翻译:** 现代软件系统日益复杂，对质量保证提出了严峻挑战。即时漏洞预测（JIT-VP）是一种主动方法，旨在识别易受攻击的提交并提供潜在安全风险的早期预警。然而，我们观察到当前的JIT-VP评估依赖于理想化的设置，其中评估数据集是人为平衡的，仅包含引入漏洞和修复漏洞的提交。为了解决这一局限性，本研究在更现实的环境下评估了JIT-VP技术的有效性，该环境包括与漏洞相关和与漏洞无关的提交。为了实现可靠的评估，我们引入了一个大型公共数据集，包含来自FFmpeg和Linux内核的超过一百万次提交。我们对八种最先进的JIT-VP技术进行的实证分析表明，当应用于现实世界条件时，其预测性能显著下降；例如，Linux上的平均PR-AUC从0.805下降了98%至0.016。这种差异主要归因于现实世界数据集中严重的类别不平衡，其中引入漏洞的提交只占所有提交的一小部分。为了缓解这个问题，我们探讨了广泛采用的数据集不平衡处理技术的有效性，包括定制损失函数、过采样和欠采样。令人惊讶的是，我们的实验结果表明，这些技术在解决JIT-VP中的不平衡问题方面无效。这些发现强调了对JIT-VP进行现实评估的重要性，以及在这种场景中需要领域特定的技术来解决数据不平衡问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [331] [Ten Essential Guidelines for Building High-Quality Research Software](https://arxiv.org/abs/2507.16166)
> *构建高质量研究软件的十大基本准则*

*Nasir U. Eisty, David E. Bernholdt, Alex Koufos, David J. Luet, Miranda Mundt* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 研究软件, 软件质量, 开发准则, 最佳实践, 科学研究

**Comment:** 

> **TL;DR:** 本文提出了构建高质量研究软件的十项基本准则，涵盖开发生命周期的各个阶段，旨在帮助研究人员提升软件质量和影响力。

**AI_Comments:** 本文提供了一套全面且实用的指南，对于提升研究软件的质量和可靠性具有重要意义。其创新之处在于将软件工程的最佳实践系统性地应用于科研领域，并强调了整个开发生命周期的考量，而不仅仅是编码阶段。这对于促进科学研究的可复现性和透明度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 高质量的研究软件是现代科学进步的基石，但创建此类软件需要遵循最佳实践以确保其健壮性、可用性和可持续性。因此，需要一套指导方针来帮助研究人员构建高质量的研究软件。

**Method:** 本文提出了十项构建高质量研究软件的准则，涵盖了开发生命周期的各个阶段，包括规划、编写清晰可读的代码、使用版本控制、实施彻底的测试策略、模块化设计、可复现性、性能优化、长期维护、文档编写和社区参与。

**Result:** 遵循这些准则，研究人员可以创建出推动其科学目标并有助于更广泛的可靠和可重用研究工具生态系统的软件。

**Conclusion:** 本文为旨在提升其研究软件质量和影响力的研究人员和开发人员提供了一个实用的资源。

> **ai_Abstract:** 本文针对构建高质量研究软件提出了十项基本准则，旨在帮助研究人员在软件开发的各个阶段遵循最佳实践。这些准则涵盖了从规划、编码、测试、版本控制到模块化设计、可复现性、性能优化、长期维护、文档和社区参与等方面，旨在提高研究软件的健壮性、可用性和可持续性，最终促进科学目标实现并贡献于可靠可重用的研究工具生态系统。

> **摘要翻译:** 高质量的研究软件是现代科学进步的基石，它使研究人员能够分析复杂数据、模拟现象并分享可复现的结果。然而，创建此类软件需要遵循最佳实践，以确保其鲁棒性、可用性和可持续性。本文提出了生产高质量研究软件的十项准则，涵盖了开发生命周期的每个阶段。这些准则强调了规划、编写清晰可读的代码、使用版本控制和实施彻底测试策略的重要性。此外，它们还涉及模块化设计、可复现性、性能优化和长期维护等关键原则。论文还强调了文档和社区参与在增强软件可用性和影响力方面的作用。通过遵循这些准则，研究人员可以创建出推动其科学目标并有助于更广泛的可靠和可重用研究工具生态系统的软件。这项工作为旨在提升其研究软件质量和影响力的研究人员和开发人员提供了一个实用的资源。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [355] [GitChameleon 2.0: Evaluating AI Code Generation Against Python Library Version Incompatibilities](https://arxiv.org/abs/2507.12367)
> *GitChameleon 2.0: 评估AI代码生成对抗Python库版本不兼容性*

*Diganta Misra, Nizar Islah, Victor May, Brice Rauby, Zihan Wang, Justine Gehring, Antonio Orvieto, Muawiz Chaudhary, Eilif B. Muller, Irina Rish, Samira Ebrahimi Kahou, Massimo Caccia* | **Category: cs.SE, cs.AI, cs.PL** | **Updated: 2025-07-21**

**Keywords:** AI代码生成, Python库, 版本不兼容性, GitChameleon 2.0, 基准测试

**Comment:** Version 2 of the dataset from: arXiv:2411.05830

> **TL;DR:** GitChameleon 2.0是一个新的数据集，用于评估AI代码生成在Python库版本不兼容性方面的能力，发现当前最先进的系统在此任务中面临显著挑战，成功率仅为48-51%。

**AI_Comments:** GitChameleon 2.0通过引入基于执行的评估和版本条件的代码生成任务，填补了现有代码演化基准的空白，这对于开发能在真实世界复杂软件环境中运行的AI代码生成系统至关重要。其揭示的当前SOTA模型在此任务上的低成功率，突显了该领域的巨大挑战和未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 软件库的快速演进对代码生成构成巨大障碍，需要持续适应版本更新并保持向后兼容性。现有代码演化基准缺乏针对特定库版本的基于执行的评估。

**Method:** 引入GitChameleon 2.0，一个包含328个Python代码补全问题的新数据集，每个问题都以特定库版本为条件并附带可执行单元测试。使用该数据集严格评估当代大型语言模型（LLMs）、LLM驱动的代理、代码助手和RAG系统在版本条件代码生成方面的功能准确性。

**Result:** 广泛的评估表明，最先进的系统在此任务中遇到显著挑战；企业模型的基础成功率在48-51%之间，这突显了问题的复杂性。

**Conclusion:** GitChameleon 2.0提供了一个强调代码库动态性质的基于执行的基准，有助于更清晰地理解这一挑战，并指导开发更具适应性和可靠性的AI代码生成方法。

> **ai_Abstract:** 本文介绍了GitChameleon 2.0，一个用于评估AI代码生成模型处理Python库版本不兼容性的新数据集。该数据集包含328个带可执行单元测试的版本条件Python代码补全问题。通过对LLMs和相关系统的评估发现，当前最先进的模型在此任务中表现不佳，企业模型的成功率仅为48-51%。GitChameleon 2.0提供了一个基于执行的基准，旨在促进更适应和可靠的AI代码生成方法的发展。

> **摘要翻译:** 软件库的快速演进对代码生成构成了相当大的障碍，需要持续适应频繁的版本更新，同时保持向后兼容性。虽然现有的代码演化基准提供了宝贵的见解，但它们通常缺乏针对生成符合特定库版本的代码的基于执行的评估。为了解决这个问题，我们引入了GitChameleon 2.0，这是一个新颖、精心策划的数据集，包含328个Python代码补全问题，每个问题都以特定的库版本为条件，并附带可执行单元测试。GitChameleon 2.0严格评估了当代大型语言模型（LLMs）、LLM驱动的代理、代码助手和RAG系统执行版本条件代码生成的能力，并通过执行展示其功能准确性。我们广泛的评估表明，最先进的系统在此任务中遇到显著挑战；企业模型的基础成功率在48-51%之间，这突显了问题的复杂性。通过提供一个强调代码库动态性质的基于执行的基准，GitChameleon 2.0能够更清晰地理解这一挑战，并有助于指导开发更具适应性和可靠性的AI代码生成方法。我们已将数据集和评估代码公开发布在https://github.com/mrcabbage972/GitChameleonBenchmark。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [384] [LOCOFY Large Design Models -- Design to code conversion solution](https://arxiv.org/abs/2507.16208)
> *LOCOFY 大型设计模型——设计到代码转换解决方案*

*Sohaib Muhammad, Ashwati Vipin, Karan Shetti, Honey Mittal* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大型设计模型, 设计到代码, UI元素, 代码生成, 机器学习

**Comment:** 

> **TL;DR:** 引入大型设计模型（LDMs），专门针对设计到代码转换进行训练，通过新颖的管道克服LLM的挑战，实现了卓越的准确性和可靠性。

**AI_Comments:** 本文通过引入专为设计到代码转换定制的大型设计模型（LDMs），提出了一种创新方法，使其区别于通用LLMs。其模块化的训练管道，包括设计优化器、标签和特征检测以及自动组件，展示了解决该领域特定挑战（如次优设计和代码可重用性）的周密策略。使用“新颖的预览匹配得分指标”以及与LLMs的对比实验验证了其卓越性能，突显了其在自动化UI开发方面取得重大进展的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型（LLMs）和多模态大型语言模型在设计到代码转换应用中面临的可解释性、可扩展性、资源需求和可重复性等挑战。

**Method:** 引入大型设计模型（LDMs）范式，该模型专门针对设计和网页进行训练，以实现从设计到代码的无缝转换。开发了一个训练和推理管道：训练管道包括设计优化器（使用专有真实数据集）、标签和特征检测（使用预训练和微调模型）、自动组件（提取可重用UI结构）。推理管道处理真实世界设计，以生成精确且可解释的代码生成指令并确保可靠性。

**Result:** 模型使用新颖的预览匹配得分指标，展示了卓越的端到端设计到代码转换准确性。对比实验表明，LDMs在节点定位准确性、响应性和可重复性方面优于LLMs。定制训练的标签和特征检测模型在识别UI元素方面表现出高精度和一致性。

**Conclusion:** 所提出的LDMs是一种可靠且卓越的解决方案，能够理解设计并随后生成高效、可靠的生产就绪代码。

> **ai_Abstract:** 本文引入大型设计模型（LDMs）作为一种新范式，旨在解决大型语言模型（LLMs）在设计到代码转换中的局限性。LDMs通过独特的管道进行训练，该管道包含设计优化器、标签和特征检测以及自动组件，旨在提高可解释性、可扩展性和资源效率。实验结果表明，与LLMs相比，LDMs在端到端转换、节点定位、响应性和可重复性方面取得了卓越的准确性，为从设计生成生产就绪代码提供了可靠的解决方案。

> **摘要翻译:** 尽管大型语言模型和多模态大型语言模型（LLMs）取得了快速进展，但在其应用于设计到代码转换领域时，仍然存在与可解释性、可扩展性、资源需求和可重复性相关的众多挑战。为了解决这些问题，我们引入了大型设计模型（LDMs）范式，该模型专门针对设计和网页进行训练，以实现从设计到代码的无缝转换。我们通过整合数据工程和适当的模型架构修改，开发了一个训练和推理管道。训练管道包括以下部分：1）设计优化器：使用专有真实数据集开发，解决次优设计问题；2）标签和特征检测：使用预训练和微调模型，实现UI元素的精确检测和分类；3）自动组件：将重复的UI结构提取为可重用组件，以创建模块化代码，从而减少冗余并增强代码可重用性。通过这种方式，每个模型都解决了设计到代码转换中独特但关键的问题。另外，我们的推理管道处理真实世界的设计，以生成精确且可解释的代码生成指令，并确保可靠性。此外，我们的模型使用一种新颖的预览匹配得分指标，展示了卓越的端到端设计到代码转换准确性。对比实验表明，在节点定位准确性、响应性和可重复性方面，LDMs相对于LLMs表现出卓越的性能。此外，我们定制训练的标签和特征检测模型在识别广泛测试设计样本中的UI元素时，表现出高精度和一致性。因此，我们提出的LDMs是一种可靠且卓越的解决方案，能够理解设计并随后生成高效、可靠的生产就绪代码。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [438] [Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels](https://arxiv.org/abs/2507.16327)
> *基于搜索的海上自主船只自适应触发航路点生成*

*Karoline Nylænder, Aitor Arrieta, Shaukat Ali, Paolo Arcaini* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 自主船舶, 自适应, 航路点生成, 多目标搜索, NSGA-II

**Comment:** 9 pages, 3 figures. Accepted at GECCO 2025 (Genetic and Evolutionary
  Computation Conference), July 14-18, 2025, Malaga, Spain

> **TL;DR:** 提出WPgen多目标搜索方法，通过微调航路点来触发海上自主船舶的自适应行为，并评估了其有效性。

**AI_Comments:** 该论文提出了一种新颖的、基于搜索的方法来系统地生成触发自主船舶自适应行为的场景。这种方法对于验证和提高自主系统的鲁棒性具有重要意义，尤其是在复杂和不可预测的海上环境中。WPgen通过对航路点进行微小修改，模拟了可能导致系统需要自适应的情况，这是一种巧妙的测试策略。其创新点在于将多目标优化算法应用于生成测试用例，以探索自适应触发条件。未来的工作可能包括探索更广泛的触发条件或将该方法应用于其他类型的自主系统。

<details>
  <summary>Details</summary>

**Motivation:** 在海上自主船舶（AVs）的设计中，理解和识别应触发自适应行为的设置至关重要，这有助于验证其实现。本文关注AVs的导航软件，该软件在操作过程中必须通过自适应来调整其行为。

**Method:** 提出了一种名为WPgen的多目标搜索方法，用于对预定义的航路点进行微小修改。该方法旨在使修改后的航路点尽可能接近原始航路点，同时导致AV在使用生成航路点导航时出现不当行为，从而触发自适应。WPgen使用NSGA-II作为多目标搜索算法，并结合了三种初始种群的播种策略，形成了三种WPgen变体。

**Result:** 在三艘AVs（一艘水面油轮和两艘水下航行器）上评估了这些变体。实验结果表明，这些变体的有效性因AV的不同而异。将WPgen的三种变体与随机搜索基线以及彼此进行了比较。

**Conclusion:** 基于实验结果，本文提出了WPgen的研究和实际意义。

> **ai_Abstract:** 本文提出了一种名为WPgen的多目标搜索方法，旨在为海上自主船舶（AVs）生成微调的航路点。这些修改后的航路点旨在触发AV的自适应行为，通过使其在导航时表现出不当行为来实现。WPgen利用NSGA-II算法和三种不同的初始种群播种策略。研究在三艘不同的AVs上对WPgen的变体进行了评估，并与随机搜索进行了比较。实验结果显示，WPgen的有效性因AV类型而异。该研究强调了WPgen在理解和验证AVs自适应能力方面的潜力和实际意义。

> **摘要翻译:** 海上自主船舶（AVs）的自适应使其能够调整行为以应对意外情况，同时保持可靠性要求。在此类AVs的设计过程中，理解和识别应触发自适应的设置至关重要，这有助于验证其实现。为此，我们关注AVs的导航软件，该软件在操作过程中必须通过自适应来调整其行为。AVs通常依赖预定义的航路点来引导它们沿指定路线航行，确保安全导航。我们提出了一种名为WPgen的多目标搜索方法，用于对预定义的航路点进行微小修改，使其尽可能接近原始航路点，同时导致AV在使用生成航路点导航时出现不当行为。WPgen使用NSGA-II作为多目标搜索算法，并结合了三种初始种群的播种策略，形成了WPgen的三种变体。我们在三艘AVs（一艘水面油轮和两艘水下航行器）上评估了这些变体。我们将WPgen的三种变体与随机搜索作为基线以及彼此进行了比较。实验结果表明，这些变体的有效性因AV的不同而异。基于这些结果，我们提出了WPgen的研究和实际意义。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [486] [Improving Code LLM Robustness to Prompt Perturbations via Layer-Aware Model Editing](https://arxiv.org/abs/2507.16407)
> *通过层感知模型编辑提高代码大型语言模型对提示扰动的鲁棒性*

*Shuhan Liu, Xing Hu, Kerui Huang, Xiaohu Yang, David Lo, Xin Xia* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 代码LLM, 鲁棒性, 提示扰动, 模型编辑, 层感知

**Comment:** 

> **TL;DR:** 本文提出CREME，一种通过识别并编辑鲁棒性敏感层来提高代码LLM对提示扰动鲁棒性的方法，显著提升了扰动提示下的代码生成准确性。

**AI_Comments:** 本文提出了一种新颖且实用的方法，通过有选择地编辑模型层来提高代码LLM的鲁棒性，而非进行全面的模型训练。其创新点在于识别出模型中对鲁棒性影响最大的特定层，并仅对这些层进行轻量级编辑，这显著降低了计算成本。该方法在实际应用中具有重要意义，因为它解决了LLM在面对常见提示扰动时的性能不稳定性问题。对鲁棒性敏感层位置的洞察也为未来的模型设计和鲁棒性研究提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在代码生成方面表现出色，但对提示扰动高度敏感，微小修改即可显著降低代码生成正确性。在实际应用中，扰动频繁发生，因此提高LLM对提示扰动的鲁棒性对于确保代码生成性能的可靠性至关重要。

**Method:** 本文提出CREME（Code Robustness Enhancement via Model Editing），一种通过目标参数更新增强LLM鲁棒性的新方法。CREME首先通过比较原始提示及其扰动变体之间的隐藏状态来识别鲁棒性敏感层，然后对识别出的层进行轻量级参数编辑以减少性能下降。

**Result:** CREME在扰动提示上将Pass@1准确率提高了63%，同时在干净输入上保持性能稳定，准确率偏差在1%以内。进一步分析表明，鲁棒性敏感层主要集中在网络的中间和深层，并且其位置因模型架构而异。

**Conclusion:** CREME通过层感知模型编辑显著提高了代码LLM对提示扰动的鲁棒性，为未来开发面向鲁棒性的编辑策略提供了有价值的基础。鲁棒性敏感层的位置洞察对于未来的研究具有指导意义。

> **ai_Abstract:** 本文提出了一种名为CREME的新型方法，旨在通过层感知模型编辑来提高代码大型语言模型（LLM）对提示扰动的鲁棒性。鉴于LLM在代码生成中对提示微小改变的敏感性，CREME通过比较原始和扰动提示的隐藏状态来识别鲁棒性敏感层，并在这些层进行参数编辑以减轻性能下降。在HumanEval和MBPP基准测试上的实验结果显示，CREME在扰动提示上将Pass@1准确率显著提高了63%，同时对干净输入的性能影响微乎其微。研究还发现鲁棒性敏感层主要位于网络的中间和深层，且位置随模型架构而异，为未来的鲁棒性增强策略提供了重要见解。

> **摘要翻译:** 大型语言模型（LLM）在代码生成方面表现出令人印象深刻的能力，其中自然语言提示在向模型传达用户意图方面起着关键作用。然而，先前的研究表明LLM对提示扰动高度敏感。措辞、语法或格式的微小修改可以显著降低生成代码的功能正确性。由于扰动在实际场景中频繁发生，提高LLM对提示扰动的鲁棒性对于确保实际代码生成中可靠的性能至关重要。在本文中，我们引入了CREME（Code Robustness Enhancement via Model Editing），一种通过有针对性的参数更新来增强LLM鲁棒性的新方法。CREME首先通过比较原始提示及其扰动变体之间的隐藏状态来识别鲁棒性敏感层。然后，它在识别出的层上执行轻量级参数编辑以减少性能下降。我们在两个广泛使用的代码生成基准（HumanEval和MBPP）及其扰动对应物上评估了CREME。实验结果表明，CREME在扰动提示上将Pass@1准确率提高了63%，同时在干净输入上保持性能稳定，准确率偏差在1%以内。进一步分析表明，鲁棒性敏感层主要集中在网络的中间和深层，并且它们的位置因不同的模型架构而异。这些见解为开发未来面向鲁棒性的编辑策略提供了宝贵的基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [534] [Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code](https://arxiv.org/abs/2507.16439)
> *探索大型语言模型在分析和改进科学代码中方法名方面的应用*

*Gunnar Larsen, Carol Wong, Anthony Peruma* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 科学代码, 方法名, 代码分析, Jupyter Notebooks

**Comment:** The 19th ACM/IEEE International Symposium on Empirical Software
  Engineering and Measurement - Emerging Results and Vision Track

> **TL;DR:** 本研究评估了LLM在分析和改进科学代码方法名方面的能力，发现它们在语法上有效但对领域术语处理不一致，仍需人工评估。

**AI_Comments:** 这项研究创新性地将大型语言模型应用于科学代码的方法名分析和改进，填补了该领域研究的空白。它揭示了LLM在代码命名规范化方面的潜力，同时也指出了当前LLM在处理领域专业知识和达到人类水平一致性方面的局限性，为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 研究科学家日益依赖软件支持研究，但科学软件中标识符（特别是方法名）质量对程序理解的影响研究有限。大型语言模型（LLMs）的最新进展为自动化代码分析任务提供了新机遇。

**Method:** 本研究评估了四种流行的大型语言模型，测试它们分析语法模式和建议改进从Python-based Jupyter Notebooks中提取的496个方法名的能力。

**Result:** 大型语言模型在分析方法名方面有一定效果，并且普遍遵循良好的命名规范（如以动词开头）。然而，它们在处理领域特定术语方面表现不一致，并且与人工标注的一致性中等。

**Conclusion:** 自动化建议仍需要人工评估。本工作为通过AI自动化提高科学代码质量提供了基础性见解。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在分析和改进科学代码中方法名方面的应用。通过评估四种LLMs对496个Python方法名的处理能力，发现LLMs在语法分析和遵循命名规范方面表现出一定效果，但面对领域特定术语时表现不佳，且与人工标注的一致性中等。研究强调了LLMs在科学代码质量提升方面的潜力，但也指出自动化建议仍需人工干预。

> **摘要翻译:** 研究科学家越来越依赖软件实现来支持他们的研究。尽管之前的研究已经探讨了传统编程环境中标识符名称对程序理解的影响，但在科学软件领域，尤其是在代码中方法名的质量方面，相关工作却很有限。大型语言模型（LLM）的最新进展为自动化代码分析任务（如标识符名称评估和推荐）带来了新的机遇。我们的研究评估了四种流行的大型语言模型分析语法模式和建议改进从基于Python的Jupyter Notebooks中提取的496个方法名的能力。我们的发现表明，大型语言模型在分析这些方法名方面具有一定的有效性，并且通常遵循良好的命名规范，例如方法名以动词开头。然而，它们对领域特定术语处理的不一致以及与人工标注的一致性仅为中等，表明自动化建议仍需要人工评估。这项工作为通过AI自动化提高科学代码质量提供了基础性见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [582] [On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization](https://arxiv.org/abs/2507.16587)
> *关于LLM作为法官在代码生成和摘要中的有效性*

*Giuseppe Crupi, Rosalia Tufano, Alejandro Velasco, Antonio Mastropaolo, Denys Poshyvanyk, Gabriele Bavota* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** LLM-as-a-judge, 代码生成, 代码摘要, GPT-4-turbo, 评估

**Comment:** Accepted at TSE. IEEE Transactions on Software Engineering

> **TL;DR:** 大型语言模型（LLM）作为法官被用于评估代码生成和摘要任务，以克服定量指标不足和人工评估成本高昂的问题。研究发现GPT-4-turbo是表现最佳的LLM，但即使是它也经常出现误判，而较小的LLM则无法胜任。

**AI_Comments:** 本文探讨了LLM作为法官在代码相关任务中的创新应用，旨在克服传统评估方法的局限性。其重要性在于揭示了LLM在此类任务中的潜力及当前局限性，特别是GPT-4-turbo的表现。局限性在于即使是最佳模型也常误判，表明LLM-as-a-judge仍需进一步提升可靠性，且小型LLM在此方面表现不佳。

<details>
  <summary>Details</summary>

**Motivation:** 传统定量指标不足以评估代码生成和摘要的质量，且大规模人工评估成本高昂。LLM作为法官可以提供一种新的自动化评估方式，并可能促进LLM之间的协作来解决复杂任务。

**Method:** 研究评估了LLM作为法官在代码生成和代码摘要任务中的有效性。对于代码生成，检查了8个LLM判断1,405个Java方法和1,281个Python函数正确性的能力。对于代码摘要，比较了5个LLM与9个人类对约1.2k个Java和Python函数摘要的判断。

**Result:** GPT-4-turbo是两项任务中判断能力最好的LLM。参数量为数百亿的“较小”LLM无法胜任判断任务。即使是表现最好的LLM也频繁错误判断代码的正确性和摘要的质量。

**Conclusion:** GPT-4-turbo在代码生成和摘要的判断能力方面表现最佳，但其判断准确性仍有局限性，经常出现误判。较小的LLM在此类判断任务中表现不佳。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）作为“法官”在代码生成和代码摘要任务中的有效性。由于定量指标不足且人工评估成本高昂，LLM-as-a-judge被提出作为一种评估复杂NLP任务输出质量的方法。研究评估了不同LLM（包括GPT-4-turbo和较小模型）在判断Java和Python代码的正确性以及代码摘要质量方面的能力。结果显示，GPT-4-turbo是表现最佳的判断LLM，但即使是它也经常出现误判，而较小的LLM则无法胜任这些判断任务。

> **摘要翻译:** 大型语言模型最近被用作复杂自然语言处理任务（如问答）的“法官”。其基本思想是将自动化技术在特定任务中提供的输出“质量”评估委托给LLM，这些任务的特点是：(i) 定量指标只能说明部分情况；(ii) 大规模的人工评估过于昂贵。如果LLM作为法官被证明对特定任务有效，它还可以开启自动化新的可能性，即多个LLM为给定任务实例提出解决方案，而其他LLM则判断并决定向用户展示哪个最佳输出。我们研究了LLM作为法官在两个与代码相关的任务——代码生成和代码摘要中的有效性。选择这些任务的理由有两方面。首先，定量指标通常不足以评估代码摘要器/生成器。例如，有充分证据表明BLEU等指标对于生成摘要的质量来说是相当弱的代理。其次，即使是最先进的技术在处理这些任务的复杂实例时仍然面临困难，这使得它们成为受益于更先进的LLM协作解决方案的良好候选。对于代码生成，我们检查了八个LLM是否能够判断1,405个Java方法和1,281个Python函数的正确性，这些方法和函数由相同的LLM生成或由人类实现。对于代码摘要，我们比较了五个LLM的判断与九个人类对约1.2k个摘要的判断，这些摘要涉及Java和Python函数。我们的研究结果表明，GPT-4-turbo在两项任务的判断能力方面是最好的LLM，而拥有数百亿参数的“较小”LLM无法胜任判断任务。然而，即使是表现最好的LLM也经常错误判断代码的正确性和摘要的质量。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [630] [VulCoCo: A Simple Yet Effective Method for Detecting Vulnerable Code Clones](https://arxiv.org/abs/2507.16661)
> *VulCoCo: 一种简单但有效的漏洞代码克隆检测方法*

*Tan Bui, Yan Naing Tun, Thanh Phuc Nguyen, Yindu Su, Ferdian Thung, Yikun Li, Han Wei Ang, Yide Yin, Frank Liauw, Lwin Khin Shar, Eng Lieh Ouh, Ting Zhang, David Lo* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 漏洞代码克隆, 大型语言模型, 嵌入式检索, 代码安全, 漏洞检测

**Comment:** 

> **TL;DR:** VulCoCo是一种结合嵌入式检索和LLM验证的轻量级可扩展方法，用于检测漏洞代码克隆，在基准测试中优于现有方法，并在真实世界项目中成功识别了新的漏洞。

**AI_Comments:** VulCoCo的创新之处在于结合了嵌入式检索和大型语言模型进行漏洞评估，这提供了一种更深层次的语义理解能力，超越了传统的句法相似性方法。其重要性体现在不仅在合成基准上取得了优异性能，更在真实世界的开源项目中成功识别并修复了大量漏洞，直接产生了实际影响。这种将LLM应用于代码安全领域的方法，为未来的漏洞检测工具开发提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 代码复用在现代软件开发中很常见，但当开发者无意中复制了有风险的代码时，也可能传播漏洞。检测漏洞代码克隆（VCCs）是一项关键但具有挑战性的任务。现有工具通常依赖句法相似性或产生粗略的漏洞预测，缺乏明确解释，限制了其实用性。

**Method:** VulCoCo是一种轻量级且可扩展的方法，它结合了基于嵌入的检索和大型语言模型（LLM）验证。该方法从一组已知漏洞函数开始，从大型语料库中检索语法或语义相似的候选函数，并使用LLM评估这些候选函数是否保留了漏洞。研究者还构建了一个涵盖各种克隆类型的合成基准。

**Result:** 在合成基准测试中，VulCoCo在Precision@k和平均精度（MAP）方面优于现有的最新方法。此外，在真实世界的项目中，通过向284个开源项目提交400个拉取请求（PRs），其中75个PRs被合并，15个导致了新发布的CVEs。

**Conclusion:** VulCoCo是一种有效且实用的漏洞代码克隆检测方法，在基准测试和真实世界应用中均表现出色，并为未来的改进工作提供了见解。

> **ai_Abstract:** 该论文提出了VulCoCo，一种结合嵌入式检索和大型语言模型（LLM）验证的轻量级可扩展方法，用于检测漏洞代码克隆（VCCs）。针对现有VCC检测工具的局限性，VulCoCo通过从已知漏洞函数检索相似代码并利用LLM进行漏洞评估。研究者构建了一个合成基准进行实验，结果显示VulCoCo在Precision@k和MAP上优于现有方法。此外，VulCoCo在真实世界项目中也表现出有效性，成功识别并促成了新CVE的发布。

> **摘要翻译:** 代码复用在现代软件开发中很常见，但当开发者无意中复制了有风险的代码时，也可能传播漏洞。保留已知漏洞逻辑的代码片段被称为漏洞代码克隆（VCCs）。检测这些VCCs是一项关键但具有挑战性的任务。现有的VCC检测工具通常依赖句法相似性或产生粗略的漏洞预测，缺乏明确解释，限制了其实用性。在本文中，我们提出了VulCoCo，一种轻量级且可扩展的方法，它结合了基于嵌入的检索和大型语言模型（LLM）验证。从一组已知漏洞函数开始，我们从大型语料库中检索语法或语义相似的候选函数，并使用LLM评估这些候选函数是否保留了漏洞。鉴于目前缺乏可复现的漏洞代码克隆基准，我们首先构建了一个涵盖各种克隆类型的合成基准。我们在基准上的实验表明，VulCoCo在Precision@k和平均精度（MAP）方面优于现有的最新方法。此外，我们还通过向284个开源项目提交400个拉取请求（PRs）来证明VulCoCo在真实世界项目中的有效性。其中，75个PRs被合并，15个导致了新发布的CVEs。我们还提供了见解，以启发未来的工作，进一步提高漏洞代码克隆检测的精度。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [672] [VulGuard: An Unified Tool for Evaluating Just-In-Time Vulnerability Prediction Models](https://arxiv.org/abs/2507.16685)
> *VulGuard：一个用于评估即时漏洞预测模型的统一工具*

*Duong Nguyen, Manh Tran-Duc, Thanh Le-Cong, Triet Huynh Minh Le, M. Ali Babar, Quyet-Thang Huynh* | **Category: cs.SE** | **Updated: 2025-07-22**

**Keywords:** 即时漏洞预测, 软件安全, 自动化工具, 可复现性, 可扩展性

**Comment:** 

> **TL;DR:** VulGuard是一个自动化工具，用于简化即时漏洞预测研究中GitHub提交的提取、处理和分析，并支持模型评估和比较，提高研究的可复现性和可扩展性。

**AI_Comments:** VulGuard的创新之处在于提供了一个统一且自动化的框架，将JIT-VP的数据挖掘与模型评估相结合，有效解决了该领域长期存在的复现性和可扩展性问题。其易于集成到CI/CD管道的特性也凸显了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是简化和改进即时漏洞预测（JIT-VP）研究，通过解决数据提取、处理、分析、模型评估、可复现性和可扩展性方面的关键挑战。

**Method:** VulGuard通过自动挖掘提交历史、提取细粒度代码变更、提交消息和软件工程指标，并将其格式化以供后续分析。此外，它还集成了多种最先进的漏洞预测模型，允许研究人员以最少的设置进行模型训练、评估和比较。它在一个统一框架内支持仓库级挖掘和模型级实验。

**Result:** 该工具在FFmpeg和Linux内核这两个有影响力的开源项目中展示了其有效性，突出了其加速实际JIT-VP研究和促进标准化基准测试的潜力。

**Conclusion:** VulGuard是一个有效的统一工具，它简化了即时漏洞预测（JIT-VP）研究中的数据处理和模型评估，显著提高了软件安全研究的可复现性和可扩展性，并有助于推广标准化基准测试。

> **ai_Abstract:** VulGuard是一个自动化工具，旨在简化即时漏洞预测（JIT-VP）研究中的GitHub提交数据处理和模型评估。它能够自动挖掘提交历史、提取代码变更和软件工程指标，并整合了先进的漏洞预测模型，以支持研究人员进行训练、评估和比较。该工具通过提供统一框架来解决软件安全研究中可复现性和可扩展性的挑战，并已在FFmpeg和Linux内核项目中得到有效验证，有助于加速JIT-VP研究和标准化基准测试。

> **摘要翻译:** 我们提出了VulGuard，一个自动化工具，旨在简化GitHub仓库中提交的提取、处理和分析，用于即时漏洞预测（JIT-VP）研究。VulGuard自动挖掘提交历史，提取细粒度代码变更、提交消息和软件工程指标，并将其格式化以供下游分析。此外，它集成了几种最先进的漏洞预测模型，允许研究人员以最少的设置训练、评估和比较模型。通过在一个统一框架内支持仓库级挖掘和模型级实验，VulGuard解决了软件安全研究中可复现性和可扩展性的关键挑战。VulGuard还可以轻松集成到CI/CD管道中。我们在两个有影响力的开源项目FFmpeg和Linux内核中展示了该工具的有效性，突出了其加速实际JIT-VP研究和促进标准化基准测试的潜力。演示视频可在以下网址观看：https://youtu.be/j96096-pxbs

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [709] [Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support](https://arxiv.org/abs/2507.16754)
> *永不落空：自适应HyDE检索以改进LLM开发者支持*

*Fangjian Lei, Mariam El Mezouar, Shayan Noei, Ying Zou* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-22**

**Keywords:** RAG, LLM, HyDE, 开发者支持, Stack Overflow

**Comment:** 

> **TL;DR:** 该研究通过构建大型Stack Overflow语料库并设计自适应RAG管道，显著提升了LLM在开发者问答中的回答质量和可靠性。

**AI_Comments:** 该论文的创新点在于构建了大规模的开发者问答语料库，并系统地评估了多种RAG管道设计。尤其值得注意的是，其提出的自适应HyDE检索方法，通过动态降低相似性阈值来处理新颖问题，有效提升了RAG在“永不落空”方面的能力，即提高了对未见查询的覆盖率。这对于提升LLM在实际开发支持场景中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在辅助开发者解决代码问题方面显示出潜力，但存在生成不可靠答案的风险（即幻觉）。为了解决这一问题，研究者提出了检索增强生成（RAG），但设计有效的RAG管道仍具挑战性。

**Method:** 构建了一个包含超过300万条带有公认答案的Java和Python相关Stack Overflow帖子的检索语料库。设计并评估了7种不同的RAG管道和63种变体，以回答历史上相似的问题。通过在检索时自动降低相似性阈值来处理没有紧密匹配的新问题，以增加找到部分相关上下文的机会。发现结合假设文档嵌入（HyDE）和完整答案上下文的RAG管道在检索和回答Stack Overflow问题方面表现最佳。将优化后的RAG管道应用于4个开源LLM并与它们的零样本性能进行比较。

**Result:** 结合假设文档嵌入（HyDE）和完整答案上下文的RAG管道在检索和回答Stack Overflow问题方面表现最佳。带有优化RAG管道的LLM在有用性、正确性和细节方面持续优于零样本基线，这通过LLM作为评估者获得更高分数验证。

**Conclusion:** 研究结果表明，本文提出的优化RAG管道能够稳定地提升LLM在各种开发者查询（包括已见和新颖问题）上的回答质量，并适用于不同的LLM。

> **ai_Abstract:** 本论文旨在提升大型语言模型（LLMs）在开发者支持中的可靠性，通过构建一个包含数百万Stack Overflow帖子的检索语料库，并深入探索多种检索增强生成（RAG）管道设计。研究发现，结合假设文档嵌入（HyDE）和完整答案上下文的自适应RAG管道表现最佳，尤其在处理新颖问题时能通过动态调整相似度阈值来提升覆盖率。实验证明，该优化RAG管道显著优于LLM的零样本性能，在回答开发者问题方面展现出更高的准确性、有用性和细节。

> **摘要翻译:** 大型语言模型（LLMs）在辅助开发者解决代码相关问题方面显示出潜力；然而，LLMs存在生成不可靠答案的风险。为了解决这个问题，研究者提出了检索增强生成（RAG）以减少LLMs的不可靠性（即幻觉）。然而，由于众多的设计选择，设计有效的管道仍然具有挑战性。在本文中，我们构建了一个包含超过300万条带有公认答案的Java和Python相关Stack Overflow帖子的检索语料库，并探索了各种RAG管道设计来回答开发者问题，评估它们在生成准确可靠响应方面的有效性。更具体地说，我们（1）设计并评估了7种不同的RAG管道和63种管道变体，以回答历史上具有相似匹配的问题，以及（2）通过在检索时自动降低相似性阈值来处理没有任何接近先前匹配的新问题，从而增加找到部分相关上下文的机会，并提高对未见案例的覆盖率。我们发现，实施一个结合假设文档嵌入（HyDE）和完整答案上下文的RAG管道在检索和回答Stack Overflow相似内容问题方面表现最佳。最后，我们将我们最优的RAG管道应用于4个开源LLMs，并将其结果与它们的零样本性能进行比较。我们的发现表明，我们的最优RAG管道在所有模型上始终优于零样本基线，通过LLM作为评估者，在有用性、正确性和细节方面获得了更高的分数。这些发现表明，我们最优的RAG管道能够稳健地提高各种开发者查询的答案质量，包括先前见过和新颖的问题，并适用于不同的LLMs。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [211] [Belief Alignment vs Opinion Leadership: Understanding Cross-linguistic Digital Activism in K-pop and BLM Communities](https://arxiv.org/abs/2507.16046)
> *信念对齐 vs 意见领袖：理解K-pop和BLM社区中的跨语言数字行动主义*

*Yuheun Kim, Joshua Introne* | **Category: cs.SI** | **Updated: 2025-07-21**

**Keywords:** 信念对齐, 意见领袖, 数字行动主义, K-pop, BLM

**Comment:** 11 pages, 5 figures, Accepted for International AAAI Conference on
  Web and Social Media (ICWSM) 2026

> **TL;DR:** 本研究发现，跨文化数字行动主义的主要驱动力是信念对齐，而非意见领袖，尽管意见领袖可以起到放大作用。

**AI_Comments:** 本研究创新性地将信念对齐而非意见领袖作为跨文化数字行动主义的主要驱动力，这为理解全球社会运动提供了新的视角。其重要性在于揭示了数字时代下，共同价值观和信念在促进跨文化合作中的核心作用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对社交媒体在跨文化行动主义中的作用进行了广泛研究，但推动这些全球运动的基本动机仍然知之甚少。

**Method:** 本研究对乔治·弗洛伊德被谋杀后，K-pop粉丝和“黑人的命也是命”(BLM)运动在Twitter上的互动进行了案例研究。

**Result:** 研究结果提供了强有力的证据，表明信念对齐是数字行动主义中跨文化互动的主要驱动力。虽然潜在意见领袖（如K-pop艺人）的行为可能放大行动主义，但他们似乎不是行动主义的直接原因。研究还初步表明，BLM和K-pop之间的互动导致了他们总体信念相似度的轻微增加。

**Conclusion:** 信念对齐是跨文化数字行动主义的主要驱动力，而意见领袖的作用更多是放大而非直接引发行动。此外，互动可以促进信念相似度的增加。

> **ai_Abstract:** 本研究探讨了跨文化数字行动主义的驱动因素，通过对K-pop粉丝和BLM运动在Twitter上互动的案例研究，发现信念对齐是主要的推动力。研究表明，尽管意见领袖（如K-pop艺人）可能放大行动主义，但他们并非直接原因。此外，这种互动还能略微增加参与者之间的信念相似度。

> **摘要翻译:** 互联网改变了行动主义，催生了更多有机、多样化和动态的社会运动，这些运动超越了地缘政治界限。尽管对社交媒体和互联网在跨文化行动主义中的作用进行了广泛研究，但推动这些全球运动的基本动机仍然知之甚少。本研究检验了跨文化行动主义的两种可能解释：第一，它是由有影响力的在线意见领袖驱动的；第二，它源于个体对新兴信念、价值观和规范的共鸣。我们对乔治·弗洛伊德被谋杀后，K-pop粉丝和“黑人的命也是命”(BLM)运动在Twitter上的互动进行了案例研究。我们的发现提供了强有力的证据，表明信念对齐（即人们与共同信念产生共鸣）是数字行动主义中跨文化互动的主要驱动力。我们还表明，虽然潜在意见领袖（在本例中为K-pop艺人）的行为可能放大行动主义并导致粉丝进一步表达爱和钦佩，但他们似乎不是行动主义的直接原因。最后，我们报告了一些初步证据，表明BLM和K-pop之间的互动导致了他们总体信念相似度的轻微增加。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [265] [WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections](https://arxiv.org/abs/2507.16298)
> *WhatsApp举报热线与2021年印度议会选举中的多语言虚假信息*

*Gautam Kishore Shahi, Scot A. Hale* | **Category: cs.SI, cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-22**

**Keywords:** WhatsApp举报热线, 虚假信息, 印度议会选举, 事实核查, 多语言分析

**Comment:** 

> **TL;DR:** 该研究分析了2021年印度议会选举期间WhatsApp举报热线中的多语言虚假信息举报，发现不同语言间举报内容相似，且事实核查机构有各自独立的用户群。

**AI_Comments:** 该研究通过对真实世界数据的深入分析，揭示了WhatsApp举报热线在打击多语言虚假信息方面的运作模式和挑战。其创新之处在于结合了语言学分析和用户行为模式，特别关注了高低资源语言的差异。研究结果对于改进未来选举期间的虚假信息打击策略具有重要实践意义，尤其是在处理多语言环境和协调不同事实核查机构方面。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在分析WhatsApp举报热线在2021年印度议会选举期间打击虚假信息的作用，特别关注多语言举报的特点、事实核查过程以及用户行为。

**Method:** 本研究采用混合方法，分析了来自451名用户的580条独特举报（tips），涵盖英语、印地语和泰卢固语。研究将举报分为选举、COVID-19和其他三类，并观察语言间的差异。通过高频词分析和神经网络句子嵌入聚类比较内容相似性，并调查了用户在不同语言和事实核查机构之间的重叠情况。同时测量了澄清举报和通知用户所需的时间。

**Result:** 结果显示，不同语言间的举报内容存在相似性，部分用户以多种语言向相同的事实核查机构提交举报。事实核查机构通常需要几天时间来澄清新的举报并与用户分享结果。值得注意的是，没有用户向多个事实核查机构提交举报，表明每个机构都拥有独特的受众。

**Conclusion:** 本研究为在选举期间使用举报热线提供了实用建议，并强调了对用户信息的伦理考量。主要结论包括：举报内容跨语言相似，事实核查耗时几天，且各事实核查机构拥有独立的用户群。

> **ai_Abstract:** 这项研究分析了2021年印度议会选举期间WhatsApp举报热线中用户提交的580条多语言虚假信息举报。研究通过混合方法，对选举、COVID-19等类别的举报内容进行分类和相似性分析，并调查用户行为和事实核查效率。结果表明，不同语言间的举报内容相似，事实核查通常需要数日，且各事实核查机构拥有独立的受众群。研究最终提出了在选举中使用举报热线的实用建议。

> **摘要翻译:** WhatsApp举报热线于2019年首次推出，旨在打击虚假信息，使用户能够与事实核查人员互动以验证误导性内容。本研究采用混合方法，分析了2021年印度议会选举期间来自451名用户的580条独特举报（tips），涵盖高资源语言（英语、印地语）和低资源语言（泰卢固语）。我们将举报分为选举、COVID-19和其他三类，并观察到语言间的差异。我们通过高频词分析和神经网络句子嵌入聚类来比较内容相似性。我们还调查了用户在不同语言和事实核查机构之间的重叠情况。我们测量了澄清举报和通知举报热线用户所需的平均时间。结果显示，不同语言间的举报存在相似性，一些用户以多种语言向相同的事实核查机构提交举报。事实核查人员通常需要几天时间来澄清新的举报并与用户分享结果。值得注意的是，没有用户向多个事实核查机构提交举报，这表明每个机构都拥有独特的受众。我们为在选举期间使用举报热线提供了实用建议，并对用户信息进行了伦理考量。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [296] [SASH: Decoding Community Structure in Graphs](https://arxiv.org/abs/2507.16583)
> *SASH：图中的社区结构解码*

*Allison Beemer, Jessalyn Bolkema* | **Category: cs.SI, cs.IT, math.CO, math.IT** | **Updated: 2025-07-22**

**Keywords:** 社区检测, 图结构, SASH算法, 纠错码, 仿真

**Comment:** 5 pages, to appear in the proceedings of the International Symposium
  on Topics in Coding 2025

> **TL;DR:** 提出了一种新算法SASH，通过编码社区结构并将其视为纠错码问题来解码图中的社区。

**AI_Comments:** 本文的创新点在于将图社区检测问题与纠错码领域相结合，并提出了一个新颖的算法SASH。这种编码视角为社区结构分析提供了一个新的理论框架和实用的解码方法。

<details>
  <summary>Details</summary>

**Motivation:** 图中的社区检测是一个重要且应用广泛的问题。以往的研究将该问题置于纠错码的范畴内，将图视为假定底层社区的噪声版本。

**Method:** 引入了社区结构的编码及其参数，并提出了一种新颖的算法SASH，用于根据观测数据集解码估计的社区。

**Result:** 通过在同配种植分区模型和Zachary空手道俱乐部数据集上的仿真，验证了SASH算法的性能。

**Conclusion:** SASH算法在社区检测问题上表现出有效性，并通过模拟得到了验证。

> **ai_Abstract:** 本文提出了一种名为SASH的新型算法，用于解码图中的社区结构。该方法将社区结构视为一种编码问题，并引入了社区编码及其参数。SASH算法旨在从观测数据中估计出社区，并通过在同配种植分区模型和Zachary空手道俱乐部数据集上的仿真验证了其性能。

> **摘要翻译:** 图中的社区检测需要识别密集连接顶点的聚类；该领域具有各种重要的应用和丰富的文献。该问题之前已被置于纠错码的范畴内，通过将图视为假定底层社区的噪声版本。在本文中，我们引入了社区结构的编码以及由此产生的代码参数。然后，我们提出了一种新颖的算法SASH，用于在给定观测数据集的情况下解码到估计的社区。我们通过在同配种植分区模型和Zachary空手道俱乐部数据集上的仿真来证明SASH的性能。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [390] [Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation](https://arxiv.org/abs/2405.19383)
> *反洗钱的网络分析——系统文献综述与实验评估*

*Bruno Deprez, Toon Vanderschueren, Bart Baesens, Tim Verdonck, Wouter Verbeke* | **Category: cs.SI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 反洗钱, 网络分析, 文献综述, 深度学习, 欺诈检测

**Comment:** 

> **TL;DR:** 本文对反洗钱（AML）领域的网络分析方法进行了系统性文献综述和实验评估，指出了现有研究的不足，并比较了不同方法的性能和局限性。

**AI_Comments:** 本文的创新之处在于提供了一个急需的、全面的反洗钱网络分析系统文献综述，填补了现有文献分散的空白。其实验评估部分具有重要的实践指导意义，特别指出了GNN在特定条件下的局限性以及合成数据的潜在误导性。提供的开源实现对于推动该领域的标准化和可复现研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 洗钱是一个普遍存在的社会问题，通过资助非法活动造成负担。尽管利用网络信息打击洗钱的研究激增，但现有文献分散，缺乏对方法的全面概述和比较性检测能力的理解。

**Method:** 本文首先基于Web of Science和Scopus的97篇论文，进行了一项广泛的系统文献综述，并构建了一个遵循欺诈分析框架的分类法。其次，提出了一个全面的框架，用于在标准化设置中评估和比较主要的反洗钱网络分析方法，包括手动特征工程、基于随机游走和深度学习方法，并在两个公开数据集上进行了实验验证。

**Result:** 文献综述发现，大多数研究依赖于专家规则和手动特征，而深度学习方法正日益受到关注。实验评估结果表明：（1）网络分析确实增加了预测能力；（2）但在面对类别不平衡和网络拓扑时，应用图神经网络（GNNs）需要谨慎；（3）使用合成数据时应小心，因为它可能导致过于乐观的结果。

**Conclusion:** 网络分析能提高反洗钱的预测能力，但GNN在处理类别不平衡和网络拓扑时需谨慎，且合成数据可能导致结果过于乐观。本文提供的开源实现有助于推动反洗钱网络分析的标准化研究和应用。

> **ai_Abstract:** 本文针对反洗钱（AML）网络分析领域文献分散的问题，进行了一项基于97篇论文的系统性文献综述，并构建了方法分类法。研究发现，现有工作多依赖专家规则和手动特征，深度学习正逐渐兴起。此外，本文提出了一个评估框架，并在公开数据集上对比了手动特征工程、随机游走和深度学习方法的性能。结果显示网络分析能提高预测能力，但使用图神经网络（GNNs）时需注意类别不平衡和网络拓扑问题，同时警示合成数据可能导致乐观偏差。论文还提供了开源实现，旨在促进该领域的标准化研究。

> **摘要翻译:** 洗钱是一个普遍存在的挑战，通过资助非法活动给社会带来负担。鉴于洗钱涉及关联方，网络信息的使用正越来越多地被探索，以有效打击洗钱。这导致了反洗钱（AML）网络分析研究的激增。然而，现有文献是分散的，缺乏对现有工作的全面概述。这导致对应用方法及其比较检测能力的理解有限。本文基于Web of Science和Scopus的97篇论文，进行了一项广泛而独特的文献综述，形成了一个遵循最近提出的欺诈分析框架的分类法。我们得出结论，大多数研究依赖于基于专家规则和手动特征，而深度学习方法已获得关注。本文还提出了一个全面的框架，用于在标准化设置中评估和比较主要方法的性能。我们在两个公开可用的数据集上比较了手动特征工程、基于随机游走和深度学习方法。我们得出结论：（1）网络分析增加了预测能力，但在面对类别不平衡和网络拓扑时应用GNN需要谨慎，并且（2）使用合成数据时应小心，因为这可能导致过于乐观的结果。开源实现有助于研究人员和从业者在专有数据上扩展这项工作，从而促进反洗钱网络分析的标准化方法。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [444] [Why We Experience Society Differently: Intrinsic Dispositions as Drivers of Ideological Complexity in Adaptive Social Networks](https://arxiv.org/abs/2504.07848)
> *我们为何不同地体验社会：内在倾向作为自适应社会网络中意识形态复杂性的驱动因素*

*Akshay Gangadhar, Hiroki Sayama* | **Category: cs.SI, physics.soc-ph** | **Updated: 2025-07-21**

**Keywords:** 意见动力学, 行为异质性, 自适应网络, 意识形态复杂性, Lempel-Ziv 复杂性

**Comment:** 

> **TL;DR:** 研究发现，在自适应社会网络中，个体的内在行为倾向（同质性偏好、新奇性偏好或社会从众性）决定了其意识形态轨迹的复杂性和不可预测性，而非外部环境。

**AI_Comments:** 这项研究通过引入个体层面的行为异质性（同质性偏好、新奇性偏好、社会从众性）来分析意见动力学，突破了传统模型中同质性假设的局限。其创新之处在于揭示了这些内在倾向如何导致反直觉的意见轨迹复杂性，并强调了行为身份在信念系统演化中的核心作用，而非仅仅是外部环境。这为理解社会网络中个体意识形态体验的内生性差异提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 传统意见动力学模型忽视了个体认知倾向的多样性，且最近引入异质性的模型多关注宏观模式，未能深入个体层面理解不平等和个性化动态。本研究旨在解决这一空白，理解内在异质性如何塑造信念演化。

**Method:** 本研究分析了一个自适应社会网络模型，其中每个智能体表现出三种行为倾向之一：同质性偏好、新奇性偏好或社会从众性。使用归一化Lempel-Ziv (nLZ) 复杂性来衡量个体意见轨迹的复杂性。

**Result:** 结果往往是反直觉的：同质性偏好的智能体尽管寻求相似性，却变得越来越不可预测；新奇性偏好的智能体尽管追求新奇，却趋于稳定；从众性智能体则呈现U形轨迹，从早期稳定过渡到后期不可预测。这些模式在不同网络设置中均保持稳健。内部行为倾向而非外部环境主要决定了长期意见的不可预测性。

**Conclusion:** 本研究为意见动力学提供了一个新颖的个体层面视角，表明智能体的行为身份在信念系统演化中起着动态指纹的作用，并在自组织社会系统中导致动态体验的持续差异，即使在结构相似的环境中也是如此。个体对意识形态波动、不确定性或稳定性的体验并非仅仅是环境因素，而是通过其自身的认知倾向内生性地自我构建的。

> **ai_Abstract:** 本文通过一个自适应社会网络模型探讨了内在行为倾向（同质性偏好、新奇性偏好、社会从众性）如何影响个体意见轨迹的复杂性。研究发现，这些倾向导致了反直觉的动态，如同质性偏好者变得不可预测，新奇性偏好者趋于稳定。结果表明，个体的内在认知倾向而非外部环境是决定其意识形态长期不可预测性的主要因素，为理解意见动力学中的个体差异提供了新视角。

> **摘要翻译:** 理解复杂系统中不平等的出现需要关注结构动态和内在异质性。在意见动力学背景下，传统模型依赖于静态快照或假设同质的智能体行为，忽视了多样化的认知倾向如何塑造信念演化。虽然一些最新模型引入了行为异质性，但它们通常侧重于宏观层面模式，忽略了在智能体层面展开的不平等和个体化动态。在本研究中，我们分析了一个自适应社会网络模型，其中每个智能体表现出三种行为倾向之一——同质性偏好、新奇性偏好或社会从众性——并使用归一化Lempel-Ziv (nLZ) 复杂性衡量个体意见轨迹的复杂性。我们发现由此产生的动态往往是反直觉的——同质性偏好的智能体尽管寻求相似性，却变得越来越不可预测；新奇性偏好的智能体尽管追求新奇，却趋于稳定；从众性智能体则呈现U形轨迹，从早期稳定过渡到后期不可预测。更根本的是，这些模式在不同的网络设置中保持稳健，表明内部行为倾向——而非外部环境——主要决定了长期意见的不可预测性。更广泛的含义是，个体对意识形态波动、不确定性或稳定性的体验并非仅仅是环境因素，而是通过其自身的认知倾向内生性地自我构建的。这些结果建立了意见动力学中一种新颖的个体层面视角，其中智能体的行为身份在信念系统演化中起着动态指纹的作用，并在自组织社会系统中导致动态体验的持续差异，即使在结构相似的环境中也是如此。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [493] [MindVote: When AI Meets the Wild West of Social Media Opinion](https://arxiv.org/abs/2505.14422)
> *MindVote：当AI遇上社交媒体意见的狂野西部*

*Xutao Mao, Ezra Xuanru Tao* | **Category: cs.SI** | **Updated: 2025-07-22**

**Keywords:** 意见预测, 社交媒体, 大型语言模型, 基准, 跨文化

**Comment:** 

> **TL;DR:** 该论文介绍了MindVote，一个用于评估大型语言模型在社交媒体民意调查中真实意见预测能力的新基准，揭示了当前模型在领域适应、文化理解和语境依赖方面的局限性。

**AI_Comments:** MindVote的创新之处在于它是第一个旨在整合领域适应、文化图式和语境支架的基准，用于社交媒体意见预测。其利用Reddit和微博上的真实数据，使其在现实世界中具有高度相关性。研究结果揭示了当前大型语言模型在深层社会和文化理解方面的关键局限性，超越了简单的翻译问题，强调了开发更具社会基础的AI系统的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有意见预测基准未能整合领域适应、文化图式激活和语境支架这三种认知能力，导致在评估真实社会理解方面存在关键空白，尤其是在基于投票的设置中。

**Method:** 我们引入了MindVote，这是第一个在自然社交媒体语境中评估投票预测的基准。MindVote由Reddit和微博上的3,918个真实投票构建而成，并包含了传统基于调查的基准所忽略的丰富语境元数据。我们通过评估揭示了理论现象。

**Result:** 评估揭示了三个理论现象：正式语篇特权（模型在机构语篇上的表现优于本土语篇）、语义空间殖民（性能偏向英语内容，超出翻译影响）和语境支架依赖性（移除社会语境后性能下降）。

**Conclusion:** 这些发现揭示了模型的局限性，弥补了当前意见预测基准的不足，并倡导开发具有真实跨文化意见预测能力的社会化AI系统。

> **ai_Abstract:** MindVote是第一个旨在评估大型语言模型（LLMs）在社交媒体民意调查中进行真实意见预测能力的基准，它整合了领域适应、文化图式和语境支架等认知能力。该基准基于Reddit和微博上的3,918个真实投票构建，并包含丰富的语境元数据。通过评估，研究揭示了当前LLMs的三个局限性：在正式语篇上表现更好、偏向英语内容以及依赖于社会语境。这些发现强调了开发具有真实跨文化意见预测能力的社会化AI系统的重要性。

> **摘要翻译:** 在社会语境中进行真实的意见预测提出了一个复杂的挑战，需要无缝整合三种不同的认知能力：领域适应、文化图式激活和语境支架。核心难点在于，没有现有的意见预测基准，特别是在基于投票的设置中，能迫使大型语言模型（LLM）整合所有这三种能力，这在评估真正社会理解的能力方面留下了关键空白。借鉴认知科学原理，我们引入了MindVote，这是第一个在自然社交媒体语境中评估投票预测的基准。我们从Reddit和微博上的3,918个真实投票构建了MindVote，并整合了传统基于调查的基准所忽略的丰富语境元数据。我们的评估揭示了三个验证认知科学假设的理论现象：正式语篇特权，即模型在机构语篇上的表现优于本土语篇；语义空间殖民，表明性能偏向英语内容，超出翻译伪影；以及语境支架依赖性，即移除社会语境后性能下降。这些发现揭示了模型的局限性，弥补了当前意见预测基准的不足，并倡导开发具有真实跨文化意见预测能力的社会化AI系统。我们的代码和数据可在https://anonymous.4open.science/r/mindvote-8DBC/获取。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [540] [Multimodal Coordinated Online Behavior: Trade-offs and Strategies](https://arxiv.org/abs/2507.12108)
> *多模态协同在线行为：权衡与策略*

*Lorenzo Mannocci, Stefano Cresci, Matteo Magnani, Anna Monreale, Maurizio Tesconi* | **Category: cs.SI, cs.AI, cs.CY, cs.HC, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 多模态, 协同在线行为, 检测, 权衡, 数字平台

**Comment:** 

> **TL;DR:** 本研究比较了检测多模态协同在线行为的不同方法，探讨了弱集成和强集成多模态模型之间的权衡，并发现多模态方法能更全面地理解协同动态，有助于提升在线协同行为的检测和分析能力。

**AI_Comments:** 本文的创新之处在于其对多模态协同在线行为检测的深入比较分析，特别是探讨了弱集成与强集成多模态模型之间的权衡。其重要性在于，通过提供更全面的理解和检测能力，有助于应对数字平台上的有害协同行为，如虚假信息传播，从而维护平台生态的完整性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单模态方法或独立考虑多种模态的方法，可能忽略多模态协同行为中固有的复杂动态，而这种行为从有益的集体行动到有害的虚假信息传播都普遍存在，是数字生态系统分析的关键焦点。

**Method:** 本研究比较了操作化检测多模态协同行为的不同方法。它考察了弱集成和强集成多模态模型之间的权衡，并比较了单模态和多模态方法，以评估不同数据模态的独特贡献，并探索多模态的不同实现方式如何影响检测结果。

**Result:** 研究结果表明，并非所有模态都能提供独特的见解，但多模态方法能够更全面地理解协同动态。

**Conclusion:** 这项工作增强了检测和分析协同在线行为的能力，为维护数字平台的完整性提供了新视角。

> **ai_Abstract:** 本论文探讨了检测多模态协同在线行为的方法，指出传统单模态方法无法捕捉其复杂性。研究比较了单模态和多模态方法，并分析了弱集成与强集成多模态模型之间的权衡。结果表明，多模态方法能提供对协同动态更全面的理解，从而提升在线协同行为的检测和分析能力，有助于维护数字平台完整性。

> **摘要翻译:** 协同在线行为，从有益的集体行动到有害的操纵（如虚假信息传播），已成为数字生态系统分析的关键焦点。传统方法通常依赖于单模态方法，侧重于单一类型的交互，如共同转发或共同使用标签，或者独立考虑多种模态。然而，这些方法可能会忽略多模态协同中固有的复杂动态。本研究比较了操作化检测多模态协同行为的不同方法。它考察了弱集成和强集成多模态模型之间的权衡，强调了捕捉更广泛协同模式和识别紧密协同行为之间的平衡。通过比较单模态和多模态方法，我们评估了不同数据模态的独特贡献，并探索了多模态的不同实现方式如何影响检测结果。我们的发现表明，并非所有模态都能提供独特的见解，但通过多模态方法，我们可以对协同动态获得更全面的理解。这项工作增强了检测和分析协同在线行为的能力，为维护数字平台的完整性提供了新视角。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [588] [Privacy-Preserving Multimodal News Recommendation through Federated Learning](https://arxiv.org/abs/2507.15460)
> *基于联邦学习的隐私保护多模态新闻推荐*

*Mehdi Khalaj, Shahrzad Golestani Najafabadi, Julita Vassileva* | **Category: cs.SI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 新闻推荐, 联邦学习, 隐私保护, 多模态, 时间感知

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的多模态联邦学习方法，用于解决传统个性化新闻推荐系统中对文本内容过度依赖、忽视短期兴趣以及数据隐私等问题，并通过实验证明其优越性。

**AI_Comments:** 该论文的创新点在于将多模态内容表示、时间感知用户兴趣建模与联邦学习隐私保护机制有效结合。联邦学习框架的设计，特别是将模型分为服务器和客户端共享的部分，以及引入Shamir秘密共享进行安全聚合，是其关键的贡献。这不仅提升了推荐的准确性，也极大地增强了用户数据的隐私安全性，为未来隐私保护的推荐系统提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的个性化新闻推荐系统面临多项挑战，包括过度依赖文本内容、常忽略用户短期兴趣，以及因集中式数据存储导致严重的隐私问题。

**Method:** 本研究提出一种新颖的多模态联邦学习新闻推荐方法。首先，利用多模态模型融合新闻的文本和视觉特征，实现更全面的内容表示。其次，采用时间感知模型，通过多头自注意力网络平衡用户的长期和短期兴趣，提高推荐准确性。最后，为增强隐私保护，引入联邦学习框架，实现不共享用户数据的协作模型训练。该框架将推荐模型分为服务器维护的大型新闻模型和服务器与客户端共享的轻量级用户模型。客户端从中央服务器请求新闻表示和用户模型，利用本地数据计算梯度，并将本地计算的梯度发送给服务器进行聚合。中央服务器聚合梯度以更新全局用户模型和新闻模型。更新后的新闻模型进一步用于服务器推断新闻表示。为进一步保障用户隐私，还采用了基于Shamir秘密共享的安全聚合算法。

**Result:** 在真实新闻数据集上的实验表明，与现有系统相比，该方法表现出强大的性能。

**Conclusion:** 本研究提出的方法在隐私保护的个性化新闻推荐方面取得了显著进展，有效解决了传统系统中的多项挑战，并展现出优越的性能。

> **ai_Abstract:** 本文提出了一种创新的多模态联邦学习方法，旨在解决传统个性化新闻推荐系统在内容表示单一、忽略短期兴趣和数据隐私方面的局限。该方法通过整合新闻的文本和视觉特征，采用时间感知模型平衡用户长期与短期兴趣，并利用联邦学习框架在不共享用户原始数据的情况下实现模型训练，同时结合Shamir秘密共享进行安全聚合。实验结果显示，该方法在真实数据集上表现优异，显著提升了隐私保护下个性化新闻推荐的性能。

> **摘要翻译:** 个性化新闻推荐系统（PNR）作为一种通过预测和推荐符合个人用户兴趣的新闻来解决信息过载的方案而兴起。然而，传统的PNR系统面临多项挑战，包括过度依赖文本内容、普遍忽视用户短期兴趣，以及由于集中式数据存储而引起严重的隐私问题。本文通过引入一种新颖的基于多模态联邦学习的新闻推荐方法来解决这些问题。首先，它使用多模态模型整合新闻项目的文本和视觉特征，从而实现更全面的内容表示。其次，它采用一种时间感知模型，通过多头自注意力网络平衡用户的长期和短期兴趣，从而提高推荐准确性。最后，为了增强隐私，实施了一个联邦学习框架，使得在不共享用户数据的情况下进行协作模型训练。该框架将推荐模型分为一个由服务器维护的大型新闻模型和一个在服务器和客户端之间共享的轻量级用户模型。客户端从中央服务器请求新闻表示（向量）和用户模型，然后使用用户本地数据计算梯度，并最终将其本地计算的梯度发送到服务器进行聚合。中央服务器聚合梯度以更新全局用户模型和新闻模型。更新后的新闻模型进一步用于服务器推断新闻表示。为了进一步保护用户隐私，采用了基于Shamir秘密共享的安全聚合算法。在真实世界新闻数据集上的实验表明，与现有系统相比，该方法表现出强大的性能，代表了隐私保护个性化新闻推荐的重大进步。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [342] [The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification](https://arxiv.org/abs/2507.16438)
> *糖的甜蜜陷阱：揭穿加密流量分类中的表示学习*

*Yuqi Zhao, Giovanni Dettori, Matteo Boffa, Luca Vassio, Marco Mellia* | **Category: cs.NI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 加密流量分类, 表示学习, 数据准备, 虚假关联, Pcap-Encoder

**Comment:** This paper has been accepted at ACM SIGCOMM 2025. It will appear in
  the proceedings with DOI 10.1145/3718958.3750498

> **TL;DR:** 现有用于加密流量分类的表示学习模型因数据准备缺陷和虚假关联而表现虚高，在真实场景下表现不佳。本文提出了Pcap-Encoder，但其复杂性限制了实际应用，并呼吁改进评估方法。

**AI_Comments:** 该论文的重要性在于它挑战了当前加密流量分类领域中许多表示学习模型被夸大的性能宣称。它揭示了数据准备和评估方法中常常被忽视的关键问题。Pcap-Encoder的引入，尽管复杂，但提出了一种更稳健的特征提取方法。其对严格基准测试的呼吁对于推动该领域获得可靠成果至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 最近，受BERT等语言模型启发的表示学习模型在加密流量分类中取得了“惊人性能”（高达98%的准确率），本文旨在批判性地重新评估这些模型的真实性能，揭示其成功背后可能存在的问题。

**Method:** 本文通过广泛的分析，批判性地重新评估了现有表示学习模型在加密流量分类中的性能，并揭示了数据准备问题导致模型利用虚假关联提升性能的现象。此外，论文还引入了Pcap-Encoder，一个基于LM的表示学习模型，专门设计用于从协议头中提取特征。论文还提出了一种正确的评估方法并强调了严格基准测试的必要性。

**Result:** 1. 现有表示学习模型所报告的成功受到数据准备问题的严重影响，这些问题使得模型在微调期间找到简单的捷径（特征和标签之间的虚假关联），从而不切实际地提升了性能。 2. 在真实场景中，当这些捷径不存在时，这些模型的表现很差。 3. Pcap-Encoder是唯一一个为流量分类提供工具性表示的模型。 4. Pcap-Encoder的复杂性使其在实际应用中的可行性受到质疑。 5. 研究结果揭示了数据集准备和模型训练中的缺陷。

**Conclusion:** 现有用于加密流量分类的表示学习模型表现被数据准备缺陷和虚假关联夸大。虽然提出了Pcap-Encoder模型，但其复杂性限制了实际应用。因此，需要更好的、更自觉的测试设计和严格的基准测试来评估这些模型。

> **ai_Abstract:** 本文批判性地重新评估了受语言模型启发的表示学习模型在加密流量分类中的性能。研究发现，这些模型报告的高准确率（高达98%）主要源于数据准备中的缺陷，导致模型利用虚假关联。在没有这些“捷径”的真实场景中，它们的性能显著下降。作者引入了Pcap-Encoder，一个基于LM的模型，用于从协议头中提取特征，该模型提供了有用的表示，但其复杂性限制了实际应用。论文最终指出了当前数据集准备和模型训练中的缺陷，并呼吁采用更稳健的评估方法和严格的基准测试。

> **摘要翻译:** 最近，我们见证了受BERT等语言模型启发，利用表示学习模型创建流量表示的提议的爆炸式增长。所有这些都承诺在加密流量分类中取得惊人的性能（高达98%的准确率）。在本文中，我们以网络专家的视角，批判性地重新评估了它们的性能。通过广泛的分析，我们证明所报告的成功受到数据准备问题的严重影响，这些问题使得这些模型在微调期间找到简单的捷径——特征和标签之间的虚假关联——从而不切实际地提升了它们的性能。当这些捷径不存在时——如同在真实场景中——这些模型的表现就很差。我们还引入了Pcap-Encoder，一个我们专门设计用于从协议头中提取特征的基于LM的表示学习模型。Pcap-Encoder似乎是唯一一个为流量分类提供工具性表示的模型。然而，它的复杂性使其在实际应用中的可行性受到质疑。我们的发现揭示了数据集准备和模型训练中的缺陷，呼吁进行更好、更自觉的测试设计。我们提出了一种正确的评估方法，并强调了严格基准测试的必要性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [396] [An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes](https://arxiv.org/abs/2507.16594)
> *超低功耗边缘/物联网节点上的分体式学习TinyML实验研究*

*Zied Jenhani, Mounir Bensalem, Jasenka Dizdarević, Admela Jukan* | **Category: cs.NI, cs.AI, cs.DC** | **Updated: 2025-07-22**

**Keywords:** 分体式学习, TinyML, 边缘计算, 物联网, 超低功耗

**Comment:** This paper is uploaded here for research community, thus it is for
  non-commercial purposes

> **TL;DR:** 本文对分体式学习TinyML在超低功耗边缘/物联网节点上的无线性能进行了实验研究，比较了不同通信协议的延迟和功耗。

**AI_Comments:** 本文的创新之处在于首次构建了端到端TinyML + SL测试平台，并对不同无线传输协议在分体式学习场景下的性能进行了详细的实验对比。这对于优化边缘/物联网设备上的深度学习部署具有重要意义。研究明确指出了不同协议在延迟和功耗方面的权衡，为实际应用提供了宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 在超低功耗边缘/物联网节点上运行深度学习推理受限于微控制器的内存和计算预算。分体式学习（SL）旨在解决此限制，但其在受限设备和低功耗无线传输协议下的性能仍未得到充分探索。

**Method:** 本文构建了首个基于乐鑫ESP32-S3开发板的端到端TinyML + SL测试平台，用于测试分体式学习TinyML在边缘/物联网环境中的无线性能。研究使用8位量化的MobileNetV2图像识别模型，通过OTA更新交付到节点。中间激活通过ESP-NOW、BLE、传统UDP/IP和TCP/IP等不同无线通信方式进行交换，并在相同硬件上进行对比。

**Result:** 数据显示，在block_16_project_BN层之后分割模型会产生一个5.66 kB的张量。使用UDP时，该张量通过链路需要3.2毫秒，稳态往返延迟为5.8秒。ESP-NOW呈现出最有利的RTT性能，为3.7秒；BLE进一步延长了电池寿命，但延迟超过10秒。

**Conclusion:** 本文通过实验比较了不同无线通信协议在分体式学习TinyML中的性能，发现ESP-NOW在往返延迟方面表现最佳，而BLE在延长电池寿命方面具有优势但延迟更高。这表明为特定应用选择合适的通信协议至关重要。

> **ai_Abstract:** 本文针对超低功耗边缘/物联网节点上深度学习推理受限的问题，提出了分体式学习（SL）的解决方案。研究构建了首个端到端TinyML + SL测试平台，在ESP32-S3开发板上，使用MobileNetV2模型，并比较了ESP-NOW、BLE、UDP/IP和TCP/IP等不同无线通信协议在传输中间激活时的性能。实验结果表明，ESP-NOW在往返延迟方面表现最佳，而BLE虽能延长电池寿命但会增加延迟。

> **摘要翻译:** 在超低功耗边缘/物联网节点上直接运行深度学习推理一直受到微控制器内存和计算预算紧张的限制。分体式学习（SL）解决了这一限制，它将推理过程的一部分在传感器上执行，其余部分卸载到伴随设备上。在受限设备和低功耗无线传输协议的相关影响下，分体式学习的性能在很大程度上仍未被探索。据我们所知，本文首次提出了一个基于乐鑫ESP32-S3开发板构建的端到端TinyML + SL测试平台，旨在对边缘/物联网环境中的分体式学习TinyML的无线性能进行基准测试。我们对MobileNetV2图像识别模型的性能进行了基准测试，该模型被量化为8位整数，分区并通过无线更新交付到节点。中间激活通过不同的无线通信方法进行交换：ESP-NOW、BLE以及传统的UDP/IP和TCP/IP，从而在相同硬件上进行正面比较。测量结果显示，在block_16_project_BN层之后分割模型会产生一个5.66 kB的张量，当使用UDP时，该张量在3.2毫秒内通过链路，实现了5.8秒的稳态往返延迟。ESP-NOW呈现出最有利的RTT性能，为3.7秒；BLE进一步延长了电池寿命，但延迟超过10秒。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [507] [InfiniteHBD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers](https://arxiv.org/abs/2502.03885)
> *InfiniteHBD：使用光电路交换收发器构建用于LLM的数据中心级高带宽域*

*Chenchen Shou, Guyue Liu, Hao Nie, Huaiyu Meng, Yu Zhou, Yimin Jiang, Wenqing Lv, Yelong Xu, Yuanwei Lu, Zhang Chen, Yanbo Yu, Yichen Shen, Yibo Zhu, Daxin Jiang* | **Category: cs.NI, cs.DC, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 高带宽域, 光电路交换, LLM, 数据中心, 收发器

**Comment:** 

> **TL;DR:** InfiniteHBD提出了一种新的以收发器为中心的HBD架构，利用光电路交换（OCS）来解决LLM训练中现有高带宽域的可扩展性、成本和容错性限制，并取得了显著的性能和成本效益。

**AI_Comments:** 本文提出了一种高度创新的方法，通过将交换智能转移到收发器级别并利用OCS来构建用于LLM训练的高带宽域。这种“以收发器为中心”的设计范式从根本上解决了传统以交换机或GPU为中心的HBD固有的可扩展性和容错性问题。使用硅光子技术实现低成本OCS收发器在数据中心部署方面具有重要的实际意义。所展示的在成本、GPU利用率和容错性方面的改进令人信服，表明AI工作负载的网络基础设施取得了重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型（LLM）的训练依赖于高带宽域（HBD），但现有HBD架构（如以交换机为中心的NVL-72、以GPU为中心的TPUv3/Dojo和混合式TPUv4）在可扩展性、成本和容错性方面存在根本性限制，例如成本过高、故障传播严重或故障爆炸半径大。

**Method:** 本文提出了InfiniteHBD，一种新颖的以收发器为中心的HBD架构，它通过在收发器级别嵌入光电路交换（OCS）来统一连接性和动态交换。关键创新包括：基于硅光子（SiPh）的低成本OCS收发器（OCSTrx）、与节点内/节点间通信共同设计的可重构k跳环形拓扑，以及一个HBD-DCN编排算法，旨在最大化GPU利用率并最小化跨ToR数据中心网络流量。该设计实现了可重构的点对多点连接，并能适应可变大小的环形拓扑。

**Result:** 评估表明，InfiniteHBD的成本是NVL-72的31%，GPU浪费率接近于零（比NVL-72和TPUv4低一个数量级以上），当节点故障率低于7%时，跨ToR流量接近于零，并且与NVIDIA DGX（每个节点8个GPU）相比，模型FLOPs利用率提高了3.37倍。

**Conclusion:** InfiniteHBD是一种优越的HBD架构，适用于LLM训练，因为它提供了数据中心范围的可扩展性而没有成本爆炸，通过将故障隔离到单个节点来提高容错性，并为无故障GPU实现全带宽利用，同时在成本和效率上显著优于现有解决方案。

> **ai_Abstract:** 本文介绍了InfiniteHBD，一种用于大规模LLM训练的新型以收发器为中心的高带宽域（HBD）架构。它通过将光电路交换（OCS）直接集成到收发器中，解决了现有HBD在可扩展性、成本和容错性方面的局限性。InfiniteHBD实现了可重构的点对多点连接和可变大小的环形拓扑，从而实现了数据中心范围的无成本爆炸的可扩展性、改进的故障隔离和全带宽利用。评估显示，与现有解决方案相比，其显著降低了成本、实现了接近零的GPU浪费、最小化了跨ToR流量，并大幅提高了模型FLOPs利用率。

> **摘要翻译:** 大规模语言模型（LLM）的训练依赖于多维并行化，其中高带宽域（HBD）对于张量并行（TP）和专家并行（EP）等通信密集型并行化至关重要。然而，现有的HBD架构在可扩展性、成本和容错性方面面临根本性限制：以交换机为中心的HBD（例如NVL-72）导致高昂的扩展成本，而以GPU为中心的HBD（例如TPUv3/Dojo）则遭受严重的故障传播。TPUv4等交换机-GPU混合HBD采取了折衷方法，但故障爆炸半径在立方体级别（例如64个TPU）仍然很大。
我们提出了InfiniteHBD，一种新颖的以收发器为中心的HBD架构，它利用光电路交换（OCS）在收发器级别统一了连接性和动态交换。通过在每个收发器中嵌入OCS，InfiniteHBD实现了可重构的点对多点连接，允许拓扑结构适应可变大小的环。这种设计提供了：i）数据中心范围的可扩展性，且没有成本爆炸；ii）通过将故障隔离到单个节点来实现容错性；以及iii）对无故障GPU实现全带宽利用。关键创新包括基于硅光子（SiPh）的低成本OCS收发器（OCSTrx）、与节点内/节点间通信共同设计的可重构k跳环形拓扑，以及一个HBD-DCN编排算法，该算法在最大化GPU利用率的同时最小化跨ToR数据中心网络流量。评估表明，InfiniteHBD的成本是NVL-72的31%，GPU浪费率接近于零（比NVL-72和TPUv4低一个数量级以上），当节点故障率低于7%时，跨ToR流量接近于零，并且与NVIDIA DGX（每个节点8个GPU）相比，模型FLOPs利用率提高了3.37倍。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [546] [Open Wireless Digital Twin: End-to-End 5G Mobility Emulation with OpenAirInterface and Sionna RT](https://arxiv.org/abs/2503.12177)
> *开放式无线数字孪生：基于OpenAirInterface和Sionna RT的端到端5G移动性仿真*

*Tetsuya Iye, Masaya Sakamoto, Shohei Takaya, Eisaku Sato, Yuki Susukida, Yu Nagaoka, Kazuki Maruta, Jin Nakazato* | **Category: cs.NI** | **Updated: 2025-07-22**

**Keywords:** 无线数字孪生, 5G仿真, OpenAirInterface, Sionna RT, 移动通信

**Comment:** 

> **TL;DR:** 本研究提出了一个开放式无线数字孪生（OWDT）平台，结合OpenAirInterface和Sionna RT，用于在CPU系统上高保真地仿真5G移动通信，旨在加速无线系统开发并降低成本。

**AI_Comments:** 该论文的创新之处在于其构建了一个端到端、基于开源和开放数据的无线数字孪生平台，特别是在CPU系统上实现了高保真5G移动性仿真。这对于无线系统开发和网络优化具有重要意义，因为它提供了一个成本效益高且接近真实世界的实验环境，有望显著加速研发周期并降低传统实验的开销。将OAI与Sionna RT结合是其技术亮点。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强移动通信系统的评估，并弥合理论模拟与实际部署之间的差距。

**Method:** 本研究构建了一个开放式无线数字孪生（OWDT）平台。该平台整合了OpenAirInterface（OAI）用于5G NR协议栈仿真，以及NVIDIA Sionna RT用于高分辨率射线追踪无线电传播建模。它在基于CPU的Linux系统上运行，并利用真实世界的建筑数据。平台还集成了OAI FlexRIC（与O-RAN近实时RAN智能控制器对齐）以动态监控关键性能指标（KPIs）。

**Result:** 该仿真框架在城市环境中的广泛评估证明了其有效性，能够高保真地复制真实世界的通信动态。结果强调了OWDT在加速无线系统开发、降低实验成本和优化网络配置方面的潜力。

**Conclusion:** 开放式无线数字孪生（OWDT）平台能够高保真地仿真5G移动通信，并有望加速无线系统开发、降低实验成本和优化网络配置。

> **ai_Abstract:** 本研究介绍了一个开放式无线数字孪生（OWDT）平台，它结合了OpenAirInterface（OAI）进行5G NR协议栈仿真和NVIDIA Sionna RT进行高分辨率无线电传播建模。该平台旨在通过在基于CPU的Linux系统上，利用真实世界数据实现端到端5G移动性高保真仿真，从而弥合理论与实际部署的鸿沟。通过集成OAI FlexRIC监控KPIs，该平台被证明能有效复制真实通信动态，并有望加速无线系统开发、降低成本和优化网络。

> **摘要翻译:** 本研究提出了一个使用开源软件和开放数据构建的端到端无线数字孪生平台，以增强移动通信系统的评估。所提出的开放式无线数字孪生（OWDT）集成了OpenAirInterface（OAI）用于5G NR协议栈仿真，以及NVIDIA Sionna RT用于高分辨率基于射线追踪的无线电传播建模。这种集成使得在基于CPU的Linux系统上，利用真实世界的建筑数据，能够对移动场景中的5G无线通信进行逼真的仿真，从而弥合了理论模拟与实际部署之间的差距。该平台还整合了OAI FlexRIC，这是一个与O-RAN近实时RAN智能控制器（near-RT RIC）对齐的实现，用于动态监控关键性能指标（KPIs）。通过在城市环境中的广泛评估，本研究证明了该仿真框架的有效性，揭示了其高保真复制真实世界通信动态的能力。结果强调了OWDT在加速无线系统开发、降低实验成本和优化网络配置方面的潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [594] [Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering](https://arxiv.org/abs/2507.13179)
> *通过高阶误差状态卡尔曼滤波实现边缘XR中可预测性感知的运动预测*

*Ziyu Zhong, Björn Landfeldt, Günter Alce, Hector A Caltenco* | **Category: cs.NI, cs.MM** | **Updated: 2025-07-22**

**Keywords:** 运动预测, 误差状态卡尔曼滤波, 边缘XR, 6G, 运动到光子延迟

**Comment:** 

> **TL;DR:** 本文提出了一种结合运动分类器的上下文感知误差状态卡尔曼滤波器（ESKF），用于预测XR中的用户头部运动，以补偿运动到光子（MTP）延迟，并在准确性和鲁棒性方面优于传统方法。

**AI_Comments:** 该论文的创新点在于结合了运动分类器与误差状态卡尔曼滤波器，实现了对不同可预测性头部运动的上下文感知预测。这解决了传统卡尔曼滤波在复杂运动处理上的不足，并增强了对6G网络中常见丢包的鲁棒性。其重要性在于为未来6G边缘XR应用提供了更可靠、高效的运动预测方案，有助于提升用户体验并降低设备能耗。

<details>
  <summary>Details</summary>

**Motivation:** 6G网络中的XR应用卸载带来了新的可能性，但网络延迟（特别是运动到光子MTP延迟）严重影响用户体验。现有的深度学习方法在边缘资源受限时面临可扩展性问题，而卡尔曼滤波在处理复杂运动和应对丢包方面表现不佳。

**Method:** 本文提出了一种上下文感知误差状态卡尔曼滤波器（ESKF）预测框架。该框架通过集成一个运动分类器来预测用户的头部运动轨迹，该分类器根据运动的可预测性对头部运动进行分类，从而补偿远程XR中的MTP延迟。

**Result:** 优化后的ESKF在位置和方向精度上超越了传统的卡尔曼滤波器，并在不同运动类别下显示出降低的预测误差。此外，它还表现出增强的鲁棒性和对丢包的弹性。

**Conclusion:** 本文提出的优化误差状态卡尔曼滤波器（ESKF）结合运动分类器，能有效预测XR中的用户头部运动，补偿MTP延迟，并在准确性和对丢包的鲁棒性方面优于传统方法，为边缘XR应用提供了更可靠的运动预测解决方案。

> **ai_Abstract:** 本文针对6G边缘XR应用中由卸载引起的运动到光子（MTP）延迟问题，提出了一种基于上下文感知误差状态卡尔曼滤波器（ESKF）的运动预测框架。该框架通过引入一个运动分类器，根据头部运动的可预测性进行分类，从而更准确地预测用户头部运动轨迹。实验结果表明，该优化ESKF在预测精度、鲁棒性及对丢包的弹性方面均优于传统卡尔曼滤波器，有效提升了边缘XR的用户体验。

> **摘要翻译:** 随着6G网络的开发和定义，XR应用的卸载正成为一个强有力的新用例。6G降低的延迟与边缘处理基础设施相结合，将首次在蜂窝网络中提供一个真实的卸载场景，其中渲染等计算密集型功能可以从用户设备迁移到网络中。这样做的一个关键优势是降低了用户设备的电池需求，并有可能设计出更小尺寸的新设备。然而，与本地执行相比，卸载会引入更高的延迟，这主要归因于网络传输延迟和边缘服务器上的排队延迟，尤其是在多用户并发情况下。尽管边缘平台具有计算能力，但由此产生的运动到光子（MTP）延迟会 negatively 影响用户体验。为了缓解这种情况，已经提出了运动预测来抵消延迟。现有方法建立在深度学习或卡尔曼滤波之上。深度学习技术在资源受限的边缘面临可扩展性限制，因为它们的计算开销随着用户并发的增加而加剧，而卡尔曼滤波在处理复杂运动方面表现不佳，并且对6G高频无线接口固有的丢包很脆弱。在这项工作中，我们引入了一种上下文感知误差状态卡尔曼滤波器（ESKF）预测框架，该框架预测用户的头部运动轨迹，以补偿远程XR中的MTP延迟。通过集成一个根据可预测性对头部运动进行分类的运动分类器，我们的算法在不同运动类别中显示出降低的预测误差。我们的发现表明，优化后的ESKF不仅在位置和方向精度上超越了传统的卡尔曼滤波器，而且还表现出增强的鲁棒性和对丢包的弹性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [7] [Constructions and List Decoding of Sum-Rank Metric Codes Based on Orthogonal Spaces over Finite Fields](https://arxiv.org/abs/2507.16377)
> *基于有限域上正交空间的和秩度量码的构造与列表译码*

*Xuemei Liu, Jiarong Zhang, Gang Wang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-22**

**Keywords:** 和秩度量码, 正交空间, 列表译码, 最大秩距离码, 子空间设计

**Comment:** 27 pages, 1 table

> **TL;DR:** 本文基于有限域上的正交空间构造了和秩度量码，并计算了不同译码算法下的列表大小，提高了译码成功率。

**AI_Comments:** 本文在和秩度量码的构造和列表译码方面取得了创新。通过结合正交空间和子空间设计，不仅提出了新的编码构造方法，还在译码效率上实现了提升，这对于多跳线性网络编码、空时编码和分布式存储系统等应用领域具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 和秩度量码在多跳线性网络编码、空时编码和分布式存储系统等领域有重要应用。本研究的目的是构造基于有限域上正交空间的和秩度量码，并计算不同译码算法输出的列表大小。

**Method:** 本研究基于有限域上本原多项式的伴随矩阵，构造了阶为 $q^n-1$ 的循环正交群和阶为 $(q^n-1)^2$ 的Abel非循环正交群。通过选择不同的子空间生成矩阵，分别构造了参数为 $(n \times {2n}, q^{2n}, n)_q$ 和 $(n \times {4n}, q^{4n}, n)_q$ 的最大秩距离(MRD)码。针对所构造的MRD码，提出了两种和秩度量码的构造方法，并计算了列表译码算法下输出的列表大小。随后，使用 $[{\bf{n}},k,d]_{{q^n}/q}$-系统将和秩度量码与子空间设计关联起来，并基于子空间设计计算了和秩度量码在列表译码算法下的列表大小。

**Result:** 构造了阶为 $q^n-1$ 的循环正交群和阶为 $(q^n-1)^2$ 的Abel非循环正交群。构造了参数为 $(n \times {2n}, q^{2n}, n)_q$ 和 $(n \times {4n}, q^{4n}, n)_q$ 的最大秩距离(MRD)码。提出了两种和秩度量码的构造方法，并计算了列表译码算法下输出的列表大小。基于子空间设计计算和秩度量码的列表大小，该计算方法与传统方法相比提高了译码成功率。

**Conclusion:** 通过基于正交空间构造和秩度量码并结合子空间设计进行列表译码，本研究提高了译码成功率。

> **ai_Abstract:** 本研究旨在构造基于有限域上正交空间的和秩度量码，并计算其列表译码算法下的列表大小。通过构造特定阶的循环和Abel非循环正交群，并利用子空间生成矩阵，成功构建了两种最大秩距离(MRD)码。基于这些MRD码，提出了两种和秩度量码的构造方法，并计算了其列表译码的列表大小。此外，研究将和秩度量码与子空间设计相结合，提出了一种新的列表大小计算方法，实验证明该方法显著提高了译码成功率。

> **摘要翻译:** 和秩度量码作为汉明码和秩度量码的推广，在多跳线性网络编码、空时编码和分布式存储系统等领域有重要应用。本研究的目的是构造基于有限域上正交空间的和秩度量码，并计算不同译码算法输出的列表大小。取得了以下成果：
在本研究中，我们基于有限域上本原多项式的伴随矩阵，构造了阶为 $q^n-1$ 的循环正交群和阶为 $(q^n-1)^2$ 的Abel非循环正交群。通过选择不同的子空间生成矩阵，分别构造了参数为 $(n \times {2n}, q^{2n}, n)_q$ 和 $(n \times {4n}, q^{4n}, n)_q$ 的最大秩距离(MRD)码。针对所构造的MRD码，提出了两种和秩度量码的构造方法，并计算了列表译码算法下输出的列表大小。随后，使用 $[{\bf{n}},k,d]_{{q^n}/q}$-系统将和秩度量码与子空间设计关联起来。基于子空间设计计算了和秩度量码在列表译码算法下的列表大小。该计算方法与传统方法相比提高了译码成功率。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [41] [Typicality with Feedback](https://arxiv.org/abs/2507.16384)
> *带反馈的典型性*

*Thomas Sturma, Michèle Wigger* | **Category: cs.IT, math.IT** | **Updated: 2025-07-22**

**Keywords:** 反馈系统, 离散无记忆信道, 基本极限, 集成传感与通信, 条件类型

**Comment:** 9 pages, 6 figures, to be published in 2025 IEEE Information Theory
  Workshop (ITW)

> **TL;DR:** 本文分析了一个闭环反馈系统，并证明了输出的条件类型与信道转移定律保持接近，从而应用于集成传感与通信（ISAC）模型，表明其闭环系统与开环系统的基本极限相同。

**AI_Comments:** 本文在信息论领域具有重要意义，它通过严谨的数学证明揭示了带有反馈的离散无记忆信道的基本特性。其创新之处在于证明了输出的条件类型与信道转移定律的接近性，并将其应用于ISAC系统，挑战了直觉上反馈总是能带来性能提升的观念，指出在某些条件下，反馈并不能改变系统的基本极限。这对于理解和设计未来通信与传感一体化系统具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文的主要目的是分析一个发射器能够根据先前信道输出调整输入的闭环反馈系统。这项研究旨在使人们能够研究某些自适应系统中的基本限制。

**Method:** 本文证明了无论发射器策略如何，给定输入的输出条件类型都接近离散无记忆信道 (DMC) 转移定律 $P_{Y|X}$。作为应用，本文为集成传感与通信 (ISAC) 模型建立了一个逆定理。

**Result:** 本文证明了，无论发射器策略如何，给定输入的输出条件类型都与离散无记忆信道 (DMC) 转移定律 $P_{Y|X}$ 保持接近。在集成传感与通信 (ISAC) 应用中，当可接受的平均解码错误概率 $\epsilon$ 与可接受的过量失真概率 $\delta$ 之和小于 $1$（即 $\delta + \epsilon < 1$）时，闭环系统的基本极限与开环系统的基本极限相同。

**Conclusion:** 本文得出的结论是，在满足特定条件（即 $\delta + \epsilon < 1$）时，闭环反馈系统的基本极限与开环系统（发射器可以使用反馈信号来估计状态但不能产生自适应信道输入）的基本极限是相同的。

> **ai_Abstract:** 本文分析了一个闭环反馈系统，并证明了在离散无记忆信道中，无论发射器策略如何，输出的条件类型都接近信道转移定律。这一普适性结果使得研究自适应系统的基本极限成为可能。作为应用，研究了集成传感与通信（ISAC）模型，并证明了在特定条件下（$\delta + \epsilon < 1$），闭环系统的基本极限与开环系统相同。

> **摘要翻译:** 本文的主要目的是分析一个闭环反馈系统，其中发射器探测一个离散无记忆信道（DMC），并可以根据之前的信道输出调整其输入。我们证明，无论发射器的策略如何，给定输入的输出条件类型始终接近DMC转移定律 $P_{Y|X}$。这一通用结果使得研究某些自适应系统中的基本极限成为可能。
作为一个应用，我们为集成传感与通信（ISAC）模型建立了一个逆结果。在此设置中，发射器也作为雷达接收器，旨在同时通过信道传输消息并从反向散射的反馈信号中估计信道状态。我们表明，只要可允许的平均解码错误概率（表示为 $\epsilon$）和可允许的过量失真概率（表示为 $\delta$）之和小于 $1$，即 $\delta + \epsilon < 1$，闭环系统的基本极限与开环系统相同，其中发射器可以使用反馈信号来估计状态但不能产生自适应信道输入。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [77] [A Robust 5G Terrestrial Positioning System with Sensor Fusion in GNSS-denied Scenarios](https://arxiv.org/abs/2507.16600)
> *5G陆地定位系统在GNSS受限场景下的鲁棒性与传感器融合*

*Hamed Talebian, Nazrul Mohamed Nazeer, Darius Chmieliauskas, Jakub Nikonowicz, Mehdi Haghshenas, Łukasz Matuszewski, Mairo Leier, Aamir Mahmood* | **Category: cs.IT, math.IT** | **Updated: 2025-07-22**

**Keywords:** 5G定位, 载波相位, 传感器融合, GNSS受限, 深度学习

**Comment:** Submitted to IEEE Transactions on Vehicular Technology

> **TL;DR:** 该论文提出了一种鲁棒的5G陆地定位系统，通过载波相位测距、深度学习和传感器融合（IMU/相机）在GNSS受阻环境下实现小于5米的定位精度，可替代GNSS。

**AI_Comments:** 这篇论文的创新点在于将5G基础设施与先进的定位技术（如载波相位测距、深度学习和多传感器融合）相结合，为GNSS受限环境提供了一个高性能的替代方案。其采用多载波CP和深度学习处理非视距问题，以及传感器融合增强鲁棒性的方法是值得关注的亮点。该系统在城市环境下表现出的与商用GNSS相当的精度，表明了其在未来智能交通、自动驾驶等领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决全球导航卫星系统（GNSS）信号受阻或不可用场景下的定位问题，提供一种可行的替代方案。

**Method:** 1. 基于5G基础设施，并进行网络规划以将定位作为主要服务。2. 利用载波相位(CP)测距结合三边测量进行用户定位。3. 采用多载波CP方法消除整数模糊度估计。4. 开发深度学习模型识别并排除非视距(NLOS)链路。5. 在视距受阻且CP测距不可靠时，使用误差状态扩展卡尔曼滤波器融合惯性测量单元(IMU)和相机等传感器数据。

**Result:** 在真实世界的KITTI城市数据集上，系统实现了小于5米的定位误差，与公共商用GNSS服务相当。

**Conclusion:** 该系统为GNSS受限环境提供了一种弹性且准确的定位解决方案。

> **ai_Abstract:** 该论文提出了一种创新的5G陆地定位系统，旨在GNSS信号受阻或不可用时提供高精度替代。系统通过优化5G网络以支持定位服务，并结合载波相位测距与三边测量。为克服挑战，它采用了多载波CP消除模糊度，利用深度学习识别并排除非视距链路，并在视距受阻时通过扩展卡尔曼滤波器融合IMU和相机数据。实验结果表明，该系统在城市环境下能达到与商用GNSS相当的亚5米定位精度，展现了其在复杂场景下的鲁棒性和准确性。

> **摘要翻译:** 本文提出了一种基于5G基础设施的陆地定位系统，作为GNSS的有效替代方案，特别适用于GNSS信号受阻或不可用的场景。论文讨论了旨在将定位作为主要服务的网络规划，这与陆地网络中传统上侧重于通信服务的做法形成对比。该系统建立在为定位优化的网络基础设施之上，提出了一种利用载波相位(CP)测距结合三边测量的方法，当至少有三个基站(BS)提供视距(LOS)条件时，可在网络中定位用户。实现准确的基于CP的定位需要解决三个关键挑战：整数模糊度解析、LOS/NLOS链路识别以及在视距受阻条件下的定位。为此，该系统采用多载波CP方法，消除了显式整数模糊度估计的需要。此外，开发了一个深度学习模型来识别NLOS链路并将其从三边测量过程中排除。在LOS受阻且CP测距变得不可靠的情况下，系统结合了误差状态扩展卡尔曼滤波器，以融合来自其他传感器（如惯性测量单元(IMU)和摄像头）的补充数据。这种混合方法能够实现在各种信道条件下对移动用户的鲁棒跟踪。所提出的陆地定位系统的性能通过真实世界的KITTI数据集进行了评估，该数据集包含在城市环境中移动的车辆。仿真结果表明，该系统在KITTI城市场景中可以实现小于5米的定位误差——与公共商用GNSS服务相当——突显了其作为GNSS受限环境的弹性和准确解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [116] [Active RISs: Modeling and Optimization](https://arxiv.org/abs/2507.16499)
> *有源RIS：建模与优化*

*Recep Akif Tasci, Panagiotis Gavriilidis, Ertugrul Basar, George C. Alexandropoulos* | **Category: cs.IT, cs.ET, eess.SP, math.IT** | **Updated: 2025-07-22**

**Keywords:** 有源RIS, 双路径损耗, 功率放大器, 隧道二极管, 能效优化

**Comment:** 43 pages, 15 figures, Book chapter

> **TL;DR:** 本文研究了有源可重构智能表面（RIS）的建模、性能分析和优化，旨在克服传统RIS的双路径损耗限制，并通过两种硬件设计（基于PA和隧道二极管）展示了其优越的性能和能效。

**AI_Comments:** 这篇论文对有源RIS的建模和优化进行了深入研究，提出了两种具体的硬件设计方案，并详细分析了其性能。其创新之处在于明确提出并解决了传统RIS的双路径损耗问题，并通过理论分析和数值模拟验证了有源RIS的优越性。尤其值得关注的是，论文不仅提供了理论模型，还考虑了实际硬件设计（如PA和隧道二极管），并探讨了能效和元件数量的权衡，这对于推动有源RIS的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统可重构智能表面（RIS）受限于双路径损耗效应，导致反射信号严重衰减。为了克服这一限制，提出了能够放大入射信号的有源RIS架构。

**Method:** 本文研究了有源RIS的建模、性能分析和优化，重点关注两种硬件设计：一种是带单个功率放大器（PA）的双RIS结构，另一种是利用隧道二极管在单元格层面的反射放大结构。对于基于PA的设计，开发了全面的数学模型，推导了接收信噪比、误码率和能效的闭式表达式，并提出了在功率约束下最大化系统容量的优化框架。对于第二种设计，通过分析隧道二极管的I-V特性，研究了其在单元格中的集成，推导了负电阻范围和功耗模型，并通过紧凑的线性代数公式表征了反射系数的内在相位-幅度耦合。

**Result:** 广泛的数值模拟验证了理论分析，表明有源RIS可以有效克服双路径损耗限制，并与无源RIS相比，实现有利的能效权衡。此外，研究了可用功率预算与有源元件数量之间的权衡，揭示了更多有源元件并不总是能带来最佳性能。

**Conclusion:** 有源RIS能够有效克服传统RIS的双路径损耗限制，并在能效方面表现出优势。然而，有源元件的数量并非越多越好，需要权衡可用功率预算以实现最佳性能。

> **ai_Abstract:** 本文深入探讨了有源可重构智能表面（Active RIS）的建模、性能分析与优化，旨在解决传统RIS面临的双路径损耗问题。研究聚焦于两种硬件实现方案：一种基于功率放大器（PA）的双RIS结构，另一种是在单元格层面集成隧道二极管。对于PA方案，建立了详细的数学模型，并推导了关键性能指标的闭式表达式，提出了系统容量最大化的优化框架。对于隧道二极管方案，分析了其电学特性以建立功耗模型并表征了反射系数的相位-幅度耦合。仿真结果证实，有源RIS能有效克服双路径损耗，并在能效上优于无源RIS，同时指出有源元件数量与性能之间存在最佳权衡点。

> **摘要翻译:** 可重构智能表面（RIS）赋能的通信已成为下一代无线网络的变革性技术，能够对传播环境进行可编程塑形。然而，传统RISs从根本上受到双路径损耗效应的限制，这严重衰减了反射信号。为了克服这一点，有源RIS架构被提出，其能够放大入射信号。本章研究了有源RISs的建模、性能分析和优化，重点关注两种硬件设计：一种是带单个功率放大器（PA）的双RIS结构，另一种是利用隧道二极管在单元格层面的反射放大结构。对于基于PA的设计，开发了一个全面的数学模型，并推导了接收信噪比、误码率和能量效率（EE）的闭式表达式。提出了一个用于配置相移和放大器增益的优化框架，以在功率约束下最大化系统容量。关于第二种设计，通过分析其I-V特性，仔细研究了隧道二极管在单元格中的集成，从而能够推导负电阻范围和功耗模型。此外，通过紧凑的线性代数公式表征了反射系数的内在相位-幅度耦合，从而实现了有源RISs的实际优化。广泛的数值模拟验证了理论分析，表明有源RISs可以有效克服双路径损耗限制，并与无源RISs相比，实现有利的EE权衡。最后，研究了可用功率预算和有源元件数量之间的权衡，揭示了更多有源元件并不总是能带来最佳性能。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [122] [Reconfigurable Intelligent Surface-Enabled Green and Secure Offloading for Mobile Edge Computing Networks](https://arxiv.org/abs/2507.16666)
> *可重构智能表面赋能的移动边缘计算网络绿色安全卸载*

*Tong-Xing Zheng, Xinji Wang, Xin Chen, Di Mao, Jia Shi, Cunhua Pan, Chongwen Huang, Haiyang Ding, Zan Li* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-22**

**Keywords:** 移动边缘计算, 可重构智能表面, 安全卸载, 能量效率, 非凸优化

**Comment:** 15 pages, 9 figures, accepted by IEEE Internet of Things Journal

> **TL;DR:** 该论文研究了多用户上行移动边缘计算（MEC）网络中的绿色安全卸载问题，利用可重构智能表面（RIS）对抗窃听者，并提出了一种高效的优化框架来最小化总能耗。

**AI_Comments:** 该论文的创新点在于将可重构智能表面（RIS）应用于移动边缘计算（MEC）网络中的安全卸载，以同时实现绿色（低能耗）和安全（防窃听）的目标。其提出的优化框架结合了多种先进的优化技术，能够有效处理非凸问题。研究结果表明RIS在提升系统能效和安全性方面的巨大潜力，为未来MEC网络设计提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决移动边缘计算（MEC）网络中的安全卸载问题，同时最小化总能耗，尤其是在存在多天线窃听者的情况下，并利用可重构智能表面（RIS）来提高安全性和能效。

**Method:** 该论文将问题建模为一个非凸优化问题，目标是最小化总能耗，并提出了一种高效的块坐标下降（BCD）框架来迭代优化用户端的本地计算比特数、发射功率、RIS相移以及接入点的多用户检测矩阵。具体地，对于完美窃听者信道状态信息（CSI）情况，采用连续凸逼近（SCA）、半定规划（SDP）和半定松弛（SDR）方法；对于不完美CSI情况，采用S-过程和惩罚凸凹规划（PCC）实现鲁棒设计。

**Result:** 数值结果验证了所提算法的收敛性和有效性。研究表明，可重构智能表面（RIS）在实现安全和节能的MEC网络中发挥了重要作用，部署良好设计的RIS可以比没有RIS的情况下节省高达60%的能耗。此外，还揭示了RIS单元数量、部署位置、用户数量、任务规模和持续时间以及CSI不完美等关键因素对保密能效的影响。

**Conclusion:** 该研究表明，在移动边缘计算网络中，利用可重构智能表面可以显著提高安全卸载的能效，并为绿色和安全的通信提供了有效的解决方案。

> **ai_Abstract:** 该论文探讨了在存在多天线窃听者的多用户上行移动边缘计算（MEC）网络中，利用可重构智能表面（RIS）实现绿色安全卸载的问题。通过构建一个最小化总能耗的非凸优化问题，并提出一种基于块坐标下降的高效算法框架，结合连续凸逼近、半定规划和S-过程等技术，解决了完美和不完美信道状态信息下的优化难题。研究结果表明，RIS能显著提升MEC网络的安全性和能效，最高可节省60%的能耗，并分析了RIS配置、用户和任务参数以及信道不完美性对系统性能的影响。

> **摘要翻译:** 本文研究了多用户上行移动边缘计算（MEC）网络，其中用户在非正交多址接入策略下，借助可重构智能表面（RIS）对抗多天线窃听者，安全地将部分任务卸载到接入点。我们建立了一个最小化总能耗的非凸优化问题，并受安全卸载要求的约束。我们构建了一个高效的块坐标下降框架，以迭代优化用户端的本地计算比特数和发射功率、RIS相移以及接入点的多用户检测矩阵。具体地，我们先后采用连续凸逼近、半定规划和半定松弛来解决具有完美窃听者信道状态信息（CSI）的问题，然后采用S-过程和惩罚凸凹规划来实现不完美CSI情况下的鲁棒设计。我们提供了大量的数值结果来验证所提出算法的收敛性和有效性。我们证明了RIS在实现安全和节能的MEC网络中发挥了重要作用，与没有RIS的情况相比，部署良好设计的RIS可以节省高达60%的能耗。我们进一步揭示了各种关键因素对保密能效的影响，包括RIS单元数量和部署位置、用户数量、任务规模和持续时间以及CSI不完美。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [167] [Error Detection Based on Generalized Successive Cancellation List Decoding for Polar Codes](https://arxiv.org/abs/2507.16699)
> *基于广义逐次消除列表译码的极化码差错检测*

*Alexander Sauter, Mustafa Cemil Coşkun, Gianluigi Liva* | **Category: cs.IT, math.IT** | **Updated: 2025-07-22**

**Keywords:** 极化码, SCL译码, 差错检测, 广义译码, Forney规则

**Comment:** 5 pages, 2 figures

> **TL;DR:** 本文提出了一种基于Forney广义译码规则的改进型逐次消除列表（SCL）译码方法，用于极化码的差错检测，能够有效丢弃不可靠决策，并通过蒙特卡洛模拟分析了其在短极化码上的性能。

**AI_Comments:** 该论文的创新之处在于将SCL译码的特定列表尺寸（$2^\gamma$）与Forney的广义译码规则联系起来，从而实现了高效的差错检测或不可靠决策丢弃。这对于极化码的实际应用可能具有重要意义，尤其是在需要高可靠性的场景下。论文结果部分对“短极化码”的关注可能暗示了该方法的特定适用范围或潜在限制。

<details>
  <summary>Details</summary>

**Motivation:** 逐次消除列表（SCL）译码在极化码中已被广泛采用，但在足够大的列表尺寸下才能实现接近最大似然的性能。本文旨在通过修改SCL译码来实现Forney的广义译码规则，从而提供一种有效丢弃不可靠决策的方法。

**Method:** 本文提出了一种对SCL译码的修改。如果列表尺寸为$2^\gamma$（其中$\gamma$是混合因子），则这种修改可以实现Forney的广义译码规则。通过蒙特卡洛模拟分析了所提出的广义SCL译码在短极化码下的性能。

**Result:** 所提出的广义SCL译码提供了一种有效丢弃不可靠决策的方法。通过蒙特卡洛模拟分析了其在短极化码下的性能。

**Conclusion:** 当列表尺寸为$2^\gamma$时，对SCL译码的修改可以实现Forney的广义译码规则，从而提供一种有效丢弃不可靠决策的手段。

> **ai_Abstract:** 本文介绍了一种针对极化码的逐次消除列表（SCL）译码的改进方法。通过将列表尺寸设置为$2^\gamma$（其中$\gamma$为混合因子），该改进后的SCL译码能够实现Forney的广义译码规则，从而提供一种有效丢弃不可靠译码决策的机制。论文通过蒙特卡洛模拟评估了该广义SCL译码在短极化码上的性能。

> **摘要翻译:** 逐次消除列表（SCL）译码已广泛应用于极化码，在列表尺寸足够大时，可以实现接近最大似然的性能。在这项工作中，我们表明，如果列表尺寸是 $2^\gamma$，其中 $\gamma$ 是称为混合因子的基本量，那么对SCL译码的修改可以实现Forney的广义译码规则。因此，它提供了一种有效的方法来丢弃不可靠的决策。通过蒙特卡洛模拟分析了所提出的广义SCL译码在短极化码下实现的性能。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [196] [Multi-RIS-Empowered Communication Systems: Capacity Analysis and Optimization](https://arxiv.org/abs/2507.16767)
> *多RIS赋能的通信系统：容量分析与优化*

*Aris L. Moustakas, George C. Alexandropoulos* | **Category: cs.IT, cs.ET, eess.SP, math.IT** | **Updated: 2025-07-22**

**Keywords:** 多RIS系统, 容量分析, 统计物理, 互信息, 信道优化

**Comment:** 24 pages, 5 figures, book chapter

> **TL;DR:** 本文利用统计物理方法，推导了多RIS存在下多天线收发对互信息的渐近闭式表达式，并发现统计RIS优化在信道相关时能带来显著增益，且可无需蛮力优化实现鲁棒通信。

**AI_Comments:** 本文通过引入统计物理方法和渐近分析，为多RIS赋能的通信系统容量分析和优化提供了新的视角。其创新点在于推导了互信息的闭式表达式和高斯近似，以及提出了基于信号相关矩阵渐近特性的非蛮力优化方法。这项工作对于未来无线通信系统中RIS的实际部署具有重要指导意义，尤其是在复杂信道条件下实现高效和鲁棒的通信。

<details>
  <summary>Details</summary>

**Motivation:** 在快速衰落条件下，信道估计具有挑战性，且传统优化RIS需要蛮力数值优化，本文旨在解决这些问题。

**Method:** 采用统计物理方法，推导了多天线收发对在多个可重构智能表面（RISs）存在下互信息的均值和方差的渐近闭式表达式。提出了互信息的近似高斯分布。利用入射和出射信号相关矩阵的新型渐近特性来优化超表面。

**Result:** 推导出了多RIS系统中互信息的均值和方差的渐近闭式表达式。证明了即使对于中等规模的天线阵列和超表面，所导出的互信息高斯近似也相当准确。分析表明，当RIS附近的信道相关时，统计RIS优化能显著提高通信链路性能，增益高于非相关情况。提出了可用于无需蛮力数值优化RIS的新型渐近相关矩阵特性。数值研究表明，即使反射偏离几何光学，超表面也能优化提供鲁棒通信链路，且无需严格的最佳放置。

**Conclusion:** 超表面可以被优化以提供鲁棒的通信链路，而无需对其进行最佳放置的显著需求。

> **ai_Abstract:** 本文利用统计物理方法，推导了多可重构智能表面（RIS）系统中多天线收发对互信息的均值和方差的渐近闭式表达式。研究发现，即使在快速衰落和信道估计困难的条件下，所提出的互信息高斯近似也具有较高精度。尤其是在RIS附近信道相关时，统计RIS优化能带来显著的性能增益。此外，文章提出了利用信号相关矩阵的渐近特性来优化超表面的方法，避免了复杂的蛮力优化，并证明了即使反射偏离几何光学，也能实现鲁棒的通信链路而无需严格的最佳放置。

> **摘要翻译:** 在本章中，利用统计物理方法，推导了在多个可重构智能表面（RISs）存在下，多天线收发对互信息的均值和方差的渐近闭式表达式。虽然名义上在大系统极限下有效，但结果表明，所推导的互信息高斯近似即使对于中等规模的天线阵列和超表面也相当准确。上述结果在存在快速衰落条件时特别有用，因为快速衰落使信道估计变得具有挑战性。所导出的分析表明，当RIS附近的信道相关时（例如由于小角度扩展，这对于载波频率不断增加的无线系统是合理的），通信链路从统计RIS优化中显著受益，导致增益出乎意料地高于几乎不相关的情况。更重要的是，所提出的RISs处入射和出射信号相关矩阵的新型渐近特性可以用于优化超表面，而无需蛮力数值优化。数值研究表明，当任何RIS的期望反射显著偏离几何光学时，超表面可以被优化以提供鲁棒的通信链路，而无需对其进行最佳放置的显著需求。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [307] [Decoding rank metric Reed-Muller codes](https://arxiv.org/abs/2501.04766)
> *秩度量Reed-Muller码的解码*

*Alain Couvreur, Rakhi Pratihar* | **Category: cs.IT, math.CO, math.IT** | **Updated: 2025-07-22**

**Keywords:** 秩度量Reed-Muller码, 解码算法, Dickson矩阵, 纠错码, 阿贝尔伽罗瓦扩张

**Comment:** 

> **TL;DR:** 本文提出了一种基于Dickson矩阵的多项式时间算法，用于解码秩度量Reed-Muller码，能够纠正秩高达最小距离一半的错误。

**AI_Comments:** 该论文的创新之处在于提出了一种针对新型秩度量Reed-Muller码的有效多项式时间解码算法。这对于纠错码领域，特别是在秩度量编码理论的实际应用中具有重要意义，因为它扩展了现有Gabidulin码的解码能力。

<details>
  <summary>Details</summary>

**Motivation:** 研究由Augot等人于2021年引入的秩度量Reed-Muller码的解码问题，这些码是Gabidulin码在阿贝尔伽罗瓦扩张上的扩展。

**Method:** 提出了一种基于Dickson矩阵结构的多项式时间算法。

**Result:** 该算法适用于任何秩度量Reed-Muller码，并能纠正秩高达最小距离一半的任何错误。

**Conclusion:** 成功开发了一种高效的算法，用于解码秩度量Reed-Muller码，能够纠正高达一半最小距离的错误。

> **ai_Abstract:** 本文研究了2021年引入的秩度量Reed-Muller码的解码问题，这些码是Gabidulin码在阿贝尔伽罗瓦扩张上的扩展。作者提出了一种基于Dickson矩阵结构的多项式时间算法，该算法能够对任何此类码进行解码，并纠正秩高达最小距离一半的错误。

> **摘要翻译:** 在本文中，我们研究了Augot、Couvreur、Lavauzelle和Neri于2021年引入的秩度量Reed-Muller码的解码问题。这些码由阿贝尔伽罗瓦扩张定义，扩展了在任意循环伽罗瓦扩张上Gabidulin码的构造。我们提出了一种基于Dickson矩阵结构的多项式时间算法，该算法适用于任何此类码，并能纠正秩高达最小距离一半的任何错误。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [361] [A DPI-PAC-Bayesian Framework for Generalization Bounds](https://arxiv.org/abs/2507.14795)
> *DPI-PAC-贝叶斯泛化界框架*

*Muhan Guan, Farhad Farokhi, Jingge Zhu* | **Category: cs.IT, math.IT, stat.ML** | **Updated: 2025-07-22**

**Keywords:** DPI-PAC-贝叶斯, 泛化界限, 数据处理不等式, PAC-贝叶斯, 信息论

**Comment:** 7 pages, 1 figures 2nd version

> **TL;DR:** 本文提出了一个统一的DPI-PAC-贝叶斯框架，用于推导监督学习中的泛化误差界限，通过结合数据处理不等式和测度变换技术，得到了更紧密的泛化界限，并与现有方法建立了联系。

**AI_Comments:** 这项工作通过整合数据处理不等式和PAC-贝叶斯理论，提供了一个创新且灵活的框架来推导泛化界限。其主要创新在于能够消除传统PAC-贝叶斯界限中的冗余松弛项，从而获得更紧密、更实际的界限。这对于理解和改进机器学习模型的泛化能力具有重要意义，提供了一个强大的信息论工具。

<details>
  <summary>Details</summary>

**Motivation:** 为了在监督学习环境中推导泛化误差界限，并解决现有PAC-贝叶斯界限中存在的冗余松弛问题，从而获得更紧密的结果。

**Method:** 开发了一个统一的DPI-PAC-贝叶斯框架，通过将数据处理不等式（DPI）嵌入到测度变换技术中。该框架用于导出针对Rényi散度和任意f-散度测量的二元Kullback-Leibler泛化差距的显式界限。

**Result:** 获得了Rényi、Hellinger (p) 和卡方散度下的显式界限。该框架还恢复了经典的奥卡姆剃刀界限，并消除了PAC-贝叶斯界限中存在的冗余\(\log(2\sqrt{n})/n\)松弛，从而实现了更紧密的结果。

**Conclusion:** 该DPI-PAC-贝叶斯框架连接了数据处理和PAC-贝叶斯视角，提供了一个灵活的信息论工具来构建泛化保证。

> **ai_Abstract:** 本文提出了一种新颖的DPI-PAC-贝叶斯框架，用于推导监督学习的泛化误差界限。该框架将数据处理不等式融入测度变换技术，从而为Rényi散度和f-散度导出了二元Kullback-Leibler泛化差距的显式界限。研究表明，该框架能恢复经典奥卡姆剃刀界限，并显著收紧了传统PAC-贝叶斯界限，消除了冗余项，提供了更精确的泛化保证，并连接了数据处理与PAC-贝叶斯理论。

> **摘要翻译:** 我们开发了一个统一的数据处理不等式PAC-贝叶斯框架——简称DPI-PAC-贝叶斯——用于在监督学习环境中推导泛化误差界限。通过将数据处理不等式（DPI）嵌入到测度变换技术中，我们获得了针对数据独立先验分布和算法相关后验分布之间测量的Rényi散度和任何f-散度的二元Kullback-Leibler泛化差距的显式界限。我们提出了在该框架下使用Rényi、Hellinger (p) 和卡方散度推导出的三个界限。此外，我们的框架还展示了与其它著名界限的紧密联系。当先验分布选择为均匀分布时，我们的界限恢复了经典的奥卡姆剃刀界限，并且关键地消除了PAC-贝叶斯界限中存在的冗余\(\log(2\sqrt{n})/n\)松弛，从而实现了更紧密的结果。因此，该框架连接了数据处理和PAC-贝叶斯视角，提供了一个灵活的信息论工具来构建泛化保证。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [716] [Byzantine-Resilient Distributed Computation via Task Replication and Local Computations](https://arxiv.org/abs/2507.16014)
> *拜占庭容错的分布式计算通过任务复制和局部计算*

*Aayush Rajesh, Nikhil Karamchandani, Vinod M. Prabhakaran* | **Category: cs.IT, cs.DC, math.IT** | **Updated: 2025-07-21**

**Keywords:** 拜占庭容错, 分布式计算, 任务复制, 本地计算, 通信效率

**Comment:** Accepted in 2025 IEEE Information Theory Workshop

> **TL;DR:** 研究在存在拜占庭工作节点情况下的分布式计算问题，通过任务复制和少量本地计算来解决子任务，并提出了优化本地计算和提高通信效率的协议。

**AI_Comments:** 该论文通过引入任务复制和优化本地计算来解决拜占庭容错的分布式计算问题，其创新点在于提出了在无通信约束下实现最优本地计算的协议，并进一步改进了通信效率，对于分布式系统中的鲁棒性设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决存在拜占庭工作节点时的分布式计算问题，目标是正确解决所有子任务并最小化昂贵的本地计算。

**Method:** 1. 通过任务复制将子任务分配给工作节点；2. 解决少量本地子任务；3. 提出一种针对通用平衡任务分配的协议，该协议在无通信约束下使用最优数量的本地计算；4. 提出该协议的修改版本以提高通信效率。

**Result:** 1. 在通用平衡任务分配下，成功解决了所有子任务，并使用了最优数量的本地计算；2. 给出了循环分配的闭式性能结果；3. 提出了在不影响本地计算量的情况下提高通信效率的协议修改。

**Conclusion:** 该研究提出了在存在拜占庭工作节点时进行分布式计算的协议，这些协议能够通过任务复制和少量本地计算来有效解决问题，并优化了本地计算量和通信效率。

> **ai_Abstract:** 本文研究了在拜占庭工作节点环境下，中心节点如何通过任务复制和少量本地计算来完成分布式任务。作者提出了一种针对通用平衡任务分配的协议，该协议在最优本地计算量下解决所有子任务，并提供了循环分配的闭式性能结果。此外，还提出了一个改进协议以提升通信效率，同时不牺牲本地计算量。

> **摘要翻译:** 我们研究了在存在拜占庭工作节点情况下的分布式计算问题，其中一个中心节点希望解决一个被划分为独立子任务的任务，每个子任务都需要被正确解决。分布式计算通过在工作节点之间复制分配子任务计算以及少量本地计算来实现，我们希望将本地计算最小化，因为它成本高昂。对于一般的平衡作业分配，我们提出了一种协议，该协议在没有通信约束的情况下，使用最优数量的本地计算成功解决了所有子任务。对于循环分配，我们给出了闭式性能结果。此外，我们提出对该协议进行修改，以在不影响本地计算量的情况下提高通信效率。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [82] [A Sparsity-Aware Autonomous Path Planning Accelerator with HW/SW Co-Design and Multi-Level Dataflow Optimization](https://arxiv.org/abs/2507.16177)
> *一种稀疏性感知的自主路径规划加速器，采用软硬件协同设计和多级数据流优化*

*Yifan Zhang, Xiaoyu Niu, Hongzheng Tian, Yanjun Zhang, Bo Yu, Shaoshan Liu, Sitao Huang* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 路径规划, FPGA加速, 二次规划, 稀疏矩阵, 数据流优化

**Comment:** Accepted by ACM Transactions on Architecture and Code Optimization
  (ACM TACO)

> **TL;DR:** 本文提出了一种基于FPGA的端到端加速框架，通过稀疏性感知优化和多级数据流策略，显著提升了自动驾驶路径规划的性能和能效。

**AI_Comments:** 该论文在自动驾驶路径规划加速方面取得了显著进展。其创新点在于全面的软硬件协同设计，特别是稀疏性感知优化和多级数据流策略的结合，有效利用了二次规划问题的特性。实验结果表明其在性能和能效方面均达到最先进水平，对于资源受限的自动驾驶系统具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 路径规划对于自动驾驶至关重要，但其计算密集型特性对资源受限的自动驾驶硬件构成了重大挑战，需要高效的加速解决方案。

**Method:** 本文提出了一种基于FPGA的加速框架，针对二次规划（QP）问题。采用硬件友好的交替方向乘子法（ADMM）和可并行化的预条件共轭梯度法（PCG）。通过分析稀疏矩阵模式，设计了定制存储方案和高效稀疏矩阵乘法单元，并采用多级数据流优化策略（包括算子内并行化/流水线化、算子间细粒度流水线化以及CPU-FPGA系统级任务映射）。

**Result:** 在AMD ZCU102平台上实现，达到了最先进的延迟和能效。性能比最佳基于FPGA的设计快1.48倍，比Intel i7-11800H CPU快2.89倍，比ARM Cortex-A57嵌入式CPU快5.62倍，比最先进的GPU解决方案快1.56倍。吞吐量比现有基于FPGA的设计提高了2.05倍。

**Conclusion:** 该框架成功解决了自动驾驶路径规划的计算挑战，通过创新的软硬件协同设计和优化，实现了卓越的性能和能效。

> **ai_Abstract:** 本文提出了一种基于FPGA的端到端加速框架，专注于解决自动驾驶路径规划中的二次规划（QP）问题。该框架采用硬件友好的ADMM和PCG方法，并通过稀疏性感知定制存储方案和高效稀疏矩阵乘法单元来优化资源使用和加速运算。结合多级数据流优化策略，该框架在AMD ZCU102平台上实现了卓越的性能和能效，超越了现有FPGA、CPU和GPU解决方案，显著提升了自动驾驶路径规划的效率。

> **摘要翻译:** 路径规划对于自动驾驶至关重要，它根据感知和定位输入生成平滑、无碰撞、可行的路径。然而，其计算密集型特性对资源受限的自动驾驶硬件构成了重大挑战。本文提出了一种基于FPGA的端到端加速框架，旨在解决基于优化的路径规划核心——二次规划（QP）问题。我们采用了一种硬件友好的交替方向乘子法（ADMM）来解决QP问题，并使用了一种可并行化的预条件共轭梯度法（PCG）来解决线性系统。通过分析稀疏矩阵模式，我们提出了定制的存储方案和高效的稀疏矩阵乘法单元，显著减少了资源使用并加速了矩阵运算。我们的多级数据流优化策略包括算子内并行化和流水线化、算子间细粒度流水线化以及CPU-FPGA系统级任务映射。我们的框架在AMD ZCU102平台上实现，达到了最先进的延迟和能效，包括比最佳基于FPGA的设计快1.48倍，比Intel i7-11800H CPU快2.89倍，比ARM Cortex-A57嵌入式CPU快5.62倍，比最先进的GPU解决方案快1.56倍，同时比现有基于FPGA的设计吞吐量提高了2.05倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [127] [Hourglass Sorting: A novel parallel sorting algorithm and its implementation](https://arxiv.org/abs/2507.16326)
> *沙漏排序：一种新颖的并行排序算法及其实现*

*Daniel Bascones, Borja Morcillo* | **Category: cs.AR, B.5.0** | **Updated: 2025-07-22**

**Keywords:** 并行排序, 沙漏排序, FPGA, 数据传输瓶颈, 亚线性时间

**Comment:** 6 pages, 5 figures

> **TL;DR:** 本文提出了一种名为沙漏排序的新型并行排序算法，解决了现有并行排序方法在数据量大时面临的实现成本高和数据传输瓶颈问题。该算法针对并行输入和串行输出的特定情况，在FPGA上实现并验证，实现了对首个元素输出的对数级延迟和总计n+logn的排序时间，且时钟速度不随n下降，资源随输入规模线性扩展。

**AI_Comments:** 本文提出了一种创新的并行排序算法“沙漏排序”，其独特之处在于针对并行输入和串行输出的特定场景进行了优化。通过在FPGA上的实现，它有效解决了现有并行排序方法在高数据量下的实现成本和数据传输瓶颈问题。尤其值得关注的是，该算法在性能上实现了对数级延迟和$n+\\log{n}$的总排序时间，并且时钟速度不随输入规模下降，资源线性扩展，这对于大规模数据处理和硬件实现具有重要意义。其在量子LDPC解码器背景下的应用也展现了其潜在的实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的并行排序技术虽然可以将复杂度降低到亚线性时间，但会增加实现成本，限制了其应用。此外，随着数组规模的增大，大量数据输入输出的移动会成为瓶颈，其时间要求可能比排序本身更严格。

**Method:** 本文提出了一种新颖的并行排序器，专门针对输入并行但输出串行的情况。该设计在量子LDPC解码器的背景下，于FPGA上实现并验证。

**Result:** 该算法实现了对第一个元素输出的对数级（$\\log{n}$）延迟，之后其余元素流出，总排序时间为$n+\\log{n}$。与其他并行排序方法不同，时钟速度不随$n$下降，并且资源随输入规模线性扩展。

**Conclusion:** 本文提出的沙漏排序算法在并行输入、串行输出的特定场景下，通过在FPGA上的实现和验证，展示了高效的性能，解决了现有并行排序方法在实现成本和数据传输方面的挑战，并展现出良好的可扩展性。

> **ai_Abstract:** 本文介绍了一种名为“沙漏排序”的新型并行排序算法，旨在解决传统并行排序方法在高数据量下遇到的实现成本和数据传输瓶瓶颈问题。该算法专为并行输入和串行输出的场景设计，并在FPGA上进行了实现和验证，作为量子LDPC解码器的一部分。实验结果表明，该算法能实现对首个元素对数级延迟和总计$n+\\log{n}$的排序时间，同时保持时钟速度不随输入规模下降，并且资源消耗呈线性增长，展现了其高效性和可扩展性。

> **摘要翻译:** 排序是计算机科学中的一个基本问题。它在许多过程中发挥作用，在顺序机器上执行时，其复杂度下限为 $\\mathcal{O}(n\\log{n})$。通过并行化技术可以将其降低到亚线性时间，从而增加并行比较的数量。然而，这增加了实现成本，限制了此类技术的应用。此外，随着数组规模的增大，在移动此类排序器输入所需和输出生成的大量数据时会出现瓶颈。这可能会施加比排序本身更严格的时间要求。在本文中，针对输入并行但输出串行这一特定情况，提出了一种新颖的并行排序器。然后，该设计在量子LDPC解码器的背景下，在FPGA上实现并验证。第一个元素的输出延迟为 $\\log{n}$，之后其余元素流出，总排序时间为 $n+\\log{n}$。与其他并行排序方法相反，时钟速度不随 $n$ 下降，并且资源随输入规模线性扩展。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [172] [ApproxGNN: A Pretrained GNN for Parameter Prediction in Design Space Exploration for Approximate Computing](https://arxiv.org/abs/2507.16379)
> *ApproxGNN：一种用于近似计算设计空间探索中参数预测的预训练GNN*

*Ondrej Vlcek, Vojtech Mrazek* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 近似计算, 设计空间探索, 图神经网络, 参数预测, 学习嵌入

**Comment:** To appear at ICCAD 2025

> **TL;DR:** ApproxGNN是一种预训练图神经网络，它使用学习到的嵌入来高效准确地预测近似计算加速器的性能和硬件成本，显著优于现有方法。

**AI_Comments:** ApproxGNN的创新之处在于其预训练的GNN架构和基于学习嵌入的组件特征提取，这极大地提高了模型对新电路的迁移能力和预测效率，克服了传统机器学习方法在近似计算DSE中面临的计算开销大的问题。其在精度上的显著提升（50%至54%）也凸显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 近似计算虽然能提高能效，但寻找最优近似方案需要大量设计空间探索（DSE）。现有机器学习方法在预测近似电路精度时，需要针对每种新电路配置进行再训练，导致计算成本高且耗时。

**Method:** 本文提出了ApproxGNN，一种构建预训练图神经网络模型的方法。该模型通过从库中选择近似加法器来预测近似加速器的性能（QoR）和硬件成本。它引入了基于学习嵌入而非传统误差度量的新颖组件特征提取，从而提高了对未知电路的迁移能力。ApproxGNN模型只需少量近似组件即可训练，支持多任务预测，并利用预计算嵌入提高效率。

**Result:** 在图像卷积滤波器集上的实验结果表明，所提出的嵌入方法将预测精度（均方误差）比传统方法提高了50%。此外，整体预测精度比统计机器学习方法在不进行微调的情况下提高了30%，在快速微调后提高了54%。

**Conclusion:** ApproxGNN通过引入预训练GNN和新颖的学习嵌入，显著提高了近似计算设计空间探索中参数预测的效率和准确性，克服了现有机器学习方法的局限性。

> **ai_Abstract:** 本文提出了ApproxGNN，一个用于近似计算设计空间探索的预训练图神经网络模型。它通过学习嵌入来预测近似加速器的质量和硬件成本，解决了现有机器学习方法需要频繁再训练且效率低下的问题。ApproxGNN在预测近似误差方面表现出显著更高的准确性，实验证明其预测精度比传统方法提高了50%，比统计机器学习方法提高了30%（无微调）至54%（有微调）。

> **摘要翻译:** 近似计算为容错应用提供了有前景的能效优势，但发现最优近似需要广泛的设计空间探索（DSE）。在不进行完整综合的情况下预测由近似组件组成的电路的精度仍然是一个具有挑战性的问题。当前用于自动化此任务的机器学习方法需要为每个新的电路配置进行再训练，这使得它们计算成本高且耗时。本文提出了ApproxGNN，一种预训练图神经网络模型的构建方法，用于预测采用库中近似加法器的近似加速器的QoR和硬件成本。该方法适用于在加速器中将近似组件分配给操作的设计空间探索。我们的方法引入了基于学习嵌入而非传统误差度量的新颖组件特征提取，从而提高了对未知电路的迁移能力。ApproxGNN模型可以用少量近似组件进行训练，支持迁移到多个预测任务，利用预计算嵌入提高效率，并显著提高了近似误差预测的准确性。在一组图像卷积滤波器上，我们的实验结果表明，所提出的嵌入方法比传统方法将预测精度（均方误差）提高了50%。此外，整体预测精度在不进行微调的情况下比统计机器学习方法提高了30%，在快速微调后提高了54%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [217] [Ironman: Accelerating Oblivious Transfer Extension for Privacy-Preserving AI with Near-Memory Processing](https://arxiv.org/abs/2507.16391)
> *钢铁侠：利用近内存处理加速隐私保护AI中的不经意传输扩展*

*Chenqi Lin, Kang Yang, Tianshi Xu, Ling Liang, Yufei Wang, Zhaohui Chen, Runsheng Wang, Mingyu Gao, Meng Li* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 不经意传输, 隐私保护机器学习, 近内存处理, 硬件加速, SPCOT, LPN

**Comment:** 

> **TL;DR:** 本文提出了一种名为Ironman的新型不经意传输（OT）加速器，通过定制硬件加速SPCOT计算和利用近内存处理（NMP）优化LPN操作，显著提升了隐私保护机器学习（PPML）的效率和端到端延迟。

**AI_Comments:** Ironman的创新在于它针对不经意传输（OT）原语中的两种不同瓶颈（计算密集型SPCOT和内存带宽受限型LPN）提出了差异化的优化方案，即定制硬件加速和近内存处理。这种结合硬件设计和内存优化的方法，对于提升隐私保护机器学习的实际可用性具有重要意义，因为它直接解决了当前PPML框架中的关键性能瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器学习的广泛应用，用户数据中的隐私问题日益突出。隐私保护机器学习（PPML）作为一种有前景的解决方案，但其对不经意传输（OT）原语的重度依赖使其成为现代PPML框架的延迟瓶颈，因为OT主要在通用CPU上进行大量计算。

**Method:** 本文提出了一种名为Ironman的新型OT加速器。针对计算密集型的单点关联不经意传输（SPCOT），提出了一种硬件友好的SPCOT算法并设计了定制加速器以提高计算吞吐量。针对内存带宽受限的学习奇偶校验与噪声（LPN）操作，利用配备内存侧缓存和索引排序的近内存处理（NMP）架构来提高有效内存带宽。

**Result:** Ironman在不同NMP配置下，与全线程CPU实现相比，OT吞吐量提高了39.2-237.4倍。对于不同的PPML框架，Ironman将CNN和Transformer模型的端到端延迟降低了2.1-3.4倍。

**Conclusion:** Ironman加速器通过优化SPCOT和LPN操作，显著提升了不经意传输的效率，从而有效降低了隐私保护机器学习框架的整体延迟，证明了其在加速隐私保护AI方面的巨大潜力。

> **ai_Abstract:** 本文提出了一种名为Ironman的硬件加速器，旨在解决隐私保护机器学习（PPML）中不经意传输（OT）的性能瓶颈。针对OT中的SPCOT操作，Ironman设计了定制的硬件加速器以提高计算吞吐量；针对LPN操作，则利用近内存处理（NMP）架构优化内存带宽。实验结果表明，Ironman显著提升了OT吞吐量，并有效降低了PPML框架的端到端延迟，从而加速了隐私保护AI的实际应用。

> **摘要翻译:** 随着机器学习（ML）的广泛应用，用户数据可能包含敏感信息，从而引发隐私担忧。基于密码原语的隐私保护机器学习（PPML）已成为一种有前景的解决方案，其中ML模型直接在加密数据上进行计算，以提供正式的隐私保证。然而，PPML框架严重依赖不经意传输（OT）原语来计算非线性函数。OT主要涉及单点关联OT（SPCOT）和带噪声学习奇偶校验（LPN）操作的计算。由于OT仍然在通用CPU上进行大量计算，它成为现代PPML框架的延迟瓶颈。
在本文中，我们提出了一种新型OT加速器，名为Ironman，旨在显著提高OT和整个PPML框架的效率。我们观察到SPCOT是计算受限的，因此提出了一种硬件友好的SPCOT算法和定制加速器以提高SPCOT计算吞吐量。相比之下，LPN由于不规则的内存访问模式而受限于内存带宽。因此，我们进一步利用配备内存侧缓存和索引排序的近内存处理（NMP）架构来提高有效内存带宽。通过大量实验，我们证明了Ironman在不同NMP配置下，与全线程CPU实现相比，OT吞吐量实现了39.2-237.4倍的提升。对于不同的PPML框架，Ironman在CNN和Transformer模型上的端到端延迟均降低了2.1-3.4倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [255] [Augmenting Von Neumann's Architecture for an Intelligent Future](https://arxiv.org/abs/2507.16628)
> *增强冯·诺依曼架构以实现智能未来*

*Rajpreet Singh, Vidhi Kothari* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 冯·诺依曼架构, 推理单元, 通用人工智能, 计算机架构, 协同设计

**Comment:** 6 pages, 2 figures

> **TL;DR:** 该工作提出了一种通过增加推理单元来扩展冯·诺依曼架构的新型计算机体系结构，旨在实现原生的通用人工智能能力。

**AI_Comments:** 这项工作通过在硬件层面集成推理单元，对传统冯·诺依曼架构进行了创新性扩展，旨在克服当前AI系统对纯软件抽象的依赖。其重要性在于，如果成功，它能使智能行为（如推理和学习）成为计算基质的固有部分，从而可能显著提升通用智能的效率和规模。然而，实现这种跨硬件、操作系统和运行时层的深度协同设计将面临巨大的工程挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有冯·诺依曼模型不足以原生支持通用人工智能（AGI）能力，需要一种新的架构来使推理、学习和适应成为系统固有的执行属性。

**Method:** 提出了一种新型计算机架构，通过增加一个专用的推理单元（RU）来扩展冯·诺依曼模型。RU作为一个协处理器，执行符号推理、多智能体协调和混合符号-神经计算。该架构包含推理专用指令集、并行符号处理流水线、智能体感知内核抽象和统一内存层次结构，并进行硬件、操作系统和智能体运行时层的系统协同设计。

**Result:** 这种硬件嵌入式方法使得自主智能体能够直接在计算基质中执行目标导向规划、动态知识操作和内省推理。推理、学习和适应将作为固有的执行属性而非软件抽象而出现。

**Conclusion:** 通过硬件、操作系统和智能体运行时层的系统协同设计，该架构为计算奠定了基础，使推理、学习和适应成为固有的执行属性，从而可能实现通用智能机器的开发。

> **ai_Abstract:** 本文提出了一种扩展冯·诺依曼模型的新型计算机架构，通过引入专用的推理单元（RU）实现原生的通用人工智能（AGI）能力。该RU作为协处理器，支持符号推理、多智能体协调和混合计算。新架构包含专用指令集、并行处理和统一内存，旨在将推理、学习和适应作为系统固有属性，而非软件抽象，从而为开发通用智能机器奠定基础。

> **摘要翻译:** 这篇工作提出了一种新颖的计算机架构，它通过一个专用的推理单元（RU）扩展了冯·诺依曼模型，以实现原生的通用人工智能能力。推理单元作为一个专业的协处理器，执行符号推理、多智能体协调和混合符号-神经计算，作为基本的架构原语。这种硬件嵌入式方法使得自主智能体能够直接在系统规模的计算基质中执行目标导向规划、动态知识操作和内省推理。该架构结合了推理专用指令集架构、并行符号处理流水线、智能体感知内核抽象以及统一的内存层次结构，无缝地集成认知和数值工作负载。通过硬件、操作系统和智能体运行时层的系统协同设计，该架构建立了一个计算基础，其中推理、学习和适应作为固有的执行属性而非软件抽象而出现，这可能促进通用智能机器的开发。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [312] [MTU: The Multifunction Tree Unit in zkSpeed for Accelerating HyperPlonk](https://arxiv.org/abs/2507.16793)
> *MTU：zkSpeed 中用于加速 HyperPlonk 的多功能树单元*

*Jianqiao Mo, Alhad Daftardar, Joey Ah-kiow, Kaiyue Guo, Benedikt Bünz, Siddharth Garg, Brandon Reagen* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 零知识证明, 硬件加速, 二叉树, MTU, 混合遍历, HyperPlonk

**Comment:** 

> **TL;DR:** 本文评估了在CPU和MTU上不同遍历策略下基于树的零知识证明工作负载，并引入了一种混合遍历方法。结果显示MTU比CPU快1478倍，混合遍历比独立方法快3倍，为ZKP硬件加速提供了指导。

**AI_Comments:** 这篇论文通过引入MTU硬件加速器和创新的混合遍历策略，显著提升了零知识证明中核心树状计算的效率。其创新点在于对底层树模式的深入利用，并提供了实际的硬件加速数据，对于未来高效ZKP硬件设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零知识证明加速研究主要关注作为整体协议的一部分，但对于如何最佳地利用底层树模式以提高硬件效率的专门研究仍然有限。

**Method:** 作者对不同遍历策略下基于树的工作负载进行了系统评估，分析了其在多线程CPU和硬件加速器（多功能树单元MTU）上的性能。他们还引入了一种硬件友好的二叉树混合遍历方法，以提高并行性、可扩展性并显著减少硬件上的内存流量。

**Result:** MTU在DDR级带宽下比CPU实现了高达1478倍的加速。所提出的混合遍历方法比独立方法性能提升高达3倍。

**Conclusion:** 这些发现为设计具有二叉树结构的零知识证明工作负载的高效硬件加速器提供了实用指导。

> **ai_Abstract:** 本文研究了零知识证明（ZKPs）中基于二叉树计算模式的核心组件的硬件加速。针对现有研究对底层树模式利用不足的问题，作者系统评估了不同遍历策略在CPU和新引入的多功能树单元（MTU）硬件加速器上的性能。通过引入一种硬件友好的混合遍历方法，该研究显著提高了并行性、可扩展性并减少了内存流量。实验结果显示，MTU比CPU有高达1478倍的加速，且混合遍历方法比传统方法性能提升高达3倍，为ZKP硬件加速器设计提供了重要指导。

> **摘要翻译:** 零知识证明（ZKPs）对于隐私保护和可验证计算至关重要。许多ZKPs依赖于SumCheck协议和Merkle树承诺等核心组件，这些组件确保了其安全特性。这些核心组件表现出平衡的二叉树计算模式，这使得高效的硬件加速成为可能。先前的研究已经调查了作为整体ZKP协议一部分的这些核心组件的加速；然而，关于如何最佳利用底层树模式以提高硬件效率的专门研究仍然有限。我们对不同遍历策略下这些基于树的工作负载进行了系统评估，分析了在多线程CPU和硬件加速器（多功能树单元MTU）上的性能。我们引入了一种硬件友好的二叉树混合遍历方法，该方法提高了并行性和可扩展性，同时显著减少了硬件上的内存流量。我们的结果表明，MTU在DDR级带宽下比CPU实现了高达1478倍的加速，并且我们的混合遍历方法比独立方法性能提升高达3倍。这些发现为设计具有二叉树结构的ZKP工作负载的高效硬件加速器提供了实用指导。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [474] [Per-Bank Bandwidth Regulation of Shared Last-Level Cache for Real-Time Systems](https://arxiv.org/abs/2410.14003)
> *实时系统中共享末级缓存的每Bank带宽调节*

*Connor Sullivan, Alex Manley, Mohammad Alian, Heechul Yun* | **Category: cs.AR** | **Updated: 2025-07-21**

**Keywords:** 缓存Bank争用, 带宽调节, 实时系统, LLC, DoS攻击

**Comment:** Update to Fig. 11: The previous version used mismatched cache
  capacities between the 2-bank and 4-bank configurations in the simulation
  setup. This has been corrected to ensure both configurations have equal total
  cache capacity. As a result, the specific numerical results in Fig. 11 have
  changed. However, the overall trend shown in Fig. 11 and key findings of the
  paper remain consistent

> **TL;DR:** 本文提出了一种针对多Bank共享末级缓存的每Bank带宽调节方法，以防止缓存Bank争用，提高实时系统的性能和可预测性，并有效抵御Bank感知的DoS攻击。

**AI_Comments:** 该论文提出了一种创新的、细粒度的缓存带宽调节机制，解决了多核实时系统中共享LLC的Bank争用和恶意攻击问题。其创新点在于将带宽调节从Bank无关提升到每Bank级别，有效避免了过度节流，提高了系统吞吐量和实时任务的保护能力。对于提高实时系统的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代多核处理器中的共享末级缓存（LLC）虽然通过多Bank设计提升了内存级并行性，但核心之间不均匀的缓存请求分布，特别是请求集中在单个Bank时，会导致严重的争用，影响所有访问缓存的核心。这种缓存Bank争用甚至可能被恶意利用，形成缓存Bank感知的拒绝服务（DoS）攻击，从而危及系统的时序可预测性。

**Method:** 本文提出了一种针对多Bank共享LLC的多核实时系统的每Bank带宽调节方法。该方法通过在每个Bank基础上调节带宽，旨在防止对非争用Bank的缓存访问进行不必要的节流，从而在不损害节流隔离益处的情况下提高整体性能（吞吐量）。该方法在基于FireSim的RISC-V片上系统（SoC）平台上实现，并使用合成和真实世界工作负载进行了广泛评估。

**Result:** 评估结果表明，所提出的每Bank调节方法有效保护了实时任务免受共同运行的缓存Bank感知DoS攻击。与先前的Bank无关的带宽节流方法相比，该方法为被节流的良性尽力而为任务提供了高达3.66倍的性能提升。

**Conclusion:** 该论文提出并验证了一种有效的每Bank带宽调节方法，可以显著提高共享末级缓存的性能，增强实时系统的预测性，并有效抵御缓存Bank感知的DoS攻击。

> **ai_Abstract:** 本文针对现代多核处理器中共享末级缓存（LLC）的Bank争用问题，特别是恶意Bank感知DoS攻击对实时系统时序可预测性的威胁，提出了一种每Bank带宽调节方法。该方法旨在通过对每个缓存Bank进行独立带宽管理，避免对非争用Bank的不必要节流，从而在保持隔离性的同时提高系统整体性能。在RISC-V SoC平台上的实验证明，该方法能有效防御DoS攻击，并为被节流的良性任务带来显著的性能提升。

> **摘要翻译:** 现代商用（COTS）多核处理器拥有先进的内存层次结构，可增强内存级并行性（MLP），这对于高性能至关重要。为了支持高MLP，共享末级缓存（LLC）被划分为多个Bank，允许并行访问。然而，来自核心的缓存请求分布不均，特别是当来自多个核心的请求集中在单个Bank时，可能导致严重的争用，影响所有访问缓存的核心。这种缓存Bank争用甚至可能被恶意诱导——被称为缓存Bank感知拒绝服务（DoS）攻击——以危及系统的时序可预测性。
在本文中，我们提出了一种针对多Bank共享LLC的基于多核实时系统的每Bank带宽调节方法。通过在每个Bank基础上调节带宽，该方法旨在防止对非争用Bank的缓存访问进行不必要的节流，从而在不损害节流隔离益处的情况下提高整体性能（吞吐量）。我们在基于FireSim的RISC-V片上系统（SoC）平台上实现了我们的方法，并使用合成和真实世界工作负载进行了广泛评估。我们的评估结果表明，所提出的每Bank调节方法有效保护了实时任务免受共同运行的缓存Bank感知DoS攻击，并且与先前的Bank无关的带宽节流方法相比，为被节流的良性尽力而为任务提供了高达3.66倍的性能改进。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [523] [GCC: A 3DGS Inference Architecture with Gaussian-Wise and Cross-Stage Conditional Processing](https://arxiv.org/abs/2507.15300)
> *GCC: 一种具有高斯级和跨阶段条件处理的3DGS推理架构*

*Minnan Pei, Gang Li, Junwen Si, Zeyu Zhu, Zitao Mo, Peisong Wang, Zhuoran Song, Xiaoyao Liang, Jian Cheng* | **Category: cs.AR** | **Updated: 2025-07-22**

**Keywords:** 3DGS, 推理加速器, 数据流, 高斯级渲染, 跨阶段条件处理

**Comment:** 

> **TL;DR:** GCC是一种新型3DGS推理加速器，通过引入跨阶段条件处理和高斯级渲染，显著提高了性能和能效，解决了现有加速器中不必要的高斯预处理和重复加载问题。

**AI_Comments:** GCC的创新性在于其数据流层面的优化，特别是跨阶段条件处理和高斯级渲染，这直接解决了3DGS推理中数据冗余和重复加载的核心痛点。这种设计思路对于实现高效的移动端3DGS应用至关重要，展示了硬件加速器在神经渲染领域的巨大潜力。该研究对于推动3DGS在实际应用中的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3DGS加速器采用的预处理-渲染解耦数据流存在两大局限性：1) 大部分预处理过的高斯在渲染中未使用；2) 同一高斯在不同瓦片渲染中被重复加载，导致巨大的计算和数据移动开销。

**Method:** 本文提出了GCC加速器，其数据流引入了：1) 跨阶段条件处理，交错预处理和渲染，动态跳过不必要的高斯预处理；2) 高斯级渲染，确保一个高斯的所有渲染操作完成后再处理下一个，消除重复加载。此外，还提出了一种基于alpha的边界识别方法来派生紧凑准确的高斯区域，降低渲染成本。

**Result:** GCC在28nm技术中实现，实验表明其在性能和能效方面显著优于最先进的3DGS推理加速器GSCore。

**Conclusion:** GCC通过优化3DGS推理的数据流和处理方式，有效解决了现有加速器的效率瓶颈，实现了卓越的性能和能效提升，为移动应用中的高保真视图合成提供了更优的硬件解决方案。

> **ai_Abstract:** 本文提出了一种名为GCC的新型3DGS推理加速器，旨在解决现有加速器在数据流中存在的效率低下问题，即不必要的高斯预处理和重复加载。GCC通过引入跨阶段条件处理和高斯级渲染，优化了预处理和渲染的交错执行，并确保高斯操作的完整性，从而显著减少了计算和数据移动开销。此外，还引入了基于alpha的边界识别方法以进一步降低渲染成本。实验结果表明，GCC在性能和能效上均优于现有的3DGS加速器GSCore。

> **摘要翻译:** 3D高斯泼溅 (3DGS) 已成为一种领先的用于高保真视图合成的神经渲染技术，促使了专用于移动应用的3DGS加速器的开发。通过深入分析，我们识别出现有加速器所采用的传统解耦预处理-渲染数据流的两个主要局限性：1) 大部分预处理过的高斯在渲染中未使用；2) 同一高斯在不同瓦片渲染中被重复加载，导致巨大的计算和数据移动开销。为了解决这些问题，我们提出了GCC，一种专为快速、节能3DGS推理设计的新型加速器。在数据流层面，GCC引入了：1) 跨阶段条件处理，它将预处理和渲染交错进行，以动态跳过不必要的高斯预处理；2) 高斯级渲染，确保给定高斯的所有渲染操作在移动到下一个高斯之前完成，从而消除重复的高斯加载。我们还提出了一种基于alpha的边界识别方法，以导出紧凑且准确的高斯区域，从而降低渲染成本。我们在28纳米技术中实现了我们的GCC加速器。大量实验表明，GCC在性能和能效方面均显著优于最先进的3DGS推理加速器GSCore。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [87] [Resilience Evaluation of Kubernetes in Cloud-Edge Environments via Failure Injection](https://arxiv.org/abs/2507.16109)
> *Kubernetes在云边环境中通过故障注入进行弹性评估*

*Zihao Chen, Mohammad Goudarzi, Adel Nadjaran Toosi* | **Category: cs.DC** | **Updated: 2025-07-21**

**Keywords:** Kubernetes, 弹性评估, 故障注入, 云边计算, 混沌工程

**Comment:** 

> **TL;DR:** 本文提出了一个评估云边Kubernetes弹性故障注入框架，并发现云边部署在网络延迟和分区下表现更好，而云部署在带宽限制下更具弹性。

**AI_Comments:** 本文的创新点在于提出了一个系统性的弹性评估框架，并首次为混合云边Kubernetes部署创建了大规模的弹性数据集。其发现为云边架构设计提供了宝贵的定量指导，有助于在实际应用中做出更明智的部署决策。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究中，针对混合云边环境中Kubernetes的系统性弹性评估有限，但Kubernetes在任务关键型微服务中的日益普及使得在实际故障条件下评估系统弹性变得至关重要。

**Method:** 提出了一个新颖的弹性评估框架，该框架整合了主流故障注入工具（如Chaos Mesh, Gremlin, ChaosBlade）和自动化工作负载生成，用于全面的云边Kubernetes测试。通过该框架，系统地针对云和云边环境中的节点级、Pod级和网络故障进行了综合实验。

**Result:** 首次创建了针对混合云边Kubernetes部署的综合弹性数据集（超过30GB，包含11,965个故障注入场景的性能数据）。分析显示，云边部署在网络延迟和分区条件下表现出80%的卓越响应稳定性，而云部署在带宽限制下表现出47%的更好弹性。

**Conclusion:** 本研究为云边部署中的架构决策提供了定量指导，通过对Kubernetes在混合云边环境中的弹性进行系统评估，揭示了不同部署模式在特定故障条件下的优势。

> **ai_Abstract:** 本文提出了一个新颖的弹性评估框架，通过整合主流故障注入工具和自动化工作负载生成，系统地评估了Kubernetes在混合云边环境中的弹性。研究创建了首个综合性云边Kubernetes弹性数据集，并通过实验发现云边部署在网络延迟和分区下表现出更高的响应稳定性，而云部署在带宽限制下更具弹性，为云边架构决策提供了量化依据。

> **摘要翻译:** Kubernetes已成为在云和边缘基础设施中部署容器化应用程序的重要平台。随着Kubernetes在任务关键型微服务中日益普及，在实际故障条件下评估系统弹性变得至关重要。然而，目前对混合云边环境中Kubernetes的系统性弹性评估研究有限。为了解决这一空白，本文提出了一个新颖的弹性评估框架，该框架整合了主流故障注入工具和自动化工作负载生成，用于全面的云边Kubernetes测试。多个故障注入平台，包括Chaos Mesh、Gremlin和ChaosBlade，与真实的流量模拟工具相结合，实现了复杂故障场景的自动化编排。通过该框架，进行了全面的实验，系统地针对云和云边环境中的节点级、Pod级和网络故障。首次创建了针对混合云边Kubernetes部署的综合弹性数据集，该数据集包含来自11,965个故障注入场景的超过30GB的性能数据，包括响应时间、故障率和错误模式。分析显示，云边部署在网络延迟和分区条件下表现出80%的卓越响应稳定性，而云部署在带宽限制下表现出47%的更好弹性，为云边部署中的架构决策提供了定量指导。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [132] [Parallel Ray Tracing of Black Hole Images Using the Schwarzschild Metric](https://arxiv.org/abs/2507.16165)
> *使用史瓦西度规的黑洞图像并行光线追踪*

*Liam Naddell, Marcelo Ponce* | **Category: cs.DC, cs.GR, gr-qc** | **Updated: 2025-07-22**

**Keywords:** 光线追踪, 黑洞, 并行计算, 史瓦西度规, 天体物理可视化

**Comment:** Published and presented at PEARC '25: Practice and Experience in
  Advanced Research Computing 2025: "The Power of Collaboration"

> **TL;DR:** 该论文描述了一个用于黑洞图像并行光线追踪的开源程序实现。

**AI_Comments:** 该工作通过开发一个并行开源的光线追踪程序，为黑洞图像的渲染提供了新的方法，尤其是在处理复杂黑洞几何体时。其创新点在于结合了多种并行计算策略，这对于提升计算效率和可访问性具有重要意义。作为一个开源项目，它也促进了科学可视化领域的合作与发展。

<details>
  <summary>Details</summary>

**Motivation:** 光线追踪技术在科学和天体物理可视化中广泛用于渲染黑洞图像，同时也在计算机图形学领域普遍应用。本文旨在解决在黑洞几何体存在下进行图像光线追踪的挑战，并提升其效率。

**Method:** 通过结合并行科学计算中的多种技术，如数学近似、利用科学库、共享内存和分布式内存并行，实现了一个并行开源程序，用于在黑洞几何体存在下进行图像光线追踪。

**Result:** 实现了并描述了一个开源的并行程序，该程序能够在黑洞几何体存在的情况下进行图像光线追踪。

**Conclusion:** 本文成功地描述并实现了一个利用并行计算技术进行黑洞图像光线追踪的开源程序。

> **ai_Abstract:** 本文介绍了一个用于渲染黑洞图像的并行开源光线追踪程序的实现。该程序结合了数学近似、科学库以及共享内存和分布式内存并行等多种并行科学计算技术，旨在高效地在黑洞几何体中生成黑洞图像。

> **摘要翻译:** 利用光线追踪技术渲染黑洞图像是科学和天体物理可视化许多方面常用的方法。同样，通用的光线追踪技术也广泛应用于计算机图形学相关领域。在这项工作中，我们描述了一个并行开源程序的实现，该程序可以在黑洞几何体存在的情况下追踪图像。我们通过结合并行科学计算中常用的几种不同技术来完成这项工作，例如数学近似、科学库的利用、共享内存和分布式内存并行。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [177] [Autonomous Dominant Resource Fairness for Blockchain Ecosystems](https://arxiv.org/abs/2507.16350)
> *区块链生态系统的自主主导资源公平性*

*Serdar Metin* | **Category: cs.DC** | **Updated: 2025-07-22**

**Keywords:** 区块链, 资源公平性, 主导资源公平性, 智能合约, 燃气效率

**Comment:** 10 pages, 3 figures

> **TL;DR:** 本文提出了一种名为“自主主导资源公平性”（ADRF）的算法，通过智能合约对预计算的主导资源公平性算法进行改进，以解决区块链环境中多资源类型分配的问题，该算法在燃气成本方面表现高效，并能管理大量资源类型和用户。

**AI_Comments:** 该论文的创新之处在于成功地将主导资源公平性（DRF）算法适配到区块链的特定约束（特别是燃气限制），通过避免循环迭代解决了传统DRF在区块链中应用的技术障碍。这对于在去中心化系统中实现高效且公平的多资源管理具有重要意义，填补了现有区块链资源分配领域的一个关键空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有区块链系统中的资源分配主要集中于单一资源或标准化捆绑资源的分配场景，未能有效处理具有异构资源需求的任务之间的多种资源类型分配问题。

**Method:** 本研究通过智能合约改编了预计算主导资源公平性（Precomputed Dominant Resource Fairness）算法，该算法近似于主导资源公平性，且无需循环迭代，从而规避了区块链的区块燃气限制。由此产生的算法被称为“自主主导资源公平性”（Autonomous Dominant Resource Fairness）。

**Result:** 实验结果表明，“自主主导资源公平性”算法是一种燃气成本高效的算法，能够管理数百种资源类型，并支持无限数量的用户。

**Conclusion:** “自主主导资源公平性”算法为区块链生态系统中异构多资源类型的公平分配提供了一种高效且可扩展的解决方案，成功克服了区块链固有的燃气限制。

> **ai_Abstract:** 本研究提出并验证了“自主主导资源公平性”（ADRF）算法，旨在解决区块链生态系统中多类型资源分配的挑战。通过智能合约对预计算主导资源公平性算法进行创新性改编，ADRF避免了循环迭代，从而规避了区块链的区块燃气限制。实证数据显示，ADRF是一种高效、低燃气成本的解决方案，能够有效地管理数百种资源类型并支持无限用户，为去中心化环境下的公平资源管理提供了可行路径。

> **摘要翻译:** 区块链系统已成为主流学术研究的一部分，并且是一个热门话题。它几乎已遍及计算机科学文献中的每个子领域，以及经济学和金融学。尤其是在一个亟需数字信任的世界中，区块链提供了多种理想的特性，例如不变性、公共审计、去中心化记录保存等。它不仅本身是一个研究主题，区块链与其他系统的集成也被提议作为许多领域的解决方案，范围从网格计算、云计算和雾计算，到物联网、自动驾驶汽车和智慧城市。在许多情况下，区块链在这些环境中被赋予的主要功能是资源管理。尽管对该主题给予了大量关注，但重点在于单一资源分配场景。即使是需要分配多种资源类型的情况，也被视为单一资源类型场景，并且问题被表述为分配由每种资源固定数量组成的标准化捆绑包，例如虚拟机。本研究通过智能合约改编了预计算主导资源公平性（Precomputed Dominant Resource Fairness）算法，解决了在具有异构资源需求的任务之间分配多种资源类型的问题；该算法近似于主导资源公平性，且无需循环迭代，这使其在区块链环境中更受青睐，因为它不受区块燃气限制。我们展示了由此产生的算法，即自主主导资源公平性，以及从该算法测试中收集到的经验数据。结果表明，自主主导资源公平性是一种燃气成本高效的算法，可用于管理数百种资源类型，并支持无限数量的用户。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [222] [FOGNITE: Federated Learning-Enhanced Fog-Cloud Architecture](https://arxiv.org/abs/2507.16668)
> *FOGNITE：联邦学习增强的雾云架构*

*Somayeh Sobati-M* | **Category: cs.DC** | **Updated: 2025-07-22**

**Keywords:** 联邦学习, 雾计算, 智能电网, 强化学习, 数字孪生

**Comment:** 

> **TL;DR:** FOGNITE是一个结合联邦学习、强化学习和数字孪生技术的雾云框架，用于提升智能电网的自治性、弹性和效率。

**AI_Comments:** FOGNITE的创新之处在于其将联邦学习、强化学习和数字孪生技术巧妙地结合在一个统一的雾云架构中，以解决智能电网的复杂挑战。这种多技术融合不仅提升了系统的智能化和适应性，还通过联邦学习解决了数据隐私问题，并通过数字孪生提高了决策的可靠性。其在真实测试台上的显著性能提升，证明了该框架的实用性和有效性，为未来可持续能源基础设施的发展提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 现代智能电网需要快速、智能、节能的边缘计算来管理实时波动并确保可靠运行，以应对分布式能源系统中的自治性、弹性和效率挑战。

**Method:** 本文提出了FOGNITE（基于雾的电网智能与神经网络集成和孪生执行）框架。它结合了三个核心组件：联邦学习（每个雾节点训练本地CNN LSTM模型，保护数据隐私），强化学习（动态调度任务以优化性能），以及数字孪生验证（在部署前模拟潜在动作，减少错误和能源浪费）。FOGNITE在Raspberry Pi设备组成的真实世界测试台上进行了评估。

**Result:** 与传统架构相比，FOGNITE在负载均衡精度方面提高了93.7%，能源浪费减少了63.2%。

**Conclusion:** FOGNITE通过将智能电网控制从被动纠正转向主动优化，代表着向更智能、适应性更强、可持续的能源基础设施迈进了一步。

> **ai_Abstract:** FOGNITE是一个为现代智能电网设计的下一代雾云框架，旨在提升分布式能源系统的自治性、弹性和效率。它整合了联邦学习以保护数据隐私并实现预测智能，强化学习以优化任务调度，以及数字孪生验证以减少错误和能源浪费。在真实世界的测试台上，FOGNITE在负载均衡精度和能源浪费方面显示出显著改进，标志着智能电网从被动管理向主动优化的转变。

> **摘要翻译:** 现代智能电网要求在边缘进行快速、智能和节能的计算，以管理实时波动并确保可靠运行。本文介绍了FOGNITE（基于雾的电网智能与神经网络集成和孪生执行），这是一个下一代雾云框架，旨在增强分布式能源系统的自主性、弹性和效率。FOGNITE结合了三个核心组件：联邦学习、强化学习和数字孪生验证。每个雾节点在私有能耗数据上训练本地CNN LSTM模型，通过联邦聚合在保护数据隐私的同时实现预测智能。强化学习代理根据当前系统负载和能源状况动态调度任务，优化不确定性下的性能。为了防止不安全或低效的决策，分层数字孪生层在部署前模拟潜在动作，显著减少执行错误和能源浪费。我们在一个由Raspberry Pi设备组成的真实世界测试台上评估了FOGNITE，结果显示与传统架构相比，负载均衡精度提高了93.7%，能源浪费减少了63.2%。通过将智能电网控制从被动纠正转向主动优化，FOGNITE代表着向更智能、适应性更强、可持续的能源基础设施迈进了一步。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [264] [AcceleratedKernels.jl: Cross-Architecture Parallel Algorithms from a Unified, Transpiled Codebase](https://arxiv.org/abs/2507.16710)
> *AcceleratedKernels.jl: 统一转译代码库中的跨架构并行算法*

*Andrei-Leonard Nicusan, Dominik Werner, Simon Branford, Simon Hartley, Andrew J. Morris, Kit Windows-Yule* | **Category: cs.DC, cs.PF** | **Updated: 2025-07-22**

**Keywords:** 并行计算, Julia, 异构计算, 转译, HPC

**Comment:** 

> **TL;DR:** AcceleratedKernels.jl是一个Julia并行计算库，通过独特的转译架构支持多种加速器，性能媲美C语言，并实现CPU-GPU协同处理，在HPC集群上展现出世界级排序吞吐量，且GPUDirect互连对GPU经济性至关重要。

**AI_Comments:** 这篇论文介绍了一个创新的Julia并行计算库，其亮点在于统一代码库实现跨架构支持和独特的转译机制，这大大简化了并行编程的复杂性。其性能表现与传统C/OpenMP相当，并在特定场景下展现出更优的数值一致性。尤其值得关注的是，论文通过实际案例强调了GPUDirect互连在提升GPU集群通信密集型任务经济性方面的关键作用，这对于HPC领域的未来发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一个统一、紧凑的代码库，以最小化实现和使用复杂性，实现高效的并行编程，并支持多架构加速器。

**Method:** 引入AcceleratedKernels.jl，一个后端无关的Julia并行计算库，通过独特的转译架构原生支持NVIDIA、AMD、Intel和Apple加速器。它采用统一的代码库，并支持CPU-GPU协同处理以及透明使用硬件专用MPI实现。

**Result:** 算术密集型内核的性能与C和OpenMP多线程CPU实现相当，Julia有时提供比传统C编译器更一致和可预测的数值性能。实现了出色的可组合性，例如CPU-GPU协同排序。在Baskerville Tier 2 UK HPC集群上，使用200个NVIDIA A100 GPU实现了538-855 GB/s的世界级排序吞吐量，与文献中报道的最高值（262,144个CPU核心实现900 GB/s）相当。使用直接NVLink GPU-to-GPU互连平均加速了4.93倍。

**Conclusion:** 结合资本、运行和环境成本来看，只有使用GPUDirect互连，通信密集型HPC任务在GPU上才具有经济可行性。

> **ai_Abstract:** AcceleratedKernels.jl是一个针对Julia的后端无关并行计算库，通过独特的转译架构支持多种加速器，旨在简化跨架构并行编程。它提供与C/OpenMP相当的性能，有时数值表现更优，并支持灵活的CPU-GPU协同处理。在HPC集群上，该库展现出世界级的排序吞吐量，并强调了GPUDirect互连对于提升GPU上通信密集型任务经济效益的关键作用。

> **摘要翻译:** AcceleratedKernels.jl被引入作为一个与后端无关的Julia并行计算库，通过独特的转译架构原生支持NVIDIA、AMD、Intel和Apple加速器。它以统一、紧凑的代码库编写，使得并行编程高效，并最大限度地降低了实现和使用复杂性。算术密集型内核的基准测试显示其性能与C和OpenMP多线程CPU实现相当，Julia有时比传统的C编译器提供更一致和可预测的数值性能。该库突出了卓越的可组合性，可以实现CPU-GPU协同处理——例如CPU-GPU协同排序——并透明地使用硬件专用的MPI实现。在英国Baskerville Tier 2 HPC集群上的测试，使用200个NVIDIA A100 GPU实现了538-855 GB/s的世界级排序吞吐量，与文献中报道的最高值（在262,144个CPU核心上实现的900 GB/s）相当。使用直接NVLink GPU-to-GPU互连平均带来了4.93倍的加速；若按综合资本、运行和环境成本进行标准化，通信密集型HPC任务只有在使用GPUDirect互连时，在GPU上才具有经济可行性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [317] [Collaborative Inference and Learning between Edge SLMs and Cloud LLMs: A Survey of Algorithms, Execution, and Open Challenges](https://arxiv.org/abs/2507.16731)
> *边缘SLM与云端LLM之间的协同推理与学习：算法、执行和开放挑战综述*

*Senyao Li, Haozhao Wang, Wenchao Xu, Rui Zhang, Song Guo, Jingling Yuan, Xian Zhong, Tianwei Zhang, Ruixuan Li* | **Category: cs.DC** | **Updated: 2025-07-22**

**Keywords:** LLM, SLM, 边缘计算, 云计算, 协同推理, 协同学习, 综述

**Comment:** 35 pages, 9 figures

> **TL;DR:** 本综述探讨了云端LLM与边缘SLM在推理和训练上的协同范式，并提供了系统性分类，以解决LLM部署中延迟、隐私、成本和个性化问题。

**AI_Comments:** 这是一篇重要的综述性文章，首次系统地构建了LLM-SLM协同的理论框架，对于解决大型模型在实际部署中的诸多瓶颈具有指导意义。其创新之处在于提出了统一的分类法，并全面覆盖了推理和训练阶段的协同策略，同时关注了隐私保护和实际应用。这有助于桥接系统与算法设计，推动边缘-云智能的发展。

<details>
  <summary>Details</summary>

**Motivation:** 由于延迟、隐私、成本和个性化等方面的担忧，将大型语言模型（LLMs）单独部署在云端或压缩到边缘设备已变得不足。

**Method:** 本综述提出了一种统一的边缘-云协同策略分类法。对于推理，将方法分为任务分配、任务划分和基于混合的协同（在任务和令牌粒度上），包括自适应调度、资源感知卸载、推测解码和模块化路由。对于训练，回顾了分布式适应技术，包括参数对齐、剪枝、双向蒸馏和小模型引导优化。此外，还总结了数据集、基准和部署案例，并强调了隐私保护方法和垂直应用。

**Result:** 本综述提出了一种统一的边缘-云协同策略分类法。在推理方面，分类了任务分配、任务划分和基于混合的协同方法。在训练方面，回顾了分布式适应技术。同时总结了相关数据集、基准测试和部署案例。

**Conclusion:** 本综述为LLM-SLM协同提供了第一个系统性基础，桥接了系统与算法的协同设计，以实现高效、可扩展和可信赖的边缘-云智能。

> **ai_Abstract:** 本综述探讨了云端大型语言模型（LLM）与边缘小型语言模型（SLM）协同推理和学习的新范式，以应对传统LLM部署在延迟、隐私、成本和个性化方面的挑战。文章提出了一个统一的边缘-云协同策略分类法，详细分析了推理阶段的任务分配、划分和混合协同方法，以及训练阶段的分布式适应技术。此外，还总结了相关数据集、基准和部署案例，并强调了隐私保护及垂直应用。本工作为LLM-SLM协同提供了首个系统性基础，旨在推动高效、可扩展和可信赖的边缘-云智能。

> **摘要翻译:** 随着大型语言模型（LLM）的发展，由于对延迟、隐私、成本和个性化的担忧，仅在云端部署它们或将其压缩到边缘设备已变得不足。本综述探讨了一种协同范式，其中基于云的LLM和部署在边缘的小型语言模型（SLM）在推理和训练中进行合作。我们提出了一个统一的边缘-云协同策略分类法。对于推理，我们将方法分为任务分配、任务划分和基于混合的协同，涵盖任务和令牌粒度，包括自适应调度、资源感知卸载、推测解码和模块化路由。对于训练，我们回顾了分布式适应技术，包括参数对齐、剪枝、双向蒸馏和小模型引导优化。我们进一步总结了数据集、基准和部署案例，并强调了隐私保护方法和垂直应用。本综述为LLM-SLM协同提供了第一个系统性基础，桥接了系统和算法的协同设计，以实现高效、可扩展和可信赖的边缘-云智能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [373] [Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems](https://arxiv.org/abs/2507.16781)
> *冷却至关重要：液冷与风冷H100 GPU系统上大型语言模型和视觉-语言模型的基准测试*

*Imran Latif, Muhammad Ali Shafique, Hayat Ullah, Alex C. Newkirk, Xi Yu, Arslan Munir* | **Category: cs.DC** | **Updated: 2025-07-22**

**Keywords:** 液冷, 风冷, H100 GPU, 大型语言模型, 视觉-语言模型, 基准测试, 数据中心, 能效

**Comment:** 11 pages

> **TL;DR:** 液冷H100 GPU系统在运行LLM和VLM时，比风冷系统温度更低，性能更高，能效更好。

**AI_Comments:** 这项研究通过实证基准测试，清晰地展示了液冷技术在高性能计算（特别是AI工作负载）中的显著优势。其创新之处在于直接量化了冷却方式对LLM/VLM性能、能效和系统效率的影响，为数据中心设计和运营提供了重要的数据支持。这对于应对AI时代日益增长的功耗和散热挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）工作负载（特别是大型语言模型LLMs和视觉-语言模型VLMs）的空前增长，加剧了数据中心的功耗和散热需求。

**Method:** 本研究在两个HGX节点（每个节点配备8块NVIDIA H100 GPU）上，分别使用液冷和风冷方式对LLMs和VLMs进行基准测试。利用GPU Burn、Weights and Biases和IPMItool工具收集详细的热量、功耗和计算数据。

**Result:** 液冷系统能将GPU温度维持在41-50摄氏度，而风冷系统在负载下温度波动在54-72摄氏度。液冷系统的热稳定性带来了17%的性能提升（每GPU 54 TFLOPs 对比 46 TFLOPs），以及更高的每瓦性能、更低的能耗开销和更高的系统效率。

**Conclusion:** 液冷技术在能源和可持续性方面具有显著优势，为超大规模数据中心提供了一个有前景的解决方案。

> **ai_Abstract:** 本研究对比了液冷与风冷H100 GPU系统在运行大型语言模型和视觉-语言模型时的性能表现。研究发现，液冷系统能有效降低GPU温度，从而显著提升17%的计算性能，并带来更高的能效和整体系统效率。这些结果突显了液冷技术在应对AI工作负载带来的数据中心能源和散热挑战方面的巨大潜力。

> **摘要翻译:** 人工智能（AI）工作负载的空前增长，近期主要由大型语言模型（LLMs）和视觉-语言模型（VLMs）主导，加剧了数据中心的功耗和散热需求。本研究在两个HGX节点上对LLMs和VLMs进行了基准测试，每个节点配备8块NVIDIA H100图形处理单元（GPUs），分别使用液冷和风冷方式。我们利用GPU Burn、Weights and Biases和IPMItool收集了详细的热量、功耗和计算数据。结果显示，液冷系统将GPU温度维持在41-50摄氏度之间，而风冷系统在负载下则在54-72摄氏度之间波动。液冷系统的这种热稳定性带来了17%的性能提升（每GPU 54 TFLOPs 对比 46 TFLOPs），以及比风冷系统更高的每瓦性能、更低的能耗开销和更高的系统效率。这些发现强调了液冷在能源和可持续性方面的益处，为超大规模数据中心提供了引人注目的前进方向。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [401] [Static Analysis for Detecting Transaction Conflicts in Ethereum Smart Contracts](https://arxiv.org/abs/2507.04357)
> *以太坊智能合约中事务冲突的静态分析检测*

*Atefeh Zareh Chahoki, Marco Roveri* | **Category: cs.DC, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 静态分析, 事务冲突, 以太坊智能合约, 并发性, 区块链可扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的静态分析方法，用于在以太坊智能合约中检测潜在的事务冲突，通过分析状态变量访问模式来提高验证器吞吐量和区块链可扩展性。

**AI_Comments:** 本文提出了一种创新的静态分析方法来解决以太坊智能合约中的并发冲突问题，这对于提高区块链的吞吐量和可扩展性至关重要。其创新点在于将冲突检测从运行时提前到静态分析阶段，从而避免了传统运行时方法的巨大开销。高精度的评估结果表明了该方法的有效性。这项工作为未来的事务调度优化奠定了基础，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 以太坊智能合约在并发环境中运行，但EVM强制顺序执行以防止冲突，这限制了验证器利用多核架构提高吞吐量的能力。现有并发解决方案（运行时冲突检测和回滚）开销大。虽然静态预测冲突的方法有前景，但缺乏全面的研究。因此，需要一种有效的静态分析方法来提前检测事务冲突。

**Method:** 本文提出了一种新颖的静态分析方法，通过分析Solidity合约中的状态变量访问模式，识别事务对之间的读写冲突、写写冲突和函数调用冲突。作者实现了一个工具来解析合约代码并执行冲突检测。

**Result:** 在真实世界以太坊智能合约数据集上的评估表明，该方法在识别潜在冲突方面实现了高精度。

**Conclusion:** 该工具通过实现主动冲突检测，支持进一步设计事务调度策略，从而减少运行时故障，提高验证器吞吐量，并有助于区块链的可扩展性。

> **ai_Abstract:** 本文提出了一种新颖的静态分析方法，用于在以太坊智能合约中检测事务冲突。针对当前EVM顺序执行限制吞吐量以及现有运行时冲突检测开销大的问题，该方法通过分析Solidity合约中的状态变量访问模式，识别读写、写写和函数调用冲突。通过在真实世界数据集上的评估，该方法在冲突识别方面表现出高精度，旨在支持更优的事务调度策略，从而提高验证器吞吐量和区块链可扩展性。

> **摘要翻译:** 以太坊智能合约在并发环境中运行，多个事务可以同时提交。然而，以太坊虚拟机（EVM）在每个区块内强制事务顺序执行，以防止由于并发访问相同状态变量而引起的冲突。尽管这种方法保证了正确的行为，但它限制了验证器利用多核架构更快处理事务的能力，从而限制了吞吐量。现有解决方案通过允许同时执行事务并结合运行时冲突检测和回滚机制来引入并发性，以保持正确性。然而，这些方法由于持续的冲突跟踪和事务回滚而产生显著的开销。最近，出现了旨在通过分析智能合约代码中的潜在事务交互，在执行前静态预测冲突的替代方法。尽管它们有前景，但缺乏全面研究来检查静态冲突检测及其在特定智能合约中的更广泛影响。本文通过提出一种新颖的静态分析方法来检测以太坊智能合约中的潜在事务冲突，填补了这一重要空白。我们的方法通过分析Solidity合约中的状态变量访问模式，识别事务对之间的读写、写写和函数调用冲突。我们实现了一个工具来解析合约代码并执行冲突检测。在真实世界以太坊智能合约数据集上的评估表明，我们的方法在识别潜在冲突方面实现了高精度。通过实现主动冲突检测，我们的工具支持进一步设计事务调度策略，从而减少运行时故障，提高验证器吞吐量，并有助于区块链的可扩展性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [481] [Hydra: Virtualized Multi-Language Runtime for High-Density Serverless Platforms](https://arxiv.org/abs/2212.10131)
> *Hydra: 高密度无服务器平台虚拟化多语言运行时*

*Serhii Ivanenko, Vasyl Lanko, Rudi Horn, Vojin Jovanovic, Rodrigo Bruno* | **Category: cs.DC, cs.PL** | **Updated: 2025-07-22**

**Keywords:** 无服务器, 虚拟化, 多语言运行时, 冷启动, 函数密度

**Comment:** 

> **TL;DR:** Hydra是一个虚拟化多语言运行时，通过整合函数调用和预热实例池，显著提高了无服务器平台的密度，降低了内存占用和冷启动延迟。

**AI_Comments:** Hydra的创新在于其虚拟化多语言运行时设计，通过整合函数调用和预热实例池，有效解决了无服务器计算中的冷启动和资源浪费问题，显著提升了平台密度和响应速度。

<details>
  <summary>Details</summary>

**Motivation:** 现有无服务器平台由臃肿的虚拟化堆栈支持，结合突发和不规则的调用，导致高内存和延迟开销。

**Method:** 提出Hydra，一个虚拟化多语言运行时和平台，能够同时托管多个沙盒。重新审视现有无服务器平台设计，使其能够感知跨所有者和功能的协同定位，并具有预分配的Hydra实例缓存层以减少冷启动。还提出了一种快照机制来检查点和恢复单个沙盒。

**Result:** 通过Hydra整合多个无服务器函数调用，与OpenWhisk运行时相比，整体函数密度（ops/GB-sec）平均提高2.41倍；与Knative运行时相比，平均提高1.43倍。在Azure Functions跟踪中，运行Hydra实例的无服务器平台与运行OpenWhisk实例相比，总内存占用减少21.3-43.9%；与运行Knative实例相比，减少14.5-30%。Hydra消除了冷启动，与OpenWhisk相比，p99延迟减少45.3-375.5倍；与Knative相比，减少1.9-51.4倍。

**Conclusion:** Hydra通过整合多语言函数调用并利用预热实例池，显著提高了无服务器平台的效率、密度并降低了延迟和内存开销。

> **ai_Abstract:** 本文提出了Hydra，一个创新的虚拟化多语言运行时和平台，旨在解决现有无服务器平台因臃肿虚拟化堆栈导致的内存和延迟开销问题。Hydra通过支持多沙盒并发托管、协同定位感知设计和预热实例缓存，显著提高了函数密度，减少了内存占用，并消除了冷启动，从而大幅优化了无服务器工作负载的性能和效率。

> **摘要翻译:** 无服务器是一种极具吸引力的计算模型，它提供无缝的可扩展性和弹性；它将基础设施管理负担从用户身上移除，并实现了按使用付费的计费模式。因此，无服务器越来越受欢迎，以支持高弹性、突发性工作负载。然而，现有平台由臃肿的虚拟化堆栈支持，这与突发和不规则的调用相结合，导致高内存和延迟开销。

为了减少虚拟化堆栈的臃肿，我们提出了Hydra，一个虚拟化多语言运行时和平台，能够同时托管多个沙盒。为了充分利用Hydra的虚拟化运行时，我们重新审视了现有的无服务器平台设计，使其能够感知跨所有者和功能的协同定位，并具有预分配的Hydra实例缓存层，这些实例可以被不同语言编写的不同函数使用，以减少冷启动。我们还提出了一种快照机制来检查点和恢复单个沙盒。

通过Hydra整合多个无服务器函数调用，与OpenWhisk运行时（大多数无服务器平台中使用的最先进的单语言运行时）相比，我们平均将整体函数密度（ops/GB-sec）提高了2.41倍；与支持同一函数内调用协同定位的Knative运行时相比，平均提高了1.43倍。当重现Azure Functions跟踪时，我们运行Hydra实例的无服务器平台与运行OpenWhisk实例相比，总内存占用减少了21.3-43.9%，与运行Knative实例相比，减少了14.5-30%。Hydra由于预热运行时实例池的存在而消除了冷启动，与OpenWhisk相比，p99延迟减少了45.3-375.5倍，与Knative相比减少了1.9-51.4倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [529] [Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration](https://arxiv.org/abs/2507.01225)
> *具有不确定资源使用和持续时间作业的能力规划与调度*

*Sunandita Patra, Mehtab Pathan, Mahmoud Mahfouz, Parisa Zehtabi, Wided Ouaja, Daniele Magazzeni, Manuela Veloso* | **Category: cs.DC, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 能力规划, 作业调度, 不确定性, 资源使用, 约束规划

**Comment:** Please cite as: Sunandita Patra, Mehtab Pathan, Mahmoud Mahfouz,
  Parisa Zehtabi, Wided Ouaja, Daniele Magazzeni, and Manuela Veloso. "Capacity
  planning and scheduling for jobs with uncertainty in resource usage and
  duration." The Journal of Supercomputing 80, no. 15 (2024): 22428-22461

> **TL;DR:** 本文提出了一种针对本地网格计算环境的能力规划和作业调度方法，该方法通过近似方法处理资源使用和持续时间的不确定性，以在最小化资源使用和保证服务质量之间取得平衡。

**AI_Comments:** 这篇论文的创新点在于其提出了一种处理资源使用和持续时间不确定性的能力规划和作业调度方法，特别是在金融行业这种随机性高的环境中。它通过平衡资源效率和服务质量，为混合计算环境中的资源管理提供了实用的解决方案。其基于对采样的约束规划方法在实际应用中展现了优越性。

<details>
  <summary>Details</summary>

**Motivation:** 组织在混合云环境中调度作业，特别是在本地网格计算环境中，面临资源使用和作业持续时间不确定性的挑战，尤其是在金融行业受随机市场条件影响的情况下。研究旨在解决如何在不确定性下进行能力规划和作业调度，同时平衡资源最小化和服务质量。

**Method:** 提出近似方法，包括使用确定性估计器和基于对采样的约束规划。

**Result:** 最佳方法（基于对采样的）与手动调度相比，在不影响服务质量的前提下，实现了更低的峰值资源使用。

**Conclusion:** 基于对采样的约束规划是处理资源使用和持续时间不确定性下能力规划和作业调度的有效方法，能在资源效率和服务质量之间取得良好平衡。

> **ai_Abstract:** 本文针对具有资源使用和持续时间不确定性的本地网格计算环境，提出了一种能力规划和作业调度方法。该方法旨在平衡最小化资源使用和提供高质量服务（满足截止日期）这两个冲突目标。研究采用了确定性估计器和基于对采样的约束规划等近似方法，并表明基于对采样的方案在不牺牲服务质量的前提下，显著降低了峰值资源使用。

> **摘要翻译:** 全球各地的组织定期调度作业（程序）以执行最终用户指定的各种任务。随着向使用云计算基础设施的重大转变，我们组织采用了一种混合方法，同时使用云服务器和本地服务器。这项工作的目标是为本地网格计算环境执行能力规划（即估算资源需求）和作业调度。我们方法的关键贡献在于处理作业资源使用和持续时间的不确定性，这是金融行业的一个关键方面，因为随机市场条件会显著影响作业特性。对于能力规划和调度，我们同时平衡两个相互冲突的目标：(a) 最小化资源使用，以及 (b) 通过在请求的截止日期前完成作业来向最终用户提供高质量的服务。我们提出了使用确定性估计器和基于对采样的约束规划的近似方法。我们最好的方法（基于对采样的）与手动调度相比，在不影响服务质量的前提下，实现了更低的峰值资源使用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [577] [Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks](https://arxiv.org/abs/2507.10789)
> *解剖NVIDIA Blackwell架构与微基准测试*

*Aaron Jarmusch, Nathan Graddon, Sunita Chandrasekaran* | **Category: cs.DC** | **Updated: 2025-07-21**

**Keywords:** NVIDIA Blackwell, GPU架构, 微基准测试, 性能分析, 内存层次结构

**Comment:** 

> **TL;DR:** 本文通过微基准测试对NVIDIA Blackwell GPU架构进行了微架构分析，揭示了其关键子系统和性能特征，并与Hopper架构进行比较，提供了优化Blackwell平台工作负载的见解。

**AI_Comments:** 这篇论文通过对NVIDIA最新Blackwell架构进行详细的微基准测试分析，揭示了其内部关键子系统和性能特性，具有重要的工程和研究价值。其创新点在于采用了微基准测试的方法来深入探测硬件细节，并提供了与前代Hopper架构的对比，这对于理解新架构的演进和性能特点至关重要。研究结果不仅有助于开发者优化其应用程序，也为未来GPU架构的设计提供了宝贵的数据。特别值得注意的是对FP4和FP6精度张量核心的关注，这反映了其对AI/ML工作负载优化的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 科学研究的快速发展对计算能力提出了更高的需求，而GPU是解决这一需求的关键。为了更好地理解和优化现代GPU架构，有必要对其进行深入的微架构分析。

**Method:** 本文通过精心设计的微基准测试，对NVIDIA Blackwell架构的GPU性能特性进行了微架构分析。具体研究了内存层次结构、SM执行管道、SM子核单元（包括支持FP4和FP6精度的第五代张量核心）。研究内容包括延迟、吞吐量、缓存行为和调度细节。为了进行全面分析，将Blackwell架构（使用GeForce RTX 5080）与之前的Hopper架构（使用H100 PCIe）进行了比较，并调查了不同工作负载下的功耗效率和能耗。

**Result:** 研究揭示了Blackwell架构的关键子系统，包括内存层次结构、SM执行管道和SM子核单元（如支持FP4和FP6精度的第五代张量核心）。分析了延迟、吞吐量、缓存行为和调度细节，揭示了Blackwell设计中微妙的调优指标。通过与Hopper架构的比较，展示了代际改进和性能退步。此外，还探讨了不同工作负载下的功耗效率和能耗。

**Conclusion:** 本研究的发现为应用程序开发人员、编译器编写者和性能工程师在基于Blackwell的平台上优化工作负载提供了可操作的见解，并为GPU架构的日益增长的研究贡献了新数据。

> **ai_Abstract:** 本文对NVIDIA Blackwell GPU架构进行了深入的微架构分析。通过精心设计的微基准测试，研究揭示了Blackwell的关键子系统，包括内存层次结构、SM执行管道和支持FP4/FP6精度的第五代张量核心。研究详细分析了延迟、吞吐量、缓存行为和调度细节，并与前代Hopper架构（通过RTX 5080和H100 PCIe）进行了性能对比，展示了代际进步和潜在的性能退步。此外，论文还探讨了功耗效率和能耗。研究结果旨在为开发者提供优化Blackwell平台工作负载的实用指导，并丰富GPU架构研究的数据。

> **摘要翻译:** 科学研究的快速发展对计算能力提出了更高的需求，部分通过GPU得以解决。本文通过精心设计的微基准测试，对现代NVIDIA Blackwell架构的GPU性能特性进行了微架构分析。我们揭示了关键子系统，包括内存层次结构、SM执行管道和SM子核单元，其中包括支持FP4和FP6精度的第五代张量核心。为了理解NVIDIA GPU的不同关键特性，我们研究了延迟、吞吐量、缓存行为和调度细节，揭示了Blackwell设计中微妙的调优指标。为了进行全面的分析，我们分别使用GeForce RTX 5080和H100 PCIe将Blackwell架构与之前的Hopper架构进行了比较。我们评估和比较了结果，展示了代际改进和性能退步。此外，我们还调查了不同工作负载下功耗效率和能耗的作用。我们的发现为应用程序开发人员、编译器编写者和性能工程师在基于Blackwell的平台上优化工作负载提供了可操作的见解，并为GPU架构的日益增长的研究贡献了新数据。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [272] [Combining Cost-Constrained Runtime Monitors for AI Safety](https://arxiv.org/abs/2507.15886)
> *结合成本受限的运行时监控器以保障AI安全*

*Tim Tian Hua, James Baskerville, Henri Lemoine, Mia Hopman, Aryan Bhatt, Tyler Tracy* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-19**

**Keywords:** AI安全, 运行时监控, 成本约束, 协议优化, 召回率最大化

**Comment:** 

> **TL;DR:** 本文提出一种算法，结合多个成本受限的运行时AI监控器，以在预算约束下最大化检测到不一致输出的概率。

**AI_Comments:** 本文的创新之处在于提出了一种在成本受限环境下，通过优化组合多个运行时监控器来提高AI安全性的方法。其利用Neyman-Pearson引理和对监控与干预成本的战略性权衡，提供了一个原则性的框架，对于AI安全实践具有重要意义。该研究的重点在于如何有效地组合现有监控器，而非开发新的监控器，这使其在实际应用中具有很强的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 运行时监控AI有助于检测和阻止有害行为。然而，运行监控器和实施安全干预是昂贵的。因此，需要在成本受限的条件下，最大化对不一致输出应用安全干预的概率（即最大化召回率）。

**Method:** 该研究通过将多个运行时监控器组合成一个单一的监控协议来解决问题。开发了一种算法，该算法在给定监控器性能和成本的情况下，通过穷尽搜索何时以及调用哪个监控器，并根据Neyman-Pearson引理分配安全干预，以找到最有效的协议。方法侧重于似然比，并战略性地权衡监控器支出与干预支出。

**Result:** 在代码审查环境中，与朴素基线相比，召回率提高了一倍以上。结果还表明，结合两个监控器可以帕累托优于单独使用任何一个监控器。

**Conclusion:** 本文提供了一种在成本敏感环境中结合现有监控器以检测不良行为的原则性方法。

> **ai_Abstract:** 本文旨在解决在成本受限条件下有效监控AI系统以防止有害行为的挑战。它提出了一种算法，将多个运行时监控器组合成一个单一的协议。该协议旨在在平均预算约束下最大化不一致输出的召回率，并利用似然比和对监控与干预成本的战略性权衡。实验结果表明，召回率显著提高，并证明了结合监控器比单独使用它们的优势，为成本敏感场景下的AI安全提供了一个原则性框架。

> **摘要翻译:** 在运行时监控AI可以帮助我们检测并阻止有害行为。在本文中，我们研究了如何将多个运行时监控器组合成一个单一的监控协议。该协议的目标是最大化对不一致输出应用安全干预的概率（即最大化召回率）。由于运行监控器和应用安全干预是昂贵的，该协议还需要遵守平均情况下的预算约束。在给定监控器性能和成本的情况下，我们开发了一种算法来寻找最有效的协议。该算法穷尽搜索何时以及调用哪个监控器，并根据Neyman-Pearson引理分配安全干预。通过关注似然比并战略性地权衡监控器支出与干预支出，我们在代码审查设置中将召回率比朴素基线提高了两倍以上。我们还表明，结合两个监控器可以帕累托优于单独使用任何一个监控器。我们的框架为在成本敏感环境中结合现有监控器以检测不良行为提供了一种原则性方法。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [322] [Verifying International Agreements on AI: Six Layers of Verification for Rules on Large-Scale AI Development and Deployment](https://arxiv.org/abs/2507.15916)
> *验证人工智能国际协议：大规模人工智能开发和部署规则的六层验证*

*Mauricio Baker, Gabriel Kulp, Oliver Marks, Miles Brundage, Lennart Heim* | **Category: cs.CY** | **Updated: 2025-07-21**

**Keywords:** AI验证, 国际协议, 大规模AI, 风险管理, 合规性

**Comment:** 80 pages, summary included

> **TL;DR:** 本报告提出了用于验证大规模AI开发和部署国际协议的六层验证方法，以应对前沿AI风险。

**AI_Comments:** 该论文创新性地提出了大规模AI开发和部署的六层验证框架，为国际社会应对前沿AI风险提供了具体的思路。其重要性在于将抽象的国际协议转化为可操作的验证机制，特别是提出了技术和人员相结合的多维度验证方法。然而，论文也指出，许多技术尚处于早期阶段，且需要强有力的保障措施来防止滥用，这提示了未来研究和政策制定中的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 前沿AI的风险可能需要国际合作，这反过来要求验证各方是否遵守协议规则。然而，AI验证研究目前缺乏清晰度和细节。

**Method:** 本报告通过整合现有文献、专家访谈和原创分析，为政策专业人士和技术研究人员提供了AI验证的深入概述，提出了新颖的概念框架、详细的实施方案和关键的研发挑战。

**Result:** 报告发现，各国最终可以通过六种基本独立的、具有实质性冗余的验证方法来验证合规性，包括：(1) AI芯片内置安全功能；(2-3) 连接AI芯片的独立监控设备；以及(4-6) 基于人员的机制，如举报人计划。

**Conclusion:** 这些验证方法虽然有前景，但需要保障措施以防止滥用和权力集中，并且许多相关技术尚未构建或进行压力测试。为了使各国能够自信地验证大规模AI开发和部署规则的合规性，所列出的研发挑战需要取得重大进展。

> **ai_Abstract:** 本报告针对前沿AI风险可能引发的国际合作中验证规则遵守的必要性，提供了AI验证的深入概述。通过整合现有文献、专家访谈和原创分析，论文提出了六层验证方法，包括AI芯片内置安全功能、独立监控设备和基于人员的机制。报告强调了这些方法在实现过程中面临的挑战，如防止滥用和技术成熟度不足，并指出了未来研发的重点。

> **摘要翻译:** 前沿人工智能的风险可能需要国际合作，这反过来又可能需要验证：检查所有各方是否遵守商定的规则。例如，各国可能需要验证强大的AI模型只有在对其国际安全风险进行评估并被认为可控后才能广泛部署。然而，人工智能验证研究可以从更高的清晰度和细节中受益。为了解决这个问题，本报告为政策专业人士和技术研究人员提供了人工智能验证的深入概述。我们提出了新颖的概念框架、详细的实施选项和关键的研发挑战。这些内容借鉴了现有文献、专家访谈和原创分析，所有这些都在保密监督使用数千个高端AI芯片的AI开发和部署的范围内。我们发现，各国最终可以通过六种基本独立的、具有实质性冗余的验证方法来验证合规性：(1) AI芯片内置安全功能；(2-3) 连接AI芯片的独立监控设备；以及(4-6) 基于人员的机制，例如举报人计划。虽然这些方法很有前景，但需要保障措施以防止滥用和权力集中，并且许多这些技术尚未构建或进行压力测试。为了使各国能够自信地验证大规模AI开发和部署规则的合规性，我们列出的研发挑战需要取得重大进展。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [379] [The Impact of Pseudo-Science in Financial Loans Risk Prediction](https://arxiv.org/abs/2507.16182)
> *金融贷款风险预测中伪科学的影响*

*Bruno Scarone, Ricardo Baeza-Yates* | **Category: cs.CY, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 伪科学, 金融贷款, 风险预测, 生存偏差, 机器学习

**Comment:** 

> **TL;DR:** 论文研究了在金融贷款风险预测中，伪科学假设和生存偏差对机器学习模型准确性和社会成本的影响，并指出模型可能在准确性下降的同时表现出虚假的改进。

**AI_Comments:** 这篇论文揭示了在金融领域应用机器学习时一个重要的伦理和社会问题，即伪科学假设和生存偏差可能导致模型表现出虚假的进步，并加剧不公平性。其创新之处在于将社会成本纳入模型评估，并强调了在模型优化过程中避免“虚假繁荣”的重要性。这对于负责任的人工智能开发具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究伪科学假设在金融贷款风险预测中对人们行为预测的社会影响，并探讨生存偏差在贷款偿还预测中的影响。

**Method:** 分析了机器学习模型在准确性和社会成本方面的表现，并验证了常用学习方法和数据集的结果。

**Result:** 1. 社会最优模型不一定会导致显著的准确性损失。2. 存在一种自然动态，受生存偏差影响的模型准确性会略微下降，但召回率和精确率会随时间提高，这会造成系统正在改善的错觉，实际上模型的不公平性和生存偏差正在增加。

**Conclusion:** 伪科学假设和生存偏差会导致金融贷款风险预测模型出现虚假的性能提升，并增加不公平性，社会最优模型可能不需要牺牲太多准确性。

> **ai_Abstract:** 本文研究了金融贷款风险预测中伪科学假设和生存偏差对机器学习模型的影响。研究发现，虽然社会最优模型可能不会显著降低准确性，但受生存偏差影响的模型会表现出一种误导性动态：准确性略微下降，而召回率和精确率提高，这造成系统改进的假象，实则不公平性和生存偏差加剧。

> **摘要翻译:** 我们研究了伪科学假设在金融贷款风险预测这一直接应用机器学习的场景中，对人们行为预测的社会影响。该用例也体现了生存偏差在贷款偿还预测中的影响。我们从准确性和社会成本角度分析了这些模型，结果表明，社会最优模型可能不会对下游任务造成显著的准确性损失。我们的结果已通过常用学习方法和数据集进行了验证。我们的发现还表明，在训练受生存偏差影响的模型时，存在一种自然动态：准确性略微下降，而召回率和精确率随时间提高。这些结果造成了一种错觉，让观察者误以为系统正在变好，而实际上模型正遭受着日益增加的不公平性和生存偏差。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [439] [Characterizing Online Activities Contributing to Suicide Mortality among Youth](https://arxiv.org/abs/2507.16185)
> *青少年自杀死亡中线上活动特征分析*

*Aparna Ananthasubramaniam, Elyse J. Thulin, Viktoryia Kalesnikava, Silas Falde, Jonathan Kertawidjaja, Lily Johns, Alejandro Rodríguez-Putnam, Emma Spring, Kara Zivin, Briana Mezuk* | **Category: cs.CY, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 青少年自杀, 线上活动, 风险因素, 零样本学习, 主题分析

**Comment:** Accepted at the AAAI International Conference on Web and Social Media
  (ICWSM) 2026

> **TL;DR:** 该研究通过混合方法分析了2013-2022年间近3万份死亡调查摘要，识别并大规模建模了12种与青少年自杀相关的线上活动类型，发现这些活动与自杀风险和死者特征相关，并在COVID-19封锁期间更为普遍。

**AI_Comments:** 该研究的创新之处在于结合了定性主题分析与大规模零样本学习，识别并量化了青少年自杀相关的线上活动，超越了对明确自杀表达的关注。其重要性在于为数字空间开发更精准、更早期干预自杀风险提供了数据驱动的洞察，尤其是在识别那些不那么显性的风险指标方面，对公共卫生和数字平台具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 近期青少年自杀率的上升，凸显了理解线上经历如何导致这一公共健康问题的紧迫需求。

**Method:** 本研究采用混合方法，首先对2013-2022年间29,124份死亡调查的开放文本摘要进行主题分析，识别出12种与自杀死亡相关的线上活动类型。随后，开发了一个零样本学习框架以大规模建模这些主题，并分析了这些主题在死者特征和时间上的变化。

**Result:** 研究发现了与自我伤害、伤害他人、人际互动、线上活动水平和生活事件相关的多种线上活动，这些活动对应于两种主要自杀理论中的不同自杀风险阶段。这些主题与死者特征（如年龄、死亡方式、人际问题）存在关联，并且许多主题在2020年COVID-19封锁期间变得更为普遍。

**Conclusion:** 本研究揭示了结合自杀理论与计算研究，开发针对自杀风险不那么明确指标的干预措施的机会。

> **ai_Abstract:** 本研究旨在应对青少年自杀率上升的挑战，探究线上活动如何影响这一公共健康问题。研究采用混合方法，首先对2013-2022年间近3万份死亡调查摘要进行主题分析，识别出12种与青少年自杀相关的线上活动类型。随后，利用零样本学习框架对这些主题进行大规模建模和分析，发现这些线上活动，包括自我伤害、人际互动等，与不同的自杀风险阶段和死者特征（如年龄、死亡方式）相关。研究还指出，许多相关线上活动在2020年COVID-19封锁期间更为普遍。最终，本研究强调了结合自杀理论和计算方法，开发针对线上自杀风险非显性指标干预措施的重要性。

> **摘要翻译:** 近期青少年自杀率的上升凸显了理解线上经历如何导致这一公共健康问题的紧迫需求。我们的混合方法应对了这一挑战，通过开发一套关注10-24岁青少年线上空间自杀死亡风险因素的主题，以及一个用于大规模建模这些主题的框架。我们使用2013-2022年间29,124份死亡调查的开放文本摘要，进行了主题分析，识别出12种被调查人员或近亲认为与特定自杀死亡情境相关的线上活动类型。随后，我们开发了一个零样本学习框架以大规模建模这12个主题，并分析了这些主题在死者特征和时间上的变化。我们的工作揭示了几种与自我伤害、伤害他人、人际互动、线上活动水平和生活事件相关的线上活动，这些活动对应于两种主要自杀理论中的不同自杀风险阶段。我们发现这些主题与死者特征（如年龄、死亡方式和人际问题）存在关联，并且许多主题在2020年COVID-19封锁期间变得更为普遍。尽管数字空间已采取一些措施来解决线上自杀意念的表达，但我们的工作表明，结合自杀理论与计算研究，在开发针对自杀风险不那么明确指标的干预措施方面存在机会。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [449] [Chameleon Channels: Measuring YouTube Accounts Repurposed for Deception and Profit](https://arxiv.org/abs/2507.16045)
> *变色龙频道：衡量被重新用于欺骗和牟利的YouTube账户*

*Alejandro Cuevas, Manoel Horta Ribeiro, Nicolas Christin* | **Category: cs.CY, cs.CR** | **Updated: 2025-07-21**

**Keywords:** 频道重定向, YouTube, 社交媒体账户市场, 虚假信息, 金融诈骗

**Comment:** 21 pages, 12 figures, 2 tables

> **TL;DR:** 研究发现，YouTube上存在大量“二手”频道市场，这些频道被重新利用来传播有害内容，甚至在改变内容后还能吸引更多订阅者。

**AI_Comments:** 本研究揭示了一个令人担忧的在线内容生态系统问题：利用既有信任和用户基础进行欺骗性活动。其创新之处在于量化了“二手”社交媒体账户市场，并揭示了频道重定向的普遍性及其对订阅者的影响。研究结果表明，平台在应对此类滥用行为方面面临重大挑战，尤其是在现有用户信任被利用时。这对于理解网络虚假信息和诈骗的传播机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在线内容创作者花费大量时间精力建立用户群，那么，一个成功的创作者为什么会彻底改变其频道内容，转而推广加密货币服务或报道选举新闻？如果他们这样做，现有订阅者会注意到吗？本文旨在探讨“频道重定向”这一问题，即频道改变其身份和内容。

**Method:** 首先，研究通过观察期内记录销售额超过100万美元的“二手”社交媒体账户市场来对其进行描述。其次，通过观察6个月内（重新）出售的YouTube频道，分析其用途。最后，研究收集了140万个准随机抽样的YouTube账户的两次快照，以估算“在野”频道重定向的普遍性。

**Result:** 在为期6个月的观察期内，“二手”社交媒体账户市场销售额超过100万美元。在这些（重新）出售的YouTube频道中，37%的频道被用于传播潜在有害内容，且通常未受处罚。令人惊讶的是，这些频道似乎增加了而非减少了订阅者。在3个月内，估计约有0.25%的频道（总计约4400万订阅者）被重定向。这些重定向的频道与出售的频道具有相似特征，主要表现为存在大量潜在问题内容。其中包括变为虚假信息频道和链接到金融诈骗网页的频道。

**Conclusion:** 滥用这些频道上残余的信任对受财务和意识形态驱动的对手有利。这种现象并非YouTube独有，并且培养有机受众的市场预计将增长，特别是如果它不受技术或其他缓解措施的挑战。

> **ai_Abstract:** 本研究探讨了YouTube上“重定向频道”的现象，即频道在建立用户基础后改变其内容和身份以用于欺骗和牟利。研究发现存在一个活跃的“二手”社交媒体账户市场，销售额巨大。通过对YouTube频道的观察和抽样分析，揭示了大量频道被重新用于传播有害信息（如虚假信息和金融诈骗），并且令人惊讶的是，这些频道在内容改变后订阅者反而增加。研究指出，利用这些频道的残余信任对恶意行为者有利，并强调若无有效缓解措施，这种现象将持续增长。

> **摘要翻译:** 在线内容创作者花费大量时间和精力通过漫长而艰苦的过程建立用户群，这需要找到合适的“利基”来迎合。那么，一个以猫咪表情包闻名的成熟内容创作者，有什么动机去彻底改造他们的页面频道，开始推广加密货币服务或报道选举新闻事件呢？如果他们这样做，他们现有的订阅者会注意不到吗？我们探讨了这种“重定向频道”的问题，即频道改变其身份和内容。我们首先描述了一个“二手”社交媒体账户市场，在我们的6个月观察期内，其销售额超过100万美元。通过观察这6个月内（重新）出售的YouTube频道，我们发现相当一部分（37%）被用于传播潜在有害内容，通常没有面临任何惩罚。更令人惊讶的是，这些频道似乎增加了而不是减少了订阅者。为了估算“在野”频道重定向的普遍性，我们还收集了140万个准随机抽样的YouTube账户的两次快照。在3个月内，我们估计约有0.25%的频道——总计约4400万订阅者——被重定向。我们证实这些重定向的频道与出售的频道有几个共同特征——主要是它们存在大量潜在问题内容。在重定向的频道中，我们发现有变为虚假信息频道，以及链接到金融诈骗网页的频道。我们认为，滥用这些频道上残余的信任对受财务和意识形态驱动的对手有利。这种现象并非YouTube独有，我们认为，培养有机受众的市场将持续增长，特别是如果它仍然不受技术或其他缓解措施的挑战。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [475] [Disability Across Cultures: A Human-Centered Audit of Ableism in Western and Indic LLMs](https://arxiv.org/abs/2507.16130)
> *跨文化残疾：对西方和印度大型语言模型中歧视残疾现象的人本审计*

*Mahika Phutane, Aditya Vashistha* | **Category: cs.CY, cs.AI, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 残疾, 歧视残疾, 大型语言模型, 跨文化, 人本AI

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs），无论是西方还是印度的，在识别跨文化背景（特别是印地语）中的残疾歧视方面表现不佳，凸显了在AI系统设计和评估中以当地残疾人经验为中心的必要性。

**AI_Comments:** 这项研究的创新之处在于其跨文化比较方法，首次深入探讨了大型语言模型在非西方语境下识别残疾歧视的能力。它明确指出，即使是本地化的模型，也可能未能充分理解特定文化背景下残疾人对歧视的感知和定义。这对于开发更公平、更具包容性的AI系统至关重要，提醒我们不能简单地将西方概念应用于全球，而忽视了当地的社会文化语境和人类经验。

<details>
  <summary>Details</summary>

**Motivation:** 残疾人（PwD）在网络上遭受的歧视和仇恨程度过高，尤其是在印度，根深蒂固的耻辱和有限的资源加剧了这些挑战。尽管大型语言模型（LLMs）越来越多地用于识别和减轻网络仇恨，但大多数关于网络歧视残疾的研究都集中在西方受众和西方AI模型上。因此，本研究旨在探讨这些模型是否足以识别非西方地区（如印度）的残疾歧视危害，以及本地化的印度语言模型是否表现更好。

**Method:** 研究团队采用并翻译了一个公开可用的歧视残疾言论数据集到印地语。随后，他们提示了八个大型语言模型（四个在美国开发：GPT-4、Gemini、Claude、Llama；四个在印度开发：Krutrim、Nanda、Gajendra、Airavata）来对歧视残疾言论进行评分和解释。同时，研究人员招募了175名来自美国和印度的残疾人来执行相同的任务，以进行比较。

**Result:** 研究结果显示，大型语言模型组与残疾人组之间存在显著差异。西方大型语言模型始终高估了残疾歧视的危害，而印度大型语言模型则低估了这种危害。更令人担忧的是，所有大型语言模型在歧视残疾言论以印地语表达并主张西方对残疾歧视危害的框架时，表现出更高的容忍度。与此形成对比的是，印度残疾人通过意图、关系性和韧性来解读危害，并强调了告知和教育施害者的愿望。

**Conclusion:** 这项工作为建立全球性的、包容的残疾歧视标准奠定了基础，并证明了在AI系统设计和评估中，将当地残疾人经验置于核心地位的必要性。

> **ai_Abstract:** 本研究对西方和印度大型语言模型（LLMs）在识别跨文化残疾歧视方面的表现进行了人本审计。鉴于残疾人在网络上（尤其是在印度）面临的严重歧视，研究旨在评估现有LLMs是否能有效识别非西方语境下的歧视。通过将歧视残疾言论数据集翻译成印地语，并让八个LLMs（四西方，四印度）和175名来自美国和印度的残疾人对言论进行评分，研究发现LLMs与人类判断存在显著差异：西方LLMs高估危害，印度LLMs低估危害，且所有LLMs在印地语和西方框架下对歧视残疾的容忍度更高。印度残疾人则从意图、关系性和韧性的角度理解危害。研究强调了在AI系统设计和评估中，以当地残疾人经验为中心，以建立全球包容性残疾歧视标准的重要性。

> **摘要翻译:** 残疾人（PwD）在网络上遭受的歧视和仇恨程度过高，尤其是在印度，根深蒂固的耻辱和有限的资源加剧了这些挑战。大型语言模型（LLMs）越来越多地用于识别和减轻网络仇恨，但大多数关于网络歧视残疾的研究都集中在西方受众和西方AI模型上。这些模型是否足以识别非西方地区（如印度）的歧视残疾危害？本地化的印度语言模型是否表现更好？为了调查这一点，我们采用并翻译了一个公开可用的歧视残疾言论数据集到印地语，并提示了八个大型语言模型——四个在美国开发（GPT-4、Gemini、Claude、Llama）和四个在印度（Krutrim、Nanda、Gajendra、Airavata）——对歧视残疾进行评分和解释。同时，我们招募了175名来自美国和印度的残疾人来执行相同的任务，揭示了群体间的显著差异。西方大型语言模型始终高估了歧视残疾的危害，而印度大型语言模型则低估了这种危害。更令人担忧的是，所有大型语言模型在歧视残疾言论以印地语表达并主张西方对歧视残疾危害的框架时，表现出更高的容忍度。相比之下，印度残疾人通过意图、关系性和韧性来解读危害——强调了告知和教育施害者的愿望。这项工作为建立全球性的、包容的歧视残疾标准奠定了基础，证明了在AI系统设计和评估中，以当地残疾人经验为中心的必要性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [487] [Beyond Algorethics: Addressing the Ethical and Anthropological Challenges of AI Recommender Systems](https://arxiv.org/abs/2507.16430)
> *超越算法伦理：解决人工智能推荐系统的伦理和人类学挑战*

*Octavian M. Machidon* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 推荐系统, 算法伦理, 人类学挑战, 人类中心设计, 人工智能伦理

**Comment:** 

> **TL;DR:** 本文探讨了人工智能推荐系统在伦理和人类学方面带来的挑战，并提出一个超越纯技术解决方案的以人为中心的框架。

**AI_Comments:** 这篇论文的创新之处在于它超越了传统的“算法伦理”范畴，从更广阔的人类学视角审视AI推荐系统的深层伦理问题，强调了这些系统对人类经验和福祉的积极构建作用。其重要性在于指出了现有技术解决方案的局限性，并提出了一个多维度的、以人为本的综合框架，为未来推荐系统的设计和监管提供了新的思路。论文的局限性可能在于其提出的框架仍需具体化和实践验证。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在探讨AI驱动的推荐系统所带来的伦理和人类学挑战，指出现有伦理方法（包括算法伦理）不足以解决推荐系统将人类复杂性量化、利用用户脆弱性以及优先考虑参与度而非福祉的问题。

**Method:** 作者提出一个全面的人类中心推荐系统设计框架，该框架整合了跨学科视角、监管策略和教育举措。

**Result:** 论文分析了推荐系统对塑造数字环境和社会互动的影响，并指出现有伦理方法的局限性，最终提出了一个旨在促进而非损害人类自主和社会繁荣的综合性框架。

**Conclusion:** 为了解决AI推荐系统的伦理和人类学挑战，需要超越纯技术解决方案，采纳一个整合多学科视角、监管和教育的人类中心设计框架，以确保AI系统能够促进人类自主和社会繁荣。

> **ai_Abstract:** 本文审视了AI推荐系统带来的伦理和人类学挑战，指出它们超越了简单反映用户偏好，积极塑造用户体验。作者认为，现有伦理方法（如算法伦理）不足以解决推荐系统简化人类复杂性、利用用户脆弱性并优先考虑参与度而非福祉的问题。为此，论文提出了一个以人为中心的综合框架，该框架结合了跨学科方法、监管策略和教育措施，旨在确保AI系统能促进人类自主和社会繁荣。

> **摘要翻译:** 在本文中，我探讨了人工智能驱动的推荐系统（RSs）所带来的伦理和人类学挑战，这些系统已成为塑造数字环境和社会互动的核心。通过策划个性化内容，推荐系统不仅反映用户偏好，而且积极构建社交媒体、娱乐平台和电子商务中的个人体验。尽管它们无处不在，但推荐系统的伦理影响仍未得到充分探索，尽管对隐私、自主性和心理健康的担忧日益加剧。我认为，包括算法伦理（旨在将伦理原则嵌入算法设计）在内的现有伦理方法是必要的，但最终是不够的。推荐系统固有地将人类复杂性简化为可量化的维度，利用用户脆弱性，并优先考虑参与度而非福祉。解决这些问题需要超越纯粹的技术解决方案。我提出了一个以人为中心的推荐系统设计的综合框架，整合了跨学科视角、监管策略和教育举措，以确保人工智能系统促进而非损害人类自主和社会繁荣。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [522] [PRAC3 (Privacy, Reputation, Accountability, Consent, Credit, Compensation): Long Tailed Risks of Voice Actors in AI Data-Economy](https://arxiv.org/abs/2507.16247)
> *PRAC3 (隐私、声誉、问责、同意、信用、补偿)：人工智能数据经济中配音演员的“长尾”风险*

*Tanusree Sharma, Yihao Zhou, Visar Berisha* | **Category: cs.CY, cs.AI, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 配音演员, AI数据经济, 隐私, 声誉, 问责制, PRAC3框架

**Comment:** 

> **TL;DR:** 现有伦理框架未能充分解决配音演员在AI数据经济中面临的隐私、声誉和问责风险，本文提出PRAC3框架以应对这些挑战。

**AI_Comments:** 这篇论文的创新之处在于识别并系统化了配音演员在AI数据经济中面临的新兴且复杂的风险，特别是“长尾”风险。它不仅指出了现有伦理框架（C3）的局限性，还提出了一个更全面、更细致的PRAC3框架，将隐私、声誉和问责制纳入考量，这对于构建负责任的AI系统和保护数字时代创作者权益具有重要意义。该研究基于定性访谈，提供了丰富的现实案例，增强了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 早期大规模音频数据集的贡献者（配音演员）如今面临一系列未被现有伦理框架（C3）充分解决的风险，尤其是声音身份与语境、著作权和控制权分离后带来的新兴风险。

**Method:** 本文通过对20名专业配音演员进行定性访谈。

**Result:** 研究揭示了在缺乏可执行约束的情况下，声音的合成复制如何使个体面临声誉损害（如用于色情内容、冒犯性政治信息、迷因文化）和问责制崩溃（如用于金融欺诈、虚假信息宣传、冒充诈骗），导致配音演员面临社会和法律后果而缺乏追索权，且很少有法律代表或工会保护。为理解这些动态，本文引入了PRAC3框架，将隐私、声誉、问责、同意、信用和补偿作为合成语音经济中数据相互依赖的支柱。

**Conclusion:** 声音作为生物识别标识符和创意劳动，需要能够恢复创作者代理权、确保可追溯性并为道德重用建立可执行边界的治理模型。PRAC3框架有助于重新构想AI数据生态系统中的问责制。

> **ai_Abstract:** 本文探讨了人工智能数据经济中配音演员面临的“长尾”风险，这些风险源于其声音数据被合成复制和去语境化使用，导致隐私、声誉和问责制问题。通过对20名专业配音演员的访谈，研究揭示了现有伦理框架（C3）的不足。为应对这些挑战，论文提出了PRAC3框架，扩展了C3，将隐私、声誉和问责纳入考量，旨在为合成语音经济中的数据使用建立更全面的治理模型，以保护创作者权益并确保数据伦理。

> **摘要翻译:** 早期的D规模音频数据集，如LibriSpeech，由数百名独立贡献者构建，他们的声音在语音技术（包括有声读物和语音助手）的开发中发挥了重要作用。然而，十年后，这些贡献使配音演员面临一系列风险。尽管现有的伦理框架强调同意（Consent）、信用（Credit）和补偿（Compensation）（C3），但它们未能充分解决涉及声音身份的新兴风险，这些风险日益脱离语境、著作权和控制。本文通过对20名专业配音演员的定性访谈，揭示了在缺乏可执行约束的情况下，声音的合成复制如何使个体面临一系列威胁。除了声誉损害，例如语音数据被重新用于色情内容、冒犯性政治信息和迷因文化外，我们还记录了当他们的声音被用于克隆声音并部署在高风险场景（如金融欺诈、虚假信息宣传或冒充诈骗）时，问责制崩溃的担忧。在这种情况下，演员面临社会和法律后果而无法追索，而他们中很少有人拥有法律代表或工会保护。为了理解这些不断变化的动态，我们引入了PRAC3框架，这是C3的扩展，将隐私（Privacy）、声誉（Reputation）、问责（Accountability）、同意（Consent）、信用（Credit）和补偿（Compensation）作为合成语音经济中使用数据的相互依赖的支柱。该框架捕捉了隐私风险如何通过未经同意的训练而被放大，声誉损害如何因去语境化部署而产生，以及如何重新构想人工智能数据生态系统中的问责制。我们认为，声音作为生物识别标识符和创意劳动，需要能够恢复创作者代理权、确保可追溯性并为道德重用建立可执行边界的治理模型。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [631] [Risks of AI Scientists: Prioritizing Safeguarding Over Autonomy](https://arxiv.org/abs/2402.04247)
> *人工智能科学家的风险：优先考虑安全而非自主性*

*Xiangru Tang, Qiao Jin, Kunlun Zhu, Tongxin Yuan, Yichi Zhang, Wangchunshu Zhou, Meng Qu, Yilun Zhao, Jian Tang, Zhuosheng Zhang, Arman Cohan, Zhiyong Lu, Mark Gerstein* | **Category: cs.CY, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 人工智能科学家, 风险, 安全, 自主性, 脆弱性

**Comment:** 

> **TL;DR:** 本文探讨了人工智能科学家带来的新颖漏洞和潜在风险，并提出了一个三元框架来减轻这些风险，强调了在发展人工智能科学家时，安全保障应优先于自主性。

**AI_Comments:** 这篇论文很有见地，及时地指出了人工智能科学家在发展过程中可能面临的潜在风险，并强调了安全保障的必要性。提出的三元框架为未来人工智能科学家的安全设计和监管提供了有价值的指导，具有重要的实践意义。其创新之处在于系统性地梳理了风险来源并提出了多维度应对策略。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能科学家在自主进行实验和促进科学发现方面展现出巨大潜力，但它们也引入了新的脆弱性，需要仔细考虑安全性。目前对这些脆弱性的全面探索有限，因此本文旨在探讨这些风险并强调安全措施的必要性。

**Method:** 本文首先概述了人工智能科学家固有的潜在风险，考虑了用户意图、特定科学领域及其对外部环境的潜在影响。然后，探讨了这些脆弱性的根本原因，并对现有有限的相关工作进行了范围界定审查。基于分析，提出了一个涉及人类监管、智能体对齐和理解环境反馈（智能体监管）的三元框架来减轻已识别的风险。

**Result:** 本文识别并分析了人工智能科学家在用户意图、科学领域和外部环境影响方面的潜在风险及其根本原因。提出了一个由人类监管、智能体对齐和环境反馈理解（智能体监管）组成的三元框架来缓解这些风险。

**Conclusion:** 本文强调了在人工智能科学家发展中，安全保障应优先于自主性。为了应对人工智能科学家的风险，需要开发改进的模型、强大的基准和全面的法规，并提出了一个三元框架来指导风险缓解。

> **ai_Abstract:** 本文探讨了由大型语言模型驱动的人工智能科学家所带来的潜在风险和新型脆弱性。尽管这些智能体在科学发现方面具有巨大潜力，但其安全问题尚未得到充分研究。作者分析了这些风险的来源，并提出了一个三元框架，包括人类监管、智能体对齐和环境反馈理解，以减轻这些风险。论文强调了将安全置于自主性之上的重要性，并呼吁开发更好的模型、基准和法规来保障人工智能科学家。

> **摘要翻译:** 由大型语言模型驱动的人工智能科学家在自主进行实验和促进跨学科科学发现方面展现出巨大的前景。虽然它们的能力令人鼓舞，但这些智能体也引入了需要仔细考虑安全性的新型脆弱性。然而，对这些脆弱性的全面探索有限。本文探讨了人工智能科学家的脆弱性，揭示了与其滥用相关的潜在风险，并强调了安全措施的必要性。我们首先概述了人工智能科学家固有的潜在风险，同时考虑了用户意图、特定科学领域及其对外部环境的潜在影响。然后，我们探讨了这些脆弱性的根本原因，并对现有有限的相关工作进行了范围界定审查。基于我们的分析，我们提出了一个涉及人类监管、智能体对齐和理解环境反馈（智能体监管）的三元框架来减轻这些已识别的风险。此外，我们强调了保障人工智能科学家相关的局限性和挑战，并倡导开发改进的模型、强大的基准和全面的法规。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [673] [Secondary Bounded Rationality: A Theory of How Algorithms Reproduce Structural Inequality in AI Hiring](https://arxiv.org/abs/2507.09233)
> *次级有限理性：算法如何在AI招聘中复制结构性不平等的理论*

*Jia Xiao* | **Category: cs.CY** | **Updated: 2025-07-22**

**Keywords:** 次级有限理性, AI招聘, 结构性不平等, 算法偏见, 资本理论

**Comment:** 

> **TL;DR:** AI招聘系统通过将文化和社会资本差异编码到算法决策中，从而延续了系统性不平等。本文提出了“次级有限理性”理论，解释AI系统如何通过技术和社会政治限制继承和放大人类偏见，并将历史不平等转化为表面上的精英结果。文章建议了缓解策略以打破这种自我强化的不平等。

**AI_Comments:** 本文创新性地提出了“次级有限理性”概念，为理解AI在招聘中如何复制不平等提供了一个新的理论框架。它不仅揭示了算法偏见的深层社会根源，还结合了经典的社会学和认知科学理论，具有较强的理论深度。提出的缓解策略也具有实践指导意义，对AI伦理和公平性研究有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** AI驱动的招聘系统虽然承诺提高效率和客观性，但往往通过将文化和社会资本差异编码到算法决策中来延续系统性不平等。本文旨在提出并捍卫一种新的“次级有限理性”理论，以解释AI系统如何继承和放大人类认知和结构性偏见，并揭示AI如何通过优化可识别但有偏见的代理指标来固化排斥。

**Method:** 本文发展并捍卫了“次级有限理性”理论，分析了多模式招聘框架，并运用布迪厄的资本理论和西蒙的有限理性理论。研究揭示了AI如何通过优化可识别但有偏见的胜任能力代理指标来固化排斥的递归循环。文章还提出了缓解策略。

**Result:** 研究表明，AI系统通过技术和社会政治限制继承并放大了人类的认知和结构性偏见。算法过程将历史不平等（如精英证书特权和网络同质性）转化为表面上的精英结果。通过布迪厄的资本理论和西蒙的有限理性理论，揭示了AI通过优化可识别但有偏见的胜任能力代理指标来固化排斥的递归循环。

**Conclusion:** AI招聘系统通过“次级有限理性”机制，将人类的认知和结构性偏见编码进算法，从而在看似客观的招聘过程中复制并强化了结构性不平等。为了打破这种自我强化的不平等，需要采取反事实公平性测试、资本感知审计和监管干预等缓解策略。

> **ai_Abstract:** 本文提出并阐述了“次级有限理性”理论，旨在解释AI招聘系统如何将人类的认知和结构性偏见（如精英教育偏好和社交网络同质性）编码进算法决策过程，从而在招聘中复制并放大社会不平等。研究结合布迪厄的资本理论和西蒙的有限理性概念，揭示了AI通过优化有偏见的代理指标来固化排斥的递归机制。文章最后提出了包括反事实公平性测试和资本感知审计在内的缓解策略，以应对这种算法驱动的结构性不平等。

> **摘要翻译:** AI驱动的招聘系统，虽然承诺提高效率和客观性，但往往通过将文化和社会资本差异编码到算法决策中来延续系统性不平等。本文发展并捍卫了一种新的次级有限理性理论，认为AI系统尽管拥有强大的计算能力，却通过技术和社会政治限制继承并放大了人类的认知和结构性偏见。通过分析多模式招聘框架，我们展示了算法过程如何将历史不平等，例如精英证书特权和网络同质性，转化为表面上的精英结果。我们利用布迪厄的资本理论和西蒙的有限理性理论，揭示了一个递归循环，即AI通过优化可识别但有偏见的胜任能力代理指标来固化排斥。我们提出了缓解策略，包括反事实公平性测试、资本感知审计和监管干预，以打破这种自我强化的不平等。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [710] [Reasoning Models Can be Easily Hacked by Fake Reasoning Bias](https://arxiv.org/abs/2507.13758)
> *推理模型易受虚假推理偏见攻击*

*Qian Wang, Yubo Fan, Zhenheng Tang, Nuo Chen, Wenxuan Wang, Bingsheng He* | **Category: cs.CY** | **Updated: 2025-07-22**

**Keywords:** 大型推理模型, 推理剧场偏见, 浅层推理, 自动评估器, 脆弱性

**Comment:** 

> **TL;DR:** 研究发现大型推理模型（LRMs）作为自动评估器时，比通用大型语言模型（LLMs）更容易受到虚假推理偏见（RTB）的影响，尤其是在主观任务上，提出浅层推理是最强的偏见形式，且现有干预措施效果有限。

**AI_Comments:** 这项研究揭示了大型推理模型在作为评估器时的一个重要且反直觉的弱点：它们在处理主观或“伪推理”时比通用模型更容易被误导。其创新点在于提出了“推理剧场偏见”（RTB）这一概念，并构建了THEATER基准来系统评估。发现“浅层推理”是最强偏见形式具有重要意义。局限性在于提出的缓解策略效果有限，表明这是一个深层次的问题，需要更复杂的解决方案。这项工作对理解和改进LLM/LRM作为评估器的可靠性和信任度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）越来越多地被用作自动评估器，这引发了对其在“LLM即法官”设置中对推理美学脆弱性的关键问题。

**Method:** 引入了THEATER基准，通过在主观偏好和客观事实数据集上比较LLM和LRM来系统评估推理剧场偏见（RTB）。研究了包括简单线索和虚假思维链在内的六种偏见类型。

**Result:** 1. 推理专业化的LRM比通用LLM始终更容易受到RTB的影响，特别是在主观任务中。
2. 存在任务依赖的权衡：LRM在事实任务上更鲁棒，但在主观任务上则较弱。
3. “浅层推理”（看似合理但有缺陷的论证）是RTB最有效的形式。
4. 设计的两种提示策略（目标系统提示和自我反思机制）在主观领域效果有限。

**Conclusion:** 推理剧场偏见（RTB）是基于LRM的评估面临的一个根深蒂固的挑战，本工作为开发更真正鲁棒和值得信赖的LRM提供了一个系统框架。

> **ai_Abstract:** 本文研究了大型推理模型（LRM）作为自动评估器时对虚假推理偏见（RTB）的脆弱性。通过引入THEATER基准，研究发现LRM，尤其是那些专门用于推理的LRM，比通用大型语言模型（LLM）更容易受到RTB影响，特别是在主观任务上。“浅层推理”被识别为最有效的偏见形式。尽管尝试了系统提示和自我反思机制来缓解偏见，但在主观任务上的效果有限。研究强调RTB是LRM评估中的一个重大挑战，并提出了构建更可靠LRM的系统性框架。

> **摘要翻译:** 大型推理模型（LRM），如DeepSeek-R1和o1，正越来越多地被用作自动评估器，这引发了对其在“LLM即法官”设置中对推理美学脆弱性的关键问题。我们引入了THEATER，一个综合基准，通过在主观偏好和客观事实数据集上比较LLM和LRM，系统地评估这种脆弱性——我们称之为推理剧场偏见（RTB）。通过调查包括简单线索和虚假思维链在内的六种偏见类型，我们发现了三个关键发现：（1）在一个关键悖论中，推理专业化的LRM比通用LLM始终更容易受到RTB的影响，特别是在主观任务中；（2）这造成了一个任务依赖的权衡，即LRM在事实任务上表现出更强的鲁棒性，但在主观任务上则较弱；（3）我们识别出“浅层推理”——看似合理但有缺陷的论证——是RTB最有效的形式。为了解决这个问题，我们设计并评估了两种提示策略：一种目标系统提示，在事实任务上将准确性提高了高达12%，但在主观任务上仅提高了1-3%；以及一种自我反思机制，在更脆弱的主观领域显示出类似有限的有效性。我们的工作揭示了RTB是基于LRM的评估面临的一个根深蒂固的挑战，并为开发更真正鲁棒和值得信赖的LRM提供了一个系统框架。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [746] [Mapping the Parasocial AI Market: User Trends, Engagement and Risks](https://arxiv.org/abs/2507.14226)
> *映射类社交AI市场：用户趋势、参与度和风险*

*Zilan Qian, Mari Izumikawa, Fiona Lodge, Angelo Leone* | **Category: cs.CY** | **Updated: 2025-07-22**

**Keywords:** 类社交AI, AI伴侣, 用户趋势, 在线安全, 市场分析

**Comment:** 17 pages, 17 figures

> **TL;DR:** 对110个AI伴侣平台进行扫描，发现类社交AI市场快速增长，存在用户参与度高、特定AI类型（如交友型）流行以及在线安全（尤其是儿童保护）等风险，呼吁加强监管。

**AI_Comments:** 这篇论文通过对新兴类社交AI市场的实证扫描，提供了宝贵的数据洞察，揭示了该市场的快速增长、用户行为模式及其潜在的社会风险。其创新之处在于首次系统性地量化了这一新兴产业的规模和趋势。论文的重要性在于及时指出了伴随技术发展而来的在线安全问题，特别是对儿童的保护，并呼吁监管机构介入，具有重要的社会和政策指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在通过对类社交AI市场的扫描，揭示其快速增长的用户趋势、参与度以及随之而来的在线安全和社会风险，并强调监管机构监测该领域和评估现有法规的必要性。

**Method:** 研究通过扫描110个AI伴侣平台来分析其市场趋势、用户参与度及相关风险。

**Result:** 类社交AI市场正在全球范围内快速增长，提供情感投入和个性化互动。通用型AI工具的类社交使用目前占主导地位，但特定用途（护理、交易、交友）平台数量增多。英国每月访问量达4600万至9100万次（全球11亿至22亿次），平均每次会话3.5分钟。交友型AI伴侣占英国访问量的44%，但会话时长和回访率低于混合使用平台。随着交友型AI产品改进，用户参与度可能增加，带来在线安全风险。

**Conclusion:** 类社交AI的使用日益主流化，尤其是在情感智能和个性化互动方面。这些趋势引发了对在线安全的紧急担忧，特别是针对儿童的年龄保护措施薄弱。研究强调英国AI安全研究所（AISI）需要监测该领域，并评估现有法规是否足以应对新兴的社会风险。

> **ai_Abstract:** 本研究通过对110个AI伴侣平台的扫描，揭示了全球类社交AI市场的迅速扩张，该市场提供情感投入和个性化互动。尽管通用型AI工具仍占主导，但专业化的护理、交易和交友AI平台正快速增长。数据显示，该市场用户参与度高，尤其在英国，交友型AI受欢迎但用户粘性有待提高。研究强调，随着AI产品改进，可能带来在线安全风险，特别是对儿童的保护不足。因此，呼吁监管机构加强对该领域的监测和风险评估。

> **摘要翻译:** 对110个AI伴侣平台进行扫描，揭示了一个快速增长的全球市场，提供情感投入、个性化的AI互动。尽管通用型AI（GPAI）工具的类社交使用目前占据主导地位，但越来越多平台专门为护理、交易或交友伴侣而设计。仅在英国，这些平台每月访问量介于4600万至9100万次之间（全球11亿至22亿次），用户每次会话平均花费3.5分钟。作为参照，Instagram在2025年1月至3月期间平均每月在英国有6730万次访问。值得注意的是，交友型AI伴侣占据英国访问量的44%（高于全球平均水平30%），但其会话时长和回访率低于混合使用平台。随着交友型浪漫AI产品不断改进，用户参与度可能会增加，这引发了对在线安全的紧急担忧，特别是考虑到年龄保护措施薄弱，对儿童的影响尤甚。与此同时，通用型AI工具正朝着更具情感智能、个性化互动的方向发展，使得类社交AI的使用日益主流化。这些趋势凸显了英国AI安全研究所（AISI）监测该领域并评估现有法规是否足以解决新兴社会风险的必要性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [445] [Interpreting CFD Surrogates through Sparse Autoencoders](https://arxiv.org/abs/2507.16069)
> *通过稀疏自动编码器解释计算流体动力学代理模型*

*Yeping Hu, Shusen Liu* | **Category: cs.CE, cs.LG** | **Updated: 2025-07-21**

**Keywords:** CFD代理模型, 可解释性, 稀疏自动编码器, 图神经网络, 计算流体动力学

**Comment:** Accepted by IJCAI 2025 Workshop on Explainable Artificial
  Intelligence (XAI)

> **TL;DR:** 本文引入了一个基于稀疏自动编码器的事后可解释性框架，用于解释计算流体动力学（CFD）中的图基代理模型，以提高其透明度和可信度。

**AI_Comments:** 该论文的创新之处在于将稀疏自动编码器应用于CFD代理模型的可解释性，解决了代理模型“黑箱”问题，对于推动CFD代理模型在安全关键领域的应用具有重要意义。其提出的模型无关的解释途径具有通用性。

<details>
  <summary>Details</summary>

**Motivation:** 学习型代理模型已成为高精度CFD求解器的实用替代方案，但其潜在表示不透明，阻碍了在安全关键或受法规约束环境中的应用。

**Method:** 该工作通过利用稀疏自动编码器（SAEs）引入了一个用于计算流体动力学（CFD）中图基代理模型的事后可解释性框架。通过在预训练代理模型的节点嵌入空间中获得一个过完备基，该方法提取了一个可解释的潜在特征字典。

**Result:** 该方法能够识别与涡度或流动结构等物理现象对齐的单义概念。

**Conclusion:** 该方法为增强CFD应用中的可解释性和可信度提供了一条模型无关的途径。

> **ai_Abstract:** 本文提出了一种利用稀疏自动编码器（SAEs）对计算流体动力学（CFD）中图基代理模型进行事后解释的框架。该方法通过在预训练代理模型的节点嵌入空间中提取可解释的潜在特征字典，旨在解决代理模型潜在表示不透明的问题，从而提高其在安全关键应用中的可信度。研究表明，该方法能够识别与物理现象相关的概念，为CFD代理模型的可解释性提供了一种通用途径。

> **摘要翻译:** 基于学习的代理模型已成为高精度计算流体动力学（CFD）求解器的实用替代方案，但其潜在表示不透明，阻碍了在安全关键或受法规约束环境中的采用。这项工作通过利用稀疏自动编码器（SAEs），引入了一个用于计算流体动力学（CFD）中图基代理模型的事后可解释性框架。通过在预训练代理模型的节点嵌入空间中获得一个过完备基，该方法提取了一个可解释的潜在特征字典。该方法能够识别与涡度或流动结构等物理现象对齐的单义概念，为增强CFD应用中的可解释性和可信度提供了一条模型无关的途径。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [495] [Computational design of personalized drugs via robust optimization under uncertainty](https://arxiv.org/abs/2507.16470)
> *不确定性下鲁棒优化实现个性化药物的计算设计*

*Rabia Altunay, Jarkko Suuronen, Eero Immonen, Lassi Roininen, Jari Hämäläinen* | **Category: cs.CE** | **Updated: 2025-07-22**

**Keywords:** 药物设计, 拓扑优化, 鲁棒优化, 不确定性, SROM

**Comment:** 

> **TL;DR:** 本文提出了一种基于拓扑优化的计算逆向设计方法，用于在不确定性下设计具有目标释放曲线的个性化药物，并利用SROM提高计算效率和降低不确定性。

**AI_Comments:** 本文的创新点在于结合了拓扑优化、鲁棒优化和SROM，实现了在不确定性条件下对个性化药物释放曲线的精确控制。SROM的应用显著提高了计算效率，使其在实际应用中更具潜力。该方法对于药物研发具有重要意义，尤其是在需要高度定制化和精确释放控制的领域。

<details>
  <summary>Details</summary>

**Motivation:** 有效疾病治疗通常需要精确控制活性药物成分的释放。本文旨在解决如何确定最佳药物成分以实现目标释放曲线的问题。

**Method:** 本文提出了一种计算逆向设计方法，基于拓扑优化来确定最佳药物成分以实现目标释放曲线。该方法假设药物释放遵循Noyes-Whitney模型，并考虑药物材料参数和最终药物形状。它是非参数的，适用于任意药物形状。为解决随机药物材料参数带来的不确定性，该方法通过鲁棒拓扑优化进行补充，并利用随机降阶方法（SROM）传播溶解模型中的不确定性，相比蒙特卡罗方法，SROM所需样本更少，计算性能更好。

**Result:** 将该方法应用于设计具有多个目标释放曲线的药物。数值结果表明，设计出的药物的释放曲线与目标曲线非常接近。基于SROM的药物设计在释放曲线中表现出更低的不确定性。

**Conclusion:** 本文提出的方法是一种有效且具有说服力的不确定性感知药物设计方法，能够实现精确控制的药物释放并降低不确定性。

> **ai_Abstract:** 本文提出了一种基于拓扑优化的计算逆向设计方法，用于在不确定性下设计具有特定释放曲线的个性化药物。该方法利用Noyes-Whitney模型描述药物溶解过程，并通过鲁棒优化和随机降阶方法（SROM）有效处理药物材料参数的不确定性，显著提高了计算效率并降低了释放曲线的不确定性。数值结果验证了该方法能够设计出与目标曲线高度匹配且不确定性较低的药物。

> **摘要翻译:** 有效疾病治疗通常需要精确控制活性药物成分（API）的释放。在这项工作中，我们提出了一种计算逆向设计方法，用于确定能够产生目标释放曲线的最佳药物成分。我们假设药物释放遵循Noyes-Whitney模型，这意味着溶解发生在药物表面。我们的逆向设计方法基于拓扑优化。该方法根据目标释放曲线优化药物成分，同时考虑药物材料参数和最终药物的形状。我们的方法是非参数的，适用于任意药物形状。逆向设计方法通过鲁棒拓扑优化进行补充，该优化考虑了随机药物材料参数。我们使用随机降阶方法（SROM）来传播溶解模型中的不确定性。与蒙特卡罗方法不同，SROM需要更少的样本并提高了计算性能。我们将我们的方法应用于设计具有多种目标释放曲线的药物。数值结果表明，所设计药物的释放曲线与目标曲线非常接近。基于SROM的药物设计在其释放曲线中表现出更低的不确定性，这表明我们的方法是一种令人信服的不确定性感知药物设计方法。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [541] [Multi-objective Portfolio Optimization Via Gradient Descent](https://arxiv.org/abs/2507.16717)
> *基于梯度下降的多目标投资组合优化*

*Christian Oliva, Pedro R. Ventura, Luis F. Lago-Fernández* | **Category: cs.CE, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 多目标投资组合优化, 梯度下降, 自动微分, 可扩展性, 投资组合理论

**Comment:** 

> **TL;DR:** 本文提出了一种使用梯度下降和自动微分的多目标投资组合优化（MPO）框架，以解决传统方法在可扩展性和灵活性方面的挑战，并在各种场景下表现出竞争力。

**AI_Comments:** 该论文的创新之处在于将梯度下降与自动微分引入多目标投资组合优化领域，这为解决传统方法在可扩展性和灵活性方面的挑战提供了一条新途径。其重要性在于提供了一个能够处理复杂约束和多目标场景的实用工具，这对于金融领域的实际应用具有显著价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的投资组合优化方法，如二次规划或进化算法，在处理复杂约束、大数据集和/或多个冲突目标时，存在可扩展性或灵活性不足的问题。

**Method:** 本文引入了一个基于梯度下降和自动微分的多目标投资组合优化（MPO）基准框架。该方法支持任何优化目标（例如，最小化风险度量如CVaR或最大化夏普比率）以及实际约束（例如，跟踪误差限制、UCITS法规或资产组限制）。

**Result:** 该框架在六个实验场景中进行了评估，从单目标设置到复杂的多目标案例，并与CVXPY和SKFOLIO等标准求解器进行了比较。结果表明，该方法在提供增强的多目标和约束建模灵活性的同时，实现了具有竞争力的性能。

**Conclusion:** 本文旨在为研究人员和从业者提供一个实用且可扩展的工具，以探索现实世界条件下的高级投资组合优化问题。

> **ai_Abstract:** 本文提出了一个基于梯度下降和自动微分的多目标投资组合优化（MPO）框架，旨在克服传统方法在处理复杂约束和多目标时的可扩展性和灵活性限制。该框架支持多种优化目标和实际约束，并通过实验证明其在不同场景下均能达到具有竞争力的性能，同时提供了更高的建模灵活性。它为高级投资组合优化问题提供了一个实用且可扩展的解决方案。

> **摘要翻译:** 传统的投资组合优化方法，通常植根于现代投资组合理论并通过二次规划或进化算法求解，在可扩展性或灵活性方面面临挑战，尤其是在涉及复杂约束、大数据集和/或多个冲突目标的场景中。为了解决这些挑战，我们引入了一个使用梯度下降和自动微分的多目标投资组合优化（MPO）基准框架。我们的方法支持任何优化目标，例如最小化风险度量（例如，CVaR）或最大化夏普比率，以及实际约束，例如跟踪误差限制、UCITS法规或资产组限制。我们已经在六个实验场景中评估了我们的框架，从单目标设置到复杂的多目标案例，并将其性能与CVXPY和SKFOLIO等标准求解器进行了比较。我们的结果表明，我们的方法在提供增强的多目标和约束建模灵活性的同时，实现了具有竞争力的性能。我们旨在为探索现实世界条件下高级投资组合优化问题的研究人员和从业者提供一个实用且可扩展的工具。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [285] [Studying homing and synchronizing sequences for Timed Finite State Machines with output delays](https://arxiv.org/abs/2507.14526)
> *研究带输出延迟的定时有限状态机的归位序列和同步序列*

*Evgenii Vinarskii, Jakub Ruszil, Adam Roman, Natalia Kushik* | **Category: cs.FL, cs.CC** | **Updated: 2025-07-22**

**Keywords:** 归位序列, 同步序列, 定时有限状态机, 输出延迟, 复杂性

**Comment:** 

> **TL;DR:** 本文定义并研究了带输出延迟的定时有限状态机（TFSM）的归位序列和同步序列，指出其与非定时机器的差异，并探讨了推导方法。

**AI_Comments:** 该论文创新性地将归位序列和同步序列的概念扩展到带输出延迟的定时有限状态机，并揭示了定时系统与非定时系统在这些序列性质上的关键差异。此外，文章对不同推导方法的适用性进行了深入探讨和评估，为该领域的研究提供了重要的理论基础和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 研究带输出延迟的定时有限状态机（TFSM）的归位序列和同步序列，因为非定时机器的某些性质不适用于定时机器，且需要探索不同方法的适用性。

**Method:** 形式化定义带输出延迟的定时有限状态机（TFSM）的归位序列（HSs）和同步序列（SSs）。探讨截断后继树基方法和FSM抽象基方法的适用性。识别可直接应用这些方法的TFSM子类。评估存在性检查和推导（最短）HSs/SSs的复杂性。

**Result:** 发现非定时机器的某些性质不适用于定时机器。识别出不同推导方法可以直接应用的定时有限状态机（TFSM）子类。评估了（最短）归位序列/同步序列的存在性检查和推导的复杂性。

**Conclusion:** 本文形式化定义了带输出延迟的定时有限状态机（TFSM）的归位序列和同步序列，揭示了其与非定时机器的差异，并探讨了不同推导方法的适用性及相关复杂性。

> **ai_Abstract:** 本论文研究了带输出延迟的定时有限状态机（TFSM）的归位序列（HSs）和同步序列（SSs）。文章形式化定义了这些序列，并指出其与非定时机器的差异。作者探讨了基于截断后继树和FSM抽象等方法在推导这些序列时的适用性，识别出适合不同方法的TFSM子类，并评估了序列存在性检查和推导的复杂性。

> **摘要翻译:** 本文介绍了带输出延迟的定时有限状态机（TFSMs）的最终状态识别（同步和归位）序列，并研究了它们的性质。我们为这些TFSMs形式化定义了归位序列（HSs）和同步序列（SSs）的概念，并证明了适用于非定时机器的某些性质不一定适用于定时机器。此外，我们探讨了各种方法（例如基于截断后继树和基于FSM抽象的方法）在推导带输出延迟的定时FSM的SSs和HSs方面的适用性。相应地，我们确定了这些方法可以直接应用的TFSM子类以及需要其他方法的子类。此外，我们评估了带输出延迟的定时FSM的（最短）HSs/SSs的存在性检查和推导的复杂性。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [24] [GenControl: Generative AI-Driven Autonomous Design of Control Algorithms](https://arxiv.org/abs/2506.12554)
> *GenControl: 生成式AI驱动的控制算法自主设计*

*Chenggang Cui, Jiaming Liu, Peifeng Hui, Pengfeng Lin, Chuanlin Zhang* | **Category: eess.SY, cs.SY, 93C40, 49K15** | **Updated: 2025-07-22**

**Keywords:** 控制算法设计, 生成式AI, 大型语言模型, 粒子群优化, 自主设计

**Comment:** 

> **TL;DR:** 本文提出一个由大型语言模型（LLM）驱动的自主设计框架GenControl，通过结合LLM的结构探索和粒子群优化（PSO）的参数精炼，实现了复杂工业电子系统控制算法的自动化设计。

**AI_Comments:** 这项工作的创新之处在于将大型语言模型引入控制算法的自主设计，通过LLM的结构探索能力与传统优化算法（PSO）的参数精炼相结合，形成了一个新颖的双层优化框架。这不仅解决了传统方法在处理非线性系统和参数不确定性时的局限性，而且显著提高了设计过程的自动化和效率。这是一个将生成式AI应用于工程设计领域的有前景的探索，为未来复杂系统控制器的快速开发提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 设计复杂工业电子系统的控制器由于非线性和参数不确定性而具有挑战性，且传统方法通常速度慢且成本高。

**Method:** 提出一个由大型语言模型（LLMs）驱动的新型自主设计框架，采用双层优化策略：LLM智能探索并迭代改进控制算法的结构，而粒子群优化（PSO）算法有效精炼给定结构的参数，实现了端到端自动化设计。

**Result:** 通过对DC-DC升压转换器的仿真验证，该框架成功地将一个基本控制器演变为一个高性能的自适应版本，满足了快速响应、低误差和鲁棒性的所有严格设计规范。

**Conclusion:** 这项工作为控制设计提供了一个新范式，显著增强了自动化和效率。

> **ai_Abstract:** 本文提出GenControl，一个由大型语言模型（LLM）驱动的自主控制算法设计框架，旨在解决复杂工业电子系统控制器设计中传统方法的效率和成本问题。该框架采用双层优化策略，利用LLM探索并优化算法结构，同时通过粒子群优化（PSO）精炼参数，实现端到端的自动化设计。在DC-DC升压转换器的仿真中，GenControl成功生成了满足严格性能要求的高性能自适应控制器，展示了其在提升控制设计自动化和效率方面的潜力。

> **摘要翻译:** 设计复杂工业电子系统的控制器由于非线性和参数不确定性而具有挑战性，并且传统方法通常缓慢且成本高昂。为了解决这个问题，我们提出了一个由大型语言模型（LLM）驱动的新型自主设计框架。我们的方法采用双层优化策略：LLM智能地探索并迭代改进控制算法的结构，而粒子群优化（PSO）算法有效地精炼任何给定结构的参数。这种方法实现了端到端自动化设计。通过对DC-DC升压转换器的仿真验证，我们的框架成功地将一个基本控制器演变为一个高性能的自适应版本，满足了快速响应、低误差和鲁棒性的所有严格设计规范。这项工作为控制设计提供了一个新范式，显著增强了自动化和效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [73] [Fast Feeder Reconfiguration via Mesh Adaptive Direct Search in Black-Box Distribution System Environments](https://arxiv.org/abs/2507.16027)
> *快速馈线重构：基于网格自适应直接搜索的黑盒配电系统环境*

*Junyuan Zheng, Wenlong Shi, Zhaoyu Wang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-21**

**Keywords:** 馈线重构, 网格自适应直接搜索, 黑盒系统, 配电系统, 双目标优化

**Comment:** 3 pages, 3 figures

> **TL;DR:** 提出一种基于MADS的快速馈线重构框架，能在黑盒配电系统环境下实现近最优配置，且评估次数显著减少。

**AI_Comments:** 这篇论文的创新点在于将MADS应用于黑盒配电系统环境下的馈线重构问题，解决了传统优化方法对显式模型依赖的局限性。其重要性在于提供了一种无需内部系统知识即可操作的有效策略，这对于实际电力公司具有极高的实用价值。通过显著减少评估次数，该方法提高了效率，为未来的智能电网管理提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的馈线重构优化方法依赖于显式数学公式和分析模型，这在实际的、由异构、专有和黑盒仿真模块组成的公用事业环境中通常是不可行的。

**Method:** 本文提出了一种基于网格自适应直接搜索（MADS）的快速馈线重构框架。该方法仅需通过用于潮流、保护和电压调节分析的仿真模块进行性能指标评估。采用双目标公式，共同最小化有功功率损耗和运行约束违规。MADS算法中集成了基于帕累托的前沿过滤器，以有效地引导搜索高质量配置，同时系统性地修剪被支配的解。该方法利用局部轮询策略和收敛感知更新，自适应地细化有希望候选解周围的搜索空间。

**Result:** 在IEEE-123节点测试馈线上的案例研究表明，所提出的方法与启发式方法相比，在评估次数显著减少的情况下，实现了近最优配置。

**Conclusion:** 该研究成功开发了一种在黑盒配电系统环境中进行快速馈线重构的MADS框架，有效解决了现有方法的局限性，并以更少的计算量获得了高效的近最优解。

> **ai_Abstract:** 本文针对现有馈线重构方法在黑盒配电系统环境中不可行的问题，提出了一种基于网格自适应直接搜索（MADS）的快速馈线重构框架。该方法无需显式模型，仅通过仿真模块评估性能，并采用双目标（最小化有功功率损耗和约束违规）优化。通过集成帕累托前沿过滤器和自适应搜索空间细化，该方法能在更少的评估次数下，在IEEE-123节点测试馈线上实现近最优配置。

> **摘要翻译:** 馈线重构是配电系统中一项关键的运行策略。然而，现有的优化方法通常依赖于显式数学公式和分析模型，这在以异构、专有和黑盒仿真模块为特征的实际公用事业环境中往往是不可行的。为了解决这一挑战，本文提出了一种基于网格自适应直接搜索（MADS）的快速馈线重构框架。所提出的方法仅需通过用于潮流、保护和电压调节分析的仿真模块进行性能指标评估。采用双目标公式，共同最小化有功功率损耗和运行约束违规。MADS算法中集成了基于帕累托的前沿过滤器，以有效地引导搜索高质量配置，同时系统性地修剪被支配的解。该方法利用局部轮询策略和收敛感知更新，自适应地细化有希望候选解周围的搜索空间。在IEEE-123节点测试馈线上的案例研究表明，所提出的方法与启发式方法相比，在评估次数显著减少的情况下，实现了近最优配置。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [93] [Analytical Framework for Power System Strength](https://arxiv.org/abs/2507.16061)
> *电力系统强度分析框架*

*Ignacio Ponce, Federico Milano* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-21**

**Keywords:** 电力系统强度, Delta算子, 复频率, 分析框架, 母线电压相量

**Comment:** 

> **TL;DR:** 本文提出了一个通用的电力系统强度评估框架，包含12个指标和一种名为Delta算子新颖有限微分技术，并利用复频率概念，通过基准系统数值结果验证了其准确性。

**AI_Comments:** 该论文的创新之处在于引入了新颖的Delta算子有限微分技术和利用复频率概念来评估电力系统强度，这为量化电压瞬时变化提供了新的方法。其提出的通用框架具有广泛的适用性，可应用于各种系统设备，这对于电力系统分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估电力系统强度。

**Method:** 本文提出了一个通用的电力系统强度评估框架，该框架包含12个指标，分为三个动态阶次，用于量化母线电压相量及其一阶和二阶变化率对突发电流注入变化的抵抗能力。为量化这些变化，论文引入了一种新颖的有限微分技术，命名为Delta算子，能够准确捕捉代数变量的“跳变”，并利用了近期发展的复频率概念。该框架可系统地应用于任何系统设备，并提供了基于同步电机、变流器和负载模型的多种示例。

**Result:** 在基准系统中的数值结果验证了该公式的准确性。

**Conclusion:** 本文提出的电力系统强度评估框架及其公式是准确的，并且可以系统地应用于各种系统设备。

> **ai_Abstract:** 本文提出了一个通用的电力系统强度分析框架，该框架包含12个指标，用于量化母线电压相量及其变化率对突发电流注入的抵抗力。通过引入创新的Delta算子有限微分技术和利用复频率概念，该框架能够准确捕捉变量的瞬时变化。论文展示了其在各种系统设备上的系统应用，并通过基准系统的数值结果验证了其公式的准确性。

> **摘要翻译:** 本文提出了一个评估电力系统强度的通用框架。该公式包含十二个指标，分为三个动态阶次，用于量化母线电压相量及其一阶和二阶变化率对突发电流注入变化的抵抗能力。为了量化这些变化，本文引入了一种新颖的有限微分技术，我们将其命名为Delta算子，它能够正确捕捉代数变量的“跳变”，并利用了最近发展的复频率概念。本文还展示了所提出的框架如何系统地应用于任何系统设备，并提供了基于同步电机、变流器和负载模型的各种示例。基准系统中的数值结果验证了该公式的准确性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [113] [Automating Capacitor Part Selection with Dual-Objective Optimization](https://arxiv.org/abs/2507.16071)
> *双目标优化自动化电容器零件选择*

*Luke Brantingham, Jason Grover* | **Category: eess.SY, cs.SY, econ.GN, q-fin.EC** | **Updated: 2025-07-21**

**Keywords:** 电容器选择, 双目标优化, 多目标优化, 成本最小化, 面积最小化

**Comment:** 7 pages, 7 figures

> **TL;DR:** 本文提出了一种使用多目标优化技术自动选择电容器零件的新颖框架，旨在最小化成本和电路板面积，同时满足性能要求。

**AI_Comments:** 本文提出了一种新颖的自动化电容器零件选择框架，其创新点在于采用了多目标优化技术来同时解决成本和电路板面积的最小化问题。这对于电子设计领域具有重要意义，因为它能显著提高设计效率并优化资源利用。

<details>
  <summary>Details</summary>

**Motivation:** 在电子设计中优化电容器选择，以最小化成本和电路板面积，同时满足关键性能要求。

**Method:** 使用多目标线性与非线性约束优化技术。

**Result:** 该方法在最小化成本和电路板面积，同时满足关键性能要求方面显示出有效性。

**Conclusion:** 所提出的框架能够有效地自动化电容器零件选择，实现成本和电路板面积的最小化，并满足性能要求。

> **ai_Abstract:** 本文介绍了一种创新的框架，通过应用多目标线性和非线性约束优化技术，自动化电子设计中的电容器选择过程。该方法旨在同时实现成本和电路板面积的最小化，并确保满足所有关键性能需求，其有效性已得到证实。

> **摘要翻译:** 本文提出了一种利用多目标线性和非线性约束优化技术来优化电子设计中电容器选择的新颖框架。我们证明了该方法在最小化成本和电路板面积，同时满足关键性能要求方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [133] [The Sustainability of the Leo Orbit Capacity via Risk-Driven Active Debris Removal](https://arxiv.org/abs/2507.16101)
> *通过风险驱动的主动碎片清除实现LEO轨道容量的可持续性*

*Yacob Medhin, Simone Servadio* | **Category: eess.SY, cs.SY, physics.space-ph** | **Updated: 2025-07-21**

**Keywords:** 空间碎片, LEO, 主动碎片清除, 风险评估, FMM

**Comment:** 20 pages, 10 figures

> **TL;DR:** 低地球轨道（LEO）空间碎片增多危及轨道可持续性。本研究开发并验证了FMM风险指数，旨在优化高危碎片的识别和优先排序，用于主动碎片清除（ADR）任务。通过MOCAT-MC模拟框架，研究发现FMM在识别高风险目标方面表现优异，并强调了物理质量项在风险评估中的重要性。该研究提供了一个开源工具，增强了选择最佳ADR目标的能力，以确保LEO运行的长期可行性。

**AI_Comments:** 本文为空间可持续性这一紧迫问题提供了一个实用的解决方案。FMM的开发及其通过模拟进行的验证，为优化主动碎片清除工作提供了宝贵的工具。对质量项重要性的强调，对于未来的风险评估模型而言是一个重要的见解。开源工具的提供进一步增强了其潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）中不断增长的空间碎片危及长期轨道可持续性，因此需要对主动碎片清除（ADR）任务进行高效的风险评估。

**Method:** 本研究开发并验证了过滤修正MITRI（FMM）风险指数，这是一种旨在改进高关键性碎片优先排序的增强型风险指数。研究利用MOCAT-MC模拟框架，进行了全面的性能评估和敏感性分析，以探究FMM公式的鲁棒性。

**Result:** 结果表明，FMM在年度清除行动中能更有效地识别高风险目标。风险模型之间存在细微的性能权衡，这取决于操作清除的节奏。分析还证实，基于物理的质量项对于实际风险评估是不可或缺的。

**Conclusion:** 通过提供经过验证的开源工具和对风险动态的关键见解，本研究增强了我们选择最佳ADR目标和确保LEO操作长期可行性的能力。

> **ai_Abstract:** 本文针对低地球轨道（LEO）空间碎片日益增多的挑战，开发并验证了过滤修正MITRI（FMM）风险指数。FMM旨在改进主动碎片清除（ADR）任务中高关键性碎片的优先排序。研究利用MOCAT-MC模拟框架，发现FMM在识别年度清除行动中的高风险目标方面表现优异，尽管性能权衡取决于清除节奏。研究还强调了基于物理的质量项在风险评估中的关键作用。本研究提供了一个开源工具和相关见解，以优化ADR目标选择并确保LEO的长期可持续性。

> **摘要翻译:** 低地球轨道（LEO）中不断增长的空间碎片危及长期轨道可持续性，这需要对主动碎片清除（ADR）任务进行高效的风险评估。本研究提出了过滤修正MITRI（FMM）的开发和验证，这是一种旨在改进高关键性碎片优先排序的增强型风险指数。利用MOCAT-MC模拟框架，我们进行了全面的性能评估和敏感性分析，以探究FMM公式的鲁棒性。结果表明，虽然FMM在年度清除行动中能更有效地识别高风险目标，但风险模型之间存在细微的性能权衡，这取决于操作清除的节奏。分析还证实，基于物理的质量项对于实际风险评估是不可或缺的。通过提供经过验证的开源工具和对风险动态的关键见解，本研究增强了我们选择最佳ADR目标和确保LEO操作长期可行性的能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [153] [Design and Implementation of a Lightweight Object Detection System for Resource-Constrained Edge Environments](https://arxiv.org/abs/2507.16155)
> *面向资源受限边缘环境的轻量级目标检测系统设计与实现*

*Jiyue Jiang, Mingtong Chen, Zhengbao Yang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 目标检测, 边缘计算, 模型压缩, 低功耗, 嵌入式视觉

**Comment:** 

> **TL;DR:** 该项目旨在为资源受限的边缘设备（如STM32H7）设计并实现一个轻量级目标检测系统，通过模型压缩技术使其能在低功耗下运行并保护数据隐私。

**AI_Comments:** 该论文的创新点在于将YOLOv5模型与多种模型压缩技术相结合，并成功部署到资源受限的STM32H7微控制器上，实现了低功耗、本地化和高效率的边缘目标检测。这对于数据隐私敏感和便携式应用场景具有重要意义，展示了在极端资源约束下实现复杂AI功能的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 在低功耗、数据隐私要求严格且资源受限的户外旅行场景下，需要在边缘设备上运行目标检测模型。

**Method:** 该系统使用STM32H7微控制器，选择YOLOv5模型进行训练。为克服嵌入式设备的资源限制，采用了剪枝、量化和蒸馏等模型压缩技术来提高模型性能和效率。

**Result:** 通过模型压缩，成功减少了模型的计算量和参数数量，使得计算机视觉模型能够在微控制器设备上运行，适用于嵌入式视觉应用开发。

**Conclusion:** 该系统实现了在微控制器设备上运行计算机视觉模型的能力，为嵌入式视觉应用开发提供了解决方案。

> **ai_Abstract:** 该论文设计并实现了一个面向资源受限边缘环境的轻量级目标检测系统。该系统针对户外旅行场景，能在STM32H7等低功耗MCU上运行，并支持本地数据处理以保护隐私。通过对YOLOv5模型进行剪枝、量化和蒸馏等压缩，显著降低了模型的计算和参数量，成功使其适应嵌入式设备，为边缘视觉应用开发提供了可行方案。

> **摘要翻译:** 该项目旨在开发一种在低功耗条件下运行目标检测模型的系统。检测场景设定为户外旅行场景，检测类别包括人员和车辆。在该系统中，用户数据无需上传到云端，这适用于便携式需求和对数据隐私有严格要求的环境。该系统使用的MCU设备是STM32H7，它在低功耗设备中具有更好的性能。选择YOLOv5系统来训练目标检测模型。为了克服嵌入式设备的资源限制，该项目使用了多种模型压缩技术，如剪枝、量化和蒸馏，这些技术可以提高检测模型的性能和效率。通过这些过程，可以减少模型的计算量和模型参数数量，以便在微控制器设备上运行计算机视觉模型，用于嵌入式视觉应用的开发。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [173] [Design and Optimization of Wearables for Human Motion Energy Harvesting](https://arxiv.org/abs/2507.16157)
> *可穿戴人体运动能量收集设备的设计与优化*

*Weijia Peng, Mingtong Chen, Zhengbao Yang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 能量收集, 可穿戴设备, 电磁发电机, 鞋载系统, 自供电

**Comment:** 

> **TL;DR:** 本文研究了一种鞋载式电磁能量收集系统，利用行走时的垂直压力发电，并通过仿真和原型测试验证了其可行性，为自供电可穿戴设备奠定了基础。

**AI_Comments:** 本文的创新之处在于其将人体运动能量收集应用于可穿戴设备，特别是鞋类，以实现能量自给自足。其重要性在于为未来减少对外部电源依赖的可穿戴电子设备提供了可行性方案。虽然目前处于早期研究阶段，但为后续的优化和产品集成奠定了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 随着可穿戴电子设备的日益普及，人们对可持续设计且能实现能量自给自足的系统越来越感兴趣并有需求。

**Method:** 本研究调查了一种鞋载式能量收集系统，该系统利用行走时的机械能输出电能。一个弹簧连接到嵌入鞋跟的电磁发电机，以回收脚部踩踏产生的垂直压力。研究人员设计了一个MATLAB仿真的标准电磁发电机原型，并测试了一个初始的低保真原型，以验证电磁发电机与简单电路之间的关系。

**Result:** 模拟原型显示最大电压为12V。初始低保真原型测试观察到能量输出。

**Conclusion:** 这项研究为自供电鞋类和能量独立的可穿戴电子设备奠定了基础。

> **ai_Abstract:** 本文研究了一种利用鞋载式电磁发电机从人体行走中收集能量的系统。通过将弹簧连接到鞋跟的电磁发电机来捕获垂直压力，并进行了MATLAB仿真和低保真原型测试。仿真结果显示最大电压为12V，初步原型也验证了能量输出。该研究为开发自供电可穿戴设备和鞋类奠定了基础。

> **摘要翻译:** 随着可穿戴电子设备的日益普及，人们对可持续设计且能实现能量自给自足的系统越来越感兴趣并有需求。本文描述的研究调查了一种鞋载式能量收集系统，该系统旨在利用行走时的机械能输出电能。一个弹簧连接到嵌入鞋跟的电磁发电机，以回收脚部踩踏产生的垂直压力。模拟原型由在MATLAB中设计的标准电磁发电机组成，演示了12V的最大电压。初始低保真原型测试了电磁发电机与简单电路之间的关系，并观察到能量输出。未来的研究将探索增强整体发电机设计，集成电源管理IC以保护和调节电池，并将系统整合到最终产品——可穿戴鞋类中。这项研究为自供电鞋类和能量独立的可穿戴电子设备奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [198] [The Bode Plots for Sliding-Mode Control Design](https://arxiv.org/abs/2507.16281)
> *适用于滑模控制设计的伯德图*

*Ulises Pérez-Ventura* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 滑模控制, 频域, 描述函数, 颤振, 鲁棒设计

**Comment:** 15 pages, 17 figures

> **TL;DR:** 本文提出了一个统一的滑模控制系统频域分析框架，利用描述函数理论和等效增益模型分析颤振和系统灵敏度，并通过仿真验证了其准确性，为滑模控制器提供了实用的鲁棒设计指导。

**AI_Comments:** 本文的创新之处在于为滑模控制系统提供了一个统一的频域分析框架，这对于传统上主要在时域进行分析的滑模控制来说是一个重要的进展。利用描述函数理论和等效增益模型，为颤振的量化分析和系统灵敏度评估提供了具体工具，这对于实际工程应用具有重要价值。其重要性体现在它为滑模控制器的鲁棒设计和系统化增益调整提供了实用的见解，有助于平衡性能指标（如扰动抑制和颤振衰减），并考虑实际约束。

<details>
  <summary>Details</summary>

**Motivation:** 传统的滑模控制系统分析主要在时域进行，缺乏统一的频域框架来分析其性能，包括颤振振荡和系统灵敏度。本文旨在开发一个统一的频域框架，为滑模控制器提供鲁棒设计和系统增益调整的实用见解，以平衡扰动抑制和颤振衰减。

**Method:** 本文开发了一个统一的滑模控制系统频域分析框架，涵盖了不连续和Lipschitz连续的实现。它利用描述函数(DF)理论推导出颤振振荡的幅度和频率的闭式表达式，并建立等效增益(EG)模型以进行闭环灵敏度分析。该方法还通过Loeb准则纳入了轨道稳定性考量，以确保颤振有界。

**Result:** 该框架推导出了颤振振荡幅度和频率的闭式表达式，并建立了等效增益模型以进行闭环灵敏度分析。所提出的方法能够捕捉执行器动力学、控制参数和扰动剖面对稳态性能的影响。仿真验证了理论预测，在低频区域，基于EG的灵敏度函数能准确预测系统响应的幅度和相位，跟踪误差在15%以内。该框架还确保了颤振有界。

**Conclusion:** 本文的结果为滑模控制器的鲁棒设计提供了实用见解，实现了系统化的增益调整，从而平衡了扰动抑制和颤振衰减，同时考虑了执行器和传感器约束。

> **ai_Abstract:** 本文提出了一个统一的滑模控制系统频域分析框架，适用于不连续和Lipschitz连续的实现。该框架利用描述函数理论推导颤振振荡的闭式表达式，并构建等效增益模型进行闭环灵敏度分析。研究验证了该方法能准确预测系统响应，且颤振有界。这些成果为滑模控制器的鲁棒设计和系统增益调整提供了实用指导，以优化扰动抑制和颤振衰减。

> **摘要翻译:** 本文为滑模控制系统（包括不连续和Lipschitz连续实现）的分析开发了一个统一的频域框架。利用描述函数（DF）理论，推导了颤振振荡的幅度和频率的闭式表达式，以及能够进行闭环灵敏度分析的等效增益（EG）模型。所提出的方法捕捉了执行器动力学、控制参数和扰动剖面对稳态性能的影响。
通过在恒定和正弦扰动下的仿真验证了偏差和振荡分量的理论预测。在低频区域，基于EG的灵敏度函数准确预测了系统响应的幅度和相位，只要DF假设成立，跟踪误差保持在15%的裕度内。该框架还通过Loeb准则纳入了轨道稳定性考量，确保颤振保持有界。
总的来说，这些结果为滑模控制器的鲁棒设计提供了实用见解，实现了系统化的增益调整，从而平衡了扰动抑制和颤振衰减，同时考虑了执行器和传感器约束。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [223] [Polarforming Design for Movable Antenna Systems](https://arxiv.org/abs/2507.16311)
> *可移动天线系统的极化成形设计*

*Zijian Zhou, Jingze Ding, Rui Zhang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 极化成形, 可移动天线, 信道去极化, SCA, 可达速率

**Comment:** 5 pages, 5 figures

> **TL;DR:** 该文研究了可移动天线（MA）通信系统中的极化成形设计，通过同时优化天线位置和极化相移，利用空间和极化自由度，以最大化可达速率，并仿真验证了其在缓解信道去极化和适应信道衰落方面的性能增益。

**AI_Comments:** 本文创新性地将极化成形技术应用于可移动天线系统，并结合空间和极化自由度进行优化，以提升通信性能。所提出的基于SCA的优化算法为解决该问题提供了有效途径。该研究对于未来无线通信系统中提高频谱效率和系统鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 极化成形技术作为一种有前景的技术，能够使天线将极化整形到期望状态，以与接收到的电磁波极化对齐，或重新配置发射的电磁波极化。本文旨在研究可移动天线（MA）通信系统中的极化成形设计。

**Method:** 本文研究了可移动天线（MA）通信系统中的极化成形设计。具体而言，考虑了一个具有可重构天线位置和极化的单输入单输出（SISO）系统，以利用空间和极化自由度。首先，提出了一个极化信道模型，并将信道响应表征为天线位置和极化相移的函数。为了最大化所提出系统的可达速率，本文开发了一种基于连续凸逼近（SCA）的优化算法，通过迭代优化发射器和接收器的天线位置和相移。

**Result:** 仿真结果表明，与传统系统相比，所提出的系统在缓解信道去极化和适应信道衰落方面具有性能增益。

**Conclusion:** 本文提出的可移动天线系统中的极化成形设计，通过优化天线位置和极化相移，能够有效利用空间和极化自由度，从而在缓解信道去极化和适应信道衰落方面展现出显著的性能增益，并最大化了可达速率。

> **ai_Abstract:** 本文研究了可移动天线（MA）通信系统中的极化成形设计。通过考虑一个具有可重构天线位置和极化的SISO系统，利用空间和极化自由度，并提出了一个极化信道模型。为最大化可达速率，开发了一种基于SCA的优化算法，迭代优化天线位置和相移。仿真结果表明，该系统在缓解信道去极化和适应信道衰落方面优于传统系统。

> **摘要翻译:** 极化成形技术已成为一种有前景的技术，能够使天线将其极化塑造成所需状态，以与接收到的电磁（EM）波对齐，或重新配置发射的电磁波。在这封信中，我们研究了可移动天线（MA）通信系统中的极化成形设计。具体而言，我们考虑了一个具有可重构天线位置和极化的单输入单输出（SISO）系统，以利用空间和极化自由度（DoFs）。首先，我们提出了一个极化信道模型，并将信道响应表征为天线位置和极化成形相移的函数。为了最大化所提出系统的可达速率，我们随后开发了一种基于连续凸逼近（SCA）的优化算法，通过迭代优化发射器和接收器的天线位置和相移。此外，仿真结果表明，与传统系统相比，所提出的系统在缓解信道去极化和适应信道衰落方面具有性能增益。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [248] [Derivative-Agnostic Inference of Nonlinear Hybrid Systems](https://arxiv.org/abs/2507.16426)
> *非线性混合系统的导数无关推理*

*Hengzhi Yu, Bohan Ma, Mingshuai Chen, Jie An, Bin Gu, Naijun Zhan, Jianwei Yin* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 混合系统, NARX模型, 导数无关, 系统推理, 模式切换

**Comment:** 

> **TL;DR:** 本文提出了一种名为Dainarx的导数无关方法，用于推理非线性混合系统，该方法使用NARX模型作为统一的、无阈值的表示，并在性能上优于现有技术。

**AI_Comments:** 本文的创新点在于提出了一个“导数无关”的混合系统推理框架，成功避免了传统方法中对用户设定阈值的依赖，这大大提升了方法的鲁棒性和易用性。通过引入NARX模型，Dainarx能够处理高阶非线性动力学，并取得了优于现有技术的准确性，对于混合系统建模领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有混合系统推理方法主要采用基于导数的方法，其中模式切换和轨迹段聚类都依赖于用户设定的阈值，这限制了其适用性和准确性。本文旨在提出一种无需这些阈值的新方法。

**Method:** 本文提出了一种名为Dainarx的导数无关方法，用于推理非线性混合系统。Dainarx使用非线性自回归外生（NARX）模型来捕捉系统动力学，并将其作为统一的、无阈值的表示，用于检测模式切换和轨迹段聚类。

**Result:** 实验结果表明，Dainarx能够有效且高效地推理具有高阶动力学的非平凡混合自动机，并能学习到紧密近似一类通用混合系统（包括高阶非线性动力学、外生输入、非线性守卫条件和线性复位）的模型。与现有技术相比，Dainarx产生了显著更准确的近似。

**Conclusion:** Dainarx方法提供了一种有效且高效的导数无关框架，用于推理复杂的非线性混合系统，克服了现有基于导数方法对用户设定阈值的依赖，并在准确性上取得了显著提升。

> **ai_Abstract:** 本文提出了一种名为Dainarx的导数无关方法，用于从输入-输出轨迹中推理非线性混合系统。与现有基于导数且依赖阈值的方法不同，Dainarx利用非线性自回归外生（NARX）模型作为统一且无需阈值的表示，来检测模式切换和聚类轨迹段。该方法能够有效学习和近似复杂的高阶非线性混合系统，并在实验中表现出比现有技术更高的推理准确性。

> **摘要翻译:** 本文解决了从混合系统的输入-输出轨迹集中推理混合自动机的问题，该混合系统在连续演化动力学之间表现出离散模式切换。现有方法主要采用基于导数的方法，其中（i）模式切换的发生由导数的剧烈变化确定，（ii）轨迹段的聚类依赖于信号相似性——两者都受用户提供的阈值影响。我们提出了一种名为Dainarx的导数无关方法，用于推理非线性混合系统，其中动力学由非线性自回归外生（NARX）模型捕获。Dainarx采用NARX模型作为统一的、无阈值的表示，通过检测模式切换和轨迹段聚类。我们表明，Dainarx足以学习紧密近似具有高阶非线性动力学、外生输入、非线性守卫条件和线性复位的通用混合系统的模型。在一系列基准测试上的实验结果表明，我们的方法可以有效且高效地推理具有高阶动力学的非平凡混合自动机，产生比最先进技术显著更准确的近似。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [278] [Arbitrage Tactics in the Local Markets via Hierarchical Multi-agent Reinforcement Learning](https://arxiv.org/abs/2507.16479)
> *通过分层多智能体强化学习实现本地市场套利策略*

*Haoyang Zhang, Mina Montazeri, Philipp Heer, Koen Kok, Nikolaos G. Paterakis* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 分层多智能体强化学习, 套利策略, 本地市场, 两阶段马尔可夫博弈, 能源管理

**Comment:** 

> **TL;DR:** 本文提出了一种分层多智能体强化学习（HMARL）算法，以实现聚合商在本地电力市场（LEM）和本地灵活性市场（LFM）之间的套利，结果显示平均利润增加40.6%。

**AI_Comments:** 本文的创新点在于首次将分层多智能体强化学习应用于跨本地市场的套利问题，解决了现有研究中单一市场限制的不足。通过引入两阶段马尔可夫博弈模型和子代理协调机制，有效提升了市场参与者的经济效益，为智能电网中的能源管理和交易提供了新的策略。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已探索在单一市场中利用多智能体强化学习（MARL）算法进行战略性竞价，但跨本地市场的套利机会尚未被探索。本文旨在通过优化能源管理和竞价，增强市场参与者的经济效益。

**Method:** 本文引入了一种分层多智能体强化学习（HMARL）算法，旨在实现聚合商在多个本地市场之间的套利。聚合商在本地市场中的战略行为被建模为两阶段马尔可夫博弈：第一阶段涉及本地电力市场（LEM），第二阶段包括本地灵活性市场（LFM）和平衡市场。为解决此博弈，HMARL框架为每个聚合商分配两个子代理，即一个主要子代理和一个次要子代理，它们在套利策略下进行通信和协调。

**Result:** 案例研究表明，尽管在本地电力市场（LEM）中初始成本较高，但该套利策略在本地灵活性市场（LFM）和平衡市场中产生了可观的节约，平均总利润增加了40.6%。

**Conclusion:** 所提出的HMARL算法能够解决两阶段马尔可夫博弈问题，并促进跨本地市场的套利，从而显著提高市场参与者的盈利能力。

> **ai_Abstract:** 本文提出了一种分层多智能体强化学习（HMARL）算法，用于解决聚合商在本地电力市场（LEM）和本地灵活性市场（LFM）之间的两阶段马尔可夫博弈中的套利问题。该算法通过为每个聚合商分配两个协调的子代理来实现跨市场套利，与独立运作的传统方法相比，能显著提高整体效率和利润。案例研究显示，采用该套利策略可使总利润平均增加40.6%。

> **摘要翻译:** 本地市场中（包括本地电力市场（LEM）和本地灵活性市场（LFM））生产者-消费者（prosumers）采用的战略性竞价策略，因其通过优化能源管理和竞价来提高市场参与者的经济效益的潜力而备受关注。尽管现有研究已经探索了在单一市场中利用多智能体强化学习（MARL）算法进行战略性竞价，但跨本地市场的套利机会仍未被探索。本文引入了一种分层多智能体强化学习（HMARL）算法，旨在实现聚合商在多个本地市场之间的套利。这些聚合商在本地市场中的战略行为被建模为两阶段马尔可夫博弈：第一阶段涉及LEM，而第二阶段包括LFM和平衡市场。为解决此两阶段马尔可夫博弈，HMARL框架为每个聚合商分配两个子代理，即一个主要子代理和一个次要子代理。如果没有套利策略，这些子代理将独立运作，主要子代理专注于第一阶段利润，次要子代理专注于第二阶段利润，各自采用独立的多智能体强化学习。相反，当使用所提出的HMARL实施套利策略时，子代理之间进行通信和协调，以在多个本地市场之间执行套利，从而提高整体效率。在所有聚合商均采用套利策略的场景下进行的案例研究表明，尽管在LEM中初始成本较高，但该策略在LFM和平衡市场中产生了可观的节约，平均总利润增加了40.6%。这突显了所提出的HMARL解决两阶段马尔可夫博弈并促进跨本地市场套利的能力，从而提高参与者的盈利能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [308] [Graphical Analysis of Nonlinear Multivariable Feedback Systems](https://arxiv.org/abs/2507.16513)
> *非线性多变量反馈系统的图形分析*

*Julius P. J. Krebbekx, Roland Tóth, Amritam Das* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-22**

**Keywords:** 尺度相对图, 非线性系统, 多输入多出系统, 图形分析, 稳定性理论

**Comment:** Submitted to IEEE-TAC on 22-07-2025

> **TL;DR:** 本文提出了一个完整的尺度相对图（SRG）框架，用于分析非线性、非方阵的多输入多输出（MIMO）系统，解决了现有SRG分析在推广到MIMO系统时仅限于方阵或线性时不变（LTI）系统的局限性。

**AI_Comments:** 本文的创新之处在于成功地将尺度相对图（SRG）分析推广到了更广泛的非线性、非方阵多输入多输出（MIMO）系统，克服了先前研究的局限性。通过引入算子嵌入和受限输入空间的概念，并开发相应的互连规则和稳定性定理，为复杂非线性系统的图形分析提供了一个强大的新工具。这对于控制系统设计和分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的尺度相对图（SRG）分析在推广到多输入多输出（MIMO）系统时存在局限性，即仅能应用于方阵系统，在某些情况下甚至只适用于线性时不变（LTI）系统。因此，需要开发一个更通用的SRG框架来分析非线性、非方阵的MIMO系统。

**Method:** 本文开发了一个完整的SRG框架，用于分析非线性、非方阵的MIMO系统。关键在于将算子嵌入到一个作用于共同希尔伯特空间的算子空间中，同时将输入空间限制在原始输入维度。文中还开发了使用受限输入空间的互连规则和稳定性定理，以保证整体互连的因果性、适定性和（增量）$L_2$增益界。此外，还提供了稳定LTI算子和对角静态非线性算子MIMO SRG的计算公式。

**Result:** 本文展示了所提出的理论概念在分析线性分数表示形式的非线性系统上的应用，这是一种非常通用的系统类别。此外，还提供了稳定LTI算子和对角静态非线性算子MIMO SRG的计算公式。最后，通过几个例子证明了所提出方法的能力。

**Conclusion:** 本文成功开发了一个完整的尺度相对图（SRG）框架，用于分析更广泛的非线性、非方阵的多输入多输出（MIMO）系统，并提供了其在实际系统分析中的应用和计算方法，克服了现有方法的局限性。

> **ai_Abstract:** 本文针对现有尺度相对图（SRG）分析在推广到多输入多输出（MIMO）系统时仅限于方阵或线性时不变（LTI）系统的不足，提出了一个完整的SRG框架。该框架能够分析非线性、非方阵的MIMO系统，通过将算子嵌入到共同希尔伯特空间并限制输入空间来构建。文章开发了互连规则和稳定性定理以确保系统特性，并展示了其在分析线性分数表示形式的非线性系统上的应用。此外，还提供了稳定LTI和对角静态非线性算子MIMO SRG的计算公式，并通过实例验证了方法的有效性。

> **摘要翻译:** 尺度相对图（SRG）为非线性系统分析提供了一种新颖的图形频率域方法。最近有一些努力将SRG分析推广到多输入多输出（MIMO）系统。然而，这些尝试仅对方阵系统产生了结果，并且在某些情况下，仅适用于线性时不变（LTI）系统的方法。在本文中，我们开发了一个完整的SRG框架，用于分析可能是非线性、非方阵的MIMO系统。关键要素是将算子嵌入到一个作用于共同希尔伯特空间的算子空间中，同时将输入空间限制在原始输入维度。我们开发了使用受限输入空间的互连规则和稳定性定理，以保证整体互连的因果性、适定性和（增量）$L_2$增益界。我们展示了所提出的理论概念在分析线性分数表示形式的非线性系统上的应用，这是一种相当通用的系统类别，其表示形式可直接用于控制。此外，我们提供了稳定LTI算子和对角静态非线性算子MIMO SRG的计算公式。最后，我们通过几个例子展示了我们提出的方法的能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [338] [A Distributed Actor-Critic Algorithm for Fixed-Time Consensus in Nonlinear Multi-Agent Systems](https://arxiv.org/abs/2507.16520)
> *一种用于非线性多智能体系统固定时间一致性的分布式Actor-Critic算法*

*Aria Delshad, Maryam Babazadeh* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 固定时间一致性, 多智能体系统, 强化学习, Actor-Critic, 非线性系统

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习（RL）的分布式Actor-Critic算法，并结合固定时间自适应机制，旨在解决非线性多智能体系统中的固定时间一致性问题，该方法在收敛速度和鲁棒性方面优于现有技术。

**AI_Comments:** 本文创新性地将Actor-Critic强化学习与固定时间自适应机制相结合，解决了非线性多智能体系统在有限信息（仅输出信息、有向图）下实现固定时间一致性的难题。其核心贡献在于无论初始条件如何，都能保证在固定时间内收敛，并增强了对不确定性的鲁棒性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非线性多智能体系统中实现固定时间一致性面临显著挑战，这主要归因于未知非线性、智能体间耦合和外部干扰的存在，尤其是在仅能进行输出信息交换的情况下。

**Method:** 本文提出了一种基于强化学习（RL）的反步控制策略，以实现非线性多智能体系统中的固定时间一致性。该方法将分布式Actor-Critic强化学习算法与一种新颖的固定时间自适应机制相结合。每个智能体都采用Actor-Critic架构，并由两个估计器网络支持，以处理系统不确定性和未知扰动。智能体仅通过有向通信图与其邻居交换输出信息。

**Result:** 所提出的自适应律确保所有智能体无论初始条件如何，都能在固定时间内跟踪领导者。一致性和跟踪误差保证收敛到原点的一个小邻域，且收敛半径可通过控制参数调节。仿真结果表明，该方法有效且在收敛速度和鲁棒性方面优于现有技术。

**Conclusion:** 本文提出的分布式Actor-Critic算法结合固定时间自适应机制，能有效实现非线性多智能体系统中的固定时间一致性，并展现出优越的收敛速度和鲁棒性。

> **ai_Abstract:** 本文针对具有严格反馈动力学的非线性多智能体系统，提出了一种基于强化学习（RL）的反步控制策略，旨在实现固定时间一致性。该方法通过集成Actor-Critic强化学习与一种新颖的固定时间自适应机制来解决未知非线性、智能体间耦合和外部干扰带来的挑战。每个智能体仅与邻居交换输出信息，并利用Actor-Critic架构和两个估计器网络处理不确定性。该方法保证所有智能体在固定时间内跟踪领导者，且一致性和跟踪误差收敛到原点的一个小邻域。仿真结果验证了其有效性，并在收敛速度和鲁棒性方面优于现有技术。

> **摘要翻译:** 本文提出了一种基于强化学习（RL）的自适应反步控制策略，旨在实现具有严格反馈动力学的非线性多智能体系统中的固定时间一致性。智能体仅通过有向通信图与其邻居交换输出信息，无需完整的状态测量或对称通信。实现固定时间一致性（即收敛在独立于初始条件的预设时间范围内发生）面临着巨大挑战，因为存在未知非线性、智能体间耦合和外部干扰。这项工作通过将actor-critic强化学习与一种新颖的固定时间自适应机制相结合来解决这些挑战。每个智能体都采用一种由两个估计器网络支持的actor-critic架构，这些网络旨在处理系统不确定性和未知扰动。自适应律的开发旨在确保所有智能体无论其初始条件如何，都能在固定时间内跟踪领导者。一致性和跟踪误差保证收敛到原点的一个小邻域，收敛半径可通过控制参数进行调节。仿真结果证明了所提出方法的有效性，并突出了其在收敛速度和鲁棒性方面优于现有方法的优势。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [380] [Integral action for bilinear systems with application to counter current heat exchanger](https://arxiv.org/abs/2507.16553)
> *双线性系统中的积分作用及其在逆流换热器中的应用*

*Francesco Ripa, Daniele Astolfi, Boussad Hamroun, Diego Regruto* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-22**

**Keywords:** 逆流换热器, 双线性系统, 积分控制, 温度调节, 鲁棒控制

**Comment:** 

> **TL;DR:** 本研究提出了一种针对逆流换热器的鲁棒控制策略，通过三种不同的控制方法（包括增强前馈控制器、带状态观测器的输出反馈控制器和纯积分控制律）来调节流体出口温度，并通过实际实验验证了其有效性。

**AI_Comments:** 该论文的创新点在于为逆流换热器提出了一个结构化的双线性系统模型，并在此基础上设计了多种控制策略。其重要性在于通过实际实验验证了所提策略的有效性，这对于工业应用具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的主要目的是通过调节第二股逆流流体的流量来控制一股流体出口的温度，从而为逆流换热器提供鲁棒控制策略。

**Method:** 研究人员利用能量平衡方程，通过将每股流体均匀空间离散化为一系列均匀体积，并考虑换热器内的传热和对流现象，开发了一个结构化的双线性系统模型。在此基础上，提出了三种控制策略：(i) 增强前馈控制器，(ii) 结合状态观测器的输出反馈控制器，以及 (iii) 纯积分控制律。

**Result:** 所提出的控制策略的有效性通过在真实换热器上的实际实验得到了验证。

**Conclusion:** 本文提出的针对逆流换热器的鲁棒控制策略，包括三种不同的控制方法，在实际实验中被证明是有效的。

> **ai_Abstract:** 本研究提出并验证了一种针对逆流换热器的鲁棒控制策略，旨在通过调节第二股流体流量来控制第一股流体的出口温度。该策略基于一个结构化的双线性系统模型，该模型通过能量平衡方程和空间离散化方法构建，并考虑了传热和对流现象。文中详细介绍了三种控制方法：增强前馈控制器、带状态观测器的输出反馈控制器以及纯积分控制律。这些控制策略的有效性已通过在实际换热器上的实验得到证实。

> **摘要翻译:** 本研究提出了一种针对逆流换热器的鲁棒控制策略。主要目标是通过操纵第二股逆流流体的流量来调节一股流体的出口温度。通过利用能量平衡方程，我们通过将每股流体均匀空间离散化为一系列均匀体积，并考虑换热器内的传热和对流现象，开发了一个结构化的双线性系统模型。我们引入了三种控制策略：(i) 增强前馈控制器，(ii) 结合状态观测器的输出反馈控制器，以及 (iii) 纯积分控制律。所提出的控制策略的有效性通过在真实换热器上的实际实验得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [422] [Dynamic Activation and Assignment of SDN Controllers in LEO Satellite Constellations](https://arxiv.org/abs/2507.16774)
> *低轨卫星星座中SDN控制器的动态激活与分配*

*Wafa Hasanain, Pablo G. Madoery, Halim Yanikomeroglu, Gunes Karabulut Kurt, Sameera Siddiqui, Stephane Martel, Khaled Ahmed, Colin Bellinger* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 软件定义网络, 低轨卫星, 控制器分配, 传播延迟, 优化

**Comment:** 

> **TL;DR:** 本文提出了一种动态卫星到控制器分配(DSCA)优化方法，用于低轨卫星星座的SDN网络，旨在最小化传播延迟并优化活跃控制器数量，仿真结果表明其性能显著优于静态分配方法。

**AI_Comments:** 该论文解决了低轨卫星星座SDN网络中一个关键的动态控制器分配问题，考虑到卫星的快速移动性，这一点非常重要。提出的Opt-DSCA方法不仅关注于降低传播延迟，还兼顾了活跃控制器数量的优化，这对于资源有限的卫星网络具有实际意义。在OMNeT++环境中的仿真验证了其有效性，但初步结果的性质可能意味着需要更深入的性能分析和更大规模的验证。

<details>
  <summary>Details</summary>

**Motivation:** 大型低轨卫星星座中，由于卫星的快速移动性，动态控制器分配是一个重大挑战。为了保持低传播延迟，卫星与控制器之间的分配必须频繁更新。

**Method:** 开发了一个基于OpenFlow协议的低轨卫星网络SDN框架，并在OMNeT++模拟环境中实现。提出了一个动态卫星到控制器分配（DSCA）优化问题，并设计了最优DSCA (Opt-DSCA)方法，以最小化传播延迟并优化活跃控制器数量。

**Result:** 初步结果表明，DSCA方法显著优于静态卫星到控制器分配（SSCA）方法。DSCA通过基于传播延迟动态重新分配卫星，持续提高了网络效率。研究还发现，增加控制器数量超过一定点后回报递减，表明在有限数量控制器下可实现最佳性能。

**Conclusion:** Opt-DSCA通过优化卫星分配和减少活跃控制器数量，有效降低了传播延迟并提高了网络性能。

> **ai_Abstract:** 本文针对低轨卫星星座中SDN网络的动态控制器分配挑战，提出了一个基于OpenFlow的SDN框架，并在OMNeT++中进行了模拟。为解决卫星移动导致的频繁分配更新问题，研究引入了动态卫星到控制器分配（DSCA）优化问题，并开发了Opt-DSCA方法，旨在最小化传播延迟并优化活跃控制器数量。结果表明，DSCA显著优于静态分配，通过动态重分配提高了网络效率，并指出存在一个最佳的控制器数量以实现最佳性能。

> **摘要翻译:** 软件定义网络（SDN）已成为管理传统卫星通信的一种有前景的方法。这增强了未来服务的机会，包括整合卫星和地面网络。在本文中，我们开发了一个支持SDN的低地球轨道（LEO）卫星网络框架，集成了OpenFlow协议，所有这些都在OMNeT++仿真环境中实现。动态控制器分配是大型LEO星座面临的最重要挑战之一。由于LEO卫星的移动，卫星与控制器之间的分配必须频繁更新，以保持较低的传播延迟。为了解决这个问题，我们提出了一个动态卫星到控制器分配（DSCA）优化问题，该问题持续调整这些分配。我们的最优DSCA（Opt-DSCA）方法旨在最小化传播延迟并优化活跃控制器的数量。我们的初步结果表明，DSCA方法显著优于静态卫星到控制器分配（SSCA）方法。虽然SSCA在拥有更多控制器时可能表现更好，但该方案无法适应卫星移动。我们的DSCA方法通过基于传播延迟动态重新分配卫星，持续提高网络效率。此外，我们发现当控制器数量增加到一定程度后，回报会递减，这表明在有限数量的控制器下可以实现最佳性能。Opt-DSCA通过优化卫星分配和减少活跃控制器，降低了传播延迟并提高了网络性能。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [548] [Node Reliability: Approximation, Upper Bounds, and Applications to Network Robustness](https://arxiv.org/abs/2411.07636)
> *节点可靠性：近似、上界及其在网络鲁棒性中的应用*

*Xinhan Liu, Robert Kooij, Piet Van Mieghem* | **Category: eess.SY, cs.SY, math.PR** | **Updated: 2025-07-21**

**Keywords:** 节点可靠性, 蒙特卡洛方法, 随机近似, 网络鲁棒性, 上界

**Comment:** The manuscript is being significantly revised and reorganized based
  on substantial feedback. A thoroughly updated version will be submitted
  through a journal review process

> **TL;DR:** 本文研究了节点可能失效的图的可靠性问题，提出了蒙特卡洛方法、随机近似以及两种基于度分布的上界来计算节点可靠性多项式，并讨论了其在Erdos-Renyi图中的相变，还应用于网络增强问题。

**AI_Comments:** 本文的创新点在于提出了高效的蒙特卡洛和随机近似方法来处理NP-Hard的节点可靠性问题，并引入了新的上界。其重要性体现在为网络鲁棒性分析和网络增强提供了实用的计算工具和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 计算图节点可靠性是一个NP-Hard问题，因此需要开发高效准确的方法来解决此问题。

**Method:** 本文引入了一种高效准确的蒙特卡洛方法和一种基于度分布的节点可靠性多项式随机近似方法。提供了Erdos-Renyi图和随机几何图的节点可靠性多项式公式。提出了两种基于图度分布的越来越精确的节点可靠性多项式上界。此外，还估算了割集数量并提出了基于可靠性的网络增强问题的解决方案。

**Result:** 提出了针对节点可靠性多项式的蒙特卡洛方法和随机近似方法，并给出了Erdos-Renyi图和随机几何图的可靠性多项式公式。讨论了Erdos-Renyi图节点可靠性中的相变。提出了两种新的节点可靠性多项式上界，并进行了比较。估算了割集数量，并提出了网络增强问题的解决方案。

**Conclusion:** 本文为计算图节点可靠性提供了一系列方法，包括高效的近似方法和上界，并将其应用于网络鲁棒性问题，为理解和提升网络可靠性提供了工具。

> **ai_Abstract:** 本文针对节点可能失效的图的可靠性问题，提出了一种高效准确的蒙特卡洛方法和一种基于度分布的随机近似方法来计算节点可靠性多项式。研究了Erdos-Renyi图和随机几何图的可靠性，并讨论了Erdos-Renyi图的相变。此外，提出了两种基于度分布的节点可靠性上界，并将其应用于估算割集数量和解决网络增强问题。

> **摘要翻译:** 本文讨论了图的可靠性，其中链接是完全可靠的，但节点可能以一定概率p失效。计算图节点可靠性是一个NP-Hard问题。我们引入了一种高效准确的蒙特卡洛方法和一种仅基于度分布的节点可靠性多项式随机近似方法。我们提供了Erdos-Renyi图和随机几何图的节点可靠性多项式公式。还讨论了Erdos-Renyi图节点可靠性中的相变。此外，我们提出了两种越来越精确的节点可靠性多项式上界，仅基于图的度分布。详细比较了这两种上界的优缺点。除了计算节点可靠性多项式，我们还估算了割集的数量，并提出了基于可靠性的网络增强问题的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [590] [Integrating and Comparing Radiality Constraints for Optimized Distribution System Reconfiguration](https://arxiv.org/abs/2411.11596)
> *整合与比较用于优化配电系统重构的辐射状约束*

*Pablo Cortes, Alejandra Tabares, Fredy Franco* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 配电系统重构, 辐射状约束, 计算效率, 功率损耗, 优化

**Comment:** 

> **TL;DR:** 本文综合比较了不同辐射状约束公式在配电系统重构中的计算负担，发现不同约束选择显著影响计算效率。

**AI_Comments:** 本文的创新点在于系统性地比较了不同辐射状约束公式的计算效率，填补了该领域的一个空白。其重要性在于为配电系统重构优化提供了实用性的指导，有助于工程师在实际应用中选择更高效的约束策略。局限性可能在于其分析范围仅限于已提出的约束公式，并未提出新的公式。

<details>
  <summary>Details</summary>

**Motivation:** 配电系统重构是一个复杂的优化问题，旨在通过改变系统拓扑来最小化功率损耗。该问题通常被建模为混合整数非线性规划，对于大规模网络需要大量的计算资源，并且需要专门的辐射状约束来维持配电网络的树状结构。本文的动机是分析和比较不同辐射状约束公式所带来的计算负担。

**Method:** 本文整合并比较了专业文献中提出的不同辐射状约束公式，用于配电系统的重构。通过使用一致的硬件和软件设置，在多个知名测试案例中评估了这些约束的性能。

**Result:** 研究结果揭示，计算效率因所选的辐射状约束集而存在显著差异。

**Conclusion:** 本文为优化实际配电网络中的重构策略提供了有价值的见解。

> **ai_Abstract:** 本研究全面分析并比较了配电系统重构中不同辐射状约束公式的计算效率。通过在一致的软硬件环境下对多个标准测试案例进行评估，结果表明，所选的辐射状约束对计算性能有显著影响，为实际配电网络的优化重构提供了重要指导。

> **摘要翻译:** 电气配电系统的重构是一个关键的优化问题，旨在通过操作互连开关改变系统拓扑来最小化功率损耗。该问题通常被建模为混合整数非线性规划，对于大规模网络需要高计算资源，并且需要专门的辐射状约束来维持配电网络的树状结构。本文提出了一项综合分析，整合并比较了专业文献中提出的用于配电系统重构的不同辐射状约束公式所带来的计算负担。通过使用一致的硬件和软件设置，我们在几个知名测试案例中评估了这些约束的性能。我们的研究结果揭示，计算效率因所选的辐射状约束集而存在显著差异，为优化实际配电网络中的重构策略提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [632] [Online Learning of Nonlinear Parametric Models under Non-smooth Regularization using EKF and ADMM](https://arxiv.org/abs/2503.01282)
> *使用EKF和ADMM的非光滑正则化下非线性参数模型的在线学习*

*Lapo Frascati, Alberto Bemporad* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 在线学习, 非线性模型, 非光滑正则化, EKF, ADMM

**Comment:** 12 pages, 5 figures

> **TL;DR:** 论文提出了一种结合EKF和ADMM的新方法，用于在线学习带有l1/l0惩罚和边界约束的非线性参数模型，并在仿真中验证了其有效性和计算效率。

**AI_Comments:** 创新性：创新性地结合了EKF和ADMM，以解决在线非线性模型学习中非光滑正则化的问题。重要性：解决了在实际应用中（如嵌入式控制）对模型参数进行稀疏性或边界约束的挑战，并提供了理论保证和计算效率。局限性：悔值界限仅针对线性时变模型和非光滑凸正则化项给出，对于更普遍的非线性情况可能需要进一步的理论分析。

<details>
  <summary>Details</summary>

**Motivation:** 针对在线学习非线性参数模型时遇到的非光滑正则化项（如l1、l0惩罚和参数边界约束）的挑战，以及对计算效率和嵌入式控制应用中在线模型适应的需求。

**Method:** 提出了一种将扩展卡尔曼滤波（EKF）与交替方向乘子法（ADMM）相结合的新方法，用于在线学习带有非光滑正则化项的参数非线性模型。

**Result:** 对于线性时变模型和非光滑凸正则化项，提供了亚线性悔值界限，确保了在线学习策略的良好行为。该方法对于多种正则化项都具有计算效率。在三个仿真示例中展示了其性能，并证明了其相对于其他批量和在线算法的有效性。

**Conclusion:** 结合EKF和ADMM的方法能够有效地在线学习带有非光滑正则化项的非线性参数模型，具有理论保证和良好的计算效率，适用于嵌入式控制等应用。

> **ai_Abstract:** 本文提出了一种结合扩展卡尔曼滤波（EKF）和交替方向乘子法（ADMM）的新颖方法，用于在线学习受非光滑正则化（如l1/l0惩罚和边界约束）约束的非线性参数模型。该方法对线性时变模型和非光滑凸正则化项提供了亚线性悔值界限，并被证明对多种正则化项具有计算效率，使其适用于嵌入式控制。仿真结果证实了其相对于现有批处理和在线算法的优越性。

> **摘要翻译:** 本文提出了一种将扩展卡尔曼滤波（EKF）与交替方向乘子法（ADMM）相结合的新方法，用于在线学习非光滑正则化项下的参数非线性模型，包括l1和l0惩罚以及模型参数的边界约束。对于线性时变模型和非光滑凸正则化项的情况，我们提供了一个亚线性悔值界限，以确保在线学习策略的良好行为。该方法对于各种正则化项都具有计算效率，这使其在嵌入式控制应用中用于在线模型适应方面具有吸引力。我们在三个仿真示例中展示了所提出方法的性能，突出了其与其他批量和在线算法相比的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [680] [Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach](https://arxiv.org/abs/2504.06439)
> *基于图神经网络的线性网络系统分布式最优控制：一种在线分布式训练方法*

*Zihao Song, Shirantha Welikala, Panos J. Antsaklis, Hai Lin* | **Category: eess.SY, cs.LG, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 图神经网络, 分布式最优控制, 线性网络系统, 在线训练, 自监督学习

**Comment:** 9 pages, 4 figures

> **TL;DR:** 本文提出了一种基于图循环神经网络（GRNN）的分布式最优控制方法，用于离散时间线性网络系统，并实现了在线分布式训练。

**AI_Comments:** 该论文的创新点在于提出了基于GRNN的分布式在线训练方法，以实现线性网络系统的分布式最优控制，解决了现有方法集中式和离线训练的局限性。其将问题转化为自监督学习，并设计了分布式优化器，具有实际应用潜力。对闭环稳定性的分析也增加了理论严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法大多导致集中式最优控制器和离线训练过程，但随着网络弹性的需求增加，最优控制器需要是分布式的，并期望以在线分布式方式进行训练。

**Method:** 首先，提出了一种基于GRNN的分布式最优控制方法，并将其视为一个自监督学习问题。然后，通过分布式梯度计算实现分布式在线训练，并设计了一个受共识分布式优化启发的分布式在线训练优化器。此外，通过假设GRNN控制器的非线性激活函数是局部扇区有界和斜率受限的，提供了所提出方法下线性网络系统的局部闭环稳定性。

**Result:** 通过使用专门开发的模拟器进行数值仿真，证明了所提出方法的有效性。

**Conclusion:** 本文成功提出了基于GRNN的在线分布式最优控制方法，并通过仿真验证了其有效性，并分析了系统的稳定性。

> **ai_Abstract:** 本文提出了一种基于图循环神经网络（GRNN）的分布式最优控制方法，用于解决离散时间线性网络系统的分布式最优控制问题。与现有集中式、离线训练方法不同，该方法通过将问题建模为自监督学习，并利用分布式梯度计算和设计的分布式在线训练优化器，实现了控制器在线分布式训练。研究还分析了GRNN控制器下系统的局部闭环稳定性，并通过数值仿真验证了方法的有效性。

> **摘要翻译:** 本文研究了离散时间线性网络系统的分布式最优控制问题。特别地，我们对使用图循环神经网络（GRNN）学习分布式最优控制器感兴趣。现有的大多数方法都导致集中式最优控制器和离线训练过程。然而，随着网络弹性的需求增加，最优控制器被进一步期望是分布式的，并且最好以在线分布式方式进行训练，这也是我们工作的主要贡献。为了解决这个问题，我们首先提出了一种基于GRNN的分布式最优控制方法，并将该问题视为一个自监督学习问题。然后，通过分布式梯度计算实现分布式在线训练，并受（基于共识的）分布式优化思想的启发，设计了一个分布式在线训练优化器。此外，通过假设基于GRNN控制器的非线性激活函数是局部扇区有界和斜率受限的，提供了我们提出的基于GRNN控制器下线性网络系统的局部闭环稳定性。我们提出的方法的有效性通过使用专门开发的模拟器进行的数值模拟得到了证明。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [732] [Towards provable probabilistic safety for scalable embodied AI systems](https://arxiv.org/abs/2506.05171)
> *可扩展具身AI系统的可证明概率安全性*

*Linxuan He, Qing-Shan Jia, Ang Li, Hongyan Sang, Ling Wang, Jiwen Lu, Tao Zhang, Jie Zhou, Yi Zhang, Yisen Wang, Peng Wei, Zhongyuan Wang, Henry X. Liu, Shuo Feng* | **Category: eess.SY, cs.AI, cs.SY** | **Updated: 2025-07-22**

**Keywords:** 具身AI, 概率安全, 可证明性, 安全关键系统, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出“可证明概率安全”新范式，旨在解决具身AI系统在大规模安全关键应用中部署时的安全挑战。

**AI_Comments:** 这篇“视角”文章提出了一种重要的范式转变，从传统的确定性安全转向更具可行性和可扩展性的概率安全，这对于推动具身AI系统在安全关键领域的实际应用具有重要意义。其创新在于将可证明性与统计方法结合，为大规模部署提供了理论和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 具身AI系统在复杂环境中确保安全仍是重大挑战，阻碍其在自动驾驶、医疗设备等安全关键领域的大规模部署。传统的确定性安全验证方法不切实际，而经验性安全评估缺乏可证明的保障。

**Method:** 提出并论证一种“可证明概率安全”的新范式，该范式将可证明保障与逐步实现整体系统性能的概率安全边界相结合。新范式利用统计方法增强可行性和可扩展性。本文还概述了可证明概率安全的路线图、挑战和潜在解决方案。

**Result:** 未在摘要中提及具体实验结果，但提出了实现可扩展具身AI系统安全部署的范式和路线图。

**Conclusion:** 通过弥合理论安全保障和实际部署之间的差距，本视角文章为具身AI系统在安全关键应用中更安全的大规模采用提供了途径。

> **ai_Abstract:** 本文提出一种“可证明概率安全”的新范式，以应对具身AI系统在复杂环境中大规模部署时的安全挑战。鉴于传统确定性安全方法的不切实际和经验性安全评估的局限性，该范式结合可证明保障和概率安全边界，利用统计方法提高可行性和可扩展性，从而实现具身AI系统在自动驾驶、医疗等安全关键领域的大规模安全部署。文章还概述了实现这一目标的路线图、挑战和解决方案。

> **摘要翻译:** 具身AI系统，由AI模型和物理设备组成，在各种应用中日益普及。由于系统故障的罕见性，在复杂操作环境中确保其安全仍然是一项重大挑战，这严重阻碍了它们在自动驾驶汽车、医疗设备和机器人等安全关键领域的大规模部署。虽然实现可证明的确定性安全——在所有可能场景中验证系统安全——在理论上是理想的，但极端情况的罕见性和复杂性使得这种方法对于可扩展的具身AI系统来说不切实际。相反，经验性安全评估被用作替代方案，但缺乏可证明的保证带来了显著的局限性。为了解决这些问题，我们主张向可证明概率安全范式转变，该范式将可证明保证与在整体系统性能上逐步实现概率安全边界相结合。新范式更好地利用统计方法来增强可行性和可扩展性，并且明确定义的概率安全边界使得具身AI系统能够大规模部署。在这篇视角文章中，我们概述了可证明概率安全的路线图，以及相应的挑战和潜在解决方案。通过弥合理论安全保障和实际部署之间的差距，这篇视角文章为具身AI系统在安全关键应用中更安全的大规模采用提供了途径。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [72] [How Many Simultaneous Beamformers are Needed for Integrated Sensing and Communications?](https://arxiv.org/abs/2507.14982)
> *集成感知与通信需要多少个同步波束赋形器？*

*Kareem M. Attiah, Wei Yu* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 集成感知与通信, 波束赋形, Cramér-Rao界限, 资源分配, 干扰消除

**Comment:** 26 pages, 7 figures

> **TL;DR:** 论文确定了集成感知与通信系统中实现最佳性能所需的最小波束赋形器数量的界限，并考虑了干扰消除的不同情况。

**AI_Comments:** 这篇论文通过量化分析，为集成感知与通信系统的设计提供了重要的理论指导，特别是在资源（波束赋形器数量）优化方面。其创新之处在于考虑了干扰消除能力对波束赋形器数量需求的影响，并揭示了集成系统在某些情况下可能比独立系统更高效的潜在优势。这对于未来ISAC系统的实际部署具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在确定在下行链路集成感知与通信 (ISAC) 系统中，基站同时执行通信和感知任务时，需要多少个波束赋形器才能实现最佳的感知和通信性能。

**Method:** 本文通过建立下行链路最小波束赋形器数量的界限来解决问题。感知性能通过参数估计的Cramér-Rao界限衡量，通信性能通过信干噪比衡量。

**Result:** 1. 如果远程用户能够消除感知波束引起的干扰，ISAC系统最多需要 $K + \sqrt{\frac{L(L+1)}{2}}$ 个波束赋形器。
2. 如果不能消除感知波束引起的干扰，界限变为 $\sqrt{K^2 + \frac{L(L+1)}{2}}$。在这种情况下，波束赋形器数量的界限小于单独执行每个任务的界限之和。
3. 对于性能由波束赋形器中 $d$ 个二次项衡量的感知任务，界限分别为 $K + \sqrt{d}$ 和 $\sqrt{K^2 + d}$。
4. 在通信 $K$ 个用户同时估计 $N_\text{tr}$ 个目标的复路径损耗和到达角时，如果感知干扰可以消除，所需波束赋形器数量与 $K$ 和 $N_\text{tr}$ 呈线性关系。
5. 当无法消除干扰时，对于 $N_\text{tr} = 1$ 的情况，当 $K=0$ 或 $1$ 时，应使用两个波束赋形器；当 $K \ge 2$ 时，只需使用 $K$ 个波束赋形器（即仅通信波束赋形器就足够了）。

**Conclusion:** 论文为集成感知与通信系统中的波束赋形器数量提供了具体的界限，揭示了在不同干扰消除能力下，所需波束赋形器数量的差异，特别指出在某些情况下，集成系统所需的波束赋形器数量可能少于单独任务的总和。

> **ai_Abstract:** 本文研究了下行链路集成感知与通信（ISAC）系统中实现最佳感知和通信性能所需的最小波束赋形器数量。通过衡量Cramér-Rao界限和信干噪比，论文建立了在有无感知干扰消除情况下的波束赋形器数量界限。结果表明，在干扰可消除时，界限为 $K + \sqrt{\frac{L(L+1)}{2}}$；不可消除时为 $\sqrt{K^2 + \frac{L(L+1)}{2}}$，且后者可能小于各任务单独所需的总和。研究还扩展到更一般的感知任务，并为特定场景提供了精确分析。

> **摘要翻译:** 考虑一个下行链路集成感知与通信（ISAC）系统，其中基站采用线性波束赋形与 $K$ 个用户通信，同时使用感知波束执行估计 $L$ 个实参数的感知任务。需要多少个波束赋形器才能实现感知和通信的最佳性能？本文建立了下行链路最小波束赋形器数量的界限，其中感知性能以参数估计的Cramér-Rao界限衡量，通信性能以信干噪比衡量。我们表明，如果远程用户能够消除感知波束引起的干扰，ISAC系统最多需要 $K + \sqrt{\frac{L(L+1)}{2}}$ 个波束赋形器。如果无法消除感知波束引起的干扰，界限变为 $\sqrt{K^2 + \frac{L(L+1)}{2}}$。有趣的是，在后一种情况下，波束赋形器数量的界限小于单独执行每个任务的界限之和。这些结果可以扩展到感知性能以波束赋形器中 $d$ 个二次项函数衡量的感知任务。在这种情况下，界限分别变为 $K + \sqrt{d}$ 和 $\sqrt{K^2 + d}$。具体而言，对于在与 $K$ 个用户通信的同时估计 $N_\text{tr}$ 个目标的复路径损耗和到达角的情况，假设感知干扰可以消除，最小波束赋形器数量的界限与 $K$ 和 $N_\text{tr}$ 呈线性关系。当无法消除干扰时，对于 $N_\text{tr} = 1$ 的情况，可以得到以下精确的表征：当 $K=0$ 或 $1$ 时，应使用两个波束赋形器；当 $K \ge 2$ 时，应精确使用 $K$ 个波束赋形器，即仅通信波束赋形器就已足够。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [163] [MSGM: A Multi-Scale Spatiotemporal Graph Mamba for EEG Emotion Recognition](https://arxiv.org/abs/2507.15914)
> *MSGM：一种用于脑电图情感识别的多尺度时空图Mamba模型*

*Hanwen Liu, Yifeng Gong, Zuwei Yan, Zeheng Zhuang, Jiaxuan Lu* | **Category: eess.SP, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 脑电图情感识别, 多尺度时空图, Mamba, 深度学习, 时空动态

**Comment:** 

> **TL;DR:** MSGM是一种新型的脑电图情感识别框架，通过结合多尺度时空图建模和Mamba架构，有效捕捉复杂的脑电动态，并在情感分类任务中超越现有方法，同时保持高计算效率。

**AI_Comments:** 本文的创新点在于将Mamba架构引入到脑电图情感识别领域，并结合多尺度时空图建模，有效解决了传统方法在捕捉复杂动态和计算效率方面的不足。其线性复杂度的动态时空交互能力以及在多个数据集上的卓越表现，显示了该模型在实时情感识别应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基于脑电图（EEG）的情感识别在捕捉多尺度时空动态和确保实时应用计算效率方面面临挑战。现有方法常过度简化时间粒度和空间层级，从而限制了识别准确性。

**Method:** 本文提出了多尺度时空图Mamba（MSGM）框架，该框架整合了多窗口时间分割、双模态空间图建模，并通过Mamba架构进行高效融合。MSGM通过在不同时间尺度上分割脑电信号，并利用神经解剖学先验构建全局-局部图，以捕捉细粒度情感波动和分层大脑连接。它结合了多深度图卷积网络（GCN）和token嵌入融合模块，并与Mamba的状态空间建模相结合，以实现线性复杂度的动态时空交互。

**Result:** MSGM仅用一个MSST-Mamba层就在SEED、THU-EP和FACED数据集上超越了该领域的领先方法，在独立于受试者的情感分类中表现优于基线，并在NVIDIA Jetson Xavier NX上实现了鲁棒的准确性和毫秒级的推理速度。

**Conclusion:** MSGM通过有效地捕捉脑电信号的多尺度时空动态并提供高效的计算，显著提升了基于脑电图的情感识别性能，证明了其在实际应用中的潜力和优越性。

> **ai_Abstract:** 本文提出了一种名为多尺度时空图Mamba（MSGM）的新型框架，旨在解决基于脑电图（EEG）情感识别中捕捉多尺度时空动态和计算效率的难题。MSGM通过整合多窗口时间分割、基于神经解剖学先验的双模态空间图建模以及Mamba架构进行高效融合。该模型能够有效捕捉细粒度情感波动和分层大脑连接，并利用GCN和Mamba实现线性复杂度的动态时空交互。实验结果表明，MSGM在多个公开数据集上表现优于现有领先方法，并在独立于受试者的情感分类任务中实现了高准确性和毫秒级推理速度。

> **摘要翻译:** 基于脑电图（EEG）的情感识别在捕捉多尺度时空动态和确保实时应用计算效率方面面临挑战。现有方法常过度简化时间粒度和空间层级，从而限制了准确性。为了克服这些挑战，我们提出了一种新颖的多尺度时空图Mamba（MSGM）框架，它整合了多窗口时间分割、双模态空间图建模，并通过Mamba架构进行高效融合。通过在不同时间尺度上分割脑电信号，并利用神经解剖学先验构建全局-局部图，MSGM有效地捕捉了细粒度情感波动和分层大脑连接。一个多深度图卷积网络（GCN）和token嵌入融合模块，与Mamba的状态空间建模相结合，能够以线性复杂度实现动态时空交互。值得注意的是，MSGM仅用一个MSST-Mamba层就在SEED、THU-EP和FACED数据集上超越了该领域的领先方法，在独立于受试者的情感分类中表现优于基线，同时在NVIDIA Jetson Xavier NX上实现了鲁棒的准确性和毫秒级的推理速度。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [178] [Modeling and Analysis of Land-to-Ship Maritime Wireless Channels at 5.8 GHz](https://arxiv.org/abs/2507.15969)
> *5.8 GHz陆海船间海上无线信道建模与分析*

*Shu Sun, Yulu Guo, Meixia Tao, Wei Feng, Jun Chen, Ruifeng Gao, Ye Li, Jue Wang, Theodore S. Rappaport* | **Category: eess.SP** | **Updated: 2025-07-21**

**Keywords:** 海上信道, 5.8 GHz, 路径损耗, SWIFT衰落, 小尺度衰落

**Comment:** 

> **TL;DR:** 该研究基于广泛的测量活动，对5.8 GHz陆海船间海上无线信道特性进行了建模和分析，提出了新的路径损耗模型和SWIFT衰落概念，并研究了小尺度衰落、信道稀疏性及时间色散，为海上无线系统设计提供了见解。

**AI_Comments:** 该论文通过结合实际测量数据和理论建模，深入研究了陆海船间无线信道特性，具有较高的实用价值。特别是在动态海洋环境下提出新型路径损耗模型和SWIFT衰落概念，对理解和模拟复杂的海上信道提供了新视角。其对小尺度衰落的分析以及信道稀疏性和时间色散的表征，也为未来海上无线通信系统的优化设计奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 海上信道建模对于设计在受海浪和风等因素影响的海洋环境中鲁棒的通信系统至关重要。

**Method:** 该研究基于广泛的测量活动，并收集了水文和气象信息。提出了一个具有物理基础和高精度的新型大尺度路径损耗模型。引入了海浪引起的定点（SWIFT）衰落概念，并提出了一个结合船舶旋转运动的增强型双径模型来模拟SWIFT衰落。通过使用包括双波扩散功率（TWDP）和非对称拉普拉斯分布在内的多种模型研究了小尺度衰落。此外，还通过基尼系数和Rician $K$因子检查了海上信道稀疏性，并表征了时间色散。

**Result:** 提出了一个新颖的、高精度的大尺度路径损耗模型。引入了海浪引起的定点（SWIFT）衰落概念。增强型双径模型在模拟SWIFT衰落方面与测量数据吻合良好，尤其是在天线运动适度的情况下。非对称拉普拉斯分布在大多数情况下对小尺度衰落表现良好，而TWDP在恶劣海况下能更好地捕捉双峰衰落。研究了海上信道稀疏性，并表征了时间色散。

**Conclusion:** 研究产生的信道模型和参数特性为海上无线系统设计和部署提供了有价值的见解。

> **ai_Abstract:** 该研究旨在为海上通信系统提供关键的信道模型。通过在5.8 GHz频段进行广泛的陆海船间测量，提出了一种新的大尺度路径损耗模型。文章还引入了海浪引起的定点（SWIFT）衰落的概念，并开发了一个考虑船舶旋转运动的增强型双径模型来模拟此现象。此外，论文还深入分析了小尺度衰落，并通过多种分布模型进行了验证。最后，研究了信道稀疏性和时间色散，为海上无线系统设计与部署提供了宝贵的指导。

> **摘要翻译:** 海上信道建模对于在受海浪和风等因素影响的海洋环境中设计鲁棒的通信系统至关重要。本文基于广泛的测量活动，并同时收集水文和气象信息，研究了5.8 GHz陆海船间海上无线信道特性。首先，针对动态海洋环境提出了一种具有物理基础和高精度的新型大尺度路径损耗模型。然后，我们引入了海浪引起的定点（SWIFT）衰落概念，这是海上场景中一种独特的现象，它捕捉了海面波动对接收功率的影响。提出了一个结合船舶旋转运动的增强型双径模型来模拟SWIFT衰落，该模型与测量数据显示出良好的一致性，特别是对于适度的天线运动。接下来，通过利用包括双波扩散功率（TWDP）和非对称拉普拉斯分布在内的多种模型研究了小尺度衰落，其中后者在大多数情况下表现良好，而TWDP在恶劣海况下能更好地捕捉双峰衰落。此外，通过基尼系数和Rician $K$因子检查了海上信道稀疏性，并表征了时间色散。由此产生的信道模型和参数特性为海上无线系统设计和部署提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [203] [Meta-Reinforcement Learning Optimization for Movable Antenna-aided Full-Duplex CF-DFRC Systems with Carrier Frequency Offset](https://arxiv.org/abs/2507.16132)
> *基于可移动天线辅助的全双工CF-DFRC系统载波频率偏移的元强化学习优化*

*Yue Xiu, Wanting Lyu, You Li, Ran Yang, Phee Lep Yeoh, Wei Zhang, Guangyi Liu, Ning Wei* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 元强化学习, 可移动天线, CF-DFRC, 载波频率偏移, 频谱效率

**Comment:** 

> **TL;DR:** 本文提出一种基于元强化学习的两阶段交替优化策略，以解决可移动天线辅助的全双工CF-DFRC系统在载波频率偏移下的通信和传感性能问题。

**AI_Comments:** 该论文创新性地将可移动天线引入到CF-DFRC系统中，以解决宽带场景下CFO带来的挑战。采用元强化学习结合两阶段优化策略，有效处理了非凸问题，并展示了相对于传统方法的显著性能提升，为6G网络中雷达通信一体化提供了新的思路和技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 在宽带场景中，载波频率偏移（CFO）引起的同步误差会严重降低通信容量和传感精度，这对于未来6G无线网络中旨在提高频谱效率的蜂窝自由双功能雷达通信（CF-DFRC）系统是一个挑战。

**Method:** 本文将可移动天线（MAs）集成到CF-DFRC框架中，利用其空间灵活性和自适应波束成形来动态减轻CFO引起的损伤。为最大化通信和传感的最坏情况和速率，论文提出一种鲁棒的基于元强化学习（MRL）的两阶段交替优化策略。第一阶段采用流形优化（MO）与惩罚对偶分解（PDD）解决CFO鲁棒最坏情况子问题；第二阶段采用数据驱动方式联合优化MA位置和波束成形向量。

**Result:** 仿真结果表明，所提出的MRL方法在CFO损伤下，通信和传感性能显著优于传统的深度强化学习（DRL）方案。此外，与固定位置天线（FPAs）相比，MA辅助的CF-DFRC系统表现出更好的性能。

**Conclusion:** 可移动天线辅助的CF-DFRC系统结合元强化学习优化，能够有效缓解载波频率偏移带来的性能下降，并在通信和传感方面取得显著提升。

> **ai_Abstract:** 本文针对宽带场景下CF-DFRC系统因载波频率偏移（CFO）导致的通信和传感性能下降问题，提出了一种基于可移动天线（MAs）的解决方案。通过集成MAs并利用其空间灵活性，论文旨在联合优化MA位置、波束成形和CFO参数以最大化最坏情况和速率。为此，提出了一种鲁棒的元强化学习（MRL）两阶段交替优化策略，结合流形优化、惩罚对偶分解和数据驱动优化。仿真结果验证了该MRL方法在CFO影响下，通信和传感性能优于传统DRL，且MA辅助系统优于固定位置天线系统。

> **摘要翻译:** 通过实现雷达和通信操作之间的频谱共享，无蜂窝双功能雷达通信（CF-DFRC）系统是未来第六代（6G）无线网络中显著提高频谱效率的有前景的候选方案。然而，在宽带场景中，由载波频率偏移（CFO）引起的同步误差会严重降低通信容量和传感精度。为了应对这一挑战，本文将可移动天线（MAs）集成到CF-DFRC框架中，利用其空间灵活性和自适应波束成形来动态减轻CFO引起的损伤。为了在存在CFO的宽带场景中充分发挥MA的优势，我们旨在通过联合优化MA位置、波束成形和CFO参数，在发射功率和MA定位约束下，最大化通信和传感的最坏情况和速率。由于问题的非凸性质，我们提出了一种鲁棒的基于元强化学习（MRL）的两阶段交替优化策略。在第一阶段，我们采用流形优化（MO）结合惩罚对偶分解（PDD）来解决CFO鲁棒最坏情况子问题。在第二阶段，我们采用数据驱动的方式联合优化动态无线环境中的MA位置和波束成形向量。仿真结果表明，所提出的MRL方法在CFO损伤下，通信和传感性能显著优于传统的深度强化学习（DRL）方案。此外，与固定位置天线（FPAs）相比，MA辅助的CF-DFRC系统表现出

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [228] [Joint Active and Passive Beamforming for Energy-Efficient STARS with Quantization and Element Selection in ISAC Systems](https://arxiv.org/abs/2507.16210)
> *ISAC系统中用于节能STARS的联合主动和被动波束成形，包含量化和单元选择*

*Li-Hsiang Shen, Yi-Hsuan Chiu* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** STARS, ISAC, 能量效率, 波束成形, 量化

**Comment:** 

> **TL;DR:** 本文提出了一种用于STARS辅助ISAC系统的AQUES方案，通过联合优化波束成形、量化和单元选择来最大化能量效率，并显著提升了EE。

**AI_Comments:** 该论文的创新之处在于为STARS辅助的ISAC系统提出了一个全面的联合优化方案（AQUES），解决了主动和被动波束成形、量化和单元选择之间复杂的相互作用。对不同STARS架构（松弛/独立/耦合）的考虑增加了实际相关性。利用多种高级优化技术来解决非凸、混合整数问题是其一大优势。其重要性在于提高了未来ISAC系统的能量效率，这对于可持续无线通信至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为STARS辅助的集成感知与通信（ISAC）系统实现全空间节能数据传输和目标感知，通过联合优化多项参数来最大化能量效率。

**Method:** 论文提出了一个能量效率（EE）最大化问题，该问题是非凸和混合整数的。为解决此问题，提出了一种基于交替优化的联合主动-被动波束成形、量化和单元选择（AQUES）方案。该方案采用拉格朗日对偶和Dinkelbach变换处理分数，逐次凸近似（SCA）进行凸化，罚对偶分解（PDD）框架和基于罚的凸凹规划（PCCP）过程求解幅度和相移，启发式搜索决定量化级别，以及整数松弛处理单元选择。同时考虑了松弛/独立/耦合的STARS架构。

**Result:** 仿真结果表明，所提出的AQUES方案显著提高了STARS-ISAC系统的能量效率（EE），同时满足了通信速率和感知质量要求。耦合STARS由于硬件复杂性降低，其EE性能优于独立和松弛STARS。此外，AQUES在各种网络参数和部署场景下均优于现有配置和基准方法。

**Conclusion:** 所提出的AQUES方案能有效最大化STARS辅助ISAC系统的能量效率，其中耦合STARS表现出最佳性能，并且总体上优于现有方法。

> **ai_Abstract:** 本文旨在最大化STARS辅助集成感知与通信（ISAC）系统的能量效率。论文提出了一个非凸、混合整数的优化问题，联合优化基站的主动-被动波束成形以及STARS的配置（包括幅度、相移、量化和单元选择）。为解决此问题，提出了一种新颖的基于交替优化的AQUES方案，该方案整合了拉格朗日对偶、SCA、PDD、PCCP、启发式搜索和整数松弛等技术。仿真结果表明，AQUES显著提升了能量效率，满足了通信和感知要求，并优于现有方法，其中耦合STARS配置因硬件复杂性降低而表现出卓越性能。

> **摘要翻译:** 本文研究了一种同时传输和反射可重构智能表面（STARS）辅助的集成感知与通信（ISAC）系统，以支持全空间节能数据传输和目标感知。我们提出一个能量效率（EE）最大化问题，联合优化双功能雷达-通信（DFRC）赋能的基站（BS）ISAC波束成形以及STARS的幅度、相移、量化级别和单元选择配置。此外，还考虑了松弛/独立/耦合的STARS，以检验架构灵活性。为了解决非凸和混合整数问题，我们提出了一种基于交替优化的联合主动-被动波束成形、量化和单元选择（AQUES）方案：拉格朗日对偶和Dinkelbach变换处理分数问题，而逐次凸近似（SCA）使问题凸化；罚对偶分解（PDD）框架和基于罚的凸凹规划（PCCP）过程求解幅度和相移；启发式搜索决定量化级别；整数松弛处理单元选择。仿真结果表明，采用所提出的AQUES方案的STARS-ISAC显著提高了EE，同时满足了通信速率和感知质量要求。耦合STARS由于其硬件复杂性降低，进一步突显了其优于独立和松弛STARS的EE性能。此外，在各种网络参数和部署场景下，AQUES优于现有配置和公开文献中的基准方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [259] [Liquid Intelligent Metasurface for Fluid Antennas-Assisted Networks](https://arxiv.org/abs/2507.16211)
> *液体智能超表面用于流体天线辅助网络*

*Li-Hsiang Shen* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 液体智能超表面, 流体天线, 空间重构, 和速率最大化, 非凸优化

**Comment:** 

> **TL;DR:** 本文提出一种基于液体智能超表面和流体天线的MISO系统，通过联合优化电磁和空间位置，显著提升系统性能。

**AI_Comments:** 这篇论文的创新点在于引入了“液体智能超表面”和“流体天线”的概念，实现了电磁和空间层面的联合动态可重构性，这与传统固定几何结构的超表面系统形成鲜明对比。这种设计为无线通信系统提供了更高的灵活性和性能潜力。解决非凸优化问题的方法也显示了扎实的数学功底。其重要性在于为未来可重构智能表面和天线技术提供了新的思路，有望在6G及未来通信中发挥关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统可重构超表面系统几何结构固定，限制了其性能。本文旨在通过引入流体天线和液体元素，实现电磁和空间联合重构，以克服这一限制并提升系统和网络性能。

**Method:** 本文提出了一种新型液体智能超表面 (LIM) 辅助的下行多用户多输入单输出 (MISO) 系统。该系统特点在于基站 (BS) 和超表面分别配备流体天线 (FA) 和液体元素，使其除了波束成形和相移控制外，还能动态调整小尺度位置，从而实现电磁和空间联合重构。研究人员将问题建模为联合优化BS波束成形、LIM相移以及流体天线和液体元素位置的和速率最大化问题。针对该高度非凸问题，论文采用交替优化、引入辅助变量、逐次凸逼近 (SCA) 以及惩罚凸凹过程 (PCCP) 等方法来解决。

**Result:** 仿真结果表明，所提出的FAS-LIM架构在各种参数设置下，性能显著优于采用传统固定超表面和固定天线阵列的基准方法。

**Conclusion:** 提出的液体智能超表面和流体天线辅助网络架构，通过实现电磁和空间联合重构，能有效提升无线通信系统的性能，优于现有固定配置的系统。

> **ai_Abstract:** 本文提出了一种创新的液体智能超表面（LIM）辅助的MISO系统，该系统结合了流体天线（FA）和液体元素，实现了电磁和空间位置的动态联合可重构性。与传统固定几何结构不同，该架构通过联合优化基站波束成形、LIM相移以及天线和元素的位置，旨在最大化系统和速率。针对所提出的非凸优化问题，研究人员采用了交替优化、逐次凸逼近和惩罚凸凹过程等技术进行求解。仿真结果验证了该FAS-LIM架构在性能上显著优于现有固定超表面和天线阵列的基准方案。

> **摘要翻译:** 本文提出了一种新型液体智能超表面（LIM）辅助的下行多用户多输入单输出（MISO）系统，其中基站（BS）和超表面分别配备流体天线（FA）和液体元素。与传统采用静态几何结构的可重构超表面辅助系统不同，所提出的架构通过允许流体天线赋能的基站（FAS）和LIM除了进行波束成形和相移控制外，还能动态调整其小尺度位置，从而实现电磁和空间联合重构。我们建立了一个和速率最大化问题，该问题联合优化了BS波束成形、LIM相移以及流体天线和液体元素的位置。由于变量之间的耦合、分数表达式、单位模量约束以及空间相关函数，该问题具有高度非凸性。为了解决这些挑战，我们采用交替优化方法，引入辅助变量，并利用逐次凸逼近（SCA）以及惩罚凸凹过程（PCCP）来解决各自的子问题。仿真结果表明，所提出的FAS-LIM架构在各种参数设置下，性能显著优于采用传统固定超表面和固定天线阵列的基准方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [283] [Latency Minimization Oriented Radio and Computation Resource Allocations for 6G V2X Networks with ISCC](https://arxiv.org/abs/2507.16375)
> *面向6G V2X网络中ISCC的低延迟无线电和计算资源分配*

*Peng Liu, Xinyi Wang, Zesong Fei, Yuan Wu, Jie Xu, Arumugam Nallanathan* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 6G V2X, ISCC, 资源分配, 延迟最小化, 交替优化

**Comment:** 15 pages, 13 figures

> **TL;DR:** 本文研究了6G V2X网络中集成传感、通信和计算(ISCC)的资源分配问题，旨在公平地最小化车辆的感知完成延迟，并提出了一种交替优化算法来解决复杂的资源分配问题，仿真结果表明该方法能显著降低延迟。

**AI_Comments:** 本文的创新点在于将ISCC技术应用于6G V2X网络，并首次尝试联合优化无线电和计算资源以实现公平的延迟最小化。其提出的交替优化算法有效地解决了复杂的MINLP问题，为未来V2X系统的资源管理提供了实用的解决方案。该研究的重要性体现在其对6G V2X通信中集成服务（传感、通信、计算）的实际应用探索，为低延迟、高可靠的车联网奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 6G网络中集成传感、通信和计算（ISCC）技术在车联网（V2X）应用中具有巨大潜力，车辆需要同时进行环境感知并将数据卸载到路边基站进行处理。然而，如何有效分配无线电和计算资源以公平地最小化感知完成延迟，同时保证检测概率约束是一个挑战。

**Method:** 提出了一种交替优化算法来解决所建立的复杂混合整数非线性规划（MINLP）问题。该算法具体包括：通过分支定界法确定子带分配；通过逐次凸逼近（SCA）优化发射功率控制；基于广义瑞利熵和公平性准则，以闭合形式推导基站的接收波束成形和计算资源分配。

**Result:** 仿真结果表明，所提出的联合资源分配设计显著降低了所有车辆的最大任务完成延迟。此外，还展示了系统性能与资源利用率之间的多项权衡关系。

**Conclusion:** 本文成功地提出了一个面向6G V2X网络中ISCC的联合无线电和计算资源分配方案，有效解决了车辆感知完成延迟最小化的问题，并为未来的V2X系统设计提供了有价值的见解。

> **ai_Abstract:** 本文研究了6G V2X网络中ISCC（集成传感、通信和计算）场景下的无线电和计算资源联合分配问题。目标是在保证检测概率的前提下，公平地最小化车辆的感知完成延迟。为此，作者提出了一个复杂的混合整数非线性规划问题，并设计了一种交替优化算法，该算法结合了分支定界法、逐次凸逼近以及闭合形式的推导来优化子带、发射功率、接收波束成形和计算资源。仿真结果验证了该方案能有效降低车辆的最大任务完成延迟，并揭示了性能与资源利用率之间的权衡。

> **摘要翻译:** 将移动边缘计算（MEC）和集成传感与通信（ISAC）相结合已成为一种有前景的技术，可以在第六代（6G）网络中实现集成传感、通信和计算（ISCC）。ISCC对于车联网（V2X）应用尤其有吸引力，其中车辆执行ISAC以感知环境并同时将感知数据卸载到路边基站（BS）进行远程处理。在本文中，我们研究了一个特定的支持ISCC的V2X系统，该系统由多个多天线基站服务一组单天线车辆，其中车辆在正交子带上执行各自的ISAC操作（用于同时感知和卸载到相关联的基站）。我们专注于公平地最小化车辆的感知完成延迟，同时确保检测概率约束，联合优化了无线电资源（即子带分配、车辆的发射功率控制和基站的接收波束成形）以及基站MEC服务器的计算资源分配。为了解决所建立的复杂混合整数非线性规划（MINLP）问题，我们提出了一种交替优化算法。在该算法中，我们通过分支定界法确定子带分配，通过逐次凸逼近（SCA）优化发射功率控制，并分别基于广义瑞利熵和公平性准则以闭合形式推导基站的接收波束成形和计算资源分配。仿真结果表明，所提出的联合资源分配设计显著降低了所有车辆的最大任务完成延迟。此外，我们还展示了系统性能与资源利用率之间的多项有趣的权衡关系。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [313] [Hybrid RISs for Simultaneous Tunable Reflections and Sensing](https://arxiv.org/abs/2507.16550)
> *用于同时可调反射和感知的混合RIS*

*George C. Alexandropoulos, Nir Shlezinger, Ioannis Gavras, Haiyang Zhang* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 混合RIS, 可重构智能表面, 传感, 信道估计, 同时通信和传感

**Comment:** 

> **TL;DR:** 传统RIS仅能反射，导致网络管理困难。混合RIS（HRIS）能同时反射和感知，从而实现更好的信道估计和自主操作。

**AI_Comments:** HRIS通过集成传感能力，解决了RIS赋能网络中信道估计和网络编排的关键挑战，代表了对传统RIS的重大改进。这种双重功能能够实现更自主和高效的无线环境。

<details>
  <summary>Details</summary>

**Motivation:** 典型的可重构智能表面（RIS）实现仅能反射入射波，这给无线网络的RIS编排（例如信道估计）带来了重大挑战，而信道估计对于相干RIS赋能的无线通信至关重要。

**Method:** 本章回顾了混合反射和传感RIS（HRIS）的新兴概念，介绍了HRIS的实现细节，提出了表征其双重功能的数学模型，并讨论了HRIS在同时通信和传感以及多用户HRIS赋能通信系统上行链路中估计单个信道方面的两个应用。

**Result:** 性能评估结果验证了HRIS在传感以及集成传感和通信方面的作用。

**Conclusion:** HRIS的传感能力促进了各种网络管理功能，包括信道参数估计和定位，并催生了计算自主和自配置的RIS。

> **ai_Abstract:** 本文回顾了混合反射和传感RIS（HRIS），它通过同时实现反射和传感来克服传统纯反射RIS的局限性。HRIS促进了信道估计和定位等关键网络管理功能，从而实现自主和自配置系统。该章节介绍了HRIS的实现细节、数学模型，并讨论了它们在同时通信和传感以及上行链路信道估计中的应用，其性能评估验证了其双重功能。

> **摘要翻译:** “智能无线环境”的概念设想通过部署可重构智能表面（RIS）来动态编程信息承载信号的传播。典型的RIS实现包括具有无源单元元件的超表面，能够以可控方式反射入射波。然而，这种单纯的反射操作给无线网络的RIS编排带来了重大挑战。例如，对于相干RIS赋能的无线通信至关重要的信道估计，在现有的单纯反射RIS设计下是相当具有挑战性的。本章回顾了新兴的混合反射和传感RIS（HRIS）概念，它使超表面能够以可控方式反射入射信号，同时感知其中一部分。HRIS的传感能力促进了各种网络管理功能，包括信道参数估计和定位，同时，最重要的是，催生了计算自主和自配置的RIS。首先介绍了HRIS的实现细节，然后是用于表征其双重功能的便捷数学模型。然后，讨论了HRIS的两个指示性应用，一个用于同时通信和传感，另一个展示了它们在多用户HRIS赋能通信系统上行链路中估计单个信道的有用性。对于这两个应用，都包含了性能评估结果，验证了HRIS在传感以及集成传感和通信方面的作用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [344] [Generative Diffusion Models for Wireless Networks: Fundamental, Architecture, and State-of-the-Art](https://arxiv.org/abs/2507.16733)
> *无线网络中的生成扩散模型：基础、架构与最新进展*

*Dayu Fan, Rui Meng, Xiaodong Xu, Yiming Liu, Guoshun Nan, Chenyuan Feng, Shujun Han, Song Gao, Bingxuan Xu, Dusit Niyato, Tony Q. S. Quek, Ping Zhang* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 生成扩散模型, 无线网络, 生成式AI, 综述, 架构

**Comment:** 30 pages, 11 figures

> **TL;DR:** 本文对无线网络中生成扩散模型的应用进行了系统性综述，分析了其技术优势、提出了多层网络架构，并回顾了现有方案，指出了未来研究挑战与方向。

**AI_Comments:** 本文作为一篇综述性文章，系统地梳理了生成扩散模型在无线网络领域的应用，填补了现有研究中缺乏全面技术演进回顾的空白。其创新之处在于提出了一个多层无线网络架构，并深入分析了GDMs在各层的作用，这对于理解和未来设计基于GDM的无线网络系统具有重要意义。文章对现有方案的详细审查和对未来挑战与解决方案的展望，为该领域的研究者提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已有许多关于无线网络中生成扩散模型的研究，但目前仍缺乏对其技术演进的全面综述。

**Method:** 本文系统性地探讨了生成扩散模型在无线网络中的应用。首先，从数学原理分析了生成扩散模型的技术优势并介绍了六种代表性模型。其次，提出了包含感知层、传输层、应用层和安全平面的多层无线网络架构，并阐述了生成扩散模型在各层中的核心机制。随后，对现有基于生成扩散模型的方案进行了严格审查，分析了其创新点、作用、优缺点。最后，提取了关键挑战并提供了潜在解决方案。

**Result:** 本文分析了生成扩散模型的技术优势，介绍了六种代表性模型；提出了多层无线网络架构；对现有基于生成扩散模型的方案进行了全面审查，分析了其创新点、作用、优缺点；并提取了关键挑战和潜在解决方案。

**Conclusion:** 本文旨在为无线网络中生成扩散模型的未来研究提供方向性指导，通过提出关键挑战和解决方案，促进该领域的发展。

> **ai_Abstract:** 本综述系统地探讨了生成扩散模型（GDMs）在无线网络中的应用。文章首先从数学原理分析了GDMs的技术优势并介绍了代表性模型。接着，提出了一个多层无线网络架构（包括感知层、传输层、应用层和安全平面），并阐述了GDMs在各层中的核心机制。随后，对现有基于GDMs的方案进行了深入审查，分析了其创新点、作用、优缺点。最后，文章总结了关键挑战并提出了潜在解决方案，旨在为未来研究提供指导。

> **摘要翻译:** 随着生成式人工智能（GAI）技术的快速发展，生成扩散模型（GDMs）凭借其抗噪声、训练稳定性、可控性和多模态生成等优势，在无线网络领域展现出显著的赋能潜力。尽管目前已有许多关于无线网络中生成扩散模型的研究，但仍缺乏对其技术演进的全面综述。受此启发，本文系统性地探讨了生成扩散模型在无线网络中的应用。首先，从数学原理出发，分析了生成扩散模型的技术优势，并介绍了六种代表性模型。此外，我们提出了包含感知层、传输层、应用层和安全平面的多层无线网络架构，并阐述了生成扩散模型在各层中的核心机制。随后，我们对现有基于生成扩散模型的方案进行了严格审查，重点分析了它们的创新点、生成扩散模型的作用、优点和缺点。最终，我们提取了关键挑战并提供了潜在解决方案，旨在为该领域的未来研究提供方向性指导。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [470] [AsyMov: Integrated Sensing and Communications with Asynchronous Moving Devices](https://arxiv.org/abs/2412.10387)
> *AsyMov: 集成传感与通信与异步移动设备*

*Gianmaria Ventura, Michele Rossi, Jacopo Pegoraro* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 多普勒频移, 集成传感与通信 (ISAC), 异步设备, 移动目标, 交替最小化

**Comment:** 13 pages, 12 figures, 2 tables

> **TL;DR:** AsyMov解决了在移动和异步设备ISAC系统中估计目标多普勒频移和速度的挑战。

**AI_Comments:** AsyMov的创新之处在于其首次联合解决了ISAC系统中设备移动和时钟异步带来的多普勒频移和相位偏移问题，克服了现有方法各自为政的局限性。其利用信道冲激响应特性和交替最小化算法的设计具有独创性，且能够与现有传感器数据融合，提升了实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有ISAC系统中，多普勒估计受设备移动和时钟异步影响。现有方法分别处理这两个方面，未能同时解决设备运动和时钟异步造成的复杂多普勒频移和时变相位偏移。

**Method:** 本文提出了AsyMov方法，用于在具有移动和异步设备的ISAC设置中估计目标双基地多普勒频率及其速度。它利用接收端的信道冲激响应，通过利用相位偏移在传播路径上的不变性以及双基地几何，通过新提出的交替最小化算法联合估计目标多普勒和设备速度。此外，它可以与从车载传感器获得（如果可用）的设备速度测量无缝集成，以增强可靠性。

**Result:** AsyMov通过理论（Cramér-Rao界）、仿真和实验（在IEEE 802.11ay测试台上实现并在多个设置上进行测试，包括移动人体目标）进行了全面表征。数值和实验结果表明，其性能优于现有技术，并与静态ISAC设备场景相当。

**Conclusion:** AsyMov成功解决了移动和异步设备ISAC系统中目标多普勒频移和速度估计的挑战，并表现出卓越的性能。

> **ai_Abstract:** 本文提出了AsyMov，一种用于集成传感与通信（ISAC）系统的新方法，旨在解决移动和异步设备环境下目标多普勒频移和速度估计的难题。该方法利用信道冲激响应的特性，结合相位偏移不变性和双基地几何，通过创新的交替最小化算法联合估计目标多普勒和设备速度。实验结果表明，AsyMov在复杂场景下表现出优异的性能，甚至可与静态ISAC设备场景媲美。

> **摘要翻译:** 估计移动目标引起的多普勒频移是集成传感与通信（ISAC）系统的关键目标之一，因为它支持目标分类、人类活动识别和步态分析等应用。在实际场景中，多普勒估计受到发射器和接收器设备移动以及时钟异步引起的相位偏移的阻碍。现有方法分别解决了这两个方面，要么假设时钟同步的移动设备，要么假设异步的静态设备。事实上，同时处理设备运动和时钟异步极具挑战性，因为设备运动引起的多普勒频移对于每个传播路径都不同，并且相位偏移是时变的。在这项工作中，我们提出了AsyMov，一种在具有移动和异步设备的ISAC设置中估计目标双基地多普勒频率及其速度的方法。它利用接收端的信道冲激响应，通过独创性地利用相位偏移在传播路径上的不变性和双基地几何结构，通过新提出的交替最小化算法联合估计目标多普勒和设备速度。此外，它可以与从车载传感器获得（如果可用）的设备速度测量无缝集成，以增强可靠性。在这里，AsyMov通过理论（Cramér-Rao界）、仿真和实验（在IEEE 802.11ay测试台上实现并在多个设置上进行测试，包括移动人体目标）进行了全面表征。数值和实验结果表明，其性能优于现有技术，并与静态ISAC设备场景相当。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [512] [Hybrid Near-field and Far-field Localization with Holographic MIMO](https://arxiv.org/abs/2501.17868)
> *基于全息MIMO的混合近场和远场定位*

*Mengyuan Cao, Haobo Zhang, Yonina C. Eldar, Hongliang Zhang* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 全息MIMO, 近场定位, 远场定位, 可重构智能表面, 定位误差界限

**Comment:** 

> **TL;DR:** 该论文提出了一种新的基于RIS的定位方法，用于在全息MIMO系统中同时定位近场和远场用户，并通过联合估计和RIS相位优化来解决信道耦合问题。

**AI_Comments:** 本文的创新点在于提出了一个针对全息MIMO系统中混合近场和远场定位的解决方案，这在现有纯近场或纯远场方法不适用的情况下具有重要意义。通过引入RIS并解决信道耦合问题，该方法为未来高精度定位提供了新的思路。其重要性在于考虑了HMIMO规模扩大带来的实际挑战，并提供了实用的工程实现可能性。

<details>
  <summary>Details</summary>

**Motivation:** 随着全息多输入多输出（HMIMO）规模的增加，近场（NF）区域扩大，导致用户可能同时存在于具有不同电磁传输特性的近场和远场（FF）区域。现有的纯近场或纯远场定位方法不再适用，因此需要一种混合近场和远场定位方案。

**Method:** 论文提出了一种基于可重构智能表面（RIS）的定位方法，该方法在近场和远场区域同时搜索用户。通过联合估计所有用户位置来解决信道耦合问题。此外，还推导了考虑信道耦合的定位误差界限，并提出了一种优化RIS相位以最小化该界限的算法。

**Result:** 仿真结果表明，所提出的方法是有效的，并且与纯近场和纯远场技术相比，显示出性能增益。

**Conclusion:** 该论文成功地解决了HMIMO系统中混合近场和远场定位的挑战，通过提出的RIS使能定位方法和RIS相位优化算法，实现了对近场和远场用户的有效定位。

> **ai_Abstract:** 本论文针对全息MIMO系统中近场和远场区域并存的混合定位场景，提出了一种基于可重构智能表面（RIS）的定位方法。该方法通过联合估计所有用户位置来解决信道耦合问题，并设计了RIS相位优化算法以最小化定位误差界限。仿真结果验证了所提方法的有效性及其相对于传统纯近场或纯远场技术的性能优势。

> **摘要翻译:** 由于全息多输入多输出（HMIMO）能够精确控制无线波束，因此有望成为实现高精度定位的有前景的解决方案。然而，随着HMIMO规模的扩大以提高波束控制能力，相应的近场（NF）区域也随之扩大，这表明用户可能同时存在于具有不同电磁传输特性的近场和远场（FF）区域。因此，现有的纯近场或纯远场定位方法不再适用。本文考虑了一种混合近场和远场定位场景，其中基站（BS）借助可重构智能表面（RIS）（HMIMO的一种低成本实现方式）在近场和远场区域定位多个用户。在这种情况下，由于用户位置是在近场还是远场区域未知，并且不同用户的信道是耦合的，因此难以定位用户并优化RIS相位。为了解决这一挑战，我们提出了一种RIS使能的定位方法，该方法在近场和远场区域搜索用户，并通过联合估计所有用户位置来解决耦合问题。我们通过考虑信道耦合推导了定位误差界限，并提出了一种最小化该界限的RIS相位优化算法。仿真结果显示了所提方法的有效性，并证明了与纯近场和纯远场技术相比的性能增益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [554] [Hybrid Near-Field and Far-Field Localization with Multiple Holographic MIMO Surfaces](https://arxiv.org/abs/2502.03171)
> *多全息MIMO表面混合近场和远场定位*

*Weiqiao Zhu, Mengyuan Cao, Yang Yang, Haobo Zhang, Weijun Hao, Xiaofei Jia, Hongliang Zhang* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 近场定位, 远场定位, 可重构智能表面, 定位精度, 复杂度降低

**Comment:** 

> **TL;DR:** 针对多RIS定位中近场扩展和高复杂度的挑战，本文提出了一种混合近场/远场两阶段定位方法，并通过优化RIS以减少干扰。

**AI_Comments:** 这篇论文的创新点在于提出了混合近场和远场定位方法，以适应大规模RIS部署下近场区域的扩展。同时，其两阶段定位策略有效降低了定位的计算复杂度，并通过旁瓣抑制解决了多RIS间的干扰问题，对于提升未来6G通信中定位精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多基站定位系统受限于天线数量，且多RIS定位方法主要关注远场，在大规模RIS下，远场方法在近场区域定位精度不足。此外，多RIS场景下用户定位和RIS优化存在高复杂度和多RIS干扰问题。

**Method:** 本文提出了一种由多个RIS辅助的混合近场和远场定位方法。为解决高复杂度和干扰问题，该方法采用两阶段定位策略：首先估计用户与每个RIS的相对位置，然后融合结果以获得最终估计，从而减少了每一步考虑的候选位置数量。同时，在RIS优化问题中引入约束，限制指向其他RIS的旁瓣电平，以有效最小化RIS间干扰。

**Result:** 所提出的方法的有效性通过仿真得到了验证。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种针对多RIS场景的混合近场和远场定位方法，旨在解决现有远场方法在近场区域定位精度不足以及多RIS系统中存在的高复杂度和干扰问题。该方法采用两阶段定位策略，通过分步估计和结果融合来降低复杂度，并通过在RIS优化中引入旁瓣电平约束来抑制RIS间干扰。仿真结果验证了所提方法的有效性。

> **摘要翻译:** 使用多个基站（BS）的定位因其在定位精度方面的优势而备受关注。然而，多基站系统的性能受限于其天线数量。为了解决上述问题，我们建议使用可重构智能表面（RIS）作为天线。现有的多RIS定位方法主要关注每个RIS的远场（FF）区域。随着RIS规模的增加，每个RIS的近场（NF）区域会扩展，此时FF方法难以实现高定位精度。在本信函中，提出了一种由多个RIS辅助的混合近场和远场定位方法。在这种场景下，由于通过穷举搜索所有候选位置来匹配信号所导致的高复杂度，实现用户定位和RIS优化变得具有挑战性。此外，来自多个RIS的干扰会降低定位精度。为了应对这一挑战，我们提出了一种两阶段定位方法，该方法首先估计用户与每个RIS的相对位置，然后融合结果以获得估计。这种方法通过减少每一步考虑的候选位置数量来降低复杂度。同时，我们在RIS优化问题中引入了一个约束，限制指向其他RIS的旁瓣电平，从而有效最小化RIS间干扰。所提出方法的有效性通过仿真得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [595] [Retrieving Filter Spectra in CNN for Explainable Sleep Stage Classification](https://arxiv.org/abs/2502.06478)
> *在CNN中检索滤波器谱以实现可解释的睡眠阶段分类*

*Stephan Goerttler, Yucheng Wang, Fei He, Min Wu* | **Category: eess.SP** | **Updated: 2025-07-22**

**Keywords:** 睡眠阶段分类, 可解释性, 卷积神经网络, 滤波器谱, 脑电图

**Comment:** 6 pages, 3 figures, conference paper

> **TL;DR:** 本研究提出了一种在CNN中检索滤波器谱的方法，以解释睡眠阶段分类模型，发现低频带的光谱处理很重要，并且模型会优先处理信息量最大的通道。

**AI_Comments:** 该研究通过提供一种量化和可视化CNN内部光谱处理的方法，为深度学习模型的可解释性领域做出了贡献。其创新之处在于能够检索和分析低级卷积层的滤波器谱，从而揭示模型如何处理和利用不同频率信息。这对于理解睡眠阶段分类模型为何做出特定预测至关重要，有助于提高模型的透明度和临床接受度。此外，发现模型能自动优先处理信息量最大的通道，也为未来多模态数据融合和特征选择提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于深度学习的睡眠阶段分类取得了显著进展，但自动分类模型的临床应用仍然缓慢，主要挑战是缺乏可解释性，因为许多模型像黑箱一样运作。

**Method:** 本研究引入了一种检索低级卷积特征提取的滤波器谱的方法，并将其与数据中与分类相关的光谱信息进行比较。该方法在EEGNet和MSA-CNN模型上，使用ISRUC-S3和Sleep-EDF-20数据集进行了评估。

**Result:** 研究结果表明，光谱处理在较低频带中起着重要作用。此外，比较滤波器谱与数据导出的光谱信息之间的相关性与单变量性能表明，模型在多模态设置中自然会优先处理信息量最大的通道。

**Conclusion:** 本研究提供了一种解释深度学习模型中光谱处理的方法，并揭示了模型如何优先处理信息量最大的通道，这些见解可用于提高模型性能。

> **ai_Abstract:** 本研究旨在提高深度学习睡眠阶段分类模型的可解释性，通过引入一种方法来检索卷积神经网络（CNN）中低级特征提取的滤波器谱，并将其与分类相关的光谱信息进行比较。该方法在EEGNet和MSA-CNN模型上，使用两个数据集进行评估。结果表明，光谱处理在较低频带中至关重要，并且模型能自然地优先处理多模态设置中最具信息量的通道。这些发现为提升模型性能提供了新的见解。

> **摘要翻译:** 尽管基于深度学习的睡眠阶段分类取得了显著进展，但自动分类模型的临床应用仍然缓慢。一个关键的挑战是缺乏可解释性，因为许多模型作为拥有数百万参数的黑箱运行。作为回应，最近的工作越来越关注增强模型的可解释性。本研究通过全局解释单个脑电图（EEG）通道的光谱处理，为这些努力做出了贡献。具体来说，我们引入了一种检索低级卷积特征提取的滤波器谱的方法，并将其与数据中与分类相关的光谱信息进行比较。我们在EEGNet和MSA-CNN模型上使用ISRUC-S3和Sleep-EDF-20数据集评估了我们的方法。我们的发现表明，光谱处理在较低频带中起着重要作用。此外，比较滤波器谱与数据导出的光谱信息之间的相关性与单变量性能表明，模型在多模态设置中自然会优先处理信息量最大的通道。我们明确了如何利用这些见解来提高模型性能。用于滤波器谱检索及其分析的代码可在https://github.com/sgoerttler/MSA-CNN获取。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [638] [Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection](https://arxiv.org/abs/2506.11815)
> *基于扩散模型的异常检测心电图噪声量化*

*Tae-Seong Han, Jae-Wook Heo, Hakseung Kim, Cheol-Hui Lee, Hyub Huh, Eue-Keun Choi, Hye Jin Kim, Dong-Joo Kim* | **Category: eess.SP, cs.AI, cs.LG, eess.IV** | **Updated: 2025-07-22**

**Keywords:** ECG噪声量化, 异常检测, 扩散模型, Wasserstein-1距离, 信号处理

**Comment:** This manuscript contains 17 pages, 10 figures, and 3 tables

> **TL;DR:** 该研究提出了一种基于扩散模型的异常检测框架，用于量化心电图（ECG）噪声，无需人工标注，并引入了Wasserstein-1距离作为评估指标，显著优于现有方法，提升了ECG监测的可靠性和普适性。

**AI_Comments:** 该论文的创新点在于将ECG噪声量化问题重新定义为异常检测任务，并利用扩散模型来学习干净ECG信号的分布，从而避免了对噪声信号进行显式标注的需求。这极大地解决了现有方法中标签不一致和泛化能力差的问题。引入Wasserstein-1距离作为评估指标也体现了对分布差异的关注，使其评估更为鲁棒。这项工作对于提高ECG在临床和可穿戴设备中的可靠性和应用范围具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 心电图（ECG）信号常受噪声干扰，限制了其在传统和可穿戴设备中的临床可靠性。现有处理ECG噪声的方法（如伪影分类或去噪）受限于标注不一致和泛化性差的问题。

**Method:** 本研究将ECG噪声量化重构为异常检测任务。提出了一种基于扩散模型（diffusion-based framework）的框架，该框架旨在建模干净ECG信号的规范分布，并将偏差识别为噪声，无需明确的伪影标签。为鲁棒评估性能并缓解标签不一致性，引入了一种使用Wasserstein-1距离（$W_1$）的基于分布的度量标准。

**Result:** 该模型实现了1.308的宏观平均$W_1$分数，比次优方法高出48%以上。外部验证证实了其强大的泛化能力，有助于排除噪声片段以提高诊断准确性和支持及时临床干预。

**Conclusion:** 这种基于扩散模型的异常检测方法通过量化ECG噪声，提高了实时ECG监测的可靠性，并拓宽了ECG在数字健康技术中的应用范围。

> **ai_Abstract:** 本研究提出了一种新颖的基于扩散模型的异常检测框架，用于量化心电图（ECG）噪声。该方法将噪声识别为干净ECG信号分布的偏差，从而克服了传统方法对人工标注的依赖和泛化性差的问题。通过引入Wasserstein-1距离作为评估指标，该模型在噪声量化方面表现出色，其性能显著优于现有技术，并展现出强大的泛化能力，有望提高ECG诊断的准确性和实时监测的可靠性。

> **摘要翻译:** 心电图（ECG）信号经常受到噪声干扰，这限制了它们在传统和可穿戴设备中的临床可靠性。现有的ECG噪声处理方法，依赖于伪影分类或去噪，受到标注不一致和泛化能力差的限制。在此，我们通过将ECG噪声量化重构为异常检测任务来解决这些限制。我们提出了一种基于扩散模型（diffusion-based）的框架，该框架经过训练以建模干净ECG信号的规范分布，无需明确的伪影标签即可将偏差识别为噪声。为了鲁棒地评估性能并缓解标签不一致性，我们引入了一种使用Wasserstein-1距离（$W_1$）的基于分布的度量标准。我们的模型实现了1.308的宏观平均$W_1$分数，比次优方法高出48%以上。外部验证证实了其强大的泛化能力，有助于排除噪声片段以提高诊断准确性和支持及时临床干预。这种方法增强了实时ECG监测，并拓宽了ECG在数字健康技术中的适用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [686] [Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization](https://arxiv.org/abs/2507.14167)
> *基于注意力机制的IQ和FFT频谱图与AoA特征融合的GNSS干扰源定位*

*Lucas Heublein, Christian Wielenberg, Thorsten Nowak, Tobias Feigl, Christopher Mutschler, Felix Ott* | **Category: eess.SP, cs.IR, cs.LG, 62H05, 65-11, 94-11, E.0; H.1.1; I.2.6; I.5.4** | **Updated: 2025-07-22**

**Keywords:** GNSS干扰源定位, 注意力机制, IQ样本, FFT频谱图, AoA特征融合

**Comment:** 6 pages, 10 figures

> **TL;DR:** 本文提出一种新颖的基于注意力机制的融合框架，结合IQ样本、FFT频谱图和AoA特征，用于GNSS干扰源的检测、分类和定位，并在新数据集上展示了优于现有技术的性能。

**AI_Comments:** 本文的创新点在于提出了一个基于注意力机制的多模态融合框架，将原始IQ数据、频域信息（FFT频谱图）和AoA特征有效结合，以克服传统AoA在复杂多径环境下的局限性，提高了GNSS干扰源的定位精度。此外，构建新的动态多径环境下移动干扰设备数据集也为该领域的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 全球导航卫星系统（GNSS）的干扰设备会破坏信号并威胁定位可靠性。因此，检测和定位这些干扰信号对于实现态势感知、减轻其影响和实施有效对策至关重要。传统的到达角（AoA）方法在多径环境下精度降低，且需要大量计算资源。

**Method:** 本文提出了一种新颖的方法，用于检测和分类干扰，并估计干扰源的距离、方位角和仰角。研究评估了128个视觉编码器和时间序列模型。引入了一个基于注意力机制的融合框架，该框架将同相和正交（IQ）样本与快速傅里叶变换（FFT）计算的频谱图相结合，同时纳入22个到达角（AoA）特征以提高定位精度。此外，还提出了一个在室内动态多径条件下记录的移动干扰设备新数据集。

**Result:** 与现有最先进的方法相比，本文提出的方法表现出卓越的性能，能够准确估计干扰源的距离、方位角和仰角。

**Conclusion:** 本文提出的基于注意力机制的IQ和FFT频谱图与AoA特征融合方法，在GNSS干扰源的检测、分类和定位方面，特别是在动态多径环境中，展示了优于现有技术的性能。

> **ai_Abstract:** 本文提出了一种创新的GNSS干扰源定位方法，旨在解决传统AoA方法在多径环境下精度低和计算资源消耗大的问题。该方法采用基于注意力机制的融合框架，整合了IQ样本、FFT频谱图和22个AoA特征，以提高定位精度。通过对128个模型进行基准测试，并引入一个包含动态多径条件下的移动干扰设备新数据集，实验结果表明该方法在检测、分类干扰并估计其距离、方位角和仰角方面，表现出优于现有技术的卓越性能。

> **摘要翻译:** 干扰设备会破坏全球导航卫星系统（GNSS）的信号，并通过损害准确定位的可靠性构成重大威胁。因此，检测和定位这些干扰信号对于实现态势感知、减轻其影响和实施有效对策至关重要。传统的到达角（AoA）方法由于信号反射和散射，在多径环境中精度会降低，从而导致定位误差。此外，基于AoA的技术需要大量的计算资源进行阵列信号处理。在本文中，我们提出了一种新颖的方法，用于检测和分类干扰，同时估计干扰源的距离、方位角和仰角。我们的基准研究评估了128个视觉编码器和时间序列模型，以确定每个任务中性能最佳的方法。我们引入了一个基于注意力机制的融合框架，该框架将同相和正交（IQ）样本与快速傅里叶变换（FFT）计算的频谱图相结合，同时纳入22个AoA特征以提高定位精度。此外，我们提出了一个在室内动态多径条件下记录的移动干扰设备新数据集，并展示了优于现有最先进方法的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [744] [NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment](https://arxiv.org/abs/2507.14184)
> *NeuroHD-RA：神经蒸馏超维度模型与节律对齐*

*ZhengXiao He, Jinghao Wen, Huayu Li, Ao Li* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 超维度计算, 心电图, 疾病检测, 神经蒸馏, 节律对齐

**Comment:** 

> **TL;DR:** NeuroHD-RA是一种结合超维度计算（HDC）和可学习神经编码的新型可解释框架，用于心电图（ECG）疾病检测，通过节律感知编码和神经蒸馏架构显著优于传统方法。

**AI_Comments:** 该论文的创新点在于将超维度计算（HDC）与深度学习的可学习性相结合，通过引入“神经蒸馏”和“节律对齐”的编码策略，克服了传统HDC依赖静态随机投影的局限性。这种混合框架不仅提升了ECG疾病检测的性能，更重要的是，它保留了HDC固有的符号可解释性，这在医疗健康领域尤为重要。它为在资源受限的边缘设备上实现可解释的、个性化健康监测开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的超维度计算（HDC）方法依赖于静态、随机的投影，限制了其在心电图（ECG）疾病检测中的表现和适应性。本文旨在开发一个更具可解释性、任务适应性且性能优越的ECG疾病检测框架。

**Method:** 该框架名为NeuroHD-RA，结合了超维度计算（HDC）和可学习的神经编码。它引入了一种基于RR间期（与心动周期对齐的生理信号分割策略）的节律感知和可训练编码管道。核心设计是神经蒸馏HDC架构，包含一个可学习的RR-block编码器和一个BinaryLinear超维度投影层，通过交叉熵和基于代理的度量损失联合优化。

**Result:** 在Apnea-ECG和PTB-XL数据集上的实验表明，该模型显著优于传统HDC和经典机器学习基线，在Apnea-ECG上实现了73.09%的精度和0.626的F1分数，并在PTB-XL上表现出可比的鲁棒性。

**Conclusion:** NeuroHD-RA框架为边缘兼容的心电图分类提供了一个高效且可扩展的解决方案，在可解释和个性化健康监测方面具有巨大潜力。

> **ai_Abstract:** 本文提出了NeuroHD-RA，一个用于心电图（ECG）疾病检测的新型可解释框架。它将超维度计算（HDC）与可学习的神经编码相结合，引入了基于RR间期的节律感知编码管道和神经蒸馏HDC架构。该框架通过联合优化，实现了任务自适应表示学习，同时保留了HDC的可解释性。实验证明，NeuroHD-RA在性能上显著优于传统HDC和经典机器学习方法，为边缘兼容、可解释的ECG分类提供了高效且可扩展的解决方案。

> **摘要翻译:** 我们提出了一种新颖且可解释的心电图（ECG）疾病检测框架，该框架结合了超维度计算（HDC）和可学习的神经编码。与依赖静态、随机投影的传统HDC方法不同，我们的方法引入了一种基于RR间期（一种与心动周期对齐的生理信号分割策略）的节律感知和可训练编码管道。我们设计的核心是神经蒸馏HDC架构，其特点是可学习的RR-block编码器和二元线性超维度投影层，并通过交叉熵和基于代理的度量损失进行联合优化。这种混合框架保留了HDC的符号可解释性，同时实现了任务自适应的表示学习。在Apnea-ECG和PTB-XL上的实验表明，我们的模型显著优于传统HDC和经典机器学习基线，在Apnea-ECG上实现了73.09%的精度和0.626的F1分数，并在PTB-XL上表现出可比的鲁棒性。我们的框架为边缘兼容的心电图分类提供了一个高效且可扩展的解决方案，在可解释和个性化健康监测方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [13] [Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices](https://arxiv.org/abs/2507.15958)
> *面向资源受限设备的量化感知神经拟态架构，用于高效皮肤病分类*

*Haitian Wang, Xinyu Wang, Yiren Wang, Karen Lee, Zichen Geng, Xian Zhang, Kehkashan Kiran, Yu Zhang, Bo Miao* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 量化感知, 神经拟态架构, 皮肤病分类, 边缘计算, 尖峰神经网络

**Comment:** This manuscript is under review for IEEE BIBM 2025

> **TL;DR:** QANA是一种量化感知的神经拟态架构，能够在资源受限设备上高效、准确地进行皮肤病分类，显著优于现有模型。

**AI_Comments:** QANA的创新之处在于其将量化感知设计与神经拟态架构相结合，专为资源受限的边缘设备优化。它通过集成多种高效模块和支持SNN转换，显著提升了皮肤病分类的效率和准确性，尤其在能耗和延迟方面表现出色，对于推动边缘AI在医疗领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在边缘设备上准确高效地进行皮肤病变分类对于可及的皮肤病护理至关重要，但由于计算、能耗和隐私限制，这仍然是一个挑战。

**Method:** 本文提出了一种名为QANA的量化感知神经拟态架构，用于增量式皮肤病变分类。QANA有效集成了Ghost模块、高效通道注意力（ECA）和Squeeze-and-Excitation（SE）模块，以实现鲁棒的特征表示、低延迟和高能效的推理。其量化感知头部和尖峰兼容转换使其能够无缝转换为尖峰神经网络（SNN）并部署在神经拟态平台上。

**Result:** 在HAM10000基准测试和真实临床数据集上的评估显示，QANA在HAM10000上达到了91.6%的Top-1准确率和82.4%的宏F1分数，在临床数据集上分别达到90.8%和81.7%，在公平比较下显著优于最先进的CNN-to-SNN模型。部署在BrainChip Akida硬件上时，QANA实现了1.5毫秒的推理延迟和每图像1.7毫焦的能耗，与基于GPU的CNN相比，推理延迟和能耗降低了94.6%/98.6%以上，超越了最先进的CNN-to-SNN转换基线。

**Conclusion:** 这些结果表明，QANA在边缘环境下对于准确、实时和隐私敏感的医学分析是有效的。

> **ai_Abstract:** 本文提出了一种名为QANA的量化感知神经拟态架构，旨在解决资源受限设备上皮肤病分类的挑战。QANA通过集成Ghost模块、高效通道注意力及Squeeze-and-Excitation模块，实现了低延迟和高能效的推理，并能无缝转换为尖峰神经网络（SNN）。实验结果表明，QANA在HAM10000和真实临床数据集上均取得了高准确率，并在BrainChip Akida硬件上展现出极低的推理延迟和能耗，显著优于现有的CNN-to-SNN模型和GPU-based CNNs。

> **摘要翻译:** 在边缘设备上准确高效地进行皮肤病变分类对于可及的皮肤病护理至关重要，但由于计算、能耗和隐私限制，这仍然是一个挑战。我们引入了QANA，一种新颖的量化感知神经拟态架构，用于在资源有限的硬件上进行增量式皮肤病变分类。QANA有效集成了Ghost模块、高效通道注意力以及Squeeze-and-Excitation模块，以实现鲁棒的特征表示，并具有低延迟和高能效的推理。其量化感知头部和尖峰兼容转换使其能够无缝转换为尖峰神经网络（SNN）并部署在神经拟态平台上。在大型HAM10000基准测试和真实世界临床数据集上的评估显示，QANA在HAM10000上达到了91.6%的Top-1准确率和82.4%的宏F1分数，在临床数据集上分别达到90.8% / 81.7%，在公平比较下显著优于最先进的CNN-to-SNN模型。部署在BrainChip Akida硬件上时，QANA实现了1.5毫秒的推理延迟和每图像1.7毫焦的能耗，与基于GPU的CNN相比，推理延迟和能耗降低了94.6%/98.6%以上，超越了最先进的CNN-to-SNN转换基线。这些结果表明QANA在边缘环境下对于准确、实时和隐私敏感的医学分析是有效的。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [33] [DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification](https://arxiv.org/abs/2507.15487)
> *DeSamba：用于3D多序列MRI病灶分类的解耦光谱自适应框架*

*Dezhen Wang, Sheng Miao, Rongxin Chai, Jiufa Cui* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** MRI病灶分类, 多序列MRI, 解耦表示学习, 光谱自适应, 3D图像分类

**Comment:** 7 figures, 3 tables, submitted to AAAI2026

> **TL;DR:** DeSamba是一个新颖的框架，用于解耦和自适应融合多序列MRI数据中的空间和光谱特征，从而在3D病灶分类中取得优于现有技术的表现。

**AI_Comments:** DeSamba框架的创新点在于其解耦表示学习（DRLM）和光谱自适应调制（SAMB）机制，这有效地解决了多序列MRI数据融合的挑战。其在两个临床数据集上的优异表现，特别是对SOTA基线的超越以及消融研究的积极结果，证明了其方法的有效性和各组件的重要性。该研究为3D医学图像病灶分类提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 有效整合多序列MRI数据进行稳健的3D病灶分类仍然是一个挑战，而MRI序列提供了丰富的空间和频率域信息，对准确的病灶分类至关重要。

**Method:** 本文提出了DeSamba（解耦光谱自适应网络和基于Mamba的模型），一个旨在提取解耦表示并自适应融合空间和光谱特征用于病灶分类的新颖框架。DeSamba引入了解耦表示学习模块（DRLM），通过自重建和交叉重建解耦不同MRI序列的特征；并在提出的SAMNet中引入了光谱自适应调制块（SAMB），根据病灶特征动态融合光谱和空间信息。

**Result:** 在六分类脊柱转移瘤数据集（n=1,448）上，DeSamba在外部验证集（n=372）上实现了62.10%的Top-1准确率、63.62%的F1分数、87.71%的AUC和93.55%的Top-3准确率，优于所有现有技术基线。在强直性脊柱炎数据集（n=251）上，DeSamba在内部和外部验证集上分别实现了70.00%/64.52%的准确率和74.75/73.88的AUC。消融研究表明DRLM和SAMB都对整体性能有显著贡献，相对基线提高了10%以上。

**Conclusion:** DeSamba作为一种通用且有效的解决方案，在多序列医学影像的3D病灶分类中展现出巨大潜力。

> **ai_Abstract:** DeSamba是一个用于3D多序列MRI病灶分类的新型框架。它通过解耦表示学习模块（DRLM）分离不同MRI序列的特征，并通过光谱自适应调制块（SAMB）动态融合空间和光谱信息。在两个临床数据集上的评估显示，DeSamba在准确率、F1分数和AUC等指标上均优于现有技术，且其核心模块对性能有显著贡献，表明其在多序列医学影像病灶分类中的有效性和通用性。

> **摘要翻译:** 磁共振成像（MRI）序列提供了丰富的空间和频率域信息，这对于医学影像中准确的病灶分类至关重要。然而，有效整合多序列MRI数据以实现稳健的3D病灶分类仍然是一个挑战。在本文中，我们提出了DeSamba（解耦光谱自适应网络和基于Mamba的模型），一个旨在提取解耦表示并自适应融合空间和光谱特征用于病灶分类的新颖框架。DeSamba引入了解耦表示学习模块（DRLM），通过自重建和交叉重建解耦不同MRI序列的特征，并在提出的SAMNet中引入了光谱自适应调制块（SAMB），从而能够根据病灶特征动态融合光谱和空间信息。我们在两个临床相关的3D数据集上评估了DeSamba。在六分类脊柱转移瘤数据集（n=1,448）上，DeSamba在外部验证集（n=372）上实现了62.10%的Top-1准确率、63.62%的F1分数、87.71%的AUC和93.55%的Top-3准确率，优于所有现有技术（SOTA）基线。在强直性脊柱炎数据集（n=251）上，DeSamba在内部和外部验证集上分别实现了70.00%/64.52%的准确率和74.75/73.88的AUC。消融研究表明，DRLM和SAMB都对整体性能有显著贡献，与基线相比相对提高了10%以上。我们的结果强调了DeSamba作为一种通用且有效的解决方案，在多序列医学影像的3D病灶分类中的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [256] [SFNet: A Spatio-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2507.16267)
> *SFNet：一种时空-频率域深度学习网络，用于高效阿尔茨海默病诊断*

*Xinyue Yang, Meiliang Liu, Yunfang Xu, Xiaoxiao Yang, Zhengye Si, Zijin Li, Zhiwen Zhao* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 阿尔茨海默病诊断, 深度学习, 时空-频率域, 3D MRI, SFNet

**Comment:** 

> **TL;DR:** SFNet是一种新的深度学习网络，它同时利用3D MRI的时空和频率域信息，以提高阿尔茨海默病的诊断效率和准确性。

**AI_Comments:** SFNet的创新之处在于其是首个针对3D MRI同时利用时空和频率域信息的端到端深度学习框架，这充分利用了MRI数据的固有特性。通过结合局部空间特征、全局频率表示以及多尺度注意力，该模型能够更全面地捕捉AD的复杂神经影像特征。其在ADNI数据集上表现出的高准确率和计算效率提升，预示着其在AD早期诊断中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有阿尔茨海默病（AD）诊断模型从单一领域（空间或频率）提取特征，限制了其捕捉复杂神经影像学特征的能力。少数结合时空和频率信息的研究仅限于2D MRI，未能充分利用3D MRI中双域分析的潜力。

**Method:** 本文提出了Spatio-Frequency Network (SFNet)，这是第一个端到端深度学习框架，它同时利用空间和频率域信息来增强基于3D MRI的AD诊断。SFNet集成了增强的密集卷积网络以提取局部空间特征，一个全局频率模块以捕获全局频率域表示，并引入了一个新颖的多尺度注意力模块以进一步细化空间特征提取。

**Result:** 在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，SFNet在认知正常（CN）和AD分类中优于现有基线模型，并降低了计算开销，实现了95.1%的准确率。

**Conclusion:** SFNet通过同时利用3D MRI的时空和频率域信息，显著提高了阿尔茨海默病诊断的效率和准确性，为AD的早期诊断提供了一种有效的新方法。

> **ai_Abstract:** 本文提出了SFNet，一个新颖的端到端深度学习框架，用于基于3D MRI的阿尔茨海默病诊断。SFNet创新性地同时利用了MRI图像的时空和频率域信息，以克服现有模型仅从单一域提取特征或局限于2D图像的局限性。它结合了增强的密集卷积网络、全局频率模块和多尺度注意力模块。实验结果表明，SFNet在ADNI数据集上达到了95.1%的分类准确率，优于现有方法并降低了计算成本。

> **摘要翻译:** 阿尔茨海默病（AD）是一种进行性神经退行性疾病，主要影响老年人群，目前尚无治愈方法。磁共振成像（MRI）作为一种非侵入性成像技术，对于AD的早期诊断至关重要。MRI本身包含空间和频率信息，因为原始信号是在频率域中获取，并通过傅里叶变换重建为空间图像。然而，大多数现有的AD诊断模型从单一领域提取特征，限制了它们充分捕捉疾病复杂神经影像学特征的能力。虽然一些研究结合了空间和频率信息，但它们大多局限于2D MRI，未探索3D MRI中双域分析的潜力。为了克服这一限制，我们提出了时空-频率网络（SFNet），这是第一个端到端深度学习框架，它同时利用空间和频率域信息来增强基于3D MRI的AD诊断。SFNet集成了增强的密集卷积网络以提取局部空间特征，以及一个全局频率模块以捕获全局频率域表示。此外，还提出了一个新颖的多尺度注意力模块以进一步细化空间特征提取。在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，SFNet优于现有基线模型，并降低了认知正常（CN）和AD分类的计算开销，准确率达到95.1%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [269] [MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2507.16122)
> *MLRU++：用于高效3D医学图像分割的多尺度轻量级残差UNETR++与注意力机制*

*Nand Kumar Yadav, Rodrigue Rizk, Willium WC Chen, KC* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 3D医学图像分割, UNETR++, 注意力机制, 轻量级, 多尺度

**Comment:** 

> **TL;DR:** MLRU++是一种新的轻量级3D医学图像分割模型，通过引入注意力模块和多尺度瓶颈块，在保持高精度的同时显著提高了计算效率。

**AI_Comments:** 本文的创新点在于其MLRU++架构，通过巧妙地结合轻量级注意力机制（LCBAM）和多尺度特征聚合（M2B），有效解决了3D医学图像分割中精度与效率难以兼顾的挑战。其重要性在于提供了一个在保持SOTA性能的同时，显著降低计算资源需求（参数和计算成本）的实用方案，这对于实际部署和资源受限环境下的应用具有重要意义。消融研究进一步验证了核心组件的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 准确高效的医学图像分割至关重要但充满挑战，原因在于解剖变异性和处理体数据的高计算需求。尽管混合CNN-Transformer架构实现了最先进的性能，但它们带来了显著的复杂性。

**Method:** 本文提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：1. 轻量级通道和瓶颈注意力模块（LCBAM）：以最小的开销增强上下文特征编码。2. 解码器中的多尺度瓶颈块（M2B）：通过多分辨率特征聚合捕获细粒度细节。

**Result:** 在四个公开基准数据集（Synapse、BTCV、ACDC、Decathlon Lung）上的实验表明，MLRU++实现了最先进的性能：平均Dice分数：Synapse 87.57%，ACDC 93.00%，Lung 81.12%。与现有领先模型相比：Synapse上的Dice分数提高了5.38%，ACDC上提高了2.12%。显著减少了参数数量和计算成本。消融研究证实了LCBAM和M2B的有效性。

**Conclusion:** 结果表明，MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。

> **ai_Abstract:** 本文提出了一种名为MLRU++的3D医学图像分割模型，旨在平衡高精度与计算效率。该模型是基于UNETR++的改进，核心创新包括引入轻量级通道和瓶颈注意力模块（LCBAM）以增强特征编码，以及多尺度瓶颈块（M2B）以捕获细粒度细节。在多个公开数据集上的实验证明，MLRU++在Dice分数上取得了最先进的性能，并显著降低了模型参数和计算成本，为3D医学图像分割提供了一个实用且高效的解决方案。

> **摘要翻译:** 准确高效的医学图像分割至关重要但充满挑战，原因在于解剖变异性和体数据的高计算需求。最近的混合CNN-Transformer架构取得了最先进的成果，但增加了显著的复杂性。在本文中，我们提出了MLRU++，一种多尺度轻量级残差UNETR++架构，旨在平衡分割精度和计算效率。它引入了两项关键创新：一个轻量级通道和瓶颈注意力模块（LCBAM），以最小的开销增强上下文特征编码；以及解码器中的多尺度瓶颈块（M2B），通过多分辨率特征聚合捕获细粒度细节。在四个公开基准数据集（Synapse、BTCV、ACDC和Decathlon Lung）上的实验表明，MLRU++实现了最先进的性能，平均Dice分数分别为87.57%（Synapse）、93.00%（ACDC）和81.12%（Lung）。与现有领先模型相比，MLRU++在Synapse和ACDC上的Dice分数分别提高了5.38%和2.12%，同时显著减少了参数数量和计算成本。评估LCBAM和M2B的消融研究进一步证实了所提出架构组件的有效性。结果表明，MLRU++为3D医学图像分割任务提供了一个实用且高性能的解决方案。源代码可在：https://github.com/1027865/MLRUPP 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [288] [Physics-Driven Neural Network for Solving Electromagnetic Inverse Scattering Problems](https://arxiv.org/abs/2507.16321)
> *物理驱动神经网络求解电磁逆散射问题*

*Yutong Du, Zicheng Liu, Bazargul Matkerim, Changyou Li, Yali Zong, Bo Qi, Jingwei Kou* | **Category: eess.IV, cs.LG, physics.comp-ph** | **Updated: 2025-07-22**

**Keywords:** 物理驱动神经网络, 逆散射问题, 电磁成像, 泛化能力, 迭代求解

**Comment:** 

> **TL;DR:** 提出一种物理驱动神经网络（PDNN）迭代求解电磁逆散射问题的新方案，克服了传统数据驱动方法的泛化性差和数据依赖性问题，并提高了成像效率和精度。

**AI_Comments:** 该论文的创新点在于提出了一个物理驱动的神经网络，有效地结合了物理约束和深度学习的优势，克服了传统数据驱动方法在逆散射问题中泛化能力差和数据依赖性强的问题。这种方法减少了对大量训练数据的需求，并提高了模型的鲁棒性，尤其是在处理复杂场景时。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习方法求解逆散射问题过度依赖数据且泛化能力有限。

**Method:** 提出一种新的迭代求解方案，其中解随着物理驱动神经网络（PDNN）的更新而迭代更新。PDNN的超参数通过最小化包含散射场约束和散射体先验信息的损失函数进行优化。与数据驱动方法不同，PDNN仅需收集到的散射场作为输入和计算预测解对应的散射场，从而避免了泛化问题。此外，为了加速成像效率，识别出包含散射体的子区域。

**Result:** 数值和实验结果表明，该方案具有高重建精度和强稳定性，即使在处理复合损耗散射体时也是如此。

**Conclusion:** 提出的物理驱动神经网络方案有效解决了电磁逆散射问题，表现出优异的重建性能和鲁棒性，克服了传统数据驱动方法的局限性。

> **ai_Abstract:** 本文提出了一种用于解决电磁逆散射问题的物理驱动神经网络（PDNN）方案。该方法通过迭代更新PDNN来求解，其超参数通过结合散射场约束和先验信息的损失函数进行优化。与传统数据驱动方法相比，PDNN仅需少量输入数据即可避免泛化问题。为提高效率，还引入了散射体子区域识别。实验证明，该方案在重建精度和稳定性方面表现出色，即使面对复杂散射体也能有效工作。

> **摘要翻译:** 近年来，基于深度学习的方法被提出用于解决逆散射问题（ISPs），但其中大多数都严重依赖数据并受限于泛化能力。在本文中，提出了一种新的求解方案，其中解随着物理驱动神经网络（PDNN）的更新而迭代更新，PDNN的超参数通过最小化包含收集到的散射场约束和散射体先验信息的损失函数进行优化。与数据驱动神经网络求解器不同，PDNN的训练仅需要收集到的散射场作为输入和计算预测解对应的散射场，从而避免了泛化问题。此外，为了加速成像效率，识别出包含散射体的子区域。数值和实验结果表明，所提出的方案具有高重建精度和强稳定性，即使在处理复合损耗散射体时也是如此。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [318] [A High Magnifications Histopathology Image Dataset for Oral Squamous Cell Carcinoma Diagnosis and Prognosis](https://arxiv.org/abs/2507.16360)
> *口腔鳞状细胞癌诊断和预后高倍病理图像数据集*

*Jinquan Guan, Junhong Guo, Qi Chen, Jian Chen, Yongkang Cai, Yilin He, Zhiquan Huang, Yan Wang, Yutong Xie* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 口腔鳞状细胞癌, 病理图像, 数据集, 诊断, 预后

**Comment:** 12 pages, 11 tables, 4 figures

> **TL;DR:** 本文介绍了Multi-OSCC，一个包含1325名口腔鳞状细胞癌(OSCC)患者的高倍病理图像数据集，用于诊断和预后任务。该数据集包含多倍率图像和六项临床任务的详细标注。基准测试显示了模型的良好性能，并揭示了染色归一化和多任务学习的挑战。数据集已公开可用。

**AI_Comments:** 该论文通过引入Multi-OSCC数据集，有效解决了现有OSCC数据集在患者数量和任务覆盖上的局限性。其创新之处在于整合了诊断和预后信息，提供了多倍率和多区域的高分辨率图像，并对多项关键临床任务进行了详尽标注。数据集的公开性对于推动OSCC领域的深度学习研究具有重要意义。同时，对染色归一化和多任务学习影响的深入分析，为未来模型开发提供了宝贵的见解，特别是指出了多任务学习中平衡不同任务的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的口腔鳞状细胞癌(OSCC)公开数据集通常患者队列有限，且仅侧重于诊断或预后任务，这限制了开发全面且通用深度学习模型的能力。

**Method:** 我们构建了一个名为Multi-OSCC的新型病理图像数据集，包含1325名OSCC患者的诊断和预后信息。每位患者有六张高分辨率病理图像，分别以x200、x400和x1000倍放大率拍摄，涵盖肿瘤核心和边缘区域。该数据集为六项关键临床任务（复发预测、淋巴结转移、肿瘤分化、肿瘤浸润、癌栓和神经周围浸润）进行了丰富标注。为基准测试该数据集，我们系统评估了不同视觉编码器、多图像融合技术、染色归一化和多任务学习框架的影响。

**Result:** 分析结果表明：1) 表现最佳的模型取得了优异的结果，复发预测(REC)的AUC达到94.72%，肿瘤分化(TD)的AUC达到81.23%，所有任务的AUC均超过70%；2) 染色归一化对诊断任务有益，但对复发预测有负面影响；3) 在我们的多任务基准测试中，与单任务模型相比，多任务学习导致平均AUC下降3.34%，这凸显了在该数据集中平衡多任务的挑战。

**Conclusion:** 为了加速未来的研究，我们公开了Multi-OSCC数据集和基线模型。

> **ai_Abstract:** 本文介绍了Multi-OSCC，一个用于口腔鳞状细胞癌（OSCC）诊断和预后的新型高倍病理图像数据集。该数据集包含1325名患者的图像，涵盖多种放大倍率和肿瘤区域，并针对六项临床任务进行了详细标注。研究人员在该数据集上评估了不同的深度学习方法，发现模型在多项任务上表现良好，但染色归一化和多任务学习仍存在挑战。为促进未来研究，该数据集及其基线模型已公开。

> **摘要翻译:** 口腔鳞状细胞癌（OSCC）是一种常见且侵袭性强的恶性肿瘤，基于深度学习的计算机辅助诊断和预后可以增强临床评估。然而，现有的公开OSCC数据集通常患者队列有限，并且仅限于诊断或预后任务，这限制了全面和通用模型的发展。为了弥补这一差距，我们引入了Multi-OSCC，这是一个新的病理图像数据集，包含1325名OSCC患者，整合了诊断和预后信息，以扩展现有公共资源。每位患者由六张高分辨率病理图像代表，分别以x200、x400和x1000倍放大率拍摄——每个放大率两张——涵盖肿瘤核心和边缘区域。Multi-OSCC数据集为六项关键临床任务进行了丰富标注：复发预测（REC）、淋巴结转移（LNM）、肿瘤分化（TD）、肿瘤浸润（TI）、癌栓（CE）和神经周围浸润（PI）。为了对该数据集进行基准测试，我们系统地评估了不同视觉编码器、多图像融合技术、染色归一化和多任务学习框架的影响。我们的分析得出几项关键见解：（1）表现最佳的模型取得了优异的结果，复发预测（REC）的曲线下面积（AUC）为94.72%，肿瘤分化（TD）的AUC为81.23%，同时所有任务的AUC均超过70%；（2）染色归一化有利于诊断任务，但对复发预测有负面影响；（3）在我们的多任务基准测试中，与单任务模型相比，多任务学习导致平均AUC下降3.34%，这凸显了平衡数据集中多个任务的挑战。为了加速未来的研究，我们公开了Multi-OSCC数据集和基线模型，网址为https://github.com/guanjinquan/OSCC-PathologyImageDataset。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [350] [Semantic Segmentation for Preoperative Planning in Transcatheter Aortic Valve Replacement](https://arxiv.org/abs/2507.16573)
> *经导管主动脉瓣置换术术前规划中的语义分割*

*Cedric Zöllner, Simon Reiß, Alexander Jaus, Amroalalaa Sholi, Ralf Sodian, Rainer Stiefelhagen* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 语义分割, 经导管主动脉瓣置换术, 术前规划, 伪标签, 损失函数

**Comment:** Accepted at 16th MICCAI Workshop on Statistical Atlases and
  Computational Modeling of the Heart (STACOM)

> **TL;DR:** 该研究提出了一种基于语义分割的AI方法，通过伪标签和损失函数调整，提高了经导管主动脉瓣置换术(TAVR)术前规划中解剖结构测量的准确性。

**AI_Comments:** 该论文的创新点在于结合医疗指南，通过生成细粒度伪标签来训练分割模型，并提出了一种有效的损失函数调整方法，显著提升了语义分割的准确性。这对于提高经导管主动脉瓣置换术(TAVR)术前规划的效率和精确性具有重要的临床应用价值。数据和伪标签的公开也促进了该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗图像基础上进行手术术前规划时，人工智能方法可以支持医生进行评估，特别是使经导管主动脉瓣置换术(TAVR)术前规划中相关的解剖结构在CT扫描中可测量。

**Method:** 首先从粗粒度解剖信息中推导出细粒度的TAVR相关伪标签，用于训练分割模型并量化其在扫描中找到这些结构的能力。此外，提出了一种对分割模型训练中损失函数的适应性改进。

**Result:** 通过对损失函数的调整，性能在Dice系数上提高了+1.27%。

**Conclusion:** 提出的方法通过伪标签和损失函数调整，有效提高了经导管主动脉瓣置换术(TAVR)术前规划中解剖结构语义分割的性能。

> **ai_Abstract:** 本文针对经导管主动脉瓣置换术(TAVR)的术前规划，提出了一种利用语义分割模型辅助医生评估的方法。研究人员从粗粒度解剖信息中生成细粒度的TAVR相关伪标签来训练分割模型，并提出了一种改进损失函数的方法，从而将Dice系数性能提升了1.27%。该研究为TAVR术前规划中关键解剖结构的测量提供了支持。

> **摘要翻译:** 当手术的术前规划基于医学图像进行时，人工智能方法可以支持医生进行评估。在这项工作中，我们考虑了经导管主动脉瓣置换术（TAVR）术前规划的医疗指南，并确定了可以通过语义分割模型支持的任务，从而使计算机断层扫描中相关的解剖结构可测量。我们首先从粗粒度解剖信息中推导出细粒度的TAVR相关伪标签，以便训练分割模型并量化它们在扫描中找到这些结构的能力。此外，我们提出了一种对这些分割模型训练中损失函数的适应性改进，并通过此实现了性能上+1.27%的Dice系数提升。我们构建的细粒度TAVR相关伪标签和计算机断层扫描数据可在https://doi.org/10.5281/zenodo.16274176获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [392] [Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis](https://arxiv.org/abs/2507.16579)
> *用于图像合成的金字塔分层掩蔽扩散模型*

*Xiaojiao Xiao, Qinmin Vivian Hu, Guanghui Wang* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 医学图像合成, 扩散模型, 金字塔分层, 多尺度掩蔽, Transformer

**Comment:** 

> **TL;DR:** PHMDiff是一种新颖的金字塔分层掩蔽扩散模型，通过多尺度分层方法和Transformer-based扩散过程，能够快速合成高质量的医学图像，并在PSNR和SSIM方面表现优异。

**AI_Comments:** PHMDiff的创新之处在于其结合了金字塔分层结构、多尺度高比例掩码加速训练以及基于Transformer的跨粒度正则化，这些设计协同工作，显著提升了医学图像合成的效率和质量。该模型在解决医学影像领域中常见的模态缺失问题上具有重要意义，有助于改进临床诊断和治疗流程。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像合成在临床工作流程中至关重要，因为扫描时间长、图像损坏、伪影、患者移动和对比剂不耐受等因素常导致成像模态缺失，本研究旨在解决这一问题。

**Method:** 本文提出了金字塔分层掩蔽扩散模型（PHMDiff），该模型采用多尺度分层方法，以更精细地控制不同分辨率和层级的高质量图像合成。具体而言，它利用随机多尺度高比例掩码加速扩散模型训练，并平衡细节保真度和整体结构。此外，整合了基于Transformer的扩散模型过程，引入了跨粒度正则化，建模了各粒度潜在空间之间的互信息一致性，从而提高了像素级感知精度。

**Result:** 在两个具有挑战性的数据集上的综合实验表明，PHMDiff在峰值信噪比（PSNR）和结构相似性指数（SSIM）方面均取得了优异的性能，突出了其生成高质量合成图像和出色结构完整性的能力。消融研究进一步证实了每个组件的贡献。

**Conclusion:** PHMDiff模型作为一种跨医学成像模态和模态内的多尺度图像合成框架，相比其他方法显示出显著优势，能够生成高质量的医学合成图像。

> **ai_Abstract:** 本文提出了一种新颖的医学图像合成模型PHMDiff，该模型基于金字塔分层掩蔽扩散框架。它通过多尺度分层方法和随机高比例掩码加速训练，并利用Transformer-based扩散过程中的跨粒度正则化来提高图像质量和结构完整性。实验证明，PHMDiff在PSNR和SSIM指标上优于现有方法，能够生成高质量的医学合成图像，有效解决了医学成像中模态缺失的问题。

> **摘要翻译:** 医学图像合成在临床工作流程中扮演着关键角色，解决了由于扫描时间延长、扫描损坏、伪影、患者移动和对造影剂不耐受等因素导致的常见成像模态缺失问题。本文提出了一种新颖的图像合成网络——金字塔分层掩蔽扩散模型（Pyramid Hierarchical Masked Diffusion Model, PHMDiff），该模型采用多尺度分层方法，能够更精细地控制不同分辨率和层级的高质量图像合成。具体而言，该模型利用随机多尺度高比例掩码来加速扩散模型的训练，并平衡了细节保真度和整体结构。集成基于Transformer的扩散模型过程，引入了跨粒度正则化，模拟了每个粒度潜在空间之间的互信息一致性，从而增强了像素级感知精度。在两个具有挑战性的数据集上进行的综合实验表明，PHMDiff在峰值信噪比（PSNR）和结构相似性指数（SSIM）方面均取得了卓越的性能，突显了其生成高质量合成图像和出色结构完整性的能力。消融研究进一步证实了每个组件的贡献。此外，PHMDiff模型作为一个跨医学成像模态和模态内的多尺度图像合成框架，相比其他方法显示出显著优势。源代码可在https://github.com/xiaojiao929/PHMDiff获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [434] [A Tutorial on MRI Reconstruction: From Modern Methods to Clinical Implications](https://arxiv.org/abs/2507.16715)
> *MRI重建教程：从现代方法到临床应用*

*Tolga Çukur, Salman U. H. Dar, Valiyeh Ansarian Nezhad, Yohan Jun, Tae Hyung Kim, Shohei Fujita, Berkin Bilgic* | **Category: eess.IV** | **Updated: 2025-07-22**

**Keywords:** MRI重建, 深度学习, 图像加速, 临床应用, 先验信息

**Comment:** 

> **TL;DR:** 本教程概述了MRI重建的基础知识和最先进的方法，包括经典方法和深度学习方法，并探讨了其临床应用和未来挑战，旨在解决MRI扫描时间过长的问题。

**AI_Comments:** 这篇教程的重要性在于它系统地梳理了MRI重建领域的最新进展，特别强调了深度学习在此领域的应用。它不仅提供了理论知识，还通过配套的Python工具箱提供了实践机会，这对于研究人员和临床医生理解并应用这些先进技术非常有价值。它弥补了理论与实践之间的鸿沟，有助于加速MRI技术的临床转化。

<details>
  <summary>Details</summary>

**Motivation:** MRI扫描时间过长导致患者吞吐量低、易受运动伪影影响以及可能牺牲图像质量或诊断范围。因此，需要开发和应用先进的图像重建算法来加速采集，同时保持诊断质量。

**Method:** 本教程概述了MRI重建的基础知识，重点介绍了最先进的方法。具体包括：依赖显式手工先验的经典方法；利用学习和手工先验组合以提升性能的深度学习方法。教程还探讨了这些方法的转化方面和最终临床意义。此外，教程还提供了一个Python工具箱来演示文中讨论的选定方法。

**Result:** 本教程提供了一个关于MRI重建的全面概述，涵盖了从经典到深度学习的现代方法及其临床应用，并附带了一个用于演示的Python工具箱。

**Conclusion:** 教程讨论了解决MRI重建中剩余挑战的未来方向。

> **ai_Abstract:** 这篇教程深入探讨了MRI重建技术，旨在解决MRI扫描时间过长导致的问题。它从基础概念入手，详细介绍了从依赖手工先验的经典算法到结合学习和手工先验的深度学习方法等最先进的重建技术。教程还涵盖了这些方法在临床实践中的转化应用和潜在影响，并展望了未来的研究方向。此外，教程还提供了一个配套的Python工具箱，以供读者实践和理解。

> **摘要翻译:** MRI是一种不可或缺的临床工具，提供丰富多样的组织对比度，以支持广泛的诊断和研究应用。临床检查通常获取多个结构序列，为鉴别诊断提供补充信息，而研究方案通常包含先进的功能、扩散、波谱和弛豫测量序列，以获取组织结构和组成的多维洞察。然而，这些能力需要以延长扫描时间为代价，这会降低患者吞吐量，增加运动伪影的敏感性，并可能需要在图像质量或诊断范围方面进行权衡。在过去的二十年中，图像重建算法的进步——以及硬件和脉冲序列设计的改进——使得在保持诊断质量的同时加速采集成为可能。这一进展的核心是能够纳入先验信息以正则化重建问题的解决方案。在本教程中，我们概述了MRI重建的基础知识，并重点介绍了最先进的方法，从依赖显式手工先验的经典方法开始，然后转向利用学习和手工先验组合以进一步提升性能的深度学习方法。我们还探讨了这些方法的转化方面和最终临床意义。最后，我们讨论了解决MRI重建中剩余挑战的未来方向。本教程附带了一个Python工具箱（https://github.com/tutorial-MRI-recon/tutorial），用于演示文章中讨论的选定方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [476] [Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning](https://arxiv.org/abs/2507.16779)
> *利用L2正则化、迁移学习和深度微调提高U-Net在透射电镜图像数据上的置信度*

*Aiden Ochoa, Xinyuan Xu, Xing Wang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** U-Net, TEM图像, L2正则化, 迁移学习, 深度微调, 缺陷检测

**Comment:** Accepted into the ICCV 2025 CV4MS Workshop

> **TL;DR:** 本研究通过结合L2正则化、迁移学习和深度微调，并引入新的评估指标，显著提高了U-Net模型在透射电镜图像中纳米级缺陷检测的性能和置信度。

**AI_Comments:** 该论文的创新点在于将L2正则化、迁移学习和深度微调相结合应用于U-Net模型，以应对TEM图像分析中数据稀缺和高变异性的挑战。特别值得注意的是，作者认识到传统评估指标在有标注错误的数据集上的局限性，并提出了新的、更稳健的评估方法，这对于处理真实世界中不完美标注的数据集具有重要意义。57%的缺陷检测率提升显示了该方法的有效性，并且强调了深度微调对于模型置信度的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 开发自动化方法识别透射电镜（TEM）图像中的纳米级缺陷至关重要。然而，TEM图像中的缺陷具有高度变异性、标注数据少和标注错误率高的问题，这些都严重阻碍了机器学习模型在TEM图像分析中的性能提升。

**Method:** 为解决TEM图像分析的局限性，研究人员探索了利用大型预训练模型进行迁移学习。通过使用预训练编码器和L2正则化，模型能够忽略语义复杂特征，转而关注更简单、可靠的线索，从而提高性能。此外，研究引入了独立于标注准确性的新型评估指标，以克服传统指标（如F1分数）受人工标注错误影响的问题。方法还包括对非常深层进行迁移学习和微调。

**Result:** 在UO2 TEM图像的晶界检测案例研究中，该方法使缺陷检测率提高了57%，这是一个衡量模型性能的稳健且全面的指标。研究还发现，模型自置信度只有通过迁移学习和非常深层的微调才能实现。

**Conclusion:** 结合L2正则化、迁移学习和深度微调，并辅以创新的评估指标，能够有效提升U-Net模型在具有挑战性的TEM图像数据上进行纳米级缺陷检测的性能和置信度。

> **ai_Abstract:** 本研究旨在解决透射电镜（TEM）图像中纳米级缺陷检测面临的挑战，即数据变异性高、标注数据稀缺和标注错误率高。作者提出了一种结合L2正则化、迁移学习和深度微调的U-Net模型改进方法。为克服传统评估指标的局限性，研究引入了新型独立于标注准确性的评估指标。在UO2 TEM图像晶界检测的案例研究中，该方法使缺陷检测率提高了57%，并证明了模型自置信度需要通过对深层进行迁移学习和微调才能实现，显著提升了模型在复杂TEM数据上的性能和可靠性。

> **摘要翻译:** 随着数据量的不断增加，开发识别透射电子显微镜（TEM）图像中纳米级缺陷的自动化方法至关重要。然而，与传统照片中的特征相比，TEM图像中的纳米级缺陷由于复杂的对比机制和复杂的缺陷结构，表现出更大的变异性。这些挑战常常导致标注数据更少和标注错误率更高，对提高TEM图像分析的机器学习模型性能构成了重大障碍。为了解决这些局限性，我们通过利用用于自然图像的大型预训练模型来研究迁移学习。
我们证明，通过使用预训练编码器和L2正则化，语义复杂的特征被忽略，转而关注更简单、更可靠的线索，从而大大提高了模型性能。然而，这种改进无法通过传统的评估指标（如F1分数）来衡量，因为F1分数可能受到被视为真实情况的人工标注错误的偏斜。相反，我们引入了独立于标注准确性的新型评估指标。以UO2 TEM图像中的晶界检测为例，我们发现我们的方法使缺陷检测率提高了57%，这是衡量模型在本次工作使用的TEM数据集上性能的稳健而全面的指标。最后，我们表明模型自置信度只有通过迁移学习和对非常深层的微调才能实现。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [518] [MultiTaskDeltaNet: Change Detection-based Image Segmentation for Operando ETEM with Application to Carbon Gasification Kinetics](https://arxiv.org/abs/2507.16803)
> *MultiTaskDeltaNet：基于变化检测的图像分割用于原位ETEM及碳气化动力学应用*

*Yushuo Niu, Tianyu Li, Yuanyuan Zhu, Qian Yang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 变化检测, 图像分割, 深度学习, TEM, 碳气化

**Comment:** 

> **TL;DR:** MTDN是一种新颖的深度学习模型，通过将分割任务重构为变化检测问题，解决了TEM图像分割中数据稀缺和特征模糊的挑战，并在碳气化ETEM数据上表现出显著优势。

**AI_Comments:** MTDN的创新之处在于将语义分割任务转化为变化检测问题，并利用Siamese网络处理配对图像，有效解决了TEM图像分析中数据稀缺和特征模糊的难题。其多任务学习策略也进一步提升了性能。这对于需要高精度、自动化分析动态纳米材料行为的实验领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统深度学习语义分割方法在处理原位透射电镜（TEM）图像时面临数据标注稀缺、感兴趣特征视觉模糊以及小目标场景的限制，难以实现对动态演化特征的自动化、高精度语义分割。

**Method:** 提出MultiTaskDeltaNet（MTDN），一种将分割任务概念化为变化检测问题的深度学习架构。它采用独特的Siamese网络与U-Net骨干，通过配对图像捕获特征变化，有效利用少量数据生成高质量分割。此外，MTDN还利用多任务学习策略来利用感兴趣物理特征之间的相关性。

**Result:** 在对丝状碳气化原位环境TEM (ETEM) 视频数据的评估中，MTDN在准确描绘精细结构特征方面显著优于传统分割模型。尤其在预测小而视觉模糊的物理特征方面，MTDN比传统分割模型性能提升了10.22%。

**Conclusion:** 这项工作弥合了深度学习与实际TEM图像分析之间的几个关键差距，推动了复杂实验环境中纳米材料的自动化表征。

> **ai_Abstract:** 本文提出MultiTaskDeltaNet (MTDN)，一种创新的深度学习架构，通过将图像分割任务重新定义为变化检测问题，解决了原位TEM图像分割中数据稀缺和特征模糊的挑战。MTDN采用Siamese网络和多任务学习策略，能够利用少量数据生成高精度分割结果。在碳气化ETEM数据上的实验表明，MTDN在精细结构和模糊特征分割方面优于传统模型，性能提升显著，有助于推动纳米材料的自动化表征。

> **摘要翻译:** 将原位透射电子显微镜（TEM）成像转变为对固态反应进行空间分辨操作表征的工具，需要对动态演化特征进行自动化、高精度的语义分割。然而，传统的深度学习语义分割方法由于标记数据稀缺、感兴趣特征视觉模糊以及小目标场景等问题，常常遇到局限性。为了应对这些挑战，我们引入了MultiTaskDeltaNet（MTDN），一种新颖的深度学习架构，它创造性地将分割任务重新概念化为变化检测问题。通过实现一个独特的Siamese网络与U-Net骨干，并使用配对图像来捕获特征变化，MTDN有效地利用最少的数据来产生高质量的分割。此外，MTDN利用多任务学习策略来利用感兴趣物理特征之间的相关性。在对丝状碳气化原位环境TEM（ETEM）视频数据的评估中，MTDN展示出优于传统分割模型的显著优势，特别是在准确描绘精细结构特征方面。值得注意的是，MTDN在预测小而视觉模糊的物理特征方面比传统分割模型性能提升了10.22%。这项工作弥合了深度学习与实际TEM图像分析之间的几个关键差距，推动了复杂实验环境中纳米材料的自动化表征。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [562] [Now and Future of Artificial Intelligence-based Signet Ring Cell Diagnosis: A Survey](https://arxiv.org/abs/2311.10118)
> *人工智能在印戒细胞诊断的现状与未来：一项综述*

*Zhu Meng, Junhao Dong, Limei Guo, Fei Su, Jiaxuan Liu, Guangxi Wang, Zhicheng Zhao* | **Category: eess.IV, cs.CV, q-bio.QM** | **Updated: 2025-07-22**

**Keywords:** 印戒细胞, 人工智能, 诊断, 综述, 病理学

**Comment:** 

> **TL;DR:** 本综述系统回顾了2008年至2025年6月期间基于人工智能的印戒细胞分析方法，涵盖单模态和多模态算法，讨论了现有挑战和未来研究方向，旨在促进AI算法向临床实践的转化。

**AI_Comments:** 这是一篇非常有价值的综述性论文，其创新性在于首次系统性地梳理了AI在印戒细胞诊断领域的现有研究，填补了该领域缺乏全面回顾的空白。其重要性体现在为研究人员，尤其是非医学背景的AI专家，提供了清晰的路线图，帮助他们理解该领域的挑战和机遇，从而加速AI算法从实验室走向临床的转化。论文对算法的分类和对未来挑战的讨论，都为后续研究提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 印戒细胞（SRCs）的检测对临床决策和预后预测至关重要，但其诊断对病理学家而言极具挑战。尽管基于AI的自动化SRC诊断备受关注，但现有方法缺乏系统性综述，导致算法能力与临床适用性之间的差距难以评估。

**Method:** 本研究对2008年至2025年6月期间基于AI的印戒细胞分析进行了全面综述。系统总结了印戒细胞的生物学特性及其自动化识别的挑战。分析并将代表性算法分为单模态（图像、组学、文本数据）和多模态（整合两种或多种数据）方法。对基于图像的单模态算法进一步细分为分类、检测、分割和基础模型任务。

**Result:** 综述分析并分类了AI驱动的印戒细胞分析算法，包括单模态（图像、组学、文本数据）和多模态方法。其中，图像基的单模态算法被细分为分类、检测、分割和基础模型任务。通过评估当前方法学性能与临床辅助需求，讨论了未解决的挑战。

**Conclusion:** 本综述讨论了印戒细胞分析中未解决的挑战和未来的研究方向，旨在帮助研究人员（特别是无医学背景者）理解印戒细胞分析的现状和智能诊断的前景，从而加速计算算法向临床实践的转化。

> **ai_Abstract:** 本综述全面审视了2008年至2025年6月间基于人工智能的印戒细胞（SRC）诊断方法。鉴于SRC检测的挑战性及其对临床决策的重要性，论文旨在填补现有AI方法缺乏系统性回顾的空白。研究系统梳理了SRC的生物学特征和自动化识别的难题，并对AI算法进行了分类，包括基于图像、组学和文本数据的单模态方法，以及整合多种数据源的多模态方法。论文评估了当前方法的临床适用性，并指出了未来研究方向和未解决的挑战，以期推动AI算法在临床实践中的转化应用。

> **摘要翻译:** 印戒细胞（SRCs）与高外周转移倾向和不良预后相关，对手术决策和结果预测具有关键影响。然而，即使对于经验丰富的病理学家来说，其检测仍然具有挑战性。尽管基于人工智能（AI）的自动化SRC诊断因其提高诊断效率和准确性的潜力而受到越来越多的关注，但现有方法缺乏系统性综述。这一空白阻碍了算法能力与临床适用性之间差异的评估。本文对2008年至2025年6月期间AI驱动的SRC分析进行了全面综述。我们系统总结了SRCs的生物学特性及其自动化识别的挑战。分析并将代表性算法分为单模态或多模态方法。对包含图像、组学和文本数据的单模态算法进行了回顾；基于图像的算法进一步细分为分类、检测、分割和基础模型任务。多模态算法整合了两种或多种数据模态（图像、组学和文本）。最后，通过评估当前方法学性能与临床辅助要求，我们讨论了SRC分析中未解决的挑战和未来的研究方向。本综述旨在帮助研究人员，特别是那些没有医学背景的研究人员，了解SRC分析的现状和智能诊断的前景，从而加速计算算法向临床实践的转化。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [602] [FLLIC: Functionally Lossless Image Compression](https://arxiv.org/abs/2401.13616)
> *FLLIC：功能无损图像压缩*

*Xi Zhang, Xiaolin Wu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 功能无损图像压缩, 联合去噪, 图像压缩, 无损编码

**Comment:** 

> **TL;DR:** 本文提出功能无损图像压缩（FLLIC）新范式，通过联合去噪和压缩来克服传统数学无损压缩的性能瓶颈，旨在更好地重建潜在的无噪声原始图像，并实现更低的计算成本。

**AI_Comments:** 这篇论文的创新点在于它挑战了传统数学无损压缩的理念，即在图像本身含有噪声的情况下，坚持保留所有比特（包括噪声）的必要性。通过引入“功能无损”的概念，并结合去噪与压缩，该方法提供了一种更实用、更高效的图像处理方案，尤其适用于实际应用中图像常带有噪声的场景。这种范式转变对于图像压缩领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数学无损图像压缩（MLLIC）比率未能满足大多数实际成像和视觉系统的带宽和成本效益要求。作者质疑在所有数字成像传感器都存在采集噪声的情况下，坚持数学无损编码（即浪费比特来保留噪声）的必要性。

**Method:** 提出一种名为功能无损图像压缩（FLLIC）的新范式，它是一种联合去噪和压缩的方法。FLLIC通过对最佳去噪图像进行无损压缩来实现，其目标是实现潜在无噪声原始图像的最佳重建，即使这在字面上对带噪声输入而言并非无损。

**Result:** 实验表明，FLLIC在带噪声图像的联合去噪和压缩方面达到了最先进的性能，并且计算成本更低。

**Conclusion:** FLLIC通过在压缩前对图像进行去噪处理，能够更有效地重建图像的本质内容（无噪声部分），克服了传统数学无损压缩的局限性，实现了性能提升和成本降低。

> **ai_Abstract:** 本文提出了一种名为功能无损图像压缩（FLLIC）的新范式，旨在解决传统数学无损图像压缩（MLLIC）在处理含噪声图像时效率不高的问题。FLLIC通过对最优去噪图像进行无损压缩，目标是重建潜在的无噪声原始图像，而非简单地保留所有输入信息（包括噪声）。实验证明，FLLIC在联合去噪和压缩方面表现出最先进的性能，并降低了计算成本。

> **摘要翻译:** 近期，用于无损图像编码的深度神经网络（DNN）模型在压缩性能上已超越了传统方法，使自然彩色图像的无损比特率降低了约百分之十。但即便有这些进展，自然图像的数学无损图像压缩（MLLIC）比率仍未能满足当前及未来大多数实际成像和视觉系统的带宽和成本效益要求。为了克服MLLIC的性能障碍，我们质疑MLLIC的必要性。考虑到所有数字成像传感器都存在采集噪声，我们为什么要坚持数学无损编码，即浪费比特来保留噪声呢？相反，我们提出了一种联合去噪和压缩的新范式，称为功能无损图像压缩（FLLIC），它对最佳去噪图像（最优性可能是任务特定的）执行无损压缩。尽管FLLIC在字面上对带噪声输入而言并非无损，但其目标是实现潜在无噪声原始图像的最佳可能重建。大量实验表明，FLLIC在带噪声图像的联合去噪和压缩方面达到了最先进的性能，并且计算成本更低。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [644] [Recurrent Inference Machine for Medical Image Registration](https://arxiv.org/abs/2406.13413)
> *医用图像配准的循环推理机*

*Yi Zhang, Yidong Zhao, Hui Xue, Peter Kellman, Stefan Klein, Qian Tao* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 医学图像配准, 深度学习, 循环推理, 元学习, 数据效率

**Comment:** Preprint version. Accepted by Medical Image Analysis

> **TL;DR:** RIIR是一种循环推理元学习图像配准网络，通过学习优化更新规则，解决了深度学习配准方法在准确性和数据效率上的不足，并在少量数据下表现优异。

**AI_Comments:** 该论文的创新之处在于将循环推理机制应用于医学图像配准中的元学习框架，有效地解决了深度学习方法在配准精度和大数据需求方面的痛点。通过学习优化更新规则，RIIR不仅提高了配准准确性，而且显著提升了数据效率，这对于医学图像领域中数据获取困难的场景尤为重要。其在仅使用少量数据下超越现有方法的表现，凸显了该方法的实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习医学图像配准方法虽然具有灵活建模和快速推理的优势，但可能以牺牲推理时的配准性能为代价，并且通常需要大量的训练数据集，而传统优化方法是免训练的。为了提高配准精度和数据效率，本文提出了新的方法。

**Method:** 本文提出了一种名为循环推理图像配准（RIIR）网络的新型图像配准方法。RIIR被设计为一种迭代的元学习求解器，通过学习优化的更新规则，结合隐式正则化和显式梯度输入，来解决配准精度和数据效率问题。

**Result:** RIIR在脑部MRI和定量心脏MRI数据集上进行了广泛评估，结果表明，即使仅使用5%的训练数据，RIIR也优于一系列基于深度学习的方法，展示了高数据效率。消融研究的关键发现强调了循环推理框架中引入的隐藏状态对元学习的重要附加价值。

**Conclusion:** 本文提出的RIIR为基于深度学习的医学图像配准提供了一个高度数据高效的框架。

> **ai_Abstract:** 本文提出了一种名为循环推理图像配准（RIIR）的新型深度学习方法，旨在解决现有深度学习医学图像配准方法在准确性和数据效率方面的不足。RIIR被设计为一个元学习求解器，通过学习优化的更新规则，并结合隐式正则化和显式梯度输入，以迭代方式提高配准性能。实验证明，RIIR在脑部和心脏MRI数据集上表现出色，即使仅使用少量训练数据（5%），其性能也优于其他深度学习方法，显示出显著的数据效率。研究还强调了循环推理框架中隐藏状态的重要性。

> **摘要翻译:** 图像配准对于医学图像应用至关重要，它需要对多个图像中的体素进行对齐，以便进行定性或定量分析。随着深度神经网络和并行计算的最新进展，基于深度学习的医学图像配准方法凭借其灵活的建模和快速推理能力而具有竞争力。然而，与传统的基于优化的配准方法相比，速度优势可能以牺牲推理时的配准性能为代价。此外，深度神经网络理想情况下需要大型训练数据集，而基于优化的方法是免训练的。为了提高配准精度和数据效率，我们提出了一种新颖的图像配准方法，称为循环推理图像配准（RIIR）网络。RIIR被设计为以迭代方式解决配准问题的元学习求解器。RIIR通过学习优化的更新规则，结合隐式正则化和显式梯度输入，解决了精度和数据效率问题。我们在脑部MRI和定量心脏MRI数据集上，在配准精度和训练数据效率方面对RIIR进行了广泛评估。我们的实验表明，即使仅使用5%的训练数据，RIIR也优于一系列基于深度学习的方法，展示了高数据效率。我们消融研究的关键发现强调了循环推理框架中引入的隐藏状态对元学习的重要附加价值。我们提出的RIIR为基于深度学习的医学图像配准提供了一个高度数据高效的框架。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [692] [Investigation of unsupervised and supervised hyperspectral anomaly detection](https://arxiv.org/abs/2408.07114)
> *高光谱异常检测中的无监督与有监督方法研究*

*Mazharul Hossain, Aaron Robinson, Lan Wang, Chrysanthe Preza* | **Category: eess.IV, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 高光谱异常检测, 无监督学习, 有监督学习, 模型堆叠, 集成学习

**Comment:** Published in Proceedings Volume 13138, Applications of Machine
  Learning 2024; 1313817 (2024). Event: Optical Engineering + Applications,
  2024, San Diego, California, United States

> **TL;DR:** 本文评估了在高光谱异常检测中，结合无监督和有监督方法的混合模型以及其他方法，以提供新的见解。

**AI_Comments:** 本文探讨了高光谱异常检测领域中监督与无监督方法的结合，尤其关注如何克服传统监督方法在检测未知模式方面的局限性。通过评估其提出的混合模型，该研究旨在为HS-AD提供更深入的理解和新颖的视角。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱异常检测（HS-AD）在农业、环境和军事应用中至关重要，但传统的有监督方法难以检测新颖或未知模式。因此，需要评估和改进HS-AD技术。

**Method:** 作者回顾了他们之前的工作：首先设计了一个包含高光谱解混和三种无监督HS-AD算法的等权投票集成模型；随后利用有监督分类器确定投票权重，创建了一个异构无监督HS-AD算法与有监督分类器相结合的模型堆叠方法。在本文中，他们评估了这种技术以及其他有监督和无监督方法。

**Result:** 本文评估了作者提出的混合技术以及其他有监督和无监督的高光谱异常检测方法，旨在利用通用高光谱数据提供新见解。

**Conclusion:** 本文通过对现有技术和多种有监督与无监督高光谱异常检测方法的评估，旨在克服有监督方法在检测新颖模式上的局限性，并为该领域提供新的见解。

> **ai_Abstract:** 本文研究了高光谱异常检测（HS-AD）方法，HS-AD在农业、环境和军事领域具有重要应用。作者回顾了他们之前的工作，包括一个结合高光谱解混和无监督HS-AD算法的集成模型，以及后来通过有监督分类器优化投票权重的混合模型，该模型曾提高了检测精度。鉴于有监督方法在检测新颖模式上的局限性，本研究旨在通过评估其自身技术以及其他有监督和无监督方法，使用通用高光谱数据，以期提供新的见解。

> **摘要翻译:** 高光谱感知是检测异常和区分场景中材料的宝贵工具。高光谱异常检测（HS-AD）有助于表征捕获的场景，并将其分为异常和背景类别。它在农业、环境和军事应用（如RSTA（侦察、监视和目标获取）任务）中至关重要。我们之前设计了一个高光谱解混和三种无监督HS-AD算法的等权投票集成模型。后来，我们利用一个有监督分类器来确定投票集成的权重，创建了一个异构无监督HS-AD算法与有监督分类器相结合的模型堆叠混合体，这提高了检测精度。然而，有监督分类方法通常无法检测到与之前所见模式显著偏离的新颖或未知模式。在这项工作中，我们使用通用高光谱数据评估了我们的技术以及其他有监督和无监督方法，以提供新的见解。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [717] [Systole-Conditioned Generative Cardiac Motion](https://arxiv.org/abs/2507.15894)
> *舒张期条件下的生成式心脏运动*

*Shahar Zuler, Gal Lifshitz, Hadar Averbuch-Elor, Dan Raviv* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-20**

**Keywords:** 心脏运动估计, 生成式模型, 条件变分自编码器, CT成像, 数据增强

**Comment:** 

> **TL;DR:** 提出一种基于条件变分自编码器（CVAE）的新方法，通过生成3D流场来合成带有密集运动标注的心脏CT图像对，以解决心脏运动估计中缺乏标注数据的问题。

**AI_Comments:** 这篇论文通过引入一种基于CVAE的生成式方法来合成带有密集运动标注的心脏CT图像对，创新性地解决了医学图像分析中数据标注稀缺的挑战。其重要性在于，该方法能够为心脏运动估计模型提供丰富且逼真的合成训练数据，从而降低了对昂贵且耗时的人工标注的依赖，有望推动心脏功能评估和手术规划领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 心脏CT图像中的精确运动估计对于评估心脏功能和手术规划至关重要，但现有数据驱动方法需要大量难以获取的密集地面真值运动标注数据。

**Method:** 提出一种新颖的方法，利用条件变分自编码器（CVAE），该CVAE包含一种多尺度特征条件机制，并经过训练以生成以单个CT帧为条件的3D流场。通过将生成的流场应用于给定帧进行形变，从而创建模拟真实心肌变形的帧对，这些帧对作为完全标注的数据样本，提供光流地面真值标注。

**Result:** 该方法能够合成逼真的、带有密集3D流场标注的心脏CT帧对，这些帧对可作为完全标注的数据样本，提供光流地面真值标注。

**Conclusion:** 所提出的数据生成流程能够实现更复杂、更精确的心肌运动模型的训练和验证，从而大大减少对手动标注的依赖。

> **ai_Abstract:** 这项研究提出了一种新颖的方法，利用条件变分自编码器（CVAE）生成带有密集3D流场标注的逼真心脏CT图像对。该方法旨在解决传统数据驱动方法在心脏运动估计中对大量手动标注数据的高度依赖问题，通过合成高质量的标注数据，为训练和验证更精确的心肌运动模型提供了可能，从而显著减少了对人工标注的需求。

> **摘要翻译:** 心脏计算机断层扫描（CT）成像中精确的运动估计对于评估心脏功能和手术规划至关重要。数据驱动方法已成为密集运动估计的标准方法，但它们依赖于大量带有密集地面真值（GT）运动标注的标记数据，而这些数据通常难以获取。为了解决这一限制，我们提出了一种新颖的方法，可以合成逼真的心脏CT帧对，并富含密集的3D流场标注。
我们的方法利用了一个条件变分自编码器（CVAE），该编码器包含一种新颖的多尺度特征条件机制，并经过训练以生成以单个CT帧为条件的3D流场。通过将生成的流场应用于给定帧进行形变，我们创建了模拟整个心动周期中心肌真实变形的帧对。这些帧对作为完全标注的数据样本，提供了光流地面真值标注。我们的数据生成流程可以实现更复杂、更精确的心肌运动模型的训练和验证，从而大大减少对手动标注的依赖。
我们的代码以及动画生成的样本和附加材料可在我们的项目页面获取：https://shaharzuler.github.io/GenerativeCardiacMotion_Page。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [742] [EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro](https://arxiv.org/abs/2507.15292)
> *EndoControlMag：基于周期性参考重置和分层组织感知双掩模控制的鲁棒内窥镜血管运动放大*

*An Wanga, Rulin Zhou, Mengya Xu, Yiru Ye, Longfei Gou, Yiting Chang, Hao Chen, Chwee Ming Lim, Jiankun Wang, Hongliang Ren* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 内窥镜血管运动放大, 周期性参考重置, 分层组织感知, 双掩模控制, 医疗图像处理

**Comment:** 

> **TL;DR:** EndoControlMag是一种新的、免训练的内窥镜血管运动放大框架，通过周期性参考重置和分层组织感知双掩模控制，显著提高了复杂内窥镜场景下的血管运动可视化精度和鲁棒性。

**AI_Comments:** EndoControlMag的创新之处在于其结合了周期性参考重置来解决传统运动放大中的误差累积问题，以及分层组织感知双掩模控制，能够自适应地处理血管核心和周围组织的不同特性。特别是其双模式软化策略，使其在面对复杂组织变形或不稳定光流时都能保持鲁棒性，这对于实际内窥镜手术场景具有重要意义。该框架免训练的特性也降低了其部署的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜手术中，观察细微的血管运动对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。

**Method:** 本文提出了EndoControlMag，一个免训练、基于拉格朗日的框架，专为内窥镜环境量身定制，实现了掩模条件下的血管运动放大。其包含两个关键模块：周期性参考重置（PRR）方案，将视频分成短的重叠片段，并动态更新参考帧，以防止误差累积同时保持时间一致性；以及分层组织感知放大（HTM）框架，采用双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，以在遮挡和视角变化下保持准确定位。然后，它对周围组织应用两种自适应软化策略之一：基于运动的软化（根据观察到的组织位移按比例调节放大强度）或基于距离的指数衰减（模拟生物力学衰减）。

**Result:** 在EndoVMM24数据集上对EndoControlMag进行了评估，该数据集涵盖了四种不同类型的手术和各种挑战性场景，包括遮挡、器械干扰、视角变化和血管变形。定量指标、视觉评估和专家外科医生评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，同时在挑战性手术条件下保持了鲁棒性。

**Conclusion:** EndoControlMag显著提高了复杂内窥镜场景下血管运动的可视化精度和视觉质量，并保持了鲁棒性，克服了现有方法在内窥镜手术中观察细微血管运动的挑战。

> **ai_Abstract:** 本文提出了EndoControlMag，一个免训练的拉格朗日框架，用于内窥镜血管运动放大。该方法通过周期性参考重置（PRR）解决误差累积问题，并通过分层组织感知放大（HTM）框架，利用预训练跟踪和双模式（运动或距离）软化策略，精确处理血管核心和周围组织。在EndoVMM24数据集上的评估表明，EndoControlMag在放大精度和视觉质量方面均显著优于现有方法，并在复杂手术条件下保持鲁棒性，有效提升了内窥镜手术中细微血管运动的可视化效果。

> **摘要翻译:** 在内窥镜手术中，观察细微的血管运动对于手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这仍然是一个挑战。为了解决这个问题，我们引入了EndoControlMag，一个免训练、基于拉格朗日的框架，专为内窥镜环境量身定制，实现了掩模条件下的血管运动放大。我们的方法具有两个关键模块：周期性参考重置（PRR）方案，它将视频分成短的重叠片段，并动态更新参考帧，以防止误差累积同时保持时间一致性；以及分层组织感知放大（HTM）框架，采用双模式掩模膨胀。HTM首先使用预训练的视觉跟踪模型跟踪血管核心，以在遮挡和视角变化下保持准确定位。然后，它对周围组织应用两种自适应软化策略之一：基于运动的软化，根据观察到的组织位移按比例调节放大强度，或基于距离的指数衰减，模拟生物力学力衰减。这种双模式方法适应了各种手术场景——基于运动的软化在复杂组织变形方面表现出色，而基于距离的软化在不可靠的光流条件下提供稳定性。我们在EndoVMM24数据集上评估了EndoControlMag，该数据集涵盖了四种不同类型的手术和各种挑战性场景，包括遮挡、器械干扰、视角变化和血管变形。定量指标、视觉评估和专家外科医生评估表明，EndoControlMag在放大精度和视觉质量方面显著优于现有方法，同时在挑战性手术条件下保持了鲁棒性。代码、数据集和视频结果可在https://szupc.github.io/EndoControlMag/获得。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [356] [Distributed Asynchronous Device Speech Enhancement via Windowed Cross-Attention](https://arxiv.org/abs/2507.16104)
> *基于窗口交叉注意的分布式异步设备语音增强*

*Gene-Ping Yang, Sebastian Braun* | **Category: eess.AS** | **Updated: 2025-07-21**

**Keywords:** 分布式语音增强, 异步设备, 窗口交叉注意力, 多麦克风, 时钟漂移

**Comment:** 

> **TL;DR:** 该研究提出了一种窗口交叉注意力模块，用于解决在动态会议环境中，麦克风设备之间存在时间延迟和时钟漂移导致的异步问题，并在异步麦克风设置下表现优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了窗口交叉注意力模块，解决了多麦克风系统中常见的异步问题，特别是时间延迟和时钟漂移，这在实际应用中非常重要。其方法对麦克风数量和排列的不变性增加了其实用性。通过在多种模型上超越TAC，证明了其方法的有效性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数多麦克风语音处理方法都依赖于时间同步的麦克风设置，然而在现实世界的动态会议场景中，设备之间存在时间延迟和时钟漂移，导致麦克风异步。在这种条件下，流行的多麦克风处理模块TAC表现不足，因此需要一种能处理异步麦克风的新方法。

**Method:** 提出了一种窗口交叉注意力模块，能够动态对齐所有麦克风之间的特征。该模块对麦克风的排列和数量具有不变性，并且可以轻松集成到现有模型中。此外，还为多说话人环境提出了一个最优训练目标。该方法在具有未知时间延迟和时钟漂移的多麦克风噪声混响环境中进行了评估。

**Result:** 实验结果表明，所提出的方法在iFaSNet和CRUSE模型上均优于TAC，并且具有更快的收敛速度和更好的学习效果。

**Conclusion:** 窗口交叉注意力模块在异步麦克风设置下表现出显著的有效性，成功解决了现有方法在处理时间异步麦克风方面的不足。

> **ai_Abstract:** 该论文针对现实世界中麦克风设备时间异步（存在延迟和时钟漂移）导致传统多麦克风语音增强方法（如TAC）失效的问题，提出了一种基于窗口交叉注意力（windowed cross-attention）的新模块。该模块能够动态对齐来自不同麦克风的特征，且对麦克风排列和数量不变，易于集成。同时，还提出了多说话人环境下的最优训练目标。实验结果表明，该方法在异步噪声混响环境下，在iFaSNet和CRUSE模型上均优于TAC，展示了其在处理异步麦克风设置方面的有效性和优越性。

> **摘要翻译:** 配备麦克风的个人设备数量不断增加，为在动态会议环境中将它们用作临时麦克风阵列提供了极大的灵活性和潜力。然而，大多数现有方法都是为时间同步的麦克风设置而设计的，这种情况在现实世界的会议场景中可能不成立，因为设备之间的时间延迟和时钟漂移各不相同。在这种条件下，我们发现变换-平均-连接（TAC），一个流行的神经多麦克风处理模块，在处理时间异步麦克风方面力不从心。为此，我们提出了一种窗口交叉注意力模块，能够动态对齐所有麦克风之间的特征。该模块对麦克风的排列和数量具有不变性，并且可以轻松集成到现有模型中。此外，我们提出了一种用于多说话人环境的最优训练目标。我们在具有未知时间延迟和时钟漂移的多麦克风噪声混响设置中评估了我们的方法。实验结果表明，我们的方法在iFaSNet和CRUSE模型上均优于TAC，提供了更快的收敛速度和改进的学习效果，证明了窗口交叉注意力模块在异步麦克风设置中的有效性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [398] [An approach to measuring the performance of Automatic Speech Recognition (ASR) models in the context of Large Language Model (LLM) powered applications](https://arxiv.org/abs/2507.16456)
> *衡量大型语言模型（LLM）驱动应用中自动语音识别（ASR）模型性能的一种方法*

*Sujith Pulikodan, Sahapthan K, Prasanta Kumar Ghosh, Visruth Sanka, Nihar Desai* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-22**

**Keywords:** 自动语音识别, 大型语言模型, 性能评估, 词错误率, 错误纠正

**Comment:** Accepted at INTERSPEECH 2025

> **TL;DR:** 传统ASR性能评估方法WER在LLM驱动应用中可能不适用，本文分析LLM纠错能力并提出新的ASR性能衡量方法。

**AI_Comments:** 这篇论文的创新点在于认识到LLM在处理ASR输出时可能具有纠错能力，并提出了一种更符合LLM时代ASR应用需求的性能评估新范式。这对于优化LLM驱动系统中的语音交互体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统ASR性能评估指标词错误率（WER）未能充分考虑大型语言模型（LLM）作为核心处理组件时，不同类型ASR错误对下游任务的影响。随着LLM的广泛应用，需要探索ASR错误的重要性并提出新的评估方法。

**Method:** 本文分析了大型语言模型（LLM）纠正自动语音识别（ASR）引入错误的能力，并提出了一种新的衡量ASR性能的方法，专为LLM驱动的应用设计。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文指出，在大型语言模型（LLM）驱动的应用背景下，传统的自动语音识别（ASR）性能评估指标词错误率（WER）可能不再适用。作者分析了LLM纠正ASR错误的能力，并提出了一种新的ASR性能衡量方法，以更好地评估ASR在LLM集成系统中的表现。

> **摘要翻译:** 自动语音识别（ASR）在人机交互中扮演着至关重要的角色，并作为各种应用的接口。传统上，ASR性能通过词错误率（WER）进行评估，该指标量化了生成转录中插入、删除和替换的数量。然而，随着大型强大的大型语言模型（LLM）作为各种应用的核心处理组件被越来越多地采用，不同类型的ASR错误在下游任务中的重要性值得进一步探索。在这项工作中，我们分析了LLM纠正ASR引入错误的能力，并提出了一种新的衡量ASR性能的方法，适用于由LLM驱动的应用。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [608] [ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting](https://arxiv.org/abs/2504.20630)
> *ISDrama: 沉浸式空间戏剧通过多模态提示生成*

*Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Tao Jin, Zhou Zhao* | **Category: eess.AS, cs.MM, cs.SD** | **Updated: 2025-07-22**

**Keywords:** 沉浸式空间戏剧, 多模态提示, 双耳语音, 戏剧韵律, 数据集

**Comment:** Accepted by ACM Multimedia 2025

> **TL;DR:** ISDrama是首个通过多模态提示生成沉浸式空间戏剧的模型，解决了现有方法在空间信息和戏剧韵律建模上的挑战，并构建了首个多模态空间戏剧数据集MRSDrama。

**AI_Comments:** 这篇论文的创新点在于它是首个尝试解决多模态沉浸式空间戏剧生成挑战的工作，并为此构建了专门的数据集MRSDrama。其提出的ISDrama模型结合了对比学习、mamba-transformer和MOE等先进技术，有效处理了空间信息和戏剧韵律的复杂建模问题，对AR/VR等沉浸式应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在基于多模态提示生成连续多说话者双耳语音与戏剧韵律的沉浸式空间戏剧方面面临挑战，需要同时建模空间信息和戏剧韵律，且数据收集成本高昂。本文是首次尝试解决这些挑战。

**Method:** 本文构建了首个多模态录制空间戏剧数据集MRSDrama，包含双耳戏剧音频、剧本、视频、几何姿态和文本提示。在此基础上，提出了首个通过多模态提示生成沉浸式空间戏剧的模型ISDrama。ISDrama主要包括：1) 多模态姿态编码器，基于对比学习，考虑移动说话者引起的多普勒效应，以从多模态提示中提取统一的姿态信息。2) 沉浸式戏剧Transformer，一个基于流的mamba-transformer模型，用于生成高质量戏剧，结合Drama-MOE以选择合适的专家来增强韵律和姿态控制。此外，还设计了一种上下文一致的无分类器引导策略，以连贯地生成完整的戏剧。

**Result:** 实验结果表明，ISDrama在客观和主观指标上均优于基线模型。

**Conclusion:** ISDrama是首个解决沉浸式空间戏剧生成挑战的模型，通过构建新的多模态数据集和创新的模型架构（包括多模态姿态编码器和沉浸式戏剧Transformer），实现了高质量的多说话者双耳语音生成，并在实验中表现出色。

> **ai_Abstract:** 本文介绍了ISDrama，一个开创性的多模态沉浸式空间戏剧生成模型。针对现有技术在空间信息和戏剧韵律建模方面的挑战，作者首次构建了MRSDrama数据集。ISDrama模型包含多模态姿态编码器和沉浸式戏剧Transformer，并结合了上下文一致的引导策略，旨在从多模态提示中生成高质量的连续多说话者双耳戏剧语音。实验结果表明ISDrama在生成效果上显著优于基线模型。

> **摘要翻译:** 多模态沉浸式空间戏剧生成旨在基于多模态提示创建具有戏剧韵律的连续多说话者双耳语音，在AR、VR等领域具有潜在应用。这项任务需要根据多模态输入同时建模空间信息和戏剧韵律，且数据收集成本高昂。据我们所知，我们的工作是首次尝试解决这些挑战。我们构建了MRSDrama，这是首个多模态录制空间戏剧数据集，包含双耳戏剧音频、剧本、视频、几何姿态和文本提示。随后，我们提出了ISDrama，这是首个通过多模态提示生成沉浸式空间戏剧的模型。ISDrama包含以下主要组件：1）多模态姿态编码器，基于对比学习，考虑移动说话者引起的多普勒效应，以从多模态提示中提取统一的姿态信息。2）沉浸式戏剧Transformer，一个基于流的mamba-transformer模型，用于生成高质量戏剧，结合Drama-MOE选择合适的专家以增强韵律和姿态控制。我们还设计了一种上下文一致的无分类器引导策略，以连贯地生成完整的戏剧。实验结果表明，ISDrama在客观和主观指标上均优于基线模型。演示可在https://aaronz345.github.io/ISDramaDemo获取。我们还在https://huggingface.co/datasets/AaronZ345/MRSDrama和https://github.com/AaronZ345/ISDrama提供了数据集和评估代码。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [650] [MDDM: A Multi-view Discriminative Enhanced Diffusion-based Model for Speech Enhancement](https://arxiv.org/abs/2505.13029)
> *MDDM：一种用于语音增强的多视角判别增强扩散模型*

*Nan Xu, Zhaolong Huang, Xiaonan Zhi* | **Category: eess.AS** | **Updated: 2025-07-22**

**Keywords:** 语音增强, 扩散模型, 多视角, 判别式, 深度学习

**Comment:** 5 pages, 2 figures; Accepted by Interspeech 2025

> **TL;DR:** MDDM是一种结合多视角判别与扩散模型的语音增强方法，通过多域特征输入和少量采样步实现高效且高质量的语音重建，解决了传统方法的失真和高计算成本问题。

**AI_Comments:** 该论文的创新之处在于将多视角判别学习与扩散模型相结合，以提高语音增强的效率（减少采样步骤）并降低失真。这种混合方法在语音增强领域显示出巨大的潜力，为解决现有扩散模型计算成本高的问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音增强方法（判别式监督学习或生成式建模）常引入语音失真或计算成本高昂。

**Method:** MDDM将时域、频域和噪声域的特征作为判别预测网络的输入，生成初步语谱图。然后，通过少量推理采样步骤将判别输出转换为纯净语音。其核心在于利用判别输出与纯净目标之间分布的交集，以更少的采样步骤达到有竞争力的性能。

**Result:** 在公共数据集和真实世界数据集上进行的实验验证了MDDM在主观和客观指标上的有效性。

**Conclusion:** MDDM是一种有效且高效的语音增强模型，能够克服现有方法的局限性，在语音质量和计算效率上取得良好平衡。

> **ai_Abstract:** 本文提出了一种名为MDDM的多视角判别增强扩散模型，旨在解决现有语音增强方法中常见的语音失真和高计算成本问题。MDDM通过将时域、频域和噪声域的特征作为判别预测网络的输入，生成初步语谱图，并能通过少量推理采样步骤将其转换为纯净语音。该模型的创新点在于利用判别输出与纯净目标分布的交集，实现在减少采样步骤的同时保持高性能。实验结果在公共和真实世界数据集上均验证了MDDM在主观和客观指标上的有效性。

> **摘要翻译:** 随着深度学习的发展，语音增强在语音质量方面得到了极大的优化。以往的方法通常侧重于判别式监督学习或生成式建模，这往往会引入语音失真或高计算成本。在本文中，我们提出了MDDM，一种多视角判别增强扩散模型。具体来说，我们将三个域（时间、频率和噪声）的特征作为判别预测网络的输入，生成初步语谱图。然后，通过几个推理采样步骤可以将判别输出转换为纯净语音。由于判别输出和纯净目标之间分布的交集，较小的采样步骤可以实现与其它基于扩散的方法相当的性能。在公共数据集和真实世界数据集上进行的实验验证了MDDM在主观和客观指标上的有效性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [9] [RAVine: Reality-Aligned Evaluation for Agentic Search](https://arxiv.org/abs/2507.16725)
> *RAVine：面向智能体搜索的现实对齐评估*

*Yilong Xu, Xiang Long, Zhi Zheng, Jinhua Gao* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-22**

**Keywords:** 智能体搜索, 评估框架, 现实对齐, 大型语言模型, 迭代过程

**Comment:** 

> **TL;DR:** 现有智能体搜索评估框架存在不真实查询、真值噪声和忽视迭代过程的问题。本文提出了RAVine，一个现实对齐的评估框架，以解决这些问题，并对模型进行基准测试以获得见解。

**AI_Comments:** 该论文创新性地提出了一个更贴近实际用户意图和智能体搜索迭代特性的评估框架RAVine，解决了现有评估框架在查询真实性、真值准确性和过程评估方面的不足。其引入可归因真值构建和关注交互效率的特点，对于推动智能体搜索的实际应用和发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能体搜索作为一种更自主、适应性强的检索增强范式，正在推动智能搜索系统的发展。然而，现有的评估框架未能很好地与智能体搜索的目标对齐，具体表现为：1. 当前基准测试中使用的复杂查询偏离了真实用户搜索场景；2. 先前方法在提取端到端评估的真值时引入噪声，导致细粒度评估失真；3. 大多数当前框架只关注最终答案的质量，忽视了智能体搜索固有的迭代过程的评估。

**Method:** 为解决现有评估框架的限制，本文提出了RAVine——一个用于带搜索功能的智能体大型语言模型（LLMs）的现实对齐评估框架。RAVine通过以下方式实现：1. 针对多点查询和长篇答案，以更好地反映用户意图；2. 引入可归因的真值构建策略，以提高细粒度评估的准确性；3. 检查模型在整个迭代过程中与搜索工具的交互，并考虑效率因素。

**Result:** 作者使用RAVine对一系列模型进行了基准测试，并得出了几项见解。

**Conclusion:** 作者希望这些通过RAVine获得的见解将有助于推动智能体搜索系统的发展。

> **ai_Abstract:** 本文提出了RAVine，一个面向智能体搜索LLMs的现实对齐评估框架，旨在解决现有评估框架中存在的查询不真实、真值噪声和忽视迭代过程的问题。RAVine通过关注多点查询和长篇答案、引入可归因的真值构建策略，并评估模型在迭代过程中与搜索工具的交互及效率来提升评估的准确性和全面性。研究者使用RAVine对模型进行了基准测试，并获得了有助于智能体搜索系统发展的见解。

> **摘要翻译:** 智能体搜索作为一种更自主、适应性强的检索增强范式，正在推动智能搜索系统的发展。然而，现有的评估框架未能很好地与智能体搜索的目标对齐。首先，当前基准测试中常用的复杂查询通常偏离真实的用例搜索场景。其次，先前的方法在提取端到端评估的真值时倾向于引入噪声，导致细粒度评估失真。第三，大多数当前框架只关注最终答案的质量，忽视了智能体搜索固有的迭代过程的评估。为了解决这些限制，我们提出了RAVine——一个用于带搜索功能的智能体大型语言模型（LLMs）的现实对齐评估框架。RAVine针对多点查询和长篇答案，这些更好地反映了用户意图，并引入了一种可归因的真值构建策略，以提高细粒度评估的准确性。此外，RAVine检查了模型在整个迭代过程中与搜索工具的交互，并考虑了效率因素。我们使用RAVine对一系列模型进行了基准测试，并得出了一些见解，我们希望这些见解将有助于推动智能体搜索系统的发展。代码和数据集可在https://github.com/SwordFaith/RAVine获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [14] [PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning](https://arxiv.org/abs/2507.16424)
> *PromptAL：面向少样本主动学习的样本感知动态软提示*

*Hui Xiang, Jinqiao Shi, Ting Zhang, Xiaojie Zhao, Yong Liu, Yong Ma* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 主动学习, 少样本学习, 软提示, 样本选择, 决策边界

**Comment:** 

> **TL;DR:** PromptAL提出了一种新的主动学习框架，通过利用未标记数据构建样本感知动态软提示来优化决策边界并选择更具代表性的样本，以解决少样本场景中经验分布与目标分布不一致的问题。

**AI_Comments:** PromptAL的创新点在于它认识到并利用了未标记数据在少样本主动学习中校正经验分布的重要性。通过引入“样本感知动态软提示”这一机制来调整决策边界，它提供了一种新颖有效的方法来克服少样本限制，提升了主动学习的效率和样本选择质量。

<details>
  <summary>Details</summary>

**Motivation:** 在少样本主动学习场景中，现有方法依赖于标记数据的经验分布来定义决策边界，但这种经验分布往往与目标分布显著偏离，导致决策边界次优，并选择出不能充分代表目标分布的样本。现有方法忽视了未标记样本在增强经验分布以更好地与目标分布对齐方面的作用。

**Method:** 论文提出了一个混合主动学习框架PromptAL。该框架首先利用未标记数据构建样本感知动态软提示，以调整模型的预测分布和决策边界。随后，基于调整后的决策边界，它将不确定性估计与全局和局部多样性相结合，以选择更能准确代表目标分布的高质量样本。

**Result:** 在六个域内数据集和三个域外数据集上的实验结果表明，PromptAL比九个基线方法取得了更优越的性能。

**Conclusion:** PromptAL通过有效利用未标记数据调整决策边界并结合不确定性与多样性选择样本，显著改善了少样本主动学习的性能，解决了经验分布与目标分布不一致的问题。

> **ai_Abstract:** 本文提出了一种名为PromptAL的混合主动学习框架，旨在解决少样本场景中经验分布与目标分布不一致导致决策边界次优的问题。PromptAL通过利用未标记数据构建样本感知动态软提示来优化模型的预测分布和决策边界。在此基础上，它结合不确定性估计和全局/局部多样性来选择更具代表性的高质量样本。实验证明，PromptAL在多个数据集上优于现有基线方法。

> **摘要翻译:** 主动学习（AL）旨在通过选择信息量最大的样本进行标注，从而优化模型训练并降低标注成本。通常，AL方法依赖于已标注数据的经验分布来定义决策边界，并进行不确定性或多样性估计，进而识别潜在的高质量样本。在少样本场景中，经验分布往往与目标分布显著偏离，导致决策边界偏离其最优位置。然而，现有方法忽视了未标注样本在增强经验分布以更好地与目标分布对齐方面的作用，从而导致次优的决策边界和选择了不能充分代表目标分布的样本。为了解决这个问题，我们提出了一个混合AL框架，名为PromptAL（用于少样本主动学习的样本感知动态软提示）。该框架考虑了每个未标注数据点在使当前经验分布与目标分布对齐方面的贡献，从而优化决策边界。具体而言，PromptAL首先利用未标注数据构建样本感知动态软提示，以调整模型的预测分布和决策边界。随后，基于调整后的决策边界，它将不确定性估计与全局和局部多样性相结合，以选择更能准确代表目标分布的高质量样本。在六个域内数据集和三个域外数据集上的实验结果表明，PromptAL比九个基线方法取得了更优越的性能。我们的代码库是公开可访问的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [25] [LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs](https://arxiv.org/abs/2507.16809)
> *LingBench++: 一个语言学知情的基准和推理框架，用于LLM的多步和跨文化推理*

*Da-Chen Lian, Ri-Sheng Huang, Pin-Er Chen, Chunki Lim, You-Kuan Lin, Guan-Yu Tseng, Zi-Cheng Yang, Shu-Kai Hsieh* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 语言模型, 基准测试, 跨文化推理, 多步推理, 语言学

**Comment:** 41 pages, 17 figures, 10 tables

> **TL;DR:** LingBench++是一个新的语言学知情基准和推理框架，旨在评估LLM在复杂、多步和跨文化语言任务上的表现，通过集成外部知识和迭代推理来提高准确性和可解释性。

**AI_Comments:** 这篇论文的创新点在于其提出的LingBench++基准不仅关注最终答案准确性，更提供了结构化推理轨迹和分步评估协议，极大地增强了对LLMs复杂推理过程的洞察。同时，它对跨文化和低资源语言的关注，以及引入结合外部知识和迭代推理的多智能体架构，为提升LLMs在语言学复杂任务上的表现和可解释性提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准仅关注最终答案准确性，无法有效评估大型语言模型（LLMs）在复杂语言任务上的多步和跨文化推理能力。本文旨在提供一个更全面、语言学知情且能提供推理轨迹的评估框架。

**Method:** 本文提出了LingBench++，一个语言学知情的基准和推理框架，灵感来源于国际语言学奥林匹克。它提供结构化推理轨迹、分步评估协议和90多种低资源及跨文化语言的丰富类型学元数据。此外，还开发了一个多智能体架构，整合了语法知识检索、工具增强推理和审慎假设检验。

**Result:** 通过对基线模型和提出的智能体模型的系统比较，研究表明配备外部知识源和迭代推理的模型在准确性和可解释性方面均优于单次通过方法。

**Conclusion:** LingBench++为推进大型语言模型中语言学基础、文化知情和认知合理的推理提供了全面的基础。

> **ai_Abstract:** LingBench++是一个创新的基准和推理框架，旨在评估大型语言模型（LLMs）在复杂、多步和跨文化语言任务上的能力。它通过提供结构化推理轨迹、分步评估协议以及涵盖90多种低资源语言的丰富类型学元数据，弥补了现有基准的不足。该框架还引入了一个多智能体架构，结合了语法知识检索、工具增强推理和假设检验。实验结果表明，采用外部知识和迭代推理的智能体模型在准确性和可解释性上均优于单一通过方法，为LLMs实现更深入的语言学和文化知情推理奠定了基础。

> **摘要翻译:** 我们提出了LingBench++，一个语言学知情的基准和推理框架，旨在评估大型语言模型（LLMs）在受国际语言学奥林匹克（IOL）启发的复杂语言任务上的表现。与以往只关注最终答案准确性的基准不同，LingBench++提供结构化推理轨迹、分步评估协议以及90多种低资源和跨文化语言的丰富类型学元数据。我们进一步开发了一种多智能体架构，整合了语法知识检索、工具增强推理和审慎假设检验。通过对基线模型和我们提出的智能体模型的系统比较，我们证明了配备外部知识源和迭代推理的模型在准确性和可解释性方面都优于单次通过方法。LingBench++为推进LLMs中语言学基础、文化知情和认知合理的推理提供了全面的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [38] [Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition](https://arxiv.org/abs/2507.05724)
> *Omni-Router：在稀疏混合专家模型中共享语音识别的路由决策*

*Zijin Gu, Tatiana Likhomanenko, Navdeep Jaitly* | **Category: cs.CL, cs.AI, cs.LG, cs.SD, eess.AS** | **Updated: 2025-07-21**

**Keywords:** 混合专家模型, 语音识别, 共享路由器, Omni-router Transformer, 词错误率

**Comment:** 

> **TL;DR:** Omni-Router通过在不同MoE层之间共享路由决策，提高了语音识别中MoE模型的性能、专家协作和数据鲁棒性。

**AI_Comments:** 本文的创新点在于提出了跨层共享路由器的概念，解决了传统MoE模型中专家独立决策导致协作不足的问题。这种方法不仅提高了模型性能，还增强了专家使用的结构化和对多样化数据的鲁棒性，对于稀疏MoE架构在ASR领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的MoE方法（如Switch Transformer）在每个层中独立路由专家，导致不同层之间路由器的专家选择相关性不强，未能充分促进专家间的合作和专业化。

**Method:** 提出了Omni-router Transformer模型，通过在不同MoE层之间使用共享路由器来增加专家间的合作并鼓励更大的专业化。

**Result:** 在大型伪标注数据集上，Omni-router Transformer的训练损失更低，并且在10个不同的域外ASR基准测试中持续优于密集模型和Switch Transformer模型，平均词错误率分别降低了11.2%和8.2%。同时，它提供了结构化的专家使用和对多样化数据改进的鲁棒性。

**Conclusion:** Omni-router通过共享路由决策，显著提升了MoE模型在语音识别任务上的性能、专家协作和对多样化数据的鲁棒性。

> **ai_Abstract:** 本论文提出了一种名为Omni-router Transformer的新型混合专家（MoE）架构，用于自动语音识别（ASR）。针对传统MoE模型中各层路由器独立决策导致专家协作不足的问题，Omni-router通过在不同MoE层之间共享路由决策，有效增强了专家间的合作与专业化。实验结果表明，该模型在训练损失、词错误率和数据鲁棒性方面均优于现有密集模型和Switch Transformer模型。

> **摘要翻译:** 混合专家（MoE）架构已从语言建模扩展到自动语音识别（ASR）。传统的MoE方法，例如Switch Transformer，在每个层内独立路由专家。我们的分析表明，大多数层中的路由器所做的专家选择与其它层中的路由器选择没有强相关性。为了增加不同层中专家之间的合作并鼓励更大的专业化，我们在不同的MoE层之间使用了一个共享路由器。我们称之为Omni-router Transformer模型。在大型伪标注数据集上进行的广泛实验以及对10个不同、域外ASR基准的评估表明，Omni-router Transformer能够实现更低的训练损失，并持续优于密集模型和Switch Transformer模型，分别将平均词错误率降低了11.2%和8.2%，同时提供了结构化的专家使用和对多样化数据改进的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [48] [Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback](https://arxiv.org/abs/2507.16007)
> *帮我写故事：评估大型语言模型生成写作反馈的能力*

*Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 大型语言模型, 写作反馈, 评估, 创意写作, 数据集

**Comment:** ACL 2025 main conference

> **TL;DR:** 本文探讨了大型语言模型（LLMs）在提供创意写作反馈方面的能力和局限性，发现LLMs在提供具体准确反馈方面表现良好，但在识别主要问题和判断反馈类型方面仍有不足。

**AI_Comments:** 本文通过提出新任务和受控数据集，为评估LLMs的写作反馈能力提供了一个新颖且系统的方法。其创新之处在于故意引入问题来测试模型的识别能力。研究结果揭示了当前LLMs在提供高级、上下文敏感反馈方面的局限性，这对于未来改进LLM在创意写作支持领域的应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型（LLMs）是否能通过提供有意义的写作反馈来支持创意作家，并识别其面临的挑战和局限性。

**Method:** 定义了一个新的任务、数据集和评估框架，以研究模型生成的写作反馈。构建了一个包含1,300个故意引入写作问题的故事测试集，并使用自动和人工评估指标研究了常用LLMs在该任务中的表现。

**Result:** 当前模型在许多方面表现出强大的开箱即用行为，能够提供具体且大多准确的写作反馈。然而，模型经常未能识别故事中最大的写作问题，也未能正确决定何时提供批评性或积极性反馈。

**Conclusion:** 尽管大型语言模型在提供写作反馈方面表现出潜力，尤其是在具体性和准确性方面，但它们在识别主要问题和判断反馈类型方面仍存在显著局限性。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）为创意写作提供反馈的能力。通过定义新任务、数据集和评估框架，并构建一个包含1,300个包含故意引入写作问题的故事测试集，作者评估了常用LLMs的表现。结果显示，LLMs在提供具体和准确的反馈方面表现良好，但在识别核心问题和判断反馈类型（批评性或积极性）方面仍存在不足。

> **摘要翻译:** 大型语言模型能否通过提供有意义的写作反馈来支持创意作家？在本文中，我们通过定义一项新任务、一个新数据集和评估框架，探讨了模型生成写作反馈的挑战和局限性。为了以受控方式研究模型性能，我们提出了一个包含1,300个故事的新颖测试集，这些故事被故意损坏以引入写作问题。我们通过自动和人工评估指标研究了常用大型语言模型在此任务中的表现。我们的分析表明，当前模型在许多方面表现出强大的开箱即用行为——提供具体且大多准确的写作反馈。然而，模型经常未能识别故事中最大的写作问题，也未能正确决定何时提供批评性或积极性反馈。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [49] [Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing](https://arxiv.org/abs/2404.14740)
> *建模神圣：在自然语言处理中使用宗教文本时的考量*

*Ben Hutchinson* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 宗教文本, 自然语言处理, 伦理, 模型偏见, 文化背景

**Comment:** Findings of NAACL2024

> **TL;DR:** NLP使用宗教文本时需要考虑模型偏见之外的伦理问题，如数据来源、文化背景和传教目的，并应关注研究者立场和边缘化社区的视角。

**AI_Comments:** 这篇论文创新性地将NLP伦理的讨论从常见的模型偏见扩展到更深层次的文化、历史和意图层面，特别关注了宗教文本的特殊性。它强调了数据来源和研究者立场的重要性，为NLP社区在处理敏感数据时提供了宝贵的伦理框架和反思方向。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言处理（NLP）研究中大量使用宗教文本，尤其是在语言数据稀缺时，这可能导致机器学习模型复制训练数据中编码的文化价值观。此外，宗教文本翻译的原始用途和动机（如吸引追随者）常被忽视，引发了超越模型偏见的伦理考量。

**Method:** 本文是一篇立场论文，通过论证指出在NLP中使用宗教文本时，应考虑数据来源、文化背景和传教目的等更深层次的问题，并呼吁研究人员更多地考量自身立场以及边缘化语言和宗教社区的视角。

**Result:** 论文指出，NLP使用宗教文本时，除了模型偏见，还应重点关注数据来源、文化背景及其在传教中的应用。文章强调了研究者自身立场以及边缘化语言和宗教社区视角的重要性。

**Conclusion:** 在自然语言处理中使用宗教文本时，研究人员应超越单纯的模型偏见考量，深入审视数据来源、文化背景及文本的原始意图（如传教），并特别关注研究者自身立场以及边缘化语言和宗教社区的观点。

> **ai_Abstract:** 本立场论文探讨了自然语言处理（NLP）中宗教文本使用的伦理问题。鉴于宗教文本承载文化价值且机器学习模型易复制训练数据中的文化偏见，以及宗教文本翻译的原始目的（如传教）常被忽视，论文认为NLP使用此类文本需考量数据来源、文化背景和传教用途，超越单纯的模型偏见。文章呼吁研究者审视自身立场，并重视边缘化语言和宗教社区的视角。

> **摘要翻译:** 这篇立场论文关注自然语言处理（NLP）中宗教文本的使用，这对于NLP伦理学具有特殊意义。宗教文本是文化重要价值观的表达，而机器学习模型倾向于复制其训练数据中编码的文化价值观。此外，当语言数据稀缺时，NLP研究人员经常使用宗教文本的翻译。这使得这些翻译偏离了其原始用途和动机，而这些用途和动机通常涉及吸引新的追随者。本文认为，NLP使用此类文本引发的考量超越了模型偏见，包括数据来源、文化背景及其在传教中的使用。我们主张更多地考量研究者立场以及边缘化语言和宗教社区的视角。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [57] [Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation](https://arxiv.org/abs/2507.16002)
> *在低语境下增强印地语命名实体识别：基于Transformer的模型在有无检索增强情况下的比较研究*

*Sumit Singh, Rohit Mishra, Uma Shanker Tiwary* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 印地语NER, 检索增强, Transformer模型, 低语境, 命名实体识别

**Comment:** 

> **TL;DR:** 本研究旨在改善低语境下的印地语命名实体识别（NER），通过比较基于Transformer的模型和生成模型在有无检索增强（RA）情况下的表现。结果显示RA能显著提升性能，尤其是在低语境数据上。

**AI_Comments:** 本论文解决了NLP领域中一个关键问题，即低资源语言（印地语）的命名实体识别。通过比较不同Transformer和生成模型在有无检索增强情况下的性能，提供了宝贵的见解。研究发现检索增强能显著提升性能，尤其对于低语境数据，这一点非常重要。同时，RA在不同生成模型（如GPT3.5-turbo与Llama2/3-70B）上的不同效果，也提示了在实际应用中需要谨慎选择和集成策略。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言处理中的一个主要挑战是命名实体识别（NER）。本研究旨在改进印地语NER技术，特别是在低语境数据和资源有限的语言中。

**Method:** 本研究调查了使用印地语特定预训练编码器（MuRIL和XLM-R）和生成模型（Llama-2-7B-chat-hf、Llama-2-70B-chat-hf、Llama-3-70B-Instruct和GPT3.5-turbo）的印地语NER技术。通过从外部相关语境（特别是维基百科）检索数据来增强数据。MuRIL、XLM-R和Llama2-7B在有无RA的情况下进行了微调。Llama2-70B、Llama3-70B和GPT3.5-turbo则用于少样本NER生成。

**Result:** 带有检索增强（RA）的语言模型（LMs）在大多数情况下优于未包含RA的基线方法。MuRIL和XLM-R在没有RA时的宏观F1分数分别为0.69和0.495，而在有RA时分别增加到0.70和0.71。微调后的Llama2-7B显著优于Llama2-7B。未微调的生成模型在使用增强数据时表现也更好。GPT3.5-turbo很好地采用了RA；然而，Llama2-70B和Llama3-70B没有采用我们的检索语境下的RA。研究结果表明，RA显著提高了性能，特别是对于低语境数据。

**Conclusion:** 检索增强（RA）显著提高了命名实体识别（NER）的性能，特别是在低语境数据和印地语等资源有限的语言中，这突出了数据增强方法和预训练模型的有效应用。

> **ai_Abstract:** 本研究旨在解决印地语命名实体识别（NER）在低语境下的挑战。论文比较了Transformer模型（MuRIL、XLM-R）和生成模型（Llama系列、GPT3.5-turbo）在有无检索增强（RA）情况下的性能。通过从维基百科等外部来源检索数据进行增强，研究发现RA普遍提升了NER性能，尤其对低语境数据效果显著。具体而言，MuRIL和XLM-R的F1分数在引入RA后有所提高，且微调后的Llama2-7B表现优异。尽管GPT3.5-turbo能有效整合RA，但Llama2-70B和Llama3-70B在所用检索语境下未能良好适应RA。研究最终强调RA是提升NER性能的有效策略，尤其适用于资源受限的语言。

> **摘要翻译:** 自然语言处理中的一个主要挑战是命名实体识别（NER），它识别并分类文本输入中的命名实体。为了改进NER，本研究调查了一种印地语NER技术，该技术利用印地语特有的预训练编码器（MuRIL和XLM-R）和生成模型（Llama-2-7B-chat-hf（Llama2-7B）、Llama-2-70B-chat-hf（Llama2-70B）、Llama-3-70B-Instruct（Llama3-70B）和GPT3.5-turbo），并用从外部相关语境（特别是维基百科）检索到的数据增强数据。我们对MuRIL、XLM-R和Llama2-7B进行了有无RA的微调。然而，Llama2-70B、Llama3-70B和GPT3.5-turbo用于少样本NER生成。我们的调查显示，上述语言模型（LMs）在大多数情况下，带有检索增强（RA）的表现优于未包含RA的基线方法。MuRIL和XLM-R在没有RA时的宏观F1分数分别为0.69和0.495，而在有RA时分别增加到0.70和0.71。微调后的Llama2-7B显著优于Llama2-7B。另一方面，未微调的生成模型在使用增强数据时表现也更好。GPT3.5-turbo很好地采用了RA；然而，Llama2-70B和Llama3-70B没有采用我们的检索语境下的RA。研究结果表明，RA显著提高了性能，特别是对于低语境数据。这项研究为如何最好地使用数据增强方法和预训练模型来提高NER性能，特别是在资源有限的语言中，增加了重要的知识。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [75] [Erasing Conceptual Knowledge from Language Models](https://arxiv.org/abs/2410.02760)
> *从语言模型中擦除概念知识*

*Rohit Gandikota, Sheridan Feucht, Samuel Marks, David Bau* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 概念遗忘, 语言模型, 模型编辑, 知识擦除, 机器遗忘

**Comment:** Project Page: https://elm.baulab.info

> **TL;DR:** 本文介绍了语言记忆擦除（ELM），一种从语言模型中选择性地擦除特定概念的方法，通过利用模型自身的评估能力实现，同时不损害其通用能力。

**AI_Comments:** 这项工作的创新之处在于利用语言模型自身的“内省分类能力”来实现概念级遗忘，这提供了一个新颖且有原则的方法来解决模型知识控制问题。其重要性在于为大型语言模型提供了精细化的知识管理能力，这对于解决偏见、隐私或有害内容生成等问题至关重要。该方法在擦除特定知识的同时，能够保持模型广泛能力和对对抗性攻击的鲁棒性，是其显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是为了实现语言模型的概念级遗忘，有效地从模型中移除不良概念的相关知识，同时保留其更广泛的能力。

**Method:** 本文提出了语言记忆擦除（ELM）方法，这是一种通过匹配模型自身内省分类能力定义的分布来实现概念级遗忘的原则性方法。它将语言模型本身用作分类器，以识别并降低生成与不良概念相关内容的可能性，并通过有针对性的低秩更新实现。

**Result:** ELM 修改后的模型在针对擦除概念的评估中实现了接近随机的性能，同时保持了生成连贯性，在无关任务上保持了基准性能，并对对抗性攻击表现出强大的鲁棒性。其有效性已在生物安全、网络安全和文学领域擦除任务中得到验证。

**Conclusion:** ELM 是一种有效且稳健的方法，用于语言模型的概念级遗忘，它在成功移除特定知识的同时，能够保持模型的通用能力。

> **ai_Abstract:** 本文提出了一种名为“语言记忆擦除”（ELM）的新型概念级遗忘方法，用于语言模型。ELM 利用模型自身的分类能力来识别并减少生成不良概念内容的可能性，通过有针对性的低秩更新实现。实验证明，ELM 能有效擦除特定知识（如生物安全、网络安全相关内容），同时保持模型的通用能力、生成连贯性以及对对抗性攻击的鲁棒性。

> **摘要翻译:** 在这项工作中，我们介绍了语言记忆擦除（ELM），这是一种基于模型自身内省分类能力所定义的分布匹配的概念级遗忘方法。我们的关键见解是，有效的遗忘应该利用模型评估自身知识的能力，将语言模型本身用作分类器来识别并降低生成与不良概念相关内容的可能性。ELM 应用此框架创建有针对性的低秩更新，以降低特定概念内容的生成概率，同时保留模型的更广泛能力。我们在生物安全、网络安全和文学领域擦除任务中展示了 ELM 的有效性。比较评估表明，ELM 修改后的模型在针对擦除概念的评估中实现了接近随机的性能，同时保持了生成连贯性，在无关任务上保持了基准性能，并对对抗性攻击表现出强大的鲁棒性。我们的代码、数据和训练模型可在 https://elm.baulab.info 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [85] [Reasoning Does Not Necessarily Improve Role-Playing Ability](https://arxiv.org/abs/2502.16940)
> *推理不一定能提升角色扮演能力*

*Xiachong Feng, Longxu Dou, Lingpeng Kong* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 角色扮演LLM, 推理, 思维链, 性能, 缩放定律

**Comment:** 

> **TL;DR:** 研究发现推理能力（如CoT和推理优化LLM）不一定能提升，甚至可能降低LLM的角色扮演能力。

**AI_Comments:** 本文通过大量实验，挑战了推理能力必然提升LLM角色扮演表现的普遍认知，并指出CoT和推理优化模型可能带来负面影响。这对于未来角色扮演LLM的研究方向具有重要指导意义，特别是提出了角色感知CoT和强化学习这两个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 角色扮演大型语言模型（LLM）的应用日益广泛，对高精度模型的需求增加。同时，推理技术快速发展。本研究旨在探讨推理技术能否增强LLM的角色扮演能力。

**Method:** 通过使用6个角色扮演基准、24个LLM和3种角色扮演策略（直接零样本、思维链CoT、推理优化LLM）进行综合研究，比较其有效性。

**Result:** CoT可能会降低角色扮演性能；推理优化的LLM不适合角色扮演；推理能力会扰乱角色扮演的缩放定律；大型模型在高级角色扮演方面仍缺乏熟练度；中文角色扮演性能优于英文。

**Conclusion:** 推理能力不一定能提升LLM的角色扮演性能，甚至可能降低。未来研究方向包括：角色感知CoT和强化学习，以提升角色扮演LLM的适应性、一致性和有效性。

> **ai_Abstract:** 本文研究了推理技术对大型语言模型（LLM）角色扮演能力的影响。通过对6个基准、24个LLM和3种策略的综合研究发现，思维链（CoT）可能降低角色扮演性能，推理优化的LLM不适合角色扮演，且推理能力会扰乱角色扮演的缩放定律。研究还指出大型模型在高级角色扮演方面仍有不足，且中文角色扮演表现优于英文。基于这些发现，文章提出了“角色感知思维链”和“强化学习”作为未来提升角色扮演LLM的两个研究方向。

> **摘要翻译:** 大型语言模型（LLM）的角色扮演应用在学术和商业领域都迅速扩展，对高精度角色扮演模型的需求日益增长。同时，推理技术的快速进步不断推动LLM的性能极限。实践中的角色扮演需求与不断发展的推理能力的这种交叉，提出了一个重要的研究问题：“推理技术能否增强LLM的角色扮演能力？”为了解决这个问题，我们使用6个角色扮演基准、24个LLM和3种不同的角色扮演策略进行了一项综合研究，比较了直接零样本角色扮演、使用思维链（CoT）的角色扮演以及使用推理优化LLM的角色扮演的有效性。我们的发现表明，CoT可能会降低角色扮演性能，推理优化的LLM不适合角色扮演，推理能力会扰乱角色扮演的缩放定律，大型模型在高级角色扮演方面仍然缺乏熟练度，并且中文角色扮演性能优于英文角色扮演性能。此外，基于大量的实验结果，我们提出了两个有前景的未来研究方向：用于改进角色扮演LLM的角色感知CoT，以及用于角色扮演LLM的强化学习，旨在增强角色扮演LLM的适应性、一致性和有效性，以满足研究和实际应用的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [94] [mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages](https://arxiv.org/abs/2507.16011)
> *mRAKL：面向低资源语言的多语言检索增强知识图谱构建*

*Hellina Hailu Nigatu, Min Li, Maartje ter Hoeve, Saloni Potdar, Sarah Chasins* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 多语言知识图谱构建, 检索增强生成, 低资源语言, 问答, mRAKL

**Comment:** Accepted to Findings of ACL 2025

> **TL;DR:** mRAKL将多语言知识图谱构建重构为问答任务，并使用检索增强生成（RAG）方法来预测缺失的实体和链接，尤其在低资源语言上表现出显著提升。

**AI_Comments:** 该论文的创新点在于将多语言知识图谱构建任务巧妙地转换为问答任务，并引入了检索增强生成（RAG）框架，这为处理低资源语言的知识图谱构建提供了一个新的有效途径。通过将知识检索与生成相结合，mRAKL能够利用外部信息来提高预测的准确性，尤其是在信息稀疏的低资源语言环境中。其重要性在于为多语言NLP和知识图谱领域提供了一种可扩展且性能优异的解决方案，对于促进低资源语言的数字资源建设具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 多语言知识图谱构建（mKGC）旨在自动构建或预测多语言环境下知识图谱中缺失的实体和链接。本文的动机是为低资源语言（如提格雷尼亚语和阿姆哈拉语）改进mKGC任务的性能。

**Method:** 本研究将多语言知识图谱构建（mKGC）任务重新定义为问答（QA）任务，并引入了mRAKL系统。mRAKL是一个基于检索增强生成（RAG）的系统，通过使用头实体和链接关系作为问题，让模型预测尾实体作为答案。实验主要针对提格雷尼亚语和阿姆哈拉语这两种低资源语言，并利用阿拉伯语和英语进行跨语言迁移。

**Result:** 使用BM25检索器时，基于RAG的方法比无上下文设置提高了性能。此外，消融研究表明，在理想化的检索系统下，mRAKL对提格雷尼亚语和阿姆哈拉语的准确率分别提高了4.92和8.79个百分点。

**Conclusion:** 基于检索增强生成（RAG）的mRAKL方法能够有效执行多语言知识图谱构建任务，尤其是在低资源语言上，并且检索增强显著提升了性能。

> **ai_Abstract:** 该论文提出了mRAKL，一个将多语言知识图谱构建（mKGC）重构为问答（QA）任务的检索增强生成（RAG）系统。mRAKL利用头实体和链接关系预测尾实体。实验主要针对低资源语言提格雷尼亚语和阿姆哈拉语，并利用高资源语言进行跨语言迁移。结果表明，RAG方法相较于无上下文设置表现更优，且在理想检索条件下，mRAKL显著提升了低资源语言的准确率。

> **摘要翻译:** 知识图谱表示现实世界中的实体及其之间的关系。多语言知识图谱构建（mKGC）是指在多语言环境下自动构建或预测知识图谱中缺失实体和链接的任务。在这项工作中，我们将mKGC任务重新定义为问答（QA）任务，并引入了mRAKL：一个基于检索增强生成（RAG）的系统来执行mKGC。我们通过将头实体和链接关系作为问题，让模型预测尾实体作为答案来实现这一点。我们的实验主要集中在两种低资源语言：提格雷尼亚语和阿姆哈拉语。我们尝试使用资源更丰富的阿拉伯语和英语进行跨语言迁移。使用BM25检索器，我们发现基于RAG的方法比无上下文设置提高了性能。此外，我们的消融研究表明，在理想化的检索系统下，mRAKL对提格雷尼亚语和阿姆哈拉语的准确率分别提高了4.92和8.79个百分点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [100] [Data Processing for the OpenGPT-X Model Family](https://arxiv.org/abs/2410.08800)
> *OpenGPT-X 模型家族的数据处理*

*Nicolo' Brandizzi, Hammam Abdelwahab, Anirban Bhowmick, Lennard Helmer, Benny Jörg Stein, Pavel Denisov, Qasid Saleem, Michael Fromm, Mehdi Ali, Richard Rutmann, Farzad Naderi, Mohamad Saif Agy, Alexander Schwirjow, Fabian Küch, Luzian Hahn, Malte Ostendorff, Pedro Ortiz Suarez, Georg Rehm, Dennis Wegener, Nicolas Flores-Herr, Joachim Köhler, Johannes Leveling* | **Category: cs.CL, H.3.1; I.2.7** | **Updated: 2025-07-22**

**Keywords:** 数据处理, 多语言LLM, OpenGPT-X, 数据准备, 欧洲数据法规

**Comment:** 

> **TL;DR:** 本文介绍了OpenGPT-X项目的数据准备流程，旨在为多语言大型语言模型创建高质量、符合法规的数据集，并分享了经验和挑战。

**AI_Comments:** 这篇论文的创新点在于其针对大规模、多语言LLM数据准备的全面性，特别是区分并处理精选数据和网络数据的策略，以及对符合欧洲数据法规的重视。其重要性体现在为未来开放、高性能多语言LLM的开发提供了宝贵的数据工程经验和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** OpenGPT-X项目旨在创建开放、高性能的多语言大型语言模型（LLMs），覆盖所有主要的欧洲语言，并专注于在欧盟的实际应用。因此，需要一个全面的数据准备流程来支持这一目标。

**Method:** 本文介绍了OpenGPT-X项目的数据准备管道，涵盖从数据选择、需求定义到最终过滤数据准备的所有步骤。该方法区分了精选数据和网络数据，并为每种类型设计了不同的处理管道：精选数据经过最少过滤，而网络数据则需要广泛的过滤和去重，并为此开发了专门的算法解决方案。此外，还对数据集进行了深入分析，以提高透明度并符合欧洲数据法规。

**Result:** 本文成功开发并概述了一个全面的数据准备流程，能够有效处理精选数据和网络数据，并提供符合欧洲数据法规的数据集。论文还分享了项目期间遇到的关键见解和挑战。

**Conclusion:** 论文总结了在大规模多语言LLM数据准备项目中的关键见解和挑战，并为未来相关工作提供了建议。

> **ai_Abstract:** 本文详细介绍了为OpenGPT-X项目构建的多语言大型语言模型数据准备流程。该流程涵盖从数据选择到最终过滤的完整步骤，并根据数据类型（精选数据和网络数据）设计了不同的处理管道，其中网络数据需要更严格的过滤和去重。论文还强调了数据分析在提高透明度和符合欧洲数据法规方面的重要性，并分享了项目经验和对未来工作的建议。

> **摘要翻译:** 本文全面概述了为OpenGPT-X项目开发的数据准备管道，该项目是一项旨在创建开放和高性能多语言大型语言模型（LLM）的大规模倡议。该项目目标是提供覆盖所有主要欧洲语言的模型，特别关注欧盟内部的实际应用。我们解释了所有数据处理步骤，从数据选择和需求定义到最终过滤数据的准备。我们区分了精选数据和网络数据，因为这些类别由不同的管道处理，其中精选数据经过最少过滤，而网络数据需要大量过滤和去重。这种区别指导了为这两个管道开发专门的算法解决方案。除了描述处理方法外，我们还对数据集进行了深入分析，以提高透明度并符合欧洲数据法规。最后，我们分享了项目期间面临的关键见解和挑战，为未来大规模多语言LLM数据准备工作提供了建议。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [104] [MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning](https://arxiv.org/abs/2507.16812)
> *MegaScience：推动科学推理的后训练数据集前沿*

*Run-Ze Fan, Zengzhi Wang, Pengfei Liu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 科学推理, 数据集, MegaScience, TextbookReasoning, 大型语言模型

**Comment:** 39 pages; Github: https://github.com/GAIR-NLP/MegaScience; HF:
  https://huggingface.co/MegaScience

> **TL;DR:** MegaScience是一个大型高质量的科学推理数据集，旨在弥补现有科学领域开源数据集的不足。它包含TextbookReasoning和多个优化后的开源数据集，并提供全面的评估系统。实验表明，MegaScience能显著提升模型性能和训练效率，尤其对大型模型效果更佳。

**AI_Comments:** 本论文的创新点在于构建了目前最大规模、高质量的科学推理数据集MegaScience，并提出了系统的数据选择方法。其重要性在于弥补了科学领域高质量开源数据集的空白，为AI科学家发展提供了坚实基础。实验结果证明了高质量数据集对提升大型语言模型科学推理能力的显著效果，尤其指出了规模效益，对未来的科学AI研究具有指导意义。该研究不仅提供了数据集，还开源了数据整理流程、评估系统和训练模型，极大地便利了后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有开源社区主要关注数学和编码领域，而科学领域因缺乏开放、大规模、高质量、可验证的科学推理数据集而被忽视。为了弥补这一空白，本研究旨在构建这样的数据集以推动AI科学家发展和支持人类研究。

**Method:** 本研究首先提出了TextbookReasoning数据集，包含从1.2万本大学教材中提取的65万个推理问题，涵盖7个科学学科。其次，通过系统消融研究，评估了各种数据选择方法，构建了MegaScience数据集，这是一个包含125万个高质量实例的开源数据集混合体。同时，还建立了一个涵盖15个基准测试的综合评估系统，确保评估指标的准确性。最后，使用MegaScience训练了Llama3.1、Qwen2.5和Qwen3系列基础模型。

**Result:** 实验表明，MegaScience数据集在性能和训练效率上优于现有开源科学数据集，并能产生更简洁的响应。使用MegaScience训练的模型（Llama3.1、Qwen2.5、Qwen3系列）平均性能显著优于相应的官方指令模型。此外，MegaScience对更大更强的模型表现出更高的有效性，表明科学调优存在规模效益。

**Conclusion:** 本研究成功构建了MegaScience数据集和综合评估系统，显著提升了AI在科学推理领域的性能。数据集和相关工具的发布将有助于推动科学推理研究的进展，并证明了高质量大规模数据集对模型性能提升的重要性。

> **ai_Abstract:** 本研究介绍了MegaScience，一个旨在解决科学推理领域高质量数据集稀缺问题的创新数据集。通过整合TextbookReasoning（来自1.2万本大学教科书的65万个推理问题）和一系列优化后的开源数据集，MegaScience提供了125万个实例。研究团队还开发了一个涵盖15个基准测试的综合评估系统。实验结果表明，MegaScience在提高模型性能和训练效率方面表现出色，并能显著提升Llama3.1、Qwen2.5和Qwen3等基础模型的科学推理能力，尤其对大型模型效果更佳。所有数据、工具和训练模型均已开源，以促进科学AI研究。

> **摘要翻译:** 科学推理对于发展人工智能科学家和支持人类研究人员推进自然科学发现的边界至关重要。然而，开源社区主要关注数学和编码，而忽视了科学领域，这主要是由于缺乏开放、大规模、高质量、可验证的科学推理数据集。为了弥补这一差距，我们首先提出了TextbookReasoning，一个开放数据集，其特点是从1.2万本大学级别的科学教科书中提取了真实的参考答案，包含跨7个科学学科的65万个推理问题。我们进一步引入了MegaScience，一个由高质量开源数据集组成的大规模混合体，总计125万个实例，通过系统的消融研究开发，评估了各种数据选择方法，以确定每个公开可用科学数据集的最佳子集。同时，我们构建了一个全面的评估系统，涵盖15个基准测试中不同的主题和问题类型，并结合了全面的答案提取策略以确保准确的评估指标。我们的实验表明，与现有开源科学数据集相比，我们的数据集实现了卓越的性能和训练效率，且响应长度更简洁。此外，我们在MegaScience上训练了Llama3.1、Qwen2.5和Qwen3系列基础模型，这些模型在平均性能上显著优于相应的官方指令模型。另外，MegaScience对更大更强的模型表现出更大的有效性，这表明科学调优存在规模效益。我们将数据整理流程、评估系统、数据集和七个训练好的模型发布给社区，以推进科学推理研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [118] [Efficient Compositional Multi-tasking for On-device Large Language Models](https://arxiv.org/abs/2507.16083)
> *面向设备端大型语言模型的高效组合多任务处理*

*Ondrej Bohdal, Mete Ozay, Jijoong Moon, Kyeng-Hun Lee, Hyeonmok Ko, Umberto Michieli* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 大型语言模型, 组合多任务, 设备端, 任务合并, 可学习校准

**Comment:** 

> **TL;DR:** 本文提出了一种面向设备端LLMs的高效组合多任务处理方法，解决了传统任务合并方法无法处理单个测试示例同时涉及多个任务的问题，并提出了一个基准和一种名为“可学习校准”的高效方法。

**AI_Comments:** 本文的创新点在于首次将大型语言模型的任务合并研究扩展到“组合多任务处理”场景，即单个测试示例需要同时执行多个任务，这更符合现实世界的复杂需求。同时，作者特别关注设备端应用，提出了一个基准和高效方法，解决了资源受限环境下的性能挑战，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）任务合并研究主要局限于每个测试示例只涉及单个任务的场景。然而，在实际应用中，尤其是在设备端设置中，常常需要模型同时执行多个任务（例如，翻译加摘要）。因此，需要开发能够处理文本组合多任务的高效解决方案。

**Method:** 本文提出了一个包含四个实际相关组合任务的基准，以促进该领域的研究。此外，还提出了一种名为“可学习校准”（Learnable Calibration）的高效方法，该方法专为计算资源有限的设备端应用设计，旨在实现资源高效和高性能。

**Result:** 本文提出了一个包含四个实际相关组合任务的基准，并介绍了一种名为“可学习校准”的高效方法，该方法专为资源受限的设备端应用设计，强调了解决方案的资源效率和高性能。

**Conclusion:** 本文的贡献为推动大型语言模型在真实世界多任务场景中的能力发展奠定了基础，扩展了它们在复杂、资源受限用例中的适用性。

> **ai_Abstract:** 本文针对设备端大型语言模型（LLMs）的组合多任务处理问题进行了研究，该问题要求模型能同时执行多个任务。鉴于以往任务合并研究的局限性，作者提出了一个包含四个实际组合任务的基准，并开发了一种名为“可学习校准”的高效方法，该方法专为资源受限的设备端环境设计，旨在实现高效率和高性能。这项工作为LLMs在复杂、资源受限的真实世界多任务场景中的应用奠定了基础。

> **摘要翻译:** 适配器参数提供了一种修改机器学习模型行为的机制，并在大型语言模型（LLMs）和生成式AI中获得了显著关注。这些参数可以通过任务合并过程来支持多任务。然而，之前在LLMs中，特别是在自然语言处理领域的合并工作，仅限于每个测试示例只处理单个任务的场景。在本文中，我们关注设备端设置，研究基于文本的组合多任务处理问题，其中每个测试示例涉及多个任务的同时执行。例如，生成长文本的翻译摘要需要同时解决翻译和摘要任务。为了促进此设置下的研究，我们提出了一个包含四个实际相关组合任务的基准。我们还提出了一种针对设备端应用量身定制的高效方法（可学习校准），在计算资源有限的情况下，强调了解决方案的资源效率和高性能。我们的贡献为推进LLMs在真实世界多任务场景中的能力奠定了基础，扩展了它们在复杂、资源受限用例中的适用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [123] [Adversarial Demonstration Learning for Low-resource NER Using Dual Similarity](https://arxiv.org/abs/2507.15864)
> *对抗性示范学习在低资源NER中使用双重相似性*

*Guowen Yuan, Tien-Hsuan Wu, Lianghao Xia, Ben Kao* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-13**

**Keywords:** 低资源NER, 示范学习, 双重相似性, 对抗性示范, 命名实体识别

**Comment:** 

> **TL;DR:** 本文针对低资源NER中的示范学习，提出了通过双重相似性（语义+特征）选择示范样本和对抗性示范训练模型的方法，有效提升了性能。

**AI_Comments:** 本文的创新点在于提出了“双重相似性”来更全面地选择示范样本，以及通过“对抗性示范”训练机制来增强模型对示范的引用能力，这对于低资源NER问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有低资源NER的示范学习存在两个问题：1) 示范样本选择主要依赖语义相似性，忽略了特征相似性；2) NER标注器引用示范样本的能力不足。

**Method:** 1) 提出通过双重相似性（语义相似性和特征相似性）选择示范样本；2) 提出使用对抗性示范训练NER模型，强制模型在标注时参考示范。

**Result:** 在低资源NER任务中进行了全面的实验，结果表明所提出的方法优于一系列现有方法。

**Conclusion:** 通过引入双重相似性进行示范选择和对抗性示范训练，可以有效提升低资源NER任务的性能。

> **ai_Abstract:** 本文研究了低资源场景下的命名实体识别（NER）示范学习问题，并指出了现有方法在示范样本选择（仅依赖语义相似性）和模型引用示范能力方面的不足。为解决这些问题，作者提出了结合语义相似性和特征相似性的“双重相似性”来选择示范样本，并引入“对抗性示范”训练NER模型，以强制模型在标注时参考示范。实验结果表明，该方法在低资源NER任务中表现优于现有方法。

> **摘要翻译:** 我们研究了在低资源场景下基于示范学习的命名实体识别（NER）问题。我们识别了示范构建和模型训练中的两个问题。首先，现有选择示范示例的方法主要依赖于语义相似性；我们表明特征相似性可以提供显著的性能改进。其次，我们表明NER标注器引用示范示例的能力普遍不足。我们提出了一种有效解决这些问题的示范和训练方法。针对第一个问题，我们提出通过双重相似性选择示例，该相似性包括语义相似性和特征相似性。针对第二个问题，我们提出使用对抗性示范训练NER模型，使得模型在执行标注任务时被迫参考示范。我们在低资源NER任务中进行了全面的实验，结果表明我们的方法优于一系列方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [124] [Universal Model Routing for Efficient LLM Inference](https://arxiv.org/abs/2502.08773)
> *通用模型路由用于高效LLM推理*

*Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Congchao Wang, Zifeng Wang, Alec Go, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, Sanjiv Kumar* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 模型路由, LLM推理, 动态路由, UniRoute, 特征向量

**Comment:** 

> **TL;DR:** UniRoute提出了一种动态模型路由方法，通过将LLM表示为特征向量来处理未见过的模型，并在基准测试中展现了其有效性，旨在降低LLM推理成本。

**AI_Comments:** UniRoute通过解决动态模型路由这一关键问题，显著推动了LLM推理效率。其处理未见过的LLM的能力尤其创新，使得路由策略在现实世界、不断发展的LLM生态系统中更具适应性和鲁棒性。理论基础与实证验证相结合，增强了其贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）模型路由方法仅限于固定模型池，无法处理测试时出现的新的、未观察到的LLMs。本文旨在解决动态路由问题，以进一步降低LLM的推理成本。

**Method:** 本文提出了UniRoute，一种新的动态路由方法。它通过基于一组代表性提示的预测，将每个LLM表示为一个特征向量。UniRoute详细介绍了两种有效的实例化方法：基于聚类的路由和学习到的聚类映射。该方法被证明是理论上最优路由规则的估计，并通过过量风险界限量化了其误差。

**Result:** 在多个公共基准测试上的实验表明，UniRoute在30多个未见过的LLM之间进行路由时表现出有效性。

**Conclusion:** UniRoute有效解决了LLMs的动态模型路由问题，为处理未见过的模型和降低推理成本提供了一个理论上可靠且实践中有效的方法。

> **ai_Abstract:** 本文介绍了UniRoute，一种用于大型语言模型（LLM）动态模型路由的新颖方法。与现有仅限于固定LLM池的方法不同，UniRoute解决了测试时出现新的、未见过的LLM的场景。它通过将每个LLM表示为一个特征向量来实现这一点，该向量来源于其在一组代表性提示上的预测。论文详细介绍了两种实际实例化：基于聚类的路由和学习到的聚类映射，并证明了它们的理论最优性并量化了其误差界限。实验结果证实了UniRoute在30多个先前未见过的LLM之间进行路由的有效性，显著促进了高效的LLM推理。

> **摘要翻译:** 模型路由是降低大型语言模型（LLMs）推理成本的一种简单技术，其中维护一个候选LLMs池，并学习将每个提示路由到最小的可行LLM。现有工作侧重于为固定LLMs池学习一个路由器。在本文中，我们考虑了动态路由问题，即在测试时可以使用新的、以前未观察到的LLMs。我们提出了UniRoute，一种解决此问题的新方法，它依赖于将每个LLM表示为一个特征向量，该向量基于在一组代表性提示上的预测得出。在此基础上，我们详细介绍了UniRoute的两种有效实例化，分别依赖于基于聚类的路由和学习到的聚类映射。我们表明这些是理论上最优路由规则的估计，并通过过量风险界限量化了它们的误差。在各种公共基准测试上的实验表明了UniRoute在30多个未见过的LLMs之间进行路由的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [129] [AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering](https://arxiv.org/abs/2507.16054)
> *AutoMeet：一项关于使用生成式AI自动化汽车工程会议的概念验证研究*

*Simon Baeuerle, Max Radyschevski, Ulrike Pado* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 生成式AI, 会议自动化, 知识管理, 汽车工程, 概念验证

**Comment:** 

> **TL;DR:** 本文介绍了一个名为AutoMeet的概念验证系统，利用生成式AI自动化会议记录和信息检索，旨在减少会议工作量并提高知识管理效率，并在真实环境中进行了测试。

**AI_Comments:** 这项研究具有重要的实用价值，它直接解决了大型组织中普遍存在的会议效率低下和知识管理混乱的问题。其创新点在于将生成式AI应用于端到端的会议自动化流程，并特别强调了在真实环境中进行概念验证及收集用户反馈的重要性。虽然技术方面已取得进展，但研究也明确指出了组织和伦理方面是未来部署的关键挑战，这为后续研究和实践提供了重要的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型组织中会议占用大量工作时间且文档不一致，导致信息难以检索。生成式AI在语言处理方面的出色表现，促使研究者探索其在工程部门知识管理中的应用，以自动化会议转录和信息整合。

**Method:** 实施了一个端到端的管道，自动化会议文档工作流程：会议被录音，生成式AI创建会议纪要，并通过聊天机器人界面使其可搜索。核心工作是在真实的工程部门测试该基于生成式AI的软件工具，并收集关于伦理和技术方面的广泛调查数据。

**Result:** 真实世界反馈指出，用户同意生成式AI能显著减少会议工作量；技术方面已基本解决；组织方面对于此类系统的成功伦理使用至关重要。

**Conclusion:** 生成式AI在自动化会议和改进知识管理方面具有巨大潜力。尽管技术挑战大部分已克服，但组织和伦理因素是成功部署的关键。该概念验证研究表明，通过生成式AI可以显著减少会议工作量并提高信息可访问性。

> **ai_Abstract:** 本文介绍了AutoMeet，一个利用生成式AI自动化汽车工程会议文档流程的概念验证系统。该系统通过AI转录会议并生成纪要，并通过聊天机器人提供可搜索的会议信息，旨在解决大型组织中会议耗时、文档不一致及信息检索困难的问题。研究在真实工程部门进行了测试，结果表明AI能显著减少会议工作量，技术挑战已基本解决，但组织和伦理因素对成功实施至关重要。

> **摘要翻译:** 在大型组织中，知识主要通过会议共享，这占用了大量工作时间。此外，频繁的面对面会议会产生不一致的文档——官方会议纪要、个人笔记、演示文稿可能存在也可能不存在。因此，共享信息在会议之外变得难以检索，这导致需要冗长的更新和高频率的会议安排。
生成式人工智能（genAI）模型，如大型语言模型（LLMs），在口语和书面语言处理方面表现出令人印象深刻的性能。这促使了生成式AI在工程部门知识管理中的实际应用：使用生成式AI转录会议，并将异构的附加信息源整合为易于使用的格式，以便进行即时搜索。
我们实现了一个端到端的管道，以概念验证状态自动化整个会议文档工作流程：会议被录音，会议纪要由生成式AI创建。这些纪要通过聊天机器人界面变得易于搜索。我们工作的核心是在真实的工程部门测试这个基于生成式AI的软件工具，并收集关于伦理和技术方面的广泛调查数据。来自真实设置的直接反馈指出了机遇和风险：a) 用户同意在生成式AI模型的帮助下，会议工作量可以显著减少，b) 技术方面已基本解决，c) 组织方面对于此类系统的成功伦理使用至关重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [135] [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](https://arxiv.org/abs/2505.00025)
> *基于Deepseek R1的医疗垂直大语言模型架构方法*

*Mingda Zhang, Jianglong Qin* | **Category: cs.CL, cs.AI, I.2.7; J.3** | **Updated: 2025-07-22**

**Keywords:** 医疗大语言模型, 模型压缩, 知识蒸馏, 低秩适应

**Comment:** 14 pages, 1 figures

> **TL;DR:** 本文提出了一种高效轻量级医疗大语言模型架构，通过三维优化（知识获取、模型压缩、计算增强）解决了医疗环境中部署大模型的挑战，并在资源受限环境下实现了高性能。

**AI_Comments:** 该论文创新性地提出了一种三维优化方法来构建轻量级医疗大语言模型，有效地解决了大型基础模型在医疗领域部署时面临的资源和专业性挑战。其结合知识蒸馏、量化和推理优化技术，在保持性能的同时大幅降低了计算成本，对推动AI在医疗领域的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管DeepSeek-R1和ChatGPT等基础模型取得了显著进展，但它们在医疗环境中的部署面临计算要求高和专业知识壁垒等关键挑战。

**Method:** 本文提出了一种高效轻量级医疗大语言模型架构，通过三维优化系统地解决这些挑战：知识获取（使用LoRA从DeepSeek-R1-Distill-70B到7B进行知识迁移）、模型压缩（通过4位量化和混合精度策略）和计算增强（结合Flash Attention加速、连续批处理和专用提示模板）。

**Result:** 在医学基准测试中，该方法在USMLE考试中保持92.1%的准确率，同时与基线模型相比，内存消耗减少64.7%，推理延迟降低12.4%。

**Conclusion:** 这项工作为在资源受限的医疗环境中部署先进语言模型提供了一个实用解决方案，从而使AI辅助医疗服务更具可及性。

> **ai_Abstract:** 本文提出了一种基于DeepSeek R1的高效轻量级医疗垂直大语言模型架构，旨在解决现有基础模型在医疗部署中的计算和知识挑战。通过三维优化，包括LoRA进行知识迁移、4位量化和混合精度进行模型压缩，以及Flash Attention和连续批处理进行计算增强，该方法在保持高医学准确率的同时显著降低了资源消耗，为资源受限的医疗环境提供了可行的AI辅助医疗部署方案。

> **摘要翻译:** 尽管DeepSeek-R1和ChatGPT等基础模型取得了显著进展，但它们在医疗环境中的部署面临计算要求高和专业知识壁垒等关键挑战。本文提出了一种高效轻量级医疗大语言模型架构，通过三维优化系统地解决这些挑战：知识获取、模型压缩和计算增强。我们设计了从DeepSeek-R1-Distill-70B到DeepSeek-R1-Distill-7B的知识迁移管道，使用低秩适应（LoRA）以精确保留医学知识。通过4位量化和混合精度策略，我们实现了模型的大幅压缩，同时保留了医学推理能力。推理框架结合了Flash Attention加速和连续批处理，并辅以专用提示模板用于多样化医疗查询。在医学基准测试中的实验评估表明，我们的方法在USMLE考试中保持92.1%的准确率，同时与基线模型相比，内存消耗减少64.7%，推理延迟降低12.4%。这项工作为在资源受限的医疗环境中部署先进语言模型提供了一个实用解决方案，从而使AI辅助医疗服务更具可及性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [144] [Combining Language and Topic Models for Hierarchical Text Classification](https://arxiv.org/abs/2507.16490)
> *结合语言模型和主题模型进行层次文本分类*

*Jaco du Toit, Marcel Dunaiski* | **Category: cs.CL, cs.LG, I.2.7; I.2.6** | **Updated: 2025-07-22**

**Keywords:** 层次文本分类, 预训练语言模型, 主题模型, 特征组合, 文本分类性能

**Comment:** 13 pages, 2 figures

> **TL;DR:** 本文研究了将预训练语言模型（PLM）和主题模型（TM）结合用于层次文本分类（HTC）的效果。实验结果表明，与仅使用PLM相比，加入主题模型提取的特征通常会降低分类性能，这与之前的一些假设相反。

**AI_Comments:** 该论文的重要创新在于它挑战了一个在文本分类领域可能存在的普遍假设，即结合主题模型特征总能带来性能提升。通过严谨的实验，它揭示了在层次文本分类任务中，这种结合实际上可能带来负面影响，这为未来的研究提供了重要的反思和指导，避免了盲目地融合多种特征提取模型。其价值在于提供了一个反例，促使研究人员更审慎地评估不同模型的集成效果。

<details>
  <summary>Details</summary>

**Motivation:** 层次文本分类（HTC）旨在将文本文档分类到预定义的结构化类别层次中。现有的HTC方法结合了预训练语言模型（PLM）来提高性能。鉴于在多标签文本分类任务中，PLM与主题模型结合提取特征被证明是有效的方法（PLM捕获细粒度上下文语义，主题模型获得高层全局表示），本文旨在确定PLM和主题模型提取特征的组合是否普遍有利于HTC性能。

**Method:** 本文采用一种HTC方法，该方法使用预训练语言模型（PLM）和主题模型（TM）从文本文档中提取特征，然后将这些特征用于训练分类模型。提取的特征通过独立的卷积层处理，其输出被组合并传递给一个标签感知注意力机制，该机制通过单独衡量每个类别最重要的特征来获得标签特定的文档表示。

**Result:** 在三个HTC基准数据集上进行的综合实验表明，与仅使用预训练语言模型（PLM）获得的特征相比，使用主题模型提取的特征通常会降低分类性能。

**Conclusion:** 与之前的工作相反，本文的结论是，不应想当然地认为将主题模型提取的特征纳入文本分类任务是有益的。

> **ai_Abstract:** 本文研究了将预训练语言模型（PLM）和主题模型（TM）结合应用于层次文本分类（HTC）的效果。研究动机是PLM和TM分别捕获细粒度和高层信息，且这种组合在多标签分类中有效。作者提出了一种方法，将PLM和TM提取的特征通过独立的卷积层处理，再结合并输入标签感知注意力机制。然而，在三个基准数据集上的实验结果显示，与仅使用PLM相比，加入主题模型特征通常会降低HTC性能。这挑战了以往关于结合主题模型特征总是有益的假设。

> **摘要翻译:** 层次文本分类（HTC）是一种自然语言处理任务，其目标是将文本文档分类到预定义的结构化类别层次中。最近的HTC方法使用各种技术将层次类别结构信息与预训练语言模型（PLM）的自然语言理解能力相结合，以提高分类性能。此外，在多标签文本分类任务中，将主题模型与PLM一起使用以从文本文档中提取特征已被证明是一种有效的方法。这些特征提取模型组合背后的基本原理是，PLM捕获更细粒度的上下文和语义信息，而主题模型获得考虑整个文档语料库的高级表示。在本文中，我们使用一种HTC方法，该方法使用PLM和主题模型从文本文档中提取特征，这些特征用于训练分类模型。我们的目标是确定从这两个模型中提取的特征组合是否普遍有利于HTC性能。在我们的方法中，提取的特征通过独立的卷积层，其输出被组合并传递给一个标签感知注意力机制，该机制通过单独衡量每个类别最重要的特征来获得标签特定的文档表示。我们在三个HTC基准数据集上进行了综合实验，结果表明，与仅使用PLM获得的特征相比，使用主题模型提取的特征通常会降低分类性能。与之前的工作形成对比，这表明不应想当然地认为将主题模型提取的特征纳入文本分类任务是有益的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [150] [MPO: An Efficient Post-Processing Framework for Mixing Diverse Preference Alignment](https://arxiv.org/abs/2502.18699)
> *MPO：一种用于混合多样化偏好对齐的高效后处理框架*

*Tianze Wang, Dongnan Gui, Yifan Hu, Shuhang Lin, Linjun Zhang* | **Category: cs.CL, cs.LG, stat.ME** | **Updated: 2025-07-22**

**Keywords:** RLHF, 偏好对齐, LLMs, 后处理, 多样化偏好

**Comment:** ICML 2025

> **TL;DR:** MPO是一种高效的后处理框架，用于混合多样化偏好对齐。它通过对现有策略进行对数线性组合，并采用批量随机镜像下降法计算权重，从而避免从头开始对齐。实验结果表明，MPO在计算成本显著降低的情况下，实现了跨多样化偏好的平衡性能，优于或媲美现有模型。

**AI_Comments:** MPO的创新之处在于其采用后处理框架来聚合现有策略，而非从头开始训练，这显著降低了计算成本和训练复杂性。它为处理多样的、有时相互冲突的人类偏好提供了一个实用且高效的解决方案，对于RLHF的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习人类反馈（RLHF）方法依赖单一奖励模型，往往忽略了人类偏好的多样性。尽管最近的多维反馈方法试图解决此问题，但其过程成本高昂且不稳定，尤其是在人类偏好相互竞争和异构的情况下。

**Method:** 本文提出了混合偏好优化（MPO），一个聚合单目标策略的后处理框架，作为多目标RLHF（MORLHF）和MaxMin-RLHF的替代方案。MPO通过批量随机镜像下降法计算每个策略的权重，将现有策略对数线性组合成一个统一策略，从而避免了从头开始对齐。

**Result:** MPO在多样化偏好下实现了平衡性能，性能优于或媲美现有模型，同时显著降低了计算成本。

**Conclusion:** MPO提供了一种高效且有效的后处理框架，用于混合多样化偏好对齐，克服了现有RLHF方法在处理复杂和异构人类偏好时的成本高昂和不稳定性问题。

> **ai_Abstract:** 本文提出MPO（混合偏好优化），一种高效的后处理框架，旨在解决传统RLHF在处理多样化人类偏好时遇到的成本高昂和不稳定性问题。MPO通过对数线性组合现有单目标策略，并利用批量随机镜像下降法计算权重，从而避免了从头开始训练。实验证明，MPO在显著降低计算成本的同时，能在多样化偏好下实现平衡且优越的性能。

> **摘要翻译:** 从人类反馈中进行的强化学习（RLHF）在对齐大型语言模型（LLM）方面展现出前景。然而，它对单一奖励模型的依赖常常忽视了人类偏好的多样性。最近的方法通过利用多维反馈来微调相应的奖励模型并使用强化学习训练LLM，从而解决了这一局限性。但是，这个过程成本高昂且不稳定，尤其是在人类偏好相互竞争和异构的情况下。在本文中，我们提出了混合偏好优化（MPO），一个聚合单目标策略的后处理框架，作为多目标RLHF（MORLHF）和MaxMin-RLHF的替代方案。MPO避免了从头开始对齐。相反，它将现有策略对数线性组合成一个统一策略，其中每个策略的权重通过批量随机镜像下降法计算。实证结果表明，MPO在多样化偏好下实现了平衡性能，性能优于或媲美现有模型，同时显著降低了计算成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [158] [Towards Compute-Optimal Many-Shot In-Context Learning](https://arxiv.org/abs/2507.16217)
> *迈向计算最优的多样本语境学习*

*Shahriar Golchin, Yanfei Chen, Rujun Han, Manan Gandhi, Tianli Yu, Swaroop Mishra, Mihai Surdeanu, Rishabh Agarwal, Chen-Yu Lee, Tomas Pfister* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 多样本语境学习, 演示选择, 计算优化, 大型语言模型, 推理成本

**Comment:** Final version; accepted at COLM 2025

> **TL;DR:** 提出了两种新的多样本语境学习演示选择策略，可在保持高性能的同时显著降低计算成本。

**AI_Comments:** 这项工作通过提出两种创新的演示选择策略，解决了多样本语境学习中计算成本高昂的挑战。其核心创新在于巧妙地结合了基于相似性的选择和可缓存的随机/聚类选择，实现了性能与效率的平衡。这对于实际部署大型语言模型具有重要意义，尤其是在需要处理大量上下文和演示的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 当前多样本语境学习（ICL）中，由于推理成本高、缓存重用以及在大规模应用中性能相似等原因，通常随机选择演示。这导致了性能提升的潜力未被充分利用，且仍存在优化计算效率的需求。

**Method:** 本文提出了两种多样本ICL的演示选择策略：1. 将少量基于与测试样本相似性选择的演示与大量缓存的随机演示相结合。2. 在第一种策略的基础上改进，用通过k-均值聚类从测试样本表示中导出的质心选择的演示替换随机演示。

**Result:** 实验结果表明，所提出的策略始终优于随机选择，并且超越或匹配性能最佳的选择方法。这些策略支持缓存，并将推理成本降低了一个数量级。此外，调整不同选择标准的演示比例可以平衡多样本ICL的性能和推理成本。

**Conclusion:** 本文提出的计算最优的多样本语境学习演示选择策略，能够在保持甚至超越现有最佳性能的同时，显著降低推理成本，并支持缓存，从而在性能和效率之间取得了良好的平衡。

> **ai_Abstract:** 该论文提出了两种计算效率高的多样本语境学习（ICL）演示选择策略。第一种策略结合了少量基于相似性的演示和大量缓存的随机演示。第二种策略在此基础上进行改进，用通过k-均值聚类选择的演示替换随机演示。实验表明，这些策略在保持高性能的同时，显著降低了长上下文LLM中多样本ICL的推理成本，并支持缓存。

> **摘要翻译:** 长上下文大型语言模型 (LLMs) 能够处理包含数百万个标记的输入。在语境学习 (ICL) 的范围内，这意味着在输入提示中使用数百/数千个演示，从而实现多样本ICL。在实践中，由于 (1) 高昂的推理成本，(2) 缓存和重用计算的好处，以及 (3) 在扩展时与其他策略相比，这种策略提供的性能相似，因此在多样本设置中通常随机选择一组固定的演示。在这项工作中，我们提出了两种直接的多样本ICL演示选择策略，它们以最小的计算开销提高性能。我们的第一个方法将少量根据与每个测试样本的相似性选择的演示与不成比例的更大一组缓存的随机演示相结合。第二种策略通过用通过k-均值聚类从测试样本表示中导出的质心选择的演示替换随机演示来改进第一种策略。我们使用Gemini Pro和Flash在多个数据集上进行的实验表明，我们的策略始终优于随机选择，并且超越或匹配性能最佳的选择方法，同时支持缓存并将推理成本降低了一个数量级。我们还表明，调整根据不同标准选择的演示比例可以在多样本ICL中平衡性能和推理成本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [159] [Deep Researcher with Test-Time Diffusion](https://arxiv.org/abs/2507.16075)
> *具有测试时扩散的深度研究员*

*Rujun Han, Yanfei Chen, Zoey CuiZhu, Lesly Miculicich, Guan Sun, Yuanjun Bi, Weiming Wen, Hui Wan, Chunfeng Wen, Solène Maître, George Lee, Vishy Tirumalashetty, Emily Xue, Zizhao Zhang, Salem Haykal, Burak Gokturk, Tomas Pfister, Chen-Yu Lee* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 深度研究代理, 测试时扩散, 大语言模型, 报告生成, 迭代细化

**Comment:** 

> **TL;DR:** TTD-DR是一个受人类研究启发的新框架，通过将研究报告生成视为一个扩散过程，并结合迭代细化和外部信息检索，显著提高了深度研究代理在复杂报告生成上的性能。

**AI_Comments:** 该论文通过将研究报告生成类比为扩散过程，并引入迭代细化和动态外部信息检索机制，为深度研究代理的性能提升提供了一个新颖且有效的范式。其草稿中心的设计理念有助于提高报告的质量和生成效率，减少信息丢失，具有重要的创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度研究代理在生成复杂的长篇研究报告时，性能常因使用通用测试时扩展算法而停滞不前。

**Method:** 本文提出了测试时扩散深度研究员（TTD-DR）框架，将研究报告生成概念化为一个扩散过程。它从一个初步草稿开始，通过动态结合检索机制的“去噪”过程进行迭代细化，并在代理工作流的每个组件上应用自进化算法，以生成高质量的上下文。

**Result:** TTD-DR在需要密集搜索和多跳推理的广泛基准测试中取得了最先进的结果，显著优于现有深度研究代理。

**Conclusion:** TTD-DR的草稿中心设计使报告撰写过程更及时、连贯，同时减少了迭代搜索过程中的信息损失。

> **ai_Abstract:** 本文提出了一种名为测试时扩散深度研究员（TTD-DR）的新型框架，旨在解决现有深度研究代理在生成复杂长篇研究报告时性能停滞的问题。TTD-DR受人类研究的迭代过程启发，将报告生成视为一个扩散过程，通过初步草稿的迭代细化、动态外部信息检索和自进化算法，显著提升了报告的及时性、连贯性并减少了信息损失。实验结果表明，TTD-DR在需要密集搜索和多跳推理的基准测试中达到了最先进的性能。

> **摘要翻译:** 由大型语言模型（LLM）驱动的深度研究代理正在迅速发展；然而，当它们使用通用测试时扩展算法生成复杂、长篇研究报告时，其性能往往会停滞不前。我们从人类研究的迭代性质中汲取灵感，该过程涉及搜索、推理和修订的循环，提出了测试时扩散深度研究员（TTD-DR）。这个新颖的框架将研究报告生成概念化为一个扩散过程。TTD-DR通过一个初步草稿启动这个过程，该草稿是一个可更新的骨架，作为指导研究方向的不断演变的基础。然后，草稿通过一个“去噪”过程进行迭代细化，该过程由一个检索机制在每一步动态地获取外部信息。核心过程通过应用于代理工作流每个组件的自进化算法得到进一步增强，确保为扩散过程生成高质量的上下文。这种以草稿为中心的设计使得报告撰写过程更及时、更连贯，同时减少了迭代搜索过程中的信息损失。我们证明了我们的TTD-DR在需要密集搜索和多跳推理的广泛基准测试中取得了最先进的结果，显著优于现有深度研究代理。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [175] [LLMs syntactically adapt their language use to their conversational partner](https://arxiv.org/abs/2503.07457)
> *大型语言模型在句法上适应其对话伙伴的语言使用*

*Florian Kandra, Vera Demberg, Alexander Koller* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 语言适应, 句法选择, 对话, 语料库

**Comment:** 5 pages, 1 table, 3 figures, accepted at ACL (main conference) 2025

> **TL;DR:** 研究发现大型语言模型（LLMs）在对话中会使其语言使用在句法上与对话伙伴趋于一致。

**AI_Comments:** 这项研究揭示了LLMs在对话中具备基本的语言适应能力，类似于人类的语言对齐现象。这对于理解LLMs的交互行为及其潜在的社交智能具有重要意义。其创新之处在于首次实证研究了LLMs的句法适应性，但研究也指出这种适应性仍处于“基本”阶段，未来可能需要更深入的研究来探索更复杂的适应机制。

<details>
  <summary>Details</summary>

**Motivation:** 人类在对话中会使其语言使用相互对齐，本文旨在实证研究大型语言模型（LLMs）是否也表现出这种对话适应行为。

**Method:** 本文构建了一个大型语言模型之间的对话语料库。

**Result:** 研究发现，随着对话的进行，两个大型语言模型代理最终会做出更相似的句法选择。

**Conclusion:** 现代大型语言模型至少以一种基本的方式适应其对话伙伴的语言使用。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）是否像人类一样在对话中表现出语言适应性。通过构建LLM对话语料库，研究发现LLM代理在对话过程中会使其句法选择更加相似，表明LLMs能够以初步方式适应其对话伙伴的语言使用。

> **摘要翻译:** 人们经常观察到人类说话者在对话中会使他们的语言使用相互对齐。本文实证研究了大型语言模型（LLMs）是否也表现出这种对话适应行为。我们构建了一个大型语言模型之间的对话语料库，发现两个LLM代理在对话过程中最终会做出更相似的句法选择，这证实了现代LLMs至少以一种基本的方式适应其对话伙伴的语言使用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [185] [Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model](https://arxiv.org/abs/2505.22116)
> *基于语言模型的多模态稀疏术中低血压事件预测*

*Jintao Zhang, Zirui Liu, Mingyue Cheng, Shilong Zhang, Tingyue Pan, Yitong zhou, Qi Liu, Yanhu Xie* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 术中低血压, 多模态预测, 语言模型, 事件稀疏性, 临床决策支持

**Comment:** 

> **TL;DR:** IOHFuseLM是一个多模态语言模型框架，通过两阶段训练和多模态融合，有效预测稀疏的术中低血压事件。

**AI_Comments:** 该论文的创新点在于提出了一个基于语言模型的多模态框架IOHFuseLM，并采用了两阶段训练策略来解决稀疏事件预测的难题。通过将结构化临床数据和生理时间序列在token级别对齐，实现了有效的信息融合，同时利用扩散方法增强数据，提高了模型对低血压模式的敏感性。这对于临床决策支持具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 术中低血压（IOH）在全身麻醉下频繁发生，与心肌损伤和死亡率增加等不良后果密切相关。尽管其重要性，IOH预测受到事件稀疏性以及整合不同患者的静态和动态数据挑战的阻碍。

**Method:** 本文提出了IOHFuseLM，一个多模态语言模型框架。采用两阶段训练策略：第一阶段是利用扩散方法增强的IOH生理时间序列进行领域自适应预训练，以提高模型对低血压相关模式的敏感性；第二阶段是对原始临床数据集进行任务微调，以增强区分正常血压和低血压状态的能力。为了实现每位患者的多模态融合，将结构化临床描述与相应的生理时间序列在token级别对齐，以捕捉个体化时间模式及其临床语义。此外，将静态患者属性转换为结构化文本以丰富个性化信息。

**Result:** 在两个术中数据集上的实验评估表明，IOHFuseLM在准确识别IOH事件方面优于现有基线。

**Conclusion:** IOHFuseLM在准确识别术中低血压事件方面表现出色，突出了其在临床决策支持场景中的适用性。

> **ai_Abstract:** 本文提出了一种名为IOHFuseLM的多模态语言模型框架，用于预测稀疏的术中低血压（IOH）事件。该模型通过两阶段训练策略解决事件稀疏性和多模态数据整合的挑战，包括基于扩散增强时间序列的领域自适应预训练和基于临床数据的任务微调。IOHFuseLM通过在token级别对齐临床描述和生理时间序列，并整合静态患者属性，实现多模态融合。实验结果表明，IOHFuseLM在IOH事件识别方面优于现有基线，具有临床应用潜力。

> **摘要翻译:** 术中低血压（IOH）在全身麻醉下频繁发生，与心肌损伤和死亡率增加等不良后果密切相关。尽管其重要性，IOH预测受到事件稀疏性以及整合不同患者的静态和动态数据挑战的阻碍。在本文中，我们提出了IOHFuseLM，一个多模态语言模型框架。为了准确识别和区分稀疏的低血压事件，我们利用了两阶段训练策略。第一阶段涉及对通过扩散方法增强的IOH生理时间序列进行领域自适应预训练，从而增强模型对与低血压相关的模式的敏感性。随后，在原始临床数据集上进行任务微调，以进一步增强区分正常血压和低血压状态的能力。为了实现每位患者的多模态融合，我们将结构化临床描述与相应的生理时间序列在token级别对齐。这种对齐使模型能够捕获个体化时间模式及其相应的临床语义。此外，我们将静态患者属性转换为结构化文本以丰富个性化信息。在两个术中数据集上的实验评估表明，IOHFuseLM在准确识别IOH事件方面优于现有基线，突出了其在临床决策支持场景中的适用性。我们的代码已公开可用，以促进复现性，网址为https://github.com/zjt-gpu/IOHFuseLM。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [189] [The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models](https://arxiv.org/abs/2507.16076)
> *提示语塑造角色：大型语言模型社会人口学角色提示的系统评估*

*Marlene Lutz, Indira Sen, Georg Ahnert, Elisa Rogers, Markus Strohmaier* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 大型语言模型, 角色提示, 社会人口学模拟, 刻板印象, 提示策略

**Comment:** 

> **TL;DR:** 本研究系统评估了不同角色提示策略对大型语言模型模拟社会人口学群体的影响，发现LLMs难以模拟边缘化群体，但特定提示策略可改善表现，且小模型有时优于大模型。

**AI_Comments:** 该论文创新性地系统评估了LLMs在模拟不同社会人口学群体时的表现，并揭示了提示策略对模拟结果的关键影响。其重要性在于指出了LLMs在模拟边缘化群体方面的局限性，并提供了改善模拟保真度的具体方法。特别是，小模型表现优于大模型的发现，对LLM研究和应用具有重要的启示意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地用于模拟不同社会人口学群体的观点，但提示语的制定方式会显著影响结果，引发对模拟保真度的担忧。

**Method:** 使用五种开源LLMs，系统性地检查了不同的角色提示策略（特别是角色采纳格式和人口统计学引导策略）如何影响LLM在开放式和封闭式任务中对15个交叉人口统计学群体的模拟。

**Result:** LLMs难以模拟边缘化群体，尤其是非二元性别、西班牙裔和中东身份。人口统计学引导和角色采纳策略的选择显著影响其表现。访谈式提示和基于姓名的引导有助于减少刻板印象并提高对齐度。令人惊讶的是，OLMo-2-7B等小型模型表现优于Llama-3.3-70B等大型模型。

**Conclusion:** 研究结果为LLM模拟研究中社会人口学角色提示的设计提供了可操作的指导。

> **ai_Abstract:** 本研究系统评估了大型语言模型（LLMs）中社会人口学角色提示的效果，旨在解决模拟保真度问题。研究使用了五种开源LLMs，通过不同角色采纳格式和人口统计学引导策略，在开放式和封闭式任务中模拟了15个交叉人口统计学群体。结果显示LLMs在模拟边缘化群体方面存在困难，但特定提示策略（如访谈式和基于姓名的引导）能有效减少刻板印象并提升对齐度。此外，小型模型有时能超越大型模型。这些发现为LLM中社会人口学角色提示的设计提供了实用建议。

> **摘要翻译:** 角色提示越来越多地应用于大型语言模型（LLMs），以模拟各种社会人口学群体的观点。然而，角色提示的制定方式会显著影响结果，引发了对此类模拟保真度的担忧。我们使用五种开源LLMs，系统地检查了不同的角色提示策略，特别是角色采纳格式和人口统计学引导策略，如何影响LLM在开放式和封闭式任务中对15个交叉人口统计学群体的模拟。我们的发现表明，LLMs难以模拟边缘化群体，特别是非二元性别、西班牙裔和中东身份，但人口统计学引导和角色采纳策略的选择显著影响了它们的表现。具体而言，我们发现访谈式提示和基于姓名的引导有助于减少刻板印象并提高对齐度。令人惊讶的是，OLMo-2-7B等小型模型表现优于Llama-3.3-70B等大型模型。我们的发现为LLM模拟研究中社会人口学角色提示的设计提供了可操作的指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [200] [Synthetic Data Generation Using Large Language Models: Advances in Text and Code](https://arxiv.org/abs/2503.14023)
> *使用大型语言模型生成合成数据：文本和代码领域的进展*

*Mihai Nadas, Laura Diosan, Andreea Tomescu* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 合成数据, 大型语言模型, 文本生成, 代码生成, 数据增强

**Comment:** 24 pages, 6 tables, 1 figure, 64 references

> **TL;DR:** 本综述探讨了大型语言模型（LLMs）如何彻底改变文本和代码领域的合成数据生成，解决了真实数据稀缺、昂贵或敏感的问题，同时也讨论了其面临的挑战及缓解策略。

**AI_Comments:** 这是一篇及时且全面的综述，突出了大型语言模型在解决AI数据稀缺问题上的巨大潜力。其创新之处在于详细分类并探讨了LLM生成合成数据的具体技术和应用，同时平衡地讨论了其优势、挑战及缓解策略。对伦理和质量保障的强调，以及对未来研究方向的展望，使其具有重要的参考价值和指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在真实世界数据集稀缺、昂贵或敏感的场景中，大型语言模型（LLMs）能够生成人工但与任务相关的示例，从而显著增强甚至替代真实数据集，以解决数据不足的问题。

**Method:** 该论文综述了利用LLMs创建合成文本和代码的最新进展，重点介绍了提示生成、检索增强管道和迭代自我完善等关键技术。对于代码领域，还强调了通过功能正确性自动验证的方法。

**Result:** LLMs生成的合成数据能够显著增强或替代真实数据集，尤其适用于低资源任务（如分类、问答）和以代码为中心的应用（如指令调优、代码翻译、错误修复）。其潜在优势包括成本效益、广泛覆盖和可控多样性。同时，也存在生成文本的事实不准确、风格或分布真实性不足以及偏见放大等挑战。缓解策略包括过滤和加权合成输出，以及在代码领域使用带执行反馈的强化学习。

**Conclusion:** 该论文总结了开放研究方向，包括自动化提示工程、跨模态数据合成和鲁棒评估框架，强调了LLM生成的合成数据在加速AI发展中的日益增长的重要性，并强调了伦理和质量保障的必要性。

> **ai_Abstract:** 本综述探讨了大型语言模型（LLMs）在合成训练数据生成方面的变革性作用，涵盖文本和代码领域。文章详细介绍了提示生成、检索增强和迭代自我完善等关键技术，并阐述了这些技术如何支持低资源任务和代码应用。论文还分析了合成数据的优势（如成本效益、广泛覆盖）与挑战（如不准确性、偏见）并提出了相应的缓解策略。最后，文章展望了未来的研究方向，强调了LLM生成合成数据在AI发展中的重要性及其伦理和质量保障。

> **摘要翻译:** 本综述回顾了大型语言模型（LLMs）如何改变自然语言和代码领域的合成训练数据生成。通过生成人工但与任务相关的示例，这些模型可以显著增强甚至替代真实世界数据集，特别是在标记数据稀缺、昂贵或敏感的场景中。本文综述了利用LLMs创建合成文本和代码的最新进展，重点介绍了提示生成、检索增强管道和迭代自我完善等关键技术。我们研究了这些方法如何通过功能正确性的自动验证来丰富低资源任务（例如，分类、问答）并促进以代码为中心的应用（例如，指令调优、代码翻译、错误修复）。除了潜在的好处——成本效益、广泛覆盖和可控多样性——我们还讨论了随之而来的挑战，包括生成文本中的事实不准确、不足的风格或分布真实性以及偏见放大的风险。建议的缓解策略包括过滤和加权合成输出，以及在代码领域使用带执行反馈的强化学习。最后，我们概述了开放的研究方向，例如自动化提示工程、跨模态数据合成和鲁棒评估框架，强调了LLM生成的合成数据在加速人工智能发展中的日益增长的重要性，同时强调了伦理和质量保障。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [204] [Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language](https://arxiv.org/abs/2507.16557)
> *探索大型语言模型中的性别偏见：深入研究德语*

*Kristin Gnadt, David Thulke, Simone Kopeinik, Ralf Schlüter* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 性别偏见, 大型语言模型, 德语, 数据集, 跨语言评估

**Comment:** Accepted at the 6th Workshop on Gender Bias in Natural Language
  Processing (GeBNLP) at ACL 2025

> **TL;DR:** 该研究提出了五个德语数据集，用于评估大型语言模型中的性别偏见，并揭示了德语中性别偏见的独特挑战，强调了定制评估框架的必要性。

**AI_Comments:** 这项工作通过提供特定语言的数据集来解决大型语言模型性别偏见评估中的一个重要限制，即英语中心性。其创新之处在于构建了德语数据集并揭示了德语中性别偏见的独特挑战，这对于开发更具普适性的偏见缓解策略至关重要。研究强调了定制化评估框架的必要性，指出了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估大型语言模型中性别偏见的方法主要针对英语，但在应用于其他语言时存在可迁移性挑战。本研究旨在通过为德语提供评估数据集来解决这一问题。

**Method:** 本研究提出了五个基于既定性别偏见概念的德语数据集，用于评估大型语言模型中的性别偏见。这些数据集可通过多种方法进行访问，并用于评估了八个多语言大型语言模型。

**Result:** 研究发现德语中存在与性别偏见相关的独特挑战，包括男性职业术语的模糊解释以及看似中性名词对性别感知的影响。

**Conclusion:** 本研究有助于理解跨语言大型语言模型中的性别偏见，并强调了需要定制评估框架的重要性。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLM）中性别偏见评估方法在跨语言应用时的可迁移性挑战。为此，研究构建了五个专门针对德语的性别偏见评估数据集，并基于这些数据集对八个多语言LLM进行了评估。研究结果揭示了德语中性别偏见的独特复杂性，例如男性职业词汇的模糊性以及中性名词对性别感知的影响。这项工作强调了在不同语言背景下评估LLM性别偏见的必要性，并呼吁开发定制化的评估框架。

> **摘要翻译:** 近年来，人们提出了各种方法来评估大型语言模型（LLM）中的性别偏见。一个关键挑战在于，最初为英语开发的偏见测量方法在应用于其他语言时的可迁移性。这项工作旨在通过提出五个用于LLM中性别偏见评估的德语数据集来为这一研究领域做出贡献。这些数据集基于公认的性别偏见概念，并可通过多种方法访问。我们对八个多语言LLM模型报告的研究结果揭示了德语中与性别偏见相关的独特挑战，包括男性职业术语的模糊解释以及看似中性名词对性别感知的影响。这项工作有助于理解LLM中跨语言的性别偏见，并强调了定制评估框架的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [210] [SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods](https://arxiv.org/abs/2505.23714)
> *SenWiCh：使用混合方法对低资源语言进行WiC的词义标注*

*Roksana Goworek, Harpal Karlcut, Muhammad Shezad, Nijaguna Darshana, Abhishek Mane, Syam Bondada, Raghav Sikka, Ulvi Mammadov, Rauf Allahverdiyev, Sriram Purighella, Paridhi Gupta, Muhinyia Ndegwa, Haim Dubossarsky* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 低资源语言, 词义标注, 跨语言迁移, 多义词消歧, WiC

**Comment:** 8 pages, 22 figures, published at SIGTYP 2025 workshop in ACL

> **TL;DR:** 本文发布了针对10种低资源语言的词义标注数据集，并提出了一种半自动标注方法，以支持跨语言迁移和多义词消歧研究。

**AI_Comments:** 这篇论文通过发布针对十种低资源语言的词义标注数据集，解决了当前多语言NLP领域中高质量评估基准稀缺的关键问题。其提出的半自动标注方法具有创新性，能够有效促进低资源语言的数据集构建。该工作对于推动跨语言迁移学习、多义词消歧以及实现更公平、鲁棒的多语言NLP具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 推进跨语言迁移需要高质量的低资源语言评估数据集，而现有基准不足以有效评估多语言预训练模型的效用。

**Method:** 论文提出了一种半自动标注方法来创建数据集，并利用Word-in-Context (WiC) 格式的实验来评估这些低资源语言上的迁移效果。

**Result:** 发布了包含多义词句子的新词义标注数据集，涵盖十种低资源语言。实验结果强调了有针对性的数据集创建和评估对于低资源环境下有效多义词消歧和迁移研究的重要性。

**Conclusion:** 高质量的低资源语言评估数据集对推进跨语言迁移至关重要。本文发布的数据集和代码旨在支持公平、鲁棒和真正的多语言NLP研究。

> **ai_Abstract:** 本文针对低资源语言中高质量评估数据集的缺乏，发布了涵盖十种低资源语言的全新词义标注数据集，用于多义词消歧。为方便数据集创建，论文提出了一种有效的半自动标注方法。通过WiC格式的实验，证明了这些数据集在评估低资源语言上迁移效果的实用性，并强调了此类数据集对有效多义词消歧和跨语言迁移研究的重要性。

> **摘要翻译:** 本文旨在解决低资源语言中高质量评估数据集的关键需求，以推进跨语言迁移。虽然跨语言迁移提供了一种利用多语言预训练将语言技术扩展到未充分研究和类型学多样化的语言的关键策略，但其有效性取决于质量和合适的基准。我们发布了新的词义标注数据集，包含多义词句子，涵盖十种跨越不同语系和文字的低资源语言。为了促进数据集创建，本文提出了一种被证明有益的半自动标注方法。通过上下文词义消歧 (WiC) 格式的实验，展示了这些数据集的实用性，这些实验评估了在这些低资源语言上的迁移效果。结果强调了有针对性的数据集创建和评估对于低资源环境下有效多义词消歧和迁移研究的重要性。发布的这些数据集和代码旨在支持对公平、鲁棒和真正的多语言NLP的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [219] [BIDWESH: A Bangla Regional Based Hate Speech Detection Dataset](https://arxiv.org/abs/2507.16183)
> *BIDWESH：一个基于孟加拉语区域的仇恨言论检测数据集*

*Azizul Hakim Fayaz, MD. Shorif Uddin, Rayhan Uddin Bhuiyan, Zakia Sultana, Md. Samiul Islam, Bidyarthi Paul, Tashreef Muhammad, Shahriar Manzoor* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 仇恨言论检测, 孟加拉语方言, 数据集, 自然语言处理, 低资源语言

**Comment:** 

> **TL;DR:** 该研究引入了BIDWESH，首个多方言孟加拉语仇恨言论检测数据集，以解决现有系统对孟加拉语区域方言中仇恨言论检测不足的问题。

**AI_Comments:** 这项研究的创新之处在于它是首个针对孟加拉语区域方言的仇恨言论检测数据集，解决了标准孟加拉语数据集无法覆盖方言表达的问题。这对于促进低资源语言的自然语言处理工具开发以及实现更公平、更具语境意识的内容审核至关重要。其局限性可能在于数据集的规模和所覆盖方言的数量，未来可以进一步扩展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管标准孟加拉语的仇恨言论检测取得了进展，但现有数据集和系统未能处理巴里萨尔、诺阿卡利和吉大港等方言中非正式和文化丰富的表达。这种疏忽导致检测能力有限和内容审核存在偏见，使得大量有害内容未被识别。

**Method:** 本研究通过将BD-SHS语料库中的9,183个实例翻译并标注成三种主要的区域方言，构建了BIDWESH数据集。每个条目都经过人工验证和标注，包括仇恨的存在、类型（诽谤、性别、宗教、煽动暴力）和目标群体（个人、男性、女性、群体），以确保语言和语境的准确性。

**Result:** 构建了BIDWESH数据集，这是第一个多方言孟加拉语仇恨言论数据集。该数据集为孟加拉语的仇恨言论检测提供了一个语言丰富、平衡且包容的资源。

**Conclusion:** BIDWESH数据集为开发方言敏感的自然语言处理工具奠定了基础，并为低资源语言环境下公平和语境感知的数字内容审核做出了重要贡献。

> **ai_Abstract:** 本研究介绍了BIDWESH，一个针对孟加拉语区域方言的仇恨言论检测数据集。鉴于现有系统在处理孟加拉语多种方言中的非标准仇恨言论方面的不足，该数据集通过从BD-SHS语料库翻译和人工标注9,183个实例，覆盖了巴里萨尔、诺阿卡利和吉大港等主要方言。BIDWESH旨在提供一个语言丰富、平衡且包容的资源，以促进孟加拉语仇恨言论检测技术的发展，并为低资源语言环境下的内容审核提供支持。

> **摘要翻译:** 数字平台上的仇恨言论已成为全球日益关注的问题，尤其是在孟加拉国这样语言多样化的国家，区域方言在日常交流中扮演着重要角色。尽管标准孟加拉语的仇恨言论检测取得了进展，但现有数据集和系统未能处理巴里萨尔、诺阿卡利和吉大港等方言中非正式和文化丰富的表达。这种疏忽导致检测能力有限和内容审核存在偏见，使得大量有害内容未被识别。为了弥补这一空白，本研究引入了BIDWESH，这是第一个多方言孟加拉语仇恨言论数据集，通过将BD-SHS语料库中的9,183个实例翻译并标注成三种主要的区域方言而构建。每个条目都经过人工验证和标注，包括仇恨的存在、类型（诽谤、性别、宗教、煽动暴力）和目标群体（个人、男性、女性、群体），以确保语言和语境的准确性。由此产生的数据集为孟加拉语的仇恨言论检测提供了一个语言丰富、平衡且包容的资源。BIDWESH为开发方言敏感的自然语言处理工具奠定了基础，并为低资源语言环境下公平和语境感知的数字内容审核做出了重要贡献。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [225] [Evaluating Intermediate Reasoning of Code-Assisted Large Language Models for Mathematics](https://arxiv.org/abs/2504.17665)
> *评估代码辅助大型语言模型在数学领域中的中间推理能力*

*Zena Al-Khalili, Nick Howell, Dietrich Klakow* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 代码辅助LLM, 数学推理, 推理健全性, 程序评估, 模型局限性

**Comment:** 

> **TL;DR:** 本研究深入分析了代码辅助LLMs在数学推理任务中生成的程序，发现现有评估方法仅限于执行正确性。研究提出了一个基于逻辑健全性的程序分类法，并发现闭源模型更依赖数学概念，而开源模型常使用不健全推理。所有模型在面对复杂问题时，健全推理的生成能力均下降，表明需要更全面的评估方法。

**AI_Comments:** 本文通过引入对代码辅助LLMs生成程序逻辑健全性的评估，填补了现有评估方法的一个重要空白。其创新之处在于提出了一种基于逻辑健全性的程序分类法，并揭示了闭源与开源模型在推理机制上的差异，以及LLMs在处理复杂数学问题时的深层局限性。这对于未来LLMs在数学推理领域的发展和评估具有重要指导意义，提醒研究者不仅要关注结果的正确性，更要深入理解其推理过程。

<details>
  <summary>Details</summary>

**Motivation:** 尽管代码辅助大型语言模型（LLMs）在数学推理任务上表现有所提升，但对其生成的程序评估通常仅限于执行正确性，缺乏对其推理过程健全性的严格评估。本研究旨在弥补这一评估空白。

**Method:** 研究通过对五个大型语言模型在多个数学数据集上生成的程序进行人工和自动评估，深入分析了它们在数学推理任务中的表现。为此，提出了一种基于逻辑健全性的生成程序分类法。

**Result:** 研究发现，模型的性能显著影响其解决问题的逻辑。闭源LLMs的程序根植于数学概念，而开源模型则常诉诸不健全的推理，依赖记忆信息和穷举搜索。此外，问题难度增加会降低所有模型健全生成的比例，揭示了LLMs在复杂数学任务上的关键缺陷，这与准确性指标所暗示的相反。

**Conclusion:** 本研究强调，需要对代码辅助LLMs进行超越执行准确性指标的更全面评估，以便更好地理解LLMs在数学领域的局限性。

> **ai_Abstract:** 本论文旨在解决代码辅助大型语言模型（LLMs）在数学推理任务评估中仅关注执行正确性而忽视其生成程序推理健全性的问题。研究通过对五个LLMs在多项数学数据集上生成的程序进行手动和自动评估，并提出了一种基于逻辑健全性的程序分类法。结果显示，闭源模型倾向于基于数学概念进行推理，而开源模型常依赖不健全的推理或记忆。所有模型在面对更复杂问题时，其健全推理的生成能力均显著下降，揭示了LLMs在复杂数学推理上的局限性。论文强调了对代码辅助LLMs进行更全面评估的必要性，以超越单纯的执行准确性。

> **摘要翻译:** 协助大型语言模型（LLMs）进行代码生成提高了它们在数学推理任务上的表现。然而，对代码辅助LLMs的评估通常仅限于执行正确性，缺乏对其生成程序的严格评估。在这项工作中，我们通过对代码辅助LLMs在数学推理任务中生成的程序进行深入分析来弥补这一空白，重点评估底层推理过程的健全性。为此，我们手动和自动评估了五个LLMs在多个数学数据集上的生成结果，并提出了一个基于其逻辑健全性的生成程序分类法。我们的研究结果表明，模型的能力显著影响了解决问题所实现的逻辑。闭源LLMs将其程序建立在数学概念之上，而开源模型则经常诉诸不健全的推理，依赖记忆信息和穷举搜索。此外，增加问题的难度会降低所有模型健全生成的比例，揭示了LLMs在复杂数学领域的一个关键缺陷，这与准确性指标所暗示的相反。我们的工作强调，需要对代码辅助LLMs进行超越执行准确性指标的更全面评估，以更好地理解LLMs在数学领域的局限性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [233] [Efficient RL for optimizing conversation level outcomes with an LLM-based tutor](https://arxiv.org/abs/2507.16252)
> *使用基于LLM的导师优化对话级别结果的有效强化学习*

*Hyunji Nam, Omer Gottesman, Amy Zhang, Dean Foster, Emma Brunskill, Lyle Ungar* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 强化学习, 大型语言模型, 在线辅导, 多轮对话, 长期优化

**Comment:** 9 pages

> **TL;DR:** 本文提出一种轻量级强化学习方法，通过优化长期策略和使用低维潜在状态来改进LLM导师在多轮对话中的长期学习成果，优于传统RLHF。

**AI_Comments:** 这项工作通过引入低维潜在状态和长期策略优化，解决了LLM在多轮对话中优化长期目标的关键挑战，尤其是在教育辅导场景。其轻量级特性也增加了实际应用的潜力，是对传统RLHF在多轮对话背景下局限性的一种有效改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于RLHF的LLM在多轮对话（如在线数学辅导）中表现不足，因为它们只优化即时回合级别的人类偏好，未能实现引导学生独立解决问题的长期目标。

**Method:** 提出一种增强LLM导师的方法，通过使用学生低维潜在状态表示对话历史，并优化一个长期策略来根据潜在状态确定高级动作。该模型是轻量级的，计算资源需求少。

**Result:** 实验结果表明，与LLM模拟辅导任务中的提示方式相比，所提出的修改带来了改进的长期结果。

**Conclusion:** 通过优化长期策略和利用低维潜在状态，可以有效提高基于LLM的导师在多轮对话中实现长期学习目标的能力，并且计算效率更高。

> **ai_Abstract:** 本文提出一种改进基于LLM的导师在多轮对话中表现的方法。针对现有RLHF在优化长期目标方面的不足，该方法通过将对话历史表示为学生低维潜在状态，并优化一个长期策略来决定高级动作，从而引导学生独立解决问题。实验表明，这种轻量级方法在LLM模拟辅导任务中实现了更好的长期学习成果。

> **摘要翻译:** 大型语言模型（LLM）建立在现有的基于人类反馈的强化学习（RLHF）框架上，通常根据即时回合级别的人类偏好优化响应。然而，这种方法在多轮对话设置中（例如在线数学辅导）表现不足。我们提出一种方法来增强基于LLM的导师，通过使用学生低维潜在状态表示对话历史，并优化一个长期策略来根据潜在状态确定高级动作。目标是更好地使导师的行为与引导学生独立解决目标数学问题的长期目标对齐。我们的模型是轻量级的，与之前端到端训练导师策略直接输出导师下一句话的工作相比，需要更少的计算资源。我们的实验结果表明，与LLM模拟辅导任务中的提示方式相比，这些修改带来了改进的长期结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [249] [Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task](https://arxiv.org/abs/2507.16196)
> *大型语言模型是否具备规划心智理论？来自多步骤说服任务MindGames的证据*

*Jared Moore, Ned Cooper, Rasmus Overmark, Beba Cibralic, Nick Haber, Cameron R. Jones* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 心智理论, 规划心智理论, 社交推理, MindGames

**Comment:** To appear in COLM, 2025

> **TL;DR:** 大型语言模型在规划心智理论（PToM）任务中表现不如人类，但在不需要太多心智状态推断的基线规划任务中表现优于人类，表明在类人社交推理方面存在显著差距。

**AI_Comments:** 该论文创新性地提出了“规划心智理论”（PToM）的概念，并设计了“MindGames”任务来评估LLM在动态社交情境中运用ToM的能力，而非仅仅停留在旁观者预测层面。这对于深入理解LLM的社交智能边界及其与人类智能的差异具有重要意义。研究结果揭示了LLM在需要深层心智状态推断和主动干预的社交推理方面仍有显著不足，为未来LLM的社会智能发展指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型心智理论（ToM）实验多将参与者置于旁观者角色，预测和解释他人的行为。然而，人类的ToM也涉及动态规划行动和策略性干预他人的心理状态。本文旨在评估LLM是否具备这种“规划心智理论”（PToM）能力。

**Method:** 本文提出了一个新颖的“规划心智理论”（PToM）任务——MindGames，该任务要求智能体推断对话者的信念和欲望，以说服他们改变行为。与以往的评估不同，该研究明确评估了ToM的使用案例。

**Result:** 人类在PToM任务中显著优于o1-preview（一种LLM），表现高出11%（p=0.006）。研究人员推测这是因为人类拥有其他智能体的隐含因果模型。相反，在需要类似规划量但心智状态推断最小的基线条件下（例如，在已知某人偏好时进行规划），o1-preview的表现优于人类。

**Conclusion:** 这些结果表明，在类人社交推理能力方面，大型语言模型与人类之间存在显著差距。

> **ai_Abstract:** 本研究通过引入“MindGames”这一多步骤说服任务，探讨大型语言模型（LLMs）是否具备规划心智理论（PToM）能力。与以往侧重旁观者角色的ToM评估不同，MindGames要求智能体主动推断并影响他人的心理状态以实现行为改变。实验结果显示，人类在PToM任务中显著优于LLM (o1-preview)，这可能归因于人类具备隐含的因果模型。然而，在仅需规划而心智推断需求较低的基线任务中，LLM表现优于人类。这表明LLM在复杂、类人社交推理方面与人类存在明显差距。

> **摘要翻译:** 最近的证据表明，大型语言模型（LLMs）展现出心智理论（ToM）能力。大多数ToM实验将参与者置于旁观者角色，预测和解释其他智能体的行为。然而，人类的ToM也有助于动态规划行动和策略性干预他人的心理状态。我们提出了MindGames：一个新颖的“规划心智理论”（PToM）任务，该任务要求智能体推断对话者的信念和欲望，以说服他们改变行为。与之前的评估不同，我们明确评估了ToM的使用案例。我们发现人类在我们的PToM任务中显著优于o1-preview（一种LLM）（高出11%；p=0.006）。我们推测这是因为人类拥有其他智能体的隐含因果模型（例如，他们知道，正如我们的任务所要求的那样，询问人们的偏好）。相比之下，在需要类似规划量但心智状态推断最小的基线条件下（例如，在已知某人偏好时进行规划），o1-preview的表现优于人类。这些结果表明，在类人社交推理能力和LLM能力之间存在显著差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [251] [Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition](https://arxiv.org/abs/2505.02304)
> *用于手语识别的生成式手语描述提示与多正例对比学习*

*Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao* | **Category: cs.CL, cs.CV** | **Updated: 2025-07-22**

**Keywords:** 手语识别, 生成式大型语言模型, 对比学习, 检索增强生成, 骨骼特征

**Comment:** 9 pages, 6 figures

> **TL;DR:** 本文提出了一种名为GSP-MC的新型手语识别方法，该方法首次将生成式大型语言模型（LLMs）集成到SLR任务中，并结合多正例对比学习，在中文SLR500和土耳其AUTSL数据集上取得了最先进的性能。

**AI_Comments:** 本文的创新点在于首次将生成式大型语言模型（LLMs）引入手语识别领域，并结合检索增强生成（RAG）和多正例对比学习，有效解决了手语标注复杂性带来的挑战。其提出的GSP-MC方法通过细致的提示工程和多级别特征对齐，实现了手语语义和动态的精确捕获。在多个跨语言数据集上取得的最先进性能，证明了该方法的有效性和泛化能力，对手语识别技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手语识别（SLR）在创建准确标注方面面临根本性挑战，因为同时存在的手动和非手动信号固有的复杂性。

**Method:** 本文提出了一种新颖的生成式手语描述提示多正例对比学习（GSP-MC）方法。该方法利用检索增强生成（RAG）与领域特定大型语言模型（LLMs），结合多步提示工程和专家验证的手语语料库来生成精确的多部分描述。GSP-MC方法还采用双编码器架构，通过概率匹配将分层骨骼特征与多个文本描述（全局、同义词和部分级别）进行双向对齐。该方法结合了全局和部分级别损失，优化KL散度以确保所有相关文本-骨骼对之间的鲁棒对齐，同时捕获手语级别语义和详细的部分动态。

**Result:** 实验证明，该方法在中文SLR500数据集上达到了97.1%的准确率，在土耳其AUTSL数据集上达到了97.07%的准确率，超越了现有方法，达到了最先进的性能。

**Conclusion:** 该方法的跨语言有效性突出了其在开发包容性通信技术方面的潜力。

> **ai_Abstract:** 针对手语识别（SLR）中准确标注的挑战，本文首次提出了一种将生成式大型语言模型（LLMs）集成到SLR任务中的方法——生成式手语描述提示多正例对比学习（GSP-MC）。该方法利用检索增强生成（RAG）、多步提示工程和专家语料库来生成精确的手语描述，并通过双编码器架构和概率匹配实现骨骼特征与多级别文本描述的双向对齐。通过结合全局和部分级别损失并优化KL散度，确保了文本-骨骼对的鲁棒对齐。实验结果表明，GSP-MC在中文SLR500和土耳其AUTSL数据集上均取得了最先进的性能，展现了其跨语言有效性和在包容性通信技术中的应用潜力。

> **摘要翻译:** 手语识别（SLR）在创建准确标注方面面临根本性挑战，因为同时存在的手动和非手动信号固有的复杂性。据我们所知，这是首次将生成式大型语言模型（LLMs）集成到SLR任务中的工作。我们提出了一种新颖的生成式手语描述提示多正例对比学习（GSP-MC）方法，该方法利用检索增强生成（RAG）与领域特定大型语言模型（LLMs），结合多步提示工程和专家验证的手语语料库来生成精确的多部分描述。GSP-MC方法还采用双编码器架构，通过概率匹配将分层骨骼特征与多个文本描述（全局、同义词和部分级别）进行双向对齐。我们的方法结合了全局和部分级别损失，优化KL散度以确保所有相关文本-骨骼对之间的鲁棒对齐，同时捕获手语级别语义和详细的部分动态。实验证明，该方法在中文SLR500（达到97.1%）和土耳其AUTSL数据集（97.07%准确率）上超越现有方法，达到了最先进的性能。该方法的跨语言有效性突出了其在开发包容性通信技术方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [267] [Learning without training: The implicit dynamics of in-context learning](https://arxiv.org/abs/2507.16003)
> *无需训练的学习：上下文学习的隐含动态*

*Benoit Dherin, Michael Munn, Hanna Mazzawi, Michael Wunder, Javier Gonzalvo* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 上下文学习, 大型语言模型, Transformer, MLP, 自注意力

**Comment:** 

> **TL;DR:** 本文通过理论和实验证明，Transformer块中自注意力层与MLP层的堆叠，能够根据上下文隐式修改MLP层的权重，解释了大型语言模型（LLMs）无需训练即可进行上下文学习的机制。

**AI_Comments:** 这篇论文创新性地从Transformer架构的内部机制出发，对LLM的上下文学习能力提供了具体的解释，将其归因于自注意力层对MLP层权重的隐式修改。这为理解LLM为何能在推理时学习新模式提供了理论基础和实验证据，对于LLM的可解释性和未来发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在推理时无需额外权重更新即可进行上下文学习的能力令人瞩目，但其内在机制尚不清楚。

**Method:** 研究通过理论和实验证明，自注意力层与MLP层的堆叠允许Transformer块根据上下文隐式修改MLP层的权重。具体来说，在温和的简化假设下，展示了Transformer块如何将上下文隐式转换为MLP层的低秩权重更新。

**Result:** 自注意力层与MLP层的堆叠使得Transformer块能够根据上下文隐式修改MLP层的权重。这种简单的机制可能是LLM不仅在训练期间，而且在上下文中也能学习的原因。Transformer块能够将上下文隐式地转换为MLP层的低秩权重更新。

**Conclusion:** Transformer块通过自注意力层和MLP层的堆叠，能够隐式地修改MLP层的权重，这种机制是大型语言模型实现上下文学习的关键。

> **ai_Abstract:** 大型语言模型（LLM）在推理时展现出无需权重更新的上下文学习能力。本研究旨在揭示其内在机制，提出Transformer块中自注意力层与MLP层的堆叠，能够根据上下文隐式修改MLP层的权重。通过理论和实验分析，论文阐明了Transformer块如何将上下文隐式地转换为MLP层的低秩权重更新，认为这是LLM实现上下文学习的核心原因。

> **摘要翻译:** 大型语言模型（LLM）最引人注目的特性之一是其上下文学习能力。即在推理时，LLM能够在提示中以示例形式呈现新的模式时，无需任何额外的权重更新即可学习这些模式，即使这些模式在训练期间从未见过。实现这一机制的方式在很大程度上仍然未知。在这项工作中，我们展示了自注意力层与MLP层的堆叠，允许Transformer块根据上下文隐式修改MLP层的权重。我们通过理论和实验论证，这种简单的机制可能是LLM不仅在训练期间，而且在上下文中也能学习的原因。具体来说，我们在温和的简化假设下，展示了Transformer块如何将上下文隐式地转换为MLP层的低秩权重更新。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [275] [HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing](https://arxiv.org/abs/2505.14311)
> *豪萨语自然语言处理：现状、挑战与未来方向*

*Shamsuddeen Hassan Muhammad, Ibrahim Said Ahmad, Idris Abdulmumin, Falalu Ibrahim Lawan, Babangida Sani, Sukairaj Hafiz Imam, Yusuf Aliyu, Sani Abdullahi Sani, Ali Usman Umar, Tajuddeen Gwadabe, Kenneth Church, Vukosi Marivate* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 豪萨语NLP, 低资源语言, HausaNLP, 大型语言模型, 研究方向

**Comment:** 

> **TL;DR:** 豪萨语作为一种低资源语言，其自然语言处理（NLP）领域面临数据集和模型表示不足的挑战。本文概述了豪萨语NLP的现状，介绍了HausaNLP资源目录，讨论了其在大型语言模型中的整合挑战，并提出了未来的研究方向。

**AI_Comments:** 该论文通过系统性地梳理豪萨语NLP的现状、挑战和资源，并提出具体的研究方向，为低资源语言的NLP发展提供了一个全面的视角和可行的路径。特别是HausaNLP目录的推出，对于集中和促进豪萨语NLP研究具有重要意义。同时，对LLM中豪萨语整合挑战的讨论也具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管豪萨语拥有超过1.2亿第一语言使用者和8000万第二语言使用者，但其自然语言处理（NLP）领域仍被低估，面临开源数据集有限和模型表示不足等挑战。

**Method:** 本文概述了豪萨语NLP的当前状态，系统性地审视了现有资源、研究贡献以及在文本分类、机器翻译、命名实体识别、语音识别和问答等基本NLP任务中的差距。论文还介绍了HausaNLP，一个整合数据集、工具和研究工作的精选目录，并讨论了将豪萨语整合到大型语言模型（LLMs）中的挑战，包括次优的标记化和方言变异问题。最后，提出了强调数据集扩展、改进语言建模方法和加强社区合作的战略研究方向。

**Result:** 本文提供了对豪萨语NLP现状的系统性审查，推出了HausaNLP（一个聚合数据集、工具和研究工作的精选目录），讨论了豪萨语在大型语言模型中面临的挑战，并提出了加速豪萨语NLP进展的战略研究方向。

**Conclusion:** 本研究为加速豪萨语自然语言处理的进展奠定了基础，并为更广泛的多语言自然语言处理研究提供了宝贵的见解。

> **ai_Abstract:** 本文深入探讨了豪萨语自然语言处理（NLP）的现状、挑战和未来发展方向。尽管豪萨语拥有庞大的使用者群体，但其NLP研究仍属低资源领域，面临数据集和模型表示不足的问题。论文系统性地审视了豪萨语在文本分类、机器翻译等核心NLP任务上的现有资源和研究空白，并推出了HausaNLP——一个整合数据集、工具和研究成果的在线目录。此外，文章还讨论了将豪萨语整合到大型语言模型中遇到的标记化和方言挑战，并提出了通过数据集扩展、改进语言建模和加强社区合作来推动豪萨语NLP发展的策略。

> **摘要翻译:** 豪萨语自然语言处理（NLP）近年来受到越来越多的关注，但尽管全球有超过1.2亿第一语言（L1）使用者和8000万第二语言（L2）使用者，它作为一种低资源语言仍未得到充分研究。尽管高资源语言取得了显著进展，豪萨语NLP仍面临持续的挑战，包括有限的开源数据集和不足的模型表示。本文概述了豪萨语NLP的当前状态，系统性地审视了现有资源、研究贡献以及在文本分类、机器翻译、命名实体识别、语音识别和问答等基本NLP任务中的差距。我们介绍了HausaNLP（https://catalog.hausanlp.org），这是一个精选目录，汇集了数据集、工具和研究工作，以增强可访问性并推动进一步发展。此外，我们讨论了将豪萨语整合到大型语言模型（LLMs）中的挑战，解决了次优的标记化和方言变异问题。最后，我们提出了强调数据集扩展、改进语言建模方法和加强社区合作的战略研究方向，以推进豪萨语NLP。我们的工作为加速豪萨语NLP进展奠定了基础，并为更广泛的多语言NLP研究提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [284] [WakenLLM: A Fine-Grained Benchmark for Evaluating LLM Reasoning Potential and Reasoning Process Stability](https://arxiv.org/abs/2507.16199)
> *WakenLLM：一个评估LLM推理潜力和推理过程稳定性的细粒度基准*

*Zipeng Ling, Yuehao Tang, Shuliang Liu, Junqi Yang, Shenghong Fu, Yao Wan, Kejia Huang, Zhichao Hou, Xuming Hu* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 推理能力, 基准测试, 模糊感知, WakenLLM

**Comment:** 

> **TL;DR:** 本文提出了WakenLLM，一个细粒度基准，用于评估大型语言模型（LLM）的推理潜力及其推理过程的稳定性，旨在解决LLM输出“Unknown”的模糊感知问题。

**AI_Comments:** 该论文的创新点在于提出了“模糊感知”这一概念，并构建了一个细粒度基准WakenLLM来专门评估LLM在面对不确定性时的真实推理能力和过程稳定性。它超越了传统上只关注“诚实性”的评估方法，深入探讨了LLM输出“Unknown”的深层原因，即区分了模型无能和问题固有的不确定性。这对于理解LLM的局限性、指导模型改进以及开发更可靠的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前对LLM输出“Unknown”的评估主要关注其是否“诚实”，而非其产生原因，这混淆了两种情况：真正不确定的输入和模型未能解决的可解问题。作者称之为“模糊感知”（Vague Perception）现象。

**Method:** 引入了一个框架，量化归因于模型能力不足的“Unknown”响应比例，并测试引导式刺激是否能将其转化为正确（“Known”）或本质上不确定的结果。通过分离不确定性来源，该方法提供了LLM推理限制及其改进潜力的更清晰图景。他们还通过应用不同方法测试模型能否达到给定基准框架下的理论推理任务准确率。

**Result:** 获得了不同LLM在推理任务上的理论准确率，并测试了模型是否能达到该准确率。该方法为LLM的推理极限及其改进潜力提供了更清晰的认识。

**Conclusion:** 他们的工作对于探索LLM的真实推理能力并为解决“模糊感知”现象提供新视角具有重要意义。

> **ai_Abstract:** 本文提出了WakenLLM，一个细粒度基准，旨在解决大型语言模型（LLM）在推理任务中频繁输出“Unknown”标签时所产生的“模糊感知”问题。现有评估未能区分模型能力不足与问题本身的不确定性。WakenLLM框架通过量化归因于模型缺陷的“Unknown”响应，并探索引导刺激如何改善这些响应，从而更清晰地揭示LLM的推理限制和改进潜力。该工作通过测量理论准确率并测试模型能否达到，为理解LLM的真实推理能力和解决“模糊感知”提供了新视角。

> **摘要翻译:** 大型语言模型（LLM）经常输出标签“Unknown”，然而当前的评估几乎只关注这些答案是否“诚实”，而不是它们为何产生。这模糊了两种不同的情况：(i) 真正不确定的输入和 (ii) 模型未能解决的可解问题。我们将这种现象称为“模糊感知”（Vague Perception）。因此，我们引入了一个框架，量化归因于模型能力不足的“Unknown”响应比例，并测试引导式刺激是否能将其转化为正确（“Known”）或本质上不确定的结果。通过分离这些不确定性来源，我们的方法提供了LLM推理限制及其改进潜力的更清晰图景。由于我们获得了不同LLM在推理任务上的理论准确率，我们应用不同的方法来测试模型在给定基准框架下是否能达到该准确率。我们的工作对于探索LLM的真实推理能力并为解决“模糊感知”现象提供新视角具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [305] [Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models](https://arxiv.org/abs/2505.16104)
> *分层安全重校准：轻量级恢复剪枝大型视觉-语言模型的安全性*

*Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang* | **Category: cs.CL, cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 大型视觉-语言模型, 模型剪枝, 安全性恢复, 分层安全重校准, 注意力头

**Comment:** ACL 2025 Findings

> **TL;DR:** 本文提出了一种名为分层安全重校准（HSR）的轻量级方法，用于解决剪枝大型视觉-语言模型（LVLMs）后安全性下降的问题，通过识别并恢复对安全至关重要的注意力头中的神经元，显著提高了模型的安全性能。

**AI_Comments:** 该论文的创新点在于提出了HSR这一新颖且轻量级的方法，首次明确专注于剪枝后大型视觉-语言模型安全性的恢复。其分层重校准策略（从注意力头到神经元）具有独特性和针对性，解决了模型压缩与安全性能之间的矛盾，对于LVLMs在资源受限环境中的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型视觉-语言模型（LVLMs）规模的增大，为在资源受限环境中部署而进行的网络剪枝技术受到关注。然而，研究发现剪枝通常会导致模型安全性能的下降，因此需要一种方法来恢复剪枝后LVLMs的安全性。

**Method:** 本研究提出了一种新颖的轻量级方法，称为分层安全重校准（HSR）。HSR首先量化每个注意力头对安全性的贡献，识别出最关键的注意力头，然后选择性地恢复这些注意力头中对维持安全至关重要的神经元。这个过程从注意力头层面到神经元层面分层地重校准了剪枝LVLMs的安全性。

**Result:** HSR在各种模型和剪枝策略上进行了验证，始终实现了安全性能的显著提升。

**Conclusion:** HSR成功地解决了剪枝大型视觉-语言模型后安全性能下降的问题，是首个明确专注于剪枝后LVLMs安全恢复的工作，并取得了显著的改进。

> **ai_Abstract:** 本文提出了一种名为分层安全重校准（HSR）的轻量级方法，旨在解决大型视觉-语言模型（LVLMs）在剪枝后出现的安全性能下降问题。HSR通过量化注意力头对安全性的贡献，识别关键注意力头，并在此基础上选择性地恢复这些关键头中对安全至关重要的神经元，从而实现从注意力头到神经元层面的分层安全重校准。实验结果表明，HSR在不同的模型和剪枝策略下均能显著提升LVLMs的安全性，是首个专注于此领域的研究。

> **摘要翻译:** 随着大型视觉-语言模型（LVLMs）规模的不断增长，旨在压缩模型以在资源受限环境中部署的网络剪枝技术受到了广泛关注。然而，我们观察到剪枝通常会导致安全性能的下降。为了解决这个问题，我们提出了一种新颖且轻量级的方法，称为分层安全重校准（HSR）。HSR首先量化每个注意力头对安全性的贡献，识别出最关键的注意力头，然后选择性地恢复这些注意力头中在维持安全方面起关键作用的神经元。这个过程分层地重校准了剪枝LVLMs的安全性，从注意力头层面到神经元层面逐步进行。我们在各种模型和剪枝策略上验证了HSR，始终实现了安全性能的显著提升。据我们所知，这是首个明确专注于剪枝后LVLMs安全恢复的工作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [314] [FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents](https://arxiv.org/abs/2507.16248)
> *FinResearchBench：一个基于逻辑树的金融研究智能体评估框架*

*Run Sun, Zuo Bai, Wentao Zhang, Yuxiang Zhang, Li Zhao, Shan Sun, Zhengwen Qiu* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** AI智能体, 金融研究, 评估框架, Agent-as-a-Judge, 逻辑树

**Comment:** 

> **TL;DR:** FinResearchBench是一个基于逻辑树的Agent-as-a-Judge评估框架，专门用于全面自动化评估金融研究智能体的能力。

**AI_Comments:** 该论文的创新点在于提出了首个基于逻辑树的Agent-as-a-Judge评估系统，通过结构化的逻辑树来评估AI智能体的研究成果，这比传统的基于文本匹配或人工评估的方法更加精细和可靠。同时，其专注于金融研究领域，填补了特定专业领域评估工具的空白，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前，针对深度研究智能体（特别是金融研究领域）的系统性、自动化评估框架和基准非常稀缺。金融研究问题具有独特的复杂性和微妙性，现有框架无法很好地应对。

**Method:** 本文提出了FinResearchBench，这是一个基于逻辑树的Agent-as-a-Judge系统，专门用于评估金融研究智能体。该系统通过提取研究结果的逻辑树作为中间信息，进行全面、可靠和鲁棒的评估。

**Result:** FinResearchBench提供了一个全面自动化的评估系统，能够对金融研究领域7种关键任务类型的研究智能体进行评估。它是首个创新性的Agent-as-a-Judge系统，通过逻辑树提取研究成果并作为评估的中间信息，覆盖了70个典型的金融研究问题，涵盖了7种常见的任务类型。

**Conclusion:** 本文提出了FinResearchBench，一个创新的、基于逻辑树的Agent-as-a-Judge评估框架，专门用于对金融研究智能体进行全面、可靠和鲁棒的自动化评估，填补了该领域评估基准的空白。

> **ai_Abstract:** 本文针对现有金融研究智能体评估框架的不足，提出了一种名为FinResearchBench的创新性评估框架。该框架基于逻辑树的Agent-as-a-Judge方法，能够全面、自动化地评估金融研究智能体在7种关键任务类型上的表现。FinResearchBench通过提取研究成果的逻辑树作为中间信息，实现了更可靠和鲁棒的评估，并涵盖了70个典型的金融研究问题。

> **摘要翻译:** 最近，AI智能体在智能方面迅速发展，并广泛应用于专业研究应用，例如STEM、软件开发、金融等。在这些AI智能体中，深度研究智能体是一个关键类别，因为它可以执行长周期任务并解决更复杂的问题。然而，目前鲜有评估框架和基准能够系统地、自动化地研究这些研究智能体的能力。此外，金融研究问题具有独特的复杂性和微妙性。为了填补这一空白，我们提出了FinResearchBench，这是一个基于逻辑树的Agent-as-a-Judge系统，专门针对金融研究智能体。它提供了对金融研究领域7种关键任务类型的研究智能体进行全面和自动化的评估。这项工作的贡献是双重的：（1）第一个创新的Agent-as-a-Judge系统，它提取研究成果的逻辑树并将其用作中间信息，以提供全面、可靠和鲁棒的评估；（2）面向金融领域，涵盖了70个典型的金融研究问题，分布在7种该领域常见的任务类型中。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [330] [Self-Correcting Code Generation Using Small Language Models](https://arxiv.org/abs/2505.23060)
> *小型语言模型自纠正代码生成*

*Jeonghun Cho, Deokhyung Kang, Hyounghun Kim, Gary Geunbae Lee* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 代码生成, 自纠正, 小型语言模型, 强化学习, 多轮纠正

**Comment:** 

> **TL;DR:** 本文研究小型语言模型在代码生成中的自纠正能力，发现它们难以有效自反思。为此，提出CoCoS方法，通过在线强化学习和新的奖励函数显著提升了小型模型的多轮代码纠正能力，在MBPP和HumanEval上取得了显著改进。

**AI_Comments:** 这项研究的创新之处在于，它直接解决了小型语言模型在代码生成自纠正方面存在的挑战，而以往的研究多集中于大型模型。通过引入在线强化学习和定制的奖励机制，CoCoS为小型模型提供了实现多轮代码纠正的有效途径，这对于资源受限的环境或需要部署更轻量级模型的场景具有重要意义。其结果表明，即使是小型模型，在经过适当的训练后也能展现出强大的自纠正能力，这为未来小型LLM的应用拓展了可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自纠正代码生成研究主要集中于专有大型模型，而小型语言模型是否具备有效的自我反思和引导输出的能力尚未被探索。研究发现小型模型在这方面表现不佳。

**Method:** 本文引入CoCoS，一种旨在增强小型语言模型多轮代码纠正能力的方法。具体而言，CoCoS提出了一个在线强化学习目标，训练模型在轮次进行中自信地保持正确输出并逐步纠正错误输出。该方法还包含一个在整个轨迹上聚合奖励的累积奖励函数，以及一个更适合多轮纠正场景的细粒度奖励。

**Result:** 使用1B规模的模型，CoCoS在MBPP上实现了35.8%的改进，在HumanEval上实现了27.7%的改进，均优于基线模型。

**Conclusion:** CoCoS方法能够显著提升小型语言模型在多轮代码纠正中的表现，使其在保持初始响应质量的同时，通过自纠正实现实质性改进，证明了小型模型通过特定训练也能有效进行自纠正。

> **ai_Abstract:** 本文探讨了小型语言模型在代码生成自纠正方面的能力。研究发现，与大型专有模型不同，小型模型难以有效进行自我反思和修正。为解决此问题，作者提出了CoCoS框架，该框架采用在线强化学习，并设计了累积奖励和细粒度奖励函数，以训练小型模型进行多轮代码纠正。实验结果表明，CoCoS显著提升了1B规模模型在MBPP和HumanEval基准测试上的性能，证明了通过专门训练小型模型也能有效实现自纠正。

> **摘要翻译:** 自纠正通过允许语言模型通过连续细化来修改和改进其输出，在代码生成中展现了潜力。最近的研究探索了使用专有模型结合验证或反馈循环的基于提示的策略，以及利用其强大推理能力的基于训练的方法。然而，较小的模型是否具备有效通过自我反思引导其输出的能力仍未被探索。我们的发现揭示，在两种自纠正范式下，较小的模型都难以表现出反思性修正行为。为此，我们引入了CoCoS，一种旨在增强小型语言模型多轮代码纠正能力的方法。具体而言，我们提出了一种在线强化学习目标，训练模型在轮次进行中自信地保持正确输出，同时逐步纠正不正确的输出。我们的方法具有一个在整个轨迹上聚合奖励的累积奖励函数，以及一个更适合多轮纠正场景的细粒度奖励。这有助于模型在提高初始响应质量的同时，通过自纠正实现实质性改进。对于1B规模的模型，CoCoS在MBPP上实现了35.8%的改进，在HumanEval上实现了27.7%的改进，均优于基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [340] [Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving](https://arxiv.org/abs/2507.06229)
> *Agent KB：利用跨领域经验实现智能体问题解决*

*Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, Fang Wu, He Zhu, Ge Zhang, Jiaheng Liu, Xingyao Wang, Sirui Hong, Chenglin Wu, Hao Cheng, Chi Wang, Wangchunshu Zhou* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-21**

**Keywords:** Agent KB, 知识库, 跨领域经验, 智能体, 问题解决

**Comment:** 

> **TL;DR:** Agent KB是一个共享知识库，通过教师-学生双阶段检索机制，使AI智能体能有效学习和利用跨领域经验，显著提升了在GAIA和SWE-bench基准上的问题解决成功率。

**AI_Comments:** Agent KB的创新之处在于其提出的教师-学生双阶段检索机制，它有效地结合了宏观策略指导和微观执行完善，从而实现了跨领域知识的高效迁移。这对于提升AI智能体的泛化能力和鲁棒性具有重要意义，尤其是在复杂、多样的任务环境中。消融研究进一步证实了其模块设计的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI智能体无法有效学习彼此的问题解决经验，也无法利用过去的成功经验指导自我反思和纠错，尤其是在新任务中表现不足。

**Method:** 本文提出了Agent KB，一个共享知识库，它捕获高级问题解决策略和详细执行经验。它实现了一种新颖的教师-学生双阶段检索机制：学生智能体检索工作流级别的模式以获取战略指导，而教师智能体识别执行级别的模式以进行完善。这种分层方法使智能体能够通过整合外部来源的多样化策略来突破有限的推理路径。

**Result:** 在GAIA基准测试中，Agent KB显著提高了性能，在pass@1下整体成功率提升了高达6.06个百分点。对于SWE-bench代码修复任务，系统显著提高了解决率，其中o3-mini在pass@1下实现了8.67个百分点的提升（从23%到31.67%）。消融研究表明，完善模块最为关键，其移除导致在挑战性三级任务上性能下降3.85%。

**Conclusion:** 有效地进行知识迁移需要战略指导和执行层面的完善。Agent KB通过其独特的教师-学生双阶段检索机制，成功地使AI智能体能够学习和利用跨领域经验，从而显著提升了问题解决能力。

> **ai_Abstract:** Agent KB是一个旨在解决当前AI智能体无法有效学习和利用跨领域经验问题的共享知识库。它通过独特的教师-学生双阶段检索机制，提供从高级策略到具体执行的全面指导。在GAIA和SWE-bench基准测试中，Agent KB显著提升了问题解决成功率和代码修复率，特别强调了执行层面完善在知识迁移中的关键作用。

> **摘要翻译:** 当前的人工智能智能体无法有效地从彼此的问题解决经验中学习，也无法利用过去的成功经验来指导新任务中的自我反思和错误纠正。我们引入了Agent KB，一个共享知识库，它捕获了高级问题解决策略和详细的执行经验，从而实现了跨智能体框架的知识转移。Agent KB实现了一种新颖的教师-学生双阶段检索机制，其中学生智能体检索工作流级别的模式以获取战略指导，而教师智能体识别执行级别的模式以进行完善。这种分层方法使智能体能够通过整合来自外部来源的多样化策略来突破有限的推理路径。在GAIA基准测试中的评估表明，性能获得了显著提升，Agent KB在pass@1下整体成功率提高了高达6.06个百分点。对于SWE-bench代码修复任务，我们的系统显著提高了解决率，其中o3-mini在pass@1下实现了8.67个百分点的提升（从23%到31.67%）。我们的消融研究表明，完善模块被证明是最关键的，其移除导致在挑战性三级任务上性能下降3.85%，这突出表明有效的知识转移需要战略指导和执行层面的完善。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [343] [SciFi-Benchmark: Leveraging Science Fiction To Improve Robot Behavior](https://arxiv.org/abs/2503.10706)
> *科幻基准：利用科幻小说改进机器人行为*

*Pierre Sermanet, Anirudha Majumdar, Vikas Sindhwani* | **Category: cs.CL, cs.AI, cs.CY, cs.HC, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 机器人伦理, 人工智能对齐, 科幻基准, 大型语言模型, 道德宪法

**Comment:** Minor improvements over previous version

> **TL;DR:** 该研究提出了一个名为SciFi-Benchmark的基准，通过分析824部科幻作品中的关键决策来评估AI和机器人与人类价值观的对齐程度，并发现结合科幻启发的“宪法”能显著提高LLM与人类价值观的对齐性，即使在对抗性环境下也表现出色。

**AI_Comments:** 这项研究的创新之处在于其独特地利用了科幻文学作为探索AI伦理和价值观对齐的资源，构建了一个大规模且富有想象力的基准测试。通过从科幻作品中提取“关键决策”并结合LLM生成问答，提供了一种新颖且可扩展的评估AI道德行为的方法。引入“科幻启发宪法”并通过修正过程使其自动改进，为AI伦理规则的制定提供了一个实用的框架。研究结果表明，结合这类“宪法”可以显著提升LLM的道德对齐性，这对于未来AI系统的开发和部署具有重要指导意义，尤其是在应对现实世界复杂伦理挑战方面。其对对抗性鲁棒性的发现也增加了其实用性。该数据集的发布将极大地促进相关领域的进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能和机器人技术的快速发展，出现了一个引人入胜的问题：由新兴AI系统控制的机器人是否能与人类价值观高度对齐？

**Method:** 研究通过分析824部主要科幻文学作品（电影、电视、小说和科学书籍）中的关键决策时刻（AI或机器人做出好或坏的决策），提出了一个可扩展的方法来探究AI与人类价值观的对齐问题。利用最先进的LLM回忆这些关键时刻，生成类似情境下的问题、代理的决策以及可能的替代决策。通过一套人类投票的答案来衡量模型与人类价值观的对齐程度。此外，研究还生成了可通过修正过程自动改进的规则，以创建首个受科幻启发的“宪法”，用于促进现实世界中AI和机器人的道德行为。

**Result:** 1. 现代LLM与“宪法”结合后与人类价值观高度对齐（95.8%），这与科幻作品中通常令人不安的决策（仅21.2%的对齐度）形成对比。2. 生成的“宪法”显著提高了模型与人类价值观的对齐度（从基础模型的79.4%提高到95.8%），并且在对抗性提示设置下显示出韧性（从23.3%提高到92.3%）。3. 这些“宪法”在ASIMOV基准测试中也表现出色，该基准源自真实世界的图像和医院伤害报告。

**Conclusion:** 受科幻启发的“宪法”能够使AI和机器人与人类价值观高度对齐，并适用于现实世界的复杂情况。研究发布了SciFi-Benchmark数据集，以推动机器人伦理和安全研究。

> **ai_Abstract:** 本研究提出SciFi-Benchmark，一个基于824部科幻作品关键决策的大规模数据集，旨在评估AI和机器人与人类价值观的对齐程度。通过LLM生成问题和决策，并结合人类投票答案进行评估。研究引入了受科幻启发的“宪法”来指导AI行为，结果显示，与这些“宪法”结合的现代LLM能显著提高与人类价值观的对齐度（95.8%），远超科幻作品中通常较低的对齐表现，并在对抗性环境下保持鲁棒性。这些“宪法”在其他真实世界基准测试中也表现优异。SciFi-Benchmark数据集的发布旨在推动机器人伦理和安全研究。

> **摘要翻译:** 鉴于人工智能（AI）和机器人技术最近的进展速度，一个引人入胜的问题正在浮现：由新兴AI系统控制的机器人是否会与人类价值观高度对齐？在这项工作中，我们提出了一种可扩展的方法来探究这个问题，通过生成一个基准，涵盖了824部主要科幻文学作品（电影、电视、小说和科学书籍）中的关键时刻，在这些时刻，一个代理（AI或机器人）做出了关键决策（好的或坏的）。我们使用最先进的大型语言模型（LLM）对每个关键时刻的回忆来生成类似情境下的问题、代理所做的决策以及它可以做出的替代决策（好的或坏的）。然后，我们通过一套人类投票的答案来衡量模型与人类价值观的对齐程度。我们还生成了可以通过修正过程自动改进的规则，以生成首个受科幻启发的“宪法”，用于促进现实世界中AI和机器人的道德行为。我们的第一个发现是，现代LLM与“宪法”结合后，与人类价值观高度对齐（95.8%），这与科幻作品中通常令人不安的决策（仅21.2%的对齐度）形成对比。其次，我们发现生成的“宪法”相对于基础模型显著提高了对齐度（79.4%提高到95.8%），并且在对抗性提示设置下显示出韧性（23.3%提高到92.3%）。此外，我们发现这些“宪法”在ASIMOV基准测试中也表现出色，该基准源自真实世界的图像和医院伤害报告。因此，受科幻启发的“宪法”高度对齐且适用于现实世界的情况。我们发布了SciFi-Benchmark：一个大规模数据集，旨在推进机器人伦理和安全研究。它包含通过新颖的LLM内省过程生成的9,056个问题和53,384个答案，以及一个较小的人类标记评估集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [345] [iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss](https://arxiv.org/abs/2507.16263)
> *iShumei-Chinchunmei 在 SemEval-2025 任务 4：一种使用有效遗忘损失的平衡遗忘与保留多任务框架*

*Yujian Sun, Tian Li* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 机器遗忘, 有效遗忘损失, 多任务框架, SemEval

**Comment:** 

> **TL;DR:** 本文针对大型语言模型（LLM）的机器遗忘问题，提出了一种名为“有效遗忘损失”的新型可控遗忘损失，并将其整合到平衡遗忘与保留的多任务框架中。该系统在SemEval 2025任务4中排名第5。

**AI_Comments:** 本文针对LLM的机器遗忘这一重要且日益增长的问题提供了解决方案。其创新点在于提出了“有效遗忘损失”以及将其融入多任务框架，以平衡遗忘效果和模型能力保留。在SemEval竞赛中取得的良好排名也验证了方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）的广泛应用，如何让LLM遗忘预训练过程中记忆的非合规和敏感数据成为一个重要挑战。机器遗忘旨在有限计算资源下高效擦除LLM中的敏感信息。SemEval 2025任务4为此设立了基准，旨在推进该领域的研究。

**Method:** 本文提出了一种更可控的遗忘损失，命名为“有效遗忘损失”（Effective Unlearning Loss），并探索将其与各种技术相结合，以实现更高效和可控的遗忘。系统采用了一个平衡遗忘与保留的多任务框架。

**Result:** 该系统在SemEval 2025任务4的“从大型语言模型中遗忘敏感内容”竞赛排行榜上最终排名第5。

**Conclusion:** 本文提出的有效遗忘损失和平衡遗忘与保留的多任务框架，能够实现大型语言模型的高效和可控遗忘，并在相关竞赛中取得了优异成绩，证明了其方法的有效性和竞争力。

> **ai_Abstract:** 针对大型语言模型（LLM）遗忘敏感内容的挑战，本文提出了一个名为“有效遗忘损失”（Effective Unlearning Loss）的新型可控遗忘损失，并将其整合到一个平衡遗忘与保留的多任务框架中，旨在实现高效和可控的机器遗忘。该系统在SemEval 2025任务4的“从大型语言模型中遗忘敏感内容”竞赛中表现出色，最终排名第5。

> **摘要翻译:** 随着大型语言模型（LLM）的广泛采用，LLM 在预训练期间记忆的非合规数据遗忘挑战受到了越来越多的关注。机器遗忘专注于在有限的计算资源下高效地从 LLM 中擦除敏感信息。为了推进该领域的研究，SemEval 2025 任务 4：“从大型语言模型中遗忘敏感内容”引入了三个遗忘数据集，并通过评估遗忘有效性和标准能力的保留来建立基准。在这项工作中，我们提出了一种更可控的遗忘损失，即有效遗忘损失，并探索其与各种技术的结合，以实现更高效和可控的遗忘。我们的系统最终在竞赛排行榜上排名第 5。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [358] [Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction](https://arxiv.org/abs/2505.23822)
> *基于多任务LLM的精神健康预测中语音作为多模态数字表型*

*Mai Ali, Christopher Lucasius, Tanmay P. Patel, Madison Aitken, Jacob Vorstman, Peter Szatmari, Marco Battaglia, Deepa Kundur* | **Category: cs.CL, cs.MM** | **Updated: 2025-07-22**

**Keywords:** 语音数字表型, 精神健康预测, 多任务学习, 大型语言模型, 抑郁症检测

**Comment:** 6 pages, 1 figure, 3 tables. Accepted to ICSM 2025. The corresponding
  author is Mai Ali (maia dot ali at mail dot utoronto dot ca). Christopher
  Lucasius and Tanmay P. Patel contributed equally

> **TL;DR:** 本文提出将语音作为三模态数据（文本、声学地标、声学生物标志物）并结合多任务学习（预测抑郁症、自杀意念、睡眠障碍）和纵向分析，利用大型语言模型进行精神健康预测，在抑郁症早期预警数据集上取得了70.8%的平衡准确率，优于单一模态和单任务方法。

**AI_Comments:** 该论文的创新点在于将语音数据提升为三模态处理，并结合多任务学习和纵向分析，以更全面地捕捉精神健康状况。利用LLM架构进行语音分析也具有前瞻性。这种多维度、多任务的预测方法对于复杂精神疾病的早期预警和管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语音是精神健康的非侵入性数字表型，但常被视为单一模态，未能充分利用其潜力。此外，青少年抑郁症常伴有多种共病，如自杀意念和睡眠障碍，这为多任务学习提供了机会。

**Method:** 本研究提出将患者语音数据视为三模态（语音衍生的文本、声学地标和声学生物标志物）多媒体数据源，并探索基于大型语言模型（LLM）的架构进行语音抑郁症预测。同时，通过多任务学习（MTL）同步预测抑郁症、自杀意念和睡眠障碍。此外，还提出了纵向分析策略来建模跨多次临床互动的时间变化。

**Result:** 所提出的三模态、纵向多任务学习方法在抑郁症早期预警数据集上取得了70.8%的平衡准确率。该准确率高于单一模态、单任务和非纵向方法。

**Conclusion:** 结合语音的三模态处理、多任务学习和纵向分析，能显著提高基于语音的精神健康预测性能，尤其在抑郁症、自杀意念和睡眠障碍的综合预测中表现优异。

> **ai_Abstract:** 本文提出一种新颖的方法，将语音作为多模态（文本、声学地标、声学生物标志物）数字表型，并结合基于大型语言模型的多任务学习和纵向分析，用于精神健康预测，特别是抑郁症、自杀意念和睡眠障碍的同步检测。该方法在抑郁症早期预警数据集上表现出优越的性能，平衡准确率达到70.8%，超越了传统单一模态和单任务方法。

> **摘要翻译:** 语音是一种非侵入性的数字表型，可以为精神健康状况提供有价值的见解，但它通常被视为单一模态。与此相反，我们建议将患者语音数据视为用于抑郁症检测的三模态多媒体数据源。本研究探索了基于大型语言模型（LLM）的架构在多模态（整合了语音衍生的文本、声学地标和声学生物标志物）语音抑郁症预测方面的潜力。青少年抑郁症是一个重大挑战，并且通常与多种疾病（例如自杀意念和睡眠障碍）并存。这为将多任务学习（MTL）整合到我们的研究中提供了额外的机会，通过多模态公式同时预测抑郁症、自杀意念和睡眠障碍。我们还提出了一种纵向分析策略，该策略模拟了多次临床互动中的时间变化，从而全面了解病情的进展。我们提出的方法，即具有三模态、纵向MTL的方法，在抑郁症早期预警数据集上进行了评估。它实现了70.8%的平衡准确率，高于单一模态、单任务和非纵向方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [362] [ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs](https://arxiv.org/abs/2507.16488)
> *ICR探测器：追踪隐藏状态动态以实现大型语言模型中可靠的幻觉检测*

*Zhenliang Zhang, Xinyu Hu, Huixuan Zhang, Junzhe Zhang, Xiaojun Wan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 幻觉检测, 大型语言模型, 隐藏状态, ICR分数, ICR探测器

**Comment:** Accepted to ACL 2025 (Main Conference)

> **TL;DR:** 大型语言模型容易产生幻觉，本文提出了一种名为ICR探测器的新方法，通过追踪隐藏状态的动态演变和引入ICR分数来有效检测幻觉，且所需参数显著减少。

**AI_Comments:** 该研究通过关注LLM隐藏状态的动态演变而非静态表示，为幻觉检测提供了一个创新视角。ICR分数和ICR探测器的提出，不仅提高了检测的有效性和效率（参数更少），还增强了方法的可解释性，这对于深入理解LLM行为模式和提升其可靠性具有重要意义和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的幻觉损害了其可靠性。现有基于隐藏状态的幻觉检测方法主要关注静态和孤立的表示，忽视了隐藏状态跨层的动态演变，从而限制了其检测效能。

**Method:** 本文将研究重点转向隐藏状态的更新过程，并引入了ICR分数（信息对残差流的贡献）这一新颖度量，用于量化模块对隐藏状态更新的贡献。在此基础上，提出了一种名为ICR探测器（ICR Probe）的幻觉检测方法，该方法能够捕获隐藏状态的跨层演变。

**Result:** ICR分数在区分幻觉方面被经验验证为有效且可靠。ICR探测器在幻觉检测上取得了卓越的性能，并且参数量显著减少。此外，消融研究和案例分析为该方法的底层机制提供了更深入的见解，提高了其可解释性。

**Conclusion:** 通过追踪隐藏状态的动态演变并利用ICR分数，ICR探测器为大型语言模型中的幻觉检测提供了一种有效、高效且可解释的方法。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）中存在的幻觉问题，提出了一种新颖的幻觉检测方法——ICR探测器。该方法通过引入ICR分数来量化模块对隐藏状态更新的贡献，从而关注并捕捉隐藏状态在模型层间的动态演变，而非仅仅依赖静态表示。实验结果表明，ICR探测器在幻觉检测方面表现出优越性能，且所需参数量显著减少，同时通过深入分析提升了方法的可解释性。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但它们生成幻觉的倾向损害了其可靠性。现有的利用隐藏状态的幻觉检测方法主要关注静态和孤立的表示，忽略了它们跨层的动态演变，这限制了其有效性。为了解决这一限制，我们将重点转移到隐藏状态更新过程，并引入了一种新颖的度量——ICR分数（信息对残差流的贡献），该分数量化了模块对隐藏状态更新的贡献。我们通过经验验证，ICR分数在区分幻觉方面是有效且可靠的。基于这些见解，我们提出了一种幻觉检测方法——ICR探测器，它捕获了隐藏状态的跨层演变。实验结果表明，ICR探测器以显著更少的参数实现了卓越的性能。此外，消融研究和案例分析为该方法的底层机制提供了更深入的见解，提高了其可解释性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [370] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
> *Gemini 2.5：以先进推理、多模态、长上下文和下一代代理能力推动前沿*

*Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, Ilaï Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre Ramé, Sagar Waghmare, Helen Miller, Nathan Byrd, Ashrith Sheshan, Raia Hadsell Sangnie Bhardwaj, Pawel Janus, Tero Rissa, Dan Horgan, Sharon Silver, Ayzaan Wahid, Sergey Brin, Yves Raimond, Klemen Kloboves, Cindy Wang, Nitesh Bharadwaj Gundavarapu, Ilia Shumailov, Bo Wang, Mantas Pajarskas, Joe Heyward, Martin Nikoltchev, Maciej Kula, Hao Zhou, Zachary Garrett, Sushant Kafle, Sercan Arik, Ankita Goel, Mingyao Yang, Jiho Park, Koji Kojima, Parsa Mahmoudieh, Koray Kavukcuoglu, Grace Chen, Doug Fritz, Anton Bulyenov, Sudeshna Roy, Dimitris Paparas, Hadar Shemtov, Bo-Juen Chen, Robin Strudel, David Reitter, Aurko Roy, Andrey Vlasov, Changwan Ryu, Chas Leichner, Haichuan Yang, Zelda Mariet, Denis Vnukov, Tim Sohn, Amy Stuart, Wei Liang, Minmin Chen, Praynaa Rawlani, Christy Koh, JD Co-Reyes, Guangda Lai, Praseem Banzal, Dimitrios Vytiniotis, Jieru Mei, Mu Cai, Mohammed Badawi, Corey Fry, Ale Hartman, Daniel Zheng, Eric Jia, James Keeling, Annie Louis, Ying Chen, Efren Robles, Wei-Chih Hung, Howard Zhou, Nikita Saxena, Sonam Goenka, Olivia Ma, Zach Fisher, Mor Hazan Taege, Emily Graves, David Steiner, Yujia Li, Sarah Nguyen, Rahul Sukthankar, Joe Stanton, Ali Eslami, Gloria Shen, Berkin Akin, Alexey Guseynov, Yiqian Zhou, Jean-Baptiste Alayrac, Armand Joulin, Efrat Farkash, Ashish Thapliyal, Stephen Roller, Noam Shazeer, Todor Davchev, Terry Koo, Hannah Forbes-Pollard, Kartik Audhkhasi, Greg Farquhar, Adi Mayrav Gilady, Maggie Song, John Aslanides, Piermaria Mendolicchio, Alicia Parrish, John Blitzer, Pramod Gupta, Xiaoen Ju, Xiaochen Yang, Puranjay Datta, Andrea Tacchetti, Sanket Vaibhav Mehta, Gregory Dibb, Shubham Gupta, Federico Piccinini, Raia Hadsell, Sujee Rajayogam, Jiepu Jiang, Patrick Griffin, Patrik Sundberg, Jamie Hayes, Alexey Frolov, Tian Xie, Adam Zhang, Kingshuk Dasgupta, Uday Kalra, Lior Shani, Klaus Macherey, Tzu-Kuo Huang, Liam MacDermed, Karthik Duddu, Paulo Zacchello, Zi Yang, Jessica Lo, Kai Hui, Matej Kastelic, Derek Gasaway, Qijun Tan, Summer Yue, Pablo Barrio, John Wieting, Weel Yang, Andrew Nystrom, Solomon Demmessie, Anselm Levskaya, Fabio Viola, Chetan Tekur, Greg Billock, George Necula, Mandar Joshi, Rylan Schaeffer, Swachhand Lokhande, Christina Sorokin, Pradeep Shenoy, Mia Chen, Mark Collier, Hongji Li, Taylor Bos, Nevan Wichers, Sun Jae Lee, Angéline Pouget, Santhosh Thangaraj, Kyriakos Axiotis, Phil Crone, Rachel Sterneck, Nikolai Chinaev, Victoria Krakovna, Oleksandr Ferludin, Ian Gemp, Stephanie Winkler, Dan Goldberg, Ivan Korotkov, Kefan Xiao, Malika Mehrotra, Sandeep Mariserla, Vihari Piratla, Terry Thurk, Khiem Pham, Hongxu Ma, Alexandre Senges, Ravi Kumar, Clemens Meyer, Ellie Talius, Nuo Wang Pierse, Ballie Sandhu, Horia Toma, Kuo Lin, Swaroop Nath, Tom Stone, Dorsa Sadigh, Nikita Gupta, Arthur Guez, Avi Singh, Matt Thomas, Tom Duerig, Yuan Gong, Richard Tanburn, Lydia Lihui Zhang, Phuong Dao, Mohamed Hammad, Sirui Xie, Shruti Rijhwani, Ben Murdoch, Duhyeon Kim, Will Thompson, Heng-Tze Cheng, Daniel Sohn, Pablo Sprechmann, Qiantong Xu, Srinivas Tadepalli, Peter Young, Ye Zhang, Hansa Srinivasan, Miranda Aperghis, Aditya Ayyar, Hen Fitoussi, Ryan Burnell, David Madras, Mike Dusenberry, Xi Xiong, Tayo Oguntebi, Ben Albrecht, Jörg Bornschein, Jovana Mitrović, Mason Dimarco, Bhargav Kanagal Shamanna, Premal Shah, Eren Sezener, Shyam Upadhyay, Dave Lacey, Craig Schiff, Sebastien Baur, Sanjay Ganapathy, Eva Schnider, Mateo Wirth, Connor Schenck, Andrey Simanovsky, Yi-Xuan Tan, Philipp Fränken, Dennis Duan, Bharath Mankalale, Nikhil Dhawan, Kevin Sequeira, Zichuan Wei, Shivanker Goel, Caglar Unlu, Yukun Zhu, Haitian Sun, Ananth Balashankar, Kurt Shuster, Megh Umekar, Mahmoud Alnahlawi, Aäron van den Oord, Kelly Chen, Yuexiang Zhai, Zihang Dai, Kuang-Huei Lee, Eric Doi, Lukas Zilka, Rohith Vallu, Disha Shrivastava, Jason Lee, Hisham Husain, Honglei Zhuang, Vincent Cohen-Addad, Jarred Barber, James Atwood, Adam Sadovsky, Quentin Wellens, Steven Hand, Arunkumar Rajendran, Aybuke Turker, CJ Carey, Yuanzhong Xu, Hagen Soltau, Zefei Li, Xinying Song, Conglong Li, Iurii Kemaev, Sasha Brown, Andrea Burns, Viorica Patraucean, Piotr Stanczyk, Renga Aravamudhan, Mathieu Blondel, Hila Noga, Lorenzo Blanco, Will Song, Michael Isard, Mandar Sharma, Reid Hayes, Dalia El Badawy, Avery Lamp, Itay Laish, Olga Kozlova, Kelvin Chan, Sahil Singla, Srinivas Sunkara, Mayank Upadhyay, Chang Liu, Aijun Bai, Jarek Wilkiewicz, Martin Zlocha, Jeremiah Liu, Zhuowan Li, Haiguang Li, Omer Barak, Ganna Raboshchuk, Jiho Choi, Fangyu Liu, Erik Jue, Mohit Sharma, Andreea Marzoca, Robert Busa-Fekete, Anna Korsun, Andre Elisseeff, Zhe Shen, Sara Mc Carthy, Kay Lamerigts, Anahita Hosseini, Hanzhao Lin, Charlie Chen, Fan Yang, Kushal Chauhan, Mark Omernick, Dawei Jia, Karina Zainullina, Demis Hassabis, Danny Vainstein, Ehsan Amid, Xiang Zhou, Ronny Votel, Eszter Vértes, Xinjian Li, Zongwei Zhou, Angeliki Lazaridou, Brendan McMahan, Arjun Narayanan, Hubert Soyer, Sujoy Basu, Kayi Lee, Bryan Perozzi, Qin Cao, Leonard Berrada, Rahul Arya, Ke Chen, Katrina, Xu, Matthias Lochbrunner, Alex Hofer, Sahand Sharifzadeh, Renjie Wu, Sally Goldman, Pranjal Awasthi, Xuezhi Wang, Yan Wu, Claire Sha, Biao Zhang, Maciej Mikuła, Filippo Graziano, Siobhan Mcloughlin, Irene Giannoumis, Youhei Namiki, Chase Malik, Carey Radebaugh, Jamie Hall, Ramiro Leal-Cavazos, Jianmin Chen, Vikas Sindhwani, David Kao, David Greene, Jordan Griffith, Chris Welty, Ceslee Montgomery, Toshihiro Yoshino, Liangzhe Yuan, Noah Goodman, Assaf Hurwitz Michaely, Kevin Lee, KP Sawhney, Wei Chen, Zheng Zheng, Megan Shum, Nikolay Savinov, Etienne Pot, Alex Pak, Morteza Zadimoghaddam, Sijal Bhatnagar, Yoad Lewenberg, Blair Kutzman, Ji Liu, Lesley Katzen, Jeremy Selier, Josip Djolonga, Dmitry Lepikhin, Kelvin Xu, Jacky Liang, Jiewen Tan, Benoit Schillings, Muge Ersoy, Pete Blois, Bernd Bandemer, Abhimanyu Singh, Sergei Lebedev, Pankaj Joshi, Adam R. Brown, Evan Palmer, Shreya Pathak, Komal Jalan, Fedir Zubach, Shuba Lall, Randall Parker, Alok Gunjan, Sergey Rogulenko, Sumit Sanghai, Zhaoqi Leng, Zoltan Egyed, Shixin Li, Maria Ivanova, Kostas Andriopoulos, Jin Xie, Elan Rosenfeld, Auriel Wright, Ankur Sharma, Xinyang Geng, Yicheng Wang, Sam Kwei, Renke Pan, Yujing Zhang, Gabby Wang, Xi Liu, Chak Yeung, Elizabeth Cole, Aviv Rosenberg, Zhen Yang, Phil Chen, George Polovets, Pranav Nair, Rohun Saxena, Josh Smith, Shuo-yiin Chang, Aroma Mahendru, Svetlana Grant, Anand Iyer, Irene Cai, Jed McGiffin, Jiaming Shen, Alanna Walton, Antonious Girgis, Oliver Woodman, Rosemary Ke, Mike Kwong, Louis Rouillard, Jinmeng Rao, Zhihao Li, Yuntao Xu, Flavien Prost, Chi Zou, Ziwei Ji, Alberto Magni, Tyler Liechty, Dan A. Calian, Deepak Ramachandran, Igor Krivokon, Hui Huang, Terry Chen, Anja Hauth, Anastasija Ilić, Weijuan Xi, Hyeontaek Lim, Vlad-Doru Ion, Pooya Moradi, Metin Toksoz-Exley, Kalesha Bullard, Miltos Allamanis, Xiaomeng Yang, Sophie Wang, Zhi Hong, Anita Gergely, Cheng Li, Bhavishya Mittal, Vitaly Kovalev, Victor Ungureanu, Jane Labanowski, Jan Wassenberg, Nicolas Lacasse, Geoffrey Cideron, Petar Dević, Annie Marsden, Lynn Nguyen, Michael Fink, Yin Zhong, Tatsuya Kiyono, Desi Ivanov, Sally Ma, Max Bain, Kiran Yalasangi, Jennifer She, Anastasia Petrushkina, Mayank Lunayach, Carla Bromberg, Sarah Hodkinson, Vilobh Meshram, Daniel Vlasic, Austin Kyker, Steve Xu, Jeff Stanway, Zuguang Yang, Kai Zhao, Matthew Tung, Seth Odoom, Yasuhisa Fujii, Justin Gilmer, Eunyoung Kim, Felix Halim, Quoc Le, Bernd Bohnet, Seliem El-Sayed, Behnam Neyshabur, Malcolm Reynolds, Dean Reich, Yang Xu, Erica Moreira, Anuj Sharma, Zeyu Liu, Mohammad Javad Hosseini, Naina Raisinghani, Yi Su, Ni Lao, Daniel Formoso, Marco Gelmi, Almog Gueta, Tapomay Dey, Elena Gribovskaya, Domagoj Ćevid, Sidharth Mudgal, Garrett Bingham, Jianling Wang, Anurag Kumar, Alex Cullum, Feng Han, Konstantinos Bousmalis, Diego Cedillo, Grace Chu, Vladimir Magay, Paul Michel, Ester Hlavnova, Daniele Calandriello, Setareh Ariafar, Kaisheng Yao, Vikash Sehwag, Arpi Vezer, Agustin Dal Lago, Zhenkai Zhu, Paul Kishan Rubenstein, Allen Porter, Anirudh Baddepudi, Oriana Riva, Mihai Dorin Istin, Chih-Kuan Yeh, Zhi Li, Andrew Howard, Nilpa Jha, Jeremy Chen, Raoul de Liedekerke, Zafarali Ahmed, Mikel Rodriguez, Tanuj Bhatia, Bangju Wang, Ali Elqursh, David Klinghoffer, Peter Chen, Pushmeet Kohli, Te I, Weiyang Zhang, Zack Nado, Jilin Chen, Maxwell Chen, George Zhang, Aayush Singh, Adam Hillier, Federico Lebron, Yiqing Tao, Ting Liu, Gabriel Dulac-Arnold, Jingwei Zhang, Shashi Narayan, Buhuang Liu, Orhan Firat, Abhishek Bhowmick, Bingyuan Liu, Hao Zhang, Zizhao Zhang, Georges Rotival, Nathan Howard, Anu Sinha, Alexander Grushetsky, Benjamin Beyret, Keerthana Gopalakrishnan, James Zhao, Kyle He, Szabolcs Payrits, Zaid Nabulsi, Zhaoyi Zhang, Weijie Chen, Edward Lee, Nova Fallen, Sreenivas Gollapudi, Aurick Zhou, Filip Pavetić, Thomas Köppe, Shiyu Huang, Rama Pasumarthi, Nick Fernando, Felix Fischer, Daria Ćurko, Yang Gao, James Svensson, Austin Stone, Haroon Qureshi, Abhishek Sinha, Apoorv Kulshreshtha, Martin Matysiak, Jieming Mao, Carl Saroufim, Aleksandra Faust, Qingnan Duan, Gil Fidel, Kaan Katircioglu, Raphaël Lopez Kaufman, Dhruv Shah, Weize Kong, Abhishek Bapna, Gellért Weisz, Emma Dunleavy, Praneet Dutta, Tianqi Liu, Rahma Chaabouni, Carolina Parada, Marcus Wu, Alexandra Belias, Alessandro Bissacco, Stanislav Fort, Li Xiao, Fantine Huot, Chris Knutsen, Yochai Blau, Gang Li, Jennifer Prendki, Juliette Love, Yinlam Chow, Pichi Charoenpanit, Hidetoshi Shimokawa, Vincent Coriou, Karol Gregor, Tomas Izo, Arjun Akula, Mario Pinto, Chris Hahn, Dominik Paulus, Jiaxian Guo, Neha Sharma, Cho-Jui Hsieh, Adaeze Chukwuka, Kazuma Hashimoto, Nathalie Rauschmayr, Ling Wu, Christof Angermueller, Yulong Wang, Sebastian Gerlach, Michael Pliskin, Daniil Mirylenka, Min Ma, Lexi Baugher, Bryan Gale, Shaan Bijwadia, Nemanja Rakićević, David Wood, Jane Park, Chung-Ching Chang, Babi Seal, Chris Tar, Kacper Krasowiak, Yiwen Song, Georgi Stephanov, Gary Wang, Marcello Maggioni, Stein Xudong Lin, Felix Wu, Shachi Paul, Zixuan Jiang, Shubham Agrawal, Bilal Piot, Alex Feng, Cheolmin Kim, Tulsee Doshi, Jonathan Lai, Chuqiao, Xu, Sharad Vikram, Ciprian Chelba, Sebastian Krause, Vincent Zhuang, Jack Rae, Timo Denk, Adrian Collister, Lotte Weerts, Xianghong Luo, Yifeng Lu, Håvard Garnes, Nitish Gupta, Terry Spitz, Avinatan Hassidim, Lihao Liang, Izhak Shafran, Peter Humphreys, Kenny Vassigh, Phil Wallis, Virat Shejwalkar, Nicolas Perez-Nieves, Rachel Hornung, Melissa Tan, Beka Westberg, Andy Ly, Richard Zhang, Brian Farris, Jongbin Park, Alec Kosik, Zeynep Cankara, Andrii Maksai, Yunhan Xu, Albin Cassirer, Sergi Caelles, Abbas Abdolmaleki, Mencher Chiang, Alex Fabrikant, Shravya Shetty, Luheng He, Mai Giménez, Hadi Hashemi, Sheena Panthaplackel, Yana Kulizhskaya, Salil Deshmukh, Daniele Pighin, Robin Alazard, Disha Jindal, Seb Noury, Pradeep Kumar S, Siyang Qin, Xerxes Dotiwalla, Stephen Spencer, Mohammad Babaeizadeh, Blake JianHang Chen, Vaibhav Mehta, Jennie Lees, Andrew Leach, Penporn Koanantakool, Ilia Akolzin, Ramona Comanescu, Junwhan Ahn, Alexey Svyatkovskiy, Basil Mustafa, David D'Ambrosio, Shiva Mohan Reddy Garlapati, Pascal Lamblin, Alekh Agarwal, Shuang Song, Pier Giuseppe Sessa, Pauline Coquinot, John Maggs, Hussain Masoom, Divya Pitta, Yaqing Wang, Patrick Morris-Suzuki, Billy Porter, Johnson Jia, Jeffrey Dudek, Raghavender R, Cosmin Paduraru, Alan Ansell, Tolga Bolukbasi, Tony Lu, Ramya Ganeshan, Zi Wang, Henry Griffiths, Rodrigo Benenson, Yifan He, James Swirhun, George Papamakarios, Aditya Chawla, Kuntal Sengupta, Yan Wang, Vedrana Milutinovic, Igor Mordatch, Zhipeng Jia, Jamie Smith, Will Ng, Shitij Nigam, Matt Young, Eugen Vušak, Blake Hechtman, Sheela Goenka, Avital Zipori, Kareem Ayoub, Ashok Popat, Trilok Acharya, Luo Yu, Dawn Bloxwich, Hugo Song, Paul Roit, Haiqiong Li, Aviel Boag, Nigamaa Nayakanti, Bilva Chandra, Tianli Ding, Aahil Mehta, Cath Hope, Jiageng Zhang, Idan Heimlich Shtacher, Kartikeya Badola, Ryo Nakashima, Andrei Sozanschi, Iulia Comşa, Ante Žužul, Emily Caveness, Julian Odell, Matthew Watson, Dario de Cesare, Phillip Lippe, Derek Lockhart, Siddharth Verma, Huizhong Chen, Sean Sun, Lin Zhuo, Aditya Shah, Prakhar Gupta, Alex Muzio, Ning Niu, Amir Zait, Abhinav Singh, Meenu Gaba, Fan Ye, Prajit Ramachandran, Mohammad Saleh, Raluca Ada Popa, Ayush Dubey, Frederick Liu, Sara Javanmardi, Mark Epstein, Ross Hemsley, Richard Green, Nishant Ranka, Eden Cohen, Chuyuan Kelly Fu, Sanjay Ghemawat, Jed Borovik, James Martens, Anthony Chen, Pranav Shyam, André Susano Pinto, Ming-Hsuan Yang, Alexandru Ţifrea, David Du, Boqing Gong, Ayushi Agarwal, Seungyeon Kim, Christian Frank, Saloni Shah, Xiaodan Song, Zhiwei Deng, Ales Mikhalap, Kleopatra Chatziprimou, Timothy Chung, Toni Creswell, Susan Zhang, Yennie Jun, Carl Lebsack, Will Truong, Slavica Andačić, Itay Yona, Marco Fornoni, Rong Rong, Serge Toropov, Afzal Shama Soudagar, Andrew Audibert, Salah Zaiem, Zaheer Abbas, Andrei Rusu, Sahitya Potluri, Shitao Weng, Anastasios Kementsietsidis, Anton Tsitsulin, Daiyi Peng, Natalie Ha, Sanil Jain, Tejasi Latkar, Simeon Ivanov, Cory McLean, Anirudh GP, Rajesh Venkataraman, Canoee Liu, Dilip Krishnan, Joel D'sa, Roey Yogev, Paul Collins, Benjamin Lee, Lewis Ho, Carl Doersch, Gal Yona, Shawn Gao, Felipe Tiengo Ferreira, Adnan Ozturel, Hannah Muckenhirn, Ce Zheng, Gargi Balasubramaniam, Mudit Bansal, George van den Driessche, Sivan Eiger, Salem Haykal, Vedant Misra, Abhimanyu Goyal, Danilo Martins, Gary Leung, Jonas Valfridsson, Four Flynn, Will Bishop, Chenxi Pang, Yoni Halpern, Honglin Yu, Lawrence Moore, Yuvein, Zhu, Sridhar Thiagarajan, Yoel Drori, Zhisheng Xiao, Lucio Dery, Rolf Jagerman, Jing Lu, Eric Ge, Vaibhav Aggarwal, Arjun Khare, Vinh Tran, Oded Elyada, Ferran Alet, James Rubin, Ian Chou, David Tian, Libin Bai, Lawrence Chan, Lukasz Lew, Karolis Misiunas, Taylan Bilal, Aniket Ray, Sindhu Raghuram, Alex Castro-Ros, Viral Carpenter, CJ Zheng, Michael Kilgore, Josef Broder, Emily Xue, Praveen Kallakuri, Dheeru Dua, Nancy Yuen, Steve Chien, John Schultz, Saurabh Agrawal, Reut Tsarfaty, Jingcao Hu, Ajay Kannan, Dror Marcus, Nisarg Kothari, Baochen Sun, Ben Horn, Matko Bošnjak, Ferjad Naeem, Dean Hirsch, Lewis Chiang, Boya Fang, Jie Han, Qifei Wang, Ben Hora, Antoine He, Mario Lučić, Beer Changpinyo, Anshuman Tripathi, John Youssef, Chester Kwak, Philippe Schlattner, Cat Graves, Rémi Leblond, Wenjun Zeng, Anders Andreassen, Gabriel Rasskin, Yue Song, Eddie Cao, Junhyuk Oh, Matt Hoffman, Wojtek Skut, Yichi Zhang, Jon Stritar, Xingyu Cai, Saarthak Khanna, Kathie Wang, Shriya Sharma, Christian Reisswig, Younghoon Jun, Aman Prasad, Tatiana Sholokhova, Preeti Singh, Adi Gerzi Rosenthal, Anian Ruoss, Françoise Beaufays, Sean Kirmani, Dongkai Chen, Johan Schalkwyk, Jonathan Herzig, Been Kim, Josh Jacob, Damien Vincent, Adrian N Reyes, Ivana Balazevic, Léonard Hussenot, Jon Schneider, Parker Barnes, Luis Castro, Spandana Raj Babbula, Simon Green, Serkan Cabi, Nico Duduta, Danny Driess, Rich Galt, Noam Velan, Junjie Wang, Hongyang Jiao, Matthew Mauger, Du Phan, Miteyan Patel, Vlado Galić, Jerry Chang, Eyal Marcus, Matt Harvey, Julian Salazar, Elahe Dabir, Suraj Satishkumar Sheth, Amol Mandhane, Hanie Sedghi, Jeremiah Willcock, Amir Zandieh, Shruthi Prabhakara, Aida Amini, Antoine Miech, Victor Stone, Massimo Nicosia, Paul Niemczyk, Ying Xiao, Lucy Kim, Sławek Kwasiborski, Vikas Verma, Ada Maksutaj Oflazer, Christoph Hirnschall, Peter Sung, Lu Liu, Richard Everett, Michiel Bakker, Ágoston Weisz, Yufei Wang, Vivek Sampathkumar, Uri Shaham, Bibo Xu, Yasemin Altun, Mingqiu Wang, Takaaki Saeki, Guanjie Chen, Emanuel Taropa, Shanthal Vasanth, Sophia Austin, Lu Huang, Goran Petrovic, Qingyun Dou, Daniel Golovin, Grigory Rozhdestvenskiy, Allie Culp, Will Wu, Motoki Sano, Divya Jain, Julia Proskurnia, Sébastien Cevey, Alejandro Cruzado Ruiz, Piyush Patil, Mahdi Mirzazadeh, Eric Ni, Javier Snaider, Lijie Fan, Alexandre Fréchette, AJ Pierigiovanni, Shariq Iqbal, Kenton Lee, Claudio Fantacci, Jinwei Xing, Lisa Wang, Alex Irpan, David Raposo, Yi Luan, Zhuoyuan Chen, Harish Ganapathy, Kevin Hui, Jiazhong Nie, Isabelle Guyon, Heming Ge, Roopali Vij, Hui Zheng, Dayeong Lee, Alfonso Castaño, Khuslen Baatarsukh, Gabriel Ibagon, Alexandra Chronopoulou, Nicholas FitzGerald, Shashank Viswanadha, Safeen Huda, Rivka Moroshko, Georgi Stoyanov, Prateek Kolhar, Alain Vaucher, Ishaan Watts, Adhi Kuncoro, Henryk Michalewski, Satish Kambala, Bat-Orgil Batsaikhan, Alek Andreev, Irina Jurenka, Maigo Le, Qihang Chen, Wael Al Jishi, Sarah Chakera, Zhe Chen, Aditya Kini, Vikas Yadav, Aditya Siddhant, Ilia Labzovsky, Balaji Lakshminarayanan, Carrie Grimes Bostock, Pankil Botadra, Ankesh Anand, Colton Bishop, Sam Conway-Rahman, Mohit Agarwal, Yani Donchev, Achintya Singhal, Félix de Chaumont Quitry, Natalia Ponomareva, Nishant Agrawal, Bin Ni, Kalpesh Krishna, Masha Samsikova, John Karro, Yilun Du, Tamara von Glehn, Caden Lu, Christopher A. Choquette-Choo, Zhen Qin, Tingnan Zhang, Sicheng Li, Divya Tyam, Swaroop Mishra, Wing Lowe, Colin Ji, Weiyi Wang, Manaal Faruqui, Ambrose Slone, Valentin Dalibard, Arunachalam Narayanaswamy, John Lambert, Pierre-Antoine Manzagol, Dan Karliner, Andrew Bolt, Ivan Lobov, Aditya Kusupati, Chang Ye, Xuan Yang, Heiga Zen, Nelson George, Mukul Bhutani, Olivier Lacombe, Robert Riachi, Gagan Bansal, Rachel Soh, Yue Gao, Yang Yu, Adams Yu, Emily Nottage, Tania Rojas-Esponda, James Noraky, Manish Gupta, Ragha Kotikalapudi, Jichuan Chang, Sanja Deur, Dan Graur, Alex Mossin, Erin Farnese, Ricardo Figueira, Alexandre Moufarek, Austin Huang, Patrik Zochbauer, Ben Ingram, Tongzhou Chen, Zelin Wu, Adrià Puigdomènech, Leland Rechis, Da Yu, Sri Gayatri Sundara Padmanabhan, Rui Zhu, Chu-ling Ko, Andrea Banino, Samira Daruki, Aarush Selvan, Dhruva Bhaswar, Daniel Hernandez Diaz, Chen Su, Salvatore Scellato, Jennifer Brennan, Woohyun Han, Grace Chung, Priyanka Agrawal, Urvashi Khandelwal, Khe Chai Sim, Morgane Lustman, Sam Ritter, Kelvin Guu, Jiawei Xia, Prateek Jain, Emma Wang, Tyrone Hill, Mirko Rossini, Marija Kostelac, Tautvydas Misiunas, Amit Sabne, Kyuyeun Kim, Ahmet Iscen, Congchao Wang, José Leal, Ashwin Sreevatsa, Utku Evci, Manfred Warmuth, Saket Joshi, Daniel Suo, James Lottes, Garrett Honke, Brendan Jou, Stefani Karp, Jieru Hu, Himanshu Sahni, Adrien Ali Taïga, William Kong, Samrat Ghosh, Renshen Wang, Jay Pavagadhi, Natalie Axelsson, Nikolai Grigorev, Patrick Siegler, Rebecca Lin, Guohui Wang, Emilio Parisotto, Sharath Maddineni, Krishan Subudhi, Eyal Ben-David, Elena Pochernina, Orgad Keller, Thi Avrahami, Zhe Yuan, Pulkit Mehta, Jialu Liu, Sherry Yang, Wendy Kan, Katherine Lee, Tom Funkhouser, Derek Cheng, Hongzhi Shi, Archit Sharma, Joe Kelley, Matan Eyal, Yury Malkov, Corentin Tallec, Yuval Bahat, Shen Yan, Xintian, Wu, David Lindner, Chengda Wu, Avi Caciularu, Xiyang Luo, Rodolphe Jenatton, Tim Zaman, Yingying Bi, Ilya Kornakov, Ganesh Mallya, Daisuke Ikeda, Itay Karo, Anima Singh, Colin Evans, Praneeth Netrapalli, Vincent Nallatamby, Isaac Tian, Yannis Assael, Vikas Raunak, Victor Carbune, Ioana Bica, Lior Madmoni, Dee Cattle, Snchit Grover, Krishna Somandepalli, Sid Lall, Amelio Vázquez-Reina, Riccardo Patana, Jiaqi Mu, Pranav Talluri, Maggie Tran, Rajeev Aggarwal, RJ Skerry-Ryan, Jun Xu, Mike Burrows, Xiaoyue Pan, Edouard Yvinec, Di Lu, Zhiying Zhang, Duc Dung Nguyen, Hairong Mu, Gabriel Barcik, Helen Ran, Lauren Beltrone, Krzysztof Choromanski, Dia Kharrat, Samuel Albanie, Sean Purser-haskell, David Bieber, Carrie Zhang, Jing Wang, Tom Hudson, Zhiyuan Zhang, Han Fu, Johannes Mauerer, Mohammad Hossein Bateni, AJ Maschinot, Bing Wang, Muye Zhu, Arjun Pillai, Tobias Weyand, Shuang Liu, Oscar Akerlund, Fred Bertsch, Vittal Premachandran, Alicia Jin, Vincent Roulet, Peter de Boursac, Shubham Mittal, Ndaba Ndebele, Georgi Karadzhov, Sahra Ghalebikesabi, Ricky Liang, Allen Wu, Yale Cong, Nimesh Ghelani, Sumeet Singh, Bahar Fatemi, Warren, Chen, Charles Kwong, Alexey Kolganov, Steve Li, Richard Song, Chenkai Kuang, Sobhan Miryoosefi, Dale Webster, James Wendt, Arkadiusz Socala, Guolong Su, Artur Mendonça, Abhinav Gupta, Xiaowei Li, Tomy Tsai, Qiong, Hu, Kai Kang, Angie Chen, Sertan Girgin, Yongqin Xian, Andrew Lee, Nolan Ramsden, Leslie Baker, Madeleine Clare Elish, Varvara Krayvanova, Rishabh Joshi, Jiri Simsa, Yao-Yuan Yang, Piotr Ambroszczyk, Dipankar Ghosh, Arjun Kar, Yuan Shangguan, Yumeya Yamamori, Yaroslav Akulov, Andy Brock, Haotian Tang, Siddharth Vashishtha, Rich Munoz, Andreas Steiner, Kalyan Andra, Daniel Eppens, Qixuan Feng, Hayato Kobayashi, Sasha Goldshtein, Mona El Mahdy, Xin Wang, Jilei, Wang, Richard Killam, Tom Kwiatkowski, Kavya Kopparapu, Serena Zhan, Chao Jia, Alexei Bendebury, Sheryl Luo, Adrià Recasens, Timothy Knight, Jing Chen, Mohak Patel, YaGuang Li, Ben Withbroe, Dean Weesner, Kush Bhatia, Jie Ren, Danielle Eisenbud, Ebrahim Songhori, Yanhua Sun, Travis Choma, Tasos Kementsietsidis, Lucas Manning, Brian Roark, Wael Farhan, Jie Feng, Susheel Tatineni, James Cobon-Kerr, Yunjie Li, Lisa Anne Hendricks, Isaac Noble, Chris Breaux, Nate Kushman, Liqian Peng, Fuzhao Xue, Taylor Tobin, Jamie Rogers, Josh Lipschultz, Chris Alberti, Alexey Vlaskin, Mostafa Dehghani, Roshan Sharma, Tris Warkentin, Chen-Yu Lee, Benigno Uria, Da-Cheng Juan, Angad Chandorkar, Hila Sheftel, Ruibo Liu, Elnaz Davoodi, Borja De Balle Pigem, Kedar Dhamdhere, David Ross, Jonathan Hoech, Mahdis Mahdieh, Li Liu, Qiujia Li, Liam McCafferty, Chenxi Liu, Markus Mircea, Yunting Song, Omkar Savant, Alaa Saade, Colin Cherry, Vincent Hellendoorn, Siddharth Goyal, Paul Pucciarelli, David Vilar Torres, Zohar Yahav, Hyo Lee, Lars Lowe Sjoesund, Christo Kirov, Bo Chang, Deepanway Ghoshal, Lu Li, Gilles Baechler, Sébastien Pereira, Tara Sainath, Anudhyan Boral, Dominik Grewe, Afief Halumi, Nguyet Minh Phu, Tianxiao Shen, Marco Tulio Ribeiro, Dhriti Varma, Alex Kaskasoli, Vlad Feinberg, Navneet Potti, Jarrod Kahn, Matheus Wisniewski, Shakir Mohamed, Arnar Mar Hrafnkelsson, Bobak Shahriari, Jean-Baptiste Lespiau, Lisa Patel, Legg Yeung, Tom Paine, Lantao Mei, Alex Ramirez, Rakesh Shivanna, Li Zhong, Josh Woodward, Guilherme Tubone, Samira Khan, Heng Chen, Elizabeth Nielsen, Catalin Ionescu, Utsav Prabhu, Mingcen Gao, Qingze Wang, Sean Augenstein, Neesha Subramaniam, Jason Chang, Fotis Iliopoulos, Jiaming Luo, Myriam Khan, Weicheng Kuo, Denis Teplyashin, Florence Perot, Logan Kilpatrick, Amir Globerson, Hongkun Yu, Anfal Siddiqui, Nick Sukhanov, Arun Kandoor, Umang Gupta, Marco Andreetto, Moran Ambar, Donnie Kim, Paweł Wesołowski, Sarah Perrin, Ben Limonchik, Wei Fan, Jim Stephan, Ian Stewart-Binks, Ryan Kappedal, Tong He, Sarah Cogan, Romina Datta, Tong Zhou, Jiayu Ye, Leandro Kieliger, Ana Ramalho, Kyle Kastner, Fabian Mentzer, Wei-Jen Ko, Arun Suggala, Tianhao Zhou, Shiraz Butt, Hana Strejček, Lior Belenki, Subhashini Venugopalan, Mingyang Ling, Evgenii Eltyshev, Yunxiao Deng, Geza Kovacs, Mukund Raghavachari, Hanjun Dai, Tal Schuster, Steven Schwarcz, Richard Nguyen, Arthur Nguyen, Gavin Buttimore, Shrestha Basu Mallick, Sudeep Gandhe, Seth Benjamin, Michal Jastrzebski, Le Yan, Sugato Basu, Chris Apps, Isabel Edkins, James Allingham, Immanuel Odisho, Tomas Kocisky, Jewel Zhao, Linting Xue, Apoorv Reddy, Chrysovalantis Anastasiou, Aviel Atias, Sam Redmond, Kieran Milan, Nicolas Heess, Herman Schmit, Allan Dafoe, Daniel Andor, Tynan Gangwani, Anca Dragan, Sheng Zhang, Ashyana Kachra, Gang Wu, Siyang Xue, Kevin Aydin, Siqi Liu, Yuxiang Zhou, Mahan Malihi, Austin Wu, Siddharth Gopal, Candice Schumann, Peter Stys, Alek Wang, Mirek Olšák, Dangyi Liu, Christian Schallhart, Yiran Mao, Demetra Brady, Hao Xu, Tomas Mery, Chawin Sitawarin, Siva Velusamy, Tom Cobley, Alex Zhai, Christian Walder, Nitzan Katz, Ganesh Jawahar, Chinmay Kulkarni, Antoine Yang, Adam Paszke, Yinan Wang, Bogdan Damoc, Zalán Borsos, Ray Smith, Jinning Li, Mansi Gupta, Andrei Kapishnikov, Sushant Prakash, Florian Luisier, Rishabh Agarwal, Will Grathwohl, Kuangyuan Chen, Kehang Han, Nikhil Mehta, Andrew Over, Shekoofeh Azizi, Lei Meng, Niccolò Dal Santo, Kelvin Zheng, Jane Shapiro, Igor Petrovski, Jeffrey Hui, Amin Ghafouri, Jasper Snoek, James Qin, Mandy Jordan, Caitlin Sikora, Jonathan Malmaud, Yuheng Kuang, Aga Świetlik, Ruoxin Sang, Chongyang Shi, Leon Li, Andrew Rosenberg, Shubin Zhao, Andy Crawford, Jan-Thorsten Peter, Yun Lei, Xavier Garcia, Long Le, Todd Wang, Julien Amelot, Dave Orr, Praneeth Kacham, Dana Alon, Gladys Tyen, Abhinav Arora, James Lyon, Alex Kurakin, Mimi Ly, Theo Guidroz, Zhipeng Yan, Rina Panigrahy, Pingmei Xu, Thais Kagohara, Yong Cheng, Eric Noland, Jinhyuk Lee, Jonathan Lee, Cathy Yip, Maria Wang, Efrat Nehoran, Alexander Bykovsky, Zhihao Shan, Ankit Bhagatwala, Chaochao Yan, Jie Tan, Guillermo Garrido, Dan Ethier, Nate Hurley, Grace Vesom, Xu Chen, Siyuan Qiao, Abhishek Nayyar, Julian Walker, Paramjit Sandhu, Mihaela Rosca, Danny Swisher, Mikhail Dektiarev, Josh Dillon, George-Cristian Muraru, Manuel Tragut, Artiom Myaskovsky, David Reid, Marko Velic, Owen Xiao, Jasmine George, Mark Brand, Jing Li, Wenhao Yu, Shane Gu, Xiang Deng, François-Xavier Aubet, Soheil Hassas Yeganeh, Fred Alcober, Celine Smith, Trevor Cohn, Kay McKinney, Michael Tschannen, Ramesh Sampath, Gowoon Cheon, Liangchen Luo, Luyang Liu, Jordi Orbay, Hui Peng, Gabriela Botea, Xiaofan Zhang, Charles Yoon, Cesar Magalhaes, Paweł Stradomski, Ian Mackinnon, Steven Hemingray, Kumaran Venkatesan, Rhys May, Jaeyoun Kim, Alex Druinsky, Jingchen Ye, Zheng Xu, Terry Huang, Jad Al Abdallah, Adil Dostmohamed, Rachana Fellinger, Tsendsuren Munkhdalai, Akanksha Maurya, Peter Garst, Yin Zhang, Maxim Krikun, Simon Bucher, Aditya Srikanth Veerubhotla, Yaxin Liu, Sheng Li, Nishesh Gupta, Jakub Adamek, Hanwen Chen, Bernett Orlando, Aleksandr Zaks, Joost van Amersfoort, Josh Camp, Hui Wan, HyunJeong Choe, Zhichun Wu, Kate Olszewska, Weiren Yu, Archita Vadali, Martin Scholz, Daniel De Freitas, Jason Lin, Amy Hua, Xin Liu, Frank Ding, Yichao Zhou, Boone Severson, Katerina Tsihlas, Samuel Yang, Tammo Spalink, Varun Yerram, Helena Pankov, Rory Blevins, Ben Vargas, Sarthak Jauhari, Matt Miecnikowski, Ming Zhang, Sandeep Kumar, Clement Farabet, Charline Le Lan, Sebastian Flennerhag, Yonatan Bitton, Ada Ma, Arthur Bražinskas, Eli Collins, Niharika Ahuja, Sneha Kudugunta, Anna Bortsova, Minh Giang, Wanzheng Zhu, Ed Chi, Scott Lundberg, Alexey Stern, Subha Puttagunta, Jing Xiong, Xiao Wu, Yash Pande, Amit Jhindal, Daniel Murphy, Jon Clark, Marc Brockschmidt, Maxine Deines, Kevin R. McKee, Dan Bahir, Jiajun Shen, Minh Truong, Daniel McDuff, Andrea Gesmundo, Edouard Rosseel, Bowen Liang, Ken Caluwaerts, Jessica Hamrick, Joseph Kready, Mary Cassin, Rishikesh Ingale, Li Lao, Scott Pollom, Yifan Ding, Wei He, Lizzetth Bellot, Joana Iljazi, Ramya Sree Boppana, Shan Han, Tara Thompson, Amr Khalifa, Anna Bulanova, Blagoj Mitrevski, Bo Pang, Emma Cooney, Tian Shi, Rey Coaguila, Tamar Yakar, Marc'aurelio Ranzato, Nikola Momchev, Chris Rawles, Zachary Charles, Young Maeng, Yuan Zhang, Rishabh Bansal, Xiaokai Zhao, Brian Albert, Yuan Yuan, Sudheendra Vijayanarasimhan, Roy Hirsch, Vinay Ramasesh, Kiran Vodrahalli, Xingyu Wang, Arushi Gupta, DJ Strouse, Jianmo Ni, Roma Patel, Gabe Taubman, Zhouyuan Huo, Dero Gharibian, Marianne Monteiro, Hoi Lam, Shobha Vasudevan, Aditi Chaudhary, Isabela Albuquerque, Kilol Gupta, Sebastian Riedel, Chaitra Hegde, Avraham Ruderman, András György, Marcus Wainwright, Ashwin Chaugule, Burcu Karagol Ayan, Tomer Levinboim, Sam Shleifer, Yogesh Kalley, Vahab Mirrokni, Abhishek Rao, Prabakar Radhakrishnan, Jay Hartford, Jialin Wu, Zhenhai Zhu, Francesco Bertolini, Hao Xiong, Nicolas Serrano, Hamish Tomlinson, Myle Ott, Yifan Chang, Mark Graham, Jian Li, Marco Liang, Xiangzhu Long, Sebastian Borgeaud, Yanif Ahmad, Alex Grills, Diana Mincu, Martin Izzard, Yuan Liu, Jinyu Xie, Louis O'Bryan, Sameera Ponda, Simon Tong, Michelle Liu, Dan Malkin, Khalid Salama, Yuankai Chen, Rohan Anil, Anand Rao, Rigel Swavely, Misha Bilenko, Nina Anderson, Tat Tan, Jing Xie, Xing Wu, Lijun Yu, Oriol Vinyals, Andrey Ryabtsev, Rumen Dangovski, Kate Baumli, Daniel Keysers, Christian Wright, Zoe Ashwood, Betty Chan, Artem Shtefan, Yaohui Guo, Ankur Bapna, Radu Soricut, Steven Pecht, Sabela Ramos, Rui Wang, Jiahao Cai, Trieu Trinh, Paul Barham, Linda Friso, Eli Stickgold, Xiangzhuo Ding, Siamak Shakeri, Diego Ardila, Eleftheria Briakou, Phil Culliton, Adam Raveret, Jingyu Cui, David Saxton, Subhrajit Roy, Javad Azizi, Pengcheng Yin, Lucia Loher, Andrew Bunner, Min Choi, Faruk Ahmed, Eric Li, Yin Li, Shengyang Dai, Michael Elabd, Sriram Ganapathy, Shivani Agrawal, Yiqing Hua, Paige Kunkle, Sujeevan Rajayogam, Arun Ahuja, Arthur Conmy, Alex Vasiloff, Parker Beak, Christopher Yew, Jayaram Mudigonda, Bartek Wydrowski, Jon Blanton, Zhengdong Wang, Yann Dauphin, Zhuo Xu, Martin Polacek, Xi Chen, Hexiang Hu, Pauline Sho, Markus Kunesch, Mehdi Hafezi Manshadi, Eliza Rutherford, Bo Li, Sissie Hsiao, Iain Barr, Alex Tudor, Matija Kecman, Arsha Nagrani, Vladimir Pchelin, Martin Sundermeyer, Aishwarya P S, Abhijit Karmarkar, Yi Gao, Grishma Chole, Olivier Bachem, Isabel Gao, Arturo BC, Matt Dibb, Mauro Verzetti, Felix Hernandez-Campos, Yana Lunts, Matthew Johnson, Julia Di Trapani, Raphael Koster, Idan Brusilovsky, Binbin Xiong, Megha Mohabey, Han Ke, Joe Zou, Tea Sabolić, Víctor Campos, John Palowitch, Alex Morris, Linhai Qiu, Pranavaraj Ponnuramu, Fangtao Li, Vivek Sharma, Kiranbir Sodhia, Kaan Tekelioglu, Aleksandr Chuklin, Madhavi Yenugula, Erika Gemzer, Theofilos Strinopoulos, Sam El-Husseini, Huiyu Wang, Yan Zhong, Edouard Leurent, Paul Natsev, Weijun Wang, Dre Mahaarachchi, Tao Zhu, Songyou Peng, Sami Alabed, Cheng-Chun Lee, Anthony Brohan, Arthur Szlam, GS Oh, Anton Kovsharov, Jenny Lee, Renee Wong, Megan Barnes, Gregory Thornton, Felix Gimeno, Omer Levy, Martin Sevenich, Melvin Johnson, Jonathan Mallinson, Robert Dadashi, Ziyue Wang, Qingchun Ren, Preethi Lahoti, Arka Dhar, Josh Feldman, Dan Zheng, Thatcher Ulrich, Liviu Panait, Michiel Blokzijl, Cip Baetu, Josip Matak, Jitendra Harlalka, Maulik Shah, Tal Marian, Daniel von Dincklage, Cosmo Du, Ruy Ley-Wild, Bethanie Brownfield, Max Schumacher, Yury Stuken, Shadi Noghabi, Sonal Gupta, Xiaoqi Ren, Eric Malmi, Felix Weissenberger, Blanca Huergo, Maria Bauza, Thomas Lampe, Arthur Douillard, Mojtaba Seyedhosseini, Roy Frostig, Zoubin Ghahramani, Kelvin Nguyen, Kashyap Krishnakumar, Chengxi Ye, Rahul Gupta, Alireza Nazari, Robert Geirhos, Pete Shaw, Ahmed Eleryan, Dima Damen, Jennimaria Palomaki, Ted Xiao, Qiyin Wu, Quan Yuan, Phoenix Meadowlark, Matthew Bilotti, Raymond Lin, Mukund Sridhar, Yannick Schroecker, Da-Woon Chung, Jincheng Luo, Trevor Strohman, Tianlin Liu, Anne Zheng, Jesse Emond, Wei Wang, Andrew Lampinen, Toshiyuki Fukuzawa, Folawiyo Campbell-Ajala, Monica Roy, James Lee-Thorp, Lily Wang, Iftekhar Naim, Tony, Nguy\~ên, Guy Bensky, Aditya Gupta, Dominika Rogozińska, Justin Fu, Thanumalayan Sankaranarayana Pillai, Petar Veličković, Shahar Drath, Philipp Neubeck, Vaibhav Tulsyan, Arseniy Klimovskiy, Don Metzler, Sage Stevens, Angel Yeh, Junwei Yuan, Tianhe Yu, Kelvin Zhang, Alec Go, Vincent Tsang, Ying Xu, Andy Wan, Isaac Galatzer-Levy, Sam Sobell, Abodunrinwa Toki, Elizabeth Salesky, Wenlei Zhou, Diego Antognini, Sholto Douglas, Shimu Wu, Adam Lelkes, Frank Kim, Paul Cavallaro, Ana Salazar, Yuchi Liu, James Besley, Tiziana Refice, Yiling Jia, Zhang Li, Michal Sokolik, Arvind Kannan, Jon Simon, Jo Chick, Avia Aharon, Meet Gandhi, Mayank Daswani, Keyvan Amiri, Vighnesh Birodkar, Abe Ittycheriah, Peter Grabowski, Oscar Chang, Charles Sutton, Zhixin, Lai, Umesh Telang, Susie Sargsyan, Tao Jiang, Raphael Hoffmann, Nicole Brichtova, Matteo Hessel, Jonathan Halcrow, Sammy Jerome, Geoff Brown, Alex Tomala, Elena Buchatskaya, Dian Yu, Sachit Menon, Pol Moreno, Yuguo Liao, Vicky Zayats, Luming Tang, SQ Mah, Ashish Shenoy, Alex Siegman, Majid Hadian, Okwan Kwon, Tao Tu, Nima Khajehnouri, Ryan Foley, Parisa Haghani, Zhongru Wu, Vaishakh Keshava, Khyatti Gupta, Tony Bruguier, Rui Yao, Danny Karmon, Luisa Zintgraf, Zhicheng Wang, Enrique Piqueras, Junehyuk Jung, Jenny Brennan, Diego Machado, Marissa Giustina, MH Tessler, Kamyu Lee, Qiao Zhang, Joss Moore, Kaspar Daugaard, Alexander Frömmgen, Jennifer Beattie, Fred Zhang, Daniel Kasenberg, Ty Geri, Danfeng Qin, Gaurav Singh Tomar, Tom Ouyang, Tianli Yu, Luowei Zhou, Rajiv Mathews, Andy Davis, Yaoyiran Li, Jai Gupta, Damion Yates, Linda Deng, Elizabeth Kemp, Ga-Young Joung, Sergei Vassilvitskii, Mandy Guo, Pallavi LV, Dave Dopson, Sami Lachgar, Lara McConnaughey, Himadri Choudhury, Dragos Dena, Aaron Cohen, Joshua Ainslie, Sergey Levi, Parthasarathy Gopavarapu, Polina Zablotskaia, Hugo Vallet, Sanaz Bahargam, Xiaodan Tang, Nenad Tomasev, Ethan Dyer, Daniel Balle, Hongrae Lee, William Bono, Jorge Gonzalez Mendez, Vadim Zubov, Shentao Yang, Ivor Rendulic, Yanyan Zheng, Andrew Hogue, Golan Pundak, Ralph Leith, Avishkar Bhoopchand, Michael Han, Mislav Žanić, Tom Schaul, Manolis Delakis, Tejas Iyer, Guanyu Wang, Harman Singh, Abdelrahman Abdelhamed, Tara Thomas, Siddhartha Brahma, Hilal Dib, Naveen Kumar, Wenxuan Zhou, Liang Bai, Pushkar Mishra, Jiao Sun, Valentin Anklin, Roykrong Sukkerd, Lauren Agubuzu, Anton Briukhov, Anmol Gulati, Maximilian Sieb, Fabio Pardo, Sara Nasso, Junquan Chen, Kexin Zhu, Tiberiu Sosea, Alex Goldin, Keith Rush, Spurthi Amba Hombaiah, Andreas Noever, Allan Zhou, Sam Haves, Mary Phuong, Jake Ades, Yi-ting Chen, Lin Yang, Joseph Pagadora, Stan Bileschi, Victor Cotruta, Rachel Saputro, Arijit Pramanik, Sean Ammirati, Dan Garrette, Kevin Villela, Tim Blyth, Canfer Akbulut, Neha Jha, Alban Rrustemi, Arissa Wongpanich, Chirag Nagpal, Yonghui Wu, Morgane Rivière, Sergey Kishchenko, Pranesh Srinivasan, Alice Chen, Animesh Sinha, Trang Pham, Bill Jia, Tom Hennigan, Anton Bakalov, Nithya Attaluri, Drew Garmon, Daniel Rodriguez, Dawid Wegner, Wenhao Jia, Evan Senter, Noah Fiedel, Denis Petek, Yuchuan Liu, Cassidy Hardin, Harshal Tushar Lehri, Joao Carreira, Sara Smoot, Marcel Prasetya, Nami Akazawa, Anca Stefanoiu, Chia-Hua Ho, Anelia Angelova, Kate Lin, Min Kim, Charles Chen, Marcin Sieniek, Alice Li, Tongfei Guo, Sorin Baltateanu, Pouya Tafti, Michael Wunder, Nadav Olmert, Divyansh Shukla, Jingwei Shen, Neel Kovelamudi, Balaji Venkatraman, Seth Neel, Romal Thoppilan, Jerome Connor, Frederik Benzing, Axel Stjerngren, Golnaz Ghiasi, Alex Polozov, Joshua Howland, Theophane Weber, Justin Chiu, Ganesh Poomal Girirajan, Andreas Terzis, Pidong Wang, Fangda Li, Yoav Ben Shalom, Dinesh Tewari, Matthew Denton, Roee Aharoni, Norbert Kalb, Heri Zhao, Junlin Zhang, Angelos Filos, Matthew Rahtz, Lalit Jain, Connie Fan, Vitor Rodrigues, Ruth Wang, Richard Shin, Jacob Austin, Roman Ring, Mariella Sanchez-Vargas, Mehadi Hassen, Ido Kessler, Uri Alon, Gufeng Zhang, Wenhu Chen, Yenai Ma, Xiance Si, Le Hou, Azalia Mirhoseini, Marc Wilson, Geoff Bacon, Becca Roelofs, Lei Shu, Gautam Vasudevan, Jonas Adler, Artur Dwornik, Tayfun Terzi, Matt Lawlor, Harry Askham, Mike Bernico, Xuanyi Dong, Chris Hidey, Kevin Kilgour, Gaël Liu, Surya Bhupatiraju, Luke Leonhard, Siqi Zuo, Partha Talukdar, Qing Wei, Aliaksei Severyn, Vít Listík, Jong Lee, Aditya Tripathi, SK Park, Yossi Matias, Hao Liu, Alex Ruiz, Rajesh Jayaram, Jackson Tolins, Pierre Marcenac, Yiming Wang, Bryan Seybold, Henry Prior, Deepak Sharma, Jack Weber, Mikhail Sirotenko, Yunhsuan Sung, Dayou Du, Ellie Pavlick, Stefan Zinke, Markus Freitag, Max Dylla, Montse Gonzalez Arenas, Natan Potikha, Omer Goldman, Connie Tao, Rachita Chhaparia, Maria Voitovich, Pawan Dogra, Andrija Ražnatović, Zak Tsai, Chong You, Oleaser Johnson, George Tucker, Chenjie Gu, Jae Yoo, Maryam Majzoubi, Valentin Gabeur, Bahram Raad, Rocky Rhodes, Kashyap Kolipaka, Heidi Howard, Geta Sampemane, Benny Li, Chulayuth Asawaroengchai, Duy Nguyen, Chiyuan Zhang, Timothee Cour, Xinxin Yu, Zhao Fu, Joe Jiang, Po-Sen Huang, Gabriela Surita, Iñaki Iturrate, Yael Karov, Michael Collins, Martin Baeuml, Fabian Fuchs, Shilpa Shetty, Swaroop Ramaswamy, Sayna Ebrahimi, Qiuchen Guo, Jeremy Shar, Gabe Barth-Maron, Sravanti Addepalli, Bryan Richter, Chin-Yi Cheng, Eugénie Rives, Fei Zheng, Johannes Griesser, Nishanth Dikkala, Yoel Zeldes, Ilkin Safarli, Dipanjan Das, Himanshu Srivastava, Sadh MNM Khan, Xin Li, Aditya Pandey, Larisa Markeeva, Dan Belov, Qiqi Yan, Mikołaj Rybiński, Tao Chen, Megha Nawhal, Michael Quinn, Vineetha Govindaraj, Sarah York, Reed Roberts, Roopal Garg, Namrata Godbole, Jake Abernethy, Anil Das, Lam Nguyen Thiet, Jonathan Tompson, John Nham, Neera Vats, Ben Caine, Wesley Helmholz, Francesco Pongetti, Yeongil Ko, James An, Clara Huiyi Hu, Yu-Cheng Ling, Julia Pawar, Robert Leland, Keisuke Kinoshita, Waleed Khawaja, Marco Selvi, Eugene Ie, Danila Sinopalnikov, Lev Proleev, Nilesh Tripuraneni, Michele Bevilacqua, Seungji Lee, Clayton Sanford, Dan Suh, Dustin Tran, Jeff Dean, Simon Baumgartner, Jens Heitkaemper, Sagar Gubbi, Kristina Toutanova, Yichong Xu, Chandu Thekkath, Keran Rong, Palak Jain, Annie Xie, Yan Virin, Yang Li, Lubo Litchev, Richard Powell, Tarun Bharti, Adam Kraft, Nan Hua, Marissa Ikonomidis, Ayal Hitron, Sanjiv Kumar, Loic Matthey, Sophie Bridgers, Lauren Lax, Ishaan Malhi, Ondrej Skopek, Ashish Gupta, Jiawei Cao, Mitchelle Rasquinha, Siim Põder, Wojciech Stokowiec, Nicholas Roth, Guowang Li, Michaël Sander, Joshua Kessinger, Vihan Jain, Edward Loper, Wonpyo Park, Michal Yarom, Liqun Cheng, Guru Guruganesh, Kanishka Rao, Yan Li, Catarina Barros, Mikhail Sushkov, Chun-Sung Ferng, Rohin Shah, Ophir Aharoni, Ravin Kumar, Tim McConnell, Peiran Li, Chen Wang, Fernando Pereira, Craig Swanson, Fayaz Jamil, Yan Xiong, Anitha Vijayakumar, Prakash Shroff, Kedar Soparkar, Jindong Gu, Livio Baldini Soares, Eric Wang, Kushal Majmundar, Aurora Wei, Kai Bailey, Nora Kassner, Chizu Kawamoto, Goran Žužić, Victor Gomes, Abhirut Gupta, Michael Guzman, Ishita Dasgupta, Xinyi Bai, Zhufeng Pan, Francesco Piccinno, Hadas Natalie Vogel, Octavio Ponce, Adrian Hutter, Paul Chang, Pan-Pan Jiang, Ionel Gog, Vlad Ionescu, James Manyika, Fabian Pedregosa, Harry Ragan, Zach Behrman, Ryan Mullins, Coline Devin, Aroonalok Pyne, Swapnil Gawde, Martin Chadwick, Yiming Gu, Sasan Tavakkol, Andy Twigg, Naman Goyal, Ndidi Elue, Anna Goldie, Srinivasan Venkatachary, Hongliang Fei, Ziqiang Feng, Marvin Ritter, Isabel Leal, Sudeep Dasari, Pei Sun, Alif Raditya Rochman, Brendan O'Donoghue, Yuchen Liu, Jim Sproch, Kai Chen, Natalie Clay, Slav Petrov, Sailesh Sidhwani, Ioana Mihailescu, Alex Panagopoulos, AJ Piergiovanni, Yunfei Bai, George Powell, Deep Karkhanis, Trevor Yacovone, Petr Mitrichev, Joe Kovac, Dave Uthus, Amir Yazdanbakhsh, David Amos, Steven Zheng, Bing Zhang, Jin Miao, Bhuvana Ramabhadran, Soroush Radpour, Shantanu Thakoor, Josh Newlan, Oran Lang, Orion Jankowski, Shikhar Bharadwaj, Jean-Michel Sarr, Shereen Ashraf, Sneha Mondal, Jun Yan, Ankit Singh Rawat, Sarmishta Velury, Greg Kochanski, Tom Eccles, Franz Och, Abhanshu Sharma, Ethan Mahintorabi, Alex Gurney, Carrie Muir, Vered Cohen, Saksham Thakur, Adam Bloniarz, Asier Mujika, Alexander Pritzel, Paul Caron, Altaf Rahman, Fiona Lang, Yasumasa Onoe, Petar Sirkovic, Jay Hoover, Ying Jian, Pablo Duque, Arun Narayanan, David Soergel, Alex Haig, Loren Maggiore, Shyamal Buch, Josef Dean, Ilya Figotin, Igor Karpov, Shaleen Gupta, Denny Zhou, Muhuan Huang, Ashwin Vaswani, Christopher Semturs, Kaushik Shivakumar, Yu Watanabe, Vinodh Kumar Rajendran, Eva Lu, Yanhan Hou, Wenting Ye, Shikhar Vashishth, Nana Nti, Vytenis Sakenas, Darren Ni, Doug DeCarlo, Michael Bendersky, Sumit Bagri, Nacho Cano, Elijah Peake, Simon Tokumine, Varun Godbole, Carlos Guía, Tanya Lando, Vittorio Selo, Seher Ellis, Danny Tarlow, Daniel Gillick, Alessandro Epasto, Siddhartha Reddy Jonnalagadda, Meng Wei, Meiyan Xie, Ankur Taly, Michela Paganini, Mukund Sundararajan, Daniel Toyama, Ting Yu, Dessie Petrova, Aneesh Pappu, Rohan Agrawal, Senaka Buthpitiya, Justin Frye, Thomas Buschmann, Remi Crocker, Marco Tagliasacchi, Mengchao Wang, Da Huang, Sagi Perel, Brian Wieder, Hideto Kazawa, Weiyue Wang, Jeremy Cole, Himanshu Gupta, Ben Golan, Seojin Bang, Nitish Kulkarni, Ken Franko, Casper Liu, Doug Reid, Sid Dalmia, Jay Whang, Kevin Cen, Prasha Sundaram, Johan Ferret, Berivan Isik, Lucian Ionita, Guan Sun, Anna Shekhawat, Muqthar Mohammad, Philip Pham, Ronny Huang, Karthik Raman, Xingyi Zhou, Ross Mcilroy, Austin Myers, Sheng Peng, Jacob Scott, Paul Covington, Sofia Erell, Pratik Joshi, João Gabriel Oliveira, Natasha Noy, Tajwar Nasir, Jake Walker, Vera Axelrod, Tim Dozat, Pu Han, Chun-Te Chu, Eugene Weinstein, Anand Shukla, Shreyas Chandrakaladharan, Petra Poklukar, Bonnie Li, Ye Jin, Prem Eruvbetine, Steven Hansen, Avigail Dabush, Alon Jacovi, Samrat Phatale, Chen Zhu, Steven Baker, Mo Shomrat, Yang Xiao, Jean Pouget-Abadie, Mingyang Zhang, Fanny Wei, Yang Song, Helen King, Yiling Huang, Yun Zhu, Ruoxi Sun, Juliana Vicente Franco, Chu-Cheng Lin, Sho Arora, Hui, Li, Vivian Xia, Luke Vilnis, Mariano Schain, Kaiz Alarakyia, Laurel Prince, Aaron Phillips, Caleb Habtegebriel, Luyao Xu, Huan Gui, Santiago Ontanon, Lora Aroyo, Karan Gill, Peggy Lu, Yash Katariya, Dhruv Madeka, Shankar Krishnan, Shubha Srinivas Raghvendra, James Freedman, Yi Tay, Gaurav Menghani, Peter Choy, Nishita Shetty, Dan Abolafia, Doron Kukliansky, Edward Chou, Jared Lichtarge, Ken Burke, Ben Coleman, Dee Guo, Larry Jin, Indro Bhattacharya, Victoria Langston, Yiming Li, Suyog Kotecha, Alex Yakubovich, Xinyun Chen, Petre Petrov, Tolly Powell, Yanzhang He, Corbin Quick, Kanav Garg, Dawsen Hwang, Yang Lu, Srinadh Bhojanapalli, Kristian Kjems, Ramin Mehran, Aaron Archer, Hado van Hasselt, Ashwin Balakrishna, JK Kearns, Meiqi Guo, Jason Riesa, Mikita Sazanovich, Xu Gao, Chris Sauer, Chengrun Yang, XiangHai Sheng, Thomas Jimma, Wouter Van Gansbeke, Vitaly Nikolaev, Wei Wei, Katie Millican, Ruizhe Zhao, Justin Snyder, Levent Bolelli, Maura O'Brien, Shawn Xu, Fei Xia, Wentao Yuan, Arvind Neelakantan, David Barker, Sachin Yadav, Hannah Kirkwood, Farooq Ahmad, Joel Wee, Jordan Grimstad, Boyu Wang, Matthew Wiethoff, Shane Settle, Miaosen Wang, Charles Blundell, Jingjing Chen, Chris Duvarney, Grace Hu, Olaf Ronneberger, Alex Lee, Yuanzhen Li, Abhishek Chakladar, Alena Butryna, Georgios Evangelopoulos, Guillaume Desjardins, Jonni Kanerva, Henry Wang, Averi Nowak, Nick Li, Alyssa Loo, Art Khurshudov, Laurent El Shafey, Nagabhushan Baddi, Karel Lenc, Yasaman Razeghi, Tom Lieber, Amer Sinha, Xiao Ma, Yao Su, James Huang, Asahi Ushio, Hanna Klimczak-Plucińska, Kareem Mohamed, JD Chen, Simon Osindero, Stav Ginzburg, Lampros Lamprou, Vasilisa Bashlovkina, Duc-Hieu Tran, Ali Khodaei, Ankit Anand, Yixian Di, Ramy Eskander, Manish Reddy Vuyyuru, Jasmine Liu, Aishwarya Kamath, Roman Goldenberg, Mathias Bellaiche, Juliette Pluto, Bill Rosgen, Hassan Mansoor, William Wong, Suhas Ganesh, Eric Bailey, Scott Baird, Dan Deutsch, Jinoo Baek, Xuhui Jia, Chansoo Lee, Abe Friesen, Nathaniel Braun, Kate Lee, Amayika Panda, Steven M. Hernandez, Duncan Williams, Jianqiao Liu, Ethan Liang, Arnaud Autef, Emily Pitler, Deepali Jain, Phoebe Kirk, Oskar Bunyan, Jaume Sanchez Elias, Tongxin Yin, Machel Reid, Aedan Pope, Nikita Putikhin, Bidisha Samanta, Sergio Guadarrama, Dahun Kim, Simon Rowe, Marcella Valentine, Geng Yan, Alex Salcianu, David Silver, Gan Song, Richa Singh, Shuai Ye, Hannah DeBalsi, Majd Al Merey, Eran Ofek, Albert Webson, Shibl Mourad, Ashwin Kakarla, Silvio Lattanzi, Nick Roy, Evgeny Sluzhaev, Christina Butterfield, Alessio Tonioni, Nathan Waters, Sudhindra Kopalle, Jason Chase, James Cohan, Girish Ramchandra Rao, Robert Berry, Michael Voznesensky, Shuguang Hu, Kristen Chiafullo, Sharat Chikkerur, George Scrivener, Ivy Zheng, Jeremy Wiesner, Wolfgang Macherey, Timothy Lillicrap, Fei Liu, Brian Walker, David Welling, Elinor Davies, Yangsibo Huang, Lijie Ren, Nir Shabat, Alessandro Agostini, Mariko Iinuma, Dustin Zelle, Rohit Sathyanarayana, Andrea D'olimpio, Morgan Redshaw, Matt Ginsberg, Ashwin Murthy, Mark Geller, Tatiana Matejovicova, Ayan Chakrabarti, Ryan Julian, Christine Chan, Qiong Hu, Daniel Jarrett, Manu Agarwal, Jeshwanth Challagundla, Tao Li, Sandeep Tata, Wen Ding, Maya Meng, Zhuyun Dai, Giulia Vezzani, Shefali Garg, Jannis Bulian, Mary Jasarevic, Honglong Cai, Harish Rajamani, Adam Santoro, Florian Hartmann, Chen Liang, Bartek Perz, Apoorv Jindal, Fan Bu, Sungyong Seo, Ryan Poplin, Adrian Goedeckemeyer, Badih Ghazi, Nikhil Khadke, Leon Liu, Kevin Mather, Mingda Zhang, Ali Shah, Alex Chen, Jinliang Wei, Keshav Shivam, Yuan Cao, Donghyun Cho, Angelo Scorza Scarpati, Michael Moffitt, Clara Barbu, Ivan Jurin, Ming-Wei Chang, Hongbin Liu, Hao Zheng, Shachi Dave, Christine Kaeser-Chen, Xiaobin Yu, Alvin Abdagic, Lucas Gonzalez, Yanping Huang, Peilin Zhong, Cordelia Schmid, Bryce Petrini, Alex Wertheim, Jifan Zhu, Hoang Nguyen, Kaiyang Ji, Yanqi Zhou, Tao Zhou, Fangxiaoyu Feng, Regev Cohen, David Rim, Shubham Milind Phal, Petko Georgiev, Ariel Brand, Yue Ma, Wei Li, Somit Gupta, Chao Wang, Pavel Dubov, Jean Tarbouriech, Kingshuk Majumder, Huijian Li, Norman Rink, Apurv Suman, Yang Guo, Yinghao Sun, Arun Nair, Xiaowei Xu, Mohamed Elhawaty, Rodrigo Cabrera, Guangxing Han, Julian Eisenschlos, Junwen Bai, Yuqi Li, Yamini Bansal, Thibault Sellam, Mina Khan, Hung Nguyen, Justin Mao-Jones, Nikos Parotsidis, Jake Marcus, Cindy Fan, Roland Zimmermann, Yony Kochinski, Laura Graesser, Feryal Behbahani, Alvaro Caceres, Michael Riley, Patrick Kane, Sandra Lefdal, Rob Willoughby, Paul Vicol, Lun Wang, Shujian Zhang, Ashleah Gill, Yu Liang, Gautam Prasad, Soroosh Mariooryad, Mehran Kazemi, Zifeng Wang, Kritika Muralidharan, Paul Voigtlaender, Jeffrey Zhao, Huanjie Zhou, Nina D'Souza, Aditi Mavalankar, Séb Arnold, Nick Young, Obaid Sarvana, Chace Lee, Milad Nasr, Tingting Zou, Seokhwan Kim, Lukas Haas, Kaushal Patel, Neslihan Bulut, David Parkinson, Courtney Biles, Dmitry Kalashnikov, Chi Ming To, Aviral Kumar, Jessica Austin, Alex Greve, Lei Zhang, Megha Goel, Yeqing Li, Sergey Yaroshenko, Max Chang, Abhishek Jindal, Geoff Clark, Hagai Taitelbaum, Dale Johnson, Ofir Roval, Jeongwoo Ko, Anhad Mohananey, Christian Schuler, Shenil Dodhia, Ruichao Li, Kazuki Osawa, Claire Cui, Peng Xu, Rushin Shah, Tao Huang, Ela Gruzewska, Nathan Clement, Mudit Verma, Olcan Sercinoglu, Hai Qian, Viral Shah, Masa Yamaguchi, Abhinit Modi, Takahiro Kosakai, Thomas Strohmann, Junhao Zeng, Beliz Gunel, Jun Qian, Austin Tarango, Krzysztof Jastrzębski, Robert David, Jyn Shan, Parker Schuh, Kunal Lad, Willi Gierke, Mukundan Madhavan, Xinyi Chen, Mark Kurzeja, Rebeca Santamaria-Fernandez, Dawn Chen, Alexandra Cordell, Yuri Chervonyi, Frankie Garcia, Nithish Kannen, Vincent Perot, Nan Ding, Shlomi Cohen-Ganor, Victor Lavrenko, Junru Wu, Georgie Evans, Cicero Nogueira dos Santos, Madhavi Sewak, Ashley Brown, Andrew Hard, Joan Puigcerver, Zeyu Zheng, Yizhong Liang, Evgeny Gladchenko, Reeve Ingle, Uri First, Pierre Sermanet, Charlotte Magister, Mihajlo Velimirović, Sashank Reddi, Susanna Ricco, Eirikur Agustsson, Hartwig Adam, Nir Levine, David Gaddy, Dan Holtmann-Rice, Xuanhui Wang, Ashutosh Sathe, Abhijit Guha Roy, Blaž Bratanič, Alen Carin, Harsh Mehta, Silvano Bonacina, Nicola De Cao, Mara Finkelstein, Verena Rieser, Xinyi Wu, Florent Altché, Dylan Scandinaro, Li Li, Nino Vieillard, Nikhil Sethi, Garrett Tanzer, Zhi Xing, Shibo Wang, Parul Bhatia, Gui Citovsky, Thomas Anthony, Sharon Lin, Tianze Shi, Shoshana Jakobovits, Gena Gibson, Raj Apte, Lisa Lee, Mingqing Chen, Arunkumar Byravan, Petros Maniatis, Kellie Webster, Andrew Dai, Pu-Chin Chen, Jiaqi Pan, Asya Fadeeva, Zach Gleicher, Thang Luong, Niket Kumar Bhumihar* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** Gemini 2.X, 多模态, 代理能力, 长上下文, 推理

**Comment:** 72 pages, 17 figures

> **TL;DR:** 报告介绍了Gemini 2.X系列模型，包括2.5 Pro（SOTA推理、多模态、长上下文、代理能力）和2.5 Flash（高效率推理），以及2.0 Flash/Flash-Lite（低成本高性能），共同覆盖了性能与成本的帕累托前沿，旨在推动复杂代理问题解决。

**AI_Comments:** 这篇报告介绍了Gemini模型系列的重要进展，特别是Gemini 2.5 Pro在多模态理解和长视频处理方面的突破性能力，以及其在编码和推理领域的SOTA表现。整个2.X系列通过提供不同性能-成本权衡的模型，展示了Google在大型模型领域不断探索和扩展其能力的决心，特别是在推动下一代代理能力方面的潜力值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在介绍Gemini 2.X系列模型，通过结合长上下文、多模态和推理能力，解锁新的代理工作流程，并覆盖模型能力与成本的帕累托前沿，使用户能够探索复杂代理问题解决的边界。

**Method:** 本报告介绍了Gemini 2.X模型家族，包括最强大的Gemini 2.5 Pro、高效的Gemini 2.5 Flash，以及早期的Gemini 2.0 Flash和Flash-Lite模型。

**Result:** Gemini 2.5 Pro在前沿编码和推理基准测试中取得了SoTA性能，擅长多模态理解，并能处理长达3小时的视频内容。Gemini 2.5 Flash以较低的计算和延迟要求提供出色的推理能力。Gemini 2.0 Flash和Flash-Lite以低延迟和低成本提供高性能。整个Gemini 2.X模型系列覆盖了模型能力与成本的帕累托前沿。

**Conclusion:** Gemini 2.X模型系列通过提供不同能力与成本权衡的模型，推动了先进推理、多模态理解、长上下文处理和下一代代理能力的边界，使用户能够解决复杂的代理问题。

> **ai_Abstract:** 本报告介绍了Google的Gemini 2.X系列模型，包括强大的Gemini 2.5 Pro（在编码、推理、多模态理解和长视频处理方面达到SoTA）以及更高效的Gemini 2.5 Flash。此外，还提及了早期的Gemini 2.0 Flash和Flash-Lite，它们以低成本提供高性能。整个Gemini 2.X系列旨在通过覆盖性能与成本的广泛范围，推动先进的推理、多模态和代理能力，从而赋能用户解决复杂的代理问题。

> **摘要翻译:** 在本报告中，我们介绍了Gemini 2.X模型家族：Gemini 2.5 Pro和Gemini 2.5 Flash，以及我们早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是我们迄今为止能力最强的模型，在前沿编码和推理基准测试中取得了最先进的性能。除了其令人难以置信的编码和推理技能外，Gemini 2.5 Pro是一个擅长多模态理解的思考模型，现在能够处理长达3小时的视频内容。其长上下文、多模态和推理能力的独特组合可以协同解锁新的代理工作流程。Gemini 2.5 Flash以极低的计算和延迟要求提供出色的推理能力，而Gemini 2.0 Flash和Flash-Lite则以低延迟和低成本提供高性能。总而言之，Gemini 2.X模型世代涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索复杂代理问题解决的可能边界。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [375] [Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction](https://arxiv.org/abs/2507.16271)
> *超越孤立点：将结构化表格构建作为深度知识提取的基准测试*

*Tianyun Zhong, Guozhao Mo, Yanjiang Liu, Yihan Chen, Lingdi Kong, Xuanang Chen, Yaojie Lu, Hongyu Lin, Ben He, Le Sun* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 知识提取, 结构化表格, 基准测试, AOE

**Comment:** 

> **TL;DR:** 该论文引入了一个名为AOE的新基准，用于评估大型语言模型（LLMs）从复杂文档中提取信息并将其重构为结构化表格的能力，实验结果表明即使是最先进的LLMs也表现不佳。

**AI_Comments:** 该论文通过引入AOE基准，填补了评估LLMs在结构化知识提取方面能力的一个重要空白。其创新之处在于超越了传统的固定模式文本到表格任务，要求模型生成上下文相关的模式，这更接近真实世界的复杂性。研究结果揭示了当前LLMs在处理深度知识提取和信息重组方面的局限性，对未来LLMs的发展方向提供了重要的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在从复杂文档中提取显式信息时，生成的答案通常是混乱、无组织且难以追溯的段落式内容，无法将孤立信息重构为有组织的表格。为了弥补这一差距，需要一个系统性的基准来评估LLMs构建结构化表格的能力。

**Method:** 论文引入了一个名为“Arranged and Organized Extraction Benchmark (AOE)”的新型双语基准测试。AOE包含不同长度的数据和文档，旨在系统地评估LLMs理解碎片化文档并将孤立信息重构为有组织表格的能力。与传统依赖固定模式和狭窄任务领域的文本到表格任务不同，AOE包含来自三个不同领域的11个精心设计的任务，要求模型根据不同的输入查询生成特定于上下文的模式。

**Result:** 实验结果显示，即使是最先进的开源和闭源大型语言模型，在AOE基准测试中也表现出显著的挣扎。

**Conclusion:** 大型语言模型在从复杂文档中提取信息并构建结构化表格方面仍面临显著挑战，需要进一步的研究和改进，以提高其在深度知识提取方面的能力。

> **ai_Abstract:** 本研究引入了“Arranged and Organized Extraction Benchmark (AOE)”，这是一个旨在评估大型语言模型（LLMs）从复杂文档中提取并重构结构化表格能力的新型双语基准测试。与传统文本到表格任务不同，AOE涵盖三个多样化领域中的11个任务，要求LLMs生成上下文特定的模式。对最先进LLMs的评估结果表明，它们在这一任务上仍面临显著挑战。

> **摘要翻译:** 随着大型语言模型（LLMs）的出现，人们期望LLMs能够有效地从复杂的真实世界文档（例如论文、报告）中提取显式信息。然而，大多数LLMs生成的答案是混乱、无组织且难以追溯的段落式内容。为了弥补这一差距，我们引入了“Arranged and Organized Extraction Benchmark (AOE)”，这是一个新的双语基准测试，包含不同长度的数据和文档，旨在系统地评估LLMs理解碎片化文档并将孤立信息重构为一个有组织表格的能力。与依赖固定模式和狭窄任务领域的传统文本到表格任务不同，AOE包含来自三个不同领域的11个精心设计的任务，要求模型生成针对不同输入查询的上下文特定模式。在实验中，我们评估了开源和闭源的最新LLMs。结果表明，即使是最先进的模型也表现出显著的挣扎。该基准可在https://huggingface.co/datasets/tianyumyum/AOE获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [388] [Continuously Updating Digital Twins using Large Language Models](https://arxiv.org/abs/2506.12091)
> *使用大型语言模型持续更新数字孪生*

*Harry Amad, Nicolás Astorga, Mihaela van der Schaar* | **Category: cs.CL** | **Updated: 2025-07-21**

**Keywords:** 数字孪生, 大型语言模型, 上下文学习, 持续更新, CALM-DT

**Comment:** 

> **TL;DR:** 本文提出了一种基于大型语言模型（LLM）的数字孪生系统CALM-DT，它能通过上下文学习实现持续更新和适应不断变化的建模环境，无需重新设计或重新训练。

**AI_Comments:** 本文创新性地将大型语言模型引入数字孪生领域，解决了传统方法在动态环境中更新困难的痛点。通过上下文学习，CALM-DT实现了无需重新训练或重新设计即可适应新信息和新变量，这对于构建更灵活、更具韧性的数字孪生系统具有重要意义。其无需参数更新即可适应环境变化的能力是其显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数字孪生方法难以适应不断变化的系统状态、动作变量、数据和知识，因为它们需要固定的建模环境，并且在面对新变量时需要重新设计，或在纳入新信息时需要重新训练。

**Method:** 本文将数字孪生视为一个使用大型语言模型的上下文学习问题。开发了CALM-DT（Context-Adaptive Language Model-based Digital Twin），它利用微调的编码器进行样本检索，仅通过上下文学习就能在不同的状态-动作空间中进行准确模拟。

**Result:** CALM-DT在性能上与现有数字孪生方法具有竞争力，并且独特地能够适应建模环境的变化而无需更新参数。

**Conclusion:** CALM-DT展示了大型语言模型在构建能够持续更新和适应不断变化环境的数字孪生方面的潜力。

> **ai_Abstract:** 本文提出了一种名为CALM-DT的新型数字孪生方法，该方法利用大型语言模型（LLM）的上下文学习能力，解决了传统数字孪生在动态环境中难以持续更新和适应的问题。CALM-DT通过将数字孪生视为一个上下文学习问题，并在推理时进行无缝更新，无需重新设计或重新训练。实验结果表明，CALM-DT在性能上与现有方法相当，并能独特地适应环境变化而无需参数更新。

> **摘要翻译:** 数字孪生是真实世界系统的模型，可以模拟其对潜在行动的动态响应。在复杂的环境中，与系统相关的状态和动作变量以及可用数据和知识可以不断变化，这要求数字孪生能够持续更新以保持相关性。当前的方法在这方面存在困难，因为它们需要固定、明确定义的建模环境，并且无法在不重新设计的情况下适应新的变量，也无法在不重新训练的情况下整合新的信息。为了解决这个问题，我们将数字孪生建模构架为使用大型语言模型的上下文学习问题，从而在推理时实现孪生的无缝更新。我们开发了CALM-DT，一个基于上下文自适应语言模型的数字孪生系统，它通过利用微调的编码器进行样本检索，仅通过上下文学习就能在不同的状态-动作空间中进行准确模拟。我们通过实证证明了CALM-DT与现有数字孪生方法具有竞争力的性能，以及其独特的能力，即无需参数更新即可适应其建模环境的变化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [393] [Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning](https://arxiv.org/abs/2507.16802)
> *Agentar-Fin-R1：通过领域专业知识、训练效率和高级推理增强金融智能*

*Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wang Wei, Peng Zhang* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 金融大模型, 推理能力, 可信度, Agentar-Fin-R1, Finova

**Comment:** 

> **TL;DR:** Agentar-Fin-R1是一系列基于Qwen3的金融大语言模型，旨在通过优化方法和新的评估基准，解决现有模型在金融领域推理能力、可信度和效率方面的不足，并在金融和通用推理任务上取得最先进的性能。

**AI_Comments:** Agentar-Fin-R1的创新之处在于其对金融领域特性的深入理解和系统性优化，特别是在推理能力、可信度保障和训练效率方面的提升。其提出的Finova评估基准也填补了智能体级别金融推理和合规验证的空白，对于实际部署具有重要意义。该工作为金融LLM的发展提供了有价值的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在金融领域展现出巨大潜力，但在需要强大的推理能力、严格的可信度要求以及高效适应特定任务的场景中表现不足。

**Method:** 本文引入了Agentar-Fin-R1系列金融大语言模型（8B和32B参数），基于Qwen3基础模型进行工程设计，以增强金融应用的推理能力、可靠性和领域专业化。优化方法整合了高质量、系统的金融任务分类体系和全面的多层可信度保障框架，包括高质量可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段学习过程和详细归因系统，显著提高了训练效率。模型在FinEva、FinEval、FinanceIQ等主流金融基准以及MATH-500、GPQA等通用推理数据集上进行了全面评估。还创新性地提出了Finova评估基准，专注于智能体级别的金融推理和合规验证。

**Result:** 实验结果表明，Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力。

**Conclusion:** Agentar-Fin-R1被验证是高风险金融应用中值得信赖的有效解决方案。

> **ai_Abstract:** 本文介绍了Agentar-Fin-R1系列金融大语言模型（8B和32B），旨在解决现有LLM在金融领域推理、可信度和效率方面的不足。该模型基于Qwen3构建，通过整合高质量金融任务分类和多层可信度保障框架进行优化，并采用难度感知优化和两阶段学习提升训练效率。模型在主流金融和通用推理基准上进行了全面评估，并提出了新的Finova基准。实验证明Agentar-Fin-R1在金融任务上达到SOTA性能，并具有出色的通用推理能力，是高风险金融应用的可靠方案。

> **摘要翻译:** 大型语言模型（LLMs）在金融领域展现出巨大潜力，然而现有模型在需要强大推理能力、严格可信度要求以及高效适应特定任务的场景中往往表现不足。我们引入了Agentar-Fin-R1系列金融大型语言模型（8B和32B参数），专门基于Qwen3基础模型进行工程设计，以增强金融应用的推理能力、可靠性和领域专业化。我们的优化方法整合了高质量、系统的金融任务分类体系和一个全面的多层可信度保障框架。该框架包括高质量可信知识工程、多智能体可信数据合成以及严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段学习过程和详细归因系统，我们实现了训练效率的显著提升。我们的模型在包括FinEva、FinEval和FinanceIQ在内的主流金融基准以及MATH-500和GPQA等通用推理数据集上进行了全面评估。为了彻底评估实际部署能力，我们创新性地提出了Finova评估基准，该基准专注于智能体级别的金融推理和合规验证。实验结果表明，Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，而且展现出卓越的通用推理能力，验证了其作为高风险金融应用中值得信赖的解决方案的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [404] [The Ever-Evolving Science Exam](https://arxiv.org/abs/2507.16514)
> *不断演变的科学考试*

*Junying Wang, Zicheng Zhang, Yijin Guo, Farong Wen, Ye Shen, Yingji Liang, Yalun Wu, Wenzhe Li, Chunyi Li, Zijian Chen, Qi Jia, Guangtao Zhai* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 基础模型, 科学理解, 基准测试, 数据泄露, EESE

**Comment:** 20 pages

> **TL;DR:** 本文介绍了EESE，一个动态且不断更新的科学基准测试，旨在解决现有基准测试中数据泄露和评估效率低下的问题，并有效评估基础模型的科学理解能力。

**AI_Comments:** 本文的创新点在于提出了一个动态且抗数据泄露的科学基准测试EESE，通过非公开题库和定期更新子集的方式有效解决了现有基准测试面临的数据泄露和评估效率问题。其重要性在于为评估日益强大的基础模型在科学领域的理解能力提供了一个更可靠和可扩展的工具，这对于确保AI模型的公平性和进步至关重要。该方法通过分离大型私有池和小型公开测试集，巧妙地平衡了测试的广度、严谨性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 随着基础模型能力的快速增长和部署，评估它们的科学理解变得越来越重要。然而，现有的科学基准测试面临两大挑战：数据泄露风险损害基准测试的有效性，以及大规模测试导致的评估效率低下。

**Method:** 作者引入了“不断演变的科学考试（EESE）”，这是一个动态基准测试。它包含两个部分：1) 一个非公开的EESE-Pool，包含超过10万个精心构建的科学实例，涵盖5个学科和500多个子领域，通过多阶段流程确保广度、覆盖范围和严谨性；2) 一个定期更新的500个实例的EESE子集，经过抽样和验证，以实现抗泄露、低开销的评估。

**Result:** 在32个开源和闭源模型上的实验表明，EESE能够有效区分模型在科学领域和认知维度上的优势和劣势。

**Conclusion:** EESE为科学基准测试设计提供了一个强大、可扩展且向前兼容的解决方案，为基础模型处理科学问题提供了真实的衡量标准。

> **ai_Abstract:** 本文提出了EESE（Ever-Evolving Science Exam），一个动态的科学基准测试，旨在解决现有基准测试中数据泄露和评估效率低下的问题。EESE包含一个大型非公开问题池（EESE-Pool）和一个定期更新的小型公开子集，用于低开销、抗泄露的评估。实验证明EESE能有效评估和区分基础模型的科学理解能力，为未来科学基准测试提供了鲁棒、可扩展的解决方案。

> **摘要翻译:** 随着基础模型在能力和部署方面迅速发展，评估它们的科学理解变得越来越重要。现有的科学基准测试在广度、覆盖范围和严谨性方面取得了进展，但它们常常面临两大主要挑战：损害基准测试有效性的数据泄露风险，以及由于大规模测试导致的评估效率低下。为了解决这些问题，我们引入了“不断演变的科学考试（EESE）”，这是一个动态基准测试，旨在可靠地评估基础模型的科学能力。我们的方法包括两个组成部分：1) 一个非公开的EESE-Pool，其中包含超过10万个精心构建的科学实例（问答对），涵盖5个学科和500多个子领域，通过多阶段流程构建，确保了广度、覆盖范围和严谨性；2) 一个定期更新的500个实例的EESE子集，经过抽样和验证，以实现抗泄露、低开销的评估。在32个开源和闭源模型上的实验表明，EESE能够有效区分模型在科学领域和认知维度上的优势和劣势。总的来说，EESE为科学基准测试设计提供了一个强大、可扩展且向前兼容的解决方案，为基础模型如何处理科学问题提供了真实的衡量标准。项目页面位于：https://github.com/aiben-ch/EESE。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [405] [Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis](https://arxiv.org/abs/2507.16284)
> *基于闵可夫斯基范数的语言检测：通过字符二元组和频率分析进行识别*

*Paul-Andrei Pogăcean, Sanda-Maria Avram* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 语言检测, 闵可夫斯基范数, 字符二元组, 频率分析, 非AI方法

**Comment:** 

> **TL;DR:** 本研究探索了一种基于闵可夫斯基范数、利用字符一元组和二元组频率排序的数学算法，用于语言识别，并在短文本上实现了80%以上准确率，在长文本和旧文本上达到100%准确率，证明了经典频率方法在语言检测方面仍是AI模型的有效替代方案。

**AI_Comments:** 这篇论文的创新点在于，它在AI模型日益占据主导地位的当下，重新审视并验证了经典的、非AI驱动的语言识别方法的有效性。它证明了在某些特定场景下（如短文本和旧文本），简单的频率分析结合数学范数也能达到甚至超越AI模型的表现。这对于资源有限或需要高可解释性的应用场景具有重要意义，提供了一个有力的替代方案。其局限性可能在于是否能处理高度口语化、非标准化的文本或多语言混合文本。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，语言识别的讨论再次受到关注，特别是随着AI驱动的语言模型快速发展。然而，非AI的语言识别方法却被忽视了。本研究旨在探索一种基于数学实现的算法，以证明经典方法在语言识别中的有效性。

**Method:** 本研究探索了一种通过利用基于既定语言学研究的一元组和二元组频率排名，结合闵可夫斯基范数实现的语言确定性算法。数据集包含长度、历史时期和体裁各异的文本，如短篇小说、童话和诗歌。

**Result:** 该方法在短于150个字符的文本上实现了超过80%的准确率，对于更长的文本和更古老的著作，准确率达到了100%。

**Conclusion:** 这些结果表明，经典的基于频率的方法在语言检测方面仍然是AI驱动模型的有效且可扩展的替代方案。

> **ai_Abstract:** 本研究提出了一种基于闵可夫斯基范数和字符一元组/二元组频率分析的非AI语言识别算法。该算法利用语言学研究中的频率排名，并在多样化的文本数据集（包括不同长度、时期和体裁的文本）上进行评估。结果显示，该方法在短于150字符的文本上准确率超过80%，对于更长的文本和旧文本则达到100%准确率。研究强调，经典的频率分析方法仍然是语言检测领域中AI模型的有效且可扩展的替代方案。

> **摘要翻译:** 近年来，围绕语言识别的争论再次受到关注，特别是随着AI驱动的语言模型快速发展。然而，非AI的语言识别方法却被忽视了。本研究探索了一种通过利用基于既定语言学研究的一元组和二元组频率排名，结合闵可夫斯基范数实现的语言确定性算法。所使用的数据集包括长度、历史时期和体裁各异的文本，包括短篇小说、童话和诗歌。尽管存在这些变异，该方法在短于150个字符的文本上实现了超过80%的准确率，对于更长的文本和更古老的著作，准确率达到了100%。这些结果表明，经典的基于频率的方法在语言检测方面仍然是AI驱动模型的有效且可扩展的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [415] [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](https://arxiv.org/abs/2506.06821)
> *大型语言模型能否生成可靠的测试用例生成器？一项关于竞赛级编程问题的研究*

*Yuhan Cao, Zian Chen, Kun Quan, Ziliang Zhang, Yu Wang, Xiaoning Dong, Yeqi Feng, Guanzhong He, Jingcheng Huang, Jianhao Li, Yixuan Tan, Jiafu Tang, Yilin Tang, Junlei Wu, Qianyu Xiao, Can Zheng, Shouchen Zhou, Yuxiang Zhu, Yiming Huang, Tian Xie, Tianxing He* | **Category: cs.CL, cs.AI, cs.SE** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 测试用例生成, 竞赛级编程, 代码调试, TCGBench

**Comment:** 37 pages, 22 figures

> **TL;DR:** 本研究探讨了大型语言模型（LLMs）生成竞赛级编程问题测试用例生成器的能力。结果显示，LLMs可以生成有效的测试用例，但在生成能有效揭示人类代码错误的有针对性测试用例方面表现不佳，即使是先进的推理模型也远低于人类水平。然而，高质量的数据集可以提升LLMs的表现。

**AI_Comments:** 这篇论文创新性地将LLMs的能力拓展到测试用例生成领域，并提出了一个专门的基准TCGBench来评估LLMs在这方面的表现。其重要性在于揭示了LLMs在生成有效测试用例方面的潜力，同时也明确指出了其在生成有针对性、能揭示代码错误的测试用例方面的局限性。论文的亮点在于其对LLMs在代码调试辅助方面的深入探索，并提供了一个明确的提升方向（高质量数据集）。这项研究为未来LLM在软件测试和调试领域的应用提供了宝贵的见解和方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在代码生成方面表现出色，但其在通过测试用例生成进行代码检查或调试方面的应用程度仍未被充分探索。本研究旨在探讨LLMs生成可靠测试用例生成器的能力，特别是在竞赛级编程问题背景下。

**Method:** 研究从竞赛级编程（CP）问题的角度出发，提出了TCGBench，一个用于评估LLM生成测试用例生成器能力的基准。该基准包含两项任务：(1) 为给定CP问题生成有效的测试用例生成器；(2) 生成能揭示人类编写代码中错误的有针对性测试用例生成器。此外，构建了一个高质量、人工整理的指令数据集，用于生成有针对性的生成器，并通过提示和微调来评估其对LLM性能的提升作用。

**Result:** 实验结果表明，最先进的LLMs在大多数情况下可以生成有效的测试用例生成器。然而，大多数LLMs在生成能有效揭示人类代码缺陷的有针对性测试用例方面表现不佳。特别是，即使是先进的推理模型（例如o3-mini）在生成有针对性生成器的任务中也显著低于人类表现。此外，分析表明，借助高质量、人工整理的指令数据集，LLMs的性能可以通过提示和微调得到提升。

**Conclusion:** 大型语言模型在生成有效测试用例生成器方面表现出一定能力，但在生成能够揭示代码缺陷的有针对性测试用例方面仍存在显著不足，与人类表现差距较大。然而，通过高质量的数据集进行提示或微调可以有效提升LLMs在此任务上的性能。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在生成竞赛级编程问题测试用例生成器方面的能力。研究提出了TCGBench基准，用于评估LLMs在生成有效测试用例和揭示代码缺陷的有针对性测试用例方面的表现。实验结果显示，LLMs能生成有效测试用例，但在生成有针对性测试用例方面表现不佳，与人类水平存在显著差距。研究还发现，通过高质量、人工整理的指令数据集进行提示或微调，可以有效提升LLMs的性能。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成方面展现了卓越的能力，能够在推理过程中处理复杂的任务。然而，LLMs在通过测试用例生成进行代码检查或调试方面的利用程度在很大程度上仍未被探索。我们从竞赛级编程（CP）程序的角度研究了这个问题，并提出了TCGBench，一个用于（LLM生成）测试用例生成器的基准。该基准包括两项任务，旨在研究LLMs在以下方面的能力：(1) 为给定CP问题生成有效的测试用例生成器，以及进一步(2) 生成能够揭示人类编写代码中错误的有针对性测试用例生成器。实验结果表明，尽管最先进的LLMs在大多数情况下可以生成有效的测试用例生成器，但大多数LLMs难以有效生成揭示人类代码缺陷的有针对性测试用例。特别是，即使是先进的推理模型（例如o3-mini）在生成有针对性生成器的任务中也显著低于人类表现。此外，我们构建了一个高质量、人工整理的用于生成有针对性生成器的指令数据集。分析表明，通过提示和微调，借助该数据集可以增强LLMs的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [418] [SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment](https://arxiv.org/abs/2507.07939)
> *SAGE: 一种通过事实增强和熵感知对齐的异常检测视觉语言模型*

*Guoxin Zang, Xue Li, Donglin Di, Lanshun Nie, Dechen Zhan, Yang Song, Lei Fan* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 异常检测, 视觉语言模型, 事实增强, 偏好优化, 工业应用

**Comment:** Accepted by ACMMM2025

> **TL;DR:** SAGE是一种新的视觉语言模型框架，通过事实增强和熵感知对齐来改进工业异常检测和推理，解决了现有VLM在可解释性和泛化性方面的局限性。

**AI_Comments:** SAGE的创新之处在于其结合了领域特定知识的事实增强（SFE）和利用专家偏好的熵感知对齐（E-DPO），这对于提升VLM在复杂工业异常检测场景中的可解释性和泛化能力至关重要。同时，提出的AD-PL数据集和MLE评估框架也为该领域的未来研究提供了宝贵的资源和工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言模型（VLMs）在通用多模态任务中表现出色，但在工业异常检测和推理方面表现不佳，尤其是在提供可解释性解释和泛化到未见类别方面。这源于异常检测固有的领域特定性质，阻碍了现有VLM在需要精确、结构化和上下文感知分析的工业场景中的应用。

**Method:** 我们提出了SAGE，一个基于VLM的框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）来增强异常推理。SFE通过事实提取和融合将领域特定知识整合到视觉推理中。E-DPO使用熵感知优化将模型输出与专家偏好对齐。此外，我们引入了AD-PL，一个为工业异常推理量身定制的偏好优化数据集，包含28,415个带有专家排名响应的问答实例。为了评估异常推理模型，我们开发了多尺度逻辑评估（MLE），一个分析模型逻辑和一致性的定量框架。

**Result:** SAGE在零样本和单样本设置下，在工业异常数据集上表现出卓越的性能。

**Conclusion:** SAGE通过引入自引导事实增强和熵感知直接偏好优化，显著提升了视觉语言模型在工业异常检测和推理方面的能力，解决了现有模型在可解释性和泛化性上的挑战。

> **ai_Abstract:** SAGE是一个专为工业异常检测设计的视觉语言模型框架，旨在解决现有VLM在可解释性和泛化性上的不足。它通过自引导事实增强（SFE）整合领域知识，并利用熵感知直接偏好优化（E-DPO）对齐专家偏好。该研究还引入了用于偏好优化的AD-PL数据集和用于评估的多尺度逻辑评估（MLE）框架。实验结果表明，SAGE在工业异常数据集上表现优异。

> **摘要翻译:** 虽然视觉语言模型（VLMs）在通用多模态任务中取得了可喜的进展，但它们在工业异常检测和推理中常常面临困难，尤其是在提供可解释的解释和泛化到未见类别方面。这种局限性源于异常检测固有的领域特定性质，这阻碍了现有VLM在需要精确、结构化和上下文感知分析的工业场景中的适用性。为了解决这些挑战，我们提出了SAGE，一个基于VLM的框架，通过自引导事实增强（SFE）和熵感知直接偏好优化（E-DPO）来增强异常推理。SFE通过事实提取和融合将领域特定知识整合到视觉推理中，而E-DPO使用熵感知优化将模型输出与专家偏好对齐。此外，我们引入了AD-PL，一个为工业异常推理量身定制的偏好优化数据集，包含28,415个带有专家排名响应的问答实例。为了评估异常推理模型，我们开发了多尺度逻辑评估（MLE），一个分析模型逻辑和一致性的定量框架。SAGE在零样本和单样本设置下，在工业异常数据集上表现出卓越的性能。代码、模型和数据集可在https://github.com/amoreZgx1n/SAGE 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [430] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
> *深度学习在几何问题求解中的综述*

*Jianzhe Ma, Wenxuan Wang, Qin Jin* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 深度学习, 几何问题求解, 综述, 数学推理, 多模态大语言模型

**Comment:** Work in progress

> **TL;DR:** 这篇综述论文概述了深度学习在几何问题求解中的应用，包括任务、方法、评估和未来方向，旨在提供一个全面的参考。

**AI_Comments:** 这篇综述论文的重要性在于它整合了深度学习在几何问题求解这一复杂且日益重要的领域中的最新进展。它不仅系统地梳理了现有任务、方法和评估，还指出了未来的研究方向和挑战，为领域内的研究者提供了宝贵的路线图。其创建并维护GitHub论文列表的实践，也极大地增加了其作为实用参考的价值。

<details>
  <summary>Details</summary>

**Motivation:** 几何问题求解是数学推理的关键领域，广泛应用于教育、AI数学能力评估等。近年来深度学习，特别是多模态大语言模型的快速发展，引发了研究热潮。因此，需要一个关于深度学习在几何问题求解中应用的全面综述。

**Method:** 这篇论文通过以下方式对深度学习在几何问题求解中的应用进行了综述：(i) 全面总结了几何问题求解中的相关任务；(ii) 彻底回顾了相关的深度学习方法；(iii) 详细分析了评估指标和方法；(iv) 批判性讨论了当前的挑战和未来的发展方向。此外，还创建了一个持续更新的GitHub论文列表。

**Result:** 本文提供了一个关于深度学习在几何问题求解中的应用、方法、评估和未来方向的全面和实用的参考，旨在促进该领域进一步发展。

**Conclusion:** 本文旨在通过提供一个全面且实用的参考，来促进深度学习在几何问题求解领域中的进一步发展。

> **ai_Abstract:** 本文对深度学习在几何问题求解中的应用进行了全面综述。它涵盖了几何问题求解的相关任务、深度学习方法、评估指标与方法，并讨论了当前挑战和未来方向。该综述旨在为该领域的研究人员提供一个实用且持续更新的参考资源，以推动几何问题求解领域的发展。

> **摘要翻译:** 几何问题求解是数学推理的一个关键领域，广泛涉及教育、人工智能数学能力评估和多模态能力评估等许多重要领域。近年来，深度学习技术的快速发展，特别是多模态大语言模型的兴起，引发了广泛的研究热潮。本文对深度学习在几何问题求解中的应用进行了综述，包括（i）对几何问题求解中相关任务的全面总结；（ii）对相关深度学习方法的彻底回顾；（iii）对评估指标和方法的详细分析；以及（iv）对当前挑战和未来可探索方向的批判性讨论。我们的目标是为深度学习在几何问题求解领域提供一个全面且实用的参考，以促进该领域的进一步发展。我们还在GitHub上创建了一个持续更新的论文列表：https://github.com/majianz/dl4gps。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [435] [SpeLLM: Character-Level Multi-Head Decoding](https://arxiv.org/abs/2507.16323)
> *SpeLLM：字符级多头解码*

*Amit Ben-Artzy, Roy Schwartz* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** SpeLLM, 字符级解码, 多头解码, 词汇表扩展, LLM成本

**Comment:** 

> **TL;DR:** SpeLLM通过字符级多头解码，解耦输入输出词汇表，从而在不影响性能的情况下，有效解决了大规模词汇表带来的LLM输出层瓶颈，并降低了运行成本。

**AI_Comments:** SpeLLM的创新之处在于其通过字符级多头解码来解决LLM输出层扩展性问题，这为LLM的成本优化和多语言支持提供了一个独特且实用的视角。自蒸馏方法的引入也使得该方案具有较好的可落地性。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM架构中，输出投影层与词汇量大小呈线性关系，导致词汇量大幅扩展不切实际，限制了通过扩大词汇量来缩短输入序列长度和降低注意力二次成本的方法。

**Method:** SpeLLM通过多个输出头预测字符级字符串，解耦了输入和输出词汇表。它使用k个独立的线性头同时预测单个字符，从而利用更小的、独立的线性头表示更大的输出空间。论文还提出了一种将标准LLM转换为SpeLLM的自蒸馏方法。

**Result:** 在四种预训练LLM上的实验表明，SpeLLM变体在下游任务中取得了有竞争力的性能，并且平均运行时减少了5.1%。

**Conclusion:** SpeLLM为降低LLM成本，同时增加对代表性不足的语言和领域的支持提供了一个潜在途径。

> **ai_Abstract:** 该论文提出了SpeLLM，一种通过字符级多头解码来解决大型语言模型（LLM）词汇表扩展瓶颈的方法。SpeLLM解耦了输入和输出词汇表，通过多个独立的线性头同时预测字符，从而在不增加输出投影层复杂性的情况下支持更大的输出空间。通过自蒸馏方法将现有LLM转换为SpeLLM，实验证明其在保持竞争性能的同时，平均降低了5.1%的运行时，为降低LLM成本和支持更多语言提供了新途径。

> **摘要翻译:** 扩展LLM词汇表通常用于减少输入序列长度并缓解注意力的二次成本。然而，当前的LLM架构对这一过程施加了一个关键瓶颈：输出投影层与词汇量大小呈线性关系，使得大规模扩展变得不切实际。我们提出了SpeLLM，一种通过多个输出头预测字符级字符串来解耦输入和输出词汇表的方法。在SpeLLM中，k个线性头中的每一个同时预测一个单一字符，使得模型能够使用更小、独立的线性头来表示更大的输出空间。我们提出了一种将标准LLM转换为SpeLLM的自蒸馏方法。我们对四种预训练LLM的实验表明，它们的SpeLLM变体在下游任务上取得了有竞争力的性能，同时平均运行时减少了5.1%。我们的方法为降低LLM成本，同时增加对代表性不足的语言和领域的支持提供了一个潜在途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [448] [Banzhida: Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training](https://arxiv.org/abs/2507.09205)
> *Banzhida：通过精选数据和持续预训练推进藏语大型语言模型*

*Leiyu Pan, Bojian Xiong, Lei Yang, Renren Jin, Shaowei Zhang, Yue Chen, Ling Shi, Jiang Zhou, Junru Wu, Zhen Wang, Jianxiang Peng, Juesi Xiao, Tianyu Dong, Zhuowen Han, Zhuo Chen, Sangjee Dondrub, Caizang Tai, Haixing Zhao, Huaque Cairang, Suonan Cairang, Rou Te, Lengben Zhaxi, Gazang Zhaxi, Zhonglin Ye, Yuhui Zheng, Chunyan Peng, Secha Jia, Pema Tashi, Cizhen Jiacuo, Pema Dorjee, Hongkai Liu, Pema Yanggon, Tsehang Dorjee, Jiaxin Han, Qiongying Hu, Jilin Man, Huanke You, Yuqi Ren, Duo La, Deyi Xiong* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 藏语, 大型语言模型, 低资源语言, 数据整理, 预训练

**Comment:** paper modification

> **TL;DR:** Banzhida通过构建最大的藏语训练语料库并持续预训练多语言模型，显著提升了藏语大型语言模型的性能，超越了现有模型。

**AI_Comments:** 该论文的创新之处在于构建了迄今为止最大的藏语预训练语料库，并开发了专门的数据清洗和处理流程，有效解决了藏语作为低资源语言面临的数据稀缺问题。通过持续预训练多语言模型并创建新的高质量藏语基准测试，Banzhida模型在藏语能力上取得了显著提升，对推进藏语乃至其他低资源语言的生成式AI发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型中藏语代表性不足，主要原因是高质量训练语料稀缺。

**Method:** 作者通过聚合多样化来源的数据，并应用专门的藏语数据清洗和处理流程，构建了迄今为止最大的藏语预训练语料库。利用该语料库，对一个多语言基础模型进行持续的预训练和后训练，形成了Banzhida模型。同时，为了评估模型能力，创建了新的高质量藏语基准测试，并辅以现有公共基准测试。

**Result:** 实验结果表明，Banzhida在广泛的任务中，始终显著优于同等规模的开源模型和专门针对藏语的模型。

**Conclusion:** Banzhida通过其精选数据和持续预训练方法，成功推进了藏语的生成式人工智能发展。

> **ai_Abstract:** 该研究针对藏语作为低资源语言在现有大型语言模型中代表性不足的问题，构建了迄今最大的藏语预训练语料库，并在此基础上持续预训练了一个多语言基础模型，命名为Banzhida。为评估Banzhida的藏语能力，研究团队创建了新的高质量藏语基准测试。实验证明，Banzhida在多项任务上均显著优于其他同类模型，有效推动了藏语生成式人工智能的发展。

> **摘要翻译:** 大型语言模型在许多语言中取得了显著进展。然而，藏语作为一种典型的低资源语言，由于高质量训练语料的稀缺，在现有模型中代表性不足。为了解决这一差距，我们策划了迄今为止最大的藏语预训练语料库，聚合了来自不同来源的数据，并应用了专门为藏语量身定制的数据清洗和处理流程。利用精选数据，我们对一个多语言基础模型进行持续的预训练/后训练，使其成为Banzhida，一个推进藏语生成式人工智能的多语言大型语言模型。为了评估该模型的藏语能力，我们创建了新的高质量藏语基准测试，并辅以现有公共基准测试。实验结果表明，Banzhida在广泛的任务中，始终显著优于同等规模的开源模型和专门针对藏语的模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [471] [Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny](https://arxiv.org/abs/2507.16331)
> *Re:Form -- 通过LLM中的强化学习减少可扩展形式化软件验证中的人类先验：一项关于Dafny的初步研究*

*Chuanhao Yan, Fengdi Che, Xuhan Huang, Xu Xu, Xin Li, Yizhi Li, Xingwei Qu, Jingzhe Shi, Zhuangzhuang He, Chenghua Lin, Yaodong Yang, Binhang Yuan, Hang Zhao, Yu Qiao, Bowen Zhou, Jie Fu* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 形式化验证, 大型语言模型, 强化学习, Dafny, 人类先验

**Comment:** 

> **TL;DR:** 现有LLM在软件验证中因依赖人类先验而面临可靠性和可扩展性问题。本文探索利用形式化语言（Dafny）和强化学习来减少人类先验，即使是小型模型也能实现更好的验证性能。

**AI_Comments:** 该研究的创新之处在于利用形式化语言（Dafny）和强化学习来减少LLM驱动软件验证中对昂贵的人类先验的依赖。这种方法解决了当前LLM在生成可验证代码方面面临的可靠性和可扩展性等关键挑战。引入DafnyComp作为基准也对未来的研究具有重要价值。值得注意的是，小型模型能够超越专有模型的发现尤为突出。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于非正式语言的LLM在软件验证过程中既不可靠也不可扩展，难以生成可验证的程序。它们严重依赖耗时的人类标注先验，这对于复杂的编程任务来说是不可持续的。基于形式化语言的推理提供了一种有前景的替代方案，可以实现自动且数学上可证明的验证。

**Method:** 本文系统地探索了以Dafny作为主要环境来减少人类先验的方法。研究管道主要包括引入一个自动化且可扩展的数据整理管道，以及与形式化语言验证器反馈相结合的精心设计的强化学习（RL）方案。研究还引入了DafnyComp，一个用于规范推理的组合形式化程序基准。方法中采用了监督微调（SFT）和带有正则化的RL。

**Result:** 监督微调（SFT）使小型模型（例如0.5B）能够生成语法有效且可验证的Dafny代码，超越了专有模型。带有正则化的强化学习（RL）进一步提高了性能，实现了对域外任务更强的泛化能力，并在具有挑战性的DafnyComp基准上超越了所有强大的基线。

**Conclusion:** 通过利用形式化语言和先进的强化学习技术减少人类先验，即使是小型模型也能实现可扩展且可靠的形式化软件验证。这种方法为更鲁棒和泛化能力更强的基于LLM的程序生成和验证开辟了道路。

> **ai_Abstract:** 本文题为“Re:Form”，旨在探讨如何通过在形式化语言环境（如Dafny）中使用强化学习（RL）与大型语言模型（LLM）相结合，来减少可扩展形式化软件验证中对人类先验的依赖。研究解决了当前基于非正式语言的LLM在验证过程中存在的不可靠性和可扩展性问题。作者提出了一种方法，该方法涉及自动化数据整理和与形式化验证器反馈相结合的RL设计。他们还引入了DafnyComp，一个用于形式化程序的基准。实验结果表明，其方法（包括监督微调SFT和带正则化的RL）使小型LLM也能够生成可验证的Dafny代码，性能超越了大型专有模型，并在复杂任务上展示了强大的泛化能力。

> **摘要翻译:** 现有基于非正式语言（例如，人类语言）的、通过强化学习（RL）训练的大型语言模型（LLM）面临一个重大挑战：它们提供关键训练信号的验证过程既不可靠也不可扩展。事实上，目前流行的大型专有模型很难生成可验证的程序。一个有前景但很大程度上尚未探索的替代方案是基于形式化语言的推理。将LLM建立在严格的形式化系统之上，其中生成模型在形式化语言空间（例如，Dafny）中运行，能够对其推理过程和结果进行自动且数学上可证明的验证。这种能力对于实现大规模、可靠的形式化软件验证至关重要。通常的做法是采用人类标注的思维链和其他人类先验来诱导LLM的推理和编码能力。不幸的是，为监督复杂的编程任务提供此类先验变得不可接受地耗时。在这项工作中，我们系统地探索了如何利用形式化语言Dafny作为我们初步研究的主要环境来减少人类先验。我们的管道主要依赖于引入一个自动化和可扩展的数据整理管道，以及与形式化语言验证器反馈相结合的精心设计的RL。我们引入了DafnyComp，这是一个具有自动形式化规范的组合形式化程序基准，用于规范推理。我们的监督微调（SFT）阶段使即使是小型模型（例如，0.5B）也能够生成语法有效且可验证的Dafny代码，超越了专有模型。带有正则化的RL进一步提高了性能，实现了对域外任务更强的泛化能力，并在具有挑战性的DafnyComp基准上超越了所有强大的基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [478] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
> *Seed-X：构建强大的70亿参数多语言翻译大型语言模型*

*Shanbo Cheng, Yu Bao, Qian Cao, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Wenhao Zhu, Jingwen Chen, Zhichao Huang, Tao Li, Yifu Li, Huiying Lin, Sitong Liu, Ningxin Peng, Shuaijie She, Lu Xu, Nuo Xu, Sen Yang, Runsheng Yu, Yiming Yu, Liehao Zou, Hang Li, Lu Lu, Yuxuan Wang, Yonghui Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 多语言翻译, 大型语言模型, Seed-X, 思维链, 强化学习

**Comment:** 

> **TL;DR:** Seed-X是一个70亿参数的开源多语言翻译LLM，通过高质量数据集预训练和CoT/RL微调，在28种语言上性能媲美顶级闭源模型，并优于大型开源模型。

**AI_Comments:** Seed-X的创新在于以相对较小的70亿参数规模实现了与顶级闭源模型（如Gemini-2.5和GPT-4o）相媲美的多语言翻译性能，这对于开源社区和资源受限的研究者来说具有重要意义。其结合高质量数据集预训练、CoT微调和RL增强的方法为构建高效的多语言LLM提供了宝贵的经验。公开模型参数进一步促进了翻译研究的进展。

<details>
  <summary>Details</summary>

**Motivation:** 多语言翻译对于大型语言模型（LLMs）来说是一项具有挑战性的任务，因为它们难以处理复杂的语言模式和自动化翻译中出现的生硬翻译。

**Method:** 本文介绍了Seed-X，一个包含指令和推理模型的开源LLM家族。基础模型在涵盖28种语言的单语和双语内容的多样化、高质量数据集上进行预训练。指令模型通过思维链（CoT）推理进行微调以实现翻译，并通过强化学习（RL）进一步增强，以实现跨不同语言对的更好泛化。

**Result:** Seed-X在28种语言上的性能可与领先的闭源模型（包括Gemini-2.5和GPT-4o）相媲美。在自动指标和人工评估中，它显著优于更大的开源模型。研究团队还分享了优化过程中的最佳实践，并公开了模型参数。

**Conclusion:** Seed-X展示了在70亿参数规模下，通过高质量数据预训练和CoT/RL微调，可以构建出性能卓越的多语言翻译LLM，其表现足以与顶级闭源模型竞争，并超越更大的开源模型，为多语言翻译研究提供了新的开源基准和资源。

> **ai_Abstract:** 本文介绍了Seed-X，一个70亿参数的开源多语言翻译LLM家族，旨在解决现有LLM在多语言翻译中的挑战。Seed-X的基础模型在涵盖28种语言的单语和双语高质量数据集上进行预训练，其指令模型通过思维链（CoT）推理进行微调，并通过强化学习（RL）增强泛化能力。实验结果表明，Seed-X在28种语言上的性能可与Gemini-2.5和GPT-4o等领先闭源模型媲美，并显著超越了更大的开源模型。研究团队还分享了优化经验并公开了模型参数，以推动翻译研究。

> **摘要翻译:** 多语言翻译对于大型语言模型（LLMs）来说是一项具有挑战性的任务，因为它们需要处理复杂的语言模式和自动化翻译中出现的生硬翻译。在本文中，我们介绍了Seed-X，一个由指令模型和推理模型组成的开源LLM家族，以70亿参数的规模，突破了翻译能力的极限。基础模型在一个多样化、高质量的数据集上进行预训练，该数据集涵盖了28种语言的单语和双语内容，充分利用了多语言数据的潜力。指令模型随后通过思维链（CoT）推理进行微调以进行翻译，并通过强化学习（RL）进一步增强，以在不同的语言对之间实现更好的泛化。Seed-X在28种语言上的性能与领先的闭源模型（包括Gemini-2.5和GPT-4o）相当，并且在自动指标和人工评估方面显著优于更大的开源模型。我们通过优化过程分享了最佳实践，并公开了参数，以促进翻译研究和应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [505] [Dutch CrowS-Pairs: Adapting a Challenge Dataset for Measuring Social Biases in Language Models for Dutch](https://arxiv.org/abs/2507.16442)
> *荷兰语CrowS-Pairs：为衡量荷兰语语言模型中社会偏见而改编的挑战性数据集*

*Elza Strazda, Gerasimos Spanakis* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 语言模型偏见, CrowS-Pairs, 荷兰语, 社会偏见, 数据集

**Comment:** 10 pages, accepted at RANLP 2025 data and code here:
  https://github.com/jerryspan/Dutch-CrowS-Pairs

> **TL;DR:** 引入了荷兰语CrowS-Pairs数据集以衡量荷兰语语言模型中的社会偏见；发现不同语言的偏见程度不同，且人格设定会影响偏见。

**AI_Comments:** 本文的创新之处在于创建了首个专门针对荷兰语的偏见测量数据集Dutch CrowS-Pairs，并进行了跨语言的偏见比较。其重要性在于揭示了语言模型偏见的语言和文化依赖性，强调了在多语言环境中进行偏见评估的必要性。研究结果表明，简单的跨语言应用现有偏见数据集可能不足以全面捕捉所有偏见，且人格设定对偏见有影响，为未来缓解偏见提供了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型容易表现出偏见，进一步放大不公平和有害的刻板印象。鉴于这些模型的快速普及和广泛应用，有必要确保语言模型的安全和公平。尽管最近对衡量语言模型偏见给予了相当大的关注，但大多数研究只关注英语。

**Method:** 引入了美国特有的CrowS-Pairs数据集的荷兰语版本，用于衡量荷兰语语言模型中的偏见。该数据集包含1463对句子，涵盖9个类别的偏见。使用荷兰语CrowS-Pairs数据集，评估了各种荷兰语语言模型（BERTje, RobBERT, multilingual BERT, GEITje, Mistral-7B）的偏见。同时，也使用英语和法语版本的CrowS-Pairs数据集评估了英语和法语语言模型的偏见。

**Result:** 各种荷兰语语言模型（BERTje, RobBERT, multilingual BERT, GEITje, Mistral-7B）在不同偏见类别中表现出显著偏见。英语模型表现出最多的偏见，而荷兰语模型表现出最少的偏见。此外，结果还表明，为语言模型分配人格会改变其表现出的偏见水平。

**Conclusion:** 这些发现突出了偏见在不同语言和语境中的变异性，表明文化和语言因素在塑造模型偏见方面发挥着重要作用。

> **ai_Abstract:** 本文介绍了Dutch CrowS-Pairs数据集，这是一个为衡量荷兰语语言模型中社会偏见而改编的挑战性数据集。该数据集包含1463对涵盖9个偏见类别的对比句。研究使用该数据集评估了BERTje、RobBERT等荷兰语模型，发现它们存在显著偏见。跨语言比较显示英语模型偏见最多，荷兰语模型最少，且模型人格设定会影响偏见水平。研究强调偏见在不同语言和语境下的变异性，以及文化和语言因素对其影响。

> **摘要翻译:** 警告：本文包含可能令人不安的冒犯性刻板印象的明确陈述。
语言模型容易表现出偏见，进一步放大不公平和有害的刻板印象。鉴于这些模型的快速普及和广泛应用，有必要确保语言模型的安全和公平。尽管最近对衡量语言模型偏见给予了相当大的关注，但但大多数研究只关注英语。本文引入了美国特有的CrowS-Pairs数据集的荷兰语版本，用于衡量荷兰语语言模型中的偏见。由此产生的数据集包含1463对句子，涵盖9个类别的偏见，例如性取向、性别和残疾。这些句对由对比句组成，其中一句涉及弱势群体，另一句涉及优势群体。使用荷兰语CrowS-Pairs数据集，我们发现各种语言模型，如BERTje、RobBERT、多语言BERT、GEITje和Mistral-7B，在各种偏见类别中表现出显著偏见。使用英语和法语版本的CrowS-Pairs数据集，对英语（BERT和RoBERTa）和法语（FlauBERT和CamemBERT）语言模型中的偏见进行了评估，结果显示英语模型表现出最多的偏见，而荷兰语模型表现出最少的偏见。此外，结果还表明，为语言模型分配人格会改变其表现出的偏见水平。这些发现突出了偏见在不同语言和语境中的变异性，表明文化和语言因素在塑造模型偏见方面发挥着重要作用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [506] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
> *Promptomatix：一个大型语言模型自动提示优化框架*

*Rithesh Murthy, Ming Zhu, Liangwei Yang, Jielin Qiu, Juntao Tan, Shelby Heinecke, Caiming Xiong, Silvio Savarese, Huan Wang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 提示优化, 大型语言模型, 自动化框架, 提示工程, Promptomatix

**Comment:** 

> **TL;DR:** Promptomatix是一个自动提示优化框架，旨在通过自动化提示工程过程，将自然语言任务描述转化为高质量提示，从而提高大型语言模型的性能。

**AI_Comments:** Promptomatix的创新之处在于其自动化的提示优化流程，特别是通过结合元提示和DSPy，并引入成本感知优化，极大地降低了提示工程的门槛。其模块化设计也为未来的扩展提供了灵活性。这项工作对于提升大型语言模型在实际应用中的易用性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）需要精心设计的提示才能发挥最佳性能，然而，当前的提示工程是手动的、不一致的，且非专家难以使用。

**Method:** Promptomatix是一个自动提示优化框架，它将自然语言任务描述转化为高质量提示，无需手动调整或领域专业知识。它支持轻量级元提示优化器和基于DSPy的编译器，采用模块化设计。该系统分析用户意图，生成合成训练数据，选择提示策略，并使用成本感知目标优化提示。

**Result:** Promptomatix在5个任务类别中进行了评估，与现有库相比，它取得了具有竞争力甚至更优的性能，同时减少了提示长度和计算开销，使提示优化变得可扩展且高效。

**Conclusion:** Promptomatix成功地提供了一个自动化的提示优化解决方案，解决了手动提示工程的痛点，显著提升了大型语言模型提示的生成效率和质量。

> **ai_Abstract:** Promptomatix是一个创新的自动提示优化框架，旨在解决大型语言模型提示工程中手动、不一致和难以访问的问题。它能够将自然语言任务描述自动转换为高质量提示，无需人工干预或专业知识。该框架集成了元提示优化器和DSPy编译器，通过分析用户意图、生成合成数据、选择策略和成本感知优化来精炼提示。实验证明，Promptomatix在性能上优于或媲美现有方案，并显著降低了提示长度和计算成本，实现了高效且可扩展的提示优化。

> **摘要翻译:** 大型语言模型（LLMs）通过精心制作的提示表现最佳，然而，提示工程仍然是手动的、不一致的，且非专家难以接触。我们引入了Promptomatix，一个自动提示优化框架，它将自然语言任务描述转化为高质量提示，无需手动调整或领域专业知识。Promptomatix支持轻量级元提示优化器和基于DSPy的编译器，其模块化设计允许未来扩展到更高级的框架。该系统分析用户意图，生成合成训练数据，选择提示策略，并使用成本感知目标优化提示。在5个任务类别中进行评估，Promptomatix与现有库相比，取得了具有竞争力或更优的性能，同时减少了提示长度和计算开销，使提示优化变得可扩展且高效。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [513] [Typed-RAG: Type-Aware Decomposition of Non-Factoid Questions for Retrieval-Augmented Generation](https://arxiv.org/abs/2503.15879)
> *Typed-RAG：面向检索增强生成的非事实性问题类型感知分解*

*DongGeon Lee, Ahjeong Park, Hyeri Lee, Hyeonseo Nam, Yunho Maeng* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-22**

**Keywords:** 非事实性问答, 检索增强生成, 类型感知分解, 问题分解, Wiki-NFQA

**Comment:** Accepted to XLLM@ACL 2025

> **TL;DR:** Typed-RAG通过类型感知分解非事实性问题，显著提升了检索增强生成在非事实性问答中的表现。

**AI_Comments:** 该论文的创新点在于提出了类型感知分解（Type-Aware Decomposition）的概念，将复杂的非事实性问题分解为更易处理的子问题，有效提升了检索增强生成（RAG）在非事实性问答（NFQA）任务上的表现。此外，构建了一个新的基准数据集Wiki-NFQA，对于该领域的研究具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决非事实性问答（NFQA）的挑战，因为其开放性、多样用户意图和多方面推理需求，传统检索增强生成（RAG）方法存在局限。

**Method:** 提出Typed-RAG框架，它首先将非事实性问题（NFQ）分类为预定义类型（如辩论、经验、比较），然后将问题分解为聚焦于单一方面的子查询，最后结合子查询结果生成信息更丰富、上下文更一致的响应。同时构建了Wiki-NFQA基准数据集。

**Result:** 实验表明Typed-RAG始终优于现有基于大型语言模型（LLMs）或检索增强生成（RAG）的问答方法，验证了类型感知分解在提高NFQA检索质量和答案生成方面的有效性。

**Conclusion:** 类型感知分解对于提高非事实性问答中的检索质量和答案生成是有效的。

> **ai_Abstract:** 本文提出了Typed-RAG框架，旨在通过类型感知分解解决非事实性问答（NFQA）的挑战。该框架首先对非事实性问题进行类型分类，然后将其分解为多个聚焦子查询，以提高检索相关性和答案质量。实验结果表明，Typed-RAG在NFQA任务上显著优于现有的大语言模型和检索增强生成方法，证明了类型感知分解的有效性。同时，论文还构建了Wiki-NFQA基准数据集。

> **摘要翻译:** 解决非事实性问答（NFQA）仍然具有挑战性，因为其开放性、多样的用户意图以及对多方面推理的需求。这些特点常常暴露出传统检索增强生成（RAG）方法的局限性。为了克服这些挑战，我们提出了Typed-RAG，一个在RAG范式内对非事实性问题（NFQs）进行类型感知分解的框架。具体来说，Typed-RAG首先将一个NFQ分类为预定义类型（例如，辩论、经验、比较）。然后它将问题分解为聚焦的子查询，每个子查询都侧重于一个单一方面。这种分解增强了检索相关性和答案质量。通过结合这些子查询的结果，Typed-RAG能够产生更具信息量和上下文对齐的响应。此外，我们构建了Wiki-NFQA，一个涵盖广泛NFQ类型的NFQA基准数据集。实验表明，Typed-RAG始终优于现有基于大型语言模型（LLMs）或RAG方法的问答方法，验证了类型感知分解在提高NFQA检索质量和答案生成方面的有效性。我们的代码和数据集可在https://github.com/TeamNLP/Typed-RAG 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [525] [Step-Audio 2 Technical Report](https://arxiv.org/abs/2507.16632)
> *Step-Audio 2 技术报告*

*Boyong Wu, Chao Yan, Chen Hu, Cheng Yi, Chengli Feng, Fei Tian, Feiyu Shen, Gang Yu, Haoyang Zhang, Jingbei Li, Mingrui Chen, Peng Liu, Wang You, Xiangyu Tony Zhang, Xingyuan Li, Xuerui Yang, Yayue Deng, Yechang Huang, Yuxin Li, Yuxin Zhang, Zhao You, Brian Li, Changyi Wan, Hanpeng Hu, Jiangjie Zhen, Siyu Chen, Song Yuan, Xuelin Zhang, Yimin Jiang, Yu Zhou, Yuxiang Yang, Bingxin Li, Buyun Ma, Changhe Song, Dongqing Pang, Guoqiang Hu, Haiyang Sun, Kang An, Na Wang, Shuli Gao, Wei Ji, Wen Li, Wen Sun, Xuan Wen, Yong Ren, Yuankai Ma, Yufan Lu, Bin Wang, Bo Li, Changxin Miao, Che Liu, Chen Xu, Dapeng Shi, Dingyuan Hu, Donghang Wu, Enle Liu, Guanzhe Huang, Gulin Yan, Han Zhang, Hao Nie, Haonan Jia, Hongyu Zhou, Jianjian Sun, Jiaoren Wu, Jie Wu, Jie Yang, Jin Yang, Junzhe Lin, Kaixiang Li, Lei Yang, Liying Shi, Li Zhou, Longlong Gu, Ming Li, Mingliang Li, Mingxiao Li, Nan Wu, Qi Han, Qinyuan Tan, Shaoliang Pang, Shengjie Fan, Siqi Liu, Tiancheng Cao, Wanying Lu, Wenqing He, Wuxun Xie, Xu Zhao, Xueqi Li, Yanbo Yu, Yang Yang, Yi Liu, Yifan Lu, Yilei Wang, Yuanhao Ding, Yuanwei Liang, Yuanwei Lu, Yuchu Luo, Yuhe Yin, Yumeng Zhan, Yuxiang Zhang, Zidong Yang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Heung-Yeung Shum, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 多模态大语言模型, 音频理解, 语音对话, 检索增强生成, 强化学习

**Comment:** 

> **TL;DR:** Step-Audio 2 是一个端到端的多模态大型语言模型，通过集成潜在音频编码器、推理中心强化学习、离散音频令牌生成和检索增强生成，实现了工业级音频理解和语音对话，并在多项基准测试中达到了最先进的性能。

**AI_Comments:** Step-Audio 2 的创新点在于其作为端到端多模态大型语言模型的集成性，特别是将离散音频令牌生成融入语言建模以增强对副语言信息的响应，以及结合RAG和外部工具调用（如网络和音频搜索）来减轻幻觉并提高实用性。这使其在工业级应用中具有重要意义，尤其是在需要高度智能和表达力的对话场景中。其在数百万小时数据上的训练以及SOTA性能表明了其强大的能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现工业级的音频理解和语音对话，并增强对副语言信息（如说话风格和情感）的响应能力，同时有效利用真实世界数据中的文本和声学知识，并减轻幻觉现象，研究人员开发了Step-Audio 2。

**Method:** Step-Audio 2 是一个端到端的多模态大型语言模型。它集成了潜在音频编码器和推理中心强化学习。为了促进真正的端到端语音对话，它将离散音频令牌的生成融入语言建模。此外，它还集成了检索增强生成（RAG），并能够调用外部工具（如网络搜索和音频搜索）来缓解幻觉和切换音色。该模型在数百万小时的语音和音频数据上进行了训练。

**Result:** Step-Audio 2 在自动语音识别（ASR）和音频理解方面取得了有希望的性能。它在各种对话场景中展现了智能和表现力。与现有开源和商业解决方案相比，Step-Audio 2 在多项音频理解和对话基准测试中取得了最先进的性能。

**Conclusion:** Step-Audio 2 作为一种端到端的多模态大型语言模型，通过其创新的架构和训练方法，成功地在音频理解和语音对话方面实现了行业领先的性能，并有效解决了传统模型在处理副语言信息和幻觉方面的问题。

> **ai_Abstract:** Step-Audio 2 是一种端到端的多模态大型语言模型，旨在实现工业级音频理解和语音对话。它通过结合潜在音频编码器、推理中心强化学习、离散音频令牌生成以及检索增强生成（RAG）和外部工具调用能力来增强其功能。该模型在大量语音和音频数据上进行训练，在自动语音识别和音频理解方面表现出色，并在多项基准测试中达到了最先进的性能，同时提高了对副语言信息的响应能力并减少了幻觉。

> **摘要翻译:** 本文介绍了Step-Audio 2，这是一个端到端的多模态大型语言模型，专为工业级的音频理解和语音对话而设计。通过集成潜在音频编码器和以推理为中心的强化学习（RL），Step-Audio 2 在自动语音识别（ASR）和音频理解方面取得了有希望的性能。为了促进真正的端到端语音对话，Step-Audio 2 将离散音频令牌的生成整合到语言建模中，显著增强了其对说话风格和情感等副语言信息的响应能力。为了有效利用真实世界数据中丰富的文本和声学知识，Step-Audio 2 集成了检索增强生成（RAG），并能够调用外部工具，如网络搜索以减轻幻觉，以及音频搜索以切换音色。Step-Audio 2 在数百万小时的语音和音频数据上进行训练，在各种对话场景中提供了智能和表现力。评估结果表明，与其它开源和商业解决方案相比，Step-Audio 2 在各种音频理解和对话基准测试中取得了最先进的性能。请访问 https://github.com/stepfun-ai/Step-Audio2 获取更多信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [535] [GG-BBQ: German Gender Bias Benchmark for Question Answering](https://arxiv.org/abs/2507.16410)
> *GG-BBQ：德语问答性别偏见基准*

*Shalaka Satheesh, Katrin Klug, Katharina Beckh, Héctor Allende-Cid, Sebastian Houben, Teena Hassan* | **Category: cs.CL, cs.CY, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 性别偏见, 德语, 大型语言模型, 问答, 数据集

**Comment:** Accepted to the 6th Workshop on Gender Bias in Natural Language
  Processing (GeBNLP), taking place on August 1st 2025, as part of ACL 2025 in
  Vienna

> **TL;DR:** 该论文介绍了GG-BBQ，一个用于评估德语大型语言模型中性别偏见的基准数据集，发现所有评估的模型都存在偏见。

**AI_Comments:** 这项工作通过创建专门针对德语的性别偏见评估数据集，填补了现有研究的空白。其创新之处在于强调并实践了机器翻译后的人工校正，这对于处理具有复杂语法（如语法性别）的语言至关重要。这使得评估结果更加可靠，并为未来的多语言偏见研究提供了宝贵的经验。该数据集的创建对于推动德语NLP模型的公平性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在自然语言处理（NLP）中，公平性评估通常与偏见的评估和相关危害的减少相关。具体而言，需要一个基准数据集来衡量模型预测在包括性别认同在内的各个维度上的偏见。

**Method:** 作者基于Parrish等人（2022）的英语问答偏见基准，将其性别认同子集中的模板机器翻译成德语。然后，语言专家手动审查并纠正了机器翻译的错误，强调了手动修订对于创建性别偏见评估数据集的重要性，尤其是在从英语翻译到具有语法性别的德语时。最终数据集包含两个子集：Subset-I（包含与性别认同相关的群体术语）和Subset-II（群体术语被专有名词替换）。作者使用这个新创建的数据集评估了几种用于德语NLP的大型语言模型，并报告了准确性和偏见分数。

**Result:** 所有评估的模型都表现出偏见，既有符合现有社会刻板印象的偏见，也有对抗现有社会刻板印象的偏见。

**Conclusion:** 手动修订翻译对于创建性别偏见评估数据集至关重要，特别是对于像德语这样具有语法性别的语言。所有评估的德语大型语言模型都存在性别偏见。

> **ai_Abstract:** 本论文介绍了GG-BBQ，一个专为评估德语大型语言模型中性别偏见而设计的问答基准数据集。该数据集通过将现有英语数据集的模板机器翻译成德语并进行专家手动校正而构建，强调了在处理具有语法性别的语言时人工修订的重要性。研究人员使用GG-BBQ评估了多个德语LLM，发现所有模型都表现出性别偏见，包括符合和对抗社会刻板印象的偏见。

> **摘要翻译:** 在自然语言处理（NLP）的背景下，公平性评估通常与偏见的评估和相关危害的减少相关。在这方面，评估通常通过使用基准数据集进行，例如为衡量模型预测在包括性别认同在内的各个维度上的偏见而创建的问答任务。在我们的工作中，我们使用Parrish等人（2022）的问答偏见基准作为参考，评估德语大型语言模型（LLMs）中的性别偏见。具体来说，该英语数据集中性别认同子集中的模板被机器翻译成德语。然后，机器翻译模板中的错误在语言专家的帮助下进行了手动审查和纠正。我们发现，在创建性别偏见评估数据集时，手动修订翻译至关重要，因为从英语到像德语这样具有语法性别的语言的机器翻译存在局限性。我们的最终数据集包含两个子集：Subset-I，由与性别认同相关的群体术语组成；Subset-II，其中群体术语被专有名词替换。我们使用这个新创建的数据集评估了几种用于德语NLP的LLM，并报告了准确性和偏见分数。结果表明，所有模型都表现出偏见，既有符合现有社会刻板印象的偏见，也有对抗现有社会刻板印象的偏见。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [538] [X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display](https://arxiv.org/abs/2507.14430)
> *X-Intelligence 3.0：用于半导体显示领域的推理大语言模型训练与评估*

*Xiaolin Yan, Yangxing Liu, Jiazhang Zheng, Chi Liu, Mingyu Du, Caisheng Chen, Haoyang Liu, Ming Ding, Yuan Li, Qiuping Liao, Linfeng Li, Zhili Mei, Siyu Wan, Li Li, Ruyi Zhong, Jiangling Yu, Xule Liu, Huihui Hu, Jiameng Yue, Ruohui Cheng, Qi Yang, Liangqing Wu, Ke Zhu, Chi Zhang, Chufei Jing, Yifan Zhou, Yan Liang, Dongdong Li, Zhaohui Wang, Bin Zhao, Mingzhou Wu, Mingzhong Zhou, Peng Du, Zuomin Liao, Chao Dai, Pengfei Liang, Xiaoguang Zhu, Yu Zhang, Yu Gu, Kun Pan, Yuan Wu, Yanqing Guan, Shaojing Wu, Zikang Feng, Xianze Ma, Peishan Cheng, Wenjuan Jiang, Jing Ba, Huihao Yu, Zeping Hu, Yuan Xu, Zhiwei Liu, He Wang, Zhenguo Lin, Ming Liu, Yanhong Meng* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大语言模型, 半导体显示, 推理, 领域特定, 检索增强生成

**Comment:** Technical Report

> **TL;DR:** X-Intelligence 3.0是首个专为半导体显示行业开发的高性能推理大语言模型，通过领域特定训练和评估框架，以320亿参数的较小规模超越了现有最先进模型，解决了行业长期存在的推理挑战。

**AI_Comments:** 该论文的创新点在于首次为半导体显示行业开发了领域特定的高性能推理LLM。其重要性体现在通过较小参数规模的模型取得了超越大型SOTA模型的性能，展示了领域专业化训练的巨大潜力。自动化评估框架和RAG机制的引入也进一步提升了模型的实用性和效率。这为特定行业LLM的开发提供了新的范例。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在推理方面取得了显著进展，但在半导体显示行业中的有效性有限，原因是缺乏领域特定的训练和专业知识。本研究旨在弥补这一差距，为该行业的复杂挑战提供专家级的理解和推理能力。

**Method:** 开发了X-Intelligence 3.0模型，利用精心策划的行业知识库，进行监督微调和强化学习以增强推理和理解能力。实现了自动化评估框架来模拟专家级评估，并集成了领域特定的检索增强生成（RAG）机制。

**Result:** X-Intelligence 3.0尽管参数量相对较小（320亿），但在多项评估中超越了SOTA DeepSeek-R1-671B，并在基准数据集上取得了显著的性能提升。

**Conclusion:** X-Intelligence 3.0展示了其卓越的效率，并被确立为解决半导体显示行业长期推理挑战的强大解决方案。

> **ai_Abstract:** X-Intelligence 3.0是首个针对半导体显示行业设计的高性能推理大语言模型。该模型通过利用领域知识库进行监督微调和强化学习，并结合自动化评估框架和检索增强生成（RAG）机制进行开发。尽管规模较小（320亿参数），X-Intelligence 3.0在多项评估中表现优异，超越了更大的SOTA模型，有效解决了半导体显示领域的复杂推理问题。

> **摘要翻译:** 大型语言模型（LLM）最近在推理方面取得了显著进展，并在解决挑战性问题方面展现出优势。然而，由于缺乏领域特定训练和专业知识，它们在半导体显示行业中的有效性仍然有限。为了弥补这一差距，我们提出了X-Intelligence 3.0，这是首个专门为半导体显示行业开发的高性能推理模型。该模型旨在为行业复杂的挑战提供专家级的理解和推理。该模型利用精心策划的行业知识库，经过监督微调和强化学习，以增强其推理和理解能力。为了进一步加速开发，我们实施了一个自动化评估框架，模拟专家级评估。我们还集成了一个领域特定的检索增强生成（RAG）机制，在基准数据集上取得了显著的性能提升。尽管其参数规模相对紧凑（320亿），X-Intelligence 3.0在多项评估中超越了SOTA DeepSeek-R1-671B。这展示了其卓越的效率，并确立了其作为解决半导体显示行业长期推理挑战的强大解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [543] [Towards Enforcing Company Policy Adherence in Agentic Workflows](https://arxiv.org/abs/2507.16459)
> *迈向在代理工作流中强制执行公司政策合规性*

*Naama Zwerdling, David Boaz, Ella Rabinovich, Guy Uziel, David Amid, Ateret Anaby-Tavor* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** LLM代理, 政策合规, 代理工作流, 业务自动化, 守卫代码

**Comment:** 11 pages

> **TL;DR:** 本文提出一个确定性、透明和模块化的框架，用于在基于LLM的代理工作流中强制执行公司政策合规性，通过离线编译策略为可验证的守卫代码并在运行时集成以确保合规。

**AI_Comments:** 该论文创新性地提出了一个两阶段框架来解决LLM代理在复杂政策遵循上的痛点，其确定性、透明和模块化的设计具有较高的实用价值。通过将政策编译为可验证代码并在运行时强制执行，有效提升了LLM代理的可靠性和可信度，对于推动LLM在企业级应用中的落地具有重要意义。然而，论文也指出了实际部署中的挑战，这提示未来研究需要关注这些问题。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）代理在业务流程自动化方面具有潜力，但难以可靠地遵循复杂的公司政策，因此需要一个框架来强制执行政策合规性。

**Method:** 本方法分两个阶段：(1) 离线构建阶段，将策略文档编译成与工具使用相关的可验证守卫代码；(2) 运行时集成阶段，这些守卫在每个代理动作前确保合规性。

**Result:** 在具有挑战性的$\tau$-bench Airlines领域进行了演示，显示出令人鼓舞的初步政策执行结果。

**Conclusion:** 研究表明了在代理工作流中强制执行公司政策合规性的潜力，并提出了真实世界部署的关键挑战。

> **ai_Abstract:** 本研究提出了一种确定性、透明且模块化的框架，旨在解决大型语言模型（LLM）代理在遵循复杂公司政策方面的挑战。该框架包含两个阶段：离线构建时将政策编译为可验证的守卫代码，以及运行时集成这些守卫以在代理行动前强制执行合规性。研究在$\tau$-bench Airlines领域验证了该方法，取得了积极的初步成果，并指出了实际部署面临的挑战。

> **摘要翻译:** 大型语言模型（LLM）代理有望成为传统业务流程自动化的灵活且可扩展的替代方案，但难以可靠地遵循复杂的公司政策。在本研究中，我们引入了一个确定性、透明且模块化的框架，用于在代理工作流中强制执行业务政策合规性。我们的方法分两个阶段运行：(1) 一个离线构建时阶段，将策略文档编译成与工具使用相关的可验证守卫代码；(2) 一个运行时集成阶段，这些守卫在每个代理动作之前确保合规性。我们在具有挑战性的$\tau$-bench Airlines领域展示了我们的方法，显示出令人鼓舞的初步政策执行结果，并进一步概述了实际部署的关键挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [549] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
> *TREC 生物医学摘要通俗语言改编 (PLABA) 赛道的经验教训*

*Brian Ondov, William Xia, Kush Attal, Ishita Unde, Jerry He, Dina Demner-Fushman* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-21**

**Keywords:** 生物医学摘要, 通俗语言改编, 大型语言模型, TREC PLABA, 评估

**Comment:** 

> **TL;DR:** PLABA 赛道评估了大型语言模型将生物医学文献改编为通俗语言的潜力，发现它们在准确性方面表现良好，但在简洁性和自动评估方面仍有不足，并强调需要改进基准测试工具。

**AI_Comments:** 该论文通过举办PLABA赛道，对当前语言模型在生物医学通俗语言改编领域的应用进行了重要的实证评估。其创新之处在于提供了大规模、多团队参与的评估框架，并结合了严谨的人工判断，揭示了LLM在此类高风险应用中的优势与不足。重要性在于它为未来研究指明了方向，特别是在提升LLM的简洁性、解决自动评估指标与人工判断相关性差的问题以及开发更有效的基准测试工具方面。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于语言模型在将专业生物医学文献改编为通俗语言方面的潜力，以及该领域潜在的危害，需要进行严格评估以刺激研究并提供高质量的系统评估。

**Method:** 在2023年和2024年的文本检索会议上举办了生物医学摘要通俗语言改编 (PLABA) 赛道。任务包括完整的句子级摘要重写（任务1）以及识别和替换难懂术语（任务2）。任务1开发了四套专业编写的参考文本进行自动评估，任务1和任务2的提交均由生物医学专家进行了广泛的人工评估。

**Result:** 共有来自12个国家的12支团队参与。在任务1的人工评估中，表现最佳的模型在事实准确性和完整性方面与人类水平相当，但在简洁性方面不足。自动的、基于参考的指标与人工判断的相关性不佳。在任务2中，系统在识别难懂术语和分类替换方式方面表现不佳。然而，在生成替换时，基于LLM的系统在人工评估的准确性、完整性和简洁性方面表现良好，但在简洁性方面仍有不足。

**Conclusion:** PLABA 赛道展示了使用大型语言模型将生物医学文献改编为大众可理解文本的潜力，同时也揭示了它们的不足以及对改进自动基准测试工具的需求。

> **ai_Abstract:** TREC PLABA 赛道旨在评估语言模型将生物医学摘要改编为通俗语言的能力。通过两项任务（摘要重写和术语替换）并结合人工与自动评估，赛道发现尽管大型语言模型在准确性和完整性方面表现出色，但仍面临简洁性和自动评估指标有效性方面的挑战。研究强调了未来在通俗语言生成和评估工具方面改进的必要性。

> **摘要翻译:** 目标：语言模型的最新进展已显示出将面向专业人士的生物医学文献改编为通俗语言的潜力，使其可供患者和护理人员使用。然而，它们的不可预测性，加上该领域潜在的巨大危害，意味着严格的评估是必要的。我们举办此赛道的目的是刺激研究并为最有前途的系统提供高质量的评估。
方法：我们在2023年和2024年的文本检索会议上举办了生物医学摘要通俗语言改编 (PLABA) 赛道。任务包括完整的、句子级别的摘要重写（任务1）以及识别和替换难懂术语（任务2）。为了对任务1进行自动评估，我们开发了一套四部分的专业编写参考文本。任务1和任务2的提交都获得了生物医学专家的广泛人工评估。
结果：来自12个国家的12支团队参加了该赛道，模型从多层感知器到大型预训练Transformer。在任务1的人工判断中，表现最佳的模型在事实准确性和完整性方面与人类水平相当，但在简洁性或简短性方面不及。自动的、基于参考的指标通常与人工判断的相关性不佳。在任务2中，系统在识别难懂术语和分类如何替换它们方面遇到了困难。然而，在生成替换时，基于LLM的系统在人工判断的准确性、完整性和简洁性方面表现良好，尽管在简短性方面不及。
结论：PLABA 赛道展示了使用大型语言模型将生物医学文献改编为大众的潜力，同时也突出了它们的不足以及对改进自动基准测试工具的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [550] [Supernova: Achieving More with Less in Transformer Architectures](https://arxiv.org/abs/2507.15773)
> *Supernova：在Transformer架构中以更少的资源实现更多*

*Andrei-Valentin Tanase, Elena Pelican* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** Transformer, Supernova, 分词, 效率, 模型架构

**Comment:** 

> **TL;DR:** Supernova是一个6.5亿参数的Transformer模型，通过优化架构和分词创新，在参数和训练数据量更少的情况下，实现了与更大模型相当的性能。

**AI_Comments:** 该论文通过Supernova模型展示了在不大幅增加参数和训练数据的情况下，实现高性能Transformer模型的可能性。其创新点在于结合了多种高效的架构组件和定制的分词器。这项工作对于推动AI模型在资源受限环境下的应用具有重要意义，并对当前AI领域“越大越好”的趋势提出了挑战。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过精心的架构设计和分词创新，在保持计算效率的同时，实现与更大模型相当的性能，并挑战当前普遍存在的模型规模化范式。

**Method:** 本研究提出了Supernova，一个6.5亿参数的仅解码器Transformer模型。其架构结合了旋转位置嵌入（RoPE）、具有3:1压缩比的分组查询注意力（GQA）、用于计算效率的RMSNorm以及SwiGLU激活函数。一个关键创新是定制的128,000词汇量字节级BPE分词器。

**Result:** Supernova实现了10亿参数模型90%的性能，同时参数减少了35%，并且仅需1000亿训练Token，比竞争模型少一个数量级。

**Conclusion:** 本研究发现挑战了当前普遍存在的规模化范式，表明架构效率和分词质量可以弥补参数量的减少。

> **ai_Abstract:** Supernova是一个6.5亿参数的仅解码器Transformer模型，通过精心的架构设计（包括RoPE、GQA、RMSNorm和SwiGLU）和创新的12.8万词汇量字节级BPE分词器，实现了卓越的计算效率和压缩性能。研究表明，Supernova在参数减少35%且训练数据量减少一个数量级的情况下，能达到10亿参数模型90%的性能。这挑战了当前模型规模化的范式，证明了架构效率和分词质量可以弥补参数量的减少。

> **摘要翻译:** 我们提出了Supernova，一个6.5亿参数的仅解码器Transformer模型，它展示了精心的架构设计和分词创新如何在保持计算效率的同时，实现更大模型的性能。我们的架构结合了旋转位置嵌入（RoPE）、具有3:1压缩比的分组查询注意力（GQA）、用于计算效率的RMSNorm以及SwiGLU激活函数。一个关键创新是我们定制的128,000词汇量字节级BPE分词器，它实现了最先进的压缩性能。通过详细分析，我们表明Supernova实现了10亿参数模型90%的性能，同时参数减少了35%，并且仅需1000亿训练Token——比竞争模型少一个数量级。我们的发现挑战了当前普遍存在的规模化范式，表明架构效率和分词质量可以弥补参数量的减少。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [569] [Mangosteen: An Open Thai Corpus for Language Model Pretraining](https://arxiv.org/abs/2507.14664)
> *山竹：一个用于语言模型预训练的开放泰语语料库*

*Wannaphong Phatthiyaphaibun, Can Udomcharoenchaikit, Pakpoom Singkorapoom, Kunat Pipatanakul, Ekapol Chuangsuwanich, Peerat Limkonchotiwat, Sarana Nutanong* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 泰语语料库, 语言模型预训练, Mangosteen, Dolma管道, 数据清洗

**Comment:** Work in Progress. All artifacts in this papers:
  https://huggingface.co/collections/aisingapore/wangchanlion-v3-687a362d8f0ea2fe4077c6b3

> **TL;DR:** 引入了一个名为Mangosteen的470亿token泰语语料库，它通过泰语适应的Dolma管道构建，包含定制的语言ID、质量过滤器和内容过滤器，并结合了多种非网络来源。该语料库显著提高了GPT-2和SEA-LION模型在泰语基准上的性能，并提供了完整的可复现资源。

**AI_Comments:** 本文的创新之处在于其构建了一个高质量、大规模且完全可复现的泰语预训练语料库，弥补了现有泰语语料库在质量、透明度和可复现性方面的不足。其方法论，即通过泰语适应的Dolma管道进行数据清洗和整合多元数据源，对于其他低资源或特定语言的语料库构建具有重要的借鉴意义。通过发布所有代码和数据，极大地促进了未来泰语及区域性大型语言模型研究的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的预训练语料库主要以英语为中心或语言无关，其启发式方法无法捕捉泰语脚本或文化细微差别，导致如赌博内容等风险材料未被处理。之前的泰语特定工作很少发布数据或设计选择，阻碍了可复现性，因此需要构建一个透明、高质量的泰语语料库。

**Method:** 引入了Mangosteen，一个470亿token的泰语语料库，通过泰语适应的Dolma管道构建。该管道包括自定义的基于规则的语言ID、修订后的C4/Gopher质量过滤器和泰语训练的内容过滤器。此外，还整合了精选的非网络来源，如维基百科、皇家公报文本、OCR提取的书籍和CC许可的YouTube字幕。

**Result:** 系统性消融实验表明，使用GPT-2时，管道将CommonCrawl文档从2.02亿减少到2500万，同时将SEA-HELM NLG从3提高到11。一个在Mangosteen上持续预训练的80亿参数SEA-LION模型在泰语基准上比SEA-LION-v3和Llama-3.1高出约四个百分点。

**Conclusion:** Mangosteen语料库及其构建流程为未来的泰语和区域性大型语言模型研究提供了一个完全可复现的高质量基础。

> **ai_Abstract:** 本文介绍了Mangosteen，一个为语言模型预训练而设计的470亿token泰语语料库。该语料库通过一个泰语适应的Dolma管道构建，该管道整合了定制的语言ID、改进的质量过滤器和泰语训练的内容过滤器，并结合了多种高质量的非网络数据源。实验证明，Mangosteen显著提升了现有模型在泰语任务上的性能，并解决了现有泰语语料库透明度和质量不足的问题。作者还发布了所有构建资源，以确保研究的可复现性。

> **摘要翻译:** 预训练数据决定了语言模型的质量，但原始网络文本噪音大，需要仔细清洗。现有的大规模语料库依赖于以英语为中心或与语言无关的管道，其启发式方法无法捕捉泰语脚本或文化细微差别，导致诸如赌博内容等风险材料未被处理。之前的泰语特定工作很少定制管道或构建新管道，但很少发布其数据或设计选择，这阻碍了可复现性，并提出了如何构建一个透明、高质量的泰语语料库的问题。我们引入了Mangosteen：一个470亿token的泰语语料库，通过泰语适应的Dolma管道构建，该管道包括自定义的基于规则的语言ID、修订后的C4/Gopher质量过滤器和泰语训练的内容过滤器，此外还有精选的非网络来源，如维基百科、皇家公报文本、OCR提取的书籍和CC许可的YouTube字幕。使用GPT-2进行的系统性消融实验表明，该管道将CommonCrawl的文档数量从2.02亿减少到2500万，同时将SEA-HELM NLG从3提高到11；一个在Mangosteen上持续预训练的80亿参数SEA-LION模型在泰语基准上比SEA-LION-v3和Llama-3.1高出约四个百分点。我们发布了完整的管道代码、清洗清单、语料库快照和所有检查点，为未来的泰语和区域性LLM研究提供了完全可复现的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [570] [Introducing Quality Estimation to Machine Translation Post-editing Workflow: An Empirical Study on Its Usefulness](https://arxiv.org/abs/2507.16515)
> *将质量评估引入机器翻译译后编辑工作流程：一项关于其有用性的实证研究*

*Siqi Liu, Guangrong Dai, Dechao Li* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-22**

**Keywords:** 质量评估, 机器翻译译后编辑, 译后编辑速度, 经验研究, 翻译生产力

**Comment:** 11 pages, 5 figures, 2 tables. To be published in the Proceedings of
  the 20th Machine Translation Summit (MT Summit 2025; Geneva, Switzerland)

> **TL;DR:** 本研究实证考察了在英汉机器翻译译后编辑中引入句子级质量评估的有用性，发现其显著缩短了译后编辑时间，并对不同质量的机器翻译输出和不同专业水平的学生译员均有效，但准确性不足的质量评估可能阻碍编辑过程。

**AI_Comments:** 该研究通过实证方法验证了质量评估在机器翻译译后编辑中的实际效用，尤其是在提高效率方面。其创新之处在于不仅关注了效率提升，还深入探讨了QE与MT质量、译员专业知识的交互作用，并揭示了QE的多功能性。同时，也指出了QE准确性不足可能带来的局限性，为未来的QE技术发展和应用提供了明确的方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查句子级质量评估（QE）在英汉机器翻译译后编辑（MTPE）中的有用性，重点关注其对译后编辑速度和学生译员感知的影响，并探索QE与机器翻译质量以及QE与翻译专业知识之间的交互效应。

**Method:** 本研究是一项初步的实证研究，调查了句子级质量评估（QE）在英汉机器翻译译后编辑（MTPE）中的应用。研究方法包括分析QE对译后编辑时间的影响，并考察QE与MT质量以及QE与翻译专业知识之间的交互效应。研究数据来自访谈和实验结果。

**Result:** 研究结果显示，质量评估（QE）显著缩短了译后编辑时间。QE与机器翻译质量以及与翻译专业知识之间的交互效应不显著，表明QE能持续提高中高质量机器翻译输出和不同专业水平学生译员的MTPE效率。此外，QE除了指示潜在问题片段外，还在MTPE中具有多种功能，如验证译员对MT质量的评估和帮助他们复核翻译输出。然而，访谈数据显示不准确的QE可能会阻碍译后编辑过程。

**Conclusion:** 本研究提供了关于质量评估（QE）优势和局限性的新见解，有助于将其更有效地整合到机器翻译译后编辑（MTPE）工作流程中，以提高译员的生产力。QE能有效提高MTPE效率，但其准确性仍需关注。

> **ai_Abstract:** 本研究通过一项实证调查，探讨了句子级质量评估（QE）在英汉机器翻译译后编辑（MTPE）中的应用价值。研究发现，QE能显著缩短译后编辑时间，且其效率提升不受机器翻译质量或译员专业水平的影响。QE不仅能识别问题，还能帮助译员验证和复核翻译。尽管不准确的QE可能带来挑战，但本研究为QE在MTPE中的有效整合提供了宝贵见解，旨在提升译员的生产力。

> **摘要翻译:** 这项初步研究调查了句子级质量评估（QE）在英汉机器翻译译后编辑（MTPE）中的有用性，重点关注其对译后编辑速度和学生译员感知的影响。它还探讨了QE与机器翻译质量之间以及QE与翻译专业知识之间的交互效应。研究结果表明，QE显著缩短了译后编辑时间。所考察的交互效应不显著，这表明QE在中高质量机器翻译输出和不同专业水平的学生译员中都能持续提高MTPE效率。除了指示潜在问题片段外，QE在MTPE中还具有多种功能，例如验证译员对机器翻译质量的评估并使他们能够复核翻译输出。然而，访谈数据显示，不准确的QE可能会阻碍译后编辑过程。这项研究为QE的优势和局限性提供了新见解，有助于将其更有效地整合到MTPE工作流程中，以提高译员的生产力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [572] [Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models](https://arxiv.org/abs/2507.16642)
> *利用大型语言模型实现金融审计中自动化法规遵从性验证*

*Armin Berger, Lars Hillebrand, David Leonhard, Tobias Deußer, Thiago Bell Felix de Oliveira, Tim Dilmaghani, Mohamed Khaled, Bernd Kliem, Rüdiger Loitz, Christian Bauckhage, Rafet Sifa* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 金融审计, 法规遵从性, Llama-2, GPT

**Comment:** Accepted and published at BigData 2023, 10 pages, 3 figures, 5 tables

> **TL;DR:** 本文探讨了大型语言模型（LLMs）在金融审计中进行法规遵从性验证的效率。研究发现，开源的Llama-2 70B模型在检测违规方面表现出色，而专有模型如GPT-4在多种场景（尤其非英语语境）下表现最佳。

**AI_Comments:** 该论文通过实证研究，首次比较了开源与专有大型语言模型在金融审计法规遵从性验证这一特定且关键应用场景中的表现，具有创新性。其重要性在于指出了LLM在自动化审计流程中的巨大潜力，并为选择合适的模型提供了初步指导。局限性可能在于其依赖于定制数据集，且结论可能受限于特定审计标准和语言环境。

<details>
  <summary>Details</summary>

**Motivation:** 金融文件审计历来是劳动密集型过程，尽管AI解决方案已能推荐相关文本段落以符合法律要求，但这些系统在验证推荐摘录是否真正符合特定法律规定方面存在明显局限性。因此，本文旨在探究大型语言模型在此领域的效率。

**Method:** 研究通过比较不同模型配置下（特别是Llama-2等开源LLM与OpenAI GPT模型等专有LLM）公开可用的LLM在法规遵从性验证方面的效率。实验利用了普华永道（德国）提供的两个定制数据集。

**Result:** 研究发现，开源的Llama-2 700亿参数模型在检测不合规或真阴性事件方面表现出色，超越了所有专有模型。然而，在各种场景下，特别是非英语语境中，GPT-4等专有模型表现最佳。

**Conclusion:** 大型语言模型在金融审计的法规遵从性验证方面具有巨大潜力，开源模型在特定任务上可与专有模型竞争，但专有模型在更广泛的场景中表现出更强的普适性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在金融审计中自动化法规遵从性验证的能力，旨在解决现有AI系统无法有效验证合规性的问题。研究比较了Llama-2等开源LLM与GPT模型等专有LLM在普华永道提供的定制数据集上的性能。结果显示，Llama-2 70B在检测违规方面表现突出，而GPT-4在多场景（尤其是非英语环境）下总体表现最佳，揭示了LLM在提升审计效率方面的潜力。

> **摘要翻译:** 金融文件审计历来是一个劳动密集型过程，正处于转型前夕。人工智能驱动的解决方案已通过推荐金融报告中相关的文本段落以符合会计准则的法律要求，从而简化了这一过程。然而，一个明显的局限性依然存在：这些系统通常未能验证所推荐的摘录是否确实符合具体的法律规定。因此，在本文中，我们探讨了公开可用的大型语言模型（LLMs）在不同模型配置下在法规遵从性领域中的效率。我们特别强调比较尖端的开源LLM（如Llama-2）与OpenAI的GPT模型等专有对应产品。这种比较分析利用了我们合作伙伴普华永道（德国）提供的两个定制数据集。我们发现开源的Llama-2 700亿参数模型在检测不合规或真阴性事件方面表现出色，击败了所有专有对应产品。然而，像GPT-4这样的专有模型在各种场景中表现最佳，特别是在非英语语境下。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [579] [Learning Text Styles: A Study on Transfer, Attribution, and Verification](https://arxiv.org/abs/2507.16530)
> *学习文本风格：一项关于迁移、归因和验证的研究*

*Zhiqiang Hu* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 文本风格迁移, 作者归因, 作者验证, 大语言模型, 风格解耦

**Comment:** PhD thesis

> **TL;DR:** 本研究通过文本风格迁移、作者归因和作者验证三个方面，利用大语言模型的高效参数适应、对比解耦和指令微调，提升了对文本风格的计算理解和操控能力。

**AI_Comments:** 这项研究的创新之处在于其将文本风格的理解和操作分解为三个相互关联的核心任务，并系统性地应用了大型语言模型的最新技术，如参数高效适应和指令微调，以解决这些挑战。这为文本风格的计算分析和应用提供了全面的框架。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过解决文本风格迁移、作者归因和作者验证中的关键挑战，推动对文本风格的计算理解和操控能力。

**Method:** 该研究利用大语言模型（LLMs）的参数高效适应、风格特征的对比解耦以及用于可解释验证的指令微调。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究通过深入探讨文本风格迁移、作者归因和作者验证，旨在提升对文本风格的计算理解与操作能力。论文通过结合大语言模型的高效参数适应、风格特征的对比解耦以及基于指令的微调技术，有效应对了相关领域的核心挑战。

> **摘要翻译:** 本论文通过三个相互关联的支柱，推进了对文本风格的计算理解和操控：(1) 文本风格迁移（TST），即在保留内容的同时改变风格属性（例如，情感、正式度）；(2) 作者归因（AA），通过风格指纹识别文本的作者；以及 (3) 作者验证（AV），确定两篇文本是否共享同一作者。我们通过利用大语言模型（LLMs）的参数高效适应、风格特征的对比解耦以及用于可解释验证的指令微调，解决了这些领域的关键挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [583] [PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization](https://arxiv.org/abs/2507.16679)
> *PICACO：通过总相关性优化实现大型语言模型多元语境价值对齐*

*Han Jiang, Dongyao Zhu, Zhihua Wei, Xiaoyuan Yi, Ziang Xiao, Xing Xie* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-22**

**Keywords:** PICACO, 语境对齐, LLMs, 价值对齐, 总相关性

**Comment:** 

> **TL;DR:** PICACO提出了一种新颖的多元语境对齐方法，通过优化元指令和最大化总相关性，解决了现有语境对齐方法在处理多元价值观时的指令瓶颈问题，无需微调即可提高LLM的价值对齐效果。

**AI_Comments:** PICACO的创新之处在于其无需微调即可实现多元语境价值对齐，并通过优化元指令和最大化总相关性来解决“指令瓶颈”问题，这为LLM的价值对齐提供了一种高效且灵活的新范式。其在不进行模型微调的情况下，通过优化输入指令来提升LLM的复杂价值理解和对齐能力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）语境对齐（ICA）方法在处理多元化的人类价值观（如刺激与传统）时面临“指令瓶颈”挑战。LLMs对输入提示的理解是不可知的，这限制了ICA解决价值冲突的能力，导致不完整或有偏见的对齐。

**Method:** 本文提出了PICACO，一种新颖的多元语境对齐方法。PICACO无需微调，通过优化一个元指令来引导LLM理解和对齐多个价值观。这通过最大化指定价值观与LLM响应之间的总相关性来实现，理论上能增强价值相关性并减少干扰噪声，从而生成有效的价值指令。

**Result:** 在五个价值集上的大量实验表明，PICACO在黑盒和开源LLM上均表现良好，优于多个近期强大的基线方法，并在多达8个不同价值观之间实现了更好的平衡。

**Conclusion:** PICACO有效解决了现有语境对齐方法在处理多元价值观时的“指令瓶颈”问题，通过优化元指令和最大化总相关性，显著提高了LLM的价值对齐能力和平衡性。

> **ai_Abstract:** 本文提出PICACO，一种无需微调的多元语境对齐（ICA）方法，旨在解决大型语言模型（LLMs）在处理多元价值观时遇到的“指令瓶颈”问题。PICACO通过优化一个元指令，并最大化指定价值观与LLM响应之间的总相关性，以增强LLMs对多元价值观的理解和对齐。实验证明，PICACO在多种LLMs上表现优异，超越了现有基线，并在多个冲突价值观之间实现了更好的平衡。

> **摘要翻译:** 语境学习在使大型语言模型（LLMs）与人类价值观对齐方面显示出巨大潜力，有助于减少有害输出并适应多样化偏好，而无需昂贵的后期训练，这被称为语境对齐（ICA）。然而，LLMs对输入提示的理解仍然是不可知的，这限制了ICA解决价值冲突的能力——人类价值观本质上是多元化的，常常施加相互冲突的需求，例如，刺激与传统。因此，当前的ICA方法面临“指令瓶颈”挑战，LLMs难以在一个提示中协调多个预期价值观，导致不完整或有偏见的对齐。为了解决这个问题，我们提出了PICACO，一种新颖的多元ICA方法。PICACO无需微调，优化了一个元指令，该指令能引导LLMs更好地理解多个价值观并改进其对齐。这通过最大化指定价值观与LLM响应之间的总相关性来实现，理论上能增强价值相关性同时减少干扰噪声，从而产生有效的价值指令。在五个价值集上的大量实验表明，PICACO在黑盒和开源LLMs上均表现良好，优于多个近期强大的基线方法，并在多达8个不同价值观之间实现了更好的平衡。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [609] [Pixels to Principles: Probing Intuitive Physics Understanding in Multimodal Language Models](https://arxiv.org/abs/2507.16572)
> *像素到原理：探究多模态语言模型对直观物理的理解*

*Mohamad Ballout, Serwan Jassim, Elia Bruni* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 多模态大语言模型, 直观物理, 视觉-语言对齐, 模型评估, 嵌入分析

**Comment:** 

> **TL;DR:** 最新的多模态大语言模型在直观物理任务中表现不佳，主要原因是视觉编码器捕获的信息未能被语言模型有效利用，导致视觉-语言对齐问题。

**AI_Comments:** 这项研究通过深入的探针分析，超越了传统的性能指标，揭示了多模态大语言模型在直观物理理解方面的一个核心限制——视觉与语言信息整合的不足。其创新之处在于明确指出了问题并非出在视觉编码器，而是视觉信息未能有效传递给语言模型进行推理。这为未来多模态模型的设计和优化提供了重要的方向性指导，强调了视觉-语言对齐的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在系统评估当前最先进的多模态大语言模型（MLLMs）在直观物理任务上的表现，并深入探究其失败的根本原因，超越单纯的性能指标。

**Method:** 本文使用GRASP和IntPhys 2数据集对InternVL 2.5、Qwen 2.5 VL、LLaVA-OneVision和Gemini 2.0 Flash Thinking等最先进的多模态大语言模型进行了系统评估。此外，研究还对模型嵌入进行了探针分析，提取了关键处理阶段的中间表示，以检查任务相关信息的保留情况。

**Result:** 评估结果显示，即使是最新的多模态大语言模型也难以可靠地区分物理上合理和不合理的场景。探针分析表明，根据任务难度，可能会出现关键的视觉-语言不对齐：视觉编码器成功捕获了物理合理性线索，但这些信息未能被语言模型有效利用，导致推理失败。

**Conclusion:** 多模态大语言模型在直观物理任务中的主要限制不在于视觉组件本身，而是视觉和语言信息未能有效整合。因此，视觉-语言对齐是未来多模态大语言模型发展的关键改进领域。

> **ai_Abstract:** 本文系统评估了多种最先进的多模态大语言模型在直观物理任务上的表现，发现它们在区分物理合理性方面存在困难。通过对模型嵌入的探针分析，研究揭示了导致失败的关键原因在于视觉-语言对齐问题：尽管视觉编码器能捕捉到物理线索，但语言模型未能有效利用这些信息进行推理。这表明多模态模型的主要瓶颈在于视觉与语言信息的整合，而非视觉能力本身，并指出视觉-语言对齐是未来模型改进的关键方向。

> **摘要翻译:** 本文对最先进的多模态大语言模型（MLLMs）在直观物理任务上的表现进行了系统评估，使用了GRASP和IntPhys 2数据集。我们评估了开源模型InternVL 2.5、Qwen 2.5 VL、LLaVA-OneVision以及专有模型Gemini 2.0 Flash Thinking，发现即使是最新模型也难以可靠地区分物理上合理和不合理的场景。为了超越性能指标，我们对模型嵌入进行了探针分析，提取关键处理阶段的中间表示，以检查任务相关信息保留得如何。我们的结果表明，根据任务难度，可能会出现关键的视觉-语言不对齐：视觉编码器成功捕获了物理合理性线索，但这些信息未能被语言模型有效利用，导致推理失败。这种不对齐表明，MLLMs在直观物理任务中的主要限制不在于视觉组件，而是视觉和语言信息未能有效整合。我们的发现强调了视觉-语言对齐是需要改进的关键领域，为未来MLLMs的发展提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [616] [Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs](https://arxiv.org/abs/2507.16663)
> *“自我矛盾”作为“自我提升”：弥合多模态大语言模型中的生成-理解鸿沟*

*Yujin Han, Hao Chen, Andi Han, Zhiheng Wang, Xinyu Lin, Yingya Zhang, Shiwei Zhang, Difan Zou* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 多模态大语言模型, 自我矛盾, 生成-理解鸿沟, 自我提升, 后训练

**Comment:** 19 pages, 9 figures, 3 tables

> **TL;DR:** MLLMs在生成和理解之间存在自我矛盾，本文提出利用模型自身的理解能力指导生成，并通过后训练方法和课程学习策略，成功弥合了生成-理解鸿沟并实现了生成和理解能力的共同提升。

**AI_Comments:** 这篇论文的创新点在于首次明确提出了MLLMs中生成与理解之间的“自我矛盾”问题，并将其转化为一种“自我提升”的机制。通过利用模型自身更强的理解能力来指导生成，提供了一种新颖的内部监督范式。发现仅微调生成分支即可实现生成和理解的共同提升，以及揭示在劣质监督下可能出现共同退化，这些都是对MLLMs后训练过程的重要见解。论文不仅提出了问题和解决方案，还进行了理论分析和实证验证，并提出了实用的课程学习策略，对未来MLLMs的优化具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）致力于统一生成和理解任务，但它们表现出“自我矛盾”，即生成的图像与模型自身理解的输入提示不符。这种生成与理解之间的能力不对称促使研究者探索如何利用这种“自我矛盾”来实现模型自我提升。

**Method:** 1. 定义了一个“非统一分数（Nonunified score）”来量化这种自我矛盾。2. 利用模型更强的理解能力来指导较弱的生成，以弥合生成-理解鸿沟。3. 应用标准后训练方法（如SFT、DPO）并结合这种内部监督机制。4. 提出了一种基于发现的课程学习策略，逐步引入更难的样本以提升模型。

**Result:** 1. 自我矛盾主要源于弱生成未能与提示对齐，而非理解不足。2. 通过内部监督的后训练方法成功提升了生成和统一性。3. 仅微调生成分支即可发现生成和理解的共同提升效应。4. 改进源于更好地检测出之前被错误识别为与提示对齐的假阳性。5. 理论上，生成和理解之间对齐的训练动态使得减少提示未对齐的生成也能改善理解分支中的不匹配检测。6. 框架揭示了在糟糕监督下可能出现共同退化的风险，并得到实证验证。7. 内在指标如Nonunified分数无法区分共同退化和共同提升，强调了数据质量检查的必要性。8. 所提出的课程学习策略能够带来更好的统一性以及改进的MLLM生成和理解能力。

**Conclusion:** MLLMs中生成与理解之间的自我矛盾可以通过利用模型自身的理解能力进行内部监督的后训练方法有效缓解，从而实现生成和理解的共同提升。需要注意劣质监督可能导致共同退化，且内在指标不足以区分好坏，数据质量至关重要。

> **ai_Abstract:** 本文揭示了多模态大语言模型（MLLMs）在生成和理解任务中存在的“自我矛盾”现象，即模型生成的内容可能与其自身的理解不一致。研究通过定义“非统一分数”量化了这种矛盾，并发现其主要源于弱生成而非理解不足。作者提出利用模型更强的理解能力作为内部监督，通过标准后训练方法（如SFT、DPO）指导生成，成功弥合了生成-理解鸿沟。论文还发现仅微调生成分支即可实现生成和理解的共同提升效应，并从理论上解释了其机制。此外，研究强调了劣质监督可能导致共同退化，并指出内在指标不足以区分模型的进步或退步，凸显了数据质量检查的重要性。最终，提出了一种课程学习策略，以进一步提升MLLM的统一性、生成和理解能力。

> **摘要翻译:** 尽管致力于在单一模型中统一多模态生成和理解任务，我们发现这些多模态大语言模型（MLLMs）表现出自我矛盾，即根据模型自身的理解，其生成的图像被认为与输入提示不符。我们定义了一个非统一分数（Nonunified score）来量化这种自我矛盾。我们的实证结果表明，这种自我矛盾主要源于未能与提示对齐的弱生成，而非理解不足。这种能力不对称表明了利用自我矛盾进行自我提升的潜力，即通过模型更强的理解能力来指导较弱的生成，以弥合生成-理解鸿沟。应用标准后训练方法（例如SFT、DPO）并结合这种内部监督成功地改善了生成和统一性。我们发现，仅对生成分支进行微调时，生成和理解都会出现共同提升效应，这是一种在预训练中已知但在后训练中未被充分探索的现象。我们的分析表明，改进源于更好地检测出之前被错误识别为与提示对齐的假阳性。理论上，我们展示了生成和理解之间对齐的训练动态允许减少提示未对齐的生成，从而也改善了理解分支中的不匹配检测。此外，该框架揭示了在糟糕监督下共同退化的潜在风险——这是一个被忽视的现象，并在我们的实验中得到了经验验证。值得注意的是，我们发现像非统一分数这样的内在指标无法区分共同退化和共同提升，这凸显了数据质量检查的必要性。最后，我们根据我们的发现提出了一种基于课程的策略，即随着模型的改进逐渐引入更难的样本，从而带来更好的统一性以及改进的MLLM生成和理解能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [635] [Adaptive Graph Pruning for Multi-Agent Communication](https://arxiv.org/abs/2506.02951)
> *多智能体通信的自适应图剪枝*

*Boyi Li, Zhonghan Zhao, Der-Horng Lee, Gaoang Wang* | **Category: cs.CL, cs.MA** | **Updated: 2025-07-22**

**Keywords:** 多智能体系统, 图剪枝, 协作通信, LLM, 任务自适应

**Comment:** ECAI 2025

> **TL;DR:** 本文提出了一种名为自适应图剪枝（AGP）的新型框架，用于动态优化基于LLM的多智能体系统中智能体数量和通信拓扑，以适应不同任务复杂性并提高性能和效率。

**AI_Comments:** AGP的创新之处在于其动态优化智能体数量和通信拓扑的联合剪枝机制，解决了传统多智能体系统缺乏灵活性的问题。其两阶段训练策略设计巧妙，能够根据任务需求自适应调整系统配置，显著提升了LLM多智能体系统在性能和效率上的表现。尤其在资源受限的环境下，其Token经济性和训练效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于LLM的多智能体系统在协作通信方面表现出色，但其依赖固定数量的智能体和静态通信结构，限制了它们适应不同任务复杂性的能力。

**Method:** 本文提出自适应图剪枝（AGP），一个新颖的任务自适应多智能体协作框架，联合优化智能体数量（硬剪枝）和通信拓扑（软剪枝）。具体而言，该方法采用两阶段训练策略：首先，独立训练不同智能体数量的软剪枝网络，以确定特定任务下最优的智能体数量特定完整图和位置掩码；然后，在最大完整图中联合优化硬剪枝和软剪枝，以动态配置每个任务的智能体数量及其通信拓扑。

**Result:** 实验证明，AGP方法：(1) 性能卓越，在六个基准测试中达到了最先进的结果，并在多个主流LLM架构上持续泛化，性能提升2.58%~9.84%；(2) 任务自适应，动态构建针对特定任务优化的通信拓扑，在所有三种任务类别（通用推理、数学推理和代码生成）中表现极高；(3) 节省Token，训练步骤和Token消耗更少，Token消耗减少90%以上；(4) 训练高效，与其他方法相比，在极少训练步骤下即可达到高性能，在六个基准测试中，约十步训练后性能即可超越现有基线。

**Conclusion:** AGP通过动态调整智能体数量和通信结构，显著提升了LLM多智能体系统的性能、任务适应性、Token效率和训练效率，解决了现有方法在适应任务复杂性方面的局限性。

> **ai_Abstract:** 本文提出了一种名为自适应图剪枝（AGP）的新型任务自适应多智能体协作框架，旨在解决现有LLM多智能体系统在固定智能体数量和静态通信结构方面的局限性。AGP通过两阶段训练策略，联合优化智能体数量（硬剪枝）和通信拓扑（软剪枝），从而动态适应不同任务的复杂性。实验结果表明，AGP在多个基准测试中实现了SOTA性能，提高了任务适应性，显著降低了Token消耗（90%以上），并提高了训练效率。

> **摘要翻译:** 大型语言模型（LLM）驱动的多智能体系统在各种任务中展现出卓越性能，尤其是在通过协作通信增强后。然而，当前方法通常依赖固定数量的智能体和静态通信结构，这限制了它们适应不同任务复杂性的能力。在本文中，我们提出了自适应图剪枝（AGP），一种新颖的任务自适应多智能体协作框架，该框架联合优化智能体数量（硬剪枝）和通信拓扑（软剪枝）。具体而言，我们的方法采用两阶段训练策略：首先，独立训练针对不同智能体数量的软剪枝网络，以确定特定任务下最优的智能体数量特定完整图和位置掩码；然后，在最大完整图中联合优化硬剪枝和软剪枝，以动态配置每个任务的智能体数量及其通信拓扑。大量的实验表明，我们的方法具有以下特点：(1) 高性能，在六个基准测试中取得了最先进的结果，并在多个主流LLM架构上持续泛化，性能提升2.58%~9.84%；(2) 任务自适应，动态构建针对特定任务优化的通信拓扑，在所有三种任务类别（通用推理、数学推理和代码生成）中表现出极高的性能；(3) 节省Token，同时拥有更少的训练步骤和Token消耗，Token消耗减少90%以上；(4) 训练高效，与其他方法相比，以极少的训练步骤即可实现高性能。在六个基准测试中，大约十步训练后，性能将超越现有基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [636] [Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study](https://arxiv.org/abs/2502.02451)
> *超越英语：以中文案例研究评估非英语语篇中道德基础的自动化测量*

*Calvin Yixiang Cheng, Scott A Hale* | **Category: cs.CL, cs.SI** | **Updated: 2025-07-22**

**Keywords:** 道德基础, 跨语言, 大型语言模型, 中文, 自动化测量

**Comment:** 12 pages, 2 figures, 6 tables

> **TL;DR:** 本研究评估了在非英语语篇中自动化测量道德基础的方法，发现机器翻译和本地词典方法不足，而多语言模型和大型语言模型（LLMs）表现可靠，LLMs在数据效率方面表现出色，但仍需人工验证以捕捉文化细微差别。

**AI_Comments:** 该研究创新性地探讨了在非英语语境下进行道德基础测量的挑战与机遇，特别是在多语言模型和LLMs的应用方面。其重要性在于为跨文化计算社会科学研究提供了新的工具和见解。强调人工验证的必要性也体现了对模型局限性的深刻理解。

<details>
  <summary>Details</summary>

**Motivation:** 由于大多数资源主要为英语开发，道德基础理论的跨语言应用仍然有限，因此需要探索在非英语语料库中测量道德基础的计算方法。

**Method:** 本研究以中文为案例，评估了将英语资源应用于机器翻译文本、本地语言词典、多语言语言模型和大型语言模型（LLMs）在测量非英语文本中道德基础方面的有效性。

**Result:** 结果表明，机器翻译和本地词典方法不足以进行复杂的道德评估，常导致文化信息大量丢失。相比之下，多语言模型和LLMs通过迁移学习展现出可靠的跨语言性能，其中LLMs在数据效率方面表现突出。

**Conclusion:** 本研究强调了LLMs在跨语言道德基础测量和其他复杂多语言演绎编码任务中的潜力，同时也指出自动化道德基础评估需要人工验证，因为最先进的模型可能会在跨语言测量中忽略文化细微差别。

> **ai_Abstract:** 本研究探讨了在非英语语料库中计算测量道德基础的方法，并以中文为例，评估了不同方法（机器翻译、本地词典、多语言模型、LLMs）的有效性。研究发现，机器翻译和本地词典方法不足，而多语言模型和LLMs表现良好，其中LLMs在数据效率上更优。研究同时强调了人工验证在跨语言道德评估中的重要性，以捕捉文化细微差别。

> **摘要翻译:** 本研究探索了在非英语语料库中测量道德基础（MFs）的计算方法。由于大多数资源主要为英语开发，道德基础理论的跨语言应用仍然有限。本论文以中文为案例研究，评估了将英语资源应用于机器翻译文本、本地语言词典、多语言语言模型和大型语言模型（LLMs）在测量非英语文本中MFs的有效性。结果表明，机器翻译和本地词典方法不足以进行复杂的道德评估，常导致文化信息大量丢失。相比之下，多语言模型和LLMs通过迁移学习展现出可靠的跨语言性能，其中LLMs在数据效率方面表现突出。重要的是，本研究还强调了自动化MF评估需要人工验证，因为最先进的模型可能会在跨语言测量中忽略文化细微差别。研究结果凸显了LLMs在跨语言MF测量和其他复杂多语言演绎编码任务中的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [645] [P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs](https://arxiv.org/abs/2507.16656)
> *P-CoT：一种基于教学启发式参与式思维链提示，用于LLMs的音韵推理*

*Dongjun Jang, Youngchae Ahn, Hyopil Shin* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** P-CoT, LLM, 音韵推理, 思维链, 提示工程

**Comment:** 

> **TL;DR:** 本研究引入了一种名为P-CoT的新型提示方法，该方法基于教学理论，显著提升了大型语言模型（LLMs）在音韵推理任务上的表现，最高提升52%，甚至在某些任务上超越了人类基线。

**AI_Comments:** 这篇论文的创新点在于提出了P-CoT这种新颖的提示方法，它将教育理论（如支架式学习和发现式学习）融入到LLM的提示设计中，为提升LLM特定领域（如音韵推理）的能力提供了新的思路。其重要性在于证明了通过精心设计的提示，可以有效激活和增强LLM的潜在能力，甚至在某些任务上超越人类表现，这对于LLM的应用和发展具有重要意义。该方法也为未来在其他复杂推理任务中利用教学原理设计提示提供了借鉴。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索文本型大型语言模型（LLMs）在音韵推理方面的潜力，并评估其在韵律词生成、g2p转换和音节计数等任务上的表现。

**Method:** 研究利用PhonologyBench基准测试，评估了12个LLMs在音韵推理任务上的表现。研究引入了一种新颖的、基于支架式学习和发现式学习等教育理论的“教学启发式参与式思维链（P-CoT）”提示方法，通过结构化指导来激活LLMs潜在的音韵能力。

**Result:** 评估结果显示，尽管少量样本学习（few-shot learning）的提升不一致，但P-CoT提示方法能持续提升LLMs的性能，最高可达52%的改进，并且在某些任务上甚至超越了人类基线。

**Conclusion:** P-CoT提示方法，作为一种基于教学理论的结构化指导，能够显著且持续地增强大型语言模型在音韵推理任务上的能力，使其在某些方面甚至超越人类表现。

> **ai_Abstract:** 本研究探索了大型语言模型（LLMs）的音韵推理能力，并使用PhonologyBench基准测试了韵律词生成、g2p转换和音节计数等任务。研究发现，传统的少量样本学习效果不稳定，而新提出的、受教育理论启发的“教学启发式参与式思维链（P-CoT）”提示方法，通过提供结构化指导，能够持续显著提升12个LLMs的音韵推理性能，最高提升52%，并在部分任务上超越人类基线。

> **摘要翻译:** 本研究探讨了文本型大型语言模型（LLMs）在音韵推理方面的潜力。我们利用PhonologyBench基准测试，评估了韵律词生成、g2p转换和音节计数等任务。我们对12个LLMs的评估显示，虽然少量样本学习（few-shot learning）提供的增益不一致，但引入一种新颖的、基于支架式学习和发现式学习等教育理论的“教学启发式参与式思维链（P-CoT）”提示方法，能持续提升性能。该方法利用结构化指导来激活潜在的音韵能力，实现了高达52%的改进，甚至在某些任务中超越了人类基线。未来的工作可以旨在优化P-CoT提示以适应特定模型，或探索其在不同语言领域的应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [649] [eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs](https://arxiv.org/abs/2507.15863)
> *eSapiens的DEREK模块：基于LLM的深度知识抽取与推理引擎*

*Isaac Shi, Zeyuan Li, Fan Liu, Wenli Wang, Lewei He, Yang Yang, Tianyu Shi* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-13**

**Keywords:** DEREK模块, 检索增强生成, LLMs, 企业问答, 文档问答, 安全性

**Comment:** 8 pages;1 figure;5 tables

> **TL;DR:** DEREK模块是一个为企业文档问答设计的安全、可扩展的检索增强生成（RAG）管道，它整合了多种技术（如GPT-4o、Cohere、LangGraph），在法律数据集上表现出高准确性和可追溯性，适用于高风险领域。

**AI_Comments:** DEREK模块的创新之处在于其针对企业级应用场景的全面设计，特别强调了安全性（TLS 1.3, AES-256）、可审计性（LangGraph verifier确保引用）和生产就绪性。它整合了多种先进的LLM和检索技术，形成了一个鲁棒的RAG管道。在法律领域的具体性能提升数据，如Recall@50和Precision@10的改善，以及TRACe利用率的提高，都证明了其在实际应用中的有效性。该系统为高风险领域提供了可靠的解决方案，其模块化和容器化的设计也利于部署和扩展。

<details>
  <summary>Details</summary>

**Motivation:** 该模块专为企业文档问答设计，旨在满足企业对安全、可审计和上下文忠实的检索需求，提供一个针对法律和金融等高风险领域的可靠基线。

**Method:** DEREK模块是一个安全的、可扩展的检索增强生成（RAG）管道。它能够摄取异构内容（PDF、Office、web），将其分割成1000个token的重叠块，并索引到混合HNSW+BM25存储中。用户查询通过GPT-4o进行优化，通过向量+BM25组合搜索进行检索，使用Cohere进行重新排序，并由LLM使用CO-STAR提示工程回答。一个LangGraph验证器强制执行引用重叠，并重新生成答案直到每个声明都有依据。所有组件都在容器中运行，并强制执行端到端TLS 1.3和AES-256。

**Result:** 在四个LegalBench子集上，1000-token的块将Recall@50提高了大约1个百分点，混合+重排将Precision@10提高了大约7个百分点；验证器将TRACe利用率提高到0.50以上，并将未经支持的陈述限制在3%以下。

**Conclusion:** DEREK模块提供了准确、可追溯且可用于生产的文档问答系统，且操作开销极小。该模块旨在满足企业对安全、可审计和上下文忠实检索的需求，为法律和金融等高风险领域提供了可靠的基线。

> **ai_Abstract:** eSapiens开发的DEREK模块是一个专为企业级文档问答设计的安全、可扩展的检索增强生成（RAG）系统。它能够处理多种格式的企业文档，通过高级索引、结合LLM（如GPT-4o和Cohere）进行查询优化、检索和重排，并使用LangGraph验证器确保答案的准确性和可追溯性。实验结果表明，该模块在法律数据集上显著提升了检索精度和召回率，并有效限制了不实陈述。DEREK模块强调安全性和可审计性，适用于法律和金融等高风险领域的生产环境。

> **摘要翻译:** 我们介绍了DEREK（深度知识抽取与推理引擎）模块，这是一个专为企业文档问答设计的安全、可扩展的检索增强生成（RAG）管道。由eSapiens设计和实现，该系统摄取异构内容（PDF、Office、web），将其分割成1000个token的重叠块，并将其索引到混合HNSW+BM25存储中。用户查询由GPT-4o优化，通过组合向量+BM25搜索检索，使用Cohere重新排序，并由LLM使用CO-STAR提示工程回答。一个LangGraph验证器强制执行引用重叠，重新生成答案直到每个声明都有依据。在四个LegalBench子集上，1000-token的块将Recall@50提高了大约1个百分点，混合+重排将Precision@10提高了大约7个百分点；验证器将TRACe利用率提高到0.50以上，并将未经支持的陈述限制在3%以下。所有组件都在容器中运行，强制执行端到端TLS 1.3和AES-256。这些结果表明，DEREK模块以最小的操作开销提供了准确、可追溯且可用于生产的文档问答。该模块旨在满足企业对安全、可审计和上下文忠实检索的需求，为法律和金融等高风险领域提供了可靠的基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [662] [Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM](https://arxiv.org/abs/2507.16695)
> *使用行随机DEDICOM的可解释主题提取和词嵌入学习*

*Lars Hillebrand, David Biesner, Christian Bauckhage, Rafet Sifa* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** DEDICOM, 主题提取, 词嵌入, 可解释性, 矩阵分解

**Comment:** Accepted and published at CD-MAKE 2020, 20 pages, 8 tables, 8 figures

> **TL;DR:** 本文提出了一种使用行随机DEDICOM算法处理文本语料库的点互信息矩阵的方法，以同时进行可解释的主题提取和词嵌入学习。

**AI_Comments:** 本文的创新点在于将行随机DEDICOM算法应用于文本分析，以实现可解释的主题提取和词嵌入。通过利用DEDICOM固有的可解释性，该方法有望在理解模型输出方面提供比传统方法更清晰的洞察。其重要性在于为自然语言处理领域提供了一种新的可解释模型。

<details>
  <summary>Details</summary>

**Motivation:** DEDICOM算法提供了一种独特的可解释矩阵分解方法。本文旨在利用其新的行随机变体，对文本语料库进行主题提取并学习可解释的词嵌入。

**Method:** 作者在文本语料库的点互信息矩阵上应用了一种新的行随机DEDICOM变体。该方法旨在识别词汇中的潜在主题簇并同时学习可解释的词嵌入。他们还引入了一种有效训练受约束DEDICOM算法的方法，并对其主题建模和词嵌入性能进行了定性评估。

**Result:** 该研究对所提出的行随机DEDICOM方法在主题建模和词嵌入方面的性能进行了定性评估。

**Conclusion:** 本文提出的基于行随机DEDICOM的方法能够实现可解释的主题提取和词嵌入学习。

> **ai_Abstract:** 本文提出了一种基于行随机DEDICOM的新方法，用于对文本语料库的点互信息矩阵进行处理。该方法旨在同时实现词汇中潜在主题簇的识别和可解释词嵌入的学习。研究还引入了一种高效训练受约束DEDICOM算法的策略，并对其在主题建模和词嵌入方面的表现进行了定性评估。

> **摘要翻译:** DEDICOM算法为对称和非对称方阵提供了一种独特的可解释矩阵分解方法。我们对文本语料库的点互信息矩阵采用了一种新的行随机DEDICOM变体，以识别词汇中的潜在主题簇并同时学习可解释的词嵌入。我们介绍了一种有效训练受约束DEDICOM算法的方法，并对其主题建模和词嵌入性能进行了定性评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [663] [Atomic Calibration of LLMs in Long-Form Generations](https://arxiv.org/abs/2410.13246)
> *长文本生成中大型语言模型的原子校准*

*Caiqi Zhang, Ruihan Yang, Zhisong Zhang, Xinting Huang, Sen Yang, Dong Yu, Nigel Collier* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** LLMs, 置信度校准, 原子校准, 长文本生成, 幻觉

**Comment:** ACL 2025 KnowFM Oral

> **TL;DR:** 本文提出了一种名为“原子校准”的新方法，通过将长文本响应分解为原子声明来对大型语言模型（LLMs）进行细粒度的事实性校准，有效解决了长文本生成中的幻觉问题并提高了模型可信度。

**AI_Comments:** 本文提出了一种对LLM在长文本生成中进行细粒度校准的创新方法，即原子校准。其核心在于将长文本拆解为原子声明进行评估，这比传统的宏观校准更具洞察力。通过结合判别式和生成式方法，该研究为提升LLM在复杂长文本场景下的可信度提供了有价值的途径。其创新性在于解决了长文本中信息混合准确与不准确的挑战，对于提高LLM的实际应用价值具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在长文本生成中常出现幻觉问题，影响其在实际应用中的可信度。现有的大模型校准研究主要集中在短文本任务，采用的是宏观（响应级别）校准，这对于长文本生成而言是不足的，因为长文本响应往往包含复杂且可能混杂准确与不准确信息的内容。

**Method:** 本文引入了一种新颖的“原子校准”方法，通过将长文本响应分解为原子声明，在细粒度级别评估事实性校准。研究将置信度启发方法分为判别式和生成式两种类型，并证明它们的结合可以增强校准效果。

**Result:** 在各种LLMs和数据集上进行的广泛实验表明，原子校准非常适用于长文本生成，并且还可以改善宏观校准结果。此外，原子校准揭示了LLM在整个生成过程中置信度的深刻模式。

**Conclusion:** 原子校准是一种新颖且有效的细粒度事实性校准方法，专门针对长文本生成中的大型语言模型，能够有效提升模型的可靠性和可信度，并揭示其置信度模式。

> **ai_Abstract:** 本文提出了一种名为“原子校准”的创新方法，旨在解决大型语言模型（LLMs）在长文本生成中普遍存在的幻觉问题。与现有仅关注短文本和宏观校准的方法不同，原子校准将长响应分解为细粒度的原子声明，从而实现更精确的事实性评估。研究还探讨了判别式和生成式置信度启发方法的结合应用。实验证明，原子校准不仅适用于长文本生成，还能提升宏观校准效果，并揭示LLM生成过程中的置信度模式，显著增强了模型的可靠性和可信度。

> **摘要翻译:** 大型语言模型（LLMs）常出现幻觉，给实际应用带来重大挑战。置信度校准，即估计模型预测的潜在不确定性，对于增强LLMs的可信度至关重要。现有的大模型校准研究主要集中在短文本任务，在响应级别提供单一置信度分数（宏观校准）。然而，这种方法对于长文本生成而言是不足的，因为响应通常包含更复杂的陈述，并且可能包含准确和不准确的信息。因此，我们引入了原子校准，这是一种通过将长响应分解为原子声明，在细粒度级别评估事实性校准的新方法。我们将置信度启发方法分为判别式和生成式两种类型，并证明它们的组合可以增强校准。我们在各种LLMs和数据集上进行的广泛实验表明，原子校准非常适用于长文本生成，并且还可以改善宏观校准结果。此外，原子校准揭示了LLM在整个生成过程中置信度的深刻模式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [681] [Unpacking Ambiguity: The Interaction of Polysemous Discourse Markers and Non-DM Signals](https://arxiv.org/abs/2507.16748)
> *揭示歧义：多义语篇标记与非语篇标记信号的互动*

*Jingni Wu, Amir Zeldes* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 语篇标记, 多义性, 非语篇标记信号, 语域, 歧义

**Comment:** 

> **TL;DR:** 多义语篇标记与更多样而非数量更多的非语篇标记信号共现，且语域对语篇标记-信号互动有显著影响。

**AI_Comments:** 该论文为理解语篇标记的复杂性及其与非语篇标记信号的互动提供了新的视角，特别强调了语域的关键作用。通过提出语篇标记多义性的分级定义和采用定量分析方法，该研究在语篇分析领域具有创新性，有助于深化对语言中歧义消解机制的理解。

<details>
  <summary>Details</summary>

**Motivation:** 语篇标记（DM）和非语篇标记信号在语篇连贯性中至关重要，但它们之间的互动机制尚不明确，而这对于它们的消歧至关重要。

**Method:** 本研究采用eRST框架，提出了语篇标记多义性的分级定义，并进行相关和回归分析，以检验多义语篇标记是否伴随出现更多、更多样的非语篇标记信号。研究还考察了语域对这些模式的影响。

**Result:** 研究发现，多义语篇标记确实与更多样化的非语篇标记共现，但共现信号的总数不一定增加。此外，语域在塑造语篇标记-信号互动中扮演重要角色。

**Conclusion:** 多义语篇标记与非语篇标记信号之间的互动是复杂的，其特征在于非语篇标记的多样性而非数量，且语域是影响这些互动的关键因素，这对于消歧至关重要。

> **ai_Abstract:** 本研究探讨了英语中多义语篇标记（DM）与非语篇标记信号共现的互动机制，以及语域对其影响。文章利用eRST框架，提出了语篇标记多义性的分级定义，并通过相关和回归分析发现，多义语篇标记与更多样化的非语篇标记共现，但共现信号的总数并未必然增加。研究还强调了语域在塑造语篇标记-信号互动中的重要作用，为理解语篇连贯性和歧义消解提供了新见解。

> **摘要翻译:** 语篇标记（DM）如“but”或“then”对于语篇连贯性至关重要，但它们经常被非语篇标记取代或与之共现（例如，“in the morning”可以与“then”含义相同），并且两者都可能存在歧义（例如，“since”可以指时间或原因）。这些信号之间的互动机制仍不清楚，但对于它们的消歧至关重要。本文研究了英语中语篇标记多义性与非语篇标记信号共现之间的关系，以及语域对这些模式的影响。
我们使用eRST框架，提出了语篇标记多义性的分级定义，并进行了相关和回归分析，以检验多义语篇标记是否伴随出现更多数量和更多样化的非语篇标记信号。我们的研究结果表明，虽然多义语篇标记确实与更多样化的非语篇标记共现，但共现信号的总数不不一定增加。此外，语域在塑造语篇标记-信号互动中扮演重要角色。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [685] [Small Edits, Big Consequences: Telling Good from Bad Robustness in Large Language Models](https://arxiv.org/abs/2507.15868)
> *小改动，大影响：区分大型语言模型中好坏鲁棒性*

*Altynbek Ismailov, Salia Asanova* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-15**

**Keywords:** 大型语言模型, 鲁棒性, 提示工程, 代码生成, 语义敏感性

**Comment:** 

> **TL;DR:** LLMs对提示中的小改动表现出过度鲁棒性（对删除不敏感）和有害不敏感性（对关键语义变化不敏感），需要更好的评估和训练来区分良性噪声和语义改变。

**AI_Comments:** 这项研究通过系统地测试LLMs对不同类型提示扰动的反应，揭示了当前LLMs在鲁棒性方面存在的“双重不对称”问题，即对不重要的信息变化过度鲁棒，而对关键的语义变化却有害地不敏感。其创新之处在于设计了精细的扰动类型和量化评估方法。这项工作对于理解LLMs的局限性、改进其在敏感应用（如代码生成）中的可靠性具有重要意义，并为未来LLM的评估和训练提出了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在编写代码等场景中，即使是微小的误读也可能导致安全问题或经济损失，但同时我们又期望它们能忽略无关紧要的错别字。为了探究有益的鲁棒性到有害的不敏感性之间的界限，本研究旨在区分LLMs对不同类型提示扰动的反应。

**Method:** 研究人员编译了50个LeetCode问题，并设计了三种最小的提示扰动：1) 逐步欠规范化（每次删除10%的词）；2) 词汇翻转（将关键量词如“max”改为“min”）；3) 行话膨胀（用晦涩的技术同义词替换常见名词）。六个前沿模型（包括三个“推理调优”版本）对每个变异提示进行求解，并将其Python输出与原始测试套件进行检查，以确定它们是重复了基线解决方案还是进行了适应。

**Result:** 在11,853次生成中，观察到明显的双重不对称性。即使提示中缺少90%的内容，模型在85%的情况下仍保持正确，显示出对欠规范化的过度鲁棒性。然而，对于一个反转任务的单一量词翻转，只有54%的模型做出反应，其中推理调优版本甚至比其基础版本更不敏感。行话编辑的影响介于两者之间，通过率为56%。

**Conclusion:** 当前的LLMs模糊了无害噪声和改变意义的编辑之间的界限，通常将两者都视为可忽略的。遮蔽诸如函数名等显著锚点可以强制模型重新评估。研究倡导评估和训练协议，以奖励差异化敏感性：在良性噪声下保持稳定，但在语义真正改变时进行适应或拒绝。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在面对提示微小改动时的鲁棒性表现。通过对50个LeetCode问题进行三种类型的最小扰动（逐步欠规范化、关键量词翻转、行话替换），并测试了六个前沿LLM。结果发现，LLMs对大量信息缺失表现出过度鲁棒性（85%正确率），但对改变任务语义的关键量词翻转却不敏感（仅54%响应），甚至推理调优模型更差。研究指出当前LLMs未能有效区分无害噪声和改变意义的编辑，并建议开发奖励差异化敏感性的评估和训练方法。

> **摘要翻译:** 大型语言模型（LLMs）现在在编写代码的场景中，即使是误读一个单词也可能破坏安全性或造成经济损失，然而我们仍然期望它们能忽略零星的错别字。为了探究有益的鲁棒性到有害的不敏感性之间的界限，我们编译了50个LeetCode问题，并设计了三种应在重要性上有所不同的最小提示扰动：（i）逐步欠规范化，每步删除10%的词；（ii）词汇翻转，交换一个关键量词（“max”到“min”）；以及（iii）行话膨胀，用一个晦涩的技术同义词替换一个常见名词。包括三个“推理调优”版本在内的六个前沿模型解决了每个变异提示，它们的Python输出对照原始测试套件进行检查，以揭示它们是重用了基线解决方案还是进行了适应。在11,853次生成中，我们观察到明显的双重不对称性。即使提示中90%的内容缺失，模型在85%的情况下仍保持正确，显示出对欠规范化的过度鲁棒性，然而只有54%的模型对一个反转任务的单一量词翻转做出反应，其中推理调优版本甚至比其基础版本更不敏感。行话编辑介于两者之间，通过率为56%。当前的LLMs因此模糊了无害噪声和改变意义的编辑之间的界限，通常将两者都视为可忽略的。遮蔽诸如函数名等显著锚点可以强制重新评估。我们倡导奖励差异化敏感性的评估和训练协议：在良性噪声下保持稳定，但在语义真正改变时进行适应或拒绝。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [711] [Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance](https://arxiv.org/abs/2507.16711)
> *推进风险与质量保证：用于改善法规遵从的RAG聊天机器人*

*Lars Hillebrand, Armin Berger, Daniel Uedelhoven, David Berghaus, Ulrich Warning, Tim Dilmaghani, Bernd Kliem, Thomas Schmid, Rüdiger Loitz, Rafet Sifa* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 检索增强生成, RAG, 大型语言模型, 监管合规, 风险与质量 assurance

**Comment:** Accepted and published at BigData 2024, 3 pages, 3 tables, 2 figures

> **TL;DR:** 引入一个RAG聊天机器人，通过利用LLM、混合搜索和相关性提升，解决了受监管行业中风险与质量查询处理的瓶颈问题，并显著优于传统RAG方法。

**AI_Comments:** 这篇论文通过引入一个结合LLMs、混合搜索和相关性提升的RAG聊天机器人，为受监管行业中复杂的风险与质量查询处理提供了一个创新的解决方案。其重要性在于解决了传统方法的瓶颈和可扩展性限制，并通过实际部署和评估证明了其有效性。超参数分析的加入也增加了其实用价值，为实践者提供了直接的指导，使其更具落地性。

<details>
  <summary>Details</summary>

**Motivation:** 在高度受监管的行业中，风险与质量(R&Q)保证需要不断应对复杂的监管框架，员工日常处理大量查询，需要准确的政策解读。依赖专业专家的传统方法会造成操作瓶颈并限制可扩展性。

**Method:** 提出了一种新颖的检索增强生成（RAG）系统，该系统利用大型语言模型（LLMs）、混合搜索和相关性提升来增强R&Q查询处理。对124个专家标注的真实世界查询进行了评估，并进行了广泛的超参数分析。

**Result:** 活跃部署的系统在124个专家标注的真实世界查询上，表现出比传统RAG方法显著的改进。此外，超参数分析为实践者提供了有价值的见解。

**Conclusion:** 该RAG聊天机器人系统通过提高R&Q查询处理效率和准确性，有效解决了受监管行业中的操作瓶颈和可扩展性问题，并为实践者提供了实用指导。

> **ai_Abstract:** 本文介绍了一个创新的检索增强生成（RAG）系统，旨在解决高度受监管行业中风险与质量（R&Q）查询处理的效率和准确性问题。该系统结合了大型语言模型（LLMs）、混合搜索和相关性提升技术，用于取代传统专家依赖模式造成的瓶颈。通过对124个真实世界查询的评估，该系统展示了优于传统RAG方法的显著性能提升。研究还包括详细的超参数分析，为实际应用提供了宝贵的配置指导。

> **摘要翻译:** 风险与质量（R&Q）保证在高度受监管的行业中，需要不断驾驭复杂的监管框架，员工每天处理大量查询，需要准确的政策解读。依赖专业专家的传统方法会造成操作瓶颈并限制可扩展性。我们提出了一种新颖的检索增强生成（RAG）系统，该系统利用大型语言模型（LLMs）、混合搜索和相关性提升来增强R&Q查询处理。该系统已在124个专家标注的真实世界查询上进行评估并积极部署，结果表明其比传统RAG方法有显著改进。此外，我们还进行了广泛的超参数分析，以比较和评估多种配置设置，为实践者提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [719] [Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning](https://arxiv.org/abs/2507.16784)
> *超越上下文限制：用于长程推理的潜意识线程*

*Hongyin Luo, Nathaniel Morgan, Tina Li, Derek Zhao, Ai Vy Ngo, Philip Schroeder, Lijie Yang, Assaf Ben-Kish, Jack O'Brien, James Glass* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 上下文限制, 长程推理, 线程推理模型, 工作记忆

**Comment:** Research preview

> **TL;DR:** 该研究提出了一种名为TIM和TIMRUN的新系统，旨在通过将自然语言建模为推理树并有效管理工作记忆来克服大型语言模型的上下文限制，从而实现长程结构化推理和高吞吐量。

**AI_Comments:** 这项工作具有创新性，因为它通过将自然语言建模为推理树并引入高效的内存管理机制（如子任务剪枝和KV缓存重用），显著解决了LLM在长程推理中的上下文限制问题。TIM和TIMRUN的结合为构建更强大、更高效的LLM推理系统提供了新的范式，尤其是在处理复杂、多步骤任务方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了突破大型语言模型（LLMs）的上下文限制，这些限制瓶颈了推理的准确性和效率。

**Method:** 提出了Thread Inference Model (TIM) 和推理运行时TIMRUN。TIM是一系列LLMs，用于递归和分解问题解决。TIMRUN使能超越上下文限制的长程结构化推理。通过将自然语言建模为推理树（由任务、思想、递归子任务和结论组成），而不是线性序列来提高性能。在生成过程中，通过基于规则的子任务剪枝机制，只保留最相关上下文令牌的关键-值状态，从而实现位置嵌入和GPU内存页面的重用。

**Result:** 实验结果表明，该系统即使在操作高达90%的GPU内存中的KV缓存时，也能保持高推理吞吐量。它还在数学任务上提供准确的推理，并处理需要长程推理和多跳工具使用的信息检索挑战。

**Conclusion:** 该研究通过提出TIM和TIMRUN系统，成功克服了大型语言模型的上下文限制、输出限制、位置嵌入约束和GPU内存瓶颈，实现了长程、高效率的结构化推理。

> **ai_Abstract:** 该论文提出了一种名为线程推理模型（TIM）及其运行时TIMRUN的系统，旨在克服大型语言模型（LLMs）的上下文限制，以提高推理的准确性和效率。TIM和TIMRUN通过将自然语言表示为推理树，并利用基于规则的子任务剪枝机制来有效管理工作记忆和重用GPU内存，从而实现几乎无限的工作记忆和长程结构化推理。实验证明，该系统能够保持高推理吞吐量，并在数学推理和需要多跳工具使用的信息检索任务中表现出准确性。

> **摘要翻译:** 为了突破大型语言模型（LLMs）的上下文限制，这些限制瓶颈了推理的准确性和效率，我们提出了线程推理模型（TIM），这是一系列用于递归和分解问题解决的LLM，以及TIMRUN，一个能够实现超越上下文限制的长程结构化推理的推理运行时。TIM在TIMRUN上运行，支持在单个语言模型推理中实现几乎无限的工作记忆和多跳工具调用，克服了输出限制、位置嵌入约束和GPU内存瓶颈。通过将自然语言建模为由长度和深度衡量的推理树而不是线性序列来实现性能。推理树由任务、思想、递归子任务和基于我们在Schroeder等人2025年提出的概念的结论组成。在生成过程中，我们维护一个工作记忆，该记忆仅保留最相关上下文令牌的关键-值状态，这些状态通过基于规则的子任务剪枝机制选择，从而在整个推理过程中实现位置嵌入和GPU内存页的重用。实验结果表明，我们的系统保持了高推理吞吐量，即使在操作高达90%的GPU内存中的KV缓存时也是如此。它还在数学任务上提供准确的推理，并处理需要长程推理和多跳工具使用的信息检索挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [754] [Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent](https://arxiv.org/abs/2507.16799)
> *测试时匹配：在基于LLM的角色扮演语言智能体中解耦个性、记忆和语言风格*

*Xiaoyu Zhan, Xinyu Fu, Hao Sun, Yuanqi Li, Jie Guo, Yanwen Guo* | **Category: cs.CL** | **Updated: 2025-07-22**

**Keywords:** 角色扮演, 大型语言模型, 测试时匹配, 特征解耦, 语言智能体

**Comment:** 

> **TL;DR:** 提出Test-Time-Matching (TTM) 框架，通过在测试时解耦角色特征（个性、记忆、语言风格），实现高保真、可控的LLM角色扮演，无需微调。

**AI_Comments:** Test-Time-Matching (TTM) 的创新之处在于其“测试时”和“无需训练”的特性，有效绕过了传统微调方法的计算和数据瓶颈。通过将角色特征解耦为个性、记忆和语言风格，并采用结构化的三阶段生成流程，该方法大大提高了LLM角色扮演的保真度和可控性。其重要性在于为LLM在更广泛的角色扮演应用中提供了高效且高质量的解决方案，尤其是在处理知名人物角色时。该方法的通用性和灵活性，特别是实现不同特征的无缝组合，是其显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于提示或上下文的LLM角色扮演方法难以实现深度沉浸，而基于微调的方法受限于数据收集和计算资源。本研究旨在解决这些问题，实现更广泛适用的高保真角色扮演。

**Method:** 提出Test-Time-Matching (TTM) 框架，这是一种无需训练的角色扮演方法，通过测试时缩放和上下文工程实现。TTM使用LLM智能体自动将角色特征解耦为个性、记忆和语言风格。该框架包含一个结构化的三阶段生成流程，利用这些特征进行受控的角色扮演。

**Result:** 通过人工评估，结果表明TTM方法在生成富有表现力且风格一致的角色对话方面取得了出色的性能，并能够实现不同语言风格、甚至个性和记忆的无缝组合。

**Conclusion:** Test-Time-Matching (TTM) 框架通过在测试时解耦角色特征，有效解决了LLM角色扮演中深度沉浸和资源限制的问题，实现了高保真、可控的角色扮演能力。

> **ai_Abstract:** 该论文提出了Test-Time-Matching (TTM) 框架，旨在解决大型语言模型（LLM）在角色扮演中深度沉浸不足以及微调方法资源消耗大的问题。TTM是一种无需训练的方法，通过在测试时将角色特征（个性、记忆、语言风格）解耦，并利用三阶段生成流程实现高保真、可控的角色扮演。人工评估结果显示，TTM在生成表达力强、风格一致的角色对话方面表现出色，并支持特征的灵活组合。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展使得角色扮演语言智能体在各种应用中展现出巨大潜力。然而，仅仅依靠提示和上下文输入往往不足以在特定角色中实现深度沉浸，特别是对于知名虚构人物或公众人物。另一方面，基于微调的方法面临数据收集和训练所需计算资源的挑战，从而限制了其更广泛的适用性。为了解决这些问题，我们提出了Test-Time-Matching (TTM)，一种通过测试时缩放和上下文工程实现的无需训练的角色扮演框架。TTM使用LLM智能体自动将角色的特征解耦为个性、记忆和语言风格。我们的框架包含一个结构化的三阶段生成流程，利用这些特征进行受控的角色扮演。它实现了高保真度的角色扮演性能，还能够实现不同语言风格的无缝组合，甚至是个性和记忆的变化。我们通过人工评估了我们的框架，结果表明我们的方法在生成富有表现力且风格一致的角色对话方面取得了出色的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [4] [An Exact Solver for Maximizing a Submodular Function Subject to a Knapsack Constraint](https://arxiv.org/abs/2507.16149)
> *一个用于在背包约束下最大化次模函数的精确求解器*

*Sabine Münch, Stephen Raach* | **Category: cs.DS, cs.DM** | **Updated: 2025-07-22**

**Keywords:** 次模函数, 背包约束, 精确求解器, 分支定界, 加速技术

**Comment:** 

> **TL;DR:** 本文提出了一种用于次模背包问题的精确分支定界算法，并引入了加速技术，其性能优于现有方法。

**AI_Comments:** 本文的创新点在于为NP-hard的次模背包问题提供了一个精确求解器，并引入了有效的加速技术，解决了实际应用中对精确解的需求，其性能超越了现有方法，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多应用需要精确解，因为近似解在实践中往往不足。

**Method:** 提出了一种针对次模背包问题的精确分支定界算法，并引入了多种加速技术以提高效率。

**Result:** 所提出的方法优于现有方法。

**Conclusion:** 所提出的精确求解器在次模背包问题上表现优异，超越了现有技术。

> **ai_Abstract:** 本文针对NP-hard的次模背包问题，提出了一种精确分支定界算法，旨在满足对精确解的需求。该算法引入了多种加速技术以提高效率，并通过在三个基准问题上的评估，证明其性能优于现有的最新方法。

> **摘要翻译:** 我们研究在背包约束下最大化一组加权元素的单调递增次模函数的问题。尽管此问题是NP-hard的，但许多应用需要精确解，因为近似解在实践中往往不足。为了解决这一需求，我们提出了一种针对次模背包问题的精确分支定界算法，并引入了多种加速技术来提高其效率。我们在三个基准问题的实例上评估了这些技术，并将所提出的求解器与Sakaue和Ishihata的两种被认为是最新技术的求解器进行了比较，结果表明所提出的方法优于现有方法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [43] [Longest Unbordered Factors on Run-Length Encoded Strings](https://arxiv.org/abs/2507.16285)
> *游程编码字符串上的最长无边界因子*

*Shoma Sekizaki, Takuya Mieno* | **Category: cs.DS** | **Updated: 2025-07-22**

**Keywords:** 无边界因子, 游程编码, 压缩字符串, 字符串算法, 周期性

**Comment:** SPIRE 2025

> **TL;DR:** 本文提出了一个在游程编码字符串上计算最长无边界因子的算法，当输入字符串可压缩时，该算法可能比现有方法表现更好。

**AI_Comments:** 本文的创新之处在于将最长无边界因子问题扩展到游程编码字符串，这对于处理大规模、重复性数据非常重要。其贡献在于为压缩字符串处理提供了更高效的算法，尤其适用于高度可压缩的数据，展现了在特定输入条件下的性能优势。

<details>
  <summary>Details</summary>

**Motivation:** 最长无边界因子是字符串学中的一个基本概念，与字符串周期性密切相关。现有针对未压缩字符串的算法最差时间复杂度为$O(n \log n)$。本文旨在压缩字符串处理的背景下，特别是在游程编码（RLE）字符串上研究这个问题，以期在字符串高度可压缩时提高性能。

**Method:** 本文首先提出了一个将无边界因子与RLE压缩字符串相关联的简单而关键的结构性观察。在此基础上，本文提出了一种算法，该算法通过新的组合学见解，将[Gawrychowski et al., SPIRE 2015]提出的$O(n^{1.5})$-时间算法中的一个关键思想适配到RLE设置中。

**Result:** 所提出的算法在$O(m^{1.5} \log^2 m)$时间和$O(m \log^2 m)$空间内解决了该问题，其中$m$是RLE压缩输入字符串的大小。当RLE大小$m$相对于$n$足够小时，该算法可能表现出$n$的线性时间行为，从而在这些情况下可能比现有方法性能更优。

**Conclusion:** 本文提出了一个用于计算游程编码字符串上最长无边界因子的有效算法，为高度可压缩的输入提供了性能改进。

> **ai_Abstract:** 本文研究了在游程编码（RLE）字符串上查找最长无边界因子的问题。通过一项关于无边界因子与RLE压缩字符串之间关系的新结构性观察，论文提出了一种算法，该算法将现有技术（Gawrychowski et al., SPIRE 2015）适配到RLE环境中。该算法在$O(m^{1.5} \log^2 m)$时间和$O(m \log^2 m)$空间内运行，其中$m$为RLE字符串的大小，当$m$相对于原始字符串长度$n$较小时，该方法可能比处理未压缩字符串的现有算法更高效。

> **摘要翻译:** 字符串的边界是字符串的非空真前缀，同时也是其后缀。如果一个字符串没有边界，则称其为无边界的。最长无边界因子是字符串学中的一个基本概念，与字符串周期性密切相关。本文解决了最长无边界因子问题：给定一个长度为$n$的字符串，目标是计算其最长的无边界因子。虽然最近的工作已经实现了该问题的次二次方和近线性时间算法，但已知最差时间复杂度仍为$O(n \log n)$ [Kociumaka et al., ISAAC 2018]。在本文中，我们研究了压缩字符串处理背景下的该问题，特别关注游程编码（RLE）字符串。我们首先提出了一个简单而关键的结构性观察，将无边界因子与RLE压缩字符串关联起来。在此基础上，我们提出了一种算法，该算法在$O(m^{1.5} \log^2 m)$时间和$O(m \log^2 m)$空间内解决了该问题，其中$m$是RLE压缩输入字符串的大小。为了实现这一点，我们的方法模拟了[Gawrychowski et al., SPIRE 2015]提出的$O(n^{1.5})$-时间算法中的一个关键思想，通过新的组合学见解将其适配到RLE设置中。当RLE大小$m$相对于$n$足够小时，我们的算法可能表现出$n$的线性时间行为，从而在这些情况下可能比现有方法性能更优。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [184] [Rapid Mixing at the Uniqueness Threshold](https://arxiv.org/abs/2411.03413)
> *唯一性阈值处的快速混合*

*Xiaoyu Chen, Zongchen Chen, Yitong Yin, Xinyuan Zhang* | **Category: cs.DS, math.PR** | **Updated: 2025-07-22**

**Keywords:** 吉布斯分布, 混合时间, Glauber动力学, 唯一性阈值, 计算复杂度

**Comment:** 

> **TL;DR:** 该论文解决了吉布斯分布采样在临界相变阈值处的计算复杂性问题，表明Glauber动力学在硬核模型和伊辛模型中具有多项式混合时间。

**AI_Comments:** 本文通过首次在精确的唯一性阈值处提供混合时间的结果，解决了计算相变领域的一个长期存在的开放性问题，具有重要的理论意义。对定位方案方法的新颖应用和分析是其主要创新点，展示了在复杂系统分析方面的强大能力。

<details>
  <summary>Details</summary>

**Motivation:** 在吉布斯分布采样中，计算相变在临界点处的计算复杂性尚不清楚，因为之前的算法和难度结果都需要与该阈值保持一定的松弛。本研究旨在解决在临界相变阈值处的这一开放性问题。

**Method:** 本研究通过对Chen和Eldan（2022）引入的定位方案方法进行新的解释和分析来推导出混合时间上限，并将其应用于硬核模型的场动力学和伊辛模型的近端采样器。在上下限的推导中，关键步骤是在最坏情况下为临界点的谱独立性建立了次线性上下限。

**Result:** 对于最大度$\\Delta\\ge 3$的图上的硬核模型，在唯一性阈值$\\lambda = \\lambda_c(\\Delta)$处，Glauber动力学的混合时间上限是$n$的多项式，但在最坏情况下并非接近线性。对于最大度$\\Delta\\ge 3$的图上的伊辛模型（反铁磁或铁磁），在临界温度$\\beta$（其中$|\\beta| = \\beta_c(\\Delta)$）处，Glauber动力学的混合时间上限为$\\tilde{O}\\left(n^{2 + O(1/\\Delta)}\\right)$，下限为$\\Omega\\left(n^{3/2}\\right)$。对于由临界相互作用矩阵$J$（其中$\\left \\lVert J \\right \\rVert_2=1$）指定的伊辛模型，混合时间上限为$\\tilde{O}(n^{3/2})$，与完全图上的下限$\\Omega\\left(n^{3/2}\\right)$（对数因子内）匹配。

**Conclusion:** 本研究通过解决吉布斯分布采样在临界相变阈值处的计算复杂性这一开放性问题，完善了计算相变的图景。

> **ai_Abstract:** 本文解决了吉布斯分布采样在临界相变阈值处的计算复杂性问题，填补了此前研究未能触及这一精确阈值的空白。研究表明，对于硬核模型和伊辛模型，Glauber动力学的混合时间在最坏情况下是多项式时间，但并非接近线性。这些结果是通过对现有定位方案方法进行创新性解释和分析，并结合对临界点谱独立性的次线性界限的建立而获得的，从而全面阐明了计算相变的特性。

> **摘要翻译:** 在过去的几十年里，在吉布斯分布的采样中发现了一个引人入胜的计算相变。然而，临界点的计算复杂性仍然知之甚少，因为之前的算法和难度结果都需要与该阈值保持一个常数松弛。
在本文中，我们解决了临界相变阈值处的这个开放性问题，从而完善了计算相变的图景。我们表明，对于最大度$\\Delta\\ge 3$的图上的硬核模型，在唯一性阈值$\\lambda = \\lambda_c(\\Delta)$处，Glauber动力学的混合时间上限是$n$的多项式，但在最坏情况下并非接近线性。
对于伊辛模型（反铁磁或铁磁），我们建立了类似的结果。对于最大度$\\Delta\\ge 3$的图上的伊辛模型，在临界温度$\\beta$（其中$|\\beta| = \\beta_c(\\Delta)$）处，我们表明Glauber动力学的混合时间上限为$\\tilde{O}\\left(n^{2 + O(1/\\Delta)}\\right)$，下限为$\\Omega\\left(n^{3/2}\\right)$。对于由临界相互作用矩阵$J$（其中$\\left \\lVert J \\right \\rVert_2=1$）指定的伊辛模型，我们获得了混合时间$\\tilde{O}(n^{3/2})$的上限，与完全图上的下限$\\Omega\\left(n^{3/2}\\right)$（对数因子内）匹配。
我们的混合时间上限来源于对Chen和Eldan（2022）引入的定位方案方法的新解释和分析，并将其应用于硬核模型的场动力学和伊辛模型的近端采样器。作为我们上下限的关键步骤，我们为最坏情况下临界点的谱独立性建立了次线性上下限。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [214] [LimTDD: A Compact Decision Diagram Integrating Tensor and Local Invertible Map Representations](https://arxiv.org/abs/2504.01168)
> *LimTDD：一种集成张量和局部可逆映射表示的紧凑决策图*

*Xin Hong, Aochu Dai, Dingchao Gao, Sanjiang Li, Zhengfeng Ji, Mingsheng Ying* | **Category: cs.DS** | **Updated: 2025-07-22**

**Keywords:** 张量决策图, 局部可逆映射, 张量网络, 数据压缩, 量子计算

**Comment:** 

> **TL;DR:** LimTDD通过引入局部可逆映射，显著提高了张量决策图的压缩效率，并在量子计算等应用中表现出卓越性能。

**AI_Comments:** LimTDD的创新之处在于其将局部可逆映射与张量决策图相结合，有效解决了现有TDDs的压缩瓶颈。采用XP-稳定器群而非Pauli算符，极大地扩展了其适用范围，使其不仅限于量子态表示，还能应用于更广泛的张量任务。该工作对于高维数据的高效表示和操作具有重要意义，尤其是在量子信息和机器学习等领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的张量决策图（TDDs）未能充分利用张量同构性，限制了其压缩潜力，因此需要一种更紧凑的张量表示方法。

**Method:** 本文引入了局部可逆映射张量决策图（LimTDDs），它是TDDs的扩展，通过集成局部可逆映射（LIMs）来实现更紧凑的表示。与LIMDD不同，LimTDD采用XP-稳定器群，使其适用于更广泛的基于张量的任务。文章还提出了针对归一化、切片、加法和收缩等关键操作的高效算法。

**Result:** 理论分析表明，LimTDDs比TDDs更紧凑，在最佳情况下和量子态表示方面，比TDDs和LIMDDs都具有指数级的压缩优势。量子电路张量计算和模拟的实验结果证实了LimTDD的卓越效率。

**Conclusion:** LimTDD通过引入局部可逆映射和XP-稳定器群，显著提升了张量决策图的压缩效率和适用性，在量子计算等领域展现出优越的性能和潜力。

> **ai_Abstract:** 本文提出了LimTDD，一种新型的张量决策图，通过引入局部可逆映射（LIMs）和采用XP-稳定器群，解决了现有TDDs在利用张量同构性方面的不足，从而实现了更紧凑的张量表示。LimTDD在理论上和实验上都证明了其在压缩效率上的显著提升，尤其是在量子计算等应用中，比TDDs和LIMDDs具有指数级的优势，并提供了高效的张量操作算法。

> **摘要翻译:** 张量网络是有效表示和操作高维数据的强大工具，应用于量子物理、机器学习和数据压缩等领域。张量决策图（TDDs）通过利用决策图技术，为张量表示提供了一个高效的框架。然而，当前TDDs和其他决策图的实现未能利用张量同构性，限制了它们的压缩潜力。本文引入了局部可逆映射张量决策图（LimTDDs），它是TDDs的扩展，通过集成局部可逆映射（LIMs）来实现更紧凑的表示。与LIMDD不同，LIMDD使用泡利算符表示量子态，而LimTDD采用XP-稳定器群，从而使其在基于张量的任务中具有更广泛的适用性。我们提出了用于归一化、切片、加法和收缩的高效算法，这些对于张量网络应用至关重要。理论分析表明，LimTDDs比TDDs实现了更大的紧凑性，并且在最佳情况下和量子态表示方面，比TDDs和LIMDDs都提供了指数级的压缩优势。量子电路张量计算和模拟的实验结果证实了LimTDD的卓越效率。开源代码可在https://github.com/Veriqc/LimTDD获取。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [244] [On Distributed Colouring of Hyperbolic Random Graphs](https://arxiv.org/abs/2505.19109)
> *关于双曲随机图的分布式着色*

*Yannic Maus, Janosch Ruff* | **Category: cs.DS, 68W15** | **Updated: 2025-07-21**

**Keywords:** 分布式着色, 双曲随机图, 算法性能, 真实世界网络, 幂律度分布

**Comment:** 53 pages, 6 figures

> **TL;DR:** 研究在双曲随机图上简单分布式着色算法的性能。

**AI_Comments:** 这篇论文的创新点在于将分布式着色算法的分析背景从传统的最坏情况模型转向了更符合真实世界网络特性的双曲随机图模型。这对于理解算法在实际应用中的表现具有重要意义，尤其是在处理具有幂律度分布和高聚类系数的大规模网络时。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机是由于从最坏情况分析转向更现实的网络模型，研究在分布式环境下对双曲随机图进行着色所需的轮数和颜色空间大小。

**Method:** 分析简单的分布式着色算法在双曲随机图（一种捕捉真实世界网络关键属性的生成模型）上的性能，并研究着色所需的回合数和颜色空间大小。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文分析了简单分布式着色算法在双曲随机图（HRG）上的性能。HRG是一种能够捕捉真实世界网络特征（如幂律度分布和高聚类系数）的生成模型。研究动机在于从最坏情况分析转向更现实的网络模型，因此论文探讨了在分布式环境下对HRG进行着色所需的轮数和颜色空间的大小。

> **摘要翻译:** 我们分析了简单分布式着色算法的性能，假设输入图是双曲随机图（HRG），这是一种捕捉真实世界网络关键属性的生成模型，例如幂律度分布和大的聚类系数。受从最坏情况分析转向更现实网络模型的启发，我们研究了在分布式设置中对HRG进行着色所需的轮数和颜色空间大小。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [578] [Toward a Lightweight and Robust Design for Caching with Predictions](https://arxiv.org/abs/2507.16242)
> *迈向轻量级和鲁棒的预测缓存设计*

*Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng* | **Category: cs.DS, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 缓存, 鲁棒性, 预测, 学习增强, 轻量级

**Comment:** preprint

> **TL;DR:** 本文介绍了	extsc{Guard}，一个轻量级的鲁棒化框架，旨在提高学习增强型缓存算法的鲁棒性，同时保持其1-一致性和低计算开销。

**AI_Comments:** 	extsc{Guard}的创新之处在于它提供了一种轻量级的鲁棒化方案，解决了学习增强型缓存算法在鲁棒性方面的不足，同时避免了现有方法牺牲一致性或引入高计算开销的问题。其$\mathcal{O}(1)$的额外开销使其具有很高的实用价值和效率。

<details>
  <summary>Details</summary>

**Motivation:** 在线缓存问题旨在有限的缓存大小下最小化缓存未命中。虽然朴素的学习增强型缓存算法能实现理想的1-一致性，但它们缺乏鲁棒性保证。现有的鲁棒化方法要么牺牲1-一致性，要么引入显著的计算开销。

**Method:** 本文引入了	extsc{Guard}，一个轻量级的鲁棒化框架，它能将一类广泛的学习增强型缓存算法的鲁棒性提高到$2H_k + 2$，同时保持其1-一致性。	extsc{Guard}实现了当前已知的一致性和鲁棒性之间的最佳权衡，并且每请求仅增加$\mathcal{O}(1)$的额外开销。

**Result:** 	extsc{Guard}实现了当前已知的一致性和鲁棒性之间的最佳权衡，并且每请求仅增加$\mathcal{O}(1)$的额外开销，从而保持了基础算法的原始时间复杂度。在多个真实世界数据集和预测模型上的大量实验验证了	extsc{Guard}在实践中的有效性。

**Conclusion:** 	extsc{Guard}是一个有效且实用的轻量级鲁棒化框架，能显著增强学习增强型缓存算法的鲁棒性，同时保持其高效率和一致性。

> **ai_Abstract:** 本文提出	extsc{Guard}，一个轻量级且鲁棒的框架，用于增强学习增强型缓存算法的鲁棒性。针对现有方法在鲁棒性和一致性之间的权衡或高开销问题，	extsc{Guard}在保持1-一致性的同时，将鲁棒性提高到$2H_k + 2$，且每请求仅增加$\mathcal{O}(1)$的额外开销。实验证明	extsc{Guard}在实践中表现出有效性，实现了当前已知的一致性和鲁棒性之间的最佳权衡。

> **摘要翻译:** 在线缓存问题旨在有限的缓存大小下最小化服务请求序列时的缓存未命中。虽然朴素的学习增强型缓存算法能实现理想的1-一致性，但它们缺乏鲁棒性保证。现有的鲁棒化方法要么牺牲1-一致性，要么引入显著的计算开销。在本文中，我们引入了	extsc{Guard}，一个轻量级的鲁棒化框架，它能将一类广泛的学习增强型缓存算法的鲁棒性提高到$2H_k + 2$，同时保持其1-一致性。	extsc{Guard}实现了当前已知的一致性和鲁棒性之间的最佳权衡，并且每请求仅增加$\mathcal{O}(1)$的额外开销，从而保持了基础算法的原始时间复杂度。在多个真实世界数据集和预测模型上的大量实验验证了	extsc{Guard}在实践中的有效性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [656] [Online Combinatorial Optimization with Graphical Dependencies](https://arxiv.org/abs/2507.16031)
> *在线组合优化与图依赖*

*Zhimeng Gao, Evangelia Gergatsouli, Kalen Patton, Sahil Singla* | **Category: cs.DS, F.2.2** | **Updated: 2025-07-21**

**Keywords:** 在线组合优化, 马尔可夫随机场, 竞争性算法, 图依赖, 结构化依赖

**Comment:** 

> **TL;DR:** 本文研究在马尔可夫随机场（MRF）下在线组合优化，并提出了$O(\\Delta)$竞争性算法，填补了独立输入和任意相关性之间的空白。

**AI_Comments:** 这项工作通过引入MRF模型，有效地桥接了在线优化中独立输入和完全相关输入之间的鸿沟，提供了一种处理温和依赖的有效方法。其创新之处在于将MRF的参数$\\Delta$与算法的竞争比联系起来，并为不同类型的组合优化问题提供了具体的解决方案，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有在线随机组合优化假设输入独立，这在实践中往往不成立。而任意相关性又使得设计有效算法变得不可能。因此，需要研究能够捕捉温和相关性同时仍允许非平凡算法的中间模型。

**Method:** 本文在马尔可夫随机场（MRF）模型下研究在线组合优化，MRF通过最大加权度$\\Delta$来参数化相关性强度。研究目标是设计紧密的$\\\\Theta(\\Delta)$竞争性算法。具体方法包括：对于具有覆盖约束的最小化问题，将其归结为$p$-样本模型；对于最大化问题，将“平衡价格”框架扩展到MRF。

**Result:** 本文提出了通用的技术，为MRF分布输入下的最小化和最大化问题实现了$O(\\Delta)$竞争性算法。

**Conclusion:** 本研究表明，在马尔可夫随机场（MRF）模型下，可以设计出紧密的$O(\\Delta)$竞争性算法，从而有效解决了具有温和相关性的在线组合优化问题。

> **ai_Abstract:** 本文针对在线随机组合优化中独立性假设的局限性以及任意相关性导致算法困难的问题，引入了马尔可夫随机场（MRF）作为一种捕捉结构化依赖的中间模型。作者提出了通用的技术，为MRF分布输入下的最小化和最大化问题设计了$O(\\Delta)$竞争性算法。具体地，对于最小化问题（如设施选址），将其归结为$p$-样本模型；对于最大化问题（如匹配），则将“平衡价格”框架扩展到MRF。研究旨在探寻在MRF模型下实现紧密$O(\\Delta)$竞争性算法的条件。

> **摘要翻译:** 现有的大多数在线随机组合优化工作都假设输入来自独立分布——这是一个在实践中经常失败的强假设。在另一个极端，通过姚氏极小极大原理，任意相关性等同于最坏情况输入，使得好的算法通常不可能实现。这促使我们研究能够捕捉轻度相关性同时仍允许非平凡算法的中间模型。
在本文中，我们研究了马尔可夫随机场（MRF）下的在线组合优化，MRF是一种成熟的用于结构化依赖的图模型。MRF通过最大加权度$\\Delta$来参数化相关性强度，在独立性（$\\Delta = 0$）和完全相关性（$\\Delta \\to \\infty$）之间平滑插值。虽然朴素方法会产生$e^{O(\\Delta)}$竞争性算法和$\\\\Omega(\\Delta)$的硬度，但我们问道：我们何时能设计出紧密的$\\\\Theta(\\Delta)$竞争性算法？
我们提出了通用的技术，为MRF分布输入下的最小化和最大化问题实现了$O(\\Delta)$竞争性算法。对于具有覆盖约束的最小化问题（例如，设施选址和斯坦纳树），我们将其归结为成熟的$p$-样本模型。对于最大化问题（例如，匹配和带有XOS买家的组合拍卖），我们将在线分配问题的“平衡价格”框架扩展到MRF。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [704] [Online Joint Replenishment Problem with Arbitrary Holding and Backlog Costs](https://arxiv.org/abs/2507.16096)
> *在线联合补货问题与任意持有和积压成本*

*Yossi Azar, Shahar Lewkowicz* | **Category: cs.DS** | **Updated: 2025-07-21**

**Keywords:** 联合补货问题, 在线算法, 竞争分析, 持有成本, 积压成本

**Comment:** 

> **TL;DR:** 本文为具有任意持有和积压成本的在线联合补货问题设计了一个常数竞争算法，解决了先前工作中留下的开放问题。

**AI_Comments:** 该论文的关键创新在于其提出的动态优先级算法，它成功地处理了先前研究中未能解决的任意成本函数情况，填补了在线联合补货问题领域的一个重要空白。其竞争比结果表明了算法的有效性，对于供应链管理中的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Moseley、Niaparast和Ravi在其开创性工作中提出了带有持有和积压成本的联合补货问题（JRP），但他们提出的常数竞争算法仅适用于所有物品的持有成本和积压成本相同的情况，未能处理任意（依赖于请求的）持有成本和积压成本函数，并将其作为一个开放问题。

**Method:** 本文设计了一种具有动态优先级的算法，与现有算法基于固定优先级按截止日期服务请求不同，新算法可以服务请求的任意子集，从而适用于任意依赖于请求的函数。

**Result:** 对于单物品情况，设计了一个4-竞争算法；对于通用（多物品）版本，设计了一个16-竞争算法，成功解决了先前工作中悬而未决的问题。

**Conclusion:** 本文成功为具有任意持有和积压成本的在线联合补货问题开发了一个常数竞争算法，填补了现有研究的空白，并提供了具体且有竞争力的性能保证。

> **ai_Abstract:** 本文解决了在线联合补货问题中长期存在的挑战，即在存在任意（依赖于请求的）持有和积压成本函数的情况下设计常数竞争算法。针对Moseley等人先前工作中的开放问题，本文提出了一种创新的、具有动态优先级的算法。该算法能够为单物品情况提供4-竞争性，并为多物品情况提供16-竞争性，显著提升了该类问题的解决能力。

> **摘要翻译:** Moseley、Niaparast和Ravi在其开创性论文中引入了带有持有和积压成本的联合补货问题（JRP），该问题在供应链规划系统中模拟了订购成本、持有成本和积压成本之间的权衡。他们的模型概括了经典的按订单生产版本以及按库存生产版本。对于所有物品的持有成本函数相同且所有积压成本相同的情况，他们提供了一个常数竞争算法，但将为任意函数设计常数竞争算法的问题留作开放。此外，他们注意到他们的算法不适用于任意（依赖于请求的）持有成本和积压成本函数。我们解决了他们的开放问题，并设计了一个适用于任意依赖于请求的函数的常数竞争算法。具体来说，我们为单物品情况建立了一个4-竞争算法，为通用（多物品）版本建立了一个16-竞争算法。Moseley、Niaparast和Ravi的算法基于对物品请求的固定优先级，并且对物品的请求总是按截止日期顺序服务。相比之下，我们设计了一种对请求具有动态优先级的算法，这样我们可能需要服务请求的一个通用子集，而不是按请求的截止日期服务前缀。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [42] [Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars](https://arxiv.org/abs/2507.15979)
> *梦想、提升、动画：从单张图像到可动画高斯替身*

*Marcel C. Bühler, Ye Yuan, Xueting Li, Yangyi Huang, Koki Nagano, Umar Iqbal* | **Category: cs.GR, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 3D人体替身, 单图像重建, 高斯, 动画, 视频扩散模型

**Comment:** 

> **TL;DR:** DLA是一个新颖的框架，它利用多视角生成、3D高斯提升和姿态感知UV空间映射，从单张图像重建可动画的3D人体替身，实现实时渲染和直观编辑。

**AI_Comments:** DLA的创新性在于其整合了视频扩散模型、3D高斯表示和姿态感知UV空间映射，从而解决了从单张图像生成高质量可动画3D替身的难题。特别是将高斯锚定到UV流形，有效保证了动画过程中的一致性，同时保留了精细细节，这是一个重要的进步。其支持实时渲染和无需后处理的编辑能力，使其在实际应用中具有巨大潜力。该方法为未来单图3D人体重建和动画领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 从单张图像重建可动画的3D人体替身是一个挑战，现有方法可能难以同时实现高保真度、动画一致性和实时渲染。该论文旨在弥合非结构化3D表示与高保真、可动画替身之间的差距。

**Method:** DLA（Dream, Lift, Animate）框架通过以下步骤实现：1. **梦想多视角：** 使用视频扩散模型从单张图像生成多视角图像，捕获几何和外观细节。2. **提升到3D高斯：** 将这些多视角图像提升为非结构化3D高斯。3. **姿态感知UV空间映射：** 提出一个基于Transformer的编码器，将3D高斯投影到与参数化身体模型UV空间对齐的结构化潜在表示。4. **动画：** 潜在代码被解码为UV空间高斯，通过身体驱动变形进行动画处理，并根据姿态和视角进行渲染。通过将高斯锚定到UV流形，确保动画期间的一致性并保留视觉细节。

**Result:** DLA在ActorsHQ和4D-Dress数据集上，在感知质量和光度精度方面均优于最先进的方法。该方法支持实时渲染和直观编辑，无需后期处理。

**Conclusion:** DLA通过结合视频扩散模型的生成能力和姿态感知UV空间高斯映射，成功弥合了非结构化3D表示与高保真、可动画替身之间的差距，实现了从单张图像重建高质量的可动画3D人体替身。

> **ai_Abstract:** DLA是一个创新的框架，它能从单张图像重建可动画的3D人体替身。该方法结合了视频扩散模型的多视角生成能力、3D高斯提升技术以及独特的姿态感知UV空间映射。通过将非结构化3D高斯投影到UV空间对齐的结构化潜在表示，DLA实现了高保真度的实时动画渲染和直观编辑。实验结果表明，DLA在感知质量和光度精度方面均超越了现有SOTA方法，有效弥合了非结构化3D表示与高质量动画替身之间的鸿沟。

> **摘要翻译:** 我们引入了Dream, Lift, Animate (DLA)，这是一个从单张图像重建可动画3D人体替身的新颖框架。这通过利用多视角生成、3D高斯提升和3D高斯的姿态感知UV空间映射来实现。给定一张图像，我们首先使用视频扩散模型“梦想”出合理的多视角，捕获丰富的几何和外观细节。然后将这些视角提升为非结构化3D高斯。为了实现动画，我们提出了一个基于Transformer的编码器，该编码器建模全局空间关系并将这些高斯投影到与参数化身体模型UV空间对齐的结构化潜在表示中。此潜在代码被解码为UV空间高斯，可以通过身体驱动变形进行动画处理，并根据姿态和视角进行渲染。通过将高斯锚定到UV流形，我们的方法确保了动画期间的一致性，同时保留了精细的视觉细节。DLA实现了实时渲染和直观编辑，无需后期处理。我们的方法在感知质量和光度精度方面均优于ActorsHQ和4D-Dress数据集上的最先进方法。通过结合视频扩散模型的生成优势与姿态感知UV空间高斯映射，DLA弥合了非结构化3D表示与高保真、动画就绪替身之间的差距。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [99] [MMS Player: an open source software for parametric data-driven animation of Sign Language avatars](https://arxiv.org/abs/2507.16463)
> *MMS播放器：一个用于手语形象参数化数据驱动动画的开源软件*

*Fabrizio Nunnari, Shailesh Mishra, Patrick Gebhard* | **Category: cs.GR, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 手语动画, 开源软件, MMS, Blender, 参数化数据驱动

**Comment:** 

> **TL;DR:** MMS播放器是一个开源软件，它能从新型MMS格式生成手语动画，基于Blender实现，并支持多种输出。

**AI_Comments:** 该论文介绍的MMS-Player是一个重要的开源工具，它通过引入MMS这一增强型手语表示格式，并结合Blender的强大功能，为手语动画的自动化生成提供了新的解决方案。其开源性质和API接口使其具有很高的可扩展性和应用潜力，有助于推动手语数字内容创作和无障碍交流领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个开源软件MMS-Player，用于从新颖的MMS手语表示格式合成手语动画，以增强现有基于词汇的手语表示，增加并行执行、时间信息和屈折变化。

**Method:** MMS-Player是一个开源软件，能够从MMS（多模态手语流）这一新颖的手语表示格式合成手语动画。MMS格式通过添加手语的并行执行、时间信息和屈折变化来增强基于词汇的表示。该软件作为Blender 3D创作工具的Python脚本实现，可通过命令行或HTTP API调用。

**Result:** 该软件可以生成手语动画，并能将其渲染为视频或导出为其他流行的3D动画交换格式。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** MMS播放器是一个开源软件，它能利用一种名为MMS的新颖手语表示格式生成手语动画。MMS格式通过整合并行执行、时序和屈折信息，改进了传统基于词汇的手语表示。该软件基于Blender的Python脚本实现，支持命令行和HTTP API调用，可输出视频或多种3D动画格式，并已在GitHub上开源。

> **摘要翻译:** 本文描述了MMS-Player，这是一个开源软件，能够从一种名为MMS（多模态手语流）的新颖手语表示格式合成手语动画。MMS通过添加手语的并行执行、时间、和屈折变化信息来增强基于词汇的表示。该实现由用于流行Blender 3D创作工具的Python脚本组成，可以通过命令行或HTTP API调用。动画可以渲染为视频或导出为其他流行的3D动画交换格式。该软件根据GPL-3.0许可证免费提供，网址为https://github.com/DFKI-SignLanguage/MMS-Player。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [134] [High-Resolution Thermal Simulation Framework for Extrusion-based Additive Manufacturing of Complex Geometries](https://arxiv.org/abs/2305.07120)
> *高分辨率挤出式增材制造复杂几何体的热模拟框架*

*Dhruv Gamdha, Kumar Saurabh, Baskar Ganapathysubramanian, Adarsh Krishnamurthy* | **Category: cs.GR** | **Updated: 2025-07-22**

**Keywords:** 增材制造, 热模拟, 数字孪生, 八叉树网格, 挤出式打印

**Comment:** 24 pages, 12 figures

> **TL;DR:** 本文提出了一种用于挤出式增材制造的高分辨率、实时热模拟框架，通过创建数字孪生，实现了比实际打印更快的模拟，并为未来的闭环控制奠定了基础。

**AI_Comments:** 本文的创新点在于提出了一个通用的、可扩展的高分辨率热模拟框架，并利用自适应八叉树网格实现了比实际打印更快的模拟速度。这为实时数字孪生和闭环控制提供了计算基础，对于提高增材制造质量和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高挤出式增材制造的打印质量、减少浪费并优化打印参数。传统的增材制造模拟计算量大，且无法扩展到模拟中等大小的几何体。

**Method:** 本文提出了一个通用框架，通过对中间打印几何体进行物理模拟来创建动态打印过程的数字孪生。该框架接受通用的挤出式增材制造G代码，从打印计划生成适合分析的体素化几何表示，并执行基于物理的（瞬态热）打印过程模拟。该方法利用自适应八叉树网格进行几何表示和快速模拟，以实现实时预测。

**Result:** 该方法能够模拟高体素分辨率下复杂几何体（稀疏和密集填充）的打印。该方法可扩展到高体素分辨率，并能预测打印过程中的瞬态热分布。模拟运行速度快于实际打印时间。

**Conclusion:** 本研究为实时数字孪生奠定了计算基础，未来可用于闭环控制（例如，调整风扇速度或挤出速率）。

> **ai_Abstract:** 本文提出了一种用于挤出式增材制造的高分辨率热模拟框架，旨在克服传统模拟计算量大且难以扩展的问题。该框架通过处理G代码、生成体素化几何表示并利用自适应八叉树网格进行瞬态热物理模拟，创建动态打印过程的数字孪生。实验证明，该方法能有效模拟复杂几何体，实现高分辨率下的瞬态热分布预测，且模拟速度快于实际打印时间，为未来实现实时闭环控制奠定了基础。

> **摘要翻译:** 准确模拟打印过程对于提高打印质量、减少浪费和优化挤出式增材制造的打印参数至关重要。传统的增材制造模拟计算量非常大，并且无法扩展到模拟中等大小的几何体。在本文中，我们提出了一种通用框架，通过对中间打印几何体进行物理模拟来创建动态打印过程的数字孪生。我们的框架接受通用的挤出式增材制造G代码，从打印计划生成适合分析的体素化几何表示，并执行基于物理的（瞬态热）打印过程模拟。我们的方法利用自适应八叉树网格进行几何表示和快速模拟，以实现实时预测。我们通过模拟高体素分辨率下具有稀疏和密集填充的复杂几何体的打印来证明我们方法的有效性。我们的结果表明，这种方法可以扩展到高体素分辨率，并且可以预测随着打印进行而产生的瞬态热分布。由于模拟运行速度快于实际打印时间，因此相同的引擎原则上可以将热预测反馈给机器控制器（例如，调整风扇速度或挤出速率）。本研究为实时数字孪生奠定了计算基础，未来可用于闭环控制。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [164] [Flow Symmetrization for Parameterized Constrained Diffeomorphisms](https://arxiv.org/abs/2312.06317)
> *参数化约束微分同胚的流对称化*

*Aalok Gangopadhyay, Dwip Dalal, Progyan Das, Shanmuganathan Raman* | **Category: cs.GR** | **Updated: 2025-07-21**

**Keywords:** 微分同胚, 流对称化, 约束微分同胚, 埃舍尔化, 密度估计

**Comment:** 

> **TL;DR:** 本文提出了“流对称化”方法，用于表示具有周期性、旋转等变性等对称约束的参数化约束微分同胚，适用于形状搜索、埃舍尔化和识别空间上的密度估计。

**AI_Comments:** 该论文引入了一种处理具有对称性约束的微分同胚的创新方法，这是对以前无约束方法的重大进步。其可微分性允许与基于梯度的优化相结合，使其具有高度实用性。在埃舍尔化和识别空间密度估计方面的应用突显了其多功能性，并解决了几何建模和拓扑学中的挑战性问题。

<details>
  <summary>Details</summary>

**Motivation:** 在搜索具有固定拓扑性质的形状时，微分同胚发挥着关键作用，但现有方法仅使用无约束的微分同胚。因此，需要一种能够处理具有额外对称约束的受限微分同胚的方法。

**Method:** 开发了“流对称化”方法，以表示包含周期性、旋转等变性和反射等变性等对称约束的参数化约束微分同胚族。该表示是可微分的，适用于基于梯度的优化。该方法通过两个框架进行演示：一是埃舍尔化问题，通过梯度优化变形瓦片形状以匹配目标；二是识别空间（如环面、球面、克莱因瓶和射影平面）上的密度估计，利用平铺理论和识别拓扑的内在联系设计约束微分同胚。

**Result:** 该方法在欧几里得平面上的埃舍尔化和非欧几里得识别空间上的密度估计方面取得了令人印象深刻的结果。

**Conclusion:** 该方法在欧几里得平面上的埃舍尔化和非欧几里得识别空间上的密度估计方面取得了令人印象深刻的结果，证明了其有效性。

> **ai_Abstract:** 本文提出了一种名为“流对称化”的新方法，用于表示包含周期性、等变性等对称约束的参数化约束微分同胚。这种可微分的表示适用于基于梯度的形状搜索优化。该方法特别适用于平铺类中的瓦片形状。作者通过埃舍尔化（变形瓦片形状以匹配目标）和识别空间（如环面、球面）上的密度估计这两个框架展示了其有效性，利用了平铺理论和识别拓扑之间的联系。实验结果表明，该方法在两项应用中均表现出色。

> **摘要翻译:** 微分同胚在搜索具有固定拓扑性质的形状时起着关键作用，它允许模板形状的平滑变形。有几种方法使用微分同胚进行形状搜索。然而，这些方法只使用无约束的微分同胚。在这项工作中，我们开发了流对称化——一种表示参数化约束微分同胚族的方法，该族包含额外的对称约束，如周期性、旋转等变性和反射等变性。我们的表示本质上是可微分的，使其适用于基于梯度的形状搜索优化方法。由于这些对称约束在平铺类中自然产生，因此我们的方法非常适合表示属于任何平铺类的瓦片形状。为了证明我们方法的有效性，我们设计了两个框架来解决埃舍尔化和密度估计这两个具有挑战性的问题。第一个框架专门用于埃舍尔化问题，我们对属于不同等边类的瓦片形状进行参数化。给定目标形状，使用基于梯度的优化来变形模板瓦片以使其类似于目标形状。第二个框架侧重于识别空间中的密度估计。通过利用平铺理论和识别拓扑之间的内在联系，我们设计了平面上的约束微分同胚，从而在识别空间上产生了无约束微分同胚。具体来说，我们在环面、球面、克莱因瓶和射影平面等识别空间上进行密度估计。通过结果和实验，我们证明了我们的方法在欧几里得平面上的埃舍尔化和非欧几里得识别空间上的密度估计方面取得了令人印象深刻的结果。代码和结果：https://dwipddalal.github.io/FlowSymmetry/

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [194] [Distilling Diversity and Control in Diffusion Models](https://arxiv.org/abs/2503.10637)
> *扩散模型中的多样性和控制蒸馏*

*Rohit Gandikota, David Bau* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 扩散模型, 模型蒸馏, 样本多样性, 控制蒸馏, 混合推理

**Comment:** Project Page: https://distillation.baulab.info

> **TL;DR:** 本文研究了蒸馏扩散模型中样本多样性下降的问题，发现基础模型的概念表征得以保留，并提出了控制蒸馏和多样性蒸馏方法，显著恢复甚至超越了多样性，同时保持了计算效率。

**AI_Comments:** 本文创新性地解决了蒸馏扩散模型多样性下降的痛点，通过揭示概念表征的保留和时间步对多样性的影响，提出了实用的控制蒸馏和多样性蒸馏方法。特别是多样性蒸馏，通过混合推理实现了在效率和多样性上的双赢，且无需额外训练，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 蒸馏扩散模型存在一个关键限制：与基础模型相比，样本多样性降低。本文旨在解决这一问题，并理解多样性下降的机制。

**Method:** 本文首先揭示了尽管多样性丧失，但蒸馏模型保留了基础模型的概念表征，并展示了控制机制（如Concept Sliders和LoRAs）可以无缝迁移。为了理解多样性下降的机制，利用$\hat{\mathbf{x}}_{0}$可视化作为分析工具，揭示了模型在中间步骤预测最终输出的方式，并识别出初始扩散时间步对输出多样性起决定性作用。基于这些见解，引入了多样性蒸馏——一种混合推理方法，仅在第一个关键时间步使用基础模型，然后过渡到高效的蒸馏模型。

**Result:** 实验证明，通过在第一个关键时间步使用基础模型，然后切换到蒸馏模型的简单修改，不仅恢复了从基础模型到蒸馏模型的多样性能力，甚至超出了它，同时保持了接近蒸馏推理的计算效率，并且无需额外的训练或模型修改。

**Conclusion:** 本文成功解决了蒸馏扩散模型中多样性下降的问题，通过控制蒸馏和一种创新的混合推理方法（多样性蒸馏），在不牺牲计算效率和不额外训练的情况下，显著提升了蒸馏模型的样本多样性，并揭示了多样性下降的机制。

> **ai_Abstract:** 本文解决了蒸馏扩散模型中样本多样性降低的问题。研究发现蒸馏模型保留了基础模型的概念表征，并提出了“控制蒸馏”实现控制机制的无缝迁移。通过$\hat{\mathbf{x}}_{0}$可视化，揭示了初始扩散时间步对多样性至关重要。基于此，引入了“多样性蒸馏”——一种混合推理方法，即在第一个关键时间步使用基础模型，随后切换到蒸馏模型。实验证明，该方法在不额外训练的情况下，显著提升了蒸馏模型的样本多样性，甚至超越了基础模型，同时保持了高计算效率。

> **摘要翻译:** 蒸馏扩散模型存在一个关键限制：与基础模型相比，样本多样性降低。在这项工作中，我们发现尽管存在这种多样性损失，蒸馏模型保留了基础模型的根本概念表征。我们展示了控制蒸馏——在基础模型上训练的控制机制，如概念滑块（Concept Sliders）和LoRA，可以无缝地转移到蒸馏模型，反之亦然，有效地在无需任何再训练的情况下蒸馏了控制。这种表征结构的保留促使我们深入研究蒸馏过程中样本多样性崩溃的机制。为了理解蒸馏如何影响多样性，我们利用$\hat{\mathbf{x}}_{0}$可视化作为分析和调试工具，揭示模型如何在中间步骤预测最终输出。通过$\hat{\mathbf{x}}_{0}$可视化，我们识别了生成伪影、不一致性，并证明初始扩散时间步不成比例地决定了输出多样性，而后续步骤主要用于细化细节。基于这些见解，我们引入了多样性蒸馏——一种混合推理方法，它策略性地仅在第一个关键时间步使用基础模型，然后过渡到高效的蒸馏模型。我们的实验表明，这种简单的修改不仅恢复了从基础模型到蒸馏模型的多样性能力，而且令人惊讶地超越了它，同时保持了接近蒸馏推理的计算效率，所有这些都无需额外的训练或模型修改。我们的代码和数据可在https://distillation.baulab.info/获取。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [250] [Scaling Recommender Transformers to One Billion Parameters](https://arxiv.org/abs/2507.15994)
> *将推荐系统Transformer模型扩展到十亿参数*

*Kirill Khrylchenko, Artem Matveev, Sergei Makeev, Vladimir Baikalov* | **Category: cs.IR** | **Updated: 2025-07-21**

**Keywords:** Transformer, 推荐系统, 大规模模型, 自回归学习, 在线A/B测试

**Comment:** To be submitted

> **TL;DR:** 本文提出了一种训练十亿参数级大型Transformer推荐模型的方法，通过将用户历史上的自回归学习分解为反馈预测和下一项预测两个子任务，并成功部署到大型音乐平台，显著提升了用户互动。

**AI_Comments:** 该论文的创新之处在于成功地将Transformer模型扩展到了推荐系统领域前所未有的十亿参数规模，这对于解决推荐系统中的冷启动、长尾问题以及捕捉复杂用户行为模式具有重要意义。通过将自回归学习分解为两个子任务，提供了一种有效的扩展策略。其在大型音乐平台上的实际部署和显著的性能提升，充分证明了该方法的有效性和实用价值，为未来的大规模推荐系统研究和应用提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型Transformer模型在NLP、CV和语音处理等领域取得了巨大成功，但将Transformer扩展到推荐系统仍然是一个挑战。现有的生成式推荐模型（如HSTU）最大也仅有1.76亿参数，远小于现代语言模型动辄千亿万亿的参数量，这促使研究者探索如何训练更大规模的推荐Transformer模型。

**Method:** 本文提出了一种训练十亿参数级大型Transformer推荐模型的方法。核心思想是将用户历史上的自回归学习自然地分解为两个子任务：反馈预测和下一项预测。这种分解被证明可以有效地扩展到各种Transformer模型尺寸。研究者还成功地将该架构部署到一个服务数百万用户的大型音乐平台。

**Result:** 本文成功训练了一个拥有高达十亿参数的Transformer推荐模型。在线A/B测试结果显示，该新模型使总听歌时长增加了+2.26%，用户点赞的可能性提高了+6.37%。据作者称，这是该平台历史上基于深度学习系统在推荐质量方面报告的最大改进。

**Conclusion:** 本文证明了通过将自回归学习分解为反馈预测和下一项预测，可以有效地将Transformer推荐模型扩展到十亿参数级别。所提出的架构在实际部署中显著提升了用户参与度和推荐质量，达到了平台历史上的最佳表现。

> **ai_Abstract:** 本文提出了一种将推荐系统中的Transformer模型扩展到十亿参数的方法。通过将用户历史上的自回归学习分解为反馈预测和下一项预测两个子任务，研究人员成功训练并部署了大型Transformer推荐器。该模型在一个大型音乐平台上的在线A/B测试中表现出色，显著提升了用户总听歌时长和点赞率，实现了平台历史上深度学习推荐系统的最大改进。

> **摘要翻译:** 虽然大型Transformer模型已成功应用于自然语言处理、计算机视觉和语音处理等许多实际应用中，但将Transformer模型扩展到推荐系统仍然是一个具有挑战性的问题。最近，生成式推荐器框架被提出，旨在超越典型的深度学习推荐模型（DLRMs）的规模。将推荐重构为序列转换任务，在计算方面改善了扩展特性。然而，HSTU作者报告的最大编码器配置仅为约1.76亿参数，这远小于现代语言模型中常见的数千亿甚至数万亿参数。
在这项工作中，我们提出了一种训练具有多达十亿参数的大型Transformer推荐器的方法。我们展示了用户历史上的自回归学习自然地分解为两个子任务：反馈预测和下一项预测，并证明了这种分解可以有效地扩展到各种Transformer尺寸。此外，我们报告了我们提出的架构已成功部署到一个服务数百万用户的大型音乐平台。根据我们的在线A/B测试，这个新模型使总听歌时长增加了+2.26%，并使用户点赞的可能性提高了+6.37%，这（据我们所知）构成了该平台历史上任何基于深度学习系统的推荐质量报告中最大的改进。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [289] [Reinforce Lifelong Interaction Value of User-Author Pairs for Large-Scale Recommendation Systems](https://arxiv.org/abs/2507.16253)
> *为大规模推荐系统强化用户-作者对的终身互动价值*

*Yisha Li, Lexi Gao, Jingxin Liu, Xiang Gao, Xin Li, Haiyang Lu, Liyin Hong* | **Category: cs.IR** | **Updated: 2025-07-22**

**Keywords:** 强化学习, 推荐系统, 终身互动价值, 用户-作者对, 多任务学习

**Comment:** 

> **TL;DR:** 本文提出RLIV-UA模型，通过强化学习优化大规模推荐系统中用户-作者对的终身互动价值，引入SCRI-MDP、ASA和MTCL等方法处理稀疏和长间隔互动，并在实验中取得了更高的用户满意度和平台利润。

**AI_Comments:** 本文的创新之处在于其关注点从传统的用户即时反馈或长期用户参与度转移到用户-作者对的终身互动价值，这对于社交平台生态系统的健康发展具有重要意义。通过引入强化学习并针对大规模和稀疏互动环境设计了SCRI-MDP、ASA和MTCL等创新方法，有效解决了实际应用中的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大多数推荐系统研究倾向于关注用户即时反馈或长期参与度，但忽略了作者的影响以及用户-作者对的终身互动价值（LIV），这对于提高短视频平台社交社区的繁荣至关重要。

**Method:** 本文引入强化学习（RL）来强化用户-作者对的终身互动价值（RLIV-UA）。为解决用户-作者互动间隔长和空间规模大的问题，提出了稀疏跨请求互动马尔可夫决策过程（SCRI-MDP），并引入邻近状态近似（ASA）方法来构建RL训练样本。此外，引入多任务评论学习（MTCL）来捕捉用户-作者互动（点击->关注->打赏）的渐进性，利用更密集的互动信号来弥补稀疏标签的学习。最后，设计了一个辅助监督学习任务来增强RLIV-UA模型的收敛性。

**Result:** 在离线实验和在线A/B测试中，RLIV-UA模型比对比方法取得了更高的用户满意度和更高的平台利润。

**Conclusion:** RLIV-UA模型通过优化用户-作者对的终身互动价值，有效提升了大规模推荐系统的用户满意度和平台利润。

> **ai_Abstract:** 本文针对大规模推荐系统中被忽视的用户-作者对的终身互动价值（LIV）进行了研究，该价值对社交社区的繁荣至关重要。研究提出了一种基于强化学习的RLIV-UA模型来优化此价值。为解决用户-作者互动稀疏和间隔长的问题，模型引入了稀疏跨请求互动马尔可夫决策过程（SCRI-MDP）和邻近状态近似（ASA）方法来构建训练样本。此外，采用多任务评论学习（MTCL）利用更密集的互动信号（如点击、关注、打赏）来辅助稀疏标签的学习，并通过辅助监督学习任务增强模型收敛性。实验结果表明，RLIV-UA模型在用户满意度和平台利润方面均优于现有方法。

> **摘要翻译:** 推荐系统（RS）帮助用户找到感兴趣的内容并将作者与目标受众连接起来。大多数RS研究倾向于关注准确预测用户的即时反馈（如点击率）或提高用户的长期参与度。然而，它们忽略了对作者的影响以及用户-作者对的终身互动价值（LIV），这对于提高短视频平台社交社区的繁荣尤为关键。目前，强化学习（RL）可以优化长期利益，并已广泛应用于RS中。在本文中，我们引入RL来强化用户-作者对的终身互动价值（RLIV-UA），基于用户-作者对的每次互动。为了解决用户-作者互动之间长间隔和用户-作者空间规模大的问题，我们提出了一种新颖的稀疏跨请求互动马尔可夫决策过程（SCRI-MDP），并引入邻近状态近似（ASA）方法来构建RL训练样本。此外，我们引入多任务评论学习（MTCL）来捕捉用户-作者互动（点击 -> 关注 -> 打赏）的渐进性，其中利用更密集的互动信号来弥补稀疏标签的学习。最后，设计了一个辅助监督学习任务来增强RLIV-UA模型的收敛性。在离线实验和在线A/B测试中，RLIV-UA模型比对比方法取得了更高的用户满意度和更高的平台利润。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [319] [Enhancing patent retrieval using automated patent summarization](https://arxiv.org/abs/2507.16371)
> *利用自动化专利摘要增强专利检索*

*Eleni Kamateri, Renukswamy Chikkamath, Michail Salampasis, Linda Andersson, Markus Endres* | **Category: cs.IR** | **Updated: 2025-07-22**

**Keywords:** 专利检索, 自动化摘要, 查询构建, 信息检索, 现有技术检索

**Comment:** This version was submitted and accepted for publication at the 6th
  Workshop on Patent Text Mining and Semantic Technologies (PatentSemTech
  2025), held in conjunction with SIGIR 2025. A revised and polished version,
  incorporating reviewers' feedback, will follow

> **TL;DR:** 通过自动化专利摘要来改进专利检索。

**AI_Comments:** 该论文的创新之处在于利用自动化摘要作为专利检索的查询，这为解决长文档信息检索中的查询构建难题提供了一种新颖且高效的方法。这有望显著简化专利检索过程，提高效率。

<details>
  <summary>Details</summary>

**Motivation:** 在长文档信息检索（特别是专利检索）中，有效的查询构建是一个关键挑战，因为专利文档冗长、语言复杂且包含多个相互关联的技术主题。

**Method:** 本研究应用了最新的抽取式和抽象式摘要方法来生成专利文档的简洁、特定用途的摘要。进一步评估了这些自动生成的摘要作为替代查询在三个基准专利数据集上的效用，并将其检索性能与使用整个专利部分的传统方法进行了比较。

**Result:** 实验结果表明，基于摘要的查询显著提高了现有技术检索的有效性。

**Conclusion:** 基于摘要的查询作为传统查询构建技术的一种高效替代方案，具有巨大潜力。

> **ai_Abstract:** 本研究旨在解决专利检索中查询构建的挑战，提出使用自动生成的专利摘要作为替代查询。论文应用了抽取式和抽象式摘要方法来创建专利文档的简洁摘要，并在三个基准数据集上评估了这些摘要作为查询的有效性。实验结果表明，与使用整个专利部分的传统方法相比，基于摘要的查询显著提高了现有技术检索的性能，证明了其作为高效查询构建替代方案的潜力。

> **摘要翻译:** 有效查询构建是长文档信息检索（IR）中的一个关键挑战。在专利检索等特定领域背景下，这一挑战尤为突出，因为文档冗长、语言复杂且涵盖多个相互关联的技术主题。在这项工作中，我们介绍了最新抽取式和抽象式摘要方法在生成专利文档简洁、特定用途摘要方面的应用。我们进一步评估了这些自动生成的摘要作为替代查询在三个基准专利数据集上的效用，并将其检索性能与使用整个专利部分的传统方法进行了比较。实验结果表明，基于摘要的查询显著提高了现有技术检索的有效性，突出了它们作为传统查询构建技术的一种高效替代方案的潜力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [351] [Generating Search Explanations using Large Language Models](https://arxiv.org/abs/2507.16692)
> *使用大型语言模型生成搜索解释*

*Arif Laksito, Mark Stevenson* | **Category: cs.IR** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 搜索解释, 编码器-解码器, 仅解码器, 信息检索

**Comment:** Extended Abstract - Workshop on Explainability in Information
  Retrieval (WExIR), SIGIR 2025

> **TL;DR:** 本研究探讨并证明了大型语言模型在生成搜索结果解释方面的有效性，其解释比基线模型更准确、更合理。

**AI_Comments:** 该研究首次探索了大型语言模型在生成搜索解释方面的应用，并展示了其超越传统基线模型的性能，为搜索解释生成提供了一个新的、有前景的方向。其创新点在于将LLMs应用于一个未被充分探索的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究尚未充分探索大型语言模型在生成搜索结果解释方面的潜力，而这些解释对于用户高效定位信息至关重要。本研究旨在填补这一空白。

**Method:** 本研究利用编码器-解码器和仅解码器的大型语言模型来生成搜索结果的解释。

**Result:** 生成解释的准确性和合理性始终高于一系列基线模型。

**Conclusion:** 大型语言模型能够生成比现有基线模型更准确、更合理的搜索结果解释，表明其在该领域具有应用潜力。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在生成搜索结果解释方面的应用潜力，以填补当前研究的空白。通过利用编码器-解码器和仅解码器LLMs，研究发现其生成的搜索解释比现有基线模型更准确和合理，证明了LLMs在该任务中的有效性。

> **摘要翻译:** 搜索结果中面向方面的解释通常是与检索到的文档一起放置的简洁文本片段，作为解释来帮助用户高效地定位相关信息。尽管大型语言模型（LLMs）在一系列问题中表现出卓越的性能，但它们生成搜索结果解释的潜力尚未被探索。本研究通过利用编码器-解码器和仅解码器的大型语言模型来生成搜索结果的解释，解决了这一空白。生成的解释始终比一系列基线模型产生的解释更准确、更合理。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [381] [Biases in LLM-Generated Musical Taste Profiles for Recommendation](https://arxiv.org/abs/2507.16708)
> *LLM生成的音乐品味档案在推荐中的偏见*

*Bruno Sguerra, Elena V. Epure, Harin Lee, Manuel Moussallam* | **Category: cs.IR** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 推荐系统, 用户品味档案, 偏见, 音乐推荐

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型（LLM）在音乐推荐中生成用户品味档案时可能存在的偏见及其对信任和可用性的影响。

**AI_Comments:** 本文创新性地探讨了LLM在推荐系统中生成用户品味档案的应用，并深入分析了其潜在的偏见问题，这对于提升个性化系统的透明度、用户信任和公平性具有重要意义。研究通过用户实验验证了偏见的存在，为LLM在实际推荐系统中的部署提供了关键的考量。

<details>
  <summary>Details</summary>

**Motivation:** LLM生成的自然语言用户品味档案为不透明的协同过滤提供了可解释和可编辑的替代方案，但用户对其准确性存在疑问，且LLM继承的社会和数据偏见可能导致档案质量因用户和物品特征而系统性地变化，从而影响信任和可用性。

**Method:** 研究在音乐流媒体背景下进行了一项用户研究，参与者对根据其收听历史生成的自然语言档案进行评分。分析了档案认同是否受到用户属性（如主流性、品味多样性）和物品特征（如流派、原产国）的偏见影响，并将这些模式与下游推荐任务中观察到的模式进行了比较。

**Result:** 研究结果揭示了LLM生成的可审查档案在个性化系统中的潜力和局限性。

**Conclusion:** 本文强调了LLM生成的用户品味档案在个性化系统中的潜力和局限性，特别是在存在偏见的情况下，这对于确保推荐系统的信任和可用性至关重要。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）在音乐推荐中生成用户品味档案时可能存在的偏见问题。研究通过一项用户实验，评估了用户对LLM生成的自然语言品味档案的认同度，并分析了用户属性（如主流性、品味多样性）和物品特征（如流派、原产国）如何影响这种认同，以及这些偏见在下游推荐任务中的表现。研究结果揭示了LLM生成可解释用户档案的潜力和局限性。

> **摘要翻译:** 大型语言模型（LLM）在推荐系统中的一个特别有前景的应用是根据消费数据自动生成自然语言（NL）用户品味档案。这些档案提供了可解释和可编辑的替代方案，以取代不透明的协同过滤表示，从而提高透明度和用户控制。然而，用户是否认为这些档案能准确代表其品味尚不清楚，而这对于信任和可用性至关重要。此外，由于LLM继承了社会和数据驱动的偏见，档案质量可能因用户和物品特征而系统性地变化。在本文中，我们在音乐流媒体的背景下研究了这个问题，其中个性化面临着庞大且文化多元的目录的挑战。我们进行了一项用户研究，参与者对根据其自身收听历史生成的自然语言档案进行了评分。我们分析了档案认同是否受到用户属性（例如，主流性、品味多样性）和物品特征（例如，流派、原产国）的偏见影响。我们还将这些模式与在下游推荐任务中使用档案时观察到的模式进行了比较。我们的研究结果强调了可审查的、基于LLM的档案在个性化系统中的潜力和局限性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [411] [Probing Ranking LLMs: A Mechanistic Analysis for Information Retrieval](https://arxiv.org/abs/2410.18527)
> *探测排序LLM：信息检索的机制分析*

*Tanya Chowdhury, Atharva Nijasure, James Allan* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 排序LLM, 信息检索, 机制分析, 特征提取, 可解释性

**Comment:** 9 pages

> **TL;DR:** 本研究通过探究排序LLM的内部机制，分析其神经元激活中编码的人工设计和语义特征，旨在提高排序模型的可解释性和有效性。

**AI_Comments:** 该论文通过对排序LLM进行机制分析，深入探讨了其内部特征提取过程。其创新点在于采用探测方法来量化LLM内部对人工设计特征的编码情况，这对于理解黑箱模型至关重要。研究结果揭示了LLM在信息检索任务中的优势和潜在不足，为模型解释性和可靠性提供了宝贵的见解。通过发布代码和脚本，也促进了社区的进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** Transformer网络，特别是与GPT模型性能相当的LLM，以其强大的特征提取能力而闻名，但这些提取特征的性质及其与人工设计特征的一致性仍未被探索。

**Method:** 本研究采用基于探测的分析方法，检查排序LLM中的神经元激活，以识别已知的人工设计和语义特征的存在。研究涵盖了广泛的特征类别，包括词汇信号、文档结构、查询-文档交互和复杂的语义表示，并在四种不同的排序LLM上进行了实验。

**Result:** 研究识别出LLM激活中显著编码的统计信息检索（IR）特征，以及明显缺失的特征。此外，分析了模型对分布外查询和文档的响应，揭示了不同的泛化行为。

**Conclusion:** 通过剖析LLM激活中的潜在表示，旨在提高排序模型的可解释性和有效性。研究结果为开发更透明和可靠的检索系统提供了重要见解。

> **ai_Abstract:** 本研究深入分析了用于信息检索的排序大型语言模型（LLM）的内部机制。通过探测LLM的神经元激活，研究识别了其中编码的人工设计和语义特征，涵盖了词汇、结构和语义等多个维度。实验结果揭示了LLM激活中显著存在和缺失的统计信息检索特征，并分析了模型在面对分布外数据时的泛化行为。最终，本研究旨在提高排序模型的可解释性和效率，为构建更透明可靠的检索系统提供关键见解。

> **摘要翻译:** Transformer网络，特别是那些性能可与GPT模型媲美的网络，以其强大的特征提取能力而闻名。然而，这些提取特征的性质及其与人工设计特征的一致性仍未被探索。在这项工作中，我们研究了用于段落重排序的最先进的、经过微调的LLM的内部机制。我们采用基于探测的分析方法来检查排序LLM中的神经元激活，识别已知的人工设计和语义特征的存在。我们的研究涵盖了广泛的特征类别，包括词汇信号、文档结构、查询-文档交互和复杂的语义表示，以揭示影响排序决策的潜在模式。通过在四种不同的排序LLM上进行的实验，我们识别出在LLM激活中显著编码的统计IR特征，以及其他明显缺失的特征。此外，我们分析了这些模型如何响应分布外查询和文档，揭示了独特的泛化行为。通过剖析LLM激活中的潜在表示，我们旨在提高排序模型的可解释性和有效性。我们的发现为开发更透明和可靠的检索系统提供了重要见解，并且我们发布了所有必要的脚本和代码以支持进一步的探索。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [441] [Cross-Encoder Rediscovers a Semantic Variant of BM25](https://arxiv.org/abs/2502.04645)
> *交叉编码器重新发现BM25的语义变体*

*Meng Lu, Catherine Chen, Carsten Eickhoff* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 交叉编码器, BM25, 语义变体, 信息检索, 神经网络排序模型

**Comment:** 

> **TL;DR:** 研究发现，交叉编码器（Cross-Encoder）通过Transformer注意力头和嵌入矩阵的低秩组件，以可解释的方式实现了传统BM25的语义变体，从而提升了信息检索性能。

**AI_Comments:** 这项研究通过揭示交叉编码器与传统BM25之间的深层联系，为神经网络排序模型的内部机制提供了宝贵的解释性见解。它不仅解释了为什么这些模型表现优异，还为未来的模型编辑、增强透明度和解决实际应用中的安全及可扩展性问题奠定了基础，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了理解神经网络排序模型（NRMs）中交叉编码器（Cross-Encoder）优越性能的原因，本研究旨在调查一个MiniLM的交叉编码器变体计算哪些相关性特征以及这些特征存储在哪里。

**Method:** 本研究调查了一个MiniLM的交叉编码器变体，分析其内部机制，以确定它如何计算和存储相关性特征。

**Result:** 研究发现，该交叉编码器以可解释的方式采用了传统BM25的语义变体。具体表现为：1) Transformer注意力头计算软词频并控制词饱和度与文档长度效应；2) 其嵌入矩阵的低秩组件编码词汇表的逆文档频率信息。

**Conclusion:** 交叉编码器使用了与BM25相同的基本机制，但进一步利用其捕获语义的能力来提高检索性能。这种细粒度的理解为模型编辑奠定了基础，以增强模型透明度、解决安全问题并提高训练和实际应用的扩展性。

> **ai_Abstract:** 本文深入探究了MiniLM的一个交叉编码器变体，旨在揭示其如何计算和存储相关性特征。研究发现，该模型巧妙地融合了传统BM25的语义变体，具体通过Transformer注意力头处理软词频并调整文档长度效应，以及嵌入矩阵的低秩部分编码逆文档频率信息。这表明交叉编码器在继承BM25核心机制的基础上，进一步利用其语义理解能力显著提升了信息检索性能。这项工作为提高模型透明度、解决安全隐患以及优化训练和应用的可扩展性提供了重要的理论基础。

> **摘要翻译:** 神经网络排序模型（NRMs）在信息检索任务上迅速提升了最先进的性能。在这项工作中，我们研究了MiniLM的一个交叉编码器变体，以确定它计算哪些相关性特征以及它们存储在哪里。我们发现它以可解释的方式采用了传统BM25的语义变体，具有局部化的组件：(1) Transformer注意力头计算软词频，同时控制词饱和度与文档长度效应；(2) 其嵌入矩阵的低秩组件编码词汇表的逆文档频率信息。这表明交叉编码器使用了与BM25相同的基本机制，但进一步利用其捕获语义的能力来提高检索性能。这种细粒度的理解为模型编辑奠定了基础，以增强模型透明度，解决安全问题，并提高训练和实际应用中的可扩展性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [536] [LLM-Enhanced Reranking for Complementary Product Recommendation](https://arxiv.org/abs/2507.16237)
> *基于LLM增强的互补商品推荐重排序*

*Zekun Xu, Yudi Zhang* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 互补商品推荐, 大型语言模型, 重排序, 准确性, 多样性

**Comment:** 

> **TL;DR:** 本文提出了一种模型无关的方法，利用大型语言模型（LLMs）直接对现有推荐模型检索到的互补商品候选列表进行重排序，有效提升了推荐的准确性和多样性，且无需模型再训练。

**AI_Comments:** 该论文的创新点在于其模型无关性以及将LLM直接应用于推荐系统的重排序阶段，而非仅仅用于数据预处理。这种方法避免了模型再训练的成本，同时在准确性和多样性之间取得了更好的平衡，对于电商推荐系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 互补商品推荐是电商领域中一项重要但具有挑战性的任务。尽管现有的图神经网络（GNN）方法在捕捉复杂商品关系方面取得了显著进展，但它们在准确性-多样性权衡方面常常遇到困难，尤其对于长尾商品。

**Method:** 本文提出了一种模型无关的方法，利用大型语言模型（LLMs）来增强互补商品推荐的重排序。与以往将LLMs用于数据预处理和图增强不同，我们的方法直接将基于LLM的提示策略应用于从现有推荐模型中检索到的候选商品的重排序，从而无需进行模型再训练。

**Result:** 通过在公共数据集上进行的广泛实验表明，我们的方法有效地平衡了互补商品推荐的准确性和多样性，在不同数据集上，对于排名前列的推荐商品，准确性指标平均提升至少50%，多样性指标平均提升2%。

**Conclusion:** 该方法通过LLM增强的重排序，在不进行模型再训练的情况下，显著提升了互补商品推荐的准确性和多样性。

> **ai_Abstract:** 本文提出了一种创新的模型无关方法，利用大型语言模型（LLMs）直接对现有推荐模型生成的互补商品候选列表进行重排序。该方法通过LLM驱动的提示策略，有效解决了传统GNN方法在互补商品推荐中面临的准确性与多样性权衡问题，尤其对长尾商品表现更佳，且无需对基础推荐模型进行再训练。实验结果表明，该方法显著提升了推荐的准确性和多样性。

> **摘要翻译:** 互补商品推荐旨在推荐一起使用以提升客户价值的商品，是电子商务中一项关键但具有挑战性的任务。尽管现有的图神经网络（GNN）方法在捕捉复杂商品关系方面取得了显著进展，但它们常常在准确性-多样性权衡方面遇到困难，特别是对于长尾商品。本文介绍了一种模型无关的方法，利用大型语言模型（LLMs）来增强互补商品推荐的重排序。与以往主要将LLMs用于数据预处理和图增强的工作不同，我们的方法直接将基于LLM的提示策略应用于从现有推荐模型中检索到的候选商品的重排序，从而无需进行模型再训练。通过在公共数据集上进行的广泛实验，我们证明了我们的方法有效地平衡了互补商品推荐的准确性和多样性，在不同数据集上，对于排名前列的推荐商品，准确性指标平均提升至少50%，多样性指标平均提升2%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [620] [Time to Split: Exploring Data Splitting Strategies for Offline Evaluation of Sequential Recommenders](https://arxiv.org/abs/2507.16289)
> *是时候拆分了：探索序列推荐器离线评估的数据拆分策略*

*Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, Evgeny Frolov* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 序列推荐, 数据拆分, 离线评估, 时间泄露, 可复现性

**Comment:** Accepted for ACM RecSys 2025. Author's version. The final published
  version will be available at the ACM Digital Library

> **TL;DR:** 本文探讨了序列推荐系统中数据拆分策略对离线评估结果的显著影响，并指出当前常用的拆分方法可能与实际场景不符，强调了选择合适拆分策略的重要性。

**AI_Comments:** 本文的创新点在于系统性地揭示了序列推荐系统离线评估中数据拆分策略的巨大影响，挑战了业界和学术界普遍采用的留一法。其重要性在于，研究结果直接影响模型评估的可靠性和实际部署的决策，为未来的研究和实践提供了重要的指导，强调了评估协议与真实世界场景对齐的必要性。论文提供了代码库，增强了研究的可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现代序列推荐系统性能强大，但在评估协议方面仍不完善。常用的留一法（leave-one-out）存在训练集与测试集时间重叠、时间泄露和测试周期过长的问题，限制了其在现实世界中的相关性。全局时间拆分（Global temporal splitting）虽然能解决这些问题，但在序列推荐中的应用定义不明确，特别是在选择目标交互和构建验证子集方面。因此，需要系统地研究不同的数据拆分策略对评估结果的影响。

**Method:** 本文通过在多个数据集和已建立的基线上系统比较了不同的数据拆分策略，以评估其对序列推荐系统离线评估结果的影响。研究方法侧重于展示不同拆分策略如何影响模型排名和实际部署决策。

**Result:** 评估结果在不同拆分策略之间存在显著差异，这会影响模型的排名和实际部署决策。研究发现，诸如留一法等流行的数据拆分策略可能与更现实的评估策略不充分对齐。

**Conclusion:** 本文的结论是，在序列推荐系统的离线评估中，数据拆分策略的选择至关重要，因为它显著影响评估结果、模型排名和实际部署决策。为了提高学术界和工业界的可复现性，需要采用更贴近现实场景的评估策略，而非仅仅依赖于如留一法等可能不够现实的流行方法。

> **ai_Abstract:** 本文探讨了序列推荐系统离线评估中数据拆分策略的重要性。研究指出，当前常用的评估协议，如留一法，存在时间泄露和与现实场景不符的问题。虽然全局时间拆分能部分解决这些问题，但其应用仍缺乏明确定义。作者系统比较了不同拆分策略在多个数据集上的影响，发现不同的策略会导致评估结果和模型排名的显著差异，并强调了选择与现实场景更匹配的评估策略对提高可复现性和实际部署决策的关键作用。

> **摘要翻译:** 现代序列推荐系统，从轻量级基于Transformer的变体到大型语言模型，因其在下一个项目预测任务中的强大性能，在学术界和工业界变得越来越突出。然而，序列推荐的常见评估协议仍然不够完善：它们常常未能准确反映相应的推荐任务，或者与现实世界场景不符。
尽管广泛使用的留一法拆分与下一个项目预测相匹配，但它允许训练和测试周期之间存在重叠，这导致了时间泄露和不切实际的过长测试周期，限制了现实世界的相关性。全局时间拆分通过在不同的未来周期进行评估来解决这些问题。然而，其在序列推荐中的应用定义仍然松散，特别是在选择目标交互和构建验证子集方面，这需要验证和测试指标之间提供必要的M一致性。
在本文中，我们证明了评估结果在不同拆分策略之间可能存在显著差异，影响模型排名和实际部署决策。为了提高学术界和工业界的可复现性，我们系统地比较了序列推荐在多个数据集和已建立的基线上的不同拆分策略。我们的研究结果表明，流行的拆分方法，如留一法，可能与更现实的评估策略不充分对齐。代码：https://github.com/monkey0head/time-to-split

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [98] [Beyond Rate Coding: Surrogate Gradients Enable Spike Timing Learning in Spiking Neural Networks](https://arxiv.org/abs/2507.16043)
> *越过速率编码：替代梯度使脉冲神经网络中的尖峰时序学习成为可能*

*Ziqiao Yu, Pengfei Sun, Dan F. M. Goodman* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 脉冲神经网络, 替代梯度下降, 尖峰时序, 时间编码, 语音识别

**Comment:** 

> **TL;DR:** 本文研究了使用替代梯度下降训练的脉冲神经网络（SNNs）如何利用精确的尖峰时序进行学习，超越了传统的速率编码。研究表明，SNNs在仅有时序信息的任务上表现出色，且对生物学扰动具有一定鲁棒性，并揭示了延迟训练的网络在时间处理上的类人行为。

**AI_Comments:** 这篇论文通过实验证明了替代梯度下降在使脉冲神经网络学习精确尖峰时序方面的有效性，这超越了传统的速率编码范式。其创新之处在于，不仅设计了巧妙的实验来隔离和测试时序信息学习，还通过构建仅含时序信息的变体数据集（SHD和SSC）来验证其方法，并将其开源，极大地促进了该领域的研究。此外，对生物学扰动和时间反转的鲁棒性分析也为SNNs的实际应用和生物学 plausibility 提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨使用替代梯度下降（Surrogate GD）训练的脉冲神经网络（SNNs），在有无延迟学习的情况下，能否超越发放速率，从精确的尖峰时序中学习。

**Method:** 研究首先设计了合成任务，用于隔离神经元内尖峰间隔和跨神经元同步，并保持尖峰计数匹配。随后，在尖峰语音识别数据集（SHD和SSC）上，构建了去除尖峰计数信息、仅保留时序信息的变体。最后，评估了网络在生物学启发扰动（如高斯抖动和尖峰删除）下的鲁棒性。

**Result:** 研究发现，通过替代梯度下降训练的SNNs在仅有时序信息的任务上表现显著高于随机水平，而纯粹基于速率的模型则处于随机水平。网络在生物学扰动下显示出一致但特定于扰动的性能下降。当尖峰序列时间反转时，网络性能急剧下降，其中带有延迟训练的SNNs下降幅度更大。

**Conclusion:** 替代梯度下降能够有效使脉冲神经网络学习和利用精确的尖峰时序信息。带有延迟训练的SNNs在处理时间反转的尖峰序列时，表现出更接近人类的行为特性。

> **ai_Abstract:** 本文探讨了脉冲神经网络（SNNs）在替代梯度下降（Surrogate GD）训练下，利用精确尖峰时序信息进行学习的能力。研究者通过合成任务和修改的语音识别数据集（SHD, SSC），证明了SNNs在仅有时序信息的情况下仍能显著优于基于速率的模型。同时，研究评估了网络在生物学扰动下的鲁棒性，并发现带有延迟训练的SNNs在处理时间反转时表现出更接近人类的特性。为推动时间编码研究，作者还发布了修改后的数据集。

> **摘要翻译:** 我们研究了使用替代梯度下降（Surrogate GD）训练的脉冲神经网络（SNNs），无论是否包含延迟学习，能在多大程度上超越发放速率，从精确的尖峰时序中学习。我们首先设计了合成任务，在匹配尖峰计数的情况下，分离神经元内尖峰间隔和跨神经元同步。在更复杂的基于尖峰的语音识别数据集（Spiking Heidelberg Digits (SHD) 和 Spiking Speech Commands (SSC)）上，我们构建了消除了尖峰计数信息而仅保留时序信息的变体，并显示出由替代梯度下降训练的SNNs能够显著高于随机水平地执行任务，而纯粹基于速率的模型则处于随机水平。我们进一步评估了在生物学启发扰动（包括每个尖峰或每个神经元的高斯抖动，以及尖峰删除）下的鲁棒性，揭示了一致但特定于扰动的性能下降。当尖峰序列时间反转时，网络性能出现急剧下降，其中通过延迟训练的SNNs下降更大，这表明这些网络在行为上更像人类。为了促进对时间编码的进一步研究，我们发布了我们修改后的SHD和SSC数据集。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [324] [Assessing an evolutionary search engine for small language models, prompts, and evaluation metrics](https://arxiv.org/abs/2506.21512)
> *评估一种用于小型语言模型、提示和评估指标的演化搜索引擎*

*Cláudio Lúcio do Val Lopes, Lucca Machado* | **Category: cs.NE** | **Updated: 2025-07-21**

**Keywords:** 小型语言模型, 演化搜索, 提示工程, 多目标优化, NSGA-II

**Comment:** 14 pages, 1 figure, 1 table

> **TL;DR:** 本文介绍并评估了一种双目标演化搜索引擎，利用NSGA-II算法优化小型语言模型（SLMs）和指令提示，旨在同时提高任务准确性和token效率，并成功识别了高性能组合，揭示了性能与成本之间的权衡。

**AI_Comments:** 该研究通过引入双目标演化搜索引擎，为SLM和提示的联合优化提供了一种新颖的自动化方法，克服了传统手动调优的局限性。其创新点在于同时考虑了性能和计算成本，并利用NSGA-II生成了实用的帕累托前沿，为实际部署提供了灵活的决策支持。这对于提高AI系统的效率和可部署性具有重要意义，并为未来人机交互模式的发现奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前语言模型和指令提示的同步优化面临巨大挑战，尤其是在平衡性能与计算成本（如token使用量）时，这阻碍了高效AI系统的部署。

**Method:** 本文引入并评估了一个双目标演化搜索引擎，专门用于小型语言模型（SLMs）。该方法采用NSGA-II算法和提示语法，在推理任务中同时优化任务准确性和token效率。

**Result:** 研究成功识别了多样化的高性能模型-提示组合，并量化揭示了任务准确性和token效率之间的关键权衡。此外，研究还突出了特定SLM和提示结构（如指令、上下文、思维链）之间的任务特异性亲和力。生成的实用帕累托前沿为决策者提供了可适应其特定约束的优化解决方案组合。

**Conclusion:** 这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了一个基础框架。

> **ai_Abstract:** 本文引入并评估了一个双目标演化搜索引擎，旨在解决小型语言模型（SLMs）和指令提示的同步优化挑战，尤其是在平衡性能与计算成本方面。该引擎利用NSGA-II算法和提示语法，在推理任务中同时优化任务准确性和token效率。研究成功识别了多样化的高性能模型-提示组合，并量化揭示了准确性和效率之间的关键权衡，同时突出了SLM与特定提示结构的任务特异性亲和力。生成的帕累托前沿为决策者提供了灵活的优化解决方案，标志着从传统手动调优向自动化发现有效人机交互模式的转变。

> **摘要翻译:** 并发优化语言模型和指令提示对部署高效且有效的AI系统提出了重大挑战，尤其是在平衡性能与计算成本（如token使用量）时。本文介绍并评估了一个双目标演化搜索引擎，旨在解决这个复杂的空间，特别关注小型语言模型（SLMs）。我们采用NSGA-II算法和提示语法，在一些推理任务中同时优化任务准确性和token效率。我们的结果成功识别了多样化的高性能模型-提示组合，定量揭示了两个目标之间的关键权衡。这项研究强调了特定SLM和提示结构（例如指令、上下文、思维链）之间任务特异性亲和力。生成的实用帕累托前沿为决策者提供了一系列可适应其特定约束的优化解决方案。这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了一个基础框架。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [5] [Time integration of dissipative stochastic PDEs](https://arxiv.org/abs/2507.16658)
> *耗散随机偏微分方程的时间积分*

*Helena Biščević, Raffaele D'Ambrosio* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 随机偏微分方程, 时间积分, 均方耗散性, 随机θ-方法, 数值解

**Comment:** 

> **TL;DR:** 本文研究了耗散随机偏微分方程的数值解法，特别关注在时间积分中保持均方耗散性，并分析了随机θ-方法和随机θ-IMEX方法的守恒能力。

**AI_Comments:** 本文的创新之处在于其对随机偏微分方程数值解中均方耗散性守恒的深入分析，特别是对随机θ-方法和随机θ-IMEX方法的应用。这对于确保数值模拟的稳定性和准确性至关重要。研究强调了步长选择的重要性，为实际应用提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机是为随机反应扩散问题提供数值解，并特别关注在时间积分过程中保持空间离散化问题的均方耗散性。

**Method:** 本文采用有限差分法对空间进行离散化，并使用随机θ-方法和随机θ-IMEX方法进行时间积分。

**Result:** 分析结果表明，随机θ-方法和随机θ-IMEX方法具有均方耗散性守恒能力。数值实验也证实了理论预期，强调了空间和时间步长的作用。

**Conclusion:** 本文得出结论，随机θ-方法和随机θ-IMEX方法在对耗散随机偏微分方程进行时间积分时能够有效保持均方耗散性，且空间和时间步长在其中扮演重要角色。

> **ai_Abstract:** 本文研究了耗散随机偏微分方程的数值解，特别是随机反应扩散问题。研究着重于在空间离散化后，通过时间积分保持均方耗散性。分析发现，随机θ-方法和随机θ-IMEX方法在保持耗散性方面表现出色，并且空间和时间步长对结果有重要影响。数值实验验证了这些理论发现。

> **摘要翻译:** 本文重点关注随机反应扩散问题的数值解。特别关注在通过有限差分法获得的空间离散化问题的时间积分中保持均方耗散性。分析强调了随机θ-方法和随机θ-IMEX方法的守恒能力，并强调了空间和时间步长的作用。提供了一些数值实验，证实了理论预期。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [29] [The inverse initial data problem for anisotropic Navier-Stokes equations via Legendre time reduction method](https://arxiv.org/abs/2507.16810)
> *通过Legendre时间降维方法解决各向异性Navier-Stokes方程的逆初始数据问题*

*Cong B. Van, Thuy T. Le, Loc H. Nguyen* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 逆初始数据问题, 各向异性Navier-Stokes, Legendre时间降维, 速度场重建, 逆向建模

**Comment:** 

> **TL;DR:** 本文提出了一种基于Legendre时间降维的新型计算框架，用于从边界观测重建可压缩各向异性Navier-Stokes方程的初始速度场，并经数值实验验证其在噪声和复杂结构下仍能准确鲁棒地重建。

**AI_Comments:** 这项研究的创新之处在于引入了Legendre时间降维方法来解决复杂的逆初始数据问题，有效地将时间依赖问题转化为更易于处理的时间无关系统。其重要性体现在为无法直接测量的流体内部状态提供了一种有效的重建手段，特别是在存在噪声和各向异性介质的实际应用中展现出鲁棒性。该方法为流体动力学中的逆向建模提供了一个计算上可行且灵活的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 在流体内状态无法直接测量的应用中，需要从边界观测重建初始速度场，以解决可压缩各向异性Navier-Stokes方程的逆初始数据问题。

**Method:** 引入了一种基于Legendre时间降维的新型计算框架。该框架将速度场投影到时间上的指数加权Legendre基，将原始时间相关的逆问题转化为耦合的、时间无关的椭圆系统。所得的降维模型通过Picard迭代和在噪声边界数据下的稳定最小二乘公式迭代求解。

**Result:** 二维数值实验证实，该方法即使在存在显著测量噪声和复杂各向异性结构的情况下，也能准确、鲁棒地重建初始速度场。

**Conclusion:** 该方法为各向异性介质中流体动力学的逆向建模提供了一种灵活且计算上可行的方法。

> **ai_Abstract:** 本文针对可压缩各向异性Navier-Stokes方程的逆初始数据问题，提出了一种基于Legendre时间降维的新型计算框架。该框架通过将速度场投影到指数加权Legendre基，将时间相关的逆问题转化为时间无关的椭圆系统。该降维模型通过Picard迭代和稳定最小二乘法求解。数值实验表明，该方法在存在噪声和复杂结构的情况下，仍能准确鲁棒地重建初始速度场，为各向异性介质中的流体逆建模提供了一种可行方案。

> **摘要翻译:** 我们考虑可压缩各向异性Navier-Stokes方程的逆初始数据问题，目标是从侧向边界观测重建初始速度场。这个问题出现在内部流体状态无法直接测量的应用中。我们引入了一种基于Legendre时间降维的新型计算框架，该框架将速度场投影到时间上的指数加权Legendre基。这种变换将原始的时间相关逆问题简化为耦合的、时间无关的椭圆系统。由此产生的降维模型在噪声边界数据下使用Picard迭代和稳定的最小二乘公式进行迭代求解。二维数值实验证实，该方法即使在存在显著测量噪声和复杂各向异性结构的情况下，也能准确、鲁棒地重建初始速度场。这种方法为各向异性介质中流体动力学的逆向建模提供了一种灵活且计算上可行的方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [130] [Chebyshev symplectic methods based on continuous-stage Runge-Kutta methods](https://arxiv.org/abs/1805.11237)
> *切比雪夫辛方法基于连续阶段龙格-库塔方法*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 切比雪夫辛方法,切比雪夫正交多项式,连续阶段龙格-库塔方法,数值实验

**Comment:** The paper needs to be further modified

> **TL;DR:** 本文开发了基于切比雪夫正交多项式和加权连续阶段龙格-库塔方法理论的切比雪夫辛方法，并通过数值实验验证了其效率。

**AI_Comments:** 该研究的创新点在于结合切比雪夫正交多项式和加权连续阶段龙格-库塔方法理论来构建辛方法。其重要性在于开发了高效的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 开发新的切比雪夫辛方法，并利用新的理论方便地构建它们。

**Method:** 基于第一类和第二类切比雪夫正交多项式开发切比雪夫辛方法，并利用新构建的加权连续阶段龙格-库塔方法理论进行构建和验证。

**Result:** 数值实验验证了新方法的效率。

**Conclusion:** 新开发的切比雪夫辛方法是有效的。

> **ai_Abstract:** 本文提出了一种基于第一类和第二类切比雪夫正交多项式的切比雪夫辛方法，该方法利用新构建的加权连续阶段龙格-库塔方法理论进行构建，并通过数值实验验证了其高效性。

> **摘要翻译:** 我们在本文中分别基于第一类和第二类切比雪夫正交多项式开发了切比雪夫辛方法。这类辛方法可以利用新构建的加权连续阶段龙格-库塔方法理论方便地构建。通过一些数值实验很好地验证了我们新方法的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [154] [Symplectic integration with Jacobi polynomials](https://arxiv.org/abs/1806.03380)
> *基于雅可比多项式的辛积分*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 辛积分, 雅可比多项式, 哈密顿系统, 龙格-库塔方法, 数值实验

**Comment:** The paper needs to be further modified

> **TL;DR:** 本文研究了使用雅可比多项式对正则哈密顿系统进行辛积分的新方法，并通过数值实验验证了其效率。

**AI_Comments:** 该论文通过引入雅可比多项式来构建辛积分方法，为哈密顿系统的数值模拟提供了一种新的途径，可能在保持系统辛结构的同时提高计算效率。其与连续阶段龙格-库塔方法的联系也表明了其理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 研究基于雅可比多项式的正则哈密顿系统的辛积分方法。

**Method:** 首先回顾了连续阶段龙格-库塔方法的相关理论结果，然后建立了基于雅可比多项式的辛方法，并通过数值实验验证了其效率。

**Result:** 数值实验验证了新方法的效率。

**Conclusion:** 基于雅可比多项式建立的辛方法对正则哈密顿系统的积分是有效的。

> **ai_Abstract:** 本文研究了正则哈密顿系统的辛积分问题，并引入了基于雅可比多项式的新方法。文章首先回顾了连续阶段龙格-库塔方法的相关理论，随后建立了利用雅可比多项式的辛积分方法。通过数值实验，验证了这些新方法的有效性。

> **摘要翻译:** 在本文中，我们研究了基于雅可比多项式的正则哈密顿系统的辛积分。首先回顾了连续阶段龙格-库塔方法的相关理论结果，然后建立了基于雅可比多项式的辛方法。进行了一些数值实验以验证我们新方法的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [180] [Energy-preserving continuous-stage partitioned Runge-Kutta methods](https://arxiv.org/abs/1808.02391)
> *能量守恒的连续阶段分段Runge-Kutta方法*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 能量守恒, 连续阶段分段Runge-Kutta方法, 哈密顿系统, 充分条件, 数值积分

**Comment:** There are some drawbacks for this paper

> **TL;DR:** 本文提出了用于哈密顿系统能量守恒积分的连续阶段分段Runge-Kutta方法，并推导了一个能量守恒的充分条件，该条件推广了现有结果，且发现某些系数必须为1。

**AI_Comments:** 本文的创新点在于提出了能量守恒的csPRK方法，并推导了其普适的能量守恒条件，该条件推广了现有结果。特别是在高阶方法构建中，发现特定权重系数必须为1是一个有趣的理论发现。

<details>
  <summary>Details</summary>

**Motivation:** 为了对哈密顿系统进行能量守恒积分。

**Method:** 提出了连续阶段分段Runge-Kutta (csPRK) 方法，并推导了其能量守恒的充分条件。通过使用阶条件和归一化移位勒让德多项式的简化假设来构建高阶能量守恒的csPRK方法。

**Result:** 导出了csPRK方法能量守恒的充分条件，该条件包含了现有连续阶段Runge-Kutta方法能量守恒条件的特例。发现当使用阶条件和归一化移位勒让德多项式构建高阶能量守恒csPRK方法时，Butcher“权重”系数$B_\tau$和$\widehat{B}_\tau$都必须等于1。获得了新的能量守恒积分器，并通过数值实验验证了理论结果。

**Conclusion:** 本文成功提出了能量守恒的csPRK方法，并为其能量守恒提供了充分条件，通过理论推导和数值实验验证了其有效性。

> **ai_Abstract:** 本文介绍了一种新的连续阶段分段Runge-Kutta (csPRK) 方法，用于哈密顿系统的能量守恒积分。研究推导了csPRK方法能量守恒的充分条件，并指出该条件是现有连续阶段Runge-Kutta方法条件的推广。一个重要发现是，在特定条件下，高阶能量守恒csPRK方法的Butcher权重系数必须为1。通过新获得的积分器和数值实验验证了理论结果。

> **摘要翻译:** 在本文中，我们提出了用于哈密顿系统能量守恒积分的连续阶段分段Runge-Kutta (csPRK) 方法。推导了csPRK方法能量守恒的充分条件。结果表明，所提出的条件包含了现有能量守恒连续阶段Runge-Kutta方法的条件作为特例。一个值得注意且有趣的结果是，当我们使用阶条件和归一化移位勒让德多项式的简化假设来构建高阶能量守恒的csPRK方法时，Butcher“权重”系数$B_\tau$和$\widehat{B}_\tau$都必须等于1。作为说明性例子，通过所提出的条件获得了新的能量守恒积分器，并且为了验证我们的理论结果，报告了一些数值实验。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [205] [Energy-preserving continuous-stage Runge-Kutta-Nyström methods](https://arxiv.org/abs/1808.08451)
> *能量守恒的连续阶段Runge-Kutta-Nyström方法*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 能量守恒, Runge-Kutta-Nyström, 二阶系统, 数值积分, 连续阶段

**Comment:** The paper needs to be further modified

> **TL;DR:** 本文开发了能量守恒的连续阶段Runge-Kutta-Nyström (csRKN) 方法，用于求解二阶系统，并给出了其能量守恒的充分条件。

**AI_Comments:** 本文的创新点在于提出了能量守恒的连续阶段Runge-Kutta-Nyström方法，解决了传统数值积分器在处理具有物理不变量的二阶系统时能量无法守恒的问题，这对于保证数值模拟的物理准确性至关重要。其理论证明了该方法与现有能量守恒方法的联系，增强了其理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 许多实际问题可以用二阶系统 $\ddot{q}=-M\nabla U(q)$ 描述，这些系统具有明确物理意义的不变量（如能量、动量、角动量等）。然而，传统的数值积分器无法保持这些量，可能导致定性上不正确的数值解。

**Method:** 本文关注于开发用于求解二阶系统的能量守恒连续阶段Runge-Kutta-Nyström (csRKN) 方法。文中提出了csRKN方法能量守恒的充分条件，并证明了所有满足这些充分条件的能量守恒csRKN方法本质上都可以由能量守恒连续阶段分区Runge-Kutta方法导出。

**Result:** 提出了csRKN方法能量守恒的充分条件；证明了所有满足这些充分条件的能量守恒csRKN方法本质上都可以由能量守恒连续阶段分区Runge-Kutta方法导出；给出了说明性例子并报告了相关的数值结果。

**Conclusion:** 本文成功开发了能量守恒的连续阶段Runge-Kutta-Nyström方法，为求解具有不变量的二阶系统提供了更精确和可靠的数值积分器。

> **ai_Abstract:** 本文针对描述二阶系统的物理问题中传统数值方法无法保持能量等不变量导致数值解不准确的问题，提出并开发了能量守恒的连续阶段Runge-Kutta-Nyström (csRKN) 方法。研究给出了csRKN方法能量守恒的充分条件，并证明了此类方法可由能量守恒连续阶段分区Runge-Kutta方法导出。通过算例验证了其有效性。

> **摘要翻译:** 许多实际问题可以用二阶系统 $\ddot{q}=-M\nabla U(q)$ 描述，其中人们特别强调一些具有明确物理意义的不变量，如能量、动量、角动量等。然而，用于此类系统的传统数值积分器无法保持这些量中的任何一个，这可能导致定性上不正确的数值解。本文关注于开发用于求解二阶系统的能量守恒连续阶段Runge-Kutta-Nyström (csRKN) 方法。文中提出了csRKN方法能量守恒的充分条件，并证明了所有满足这些充分条件的能量守恒csRKN方法本质上都可以由能量守恒连续阶段分区Runge-Kutta方法导出。文中给出了一些说明性例子并报告了相关的数值结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [230] [Energy-preserving integration of non-canonical Hamiltonian systems by continuous-stage methods](https://arxiv.org/abs/1809.01770)
> *连续阶段方法对非正则哈密顿系统的能量保持积分*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 能量保持, 非正则哈密顿系统, 连续阶段方法, 对称积分器, 数值方法

**Comment:** The paper needs to be further modified

> **TL;DR:** 本文提出了一种新的对称的2m阶能量保持积分器，用于非正则哈密顿系统，并通过数值结果验证了其有效性。

**AI_Comments:** 本文的创新之处在于为非正则哈密顿系统构建了一类新的、对称的、高阶（2m阶）能量保持积分器。通过引入基于Butcher系数的代数条件和利用正交展开技术，为解决复杂系统中的能量保持问题提供了有效途径。这项工作对于需要长期精确模拟保守系统的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 能量在许多保守问题中被认为是重要的物理不变量，因此研究能够保持能量的数值方法具有重要意义。

**Method:** 本文采用连续阶段方法，提出了基于Butcher系数的代数条件，以确保能量保持、对称性和二次Casimir保持。利用正交展开技术，构建了能量保持积分器。

**Result:** 构建了一类新的对称的2m阶能量保持积分器。数值结果验证了理论分析的正确性并显示了新方法的有效性。

**Conclusion:** 本文提出的新方法能够有效地对非正则哈密顿系统进行能量保持积分，并且具有对称性和高阶特性。

> **ai_Abstract:** 本文研究了使用连续阶段方法对非正则哈密顿系统进行能量保持积分。作者提出了基于Butcher系数的代数条件，以确保能量、对称性和二次Casimir的保持。通过结合这些条件和正交展开技术，构建了一类新的对称的、2m阶的能量保持积分器。数值结果验证了所提出方法的理论分析和有效性。

> **摘要翻译:** 众所周知，能量通常被认为是许多保守问题中最重要的物理不变量之一，因此考虑能够保持能量的数值方法具有显著的意义。在本文中，我们关注通过连续阶段方法对非正则哈密顿系统进行能量保持积分。我们提出了关于Butcher系数的代数条件，分别用于确保能量保持、对称性和二次Casimir保持。利用所提出的条件并结合正交展开技术，我们研究了能量保持积分器的构造。构建了一类新的对称的2m阶能量保持积分器。报告了一些数值结果，以验证我们的理论分析并展示我们新方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [234] [Deep Unfolding Network for Nonlinear Multi-Frequency Electrical Impedance Tomography](https://arxiv.org/abs/2507.16678)
> *用于非线性多频电阻抗断层扫描的深度展开网络*

*Giovanni S. Alberti, Damiana Lazzaro, Serena Morigi, Luca Ratti, Matteo Santacesaria* | **Category: math.NA, cs.LG, cs.NA, stat.ML, 65K10, 65N20, 68T07** | **Updated: 2025-07-22**

**Keywords:** 多频电阻抗断层扫描, 深度展开网络, 图神经网络, 图像重建, 变分网络

**Comment:** 

> **TL;DR:** 该论文提出了一种深度展开网络，通过将图神经网络集成到近端正则化高斯牛顿框架中，用于多频电阻抗断层扫描（mfEIT）的图像重建，实现了对重叠组织分数浓度的准确重建。

**AI_Comments:** 该论文的创新之处在于将深度展开网络与图神经网络相结合，用于解决非线性多频电阻抗断层扫描问题。通过将物理模型（PRGN）与数据驱动的GNN相结合，该方法在保持可解释性的同时，利用了深度学习的强大能力。GNN在保留不规则网格结构和捕获频率间相关性方面的应用是其重要亮点，这对于生物医学成像中的复杂组织重建至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 多频电阻抗断层扫描（mfEIT）是一种有前景的生物医学成像模式，可以估计不同频率下的组织电导率。本文旨在解决mfEIT的图像重建挑战。

**Method:** 本文提出了一种新颖的变分网络，这是一种基于模型的学习范式，它将经典迭代重建的优点和可解释性与深度学习的能力相结合。该方法将图神经网络（GNN）集成到迭代近端正则化高斯牛顿（PRGN）框架中。通过展开PRGN算法，使每次迭代对应一个网络层，该方法利用非线性模型拟合的物理见解和GNN捕获频率间相关性的能力。GNN架构还保留了用于非线性正向模型求解的不规则三角网格结构。

**Result:** 该方法能够准确重建重叠的组织分数浓度。

**Conclusion:** 该论文提出的深度展开网络有效地结合了基于模型的方法和深度学习的优势，实现了多频电阻抗断层扫描中组织电导率的准确重建。

> **ai_Abstract:** 该论文介绍了一种用于多频电阻抗断层扫描（mfEIT）的深度展开网络，旨在解决组织电导率的图像重建问题。该网络是一种变分学习范式，通过将图神经网络（GNN）嵌入到展开的近端正则化高斯牛顿（PRGN）算法中，有效结合了模型驱动的物理见解和数据驱动的深度学习能力。GNN特别用于捕获频率间相关性并保留非线性正向模型中的不规则网格结构。该方法能够准确重建重叠的组织分数浓度。

> **摘要翻译:** 多频电阻抗断层扫描（mfEIT）代表了一种有前景的生物医学成像模式，能够估计一系列频率下的组织电导率。为了应对这一挑战，我们提出了一种新颖的变分网络，这是一种基于模型的学习范式，它战略性地融合了经典迭代重建的优点和可解释性与深度学习的力量。这种方法将图神经网络（GNN）集成到迭代近端正则化高斯牛顿（PRGN）框架中。通过展开PRGN算法，其中每次迭代对应一个网络层，我们利用了非线性模型拟合的物理见解以及GNN捕获频率间相关性的能力。值得注意的是，GNN架构保留了用于非线性正向模型求解的不规则三角网格结构，从而能够准确重建重叠的组织分数浓度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [262] [Two types of variational integrators and their equivalence](https://arxiv.org/abs/1809.06825)
> *两种变分积分器及其等价性*

*Wensheng Tang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 变分积分器, 离散哈密顿原理, 伽辽金变分方法, 等价性, 辛性

**Comment:** The paper needs to be further modified

> **TL;DR:** 论文介绍了两种变分积分器，并证明了它们在特定经典力学系统中的等价性，且它们具有辛性、对称性、超收敛阶等优良性质。

**AI_Comments:** 这篇论文的创新点在于揭示了两种不同来源的变分积分器在特定条件下的等价性，这有助于统一对变分积分方法的理解。其重要性在于证明了这些积分器在数值性质上的优越性（如辛性、对称性、超收敛），这对于长期数值模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 引入和研究两种不同来源的变分积分器，并探讨它们之间的关系。

**Method:** 引入了两种变分积分器：一种源于离散哈密顿原理，另一种源于伽辽金变分方法。

**Result:** 证明了当用于积分具有特定拉格朗日函数 ($L(q,\dot{q})=\frac{1}{2}\dot{q}^TM\dot{q}-U(q)$) 的经典力学系统时，这两种变分积分器是等价的。它们具有辛性、对称性、超收敛阶2s（取决于逼近多项式的次数），并且可以与连续阶段的Runge-Kutta方法相关联。

**Conclusion:** 在经典力学系统中，这两种不同来源的变分积分器是等价的，并且具有优良的数值性质。

> **ai_Abstract:** 本文介绍了两种变分积分器，分别基于离散哈密顿原理和伽辽金变分方法。研究发现，在积分特定形式的经典力学系统时，这两种积分器是等价的。此外，它们都表现出辛性、对称性、依赖于逼近多项式次数的超收敛阶，并且与连续阶段的Runge-Kutta方法存在关联。

> **摘要翻译:** 在本文中，我们介绍了两种变分积分器，其中一种源于离散哈密顿原理，另一种源于伽辽金变分方法。结果表明，当它们用于积分具有拉格朗日函数 $L(q,\dot{q})=\frac{1}{2}\dot{q}^TM\dot{q}-U(q)$（M是一个可逆的对称常数矩阵）的经典力学系统时，这两种变分积分器是等价的。它们具有辛性、对称性、超收敛阶2s（取决于逼近多项式的次数），并且可以与连续阶段的分裂Runge-Kutta方法相关联。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [280] [Numerical solution of two dimensional scalar conservation laws using compact implicit numerical schemes](https://arxiv.org/abs/2407.05275)
> *二维标量守恒律的紧致隐式数值格式求解*

*Peter Frolkovic, Dagmar Zakova* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 守恒律, 紧致隐式格式, 有限体积法, ENO, WENO

**Comment:** 

> **TL;DR:** 本文提出了一种新的紧致隐式时间离散化方法，用于求解二维守恒律，并结合有限体积法和ENO/WENO近似，通过时间限制来避免大时间步长下的振荡。

**AI_Comments:** 创新点在于提出了新的紧致隐式时间离散化和时间限制策略，以解决二维守恒律的数值振荡问题并支持快速求解器。这对于提高数值模拟的效率和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了利用快速代数求解器解决二维守恒律的数值解问题，并避免在大时间步长下出现振荡的数值解。

**Method:** 采用新颖的紧致隐式时间离散化方法，基于有限体积法构建了二阶精确参数格式，并结合了ENO和WENO近似。为避免振荡，提出了时间限制策略。

**Result:** 所提出的时间限制方法在变速度线性平流方程的情况下被证明是无振荡的。文章展示了代表性线性和非线性问题的数值实验结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种求解二维标量守恒律的紧致隐式数值格式。该方法采用新颖的紧致隐式时间离散化，结合有限体积法和ENO/WENO近似，旨在实现快速代数求解并避免大时间步长下的数值振荡。研究表明，所提出的时间限制策略在线性平流方程中能有效抑制振荡，并通过数值实验验证了其在线性和非线性问题上的表现。

> **摘要翻译:** 本文利用一种新颖的紧致隐式时间离散化方法来处理二维情况下的守恒律数值解，该方法能够应用快速代数求解器。我们详细介绍了基于有限体积法的二阶精确参数格式，包括ENO（本质非振荡）和WENO（加权本质非振荡）近似的简单变体。为了避免大时间步长下的振荡数值解，我们提出了时间限制，该方法在变速度线性平流方程的情况下被证明是无振荡的。我们展示了代表性线性和非线性问题的数值实验。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [310] [A Fast and Accurate Solver for the Fractional Fokker-Planck Equation with Dirac-Delta Initial Conditions](https://arxiv.org/abs/2407.15315)
> *分形Fokker-Planck方程在Dirac-Delta初始条件下的快速精确求解器*

*Qihao Ye, Xiaochuan Tian, Dong Wang* | **Category: math.NA, cs.NA, 34K37, 44A35, 35Q84, 65D40, 33C10** | **Updated: 2025-07-22**

**Keywords:** 分数阶Fokker-Planck方程, Dirac-delta初始条件, 数值求解器, 高维问题, Lévy过程

**Comment:** 38 pages, 10 figures

> **TL;DR:** 本文提出了一种针对具有Dirac-delta初始条件的分数阶Fokker-Planck方程 (FFPE) 的快速精确数值求解器，该方法能高效处理高维问题。

**AI_Comments:** 本文的创新之处在于首次为具有Dirac-delta初始条件的分数阶Fokker-Planck方程提供了一个高精度的数值求解器，这对于建模高斯假设不适用的系统至关重要。其高效处理高维问题的能力是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 经典的Fokker-Planck方程 (FPE) 适用于受高斯噪声影响的系统，但对于由Lévy过程驱动的、高斯假设失效的系统，需要分数阶Fokker-Planck方程 (FFPE) 来进行建模。

**Method:** 本文提出了一种高效精确的数值方法，用于解决具有常系数和Dirac-delta初始条件的自由空间FFPE。该方法利用解的积分表示，并结合快速算法以有效处理高维问题。

**Result:** 该方法首次提供了针对具有Dirac-delta初始条件的自由空间FFPE的高精度数值求解器。此外，该方法对于由高斯和给出的初始条件也表现出有效性。

**Conclusion:** 本文首次提出了针对具有Dirac-delta初始条件的自由空间FFPE的高精度数值求解器，为未来研究具有可变系数和其他类型初始条件的更复杂情景奠定了基础。

> **ai_Abstract:** 本文提出了一种新颖、高效且精确的数值求解器，用于解决在Dirac-delta初始条件下的自由空间分数阶Fokker-Planck方程 (FFPE)。该方法克服了经典Fokker-Planck方程的局限性，利用积分表示和快速算法来处理高维问题。这是第一个针对特定FFPE变体的高精度求解器，并已被证明对高斯和初始条件也有效，为未来研究更复杂场景铺平了道路。

> **摘要翻译:** 经典的Fokker-Planck方程 (FPE) 是物理学中描述受阻力作用和高斯噪声影响系统的关键工具，其应用涵盖多个领域。我们考虑分数阶Fokker-Planck方程 (FFPE)，它模拟由Lévy过程驱动的系统概率密度的时间演化，适用于高斯假设失效的场景。本文提出了一种针对具有常系数和Dirac-delta初始条件的自由空间FFPE的高效精确数值方法。该方法利用解的积分表示，并能使用快速算法有效处理非常高维的问题。我们的工作首次提出了针对具有Dirac-delta初始条件的自由空间FFPE的高精度数值求解器。除了Dirac-delta初始数据，我们还展示了该方法对于由高斯和给出的初始条件的有效性。这为未来研究更复杂的情景打开了大门，包括那些具有可变系数和其他类型初始条件的情景。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [335] [Modeling Advection-Dominated Flows with Space-Local Reduced-Order Models](https://arxiv.org/abs/2409.08793)
> *使用空间局部降阶模型模拟对流主导流*

*Toby van Gastelen, Wouter Edeling, Benjamin Sanderse* | **Category: math.NA, cs.NA, 65Mxx** | **Updated: 2025-07-22**

**Keywords:** 降阶模型, 空间局部POD, 对流主导流, 泛化能力, 计算效率

**Comment:** 30 pages, 13 figures, source code can be found at
  https://github.com/tobyvg/local_POD_overlap.jl

> **TL;DR:** 本文提出一种新型空间局部POD降阶模型，有效解决了传统POD在对流主导流中奇异值衰减缓慢的问题，实现了更好的泛化能力和计算效率。

**AI_Comments:** 本文的创新之处在于将POD方法应用于局部、基于子域的框架，类似于有限元方法但采用数据驱动的方式，专门解决了对流主导流中奇异值衰减缓慢的难题。这显著提高了ROMs在处理这类复杂问题时的泛化能力和计算效率。引入重叠子域以确保平滑性也是一个值得注意的实用细节。

<details>
  <summary>Details</summary>

**Motivation:** 传统的降阶模型（如基于POD的方法）在处理对流主导流时，由于奇异值衰减缓慢，常导致计算成本高昂和潜在的不稳定性。

**Method:** 本文提出了一种使用空间局部POD的新方法。该方法不使用全局基函数，而是采用在域内应用的局部基函数，类似于有限元方法但具有数据驱动的基。通过将域划分为子域并应用空间局部POD，实现稀疏表示和更好的泛化能力。为确保子域边界平滑性，引入了重叠子域。

**Result:** 通过一维和二维对流方程模拟验证了该方法。结果表明，空间局部降阶模型对非训练数据流条件具有更好的泛化能力，继承了全阶模型的能量守恒和非线性稳定性特性，并允许使用更大的时间步长。

**Conclusion:** 空间局部降阶模型有效解决了对流主导流的挑战，提供了改进的泛化能力、稳定性和计算效率。

> **ai_Abstract:** 本文提出了一种新颖的空间局部POD方法，旨在克服传统降阶模型（ROMs）在模拟对流主导流时因奇异值衰减缓慢而导致的局限性。通过在子域上使用局部、数据驱动的基函数并引入重叠区域以确保平滑性，该方法实现了稀疏表示并显著提高了对训练数据范围之外的泛化能力。在一维和二维对流方程上的验证表明，该空间局部ROM展现出更优的泛化性、继承了模型的稳定性，并允许更大的时间步长，为复杂的对流主导流仿真提供了一种更高效和鲁棒的解决方案。

> **摘要翻译:** 降阶模型（ROMs）常用于加速大型物理系统的仿真。然而，传统的ROM技术，例如基于本征正交分解（POD）的技术，由于奇异值衰减缓慢，在处理对流主导流时常常遇到困难。这导致计算成本高昂和潜在的不稳定性。
本文提出了一种使用空间局部POD的新方法，以解决奇异值衰减缓慢带来的挑战。我们的方法不使用全局基函数，而是采用在域内应用的局部基函数，类似于有限元方法，但具有数据驱动的基。通过将域划分为子域并应用空间局部POD，我们实现了一种稀疏且在训练范围外具有更好泛化能力的表示。这使得与标准POD相比，可以使用更多的基函数，而不会产生过高的计算成本。为了确保子域边界之间的平滑性，我们引入了受单位分解方法启发的重叠子域。
我们的方法通过一维和二维对流方程的模拟进行了验证。我们证明，使用我们的空间局部方法，我们获得的ROM对不属于训练数据的流动条件具有更好的泛化能力。此外，我们展示了所构建的ROM继承了全阶模型的能量守恒和非线性稳定性特性。最后，我们发现使用空间局部ROM允许更大的时间步长。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [364] [Multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation overcome the curse of dimensionality when approximating semilinear parabolic partial differential equations in $L^p$-sense](https://arxiv.org/abs/2409.20431)
> *多层Picard逼近和带有ReLU、leaky ReLU和softplus激活函数的深度神经网络在$L^p$意义下逼近半线性抛物型偏微分方程时克服维度灾难*

*Ariel Neufeld, Tuan Anh Nguyen* | **Category: math.NA, cs.LG, cs.NA, math.PR** | **Updated: 2025-07-22**

**Keywords:** 维度灾难, 多层Picard逼近, 深度神经网络, 半线性PDEs, Kolmogorov方程

**Comment:** 

> **TL;DR:** 多层Picard逼近和特定深度神经网络能以多项式复杂度克服维度灾难，逼近半线性PDEs解。

**AI_Comments:** 这项工作在理论上证明了结合多层Picard方法和特定深度学习架构可以有效应对高维半线性PDEs的求解难题，解决了传统数值方法中常见的维度灾难问题，对科学计算和机器学习交叉领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 克服在逼近半线性偏微分方程（PDEs）解时遇到的“维度灾难”问题。

**Method:** 使用多层Picard逼近（Multilevel Picard approximations）和带有ReLU、leaky ReLU、softplus激活函数的深度神经网络（deep neural networks）。

**Result:** 证明了多层Picard逼近和带有ReLU、leaky ReLU、softplus激活函数的深度神经网络能够以$L^\mathfrak{p}$-sense ($\mathfrak{p}\in [2,\infty)$) 逼近梯度无关、Lipschitz连续非线性半线性Kolmogorov PDEs的解，且计算量和所需参数量随维度和精度倒数呈多项式增长。

**Conclusion:** 多层Picard逼近和特定深度神经网络在逼近半线性PDEs解时，能够克服维度灾难。

> **ai_Abstract:** 本文证明了多层Picard逼近和使用ReLU、leaky ReLU、softplus激活函数的深度神经网络在逼近梯度无关、Lipschitz连续非线性半线性Kolmogorov PDEs的$L^\mathfrak{p}$解时，能够有效克服维度灾难。其计算成本和参数量仅随维度和所需精度倒数呈多项式增长。

> **摘要翻译:** 我们证明了多层Picard逼近和带有ReLU、leaky ReLU、softplus激活函数的深度神经网络能够以$L^\mathfrak{p}$意义（$\mathfrak{p}\in [2,\infty)$）逼近半线性Kolmogorov偏微分方程的解，适用于梯度无关、Lipschitz连续的非线性情况。同时，多层Picard逼近的计算开销和神经网络所需的参数数量在维度$d\in \mathbb{N}$和给定精度$\epsilon$的倒数方面，最多呈多项式增长。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [394] [Virtual finite element and hyperbolic problems: the PAMPA algorithm](https://arxiv.org/abs/2412.01341)
> *虚拟有限元与双曲问题：PAMPA算法*

*Rémi Abgrall, Yongle Liu, Walter Boscheri* | **Category: math.NA, cs.NA, 65M06, 65M08** | **Updated: 2025-07-22**

**Keywords:** 虚拟元方法, 双曲问题, PAMPA算法, 主动通量, 凸限制

**Comment:** 

> **TL;DR:** 本文提出了一种基于虚拟元方法（VEM）和主动通量方法的新型PAMPA算法，用于在多边形网格上解决标量和系统双曲问题，并通过凸限制策略进行稳定化，展现了其在各种基准测试中的精度和鲁棒性。

**AI_Comments:** 这篇论文通过将虚拟元方法（VEM）与主动通量方法相结合，为双曲问题的数值求解提供了一种新颖的高阶（三阶）方案。其创新之处在于利用VEM的无多项式近似能力在通用多边形网格上处理复杂几何，并结合了有效的稳定化策略来应对非线性问题和不连续性。该方法在处理激波等强间断问题上的鲁棒性是一个亮点，对于计算流体力学等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决在一般多边形网格上的标量和系统双曲问题，并开发新的高阶精度方案。

**Method:** 结合虚拟元方法（VEM）和主动通量方法，开发了新的三阶精度方法。该方法利用VEM技术通过无多项式近似离散化数值解的梯度，采用局部定义的虚拟基。对于非线性问题，采用扩展自“Abgrall_BP_PAMPA”的单片凸限制策略进行稳定化。

**Result:** 所提出的方案在全球范围内是连续的，并在标量问题以及二维声学和欧拉方程中得到了应用。通过一系列涉及平滑解、激波和其他不连续性的基准测试，评估了所提方案的精度和鲁棒性。

**Conclusion:** 所提出的基于VEM和主动通量方法的PAMPA算法在解决双曲问题上表现出高精度和鲁棒性，尤其是在处理不连续性方面。

> **ai_Abstract:** 本文提出了一种名为PAMPA的新型算法，该算法结合了虚拟元方法（VEM）和主动通量方法，用于在一般多边形网格上求解标量和系统双曲问题。该方法实现了三阶精度，并通过无多项式近似和局部虚拟基来离散化梯度。对于非线性问题，采用了一种单片凸限制策略进行稳定。研究通过对标量问题、声学和欧拉方程的基准测试，验证了其在处理平滑解、激波和不连续性时的精度和鲁棒性。

> **摘要翻译:** 在本文中，我们探索了使用虚拟元方法（Virtual Element Method, VEM）的概念来解决一般多边形网格上的标量和系统双曲问题。新方案源于主动通量方法[AF1]，该方法结合了单元边界处的点值和代表每个控制体内解的平均值的额外自由度。沿着[Abgrall_AF,abgrall2023activefluxtriangularmeshes]中引入的残差分布方案家族的路线，我们设计了新颖的三阶精度方法，这些方法依赖于VEM技术，通过无多项式近似来离散化数值解的梯度，采用局部定义在每个单元的虚拟基。获得的离散化是全局连续的，对于非线性问题，它需要通过扩展自[Abgrall_BP_PAMPA]的单片凸限制策略来提供稳定化。这应用于离散解的点值和平均值。我们展示了在标量问题以及二维声学和欧拉方程中的应用。所提出方案的精度和鲁棒性通过一系列涉及平滑解、激波和其他不连续性的基准测试进行了评估。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [424] [An Efficient Iterative Decoupling Method for Thermo-Poroelasticity Based on a Four-Field Formulation](https://arxiv.org/abs/2502.13445)
> *基于四场公式的热孔弹性高效迭代解耦方法*

*Mingchao Cai, Jingzhi Li, Ziliang Li, Qiang Liu* | **Category: math.NA, cs.NA** | **Updated: 2025-07-21**

**Keywords:** 热孔弹性, 四场公式, 迭代解耦, 有限元方法, 收敛性

**Comment:** submitted to a journal, accepted, need to be updated

> **TL;DR:** 本文提出并分析了一种基于四场公式的热孔弹性高效迭代解耦有限元方法，证明了其收敛性，且无需额外参数假设。

**AI_Comments:** 这项研究的创新之处在于提出了基于四场公式的热孔弹性高效迭代解耦方法，并证明了其收敛性不依赖于额外的物理参数或稳定化参数假设，这对于实际应用具有重要意义，因为它简化了模型的参数选择。

<details>
  <summary>Details</summary>

**Motivation:** 研究热孔弹性模型，并寻求一种更高效的迭代解耦方法来解决它，以避免对物理参数或稳定化参数的额外假设。

**Method:** 通过引入一个中间变量，将原有的三场热孔弹性模型转换为四场模型。在此基础上，提出了耦合有限元方法和解耦迭代有限元方法，并主要分析了迭代解耦算法。

**Result:** 证明了耦合有限元方法的稳定性和最优收敛性。建立了迭代解耦方法的收敛性，并证明其收敛性不依赖于物理参数或稳定化参数的额外假设。数值结果验证了新方法的有效性和理论正确性。

**Conclusion:** 本文成功提出并分析了一种基于四场公式的热孔弹性高效迭代解耦有限元方法，该方法具有良好的收敛性且对参数无额外要求，并通过数值实验验证了其有效性。

> **ai_Abstract:** 本文研究热孔弹性模型，通过引入中间变量将其转换为四场公式。在此基础上，提出了耦合和迭代解耦有限元方法。研究证明了耦合方法的稳定性和最优收敛性，并重点分析了迭代解耦算法的收敛性，指出其收敛性无需额外物理或稳定化参数假设。数值结果验证了所提方法的有效性。

> **摘要翻译:** 本文研究热孔弹性模型。通过引入一个中间变量，我们将原始的三场模型转换为一个四场模型。基于这个四场模型，我们提出了一种耦合有限元方法和一种解耦迭代有限元方法。我们证明了耦合有限元方法的稳定性和最优收敛性。此外，我们建立了解耦迭代方法的收敛性。本文主要侧重于分析迭代解耦算法。它表明该算法的收敛性不需要对物理参数或稳定化参数进行任何额外的假设。提供了数值结果以证明这些新方法的有效性和理论正确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [447] [Structure-preserving deflation of critical eigenvalues in quadratic eigenvalue problems associated with damped mass-spring systems](https://arxiv.org/abs/2507.16024)
> *阻尼质量-弹簧系统二次特征值问题中临界特征值的保结构紧缩*

*Rafikul Alam, Volker Mehrmann, Ninoslav Truhar* | **Category: math.NA, cs.NA, math.SP, 65F15, 15A57, 15A18, 65F35** | **Updated: 2025-07-21**

**Keywords:** 二次特征值问题, 临界特征值, 保结构紧缩, 阻尼质量-弹簧系统, 线性化

**Comment:** 

> **TL;DR:** 本文提出了一种保结构的紧缩策略，用于二次特征值问题中临界特征值（0、无穷和虚轴上的特征值）的消去，以提高数值计算和稳定性分析的效率。

**AI_Comments:** 本文的创新点在于提出了针对二次特征值问题中临界特征值的保结构紧缩策略，通过保留原有的结构，可以更好地应用于数值方法和稳定性分析，特别是在阻尼质量-弹簧系统和双曲问题中。这种方法对于处理大型稀疏矩阵问题可能具有重要意义，因为它能降低计算复杂度。

<details>
  <summary>Details</summary>

**Motivation:** 对于数值方法和鲁棒稳定性分析，需要通过将矩阵多项式投影到较低维子空间来紧缩临界特征值（0、无穷和虚轴上的特征值），以便在计算其他特征值和特征向量之前消除它们。

**Method:** 本文通过剪裁的保结构线性化描述了保结构紧缩策略来紧缩这些临界特征值。这些结果被应用于双曲问题的特殊情况。同时，还分析了参数阻尼矩阵（可能是低秩的）对纯虚特征值的影响。

**Result:** 描述并应用了通过剪裁的保结构线性化实现临界特征值保结构紧缩的策略，并将其应用于双曲问题。此外，还分析了参数阻尼矩阵对纯虚特征值的影响。

**Conclusion:** 本文提供了处理阻尼质量-弹簧系统二次特征值问题中临界特征值的保结构紧缩策略，这对于数值计算和稳定性分析具有重要意义。

> **ai_Abstract:** 本文研究了与阻尼质量-弹簧系统相关的二次特征值问题中的临界特征值（包括0、无穷和虚轴上的特征值），这些特征值位于稳定特征值集合的边界。为了提高数值方法和稳定性分析的效率，作者提出并描述了通过剪裁的保结构线性化实现的保结构紧缩策略，以消除这些临界特征值。该策略被应用于双曲问题，并且还分析了参数阻尼矩阵对纯虚特征值的影响。

> **摘要翻译:** 对于与阻尼质量-弹簧系统相关的二次矩阵多项式，存在三种类型的临界特征值：无穷大、0 以及虚轴上的特征值。所有这些特征值都位于（鲁棒）稳定特征值集合的边界上。对于数值方法，以及（鲁棒）稳定性分析，通过将矩阵多项式投影到较低维子空间来紧缩这些特征值是可取的，以便在计算其他特征值和特征向量之前消除它们。我们描述了通过剪裁的保结构线性化来紧缩这些特征值的保结构紧缩策略。我们将这些结果应用于双曲问题的特殊情况。我们还分析了（可能是低秩的）参数阻尼矩阵对纯虚特征值的影响。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [454] [Finite element form-valued forms: Construction](https://arxiv.org/abs/2503.03243)
> *有限元形式值形式：构造*

*Kaibo Hu, Ting Lin* | **Category: math.NA, cs.NA, math.DG, 65N30, 53A70, 58A10** | **Updated: 2025-07-22**

**Keywords:** 有限元, 形式值形式, 离散化, 推广, BGG图

**Comment:** 97 pages, 26 figures, 21 tables

> **TL;DR:** 该论文提出了一种通用的有限元离散化方法，用于在任意维度和多项式次数下对形式值k-形式进行离散化，统一了多种现有有限元方法，并离散化了Bernstein-Gelfand-Gelfand (BGG) 图。

**AI_Comments:** 该论文的创新之处在于提供了一个高度通用和统一的有限元离散化框架，将许多不同的方法整合到一个范式之下。这可以显著简化复杂有限元问题的理论理解和实际实现，特别是那些涉及高阶形式和不同维度张量的问题。它与BGG图的联系表明了其深远的数学基础。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在提供一种通用的有限元离散化方法，以统一和推广现有针对不同数学对象（如de Rham复形、应力张量、双调和方程等）的有限元方法，涵盖更广泛的k、l和n以及任意多项式次数。

**Method:** 该方法构建了在$\\mathbb{R}^{n}$三角剖分上对$\ell$-形式值$k$-形式的有限元离散化，适用于一般的$k$、$\ell$和$n$以及任意多项式次数。这种构造方法推广了多种现有有限元方法，并离散化了Bernstein-Gelfand-Gelfand (BGG) 图。

**Result:** 该构造方法成功地推广了包括Whitney形式、Regge有限元、TDNNS单元、MCS单元、Hellan-Herrmann-Johnson (HHJ) 单元以及离散divdiv和Hessian复形在内的多种有限元方法，并实现了Bernstein-Gelfand-Gelfand (BGG) 图的离散化。

**Conclusion:** 该构造方法为复杂数学对象（如连续介质力学中的应变和应力张量，以及微分几何中的度量和曲率张量）的离散化提供了一个强大且通用的有限元框架，具有广泛的应用前景。

> **ai_Abstract:** 本文提出了一种新颖且通用的有限元构造方法，用于在$\mathbb{R}^{n}$三角剖分上离散化$\ell$-形式值$k$-形式。这种统一的方法推广了广泛存在的各种专业有限元方法，包括Whitney形式、Regge单元和各种复形，并有效地离散化了Bernstein-Gelfand-Gelfand (BGG) 图。所提出的方法在连续介质力学中的应变和应力张量以及微分几何中的度量和曲率张量等领域具有广泛应用。

> **摘要翻译:** 我们提供了一种在 $\\mathbb{R}^{n}$ 三角剖分上对 $\ell$-形式值 $k$-形式进行有限元离散化的方法，适用于一般的 $k$、$\ell$ 和 $n$ 以及任意多项式次数。这种构造方法推广了用于 de~Rham 复形的有限元 Whitney 形式及其高阶和分布版本、Regge 有限元和 Christiansen-Regge 弹性复形、用于对称应力张量的 TDNNS 单元、用于无迹矩阵场的 MCS 单元、用于双调和方程的 Hellan-Herrmann-Johnson (HHJ) 单元，以及 [Hu, Lin, and Zhang, 2025] 中离散的 divdiv 和 Hessian 复形。该构造方法离散化了 Bernstein-Gelfand-Gelfand (BGG) 图。该构造的应用包括连续介质力学中应变和应力张量的离散化，以及任何维度下微分几何中度量和曲率张量的离散化。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [483] [Diff-ANO: Towards Fast High-Resolution Ultrasound Computed Tomography via Conditional Consistency Models and Adjoint Neural Operators](https://arxiv.org/abs/2507.16344)
> *Diff-ANO：通过条件一致性模型和伴随神经算子实现快速高分辨率超声计算断层成像*

*Xiang Cao, Qiaoqiao Ding, Xinliang Liu, Lei Zhang, Xiaoqun Zhang* | **Category: math.NA, cs.NA, 92C55, 35R30, 65N21, 68T07, 60J60** | **Updated: 2025-07-22**

**Keywords:** 超声计算断层成像, 条件一致性模型, 伴随神经算子, 扩散模型, 逆问题

**Comment:** 27 pages, 10 figures, 6 tables

> **TL;DR:** Diff-ANO是一种新框架，结合了条件一致性模型和伴随神经算子学习，旨在解决超声计算断层成像(USCT)中PDE约束梯度计算、离散化误差和计算不平衡的挑战，实现更高效、高质量的重建。

**AI_Comments:** Diff-ANO的创新之处在于其将条件一致性模型与伴随神经算子学习相结合，解决了USCT中的PDE约束梯度计算效率低、离散化误差大以及计算资源不平衡等核心问题。通过用神经网络替代传统PDE求解器进行梯度计算，并引入高效的训练数据生成策略，极大地提升了USCT的实用性和性能，尤其对于高分辨率和挑战性测量条件下的成像具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的超声计算断层成像(USCT)在整合扩散生成先验时，面临PDE约束梯度计算、离散化引起的近似误差以及神经网络与数值PDE求解器之间的计算不平衡等挑战。

**Method:** 本文提出了Diff-ANO框架，结合了条件一致性模型和伴随算子学习。其主要创新包括：1) 一个条件一致性模型，通过直接学习扩散轨迹的自洽映射实现测量条件下的少步采样；2) 一个伴随算子学习模块，用神经算子替代传统PDE求解器，实现高效的基于伴随的梯度计算。为实现实际部署，引入了批处理收敛Born级数(BCBS)策略，用于在线生成神经算子训练对。

**Result:** 综合实验表明，Diff-ANO显著提高了计算效率和重建质量，尤其在稀疏视图和部分视图测量场景下表现更佳。

**Conclusion:** Diff-ANO通过其创新的模型和优化策略，成功克服了传统USCT方法的局限性，为实现快速高分辨率超声计算断层成像提供了一条有效途径。

> **ai_Abstract:** Diff-ANO是一个针对超声计算断层成像(USCT)的新型框架，旨在解决现有方法在整合扩散先验时面临的计算效率和准确性问题。该框架结合了条件一致性模型和伴随神经算子学习，通过直接学习自洽映射进行少步采样，并用神经算子替代传统PDE求解器以实现高效梯度计算。此外，引入了批处理收敛Born级数(BCBS)以优化训练对生成。实验证明Diff-ANO显著提升了USCT的计算效率和重建质量，尤其在稀疏和部分视图条件下表现突出。

> **摘要翻译:** 超声计算断层成像（USCT）是一个非线性逆问题，具有固有的病态性，可以通过扩散生成先验进行正则化。然而，传统的求解亥姆霍兹方程约束的USCT方法在整合这些先验时面临三个基本挑战：PDE约束梯度计算、离散化引起的近似误差以及神经网络与数值PDE求解器之间的计算不平衡。在这项工作中，我们引入了**Diff-ANO**（基于**扩散**的模型与**伴随神经算子**），这是一个结合了条件一致性模型和伴随算子学习的新颖框架，旨在解决这些限制。我们的两个关键创新包括：(1) 一个**条件一致性模型**，通过直接学习扩散轨迹的自洽映射，实现测量条件下的少步采样；(2) 一个**伴随算子学习**模块，用神经算子替代传统PDE求解器，实现高效的基于伴随的梯度计算。为了实现实际部署，我们引入了批处理收敛Born级数（BCBS）——一种用于在线生成神经算子训练对的内存高效策略。综合实验表明，Diff-ANO显著提高了计算效率和重建质量，尤其在稀疏视图和部分视图测量场景下。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [484] [An Efficient Second-Order Adaptive Procedure for Inserting CAD Geometries into Hexahedral Meshes using Volume Fractions](https://arxiv.org/abs/2504.03525)
> *一种使用体积分数将CAD几何体插入六面体网格的有效二阶自适应程序*

*Brian N. Granzow, Stephen D. Bond, Michael J. Powell, Daniel A. Ibanez* | **Category: math.NA, cs.NA** | **Updated: 2025-07-21**

**Keywords:** CAD几何体, 六面体网格, 自适应程序, 体积分数, 二阶精度

**Comment:** 15 pages, 15 figures, 2 tables

> **TL;DR:** 本文提出了一种高效的二阶自适应程序，用于将三维CAD几何体精确插入到六面体网格中，该程序利用k-d树进行空间加速并自适应细分六面体。

**AI_Comments:** 该论文的创新之处在于提出了一种高效且高精度的CAD几何体插入六面体网格的方法。其亮点在于仅需CAD内核的两次基本几何查询，大大降低了对CAD内核复杂功能的需求，同时实现了二阶精度，这对于工程仿真和分析领域具有重要意义。自适应细分和k-d树的应用也体现了其在计算效率上的考量。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决将三维计算机辅助设计（CAD）几何体插入到由六面体单元组成的网格中的问题，并提出一种自适应程序。

**Method:** 该程序包含两个步骤：首先，使用k-d树进行空间加速；其次，以自适应网格细化（AMR）的方式细分单个六面体，并在最精细的细分级别上将CAD几何体线性近似（作为平面）。该过程仅需要CAD内核的两次几何查询：判断查询的空间坐标是否在CAD几何体内或外，以及确定给定空间坐标到CAD几何体表面最近的点。

**Result:** 研究证明，对于足够光滑的几何体和足够精细的背景网格，该程序具有二阶精度。通过多项验证测试，证明了其达到了预期的精度，并展示了该程序对多个示例CAD几何体的有效性。

**Conclusion:** 本文提出的自适应程序能够高效且精确地将CAD几何体插入到六面体网格中，实现了二阶精度并仅需少量CAD内核查询。

> **ai_Abstract:** 本文提出了一种高效的二阶自适应程序，用于将三维CAD几何体精确插入到六面体网格中，利用体积分数表示。该程序通过k-d树进行空间加速，并对六面体进行自适应细分，将CAD几何体在最精细级别上线性近似。它仅需CAD内核的两次几何查询，并被证明对光滑几何体和精细网格具有二阶精度，并通过验证测试和实例展示了其有效性。

> **摘要翻译:** 本文关注的是使用体积分数表示法，将三维计算机辅助设计（CAD）几何体插入到由六面体单元组成的网格中。本文提出了一种实现这一目的的自适应程序。该程序由两个步骤组成。第一步使用k-d树进行空间加速。第二步涉及以自适应网格细化（AMR）的方式细分单个六面体，并在最精细的细分级别上将CAD几何体线性近似（作为平面）。该程序仅需要CAD内核的两次几何查询：确定查询的空间坐标是否在CAD几何体内或外，以及确定给定空间坐标到CAD几何体表面最近的点。我们证明，对于足够光滑的几何体和足够精细的背景网格，该程序具有二阶精度。我们通过多项验证测试证明了其达到了预期的精度，并展示了该程序对多个示例CAD几何体的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [514] [Adaptive feature capture method for solving partial differential equations with low regularity solutions](https://arxiv.org/abs/2507.12941)
> *求解低正则性解偏微分方程的自适应特征捕获方法*

*Yangtao Deng, Qiaolin He, Xiaoping Wang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-21**

**Keywords:** 偏微分方程, 低正则性解, 自适应特征捕获方法, 随机特征方法, 机器学习

**Comment:** Irreconcilable authorship disagreements. Key reasons: Unresolved
  author attribution disputes. No consensus on contributor inclusion/order. All
  co-authors notified. Full responsibility accepted

> **TL;DR:** AFCM是一种新的机器学习方法，通过在梯度高区域自适应地重新分配神经元和配置点，有效解决了具有低正则性解的偏微分方程，无需网格，且在复杂几何形状中表现出色。

**AI_Comments:** AFCM的创新之处在于将自适应网格细化的思想引入到无网格的随机神经网络方法中，通过动态调整计算资源（神经元和配置点）的分布来应对低正则性解带来的挑战。这解决了现有深度学习方法在处理局部高梯度或奇异性时的精度限制，同时保持了无网格的效率，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的数值方法在求解低正则性解的偏微分方程（PDEs）时面临巨大挑战，尤其是在复杂几何形状中，网格生成和自适应加密计算成本高昂。现有的基于深度学习的方法（如PINNs和RFM）虽然是无网格的替代方案，但缺乏在关键区域的自适应分辨率，限制了它们在处理陡峭梯度或奇异性解时的准确性。

**Method:** 本文提出了自适应特征捕获方法（AFCM），这是一种新颖的机器学习框架。AFCM通过自适应地重新分配神经元和配置点到高梯度区域来增强局部表达能力。受自适应移动网格技术的启发，AFCM使用近似解的梯度范数作为监测函数，指导特征函数参数的重新初始化，从而使划分超平面和配置点在最需要的地方聚集，在不增加计算开销的情况下实现更高分辨率。AFCM扩展了RFM的能力，使其能够处理接近奇异解的PDEs，同时保持其无网格效率。

**Result:** 数值实验证明了该方法在准确解决低正则性问题方面的有效性，即使在复杂几何形状中也表现良好。

**Conclusion:** AFCM通过弥合自适应网格细化和随机神经网络之间的差距，为解决科学和工程应用中具有挑战性的偏微分方程提供了一种鲁棒且可扩展的方法。

> **ai_Abstract:** 该论文提出了一种名为自适应特征捕获方法（AFCM）的新型机器学习框架，旨在解决具有低正则性解的偏微分方程。针对传统方法和现有深度学习方法在处理陡峭梯度或奇异性时分辨率不足的问题，AFCM通过在梯度高区域自适应地重新分配神经元和配置点，提高了局部表达能力和分辨率，且不增加计算开销。该方法利用梯度范数作为监测函数指导特征参数的重新初始化，并被证明在复杂几何形状中也能有效且准确地处理低正则性问题，扩展了随机特征方法的能力，提供了一种鲁棒且可扩展的无网格求解方案。

> **摘要翻译:** 低正则性解的偏微分方程（PDEs）对传统数值方法提出了重大挑战，特别是在复杂几何形状中，网格生成和自适应细化变得计算成本高昂。虽然基于深度学习的方法，如物理信息神经网络（PINNs）和随机特征方法（RFM），提供了无网格的替代方案，但它们通常缺乏在关键区域的自适应分辨率，从而限制了它们在处理具有陡峭梯度或奇异性的解时的准确性。在这项工作中，我们提出了自适应特征捕获方法（AFCM），这是一种新颖的机器学习框架，它在高梯度区域自适应地重新分配神经元和配置点，以增强局部表达能力。受自适应移动网格技术的启发，AFCM采用近似解的梯度范数作为监测函数，以指导特征函数参数的重新初始化。这确保了划分超平面和配置点在最需要的地方聚集，在不增加计算开销的情况下实现更高分辨率。AFCM扩展了RFM的能力，使其能够处理接近奇异解的PDEs，同时保持其无网格效率。数值实验证明了该方法在准确解决低正则性问题方面的有效性，即使在复杂几何形状中也表现良好。通过弥合自适应网格细化和随机神经网络之间的差距，AFCM为解决科学和工程应用中具有挑战性的PDEs提供了一种鲁棒且可扩展的方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [519] [Neural Network Acceleration of Iterative Methods for Nonlinear Schrödinger Eigenvalue Problems](https://arxiv.org/abs/2507.16349)
> *神经网络加速非线性薛定谔本征值问题的迭代方法*

*Daniel Peterseim, Jan-F. Pietschmann, Jonas Püschel, Kilian Ruess* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 神经网络, 迭代方法, 非线性薛定谔方程, 本征值问题, 加速

**Comment:** 19 Pages, 22 figures

> **TL;DR:** 本文提出了一种利用神经网络加速求解非线性薛定谔本征值问题迭代方法的新方法，通过预测和改进解的轨迹来提高收敛速度和精度，并在数值实验中展示了显著的加速效果。

**AI_Comments:** 该论文提出了一种新颖的方法，将神经网络应用于加速迭代求解非线性薛定谔本征值问题，这在解决传统方法收敛慢的瓶颈上具有创新性。其重要性在于为量子力学等领域的复杂问题提供了更高效的计算工具。论文也提及了方法的局限性，这表明研究仍在进行中，未来可能需要进一步的优化和改进。

<details>
  <summary>Details</summary>

**Motivation:** 非线性本征向量问题在量子力学和其他领域中是基础性的，但传统的求解器在极端参数区域（如旋转玻色-爱因斯坦凝聚体问题）中往往收敛缓慢。

**Method:** 该方法利用神经网络预测和改进解的轨迹，通过利用先前模拟的知识来提高收敛速度和精度。

**Result:** 数值实验表明，与经典求解器相比，该方法实现了显著的加速。

**Conclusion:** 该方法成功地利用神经网络加速了非线性薛定谔本征值问题的迭代求解，显示出其优势，但也存在局限性。

> **ai_Abstract:** 本文介绍了一种利用神经网络加速非线性薛定谔本征值问题迭代求解的新方法。针对传统求解器在极端参数下收敛慢的问题，该方法通过神经网络预测并优化解的轨迹，从而提高收敛速度和准确性。数值实验证实了其相较于传统方法的显著加速效果，同时指出了该方法的优势与局限性。

> **摘要翻译:** 我们提出了一种利用神经网络加速求解非线性薛定谔本征值问题的迭代方法的新方法。非线性本征向量问题在量子力学和其他领域中是基础性的，但传统的求解器在极端参数区域中往往收敛缓慢，例如旋转玻色-爱因斯坦凝聚体（BEC）问题。我们的方法利用神经网络预测和改进解的轨迹，利用先前模拟的知识来提高收敛速度和精度。数值实验表明，与经典求解器相比，该方法实现了显著的加速，突出了该方法的优点和局限性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [531] [Data-Driven Adaptive Gradient Recovery for Unstructured Finite Volume Computations](https://arxiv.org/abs/2507.16571)
> *非结构化有限体积计算中的数据驱动自适应梯度恢复*

*G. de Romémont, F. Renac, F. Chinesta, J. Nunez, D. Gueyffier* | **Category: math.NA, cs.AI, cs.NA, math.AP** | **Updated: 2025-07-22**

**Keywords:** 数据驱动, 梯度恢复, 有限体积法, DeepONet, 双曲守恒律

**Comment:** 19 pages, 13 Figures, 1 table

> **TL;DR:** 该论文提出了一种用于非结构化有限体积方法的创新数据驱动梯度重建DeepONet，通过结合局部几何和物理信息正则化，显著提高了双曲守恒律（特别是欧拉方程）的精度和效率。

**AI_Comments:** 该研究的创新之处在于将数据驱动的DeepONet架构应用于非结构化网格上的梯度重建，并通过整合局部几何和物理信息正则化克服了传统方法的局限性。其重要性体现在显著提高了计算精度和效率，使得在更粗糙网格上进行高保真模拟成为可能，这对于复杂流体动力学模拟具有重要意义。该工作是机器学习与数值方法结合的典范，为未来的高性能求解器开发奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在增强双曲守恒律非结构化有限体积方法中的梯度重建，克服传统结构化网格方法的局限性，并提高现有二阶有限体积方案的精度和效率。

**Method:** 提出一种新颖的数据驱动方法，通过修改后的DeepONet架构将结构化网格方法扩展到非结构化网格。该架构整合了局部几何和网格拓扑以确保旋转不变性和一阶约束。训练过程中引入了物理信息正则化（包括熵惩罚、总变差递减惩罚和参数正则化），并在高保真数据集上进行训练。

**Result:** 与传统二阶有限体积方案相比，解决方案精度提高了20-60%，计算效率得到提升。网格收敛率有所改善，算法更快、更准确。能够在更粗糙的网格上实现高保真模拟，同时保持稳定性和守恒特性。

**Conclusion:** 所提出的结合机器学习工具与传统数值方案的算法，为双曲守恒律在非结构化网格上的求解提供了更快、更准确、更稳定的方法，能够在粗糙网格上进行高保真模拟，并确保物理一致性。

> **ai_Abstract:** 这篇论文提出了一种新颖的数据驱动方法，利用修改后的DeepONet架构，在非结构化有限体积方法中增强双曲守恒律（特别是2D欧拉方程）的梯度重建。该方法通过整合局部几何和网格拓扑确保旋转不变性与一阶约束，并采用物理信息正则化（如熵惩罚）来保证解的物理一致性。模型在高保真数据集上训练，并在验证案例中显示出比传统二阶方案更高的精度（提高20-60%）和计算效率，同时改善了网格收敛率。该算法更快、更准确，能在粗糙网格上进行高保真模拟，并保持稳定性和守恒性，代表了结合ML与传统数值方案的新一代求解器。

> **摘要翻译:** 我们提出了一种新颖的数据驱动方法，用于增强双曲守恒律非结构化有限体积方法中的梯度重建，特别是针对二维欧拉方程。我们的方法通过修改后的DeepONet架构将先前的结构化网格方法扩展到非结构化网格，该架构将局部几何结构整合到神经网络中。该架构采用局部网格拓扑结构以确保旋转不变性，同时确保学习算子的一阶约束。训练方法通过熵惩罚、总变差递减惩罚和参数正则化引入了物理信息正则化，以确保物理一致的解，特别是在激波主导区域。该模型在从正弦波和具有周期性边界条件的随机分段常数初始条件导出的高保真数据集解决方案上进行训练，从而能够稳健地推广到复杂的流动配置或几何形状。文献中的验证测试案例，包括具有挑战性的几何配置，表明与传统二阶有限体积方案相比，精度有大幅提高。该方法在提高计算效率的同时，解决方案精度提高了20-60%。已经进行了收敛性研究，结果显示与传统求解器相比，网格收敛率有所改善。所提出的算法比传统的二阶有限体积求解器更快、更准确，能够在更粗糙的网格上实现高保真模拟，同时保留双曲守恒律所必需的稳定性和守恒特性。这项工作是新一代求解器的一部分，这些求解器通过将机器学习（ML）工具与传统数值方案相结合而构建，同时确保结果的物理约束。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [544] [Exponential Runge-Kutta Galerkin finite element method for a reaction-diffusion system with nonsmooth initial data](https://arxiv.org/abs/2507.15345)
> *具有非光滑初始数据的反应扩散系统的指数Runge-Kutta Galerkin有限元方法*

*Runjie Zhang, Shuo Yang, Jinwei Fang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 反应扩散系统, 指数Runge-Kutta, Galerkin有限元, 非光滑初始数据, 误差估计

**Comment:** 

> **TL;DR:** 本文提出了一种用于处理具有非光滑初始数据的反应扩散系统的指数Runge-Kutta Galerkin有限元方法，并推导了其自适应初始数据平滑度的精确误差估计。

**AI_Comments:** 该研究的创新点在于其能够处理非光滑初始数据，并通过结合半群和分数阶Sobolev空间理论，推导出精确的误差估计，使得收敛阶能够自适应于初始数据的平滑度，这对于实际应用中常见的低正则性问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统数值方法在处理具有非光滑初始数据的反应扩散模型时，因违反经典正则性条件而无法进行有效误差分析的问题。

**Method:** 采用线性Galerkin有限元方法进行空间离散，二阶指数Runge-Kutta方案进行时间积分。初始数据假定在分数阶Sobolev空间H^gamma (0 < gamma < 2)中。通过结合半群技术和分数阶Sobolev空间理论进行误差分析。

**Result:** 在L2和H1范数下推导出了精确的完全离散误差估计。证明了收敛阶能够自适应于初始数据的平滑度，这优于假设更高正则性的传统方法。

**Conclusion:** 该研究提出的指数Runge-Kutta Galerkin有限元方法能够有效处理非光滑初始数据的反应扩散系统，其收敛性分析考虑了初始数据的低正则性，并提供了理论支持和数值验证。

> **ai_Abstract:** 本文提出了一种用于模拟具有非光滑初始数据的Field-Noyes反应扩散模型的指数Runge-Kutta Galerkin有限元方法。该方法结合了线性Galerkin空间离散和二阶指数Runge-Kutta时间积分。研究在分数阶Sobolev空间中对初始数据进行假设，并利用半群理论和分数阶Sobolev空间理论推导了L2和H1范数下的精确误差估计。核心贡献在于证明了该方法的收敛阶能够自适应于初始数据的平滑度，显著优于依赖高正则性假设的传统方法，并通过数值例子验证了理论。

> **摘要翻译:** 本研究对具有非光滑初始数据的Field-Noyes反应扩散模型进行了数值分析，采用线性Galerkin有限元方法进行空间离散，并采用二阶指数Runge-Kutta方案进行时间积分。初始数据假定位于分数阶Sobolev空间H^gamma中，其中0 < gamma < 2，这违反了经典的正则性条件，因此需要专门的误差分析。通过结合半群技术和分数阶Sobolev空间理论，在L2和H1范数下推导出了精确的完全离散误差估计。这表明收敛阶自适应于初始数据的平滑度，这是相对于假设更高正则性的传统方法的一个关键进步。提供了数值例子来支持理论分析。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [555] [Entropic approximations of the semigeostrophic shallow water equations](https://arxiv.org/abs/2507.16415)
> *准地转浅水方程的熵近似*

*Jean-David Benamou, Colin J. Cotter, Jacob J. M. Francis, Hugo Malamut* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 准地转浅水方程, 熵近似, 最优传输, 离散化, 迭代方法

**Comment:** 

> **TL;DR:** 本文基于最优传输公式，开发了一种准地转浅水方程的熵正则化离散化方法，并提出了一个收敛的迭代求解算法。

**AI_Comments:** 这项工作通过引入熵正则化和迭代求解方法，为准地转浅水方程的数值模拟提供了一种新颖且具有理论基础的离散化方案，特别是在处理最优传输公式方面显示出创新性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种基于最优传输公式的准地转旋转浅水方程的离散化方法。

**Method:** 首先，提出了旋转浅水方程的熵正则化版本。其次，通过用Dirac测度的加权和替换两个测度，并近似层深度的L2范数（定义势能），对正则化问题进行离散化。最后，提出了一种迭代方法来解决与两个测度相关的离散优化问题，并分析了其收敛性。

**Result:** 所提出的迭代方法在数值示例中得到了验证，并应用于求解时间相关的浅水问题。

**Conclusion:** 所提出的迭代方法能够有效地求解时间相关的准地转浅水问题，证明了其数值可行性和收敛性。

> **ai_Abstract:** 本文提出了一种基于最优传输公式的准地转浅水方程的熵近似离散化方法。该方法利用Moreau-Yoshida正则化Wasserstein度量，并通过熵正则化和将测度替换为Dirac测度加权和的方式离散化问题。研究提出了一种迭代求解算法，并分析了其收敛性，通过数值示例验证了其在求解时间相关浅水问题中的有效性。

> **摘要翻译:** 我们基于最优传输公式，开发了一种准地转旋转浅水方程的离散化方法。这采取了Wasserstein度量的Moreau-Yoshida正则化的形式。最优传输公式的解提供了以测度表示的浅水层深度，该测度本身是在准地转坐标变换下演化测度的前推。首先，我们提出并研究了旋转浅水方程的熵正则化版本。其次，我们通过用Dirac测度的加权和替换两个测度，并近似层深度的（平方）L2范数（定义势能），对正则化问题进行离散化。我们提出了一种迭代方法来解决与两个测度相关的离散优化问题，并分析了其收敛性。该迭代方法在数值示例中得到了数值验证，并应用于求解时间相关的浅水问题。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [584] [On finite precision block Lanczos computations](https://arxiv.org/abs/2507.16484)
> *关于有限精度块Lanczos计算*

*Dorota Šimonová, Petr Tichý* | **Category: math.NA, cs.NA, 65F10, 65F15, 65G50** | **Updated: 2025-07-22**

**Keywords:** 有限精度, 块Lanczos, 扰动分析, 数值稳定性, 延续过程

**Comment:** 26 pages; 9 figures

> **TL;DR:** 本文将Greenbaum关于有限精度Lanczos算法的理论扩展到块Lanczos算法，表明其结果可解释为在扰动后的较大矩阵上进行的精确块Lanczos计算，并探讨了使扰动保持较小的条件，但块情况下的条件满足性仍是开放问题。

**AI_Comments:** 本文在有限精度Lanczos算法的理论基础上进行了重要的扩展，将其应用于更复杂的块Lanczos算法。其创新点在于推广了延续过程并提出了在块情况下的扰动分析。尽管解决了一个重要问题，但论文也明确指出了块情况下条件满足性的开放性问题，这为未来的研究提供了方向。这项工作对于理解和改进数值线性代数中的算法稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Greenbaum在1989年证明了有限精度Lanczos算法的结果可以解释为应用于一个较大矩阵的精确Lanczos结果，这为有限精度Lanczos计算建立了数学模型。本文的动机是将这些思想扩展到块Lanczos算法。

**Method:** 本文将延续过程推广到块Lanczos算法，并通过精心构造的扰动在有限次迭代中完成该过程。推导了扰动保持较小，从而使模型矩阵的特征值接近原始矩阵的充分条件。最后，通过数值实验验证了延续过程的实际实现和条件的有效性。

**Result:** 经过k次迭代产生的块三对角矩阵可以解释为应用于一个较大的模型矩阵的精确块Lanczos算法的结果。推导出了保持所需扰动较小的充分条件，确保模型矩阵的特征值接近原始矩阵的特征值。数值实验演示了延续过程的实际实现，并经验性地评估了充分条件和扰动大小的有效性。

**Conclusion:** 在单向量情况下，这些条件总是可以满足的，但在块情况下，这些条件是否总是可以满足的问题仍然悬而未决。

> **ai_Abstract:** 本文将Greenbaum关于有限精度Lanczos算法的理论框架扩展到块Lanczos算法。研究表明，有限精度块Lanczos计算的结果可以被理解为对一个经过扰动、特征值与原始矩阵接近的较大模型矩阵执行精确块Lanczos算法的结果。论文推广了延续过程，并推导了使扰动保持较小的充分条件，但指出在块情况下这些条件是否总能满足仍是未解决的问题。数值实验验证了理论的实际应用和条件的有效性。

> **摘要翻译:** 在Greenbaum于1989年的开创性工作中，她证明了有限精度Lanczos算法在k次迭代后产生的结果可以解释为应用于一个较大矩阵的精确Lanczos结果，该矩阵的特征值位于原始矩阵特征值附近的小区间内。这为有限精度Lanczos计算建立了一个数学模型。在本文中，我们将这些思想扩展到块Lanczos算法。我们推广了延续过程，并表明它可以使用精心构造的扰动在有限次迭代中完成。k次迭代后产生的块三对角矩阵可以解释为由应用于一个较大模型矩阵的精确块Lanczos算法产生。我们推导了所需扰动保持较小的充分条件，确保模型矩阵的特征值保持接近原始矩阵的特征值。虽然在单向量情况下，这些条件总是可以满足的，正如Greenbaum基于Paige的结果所示，但在块情况下它们是否总是可以满足的问题仍然悬而未决。最后，我们提出了数值实验，演示了延续过程的实际实现，并经验性地评估了充分条件和扰动大小的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [614] [Neumann series of Bessel functions in direct and inverse spherically symmetric transmission eigenvalue problems](https://arxiv.org/abs/2507.16554)
> *球对称透射本征值问题中贝塞尔函数的诺伊曼级数及其正逆问题应用*

*Vladislav V. Kravchenko, L. Estefania Murcia-Lozano, Nikolaos Pallikarakis* | **Category: math.NA, cs.NA, math.CA** | **Updated: 2025-07-22**

**Keywords:** 透射本征值问题, 贝塞尔函数诺伊曼级数, 逆散射理论, 折射率重建, 球对称

**Comment:** 

> **TL;DR:** 本研究引入了一种新颖的基于贝塞尔函数诺伊曼级数（NSBF）的方法，以高精度解决球对称域中具有可变折射率的透射本征值问题（TEP）的正向和反向数值解，尤其是在处理实数和复数本征值以及有限本征值数据时。

**AI_Comments:** 该论文的创新之处在于引入了贝塞尔函数诺伊曼级数（NSBF）方法来解决透射本征值问题的正向和反向解，特别是在处理实数和复数本征值时表现出高精度。其优势在于通过简单的递归积分计算系数，并且无需对参数进行先验假设，同时提供了频谱补全技术以应对数据限制，这在实际应用中非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管理论上取得了 substantial 进展，但在球对称域中，对具有可变折射率且涵盖实数和复数本征值的透射本征值问题（TEP）的正向和反向数值求解仍然具有挑战性。

**Method:** 本研究引入了一种新颖的贝塞尔函数诺伊曼级数（NSBF）方法。通过 Liouville 变换将 TEP 重新表述为 Sturm-Liouville 方程，并将其特征函数展开为 NSBF，其系数通过简单的递归积分计算。对于正向问题，通过对截断的 NSBF 部分和进行求根来找到本征值。对于逆问题，开发了两步法：首先，通过新的基于 NSBF 的算法从频谱数据中恢复变换后的区间长度 $\delta$；其次，通过求解 NSBF 前几个系数的线性系统来重建折射率 $n(r)$。还实施了频谱补全技术以在本征值数据有限时解决相应的逆问题。

**Result:** 在正向问题中，通过对截断的 NSBF 部分和进行求根，以少量系数获得了高精度的实数或复数本征值。在逆问题中，该方法成功地从频谱数据中恢复了变换后的区间长度 $\delta$，并通过求解线性系统重建了折射率 $n(r)$。数值例子证实了该方法在各种折射率范围内的鲁棒性和准确性，无需对 $\delta$ 或对比度 $1-n(r)$ 的符号进行先验假设。频谱补全技术在有限本征值数据下也有效。

**Conclusion:** 本研究提出的基于贝塞尔函数诺伊曼级数（NSBF）的方法为解决球对称透射本征值问题的正向和反向数值解提供了高精度和鲁棒性，尤其是在处理实数和复数本征值以及有限本征值数据方面表现出色，且无需先验假设。

> **ai_Abstract:** 本研究提出了一种新颖的贝塞尔函数诺伊曼级数（NSBF）方法，用于解决球对称透射本征值问题（TEP）的正向和反向数值解。该方法首先将 TEP 转换为 Sturm-Liouville 方程，并利用 NSBF 展开其特征函数。在正向问题中，通过对截断的 NSBF 进行求根实现高精度本征值计算。在反向问题中，通过两步法恢复变换区间长度并重建折射率，同时引入频谱补全技术处理有限数据情况。数值结果验证了该方法在多种折射率情况下的鲁棒性和准确性。

> **摘要翻译:** 透射本征值问题（TEP）在逆散射理论中扮演着核心角色。尽管理论上取得了 substantial 进展，但在球对称域中，对具有可变折射率且涵盖实数和复数本征值的透射本征值问题（TEP）的正向和反向数值求解仍然具有挑战性。本研究引入了一种新颖的贝塞尔函数诺伊曼级数（NSBF）方法来解决这一挑战。通过 Liouville 变换将 TEP 重新表述为 Sturm-Liouville 方程后，我们将其特征函数展开为 NSBF，其系数通过简单的递归积分计算。在正向问题中，通过对截断的 NSBF 部分和进行求根来找到实数或复数本征值，如各种例子所示，以少量系数即可获得高精度。对于逆问题，我们开发了两步法：首先，通过新的基于 NSBF 的算法从频谱数据中恢复变换后的区间长度 $\delta$；其次，通过求解 NSBF 前几个系数的线性系统来重建折射率 $n(r)$。还实施了频谱补全技术以在本征值数据有限时完成频谱并解决相应的逆问题。数值例子证实了该方法在各种折射率范围内的鲁棒性和准确性，无需对 $\delta$ 或对比度 $1-n(r)$ 的符号进行先验假设。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [651] [A Conservative and Positivity-Preserving Discontinuous Galerkin Method for the Population Balance Equation](https://arxiv.org/abs/2507.16631)
> *群体平衡方程的保守且保正间断伽辽金方法*

*Ziyao Xu, Guanyang Liu, Yong-Tao Zhang* | **Category: math.NA, cs.NA** | **Updated: 2025-07-22**

**Keywords:** 群体平衡方程, 间断伽辽金方法, 守恒, 正性保持, 矩守恒

**Comment:** 

> **TL;DR:** 本文开发了一种用于群体平衡方程的保守且保正的间断伽辽金（DG）方法，创新性地处理了聚集和破碎项，实现了动量守恒和数密度正性保持。

**AI_Comments:** 该论文的主要创新点在于首次提出了一种能够同时保持数密度正性并守恒预设矩的数值算法，这对于群体平衡方程的准确和物理合理模拟至关重要，尤其是在处理复杂的聚集和破碎项时。该方法在保证守恒性和正性的同时，也展现出良好的准确性和鲁棒性。抽象中未提及具体限制，但这类高阶方法通常在计算成本上会有所增加。

<details>
  <summary>Details</summary>

**Motivation:** 在模拟粒子分布的群体平衡方程（PBE）中，确保粒子数和质量守恒以及数密度的正性是关键挑战。传统的数值方法在处理PBE的增长、成核、聚集和破碎等复杂过程时，难以同时满足这些物理约束，尤其是在聚集和破碎项中保持正性。

**Method:** 本文开发了一种保守且保正的间断伽辽金（DG）方法来求解群体平衡方程。对于增长和成核项采用标准处理；对于聚集和破碎项，引入了一种新颖的离散化方案，其中出生和死亡项被离散为对称双积分形式，并通过积分域的共同细化和精心选择的求积规则进行评估。为了保持数密度的正性，该方法通过证明每个单元上第一矩的正性，并构建了一个矩守恒限制器来强制全域非负性。

**Result:** 数值结果验证了所提出的间断伽辽金方法在处理群体平衡方程时的准确性、守恒性和鲁棒性。

**Conclusion:** 本文成功开发了一种保守且保正的间断伽辽金方法，能够有效地求解群体平衡方程。该方法在处理复杂的聚集和破碎项时，创新性地实现了预设矩的守恒和数密度正性保持，并通过数值验证表明其具有良好的性能。

> **ai_Abstract:** 本文提出了一种用于群体平衡方程（PBE）的保守且保正的间断伽辽金（DG）方法。该方法通过对增长和成核采用标准处理，并为聚集和破碎引入了新颖的离散化方案，以确保粒子数和质量守恒。特别地，针对聚集-破碎过程中数密度的正性保持问题，该研究通过证明第一矩的正性并构建了一个矩守恒限制器来强制全域非负性。该工作被认为是首次开发出一种同时保持正性并守恒预设矩的算法。数值结果证实了所提出方法的准确性、守恒性和鲁棒性。

> **摘要翻译:** 我们开发了一种保守、保正的间断伽辽金 (DG) 方法来求解群体平衡方程 (PBE)，该方程模拟由于生长、成核、聚集和破碎导致的粒子数量在粒子尺寸上的分布。为了确保生长中的数量守恒以及聚集和破碎中的质量守恒，我们设计了一种 DG 方案，该方案对生长和成核采用标准处理，并对聚集和破碎引入了一种新颖的离散化方法。出生和死亡项以对称双积分形式离散，通过对积分域的共同细化和精心选择的求积规则进行评估。除了守恒性，我们还专注于保持聚集-破碎过程中数密度的正性。由于局部质量对应于一阶矩，因此保留零阶矩（单元平均值）的经典 Zhang-Shu 限制器不能直接适用。我们通过证明每个单元上第一矩的正性并构建一个强制全域非负性的矩守恒限制器来解决这个问题。据我们所知，这是首次开发出一种既能保持正性又能守恒给定矩的算法。数值结果验证了所提出方法的准确性、守恒性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [687] [A quasi-Monte Carlo multiscale method for the wave propagation in random media](https://arxiv.org/abs/2507.16647)
> *随机介质中波传播的准蒙特卡罗多尺度方法*

*Panchi Li, Zhiwen Zhang* | **Category: math.NA, cs.NA, 35J05, 35R60, 65D30, 65N30** | **Updated: 2025-07-22**

**Keywords:** 准蒙特卡罗, 多尺度方法, 亥姆霍兹问题, 随机介质, 波传播

**Comment:** 

> **TL;DR:** 本文提出并分析了一种结合准蒙特卡罗和边界校正多尺度方法的数值方法，用于模拟随机介质中的亥姆霍兹问题，并在物理和随机空间中均展现出高阶收敛性。

**AI_Comments:** 该论文创新性地结合了准蒙特卡罗方法和边界校正多尺度方法来解决随机介质中的亥姆霍兹问题，特别是在处理随机Robin边界条件方面。其理论分析和数值验证展示了方法的高精度和效率，尤其是在物理和随机空间中的高阶收敛性，这对于波传播模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 模拟具有随机折射率的有界区域中的亥姆霍兹问题，并准确计算解的统计量。

**Method:** 提出了一种结合准蒙特卡罗（qMC）方法和边界校正多尺度方法的数值方法。首先截断随机折射率的参数化模型，利用qMC生成随机变量。随后，开发边界校正多尺度方法离散截断问题，以精确处理带有随机性的Robin边界条件。

**Result:** 该方法在物理空间中展现出超收敛速度（$L^2$误差为$\mathcal{O}(H^4)$，特定$V$误差为$\mathcal{O}(H^2)$），并在随机空间中由于采用qMC方法而表现出接近一阶的收敛速度。

**Conclusion:** 提出的准蒙特卡罗多尺度方法通过波数显式收敛分析和数值实验得到了验证，证明了其在模拟随机介质中亥姆霍兹问题时的准确性和高效性。

> **ai_Abstract:** 本文提出了一种用于模拟随机介质中亥姆霍兹问题的精确数值方法。该方法通过截断随机折射率模型并结合准蒙特卡罗（qMC）方法生成随机变量。同时，开发了边界校正多尺度方法来离散截断问题，以准确处理带有随机性的Robin边界条件。理论分析和数值实验表明，该方法在物理空间中具有超收敛速度，在随机空间中具有接近一阶的收敛速度，验证了其有效性。

> **摘要翻译:** 在本文中，我们提出并分析了一种精确的数值方法，用于模拟具有随机折射率的有界区域中的亥姆霍兹问题，其中随机折射率使用由随机变量参数化的无限级数表示。为了数值计算解的统计量，我们首先截断参数化模型，并采用准蒙特卡罗（qMC）方法生成随机变量。我们开发了一种边界校正多尺度方法来离散截断问题，这使我们能够准确地解决带有随机性的Robin边界条件。所提出的方法在物理空间中表现出超收敛速度（理论分析表明$L^2$误差为$\mathcal{O}(H^4)$，定义的$V$误差为$\mathcal{O}(H^2)$）。由于采用了qMC方法，它在随机空间中也表现出接近一阶的收敛速度。我们提供了波数显式收敛分析，并进行了数值实验以验证所提出方法的关键特征。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [726] [A $\star$-Product Approach for Analytical and Numerical Solutions of Nonautonomous Linear Fractional Differential Equations](https://arxiv.org/abs/2507.16652)
> *非自治线性分数阶微分方程解析解和数值解的$\%star$-乘积方法*

*Fabio Durastante, Pierre-Louis Giscard, Stefano Pozza* | **Category: math.NA, cs.NA, 26A33, 65L05, 33C45** | **Updated: 2025-07-22**

**Keywords:** 分数阶微分方程, $\%star$-乘积, 非自治, 解析解, 数值解

**Comment:** 

> **TL;DR:** 提出了一种基于$\%star$-乘积的新方法，用于求解非自治线性分数阶微分方程的解析解和数值解，并能在某些情况下得到闭合形式解。

**AI_Comments:** 该论文提出了一种新颖的$\%star$-乘积方法，用于求解非自治线性分数阶微分方程，这在理论和应用上都具有重要意义。特别是其能够推导出闭合形式解的能力，进一步增强了该方法的实用性和吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 解决非自治线性常分数阶微分方程的解析解和数值解问题，并提出一种新颖的求解方法。

**Method:** 该方法通过使用$\%star$-乘积（Volterra卷积的推广）重新构建解析解，然后对所得表达式进行适当的离散化。

**Result:** 该方法为非自治线性常分数阶微分方程提供了一种新的求解途径。此外，研究表明在某些情况下，$\%star$-形式能够推导出闭合形式解。

**Conclusion:** 基于$\%star$-乘积的方法为非自治线性分数阶微分方程的解析解和数值解提供了一种有效且新颖的框架，特别是在某些情况下还能得到闭合形式解，突显了其效用。

> **ai_Abstract:** 本文介绍了一种创新的方法，利用$\%star$-乘积（Volterra卷积的泛化）来解决非自治线性常分数阶微分方程的解析解和数值解问题。该方法首先重构解析解，然后进行离散化。研究还表明，在特定条件下，这种$\%star$-形式能够推导出闭合形式解，从而凸显了该框架的广泛适用性。

> **摘要翻译:** 本文提出了一种求解非自治线性常分数阶微分方程的新型解法。该方法基于使用$\%star$-乘积（Volterra卷积的推广）重新构建解析解，然后对所得表达式进行适当的离散化。此外，我们证明在某些情况下，$\%star$-形式能够推导出闭合形式解，进一步突出了该框架的实用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [28] [Nonlinear Framework for Speech Bandwidth Extension](https://arxiv.org/abs/2507.15970)
> *语音带宽扩展的非线性框架*

*Tarikul Islam Tamiti, Nursad Mamun, Anomadarshi Barua* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-21**

**Keywords:** 语音带宽扩展, 非线性动力学系统, 对抗性网络, 深度学习, ConformerNeXt

**Comment:** 

> **TL;DR:** 提出NDSI-BWE，一个基于非线性动力学系统启发的新型对抗性语音带宽扩展框架，通过七个鉴别器和复合生成器实现参数量减少八倍，并在带宽扩展任务上达到新的SOTA。

**AI_Comments:** 这篇论文的创新点在于将非线性动力学系统的概念引入到鉴别器设计中，以更精细地捕捉语音信号的复杂时间行为。通过引入七个专门的鉴别器，并结合高效的深度卷积和先进的生成器架构，实现了参数量大幅减少的同时，达到了SOTA性能，这对于资源受限的高保真音频应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 恢复因带宽限制而丢失的高频分量对于从电信到有限资源上的高保真音频等应用至关重要。

**Method:** 本文提出了NDSI-BWE，一个新型对抗性带宽扩展（BWE）框架。该框架利用七个受非线性动力学系统启发的鉴别器来捕获多样化的时间行为，包括：多分辨率Lyapunov鉴别器(MRLD)、多尺度循环鉴别器(MS-RD)、多尺度去趋势分形分析鉴别器(MSDFA)、多分辨率Poincaré图鉴别器(MR-PPD)、多周期鉴别器(MPD)、多分辨率幅度鉴别器(MRAD)和多分辨率相位鉴别器(MRPD)。这些鉴别器通过深度卷积实现八倍的参数减少。七个鉴别器引导一个基于复数值ConformerNeXt的双流Lattice-Net生成器，用于同时细化幅度和相位，该生成器结合了Conformer的全局依赖建模和ConvNeXt的局部时间建模能力。

**Result:** NDSI-BWE在六个客观评估指标和由五名人类评委组成的主观测试中，在BWE领域建立了新的SOTA（State-of-the-Art）。

**Conclusion:** NDSI-BWE是一个创新的非线性对抗性框架，显著提升了语音带宽扩展的性能，达到了当前最佳水平。

> **ai_Abstract:** 本文提出了NDSI-BWE，一个新颖的基于非线性动力学系统启发的对抗性语音带宽扩展（BWE）框架。该框架包含七个独特的鉴别器，能够捕捉音频信号中复杂的非线性时间特性，并通过深度卷积实现显著的参数量减少。结合一个创新的复数值ConformerNeXt生成器，NDSI-BWE在多项客观和主观评估中，实现了语音带宽扩展的最新技术水平。

> **摘要翻译:** 恢复因带宽限制而丢失的高频分量对于从电信到有限资源上的高保真音频等应用至关重要。我们引入了NDSI-BWE，一个受非线性动力学系统启发的新型对抗性带宽扩展（BWE）框架，它利用七个新的鉴别器来捕获多样化的时间行为：一个多分辨率Lyapunov鉴别器（MRLD）用于通过捕获确定性混沌来确定对初始条件的敏感性，一个多尺度循环鉴别器（MS-RD）用于自相似循环动力学，一个多尺度去趋势分形分析鉴别器（MSDFA）用于长程慢变尺度不变关系，一个多分辨率Poincaré图鉴别器（MR-PPD）用于捕获隐藏的潜在空间关系，一个多周期鉴别器（MPD）用于周期性模式，一个多分辨率幅度鉴别器（MRAD）和多分辨率相位鉴别器（MRPD）用于捕获复杂的幅度-相位转换统计。通过在每个鉴别器中的卷积块核心使用深度卷积，NDSI-BWE实现了八倍的参数减少。这七个鉴别器引导一个基于复数值ConformerNeXt的生成器，该生成器采用双流Lattice-Net架构，用于同时细化幅度和相位。该生成器利用了基于Transformer的Conformer的全局依赖建模能力和ConvNeXt块的局部时间建模能力。在六个客观评估指标和由五名人类评委组成的主观测试中，NDSI-BWE在BWE领域建立了新的SOTA。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [138] [SDBench: A Comprehensive Benchmark Suite for Speaker Diarization](https://arxiv.org/abs/2507.16136)
> *SDBench：一个全面的说话人分离基准测试套件*

*Eduardo Pacheco, Atila Orhon, Berkin Durmus, Blaise Munyampirwa, Andrey Leonov* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 说话人分离, 基准测试, SDBench, 性能评估, 开源

**Comment:** 

> **TL;DR:** SDBench是一个开源的说话人分离基准测试套件，集成了13个多样化数据集和内置工具，用于对各种系统进行一致且细粒度的性能分析。它能够实现可复现的评估，并帮助开发出更快的系统，如SpeakerKit，同时揭示了现有系统在准确性和速度之间的权衡。

**AI_Comments:** SDBench的创新之处在于其整合了多样化数据集和提供一致性分析工具，解决了说话人分离领域长期存在的评估标准不统一和难以进行公平比较的问题。其重要性体现在能够促进系统开发（如SpeakerKit的加速），并为业界提供了评估和选择合适系统的标准。这是一个非常有价值的贡献，能加速该领域的研究和应用落地。

<details>
  <summary>Details</summary>

**Motivation:** 现有的说话人分离系统在不同数据集上的错误率差异很大，且系统间比较缺乏一致的最佳实践，导致难以进行公平对比。因此，需要一个标准化的工具来全面、一致地评估和比较这些系统。

**Method:** 本文提出了SDBench（说话人分离基准测试），一个开源的基准测试套件。SDBench集成了13个多样化的数据集，并内置了工具，用于对各种片上设备和服务器端系统的说话人分离性能进行一致且细粒度的分析。它支持可复现的评估，并方便新系统的集成。

**Result:** SDBench成功地帮助开发了SpeakerKit，一个基于Pyannote v3且专注于推理效率的系统。通过SDBench，快速执行的消融研究使得SpeakerKit比Pyannote v3快9.6倍，同时保持了相当的错误率。此外，对包括Deepgram、AWS Transcribe和Pyannote AI API在内的6个最先进系统进行的基准测试，揭示了准确性和速度之间的重要权衡。

**Conclusion:** SDBench作为一个全面的开源基准测试套件，有效地解决了说话人分离系统评估中一致性和可复现性不足的问题。它不仅能促进新系统的开发和优化（如SpeakerKit），还能帮助揭示现有系统在性能上的权衡，为领域内的研究和应用提供了宝贵的工具。

> **ai_Abstract:** SDBench是一个开源的说话人分离基准测试套件，旨在解决当前系统性能评估中数据集差异大和比较标准不一致的问题。它整合了13个多样化数据集和内置分析工具，支持对各种在设备端和服务器端系统的说话人分离性能进行细致且可复现的评估。通过SDBench，研究人员能够高效地进行系统开发和优化，例如，利用它开发出的SpeakerKit比Pyannote v3快9.6倍且保持同等错误率。SDBench还揭示了现有顶尖系统在准确性和速度之间的关键权衡，为说话人分离领域提供了一个统一且高效的评估平台。

> **摘要翻译:** 即使是目前最先进的说话人分离系统，在不同数据集上的错误率也表现出高度差异，这些数据集代表了众多的使用场景和领域。此外，系统间的比较需要仔细应用最佳实践，例如数据集划分和度量定义，以实现公平对比。我们提出了SDBench（说话人分离基准测试），一个开源的基准测试套件，它集成了13个多样化的数据集，并内置了工具，用于对各种片上设备和服务器端系统的说话人分离性能进行一致且细粒度的分析。SDBench能够实现可复现的评估，并随着时间的推移轻松集成新系统。为了展示SDBench的有效性，我们构建了SpeakerKit，一个基于Pyannote v3并专注于推理效率的系统。SDBench使得快速执行消融研究成为可能，从而使SpeakerKit比Pyannote v3快9.6倍，同时实现了相当的错误率。我们对包括Deepgram、AWS Transcribe和Pyannote AI API在内的6个最先进系统进行了基准测试，揭示了准确性和速度之间的重要权衡。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [293] [Detect Any Sound: Open-Vocabulary Sound Event Detection with Multi-Modal Queries](https://arxiv.org/abs/2507.16343)
> *检测任何声音：基于多模态查询的开放词汇声音事件检测*

*Pengfei Cai, Yan Song, Qing Gu, Nan Jiang, Haoyu Song, Ian McLoughlin* | **Category: cs.SD, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 开放词汇声音事件检测, 多模态查询, 零样本学习, 双流解码器, 帧级检索

**Comment:** Accepted by MM 2025

> **TL;DR:** DASM是一种新的开放词汇声音事件检测框架，通过多模态查询实现，并在开放和封闭集设置中均表现出色，甚至在零样本跨数据集评估中超越了有监督基线。

**AI_Comments:** 本文的创新点在于提出了一个基于多模态查询的开放词汇SED框架DASM，通过将SED任务转化为帧级检索，并引入了独特的双流解码器和推理时注意力掩码策略，有效解决了现有方法在开放词汇场景下泛化能力不足的问题。其在零样本跨数据集评估中超越有监督基线的表现，预示着开放词汇SED领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有声音事件检测（SED）算法在预定义类别下运行，限制了其检测能力。尽管近期研究探索了语言驱动的零样本SED，但由于缺乏细粒度对齐和跨模态特征融合，其性能仍不理想。

**Method:** 本文提出了Detect Any Sound Model (DASM)，一个由多模态查询（文本或音频提示）引导的基于查询的开放词汇SED框架。DASM将SED公式化为帧级检索任务。它引入了一个双流解码器，明确解耦事件识别（通过跨模态事件解码器）和时间定位（通过上下文网络）。此外，还提出了一种推理时注意力掩码策略，以利用基类和新类之间的语义关系，增强泛化能力。

**Result:** 在AudioSet Strong数据集上，DASM在开放词汇设置中性能优于CLAP-based方法（+7.8 PSDS），在封闭集设置中优于基线（+6.9 PSDS）。在DESED上的跨数据集零样本评估中，DASM的PSDS1得分达到42.2，甚至超过了有监督的CRNN基线。

**Conclusion:** DASM通过其多模态查询和独特的双流解码器设计，有效平衡了定位准确性与对新类别的泛化能力，显著提升了开放词汇声音事件检测的性能，并在零样本设置中表现出色。

> **ai_Abstract:** 本文提出了DASM（Detect Any Sound Model），一个创新的基于查询的开放词汇声音事件检测框架。DASM通过将SED视为帧级检索任务，并利用文本或音频提示的多模态查询，克服了现有方法的封闭集限制和零样本性能不足的问题。其核心在于一个双流解码器，负责解耦事件识别和时间定位，并结合推理时注意力掩码策略，以增强对新类别的泛化能力。实验证明，DASM在开放词汇和封闭集SED任务上均显著优于现有基线，并在零样本跨数据集评估中甚至超越了有监督模型。

> **摘要翻译:** 大多数现有的声音事件检测（SED）算法在封闭集假设下运行，将其检测能力限制在预定义的类别中。虽然最近的研究探索了通过利用音频-语言模型进行语言驱动的零样本SED，但由于缺乏细粒度对齐和跨模态特征融合，它们的性能仍远不能令人满意。在这项工作中，我们提出了检测任何声音模型（DASM），这是一个由多模态查询引导的基于查询的开放词汇SED框架。DASM将SED公式化为帧级检索任务，其中音频特征与从文本或音频提示派生的查询向量进行匹配。为了支持这种公式，DASM引入了一个双流解码器，明确地解耦了事件识别和时间定位：一个跨模态事件解码器执行查询-特征融合并确定剪辑级别的声音事件存在，而上下文网络建模时间依赖性以进行帧级定位。此外，提出了一种推理时注意力掩码策略，以利用基类和新类之间的语义关系，从而大大增强了对新类的泛化能力。在AudioSet Strong数据集上的实验表明，DASM有效地平衡了定位准确性与对新类的泛化能力，在开放词汇设置中优于基于CLAP的方法（+ 7.8 PSDS），在封闭集设置中优于基线（+ 6.9 PSDS）。此外，在DESED上的跨数据集零样本评估中，DASM的PSDS1得分达到42.2，甚至超过了有监督的CRNN基线。项目页面可在https://cai525.github.io/Transformer4SED/demo_page/DASM/获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [440] [LABNet: A Lightweight Attentive Beamforming Network for Ad-hoc Multichannel Microphone Invariant Real-Time Speech Enhancement](https://arxiv.org/abs/2507.16190)
> *LABNet：一种用于自组织多通道麦克风不变实时语音增强的轻量级注意力波束形成网络*

*Haoyin Yan, Jie Zhang, Chengqian Jiang, Shuang Zhang* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 语音增强, 波束形成, 麦克风不变性, 轻量级网络, 自组织阵列

**Comment:** 

> **TL;DR:** LABNet是一种轻量级、注意力波束形成网络，它在保持麦克风不变性的同时，以超低资源开销实现了高性能的实时多通道语音增强，适用于自组织阵列。

**AI_Comments:** 该论文的创新点在于提出了LABNet，一个将麦克风不变性与轻量化设计相结合的实时语音增强系统。其采用的三阶段框架和跨通道注意力模块是实现高效性能的关键。这对于资源受限的边缘设备应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多通道语音增强在边缘设备应用中面临计算负担重的问题，特别是在自组织阵列条件下需要处理不同麦克风数量和阵列几何形状（麦克风不变性）。因此，需要开发一种轻量级、高效且能保持麦克风不变性的实时语音增强系统。

**Method:** 本文提出了一种轻量级注意力波束形成网络（LABNet）。它设计了一个三阶段框架，用于高效的通道内建模和通道间交互。开发了一个跨通道注意力模块，以选择性地聚合来自每个通道的特征。

**Result:** LABNet在保持麦克风不变性的同时，以超轻的资源开销实现了令人印象深刻的性能。

**Conclusion:** LABNet在自组织阵列处理方面具有巨大潜力，因为它能够以低资源消耗实现高性能的实时多通道语音增强并保持麦克风不变性。

> **ai_Abstract:** LABNet是一种新颖的轻量级注意力波束形成网络，旨在解决自组织多通道麦克风阵列中实时语音增强的计算开销和麦克风不变性问题。该网络采用三阶段框架，并引入跨通道注意力模块，以高效地处理通道内信息和通道间交互。实验证明，LABNet在保持麦克风不变性的同时，以极低的资源消耗实现了卓越的语音增强性能，展示了其在实际应用中的巨大潜力。

> **摘要翻译:** 多通道语音增强（SE）旨在通过利用时空信号特征从噪声测量中恢复干净的语音。在自组织阵列条件下，麦克风不变性（MI）要求系统能够处理不同数量的麦克风和阵列几何形状。从实际角度来看，多通道录音不可避免地增加了边缘设备应用的计算负担，突显了轻量级和高效部署的必要性。在这项工作中，我们提出了一种轻量级注意力波束形成网络（LABNet），将MI集成到低复杂度的实时SE系统中。我们设计了一个三阶段框架，用于高效的通道内建模和通道间交互。开发了一个跨通道注意力模块，以选择性地聚合来自每个通道的特征。实验结果表明，我们的LABNet以超轻的资源开销实现了令人印象深刻的性能，同时保持了MI，表明其在自组织阵列处理方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [482] [TTMBA: Towards Text To Multiple Sources Binaural Audio Generation](https://arxiv.org/abs/2507.16564)
> *TTMBA：迈向文本到多源双耳音频生成*

*Yuxuan He, Xiaoran Yang, Ningning Pan, Gongping Huang* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 文本到双耳音频, 多源音频, 空间音频, 级联方法, 大型语言模型

**Comment:** 5 pages,3 figures,2 tables

> **TL;DR:** TTMBA是一种将文本转换为具有时间和空间控制的多源双耳音频的级联方法，解决了现有文本到音频方法缺乏空间信息的问题。

**AI_Comments:** TTMBA的创新之处在于其级联方法，结合了LLM进行文本解析和空间信息提取，以及专门的双耳渲染网络，有效解决了传统TTA在空间维度上的不足。这对于提升沉浸式听觉体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有文本到音频（TTA）生成方法产生单声道输出，忽略了沉浸式听觉体验所必需的空间信息。为解决此问题，本文提出了TTMBA。

**Method:** TTMBA采用级联方法：首先，预训练的大型语言模型（LLM）将文本分割成包含每个声音事件的时间和空间细节的结构化格式；其次，预训练的单声道音频生成网络为每个事件创建多个不同持续时间的单声道音频；接着，利用基于LLM提供的空间数据的双耳渲染神经网络将这些单声道音频转换为双耳音频；最后，根据起始时间排列双耳音频，生成多源双耳音频。

**Result:** 实验结果表明，所提出的方法在音频生成质量和空间感知准确性方面均表现出优越性。

**Conclusion:** TTMBA方法成功地实现了具有时间和空间控制的文本到多源双耳音频生成，显著提升了音频生成质量和空间感知准确性，弥补了现有TTA方法在空间信息方面的不足。

> **ai_Abstract:** 本文提出了一种名为TTMBA的级联方法，旨在解决现有文本到音频（TTA）生成方法缺乏空间信息的问题，实现文本到多源双耳音频的生成。该方法首先利用大型语言模型（LLM）从文本中提取时间与空间信息，随后通过单声道音频生成网络创建单声道音频，并通过双耳渲染网络将其转换为双耳音频，最终合成多源双耳音频。实验证明，TTMBA在音频质量和空间感知准确性上均表现出色。

> **摘要翻译:** 大多数现有的文本到音频（TTA）生成方法产生单声道输出，忽略了沉浸式听觉体验所必需的关键空间信息。为了解决这个问题，我们提出了一种级联方法，用于文本到多源双耳音频生成（TTMBA），该方法具有时间和空间控制能力。首先，一个预训练的大型语言模型（LLM）将文本分割成一个结构化格式，其中包含每个声音事件的时间和空间细节。接下来，一个预训练的单声道音频生成网络为每个事件创建多个不同持续时间的单声道音频。这些单声道音频利用基于LLM提供的空间数据的双耳渲染神经网络转换为双耳音频。最后，双耳音频根据其起始时间进行排列，从而形成多源双耳音频。实验结果表明，所提出的方法在音频生成质量和空间感知准确性方面均表现出优越性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [491] [LENS-DF: Deepfake Detection and Temporal Localization for Long-Form Noisy Speech](https://arxiv.org/abs/2507.16220)
> *LENS-DF：长篇嘈杂语音的深度伪造检测和时间定位*

*Xuechen Liu, Wanying Ge, Xin Wang, Junichi Yamagishi* | **Category: cs.SD, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 深度伪造检测, 时间定位, 嘈杂语音, LENS-DF, 音频深度伪造

**Comment:** Accepted by IEEE International Joint Conference on Biometrics (IJCB)
  2025, Osaka, Japan

> **TL;DR:** LENS-DF是一种用于在复杂现实条件下训练和评估音频深度伪造检测和时间定位的新方法，其训练的模型表现优于传统方法。

**AI_Comments:** LENS-DF的创新之处在于其提供了一种全面的“食谱”，能够生成具有复杂真实世界特征（如长持续时间、噪音、多说话人）的合成音频数据，这对于训练和评估鲁棒的深度伪造检测模型至关重要。它通过解决现实世界中音频深度伪造的复杂性，提高了检测和定位的性能，对于打击深度伪造技术具有重要意义。该研究通过消融实验进一步验证了其引入变体对现实挑战的影响，增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂和真实的音频条件下，对音频深度伪造进行鲁棒的检测和时间定位是一个挑战。

**Method:** 本研究提出LENS-DF，一种用于训练和评估音频深度伪造检测和时间定位的新颖全面方案。该方案的生成部分可控地输出具有长持续时间、嘈杂条件和包含多说话人等关键特征的音频。相应的检测和定位协议使用模型，并基于自监督学习前端和简单后端进行实验。

**Result:** 使用LENS-DF生成数据训练的模型始终优于通过传统方案训练的模型。

**Conclusion:** LENS-DF在鲁棒的音频深度伪造检测和定位方面表现出有效性和实用性。

> **ai_Abstract:** LENS-DF是一种新颖全面的方案，旨在解决复杂真实音频环境下的音频深度伪造检测和时间定位问题。该方案能生成具有长持续时间、噪音和多说话人等特征的音频数据，并结合自监督学习前端和简单后端进行模型训练和评估。实验结果表明，LENS-DF训练的模型在鲁棒性方面显著优于传统方法，证实了其在实际应用中的有效性和实用性。

> **摘要翻译:** 本研究介绍了LENS-DF，一种新颖且全面的方案，用于在复杂和真实的音频条件下训练和评估音频深度伪造检测和时间定位。该方案的生成部分以可控的方式从输入数据集中输出具有几个关键特征的音频，例如更长的持续时间、嘈杂条件和包含多个说话者。相应的检测和定位协议使用模型。我们基于自监督学习前端和简单后端进行实验。结果表明，使用LENS-DF生成数据训练的模型始终优于通过传统方案训练的模型，这证明了LENS-DF在鲁棒的音频深度伪造检测和定位方面的有效性和实用性。我们还对引入的变体进行了消融研究，调查它们对该领域现实挑战的影响和相关性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [565] [SALM: Spatial Audio Language Model with Structured Embeddings for Understanding and Editing](https://arxiv.org/abs/2507.16724)
> *SALM：用于理解和编辑的结构化嵌入空间音频语言模型*

*Jinbo Hu, Yin Cao, Ming Wu, Feiran Yang, Jun Yang* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 空间音频, 语言模型, 多模态学习, 结构化嵌入, 音频编辑

**Comment:** 5 pages, 1 figure

> **TL;DR:** SALM是一个新的框架，它通过多模态对比学习将空间音频和语言联系起来，能够理解和编辑空间音频，支持零样本方向分类和基于文本的空间音频编辑。

**AI_Comments:** 该论文提出的SALM模型通过引入结构化嵌入和双分支音频编码器，有效地解决了现有音频-语言模型在空间音频处理上的局限性。其创新点在于将空间声音分解为语义和空间分量，并实现跨模态对齐，这对于空间声学场景的理解和编辑具有重要意义。支持零样本分类和文本驱动编辑是其重要的优势，展示了广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频-语言模型在处理空间音频和感知空间声学场景方面存在困难，而空间音频理解对于准确感知和解释声学环境至关重要。

**Method:** SALM（空间音频语言模型）通过多模态对比学习将空间音频与语言连接起来。它由一个文本编码器和一个双分支音频编码器组成，通过结构化音频嵌入将空间声音分解为语义和空间分量。其关键特性包括空间和文本表示的无缝对齐、空间和语义信息的单独及联合提取、零样本方向分类以及对空间音频编辑的鲁棒支持。

**Result:** 实验结果表明，SALM能够有效地捕获和对齐跨模态表示。此外，它支持高级编辑功能，例如使用基于文本的嵌入改变定向音频。

**Conclusion:** SALM成功地弥合了空间音频和语言之间的鸿沟，实现了有效的空间音频理解和编辑能力。

> **ai_Abstract:** SALM是一个创新的空间音频语言模型，旨在解决现有模型在处理空间音频方面的不足。它通过多模态对比学习，将空间音频分解为语义和空间成分，实现空间音频与文本的对齐。SALM支持零样本方向分类和基于文本的空间音频编辑，实验证明其在跨模态表示捕获和对齐方面表现出色。

> **摘要翻译:** 空间音频理解对于准确感知和解释声学环境至关重要。然而，现有音频-语言模型在处理空间音频和感知空间声学场景方面存在困难。我们引入了空间音频语言模型（SALM），这是一个通过多模态对比学习连接空间音频和语言的新颖框架。SALM由一个文本编码器和一个双分支音频编码器组成，通过结构化音频嵌入将空间声音分解为语义和空间分量。SALM的关键特性包括空间和文本表示的无缝对齐、空间和语义信息的单独和联合提取、零样本方向分类以及对空间音频编辑的鲁棒支持。实验结果表明，SALM有效地捕获并对齐了跨模态表示。此外，它支持高级编辑功能，例如使用基于文本的嵌入改变定向音频。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [622] [A new XML conversion process for mensural music encoding : CMME\_to\_MEI (via Verovio)](https://arxiv.org/abs/2507.15991)
> *一种新的量度音乐编码XML转换过程：CMME_to_MEI（通过Verovio）*

*David Fiala, Laurent Pugin, Marnix van Berchum, Martha Thomae, Kévin Roger* | **Category: cs.SD, cs.DB** | **Updated: 2025-07-17**

**Keywords:** CMME, MEI, 音乐编码, Verovio, 转换工具

**Comment:** 

> **TL;DR:** 本文介绍了一种新的工具，通过Verovio将过时的CMME音乐XML文件转换为现代MEI格式，从而赋予一个大型语料库新的生命，并提供了一个新的编码流程。

**AI_Comments:** 本文的创新之处在于其直接在Verovio中开发了CMME到MEI的转换器，这对于一个重要但小众的历史音乐编码领域具有重要意义。双重转换（先到MEI量度音乐，再到MEI CMN）的设计考虑周全，旨在实现更广泛的兼容性。这项工作对于数字音乐学而言至关重要，因为它使一个庞大而有价值的历史音乐语料库得以保存和访问，该语料库此前被困于过时的格式中，从而弥合了传统数据与现代标准之间的鸿沟。它还为量度音乐编码的持续工作提供了一个实用的解决方案。尽管论文未明确提及转换器本身的局限性，但它强调了对独立CMME编辑器进行初始编码的持续依赖，这表明仍需要一个针对量度音乐的原生MEI编辑器。此外，提到“最小的信息损失”也暗示了CMN转换过程中可能存在（尽管很小）的数据损失。

<details>
  <summary>Details</summary>

**Motivation:** 法国图尔大学文艺复兴高级研究中心Ricercar实验室决定开放访问一个包含约3500个15世纪音乐XML文件的语料库，该语料库采用专门为量度音乐设计的CMME格式编码。然而，CMME格式及其配套工具自21世纪初以来未曾更新，无法满足当前音乐编码的最新标准（MEI）。因此，需要开发转换工具，使现有CMME语料库焕发新生，并为量度音乐的编码和编辑提供新的流程，因为目前尚无原生的MEI替代编辑器。

**Method:** 研究团队开发了一套将CMME文件转换为MEI格式的转换工具。为此，于2024年9月在巴黎Campus Condorcet组织了一场汇集了量度音乐符号、XML格式和编程领域专家的研讨会。他们直接在开源渲染库Verovio中开发了一个转换器，实现了从CMME到MEI量度音乐的转换。随后，又实现了向MEI CMN（通用音乐符号）的转换。

**Result:** 开发了一个直接在Verovio中运行的转换器，实现了CMME到MEI量度音乐的转换。同时，也实现了向MEI CMN的转换，这使得这些文件能够以最小的信息损失加载到MuseScore等常用雕版软件中。由于CMME-XML文件可以直接导入Verovio，现有的CMME语料库得以重获新生。此外，由于独立的CMME编辑器仍能正常工作且尚无原生的MEI替代品，该转换器为量度音乐的编码和编辑提供了一个新的流程。

**Conclusion:** 本文开发的CMME到MEI转换工具（通过Verovio）为重要的历史音乐语料库提供了关键的更新，使其能够被现代工具访问，并为量度音乐的编码和编辑提供了一种新的、可行的工作流程。

> **ai_Abstract:** 本文详细介绍了将一个庞大的15世纪量度音乐语料库（最初以过时的CMME XML格式编码）转换为现代MEI标准的转换工具的开发过程。这些工具在Verovio渲染库中开发，实现了从CMME到MEI量度音乐的转换，并进一步转换为MEI CMN，从而与当代音乐雕版软件兼容。这项工作使大量CMME语料库得以重新焕发活力，并为量度音乐的编码和编辑建立了一个新流程，解决了旧格式工具未更新的问题。

> **摘要翻译:** 图尔大学文艺复兴高级研究中心Ricercar实验室（音乐学研究团队）在法国数字基础设施Biblissima的支持下，决定开放访问一个大型的15世纪音乐语料库，其中包含约3500个XML文件。该语料库由德国音乐学家Clemens Goldberg自2010年起编码而成，内容包括34份主要的15世纪音乐手稿及其他补充文件，旨在通过其基金会网站提供杜费、比努瓦、奥克格姆、布斯诺瓦及其大部分主要同期作曲家作品完整集的PDF文件，重点关注他们的世俗作品。该语料库采用名为CMME（计算机量度音乐编辑）的XML格式编码，该格式由Theodor Dumitrescu在21世纪初专门为量度音乐设计，并附带了自那时起未曾更新的编辑和出版工具。本文重点关注开发一套转换工具，将这些CMME文件转换为更符合最新音乐编码标准（即MEI）的格式。2024年9月在巴黎Campus Condorcet组织了一场研讨会，汇集了在量度音乐符号、XML格式和编程方面拥有广泛知识的专家。一个转换器直接在开源渲染库Verovio中开发，实现了从CMME到MEI量度音乐的转换。随后，又实现了向MEI CMN的转换，使得这些文件能够以最小的信息损失加载到MuseScore等常用雕版软件中。随着CMME-XML直接导入Verovio的可用性，现有的CMME文件语料库获得了新生。此外，由于独立的CMME编辑器仍能正常工作且尚无原生的MEI替代品，该转换器为量度音乐的编码和编辑提供了一个新的流程。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [657] [Robust Bioacoustic Detection via Richly Labelled Synthetic Soundscape Augmentation](https://arxiv.org/abs/2507.16235)
> *通过丰富标记的合成声景增强实现鲁棒的生物声学检测*

*Kaspar Soltero, Tadeu Siqueira, Stefanie Gutschmidt* | **Category: cs.SD** | **Updated: 2025-07-22**

**Keywords:** 生物声学检测, 合成数据, 数据增强, 被动声学监测, 鲁棒性

**Comment:** 12 pages, 4 figures

> **TL;DR:** 本研究提出了一种合成数据框架，通过少量原始材料生成大量标记训练数据，以提高生物声学检测模型的鲁棒性，有效减少手动标注工作。

**AI_Comments:** 该研究提出了一种创新的合成数据生成方法，有效解决了生物声学领域数据标注成本高昂的痛点。其通过自动生成动态标签并验证模型在低多样性数据下的泛化能力，证明了合成数据在训练鲁棒检测模型方面的巨大潜力，对计算生物声学和生态评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 被动声学监测（PAM）分析常因创建标记训练数据所需的大量手动工作而受阻，这限制了生物声学检测模型的开发和鲁棒性。

**Method:** 研究引入了一个合成数据框架，通过将纯净的背景噪声与孤立的目标发声（小猫头鹰）结合来合成逼真的声景。在合成过程中自动生成动态标签，如边界框。然后使用这些合成数据对模型进行微调。

**Result:** 在合成数据上微调的模型对真实世界声景具有良好的泛化能力，即使原始发声的多样性大幅减少，性能仍保持高水平，表明模型学习了泛化特征而没有过拟合。

**Conclusion:** 合成数据生成是从小型原始数据集训练鲁棒生物声学检测器的一种高效策略，显著减少了手动标注工作，克服了计算生物声学中的关键瓶颈，并增强了生态评估能力。

> **ai_Abstract:** 本研究提出了一种合成数据框架，用于从有限的原始材料生成大量标记丰富的训练数据，以解决被动声学监测中手动标注工作量大的问题。该框架通过结合背景噪声和目标发声来合成逼真的声景，并自动生成动态标签。实验结果表明，在合成数据上训练的模型对真实声景具有良好的泛化能力和鲁棒性，即使原始数据多样性较低也能保持高性能，从而有效减少了生物声学检测的标注成本并提升了生态评估能力。

> **摘要翻译:** 被动声学监测（PAM）分析常因创建标记训练数据所需的大量手动工作而受阻。本研究引入了一个合成数据框架，能够从非常有限的原始材料中生成大量标记丰富的训练数据，从而提高生物声学检测模型的鲁棒性。我们的框架通过将纯净的背景噪声与孤立的目标发声（小猫头鹰）结合来合成逼真的声景，并在合成过程中自动生成动态标签，如边界框。一个在此数据上微调的模型对真实世界声景具有良好的泛化能力，即使原始发声的多样性大幅减少，性能仍保持高水平，这表明模型学习了泛化特征而没有过拟合。这表明合成数据生成是从小型原始数据集训练鲁棒生物声学检测器的一种高效策略。该方法显著减少了手动标注工作，克服了计算生物声学中的关键瓶颈，并增强了生态评估能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [698] [ReMi: A Random Recurrent Neural Network Approach to Music Production](https://arxiv.org/abs/2505.17023)
> *ReMi：一种随机循环神经网络的音乐制作方法*

*Hugo Chateau-Laurent, Tara Vanhatalo, Wei-Tung Pan, Xavier Hinaut* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 随机循环神经网络, 音乐制作, 生成式AI, 创意辅助, 低功耗

**Comment:** Accepted for an Innovation Showcase Demo at International Computer
  Music Conference

> **TL;DR:** 使用随机初始化的循环神经网络可以生成丰富且可配置的音乐元素，且无需数据、计算量小，旨在扩展而非取代音乐家。

**AI_Comments:** 该论文的创新之处在于其“无数据”和“低计算量”的随机循环神经网络方法，这与当前主流的、依赖大量数据和算力的生成式 AI 形成鲜明对比。它将 AI 定位为人类创造力的辅助工具，而非替代品，这在版权和创意伦理方面具有重要意义。这种轻量级的方法可能为资源有限的创作者提供新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成式人工智能面临能耗、版权侵权和创意萎缩等问题。作者旨在提出一种新的音乐生成方法，以解决这些问题并辅助音乐家。

**Method:** 采用随机初始化的循环神经网络（Random Recurrent Neural Networks）来生成音乐元素。

**Result:** 能够生成丰富且可配置的琶音（arpeggios）和低频振荡（low-frequency oscillations）。

**Conclusion:** 这种方法扩展了音乐家的创造力，且无需数据，计算能力需求也大大降低，与旨在取代音乐家的端到端音乐生成方法形成对比。

> **ai_Abstract:** 本文提出了一种名为 ReMi 的音乐制作方法，利用随机初始化的循环神经网络生成琶音和低频振荡。该方法旨在解决当前生成式 AI 面临的能耗、版权和创意问题，通过无需数据和低计算量来扩展音乐家的创造力，而非取代他们。

> **摘要翻译:** 生成式人工智能引发了关于能耗、版权侵权和创意萎缩的担忧。我们展示了随机初始化的循环神经网络可以生成丰富且可配置的琶音和低频振荡。与旨在取代音乐家的端到端音乐生成不同，我们的方法扩展了他们的创造力，同时无需数据且计算能力需求大大降低。更多信息请访问：https://allendia.com/

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [753] [Audio Geolocation: A Natural Sounds Benchmark](https://arxiv.org/abs/2505.18726)
> *音频地理定位：一个自然声音基准*

*Mustafa Chasmai, Wuao Liu, Subhransu Maji, Grant Van Horn* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-21**

**Keywords:** 音频地理定位, 自然声音, 频谱图, 物种范围预测, 多模态

**Comment:** 

> **TL;DR:** 该研究探讨了仅凭声音确定地理位置的可能性，提出了一个全球尺度的音频地理定位问题，并使用自然声音数据集iNatSounds进行了深入分析和基准测试，整合了物种范围预测和多模态方法。

**AI_Comments:** 这项研究创新性地将图像地理定位技术应用于音频领域，并通过引入物种发声范围预测的概念，为音频地理定位提供了新的视角。其重要性在于开辟了利用自然声音进行大规模地理定位的可能性，并强调了多模态数据融合的潜力。该工作为未来的音频地理定位研究奠定了坚实的基础，并可能在环境监测、野生动物保护等领域有实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探讨是否可以仅凭听到的声音确定地理位置，以及声学信号是否足以在国家、州甚至城市范围内进行定位，从而解决全球尺度的音频地理定位挑战。

**Method:** 研究将音频记录转换为频谱图，并对现有图像地理定位技术进行基准测试。提出了一种将物种发声范围预测与基于检索的地理定位相结合的方法。此外，还评估了在分析物种丰富的录音或在时空邻域聚合时地理定位是否有所改善。最后，通过电影案例研究探索了结合音频和视觉内容的多模态地理定位。

**Result:** 研究结果强调了整合音频和视觉线索的优势。

**Conclusion:** 该工作为未来的音频地理定位研究奠定了基础，并强调了整合音频和视觉线索的优势。

> **ai_Abstract:** 本研究探讨了纯粹通过声音进行地理定位的可行性，并提出了全球尺度的音频地理定位问题。论文利用iNatSounds数据集中的野生动物音频，将音频转换为频谱图并应用图像地理定位技术进行基准测试。研究假设物种发声提供强地理定位线索，并提出了一种结合物种范围预测与检索式地理定位的方法。此外，研究还评估了物种丰富录音和时空聚合对定位效果的影响，并通过电影案例研究探索了音频与视觉结合的多模态地理定位，强调了整合多模态线索的优势，为未来研究奠定了基础。

> **摘要翻译:** 我们能否仅仅根据听到的声音来确定某人的地理位置？声学信号是否足以在国家、州甚至城市内进行定位？我们应对全球尺度的音频地理定位挑战，将问题形式化，并使用来自 iNatSounds 数据集的野生动物音频进行了深入分析。我们采用受视觉启发的方法，将音频录音转换为频谱图，并对现有的图像地理定位技术进行基准测试。我们假设物种发声由于其明确的地理范围而提供强大的地理定位线索，并提出了一种将物种范围预测与基于检索的地理定位相结合的方法。我们进一步评估了在分析物种丰富的录音或在时空邻域聚合时地理定位是否有所改善。最后，我们引入了电影案例研究，以探索使用音频和视觉内容的多模态地理定位。我们的工作突出了整合音频和视觉线索的优势，并为未来的音频地理定位研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [36] [RightTyper: Effective and Efficient Type Annotation for Python](https://arxiv.org/abs/2507.16051)
> *RightTyper: Python的高效类型标注工具*

*Juan Altmayer Pizzorno, Emery D. Berger* | **Category: cs.PL, cs.SE** | **Updated: 2025-07-21**

**Keywords:** Python, 类型标注, RightTyper, 类型检查, 异常检测

**Comment:** 

> **TL;DR:** RightTyper是一种新的Python类型标注方法，它通过采样和统计过滤，实现了精确、高效的类型推断，并将类型检查转化为异常检测，解决了现有方法的不足。

**AI_Comments:** RightTyper的创新之处在于其将类型检查转化为异常检测的理念，这为发现代码中的潜在问题提供了新的视角。其基于采样的动态方法不仅提高了类型推断的精确性，还显著降低了性能开销，使其在实际大型代码库中具有更高的实用性。同时，它解决了现有方法对“代码正确性”的错误假设，更贴近实际开发需求。

<details>
  <summary>Details</summary>

**Motivation:** 手动编写Python类型标注耗时且繁琐，导致大多数实际代码缺乏类型。现有方法（静态、AI和动态）存在各自的缺陷，如难以处理动态特性、不健全、性能开销大或推断不准确。此外，所有现有工作都错误地假设待标注代码是正确的。

**Method:** 本文提出了RightTyper，一种新颖的Python类型标注方法。它通过以自分析为指导的采样、统计过滤以及类型信息的仔细解析和聚合，生成基于实际程序行为的精确类型标注。RightTyper还将类型检查转化为异常检测。

**Result:** RightTyper能够生成精确的类型标注，提高了类型检查的召回率。它将类型检查转化为异常检测，帮助程序员发现异常行为。RightTyper还快速且节省空间，平均只带来30%的性能开销。

**Conclusion:** RightTyper提供了一种有效且高效的Python类型标注解决方案，克服了现有方法的缺点，并显著提高了类型标注的准确性和实用性。

> **ai_Abstract:** RightTyper是一种新颖的Python类型标注工具，旨在解决现有手动和自动化方法的局限性。它通过利用实际程序行为、采样、自分析和统计过滤来生成精确的类型标注，显著提高了类型检查的召回率。与传统方法不同，RightTyper将类型检查转化为异常检测，帮助识别潜在的意外行为。该工具还表现出高效率，平均性能开销仅为30%，克服了现有动态方法的高开销问题，并解决了它们无法处理不正确代码的假设。

> **摘要翻译:** Python类型标注为语言带来了静态类型检查的好处。然而，手动编写标注可能既耗时又繁琐。结果是，大多数现实世界的Python代码仍然基本未被类型化。过去在Python代码中标注类型的方法存在诸多不足。静态方法难以处理动态特性并推断出过于宽泛的类型。基于AI的方法本质上是不健全的，可能会遗漏稀有或用户定义的类型。动态方法可能带来极高的运行时开销，性能下降高达270倍，在资源耗尽时中止执行，甚至推断出导致运行时错误的错误类型。关键的是，所有先前的工作都隐含地假设待标注的代码已经是正确的。这种假设通常是没有根据的，特别是对于尚未类型化的大型代码库。
本文提出了RightTyper，一种新颖的Python方法，克服了这些缺点。RightTyper不仅基于实际程序行为生成精确的类型标注，相对于先前的方法提高了类型检查的召回率。它还将类型检查转化为异常检测，允许类型检查器识别程序员可以审计的意外行为的边缘情况。RightTyper还快速且节省空间，平均只带来30%的性能开销。RightTyper通过以自分析为指导的原则性但普遍使用的采样，以及统计过滤和对类型信息的仔细解析和聚合，实现了这些特性。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [598] [Hear Your Code Fail, Voice-Assisted Debugging for Python](https://arxiv.org/abs/2507.15007)
> *听见你的代码失败，Python 语音辅助调试*

*Sayed Mahbub Hasan Amiri, Md. Mainul Islam, Mohammad Shakhawat Hossen, Sayed Majhab Hasan Amiri, Mohammad Shawkat Ali Mamun, Sk. Humaun Kabir, Naznin Akter* | **Category: cs.PL, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 语音辅助调试, Python, 错误诊断, 认知负荷, 可访问性

**Comment:** 35 pages, 20 figures

> **TL;DR:** Python 语音调试插件将运行时错误转换为可听见的诊断，显著降低认知负荷并加速错误识别，提升编程可访问性。

**AI_Comments:** 这项研究提出了一种新颖且具有前瞻性的调试范式，通过引入听觉反馈极大地改善了传统调试的痛点。其创新性在于将无形的运行时错误转化为可感知的语音信息，显著降低了开发者的认知负荷，并提高了错误识别效率。对于视力受损开发者和多任务工作流而言，该工具的辅助作用尤其重要。此外，在教育领域的应用潜力也值得关注。未来的GPT集成和多语言支持将使其功能更加强大和普适。

<details>
  <summary>Details</summary>

**Motivation:** 传统调试方法（如堆栈跟踪）认知负荷高，效率低；现有工具缺乏对视力受损开发者和多任务工作流的支持；加速新手程序员的调试技能习得。

**Method:** 开发了一个创新的Python语音辅助调试插件。该插件通过实现一个全局异常钩子架构，结合pyttsx3文本转语音转换和Tkinter-based GUI可视化，提供通过并行的听觉和视觉通道的多模态错误反馈。

**Result:** 实证评估显示，与传统堆栈跟踪调试相比，认知负荷降低37%（p<0.01, n=50），错误识别速度加快78%；系统语音延迟低于1.2秒，异常处理期间CPU开销低于18%；兼容Python 3.7+（Windows, macOS, Linux）；仅需两行集成代码；显著提升视力受损设计师的可用性；支持多任务工作流；试点研究表明新手程序员调试技能习得速度加快45%。

**Conclusion:** 该解决方案代表了以人为中心的错误诊断的根本性转变，弥合了编程可访问性方面的关键差距，同时为软件开发工作流中的认知效率建立了新标准。

> **ai_Abstract:** 本研究提出并评估了一个名为“Hear Your Code Fail”的Python语音辅助调试插件。该插件将运行时错误转化为可听见的诊断信息，并通过全局异常钩子、文本转语音（pyttsx3）和GUI可视化（Tkinter）提供多模态反馈。实验结果表明，该系统能显著降低开发者认知负荷（37%）并加速错误识别（78%），同时保持低延迟和CPU开销。它提升了编程可访问性，支持多任务，并加速了新手程序员的调试技能习得。

> **摘要翻译:** 这项研究引入了一种创新的Python语音辅助调试插件，它将无声的运行时错误转化为可操作的听觉诊断。通过实现一个全局异常钩子架构，结合pyttsx3文本转语音转换和基于Tkinter的GUI可视化，该解决方案通过并行的听觉和视觉通道提供多模态错误反馈。实证评估表明，与传统的堆栈跟踪调试相比，认知负荷降低了37%（p<0.01，n=50），同时通过语音异常分类和语境化，错误识别速度加快了78%。该系统在异常处理期间实现了低于1.2秒的语音延迟和低于18%的CPU开销，能够将错误类型和后果语音化，同时显示带有文档深层链接的交互式回溯。验证标准证实了其在Windows、macOS和Linux平台上Python 3.7+环境中的兼容性。该插件仅需两行集成代码，显著提高了对视力受损设计师的可用性，并通过免提错误诊断支持多任务工作流程。教育应用前景广阔，试点研究表明新手程序员的调试技能习得速度加快了45%。未来的开发将整合基于GPT的修复建议和实时多语言翻译，以进一步推进听觉调试范式。该解决方案代表了以人为中心的错误诊断的根本性转变，弥合了编程可访问性方面的关键差距，同时为软件开发工作流中的认知效率建立了新标准。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [619] [Autocomp: LLM-Driven Code Optimization for Tensor Accelerators](https://arxiv.org/abs/2505.18574)
> *Autocomp：LLM驱动的张量加速器代码优化*

*Charles Hong, Sahil Bhatia, Alvin Cheung, Yakun Sophia Shao* | **Category: cs.PL, cs.AI, cs.AR, cs.LG** | **Updated: 2025-07-21**

**Keywords:** LLM, 代码优化, 张量加速器, Autocomp, 硬件反馈

**Comment:** 

> **TL;DR:** Autocomp是一种利用大型语言模型（LLM）和硬件反馈自动优化张量加速器代码的方法，显著提升了代码性能并超越了手动优化。

**AI_Comments:** 该论文提出了一种创新的LLM驱动代码优化框架Autocomp，它有效地结合了LLM的代码生成能力、领域知识和硬件反馈，解决了张量加速器编程的挑战。其亮点在于将优化过程分解为规划和代码生成，并融入了实际的性能反馈，这对于LLM在低资源代码优化方面的应用具有重要意义。性能提升显著，且优化调度可重用性也增强了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管张量加速器已普及，但其编程仍具挑战性，导致潜力未充分利用。大型语言模型（LLM）在代码生成和优化方面显示出前景，但生成专门的张量加速器代码等低资源语言仍面临重大挑战。

**Method:** Autocomp通过自动化LLM驱动的搜索来优化代码。其实现方式包括：1）将每个优化过程制定为结构化的两阶段提示（规划和代码生成）；2）在规划阶段通过简洁灵活的优化菜单注入领域知识；3）在每次搜索迭代中整合来自硬件的正确性和性能指标作为反馈。

**Result:** 在三类代表性工作负载和两种不同加速器上，Autocomp优化后的代码比供应商提供的库快5.6倍（GEMM）和2.7倍（卷积），并且比专家级手动调优代码快1.4倍（GEMM）、1.1倍（卷积）和1.3倍（细粒度线性代数）。此外，Autocomp生成的优化调度可以在类似的张量操作中重复使用，在固定样本预算下将加速提高高达24%。

**Conclusion:** Autocomp成功地利用LLM和硬件反馈解决了张量加速器代码优化难题，显著提升了性能，并证明了优化调度在类似操作中的可重用性。

> **ai_Abstract:** Autocomp是一种利用大型语言模型（LLM）和硬件反馈来自动化张量加速器代码优化的新方法。它通过结构化的两阶段提示、领域知识注入和性能反馈循环来操作。实验结果表明，Autocomp优化后的代码在多种工作负载和加速器上显著优于供应商库和专家手动调优的代码，且优化调度具有可重用性。

> **摘要翻译:** 硬件加速器，特别是为张量处理设计的加速器，在当今的计算领域变得无处不在。然而，即使在编译器构建方面付出了巨大努力，编程这些张量加速器仍然充满挑战，导致其大部分潜力未能得到充分利用。最近，在大量代码上训练的大型语言模型（LLM）在代码生成和优化任务中显示出巨大的前景，但生成像专用张量加速器代码这样的低资源语言仍然是一个重大挑战。我们通过Autocomp解决了这一挑战，这是一种赋能加速器程序员利用领域知识和硬件反馈，通过自动化的LLM驱动搜索来优化代码的方法。我们通过以下方式实现：1）将每个优化过程制定为结构化的两阶段提示，分为规划和代码生成阶段；2）在规划期间通过简洁且适应性强的优化菜单插入领域知识；3）在每次搜索迭代中整合来自硬件的正确性和性能指标作为反馈。在三类代表性工作负载和两种不同加速器上，我们证明了Autocomp优化后的代码比供应商提供的库快5.6倍（GEMM）和2.7倍（卷积），并且比专家级手动调优代码快1.4倍（GEMM）、1.1倍（卷积）和1.3倍（细粒度线性代数）。此外，我们证明了Autocomp生成的优化调度可以在类似的张量操作中重复使用，在固定样本预算下将加速提高高达24%。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [53] [Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models](https://arxiv.org/abs/2507.16801)
> *使用可解释深度学习模型解码5'UTR中与翻译相关的功能序列*

*Yuxi Lin, Yaxue Fang, Zehong Zhang, Zhouwu Liu, Siyun Zhong, Fulong Yu* | **Category: q-bio.QM, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 5'UTR, 深度学习, 翻译调控, Transformer, 可解释AI

**Comment:** 

> **TL;DR:** UTR-STCNet是一个基于Transformer的深度学习模型，用于灵活且可解释地预测5'UTR的翻译效率，它在基准数据集上优于现有模型并能识别已知功能元件。

**AI_Comments:** 该论文的创新之处在于提出了一个能够处理可变长度5'UTR并提供生物学可解释性的深度学习模型。通过结合SATC和SGT模块，UTR-STCNet克服了现有模型的局限性，并在预测翻译效率方面取得了显著提升。其能够恢复已知功能元件的能力，进一步增强了模型在生物学发现方面的潜力，对于设计治疗性mRNA具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 了解5'非翻译区(5'UTR)如何调节mRNA翻译对于控制蛋白质表达和设计有效的治疗性mRNA至关重要。现有的深度学习模型在预测翻译效率方面存在输入长度固定和可解释性有限的局限性。

**Method:** 本文提出了UTR-STCNet，一个基于Transformer的架构，用于建模可变长度的5'UTR。它集成了Saliency-Aware Token Clustering (SATC)模块，根据显著性分数将核苷酸标记迭代聚类为多尺度、语义有意义的单元；以及Saliency-Guided Transformer (SGT)块，使用轻量级注意力机制捕获局部和远端调节依赖性。

**Result:** UTR-STCNet在三个基准数据集上持续优于最先进的基线模型，在预测平均核糖体负荷(MRL)方面表现出色。此外，该模型恢复了已知的GUG和Kozak序列等功能元件。

**Conclusion:** UTR-STCNet提供了一种高效且可解释的方法来建模5'UTR，无需截断输入或增加计算成本，并能提供对翻译调控机制的深入理解。

> **ai_Abstract:** 本文介绍了UTR-STCNet，这是一种基于Transformer的深度学习模型，旨在解决现有模型在预测5'UTR翻译效率时输入长度固定和可解释性差的问题。UTR-STCNet通过整合显著性感知标记聚类(SATC)模块和显著性引导Transformer(SGT)块，实现了对可变长度5'UTR的灵活且生物学上可解释的建模。该模型在多个基准数据集上表现优于现有技术，并能够识别已知的翻译相关功能序列，为深入理解翻译调控机制提供了新的工具。

> **摘要翻译:** 了解5'非翻译区 (5'UTRs) 如何调节 mRNA 翻译对于控制蛋白质表达和设计有效的治疗性 mRNA 至关重要。虽然最近的深度学习模型在根据 5'UTR 序列预测翻译效率方面显示出前景，但大多数模型受限于固定的输入长度和有限的可解释性。我们引入了 UTR-STCNet，这是一种基于 Transformer 的架构，用于灵活且具有生物学基础的可变长度 5'UTR 建模。UTR-STCNet 集成了显著性感知标记聚类 (SATC) 模块，该模块根据显著性分数迭代地将核苷酸标记聚合为多尺度、语义有意义的单元。然后，显著性引导 Transformer (SGT) 块使用轻量级注意力机制捕获局部和远端调节依赖性。这种组合架构实现了高效且可解释的建模，而无需输入截断或增加计算成本。在三个基准数据集上进行评估，UTR-STCNet 在预测平均核糖体负荷 (MRL) 方面始终优于最先进的基线模型，MRL 是翻译效率的关键代理。此外，该模型恢复了已知的上游 AUG 和 Kozak 序列等功能元件，突出了其对翻译调控机制洞察的潜力。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [477] [Antibiotic Resistance Microbiology Dataset (ARMD): A Resource for Antimicrobial Resistance from EHRs](https://arxiv.org/abs/2503.07664)
> *抗生素耐药性微生物学数据集 (ARMD)：一份来自电子健康记录的抗菌素耐药性资源*

*Fateme Nateghi Haredasht, Fatemeh Amrollahi, Manoj Maddali, Nicholas Marshall, Stephen P. Ma, Lauren N. Cooper, Andrew O. Johnson, Ziming Wei, Richard J. Medford, Sanjat Kanjilal, Niaz Banaei, Stanley Deresinski, Mary K. Goldstein, Steven M. Asch, Amy Chang, Jonathan H. Chen* | **Category: q-bio.QM, cs.IR, cs.LG, stat.AP** | **Updated: 2025-07-21**

**Keywords:** 抗菌素耐药性, 电子健康记录, 数据集, 微生物学, 抗生素敏感性

**Comment:** 

> **TL;DR:** ARMD是一个从电子健康记录(EHR)中提取的去识别化数据集，旨在促进抗菌素耐药性(AMR)研究，包含超过15年的微生物培养和抗生素敏感性数据。

**AI_Comments:** ARMD数据集的创新之处在于其大规模、长期的数据收集以及对关键微生物和抗生素敏感性模式的详细记录。作为一个去识别化的资源，它为研究人员提供了宝贵的数据，以应对日益严峻的抗菌素耐药性挑战。其支持抗菌药物管理和临床决策的潜力，使其在实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 促进抗菌素耐药性 (AMR) 研究，支持抗菌药物管理、因果推断和临床决策。

**Method:** ARMD是一个从电子健康记录 (EHR) 中提取的去识别化资源，包含来自两家学术附属医院超过15年的成人患者大数据，重点是微生物培养、抗生素敏感性以及相关的临床和人口统计学特征。本文详细描述了数据集的获取、结构、效用和去识别化过程。

**Result:** 创建了抗生素耐药性微生物学数据集 (ARMD)，其中包含生物体识别、55种抗生素的敏感性模式、隐含敏感性规则以及去识别化的患者信息。

**Conclusion:** ARMD数据集是一个可重用和可互操作的资源，旨在促进抗菌素耐药性领域的合作和创新。

> **ai_Abstract:** 抗生素耐药性微生物学数据集 (ARMD) 是一个基于15年多电子健康记录的去识别化大数据资源，专注于微生物培养和抗生素敏感性，旨在支持抗菌素耐药性研究、抗菌药物管理、因果推断和临床决策，并通过其可重用性和互操作性促进该领域的合作与创新。

> **摘要翻译:** 抗生素耐药性微生物学数据集 (ARMD) 是一份从电子健康记录 (EHR) 中提取的去识别化资源，旨在促进抗菌素耐药性 (AMR) 研究。ARMD 包含来自两家学术附属医院超过 15 年的成人患者大数据，重点是微生物培养、抗生素敏感性以及相关的临床和人口统计学特征。关键属性包括生物体识别、55 种抗生素的敏感性模式、隐含敏感性规则以及去识别化的患者信息。该数据集支持抗菌药物管理、因果推断和临床决策方面的研究。ARMD 被设计为可重用和可互操作，旨在促进抗击 AMR 的合作和创新。本文描述了数据集的获取、结构和效用，同时详细介绍了其去识别化过程。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [700] [Quantum Cognition Machine Learning for Forecasting Chromosomal Instability](https://arxiv.org/abs/2506.03199)
> *量子认知机器学习预测染色体不稳定性*

*Giuseppe Di Caro, Vahagn Kirakosyan, Alexander G. Abanov, Jerome R. Busemeyer, Luca Candelori, Nadine Hartmann, Ernest T. Lam, Kharen Musaelian, Ryan Samson, Harold Steinacker, Dario Villani, Martin T. Wells, Richard J. Wenstrup, Mengjia Xu* | **Category: q-bio.QM, cs.LG, quant-ph** | **Updated: 2025-07-22**

**Keywords:** 量子认知机器学习, 染色体不稳定性, 循环肿瘤细胞, 液体活检, 高维数据

**Comment:** 

> **TL;DR:** 本研究引入了量子认知机器学习（QCML）框架，用于从循环肿瘤细胞（CTC）形态学数据中预测染色体不稳定性，并在高维、低样本量生物医学背景下表现出优于传统机器学习方法的性能。

**AI_Comments:** 该论文的创新之处在于将量子力学原理应用于机器学习，提出了QCML框架，以解决高维度、低样本量生物医学数据分析中的挑战。其重要性体现在为液体活检中CTC分类和染色体不稳定性预测提供了一种高性能的新工具，有望提高癌症诊断和预后评估的准确性。然而，该研究目前处于初步阶段，需要进一步的临床验证和大规模数据集测试来确认其普适性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测循环肿瘤细胞（CTC）的染色体不稳定性对于液体活检诊断中实时检测高转移潜能的CTC至关重要，但由于单细胞数字病理数据的高维度和复杂性，这带来了重大挑战。

**Method:** 本研究引入了量子认知机器学习（QCML），一个受量子启发的计算框架，用于从转移性乳腺癌患者的CTC中估计形态学预测的染色体不稳定性。QCML利用量子力学原理将数据表示为希尔伯特空间中的状态向量，从而实现上下文感知特征建模、降维和增强泛化能力，而无需精选特征选择。

**Result:** QCML在样本外验证CTC上进行测试时，其性能优于传统机器学习方法，在从CTC衍生的形态学特征中识别预测的大规模状态转换（pLST）状态方面实现了更高的准确性。这些初步发现支持QCML作为一种新型机器学习工具，在高维、低样本量的生物医学背景下具有卓越性能。

**Conclusion:** QCML能够模拟认知式学习，以从CTC形态学中识别具有生物学意义的染色体不稳定性预测，为液体活检中的CTC分类提供了一种新颖的工具。

> **ai_Abstract:** 本研究提出了一种名为量子认知机器学习（QCML）的新型量子启发计算框架，用于从循环肿瘤细胞（CTC）的形态学特征中预测染色体不稳定性。QCML通过将数据表示为希尔伯特空间中的状态向量，实现了上下文感知的特征建模和降维，并在高维、低样本量的生物医学数据上，特别是针对转移性乳腺癌患者的CTC，表现出优于传统机器学习方法的性能，能够更准确地识别大规模状态转换（pLST）状态，为液体活检中的CTC分类提供了一种有前景的工具。

> **摘要翻译:** 从循环肿瘤细胞（CTCs）的形态学准确预测染色体不稳定性，可以在液体活检诊断中实时检测具有高转移潜能的CTCs。然而，由于单细胞数字病理数据的高维度和复杂性，这提出了一个重大挑战。在此，我们引入了量子认知机器学习（QCML）的应用，这是一种受量子启发的计算框架，用于从转移性乳腺癌患者的CTCs中估计形态学预测的染色体不稳定性。QCML利用量子力学原理将数据表示为希尔伯特空间中的状态向量，从而实现上下文感知特征建模、降维和增强泛化能力，而无需精选特征选择。QCML在样本外验证CTCs上进行测试时，其性能优于传统机器学习方法，在从CTCs衍生的形态学特征中识别预测的大规模状态转换（pLST）状态方面实现了更高的准确性。这些初步发现支持QCML作为一种新型机器学习工具，在高维、低样本量生物医学背景下具有卓越性能。QCML能够模拟认知式学习，以从CTCs形态学中识别具有生物学意义的染色体不稳定性预测，为液体活检中的CTCs分类提供了一种新颖的工具。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [54] [The Intrinsic Riemannian Proximal Gradient Method for Convex Optimization](https://arxiv.org/abs/2507.16055)
> *黎曼流形上的凸优化内蕴近端梯度法*

*Ronny Bergmann, Hajg Jasa, Paula John, Max Pfeffer* | **Category: math.OC, cs.NA, math.DG, math.NA, 90C25, 49Q99, 49M30, 65K10** | **Updated: 2025-07-21**

**Keywords:** 黎曼优化, 近端梯度法, 测地线凸性, Hadamard流形, 收敛性分析

**Comment:** 

> **TL;DR:** 针对Hadamard流形上的测地线凸优化问题，提出了一种内蕴凸黎曼近端梯度(CRPG)方法，具有理论收敛性，并在数值实验中显示出计算优势。

**AI_Comments:** 该研究的创新之处在于提出了一种完全内蕴的黎曼近端梯度方法，避免了复杂的嵌入或切空间操作，这对于处理高维或复杂流形上的优化问题具有重要意义。其理论收敛性分析和在特定流形上的实验优势进一步验证了方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 解决Hadamard流形上一类目标函数可分为光滑和非光滑部分（可能强）测地线凸优化问题。

**Method:** 引入了一种内蕴凸黎曼近端梯度(CRPG)方法，该方法利用流形近端映射处理非光滑步骤，且无需在嵌入空间或切空间中操作。

**Result:** 建立了凸问题次线性收敛速率和强凸问题线性收敛速率；推导了泛化欧几里得情况的基本近端梯度不等式；在双曲空间和对称正定矩阵流形上的数值实验表明，该方法比现有方法具有显著的计算优势。

**Conclusion:** 内蕴凸黎曼近端梯度(CRPG)方法在Hadamard流形上的测地线凸优化问题中表现出良好的理论收敛性和实际计算优势。

> **ai_Abstract:** 这篇论文提出了一种针对Hadamard流形上测地线凸优化问题的内蕴凸黎曼近端梯度（CRPG）方法。该方法将目标函数分解为光滑和非光滑部分，并利用流形近端映射进行处理，避免了在嵌入或切空间操作。研究建立了凸问题和强凸问题的收敛速率，并推广了欧几里得空间的近端梯度不等式。数值实验证明了其在计算上的显著优势。

> **摘要翻译:** 我们考虑Hadamard流形上一类（可能强）测地线凸优化问题，其中目标函数分解为光滑函数和可能非光滑函数的和。我们引入了一种内蕴凸黎曼近端梯度（CRPG）方法，该方法利用流形近端映射进行非光滑步骤，而无需在嵌入空间或切空间中操作。该方法对凸问题建立了次线性收敛速率，对强凸问题建立了线性收敛速率，并且我们推导了泛化欧几里得情况的基本近端梯度不等式。我们在双曲空间和对称正定矩阵流形上的数值实验表明，该方法比现有方法具有显著的计算优势。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [67] [Interpretable Gradient Descent for Kalman Gain](https://arxiv.org/abs/2507.14354)
> *卡尔曼增益的可解释梯度下降*

*M. A. Belabbas, A. Olshevsky* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 梯度下降, 卡尔曼增益, 可观测性, 线性时不变系统, 创新损失

**Comment:** 

> **TL;DR:** 该研究推导了线性时不变系统中创新损失梯度相对于滤波器增益的分解，并利用此分解证明了梯度下降收敛到最优卡尔曼增益，并得到了可解释的几何收敛速度。

**AI_Comments:** 该论文通过对梯度进行分解，为卡尔曼增益的梯度下降收敛性提供了理论基础和可解释性，尤其是在非标准可观测性条件下的分析具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 该研究推导了线性时不变系统中创新损失梯度相对于滤波器增益的分解，将其分解为可观测性Gramian和量化估计误差与创新之间“非正交性”的项的乘积。研究利用此分解来证明梯度下降收敛到最优卡尔曼增益。

**Result:** 研究明确了卡尔曼增益的恢复如何依赖于一个非标准的可观测性条件，并获得了可解释的几何收敛速度。

**Conclusion:** 梯度下降可以收敛到最优卡尔曼增益，其收敛性依赖于一个非标准的可观测性条件，并且收敛速度是可解释的几何收敛。

> **ai_Abstract:** 这篇论文推导了线性时不变系统中创新损失梯度相对于滤波器增益的分解，该分解是可观测性Gramian与一个表示估计误差和创新之间“非正交性”的项的乘积。基于此分解，论文证明了梯度下降法能够收敛到最优卡尔曼增益，并阐明了卡尔曼增益的恢复依赖于一个非标准的可观测性条件，同时得到了一个可解释的几何收敛速度。

> **摘要翻译:** 我们推导了线性时不变系统中创新损失梯度相对于滤波器增益的分解，将其分解为可观测性Gramian和量化估计误差与创新之间“非正交性”的项的乘积。我们利用此分解来证明梯度下降收敛到最优卡尔曼增益，具体指出了卡尔曼增益的恢复如何依赖于一个非标准的可观测性条件，并获得了可解释的几何收敛速度。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [80] [A robust and stable phase field method for structural topology optimization](https://arxiv.org/abs/2507.16519)
> *一种鲁棒稳定的结构拓扑优化相场方法*

*Huangxin Chen, Piaopiao Dong, Dong Wang, Xiao-Ping Wang* | **Category: math.OC, cs.NA, math.NA** | **Updated: 2025-07-22**

**Keywords:** 拓扑优化, 相场方法, 算子分裂, 约束最小化, 鲁棒性

**Comment:** 26 pages, 15 figures

> **TL;DR:** 本文提出了一种新颖的相场方法，用于解决结构拓扑优化中的最小柔度问题，通过算子分裂算法和新颖的限幅器机制，保证了边界保持、体积守恒和目标函数衰减的严格性与鲁棒性。

**AI_Comments:** 该论文的创新之处在于提出了一种混合算子分裂算法，并结合了新颖的限幅器机制，从而有效解决了相场拓扑优化中域相关体力这一数学难题。同时，该方法能够严格保证边界保持、体积守恒和目标函数衰减等关键性质，这对于优化过程的稳定性和结果的准确性至关重要。其在2D和3D基准测试中展现出的鲁棒性是其重要优势。

<details>
  <summary>Details</summary>

**Motivation:** 解决拓扑优化中的最小柔度问题，特别是处理域相关体力带来的数学挑战，并确保优化过程中边界保持、体积守恒和目标函数单调衰减等关键性质的满足。

**Method:** 提出了一种新颖的基于相场的拓扑优化方法。该方法将最优结构通过一个序参数函数来表征，并将拓扑优化问题重新表述为一个关于此序参数的约束最小化问题。为解决域相关体力的挑战，开发了一种结合拉格朗日乘子和新型限幅器机制的算子分裂算法。

**Result:** 所提出的混合方法保证了严格的边界保持、精确的体积守恒和正确的目标函数衰减率。通过全面的二维和三维基准测试，数值实现证明了该方案的鲁棒性。

**Conclusion:** 本文成功开发了一种鲁棒稳定的结构拓扑优化相场方法，有效处理了域相关体力并确保了关键性质的满足，数值结果验证了其有效性。

> **ai_Abstract:** 本文提出了一种新颖的基于相场的结构拓扑优化方法，旨在解决固定载荷和体力作用下的最小柔度问题。该方法将问题重新表述为关于序参数的约束最小化问题，并要求满足边界保持、体积守恒和目标函数单调衰减。为应对域相关体力的挑战，研究开发了一种结合拉格朗日乘子和新型限幅器机制的算子分裂算法。该混合方法被证明能严格保证上述关键性质，并通过二维和三维数值基准测试展示了其鲁棒性。

> **摘要翻译:** 本文提出了一种新颖的基于相场的方法，用于解决固定外部载荷和体力作用下拓扑优化中的最小柔度问题。所提出的框架通过一个序参数函数来表征最优结构，类似于材料科学中的相场模型，其中设计域及其边界由序参数函数内在表示。拓扑优化问题被重新表述为一个关于该序参数的约束最小化问题，要求在整个优化过程中同时满足三个关键性质：边界保持、体积守恒和目标函数单调衰减。主要的数学挑战来自于处理域相关体力，这需要开发一个约束优化框架。为了解决这个问题，我们开发了一种结合拉格朗日乘子和新颖限幅器机制的算子分裂算法。这种混合方法保证了严格的边界保持、精确的体积守恒和正确的目标函数衰减率。数值实现通过全面的二维和三维基准测试证明了该方案的鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [408] [Physics-aware Truck and Drone Delivery Planning Using Optimization & Machine Learning](https://arxiv.org/abs/2507.16259)
> *考虑物理特性的卡车与无人机配送规划：结合优化与机器学习*

*Yineng Sun, Armin Fügenschuh, Vikrant Vaze* | **Category: math.OC, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 卡车与无人机配送, 优化, 机器学习, 无人机轨迹, 末英里配送

**Comment:** 

> **TL;DR:** 本文提出了一种结合优化和机器学习的方法，用于考虑无人机物理特性的卡车与无人机联合配送规划，显著提高了配送效率和能耗。

**AI_Comments:** 本文的创新点在于将无人机飞行物理特性（运动学和能量方程）直接整合到卡车-无人机联合配送规划中，并通过结合优化与机器学习的端到端方法解决了这一复杂问题。这克服了传统简化模型的局限性，提高了配送方案的实际性能和效率，对于物流行业具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 将无人机与卡车结合进行末英里配送可减少配送时间和环境影响，但将无人机飞行动力学直接整合到组合上困难的卡车路线规划中极具挑战性，而忽略无人机物理特性的简化模型会导致次优的配送方案。

**Method:** 提出了一种卡车路线和无人机轨迹联合规划的集成公式，并开发了一种结合优化和机器学习的端到端解决方案。该方法通过离线训练神经网络预测器来近似无人机飞行时间，并将这些近似值用于优化整体卡车-无人机配送计划，增强了现有的“先订单后拆分”启发式算法。它明确地将无人机轨迹优化中的关键运动学和能量方程纳入考量。

**Result:** 该方法优于忽略无人机飞行物理的现有最先进基准。通过合成数据集和真实案例研究的广泛实验表明，将无人机轨迹整合到包裹配送规划中，在行程持续时间和无人机能耗方面显著提高了系统性能。

**Conclusion:** 本文的建模和计算框架可以帮助配送规划者实现每年数百万美元的节省，同时也有益于环境。

> **ai_Abstract:** 本文针对卡车与无人机联合配送中的复杂性，提出了一种考虑无人机物理特性的集成规划方法。该方法结合优化与机器学习，通过训练神经网络预测器来近似无人机飞行时间，并以此优化整体配送方案。实验证明，与忽略无人机物理特性的传统方法相比，该方法在配送时长和无人机能耗方面表现更优，具有显著的经济和环境效益。

> **摘要翻译:** 将节能无人机与高容量卡车结合用于末英里包裹配送，可以通过减少配送时间和环境影响来使运营商和客户受益。然而，将无人机飞行动力学直接整合到组合上困难的卡车路线规划问题中具有挑战性。忽略无人机飞行物理的简化模型可能导致次优的配送方案。我们提出了一种卡车路线和无人机轨迹联合规划的集成公式，以及一种新的端到端解决方案方法，该方法结合优化和机器学习，以在实际在线运行时生成高质量的解决方案。我们的解决方案通过基于无人机轨迹优化问题实例的离线解决方案训练神经网络预测器来近似无人机飞行时间，并利用这些近似值通过增强现有的“先订单后拆分”启发式算法来优化整体卡车-无人机配送计划。我们的方法明确地将关键运动学和能量方程纳入无人机轨迹优化中，因此优于忽略无人机飞行物理的最先进基准。使用合成数据集和真实案例进行的广泛实验表明，将无人机轨迹整合到包裹配送规划中，在行程持续时间和无人机能耗方面显著提高了系统性能。我们的建模和计算框架可以帮助配送规划者实现每年数百万美元的节省，同时也有益于环境。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [574] [Port-Hamiltonian Realizations of Nonminimal Linear Time Invariant Systems](https://arxiv.org/abs/2201.05355)
> *非最小线性时不变系统的端口哈密顿实现*

*Christopher Beattie, Volker Mehrmann, Hongguo Xu* | **Category: math.OC, cs.NA, math.NA, 93A30, 93B17, 93B11** | **Updated: 2025-07-21**

**Keywords:** 端口哈密顿系统, 线性时不变系统, 数值方法, 非最小系统, 馈通项

**Comment:** 

> **TL;DR:** 本文研究了为通用线性时不变系统构建端口哈密顿表示的数值方法，扩展了现有表征以涵盖非最小系统和特定馈通项情况，并能识别不可行性或通过扰动得到近似系统。

**AI_Comments:** 该论文的创新之处在于其将端口哈密顿表征的适用范围扩展到更复杂的系统类型，特别是非最小系统和馈通项具有特定性质的系统。其能够识别不可行性并提供近似解的能力，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩展先前的端口哈密顿表征，以包括一般的非最小系统以及馈通项不具有可逆对称部分的情况。

**Method:** 采用数值方法来开发通用线性时不变系统的端口哈密顿表示。该方法扩展了先前的端口哈密顿表征。

**Result:** 所构建的方法能够识别系统不满足端口哈密顿条件时的不可行性，并允许通过引入扰动来获得一个近似的端口哈密顿系统。结果通过数值例子进行了说明。

**Conclusion:** 该研究为处理更广泛的线性时不变系统的端口哈密顿表示提供了数值方法，尤其是在非最小和特定馈通项条件下的系统。它能有效判断系统是否为端口哈密顿系统，并提供近似解决方案。

> **ai_Abstract:** 本文研究了为通用线性时不变系统构建端口哈密顿表示的数值方法。该方法扩展了现有端口哈密顿表征，以涵盖非最小系统和馈通项对称部分不可逆的情况。所提出的构造能够识别系统不满足端口哈密顿条件的不可行性，并支持通过扰动得到近似的端口哈密顿系统。

> **摘要翻译:** 研究了开发通用线性时不变系统端口哈密顿表示的数值方法。该方法将先前的端口哈密顿表征扩展到包括一般的非最小情况以及馈通项不具有可逆对称部分的情况。所得到的构造能够识别系统不满足端口哈密顿条件时的不可行性，并允许通过引入扰动来获得一个近似的端口哈密顿系统。结果通过数值例子进行了说明。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [727] [On exploration of an interior mirror descent flow for stochastic nonconvex constrained problem](https://arxiv.org/abs/2507.15264)
> *关于随机非凸约束问题内点镜像下降流的探索*

*Kuangyu Ding, Kim-Chuan Toh* | **Category: math.OC, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 非凸优化, 黎曼次梯度流, 内点法, Hessian障碍法, 镜像下降法, 伪驻点

**Comment:** 34 Pages

> **TL;DR:** 本文通过引入黎曼次梯度流，统一了Hessian障碍法和镜像下降法，并提供了对伪驻点的解释和避免策略，提出了两种新的黎曼次梯度方法。

**AI_Comments:** 本文的创新之处在于通过引入黎曼次梯度流，为理解和改进非凸优化中的Hessian障碍法和镜像下降法提供了统一的框架和深刻的见解。特别是，将伪驻点解释为动力系统的稳定平衡点，并提出避免策略，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究一个在非凸约束下定义的非光滑非凸优化问题，并解决现有Hessian障碍法和镜像下降法收敛性不足的问题，特别是解释和避免伪驻点。

**Method:** 通过对开放集赋予由障碍函数诱导的黎曼度量，得到一个黎曼次梯度流（微分包含式），该流严格保持在可行集的内部。该连续动力系统统一了Hessian障碍法和镜像下降法，并将它们解释为连续流的离散近似。通过分析该动力系统的长期行为，解释了伪驻点为稳定平衡点。提供了两个避免伪驻点的充分条件（严格互补条件），并在缺乏正则条件时提出了随机扰动策略，以确保轨迹收敛到近似驻点。在此基础上，提出了两种迭代黎曼次梯度方法，作为内点法形式，推广了现有的Hessian障碍法和镜像下降法。

**Result:** 现有Hessian障碍法和镜像下降法的收敛性缺陷可以通过连续轨迹得到统一和更深入的解释，例如伪驻点被解释为动力系统的稳定平衡点。提供了两个在严格互补条件成立时避免伪驻点的充分条件。在缺乏正则条件时，随机扰动策略能确保轨迹（子序列地）收敛到近似驻点。提出了两种新的迭代黎曼次梯度方法，推广了现有方法。

**Conclusion:** 本文通过构建内点黎曼次梯度流，统一了Hessian障碍法和镜像下降法，并深入解释了它们的收敛性问题，特别是伪驻点现象。研究成果不仅提供了避免伪驻点的新条件，还提出了新的迭代算法，为解决非光滑非凸约束优化问题提供了理论基础和实用方法。

> **ai_Abstract:** 本文研究了在非凸约束下的非光滑非凸优化问题。通过引入由障碍函数诱导的黎曼度量，构建了一个严格保持在可行集内部的黎曼次梯度流。该连续动力系统统一了Hessian障碍法和镜像下降法，并揭示了它们是该连续流的离散近似。研究表明，现有方法的收敛性缺陷（如伪驻点）可以通过该连续轨迹得到统一且更深入的解释。伪驻点被解释为动力系统的稳定平衡点。文章提供了避免伪驻点的充分条件，并在条件不满足时提出随机扰动策略以确保收敛。基于这些见解，本文提出了两种推广现有方法的迭代黎曼次梯度内点法。

> **摘要翻译:** 我们研究了一个在非凸约束下定义的非光滑非凸优化问题，其中可行集由一个开集的闭包和一个光滑流形的交集给出。通过赋予开集一个由障碍函数诱导的黎曼度量，我们得到了一个表述为微分包含式的黎曼次梯度流，该流严格保持在可行集的内部。这个连续动力系统统一了两类迭代优化方法，即Hessian障碍法和镜像下降方案，揭示了这些方法可以被解释为连续流的离散近似。我们探索了由该动力系统生成的轨迹的长期行为，并表明现有Hessian障碍法和镜像下降方案的不足收敛性可以通过连续轨迹得到统一和更深入的解释。例如，Hessian障碍法和镜像下降方案中观察到的臭名昭著的伪驻点[chen2024spurious]被解释为动力系统的稳定平衡点，它们不对应于原始优化问题的真实驻点。我们提供了两个充分条件，如果严格互补条件成立，则可以避免这些伪驻点。在缺乏这些正则条件的情况下，我们提出了一种随机扰动策略，确保轨迹（子序列地）收敛到近似驻点。基于这些见解，我们引入了两种迭代黎曼次梯度方法，即内点法形式，它们推广了现有的用于解决非光滑非凸优化问题的Hessian障碍法和镜像下降方案。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [58] [An effective physics-informed neural operator framework for predicting wavefields](https://arxiv.org/abs/2507.16431)
> *一种预测波场的有效物理信息神经网络算子框架*

*Xiao Ma, Tariq Alkhalifah* | **Category: physics.geo-ph, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 物理信息神经网络算子, 波场预测, 亥姆霍兹方程, 深度学习, 地球物理

**Comment:** 

> **TL;DR:** 引入了一种物理信息卷积神经网络算子 (PICNO) 来高效求解亥姆霍兹方程，即使在训练样本有限的情况下也能实现高分辨率和相当准确的波场预测，并且在预测高频波场方面优于纯数据驱动方法。

**AI_Comments:** 该论文的创新点在于将物理信息（PDE约束）直接融入到神经网络算子的训练中，解决了传统数值方法在计算和内存上的挑战。这种方法不仅提高了预测的准确性，尤其是在高频波场方面，而且在数据受限的情况下也能表现出色，这对于实际地球物理应用，特别是波形反演，具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 求解波方程在地质地球物理应用中至关重要，但亥姆霍兹方程的数值解面临显著的计算和内存挑战。

**Method:** 引入了物理信息卷积神经网络算子 (PICNO)，它以均匀介质对应的背景波场和速度模型作为输入函数空间，生成散射波场作为输出函数空间。该工作流程将偏微分方程约束直接整合到训练过程中，使神经网络算子不仅能拟合可用数据，还能捕捉控制波现象的底层物理。

**Result:** PICNO 即使在训练样本有限的情况下也能实现高分辨率、相当准确的预测，并且在预测高频波场方面比纯数据驱动的卷积神经网络算子 (CNO) 有显著改进。

**Conclusion:** 这些特性和改进对于未来的波形反演非常重要。

> **ai_Abstract:** 本研究提出了一种物理信息卷积神经网络算子（PICNO），旨在高效解决亥姆霍兹方程在地球物理波场预测中的计算和内存难题。PICNO 通过将背景波场和速度模型作为输入，并整合偏微分方程约束到训练流程中，使其能够学习波动的物理规律。实验证明，即使在数据有限的情况下，PICNO 也能实现高分辨率和准确的预测，并且在处理高频波场时，其性能显著优于纯数据驱动的方法，这对于未来的波形反演具有重要意义。

> **摘要翻译:** 求解波方程对于地球物理应用至关重要。然而，亥姆霍兹方程的数值解面临显著的计算和内存挑战。因此，我们引入了一种物理信息卷积神经网络算子（PICNO）来高效求解亥姆霍兹方程。PICNO 将均匀介质对应的背景波场和速度模型作为输入函数空间，生成散射波场作为输出函数空间。我们的工作流程将偏微分方程约束直接整合到训练过程中，使神经网络算子不仅能够拟合可用数据，还能捕捉控制波现象的底层物理。PICNO 即使在训练样本有限的情况下也能实现高分辨率、相当准确的预测，并且在预测高频波场方面比纯数据驱动的卷积神经网络算子（CNO）有显著改进。这些特性和改进对于未来的波形反演非常重要。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

### [386] [DASPack: Controlled Data Compression for Distributed Acoustic Sensing](https://arxiv.org/abs/2507.16390)
> *DASPack：分布式声学传感的受控数据压缩*

*Aleix Segui, Arantza Ugalde, Andreas Fichtner, Sergi Ventosa, Josep Ramon Morros* | **Category: physics.geo-ph, eess.SP** | **Updated: 2025-07-22**

**Keywords:** 分布式声学传感, 数据压缩, DASPack, 小波变换, 线性预测编码

**Comment:** 

> **TL;DR:** DASPack是一款高性能、开源的分布式声学传感（DAS）数据压缩工具，支持有损和无损压缩，性能优于现有技术，有助于解决DAS数据存储挑战。

**AI_Comments:** DASPack的创新之处在于其专门为分布式声学传感（DAS）数据设计，并结合了多种先进压缩技术（小波变换、线性预测编码、熵编码），实现了有损和无损的受控压缩。其重要性在于有效解决了DAS数据量爆炸式增长带来的存储和管理挑战，并提供了满足实时处理需求的高吞吐量。该工具的开源性质和在多种数据集上的广泛验证，进一步增强了其在实际应用中的潜力和价值。

<details>
  <summary>Details</summary>

**Motivation:** 分布式声学传感（DAS）数据量快速增长，导致长期存储成为主要挑战，而现有压缩方法缺乏实用性和可扩展性。

**Method:** DASPack结合了小波变换、线性预测编码和熵编码来优化效率。它允许用户选择原始数据和压缩数据之间的最大绝对差异，从而实现受控的有损和无损压缩。

**Result:** 在无损模式下，DASPack可将应变和应变率数据的文件大小减少高达3倍。在有损模式下，在接近完美的信号保真度下压缩率提高到6倍，在可接受的信号降级下达到10倍。它提供快速吞吐量（单线程100-200 MB/s，8线程高达750 MB/s），支持实时部署。该工具已在15个不同采集环境的数据集上验证了其性能，展示了其速度、鲁棒性和广泛适用性。

**Conclusion:** DASPack为大规模监测网络中分布式声学传感（DAS）数据的长期可持续管理提供了实用的基础。

> **ai_Abstract:** DASPack是一种高性能、开源的数据压缩工具，专门用于解决分布式声学传感（DAS）数据量快速增长带来的存储挑战。它通过结合小波变换、线性预测编码和熵编码，提供受控的有损和无损压缩，允许用户指定最大可接受的误差。该工具在无损模式下可实现高达3倍的压缩，在有损模式下可实现高达10倍的压缩，同时保持高信号保真度，并提供高吞吐量以支持实时应用。DASPack已在多个数据集上验证，证明其在DAS数据管理方面的实用性、速度和鲁棒性。

> **摘要翻译:** 我们推出了DASPack，这是一款专为分布式声学传感（DAS）数据设计的高性能开源压缩工具。随着DAS成为地球物理、基础设施监测和环境传感等领域实时、高密度和长距离监测的关键技术，收集的数据量正在迅速增加。大规模DAS部署已经产生数百TB数据，预计未来几年还会增加，这使得长期存储成为一个重大挑战。尽管存在这种迫切需求，但很少有压缩方法在实际场景中被证明既实用又可扩展。DASPack是一个完全可操作的解决方案，其性能始终优于现有DAS数据技术。它通过允许用户选择原始数据和压缩数据之间每个数据点的最大绝对差异，实现受控的有损和无损压缩。压缩流程结合了小波变换、线性预测编码和熵编码以优化效率。我们的方法在无损模式下，针对各种数据集的应变和应变率数据，实现了高达3倍的文件大小缩减。在有损模式下，在接近完美的信号保真度下，压缩率提高到6倍，在可接受的信号降级下可达到10倍。它提供快速吞吐量（单线程100-200 MB/s，使用8线程高达750 MB/s），即使在高数据速率下也能实现实时部署。我们在来自各种采集环境的15个数据集上验证了其性能，展示了其速度、鲁棒性和广泛适用性。DASPack为大规模监测网络中DAS数据的长期可持续管理提供了实用基础。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

### [589] [Benchmarking CO$_2$ Storage Simulations: Results from the 11th Society of Petroleum Engineers Comparative Solution Project](https://arxiv.org/abs/2507.15861)
> *CO$_2$ 储存模拟基准测试：第11届石油工程师协会对比解决方案项目的结果*

*Jan M. Nordbotten, Martin A. Fernø, Bernd Flemisch, Anthony R. Kovscek, Knut-Andreas Lie, Jakub W. Both, Olav Møyner, Tor Harald Sandve, Etienne Ahusborde, Sebastian Bauer, Zhangxing Chen, Holger Class, Chaojie Di, Didier Ding, David Element, Abbas Firoozabadi, Eric Flauraud, Jacques Franc, Firdovsi Gasanzade, Yousef Ghomian, Marie Ann Giddins, Christopher Green, Bruno R. B. Fernandes, George Hadjisotiriou, Glenn Hammond, Hai Huang, Dickson Kachuma, Michel Kern, Timo Koch, Prasanna Krishnamurthy, Kjetil Olsen Lye, David Landa-Marbán, Michael Nole, Paolo Orsini, Nicolas Ruby, Pablo Salinas, Mohammad Sayyafzadeh, Jakub Solovský, Jakob Torben, Adam Turner, Denis V. Voskov, Kai Wendel, AbdAllah A. Youssef* | **Category: physics.geo-ph, cs.CE, cs.NA, math.NA** | **Updated: 2025-07-05**

**Keywords:** CO2储存模拟, 基准测试, SPE11, 模拟变异性, 人为因素

**Comment:** 

> **TL;DR:** 第11届SPE对比解决方案项目（SPE11）对地质CO$_2$储存模拟工具进行了基准测试。研究发现，模拟结果的差异不仅受热效应、溶解驱动对流混合和相间不连续性分辨率等计算因素影响，还受到未报告的人为选择的显著影响。

**AI_Comments:** 这项研究的重要性在于揭示了CO$_2$储存模拟中人为因素对结果的潜在影响。它提醒研究人员和工程师，除了计算参数外，操作者在模拟准备和报告过程中的选择也可能导致显著的变异性，这对于确保模拟的可靠性和可重复性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的目的是对地质二氧化碳（CO$_2$）储存的模拟工具进行基准测试。

**Method:** 该研究总结了第11届石油工程师协会对比解决方案项目（SPE11），共有45个小组报名参与，其中18个小组提供了有效结果。研究提供了提交数据的全面介绍和定性讨论，并提出了一个用于分析提交结果之间相对距离的全球度量标准，并用其进行了定量分析，试图统计性地解决影响提交结果变异性的关键因素。

**Result:** 研究显示，提交结果之间的主要定性差异与热效应、溶解驱动对流混合以及相间不连续性的分辨率有关。此外，在SPE11的所有三个版本中，都观察到对网格分辨率的强烈依赖。然而，定量分析表明，观察到的变异主要受到参与者未在技术响应中记录的因素影响。

**Conclusion:** 未报告的人为选择，在设置、执行和报告模拟过程中，其影响至少与报告的计算选择一样大。

> **ai_Abstract:** 本研究对第11届石油工程师协会对比解决方案项目（SPE11）进行了总结，该项目旨在对地质CO$_2$储存模拟工具进行基准测试。研究分析了来自18个有效提交结果的数据，发现模拟结果的变异性主要与热效应、溶解驱动对流混合和相间不连续性分辨率有关，并强烈依赖于网格分辨率。然而，定量分析揭示，未报告的人为选择在模拟设置、执行和报告过程中，对结果变异性的影响与报告的计算选择同样显著。

> **摘要翻译:** 第11届石油工程师协会对比解决方案项目（本文简称SPE11）对地质二氧化碳（CO$_2$）储存的模拟工具进行了基准测试。全球领先的研究机构和工业界的45个小组报名参加，其中18个最终贡献了有效结果，并被纳入本报告的对比研究中。
本文总结了SPE11。提供了提交数据的全面介绍和定性讨论，以及访问完整数据在线资源的概述。提出了一个用于分析提交结果之间相对距离的全球度量标准，并用其对提交结果进行了定量分析。这项分析试图统计性地解决影响提交结果变异性的关键方面。
研究表明，提交结果之间的主要定性差异与热效应、溶解驱动对流混合以及相间不连续性的分辨率有关。此外，在SPE11的所有三个版本中，都观察到对网格分辨率的强烈依赖。然而，我们的定量分析表明，观察到的变异主要受到参与者提供的技术响应中未记录的因素影响。因此，我们认为，在设置、执行和报告每个SPE11提交所依据的模拟过程中，由于人为选择导致的未报告变异至少与报告的计算选择一样具有影响力。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [74] [Wide-Angle, Multiplexed Backscatter Communications Using a Dynamic Metasurface-Backed Luneburg Lens](https://arxiv.org/abs/2503.16366)
> *使用动态超表面背衬透镜的广角、多路反向散射通信*

*Samuel Kim, Tim Sleasman, Avrami Rakovsky, Ra'id Awadallah, David B. Shrekenhamer* | **Category: physics.optics, eess.SP** | **Updated: 2025-07-21**

**Keywords:** 反向散射通信, 超表面, 透镜, 广角, 空间复用

**Comment:** 13 pages, 9 figures. Accepted for publication in IEEE Access

> **TL;DR:** 本文设计并演示了一种结合扁平化透镜和动态超表面的反向散射设备，实现了宽视场、长距离、多功能和安全的反向散射通信。

**AI_Comments:** 该论文通过将扁平化透镜与动态超表面相结合，提出了一种创新的反向散射通信方案，显著拓展了反向散射技术的应用范围和功能。其创新性在于利用变换光学实现宽视场回射和利用超表面进行精细信号控制，解决了传统反向散射设备在距离和功能上的限制。该技术在低功耗、长距离和安全无线通信领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的反向散射通信设备通常在范围和功能上受到限制，无法满足长距离和高级通信的需求。

**Method:** 本文设计并制造了一种扁平化透镜，结合准共形变换光学，使其能将宽视场内的入射波聚焦到其平面焦平面上。通过在焦平面放置反射面，实现宽视场（±30°）和宽带宽的回射。动态超表面被设计用于在S波段（2-4 GHz）内对反射相位进行精细的空间控制调制。将扁平化透镜与动态超表面结合，使设备能够调制回射信号以实现反向散射通信。

**Result:** 实验证明了对反向散射信号在不同入射角下的全相位控制、空间复用能力，以及通过主动抑制或随机化不需要方向的信号来实现对抗窃听者的安全通信。

**Conclusion:** 该超表面背衬透镜设备为具有先进功能的远程无线网络提供了一种低功耗解决方案。

> **ai_Abstract:** 本文提出并实验验证了一种新型反向散射设备，该设备结合了扁平化透镜和动态超表面，旨在克服传统反向散射设备在范围和功能上的局限性。通过准共形变换光学设计的扁平化透镜实现了宽视场（±30°）和宽带宽的回射，而动态超表面则提供了S波段（2-4 GHz）的精细相位调制能力。实验结果表明，该设备能够实现反向散射信号的全相位控制、空间复用以及通过主动信号管理增强通信安全性，为长距离、低功耗无线网络提供了先进的解决方案。

> **摘要翻译:** 反向散射通信因其无需主动辐射组件而具有低功耗的吸引力；然而，常用的设备通常在范围和功能上受到限制。本文设计并演示了一种反向散射设备，该设备由一个扁平化透镜和一个空间可调的动态超表面组成。利用准共形变换光学（QCTO），我们设计了一个扁平化、增材制造的透镜，它能将宽视场内的入射波聚焦到其扁平化的焦平面上。当反射面放置在焦平面时，扁平化透镜会回射，从而实现超大视场（±30°）和宽带宽的长距离反向散射通信。动态超表面被设计用于在S波段（2-4 GHz）内通过精细的空间控制调制反射相位。因此，当与扁平化透镜结合时，该设备能够调制回射信号以实现反向散射通信。我们实验证明了在一定入射角范围内对反向散射信号的全相位控制、空间复用，以及通过主动抑制或随机化不需要方向的信号来实现对抗窃听者的安全通信。这种超表面背衬透镜设备为具有先进功能的远程无线网络提供了一种低功耗解决方案。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [78] [AutoMAT: A Hierarchical Framework for Autonomous Alloy Discovery](https://arxiv.org/abs/2507.16005)
> *AutoMAT：一个用于自主合金发现的层次框架*

*Penghui Yang, Chendong Zhao, Bijun Tang, Zhonghan Zhang, Xinrun Wang, Yanchen Deng, Yuhao Lu, Cuntai Guan, Zheng Liu, Bo An* | **Category: cond-mat.mtrl-sci, cs.AI, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 合金发现, 自主框架, 大型语言模型, CALPHAD, AI驱动搜索

**Comment:** 

> **TL;DR:** AutoMAT是一个分层自主框架，结合LLM、CALPHAD模拟和AI搜索，显著加速合金设计，并在案例研究中发现了性能优异的新合金，将发现时间从数年缩短至数周。

**AI_Comments:** AutoMAT的创新之处在于其将LLM、自动化CALPHAD模拟和AI搜索集成到一个分层的自主框架中，实现了从构思到验证的全流程自动化，并且无需大量人工数据集，显著提高了合金发现的效率和准确性。其在实际案例中将发现时间从数年缩短到数周，显示出巨大的应用前景，有望成为下一代合金设计的重要工具。

<details>
  <summary>Details</summary>

**Motivation:** 合金发现是推动现代工业发展的核心，但其仍受制于巨大的成分设计空间和昂贵的验证成本。

**Method:** AutoMAT是一个分层且自主的框架，整合了大型语言模型（LLM）、自动化CALPHAD模拟和AI驱动的搜索。它涵盖从构思到验证的整个流程，无需人工整理的大型数据集。

**Result:** 在轻质高强度合金的案例研究中，AutoMAT发现了一种钛合金，其密度比现有技术参考低8.1%，屈服强度相当，并实现了所有比较中最高的比强度。在第二个针对高屈服强度高熵合金的案例中，AutoMAT使屈服强度比基础合金提高了28.2%。在两个案例中，AutoMAT都将发现时间从数年缩短到数周。

**Conclusion:** AutoMAT展示了其作为下一代合金设计可扩展且多功能平台的潜力。

> **ai_Abstract:** AutoMAT是一个新颖的分层自主框架，旨在通过整合大型语言模型、自动化CALPHAD模拟和AI驱动搜索来加速合金发现。该框架覆盖从构思到验证的全流程，无需大量手动数据集，即可实现高效、准确和可解释的合金设计。通过两个案例研究，AutoMAT成功发现了性能优越的新合金，包括一种比现有技术密度更低的钛合金和一种屈服强度显著提高的高熵合金，显著缩短了合金研发周期，展现了其在未来合金设计中的巨大潜力。

> **摘要翻译:** 合金发现是推动现代工业发展的核心，但其仍受制于巨大的成分设计空间和昂贵的验证成本。在此，我们提出了AutoMAT，一个基于实验验证的分层自主框架，它整合了大型语言模型、自动化CALPHAD模拟和AI驱动搜索，以加速合金设计。AutoMAT涵盖从构思到验证的整个流程，无需人工整理的大型数据集即可实现高效率、高准确性和可解释性。在一个针对轻质高强度合金的案例研究中，AutoMAT发现了一种钛合金，其密度比现有技术参考低8.1%，屈服强度相当，并实现了所有比较中最高的比强度。在第二个针对高屈服强度高熵合金的案例中，AutoMAT使屈服强度比基础合金提高了28.2%。在这两个案例中，AutoMAT都将发现时间从数年缩短到数周，展示了其作为下一代合金设计可扩展且多功能平台的潜力。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [464] [Nd3+ Doping-induced Leakage Currents Suppression in High-temperature 0.7BiFeO3-0.3BaTiO3 Lead-free Piezoceramics](https://arxiv.org/abs/2507.16156)
> *Nd3+掺杂抑制高温0.7BiFeO3-0.3BaTiO3无铅压电陶瓷的漏电流*

*Jinming Liu, Mingtong Chen, Zhengbao Yang* | **Category: cond-mat.mtrl-sci, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** Nd3+掺杂, 漏电流抑制, 无铅压电陶瓷, 高温稳定性, BiFeO3-BaTiO3

**Comment:** 

> **TL;DR:** Nd3+掺杂能显著抑制0.7BiFeO3-0.3BaTiO3无铅压电陶瓷在高温下的漏电流，提高其电阻率和热稳定性，并保持优异的压电性能，为高温应用提供新策略。

**AI_Comments:** 该论文提出了一种通过Nd3+掺杂有效抑制BF-BT无铅压电陶瓷高温漏电流的方法，解决了其在高温应用中的关键限制。其创新性在于明确指出Nd掺杂通过改善晶格对称性和减少氧空位缺陷来达到效果，并提供了量化的漏电流抑制数据。这不仅为BF-BT体系的实际应用铺平了道路，也为其他无铅压电材料的高温稳定性优化提供了普适性的设计策略，具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** BiFeO3作为传统铅基压电材料的潜在替代品备受关注，但其固有的高漏电流严重限制了其实际应用，导致压电响应低和温度稳定性差。

**Method:** 制备了0.7BiFeO3-0.3BaTiO3（BF-BT）体系的无铅压电陶瓷，并通过引入Nd3+来调控其微观结构和高温电学性能。

**Result:** 适度的Nd掺杂改善了晶格对称性，减少了氧空位相关的缺陷偶极子，从而有效抑制了75°C以上温度的漏电流。Nd掺杂样品的漏电流密度比未掺杂陶瓷降低了99%以上，低至10-5Acm-2。它们在高温和电场下表现出更高的电阻率，热稳定性显著提高。此外，Nd掺杂样品在室温下获得了高达172 pC N-1的压电系数，并在高温下仍保持高介电和压电响应。

**Conclusion:** 这项工作不仅为解决BF-BT陶瓷在高温应用中的漏电流问题提供了有效方法，而且为优化无铅压电材料的高温稳定性指示了一种新的设计策略，在高温传感器和执行器领域具有广阔的应用前景。

> **ai_Abstract:** 本研究旨在解决0.7BiFeO3-0.3BaTiO3（BF-BT）无铅压电陶瓷在高温下漏电流过高的问题。通过引入Nd3+掺杂，研究人员成功改善了材料的晶格对称性并减少了氧空位缺陷，从而显著抑制了高温漏电流（降低超过99%）。Nd掺杂样品在高温下展现出更高的电阻率和优异的热稳定性，同时保持了良好的压电性能。这项工作为开发用于高温传感器和执行器的新型无铅压电材料提供了有效策略和设计思路。

> **摘要翻译:** BiFeO3作为替代传统铅基压电材料的潜在候选者，因其卓越的自发极化和高居里温度而备受关注。然而，其固有的高漏电流导致压电响应低和温度稳定性差，严重限制了其实际应用。在本研究中，制备了0.7BiFeO3-0.3BaTiO3（BF-BT）体系的无铅压电陶瓷，并通过引入Nd3+来调控其微观结构和高温电学性能。结果表明，适度的Nd掺杂改善了晶格对称性并减少了氧空位相关的缺陷偶极子，从而有效抑制了75°C以上温度的漏电流。Nd掺杂样品的漏电流密度比未掺杂陶瓷显著降低了99%以上，低至10-5Acm-2。它们在高温和电场下也表现出更高的电阻率，与未掺杂样品相比，热稳定性显著提高。此外，Nd掺杂样品在室温下获得了高达172 pC N-1的压电系数，同时在高温下仍保持高介电和压电响应。这项工作不仅为解决BF-BT陶瓷在高温应用中的漏电流问题提供了有效方法，而且为优化无铅压电材料的高温稳定性指示了一种新的设计策略，这在高温传感器和执行器领域显示出广阔的应用前景。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [668] [Constructing material network representations for intelligent amorphous alloys design](https://arxiv.org/abs/2507.16336)
> *构建材料网络表征以实现智能非晶合金设计*

*S. -Y. Zhang, J. Tian, S. -L. Liu, H. -M. Zhang, H. -Y. Bai, Y. -C. Hu, W. -H. Wang* | **Category: cond-mat.mtrl-sci, cond-mat.dis-nn, cs.CC, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 材料网络, 非晶合金, 智能设计, 合金发现

**Comment:** 5 figures

> **TL;DR:** 本文提出利用材料网络加速二元和三元非晶合金的发现，通过动态材料网络揭示传统方法难以发现的隐藏材料候选，并展示其在指导新合金设计方面的预测能力，为智能材料设计开辟了新途径。

**AI_Comments:** 该论文的创新之处在于将网络科学引入材料设计领域，特别是针对非晶合金。通过构建材料网络和动态材料网络，它提供了一种全新的视角来探索材料空间，并揭示了传统方法无法捕捉的隐藏关系和预测能力。这对于加速新材料发现和降低研发成本具有重要意义，为智能材料设计开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 设计高性能非晶合金过程高度依赖经验法则和无限制的尝试，传统策略成本高、效率低，阻碍了在巨大材料空间中的有效采样。

**Method:** 提出并构建了材料网络来加速二元和三元非晶合金的发现。通过分析不同年份合成的非晶合金，构建动态材料网络来追踪合金发现的历史。

**Result:** 材料网络拓扑结构揭示了传统表格数据表示所掩盖的隐藏材料候选。过去设计的创新材料被编码在网络中，证明了其在指导新合金设计方面的预测能力。这些材料网络与现实世界中的一些网络表现出物理相似性。

**Conclusion:** 研究结果为智能材料设计，特别是复杂合金的设计，开辟了一条新途径。

> **ai_Abstract:** 本文提出了一种基于材料网络的新方法，旨在克服传统非晶合金设计中高成本、低效率和经验依赖的局限性。通过构建静态和动态材料网络，该方法能够揭示传统表格数据难以发现的隐藏材料候选，并有效追踪合金发现的历史。研究发现，这些网络具有预测能力，能够指导新合金的设计，且与现实世界网络具有物理相似性。这为智能材料设计，尤其是复杂合金的设计，提供了新的范式。

> **摘要翻译:** 设计高性能非晶合金对于各种应用来说要求很高。但这一过程高度依赖经验法则和无限次的尝试。传统策略的高成本和低效率性质阻碍了在巨大的材料空间中进行有效采样。本文提出利用材料网络来加速二元和三元非晶合金的发现。网络拓扑揭示了传统表格数据表示所掩盖的隐藏材料候选。通过仔细审查不同年份合成的非晶合金，我们构建了动态材料网络来追踪合金发现的历史。我们发现过去设计的一些创新材料被编码在网络中，这证明了它们在指导新合金设计方面的预测能力。这些材料网络与我们日常生活中几个真实世界的网络表现出物理相似性。我们的发现为智能材料设计，特别是复杂合金的设计，开辟了一条新途径。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [84] [Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling](https://arxiv.org/abs/2507.14915)
> *音乐对齐的全身3D舞蹈通过分层运动建模生成*

*Xiaojie Li, Ronghui Li, Shukai Fang, Shuzhao Xie, Xiaoyang Guo, Jiaqing Zhou, Junkun Peng, Zhi Wang* | **Category: cs.MM, cs.SD, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 全身3D舞蹈生成, 音乐对齐, 分层运动建模, SoulDance, SoulNet

**Comment:** 

> **TL;DR:** 本文提出了SoulDance数据集和SoulNet框架，通过分层运动建模和音乐对齐，解决了全身3D舞蹈生成中数据稀缺、跨模态对齐和复杂运动建模的挑战，能够生成高质量的音乐对齐全身舞蹈。

**AI_Comments:** 本文的创新点在于构建了一个高精度的全身3D舞蹈数据集，并提出了一个结合分层运动建模和跨模态对齐的框架，有效解决了全身舞蹈生成中的核心挑战。其重要性在于提升了音乐舞蹈生成领域的真实性和协调性。

<details>
  <summary>Details</summary>

**Motivation:** 生成协调良好、与音乐对齐的整体舞蹈具有挑战性，原因在于：1. 整体3D舞蹈数据集稀缺；2. 音乐与舞蹈之间跨模态对齐困难；3. 身体、手和脸之间相互依赖运动建模的复杂性。

**Method:** 本文引入了SoulDance数据集，这是一个通过专业动作捕捉系统捕获的高精度音乐-舞蹈配对数据集。在此基础上，提出了SoulNet框架，用于生成音乐对齐、运动协调的整体舞蹈序列。SoulNet包含三个主要组件：1. 分层残差矢量量化，用于建模身体、手和脸之间复杂、细粒度的运动依赖；2. 音乐对齐生成模型，将这些分层运动单元组合成富有表现力和协调的整体舞蹈；3. 音乐-运动检索模块，作为音乐-舞蹈对齐的先验，确保生成过程中舞蹈与音乐的时间同步和语义一致性。

**Result:** 广泛的实验表明，SoulNet在生成高质量、音乐协调且对齐的整体3D舞蹈序列方面显著超越了现有方法。

**Conclusion:** 本文提出的SoulDance数据集和SoulNet框架有效解决了整体3D舞蹈生成中的关键挑战，并能够生成高质量、音乐对齐的舞蹈序列。

> **ai_Abstract:** 本文针对全身3D舞蹈生成中数据稀缺、跨模态对齐和复杂运动建模的难题，构建了高精度的SoulDance数据集，并提出了SoulNet框架。SoulNet通过分层残差矢量量化、音乐对齐生成模型和音乐-运动检索模块，实现了高质量、音乐协调的全身3D舞蹈序列生成，并在实验中验证了其优越性。

> **摘要翻译:** 协调良好、与音乐对齐的整体舞蹈能增强情感表达和观众参与度。然而，生成此类舞蹈仍然充满挑战，原因在于整体3D舞蹈数据集稀缺、音乐与舞蹈之间跨模态对齐困难，以及身体、手和脸之间相互依赖运动建模的复杂性。为了解决这些挑战，我们引入了SoulDance，一个通过专业动作捕捉系统捕获的高精度音乐-舞蹈配对数据集，其中包含精心标注的整体舞蹈动作。基于此数据集，我们提出了SoulNet，一个旨在生成与音乐对齐、运动协调的整体舞蹈序列的框架。SoulNet由三个主要组件构成：(1) 分层残差矢量量化，用于建模身体、手和脸之间复杂、细粒度的运动依赖；(2) 音乐对齐生成模型，将这些分层运动单元组合成富有表现力和协调的整体舞蹈；(3) 音乐-运动检索模块，一个预训练的跨模态模型，作为音乐-舞蹈对齐的先验，确保在整个生成过程中生成舞蹈与输入音乐之间的时间同步和语义一致性。广泛的实验表明，SoulNet在生成高质量、音乐协调且对齐的整体3D舞蹈序列方面显著超越了现有方法。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='mathca'></a>
## math.CA 

### [88] [A Best Possible General Form of the Master Theorem for Divide-and-Conquer Recurrences](https://arxiv.org/abs/2507.16064)
> *分治递归主定理的最佳通用形式*

*Carl D. Offner* | **Category: math.CA, cs.DS, math.CO, 41, F.2** | **Updated: 2025-07-21**

**Keywords:** 主定理, 分治递归, 递归关系, 通用形式

**Comment:** 20 pages, 1 figure

> **TL;DR:** 本文提出了一个关于分治递归主定理的通用、最优且推导平滑的形式。

**AI_Comments:** 本文的创新点在于提出了一个更通用、更优化且推导过程更平滑的主定理形式，这对于分析分治算法的复杂度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是提供一个关于分治递归主定理的通用、最佳且推导平滑的形式。

**Method:** Not mentioned in abstract

**Result:** 得到了一个通用、最佳且推导平滑的分治递归主定理形式。

**Conclusion:** 本文成功提供了一个通用、最佳且推导平滑的分治递归主定理形式。

> **ai_Abstract:** 本文提出并详细阐述了分治递归主定理的一个新的、通用且最优的形式，该形式的推导过程也更为平滑。

> **摘要翻译:** 我们在此给出了分治递归主定理的一个通用、最佳且推导平滑的形式。

</details>

[⬆️ 返回分类顶部](#mathca) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [105] [From heteroclinic loops to homoclinic snaking in reversible systems: rigorous forcing through computer-assisted proofs](https://arxiv.org/abs/2507.16798)
> *从异宿环到可逆系统中的同宿缠绕：通过计算机辅助证明的严格强迫*

*Jan Bouwe van den Berg, Gabriel William Duchesne, Jean-Philippe Lessard* | **Category: math.DS, cs.NA, math.AP, math.NA, 34C37 (Primary) 37M21, 35B36, 65G40, 65T40, 42A10, 37C79 (Secondary)** | **Updated: 2025-07-22**

**Keywords:** 同宿缠绕, 异宿连接, 计算机辅助证明, 可逆系统, 非线性动力系统

**Comment:** Preprint

> **TL;DR:** 本文利用计算机辅助证明，通过分析异宿连接，严格证明了可逆系统（特别是Swift-Hohenberg和Gray-Scott问题）中的同宿缠绕现象。

**AI_Comments:** 本文的创新之处在于严格应用计算机辅助证明来分析非线性动力系统中连续连接轨道族。这种方法为解决同宿缠绕等复杂问题提供了一种强大而新颖的途径，这些问题由于其非线性性质而难以解决。其重要性在于将严格证明的适用性扩展到分析方法不足的领域，为理解全局动力学开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 同宿缠绕现象普遍存在，但在非微扰区域难以证明。现有的强迫理论依赖于模式前沿解（异宿解），而这些解由于非线性性质难以分析。

**Method:** 利用计算机辅助证明，在时间可逆系统中寻找平衡点和周期轨道之间异宿连接的参数化环。

**Result:** 证明了Swift-Hohenberg和Gray-Scott问题中的同宿缠绕现象。

**Conclusion:** 计算机辅助证明连续连接轨道族在非线性动力系统中的应用，是理解全局动力学及其参数依赖性的强大工具。

> **ai_Abstract:** 本文解决了在模式形成系统的非微扰区域中严格证明同宿缠绕的难题。通过采用计算机辅助证明，作者识别了时间可逆系统中异宿连接的参数化环。该方法成功证明了Swift-Hohenberg和Gray-Scott问题中同宿缠绕的存在，突出了计算机辅助证明在分析非线性系统全局动力学方面的强大作用。

> **摘要翻译:** 同宿缠绕是许多模式形成系统中普遍存在的现象。尽管已经发展出基于模式前沿解识别的强迫理论，但在非微扰区域证明其发生仍被证实是困难的。这些异宿解本身由于问题的非线性性质而难以分析。在本文中，我们使用计算机辅助证明来寻找时间可逆系统中平衡点和周期轨道之间异宿连接的参数化环。这导致了Swift-Hohenberg和Gray-Scott问题中同宿缠绕的证明。我们的结果表明，非线性动力系统中连续连接轨道族的计算机辅助证明是理解全局动力学及其参数依赖性的强大工具。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [109] [Adaptive Multi-task Learning for Multi-sector Portfolio Optimization](https://arxiv.org/abs/2507.16433)
> *多领域投资组合优化的自适应多任务学习*

*Qingliang Fan, Ruike Wu, Yanrong Yang* | **Category: stat.ME, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 多任务学习, 投资组合优化, 因子建模, 投影惩罚主成分分析, 跨领域信息传递

**Comment:** 

> **TL;DR:** 提出了一种自适应多任务学习方法，通过量化和学习多领域因子模型之间的相关性，来改进多领域投资组合优化，并开发了相应的算法。

**AI_Comments:** 这项研究的创新点在于提出了数据自适应的多任务学习方法，通过量化和学习不同领域因子模型之间的内在相关性，有效地提升了多领域投资组合优化的性能。特别值得关注的是，其提出的投影惩罚主成分分析算法，为实现这种多任务学习提供了一种具体且易于实施的工具。该方法对于处理跨领域数据依赖性和提高模型估计精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在涉及大量不同类别资产的多领域投资组合优化中，跨多领域准确传递信息以增强模型估计既重要又具有挑战性。

**Method:** 在因子建模框架下，提出了一种新颖的数据自适应多任务学习方法，该方法量化并学习所研究的多个领域中主要时间子空间（由因子跨越）之间的相关性。此外，开发了一种新颖且易于实现的算法，称为投影惩罚主成分分析，以完成多任务学习过程。

**Result:** 该方法不仅改进了多个因子模型的同步估计，还增强了多领域投资组合优化。通过多种模拟设计和在罗素3000指数日收益数据上的实际应用，证明了多任务学习方法的优势。

**Conclusion:** 通过自适应多任务学习和新颖的算法（投影惩罚主成分分析），可以有效解决多领域投资组合优化中信息传递和模型估计的挑战，从而提升优化效果。

> **ai_Abstract:** 这篇论文提出了一种在因子建模框架下的数据自适应多任务学习方法，旨在解决多领域投资组合优化中跨领域信息传递和模型估计的挑战。该方法通过量化和学习不同领域主要时间子空间的相关性，改进了因子模型的同步估计，从而增强了投资组合优化。为实现这一过程，还开发了一种名为投影惩罚主成分分析的新算法。仿真和实际数据应用验证了其有效性。

> **摘要翻译:** 准确地跨多个领域传递信息以增强模型估计在涉及大量不同类别资产的多领域投资组合优化中既重要又具有挑战性。在因子建模框架内，我们提出了一种新颖的数据自适应多任务学习方法，该方法量化并学习所研究的多个领域中主要时间子空间（由因子跨越）之间的相关性。这种方法不仅改进了多个因子模型的同步估计，而且增强了多领域投资组合优化，而多领域投资组合优化严重依赖于这些因子模型的准确恢复。此外，开发了一种新颖且易于实现的算法，称为投影惩罚主成分分析，以完成多任务学习过程。多样化的模拟设计和在罗素3000指数日收益数据上的实际应用证明了多任务学习方法的优势。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [410] [Recursive Equations For Imputation Of Missing Not At Random Data With Sparse Pattern Support](https://arxiv.org/abs/2507.16107)
> *稀疏模式支持下非随机缺失数据归因的递归方程*

*Trung Phung, Kyle Reese, Ilya Shpitser, Rohit Bhattacharya* | **Category: stat.ME, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 缺失数据, 多重插补, MNAR, 图模型, MISPR

**Comment:** 45 pages

> **TL;DR:** 本文提出了一种名为MISPR的新型多重插补算法，它能有效处理随机缺失(MAR)和非随机缺失(MNAR)数据，以及稀疏缺失模式，并在MNAR情况下表现优于现有方法如MICE。

**AI_Comments:** 本文在缺失数据插补领域取得了显著进展，它提供了一种有原则的方法，明确解决了非随机缺失（MNAR）数据和稀疏缺失模式带来的挑战，这些在真实世界数据集中非常普遍。所提出的MISPR算法克服了MICE等广泛使用工具的局限性，避免了不切实际的参数假设，从而产生了偏差更小的结果。它在MAR和MNAR设置下的一致性使其成为实际应用中，尤其是在高维背景下，更稳健和通用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多重插补方法（如MICE和Amelia）通常假设数据是随机缺失(MAR)，并施加不切实际的参数或平滑假设，这在实践中是不现实的，会导致模型误设定偏差，尤其是在数据是非随机缺失(MNAR)或缺失模式稀疏的情况下。

**Method:** 本文提出了一种在缺失数据图模型中表征完整数据律的新方法。基于此，开发了一种新的插补算法——通过支持模式递归进行多元插补(MISPR)，该算法通过类比MICE使用吉布斯采样，但其在MAR和MNAR设置下均保持一致性，并且无需在缺失数据模型本身已有的假设之外施加额外假设即可处理没有支持的缺失数据模式。

**Result:** 在模拟中，MISPR在数据为MAR时取得了与MICE相当的结果，而在数据为MNAR时获得了更优、偏差更小的结果。

**Conclusion:** 本文提出的数据律表征和基于此的插补算法，是使原则性缺失数据方法在实际应用中更具可行性的一步，尤其适用于数据可能同时是MNAR且维度高到在现有样本量下产生没有支持的缺失数据模式的场景。

> **ai_Abstract:** 本文旨在解决传统多重插补方法（如MICE）在处理非随机缺失（MNAR）数据和稀疏缺失模式时存在的局限性，这些方法常假设数据随机缺失（MAR）并依赖不切实际的参数假设。作者提出了一种新的缺失数据图模型中完整数据律的表征，并基于此开发了一种名为多元插补支持模式递归（MISPR）的新型插补算法，该算法采用吉布斯采样。MISPR在MAR和MNAR两种设置下均表现出一致性，并能有效处理无支持的缺失数据模式，而无需额外假设。模拟结果表明，MISPR在MAR数据上与MICE表现相当，但在MNAR数据上则更优且偏差更小，从而为实际应用中复杂的缺失数据场景提供了更实用、更有原则的解决方案。

> **摘要翻译:** 在数据分析流程中处理缺失值的常见方法是通过MICE（Van Buuren和Groothuis-Oudshoorn，2011）和Amelia（Honaker et al.，2011）等软件包进行多重插补。这些软件包通常假设数据是随机缺失（MAR），并在插补分布上施加参数或平滑假设，以便即使并非所有缺失模式在数据中都有支持也能进行插补。这种假设在实践中是不切实际的，并会对经过此类插补后进行的任何分析引入模型误设定偏差。
在本文中，我们提供了一种有原则的替代方案。具体来说，我们为缺失数据图模型中的完整数据律开发了一种新的表征。这种表征是建设性的，易于适应MAR和MNAR（非随机缺失）机制的插补分布计算，并且能够处理某些缺失模式缺乏支持的情况。我们利用这种表征开发了一种新的插补算法——通过支持模式递归进行多元插补（MISPR）——它通过类比多重插补链式方程（MICE）算法使用吉布斯采样，但其在MAR和MNAR设置下均保持一致，并且无需在缺失数据模型本身已有的假设之外施加额外假设即可处理没有支持的缺失数据模式。
在模拟中，我们展示了当数据为MAR时，MISPR获得了与MICE相当的结果，而当数据为MNAR时，获得了更优、偏差更小的结果。我们的表征以及基于它的插补算法，是使原则性缺失数据方法在应用环境中更具实用性的一步，在这些环境中，数据很可能是MNAR且维度足够高，以至于在可用样本量下产生没有支持的缺失数据模式。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [125] [Best-of-Both-Worlds Guarantees with Fairer Endings](https://arxiv.org/abs/2507.16209)
> *兼顾两全的保证与更公平的结局*

*Telikepalli Kavitha, Surya Panchapakesan, Rohit Vaish, Vignesh Viswanathan, Jatin Yadav* | **Category: cs.GT, cs.DS** | **Updated: 2025-07-22**

**Keywords:** 公平分配, 不可分割物品, 无嫉妒, 兼顾两全, 随机分配

**Comment:** 46 pages. Abstract shortened to meet arXiv requirements

> **TL;DR:** 该论文旨在为不可分割物品的公平分配实现更强的事后公平保证，并针对不同估值类型提出了算法。

**AI_Comments:** 该论文通过将“兼顾两全”的保证扩展到更强的事后公平概念（如EFX），做出了重要贡献，而EFX是众所周知的难以实现的。它系统地分析了不同估值类型，并提供了具体的算法解决方案和不可能性结果，突出了不同公平概念之间固有的权衡。依赖舍入的使用是一种值得注意的算法技术。其创新在于将可实现的公平保证的边界从EF1推向EFX变体，这是公平分配领域的一个主要挑战。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为不可分割物品的公平分配问题，在保持有意义的事前（ex-ante）保证的同时，实现更强的事后（ex-post）公平保证，例如“无嫉妒任何物品”（EFX）的公平性。

**Method:** 1) 针对词典偏好，探讨了事前sd-EF与事后EFX的不兼容性，并提出了一种多项式时间算法，通过依赖舍入实现事后EFX和PO以及事前9/10-EF。2) 对于单调估值，研究了“带慈善的EFX”（EFX-with-charity），并证明其可以与事前0.5-EF同时实现。3) 对于次可加估值，将事后保证加强到“带有限慈善的EFX”（EFX-with-bounded-charity），同时将事前保证放宽到0.5-比例性。

**Result:** 1) 对于词典偏好，证明了事前随机支配无嫉妒（sd-EF）与事后无嫉妒任何物品（EFX）从根本上不兼容；提出了一种多项式时间算法，实现了事后EFX和PO，同时达到事前9/10-EF。2) 对于单调估值，证明了事后“带慈善的EFX”可以与事前0.5-EF同时实现。3) 对于次可加估值，实现了事后“带有限慈善的EFX”（最多n-1个物品未分配），同时达到事前0.5-比例性。

**Conclusion:** 论文探讨了在不同估值类型下，公平分配问题中实现更强的事后公平性（EFX变体）与事前保证的权衡和可实现性。它揭示了固有的不兼容性，并提出了在各种条件下实现“兼顾两全”保证的算法。

> **ai_Abstract:** 本文探讨了不可分割物品的公平分配问题，旨在在维持事前保证的同时实现更强的事后公平性（EFX）。研究表明，对于词典偏好，强大的事前和事后保证之间存在不兼容性，并提出了一种算法，实现了EFX、PO和9/10-EF。对于单调和次可加估值，论文探索了诸如“带慈善的EFX”和“带有限慈善的EFX”等放宽条件，并证明了它们在特定事前保证（分别为0.5-EF和0.5-比例性）下的可实现性。这项工作有助于理解在实现“兼顾两全”的公平性时的权衡。

> **摘要翻译:** 不可分割物品的公平分配是经济学和计算机科学交叉领域的一个基本问题。传统方法侧重于期望公平的随机分配或近似公平的确定性分配。最近的工作通过“兼顾两全”的保证调和了这两种方法，即寻求在期望上公平（事前公平）同时又基于近似公平分配（事后公平）的随机分配。先前的研究表明，在可加估值下，总是存在一种随机分配，它事前随机支配无嫉妒（sd-EF）且事后无嫉妒一物（EF1）。
我们的工作旨在实现更强的事后公平保证，例如无嫉妒任何物品（EFX），同时提供有意义的事前保证。我们做出了以下贡献：
1) 我们首先考虑词典偏好，这是可加估值的一个子域，其中事后EFX分配总是存在且可以高效计算。从负面来看，我们表明事前sd-EF与事后EFX从根本上不兼容，这促使我们放宽事前基准。然后，我们提出了一种多项式时间算法，实现了事后EFX和PO，同时达到事前9/10-EF。我们的算法使用依赖舍入并利用了EFX和PO分配的结构特性。
2) 对于单调估值，我们研究了“带慈善的EFX”：这是EFX的一种放宽，其中一些物品未分配，但没有任何代理人嫉妒未分配的物品池。我们证明事后“带慈善的EFX”可以与事前0.5-EF同时实现。
3) 最后，对于次可加估值，我们将先前的后保证加强到“带有限慈善的EFX”，其中最多n-1个物品（n=代理人数量）未分配，代价是将事前保证弱化到0.5-比例性。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [143] [Structural DID with ML: Theory, Simulation, and a Roadmap for Applied Research](https://arxiv.org/abs/2507.15899)
> *结构化双重差分法与机器学习结合：理论、模拟与应用研究路线图*

*Yile Yu, Anzhi Xu, Yi Wang* | **Category: stat.ML, cs.LG, 91-01** | **Updated: 2025-07-21**

**Keywords:** 双重差分法, 机器学习, 因果推断, 高维数据, 结构化识别

**Comment:** 45 pages, 29 figures

> **TL;DR:** 本文提出了S-DIDML框架，结合结构化识别与高维估计，解决传统双重差分法在高维混淆变量下的局限性，并弥补机器学习在因果结构解释上的不足，旨在提升观察性面板数据的因果推断能力。

**AI_Comments:** S-DIDML框架的创新之处在于其将传统因果推断方法（DID）与现代机器学习技术相结合，有效解决了高维数据下因果效应识别的挑战。它不仅保留了DID的结构化识别能力，还利用ML处理复杂混淆和异质性，提供了一个更鲁棒和可解释的因果推断工具。该框架通过Stata实现路径，增强了其在应用研究中的实用性和可复制性，对于社会科学领域的政策评估和资源优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统双重差分法（DID）在处理观察性面板数据中的高维混淆变量时面临挑战，而机器学习（ML）方法又缺乏因果结构的可解释性。为了解决这一核心矛盾，提升因果推断能力，本文提出了S-DIDML框架。

**Method:** 本文提出了S-DIDML框架，该框架将结构化识别与高维估计相结合。它在传统DID结构基础上，采用结构化残差正交化技术（Neyman正交性+交叉拟合）来保留组-时间处理效应（ATT）的识别结构，同时解决高维协变量干扰问题。此外，它设计了一个结合因果森林和半参数模型的动态异质性估计模块，以捕捉时空异质性效应。该框架还建立了完整的模块化应用流程，并提供了标准化的Stata实现路径。

**Result:** S-DIDML的引入丰富了DID和DDML创新的方法学研究，将因果推断从方法堆叠转向架构集成。该进展使社会科学能够精确识别政策敏感群体并优化资源配置。该框架为数字转型政策和环境法规等复杂干预情景提供了可复制的评估工具、决策优化参考和方法范式。

**Conclusion:** S-DIDML框架通过结合结构化识别和高维估计，有效解决了传统DID在高维数据中的局限性以及ML在因果解释上的不足，为社会科学提供了强大的工具，以精确识别政策影响、优化资源分配，并为复杂干预场景提供可复制的评估和决策支持。

> **ai_Abstract:** 本文针对传统双重差分法（DID）在高维混淆变量下的局限性以及机器学习（ML）缺乏因果结构可解释性的问题，提出了S-DIDML框架。该框架创新性地结合了结构化识别与高维估计，通过结构化残差正交化技术保留DID的因果识别结构，同时利用因果森林和半参数模型处理高维协变量和动态异质性。S-DIDML提供了标准化的Stata实现路径，旨在将因果推断从方法堆叠转向架构集成，从而帮助社会科学更精确地识别政策敏感群体、优化资源配置，并为复杂干预场景提供可复制的评估和决策工具。

> **摘要翻译:** 观察性面板数据中的因果推断已成为经济学、政策分析以及更广泛社会科学的核心关注点。为了解决传统双重差分法（DID）在处理观察性面板数据中高维混淆变量时的困难，以及机器学习（ML）缺乏因果结构可解释性的核心矛盾，本文提出了一个名为S-DIDML的创新框架，该框架将结构化识别与高维估计相结合。S-DIDML建立在传统DID方法的基础上，采用结构化残差正交化技术（Neyman正交性+交叉拟合），在保留组-时间处理效应（ATT）识别结构的同时，解决了高维协变量干扰问题。它设计了一个结合因果森林和半参数模型的动态异质性估计模块，以捕捉时空异质性效应。该框架建立了一个完整的模块化应用过程，并提供了标准化的Stata实现路径。S-DIDML的引入丰富了DID和DDML创新的方法学研究，将因果推断从方法堆叠转向架构集成。这一进步使社会科学能够精确识别政策敏感群体并优化资源配置。该框架为数字转型政策和环境法规等复杂干预情景提供了可复制的评估工具、决策优化参考和方法范式。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [213] [Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains](https://arxiv.org/abs/2507.15990)
> *用于学习有界域内随机动力系统流图的生成式AI模型*

*Minglei Yang, Yanfang Liu, Diego del-Castillo-Negrete, Yanzhao Cao, Guannan Zhang* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-17**

**Keywords:** 随机微分方程, 有界域, 生成式AI, 扩散模型, 粒子逸出

**Comment:** 

> **TL;DR:** 现有机器学习方法难以处理有界域内的随机微分方程（SDEs）中的粒子逸出问题。本文提出了一种混合数据驱动方法，结合条件扩散模型和逸出预测神经网络，以准确捕获内部动力学和边界逸出。

**AI_Comments:** 本文的创新之处在于将扩散模型与逸出预测神经网络相结合，专门解决了有界域中具有挑战性的粒子逸出现象，这是现有机器学习方法的一个关键局限。免训练扩散模型的使用也值得关注。其在聚变等离子体中的适用性突显了其潜在的实际影响。

<details>
  <summary>Details</summary>

**Motivation:** 在有界域中模拟随机微分方程（SDEs）由于粒子逸出现象而带来显著的计算挑战，这需要对内部随机动力学和边界相互作用进行精确建模。尽管基于机器学习的方法在学习SDEs方面取得了成功，但现有方法不适用于有界域中的SDEs，因为它们无法准确捕获粒子逸出动力学。

**Method:** 本文提出了一种统一的混合数据驱动方法，该方法结合了条件扩散模型和逸出预测神经网络。该机器学习模型包含两个主要组件：一个使用二元交叉熵损失学习逸出概率并具有严格收敛保证的神经网络，以及一个使用封闭形式分数函数为未逸出粒子生成状态转换的免训练扩散模型。这两个组件通过一种概率采样算法进行整合，该算法在每个时间步确定粒子逸出并生成适当的状态转换。

**Result:** 所提出方法的性能通过三个测试案例得到验证：一个用于理论验证的一维简化问题，一个有界域中的二维平流-扩散问题，以及一个与磁约束聚变等离子体相关的三维问题。

**Conclusion:** 本文提出了一种成功的统一混合数据驱动方法，通过准确捕获内部动力学和边界逸出现象，解决了在有界域中模拟随机微分方程的挑战。

> **ai_Abstract:** 本文提出了一种新颖的混合数据驱动方法，用于模拟有界域中的随机微分方程（SDEs），解决了现有机器学习方法在捕获粒子逸出动力学方面的局限性。所提出的模型整合了一个用于预测逸出概率的神经网络和一个用于非逸出粒子转换的免训练扩散模型，并在各种测试案例中展示了其有效性。

> **摘要翻译:** 在有界域中模拟随机微分方程（SDEs）由于粒子逸出现象而带来显著的计算挑战，这需要对内部随机动力学和边界相互作用进行精确建模。尽管基于机器学习的方法在学习SDEs方面取得了成功，但现有的学习方法不适用于有界域中的SDEs，因为它们无法准确捕获粒子逸出动力学。我们提出了一种统一的混合数据驱动方法，该方法结合了条件扩散模型和逸出预测神经网络，以捕获内部随机动力学和边界逸出现象。我们的机器学习模型由两个主要组件组成：一个使用二元交叉熵损失学习逸出概率并具有严格收敛保证的神经网络，以及一个使用封闭形式分数函数为未逸出粒子生成状态转换的免训练扩散模型。这两个组件通过一种概率采样算法进行整合，该算法在每个时间步确定粒子逸出并生成适当的状态转换。所提出方法的性能通过三个测试案例得到验证：一个用于理论验证的一维简化问题，一个有界域中的二维平流-扩散问题，以及一个与磁约束聚变等离子体相关的三维问题。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [268] [Structural Effect and Spectral Enhancement of High-Dimensional Regularized Linear Discriminant Analysis](https://arxiv.org/abs/2507.16682)
> *高维正则化线性判别分析的结构效应与谱增强*

*Yonghan Zhang, Zhangni Pu, Lu Yan, Jiang Hu* | **Category: stat.ML, cs.LG, math.ST, stat.ME, stat.TH** | **Updated: 2025-07-22**

**Keywords:** 正则化线性判别分析, 高维, 谱增强, 误分类率, 数据结构

**Comment:** 

> **TL;DR:** 本文针对正则化线性判别分析（RLDA）在高维场景下的性能不一致问题，通过推导误分类率的非渐近近似来分析数据结构的影响，并提出了谱增强判别分析（SEDA）算法，通过调整协方差矩阵的尖峰特征值来优化数据结构。实验证明SEDA比现有LDA方法具有更高的分类精度和降维效果。

**AI_Comments:** 该论文创新性地从数据结构角度分析了高维RLDA的性能问题，并通过引入谱增强概念提出了SEDA算法。其价值在于提供了理论分析（非渐近近似和渐近近似）和实际应用（SEDA算法），有效解决了RLDA在高维场景下的性能瓶颈，对分类和降维领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 正则化线性判别分析（RLDA）在高维场景下的性能不稳定，且现有理论分析缺乏对数据结构如何影响分类性能的清晰洞察。

**Method:** 本文推导了误分类率的非渐近近似，分析了RLDA的结构效应和结构调整策略。在此基础上，提出了谱增强判别分析（SEDA）算法，通过调整总体协方差矩阵的尖峰特征值来优化数据结构。通过发展随机矩阵理论中特征向量的新理论结果，推导了SEDA误分类率的渐近近似，并获得了偏差校正算法和参数选择策略。

**Result:** 在合成数据集和真实数据集上的实验表明，SEDA比现有LDA方法实现了更高的分类精度和降维效果。

**Conclusion:** 本文通过分析RLDA的结构效应，提出了SEDA算法，该算法通过优化数据结构显著提高了高维场景下的分类精度和降维效果。

> **ai_Abstract:** 本文针对高维正则化线性判别分析（RLDA）的性能不一致问题，通过理论推导分析了数据结构对分类性能的影响。在此基础上，提出了一种名为谱增强判别分析（SEDA）的新算法，该算法通过调整总体协方差矩阵的尖峰特征值来优化数据结构。实验结果表明，SEDA在分类精度和降维方面优于现有LDA方法。

> **摘要翻译:** 正则化线性判别分析（RLDA）是一种广泛用于分类和降维的工具，但其在高维场景下的性能不一致。RLDA现有的理论分析往往缺乏对数据结构如何影响分类性能的清晰洞察。为了解决这个问题，我们推导了误分类率的非渐近近似，从而分析了RLDA的结构效应和结构调整策略。在此基础上，我们提出了谱增强判别分析（SEDA）算法，该算法通过调整总体协方差矩阵的尖峰特征值来优化数据结构。通过发展随机矩阵理论中特征向量的新理论结果，我们推导了SEDA误分类率的渐近近似。然后获得了偏差校正算法和参数选择策略。在合成数据集和真实数据集上的实验表明，SEDA比现有LDA方法实现了更高的分类精度和降维效果。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [290] [The Joys of Categorical Conformal Prediction](https://arxiv.org/abs/2507.04441)
> *范畴共形预测的乐趣*

*Michele Caprio* | **Category: stat.ML, cs.AI, cs.LG, math.CT, Primary: 18D99, Secondary: 62G07, 28B20** | **Updated: 2025-07-22**

**Keywords:** 共形预测, 不确定性量化, 范畴论, 隐私保护, 预测区域

**Comment:** 

> **TL;DR:** 本文通过范畴论方法深入探讨共形预测（CP），揭示其固有的不确定性量化能力，并指出CP能整合贝叶斯、频率论和不精确概率方法，且其对隐私保护有益。

**AI_Comments:** 这篇论文的创新点在于首次将范畴论引入共形预测，从而从理论上揭示了CP固有的不确定性量化能力，并展示了其统一不同统计推理范式的潜力。其发现CPRs作为协变函子的像，对AI隐私保护提供了新的理论支持，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 共形预测（CP）作为一种不确定性量化（UQ）工具，其概念上的不透明性在于其预测区域（CPRs）只能提供不确定性的序数表示，而缺乏基数量化能力。

**Method:** 本文采用范畴论方法来研究共形预测，将其构建为两个新定义范畴的态射，并嵌入到交换图中。

**Result:** 1. 在最小假设下，共形预测本质上是一种不确定性量化机制，其基数UQ能力是该方法的结构特征。
2. 共形预测连接（并可能涵盖）了贝叶斯、频率论和不精确概率的预测统计推理方法。
3. 共形预测区域是协变函子的像。

**Conclusion:** 共形预测的范畴论视角揭示了其固有的不确定性量化能力，并展示了其在整合不同统计推理范式中的潜力，同时对AI隐私保护具有重要意义，即局部隐私噪声不会破坏全局覆盖保证。

> **ai_Abstract:** 本文通过范畴论方法深入剖析共形预测（CP），旨在解决其作为不确定性量化工具时基数量化能力不足的问题。研究将CP建模为新定义范畴间的态射，揭示了CP固有的不确定性量化能力，并证明其能统一贝叶斯、频率论和不精确概率的预测推理范式。此外，论文还指出CPRs作为协变函子像的特性，对AI隐私保护具有积极意义，即局部隐私噪声不影响全局覆盖保证。

> **摘要翻译:** 共形预测（CP）是一种不确定性表示技术，它能为任何底层机器学习模型提供有限样本校准的预测区域。然而，其作为一种不确定性量化（UQ）工具的地位在概念上仍然不透明：尽管共形预测区域（CPRs）提供了不确定性的序数表示（较大的区域通常表示较高的不确定性），但它们缺乏对其进行基数量化的能力（两倍大的区域并不意味着两倍的不确定性）。我们对CP采用了一种范畴论方法——将其构建为两个新定义范畴的态射，并嵌入到交换图中——这带来了三个乐趣。首先，我们表明——在最小假设下——CP本质上是一种UQ机制，也就是说，其基数UQ能力是该方法的结构特征。其次，我们证明了CP桥接（并可能涵盖）了贝叶斯、频率论和不精确概率的预测统计推理方法。最后，我们表明CPRs是协变函子的像。这一观察与AI隐私相关：它意味着局部添加的隐私噪声不会破坏全局覆盖保证。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [323] [Estimating Treatment Effects with Independent Component Analysis](https://arxiv.org/abs/2507.16467)
> *使用独立成分分析估计治疗效果*

*Patrik Reizinger, Lester Mackey, Wieland Brendel, Rahul Krishnan* | **Category: stat.ML, cs.AI, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 因果推断, 独立成分分析, 治疗效果, 部分线性回归, 非高斯性

**Comment:** 

> **TL;DR:** 本文首次理论和实证地展示了独立成分分析（ICA）可用于在部分线性回归（PLR）模型中估计因果效应，并且线性ICA即使在存在高斯混杂因素或非线性干扰的情况下也能准确估计多重治疗效果。

**AI_Comments:** 本文的创新之处在于首次将独立成分分析（ICA）引入因果效应估计领域，尤其是在部分线性回归（PLR）模型中。它揭示了两个看似独立的领域之间的深层联系，并利用ICA对非高斯性的敏感性来处理复杂的因果推断问题。其重要性在于提供了一种在存在高斯混杂因素或非线性干扰时也能有效估计多重治疗效果的新方法，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 因果推断和可识别性理论（如ICA）这两个独立发展的研究领域，尽管目标相似（准确且样本高效地估计模型参数），但其潜在联系尚未被充分探索。特别是在部分线性回归（PLR）设置中，非高斯性噪声对估计一致性的改善与ICA识别潜在因素的关键假设存在共通之处，这促使作者探究ICA在因果效应估计中的应用。

**Method:** 本文通过理论分析和实证研究，首次探究了独立成分分析（ICA）与因果效应估计之间的联系。研究重点在于展示ICA如何应用于部分线性回归（PLR）模型中进行因果效应估计。

**Result:** 研究发现，独立成分分析（ICA）可以用于部分线性回归（PLR）模型中的因果效应估计。令人惊讶的是，线性ICA即使在存在高斯混杂因素或非线性干扰的情况下，也能准确估计多个治疗效果。

**Conclusion:** 独立成分分析（ICA）是一种有效且鲁棒的方法，可用于在部分线性回归（PLR）模型中估计因果效应，即使面对复杂的噪声和混杂因素。

> **ai_Abstract:** 本文首次深入探讨了因果推断与独立成分分析（ICA）之间的联系。研究发现，尽管两个领域独立发展，但其目标相似。文章进一步展示了ICA，特别是在非高斯性假设下，如何应用于部分线性回归（PLR）模型中进行因果效应估计。研究结果表明，线性ICA即使在存在高斯混杂因素或非线性干扰的情况下，也能准确估计多个治疗效果，为因果效应估计提供了一种新颖且鲁棒的方法。

> **摘要翻译:** 因果推断领域已经开发出多种方法，用于在存在干扰的情况下准确估计治疗效果。同时，可识别性理论领域也开发了独立成分分析（ICA）等方法，用于从数据中识别潜在源和混合权重。尽管这两个研究社区在很大程度上独立发展，但它们的目标相似：准确且样本高效地估计模型参数。在部分线性回归（PLR）设置中，Mackey 等人（2018）最近发现，非高斯治疗噪声可以改善估计的一致性。非高斯性也是ICA中识别潜在因素的关键假设。我们首次提供了对这种联系的理论和实证见解，表明ICA可用于PLR模型中的因果效应估计。令人惊讶的是，我们发现线性ICA即使在存在高斯混杂因素或非线性干扰的情况下，也能准确估计多个治疗效果。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [497] [PAC Off-Policy Prediction of Contextual Bandits](https://arxiv.org/abs/2507.16236)
> *上下文强盗的PAC离策略预测*

*Yilong Wan, Yuqiang Li, Xianyi Wu* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 离策略评估, 上下文强盗, 共形预测, PAC, 预测区间

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于PAC有效共形预测的算法，用于上下文强盗中的离策略评估，旨在构建具有PAC型覆盖边界的可靠预测区间。

**AI_Comments:** 该论文的创新之处在于将共形预测与PAC型界限相结合，为离策略评估提供了更强的理论保证，尤其是在条件覆盖方面。这对于需要可靠性能量化的安全关键型应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在利用在不同且可能未知的行为策略下收集的数据来量化目标策略的性能，特别适用于安全关键型应用，因为这些应用需要可靠的预测区间。

**Method:** 提出了一种新颖的算法来构建可能近似正确的（PAC）预测区间。该方法建立在PAC有效的共形预测框架之上，并通过建立覆盖率的PAC型界限来加强其理论保证。

**Result:** 分析了所提出方法的有限样本和渐近特性，并在模拟中将其经验性能与现有方法进行了比较。

**Conclusion:** 通过建立PAC型覆盖界限，该方法加强了离策略评估的理论保证，为上下文强盗问题提供了更可靠的性能量化。

> **ai_Abstract:** 本文探讨了上下文强盗中的离策略评估问题，目标是利用离线数据量化目标策略的性能。论文提出了一种新颖的算法，用于构建基于PAC有效共形预测框架的PAC预测区间，并通过建立PAC型覆盖边界来强化其理论保证。该方法分析了有限样本和渐近特性，并在模拟中展示了与现有方法相比具有竞争力的经验性能。

> **摘要翻译:** 本文研究了上下文强盗（contextual bandits）中的离策略评估（off-policy evaluation），旨在利用在不同且可能未知的行为策略下收集的数据来量化目标策略的性能。最近，基于共形预测（conformal prediction）的方法已被开发出来，用于构建可靠的预测区间，这些区间在有限样本中保证边际覆盖，使其特别适用于安全关键型应用。为了进一步实现给定离线数据集的条件覆盖，我们提出了一种新颖的算法，该算法构建了可能近似正确的（PAC）预测区间。我们的方法建立在PAC有效的共形预测框架之上，并且我们通过建立覆盖率的PAC型界限来加强其理论保证。我们分析了所提出方法的有限样本和渐近特性，并在模拟中将其经验性能与现有方法进行了比较。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [585] [Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests](https://arxiv.org/abs/2402.12668)
> *随机化可以同时减少偏差和方差：随机森林的案例研究*

*Brian Liu, Rahul Mazumder* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 随机森林, 偏差-方差权衡, Bagging, 随机化, 信噪比

**Comment:** 

> **TL;DR:** 本文研究了随机森林如何通过随机化在减少方差的同时也减少偏差，尤其是在高信噪比（SNR）设置下，并解释了其在实际应用中的成功。

**AI_Comments:** 本文深入探讨了随机森林的一个核心优势——即它不仅能降低方差，还能降低偏差，这在以往的研究中常被忽视。通过实证分析，它为随机森林在高信噪比设置下的优越性提供了新的解释，并强调了随机化在模型性能中的关键作用。此外，它还提供了mtry参数调优的实践指导，对随机森林的理论理解和实际应用都具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文研究了随机森林相比于Bagging能够降低偏差的现象，并受到一篇解释随机森林在低信噪比环境下成功表现的论文启发，旨在探索随机森林如何捕获Bagging集成模型未能捕获的数据模式。

**Method:** 通过实证研究（empirically demonstrate）。

**Result:** 在存在特定数据模式的情况下，随机森林在减少方差的同时也降低了偏差，并且在高信噪比（SNR）下，其性能越来越优于Bagging集成模型。研究还提供了关于随机森林中mtry参数调优重要性的实践见解。

**Conclusion:** 随机森林在不同信噪比范围内都能取得成功，这得益于其同时减少偏差和方差的能力。研究加深了对随机森林与Bagging集成之间差异的理解，并强调了mtry参数调优的重要性。

> **ai_Abstract:** 本文研究了随机森林在减少方差的同时如何通过随机化减少偏差的现象，这与Bagging不同。研究受到先前工作的启发，通过实证分析证明，在特定数据模式下，随机森林能捕获Bagging未能捕获的模式，从而在高信噪比环境下表现出更优的性能，同时降低了偏差和方差。这些发现有助于解释随机森林在实际应用中的成功，并强调了mtry参数调优的重要性。

> **摘要翻译:** 我们研究了
\cite{breiman2001random}首次指出的、经常被忽视的现象，即随机森林似乎比Bagging更能减少偏差。受到
\cite{mentch2020randomization}一篇有趣论文的启发，该论文通过正则化解释了随机森林在低信噪比（SNR）设置下的成功，我们探讨了随机森林如何捕获Bagging集成模型未能捕获的数据模式。我们通过实证证明，在存在此类模式的情况下，随机森林在减少方差的同时也降低了偏差，并且当信噪比较高时，其性能可以越来越优于Bagging集成模型。我们的观察为随机森林在各种信噪比下的实际成功提供了见解，并增强了我们对随机森林和Bagging集成之间差异的理解。我们的研究还提供了关于随机森林中mtry参数调优重要性的实践见解。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [612] [Risk and cross validation in ridge regression with correlated samples](https://arxiv.org/abs/2408.04607)
> *具有相关样本的岭回归中的风险和交叉验证*

*Alexander Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan* | **Category: stat.ML, cond-mat.dis-nn, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 岭回归, 交叉验证, 相关样本, 随机矩阵理论, CorrGCV

**Comment:** 44 pages, 19 figures. v4: ICML 2025 camera-ready. v5: Fix typo in
  statement of Theorem 5

> **TL;DR:** 本文利用随机矩阵理论和自由概率，首次系统研究了数据点具有任意相关性时高维岭回归的风险和交叉验证问题，并提出了改进的交叉验证方法CorrGCV。

**AI_Comments:** 这篇论文的创新之处在于它填补了高维岭回归理论在处理相关数据方面的空白，为理解和解决实际中普遍存在的相关性问题提供了重要理论基础。提出的CorrGCV方法具有很强的实用价值，尤其是在时间序列等领域。其结合随机矩阵理论和自由概率的严谨分析方法，为复杂统计模型的理论研究树立了典范。

<details>
  <summary>Details</summary>

**Motivation:** 现有高维岭回归理论假设训练样本是独立的，但实际数据通常存在相关性。因此，需要深入理解数据点具有任意相关性时岭回归的风险行为及其交叉验证的有效性。

**Method:** 本文利用随机矩阵理论和自由概率的技术，推导了数据点具有任意相关性时岭回归的样本内和样本外风险的精确渐近结果。在此基础上，提出了改进的广义交叉验证（GCV）估计器CorrGCV，并在测试点与训练集存在非平凡相关性的情况下进一步扩展了渐近分析。

**Result:** 研究表明，在数据点具有任意相关性时，标准的广义交叉验证（GCV）估计器无法正确预测样本外风险。然而，当噪声残差与数据点具有相同的相关性时，可以修改GCV得到一个高效可计算的无偏估计器，即CorrGCV。此外，对于测试点与训练集存在相关性的情况（如时间序列预测），假设已知时间序列的相关结构，本文提供了GCV估计器的扩展，并精确刻画了此类测试点对长期风险的过度乐观预测程度。理论预测在多种高维数据上得到了验证。

**Conclusion:** 本文为具有相关样本的高维岭回归提供了深入的理论分析，揭示了标准交叉验证方法的局限性，并提出了有效的改进方案（CorrGCV及其扩展），为处理实际中普遍存在的相关数据提供了严谨的理论支持和实用工具。

> **ai_Abstract:** 本文通过随机矩阵理论和自由概率，深入分析了数据点存在任意相关性时高维岭回归的风险特性。研究发现，在这种情况下，标准的广义交叉验证（GCV）无法准确预测样本外风险。为此，作者提出了一种改进的无偏估计器CorrGCV，适用于噪声残差与数据具有相同相关性的情况。此外，论文还将分析扩展到测试点与训练集相关的情景，并提供了相应的GCV扩展，解决了时间序列预测中乐观风险预测的问题。

> **摘要翻译:** 近年来，我们对高维岭回归的理解取得了实质性进展，但现有理论假设训练样本是独立的。通过利用随机矩阵理论和自由概率的技术，我们为数据点具有任意相关性时岭回归的样本内和样本外风险提供了精确的渐近结果。我们证明在这种情况下，广义交叉验证（GCV）估计器无法正确预测样本外风险。然而，在噪声残差与数据点具有相同相关性的情况下，可以修改GCV以产生一个高效可计算的无偏估计器，该估计器在高维极限下是集中的，我们称之为CorrGCV。我们进一步将渐近分析扩展到测试点与训练集存在非平凡相关性的情况，这在时间序列预测中经常遇到。假设已知时间序列的相关结构，这再次产生了GCV估计器的扩展，并精确刻画了此类测试点对长期风险的过度乐观预测程度。我们在各种高维数据中验证了我们理论的预测。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [646] [Spectral Algorithms under Covariate Shift](https://arxiv.org/abs/2504.12625)
> *协变量偏移下的谱算法*

*Jun Fan, Zheng-Chu Guo, Lei Shi* | **Category: stat.ML, cs.LG, 68Q32, 68T05, 62J02** | **Updated: 2025-07-22**

**Keywords:** 谱算法, 协变量偏移, 收敛速率, 密度比, 权重裁剪

**Comment:** 

> **TL;DR:** 本文研究了协变量偏移下谱算法的收敛性，发现其在密度比有界时达到最优，但在无界时表现不佳。为解决此问题，提出了一种带归一化权重和权重裁剪的加权谱算法，实现了接近最优的收敛速率。

**AI_Comments:** 本文创新性地研究了谱算法在协变量偏移这一复杂真实场景下的性能，并针对密度比无界导致的次优性问题，提出了实用的加权和权重裁剪技术。理论分析严谨，不仅揭示了算法的潜在局限，也提供了有效的解决方案，对理解和改进实际应用中的机器学习模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了深入理解谱算法在训练和测试数据分布可能不同的真实场景中的性能，本文对协变量偏移下谱算法的收敛行为进行了严格研究。

**Method:** 在再生核希尔伯特空间上的非参数回归框架内，分析了协变量偏移下谱算法的收敛速率。为解决无界密度比情况下的次优性问题，提出了一种新颖的带归一化权重的加权谱算法，并将密度比信息纳入学习过程。此外，还引入了权重裁剪技术。

**Result:** 当训练和测试分布之间的密度比一致有界时，谱算法实现了极小极大最优性。然而，当这些密度比无界时，谱算法可能变得次优。所提出的归一化加权方法实现了最优的容量无关收敛速率，但速率会受到饱和现象的影响。通过引入权重裁剪技术，加权谱算法的收敛速率可以任意接近最优的容量相关收敛速率。

**Conclusion:** 这项改进解决了无界密度比情况下的次优性问题，并通过完善现有理论结果，提升了当前的技术水平。

> **ai_Abstract:** 本文深入探讨了在协变量偏移（即训练和测试数据输入边际分布不同）下谱算法的收敛行为。研究发现，当密度比有界时，谱算法能达到极小极大最优性；但当密度比无界时，其性能会次优。为克服这一局限，论文提出了一种新的带归一化权重的加权谱算法，并通过引入权重裁剪技术，显著提升了算法在无界密度比情况下的收敛性能，使其能够接近最优的容量相关收敛速率，从而解决了次优性问题并完善了现有理论。

> **摘要翻译:** 谱算法利用谱正则化技术分析和处理数据，为解决监督学习问题提供了一个灵活的框架。为了深化我们对其在训练和测试数据分布可能不同的真实场景中性能的理解，我们对协变量偏移下谱算法的收敛行为进行了严格研究。在这种设置下，输入数据的边际分布在训练和测试数据集之间不同，而给定输入的输出条件分布保持不变。在再生核希尔伯特空间上的非参数回归框架内，我们分析了协变量偏移下谱算法的收敛速率，并表明当训练和测试分布之间的密度比一致有界时，它们达到了极小极大最优性。然而，当这些密度比无界时，谱算法可能变得次优。为了解决这个问题，我们提出了一种新颖的带归一化权重的加权谱算法，该算法将密度比信息纳入学习过程。我们的理论分析表明，这种归一化加权方法实现了最优的容量无关收敛速率，但速率会受到饱和现象的影响。此外，通过引入权重裁剪技术，我们证明了带裁剪权重的加权谱算法的收敛速率可以任意接近最优的容量相关收敛速率。这项改进解决了无界密度比情况下的次优性问题，并通过完善现有理论结果，提升了当前的技术水平。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [155] [An unconditional lower bound for the active-set method in convex quadratic maximization](https://arxiv.org/abs/2507.16648)
> *凸二次最大化中主动集方法的无条件下界*

*Eleon Bach, Yann Disser, Sophie Huiberts, Nils Mosis* | **Category: cs.DM, cs.CC, cs.DS, math.CO** | **Updated: 2025-07-22**

**Keywords:** 主动集方法, 下界, 凸二次最大化, 指数迭代, 枢轴规则

**Comment:** 

> **TL;DR:** 证明了主动集方法在凸二次最大化问题中需要指数级迭代次数，解决了常数次数目标函数是否足够的开放问题。

**AI_Comments:** 这项工作具有重要意义，因为它通过一个常数（二次）度数目标函数，为主动集方法提供了一个无条件的指数级下界，解决了该领域的一个长期存在的开放问题。其创新之处在于构建了一个巧妙的扩展形式和相应的目标函数，迫使算法遍历指数级的路径。这对于理解主动集方法（以及与之相关的单纯形法）的理论最坏情况性能具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于主动集方法的下界需要高阶多项式目标函数，本研究旨在改进这一结果，证明对于二次凸多项式也存在指数下界，并解决了一个关于常数次数目标函数是否足以证明此下界的开放问题。

**Method:** 通过构建一种新颖的扩展形式（使用变形乘积递归构建），该形式将问题投影到一个抛物线的多边形近似上，同时保留了指数级的顶点。然后定义一个特定的二次目标函数，迫使主动集方法沿着抛物线边界而非捷径进行迭代。

**Result:** 证明了在最坏情况下，主动集方法在解决线性约束下的凸二次函数最大化问题时，无论采用何种枢轴规则，都需要指数级的迭代次数。这改进了现有结果，仅使用二次凸多项式就达到了这一界限。

**Conclusion:** 本研究通过证明主动集方法在凸二次最大化中存在无条件指数下界，彻底解决了常数次数目标函数是否足以证明该下界的问题，并为线性目标函数下的类似突破奠定了基础。

> **ai_Abstract:** 本文证明了在最坏情况下，主动集方法在求解线性约束下的凸二次最大化问题时，需要指数级的迭代次数，且与枢轴规则无关。这一发现通过使用二次凸多项式目标函数，显著改进了现有结果，并解决了关于常数次数目标函数是否足以证明此下界的开放问题。研究方法基于构建一种新颖的扩展形式和设计一个特定的二次目标函数来强制最坏情况路径。

> **摘要翻译:** 我们证明了在最坏情况下，主动集方法在受线性约束的凸二次函数最大化问题中需要指数级的迭代次数，无论使用何种枢轴规则。这大大改进了之前已知的最佳下界 [IPCO 2025]，后者需要在维度 $d$ 中使用多项式次数为 $\omega(\log d)$ 的目标函数，而本研究将下界推广到使用二次凸多项式。特别是，我们的结果明确解决了 [IPCO 2025] 中关于常数次数是否足够的开放问题，并且代表了向线性目标函数迈出的重要一步，在后一种情况下，主动集方法与单纯形法一致，而所有枢轴规则的下界将构成重大突破。
我们的结果基于一种新颖的扩展形式，该形式使用变形乘积递归构建。其关键特征是它投影到一个抛物线的多边形近似上，同时保留了其指数级的顶点。我们定义了一个二次目标函数，强制主动集方法遵循此投影的抛物线边界，而不允许沿其全维度原像的边对应的弦进行任何捷径。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [174] [Alternative Loss Function in Evaluation of Transformer Models](https://arxiv.org/abs/2507.16548)
> *评估Transformer模型中的替代损失函数*

*Jakub Michańków, Paweł Sakowski, Robert Ślepaczuk* | **Category: q-fin.CP, cs.LG, q-fin.TR** | **Updated: 2025-07-22**

**Keywords:** 损失函数, Transformer模型, LSTM模型, 量化金融, 平均绝对方向损失 (MADL) 

**Comment:** 12 pages

> **TL;DR:** 本研究引入了一种新的损失函数MADL，用于优化金融预测模型，并发现Transformer模型在使用MADL时表现优于LSTM。

**AI_Comments:** 本文的创新点在于提出了专为量化金融预测优化的MADL损失函数，并实证比较了Transformer和LSTM模型在该函数下的表现。其重要性在于为金融领域的预测模型提供了新的优化工具，并再次确认了Transformer模型在特定任务上的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习模型（特别是应用于量化金融问题时）的测试设计和架构中，选择一个合适的损失函数对于训练、验证、估计和超参数调优至关重要。

**Method:** 通过在股票和加密货币资产上的实证实验，引入了平均绝对方向损失（MADL）函数，该函数更适用于优化用于算法投资策略的预测生成模型。将MADL函数在Transformer和LSTM模型上的结果进行了比较。

**Result:** 在几乎所有情况下，Transformer模型的结果都显著优于使用LSTM模型获得的结果。

**Conclusion:** 引入的MADL函数能够有效地优化金融预测模型，并且Transformer模型在使用该损失函数时表现出优越性。

> **ai_Abstract:** 本文强调了在量化金融中选择合适损失函数的重要性。研究引入了一种新的损失函数——平均绝对方向损失（MADL），并通过在股票和加密货币上的实证实验证明其适用于优化预测模型。结果表明，在使用MADL时，Transformer模型在预测性能上显著优于LSTM模型。

> **摘要翻译:** 机器学习模型，尤其是在其应用于量化金融问题时，其测试的正确设计和架构至关重要。在此过程中最重要的是选择一个用于训练、验证、估计和超参数调优的足够损失函数。因此，在本研究中，通过对股票和加密货币资产的实证实验，我们引入了平均绝对方向损失（MADL）函数，该函数更适用于优化用于算法投资策略的预测生成模型。MADL函数的结果在Transformer和LSTM模型之间进行了比较，我们发现几乎在所有情况下，Transformer模型的结果都显著优于LSTM模型。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

<a id='physicsao-ph'></a>
## physics.ao-ph 

### [183] [Bayesian Deep Learning for Convective Initiation Nowcasting Uncertainty Estimation](https://arxiv.org/abs/2507.16219)
> *贝叶斯深度学习在对流起始临近预报不确定性估计中的应用*

*Da Fan, David John Gagne II, Steven J. Greybush, Eugene E. Clothiaux, John S. Schreck, Chaopeng Shen* | **Category: physics.ao-ph, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 贝叶斯深度学习, 对流起始, 临近预报, 不确定性估计, ResNet

**Comment:** 

> **TL;DR:** 本研究评估了五种贝叶斯深度学习方法在对流起始临近预报中对不确定性估计的性能，发现多数贝叶斯方法优于确定性模型，其中初始权重集成+MC dropout表现最佳，但泛化能力有限。

**AI_Comments:** 这篇论文创新性地将贝叶斯深度学习应用于对流起始临近预报，并详细比较了不同贝叶斯方法的性能。其重要性在于能够提供不确定性估计，这对于决策制定至关重要。论文发现初始权重集成+MC dropout在性能上表现突出，但同时也指出了其在某些场景下泛化能力不足的局限性，为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 评估和比较不同贝叶斯深度学习方法在对流起始临近预报中提供概率和不确定性估计的能力，并与确定性基线模型进行对比。

**Method:** 本研究使用GOES-16卫星红外观测数据，评估了五种贝叶斯深度学习方法（包括初始权重集成+MC dropout、贝叶斯ResNet集成、贝叶斯-MOPED ResNet集成等）相对于确定性残差神经网络（ResNet）基线在0-1小时对流起始（CI）临近预报中的性能。通过概率预报的校准度以及不确定性区分大误差和小误差预报的能力来评估不确定性。

**Result:** 大多数贝叶斯深度学习方法生成的概率预报优于确定性ResNet。初始权重集成+MC dropout方法产生了最熟练和校准良好的预报，因为它生成了多个解决方案，更彻底地采样了假设空间。贝叶斯ResNet集成在较长预报时效上表现不如确定性ResNet，可能是由于参数优化挑战。贝叶斯-MOPED ResNet集成通过约束假设搜索，提高了预报技能。所有贝叶斯方法都表现出良好的不确定性校准，并有效地区分了大小误差的案例。案例研究显示，初始权重集成+MC dropout在晴空区域的CI事件上优于贝叶斯-MOPED集成和确定性ResNet。但初始权重集成+MC dropout在无CI发生的晴空和砧状云区域的泛化能力不如确定性ResNet和贝叶斯-MOPED集成。

**Conclusion:** 贝叶斯深度学习方法在对流起始临近预报中能够提供优于确定性模型的概率预报和不确定性估计，其中初始权重集成+MC dropout表现突出，但其泛化能力在某些特定无CI场景下仍有待提高。

> **ai_Abstract:** 本研究评估了五种贝叶斯深度学习方法在0-1小时对流起始临近预报中对不确定性估计的性能，并与确定性ResNet基线进行比较。结果表明，多数贝叶斯方法生成的概率预报优于确定性模型，尤其初始权重集成+MC dropout表现最佳，提供了最熟练和校准良好的预报。尽管所有贝叶斯方法都能有效校准不确定性并区分误差，但初始权重集成+MC dropout在无对流起始发生的特定区域泛化能力较弱。贝叶斯-MOPED ResNet集成则通过限制假设空间提升了性能。

> **摘要翻译:** 这项研究评估了五种最近提出的贝叶斯深度学习方法相对于确定性残差神经网络（ResNet）基线，在使用GOES-16卫星红外观测数据进行0-1小时对流起始（CI）临近预报时，其概率和不确定性预报的性能。不确定性通过概率预报的校准程度以及不确定性区分大误差和小误差预报的能力来评估。大多数贝叶斯深度学习方法产生的概率预报优于确定性ResNet，其中一种方法——初始权重集成+蒙特卡洛（MC）dropout（一个由不同初始权重开始训练并在推理过程中激活dropout的确定性ResNet集成）产生了最熟练且校准良好的预报。初始权重集成+MC dropout受益于生成多个解决方案，更彻底地采样了假设空间。贝叶斯ResNet集成是唯一在较长预报时效上表现不如确定性ResNet的方法，这可能是由于优化大量参数的挑战。为了解决这个问题，采用了贝叶斯-MOPED（基于深度神经网络的经验贝叶斯模型先验）ResNet集成，它通过将假设搜索限制在确定性ResNet假设附近来增强预报技能。所有贝叶斯方法都表现出良好的不确定性校准，并有效地区分了大误差和小误差的案例。在案例研究中，初始权重集成+MC dropout在晴空区域的选定CI事件上表现出比贝叶斯-MOPED集成和确定性ResNet更好的预报技能。然而，与确定性ResNet和贝叶斯-MOPED集成相比，初始权重集成+MC dropout在没有CI发生的晴空和砧状云区域表现出较差的泛化能力。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsplasm-ph'></a>
## physics.plasm-ph 

### [188] [Efficient dataset construction using active learning and uncertainty-aware neural networks for plasma turbulent transport surrogate models](https://arxiv.org/abs/2507.15976)
> *使用主动学习和不确定性感知神经网络构建高效数据集用于等离子体湍流输运代理模型*

*Aaron Ho, Lorenzo Zanisi, Bram de Leeuw, Vincent Galvan, Pablo Rodriguez-Fernandez, Nathaniel T. Howard* | **Category: physics.plasm-ph, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 主动学习, 不确定性感知神经网络, 等离子体湍流输运, 代理模型, 数据集构建

**Comment:** 

> **TL;DR:** 本研究展示了一种结合不确定性感知神经网络、主动学习和物理模拟代码来高效构建数据集的方法，用于等离子体湍流输运代理模型的生成，并在小数据集上取得了良好的分类和回归性能。

**AI_Comments:** 该论文的关键创新在于将不确定性感知神经网络与主动学习结合，并应用于构建等离子体湍流输运代理模型的数据集。这种方法有望显著减少昂贵物理模拟所需的数据量，从而加速科学发现。虽然文中提到改进率衰减快于预期，但其通用性和模块化设计使其具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 为了高效地为数据驱动的代理模型构建数据集，特别是针对等离子体湍流输运问题中昂贵的物理模拟代码，本研究旨在探索结合不确定性感知架构和主动学习技术来减少所需训练数据量。

**Method:** 本研究采用了一种结合不确定性感知架构（SNGP用于分类，BNN-NCP用于回归）和主动学习技术的方法。它使用QuaLiKiz准线性静电回旋动理学湍流输运代码作为数据标注器，通过45次主动学习迭代，将初始训练集从$10^2$扩展到$10^4$个样本，训练了等离子体湍流输运模型。

**Result:** 经过45次主动学习迭代，模型在独立测试集上对所有输出的F1分类性能达到约0.8，R2回归性能达到约0.75。这表明该方法在处理多一个输入维度的问题时，能够达到与之前ADEPT流程相同的性能和效率。

**Conclusion:** 尽管当前实现的改进率衰减速度快于预期，但该整体技术及其组件具有可升级性和通用性，能够应用于等离子体湍流输运预测之外的许多代理建模应用。

> **ai_Abstract:** 本研究提出并验证了一种利用不确定性感知神经网络与主动学习相结合的方法，并通过物理模拟代码作为数据标注器，高效构建等离子体湍流输运代理模型所需的数据集。该方法成功应用于QuaLiKiz代码，即使在小数据集上也能为所有湍流模式和输运通量提供良好的分类和回归性能，验证了其在构建高效训练集方面的潜力，尤其对于替代昂贵模拟代码的应用。

> **摘要翻译:** 这项工作展示了结合不确定性感知架构、主动学习技术和作为数据标注器的循环物理模拟代码，来构建用于数据驱动代理模型生成的高效数据集的原理验证。基于之前成功在静态预标注数据集上使用ADEPT框架展示训练集缩减的原理验证，该策略再次应用于托卡马克聚变等离子体中的等离子体湍流输运问题，特别是QuaLiKiz准线性静电回旋动理学湍流输运代码。尽管QuaLiKiz提供了相对快速的评估，但本研究专门针对小数据集，以作为更昂贵代码（如CGYRO或GENE）的替代。新实现的算法使用SNGP架构用于问题的分类部分，BNN-NCP架构用于回归部分，为所有湍流模式（ITG、TEM、ETG）和所有由通用QuaLiKiz输出描述的输运通量（$Q_e$、$Q_i$、$\Gamma_e$、$\Gamma_i$和$\Pi_i$）训练模型。通过45次主动学习迭代，从$10^2$个小型初始训练集扩展到$10^4$个最终集合，所得模型在独立测试集上对所有输出的F1分类性能达到约0.8，R2回归性能达到约0.75。这可以推断出，即使在一个多一个输入维度的问题上，也能达到与之前ADEPT流程相同的性能和效率。尽管此实现中实现的改进率衰减速度快于预期，但该整体技术由可升级和可推广到等离子体湍流输运预测之外的许多代理建模应用的组件构成。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

---

### [208] [Predictive Hydrodynamic Simulations for Laser Direct-drive Implosion Experiments via Artificial Intelligence](https://arxiv.org/abs/2507.16227)
> *基于人工智能的激光直接驱动内爆实验预测性流体动力学模拟*

*Zixu Wang, Yuhan Wang, Junfei Ma, Fuyuan Wu, Junchi Yan, Xiaohui Yuan, Zhe Zhang, Jie Zhang* | **Category: physics.plasm-ph, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 激光直接驱动, 内爆, 人工智能, 流体动力学模拟, 深度学习

**Comment:** 7 pages, 7 figures

> **TL;DR:** 本研究提出了一种由人工智能驱动的预测性流体动力学模拟框架，用于激光直接驱动内爆实验，通过Transformer模型和物理信息解码器显著提高了复杂激光聚变实验的预测能力。

**AI_Comments:** 本研究的创新点在于将基于Transformer的深度学习模型（MULTI-Net）与新颖的物理信息解码器（PID）相结合，显著提升了复杂激光聚变实验流体动力学模拟的准确性和效率。利用AI进行预测性模拟在推进聚变能研究方面具有重要意义，有望减少对大量物理实验的需求。PID在降低预测误差方面的表现是其关键贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过数据驱动的人工智能框架，增强复杂激光聚变实验模拟的预测能力。

**Method:** 建立了一个基于Transformer的深度学习模型MULTI-Net，用于根据激光波形和靶丸半径预测内爆特征。提出了一个物理信息解码器（PID）用于高维采样，以显著降低预测误差。该方法应用于SG-II升级装置上的双锥点火（DCI）实验。

**Result:** MULTI-Net模型能够预测由X射线条纹相机测量的内爆动力学。发现约65%的有效激光吸收因子适用于DCI-R10实验的一维模拟。对于第33次发射，平均内爆速度达到195公里/秒，碰撞等离子体密度达到117克/立方厘米。

**Conclusion:** 本研究展示了一个数据驱动的AI框架，该框架增强了复杂激光聚变实验模拟的预测能力。

> **ai_Abstract:** 本文介绍了一个由人工智能驱动的预测性流体动力学模拟框架，用于激光直接驱动内爆实验，并以双锥点火（DCI）方案为例。研究建立了一个基于Transformer的深度学习模型MULTI-Net，用于根据激光波形和靶丸半径预测内爆特征。此外，提出了一种新的物理信息解码器（PID），用于高维采样，相比传统方法显著降低了预测误差。该模型成功应用于SG-II升级装置上的DCI实验，能够准确预测内爆动力学，并确定了适用于一维模拟的有效激光吸收因子，还给出了具体实验的内爆参数。这项工作验证了一个数据驱动的AI框架在提升复杂激光聚变实验模拟预测能力方面的有效性。

> **摘要翻译:** 这项工作提出了由人工智能 (AI) 驱动的激光内爆实验预测性流体动力学模拟，以双锥点火 (DCI) 方案为例。建立了一个基于 Transformer 的深度学习模型 MULTI-Net，用于根据激光波形和靶丸半径预测内爆特征。提出了一种物理信息解码器 (PID) 用于高维采样，与拉丁超立方采样相比，显著降低了预测误差。应用于在 SG-II 升级装置上进行的 DCI 实验，MULTI-Net 模型能够预测由 X 射线条纹相机测量的内爆动力学。发现约 65% 的有效激光吸收因子适用于 DCI-R10 实验的一维模拟。对于第 33 次发射，平均内爆速度和碰撞等离子体密度分别达到 195 公里/秒和 117 克/立方厘米。这项研究展示了一个数据驱动的 AI 框架，该框架增强了复杂激光聚变实验模拟的预测能力。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [212] [Linear codes arising from the point-hyperplane geometry -- Part II: the twisted embedding](https://arxiv.org/abs/2507.16694)
> *由点-超平面几何产生的线性码 -- 第二部分：扭曲嵌入*

*Ilaria Cardinali, Luca Giuzzi* | **Category: math.CO, cs.IT, math.IT, 51E22, 94B05, 14M15** | **Updated: 2025-07-22**

**Keywords:** 线性码, 点-超平面几何, 扭曲嵌入, 射影空间, 极小码

**Comment:** 28 pages

> **TL;DR:** 本文研究了由射影空间中点-超平面几何的扭曲嵌入产生的线性码的性质和参数。

**AI_Comments:** 本文是关于点-超平面几何产生的线性码的系列研究的第二部分，通过引入扭曲嵌入（$\sigma\neq1$）的概念，扩展了前一部分关于Segre嵌入（$\sigma=1$）的工作。其创新之处在于系统地分析了在自同构作用下的码结构，并提供了码参数、距离和自同构群的详细刻画。这对于理解和构建新型的几何码具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在延续前一部分（聚焦于 $\sigma=1$ 的Segre嵌入）的工作，通过考察 $\sigma\neq1$ 的情况（扭曲嵌入），深入研究由此产生的线性码 ${\mathcal C}(\Lambda_{\sigma})$。

**Method:** 研究方法包括验证 ${\mathcal C}(\Lambda_{\sigma})$ 是否为极小码，确定其参数、最小距离和自同构群。此外，还对其最小和第二低权码字进行了（几何）表征，并在 $q$ 和 $n$ 均为奇数时确定了其最大权。

**Result:** 研究结果表明，${\mathcal C}(\Lambda_{\sigma})$ 是一个极小码。论文成功确定了该码的参数、最小距离和自同构群，并对最小和第二低权码字进行了几何表征。当 $q$ 和 $n$ 均为奇数时，还确定了其最大权。

**Conclusion:** 本文全面分析了由点-超平面几何的扭曲嵌入产生的线性码 ${\mathcal C}(\Lambda_{\sigma})$ 的关键性质，包括其极小性、参数、距离特性以及自同构群，并提供了特定条件下码字权重的几何洞察。

> **ai_Abstract:** 本文在射影空间点-超平面几何的背景下，研究了当域自同构 $\sigma\neq1$ 时，由扭曲嵌入 $\varepsilon_{\sigma}$ 产生的线性码 ${\mathcal C}(\Lambda_{\sigma})$。该研究是前一部分工作（关于Segre嵌入，即 $\sigma=1$ 的情况）的延续。论文详细分析了 ${\mathcal C}(\Lambda_{\sigma})$ 的性质，包括证明其为极小码，并确定了其参数、最小距离、自同构群，以及对最小和第二低权码字的几何表征。此外，还计算了当 $q$ 和 $n$ 皆为奇数时的最大权。

> **摘要翻译:** 设 $\bar{\Gamma}$ 是射影空间 $\mathrm{PG(V)}$ 的点-超平面几何，其中 $V$ 是一个定义在有限域 $\mathbb{F}_q$ 上的 $(n+1)$ 维向量空间，域的阶为 $q$。假设 $\sigma$ 是 $\mathbb{F}_q$ 的一个自同构，并考虑 $\bar{\Gamma}$ 到射影空间 $\mathrm{PG}(V\otimes V^*)$ 的射影嵌入 $\varepsilon_{\sigma}$，它将点 $([x],[\xi])\in \bar{\Gamma}$ 映射到由纯张量 $x^{\sigma}\otimes \xi$ 表示的射影点，其中 $\xi(x)=0$。在 [I. Cardinali, L. Giuzzi, Linear codes arising from the point-hyperplane geometry -- part I: the Segre embedding (Jun. 2025). arXiv:2506.21309, doi:10.48550/ARXIV.2506.21309] 中，我们关注了 $\sigma=1$ 的情况，并研究了由射影系统 $\Lambda_1=\varepsilon_{1}(\bar{\Gamma})$ 产生的射影码。本文我们关注 $\sigma\not=1$ 的情况，并研究了由射影系统 $\Lambda_{\sigma}=\varepsilon_{\sigma}(\bar{\Gamma})$ 产生的线性码 ${\mathcal C}(\Lambda_{\sigma})$。特别地，在验证了 ${\mathcal C}( \Lambda_{\sigma})$ 是一个极小码之后，我们确定了它的参数、最小距离以及它的自同构群。我们还给出了其最小和第二低权码字的（几何）表征，并在 $q$ 和 $n$ 均为奇数时确定了其最大权。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [238] [Automated Design of Structured Variational Quantum Circuits with Reinforcement Learning](https://arxiv.org/abs/2507.16001)
> *基于强化学习的结构化变分量子电路自动设计*

*Gloria Turati, Simone Foderà, Riccardo Nembrini, Maurizio Ferrari Dacrema, Paolo Cremonesi* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 变分量子算法, 强化学习, 量子电路设计, 量子近似优化算法, ansatz

**Comment:** 

> **TL;DR:** 本文提出了两种基于强化学习的方法（RLVQC Global和RLVQC Block）来自动设计变分量子电路（VQC）的结构，并在组合优化问题上展示了其有效性。

**AI_Comments:** 本文的创新之处在于将量子电路的ansatz设计转化为强化学习的顺序决策问题，这为VQA的电路优化提供了一种全新的、自动化的途径。RLVQC Block能够超越QAOA，并找到结构与适应性的最佳平衡点，这对于未来量子算法的设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 变分量子算法（VQAs）的有效性强烈依赖于底层电路ansatz的设计，而这通常通过启发式方法构建。

**Method:** 本文将变分量子电路的合成表示为一个顺序决策问题，并引入了两种基于强化学习的方法：RLVQC Global和RLVQC Block，专为组合优化问题设计。RLVQC Block通过发现应用于所有相互作用量子比特对的两量子比特块来泛化量子近似优化算法（QAOA），而RLVQC Global则进一步泛化ansatz，并添加不受相互作用量子比特结构限制的门。两种方法都采用近端策略优化（PPO）算法，并使用经验测量结果作为状态观测来指导智能体。

**Result:** 在从经典图基优化问题派生的大量QUBO实例上评估了所提出的方法。结果表明，两种RLVQC方法都表现出强大的性能，其中RLVQC Block始终优于QAOA并普遍超越RLVQC Global。RLVQC Block产生的电路深度与QAOA相当，而Global变体则能够找到明显更短的电路。

**Conclusion:** 这些发现表明，强化学习方法可以成为发现针对特定问题量身定制的新ansatz结构的有效工具，并且最有效的电路设计策略介于刚性预定义架构和完全无约束架构之间，在结构和适应性之间提供了有利的权衡。

> **ai_Abstract:** 本文提出了一种利用强化学习自动设计变分量子电路（VQC）结构的新方法。将电路合成视为顺序决策问题，并引入了两种基于PPO的RLVQC方法：RLVQC Block和RLVQC Global。RLVQC Block能泛化QAOA并表现出优于QAOA和RLVQC Global的性能，而RLVQC Global能找到更短的电路。研究表明，RL方法是发现新ansatz结构的有效工具，并且最佳电路设计策略在于结构化与无约束设计之间取得平衡。

> **摘要翻译:** 变分量子算法（VQAs）是利用近期量子硬件最有前景的方法之一，然而其有效性强烈依赖于底层电路ansatz的设计，而这通常通过启发式方法构建。在这项工作中，我们将变分量子电路的合成表示为一个顺序决策问题，其中门被迭代添加以优化目标函数，并且我们引入了两种基于强化学习的方法，RLVQC Global和RLVQC Block，专为组合优化问题设计。RLVQC Block通过发现应用于所有相互作用量子比特对的两量子比特块来泛化量子近似优化算法（QAOA）。而RLVQC Global则进一步泛化ansatz，并添加不受相互作用量子比特结构限制的门。两种方法都采用近端策略优化（PPO）算法，并使用经验测量结果作为状态观测来指导智能体。我们在从经典图基优化问题派生的大量QUBO实例上评估了所提出的方法。我们的结果表明，两种RLVQC方法都表现出强大的性能，其中RLVQC Block始终优于QAOA并普遍超越RLVQC Global。虽然RLVQC Block产生的电路深度与QAOA相当，但Global变体则能够找到明显更短的电路。这些发现表明，强化学习方法可以成为发现针对特定问题量身定制的新ansatz结构的有效工具，并且最有效的电路设计策略介于刚性预定义架构和完全无约束架构之间，在结构和适应性之间提供了有利的权衡。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [254] [Efficient Quantum Pseudorandomness from Hamiltonian Phase States](https://arxiv.org/abs/2410.08073)
> *基于哈密顿相态的有效量子伪随机性*

*John Bostanci, Jonas Haferkamp, Dominik Hangleiter, Alexander Poremba* | **Category: quant-ph, cs.CR** | **Updated: 2025-07-21**

**Keywords:** 量子伪随机性, 哈密顿相态, 量子硬度假设, 量子密码学, 量子原语

**Comment:** 53 pages and 1 figure. Proceedings of TQC 2025. Minor revisions.
  Note: an earlier version of the paper included an analysis of an iterative
  construction of pseudorandom unitaries. This section has been removed due to
  a bug

> **TL;DR:** 本文提出了一种新的量子硬度假设——哈密顿相态（HPS）问题，用于在不依赖经典单向函数的情况下高效构建量子伪随机原语。

**AI_Comments:** 这项工作在量子密码学领域具有重要意义，因为它首次尝试将量子伪随机性的构建与经典密码学中的单向函数完全解耦。通过引入哈密顿相态（HPS）问题，并提供其可信的量子硬度证据，为未来纯量子密码学原语的开发奠定了基础。其高效生成方式也使其在实际量子硬件上具有更高的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有量子伪随机性构造依赖于经典密码学构建块，这些构建块与单向函数的存在性相关，并且在实际量子硬件上难以实现。本文旨在使量子伪随机性完全脱离经典密码学。

**Method:** 引入了哈密顿相态（HPS）问题，其任务是解码随机瞬时量子多项式时间（IQP）电路的输出状态。HPS可以仅使用Hadamard门、单量子比特Z旋转和CNOT电路高效生成。证明了该问题的硬度可以简化为最坏情况版本，并提供了证据表明该假设是完全量子的。在只有少量HPS副本可用时，通过证明其集合的近似t-设计属性，展示了信息理论上的硬度。

**Result:** 1. 提出了哈密顿相态（HPS）问题作为量子硬度假设。2. HPS问题可以高效生成，且其硬度可简化为最坏情况。3. 提供了HPS假设是可信的完全量子的证据，意味着它不能用于构建单向函数。4. 在少量HPS副本下，证明了信息理论上的硬度。5. 基于HPS假设及其变体，可以高效构建多种伪随机量子原语，包括伪随机态、量子伪纠缠、伪随机幺正变换以及带量子密钥的公钥加密等。

**Conclusion:** 本文成功地将量子伪随机性与经典密码学解耦，通过引入哈密顿相态（HPS）问题，提供了一种新的、可信的量子硬度假设，并展示了其在高效构建多种量子伪随机原语方面的潜力。

> **ai_Abstract:** 本文提出了一种新的量子硬度假设——哈密顿相态（HPS）问题，旨在不依赖经典单向函数的情况下，高效地生成量子伪随机原语。研究表明，HPS问题可以通过简单的量子门电路高效生成，其硬度可归结为最坏情况，并且具有完全量子的特性。该假设及其变体能够构建包括伪随机态、量子伪纠缠和伪随机幺正变换等多种量子密码学基本组件。

> **摘要翻译:** 量子伪随机性已在量子信息学的许多领域中得到应用，包括纠缠理论、混沌量子系统中加扰现象的模型，以及最近在量子密码学基础中。Kretschmer（TQC '21）证明了即使在一个没有经典单向函数的世界中，伪随机态和伪随机幺正变换也存在。然而，迄今为止，所有已知的构造都需要经典密码学构建块，这些构建块本身就与单向函数的存在性同义，并且在实际量子硬件上实现也具有挑战性。
在这项工作中，我们寻求同时在这两个方面取得进展——通过将量子伪随机性完全与经典密码学解耦。我们引入了一个名为哈密顿相态（HPS）问题的量子硬度假设，其任务是解码随机瞬时量子多项式时间（IQP）电路的输出状态。哈密顿相态可以仅使用Hadamard门、单量子比特Z旋转和CNOT电路非常高效地生成。我们证明了我们问题的硬度可以简化为问题的最坏情况版本，并且我们提供了证据表明我们的假设是可信的完全量子的；这意味着它不能用于构建单向函数。当只有少量HPS副本可用时，我们通过证明我们集合的近似t-设计属性，展示了信息理论上的硬度。最后，我们表明我们的HPS假设及其变体使我们能够高效地构建许多伪随机量子原语，包括伪随机态、量子伪纠缠、伪随机幺正变换，甚至包括带量子密钥的公钥加密等原语。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [298] [Minor Embedding for Quantum Annealing with Reinforcement Learning](https://arxiv.org/abs/2507.16004)
> *量子退火中基于强化学习的次要嵌入*

*Riccardo Nembrini, Maurizio Ferrari Dacrema, Paolo Cremonesi* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-21**

**Keywords:** 量子退火, 次要嵌入, 强化学习, 组合优化, 近端策略优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的方法来解决量子退火中的次要嵌入问题，该方法在不同拓扑结构上表现良好，并能扩展到中等规模的问题。

**AI_Comments:** 本文创新性地将强化学习应用于量子退火中的次要嵌入这一关键且计算密集型的问题。其重要性在于解决了传统启发式方法泛化能力差和扩展性不足的痛点，为量子计算的实际应用提供了更灵活、更通用的解决方案。尤其是在现代量子硬件拓扑上的良好表现，预示了RL在该领域巨大的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 量子退火中的次要嵌入计算成本高，扩展性差，现有启发式方法难以泛化，且通常针对特定问题图或硬件拓扑开发。

**Method:** 提出了一种基于强化学习的次要嵌入方法，使用近端策略优化（PPO）智能体，通过迭代映射问题变量到硬件量子比特来构建次要嵌入。在Chimera和Zephyr两种硬件拓扑上测试了全连接和随机生成的问题图。

**Result:** 智能体始终能生成有效的次要嵌入，使用相对高效的量子比特数量，尤其在更现代的Zephyr拓扑上表现突出。该方法能扩展到中等问题规模，并能很好地适应不同的图结构。

**Conclusion:** 强化学习在量子退火的次要嵌入中展现出作为灵活通用框架的潜力。

> **ai_Abstract:** 本文提出了一种基于强化学习（RL）的量子退火（QA）次要嵌入方法，旨在解决现有方法计算成本高、扩展性差及泛化能力不足的问题。该方法利用近端策略优化（PPO）智能体，通过学习迭代映射问题变量到量子比特来构建嵌入。实验结果表明，该方法在不同硬件拓扑（Chimera和Zephyr）上均能生成有效的次要嵌入，并能高效利用量子比特，尤其在Zephyr拓扑上表现优异。此外，该方法具有良好的可扩展性和图结构适应性，证明了RL在QA次要嵌入领域的通用潜力。

> **摘要翻译:** 量子退火（QA）是一种量子计算范式，用于解决表述为二次无约束二元优化（QUBO）问题的组合优化问题。QA中的一个重要步骤是次要嵌入，它将问题图映射到量子处理器的稀疏拓扑上。这个过程计算成本高，并且随着问题规模和硬件复杂度的增加而扩展性差。现有的启发式方法通常是为特定的问题图或硬件拓扑开发的，难以泛化。强化学习（RL）通过将次要嵌入视为一个序列决策问题，提供了一个有前景的替代方案，其中智能体通过迭代地将问题变量映射到硬件量子比特来学习构建次要嵌入。我们提出了一种基于RL的次要嵌入方法，使用近端策略优化智能体，测试其在两种硬件拓扑（Chimera和Zephyr）上嵌入全连接和随机生成的问题图的能力。结果表明，我们的智能体始终能够生成有效的次要嵌入，并使用合理高效的量子比特数量，特别是在更现代的Zephyr拓扑上。我们提出的方法还能够扩展到中等问题规模，并能很好地适应不同的图结构，这突出了RL作为QA中次要嵌入的灵活通用框架的潜力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [428] [Adaptive Bayesian Single-Shot Quantum Sensing](https://arxiv.org/abs/2507.16477)
> *自适应贝叶斯单次量子传感*

*Ivana Nikoloska, Ruud Van Sloun, Osvaldo Simeone* | **Category: quant-ph, cs.LG, eess.SP** | **Updated: 2025-07-22**

**Keywords:** 量子传感, 贝叶斯推断, 自适应协议, 变分量子传感, 单次传感

**Comment:** submitted for publication

> **TL;DR:** 本文提出了一种自适应贝叶斯推断协议，用于优化量子传感策略，特别适用于单次、非渐近场景和多代理融合。

**AI_Comments:** 该论文的创新点在于将自适应贝叶斯推断应用于量子传感优化，超越了传统的离线频率学方法。其对单次、非渐近状态的适用性以及支持多代理估计融合的能力，是其重要的亮点，有望提升资源受限环境下量子传感的实用性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 量子传感中，在高维希尔伯特空间中优化传感探针和测量方案是经典上难以解决的任务，且现有方法多采用离线频率学优化。

**Method:** 提出了一种自适应协议，利用贝叶斯推断通过最大化主动信息增益来优化传感策略。该方法专为非渐近状态下的单探针部署设计，并可扩展支持多量子传感代理的估计融合。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种自适应贝叶斯协议，旨在解决高维希尔伯特空间中量子传感优化难题。与传统的离线频率学方法不同，该协议通过最大化主动信息增益来优化传感策略。它特别适用于单次、非渐近的量子传感场景，并支持从多个量子传感代理融合估计，有望提高量子传感的实用性和效率。

> **摘要翻译:** 量子传感利用量子系统独特的性质，能够实现对时间、磁场和电场、加速度以及引力梯度等物理量的精确测量，远超经典传感器的极限。然而，识别合适的传感探针和测量方案可能是一项经典上难以解决的任务，因为它需要在高维希尔伯特空间中进行优化。在变分量子传感中，通过参数化量子电路（PQC）生成一个探针量子系统，通过量子通道暴露于未知物理参数，并进行测量以收集经典数据。PQC和测量通常使用基于频率学学习准则的离线策略进行优化。本文介绍了一种自适应协议，该协议使用贝叶斯推断通过最大化主动信息增益来优化传感策略。所提出的变分方法适用于非渐近状态，其中每个时间步可以部署单个探针，并且扩展支持从多个量子传感代理融合估计。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [433] [Entanglement-Efficient Compilation of Quantum Circuits over Large-Scale Quantum Networks](https://arxiv.org/abs/2507.16036)
> *大规模量子网络中量子电路的纠缠高效编译*

*Felix Burt, Kuan-Cheng Chen, Kin K. Leung* | **Category: quant-ph, cs.DC** | **Updated: 2025-07-21**

**Keywords:** 量子电路, 纠缠, 分布式量子计算, 电路划分, 粗化

**Comment:** 12 pages, 10 figures, to be published in proceedings of IEEE QCE2025

> **TL;DR:** 本文提出了一种改进的量子电路划分方案，通过考虑网络连接性和纠缠成本，实现了在大规模分布式量子计算中更低的纠缠开销和更快的运行时间。

**AI_Comments:** 本文通过对现有量子电路划分方案的创新性修改，并引入了网络和问题粗化技术，有效地解决了大规模分布式量子计算中纠缠共享的效率问题。其贡献在于不仅降低了纠缠开销，还在保证解决方案质量的同时显著提升了算法运行效率，为未来大规模量子网络的实际部署提供了重要的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算机面临固有的扩展挑战，需要通过互连小型量子处理单元来构建分布式量子计算系统。然而，连接大量量子处理单元会导致网络层面的连接性限制，纠缠共享的难度随网络路径长度增加，从而增加了量子电路划分问题的复杂性。

**Method:** 通过对现有针对全连接网络的划分方案进行简单修改，以有效考虑网络拓扑和现有链路对纠缠生成成本的影响。此外，还引入了网络和问题粗化技术，以支持扩展到大规模量子网络。

**Result:** 在大多数情况下，相比现有最先进的方法，实现了更低的纠缠成本。粗化方法在大多数情况下提高了解决方案质量，并显著降低了运行时间。

**Conclusion:** 通过改进的电路划分方案和粗化技术，可以有效地解决大规模量子网络中的纠缠共享和电路划分复杂性问题，从而实现更高效的分布式量子计算。

> **ai_Abstract:** 为了解决分布式量子计算中大规模量子网络互连带来的纠缠共享和电路划分复杂性问题，本文提出了一种对现有划分方案的简单修改方法。该方法有效考虑了网络拓扑和纠缠成本，并通过引入网络和问题粗化技术，实现了在大多数情况下比现有技术更低的纠缠成本、更高的解决方案质量和显著缩短的运行时间。

> **摘要翻译:** 量子计算机面临固有的扩展挑战，这使得分布式量子计算系统的研究变得必要，其中通过互连较小的量子处理单元来实现扩展。然而，连接大量量子处理单元最终将导致网络层面的连接性限制，其中纠缠共享的难度随网络路径长度增加。这增加了量子电路划分问题的复杂性，因为端节点之间生成纠缠的成本随网络拓扑和现有链路而变化。我们通过对现有为全连接网络设计的划分方案进行简单修改来解决这一挑战，该修改有效地考虑了这两个因素。我们研究了各种量子电路在不同网络拓扑上的纠缠需求和优化时间方面的性能，在大多数情况下实现了比现有最先进方法更低的纠缠成本。我们提供了利用网络和问题粗化技术扩展到大规模量子网络的方法。我们表明，粗化方法在大多数情况下可以实现改进的解决方案质量，并且运行时间比直接划分方法显著降低。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [467] [Pulse-Level Simulation of Crosstalk Attacks on Superconducting Quantum Hardware](https://arxiv.org/abs/2507.16181)
> *超导量子硬件中串扰攻击的脉冲级模拟*

*Syed Emad Uddin Shubha, Tasnuva Farheen* | **Category: quant-ph, cs.CR** | **Updated: 2025-07-22**

**Keywords:** 超导量子计算, 硬件串扰, 量子安全, 脉冲级模拟, 量子攻击

**Comment:** This paper has been accepted to the Security, Privacy, and Resilience
  Workshop at IEEE Quantum Week (QCE 2025) and will appear in the workshop
  proceedings

> **TL;DR:** 本文对超导量子计算机中硬件串扰引起的脉冲级攻击进行了模拟研究，分析了攻击者如何通过控制脉冲参数来扰乱受害者计算，并提出了检测和缓解方法。

**AI_Comments:** 这项工作在量子计算安全领域具有重要意义，因为它首次在脉冲级详细模拟了超导量子硬件中的串扰攻击，揭示了潜在的漏洞。研究不仅识别了攻击参数，还评估了不同协议的脆弱性，并提出了实用的防御策略，对未来量子云平台的安全设计具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 超导量子计算机中的硬件串扰对多租户系统构成严重安全威胁，允许攻击者通过注入精心设计的脉冲在租户边界间诱发目标错误。

**Method:** 本文采用基于模拟的方法，在脉冲级对主动串扰攻击进行研究。框架建模了一个旋转坐标系下三量子比特系统的时变动力学，捕获了常开耦合和注入的驱动脉冲。研究了两种攻击策略：攻击者优先（在受害者操作前注入脉冲）和受害者优先（在受害者操作后注入脉冲），并系统地识别了导致最大逻辑错误的脉冲和耦合配置。

**Result:** 研究发现，某些量子协议（如量子抛硬币和异或分类电路）对这些攻击高度脆弱，而另一些则保持鲁棒。本文系统地识别了导致最大逻辑错误的脉冲和耦合配置。

**Conclusion:** 基于研究发现，本文讨论了在量子云平台中提高安全性的实用检测和缓解方法。

> **ai_Abstract:** 本文研究了超导量子计算机中硬件串扰引起的安全威胁，通过脉冲级模拟分析了攻击者如何利用精心设计的脉冲来扰乱受害者的量子计算。研究构建了一个三量子比特系统模型，并探讨了两种攻击策略。结果表明，某些量子协议对此类攻击高度脆弱。基于这些发现，文章提出了实用的检测和缓解方法，以增强量子云平台的安全性。

> **摘要翻译:** 在多租户超导量子计算机中，硬件串扰构成了严重的安全威胁，允许攻击者通过注入精心设计的脉冲在租户边界间诱发目标错误。本文对脉冲级主动串扰攻击进行了基于模拟的研究，分析了攻击者如何通过控制脉冲时序、形状、幅度以及耦合来扰乱受害者的计算。我们的框架建模了旋转坐标系下三量子比特系统的时变动力学，捕获了常开耦合和注入的驱动脉冲。我们研究了两种攻击策略：攻击者优先（在受害者操作前注入脉冲）和受害者优先（在受害者操作后注入脉冲），并系统地识别了导致最大逻辑错误的脉冲和耦合配置。在量子抛硬币和异或分类电路上的协议级实验表明，一些协议对这些攻击高度脆弱，而另一些则保持鲁棒。基于这些发现，我们讨论了在量子云平台中提高安全性的实用检测和缓解方法。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [718] [Meta-learning of Gibbs states for many-body Hamiltonians with applications to Quantum Boltzmann Machines](https://arxiv.org/abs/2507.16373)
> *多体哈密顿量的吉布斯态元学习及其在量子玻尔兹曼机中的应用*

*Ruchira V Bhat, Rahul Bhowmick, Avinash Singh, Krishna Kumar Sabapathy* | **Category: quant-ph, cs.LG, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 元学习, 吉布斯态, 量子玻尔兹曼机, NISQ, 热态制备

**Comment:** 20 pages, 14 figures, 3 tables, 3 algorithms

> **TL;DR:** 本文提出了两种元学习算法（Meta-VQT和NN-Meta VQT），用于在NISQ设备上高效制备参数化哈密顿量的热态，并应用于量子玻尔兹曼机训练。

**AI_Comments:** 该论文创新性地将元学习引入量子吉布斯态的制备，解决了NISQ设备上热态生成效率和泛化性的挑战。通过引入全量子和量子经典混合两种元学习算法，并结合热启动优化，显著提升了算法的实用性。尤其在量子玻尔兹曼机训练中的应用，展示了其在量子机器学习领域的重要潜力，实现了显著的速度提升和精度改善，为未来量子算法设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 制备量子吉布斯态是量子计算中的一个基本挑战，对于从开放量子系统建模到量子机器学习等应用至关重要。

**Method:** 本文在Meta-Variational Quantum Eigensolver框架和问题驱动的Ansatz设计基础上，引入了两种元学习算法：元变分量子热化器（Meta-VQT）和神经网络元变分量子热化器（NN-Meta VQT），用于在噪声中等规模量子（NISQ）设备上高效制备参数化哈密顿量的热态。Meta-VQT利用全量子Ansatz，而NN Meta-VQT整合了量子经典混合架构。两者都利用训练集上的集体优化来将吉布斯态制备推广到未见参数。

**Result:** 方法在高达8量子比特的横场伊辛模型和2量子比特海森堡模型上进行了验证，展示了超越训练数据的高效热态生成。对于更大的系统，元学习参数结合适当设计的Ansatz可作为热启动初始化，显著优于随机初始化。在3量子比特Kitaev环示例中展示了算法在有限温度交叉区域的有效性。应用于2量子比特海森堡模型上的量子玻尔兹曼机训练，实现了更高的训练效率、改进的吉布斯态精度和比现有技术（如VarQITE-based QBM）快30倍的运行时加速。

**Conclusion:** 本文提出的元算法（Meta-VQT和NN-Meta VQT）在NISQ设备上高效制备量子吉布斯态，并显著提升了量子玻尔兹曼机的训练效率和性能，展示了其可扩展性和实用性。

> **ai_Abstract:** 本文提出了两种基于元学习的量子算法：Meta-VQT和NN-Meta VQT，旨在高效制备多体哈密顿量的量子吉布斯态，尤其适用于NISQ设备。这些算法通过集体优化实现对未见参数的泛化。实验验证表明，它们能在不同量子模型上高效生成热态，并能为大型系统提供有效的热启动初始化。此外，将这些算法应用于量子玻尔兹曼机训练，显著提升了训练效率、精度和速度，突显了元学习在量子机器学习中的潜力。

> **摘要翻译:** 量子吉布斯态的制备是量子计算中的一个基本挑战，对于从开放量子系统建模到量子机器学习等应用至关重要。本文在Cervera-Lierta等人（2021）提出的元变分量子本征求解器框架和问题驱动的Ansatz设计基础上，引入了两种元学习算法：元变分量子热化器（Meta-VQT）和神经网络元变分量子热化器（NN-Meta VQT），用于在噪声中等规模量子（NISQ）设备上高效制备参数化哈密顿量的热态。Meta-VQT利用全量子Ansatz，而NN Meta-VQT则整合了量子经典混合架构。两者都利用训练集上的集体优化来将吉布斯态制备推广到未见参数。我们在高达8量子比特的横场伊辛模型和包含所有场项的2量子比特海森堡模型上验证了我们的方法，展示了超越训练数据的高效热态生成。对于更大的系统，我们表明，当我们的元学习参数与适当设计的Ansatz结合时，可以作为热启动初始化，在优化任务中显著优于随机初始化。此外，一个3量子比特Kitaev环示例展示了我们算法在有限温度交叉区域的有效性。最后，我们将我们的算法应用于在包含所有场项的2量子比特海森堡模型上训练量子玻尔兹曼机（QBM），实现了更高的训练效率、改进的吉布斯态精度，以及比现有技术（如基于变分量子虚时间（VarQITE）的QBM）快30倍的运行时加速，突出了基于元算法的QBM的可扩展性和实用性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [266] [Gaussian Sequence Model: Sample Complexities of Testing, Estimation and LFHT](https://arxiv.org/abs/2507.16734)
> *高斯序列模型：检验、估计和LFHT的样本复杂度*

*Zeyu Jia, Yury Polyanskiy* | **Category: math.ST, cs.IT, math.IT, stat.TH** | **Updated: 2025-07-22**

**Keywords:** 高斯序列模型, 样本复杂度, 拟合优度检验, 统计估计, 无似然假设检验

**Comment:** 

> **TL;DR:** 本文研究了高斯序列模型中拟合优度检验与估计的样本复杂度关系，并完全刻画了无似然假设检验（LFHT）的复杂度，发现了新的样本权衡。

**AI_Comments:** 本文在高斯序列模型中对统计检验和估计的样本复杂度进行了深入的理论分析，特别是在检验-估计关系和无似然假设检验方面取得了重要进展。其创新点在于扩展了现有理论的适用范围，并揭示了样本之间的新型权衡关系，对于理解高维数据分析中的统计效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在深入研究高斯序列模型中拟合优度检验、估计和无似然假设检验（LFHT）的样本复杂度，并揭示它们之间的相互关系。

**Method:** 通过理论分析和推导，本文证明了拟合优度检验样本复杂度的下界，并在特定条件下证明了其紧致性，同时完整刻画了LFHT的复杂度。

**Result:** 当参数空间$\\Gamma$是正交对称时，拟合优度检验的样本复杂度以下界为估计复杂度的平方根。当$\\Gamma$也是二次凸时，该下界是紧致的，显著扩展了[GP24]中检验-估计关系的有效性。本文还完全刻画了$\\ell_p$体上的无似然假设检验（LFHT）复杂度，并发现了模拟样本和观测样本之间的新型权衡。

**Conclusion:** 本文扩展了高斯序列模型中拟合优度检验与估计之间的样本复杂度关系，并对无似然假设检验的复杂度进行了全面刻画，揭示了新的样本权衡。

> **ai_Abstract:** 本文在高斯序列模型中，当参数空间$\\Gamma$为凸且紧致时，研究了拟合优度检验、估计和无似然假设检验（LFHT）的样本复杂度。研究表明，当$\\Gamma$正交对称时，检验复杂度以下界为估计复杂度的平方根，并且在$\\Gamma$二次凸时该下界紧致，扩展了现有工作。此外，本文还完整刻画了$\\ell_p$体上的LFHT复杂度，并发现了模拟和观测样本之间的新型权衡关系。

> **摘要翻译:** 我们研究了高斯序列模型，即 $X \\sim N(\\mathbf{\\theta}, I_\\infty)$，其中 $\\mathbf{\\theta} \\in \\Gamma \\subset \\ell_2$ 被假定为凸且紧致。我们证明，当 $\\Gamma$ 是正交对称时，拟合优度检验的样本复杂度以下界为估计复杂度的平方根。我们还证明，当 $\\Gamma$ 也是二次凸时，该下界是紧致的，从而显著扩展了 [GP24] 中检验-估计关系的有效性。使用类似的方法，我们还完全刻画了 $\\ell_p$ 体上的无似然假设检验 (LFHT) 复杂度，发现了模拟样本和观测样本之间的新型权衡。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

### [621] [On low frequency inference for diffusions without the hot spots conjecture](https://arxiv.org/abs/2410.19393)
> *关于没有热点猜想的扩散低频推断*

*Giovanni S. Alberti, Douglas Barnes, Aditya Jambhale, Richard Nickl* | **Category: math.ST, cs.NA, math.AP, math.NA, stat.TH** | **Updated: 2025-07-22**

**Keywords:** 扩散, Neumann Laplacian, 极小极大收敛速度, 逆问题, Lipschitz稳定性

**Comment:** To appear in Mathematical Statistics and Learning

> **TL;DR:** 该论文在扩散低频推断中，成功消除了对“热点”猜想的依赖，并刻画了转移算子估计的极小极大收敛速度，同时证明了逆映射的Lipschitz稳定性。

**AI_Comments:** 该论文的创新之处在于成功移除了“热点”猜想这一对扩散推断理论结果的限制，显著增强了相关研究的适用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是消除Nickl（2024年，《统计年鉴》）近期论文中两个主要定理对“热点”猜想的依赖。

**Method:** 研究方法是刻画在具有光滑边界的任意凸域上，由Neumann Laplacian与扩散系数f产生的转移算子$P_f$估计的极小极大收敛速度，并进一步证明了逆映射$P_f 	o f$从$H^2 	o H^2$到$L^1$的一般Lipschitz稳定性估计。

**Result:** 论文成功消除了对“热点”猜想的依赖。它刻画了对Neumann Laplacian下扩散系数f产生的转移算子$P_f$估计的极小极大收敛速度，并证明了逆映射$P_f 	o f$从$H^2 	o H^2$到$L^1$的一般Lipschitz稳定性估计成立。

**Conclusion:** 该论文成功消除了扩散低频推断中对“热点”猜想的依赖，并提供了转移算子估计的极小极大收敛速度的刻画，同时证明了逆映射的Lipschitz稳定性。

> **ai_Abstract:** 本论文通过消除对“热点”猜想的依赖，解决了扩散低频推断中的一个关键问题。它刻画了在凸域上由Neumann Laplacian和扩散系数f产生的转移算子$P_f$的极小极大收敛速度，并建立了从转移算子到扩散系数的逆映射的Lipschitz稳定性估计。

> **摘要翻译:** 我们消除了对Nickl（2024年，《统计年鉴》）近期论文中两个主要定理中“热点”猜想的依赖。具体来说，我们刻画了在具有光滑边界的任意凸域上，由Neumann Laplacian与扩散系数f产生的转移算子$P_f$估计的极小极大收敛速度，并进一步表明逆映射$P_f 	o f$从$H^2 	o H^2$到$L^1$的一般Lipschitz稳定性估计成立。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [279] [A computational transition for detecting correlated stochastic block models by low-degree polynomials](https://arxiv.org/abs/2409.00966)
> *通过低度多项式检测相关随机块模型的计算相变*

*Guanyi Chen, Jian Ding, Shuyang Gong, Zhangsong Li* | **Category: math.PR, cs.DS, cs.LG, math.ST, stat.TH, Primary 62M20, Secondary 68Q87, 68Q17** | **Updated: 2025-07-22**

**Keywords:** 相关随机块模型, 低度多项式, 计算相变, 检测, 随机图

**Comment:** 80 pages, 2 figures, added further explanations and remarks; to
  appear in Annals of Statistics

> **TL;DR:** 本文通过低度多项式测试，确定了在相关随机块模型中检测相关性的计算阈值，并揭示了低于该阈值时的计算硬度。

**AI_Comments:** 本文的创新之处在于利用低度多项式方法，精确地确定了相关随机块模型检测的计算相变阈值。这一发现将计算复杂性与图模型中的关键统计物理学常数（如Otter常数和Kesten-Stigum阈值）联系起来，为理解图结构数据的计算限制提供了深入的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 检测一对随机图中的相关性是一个基础的统计和计算问题，近年来得到了广泛研究。

**Method:** 本研究考虑了一对从共同父随机块模型中子采样得到的稀疏随机块模型。我们专注于基于邻接矩阵条目低度多项式的测试，并确定了区分易处理和难处理区域的阈值。低度硬度的证明基于低度似然计算的条件变体。

**Result:** 研究表明，这类测试能够区分两种模型当且仅当子采样概率 $s > \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$，其中 $\alpha\approx 0.338$ 是Otter常数，$\frac{1}{\lambda \epsilon^2}$ 是Kesten-Stigum阈值。当 $s < \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$ 时，该硬度结果也暗示了部分恢复和检测（到独立块模型）的低度硬度。

**Conclusion:** 本文确定了使用低度多项式检测相关随机块模型的计算相变阈值，并揭示了低于此阈值时的计算硬度，将计算能力与统计物理学中的已知常数联系起来。

> **ai_Abstract:** 本文研究了检测一对相关随机块模型中相关性的计算问题。通过利用邻接矩阵条目的低度多项式测试，作者确定了区分该模型与独立Erd\H{o}s-R\'enyi图的计算阈值。研究表明，当子采样概率 $s$ 大于一个由Otter常数和Kesten-Stigum阈值决定的特定阈值时，可以成功进行检测；反之，则存在低度计算硬度，这为图模型中的计算界限提供了新的见解。

> **摘要翻译:** 一对随机图中相关性的检测是一个基础的统计和计算问题，近年来得到了广泛研究。在这项工作中，我们考虑了一对相关的（稀疏）随机块模型 $\mathcal{S}(n,\tfrac{\lambda}{n};k,\epsilon;s)$，它们是从一个共同的父随机块模型 $\mathcal S(n,\tfrac{\lambda}{n};k,\epsilon)$ 中子采样的，其中 $k=O(1)$ 对称社区，平均度 $\lambda=O(1)$，发散参数 $\epsilon$，和子采样概率 $s$。
对于将该模型与一对具有相同边密度的独立Erd\H{o}s-R\'enyi图 $\mathcal{G}(n,\tfrac{\lambda s}{n})$ 区别的检测问题，我们专注于基于邻接矩阵条目“低度多项式”的测试，并确定了区分易处理和难处理区域的阈值。更精确地说，我们表明这类测试能够区分这两种模型当且仅当 $s> \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$，其中 $\alpha\approx 0.338$ 是Otter常数，$\frac{1}{\lambda \epsilon^2}$ 是Kesten-Stigum阈值。结合 \cite{Li25+} 中的归约论证，我们的硬度结果也暗示了当 $s< \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$ 时，部分恢复和检测（到独立块模型）的低度硬度。最后，我们对低度硬度的证明是基于低度似然计算的条件变体。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

### [520] [Low complexity convergence rate bounds for push-sum algorithms with homogeneous correlation structure](https://arxiv.org/abs/2507.16601)
> *具有同质相关结构的推和算法的低复杂度收敛速率界限*

*Balázs Gerencsér, Miklós Kornyik* | **Category: math.PR, cs.MA, 37M25 (Primary) 93D50, 93D05 (Secondary}, G.3** | **Updated: 2025-07-22**

**Keywords:** 推和算法, 收敛速率, 低复杂度, 参数分析, 分布式算法

**Comment:** 15 pages, 3 figures

> **TL;DR:** 本文为一类推和算法建立了几乎必然收敛速率的上限，并通过参数分析和数值结果展示了其低复杂度和显著的计算效率提升。

**AI_Comments:** 本文的创新点在于为推和算法提供了一个低复杂度的收敛速率上限，并通过参数分析实现了算法的效率优化。其重要性体现在显著提升了计算效率（运行时长降低了四个数量级以上），使得此类算法在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 本工作的目标是为一类推和算法建立几乎必然收敛速率的上限。它扩展了作者之前关于低复杂度界限的方法和结果，并补充了Gerencsér和Gerencsér于2022年提出的通用方法，旨在提供一个精确但通常更易于访问的描述。

**Method:** 本研究扩展了作者之前关于具有特定同步消息传递方案的推和算法低复杂度界限的方法和结果。它补充了Gerencsér和Gerencsér于2022年提出的通用方法。此外，还对消息的“权重”进行了参数分析，发现其是凸的，并给出了梯度的显式表达式。

**Result:** 数值结果证实了在不降低性能的情况下，评估可计算界限的速度得到了显著提升。对于一个包含120个顶点的图，运行时长下降了4个数量级以上。

**Conclusion:** 该研究成功为推和算法提供了一个低复杂度的收敛速率上限，并通过对消息权重的参数分析实现了算法效率的微调和显著的计算加速。

> **ai_Abstract:** 本文旨在为一类推和算法建立几乎必然收敛速率的低复杂度上限。研究扩展了现有方法，并补充了通用方法，以提供更易于访问的描述。通过对消息“权重”的参数分析，发现了其凸性及梯度的显式表达式，从而实现了算法效率的微调。数值结果表明，该方法在保持性能的同时，显著加速了可计算界限的评估，运行时长降低了四个数量级以上。

> **摘要翻译:** 这项工作的目标是为一类推和算法建立几乎必然收敛速率的上限。目前的工作扩展了作者在具有特定同步消息传递方案的推和算法低复杂度界限上的方法和结果，并补充了Gerencsér和Gerencsér于2022年提出的通用方法，后者提供了精确但通常较难理解的描述。此外，还对消息的“权重”进行了参数分析，发现其是凸的，并给出了梯度的显式表达式。这使得算法能够进行微调以提高效率。数值结果证实了在不降低性能的情况下，评估可计算界限的速度得到了提升，对于一个包含120个顶点的图，运行时长下降了4个数量级以上。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [299] [Pixel-Resolved Long-Context Learning for Turbulence at Exascale: Resolving Small-scale Eddies Toward the Viscous Limit](https://arxiv.org/abs/2507.16697)
> *像素分辨的超大规模湍流长上下文学习：解析小尺度涡流直至粘性极限*

*Junqi Yin, Mijanur Palash, M. Paul Laiu, Muralikrishnan Gopalakrishnan Meena, John Gounley, Stephen M. de Bruyn Kops, Feiyi Wang, Ramanan Sankaran, Pei Zhang* | **Category: physics.flu-dyn, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 湍流, 超大规模计算, 深度学习, Transformer, 并行计算

**Comment:** 

> **TL;DR:** 本文提出了一种多尺度分层湍流Transformer模型和RingX序列并行方法，以解决超大规模湍流模拟中极端分辨率数据带来的计算成本问题，并在Frontier超级计算机上实现了出色的性能，首次使AI模型能够捕捉到耗散范围内的小尺度涡流。

**AI_Comments:** 该论文在解决超大规模湍流模拟的计算挑战方面展现了显著的创新性。通过结合多尺度Transformer架构和新颖的序列并行策略，它成功地将计算复杂度降低，并在全球顶尖的超级计算机上实现了前所未有的性能。其能够解析小尺度涡流至耗散范围的能力，对于多物理场应用的精确预测具有重要意义，是AI在科学计算领域的一大突破。

<details>
  <summary>Details</summary>

**Motivation:** 准确捕捉湍流的多尺度特性对于多物理场应用的可靠预测至关重要，但即使对于超大规模超级计算机和先进的深度学习模型，这仍然是一个巨大的挑战。表示湍流所需的极端分辨率数据（从数十亿到数万亿网格点）对基于视觉Transformer等架构的模型造成了高昂的计算成本。

**Method:** 我们引入了一种多尺度分层湍流Transformer，将序列长度从数十亿减少到数百万，并提出了一种新颖的RingX序列并行方法，以实现可扩展的长上下文学习。

**Result:** 我们的方法在32,768个AMD GPU上展示了高达1.1 EFLOPS的出色性能，扩展效率达到94%。据我们所知，这是第一个能够捕捉到耗散范围内小尺度涡流的湍流AI模型。

**Conclusion:** 本文提出的多尺度分层湍流Transformer和RingX序列并行方法，首次使AI模型能够有效处理超大规模湍流数据，并解析小尺度涡流至耗散范围，实现了在Frontier超级计算机上的卓越性能。

> **ai_Abstract:** 本文提出了一种像素分辨的超大规模湍流长上下文学习方法，旨在解决现有深度学习模型在处理极端分辨率湍流数据时面临的巨大计算挑战。通过引入多尺度分层湍流Transformer和新颖的RingX序列并行方法，该研究成功将序列长度大幅缩减，并实现了可扩展的长上下文学习。实验在Frontier超级计算机上进行，结果显示该方法在32,768个AMD GPU上达到了1.1 EFLOPS的性能，扩展效率高达94%，并且首次使AI模型能够捕捉到耗散范围内的精细小尺度涡流。

> **摘要翻译:** 湍流在空气动力学、聚变和燃烧等多物理场应用中扮演着关键角色。准确捕捉湍流的多尺度特性对于多物理场相互作用的可靠预测至关重要，但即使对于超大规模超级计算机和先进的深度学习模型，这仍然是一个巨大的挑战。表示湍流所需的极端分辨率数据（从数十亿到数万亿网格点）对基于视觉Transformer等架构的模型造成了高昂的计算成本。为了解决这一挑战，我们引入了一种多尺度分层湍流Transformer，将序列长度从数十亿减少到数百万，并提出了一种新颖的RingX序列并行方法，以实现可扩展的长上下文学习。我们在Frontier超级计算机上进行了扩展和科学运行。我们的方法在32,768个AMD GPU上展示了高达1.1 EFLOPS的出色性能，扩展效率达到94%。据我们所知，这是第一个能够捕捉到耗散范围内小尺度涡流的湍流AI模型。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [368] [Is memory all you need? Data-driven Mori-Zwanzig modeling of Lagrangian particle dynamics in turbulent flows](https://arxiv.org/abs/2507.16058)
> *记忆是你所需要的一切吗？湍流中拉格朗日粒子动力学的数据驱动Mori-Zwanzig建模*

*Xander de Wit, Alessandro Gabbana, Michael Woodward, Yen Ting Lin, Federico Toschi, Daniel Livescu* | **Category: physics.flu-dyn, cs.LG, nlin.CD** | **Updated: 2025-07-21**

**Keywords:** 拉格朗日粒子, 湍流, Mori-Zwanzig, 数据驱动建模, 替代模型

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的Mori-Zwanzig模型，用于模拟湍流中拉格朗日粒子的动力学，实现了短期预测的精确性和长期统计行为的稳定性，有效降低了计算成本。

**AI_Comments:** 本文的创新点在于将Mori-Zwanzig形式论与数据驱动的机器学习技术相结合，成功构建了计算效率高且能同时保持短期精度和长期统计稳定性的湍流拉格朗日粒子动力学替代模型。这对于克服传统模拟的高昂计算成本具有重要意义，并为在湍流环境中控制主动拉格朗日智能体等实际应用打开了大门。

<details>
  <summary>Details</summary>

**Motivation:** 湍流中拉格朗日粒子的轨迹表现出高度非平凡的统计行为，直接数值模拟（DNS）计算成本高昂，且现有降阶模型难以完全捕捉与湍流场的相互作用，因此需要开发能够以较低计算成本重现这些轨迹的替代模型。

**Method:** 该方法基于Mori-Zwanzig形式论，将完整的动力系统分解为依赖于当前状态和可观测变量过去历史的已解析动力学，以及由初始状态未解析自由度引起的未解析正交动力学。通过在短期预测的点误差度量上训练该降阶模型，来学习拉格朗日湍流的动力学。

**Result:** 所学习的替代动力系统能够以点对点精确的方式演化湍流拉格朗日轨迹，适用于短期预测（相对于Kolmogorov时间），并且在长时间尺度上稳定且统计准确地恢复了长期的统计行为。

**Conclusion:** 该方法为一系列新应用开辟了前景，例如在湍流中控制主动拉格朗日智能体。

> **ai_Abstract:** 本文提出了一种基于Mori-Zwanzig形式论的数据驱动方法，用于构建湍流中拉格朗日粒子动力学的替代模型。该模型通过分解系统动力学并利用短期预测的点误差度量进行训练，成功实现了对湍流拉格朗日轨迹的精确模拟，既能在短期内保持点对点准确性，又能稳定且统计准确地重现长期行为，从而有效解决了传统直接数值模拟计算成本高昂的问题，并为流体控制等新应用提供了可能。

> **摘要翻译:** 湍流中拉格朗日粒子的动力学在复杂流动的混合、传输和分散过程中起着关键作用。它们的轨迹表现出高度非平凡的统计行为，这促使人们开发替代模型，这些模型可以在不产生完整欧拉场直接数值模拟高计算成本的情况下重现这些轨迹。这项任务特别具有挑战性，因为降阶模型通常无法访问与底层湍流场的完整相互作用集。新颖的数据驱动机器学习技术在捕获和重现降阶/替代动力学的复杂统计数据方面非常强大。在这项工作中，我们展示了如何学习一个替代动力系统，该系统能够以对短期预测（相对于Kolmogorov时间）点对点精确且在长时间内稳定且统计准确的方式演化湍流拉格朗日轨迹。这种方法基于Mori-Zwanzig形式论，该形式论规定了将完整动力系统数学分解为依赖于当前状态和一组简化可观测变量的过去历史的已解析动力学，以及由于初始状态未解析自由度引起的未解析正交动力学。我们展示了如何通过在短期预测的点误差度量上训练这个降阶模型，我们能够正确学习拉格朗日湍流的动力学，从而在测试时也能稳定地恢复长期统计行为。这开辟了一系列新应用，例如，用于湍流中主动拉格朗日智能体的控制。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [664] [Benchmarking machine learning models for predicting aerofoil performance](https://arxiv.org/abs/2504.15993)
> *基准测试机器学习模型预测翼型性能*

*Oliver Summerell, Gerardo Aragon-Camarasa, Stephanie Ordonez Sanchez* | **Category: physics.flu-dyn, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 机器学习, 神经网络, 翼型性能, 升力系数, 基准测试

**Comment:** 9 pages, 10 figures, submitted to EWTEC

> **TL;DR:** 本文对机器学习模型在预测翼型性能方面的能力进行了基准测试，发现PointNet和MLP是预测流体行为和升力系数的最强模型。

**AI_Comments:** 本文的创新点在于系统地将多种神经网络模型应用于翼型性能预测，并对其进行了基准测试。这为风能和潮汐能行业提供了一种潜在的、更高效的替代方案，以取代计算成本较高的传统方法。研究结果揭示了不同模型在预测不同方面（流体行为与升力系数）的优势，这对于实际应用具有指导意义。未来的工作可以探索这些模型的结合使用或进一步优化。

<details>
  <summary>Details</summary>

**Motivation:** 传统的翼型性能分析方法（如CFD、薄翼型和面板方法）在计算速度和结果精度之间存在权衡。为了寻求一种既快速又准确的替代方案，本文研究了神经网络（NNs）的应用。

**Method:** 本研究对风能和潮汐能行业中使用的翼型性能的神经网络模型进行了基准测试。具体使用了NREL发布的windAI_bench数据集进行基准测试，并以AirfRANSdataset基准作为验证方法的起点和比较点。研究评估了四种神经网络模型（MLP、PointNet、GraphSAGE、GUNet），这些模型在25个攻角（4°至20°）范围内的多种翼型上进行训练，以预测流体流动并通过面板方法计算升力系数（$C_L$）。

**Result:** GraphSAGE和GUNet在训练阶段表现良好，但在测试阶段表现不佳。PointNet和MLP被确定为测试过的两种最强模型。其中，MLP在预测流体行为方面更常获得正确结果，而PointNet在计算$C_L$方面提供了更准确的结果。

**Conclusion:** 本文确定了PointNet和MLP是用于预测翼型性能的两种最强机器学习模型，它们各自在预测流体行为和计算升力系数方面表现出不同的优势。

> **ai_Abstract:** 本研究旨在评估机器学习模型，特别是神经网络，在预测翼型性能方面的能力，以克服传统方法在计算速度和精度上的局限。通过对NREL的windAI_bench数据集进行基准测试，并参考AirfRANSdataset，本文评估了MLP、PointNet、GraphSAGE和GUNet四种神经网络模型。结果显示，PointNet和MLP是表现最佳的模型，其中MLP在流体行为预测上表现良好，而PointNet在升力系数计算上更精确。

> **摘要翻译:** 本文研究了神经网络（NNs）作为传统方法替代品的能力，以分析风能和潮汐能行业中使用的翼型性能。目前评估特征升力和阻力系数的方法包括计算流体动力学（CFD）、薄翼型和面板方法，所有这些方法都在计算速度和结果精度之间面临权衡，因此研究了NNs作为替代方案，旨在实现快速准确。因此，本文为美国国家可再生能源实验室（NREL）发布的windAI_bench数据集提供了基准。为了验证基准测试的方法，AirfRANSdataset基准被用作起点和比较点。本研究评估了在25个攻角（4°至20°）范围内的多种翼型上训练的四种神经网络（MLP、PointNet、GraphSAGE、GUNet），以预测流体流动并通过面板方法计算升力系数（$C_L$）。GraphSAGE和GUNet在训练阶段表现良好，但在测试阶段表现不佳。因此，本文将PointNet和MLP确定为测试过的两种最强模型，然而，尽管MLP的结果在预测流体行为方面更常正确，但PointNet的结果在计算$C_L$方面提供了更准确的结果。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [329] [Radiological and Biological Dictionary of Radiomics Features: Addressing Understandable AI Issues in Personalized Breast Cancer; Dictionary Version BM1.0](https://arxiv.org/abs/2507.16041)
> *影像组学特征的放射学和生物学词典：解决个性化乳腺癌中可理解AI问题；词典版本BM1.0*

*Arman Gorji, Nima Sanati, Amir Hossein Pouria, Somayeh Sadat Mehrnia, Ilker Hacihaliloglu, Arman Rahmim, Mohammad R. Salmanpour* | **Category: physics.comp-ph, cs.LG, F.2.2, I.2.7** | **Updated: 2025-07-21**

**Keywords:** 影像组学, 可解释AI, 乳腺癌, BI-RADS, 双词典

**Comment:** 

> **TL;DR:** 本研究开发了一种名为BM1.0的双词典框架，通过将影像组学特征与BI-RADS描述符关联，显著提高了乳腺癌AI模型的可解释性，并在三阴性乳腺癌分类中取得了0.83的准确率，从而促进了影像组学在临床诊断中的应用。

**AI_Comments:** 这项研究通过引入双词典框架（BM1.0），有效解决了影像组学AI模型在乳腺癌诊断中长期存在的“黑箱”问题，显著增强了模型的可解释性。其创新之处在于结合了临床专业知识（CIFID）和数据驱动方法（DDFID），弥合了技术特征与临床语言之间的鸿沟。这对于促进AI在个性化医疗中的应用至关重要，因为它增加了临床医生对AI决策的信任和理解。

<details>
  <summary>Details</summary>

**Motivation:** 影像组学AI模型在乳腺癌诊断中显示出前景，但其缺乏可解释性限制了临床应用。本研究旨在弥合影像组学特征与标准化BI-RADS词汇之间的鸿沟，以解决AI模型的可理解性问题。

**Method:** 本研究提出了一个双词典框架（BM1.0）。首先，通过文献和专家评审，将56个影像组学特征映射到BI-RADS描述符（形状、边缘、内部强化），创建了临床知情特征解释词典（CIFID）。接着，该框架应用于使用来自1549名患者的多机构队列的动态对比增强MRI数据，分类三阴性乳腺癌（TNBC）与非TNBC。研究训练了27种机器学习分类器和27种特征选择方法。此外，利用SHAP解释预测结果，并生成了一个补充的数据驱动特征解释词典（DDFID），用于解释另外52个影像组学特征。

**Result:** 最佳模型（结合方差膨胀因子VIF特征选择和Extra Trees分类器）实现了0.83的平均交叉验证准确率。研究发现，关键预测性影像组学特征与临床知识一致：更高的球形度（圆形/椭圆形）和更低的忙碌度（更均匀的增强）与三阴性乳腺癌相关。该框架不仅证实了已知的影像生物标志物，还发现了新颖且可解释的关联。

**Conclusion:** 这种双词典方法（BM1.0）显著增强了AI模型的透明度，并支持将影像组学特征整合到常规乳腺癌诊断和个性化护理中。

> **ai_Abstract:** 本研究旨在解决影像组学AI模型在乳腺癌诊断中缺乏可解释性的问题。通过开发一个名为BM1.0的双词典框架，该研究将影像组学特征与BI-RADS描述符关联起来，创建了临床知情和数据驱动的解释词典。该框架应用于分类三阴性乳腺癌，取得了0.83的准确率，并揭示了与临床知识一致的可解释性特征关联。此方法显著提升了AI模型的透明度及其在临床实践中的应用潜力。

> **摘要翻译:** 影像组学AI模型在乳腺癌诊断中显示出前景，但往往缺乏可解释性，从而限制了临床应用。本研究通过提出一个双词典框架来弥合影像组学特征（RF）与标准化BI-RADS词汇之间的差距。首先，通过文献和专家评审，将56个RF映射到BI-RADS描述符（形状、边缘、内部强化），创建了一个临床知情特征解释词典（CIFID）。该框架应用于使用来自1549名患者的多机构队列的动态对比增强MRI数据，分类三阴性乳腺癌（TNBC）与非TNBC。我们训练了27种机器学习分类器，并使用了27种特征选择方法。SHapley Additive exPlanations（SHAP）用于解释预测并生成一个补充的数据驱动特征解释词典（DDFID），用于另外52个RF。最佳模型结合了方差膨胀因子（VIF）选择和Extra Trees分类器，实现了0.83的平均交叉验证准确率。关键预测性RF与临床知识一致：更高的球形度（圆形/椭圆形）和更低的忙碌度（更均匀的增强）与TNBC相关。该框架证实了已知的影像生物标志物并发现了新颖、可解释的关联。这种双词典方法（BM1.0）增强了AI模型的透明度，并支持将RF整合到常规乳腺癌诊断和个性化护理中。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

### [605] [Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations](https://arxiv.org/abs/2505.08195)
> *Aitomia：您用于人工智能驱动的原子和量子化学模拟的智能助手*

*Jinming Hu, Hassan Nawaz, Yuting Rui, Lijie Chi, Arif Ullah, Pavlo O. Dral* | **Category: physics.comp-ph, cs.AI, cs.LG, cs.MA, physics.chem-ph** | **Updated: 2025-07-22**

**Keywords:** Aitomia, 原子模拟, 量子化学, 智能助手, 大型语言模型

**Comment:** 

> **TL;DR:** Aitomia是一个基于AI的智能助手平台，旨在通过聊天机器人和AI代理帮助专家和非专家进行原子和量子化学模拟，降低模拟门槛。

**AI_Comments:** Aitomia的创新之处在于将大型语言模型和多代理系统应用于复杂的原子和量子化学模拟，提供了一个用户友好的智能助手。其重要性在于有望显著降低非专业人士进行高级模拟的门槛，从而加速科学研究和开发。该平台通过提供在线云服务和本地部署选项，提高了其可访问性。

<details>
  <summary>Details</summary>

**Motivation:** 开发Aitomia的动机是创建一个由AI驱动的平台，以协助执行人工智能驱动的原子和量子化学（QC）模拟。它旨在帮助专家和指导非专家进行模拟，并最终降低执行原子模拟的门槛，从而使模拟民主化并加速相关领域的研究和开发。

**Method:** Aitomia通过利用大型语言模型来实现其目标，这些模型利用了MLatom生态系统的多功能性，支持AI增强的计算化学任务。该平台配备了聊天机器人和AI代理，并且其多代理实现能够自主执行复杂的计算工作流。

**Result:** Aitomia能够帮助用户设置和运行原子模拟，监控计算状态，分析模拟结果，并以文本和图形形式进行总结。它支持从基态到激发态计算的AI增强计算化学任务，包括几何优化、热化学和光谱计算。它还实现了复杂计算工作流的自主执行。Aitomia是第一个在云计算平台上公开可用的、用于广泛范围原子模拟的智能助手。

**Conclusion:** Aitomia有望降低执行原子模拟的门槛，从而使模拟民主化并加速相关领域的研究和开发。

> **ai_Abstract:** Aitomia是一个新开发的人工智能平台，旨在作为智能助手，协助用户进行原子和量子化学模拟。该平台利用大型语言模型、聊天机器人和多代理系统，帮助用户设置、运行、监控、分析和总结模拟结果，并能自主执行复杂计算工作流。Aitomia是首个公开可用的原子模拟智能助手，旨在降低模拟门槛，促进相关领域的研究和发展。

> **摘要翻译:** 我们开发了 Aitomia——一个由人工智能驱动的平台，旨在协助执行人工智能驱动的原子和量子化学 (QC) 模拟。这个不断发展的智能助手平台配备了聊天机器人和人工智能代理，以帮助专家并指导非专家设置和运行原子模拟、监控其计算状态、分析模拟结果，并以文本和图形形式为用户总结它们。我们通过利用大型语言模型来实现这些目标，这些模型利用了我们 MLatom 生态系统的多功能性，支持从基态到激发态计算的人工智能增强计算化学任务，包括几何优化、热化学和光谱计算。多代理实现使得复杂计算工作流（例如反应焓的计算）的自主执行成为可能。Aitomia 是第一个在云计算平台上公开可用的、用于广泛范围原子模拟的智能助手（Aitomistic Hub，网址为 https://aitomistic.xyz）。它也可以在本地部署，如 http://mlatom.com/aitomia 所述。Aitomia 有望降低执行原子模拟的门槛，从而使模拟民主化并加速相关领域的研究和开发。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

### [658] [On the time integration for phase field modeling of grain growth in additive manufacturing](https://arxiv.org/abs/2507.13492)
> *增材制造中晶粒生长的相场建模时间积分研究*

*Chaoqian Yuan, Chinnapat Panwisawas, Ye Lu* | **Category: physics.comp-ph, cs.NA, math.NA** | **Updated: 2025-07-22**

**Keywords:** 相场模拟, 时间积分, 增材制造, 晶粒生长, 计算效率

**Comment:** 

> **TL;DR:** 本文研究了一种稳定的时间积分算法，用于加速增材制造中的相场模拟，显著增加了时间步长，同时保持了数值稳定性和能量要求，为大规模相场建模提供了高效的数值框架。

**AI_Comments:** 本文的创新点在于引入并验证了稳定的时间积分算法，显著提升了增材制造中相场模拟的计算效率，突破了传统方法在时间步长上的限制。这对于理解和优化增材制造过程中的微观结构演化具有重要意义，并为未来大规模、高精度的相场模拟奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 相场模拟在理解增材制造中的微观结构演化方面至关重要，但计算成本极高，其中一个原因是需要极小的时间步长来解析快速凝固过程中的复杂微观结构演化。

**Method:** 本文研究了使用一类稳定的时间积分算法来加速相场模拟的可能性，通过增加时间步长。基于专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析。

**Result:** 数值结果证实，所提出的方法可以确保相场模拟的数值稳定性和递减的能量要求，与传统显式方法相比，时间步长至少大两个数量级。已针对316L不锈钢进行了2D和3D相场模拟，并使用了相关的物理和动力学参数。

**Conclusion:** 这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模开辟了众多机会。

> **ai_Abstract:** 本文旨在解决增材制造中相场模拟计算成本高昂的问题，其主要原因在于需要极小的时间步长。研究人员提出并开发了一类稳定的时间积分算法，通过理论分析和数值验证，证明该方法能显著增大时间步长（至少两个数量级），同时保持数值稳定性和能量要求。这项工作为高效的相场模拟提供了一个新的数值框架，有望推动大规模相场建模的发展。

> **摘要翻译:** 相场模拟在理解增材制造中的微观结构演化方面发挥着关键作用。然而，它们被发现计算成本极高。其中一个原因是需要极小的时间步长来解析快速凝固过程中的复杂微观结构演化。本文研究了使用一类稳定的时间积分算法来加速此类相场模拟的可能性，通过增加时间步长。基于专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析。数值结果证实，所提出的方法可以确保相场模拟的数值稳定性和递减的能量要求，与传统显式方法相比，时间步长至少大两个数量级。已针对316L不锈钢进行了2D和3D相场模拟，并使用了相关的物理和动力学参数。这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模开辟了众多机会。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [452] [Toward Routine CSP of Pharmaceuticals: A Fully Automated Protocol Using Neural Network Potentials](https://arxiv.org/abs/2507.16218)
> *迈向药物的常规晶体结构预测：一种使用神经网络势能的全自动化协议*

*Zachary L. Glick, Derek P. Metcalf, Scott F. Swarthout* | **Category: physics.chem-ph, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 晶体结构预测, 神经网络势能, 药物发现, 自动化协议, 多晶型

**Comment:** 

> **TL;DR:** 本文介绍了一种名为Lavo-NN的全自动化、高通量晶体结构预测（CSP）协议，该协议使用神经网络势能，显著降低了计算成本和时间，使CSP能够更早地应用于药物发现。

**AI_Comments:** 该论文的创新之处在于引入了Lavo-NN，一种专门为药物晶体结构预测设计的神经网络势能，并将其集成到全自动化、高通量的云端工作流中。这显著降低了CSP的计算成本和时间，解决了长期以来阻碍其在药物发现中广泛应用的障碍。其重要性在于，通过实现CSP的常规化和早期部署，可以为药物研发提供更快的反馈和更深入的洞察，从而加速药物发现过程。该方法在处理大量分子和与实验数据结合方面的能力，预示着其在制药行业具有巨大的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 晶体结构预测（CSP）在药物开发中识别和评估多晶型风险方面非常有用，但其广泛应用受到高计算成本、需要手动指定和专家知识的阻碍。

**Method:** 本文引入了一种全自动化、高通量CSP协议，其效率由Lavo-NN驱动。Lavo-NN是一种新型神经网络势能（NNP），专为药物晶体结构生成和排序而设计和训练。NNP驱动的晶体生成阶段被集成到一个可扩展的基于云的工作流中。

**Result:** 该CSP协议在49个独特分子（几乎都是药物类分子）的广泛回顾性基准测试中得到了验证，成功生成了与所有110个Z'=1实验多晶型物匹配的结构。在该基准测试中，平均CSP计算大约只需要8.4k CPU小时，这与其他协议相比显著减少。通过案例研究解决了实验数据中的歧义，并通过半盲挑战成功识别和排序了三种现代药物的多晶型物，进一步证明了该协议的实用性。

**Conclusion:** 通过显著减少所需的时间和成本，该协议使CSP能够更早地在药物发现流程中常规部署，例如在先导化合物优化阶段。快速周转时间和高通量也使得CSP能够与实验筛选并行运行，为化学家提供实时见解以指导其实验室工作。

> **ai_Abstract:** 本研究提出了一种名为Lavo-NN的全自动化、高通量晶体结构预测（CSP）协议，旨在解决现有CSP方法计算成本高昂和操作复杂的问题。该协议利用专门为药物晶体结构生成和排序训练的神经网络势能，并集成到云端工作流中。通过对49个药物分子的广泛基准测试，该协议成功预测了所有已知的实验多晶型物，并将平均计算时间显著降低至8.4k CPU小时。此外，该协议在解决实验歧义和半盲挑战中展现了实用性，使其能够更早、更常规地应用于药物发现过程，并与实验筛选并行进行，提供实时指导。

> **摘要翻译:** 晶体结构预测（CSP）是药物开发中识别和评估多晶型相关风险的有用工具，但其广泛应用一直受到高计算成本以及需要手动指定和专家知识才能获得有用结果的阻碍。在此，我们介绍了一种旨在克服这些障碍的全自动化、高通量CSP协议。该协议的效率由Lavo-NN驱动，Lavo-NN是一种新型神经网络势能（NNP），专门为药物晶体结构生成和排序而设计和训练。这种NNP驱动的晶体生成阶段被集成到一个可扩展的基于云的工作流中。我们通过对49个独特分子（几乎都是药物类分子）的广泛回顾性基准测试验证了该CSP协议，成功生成了与所有110个Z'=1实验多晶型物匹配的结构。在该基准测试中，平均CSP计算大约需要8.4k CPU小时，与其他协议相比显著减少。通过解决实验数据中歧义的案例研究和仅通过粉末X射线衍射图谱成功识别和排序三种现代药物多晶型物的半盲挑战，进一步证明了该协议的实用性。通过显著减少所需的时间和成本，该协议使CSP能够更早地在药物发现流程中常规部署，例如在先导化合物优化阶段。快速周转时间和高通量也使得CSP能够与实验筛选并行运行，为化学家提供实时见解以指导其实验室工作。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

### [628] [Stable and Accurate Orbital-Free DFT Powered by Machine Learning](https://arxiv.org/abs/2503.00443)
> *机器学习驱动的稳定准确的无轨道密度泛函理论*

*Roman Remme, Tobias Kaczun, Tim Ebert, Christof A. Gehrig, Dominik Geng, Gerrit Gerhartz, Marc K. Ickler, Manuel V. Klockow, Peter Lippmann, Johannes S. Schmidt, Simon Wagner, Andreas Dreuw, Fred A. Hamprecht* | **Category: physics.chem-ph, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 无轨道密度泛函理论, 机器学习, 化学精度, 电子密度, QM9

**Comment:** 

> **TL;DR:** 本文首次使用机器学习方法，实现了无轨道密度泛函理论(OF-DFT)在有机分子上的化学精度，并能收敛到有意义的电子密度，为大型分子体系的高效计算铺平了道路。

**AI_Comments:** 本文的创新之处在于首次将机器学习应用于无轨道密度泛函理论，成功解决了长期以来困扰该领域的精度和收敛性问题。通过实现化学精度，它为大型分子体系的量子化学计算提供了更高效的替代方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** Hohenberg和Kohn证明了电子能量和单粒子电子密度原则上可以通过最小化能量泛函来获得。然而，尽管经过数十年的理论工作，现有的能量泛函近似的精度对于许多应用来说仍然不足，因此尝试通过经验学习来改进它变得合理。

**Method:** 本文采用旋转等变原子机器学习方法，并通过使用来自扰动势的密度来增强训练数据。

**Result:** 首次获得了一个密度泛函，当应用于QM9数据集中的有机分子时，相对于Kohn-Sham参考，其能量达到了化学精度，同时也能收敛到有意义的电子密度。

**Conclusion:** 这项工作表明，机器学习可以在缩小理论与Hohenberg和Kohn愿景的实际实现之间的差距方面发挥关键作用，为大型分子系统中的更高效计算铺平道路。

> **ai_Abstract:** 本研究利用旋转等变原子机器学习，首次实现了无轨道密度泛函理论(OF-DFT)在有机分子上的化学精度，并能生成有意义的电子密度。通过增加扰动势获得的密度数据增强训练集是实现这一突破的关键。这项工作展示了机器学习在弥合DFT理论与实际应用之间差距的巨大潜力，为未来大型分子体系的高效计算奠定了基础。

> **摘要翻译:** Hohenberg和Kohn已经证明，原则上可以通过最小化能量泛函来获得电子能量和单粒子电子密度。尽管数十年的理论工作已经产生了对这种难以捉摸的精确能量泛函越来越忠实的近似，但它们的精度对于许多应用来说仍然不足，因此尝试通过经验学习来获得它是合理的。我们首次使用旋转等变原子机器学习，获得了一个密度泛函，当应用于QM9中的有机分子时，其能量相对于Kohn-Sham参考达到了化学精度，同时也能收敛到有意义的电子密度。用来自扰动势的密度增强训练数据被证明是这些进展的关键。这项工作表明，机器学习可以在缩小理论与Hohenberg和Kohn愿景的实际实现之间的差距方面发挥关键作用，为大型分子系统中的更高效计算铺平道路。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [456] [Improved Wake-Up Time For Euclidean Freeze-Tag Problem](https://arxiv.org/abs/2507.16269)
> *欧几里得冻结标签问题唤醒时间改进*

*Sharareh Alipour, Arash Ahadi, Kajal Baghestani* | **Category: cs.CG, cs.DC, cs.RO** | **Updated: 2025-07-22**

**Keywords:** 冻结标签问题, 唤醒比率, 欧几里得几何, 多机器人系统, 完成时间

**Comment:** 

> **TL;DR:** 本文改进了欧几里得冻结标签问题在二维和三维空间中唤醒比率的上限。

**AI_Comments:** 本文的创新之处在于通过提出新策略或优化现有方法，成功改进了欧几里得冻结标签问题在不同维度下的唤醒比率上限。这对于优化多机器人系统的协调和效率具有重要意义。然而，摘要中并未详细阐述所提出的“新策略”的具体内容。

<details>
  <summary>Details</summary>

**Motivation:** 冻结标签问题（FTP）旨在尽快激活一组最初处于休眠状态的机器人，以最小化完成时间（即激活最后一个机器人所需的时间）。本文的动机是提高欧几里得冻结标签问题的唤醒比率性能。

**Method:** 对于$(\mathbb{R}^2, \ell_2)$，作者改进了先前的上限。对于$\mathbb{R}^3$中的情况，作者提出了一种新的策略。

**Result:** 在$(\mathbb{R}^2, \ell_2)$中，唤醒比率的上限从4.62改进到4.31。在$(\mathbb{R}^3, \ell_1)$中，提出了一种新策略，唤醒比率达到12（此前为13）。在$(\mathbb{R}^3, \ell_2)$中，提出了一种新策略，唤醒比率达到12.76（此前为$13\sqrt{3}$）。

**Conclusion:** 本文成功改进了欧几里得冻结标签问题在不同维度和范数下的唤醒比率上限，展示了更高效的机器人激活策略。

> **ai_Abstract:** 本文探讨了欧几里得冻结标签问题，旨在最小化机器人群体的唤醒时间。作者改进了$(\mathbb{R}^2, \ell_2)$中唤醒比率的现有上限，从4.62降至4.31。此外，对于$\mathbb{R}^3$中的问题，他们提出了一种新策略，显著降低了$(\mathbb{R}^3, \ell_1)$和$(\mathbb{R}^3, \ell_2)$的唤醒比率，分别达到12和12.76，优于之前的最佳结果。

> **摘要翻译:** 冻结标签问题（FTP）涉及从一个单一的清醒机器人开始，尽快激活一组最初处于休眠状态的机器人。一旦被激活，机器人就可以协助唤醒其他机器人。每个活跃的机器人以单位速度移动。目标是最小化完成时间，即激活最后一个机器人所需的时间。一个关键的性能指标是唤醒比率，定义为在任何主要位置激活任意数量机器人所需的最大时间。这项工作侧重于$\mathbb{R}^d$中$\ell_p$范数下的几何（欧几里得）FTP，其中每个休眠机器人与单一活跃机器人之间的初始距离最大为1。对于$(\mathbb{R}^2, \ell_2)$，我们将之前4.62的上限（[7], CCCG 2024）改进到4.31。已知3.82是唤醒比率的下限。在$\mathbb{R}^3$中，我们提出了一种新策略，对于$(\mathbb{R}^3, \ell_1)$实现了12的唤醒比率，对于$(\mathbb{R}^3, \ell_2)$实现了12.76的唤醒比率，分别改进了[2]中报告的13和$13\sqrt{3}$的先前界限。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [472] [Unbeatable imitation of a friend](https://arxiv.org/abs/2507.16221)
> *朋友的不可战胜模仿*

*Masahiko Ueda* | **Category: physics.soc-ph, cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 不可战胜模仿, 模仿朋友, 零决定策略, 重复博弈, 存在条件

**Comment:** 16 pages, 2 figures

> **TL;DR:** 本文研究了在重复博弈中“模仿朋友”的不可战胜模仿的存在条件，发现其条件比不可战胜的零决定策略的存在条件更强，但两者都非常有限。

**AI_Comments:** 本文的创新之处在于将不可战胜模仿的研究范围从“模仿对手”扩展到“模仿朋友”这一新的情境。这填补了现有研究的空白，并揭示了不同模仿策略下成功条件的关键差异。研究结果对于理解多智能体系统中的合作与竞争行为具有重要意义，尤其是在社交网络或团队协作等场景中。其局限性在于发现这些条件都非常有限，暗示不可战胜的模仿在实际应用中可能不那么普遍。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究主要集中在“模仿对手”的不可战胜模仿，但指出“模仿朋友”的情况会产生不同的结果。因此，本文旨在探究“模仿朋友”情境下不可战胜模仿的存在条件。

**Method:** 本文研究了“模仿朋友”情境下不可战胜模仿的存在条件。

**Result:** 研究发现，“模仿朋友”的不可战胜模仿的存在条件比不可战胜的零决定策略的存在条件更强，同时两者都非常有限。研究结果表明，即使在“模仿朋友”情境下，两者之间也存在强烈的关系。

**Conclusion:** 在重复博弈中，“模仿朋友”的不可战胜模仿的存在条件比“模仿对手”的零决定策略更严格，但两者都非常有限，且它们之间存在紧密联系。

> **ai_Abstract:** 本文在博弈论框架下，深入探讨了“模仿朋友”情境中不可战胜模仿的存在条件。与以往研究主要关注“模仿对手”不同，本文发现“模仿朋友”的不可战胜模仿的存在条件比不可战胜的零决定策略更为严格，尽管两者都具有局限性。研究结果强调了在“模仿朋友”场景中，不可战胜模仿与零决定策略之间存在显著关联。

> **摘要翻译:** 模仿有时在多智能体情境中能取得成功，尽管它非常简单。在博弈论中，模仿的成功已被描述为对其他智能体的不可战胜性。先前的研究明确了在重复博弈中模仿不可战胜的条件，并阐明了不可战胜模仿的存在与支付控制策略（称为零决定策略）的存在密切相关。然而，先前的研究主要集中在“模仿对手”。有人指出，模仿同一群体中的其他玩家以及模仿其他群体中扮演相同角色的其他玩家通常会导致不同的结果。在这里，我们调查了后者“模仿朋友”情境下不可战胜模仿的存在条件。我们发现它比不可战胜的零决定策略的存在条件更强，而两者都非常有限。我们的发现表明，即使在“模仿朋友”情境下，两者之间也存在强烈的关系。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [503] [Spiking neurons as predictive controllers of linear systems](https://arxiv.org/abs/2507.16495)
> *脉冲神经元作为线性系统的预测控制器*

*Paolo Agliati, André Urbano, Pablo Lanillos, Nasir Ahmad, Marcel van Gerven, Sander Keemink* | **Category: q-bio.NC, cs.NE, cs.SY, eess.SY** | **Updated: 2025-07-22**

**Keywords:** 脉冲神经网络, 预测控制, 线性系统, 稀疏活动, 神经形态硬件

**Comment:** 

> **TL;DR:** 本文提出了一种可扩展的脉冲神经网络（SNN）控制方法，直接使用稀疏脉冲作为控制信号，无需速率编码，并成功应用于线性系统控制。

**AI_Comments:** 这项研究的创新之处在于其直接将稀疏脉冲作为控制信号，而非依赖于连续的速率编码或滤波近似，这克服了传统脉冲控制在可扩展性和分析可追踪性方面的挑战。其从生物学和最优控制理论中汲取灵感，并提供了闭式数学推导，增强了模型的理论严谨性。这项工作对于理解生物神经元如何实现精确控制以及推动神经形态计算硬件的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有脉冲控制方法通常依赖于滤波脉冲信号以近似模拟控制，导致需要连续能量输入下游系统，且难以扩展到大型网络并降低了分析可追踪性。本文旨在克服这些局限性，实现稀疏神经活动下的任务特定脉冲控制。

**Method:** 作者提出了一种新的脉冲发放规则，即只有当脉冲能使动态系统更接近目标时才发射。基于此原则，他们推导了脉冲神经网络所需的连接性，并展示了其如何成功控制线性系统。该方法利用了最优控制和神经科学理论的启发，规避了对基于速率的表示的需求。

**Result:** 研究表明，所提出的方法能够成功控制线性系统。对于物理受限系统，需要预测控制，并且控制信号会利用下游系统的被动动力学来达到目标。此外，该控制方法可以扩展到高维网络和系统。在所有情况下，网络连接性、网络动力学和控制目标都保持了闭式数学推导。

**Conclusion:** 这项工作增进了对脉冲神经网络作为生物启发控制器的理解，为真实神经元如何施加控制提供了见解，并为神经形态硬件设计中的应用提供了可能性。

> **ai_Abstract:** 本文提出了一种创新的脉冲神经网络（SNN）控制方法，直接利用稀疏脉冲作为控制信号，而非传统的速率编码。该方法受最优控制和神经科学理论启发，定义了一个新的脉冲发放规则，即仅在脉冲能使系统接近目标时才发射。研究推导了SNN所需的连接性，并证明其能成功控制线性系统，包括利用被动动力学处理受限系统，并能扩展到高维网络。这项工作为SNN作为生物启发控制器提供了新的理解，并为神经形态硬件设计开辟了应用前景。

> **摘要翻译:** 神经元通过稀疏且极其短暂的电脉冲（即尖峰）与下游系统进行通信。利用这些事件，它们控制着各种目标，例如神经肌肉单元、神经分泌系统以及连接电路中的其他神经元。这催生了将脉冲神经元作为控制器的想法，其中尖峰是控制信号。直接使用瞬时事件作为控制输入，也称为“脉冲控制”，具有挑战性，因为它无法很好地扩展到更大的网络，并且分析可追踪性较低。因此，当前的脉冲控制通常依赖于滤波脉冲信号以近似模拟控制。这最终意味着脉冲神经网络（SNNs）必须输出连续控制信号，从而需要向下游系统连续输入能量。在这里，我们规避了对基于速率的表示的需求，提供了一种使用稀疏神经活动进行任务特定脉冲控制的可扩展方法。在此过程中，我们从最优控制和神经科学理论中汲取灵感，并定义了一种脉冲规则，即只有当脉冲能使动态系统更接近目标时才发射。根据这一原则，我们推导了SNN所需的连接性，并表明它能够成功控制线性系统。我们表明，对于物理受限系统，需要预测控制，并且控制信号最终会利用下游系统的被动动力学来达到目标。最后，我们表明该控制方法可以扩展到高维网络和系统。重要的是，在所有情况下，我们都保持了网络连接性、网络动力学和控制目标的闭式数学推导。这项工作增进了对SNN作为生物启发控制器的理解，为真实神经元如何施加控制提供了见解，并为神经形态硬件设计中的应用提供了可能性。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [693] [Interpretable Embeddings of Speech Enhance and Explain Brain Encoding Performance of Audio Models](https://arxiv.org/abs/2507.16080)
> *可解释的语音嵌入增强并解释音频模型的脑编码性能*

*Riki Shimizu, Richard J. Antonello, Chandan Singh, Nima Mesgarani* | **Category: q-bio.NC, cs.SD** | **Updated: 2025-07-21**

**Keywords:** 语音感知, 自监督模型, 可解释性, 脑编码, ECoG

**Comment:** 7pages, 4 figures

> **TL;DR:** 可解释特征比自监督模型更能预测大脑对语音的反应，并且结合两者效果最佳，揭示了自监督模型中未被理解的低层和语义信息。

**AI_Comments:** 这项研究通过引入可解释特征来揭示自监督语音模型的“黑箱”内部机制，具有重要的创新性。它挑战了关于SSMs处理低级声学信息和高级语义信息的普遍假设，为理解语音感知和优化未来模型提供了新的视角。其发现表明，可解释特征不仅能独立预测神经活动，还能增强现有黑箱模型的性能。

<details>
  <summary>Details</summary>

**Motivation:** 自监督语音模型（SSMs）在人类语音感知方面表现出色，但其内部表示是黑盒，不清楚是什么驱动它们与大脑反应的对齐。

**Method:** 构建了基于六种可解释特征家族（梅尔频谱、Gabor滤波器组特征、语音存在、语音、句法和语义问答特征）的线性编码模型，并结合三种最先进的SSMs（Whisper, HuBERT, WavLM）的上下文嵌入，量化了每种特征类别捕获的共享和独特的神经方差。进行了方差分解分析。

**Result:** 1. 可解释模型比任何SSM模型更能准确预测ECoG对语音的反应。2. 结合SSM表示与可解释特征能产生最佳的神经预测。3. SSM的后期层保留了对语音神经编码关键的频率带（100-1000 Hz）。4. SSM编码了与大脑相关的语义信息，这些信息不能简化为低级特征，并随上下文长度和模型大小的增加而改善。

**Conclusion:** 强调了使用精细、可解释的特征在理解语音感知中的重要性。

> **ai_Abstract:** 本文研究了自监督语音模型（SSMs）与大脑语音感知的对齐机制。通过构建基于可解释特征的线性编码模型，并结合SSMs的嵌入，发现可解释特征在预测大脑对语音的反应上优于SSMs，且两者结合能获得最佳预测。研究进一步揭示SSMs即使在后期层也保留了关键的低频声学信息，并编码了独立的语义信息，这有助于理解SSMs的脑编码性能。

> **摘要翻译:** 自监督语音模型（SSMs）被越来越多地誉为比传统手工特征模型更强大的人类语音感知计算模型。然而，由于其表示本质上是黑盒，目前尚不清楚是什么驱动它们与大脑反应的对齐。为了弥补这一点，我们从六种可解释特征家族构建了线性编码模型：梅尔频谱、Gabor滤波器组特征、语音存在、语音、句法和语义问答特征，以及来自三种最先进SSMs（Whisper、HuBERT、WavLM）的上下文嵌入，量化了每种特征类别捕获的共享和独特的神经方差。与普遍假设相反，我们的可解释模型预测脑电图（ECoG）对语音的反应比任何SSM都更准确。此外，用可解释特征增强SSM表示产生了最佳的整体神经预测，显著优于任何单独的类别。进一步的方差分解分析揭示了SSM表示中以前未解决的、有助于其神经对齐的组件：1. 尽管普遍认为SSMs的后期层丢弃了低级声学信息，但这些模型压缩并优先保留了对语音神经编码至关重要的频带（100-1000 Hz）。2. 与之前的说法相反，SSMs编码了与大脑相关的语义信息，这些信息不能简化为低级特征，并随上下文长度和模型大小的增加而改善。这些结果强调了使用精细、可解释的特征在理解语音感知中的重要性。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [537] [Handcrafted vs. Deep Radiomics vs. Fusion vs. Deep Learning: A Comprehensive Review of Machine Learning -Based Cancer Outcome Prediction in PET and SPECT Imaging](https://arxiv.org/abs/2507.16065)
> *手工特征 vs. 深度影像组学 vs. 融合 vs. 深度学习：基于机器学习的PET和SPECT成像癌症结局预测的综合综述*

*Mohammad R. Salmanpour, Somayeh Sadat Mehrnia, Sajad Jabarzadeh Ghandilu, Zhino Safahi, Sonya Falahati, Shahram Taeb, Ghazal Mousavi, Mehdi Maghsoudi, Ahmad Shariftabrizi, Ilker Hacihaliloglu, Arman Rahmim* | **Category: physics.med-ph, cs.CV** | **Updated: 2025-07-21**

**Keywords:** 机器学习, 影像组学, 深度学习, PET, SPECT, 癌症结局预测

**Comment:** 

> **TL;DR:** 本系统综述比较了机器学习方法（包括深度学习和影像组学）在PET和SPECT成像中预测癌症结局的性能，发现深度影像组学模型准确性最高，融合模型AUC最高，并指出数据质量和标准化方面的常见限制。

**AI_Comments:** 这项系统综述具有重要意义，因为它对PET和SPECT成像中基于机器学习的癌症结局预测方法进行了全面的比较分析。它不仅量化了不同方法的性能差异，如DRF和融合模型，还明确指出了当前研究的普遍局限性，例如数据不平衡、缺失数据和缺乏标准化。这些发现为未来的研究和临床实践提供了明确的方向，强调了数据质量、标准化流程和可解释性在推动该领域发展中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习（包括深度学习和影像组学）越来越多地用于PET和SPECT成像的癌症结局预测，但手工影像组学特征（HRF）、深度影像组学特征（DRF）、深度学习模型和混合融合方法的比较性能在临床应用中仍不一致。

**Method:** 本研究对2020年至2025年间发表的226项将机器学习应用于PET或SPECT成像进行结局预测的研究进行了系统综述。每项研究均使用包含59个项目（涵盖数据集构建、特征提取、验证方法、可解释性和偏倚风险）的框架进行评估，并提取了模型类型、癌症部位、成像模态和性能指标等关键细节。

**Result:** PET研究（95%）通常优于SPECT研究，这可能归因于其更高的空间分辨率和敏感性。深度影像组学特征（DRF）模型实现了最高的平均准确率（0.862），而融合模型则产生了最高的AUC（0.861）。方差分析证实性能存在显著差异（准确率：p=0.0006，AUC：p=0.0027）。常见限制包括类不平衡处理不足（59%）、数据缺失（29%）和人群多样性低（19%）。只有48%的研究遵守了IBSI标准。

**Conclusion:** 这些发现强调了需要标准化流程、提高数据质量和开发可解释的人工智能，以支持临床整合。

> **ai_Abstract:** 本系统综述全面比较了基于机器学习（包括手工影像组学、深度影像组学、深度学习和融合方法）在PET和SPECT成像中进行癌症结局预测的性能。通过分析226项研究，结果显示PET优于SPECT，深度影像组学模型在准确性上表现最佳，而融合模型在AUC上表现最佳。研究还揭示了现有文献中数据处理、标准化和可解释性方面的常见不足，强调了未来研究和临床应用中对标准化流程、高质量数据和可解释AI的需求。

> **摘要翻译:** 机器学习（ML），包括深度学习（DL）和基于影像组学的方法，正越来越多地用于PET和SPECT成像的癌症结局预测。然而，手工影像组学特征（HRF）、深度影像组学特征（DRF）、深度学习模型和混合融合方法的比较性能在临床应用中仍不一致。本系统综述分析了2020年至2025年间发表的226项将机器学习应用于PET或SPECT成像进行结局预测的研究。每项研究均使用包含59个项目（涵盖数据集构建、特征提取、验证方法、可解释性和偏倚风险）的框架进行评估。我们提取了关键细节，包括模型类型、癌症部位、成像模态以及准确率和曲线下面积（AUC）等性能指标。基于PET的研究（95%）通常优于使用SPECT的研究，这可能归因于其更高的空间分辨率和敏感性。深度影像组学特征（DRF）模型实现了最高的平均准确率（0.862），而融合模型则产生了最高的AUC（0.861）。方差分析证实性能存在显著差异（准确率：p=0.0006，AUC：p=0027）。常见限制包括类不平衡处理不足（59%）、数据缺失（29%）和人群多样性低（19%）。只有48%的研究遵守了IBSI标准。这些发现强调了需要标准化流程、提高数据质量和开发可解释的人工智能，以支持临床整合。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathfa'></a>
## math.FA 

### [604] [How averaged is the projection?](https://arxiv.org/abs/2312.15421)
> *投影的平均性如何？*

*Shuang Song* | **Category: math.FA, cs.NA, math.NA, math.OC** | **Updated: 2025-07-22**

**Keywords:** 投影算子, 平均算子, 非扩张性, 算子组合, 下界

**Comment:** This manuscript is not yet mature. A significantly revised and more
  complete version will be uploaded at a later date

> **TL;DR:** 本文通过发展平均算子理论，给出了一个精确结果，从而深化了投影算子是严格非扩张的已知结论，并探讨了算子组合的平均性。

**AI_Comments:** 本文通过引入平均算子理论，对投影算子的性质进行了深入分析，特别是对其严格非扩张性提供了更精确的刻画，这对于分析、优化和算法领域的理论研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 投影算子在分析、优化和算法中很重要，且已知它们是严格非扩张的。本文旨在提供一个更精确的结果来深化这一已知结论。

**Method:** 发展平均算子理论，提供一个下界，给出关于算子组合平均性的结果，并使用非线性例子进行说明。

**Result:** 提供了使投影算子是严格非扩张这一已知结果更精确的精确结果；发展了平均算子理论并提供了下界；给出了算子组合平均性的结果；提供了非线性例子。

**Conclusion:** 本文通过引入平均算子理论和提供精确结果，深化了对投影算子性质的理解，特别是其严格非扩张性。

> **ai_Abstract:** 本文研究了投影算子的平均性，通过发展平均算子理论，提供了一个精确结果，从而深化了投影算子是严格非扩张的已知结论。研究还给出了平均算子的下界以及算子组合的平均性结果，并通过非线性例子进行了说明。

> **摘要翻译:** 投影算子在分析、优化和算法中非常重要。众所周知，这些算子是严格非扩张的。在本文中，我们提供了一个精确结果，它使这个众所周知的结果更加精确。我们发展了平均算子理论并提供了一个下界。我们给出了一个关于算子组合平均性的结果。我们还提供了一些非线性例子来阐明我们的结果。

</details>

[⬆️ 返回分类顶部](#mathfa) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [637] [Modeling Maritime Transportation Behavior Using AIS Trajectories and Markovian Processes in the Gulf of St. Lawrence](https://arxiv.org/abs/2506.00025)
> *建模圣劳伦斯湾海运交通行为：AIS轨迹与马尔可夫过程的应用*

*Gabriel Spadon, Vaishnav Vaidheeswaran, Md Mahbub Alam, Ruixin Song, Floris Goerlandt, Ronald Pelot* | **Category: stat.AP, cs.CE, math.PR** | **Updated: 2025-07-21**

**Keywords:** 海运交通, AIS轨迹, 马尔可夫链, COVID-19, 圣劳伦斯湾

**Comment:** 

> **TL;DR:** 利用AIS数据和马尔可夫链模型分析圣劳伦斯湾的海运行为，并揭示疫情期间的交通模式变化。

**AI_Comments:** 该论文创新性地将离散时间马尔可夫链应用于AIS轨迹数据，以建模和分析大规模海运交通行为，并引入了六边形单元格离散化方法，这提供了一种精细化的时空分析视角。其重要性在于，该框架不仅能揭示常规的船舶移动模式，还能有效识别和量化如COVID-19大流行等外部因素对海运行为造成的短期和长期影响，为交通规划和应急管理提供了关键的决策支持工具。

<details>
  <summary>Details</summary>

**Motivation:** 分析大规模海运行为数据对于运营规划、环境管理和治理至关重要。特别是，该研究旨在分析COVID-19大流行引起的海运中断。

**Method:** 该研究提出了一个基于离散时间马尔可夫链的时空分析框架，用于模拟圣劳伦斯湾的船舶移动模式。具体方法包括：将海域离散化为六边形单元格；利用单元格转换频率和停留时间构建不同船舶类型的移动特征；利用这些特征构建起点-终点矩阵和空间转换概率模型，以表征多时间分辨率下的海运动态。研究重点关注商船、渔船和客船。

**Result:** 研究揭示了在空间上不相连的区域中持续存在的特定船舶移动特征，表明某些行为不随时间变化。相反，研究观察到在大流行期间客船和渔船之间存在时间偏差，反映了社会隔离措施和运营限制对该区域非必需海运交通的影响。

**Conclusion:** 该研究所贡献的方法学为交通规划提供了重要的行为分析工具。研究结果表明，船舶特定的移动特征在不同区域保持不变，但疫情期间客船和渔船的移动模式受到显著的、暂时的干扰。

> **ai_Abstract:** 该研究基于离散时间马尔可夫链和AIS轨迹数据，构建了一个时空分析框架，用于建模圣劳伦斯湾的船舶移动行为，并特别关注COVID-19疫情造成的影响。通过将海域划分为六边形单元格并分析船舶的移动特征、起点-终点矩阵和空间转换概率，研究发现不同船舶类型存在持续的移动特征，但疫情期间客船和渔船的移动模式出现了显著且暂时的偏差，这反映了社会隔离措施和运营限制对其非必需交通的影响。该方法为海运交通规划提供了有价值的行为分析工具。

> **摘要翻译:** 海运交通是全球经济的核心，分析其大规模行为数据对于运营规划、环境管理和治理至关重要。这项工作提出了一个基于离散时间马尔可夫链的时空分析框架，用于模拟圣劳伦斯湾的船舶移动模式，特别强调了COVID-19大流行引起的中断。我们将海域离散化为六边形单元格，并利用单元格转换频率和停留时间构建不同船舶类型的移动特征。这些特征用于构建起点-终点矩阵和空间转换概率模型，以表征多时间分辨率下的海运动态。研究重点关注商船、渔船和客船，分析了大流行期间移动行为的时间演变，突出了对重复交通模式的显著但短暂的中断。我们对本文贡献的方法学有助于进行广泛的行为分析，这对交通规划至关重要。因此，我们的发现揭示了在空间上不相连的区域中持续存在的特定船舶移动特征，表明行为不随时间变化。相反，我们观察到在大流行期间客船和渔船之间存在时间偏差，反映了社会隔离措施和运营限制对该区域非必需海运交通的影响。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [640] [On the Minimal Denominator Problem in Function Fields](https://arxiv.org/abs/2501.00171)
> *函数域中的最小分母问题*

*Noy Soffer Aranov* | **Category: math.NT, cs.NA, math.NA, 11J61, 11J04, 11J13** | **Updated: 2025-07-21**

**Keywords:** 最小分母问题, 函数域, 概率分布函数

**Comment:** Minor errors corrected

> **TL;DR:** 本文研究函数域中的最小分母问题，计算了特定条件下最小分母Q的度数的概率分布函数，并讨论了相关推广。

**AI_Comments:** 本文的创新之处在于将Chen和Haynes的理论推广到函数域，解决了函数域中的最小分母问题。通过计算概率分布函数，为理解函数域中有理函数的分布提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究函数域中的最小分母问题，并将其视为Chen和Haynes论文的函数域推广。

**Method:** 本文通过计算随机变量的概率分布函数来研究最小分母问题，该随机变量返回在固定半径的球内包含P/Q形式的有理函数的最小分母Q的度数。此外，还讨论了返回最小度数分母的随机变量的分布以及高维和P-adic推广。

**Result:** 本文计算了特定条件下最小分母Q的度数的概率分布函数。此外，还讨论了返回最小度数分母的随机变量的分布以及高维和P-adic推广。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了函数域中的最小分母问题。研究人员计算了在给定点周围固定半径的球内包含特定形式有理函数的最小分母Q的度数的概率分布函数。此外，论文还讨论了最小度数分母的随机变量分布，并探讨了高维和P-adic推广，将其视为对Chen和Haynes相关工作的函数域泛化。

> **摘要翻译:** 我们研究函数域中的最小分母问题。特别是，我们计算了随机变量的概率分布函数，该变量返回最小分母Q的度数，使得一个点周围固定半径的球包含P/Q形式的有理函数。此外，我们还讨论了返回最小度数分母的随机变量的分布，以及高维和P-adic推广。这可以被视为Chen和Haynes论文的函数域推广。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [676] [Tagging fully hadronic exotic decays of the vectorlike $\mathbf{B}$ quark using a graph neural network](https://arxiv.org/abs/2505.07769)
> *使用图神经网络标记矢量类B夸克的全强子奇异衰变*

*Jai Bardhan, Tanumoy Mandal, Subhadip Mitra, Cyrin Neeraj, Mihir Rawat* | **Category: hep-ph, cs.LG, hep-ex** | **Updated: 2025-07-22**

**Keywords:** 矢量类B夸克, 图神经网络, 奇异衰变, 深度学习, LHC

**Comment:** 13 pages, 10 figures, 3 tables

> **TL;DR:** 使用图神经网络和深度神经网络来探测LHC上矢量类B夸克的全强子奇异衰变，提高了探测灵敏度。

**AI_Comments:** 这项研究的创新之处在于将图神经网络应用于高能物理中难以探测的全强子奇异衰变道，有效克服了传统方法在处理大量标准模型背景和缺乏轻子信号时的挑战。它展示了深度学习在粒子物理数据分析中的强大潜力，特别是在复杂多体末态重建和背景抑制方面的能力。

<details>
  <summary>Details</summary>

**Motivation:** 探测大型强子对撞机（LHC）上矢量类B夸克到规范单态（伪）标量场$\Phi$和b夸克的奇异衰变。由于标准模型背景较大且缺乏轻子信号，这是一个难以探测的道。

**Method:** 采用了一种混合深度学习模型，该模型包含一个图神经网络（GNN）和一个随后的深度神经网络（DNN）。

**Result:** 估计这种先进的深度学习分析流程可以达到与半轻子模式相当的性能，在HL-LHC上，当B夸克完全奇异衰变（BR$(B \to b\Phi) = 100\%$）时，发现极限可达约$M_B=1.8$ TeV，排除极限可达约$2.4$ TeV。

**Conclusion:** 混合深度学习模型（GNN+DNN）显著提高了在LHC上探测矢量类B夸克全强子奇异衰变的灵敏度，使其性能与半轻子模式相当。

> **ai_Abstract:** 这项研究延续了之前的工作，探究了LHC上矢量类B夸克奇异衰变为规范单态（伪）标量场$\Phi$和b夸克的前景。针对全强子末态（$2b+4j$或$6b$）探测困难的问题，研究提出并使用了一种结合图神经网络和深度神经网络的混合深度学习模型。结果表明，该模型能将B夸克的发现极限提升至1.8 TeV，排除极限提升至2.4 TeV，性能可媲美半轻子模式。

> **摘要翻译:** 在[J. Bardhan et al., Machine learning-enhanced search for a vectorlike singlet B quark decaying to a singlet scalar or pseudoscalar, Phys. Rev. D 107 (2023) 115001; arXiv:2212.02442]中我们早期的研究之后，我们研究了LHC上成对产生的矢量类B夸克奇异衰变为新的规范单态（伪）标量场$\Phi$和b夸克的前景。在电弱对称性破缺后，$\Phi$主要衰变为$gg/bb$末态，导致全强子$2b+4j$或$6b$特征。由于标准模型背景较大且缺乏轻子信号，这是一个难以探测的道。为了克服这一挑战，我们采用了一种混合深度学习模型，其中包含一个图神经网络，随后是一个深度神经网络。我们估计，这种最先进的深度学习分析流程可以达到与半轻子模式相当的性能，在HL-LHC上，当B夸克完全奇异衰变时，发现（排除）极限可达约$M_B=1.8\:(2.4)$ TeV，即BR$(B \to b\Phi) = 100\%$。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [688] [Learning novel representations of variable sources from multi-modal $\textit{Gaia}$ data via autoencoders](https://arxiv.org/abs/2505.16320)
> *通过自编码器从多模态盖亚数据中学习变源的新表示*

*P. Huijse, J. De Ridder, L. Eyer, L. Rimoldini, B. Holl, N. Chornay, J. Roquette, K. Nienartowicz, G. Jevardat de Fombelle, D. J. Fritzewski, A. Kemp, V. Vanlaer, M. Vanrespaille, H. Wang, M. I. Carnerero, C. M. Raiteri, G. Marton, M. Madarász, G. Clementini, P. Gavras, C. Aerts* | **Category: astro-ph.IM, cs.LG** | **Updated: 2025-07-22**

**Keywords:** Gaia DR3, 变分自编码器, 变星, 多模态数据, 非监督分类

**Comment:** Manuscript accepted on Astronomy & Astrophysics, 20 pages, 20
  figures, 2 tables

> **TL;DR:** 本文提出并评估了一种机器学习方法，利用变分自编码器从多模态盖亚DR3数据中学习变星和类星体变异性的新颖潜在表示，以实现非监督分类，并展示其在天体物理发现和变异性分析任务中的潜力。

**AI_Comments:** 该论文的创新之处在于首次系统地结合了Gaia的多模态数据（光谱、光度差异、光变曲线）并通过变分自编码器学习统一的潜在表示，实现了变源的非监督分类。这为处理海量天文数据并自动发现新的变异性类别或异常源提供了一种强大的新工具。其重要性在于为未来的Gaia数据发布（如DR4）提供了先进的数据分析方法，有望加速天体物理学领域的发现。

<details>
  <summary>Details</summary>

**Motivation:** Gaia DR3首次发布了数百万变源的历元测光数据、BP/RP低分辨率平均光谱和监督分类结果。这个庞大的数据集提供了结合多种Gaia数据产品研究其变异性的独特机会。为准备DR4，需要一种能够整合多种Gaia数据产品以实现恒星和类星体变异性非监督分类的机器学习方法。

**Method:** 提出并评估了一种机器学习方法。使用4百万Gaia DR3源数据集训练了三个变分自编码器（VAE），它们是用于数据压缩和生成的人工神经网络（ANN）。一个VAE在Gaia XP低分辨率光谱上训练，另一个基于Gaia G波段星等差异分布的新方法，第三个在折叠的Gaia G波段光变曲线上训练。每个Gaia源被压缩成15个数字，代表由这三个模型输出组合生成的15维潜在空间中的坐标。

**Result:** ANN学习到的潜在表示有效区分了Gaia DR3中存在的主要变异性类别，通过对潜在空间的监督和非监督分类分析得到了证实。结果强调了光变曲线和低分辨率光谱数据之间的强协同作用，突出了结合不同Gaia数据产品的好处。潜在变量的二维投影揭示了许多过密度，其中大多数与天体物理性质高度相关，显示了该潜在空间在天体物理发现方面的潜力。

**Conclusion:** 本文表明，我们新颖的潜在表示的特性使其对变异性分析任务（包括分类、聚类和异常值检测）具有极高的价值。

> **ai_Abstract:** 本文提出了一种创新的机器学习方法，利用三个变分自编码器（VAE）从多模态Gaia DR3数据中学习变源的潜在表示。通过整合Gaia XP光谱、G波段星等差异分布以及G波段光变曲线数据，模型将每个源压缩成15维的潜在空间坐标。研究表明，这种学习到的潜在表示能够有效区分Gaia DR3中的主要变异性类别，并揭示了不同Gaia数据产品之间的强协同作用。此外，该潜在空间在天体物理发现和变异性分析任务（如分类、聚类和异常值检测）中展现出巨大潜力。

> **摘要翻译:** 盖亚数据发布3（DR3）首次公布了数百万变源的历元测光、BP/RP（XP）低分辨率平均光谱以及监督分类结果。这一庞大的数据集为结合多种盖亚数据产品研究其变异性提供了独特的机会。为准备DR4，我们提出并评估了一种机器学习方法，该方法能够整合多种盖亚数据产品，以实现恒星和类星体变异性的非监督分类。我们使用400万盖亚DR3源数据集训练了三个变分自编码器（VAE），它们是专为数据压缩和生成而设计的人工神经网络（ANN）。一个VAE在盖亚XP低分辨率光谱上训练，另一个基于盖亚G波段星等差异分布的新方法，第三个在折叠的盖亚G波段光变曲线上训练。每个盖亚源被压缩成15个数字，代表由这三个模型输出组合生成的15维潜在空间中的坐标。通过对潜在空间的监督和非监督分类分析表明，ANN学习到的潜在表示有效区分了盖亚DR3中存在的主要变异性类别。结果强调了光变曲线和低分辨率光谱数据之间的强协同作用，突出了结合不同盖亚数据产品的好处。潜在变量的二维投影揭示了许多过密度，其中大多数与天体物理性质高度相关，显示了该潜在空间在天体物理发现方面的潜力。我们表明，我们新颖的潜在表示的特性使其对变异性分析任务（包括分类、聚类和异常值检测）具有极高的价值。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

### [740] [A Generative Model for Disentangling Galaxy Photometric Parameters](https://arxiv.org/abs/2507.15898)
> *一种用于解缠星系测光参数的生成模型*

*Keen Leung, Colen Yan, Jun Yin* | **Category: astro-ph.IM, astro-ph.GA, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 星系, 测光参数, 生成模型, 条件自编码器, 形态学

**Comment:** 12 pages, 5 figures

> **TL;DR:** 本文提出了一种条件自编码器（CAE）框架，用于高效、准确地从大规模星系图像中解缠并推断星系形态参数。

**AI_Comments:** 这项工作提出了一种创新的基于生成模型（CAE）的方法来解决大规模星系图像形态参数提取的计算挑战。其核心创新在于利用CAE实现参数的“解缠”，这对于理解星系物理性质至关重要。该方法在处理未来海量天文数据方面具有显著潜力，提供了一个比传统拟合方法更高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 正在进行和未来的测光巡天将产生前所未有的星系图像数据量，需要鲁棒、高效的方法来大规模推导星系形态参数。传统的参数化光廓线拟合方法计算成本过高，无法应用于数十亿个星系源。

**Method:** 研究人员提出了一种条件自编码器（CAE）框架，用于同时建模和表征星系形态。该CAE模型通过GalSim生成的逼真模拟星系图像进行训练，这些图像涵盖了广泛的星系类型、测光参数（如通量、半光半径、Sersic指数、椭圆度）和观测条件。通过将每个星系图像编码为基于关键参数的低维潜在表示，模型能够以解缠的方式有效恢复这些形态特征，同时重建原始图像。

**Result:** 结果表明，CAE方法可以准确高效地推断复杂的结构属性。

**Conclusion:** 该方法为现有方法提供了一个强大的替代方案。

> **ai_Abstract:** 本文针对未来大规模星系图像数据处理的需求，提出了一种基于条件自编码器（CAE）的框架。该模型通过在GalSim生成的模拟星系图像上训练，学习将星系图像编码为低维潜在表示，并能够有效解缠和恢复星系的测光参数和形态特征，同时重建原始图像。研究结果表明，CAE方法能准确高效地推断复杂的星系结构属性，为现有方法提供了一种计算效率更高的替代方案。

> **摘要翻译:** 正在进行和未来的测光巡天将产生前所未有的星系图像数据量，需要鲁棒、高效的方法来大规模推导星系形态参数。传统的参数化光廓线拟合方法虽然提供了有价值的见解，但在应用于数十亿个星系源时，计算成本变得过高。在这项工作中，我们提出了一种条件自编码器（CAE）框架，用于同时建模和表征星系形态。我们的CAE模型通过GalSim生成的逼真模拟星系图像进行训练，这些图像涵盖了广泛的星系类型、测光参数（例如通量、半光半径、Sersic指数、椭圆度）和观测条件。通过将每个星系图像编码为基于关键参数的低维潜在表示，我们的模型能够以解缠的方式有效恢复这些形态特征，同时重建原始图像。结果表明，CAE方法可以准确高效地推断复杂的结构属性，为现有方法提供了一个强大的替代方案。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [713] [A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design](https://arxiv.org/abs/2507.13580)
> *整合大型语言模型和化学片段空间的协同框架：先导化合物设计的相互启发*

*Hao Tuo, Yan Li, Xuanning Hu, Haishi Zhao, Xueyan Liu, Bo Yang* | **Category: q-bio.BM, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 药物设计, 大型语言模型, 化学片段, 先导化合物, 组合优化

**Comment:** 

> **TL;DR:** AutoLeadDesign是一个整合大型语言模型和化学片段空间的框架，用于高效的先导化合物设计，在实验中表现优于基线方法并能生成专家级别的化合物。

**AI_Comments:** 该论文提出了一种新颖的结合大型语言模型和化学片段的药物设计框架，其创新性在于利用LLM编码的丰富领域知识来指导化学空间的探索，从而克服了传统方法在整合复杂领域知识方面的不足。其重要性体现在能够从头生成专家级别的先导化合物，并已在临床相关靶点上得到验证。这为药物研发带来了效率提升和新颖性突破，具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 当前的计算机辅助药物设计方法在整合领域知识方面面临固有挑战，限制了它们在识别具有新颖有效结合模式的先导化合物方面的性能。

**Method:** 本文提出了AutoLeadDesign，一个先导化合物设计框架，它将大型语言模型中编码的广泛领域知识与化学片段相结合，以逐步高效地探索巨大的化学空间。

**Result:** AutoLeadDesign的综合实验表明其优于基线方法。针对PRMT5和SARS-CoV-2 PLpro两个临床相关靶点的先导化合物设计活动表明，AutoLeadDesign在从头生成先导化合物方面具有能力，达到了专家级别的设计效率。结构分析进一步证实了其机制验证的抑制模式。

**Conclusion:** AutoLeadDesign为先导化合物设计提供了一种高效方法，预示着其在药物设计中的潜在实用性。

> **ai_Abstract:** 本文提出了AutoLeadDesign，一个整合大型语言模型（LLM）和化学片段空间的协同框架，旨在解决现有计算机辅助药物设计方法在整合领域知识方面的局限性。该框架通过LLM的领域知识与化学片段的相互启发，实现对广阔化学空间的高效探索，以设计高亲和力的先导化合物。实验结果表明，AutoLeadDesign在性能上优于基线方法，并能从头生成具有专家级设计效率的先导化合物，其有效性在针对PRMT5和SARS-CoV-2 PLpro等临床相关靶点的设计中得到验证，并通过结构分析确认了抑制模式。研究还发现AutoLeadDesign与基于片段的药物设计具有相似机制。该框架为先导化合物设计提供了一种高效途径，展现了其在药物设计领域的巨大潜力。

> **摘要翻译:** 组合优化算法在计算机辅助药物设计中至关重要，通过逐步探索化学空间来设计对靶蛋白具有高亲和力的先导化合物。然而，当前方法在整合领域知识方面面临固有挑战，限制了它们在识别具有新颖有效结合模式的先导化合物方面的性能。在此，我们提出了AutoLeadDesign，一个先导化合物设计框架，它将大型语言模型中编码的广泛领域知识与化学片段相结合，以逐步高效地探索巨大的化学空间。综合实验表明，AutoLeadDesign优于基线方法。显著的是，针对两个临床相关靶点（PRMT5和SARS-CoV-2 PLpro）的经验性先导化合物设计活动表明，AutoLeadDesign在从头生成先导化合物方面具有能力，达到了专家级别的设计效率。结构分析进一步证实了其机制验证的抑制模式。通过追踪设计过程，我们发现AutoLeadDesign与传统上依赖专家决策的基于片段的药物设计具有相似的机制，这进一步揭示了其工作原理。总的来说，AutoLeadDesign为先导化合物设计提供了一种高效方法，预示着其在药物设计中的潜在实用性。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [734] [R-Bot: An LLM-based Query Rewrite System](https://arxiv.org/abs/2412.01661)
> *R-Bot: 一个基于LLM的查询重写系统*

*Zhaoyan Sun, Xuanhe Zhou, Guoliang Li, Xiang Yu, Jianhua Feng, Yong Zhang* | **Category: cs.DB, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 查询重写, 大型语言模型, SQL优化, 幻觉, R-Bot

**Comment:** 

> **TL;DR:** R-Bot是一个基于大型语言模型（LLM）的SQL查询重写系统，它通过生成重写证据、混合检索和逐步重写来解决LLM幻觉问题，并在实际应用中表现出优于现有方法的性能，降低了查询延迟。

**AI_Comments:** R-Bot的创新之处在于它系统性地解决了LLM在查询重写中可能出现的幻觉问题，通过引入证据准备、混合检索和分步重写，有效利用了LLM强大的理解能力，同时避免了其固有的缺陷。其在实际部署中的表现也证明了其重要的实用价值，为SQL查询优化提供了一个新的高效解决方案。

<details>
  <summary>Details</summary>

**Motivation:** SQL查询重写对于优化执行效率至关重要，但传统方法（启发式和基于学习的方法）存在质量差和鲁棒性低的问题。尽管大型语言模型（LLM）具有潜力，但直接应用如GPT-4等LLM面临幻觉问题，即可能生成不准确或不相关的结果。

**Method:** 本文提出了R-Bot系统，一个基于LLM的查询重写系统，采用系统化方法：首先，设计了一个多源重写证据准备流程，生成查询重写证据以指导LLM避免幻觉；其次，提出了一种结合结构和语义分析的混合结构-语义检索方法，以检索最相关的重写证据；最后，提出了一种分步LLM重写方法，通过自我反思迭代地利用检索到的证据来选择和安排重写规则。

**Result:** 在真实世界数据集和广泛使用的基准测试上进行了全面实验，结果表明R-Bot系统性能优越，超越了最先进的查询重写方法。R-Bot系统已在华为和实际客户处部署，结果显示其实现了更低的查询延迟。

**Conclusion:** R-Bot系统通过其独特的多源证据准备、混合检索和逐步重写方法，有效解决了LLM在查询重写中的幻觉问题，显著提升了SQL查询的优化效果和执行效率，并在实际应用中得到了验证。

> **ai_Abstract:** R-Bot是一个创新的基于LLM的SQL查询重写系统，旨在解决传统方法和直接应用LLM（如GPT-4）所面临的局限性和幻觉问题。该系统引入了一个多源重写证据准备流程来指导LLM，一个混合结构-语义检索方法来获取相关证据，以及一个分步LLM重写方法，通过自我反思迭代优化重写规则。实验结果表明，R-Bot在性能上超越了现有技术，并且在华为及实际客户的部署中有效降低了查询延迟。

> **摘要翻译:** 查询重写对于优化SQL查询以提高其执行效率而不改变结果至关重要。传统上，这项任务通过启发式和基于学习的方法来解决，但这些方法在质量和鲁棒性方面都存在局限性。大型语言模型（LLM）的最新进展通过利用其卓越的自然语言和代码理解能力提供了一种新范式。尽管它们具有潜力，但直接应用像GPT-4这样的LLM面临幻觉等挑战，即模型可能会生成不准确或不相关的结果。为了解决这个问题，我们提出了R-Bot，一个基于LLM的查询重写系统，采用系统化方法。我们首先设计了一个多源重写证据准备流程，以生成查询重写证据，指导LLM避免幻觉。然后，我们提出了一种混合结构-语义检索方法，该方法结合了结构和语义分析，以检索最相关的重写证据，从而有效地回答在线查询。接下来，我们提出了一种分步LLM重写方法，该方法通过自我反思迭代地利用检索到的证据来选择和安排重写规则。我们在真实世界数据集和广泛使用的基准测试上进行了全面实验，并证明了我们系统R-Bot的卓越性能，超越了最先进的查询重写方法。R-Bot系统已在华为和实际客户处部署，结果显示所提出的R-Bot系统实现了更低的查询延迟。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

