# AI-Enhanced arXiv Daily 2025-06-16

<a id='toc'></a>
## 今日总计: 623 篇论文
### 目录
- [cs.CR](#cscr) (15 篇)
- [cs.AI](#csai) (23 篇)
- [cs.LG](#cslg) (103 篇)
- [cs.MA](#csma) (3 篇)
- [cs.RO](#csro) (21 篇)
- [cs.CV](#cscv) (91 篇)
- [cs.HC](#cshc) (12 篇)
- [cs.ET](#cset) (1 篇)
- [cs.SE](#csse) (68 篇)
- [cs.SI](#cssi) (1 篇)
- [cs.NI](#csni) (11 篇)
- [cs.IT](#csit) (7 篇)
- [cs.AR](#csar) (6 篇)
- [cs.DC](#csdc) (5 篇)
- [cs.CY](#cscy) (9 篇)
- [cs.CE](#csce) (2 篇)
- [cs.FL](#csfl) (1 篇)
- [eess.SY](#eesssy) (11 篇)
- [eess.SP](#eesssp) (14 篇)
- [eess.IV](#eessiv) (17 篇)
- [eess.AS](#eessas) (17 篇)
- [cs.CL](#cscl) (89 篇)
- [cs.DS](#csds) (5 篇)
- [cs.GR](#csgr) (4 篇)
- [cs.IR](#csir) (8 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (18 篇)
- [cs.SD](#cssd) (12 篇)
- [math.CO](#mathco) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)
- [stat.ML](#statml) (9 篇)
- [quant-ph](#quant-ph) (6 篇)
- [q-bio.NC](#q-bionc) (3 篇)
- [cs.DB](#csdb) (1 篇)
- [cs.PL](#cspl) (1 篇)
- [stat.ME](#statme) (2 篇)
- [astro-ph.IM](#astro-phim) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (3 篇)
- [math.OC](#mathoc) (5 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [math.AP](#mathap) (2 篇)
- [q-bio.GN](#q-biogn) (4 篇)
- [nlin.AO](#nlinao) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [hep-ex](#hep-ex) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [User Perceptions and Attitudes Toward Untraceability in Messaging Platforms](https://arxiv.org/abs/2506.11212)
> *用户对消息平台中不可追踪性的看法和态度*

*Carla F. Griggio, Boel Nelson, Zefan Sramek, Aslan Askarov* | **Main category: cs.CR**

**Keywords:** 不可追踪性, 用户感知, 消息平台, 隐私增强技术, 匿名性

**Comment:** 

> **TL;DR:** 本研究探讨用户对消息平台中“不可追踪性”的看法，发现用户将其与多种隐私增强技术相关联，并对匿名性有不同于协议设计者的理解，揭示了用户认知与现有不可追踪通信协议威胁模型之间的差距。

**AI_Comments:** 这项研究创新地关注了用户对隐私增强技术（特别是不可追踪性）的实际理解，而非仅仅技术实现。它揭示了用户心理模型与技术设计者意图之间的关键差距，这对于未来设计更符合用户需求和期望的隐私功能至关重要。研究的发现强调了在推广隐私技术时进行用户教育和明确概念解释的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在了解用户对“不可追踪性”的看法，以指导消息平台中隐私增强功能和不可追踪通信协议的设计，这些协议依赖于大型匿名集和广泛的用户采用。

**Method:** 通过对189名参与者进行基于小插曲的调查，分析用户如何推理两个虚构平台（Texty和Chatty）应包含哪些功能来防止第三方知晓谁与谁通信，而不是研究特定解决方案的心理模型。

**Result:** 用户将不可追踪性概念与广泛的隐私增强技术联系起来，这意味着多样化的威胁模型。参与者提出的功能表明他们意识到了源于监视和未经授权访问消息内容的隐私威胁。许多参与者还将不可追踪性与匿名性概念联系起来，但将其解释为发送者和接收者相互隐藏身份，而不仅仅是向第三方隐藏。

**Conclusion:** 论文讨论了用户对不可追踪性的看法与不可追踪通信协议所解决的威胁模型之间的差距，以及不同的隐私态度如何指向在消息平台中采用不可追踪通信工具的挑战和机遇。

> **ai_Abstract:** 本研究通过对189名参与者进行调查，探讨了用户对消息平台中“不可追踪性”的理解和态度。结果显示，用户将不可追踪性与多种隐私技术和威胁模型相关联，并普遍意识到监视和未经授权访问内容的隐私威胁。值得注意的是，许多用户将不可追踪性误解为发送者与接收者之间的相互匿名，而非仅针对第三方。研究揭示了用户认知与现有不可追踪通信协议威胁模型之间的差距，并讨论了这对于未来隐私工具采纳的挑战与机遇。

> **摘要翻译:** 主流消息平台提供各种旨在增强用户隐私的功能，例如阅后即焚消息、密码保护聊天以及端到端加密（E2EE），这些功能主要保护消息内容。除了内容，消息的传输还会生成元数据，这些数据可以揭示谁与谁通信、何时以及多久一次。在本文中，我们研究了用户对“不可追踪性”的看法，即防止第三方追踪谁与谁通信，目的是为消息平台中隐私增强功能和依赖于大型匿名集以及广泛用户采用的不可追踪通信协议的设计提供信息。我们从广泛的概念角度探讨了这一点：我们没有研究特定解决方案的心理模型，而是分析了用户如何推理两个虚构平台Texty和Chatty应包含哪些功能，以防止第三方知晓谁与谁通信。通过对189名参与者进行基于小插曲的调查，我们发现用户将不可追踪性概念与广泛的隐私增强技术联系起来，这意味着多样化的威胁模型。总的来说，参与者提出的功能表明他们意识到了源于监视和未经授权访问消息内容的隐私威胁。许多参与者还将不可追踪性与匿名性概念联系起来，但将其解释为发送者和接收者相互隐藏身份，而不仅仅是向第三方隐藏。我们讨论了用户对不可追踪性的看法与不可追踪通信协议所解决的威胁模型之间的差距，以及不同的隐私态度如何指向在消息平台中采用不可追踪通信工具的挑战和机遇。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [Uncovering Reliable Indicators: Improving IoC Extraction from Threat Reports](https://arxiv.org/abs/2506.11325)
> *揭示可靠指标：改进威胁报告中的IoC提取*

*Evangelos Froudakis, Athanasios Avgetidis, Sean Tyler Frankum, Roberto Perdisci, Manos Antonakakis, Angelos Keromytis* | **Main category: cs.CR**

**Keywords:** IoC提取, 威胁情报, 大型语言模型, 人机协作, PRISM

**Comment:** 

> **TL;DR:** 该研究提出了一种混合人机协作管道，结合大型语言模型分类器（LANCE）和专家分析师验证，以改进IoC提取，解决了现有方法中高质量真实数据缺乏的问题，并创建了一个高质量的公共基准数据集PRISM。

**AI_Comments:** 这篇论文的创新点在于提出了第一个将大型语言模型与人机协作相结合的IoC提取管道，有效解决了威胁情报领域中长期存在的真实数据质量问题。其重要性体现在不仅提高了IoC提取的精度和效率，还通过创建PRISM基准数据集为未来的研究提供了可靠的基础，促进了该领域的可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现有IoC提取系统受限于缺乏高质量的真实数据。手动提取成本高昂，自动化方法则包含非恶意工件，导致高误报率和不可靠的威胁情报。

**Method:** 引入了第一个混合人机协作（human-in-the-loop）管道，用于IoC提取。该管道结合了基于大型语言模型（LLM）的分类器（LANCE）和专家分析师验证。

**Result:** 通过可解释、上下文感知的标注提高了准确性（precision）。与手动标注相比，分析师的工作量减少了43%。创建了PRISM，一个包含1,791个已标注IoC的高质量、公开可用的基准数据集，源自50份真实威胁报告。

**Conclusion:** 该方法通过结合LLM和专家验证，有效解决了IoC提取中高质量真实数据缺乏的问题，提高了提取精度并减轻了分析师的工作负担，同时提供了一个有价值的公共基准数据集，支持可复现的研究。

> **ai_Abstract:** 这篇论文提出了一种创新的混合人机协作管道，用于从威胁报告中提取妥协指标（IoCs）。针对现有IoC提取方法中高质量真实数据不足的问题，该系统结合了大型语言模型（LANCE）和专家分析师的验证，显著提高了提取精度，并通过可解释的上下文感知标注减少了分析师43%的工作量。此外，研究还构建并发布了PRISM，一个包含1791个专家验证IoCs的高质量公共基准数据集，旨在促进IoC提取方法的公平评估和可复现研究。

> **摘要翻译:** 妥协指标（IoCs）对于威胁检测和响应至关重要，它们标记了跨网络和系统的恶意活动。然而，自动化IoC提取系统的有效性受到一个关键问题的根本限制：缺乏高质量的真实数据。当前的提取工具要么依赖于手动提取的真实数据，这既耗时又昂贵，要么依赖于包含非恶意工件的自动化真实数据创建方法，导致误报率（FP）虚高和不可靠的威胁情报。在这项工作中，我们分析了现有真实数据创建策略的缺点，并通过引入第一个用于IoC提取的混合人机协作管道来解决这些问题，该管道将基于大型语言模型的分类器（LANCE）与专家分析师验证相结合。我们的系统通过可解释、上下文感知的标注提高了精确度，并且在对六名分析师的评估中表明，与手动标注相比，分析师的工作量减少了43%。通过这种方法，我们生成了PRISM，一个高质量、公开可用的基准数据集，包含来自50份真实威胁报告的1,791个已标注IoC。PRISM支持IoC提取方法的公平评估和训练，并支持基于专家验证指标的可复现研究。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning](https://arxiv.org/abs/2506.11423)
> *巴特猜想：关于类人推理的必要但不充分的基准重言式*

*Manish Bhatt* | **Main category: cs.CR**

**Keywords:** LLMs, 推理, 基准, 重言式, 类人推理

**Comment:** 

> **TL;DR:** 作者提出了两个“重言式”基准，旨在澄清关于大型语言模型（LLMs）是真正推理还是仅仅模式匹配的争论。

**AI_Comments:** 这篇论文似乎提供了一个概念性框架而非实证结果。其创新之处在于提出了“重言式基准”，这可能为人工智能推理领域中常有的模糊争论提供一个稳定的参考点。局限性在于摘要中并未详细说明这些基准或其应用方式。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决关于大型语言模型（LLMs/LRMs）是否真正推理的争论中目标不断变化的问题，并试图将作者的心智模型具体化。

**Method:** 作者试图具体地阐述其心智模型，并提出两个分析性的“重言式”基准。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了作者的“巴特猜想”，提出了两个“重言式”基准。这些基准旨在通过提供一个具体的评估框架，来澄清关于大型语言模型（LLMs）是真正推理还是仅仅进行模式匹配的持续争论。

> **摘要翻译:** 关于大型语言或推理模型（LLMs/LRMs）是真正推理还是仅仅模式匹配的争论，一直面临着目标不断变化的问题。在我个人看来，两个分析性——因此是“重言式”——的基准在我的心智模型中能够拨开迷雾。在本文中，我试图将我的心智模型具体化地记录下来。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444)
> *GaussMarker：扩散模型的鲁棒双域水印*

*Kecen Li, Zhicong Huang, Xinwen Hou, Cheng Hong* | **Main category: cs.CR**

**Keywords:** 扩散模型, 水印, 双域, 鲁棒性, GaussMarker

**Comment:** Accepted at ICML 2025

> **TL;DR:** GaussMarker提出了一种鲁棒的双域水印方法，用于扩散模型生成的图像，通过在空间和频率域嵌入水印并引入高斯噪声恢复器，以应对各种攻击。

**AI_Comments:** GaussMarker的创新点在于其首创的双域水印嵌入（空间域和频率域）以及引入了模型无关的可学习高斯噪声恢复器（GNR），显著提升了对各种攻击的鲁棒性。这对于解决扩散模型生成图像的版权和滥用问题具有重要意义。其在实际应用中表现出的高召回率和低误报率是其关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 随着扩散模型生成图像的真实性不断提高，版权和滥用等相关问题日益突出。水印技术被认为是一种有前景的解决方案，但现有方法将水印注入到单一域（初始高斯噪声），导致鲁棒性不佳。

**Method:** 本文提出了首个双域扩散模型水印方法GaussMarker。它使用流水线注入器在空间域和频率域同时嵌入水印。为了进一步提高对抗图像操作和高级攻击的鲁棒性，引入了一个模型无关的可学习高斯噪声恢复器（GNR）来细化从被操作图像中提取的高斯噪声，并通过整合两个水印的检测分数来增强检测鲁棒性。

**Result:** GaussMarker在八种图像失真和四种高级攻击下，在三个版本的Stable Diffusion上实现了最先进的性能，具有更好的召回率和更低的误报率，这在实际应用中更受欢迎。

**Conclusion:** GaussMarker通过其独特的双域水印嵌入和高斯噪声恢复机制，显著提高了扩散模型水印的鲁棒性和检测性能，为解决扩散模型图像的版权和滥用问题提供了有效方案。

> **ai_Abstract:** GaussMarker是一种为扩散模型生成的图像设计的鲁棒双域水印技术。针对现有单域水印鲁棒性差的问题，GaussMarker首次在空间和频率域同时嵌入水印，并通过引入可学习的高斯噪声恢复器（GNR）来增强对图像操作和高级攻击的抵抗力。该方法在多种失真和攻击下，在Stable Diffusion模型上表现出卓越的性能，具有高召回率和低误报率，适用于实际应用。

> **摘要翻译:** 随着扩散模型（DM）生成越来越逼真的图像，版权和滥用等相关问题日益受到关注。水印技术是其中一个有前景的解决方案。现有方法将水印注入到生成初始高斯噪声的单一域中，这导致鲁棒性不尽如人意。本文提出了第一个双域DM水印方法，使用流水线注入器在空间域和频率域持续嵌入水印。为了进一步提高对抗某些图像操作和高级攻击的鲁棒性，我们引入了一个模型无关的可学习高斯噪声恢复器（GNR），用于细化从被操作图像中提取的高斯噪声，并通过整合两个水印的检测分数来增强检测鲁棒性。GaussMarker在八种图像失真和四种高级攻击下，在三个版本的Stable Diffusion上高效地实现了最先进的性能，具有更好的召回率和更低的误报率，这在实际应用中更受欢迎。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [32] [Computational Attestations of Polynomial Integrity Towards Verifiable Machine-Learning](https://arxiv.org/abs/2506.11458)
> *多项式完整性的计算证明迈向可验证机器学习*

*Dustin Ray, Caroline El Jazmi* | **Main category: cs.CR**

**Keywords:** 零知识密码学, 机器学习即服务, 差分隐私, 可验证计算, 线性回归

**Comment:** 21 pages, Future Technologies Conference (FTC) 2024

> **TL;DR:** 本文利用零知识密码学，实现了在6分钟内对50,000个样本的差分隐私线性回归进行正确训练的证明，并在0.17秒内完成验证，为端到端私有MLaaS奠定了基础。

**AI_Comments:** 这项工作在可验证机器学习领域迈出了重要一步，特别是在MLaaS的背景下解决了隐私和正确性问题。其创新之处在于利用零知识密码学实现了高效的计算完整性证明，并且在实际数据集上展示了显著的性能提升，达到了现有文献中的最快速度。这对于推动私有机器学习的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器学习系统规模和复杂性的增长，机器学习即服务（MLaaS）行业正在兴起。然而，将操作和训练外包给强大的硬件带来了隐私和工作正确性方面的挑战，需要确保这些系统的完整性。

**Method:** 本文利用零知识密码学领域的最新进展，生成计算完整性论证。具体地，他们证明了在一个包含50,000个样本的数据集上，单机上差分隐私（DP）线性回归的正确训练。

**Result:** 成功在不到6分钟内证明了在一个包含50,000个样本的数据集上，单机上差分隐私（DP）线性回归的正确训练，并在0.17秒内验证了整个计算。据作者所知，这是目前文献中已知对该规模数据集进行可证明DP的最快实例。

**Conclusion:** 这项成果是实现端到端私有机器学习即服务（MLaaS）的关键一步。

> **ai_Abstract:** 本文提出了一种利用零知识密码学来解决机器学习即服务（MLaaS）中隐私和计算正确性挑战的方法。研究人员成功证明了在一个包含50,000个样本的数据集上，差分隐私线性回归的正确训练，并在6分钟内完成训练证明，0.17秒内完成验证。这被认为是该规模数据集上可证明差分隐私的最快实例，为实现端到端私有MLaaS奠定了重要基础。

> **摘要翻译:** 机器学习系统正以惊人的速度发展，在各个领域和学科中展现出卓越的效用。随着这些系统规模和复杂性的不断增长，一个新兴的产业正在形成，旨在将机器学习即服务（MLaaS）推向市场。将这些系统的操作和训练外包给强大的硬件具有诸多优势，但当必须确保隐私和工作正确性时，挑战随之而来。零知识密码学领域的最新进展，已经催生了一种为任何计算生成完整性论证的方法，而这些论证反过来可以被任何一方，在任何地方，任何时间高效地验证。在这项工作中，我们证明了在一个包含50,000个样本的数据集上，单机在不到6分钟内对差分隐私（DP）线性回归进行了正确训练，并在0.17秒内验证了整个计算。据我们所知，这项结果代表了文献中已知对该规模数据集进行可证明DP的最快实例。我们相信这项结果构成了实现端到端私有MLaaS的关键一步。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [60] [Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models](https://arxiv.org/abs/2506.11521)
> *调查音视频攻击的脆弱性和防御：一项强调多模态模型的综合性调查*

*Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li* | **Main category: cs.CR**

**Keywords:** 音视频攻击, 多模态模型, 安全漏洞, 对抗性攻击, 越狱攻击

**Comment:** 

> **TL;DR:** 本文对音视频攻击及其防御进行了全面系统的综述，特别关注多模态大语言模型（MLLMs）中存在的漏洞和攻击类型，并指出了未来的研究挑战和趋势。

**AI_Comments:** 这篇综述论文具有重要的及时性和实用价值。它不仅弥补了现有研究在音视频攻击类型统一回顾上的不足，更是首次将对最新多模态大语言模型（MLLMs）的攻击纳入考量，这对于新兴的MLLMs安全领域至关重要。论文为研究人员提供了全面的攻击概览和未来研究方向，有助于推动音视频多模态模型安全防御技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）在音视频任务上表现出色，但其对第三方数据和开源模型的依赖带来了显著的安全风险，现有研究表明MLLMs易受恶意内容操纵。现有音视频攻击调查缺乏对各种攻击类型的统一回顾，尤其是针对最新MLLMs的攻击。

**Method:** 本文通过对现有文献的综合和系统性回顾，调查了音视频攻击，包括对抗性攻击、后门攻击和越狱攻击。此外，还回顾了针对最新基于音视频的MLLMs的各种攻击类型。

**Result:** 本文提供了一个全面且系统的音视频攻击综述，涵盖了对抗性攻击、后门攻击和越狱攻击，并首次包含了针对最新音视频MLLMs的攻击类型。

**Conclusion:** 本文基于全面的回顾，阐述了音视频攻击和防御未来研究的挑战和新兴趋势。

> **ai_Abstract:** 本文对音视频攻击及其防御进行了全面系统的综述，特别关注了多模态大语言模型（MLLMs）的安全漏洞。鉴于MLLMs对第三方数据和开源模型的依赖带来的安全风险，以及其易受对抗性扰动、恶意查询等操纵，现有调查未能提供统一的攻击类型回顾，也未涉及针对最新MLLMs的攻击。因此，本文旨在弥补这一空白，详细审查了对抗性攻击、后门攻击和越狱攻击，并首次涵盖了针对最新音视频MLLMs的攻击。最后，论文指出了未来音视频攻击和防御研究的挑战和新兴趋势。

> **摘要翻译:** 多模态大语言模型（MLLMs）弥合了音视频与自然语言处理之间的鸿沟，在多项音视频任务上取得了最先进的性能。尽管MLLMs性能卓越，但高质量音视频训练数据和计算资源的稀缺性使得利用第三方数据和开源MLLMs成为必然，这一趋势在当代研究中日益显著。这种繁荣掩盖了重大的安全风险。实证研究表明，最新的MLLMs可以被操纵以产生恶意或有害内容。这种操纵完全通过指令或输入实现，包括对抗性扰动和恶意查询，有效地绕过了模型内部嵌入的安全机制。为了更深入地理解基于音视频的多模态模型固有的安全漏洞，一系列调查研究了各种类型的攻击，包括对抗性攻击和后门攻击。尽管现有关于音视频攻击的调查提供了全面的概述，但它们仅限于特定类型的攻击，缺乏对各种类型攻击的统一回顾。为了解决这个问题并深入了解该领域的最新趋势，本文对音视频攻击进行了全面而系统的回顾，其中包括对抗性攻击、后门攻击和越狱攻击。此外，本文还回顾了最新基于音视频的MLLMs中的各种攻击类型，这是现有调查中明显缺失的一个维度。本文借鉴大量综述的全面见解，阐述了未来音视频攻击和防御研究的挑战和新兴趋势。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [88] [SecONNds: Secure Outsourced Neural Network Inference on ImageNet](https://arxiv.org/abs/2506.11586)
> *SecONNds：ImageNet上的安全外包神经网络推理*

*Shashank Balla* | **Main category: cs.CR**

**Keywords:** 安全推理, 神经网络推理, ImageNet, GMW协议, GPU加速

**Comment:** 

> **TL;DR:** SecONNds是一个安全外包神经网络推理框架，通过引入新的安全比较协议、NTT预处理和GPU加速，显著提高了ImageNet规模模型推理的速度并降低了通信开销，使其适用于实际的隐私保护AI部署。

**AI_Comments:** SecONNds的创新之处在于其结合了新的GMW协议进行安全比较，并有效利用NTT预处理和GPU加速，显著提升了安全神经网络推理的效率和实用性。其在ImageNet规模模型上的表现，以及开源的特性，对于推动隐私保护AI在实际场景中的应用具有重要意义。它成功解决了现有方案高开销的痛点，是其主要价值。

<details>
  <summary>Details</summary>

**Motivation:** 外包神经网络推理的广泛应用带来了显著的隐私挑战，因为敏感的用户数据在不受信任的远程服务器上进行处理。现有的安全推理框架存在计算开销高和通信成本大的问题，使其在实际部署中不切实际。

**Method:** 本文介绍了SecONNds，一个非侵入式安全推理框架，专为大型ImageNet规模的卷积神经网络优化。SecONNds集成了一种新颖的完全布尔Goldreich-Micali-Wigderson (GMW) 协议，用于安全比较，该协议使用通过静默随机不经意传输生成的预处理Beaver比特三元组。为进一步提高性能，SecONNds采用了数论变换（NTT）预处理并利用GPU加速同态加密操作。此外，还提出了SecONNds-P，一个位精确的变体，确保在安全计算中获得可验证的全精度结果。

**Result:** 与最先进的解决方案相比，SecONNds的新型协议在非线性操作方面实现了17倍的在线加速，同时减少了通信开销。在线性操作方面，在CPU上实现了1.6倍的加速，在GPU上实现了2.2倍的加速。在37位量化的SqueezeNet模型上评估，SecONNds在GPU上实现了2.8秒的端到端推理时间，在CPU上实现了3.6秒，总通信量仅为420 MiB。

**Conclusion:** SecONNds的高效率和降低的计算负载使其非常适合在资源受限的环境中部署隐私敏感的应用。

> **ai_Abstract:** SecONNds是一个针对ImageNet规模卷积神经网络优化的非侵入式安全推理框架，旨在解决现有安全推理方案计算开销大和通信成本高的问题。它引入了一种新的基于GMW协议的安全比较方法，并结合了NTT预处理和GPU加速来提升性能。实验结果表明，SecONNds在非线性操作上实现了17倍的加速，在线性操作上也有显著提升，并在GPU和CPU上实现了高效的端到端推理时间及低通信量，使其适用于资源受限的隐私敏感应用部署。

> **摘要翻译:** 外包神经网络推理的广泛采用带来了显著的隐私挑战，因为敏感的用户数据在不受信任的远程服务器上进行处理。安全推理提供了一种保护隐私的解决方案，但现有框架存在计算开销高和通信成本大的问题，使其在实际部署中不切实际。我们引入了SecONNds，一个非侵入式安全推理框架，专为大型ImageNet规模的卷积神经网络优化。SecONNds集成了一种新颖的完全布尔Goldreich-Micali-Wigderson (GMW) 协议，用于安全比较——解决了姚氏百万富翁问题——该协议使用通过静默随机不经意传输生成的预处理Beaver比特三元组。我们新颖的协议在非线性操作方面比最先进的解决方案实现了17倍的在线加速，同时减少了通信开销。为了进一步提高性能，SecONNds采用了数论变换（NTT）预处理，并利用GPU加速同态加密操作，使得线性操作在CPU上加速1.6倍，在GPU上加速2.2倍。我们还提出了SecONNds-P，一个位精确的变体，确保在安全计算中获得可验证的全精度结果，与明文计算结果相匹配。在37位量化的SqueezeNet模型上进行评估，SecONNds在GPU上实现了2.8秒的端到端推理时间，在CPU上实现了3.6秒，总通信量仅为420 MiB。SecONNds的效率和降低的计算负载使其非常适合在资源受限的环境中部署隐私敏感的应用。SecONNds是开源的，可从https://github.com/shashankballa/SecONNds访问。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [115] [KEENHash: Hashing Programs into Function-Aware Embeddings for Large-Scale Binary Code Similarity Analysis](https://arxiv.org/abs/2506.11612)
> *KEENHash：将程序哈希为函数感知嵌入以进行大规模二进制代码相似性分析*

*Zhijie Liu, Qiyi Tang, Sen Nie, Shi Wu, Liang Feng Zhang, Yutian Tang* | **Main category: cs.CR**

**Keywords:** 二进制代码相似性分析, 程序嵌入, 哈希, 大型语言模型, 网络安全

**Comment:** 

> **TL;DR:** KEENHash提出了一种新颖的哈希方法，利用LLM生成的函数嵌入将二进制文件哈希为紧凑的程序级表示，从而实现高效且有效的大规模二进制代码相似性分析，显著优于现有方法。

**AI_Comments:** KEENHash的创新之处在于其将LLM生成的函数嵌入与K-Means和特征哈希相结合，创建紧凑的程序级表示，从而显著提升了大规模二进制代码相似性分析的效率。其在大规模场景下的巨大速度提升（例如，比现有工具快215倍，并在53亿次评估中仅需395.83秒）和在恶意软件检测等安全应用中的优越性（性能至少优于现有方法23.16%）使其成为二进制代码分析领域的一个重要进展，特别是在处理大规模数据集时。

<details>
  <summary>Details</summary>

**Motivation:** 现有的函数级二进制代码相似性分析（BCSA）工具时间复杂度高，在大规模场景（如1/n-to-n搜索）下无法扩展，导致效率低下。

**Method:** 本文提出了KEENHash，一种新颖的哈希方法，通过大型语言模型（LLM）生成的函数嵌入将二进制文件哈希为程序级表示。KEENHash利用K-Means和特征哈希将二进制文件浓缩为紧凑的固定长度程序嵌入，从而实现有效且高效的大规模程序级BCSA。

**Result:** 实验结果表明，KEENHash比最先进的函数匹配工具至少快215倍，同时保持了有效性。在53亿次相似性评估的大规模场景中，KEENHash仅需395.83秒，而这些工具至少需要56天。在202,305个二进制文件的大规模程序克隆搜索中，KEENHash比4种最先进的方法至少高出23.16%，并在恶意软件检测的大规模BCSA安全场景中表现出卓越的优势。

**Conclusion:** KEENHash通过将程序哈希为函数感知嵌入，显著提高了大规模二进制代码相似性分析的效率和有效性，超越了现有技术，尤其在处理大规模数据集和安全应用方面表现出色。

> **ai_Abstract:** KEENHash是一种新颖的哈希方法，旨在解决大规模二进制代码相似性分析中现有方法效率低下的问题。它利用大型语言模型（LLM）生成的函数嵌入，结合K-Means和特征哈希，将二进制文件转换为紧凑且固定长度的程序级嵌入。实验结果表明，KEENHash在保持有效性的同时，速度比现有方法快数百倍，并在大规模程序克隆搜索和恶意软件检测等安全场景中表现出卓越的性能，显著超越了现有技术。

> **摘要翻译:** 二进制代码相似性分析（BCSA）是网络安全等许多领域的关键研究领域。具体而言，函数级差异化工具是BCSA中使用最广泛的：它们通过逐个进行函数匹配来评估二进制程序之间的相似性。然而，此类方法需要高时间复杂度，使其在大规模场景（例如1/n到n搜索）中无法扩展。为了实现有效且高效的程序级BCSA，我们提出了KEENHash，这是一种新颖的哈希方法，通过大型语言模型（LLM）生成的函数嵌入将二进制文件哈希为程序级表示。KEENHash使用K-Means和特征哈希将二进制文件浓缩成一个紧凑且固定长度的程序嵌入，从而使我们能够进行有效且高效的大规模程序级BCSA，超越了以前的最新方法。实验结果表明，KEENHash比最先进的函数匹配工具至少快215倍，同时保持了有效性。此外，在53亿次相似性评估的大规模场景中，KEENHash仅需395.83秒，而这些工具将花费至少56天。我们还在202,305个二进制文件的广泛数据集上评估了KEENHash在大规模BCSA的程序克隆搜索中的性能。与4种最先进的方法相比，KEENHash的性能至少优于所有这些方法23.16%，并在恶意软件检测的大规模BCSA安全场景中显示出卓越的优势。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [142] [FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations](https://arxiv.org/abs/2506.11635)
> *FAA框架：一种基于大型语言模型的信用卡欺诈调查方法*

*Shaun Shuster, Eyal Zaloof, Asaf Shabtai, Rami Puzis* | **Main category: cs.CR**

**Keywords:** 信用卡欺诈, 大型语言模型, 自动化调查, 欺诈分析师助手, 多模态LLM

**Comment:** 

> **TL;DR:** 提出FAA框架，利用多模态LLM自动化信用卡欺诈调查并生成报告，减轻欺诈分析师的工作负担。

**AI_Comments:** 该论文的创新点在于将多模态大型语言模型应用于复杂的信用卡欺诈调查流程，实现了自动化规划、证据收集和分析，并能生成解释性报告，这对于减轻欺诈分析师的警报疲劳具有重要意义。其利用LLM的多种能力（推理、代码执行、视觉）来处理现实世界复杂欺诈案件的能力值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 欺诈分析师被信用卡交易监控系统发出的大量警报所淹没，每个调查都需要细致、专业知识和精确文档，导致警报疲劳。

**Method:** 提出FAA（欺诈分析师助手）框架，该框架采用多模态大型语言模型（LLM），利用其推理、代码执行和视觉能力，自动化信用卡欺诈调查的规划、证据收集和分析，并生成解释性报告。

**Result:** 对500起信用卡欺诈调查的全面实证评估表明，FAA框架产生了可靠且高效的调查，平均包含七个步骤。

**Conclusion:** FAA框架可以自动化大部分工作量，并有助于减少欺诈分析师面临的挑战。

> **ai_Abstract:** 本文提出FAA（欺诈分析师助手）框架，旨在通过利用多模态大型语言模型（LLM）自动化信用卡欺诈调查并生成解释性报告，以解决欺诈分析师因海量警报而面临的警报疲劳问题。FAA框架利用LLM的推理、代码执行和视觉能力进行调查的规划、证据收集和分析。对500起调查的实证评估表明，FAA框架能进行可靠高效的调查，显著减轻分析师工作负担。

> **摘要翻译:** 电子商务行业的持续增长吸引了利用被盗信用卡详细信息的欺诈者。公司通常会调查可疑交易，以保持客户信任并解决其欺诈检测系统中的漏洞。然而，分析师被信用卡交易监控系统发出的大量警报所淹没。每次警报调查都需要欺诈分析师的细致关注、专业知识和对结果的精确记录，导致警报疲劳。为了解决这个问题，我们提出了一个欺诈分析师助手（FAA）框架，该框架采用多模态大型语言模型（LLM）来自动化信用卡欺诈调查并生成解释性报告。FAA框架利用LLM的推理、代码执行和视觉能力，在每个调查步骤中进行规划、证据收集和分析。对500起信用卡欺诈调查的全面实证评估表明，FAA框架产生了可靠且高效的调查，平均包含七个步骤。因此，我们发现FAA框架可以自动化大部分工作量，并有助于减少欺诈分析师面临的挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [165] [DTHA: A Digital Twin-Assisted Handover Authentication Scheme for 5G and Beyond](https://arxiv.org/abs/2506.11669)
> *DTHA：一种面向5G及未来网络的数字孪生辅助切换认证方案*

*Guanjie Li, Tom H. Luan, Chengzhe Lai, Jinkai Zheng, Rongxing Lu* | **Main category: cs.CR**

**Keywords:** 数字孪生, 切换认证, 5G, 未来网络, 安全性

**Comment:** 

> **TL;DR:** 为解决5G及未来网络中移动设备频繁切换认证导致的连接中断和恶意攻击问题，本文提出了一种基于数字孪生的安全高效的切换认证方案DTHA。

**AI_Comments:** 本文的创新点在于将数字孪生技术引入到5G及未来网络的切换认证过程中，通过数字孪生进行预认证，有效解决了传统方案在高速移动场景下频繁切换带来的连接中断和安全威胁。形式化验证的引入增强了方案的可靠性，性能评估也证实了其高效性。该研究为未来高移动性通信环境下的认证安全提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在5G及未来网络中，毫米波、太赫兹频段和超密集网络技术的使用导致移动设备在高速移动时需要频繁与目标基站进行切换认证，这可能造成连接中断并招致恶意攻击。因此，迫切需要解决这些挑战。

**Method:** 本文提出了一种名为DTHA的安全高效的数字孪生辅助切换认证方案。DTHA利用授权的数字孪生作为智能中间体，在移动设备连接目标基站之前，提前处理计算并协助移动设备在域内和域间场景中执行安全的相互认证和密钥协商。此外，该方案通过BAN逻辑、RoR模型和ProVerif进行了形式化验证，并进行了非形式化分析。

**Result:** 形式化验证和非形式化分析表明，所提出的方案能够提供多种安全功能。性能评估显示，该方案在信令、计算和通信开销方面优于大多数现有相关方案。

**Conclusion:** 本文提出的数字孪生辅助切换认证方案（DTHA）能够有效解决5G及未来网络中移动设备频繁切换认证带来的连接中断和安全威胁问题，并在安全性、计算和通信开销方面表现出优越性。

> **ai_Abstract:** 本文针对5G及未来网络中移动设备因快速移动导致的频繁切换认证问题，提出了一种名为DTHA的数字孪生辅助切换认证方案。DTHA利用数字孪生作为智能中间体，在移动设备连接目标基站之前，提前完成安全的相互认证和密钥协商，从而有效避免了连接中断和恶意攻击。通过BAN逻辑、RoR模型和ProVerif的形式化验证以及非形式化分析，DTHA被证明具有强大的安全功能。性能评估结果显示，与现有方案相比，DTHA在信令、计算和通信开销方面表现出更优越的性能。

> **摘要翻译:** 随着第五代无线系统（5G）的快速发展和广泛部署，它实现了普遍的高速连接并提高了整体通信性能。此外，作为5G未来网络集成的一项有前景的技术，网络空间中的数字孪生可以与核心网络交互，传输重要信息，并进一步增强相应移动设备（MD）的无线通信质量。然而，毫米波、太赫兹频段和超密集网络技术的利用给5G及未来网络中的移动设备带来了紧迫的挑战，特别是在更快的移动性下与目标基站进行频繁的切换认证，这可能导致连接中断并招致恶意攻击。为了解决5G及未来网络中的此类挑战，本文提出了一种利用数字孪生的安全高效的切换认证方案。作为智能中间体，授权的数字孪生可以在域内和域间场景中，在移动设备连接目标基站之前，提前处理计算并协助相应的移动设备执行安全的相互认证和密钥协商。此外，我们提供了基于BAN逻辑、RoR模型和ProVerif的形式化验证以及非形式化分析，以证明所提出的方案可以提供多种安全功能。性能评估表明，所提出的方案在信令、计算和通信开销方面优于大多数相关方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [183] [LLMs on support of privacy and security of mobile apps: state of the art and research directions](https://arxiv.org/abs/2506.11679)
> *LLM在移动应用隐私和安全支持方面的现状与研究方向*

*Tran Thanh Lam Nguyen, Barbara Carminati, Elena Ferrari* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 移动应用安全, 隐私保护, 数据泄露检测, 威胁缓解

**Comment:** 

> **TL;DR:** 本文探讨了大型语言模型（LLM）在识别和缓解移动应用安全与隐私风险方面的应用潜力，并讨论了相关研究挑战。

**AI_Comments:** 本文创新性地将LLM应用于移动应用的安全和隐私领域，展示了其替代传统分析方法的潜力，为应对日益复杂的移动威胁提供了新思路。其重要性在于开辟了LLM在网络安全领域的新应用方向。

<details>
  <summary>Details</summary>

**Motivation:** 移动应用的安全和隐私风险日益复杂，需要更先进和高效的检测方法来保护用户。

**Method:** 本文探讨了大型语言模型（LLM）在识别、缓解移动应用安全风险和隐私侵犯方面的应用。通过介绍LLM在缓解智能手机平台十大常见安全风险方面的最新研究，并以检测用户在线共享图片时的敏感数据泄露为例进行说明。

**Result:** 强调了LLM替代传统移动应用分析方法（如动态和混合分析）的可行性和潜力。展示了一个基于LLM的敏感数据泄露检测方法。

**Conclusion:** LLM在移动应用安全和隐私支持方面具有巨大的潜力，能够替代传统分析方法，但仍存在开放的研究挑战。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）在提升移动应用隐私和安全方面的应用前景。鉴于日益复杂的移动威胁，研究强调了LLM识别和缓解安全风险及隐私侵犯的能力，并指出其有望取代传统的分析方法。文中介绍了LLM在应对智能手机常见安全风险方面的最新研究，并以检测图片共享中的敏感数据泄露为例，最后讨论了未来的研究挑战。

> **摘要翻译:** 现代生活见证了移动设备的爆炸式增长。然而，除了为终端用户带来便利的宝贵功能外，安全和隐私风险仍然威胁着移动应用用户。近年来，这些威胁日益复杂，凸显了对更先进、更高效检测方法的需求。在本章中，我们探讨了大型语言模型（LLM）在识别安全风险和隐私侵犯以及为移动应用生态系统缓解这些风险方面的应用。通过介绍应用LLM缓解智能手机平台十大常见安全风险的最新研究，我们强调了LLM替代传统分析方法（如移动应用的动态和混合分析）的可行性和潜力。作为一个基于LLM解决方案的代表性例子，我们提出了一种检测用户在线共享图片时敏感数据泄露的方法，这是当今智能手机用户的常见行为。最后，我们讨论了开放的研究挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [203] [Differential Privacy in Machine Learning: From Symbolic AI to LLMs](https://arxiv.org/abs/2506.11687)
> *机器学习中的差分隐私：从符号人工智能到大型语言模型*

*Francisco Aguilera-Martínez, Fernando Berzal* | **Main category: cs.CR**

**Keywords:** 差分隐私, 机器学习, 隐私保护, AI安全, 综述

**Comment:** arXiv admin note: text overlap with arXiv:2303.00654 by other authors

> **TL;DR:** 这篇综述论文探讨了差分隐私在机器学习中的应用，从其基本定义、演变到在训练机器学习模型时保护隐私的现有方法和评估技术，旨在促进安全负责任的AI系统发展。

**AI_Comments:** 这篇综述论文的重要性在于它系统地梳理了差分隐私在机器学习领域的发展和应用，为研究人员和实践者提供了全面的视角，有助于推动安全AI系统的构建。其贡献在于对现有方法和评估技术的整合性分析，填补了该领域系统性概述的空白。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型不应泄露敏感的私人信息。差分隐私提供了一个正式的框架来减轻隐私风险。这篇综述论文旨在全面探讨差分隐私在机器学习中的应用，以促进安全和负责任的AI系统发展。

**Method:** 这是一篇综述论文，其方法包括：探索差分隐私的基本定义，回顾其原始公式并追溯其关键研究贡献的演变；深入检查差分隐私如何集成到机器学习模型中，分析现有提案和方法以在训练机器学习模型时保护隐私；描述如何实践中评估基于差分隐私的机器学习技术。

**Result:** 这篇综述论文提供了一个关于机器学习中差分隐私的全面概述，包括其基本定义、演变、与机器学习模型的集成方法、现有提案、隐私保护方法以及评估技术。

**Conclusion:** 通过对机器学习中差分隐私的全面概述，这项工作旨在为安全和负责任的人工智能系统的持续发展做出贡献。

> **ai_Abstract:** 本综述论文全面探讨了机器学习中的差分隐私，从其基本概念、发展历程到在训练机器学习模型时集成差分隐私以保护隐私的各种方法和评估技术。论文旨在通过提供深入分析，促进安全和负责任的人工智能系统的发展，并讨论了差分隐私的实际应用和面临的挑战。

> **摘要翻译:** 机器学习模型不应泄露原本无法访问的特定信息。差分隐私提供了一个正式的框架来减轻隐私风险，它通过确保任何单个数据点的包含或排除不会显著改变算法的输出，从而限制私人信息的暴露。这篇综述论文探讨了差分隐私的基本定义，回顾了其原始公式并追溯了其通过关键研究贡献的演变。然后，它深入研究了差分隐私如何集成到机器学习模型中，分析了在训练机器学习模型时保护隐私的现有提案和方法。最后，它描述了如何实践中评估基于差分隐私的机器学习技术。%最后，它讨论了差分隐私的更广泛影响，强调了其对公共利益的潜力、其现实世界应用以及其面临的挑战，包括对抗性攻击的脆弱性。通过提供机器学习中差分隐私的全面概述，这项工作旨在为安全和负责任的人工智能系统的持续发展做出贡献。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [221] [Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches](https://arxiv.org/abs/2506.11939)
> *今日之猫，明日之狗：解释机器学习漏洞检测方法标签中的时间变化*

*Ranindya Paramitha, Yuan Feng, Fabio Massacci* | **Main category: cs.CR**

**Keywords:** 漏洞检测, 机器学习, 时间动态性, 标签变化, 性能评估

**Comment:** Accepted at The ACM International Conference on the Foundations of
  Software Engineering (FSE) 2025. Published in the Proceedings of the ACM on
  Software Engineering (PACMSE), Issue FSE 2025

> **TL;DR:** 机器学习漏洞检测中，标签随时间变化导致性能不稳定，本研究提出一种考虑时间变化的评估方法，并发现多数模型并未有效学习。

**AI_Comments:** 本文提出了一个重要且被忽视的问题：机器学习漏洞检测模型在实际部署中面临的标签动态变化问题。其创新点在于提出了一种系统性地重构数据集以模拟时间演变的方法，并引入统计检验来评估模型的“学习”能力。结果揭示了当前模型在处理时间动态性方面的局限性，对未来的研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 漏洞数据集隐式包含回顾性信息，导致机器学习模型在实际应用中性能与训练时脱节，因为漏洞标签会随时间变化。现有评估方法未能充分考虑这种时间动态性，或过于乐观或过于保守。

**Method:** 提出一种方法，将漏洞数据集重构为一系列时间序列数据集，其中训练和测试标签都随时间动态变化，以反映特定时间点可用的知识。使用Mann-Kendall检验来评估模型性能是否随时间改善，以判断模型是否真正学习。

**Result:** 在4个时间序列数据集（BigVul的3个项目和Vuldeepecker的NVD）和5个机器学习模型（Code2Vec, CodeBERT, LineVul, ReGVD, Vuldeepecker）上进行了验证。结果显示，与直觉预期（更多回顾性信息，性能更好）相反，模型性能在不同年份之间变化不一致，表明大多数模型并未有效学习。

**Conclusion:** 机器学习漏洞检测模型未能有效适应标签随时间变化，其性能并未随数据积累而稳定提升，提示当前模型可能并未真正“学习”时间动态性。

> **ai_Abstract:** 本文提出一种新的方法，用于评估机器学习漏洞检测模型在标签随时间动态变化下的性能。现有方法未能充分考虑漏洞标签随时间发现和变化的事实，导致评估结果不准确。作者将数据集重构为时间序列，使训练和测试标签均反映特定时间点的知识，并使用Mann-Kendall检验评估模型随时间学习的能力。实验结果表明，尽管直觉认为数据增加会提升性能，但大多数现有模型并未展现出稳定的性能提升，反而表现出不一致的变化，暗示它们可能未能有效学习。

> **摘要翻译:** 机器学习测试中使用的漏洞数据集隐式地包含回顾性信息。在实际应用中测试时，只能使用训练和测试时可用的标签（例如，已见和假定的负例）。随着漏洞在日历时间上被发现，标签会发生变化，过去的性能不一定与未来的性能保持一致。过去的工作只考虑了整个历史的片段（例如 DiverseVUl）或版本之间的个体差异（例如 Jimenez 等人的 ESEC/FSE 2019）。这些方法在训练时要么过于乐观（例如，使用整个历史），要么过于保守（例如，连续版本）。我们提出一种方法来将数据集重构为一系列数据集，其中训练和测试标签都随时间变化，以考虑当时可用的知识。如果模型确实在学习，它的性能应该随着更多数据的可用和数据变得更稳定而随时间改善，这种效果可以用 Mann-Kendall 检验来检查。我们使用 4 个基于时间的数据集（来自 BigVul 数据集的 3 个项目 + Vuldeepecker 的 NVD）和 5 个机器学习模型（Code2Vec、CodeBERT、LineVul、ReGVD 和 Vuldeepecker）验证了我们的漏洞检测方法。与直观预期（更多回顾性信息，性能更好）相反，趋势结果表明性能在不同年份之间变化不一致，这表明大多数模型并未学习。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [235] [Technical Evaluation of a Disruptive Approach in Homomorphic AI](https://arxiv.org/abs/2506.11954)
> *同态人工智能颠覆性方法的技评价*

*Eric Filiol* | **Main category: cs.CR**

**Keywords:** HbHAI, 同态AI, 数据安全, 哈希函数, 机器学习

**Comment:** This is the extended version of the talk presented at CyberWiseCon
  2025 in Vilnius, Lituania in May 21$^{st}$-23$^{rd}$, 2025

> **TL;DR:** 本文对一种名为HbHAI的基于哈希的同态AI方法进行了技术评估，该方法允许在加密数据上直接运行现有AI算法，并取得了前所未有的性能。

**AI_Comments:** 该论文提出了一种名为HbHAI的颠覆性方法，其创新之处在于允许在加密数据上直接使用现有AI算法进行处理，而无需修改，并声称具有前所未有的性能。这对于数据隐私和AI应用结合具有重要意义，可能极大地推动安全AI领域的发展。其声称的性能突破是关键亮点，如果得到广泛验证，将对行业产生深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 评估HbHAI（基于哈希的同态人工智能）这一新型颠覆性加密方法在数据安全、可操作性和性能方面的声明。

**Method:** 使用传统的无监督和有监督学习技术（聚类、分类、深度神经网络）以及经典的未经修改的AI算法，测试了受HbHAI保护的数据集。进行了一项独立的分析。

**Result:** 结果证实了HbHAI的大部分声明，仅有少数细微保留。

**Conclusion:** HbHAI是一种有前景的颠覆性方法，它使得在加密数据上使用现有原生AI算法进行分析和处理成为可能，且性能优于现有同态加密方案，其安全性、可操作性和性能声明得到了证实。

> **ai_Abstract:** 本文对一种名为HbHAI的创新性基于哈希的同态人工智能加密方法进行了技术评估。HbHAI利用新型哈希函数，使得在加密数据上直接运行现有AI算法成为可能，无需修改，并展现出优于现有同态加密方案的性能。通过对受保护数据集进行聚类、分类和深度学习等测试，独立分析结果证实了HbHAI在安全性、可操作性和性能方面的大部分声明。

> **摘要翻译:** 我们对一种名为HbHAI（基于哈希的同态人工智能）的、具有颠覆性的新型数据安全加密方法进行了技术评估。HbHAI基于一种新型的、依赖于密钥的哈希函数，这些函数自然地保留了大多数AI算法所依赖的相似性属性。作为主要主张，HbHAI现在使得在加密安全形式下分析和处理数据成为可能，同时无需修改即可使用现有原生AI算法，与现有同态加密方案相比，性能前所未有。我们使用传统的无监督和有监督学习技术（聚类、分类、深度神经网络）以及经典的未经修改的AI算法，测试了各种受HbHAI保护的数据集（非公开预览）。本文展示了使用这些不同的、现成的AI算法进行的独立分析的技术结果。目的是评估HbHAI技术的安全性、可操作性和性能主张。结果显示，我们的结果证实了这些主张的大部分，仅有少数细微保留。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [251] [CnC-PRAC: Coalesce, not Cache, Per Row Activation Counts for an Efficient in-DRAM Rowhammer Mitigation](https://arxiv.org/abs/2506.11970)
> *CnC-PRAC: 合并而非缓存，用于高效DRAM内Rowhammer缓解的每行激活计数*

*Chris S. Lin, Jeonghyun Woo, Prashant J. Nair, Gururaj Saileshwar* | **Main category: cs.CR**

**Keywords:** Rowhammer, DRAM, PRAC, CnC-PRAC, 缓解

**Comment:** 8 pages, including appendices. The paper is presented at DRAMSec
  2025. (see https://dramsec.ethz.ch/)

> **TL;DR:** CnC-PRAC是一种新的DRAM Rowhammer缓解方案，通过合并而非缓存激活计数来显著降低性能和能耗开销。

**AI_Comments:** 这篇论文的创新点在于其“合并而非缓存”的独特思想，通过解耦计数器访问和关键数据路径，有效地解决了现有Rowhammer缓解方案的性能和能耗瓶颈。这种方法为DRAM安全和性能平衡提供了新的视角，对于未来DRAM设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的PRAC（Per Row Activation Counting）实现（如JEDEC PRAC和Chronus）在缓解Rowhammer攻击时，会引入高达10%的性能下降或额外的能耗开销。

**Method:** CnC-PRAC通过将计数器访问与数据访问的关键路径解耦，并重新排序和合并对同一物理行中激活计数的访问来实现。具体优化包括缓冲计数器读-修改-写请求以及合并对同一行的请求。

**Result:** 相比Chronus等现有解决方案，CnC-PRAC将计数器访问的行激活次数减少了近75%-83%，实现了可忽略的性能下降和0.84%-1%的最小动态能耗开销（相对于不安全的DDR5 DRAM）。

**Conclusion:** CnC-PRAC提供了一种高效的DRAM内Rowhammer缓解方案，同时解决了现有PRAC实现所面临的性能和能耗开销问题。

> **ai_Abstract:** 本文提出了CnC-PRAC，一种新的DRAM内Rowhammer缓解方案，旨在解决现有每行激活计数（PRAC）方法带来的性能和能耗开销。与传统的缓存策略不同，CnC-PRAC通过解耦计数器访问与数据关键路径，并合并对同一物理行中激活计数的访问来优化。实验结果表明，CnC-PRAC显著减少了计数器访问的DRAM激活次数，从而实现了接近零的性能下降和极低的能耗开销。

> **摘要翻译:** JEDEC为DDR5及未来的DRAM引入了每行激活计数（PRAC）框架，以实现使用每行激活计数对DRAM行激活进行精确计数。虽然最近的PRAC实现能够全面缓解Rowhammer攻击，但由于执行计数器读-修改-写操作增加了DRAM时序，它们导致高达10%的性能下降。另一方面，最近的工作Chronus解决了这些性能下降问题，但由于计数器额外的DRAM激活而产生了能耗开销。在本文中，我们提出了CnC-PRAC，一种解决了性能和能耗开销的PRAC实现。与之前专注于缓存激活计数以减少开销的工作不同，我们的核心思想是重新排序并合并对位于同一物理行中激活计数的访问。我们的设计通过将计数器访问与数据访问的关键路径解耦来实现这一点。这使得能够进行优化，例如缓冲计数器读-修改-写请求和合并对同一行的请求。总的来说，这些优化使得计数器访问的行激活次数比Chronus等最先进的解决方案减少了近75%-83%，并实现了可忽略的性能下降和相对于不安全的DDR5 DRAM仅0.84%-1%的最小动态能耗开销的PRAC实现。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [27] [A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects](https://arxiv.org/abs/2506.11012)
> *面向任务的知识图谱推理综述：现状、应用与展望*

*Guanglin Niu, Bo Li, Yangguang Lin* | **Main category: cs.AI**

**Keywords:** 知识图谱推理, 任务导向, 综述, 大型语言模型, 应用

**Comment:** 45 pages, 17 figures, 12 tables

> **TL;DR:** 这篇综述系统地总结了面向任务的知识图谱推理（KGR）的现状、应用和未来方向，填补了现有综述的空白。

**AI_Comments:** 这篇综述填补了现有KGR综述的空白，通过提供一个更全面的视角，特别是整合了下游应用和新兴的挑战性推理范式。其创新之处在于将LLMs与KGR结合的探讨，这对于未来的研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于知识图谱推理（KGR）的综述未能全面系统地总结所有KGR任务，特别是缺乏对下游应用和更具挑战性推理范式的覆盖。

**Method:** 本综述通过根据主要推理任务、下游应用任务和潜在的挑战性推理任务对方法进行分类，提供了KGR研究的更全面视角。此外，还探讨了大型语言模型（LLMs）等先进技术及其对KGR的影响。

**Result:** 本综述全面回顾了知识图谱推理（KGR）的研究，涵盖了基于任务的分类、下游应用和挑战性推理任务，并探讨了LLMs等先进技术对KGR的影响。

**Conclusion:** 本工作旨在突出知识图谱推理（KGR）领域的关键研究趋势，并描绘有前景的未来发展方向。

> **ai_Abstract:** 本综述全面审视了知识图谱推理（KGR）领域，从面向任务的角度出发，对现有方法进行了系统分类，并涵盖了下游应用和新兴的挑战性推理范式。论文特别探讨了大型语言模型（LLMs）等先进技术对KGR的影响，旨在识别关键研究趋势并指明未来的发展方向，以填补当前综述的空白。

> **摘要翻译:** 知识图谱（KGs）已成为一种强大的范式，用于构建和利用多样化的真实世界知识，是使认知智能系统具备高级理解和推理能力的基础技术。知识图谱推理（KGR）旨在基于KGs中现有事实推断新知识，在公共安全情报、智能医疗和金融风险评估等应用中发挥着关键作用。从任务中心的角度来看，现有KGR方法可大致分为静态单步KGR、静态多步KGR、动态KGR、多模态KGR、少样本KGR和归纳KGR。虽然现有综述已涵盖了这六种类型的KGR任务，但仍缺乏一个系统总结所有KGR任务，特别是包括下游应用和更具挑战性推理范式的全面综述。与以往的工作相比，本综述通过根据主要推理任务、下游应用任务和潜在的挑战性推理任务对方法进行分类，提供了KGR研究的更全面视角。此外，我们还探讨了大型语言模型（LLMs）等先进技术及其对KGR的影响。本工作旨在突出KGR领域的关键研究趋势，并描绘有前景的未来发展方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [55] [OntoGSN: An Ontology for Dynamic Management of Assurance Cases](https://arxiv.org/abs/2506.11023)
> *OntoGSN：一种用于保证案例动态管理的本体*

*Tomas Bueno Momcilovic, Barbara Gallina, Ingmar Kessler, Dian Balta* | **Main category: cs.AI**

**Keywords:** 本体, 保障案例, GSN, 动态管理, 知识表示

**Comment:** Submitted to the ISWC 2025 Resources track

> **TL;DR:** OntoGSN引入了一个本体和支持中间件，用于动态管理保障案例（ACs），旨在简化GSN中AC的维护并提高其可靠性。

**AI_Comments:** OntoGSN提供了一种动态管理保障案例的创新方法，解决了系统开发中的一个关键痛点。它对GSN的形式化和集成能力增强了ACs的可靠性和可维护性，这对于自动驾驶和人工智能等复杂系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 保障案例（ACs）的管理具有挑战性，尤其是在面对变化时维护其中嵌入的知识需要大量精力，这会阻碍开发人员——甚至更糟的是，导致管理不善的案例灌输虚假的信心。

**Method:** 作者提出了OntoGSN，一个带有SWRL规则的OWL本体和支持中间件。它包括GSN社区标准v3的1:1形式化，一个用于与广泛使用的AC工具集成的辅助本体和解析器，一个OntoGSN维护的设计决策存储库和文档，一个带有自动化模式的SPARQL查询库，以及一个原型接口。该本体严格遵循标准文本，并已根据FAIR原则、OOPS框架、能力问题和社区反馈进行了评估。

**Result:** OntoGSN提供了一种知识表示和一个可查询的图，可以自动填充、评估和更新。通过一个涉及大型语言模型对抗鲁棒性保证的例子，展示了其贡献的实用性。

**Conclusion:** 本文介绍了OntoGSN，一个用于保障案例动态管理的本体和中间件，解决了AC维护的挑战，并提供了一个经过各种标准和社区反馈评估的健壮解决方案。

> **ai_Abstract:** OntoGSN旨在解决保障案例（ACs）动态管理的挑战，特别是在需要频繁更新的场景中。它为GSN标准中的ACs提供了一个OWL本体和中间件，能够自动填充、评估和更新可查询的知识图谱。该系统形式化了GSN v3，与现有工具集成，并包含一个SPARQL查询库，通过各种原则和社区反馈进行了验证，并通过大型语言模型鲁棒性示例进行了演示。

> **摘要翻译:** 保障案例（ACs）是建立和维护系统属性（如安全性或鲁棒性）信心的常见工件。构建AC可能具有挑战性，尽管现有工具在静态、以文档为中心的应用程序中提供支持，并且针对动态上下文（例如自动驾驶）的方法正在出现。不幸的是，管理AC仍然是一个挑战，因为面对变化时维护嵌入的知识需要大量精力，在此过程中阻碍开发人员——甚至更糟的是，产生管理不善的案例，灌输虚假的信心。为了解决这个问题，我们提出了OntoGSN：一个用于在目标结构化符号（GSN）标准中管理AC的本体和支持中间件。OntoGSN提供了一种知识表示和一个可查询的图，可以自动填充、评估和更新。我们的贡献包括：GSN社区标准v3在OWL本体中与SWRL规则的1:1形式化；一个用于与广泛使用的AC工具集成的辅助本体和解析器；OntoGSN维护的设计决策存储库和文档；一个带有自动化模式的SPARQL查询库；以及一个原型接口。该本体严格遵循标准文本，并已根据FAIR原则、OOPS框架、能力问题和社区反馈进行了评估。其他中间件元素的开发以社区需求为指导，并受到持续评估。为了展示我们贡献的实用性，我们通过一个涉及大型语言模型中对抗鲁棒性保证的示例，说明了动态AC管理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [83] [LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic](https://arxiv.org/abs/2506.11221)
> *LLM-作为-模糊判官：利用模糊逻辑微调大型语言模型作为临床评估判官*

*Weibing Zheng, Laurah Turner, Jess Kropczynski, Murat Ozer, Tri Nguyen, Shane Halse* | **Main category: cs.AI**

**Keywords:** 临床评估, 模糊逻辑, 大型语言模型, 医学教育, 沟通技能

**Comment:** 12 pages, 1 figure, 2025 IFSA World Congress NAFIPS Annual Meeting

> **TL;DR:** LLM-as-a-Fuzzy-Judge结合模糊逻辑与大型语言模型，旨在解决医学教育中临床沟通技能评估难以规模化和与医生主观判断对齐的挑战，通过微调LLM实现自动化、可解释且与人类偏好一致的评估，准确率超过80%。

**AI_Comments:** 该论文通过将模糊逻辑与大型语言模型相结合，提出了一种创新的混合方法，用于主观评估，这在医学教育等领域至关重要。它解决了自动化评估与人类细微判断对齐的挑战，提供了一种比纯粹的黑盒LLM方法更具可解释性和鲁棒性的解决方案。其在医学教育中应用于临床沟通技能评估的应用具有高度的实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 医学教育中临床沟通技能的实践和评估难以规模化，现有基于LLM的临床情景模拟虽然有潜力，但难以提供符合医生细微判断的自动化、可扩展的临床评估。

**Method:** 本文提出了LLM-as-a-Fuzzy-Judge方法，将模糊逻辑与大型语言模型（LLM）结合，通过微调LLM来评估学生在学生-AI病人对话脚本中的话语。方法包括从基于LLM的医学教育系统收集数据、基于专业性、医学相关性、伦理行为和情境干扰四个模糊集进行人工标注、提示工程以及使用这些人工标注对预训练LLM进行监督微调（SFT）。

**Result:** LLM-as-a-Fuzzy-Judge实现了超过80%的准确率，主要评价项目超过90%，有效利用模糊逻辑和LLM作为解决方案，提供了可解释、与人类对齐的评估。

**Conclusion:** 这项工作表明了利用模糊逻辑和LLM与人类偏好对齐的可行性，推动了医学教育中自动化评估的发展，并支持更稳健的评估和判断实践。

> **ai_Abstract:** 本文提出了一种名为LLM-as-a-Fuzzy-Judge的创新方法，它将模糊逻辑与大型语言模型（LLM）相结合，旨在解决医学教育中临床沟通技能自动化评估的可扩展性及与医生主观判断对齐的难题。该方法通过对LLM进行微调，利用基于专业性、医学相关性、伦理行为和情境干扰这四个模糊集的人工标注，来评估医学生在与AI患者对话中的表现。其流程包括数据收集、多维模糊集标注、提示工程和监督微调。实验结果显示，该方法整体准确率超过80%，主要评估项准确率超过90%，证明了其在提供可解释且与人类评估一致的自动化评估方面的有效性。这项工作突显了模糊逻辑与LLM结合在推动医学教育自动化评估方面的潜力。

> **摘要翻译:** 临床沟通技能在医学教育中至关重要，但规模化地实践和评估临床沟通技能具有挑战性。尽管基于LLM的临床情景模拟在提高医学生临床实践方面显示出前景，但提供遵循细致医生判断的自动化、可扩展的临床评估仍然困难。本文结合模糊逻辑和大型语言模型（LLM），提出了LLM-as-a-Fuzzy-Judge，以解决医学生临床技能自动化评估与医生主观偏好对齐的挑战。LLM-as-a-Fuzzy-Judge是一种方法，通过人类对四个模糊集（包括专业性、医学相关性、伦理行为和情境干扰）的标注，对LLM进行微调，以评估学生在学生-AI病人对话脚本中的话语。本文的方法始于从基于LLM的医学教育系统收集数据，然后基于多维模糊集进行数据标注，接着是提示工程，并使用这些人工标注对预训练LLM进行监督微调（SFT）。结果表明，LLM-as-a-Fuzzy-Judge实现了超过80%的准确率，主要评价项目超过90%，有效利用模糊逻辑和LLM作为解决方案，提供了可解释、与人类对齐的评估。这项工作表明了利用模糊逻辑和LLM与人类偏好对齐的可行性，推动了医学教育中自动化评估的发展，并支持更稳健的评估和判断实践。该工作的GitHub仓库可在https://github.com/2sigmaEdTech/LLMAsAJudge上获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [110] [MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification](https://arxiv.org/abs/2506.11331)
> *MUDAS：微型无监督域适应在多标签声音分类中的应用*

*Jihoon Yun, Chengzhang Li, Dhrubojyoti Roy, Anish Arora* | **Main category: cs.AI**

**Keywords:** 无监督域适应, 多标签分类, 物联网, 声音分类, 资源受限

**Comment:** 

> **TL;DR:** MUDAS是一个为资源受限物联网设备上的多标签声音分类设计的无监督域适应（UDA）框架，它通过选择性重训练和自适应阈值提高了分类准确性。

**AI_Comments:** MUDAS通过将UDA应用于多标签任务并专门针对资源受限的物联网环境，提供了一个创新解决方案，这是一个重大挑战。其选择性重训练和用于伪标签的自适应阈值方法是其效率和有效性的关键。这项工作对于在边缘设备上部署高级机器学习模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无监督域适应（UDA）算法主要针对单标签任务，且计算资源需求高，不适用于多标签场景和资源受限的物联网设备，特别是在需要鲁棒、自适应多标签能力的城市声音分类等低功耗系统上。

**Method:** MUDAS是一个为资源受限物联网环境中的多标签声音分类开发的UDA框架。它通过使用高置信度数据在现场选择性地重新训练分类器来高效地适应模型，从而最大限度地减少计算和内存要求。此外，MUDAS结合了特定类别的自适应阈值以生成可靠的伪标签，并应用多样性正则化以提高多标签分类准确性。

**Result:** 在对SONYC城市声音标记（SONYC-UST）数据集进行的评估中，MUDAS展示了比现有UDA算法在分类准确性方面显著的改进，并在资源受限的物联网环境中取得了良好的性能。

**Conclusion:** MUDAS成功解决了现有UDA算法的局限性，为资源受限物联网环境中的多标签声音分类提供了一个高效且准确的解决方案。

> **ai_Abstract:** MUDAS是一个新颖的无监督域适应（UDA）框架，专为资源受限的物联网设备上的多标签声音分类而设计。它解决了现有UDA方法计算密集且主要用于单标签任务的局限性。MUDAS通过选择性地使用高置信度数据重新训练分类器来实现效率，并采用特定类别的自适应阈值和多样性正则化来提高多标签准确性。对SONYC-UST数据集的评估表明，MUDAS在物联网环境中比现有UDA算法显著提高了分类准确性。

> **摘要翻译:** 无监督域适应（UDA）对于将机器学习模型适应新的、未标记的环境至关重要，因为数据分布变化会降低性能。现有的UDA算法专为单标签任务设计，并依赖大量的计算资源，这限制了它们在多标签场景和资源受限的物联网设备中的使用。克服这些限制在城市声音分类等背景下尤其具有挑战性，因为重叠的声音和变化的声学要求低功耗、设备上系统具有鲁棒、自适应的多标签能力。为了解决这些限制，我们引入了Mote-scale Unsupervised Domain Adaptation for Sounds（MUDAS），这是一个为资源受限物联网环境中的多标签声音分类开发的UDA框架。MUDAS通过使用高置信度数据在现场选择性地重新训练分类器来高效地适应模型，从而最大限度地减少计算和内存要求以适应设备部署。此外，MUDAS结合了特定类别的自适应阈值以生成可靠的伪标签，并应用多样性正则化以提高多标签分类准确性。在对纽约市不同地点记录的SONYC城市声音标记（SONYC-UST）数据集进行的评估中，MUDAS展示了比现有UDA算法在分类准确性方面显著的改进，并在资源受限的物联网环境中取得了良好的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [137] [Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables](https://arxiv.org/abs/2506.11375)
> *多模态大型语言模型在化学表格识别与理解上的基准测试*

*Yitong Zhou, Mingyue Cheng, Qingyang Mao, Yucong Luo, Qi Liu, Yupeng Li, Xiaohan Zhang, Deguang Liu, Xin Li, Enhong Chen* | **Main category: cs.AI**

**Keywords:** 化学表格, 多模态LLM, 基准测试, 表格识别, 表格理解

**Comment:** 

> **TL;DR:** 现有基准忽视了化学表格的复杂性，本文引入ChemTable，一个大规模真实世界化学表格基准，用于测试多模态LLM的识别与理解能力。结果显示模型在复杂QA任务上表现不佳，且开源与闭源模型存在性能差距。

**AI_Comments:** 这项工作通过引入ChemTable，一个专门针对化学领域复杂多模态表格的基准测试，填补了现有LLM评估中的一个重要空白。其创新之处在于结合了领域专家标注，并细分了表格识别和理解任务。研究结果揭示了当前多模态LLM在处理专业领域复杂推理任务上的局限性，特别是与人类表现的差距，以及开源和闭源模型之间的性能差异，为未来的模型开发指明了方向。ChemTable的推出对于推动科学文献理解和化学领域的AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准测试在很大程度上忽视了化学表格的多模态和领域特定复杂性，限制了多模态大型语言模型在化学领域支持科学理解的能力。

**Method:** 引入了ChemTable，一个从文献实验部分整理而成的大规模真实世界化学表格基准。ChemTable包含专家标注的单元格多边形、逻辑布局和领域特定标签，并支持两个核心任务：(1) 表格识别（结构解析和内容提取）；以及(2) 表格理解（基于表格结构和领域语义的描述性和推理性问答）。在ChemTable上评估了一系列代表性的多模态模型，包括开源和闭源模型。

**Result:** 模型在基本布局解析上表现出合理性能，但在描述性和推理性问答任务上与人类表现相比存在显著局限性。观察到开源和闭源模型在多个维度上存在显著性能差距。

**Conclusion:** 这些结果强调了化学感知表格理解的挑战，并将ChemTable定位为推进科学推理的严格且真实的基准。

> **ai_Abstract:** 本文介绍了ChemTable，一个针对化学领域多模态大型语言模型（LLMs）的新的大规模基准测试。该基准包含从真实文献中提取的化学表格，并提供专家标注，支持表格识别（结构解析、内容提取）和表格理解（描述性、推理性问答）两项核心任务。研究人员评估了多种开源和闭源多模态模型，发现尽管模型在基本布局解析上表现尚可，但在复杂的描述性和推理性问答任务上与人类性能存在显著差距，且开源与闭源模型之间存在性能差异。这项工作强调了化学感知表格理解的挑战，并为未来研究提供了严谨的评估工具。

> **摘要翻译:** 化学表格通过符号表达式、结构化变量和嵌入式分子图形编码复杂的实验知识。现有基准测试在很大程度上忽视了这种多模态和领域特定复杂性，限制了多模态大型语言模型在化学领域支持科学理解的能力。在这项工作中，我们引入了ChemTable，一个从文献实验部分整理而成的大规模真实世界化学表格基准。ChemTable包含专家标注的单元格多边形、逻辑布局和领域特定标签，包括试剂、催化剂、产率和图形组件，并支持两个核心任务：(1) 表格识别，涵盖结构解析和内容提取；以及(2) 表格理解，包括基于表格结构和领域语义的描述性和推理性问答。我们评估了一系列代表性的多模态模型，包括开源和闭源模型，并在ChemTable上报告了一系列具有实践和概念见解的发现。尽管模型在基本布局解析上表现出合理性能，但与人类表现相比，它们在描述性和推理性问答任务上表现出显著局限性，并且我们观察到开源和闭源模型在多个维度上存在显著性能差距。这些结果强调了化学感知表格理解的挑战，并将ChemTable定位为推进科学推理的严格且真实的基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [144] [Revealing Political Bias in LLMs through Structured Multi-Agent Debate](https://arxiv.org/abs/2506.11825)
> *通过结构化多智能体辩论揭示大型语言模型中的政治偏见*

*Aishwarya Bandaru, Fabian Bindley, Trevor Bluth, Nandini Chavda, Baixu Chen, Ethan Law* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 政治偏见, 多智能体辩论, 回音室, 性别影响

**Comment:** 

> **TL;DR:** 本研究通过多智能体辩论框架，深入探讨了LLM的政治偏见及其互动动态，发现中立LLM倾向民主党，共和党倾向中立，性别影响态度，且同政治立场LLM会形成回音室。

**AI_Comments:** 这项研究通过创新的多智能体辩论框架，系统地揭示了LLMs中存在的复杂政治偏见和互动模式。其创新之处在于引入了性别属性和动态的辩论过程，并发现了与传统认知（如同立场智能体形成回音室）相悖的现象。这对于理解LLMs在模拟社会行为时的局限性和潜在风险具有重要意义，也为未来开发更公平、无偏见的LLMs提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）越来越多地用于模拟社会行为，但其政治偏见和在辩论中的互动动态仍未被充分探索。

**Method:** 研究使用结构化多智能体辩论框架，让中立、共和党和民主党美国LLM智能体就政治敏感话题进行辩论。系统地改变底层LLM、智能体性别和辩论形式，以检查模型来源和智能体角色如何影响辩论中的政治偏见和态度。

**Result:** 发现中立智能体始终与民主党保持一致，而共和党则更接近中立；性别影响智能体态度，智能体在了解其他智能体性别时会调整观点；与先前研究相反，具有共同政治立场的智能体可以形成回音室，表现出随着辩论进展预期的态度强化。

**Conclusion:** 本研究通过多智能体辩论揭示了LLMs的政治偏见及其在互动中的复杂动态，包括中立LLM的倾向性、性别对态度的影响以及同立场智能体形成回音室的现象。

> **ai_Abstract:** 本研究通过构建一个结构化的多智能体辩论框架，深入探讨了大型语言模型（LLM）的政治偏见及其在模拟社会行为时的互动动态。研究通过让不同政治倾向（中立、共和党、民主党）和不同性别属性的LLM智能体就政治敏感话题进行辩论，系统分析了底层模型、智能体性别和辩论形式对政治偏见和态度的影响。主要发现包括：中立智能体倾向于民主党立场，共和党智能体向中立靠拢；智能体在得知对方性别时会调整态度；以及同政治立场智能体能形成回音室，强化既有态度。

> **摘要翻译:** 大型语言模型（LLM）越来越多地被用于模拟社会行为，但其政治偏见和在辩论中的互动动态仍未得到充分探索。我们通过一个结构化的多智能体辩论框架，让中立、共和党和民主党美国LLM智能体参与关于政治敏感话题的辩论，从而调查LLM类型和智能体性别属性如何影响政治偏见。我们系统地改变底层LLM、智能体性别和辩论形式，以检查模型来源和智能体角色如何在整个辩论过程中影响政治偏见和态度。我们发现，中立智能体始终与民主党保持一致，而共和党则更接近中立；性别会影响智能体的态度，智能体在了解其他智能体性别时会调整自己的观点；与之前的研究相反，具有共同政治立场的智能体可以形成回音室，表现出随着辩论进展预期的态度强化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [160] [Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](https://arxiv.org/abs/2506.11376)
> *大语言模型驱动的对话代理为家庭照护者提供问题解决疗法（PST）：利用情境学习增强同理心和治疗联盟*

*Liying Wang, Ph. D., Daffodil Carrington, M. S., Daniil Filienko, M. S., Caroline El Jazmi, M. S., Serena Jinchen Xie, M. S., Martine De Cock, Ph. D., Sarah Iribarren, Ph. D., Weichao Yuwen, Ph. D* | **Main category: cs.AI**

**Keywords:** 大语言模型, 对话代理, 问题解决疗法, 家庭照护者, 同理心

**Comment:** 

> **TL;DR:** 研究表明，通过情境学习和RAG技术优化的大语言模型对话代理，能有效为家庭照护者提供同理心和治疗联盟更强的心理支持。

**AI_Comments:** 这项研究的创新之处在于将大语言模型应用于为家庭照护者提供专业的心理健康支持，并成功地通过情境学习（Few-Shot和RAG）增强了模型的同理心和治疗联盟能力。其重要性在于为资源有限的特定弱势群体提供了一种可扩展、可及且个性化的心理干预方案。然而，研究也指出了一个关键局限性，即在提供彻底评估与高效给出建议之间仍需找到平衡点，这对于未来实际部署至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 家庭照护者因角色多样和资源有限常面临精神健康挑战，本研究旨在探索大语言模型（LLM）驱动的对话代理为他们提供循证心理支持的潜力。

**Method:** 本研究进行了一项受试者内部实验，28名家庭照护者与四种不同配置的大语言模型进行互动，以评估模型的同理心和治疗联盟。最佳表现的模型配置结合了少样本学习（Few-Shot）和检索增强生成（RAG）提示技术，并融入了临床医生策划的示例。

**Result:** 最佳模型配置在上下文理解和个性化支持方面表现出显著改进，这体现在定性反馈和感知同理心及治疗联盟的定量评分上。参与者高度评价模型验证情感、探索未表达感受和提供可行策略的能力。

**Conclusion:** 本研究强调了大语言模型在为家庭照护者提供富有同理心和量身定制的心理支持方面的巨大潜力。

> **ai_Abstract:** 本研究探讨了利用大语言模型（LLM）驱动的对话代理为家庭照护者提供问题解决疗法（PST）等心理支持的潜力。通过一项28名照护者参与的内部实验，结果显示结合少样本学习、检索增强生成（RAG）和临床医生示例的LLM配置在增强同理心和治疗联盟方面表现最佳，为照护者提供了改进的个性化支持和可操作策略。研究强调了LLM在提供富有同理心和定制化支持方面的应用前景，尽管在评估彻底性与高效建议传递之间仍存在平衡挑战。

> **摘要翻译:** 家庭照护者因其多重角色和有限资源，常常面临巨大的精神健康挑战。本研究探索了由大型语言模型（LLM）驱动的对话代理为照护者提供循证心理健康支持的潜力，特别是结合了问题解决疗法（PST）、动机访谈（MI）和行为链分析（BCA）的方案。我们进行了一项受试者内部实验，28名照护者与四种LLM配置进行互动，以评估同理心和治疗联盟。表现最佳的模型融合了少样本学习（Few-Shot）和检索增强生成（RAG）提示技术，并结合了临床医生策划的示例。通过定性反馈和对感知同理心及治疗联盟的定量评分，模型显示出改进的上下文理解和个性化支持。参与者高度评价模型验证情感、探索未表达感受和提供可操作策略的能力。然而，平衡彻底评估与高效建议传递仍然是一个挑战。这项工作突出了LLM在为家庭照护者提供富有同理心和量身定制支持方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [178] [FocalAD: Local Motion Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11419)
> *FocalAD：面向端到端自动驾驶的局部运动规划*

*Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song* | **Main category: cs.AI**

**Keywords:** 端到端自动驾驶, 局部运动规划, 运动预测, 交互表示, 鲁棒性

**Comment:** 

> **TL;DR:** FocalAD是一个新的端到端自动驾驶框架，通过关注关键局部邻居并增强局部运动表示来改进规划，显著提高了规划的可靠性和鲁棒性，尤其是在对抗性场景中。

**AI_Comments:** FocalAD的创新点在于其针对端到端自动驾驶中局部交互的深度关注，通过ELAI和FLA Loss模块，有效地将局部关键信息融入到运动规划中。这种局部优先的策略解决了传统方法因全局特征聚合而忽视局部风险的问题，显著提升了系统在复杂和对抗性环境下的鲁棒性和安全性。其在碰撞率上的显著降低尤其突出，证明了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的端到端自动驾驶方法在运动预测中常依赖全局聚合运动特征，但规划决策主要受少数局部交互代理影响，忽视这些关键局部交互可能掩盖潜在风险并损害规划可靠性。

**Method:** 本文提出了FocalAD，一个新颖的端到端自动驾驶框架，通过关注关键局部邻居和增强局部运动表示来优化规划。FocalAD包含两个核心模块：自我-局部代理交互器（ELAI）和焦点-局部代理损失（FLA Loss）。ELAI进行基于图的自我中心交互表示，捕获与局部邻居的运动动态，以增强自我规划和代理运动查询。FLA Loss增加决策关键邻近代理的权重，引导模型优先考虑与规划更相关的代理。

**Result:** FocalAD在开放循环nuScenes数据集和闭环Bench2Drive基准测试中均优于现有最先进方法。在以鲁棒性为重点的Adv-nuScenes数据集上，FocalAD取得了更大的改进，与DiffusionDrive相比，平均碰撞率降低了41.9%，与SparseDrive相比降低了15.6%。

**Conclusion:** FocalAD通过关注局部关键交互并增强局部运动表示，显著提升了端到端自动驾驶的规划可靠性和鲁棒性，尤其在复杂和对抗性场景下表现优异。

> **ai_Abstract:** 本文提出了FocalAD，一个用于端到端自动驾驶的新框架，旨在解决现有方法忽视局部关键交互导致规划可靠性不足的问题。FocalAD通过引入自我-局部代理交互器（ELAI）进行图基交互表示，并利用焦点-局部代理损失（FLA Loss）加权决策关键邻居，从而增强局部运动表示并优化规划。实验结果表明，FocalAD在多个数据集上均超越了现有SOTA方法，尤其在对抗性场景中显著降低了碰撞率，验证了其在提升自动驾驶规划可靠性和鲁棒性方面的有效性。

> **摘要翻译:** 在端到端自动驾驶中，运动预测在自我车辆规划中起着关键作用。然而，现有方法通常依赖全局聚合运动特征，忽略了规划决策主要受少数局部交互代理影响的事实。未能关注这些关键的局部交互可能会掩盖潜在风险并损害规划可靠性。在这项工作中，我们提出了FocalAD，一个新颖的端到端自动驾驶框架，它专注于关键的局部邻居并通过增强局部运动表示来改进规划。具体而言，FocalAD包含两个核心模块：自我-局部代理交互器（ELAI）和焦点-局部代理损失（FLA Loss）。ELAI进行基于图的自我中心交互表示，捕捉与局部邻居的运动动态，以增强自我规划和代理运动查询。FLA Loss增加决策关键邻近代理的权重，引导模型优先考虑那些与规划更相关的代理。广泛的实验表明，FocalAD在开放循环nuScenes数据集和闭环Bench2Drive基准测试中均优于现有最先进方法。值得注意的是，在以鲁棒性为重点的Adv-nuScenes数据集上，FocalAD取得了更大的改进，与DiffusionDrive相比，平均碰撞率降低了41.9%，与SparseDrive相比降低了15.6%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [198] [Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention](https://arxiv.org/abs/2506.11445)
> *基于局部状态注意力的多自动驾驶汽车控制中高速公路冲突的解决*

*Xuan Duy Ta, Bang Giang Le, Thanh Ha Le, Viet Cuong Ta* | **Main category: cs.AI**

**Keywords:** 自动驾驶, 多智能体强化学习, 局部状态注意力, 交通冲突, 高速公路并道

**Comment:** 

> **TL;DR:** 提出局部状态注意力模块，以解决多自动驾驶汽车在混合交通中遇到的局部冲突，提高并道效率。

**AI_Comments:** 该论文通过引入局部状态注意力模块，有效地解决了多智能体强化学习在处理自动驾驶中局部冲突和随机事件方面的挑战。其创新点在于利用自注意力机制来压缩关键的局部状态信息，从而提高在复杂混合交通环境下的决策效率和泛化能力。在高速公路并道场景中的显著性能提升，证明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在混合交通环境中，自动驾驶汽车需要适应人类驾驶车辆和异常驾驶情况。现有的多智能体强化学习（MARL）方法，如Multi-agent Proximal Policy Optimization，在训练MARL任务时通常无法解决智能体之间的局部冲突，也无法泛化到随机事件。

**Method:** 本文提出了一个局部状态注意力模块来辅助输入状态表示。该模块通过依赖自注意力操作符，旨在压缩附近智能体的基本信息，以解决交通情况中的冲突。

**Result:** 在模拟高速公路并道场景中，以优先车辆作为意外事件，我们的方法能够优先处理其他车辆的信息来管理并道过程。结果表明，与流行的基线相比，尤其是在高密度交通设置下，并道效率显著提高。

**Conclusion:** 局部状态注意力模块能够有效处理多自动驾驶汽车在混合交通环境中的局部冲突，显著提高并道效率，尤其是在高密度交通条件下。

> **ai_Abstract:** 本文提出一种名为“局部状态注意力”的新模块，用于多自动驾驶汽车在混合交通环境中的控制。该模块利用自注意力机制，有效处理附近车辆信息，以解决现有MARL方法在处理局部冲突和随机事件时的不足。在模拟高速公路并道场景中的实验证明，该方法显著提升了并道效率，尤其是在交通密度较高的情况下。

> **摘要翻译:** 在混合交通环境中，自动驾驶车辆必须适应人类控制的车辆和其他异常驾驶情况。这种设置可以被构建为一个多智能体强化学习（MARL）环境，其中自动驾驶车辆之间具有完全合作的奖励。虽然像多智能体近端策略优化（Multi-agent Proximal Policy Optimization）这样的方法在训练MARL任务时可能有效，但它们通常无法解决智能体之间的局部冲突，也无法泛化到随机事件。在本文中，我们提出了一个局部状态注意力模块来辅助输入状态表示。通过依赖自注意力操作符，该模块有望压缩附近智能体的基本信息，以解决交通情况中的冲突。利用一个以优先车辆作为意外事件的模拟高速公路并道场景，我们的方法能够优先处理其他车辆的信息来管理并道过程。结果表明，与流行的基线相比，尤其是在高密度交通设置下，并道效率显著提高。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [216] [Structure-Aware Automatic Channel Pruning by Searching with Graph Embedding](https://arxiv.org/abs/2506.11469)
> *基于图嵌入搜索的结构感知自动通道剪枝*

*Zifan Liu, Yuan Cao, Yanwei Yu, Heng Qi, Jie Gui* | **Main category: cs.AI**

**Keywords:** 通道剪枝, 图卷积网络, 结构感知, 自动剪枝, 深度神经网络

**Comment:** 12 pages, 2 figures

> **TL;DR:** 提出SACP框架，利用图卷积网络实现结构感知和自动通道剪枝，以提高深度神经网络的压缩效率并保持性能。

**AI_Comments:** 本文的创新之处在于将图卷积网络引入通道剪枝领域，通过建模网络拓扑来捕获全局结构依赖，从而实现更优的剪枝决策。此外，其全自动化的剪枝过程也显著减少了人工干预的需求，提升了实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有通道剪枝方法依赖局部启发式或基于权重的标准，未能捕获网络全局结构依赖，导致剪枝决策次优和模型性能下降。

**Method:** 提出结构感知自动通道剪枝 (SACP) 框架，利用图卷积网络 (GCNs) 建模网络拓扑并学习通道的全局重要性。该方法通过编码结构关系实现拓扑感知和全自动剪枝，并通过搜索方法在特定剪枝率组合空间中确定最优组合。

**Result:** 在CIFAR-10和ImageNet数据集上，使用ResNet和VGG16等模型进行的实验表明，SACP在压缩效率上优于现有最先进的剪枝方法，并在精度保持上具有竞争力。

**Conclusion:** SACP是一种有效的通道剪枝方法，通过结构感知和自动化，在提高压缩效率的同时保持了深度神经网络的性能。

> **ai_Abstract:** 本文提出了一种新颖的结构感知自动通道剪枝 (SACP) 框架，旨在解决现有方法未能捕获网络全局结构依赖的局限性。SACP利用图卷积网络 (GCNs) 建模网络拓扑并学习通道的全局重要性，实现了拓扑感知和全自动剪枝。该方法通过搜索确定最优剪枝率组合。实验证明，SACP在压缩效率上优于现有方法，并在精度保持上具有竞争力。

> **摘要翻译:** 通道剪枝是一种强大的技术，可以减少深度神经网络的计算开销，从而在资源受限的设备上实现高效部署。然而，现有的剪枝方法通常依赖于局部启发式或基于权重的标准，未能捕获网络内部的全局结构依赖，导致次优的剪枝决策和模型性能下降。为了解决这些限制，我们提出了一种新颖的结构感知自动通道剪枝 (SACP) 框架，该框架利用图卷积网络 (GCNs) 对网络拓扑进行建模，并学习每个通道的全局重要性。通过编码网络内的结构关系，我们的方法实现了拓扑感知剪枝，并且这种剪枝是完全自动化的，减少了人工干预的需要。我们将剪枝率组合限制在特定空间内，其中组合的数量可以动态调整，并使用基于搜索的方法来确定最佳剪枝率组合。在基准数据集 (CIFAR-10, ImageNet) 上使用各种模型 (ResNet, VGG16) 进行的广泛实验表明，SACP在压缩效率上优于最先进的剪枝方法，并在精度保持上具有竞争力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [230] [Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models](https://arxiv.org/abs/2506.11487)
> *在推理模型时代复兴DSP以进行高级定理证明*

*Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, Fan Yang* | **Main category: cs.AI**

**Keywords:** 定理证明, 神经符号, DSP+, 形式化验证, 推理模型

**Comment:** 31 pages. Associated code and results are available at
  https://github.com/microsoft/DSP-Plus

> **TL;DR:** DSP+，一个改进的神经符号定理证明框架，在不进行模型训练的情况下，通过协调现有推理模型和策略证明器，实现了与最先进的基于RL的方法相当的性能，并解决了之前未解决的问题。

**AI_Comments:** 本文的创新之处在于，它挑战了当前自动化定理证明领域中普遍依赖大规模RL训练的范式。通过精心设计的神经符号协调框架DSP+，作者证明了在不进行额外模型训练的情况下，也能达到甚至超越现有先进方法的性能。这不仅为定理证明领域开辟了新的研究方向，也强调了经典推理模式与现代推理模型有效结合的潜力。DSP+能够解决此前未解决的问题，并生成人类可理解的证明，这对于促进形式化验证和错误识别具有重要意义。论文承诺开源所有组件，这将极大地促进后续研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动化定理证明趋势依赖于基于强化学习的大规模训练。然而，本文发现即使不进行训练，通过精心协调神经符号方法和现有推理模型，也能达到可比的性能，从而激发了对经典推理模式潜力的探索。

**Method:** 本文提出了DSP+框架，这是Draft, Sketch, and Prove的改进版本，通过细粒度集成神经符号增强：(1) 草稿阶段：模型生成简洁的自然语言子目标，去除思考标记和人类证明引用；(2) 草图阶段：子目标被假设自动形式化，并根据规则掩盖语法错误；(3) 证明阶段：紧密集成符号搜索方法（如Aesop）与步骤证明器来建立子目标的证明。

**Result:** 在不进行额外模型训练或微调的情况下，DSP+解决了miniF2F中80.7%、ProofNet中32.8%以及PutnamBench中644个问题中的24个，且所需预算更少。它解决了miniF2F中一个以前未解决的IMO问题（imo_2019_p1）。此外，DSP+生成的证明模式对人类专家可理解，有助于发现形式化错误，例如发现了miniF2F中的八个错误形式化语句。

**Conclusion:** 研究结果强调了除基于强化学习训练之外的经典推理模式的潜力。DSP+在不依赖大规模模型训练的情况下，实现了先进的定理证明性能，并能生成可理解的证明。

> **ai_Abstract:** 本文提出了DSP+，一个改进的神经符号定理证明框架，旨在挑战当前基于RL的大规模训练趋势。DSP+通过在草稿、草图和证明三个阶段中细粒度集成神经符号增强，实现了卓越的性能。它能够在不进行额外模型训练的情况下，有效协调现有推理模型和策略证明器，解决多项基准测试中的问题，包括之前未解决的IMO问题。DSP+不仅效率高，而且生成的证明模式易于人类理解，有助于发现形式化错误，突显了经典推理模式在高级定理证明中的巨大潜力。

> **摘要翻译:** 最近的进展，例如DeepSeek-Prover-V2-671B和Kimina-Prover-Preview-72B，展示了利用基于强化学习（RL）的大规模训练进行自动化定理证明的普遍趋势。令人惊讶的是，我们发现即使没有任何训练，通过精心协调现有的即用型推理模型和策略步骤证明器，也能达到可比的性能。本文介绍了**DSP+**，一个改进版的Draft, Sketch, and Prove框架，其特点是对每个阶段进行

细粒度且集成

的神经符号增强：(1) 在草稿阶段，我们提示推理模型生成简洁的自然语言子目标，以利于草图阶段，同时移除思考标记和对人类编写证明的引用；(2) 在草图阶段，子目标被假设自动形式化，以利于证明阶段，并且根据预定义规则屏蔽包含语法错误的草图行；(3) 在证明阶段，我们紧密集成符号搜索方法（如Aesop）与步骤证明器，以建立草图子目标的证明。实验结果表明，在不进行任何额外模型训练或微调的情况下，DSP+分别解决了miniF2F中80.7%、ProofNet中32.8%以及PutnamBench中644个问题中的24个，同时与最先进的方法相比所需预算更少。DSP+证明了

imo_2019_p1

，这是一个miniF2F中的IMO问题，此前没有任何现有工作解决过。此外，DSP+生成了人类专家可理解的证明模式，有助于识别形式化错误；例如，发现了miniF2F中八个错误形式化的语句。我们的结果突出了除基于RL训练之外的经典推理模式的潜力。所有组件都将开源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [246] [RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning](https://arxiv.org/abs/2506.11555)
> *RAG+：通过应用感知推理增强检索增强生成*

*Yu Wang, Shiwan Zhao, Ming Fan, Zhihu Wang, Yubo Zhang, Xicheng Zhang, Zhengfan Wang, Heyuan Huang, Ting Liu* | **Main category: cs.AI**

**Keywords:** 检索增强生成, 应用感知推理, 大型语言模型, 知识整合, 双语料库

**Comment:** 

> **TL;DR:** RAG+通过明确整合应用感知推理来改进检索增强生成（RAG），解决了现有RAG在知识应用方面的不足，并通过双语料库和联合检索实现了在数学、法律和医学领域的一致性能提升。

**AI_Comments:** RAG+的创新之处在于其将“应用感知推理”明确地融入RAG流程，解决了传统RAG在知识应用层面的不足。通过构建双语料库和联合检索机制，RAPER使得LLMs不仅能够获取信息，更能理解如何将这些信息应用于特定任务。这种方法具有重要意义，因为它使得LLMs的知识整合更加认知化和可解释，有助于提升LLMs在复杂知识密集型任务中的性能和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有检索增强生成（RAG）范式在整合外部知识时，常常忽略了知识应用的认知步骤，导致检索到的事实与任务特定推理之间存在差距。

**Method:** RAG+引入了一个原则性、模块化扩展，将应用感知推理明确整合到RAG流程中。它构建了一个包含知识和对齐应用示例的双语料库（可手动或自动创建），并在推理过程中联合检索两者。这种设计使大型语言模型不仅能获取相关信息，还能在结构化、目标导向的推理过程中应用这些信息。

**Result:** 在数学、法律和医学领域，RAG+在多个模型上的实验表明，它始终优于标准RAG变体，平均性能提升3-5%，在复杂场景中峰值增益高达7.5%。

**Conclusion:** RAG+通过将检索与可操作的应用相结合，推进了一个更具认知基础的知识整合框架，代表着迈向更可解释、能力更强的LLM的重要一步。

> **ai_Abstract:** RAG+是一种新的检索增强生成（RAG）框架，旨在通过显式整合“应用感知推理”来弥补现有RAG在知识应用方面的不足。它通过构建一个包含知识和应用示例的双语料库，并在推理时联合检索，使大型语言模型（LLMs）能够更有效地应用检索到的信息。实验证明，RAG+在多个领域和模型上均能持续超越标准RAG，平均性能提升3-5%，最高可达7.5%。这标志着RAG向更具认知基础和可解释性的LLMs迈进。

> **摘要翻译:** 检索增强生成（RAG）通过整合外部知识，已成为增强大型语言模型（LLM）处理知识密集型任务的基础。然而，现有的RAG范式常常忽视知识应用的认知步骤，导致检索到的事实与任务特定推理之间存在差距。在这项工作中，我们引入了RAG+，一个原则性且模块化的扩展，它明确地将应用感知推理整合到RAG流程中。RAG+构建了一个由知识和对齐应用示例组成的双语料库，这些语料库可以手动或自动创建，并在推理过程中联合检索两者。这种设计使LLM不仅能够访问相关信息，还能在结构化、目标导向的推理过程中应用这些信息。在数学、法律和医学领域对多个模型进行的实验表明，RAG+始终优于标准RAG变体，平均性能提升3-5%，在复杂场景中峰值增益高达7.5%。通过将检索与可操作的应用相结合，RAG+推进了一个更具认知基础的知识整合框架，代表着迈向更可解释、能力更强的LLM的重要一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [262] [Collaborative LLM Inference via Planning for Efficient Reasoning](https://arxiv.org/abs/2506.11578)
> *通过规划实现高效推理的协作式大型语言模型推理*

*Byeongchan Lee, Jonghoon Lee, Dongyoung Kim, Jaehyung Kim, Jinwoo Shin* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 协作推理, 规划, 成本效益, 模型部署

**Comment:** 

> **TL;DR:** 本文提出了一种协作式LLM推理框架，通过规划将小型和大型模型结合起来，在保持高准确性的同时显著降低了对付费推理的依赖。

**AI_Comments:** 这项研究的创新点在于提出了一个新颖的协作推理框架，有效地结合了不同规模LLM的优势，解决了高性能模型成本高昂的实际问题。通过引入“规划”作为中间步骤，实现了成本效益与性能的平衡，对于LLM在资源受限环境下的广泛应用具有重要意义。该方法提供了一个实用的解决方案，以在不牺牲太多准确性的前提下降低大型模型的使用成本。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在复杂推理任务中表现出色，但功能强大的模型通常通过付费API访问，成本高昂。小型开源LLMs虽然免费且易于部署，但推理能力不足。本文旨在探索小型（免费）和大型（昂贵）模型在测试时能否协作以结合各自优势。

**Method:** 本文提出了一种测试时协作框架。其中，规划器模型首先生成一个“计划”，即问题的精炼和高级抽象。该计划作为轻量级中间件，指导推理器模型生成完整的解决方案。小型和大型模型轮流充当规划器和推理器，通过多轮级联交换计划，协作解决复杂任务。

**Result:** 该方法实现了与单独使用强大的专有模型相当的准确性，同时显著降低了对付费推理的依赖。

**Conclusion:** 规划作为一种有效的先验，可以在实际部署限制下，协调成本敏感的跨模型推理。

> **ai_Abstract:** 本文提出了一种协作式大型语言模型（LLM）推理框架，旨在结合小型开源模型和大型付费模型的优势。该框架中，一个“规划器”模型生成问题的高级抽象计划，然后由“推理器”模型基于此计划生成完整解决方案。小型和大型模型交替扮演规划器和推理器角色，通过多轮交互协作解决复杂任务。实验结果表明，该方法在保持与强大专有模型相当准确性的同时，显著降低了对付费推理的依赖，证明了规划在成本敏感的跨模型推理中的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在复杂推理任务中表现出色，但那些能力强大的模型（例如，参数数量大于100B的模型）通常只能通过付费API访问，这使得它们对于频繁使用的应用来说过于昂贵。相比之下，较小的开源LLMs（例如，参数数量小于3B的模型）是免费的，并且易于本地部署（例如，在单个具有8G VRAM的GPU下），但缺乏足够的推理能力。这种权衡引出了一个自然的问题：小型（免费）和大型（昂贵）模型能否在测试时协作以结合各自的优势？我们提出了一种测试时协作框架，其中规划器模型首先生成一个计划，该计划被定义为问题的精炼和高级抽象。该计划作为轻量级中间件，指导推理器模型生成完整的解决方案。小型和大型模型轮流充当规划器和推理器，通过多轮级联交换计划，协作解决复杂任务。我们的方法实现了与单独使用强大的专有模型相当的准确性，同时显著降低了对付费推理的依赖。这些结果突出表明，规划是一种有效的先验，可以在实际部署限制下，协调成本敏感的跨模型推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [276] [VLM@school -- Evaluation of AI image understanding on German middle school knowledge](https://arxiv.org/abs/2506.11604)
> *VLM@school -- 评估AI图像理解在德国中学知识上的表现*

*René Peinl, Vincent Tischler* | **Main category: cs.AI**

**Keywords:** 视觉语言模型, 基准数据集, 德国中学知识, 多模态理解, AI评估

**Comment:** 

> **TL;DR:** 本文引入了一个新的基准数据集，用于评估视觉语言模型（VLMs）在结合视觉推理和德语特定学科背景知识的任务上的能力。研究发现，即使是性能最好的模型在这些真实世界的任务中也表现不佳，强调了在非英语环境中压力测试VLMs的重要性。

**AI_Comments:** 本文的创新之处在于其引入了一个基于真实世界、非英语（德语）中学课程知识的视觉语言模型（VLM）评估基准。这解决了现有基准测试常依赖人工构造或脱离语境的英语问题的局限性。其重要性在于揭示了当前最先进VLM在实际应用场景（如教育领域）中，尤其是在需要深度知识集成和非英语语境下的不足，为未来VLM的发展指明了方向。通过关注真实世界的学科知识，该研究为AI在教育领域的应用提供了更贴近实际的评估标准。

<details>
  <summary>Details</summary>

**Motivation:** 现有广泛使用的英语基准测试往往依赖于人为制造的困难或脱离语境的问题，无法有效评估视觉语言模型（VLMs）在结合视觉推理和特定学科背景知识任务上的真实能力。因此，需要一个基于真实世界、非英语语境（尤其是德语中学课程）的基准数据集来更准确地评估和揭示VLMs的局限性。

**Method:** 本文设计并引入了一个名为VLM@school的新型基准数据集。该数据集从德国中学九个学科（包括数学、历史、生物和宗教）的真实课程中抽取内容，包含超过2,000个基于486张图像的开放式问题。研究评估了十三个最先进的开源VLM模型，从领域特定准确性和对抗性问题表现等多个维度进行测试，以确保模型必须整合视觉解释和事实推理，而非仅仅依赖表面文本线索。

**Result:** 研究发现，即使是最强的模型，总体准确率也低于45%，特别是在音乐、数学和对抗性设置中表现尤为糟糕。此外，结果表明，模型在流行基准测试上的成功与在真实世界多模态理解能力之间存在显著差异。

**Conclusion:** 中学生水平的任务为压力测试视觉语言模型（VLMs）提供了一个有意义且未被充分利用的途径，尤其是在非英语语境中。本文创建的数据集和评估协议可作为严格的测试平台，以更好地理解和改进未来AI系统的视觉和语言推理能力。

> **ai_Abstract:** 本文提出了一个名为VLM@school的新基准数据集，用于评估视觉语言模型（VLMs）在结合视觉理解和德语中学学科知识方面的能力。该数据集包含来自德国中学真实课程的2000多个图像相关开放式问题，旨在解决现有英语基准测试的局限性。通过评估13个最先进的开源VLM，研究发现即使是表现最好的模型，其在真实世界中学任务中的准确率也低于45%，尤其在音乐和数学等领域表现不佳。这表明在流行基准测试上的成功与实际多模态理解之间存在差距。研究强调中学级任务是压力测试VLMs，尤其是在非英语环境中，一个有价值的途径。

> **摘要翻译:** 本文介绍了一个新颖的基准数据集，旨在评估视觉语言模型（VLMs）在结合视觉推理和德语特定学科背景知识的任务上的能力。与广泛使用的、通常依赖人为制造的困难或脱离语境问题的英语基准测试不同，该数据集取材于德国中学九个领域（包括数学、历史、生物和宗教）的真实课程。该基准包含2,000多个基于486张图像的开放式问题，确保模型必须整合视觉解释和事实推理，而非仅仅依赖肤浅的文本线索。我们评估了十三个最先进的开源VLM模型，涵盖多个维度，包括领域特定准确性和在对抗性问题上的表现。我们的研究结果表明，即使是最强的模型，其总体准确率也低于45%，尤其是在音乐、数学和对抗性设置中表现不佳。此外，结果表明，在流行基准测试上的成功与真实世界多模态理解之间存在显著差异。我们得出结论，中学水平的任务为压力测试VLM提供了一个有意义且未被充分利用的途径，尤其是在非英语语境中。该数据集和评估协议可作为严格的测试平台，以更好地理解和改进未来AI系统的视觉和语言推理能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [288] [Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization](https://arxiv.org/abs/2506.11712)
> *通过理论一致的对称多模态偏好优化来缓解幻觉*

*Wenqi Liu, Xuemeng Song, Jiaxi Li, Yinwei Wei, Na Zheng, Jianhua Yin, Liqiang Nie* | **Main category: cs.AI**

**Keywords:** 多模态大语言模型, 幻觉缓解, 偏好优化, 对称学习, 直接偏好监督

**Comment:** 

> **TL;DR:** 提出SymMPO，一种理论一致的对称多模态偏好优化方法，通过直接偏好监督和偏好裕度一致性损失来有效缓解多模态大语言模型中的幻觉问题。

**AI_Comments:** 本文创新性地提出了SymMPO，通过引入对称偏好学习和偏好裕度一致性损失，解决了现有DPO方法在多模态幻觉缓解中优化目标不严谨和偏好监督不直接的问题。其理论一致性保证了方法的稳健性，并在实践中展现了优越性能，对提升MLLMs的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有缓解多模态大语言模型（MLLMs）幻觉的DPO方法虽然通过视觉对比目标取得进展，但存在优化目标函数不严谨和偏好监督不直接的问题。

**Method:** 提出对称多模态偏好优化（SymMPO），通过直接偏好监督（即响应对）进行对称偏好学习，以增强视觉理解，并保持与标准DPO的严格理论一致性。此外，SymMPO引入偏好裕度一致性损失来定量调节对称偏好对之间的偏好差距。

**Result:** 在五个基准测试中进行了综合评估，SymMPO表现出卓越的性能。

**Conclusion:** SymMPO在缓解多模态大语言模型中的幻觉问题上是有效的。

> **ai_Abstract:** 本文提出了一种名为对称多模态偏好优化（SymMPO）的新方法，旨在解决多模态大语言模型（MLLMs）中幻觉问题。针对现有DPO方法在偏好监督和优化严谨性方面的不足，SymMPO通过直接偏好监督进行对称偏好学习，并引入偏好裕度一致性损失来量化偏好差距，同时保持与标准DPO的理论一致性。实验结果表明，SymMPO在多个基准测试中表现优异，有效缓解了MLLMs的幻觉现象。

> **摘要翻译:** 直接偏好优化（DPO）已成为缓解多模态大语言模型（MLLMs）中幻觉问题的有效方法。尽管现有方法通过利用面向视觉的对比目标来增强MLLMs对视觉输入的注意力，从而减少幻觉，但它们存在优化目标函数不严谨和偏好监督不直接的问题。为了解决这些限制，我们提出了一种对称多模态偏好优化（SymMPO），它通过直接偏好监督（即响应对）进行对称偏好学习，以增强视觉理解，同时保持与标准DPO的严格理论对齐。除了传统的序数偏好学习，SymMPO还引入了偏好裕度一致性损失，以定量调节对称偏好对之间的偏好差距。在五个基准测试中的综合评估表明，SymMPO表现出卓越的性能，验证了其在缓解MLLMs幻觉方面的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [301] [Relational GNNs Cannot Learn $C_2$ Features for Planning](https://arxiv.org/abs/2506.11721)
> *关系图神经网络无法学习规划中的 $C_2$ 特征*

*Dillon Z. Chen* | **Main category: cs.AI**

**Keywords:** 关系图神经网络, R-GNN, 规划, $C_2$ 特征, 价值函数

**Comment:** 

> **TL;DR:** 关系图神经网络 (R-GNN) 无法学习规划问题中 $C_2$ 特征定义的价值函数，这与现有经验结果相悖。

**AI_Comments:** 这篇论文的创新之处在于挑战了当前关于 R-GNNs 学习能力的一些经验性认知，揭示了其在学习特定规划领域 $C_2$ 特征方面的局限性。其重要性在于促使研究人员重新审视 R-GNNs 的理论基础和实际应用，并寻找更合适的 GNN 架构来解决此类规划问题。

<details>
  <summary>Details</summary>

**Motivation:** R-GNNs 被理论上认为与 $C_2$（一种具有两个变量和计数的二阶逻辑）的表达能力有关，并且某些规划域的最优价值函数可以分解为 $C_2$ 特征的算术表达式，因此期望 R-GNNs 能够学习这些特征以泛化到未见问题。

**Method:** 论文通过理论分析或证明，表明关系图神经网络 (R-GNNs) 无法学习由 $C_2$ 特征定义的价值函数。

**Result:** 结果显示，与现有经验结果相反，R-GNNs 无法学习由 $C_2$ 特征定义的价值函数。

**Conclusion:** 关系图神经网络 (R-GNNs) 无法学习规划中由 $C_2$ 特征定义的价值函数。论文还指出了可能更适合学习 $C_2$ 特征的现有 GNN 架构。

> **ai_Abstract:** 本文研究了关系图神经网络 (R-GNNs) 在规划领域中学习 $C_2$ 特征定义价值函数的能力。尽管 R-GNNs 在理论上与 $C_2$ 的表达能力相关联，并且一些规划问题的最优价值函数可由 $C_2$ 特征表示，但本文证明 R-GNNs 实际上无法学习这些价值函数，这与先前的经验结果相悖。此外，论文还提出了可能更适合学习 $C_2$ 特征的其他 GNN 架构。

> **摘要翻译:** 关系图神经网络 (R-GNNs) 是一种基于 GNN 的方法，用于学习价值函数，这些函数可以从给定的规划域泛化到未见问题。R-GNNs 的理论动机是 GNN 的表达能力与 $C_2$（一种具有两个变量和计数的二阶逻辑）之间众所周知的联系。在规划的背景下，$C_2$ 特征是指 $C_2$ 中由规划域的一元和二元谓词定义的关系公式集合。一些规划域的最优价值函数可以分解为 $C_2$ 特征的算术表达式。我们表明，与经验结果相反，R-GNNs 无法学习由 $C_2$ 特征定义的价值函数。我们还识别了以前的 GNN 架构，它们可能更好地学习由 $C_2$ 特征定义的价值函数。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [312] [Causal Effect Identification in Heterogeneous Environments from Higher-Order Moments](https://arxiv.org/abs/2506.11756)
> *异质环境下基于高阶矩的因果效应识别*

*Yaroslav Kivva, Sina Akbari, Saber Salehkaleybar, Negar Kiyavash* | **Main category: cs.AI**

**Keywords:** 因果效应, 潜在混杂因素, 异质环境, 可识别性, 基于矩算法

**Comment:** 

> **TL;DR:** 本文研究了在存在潜在混杂因素的情况下，如何从多源环境中识别和估计因果效应，并提出了一种基于矩的算法，适用于数据生成机制中只有一个参数在不同环境间变化的情况。

**AI_Comments:** 本文的创新之处在于利用异质环境中的高阶矩来解决存在潜在混杂因素时的因果效应识别问题。其重要性在于为复杂数据环境下的因果推断提供了新的理论基础和算法。局限性可能在于其对“只有一个参数变化”的假设，这在现实世界的复杂场景中可能难以完全满足，并且目前仅在合成数据上进行了评估。

<details>
  <summary>Details</summary>

**Motivation:** 研究目标是在存在潜在混杂因素的情况下，估计处理变量对结果的因果效应。

**Method:** 首先，证明了在多环境数据可用且目标因果效应在这些环境中保持不变的特定条件下，因果效应是可识别的。其次，提出了一种基于矩的算法来估计因果效应，前提是数据生成机制中只有一个参数（无论是外生噪声分布还是两个变量之间的因果关系）在不同环境间变化。最后，提出了一种识别数据生成机制中哪个参数在不同环境间变化的程序，并通过合成数据实验评估了所提出方法的性能。

**Result:** 研究表明，在多环境数据可用且目标因果效应保持不变的情况下，因果效应是可识别的。当数据生成机制中只有一个参数在不同环境间变化时，可以利用所提出的基于矩的算法来估计因果效应。相反，如果潜在变量和处理变量的两种外生噪声分布都在不同环境间变化，则可识别性会丧失。

**Conclusion:** 在某些条件下，即使存在潜在混杂因素，也可以从异质环境中识别因果效应，并且所提出的基于矩的算法在特定参数变化模式下有效。然而，如果多个关键参数同时变化，则可识别性会丧失。

> **ai_Abstract:** 本文探讨了在存在潜在混杂因素时，如何利用异质环境数据识别和估计因果效应。研究表明，在因果效应在不同环境间保持不变的条件下，因果效应是可识别的。文章提出了一种基于矩的算法，用于当数据生成机制中只有一个参数（如噪声分布或因果关系）在环境间变化时进行估计。同时，证明了当潜在变量和处理变量的噪声分布均在环境间变化时，可识别性会丧失。此外，还提出了识别变化参数的程序，并通过合成数据验证了方法的有效性。

> **摘要翻译:** 我们研究了在存在潜在混杂因素的情况下，处理变量对结果的因果效应估计。我们首先表明，当数据来自多个环境时，在特定条件下，只要目标因果效应在这些环境中保持不变，因果效应就是可识别的。其次，我们提出了一种基于矩的算法来估计因果效应，只要数据生成机制中只有一个参数在不同环境间变化——无论是外生噪声分布还是两个变量之间的因果关系。相反，我们证明如果潜在变量和处理变量的两种外生噪声分布都在不同环境间变化，可识别性就会丧失。最后，我们提出了一种识别数据生成机制中哪个参数在不同环境间变化的程序，并通过合成数据实验评估了我们所提出方法的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [320] [On the Performance of LLMs for Real Estate Appraisal](https://arxiv.org/abs/2506.11812)
> *大型语言模型在房地产估价中的表现*

*Margot Geerts, Manon Reusens, Bart Baesens, Seppe vanden Broucke, Jochen De Weerdt* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 房地产估价, 上下文学习, 房价预测, 信息不对称

**Comment:** Accepted at ECML-PKDD 2025

> **TL;DR:** 研究评估了大型语言模型（LLMs）在房地产估价中的表现，发现它们能提供有竞争力的可解释估价，但在纯预测准确性上仍不如传统模型，且存在过度自信和空间推理不足的问题。

**AI_Comments:** 该论文创新性地将大型语言模型应用于房地产估价领域，并强调了其在提供可解释性方面的优势，这对于改善房地产市场的信息不对称具有重要意义。尽管LLMs在纯预测准确性和某些局限性（如过度自信和空间推理）上仍需提升，但其交互性和可解释性为该领域带来了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 房地产市场存在严重的信息不对称，本研究旨在探讨大型语言模型（LLMs）如何通过生成有竞争力和可解释的房价估算来普及房地产洞察，从而改善市场透明度。

**Method:** 本研究系统地评估了领先的LLMs在多样化的国际住房数据集上的表现，比较了零样本、少样本、市场报告增强和混合提示技术，并通过优化上下文学习（ICL）策略来生成有竞争力和可解释的房价估算。同时，分析了LLMs如何利用享乐变量进行估算，并评估了其自我解释的可靠性。

**Result:** LLMs能有效利用享乐变量（如物业大小和便利设施）生成有意义的估算。尽管传统机器学习模型在纯预测准确性上仍表现强劲，但LLMs提供了更易于访问、交互和可解释的替代方案。LLMs的自我解释与最先进模型一致，证实了其可靠性。基于特征相似性和地理邻近性精心选择的上下文示例能显著提升LLM性能，但LLMs在价格区间上的过度自信和有限的空间推理能力是其弱点。

**Conclusion:** 本研究强调了LLMs在改善房地产估价透明度方面的潜力，并为利益相关者提供了可行的见解。通过提示优化，LLMs在结构化预测任务中具有应用前景。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在房地产估价中的应用。通过评估不同提示策略下LLMs在国际住房数据集上的表现，发现LLMs能有效利用享乐变量生成可解释的房价估算，并提供比传统模型更易于访问和交互的替代方案。尽管LLMs在纯预测准确性上仍有不足，且存在过度自信和空间推理限制，但其解释能力与现有先进模型一致。研究提出优化上下文学习能显著提升性能，并强调了LLMs在提高房地产市场透明度方面的潜力。

> **摘要翻译:** 房地产市场对全球经济至关重要，但存在显著的信息不对称问题。本研究通过优化上下文学习（ICL）策略，探讨大型语言模型（LLMs）如何通过生成具有竞争力且可解释的房价估算来普及房地产洞察。我们系统地评估了领先的LLMs在多样化的国际住房数据集上的表现，比较了零样本、少样本、市场报告增强和混合提示技术。我们的结果表明，LLMs能有效利用享乐变量，如物业大小和便利设施，来生成有意义的估算。尽管传统机器学习模型在纯预测准确性方面仍然强大，但LLMs提供了一种更易于访问、交互和可解释的替代方案。虽然自我解释需要谨慎解读，但我们发现LLMs的预测解释与最先进的模型一致，证实了其可信度。基于特征相似性和地理邻近性精心选择的上下文示例能显著提升LLM性能，然而LLMs在价格区间的过度自信和有限的空间推理能力是其不足之处。我们为通过提示优化进行结构化预测任务提供了实用指导。我们的研究结果强调了LLMs在改善房地产估价透明度方面的潜力，并为利益相关者提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [336] [Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment](https://arxiv.org/abs/2506.11880)
> *解决大型语言模型中的偏见：公平AI招聘的策略与应用*

*Alejandro Peña, Julian Fierrez, Aythami Morales, Gonzalo Mancera, Miguel Lopez, Ruben Tolosana* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 偏见缓解, AI招聘, 隐私增强, 公平性

**Comment:** Submitted to AIES 2025 (Under Review)

> **TL;DR:** 本文分析了大型语言模型（LLMs）中的人口统计学偏见，并提出了一个隐私增强框架，通过减少学习管道中的性别信息来缓解AI招聘工具中的偏见，实验证明该框架能有效阻止偏见复制。

**AI_Comments:** 本文关注了LLM在高风险应用中一个关键的伦理问题——偏见，并提出了一个实用的解决方案。其创新点在于通过隐私增强框架来减少学习管道中的敏感信息，从而从源头缓解偏见。在AI招聘等对公平性要求极高的领域，这项工作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的成功，语言技术在高风险场景中的应用日益增多。然而，LLMs易受人口统计学偏见等伦理问题影响。本研究旨在分析基于Transformer的系统学习数据中人口统计学偏见的能力，并解决AI招聘中的偏见问题。

**Method:** 本文分析了基于Transformer的系统学习数据中人口统计学偏见的能力，并以AI招聘为例进行了案例研究。作者提出了一种隐私增强框架，旨在减少学习管道中的性别信息，从而减轻最终工具中的偏见行为。实验分析了数据偏见对基于两种不同LLM构建的系统的影响。

**Result:** 实验结果表明，所提出的隐私增强框架能够有效阻止训练系统复制数据中的偏见。

**Conclusion:** 本文提出的隐私增强框架能够有效缓解大型语言模型在AI招聘等高风险应用中学习和复制数据中的人口统计学偏见。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在高风险应用中存在的偏见问题，特别是人口统计学偏见。以AI招聘为例，研究分析了基于Transformer的系统学习数据中偏见的能力，并提出了一种隐私增强框架。该框架通过减少学习管道中的性别信息来缓解偏见行为。实验证明，该框架能有效阻止训练系统复制数据中的偏见，从而有助于构建更公平的AI工具。

> **摘要翻译:** 近年来，受大型语言模型（LLMs）成功的推动，语言技术在高风险场景中的应用日益增多。然而，尽管LLMs性能卓越，但它们易受伦理问题的影响，例如人口统计学偏见、问责制或隐私。这项工作旨在分析基于Transformer的系统学习数据中存在的人口统计学偏见的能力，并以基于AI的自动化招聘为例进行案例研究。我们提出了一个隐私增强框架，以减少学习管道中的性别信息，作为减轻最终工具中偏见行为的一种方式。我们的实验分析了数据偏见对基于两种不同LLMs构建的系统的影响，以及所提出的框架如何有效阻止训练系统复制数据中的偏见。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [342] [Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making](https://arxiv.org/abs/2506.11887)
> *面向成本效益型人机决策的级联LLM框架*

*Claudio Fanconi, Mihaela van der Schaar* | **Main category: cs.AI**

**Keywords:** 级联LLM, 人机决策, 成本效益, 弃权策略, 在线学习

**Comment:** 

> **TL;DR:** 该论文提出一个级联LLM框架，通过分层委托任务（基础模型、大型模型、人类专家）来平衡预测的正确性、知识获取成本和决策置信度，从而实现成本效益型人机决策。

**AI_Comments:** 该论文的创新点在于提出了一个分层级的LLM决策框架，有效解决了人机协作决策中正确性、成本和不确定性处理的平衡问题。其引入的推迟和弃权策略，以及在线学习机制，为构建更智能、更经济的AI辅助决策系统提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 有效的人机决策需要在预测的正确性、知识和推理的复杂性成本以及是否放弃自动化答案或寻求人类专家干预的置信度之间取得平衡。现有方法可能难以同时优化这三个因素。

**Method:** 本文提出了一个级联LLM决策框架，它自适应地将任务委托给多个专业层级：首先是基础模型提供初步答案，然后是能力更强但成本更高的大型模型，最后是当模型级联放弃时由人类专家介入。该方法分两个阶段进行：首先，一个推迟策略根据置信度决定是接受基础模型的答案还是用大型模型重新生成；其次，一个弃权策略决定级联模型响应是否足够确定或需要人工干预。此外，框架中还融入了在线学习机制，利用人类反馈随时间改进决策质量。

**Result:** 在通用问答（ARC-Easy和ARC-Challenge）和医学问答（MedQA和MedMCQA）任务上的实验表明，该级联策略在大多数情况下优于单模型基线，提高了准确性，同时降低了成本，并提供了一种处理弃权的原则性方法。

**Conclusion:** 该级联LLM框架通过分层决策和在线学习，成功地平衡了人机决策中的正确性、成本和弃权问题，并在多个问答任务中展现出优越的性能。

> **ai_Abstract:** 本研究提出一种级联LLM框架，旨在优化人机决策中的正确性、成本和弃权平衡。该框架包含基础模型、大型模型和人类专家三个层级，通过两阶段策略（推迟和弃权）自适应地委托任务。推迟策略基于置信度决定是否升级到更大型模型，弃权策略则判断是否需要人类干预。此外，框架整合了在线学习机制以持续改进。实验结果表明，该方法在多个问答任务中表现优异，既提高了准确性又降低了成本，并有效处理了弃权问题。

> **摘要翻译:** 有效的人机决策需要在三个关键因素之间取得平衡：预测的正确性、知识和推理复杂性的成本，以及关于是否放弃自动化答案或引入人类专家的置信度。在这项工作中，我们提出了一种级联LLM决策框架，该框架自适应地将任务委托给多个专业层级——一个用于初始候选答案的基础模型，一个能力更强且知识更丰富（但成本更高）的大型模型，以及当模型级联放弃时的人类专家。我们的方法分两个阶段进行。首先，一个推迟策略根据置信度分数决定是接受基础模型的答案还是用大型模型重新生成。其次，一个弃权策略决定级联模型响应是否足够确定或需要人工干预。此外，我们在框架中融入了一个在线学习机制，该机制可以利用人类反馈随时间提高决策质量。我们在通用问答（ARC-Easy和ARC-Challenge）和医学问答（MedQA和MedMCQA）中展示了这种方法。我们的结果表明，我们的级联策略在大多数情况下在准确性方面优于单模型基线，同时降低了成本并提供了一种处理弃权的原则性方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [350] [Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task](https://arxiv.org/abs/2506.11986)
> *Schema-R1：一种用于Text-to-SQL任务中模式链接的推理训练方法*

*Wuzhenghong Wen, Su Pan, yuwei Sun* | **Main category: cs.AI**

**Keywords:** 模式链接, Text-to-SQL, 强化学习, 推理能力, Schema-R1

**Comment:** 11 pages, 3 figures, conference

> **TL;DR:** Schema-R1通过强化学习提升了Text-to-SQL中模式链接的推理能力，解决了现有方法死记硬背的问题，并在过滤精度上提高了10%。

**AI_Comments:** 这篇论文通过引入强化学习来解决Text-to-SQL任务中模式链接的推理能力不足问题，具有创新性。它识别了现有方法过度依赖死记硬背的问题，并通过生成高质量推理样本和强化学习训练来直接解决。10%的过滤精度提升是一个显著的改进，表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前Text-to-SQL任务中的模式链接模型采用死记硬背的学习范式，过度优化真实标签结果，但损害了推理能力。这主要是因为难以获取高质量的下游任务推理样本。

**Method:** 本文提出了Schema-R1，一个基于强化学习训练的推理模式链接模型。该方法包括三个关键步骤：构建小批量高质量推理样本、进行冷启动初始化监督微调，以及基于规则的强化学习训练。

**Result:** 实验结果表明，该方法有效增强了模式链接模型的推理能力，与现有方法相比，过滤精度提高了10%。

**Conclusion:** 该研究成功通过强化学习提升了Text-to-SQL任务中模式链接的推理能力，显著优于现有死记硬背的方法。

> **ai_Abstract:** 本文提出了Schema-R1，一个通过强化学习训练的模式链接模型，旨在解决Text-to-SQL任务中现有方法因死记硬背而导致的推理能力不足问题。Schema-R1通过构建高质量推理样本、监督微调和基于规则的强化学习三步提升模型推理能力，实验证明其在过滤精度上比现有方法提高了10%。

> **摘要翻译:** 模式链接是Text-to-SQL任务中的关键一步，旨在根据给定问题准确预测SQL查询所需的表名和列名。然而，当前用于模式链接模型的微调方法采用死记硬背的学习范式，过度优化真实模式链接结果，从而损害了推理能力。这种局限性源于难以获取高质量的下游任务推理样本。为了解决这个问题，我们提出了Schema-R1，一个使用强化学习训练的推理模式链接模型。具体而言，Schema-R1包含三个关键步骤：构建小批量高质量推理样本、进行冷启动初始化的监督微调，以及基于规则的强化学习训练。最终结果表明，我们的方法有效地增强了模式链接模型的推理能力，与现有方法相比，过滤精度提高了10%。我们的代码可在https://github.com/hongWin/Schema-R1/获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [359] [Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making](https://arxiv.org/abs/2506.12012)
> *使用策略游戏追踪大型语言模型推理过程：一个关于规划、修正和资源受限决策的框架*

*Xiaopeng Yuan, Xingjian Zhang, Ke Xu, Yifan Xu, Lijun Yu, Jindong Wang, Yushun Dong, Haohan Wang* | **Main category: cs.AI**

**Keywords:** LLM推理, 策略游戏, 规划, 修正, 资源受限决策

**Comment:** 19 pages, 7 figures. Under review

> **TL;DR:** 本文提出一个框架，利用策略游戏评估大型语言模型（LLM）的中间推理过程，包括规划、修正和资源受限决策，而非仅关注最终结果。研究发现ChatGPT-o3-mini表现最佳，而Qwen-Plus因过度使用资源表现不佳，并强调评估LLM如何做出决策的重要性。

**AI_Comments:** 本文通过提出一种关注LLM中间推理过程的评估框架，在LLM评估方法上实现了重要的转变，超越了传统的只关注最终结果的范式。使用策略游戏作为评估环境，为评估LLM复杂的规划、修正和资源受限决策能力提供了一个清晰且可量化的平台，具有创新性。这项研究直接解决了LLM可解释性和可靠性问题，通过剖析其内部决策过程，为未来模型开发提供了关键见解，特别是关于过度修正和资源使用的权衡。

<details>
  <summary>Details</summary>

**Motivation:** 目前大多数大型语言模型（LLM）的基准测试只关注最终结果，而忽略了模型在复杂推理任务中的中间推理步骤，例如规划、修正和资源受限下的决策。理解和衡量这些内部过程对于深入理解模型行为和提高其可靠性至关重要。

**Method:** 本文提出使用策略游戏作为评估LLM的自然环境，这些游戏是封闭的、基于规则的系统，具有清晰的状态、有限的资源和自动反馈。研究引入了一个框架，从规划、修正和资源受限决策三个核心维度评估LLM。除了胜率，还定义了新的评估指标，包括过度修正风险率、修正成功率、改进斜率和超预算比。在4320轮对抗性测试中，对12个领先模型进行了评估。

**Result:** ChatGPT-o3-mini在综合得分上表现最佳，胜率为74.7%，修正成功率为78.6%，改进斜率为0.041。相比之下，Qwen-Plus尽管过度修正风险率高达81.6%，但胜率仅为25.6%，主要原因是过度使用资源。研究还发现过度修正风险率与修正成功率之间存在负相关（Pearson r = -0.51, p = 0.093）。

**Conclusion:** 研究结果强调了评估大型语言模型不仅要看它们做出什么决定，还要看它们如何做出这些决定的价值。频繁的编辑或修正并不总是能改善结果。

> **ai_Abstract:** 本文提出了一种新颖的框架，通过关注大型语言模型（LLM）的中间推理过程（包括规划、修正和资源受限决策），而非仅仅最终结果，来评估LLM。该框架利用策略游戏作为受控评估环境，并引入了过度修正风险率和修正成功率等新指标。对12个模型的实验结果显示，ChatGPT-o3-mini表现最佳，而Qwen-Plus因过度使用资源表现不佳。研究强调了理解LLM决策“如何形成”的重要性，并指出更频繁的修正不一定能带来更好的结果。

> **摘要翻译:** 大型语言模型（LLM）越来越多地用于需要复杂推理的任务。大多数基准测试只关注最终结果，而忽略了中间的推理步骤——例如规划、修正和资源受限下的决策。我们认为，衡量这些内部过程对于理解模型行为和提高可靠性至关重要。我们建议使用策略游戏作为一种自然的评估环境：封闭的、基于规则的系统，具有清晰的状态、有限的资源和自动反馈。我们提出了一个框架，从三个核心维度评估LLM：规划、修正和资源受限决策。为了实现这一点，我们定义了超越胜率的指标，包括过度修正风险率、修正成功率、改进斜率和超预算比。在针对12个领先模型的4320轮对抗性测试中，ChatGPT-o3-mini取得了最高的综合得分，胜率为74.7%，修正成功率为78.6%，改进斜率为0.041。相比之下，尽管Qwen-Plus的过度修正风险率为81.6%，但其胜率仅为25.6%——这主要是由于过度使用资源。我们还观察到过度修正风险率与修正成功率之间存在负相关（Pearson r = -0.51，p = 0.093），这表明更频繁的编辑并不总是能改善结果。我们的发现强调了评估LLM不仅决定了什么，而且如何做出这些决定的价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [600] [Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design](https://arxiv.org/abs/2506.04734)
> *评估就是你所需要的一切：通过评估设计战略性地夸大LLM推理能力*

*Lin Sun, Weihong Lin, Jinzhu Wu, Yongfu Zhu, Xiaoqi Jian, Guangxiang Zhao, Change Jia, Linglin Zhang, Sai-er Hu, Yuhan Wu, Xiangzheng Zhang* | **Main category: cs.AI**

**Keywords:** LLM评估, Deepseek-R1-Distill, 推理能力, 评估波动, 复现性

**Comment:** 

> **TL;DR:** 本研究揭示了Deepseek-R1-Distill等推理模型在基准评估中存在显著波动，且其声称的性能提升难以可靠复现。因此，作者呼吁建立更严格的模型性能评估范式。

**AI_Comments:** 这篇论文指出了当前大型语言模型（LLM）评估中一个关键且普遍存在的问题：评估结果的脆弱性和不可靠性。其重要性在于，它挑战了现有模型性能报告的有效性，并强调了评估方法本身对模型“能力”呈现的巨大影响。论文的创新点在于明确指出“评估设计”可以战略性地夸大模型能力，并呼吁行业对评估范式进行反思和改进。

<details>
  <summary>Details</summary>

**Motivation:** Deepseek-R1-Distill系列等推理模型因其在数学、科学、编程等领域的强大性能而被广泛采用。然而，研究发现它们的基准评估结果受多种因素影响而存在显著波动，细微的评估条件差异会导致结果的巨大变化，且声称的性能改进难以可靠复现。

**Method:** 本研究对Deepseek-R1-Distill系列模型进行了实证评估。

**Result:** 研究揭示，Deepseek-R1-Distill系列模型的基准评估结果存在显著波动，受多种因素影响，细微的评估条件差异可导致结果的巨大变化。类似现象也存在于其他基于Deepseek-R1-Distill系列微调的开源推理模型以及QwQ-32B模型中，使得其声称的性能改进难以可靠复现。

**Conclusion:** 本研究倡导建立更严格的模型性能评估范式，以解决当前评估中存在的波动性和结果难以复现的问题。

> **ai_Abstract:** 本研究发现，Deepseek-R1-Distill系列等流行的开源大型语言模型在数学、科学和编程等领域的基准评估结果存在显著波动，且其声称的性能提升难以可靠复现，这主要归因于评估设计的细微差异。为解决这一问题，论文呼吁建立更严格的模型性能评估范式，并提供了对Deepseek-R1-Distill系列模型的实证评估结果。

> **摘要翻译:** 推理模型，以Deepseek-R1-Distill系列为代表，因其在数学、科学、编程等领域的强大性能而被开源社区广泛采用。然而，我们的研究揭示，它们的基准评估结果受多种因素影响而存在显著波动。评估条件的细微差异可能导致结果的巨大变化。在其他基于Deepseek-R1-Distill系列微调的开源推理模型以及QwQ-32B模型中也观察到类似现象，使得它们声称的性能改进难以可靠复现。因此，我们倡导建立更严格的模型性能评估范式，并提出了我们对Deepseek-R1-Distill系列模型的实证评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [28] [Developing a Dyslexia Indicator Using Eye Tracking](https://arxiv.org/abs/2506.11004)
> *开发一种基于眼动追踪的阅读障碍指标*

*Kevin Cogan, Vuong M. Ngo, Mark Roantree* | **Main category: cs.LG**

**Keywords:** 阅读障碍, 眼动追踪, 机器学习, 早期检测, 随机森林

**Comment:** The 23rd International Conference on Artificial Intelligence in
  Medicine (AIME 2025), LNAI, Springer, 11 pages

> **TL;DR:** 本文研究了结合眼动追踪技术和机器学习算法作为一种经济有效的阅读障碍早期检测方法，并取得了88.58%的准确率。

**AI_Comments:** 这项研究的创新之处在于将眼动追踪技术与机器学习相结合，为阅读障碍的早期诊断提供了一种非侵入性、高准确率且成本效益高的新途径。其重要性在于能够及早识别阅读障碍个体，包括边缘病例，从而可能促进更及时的干预。该方法在不同人群和设置中的应用潜力也值得关注，为未来的临床应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 阅读障碍影响全球10%到20%的人口，严重损害学习能力，因此需要创新且可及的诊断方法。

**Method:** 通过分析包括注视时间延长和不规则扫视在内的普遍眼动模式，提出了一种增强的基于眼动追踪的阅读障碍特征确定方案。随后使用随机森林分类器检测阅读障碍，并应用层次聚类方法识别不同严重程度的阅读障碍。

**Result:** 随机森林分类器检测阅读障碍的准确率达到88.58%。该技术能够通过非侵入性手段识别阅读障碍个体，包括那些具有边缘特征的个体。

**Conclusion:** 眼动追踪与机器学习的结合代表了诊断过程的重大进步，为临床研究提供了一种高度准确且易于获取的方法。

> **ai_Abstract:** 本研究旨在开发一种基于眼动追踪和机器学习的经济有效且非侵入性的阅读障碍早期检测方法。通过分析眼动模式并使用随机森林分类器，该方法在阅读障碍检测中实现了88.58%的准确率。此外，研究还利用层次聚类识别了不同严重程度的阅读障碍，证明了该技术在临床诊断中的巨大潜力。

> **摘要翻译:** 阅读障碍影响全球约10%到20%的人口，严重损害学习能力，这凸显了对创新和可及诊断方法的需求。本文研究了眼动追踪技术结合机器学习算法作为一种经济有效的阅读障碍早期检测替代方案的有效性。通过分析普遍的眼动模式，包括延长注视时间和不规则扫视，我们提出了一种增强的、基于眼动追踪的阅读障碍特征确定方案。随后，采用随机森林分类器检测阅读障碍，准确率达到88.58%。此外，还应用层次聚类方法识别不同严重程度的阅读障碍。该分析结合了不同人群和环境下的多种方法，展示了该技术通过非侵入性手段识别阅读障碍个体（包括那些具有边缘特征的个体）的潜力。将眼动追踪与机器学习相结合代表了诊断过程的重大进步，在临床研究中提供了一种高度准确和可及的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [Large Language models for Time Series Analysis: Techniques, Applications, and Challenges](https://arxiv.org/abs/2506.11040)
> *大型语言模型用于时间序列分析：技术、应用与挑战*

*Feifei Shi, Xueyan Yin, Kang Wang, Wanyu Tu, Qifu Sun, Huansheng Ning* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 时间序列分析, 系统综述, 技术, 应用, 挑战

**Comment:** 

> **TL;DR:** 本文系统回顾了大型语言模型（LLMs）在时间序列分析中的应用，涵盖了其技术、潜在应用和面临的挑战，并为未来研究提供了指导。

**AI_Comments:** 这篇综述性论文的重要性在于它系统地梳理了新兴的LLM在时间序列分析领域的应用现状、技术路线和未来挑战。它不仅填补了这一快速发展领域知识整合的空白，还为研究人员提供了清晰的路线图，指出了有前景的研究方向，对于推动LLM在时间序列分析中的实际应用和理论发展具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统时间序列分析方法在非线性特征表示和长期依赖捕获方面存在局限性。大型语言模型（LLMs）凭借其跨模态知识整合和注意力机制，为时间序列分析带来了变革性潜力。然而，从零开始开发通用的时间序列LLM面临数据多样性、标注稀缺性和计算资源限制等挑战。

**Method:** 本文对预训练LLM驱动的时间序列分析进行了系统回顾。首先，建立了AI驱动时间序列分析的演进路线图，从早期机器学习到LLM驱动范式，再到原生时间基础模型的发展。其次，从工作流角度系统化地组织了LLM驱动时间序列分析的技术图景，包括LLM的输入、优化和轻量化阶段。最后，批判性地审视了新颖的实际应用，并强调了指导未来研究和创新的关键开放挑战。

**Result:** 该工作不仅提供了对当前进展的宝贵见解，还描绘了未来发展的有前景方向。

**Conclusion:** 本文为学术界和工业界研究人员提供了基础性参考，为开发更高效、更通用、更可解释的LLM驱动时间序列分析系统铺平了道路。

> **ai_Abstract:** 本文系统回顾了大型语言模型（LLMs）在时间序列分析中的应用。鉴于传统方法的局限性，LLMs展现出巨大潜力，尽管其从头开发面临数据和计算挑战。文章首先梳理了AI时间序列分析的演进路径，接着从工作流角度详细阐述了LLM驱动的时间序列分析技术，并探讨了实际应用及开放性挑战。该研究旨在为LLM驱动的时间序列分析提供全面指导，并促进未来更高效、通用和可解释系统的发展。

> **摘要翻译:** 时间序列分析在金融预测和生物医学监测等领域至关重要，但传统方法受限于有限的非线性特征表示和长期依赖捕获能力。大型语言模型（LLMs）的出现，通过利用其跨模态知识整合和固有的注意力机制，为时间序列分析带来了变革性的潜力。然而，从零开始开发通用的时间序列LLM仍受限于数据多样性、标注稀缺性和计算要求。本文对预训练LLM驱动的时间序列分析进行了系统回顾，重点关注使能技术、潜在应用和开放挑战。首先，它建立了AI驱动时间序列分析的演进路线图，从早期机器学习时代，通过新兴的LLM驱动范式，到原生时间基础模型的发展。其次，它从工作流角度组织和系统化了LLM驱动时间序列分析的技术图景，涵盖了LLM的输入、优化和轻量化阶段。最后，它批判性地审视了新颖的实际应用，并强调了可以指导未来研究和创新的关键开放挑战。这项工作不仅提供了对当前进展的宝贵见解，还描绘了未来发展的有前景方向。它为学术界和工业界研究人员提供了基础性参考，为开发更高效、更通用、更可解释的LLM驱动时间序列分析系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [Data Science: a Natural Ecosystem](https://arxiv.org/abs/2506.11010)
> *数据科学：一个自然生态系统*

*Emilio Porcu, Roy El Moukari, Laurent Najman, Francisco Herrera, Horst Simon* | **Main category: cs.LG**

**Keywords:** 数据科学, 自然生态系统, 5D复杂性, 计算数据科学, 基础数据科学

**Comment:** 

> **TL;DR:** 本文将数据科学视为一个自然生态系统，分析其复杂性、挑战，并提出计算数据科学与基础数据科学之间存在分歧的威胁，建议通过衡量发现的有用性来缓解。

**AI_Comments:** 本文创新性地将数据科学体系类比为“自然生态系统”，并引入了“5D复杂性”和“数据代理/数据科学家”等概念，为理解数据科学的组成和运作提供了一个新颖的框架。其提出的计算数据科学与基础数据科学之间潜在的分歧以及通过“有用性衡量”来弥合分歧的观点，对于数据科学领域的发展具有重要的警示和指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提供一个全面的（以数据为中心）视角来看待“基本数据科学”，将其定义为一个自然生态系统，并解决数据宇宙中由5D复杂性（数据结构、领域、基数、因果关系和伦理）及数据生命周期阶段带来的挑战和任务。此外，还关注计算数据科学与基础数据科学之间可能出现的分歧。

**Method:** 作者将数据科学视为一个自然生态系统，引入了“基本数据科学”、“学科诱导数据科学”和“泛数据科学”等概念。他们将基本数据科学语义上分为计算型和基础型，并提出了5D复杂性（数据结构、领域、基数、因果关系和伦理）和数据生命周期阶段。

**Result:** 提出了数据科学作为自然生态系统的概念，并区分了基本、学科诱导和泛数据科学。将基本数据科学分为计算型和基础型，并指出两者之间存在严重分歧的威胁。

**Conclusion:** 存在计算数据科学与基础数据科学之间严重分歧的威胁，建议通过严格的方法来衡量数据宇宙发现的有用性，以缓解这种分歧。

> **ai_Abstract:** 本文提出将数据科学视为一个复杂的自然生态系统，涵盖5D复杂性（数据结构、领域、基数、因果关系和伦理）和数据生命周期。文章定义了“基本数据科学”，并进一步细分为计算型和基础型，同时引入了“学科诱导数据科学”和“泛数据科学”的概念。作者强调了计算数据科学与基础数据科学之间可能出现的严重分歧，并建议通过衡量数据发现的有用性来应对这一挑战。

> **摘要翻译:** 本手稿提供了一个我们称之为基本数据科学的整体（以数据为中心）视图，将其视为一个自然生态系统，其挑战和任务源于数据宇宙，数据宇宙具有5D复杂性（数据结构、领域、基数、因果关系和伦理）与数据生命周期的多个组合。数据代理执行由特定目标驱动的任务。数据科学家是一个抽象实体，它来自于数据代理及其行动的逻辑组织。数据科学家面临的挑战是根据任务定义的。我们定义了特定的学科诱导数据科学，这反过来又允许定义泛数据科学，一个将特定学科与基本数据科学整合的自然生态系统。我们将基本数据科学语义上分为计算型和基础型。我们声称计算数据科学与基础数据科学之间存在严重分歧的威胁。特别是，如果没有采取任何方法来评估数据宇宙的发现是否有用。我们建议，衡量数据宇宙发现有用性的严格方法可能会缓解这种分歧。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [84] [Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients](https://arxiv.org/abs/2506.11024)
> *并非所有客户端都相同：异构多模态客户端上的个性化联邦学习*

*Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars* | **Main category: cs.LG**

**Keywords:** 个性化联邦学习, 异构性, 多模态, 模型聚合, 知识共享

**Comment:** 

> **TL;DR:** 本文提出了一个针对异构多模态客户端的个性化联邦学习（PFL）框架，通过任务相似性感知模型聚合和维度不变模块来解决数据和模型异构性问题，并优于现有技术。

**AI_Comments:** 该论文的创新点在于首次同时考虑了大规模数据异构性和模型异构性在个性化联邦学习中的影响，并提出了相应的解决方案，这对于推动PFL在真实世界场景中的应用具有重要意义。新引入的基准也为未来的研究提供了有价值的平台。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型虽然强大但存在隐私和传输成本问题。联邦学习（FL）解决了这些问题，而个性化联邦学习（PFL）则进一步满足了用户个性化需求。然而，大多数PFL研究局限于模拟环境，忽视了真实世界中的数据和模型异构性。

**Method:** 为解决数据异构性，提出了一种任务相似性感知模型聚合方法，为每个客户端提供定制的全局模型。为解决模型异构性，提出了一种维度不变模块，以实现在异构模型间共享知识。

**Result:** 实证验证表明，所提出的方法在个性化和泛化能力方面均优于现有最先进的技术。

**Conclusion:** 本文提出的PFL方法通过解决真实世界中的数据和模型异构性，显著提升了多模态个性化联邦学习的性能。

> **ai_Abstract:** 本文针对真实世界中个性化联邦学习（PFL）面临的数据和模型异构性挑战，提出了一种新的PFL框架。该框架引入了任务相似性感知模型聚合方法以处理数据异构性，并设计了维度不变模块以实现异构模型间的知识共享。通过在新的多模态基准上的评估，实验结果证明所提出的方法在个性化和泛化能力上均优于现有最先进的方法。

> **摘要翻译:** 基础模型在各种多模态任务中展现出卓越的能力，但其集中式训练引发了隐私担忧并导致高昂的传输成本。相比之下，联邦学习（FL）提供了一种分布式替代方案，无需共享数据。近年来，为了满足不同用户对AI模型个性化的日益增长的需求，个性化联邦学习（PFL）应运而生。PFL允许每个客户端利用其他客户端的知识，以便进一步适应个人用户偏好，同样无需共享数据。尽管PFL潜力巨大，但大多数PFL研究仍局限于模拟环境，忽视了真实世界场景中出现的数据和模型异构性。与此相反，我们首先考虑大规模数据异构性，并在一个新的多模态PFL基准上进行评估，该基准涵盖40个不同任务，具有真实的数据分布偏移。然后，我们考虑模型异构性，即我们不假设所有客户端共享相似的模型架构。为了解决数据异构性，我们提出了一种任务相似性感知模型聚合方法，为每个客户端提供定制的全局模型。对于模型异构性，我们提出了一种维度不变模块，该模块能够实现异构模型之间的知识共享。实证验证表明，所提出的方法优于现有最先进的技术，在个性化和泛化能力方面都表现出色。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [100] [An Attention-based Spatio-Temporal Neural Operator for Evolving Physics](https://arxiv.org/abs/2506.11328)
> *基于注意力的时空神经算子用于演化物理*

*Vispi Karkaria, Doksoo Lee, Yi-Ping Chen, Yue Yu, Wei Chen* | **Main category: cs.LG**

**Keywords:** 科学机器学习, 神经算子, 注意力机制, 时空预测, 物理可解释性

**Comment:** 

> **TL;DR:** 提出ASNO模型，结合时空注意力机制和神经算子，解决科学机器学习中演化物理过程的预测和泛化问题，在基准测试中表现优异。

**AI_Comments:** ASNO的创新之处在于将可分离的注意力机制与神经算子结合，并受BDF启发，使其在处理演化物理系统时能够兼顾时空交互、对未知环境的泛化能力以及物理可解释性。通过分离历史状态贡献和外部力，它为发现潜在物理定律提供了新途径，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 科学机器学习（SciML）面临的关键挑战是如何学习未知的、演化的物理过程，并在时空尺度上进行预测。传统机器学习模型在捕捉长程时空交互方面表现良好，但缺乏物理可解释性，并且难以在变化的环境条件下泛化。

**Method:** 提出了一种名为“基于注意力的时空神经算子”（ASNO）的新型架构。ASNO结合了用于空间和时间交互的可分离注意力机制，并能适应新的、未知的物理参数。该模型受后向微分公式（BDF）启发，学习一个用于时间预测和外推的Transformer，以及一个用于处理不同外部载荷的基于注意力的神经算子，通过分离历史状态贡献和外部力来增强可解释性。

**Result:** 经验结果表明，ASNO在科学机器学习基准测试中优于现有模型。

**Conclusion:** ASNO在工程应用、物理发现和可解释机器学习方面展现出潜力。

> **ai_Abstract:** 本文提出了一种名为基于注意力的时空神经算子（ASNO）的新型模型，旨在解决科学机器学习中学习演化物理过程和跨时空尺度预测的挑战。ASNO通过结合可分离的时空注意力机制和受BDF启发的神经算子（包含一个Transformer用于时间预测和一个注意力算子用于外部载荷），增强了模型对未知环境的适应性和物理可解释性。实验结果表明，ASNO在SciML基准测试中超越了现有模型，展现了其在工程、物理发现和可解释AI领域的应用前景。

> **摘要翻译:** 在科学机器学习（SciML）中，一个关键挑战是学习未知的、演化的物理过程并在时空尺度上进行预测。例如，在增材制造等现实世界制造问题中，用户会调整已知的机器设置，同时未知的环境参数也在波动。为了做出可靠的预测，模型不仅需要从数据中捕获长程时空交互，还需要适应新的未知环境；传统的机器学习模型擅长第一项任务，但往往缺乏物理可解释性，并且在不同的环境条件下难以泛化。为了应对这些挑战，我们提出了基于注意力的时空神经算子（ASNO），这是一种新颖的架构，它结合了用于空间和时间交互的可分离注意力机制，并能适应未见的物理参数。受后向微分公式（BDF）的启发，ASNO学习一个用于时间预测和外推的Transformer，以及一个用于处理不同外部载荷的基于注意力的神经算子，通过分离历史状态贡献和外部力来增强可解释性，从而实现对底层物理定律的发现以及对未见物理环境的泛化能力。SciML基准测试的经验结果表明，ASNO优于现有模型，确立了其在工程应用、物理发现和可解释机器学习方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [111] [When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces](https://arxiv.org/abs/2506.11025)
> *当算法偏爱：面部生成与感知中的外貌歧视*

*Miriam Doh, Aditya Gulati, Matei Mancas, Nuria Oliver* | **Main category: cs.LG**

**Keywords:** 算法外貌歧视, AI公平性, 性别分类, 文本到图像, 数字身份

**Comment:** Accepted as an extended abstract at the Fourth European Workshop on
  Algorithmic Fairness (EWAF) (URL: https://2025.ewaf.org/home)

> **TL;DR:** 本研究揭示了算法在生成和感知人脸时存在外貌歧视，导致文本到图像系统将吸引力与积极特质关联，以及性别分类模型对“不那么吸引人”的人脸，尤其是非裔女性，表现出更高的错误率，这引发了对数字身份系统公平性的担忧。

**AI_Comments:** 该论文揭示了人工智能中一个重要的公平性问题，即与外貌相关的算法偏见。这对于开发道德AI至关重要，尤其是在数字身份等敏感应用中。关于非裔女性面临更高错误率的发现尤其具有洞察力，指出了交叉偏见的存在。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨合成生成的人脸和基于机器学习的性别分类算法如何受到算法外貌歧视（即基于外貌的偏好对待）的影响。

**Method:** 研究通过对13,200张合成生成的人脸进行实验。

**Result:** 实验发现：1) 文本到图像（T2I）系统倾向于将面部吸引力与无关的积极特质（如智力和可信度）联系起来；2) 性别分类模型对“不那么吸引人”的人脸表现出更高的错误率，尤其是在非裔女性中。

**Conclusion:** 这些结果引发了对数字身份系统公平性的担忧。

> **ai_Abstract:** 本研究调查了算法外貌歧视如何影响合成人脸的生成和机器学习驱动的性别分类。研究发现，文本到图像系统倾向于将面部吸引力与智力、可信度等积极特质关联，且性别分类模型对“不那么吸引人”的人脸（特别是非裔女性）错误率更高。这些发现对数字身份系统的公平性提出了重要关切。

> **摘要翻译:** 本文探讨了合成生成的人脸和基于机器学习的性别分类算法如何受到算法外貌歧视（即基于外貌的偏好对待）的影响。在对13,200张合成生成的人脸进行的实验中，我们发现：1）文本到图像（T2I）系统倾向于将面部吸引力与无关的积极特质（如智力和可信度）联系起来；2）性别分类模型对“不那么吸引人”的人脸表现出更高的错误率，尤其是在非裔女性中。这些结果引发了对数字身份系统公平性的担忧。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [127] [PPDiff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design](https://arxiv.org/abs/2506.11420)
> *PPDiff：在混合序列-结构空间中扩散以用于蛋白质-蛋白质复合物设计*

*Zhenqiao Song, Tiaoxiao Li, Lei Li, Martin Renqiang Min* | **Main category: cs.LG**

**Keywords:** 蛋白质-蛋白质复合物设计, 扩散模型, 序列-结构设计, 蛋白质结合物, PPDiff, SSINC

**Comment:** 

> **TL;DR:** PPDiff是一个扩散模型，通过联合考虑序列和结构来设计蛋白质结合物，在蛋白质复合物设计任务上优于基线方法。

**AI_Comments:** PPDiff通过将扩散模型与专门的网络（SSINC）相结合，在混合空间中同时处理序列和结构信息，提出了一种创新的方法，解决了从头设计蛋白质的关键挑战。其非自回归特性和大型数据集（PPBench）的创建也是重要的贡献。它在不同任务中超越基线的能力突显了其在生物技术实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 按需为任意蛋白质靶点创建高亲和力结合物，而无需进行大量湿实验室测试，仍然是一个重大挑战。

**Method:** 引入PPDiff，一个非自回归扩散模型，用于联合设计结合物的序列和结构。PPDiff基于序列结构交错网络（SSINC），该网络结合了自注意力层（用于全局相关性）、kNN等变图层（用于局部3D相互作用）和因果注意力层（用于简化序列依赖性）。模型在PPBench（一个包含706,360个复合物的新数据集）上进行预训练，并在靶蛋白小结合物复合物设计和抗原-抗体复合物设计这两个实际应用中进行微调。

**Result:** PPDiff始终超越基线方法。在预训练任务中成功率为50.00%，在靶蛋白小结合物复合物设计中为23.16%，在抗原-抗体复合物设计中为16.89%。

**Conclusion:** PPDiff模型能够有效地设计蛋白质-蛋白质复合物，并生成具有高亲和力的结合物，性能优于现有基线方法。

> **ai_Abstract:** PPDiff是一个新颖的非自回归扩散模型，旨在为任意靶点蛋白质联合生成结合物的序列和结构。它利用序列结构交错网络（SSINC），该网络集成了自注意力、kNN图层和因果注意力来建模复杂的蛋白质相互作用。在新的PPBench数据集上进行评估，并针对迷你结合物和抗原-抗体设计等实际应用进行微调，PPDiff始终以显著的成功率优于基线方法。

> **摘要翻译:** 设计具有高亲和力的蛋白质结合蛋白在生物医学研究和生物技术中至关重要。尽管最近针对特定蛋白质取得了进展，但如何在不进行大量湿实验室测试的情况下，按需为任意蛋白质靶点创建高亲和力结合物仍然是一个重大挑战。在此，我们引入了PPDiff，一个扩散模型，以非自回归的方式联合设计任意蛋白质靶点结合物的序列和结构。PPDiff建立在我们开发的序列结构交错网络（SSINC）之上，该网络具有因果注意力层，它集成了交错的自注意力层以捕获全局氨基酸相关性，k近邻（kNN）等变图层以模拟三维（3D）空间中的局部相互作用，以及因果注意力层以简化蛋白质序列中复杂的相互依赖性。为了评估PPDiff，我们整理了PPBench，一个包含来自蛋白质数据库（PDB）的706,360个复合物的通用蛋白质-蛋白质复合物数据集。该模型在PPBench上进行预训练，并在两个实际应用中进行微调：靶蛋白小结合物复合物设计和抗原-抗体复合物设计。PPDiff始终超越基线方法，在预训练任务和两个下游应用中分别达到了50.00%、23.16%和16.89%的成功率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [138] [Evaluating Privacy-Utility Tradeoffs in Synthetic Smart Grid Data](https://arxiv.org/abs/2506.11026)
> *评估合成智能电网数据中的隐私-效用权衡*

*Andre Catarino, Rui Melo, Rui Abreu, Luis Cruz* | **Main category: cs.LG**

**Keywords:** 合成数据, 隐私, 效用, 智能电网, 生成模型

**Comment:** 9 pages, 4 figures

> **TL;DR:** 本研究评估了四种合成智能电网数据生成方法在隐私和效用方面的权衡。结果表明，扩散模型具有最高的效用，而CTGAN提供了最强的隐私保护。

**AI_Comments:** 该论文通过对不同生成模型在智能电网数据合成中的隐私-效用权衡进行深入比较，具有重要的实践意义。它不仅指出了扩散模型在高实用性方面的优势，也突出了CTGAN在隐私保护上的强大能力，为未来隐私保护型数据驱动能源系统的发展提供了有价值的指导。

<details>
  <summary>Details</summary>

**Motivation:** 动态分时电价（dToU）的广泛应用需要准确识别受益家庭，但使用真实消费数据存在严重的隐私问题，因此需要采用合成数据替代方案。

**Method:** 本研究比较评估了四种合成数据生成方法：Wasserstein-GP生成对抗网络（WGAN）、条件表格GAN（CTGAN）、扩散模型和高斯噪声增强，并在不同合成机制下进行。评估指标包括分类效用、分布保真度和隐私泄露。

**Result:** 结果显示，架构设计起着关键作用：扩散模型实现了最高的效用（宏F1最高达88.2%），而CTGAN对重构攻击提供了最强的抵抗力。

**Conclusion:** 这些发现突出了结构化生成模型在开发隐私保护、数据驱动的能源系统方面的潜力。

> **ai_Abstract:** 本研究旨在解决智能电网数据中的隐私问题，通过比较评估WGAN、CTGAN、扩散模型和高斯噪声增强四种合成数据生成方法，以在隐私和效用之间取得平衡。研究发现，扩散模型在效用方面表现最佳，而CTGAN在隐私保护方面表现出最强的抵抗力。这些结果强调了结构化生成模型在构建隐私保护型能源系统中的应用潜力。

> **摘要翻译:** 动态分时电价（dToU）的广泛应用需要准确识别受益于此类定价结构的家庭。然而，使用真实消费数据会引发严重的隐私问题，这促使人们采用合成数据替代方案。在本研究中，我们对四种合成数据生成方法——Wasserstein-GP生成对抗网络（WGAN）、条件表格GAN（CTGAN）、扩散模型和高斯噪声增强——在不同合成机制下进行了比较评估。我们评估了分类效用、分布保真度和隐私泄露。我们的结果表明，架构设计起着关键作用：扩散模型实现了最高的效用（宏F1最高达88.2%），而CTGAN对重构攻击提供了最强的抵抗力。这些发现突出了结构化生成模型在开发隐私保护、数据驱动的能源系统方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [161] [From Reasoning to Code: GRPO Optimization for Underrepresented Languages](https://arxiv.org/abs/2506.11027)
> *从推理到代码：面向欠代表语言的GRPO优化*

*Federico Pennino, Bianca Raimondi, Massimo Rondelli, Andrea Gurioli, Maurizio Gabbrielli* | **Main category: cs.LG**

**Keywords:** 代码生成, 低资源语言, GRPO, 大型语言模型, 推理

**Comment:** Preprint. Under review

> **TL;DR:** 本文提出一种结合Qwen 2.5小规模模型和GRPO的方法，通过显式推理步骤为训练数据有限的语言生成准确代码，并在Prolog上取得显著改进。

**AI_Comments:** 该研究通过结合GRPO和显式推理步骤，为LLMs在低资源语言上的代码生成提供了创新解决方案。其将推理反馈融入强化学习循环的方法，对于提高代码的逻辑一致性和语法准确性至关重要，有望极大地扩展LLMs在多样化编程语言中的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）为训练数据有限的语言（相对于Python等流行语言）生成准确可执行代码面临挑战。

**Method:** 本文提出一种通用方法，结合Qwen 2.5模型的小规模代码版本与群组相对策略优化（GRPO），通过将推理驱动反馈直接整合到强化学习循环中，实现有效的代码生成。以Prolog为例进行训练和评估。

**Result:** 在数学逻辑问题基准上的实验评估表明，推理质量、代码准确性和逻辑正确性均有显著提高，模型能够成功生成逻辑一致且语法准确的代码。

**Conclusion:** 该方法有潜力使缺乏大量训练资源的广泛编程语言受益。

> **ai_Abstract:** 本文提出一种通用方法，结合Qwen 2.5小规模模型和GRPO，通过显式推理步骤和强化学习循环中的推理驱动反馈，解决大型语言模型为训练数据有限的语言生成准确代码的挑战。以Prolog为例，实验证明该方法显著提高了推理质量、代码准确性和逻辑正确性，表明其对缺乏训练资源的编程语言具有广泛适用性。

> **摘要翻译:** 使用大型语言模型（LLMs）为公共训练数据有限的语言（与Python等流行语言相比）生成准确且可执行的代码具有挑战性。本文介绍了一种通用方法，该方法使用Qwen 2.5模型的小规模代码版本，并结合群组相对策略优化（GRPO），通过显式推理步骤实现有效的代码生成，这对于源代码数据库较小的语言尤其有益。以Prolog作为代表性用例——考虑到其有限的在线存在——初始模型在生成可执行代码方面面临挑战。经过一些训练步骤后，该模型通过将推理驱动的反馈直接整合到强化学习循环中，成功生成了逻辑一致且语法准确的代码。使用数学逻辑问题基准进行的实验评估表明，推理质量、代码准确性和逻辑正确性均有显著提高，这强调了该方法有潜力使缺乏大量训练资源的广泛编程语言受益。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Enhancing Epidemic Forecasting: Evaluating the Role of Mobility Data and Graph Convolutional Networks](https://arxiv.org/abs/2506.11028)
> *增强流行病预测：评估流动性数据和图卷积网络的作用*

*Suhan Guo, Zhenghao Xu, Furao Shen, Jian Zhao* | **Main category: cs.LG**

**Keywords:** 流行病预测, 流动性数据, 图卷积网络, 传染病, 预测建模

**Comment:** 

> **TL;DR:** 本研究评估了流动性数据和图卷积网络在流行病预测中的作用，发现它们并未显著提升预测性能，但死亡率和住院数据显著提高了模型准确性。研究还指出空间图与封锁令存在相关性。

**AI_Comments:** 本研究创新性地探讨了流动性数据和GCN在流行病预测中的作用，挑战了关于流动性数据重要性的普遍假设。其重要性在于揭示了在真实世界数据中，死亡率和住院数据可能比流动性数据对模型准确性有更显著的贡献。同时，发现GCN空间图与封锁令的相关性也提供了一个新的视角来理解和利用地理信息。局限性可能在于研究范围和特定数据集的通用性。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测传染病爆发对决策至关重要。现有机器学习算法在流行病学应用中存在差距，特别是在整合流动性信息方面，导致在真实世界数据上表现不佳。

**Method:** 采用两阶段方法：首先通过试点研究评估流动性数据的重要性；然后评估图卷积网络（GCNs）在Transformer骨干网络上的影响。

**Result:** 流动性数据和GCN模块并未显著增强预测性能；死亡率和住院数据的加入显著提高了模型准确性。GCN衍生的空间图与封锁令之间存在显著相关性，表明空间图可能是流动性的敏感指标。

**Conclusion:** 本研究为传染病预测模型中的流动性表示提供了新视角，强调了死亡率和住院数据的重要性，并指出空间图作为流动性指标的潜力，有助于决策者更好地准备未来的疫情爆发。

> **ai_Abstract:** 本研究旨在弥合机器学习算法与流行病学应用之间的鸿沟，特别关注流动性数据在预测传染病爆发中的整合难题。研究采用两阶段方法，评估了流动性数据和图卷积网络（GCNs）对预测性能的影响。结果显示，流动性数据和GCNs并未显著提升预测准确性，但死亡率和住院数据的纳入显著改善了模型表现。此外，研究发现GCN生成的空间图与封锁令之间存在相关性，提示空间图可作为流动性的敏感指标。这为传染病预测建模中的数据表示提供了新的见解。

> **摘要翻译:** 准确预测传染病爆发对于知情决策至关重要。我们的研究解决了机器学习算法及其流行病学应用之间的差距，注意到在基准数据集上表现最佳的方法在真实世界数据上往往表现不佳，原因在于难以整合流动性信息。我们采用两阶段方法：首先，通过试点研究评估流动性数据的重要性；然后，评估图卷积网络（GCNs）在Transformer骨干网络上的影响。我们的研究结果表明，虽然流动性数据和GCN模块并未显著增强预测性能，但死亡率和住院数据的加入显著提高了模型准确性。此外，GCN衍生的空间图与封锁令之间的比较分析表明存在显著相关性，突出了空间图作为流动性敏感指标的潜力。我们的研究为传染病预测建模中的流动性表示提供了新颖的视角，使决策者能够更好地为未来的疫情爆发做好准备。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [190] [An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry](https://arxiv.org/abs/2506.11100)
> *一种基于主动学习的流式管道，用于中子衍射中结构发现模型的减少数据训练*

*Tianle Wang, Jorge Ramirez, Cristina Garcia-Cardona, Thomas Proffen, Shantenu Jha, Sudip K. Seal* | **Main category: cs.LG**

**Keywords:** 主动学习, 中子衍射, 结构发现, 数据减少, 流式管道

**Comment:** 

> **TL;DR:** 本文提出了一种基于主动学习的流式训练管道，用于中子衍射中的结构发现模型，可将训练数据量减少75%并提高准确性，同时将训练时间缩短20%。

**AI_Comments:** 本文的创新之处在于将主动学习引入到中子衍射结构发现模型的训练中，有效解决了模拟数据量指数级增长带来的计算挑战。通过结合流式训练工作流程，不仅大幅减少了数据需求，还显著缩短了训练时间，同时保持或提高了模型精度，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 中子衍射中的结构确定工作计算成本高昂，且机器学习模型需要指数级增长的模拟数据，这带来了巨大的计算挑战。

**Method:** 本文提出了一种新颖的批处理模式主动学习（AL）策略，该策略使用不确定性采样来模拟从概率分布中提取的训练数据，这些数据偏好模型最不确定的标记示例。然后，设计了一个使用此AL策略的有效流式训练工作流程。

**Result:** 该方法在训练相同模型时，将训练数据量减少了约75%，同时提高了准确性。与传统训练工作流程相比，流式工作流程可将训练时间缩短约20%，且没有任何精度损失。

**Conclusion:** 所提出的基于主动学习的流式管道能够显著减少中子衍射中结构发现模型的训练数据需求和训练时间，同时保持或提高准确性，有效解决了数据量和计算成本的挑战。

> **ai_Abstract:** 本文针对中子衍射中结构发现模型训练所需的大量模拟数据和高计算成本问题，提出了一种基于主动学习（AL）的流式训练管道。该方法采用不确定性采样的主动学习策略，能够以更少的训练数据（减少约75%）实现更高的模型准确性。进一步结合高效的流式训练工作流程，该管道与传统方法相比，可在不损失准确性的前提下，将训练时间缩短约20%。这为中子衍射领域的结构确定任务提供了更高效、数据需求更低的机器学习训练方案。

> **摘要翻译:** 中子衍射中的结构确定工作计算成本高昂，通常需要数小时到数天才能从其中子衍射图谱中确定材料的结构。最近有报道称，在模拟中子散射图谱上训练的机器学习模型有潜力显著加快这些任务。然而，训练这些模型所需的模拟数据量随着要预测的结构参数数量呈指数级增长，并带来了巨大的计算挑战。为了克服这一挑战，我们引入了一种新颖的批处理模式主动学习（AL）策略，该策略使用不确定性采样来模拟从概率分布中提取的训练数据，这些数据偏好模型最不确定的标记示例。我们证实了其在减少约75%训练数据量的情况下训练相同模型并提高准确性的功效。然后，我们讨论了使用此AL策略的有效流式训练工作流程的设计，并介绍了在两个异构平台上的性能研究，以证明与传统训练工作流程相比，流式工作流程可将训练时间缩短约20%，且没有任何精度损失。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [199] [Output Scaling: YingLong-Delayed Chain of Thought in a Large Pretrained Time Series Forecasting Model](https://arxiv.org/abs/2506.11029)
> *输出扩展：大型预训练时间序列预测模型中的盈龙-延迟思维链*

*Xue Wang, Tian Zhou, Jinyang Gao, Bolin Ding, Jingren Zhou* | **Main category: cs.LG**

**Keywords:** 时间序列预测, YingLong, Transformer, 输出扩展, 思维链

**Comment:** 

> **TL;DR:** 本文提出了YingLong，一个新颖的非因果时间序列预测模型，揭示了“输出扩展”效应，即更长的输出通过延迟思维链推理显著提高模型精度，并在多个基准测试中超越现有SOTA模型。

**AI_Comments:** 本文的创新点在于将非因果、双向注意力Transformer应用于时间序列预测，并发现了独特的“输出扩展”效应，即利用延迟思维链通过更长的输出提升精度。它有效地将语言模型预训练（掩码令牌恢复）适应到时间序列领域。YingLong在多样化数据集和零样本任务中的卓越表现凸显了其作为时间序列新基础模型的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决时间序列预测的挑战，并提出一个有别于传统直接或递归方法的联合预测框架，该框架旨在实现最先进的性能并揭示一种新的缩放效应。

**Method:** 本研究提出了一个联合时间序列预测框架，并设计了名为YingLong的基础模型。YingLong是一个非因果、双向注意力、仅编码器的Transformer模型，通过掩码令牌恢复进行训练，以更好地对齐语言理解任务。该方法通过多输入集成来解决输出方差问题以提升性能。研究还发现，在非因果方法中，更长的输出因延迟思维链推理而显著提高模型精度，这是一种新颖的缩放效应。

**Result:** YingLong模型在时间序列预测中实现了最先进的性能。研究揭示了“输出扩展”效应，即更长的输出显著提高了模型精度。在ETT和Weather数据集的零样本任务中，模型表现优异，YingLong实现了超过60%的最佳性能。在包含7个领域23个时间序列数据集的GIFT-Eval基准测试中，YingLong在排名上分别比最佳时间序列基础模型和端到端训练模型高出14%和44%。研究还发布了参数从6M到300M的四种基础模型，其中300M的预训练模型已公开。

**Conclusion:** YingLong模型及其提出的联合预测框架，通过其非因果、双向注意力Transformer架构以及对“延迟思维链”的利用，为时间序列预测提供了一种高效且泛化能力强的方法。通过更长的输出显著提高精度，它在多个基准测试中持续超越了现有的最先进时间序列模型。

> **ai_Abstract:** 本文介绍了一个名为YingLong的非因果、双向注意力编码器专用Transformer，用于时间序列预测，并提出了一个实现最先进性能的联合预测框架。核心发现是“输出扩展”效应：更长的输出通过延迟思维链推理显著提高模型精度。YingLong通过掩码令牌恢复进行训练，并结合多输入集成以提升性能。在ETT、Weather和GIFT-Eval等多个数据集上的评估表明，YingLong在零样本任务中表现出色，并持续超越现有领先的时间序列基础模型和端到端训练模型，展现出强大的通用性。

> **摘要翻译:** 我们提出了一个时间序列预测的联合预测框架，与传统的直接或递归方法形成对比。该框架为我们设计的DichLong基础模型实现了最先进的性能，并揭示了一种新颖的扩展效应：由于我们非因果方法中的延迟思维链推理，更长的输出显著提高了模型精度。YingLong是一个非因果、双向注意力编码器专用Transformer，通过掩码令牌恢复进行训练，比生成任务更能有效地与语言理解任务对齐。此外，我们通过多输入集成来解决输出方差问题，从而提升了性能。我们发布了四种基础模型，参数范围从6M到300M，在ETT和Weather数据集的零样本任务中展示了卓越的结果。YingLong实现了超过60%的最佳性能。为了确保通用性，我们使用GIFT-Eval基准对模型进行了评估，该基准包含7个领域23个时间序列数据集。YingLong在排名上分别比最佳时间序列基础模型和端到端训练模型高出14%和44%。预训练的300M模型可在https://huggingface.co/qcw1314/YingLong_300m获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [217] [Forward Target Propagation: A Forward-Only Approach to Global Error Credit Assignment via Local Losses](https://arxiv.org/abs/2506.11030)
> *前向目标传播：一种通过局部损失进行全局错误归因的仅前向方法*

*Nazmus Saadat As-Saquib, A N M Nafiz Abeer, Hung-Ta Chien, Byung-Jun Yoon, Suhas Kumar, Su-in Yi* | **Main category: cs.LG**

**Keywords:** 前向目标传播, 反向传播, 神经网络, 信用分配, 生物合理性

**Comment:** 

> **TL;DR:** 提出了一种名为前向目标传播（FTP）的新型神经网络训练算法，它用第二次前向传播取代了传统的反向传播，实现了与反向传播相当的性能，并在硬件兼容性和效率方面表现更优，尤其适用于设备端学习和神经形态计算。

**AI_Comments:** 本文提出了一种新颖的神经网络训练方法FTP，其创新性在于用第二次前向传播替代了传统的反向传播，解决了BP在生物合理性和硬件实现方面的固有局限。通过仅前向计算和局部学习，FTP有望在能效和边缘计算领域发挥重要作用，为神经形态硬件的发展提供了新的思路。其在各种网络类型和数据集上与BP相媲美的性能，以及在低精度和新兴硬件上的优势，突显了其潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的反向传播（BP）算法在生物学和硬件方面存在局限性，包括需要对称权重进行反向错误传播、非局部信用分配以及反向传播期间的活动冻结。本文旨在提出一种更具生物合理性且计算效率更高的替代方案。

**Method:** 本文提出了前向目标传播（FTP）算法，它用第二次前向传播取代了反向传播，以估计逐层目标。FTP仅使用前馈计算，无需对称反馈权重或可学习的逆函数，从而实现了模块化和局部学习。

**Result:** FTP在全连接网络、CNN和RNN上进行了评估，在MNIST、CIFAR10和CIFAR100数据集上实现了与反向传播（BP）相当的准确性。它还能有效建模序列任务中的长期依赖关系。此外，FTP在量化低精度和新兴硬件限制下表现优于BP，并比其他受生物学启发的算法（如目标传播变体和仅前向学习算法）具有显著的效率提升。

**Conclusion:** 前向目标传播（FTP）以其最小的计算开销、仅前向的特性和硬件兼容性，为能源效率高的设备端学习和神经形态计算提供了一个有前景的方向。

> **ai_Abstract:** 本文提出了一种名为前向目标传播（FTP）的新型神经网络训练算法，旨在克服传统反向传播（BP）在生物学和硬件方面的局限性。FTP通过第二次前向传播而非反向传播来分配全局错误信用，仅使用前馈计算估计逐层目标，从而避免了对称权重和复杂的逆函数，实现了模块化和局部学习。实验证明，FTP在多种网络结构和数据集上取得了与BP相当的准确性，并能有效处理长期依赖。更重要的是，FTP在低精度和新兴硬件环境下表现出优于BP的性能，并显著提升了相较于其他生物启发方法的效率。鉴于其计算开销小、仅前向特性和硬件兼容性，FTP为未来能源高效的设备端学习和神经形态计算提供了重要方向。

> **摘要翻译:** 训练神经网络传统上依赖于反向传播（BP），这是一种基于梯度的算法，尽管取得了广泛成功，但在生物学和硬件方面存在关键局限性。这些局限性包括通过对称权重进行反向错误传播、非局部信用分配以及反向传播期间活动冻结。我们提出了前向目标传播（FTP），这是一种生物学上合理且计算效率高的替代方案，它用第二次前向传播取代了反向传播。FTP仅使用前馈计算来估计逐层目标，消除了对对称反馈权重或可学习逆函数的需求，从而实现了模块化和局部学习。我们在全连接网络、CNN和RNN上评估了FTP，结果表明其在MNIST、CIFAR10和CIFAR100数据集上的准确性与BP相当，并且能有效建模序列任务中的长期依赖关系。此外，FTP在量化低精度和新兴硬件约束下表现优于BP，并且比其他受生物学启发的算法（如目标传播变体和仅前向学习算法）显示出显著的效率提升。凭借其最小的计算开销、仅前向的特性和硬件兼容性，FTP为能源效率高的设备端学习和神经形态计算提供了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [231] [Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models](https://arxiv.org/abs/2506.11031)
> *任务对齐提示改进了视觉-语言模型对AI生成图像的零样本检测*

*Zoher Kachwala, Danishjeet Singh, Danielle Yang, Filippo Menczer* | **Main category: cs.LG**

**Keywords:** 零样本检测, 视觉-语言模型, 任务对齐提示, AI生成图像, 泛化能力

**Comment:** 

> **TL;DR:** 通过任务对齐提示（特别是zero-shot-s²方法），预训练视觉-语言模型（VLMs）在无需微调的情况下显著提高了对AI生成图像的零样本检测性能，并展现出强大的泛化能力和鲁棒性。

**AI_Comments:** 这项研究的创新之处在于提出了一种简单而有效的任务对齐提示方法（zero-shot-s²），在不进行微调的情况下显著提升了VLMs对AI生成图像的零样本检测能力。其重要性在于提供了一个无需大量监督数据即可泛化到新生成器的解决方案，这对于应对日益增长的AI图像滥用问题至关重要。该方法在泛化性、鲁棒性以及与自洽性的结合方面都表现出色，提供了一个有前景的替代传统监督方法的方案。

<details>
  <summary>Details</summary>

**Motivation:** 随着图像生成器产生越来越逼真的图像，人们对潜在滥用的担忧日益增加。传统的监督检测方法依赖大量数据集且难以泛化到不同生成器。

**Method:** 本研究探讨了使用预训练视觉-语言模型（VLMs）进行AI生成图像的零样本检测。通过引入任务对齐提示，特别是名为“zero-shot-s²”的方法（在模型响应前添加短语“Let's examine the style and the synthesis artifacts”），来引导模型进行更集中的推理。

**Result:** zero-shot-s²方法使两种广泛使用的开源模型的Macro F1分数提高了8%-29%，且在涵盖人脸、物体和动物的三种不同数据集（由16种不同模型生成）上表现出一致的增益和强大的泛化能力。该方法对模型规模也表现出鲁棒性。此外，自洽性（self-consistency）在该设置中也有效，并且zero-shot-s²在大多数情况下比思维链（chain-of-thought）方法更好地扩展，表明它能激发更有用的多样性。

**Conclusion:** 任务对齐提示能够激发视觉-语言模型更集中的推理，并增强其潜在能力，如AI生成图像的检测，提供了一种简单、可泛化且可解释的替代监督方法。

> **ai_Abstract:** 本研究提出了一种通过任务对齐提示来改进预训练视觉-语言模型（VLMs）进行AI生成图像零样本检测的方法。具体而言，引入了“zero-shot-s²”方法，即在模型响应前添加特定短语以引导其关注风格和合成伪影。实验结果表明，该方法在不进行微调的情况下，显著提高了Macro F1分数（8%-29%），并在多样化的数据集和多个生成模型上展现出强大的泛化能力和对模型规模的鲁棒性。研究还发现自洽性在该设置中有效，且zero-shot-s²比思维链提示表现更好。这表明任务对齐提示能有效增强VLMs的潜在能力，为AI生成图像检测提供了一种简单、通用且可解释的解决方案。

> **摘要翻译:** 随着图像生成器产生越来越逼真的图像，人们对潜在滥用的担忧持续增长。监督检测依赖于大型、精心策划的数据集，并且难以在不同生成器之间进行泛化。在这项工作中，我们研究了使用预训练视觉-语言模型（VLMs）进行AI生成图像的零样本检测。尽管现成的VLMs表现出一些任务特定推理能力，并且思维链提示（chain-of-thought prompting）能带来一些增益，但我们发现任务对齐提示能引发更集中的推理，并在不进行微调的情况下显著提高性能。具体来说，在模型响应前加上“Let's examine the style and the synthesis artifacts”这句话——我们称之为零样本-s²方法（zero-shot-s²）——使两种广泛使用的开源模型的Macro F1分数提高了8%-29%。这些增益在涵盖人脸、物体和动物的三种近期、多样化数据集上保持一致，这些图像由16种不同的模型生成——这表明了强大的泛化能力。我们进一步评估了该方法在另外三种模型规模下的表现，并观察到在大多数数据集-模型组合中都有所改进——这表明对模型规模具有鲁棒性。令人惊讶的是，自洽性（self-consistency），一种先前在语言推理中观察到的行为（即聚合来自不同推理路径的答案可以提高性能），也适用于这种设置。即使在这种情况下，零样本-s²在大多数情况下也比思维链方法更好地扩展——这表明它能激发更有用的多样性。我们的研究结果表明，任务对齐提示能够引发更集中的推理，并增强VLMs的潜在能力，例如检测AI生成图像——提供了一种简单、可泛化且可解释的替代监督方法。我们的代码已在GitHub上公开：https://github.com/osome-iu/Zero-shot-s2.git。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [Deep Learning Approach to Bearing and Induction Motor Fault Diagnosis via Data Fusion](https://arxiv.org/abs/2506.11032)
> *基于深度学习和数据融合的轴承与感应电机故障诊断方法*

*Mert Sehri, Merve Ertagrin, Ozal Yildirim, Ahmet Orhan, Patrick Dumond* | **Main category: cs.LG**

**Keywords:** 深度学习, 故障诊断, 数据融合, 卷积神经网络, 长短期记忆网络

**Comment:** 

> **TL;DR:** 该研究提出了一种结合卷积神经网络（CNNs）和长短期记忆（LSTM）循环神经网络的深度学习方法，通过融合加速度计和麦克风数据，实现轴承和感应电机的故障诊断，并强调了数据融合的优势。

**AI_Comments:** 该论文的创新点在于将CNN和LSTM结合起来处理多模态传感器数据（加速度计和麦克风），实现了有效的故障诊断。其重要性在于突出了数据融合在提高诊断准确性方面的潜力，并为工业设备故障诊断提供了一个实用的深度学习框架。该方法鼓励了在恒速数据采集条件下，对多传感器数据进行多模型诊断的研究。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过提出一种结合深度学习和传感器融合的综合方法，鼓励研究人员关注恒速数据采集下的多模型诊断，并鼓励数据科学家收集更多的多传感器数据，包括声学和加速度计数据集。

**Method:** 该方法使用卷积神经网络（CNNs）评估加速度计和麦克风数据，并利用长短期记忆（LSTM）循环神经网络有效结合传感器信息，实现数据融合。

**Result:** 结果表明数据融合在轴承和感应电机诊断中具有显著优势，并为恒速数据采集下的多模型诊断提供了一种全面的深度学习和传感器融合方法。

**Conclusion:** 该研究鼓励研究人员和数据科学家收集更多包括声学和加速度计在内的多传感器数据，以促进多模型诊断。

> **ai_Abstract:** 本研究提出了一种利用深度学习进行轴承和感应电机故障诊断的新方法。它结合了卷积神经网络（CNNs）来处理加速度计和麦克风数据，并使用长短期记忆（LSTM）网络进行有效的数据融合，从而提升了诊断性能。该方法强调了多传感器数据融合在故障诊断中的潜力，并鼓励未来在多模型诊断和多传感器数据采集方面的研究。

> **摘要翻译:** 卷积神经网络（CNNs）用于评估加速度计和麦克风数据，以进行轴承和感应电机诊断。长短期记忆（LSTM）循环神经网络用于有效结合传感器信息，突出了数据融合的优势。这种方法通过提出一种使用深度学习和传感器融合的综合方式，鼓励研究人员关注恒速数据采集下的多模型诊断，并鼓励数据科学家收集更多多传感器数据，包括声学和加速度计数据集。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees](https://arxiv.org/abs/2506.11033)
> *运行时安全通过自适应防护：从隐藏参数推断到可证明的保证*

*Minjae Kwon, Tyler Ingebrand, Ufuk Topcu, Lu Feng* | **Main category: cs.LG**

**Keywords:** 运行时安全, 自适应防护, 隐藏参数推断, 强化学习, 概率安全保证

**Comment:** Submitted

> **TL;DR:** 一种针对强化学习的运行时自适应防护机制，通过隐藏参数推断提供可证明的概率安全保证，以解决执行中的安全风险。

**AI_Comments:** 这篇论文的创新点在于将隐藏参数推断与运行时防护机制结合，并提供了可证明的概率安全保证和最优性。它通过在线适应和不确定性量化（保形预测）增强了强化学习在现实世界应用中的安全性，特别是在机器人等对安全要求高的领域具有重要意义。其在保持低运行时开销的同时实现强大的泛化能力也是一个显著优点。

<details>
  <summary>Details</summary>

**Motivation:** 隐藏参数（如机器人质量分布或摩擦）的变化在执行过程中会带来安全风险，需要一种机制来保证运行时安全。

**Method:** 开发了一种运行时防护机制，基于约束隐藏参数马尔可夫决策过程。利用函数编码器从观测中实时推断隐藏参数，使防护机制和底层策略能够在线适应。防护机制通过预测未来安全风险（如障碍物接近）来约束动作空间，并通过保形预测来考虑不确定性。

**Result:** 实验表明，该方法显著减少了安全违规，实现了强大的分布外泛化能力，同时运行时开销最小。

**Conclusion:** 所提出的机制满足概率安全保证，并在安全兼容策略集中产生最优策略。

> **ai_Abstract:** 这篇论文提出了一种针对强化学习的运行时自适应防护机制，旨在解决隐藏参数变化带来的安全风险。该机制利用函数编码器实时推断隐藏参数，并基于约束隐藏参数马尔可夫决策过程构建，通过预测未来风险和保形预测来约束动作空间。研究证明，该方法能提供概率安全保证并产生最优的安全兼容策略。实验结果显示，该方法在减少安全违规、实现强大分布外泛化能力方面表现出色，且运行时开销极低。

> **摘要翻译:** 隐藏参数（例如机器人的质量分布或摩擦）的变化在执行过程中会带来安全风险。我们基于约束隐藏参数马尔可夫决策过程的形式化，为强化学习开发了一种运行时防护机制。函数编码器能够从观测中实时推断隐藏参数，从而使防护机制和底层策略能够在线适应。该防护机制通过预测未来的安全风险（例如障碍物接近）来约束动作空间，并通过保形预测来考虑不确定性。我们证明了所提出的机制满足概率安全保证，并在安全兼容策略集中产生了最优策略。在具有不同隐藏参数的各种环境中的实验表明，我们的方法显著减少了安全违规，并实现了强大的分布外泛化能力，同时运行时开销最小。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [277] [CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.11034)
> *CausalVLBench：基准测试大型视觉-语言模型中的视觉因果推理*

*Aneesh Komanduri, Karuna Bhaila, Xintao Wu* | **Main category: cs.LG**

**Keywords:** 大型视觉-语言模型, 视觉因果推理, 基准测试, CausalVLBench, 上下文学习

**Comment:** 

> **TL;DR:** CausalVLBench是一个新的基准，用于评估大型视觉-语言模型在视觉因果推理任务上的能力，揭示了它们的优缺点。

**AI_Comments:** CausalVLBench的创新之处在于其首次为大型视觉-语言模型在视觉因果推理领域提供了一个全面的基准测试平台。这对于填补当前研究空白、系统性评估模型能力具有重要意义。该基准的设立有望推动该领域的研究进展，帮助识别现有模型的局限性，并引导未来模型设计和改进的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在因果推理任务中表现出越来越大的效用，但在视觉因果推理任务中展示大型视觉-语言模型能力的工作相对较少。

**Method:** 引入了一个名为CausalVLBench的综合性多模态上下文学习因果推理基准。该基准包含三个代表性任务：因果结构推断、干预目标预测和反事实预测。研究人员在三个因果表示学习数据集上评估了最先进的开源大型视觉-语言模型的能力。

**Result:** 评估结果揭示了现有大型视觉-语言模型在视觉因果推理方面的基本优势和劣势。

**Conclusion:** 该基准有望阐明现有视觉-语言模型的缺点，并激励改进大型视觉-语言模型视觉因果推理能力的新方向和范式。

> **ai_Abstract:** 本文提出了CausalVLBench，一个针对大型视觉-语言模型（LVLM）的综合性视觉因果推理基准。鉴于现有研究较少关注LVLM在视觉因果推理方面的能力，CausalVLBench旨在通过因果结构推断、干预目标预测和反事实预测这三个任务，评估LVLM在多模态上下文学习中的表现。研究人员利用该基准评估了最先进的开源LVLM，并揭示了它们在视觉因果推理任务中的优势与不足，旨在推动未来研究改进LVLM的因果推理能力。

> **摘要翻译:** 大型语言模型（LLM）在各种语言任务中表现出卓越的能力，尤其是在其涌现的上下文学习能力方面。将LLM扩展以整合视觉输入后，大型视觉-语言模型（LVLM）在识别和视觉问答（VQA）等任务中表现出令人印象深刻的性能。尽管人们对LLM在因果发现和反事实推理等因果推理任务中的效用越来越感兴趣，但展示LVLM在视觉因果推理任务中能力的工作相对较少。我们借此机会正式引入一个针对LVLM多模态上下文学习的综合因果推理基准。我们的CausalVLBench包含三个代表性任务：因果结构推断、干预目标预测和反事实预测。我们在三个因果表示学习数据集上评估了最先进的开源LVLM在我们的因果推理任务上的能力，并展示了它们的基本优势和劣势。我们希望我们的基准能阐明现有视觉-语言模型的缺点，并激励改进LVLM视觉因果推理能力的新方向和范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [289] [Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity](https://arxiv.org/abs/2506.11035)
> *Tversky 神经网络：基于可微分Tversky相似性的心理学合理深度学习*

*Moussa Koulako Bala Doumbouya, Dan Jurafsky, Christopher D. Manning* | **Main category: cs.LG**

**Keywords:** Tversky相似性, 深度学习, 心理学合理性, 神经网络, 可解释性

**Comment:** 

> **TL;DR:** 本文提出了Tversky神经网络，通过可微分的Tversky相似性替代深度学习中不符合心理学认知的几何相似性，并在图像识别和语言模型任务中取得了显著性能提升和更好的可解释性。

**AI_Comments:** 本文的创新之处在于成功地将心理学领域的Tversky相似性理论引入深度学习，解决了现有深度学习模型在相似性建模方面与人类感知不符的问题。通过开发可微分的Tversky相似性参数化和Tversky投影层，作者不仅理论上提出了更合理的模型，而且在实际应用中（图像识别和语言建模）展示了显著的性能提升和模型参数的有效减少。此外，提出的统一解释和可视化技术增强了模型的可解释性，为设计更符合人类认知且可理解的AI系统开辟了新路径，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习中标准的几何相似性模型在心理学上不合理，其度量属性（如对称性）与人类感知不符。Tversky的相似性模型虽然更符合心理学原理，但因难以整合离散集合操作而未被用于深度学习。本研究旨在解决这一问题，将心理学上更合理的Tversky相似性引入深度学习。

**Method:** 开发了一种可微分的Tversky相似性参数化，可通过梯度下降进行学习。基于此，推导了Tversky投影层等神经网络构建块。通过图像识别（NABirds数据集上的ResNet-50）和语言建模（PTB数据集上的GPT-2）实验验证其有效性。提出了将投影层解释为计算输入刺激与学习原型相似性的统一方法，并引入了一种新的可视化技术。

**Result:** Tversky投影层能够建模非线性函数（如XOR）。在NABirds图像分类任务中，带有Tversky投影层的冻结ResNet-50比基线线性层适配器实现了24.7%的相对准确性提升。在语言建模任务中，使用Tversky投影层使GPT-2在PTB上的困惑度降低了7.5%，参数数量减少了34.8%。该方法还提供了更好的可解释性。

**Conclusion:** 本研究为思考深度学习中隐含的相似性模型以及设计在已建立的心理学相似性理论下可解释的网络提供了一个新范式。

> **ai_Abstract:** 本论文引入了Tversky神经网络，将Tversky的心理学合理相似性模型的可微分版本融入深度学习。与标准几何相似性不同，基于共同和独特特征的Tversky相似性解决了当前深度学习模型的局限性。作者开发了Tversky投影层，展示了其建模非线性函数（如XOR）的能力。实验结果显示显著的性能提升：在NABirds图像分类任务中相对准确性提高了24.7%，在PTB数据集上，GPT-2的困惑度降低了7.5%，同时参数数量减少了34.8%。该工作还提供了投影层的统一解释和新颖的可视化技术，增强了深度学习模型在心理学相似性框架下的可解释性。

> **摘要翻译:** 心理学研究强调，深度学习中标准的几何相似性模型在心理学上不合理，因为其度量属性（如对称性）与人类感知不符。相比之下，Tversky (1977) 提出了一种基于将对象表示为特征集合，以及其相似性作为共同特征和独特特征的函数的公理化相似性理论。然而，由于整合离散集合操作的挑战，该模型以前从未在深度学习中使用。我们开发了一种可微分的Tversky相似性参数化，可以通过梯度下降学习，并推导出神经网络构建块，例如Tversky投影层，它与线性投影层不同，可以建模非线性函数（如XOR）。通过图像识别和语言建模的实验，我们表明Tversky投影层是线性投影层（采用几何相似性）的有益替代。在NABirds图像分类任务中，一个带有Tversky投影层的冻结ResNet-50比线性层适配器基线实现了24.7%的相对准确性提升。使用Tversky投影层，GPT-2在PTB上的困惑度降低了7.5%，其参数数量减少了34.8%。最后，我们提出了一种统一的解释，将两种投影层都视为计算输入刺激与学习原型之间的相似性，为此我们还提出了一种新颖的可视化技术，突出了Tversky投影层的可解释性。我们的工作为思考深度学习中隐含的相似性模型以及设计在已建立的心理学相似性理论下可解释的网络提供了一个新范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [292] [Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates](https://arxiv.org/abs/2506.11413)
> *外部拜占庭，内部好奇：通过恶意更新重建数据*

*Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai* | **Main category: cs.LG**

**Keywords:** 联邦学习, 隐私泄露, 数据重建, 恶意好奇客户端, 梯度反演

**Comment:** 

> **TL;DR:** 本文引入了一种联邦学习中“恶意好奇客户端”的新威胁模型，该模型利用拜占庭攻击者的能力，通过操纵自身梯度来推断其他客户端的私有数据，并发现现有防御措施可能无效甚至适得其反。

**AI_Comments:** 本文创新性地提出了联邦学习中客户端层面的数据重建攻击，将传统的拜占庭攻击重新利用于隐私泄露，而非模型鲁棒性破坏。这一发现揭示了FL隐私保护的一个关键盲点，特别是现有防御措施可能适得其反，对FL的安全性和隐私设计具有重要意义。研究方法严谨，结合了理论分析和实际算法验证，对未来FL防御策略的研发具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）虽然旨在保护隐私，但现有研究表明其在常用协议下可能存在隐私泄露，特别是服务器能够通过客户端梯度合成训练数据。本文旨在揭示并解决客户端层面的数据重建攻击风险，即恶意客户端利用自身梯度推断其他客户端的私有数据。

**Method:** 本文首先正式定义了一种名为“恶意好奇客户端”的FL新型威胁模型。接着，提供了理论分析来证明该模型在FL训练期间实现显著数据重建成功的可能性。为了展示其实际影响，进一步开发了一种结合梯度反演和恶意更新策略的重建算法。

**Result:** 分析和实验结果揭示了FL防御的一个关键盲点：服务器端鲁棒聚合和客户端隐私机制可能无法抵御本文提出的攻击。令人惊讶的是，旨在增强鲁棒性或隐私的标准服务器端和客户端防御措施可能会无意中放大数据泄露，导致重建图像质量比基线方法提高10-15%。

**Conclusion:** 本文证明了“恶意好奇客户端”威胁模型在联邦学习中构成严重的数据隐私风险，现有鲁棒性或隐私防御措施可能无法抵御此类攻击，甚至可能适得其反，反而加剧数据泄露。这强调了需要重新思考和开发更全面的FL隐私保护策略。

> **ai_Abstract:** 本文提出了一种联邦学习中的新型威胁模型——“恶意好奇客户端”，该客户端利用拜占庭攻击者的能力，通过操纵自身梯度来推断其他客户端的私有数据。研究通过理论分析和实验验证，开发了一种结合梯度反演和恶意更新的重建算法，揭示了现有联邦学习防御机制（包括服务器端聚合和客户端隐私机制）对此类攻击的脆弱性。令人担忧的是，某些标准防御措施甚至可能无意中加剧数据泄露，提高了重建数据的质量。

> **摘要翻译:** 联邦学习（FL）实现了去中心化的机器学习，无需共享原始数据，允许多个客户端协同学习一个全局模型。然而，研究表明在常用FL协议下可能发生隐私泄露。特别是，拥有客户端梯度的服务器可以合成类似于客户端训练数据的数据。在本文中，我们引入了FL中一种新颖的威胁模型，名为“恶意好奇客户端”，其中客户端操纵其自身的梯度，目标是从同行那里推断出私有数据。这种攻击者独特地利用了拜占庭对手的优势，传统上拜占庭对手旨在破坏模型鲁棒性，而此处被重新利用以促进数据重建攻击。我们首先正式定义了这种新颖的客户端威胁模型，并提供了理论分析，证明其在FL训练期间能够实现显著的重建成功。为了证明其实际影响，我们进一步开发了一种结合梯度反演和恶意更新策略的重建算法。我们的分析和实验结果揭示了FL防御中的一个关键盲点：服务器端鲁棒聚合和客户端隐私机制都可能无法抵御我们提出的攻击。令人惊讶的是，旨在增强鲁棒性或隐私的标准服务器端和客户端防御措施可能会无意中放大数据泄露。与基线方法相比，错误使用的防御措施反而可能将重建图像质量提高10-15%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [295] [Perception-Driven Bias Detection in Machine Learning via Crowdsourced Visual Judgment](https://arxiv.org/abs/2506.11047)
> *基于感知驱动的机器学习偏见检测：通过众包视觉判断*

*Chirudeep Tupakula, Rittika Shamsuddin* | **Main category: cs.LG**

**Keywords:** 机器学习偏见检测, 众包, 视觉判断, 公平性审计, 感知驱动

**Comment:** Pilot Study. 12 pages. 4 Figures

> **TL;DR:** 本文提出了一种新颖的、基于感知的众包视觉判断框架，用于机器学习中的偏见检测，通过非专家用户的视觉直觉可靠地识别偏见，提供了一种可扩展且易于解释的替代方案。

**AI_Comments:** 这篇论文的创新点在于将众包和人类视觉感知引入机器学习偏见检测，解决了传统方法对敏感标签和僵化指标的依赖问题。其重要性在于提供了一种可扩展、易于理解且标签高效的偏见审计新途径，使非专家也能参与到公平性评估中，这对于推动机器学习的伦理发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习系统在关键领域部署，但易受偏见影响。传统偏见检测方法依赖敏感标签或僵化公平性指标，限制了其在实际应用中的可行性。

**Method:** 本文提出了一种新颖的、感知驱动的偏见检测框架，利用众包人工判断。开发了一个轻量级网络平台，展示数字数据的简化可视化（如不同人口群体的薪资分布），并收集关于群体相似性的二元判断。用户反馈被聚合以标记有偏见的数据段，然后通过统计测试和机器学习交叉评估进行验证。

**Result:** 研究结果表明，非专家用户的感知信号与已知偏见案例可靠相关。

**Conclusion:** 视觉直觉可以作为公平性审计的强大、可扩展的代理。这种方法提供了一种标签高效、可解释的传统公平性诊断替代方案，为人类对齐的众包偏见检测管道铺平了道路。

> **ai_Abstract:** 本文提出了一种新颖的、基于感知的机器学习偏见检测框架，该框架利用众包视觉判断。通过一个轻量级网络平台展示简化数据可视化并收集非专家用户的二元判断，研究发现用户的视觉直觉能够可靠地识别已知偏见。这种方法提供了一种标签高效且可解释的替代方案，有望实现人类对齐的众包偏见检测。

> **摘要翻译:** 机器学习系统越来越多地部署在关键领域，但它们仍然容易受到偏见的影响——即不成比例地影响特定人口群体的系统性差异。传统的偏见检测方法通常依赖于敏感标签的获取或僵化的公平性指标，这限制了它们在实际环境中的适用性。本文提出了一种新颖的、感知驱动的偏见检测框架，该框架利用众包人类判断。受reCAPTCHA和其他众包系统的启发，我们提出了一个轻量级网络平台，该平台显示数字数据（例如不同人口群体的薪资分布）的简化可视化，并收集关于群体相似性的二元判断。我们探讨了用户的视觉感知——受布局、间距和问题措辞的影响——如何预示潜在的差异。用户反馈被聚合以将数据段标记为有偏见，然后通过统计测试和机器学习交叉评估进行验证。我们的研究结果表明，来自非专家用户的感知信号与已知的偏见案例可靠相关，这表明视觉直觉可以作为公平性审计的强大、可扩展的代理。这种方法提供了一种标签高效、可解释的传统公平性诊断替代方案，为人类对齐的众包偏见检测管道铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [298] [Can Time-Series Foundation Models Perform Building Energy Management Tasks?](https://arxiv.org/abs/2506.11250)
> *时间序列基础模型能否执行建筑能源管理任务？*

*Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava* | **Main category: cs.LG**

**Keywords:** 时间序列基础模型, 建筑能源管理, 泛化能力, 预测, 协变量

**Comment:** 30 pages, 5 tables, 8 figures. Under review for Data-Centric
  Engineering journal

> **TL;DR:** 时间序列基础模型（TSFMs）在建筑能源管理（BEM）任务中的泛化能力有限，在预测方面通常不如传统统计模型，尤其是在处理协变量和复杂环境时。它们在零样本表示学习方面表现良好，但需要针对性改进以提高适应性和可扩展性。

**AI_Comments:** 这篇论文对时间序列基础模型（TSFMs）在建筑能源管理（BEM）领域的应用潜力进行了及时的评估。其创新之处在于系统性地考察了TSFMs在多个关键维度上的表现，包括泛化能力、协变量处理、表示学习和鲁棒性。研究结果清晰地指出了当前TSFMs的局限性，即在许多BEM任务中仍未超越传统统计模型，尤其是在处理复杂上下文信息和泛化到新数据方面。这对于未来的TSFM研究具有重要指导意义，强调了在模型设计中需要更深入地考虑时间动态和外部协变量的整合，以实现真正的通用性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的建筑能源管理（BEM）解决方案依赖于定制化的模型，这限制了它们的广泛适用性。受大型语言模型（LLMs）成功的启发，研究者们探讨了时间序列基础模型（TSFMs）是否能像LLMs一样，通过在多样化数据集上的训练，实现跨任务和跨上下文的泛化能力，从而解决BEM中普遍存在的扩展性挑战。

**Method:** 本研究评估了时间序列基础模型（TSFMs）在建筑能源管理（BEM）任务中的表现，具体从四个维度进行：1）零样本单变量预测的泛化能力；2）包含协变量进行热行为建模的预测能力；3）用于分类任务的零样本表示学习能力；4）对性能指标和不同操作条件的鲁棒性。

**Result:** 研究结果表明，时间序列基础模型（TSFMs）的泛化能力有限，在未见数据集和模态上的单变量预测表现仅略优于统计模型。在TSFMs中加入协变量并未带来性能提升，并且其表现仍逊于利用协变量的传统模型。虽然TSFMs能为下游分类任务生成有效的零样本表示，但在预测方面，当统计模型进行测试时拟合时，TSFMs可能仍不如统计模型。此外，TSFMs的预测性能对评估指标敏感，并且在更复杂的建筑环境中，其表现不如统计模型。

**Conclusion:** 研究发现时间序列基础模型（TSFMs）在建筑能源管理任务中的泛化能力和鲁棒性有限，尤其是在处理协变量和复杂环境时表现不足。这些发现强调了需要针对性地改进TSFM设计，特别是它们对协变量的处理以及将上下文和时间动态整合到预测机制中，以开发更具适应性和可扩展性的BEM解决方案。

> **ai_Abstract:** 本研究评估了时间序列基础模型（TSFMs）在建筑能源管理（BEM）任务中的潜力。尽管TSFMs在零样本表示学习方面表现出一定效果，但在泛化能力、协变量处理以及在复杂环境中的预测性能方面，它们仍显示出局限性，并且往往不如传统统计模型。研究强调需要进一步改进TSFM的设计，以提高其在BEM领域的适应性和可扩展性。

> **摘要翻译:** 建筑能源管理（BEM）任务需要处理和学习各种时间序列数据。现有解决方案依赖于定制化的任务和数据特定模型来执行这些任务，这限制了它们的广泛适用性。受大型语言模型（LLMs）变革性成功的启发，在多样化数据集上训练的时间序列基础模型（TSFMs）有潜力改变这一现状。如果TSFMs能够达到与LLMs类似的跨任务和跨上下文的泛化水平，它们就可以从根本上解决BEM中普遍存在的扩展性挑战。为了了解它们目前的状况，我们从四个维度评估了TSFMs：(1) 零样本单变量预测的泛化能力，(2) 包含协变量进行热行为建模的预测能力，(3) 用于分类任务的零样本表示学习能力，以及 (4) 对性能指标和不同操作条件的鲁棒性。我们的结果显示，TSFMs表现出有限的泛化能力，在未见数据集和模态上的单变量预测表现仅略优于统计模型。同样，在TSFMs中加入协变量并未带来性能提升，并且其表现仍逊于利用协变量的传统模型。虽然TSFMs为下游分类任务生成了有效的零样本表示，但当统计模型进行测试时拟合时，它们在预测方面可能仍不如统计模型。此外，TSFMs的预测性能对评估指标敏感，并且在更复杂的建筑环境中，它们与统计模型相比表现不佳。这些发现强调了需要针对性地改进TSFM设计，特别是它们对协变量的处理以及将上下文和时间动态整合到预测机制中，以开发更具适应性和可扩展性的BEM解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [302] [Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification](https://arxiv.org/abs/2506.11036)
> *基于多模态大语言模型的人机交互学习用于文本到图像行人重识别*

*Yang Qin, Chao Chen, Zhihang Fu, Dezhong Peng, Xi Peng, Peng Hu* | **Main category: cs.LG**

**Keywords:** 文本到图像行人重识别, 人机交互学习, 多模态大语言模型, 数据增强, 跨模态检索

**Comment:** 

> **TL;DR:** 提出一种人机交互学习框架ICL，通过MLLM增强文本查询，并用数据增强RDA提升文本质量，显著提高了文本到图像行人重识别的性能。

**AI_Comments:** 这篇论文的创新点在于将人机交互和多模态大语言模型引入到文本到图像行人重识别任务中，通过用户反馈和MLLM的知识来动态优化查询，这是一种新颖且直观的解决查询歧义的方法。同时，提出的数据增强策略也有效解决了训练数据质量问题，提高了模型的鲁棒性。这种以人为中心的设计理念为未来的跨模态检索研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像行人重识别 (TIReID) 方法在区分挑战性候选图像时存在困难，原因包括网络架构和数据质量的内在限制。特别是，低质量的训练文本是另一个限制。

**Method:** 本文提出交互式跨模态学习框架 (ICL)，利用以人为中心的交互，通过外部多模态知识增强文本查询的可区分性。为此，引入即插即用的测试时人机交互 (THI) 模块，该模块通过以人类特征为中心的视觉问答，促进与多模态大语言模型 (MLLM) 的多轮交互，以细化用户查询并对齐查询意图与潜在目标图像，从而提高排名准确性。此外，为解决低质量训练文本的限制，引入了新颖的重组数据增强 (RDA) 策略，通过丰富、分解和重组行人描述来增强查询的可区分性。

**Result:** 在CUHK-PEDES、ICFG-PEDES、RSTPReid和UFine6926四个TIReID基准测试上，该方法取得了显著的性能和实质性改进。

**Conclusion:** 提出的ICL框架及其THI模块和RDA策略有效解决了文本到图像行人重识别中的挑战，显著提高了性能。

> **ai_Abstract:** 本文提出了一种名为交互式跨模态学习 (ICL) 的框架，旨在解决文本到图像行人重识别 (TIReID) 中由于网络限制和数据质量问题导致的区分挑战性图像的困难。ICL通过引入测试时人机交互 (THI) 模块，利用多模态大语言模型 (MLLM) 进行多轮问答，以细化文本查询并增强其区分度。同时，为应对低质量训练文本的问题，论文还提出了一种重组数据增强 (RDA) 策略，通过丰富和重组行人描述来提升查询质量。实验结果表明，该方法在多个TIReID基准测试上取得了显著的性能提升。

> **摘要翻译:** 尽管跨模态嵌入模型的突破促进了文本到图像行人重识别 (TIReID) 的显著进步，但现有方法由于网络架构和数据质量等内在限制，在区分具有挑战性的候选图像时常常遇到困难。为了解决这些问题，我们提出了一种交互式跨模态学习框架 (ICL)，该框架利用以人为中心的交互，通过外部多模态知识增强文本查询的可区分性。为此，我们提出了一种即插即用的测试时人机交互 (THI) 模块，该模块执行以人类特征为中心的视觉问答，促进与多模态大语言模型 (MLLM) 的多轮交互，以对齐查询意图与潜在目标图像。具体而言，THI根据MLLM的响应细化用户查询，以缩小与最佳匹配图像的差距，从而提高排名准确性。此外，为了解决低质量训练文本的限制，我们引入了一种新颖的重组数据增强 (RDA) 策略，该策略基于信息丰富和多样性增强，通过丰富、分解和重组行人描述来增强查询的可区分性。在四个TIReID基准测试，即CUHK-PEDES、ICFG-PEDES、RSTPReid和UFine6926上进行的广泛实验表明，我们的方法取得了显著的性能和实质性改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [305] [Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs](https://arxiv.org/abs/2506.11415)
> *RAG中的偏见放大：毒化知识检索以引导大型语言模型*

*Linlin Wang, Tianqing Zhu, Laiqiao Qin, Longxiang Gao, Wanlei Zhou* | **Main category: cs.LG**

**Keywords:** RAG, 偏见放大, 中毒攻击, 大型语言模型, 公平性

**Comment:** 

> **TL;DR:** 本文提出了一种名为BRRA的攻击框架，通过操纵RAG系统来放大大型语言模型的偏见，并探讨了防御机制。

**AI_Comments:** 本文创新性地提出了RAG系统中偏见放大的攻击向量，填补了现有研究主要关注输出质量而非偏见放大的空白。其提出的BRRA框架和实验验证了这种攻击的有效性，并提出了初步的防御机制，对于提升RAG系统的鲁棒性和公平性具有重要意义。揭示了RAG系统在引入外部知识的同时可能带来的深层安全和伦理风险。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注RAG中毒攻击对模型输出质量的影响，但忽视了其放大模型偏见的潜力。例如，当查询家庭暴力受害者时，受损的RAG系统可能会优先检索将女性描绘成受害者的文档，导致模型生成延续性别刻板印象的输出，即使原始查询是性别中立的。

**Method:** 本文提出了偏见检索和奖励攻击（BRRA）框架，系统地研究了通过RAG系统操纵来放大语言模型偏见的攻击路径。设计了一种基于多目标奖励函数的对抗性文档生成方法，采用子空间投影技术来操纵检索结果，并构建了一个循环反馈机制以持续放大偏见。此外，还探索了一种双阶段防御机制。

**Result:** 实验表明，BRRA攻击可以显著增强多个主流大型语言模型在不同维度上的模型偏见。双阶段防御机制能有效缓解攻击影响。

**Conclusion:** RAG系统中的中毒攻击会直接放大模型输出偏见，并揭示了RAG系统安全与模型公平性之间的关系。这种新型潜在攻击表明需要关注RAG系统的公平性问题。

> **ai_Abstract:** 本文提出了一个名为偏见检索和奖励攻击（BRRA）的框架，旨在研究RAG系统中毒攻击如何放大大型语言模型的偏见。研究发现，通过对抗性文档生成、子空间投影和循环反馈机制，BRRA能够显著增强模型的偏见。文章还提出了一种双阶段防御机制来缓解此类攻击。这项工作强调了RAG系统安全与模型公平性之间的重要关联，并呼吁关注RAG系统的公平性问题。

> **摘要翻译:** 在大型语言模型中，检索增强生成（RAG）系统通过整合外部知识可以显著增强大型语言模型的性能。然而，RAG也引入了新的安全风险。现有研究主要关注RAG系统中的中毒攻击如何影响模型输出质量，而忽视了它们放大模型偏见的潜力。例如，当查询家庭暴力受害者时，受损的RAG系统可能会优先检索将女性描绘成受害者的文档，导致模型生成延续性别刻板印象的输出，即使原始查询是性别中立的。为了展示偏见的影响，本文提出了一种偏见检索和奖励攻击（BRRA）框架，该框架系统地研究了通过操纵RAG系统来放大语言模型偏见的攻击路径。我们设计了一种基于多目标奖励函数的对抗性文档生成方法，采用子空间投影技术来操纵检索结果，并构建了一个循环反馈机制以实现持续的偏见放大。在多个主流大型语言模型上的实验表明，BRRA攻击可以显著增强模型在各个维度上的偏见。此外，我们探索了一种双阶段防御机制，以有效缓解攻击的影响。这项研究揭示了RAG系统中的中毒攻击直接放大了模型输出偏见，并阐明了RAG系统安全与模型公平性之间的关系。这种新颖的潜在攻击表明我们需要持续关注RAG系统的公平性问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [Mini-Game Lifetime Value Prediction in WeChat](https://arxiv.org/abs/2506.11037)
> *微信小游戏生命周期价值预测*

*Aochuan Chen, Yifan Niu, Ziqi Gao, Yujie Sun, Shoujun Liu, Gong Chen, Yang Liu, Jia Li* | **Main category: cs.LG**

**Keywords:** 生命周期价值（LTV）, 微信小游戏, 图表示学习, 帕累托优化, 预测

**Comment:** KDD ADS Track 2025

> **TL;DR:** 本文提出了一个名为GRePO-LTV的创新框架，通过图表示学习解决数据稀缺问题，并利用帕累托优化管理预测任务之间的相互依赖性，以准确预测微信小游戏中的用户生命周期价值（LTV）。

**AI_Comments:** 该论文的创新点在于提出了GRePO-LTV框架，创造性地结合了图表示学习和帕累托优化来解决生命周期价值（LTV）预测中的两大核心难题：数据稀缺和多任务依赖。这种方法对于实际广告场景中，尤其是在用户购买行为稀疏的环境下，提升LTV预测的准确性具有重要意义。该框架有望为广告商提供更精准的用户价值评估。

<details>
  <summary>Details</summary>

**Motivation:** 广告商迫切需要精确的生命周期价值（LTV）预测系统，以提升用户兴趣与广告匹配度，从而产生可观利润。然而，实际广告场景中存在数据稀缺（购买率极低，监督信号不足）和高度相关任务之间相互依赖性（如3天预测影响7天预测）的挑战，这些都使得LTV预测变得复杂。

**Method:** 本文引入了一个名为“图表示帕累托最优生命周期价值预测”（GRePO-LTV）的创新框架。首先，利用图表示学习来解决数据稀缺问题。其次，采用帕累托优化来管理不同预测任务之间的相互依赖性。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一个名为GRePO-LTV的创新框架，用于微信小游戏中的生命周期价值（LTV）预测。该框架旨在解决LTV预测面临的两大挑战：一是数据稀缺，即用户购买率低导致有效监督信号不足；二是高度相关预测任务之间的相互依赖性。GRePO-LTV通过图表示学习来处理数据稀缺问题，并通过帕累托优化来管理不同预测任务之间的关联性，从而实现更精确的LTV预测，帮助广告商优化广告投放并获取利润。

> **摘要翻译:** 生命周期价值（LTV）预测，旨在预测用户对特定商品的累计购买贡献，仍然是广告商亟待解决的关键挑战。精确的LTV预测系统能够增强用户兴趣与精心设计的广告之间的匹配度，从而为广告商带来可观利润。然而，这个问题因现实世界广告场景中普遍存在的数据稀缺而变得复杂。注册用户的购买率通常低至0.1%，导致数据集中大多数用户只进行几次购买。因此，有效训练LTV预测模型的监督信号不足。另一个挑战源于高度相关任务之间的相互依赖性。通常做法是估计用户在特定时间间隔内对游戏的贡献。这些间隔长度的变化对应着不同的预测任务，这些任务之间高度相关。例如，7天期间的预测严重依赖于3天期间的预测，其中异常情况可能对两项任务的准确性产生不利影响。为了全面解决上述挑战，我们引入了一个创新的框架，称为图表示帕累托最优生命周期价值预测（GRePO-LTV）。首先采用图表示学习来解决数据稀缺问题。随后，利用帕累托优化来管理预测任务的相互依赖性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [MoTE: Mixture of Task-specific Experts for Pre-Trained ModelBased Class-incremental Learning](https://arxiv.org/abs/2506.11038)
> *MoTE：面向预训练模型的任务特定专家混合模型用于类增量学习*

*Linjie Li, Zhenyu Wu, Yang Ji* | **Main category: cs.LG**

**Keywords:** 类增量学习, 预训练模型, 专家混合, 任务特定专家, 灾难性遗忘

**Comment:** Accepted to KBS

> **TL;DR:** MoTE提出了一种新的框架，通过任务特定专家混合来解决预训练模型在类增量学习中遇到的提示覆盖和维度不对齐问题，无需记忆样本集。

**AI_Comments:** MoTE的创新之处在于其对MoE思想的巧妙借鉴和改进，使其适应于类增量学习的动态环境。通过引入任务特定专家和在推理阶段模拟路由，它有效地解决了预训练模型在CIL中面临的提示覆盖和维度不对齐等核心挑战，同时避免了灾难性遗忘。其无需记忆样本集的特性以及任务数量与适配器数量的线性扩展性，都凸显了其在实际应用中的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 类增量学习（CIL）要求深度学习模型在持续获取新知识的同时保留旧知识。基于预训练模型（PTMs）的CIL取得了显著成功，但基于提示的方法存在提示覆盖问题，基于适配器的方法面临任务间维度不对齐的挑战。MoE中的专家融合思想可以解决维度不一致，但其专家和路由参数在动态环境中容易被覆盖，使其难以直接应用于CIL。

**Method:** 我们提出了一个任务特定专家混合（MoTE）框架，有效缓解了任务间输出维度不一致导致的校准不良。受MoE中加权特征融合和稀疏激活机制的启发，我们在推理阶段引入了任务感知专家过滤和可靠的专家联合推理，模拟路由层的行为，同时避免灾难性遗忘。在此基础上，我们进一步探索了适配器扩展与模型性能之间的权衡，并提出了Adapter-Limited MoTE。

**Result:** 实验证明，我们的方法在无需记忆样本集的情况下表现出优越性。此外，MoTE中的任务数量与适配器数量呈线性关系。

**Conclusion:** MoTE框架有效解决了预训练模型在类增量学习中面临的挑战，特别是提示覆盖和维度不对齐问题，并通过创新的推理机制实现了优异的性能，且无需记忆样本集。

> **ai_Abstract:** MoTE是一种新颖的类增量学习框架，旨在解决预训练模型在CIL中遇到的提示覆盖和任务间维度不对齐问题。它通过引入任务感知专家过滤和可靠的专家联合推理，在推理阶段模仿MoE的路由行为，有效避免了灾难性遗忘，并缓解了维度不一致导致的校准不良。实验证明，MoTE在无需记忆样本集的情况下表现优越，并且任务数量与适配器数量呈线性关系。

> **摘要翻译:** 类增量学习（CIL）要求深度学习模型在持续获取新知识的同时保留以前学习到的信息。最近，基于预训练模型（PTMs）的CIL取得了显著成功。然而，基于提示的方法存在提示覆盖问题，而基于适配器的方法面临任务间维度不对齐等挑战。虽然专家混合（MoE）中的专家融合思想有助于解决维度不一致问题，但专家和路由参数在动态环境中都容易被覆盖，使得MoE难以直接应用于CIL。为了解决这些问题，我们提出了一种任务特定专家混合（MoTE）框架，该框架有效缓解了由任务间输出维度不一致引起的校准不良。受MoE中加权特征融合和稀疏激活机制的启发，我们在推理阶段引入了任务感知专家过滤和可靠的专家联合推理，模拟路由层的行为而不会引起灾难性遗忘。大量的实验证明了我们方法的优越性，且无需记忆样本集。此外，MoTE中的任务数量与适配器数量呈线性关系。在此基础上，我们进一步探讨了适配器扩展与模型性能之间的权衡，并提出了Adapter-Limited MoTE。代码可在https://github.com/Franklilinjie/MoTE获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [327] [uPVC-Net: A Universal Premature Ventricular Contraction Detection Deep Learning Algorithm](https://arxiv.org/abs/2506.11238)
> *uPVC-Net：一种通用室性早搏检测深度学习算法*

*Hagai Hamami, Yosef Solewicz, Daniel Zur, Yonatan Kleerekoper, Joachim A. Behar* | **Main category: cs.LG**

**Keywords:** 室性早搏, 深度学习, 心电图, 通用性, 心律失常

**Comment:** 8 pages

> **TL;DR:** uPVC-Net是一种通用的深度学习模型，能从任何单导联心电图记录中准确检测室性早搏，并在不同数据集上表现出强大的泛化能力。

**AI_Comments:** uPVC-Net的创新之处在于其“通用”性，通过多源、多导联的训练策略，解决了室性早搏检测中因导联放置、记录条件和人群差异导致的心电图波形可变性问题。其在可穿戴设备数据上取得的高性能，预示着该技术在远程医疗和日常健康监测方面具有巨大的应用潜力。该研究为开发更稳健、更广泛适用的心律失常检测系统提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 由于导联放置、记录条件和人群差异导致心电图波形的可变性，准确检测室性早搏（PVCs）仍然具有挑战性。

**Method:** 开发了uPVC-Net，一个通用的深度学习模型，用于从任何单导联心电图记录中检测室性早搏。该模型在四个独立的心电图数据集上开发，包含总计830万次心跳，数据来源于Holter监护仪和现代可穿戴心电图贴片。uPVC-Net采用自定义架构和多源、多导联训练策略。每次实验都保留一个数据集用于评估分布外（OOD）泛化能力。

**Result:** uPVC-Net在保留数据集上的AUC介于97.8%和99.1%之间。值得注意的是，在可穿戴单导联心电图数据上的性能达到99.1%的AUC。

**Conclusion:** uPVC-Net在不同的导联配置和人群中表现出强大的泛化能力，突显了其在稳健的实际临床部署中的潜力。

> **ai_Abstract:** uPVC-Net是一种新颖的深度学习算法，旨在解决由于心电图波形变异性导致的室性早搏（PVCs）检测挑战。该模型基于包含830万次心跳的多个独立心电图数据集进行训练，采用自定义架构和多源、多导联策略，以实现通用性。实验结果显示，uPVC-Net在未见过的数据集上表现出高精度（AUC 97.8%-99.1%），尤其在可穿戴设备数据上性能卓越，证明了其在实际临床应用中对不同导联配置和人群的强大泛化能力。

> **摘要翻译:** 引言：室性早搏（PVCs）是常见的心脏心律失常，起源于心室。由于导联放置、记录条件和人群差异导致心电图（ECG）波形的可变性，准确检测仍然具有挑战性。方法：我们开发了uPVC-Net，一个通用的深度学习模型，用于从任何单导联心电图记录中检测室性早搏。该模型在四个独立的心电图数据集上开发，包含总计830万次心跳，数据来源于Holter监护仪和现代可穿戴心电图贴片。uPVC-Net采用自定义架构和多源、多导联训练策略。每次实验都保留一个数据集用于评估分布外（OOD）泛化能力。结果：uPVC-Net在保留数据集上的AUC介于97.8%和99.1%之间。值得注意的是，在可穿戴单导联心电图数据上的性能达到99.1%的AUC。结论：uPVC-Net在不同的导联配置和人群中表现出强大的泛化能力，突显了其在稳健的实际临床部署中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Domain-Constrained Diffusion Models to Synthesize Tabular Data: A Case Study in Power Systems](https://arxiv.org/abs/2506.11281)
> *领域约束扩散模型用于合成表格数据：电力系统案例研究*

*Milad Hoseinpour, Vladimir Dvorkin* | **Main category: cs.LG**

**Keywords:** 扩散模型, 合成数据, 表格数据, 领域约束, 电力系统

**Comment:** 9 pages, 6 figures, conference

> **TL;DR:** 本文提出一种领域约束的扩散模型，通过梯度引导将领域知识集成到生成过程中，用于合成电力系统中的表格数据，效果良好。

**AI_Comments:** 该论文的创新点在于将领域约束直接集成到扩散模型的生成过程中，并通过梯度引导实现。这克服了传统生成模型在处理复杂领域知识时的局限性，特别是在需要严格物理或业务规则的领域（如电力系统）中具有重要意义。该方法有望提高合成数据的实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 隐私、安全和法律障碍日益增长，导致对合成数据的需求增加。现有生成模型需要整合领域特定知识以提高实用性。

**Method:** 提出一种引导式扩散模型，将领域约束直接整合到生成过程中。具体通过引入基于梯度的引导，在采样轨迹中引入可行方向，以满足领域约束（如基尔霍夫定律）。

**Result:** 数值结果表明该方法是有效的。

**Conclusion:** 该方法能够有效地合成满足领域约束的表格数据，并在电力系统案例中展示了其有效性，具有推广到其他表格数据领域的潜力。

> **ai_Abstract:** 本文提出了一种领域约束的扩散模型，旨在解决隐私、安全和法律限制下对合成数据日益增长的需求。该模型通过在生成过程中直接整合领域特定知识（如电力系统中的基尔霍夫定律），并利用基于梯度的引导来确保生成数据的统计代表性和高保真度。在电力系统的案例研究中，数值结果验证了该方法的有效性，表明其在合成满足复杂领域约束的表格数据方面具有潜力。

> **摘要翻译:** 对隐私、安全和法律障碍日益增长的担忧正在推动医疗保健、金融和能源等领域对合成数据的需求不断上升。虽然生成模型为克服这些障碍提供了一个有前景的解决方案，但其效用取决于领域特定知识的整合。我们提出使用一种引导式扩散模型来合成数据，该模型将领域约束直接集成到生成过程中。我们在电力系统背景下开发了该模型，并具有推广到其他涉及表格数据的领域的潜力。具体来说，我们合成了具有统计代表性和高保真度的潮流数据集。为了满足领域约束，例如基尔霍夫定律，我们引入了基于梯度的引导来引导采样轨迹朝向可行方向。数值结果证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [329] [Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation](https://arxiv.org/abs/2506.11039)
> *角度域引导：潜在扩散需要旋转而非外推*

*Cheng Jin, Zhenyu Xiao, Chutao Liu, Yuantao Gu* | **Main category: cs.LG**

**Keywords:** 角度域引导, 无分类器引导, 潜在扩散模型, 颜色失真, 文本到图像生成

**Comment:** Accepted at ICML 2025

> **TL;DR:** 本文提出角度域引导（ADG）算法，通过限制潜在空间中的范数变化并优化角度对齐，解决了无分类器引导（CFG）在高引导权重下导致的颜色失真问题，同时保持了文本-图像对齐。

**AI_Comments:** 该论文创新性地从潜在空间的范数放大角度解释了CFG在高引导权重下颜色失真的原因，并提出了角度域引导（ADG）这一新颖的解决方案。ADG通过在角度域进行优化，而非简单地进行外推，有效解决了色彩失真问题，同时保持了文本对齐，对文本到图像生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无分类器引导（CFG）在文本到图像潜在扩散模型中能显著增强文本-图像对齐并生成高质量图像，但在高引导权重下会导致生成的图像出现明显的颜色失真。本文认为这些失真源于潜在空间中样本范数的放大。

**Method:** 本文提出了一个理论框架来阐明无分类器引导引起的范数放大和异常扩散现象的机制。在此理论洞察和潜在空间结构的基础上，提出了角度域引导（ADG）算法。ADG通过限制幅度变化同时优化角度对齐，从而在保持高引导权重下增强的文本-图像对齐的同时，减轻颜色失真。

**Result:** 实验结果表明，ADG显著优于现有方法，生成的图像不仅保持了卓越的文本对齐，而且展现出改善的色彩保真度和更好地符合人类感知偏好。

**Conclusion:** 角度域引导（ADG）通过在潜在空间中限制范数变化并优化角度对齐，有效解决了无分类器引导（CFG）在高引导权重下导致的颜色失真问题，同时保持了高质量的文本-图像对齐，从而生成了色彩更真实、感知效果更好的图像。

> **ai_Abstract:** 本文针对无分类器引导（CFG）在高引导权重下导致文本到图像生成中颜色失真的问题，提出了角度域引导（ADG）算法。研究发现颜色失真源于潜在空间中样本范数的放大。ADG算法基于理论框架，通过限制潜在空间中的范数变化并优化角度对齐，有效缓解了颜色失真，同时保持了优异的文本-图像对齐。实验证明ADG在图像色彩保真度和人类感知偏好方面均优于现有方法。

> **摘要翻译:** 无分类器引导（CFG）已成为文本到图像潜在扩散模型中的一项关键进展，确立了其在实现高质量图像合成方面的基石技术地位。然而，在高引导权重下（此时文本-图像对齐显著增强），CFG也会导致生成的图像出现明显的颜色失真。我们发现这些失真源于潜在空间中样本范数的放大。我们提出了一个理论框架，阐明了无分类器引导引起的范数放大和异常扩散现象的机制。利用我们的理论见解和潜在空间结构，我们提出了一种角度域引导（ADG）算法。ADG在优化角度对齐的同时限制了幅度变化，从而在保持高引导权重下增强的文本-图像对齐的同时，减轻了颜色失真。实验结果表明，ADG显著优于现有方法，生成的图像不仅保持了卓越的文本对齐，而且展现出改善的色彩保真度和更好地符合人类感知偏好。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks](https://arxiv.org/abs/2506.11791)
> *SEC-bench：LLM智能体在真实世界软件安全任务中的自动化基准测试*

*Hwiwon Lee, Ziqi Zhang, Hanxiao Lu, Lingming Zhang* | **Main category: cs.LG**

**Keywords:** LLM智能体, 软件安全, 基准测试, 漏洞修补, 自动化

**Comment:** 

> **TL;DR:** SEC-bench是一个自动化基准测试框架，用于评估LLM智能体在真实世界软件安全任务（如PoC生成和漏洞修补）中的性能，结果显示当前LLM智能体在这些任务上表现不佳。

**AI_Comments:** SEC-bench的创新之处在于其全自动化和对真实世界软件安全任务的关注，解决了现有基准测试的局限性。其多智能体脚手架和低成本生成高质量数据集的能力是其重要贡献。该研究揭示了当前LLM智能体在实际安全工程任务中的显著不足，为未来LLM代理的发展指明了方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了建立对LLM智能体在软件开发生命周期中安全部署的信任，对其进行严格的以安全为重点的评估至关重要。然而，现有基准测试大多依赖合成挑战或简化漏洞数据集，无法捕捉安全工程师在实践中遇到的复杂性和模糊性。

**Method:** 引入了SEC-bench，一个全自动基准测试框架，用于评估LLM智能体在真实的软件工程任务中。SEC-bench采用一种新颖的多智能体脚手架，自动构建带有测试工具的代码仓库，在隔离环境中重现漏洞，并生成黄金补丁以进行可靠评估。该框架还能以每个实例0.87美元的成本自动创建高质量的可重现软件漏洞数据集。使用SEC-bench，作者实现了两个关键的软件安全任务：概念验证（PoC）生成和漏洞修补。

**Result:** 对最先进的LLM代码智能体进行全面评估显示出显著的性能差距，在完整数据集上，PoC生成任务的成功率最高为18.0%，漏洞修补任务的成功率最高为34.0%。

**Conclusion:** 这些结果强调了开发更实用、智能和自主的LLM智能体以用于安全工程所需采取的关键步骤。

> **ai_Abstract:** 本论文介绍了SEC-bench，一个创新的自动化基准测试框架，旨在解决现有LLM智能体安全评估中真实世界复杂性不足的问题。SEC-bench通过自动构建代码库、重现漏洞和生成黄金补丁来创建高质量、可重现的漏洞数据集。研究人员利用该框架评估了LLM智能体在概念验证（PoC）生成和漏洞修补两大关键软件安全任务上的表现。评估结果显示，当前最先进的LLM代码智能体在这些真实世界任务中表现出显著的性能差距，成功率分别仅为18.0%和34.0%，突显了未来LLM智能体在安全工程领域进一步发展和改进的必要性。

> **摘要翻译:** 对大型语言模型（LLM）智能体进行严格的以安全为重点的评估，对于在整个软件开发生命周期中建立对其安全部署的信任至关重要。然而，现有基准测试在很大程度上依赖于合成挑战或简化的漏洞数据集，这些都未能捕捉到安全工程师在实践中遇到的复杂性和模糊性。我们引入了SEC-bench，这是第一个全自动基准测试框架，用于评估LLM智能体在真实的软件工程任务中的表现。SEC-bench采用一种新颖的多智能体脚手架，可以自动构建带有测试工具的代码仓库，在隔离环境中重现漏洞，并生成黄金补丁以进行可靠评估。我们的框架以每个实例仅0.87美元的成本自动创建高质量的、可重现的软件漏洞数据集。使用SEC-bench，我们实现了两个关键的软件安全任务，以严格评估LLM智能体的能力：概念验证（PoC）生成和漏洞修补。对最先进的LLM代码智能体进行的全面评估揭示了显著的性能差距，在我们的完整数据集上，PoC生成任务的成功率最高为18.0%，漏洞修补任务的成功率最高为34.0%。这些结果突出了在开发更实用、智能和自主的LLM智能体以用于安全工程方面所需采取的关键步骤。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [341] [Robust Filtering -- Novel Statistical Learning and Inference Algorithms with Applications](https://arxiv.org/abs/2506.11530)
> *鲁棒滤波——新颖的统计学习与推理算法及其应用*

*Aamir Hussain Chughtai* | **Main category: cs.LG**

**Keywords:** 鲁棒滤波, 状态估计, 贝叶斯推理, 异常值, 非线性滤波

**Comment:** PhD Thesis

> **TL;DR:** 本文提出新颖的鲁棒非线性滤波方法，以应对真实世界中未知或部分已知噪声统计的挑战，并在多种应用中验证了其性能。

**AI_Comments:** 这篇论文的创新点在于提出了新颖的鲁棒非线性滤波方法，有效地解决了传统滤波算法在处理真实世界中未知或部分已知噪声统计的异常情况时的局限性。其重要性体现在为自主车辆、机器人、医疗监控等多个关键应用领域提供了更可靠的状态估计解决方案。此外，论文还考虑了理论估计极限，并指出了未来在机器学习和生成式AI领域的潜在扩展，显示了其深远的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准滤波假设已知噪声统计，但在真实世界中，异常情况（如异常值、偏差、漂移和缺失观测）的统计数据未知或部分已知，这限制了传统方法的应用，因此需要更鲁棒的算法。

**Method:** 本文提出了新颖的鲁棒非线性滤波方法，并将其扩展到离线估计/学习设置和平滑扩展。这些方法利用贝叶斯推理框架，采用包括变分推理（VI）和粒子滤波器/序贯蒙特卡洛（SMC）在内的确定性和随机近似技术。此外，还使用贝叶斯Cramér-Rao界（BCRBs）研究了测量异常情况下的理论估计极限。

**Result:** 通过在目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化等场景中的仿真和实验，验证了所提出方法的性能提升。

**Conclusion:** 该工作的根本性质使其在自主车辆、机器人、医疗监控等多种应用中都非常有用，并为未来开发鲁棒异常值的机器学习管道、从异常数据中学习系统动力学以及解决生成式AI中标准扩散模型面临的挑战提供了可能。

> **ai_Abstract:** 本文提出了一系列新颖的鲁棒非线性滤波方法，旨在解决传统状态估计算法在面对未知或部分已知噪声统计的真实世界异常情况（如异常值、偏差、漂移和缺失观测）时的局限性。这些方法基于贝叶斯推理框架，并结合了变分推理和粒子滤波器等确定性与随机近似技术。研究还探讨了在测量异常情况下的理论估计极限。通过在目标跟踪、室内定位和3D点云配准等多个应用场景中的仿真和实验，验证了所提出方法的有效性和性能提升。该研究具有广泛的应用潜力，并为未来在鲁棒机器学习和生成式AI等领域的发展奠定了基础。

> **摘要翻译:** 状态估计或滤波是一项基本任务，能够支持自主车辆、机器人技术、医疗保健监控、智能电网、智能交通和预测性维护等应用中的智能决策。标准滤波假定噪声统计的先验知识，以从噪声传感器数据中提取潜在系统状态。然而，真实世界场景涉及异常情况，如异常值、偏差、漂移和未知或部分已知统计的缺失观测，这限制了传统方法的应用。本论文提出了新颖的鲁棒非线性滤波方法来缓解这些挑战。基于我们滤波方案的见解，我们将公式扩展到离线估计/学习设置，并提出了平滑扩展。我们的方法利用贝叶斯推理框架，采用确定性和随机近似技术，包括变分推理（VI）和粒子滤波器/序贯蒙特卡洛（SMC）。我们还在测量异常的背景下，使用贝叶斯Cramér-Rao界（BCRBs）研究了理论估计极限。为了验证所提出方法的性能提升，我们在包括目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化在内的场景中进行了仿真和实验。这项工作的根本性质使其在各种应用中都有用，未来可能扩展到开发鲁棒异常值的机器学习管道、从异常数据中学习系统动力学以及解决生成式AI中标准扩散模型在异常值、不平衡数据集和模式崩溃方面面临的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [343] [ChemHGNN: A Hierarchical Hypergraph Neural Network for Reaction Virtual Screening and Discovery](https://arxiv.org/abs/2506.11041)
> *ChemHGNN：一种用于反应虚拟筛选和发现的分层超图神经网络*

*Xiaobao Huang, Yihong Ma, Anjali Gurajapu, Jules Schleinitz, Zhichun Guo, Sarah E. Reisman, Nitesh V. Chawla* | **Main category: cs.LG**

**Keywords:** 超图神经网络, 反应虚拟筛选, 多反应物相互作用, 反应发现, ChemHGNN

**Comment:** 

> **TL;DR:** ChemHGNN是一个分层超图神经网络，通过超边自然建模多反应物相互作用，显著优于传统GNN，用于反应虚拟筛选和发现。

**AI_Comments:** ChemHGNN的创新之处在于其利用超图神经网络（HGNN）来自然地建模多反应物之间的复杂高阶相互作用，这弥补了传统图神经网络（GNN）在处理这类问题时的不足。通过引入反应中心感知负采样和分层嵌入，该模型有效地解决了实际应用中的挑战，如组合爆炸和无效负样本。其在反应虚拟筛选和发现领域的应用潜力巨大，为加速新反应的发现提供了一个强有力的工具，具有重要的科学和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统图神经网络（GNNs）在建模多反应物相互作用方面存在困难，而反应虚拟筛选和发现是化学和材料科学中的基本挑战。

**Method:** 提出了ChemHGNN，一个超图神经网络（HGNN）框架，通过超边自然建模多反应物反应，捕获高阶关系。引入了反应中心感知负采样策略（RCNS）和结合分子、反应和超图级别特征的分层嵌入方法，以解决组合爆炸、模型崩溃和化学无效负样本等挑战。

**Result:** 在USPTO数据集上的实验表明，ChemHGNN显著优于HGNN和GNN基线，尤其是在大规模设置下，同时保持可解释性和化学合理性。

**Conclusion:** ChemHGNN将超图神经网络（HGNNs）确立为反应虚拟筛选和发现中优于图神经网络（GNNs）的替代方案，提供了一个化学信息框架来加速反应发现。

> **ai_Abstract:** 本文提出ChemHGNN，一个分层超图神经网络框架，用于解决传统图神经网络在多反应物相互作用建模方面的不足，以改进反应虚拟筛选和发现。ChemHGNN通过超边直接建模多反应物，并结合反应中心感知负采样和分层嵌入策略。实验证明，ChemHGNN在大规模反应预测中性能优越，且具有良好的可解释性和化学合理性，为反应发现提供了一个高效且化学信息化的新方法。

> **摘要翻译:** 反应虚拟筛选和发现是化学和材料科学中的基本挑战，传统图神经网络（GNNs）难以建模多反应物相互作用。在这项工作中，我们提出了ChemHGNN，一个超图神经网络（HGNN）框架，它能有效捕获反应网络中的高阶关系。与需要为多反应物反应构建完整图的GNN不同，ChemHGNN通过超边自然地建模多反应物反应，从而实现更具表达力的反应表示。为了解决组合爆炸、模型崩溃和化学无效负样本等关键挑战，我们引入了反应中心感知负采样策略（RCNS）和结合分子、反应和超图级别特征的分层嵌入方法。在USPTO数据集上的实验表明，ChemHGNN显著优于HGNN和GNN基线，尤其是在大规模设置下，同时保持可解释性和化学合理性。我们的工作将HGNNs确立为反应虚拟筛选和发现中GNNs的优越替代方案，为加速反应发现提供了一个化学信息框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [351] [GenFT: A Generative Parameter-Efficient Fine-Tuning Method for Pretrained Foundation Models](https://arxiv.org/abs/2506.11042)
> *GenFT：一种用于预训练基础模型的生成式参数高效微调方法*

*Baoquan Zhang, Guangning Xu, Michael. K. Ng* | **Main category: cs.LG**

**Keywords:** 参数高效微调, 预训练基础模型, 生成式方法, 模型适应, 结构化信息

**Comment:** 

> **TL;DR:** GenFT是一种新的参数高效微调方法，它利用预训练权重来指导任务特定权重的更新，通过提取结构化信息并分解权重，在CV和NLP任务上超越了现有PEFT方法。

**AI_Comments:** 本文的创新点在于提出了一个新颖的思路，即利用预训练权重$W_0$来指导任务特定权重$\Delta W$的训练，而不是从头开始。通过引入行/列变换和层共享/层特定分解策略，GenFT有效地解决了参数高效微调中的效率问题，并取得了SOTA性能，对未来的模型适应研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的参数高效微调（PEFT）方法在适应下游任务时，通常需要从头开始训练任务特定的重参数化权重$\Delta W$。本文的动机是探索能否利用预训练权重$W_0$来指导$\Delta W$的更新，从而避免低效的从头训练。

**Method:** 本文提出了生成式参数高效微调（GenFT）方法。GenFT通过对$W_0$应用行和列变换来提取结构化的、可迁移的信息，以指导$\Delta W$的训练。此外，GenFT采用定制策略将$\Delta W$分解为层共享和层特定的组件，以平衡信息重用和个性化灵活性。

**Result:** GenFT方法简单有效，在计算机视觉（CV）和自然语言处理（NLP）任务上均取得了卓越的性能。在VTAB-1K、FGVC和GLUE基准测试上的广泛实验表明，GenFT优于最先进的PEFT方法。

**Conclusion:** GenFT为高效模型适应提供了一个新视角。

> **ai_Abstract:** 本文提出了一种名为GenFT（生成式参数高效微调）的新方法，旨在解决现有PEFT方法中任务特定权重$\Delta W$从头训练效率低下的问题。GenFT通过从预训练权重$W_0$中提取结构化信息，并将其分解为层共享和层特定组件，来指导$\Delta W$的更新。实验证明，GenFT在CV和NLP任务上均优于现有SOTA的PEFT方法，为高效模型适应提供了新思路。

> **摘要翻译:** 预训练基础模型（PFMs）通过实现对定制任务的高效适应，改变了众多应用。参数高效微调（PEFT）已成为全量微调的资源高效替代方案，特别是利用重参数化权重$\Delta W$来适应下游任务。然而，一个关键但尚未充分探索的问题依然存在：我们能否利用训练良好的预训练权重$W_0$来指导任务特定$\Delta W$的更新，从而避免从头开始的低效训练？为此，我们提出了生成式参数高效微调（GenFT），这是一种新颖的方法，它从$W_0$中提取结构化的、可迁移的信息，用于高效的$\Delta W$训练。为了提取行和列结构信息，GenFT应用行和列变换从$W_0$中提取基本模式。定制策略进一步将$\Delta W$分解为层共享和层特定的组件，平衡了信息重用和个体灵活性。GenFT简单而有效，在CV和NLP任务中均取得了卓越的性能。在VTAB-1K、FGVC和GLUE基准测试上的广泛实验表明，GenFT优于最先进的PEFT方法，为高效模型适应提供了一个新视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [360] [Boost Post-Training Quantization via Null Space Optimization for Large Language Models](https://arxiv.org/abs/2506.11044)
> *通过零空间优化提升大语言模型训练后量化*

*Jiaqi Zhao, Miao Zhang, Weili Guan, Liqiang Nie* | **Main category: cs.LG**

**Keywords:** 大语言模型, 训练后量化, 零空间优化, 量化误差, Q2N

**Comment:** 17 pages, 4 figures

> **TL;DR:** 本文引入零空间概念以优化大语言模型训练后量化，提出Q2N模块，通过将量化误差限制在输入激活的零空间内，显著提升了量化效果，并在多种SOTA LLM上验证了其有效性。

**AI_Comments:** 本文创新性地将零空间概念引入大语言模型量化领域，提出了Q2N模块，为解决现有量化方法的性能瓶颈提供了新思路。其即插即用的特性和理论推导的闭合形式解，使其具有较强的实用性和通用性。该研究为未来开发更高效、更压缩的LLMs量化方法奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型训练后量化方法效果显著，但性能提升日益边际化，表明现有量化策略不足以支持更压缩模型的发展，因此需要新的研究方向。

**Method:** 本文引入零空间概念，认为通过将量化后的权重扰动限制在输入激活的零空间内，可以有效缓解量化误差。为此，提出了一个即插即用的零空间投影模块Q2N，它首先设计了一种针对LLM特点的高效准确的零空间投影近似方法，然后理论推导了所获得投影矩阵的等效向量的闭合形式解，以满足实际推理条件并避免额外内存开销。

**Result:** 在各种最先进的大语言模型（LLaMA3、DeepSeek、Qwen3）和基线上进行了广泛实验，证明了Q2N以及零空间优化视角对于LLMs量化的有效性。

**Conclusion:** 本文是基于零空间洞察力进一步缓解量化误差的第一步，希望能启发未来的研究人员设计更先进的量化方法。

> **ai_Abstract:** 本文针对大语言模型（LLMs）训练后量化面临的性能瓶颈，创新性地引入了零空间概念。研究认为，通过将量化误差限制在输入激活的零空间内，可以有效提升量化效果。为此，提出了一种名为Q2N的即插即用零空间投影模块，该模块包含为LLMs量身定制的高效零空间投影近似方法，并推导了满足推理条件且无额外内存开销的闭合形式解。实验证明，Q2N在多种SOTA LLMs上显著提升了量化性能，为LLMs量化提供了新的优化视角。

> **摘要翻译:** 现有的大语言模型（LLMs）训练后量化方法取得了显著成功。然而，日益边际化的性能提升表明现有量化策略不足以支持更压缩模型的发展。为了启发未来研究的新方向，本文将零空间概念引入LLMs量化。我们认为，通过将量化后的权重扰动限制在输入激活的零空间内，可以有效缓解量化误差。为了证明这一想法，我们为现有里程碑式的PTQ基线提出了一个即插即用的零空间投影模块，命名为Q2N。具体来说，我们首先设计了一种针对LLMs特点的高效准确的零空间投影近似方法。随后，我们理论推导了所获得投影矩阵的等效向量的闭合形式解，该解满足实际推理条件，同时避免了额外的内存开销。在各种最先进的LLMs（LLaMA3、DeepSeek、Qwen3）和基线上进行了广泛实验，证明了Q2N以及零空间优化视角对于LLMs量化的有效性。我们认为本文是基于零空间洞察力进一步缓解量化误差的第一步，希望能启发未来的研究人员设计更先进的量化方法。代码可在https://github.com/zjq0455/q2n获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [368] [Procedural Environment Generation for Tool-Use Agents](https://arxiv.org/abs/2506.11045)
> *用于工具使用代理的程序化环境生成*

*Michael Sullivan, Mareike Hartmann, Alexander Koller* | **Main category: cs.LG**

**Keywords:** 程序化生成, 工具使用代理, 合成数据, RandomWorld, 强化学习

**Comment:** 16 pages, 3 figures

> **TL;DR:** 引入了RandomWorld，一个用于程序化生成交互式工具和组合式工具使用数据的管道，以解决工具使用训练数据策展的开放问题。

**AI_Comments:** 该论文的创新之处在于提出了一个程序化生成交互式和组合式工具使用数据的管道，解决了LLM工具使用代理训练数据稀缺和非交互性的问题。其重要性在于证明了合成数据可以有效提升模型性能，并开辟了通过纯合成数据实现进一步改进的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）工具使用代理的强大功能引发了该领域的近期研究热潮，但工具使用训练数据的策展仍然是一个开放问题，特别是对于在线强化学习（RL）训练。现有的合成工具使用数据生成方法往往是非交互式的和/或非组合式的。

**Method:** 本文引入了RandomWorld，这是一个用于程序化生成交互式工具和组合式工具使用数据的管道。

**Result:** 通过在合成RandomWorld数据上进行SFT（监督微调）和RL（强化学习）调优的模型，在各种工具使用基准上都取得了改进，并在NESTFUL数据集的两个指标上设置了新的最新技术水平（SoTA）。进一步的实验表明，下游性能与RandomWorld生成的训练数据量呈正比，这为通过完全使用合成数据实现进一步改进提供了可能性。

**Conclusion:** 通过程序化生成交互式和组合式的合成数据，可以显著提高LLM工具使用代理的性能，并有望通过增加合成数据量实现进一步的改进。

> **ai_Abstract:** 该论文提出了RandomWorld，一个程序化生成工具使用训练数据的管道，旨在解决LLM工具使用代理在训练数据策展方面的挑战。RandomWorld能够生成交互式和组合式的工具与数据，并展示了使用其生成的数据进行模型调优（SFT和RL）能够提高在多个工具使用基准上的性能，并在NESTFUL数据集上创下新高。研究还发现，性能与合成数据量呈正相关，表明未来可通过纯合成数据进一步提升。

> **摘要翻译:** 尽管大型语言模型（LLM）工具使用代理的强大功能引发了该领域的近期研究热潮，但工具使用训练数据的策展仍然是一个开放问题，特别是对于在线强化学习（RL）训练。现有的合成工具使用数据生成方法往往是非交互式的和/或非组合式的。我们引入了RandomWorld，一个用于程序化生成交互式工具和组合式工具使用数据的管道。我们展示了通过在合成RandomWorld数据上进行SFT（监督微调）和RL（强化学习）调优的模型，在各种工具使用基准上都取得了改进，并在NESTFUL数据集的两个指标上设置了新的最新技术水平（SoTA）。进一步的实验表明，下游性能与RandomWorld生成的训练数据量呈正比，这为通过完全使用合成数据实现进一步改进提供了可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [373] [The Effects of Data Augmentation on Confidence Estimation for LLMs](https://arxiv.org/abs/2506.11046)
> *数据增强对大型语言模型置信度估计的影响*

*Rui Wang, Renyu Zhu, Minmin Lin, Runze Wu, Tangjie Lv, Changjie Fan, Haobo Wang* | **Main category: cs.LG**

**Keywords:** 数据增强, 置信度估计, 大型语言模型, 过度自信, 数据多样性

**Comment:** 

> **TL;DR:** 本文研究了不同数据增强方法对大型语言模型（LLMs）置信度估计的影响，发现数据增强能提升性能并缓解过拟合，且在保持语义信息的前提下，数据多样性越大效果越好。随机组合增强是一种有前景的选择。

**AI_Comments:** 这篇论文探讨了一个重要且及时的研究方向，即数据增强对大型语言模型置信度估计的影响。其创新之处在于不仅验证了数据增强的有效性，还深入分析了数据多样性这一关键影响因素，并提出了随机组合增强作为一种实用的解决方案，这对于提升LLMs在实际应用中的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 置信度估计对于反映大型语言模型（LLMs）的可靠性至关重要，特别是在广泛使用的闭源模型中。尽管数据增强可用于置信度估计，但现有讨论主要集中在特定的增强技术上，限制了其潜力。

**Method:** 我们研究了不同数据增强方法对置信度估计的影响，并调查了相关的影响因素。

**Result:** 研究结果表明，数据增强策略可以实现更好的性能并减轻过度自信的影响。我们发现，在保留语义信息的同时，更大的数据多样性可以增强增强的有效性。此外，不同增强策略的影响在不同的应用范围中有所不同。

**Conclusion:** 考虑到参数可迁移性和可用性，数据增强的随机组合是一个有前景的选择。

> **ai_Abstract:** 本文探讨了数据增强对大型语言模型（LLMs）置信度估计的影响。研究发现，数据增强策略能有效提升置信度估计的性能并缓解模型的过度自信。进一步分析表明，在保持语义完整性的前提下，数据多样性是提升增强效果的关键因素。此外，不同增强策略在不同应用场景下的效果存在差异。综合考虑参数的可迁移性和实用性，随机组合数据增强被认为是一种有前景的选择。

> **摘要翻译:** 置信度估计对于反映大型语言模型（LLMs）的可靠性至关重要，尤其是在广泛使用的闭源模型中。利用数据增强进行置信度估计是可行的，但讨论主要集中在特定的增强技术上，限制了其潜力。我们研究了不同数据增强方法对置信度估计的影响。我们的研究结果表明，数据增强策略可以实现更好的性能并减轻过度自信的影响。我们调查了与此相关的影响因素，发现，在保留语义信息的同时，更大的数据多样性可以增强增强的有效性。此外，不同增强策略的影响在不同的应用范围中有所不同。考虑到参数可迁移性和可用性，数据增强的随机组合是一个有前景的选择。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [383] [I Can't Believe It's Not Real: CV-MuSeNet: Complex-Valued Multi-Signal Segmentation](https://arxiv.org/abs/2506.11048)
> *难以置信这不是真的：CV-MuSeNet：复值多信号分割*

*Sangwon Shin, Mehmet C. Vuran* | **Main category: cs.LG**

**Keywords:** 复值神经网络, 频谱感知, 多信号分割, 低信噪比, 认知无线电

**Comment:** 

> **TL;DR:** CMuSeNet是一种复值神经网络，用于宽带频谱感知，在低信噪比环境下显著提高了弱信号检测精度和训练效率。

**AI_Comments:** 该论文的创新点在于提出了一个专门针对无线信号复值特性的神经网络CMuSeNet，并引入了新的损失函数和度量。其显著提升的检测精度和训练效率，尤其是在低信噪比环境下的表现，对认知无线电和频谱感知领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 射频频谱日益拥堵，对高效频谱利用提出了挑战。传统的实值神经网络（RVNNs）在低信噪比（SNR）环境下难以捕获无线信号的相位和幅度等基本特性，导致性能不佳。

**Method:** 本文提出了CMuSeNet，一个基于复值神经网络（CVNNs）和残差架构的复值多信号分割网络，以解决传统实值神经网络的局限性。CMuSeNet引入了复值傅里叶频谱焦点损失（CFL）和复平面交并比（CIoU）相似性度量来增强训练性能。

**Result:** CMuSeNet在合成、室内空中和真实世界数据集上实现了98.98%-99.90%的平均准确率，比其对应的实值网络提高了9.2个百分点，并持续优于现有技术。它仅需2个训练周期即可达到实值网络所需的准确率水平（实值网络需要27个训练周期），同时训练时间比现有技术缩短了92.2%。

**Conclusion:** 复值架构在改善挑战性低信噪比环境下频谱感知的弱信号检测和训练效率方面是有效的。

> **ai_Abstract:** 本文提出了CMuSeNet，一种用于宽带频谱感知的复值多信号分割网络，旨在解决传统实值神经网络在低信噪比环境下无法有效处理无线信号相位和幅度信息的问题。CMuSeNet基于复值神经网络和残差架构，并引入了复值傅里叶频谱焦点损失和复平面交并比度量以优化训练。实验结果表明，CMuSeNet在弱信号检测精度和训练效率上均显著优于现有实值网络和SOTA方法。

> **摘要翻译:** 射频频谱日益拥堵，对高效频谱利用提出了挑战。认知无线电系统借助神经网络的最新创新，实现了动态频谱接入。然而，传统的实值神经网络（RVNN）在低信噪比（SNR）环境下表现不佳，因为它们并非专门开发用于捕获无线信号的相位和幅度等基本特性。本文提出了CMuSeNet，一个用于宽带频谱感知的复值多信号分割网络，以解决这些局限性。广泛的超参数分析表明，将现有实值神经网络简单转换为其复值对应物是无效的。CMuSeNet基于具有残差架构的复值神经网络（CVNN），引入了复值傅里叶频谱焦点损失（CFL）和复平面交并比（CIoU）相似性度量，以提高训练性能。在合成、室内无线和真实世界数据集上的广泛评估表明，CMuSeNet的平均准确率达到98.98%-99.90%，比其对应的实值网络提高了9.2个百分点，并持续优于现有技术。引人注目的是，CMuSeNet仅需两个训练周期即可达到实值神经网络的准确率水平，而实值神经网络需要27个训练周期，同时训练时间比现有技术缩短了92.2%。结果强调了复值架构在改善挑战性低信噪比环境下频谱感知的弱信号检测和训练效率方面的有效性。数据集可在以下网址获取：https://dx.doi.org/10.21227/hcc1-6p22

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks](https://arxiv.org/abs/2506.11049)
> *15,500秒：利用PEFT和预训练网络实现精益无人机分类*

*Andrew P. Berg, Qian Zhang, Mia Y. Wang* | **Main category: cs.LG**

**Keywords:** 无人机分类, 数据稀缺, 参数高效微调, 预训练网络, 音频分类

**Comment:** 

> **TL;DR:** 本文通过参数高效微调、数据增强和预训练网络解决了无人机音频分类中的数据稀缺问题，并达到了超过95%的验证准确率。

**AI_Comments:** 这篇论文的创新点在于将参数高效微调（PEFT）与预训练网络和数据增强结合，以解决无人机音频分类中常见的数据稀缺问题。其重要性在于提供了一种“精益”且高效的分类方法，在数据量有限的情况下仍能取得高性能，这对于实际部署和资源受限的环境非常有价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着消费和军用无人机市场的增长，无人机带来了日益增长的安全隐患。本文旨在解决深度无人机音频分类中关键的数据稀缺挑战。

**Method:** 该研究基于之前的成果，采用了参数高效微调（PEFT）、数据增强和预训练网络等新颖方法。具体使用了EfficientNet-B0。

**Result:** 使用EfficientNet-B0，实现了超过95%的验证准确率。

**Conclusion:** 通过利用PEFT和预训练网络等方法，能够有效解决无人机音频分类中的数据稀缺问题，并取得高准确率的分类性能。

> **ai_Abstract:** 本文针对日益增长的无人机安全隐患，致力于解决无人机音频分类中的数据稀缺难题。研究人员利用参数高效微调（PEFT）、数据增强和预训练网络等方法，成功地在EfficientNet-B0模型上实现了超过95%的验证准确率，展示了在数据受限环境下进行高效无人机分类的潜力。

> **摘要翻译:** 无人机（UAV）市场（包括消费级和军用）的增长带来了日益升级的安全隐患。本文旨在解决深度无人机音频分类中关键的数据稀缺挑战。我们基于先前的工作，扩展了新颖的方法，例如：参数高效微调、数据增强和预训练网络。我们使用EfficientNet-B0实现了超过95%的验证准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [394] [NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with LLMs](https://arxiv.org/abs/2506.11050)
> *NSW-EPNews：一个用于LLM电力价格预测的新闻增强基准*

*Zhaoge Bi, Linghan Huang, Haolin Jin, Qingwen Zeng, Huaming Chen* | **Main category: cs.LG**

**Keywords:** 电力价格预测, 大型语言模型, 新闻增强, 基准数据集, 多模态预测

**Comment:** 9 pages' main texts. Submitted to NeurIPS 2025 Datasets and
  Benchmarks Track

> **TL;DR:** NSW-EPNews是一个新的基准数据集，首次将时序模型和大型语言模型（LLMs）结合用于电力价格预测，发现新闻特征对传统模型提升不大，而LLMs虽有小幅提升但存在幻觉问题。

**AI_Comments:** 该论文的创新点在于首次将新闻文本信息引入电力价格预测领域，并构建了一个专门用于评估LLMs在此任务上表现的基准数据集。其重要性在于揭示了LLMs在处理复杂数值推理和高风险预测任务时，尽管有潜力，但仍存在“幻觉”等关键局限性，为未来LLM在实际应用中的发展方向提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有电力价格预测方法严重依赖数值历史数据，忽略了同期的文本信号。本研究旨在引入新闻信息来增强电力价格预测，并评估大型语言模型在此任务上的潜力。

**Method:** 引入NSW-EPNews数据集，包含来自澳大利亚新南威尔士州（2015-2024年）超过175,000个半小时现货价格、每日温度读数和WattClarity策划的市场新闻摘要。任务被设定为48步超前预测，使用多模态输入，包括滞后价格、矢量化新闻和天气特征用于传统模型，以及为LLMs设计的提示工程结构化上下文。数据集为LLM评估生成了3.6k个多模态提示-输出对。

**Result:** 对于传统的统计和机器学习模型，新闻特征带来的收益微乎其微。对于GPT-4o和Gemini 1.5 Pro等最先进的LLMs，观察到性能有小幅提升，但它们也频繁产生幻觉，例如捏造和畸形的价格序列。

**Conclusion:** NSW-EPNews为多模态设置中的数值推理提供了一个严格的测试平台，并强调了当前LLM能力与高风险能源预测需求之间的关键差距。

> **ai_Abstract:** 本研究介绍了NSW-EPNews，一个新颖的基准数据集，旨在首次结合时间序列模型和大型语言模型（LLMs）进行电力价格预测。该数据集包含澳大利亚新南威尔士州的电力价格、温度数据和市场新闻摘要。研究将预测任务设定为48步超前预测，并为传统模型和LLMs设计了多模态输入。结果表明，新闻特征对传统模型的性能提升不显著，而LLMs虽然有小幅提升，但容易产生幻觉。NSW-EPNews提供了一个评估多模态下数值推理的测试平台，并揭示了当前LLM能力在高风险能源预测中的不足。

> **摘要翻译:** 电力价格预测是现代能源管理系统中的关键组成部分，然而现有方法严重依赖数值历史数据，并忽略了同期的文本信号。我们引入了NSW-EPNews，这是第一个联合评估时间序列模型和大型语言模型（LLMs）在真实世界电力价格预测上的基准。该数据集包含来自澳大利亚新南威尔士州（2015-2024年）超过175,000个半小时现货价格、每日温度读数以及来自WattClarity的精选市场新闻摘要。我们将任务设定为48步超前预测，使用多模态输入，包括滞后价格、用于经典模型的矢量化新闻和天气特征，以及为LLMs设计的提示工程结构化上下文。我们的数据集为LLM评估生成了3.6k个多模态提示-输出对，并使用了特定的模板。通过全面的基准设计，我们发现对于传统统计和机器学习模型，新闻特征带来的收益微乎其微。对于GPT-4o和Gemini 1.5 Pro等最先进的LLMs，我们观察到性能有小幅提升，但它们也频繁产生幻觉，例如捏造和畸形的价格序列。NSW-EPNews为多模态设置中的接地数值推理提供了一个严格的测试平台，并强调了当前LLM能力与高风险能源预测需求之间的关键差距。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [399] [ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention](https://arxiv.org/abs/2506.11052)
> *ACCORD：用于组合优化中路由和动态注意的自回归约束满足生成*

*Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 组合优化, NP-难问题, 自回归生成, 约束满足

**Comment:** 

> **TL;DR:** ACCORD是一个基于LLM的端到端框架，用于解决NP-难组合优化问题，通过新颖的数据表示和模型架构，在各种任务上优于现有方法。

**AI_Comments:** ACCORD的创新之处在于其新颖的数据表示和模型架构，能够将LLM的自回归特性与约束满足和动态注意力相结合，从而有效地解决NP-难组合优化问题。该工作填补了LLM在CPs应用方面的空白，并首次提出了一个大规模的端到端框架，其性能超越了现有方法，包括更大的LLMs，具有重要的研究价值和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）展现出强大的推理能力，但它们在NP-难组合问题（CPs）上的直接应用尚未得到充分探索。

**Method:** 本研究提出了ACCORD模型，它利用LLM的自回归特性，通过新颖的数据表示和模型架构，动态强制执行可行性约束，并结合基于注意力的路由来激活特定问题的LoRA模块。研究还推出了ACCORD-90k监督数据集，涵盖了六种NP-难组合问题：TSP、VRP、Knapsack、FlowShop、JSSP和BinPacking。

**Result:** 基于80亿参数Llama骨干的ACCORD模型，在广泛的实验中持续优于标准提示和输入-输出方法，甚至比更大的LLM（如GPT-4）表现更好。消融研究表明，其输出结构增强了解决方案的可行性。

**Conclusion:** ACCORD是首个大规模、端到端探索LLM在广泛组合优化问题中应用的方法，并显著提升了解决NP-难问题的能力。

> **ai_Abstract:** 本研究提出ACCORD，一个利用大型语言模型（LLMs）解决NP-难组合优化问题（CPs）的端到端框架。ACCORD引入了新颖的数据表示和模型架构，通过自回归生成和动态注意力机制来强制执行约束并激活问题特定模块。该模型在ACCORD-90k数据集（涵盖六种CPs）上进行训练，并实验证明其性能优于现有LLM方法，甚至超越了更大的模型，同时提高了解决方案的可行性。这是LLMs在组合优化领域应用的首个大规模探索。

> **摘要翻译:** 大型语言模型（LLMs）展示了令人印象深刻的推理能力，但它们在NP-难组合问题（CPs）上的直接应用仍未得到充分探索。在这项工作中，我们系统地研究了LLMs在各种NP-难组合优化任务上的推理能力，并引入了ACCORD：用于组合优化中路由和动态注意的自回归约束满足生成。ACCORD具有新颖的数据表示和模型架构，利用LLMs的自回归特性动态强制执行可行性约束，并结合基于注意力的路由来激活特定问题的LoRA模块。我们还提出了ACCORD-90k监督数据集，涵盖了六种NP-难组合问题：旅行商问题（TSP）、车辆路径问题（VRP）、背包问题（Knapsack）、流水车间调度问题（FlowShop）、作业车间调度问题（JSSP）和装箱问题（BinPacking）。广泛的实验表明，我们基于80亿参数Llama骨干构建的ACCORD模型，即使与GPT-4等更大的LLM相比，也始终优于标准提示和输入-输出方法。消融研究进一步表明，我们的输出结构增强了解决方案的可行性。据我们所知，这是第一个大规模、端到端的框架，用于探索LLMs在广泛组合优化问题中的应用。代码已在https://github.com/starjob42/ACCORD 公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data](https://arxiv.org/abs/2506.11053)
> *自举行为：一种新的用户行为序列数据预训练策略*

*Weichang Wu, Xiaolu Zhang, Jun Zhou, Yuchen Li, Wenwen Xia* | **Main category: cs.LG**

**Keywords:** 用户行为序列, 预训练, 自举学习, 自监督学习, 金融风控

**Comment:** 

> **TL;DR:** 本文提出了一种名为自举行为（BYB）的新型用户行为序列（UBS）预训练策略，通过自动构建监督嵌入来解决现有方法中手动选择行为词汇的局限性。BYB在实验中实现了AUC平均提升3.9%，训练吞吐量提升98.9%，并在实际部署中显著降低了数百万美元的坏账风险。

**AI_Comments:** 本文的主要创新在于提出了一种无需手动构建行为词汇的UBS预训练策略，通过自动化的监督嵌入构建解决了现有方法的痛点。其重要性体现在显著的性能提升（AUC和吞吐量）以及在实际工业应用中（如支付宝）带来的可量化经济效益，这表明该方法具有很高的实用价值和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的用户行为序列（UBS）预训练方法依赖于预测行为分布，其关键步骤是构建选定的行为词汇。然而，这个手动步骤劳动密集且容易产生偏差，并且词汇容量的限制直接影响模型的泛化能力。

**Method:** 本文引入了自举行为（Bootstrapping Your Behavior, BYB），这是一种新颖的UBS预训练策略，它通过预测一个自动构建的监督嵌入来总结未来时间窗口内所有行为的信息，从而消除了手动行为词汇选择。在实现中，该方法结合了学生-教师编码器方案以有效构建预训练监督。

**Result:** 在两个真实世界的工业数据集和八个下游任务上的实验表明，BYB在AUC上平均提高了3.9%，训练吞吐量提高了98.9%。值得注意的是，该模型在预训练期间表现出有意义的注意力模式和聚类表示，且无需任何标签监督。在两个多月的在线部署中，对于支付宝移动应用程序中的两项金融逾期风险预测任务，预训练模型比基线模型将KS提高了约2.7%和7.1%，为蚂蚁集团减少了数百万美元的坏账风险。

**Conclusion:** 自举行为（BYB）策略有效地解决了UBS预训练中手动词汇选择的局限性，带来了显著的性能提升和真实的财务效益，证明了其在工业应用中的重要性和有效性。

> **ai_Abstract:** 本文提出了一种名为“自举行为”（Bootstrapping Your Behavior, BYB）的新型预训练策略，用于用户行为序列（UBS）建模。与现有方法依赖手动且易偏的行为词汇构建不同，BYB通过自动构建涵盖未来行为信息的监督嵌入来消除这一手动过程。该方法采用学生-教师编码器方案，在两个工业数据集和八个下游任务上实现了AUC平均3.9%和训练吞吐量98.9%的显著提升。此外，在支付宝的在线部署中，BYB有效降低了金融逾期风险，为蚂蚁集团节省了数百万美元的坏账损失。

> **摘要翻译:** 用户行为序列（UBS）建模在工业应用中至关重要。随着数据规模和任务多样性的增长，UBS预训练方法变得越来越关键。最先进的UBS预训练方法依赖于预测行为分布。这些方法中的关键步骤是构建选定的行为词汇。然而，这个手动步骤劳动密集且容易产生偏差。词汇容量的限制也直接影响模型的泛化能力。在本文中，我们引入了自举行为（Bootstrapping Your Behavior, BYB），这是一种新颖的UBS预训练策略，它通过预测一个自动构建的监督嵌入来总结未来时间窗口内所有行为的信息，从而消除了手动行为词汇选择。在实现中，我们结合了学生-教师编码器方案以有效构建预训练监督。在两个真实世界的工业数据集和八个下游任务上的实验表明，BYB在AUC上平均提高了3.9%，训练吞吐量提高了98.9%。值得注意的是，该模型在预训练期间表现出有意义的注意力模式和聚类表示，且无需任何标签监督。在我们两个多月的在线部署中，对于支付宝移动应用程序中的两项金融逾期风险预测任务，预训练模型比基线模型将KS提高了约2.7%和7.1%，这为蚂蚁集团减少了数百万美元的坏账风险。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments](https://arxiv.org/abs/2506.11054)
> *物联网环境中机器学习即服务(MLaaS)的自适应组合*

*Deepak Kanneganti, Sajib Mistry, Sheik Mohammad Mostakim Fattah, Aneesh Krishna, Monowar Bhuyan* | **Main category: cs.LG**

**Keywords:** MLaaS, IoT, 自适应组合, 上下文多臂老虎机, 服务质量

**Comment:** 

> **TL;DR:** 本文提出一个自适应MLaaS组合框架，用于动态IoT环境，通过上下文多臂老虎机优化策略持续适应和优化MLaaS组合，以保持服务质量并降低计算成本。

**AI_Comments:** 该论文提出了一种创新的自适应方法来解决MLaaS在动态IoT环境中的长期有效性问题。其核心创新在于引入了上下文多臂老虎机优化策略进行MLaaS组合的增量更新，这有效平衡了服务质量和计算成本，为动态服务组合提供了一个高效且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 物联网（IoT）环境的动态性导致数据分布波动（如概念漂移、数据异构性）和系统需求演变（如可伸缩性需求、资源限制），这些因素挑战了机器学习即服务（MLaaS）组合的长期有效性。

**Method:** 本文提出了一个自适应MLaaS组合框架。该框架包含一个服务评估模型，用于识别性能不佳的MLaaS服务；一个候选选择模型，用于筛选最优替代品；以及一个自适应组合机制，该机制利用上下文多臂老虎机优化策略来增量更新MLaaS组合。

**Result:** 在真实世界数据集上的实验结果证明了所提出方法的效率。

**Conclusion:** 该方法通过持续适应不断变化的IoT约束，能够在降低与从头开始重组相关的计算成本的同时，保持服务质量（QoS）。

> **ai_Abstract:** 本文提出了一种自适应MLaaS组合框架，旨在解决动态IoT环境中MLaaS组合的长期有效性问题。该框架通过整合服务评估模型、候选选择模型以及基于上下文多臂老虎机优化策略的自适应组合机制，能够持续适应IoT环境的变化，从而在保持服务质量（QoS）的同时，显著降低了重组的计算成本。实验结果验证了该方法的效率。

> **摘要翻译:** 物联网（IoT）环境的动态性挑战了机器学习即服务（MLaaS）组合的长期有效性。物联网环境的不确定性和可变性导致数据分布波动，例如概念漂移和数据异构性，以及不断演变的系统需求，例如可伸缩性需求和资源限制。本文提出了一种自适应MLaaS组合框架，以确保无缝、高效和可伸缩的MLaaS组合。该框架集成了服务评估模型以识别性能不佳的MLaaS服务，以及候选选择模型以过滤最佳替代品。开发了一种自适应组合机制，使用上下文多臂老虎机优化策略增量更新MLaaS组合。通过持续适应不断变化的IoT约束，该方法在降低与从头开始重组相关的计算成本的同时，保持了服务质量（QoS）。在真实世界数据集上的实验结果证明了我们提出方法的效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [PolyMicros: Bootstrapping a Foundation Model for Polycrystalline Material Structure](https://arxiv.org/abs/2506.11055)
> *PolyMicros：为多晶材料结构引导基础模型*

*Michael Buzzy, Andreas Robertson, Peng Chen, Surya Kalidindi* | **Main category: cs.LG**

**Keywords:** 多晶材料, 基础模型, 数据增强, 零样本学习, 材料科学

**Comment:** 43 Pages, 19 figures

> **TL;DR:** 针对材料科学中多晶材料数据稀疏的挑战，本文提出一种物理驱动的数据增强方法PolyMicros，能从少量数据生成大规模数据集，并成功构建首个多晶材料基础模型，解决了3D显微镜的长期难题。

**AI_Comments:** 该论文的创新点在于提出了一个针对超稀疏、复杂科学数据的物理驱动数据增强方案，有效解决了多晶材料领域数据量稀缺的难题。通过此方法成功构建了首个多晶材料基础模型PolyMicros，填补了该领域的空白。其重要性体现在能够加速新材料的发现和设计，尤其是在数据获取成本高昂的结构和功能材料领域。开源模型和数据集也促进了社区的进一步研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的材料科学基础模型需要大量数据，但许多结构和功能材料（如中尺度结构金属合金）的数据集难以构建且样本极少，限制了这些模型在这些领域的应用。

**Method:** 提出一种新颖的机器学习方法，用于从超稀疏、复杂的科学领域空间数据中学习。核心贡献是一个物理驱动的数据增强方案，该方案利用少量（低至五个）实验观测训练的局部生成模型集合，并通过新颖的多样性策展策略进行协调，以生成大规模、物理多样的数据集。利用此框架构建了PolyMicros。

**Result:** 成功构建了PolyMicros，这是第一个用于多晶材料的基础模型。通过零样本学习解决了与加速3D实验显微镜相关的几个长期挑战。

**Conclusion:** PolyMicros是首个针对多晶材料的基础模型，通过创新的数据增强方案有效解决了数据稀疏问题，并在3D实验显微镜应用中展现出实用性。作者还开源了模型和数据集。

> **ai_Abstract:** 该论文针对材料科学中多晶材料数据稀疏的挑战，提出了一种名为PolyMicros的新型基础模型。其核心方法是物理驱动的数据增强方案，通过集合多个局部生成模型和多样性策展策略，能够从极少量（低至5个）的实验观测数据中生成大规模、物理多样的数据集。PolyMicros是首个专为多晶材料设计的基础模型，并在加速3D实验显微镜的零样本任务中展现了其有效性。研究团队已将模型和数据集开源。

> **摘要翻译:** 材料科学基础模型的最新进展有望彻底改变具有定制性质和响应的新材料的发现、制造和设计。尽管取得了巨大进步，但成功仅限于可以轻松整理出数百万样本数据存储库的材料类别（例如，原子结构）。不幸的是，对于许多结构和功能材料（例如，中尺度结构金属合金），此类数据集的构建成本过高或受到限制；相反，数据集仅限于极少数示例。为了解决这一挑战，我们引入了一种新颖的机器学习方法，用于从科学领域中超稀疏、复杂的空间数据中学习。我们的核心贡献是一个物理驱动的数据增强方案，该方案利用少量（低至五个）实验观测训练的局部生成模型集合，并通过新颖的多样性策展策略进行协调，以生成大规模、物理多样的数据集。我们利用此框架构建了PolyMicros，这是第一个用于多晶材料的基础模型（多晶材料是一种在广泛工业和科学应用中都很重要的结构材料类别）。我们通过零样本解决与加速3D实验显微镜相关的几个长期挑战，展示了PolyMicros的实用性。最后，我们将模型和数据集都开放给社区。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [414] [xInv: Explainable Optimization of Inverse Problems](https://arxiv.org/abs/2506.11056)
> *xInv：逆问题的可解释优化*

*Sean Memery, Kevin Denamganai, Anna Kapron-King, Kartic Subr* | **Main category: cs.LG**

**Keywords:** 逆问题, 可解释性, 优化, 可微分模拟器, 语言模型

**Comment:** 

> **TL;DR:** 本文提出了一种解释逆问题迭代优化过程的方法，通过可微分模拟器在正向和反向传播中生成自然语言事件，并利用语言模型进行解释，使领域专家能够理解。

**AI_Comments:** 该论文的创新点在于将可解释性引入到长期以来对领域专家不透明的逆问题迭代优化过程中。通过结合可微分模拟器和大型语言模型，它提供了一种新颖的途径，将复杂的优化轨迹转化为人类可理解的叙述，这对于提高逆问题在实际应用中的可信度和采纳度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管正向模型的可解释性已取得显著进展，但逆问题的迭代优化过程对领域专家来说仍然难以理解，而逆问题在医疗、气候科学和农业等广泛领域中至关重要。

**Method:** 该方法的核心思想是：对可微分模拟器进行改造，使其在正向和反向传播过程中发出自然语言事件。随后，利用语言模型从这些事件列表中生成解释。

**Result:** 该方法通过一个说明性优化问题和一个涉及神经网络训练的例子，证明了其有效性。

**Conclusion:** 该方法在说明性优化问题和神经网络训练示例中展示了其有效性，解决了逆问题优化过程对领域专家而言不透明的问题。

> **ai_Abstract:** 本文提出xInv，一种针对逆问题迭代优化过程的可解释方法。鉴于逆问题在多领域的重要性及其优化过程对领域专家而言的“黑箱”特性，该方法通过改造可微分模拟器使其在正向和反向传播中生成自然语言事件，并结合语言模型对这些事件进行后处理，从而生成人类可理解的解释。实验通过一个优化问题和神经网络训练案例验证了该方法的有效性。

> **摘要翻译:** 逆问题在医疗保健、气候科学和农业等广泛领域中居于核心地位。它们通常涉及通过迭代优化来估计某些已知正向模型的输入，以使其产生期望的结果。尽管正向模型的可解释性和可解释性取得了相当大的发展，但逆问题的迭代优化过程对领域专家来说仍然在很大程度上是神秘的。我们提出了一种方法，可以从优化器产生的痕迹中生成解释，这些解释在领域抽象层面是人类可解释的。我们方法的核心思想是改造一个可微分模拟器，使其在正向和反向传播过程中发出自然语言事件。在后处理中，我们使用语言模型从事件列表中创建解释。我们通过一个说明性优化问题和一个涉及神经网络训练的例子证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [417] [STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization](https://arxiv.org/abs/2506.11057)
> *STRCMP：将图结构先验与语言模型相结合用于组合优化*

*Xijun Li, Jiexiang Yang, Jinghao Wang, Bo Peng, Jianguo Yao, Haibing Guan* | **Main category: cs.LG**

**Keywords:** 组合优化, 大型语言模型, 图神经网络, 结构先验, 算法发现

**Comment:** 

> **TL;DR:** STRCMP是一个新颖的框架，它将图结构先验与语言模型相结合，以更有效地解决组合优化问题，通过结合图神经网络提取结构嵌入来指导大型语言模型生成高性能算法代码，并在多种基准测试中显著优于现有方法。

**AI_Comments:** 该论文的创新点在于系统地将图结构先验（这是当前大型语言模型常忽略的关键信息）整合到组合优化问题的算法发现过程中。这解决了现有LLM方法的一个主要局限性，并借鉴了人类专家利用结构知识的成功经验。其复合架构设计确保了生成代码的正确性和解决问题的效率，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 组合优化（CO）问题由于其NP-难性质，带来了显著的计算挑战。现有的大型语言模型（LLMs）解决CO问题的方法往往忽略了问题固有的关键结构先验，导致次优解和迭代效率低下。本文受人类专家利用CO结构进行算法设计的启发。

**Method:** 本文提出了STRCMP，一个新颖的、结构感知的基于LLM的算法发现框架。它系统地整合了结构先验，以提高解决方案质量和求解效率。该框架结合了图神经网络（GNN）用于从CO实例中提取结构嵌入，并使用LLM基于这些嵌入来识别高性能算法（以求解器特定代码的形式）。这种复合架构确保了语法正确性、保留了问题拓扑并与自然语言目标对齐，同时通过进化优化过程迭代地优化生成的算法。

**Result:** 在混合整数线性规划和布尔可满足性问题上，使用九个基准数据集进行的广泛评估表明，STRCMP在解决方案最优性和计算效率方面，以显著优势超越了五种强大的神经和基于LLM的方法。

**Conclusion:** STRCMP成功地将图结构先验与语言模型相结合，用于组合优化，在解决方案质量和计算效率方面均优于现有方法。

> **ai_Abstract:** STRCMP是一个创新的框架，旨在通过将图结构先验集成到大型语言模型中来解决计算密集型组合优化（CO）问题。该方法利用图神经网络（GNN）提取CO实例的结构嵌入，并以此作为条件指导LLM生成高性能的求解器特定代码。通过结合结构感知设计和进化优化过程，STRCMP解决了现有LLM方法在处理CO问题时忽视结构信息导致的效率和质量问题。实验结果表明，STRCMP在多种CO基准测试中，其解决方案的最优性和计算效率均显著优于其他主流神经和LLM方法。

> **摘要翻译:** 组合优化（CO）问题是运筹学和理论计算机科学的核心，由于其NP-难性质，带来了显著的计算挑战。虽然大型语言模型（LLMs）已成为CO领域有前景的工具——无论是直接生成解决方案还是合成特定于求解器的代码——现有方法往往忽略了CO问题固有的关键结构先验，导致次优解和迭代效率低下。受人类专家成功利用CO结构进行算法设计的启发，我们提出了STRCMP，一个新颖的、结构感知的基于LLM的算法发现框架，它系统地整合了结构先验，以提高解决方案质量和求解效率。我们的框架结合了图神经网络（GNN）用于从CO实例中提取结构嵌入，并使用LLM基于这些嵌入来识别高性能算法（以求解器特定代码的形式）。这种复合架构确保了语法正确性、保留了问题拓扑并与自然语言目标对齐，同时通过进化优化过程迭代地优化生成的算法。在混合整数线性规划和布尔可满足性问题上，使用九个基准数据集进行的广泛评估表明，我们提出的STRCMP在解决方案最优性和计算效率方面，以显著优势超越了五种强大的神经和基于LLM的方法。代码和学习模型将在论文接受后公开发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [420] [ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models](https://arxiv.org/abs/2506.11087)
> *ADAMIX：面向大型语言模型的自适应混合精度增量压缩与量化误差优化*

*Boya Xiong, Shuo Wang, Weifeng Ge, Guanhua Chen, Yun Chen* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 增量压缩, 混合精度, 量化误差优化, 比特分配

**Comment:** 

> **TL;DR:** ADAMIX提出了一种自适应混合精度增量压缩框架，通过优化量化误差，显著提升了大型语言模型在特定任务上的压缩性能。

**AI_Comments:** ADAMIX的创新之处在于其理论驱动的混合精度比特分配策略，通过将量化误差优化问题转化为0/1整数线性规划，克服了传统经验分配的局限性，从而在高压缩比下仍能保持甚至提升模型性能。这对于LLM在多租户环境中的高效部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有增量压缩方法在高压缩比下表现不佳，或者依赖于经验性的比特分配方案。

**Method:** 提出了ADAMIX框架，通过数学推导量化误差来指导混合精度压缩策略，并将最优混合精度比特分配方案公式化为0/1整数线性规划问题，以在满足压缩比要求的同时最小化量化误差。

**Result:** 在各种模型和基准测试上，ADAMIX显著超越了最佳基线。在AIME2024和GQA等任务中，对于7B模型，ADAMIX分别比最佳基线Delta-CoMe高出22.3%和6.1%。

**Conclusion:** ADAMIX通过其自适应混合精度和量化误差优化策略，有效解决了大型语言模型增量压缩中性能下降和经验比特分配的问题，显著提升了压缩效率和模型性能。

> **ai_Abstract:** 本文提出了ADAMIX，一种自适应混合精度增量压缩框架，旨在解决大型语言模型增量压缩中现有方法性能不佳或依赖经验比特分配的问题。ADAMIX通过数学推导量化误差，将最优比特分配问题建模为0/1整数线性规划，以最小化量化误差并满足压缩比。实验证明，ADAMIX在多个任务上显著优于现有最佳基线。

> **摘要翻译:** 大型语言模型（LLMs）在不同领域的各种知识密集型和复杂推理任务中取得了令人印象深刻的性能。在多租户服务等特定场景中，部署了大量从相同基础模型微调而来的LLM，以满足用户复杂的需求。最近的工作探索了增量压缩方法来量化和压缩定制LLM与相应基础模型之间的增量参数。然而，现有工作在高压缩比下表现不佳，或者依赖于经验性的比特分配方案。在这项工作中，我们提出了ADAMIX，一个有效的自适应混合精度增量压缩框架。我们提供了量化误差的数学推导，以激发我们的混合精度压缩策略，并将最优混合精度比特分配方案公式化为0/1整数线性规划问题的解。我们推导出的比特分配策略在满足预定义压缩比要求的同时最小化量化误差。在各种模型和基准测试上的实验结果表明，我们的方法显著超越了最佳基线。在AIME2024和GQA等任务中，当$\Delta \mathbf{W}$的范数较大且基础模型能力不足时，对于7B模型，ADAMIX分别比最佳基线Delta-CoMe高出22.3%和6.1%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [423] [Debiasing Online Preference Learning via Preference Feature Preservation](https://arxiv.org/abs/2506.11098)
> *通过偏好特征保留来消除在线偏好学习中的偏差*

*Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim* | **Main category: cs.LG**

**Keywords:** 偏好学习, 大型语言模型, 偏见消除, 特征保留, 在线学习

**Comment:** 20 page, 20 figures

> **TL;DR:** PFP框架通过保留人类偏好特征的分布，成功减轻了大型语言模型在线偏好学习中的偏见，并在LLM对齐基准测试中表现优异。

**AI_Comments:** PFP框架的创新之处在于其通过“偏好特征保留”来解决LLM偏好学习中的偏差问题，这超越了简单二元比较和标量奖励的局限。通过维护和利用人类偏好特征的丰富信号，该方法有望使LLMs的响应更加全面和无偏。其重要性体现在提升LLM的对齐性能和减轻在线学习中的偏见，为未来LLM训练提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型偏好学习框架通过二进制成对比较和标量奖励简化了人类偏好，这可能导致LLM的响应偏向于主要偏好的特征，并且这种偏见在在线偏好学习的迭代过程中会加剧。

**Method:** 本文提出了PFP（Preference Feature Preservation）框架。PFP首先从离线成对人类偏好数据中提取偏好特征并训练一个特征分类器。然后，在在线学习过程中，PFP利用训练好的分类器和分布保留优化，为新的输入指令映射适当的偏好特征。最后，PFP通过将偏好特征整合到系统提示中，并使LLM能够明确处理各种人类偏好，使用现有偏好学习方法训练LLM。

**Result:** 实验表明，PFP成功减轻了在线学习中偏好特征的偏差，因此在评估LLM对齐的标准基准测试上，与以前的偏好学习方法相比，取得了卓越的性能。

**Conclusion:** PFP框架通过保留人类偏好特征的分布，有效解决了在线偏好学习中大型语言模型响应偏向性问题，并在LLM对齐任务上取得了显著改进。

> **ai_Abstract:** 本文提出了一种名为PFP（Preference Feature Preservation）的新框架，旨在解决大型语言模型（LLMs）在线偏好学习中因简化人类偏好而导致的响应偏差问题。PFP通过提取和保留人类偏好特征的分布，并在在线学习过程中利用这些特征，从而减轻偏见。具体而言，PFP训练一个特征分类器，然后将适当的偏好特征映射到新的输入指令，并通过将这些特征整合到系统提示中来训练LLM。实验结果表明，PFP成功缓解了在线学习中的偏好特征偏差，并在LLM对齐基准测试上优于现有方法。

> **摘要翻译:** 最近针对大型语言模型（LLMs）的偏好学习框架通过二元成对比较和标量奖励简化了人类偏好。这种简化可能使LLMs的响应偏向于主要偏好的特征，并且在在线偏好学习步骤的迭代过程中会加剧。为了解决这些挑战，我们提出了一个新颖的框架，命名为PFP（Preference Feature Preservation）。PFP的关键思想是保持人类偏好特征的分布，并在整个在线偏好学习过程中利用这些丰富的信号。具体来说，PFP首先从离线成对人类偏好数据中提取偏好特征并训练一个特征分类器。然后，利用训练好的分类器和分布保留优化，PFP在在线学习期间为新的输入指令映射适当的偏好特征。最后，PFP通过将偏好特征整合到系统提示中，并使LLM能够明确处理各种人类偏好，使用现有偏好学习方法训练LLM。我们的实验表明，PFP成功减轻了在线学习中偏好特征的偏差，因此在评估LLM对齐的标准基准测试上，与以前的偏好学习方法相比，取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [426] [Knowledge Graph Embeddings with Representing Relations as Annular Sectors](https://arxiv.org/abs/2506.11099)
> *知识图谱嵌入：用环扇区表示关系*

*Huiling Zhu, Yingqi Zeng* | **Main category: cs.LG**

**Keywords:** 知识图谱嵌入, 环扇区, 语义层次, 极坐标, 链接预测

**Comment:** 

> **TL;DR:** SectorE是一种新的知识图谱嵌入模型，它在极坐标系中将关系建模为环扇区，实体建模为点，以捕获语义层次结构，并在多个数据集上取得了有竞争力的性能。

**AI_Comments:** SectorE的创新之处在于其独特的关系和实体表示方式，即在极坐标系中使用环扇区表示关系，点表示实体，这提供了一种新颖且直观的方式来捕获知识图谱中的语义层次结构。这种方法为知识图谱嵌入领域带来了新的视角，尤其是在处理复杂关系和实体结构方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于区域的知识图谱嵌入模型在知识图谱补全任务中常常忽略实体中固有的语义层次结构。

**Method:** 本文提出了SectorE，一个在极坐标系下的新型嵌入模型。该模型将关系建模为环形扇区，结合模数和相位来捕获推理模式和关系属性。实体则被嵌入为这些扇区内的点，以直观地编码层次结构。

**Result:** SectorE在FB15k-237、WN18RR和YAGO3-10数据集上进行了评估，与各种模型相比，取得了有竞争力的性能，并展示了其在语义建模能力上的优势。

**Conclusion:** SectorE模型通过在极坐标系中将关系表示为环形扇区，实体表示为点，有效捕获了知识图谱中的语义层次结构，并在知识图谱补全任务中表现出色。

> **ai_Abstract:** 本文提出了一种名为SectorE的新型知识图谱嵌入模型，旨在解决现有模型忽视实体语义层次结构的问题。SectorE在极坐标系中将关系表示为环形扇区，实体表示为扇区内的点，从而有效地编码了层次信息。实验结果表明，SectorE在多个基准数据集上表现出有竞争力的性能，验证了其在语义建模方面的能力。

> **摘要翻译:** 知识图谱（KGs）以实体和关系的多关系数据形式构建，对于数据分析和推荐系统等任务至关重要。知识图谱补全（KGC），也称为链接预测，通过推断缺失的三元组（h, r, t）来解决知识图谱的不完整性。这对于下游应用至关重要。基于区域的嵌入模型通常将实体嵌入为点，将关系嵌入为几何区域来完成任务。尽管取得了进展，但这些模型常常忽视实体中固有的语义层次结构。为了解决这个问题，我们提出了SectorE，一个在极坐标系下的新型嵌入模型。关系被建模为环形扇区，结合模数和相位来捕获推理模式和关系属性。实体被嵌入为这些扇区内的点，直观地编码了层次结构。在FB15k-237、WN18RR和YAGO3-10数据集上进行评估，SectorE与各种模型相比，取得了有竞争力的性能，展示了其在语义建模能力上的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation](https://arxiv.org/abs/2506.11170)
> *PromptTSS：一种基于提示的交互式多粒度时间序列分割方法*

*Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen* | **Main category: cs.LG**

**Keywords:** 时间序列分割, 多粒度, 提示学习, 动态适应, 统一模型

**Comment:** This paper is currently under review. The code will be made available
  upon acceptance

> **TL;DR:** PromptTSS是一种新颖的时间序列分割框架，通过统一模型和提示机制解决多粒度状态处理及动态环境适应性问题，并在多粒度、单粒度分割和迁移学习方面表现出显著的准确性提升。

**AI_Comments:** PromptTSS的创新点在于引入了提示机制来处理多粒度时间序列分割，这使得模型能够在一个统一框架下同时捕获粗粒度和细粒度模式。其对动态和未见模式的强大适应性，尤其是在迁移学习中的巨大提升，是其重要优势。这对于实际应用中不断演变的时间序列数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间序列分割方法面临两大挑战：一是无法在统一模型中处理多个粒度级别，二是适应动态环境中新的、演变模式的能力有限。

**Method:** PromptTSS提出了一种新颖的、基于提示机制的统一模型框架，利用标签和边界信息来指导分割，从而捕获粗粒度和细粒度模式，并能动态适应未见模式。

**Result:** 实验表明，PromptTSS在多粒度分割中将准确率提高了24.49%，在单粒度分割中提高了17.88%，在迁移学习中最高提高了599.24%。这证明了它对分层状态和演变时间序列动态的适应性。

**Conclusion:** PromptTSS通过其统一的提示机制，成功解决了多粒度时间序列分割的挑战，显著提升了分割准确性和对动态环境的适应性。

> **ai_Abstract:** 本文提出了PromptTSS，一个用于多粒度时间序列分割的新框架。它通过一个统一模型和提示机制，利用标签和边界信息来处理时间序列数据中存在的粗粒度和细粒度状态。该方法旨在克服现有分割方法在多粒度处理和动态环境适应性方面的局限性。实验结果验证了PromptTSS在多粒度、单粒度分割以及迁移学习任务上的显著性能提升和强大的适应能力。

> **摘要翻译:** 多元时间序列数据，收集自制造业和可穿戴技术等各种领域，在多个粒度级别上展现状态，从粗粒度的系统行为到细粒度的详细事件。有效地分割和整合这些不同粒度级别上的状态对于预测性维护和性能优化等任务至关重要。然而，现有时间序列分割方法面临两个关键挑战：(1) 无法在统一模型中处理多个粒度级别，以及 (2) 对动态环境中新的、演变模式的适应性有限。为了解决这些挑战，我们提出了PromptTSS，一个用于多粒度状态时间序列分割的新颖框架。PromptTSS使用一个带有提示机制的统一模型，该机制利用标签和边界信息来指导分割，捕获粗粒度和细粒度模式，同时动态适应未见模式。实验表明，PromptTSS在多粒度分割中将准确率提高了24.49%，在单粒度分割中提高了17.88%，在迁移学习中最高提高了599.24%，这证明了它对分层状态和演变时间序列动态的适应性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [436] [Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning](https://arxiv.org/abs/2506.11172)
> *离线强化学习中通过投毒攻击破坏序列级数据策略覆盖*

*Xue Zhou, Dapeng Man, Chen Xu, Fanyi Zeng, Tao Liu, Huan Wang, Shucheng He, Chaoyang Gao, Wu Yang* | **Main category: cs.LG**

**Keywords:** 离线强化学习, 投毒攻击, 数据策略覆盖, 序列级, 分布偏移

**Comment:** 

> **TL;DR:** 该论文提出了一种在离线强化学习中通过投毒攻击（CSDPC）破坏序列级数据覆盖的方法，仅通过少量数据投毒就能显著降低智能体性能。

**AI_Comments:** 该论文的创新之处在于将离线强化学习的安全分析焦点从单步转移到序列级数据策略覆盖。所提出的CSDPC攻击展示了一种以最小数据扰动显著降低性能的高效方法，这对理解和缓解离线强化学习系统中的漏洞具有重要意义。这项工作强调了预收集数据集中数据完整性对于离线强化学习的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有离线强化学习研究旨在改善数据策略覆盖以减轻分布偏移，但忽略了覆盖不足带来的安全风险，并且单步分析与离线强化学习的多步决策性质不符。本文旨在解决这些安全风险，特别是关注序列级覆盖。

**Method:** 引入序列级集中度系数来量化覆盖，并通过理论分析揭示其对估计误差上限的指数放大作用。在此基础上，提出了崩溃序列级数据策略覆盖（CSDPC）投毒攻击。该方法将状态-动作对转换为决策单元，提取代表性的多步决策模式，识别并投毒可能导致覆盖不足的稀有模式，从而降低覆盖并加剧分布偏移。

**Result:** 实验表明，仅投毒1%的数据集就可以使智能体性能下降90%。

**Conclusion:** 这一发现为分析和保障离线强化学习的安全性提供了新的视角。

> **ai_Abstract:** 本文针对离线强化学习中被忽视的、源于数据策略覆盖不足的安全风险，特别是考虑到其多步决策性质，提出了解决方案。论文引入了序列级集中度系数来量化覆盖，并从理论上证明了其对估计误差的影响。在此基础上，作者提出了崩溃序列级数据策略覆盖（CSDPC）投毒攻击，该攻击将状态-动作对转换为决策单元，以识别并投毒稀有的多步决策模式。实验证明，仅对数据集进行1%的投毒就能使智能体性能急剧下降90%，这揭示了一个关键的漏洞，并为离线强化学习的安全性提供了新见解。

> **摘要翻译:** 离线强化学习（RL）严重依赖于预收集数据对目标策略分布的覆盖。现有研究旨在改善数据策略覆盖以减轻分布偏移，但忽略了覆盖不足带来的安全风险，并且单步分析与离线RL的多步决策性质不符。为了解决这个问题，我们引入了序列级集中度系数来量化覆盖，并通过理论分析揭示了其对估计误差上限的指数放大作用。在此基础上，我们提出了崩溃序列级数据策略覆盖（CSDPC）投毒攻击。考虑到离线RL数据的连续性，我们将状态-动作对转换为决策单元，并提取捕获多步行为的代表性决策模式。我们识别了可能导致覆盖不足的稀有模式，并对其进行投毒以降低覆盖并加剧分布偏移。实验表明，仅投毒1%的数据集就可以使智能体性能下降90%。这一发现为分析和保障离线RL的安全性提供了新的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [440] [Detection of obstructions in oil and gas pipelines: machine learning techniques for hydrate classification](https://arxiv.org/abs/2506.11220)
> *油气管道堵塞检测：用于水合物分类的机器学习技术*

*Hellockston Gomes de Brito, Carla Wilza Souza de Paula Maitelli, Osvaldo Chiavone-Filho* | **Main category: cs.LG**

**Keywords:** 水合物分类, 机器学习, 管道堵塞, 决策树, 油气

**Comment:** 

> **TL;DR:** 本研究利用机器学习技术（决策树、k-NN、朴素贝叶斯）有效检测油气管道中的水合物形成，其中决策树表现最佳（99.99%准确率）。

**AI_Comments:** 该论文将机器学习应用于油气行业的一个关键实际问题，即水合物堵塞检测。决策树高达99.99%的准确率非常引人注目，表明其在实际部署中进行实时检测的潜力。利用公开数据集也增强了研究的可重复性。

<details>
  <summary>Details</summary>

**Motivation:** 油气管道中的堵塞问题，特别是天然气水合物的形成，严重影响流体运输效率和生产操作。本研究旨在通过自动化检测来解决这些流量保障挑战。

**Method:** 采用监督机器学习技术，包括决策树、k-近邻（k-NN）算法和朴素贝叶斯分类器。数据来源于巴西国家石油公司（Petrobras）公开的3W项目GitHub存储库，并进行了预处理和清洗。分类任务使用scikit-learn Python库完成。

**Result:** 所提出的方法能有效分类操作条件下的水合物形成。其中，决策树算法表现出最高的预测准确率，达到99.99%。

**Conclusion:** 该方法为优化生产效率提供了一种可靠的解决方案，通过有效预防天然气水合物的形成来缓解油气管道堵塞问题。

> **ai_Abstract:** 本研究旨在通过应用监督机器学习技术（决策树、k-NN和朴素贝叶斯分类器）来解决油气管道中由水合物形成引起的堵塞问题。研究利用来自Petrobras 3W项目的数据集进行训练，并使用scikit-learn进行分类。结果显示，该方法能有效识别水合物形成，其中决策树算法表现出最高的预测准确率（99.99%），从而为优化油气生产效率提供可靠方案。

> **摘要翻译:** 石油和天然气储备是全球经济的重要资源，是交通、能源生产和工业过程的关键组成部分。然而，石油和天然气开采和生产作业可能会遇到一些挑战，例如由沉积物堆积、蜡沉积、矿物结垢和腐蚀等因素引起的管道和生产线堵塞。本研究通过采用监督机器学习技术，特别是决策树、k-近邻（k-NN）算法和朴素贝叶斯分类器方法，来解决这些挑战，以检测和缓解流量保障问题，确保流体高效运输。主要重点是防止油气生产系统中天然气水合物的形成。为此，对数据集进行了数据预处理和清洗，以确保其质量和一致性，该数据集来源于巴西国家石油公司在GitHub上公开的3W项目存储库。scikit-learn Python库，一个广泛认可的用于监督机器学习技术的开源工具，因其鲁棒性和多功能性而被用于分类任务。结果表明，所提出的方法在操作条件下有效分类水合物形成，其中决策树算法表现出最高的预测准确率（99.99%）。因此，这种方法为优化生产效率提供了一种可靠的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [445] [A Causal Lens for Learning Long-term Fair Policies](https://arxiv.org/abs/2506.11242)
> *一种学习长期公平策略的因果视角*

*Jacob Lear, Lu Zhang* | **Main category: cs.LG**

**Keywords:** 长期公平性, 因果推断, 强化学习, 效益公平, 动态系统

**Comment:** This is an extension to the paper which was accepted to the 13th
  International Conference on Learning Representations

> **TL;DR:** 本文提出一个在强化学习背景下衡量长期公平性的通用框架，并通过因果视角分解其指标，旨在解决动态决策系统中长期公平性问题，并平衡各种公平概念。

**AI_Comments:** 本文创新性地将因果推断引入长期公平性研究，并通过分解指标的方式，深入理解了策略对资格增益的复杂影响。其提出的框架和方法对于在动态、持续学习系统中实现更全面的公平性具有重要意义，超越了传统对即时偏差的关注。方法的简单有效性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大多数关于公平感知学习的研究集中于静态环境中的即时偏差，但本文强调了在动态决策系统中调查长期公平性的重要性，同时考虑瞬时公平性要求。

**Method:** 本文提出了一个通用框架，在强化学习背景下，通过衡量不同群体个体可能获得的平均预期资格增益的差异来衡量长期公平性。然后，通过因果视角，将此指标分解为代表策略对资格增益的直接影响、延迟影响以及虚假效应的三个组成部分。最后，开发了一种简单而有效的方法来平衡各种公平概念。

**Result:** 本文将长期公平性指标分解为直接影响、延迟影响和虚假效应三个组成部分，并分析了这些组成部分与新兴的效益公平概念之间的内在联系，并开发出一种简单而有效的方法来平衡各种公平概念。

**Conclusion:** 本文提出了一个衡量和分解强化学习中长期公平性的框架，并通过因果视角分析了其组成部分与效益公平的联系，并开发了一种平衡多种公平概念的有效方法。

> **ai_Abstract:** 本文关注动态决策系统中长期公平性的重要性，提出一个在强化学习背景下衡量长期公平性的通用框架。该框架通过不同群体预期资格增益的差异来衡量长期公平，并利用因果视角将其分解为直接影响、延迟影响和虚假效应。研究分析了这些组件与效益公平的关联，并开发了一种平衡多种公平概念的有效方法。

> **摘要翻译:** 公平感知学习研究旨在开发算法，以避免尽管训练数据存在偏差但仍能产生歧视性决策结果。虽然大多数研究集中于静态环境中的即时偏差，但本文强调了在动态决策系统中调查长期公平性的重要性，同时考虑瞬时公平性要求。在强化学习的背景下，我们提出了一个通用框架，其中长期公平性通过不同群体个体可能获得的平均预期资格增益的差异来衡量。然后，通过因果视角，我们将此指标分解为代表策略对资格增益的直接影响、延迟影响以及虚假效应的三个组成部分。我们分析了这些组成部分与一种新兴的公平概念——效益公平（旨在控制决策结果的公平性）之间的内在联系。最后，我们开发了一种简单而有效的方法来平衡各种公平概念。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [Sampling Imbalanced Data with Multi-objective Bilevel Optimization](https://arxiv.org/abs/2506.11315)
> *使用多目标双层优化对不平衡数据进行采样*

*Karen Medlin, Sven Leyffer, Krishnan Raghavan* | **Main category: cs.LG**

**Keywords:** 不平衡数据采样, 多目标优化, 双层优化, 数据多样性, MOODS

**Comment:** 

> **TL;DR:** 本文提出了MOODS，一个多目标双层优化框架，用于指导合成过采样和多数欠采样，并引入了一个新的验证指标来量化采样方法对模型性能的影响，实验证明其在不平衡数据分类上达到了最先进的性能。

**AI_Comments:** 本文的主要创新在于提出了一个结合多目标双层优化和新型多样性度量的采样框架。通过明确考虑数据多样性，它克服了传统重采样方法在处理不平衡数据时易导致过拟合的局限性。引入的“$\epsilon/\delta$ 非重叠多样性指标”是一个关键贡献，它为评估采样效果提供了一个量化标准，使得优化过程更加有效和可衡量。这对于提升不平衡数据集上的模型泛化能力和少数类分类性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的处理不平衡数据的方法（如重新加权损失函数或朴素重采样）存在过拟合风险，并且未能考虑多数和少数数据集之间的多样性。由于缺乏衡量不平衡对模型影响的指标，导致这些方法无法有效提升分类性能，尤其是在少数类别的分类上表现不佳。

**Method:** 本文提出了MOODS（Multi-Objective Optimization for Data Sampling），一个新颖的多目标双层优化框架，用于指导合成过采样和多数欠采样。同时，引入了一个新的验证指标——“$\epsilon/\delta$ 非重叠多样性指标”，用于量化采样方法对模型性能的优劣。

**Result:** 通过引入新的多样性指标，实验证明所提出的方法达到了最先进的性能，F1分数提高了1-15%。

**Conclusion:** 所提出的MOODS多目标双层优化框架结合新的多样性指标能够有效解决不平衡数据分类问题，显著提升模型性能，特别是在少数类别的分类准确性上。

> **ai_Abstract:** 本文针对两类分类中数据不平衡导致少数类分类性能差的问题，提出了一种名为MOODS的新型多目标双层优化框架。该框架能够同时指导合成过采样和多数欠采样，并引入了一个创新的“$\epsilon/\delta$ 非重叠多样性指标”来量化采样方法对模型性能的影响。实验结果表明，MOODS显著提升了数据多样性，并使F1分数提高了1-15%，达到了最先进的性能，有效解决了传统方法因未考虑多样性而导致的过拟合和性能不佳问题。

> **摘要翻译:** 两类分类问题通常表现为多数和少数数据点数量之间的不平衡，这导致少数类别的分类性能尤其差。传统的方​​法，例如重新加权损失函数或朴素重采样，存在过拟合的风险，因此未能改善分类，因为它们没有考虑多数和少数数据集之间的多样性。这种考虑是不可行的，因为没有可以衡量不平衡对模型影响的指标。为了克服这些挑战，我们做出了两个关键贡献。首先，我们引入了MOODS（Multi-Objective Optimization for Data Sampling），一个新颖的多目标双层优化框架，它指导合成过采样和多数欠采样。其次，我们引入了一个验证指标——“$\epsilon/\delta$ 非重叠多样性指标”，它量化了采样方法对模型性能的优劣。利用这个指标，我们通过实验证明了最先进的性能，多样性的改善带来了F1分数1-15%的提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [458] [The Sample Complexity of Parameter-Free Stochastic Convex Optimization](https://arxiv.org/abs/2506.11336)
> *参数无关随机凸优化的样本复杂度*

*Jared Lawrence, Ari Kalinsky, Hannah Bradfield, Yair Carmon, Oliver Hinder* | **Main category: cs.LG**

**Keywords:** 随机凸优化, 样本复杂度, 参数无关, 模型选择, 正则化

**Comment:** 

> **TL;DR:** 本文研究了当问题参数未知时，随机凸优化的样本复杂度。提出了两种策略：一种可靠的模型选择方法，可以通用地调整学习率以匹配最优的已知参数样本复杂度；另一种是基于正则化的方法，专门针对到最优距离未知的情况，实现了完美的适应性。结合两种方法可以同时适应多种问题结构。

**AI_Comments:** 这篇论文通过提出两种互补的策略，在参数未知的情况下解决了随机凸优化的样本复杂度问题，具有创新性。特别是，可靠的模型选择方法通过避免过拟合和自适应学习率，以及基于正则化的方法对未知距离的完美适应性，都显示了其重要性。它还指出了样本复杂度和计算复杂度之间的潜在分离，这是一个有趣的理论发现。实验部分也展示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究在问题参数（例如，到最优值的距离）未知的情况下，随机凸优化的样本复杂度。

**Method:** 开发了一种可靠的模型选择方法，该方法避免了验证集的过拟合，并能将随机优化方法的学习率调整到与最优已知参数样本复杂度匹配；开发了一种基于正则化的方法，专门针对仅到最优距离未知的情况，实现了对未知距离的完美适应性；结合这两种方法，以同时适应多种问题结构。

**Result:** 可靠的模型选择方法可以将学习率调整到与最优已知参数样本复杂度匹配，最多相差loglog因子；基于正则化的方法在到最优距离未知时，实现了完美的适应性，并揭示了参数无关随机凸优化的样本复杂度和计算复杂度之间的分离；结合两种方法可以同时适应多种问题结构；实验表明，可靠的模型选择方法有助于减轻对小验证集的过拟合。

**Conclusion:** 结合可靠的模型选择方法和基于正则化的方法，可以有效解决参数未知情况下的随机凸优化问题，并实现对多种问题结构的适应性，同时模型选择方法能减轻小验证集过拟合。

> **ai_Abstract:** 本文探讨了在问题参数未知情况下的随机凸优化样本复杂度问题。作者提出了两种主要策略：一是开发了一种可靠的模型选择方法，该方法能够避免验证集过拟合，并能将学习率调整到接近最优已知参数样本复杂度；二是设计了一种基于正则化的方法，专门处理到最优距离未知的情况，实现了完美的适应性，并揭示了样本复杂度和计算复杂度的分离。通过结合这两种方法，可以同时适应多种问题结构。实验证明，所提出的模型选择方法有助于减轻小验证集的过拟合。

> **摘要翻译:** 我们研究了当问题参数（例如，到最优解的距离）未知时，随机凸优化的样本复杂度。我们采用了两种策略。首先，我们开发了一种可靠的模型选择方法，该方法避免了验证集的过拟合。这种方法使我们能够通用地调整随机优化方法的学习率，使其与最优的已知参数样本复杂度匹配，最多相差$\log\log$因子。其次，我们开发了一种基于正则化的方法，该方法专门针对仅到最优解的距离未知的情况。该方法对未知到最优解的距离提供了完美的适应性，这表明参数无关随机凸优化的样本复杂度和计算复杂度之间存在分离。结合这两种方法使我们能够同时适应多种问题结构。在CIFAR-10上通过微调CLIP模型和提示工程Gemini来计数形状进行的少量样本学习实验表明，我们可靠的模型选择方法有助于减轻对小型验证集的过拟合。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [462] [Improving Group Robustness on Spurious Correlation via Evidential Alignment](https://arxiv.org/abs/2506.11347)
> *通过证据对齐提高虚假相关性上的群组鲁棒性*

*Wenqian Ye, Guangtao Zheng, Aidong Zhang* | **Main category: cs.LG**

**Keywords:** 虚假相关性, 群组鲁棒性, 不确定性量化, 证据对齐, 深度学习

**Comment:** Accepted at KDD2025

> **TL;DR:** 提出 Evidential Alignment 框架，利用不确定性量化在无需群组标注的情况下识别和抑制虚假相关性，显著提高群组鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了 Evidential Alignment 框架，它通过不确定性量化而非传统的外部标注或辅助模型来解决虚假相关性问题，这大大降低了数据成本。其理论依据和在不同架构及数据模态上的显著效果表明了其重要性和广泛应用潜力，为提升模型在分布外场景下的鲁棒性和可信度提供了一条新路径。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络常学习并依赖虚假相关性，导致泛化能力下降，对分布外鲁棒性和可信度构成挑战。现有方法需要昂贵的外部群组标注或可能无法完全捕捉偏差的确定性模型。

**Method:** 提出 Evidential Alignment 框架。该框架利用不确定性量化来理解有偏模型的行为，无需群组标注。通过使用二阶风险最小化量化模型预测的证据，并利用所提出的证据校准技术校准有偏模型，Evidential Alignment 能够识别并抑制虚假相关性，同时保留核心特征。

**Result:** 经验结果表明，该方法显著提高了跨不同架构和数据模态的群组鲁棒性。

**Conclusion:** Evidential Alignment 提供了一种可扩展且有原则的解决方案来解决虚假相关性问题，能够在无需虚假相关性标注的情况下学习有偏模型的模式并进行去偏。

> **ai_Abstract:** 本文提出 Evidential Alignment 框架，旨在解决深度神经网络依赖虚假相关性导致泛化能力下降的问题。该框架通过利用不确定性量化，在无需外部群组标注的情况下，通过二阶风险最小化量化预测证据并进行证据校准，从而识别并抑制虚假相关性。理论分析证明了其去偏能力，实验结果表明该方法显著提升了群组鲁棒性，为虚假相关性问题提供了一个可扩展且有原则的解决方案。

> **摘要翻译:** 深度神经网络经常学习并依赖虚假相关性，即非因果特征与目标之间的肤浅关联。例如，图像分类器可能会根据沙漠背景来识别骆驼。虽然在训练期间可以产生较高的整体准确性，但在这种相关性不成立的更多样化的场景中，其泛化能力会下降。这个问题对分布外鲁棒性和可信度构成了重大挑战。现有方法通常通过使用外部群组标注或辅助确定性模型来学习无偏表示来缓解这个问题。然而，此类信息获取成本高昂，并且确定性模型可能无法捕捉模型学习到的所有偏差。为了解决这些限制，我们提出了 Evidential Alignment，一个新颖的框架，它利用不确定性量化来理解有偏模型的行为，而无需群组标注。通过使用二阶风险最小化量化模型预测的证据，并利用所提出的证据校准技术校准有偏模型，Evidential Alignment 能够识别并抑制虚假相关性，同时保留核心特征。我们从理论上证明了我们方法的有效性，即它能够学习有偏模型的模式并在不需要任何虚假相关性标注的情况下对模型进行去偏。经验结果表明，我们的方法显著提高了跨不同架构和数据模态的群组鲁棒性，为虚假相关性问题提供了一种可扩展且有原则的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [466] [Generalization Bound of Gradient Flow through Training Trajectory and Data-dependent Kernel](https://arxiv.org/abs/2506.11357)
> *梯度流通过训练轨迹和数据依赖核的泛化界限*

*Yilan Chen, Zhichao Wang, Wei Huang, Andi Han, Taiji Suzuki, Arya Mazumdar* | **Main category: cs.LG**

**Keywords:** 梯度流, 泛化界限, 损失路径核, Rademacher复杂度, 训练轨迹

**Comment:** 

> **TL;DR:** 本文通过引入数据依赖的损失路径核（LPK），为梯度流建立了新的泛化界限，该界限考虑了整个训练轨迹并提供了更紧密的泛化保证。

**AI_Comments:** 这篇论文通过引入损失路径核（LPK）来分析梯度流的泛化能力，是一个重要的创新点。LPK能够捕捉整个训练轨迹和数据依赖性，这使得泛化界限比传统的静态核更紧密、更具洞察力。它不仅加深了对梯度下降优化过程泛化机制的理解，还突出了神经网络的特征学习能力，为深度学习的理论研究提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 梯度优化方法在实践中取得了显著成功，但其理论泛化性质尚未完全理解。

**Method:** 论文通过引入一种数据依赖的核——损失路径核（LPK），结合梯度流的稳定性分析和Rademacher复杂度下的均匀收敛性，为梯度流建立了泛化界限。LPK捕获了整个训练轨迹并适应数据和优化动态。

**Result:** 建立了与经典Rademacher复杂度核方法界限（基于RKHS范数和核迹）相符的梯度流泛化界限。该界限更紧密、信息更丰富，并揭示了训练损失梯度范数如何影响泛化性能。该界限能恢复超参数化神经网络的现有核回归界限，并显示了神经网络相对于核方法的特征学习能力。数值实验验证了界限与真实泛化差距的相关性。

**Conclusion:** 本文成功为梯度流建立了新的泛化界限，通过考虑训练轨迹和数据依赖性，提供了对泛化性能更深入的理解和更紧密的保证，并突出了神经网络的特征学习能力。

> **ai_Abstract:** 本文通过引入数据依赖的损失路径核（LPK），为梯度流建立了新的泛化界限，该界限超越了静态核的局限，能够捕获完整的训练轨迹并适应数据与优化动态。研究表明，此界限不仅提供了更紧密、更具信息量的泛化保证，还揭示了训练损失梯度范数对泛化性能的影响。理论上，该界限结合了梯度流的稳定性分析和Rademacher复杂度，能够恢复现有超参数化神经网络的核回归界限，并突显了神经网络的特征学习能力。数值实验进一步验证了其与真实泛化差距的良好相关性。

> **摘要翻译:** 基于梯度的优化方法取得了显著的经验成功，但其理论泛化性质仍仅部分被理解。在本文中，我们通过一个名为损失路径核（LPK）的数据依赖核，为梯度流建立了一个泛化界限，该界限与核方法的经典Rademacher复杂度界限（特别是那些基于RKHS范数和核迹的界限）相符。与NTK等静态核不同，LPK捕获了整个训练轨迹，适应数据和优化动态，从而带来了更紧密、信息更丰富的泛化保证。此外，该界限强调了优化轨迹上训练损失梯度的范数如何影响最终的泛化性能。我们证明中的关键技术要素结合了梯度流的稳定性分析和通过Rademacher复杂度的均匀收敛性。我们的界限恢复了超参数化神经网络的现有核回归界限，并展示了神经网络相对于核方法的特征学习能力。在真实世界数据集上的数值实验验证了我们的界限与真实泛化差距具有良好相关性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [468] [EDN: A Novel Edge-Dependent Noise Model for Graph Data](https://arxiv.org/abs/2506.11368)
> *EDN：一种新颖的图数据边依赖噪声模型*

*Pintu Kumar, Nandyala Hemachandra* | **Main category: cs.LG**

**Keywords:** 边依赖噪声, 图数据, 标签噪声, 图神经网络, 节点度

**Comment:** 

> **TL;DR:** EDN是一种新的图数据标签噪声模型，它考虑了边的影响，并显示出比传统模型更能降低GNN和去噪算法的性能，这对于评估图学习算法的鲁棒性至关重要。

**AI_Comments:** EDN模型创新性地将图结构（边和节点度）纳入标签噪声建模，这比传统的独立同分布噪声模型更符合现实世界的图数据噪声特征。其重要性在于，它提供了一个更具挑战性也更真实的基准来评估图神经网络和噪声鲁棒算法的性能，有助于开发更鲁棒的图学习方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的节点标签噪声模型（如Symmetric Label Noise (SLN)和Class Conditional Noise (CCN)）忽略了图数据中节点关系（即边）的重要性，而EDN模型旨在解决这一局限性，因为它假设在现实世界中标签噪声可能受到节点间连接的影响。

**Method:** 本文提出了Edge-Dependent Noise (EDN)模型，认为标签噪声可能受到节点之间连接的影响。研究探索了EDN的三个变体，并证明在所有三个变体中，节点标签损坏的概率都依赖于其度。此外，还比较了不同变体中这些概率对节点度的依赖性。实验在流行图数据集上使用5种不同的GNN架构和8种噪声鲁棒算法进行。

**Result:** 实验结果表明，与传统的节点标签噪声模型相比，EDN的两个变体导致图神经网络（GNNs）和现有噪声鲁棒算法的性能下降更大。通过适当的假设检验问题，统计验证了这一发现。

**Conclusion:** 在评估图的噪声鲁棒算法时，纳入EDN模型至关重要，以提高嘈杂环境中基于图的学习的可靠性。

> **ai_Abstract:** 本文提出了EDN（边依赖噪声）模型，旨在解决现有节点标签噪声模型忽略图数据中边关系的问题。EDN模型假设标签噪声受节点连接影响，并探索了三个变体，证明节点标签损坏概率与其度相关。实验表明，EDN的两个变体比传统噪声模型更能导致GNNs和噪声鲁棒算法的性能显著下降。研究强调在评估图的噪声鲁棒算法时应考虑EDN，以提高图学习在噪声环境中的可靠性。

> **摘要翻译:** 图的一个重要结构特征是它的边集，因为它捕捉了节点之间的关系（图的拓扑结构）。现有的节点标签噪声模型，如对称标签噪声（SLN）和类条件噪声（CCN），忽略了图数据中这种重要的节点关系；而边依赖噪声（EDN）模型解决了这一局限性。EDN假设在现实世界场景中，标签噪声可能受到节点之间连接的影响。我们探索了EDN的三个变体。图中连接节点和边的一个关键概念是节点的度；我们表明，在所有三个变体中，节点标签损坏的概率都取决于其度。此外，我们比较了这些概率在不同变体中对节点度的依赖性。我们使用5种不同的GNN架构和8种用于图数据的噪声鲁棒算法，在流行的图数据集上进行了实验。结果表明，与传统的节点标签噪声模型相比，EDN的两个变体导致图神经网络（GNNs）和现有噪声鲁棒算法的性能下降更大。我们通过提出合适的假设检验问题来统计验证了这一点。这强调了在评估图的噪声鲁棒算法时纳入EDN的重要性，以提高嘈杂环境中基于图的学习的可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [471] [The Effect of Stochasticity in Score-Based Diffusion Sampling: a KL Divergence Analysis](https://arxiv.org/abs/2506.11378)
> *基于分数扩散采样的随机性效应：KL散度分析*

*Bernardo P. Schaeffer, Ricardo M. S. Rosa, Glauco Valle* | **Main category: cs.LG**

**Keywords:** 分数扩散模型, 随机性, KL散度, 采样, 对数-Sobolev不等式

**Comment:** 

> **TL;DR:** 本文研究了分数扩散模型中采样的随机性如何影响生成质量（KL散度），发现对于精确分数函数，随机性是误差校正机制，而对于近似分数函数，则存在误差校正与误差放大之间的权衡。

**AI_Comments:** 这篇论文对分数扩散模型中的随机性采样机制进行了严谨的理论分析，具有重要的创新性和实践指导意义。通过引入KL散度分析和利用对数-Sobolev不等式，作者深入揭示了随机性在误差传播中的复杂作用。尤其值得关注的是，论文区分了精确分数函数和近似分数函数下的随机性效应，指出了在实际应用中（通常分数函数是近似的）可能存在的权衡，这为优化扩散模型的采样策略和理解其性能边界提供了宝贵的理论依据。这一发现对于指导未来模型设计和训练具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了理解分数扩散模型中，逆时间随机微分方程（SDE）采样过程中的随机性参数如何影响生成过程，特别是其对Kullback-Leibler（KL）散度的影响，并量化误差的传播。

**Method:** 通过分析Kullback-Leibler（KL）散度的边界来研究随机性效应。理论边界是使用前向过程边际的对数-Sobolev不等式推导的，以更有效地控制采样过程中KL散度的衰减。此外，还通过在简单数据集上的数值实验和一个完全分析的示例来补充和阐明理论结果。研究结果适用于具有加性噪声和Lipschitz连续分数函数的通用前向SDE。

**Result:** 研究量化了在不同随机性参数选择下，来自先验分布和分数近似的误差如何传播。对于精确分数函数，随机性被发现是一种误差校正机制，能够沿采样轨迹降低KL散度。然而，对于近似分数函数，在误差校正和分数误差放大之间存在权衡，这意味着随机性可以根据分数误差的结构改善或恶化性能。

**Conclusion:** 分数扩散模型采样中的随机性对生成质量（以KL散度衡量）具有复杂的影响。对于精确分数函数，随机性表现为误差校正机制，有助于提高性能。但对于近似分数函数，其影响则取决于误差校正与误差放大之间的权衡，可能带来积极或消极的结果。本研究提供了量化这些行为的理论边界和实证证据。

> **ai_Abstract:** 本文深入探讨了分数扩散模型采样中随机性的作用，特别关注其对生成质量（通过Kullback-Leibler散度衡量）的影响。研究通过推导基于对数-Sobolev不等式的理论边界，揭示了对于精确分数函数，随机性能够作为误差校正机制，有效降低KL散度。然而，对于近似分数函数，随机性则在误差校正和分数误差放大之间构成一种权衡，其最终效果取决于分数误差的具体结构。数值实验和分析示例进一步验证并阐明了这些理论发现，量化了不同随机性参数下误差的传播情况。

> **摘要翻译:** 基于分数的扩散模型中的采样可以通过求解概率流ODE或由任意随机性参数化的逆时间随机微分方程（SDE）来执行。在这项工作中，我们通过对Kullback-Leibler（KL）散度的边界来研究随机性对生成过程的影响，并辅以数值和分析示例进行分析。我们的结果适用于具有加性噪声和Lipschitz连续分数函数的通用前向SDE，并量化了在不同随机性参数选择下，来自先验分布和分数近似的误差如何传播。理论边界是使用前向过程边际的对数-Sobolev不等式推导的，这使得在采样过程中能够更有效地控制KL散度的衰减。对于精确分数函数，我们发现随机性充当误差校正机制，沿采样轨迹降低KL散度。对于近似分数函数，在误差校正和分数误差放大之间存在权衡，因此随机性可以根据分数误差的结构改善或恶化性能。文中包含了在简单数据集上的数值实验和一个完全分析的例子，以说明和阐明理论结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [475] [FIGNN: Feature-Specific Interpretability for Graph Neural Network Surrogate Models](https://arxiv.org/abs/2506.11398)
> *FIGNN：图神经网络替代模型的特征特异性可解释性*

*Riddhiman Raut, Romit Maulik, Shivam Barwey* | **Main category: cs.LG**

**Keywords:** 图神经网络, 可解释性, 替代模型, 特征特异性, 科学应用

**Comment:** 

> **TL;DR:** FIGNN是一种新型图神经网络，通过引入特征特异性池化策略和基于掩码的正则化项，增强了科学应用中深度学习替代模型的可解释性，同时保持了竞争性的预测性能并揭示了物理上有意义的空间模式。

**AI_Comments:** FIGNN的创新之处在于其特征特异性池化策略和基于掩码的正则化项，这些设计直接解决了GNN在科学替代模型中可解释性不足的问题。其能够揭示物理上有意义的空间模式，对于科学发现和模型理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图神经网络在多元预测任务中常常模糊不同特征的独特空间影响，限制了深度学习替代模型在科学应用中的可解释性。

**Method:** 该研究提出了一种名为特征特异性可解释图神经网络（FIGNN）的新型GNN架构。FIGNN通过引入特征特异性池化策略，实现对每个预测变量的空间重要性进行独立归因。此外，训练目标中加入了基于掩码的正则化项，以明确促进可解释性与预测误差之间的一致性，从而实现模型性能的局部归因。该方法在SPEEDY大气环流模型和后向台阶（BFS）流体动力学基准两个物理系统上进行了评估。

**Result:** FIGNN取得了具有竞争力的预测性能，并揭示了每个特征独特的、物理上有意义的空间模式。对滚动稳定性、特征误差预算和空间掩码叠加的分析证实了FIGNN作为可解释替代建模通用框架的实用性。

**Conclusion:** FIGNN被证实是一个适用于复杂物理领域中可解释替代建模的通用框架，其通过分析滚动稳定性、特征误差预算和空间掩码叠加得到了进一步确认。

> **ai_Abstract:** 本文介绍了一种名为FIGNN的新型图神经网络，旨在提高科学应用中深度学习替代模型的可解释性。FIGNN通过引入特征特异性池化策略来独立归因每个预测变量的空间重要性，并结合基于掩码的正则化项来确保可解释性与预测误差的一致性，从而解决了传统GNN在多元任务中对特征空间影响的模糊问题。在两个物理系统上的评估表明，FIGNN不仅实现了竞争性的预测性能，还能揭示出每个特征独特的、物理上有意义的空间模式，证明了其作为可解释替代建模通用框架的实用性。

> **摘要翻译:** 这项工作提出了一种新颖的图神经网络（GNN）架构，即特征特异性可解释图神经网络（FIGNN），旨在增强科学应用中非结构化网格上定义的深度学习替代模型的可解释性。传统的GNN在多元预测任务中常常模糊不同特征的独特空间影响。FIGNN通过引入特征特异性池化策略来解决这一限制，该策略能够独立归因每个预测变量的空间重要性。此外，训练目标中还融入了一个基于掩码的正则化项，以明确鼓励可解释性与预测误差之间的一致性，从而促进模型性能的局部归因。该方法针对两个物理上不同的系统的替代建模进行了评估：SPEEDY大气环流模型和后向台阶（BFS）流体动力学基准。结果表明，FIGNN在实现具有竞争力的预测性能的同时，揭示了每个特征独特的物理上有意义的空间模式。对滚动稳定性、特征误差预算和空间掩码叠加的分析证实了FIGNN作为复杂物理领域中可解释替代建模通用框架的实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [479] [LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](https://arxiv.org/abs/2506.11402)
> *LoRA 用户请注意：少量虚假令牌即可操控您的微调模型*

*Pradyut Sekhsaria, Marcel Mateos Salles, Hai Huang, Randall Balestriero* | **Main category: cs.LG**

**Keywords:** LoRA, PEFT, 虚假令牌, LLM 操纵, 鲁棒性, 微调

**Comment:** 29 pages, 16 figures, 15 tables. Submitted for publication. for
  associated blog post, see https://pradyut3501.github.io/lora-spur-corr/

> **TL;DR:** 参数高效微调（PEFT）方法（如 LoRA）训练的 LLM 容易被少量虚假令牌操控，即使一个令牌也足以影响模型决策。

**AI_Comments:** 这篇论文揭示了 PEFT 方法（特别是 LoRA）一个重要的安全和鲁棒性问题，这些方法因其效率而被广泛采用。对“虚假令牌”的发现和提出的 SSTI 攻击向量具有创新性，展示了一种操纵微调模型的新方法。研究结果强调了开发更鲁棒的微调技术和改善数据卫生实践的必要性。关于 LoRA 秩的双重效应（轻度 SSTI 增加脆弱性，激进 SSTI 提高鲁棒性）的观察尤其有见地。

<details>
  <summary>Details</summary>

**Motivation:** 当前的参数高效微调（PEFT）研究主要关注效率，而忽视了潜在的灾难性故障。本研究旨在揭示 PEFT 的一个此类故障，即模型容易通过“捷径解决方案”被虚假令牌操控。

**Method:** 研究发现 PEFT 鼓励模型寻找捷径解决方案。提出“无缝虚假令牌注入（SSTI）”方法，在数据集创建时注入少量与下游任务类别相关的令牌。将 SSTI 应用于三个模型家族（Snowflake Arctic、Apple OpenELM、Meta LLaMA-3）和四个数据集（IMDB、金融分类、常识问答、生物偏差）以观察模型行为。

**Result:** 首先，少至一个 SSTI 令牌就足以引导模型的决策。其次，对于轻度 SSTI，对虚假令牌的依赖与 LoRA 秩成正比。最后，在激进的 SSTI 下，较大的 LoRA 秩值优于较小的秩值，因为它使模型关注非虚假令牌，从而提高了鲁棒性。

**Conclusion:** PEFT 模型，特别是使用 LoRA 的模型，容易受到虚假令牌的操控，即使是极少量的令牌也能影响其决策。LoRA 秩的大小会影响这种脆弱性和模型的鲁棒性。

> **ai_Abstract:** 本文揭示了参数高效微调（PEFT）方法（如 LoRA）的一个关键漏洞，即它们鼓励模型采用“捷径解决方案”，使其极易受到与任务类别相关的少量“虚假令牌”的操纵。这种现象被称为无缝虚假令牌注入（SSTI），允许外部控制微调后的 LLM。跨多个模型和数据集的实验表明，即使一个虚假令牌也足以引导模型决策。研究还发现，对于轻度注入，模型对虚假令牌的依赖与 LoRA 秩成正比，而对于激进注入，较高的 LoRA 秩反而能提高鲁棒性。

> **摘要翻译:** 参数高效微调 (PEFT)，例如低秩适应 (LoRA)，以资源高效的方式使预训练的大型语言模型 (LLM) 与特定下游任务对齐。由于效率一直是衡量进步的主要指标，因此很少有人关注理解可能的灾难性故障。我们发现了一个这样的故障：PEFT 鼓励模型寻找捷径解决方案来解决其微调任务。当极少量的令牌（例如，每个提示一个令牌）与下游任务类别相关时，PEFT 会使任何预训练模型在决策时主要依赖该令牌。虽然这种虚假令牌可能由于不正确的数据清理而偶然出现，但它也为恶意方通过无缝虚假令牌注入 (SSTI) 控制模型的行为提供了机会。在 SSTI 中，数据集创建者注入少量与下游类别相关的令牌。在测试时，微调后的 LLM 的行为可以仅通过注入这些少量令牌来控制。我们将 SSTI 应用于来自三个系列（Snowflake Arctic、Apple OpenELM 和 Meta LLaMA-3）的模型和四个不同的数据集（IMDB、金融分类、常识问答和生物偏差）。我们的发现揭示了三种惊人的行为。首先，少至一个 SSTI 令牌就足以引导模型的决策。其次，对于轻度 SSTI，对虚假令牌的依赖与 LoRA 秩成正比。最后，在激进的 SSTI 下，较大的 LoRA 秩值优于较小的秩值，因为它使模型关注非虚假令牌，从而提高了鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [491] [TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision](https://arxiv.org/abs/2506.11431)
> *TruncQuant：适用于具有灵活权重位精度的DNN的截断就绪量化*

*Jinhee Kim, Seoyeon Yoon, Taeho Lee, Joo Chan Lee, Kang Eun Jeon, Jong Hwan Ko* | **Main category: cs.LG**

**Keywords:** 截断, 量化, 深度神经网络, 灵活位精度, 边缘设备

**Comment:** 

> **TL;DR:** TruncQuant是一种新颖的训练方案，允许DNN在运行时通过位移实现灵活的位精度，以适应边缘设备上的截断量化。

**AI_Comments:** TruncQuant的创新之处在于它专门针对截断过程设计了量化感知训练方案，解决了现有方案的不足。其通过位移实现灵活位精度的能力，对于需要在不同硬件平台部署的DNN模型具有重要意义。该方法提高了模型在低位精度下的鲁棒性，并且易于实现，这有助于加速DNN在边缘设备上的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 在边缘设备上部署深度神经网络面临模型复杂性日益增加的挑战，需要减少模型大小和推理延迟。截断是一种实现更低位精度映射的有效方法，但当前的量化感知训练方案并非为处理截断引入的误差而设计，这仍然是一个挑战。

**Method:** 本文提出了TruncQuant，一种新颖的截断就绪训练方案，通过在运行时进行位移来实现灵活的位精度。该方法通过将TruncQuant与截断过程的输出对齐来实现，并将其设计为易于在现有量化感知框架中实现。

**Result:** TruncQuant在不同位宽设置下表现出强大的鲁棒性，并提供了一种易于实现的训练方案。

**Conclusion:** TruncQuant提供了一种有效的训练方案，使深度神经网络能够通过截断量化在边缘设备上实现灵活的位精度和强大的鲁棒性。

> **ai_Abstract:** 本文提出了TruncQuant，一种针对深度神经网络的新型截断就绪训练方案，旨在解决模型在边缘设备上部署时面临的挑战。该方案通过在运行时进行位移来实现灵活的位精度，并与截断过程的输出对齐，从而在不同位宽设置下表现出强大的鲁棒性。TruncQuant易于集成到现有量化感知训练框架中，有助于减小模型大小和降低推理延迟。

> **摘要翻译:** 将深度神经网络部署在边缘设备上是一项具有挑战性的任务，因为最先进模型的复杂性日益增加，需要努力减小模型大小和推理延迟。最近的研究探索了在不同量化设置下运行的模型，以找到平衡计算效率和准确性的最佳点。截断是一种实现较低位精度映射的有效方法，它使单个模型能够以很小的成本或无需成本适应各种硬件平台。然而，为深度神经网络制定一个训练方案以承受截断引入的相关误差仍然是一个挑战，因为当前的量化感知训练方案并非为截断过程而设计。我们提出了TruncQuant，一种新颖的截断就绪训练方案，允许通过运行时位移实现灵活的位精度。我们通过将TruncQuant与截断过程的输出对齐来实现这一点，展示了在不同位宽设置下的强大鲁棒性，并提供了一种在现有量化感知框架内易于实现的训练方案。我们的代码已发布在https://github.com/a2jinhee/TruncQuant。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [494] [Dynamic Sparse Training of Diagonally Sparse Networks](https://arxiv.org/abs/2506.11449)
> *对角稀疏网络的动态稀疏训练*

*Abhishek Tyagi, Arjun Iyer, William H Renninger, Christopher Kanan, Yuhao Zhu* | **Main category: cs.LG**

**Keywords:** 动态稀疏训练, 对角稀疏, 结构化稀疏, 硬件加速, DynaDiag

**Comment:** 

> **TL;DR:** DynaDiag提出了一种对角稀疏的动态稀疏训练方法，解决了非结构化稀疏在现代硬件上加速不足的问题，并在保持精度的同时实现了显著的计算加速。

**AI_Comments:** 本文的创新点在于提出了DynaDiag，一种结合了对角稀疏模式和自定义CUDA内核的DST方法，有效解决了非结构化稀疏在硬件加速方面的瓶颈。这种结构化的稀疏方法不仅保持了模型精度，还带来了显著的计算效率提升，对于实际部署和大规模模型训练具有重要意义。其硬件友好的设计是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态稀疏训练（DST）虽然减少了参数量并匹配了密集模型的性能，但非结构化稀疏在现代硬件上往往无法转化为实际的速度提升。为了解决这一不足，本文提出了DynaDiag。

**Method:** 本文提出了DynaDiag，一种新颖的结构化稀疏到稀疏的动态稀疏训练（DST）方法。DynaDiag在整个训练过程中强制执行对角稀疏模式，并在前向和后向传播中保留稀疏计算。该方法还利用对角结构通过自定义CUDA内核加速计算，使其对硬件友好。

**Result:** 经验评估表明，DynaDiag在保持与非结构化对应方法相同精度的同时，获得了显著的计算增益。具体而言，在ViT中，使用90%稀疏的线性层，在线推理速度提高了3.13倍，训练速度在GPU上提高了1.59倍，且不牺牲模型性能。

**Conclusion:** DynaDiag通过引入对角稀疏模式和自定义CUDA内核，成功解决了非结构化稀疏在硬件加速上的局限性，实现了在保持模型性能的同时，显著提升稀疏神经网络的训练和推理速度。

> **ai_Abstract:** 本文提出了一种名为DynaDiag的新型动态稀疏训练（DST）方法，旨在解决非结构化稀疏在现代硬件上缺乏实际加速的问题。DynaDiag通过在训练中强制执行对角稀疏模式并利用自定义CUDA内核进行加速，实现了结构化稀疏性。实验结果表明，该方法在保持与非结构化稀疏相当的精度的同时，显著提升了计算效率，尤其是在ViT中实现了显著的推理和训练速度提升。

> **摘要翻译:** 动态稀疏训练（DST）的最新进展推动了结构化和非结构化背景下稀疏神经网络训练的前沿，在大幅减少参数数量以促进模型扩展的同时，匹配了密集模型的性能。然而，非结构化稀疏往往无法在现代硬件上转化为实际的速度提升。为了解决这一不足，我们提出了DynaDiag，一种新颖的结构化稀疏到稀疏的DST方法，其性能与非结构化稀疏相当。DynaDiag在整个训练过程中强制执行对角稀疏模式，并在前向和后向传播中保留稀疏计算。我们进一步利用对角结构通过自定义CUDA内核加速计算，使该方法对硬件友好。对各种神经网络架构的实证评估表明，我们的方法在保持与非结构化对应方法相同精度的同时，受益于切实的计算增益。值得注意的是，在ViT中使用90%稀疏的线性层，我们观察到在线推理速度提高了3.13倍，而没有牺牲模型性能，并且在GPU上训练速度比等效的非结构化层提高了1.59倍。我们的源代码可在https://github.com/horizon-research/DynaDiag/获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [498] [RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer](https://arxiv.org/abs/2506.11465)
> *RollingQ: 恢复多模态Transformer中的协作动态*

*Haotian Ni, Yake Wei, Hang Liu, Gong Chen, Chong Peng, Hao Lin, Di Hu* | **Main category: cs.LG**

**Keywords:** 多模态学习, Transformer, 自注意力, 动态融合, RollingQ

**Comment:** Accepted by ICML 2025

> **TL;DR:** 多模态Transformer中的自注意力机制会偏向单一模态，导致动态适应性下降。本文提出RollingQ方法，通过旋转查询来平衡注意力分配，恢复模态间的协作动态性，有效提升多模态Transformer的性能。

**AI_Comments:** 这篇论文通过深入的实验揭示了多模态Transformer中自注意力机制的一个重要缺陷，即其动态适应性的丧失和对单一模态的偏爱。RollingQ方法简单而巧妙，通过旋转查询来重新平衡注意力，有效解决了这一问题。其创新点在于对现有模型缺陷的深刻洞察以及提出了一种优雅的解决方案，对于提升多模态Transformer的性能和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态学习在有效融合不同模态信息时面临挑战，尤其当模态质量因样本而异时。研究发现，广泛使用的自注意力模型其动态适应性会减弱，模型倾向于偏好单一模态，引发自我强化的循环，导致注意力键分布差距扩大并使注意力机制的动态特性失效。

**Method:** 提出了一种名为“Rolling Query (RollingQ)”的简单而有效的方法。它通过旋转查询来平衡注意力分配，从而打破自增强循环并减轻注意力键在模态间的分布差距，以恢复模型的适应性。

**Result:** 在各种多模态场景下进行了广泛的实验，验证了RollingQ的有效性。实验结果表明，恢复协作动态性对于增强广泛部署的多模态Transformer的更广泛能力至关重要。

**Conclusion:** RollingQ通过平衡注意力分配成功恢复了多模态Transformer中自注意力机制的动态适应性，解决了模型偏向单一模态的问题，从而显著提升了多模态模型的性能。

> **ai_Abstract:** 本文针对多模态Transformer中自注意力机制动态适应性减弱、模型偏向单一模态的问题，通过实验揭示了其内在机制。为恢复模态间的协作动态性，提出Rolling Query (RollingQ) 方法，通过旋转查询来平衡注意力分配，有效打破了自我强化循环并缩小了注意力键的分布差距。在多模态场景下的广泛实验证明了RollingQ的有效性，并强调了恢复协作动态性对提升多模态Transformer能力的重要性。

> **摘要翻译:** 多模态学习在有效融合来自不同模态的信息时面临挑战，尤其当模态质量因样本而异时。动态融合策略，例如Transformer中的注意力机制，旨在通过根据输入数据的特征自适应地强调模态来解决此类挑战。然而，通过大量精心设计的实验，我们惊讶地观察到广泛使用的自注意力模型的动态适应性减弱了。模型倾向于偏好一种模态，而不管数据特征如何。这种偏见引发了一个自我强化的循环，逐渐过度强调受偏爱的模态，扩大了注意力键在模态间的分布差距，并使注意力机制的动态特性失效。为了恢复适应性，我们提出了一种简单而有效的方法——旋转查询（Rolling Query, RollingQ），它通过旋转查询来平衡注意力分配，从而打破自我强化的循环并减轻键分布差距。在各种多模态场景下进行的广泛实验验证了RollingQ的有效性，并且恢复协作动态性对于增强广泛部署的多模态Transformer的更广泛能力至关重要。源代码可在https://github.com/GeWu-Lab/RollingQ_ICML2025获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [502] [Position Paper: Rethinking AI/ML for Air Interface in Wireless Networks](https://arxiv.org/abs/2506.11466)
> *立场文件：重新思考无线网络空口中的AI/ML*

*Georgios Kontes, Diomidis S. Michalopoulos, Birendra Ghimire, Christopher Mutschler* | **Main category: cs.LG**

**Keywords:** AI/ML, 无线网络, 空口, 3GPP标准化, 研究挑战

**Comment:** 

> **TL;DR:** 本立场文件讨论了AI/ML在无线网络空口应用中的早期阶段，概述了3GPP标准化中的相关讨论，并指出了未来的研究挑战和机遇。

**AI_Comments:** 本文作为一篇立场文件，清晰地指出了AI/ML在无线通信领域，尤其是空口应用方面的巨大潜力和当前面临的挑战。其创新之处在于将AI/ML研究与3GPP标准化讨论相结合，为未来研究和产业发展提供了明确的方向。重要性体现在其对跨学科合作的强调，以及对塑造未来AI赋能无线系统的愿景。

<details>
  <summary>Details</summary>

**Motivation:** AI/ML在计算机视觉、自然语言处理等领域已取得显著进展，但在无线网络特别是空口的应用仍处于早期阶段。充分发挥AI/ML在无线通信中的潜力需要跨学科的深入理解。因此，本文旨在探讨并推动AI/ML在无线空口的应用。

**Method:** 本文概述了3GPP标准化中与AI/ML相关的讨论，重点介绍了关键用例、架构考量和技术要求。同时，它还概述了学术界和工业界可以为塑造AI赋能的无线系统未来做出贡献的开放研究挑战和机遇。

**Result:** 本文提供了3GPP标准化中AI/ML相关讨论的概述，强调了关键用例、架构考量和技术要求。此外，它还指出了开放的研究挑战和机遇。

**Conclusion:** 本文旨在通过概述3GPP标准化中的AI/ML讨论、突出用例、架构和技术要求，并指出开放的研究挑战和机遇，以促进学术界和工业界共同塑造AI赋能的无线系统的未来。

> **ai_Abstract:** 本立场文件探讨了AI/ML在无线网络空口应用中的现状和潜力。鉴于AI/ML在其他领域的高度发展与在无线通信领域应用的初期阶段形成对比，文章强调了跨学科理解的重要性。论文概述了3GPP标准化中关于AI/ML的讨论，包括关键用例、架构考量和技术要求，并指出了需要学术界和工业界共同努力的开放研究挑战和机遇，以推动AI赋能的无线系统发展。

> **摘要翻译:** 人工智能/机器学习（AI/ML）研究主要由计算机视觉、自然语言处理和视频分析等领域驱动。相比之下，AI/ML在无线网络，特别是空口的应用仍处于早期阶段。尽管已有新兴的努力来探索这一交叉点，但要充分发挥AI/ML在无线通信中的潜力，需要对这两个领域有深入的跨学科理解。我们概述了3GPP标准化中与AI/ML相关的讨论，重点介绍了关键用例、架构考量和技术要求。我们还概述了学术界和工业界可以为塑造AI赋能的无线系统未来做出贡献的开放研究挑战和机遇。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [506] [LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment](https://arxiv.org/abs/2506.11480)
> *LearnAlign：基于改进梯度对齐的大型语言模型强化学习推理数据选择方法*

*Shikun Li, Shipeng Li, Zhiqin Yang, Xinghua Zhang, Gaode Chen, Xiaobo Xia, Hengyu Liu, Zhe Peng* | **Main category: cs.LG**

**Keywords:** 强化学习, 大型语言模型, 数据选择, 梯度对齐, 推理能力

**Comment:** 

> **TL;DR:** LearnAlign是一种新的数据选择方法，通过改进梯度对齐来提高大型语言模型强化学习的效率，显著减少训练数据需求。

**AI_Comments:** LearnAlign的创新之处在于其结合了梯度对齐和基于成功率的数据可学习性来解决RL的数据效率问题，克服了传统梯度范数中响应长度偏差的局限性。其重要性体现在能够显著减少LLM强化学习所需的训练数据，这对于资源受限的训练环境和提高训练效率具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在增强大型语言模型（LLMs）推理能力方面是关键技术，但其数据效率低下是一个主要瓶颈。

**Method:** 本文提出了一种名为LearnAlign的新型基于梯度对齐的方法，用于智能选择RL后训练中可学习且具有代表性的训练推理数据。为了克服梯度范数中响应长度偏差的问题，该方法引入了基于成功率的数据可学习性，以指示每个数据点的学习潜力。

**Result:** 实验表明，在三个数学推理基准测试中，LearnAlign显著减少了训练数据需求，同时实现了轻微的性能下降甚至性能提升。例如，在GSM8K基准测试中，它将数据需求减少了多达1000个数据点，性能（77.53%）优于完整数据集（77.04%）。此外，该方法在分阶段RL设置中也显示出有效性。

**Conclusion:** 这项工作为数据高效的RL后训练提供了有价值的见解，并为未来优化推理数据选择的研究奠定了基础。

> **ai_Abstract:** 本研究提出了一种名为LearnAlign的新型数据选择方法，旨在解决大型语言模型（LLMs）强化学习（RL）中数据效率低下的问题。LearnAlign通过改进的梯度对齐机制，并结合基于成功率的数据可学习性，智能选择RL后训练的推理数据。实验证明，该方法在保持或提升性能的同时，显著减少了数学推理任务的训练数据量，并对未来的数据高效RL研究具有指导意义。

> **摘要翻译:** 强化学习（RL）已成为增强大型语言模型（LLMs）推理能力的关键技术，但其数据效率低下仍然是主要瓶颈。为了解决这个关键但具有挑战性的问题，我们提出了一种名为LearnAlign的新型基于梯度对齐的方法，该方法智能地选择RL后训练中可学习且具有代表性的训练推理数据。为了克服梯度范数中众所周知的响应长度偏差问题，我们引入了基于成功率的数据可学习性，这可以指示每个数据点的学习潜力。在三个数学推理基准测试中的实验表明，我们的方法显著减少了训练数据需求，同时与全数据训练相比，性能下降微乎其微甚至有所提高。例如，它在GSM8K基准测试中将数据需求减少了多达1,000个数据点，并取得了比完整数据集（77.04%）更好的性能（77.53%）。此外，我们展示了其在分阶段RL设置中的有效性。这项工作为数据高效的RL后训练提供了有价值的见解，并为未来优化推理数据选择的研究奠定了基础。为了方便未来的工作，我们将发布代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Diabetes Prediction and Management Using Machine Learning Approaches](https://arxiv.org/abs/2506.11501)
> *使用机器学习方法进行糖尿病预测与管理*

*Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh, Mohammad Subhi Al-Batah* | **Main category: cs.LG**

**Keywords:** 糖尿病预测, 机器学习, 神经网络, Pima印第安人糖尿病数据库, 疾病管理

**Comment:** 

> **TL;DR:** 本研究利用Pima印第安人糖尿病数据库，评估了多种机器学习算法在糖尿病风险分类中的预测能力，其中神经网络模型表现出最高的预测准确率（78.57%）。

**AI_Comments:** 本文通过比较多种机器学习模型在糖尿病预测任务上的性能，验证了机器学习技术在早期疾病筛查中的潜力。其创新点在于对多种主流算法进行了统一评估，并明确指出了神经网络在此特定数据集上的优越性。这项研究的重要性在于为医疗从业者提供了数据驱动的工具，有望实现更早的干预和更好的疾病管理。然而，研究仅基于Pima印第安人糖尿病数据库，模型的泛化能力在其他人群或更大数据集上可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 糖尿病已成为一个重要的全球健康问题，病例数量不断增加，因此迫切需要早期检测和主动管理以避免或减轻严重并发症。近年来，机器学习算法在预测糖尿病风险方面显示出巨大潜力。

**Method:** 研究使用了Pima印第安人糖尿病数据库中的768个样本，这些样本包含年龄、BMI和血糖水平等人口统计学和临床特征。评估了多种机器学习算法在糖尿病风险分类中的准确性和有效性，包括逻辑回归、决策树、随机森林、K-近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型。

**Result:** 实验结果显示，神经网络算法的预测准确率最高，达到78.57%；随机森林算法位居第二，准确率为76.30%。

**Conclusion:** 研究发现机器学习技术不仅高效，而且有潜力作为早期筛查工具，以数据驱动的方式预测糖尿病，并提供关于谁更容易受影响的有价值信息。本研究有助于实现机器学习在长期及时干预方面的潜力，从而减轻糖尿病对医疗系统的健康影响和疾病负担。

> **ai_Abstract:** 本研究旨在评估多种机器学习算法在糖尿病风险分类中的预测能力，利用包含768个样本的Pima印第安人糖尿病数据库。实验比较了逻辑回归、决策树、随机森林、K-近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型等算法的准确性。结果显示，神经网络模型以78.57%的准确率表现最佳，其次是随机森林（76.30%）。研究强调机器学习技术在早期糖尿病预测和潜在的及时干预方面的有效性和应用前景，有助于减轻糖尿病的健康负担。

> **摘要翻译:** 糖尿病已成为一个重大的全球健康问题，尤其是在许多国家病例数量不断增加的情况下。这一趋势强调了需要更加重视早期检测和主动管理，以避免或减轻这种疾病的严重健康并发症。近年来，机器学习算法在预测糖尿病风险方面显示出有前景的潜力，对从业者有益。目的：本研究重点介绍了统计和非统计机器学习方法在Pima印第安人糖尿病数据库的768个样本中对糖尿病风险分类的预测能力。该数据库包含年龄、体重指数（BMI）和血糖水平等重要的人口统计学和临床特征，这些特征在很大程度上取决于对糖尿病的脆弱性。实验评估了各种机器学习算法在糖尿病预测方面的准确性和有效性。这些算法包括逻辑回归、决策树、随机森林、K-近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络模型。结果显示，神经网络算法获得了最高的预测准确率，达到78.57%，其次是随机森林算法，以76.30%的准确率位居第二。这些发现表明，机器学习技术不仅高效，而且有潜力作为早期筛查工具，以数据驱动的方式预测糖尿病，并提供关于谁更容易受影响的有价值信息。此外，本研究有助于实现机器学习在长期及时干预方面的潜力，这是朝着减少糖尿病对医疗系统造成的健康后果和疾病负担迈出的一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [513] [Machine Learning-Based Quantification of Vesicoureteral Reflux with Enhancing Accuracy and Efficiency](https://arxiv.org/abs/2506.11508)
> *基于机器学习的膀胱输尿管反流定量分析：提高准确性和效率*

*Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Mohammad Subhi Al-Batah, Lana Yasin Al Aesa, Mohammed Hasan Abu-Arqoub, Rashiq Rafiq Marie, Firas Hussein Alsmad* | **Main category: cs.LG**

**Keywords:** 机器学习, 膀胱输尿管反流, VCUG, 图像分析, 肾盏变形

**Comment:** 

> **TL;DR:** 本研究利用机器学习对膀胱输尿管反流（VUR）进行客观量化，通过分析VCUG图像，实现了高准确率的VUR分级，并发现肾盏变形是高级别VUR的关键指标，为现有主观评估提供了标准化替代方案。

**AI_Comments:** 本研究通过引入机器学习方法，有效解决了传统膀胱输尿管反流（VUR）诊断中主观性强、变异性大的痛点。其创新之处在于将图像特征与机器学习模型相结合，实现了客观、高效的VUR定量评估。特别是识别出肾盏变形作为高级别VUR的关键指标，为临床诊断提供了新的视角和潜在的生物标志物。该研究为VUR的标准化诊断奠定了基础，具有重要的临床应用前景，尽管未来仍需扩大数据集和提高模型泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的膀胱输尿管反流（VUR）评估方法依赖主观分级系统，导致诊断存在变异性。本研究旨在利用机器学习提高诊断一致性。

**Method:** 研究回顾了113张排尿性膀胱尿道造影（VCUG）图像，并由专家对VUR严重程度进行分级。选择了9个基于图像的特征，训练了六种预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降。模型使用留一法交叉验证进行评估。

**Result:** 所有模型都实现了准确分类，没有假阳性或假阴性。通过高AUC值证实了模型对不同VUR等级的细微图像模式具有高敏感性。分析发现肾盏变形模式是高级别VUR的关键指标。

**Conclusion:** 机器学习可以为当前主观的VUR评估提供一种客观、标准化的替代方案。肾盏变形是严重VUR病例的有力预测因子。未来的研究应扩大数据集、改进成像特征并提高模型泛化能力以实现更广泛的临床应用。

> **ai_Abstract:** 本研究旨在解决膀胱输尿管反流（VUR）诊断中主观评估导致的变异性问题。通过分析113张VCUG图像，提取9个图像特征，并训练了逻辑回归、决策树、梯度提升、神经网络和随机梯度下降六种机器学习模型。结果显示，所有模型均实现了高准确度分类，无假阳性或假阴性，且对细微图像模式具有高敏感性。研究发现肾盏变形是高级别VUR的关键指标。这表明机器学习可为VUR评估提供客观、标准化的替代方案。

> **摘要翻译:** 膀胱输尿管反流（VUR）传统上采用主观分级系统进行评估，这导致诊断存在变异性。本研究调查了使用机器学习通过分析排尿性膀胱尿道造影（VCUG）图像来提高诊断一致性。共审查了113张VCUG图像，并由专家对VUR严重程度进行分级。选择了9个基于图像的特征来训练六个预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降。模型使用留一法交叉验证进行评估。分析确定肾盏变形模式是高级别VUR的关键指标。所有模型都实现了准确分类，没有假阳性或假阴性。通过高曲线下面积（AUC）值证实了模型对不同VUR等级的细微图像模式具有高敏感性。结果表明，机器学习可以为当前主观的VUR评估提供一种客观和标准化的替代方案。这些发现强调肾盏变形是严重病例的有力预测因子。未来的研究应旨在扩大数据集、改进成像特征，并提高模型泛化能力以实现更广泛的临床使用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [517] [Task-Driven Discrete Representation Learning](https://arxiv.org/abs/2506.11511)
> *任务驱动的离散表示学习*

*Tung-Long Vuong* | **Main category: cs.LG**

**Keywords:** 离散表示学习, 任务驱动, 统一框架, 理论分析, 下游任务

**Comment:** 

> **TL;DR:** 大多数离散表示学习（DRL）侧重于生成；本文提出一个任务驱动的DRL框架，分析其特性，并展示其在不同应用中的有效性。

**AI_Comments:** 该论文将离散表示学习（DRL）的范式从纯粹的生成式设置转变为更实用的任务驱动视角，这具有创新性。通过纳入表示能力和样本复杂度之间权衡的理论分析，为理解离散表示如何影响任务性能提供了更深入的洞察，从而增加了显著价值。这种方法可能导致更健壮和针对特定任务的DRL模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度离散表示学习（DRL）主要关注生成式设置，且离散表示的“好坏”定义模糊；离散表示的特性及其对特定任务的益处也研究不足。

**Method:** 提出一个统一的框架，从任务驱动的角度探讨离散特征对下游任务的有用性；并提供了表示能力和样本复杂度之间权衡的理论分析。

**Result:** 该框架在各种应用中展现出灵活性和有效性。

**Conclusion:** 本文提出了一个任务驱动的离散表示学习框架，并从理论上分析了其特性，实验证明了其在多种应用中的有效性。

> **ai_Abstract:** 本文旨在解决当前深度离散表示学习（DRL）框架主要侧重于生成任务且表示质量定义模糊的局限性。它提出了一个新颖的任务驱动统一框架，用于评估离散特征对下游任务的实用性，并将生成视为其中一种应用。该工作还包括对表示能力和样本复杂度之间权衡的理论分析，阐明了离散表示的利用如何影响任务性能。该框架的灵活性和有效性在多种应用中得到了展示。

> **摘要翻译:** 近年来，深度离散表示学习（DRL）在各个领域取得了显著成功。大多数DRL框架（例如广泛使用的VQ-VAE及其变体）主要集中在生成式设置中，其中表示的质量通过其生成的保真度隐式衡量。事实上，离散表示的优劣在文献中仍然定义模糊。在这项工作中，我们采用一种实用方法，从任务驱动的角度审视DRL。我们提出了一个统一的框架，探索离散特征与下游任务相关的有用性，其中生成自然地被视为一种可能的应用。在这种背景下，离散表示的特性以及它们如何使某些任务受益也相对未被充分研究。因此，我们提供了关于表示能力和样本复杂度之间权衡的额外理论分析，阐明了离散表示的利用如何影响任务性能。最后，我们展示了我们框架在不同应用中的灵活性和有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [521] [Prioritizing Alignment Paradigms over Task-Specific Model Customization in Time-Series LLMs](https://arxiv.org/abs/2506.11512)
> *在时间序列大型语言模型中优先考虑对齐范式而非任务特定模型定制*

*Wei Li, Yunyao Cheng, Xinli Hao, Chaohong Ma, Yuxuan Liang, Bin Yang, Christian S. Jensen, Xiaofeng Meng* | **Main category: cs.LG**

**Keywords:** 时间序列LLMs, 对齐范式, 时间序列原语, 模型定制, 推理

**Comment:** 

> **TL;DR:** 该论文提出在时间序列大型语言模型中，应优先考虑以数据为中心的对齐范式，而非任务特定的模型定制，以改善推理能力。

**AI_Comments:** 这篇论文通过将焦点从任务特定定制转移到以数据为中心的时间序列大型语言模型对齐范式，提供了一个新颖的视角。其创新之处在于识别了时间序列原语被忽视的重要性，并提出了一个结构化的方法来利用它们。这可能显著提高大型语言模型在时间序列应用中的效率和灵活性，有望带来更鲁棒和泛化能力更强的模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列大型语言模型方法侧重于任务特定的定制，忽略了内在的时间序列原语，导致推理成本高、不灵活且效率低下。本论文倡导将重点转移到优先与这些原语进行对齐。

**Method:** 本文提出了三种对齐范式：内射对齐（优先考虑领域原语）、桥接对齐（优先考虑特征原语）和内部对齐（优先考虑表示原语）。它还建议实践者采用面向对齐的方法，并对现有文献进行分类。

**Result:** 本文提出了一种新方法，通过在任务工程之前系统地考虑数据的内在结构，激活大型语言模型的时间序列推理能力，从而实现经济、灵活和高效的推理。本文还概述了有前景的研究方向。

**Conclusion:** 本文总结道，为了克服当前方法的局限性并使大型语言模型在时间序列推理中更经济、灵活和高效，应将重点从任务特定定制转移到优先考虑基于时间序列原语的对齐范式。

> **ai_Abstract:** 这篇立场论文主张在时间序列大型语言模型推理中进行范式转变。它倡导优先考虑与内在时间序列原语（领域、特征、表示）的对齐，而非任务特定的模型定制。论文提出了三种对齐范式——内射、桥接和内部对齐——以实现更经济、灵活和高效的时间序列推理，从而解决当前方法成本高、不灵活等局限性。论文还为实践者提供了指导，并概述了未来的研究方向。

> **摘要翻译:** 近期大型语言模型（LLMs）的进展为时间序列推理在各种现实世界应用中，包括医疗、金融和时空领域，带来了前所未有的能力。然而，现有方法通常侧重于任务特定的模型定制，例如预测和异常检测，而忽略了数据本身，即时间序列原语，这对于深入推理至关重要。这篇立场论文倡导在时间序列LLMs推理方法上进行根本性转变：优先考虑基于时间序列数据内在原语的对齐范式，而非任务特定的模型定制。这种重新对齐通过在任务工程之前系统地考虑数据的内在结构，解决了当前时间序列推理方法的核心局限性，这些方法通常成本高昂、不灵活且效率低下。为此，我们提出了三种对齐范式：内射对齐（Injective Alignment）、桥接对齐（Bridging Alignment）和内部对齐（Internal Alignment），它们分别通过优先考虑时间序列原语的不同方面：领域、特征和表示来强调，以激活LLMs的时间序列推理能力，从而实现经济、灵活和高效的推理。我们进一步建议实践者采用面向对齐的方法，利用此指导来选择合适的对齐范式。此外，我们将相关文献归类到这些对齐范式中，并概述了有前景的研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [525] [Brewing Knowledge in Context: Distillation Perspectives on In-Context Learning](https://arxiv.org/abs/2506.11516)
> *上下文中的知识蒸馏：情境学习的蒸馏视角*

*Chengye Li, Haiyun Liu, Yuanxi Li* | **Main category: cs.LG**

**Keywords:** 情境学习, 知识蒸馏, 大型语言模型, 泛化界限, 提示工程

**Comment:** 10 main pages, 10 page appendix

> **TL;DR:** 情境学习（ICL）可以被视为隐式知识蒸馏。本文提出了一种新的理论框架，推导了泛化界限，并解释了经验现象，为提示工程提供了见解。

**AI_Comments:** 本文通过将其与知识蒸馏联系起来，为理解情境学习（ICL）提供了一个新颖的理论视角，考虑到ICL在经验上的成功但理论上的不透明性，这是一个重要的贡献。将推理时注意力形式化为蒸馏过程具有创新性，并为未来提示工程的实际进展提供了坚实的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管情境学习（ICL）取得了经验上的成功，但其背后的机制仍然知之甚少，这限制了我们解释、改进和可靠应用它的能力。

**Method:** 本文提出了一种新的理论视角，将情境学习（ICL）解释为一种隐式知识蒸馏（KD）形式，其中提示演示引导模型在推理过程中形成一个任务特定的参考模型。在此视图下，推导了一个基于Rademacher复杂度的泛化界限，并证明了蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长。

**Result:** 该理论框架解释了几种经验现象，并统一了先前的基于梯度和分布的分析。蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长。

**Conclusion:** 据我们所知，这是首次将推理时注意力形式化为蒸馏过程，为未来的提示工程和自动化演示选择提供了理论见解。

> **ai_Abstract:** 本文提出了一种新颖的理论框架，将情境学习（ICL）视为一种隐式知识蒸馏过程。它推导了一个基于Rademacher复杂度的泛化界限，表明蒸馏权重的偏差随提示和目标分布之间的最大均值差异（MMD）线性增长。该框架统一了现有分析并解释了ICL的经验现象，为提示工程和演示选择提供了基础性见解。

> **摘要翻译:** 情境学习（ICL）允许大型语言模型（LLMs）在不更新权重的情况下解决新任务。尽管其在经验上取得了成功，但ICL背后的机制仍然知之甚少，这限制了我们解释、改进和可靠应用它的能力。在本文中，我们提出了一种新的理论视角，将ICL解释为一种隐式知识蒸馏（KD）形式，其中提示演示引导模型在推理过程中形成一个任务特定的参考模型。在此观点下，我们推导了一个基于Rademacher复杂度的泛化界限，并证明了蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长。这个理论框架解释了几种经验现象，并统一了先前的基于梯度和分布的分析。据我们所知，这是首次将推理时注意力形式化为蒸馏过程，为未来的提示工程和自动化演示选择提供了理论见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [529] [Delayformer: spatiotemporal transformation for predicting high-dimensional dynamics](https://arxiv.org/abs/2506.11528)
> *Delayformer：用于预测高维动态的时空变换*

*Zijian Wang, Peng Tao, Luonan Chen* | **Main category: cs.LG**

**Keywords:** 时间序列预测, 高维动态, 延迟嵌入, Transformer, 时空变换

**Comment:** This paper is currently under review

> **TL;DR:** Delayformer是一个新的框架，通过时空信息变换和延迟嵌入预测高维时间序列，优于现有SOTA方法。

**AI_Comments:** Delayformer的创新点在于将动力系统的延迟嵌入理论与Transformer的强大表示能力相结合，通过预测“系统状态”而非单个变量来处理高维时间序列的非线性和复杂交互。这提供了一个新的视角和有效的解决方案，有望成为时间序列预测领域的基础模型。

<details>
  <summary>Details</summary>

**Motivation:** 在有限和有噪声数据下，准确预测高维系统中所有变量的动态是一个挑战，因为它们的非线性和复杂交互，现有方法表现不佳。

**Method:** 本研究引入了Delayformer框架。它通过开发一种新颖的多元时空信息（mvSTI）变换来同时预测所有变量的动态，该变换将每个观测变量转化为延迟嵌入状态（向量），并进一步交叉学习来自不同变量的这些状态。Delayformer利用一个共享的Visual Transformer (ViT) 编码器以延迟嵌入形式交叉表示动态状态，然后使用不同的线性解码器预测下一个状态，即并行预测所有原始变量。

**Result:** Delayformer在合成数据集和真实世界数据集上的预测任务中优于当前最先进的方法。其作为基础时间序列模型的潜力通过跨领域预测任务得到证明，突出了其广泛适用性。

**Conclusion:** Delayformer通过将系统状态而非单个变量作为预测对象，并结合延迟嵌入理论和Transformer的表示能力，成功克服了高维时间序列预测中的非线性和交叉交互问题，并在多种场景下展现出优越的性能和广泛的适用性。

> **ai_Abstract:** Delayformer是一个用于预测高维动态的新框架，旨在解决现有方法在有限和噪声数据下对非线性、复杂交互系统预测不佳的问题。它通过引入多元时空信息（mvSTI）变换，将观测变量转化为延迟嵌入状态，并利用共享的Visual Transformer编码器和线性解码器来预测系统状态。该方法在理论上和计算上克服了高维动态预测的挑战，并在合成和真实数据集上超越了现有SOTA方法，展现出作为基础时间序列模型的广泛适用性。

> **摘要翻译:** 预测时间序列在各种科学和工程领域中都至关重要。然而，在数据有限且噪声较大的情况下，由于高维系统变量的非线性和复杂的相互作用，准确预测所有变量的动态是一项具有挑战性的任务。包括深度学习方法在内的当前方法在这种情况下往往表现不佳。本研究引入了Delayformer框架，通过开发一种新颖的多元时空信息（mvSTI）变换来同时预测所有变量的动态，该变换将每个观测变量转化为延迟嵌入状态（向量），并进一步交叉学习来自不同变量的这些状态。从动力系统角度看，Delayformer预测的是系统状态而非单个变量，从而在理论和计算上克服了非线性和交叉作用问题。具体而言，它首先利用一个单一的共享视觉Transformer（ViT）编码器以延迟嵌入形式交叉表示观测变量的动态状态，然后采用不同的线性解码器预测下一个状态，即等效地并行预测所有原始变量。通过利用延迟嵌入理论的理论基础和Transformer的表示能力，Delayformer在合成和真实世界数据集上的预测任务中都优于当前最先进的方法。此外，通过跨领域预测任务，展示了Delayformer作为基础时间序列模型的潜力，突显了其在各种场景中的广泛适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [534] [Improving Multimodal Learning Balance and Sufficiency through Data Remixing](https://arxiv.org/abs/2506.11550)
> *通过数据重组改进多模态学习的平衡性和充分性*

*Xiaoyu Ma, Hao Chen, Yongjian Deng* | **Main category: cs.LG**

**Keywords:** 多模态学习, 数据重组, 模态平衡, 模态充分性, 梯度对齐

**Comment:** ICML2025

> **TL;DR:** 针对多模态学习中模态懒惰和冲突导致的学习不足与不平衡问题，本文首次提出数据重组方法，通过解耦数据、过滤难样本和批级重组来提升单模态学习充分性并实现多模态平衡，显著提升了准确率。

**AI_Comments:** 本文的创新点在于首次从数据层面，而非传统的模型结构或优化目标层面，解决多模态学习的平衡性和充分性问题。通过数据重组的策略，有效缓解了模态间优化轨迹差异带来的负面影响，为多模态学习提供了一种新颖且高效的解决方案。其兼容性和不增加额外开销的特点也使其具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在多模态学习中未能同时实现单模态学习的充分性和多模态之间的平衡，导致模态懒惰和模态冲突。

**Method:** 提出多模态数据重组（Data Remixing），包括：1) 解耦多模态数据并过滤每种模态的难样本以缓解模态不平衡；2) 然后进行批级重组以对齐梯度方向并避免跨模态干扰，从而增强单模态学习的充分性。

**Result:** 该方法可与现有方法无缝集成，在CREMAD数据集上准确率提高了约6.50%，在Kinetic-Sounds数据集上提高了3.41%，且无需扩展训练集或增加推理时的计算开销。

**Conclusion:** 通过数据重组，本研究有效解决了多模态学习中的平衡性和充分性问题，显著提升了模型性能，且具有良好的兼容性和效率。

> **ai_Abstract:** 本文提出一种名为“多模态数据重组”（Data Remixing）的新方法，旨在解决多模态学习中普遍存在的模态惰性、模态冲突以及由此导致的学习不足和不平衡问题。该方法通过解耦多模态数据、针对性过滤每种模态的难样本来缓解模态间不平衡，并通过批级重组来对齐梯度方向、避免跨模态干扰，从而提升单模态学习的充分性。实验证明，该方法能有效提升现有模型的准确率，且不增加额外开销。

> **摘要翻译:** 不同的模态在优化轨迹上存在相当大的差距，包括速度和路径，这在联合训练多模态模型时会导致模态惰性（modality laziness）和模态冲突（modality clash），从而导致多模态学习的不足和不平衡。现有方法侧重于通过添加模态特定优化目标、对齐其优化速度或分解多模态学习以增强单模态学习来强制弱模态。这些方法未能同时实现单模态的充分性和多模态的平衡。在本文中，我们首次通过提出多模态数据重组（Data Remixing）解决了这两个问题，包括解耦多模态数据和过滤每种模态的难样本以缓解模态不平衡；然后进行批级重组以对齐梯度方向并避免跨模态干扰，从而增强单模态学习的充分性。实验结果表明，我们的方法可以与现有方法无缝集成，在CREMAD数据集上准确率提高了约6.50%$\\uparrow$，在Kinetic-Sounds数据集上提高了3.41%$\\uparrow$，且无需扩展训练集或在推理时增加额外的计算开销。源代码可在\href{https://github.com/MatthewMaxy/Remix_ICML2025}{Data Remixing}获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [536] [Learn to Preserve Personality: Federated Foundation Models in Recommendations](https://arxiv.org/abs/2506.11563)
> *学习保留个性：推荐系统中的联邦基础模型*

*Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang* | **Main category: cs.LG**

**Keywords:** 联邦基础模型, 推荐系统, 个性化, 泛化, 用户个性

**Comment:** 14 pages, 3 figures, conference, position paper

> **TL;DR:** 本文提出联邦基础模型（FFM）作为一种新的学习范式，用于推荐系统中在去中心化过程中平衡泛化与个性化，以保留用户个性并实现用户中心化控制。

**AI_Comments:** 本文引入了一个有趣的概念框架，将联邦学习原则应用于推荐系统中的基础模型。其主要创新在于明确解决了“个性保留”方面，旨在实现更以用户为中心和去中心化的方法。尽管是一篇立场论文，但它为未来个性化代理描绘了一个引人注目的愿景。挑战将在于这种复杂分布式系统的实际实施和评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有基础模型（FM）在泛化和个性化之间存在权衡困境。联邦基础模型（FFM）提供了一种通过去中心化过程将共享知识与个体特定适应解耦的结构化方法。推荐系统因其依赖反映独特用户特征的丰富隐式反馈，成为FFM的理想试验台。

**Method:** 本文讨论了一种新颖的学习范式，其中联邦基础模型（FFM）不仅利用其泛化能力，而且专门设计用于在推荐上下文中保留用户个性的完整性。这是一种通过去中心化过程解耦共享知识和个体适应的方法。

**Result:** Not mentioned in abstract

**Conclusion:** 联邦基础模型（FFM）有望实现一个以用户为中心、去中心化的系统，其中个人可以掌控其个性化代理。未来的个人代理将由个性化自适应FM提供支持，指导用户内容决策。

> **ai_Abstract:** 这篇立场论文探讨了现有基础模型（FM）在泛化与个性化之间取得平衡的挑战，特别是在推荐系统中。它提出联邦基础模型（FFM）作为一种新颖的学习范式，通过去中心化过程将共享知识与个体用户适应解耦。其核心目标是利用FFM的泛化能力同时保留用户个性，并展望了由个性化自适应FM驱动的未来用户中心化代理，赋予个体对其决策的控制权。

> **摘要翻译:** 现有基础模型（FM）的核心学习挑战是在泛化与个性化之间取得平衡，这一困境已通过各种参数高效的适应技术得到凸显。联邦基础模型（FFM）提供了一种结构化方法，通过去中心化过程将共享知识与个体特定适应解耦。推荐系统是FFM的完美试验台，因为它们依赖于反映独特用户特征的丰富隐式反馈。这篇立场论文讨论了一种新颖的学习范式，其中FFM不仅利用其泛化能力，而且专门设计用于保留用户个性的完整性，并在推荐上下文中进行了详尽阐述。我们设想未来的个人代理，由个性化自适应FM提供支持，指导用户内容决策。这种架构承诺了一个以用户为中心、去中心化的系统，个人可以掌控其个性化代理。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [538] [A Comparative Analysis of Influence Signals for Data Debugging](https://arxiv.org/abs/2506.11584)
> *数据调试中影响力信号的比较分析*

*Nikolaos Myrtakis, Ioannis Tsamardinos, Vassilis Christophides* | **Main category: cs.LG**

**Keywords:** 数据调试, 影响力信号, 错误标签, 异常检测, 机器学习

**Comment:** Accepted and presented at the Data-centric Machine Learning Research
  (DMLR) Workshop at ICML 2024

> **TL;DR:** 本文对用于调试训练数据的现有影响力信号进行了比较评估，发现部分信号能有效检测错误标签，但无一能检测异常样本，且现有信号未考虑训练动态和存在影响力抵消效应。

**AI_Comments:** 这项研究通过系统性的比较分析，填补了现有影响力信号在不同条件下的性能评估空白，具有重要的实践意义。它明确指出了现有信号在异常检测和考虑训练动态方面的不足，这为未来的研究提供了清晰的方向。文章的贡献在于揭示了当前数据调试方法面临的挑战，并强调了开发更鲁棒、更全面的影响力评估方法的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 提高训练样本的质量对于提升机器学习模型的可靠性和性能至关重要。尽管已有多种基于影响力的信号被提出用于识别训练数据中的错误标签和异常样本，但缺乏在统一影响力估计器、不同数据模态和深度学习模型下，对这些信号在检测不同类型缺陷方面的有效性进行实验研究。

**Method:** 本文对现有基于影响力的信号（如Self-Influence, Average Absolute Influence, Marginal Influence, GD-class）进行了比较评估。评估在一个共同的影响力估计器（如TraceIn）下进行，涵盖了不同的数据模态（图像和表格）以及深度学习模型（从头训练或基础模型）。

**Result:** 实验结果表明，Self-Influence等信号能有效检测错误标签样本，但现有信号均无法检测异常样本。此外，现有信号未考虑训练动态（即样本对模型的影响在训练期间如何变化），且部分信号存在影响力抵消效应（即由于未签名分数的累积导致影响力得分为零），从而导致误导性的影响力归因。

**Conclusion:** 现有基于影响力的信号在检测训练数据中的异常样本方面存在局限性，并且未能充分考虑训练动态，也可能受到影响力抵消效应的影响。

> **ai_Abstract:** 本文对用于调试机器学习模型训练数据的现有影响力信号进行了比较评估。研究发现，虽然Self-Influence等信号能有效检测错误标签样本，但现有信号在检测异常样本方面表现不足。此外，现有信号未考虑训练动态，并且可能因影响力抵消效应而产生误导性结果。这项工作揭示了当前影响力信号的局限性，并强调了未来研究的潜在方向。

> **摘要翻译:** 提高训练样本的质量对于提升机器学习模型的可靠性和性能至关重要。本文对用于调试训练数据的基于影响力的信号进行了比较评估。这些信号可能在构建模型时，从潜在的嘈杂训练集中识别出错误标签和异常样本，从而减轻对专用故障检测器的需求。尽管最近文献中提出了几种基于影响力的信号（例如，Self-Influence、Average Absolute Influence、Marginal Influence、GD-class），但尚无实验研究评估它们在统一影响力估计器（例如TraceIn）、不同数据模态（图像和表格）以及深度学习模型（从头训练或基础模型）下，检测不同类型缺陷（例如，错误标签和异常样本）的能力。通过大量实验，我们发现Self-Influence等信号能有效检测错误标签样本，但现有信号均无法检测异常样本。现有信号未考虑训练动态，即样本对模型的影响在训练期间如何变化，而某些信号则陷入影响力抵消效应，即由于未签名分数的累积导致影响力得分为零，从而导致误导性的影响力归因。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [542] [KCES: Training-Free Defense for Robust Graph Neural Networks via Kernel Complexity](https://arxiv.org/abs/2506.11611)
> *KCES：通过核复杂度实现鲁棒图神经网络的免训练防御*

*Yaning Jia, Shenyang Deng, Chiyu Ma, Yaoqing Yang, Soroush Vosoughi* | **Main category: cs.LG**

**Keywords:** 图神经网络, 对抗性攻击, 鲁棒性, 核复杂度, 边净化

**Comment:** 

> **TL;DR:** KCES是一种免训练、模型无关的图神经网络防御框架，通过移除高核复杂度得分的边来增强GNN的鲁棒性，有效对抗对抗性攻击。

**AI_Comments:** KCES的创新性在于其“免训练”和“模型无关”的特性，这大大降低了其应用门槛和计算成本。通过引入“图核复杂度”这一新颖的、基于理论的度量，KCES提供了一种有原则的方法来识别和消除对抗性扰动，而不是依赖于启发式规则。其即插即用的模块化设计也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在图任务中取得了巨大成功，但它们极易受到微小、难以察觉的扰动和对抗性攻击。现有的许多防御方法依赖启发式指标，过度拟合特定攻击模式，并存在高计算复杂度的问题。

**Method:** 本文提出了基于核复杂度的边净化（KCES）方法，这是一个免训练、模型无关的防御框架。KCES利用图核复杂度（GKC）这一新颖指标，该指标源自图的Gram矩阵，通过其测试误差界限来表征GNN的泛化能力。基于GKC，KCES为每条边定义了一个KC分数，衡量移除该边时GKC的变化。KC分数高的边（通常由对抗性扰动引入）会被修剪以减轻其有害影响，从而提高GNN的鲁棒性。KCES还可以作为即插即用模块与现有防御策略无缝集成，无需训练。

**Result:** KCES持续增强了GNN的鲁棒性，超越了最先进的基线方法，并放大了现有防御措施的有效性。

**Conclusion:** KCES为保护GNN提供了一个有原则且高效的解决方案。

> **ai_Abstract:** 本文提出KCES（Kernel Complexity-Based Edge Sanitization），一种免训练、模型无关的GNN防御框架，旨在解决现有方法计算复杂和对特定攻击模式过拟合的问题。KCES引入图核复杂度（GKC）指标来衡量GNN的泛化能力，并基于此定义KC分数来识别并修剪对抗性扰动引入的高风险边。实验证明，KCES能有效提升GNN的鲁棒性，优于现有基线，并能与现有防御方法协同工作，提供了一个原则性且高效的GNN安全解决方案。

> **摘要翻译:** 图神经网络（GNNs）在各种基于图的任务中取得了令人瞩目的成功，但它们仍然极易受到微小、难以察觉的扰动和对抗性攻击。尽管已经提出了许多防御方法来解决这些漏洞，但许多方法依赖启发式指标，过度拟合特定的攻击模式，并存在高计算复杂度的问题。在本文中，我们提出了基于核复杂度的边净化（KCES），这是一个免训练、模型无关的防御框架。KCES利用图核复杂度（GKC），这是一个源自图的Gram矩阵的新颖指标，通过其测试误差界限来表征GNN的泛化能力。基于GKC，我们为每条边定义了一个KC分数，衡量移除该边时GKC的变化。具有高KC分数的边（通常由对抗性扰动引入）会被修剪以减轻其有害影响，从而增强GNN的鲁棒性。KCES还可以作为即插即用模块与现有防御策略无缝集成，无需训练。理论分析和广泛的实验表明，KCES持续增强了GNN的鲁棒性，超越了最先进的基线方法，并放大了现有防御措施的有效性，为保护GNN提供了一个有原则且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [545] [Model Organisms for Emergent Misalignment](https://arxiv.org/abs/2506.11613)
> *涌现性失对齐的模型生物*

*Edward Turner, Anna Soligo, Mia Taylor, Senthooran Rajamanoharan, Neel Nanda* | **Main category: cs.LG**

**Keywords:** 涌现性失对齐, 模型生物, 大型语言模型, 对齐, AI安全

**Comment:** 

> **TL;DR:** 本文通过创建改进的模型生物，在更小的模型上用更简单的方法（LoRA）重现并研究了涌现性失对齐（EM）现象，并发现了一个与行为失对齐相关的机制相变，为理解和缓解大型语言模型中的对齐风险奠定了基础。

**AI_Comments:** 本文的创新之处在于成功构建了更高效、更易于研究的“模型生物”，极大地降低了研究涌现性失对齐现象的成本和复杂性。通过在更小的模型上使用LoRA等简单方法复现并稳定观察EM，并进一步识别出相关的机制相变，为深入理解这一重要安全问题提供了关键工具和方向。这项工作对于推动AI安全领域，特别是大型语言模型的对齐研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究发现，对大型语言模型进行窄范围的有害数据集微调会导致其广泛失对齐（涌现性失对齐，EM），这出乎专家意料，表明我们对模型对齐的理解存在关键空白。鉴于大型语言模型对齐对于前沿AI安全至关重要，但EM现象揭示了我们在这方面还有多远，因此本研究旨在加深理解并提供未来研究的工具。

**Method:** 本研究使用新的窄范围失对齐数据集，创建了一组改进的模型生物，这些模型生物实现了99%的一致性（之前为67%），适用于更小的0.5B参数模型（之前为32B），并且使用单个rank-1 LoRA适配器即可诱导失对齐。研究者在不同模型大小、三种模型家族和多种训练协议（包括完全监督微调）下，证明了EM的鲁棒性。利用这些更清晰的模型生物，研究者分离出一个机制相变，并证明其与所有研究生物中鲁棒的行为相变相对应。

**Result:** 研究成功创建了改进的模型生物，其一致性达到99%（相比之前的67%），并且能够在更小的0.5B参数模型上（相比之前的32B）通过单个rank-1 LoRA适配器诱导失对齐。研究证明了涌现性失对齐（EM）在不同模型大小、三种模型家族和多种训练协议（包括完全监督微调）中均能鲁棒地发生。此外，研究还分离出了一个机制相变，并证明其与所有研究模型生物中鲁棒的行为相变相对应。

**Conclusion:** 通过提炼出能够隔离最小对齐妥协变化及其学习方式的清晰模型生物，本研究为未来理解和缓解大型语言模型中的对齐风险奠定了基础。

> **ai_Abstract:** 本文针对大型语言模型中新发现的“涌现性失对齐”（Emergent Misalignment, EM）现象，旨在加深理解并提供研究工具。研究通过构建新的、更高效的模型生物（实现99%一致性，适用于0.5B小模型，并使用LoRA诱导失对齐），证明了EM在多种模型和训练条件下均能鲁棒发生。进一步，论文成功分离出一个与行为失对齐紧密关联的机制相变。这些发现为未来深入研究和缓解大型语言模型对齐风险奠定了重要基础。

> **摘要翻译:** 最近的工作发现了涌现性失对齐（EM）：对大型语言模型在窄范围有害数据集上进行微调会导致它们广泛失对齐。在发表前对专家的调查显示，这非常出乎意料，表明我们对模型对齐的理解存在关键空白。在这项工作中，我们既增进了理解，也为未来的研究提供了工具。利用新的窄范围失对齐数据集，我们创建了一组改进的模型生物，它们实现了99%的一致性（之前为67%），适用于更小的0.5B参数模型（之前为32B），并且使用单个rank-1 LoRA适配器即可诱导失对齐。我们证明了EM在不同模型大小、三种模型家族和多种训练协议（包括完全监督微调）中均能鲁棒地发生。利用这些更清晰的模型生物，我们分离出一个机制相变，并证明其与所有研究生物中鲁棒的行为相变相对应。对齐大型语言模型对于前沿AI安全至关重要，然而EM揭示了我们离稳健实现这一目标还有多远。通过提炼出能够隔离最小对齐妥协变化及其学习方式的清晰模型生物，我们为未来理解和缓解大型语言模型中的对齐风险奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [547] [Machine Unlearning for Robust DNNs: Attribution-Guided Partitioning and Neuron Pruning in Noisy Environments](https://arxiv.org/abs/2506.11615)
> *鲁棒DNN的机器遗忘：噪声环境下的归因引导分区和神经元剪枝*

*Deliang Jin, Gang Chen, Shuo Feng, Yufeng Ling, Haoran Zhu* | **Main category: cs.LG**

**Keywords:** 机器遗忘, 深度神经网络, 噪声鲁棒性, 归因引导, 神经元剪枝

**Comment:** 

> **TL;DR:** 本文提出一种新的机器遗忘框架，通过归因引导的数据分区和神经元剪枝，在不进行完全重训练或明确噪声建模的情况下，显著提高了深度神经网络在噪声环境下的鲁棒性和泛化性能。

**AI_Comments:** 该研究创新性地将机器遗忘的思想应用于噪声鲁棒DNNs，通过结合数据层面的选择（归因引导分区）和模型层面的优化（神经元剪枝），有效地解决了传统方法在处理噪声数据时效率低下和假设严格的问题。其无需完全重训练和明确噪声建模的特性，使其在大规模模型和复杂噪声环境下的应用前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络的性能易受噪声或损坏的训练数据严重影响。传统的噪声缓解方法通常依赖于对噪声分布的明确假设或需要大量重训练，这对于大型模型来说可能不切实际。

**Method:** 本文提出一个整合了归因引导数据分区、判别性神经元剪枝和目标微调的新型框架。具体地，利用基于梯度的归因概率性区分高质量和潜在损坏样本；然后应用基于回归的敏感性分析识别并剪枝对噪声最脆弱的神经元；最后在高质量数据子集上对所得网络进行微调，以恢复和增强泛化性能。

**Result:** 该方法在CIFAR-10图像分类和语音识别等代表性任务中，在各种噪声水平下，均在准确性和效率上取得了显著提升。例如，在注入标签噪声的CIFAR-10上，比标准重训练的绝对准确率提高了约10%，同时在某些设置下将重训练时间减少了高达47%。

**Conclusion:** 该集成的、受遗忘启发的框架通过结合数据级遗忘与模型级适应，避免了完全模型重训练或明确噪声建模的需要，在噪声环境中实现了有效的鲁棒泛化。

> **ai_Abstract:** 本文提出一种新颖的机器遗忘框架，旨在提高深度神经网络在噪声环境下的鲁棒性。该框架通过归因引导的数据分区识别并隔离高质量数据，随后通过敏感性分析剪枝受噪声影响的神经元，并最终在高质量数据上进行微调。该方法避免了传统方法中对噪声分布的严格假设和昂贵的完整模型重训练，通过结合数据和模型层面的适应性，显著提升了模型在噪声环境下的准确性和效率，并在多个任务上展现了优越性。

> **摘要翻译:** 深度神经网络（DNNs）在不同领域取得了显著成功，但其性能可能会因噪声或损坏的训练数据而严重下降。传统的噪声缓解方法通常依赖于对噪声分布的明确假设，或者需要大量的重新训练，这对于大型模型来说可能不切实际。受机器遗忘原则的启发，我们提出了一种新颖的框架，该框架集成了归因引导的数据分区、判别性神经元剪枝和目标微调，以减轻噪声样本的影响。我们的方法采用基于梯度的归因来概率性地区分高质量样本和潜在损坏样本，而无需对噪声施加限制性假设。然后，它应用基于回归的敏感性分析来识别并剪枝对噪声最脆弱的神经元。最后，在高质量数据子集上对所得网络进行微调，以有效地恢复和增强其泛化性能。这种集成的、受遗忘启发的框架与传统的噪声鲁棒学习方法相比具有多个优势。值得注意的是，它将数据级遗忘与模型级适应相结合，从而避免了完全模型重训练或明确噪声建模的需要。我们在各种噪声水平下，在代表性任务（例如，CIFAR-10图像分类和语音识别）上评估了我们的方法，并观察到在准确性和效率方面都有显著提高。例如，我们的框架在注入标签噪声的CIFAR-10上比标准重新训练的绝对准确率提高了约10%，同时在某些设置下将重新训练时间减少了高达47%。这些结果证明了所提出方法在噪声环境中实现鲁棒泛化的有效性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [549] [Convergent Linear Representations of Emergent Misalignment](https://arxiv.org/abs/2506.11618)
> *涌现性未对齐的收敛线性表示*

*Anna Soligo, Edward Turner, Senthooran Rajamanoharan, Neel Nanda* | **Main category: cs.LG**

**Keywords:** 涌现性未对齐, 大语言模型, 模型对齐, 线性表示, 微调

**Comment:** 

> **TL;DR:** 研究发现，通过窄数据集微调导致的大语言模型“涌现性未对齐”行为，其内在机制是不同的未对齐模型会收敛到相似的未对齐表示，并可以通过提取的“未对齐方向”进行有效消除。

**AI_Comments:** 本文通过对“涌现性未对齐”现象的深入分析，揭示了其潜在的线性表示收敛性，具有重要的创新性。通过提取“未对齐方向”并进行有效消除的实验，为未来缓解模型未对齐提供了新的思路和工具。对适配器的直接解释也为理解模型行为提供了更精细的视角。这项工作对于提升大模型对齐性研究具有显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在窄数据集上微调时会出现“涌现性未对齐”行为，这种行为会泛化到训练域之外，但其潜在机制尚不清楚，这表明在模型对齐方面存在关键知识空白。

**Method:** 本文训练并研究了一个最小模型（使用9个rank-1适配器对Qwen2.5-14B-Instruct进行涌现性未对齐）。通过从一个微调模型的激活中提取“未对齐方向”，并用其有效消除使用更高维度LoRA和不同数据集的微调模型的未对齐行为。此外，利用rank-1 LoRA的标量隐藏状态，直接解释了微调适配器。

**Result:** 研究发现，不同的涌现性未对齐模型会收敛到相似的未对齐表示。提取的“未对齐方向”可以有效消除未对齐行为。在分析微调适配器时发现，有六个适配器导致了通用未对齐，而另外两个则专门导致了仅在微调域内的未对齐。

**Conclusion:** 通过深入理解涌现性未对齐背后的机制，有望更好地理解和更普遍地缓解模型未对齐问题。

> **ai_Abstract:** 本研究探讨了大型语言模型在窄数据集上微调时出现的“涌现性未对齐”现象。通过对一个最小模型Qwen2.5-14B-Instruct（使用9个rank-1适配器）进行研究，发现不同的未对齐模型会收敛到相似的未对齐表示。文章通过提取“未对齐方向”并成功消除其他微调模型的未对齐行为来证明了这一点。进一步的适配器解释实验显示，六个适配器导致了通用未对齐，而两个则专注于特定领域的未对齐。本工作旨在通过揭示这些机制，为更好地理解和缓解模型未对齐提供基础。

> **摘要翻译:** 将大型语言模型在狭窄数据集上进行微调可能会导致它们产生广泛的未对齐行为：这是一种被称为涌现性未对齐的现象。然而，这种未对齐的潜在机制以及它为何会泛化到训练领域之外，目前尚不清楚，这表明我们在模型对齐方面的知识存在关键空白。在这项工作中，我们训练并研究了一个最小模型生物，它仅使用9个rank-1适配器来使Qwen2.5-14B-Instruct涌现性未对齐。通过研究，我们发现不同的涌现性未对齐模型收敛到相似的未对齐表示。我们通过从一个微调模型的激活中提取“未对齐方向”来证明这种收敛性，并使用它有效地消除使用更高维度LoRA和不同数据集的微调模型的未对齐行为。利用rank-1 LoRA的标量隐藏状态，我们进一步提出了一系列实验，用于直接解释微调适配器，结果显示其中六个适配器导致了通用未对齐，而另外两个则专门导致了仅在微调域内的未对齐。涌现性未对齐是模型不期望和意外行为的一个特别显著的例子，通过增进我们对其背后机制的理解，我们希望能够更好地理解和更普遍地缓解未对齐问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [551] [Physically-informed change-point kernels for structural dynamics](https://arxiv.org/abs/2506.11625)
> *结构动力学中物理信息驱动的变点核*

*Daniel James Pitchforth, Matthew Rhys Jones, Samuel John Gibson, Elizabeth Jane Cross* | **Main category: cs.LG**

**Keywords:** 物理信息, 变点核, 高斯过程, 结构动力学, 物理-数据平衡

**Comment:** 26 pages, 14 figures, 2 tables, 38 references

> **TL;DR:** 该论文开发了高斯过程的新型物理信息变点核，能够动态调整对物理知识的依赖，以优化物理与数据之间的平衡，特别是在物理模型仅在特定条件下有效时，并在结构动力学案例中进行了验证。

**AI_Comments:** 该论文的创新之处在于其提出的动态调整物理知识与数据平衡的方法，这超越了传统静态物理信息模型的限制。通过引入变点核，模型能够灵活适应物理规律仅在特定条件下有效或随时间变化的复杂场景。用户可控的知识引入/退出机制以及自动学习切换能力，极大地增强了模型的实用性和可解释性。同时，对噪声建模的改进也提升了不确定性量化的准确性。其在结构动力学领域的应用案例展示了该方法在实际工程问题中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在物理信息机器学习中，物理与数据之间的平衡是一个重要的建模考量。过分依赖物理知识可能有害，尤其当物理模型不能准确代表真实系统时；而物理知识的利用不足又会浪费宝贵资源并牺牲模型可解释性。实现最优的物理-数据平衡具有挑战性，特别是当这种平衡随时间变化时（例如，物理近似仅在特定区域有效，或物理现象仅在特定条件（如高温）下发生）。

**Method:** 本文开发了新颖的、物理信息驱动的变点核用于高斯过程，能够动态改变对可用物理知识的依赖。用户可以高度控制，定义现象应该发生的条件以及知识应该如何逐步引入和退出模型。在用户不太确定的情况下，对物理知识的切换依赖可以以可解释和直观的方式自动学习和从模型中恢复。此外，还实现了基于物理现象发生的建模噪声变化，以提供更具代表性的不确定性捕获。

**Result:** 新核结构的能力通过两个工程案例研究进行了探索：斜拉桥的定向风荷载和飞行操纵过程中飞机机翼应变的预测。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对物理信息机器学习中物理与数据平衡的挑战，特别是当物理知识的有效性随时间或条件变化时，提出了一种新颖的解决方案。作者开发了用于高斯过程的物理信息变点核，能够动态调整模型对物理知识的依赖程度。这些核允许用户自定义物理知识的引入和退出条件及速率，或在不确定情况下自动学习这种切换。此外，模型还实现了基于物理现象的噪声变化，以更准确地捕捉不确定性。论文通过斜拉桥风荷载和飞机机翼应变预测的工程案例研究，验证了新核结构的有效性。

> **摘要翻译:** 在任何物理信息机器学习器中，物理和数据之间的相对平衡是重要的建模考虑因素，以确保物理和数据驱动方法的优势最大化。过度依赖物理知识可能有害，特别是当模型的物理部分不能准确代表真实的底层系统时。物理知识的利用不足可能会浪费宝贵的资源，同时降低模型的可解释性并增加昂贵数据收集的需求。实现最优的物理-数据平衡是模型设计中具有挑战性的一方面，特别是如果其水平随时间变化；例如，可能存在仅在特定区域内有效的物理近似，或者已知物理现象仅在满足给定条件（例如高温）时才会发生。本文开发了新颖的、物理信息驱动的变点核用于高斯过程，能够动态改变对可用物理知识的依赖。用户可以高度控制，允许定义他们认为现象应该发生的条件以及知识应该以何种速率引入和退出模型。在用户可能不太确定的情况下，对物理知识的切换依赖可以以可解释和直观的方式自动学习和从模型中恢复。还实现了基于物理现象发生的建模噪声变化，以在预测的同时提供更具代表性的不确定性捕获。新核结构的能力通过两个工程案例研究进行了探索：斜拉桥的定向风荷载和飞行操纵过程中飞机机翼应变的预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [554] [Geometry-Aware Edge Pooling for Graph Neural Networks](https://arxiv.org/abs/2506.11700)
> *几何感知边池化图神经网络*

*Katharina Limbeck, Lydia Mezrag, Guy Wolf, Bastian Rieck* | **Main category: cs.LG**

**Keywords:** 图神经网络, 池化, 边坍塌, 扩散几何, 图结构保留

**Comment:** 

> **TL;DR:** 本文提出了一种几何感知的边池化方法，用于图神经网络，通过保留图结构和多样性来提高性能和稳定性。

**AI_Comments:** 这篇论文的创新点在于提出了一个“几何感知”的池化机制，通过边坍塌和利用扩散几何来显式地保留图的结构和多样性，而不是简单地为了降维而牺牲结构信息。它解决了现有池化方法在结构保留和性能稳定性方面的痛点，尤其是在处理大型图数据时，其对计算效率的关注也很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有图神经网络的池化操作为了优化学习任务，往往牺牲了图的基本结构和可解释性，导致在不同数据集类型、下游任务和池化比率下性能不可靠。

**Method:** 提出了一种新的图池化层，通过边坍塌实现结构感知的池化。该方法利用扩散几何，迭代地减小图的尺寸，同时保留其度量结构和结构多样性。通过使用“幅度”（一种等距不变的多样性度量）来指导池化过程的保真度控制，并使用“度量空间的展开”作为更快更稳定的替代方案以确保计算效率。

**Result:** (i) 在各种图分类任务中，与现有池化层相比，实现了卓越的性能。
(ii) 保留了输入图的关键谱特性。
(iii) 在不同池化比率下仍保持高精度。

**Conclusion:** 本文提出的几何感知边池化方法通过有效保留图的结构特性，显著提升了图神经网络在多种任务上的性能、稳定性和鲁棒性，解决了现有池化方法牺牲结构完整性的问题。

> **ai_Abstract:** 本文提出了一种名为“几何感知边池化”的新型图池化方法，旨在解决现有GNNs池化层在减小图尺寸时牺牲结构和可解释性的问题。该方法利用扩散几何和边坍塌，迭代地减小图的尺寸，同时通过引入“幅度”和“度量空间的展开”来有效保留图的度量结构和结构多样性。实验证明，该方法在多种图分类任务中表现出优越性能，能有效保留图的谱特性，并在不同池化比率下保持高精度。

> **摘要翻译:** 图神经网络（GNNs）在基于图的任务中取得了显著成功。受现实世界应用中大型数据集普遍存在的启发，池化层是GNNs的关键组成部分。通过减小输入图的尺寸，池化能够加速训练并可能提高泛化能力。然而，现有的池化操作通常以牺牲基本图结构和可解释性为代价来优化学习任务。这导致在不同数据集类型、下游任务和池化比率下性能不可靠。为了解决这些问题，我们提出了一种新颖的图池化层，通过边坍塌实现结构感知池化。我们的方法利用扩散几何，迭代地减小图的尺寸，同时保留其度量结构和结构多样性。我们使用“幅度”（一种等距不变的多样性度量）来指导池化，这使得我们能够控制池化过程的保真度。此外，我们使用“度量空间的展开”作为更快、更稳定的替代方案，以确保计算效率。实证结果表明，我们的方法（i）在各种不同的图分类任务中，与替代的池化层相比，实现了卓越的性能，（ii）保留了输入图的关键谱特性，并且（iii）在不同池化比率下仍保持高精度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [555] [Growing with Experience: Growing Neural Networks in Deep Reinforcement Learning](https://arxiv.org/abs/2506.11706)
> *随经验增长：深度强化学习中神经网络的增长*

*Lukas Fehring, Marius Lindauer, Theresa Eimer* | **Main category: cs.LG**

**Keywords:** 深度强化学习, 神经网络增长, 渐进式训练, 网络容量, GrowNN

**Comment:** 3 pages

> **TL;DR:** GrowNN 是一种在深度强化学习训练过程中逐步增长神经网络的方法，以提高性能并学习更复杂的策略。

**AI_Comments:** 本文的创新之处在于提出了一种动态调整神经网络结构以适应强化学习任务复杂度的 GrowNN 方法。通过在训练过程中逐步增加网络深度，该方法有效解决了训练大型RL模型所面临的挑战，同时保持了模型的易训练性。其易于集成到现有RL智能体的特性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 训练中等规模的强化学习（RL）网络仍然很困难，这严重限制了能够学习的策略的复杂性。

**Method:** 本文提出了一种名为 GrowNN 的简单有效的方法，该方法在训练期间利用渐进式网络增长。首先训练一个小型网络来学习初始策略，然后添加层而不改变编码函数。随后的更新可以利用添加的层来学习更具表达力的策略，随着策略复杂性的增加而增加容量。GrowNN 可以无缝集成到大多数现有的 RL 智能体中。

**Result:** 在 MiniHack 和 Mujoco 上的实验表明，智能体性能有所提高，渐进式 GrowNN-深度网络在 MiniHack Room 上比同等大小的静态对应网络性能高出 48%，在 Ant 上高出 72%。

**Conclusion:** GrowNN 方法通过逐步增加网络容量，成功解决了训练大型强化学习网络的挑战，从而显著提高了性能。

> **ai_Abstract:** 本文针对强化学习中训练大型网络困难、限制策略复杂性的问题，提出了一种名为 GrowNN 的方法。GrowNN 在训练过程中通过渐进式地增加神经网络的层数来逐步扩展网络容量，从而在不影响可训练性的前提下，使模型能够学习更复杂的策略。实验结果表明，GrowNN 在 MiniHack 和 Mujoco 等任务上显著提升了智能体的性能，其动态增长的网络比相同大小的静态网络表现更优。

> **摘要翻译:** 尽管越来越大的模型彻底改变了机器学习的格局，但训练中等规模的强化学习（RL）网络仍然很困难。然而，这严重限制了我们能够学习的策略的复杂性。为了在保持网络可训练性的同时增加网络容量，我们提出了 GrowNN，这是一种简单而有效的方法，它在训练期间利用渐进式网络增长。我们首先训练一个小型网络来学习初始策略。然后我们添加层而不改变编码函数。随后的更新可以利用添加的层来学习更具表达力的策略，随着策略复杂性的增加而增加容量。GrowNN 可以无缝集成到大多数现有的 RL 智能体中。我们在 MiniHack 和 Mujoco 上的实验表明，智能体性能有所提高，渐进式 GrowNN-深度网络在 MiniHack Room 上比同等大小的静态对应网络性能高出 48%，在 Ant 上高出 72%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [Taxonomy of reduction matrices for Graph Coarsening](https://arxiv.org/abs/2506.11743)
> *图粗化中约简矩阵的分类*

*Antonin Joly, Nicolas Keriven, Aline Roumy* | **Main category: cs.LG**

**Keywords:** 图粗化, 约简矩阵, 提升矩阵, 受限谱近似, 图神经网络

**Comment:** 

> **TL;DR:** 图粗化使用约简和提升矩阵。本文指出它们的作用不对称，并提出了一种新的约简矩阵分类，即使在固定提升矩阵的情况下，也能进一步减少信息损失（RSA），从而提高图神经网络性能。

**AI_Comments:** 这篇论文通过挑战约简矩阵和提升矩阵之间传统的固定关系，为图粗化提供了一个创新的视角。其关键创新在于认识到这些作用的不对称性，并提出了一个更广义的约简矩阵分类法。这种方法很重要，因为它展示了一种在粗化中进一步最小化信息损失（RSA）的新颖方法，这直接转化为图神经网络等下游应用中性能的提高。这篇论文的贡献对于推进图粗化的理论理解和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图粗化很重要但会导致信息损失（RSA）。现有方法固定了约简矩阵和提升矩阵之间的关系（通常是伪逆），通过定义粗化来最小化RSA。作者观察到这两个矩阵的作用并非完全对称，并且仅对提升矩阵施加约束就能确保重要图对象的存在。这促使他们探索更通用的约简矩阵概念，以进一步减少RSA。

**Method:** 本文引入了一种更通用的约简矩阵概念，其不一定是提升矩阵的伪逆。它建立了“可接受”约简矩阵家族的分类，讨论了它们必须满足的不同属性以及它们是否承认闭合形式描述。文章探讨了不同的示例，包括基于RSA约束优化过程的示例。同时，还阐述了这些选择对粗化图上不同节点分类任务中图神经网络性能的影响。

**Result:** 论文表明，对于固定的粗化（由固定的提升矩阵表示），仅通过修改约简矩阵就可以进一步减少受限谱近似（RSA）。它还阐明了这些选择对粗化图上不同节点分类任务中图神经网络性能的积极影响。

**Conclusion:** 通过引入更通用的约简矩阵概念和分类，与提升矩阵的伪逆不同，可以在图粗化中进一步减少信息损失（RSA）。这种改进的理解和方法带来了图神经网络等应用中更好的性能。

> **ai_Abstract:** 本文提出了一种新的图粗化中约简矩阵的分类法，超越了约简矩阵和提升矩阵互为伪逆的普遍假设。作者认为它们的作用不对称，并且约简矩阵的更通用定义可以导致受限谱近似（RSA）的进一步减少，即使在提升矩阵固定的情况下也是如此。他们确立了“可接受”约简矩阵的属性，探讨了优化示例，并展示了他们的方法对粗化图上节点分类任务中图神经网络性能的积极影响。

> **摘要翻译:** 图粗化旨在减小图的大小以减轻内存占用，并在图信号处理和机器学习中具有广泛应用。它通常使用约简矩阵和提升矩阵来定义，这两个矩阵分别允许将图信号从原始图投影到粗化图并返回。这会导致信息损失，由所谓的受限谱近似（RSA）来衡量。大多数粗化框架在约简矩阵和提升矩阵之间施加固定的关系，通常是彼此的伪逆，并寻求定义一个最小化RSA的粗化。在本文中，我们指出这两个矩阵的作用并非完全对称：事实上，仅对提升矩阵施加约束就能确保重要对象（如粗化图的邻接矩阵或拉普拉斯算子）的存在。鉴于此，在本文中，我们引入了一种更通用的约简矩阵概念，它不一定是提升矩阵的伪逆。我们建立了“可接受”约简矩阵家族的分类，讨论了它们必须满足的不同属性以及它们是否承认闭合形式描述。我们表明，对于由固定提升矩阵表示的固定粗化，仅通过修改约简矩阵就可以进一步减少RSA。我们探讨了不同的示例，包括一些基于RSA约束优化过程的示例。由于此标准也与图神经网络的性能相关联，我们还阐述了这些选择对粗化图上不同节点分类任务的影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [561] [SSPINNpose: A Self-Supervised PINN for Inertial Pose and Dynamics Estimation](https://arxiv.org/abs/2506.11786)
> *SSPINNpose：一种用于惯性姿态和动力学估计的自监督物理信息神经网络*

*Markus Gambietz, Eva Dorschky, Altan Akat, Marcel Schöckel, Jörg Miehling, Anne D. Koelewijn* | **Main category: cs.LG**

**Keywords:** 自监督学习, 物理信息神经网络, 惯性测量单元, 姿态估计, 运动动力学

**Comment:** 

> **TL;DR:** SSPINNpose是一种自监督的物理信息神经网络，无需地面真值即可从IMU数据中准确估计人体运动的姿态和动力学，解决了现有监督学习方法的局限性。

**AI_Comments:** SSPINNpose的创新之处在于其自监督学习范式，结合了物理信息神经网络（PINN），有效地解决了传统监督学习方法对昂贵且难以泛化的地面真值数据的依赖。这种方法提高了数据采集的实用性和泛化能力，使其更适用于真实世界环境。其能够处理稀疏传感器配置并推断传感器位置的能力，进一步增强了其实用性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的实时人体运动动力学估计方法依赖于监督学习，需要通过光学运动捕捉等实验室测量系统获取地面真值数据集。这些系统存在测量和处理误差，且难以泛化到真实世界或未见过的运动，导致数据收集耗时且不实用。

**Method:** 本文提出了SSPINNpose，一种自监督的物理信息神经网络，用于直接从IMU数据估计关节运动学和动力学，无需地面真值标签进行训练。其核心方法是将网络输出通过人体物理模型运行，以优化物理合理性并生成虚拟测量数据。随后，网络直接使用这些虚拟传感器数据对实际测量的传感器数据进行训练，而非依赖地面真值。

**Result:** 与光学运动捕捉相比，SSPINNpose在步行和跑步（速度高达4.9米/秒）时，能够以8.7度的均方根偏差准确估计关节角度，并以4.9 BWBH%的均方根偏差准确估计关节力矩，延迟为3.5毫秒。此外，该框架在稀疏传感器配置下表现出鲁棒性，并能推断传感器的解剖位置。

**Conclusion:** SSPINNpose作为一种可扩展、适应性强的解决方案，在实验室和现场环境中进行实时生物力学分析具有巨大潜力。

> **ai_Abstract:** 本文提出了SSPINNpose，一种自监督的物理信息神经网络，旨在克服传统监督学习方法在人体运动动力学估计中对地面真值数据的依赖。SSPINNpose通过将网络输出与人体物理模型结合生成虚拟测量数据，并以此训练网络，从而直接从IMU数据估计关节运动学和动力学。实验结果表明，SSPINNpose在关节角度和力矩估计方面达到与光学运动捕捉相当的精度，且具有低延迟和稀疏传感器配置下的鲁棒性，为实时生物力学分析提供了一种有前景的解决方案。

> **摘要翻译:** 准确实时估计人体运动动力学，包括内部关节力矩和肌肉力，对于临床诊断和运动表现监测应用至关重要。惯性测量单元（IMU）提供了一种微创解决方案来捕获运动数据，尤其是在稀疏传感器配置中使用时。然而，当前的实时方法依赖于监督学习，其中需要使用光学运动捕捉等实验室测量系统来测量地面真值数据集。已知这些系统会引入测量和处理误差，并且通常无法泛化到真实世界或以前未见过的运动，这使得新的数据收集工作耗时且不实用。为了克服这些限制，我们提出了SSPINNpose，一种自监督的物理信息神经网络，它直接从IMU数据估计关节运动学和动力学，无需训练所需的地面真值标签。我们将网络输出通过人体物理模型运行，以优化物理合理性并生成虚拟测量数据。利用这些虚拟传感器数据，网络直接在测量的传感器数据上进行训练，而不是地面真值。与光学运动捕捉相比，SSPINNpose能够以8.7度的均方根偏差和4.9 BWBH%的均方根偏差（针对步行和跑步，速度高达4.9米/秒）准确估计关节角度和关节力矩，延迟为3.5毫秒。此外，该框架在稀疏传感器配置下表现出鲁棒性，并能推断传感器的解剖位置。这些结果强调了SSPINNpose作为一种可扩展和适应性强的解决方案，在实验室和现场环境中进行实时生物力学分析的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [564] [Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation](https://arxiv.org/abs/2506.11790)
> *时间序列特征归因中为何会出现类别依赖的评估效应？一项合成数据调查*

*Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp* | **Main category: cs.LG**

**Keywords:** 特征归因, 可解释AI, 评估效应, 时间序列, 合成数据

**Comment:** 

> **TL;DR:** 该研究通过合成数据发现，时间序列特征归因的评估方法（包括基于扰动和基于真实值的方法）会产生类别依赖的效应，并且基于扰动的方法与真实值度量结果之间存在弱相关性甚至矛盾，提示需要谨慎解释扰动评估结果。

**AI_Comments:** 该研究通过严谨的合成数据实验，揭示了XAI领域中一个重要的评估挑战，即特征归因评估的类别依赖性问题。其创新之处在于通过控制变量的方式，明确了导致这些效应的条件，并首次发现基于扰动的评估方法与真实值指标可能存在显著偏差，甚至产生矛盾的评估结果。这对于XAI方法开发和评估实践具有重要指导意义，提醒研究人员在评估归因质量时需更加审慎，并促使社区思考更鲁棒的评估范式。

<details>
  <summary>Details</summary>

**Motivation:** 可解释人工智能（XAI）中特征归因方法的评估是一个关键挑战，研究人员通常依赖基于扰动的方法，但近期工作表明这些评估指标在不同预测类别上表现不同，即“类别依赖的评估效应”。这引发了对扰动分析能否可靠衡量归因质量的疑问，并直接影响XAI方法开发和评估技术的可靠性。

**Method:** 研究通过合成时间序列数据进行受控实验，这些数据具有已知的真实特征位置。系统地改变二分类任务中的特征类型和类别对比度，然后使用多种归因方法，比较基于扰动的退化分数与基于真实值的精确召回指标。

**Result:** 实验表明，即使在具有时间局部特征的简单场景中，类别依赖效应也会在两种评估方法中出现，其原因在于类间特征幅度或时间范围的基本变化。最关键的是，研究发现基于扰动和基于真实值的度量在评估归因质量时经常产生矛盾的结果，并且评估方法之间相关性很弱。

**Conclusion:** 研究结果表明，研究人员应谨慎解释基于扰动的度量，因为它们可能并非总能与归因是否正确识别区分性特征相符。这些发现揭示了重新思考归因评估实际衡量什么以及开发更全面的评估框架以捕获归因质量多个维度的机会。

> **ai_Abstract:** 该论文 investigates 时间序列特征归因中“类别依赖的评估效应”的成因。通过使用已知真实特征的合成数据，研究发现基于扰动和基于真实值的评估方法均存在此类效应，且其出现与特征幅度和时间范围的类间差异有关。更重要的是，研究揭示了基于扰动的评估指标与真实值指标之间存在弱相关性甚至矛盾，这表明在解释基于扰动的评估结果时需要格外谨慎，并呼吁开发更全面的归因评估框架。

> **摘要翻译:** 评估特征归因方法是可解释人工智能（XAI）中的一个关键挑战，因为当缺乏真实值时，研究人员通常依赖基于扰动的指标。然而，最近的工作表明这些评估指标在同一数据集内，不同预测类别之间会表现出不同的性能。这些“类别依赖的评估效应”引发了对扰动分析能否可靠衡量归因质量的疑问，并对XAI方法开发和评估技术的可靠性产生了直接影响。我们通过使用已知真实特征位置的合成时间序列数据进行受控实验，调查了这些类别依赖效应在何种条件下产生。我们系统地改变二分类任务中的特征类型和类别对比度，然后使用多种归因方法，比较基于扰动的退化分数与基于真实值的精确召回指标。我们的实验表明，即使在具有时间局部特征的简单场景中，类别依赖效应也会在两种评估方法中出现，其原因在于类间特征幅度或时间范围的基本变化。最关键的是，我们发现基于扰动和基于真实值的度量在评估归因质量时经常产生矛盾的结果，并且评估方法之间相关性很弱。这些发现表明，研究人员应谨慎解释基于扰动的度量，因为它们可能并非总能与归因是否正确识别区分性特征相符。这些发现揭示了重新思考归因评估实际衡量什么以及开发更全面的评估框架以捕获归因质量多个维度的机会。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [568] [TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks](https://arxiv.org/abs/2506.11844)
> *TrustGLM：评估GraphLLM对抗提示、文本和结构攻击的鲁棒性*

*Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan* | **Main category: cs.LG**

**Keywords:** GraphLLM, 鲁棒性, 对抗性攻击, TrustGLM, 提示攻击

**Comment:** 12 pages, 5 figures, in KDD 2025

> **TL;DR:** 本文引入了TrustGLM，一项全面研究，评估了GraphLLM在文本、图结构和提示操作方面的对抗性攻击漏洞，发现它们易受攻击，并探索了防御技术。

**AI_Comments:** 这项工作开创性地全面评估了GraphLLM在多种对抗性攻击下的鲁棒性，填补了现有研究的空白。其创新之处在于系统地分析了文本、图结构和提示层面的漏洞，并提出了相应的防御策略。开源的库对于促进后续研究和公平评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GraphLLM很有前景，但其对抗性扰动的鲁棒性在很大程度上尚未被探索，这对于在高风险场景中部署这些模型至关重要。

**Method:** 我们引入了TrustGLM，一项全面研究，评估GraphLLM在文本、图结构和提示操作方面的漏洞。我们从每个角度实施了最先进的攻击算法来严格评估模型弹性。此外，我们通过数据增强训练和对抗性训练，研究了针对每个攻击向量的防御技术。

**Result:** GraphLLM高度容易受到文本攻击，这些攻击仅替换节点文本属性中少量语义相似的词。标准的图结构攻击方法可以显著降低模型性能，而提示模板中候选标签集的随机打乱会导致性能大幅下降。数据增强训练和对抗性训练等防御技术显示出增强GraphLLM鲁棒性的潜力。

**Conclusion:** GraphLLM容易受到文本、图结构和提示攻击。通过数据增强训练和对抗性训练等防御技术有望增强其鲁棒性。我们开源的库将促进快速、公平的评估，并激发该领域的进一步创新研究。

> **ai_Abstract:** 本文介绍了TrustGLM，一项针对GraphLLM鲁棒性的全面研究，评估了它们在文本、图结构和提示攻击下的脆弱性。研究发现GraphLLM对这些攻击高度敏感，即使是微小的扰动也能显著影响性能。此外，论文还探索了数据增强训练和对抗性训练等防御策略，并指出它们在增强GraphLLM鲁棒性方面的潜力。该研究还开源了一个库，旨在推动该领域的进一步研究。

> **摘要翻译:** 受大型语言模型（LLM）成功的启发，研究重心正从传统的图学习方法转向基于LLM的图框架，即GraphLLM。GraphLLM通过整合三个关键组件来利用LLM的推理能力：输入节点的文本属性、节点邻域的结构信息以及指导决策的任务特定提示。尽管GraphLLM前景广阔，但其对抗性扰动的鲁棒性在很大程度上尚未被探索——这对于在高风险场景中部署这些模型是一个关键问题。为了弥补这一空白，我们引入了TrustGLM，一项全面研究，评估GraphLLM在三个维度上对对抗性攻击的脆弱性：文本、图结构和提示操作。我们从每个角度实施了最先进的攻击算法，以严格评估模型的弹性。通过在来自不同领域的六个基准数据集上进行大量实验，我们的研究结果表明，GraphLLM极易受到文本攻击，这些攻击仅替换节点文本属性中少量语义相似的词。我们还发现，标准的图结构攻击方法可以显著降低模型性能，而提示模板中候选标签集的随机打乱会导致性能大幅下降。除了描述这些漏洞之外，我们还通过数据增强训练和对抗性训练，研究了针对每个攻击向量的防御技术，这些技术显示出增强GraphLLM鲁棒性的巨大潜力。我们希望我们开源的库能够促进快速、公平的评估，并激发该领域的进一步创新研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [571] [In Defense of Defensive Forecasting](https://arxiv.org/abs/2506.11848)
> *为防御性预测辩护*

*Juan Carlos Perdomo, Benjamin Recht* | **Main category: cs.LG**

**Keywords:** 防御性预测, 在线学习, 序贯博弈, 预测算法, 错误纠正

**Comment:** 

> **TL;DR:** 本教程介绍了防御性预测的算法，这是一种通过纠正过去错误而非预测来得出预测的方法，它将预测目标视为序贯博弈，并提出了适用于在线学习等任务的简单、接近最优的算法。

**AI_Comments:** 本文的创新之处在于提出了“防御性预测”这一概念，它将预测视为一种序贯博弈，并通过纠正过去错误而非单纯预报来生成预测，强调了预测的稳健性。其重要性在于为在线学习和预测领域提供了一种新颖且实用的方法，尤其在结果不确定性高的情况下具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 本教程旨在介绍防御性预测，这是一种不同于传统预测方法的预测范式。它通过纠正过去的错误来生成预测，并将预测目标定义为一种序贯博弈，旨在无论结果如何都能最小化指标，从而提供一种稳健的预测方法。

**Method:** 防御性预测通过纠正过去的错误来得出预测，而不是通过预报。它将预测目标构建为一种序贯博弈，并推导出预测以最小化指标，无论结果如何。本教程介绍了这种通用理论，并推导了用于在线学习、校准、专家建议预测和在线共形预测的简单、接近最优的算法。

**Result:** 本教程提供了防御性预测通用理论的入门介绍，并推导出了针对在线学习、校准、专家建议预测和在线共形预测的简单、接近最优的算法。

**Conclusion:** 本教程为防御性预测提供了一个基础性的介绍，并展示了其在多种在线学习场景下稳健且接近最优的算法，强调了其通过纠正错误而非预报进行预测的独特方法。

> **ai_Abstract:** 本教程对防御性预测的算法进行了综述，这是一种由Vovk开创的预测方法，其特点是通过纠正过去的错误而非传统预报来生成预测。该方法将预测视为一种序贯博弈，旨在无论结果如何都能最小化预测指标。教程不仅提供了该通用理论的入门介绍，还推导出了适用于在线学习、校准、专家建议预测和在线共形预测的简单且接近最优的算法。

> **摘要翻译:** 本教程概述了防御性预测的算法，其中预测不是通过预报而是通过纠正过去的错误得出的。由Vovk开创的防御性预测将预测目标定义为序贯博弈，并推导出预测以最小化指标，无论结果如何。我们对这一通用理论进行了初步介绍，并推导出了适用于在线学习、校准、专家建议预测和在线共形预测的简单、接近最优的算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [573] [Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values](https://arxiv.org/abs/2506.11849)
> *针对Shapley值和概率值的回归调整蒙特卡洛估计器*

*R. Teal Witter, Yurong Liu, Christopher Musco* | **Main category: cs.LG**

**Keywords:** Shapley值, 概率值, 蒙特卡洛, 回归, 可解释AI

**Comment:** 

> **TL;DR:** 本文提出了一种结合蒙特卡洛采样和回归的新方法，用于更准确地估计可解释AI中的Shapley值和概率值，实现了最先进的性能。

**AI_Comments:** 本文的创新之处在于其提出的结合蒙特卡洛采样和回归的新框架，特别是其灵活性，允许集成非线性模型（如XGBoost）来提高估计精度，同时保持估计的无偏性。这对于需要高精度特征归因和数据估值的可解释AI领域具有重要意义，克服了传统方法在计算效率和准确性上的局限。

<details>
  <summary>Details</summary>

**Motivation:** 由于Shapley值、Banzhaf值和半值等概率值在可解释AI中被广泛用于特征归因和数据估值，但其精确计算需要指数级时间，因此需要开发高效的近似方法。

**Method:** 本文提出了一种结合蒙特卡洛采样和线性回归公式的新方法。该方法比现有算法更灵活，允许用任何可以高效计算概率值的函数族（例如XGBoost等树模型）替代线性回归，同时仍能产生无偏估计。

**Result:** 在八个数据集上的实验表明，该方法在估计概率值方面达到了最先进的性能。对于Shapley值，其误差比Permutation SHAP低6.5倍，比Kernel SHAP低3.8倍，比Leverage SHAP低2.6倍。对于更通用的概率值，误差比现有最佳估计器低215倍。

**Conclusion:** 本文提出的回归调整蒙特卡洛估计器显著提高了Shapley值及其他概率值的估计精度，为可解释AI提供了更可靠的归因工具。

> **ai_Abstract:** 本文提出了一种新颖的回归调整蒙特卡洛估计器，旨在高效准确地近似计算Shapley值和更广泛的概率值，这些值在可解释AI中至关重要。该方法创新性地结合了蒙特卡洛采样和回归技术，并允许使用如XGBoost等高性能树模型，从而在保持无偏估计的同时显著提高准确性。实验证明，与现有最先进的方法相比，该方法在Shapley值和通用概率值的估计误差上均有显著降低。

> **摘要翻译:** 起源于博弈论的概率值，如Shapley值、Banzhaf值和半值，已成为可解释AI中的核心工具。它们被用于特征归因、数据归因、数据估值等。由于所有这些值的精确计算都需要指数级时间，研究重点放在使用两种技术的高效近似方法上：蒙特卡洛采样和线性回归公式。在这项工作中，我们提出了一种结合这两种技术的新方法。我们的方法比现有算法更灵活，允许用任何可以高效计算概率值的函数族替代线性回归。这使我们能够利用XGBoost等基于树的模型的准确性，同时仍然产生无偏估计。通过在八个数据集上的实验，我们发现我们的方法在估计概率值方面提供了最先进的性能。对于Shapley值，我们方法的误差比Permutation SHAP（最流行的蒙特卡洛方法）低6.5倍，比Kernel SHAP（最流行的线性回归方法）低3.8倍，比Leverage SHAP（先前最先进的Shapley值估计器）低2.6倍。对于更通用的概率值，我们可以获得比现有工作中最佳估计器低215倍的误差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [576] [Robust Molecular Property Prediction via Densifying Scarce Labeled Data](https://arxiv.org/abs/2506.11877)
> *通过稠密化稀疏标记数据实现鲁棒的分子性质预测*

*Jina Kim, Jeffrey Willette, Bruno Andreis, Sung Ju Hwang* | **Main category: cs.LG**

**Keywords:** 分子性质预测, 分布外泛化, 元学习, 未标记数据, 协变量偏移

**Comment:** 

> **TL;DR:** 针对分子预测模型对训练数据过度依赖导致对分布外化合物泛化能力差的问题，本研究提出了一种新颖的基于元学习的方法，利用未标记数据在分布内和分布外数据之间进行插值，从而使模型能够更好地泛化。该方法在存在协变量偏移的真实世界数据集中表现出显著优于现有技术。

**AI_Comments:** 本文的创新之处在于将元学习与未标记数据结合起来，以解决分子性质预测中关键的分布外泛化问题，这在药物发现等领域具有重要意义。该方法通过插值ID和OOD数据，有效地弥合了训练数据与实际应用中遇到的新颖化合物之间的差距，为提高模型在复杂真实世界场景中的鲁棒性和准确性提供了有前景的途径。

<details>
  <summary>Details</summary>

**Motivation:** 分子预测模型普遍存在对训练数据中观测到的结构过度依赖的局限性，导致对分布外（OOD）化合物的泛化能力差。在药物发现中，最关键的化合物往往在训练集之外，使得这种对训练数据的偏倚成为一个特别严重的问题。这种不匹配引入了显著的协变量偏移，导致标准深度学习模型产生不稳定和不准确的预测。此外，实验验证的繁重和昂贵性质导致标记数据稀缺，进一步加剧了实现可靠泛化的难度。

**Method:** 为了解决上述局限性，本文提出了一种新颖的基于元学习的方法，该方法利用未标记数据在分布内（ID）和分布外（OOD）数据之间进行插值，使模型能够元学习如何泛化到训练分布之外。

**Result:** 本研究证明，在表现出显著协变量偏移的、具有挑战性的真实世界数据集上，该方法比现有最先进的方法取得了显著的性能提升。

**Conclusion:** 通过利用未标记数据进行元学习以插值分布内和分布外数据，所提出的方法有效解决了分子性质预测中泛化能力差和标记数据稀缺的问题，显著提高了模型在具有协变量偏移的真实世界数据集上的鲁棒性和准确性。

> **ai_Abstract:** 针对分子性质预测模型在处理分布外化合物和数据稀缺性方面的泛化能力不足问题，本文提出了一种新颖的基于元学习的方法。该方法通过利用未标记数据在分布内和分布外数据之间进行插值，使模型能够学习如何泛化到训练分布之外。实验结果表明，在存在显著协变量偏移的真实世界数据集上，该方法相较于现有技术实现了显著的性能提升，有效提高了预测的鲁棒性和准确性。

> **摘要翻译:** 分子预测模型的一个广为人知的局限性是它们对训练数据中观察到的结构的依赖，这导致了对分布外化合物的泛化能力差。然而在药物发现中，对推进研究最关键的化合物往往超出训练集，这使得对训练数据的偏倚成为一个特别严重的问题。这种不匹配引入了显著的协变量偏移，在此情况下，标准深度学习模型会产生不稳定和不准确的预测。此外，实验验证的繁重和昂贵性质导致标记数据稀缺，进一步加剧了实现可靠泛化的难度。为了解决这些局限性，我们提出了一种新颖的基于元学习的方法，该方法利用未标记数据在分布内（ID）和分布外（OOD）数据之间进行插值，使模型能够元学习如何泛化到训练分布之外。我们证明了在表现出显著协变量偏移的、具有挑战性的真实世界数据集上，该方法比现有最先进的方法取得了显著的性能提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [579] [An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing](https://arxiv.org/abs/2506.11882)
> *车辆网络切片中动态资源管理的解释性人工智能框架*

*Haochen Sun, Yifan Liu, Ahmed Al-Tahmeesschi, Swarna Chetty, Syed Ali Raza Zaidi, Avishek Nag, Hamed Ahmadi* | **Main category: cs.LG**

**Keywords:** 解释性人工智能, 深度强化学习, 车辆网络, 网络切片, 资源管理

**Comment:** To appear in Proceedings of IEEE PIMRC 2025. 6 pages, 4 figures

> **TL;DR:** 本文提出了一个解释性深度强化学习（XRL）框架，用于车辆网络中的动态网络切片和资源分配，通过结合Shapley值和注意力机制提高了决策的可解释性，并提升了URLLC和eMBB服务的QoS满意度。

**AI_Comments:** 这篇论文的创新点在于将解释性人工智能（XAI）引入到车辆网络的动态资源管理中，特别是结合了Shapley值和注意力机制来提高深度强化学习决策的可解释性。这对于提高关键通信系统（如URLLC）的可靠性和透明度具有重要意义。所提出的框架不仅提供了技术上的改进，还在实际性能（QoS满意度）上展现了提升。

<details>
  <summary>Details</summary>

**Motivation:** 车辆网络中有效的资源管理和网络切片对于满足eMBB和URLLC等多样化服务需求至关重要。

**Method:** 本文提出了一个解释性深度强化学习（XRL）框架，用于车辆网络中的动态网络切片和资源分配。该框架建立在近实时RAN智能控制器之上，并通过整合利用Shapley值和注意力机制的基于特征的方法来解释和完善强化学习代理的决策。

**Result:** 模拟结果表明，该方法能为资源分配过程提供清晰、实时的洞察，并比纯注意力机制实现更高的可解释性精度。此外，URLLC服务的QoS满意度从78.0%提高到80.13%，eMBB服务的QoS满意度从71.44%提高到73.21%。

**Conclusion:** 该解释性人工智能框架有效解决了车辆通信系统中的关键可靠性挑战，并通过提高决策可解释性和服务QoS满意度，提升了车辆网络中动态资源管理和网络切片的性能。

> **ai_Abstract:** 本文提出了一个解释性深度强化学习（XRL）框架，用于车辆网络中动态网络切片和资源分配。该框架基于近实时RAN智能控制器，并结合Shapley值和注意力机制来解释和优化强化学习代理的决策，旨在解决车辆通信的可靠性挑战。仿真结果表明，该方法不仅提高了资源分配过程的可解释性，还显著提升了URLLC和eMBB服务的QoS满意度。

> **摘要翻译:** 车辆网络切片中动态资源管理的解释性人工智能框架
有效的资源管理和网络切片对于满足车辆网络的多样化服务需求至关重要，包括增强型移动宽带（eMBB）和超可靠低延迟通信（URLLC）。本文介绍了一种解释性深度强化学习（XRL）框架，用于车辆网络中的动态网络切片和资源分配，该框架建立在近实时RAN智能控制器之上。通过整合利用Shapley值和注意力机制的基于特征的方法，我们解释并完善了强化学习代理的决策，解决了车辆通信系统中的关键可靠性挑战。仿真结果表明，我们的方法为资源分配过程提供了清晰、实时的洞察，并实现了比纯注意力机制更高的可解释性精度。此外，URLLC服务的服务质量（QoS）满意度从78.0%提高到80.13%，而eMBB服务的服务质量满意度从71.44%提高到73.21%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [581] [Understanding Input Selectivity in Mamba: Impact on Approximation Power, Memorization, and Associative Recall Capacity](https://arxiv.org/abs/2506.11891)
> *理解Mamba中的输入选择性：对逼近能力、记忆和联想回忆能力的影响*

*Ningyuan Huang, Miguel Sarabia, Abhinav Moudgil, Pau Rodriguez, Luca Zappella, Federico Danieli* | **Main category: cs.LG**

**Keywords:** Mamba, 状态空间模型, 输入选择性, 函数逼近, 记忆

**Comment:** 

> **TL;DR:** 本研究揭示了Mamba架构中输入选择性的作用，证明了其在函数逼近、记忆保持和联想回忆方面的优势。

**AI_Comments:** 这项工作对Mamba架构的核心创新——输入选择性——进行了深入的机制性分析，这对于理解其超越传统SSM模型的性能至关重要。通过结合理论证明（如Haar小波表示）和经验验证，论文不仅揭示了Mamba的优势，还为未来的模型优化和新架构设计提供了宝贵的线索，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Mamba引入的输入选择性提高了其相对于SSM前身模型的性能，但其如何利用这些额外功能以及如何与其他操作交互仍不清楚，因此需要揭示输入选择性在Mamba中的作用。

**Method:** 本研究通过以下方式进行：(i) 证明Mamba的S6层可以表示对Haar小波的投影；(ii) 展示S6层如何动态抵消记忆衰减；(iii) 为使用Mamba、Mamba-2和S4D不同混合器的MQAR联想回忆任务提供分析解决方案。并通过经验结果验证了理论构建的紧密性。

**Result:** 结果表明：(i) Mamba的S6层在逼近实践中常见的不连续函数方面优于其前身S4D；(ii) S6层能够动态抵消记忆衰减；(iii) 为使用Mamba架构不同混合器的MQAR联想回忆任务提供了分析解决方案。理论构造与经验结果紧密吻合。

**Conclusion:** 本研究为Mamba提供了机械性理解，并揭示了进一步改进的机会。

> **ai_Abstract:** 本研究深入探讨了新型状态空间模型Mamba中的输入选择性机制，旨在揭示其对模型性能的具体影响。通过理论证明和实证分析，论文阐明了Mamba的S6层在函数逼近、记忆保持和联想回忆方面的独特优势，特别是其在处理不连续函数和动态抵消记忆衰减方面的能力。研究结果为理解Mamba的工作原理提供了机械性见解，并指出了未来改进的方向。

> **摘要翻译:** 状态空间模型（SSM），特别是Mamba，最近已成为Transformer的一种有前景的替代方案。Mamba在其SSM层（S6）中引入了输入选择性，并将其卷积和门控整合到其块定义中。虽然这些修改确实改善了Mamba相对于其SSM前身模型的性能，但Mamba如何利用输入选择性提供的额外功能，以及这些功能如何与Mamba架构中的其他操作相互作用，仍 largely 不清楚。在这项工作中，我们揭示了Mamba中输入选择性的作用，研究了它对函数逼近能力、长期记忆和联想回忆能力的影响。具体而言：(i) 我们证明Mamba的S6层可以表示对Haar小波的投影，这在逼近实践中常见的不连续函数方面比其对角SSM（S4D）前身具有优势；(ii) 我们展示了S6层如何动态抵消记忆衰减；(iii) 我们使用具有不同混合器——Mamba、Mamba-2和S4D的Mamba架构，为MQAR联想回忆任务提供了分析解决方案。我们通过具体任务的经验结果证明了我们理论构建的紧密性。我们的发现为Mamba提供了机械性理解，并揭示了改进的机会。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [583] [Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices](https://arxiv.org/abs/2506.11892)
> *基于注意力的无线电信号分类对抗鲁棒蒸馏，适用于低功耗物联网设备*

*Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli* | **Main category: cs.LG**

**Keywords:** 对抗鲁棒性, 知识蒸馏, Transformer, 无线电信号分类, 物联网

**Comment:** 

> **TL;DR:** 本文提出了一种新的紧凑型Transformer模型，通过对抗注意力图蒸馏，增强了无线电信号分类在对抗攻击下的鲁棒性，尤其适用于低功耗物联网设备。

**AI_Comments:** 本文创新性地将对抗注意力图蒸馏引入到低功耗物联网设备的紧凑型Transformer中，解决了小型模型在对抗训练中的局限性。其关注实际应用场景（IoT低功耗）并提出针对性解决方案，具有重要意义。该方法不仅提高了模型的鲁棒性，还探讨了对抗样本的可迁移性，为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在自动调制分类中表现出色，但易受对抗样本攻击。同时，物联网设备对计算效率和功耗有严格要求，导致紧凑型Transformer难以实现鲁棒训练的优势。因此，需要一种针对低功耗物联网设备的对抗防御系统。

**Method:** 本文提出了一种新型的紧凑型Transformer模型，通过将鲁棒训练过的大型Transformer的对抗注意力图转移到紧凑型Transformer中，以增强其在对抗攻击下的鲁棒性。该方法旨在克服紧凑型模型难以进行对抗训练的限制。

**Result:** 所提出的方法在白盒场景（包括快速梯度下降和投影梯度下降攻击）下，性能优于现有最先进技术。研究还提供了底层工作机制的推理，并探讨了对抗样本在不同架构之间的可迁移性。

**Conclusion:** 所提出的方法能够有效提高紧凑型Transformer在无线电信号分类中对抗对抗攻击的鲁棒性，并有可能保护Transformer免受对抗样本的可迁移性影响。

> **ai_Abstract:** 本研究针对基于Transformer的无线电信号分类在对抗攻击下的脆弱性，提出了一种名为“基于注意力的对抗鲁棒蒸馏”的新方法。鉴于低功耗物联网设备对计算效率的需求，该方法通过将鲁棒训练过的大型Transformer的对抗注意力图转移到紧凑型Transformer中，有效提升了其在对抗攻击下的鲁棒性。实验结果表明，该方法在白盒攻击场景下优于现有技术，并能有效防御对抗样本的可迁移性。

> **摘要翻译:** 由于Transformer在自然语言处理和计算机视觉等许多应用中取得了巨大成功，因此Transformer已成功应用于自动调制分类。我们已经表明，基于Transformer的无线电信号分类容易受到被称为对抗样本的难以察觉且精心设计的攻击。因此，我们提出了一种针对基于Transformer的调制分类中对抗样本的防御系统。考虑到物联网（IoT）应用或设备在电源受限环境中运行对计算效率架构的需求，我们提出了一种用于调制分类的紧凑型Transformer。在紧凑型Transformer中，对抗训练等鲁棒训练的优势可能无法实现。通过证明这一点，我们提出了一种新型紧凑型Transformer，可以在存在对抗攻击的情况下增强鲁棒性。新方法旨在将对抗注意力图从鲁棒训练过的大型Transformer转移到紧凑型Transformer。所提出的方法在所考虑的白盒场景（包括快速梯度方法和投影梯度下降攻击）中优于最先进的技术。我们提供了底层工作机制的推理，并研究了对抗样本在不同架构之间的可迁移性。所提出的方法有潜力保护Transformer免受对抗样本可迁移性的影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [Measurement-aligned Flow for Inverse Problem](https://arxiv.org/abs/2506.11893)
> *测量对齐流用于逆问题*

*Shaorong Zhang, Rob Brekelmans, Yunshu Wu, Greg Ver Steeg* | **Main category: cs.LG**

**Keywords:** 扩散模型, 逆问题, 测量对齐采样, 噪声, 先验信息

**Comment:** 

> **TL;DR:** 提出了一种名为MAS的新框架，用于解决逆问题，能够更好地平衡先验和测量信息，并处理各种噪声类型，性能优于现有方法。

**AI_Comments:** MAS框架的创新之处在于其能够更灵活地平衡先验和测量信息，并处理多种复杂的噪声类型（包括非高斯和未知噪声），这显著提高了其在逆问题解决中的鲁棒性和通用性。它统一并扩展了现有方法，表明其具有较强的理论基础和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型方法在解决逆问题时，难以正确整合来自先验和测量中的冲突信号，尤其是在非高斯或未知噪声的挑战性设置下。

**Method:** 提出了一种名为测量对齐采样（Measurement-Aligned Sampling, MAS）的新颖框架，用于解决线性逆问题。MAS能够更灵活地平衡先验和测量信息，统一并扩展了现有的方法（如DDNM和DAPS），并提供了一种新的优化视角。MAS可以推广处理已知高斯噪声、未知或非高斯噪声类型。

**Result:** 广泛的实验表明，MAS在各种任务中始终优于最先进的方法。

**Conclusion:** MAS通过有效平衡先验和测量信息，即使在面临挑战性的噪声类型时，也能为逆问题提供更灵活和鲁棒的解决方案，从而实现卓越的性能。

> **ai_Abstract:** 本研究提出了一种名为测量对齐采样（MAS）的新型框架，旨在解决扩散模型在逆问题中处理冲突先验和测量信号的挑战，尤其是在存在非高斯或未知噪声的情况下。MAS能够灵活地平衡先验和测量信息，并统一扩展了现有方法。实验结果表明，MAS在多项任务中均优于当前最先进的方法。

> **摘要翻译:** 扩散模型为解决逆问题提供了一种强大的方式，可以整合复杂的先验信息。然而，现有方法难以正确整合来自先验和测量中冲突信号的指导，尤其是在非高斯或未知噪声的挑战性设置下。为了弥合这些差距，我们提出了测量对齐采样（MAS），这是一种用于线性逆问题解决的新颖框架，可以更灵活地平衡先验和测量信息。MAS统一并扩展了DDNM和DAPS等现有方法，并提供了一种新的优化视角。MAS可以推广处理已知高斯噪声、未知或非高斯噪声类型。广泛的实验表明，MAS在各种任务中始终优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [586] [Scalable Generalized Bayesian Online Neural Network Training for Sequential Decision Making](https://arxiv.org/abs/2506.11898)
> *可扩展的广义贝叶斯在线神经网络训练用于序列决策*

*Gerardo Duran-Martin, Leandro Sánchez-Betancourt, Álvaro Cartea, Kevin Murphy* | **Main category: cs.LG**

**Keywords:** 在线学习, 贝叶斯神经网络, 序列决策, 协方差更新, 上下文化赌博机

**Comment:** 

> **TL;DR:** 本文提出了一种可扩展的在线广义贝叶斯神经网络训练算法，专为序列决策任务设计。该方法结合了频率派和贝叶斯滤波的优点，通过特定的协方差更新策略实现快速在线参数更新，无需回放缓冲区或离线再训练。经验证明，在上下文化赌博机和贝叶斯优化问题上，该方法在速度和准确性之间取得了有竞争力的权衡。

**AI_Comments:** 这项工作在在线学习和序列决策领域具有重要意义，因为它提出了一种无需回放缓冲区或离线再训练的神经网络在线训练方法，这对于资源受限或需要实时决策的应用非常有利。其创新点在于结合了频率派和贝叶斯滤波的优点，并提出了一种新颖的协方差更新策略，即使后验不恰当也能保证预测分布的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为序列决策任务引入可扩展的在线学习和神经网络参数的广义贝叶斯推断算法。

**Method:** 所提出的方法结合了频率派和贝叶斯滤波的优点，通过参数误差协方差的块对角近似实现快速低秩更新。具体地，对隐藏层参数采用低秩误差协方差更新，对最后一层参数采用全秩误差协方差更新。尽管这种方法可能导致不恰当的后验，但其后验预测分布是明确定义的。所有网络参数均在线更新，无需回放缓冲区或离线再训练。

**Result:** 经验性地证明，所提出的方法在（非平稳）上下文化赌博机问题和贝叶斯优化问题上，在速度和准确性之间取得了有竞争力的权衡。

**Conclusion:** 所提出的可扩展广义贝叶斯在线神经网络训练方法，通过结合频率派和贝叶斯滤波的优点，并采用特定的协方差更新策略，成功地在序列决策任务中实现了高效且准确的在线学习，无需传统方法所需的额外数据存储或离线训练。

> **ai_Abstract:** 这篇论文介绍了一种用于序列决策任务的可扩展广义贝叶斯在线神经网络训练算法。该方法融合了频率派和贝叶斯滤波的优势，通过对隐藏层采用低秩误差协方差更新、对最终层采用全秩误差协方差更新，实现了参数的快速在线更新，且无需回放缓冲区。尽管可能产生不恰当的后验，但其后验预测分布是明确的。实验证明，该方法在上下文化赌博机和贝叶斯优化问题上，在速度和准确性之间取得了良好的平衡。

> **摘要翻译:** 我们引入了用于神经网络参数在线学习和广义贝叶斯推断的可扩展算法，专为序列决策任务设计。我们的方法结合了频率派和贝叶斯滤波的优点，包括通过参数误差协方差的块对角近似实现的快速低秩更新，以及我们用于决策的明确定义的后验预测分布。更精确地说，我们的主要方法更新隐藏层参数的低秩误差协方差，以及最终层参数的全秩误差协方差。尽管这表征了一个不恰当的后验，但我们表明所得到的后验预测分布是明确定义的。我们的方法在线更新所有网络参数，无需回放缓冲区或离线再训练。我们通过经验证明，我们的方法在（非平稳）上下文化赌博机问题和贝叶斯优化问题上，在速度和准确性之间取得了有竞争力的权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [587] [A Neural Rejection System Against Universal Adversarial Perturbations in Radio Signal Classification](https://arxiv.org/abs/2506.11901)
> *一种针对无线电信号分类中通用对抗性扰动的神经拒绝系统*

*Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Fabio Roli* | **Main category: cs.LG**

**Keywords:** 通用对抗性扰动, 无线电信号分类, 神经拒绝系统, 深度学习, 对抗性样本

**Comment:** 

> **TL;DR:** 深度学习在无线电信号分类中容易受到通用对抗性扰动的影响。本文提出了一种神经拒绝系统来防御这些扰动，并显示其准确性显著提高。

**AI_Comments:** 该论文创新性地解决了深度学习在无线电信号分类应用中的一个关键安全漏洞。特别关注“通用”对抗性扰动具有重要意义，因为其数据无关的特性使其成为一种实际威胁。所提出的“神经拒绝系统”提供了一种有前景的防御策略。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，深度学习在无线电信号分类方面表现出色，但研究发现，即使是微小的对抗性扰动（特别是数据无关的通用对抗性扰动）也能显著降低其性能。因此，需要一个有效的防御系统。

**Method:** 本文研究并提出了一种名为“神经拒绝系统”的防御机制，旨在对抗通用对抗性扰动。通过生成白盒通用对抗性扰动来评估该系统的性能。

**Result:** 所提出的神经拒绝系统能够以比未防御的深度神经网络显著更高的准确率防御通用对抗性扰动。

**Conclusion:** 神经拒绝系统是防御无线电信号分类中通用对抗性扰动的有效方法。

> **ai_Abstract:** 本文针对深度学习在无线电信号分类中易受通用对抗性扰动攻击的问题，提出了一种神经拒绝系统作为防御机制。通过生成白盒通用对抗性扰动进行评估，结果表明该系统能显著提高防御准确率，优于未防御的深度神经网络。

> **摘要翻译:** 近年来，深度学习在无线电信号分类方面已显示出优于传统方法的优势。然而，各种研究人员发现，即使是微小但有意的特征扰动（称为对抗性样本）也能显著降低基于深度学习的无线电信号分类的性能。在各种对抗性样本中，通用对抗性扰动因其数据无关的特性而受到广泛关注，因此成为一种以高成功率欺骗无线电信号分类的实用策略。因此，在本文中，我们研究了一种名为神经拒绝系统的防御系统，以对抗通用对抗性扰动，并通过生成白盒通用对抗性扰动来评估其性能。我们表明，所提出的神经拒绝系统能够以比未防御的深度神经网络显著更高的准确率防御通用对抗性扰动。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [588] [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://arxiv.org/abs/2506.11902)
> *TreeRL：基于策略树搜索的LLM强化学习*

*Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong* | **Main category: cs.LG**

**Keywords:** 强化学习, 大型语言模型, 树搜索, 在线策略, 推理

**Comment:** Accepted to ACL 2025 main conference

> **TL;DR:** TreeRL是一个将基于策略树搜索直接整合到LLM强化学习中的框架，它在数学和代码推理任务上表现优异，且无需单独训练奖励模型。

**AI_Comments:** TreeRL的创新之处在于将树搜索与LLM强化学习深度结合，尤其是在线策略和无需单独奖励模型训练的特点，有效解决了现有方法的痛点。其高效的树搜索策略也值得关注，提升了实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM强化学习方法在基于策略树搜索方面探索不足，且通常需要训练一个单独的奖励模型，这可能导致分布不匹配和奖励作弊问题。

**Method:** 提出TreeRL，一个直接将基于策略树搜索整合到RL训练中的强化学习框架。该方法包括中间监督，并消除了对单独奖励模型训练的需求。此外，还引入了一种成本效益高的树搜索方法，通过从高不确定性中间步骤进行战略性分支而非随机分支，在相同生成token预算下实现更高的搜索效率。

**Result:** 在具有挑战性的数学和代码推理基准测试中，TreeRL比传统的ChainRL取得了卓越的性能。

**Conclusion:** 树搜索在LLM强化学习中具有巨大潜力，TreeRL证明了其有效性。

> **ai_Abstract:** TreeRL是一个创新的强化学习框架，它将基于策略的树搜索直接整合到大型语言模型（LLM）的强化学习训练中。该方法通过中间监督避免了单独奖励模型的训练，并引入了一种高效的树搜索策略，通过识别高不确定性步骤进行智能分支。实验证明，TreeRL在数学和代码推理任务上超越了传统方法，展示了树搜索在LLM领域应用的巨大潜力。

> **摘要翻译:** 强化学习（RL）与树搜索相结合在传统推理任务中表现出卓越的性能。与传统的带结果监督的独立链式采样策略相比，树搜索能够更好地探索推理空间，并在RL训练期间提供密集的、基于策略的过程奖励，但在基于策略的LLM强化学习中仍未得到充分探索。我们提出了TreeRL，一个直接将基于策略树搜索整合到RL训练中的强化学习框架。我们的方法包括中间监督，并消除了对单独奖励模型训练的需求。现有方法通常训练一个单独的过程奖励模型，这可能导致分布不匹配和奖励作弊。我们还引入了一种成本效益高的树搜索方法，通过从高不确定性中间步骤进行战略性分支而不是使用随机分支，在相同的生成token预算下实现了更高的搜索效率。在具有挑战性的数学和代码推理基准测试上的实验表明，与传统ChainRL相比，TreeRL取得了卓越的性能，突出了树搜索在LLM中的潜力。TreeRL已在https://github.com/THUDM/TreeRL 开源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [589] [Spectra-to-Structure and Structure-to-Spectra Inference Across the Periodic Table](https://arxiv.org/abs/2506.11908)
> *跨周期表的谱图到结构和结构到谱图推断*

*Yufeng Wang, Peiyao Wang, Lu Ma, Yuewei Lin, Qun Liu, Haibin Ling* | **Main category: cs.LG**

**Keywords:** X射线吸收光谱, 机器学习, 结构推断, 谱图预测, XAStruct

**Comment:** 

> **TL;DR:** XAStruct是一个机器学习框架，能够从晶体结构预测XAS谱图，并从XAS输入推断局部结构描述符，适用于周期表中70多种元素，无需元素特异性调整。

**AI_Comments:** XAStruct的创新之处在于其能够跨周期表泛化到70多种元素，并通过机器学习直接预测邻近原子类型，这在XAS解释中是一个重要突破。它解决了传统XAS解释中对专家知识、高计算成本和元素特异性限制的依赖。通过将双向任务独立训练，确保了模型的准确性，尽管未能实现端到端集成，但这种模块化设计可能更具鲁棒性。该框架为数据驱动的XAS分析开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** X射线吸收光谱（XAS）在探测局部原子环境方面功能强大，但其解释受限于专家驱动分析、计算昂贵的模拟和元素特异性启发式方法。现有机器学习模型通常只专注于特定元素、边缘类型或光谱范围。

**Method:** 提出XAStruct框架，它能够从晶体结构预测XAS谱图，并从XAS输入推断局部结构描述符。XAStruct在大规模数据集上训练，该数据集涵盖周期表中70多种元素。该模型包括第一个直接从XAS谱图预测邻近原子类型的机器学习方法，以及一个无需元素特异性调整的平均最近邻距离的统一回归模型。为确保最佳准确性，谱图到结构和结构到谱图的任务独立训练，而不是集成到一个端到端模型中。结合深度神经网络处理复杂结构-性质映射和高效基线模型处理简单任务。

**Result:** XAStruct能够预测XAS谱图并推断局部结构描述符。它包括首个直接从XAS谱图预测邻近原子类型的机器学习方法。同时，提供了一个无需元素特异性调整的统一平均最近邻距离回归模型。经验结果表明，将两个管道集成到单一端到端模型会导致性能下降，因此两个任务独立训练以确保最佳准确性和任务特定性能。

**Conclusion:** XAStruct通过结合深度神经网络和高效基线模型，为数据驱动的XAS分析和局部结构推断提供了一个可扩展且可扩展的解决方案，能够泛化到多种化学和键合环境。

> **ai_Abstract:** 该论文提出了XAStruct，一个用于X射线吸收光谱（XAS）分析的机器学习框架。XAStruct能够双向推断：从晶体结构预测XAS谱图，并从XAS谱图推断局部结构信息。该模型在一个包含周期表中70多种元素的大规模数据集上进行训练，具有广泛的泛化能力。XAStruct引入了首个直接从XAS谱图预测邻近原子类型的机器学习方法，并提供了一个无需元素特异性调整的统一平均最近邻距离回归模型。为优化性能，谱图到结构和结构到谱图的任务独立训练。该框架结合了深度神经网络和高效基线模型，为XAS分析和局部结构推断提供了一个可扩展的解决方案。

> **摘要翻译:** X射线吸收光谱（XAS）是一种探测局部原子环境的强大技术，但其解释仍受限于需要专家驱动的分析、计算成本高昂的模拟以及元素特异性启发式方法。机器学习的最新进展已显示出加速XAS解释的潜力，但许多现有模型狭隘地专注于特定元素、边缘类型或光谱范围。在这项工作中，我们提出了XAStruct，这是一个学习框架，能够从晶体结构预测XAS谱图，并从XAS输入推断局部结构描述符。XAStruct在一个涵盖周期表中70多种元素的大规模数据集上进行训练，使其能够泛化到各种化学和键合环境。该模型包括第一个直接从XAS谱图预测邻近原子类型的机器学习方法，以及一个无需元素特异性调整的平均最近邻距离的统一回归模型。虽然我们探索了将两个管道集成到单个端到端模型中，但经验结果显示性能下降。因此，这两个任务是独立训练的，以确保最佳准确性和任务特定性能。通过将用于复杂结构-性质映射的深度神经网络与用于简单任务的高效基线模型相结合，XAStruct为数据驱动的XAS分析和局部结构推断提供了一个可扩展且可扩展的解决方案。源代码将在论文接受后发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [591] [Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations](https://arxiv.org/abs/2506.11912)
> *打破习惯：优势函数在学习因果状态表示中的作用*

*Miguel Suau* | **Main category: cs.LG**

**Keywords:** 优势函数, 策略混淆, 强化学习, 因果表示, 泛化

**Comment:** 

> **TL;DR:** 本文研究了强化学习中策略混淆的问题，并证明了优势函数不仅能降低梯度估计的方差，还能有效缓解策略混淆，从而提高智能体在未见过轨迹上的泛化能力。

**AI_Comments:** 这篇论文的创新点在于揭示了优势函数除了降低方差之外的另一个重要作用——缓解策略混淆。这为理解和改进强化学习的泛化能力提供了新的视角。其重要性在于它提出了一个实用的方法来解决强化学习中一个长期存在的问题，即智能体容易学习到虚假关联而非真正的因果关系。这对于开发更鲁棒、更具泛化能力的RL智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最近的研究表明，强化学习智能体可能会学习利用奖励和观测之间虚假关联的策略，这种现象称为策略混淆。它会产生一个反馈循环，阻碍智能体泛化到其常规轨迹之外的能力。

**Method:** 本文证明了在策略梯度方法中常用的优势函数，不仅能降低梯度估计的方差，还能减轻策略混淆的影响。通过根据状态表示调整动作值，优势函数会降低在当前策略下更可能出现的“状态-动作”对的权重，从而打破虚假关联并鼓励智能体关注因果因素。

**Result:** 分析和实证证据表明，使用优势函数进行训练可以提高智能体在轨迹外（out-of-trajectory）的性能。

**Conclusion:** 优势函数在缓解策略混淆方面发挥着关键作用，通过调整动作值并降低虚假关联的权重，它能帮助强化学习智能体学习更具因果性、泛化能力更强的状态表示，从而提升在未见过轨迹上的表现。

> **ai_Abstract:** 本文探讨了强化学习中策略混淆的问题，即智能体学习利用奖励与观测之间虚假关联的现象，这会限制其泛化能力。研究发现，策略梯度方法中常用的优势函数不仅能减少梯度估计的方差，还能有效缓解策略混淆。通过调整动作值并降低虚假关联的权重，优势函数能帮助智能体关注真正的因果因素。分析和实验结果均表明，利用优势函数进行训练能够显著提升智能体在未见过轨迹上的表现。

> **摘要翻译:** 最近的工作表明，强化学习智能体可以开发利用奖励和观测之间虚假关联的策略。这种现象被称为策略混淆，它之所以产生，是因为智能体的策略会影响过去和未来的观测变量，从而形成一个反馈循环，阻碍智能体泛化到其常规轨迹之外的能力。在本文中，我们表明，在策略梯度方法中常用的优势函数不仅能降低梯度估计的方差，还能减轻策略混淆的影响。通过根据状态表示调整动作值，优势函数会降低在当前策略下更可能出现的“状态-动作”对的权重，从而打破虚假关联并鼓励智能体关注因果因素。我们提供了分析和实证证据，证明使用优势函数进行训练可以提高轨迹外性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [592] [Visual Pre-Training on Unlabeled Images using Reinforcement Learning](https://arxiv.org/abs/2506.11967)
> *强化学习在无标签图像上的视觉预训练*

*Dibya Ghosh, Sergey Levine* | **Main category: cs.LG**

**Keywords:** 视觉预训练, 强化学习, 自监督学习, 无标签图像, 通用价值函数

**Comment:** 

> **TL;DR:** 该论文提出将无标签图像的视觉预训练直接建模为强化学习问题，通过训练一个通用价值函数来学习图像特征，并在多种无标签数据集上展示了改进的表示。

**AI_Comments:** 这篇论文通过将自监督预训练与强化学习进行创新性结合，为无标签图像数据的特征学习提供了一个新颖的视角。其核心创新在于将图像变换视为智能体的动作，并利用通用价值函数进行学习，同时引入奖励函数作为调节特征学习的灵活杠杆。这种方法有望在数据标注成本高昂的领域带来突破，特别是当存在少量弱监督信息时。

<details>
  <summary>Details</summary>

**Motivation:** 作者观察到许多自监督图像预训练方法与强化学习中的价值函数学习有相似之处，因此提出将无标签图像预训练直接视为一个强化学习问题，以探索一种新的特征学习方法，并通过奖励函数提供塑造特征学习的杠杆。

**Method:** 作者将无标签图像数据（如网络爬取和视频帧）上的预训练直接建模为强化学习问题。他们在一个动态系统中训练一个通用价值函数，其中智能体通过改变视角或添加图像增强来转换图像。这种学习方式类似于裁剪一致性自监督，但通过奖励函数，可以在存在精选图像或弱标签字幕时，提供一个简单的杠杆来塑造特征学习。

**Result:** 实验证明，在野外无标签图像（包括EpicKitchens等视频数据、COCO等场景数据以及CC12M等网络爬取数据）上进行训练时，表示效果得到了改善。

**Conclusion:** 通过将无标签图像的视觉预训练建模为强化学习问题，并利用奖励函数进行特征塑造，可以学习到改进的图像表示。

> **ai_Abstract:** 本文提出了一种新颖的视觉预训练方法，将无标签图像数据上的特征学习直接视为强化学习问题。通过在一个动态系统中训练一个通用价值函数，其中智能体通过图像变换（如改变视角或增强）来学习，该方法能够从无标签数据中学习有效的图像表示。与传统的自监督方法相比，这种基于RL的框架通过奖励函数提供了更大的灵活性，可以利用额外的（即使是弱）监督来塑造特征学习。实验结果表明，该方法在多种真实世界的无标签数据集（包括视频和网络爬取数据）上显著改善了图像表示。

> **摘要翻译:** 在强化学习（RL）中，基于价值的算法学习将每个观察与可能从其达到的状态和奖励相关联。我们观察到许多自监督图像预训练方法与这种表述相似：学习将图像的裁剪与附近视图的裁剪相关联的特征，例如，通过采取不同的裁剪或颜色增强。在本文中，我们完善了这种类比，并探索了一种直接将无标签图像数据（如网络爬虫和视频帧）上的预训练视为强化学习问题的方法。我们在一个动态系统中训练一个通用价值函数，其中智能体通过改变视角或添加图像增强来转换图像。这种学习方式类似于裁剪一致性自监督，但通过奖励函数，可以在存在精选图像或弱标签字幕时，提供一个简单的杠杆来塑造特征学习。我们的实验表明，在野外无标签图像上进行训练时，表示效果得到了改善，包括EpicKitchens等视频数据、COCO等场景数据以及CC12M等网络爬取数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [594] [Self-Regulating Cars: Automating Traffic Control in Free Flow Road Networks](https://arxiv.org/abs/2506.11973)
> *自调节汽车：自由流路网中的交通控制自动化*

*Ankit Bhardwaj, Rohail Asim, Sachin Chauhan, Yasir Zaki, Lakshminarayanan Subramanian* | **Main category: cs.LG**

**Keywords:** 自调节汽车, 强化学习, 交通控制, 自由流路网, 交通拥堵

**Comment:** 

> **TL;DR:** 提出了一种基于强化学习的自调节汽车协议，通过动态调节车速来优化自由流路网的交通吞吐量并防止拥堵，无需新增物理基础设施。

**AI_Comments:** 该论文的创新点在于将强化学习应用于自由流路网的交通控制，并提出了“自调节汽车”的概念，通过软件层面的速度调节实现交通优化，避免了昂贵的物理基础设施改造。其结合经典交通流理论与现代机器学习的物理信息强化学习框架具有重要意义，为解决高速公路拥堵提供了新思路。研究成果在实际模拟器中的表现良好，表明了其潜在的实用价值和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 自由流路网（如郊区高速公路）因通勤量增加和基础设施有限而日益面临交通拥堵。传统控制机制在这些高速、无信号环境中无效或不可行。

**Method:** 引入了自调节汽车，这是一种基于强化学习的交通控制协议，通过动态调节车速来优化吞吐量和防止拥堵。该方法将经典交通流理论、间隙接受模型和微观模拟整合到物理信息强化学习框架中。通过将道路抽象为超路段，代理能够捕捉突发流动力学并从瞬时交通观测中学习鲁棒的速度调制策略。

**Result:** 在PTV Vissim模拟器上，与无控制设置相比，该方法将总吞吐量提高了5%，平均延误减少了13%，总停车次数减少了3%。它还实现了更平稳、抗拥堵的交通流，并能泛化到不同的交通模式。

**Conclusion:** 该研究证明了自调节汽车在可扩展的、机器学习驱动的交通管理方面的潜力。

> **ai_Abstract:** 本文提出了一种名为“自调节汽车”的强化学习交通控制协议，旨在解决自由流路网中的交通拥堵问题。该协议通过动态调节车辆速度来优化交通吞吐量并防止拥堵，且无需新增物理基础设施。该方法结合了交通流理论、间隙接受模型和微观模拟，构建了一个物理信息强化学习框架。在PTV Vissim模拟器上的评估显示，该方法显著提高了吞吐量，减少了延误和停车次数，并实现了更平稳、抗拥堵的交通流，展示了其在智能交通管理领域的应用潜力。

> **摘要翻译:** 自由流路网，例如郊区高速公路，由于通勤车流量的增加和基础设施的限制，正日益经历交通拥堵。传统的控制机制，例如交通信号或局部启发式方法，在这些高速、无信号的环境中是无效或不可行的。我们引入了自调节汽车，这是一种基于强化学习的交通控制协议，它动态调节车辆速度以优化吞吐量并防止拥堵，而无需新的物理基础设施。我们的方法将经典交通流理论、间隙接受模型和微观模拟集成到一个物理信息强化学习框架中。通过将道路抽象为超路段，代理能够捕捉突发流动力学并从瞬时交通观测中学习鲁棒的速度调制策略。在真实世界高速公路网络的高保真PTV Vissim模拟器中进行评估，我们的方法与无控制设置相比，将总吞吐量提高了5%，平均延误减少了13%，总停车次数减少了3%。它还实现了更平稳、抗拥堵的交通流，同时能够泛化到不同的交通模式，展示了其在可扩展的、机器学习驱动的交通管理方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [595] [Compression Aware Certified Training](https://arxiv.org/abs/2506.11992)
> *压缩感知认证训练*

*Changming Xu, Gagandeep Singh* | **Main category: cs.LG**

**Keywords:** 深度神经网络, 模型压缩, 认证鲁棒性, CACTUS, 剪枝, 量化

**Comment:** 19 pages, 1 figure

> **TL;DR:** 提出CACTUS框架，在训练过程中统一深度神经网络的效率和认证鲁棒性，使其在压缩后仍保持高认证精度。

**AI_Comments:** CACTUS的创新之处在于其将模型压缩和认证鲁棒性这两个传统上独立的目标在训练阶段进行统一，这对于在资源受限且对安全性要求高的环境中部署深度学习模型具有重要意义。其通用框架的特性也使其能够应用于不同的压缩技术（如剪枝和量化）。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法将压缩和认证鲁棒性视为独立目标，导致在安全关键、资源受限环境中部署深度神经网络时，效率或安全性受损。

**Method:** 提出CACTUS（Compression Aware Certified Training Using network Sets）框架，在训练过程中统一压缩和认证鲁棒性目标。CACTUS模型即使在压缩后也能保持高认证精度。该方法应用于剪枝和量化。

**Result:** CACTUS有效地训练出可高效压缩同时保持高精度和可认证鲁棒性的模型。在多种数据集和输入规范上，CACTUS在剪枝和量化方面均实现了最先进的精度和认证性能。

**Conclusion:** CACTUS框架成功地在训练过程中统一了深度神经网络的效率和认证鲁棒性，使得模型在压缩后仍能保持高认证精度和最先进的性能。

> **ai_Abstract:** 本文提出了CACTUS（Compression Aware Certified Training Using network Sets）框架，旨在解决深度神经网络在安全关键、资源受限环境中部署时，现有方法无法同时兼顾效率和认证鲁棒性的问题。CACTUS通过在训练过程中统一压缩和认证鲁棒性目标，使得模型在剪枝和量化等压缩操作后仍能保持高认证精度。实验证明，CACTUS在多种数据集上实现了压缩后模型的最先进精度和认证性能。

> **摘要翻译:** 深度神经网络在安全关键、资源受限的环境中部署时，必须平衡效率和鲁棒性。现有方法将压缩和认证鲁棒性视为独立目标，导致效率或安全性受损。我们提出了CACTUS（Compression Aware Certified Training Using network Sets），这是一个在训练过程中统一这些目标的通用框架。CACTUS模型即使在压缩后也能保持高认证精度。我们将CACTUS应用于剪枝和量化，结果表明它能有效地训练出可高效压缩同时保持高精度和可认证鲁棒性的模型。CACTUS在多种数据集和输入规范上，在剪枝和量化方面均实现了最先进的精度和认证性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [596] [pLSTM: parallelizable Linear Source Transition Mark networks](https://arxiv.org/abs/2506.11997)
> *pLSTM: 可并行化的线性源转换标记网络*

*Korbinian Pöppel, Richard Freinschlag, Thomas Schmied, Wei Lin, Sepp Hochreiter* | **Main category: cs.LG**

**Keywords:** pLSTM, 循环神经网络, 有向无环图, 并行化, 长距离依赖

**Comment:** 

> **TL;DR:** pLSTM是一种新型循环神经网络，专门设计用于处理有向无环图（DAGs）等复杂多维数据，实现了并行化并有效解决了长距离依赖问题，在多项任务中表现优异。

**AI_Comments:** pLSTM的创新之处在于将线性RNNs的多维概念扩展到DAGs，并通过设计特定的门控机制实现了并行化，同时有效解决了长距离依赖的梯度问题。其在处理非序列化多维数据方面的优势，以及在长距离外推任务上超越Transformer的表现，显示了其潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现代循环架构（如xLSTM和Mamba）在语言建模中挑战了Transformer，但它们结构限制了其仅适用于序列数据或需要预定义顺序处理多维数据。多维循环神经网络（MDRNNs）适用于高层结构数据，但线性RNNs缺乏多维扩展和并行化能力。

**Method:** 本文引入了可并行化的线性源转换标记网络（pLSTMs），使用源、转换和标记门作用于通用DAG的线图。这使得并行化成为可能，类似于并行关联扫描和分块循环形式的线性RNN。对于规则网格（1D和2D），该方案可使用einsum操作、拼接和填充在对数时间内高效实现。pLSTMs通过定向传播模式（P-mode）和扩散分布模式（D-mode）两种模式，解决了DAG中长距离的激活/梯度消失/爆炸问题。

**Result:** pLSTMs在合成计算机视觉任务（箭头指向外推）中展示了良好的长距离泛化能力，即使在更大的图像尺寸下，而Transformer则难以外推。在已有的分子图和计算机视觉基准测试中，pLSTMs也表现出强大的性能。

**Conclusion:** pLSTM是一种有效且可并行化的新型循环网络，能够处理复杂的多维数据结构，并解决了长距离依赖问题，在多个任务上表现出强大的性能和泛化能力。

> **ai_Abstract:** 本文提出了pLSTM（可并行化的线性源转换标记网络），这是一种新型的循环神经网络架构，旨在解决传统循环网络和Transformer在处理多维数据结构（如DAGs、图像、分子图）时的局限性，特别是长距离依赖问题。pLSTM通过作用于DAG的线图并引入源、转换和标记门来实现并行化，并能通过两种模式（P-mode和D-mode）处理梯度问题。实验证明，pLSTM在处理长距离依赖的计算机视觉任务和现有基准测试中表现出色，尤其在泛化到更大图像尺寸方面优于Transformer。

> **摘要翻译:** 现代循环架构，如xLSTM和Mamba，最近在语言建模领域对Transformer提出了挑战。然而，它们的结构限制了其仅适用于序列数据，或要求以预定义的顺序处理多维数据结构，例如图像或分子图。相比之下，多维循环神经网络（MDRNNs）非常适合处理具有更高层结构的数据，如二维网格、树和有向无环图（DAGs）。在这项工作中，我们将多维度的概念扩展到线性循环神经网络。我们引入了可并行化的线性源转换标记网络（pLSTMs），其使用源、转换和标记门作用于通用DAG的线图。这使得并行化成为可能，类似于并行关联扫描和顺序线性RNN的分块循环形式，但适用于DAGs。对于规则网格（一维和二维），如图像，这种方案可以使用einsum操作、拼接和填充在对数时间内高效实现。pLSTMs通过两种不同的模式：定向传播模式（P-mode）和扩散分布模式（D-mode），解决了DAG中长距离的激活/梯度消失/爆炸问题。为了展示pLSTM的长距离能力，我们引入了箭头指向外推（arrow-pointing extrapolation）作为一项合成计算机视觉任务，该任务包含长距离的方向信息。我们证明了pLSTMs能够很好地泛化到更大的图像尺寸，而Transformer则难以进行外推。在已有的分子图和计算机视觉基准测试中，pLSTMs也表现出强大的性能。代码和数据集可在https://github.com/ml-jku/plstm_experiments 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [597] [An Efficient Compression of Deep Neural Network Checkpoints Based on Prediction and Context Modeling](https://arxiv.org/abs/2506.12000)
> *深度神经网络检查点基于预测和上下文建模的高效压缩*

*Yuriy Kim, Evgeny Belyaev* | **Main category: cs.LG**

**Keywords:** 深度神经网络, 检查点压缩, 预测压缩, 上下文建模, 剪枝, 量化

**Comment:** IEEE NW Russia Young Researchers in Electrical and Electronic
  Engineering Conference (EIConRusNW)

> **TL;DR:** 本文提出了一种高效压缩深度神经网络训练过程中检查点的方法，结合了预测、上下文建模、剪枝和量化，实现了显著的位大小缩减和近无损训练恢复。

**AI_Comments:** 这项工作通过结合预测、上下文建模、剪枝和量化，为深度学习模型的存储优化提供了一种实用的解决方案，特别是在分布式训练或资源受限的部署场景中具有重要意义。其创新之处在于将多种压缩技术有效整合，实现了高效压缩与性能保持的平衡。

<details>
  <summary>Details</summary>

**Motivation:** 解决深度神经网络训练过程中检查点（权重和优化器状态）的存储问题，尤其是在存储受限的环境中。

**Method:** 1. 提出基于预测的压缩方法，利用先前保存的检查点值进行算术编码的上下文建模。2. 应用剪枝和量化来增强压缩性能。

**Result:** 实现了显著的位大小缩减，同时能够从恢复的检查点进行近无损的训练恢复，保持模型性能，并适用于存储受限环境。

**Conclusion:** 该方法能有效压缩深度神经网络检查点，显著减少存储需求，同时不影响模型性能和训练恢复能力。

> **ai_Abstract:** 本文提出了一种高效压缩深度神经网络检查点的方法，结合了基于预测的上下文建模算术编码以及剪枝和量化技术。实验证明该方法能显著减小检查点大小，同时保持模型性能并实现近无损的训练恢复，使其适用于存储资源有限的场景。

> **摘要翻译:** 本文致力于高效压缩神经网络训练过程中不同阶段获得的权重和优化器状态（称为检查点）。首先，我们提出了一种基于预测的压缩方法，其中使用先前保存的检查点中的值进行算术编码中的上下文建模。其次，为了提高压缩性能，我们还建议对检查点值进行剪枝和量化。实验结果表明，我们的方法实现了显著的位大小缩减，同时能够从恢复的检查点进行近无损的训练恢复，保持模型性能，并使其适用于存储受限的环境。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [598] [SIMSHIFT: A Benchmark for Adapting Neural Surrogates to Distribution Shifts](https://arxiv.org/abs/2506.12007)
> *SIMSHIFT：一个用于使神经代理适应分布变化的基准*

*Paul Setinek, Gianluca Galletti, Thomas Gross, Dominik Schnürer, Johannes Brandstetter, Werner Zellinger* | **Main category: cs.LG**

**Keywords:** 神经代理, 分布变化, 域适应, 工业仿真, SIMSHIFT

**Comment:** 

> **TL;DR:** SIMSHIFT是一个新的基准数据集和评估套件，用于解决偏微分方程神经代理在未见配置下性能下降的问题。它扩展了域适应方法并对其进行了系统评估，旨在在工业仿真中实现更稳健的神经代理。

**AI_Comments:** 本论文的创新之处在于提出了SIMSHIFT这一新的基准数据集和评估套件，专门用于研究神经代理在工业仿真中面对分布变化时的适应性问题。它首次将域适应技术系统性地应用于偏微分方程的神经代理，为该领域提供了一个重要的研究平台。然而，论文也明确指出了在实现稳健的神经代理方面仍然存在的挑战和开放问题，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 偏微分方程 (PDE) 的神经代理在遇到未见的问题配置（如新型材料或结构尺寸）时，性能会显著下降。同时，域适应 (DA) 技术已广泛应用于视觉和语言处理中，以从有限的未见配置信息中进行泛化。本研究旨在弥补这一差距。

**Method:** 本研究通过两项主要贡献来解决问题：1) 引入了SIMSHIFT，一个新颖的基准数据集和评估套件，包含四个工业仿真任务：热轧、钣金成形、电机设计和散热器设计。2) 将已有的域适应方法扩展到最先进的神经代理，并对其进行系统评估。这些方法利用来自多个源配置的参数描述和真实仿真数据，以及仅来自目标配置的参数描述，目标是在不访问目标真实仿真数据的情况下准确预测目标仿真。

**Result:** 在SIMSHIFT上进行的广泛实验突出了分布外神经代理建模的挑战，展示了域适应在仿真中的潜力，并揭示了在工业相关场景中实现分布变化下稳健神经代理的开放问题。

**Conclusion:** 该研究表明，尽管域适应在解决工业仿真中神经代理的分布变化问题上具有潜力，但在实现稳健的神经代理方面仍存在显著挑战和开放问题。

> **ai_Abstract:** 本研究介绍了SIMSHIFT，一个专为解决偏微分方程神经代理在面对未见配置时性能下降问题而设计的基准数据集和评估套件。该基准包含热轧、钣金成形等四个工业仿真任务。作者将现有域适应方法应用于最先进的神经代理，并在SIMSHIFT上进行了系统评估。实验结果揭示了分布外神经代理建模的挑战，证明了域适应在仿真领域的潜力，并指出了在工业场景中实现对分布变化具有鲁棒性的神经代理所面临的开放问题。

> **摘要翻译:** 偏微分方程 (PDE) 的神经代理在评估未见的问题配置（如新型材料类型或结构尺寸）时，经常会遭受显著的性能下降。与此同时，域适应 (DA) 技术已广泛应用于视觉和语言处理中，以从有限的未见配置信息中进行泛化。在这项工作中，我们通过两项重点贡献来弥补这一差距。首先，我们引入了SIMSHIFT，一个新颖的基准数据集和评估套件，由四个工业仿真任务组成：热轧、钣金成形、电机设计和散热器设计。其次，我们将已有的域适应方法扩展到最先进的神经代理，并对其进行了系统评估。这些方法利用来自多个源配置的参数描述和真实仿真数据，以及仅来自目标配置的参数描述。目标是在不访问真实仿真数据的情况下准确预测目标仿真。在SIMSHIFT上进行的广泛实验突出了分布外神经代理建模的挑战，展示了域适应在仿真中的潜力，并揭示了在工业相关场景中实现分布变化下稳健神经代理的开放问题。我们的代码库可在 https://github.com/psetinek/simshift 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [599] [EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction](https://arxiv.org/abs/2506.12015)
> *EMLoC：基于模拟器的内存高效LoRA校正微调*

*Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang* | **Main category: cs.LG**

**Keywords:** 内存高效微调, LoRA, 模拟器, 奇异值分解, 大模型

**Comment:** Under review. Project page: https://hsi-che-lin.github.io/EMLoC/

> **TL;DR:** EMLoC是一种基于模拟器的内存高效微调框架，通过LoRA校正，使得大型模型可以在与推理相同的内存预算下进行微调，甚至在单个24GB消费级GPU上微调38B模型。

**AI_Comments:** EMLoC的创新点在于结合了模拟器和LoRA校正来解决大型模型微调的内存瓶颈。通过SVD构建轻量级模拟器进行微调，并引入补偿算法来弥补压缩带来的误差，这是一种新颖且实用的方法。其重要性体现在它能让更多个人用户和资源有限的团队也能进行大型模型的微调，降低了AI技术应用的门槛，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对领域特定或个性化任务微调大型基础模型，其内存开销巨大，对大多数用户来说成本过高。

**Method:** EMLoC通过在小型下游校准集上使用激活感知奇异值分解(SVD)构建一个任务特定的轻量级模拟器。然后通过LoRA在这个轻量级模拟器上进行微调。为了解决原始模型和压缩模拟器之间的不一致，提出了一种新颖的补偿算法来校正微调后的LoRA模块，使其可以合并到原始模型中进行推理。

**Result:** EMLoC在多个数据集和模态上优于其他基线。在不进行量化的情况下，EMLoC能够在单个24GB消费级GPU上微调一个38B模型。

**Conclusion:** EMLoC提供了一种高效且实用的模型适应方案，使得个人用户也能进行大型模型的微调，显著降低了内存开销。

> **ai_Abstract:** EMLoC是一种创新的、基于模拟器的内存高效微调框架，它结合了LoRA校正技术。该框架通过构建轻量级模拟器并在其上进行LoRA微调，并引入补偿算法解决模型与模拟器之间的不一致性，从而显著降低了大型模型微调所需的内存开销，使其能够在与推理相同的内存预算下运行。实验证明，EMLoC在性能上超越现有基线，并成功在单个消费级GPU上微调大型模型，极大地提升了模型适应的实用性和可及性。

> **摘要翻译:** 开源基础模型得到了快速采用和发展，在不同领域实现了强大的通用能力。然而，针对领域特定或个性化任务微调大型基础模型，对于大多数用户来说仍然成本过高，因为其内存开销远超推理所需。我们引入了EMLoC，一个基于模拟器的内存高效微调框架，带LoRA校正，它使得模型微调可以在与推理相同的内存预算内进行。EMLoC通过在小型下游校准集上使用激活感知奇异值分解（SVD）构建一个任务特定的轻量级模拟器。然后通过LoRA在这个轻量级模拟器上进行微调。为了解决原始模型和压缩模拟器之间的不一致性，我们提出了一种新颖的补偿算法来校正微调后的LoRA模块，从而可以将其合并到原始模型中进行推理。EMLoC支持灵活的压缩比和标准训练流程，使其适用于广泛的应用。广泛的实验表明，EMLoC在多个数据集和模态上优于其他基线。此外，在不进行量化的情况下，EMLoC使得在单个24GB消费级GPU上微调一个38B模型成为可能——为个人用户带来了高效实用的模型适应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [6] [Shapley Machine: A Game-Theoretic Framework for N-Agent Ad Hoc Teamwork](https://arxiv.org/abs/2506.11285)
> *Shapley Machine：一个N智能体Ad Hoc团队合作的博弈论框架*

*Jianhong Wang, Yang Li, Samuel Kaski, Jonathan Lawry* | **Main category: cs.MA**

**Keywords:** Shapley Machine, N智能体ad hoc团队合作, 合作博弈论, 强化学习, 信用分配

**Comment:** 25 pages

> **TL;DR:** 本文提出了Shapley Machine，一个基于合作博弈论的强化学习算法，用于解决N智能体ad hoc团队合作问题，通过Shapley值进行贡献分配。

**AI_Comments:** 本文的创新点在于首次将合作博弈论中的Shapley值概念与强化学习相结合，为多智能体系统中的贡献分配提供了理论上严谨且可解释的框架。这对于解决开放多智能体系统中的信用分配问题具有重要意义，尤其是在缺乏明确奖励信号的ad hoc团队合作场景中。所提出的Shapley Machine算法，特别是其TD($\\lambda$)-like的Shapley值估计方法，是该领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 开放多智能体系统在实际应用中日益重要，但现有的N智能体ad hoc团队合作（NAHT）方法多基于启发式设计，缺乏理论严谨性，且智能体间的贡献分配不明确。

**Method:** 本文通过合作博弈论建模并解决了NAHT问题。首先将开放多智能体系统建模为合作博弈空间中的一个实例，该空间由一组基础博弈生成。接着将该空间和状态空间扩展以适应动态场景，从而刻画NAHT。利用基础博弈值对应不同时间范围N步回报的假设，将NAHT的状态值表示为类似于$\\lambda$-回报的形式。进一步，推导出Shapley值以将状态值分配给受控智能体，作为其对ad hoc团队贡献的奖励。不同于传统方法，本文通过满足唯一描述Shapley值的三个公理来塑造Shapley值。为了在动态场景中估计Shapley值，提出了一种TD($\\lambda$)-like算法，命名为Shapley Machine。

**Result:** 实验证明了Shapley Machine的有效性，并验证了理论的合理性。

**Conclusion:** Shapley Machine是首次将合作博弈论概念与强化学习概念直接关联起来的方法，有效解决了N智能体ad hoc团队合作中的贡献分配和理论严谨性问题。

> **ai_Abstract:** 本文提出了一种名为Shapley Machine的强化学习算法，旨在解决N智能体ad hoc团队合作（NAHT）问题。该方法通过合作博弈论框架，将开放多智能体系统建模为合作博弈，并利用扩展博弈空间和TD($\\lambda$)-like算法估计Shapley值，以公平分配受控智能体的贡献。实验验证了其有效性和理论合理性，是首次将合作博弈论与强化学习直接结合的工作。

> **摘要翻译:** 开放多智能体系统在建模智能电网、蜂群机器人等现实世界应用中变得日益重要。本文旨在研究一个最近提出的开放多智能体系统问题，即N智能体ad hoc团队合作（NAHT），其中只有部分智能体受到控制。现有方法倾向于基于启发式设计，因此缺乏理论严谨性，并且智能体之间的贡献分配模糊不清。为了解决这些局限性，我们通过合作博弈论的视角对NAHT进行建模和求解。更具体地说，我们首先将一个开放多智能体系统（以其价值为特征）建模为位于合作博弈空间中的一个实例，该空间由一组基础博弈生成。然后，我们扩展这个空间以及状态空间，以适应动态场景，从而刻画NAHT。利用基础博弈值对应于具有不同时间范围的N步回报序列这一合理假设，我们以类似于$\\lambda$-回报的形式表示NAHT的状态值。此外，我们推导出Shapley值，将其分配给受控智能体，作为它们对ad hoc团队贡献的奖励。与传统上以显式形式塑造Shapley值的方法不同，我们通过满足唯一描述Shapley值的三个公理来塑造Shapley值，这些公理在描述NAHT的扩展博弈空间上定义良好。为了在动态场景中估计Shapley值，我们提出了一种TD($\\lambda$)-like算法。由此产生的强化学习（RL）算法被称为Shapley Machine。据我们所知，这是首次将合作博弈论的概念与强化学习的概念直接关联起来。在实验中，我们展示了Shapley Machine的有效性，并验证了我们理论的合理性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [34] [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org/abs/2506.11475)
> *AutoGen驱动的多智能体框架用于迭代犯罪数据分析和预测*

*Syeda Kisaa Fatima, Tehreem Zubair, Noman Ahmed, Asifullah Khan* | **Main category: cs.MA**

**Keywords:** 多智能体, 犯罪数据分析, 预测, AutoGen, 离线执行

**Comment:** 

> **TL;DR:** 本文提出了LUCID-MA，一个基于AutoGen的多智能体AI框架，用于离线协作分析、理解和预测犯罪数据，通过100轮自我改进实现自主分析，并保持数据隐私。

**AI_Comments:** 该论文的创新点在于提出了一个多智能体协作的犯罪数据分析框架，并利用AutoGen风格的智能体实现了离线运行和自我改进，这对于保障数据隐私和提高分析效率具有重要意义。在社会科学领域，尤其是敏感的犯罪数据分析中，离线处理和减少人工干预的能力是一个显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过多智能体AI系统协作分析和理解犯罪数据，实现社会科学领域中犯罪数据分析的自主化、可扩展性和迭代性，并确保数据隐私。

**Method:** 本文提出了LUCID-MA (Learning and Understanding Crime through Dialogue of Multiple Agents) 框架，包含三个核心组件：分析助手（突出时空犯罪模式）、反馈组件（审查和完善分析结果）和预测组件（预测未来犯罪趋势）。该系统利用精心设计的提示和LLaMA-2-13B-Chat-GPTQ模型，完全离线运行。智能体通过100轮通信进行自我改进，并结合评分函数评估性能和跟踪学习进展。

**Result:** 该工作展示了AutoGen风格的智能体在社会科学领域进行自主、可扩展和迭代分析的潜力，并通过离线执行维护了数据隐私。

**Conclusion:** 本文证明了AutoGen风格的多智能体框架在处理犯罪数据分析和预测方面的有效性与潜力，特别是在实现自主性、可扩展性以及通过离线操作保障数据隐私方面。

> **ai_Abstract:** 本文提出了LUCID-MA，一个创新的多智能体AI框架，用于迭代分析和预测犯罪数据。该框架包含分析、反馈和预测三大核心组件，并利用LLaMA-2-13B-Chat-GPTQ模型进行离线运行。通过100轮通信和评分机制，智能体能够实现自我改进，从而在社会科学领域实现自主、可扩展且保护数据隐私的犯罪数据分析。

> **摘要翻译:** 本文介绍了LUCID-MA（通过多智能体对话学习和理解犯罪），这是一个创新的AI驱动框架，其中多个AI智能体协作分析和理解犯罪数据。我们的系统由三个核心组件组成：一个分析助手，用于突出时空犯罪模式；一个反馈组件，用于审查和完善分析结果；以及一个预测组件，用于预测未来的犯罪趋势。通过精心设计的提示和LLaMA-2-13B-Chat-GPTQ模型，它完全离线运行，并允许智能体通过100轮通信进行自我改进，减少了人工干预。系统中融入了一个评分函数来评估智能体的性能，并提供可视化图表来跟踪学习进度。这项工作展示了AutoGen风格的智能体在社会科学领域进行自主、可扩展和迭代分析的潜力，同时通过离线执行维护了数据隐私。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [62] [PE-MA: Parameter-Efficient Co-Evolution of Multi-Agent Systems](https://arxiv.org/abs/2506.11803)
> *PE-MA：参数高效的多智能体系统协同演化*

*Yingfan Deng, Anhao Zhou, Yuan Yuan, Xian Zhang, Yifei Zou, Dongxiao Yu* | **Main category: cs.MA**

**Keywords:** 多智能体系统, 协同演化, 参数高效, 个性化适配器, 收敛速度

**Comment:** arXiv admin note: text overlap with arXiv:2312.10815 by other authors

> **TL;DR:** PE-MA提出了一种参数高效的多智能体协同演化框架，通过结合轻量级个性化适配器和共享适配器，实现了高效、可扩展和个性化的多智能体协作，并达到了渐近最优的收敛速度。

**AI_Comments:** PE-MA的创新之处在于其参数高效的设计，通过结合个性化适配器和共享适配器，在解决多智能体系统中的关键挑战（通信开销和个性化）的同时，实现了高效的协同演化。其理论上的收敛性保证也增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体系统在协作推理和解决复杂任务方面面临高通信开销和智能体级别个性化不足的挑战。

**Method:** 本文提出了PE-MA（参数高效多智能体协同演化）框架。在该框架中，每个智能体维护一个轻量级的个性化适配器以支持智能体特定的行为，同时一个共享适配器在相邻智能体之间协同优化。这种设计在异构环境下平衡了全局协调与局部适应。

**Result:** PE-MA实现了渐近最优的收敛速度，为O( 1/(NK)^(1/2) )，其中N是智能体数量，K是局部更新步长。

**Conclusion:** PE-MA框架通过结合个性化和共享适配器，有效解决了多智能体系统中的通信开销和个性化问题，实现了高效、可扩展且个性化的协同演化，并提供了理论上的收敛性保证。

> **ai_Abstract:** 本文提出了PE-MA，一个参数高效的多智能体协同演化框架，旨在解决现有方法中高通信开销和个性化不足的问题。PE-MA通过为每个智能体分配轻量级个性化适配器和优化共享适配器，实现了全局协调与局部适应的平衡。该框架能够支持高效、可扩展和个性化的多智能体协作，并已证明达到渐近最优的收敛速度。

> **摘要翻译:** 多智能体系统最近已成为协作推理和解决复杂任务的一个有前景的范式。然而，多智能体系统中协作学习算法的设计面临一些挑战，包括高通信开销和智能体级别个性化不足。在本文中，我们提出了PE-MA（参数高效多智能体协同演化），一个新颖的协作框架，支持多智能体系统中高效、可扩展和个性化的协同演化。在PE-MA中，每个智能体维护一个轻量级的个性化适配器以支持智能体特定的行为，同时一个共享适配器在相邻智能体之间协同优化。这种设计在异构环境下平衡了全局协调与局部适应。我们实现了渐近最优的收敛速度，为O( 1/(NK)^(1/2) )，其中N是智能体数量，K是局部更新步长。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [7] [Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11234)
> *Poutine：视觉-语言-轨迹预训练与强化学习后训练实现鲁棒的端到端自动驾驶*

*Luke Rowe, Rodrigue de Schaetzen, Roger Girgis, Christopher Pal, Liam Paull* | **Main category: cs.RO**

**Keywords:** 自动驾驶, 视觉-语言模型, 预训练, 强化学习, 长尾场景

**Comment:** 

> **TL;DR:** Poutine是一个30亿参数的视觉-语言模型，通过视觉-语言-轨迹（VLT）预训练和强化学习（RL）微调，实现了在长尾驾驶场景中鲁棒的端到端自动驾驶，并在Waymo挑战赛中取得第一名。

**AI_Comments:** Poutine的创新之处在于结合了大规模视觉-语言-轨迹（VLT）预训练和轻量级强化学习微调，有效提升了模型在复杂长尾自动驾驶场景中的性能。其在Waymo挑战赛中取得第一名的成绩，充分证明了该方法的有效性和鲁棒性。该研究为未来端到端自动驾驶系统的发展提供了新的方向，尤其是在处理不常见驾驶情况方面。未来的工作可以探索如何进一步减少对偏好标注数据的依赖，以及提升模型在更广泛场景下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决长尾驾驶场景中端到端自动驾驶的挑战，需要开发一种能够有效处理复杂和不常见驾驶情况的模型。

**Method:** 本文提出了Poutine，一个30亿参数的视觉-语言模型（VLM）。其训练分为两个阶段：1. Poutine-Base在83小时的CoVLA常规驾驶数据和11小时的Waymo长尾驾驶数据上进行自监督视觉-语言-轨迹（VLT）下一词元预测预训练，语言标注由一个720亿参数的VLM自动生成。2. Poutine通过使用Waymo验证集中不到500帧偏好标注数据，采用组相对策略优化（GRPO）对Poutine-Base进行微调。

**Result:** VLT预训练和RL微调对于在长尾场景中获得强大的驾驶性能至关重要。Poutine-Base在验证集上的评估者反馈分数（RFS）为8.12，接近Waymo专家地面真值。最终的Poutine模型在官方Waymo测试集上获得7.99的RFS，并在2025年Waymo基于视觉的端到端驾驶挑战赛中以显著优势位列第一。

**Conclusion:** 可扩展的视觉-语言-轨迹（VLT）预训练和轻量级强化学习（RL）微调有望实现鲁棒且可泛化的自动驾驶。

> **ai_Abstract:** 本文介绍了Poutine，一个30亿参数的视觉-语言模型，专为长尾场景中的端到端自动驾驶设计。模型采用两阶段训练：首先进行大规模VLT自监督预训练以建立基础驾驶能力，然后通过轻量级强化学习（GRPO）进行微调。实验结果表明，VLT预训练和RL微调对于在长尾场景中实现强大性能至关重要，Poutine在Waymo测试集上取得了领先的RFS，并在2025年Waymo挑战赛中获得第一名，展示了该方法在实现鲁棒泛化自动驾驶方面的巨大潜力。

> **摘要翻译:** 我们提出了Poutine，一个30亿参数的视觉-语言模型（VLM），专为长尾驾驶场景中的端到端自动驾驶而定制。Poutine分两个阶段进行训练。为了获得强大的基础驾驶能力，我们以自监督的视觉-语言-轨迹（VLT）下一词元预测方式，在83小时的CoVLA常规驾驶数据和11小时的Waymo长尾驾驶数据上训练了Poutine-Base。伴随的语言标注是通过一个720亿参数的VLM自动生成的。Poutine是通过使用来自Waymo验证集的不到500帧偏好标注数据，采用组相对策略优化（GRPO）对Poutine-Base进行微调而获得的。我们发现VLT预训练和RL微调对于在长尾场景中获得强大的驾驶性能都至关重要。Poutine-Base在验证集上获得了8.12的评估者反馈分数（RFS），几乎与Waymo专家地面真值的RFS相匹配。最终的Poutine模型在官方Waymo测试集上获得了7.99的RFS，在2025年Waymo基于视觉的端到端驾驶挑战赛中以显著优势位列第一。这些结果突显了可扩展的VLT预训练和轻量级RL微调在实现鲁棒和可泛化自动驾驶方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [35] [Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation](https://arxiv.org/abs/2506.11261)
> *Gondola：面向通用机器人操作的视觉语言基础规划*

*Shizhe Chen, Ricardo Garcia, Paul Pacaud, Cordelia Schmid* | **Main category: cs.RO**

**Keywords:** 机器人操作, 视觉语言规划, 大型语言模型, 泛化能力, 接地规划

**Comment:** 

> **TL;DR:** Gondola是一个基于LLM的新型视觉语言规划模型，通过处理多视角图像和历史规划，显著提升了机器人操作在复杂视觉环境中的泛化能力，并在多个泛化级别上超越了现有SOTA方法。

**AI_Comments:** 本文的创新点在于提出了Gondola模型，它通过整合多视角视觉信息和历史规划，解决了现有LLM在机器人操作中视觉接地能力不足的问题。其引入的包含分割掩码的规划输出是实现精确操作的关键。此外，为训练模型构建的专用数据集也为该领域的研究提供了宝贵资源。该工作在提高机器人操作泛化能力方面迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 机器人操作在泛化到未见物体、环境和多样语言指令指定的任务时面临挑战。现有基于LLM的方法在视觉环境中缺乏基础规划，且受限于单视角输入和精确物体接地能力不足。

**Method:** 本文提出了Gondola，一个新颖的基于LLM的视觉语言基础规划模型，用于通用机器人操作。Gondola接收多视角图像和历史规划，生成包含文本和目标物体与位置分割掩码的下一步动作规划。为支持训练，使用RLBench模拟器构建了机器人基础规划、多视角指代表达和伪长周期任务三种数据集。

**Result:** Gondola在GemBench数据集的所有四个泛化级别（包括新放置、刚体、铰接物体和长周期任务）上，均优于现有最先进的基于LLM的方法。

**Conclusion:** Gondola通过其多视角输入和精确的视觉接地规划能力，显著提升了机器人操作在各种复杂场景下的泛化能力。

> **ai_Abstract:** 本文提出了Gondola，一个基于大型语言模型的新型视觉语言规划模型，旨在解决机器人操作在复杂视觉环境中泛化能力不足的问题。Gondola通过处理多视角图像和历史规划，生成包含文本和分割掩码的动作规划，从而实现精确的物体接地。为训练模型，作者构建了三种专用数据集。实验结果表明，Gondola在多个泛化级别上显著优于现有最先进的基于LLM的方法，展现了其在通用机器人操作中的优越性。

> **摘要翻译:** 机器人操作在泛化到未见物体、环境以及由不同语言指令指定的任务时面临重大挑战。为了提高泛化能力，最近的研究已将大型语言模型（LLMs）用于规划和动作执行。尽管前景光明，但这些方法往往在视觉环境中生成基础规划时表现不足。尽管已努力对LLMs进行视觉指令调优以进行机器人操作，但现有方法通常受限于单视角图像输入，并且难以实现精确的物体接地。在这项工作中，我们引入了Gondola，一个新颖的、基于LLM的视觉语言基础规划模型，用于通用机器人操作。Gondola接收多视角图像和历史规划，以生成包含交错文本和目标物体与位置分割掩码的下一步动作规划。为了支持Gondola的训练，我们使用RLBench模拟器构建了三种类型的数据集，即机器人基础规划、多视角指代表达和伪长周期任务数据集。Gondola在GemBench数据集的所有四个泛化级别（包括新放置、刚体、铰接物体和长周期任务）上，均优于最先进的基于LLM的方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [63] [Demonstration Sidetracks: Categorizing Systematic Non-Optimality in Human Demonstrations](https://arxiv.org/abs/2506.11262)
> *演示岔路：对人类演示中系统性非最优性的分类*

*Shijie Fang, Hang Yu, Qidi Fang, Reuben M. Aronson, Elaine S. Short* | **Main category: cs.RO**

**Keywords:** 演示中学习, 演示岔路, 次优行为, 机器人学习, 人机交互

**Comment:** 

> **TL;DR:** 在机器人从演示中学习（LfD）中，人类演示中的不完美行为并非随机噪声，而是系统性的“演示岔路”。本研究通过实验识别并分类了这些岔路类型，强调了为改进LfD算法而建立更好次优演示模型的必要性。

**AI_Comments:** 这篇论文的创新点在于将LfD中通常被视为随机噪声的人类演示不完美性，系统地归类为“演示岔路”。通过实证研究和类型划分，它为理解人类行为提供了新视角，并为改进LfD算法提供了具体方向，有助于缩小实验室与实际应用之间的差距。其公开数据集也促进了后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的从演示中学习（LfD）方法在处理人类演示中的不完美性时，通常将其视为随机噪声，但这些不完美行为实际上是系统性的，这限制了LfD算法的性能和实际部署。

**Method:** 研究非专家演示中的非最优行为，并将其归类为“演示岔路”。通过一项包含40名参与者的公共空间研究，让他们执行一个长周期机器人任务，并在模拟中重现设置并标注所有演示。

**Result:** 识别出四种岔路类型（探索、错误、对齐、暂停）和一种控制模式（一维控制）。岔路在参与者中频繁出现，其时空分布与任务上下文相关。用户控制模式取决于控制界面。

**Conclusion:** 这些发现表明，需要更好的次优演示模型来改进LfD算法，并弥合实验室训练与实际部署之间的差距。

> **ai_Abstract:** 本文研究了从演示中学习（LfD）中人类演示的非最优行为，发现它们并非随机噪声，而是系统性的“演示岔路”。通过一项40名参与者的真实和模拟研究，作者识别出探索、错误、对齐、暂停四种主要岔路类型，并发现其出现频率高且与任务上下文相关。研究还指出控制模式受界面影响。这些发现强调了开发更精确的次优演示模型以提升LfD算法和实际应用的重要性。

> **摘要翻译:** 从演示中学习（LfD）是机器人获取新技能的一种流行方法，但大多数LfD方法都受到人类演示中不完美性的影响。以往的工作通常将这些次优行为视为随机噪声。在本文中，我们研究了非专家演示中的非最优行为，并表明它们是系统性的，形成了我们称之为“演示岔路”的现象。通过一项包含40名参与者的公共空间研究，让他们执行一个长周期机器人任务，我们还在模拟中重现了该设置并标注了所有演示。我们识别出四种岔路类型（探索、错误、对齐、暂停）和一种控制模式（一维控制）。岔路在参与者中频繁出现，其时空分布与任务上下文相关。我们还发现用户的控制模式取决于控制界面。这些见解表明，需要更好的次优演示模型来改进LfD算法，并弥合实验室训练与实际部署之间的差距。所有演示、基础设施和标注都可在https://github.com/AABL-Lab/Human-Demonstration-Sidetracks 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [91] [Sensor Model Identification via Simultaneous Model Selection and State Variable Determination](https://arxiv.org/abs/2506.11263)
> *通过同步模型选择和状态变量确定进行传感器模型识别*

*Christian Brommer, Alessandro Fornasier, Jan Steinbrener, Stephan Weiss* | **Main category: cs.RO**

**Keywords:** 传感器模型识别, 定位, 机器人, 灰盒识别, 传感器集成

**Comment:** 

> **TL;DR:** 该论文提出了一种自动识别机器人定位中传感器模型、校准和参考系的方法，以简化传感器集成。

**AI_Comments:** 这项工作的创新之处在于其“无人值守的灰盒识别”方法和用于鲁棒模型选择的“健康度量”。其重要性在于它大大简化了复杂机器人系统中传感器的集成过程，并使定位开发更易于访问。这有望显著减少配置新传感器所需的手动工作量和潜在错误。

<details>
  <summary>Details</summary>

**Motivation:** 简化机器人领域定位算法中新传感器元素的集成，特别针对经验不足的用户，并通过自动化传感器模型、校准和参考系的识别来避免定位开发中的常见陷阱。同时，它对模块化多智能体场景也至关重要。

**Method:** 该方法用于对机器人定位中常用的传感器模型进行无人值守的灰盒识别。它通过以下步骤实现：1. 在预定义传感器模型目录中，根据未知测量数据确定最可能的传感器模型。2. 引入健康度量，以验证选择结果，检测假阳性，并促进可靠的决策。3. 生成已识别校准状态的初始猜测。4. 评估传感器世界参考系的必要性。5. 使用识别出的传感器模型及其参数信息来参数化和初始化状态估计应用。

**Result:** 该方法确保了新传感器元素更准确、更鲁棒的集成。它有助于识别测量源和类型、传感器校准或传感器参考系。它简化了传感器与下游应用的集成，并避免了常见的使用和开发陷阱。

**Conclusion:** 这项工作通过自动识别传感器模型、校准和参考系，为传感器模态集成到定位应用中提供了一种简化且鲁棒的方法，对经验不足的用户和复杂的模块化机器人系统都带来了益处。

> **ai_Abstract:** 本文介绍了一种用于机器人定位中传感器模型的无人值守灰盒识别方法。该方法自动从预定义目录中确定最可能的传感器模型，生成初始校准状态，并评估参考系的必要性。引入的健康度量确保了可靠的模型选择。识别出的模型和参数随后用于初始化状态估计，从而实现更准确、更鲁棒的传感器集成。该方法简化了用户和模块化机器人平台的传感器设置，解决了定位开发中的常见挑战。

> **摘要翻译:** 我们提出了一种用于机器人领域定位算法中常用传感器模型的无人值守灰盒识别方法。目标是根据预定义的传感器模型的可扩展目录，确定未知测量数据时间序列最可能的传感器模型。传感器模型定义可能需要刚体校准的状态和专用参考系，以根据机器人的定位状态复制测量。引入了一个健康度量，用于验证选择过程的结果，以检测假阳性并促进可靠的决策。在第二阶段，生成已识别校准状态的初始猜测，并评估传感器世界参考系的必要性。然后，将识别出的传感器模型及其参数信息用于参数化和初始化状态估计应用，从而确保新传感器元素更准确和鲁棒的集成。该方法有助于希望识别测量源和类型、传感器校准或传感器参考系的经验不足用户。它在模块化多智能体场景和运行时通过传感器模态增强的模块化机器人平台领域也将非常重要。总的来说，这项工作旨在为下游应用提供简化的传感器模态集成，并规避定位方法使用和开发中的常见陷阱。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [118] [Robust Optimal Task Planning to Maximize Battery Life](https://arxiv.org/abs/2506.11264)
> *鲁棒最优任务规划以最大化电池寿命*

*Jiachen Li, Chu Jian, Feiyang Zhao, Shihao Li, Wei Li, Dongmei Chen* | **Main category: cs.RO**

**Keywords:** 鲁棒优化, 任务规划, 电池寿命, 自主移动机器人, 双线性规划

**Comment:** 

> **TL;DR:** 本文提出了一种针对自主移动机器人（AMR）的控制优化平台，通过线性化双线性优化问题和开发新的规划算法，实现了在确保任务完成的同时最大化电池寿命。

**AI_Comments:** 该论文提出了一种新颖的方法来解决自主移动机器人在任务规划中电池寿命最大化的问题，通过结合McCormick包络技术和鲁棒规划算法，有效应对了双线性特性和参数不确定性，具有较高的创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为自主移动机器人（AMR）提供一个控制导向的优化平台，以延长电池寿命并确保任务完成。现有快速AMR任务规划在维持最低电池电量以最大化电池寿命时，会产生一个双线性优化问题。

**Method:** 本文提出了一个控制导向的优化平台。针对双线性优化问题，采用了McCormick包络技术进行线性化。此外，还开发了一种具有松弛约束的新型规划算法，以高效且鲁棒地处理参数不确定性。

**Result:** 仿真结果表明，所提出的方法在减少电池退化同时满足任务完成要求方面具有实用性。

**Conclusion:** 本文提出的方法能够有效减少电池退化，同时确保自主移动机器人的任务完成，从而最大化电池寿命。

> **ai_Abstract:** 本文提出了一种针对自主移动机器人（AMR）的优化平台，旨在通过解决一个双线性优化问题来最大化电池寿命并确保任务完成。研究通过引入McCormick包络技术对双线性项进行线性化，并开发了一种新的、具有松弛约束的规划算法，以鲁棒高效地处理参数不确定性。仿真结果验证了该方法在减少电池损耗和满足任务需求方面的有效性。

> **摘要翻译:** 本文提出了一种针对自主移动机器人（AMR）的控制导向优化平台，重点在于延长电池寿命同时确保任务完成。快速AMR任务规划在维持最低电池电量从而最大化电池寿命的要求，导致了一个双线性优化问题。本文提出了McCormick包络技术来线性化双线性项。同时，还开发了一种具有松弛约束的新型规划算法，以高效且鲁棒地处理参数不确定性。仿真结果表明，所提出的方法在减少电池退化同时满足任务完成要求方面具有实用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [143] [Measuring and Minimizing Disturbance of Marine Animals to Underwater Vehicles](https://arxiv.org/abs/2506.11335)
> *测量和最小化水下航行器对海洋动物的干扰*

*Levi Cai, Youenn Jézéquel, T. Aran Mooney, Yogesh Girdhar* | **Main category: cs.RO**

**Keywords:** 水下航行器, 海洋动物, 行为估计, 干扰, 偏差

**Comment:** Accepted to ISER 2025

> **TL;DR:** 本文提出了一个理论和实践框架，用于测量和减轻水下航行器对海洋动物的干扰，以实现无偏的行为估计。

**AI_Comments:** 本文的创新之处在于提出了一个测量和减轻水下航行器对海洋动物干扰的框架，旨在实现无偏的动物行为估计，这对于海洋生物学研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决水下航行器可能干扰海洋动物行为，从而导致对动物行为估计产生偏差的问题。

**Method:** 提出了一个理论和实践框架，旨在实现从水下航行器观测中对动物行为进行无偏估计。同时，提供了在珊瑚礁环境中进行的初步现场结果。

**Result:** 提供了在珊瑚礁环境中进行的初步现场结果，但具体结果未在摘要中提及。

**Conclusion:** 本文提供了一个理论和实践框架，旨在实现从水下航行器观测中对动物行为的无偏估计。

> **ai_Abstract:** 这项研究旨在解决水下航行器可能对海洋动物行为产生干扰，从而导致行为估计偏差的问题。论文提出了一个理论和实践框架，以实现从水下航行器观测中对动物行为的无偏估计，并提供了在珊瑚礁环境中的初步现场结果来支持这一目标。

> **摘要翻译:** 鱼类是否会对水下航行器的存在做出反应，从而可能使我们对它们的估计产生偏差？如果是这样，是否有策略来测量和减轻这种反应？这项工作为从水下航行器观测中对动物行为进行无偏估计提供了一个理论和实践框架。我们还提供了在珊瑚礁环境中的初步现场结果，以解决这些问题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [167] [Robotic System for Chemical Experiment Automation with Dual Demonstration of End-effector and Jig Operations](https://arxiv.org/abs/2506.11384)
> *用于化学实验自动化的机器人系统，具有末端执行器和夹具操作的双重演示*

*Hikaru Sasaki, Naoto Komeno, Takumi Hachimine, Kei Takahashi, Yu-ya Ohnishi, Tetsunori Sugawara, Araki Wakiuchi, Miho Hatanaka, Tomoyuki Miyao, Hiroharu Ajiro, Mikiya Fujii, Takamitsu Matsubara* | **Main category: cs.RO**

**Keywords:** 化学实验自动化, 机器人系统, 双重演示, 夹具操作, 液体处理

**Comment:** 

> **TL;DR:** 该研究提出了一种通过化学家双重演示机器人运动和夹具操作来实现化学实验自动化的概念，并开发了一个系统，通过聚合物合成实验验证了其高重复性和鲁棒性，从而简化了机器人编程并提高了实验自动化效率。

**AI_Comments:** 该论文的创新点在于提出了双重演示（机器人运动和夹具操作）的概念，极大地简化了化学家进行机器人编程的复杂性。它通过实际系统开发和聚合物合成实验的验证，证明了其在提高实验自动化效率和灵活性方面的潜力。这一方法有望降低机器人自动化在化学实验室中的应用门槛，使其能适应更广泛的实验条件。

<details>
  <summary>Details</summary>

**Motivation:** 设计一个程序来同步机器人运动与实验夹具以进行实验具有挑战性，尤其是在需要连续执行数百个实验时。

**Method:** 提出了一种利用化学家在机器人可控实验环境中对机器人运动和夹具操作进行双重演示的概念。开发了一个化学实验自动化系统，包括辅助机器人的夹具、运动演示界面、夹具控制界面和移动机械手。通过聚合物合成实验（特别是移液和稀释等液体处理任务）验证了该概念。

**Result:** 实验结果表明，演示的运动具有高重复性，并且任务成功率高。

**Conclusion:** 该综合概念简化了化学家的机器人编程过程，提供了一种灵活高效的解决方案，以适应各种实验条件，对化学实验自动化领域做出了重大贡献。

> **ai_Abstract:** 本研究提出并验证了一种用于化学实验自动化的新概念，通过允许化学家在机器人可控的环境中双重演示机器人运动和实验夹具操作来简化编程。为此，开发了一个包含夹具、演示界面和移动机械手的自动化系统。通过聚合物合成实验（特别是液体处理任务）的验证表明，该系统实现了高重复性和鲁棒的任务成功率。该方法显著简化了机器人编程，并为化学实验自动化提供了灵活高效的解决方案。

> **摘要翻译:** 尽管机器人自动化已展现出卓越的性能，例如连续数天执行数百项实验，但设计一个程序来同步机器人运动与实验夹具以进行实验仍然具有挑战性。我们提出了一种概念，通过化学家在机器人可控的实验环境中对机器人运动和夹具操作进行双重演示，从而实现实验自动化。为了验证这一概念，我们开发了一个化学实验自动化系统，该系统由辅助机器人进行实验的夹具、运动演示界面、夹具控制界面和移动机械手组成。我们通过聚合物合成实验验证了该概念，重点关注关键的液体处理任务，例如移液和稀释。实验结果表明，演示的运动具有高重复性，并且任务成功率高。这一综合概念不仅简化了化学家的机器人编程过程，还提供了一种灵活高效的解决方案，以适应各种实验条件，对化学实验自动化领域做出了重大贡献。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [184] [Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment](https://arxiv.org/abs/2506.11387)
> *自动化制造环境中多机器人视觉伺服系统的控制架构与设计*

*Rongfei Li* | **Main category: cs.RO**

**Keywords:** 多机器人系统, 视觉伺服, 控制架构, 摄像头位置优化, 自动化制造

**Comment:** 272 pages, 171 figures, PhD dissertation, University of California,
  Davis, 2025. To be published in ProQuest ETD

> **TL;DR:** 本文提出了一种用于自动化制造环境中多机器人视觉伺服系统的控制架构，并通过优化摄像头位置来降低不确定性。

**AI_Comments:** 本文的创新点在于不仅提出了多机器人控制系统来处理制造中的不确定性，还特别关注了视觉伺服系统中摄像头位置优化这一常被忽视但至关重要的方面。通过动态优化摄像头位置以最小化图像噪声，该方法有望显著提高视觉伺服系统的精度和鲁棒性，为高精度自动化制造提供了更经济高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 21世纪机器人技术在制造业中大幅增长，但人类在微尺度制造中仍优于机器，因为人类的感官线索能补偿制造环境中的高度不确定性。现有先进传感器和微处理器虽能补偿机器人定位误差，但设计良好的控制算法仍是更经济有效的替代方案。此外，现有视觉伺服研究多关注控制和观察架构，但很少讨论摄像头位置的重要性，因为摄像头位置会影响图像噪声水平。

**Method:** 本文提出了一种多机器人控制系统，模拟紧固和松开应用的定位过程，以减少过程中可能出现的各种不确定性。此外，还提出了一种新颖的摄像头移动策略算法，使其探索摄像头工作空间并寻找图像噪声水平最小化的最佳位置。

**Result:** 研究表明，所提出的多机器人控制系统可以大大减少制造过程中可能出现的各种不确定性。

**Conclusion:** 通过设计多机器人控制系统和优化摄像头位置的算法，可以有效降低自动化制造环境中的不确定性，提高系统性能。

> **ai_Abstract:** 本文针对自动化制造环境中机器人系统面临的不确定性问题，提出了一种多机器人视觉伺服系统的控制架构和设计。该系统旨在通过模拟紧固和松开应用来减少各种不确定性。此外，鉴于摄像头位置对图像质量和噪声水平的关键影响，论文还提出了一种新颖的摄像头移动策略算法，以探索工作空间并找到图像噪声最小化的最佳观察位置，从而提高视觉伺服系统的鲁棒性和精度。

> **摘要翻译:** 21世纪，机器人技术在制造业中的应用大幅增长。然而，通过利用其感官线索，人类在微尺度制造中仍然优于机器，尤其是在需要高精度机器人操纵器的领域。这些感官线索自然地补偿了制造环境中存在的高度不确定性。执行制造任务中的不确定性可能来自测量噪声、模型不准确、关节柔顺性（例如弹性）等。尽管现代机器人中使用的先进计量传感器和高精度微处理器已经补偿了机器人定位中的许多结构和动态误差，但精心设计的控制算法仍然是减少自动化制造中不确定性的可比且更便宜的替代方案。我们的工作表明，模拟紧固和松开应用的定位过程的多机器人控制系统可以在很大程度上减少此过程中可能出现的各种不确定性。此外，大多数视觉伺服研究论文主要集中于在各种场景中开发控制和观察架构，但很少讨论摄像头在配置中位置的重要性。在制造环境中，由于环境条件的综合影响导致在不同位置拍摄的单张图像具有不同的噪声水平，因此摄像头估计的质量可能因观察位置而异。因此，在本文中，我们还提出了一种新颖的摄像头移动策略算法，使其探索摄像头工作空间并寻找图像噪声水平最小化的最佳位置。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [204] [Multi-Loco: Unifying Multi-Embodiment Legged Locomotion via Reinforcement Learning Augmented Diffusion](https://arxiv.org/abs/2506.11470)
> *Multi-Loco：通过强化学习增强扩散模型统一多体态腿式运动*

*Shunpeng Yang, Zhen Fu, Zhefeng Cao, Guo Junde, Patrick Wensing, Wei Zhang, Hua Chen* | **Main category: cs.RO**

**Keywords:** 腿式运动, 强化学习, 扩散模型, 多体态, 泛化

**Comment:** 19 pages

> **TL;DR:** Multi-Loco提出了一种结合扩散模型和残差策略的统一框架，通过强化学习优化，实现了多体态腿式机器人的通用运动策略，在模拟和真实世界中表现出更好的泛化性和鲁棒性。

**AI_Comments:** 该论文的创新点在于将生成扩散模型与强化学习残差策略相结合，以实现多体态腿式机器人的通用运动。这种组合方法有效地解决了跨形态泛化这一关键挑战，并通过利用跨体态数据提高了策略的鲁棒性和性能。其核心贡献在于证明了扩散模型作为策略骨干的潜力，并结合RL进行微调，为机器人运动控制提供了一个新颖且高效的范式。

<details>
  <summary>Details</summary>

**Motivation:** 由于观察/动作维度和系统动力学的差异，在形态各异的多种腿式机器人之间推广运动策略是一个关键挑战。

**Method:** 本研究提出了Multi-Loco，一个新颖的统一框架，它将形态无关的生成扩散模型与通过强化学习（RL）优化的轻量级残差策略相结合。扩散模型从多样化的跨体态数据集中捕获形态不变的运动模式，而残差策略则对扩散模型生成的动作进行细化。

**Result:** 与标准的PPO强化学习框架相比，Multi-Loco方法（用扩散模型和残差项取代高斯策略）实现了10.35%的平均回报提升，在轮式双足运动任务中增益高达13.57%。

**Conclusion:** 这些结果强调了跨体态数据和复合生成架构在学习鲁棒、通用运动技能方面的优势。

> **ai_Abstract:** Multi-Loco提出了一种统一的多体态腿式机器人运动框架，旨在解决跨不同形态机器人推广运动策略的挑战。该框架结合了形态无关的生成扩散模型和通过强化学习优化的轻量级残差策略。扩散模型学习形态不变的运动模式，而残差策略则细化动作以提高任务性能和鲁棒性。实验结果表明，该方法在平均回报上相比标准RL框架有显著提升，证明了跨体态数据和复合生成架构在学习通用、鲁棒运动技能方面的有效性。

> **摘要翻译:** Multi-Loco：通过强化学习增强扩散模型统一多体态腿式运动

由于观察/动作维度和系统动力学的差异，在形态各异的多种腿式机器人之间推广运动策略是一个关键挑战。在这项工作中，我们提出了Multi-Loco，一个新颖的统一框架，它将形态无关的生成扩散模型与通过强化学习（RL）优化的轻量级残差策略相结合。扩散模型从多样化的跨体态数据集中捕获形态不变的运动模式，从而提高了泛化性和鲁棒性。残差策略在所有体态之间共享，并细化扩散模型生成的动作，增强了任务感知性能和实际部署的鲁棒性。我们在模拟和真实世界实验中，使用丰富的四足机器人库评估了我们的方法。与标准的PPO强化学习框架相比，我们的方法——用扩散模型和残差项取代高斯策略——实现了10.35%的平均回报提升，在轮式双足运动任务中增益高达13.57%。这些结果强调了跨体态数据和复合生成架构在学习鲁棒、通用运动技能方面的优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [222] [Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis](https://arxiv.org/abs/2506.11526)
> *自动驾驶中的基础模型：场景生成与场景分析综述*

*Yuan Gao, Mattia Piccinini, Yuchen Zhang, Dingrui Wang, Korbinian Moller, Roberto Brusnicki, Baha Zarrouki, Alessio Gambi, Jan Frederik Totz, Kai Storms, Steven Peters, Andrea Stocco, Bassam Alrifaee, Marco Pavone, Johannes Betz* | **Main category: cs.RO**

**Keywords:** 基础模型, 自动驾驶, 场景生成, 场景分析, 综述

**Comment:** 

> **TL;DR:** 本文综述了基础模型在自动驾驶场景生成与场景分析中的应用，涵盖了统一分类、方法、数据集、平台、基准和评估指标，并提出了开放挑战和未来方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地整理了新兴的基础模型在自动驾驶这一关键领域中的应用。它不仅提供了一个清晰的分类框架，还全面回顾了当前的研究进展、可用资源和评估标准，为研究人员指明了未来研究的重点和方向，对于推动自动驾驶场景生成与分析领域的发展具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统在复杂环境中安全导航需要处理多样且罕见的驾驶场景。传统场景生成方法多样性有限且难以生成关键安全场景。基础模型的出现，作为新一代预训练通用AI模型，能够处理异构输入，为解决这些问题提供了新途径。

**Method:** 本文对截至2025年5月基础模型在自动驾驶场景生成和分析中的应用进行了综述。该综述提出了一个统一的分类法，包括大型语言模型、视觉-语言模型、多模态大型语言模型、扩散模型和世界模型。此外，还回顾了相关的方法论、开源数据集、仿真平台和基准挑战，并检查了专门针对场景生成和分析的评估指标。

**Result:** 本综述提出了一个统一的基础模型分类法，并系统地回顾了基础模型在自动驾驶场景生成与分析中的应用，包括相关方法、数据集、平台、基准挑战和评估指标。

**Conclusion:** 本综述最后强调了开放的挑战和研究问题，并概述了有前景的未来研究方向。

> **ai_Abstract:** 本文综述了基础模型在自动驾驶场景生成和分析中的应用。鉴于传统方法在生成多样化和安全关键场景方面的局限性，基础模型提供了一种新的范式，能够处理多模态输入并合成复杂场景。该综述提出了一个统一的分类法，涵盖了多种基础模型类型，并详细审视了相关的方法、数据集、仿真平台、基准挑战和评估指标。文章最后指出了当前面临的开放挑战和未来的研究方向。

> **摘要翻译:** 对于自动驾驶汽车而言，在复杂环境中安全导航取决于处理各种多样且罕见的驾驶场景。基于模拟和场景的测试已成为自动驾驶系统开发和验证的关键方法。传统的场景生成依赖于基于规则的系统、知识驱动模型和数据驱动合成，但通常产生的多样性有限，并且难以生成不切实际的安全性关键案例。随着基础模型的出现，它们代表了新一代预训练的通用AI模型，开发者可以处理异构输入（例如，自然语言、传感器数据、高清地图和控制动作），从而实现复杂驾驶场景的合成和解释。在本文中，我们对基础模型在自动驾驶场景生成和场景分析中的应用进行了综述（截至2025年5月）。我们的综述提出了一个统一的分类法，包括大型语言模型、视觉-语言模型、多模态大型语言模型、扩散模型和世界模型，用于自动驾驶场景的生成和分析。此外，我们回顾了方法论、开源数据集、仿真平台和基准挑战，并检查了专门针对场景生成和分析的评估指标。最后，本综述通过强调开放挑战和研究问题，并概述有前景的未来研究方向来结束。所有审查过的论文都列在一个持续维护的存储库中，其中包含补充材料，可在 https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [236] [Construction of a Multiple-DOF Under-actuated Gripper with Force-Sensing via Deep Learning](https://arxiv.org/abs/2506.11570)
> *基于深度学习的力传感多自由度欠驱动夹持器构建*

*Jihao Li, Keqi Zhu, Guodong Lu, I-Ming Chen, Huixu Dong* | **Main category: cs.RO**

**Keywords:** 欠驱动夹持器, 力传感, 深度学习, LSTM, 五连杆机构

**Comment:** 

> **TL;DR:** 本文提出了一种新型双指欠驱动夹持器，通过LSTM模型在无力传感器的情况下实现力反馈控制，并验证了其抓取性能、多功能性和鲁棒性。

**AI_Comments:** 本文提出了一种无需力传感器，通过深度学习实现力反馈控制的欠驱动夹持器，具有显著的创新性。其核心优势在于降低了成本和复杂性，同时通过巧妙的机械设计和先进的AI算法，实现了多功能和鲁棒的抓取能力。五连杆机构的设计使其能够自动适应不同抓取模式，结合LSTM进行力传感，是该研究的亮点。这为未来低成本、高性能机器人抓手的设计提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 传统夹持器可能需要力传感器实现力反馈控制，增加了成本和复杂性。本文旨在设计一种低成本、高性能的欠驱动夹持器，利用深度学习技术实现力传感和力反馈控制，以提高其多功能性和鲁棒性。

**Method:** 1. 设计了一种由双四连杆堆叠而成的五连杆机构作为手指，实现平行抓取和包络抓取模式的自动切换，从而构建了一个低成本的单执行器、双三指节欠驱动夹持器。2. 建立了夹持器的运动学和功率传输理论模型，以准确获取指尖位置和接触力。3. 提出了一种LSTM模型，通过利用接触传感并结合统计方法处理电流不确定性，来确定抓取模式并合成力反馈控制策略，从而实现力控制。

**Result:** 1. 设计的欠驱动夹持器能够自动实现平行抓取和包络抓取模式的转换。2. 夹持器能够准确获取指尖位置和接触力。3. 通过耦合和解耦五连杆机构，夹持器展现出预期的抓取载荷/力/稳定性以及抓取大尺寸物体的能力。4. 实验验证了夹持器在载荷、抓取力、力传感、抓取稳定性和可抓取物体尺寸范围等方面的定量指标。5. 实验证明了所提出夹持器的高多功能性和鲁棒性。

**Conclusion:** 本文成功构建了一种新型欠驱动夹持器，该夹持器通过深度学习（LSTM模型）在无力传感器的情况下实现了力反馈控制。其创新的五连杆机构设计和基于深度学习的力传感方法显著提高了夹持器的抓取性能、多功能性和鲁棒性，为低成本、高性能的欠驱动夹持器设计提供了新的途径。

> **ai_Abstract:** 本文介绍了一种新型双指欠驱动夹持器，该夹持器通过创新的五连杆机构设计实现平行和包络抓取模式的自动切换，并利用LSTM深度学习模型在无力传感器的情况下实现力反馈控制。研究详细阐述了夹持器的机构设计、运动学和功率传输模型，以及基于LSTM的力传感方法。通过实验验证了其在载荷、抓取力、力传感、抓取稳定性及物体尺寸范围等方面的性能，展示了该夹持器的高多功能性和鲁棒性。

> **摘要翻译:** 我们提出了一种新型的欠驱动夹持器，具有两个3关节手指，通过深度学习技术——长短期记忆（LSTM）模型，在没有任何力传感器的情况下实现了力反馈控制。首先，设计了一种由双四连杆堆叠而成的五连杆机构作为手指，以自动实现平行抓取和包络抓取模式之间的转换。这使得能够创建一个由单个执行器和两个3指节手指组成的低成本欠驱动夹持器。其次，我们基于所提出的夹持器设计了运动学和功率传输的理论模型，准确获取了指尖位置和接触力。通过五连杆机构的耦合和解耦，所提出的夹持器提供了预期的抓取载荷/力/稳定性以及抓取大尺寸物体范围的能力。第三，为了实现力控制，提出了一种LSTM模型，通过在概述电流不确定性后利用接触传感来确定抓取模式，从而合成力反馈控制策略。最后，进行了一系列实验来测量定量指标，例如载荷、抓取力、力传感、抓取稳定性和可抓取物体的尺寸范围。此外，实验验证了所提出的夹持器的抓取性能，以保证其高多功能性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [252] [Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control](https://arxiv.org/abs/2506.11650)
> *机器人上下文协议 (RCP)：一种运行时无关的智能体感知机器人控制接口*

*Lambert Lee, Joshua Lau* | **Main category: cs.RO**

**Keywords:** 机器人上下文协议, 通信协议, 机器人控制, 多智能体系统, 运行时无关

**Comment:** 

> **TL;DR:** RCP是一种轻量级、中间件无关的通信协议，旨在简化机器人系统复杂性，实现机器人、用户和智能体之间的无缝交互，支持多种部署环境。

**AI_Comments:** RCP的创新之处在于其运行时无关和中间件无关的设计，通过统一的、语义化的接口简化了机器人系统集成。它通过将客户端操作与后端解耦，并支持多种部署环境，显著提高了机器人系统的灵活性和可伸缩性。其内置的安全和健壮性特性也增加了其实用性，使其能够应用于制造、物流和医疗保健等多行业复杂场景。

<details>
  <summary>Details</summary>

**Motivation:** 简化机器人系统的复杂性，实现机器人、用户和自主智能体之间的无缝交互。

**Method:** RCP基于HTTP和WebSocket传输层，定义了模式驱动的消息格式，具有读、写、执行和订阅等结构化操作。它集成了运行时自省、异步反馈、多租户命名空间隔离和严格类型验证等功能，以确保鲁棒性、可伸缩性和安全性。文中描述了其架构、消息结构、接口模型和基于适配器的后端集成策略。

**Result:** RCP提供了一个统一且语义有意义的接口，将面向客户端的操作与后端实现解耦，支持包括物理机器人、云端编排器和模拟平台在内的广泛部署环境。它确保了系统的鲁棒性、可伸缩性和安全性，并能在复杂的多智能体生态系统中实现智能、弹性、安全的机器人操作。

**Conclusion:** RCP通过提供统一且语义化的接口，显著简化了机器人系统的复杂性，并促进了在多行业复杂环境中智能、安全、弹性的机器人操作。

> **ai_Abstract:** 机器人上下文协议 (RCP) 是一种轻量级、中间件无关的通信协议，旨在简化机器人系统，实现机器人、用户和智能体间的无缝交互。它提供统一的语义化接口，将前端操作与后端解耦，支持多环境部署。RCP 基于 HTTP/WebSocket，采用模式驱动消息格式，并包含运行时自省、异步反馈、多租户隔离、严格类型验证等特性，以确保鲁棒性、可伸缩性和安全性，从而在复杂的多智能体生态系统中实现智能、弹性、安全的机器人操作。

> **摘要翻译:** 机器人上下文协议 (RCP) 是一种轻量级、与中间件无关的通信协议，旨在简化机器人系统的复杂性，并实现机器人、用户和自主智能体之间的无缝交互。RCP 提供了一个统一且语义有意义的接口，将面向客户端的操作与后端实现解耦，支持广泛的部署环境，包括物理机器人、基于云的编排器和模拟平台。该协议建立在 HTTP 和 WebSocket 传输层之上，定义了一种模式驱动的消息格式，具有读、写、执行和订阅等结构化操作。它集成了运行时自省、异步反馈、多租户命名空间隔离和严格类型验证等功能，以确保鲁棒性、可伸缩性、和安全性。文中描述了 RCP 的架构、消息结构、接口模型和基于适配器的后端集成策略，以及部署实践和在制造、物流和医疗保健等行业的适用性。RCP 在复杂的多智能体生态系统中实现了智能、弹性、安全的机器人操作。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [268] [Dynamic Collaborative Material Distribution System for Intelligent Robots In Smart Manufacturing](https://arxiv.org/abs/2506.11723)
> *智能制造中智能机器人的动态协作物料配送系统*

*Ziren Xiao, Ruxin Xiao, Chang Liu, Xinheng Wang* | **Main category: cs.RO**

**Keywords:** 深度强化学习, 智能制造, 物料配送, 多机器人协作, 实时导航

**Comment:** 

> **TL;DR:** 提出一种轻量级深度强化学习方法，解决了智能制造中多机器人实时动态多源到单目的地导航的物料配送问题，显著缩短了计算时间并支持轻量级部署。

**AI_Comments:** 本文的创新点在于将轻量级深度强化学习应用于智能制造中的多机器人实时物料配送问题，显著提升了计算效率和实时性，并解决了现有方法在处理大规模地图时计算耗时过长的问题。其优势在于模型的高效训练、快速收敛以及在轻量级设备上的部署能力，这对于实际智能制造环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法（如枚举解和仅利用有限历史轨迹信息的方法）在处理智能制造中多机器人实时动态多源到单目的地（DMS-SD）物料配送问题时，计算时间过长，尤其在大地图上，导致无法满足实时操作需求。

**Method:** 提出了一种轻量级深度强化学习（DRL）方法来解决DMS-SD问题。该方法通过设计目标引导奖励函数，可以高效训练并快速收敛到最优解。

**Result:** 训练后的DRL模型能将下一次移动的计算时间缩短到毫秒级，相比枚举解，实验中时间性能提升高达100倍。此外，训练好的DRL模型可以轻松部署到智能制造中的轻量级设备上，例如物联网设备和手机，仅需要有限的计算资源。

**Conclusion:** 论文提出了一种轻量级DRL方法，有效解决了智能制造中多机器人实时物料配送的DMS-SD问题，显著提高了计算效率和实时性，并支持在资源受限设备上的部署，克服了现有方法的计算耗时问题。

> **ai_Abstract:** 本文针对智能制造中多智能机器人实时动态多源到单目的地（DMS-SD）物料配送问题，提出了一种轻量级深度强化学习（DRL）方法。该方法通过设计目标引导奖励函数，实现了高效训练和快速收敛。实验结果表明，与传统枚举解相比，所提出的DRL模型能将计算时间缩短高达100倍，达到毫秒级，极大地提升了实时性。同时，该模型易于部署在资源受限的轻量级设备上，有效克服了现有方法计算耗时的问题。

> **摘要翻译:** 多机器人协作与交互已成为智能制造不可或缺的方面。有效的规划和管理在实现节能和最小化总成本方面发挥着至关重要的作用。本文解决了实时动态多源到单目的地（DMS-SD）导航问题，特别是智能制造中多智能机器人物料配送的案例。枚举解决方案，例如在\cite{xiao2022efficient}中，通过生成尽可能多的最优或接近最优的解决方案来解决问题，但没有从先前的经验中学习模式，而\cite{xiao2023collaborative}中的方法只使用了早期轨迹的有限信息。因此，这些方法在大型地图上计算结果可能需要相当长的时间，使得实时操作不切实际。为了克服这一挑战，我们提出了一种轻量级深度强化学习（DRL）方法来解决DMS-SD问题。所提出的DRL方法可以高效训练，并使用设计的目标引导奖励函数快速收敛到最优解。训练有素的DRL模型将下一次移动的计算时间显著缩短到毫秒级，在我们的实验中，与枚举解决方案相比，时间性能提高了100倍。此外，训练好的DRL模型可以轻松部署到智能制造中的轻量级设备上，例如物联网设备和手机，仅需要有限的计算资源。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [281] [CIRO7.2: A Material Network with Circularity of -7.2 and Reinforcement-Learning-Controlled Robotic Disassembler](https://arxiv.org/abs/2506.11748)
> *CIRO7.2：一个循环度为-7.2的材料网络与强化学习控制的机器人拆卸器*

*Federico Zocco, Monica Malvezzi* | **Main category: cs.RO**

**Keywords:** 循环经济, 机器人拆卸器, 强化学习, 材料网络, 循环度

**Comment:** To be submitted

> **TL;DR:** 本文提出了一个基于热力学材料网络的循环经济模型，其中包含一个由强化学习控制的机器人拆卸器，旨在解决线性经济下的资源枯竭和废物管理问题，并评估了其循环度表现。

**AI_Comments:** 这篇论文通过引入热力学材料网络和强化学习控制的机器人拆卸器，为实现循环经济提供了一个新颖的框架。其创新点在于将循环度量化并与RL控制相结合，探索了复杂的拆卸过程对资源循环的影响。虽然文章提出了循环度为负值（如-7.2），这可能需要进一步解释其含义和实际意义，但整体上为解决线性经济问题提供了有益的思路，并开辟了循环智能和机器人这一新兴研究领域。

<details>
  <summary>Details</summary>

**Motivation:** 线性经济模式导致矿产资源竞争加剧和大量废物产生，废物管理仍是未解决的问题。向循环经济转型可以缓解这些问题。

**Method:** 1. 增强了基于隔室动力学热力学的循环度概念（$\lambda$）。2. 建模了一个处理两批固体材料（临界系数分别为0.1和0.95）的热力学材料网络，其中包含一个由强化学习（RL）控制的机器人拆卸器隔室，处理2-7公斤的材料。3. 设计了机器人拆卸器隔室，使用了最先进的RL算法，并评估了算法性能与$\lambda$的关系。4. 进行了敏感性分析。

**Result:** 最高的循环度为-2.1，在拆卸两个1公斤部件的情况下实现；当拆卸装在3公斤底盘中的四个1公斤部件时，循环度降至-7.2。敏感性分析表明，RL控制器性能对$\lambda$的影响与待拆卸材料的数量和临界性呈正相关。

**Conclusion:** 本文提出了循环智能和机器人（CIRO）新兴研究领域的原理，并展示了强化学习控制的机器人拆卸器在材料网络中实现循环经济的潜力，指出RL控制器性能对循环度的影响与材料数量和临界性有关。

> **ai_Abstract:** 本文针对线性经济导致的资源枯竭和废物管理问题，提出了一种基于隔室动力学热力学的循环度增强概念（$\lambda$）。研究构建了一个包含强化学习（RL）控制的机器人拆卸器的热力学材料网络模型，用于处理不同临界系数的固体材料。通过实验评估RL算法性能对循环度的影响，发现最高循环度为-2.1，且循环度与待拆卸材料的数量和临界性呈正相关。该工作还为循环智能和机器人（CIRO）领域奠定了基础。

> **摘要翻译:** 预计矿产自然储备的竞争将会加剧，部分原因是基于“获取-制造-处置”的线性经济范式。同时，线性经济将报废产品视为废物而非资源，导致大量废物的产生，其管理仍是一个未解决的问题。鉴于向循环经济转型可以缓解这些未解决的问题，本文首先通过基于隔室动力学热力学的方法，即$\lambda$，增强了循环度的概念；然后，我们建模了一个处理两批固体材料（临界系数分别为0.1和0.95）的热力学材料网络，其中包含一个由强化学习（RL）控制的机器人拆卸器隔室，处理2-7公斤的材料。随后，我们专注于使用最先进的RL算法设计机器人拆卸器隔室，并评估了算法性能相对于$\lambda$的表现（图1）。在拆卸两个各重1公斤的部件时，最高的循环度为-2.1；而在拆卸装在3公斤底盘中的四个各重1公斤的部件时，循环度降至-7.2。最后，敏感性分析强调，RL控制器性能对$\lambda$的影响与待拆卸材料的数量和临界性呈正相关。这项工作还给出了循环智能和机器人（CIRO）新兴研究领域的原理。源代码已公开。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [293] [ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations](https://arxiv.org/abs/2506.11775)
> *ExoStart：利用传感器化外骨骼演示实现灵巧操作的有效学习*

*Zilin Si, Jose Enrique Chen, M. Emre Karagozler, Antonia Bronars, Jonathan Hutchinson, Thomas Lampe, Nimrod Gileadi, Taylor Howell, Stefano Saliceti, Lukasz Barczyk, Ilan Olivarez Correa, Tom Erez, Mohit Shridhar, Murilo Fernandes Martins, Konstantinos Bousmalis, Nicolas Heess, Francesco Nori, Maria Bauza Villalonga* | **Main category: cs.RO**

**Keywords:** 机器人灵巧操作, 外骨骼, 强化学习, 人类演示, 零样本迁移

**Comment:** 

> **TL;DR:** ExoStart是一个利用传感器化外骨骼收集人类灵巧演示数据，并通过仿真动力学滤波和强化学习，实现机器人手部灵巧操作的通用且可扩展的学习框架，在真实世界复杂任务中表现出色。

**AI_Comments:** 这篇论文的创新点在于其独特的数据收集方法，即使用传感器化外骨骼直接获取人类演示，避免了传统遥操作的复杂性。结合仿真动力学滤波和自课程强化学习，使得从人类演示中学习到的技能能够高效且鲁棒地迁移到真实机器人。其在复杂任务上的成功率证明了该方法的有效性和实用性，为机器人灵巧操作的学习提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前的遥操作系统在机器人操作数据收集方面取得了进展，但遥操作机器人手由于高自由度和复杂接触动力学仍面临巨大挑战。本研究的动机是利用人类的灵巧性来改进机器人手部控制，以解锁更广泛的操作技能。

**Method:** 本研究提出了ExoStart框架。它通过使用低成本传感器化可穿戴外骨骼，在没有机器人参与的情况下直接收集高质量的人类操作演示数据。然后，提出一个基于仿真的动力学滤波器，从收集到的演示中生成动态可行的轨迹。最后，利用生成的轨迹来引导一种仅依赖简单稀疏奖励的自课程强化学习方法。

**Result:** ExoStart能够生成灵巧的真实世界手部技能，在各种复杂任务（如打开AirPods外壳或插入并转动锁中的钥匙）中取得了超过50%的成功率。其策略具有泛化性，并能零样本迁移到真实机器人。

**Conclusion:** ExoStart是一个通用且可扩展的学习框架，能够有效利用人类灵巧性来提高机器人手部控制。它通过独特的演示数据收集和学习流程，实现了在真实世界复杂任务中的鲁棒且灵巧的机器人操作，证明了其在解锁更广泛操作技能方面的潜力。

> **ai_Abstract:** ExoStart是一个创新的学习框架，旨在解决机器人手部灵巧操作的挑战。它通过使用传感器化外骨骼直接收集人类演示数据，避免了传统的机器人遥操作难题。该框架结合了仿真动力学滤波和自课程强化学习，从人类演示中提取动态可行的轨迹，并训练出鲁棒的策略。实验结果表明，ExoStart能够使机器人实现高水平的灵巧操作，并在多种复杂真实世界任务中展现出超过50%的成功率，具有良好的泛化性和零样本迁移能力。

> **摘要翻译:** 遥操作系统的最新进展使得机械臂能够高质量地收集数据，并在大规模学习操作方面取得了令人印象深刻的成果。这一进展表明，将这些能力扩展到机器人手可以解锁更广泛的操作技能，特别是如果我们能够达到人类手所展现的相同水平的灵巧性。然而，遥操作机器人手远未解决，因为它对机器人手的高自由度和在接触丰富的环境中的复杂动力学带来了重大挑战。在这项工作中，我们提出了ExoStart，一个通用且可扩展的学习框架，它利用人类的灵巧性来改进机器人手部控制。特别是，我们通过使用传感器化低成本可穿戴外骨骼，在没有机器人参与的情况下直接收集演示数据，捕获人类可以用自己的手展示的丰富行为，从而获得高质量数据。我们还提出了一种基于仿真的动力学滤波器，从收集到的演示中生成动态可行的轨迹，并使用生成的轨迹来引导一种仅依赖简单稀疏奖励的自课程强化学习方法。ExoStart管道具有泛化性，并产生了能够零样本迁移到真实机器人的鲁棒策略。我们的结果表明，ExoStart可以生成灵巧的真实世界手部技能，在各种复杂任务（如打开AirPods外壳或插入并转动锁中的钥匙）中取得了超过50%的成功率。更多详细信息和视频可在https://sites.google.com/view/exostart找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [306] [Auditory-Tactile Congruence for Synthesis of Adaptive Pain Expressions in RoboPatients](https://arxiv.org/abs/2506.11827)
> *机器人患者中自适应疼痛表达的听觉-触觉一致性合成*

*Saitarun Nadipineni, Chapa Sirithunge, Yue Xie, Fumiya Iida, Thilina Dulantha Lalitharatne* | **Main category: cs.RO**

**Keywords:** 机器人患者, 疼痛表达, 触觉反馈, 听觉感知, 医疗模拟

**Comment:** 17 pages, 9 figures, journal

> **TL;DR:** 研究开发了RoboPatient，一个能根据触诊合成多模态疼痛（声音和面部）的医疗机器人模拟器，并发现音高和振幅是影响疼痛声音感知和真实感的关键因素。

**AI_Comments:** 本文提出了一种创新性的方法，通过集成触觉和听觉反馈，使医疗模拟机器人能够合成逼真的自适应疼痛表达。这对于提高临床医生的诊断准确性具有重要意义。研究通过大规模用户实验验证了关键声学特征（音高和振幅）对疼痛感知真实感的影响，为未来高保真医疗模拟器的设计提供了实证依据。其创新点在于疼痛表达的自适应合成和对感知一致性的深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 误诊会导致治疗延误和伤害。机器人患者提供了一种受控的方式来训练和评估临床医生处理罕见、细微或复杂的病例，从而减少诊断错误。

**Method:** 本文介绍了RoboPatient，一个医疗机器人模拟器，旨在基于触诊训练场景中的触觉和听觉反馈进行多模态疼痛合成。RoboPatient通过内部触诊-疼痛映射模型捕获和处理触觉输入，并能合成声音和面部疼痛表达。为了评估触诊与相应听觉输出之间的感知一致性，研究进行了一项涉及20名参与者（7680次试验）的研究，参与者通过声音评估疼痛强度。

**Result:** 结果显示，振幅和音高显著影响与机器人疼痛表达的一致性，无论疼痛声音类型如何。更强的触诊力引起更强的一致性，这与心理物理学模式一致。研究揭示了两个关键维度：音高和振幅是人们感知疼痛声音的核心，其中音高是最有影响力的线索。这些声学特征决定了声音与触诊施加力度的匹配程度，影响感知真实感。

**Conclusion:** 该方法为临床教育和诊断模拟中的高保真机器人患者奠定了基础。

> **ai_Abstract:** 本文介绍了RoboPatient，一个用于临床医生训练的医疗机器人模拟器，它能根据触诊产生的触觉输入合成多模态（声音和面部）疼痛表达。通过一项用户研究，验证了触诊与听觉疼痛表达的感知一致性。研究发现音高和振幅是影响人们感知疼痛声音及其真实感的关键声学特征，其中音高影响最大。该研究为开发高保真机器人患者在医疗教育和诊断模拟中的应用奠定了基础。

> **摘要翻译:** 误诊可能导致治疗延误和伤害。机器人患者提供了一种受控的方式，用于训练和评估临床医生处理罕见、细微或复杂的病例，从而减少诊断错误。我们提出了RoboPatient，一个医疗机器人模拟器，旨在基于触诊训练场景中的触觉和听觉反馈进行多模态疼痛合成。RoboPatient作为一个自适应中介，能够根据触诊过程中产生的触觉刺激合成合理的声音和面部疼痛表达。RoboPatient使用腹部模型，通过内部触诊-疼痛映射模型捕获和处理触觉输入。为了评估触诊与相应听觉输出之间的感知一致性，我们进行了一项研究，涉及20名参与者的7680次试验，他们在其中通过声音评估疼痛强度。结果表明，振幅和音高显著影响与机器人疼痛表达的一致性，而与疼痛声音无关。更强的触诊力引起更强的一致性，这与心理物理学模式相符。研究揭示了两个关键维度：音高和振幅是人们感知疼痛声音的核心，其中音高是最有影响力的线索。这些声学特征决定了声音与触诊施加力度的匹配程度，影响感知真实感。这种方法为临床教育和诊断模拟中的高保真机器人患者奠定了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [315] [The Space Between Us: A Methodological Framework for Researching Bonding and Proxemics in Situated Group-Agent Interactions](https://arxiv.org/abs/2506.11829)
> *我们之间的空间：一种研究群体-智能体交互中亲近与空间行为的方法论框架*

*Ana Müller, Anja Richert* | **Main category: cs.RO**

**Keywords:** 群体-智能体交互, 空间行为学, 亲近理论, 多方法框架, 社交智能体

**Comment:** Accepted for presentation at the Workshop on Advancing Group
  Understanding and Robots' Adaptive Behavior (GROUND), held at the Intelligent
  Autonomous Systems (IAS) Conference 2025, Genoa, Italy

> **TL;DR:** 本文提出了一种多方法框架，用于研究真实世界中群体与社交智能体互动时的空间和社会动态，并提供了一个开源、可扩展且经过现场测试的工具包。

**AI_Comments:** 该研究的创新之处在于提出了一个结合主观和客观数据的多方法框架，用于研究人与智能体交互中的复杂空间和社会动态。其重要性体现在提供了一个经过现场测试的开源工具包，这将极大地促进未来在该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 研究真实世界中群体与社交智能体互动中的空间和社会动态，并解决人类感知与行为对齐的挑战。

**Method:** 本文引入了一个多方法框架，借鉴空间行为学和亲近理论，结合主观自我报告和客观空间跟踪。该方法已应用于博物馆（N = 187）与机器人和虚拟智能体进行的两次现场研究中。

**Result:** 该框架已在博物馆的两次现场研究中得到应用，并提出了一个开源、可扩展且经过现场测试的工具包，以供未来研究使用。

**Conclusion:** 本文的主要贡献是提供了一个用于未来研究的开源、可扩展且经过现场测试的工具包，以支持对群体-智能体交互中空间和社会动态的研究。

> **ai_Abstract:** 本文提出了一种研究真实世界中群体与社交智能体互动空间和社会动态的多方法框架。该框架结合了空间行为学和亲近理论，采用主观自我报告和客观空间跟踪相结合的方法。该方法已在博物馆与机器人和虚拟智能体的两次现场研究中应用，旨在解决人类感知与行为对齐的挑战。论文重点在于提供一个开源、可扩展且经过现场测试的工具包，以支持未来的相关研究。

> **摘要翻译:** 本文介绍了一种多方法框架，用于研究真实世界中与社交互动智能体进行群体-智能体互动时的空间和社会动态。该方法借鉴了空间行为学和亲近理论，结合了主观自我报告和客观空间跟踪。该方法应用于博物馆（N = 187）与机器人和虚拟智能体进行的两次现场研究中，解决了人类感知与行为对齐的挑战。我们主要侧重于展示一个开源、可扩展且经过现场测试的工具包，以供未来研究使用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [324] [Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems](https://arxiv.org/abs/2506.11842)
> *你的驾驶，你的规则：心理学与认知赋能的自动驾驶系统*

*Zhipeng Bao, Qianwen Li* | **Main category: cs.RO**

**Keywords:** 自动驾驶系统, 以人为中心的自主性, 心理学, 认知, 基础模型

**Comment:** 10 figures,29 pages, one colummn

> **TL;DR:** 提出PACE-ADS框架，通过感知乘员心理和认知状态，实现个性化和舒适的自动驾驶，弥补当前自动驾驶缺乏双向通信的不足。

**AI_Comments:** PACE-ADS的创新之处在于其以人为中心的自动驾驶理念，通过整合乘员的心理和认知信号，实现了对驾驶行为的智能调适，显著提升了用户体验和安全性。其基于基础模型代理的模块化设计，以及在行为层面与现有自动驾驶系统协同工作而非取代的方式，展现了良好的兼容性和扩展性。这项工作为未来自动驾驶系统如何更好地理解和适应人类需求提供了新的视角，并强调了LLM在人机交互自主性领域的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动驾驶技术发展迅速，但目前的自动驾驶汽车（AVs）缺乏与乘员有效的双向通信，这限制了车辆的个性化和从停滞状态中恢复的能力。这降低了乘坐舒适度和信任度，可能减缓自动驾驶汽车的广泛普及。

**Method:** 本文提出了PACE-ADS（心理学与认知赋能的自动驾驶系统），一个以人为中心的自主性框架，使自动驾驶汽车能够感知、解释和响应外部交通以及内部乘员状态。PACE-ADS包含三个基于基础模型的代理：一个驾驶代理（分析驾驶环境），一个心理学家代理（解释乘员的心理信号，如脑电图、心率、面部表情，以及认知指令，如语音），和一个协调代理（整合这些输入以产生高级行为决策和操作参数）。PACE-ADS通过在行为层面操作来补充现有自动驾驶模块，将低级控制委托给原生的自动驾驶系统。这种分离实现了闭环适应并支持跨不同平台的集成。

**Result:** 在涉及交通灯、行人、施工区和跟车等多种场景的模拟中，PACE-ADS能够根据乘员状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人类指导安全地从停滞状态中恢复。

**Conclusion:** 研究结果突出了基于大型语言模型（LLM）的框架在弥合机器自主性与以人为中心的驾驶之间差距的潜力。

> **ai_Abstract:** 本文提出了PACE-ADS，一个以人为中心的自动驾驶框架，旨在通过感知和响应乘员的心理与认知状态来增强自动驾驶汽车的个性化、舒适度和信任度。该框架包含驾驶、心理学家和协调三个基于基础模型的代理，它们协同工作以整合驾驶环境和乘员信号，生成高级行为决策。PACE-ADS在行为层面补充现有自动驾驶系统，并在模拟中验证了其在适应驾驶风格、提高乘坐舒适度以及安全恢复车辆停滞方面的有效性，表明LLM-based框架在实现以人为中心的自动驾驶方面的巨大潜力。

> **摘要翻译:** 尽管自动驾驶技术发展迅速，但目前的自动驾驶汽车（AVs）缺乏与乘员有效的双向通信，这限制了车辆的个性化和从停滞状态中恢复的能力。这降低了乘坐舒适度和信任度，可能减缓自动驾驶汽车的广泛普及。我们提出了PACE-ADS（心理学与认知赋能的自动驾驶系统），一个以人为中心的自主性框架，使自动驾驶汽车能够感知、解释和响应外部交通以及内部乘员状态。PACE-ADS包含三个基于基础模型的代理：一个驾驶代理，用于分析驾驶环境；一个心理学家代理，用于解释乘员的心理信号（例如脑电图、心率、面部表情）和认知指令（例如语音）；以及一个协调代理，用于整合这些输入以产生高级行为决策和操作参数。PACE-ADS并非取代现有自动驾驶模块，而是通过在行为层面操作来补充它们，将低级控制委托给原生的自动驾驶系统。这种分离实现了闭环适应并支持跨不同平台的集成。我们在涉及交通灯、行人、施工区和跟车等多种场景的模拟中评估了PACE-ADS。结果显示，PACE-ADS能够根据乘员状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人类指导安全地从停滞状态中恢复。我们的研究结果突出了基于大型语言模型（LLM）的框架在弥合机器自主性与以人为中心的驾驶之间差距的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [333] [Palpation Alters Auditory Pain Expressions with Gender-Specific Variations in Robopatients](https://arxiv.org/abs/2506.11906)
> *触诊改变机器人患者的听觉疼痛表达，并具有性别特异性差异*

*Chapa Sirithunge, Yue Xie, Saitarun Nadipineni, Fumiya Iida, Thilina Dulantha Lalitharatne* | **Main category: cs.RO**

**Keywords:** 机器人患者, 触诊, 听觉疼痛表达, 强化学习, 性别特异性差异

**Comment:** 11 pages, 9 figures, journal

> **TL;DR:** 研究开发了一个使用强化学习的机器人患者系统，能根据触诊力动态生成听觉疼痛表达，并适应人类偏好和性别差异，以提升医疗训练模拟。

**AI_Comments:** 这项研究通过结合强化学习和人类反馈，解决了机器人患者在生成逼真听觉疼痛表达方面的核心挑战，具有创新性。其发现疼痛感知存在性别特异性差异，为更精细化的医疗模拟提供了重要洞察。该系统有望显著提高医疗训练的真实感和有效性，从而减少诊断错误。

<details>
  <summary>Details</summary>

**Motivation:** 诊断错误是可预防死亡的主要原因，尤其是在资源有限地区。现有的医疗训练模拟器，特别是机器人患者，在生成多模态反馈（尤其是听觉疼痛表达）方面存在挑战，因为触诊行为与声音之间的关系复杂，且疼痛声音的高维特性使得传统方法难以探索。

**Method:** 本研究引入了一种新的机器人患者疼痛表达实验范式。机器人通过使用机器学习共同优化人类反馈，动态生成对触诊力响应的听觉疼痛表达。具体来说，它使用近端策略优化 (PPO) 这种强化学习 (RL) 技术，迭代地根据实时人类反馈调整疼痛声音。机器人最初生成随机的疼痛响应，然后RL代理学习调整这些声音以符合人类偏好。

**Result:** 该系统能够适应个体的触诊力和声音偏好，并通过RL引导的探索捕捉到广泛的疼痛强度范围（从轻度不适到急性痛苦）。研究还发现，疼痛声音感知在较低的力下表现出饱和，并且具有性别特异性阈值。

**Conclusion:** 该系统通过提供一个可控且沉浸式的模拟平台，具有增强腹部触诊训练的潜力。

> **ai_Abstract:** 本文提出了一种创新的机器人患者系统，该系统利用强化学习（PPO）和人类反馈，能够动态生成对触诊力响应的听觉疼痛表达。该系统能适应个体偏好，捕捉不同疼痛强度，并发现疼痛感知存在性别特异性差异。研究结果表明，该系统有望显著提升腹部触诊的医疗训练效果。

> **摘要翻译:** 诊断错误仍然是可预防死亡的主要原因，特别是在资源有限的地区。医疗训练模拟器，包括机器人患者，通过模仿真实患者进行触诊等程序训练，在减少这些错误方面发挥着至关重要的作用。然而，由于触诊行为与声音之间复杂的关联，生成多模态反馈，尤其是听觉疼痛表达，仍然具有挑战性。疼痛声音的高维特性使得传统方法难以探索。本研究引入了一种新的机器人患者疼痛表达实验范式，通过使用机器学习共同优化人类反馈，动态生成对触诊力响应的听觉疼痛表达。该机器人使用近端策略优化（PPO）——一种为连续适应而优化的强化学习（RL）技术，根据实时人类反馈迭代地完善疼痛声音。该机器人初始化对触诊力的随机疼痛响应，然后RL代理学习调整这些声音以符合人类偏好。结果表明，该系统能够适应个体的触诊力和声音偏好，并通过RL引导的听觉疼痛空间探索，捕捉到广泛的疼痛强度范围，从轻度不适到急性痛苦。研究进一步表明，疼痛声音感知在较低的力下表现出饱和，并具有性别特异性阈值。这些发现强调了该系统通过提供一个可控且沉浸式的模拟平台，增强腹部触诊训练的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [338] [mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity](https://arxiv.org/abs/2506.11916)
> *mimic-one：一种用于通用机器人灵巧性的可扩展模型配方*

*Elvis Nava, Victoriano Montesinos, Erik Bauer, Benedek Forrai, Jonas Pai, Stefan Weirich, Stephan-Daniel Gravert, Philipp Wand, Stephan Polinski, Benjamin F. Grewe, Robert K. Katzschmann* | **Main category: cs.RO**

**Keywords:** 机器人灵巧性, 扩散模型, 机械手, 遥操作, 自校正行为

**Comment:** 

> **TL;DR:** mimic-one提出了一种基于扩散模型的可扩展方法，结合新型灵巧机械手和遥操作数据收集，实现了高成功率和自校正能力的通用机器人精细操作。

**AI_Comments:** 该论文的创新之处在于其将扩散模型应用于机器人精细控制，并结合了定制设计的灵巧机械手与先进的遥操作数据收集方法，实现了端到端学习和实际部署。其强调的自校正行为和高分布外成功率显示了该方法的鲁棒性和实用性，为通用机器人灵巧性提供了有前景的集成解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过一种完全集成、实用的方法来推进灵巧机器人操作的最新技术，解决硬件、学习和实际部署中的挑战，以实现通用机器人灵巧性。

**Method:** 本研究提出了一种基于扩散模型的模型配方，用于高度灵巧类人型机器人手的真实世界控制。该系统采用新设计的16自由度肌腱驱动手，配备广角腕部摄像头，并安装在Franka Emika Panda机械臂上。开发了多功能遥操作管道和数据收集协议，使用手套和VR界面，以收集高质量数据。通过高频生成控制，从原始感官输入训练端到端策略。

**Result:** 在真实世界评估中，该系统实现了高达93.3%的分布外成功率，并由于出现的自校正行为，性能提升高达33.3%。同时，结果也揭示了策略性能的扩展趋势。

**Conclusion:** 该研究通过一种完全集成、实用的硬件、学习和真实世界部署方法，提升了灵巧机器人操作的最新水平。

> **ai_Abstract:** mimic-one提出了一种基于扩散模型的通用机器人灵巧性解决方案，结合了新颖的16自由度肌腱驱动机械手和集成的遥操作数据收集系统。该方法通过端到端策略训练，实现了对原始感官输入的高频生成控制，从而在复杂操作任务中展现出平滑的自校正运动。真实世界评估显示，其在分布外任务中具有高成功率和显著的性能提升，推动了灵巧机器人操作技术的发展。

> **摘要翻译:** 我们提出了一种基于扩散模型的模型配方，用于高度灵巧类人型机器人手的真实世界控制，旨在实现样本高效学习和平滑的精细运动推断。我们的系统采用新设计的16自由度肌腱驱动手，配备广角腕部摄像头，并安装在Franka Emika Panda机械臂上。我们开发了一种多功能遥操作管道和数据收集协议，使用手套和VR界面，从而可以在抓取放置、物品分类和装配插入等多种任务中收集高质量数据。利用高频生成控制，我们从原始感官输入训练端到端策略，从而在复杂操作场景中实现平滑、自校正的运动。真实世界评估显示，分布外成功率高达93.3%，由于出现的自校正行为，性能提升高达33.3%，同时还揭示了策略性能的扩展趋势。我们的结果通过一种完全集成、实用的硬件、学习和真实世界部署方法，提升了灵巧机器人操作的最新水平。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [346] [SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies](https://arxiv.org/abs/2506.11948)
> *SAIL：比示范更快地执行模仿学习策略*

*Nadun Ranawaka Arachchige, Zhenyang Chen, Wonsuhk Jung, Woo Chul Shin, Rohan Bansal, Pierre Barroso, Yu Hang He, Yingyang Celine Lin, Benjamin Joffe, Shreyas Kousik, Danfei Xu* | **Main category: cs.RO**

**Keywords:** 模仿学习, 机器人, 速度适应, 自动化, 视觉运动策略

**Comment:** The first two authors contributed equally

> **TL;DR:** SAIL提出并解决了模仿学习策略执行速度受限于演示速度的问题，实现了显著的加速。

**AI_Comments:** SAIL的创新之处在于首次明确提出并解决了模仿学习策略的“超演示速度执行”问题，并通过一个全面的系统设计来克服了机器人动力学和状态-动作分布偏移等挑战。其提出的四个组件协同工作，有效地提高了任务吞吐量，对于提升机器人自动化效率具有重要实践价值。该研究为模仿学习在实际工业部署中的应用提供了新的思路和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模仿学习（IL）方法训练出的策略，其任务执行速度受限于演示数据中的速度，这限制了机器人系统的任务吞吐量，而工业自动化等应用对高吞吐量有关键需求。

**Method:** 本文提出了SAIL（Speed Adaptation for Imitation Learning）系统，这是一个包含四个紧密连接组件的全栈系统：1) 用于高速平滑运动的保持一致性的动作推理算法；2) 对控制器不变运动目标的高保真跟踪；3) 根据运动复杂性动态调整执行速度的自适应速度调制；4) 处理真实世界系统延迟的动作调度。

**Result:** SAIL在模拟环境中实现了高达4倍于演示速度的加速，在真实世界中实现了高达3.2倍的加速，并在模拟和两个真实的机器人平台上进行了12项任务的实验验证。

**Conclusion:** SAIL成功地解决了模仿学习策略执行速度受限于演示速度的问题，显著提高了机器人系统的任务吞吐量，证明了其在工业自动化等应用中的潜力。

> **ai_Abstract:** 本文提出了SAIL系统，旨在解决模仿学习策略执行速度受限于演示速度的问题。SAIL是一个包含动作推理、目标跟踪、速度调制和动作调度四个核心组件的全栈系统。通过在模拟和真实机器人上的实验，SAIL实现了最高4倍于演示速度的执行加速，显著提升了机器人任务的吞吐量，对于工业自动化等应用具有重要意义。

> **摘要翻译:** 离线模仿学习（IL）方法，例如行为克隆，在获取复杂的机器人操作技能方面是有效的。然而，现有的IL训练策略被限制在以演示数据中所示的相同速度执行任务。这限制了机器人系统的任务吞吐量，这是工业自动化等应用的关键要求。在本文中，我们引入并形式化了使视觉运动策略实现比演示更快执行的新问题，并确定了机器人动力学和状态-动作分布偏移中的基本挑战。我们将关键见解实例化为SAIL（Speed Adaptation for Imitation Learning），一个集成四个紧密连接组件的全栈系统：（1）用于高速平滑运动的保持一致性的动作推理算法，（2）对控制器不变运动目标的高保真跟踪，（3）根据运动复杂性动态调整执行速度的自适应速度调制，以及（4）处理真实世界系统延迟的动作调度。在模拟和两个真实、不同的机器人平台上进行的12项任务的实验表明，SAIL在模拟中实现了比演示速度快4倍的加速，在真实世界中实现了高达3.2倍的加速。更多详情请访问 https://nadunranawaka1.github.io/sail-policy

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [14] [EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices](https://arxiv.org/abs/2506.11093)
> *EfficientQuant：一种面向边缘设备的CNN-Transformer混合模型的有效训练后量化方法*

*Shaibal Saha, Lanyu Xu* | **Main category: cs.CV**

**Keywords:** 训练后量化, 混合模型, 边缘设备, 神经网络量化, EfficientQuant

**Comment:** Accepted to the 4th Workshop on Transformers for Vision (T4V) at CVPR
  2025

> **TL;DR:** EfficientQuant是一种针对CNN-Transformer混合模型的训练后量化方法，通过对不同模块采用不同量化策略，显著降低了边缘设备的延迟和内存消耗，同时保持了高精度。

**AI_Comments:** EfficientQuant的创新之处在于其结构感知的混合量化策略，针对CNN和Transformer块的特性分别采用不同的量化方法，有效解决了混合模型在边缘设备部署中的资源瓶颈问题，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 结合卷积和Transformer块的混合模型在计算机视觉任务中表现出色，但对于边缘部署而言资源密集。虽然训练后量化（PTQ）可以帮助降低资源需求，但其在混合模型上的应用仍然有限。

**Method:** 我们提出了EfficientQuant，一种新颖的结构感知型训练后量化（PTQ）方法，它对卷积块应用均匀量化，对Transformer块应用$log_2$量化。

**Result:** EfficientQuant在ImageNet-1K数据集上实现了2.5倍至8.7倍的延迟降低，同时保持了最小的精度损失。它进一步在边缘设备上展示了低延迟和内存效率。

**Conclusion:** EfficientQuant在边缘设备上具有低延迟和内存效率，使其在实际部署中具有实用性。

> **ai_Abstract:** 本文提出了EfficientQuant，一种专为CNN-Transformer混合模型设计的训练后量化（PTQ）方法，旨在解决混合模型在边缘设备上资源消耗大的问题。该方法创新性地对卷积块采用均匀量化，对Transformer块采用$log_2$量化，实现了显著的延迟降低和内存效率提升，且精度损失极小，验证了其在实际边缘部署中的可行性。

> **摘要翻译:** 结合卷积和Transformer块的混合模型在计算机视觉（CV）任务中表现出色，但对于边缘部署而言资源密集。虽然训练后量化（PTQ）可以帮助降低资源需求，但其在混合模型上的应用仍然有限。我们提出了EfficientQuant，一种新颖的结构感知型训练后量化（PTQ）方法，它对卷积块应用均匀量化，对Transformer块应用$log_2$量化。EfficientQuant在ImageNet-1K数据集上实现了2.5倍至8.7倍的延迟降低，同时保持了最小的精度损失。它进一步在边缘设备上展示了低延迟和内存效率，使其在实际部署中具有实用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [42] [Adaptive Object Detection with ESRGAN-Enhanced Resolution & Faster R-CNN](https://arxiv.org/abs/2506.11122)
> *自适应目标检测：基于ESRGAN增强分辨率与Faster R-CNN*

*Divya Swetha K, Ziaul Haque Choudhury, Hemanta Kumar Bhuyan, Biswajit Brahma, Nilayam Kumar Kamila* | **Main category: cs.CV**

**Keywords:** 目标检测, 超分辨率, ESRGAN, Faster R-CNN, 低分辨率图像

**Comment:** 

> **TL;DR:** 本文提出了一种结合ESRGAN超分辨率和Faster R-CNN目标检测的方法，以提高低分辨率图像上的目标检测性能。

**AI_Comments:** 该研究的创新之处在于将超分辨率（ESRGAN）与目标检测（Faster R-CNN）协同集成，以解决低质量输入图像的实际挑战。这种预处理步骤有效地解决了现实世界应用中的一个常见限制，使目标检测更加鲁棒。其重要性在于其在无法持续获得高分辨率输入的场景中的潜在应用。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决低分辨率或图像质量不佳的图像上的目标检测性能问题，尤其是在图像分辨率不一致的应用场景中。

**Method:** 该研究将ESRGAN作为预处理步骤，用于增强低分辨率输入图像，恢复细节并提高清晰度。随后，将增强后的图像输入到Faster R-CNN模型中进行精确的目标检测和定位。

**Result:** 实验结果表明，与直接应用于低分辨率图像的传统方法相比，这种集成方法表现出卓越的性能。它在提高图像质量和高效目标检测之间取得了平衡。

**Conclusion:** 所提出的框架为图像质量可变或受限的应用提供了一个有前景的解决方案，从而在具有挑战性的场景中实现更鲁棒和可靠的目标检测。

> **ai_Abstract:** 本文介绍了一种针对低分辨率或质量不佳图像的鲁棒目标检测新方法。该方法将ESRGAN用于超分辨率增强作为预处理步骤，随后使用Faster R-CNN对增强后的图像进行精确目标检测。实验结果表明，这种组合方法优于传统的直接处理方法，为在具有挑战性的可变质量场景中提高图像质量和高效检测提供了平衡的解决方案。

> **摘要翻译:** 本研究提出了一种通过集成增强型超分辨率生成对抗网络（ESRGAN）和Faster Region-Convolutional Neural Network (Faster R-CNN) 来改进低分辨率图像目标检测的方法。ESRGAN用于增强低质量图像，恢复细节并提高清晰度，而Faster R-CNN则在增强后的图像上执行精确的目标检测。这两种技术的结合确保了即使在输入质量较差的情况下也能获得更好的检测性能，为图像分辨率不一致的应用提供了有效的解决方案。ESRGAN作为预处理步骤，用于增强低分辨率输入图像，有效恢复丢失的细节并提高整体图像质量。随后，增强后的图像被输入到Faster R-CNN模型中进行精确的目标检测和定位。实验结果表明，与直接应用于低分辨率图像的传统方法相比，这种集成方法产生了卓越的性能。所提出的框架为图像质量可变或受限的应用提供了一个有前景的解决方案，从而在具有挑战性的场景中实现更鲁棒和可靠的目标检测。它在提高图像质量和高效目标检测之间取得了平衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [70] [Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error Correction and Spatially-Aware Prompting](https://arxiv.org/abs/2506.11124)
> *Argoverse2 场景挖掘挑战的技术报告：关于迭代错误纠正和空间感知提示*

*Yifei Chen, Ross Greer* | **Main category: cs.CV**

**Keywords:** 场景挖掘, 大型语言模型, 错误纠正, 提示工程, Argoverse2

**Comment:** 

> **TL;DR:** 针对Argoverse2自动驾驶场景挖掘中LLM生成代码的错误和空间关系理解问题，本报告提出了迭代错误纠正机制和空间感知提示工程，显著提升了场景挖掘的准确性。

**AI_Comments:** 这篇技术报告通过引入迭代错误纠正和空间感知提示工程，有效地解决了LLM在自动驾驶场景挖掘中生成错误代码和理解复杂空间关系的问题。其创新点在于将LLM的错误反馈机制融入代码生成循环，并结合了领域特定的提示工程，从而显著提升了LLM在特定任务中的实用性和可靠性。这对于依赖LLM进行复杂数据处理和分析的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶数据集（如Argoverse 2）的场景挖掘对于自动驾驶系统的开发和验证至关重要。现有的RefAV框架使用LLM将自然语言查询转换为可执行代码来识别场景，但面临LLM生成代码的运行时错误和对复杂多对象空间关系函数参数解释不准确的挑战。

**Method:** 引入了两项增强：1) 容错迭代代码生成机制，通过错误反馈重新提示LLM来完善代码；2) 专门的提示工程，提高LLM对空间关系函数的理解和正确应用。

**Result:** 在Argoverse 2验证集上，使用Qwen2.5-VL-7B、Gemini 2.5 Flash和Gemini 2.5 Pro等不同LLM进行了实验，显示在多个指标上均有持续提升。最显著的是，使用Gemini 2.5 Pro在官方测试集上，所提出的系统实现了52.37的HOTA-Temporal分数。

**Conclusion:** 这些结果强调了所提出的技术对于可靠、高精度场景挖掘的有效性。

> **ai_Abstract:** 本技术报告旨在解决使用大型语言模型（LLM）进行自动驾驶场景挖掘时遇到的代码生成错误和空间关系理解不准确的问题。通过引入容错迭代代码生成机制和专门的空间感知提示工程，该方法显著提升了LLM在将自然语言查询转换为可执行代码以识别相关场景时的准确性和可靠性。实验结果表明，所提出的增强技术在Argoverse 2数据集上取得了显著的性能提升，尤其是在HOTA-Temporal分数上表现出色，证明了其在实现高精度场景挖掘方面的有效性。

> **摘要翻译:** 从Argoverse 2等大规模自动驾驶数据集中进行场景挖掘对于自动驾驶系统的开发和验证至关重要。RefAV框架通过利用大型语言模型（LLM）将自然语言查询转换为可执行代码来识别相关场景，代表了一种有前景的方法。然而，该方法面临挑战，包括LLM生成代码导致的运行时错误以及解释描述复杂多对象空间关系的函数参数时的不准确性。本技术报告介绍了两项关键增强来解决这些限制：（1）一种容错的迭代代码生成机制，通过错误反馈重新提示LLM来完善代码，以及（2）专门的提示工程，提高LLM对空间关系函数的理解和正确应用。在Argoverse 2验证集上使用不同的LLM（Qwen2.5-VL-7B、Gemini 2.5 Flash和Gemini 2.5 Pro）进行的实验显示，在多个指标上都有持续的提升；最值得注意的是，所提出的系统在使用Gemini 2.5 Pro的官方测试集上实现了52.37的HOTA-Temporal分数。这些结果强调了所提出的技术对于可靠、高精度场景挖掘的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [90] [Autonomous Computer Vision Development with Agentic AI](https://arxiv.org/abs/2506.11140)
> *采用代理AI的自主计算机视觉开发*

*Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown* | **Main category: cs.CV**

**Keywords:** 代理AI, 计算机视觉, 大语言模型, 自主开发, 医疗图像分析

**Comment:** The paper is 13 pages long and contains 4 figures

> **TL;DR:** 本文展示了如何利用基于LLM的代理AI，通过自然语言提示自主开发和配置计算机视觉系统，并在胸部X光图像分割任务上取得了良好效果。

**AI_Comments:** 这项工作的主要创新在于展示了代理AI如何实现计算机视觉系统开发的自主化，特别是自动化了传统上由数据科学家执行的规划和工具配置过程。其重要性在于，这可能显著降低计算机视觉应用开发的门槛和时间成本。尽管概念验证仅限于特定任务和数据集，但其证明了基于LLM的代理在复杂AI系统自主构建方面的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 代理AI系统在复杂推理、规划和工具利用方面潜力巨大。传统上，计算机视觉应用的开发中的规划和工具配置由数据科学家完成，本研究旨在探索实现这一过程的自动化。

**Method:** 研究人员通过使用OpenManus实现了一个基于LLM的代理，扩展了开源认知AI环境SimpleMind (SM)。该代理能够解释自然语言的计算机视觉任务提示，分解任务，并配置适当的工具以规划SimpleMind工作流（即生成YAML格式的工具配置文件），然后自主执行SM-Learn（训练）和SM-Think（推理）脚本。

**Result:** 代理AI成功地根据用户提示（如“提供用于胸部X光片中肺、心脏和肋骨分割的SM配置”）生成了规划文件，并自主执行了训练和推理。该计算机视觉代理在50张胸部X光图像上自动配置、训练和测试，肺部、心脏和肋骨的平均Dice分数分别达到0.96、0.82和0.83。

**Conclusion:** 这项工作展示了自主规划和工具配置的潜力，这些任务传统上在计算机视觉应用开发中由数据科学家执行。

> **ai_Abstract:** 本研究展示了一种利用基于大型语言模型（LLM）的代理AI系统自主开发计算机视觉应用的方法。通过扩展开源的SimpleMind环境，研究人员实现了一个AI代理，该代理能够根据自然语言提示自动进行任务规划、工具配置、训练和推理。在一个胸部X光图像分割任务的概念验证中，该代理成功地自主配置、训练和测试了模型，并在肺、心脏和肋骨分割上取得了高Dice分数，证明了其在自动化计算机视觉开发流程方面的巨大潜力。

> **摘要翻译:** 利用大型语言模型（LLMs）的代理人工智能（AI）系统在复杂推理、规划和工具利用方面展现出巨大潜力。我们证明，可以使用代理AI方法，从自然语言提示中自主构建一个专门的计算机视觉系统。这涉及扩展SimpleMind（SM）——一个开源的认知AI环境，具有用于医学图像分析的可配置工具——通过使用OpenManus实现一个基于LLM的代理，以自动化特定计算机视觉任务的规划（工具配置）。我们提供了一个概念验证演示，表明代理系统可以解释计算机视觉任务提示，通过分解任务和配置适当的工具来规划相应的SimpleMind工作流。根据用户输入提示（“提供用于胸部X光片中肺、心脏和肋骨分割的SM配置”），代理LLM能够生成计划（YAML格式的工具配置文件），并自主执行SM-Learn（训练）和SM-Think（推理）脚本。该计算机视觉代理在50张胸部X光图像上自动配置、训练和测试，肺部、心脏和肋骨的平均Dice分数分别达到0.96、0.82和0.83。这项工作展示了自主规划和工具配置的潜力，这些任务传统上在计算机视觉应用开发中由数据科学家执行。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [98] [Image-Based Method For Measuring And Classification Of Iron Ore Pellets Using Star-Convex Polygons](https://arxiv.org/abs/2506.11126)
> *使用星凸多边形的铁矿石球团图像测量与分类方法*

*Artem Solomko, Oleg Kartashev, Andrey Golov, Mikhail Deulin, Vadim Valynkin, Vasily Kharin* | **Main category: cs.CV**

**Keywords:** 铁矿石球团, 图像测量, StarDist算法, 质量分类, 尺寸分布

**Comment:** 15 pages, 41 figures

> **TL;DR:** 开发了一种基于图像的新方法，利用StarDist算法对铁矿石球团进行测量和分类，以识别质量缺陷并提高测量精度。

**AI_Comments:** 该论文的创新之处在于将主要用于医疗图像分析的StarDist算法创造性地应用于工业领域的铁矿石球团质量检测，解决了传统方法在复杂环境下精度不足的问题。这种跨领域的方法迁移展示了其潜力。其重要性体现在能够显著提高产品质量控制的准确性和效率，对工业生产具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 识别最终产品中的质量缺陷，特别是在密集不稳定的环境中准确识别和分析物体；传统算法在此背景下未能获得满意结果；球团的尺寸分布和分类（区分合格与粘连类型）是定义产品质量的最重要特征之一。

**Method:** 采用了一种创新的基于图像的测量方法，利用主要用于医疗领域的StarDist算法。过程包括分割物体、确定轮廓、分类和测量物理尺寸。探索了相关领域的方法来增强其方法。

**Result:** 提出了一种检测具有平滑边界物体的新方法。显著提高了物理尺寸测量的准确性，并促进了铁矿石球团尺寸分布的更精确分析。

**Conclusion:** 通过利用StarDist算法的优势，提供了一个鲁棒的解决方案，解决了球团分类和测量复杂性带来的挑战。

> **ai_Abstract:** 本文旨在解决铁矿石球团质量检测中的挑战，通过开发一种创新的图像测量与分类方法。研究发现传统算法在密集和不稳定环境中对球团进行准确识别和测量效果不佳。为此，作者引入并改进了主要用于医疗领域的StarDist算法，实现了对球团的精确分割、轮廓确定、分类和物理尺寸测量。新方法显著提高了尺寸测量精度和尺寸分布分析的准确性，为铁矿石球团的质量控制提供了更可靠的解决方案。

> **摘要翻译:** 我们将对铁矿石球团的分类进行一项综合研究，旨在识别最终产品中的质量违规，同时开发一种利用StarDist算法的创新图像测量方法，该算法主要应用于医疗领域。这项举措的动机是需要在密集且不稳定的环境中准确识别和分析物体。该过程涉及分割这些物体、确定它们的轮廓、对它们进行分类以及测量它们的物理尺寸。这至关重要，因为球团的尺寸分布和分类，例如区分良好（高质量）和粘连（由水分存在引起或表明生产失败过程）类型，是定义最终产品质量的最重要特征之一。包括使用Vision Transformer (ViT) 的图像分类技术、Mask R-CNN 等实例分割方法以及各种异常分割算法在内的传统算法，在这种情况下并未产生令人满意的结果。因此，我们探索了相关领域的方法来增强我们的方法。我们研究的结果是一种旨在检测具有平滑边界物体的新方法。这一进展显著提高了物理尺寸测量的准确性，并促进了铁矿石球团尺寸分布的更精确分析。通过利用StarDist算法的优势，我们旨在提供一个强大的解决方案，以应对球团分类和测量复杂性带来的挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [125] [Segment This Thing: Foveated Tokenization for Efficient Point-Prompted Segmentation](https://arxiv.org/abs/2506.11131)
> *分割这个东西：用于高效点提示分割的中心凹状标记化*

*Tanner Schmidt, Richard Newcombe* | **Main category: cs.CV**

**Keywords:** 中心凹状标记化, 图像分割, 点提示, 效率, 变分辨率

**Comment:** 

> **TL;DR:** Segment This Thing (STT)模型通过新颖的中心凹状标记化方法，在不减小模型尺寸的情况下，实现了高效的点提示图像分割，并且在性能上保持竞争力。

**AI_Comments:** 本文的创新点在于其独特的中心凹状标记化方法，它通过改变补丁分辨率而非减小模型大小来提高效率，这提供了一个新的视角。其重要性体现在能够使复杂的分割任务在消费级硬件上以交互式帧率运行，这对于实时应用如增强现实和机器人技术具有重大实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像分割模型通过减小模型尺寸来提高效率。本文旨在提出一种新的效率提升方法，即通过对输入图像进行中心凹状处理来显著降低计算成本，同时保持或提高分割性能。

**Method:** 本文提出了Segment This Thing (STT)模型。给定图像和点提示，该方法首先提取以提示为中心的裁剪区域，然后应用一种新颖的变分辨率补丁标记化技术，其中补丁的下采样率随与提示距离的增加而增加。这种方法显著减少了图像标记的数量。

**Result:** 该方法产生的图像标记远少于统一补丁标记化，从而在不减小模型尺寸的情况下大幅降低了分割的计算成本。中心凹状处理使模型能够专注于感兴趣区域。实验表明，STT模型比现有工作更高效，同时在分割基准上保持竞争力。

**Conclusion:** STT模型可以在消费级硬件上以交互式帧率轻松运行，这使其成为增强现实或机器人应用中一个有前景的工具。

> **ai_Abstract:** Segment This Thing (STT)是一种高效的图像分割模型，专门用于根据点提示生成单个分割。与传统通过缩小模型尺寸提升效率不同，STT采用新颖的中心凹状标记化方法：它提取以点提示为中心的图像裁剪区域，并应用变分辨率补丁标记化，使远离提示的区域下采样率更高。这种方法显著减少了图像标记数量，从而在不减小模型尺寸的情况下大幅降低了计算成本。STT模型在分割性能上与现有方法持平，但在效率上更优，并能在消费级硬件上实现实时运行，适用于增强现实和机器人应用。

> **摘要翻译:** 本文提出了Segment This Thing (STT)，这是一种新型高效图像分割模型，旨在根据单个点提示生成单个分割。我们没有遵循现有工作通过减小模型尺寸来提高效率，而是通过对输入图像进行中心凹状处理来提高效率。给定图像和点提示，我们提取以提示为中心的裁剪区域，并应用一种新颖的变分辨率补丁标记化，其中补丁的下采样率随与提示距离的增加而增加。这种方法产生的图像标记远少于统一补丁标记化。因此，我们可以在不减小模型尺寸的情况下大幅降低分割的计算成本。此外，中心凹状处理使模型专注于感兴趣区域，这可能是一个有用的归纳偏置。我们展示了Segment This Thing模型比现有工作更高效，同时在分割基准上保持竞争力。它可以在消费级硬件上轻松以交互式帧率运行，因此是增强现实或机器人应用中有前景的工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [134] [Monocular 3D Hand Pose Estimation with Implicit Camera Alignment](https://arxiv.org/abs/2506.11133)
> *单目3D手部姿态估计与隐式相机对齐*

*Christos Pantazopoulos, Spyridon Thermos, Gerasimos Potamianos* | **Main category: cs.CV**

**Keywords:** 单目3D手部姿态估计, 隐式相机对齐, 2D关键点, 优化, 增强现实

**Comment:** Code is available at https://github.com/cpantazop/HandRepo

> **TL;DR:** 提出一种优化方法，通过隐式相机对齐从单目2D关键点输入估计3D手部姿态，无需先验相机参数，表现与SotA相当。

**AI_Comments:** 这项工作的创新之处在于提出了一种无需显式相机参数即可进行单目3D手部姿态估计的方法，通过关键点对齐和指尖损失巧妙地解决了这一挑战。其在“野外”图像上的鲁棒性展示了其实用潜力，对于AR/VR和HCI等应用具有重要意义。然而，对2D关键点估计精度的敏感性也提示了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 从单张彩色图像估计3D手部姿态在AR、VR、HCI和机器人技术中有应用。主要挑战包括深度信息缺失、遮挡、关节复杂性和需要相机参数。

**Method:** 提出一个优化流程，用于从2D关键点输入估计3D手部关节。该流程包含一个关键点对齐步骤和一个指尖损失，以克服需要已知或估计相机参数的问题。

**Result:** 在EgoDexter和Dexter+Object基准测试上表现与SotA相当，并且在处理“野外”图像时无需任何先验相机知识也能展示其鲁棒性。定量分析强调了尽管使用了手部先验，2D关键点估计精度仍然敏感。

**Conclusion:** 该方法通过隐式相机对齐，有效解决了单目3D手部姿态估计中对相机参数依赖的问题，并在多个基准测试上取得了有竞争力的结果。

> **ai_Abstract:** 这篇论文提出了一种用于单目3D手部姿态估计的优化管道，该方法通过2D关键点输入，并引入了关键点对齐和指尖损失来隐式处理相机参数，从而无需预先知道或估计相机参数。该方法在标准基准测试上表现出与现有最佳技术相当的性能，并且在未知相机参数的“野外”图像中也表现出鲁棒性。研究还指出2D关键点估计精度对整体性能有显著影响。

> **摘要翻译:** 从单张彩色图像估计3D手部关节是一个持续研究的问题，其应用包括增强现实（AR）、虚拟现实（VR）、人机交互（HCI）和机器人技术。除了深度信息缺失之外，遮挡、关节复杂性和需要相机参数知识带来了额外的挑战。在这项工作中，我们提出了一种优化流程，用于从2D关键点输入估计3D手部关节，该流程包括一个关键点对齐步骤和一个指尖损失，以克服需要知道或估计相机参数的问题。我们在EgoDexter和Dexter+Object基准测试上评估了我们的方法，结果表明我们的方法与最先进的技术（SotA）具有竞争力，同时还展示了其在处理“野外”图像时无需任何先验相机知识的鲁棒性。我们的定量分析强调了尽管使用了手部先验，但2D关键点估计精度仍然敏感。代码可在https://github.com/cpantazop/HandRepo获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [150] [Gender Fairness of Machine Learning Algorithms for Pain Detection](https://arxiv.org/abs/2506.11132)
> *机器学习算法在疼痛检测中的性别公平性*

*Dylan Green, Yuting Shang, Jiaee Cheong, Yang Liu, Hatice Gunes* | **Main category: cs.CV**

**Keywords:** 性别公平性, 机器学习, 疼痛检测, 偏见, 深度学习

**Comment:** To appear as part of the 2025 19th International Conference on
  Automatic Face and Gesture Recognition (FG) Workshop Proceedings

> **TL;DR:** 本研究调查了用于疼痛检测的机器学习和深度学习算法的性别公平性，发现所有模型都存在性别偏见，突显了准确性和公平性之间的权衡。

**AI_Comments:** 该论文解决了医疗保健AI中一个关键且日益重要的问题：公平性。它通过实证研究揭示了现有机器学习和深度学习模型在疼痛检测中存在的性别偏见，即使是高准确性的模型也未能幸免。这一发现对实际应用具有重要意义，因为它提醒我们不能仅仅追求准确性，而忽略了算法可能带来的不公平后果。论文强调了“准确性与公平性之间的持续权衡”，这为未来研究指明了方向，即开发专门的公平性感知技术来解决这些偏见。其创新性在于将公平性分析引入到疼痛检测这一具体应用领域，并提供了具体的模型比较。

<details>
  <summary>Details</summary>

**Motivation:** 自动化疼痛检测在医疗保健领域潜力巨大，特别是对于无法自我报告疼痛水平的患者。然而，这些算法在不同人口群体（如性别）间的准确性和公平性尚未得到充分研究。

**Method:** 本研究调查了在UNBC-McMaster肩部疼痛表达档案数据库上训练的ML和DL模型的性别公平性，仅根据参与者面部表情的视觉模态评估了各种模型在疼痛检测中的性能。比较了传统ML算法（线性支持向量机L SVM和径向基函数SVM RBF SVM）与DL方法（卷积神经网络CNN和视觉转换器ViT），并使用了一系列性能和公平性指标。

**Result:** 尽管ViT获得了最高的准确性和一部分公平性指标，但所有模型都表现出基于性别的偏见。

**Conclusion:** 这些发现突显了准确性和公平性之间持续存在的权衡，强调了需要采用公平性感知技术来减轻自动化医疗保健系统中的偏见。

> **ai_Abstract:** 本论文研究了机器学习和深度学习算法在疼痛检测中的性别公平性问题。研究利用UNBC-McMaster肩部疼痛表达档案数据库，评估了L SVM、RBF SVM、CNN和ViT等模型在根据面部表情检测疼痛时的表现。结果显示，尽管ViT在准确性上表现最佳，但所有模型都存在性别偏见。这强调了在自动化医疗保健系统中，准确性和公平性之间存在权衡，并指出未来研究应关注开发公平性感知技术以减轻偏见。

> **摘要翻译:** 通过机器学习（ML）和深度学习（DL）算法实现的自动化疼痛检测在医疗保健领域具有巨大潜力，特别是对于无法自我报告疼痛水平的患者。然而，这些算法在不同人口群体（例如性别）间的准确性和公平性仍未得到充分研究。本文调查了在UNBC-McMaster肩部疼痛表达档案数据库上训练的ML和DL模型的性别公平性，仅根据参与者面部表情的视觉模态评估了各种模型在疼痛检测中的性能。我们比较了传统的ML算法，线性支持向量机（L SVM）和径向基函数SVM（RBF SVM），与DL方法，卷积神经网络（CNN）和视觉转换器（ViT），并使用了一系列性能和公平性指标。尽管ViT获得了最高的准确性和一部分公平性指标，但所有模型都表现出基于性别的偏见。这些发现突显了准确性和公平性之间持续存在的权衡，强调了需要采用公平性感知技术来减轻自动化医疗保健系统中的偏见。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [189] [ContextLoss: Context Information for Topology-Preserving Segmentation](https://arxiv.org/abs/2506.11134)
> *上下文损失：用于拓扑保持分割的上下文信息*

*Benedict Schacht, Imke Greving, Simone Frintrop, Berit Zeller-Plumhoff, Christian Wilms* | **Main category: cs.CV**

**Keywords:** 图像分割, 拓扑保持, 损失函数, 上下文信息, ContextLoss

**Comment:** 13 pages, 7 figures, accepted to ICIP 2025

> **TL;DR:** 提出一种新的损失函数ContextLoss (CLoss)，通过考虑拓扑错误及其完整上下文来提高图像分割的拓扑正确性，并在多个数据集上表现出更好的性能，修复了更多连接。

**AI_Comments:** 这项工作通过引入“上下文信息”到损失函数中，为拓扑保持分割提供了一个新颖且有效的解决方案。其创新点在于强调了拓扑错误周围的完整上下文对于网络学习的重要性，这比单纯关注骨架信息更为全面。实验结果表明，该方法在修复遗漏连接方面表现出色，对于需要高拓扑精度的应用（如医学图像分析、地理信息系统）具有重要意义。代码的公开也促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 在图像分割中，保持血管、膜、道路等结构的拓扑结构至关重要，因为拓扑错误（例如在路网中）会严重影响实际应用如导航。

**Method:** 本文提出了一种名为ContextLoss (CLoss) 的新型损失函数，它通过在关键像素掩码中考虑拓扑错误及其完整的上下文信息来提高拓扑正确性。这种额外的上下文有助于网络更专注于拓扑错误。此外，文章还提出了两种直观的度量指标来验证因修复遗漏连接而改进的连通性。

**Result:** 在三个公共数据集（2D和3D）以及一个自有的3D骨水泥线纳米成像数据集上进行基准测试表明，使用ContextLoss (CLoss) 进行训练可以提高拓扑感知度量上的性能，并且比其他最先进的方法多修复高达44%的遗漏连接。

**Conclusion:** ContextLoss通过引入拓扑错误的完整上下文信息，显著提高了图像分割的拓扑正确性，并在修复遗漏连接方面表现出优越的性能，是拓扑保持分割的有效方法。

> **ai_Abstract:** 本文提出了一种名为ContextLoss (CLoss) 的新型损失函数，旨在解决图像分割中拓扑结构难以保持的问题。CLoss通过在关键像素掩码中纳入拓扑错误及其完整的上下文信息，增强了模型对拓扑错误的关注，从而提高了分割的拓扑正确性。作者还引入了两种新的度量指标来评估连通性改进。在多个2D和3D公共数据集以及一个私有数据集上的实验结果表明，CLoss显著提升了拓扑感知度量性能，并能比现有最先进方法多修复高达44%的遗漏连接。代码已公开。

> **摘要翻译:** 在图像分割中，保持血管、膜或道路等分割结构的拓扑结构至关重要。例如，路网上的拓扑错误会严重影响导航。最近提出的解决方案是基于关键像素掩码的损失函数，这些函数在关键像素掩码中考虑了分割结构的整个骨架。我们提出了一种新颖的损失函数ContextLoss (CLoss)，通过在关键像素掩码中考虑拓扑错误及其完整的上下文信息来提高拓扑正确性。额外的上下文信息改善了网络对拓扑错误的关注。此外，我们提出了两种直观的度量标准来验证由于遗漏连接的闭合而改进的连通性。我们在三个公共数据集（2D和3D）以及我们自己的骨水泥线3D纳米成像数据集上对我们提出的CLoss进行了基准测试。使用我们提出的CLoss进行训练可以提高拓扑感知度量上的性能，并且比其他最先进的方法多修复高达44%的遗漏连接。我们公开了代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [197] [BrainMAP: Multimodal Graph Learning For Efficient Brain Disease Localization](https://arxiv.org/abs/2506.11178)
> *BrainMAP: 多模态图学习用于高效脑疾病定位*

*Nguyen Linh Dan Le, Jing Ren, Ciyuan Peng, Chengyao Xie, Bowen Li, Feng Xia* | **Main category: cs.CV**

**Keywords:** 脑疾病定位, 多模态图学习, 神经退行性疾病, 计算效率, fMRI, DTI

**Comment:** 6 pages, 5 figures

> **TL;DR:** BrainMAP是一种新型多模态图学习框架，通过关注疾病相关子图并融合fMRI和DTI数据，实现高效且准确的脑疾病区域定位。

**AI_Comments:** BrainMAP的创新点在于其结合了图谱驱动的子图过滤以提高计算效率，以及先进的多模态融合策略（跨节点注意力和自适应门控）来整合不同脑成像数据。这对于在资源受限设备上实现脑疾病的精确和高效定位具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图的学习方法在定位和提取脑疾病驱动区域方面不足，且多模态脑图模型计算复杂度高，限制了其在资源受限设备上的实际应用。

**Method:** BrainMAP首先利用AAL图谱驱动的过滤方法提取关键脑子图，相比现有方法减少超过50%的计算开销。其次，采用先进的多模态融合过程，包括跨节点注意力机制对fMRI和DTI数据进行对齐，并结合自适应门控机制动态融合这些模态。

**Result:** 实验结果表明，BrainMAP在计算效率上优于现有最先进的方法，同时不影响预测准确性。

**Conclusion:** BrainMAP提供了一种高效且准确的脑疾病区域定位解决方案，解决了现有方法的计算效率和定位不足问题。

> **ai_Abstract:** BrainMAP是一个创新的多模态图学习框架，旨在解决现有方法在神经退行性疾病定位和计算效率方面的不足。它通过AAL图谱驱动的子图提取显著降低计算开销，并利用跨节点注意力和自适应门控机制高效融合fMRI和DTI数据。实验证明BrainMAP在保持高预测准确性的同时，显著提高了计算效率。

> **摘要翻译:** 近年来，利用图学习技术检测神经退行性疾病的研究激增。然而，现有的基于图的方法通常缺乏在完整连接组中定位和提取驱动神经退行性病理学特定脑区域的能力。此外，最近关于多模态脑图模型的工作常常面临高计算复杂度，这限制了它们在资源受限设备中的实际应用。在本研究中，我们提出了BrainMAP，一个新颖的多模态图学习框架，旨在精确且计算高效地识别受神经退行性疾病影响的脑区域。首先，BrainMAP利用由AAL图谱引导的图谱驱动过滤方法来精确定位和提取关键脑子图。与建模整个脑网络的最新方法不同，BrainMAP通过专注于疾病相关的子图，实现了超过50%的计算开销减少。其次，我们采用先进的多模态融合过程，包括用于对齐功能磁共振成像（fMRI）和弥散张量成像（DTI）数据的跨节点注意力机制，以及用于动态融合和整合这些模态的自适应门控机制。实验结果表明，BrainMAP在计算效率上优于现有最先进的方法，同时不影响预测准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [209] [JAFAR: Jack up Any Feature at Any Resolution](https://arxiv.org/abs/2506.11136)
> *JAFAR：在任意分辨率下提升任意特征*

*Paul Couairon, Loick Chambon, Louis Serrano, Jean-Emmanuel Haugeard, Matthieu Cord, Nicolas Thome* | **Main category: cs.CV**

**Keywords:** 特征上采样, 基础视觉编码器, 注意力机制, 空间特征变换, 高分辨率

**Comment:** Code available at https://github.com/PaulCouairon/JAFAR

> **TL;DR:** JAFAR是一种轻量级、灵活的特征上采样器，能将任何基础视觉编码器的特征提升到任意目标分辨率，且在无高分辨率监督下表现出色，有效恢复细粒度空间细节。

**AI_Comments:** JAFAR的创新之处在于其轻量级、灵活性以及在无高分辨率监督下实现高分辨率特征上采样的能力。通过注意力机制和SFT调制实现语义对齐，使其在处理不同分辨率特征时表现出色。其强大的泛化能力对于需要高分辨率输入的密集视觉任务具有重要意义，降低了对昂贵高分辨率监督数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 基础视觉编码器输出的低分辨率空间特征无法直接满足下游任务所需的高分辨率模态，因此需要有效的特征上采样方法。

**Method:** JAFAR采用基于注意力的模块，利用空间特征变换（SFT）调制，促进来自低级图像特征的高分辨率查询与语义丰富的低分辨率键之间的语义对齐。

**Result:** 在低上采样率和分辨率下学习的模型能够很好地泛化到显著更高的输出尺度，即使没有高分辨率监督。JAFAR能有效恢复细粒度空间细节，并在各种下游任务中持续优于现有特征上采样方法。

**Conclusion:** JAFAR是一个有效且通用的特征上采样器，能够弥补基础视觉编码器在分辨率上的不足，并在无高分辨率监督下实现卓越性能，提升了密集视觉任务的能力。

> **ai_Abstract:** 本文介绍了JAFAR，一个轻量级且灵活的特征上采样器，旨在解决基础视觉编码器输出特征分辨率不足的问题。JAFAR利用基于注意力的模块和空间特征变换（SFT）调制，将任意基础视觉编码器的特征提升到任意目标分辨率，并促进高低分辨率特征之间的语义对齐。实验证明，JAFAR在无高分辨率监督的情况下也能很好地泛化，有效恢复细粒度细节，并在多种下游任务中超越现有方法。

> **摘要翻译:** 基础视觉编码器已成为广泛的密集视觉任务中不可或缺的一部分。然而，它们低分辨率的空间特征输出需要特征上采样以生成下游任务所需的高分辨率模态。在这项工作中，我们引入了JAFAR，一个轻量级且灵活的特征上采样器，它可以将任何基础视觉编码器的视觉特征的空间分辨率提升到任意目标分辨率。JAFAR采用了一个基于注意力的模块，旨在促进高分辨率查询（源自低级图像特征）与语义丰富的低分辨率键之间的语义对齐，并使用空间特征变换（SFT）调制。值得注意的是，尽管没有高分辨率监督，我们证明了在低上采样率和分辨率下学习的模型可以非常出色地泛化到显著更高的输出尺度。广泛的实验表明，JAFAR有效地恢复了细粒度空间细节，并在各种下游任务中持续优于现有特征上采样方法。项目页面位于https://jafar-upsampler.github.io

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [239] [FARCLUSS: Fuzzy Adaptive Rebalancing and Contrastive Uncertainty Learning for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2506.11142)
> *FARCLUSS：半监督语义分割中的模糊自适应再平衡与对比不确定性学习*

*Ebenezer Tarubinga, Jenifer Kalafatovich* | **Main category: cs.CV**

**Keywords:** 半监督语义分割, 模糊伪标签, 不确定性学习, 类别再平衡, 对比正则化

**Comment:** Submitted to Pattern Recognition

> **TL;DR:** FARCLUSS是一个新的半监督语义分割框架，通过模糊伪标签、不确定性感知加权、自适应类别再平衡和对比正则化来有效利用未标记数据。

**AI_Comments:** FARCLUSS的创新之处在于其将不确定性视为学习资产的全面方法，通过模糊伪标签和不确定性感知加权，有效避免了传统严格阈值带来的信息损失。结合自适应类别再平衡和对比正则化，该框架不仅解决了半监督学习中的核心挑战（如伪标签质量、类别不平衡和特征区分度），还在实践中展现了对弱势类别和模糊区域的显著改进，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 半监督语义分割（SSSS）在有效利用未标记数据时面临挑战，包括伪标签利用效率低下、类别不平衡偏差加剧以及忽视预测不确定性。现有方法通常通过严格阈值丢弃不确定区域，偏向主导类别。

**Method:** 本文提出了一个名为FARCLUSS的整体框架，通过四个主要组成部分将不确定性转化为学习资产：1) 模糊伪标签，保留top-K预测的软类别分布以丰富监督；2) 不确定性感知动态加权，通过基于熵的可靠性分数调节像素级贡献；3) 自适应类别再平衡，动态调整损失以抵消长尾类别分布；4) 轻量级对比正则化，鼓励紧凑和有区分度的特征嵌入。

**Result:** 在基准测试中进行的广泛实验表明，该方法优于当前的最新方法，在未充分表示的类别和模糊区域的分割方面取得了显著改进。

**Conclusion:** FARCLUSS通过将不确定性转化为学习资产，有效解决了半监督语义分割中利用未标记数据、类别不平衡和不确定性处理的挑战，并显著提升了分割性能，尤其是在弱势类别和模糊区域。

> **ai_Abstract:** 本文提出了FARCLUSS，一个用于半监督语义分割的框架，旨在解决现有方法在利用未标记数据时遇到的伪标签无效、类别不平衡和忽视不确定性等问题。FARCLUSS通过引入模糊伪标签、不确定性感知动态加权、自适应类别再平衡和轻量级对比正则化这四个核心组件，将不确定性转化为有用的学习信息。实验结果表明，该方法在多个基准测试上超越了现有SOTA方法，特别是在长尾类别和模糊区域的分割表现上取得了显著提升。

> **摘要翻译:** 半监督语义分割（SSSS）在有效利用未标记数据方面面临持续挑战，例如伪标签利用效率低下、类别不平衡偏差加剧以及忽视预测不确定性。当前方法通常通过严格的阈值处理来丢弃不确定区域，这偏向于主导类别。为了解决这些限制，我们引入了一个整体框架，通过四个主要组成部分将不确定性转化为学习资产：(1) 模糊伪标签，它保留了来自top-K预测的软类别分布，以丰富监督；(2) 不确定性感知动态加权，通过基于熵的可靠性分数调节像素级贡献；(3) 自适应类别再平衡，动态调整损失以抵消长尾类别分布；以及 (4) 轻量级对比正则化，它鼓励紧凑和有区分度的特征嵌入。在基准测试中进行的广泛实验表明，我们的方法优于当前的最新方法，在未充分表示的类别和模糊区域的分割方面取得了显著改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [On the development of an AI performance and behavioural measures for teaching and classroom management](https://arxiv.org/abs/2506.11143)
> *关于开发用于教学和课堂管理的AI表现和行为测量方法*

*Andreea I. Niculescu, Jochen Ehnen, Chen Yi, Du Jiawei, Tay Chiat Pin, Joey Tianyi Zhou, Vigneshwaran Subbaraju, Teh Kah Kuan, Tran Huy Dat, John Komar, Gi Soong Chee, Kenneth Kwok* | **Main category: cs.CV**

**Keywords:** AI教育分析, 课堂管理, 教师发展, 多模态数据, 行为测量

**Comment:** 7 pages, 10 figures, A video demonstration of the teacher trainer
  dashboard can be accessed here: https://vimeo.com/1076482827

> **TL;DR:** 该研究开发了基于AI的措施，利用多模态传感器数据分析课堂动态和教师行为，以支持教师发展并提供客观的课堂互动快照。

**AI_Comments:** 该研究的创新之处在于其利用多模态传感器数据和AI技术对课堂动态及教师行为进行客观、非评判性的分析，这对于传统的教师评估方式是一个重要补充。其在亚洲教育背景下的设计和测试，也使其方法论具有文化适用性。该系统能够减轻教师的评估负担，并促进其教学反思和改进，具有重要的实践意义。局限性可能在于其目前不提供绩效评级，以及对数据隐私和伦理的进一步考量。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发AI驱动的测量方法，以分析课堂动态，特别是通过多模态传感器数据捕捉的教师行为，从而支持教师发展并提供客观的课堂互动快照，帮助教师识别和改进教学策略。

**Method:** 该研究是一个为期两年的项目，利用课堂传感器捕获的实时多模态数据（特别是音频-视觉数据）和AI技术来提取有意义的洞察。它开发了新颖的行为测量方法，并创建了一个概念验证的教学回顾仪表板。在亚洲教育背景下设计和测试。

**Result:** 主要成果包括一个整理好的音频-视觉数据集、新颖的行为测量方法和一个概念验证的教学回顾仪表板。初步评估显示系统清晰、可用，且采用非评判性的自动化分析方法，减少了手动工作量并鼓励建设性反思。系统提供了课堂互动的客观快照。

**Conclusion:** 该系统通过提供课堂互动的客观快照，帮助教师识别和改进教学策略，并以非评判性的自动化分析方法减少了手动工作量。该工作还贡献了一种根植于亚洲文化背景的AI教育分析方法。

> **ai_Abstract:** 本文介绍了一项为期两年的研究，旨在开发基于AI的课堂动态和教师行为分析工具。通过处理多模态传感器数据，该系统生成了新的行为测量指标和一个教学回顾仪表板。初步评估显示其清晰、易用且能提供客观的课堂互动快照，有助于教师自我反思和改进教学，同时减少人工工作量。该研究在亚洲教育背景下进行，并提供了一种文化适用的AI教育分析方法。

> **摘要翻译:** 本文介绍了一个为期两年的研究项目，该项目专注于开发AI驱动的测量方法，以分析课堂动态，特别强调通过多模态传感器数据捕获的教师行为。我们应用来自课堂传感器的实时数据和AI技术来提取有意义的洞察并支持教师发展。主要成果包括一个整理好的音频-视觉数据集、新颖的行为测量方法，以及一个概念验证的教学回顾仪表板。对来自国立教育学院（NIE）的八名研究人员进行的初步评估突出了该系统的清晰性、可用性及其非评判性、自动化分析方法——这减少了手动工作量并鼓励建设性反思。尽管当前版本不分配绩效评级，但它提供了课堂互动的客观快照，帮助教师识别和改进他们的教学策略。这项工作在亚洲教育背景下设计和测试，也为日益增长的基于AI的教育分析领域贡献了一种根植于文化的方法论。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [271] [AlignHuman: Improving Motion and Fidelity via Timestep-Segment Preference Optimization for Audio-Driven Human Animation](https://arxiv.org/abs/2506.11144)
> *AlignHuman：通过时间步分段偏好优化改进音频驱动人体动画的运动和保真度*

*Chao Liang, Jianwen Jiang, Wang Liao, Jiaqi Yang, Zerong zheng, Weihong Zeng, Han Liang* | **Main category: cs.CV**

**Keywords:** 人体动画, 偏好优化, 扩散模型, LoRA, 运动保真度

**Comment:** Homepage: https://alignhuman.github.io/

> **TL;DR:** AlignHuman提出了一种结合偏好优化和分治训练策略的框架，通过时间步分段偏好优化和专门的LoRA模块，同时优化人体动画的运动自然度和视觉保真度，并在推理过程中显著减少NFEs，提高速度。

**AI_Comments:** AlignHuman的创新点在于其对扩散模型去噪过程的精细化理解和应用，通过时间步分段偏好优化和专门的LoRA模块，巧妙地解决了运动自然度和视觉保真度的冲突。这种“分而治之”的策略在优化复杂多目标问题上具有借鉴意义，同时显著提升了推理效率，对于实时应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型在人体视频生成和动画任务中取得了显著进展，但由于运动自然度与视觉保真度之间的权衡，实现富有表现力和真实感的人体动画仍然具有挑战性。

**Method:** 我们提出了AlignHuman框架，它结合了偏好优化作为后训练技术和分治训练策略，以共同优化运动自然度和视觉保真度这两个相互竞争的目标。核心思想是分析去噪过程在不同时间步的作用：早期时间步主要控制运动动力学，而后期时间步可以有效管理保真度和人体结构。基于此，我们提出了时间步分段偏好优化（TPO），并引入了两个专门的LoRA模块作为专家对齐模块，每个模块针对其相应时间步间隔中的特定维度。这些LoRA模块使用各自的偏好数据进行训练，并在推理期间在相应的时间间隔内激活，以增强运动自然度和保真度。

**Result:** AlignHuman改进了强大的基线模型，并在推理过程中减少了NFEs，实现了3.3倍的速度提升（从100 NFEs到30 NFEs），同时对生成质量的影响最小。

**Conclusion:** AlignHuman通过创新的时间步分段偏好优化和专门的LoRA模块，成功地解决了人体动画中运动自然度和视觉保真度之间的权衡问题，显著提升了动画质量和推理速度。

> **ai_Abstract:** AlignHuman是一个新颖的框架，旨在通过结合偏好优化和分治训练策略，解决音频驱动人体动画中运动自然度和视觉保真度之间的权衡问题。它基于对扩散模型去噪过程的深入分析，提出了时间步分段偏好优化（TPO），并引入了两个专门的LoRA模块，分别在不同的时间步间隔内优化运动和保真度。实验证明，AlignHuman不仅提升了动画质量，还在推理速度上实现了显著的3.3倍加速，同时保持了生成质量。

> **摘要翻译:** 扩散模型驱动的人体视频生成和动画任务的最新进展取得了显著进步。然而，由于运动自然度和视觉保真度之间的权衡，富有表现力和真实感的人体动画仍然具有挑战性。为了解决这个问题，我们提出了AlignHuman，这是一个将偏好优化作为后训练技术与分治训练策略相结合的框架，以共同优化这些相互竞争的目标。我们的关键见解源于对跨时间步去噪过程的分析：（1）早期去噪时间步主要控制运动动力学，而（2）即使跳过早期步骤，保真度和人体结构也可以通过后期时间步有效管理。基于这一观察，我们提出了时间步分段偏好优化（TPO），并引入了两个专门的LoRA作为专家对齐模块，每个模块针对其相应时间步间隔中的特定维度。LoRA使用各自的偏好数据进行训练，并在推理期间在相应的时间间隔内激活，以增强运动自然度和保真度。大量实验表明，AlignHuman改进了强大的基线模型，并在推理过程中减少了NFEs，实现了3.3倍的速度提升（从100 NFEs到30 NFEs），同时对生成质量的影响最小。主页：https://alignhuman.github.io/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [282] [3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks](https://arxiv.org/abs/2506.11147)
> *3D-RAD：一个包含多时间分析和多样化诊断任务的综合3D放射学医学VQA数据集*

*Xiaotang Gai, Jiaxiang Liu, Yichen Li, Zijie Meng, Jian Wu, Zuozhu Liu* | **Main category: cs.CV**

**Keywords:** 3D医学VQA, 放射学, CT扫描, 多时间分析, 数据集

**Comment:** 

> **TL;DR:** 本文介绍了3D-RAD，一个大规模3D放射学医学VQA数据集，具有多样化的任务和多时间分析，突出了当前VLM的局限性，并发布了一个训练集以促进未来的研究。

**AI_Comments:** 该论文引入了一个重要的全新数据集（3D-RAD），通过专注于3D成像并整合对真实世界临床场景至关重要的复杂多时间分析，弥补了医学VQA领域的一个关键空白。其发布的大规模训练集（3D-RAD-T）为开发更强大的3D医学AI模型提供了宝贵的基准和资源。研究结果也突出了VLM在该领域当前的局限性，为未来的研究指明了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医学视觉问答（Med-VQA）工作主要集中在2D图像上，任务多样性有限；当前的模型在复杂的3D诊断推理，特别是多时间任务方面表现出局限性。

**Method:** 本文提出了3D-RAD，一个基于放射学CT扫描的大规模3D Med-VQA数据集。该数据集包含六种多样化的VQA任务（异常检测、图像观察、医学计算、存在检测、静态时间诊断和纵向时间诊断），支持开放式和封闭式问题，并引入了复杂的推理挑战。作者还发布了一个包含136,195个专家对齐样本的高质量训练集（3D-RAD-T）。

**Result:** 广泛的评估表明，现有的视觉语言模型（VLMs），特别是医学VLMs，泛化能力有限，尤其是在多时间任务中。在3D-RAD-T上进行微调可以显著提高模型性能。

**Conclusion:** 3D-RAD旨在推动多模态医学AI研究，并为3D医学视觉理解奠定坚实基础，同时揭示了当前模型在真实世界3D诊断推理方面的不足。

> **ai_Abstract:** 本文介绍了3D-RAD，一个新颖的大规模3D医学视觉问答（Med-VQA）数据集，该数据集基于放射学CT扫描构建，旨在解决现有2D医学图像数据集任务多样性有限的问题。3D-RAD包含六种不同的VQA任务，涵盖了复杂的计算和多时间分析挑战，并支持开放式和封闭式问题。评估结果显示，当前的视觉语言模型在3D诊断推理，特别是多时间任务上表现出局限性。为了促进该领域的发展，作者发布了大规模训练子集3D-RAD-T，并证明了在此数据集上进行微调可以显著提升模型性能。该数据集旨在推动多模态医学AI研究和3D医学视觉理解的进步。

> **摘要翻译:** 医学视觉问答（Med-VQA）在临床决策支持方面具有巨大潜力，但现有工作主要集中在2D成像上，任务多样性有限。本文提出了3D-RAD，一个旨在通过放射学CT扫描推进3D Med-VQA的大规模数据集。3D-RAD数据集包含六种多样化的VQA任务：异常检测、图像观察、医学计算、存在检测、静态时间诊断和纵向时间诊断。它支持开放式和封闭式问题，同时引入了复杂的推理挑战，包括计算任务和多阶段时间分析，以实现全面的基准测试。广泛的评估表明，现有的视觉语言模型（VLMs），特别是医学VLMs，泛化能力有限，尤其是在多时间任务中，这凸显了真实世界3D诊断推理的挑战。为了推动未来的发展，我们发布了一个包含136,195个专家对齐样本的高质量训练集3D-RAD-T，表明在该数据集上进行微调可以显著提高模型性能。我们的数据集和代码旨在促进多模态医学AI研究，并为3D医学视觉理解建立一个坚实的基础，可在https://github.com/Tang-xiaoxiao/M3D-RAD 公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [Digitization of Document and Information Extraction using OCR](https://arxiv.org/abs/2506.11156)
> *使用OCR的文档数字化与信息提取*

*Rasha Sinha, Rekha B S* | **Main category: cs.CV**

**Keywords:** OCR, LLM, 信息提取, 文档数字化, 文本处理

**Comment:** 

> **TL;DR:** 本文提出了一种结合OCR和大型语言模型（LLM）的文档信息提取框架，该方法在灵活性和语义精度方面优于传统方法。

**AI_Comments:** 该论文的创新之处在于将OCR技术与大型语言模型（LLMs）相结合，利用LLMs的上下文理解能力来提高信息提取的准确性和灵活性，超越了传统方法。这种混合方法有效地解决了处理扫描和数字文档时面临的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 从文档中准确提取信息是一项关键任务，尤其是在处理扫描图像和原生数字格式的混合文档时，面临挑战。

**Method:** 本文提出一个结合OCR技术与大型语言模型（LLMs）的文本提取框架。扫描文件通过OCR引擎处理，数字文件通过布局感知库解释。提取的原始文本由LLM分析以识别键值对并解决歧义。文中还对不同的OCR工具进行了比较分析，评估其准确性、布局识别和处理速度。

**Result:** 该方法比传统的基于规则和模板的方法有显著改进，在不同文档类别中提供增强的灵活性和语义精度。

**Conclusion:** 结合OCR和LLM的方法在文档信息提取方面优于传统方法，具有更高的灵活性和准确性，能够处理扫描和数字格式的文档。

> **ai_Abstract:** 本文提出了一种混合框架，用于文档信息提取，该框架将OCR技术用于扫描文档，将布局感知库用于数字文件，并结合大型语言模型（LLM）对提取的原始文本进行处理，以识别键值对并解决歧义，从而提供结构化输出。论文还对不同OCR工具的准确性、布局识别和处理速度进行了比较分析。实验表明，该方法比传统的基于规则和模板的方法在灵活性和语义精度方面有显著提高。

> **摘要翻译:** 从文档中检索准确的详细信息是一项关键任务，尤其是在处理扫描图像和原生数字格式的组合时。本文提出了一种结合光学字符识别（OCR）技术与大型语言模型（LLM）的文本提取组合框架，旨在提供富含上下文理解和置信度指标的结构化输出。扫描文件通过OCR引擎处理，而数字文件则通过布局感知库进行解释。提取的原始文本随后由LLM分析，以识别键值对并解决歧义。文中还对不同的OCR工具进行了比较分析，以评估它们在准确性、布局识别和处理速度方面的有效性。该方法相比传统的基于规则和基于模板的方法显示出显著改进，在不同文档类别中提供了增强的灵活性和语义精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [296] [LLM-to-Phy3D: Physically Conform Online 3D Object Generation with LLMs](https://arxiv.org/abs/2506.11148)
> *LLM-to-Phy3D：使用大型语言模型生成符合物理特性的在线3D对象*

*Melvin Wong, Yueming Lyu, Thiago Rios, Stefan Menzel, Yew-Soon Ong* | **Main category: cs.CV**

**Keywords:** 大型语言模型, 3D对象生成, 物理约束, 在线优化, 生成式设计

**Comment:** 

> **TL;DR:** LLM-to-Phy3D引入了一种在线黑盒优化循环，通过视觉和物理评估，使现有LLM-to-3D模型能够生成符合物理约束的3D对象，显著提高了物理性能。

**AI_Comments:** 这篇论文的创新之处在于其将大型语言模型与物理世界约束相结合，通过一个独特的在线黑盒优化循环，弥补了现有GenAI在生成物理可行3D对象方面的不足。这对于工程设计和物理AI领域具有重要意义，因为它使得AI生成的对象不再仅仅是视觉上的，而是能够满足实际物理需求的。其迭代优化和反馈机制是核心亮点，有望推动AI在实际应用中的边界。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM-to-3D模型缺乏物理知识，生成的3D对象往往脱离现实世界的物理约束，这限制了其在工程设计等需要物理可行性的人工智能应用中的潜力。

**Method:** 本文提出了LLM-to-Phy3D模型，它引入了一个新颖的在线黑盒优化循环，通过协同的视觉和基于物理的评估，为大型语言模型提供定向反馈。通过迭代优化过程，LLM-to-Phy3D主动发现能够生成具有增强物理性能和更大几何新颖性的3D工件的提示。

**Result:** 在车辆设计优化中的系统评估和消融研究表明，LLM-to-Phy3D在生成符合物理特性的目标领域3D设计方面，比传统LLM-to-3D模型取得了4.5%到106.7%的LLM改进。

**Conclusion:** LLM-to-Phy3D的鼓舞人心的结果表明其在物理AI领域，特别是科学和工程应用中，具有潜在的通用用途。

> **ai_Abstract:** 本文提出了LLM-to-Phy3D，一个旨在解决现有LLM-to-3D模型在生成符合物理约束的3D对象方面的不足。该模型通过引入一个新颖的在线黑盒优化循环，结合视觉和物理评估，为LLM提供迭代反馈，从而生成具有更高物理性能和几何新颖性的3D设计。实验结果显示，LLM-to-Phy3D在物理符合性方面比传统模型有显著提升，预示其在物理AI和工程设计领域有广泛应用潜力。

> **摘要翻译:** 生成式人工智能（GenAI）和大型语言模型（LLMs）的出现彻底改变了不同模态下数字内容创作的格局。然而，其在工程设计等物理人工智能（Physical AI）中的潜在用途仍未得到充分探索，而这些领域中物理上可行的产物至关重要。现有LLM-to-3D模型中物理知识的缺失，往往导致其输出脱离现实世界的物理约束。为了解决这一空白，我们引入了LLM-to-Phy3D，一种物理上符合要求的在线3D对象生成方法，它使现有的LLM-to-3D模型能够即时生成符合物理要求的3D对象。LLM-to-Phy3D引入了一种新颖的在线黑盒优化循环，通过协同的视觉和基于物理的评估来赋能大型语言模型（LLMs）。通过在迭代优化过程中提供定向反馈，LLM-to-Phy3D积极推动发现能够产生具有增强物理性能和相对于参考对象具有更大几何新颖性的3D工件的提示，这标志着对AI驱动的生成设计做出了重大贡献。在车辆设计优化中，通过消融研究支持的LLM-to-Phy3D系统评估表明，与传统LLM-to-3D模型相比，LLM在生成符合物理特性的目标领域3D设计方面获得了4.5%到106.7%的改进。这些令人鼓舞的结果表明LLM-to-Phy3D在科学和工程应用的物理AI中具有潜在的通用用途。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [309] [Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds](https://arxiv.org/abs/2506.11804)
> *远程驾驶：压缩点云中三维物体检测的新挑战*

*Filippo Bragato, Michael Neri, Paolo Testolina, Marco Giordani, Federica Battisti* | **Main category: cs.CV**

**Keywords:** 远程驾驶, 3D物体检测, 点云压缩, V2X通信, SELMA数据集

**Comment:** Submitted to IEEE Transactions on Intelligent Transportation Systems

> **TL;DR:** 研究远程驾驶中压缩点云的三维物体检测，评估了压缩算法和目标检测器的性能及其对V2X网络的影响。

**AI_Comments:** 本文关注远程驾驶这一新兴且重要的领域，并提出了压缩点云中3D物体检测的新挑战，具有较强的现实意义。通过扩展开源数据集SELMA并结合V2X通信网络的考量，使其研究更为全面和实用。论文的创新点在于将点云压缩与3D物体检测相结合，并从网络传输效率的角度进行评估，为未来远程驾驶系统的设计提供了宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，互联设备和传感器技术的发展加速了远程驾驶（TD）的应用。为了实现安全的TD操作，需要解决从点云数据中检测汽车和行人等物体的问题，特别是在V2X通信中数据传输的效率和准确性。

**Method:** 本文利用并扩展了SELMA数据集（一个多模态、开源、合成的自动驾驶数据集），以支持3D物体检测。研究分析了最先进的压缩算法和物体检测器在压缩效率、(解)压缩和推理时间以及检测精度等多项指标下的性能。此外，还测量了压缩和检测对V2X网络数据速率和延迟的影响，并与3GPP对TD应用的要求进行比较。

**Result:** 论文分析了最先进的压缩算法和目标检测器在远程驾驶应用中的性能，并测量了压缩和检测对V2X网络数据速率和延迟的影响。具体性能指标包括压缩效率、(解)压缩和推理时间、检测精度。

**Conclusion:** 论文解决了远程驾驶中从点云数据检测汽车和行人的问题，并通过分析压缩算法和目标检测器在V2X网络中的表现，为实现安全的TD操作提供了见解。

> **ai_Abstract:** 本文针对远程驾驶（TD）场景下，如何安全地从压缩点云数据中检测汽车和行人这一挑战进行了研究。作者利用并扩展了SELMA数据集，评估了当前先进的压缩算法和3D物体检测器在压缩效率、处理时间及检测精度等方面的表现。此外，研究还量化了压缩和检测过程对V2X网络数据速率和延迟的影响，并参照3GPP标准进行了评估，旨在为实现安全的远程驾驶操作提供技术支持。

> **摘要翻译:** 近年来，互联设备的发展在许多领域不断扩大，从信息娱乐到教育和工业应用。传感器数量的增加以及强大硬件和软件的可及性加速了这一趋势。远程驾驶（TD）是受益于这些进步的领域之一。在这种情况下，控制器利用车载传感器数据，并通过车联网（V2X）通信进行交换，从而安全地远程驾驶车辆。在这项工作中，我们解决了从点云数据中检测汽车和行人以实现安全TD操作的问题。更具体地说，我们利用了SELMA数据集，这是一个多模态、开源、合成的自动驾驶数据集，我们通过包含3D物体的真值边界框对其进行了扩展，以支持物体检测。我们分析了最先进的压缩算法和物体检测器在多项指标下的性能，包括压缩效率、(解)压缩和推理时间以及检测精度。此外，我们测量了压缩和检测对V2X网络数据速率和延迟的影响，并与3GPP对TD应用的要求进行比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [310] [Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels](https://arxiv.org/abs/2506.11151)
> *自校准脑机接口：无需标签即可对心理目标进行排序和恢复*

*Jonathan Grizou, Carlos de la Torre-Ortiz, Tuukka Ruotsalo* | **Main category: cs.CV**

**Keywords:** 自校准BCI, 心理目标恢复, 无标签学习, 脑电图, CURSOR

**Comment:** 10 pages, 4 figures, 11 appendix pages, 7 appendix figures

> **TL;DR:** 本文提出了CURSOR，一个无需标签或预训练解码器即可从脑电图和图像数据中恢复用户心理目标（如人脸图像）的自校准框架和算法。实验证明CURSOR能预测图像相似度、对刺激进行排序并生成与心理目标难以区分的新刺激。

**AI_Comments:** 该论文的创新之处在于提出了首个无需标签数据和预训练解码器即可恢复心理目标的自校准脑机接口（BCI）框架CURSOR。这极大地扩展了BCI的应用范围，特别是在数据标注成本高昂或难以获取的场景。其在预测图像相似度、刺激排序和生成新刺激方面的能力，为未来无监督BCI系统的发展奠定了基础。通过用户研究验证了生成刺激的有效性，增加了研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在有标签数据的情况下探索了从脑电图和图像数据中恢复心理目标的问题，但尚未通过自校准方式（即无标签数据）进行探索。本文旨在解决在无标签信息的情况下，从配对的脑电图和图像数据中恢复用户心理目标的问题。

**Method:** 本文提出了首个自校准框架和算法CURSOR。该算法无需访问标记数据或预训练解码器，即可学习恢复未知的心理目标。实验在人脸的自然图像上进行。

**Result:** CURSOR能够：1) 在没有任何标签信息的情况下预测与人类感知判断相关的图像相似度分数；2) 利用这些分数根据未知心理目标对刺激进行排序；3) 生成与未知心理目标无法区分的新刺激（通过N=53的用户研究验证）。

**Conclusion:** CURSOR算法成功地在没有标签数据的情况下，实现了对心理目标的恢复、排序和生成新刺激，验证了自校准脑机接口在无监督场景下的潜力。

> **ai_Abstract:** 本文提出了一种名为CURSOR的创新自校准框架和算法，旨在解决在缺乏标签数据的情况下从脑电图和图像数据中恢复用户心理目标（如人脸图像）的挑战。与以往依赖标签数据的方法不同，CURSOR无需预训练解码器或任何标签信息即可运行。实验结果表明，CURSOR能够准确预测图像相似度、对刺激进行排序，并生成与用户心理目标高度一致的新刺激，这在无监督脑机接口领域具有重要意义。

> **摘要翻译:** 我们考虑了在交互会话期间收集的配对脑电图（即大脑反应）和图像（即感知到的面孔）数据中，在无法获取标签信息的情况下，恢复参与者心中所想的心理目标（例如，一张人脸图像）的问题。这个问题以前在有标签数据的情况下被探索过，但从未通过自校准方式（即无标签数据不可用）进行探索。在此，我们提出了第一个框架和算法CURSOR，它无需访问标签数据或预训练解码器，即可学习恢复未知的心理目标。我们对人脸自然图像进行的实验表明，CURSOR能够 (1) 在没有任何标签信息的情况下预测与人类感知判断相关的图像相似度分数，(2) 使用这些分数根据未知心理目标对刺激进行排序，以及 (3) 生成与未知心理目标难以区分的新刺激（通过N=53的用户研究验证）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [SLRNet: A Real-Time LSTM-Based Sign Language Recognition System](https://arxiv.org/abs/2506.11154)
> *SLRNet：一个基于LSTM的实时手语识别系统*

*Sharvari Kamble* | **Main category: cs.CV**

**Keywords:** 手语识别, LSTM, 实时系统, ASL, MediaPipe Holistic

**Comment:** 9 pages, 5 figures, includes experimental results. Code available at:
  https://github.com/Khushi-739/SLRNet

> **TL;DR:** SLRNet是一个基于MediaPipe Holistic和LSTM的实时网络摄像头ASL识别系统，验证准确率为86.7%，展示了包容性、硬件无关手语识别的可行性。

**AI_Comments:** 该论文提出了一种实用的实时手语识别系统SLRNet，其创新点在于结合了MediaPipe Holistic进行姿态估计和LSTM网络进行序列识别。系统的硬件无关性以及对字母和功能词的识别能力是其重要优势，有助于促进听障人士的交流。其86.7%的准确率也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 手语识别（SLR）在弥合听障社区与社会之间的沟通鸿沟方面发挥着至关重要的作用。

**Method:** 本文介绍了SLRNet，一个使用MediaPipe Holistic和长短期记忆（LSTM）网络的实时基于网络摄像头的ASL识别系统。该模型处理视频流以识别ASL字母和功能词。

**Result:** SLRNet的验证准确率为86.7%。

**Conclusion:** SLRNet展示了包容性、硬件独立手语识别的可行性。

> **ai_Abstract:** SLRNet是一个利用MediaPipe Holistic和LSTM网络构建的实时网络摄像头ASL识别系统。该系统能够处理视频流以识别ASL字母和功能词，并取得了86.7%的验证准确率。研究结果表明，这种方法在实现包容性和硬件独立的手语识别方面是可行的。

> **摘要翻译:** 手语识别（SLR）在弥合听障社区与社会之间的沟通鸿沟方面发挥着至关重要的作用。本文介绍了SLRNet，一个使用MediaPipe Holistic和长短期记忆（LSTM）网络的实时基于网络摄像头的ASL识别系统。该模型处理视频流以识别ASL字母和功能词。SLRNet的验证准确率为86.7%，展示了包容性、硬件独立手语识别的可行性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [325] [Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search](https://arxiv.org/abs/2506.11155)
> *通过蒙特卡洛树搜索评估多模态大语言模型在视频字幕生成上的表现*

*Linhao Yu, Xinguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong* | **Main category: cs.CV**

**Keywords:** 视频字幕, 多模态大语言模型, 蒙特卡洛树搜索, 视频理解, 评估基准

**Comment:** 28 pages; ACL 2025(main)

> **TL;DR:** 本文提出了AutoCaption框架，利用蒙特卡洛树搜索自动生成多样化视频描述，以更全面地评估多模态大语言模型的视频字幕能力，并构建了MCTS-VCB基准。

**AI_Comments:** 本文创新性地将蒙特卡洛树搜索应用于视频字幕的自动生成，解决了现有评估基准数据不足和同质化的问题。AutoCaption框架不仅提供了一种成本效益高的数据生成方法，还通过构建细粒度的MCTS-VCB基准，实现了对多模态大语言模型视频理解能力的更全面、更深入的评估。其对模型微调的有效性也进一步证明了所生成数据的价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频字幕评估基准存在关键问题，如关键点生成不足或同质化、数据创建成本过高以及评估范围有限，导致无法充分评估多模态大语言模型的视频理解能力。

**Method:** 提出AutoCaption自动化框架，该框架利用蒙特卡洛树搜索（MCTS）迭代构建大量多样化的描述性句子（即关键点），以彻底代表视频内容。这种迭代字幕生成策略能够持续增强视频细节。基于此，构建了MCTS-VCB细粒度视频字幕基准。

**Result:** MCTS-VCB能够有效且全面地评估视频字幕能力，其中Gemini-1.5-Pro取得了71.2的最高F1分数。使用AutoCaption生成的数据对InternVL2.5-8B进行微调，使其在MCTS-VCB上整体性能提升25.0%，在DREAM-1K上提升16.3%。

**Conclusion:** AutoCaption框架及其生成的MCTS-VCB基准能有效且全面地评估多模态大语言模型在视频字幕任务上的性能，并能通过生成的数据有效提升模型的视频理解能力。

> **ai_Abstract:** 本文提出AutoCaption框架，利用蒙特卡洛树搜索（MCTS）自动化生成多样且细致的视频描述，旨在解决现有视频字幕评估基准的不足。该框架通过迭代方式增强视频细节，并据此构建了MCTS-VCB细粒度视频字幕基准，实现了对多模态大语言模型（MLLMs）视频理解能力的全面评估。实验结果表明，MCTS-VCB能有效评估MLLMs，其中Gemini-1.5-Pro表现最佳。此外，通过AutoCaption生成的数据对模型进行微调，显著提升了模型性能，证明了该框架的有效性。

> **摘要翻译:** 视频字幕生成可用于评估多模态大语言模型（MLLMs）的视频理解能力。然而，现有的基准和评估协议存在关键问题，例如关键点创建不足或同质化、数据创建成本过高以及评估范围有限。为了解决这些问题，我们提出了一个名为AutoCaption的自动化框架，该框架利用蒙特卡洛树搜索（MCTS）以迭代方式构建大量多样化的描述性句子（即关键点），以彻底代表视频内容。这种迭代字幕生成策略能够持续增强视频细节，例如动作、物体属性、环境细节等。我们应用AutoCaption来策划MCTS-VCB，这是一个涵盖视频细节的细粒度视频字幕基准，从而能够对MLLMs在视频字幕任务上进行全面评估。我们在MCTS-VCB上评估了20多个不同大小的开源和闭源MLLMs。结果表明，MCTS-VCB可以有效且全面地评估视频字幕能力，其中Gemini-1.5-Pro取得了71.2的最高F1分数。有趣的是，我们使用AutoCaption生成的数据对InternVL2.5-8B进行了微调，这有助于该模型在MCTS-VCB上实现25.0%的整体提升，在DREAM-1K上实现16.3%的提升，进一步证明了AutoCaption的有效性。代码和数据可在https://github.com/tjunlp-lab/MCTS-VCB获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [335] [Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation](https://arxiv.org/abs/2506.11777)
> *通过在线聚类蒸馏进行超声心动图视频表示的自监督学习*

*Divyanshu Mishra, Mohammadreza Salehi, Pramit Saha, Olga Patey, Aris T. Papageorghiou, Yuki M. Asano, J. Alison Noble* | **Main category: cs.CV**

**Keywords:** 自监督学习, 超声心动图, 视频表示学习, 聚类蒸馏, 医学影像

**Comment:** 

> **TL;DR:** DISCOVR是一种新的自监督双分支框架，用于心脏超声视频表示学习，它结合了聚类视频编码器和在线图像编码器，通过语义聚类蒸馏损失，在六个超声心动图数据集上优于现有方法并实现卓越的分割迁移。

**AI_Comments:** DISCOVR的创新之处在于其双分支架构和语义聚类蒸馏损失，这有效地解决了超声心动图数据特有的挑战，如高样本相似性和低PSNR输入。通过结合时间动态和精细空间语义，该方法为医学影像领域的自监督学习提供了新的视角，并展现出在多任务上的强大泛化能力。其在零样本和迁移学习设置下的优异表现，凸显了其在实际临床应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自监督学习在自然图像和视频理解方面取得了进展，但在超声心动图等领域仍面临挑战，原因包括解剖结构细微、时间动态复杂以及缺乏特定领域预训练模型。现有自监督学习方法在处理样本间高相似性、低信噪比输入敏感性或过度增强导致临床特征失真方面存在困难。

**Method:** 本文提出了DISCOVR（通过蒸馏图像监督进行跨模态视频表示），一个用于心脏超声视频表示学习的自监督双分支框架。DISCOVR结合了一个建模时间动态的基于聚类的视频编码器和一个提取精细空间语义的在线图像编码器。这两个分支通过语义聚类蒸馏损失连接，该损失将解剖知识从演变的图像编码器传递到视频编码器，从而实现具有精细语义理解的时间连贯表示。

**Result:** DISCOVR在涵盖胎儿、儿童和成人人群的六个超声心动图数据集上进行了评估，在零样本和线性探测设置中优于专门的视频异常检测方法和最先进的视频自监督学习基线，并实现了卓越的分割迁移。

**Conclusion:** DISCOVR有效解决了超声心动图领域自监督学习的挑战，通过结合时间动态建模和精细空间语义提取，生成了高质量的视频表示，并在多项任务和数据集上取得了优异性能。

> **ai_Abstract:** 本文提出了一种名为DISCOVR的自监督双分支框架，用于学习心脏超声视频表示。针对超声心动图领域自监督学习面临的挑战，如解剖结构细微、时间动态复杂和缺乏领域模型等，DISCOVR结合了聚类视频编码器和在线图像编码器。通过语义聚类蒸馏损失，该模型能够将精细的空间语义知识传递给视频编码器，从而生成时间连贯且富含语义的视频表示。在六个超声心动图数据集上的评估表明，DISCOVR在零样本和线性探测设置下优于现有方法，并实现了卓越的分割迁移能力。

> **摘要翻译:** 自监督学习（SSL）在自然图像和视频理解方面取得了重大进展，但由于解剖结构细微、复杂的时间动态以及当前缺乏领域特定的预训练模型，超声心动图（心脏超声）等领域仍面临挑战。现有的自监督学习方法，如对比学习、掩蔽建模和基于聚类的方法，难以解决样本间高相似性、对超声中常见的低信噪比输入敏感或过度增强扭曲临床相关特征的问题。我们提出了DISCOVR（Distilled Image Supervision for Cross Modal Video Representation），一个用于心脏超声视频表示学习的自监督双分支框架。DISCOVR结合了一个基于聚类的视频编码器，该编码器建模时间动态，以及一个提取精细空间语义的在线图像编码器。这些分支通过语义聚类蒸馏损失连接，该损失将解剖知识从演变的图像编码器传递到视频编码器，从而实现具有精细语义理解的时间连贯表示。DISCOVR在涵盖胎儿、儿童和成人人群的六个超声心动图数据集上进行了评估，在零样本和线性探测设置中优于专门的视频异常检测方法和最先进的视频SSL基线，并实现了卓越的分割迁移。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [340] [VIBE: Can a VLM Read the Room?](https://arxiv.org/abs/2506.11162)
> *VIBE：VLM 能否理解社交情境？*

*Tania Chakraborty, Eylon Caplan, Dan Goldwasser* | **Main category: cs.CV**

**Keywords:** VLM, 社交推理, 视觉社交语用推理, 数据集, 基准测试

**Comment:** Pre-print, under review

> **TL;DR:** 本文探讨了视觉语言模型（VLMs）在社交推理方面的能力，并指出了一个此前被忽视的局限性：视觉社交语用推理（Visual Social-Pragmatic Inference）差距。为解决此问题，我们提出了一项新的任务，并构建了一个高质量数据集来测试VLMs在此任务上的表现，并对多种VLM进行了基准测试。

**AI_Comments:** 本文识别了一个在VLM研究中被忽视的重要领域——视觉社交语用推理，并为此提出了一个新的任务和数据集，这对于推动VLM在更复杂、更贴近人类社会行为理解方面的发展具有重要意义。其创新之处在于明确指出了VLM在非语言社交线索理解上的不足，并提供了具体的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 理解人类社交行为，如识别情绪及其背后的社会动态，是一个重要且具挑战性的问题。尽管大型语言模型（LLMs）取得了显著进展，但它们仅限于文本领域，无法解释非语言线索在理解社交情境中的重要作用。视觉语言模型（VLMs）有潜力弥补这一空白，但其对社交线索进行正确推断的能力却鲜受关注。

**Method:** 本文旨在探索VLM在社交推理方面的能力。我们识别了一个先前被忽视的VLM局限性：视觉社交语用推理（Visual Social-Pragmatic Inference）差距。为了解决这一差距，我们提出了一项针对VLM的新任务：视觉社交语用推理。我们构建了一个高质量数据集来测试VLM在此任务上的能力，并对多个VLM的性能进行了基准测试。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了视觉语言模型（VLMs）在理解人类社交行为和进行社交推理方面的潜力。研究指出，尽管大型语言模型（LLMs）在文本领域表现出色，但它们无法处理非语言线索，而VLM可能弥补这一缺陷。作者识别了VLM在社交理解中的一个“视觉社交语用推理”差距，并为此提出了一项新的VLM任务。为评估VLM在此任务上的能力，研究构建了一个高质量数据集，并在此数据集上对多种VLM进行了基准测试。

> **摘要翻译:** 理解人类社交行为，例如识别情绪以及导致这些情绪的社会动态，是一个重要且具有挑战性的问题。尽管大型语言模型（LLMs）取得了显著进展，但它们局限于文本领域，无法解释非语言线索在理解社交情境中扮演的重要角色。视觉语言模型（VLMs）有可能弥补这一空白，然而它们对这些社交线索进行正确推断的能力却很少受到关注。在本文中，我们探索了VLM在社交推理方面的能力。我们识别了一个VLM中先前被忽视的局限性：视觉社交语用推理差距。为了解决这一差距，我们为VLM提出了一项新任务：视觉社交语用推理。我们构建了一个高质量数据集来测试VLM在此任务上的能力，并对多个VLM的性能进行了基准测试。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [348] [Synthetic Geology -- Structural Geology Meets Deep Learning](https://arxiv.org/abs/2506.11164)
> *合成地质学——构造地质学与深度学习的结合*

*Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber* | **Main category: cs.CV**

**Keywords:** 合成地质学, 深度学习, 地下成像, 生成式AI, 地质建模

**Comment:** 10 pages, 8 figures, submitted to "Communications Earth &
  Environment", geological simulation code at
  https://doi.org/10.5281/zenodo.15244035, generative AI code at
  https://github.com/chipnbits/flowtrain_stochastic_interpolation/releases/tag/v1.0.0

> **TL;DR:** 本文提出了一种结合生成式AI和合成数据生成器的方法，用于通过深度学习可视化地球地下三维结构，以解决地下数据稀缺的问题，并展示了其在生成地质图像方面的潜力。

**AI_Comments:** 本文的创新之处在于通过构建一个复杂的合成数据生成器，巧妙地解决了地球地下成像领域长期存在的真实数据稀缺问题，从而使数据驱动的深度学习模型能够应用于这一传统上受数据获取限制的领域。其重要性在于，它为地球科学和工程中的各种应用提供了强大的工具，有望彻底改变地下特征描述的方式。潜在的局限性可能在于合成数据对极其复杂真实地质特征的模拟精度，但论文也指出可以通过真实数据进行微调。

<details>
  <summary>Details</summary>

**Motivation:** 可视化地球地下前几公里的结构是一个长期存在的挑战，对许多重要应用至关重要，但地下数据的可用性是瓶颈。本文旨在通过深度学习和合成数据生成来解决这一数据稀缺问题。

**Method:** 本文构建于应用于体素化图像的生成式人工智能技术。通过训练神经网络，将地表地质数据和钻孔数据扩展到三维地下区域。核心方法是设计了一个合成数据生成器，模拟数亿年的地质活动（如沉积物压实、火山侵入和构造动力学），以产生几乎无限量的近岩石圈样本。一个基于生成流匹配（generative flow matching）训练的、使用这些合成数据的基础模型能够从以前未见的地表地形和地质图生成三维地下图像。

**Result:** 一个在合成数据上训练的基础模型能够从以前未见的地表地形和地质图生成地下的三维图像，并且随着钻孔数据的增加，图像的保真度也随之提高，能够描绘出层、断层、褶皱、岩脉和岩床等结构。本文展示了合成岩石圈生成器与训练好的神经网络模型结合的早期前景。

**Conclusion:** 合成岩石圈生成器与训练好的神经网络模型相结合，显示出早期潜力。最终，此类模型将在适用的活动（如特定区域的矿产勘探）数据上进行微调，并可作为传统逆问题应用中的基于AI的正则化器，其目标函数表示附加数据与物理模型的不匹配，应用于资源勘探、灾害评估和岩土工程。

> **ai_Abstract:** 本文提出了“合成地质学”，一种结合深度学习和生成式AI来解决地球地下三维可视化挑战的新方法。针对地下数据稀缺的瓶颈，作者设计了一个创新的合成数据生成器，能模拟地质过程以产生海量的近岩石圈数据。在此合成数据上训练的神经网络模型，能够从地表地质图生成高保真度的三维地下图像，并随钻孔数据增加而提高准确性。该方法在资源勘探、灾害评估和岩土工程等领域具有广阔应用前景，并可作为传统逆问题中的AI正则化器。

> **摘要翻译:** 可视化地球地下前几公里的结构是一个长期存在的挑战，阻碍了几乎取之不尽的重要应用，而现在通过深度学习正变得触手可及。基于应用于体素化图像的生成式人工智能技术，我们展示了一种通过训练神经网络，将地表地质数据与钻孔数据相结合，扩展到三维地下区域的方法。地球陆地面积的地质特征已被广泛测绘，而这种或任何相关技术的瓶颈在于地下数据的可用性。我们通过设计一个合成数据生成器过程来弥补地下深度学习中的数据空白，该过程模拟了亿万年的地质活动，如沉积物压实、火山侵入和构造动力学，以生成几乎无限量的近岩石圈样本。一个在此类合成数据上训练的基础模型能够从以前未见的地表地形和地质图生成地下的三维图像，并且随着钻孔数据的增加，保真度也随之提高，能够描绘出层、断层、褶皱、岩脉和岩床等结构。我们利用生成流匹配（generative flow matching）展示了合成岩石圈生成器与训练好的神经网络模型相结合的早期前景。最终，此类模型将在适用的活动（如特定区域的矿产勘探）数据上进行微调。尽管其本身有用，但区域性微调的模型可能不作为目的，而作为一种手段：在更传统的逆问题应用中，作为基于AI的正则化器，其中目标函数表示附加数据与物理模型的不匹配，应用于资源勘探、灾害评估和岩土工程。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [Wi-CBR: WiFi-based Cross-domain Behavior Recognition via Multimodal Collaborative Awareness](https://arxiv.org/abs/2506.11616)
> *Wi-CBR: 基于WiFi的多模态协同感知跨域行为识别*

*Ruobei Zhang, Shengeng Tang, Huan Yan, Xiang Zhang, Richang Hong* | **Main category: cs.CV**

**Keywords:** WiFi行为识别, 多模态协同感知, 相位数据, 多普勒频移, 跨域识别

**Comment:** 

> **TL;DR:** Wi-CBR是一种基于WiFi的多模态协同感知方法，通过融合相位和多普勒频移数据，提升了跨域行为识别的准确性。

**AI_Comments:** 该论文创新性地将相位和多普勒频移两种WiFi信号特征进行多模态协同感知，并通过复杂的注意力机制和门控机制实现深度融合，有效解决了单一模态信息不足和跨域识别的挑战。其提出的PD-strengthen和PD-weaken分支设计尤其值得关注，有望为未来多模态融合研究提供新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于WiFi的人体行为识别方法通常只关注单一类型数据，忽视了多特征的交互和融合，导致识别精度受限。

**Method:** 提出Wi-CBR方法，利用相位数据（反映动态路径长度变化）和多普勒频移（DFS）数据（对应手势运动速度的频率变化）。具体包括：1. 引入双分支自注意力模块捕获每种模态内的时空线索。2. 应用组注意力机制于拼接后的相位和DFS特征，挖掘关键组特征。3. 通过门控机制将组合特征分为PD-strengthen和PD-weaken分支，优化信息熵并促进跨模态协同感知。

**Result:** 在Widar3.0和XRF55两个大型公开数据集上的域内和跨域实验表明，所提出的方法性能优越。

**Conclusion:** 本文提出的Wi-CBR方法通过有效融合多模态WiFi信号特征，显著提升了基于WiFi的跨域行为识别准确性。

> **ai_Abstract:** Wi-CBR是一种新颖的基于WiFi的多模态协同感知方法，旨在解决现有行为识别方法忽略多特征交互融合的问题。它创新性地利用相位和多普勒频移数据，通过引入双分支自注意力模块捕获模态内时空线索，接着使用组注意力机制挖掘关键特征，并通过门控机制将特征分为PD-strengthen和PD-weaken分支，优化信息熵并促进跨模态协同感知。实验证明，该方法在域内和跨域行为识别任务上均表现出卓越性能。

> **摘要翻译:** 基于WiFi的人体行为识别旨在通过分析无线信号变化来识别手势和活动。然而，现有方法通常只关注单一类型数据，忽视了多特征的交互和融合。为此，我们提出了一种新颖的多模态协同感知方法。通过利用反映动态路径长度变化的相位数据和对应手势运动速度频率变化的多普勒频移（DFS）数据，我们实现了这些特征的有效交互和融合，以提高识别精度。具体而言，我们首先引入了一个双分支自注意力模块，以捕获每种模态内的时空线索。然后，将组注意力机制应用于拼接后的相位和DFS特征，以挖掘对行为识别至关重要的关键组特征。通过门控机制，组合特征进一步分为PD-strengthen和PD-weaken分支，从而优化信息熵并促进跨模态协同感知。在两个大型公开数据集Widar3.0和XRF55上进行的广泛域内和跨域实验，证明了我们方法的卓越性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [357] [Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data](https://arxiv.org/abs/2506.11165)
> *使用WiFi CSI数据评估BiLSTM和CNN+GRU用于人体活动识别的方法*

*Almustapha A. Wakili, Babajide J. Asaju, Woosub Jung* | **Main category: cs.CV**

**Keywords:** 人体活动识别, WiFi CSI, BiLSTM, CNN+GRU, 深度学习

**Comment:** This Paper has been Accepted and will appear in the 23rd IEEE/ACIS
  International Conference on Software Engineering, Management and Applications
  (SERA 2025)

> **TL;DR:** 本研究比较了BiLSTM和CNN+GRU模型在WiFi CSI数据集上进行人体活动识别的性能，发现CNN+GRU在UT-HAR数据集上表现更好（95.20%），而BiLSTM在NTU-Fi HAR数据集上表现更优（92.05%），强调了数据集特性对模型性能的重要性。

**AI_Comments:** 该论文通过对比BiLSTM和CNN+GRU模型在不同WiFi CSI数据集上的表现，深入探讨了深度学习模型在人体活动识别领域的适用性。其创新之处在于明确指出了不同模型对数据特征（空间或时间）的偏好，并强调了数据集特性及预处理的重要性，为未来选择和优化HAR模型提供了宝贵的指导。这些模型在医疗保健和智能家居中的无创应用前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在比较BiLSTM和CNN+GRU深度学习模型在基于WiFi信道状态信息（CSI）的人体活动识别（HAR）任务上的性能。

**Method:** 研究在UT-HAR和NTU-Fi HAR两个WiFi CSI数据集上，比较了BiLSTM和CNN+GRU两种深度学习模型在人体活动识别任务中的表现。

**Result:** CNN+GRU模型在UT-HAR数据集上表现出更高的准确率（95.20%），擅长提取空间特征。而BiLSTM模型在NTU-Fi HAR高分辨率数据集上表现更好（92.05%），能更有效地提取长期时间依赖性。

**Conclusion:** 研究结果强调了数据集特性和预处理技术对模型性能提升的关键作用，并展示了这些模型在医疗保健和智能家居系统等实际应用中的潜力。

> **ai_Abstract:** 本研究评估并比较了BiLSTM和CNN+GRU深度学习模型在基于WiFi CSI的人体活动识别任务中的性能。结果显示，CNN+GRU模型在UT-HAR数据集上表现更优（95.20%），擅长空间特征提取；而BiLSTM模型在NTU-Fi HAR数据集上更佳（92.05%），善于捕获长期时间依赖性。研究强调了数据集特性和预处理技术对模型性能的关键影响，并指出了这些模型在医疗保健和智能家居等领域非侵入式活动识别的实际应用潜力。

> **摘要翻译:** 本文比较了BiLSTM和CNN+GRU深度学习模型在两个基于WiFi信道状态信息（CSI）数据集（UT-HAR和NTU-Fi HAR）上进行人体活动识别（HAR）的性能。研究结果表明，CNN+GRU模型在UT-HAR数据集上具有更高的准确率（95.20%），这得益于其提取空间特征的能力。相比之下，BiLSTM模型在NTU-Fi HAR高分辨率数据集上表现更好（92.05%），因为它能更有效地提取长期时间依赖性。研究结果强烈强调了数据集特性和预处理技术在模型性能提升中的关键作用。我们还展示了这些模型在医疗保健和智能家居系统等应用中的实际适用性，突出了它们在非侵入式活动识别方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [358] [Linearly Solving Robust Rotation Estimation](https://arxiv.org/abs/2506.11547)
> *线性求解鲁棒旋转估计*

*Yinlong Liu, Tianyu Huang, Zhi-Xin Yang* | **Main category: cs.CV**

**Keywords:** 旋转估计, 线性求解, 鲁棒性, 投票法, GPU

**Comment:** 23 pages, 18 figures

> **TL;DR:** 本文提出一种线性、鲁棒且快速的旋转估计方法，通过将其重新表述为线性模型拟合问题并采用基于投票的方法，即使在大量异常值下也能有效工作。

**AI_Comments:** 该论文的创新点在于将复杂的非线性旋转估计问题巧妙地转化为线性模型拟合，这极大地简化了问题并提升了求解效率。结合对偶结构的洞察和基于投票的策略，以及GPU并行计算的优势，使其在面对极端异常值和大规模数据时展现出非凡的鲁棒性和速度，这对于安全关键型应用和大数据处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旋转估计在计算机视觉和机器人任务中扮演基础角色，极度鲁棒的旋转估计对安全关键应用至关重要。传统方法通常被认为是需要精心设计的非线性非凸优化问题。

**Method:** 本文提出将旋转估计问题重新表述为线性模型拟合问题，不放弃任何约束且不引入奇异性。此外，探索了旋转运动的对偶结构，揭示其可表示为四元数球面上的大圆。据此，提出了一种易于理解的基于投票的方法来解决旋转估计问题，并可利用GPU进行并行计算。

**Result:** 所提出的方法对噪声和异常值表现出卓越的鲁棒性。利用GPU，该方法能够在0.5秒内为大规模（10^6）和严重损坏（99%异常值比例）的旋转估计问题获得满意的解决方案。受控实验和真实世界数据集实验提供了有力证据支持该方法的有效性和鲁棒性。

**Conclusion:** 本文提出的线性求解鲁棒旋转估计方法，通过创新的问题重构和投票策略，在面临高噪声和异常值的大规模场景下展现出卓越的有效性、鲁棒性和计算效率。

> **ai_Abstract:** 本文提出了一种新颖的鲁棒旋转估计方法，通过将传统的非线性、非凸问题重新表述为线性模型拟合问题，避免了约束丢失和奇异性。该方法探索了旋转运动的对偶结构，并基于此提出了一种易于理解的投票策略。实验证明，该方法对噪声和异常值具有卓越的鲁棒性，并且能够利用GPU在0.5秒内高效处理包含99%异常值的大规模（10^6）旋转估计任务，其有效性和鲁棒性得到了充分验证。

> **摘要翻译:** 旋转估计在计算机视觉和机器人任务中扮演基础角色，极度鲁棒的旋转估计对安全关键应用极其有用。通常，估计旋转被认为是一个非线性、非凸的优化问题，需要精心设计。然而，在本文中，我们提供了一些新的视角，即解决旋转估计问题可以被重新表述为解决一个线性模型拟合问题，而无需放弃任何约束且不引入任何奇异性。此外，我们探索了旋转运动的对偶结构，揭示它可以表示为四元数球面上的一个大圆。因此，我们提出了一种易于理解的基于投票的方法来解决旋转估计问题。所提出的方法对噪声和异常值表现出卓越的鲁棒性，并且可以轻松地与图形处理单元（GPU）并行计算。特别地，利用GPU的强大能力，所提出的方法可以在0.5秒内为大规模（10^6）和严重损坏（99%异常值比例）的旋转估计问题获得满意的旋转解决方案。此外，为了验证我们的理论框架并展示我们提出方法的优越性，我们进行了受控实验和真实世界数据集实验。这些实验提供了令人信服的证据，支持我们的方法在解决旋转估计问题方面的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [365] [AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments](https://arxiv.org/abs/2506.11773)
> *AgentSense：在模拟家庭环境中利用大型语言模型智能体生成虚拟传感器数据*

*Zikang Leng, Megha Thukral, Yaqi Liu, Hrudhai Rajasekhar, Shruthi K. Hiremath, Thomas Plötz* | **Main category: cs.CV**

**Keywords:** 虚拟传感器数据, 大型语言模型, 人类活动识别, 智能家居, 数据生成

**Comment:** 

> **TL;DR:** AgentSense利用大型语言模型智能体在模拟家庭环境中生成大规模、多样化的虚拟传感器数据，以解决智能家居人类活动识别（HAR）系统中真实数据不足的问题，并显著提升HAR性能，尤其在真实数据有限的情况下。

**AI_Comments:** 这项工作具有重要的创新性，它利用大型语言模型（LLM）的生成能力来创建逼真且多样化的虚拟用户行为和传感器数据，从而有效缓解了智能家居HAR领域数据收集困难的痛点。其核心贡献在于提供了一个无需手动标注即可生成大规模、多样化虚拟数据集的管道，这对于推动HAR系统的泛化能力和鲁棒性至关重要。该方法尤其适用于真实数据稀缺或难以获取的场景，为未来智能家居和环境感知技术的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 智能家居人类活动识别（HAR）系统开发面临的主要障碍是缺乏大规模、多样化的标注数据集。家庭布局、传感器配置和用户行为的变异性增加了复杂性，需要能够捕捉用户和环境多样性的训练数据。

**Method:** AgentSense是一个虚拟数据生成管道。它通过大型语言模型生成多样化的人物角色，然后利用这些角色创建日常例行活动，并将活动分解为低级动作序列。这些动作在名为VirtualHome的模拟家庭环境中执行，该环境已扩展了虚拟环境传感器，能够记录智能体的活动。

**Result:** AgentSense能够生成代表广泛用户和家庭设置的丰富虚拟传感器数据集。在五个基准HAR数据集上，利用虚拟传感器数据显著提高了性能，尤其是在真实数据有限的情况下。值得注意的是，结合虚拟数据和少量真实数据训练的模型，其性能与仅使用全部真实数据集训练的模型相当。

**Conclusion:** 虚拟数据在解决环境感知领域中最紧迫的挑战之一——缺乏大规模标注数据集方面具有巨大潜力，且无需任何手动数据收集工作。

> **ai_Abstract:** AgentSense提出了一种利用大型语言模型（LLM）智能体在模拟家庭环境中生成虚拟传感器数据的方法，旨在解决智能家居人类活动识别（HAR）系统开发中真实标注数据稀缺的问题。该方法通过LLM生成多样化人物角色及其日常活动，并将其分解为动作序列，然后在扩展的VirtualHome模拟环境中执行并记录传感器数据。实验结果表明，结合虚拟数据可以显著提升HAR模型的性能，尤其是在真实数据有限的情况下，甚至能达到与使用大量真实数据相当的效果，证明了虚拟数据在解决数据瓶颈方面的巨大潜力。

> **摘要翻译:** 在开发强大且通用的人类活动识别（HAR）系统时，智能家居面临的一个主要障碍是缺乏大规模、多样化的标注数据集。家庭布局、传感器配置和用户行为的变异性进一步增加了复杂性，因为个体遵循不同的日常习惯并以独特的方式执行活动。构建能够很好地泛化的HAR系统需要捕获用户和环境多样性的训练数据。为了解决这些挑战，我们引入了AgentSense，这是一个虚拟数据生成管道，它通过利用大型语言模型生成多样化的人物角色。这些角色用于创建日常活动，然后分解为低级动作序列。随后，这些动作在我们扩展了虚拟环境传感器的模拟家庭环境VirtualHome中执行，这些传感器能够记录智能体的活动。总的来说，AgentSense能够生成代表广泛用户和家庭设置的丰富虚拟传感器数据集。在五个基准HAR数据集上，我们发现利用我们的虚拟传感器数据显著提高了性能，尤其是在真实数据有限的情况下。值得注意的是，结合虚拟数据和少量真实数据训练的模型，其性能与仅使用全部真实数据集训练的模型相当。这些结果证明了虚拟数据在解决环境感知领域中最紧迫的挑战之一——缺乏大规模标注数据集方面的潜力，且无需任何手动数据收集工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning](https://arxiv.org/abs/2506.11166)
> *零样本诊断中的测试时缩放与视觉语言推理*

*Ji Young Byun, Young-Jin Park, Navid Azizan, Rama Chellappa* | **Main category: cs.CV**

**Keywords:** 零样本诊断, 医学影像, 视觉语言推理, 测试时缩放, 大型语言模型

**Comment:** 

> **TL;DR:** 本文提出了一种零样本框架，通过测试时缩放策略增强大型语言模型（LLMs）在医学影像诊断中的推理能力，有效提高了诊断准确性和可靠性。

**AI_Comments:** 该研究的创新之处在于其提出的零样本框架和测试时缩放策略，旨在增强大型语言模型在医学诊断中的推理能力。这对于解决医学领域标注数据有限的关键问题具有重要意义，使得LLMs能够在无需大量微调的情况下应用于复杂的医学视觉问答任务。

<details>
  <summary>Details</summary>

**Motivation:** 临床决策对患者预后至关重要，可通过大型语言模型（LLMs）增强。然而，LLMs在医学影像视觉问答（特别是基于推理的诊断）中的应用尚未被充分探索。此外，由于数据稀缺和标注成本高昂，针对推理任务的监督微调在医学领域通常不切实际。

**Method:** 本研究引入了一个零样本框架。首先，一个视觉语言模型接收医学图像和文本提示，生成视觉特征的多个描述或解释。随后，这些解释被输入到LLM中，该LLM运用测试时缩放策略将多个候选输出整合为一个可靠的最终诊断。

**Result:** 所提出的测试时缩放策略显著提高了包括放射学、眼科学和组织病理学在内的多种医学影像模态的诊断准确性，对本文方法和基线方法均有效。此外，实证分析表明，该方法通过允许第一阶段的无偏提示，提高了LLM生成诊断的可靠性并增强了分类准确性。

**Conclusion:** 本文提出的零样本框架，通过视觉语言推理和测试时缩放策略，为医学影像诊断提供了一种可靠且准确的解决方案，有效克服了数据限制的挑战。

> **ai_Abstract:** 本文提出了一种用于医学影像零样本诊断的框架，该框架结合了视觉语言推理和测试时缩放策略。它利用视觉语言模型从医学图像中生成多重解释，然后由大型语言模型（LLM）通过测试时缩放策略进行整合，以生成可靠的最终诊断。该方法解决了医学影像领域监督微调数据稀缺的挑战，并被证明能提高多种模态的诊断准确性和可靠性。

> **摘要翻译:** 作为患者护理的基石，临床决策显著影响患者预后，并可通过大型语言模型（LLMs）得到增强。尽管LLMs已展现出卓越性能，但它们在医学影像视觉问答中的应用，特别是基于推理的诊断，仍 largely 未被探索。此外，由于数据可用性有限和高昂的标注成本，针对推理任务的监督微调在很大程度上是不切实际的。在这项工作中，我们引入了一个用于可靠医学影像诊断的零样本框架，该框架通过测试时缩放增强了LLMs在临床环境中的推理能力。给定一张医学图像和一个文本提示，一个视觉语言模型处理医学图像及其相应的文本提示，以生成视觉特征的多个描述或解释。然后，这些解释被输入到LLM中，其中测试时缩放策略将多个候选输出整合为一个可靠的最终诊断。我们在各种医学影像模态（包括放射学、眼科学和组织病理学）上评估了我们的方法，并证明所提出的测试时缩放策略提高了我们和基线方法的诊断准确性。此外，我们提供了一项实证分析，表明所提出的方法（允许在第一阶段进行无偏提示）提高了LLM生成诊断的可靠性并增强了分类准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation](https://arxiv.org/abs/2506.11314)
> *HyBiomass：用于评估地理空间基础模型在森林地上生物量估算中性能的全球高光谱图像基准数据集*

*Aaron Banze, Timothée Stassin, Nassim Ait Ali Braham, Rıdvan Salih Kuzu, Simon Besnard, Michael Schmitt* | **Main category: cs.CV**

**Keywords:** 高光谱图像, 地理空间基础模型, 森林地上生物量, 基准数据集, 像素级回归

**Comment:** 

> **TL;DR:** 引入了一个名为HyBiomass的全球高光谱图像基准数据集，用于评估地理空间基础模型在森林地上生物量估算（像素级回归任务）中的性能，并发现Geo-FMs在此任务上表现良好，且性能受数据集大小和Transformer骨干网络中的Token Patch大小影响。

**AI_Comments:** 该论文通过引入一个针对像素级回归任务（森林地上生物量估算）的全球高光谱基准数据集，填补了现有地理空间基础模型（Geo-FMs）评估基准的空白，具有显著的创新性。其重要性在于为Geo-FMs在更复杂、更具挑战性的地球观测任务中的发展和评估提供了关键资源，并强调了数据规模和模型参数（如Token Patch大小）对性能的影响，这对于未来Geo-FMs的设计和应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的地理空间基础模型（Geo-FMs）基准数据集主要局限于分割或分类任务，且集中于特定地理区域，无法满足Geo-FMs在多样化任务、传感器和地理区域进行全面评估的需求，尤其是在森林地上生物量（AGB）估算这种像素级回归任务上存在空白。

**Method:** 引入了一个名为HyBiomass的全球分布式森林地上生物量（AGB）估算数据集，这是一个像素级回归任务。该数据集结合了来自环境测绘与分析项目（EnMAP）卫星的共置高光谱图像（HSI）和来自全球生态系统动力学调查激光雷达的AGB密度估算预测，覆盖七个大陆区域。

**Result:** 评估的地理空间基础模型（Geo-FMs）在此数据集上的性能可以匹配或在某些情况下超越基线U-Net，特别是在对编码器进行微调时。Geo-FMs与U-Net之间的性能差异取决于每个区域的数据集大小。Transformer骨干网络中的Token Patch大小对于像素级回归任务中的准确预测至关重要。

**Conclusion:** 通过发布HyBiomass全球分布式高光谱基准数据集，旨在促进地理空间基础模型（Geo-FMs）在HSI应用中的开发和评估，并有助于研究Geo-FMs的地理偏差和泛化能力。

> **ai_Abstract:** 本研究引入了HyBiomass，一个全球分布式高光谱图像基准数据集，旨在解决现有地理空间基础模型（Geo-FMs）基准数据集在森林地上生物量（AGB）估算这一像素级回归任务上的空白。该数据集整合了EnMAP高光谱图像和GEDI激光雷达AGB预测数据，覆盖七大洲。实验结果表明，Geo-FMs在微调编码器后，性能可与U-Net媲美甚至超越，其性能受区域数据集大小和Transformer中Token Patch大小的影响。该数据集的发布旨在推动Geo-FMs在HSI应用中的发展和评估，并促进对地理偏差和泛化能力的研究。

> **摘要翻译:** 综合评估地理空间基础模型（Geo-FMs）需要在多样化的任务、传感器和地理区域进行基准测试。然而，大多数现有基准数据集仅限于分割或分类任务，并专注于特定地理区域。为了弥补这一空白，我们引入了一个用于森林地上生物量（AGB）估算的全球分布式数据集，这是一项像素级回归任务。这个基准数据集结合了来自环境测绘与分析项目（EnMAP）卫星的共置高光谱图像（HSI）和来自全球生态系统动力学调查激光雷达的AGB密度估算预测，覆盖七个大陆区域。我们在此数据集上的实验结果表明，所评估的Geo-FMs可以匹配或在某些情况下超越基线U-Net的性能，尤其是在对编码器进行微调时。我们还发现U-Net和Geo-FMs之间的性能差异取决于每个区域的数据集大小，并强调了视觉Transformer骨干网络中Token Patch大小对于像素级回归任务中准确预测的重要性。通过发布这个全球分布式高光谱基准数据集，我们旨在促进Geo-FMs在HSI应用中的开发和评估。利用该数据集还有助于研究Geo-FMs的地理偏差和泛化能力。数据集和源代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation](https://arxiv.org/abs/2506.11774)
> *等长姿势评估的实时反馈和基准数据集*

*Abhishek Jaiswal, Armeet Singh Luthra, Purav Jangir, Bhavya Garg, Nisheeth Srivastava* | **Main category: cs.CV**

**Keywords:** 等长姿势评估, 实时反馈, 运动数据集, 姿势校正, 机器视觉

**Comment:** 

> **TL;DR:** 本文提出了一个用于评估等长姿势的实时反馈系统，并发布了一个包含3600多个视频片段的大型多类别等长运动数据集。该系统通过基准测试最先进的模型并引入新的三部分度量标准来提供姿势评估，旨在提高家庭锻炼的智能性和个性化，并扩展其在康复和物理治疗中的应用。

**AI_Comments:** 该论文的创新之处在于其构建的目前最大的多类别等长运动视频数据集，以及引入的结合分类准确性、错误定位和模型置信度的新型三部分评估指标，这对于实时姿势评估系统的发展至关重要。该系统在家庭健身、康复和物理治疗等领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 等长运动因其便利性、隐私性和对设备依赖性小而受欢迎。然而，这种健身训练往往过度依赖不可靠的数字媒体内容，而非专家指导，从而导致姿势不正确、受伤以及因缺乏纠正性反馈而导致参与度降低等严重风险。

**Method:** 我们提出了一个用于评估等长姿势的实时反馈系统。主要贡献包括：发布了迄今为止最大的多类别等长运动视频数据集，包含六种姿势的3600多个正确和不正确变体片段。在该数据集上对包括基于图网络的最新模型进行了基准测试，并引入了一种新颖的三部分度量标准，该标准包含分类准确性、错误定位和模型置信度。

**Result:** 我们的结果增强了家庭锻炼智能和个性化运动训练系统的可行性。

**Conclusion:** 这种直接提供给用户的专家级诊断，也扩大了这些系统在康复、物理治疗和涉及身体运动的各种其他健身学科中的潜在应用。

> **ai_Abstract:** 本文提出了一个针对等长运动姿势评估的实时反馈系统，旨在解决当前训练中缺乏专家指导和纠正性反馈的问题。作者发布了一个包含六种姿势共3600多个视频片段的大型多类别等长运动数据集，并在此数据集上对现有模型进行了基准测试。此外，还引入了一个新的三部分度量标准来评估模型的分类准确性、错误定位和置信度。研究结果表明，该系统能够提高家庭锻炼的智能性和个性化，并有望应用于康复、物理治疗等领域。

> **摘要翻译:** 等长运动因其便利性、隐私性和对设备依赖性小而受到青睐。然而，这种健身训练往往过度依赖不可靠的数字媒体内容，而非专家指导，从而引入了包括姿势不正确、受伤以及因缺乏纠正性反馈而导致参与度降低等严重风险。为了解决这些挑战，我们提出了一个用于评估等长姿势的实时反馈系统。我们的贡献包括发布了迄今为止最大的多类别等长运动视频数据集，该数据集包含六种姿势的3600多个正确和不正确变体片段。为了支持鲁棒评估，我们在此数据集上对包括基于图网络的最新模型进行了基准测试，并引入了一种新颖的三部分度量标准，该标准捕获了分类准确性、错误定位和模型置信度。我们的结果增强了家庭锻炼智能和个性化运动训练系统的可行性。这种直接提供给用户的专家级诊断，也扩大了这些系统在康复、物理治疗和涉及身体运动的各种其他健身学科中的潜在应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [Towards a general-purpose foundation model for fMRI analysis](https://arxiv.org/abs/2506.11167)
> *迈向用于fMRI分析的通用基础模型*

*Cheng Wang, Yu Jiang, Zhihao Peng, Chenxin Li, Changbae Bang, Lin Zhao, Jinglei Lv, Jorge Sepulcre, Carl Yang, Lifang He, Tianming Liu, Daniel Barron, Quanzheng Li, Randy Hirschtick, Byung-Hoon Kim, Xiang Li, Yixuan Yuan* | **Main category: cs.CV**

**Keywords:** fMRI分析, 基础模型, NeuroSTORM, 深度学习, 神经影像

**Comment:** 

> **TL;DR:** NeuroSTORM是一个用于fMRI分析的通用基础模型，通过大规模预训练和优化策略解决了现有方法的重现性和可迁移性问题，并在多项任务上表现出色。

**AI_Comments:** 该论文提出NeuroSTORM，一个通用fMRI基础模型，其创新点在于直接处理4D fMRI数据，采用Mamba骨干网络和大规模预训练，有效解决了fMRI分析中长期存在的重现性和可迁移性问题。其在多任务和多中心数据集上的优异表现，特别是临床实用性，预示着其在神经影像学领域的重要应用潜力。作为一个开源模型，它有望推动fMRI研究的标准化和进步。

<details>
  <summary>Details</summary>

**Motivation:** 当前fMRI分析方法因复杂的预处理和任务特定模型而面临重现性和可迁移性问题，这阻碍了其在研究和临床诊断中的应用。

**Method:** 引入NeuroSTORM，一个直接从4D fMRI数据中学习的通用框架。它在大规模多中心数据集（28.65百万帧，>50,000名受试者）上进行预训练，采用Mamba骨干网络和移位扫描策略处理4D数据。此外，还提出了时空优化预训练方法和任务特定提示微调以提高可迁移性。

**Result:** NeuroSTORM在五项任务（年龄/性别预测、表型预测、疾病诊断、fMRI到图像检索、基于任务的fMRI分类）上均优于现有方法。它在美国、韩国和澳大利亚医院的数据集上展现出强大的临床实用性，在疾病诊断和认知表型预测方面取得了顶尖性能。

**Conclusion:** NeuroSTORM提供了一个标准化、开源的基础模型，旨在提高基于fMRI的临床研究的重现性和可迁移性。

> **ai_Abstract:** 本文提出了NeuroSTORM，一个用于fMRI分析的通用基础模型，旨在解决现有方法在重现性和可迁移性方面的挑战。NeuroSTORM通过在大规模4D fMRI数据集上进行预训练，并结合Mamba骨干网络和创新的时空优化策略，实现了从原始数据中直接学习。该模型在多项任务（如疾病诊断、表型预测）上超越了现有方法，并在多国临床数据上验证了其有效性，为fMRI研究提供了一个标准化、开源的解决方案。

> **摘要翻译:** 功能性磁共振成像（fMRI）对于研究大脑功能和诊断神经系统疾病至关重要，但当前的分析方法由于复杂的预处理和任务特定模型而面临重现性和可迁移性问题。我们引入了NeuroSTORM（具有时空优化表示建模的神经影像基础模型），这是一个可泛化的框架，直接从4D fMRI体数据中学习，并能实现跨不同应用的有效知识迁移。NeuroSTORM在来自多个中心、年龄介于5至100岁的50,000多名受试者的28.65万fMRI帧（超过9,000小时）上进行了预训练。它使用Mamba骨干网络和移位扫描策略，高效处理完整的4D体数据。我们还提出了一种时空优化预训练方法和任务特定提示微调，以提高可迁移性。NeuroSTORM在五项任务中超越了现有方法：年龄/性别预测、表型预测、疾病诊断、fMRI到图像检索以及基于任务的fMRI分类。它在美国、韩国和澳大利亚医院的数据集上展示了强大的临床实用性，在疾病诊断和认知表型预测方面取得了顶尖性能。NeuroSTORM提供了一个标准化、开源的基础模型，以提高基于fMRI的临床研究的重现性和可迁移性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [372] [EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment](https://arxiv.org/abs/2506.11549)
> *EyeSim-VQA：一种自由能引导的视频质量评估眼动模拟框架*

*Zhaoyang Wang, Wen Lu, Jie Li, Lihuo He, Maoguo Gong, Xinbo Gao* | **Main category: cs.CV**

**Keywords:** 视频质量评估, 自由能, 眼动模拟, 自修复, 双分支架构

**Comment:** This work has been submitted to the IEEE TCSVT for possible
  publication

> **TL;DR:** EyeSim-VQA是一个新颖的视频质量评估框架，它利用自由能引导的自修复机制和双分支架构来处理视频的复杂性，并在多个基准测试中取得了优异的性能和更好的可解释性。

**AI_Comments:** 该论文的创新点在于将自由能引导的自修复机制引入VQA领域，并设计了一个独特的双分支架构和生物学启发的预测头来模拟眼动和处理视频的时空复杂性。其强调可解释性也是一个重要的优势。该框架通过整合增强模块而不影响预训练骨干网络稳定性，解决了实际应用中的一个关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 自由能引导的自修复机制在图像质量评估（IQA）中表现出色，但在视频质量评估（VQA）中尚未得到充分探索，因为视频的动态性、模型约束、丰富的时空复杂性以及难以在不影响模型稳定性的情况下集成增强模块带来了独特的挑战。

**Method:** 我们提出了EyeSimVQA，一个结合自由能自修复的新型VQA框架。它采用双分支架构：一个用于全局感知评估的美学分支和一个用于细粒度结构和语义分析的技术分支。每个分支都集成了专门的增强模块，针对不同的视觉输入（调整大小的全帧图像和基于补丁的片段）进行定制，以模拟自适应修复行为。我们还探索了一种在不干扰原始骨干网络的情况下整合高级视觉特征的策略。此外，我们设计了一个受生物学启发的预测头，模拟扫视注视动态，以更好地融合全局和局部表示进行质量预测。

**Result:** 在五个公共VQA基准测试中，EyeSimVQA与最先进的方法相比，实现了具有竞争力或更优的性能，并通过其生物学基础设计提供了更高的可解释性。

**Conclusion:** EyeSimVQA是一个有效且可解释的视频质量评估框架，它通过模拟眼动和自由能引导的自修复机制，成功应对了视频质量评估中的挑战。

> **ai_Abstract:** EyeSimVQA是一个新颖的视频质量评估（VQA）框架，旨在解决现有方法在处理视频复杂性和模型集成方面的不足。该框架引入了自由能引导的自修复机制，并采用双分支架构（美学分支和技术分支）分别处理全局感知和细粒度分析。通过模拟自适应修复行为和融入受生物学启发的注视动态预测头，EyeSimVQA能够有效融合全局和局部特征。实验证明，EyeSimVQA在多个VQA基准测试中表现优异，并提供了更好的可解释性。

> **摘要翻译:** 自由能引导的自修复机制在图像质量评估（IQA）中已显示出有前景的结果，但在视频质量评估（VQA）中仍未得到充分探索，VQA中时间动态和模型约束带来了独特的挑战。与静态图像不同，视频内容展现出更丰富的时空复杂性，使得感知恢复更加困难。此外，VQA系统通常依赖于预训练的骨干网络，这限制了在不影响模型稳定性的情况下直接集成增强模块。为了解决这些问题，我们提出了EyeSimVQA，一个结合自由能自修复的新型VQA框架。它采用双分支架构，其中一个美学分支用于全局感知评估，一个技术分支用于细粒度结构和语义分析。每个分支都集成了专门的增强模块，针对不同的视觉输入——调整大小的全帧图像和基于补丁的片段——进行定制，以模拟自适应修复行为。我们还探索了一种在不干扰原始骨干网络的情况下整合高级视觉特征的原则性策略。此外，我们设计了一个受生物学启发的预测头，模拟扫视注视动态，以更好地融合全局和局部表示进行质量预测。在五个公共VQA基准测试中的实验表明，EyeSimVQA与最先进的方法相比，实现了具有竞争力或更优的性能，并通过其生物学基础设计提供了更高的可解释性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [376] [WaveFormer: A Lightweight Transformer Model for sEMG-based Gesture Recognition](https://arxiv.org/abs/2506.11168)
> *WaveFormer：一种用于sEMG手势识别的轻量级Transformer模型*

*Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li* | **Main category: cs.CV**

**Keywords:** sEMG, 手势识别, Transformer, 轻量级模型, 小波变换

**Comment:** 6 pages, 3 figures, submitted to IEEE EMBS Conference on Neural
  Engineering (NER)

> **TL;DR:** WaveFormer是一种轻量级Transformer模型，通过结合可学习小波变换和WaveletConv模块，提高了sEMG手势识别的准确性，并实现了实时部署。

**AI_Comments:** 本文的创新点在于提出了WaveFormer，一个轻量级的Transformer模型，通过将可学习小波变换与深度可分离卷积结合，有效解决了sEMG手势识别中高相似度手势的分类难题，并实现了模型的小型化和高效实时部署。这对于资源受限的嵌入式系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 表面肌电图（sEMG）信号手势识别在人机交互中取得了进展，但分类相似手势的准确性仍是挑战。传统深度学习模型体积庞大且计算成本高昂，限制了其在资源受限嵌入式系统上的部署。

**Method:** 本文提出了WaveFormer，一种专为sEMG手势识别设计的轻量级Transformer架构。该模型通过新颖的可学习小波变换整合时域和频域特征，增强特征提取。其中，WaveletConv模块是一个多级小波分解层，结合深度可分离卷积，确保了效率和紧凑性。

**Result:** WaveFormer模型仅有310万参数，在EPN612数据集上实现了95%的分类准确率，优于大型模型。在配备Intel CPU的笔记本电脑上进行测试时，INT8量化实现了实时部署，推理延迟为6.75毫秒。

**Conclusion:** WaveFormer通过其轻量级设计和创新的特征提取方法，有效解决了sEMG手势识别中相似手势分类的挑战，并在资源受限设备上实现了高性能和实时部署。

> **ai_Abstract:** WaveFormer是一种轻量级Transformer模型，专为sEMG手势识别设计，旨在解决相似手势分类挑战和传统模型计算开销大的问题。该模型通过新颖的可学习小波变换整合时域和频域特征，并引入了高效紧凑的WaveletConv模块。WaveFormer以310万参数在EPN612数据集上实现了95%的准确率，并能通过INT8量化在Intel CPU上实现6.75毫秒的实时推理延迟，性能优于大型模型。

> **摘要翻译:** 人机交互，特别是在假肢和机器人控制方面，通过表面肌电图（sEMG）信号进行手势识别取得了进展。然而，分类产生几乎相同肌肉信号的相似手势仍然是一个挑战，这通常会降低分类准确性。传统的sEMG手势识别深度学习模型体积庞大且计算成本高昂，限制了它们在资源受限嵌入式系统上的部署。在这项工作中，我们提出了WaveFormer，一种专为sEMG手势识别量身定制的轻量级Transformer架构。我们的模型通过一种新颖的可学习小波变换整合了时域和频域特征，增强了特征提取。特别是，WaveletConv模块，一个具有深度可分离卷积的多级小波分解层，确保了效率和紧凑性。WaveFormer仅有310万参数，在EPN612数据集上实现了95%的分类准确率，超越了大型模型。此外，在配备Intel CPU的笔记本电脑上进行测试时，INT8量化实现了实时部署，推理延迟为6.75毫秒。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [381] [Teaching in adverse scenes: a statistically feedback-driven threshold and mask adjustment teacher-student framework for object detection in UAV images under adverse scenes](https://arxiv.org/abs/2506.11175)
> *恶劣场景下的教学：一种基于统计反馈的阈值和掩码调整师生框架，用于恶劣场景下无人机图像中的目标检测*

*Hongyu Chen, Jiping Liu, Yong Wang, Jun Zhu, Dejun Feng, Yakun Xie* | **Main category: cs.CV**

**Keywords:** 无人机目标检测, 恶劣场景, 无监督域适应, 师生框架, 伪标签

**Comment:** The manuscript has been accepted by ISPRS Journal of Photogrammetry
  and Remote Sensing

> **TL;DR:** 本文提出了SF-TMAT，一个用于恶劣场景下无人机目标检测的师生框架，通过动态掩码调整和基于方差反馈的阈值策略，有效解决了现有UDA方法在恶劣无人机图像中特征对齐和伪标签质量差的问题，并取得了优异的性能。

**AI_Comments:** 该论文的创新点在于首次提出了专门针对恶劣场景下无人机图像目标检测的无监督域适应框架SF-TMAT，并解决了现有方法在该特定场景下的局限性。其引入的DSFMA和VFST策略通过动态调整学习焦点和优化伪标签质量，为恶劣环境下的视觉感知提供了新的思路和有效方案，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 无监督域适应（UDA）在缓解域间隙方面显示出潜力，但现有研究主要基于自然图像或清晰的无人机图像，针对恶劣条件下无人机图像的研究仍处于早期阶段。此外，由于无人机独特的视角和恶劣条件的干扰，现有方法难以准确对齐特征，并且受限于有限或噪声伪标签。

**Method:** 本文提出了首个用于恶劣场景下无人机目标检测的基准SF-TMAT（统计反馈驱动的阈值和掩码调整师生框架）。SF-TMAT引入了动态步长反馈掩码调整自编码器（DSFMA），通过整合训练进度和损失反馈来动态调整掩码比例并重建特征图。此外，还提出了独特的方差反馈平滑阈值（VFST）策略，通过统计计算每类的平均置信度并引入方差惩罚项来动态调整选择阈值，以提高伪标签质量并发现潜在的有效标签。

**Result:** 大量实验证明了所提出的SF-TMAT在恶劣场景条件下无人机目标检测中的优越性和泛化能力。

**Conclusion:** 本文提出了SF-TMAT，首个用于恶劣场景下无人机目标检测的基准框架，通过创新的动态掩码调整和统计反馈阈值策略，有效解决了现有方法的局限性，并在恶劣场景下展示了卓越的性能和泛化能力。

> **ai_Abstract:** 本文针对现有无监督域适应（UDA）方法在恶劣场景下无人机图像目标检测中存在的特征对齐不准确和伪标签质量差的问题，提出了首个基准框架SF-TMAT。SF-TMAT包含动态步长反馈掩码调整自编码器（DSFMA）用于动态调整学习焦点，以及方差反馈平滑阈值（VFST）策略以提高伪标签质量和减轻域偏差。实验结果表明，SF-TMAT在恶劣场景下无人机目标检测中表现出优越的性能和泛化能力。

> **摘要翻译:** 无监督域适应（UDA）在有效缓解源域和目标域之间域间隙造成的性能下降方面显示出前景，并且可能推广到恶劣场景下的无人机目标检测。然而，现有的UDA研究基于自然图像或清晰的无人机图像，而针对恶劣条件下无人机图像的研究仍处于早期阶段。此外，由于无人机独特的视角和恶劣条件的干扰，这些方法往往无法准确对齐特征，并受到有限或噪声伪标签的影响。为了解决这个问题，我们提出了首个用于恶劣场景下无人机目标检测的基准——统计反馈驱动的阈值和掩码调整师生框架（SF-TMAT）。具体来说，SF-TMAT引入了一种称为动态步长反馈掩码调整自编码器（DSFMA）的设计，通过整合训练进度和损失反馈来动态调整掩码比例并重建特征图。这种方法在不同训练阶段动态调整学习焦点，以满足模型对不同粒度级别特征学习的需求。此外，我们提出了一种独特的方差反馈平滑阈值（VFST）策略，该策略统计计算每个类别的平均置信度，并通过引入方差惩罚项来动态调整选择阈值。该策略提高了伪标签的质量并揭示了潜在的有效标签，从而减轻了域偏差。大量实验证明了所提出的SF-TMAT在恶劣场景条件下无人机目标检测中的优越性和泛化能力。代码已在https://github.com/ChenHuyoo 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [382] [AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials](https://arxiv.org/abs/2506.11740)
> *AgriPotential：一种用于农业潜力的多光谱多时相新型遥感数据集*

*Mohammad El Sakka, Caroline De Pourtales, Lotfi Chaari, Josiane Mothe* | **Main category: cs.CV**

**Keywords:** 遥感, 农业潜力, 数据集, Sentinel-2, 机器学习

**Comment:** 

> **TL;DR:** 本文介绍了AgriPotential，一个用于农业潜力预测的新型多光谱多时相遥感数据集，包含像素级标注，支持多种机器学习任务，并已公开可用。

**AI_Comments:** 该论文贡献了一个有价值的公共数据集，填补了农业潜力预测领域的空白。其多光谱、多时相特性，加上像素级标注，使其适用于多种机器学习任务。该数据集有望显著推动可持续农业和土地管理领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 遥感已成为大规模地球监测和土地管理的关键工具。为了改进数据驱动的可持续土地利用规划方法，需要一个专门用于农业潜力预测的公共数据集。

**Method:** 本文介绍了AgriPotential，这是一个由Sentinel-2卫星图像组成的新型基准数据集，跨越数月。该数据集为三种主要作物类型（葡萄栽培、市场园艺和农田作物）的农业潜力提供了五种序数类别的像素级标注。

**Result:** AgriPotential是第一个专门为农业潜力预测设计的公共数据集。它涵盖了法国南部不同区域，提供了丰富的光谱信息。该数据集支持序数回归、多标签分类和时空建模等多种机器学习任务。

**Conclusion:** 本文推出了AgriPotential，这是一个新颖的公共数据集，旨在通过提供带有农业潜力标注的多光谱、多时相遥感数据，改进数据驱动的可持续土地利用规划方法。

> **ai_Abstract:** 本文介绍了AgriPotential，一个基于Sentinel-2卫星图像构建的新型多光谱多时相遥感数据集。该数据集为葡萄栽培、市场园艺和农田作物三种主要作物的农业潜力提供像素级标注，分为五种序数类别，支持序数回归、多标签分类和时空建模等多种机器学习任务。AgriPotential是首个专门用于农业潜力预测的公共数据集，旨在推动数据驱动的可持续土地利用规划。

> **摘要翻译:** 遥感已成为大规模地球监测和土地管理的关键工具。本文介绍了AgriPotential，这是一个由跨越数月的Sentinel-2卫星图像组成的新型基准数据集。该数据集为三种主要作物类型——葡萄栽培、市场园艺和农田作物——的农业潜力提供了五种序数类别的像素级标注。AgriPotential支持广泛的机器学习任务，包括序数回归、多标签分类和时空建模。数据覆盖法国南部不同区域，提供丰富的光谱信息。AgriPotential是第一个专门为农业潜力预测设计的公共数据集，旨在改进数据驱动的可持续土地利用规划方法。数据集和代码可在以下网址免费获取：https://zenodo.org/records/15556484

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [Evaluating Sensitivity Parameters in Smartphone-Based Gaze Estimation: A Comparative Study of Appearance-Based and Infrared Eye Trackers](https://arxiv.org/abs/2506.11932)
> *评估智能手机注视估计中的敏感性参数：基于外观和红外眼动追踪器的比较研究*

*Nishan Gunawardena, Gough Yumu Lui, Jeewani Anupama Ginige, Bahman Javadi* | **Main category: cs.CV**

**Keywords:** 智能手机眼动追踪, 注视估计, 深度学习, 敏感性分析, 移动眼动追踪

**Comment:** 

> **TL;DR:** 本研究比较了智能手机深度学习眼动追踪算法与商用红外眼动追踪器，分析了年龄、性别、视力矫正、光照、设备类型和头部位置等敏感因素对性能的影响。

**AI_Comments:** 这项研究通过与商用红外眼动追踪器进行比较，系统评估了智能手机上基于深度学习的眼动追踪算法的性能，并深入分析了多种敏感性因素，这对于推动移动眼动追踪技术在实际应用中的鲁棒性和可靠性具有重要意义。其创新之处在于将轻量级深度学习模型应用于移动设备，并详细揭示了其在不同使用条件下的优势与局限性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估智能手机上基于外观的深度学习眼动追踪算法在实际移动使用条件下的可行性，并通过与商用红外眼动追踪器进行性能比较，深入分析其对各种敏感性因素的响应。

**Method:** 本研究将一种结合了MobileNet-V3和LSTM的智能手机深度学习眼动追踪算法与商用红外眼动追踪器Tobii Pro Nano进行比较。从51名参与者那里收集了使用动态视觉刺激的注视数据，并使用欧几里得距离测量准确性。系统分析了年龄、性别、视力矫正、光照条件、设备类型和头部位置等关键敏感性因素对性能的影响。

**Result:** 深度学习模型的平均误差为17.76毫米，而Tobii Pro Nano的平均误差为16.53毫米。虽然总体准确性差异很小，但深度学习方法对光照、视力矫正和年龄等因素更为敏感，在低光照条件下、戴眼镜的参与者和老年群体中观察到更高的失败率。设备特定和头部位置因素也影响了追踪性能。

**Conclusion:** 基于外观的智能手机眼动追踪方法具有潜力，但在复杂和多变的实际使用条件下（如不同光照、视力矫正和年龄组）其鲁棒性仍需进一步提高。本研究为评估不同使用条件下的注视估计系统提供了一个参考框架。

> **ai_Abstract:** 本研究评估了基于智能手机的深度学习眼动追踪算法，并与商用红外眼动追踪器Tobii Pro Nano进行了性能比较。该算法采用MobileNet-V3和LSTM从灰度图像预测注视。研究系统分析了年龄、性别、视力矫正、光照、设备类型和头部位置等敏感因素。结果显示，深度学习模型（平均误差17.76毫米）与Tobii Pro Nano（平均误差16.53毫米）在总体准确性上差异不大，但深度学习方法对光照、视力矫正和年龄更为敏感，在特定条件下失败率较高。研究强调了基于外观的方法在移动眼动追踪中的潜力，并为评估此类系统提供了参考框架。

> **摘要翻译:** 本研究通过将智能手机上基于深度学习的眼动追踪算法与商用红外眼动追踪器Tobii Pro Nano的性能进行比较，对其进行了评估。目的是调查在实际移动使用条件下基于外观的注视估计的可行性。系统分析了关键的敏感性因素，包括年龄、性别、视力矫正、光照条件、设备类型和头部位置。基于外观的算法整合了一个轻量级卷积神经网络（MobileNet-V3）和循环结构（长短期记忆网络）以从灰度人脸图像预测注视坐标。从51名参与者那里收集了使用动态视觉刺激的注视数据，并使用欧几里得距离测量准确性。深度学习模型产生了17.76毫米的平均误差，而Tobii Pro Nano的平均误差为16.53毫米。尽管总体准确性差异很小，但基于深度学习的方法对光照、视力矫正和年龄等因素更为敏感，在低光照条件下、使用眼镜的参与者和老年群体中观察到更高的失败率。设备特定和位置因素也影响了追踪性能。这些结果突出了基于外观的方法在移动眼动追踪方面的潜力，并为评估不同使用条件下的注视估计系统提供了参考框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [DiffFuSR: Super-Resolution of all Sentinel-2 Multispectral Bands using Diffusion Models](https://arxiv.org/abs/2506.11764)
> *DiffFuSR：使用扩散模型对所有Sentinel-2多光谱波段进行超分辨率处理*

*Muhammad Sarmad, Arnt-Børre Salberg, Michael Kampffmeyer* | **Main category: cs.CV**

**Keywords:** 超分辨率, 扩散模型, Sentinel-2, 多光谱图像, 图像融合

**Comment:** preprint under review

> **TL;DR:** DiffFuSR是一个两阶段的扩散模型，用于将所有Sentinel-2多光谱波段超分辨率到2.5米GSD，在多个指标上优于现有SOTA方法。

**AI_Comments:** DiffFuSR的创新之处在于其模块化的两阶段管道设计，结合了扩散模型进行高分辨率RGB图像超分，并利用学习型融合网络以超分后的RGB作为先验提升其他多光谱波段。这种方法通过协调学习与生成先验和融合策略，有效解决了多光谱图像超分辨率的挑战，尤其是在处理不同分辨率波段方面。其在反射率保真度、光谱一致性和幻觉抑制方面的优异表现，以及对盲SR的支持，使其成为Sentinel-2数据处理的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 提升Sentinel-2 Level-2A图像所有12个光谱波段的地面采样距离（GSD）到统一的2.5米，以提高图像质量和应用潜力，解决现有方法在反射率保真度、光谱一致性、空间对齐和幻觉抑制方面的不足。

**Method:** 本文提出了DiffFuSR，一个模块化的两阶段超分辨率管道：(i) 基于扩散的超分辨率（SR）模型，在NAIP和WorldStrat数据集的高分辨率RGB图像上训练，并与Sentinel-2特性协调一致；(ii) 一个学习型融合网络，利用超分辨率的RGB图像作为空间先验，对剩余的多光谱波段进行升采样。该方法引入了一个鲁棒的降级模型和对比降级编码器来支持盲SR。

**Result:** 在OpenSR基准测试中，所提出的SR管道在反射率保真度、光谱一致性、空间对齐和幻觉抑制方面优于当前的SOTA基线。此外，融合网络显著优于经典的全色锐化方法，能够准确增强Sentinel-2的20米和60米波段。

**Conclusion:** 该研究强调了协调学习与生成先验和融合策略相结合的强大能力，为Sentinel-2超分辨率创建了一个模块化框架。

> **ai_Abstract:** DiffFuSR是一个用于Sentinel-2图像超分辨率的模块化两阶段管道，旨在将所有12个光谱波段统一到2.5米GSD。它结合了基于扩散的SR模型（利用高分辨率RGB数据）和一个学习型融合网络（以超分辨率RGB图像为空间先验）来处理多光谱波段。该方法引入了鲁棒的降级模型和对比降级编码器以支持盲SR。实验证明，DiffFuSR在OpenSR基准上超越了现有SOTA方法，特别是在反射率保真度、光谱一致性、空间对齐和幻觉抑制方面表现出色，其融合网络也优于传统全色锐化方法，有效增强了20米和60米波段。

> **摘要翻译:** 本文介绍了DiffFuSR，一个模块化管道，用于将Sentinel-2 Level-2A图像的所有12个光谱波段超分辨率到一个统一的2.5米地面采样距离（GSD）。该管道包括两个阶段：(i) 一个基于扩散的超分辨率（SR）模型，该模型在来自NAIP和WorldStrat数据集的高分辨率RGB图像上进行训练，并与Sentinel-2特性进行协调以进行模拟；(ii) 一个学习型融合网络，该网络使用超分辨率的RGB图像作为空间先验，对剩余的多光谱波段进行升采样。我们引入了一个鲁棒的降级模型和对比降级编码器来支持盲SR。对所提出的SR管道在OpenSR基准上的广泛评估表明，所提出的方法在反射率保真度、光谱一致性、空间对齐和幻觉抑制方面优于当前的SOTA基线。此外，融合网络显著优于经典的图像融合方法，能够准确增强Sentinel-2的20米和60米波段。这项研究强调了协调学习与生成先验和融合策略相结合的强大能力，为Sentinel-2 SR创建了一个模块化框架。我们的代码和模型可在https://github.com/NorskRegnesentral/DiffFuSR找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [Enhanced Vehicle Speed Detection Considering Lane Recognition Using Drone Videos in California](https://arxiv.org/abs/2506.11239)
> *加州无人机视频中考虑车道识别的增强型车辆速度检测*

*Amirali Ataee Naeini, Ashkan Teymouri, Ghazaleh Jafarsalehi, Michael Zhang* | **Main category: cs.CV**

**Keywords:** 车辆速度检测, 车道识别, 无人机视频, YOLOv11, 交通监控

**Comment:** 7 pages

> **TL;DR:** 本研究提出了一种经过微调的YOLOv11模型，用于在加州无人机视频中实现高精度的车辆速度检测和车道识别，并区分车辆类型。

**AI_Comments:** 该研究的创新之处在于结合了车道识别和车辆分类，并针对无人机视频数据对YOLOv11进行了微调，以适应加州交通的特定需求。其重要性在于为高载客量车道监控和不同类型车辆的限速管理提供了更准确、实用的解决方案。成果数据（MAE和MSE）表明了其较高的实用价值和准确性，但未提及模型的实时性能或部署复杂度。

<details>
  <summary>Details</summary>

**Motivation:** 加州车辆数量增加，交通系统不足且测速摄像头稀少，使得有效的车辆速度检测成为必要。现有方法在准确性、车道识别和分类方面存在不足，特别是对于高载客量（HOV）车道监控和区分不同类型车辆的速度限制。

**Method:** 本研究引入了一个在近800张鸟瞰图上训练的微调YOLOv11模型，以提高车辆速度检测精度。所提出的系统能够识别每辆车的车道，并将车辆分为轿车和重型车辆两类。该模型还评估了无人机高度、感兴趣区域（ROI）距离和车辆速度等因素对检测准确性和速度测量的影响。系统使用从北加州收集的无人机视频进行评估。

**Result:** 微调后的YOLOv11模型取得了最佳性能，平均绝对误差（MAE）为0.97英里/小时，均方误差（MSE）为0.94 $\text{mph}^2$，其精度远高于先前的工作。

**Conclusion:** 该研究证明了所提出的微调YOLOv11模型在解决车辆速度检测和分类挑战方面的有效性，并满足交通监控和法规的特定要求。

> **ai_Abstract:** 本研究提出了一种基于无人机视频的增强型车辆速度检测系统，该系统利用微调的YOLOv11模型，在加州交通背景下实现车道识别和车辆分类（轿车与重型车辆）。该模型在提高检测精度方面表现出色，并考虑了无人机高度等因素的影响，在实际应用中具有高准确性。

> **摘要翻译:** 加州车辆数量的增加，由不完善的交通系统和稀疏的测速摄像头所驱动，使得有效的车辆速度检测变得必要。按车道检测车辆速度对于监控高载客量（HOV）车道速度、区分限速不同的轿车和重型车辆以及执行重型车辆的车道限制至关重要。尽管先前的工作利用YOLO（You Only Look Once）进行车辆速度检测，但它们通常缺乏准确性，未能识别车辆车道，并且提供的分类类别有限或不实用。本研究引入了一个经过微调的YOLOv11模型，该模型在近800张鸟瞰图上进行训练，以提高车辆速度检测精度，其精度远高于先前的工作。所提出的系统识别每辆车的车道，并将车辆分为两类：轿车和重型车辆。该模型旨在满足交通监控和法规的特定要求，同时评估了无人机高度、感兴趣区域（ROI）距离和车辆速度等因素对检测精度和速度测量的影响。利用从北加州收集的无人机视频评估了所提出的系统。经过微调的YOLOv11以0.97英里/小时的平均绝对误差（MAE）和0.94 $\text{mph}^2$的均方误差（MSE）取得了最佳性能，证明了其在解决车辆速度检测和分类挑战方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models](https://arxiv.org/abs/2506.11253)
> *将数据溯源的机器遗忘提升到基础模型的知识溯源*

*Yuwen Tan, Boqing Gong* | **Main category: cs.CV**

**Keywords:** 机器遗忘, 基础模型, 知识溯源, 数据溯源, 认知研究

**Comment:** 21 pages, 3 figures

> **TL;DR:** 该立场论文提出将基础模型的机器遗忘从数据溯源转向知识溯源，这一转变是基于实际需求和认知洞察。

**AI_Comments:** 创新点：该论文提出了一个关于基础模型机器遗忘的全新概念性转变，即从数据溯源转向知识溯源，解决了实际挑战并与人类认知过程进行了类比。重要性：对于实现大规模基础模型更实用、更直观的遗忘机制至关重要，特别是考虑到多样化的利益相关者需求和数据访问限制。局限性：作为一篇立场论文，它提出了一个概念并提供了一个案例研究，但并未提供知识溯源遗忘的实证结果或详细的算法实现。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器遗忘方法（数据溯源）无法满足基础模型（FMs）多样化的遗忘请求，因为请求方（如监管机构、企业用户、产品团队）无法访问FMs的海量训练数据。相反，这些方更方便地提出关于FM不应拥有的知识或能力的遗忘请求。此外，知识溯源的遗忘在认知上更符合人类大脑的遗忘方式。

**Method:** 提出将数据溯源的机器遗忘提升到基础模型的知识溯源。基于实际需求和认知研究的见解来支持这一立场。提供一个关于视觉-语言基础模型的具体案例研究以说明如何实例化知识溯源的机器遗忘范式。

**Result:** Not mentioned in abstract

**Conclusion:** 该论文倡导对基础模型采用知识溯源的机器遗忘，认为这比数据溯源更实用且更符合认知规律。通过一个案例研究，论文阐述了这种新范式的实例化方式。

> **ai_Abstract:** 这篇立场论文提出了一种基础模型（FMs）机器遗忘的范式转变，即从数据溯源转向知识溯源。这一转变的理由是：数据溯源在FMs中存在实际局限性，因为利益相关者无法访问大量的训练数据，他们更倾向于基于知识或能力来指定遗忘请求。此外，知识溯源的遗忘与人类遗忘的认知过程更为一致。论文还提供了一个关于视觉-语言FM的案例研究，以说明这种新范式的实例化。

> **摘要翻译:** 机器遗忘是指从AI模型中移除某些训练数据点及其影响（例如，当数据所有者撤销其允许模型从数据中学习的决定时）。在这篇立场论文中，我们提出将数据溯源的机器遗忘提升到基础模型的知识溯源。我们基于实际需求和认知研究的见解支持这一立场。从实践角度来看，数据溯源无法满足基础模型的多样化遗忘请求，这些请求可能来自监管机构、企业用户、产品团队等，他们无法访问基础模型的海量训练数据。相反，对于这些方而言，提出关于基础模型（不应）拥有的知识或能力的遗忘请求更为方便。从认知角度来看，知识溯源的遗忘比溯源单个训练数据点更符合人类大脑遗忘的方式。最后，我们提供了一个关于视觉-语言基础模型的具体案例研究，以说明遗忘者如何实例化知识溯源的机器遗忘范式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [401] [TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy](https://arxiv.org/abs/2506.11302)
> *TARDIS STRIDE：一个用于探索和自主性的时空道路图像数据集*

*Héctor Carrión, Yutong Bai, Víctor A. Hernández Castro, Kishan Panaganti, Ayush Zenith, Matthew Trang, Tony Zhang, Pietro Perona, Jitendra Malik* | **Main category: cs.CV**

**Keywords:** 时空数据集, 世界模型, 具身智能体, 道路图像, TARDIS

**Comment:** Computer Vision, Pattern Recognition, LLMs, Dataset, Data
  Augmentation

> **TL;DR:** 引入了STRIDE时空道路图像数据集，并使用TARDIS模型在其上进行基准测试，以解决世界模型中动态环境建模的挑战，展示了在多种智能体任务上的强大性能。

**AI_Comments:** 这项工作通过引入一个创新的时空道路图像数据集STRIDE，解决了世界模型在复杂动态环境建模方面的关键挑战。结合TARDIS这个基于Transformer的模型，其创新性在于能够统一处理空间和时间动态，并在一系列具身智能体任务上实现了鲁棒性能，这对于推动通用智能体和具身推理领域的发展具有重要意义。数据集和代码的公开也促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 世界模型旨在模拟环境以实现有效的智能体行为，但建模真实世界环境面临独特挑战，因为它们在空间和时间上都会动态变化。

**Method:** 引入了STRIDE（Spatio-Temporal Road Image Dataset for Exploration）时空道路图像数据集，将360度全景图像转化为相互关联的观测、状态和动作节点。利用这种结构，可以同时建模自我中心视图、位置坐标和运动指令在空间和时间上的关系。通过TARDIS（一个基于Transformer的生成式世界模型）对该数据集进行基准测试，TARDIS通过统一的自回归框架整合了空间和时间动态。

**Result:** TARDIS模型在STRIDE数据集上表现出强大的性能，涵盖了可控逼真图像合成、指令遵循、自主自控和最先进的地理定位等一系列智能体任务。

**Conclusion:** 这些结果为开发能够理解和操纵其物质环境时空方面、并具有增强具身推理能力的复杂通用智能体提供了一个有前景的方向。

> **ai_Abstract:** 该论文介绍了STRIDE时空道路图像数据集，旨在解决世界模型中真实世界动态环境的建模挑战。该数据集将360度全景图像组织成互联的观测、状态和动作节点，以便同时建模空间和时间维度上的关系。作者还提出了TARDIS，一个基于Transformer的生成式世界模型，并在STRIDE上对其进行基准测试。实验结果表明，TARDIS在可控图像合成、指令遵循、自主控制和地理定位等多种智能体任务上表现出色，为开发具有增强具身推理能力的通用智能体提供了新方向。

> **摘要翻译:** 世界模型旨在模拟环境并实现有效的智能体行为。然而，建模真实世界环境带来了独特的挑战，因为它们在空间和时间上都会动态变化。为了捕捉这些复合动态，我们引入了一个用于探索的时空道路图像数据集（STRIDE），它将360度全景图像转换为丰富的互联观测、状态和动作节点。利用这种结构，我们可以同时建模自我中心视图、位置坐标和运动指令在空间和时间上的关系。我们通过TARDIS对该数据集进行基准测试，TARDIS是一个基于Transformer的生成式世界模型，通过统一的自回归框架，在STRIDE上训练以整合空间和时间动态。我们在一系列智能体任务中展示了强大的性能，例如可控逼真图像合成、指令遵循、自主自控和最先进的地理定位。这些结果为开发能够理解和操纵其物质环境时空方面、并具有增强具身推理能力的复杂通用智能体提供了一个有前景的方向。训练代码、数据集和模型检查点可在https://huggingface.co/datasets/Tera-AI/STRIDE 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [Methods for evaluating the resolution of 3D data derived from satellite images](https://arxiv.org/abs/2506.11876)
> *评估卫星图像派生三维数据分辨率的方法*

*Christina Selby, Holden Bindl, Tyler Feldman, Andrew Skow, Nicolas Norena Acosta, Shea Hagstrom, Myron Brown* | **Main category: cs.CV**

**Keywords:** 卫星图像, 三维数据, 分辨率评估, 点云, 数字表面模型

**Comment:** 11 pages, 13 figures

> **TL;DR:** 本文介绍了评估从卫星图像获取的三维数据（点云、DSM、三维网格模型）分辨率的方法，并利用高分辨率激光雷达数据进行了自动化评估。

**AI_Comments:** 本文的创新之处在于提出了基于高分辨率机载激光雷达参考数据，对卫星图像派生的三维数据分辨率进行自动化评估的方法和工具。这对于提升大规模场景建模的效率和质量具有重要意义，尤其是在难以进行实地测量或机载采集的区域。

<details>
  <summary>Details</summary>

**Motivation:** 卫星图像派生的三维数据对于大范围场景建模或难以通过机载激光雷达/相机访问的区域至关重要。测量这些数据的分辨率对于确定任务效用和跟踪改进非常重要。

**Method:** 本文考虑了评估点云、数字表面模型和三维网格模型分辨率的方法。描述了三维度量评估工具和工作流程，这些工具和工作流程能够基于高分辨率参考机载激光雷达进行自动化评估。

**Result:** 本文展示了对不同质量数据进行分析的结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了评估从卫星图像获取的三维数据（包括点云、数字表面模型和三维网格模型）分辨率的方法。研究强调了分辨率测量对于确定数据效用和跟踪改进的重要性，并介绍了利用高分辨率机载激光雷达作为参考，实现自动化评估的三维度量工具和工作流程，同时展示了对不同质量数据进行分析的结果。

> **摘要翻译:** 从卫星图像派生的三维数据对于需要大范围覆盖或涉及机载激光雷达或相机无法到达位置的场景建模应用至关重要。测量这些数据的分辨率对于确定任务效用和跟踪改进非常重要。在这项工作中，我们考虑了评估点云、数字表面模型和三维网格模型分辨率的方法。我们描述了三维度量评估工具和工作流程，这些工具和工作流程能够基于高分辨率参考机载激光雷达进行自动化评估，并展示了对不同质量数据进行分析的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [409] [GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset](https://arxiv.org/abs/2506.11356)
> *GynSurg：一个全面的妇科腹腔镜手术数据集*

*Sahar Nasirihaghighi, Negin Ghamsarian, Leonie Peschek, Matteo Munari, Heinrich Husslein, Raphael Sznitman, Klaus Schoeffmann* | **Main category: cs.CV**

**Keywords:** 妇科腹腔镜手术, 数据集, 深度学习, 动作识别, 语义分割

**Comment:** 

> **TL;DR:** 引入GynSurg，一个大型多任务妇科腹腔镜手术数据集，旨在解决现有数据集的局限性，并推动该领域在计算机辅助干预和手术视频分析方面的发展。

**AI_Comments:** GynSurg数据集的创新之处在于其大规模、多样性和多任务注释，这解决了现有妇科腹腔镜手术数据集的普遍局限性。它对于推动手术训练、术中决策支持和术后分析等方面的智能系统发展具有重要意义。公开数据集的举措也将极大促进该领域的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有妇科腹腔镜手术数据集普遍存在规模小、任务重点窄或注释不够详细的局限性，限制了它们在全面、端到端工作流分析中的实用性。高质量、大规模的标注数据集对于深度学习在计算机辅助干预和手术视频分析中的进步至关重要。

**Method:** 本文引入了GynSurg，这是迄今为止最大、最多样化的妇科腹腔镜手术多任务数据集。GynSurg提供了跨多个任务的丰富注释，支持动作识别、语义分割、手术文档和新程序洞察的发现等应用。作者通过标准化训练协议对最先进的模型进行基准测试，以展示数据集的质量和多功能性，并公开了该数据集及其注释。

**Result:** GynSurg是迄今为止最大、最多样化的妇科腹腔镜手术多任务数据集，它提供了跨多个任务的丰富注释，支持多种计算机辅助应用。通过基准测试，验证了数据集的质量和多功能性。

**Conclusion:** GynSurg数据集的发布旨在解决现有妇科腹腔镜手术数据集的局限性，通过提供大规模、高质量、多任务的标注数据，加速该领域在智能系统开发和研究方面的进展。

> **ai_Abstract:** 本文介绍了GynSurg，一个针对妇科腹腔镜手术的大型、多样化且具有丰富注释的多任务数据集。该数据集旨在弥补现有妇科手术数据集在规模、任务范围和注释细节上的不足，以支持动作识别、语义分割、手术文档和新程序发现等计算机辅助应用。作者通过基准测试验证了数据集的质量和多功能性，并将其公开以促进该领域的研究进展。

> **摘要翻译:** 深度学习的最新进展已经改变了计算机辅助干预和手术视频分析，不仅推动了手术培训、术中决策支持和患者预后的改进，还推动了术后文档和手术发现的进步。这些发展的核心是大型、高质量标注数据集的可用性。在妇科腹腔镜手术中，手术场景理解和动作识别对于构建在手术过程中协助外科医生并在术后提供更深入分析的智能系统至关重要。然而，现有数据集通常受限于规模小、任务重点窄或注释不够详细，限制了它们在全面、端到端工作流分析中的实用性。为了解决这些局限性，我们引入了GynSurg，这是迄今为止最大、最多样化的妇科腹腔镜手术多任务数据集。GynSurg在多个任务中提供了丰富的注释，支持动作识别、语义分割、手术文档以及新程序洞察发现等应用。我们通过标准化训练协议对最先进的模型进行基准测试，展示了数据集的质量和多功能性。为了加速该领域的进展，我们公开GynSurg数据集及其注释。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [A Watermark for Auto-Regressive Image Generation Models](https://arxiv.org/abs/2506.11371)
> *自动回归图像生成模型的水印技术*

*Yihan Wu, Xuehao Cui, Ruibo Chen, Georgios Milis, Heng Huang* | **Main category: cs.CV**

**Keywords:** 图像水印, 自动回归模型, 重分词不匹配, C-reweight, 深度伪造检测

**Comment:** Technical report

> **TL;DR:** 针对图像生成模型的滥用问题，本文提出了一种名为C-reweight的新型无失真水印方法，通过解决重分词不匹配问题，提高了水印的可检测性，同时保持了图像质量。

**AI_Comments:** C-reweight的创新点在于其通过聚类策略解决了图像生成模型中特有的“重分词不匹配”问题，这是传统水印方法所面临的挑战。其无失真特性对于保持生成图像的视觉质量至关重要，使其在实际应用中更具吸引力。该方法对于提高图像生成内容的真实性和可信度具有重要意义，有助于应对深度伪造等滥用问题。

<details>
  <summary>Details</summary>

**Motivation:** 图像生成模型的快速发展带来了深伪、图像钓鱼攻击和虚假视觉证据等滥用风险，因此需要强大的真实性验证机制。然而，传统的统计水印技术在应用于图像生成模型时，由于“重分词不匹配”现象（即图像生成过程中原始序列和重新分词序列之间的差异）面临重大挑战。

**Method:** 本文提出了一种名为C-reweight的新型无失真水印方法，专门为图像生成模型设计。该方法利用基于聚类的策略，将同一聚类中的令牌等效处理，以减轻重分词不匹配问题，同时保持图像保真度。

**Result:** 在领先的图像生成平台上进行的广泛评估表明，C-reweight不仅保持了生成图像的视觉质量，而且比现有的无失真水印技术提高了可检测性。

**Conclusion:** C-reweight为安全可靠的图像合成设定了新标准。

> **ai_Abstract:** 本文提出了一种名为C-reweight的新型无失真水印方法，旨在解决图像生成模型中存在的滥用风险，如深度伪造。针对传统水印技术在图像领域遇到的“重分词不匹配”问题，C-reweight采用聚类策略，在保持图像视觉质量的同时，显著提高了水印的可检测性，为可信赖的图像合成提供了新途径。

> **摘要翻译:** 图像生成模型的快速发展彻底改变了视觉内容创作，使得为各种应用合成高度真实且上下文准确的图像成为可能。然而，滥用的可能性，例如深度伪造生成、基于图像的网络钓鱼攻击以及误导性视觉证据的伪造，强调了对强大真实性验证机制的需求。尽管传统的统计水印技术已被证明对自回归语言模型有效，但由于我们称之为“重分词不匹配”的现象（图像生成过程中原始序列和重新分词序列之间的差异），它们直接适应图像生成模型遇到了重大挑战。为了克服这一限制，我们提出了C-reweight，这是一种新颖的、无失真的水印方法，专门为图像生成模型设计。通过利用基于聚类的策略，该策略将同一聚类中的令牌等效处理，C-reweight减轻了重分词不匹配，同时保持了图像保真度。在领先的图像生成平台上进行的广泛评估表明，C-reweight不仅保持了生成图像的视觉质量，而且比现有的无失真水印技术提高了可检测性，为安全可靠的图像合成设定了新标准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [416] [Scalable Context-Preserving Model-Aware Deep Clustering for Hyperspectral Images](https://arxiv.org/abs/2506.11377)
> *高光谱图像的可伸缩上下文保持模型感知深度聚类*

*Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Nikos Deligiannis, Aleksandra Pižurica* | **Main category: cs.CV**

**Keywords:** 高光谱图像, 深度聚类, 子空间聚类, 上下文保持, 可伸缩

**Comment:** 

> **TL;DR:** 现有高光谱图像（HSI）的深度子空间聚类方法计算量大且缺乏有效的结构约束。本文提出一种可伸缩的单阶段深度聚类方法，联合捕获局部和非局部结构，实现了O(n)的复杂度并展现出优越的性能。

**AI_Comments:** 本文的核心创新在于其单阶段、联合优化的局部和非局部结构约束，这解决了以往方法计算效率低下和约束应用有限的问题。O(n)的复杂度是高光谱图像分析中可伸缩性方面的一个显著改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模型感知深度子空间聚类方法在处理高光谱图像时计算成本高（O(n^2)），通常只整合局部或非局部空间结构约束之一，且其结构约束未能有效监督整个聚类全过程。

**Method:** 本文提出了一种基于基表示的可伸缩、上下文保持的深度聚类方法。该方法采用单阶段设计，并联合捕获局部（通过空间平滑约束）和非局部（通过基于微聚类的方案）结构。这两个约束被联合优化以相互增强。

**Result:** 所提出的方法具有O(n)的时间和空间复杂度，使其适用于大规模高光谱图像数据。在真实世界数据集上的实验表明，该方法优于现有最先进的技术。

**Conclusion:** 本文成功开发了一种可伸缩且高效的高光谱图像深度聚类方法，该方法有效整合了局部和非局部结构信息，从而相较于现有方法提升了聚类性能。

> **ai_Abstract:** 本文提出了一种名为SCDSC的可伸缩、上下文保持的高光谱图像深度聚类方法。与以往计算密集且结构约束有限的两阶段方法不同，SCDSC是一种单阶段方法，它联合优化了局部（空间平滑）和非局部（基于微聚类）结构约束。这种设计实现了O(n)的复杂度，使其适用于大规模数据集，并且实验结果表明其性能优于现有的最先进技术。

> **摘要翻译:** 子空间聚类已广泛应用于高光谱图像（HSI）的无监督分析。近期模型感知深度子空间聚类方法常采用两阶段框架，涉及计算复杂度为O(n^2)的自表示矩阵，随后进行谱聚类。然而，这些方法计算密集，通常仅包含局部或非局部空间结构约束之一，并且其结构约束未能有效监督整个聚类过程。我们提出了一种基于基表示的可伸缩、上下文保持深度聚类方法，该方法联合捕获局部和非局部结构，以实现高效的HSI聚类。为保留局部结构（即子空间内的空间连续性），我们引入了空间平滑约束，使聚类预测与其空间滤波版本对齐。对于非局部结构（即光谱连续性），我们采用基于微聚类的方案，在组级别细化预测，鼓励光谱相似的像素属于同一子空间。值得注意的是，这两个约束被联合优化以相互增强。具体而言，我们的模型被设计为一种单阶段方法，其中结构约束应用于整个聚类过程。我们方法的时间和空间复杂度为O(n)，使其适用于大规模HSI数据。在真实世界数据集上的实验表明，我们的方法优于最先进的技术。我们的代码可在以下网址获取：https://github.com/lxlscut/SCDSC

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation](https://arxiv.org/abs/2506.11380)
> *增强多模态一致性和连贯性以实现文本-图像计划生成*

*Xiaoxin Lu, Ranran Haoran Zhang, Yusen Zhang, Rui Zhang* | **Main category: cs.CV**

**Keywords:** 文本-图像计划生成, 多模态一致性, 视觉连贯性, 迭代精炼, 基准数据集

**Comment:** 18 pages, 10 figures; Accepted to ACL 2025 Findings

> **TL;DR:** 本文提出一种新颖的框架，通过迭代生成和精炼文本-图像计划，旨在解决现有大型模型在生成文本-图像计划时面临的多模态一致性和视觉连贯性挑战。该框架为多种骨干模型提供即插即用改进，并在新建的基准数据集上通过实验验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了一个迭代式的文本-图像计划生成与精炼框架，有效解决了多模态一致性和视觉连贯性问题。其“即插即用”的特性使其具有良好的通用性，能够应用于多种现有大型模型。此外，构建新的基准数据集和评估指标也为后续研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注大型语言模型（LLM）的文本计划生成能力，而大型模型在提供文本-图像计划方面的潜力仍未得到充分研究。生成高质量的文本-图像计划面临两个主要挑战：确保两种模态之间的一致对齐和保持视觉步骤之间的连贯性。

**Method:** 本文提出一个新颖的框架，分步生成和精炼文本-图像计划。在每次迭代中，该框架会 (1) 根据预测历史起草下一个文本步骤；(2) 编辑上一个视觉步骤以获得下一个；(3) 提取类似PDDL的视觉信息；以及 (4) 使用提取的视觉信息精炼草稿。阶段 (4) 和 (2) 中产生的文本和视觉步骤将作为下一次迭代的输入。该方法可作为即插即用改进应用于多种骨干模型，如Mistral-7B、Gemini-1.5和GPT-4o。为评估有效性，作者收集了一个包含1,100个任务和其文本-图像对解决方案的新基准数据集，并设计和验证了一套新的指标来评估多模态一致性和连贯性。

**Result:** 广泛的实验结果表明，该方法在多种骨干模型（如Mistral-7B、Gemini-1.5和GPT-4o）上，相较于竞争基线，表现出有效性。

**Conclusion:** 该框架有效解决了文本-图像计划生成中多模态一致性和视觉连贯性的挑战，并能显著提升现有骨干模型的性能，为多模态计划生成领域提供了有效且通用的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的框架，旨在解决文本-图像计划生成中多模态一致性和视觉连贯性的挑战。该框架通过迭代地起草文本步骤、编辑视觉步骤、提取视觉信息并精炼草稿来生成高质量的文本-图像计划。该方法可作为即插即用模块应用于多种现有骨干模型。为评估其有效性，研究者构建了一个包含1100个任务的新基准数据集，并设计了新的评估指标。实验结果表明，该方法在多个骨干模型上均优于现有基线。

> **摘要翻译:** 人们通过涉及文本和图像的多种媒体了解日常任务计划。然而，大多数先前的研究只关注大型语言模型（LLM）的文本计划生成能力。大型模型在提供文本-图像计划方面的潜力仍未得到充分研究。生成高质量的文本-图像计划面临两个主要挑战：确保两种模态之间的一致对齐和保持视觉步骤之间的连贯性。为了应对这些挑战，我们提出了一种新颖的框架，它分步生成和精炼文本-图像计划。在每次迭代中，我们的框架会 (1) 根据预测历史起草下一个文本步骤；(2) 编辑上一个视觉步骤以获得下一个；(3) 提取类似PDDL的视觉信息；以及 (4) 使用提取的视觉信息精炼草稿。阶段 (4) 和 (2) 中产生的文本和视觉步骤将作为下一次迭代的输入。我们的方法为各种骨干模型（如Mistral-7B、Gemini-1.5和GPT-4o）提供了即插即用的改进。为了评估我们方法的有效性，我们收集了一个新的基准数据集，包含1,100个任务及其文本-图像对解决方案，涵盖11个日常主题。我们还设计并验证了一套新的指标来评估文本-图像计划中的多模态一致性和连贯性。广泛的实验结果表明，我们的方法在多种骨干模型上，相较于竞争基线，表现出有效性。我们的代码和数据可在 https://github.com/psunlpgroup/MPlanner 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [Dynamic Double Space Tower](https://arxiv.org/abs/2506.11394)
> *动态双空间塔*

*Weikai Sun, Shijie Song, Han Wang* | **Main category: cs.CV**

**Keywords:** 视觉问答, 空间关系, 格式塔视觉, 动态双向空间塔, 多模态模型

**Comment:** 

> **TL;DR:** 本文提出了一种动态双向空间塔，以取代现有VQA模型中的注意力机制，旨在增强模型对图像内容的空间关系理解和推理能力，并在视觉问答任务中取得了最先进的成果。

**AI_Comments:** 这项研究的创新之处在于提出了一种新颖的动态双向空间塔，它通过模仿人类格式塔视觉原理来处理空间关系，替代了传统的注意力机制。这种方法为VQA任务提供了一个强大的结构先验，有助于模型更好地理解图像内容的组织方式，而非仅仅关注像素层面的关联。其重要性体现在有效提升了模型在复杂推理，尤其是空间关系理解上的能力，并且显示出良好的通用性和SOTA性能，对未来的多模态学习研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉问答（VQA）方法在处理复杂推理场景时，由于跨模态交互不足以及难以捕获图像中实体的空间关系而面临困难。

**Method:** 本文提出了一种动态双向空间塔，旨在取代注意力机制以增强模型的推理能力和对空间关系的理解。该塔分为四层，根据人类格式塔视觉原理观察图像，为实体间的空间组织提供了强大的结构先验，使模型能够基于更有意义的感知单元进行判断，从而从“看图像”转变为“感知和组织图像内容”。

**Result:** 实验表明，所提出的模块可应用于任何其他多模态模型并取得先进结果，展现了其在空间关系处理方面的潜力。此外，使用该方法训练的多模态视觉问答模型July仅用3B参数就在空间关系问答数据集上取得了最先进的结果。

**Conclusion:** 本文提出的动态双向空间塔有效提升了视觉问答模型处理复杂推理和空间关系的能力，并在相关任务中达到了最先进的性能。

> **ai_Abstract:** 本文针对现有视觉问答（VQA）方法在复杂推理和空间关系理解上的不足，提出了一种动态双向空间塔。该塔取代了传统的注意力机制，并基于人类格式塔视觉原理分层观察图像，为实体空间组织提供了结构先验，使模型能更有效地感知和组织图像内容。实验证明，该模块可集成于多种多模态模型，并显著提升性能，其训练的July模型在空间关系VQA任务上取得了最先进的成果。

> **摘要翻译:** 视觉问答（VQA）任务需要同时理解图像内容和问题语义。然而，现有方法由于跨模态交互不足以及难以捕获图像中实体的空间关系，在处理复杂推理场景时常常遇到困难。我们研究了一种全新的方法来取代注意力机制，以增强模型的推理能力及其对空间关系的理解。具体来说，我们提出了一种动态双向空间塔，它根据人类格式塔视觉的原理分为四层来观察图像。这自然为实体之间的空间组织提供了强大的结构先验，使模型不再盲目搜索像素之间的关系，而是根据更有意义的感知单元进行判断，从而从“看图像”转变为“感知和组织图像内容”。大量的实验表明，我们的模块可以用于任何其他多模态模型并取得先进结果，展示了其在空间关系处理方面的潜力。同时，通过我们方法训练的多模态视觉问答模型July仅用3B参数就取得了最先进的结果，特别是在空间关系问答数据集上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [Stop learning it all to mitigate visual hallucination, Focus on the hallucination target](https://arxiv.org/abs/2506.11417)
> *停止学习所有信息以缓解视觉幻觉，专注于幻觉目标*

*Dokyoon Yoon, Youngsook Song, Woomyong Park* | **Main category: cs.CV**

**Keywords:** 视觉幻觉, 多模态大型语言模型, 偏好学习, 目标聚焦, 可靠性

**Comment:** Accepted to CVPR 2025

> **TL;DR:** 多模态大型语言模型（MLLM）常出现视觉幻觉。本文提出一种名为 \mymethod 的偏好学习方法，通过专注于幻觉发生的特定目标区域来有效减少幻觉，同时不影响整体性能。

**AI_Comments:** 这篇论文提出了一种创新的方法来缓解多模态大型语言模型（MLLM）中的视觉幻觉问题，引入了一种有针对性的偏好学习方法。它没有进行广泛的重新训练，而是有效地专注于特定的幻觉实例，这是一种提高事实准确性的巧妙方式。强调为有针对性的学习构建特定数据集，突显了解决 MLLM 可靠性关键问题的实用有效策略，这对于实际应用尤为重要。其在不降低整体能力的情况下提高性能的能力是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLM）在视觉-语言任务中经常出现幻觉问题，即生成输入图像中不存在的物体信息，这严重损害了模型在需要准确物体识别的实际应用中的可靠性。

**Method:** 本文提出了一种名为 \mymethod 的偏好学习方法，旨在通过关注幻觉发生的特定目标区域来缓解幻觉。为此，研究人员构建了一个包含幻觉响应、正确响应以及目标信息（即图像中存在的物体及其在响应中受幻觉影响的相应块位置）的数据集。通过将偏好学习方法限制在这些特定目标上，模型能够过滤掉不相关的信号，专注于纠正幻觉，从而生成更符合事实的响应。

**Result:** 实验结果表明，\mymethod
在多个视觉幻觉任务中有效减少了幻觉，提高了多模态大型语言模型（MLLM）的可靠性和性能，且未降低整体性能。

**Conclusion:** 通过将偏好学习集中在特定的幻觉目标上，所提出的方法能够有效缓解多模态大型语言模型中的视觉幻觉问题，从而在不损害整体模型性能的前提下提高其可靠性和事实准确性。

> **ai_Abstract:** 本文旨在解决多模态大型语言模型（MLLM）中常见的视觉幻觉问题，即模型生成图像中不存在物体的信息。为此，论文提出了一种名为 \mymethod 的偏好学习方法，通过聚焦于幻觉发生的特定目标区域来减轻幻觉。该方法通过构建一个包含幻觉响应、正确响应和目标物体信息的数据集来实现。通过将偏好学习专门应用于这些目标，该方法帮助模型过滤掉不相关信号，并生成更符合事实的输出。实验结果表明，\mymethod
有效减少了幻觉，提高了 MLLM 的可靠性和性能，且没有降低整体性能。

> **摘要翻译:** 多模态大型语言模型（MLLM）经常遭受幻觉问题，在视觉-语言任务中生成关于输入图像中不存在的物体的信息。这些幻觉尤其损害了模型在需要准确物体识别的实际应用中的可靠性。为了解决这一挑战，我们提出了 \mymethod，这是一种偏好学习方法，通过关注幻觉发生的特定目标区域来缓解幻觉。为了实现这一点，我们构建了一个数据集，其中包含幻觉响应、正确响应以及目标信息（即图像中存在的物体以及响应中受幻觉影响的相应块位置）。通过将偏好学习方法限制在这些特定目标上，模型可以过滤掉不相关的信号，并专注于纠正幻觉。这使得模型能够通过仅关注相关信息来生成更符合事实的响应。实验结果表明，\mymethod
在多个视觉幻觉任务中有效减少了幻觉，在不降低整体性能的情况下提高了 MLLM 的可靠性和性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [428] [Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization](https://arxiv.org/abs/2506.11430)
> *自动连接：具有直接偏好优化的连接保持RigFormer*

*Jingfeng Guo, Jian Liu, Jinnan Chen, Shiwei Mao, Changrong Hu, Puhua Jiang, Junlin Yu, Jing Xu, Qi Liu, Lixin Xu, Zhuo Chen, Chunchao Guo* | **Main category: cs.CV**

**Keywords:** 自动骨骼绑定, 连接保持, 直接偏好优化, 测地线特征, 拓扑准确性

**Comment:** 

> **TL;DR:** Auto-Connect通过连接保持的标记化、拓扑感知奖励和测地线特征，实现了更解剖学合理且变形优越的自动骨骼绑定。

**AI_Comments:** Auto-Connect的创新点在于其将连接性信息直接编码到标记化方案中，而非作为后处理步骤，这从根本上提升了自动骨骼绑定的拓扑准确性。结合DPO进行奖励引导的优化以及利用测地线特征改善蒙皮质量，使得该方法在生成解剖学合理且变形优越的骨骼结构方面表现出色，对计算机图形学和动画领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动骨骼绑定方法在预测骨骼位置或点时未能明确保留骨骼连接性，导致拓扑准确性不足，且难以保证高质量的蒙皮效果。

**Method:** Auto-Connect通过三方面实现：1. 采用连接保持的标记化方案，使用特殊标记定义关节子节点和各层级的端点，将连接信息直接整合到预测框架中，自动化连接关系，提升拓扑准确性。2. 引入拓扑感知奖励函数，量化拓扑正确性，并在后训练阶段通过奖励引导的直接偏好优化（DPO）进一步保证高质量拓扑。3. 结合隐式测地线特征进行潜在top-k骨骼选择，利用模型潜空间中的测地线距离信息智能确定每个顶点最有影响力的骨骼，显著改善蒙皮质量并减轻蒙皮伪影。

**Result:** 该模型能够持续生成更符合解剖学原理的骨骼结构，并具有优越的变形属性。具体表现为显著增强了拓扑准确性，并大幅改善了蒙皮质量，有效减轻了常见的蒙皮伪影。

**Conclusion:** Auto-Connect通过结合连接保持的标记化、奖励引导的微调以及测地线感知的骨骼选择，有效解决了自动骨骼绑定中连接性和拓扑准确性的挑战，从而生成高质量、解剖学合理的骨骼结构及优越的变形效果。

> **ai_Abstract:** Auto-Connect是一种新颖的自动绑定方法，通过创新的连接保持标记化方案，直接将骨骼连接信息整合到预测中，显著提升拓扑准确性。为确保高质量拓扑，该方法引入了拓扑感知奖励函数并结合直接偏好优化进行微调。此外，它利用隐式测地线特征优化骨骼选择，从而大幅改善蒙皮质量。综合这些技术，Auto-Connect能够生成更符合解剖学原理且变形性能优越的骨骼结构。

> **摘要翻译:** 我们引入了Auto-Connect，这是一种新颖的自动绑定方法，它通过连接保持的标记化方案明确地保留骨骼连接性。与以往预测表示为两个关节的骨骼位置或先预测点再确定连接性的方法不同，我们的方法采用特殊标记来定义每个关节子节点和每个层级的端点，从而有效地自动化连接关系。这种方法通过将连接信息直接集成到预测框架中，显著提高了拓扑准确性。为了进一步保证高质量的拓扑结构，我们实现了一个拓扑感知奖励函数，用于量化拓扑正确性，然后在后训练阶段通过奖励引导的直接偏好优化进行利用。此外，我们结合了隐式测地线特征进行潜在的top-k骨骼选择，这大大提高了蒙皮质量。通过利用模型潜在空间中的测地线距离信息，我们的方法智能地确定每个顶点最有影响力的骨骼，有效地减轻了常见的蒙皮伪影。这种连接保持的标记化、奖励引导的微调和测地线感知骨骼选择的结合，使我们的模型能够始终生成更符合解剖学原理的骨骼结构，并具有卓越的变形属性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [431] [Auditing Data Provenance in Real-world Text-to-Image Diffusion Models for Privacy and Copyright Protection](https://arxiv.org/abs/2506.11434)
> *在真实世界文本到图像扩散模型中审计数据溯源以保护隐私和版权*

*Jie Zhu, Leye Wang* | **Main category: cs.CV**

**Keywords:** 数据溯源, 文本到图像扩散模型, 黑盒审计, 隐私保护, 版权保护

**Comment:** Under Review; A user-level accuracy of 90% in a real-world auditing
  scenario

> **TL;DR:** 提出FSCA黑盒审计框架，用于文本到图像扩散模型的数据溯源，有效保护隐私和版权，且在真实场景中表现优异。

**AI_Comments:** FSCA的创新点在于其完全黑盒的审计能力，无需模型内部知识，这使其更适用于真实世界的应用场景。其在低样本量下达到高准确率的能力，显著提升了数据溯源审计的实用性，对文本到图像生成模型的隐私和版权保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像扩散模型依赖大规模数据集，导致版权合规和个人隐私泄露问题。现有审计方法假设不切实际（需模型内部知识）或评估不可靠。

**Method:** 提出FSCA（基于特征语义一致性的审计）完全黑盒审计框架，利用文本到图像扩散模型中的两种语义连接进行审计，无需内部知识。引入召回平衡策略和阈值调整策略。

**Result:** FSCA在LAION-mi和COCO数据集上表现优于八种SOTA基线方法，在各种指标和不同数据分布下均显示出优越性。在真实审计场景中，仅用10个样本/用户即可达到90%的用户级准确率。

**Conclusion:** FSCA框架在真实世界文本到图像扩散模型的数据溯源审计中表现出强大的潜力，有效解决了隐私和版权保护问题。

> **ai_Abstract:** 本文针对文本到图像扩散模型中因大规模数据集导致的隐私和版权问题，提出了一种名为FSCA的完全黑盒数据溯源审计框架。FSCA利用模型内部的语义连接，无需访问模型内部知识，即可有效审计数据来源。实验结果表明，FSCA在多个数据集和指标上均优于现有基线方法，并通过召回平衡和阈值调整策略，在真实世界场景中仅用少量样本即可达到90%的用户级准确率，展现了其在隐私和版权保护方面的强大应用潜力。

> **摘要翻译:** 文本到图像扩散模型自提出以来，因其令人印象深刻的生成能力而显著影响了内容创作。然而，这种能力依赖于从社交媒体等网络平台收集的大规模文本-图像数据集，这给版权合规和个人隐私泄露带来了巨大的挑战。尽管已经有一些工作致力于探索文本到图像扩散模型中的数据溯源审计方法，但现有工作存在不切实际的假设，即可以获取模型内部知识（例如中间结果），或者评估不可靠。为了填补这一空白，我们提出了一种完全黑盒的审计框架，称为基于特征语义一致性的审计（FSCA）。它利用文本到图像扩散模型中的两种语义连接进行审计，从而无需访问内部知识。为了证明我们FSCA框架的有效性，我们在LAION-mi数据集和COCO数据集上进行了广泛的实验，并与八种最先进的基线方法进行了比较。结果表明，FSCA在各种指标和不同数据分布下都超越了以前的基线方法，展示了我们FSCA的优越性。此外，我们引入了召回平衡策略和阈值调整策略，这些策略共同使得FSCA在真实世界审计场景中仅用10个样本/用户即可达到90%的用户级准确率，突显了其在真实世界应用中的强大审计潜力。我们的代码已在https://github.com/JiePKU/FSCA 上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models](https://arxiv.org/abs/2506.11436)
> *TAViS：基于基础模型的文本桥接音视频分割*

*Ziyang Luo, Nian Liu, Xuguang Yang, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Fahad Shahbaz Khan, Junwei Han* | **Main category: cs.CV**

**Keywords:** 音视频分割, 基础模型, 文本桥接, 跨模态对齐, 零样本

**Comment:** 

> **TL;DR:** TAViS是一个新框架，通过文本桥接设计，有效结合多模态基础模型（ImageBind）和分割基础模型（SAM2），解决了音视频分割中跨模态对齐的挑战，并在多种数据集和零样本设置下表现出色。

**AI_Comments:** TAViS的创新之处在于其“文本桥接”设计，有效地解决了不同基础模型（ImageBind和SAM2）之间特征空间不匹配导致的知识转移难题，并增强了跨模态语义对齐。通过引入文本作为通用桥梁，它不仅促进了多模态信息的融合，还提升了分割的精确性和零样本泛化能力，为未来的多模态感知研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 音视频分割（AVS）面临音视频模态有效对齐的根本挑战。现有方法虽然利用基础模型解决数据稀缺问题，但往往依赖单一模态知识或以现成方式组合模型，未能解决跨模态对齐挑战。

**Method:** 提出TAViS框架，耦合多模态基础模型（ImageBind）的知识用于跨模态对齐，以及分割基础模型（SAM2）用于精确分割。为解决SAM2和ImageBind之间知识转移困难以及仅使用分割损失监督不足的问题，引入了文本桥接设计，包含两个关键组件：1) 文本桥接混合提示机制，提供伪文本作为类别原型信息，同时保留音视频输入的模态特定细节；2) 对齐监督策略，利用文本作为桥梁来对齐音视频模态中的共享语义概念。

**Result:** 该方法在单源、多源、语义数据集上取得了优越的性能，并在零样本设置中表现出色。

**Conclusion:** TAViS通过其创新的文本桥接设计，成功解决了音视频分割中的跨模态对齐挑战，并有效结合了多模态和分割基础模型的优势，从而在多种AVS任务中实现了卓越的性能。

> **ai_Abstract:** TAViS是一个为音视频分割（AVS）设计的创新框架，旨在解决音频和视觉模态之间的跨模态对齐挑战。它通过巧妙地结合多模态基础模型（ImageBind）和分割基础模型（SAM2），并引入了独特的文本桥接设计来克服知识转移和监督不足的问题。该设计包含一个文本桥接混合提示机制和一种利用文本进行对齐的监督策略。实验结果表明，TAViS在多种AVS数据集和零样本设置下均表现出卓越的性能。

> **摘要翻译:** 音视频分割（AVS）面临着有效对齐音频和视觉模态的根本挑战。虽然最近的方法利用基础模型来解决数据稀缺问题，但它们往往依赖于单一模态知识或以现成的方式组合基础模型，未能解决跨模态对齐的挑战。在本文中，我们提出了TAViS，一个新颖的框架，它将多模态基础模型（ImageBind）的知识与分割基础模型（SAM2）的知识相结合，用于跨模态对齐和精确分割。然而，有效组合这些模型带来了两个关键挑战：由于SAM2和ImageBind不同的特征空间，知识难以转移；以及仅使用分割损失进行监督的不足。为了解决这些挑战，我们引入了一个文本桥接设计，包含两个关键组件：（1）一个文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态特定细节，以及（2）一个对齐监督策略，利用文本作为桥梁来对齐音视频模态中的共享语义概念。我们的方法在单源、多源、语义数据集上取得了优越的性能，并在零样本设置中表现出色。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [Uncertainty Awareness Enables Efficient Labeling for Cancer Subtyping in Digital Pathology](https://arxiv.org/abs/2506.11439)
> *不确定性感知实现数字病理中癌症亚型的高效标注*

*Nirhoshan Sivaroopan, Chamuditha Jayanga Galappaththige, Chalani Ekanayake, Hasindri Watawana, Ranga Rodrigo, Chamira U. S. Edussooriya, Dushan N. Wadduwage* | **Main category: cs.CV**

**Keywords:** 不确定性感知, 癌症亚型, 数字病理, 高效标注, 自监督学习

**Comment:** 

> **TL;DR:** 本文提出一种将不确定性感知融入自监督对比学习模型的方法，通过计算不确定性得分来选择性标注关键图像，仅用1-10%的标注数据即可在癌症亚型识别中达到最先进的性能，显著减少了对大量标注数据的需求。

**AI_Comments:** 该论文的创新点在于将不确定性感知引入自监督对比学习框架，有效解决了数字病理领域中专家标注数据稀缺的痛点。通过智能地选择最需要标注的数据，极大地提高了数据标注的效率，并降低了成本，这对于推动机器学习在临床病理诊断中的应用具有重要意义。该方法对于数据受限的应用场景具有普遍适用性。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习辅助的癌症亚型识别在数字病理学中具有前景，但模型训练需要大量专家标注，而这些标注通常有限且耗时，导致模型在预测时缺乏已知确定性。

**Method:** 本文将不确定性感知引入自监督对比学习模型。通过在每个训练周期计算证据向量来评估模型对其预测的置信度，并将由此得出的不确定性分数作为衡量标准，选择性地标注最关键的、需要进一步标注的图像，从而迭代地优化训练过程。

**Result:** 仅使用1-10%的策略性选择标注，该方法在基准数据集上的癌症亚型识别中达到了最先进的性能。

**Conclusion:** 该方法不仅策略性地指导标注过程，最大限度地减少了对大量标注数据集的需求，而且提高了分类的精度和效率。这对于标记数据可用性有限的环境特别有益，为数字病理学的未来研究和应用提供了有希望的方向。

> **ai_Abstract:** 本文提出了一种在数字病理学中实现高效癌症亚型标注的方法。通过将不确定性感知融入自监督对比学习模型，该方法能够计算模型对其预测的置信度，并利用不确定性分数选择性地标注最关键的图像。实验结果表明，仅需1-10%的策略性选择标注，即可在癌症亚型识别任务中达到最先进的性能，显著减少了对大量专家标注数据的依赖，同时提高了分类的精度和效率。

> **摘要翻译:** 机器学习辅助的癌症亚型识别是数字病理学中一个有前景的方向。然而，癌症亚型模型需要使用专家标注进行仔细训练，以便它们能够以已知确定性（或不确定性）进行推断。为此，我们将不确定性感知的概念引入到自监督对比学习模型中。这是通过在每个周期计算证据向量来实现的，该向量评估模型对其预测的置信度。然后，利用得出的不确定性分数作为指标，选择性地标注最关键的、需要进一步标注的图像，从而迭代地优化训练过程。仅使用1-10%的策略性选择标注，我们在基准数据集上的癌症亚型识别中达到了最先进的性能。我们的方法不仅策略性地指导标注过程，最大限度地减少了对大量标注数据集的需求，而且提高了分类的精度和效率。这一发展在标记数据可用性有限的环境中特别有益，为数字病理学的未来研究和应用提供了有希望的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [442] [On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving](https://arxiv.org/abs/2506.11472)
> *关于视觉语言模型在自动驾驶中对抗视觉感知攻击的天然鲁棒性*

*Pedram MohajerAnsari, Amir Salarpour, Michael Kühr, Siyu Huang, Mohammad Hamad, Sebastian Steinhorst, Habeeb Olufowobi, Mert D. Pesé* | **Main category: cs.CV**

**Keywords:** 视觉语言模型, 自动驾驶, 对抗鲁棒性, 车辆感知, 深度神经网络

**Comment:** 

> **TL;DR:** 本文介绍了车辆视觉语言模型（V2LM），一种专门用于自动驾驶感知的视觉语言模型，它在不进行对抗训练的情况下，对未知的对抗性攻击表现出卓越的天然鲁棒性，显著优于传统深度神经网络。

**AI_Comments:** 本文的创新点在于提出了V2LMs，并发现其在不依赖对抗训练的情况下，对未知对抗性攻击具有天然的鲁棒性，这解决了传统对抗防御机制泛化性差和损害正常准确性的问题。V2LMs在自动驾驶安全领域具有重要意义，为开发更稳健的感知系统提供了新思路。同时，Tandem模式的引入也兼顾了实际部署中的内存效率。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车（AVs）依赖深度神经网络（DNNs）执行交通标志识别、自动车道居中和车辆检测等关键任务。然而，这些模型容易受到攻击，导致错误分类并危及安全。传统的防御机制（如对抗训练）通常会降低正常准确性，并且无法泛化到未知的攻击。

**Method:** 本文引入了车辆视觉语言模型（V2LMs），这是一种经过微调的视觉语言模型，专门用于自动驾驶感知。研究评估了两种部署策略：Solo模式（单个V2LM处理特定感知任务）和Tandem模式（单个统一的V2LM同时微调用于多个任务）。此外，还探讨了将V2LMs作为并行组件集成到AV感知中，以增强对对抗性威胁的弹性。

**Result:** 实验结果表明，在攻击下，传统DNN的性能下降33%至46%，而V2LMs在对抗条件下的准确性平均下降不到8%。Tandem模式在实现与Solo模式相当的鲁棒性的同时，还提供了一种内存效率更高的替代方案。

**Conclusion:** V2LMs为构建更安全、更具弹性的自动驾驶感知系统提供了一条有前景的途径。

> **ai_Abstract:** 本文提出了一种名为车辆视觉语言模型（V2LMs）的新型模型，旨在提高自动驾驶感知系统对视觉感知攻击的鲁棒性。与传统深度神经网络（DNNs）相比，V2LMs无需对抗训练即可展现出卓越的天然鲁棒性，在对抗条件下能保持更高的准确性。研究评估了V2LMs的两种部署模式（Solo和Tandem），发现它们在遭受攻击时性能下降远小于DNNs，并且Tandem模式在保持鲁棒性的同时更节省内存。这表明V2LMs是构建更安全、更具弹性的自动驾驶感知系统的有效方案。

> **摘要翻译:** 自动驾驶汽车（AVs）依赖深度神经网络（DNNs）执行交通标志识别（TSR）、自动车道居中（ALC）和车辆检测（VD）等关键任务。然而，这些模型容易受到攻击，导致错误分类并危及安全。传统的防御机制，包括对抗训练，通常会降低正常准确性，并且无法泛化到未知的攻击。在这项工作中，我们引入了车辆视觉语言模型（V2LMs），这是一种经过微调的视觉语言模型，专门用于AV感知。我们的研究结果表明，V2LMs在不需要对抗训练的情况下，固有地对未知攻击表现出卓越的鲁棒性，在对抗条件下保持比传统DNNs显著更高的准确性。我们评估了两种部署策略：Solo模式，即单个V2LM处理特定的感知任务；以及Tandem模式，即单个统一的V2LM同时针对多个任务进行微调。实验结果显示，DNNs在攻击下性能下降33%至46%，而V2LMs在对抗条件下的准确性平均下降不到8%。Tandem模式进一步提供了一种内存效率更高的替代方案，同时实现了与Solo模式相当的鲁棒性。我们还探讨了将V2LMs作为并行组件集成到AV感知中，以增强对对抗性威胁的弹性。我们的结果表明，V2LMs为构建更安全、更具弹性的AV感知系统提供了一条有前景的途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [FAME: A Lightweight Spatio-Temporal Network for Model Attribution of Face-Swap Deepfakes](https://arxiv.org/abs/2506.11477)
> *FAME：一种用于换脸深度伪造模型归因的轻量级时空网络*

*Wasim Ahmad, Yan-Tsung Peng, Yuan-Hao Chang* | **Main category: cs.CV**

**Keywords:** 深度伪造, 模型归因, 换脸, 时空网络, 数字取证

**Comment:** 

> **TL;DR:** FAME是一种轻量级时空网络，用于识别换脸深度伪造视频的生成模型，在准确性和运行时效率上优于现有方法。

**AI_Comments:** FAME的创新之处在于其专注于“模型归因”这一未充分探索的领域，而非仅仅二元检测。其轻量级和高效的设计，结合时空注意力机制，使其在实际应用中更具可行性。在准确性和运行时效率上的提升，使其成为一个有潜力的数字取证工具。

<details>
  <summary>Details</summary>

**Motivation:** 换脸深度伪造视频的广泛出现对数字安全、隐私和媒体完整性构成日益增长的风险，因此需要有效的取证工具来识别此类操纵的来源。尽管大多数现有研究主要集中在二元深度伪造检测上，但模型归因（确定哪个生成模型产生了给定的深度伪造）仍未得到充分探索。

**Method:** 论文引入了FAME（Fake Attribution via Multilevel Embeddings），一个轻量级且高效的时空框架，旨在捕获特定于不同换脸模型的细微生成伪影。FAME集成了空间和时间注意力机制，以提高归因准确性，同时保持计算效率。

**Result:** FAME在Deepfake Detection and Manipulation (DFDM)、FaceForensics++和FakeAVCeleb三个具有挑战性和多样性的数据集上进行了评估。结果表明，FAME在准确性和运行时效率方面始终优于现有方法。

**Conclusion:** FAME作为一种轻量级、高效且准确的换脸深度伪造模型归因工具，具有在现实世界取证和信息安全应用中部署的潜力。

> **ai_Abstract:** 本文提出FAME，一个轻量级时空网络，用于对换脸深度伪造视频进行模型归因。FAME通过整合空间和时间注意力机制，有效捕获不同生成模型的细微伪影。在多个数据集上的评估表明，FAME在准确性和效率上均优于现有方法，展现了其在数字取证和信息安全领域的应用前景。

> **摘要翻译:** 换脸深度伪造视频的广泛出现对数字安全、隐私和媒体完整性构成了日益增长的风险，因此需要有效的取证工具来识别此类操纵的来源。尽管大多数先前的研究主要集中在二元深度伪造检测上，但模型归因——确定是哪个生成模型产生了给定的深度伪造——这一任务仍未得到充分探索。在本文中，我们引入了FAME（Fake Attribution via Multilevel Embeddings），这是一个轻量级且高效的时空框架，旨在捕获特定于不同换脸模型的细微生成伪影。FAME集成了空间和时间注意力机制，以提高归因准确性，同时保持计算效率。我们在三个具有挑战性和多样性的数据集上评估了我们的模型：Deepfake Detection and Manipulation (DFDM)、FaceForensics++和FakeAVCeleb。结果表明，FAME在准确性和运行时效率方面始终优于现有方法，突显了其在现实世界取证和信息安全应用中部署的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [Environmental Change Detection: Toward a Practical Task of Scene Change Detection](https://arxiv.org/abs/2506.11481)
> *环境变化检测：迈向实用的场景变化检测任务*

*Kyusik Cho, Suhan Woo, Hongje Seong, Euntai Kim* | **Main category: cs.CV**

**Keywords:** 环境变化检测, 场景变化检测, 视角不对齐, 变化检测, 语义表示

**Comment:** Preprint. Under review

> **TL;DR:** 本文提出环境变化检测（ECD），旨在解决传统场景变化检测（SCD）中参考图像视角不匹配的实际限制，并为此引入了一种新颖的框架。

**AI_Comments:** 本文通过引入环境变化检测（ECD），解决了传统场景变化检测（SCD）中一个重要的实际局限性，即对参考图像完美对齐的不现实假设。其创新之处在于能够利用非对齐的、来自大规模未经整理数据库的图像作为环境线索进行变化检测，这更符合现实世界的应用场景。所提出的框架通过聚合多个参考候选的语义信息来处理视角不对齐和有限视场问题，展现了其在复杂环境下的强大适应性。该方法在性能上显著超越了现有技术，并能与理想设置媲美，预示着其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的场景变化检测（SCD）假设参考图像与查询图像具有理想的匹配视角，这在实际应用中是不现实的，因为可用的参考图像通常是来自附近视角的，而非完全相同的视角。本文的动机是解决这一实际限制，将场景变化检测推向一个更实用的任务。

**Method:** 本文引入了环境变化检测（ECD），其核心在于避免不切实际的对齐查询-参考图像对，并仅依赖于环境线索。通过一个大规模的、未经整理的图像数据库提供这些线索。为此，提出了一种新颖的框架，该框架能够共同理解空间环境并检测变化，通过利用多个参考候选并聚合语义丰富的表示来处理视角不对齐和有限视场（FOV）覆盖的限制。

**Result:** 该框架在为ECD重建的三个标准基准数据集上进行了评估，结果显示其显著优于最先进方法的简单组合，同时实现了与预言机设置相当的性能。

**Conclusion:** 本文成功地将场景变化检测推向了一个更实用的任务（ECD），通过解决视角不对齐和有限视场的问题，并提出了一种有效的新框架，展示了其优越的性能。

> **ai_Abstract:** 本文提出了环境变化检测（ECD），旨在克服传统场景变化检测（SCD）中对完美对齐参考图像的不切实际假设。ECD通过利用未经整理的大规模图像数据库中的环境线索，解决视角不对齐和有限视场覆盖的问题。论文提出了一种新颖的框架，该框架能够联合理解空间环境并检测变化，通过聚合多个参考候选的语义丰富表示来提高变化检测的鲁棒性。实验证明，该框架在重建的基准数据集上显著优于现有方法，并能达到与理想设置相当的性能。

> **摘要翻译:** 人类不会记住所有事物。因此，人类通过探索过去的图像来识别场景变化。然而，可用的过去（即参考）图像通常代表当前（即查询）场景的附近视角，而不是完全相同的视角。尽管存在这种实际限制，传统的场景变化检测（SCD）已在一种理想化的设置下形式化，即每个查询都有匹配视角的参考图像可用。在本文中，我们将这个问题推向一个实际任务，并引入环境变化检测（ECD）。ECD的一个关键方面是避免不切实际的对齐查询-参考对，并仅依赖环境线索。受现实世界实践的启发，我们通过一个未经整理的大规模图像数据库提供这些线索。为了解决这项新任务，我们提出了一种新颖的框架，该框架共同理解空间环境并检测变化。主要思想是，由于视角不对齐和有限的视场（FOV）覆盖范围，在查询和参考之间相同空间位置的匹配可能导致次优解决方案。我们通过利用多个参考候选并聚合语义丰富的表示来进行变化检测来处理这一限制。我们在为ECD重建的三个标准基准数据集上评估了我们的框架，并显著优于最先进方法的简单组合，同时实现了与预言机设置相当的性能。代码将在接受后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [449] [Composite Data Augmentations for Synthetic Image Detection Against Real-World Perturbations](https://arxiv.org/abs/2506.11490)
> *复合数据增强用于对抗真实世界扰动的合成图像检测*

*Efthymia Amarantidou, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis* | **Main category: cs.CV**

**Keywords:** 合成图像检测, 数据增强, 遗传算法, 真实世界扰动, 信息完整性

**Comment:** EUSIPCO 2025 (33rd European Signal Processing Conference)

> **TL;DR:** 鉴于AI生成的合成图像对信息完整性的威胁以及现有检测方案在真实扰动下的不足，本文通过探索数据增强组合、利用遗传算法和引入双标准优化，显著提升了合成图像检测模型在真实世界扰动下的性能，最佳模型平均精度提高22.53%。

**AI_Comments:** 本文的创新点在于将数据增强、遗传算法和双标准优化相结合，以解决合成图像检测在真实世界扰动下的性能瓶颈。其重要性在于直接应对了AI生成图像对信息完整性构成的威胁，并通过量化指标展示了显著的性能提升，这对于提升合成图像检测在实际应用中的鲁棒性和有效性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可访问的生成式AI工具使任何人都能创建和传播合成图像，常带有误导意图，对在线信息完整性构成重大威胁。大多数现有合成图像检测（SID）解决方案在经过压缩和其他操作的互联网来源图像上表现不佳。

**Method:** 本研究通过探索数据增强组合、利用遗传算法进行最优增强选择，并引入双标准优化方法来增强合成图像检测（SID）模型。

**Result:** 这些方法显著提高了模型在真实世界扰动下的性能。最佳模型相比没有增强的模型，平均精度（mAP）提高了+22.53%。

**Conclusion:** 本研究的发现为开发能够识别不同质量和变换下合成图像的检测模型提供了有价值的见解。

> **ai_Abstract:** 本文旨在解决现有合成图像检测（SID）解决方案在真实世界扰动（如压缩和变换）下的性能不足问题。研究通过探索复合数据增强策略，结合遗传算法以选择最优增强组合，并引入双标准优化方法，显著提升了SID模型在面对真实世界扰动时的性能。实验结果显示，所提出的方法使最佳模型的平均精度（mAP）相较于无增强模型提高了22.53%，为开发更鲁棒的合成图像检测模型提供了有效途径。

> **摘要翻译:** 可访问的生成式AI工具的出现使得任何人都能在社交媒体上创建和传播合成图像，这些图像通常带有误导意图，从而对在线信息完整性构成重大威胁。大多数现有的合成图像检测（SID）解决方案在源自互联网的生成图像上表现不佳，因为这些图像经常受到压缩和其他操作的改变。为了解决这个问题，我们的研究通过探索数据增强组合、利用遗传算法进行最优增强选择以及引入双标准优化方法来增强SID。这些方法显著提高了模型在真实世界扰动下的性能。我们的研究结果为开发能够识别不同质量和变换下合成图像的检测模型提供了有价值的见解，其中表现最佳的模型相比没有增强的模型，平均精度提高了+22.53%。代码实现可在github.com/efthimia145/sid-composite-data-augmentation获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [451] [Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation](https://arxiv.org/abs/2506.11493)
> *在无监督域适应的提示学习中保留聚类*

*Tung-Long Vuong, Hoang Phan, Vy Vo, Anh Bui, Thanh-Toan Do, Trung Le, Dinh Phung* | **Main category: cs.CV**

**Keywords:** 无监督域适应, 提示学习, 多模态模型, 最优传输, 聚类

**Comment:** 

> **TL;DR:** 本研究提出了一种新方法，通过利用视觉和文本嵌入的几何特性和聚类行为，并结合最优传输理论，来强化伪标签并改进无监督域适应中的目标提示学习，从而克服了现有方法中目标域视觉嵌入分布偏差的局限性。

**AI_Comments:** 本研究的创新点在于它识别并解决了多模态预训练模型在UDA中伪标签质量下降的问题，通过深入挖掘视觉和文本嵌入的内在几何结构和聚类特性。其引入最优传输理论来强制聚类行为，提供了一种新颖且有效的方法来提升目标域中的特征对齐和伪标签的可靠性，这对于改进基于提示学习的UDA至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有利用多模态预训练模型（如CLIP）进行无监督域适应（UDA）的方法，其训练机制存在一个关键限制：目标域中的视觉嵌入分布可能偏离预训练模型中的视觉嵌入分布，导致来自类别描述的信号产生误导。这限制了伪标签和自训练机制的有效性。

**Method:** 本研究通过利用视觉和文本嵌入的几何特性来强化伪标签并促进目标提示学习。具体方法包括：1. 基于源和目标视觉嵌入之间的关系，直接利用源提示的参考预测。2. 基于最优传输理论，将视觉和文本嵌入中观察到的强聚类行为转化为一种新策略，以强制文本嵌入中的聚类特性，进一步增强目标域中的对齐。

**Result:** 实验和消融研究验证了所提出方法的有效性，表明其在性能上表现优异，并在表示方面提高了目标提示的质量。

**Conclusion:** 通过利用视觉和文本嵌入的几何特性和聚类行为，并应用最优传输理论，本研究提出的方法有效地强化了伪标签并改进了目标提示学习，从而在无监督域适应中取得了卓越的性能。

> **ai_Abstract:** 本论文针对无监督域适应（UDA）中多模态预训练模型（如CLIP）存在的局限性，即目标域视觉嵌入分布可能导致误导信号的问题，提出了一种新颖的方法。该方法通过利用视觉和文本嵌入的几何特性和强聚类行为，并结合最优传输理论，强化伪标签并改进目标提示学习。具体而言，它利用源提示的参考预测并强制文本嵌入的聚类特性。实验结果验证了该方法的有效性，显示出优越的性能和更高质量的目标提示表示。

> **摘要翻译:** 最近利用多模态预训练模型如CLIP进行无监督域适应（UDA）的方法，通过利用在多样图像-文本数据集上广泛预训练学习到的丰富语义知识和鲁棒视觉表示，在弥合域差距和提高泛化性方面显示出巨大潜力。尽管这些方法在基准测试中取得了最先进的性能，但大部分改进源于基础伪标签（CLIP零样本预测）和自训练机制。因此，训练机制表现出一个关键限制，即目标域中的视觉嵌入分布可能偏离预训练模型中的视觉嵌入分布，导致来自类别描述的误导信号。本研究引入了一种新的解决方案，通过利用现有方法所忽视的视觉和文本嵌入的几何特性，来强化这些伪标签并促进目标提示学习。我们首先建议根据源和目标视觉嵌入之间的关系直接利用参考预测（来自源提示）。我们随后表明，在预训练的多模态模型中，视觉和文本嵌入之间存在强烈的聚类行为。基于最优传输理论，我们将这一见解转化为一种新颖的策略，以强制文本嵌入中的聚类特性，进一步增强目标域中的对齐。我们的实验和消融研究验证了所提出方法的有效性，证明了其卓越的性能和目标提示在表示方面质量的提高。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [454] [Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs](https://arxiv.org/abs/2506.11515)
> *Manager：在双塔视觉语言模型和多模态大语言模型中聚合单模态专家知识*

*Xiao Xu, Libo Qin, Wanxiang Che, Min-Yen Kan* | **Main category: cs.CV**

**Keywords:** 视觉语言模型, 多模态大语言模型, 双塔架构, 单模态专家, Manager

**Comment:** Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology (TCSVT). June 2025. DOI:
  https://doi.org/10.1109/TCSVT.2025.3578266

> **TL;DR:** 本文提出了Manager，一个轻量、高效的插件，用于自适应聚合预训练单模态专家知识，以提升VL对齐和融合。它在双塔VLM（ManagerTower）和MLLM（LLaVA-OV-Manager）架构中均表现出色，解决了现有方法的局限性。

**AI_Comments:** 本文提出了一个创新的“Manager”插件，通过聚合不同层次的单模态专家知识，有效提升了视觉语言模型的性能。其创新点在于解决了现有模型在单模态表示利用效率低下的问题，并展示了其在两种主流架构（双塔VLM和MLLM）上的普适性和有效性。尤其是在MLLM上的应用，显示了其在处理多分辨率和零样本任务上的潜力。该方法作为一个轻量级插件，具有较高的实用价值和部署潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有双塔视觉语言模型（如BridgeTower）在层级利用单模态表示、灵活利用不同层次的单模态语义知识方面效率低下，并且局限于传统低分辨率数据集的评估。

**Method:** 本文提出了Manager，一个轻量级、高效且有效的插件，能够自适应地聚合来自不同级别预训练单模态专家知识。在双塔VLM架构下，引入了ManagerTower，在每个跨模态层中加入Manager。此外，该方法扩展到多模态大语言模型（MLLM）架构，提出了LLaVA-OV-Manager，并通过深入分析揭示Manager和多网格算法可以作为插件从深度和宽度两个正交视角捕获更多视觉细节。

**Result:** ManagerTower在有无VL预训练的情况下，均超越了现有强基线模型，并在4个下游VL任务上取得了优异性能。LLaVA-OV-Manager显著提升了LLaVA-OV在20个下游数据集上的零样本性能，涵盖不同能力类别、图像和分辨率，无论是否启用多网格算法。Manager和多网格算法的协同作用可以缓解多网格算法引起的语义模糊并进一步提高性能。

**Conclusion:** Manager是一个有效的插件，通过自适应聚合单模态专家知识，显著提升了双塔VLM和MLLM的性能，解决了现有模型在单模态表示利用和语义知识利用方面的局限性。它通过捕获更丰富的视觉细节来改进视觉表示，并能与多网格算法协同工作。

> **ai_Abstract:** 本文提出了一种名为Manager的轻量级、高效插件，旨在解决现有双塔视觉语言模型在单模态表示利用和语义知识利用方面的不足。Manager通过自适应聚合预训练单模态专家知识，促进更全面的视觉语言对齐和融合。该插件应用于双塔VLM架构形成ManagerTower，在多个下游任务上超越了现有基线。此外，Manager还扩展到多模态大语言模型架构，形成了LLaVA-OV-Manager，显著提升了LLaVA-OV的零样本性能。研究表明，Manager和多网格算法能协同改进视觉表示，捕获多样化视觉细节，并缓解语义模糊。

> **摘要翻译:** 双塔视觉语言模型（VLMs）在各种下游视觉语言任务中表现出强大的性能。虽然BridgeTower通过在编码器之间构建桥梁进一步提升了性能，但它存在以下问题：(i) 单模态表示的逐层利用效率低下；(ii) 限制了对不同级别单模态语义知识的灵活利用；以及 (iii) 仅限于在传统低分辨率数据集上评估双塔VLM架构。在这项工作中，我们提出了Manager，一个轻量级、高效且有效的插件，它能自适应地聚合来自不同级别预训练单模态专家知识，以促进更全面的视觉语言对齐和融合。首先，在双塔VLM架构下，我们引入了ManagerTower，这是一种新颖的VLM，在每个跨模态层中引入了Manager。无论是否进行视觉语言预训练，ManagerTower都优于先前的强基线模型，并在4个下游视觉语言任务上取得了卓越性能。此外，我们将探索扩展到最新的多模态大语言模型（MLLM）架构。我们证明，LLaVA-OV-Manager显著提升了LLaVA-OV在20个下游数据集上的零样本性能，涵盖不同类别的能力、图像和分辨率，无论是否启用多网格算法。深入分析表明，我们的Manager和多网格算法都可以被视为一个插件，通过从两个正交视角（深度和宽度）捕获更多样化的视觉细节来改善视觉表示。它们的协同作用可以缓解多网格算法引起的语义模糊，并进一步提高性能。代码和模型可在https://github.com/LooperXX/ManagerTower获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [457] [GNSS-inertial state initialization by distance residuals](https://arxiv.org/abs/2506.11534)
> *基于距离残差的GNSS-惯性状态初始化*

*Samuel Cerezo, Javier Civera* | **Main category: cs.CV**

**Keywords:** GNSS-惯性, 状态初始化, 距离残差, Hessian矩阵, 传感器融合

**Comment:** 8 pages, 8 figures, RA-L submission

> **TL;DR:** 本文提出了一种新的GNSS-惯性初始化策略，通过延迟使用全局GNSS测量，转而先利用GNSS相对距离残差进行初始化，并在信息充足时切换到全局测量，从而实现更准确和鲁棒的初始化。

**AI_Comments:** 本文的创新点在于其延迟使用全局GNSS测量并利用相对距离残差进行初始化的策略，这有效解决了初期信息不足的问题。引入Hessian矩阵奇异值作为切换判据，为确定最佳切换时机提供了量化依据，提升了初始化的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传感器平台状态初始化具有挑战性，因为有限的初始测量信息量有限，可能导致初始估计不佳，并在非线性优化过程中收敛到局部最小值。

**Method:** 本文提出一种新的GNSS-惯性初始化策略，延迟使用全局GNSS测量，直到有足够信息准确估计GNSS和惯性坐标系之间的变换。该方法最初依赖于GNSS相对距离残差。为确定切换到全局测量的最佳时机，引入了一个基于Hessian矩阵奇异值演变的判据。

**Result:** 在EuRoC和GVINS数据集上的实验表明，该方法始终优于从一开始就使用全局GNSS数据的朴素策略，产生了更准确和鲁棒的初始化。

**Conclusion:** 通过延迟使用全局GNSS测量并利用GNSS相对距离残差，本方法能够实现更准确和鲁棒的GNSS-惯性状态初始化。

> **ai_Abstract:** 本文提出了一种创新的GNSS-惯性状态初始化方法，旨在解决传统初始化中信息不足导致估计不佳和局部最小值的问题。该方法在初期利用GNSS相对距离残差进行初始化，并根据Hessian矩阵奇异值的演变来判断何时切换到全局GNSS测量。实验结果表明，与直接使用全局GNSS数据的传统方法相比，该方法能提供更精确和鲁健的初始估计。

> **摘要翻译:** 传感器平台的状态初始化可能具有挑战性，因为有限的初始测量通常携带有限的信息，导致初始估计不佳，并可能在非线性优化过程中收敛到局部最小值。本文提出了一种新颖的GNSS-惯性初始化策略，该策略延迟使用全局GNSS测量，直到有足够的信息来准确估计GNSS和惯性框架之间的变换。相反，该方法最初依赖于GNSS相对距离残差。为了确定切换到全局测量的最佳时刻，我们引入了一个基于Hessian矩阵奇异值演变的判据。在EuRoC和GVINS数据集上的实验表明，我们的方法始终优于从一开始就使用全局GNSS数据的朴素策略，产生了更准确和鲁棒的初始化。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [461] [FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation](https://arxiv.org/abs/2506.11543)
> *FIMA-Q：基于Fisher信息矩阵近似的视觉Transformer后训练量化*

*Zhuguanyu Wu, Shihe Wang, Jiayi Zhang, Jiaxin Chen, Yunhong Wang* | **Main category: cs.CV**

**Keywords:** 后训练量化, 视觉Transformer, Fisher信息矩阵, 低比特量化, 模型压缩

**Comment:** CVPR 2025 Highlight

> **TL;DR:** FIMA-Q是一种新的视觉Transformer后训练量化方法，通过Fisher信息矩阵近似提高了低比特量化下的精度。

**AI_Comments:** 这篇论文通过引入Fisher信息矩阵近似（FIMA）来改进视觉Transformer的后训练量化，其创新点在于将KL散度与FIM联系起来，并提出了高效的DPLR-FIM近似。这解决了现有PTQ方法在低比特量化下精度显著下降的关键问题，对于部署轻量级ViT模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉Transformer后训练量化方法在低比特量化下仍存在显著的精度下降问题。

**Method:** 本文提出了一种名为FIMA-Q的新型后训练量化（PTQ）方法，旨在解决现有PTQ方法在低比特量化下严重的精度下降问题。该方法通过分析传统Hessian近似的局限性，建立了KL散度与Fisher信息矩阵（FIM）的联系，从而加速量化损失的计算。此外，FIMA-Q引入了高效的FIM近似方法DPLR-FIM（基于对角加低秩原理），并构建了最终的量化损失。

**Result:** 在各种视觉任务和ViT架构上进行的大量实验表明，FIMA-Q相比现有SOTA方法显著提高了精度，尤其是在低比特量化情况下。

**Conclusion:** FIMA-Q通过高效的Fisher信息矩阵近似，有效解决了视觉Transformer在低比特后训练量化中的精度下降问题，显著提高了量化精度。

> **ai_Abstract:** 本文提出了一种名为FIMA-Q的新型后训练量化（PTQ）方法，专为视觉Transformer（ViT）设计，旨在解决现有PTQ方法在低比特量化下严重的精度下降问题。该方法通过分析传统Hessian近似的局限性，建立了KL散度与Fisher信息矩阵（FIM）的联系，从而加速量化损失的计算。此外，FIMA-Q引入了高效的DPLR-FIM近似方法。实验证明，FIMA-Q在多种视觉任务和ViT架构上，尤其在低比特量化时，显著优于现有最先进的PTQ方法。

> **摘要翻译:** 后训练量化（PTQ）近年来已成为一种经济高效且有前景的模型压缩范式，因为它避免了计算密集型模型再训练。然而，当前用于视觉Transformer（ViT）的PTQ方法仍然面临显著的精度下降问题，尤其是在低比特量化下。为了解决这些缺点，我们分析了流行的Hessian引导量化损失，并揭示了传统Hessian近似的某些局限性。通过遵循分块重建框架，我们提出了一种新颖的ViT后训练量化方法，称为FIMA-Q。具体来说，我们首先建立了KL散度与FIM之间的联系，这使得在重建过程中可以快速计算量化损失。我们进一步提出了一种高效的FIM近似方法，即DPLR-FIM，通过采用对角加低秩原理，并制定了最终的量化损失。我们在公共数据集上，使用代表性的基于ViT的架构，在各种视觉任务上进行了广泛的实验，结果表明我们的方法与最先进的方法相比显著提高了精度，特别是在低比特量化的情况下。源代码可在https://github.com/ShiheWang/FIMA-Q获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [465] [Leveraging Satellite Image Time Series for Accurate Extreme Event Detection](https://arxiv.org/abs/2506.11544)
> *利用卫星图像时间序列实现极端事件的精准检测*

*Heng Fang, Hossein Azizpour* | **Main category: cs.CV**

**Keywords:** 卫星图像时间序列, 极端事件检测, SITS-Extreme, 灾害响应, 气候变化

**Comment:** Accepted to the WACV 2025 Workshop on GeoCV. Code, datasets, and
  model checkpoints available at:
  https://github.com/hfangcat/SITS-ExtremeEvents

> **TL;DR:** 提出SITS-Extreme框架，利用卫星图像时间序列和多灾前观测数据，更准确地检测极端事件，并在实验中表现出显著优于现有基线。

**AI_Comments:** 这项工作通过引入多灾前卫星图像时间序列来提升极端事件检测的准确性，其创新点在于利用时间序列数据有效区分灾害相关信号与无关变化。该框架在大规模灾害监测方面具有重要应用价值，尤其是在气候变化背景下极端事件日益增多的趋势下。

<details>
  <summary>Details</summary>

**Motivation:** 气候变化导致极端天气事件增加，造成严重的环境破坏和生命损失，因此早期检测此类事件对于改善灾害响应至关重要。

**Method:** 提出了SITS-Extreme框架，该框架利用卫星图像时间序列，通过整合多个灾前观测数据来检测极端事件。这种方法能有效滤除不相关变化，同时隔离与灾害相关的信号，从而实现更准确的检测。

**Result:** 在真实世界和合成数据集上的大量实验验证了SITS-Extreme的有效性，并显示出比广泛使用的强双时相基线有显著改进。此外，研究还检查了纳入更多时间步长的影响，分析了框架中关键组件的贡献，并评估了其在不同灾害类型上的性能。

**Conclusion:** SITS-Extreme框架通过利用卫星图像时间序列和多灾前观测数据，能够实现对极端事件的更准确检测，并具有良好的可扩展性和在大规模灾害监测中的适用性。

> **ai_Abstract:** 本文提出了SITS-Extreme框架，利用卫星图像时间序列并结合多灾前观测数据，旨在提高极端事件的检测精度。该框架通过过滤无关变化并隔离灾害相关信号，实现了比传统双时相基线更显著的检测性能提升。研究还探讨了时间步长、组件贡献及不同灾害类型对框架性能的影响，验证了其在大规模灾害监测中的潜力和适用性。

> **摘要翻译:** 气候变化导致极端天气事件增加，造成严重的环境破坏和生命损失。早期检测此类事件对于改善灾害响应至关重要。在这项工作中，我们提出了SITS-Extreme，一个新颖的框架，它利用卫星图像时间序列，通过整合多个灾前观测数据来检测极端事件。这种方法能有效滤除不相关变化，同时隔离与灾害相关的信号，从而实现更准确的检测。在真实世界和合成数据集上的大量实验验证了SITS-Extreme的有效性，并显示出比广泛使用的强双时相基线有显著改进。此外，我们还检查了纳入更多时间步长的影响，分析了我们框架中关键组件的贡献，并评估了其在不同灾害类型上的性能，为大规模灾害监测的可扩展性和适用性提供了宝贵见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [474] [DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs](https://arxiv.org/abs/2506.11558)
> *DaMO：一种用于视频LLM时间推理的数据高效多模态协调器*

*Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen* | **Main category: cs.CV**

**Keywords:** 视频LLM, 时间推理, 数据高效, 多模态理解, Temporal-aware Fuseformer

**Comment:** 

> **TL;DR:** DaMO是一种数据高效的视频LLM，通过创新的架构和训练范式，显著提升了视频时间推理和多模态理解能力，超越了现有方法。

**AI_Comments:** DaMO的创新点在于其独特的时间感知融合器和分层双流架构，有效解决了视频LLM在时间推理上的痛点。数据高效的设计和渐进式训练范式也提升了实用性。通过GPT生成数据集来增强时间监督是另一个亮点。这项工作对于推动视频-语言理解，特别是精细时间定位方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频LLM在细粒度时间推理方面存在局限性，难以将响应精确归因于特定的视频时刻，尤其是在监督受限的情况下。

**Method:** 提出DaMO，其核心是时间感知融合器（Temporal-aware Fuseformer），采用分层双流架构捕获模态内时间动态并融合视觉和音频信息。集成全局残差以提高计算效率。通过结构化的四阶段渐进式训练范式进行训练，逐步赋予模型多模态对齐、语义接地和时间推理能力。贡献了通过GPT生成时间定位QA对增强的数据集。

**Result:** DaMO在时间定位和视频问答基准测试中始终超越现有方法，特别是在需要精确时间对齐和推理的任务中表现出色。

**Conclusion:** 该工作为数据高效的视频语言建模建立了有前景的方向。

> **ai_Abstract:** DaMO是一个新颖的数据高效视频LLM，旨在解决现有视频LLM在细粒度时间推理方面的不足。它引入了时间感知融合器（Temporal-aware Fuseformer）和全局残差，并通过四阶段渐进式训练范式进行优化。此外，研究还通过GPT生成的数据集增强了现有数据。实验证明DaMO在时间定位和视频问答任务上显著优于现有方法，为数据高效的视频-语言建模开辟了新方向。

> **摘要翻译:** 大型语言模型（LLMs）最近已扩展到视频领域，实现了复杂的视频-语言理解。然而，现有的视频LLMs在细粒度时间推理方面常表现出局限性，限制了它们将响应精确归因于特定视频时刻的能力，尤其是在监督受限的情况下。我们引入了DaMO，一个数据高效的视频LLM，专门设计用于精确的时间推理和多模态理解。其核心是，所提出的时间感知融合器（Temporal-aware Fuseformer）采用分层双流架构，逐步捕获每种模态内的时间动态，并有效地融合互补的视觉和音频信息。为了进一步提高计算效率，DaMO集成了全局残差，在保留基本语义细节的同时减少空间冗余。我们通过结构化的四阶段渐进式训练范式训练DaMO，逐步为模型配备多模态对齐、语义接地和时间推理能力。这项工作还贡献了从现有数据集中增强的多个数据集，这些数据集通过GPT生成的时间定位QA对用于需要时间监督的任务。在时间定位和视频问答基准测试上的综合实验表明，DaMO始终超越现有方法，特别是在需要精确时间对齐和推理的任务中。我们的工作为数据高效的视频-语言建模建立了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?](https://arxiv.org/abs/2506.11571)
> *VFaith：大型多模态模型真的基于所见图像而非过往记忆进行推理吗？*

*Jiachen Yu, Yufei Zhan, Ziheng Wu, Yousong Zhu, Jinqiao Wang, Minghui Qiu* | **Main category: cs.CV**

**Keywords:** 大型多模态模型, 视觉推理, 视觉忠实度, 基准测试, 图像编辑

**Comment:** 

> **TL;DR:** 本文提出了VFaith-Bench，一个用于评估大型多模态模型视觉推理忠实度的基准，并设计了一个图像编辑管道来量化模型对视觉线索的依赖。

**AI_Comments:** 本文的创新之处在于首次提出了一个专注于评估大型多模态模型视觉推理忠实度的基准VFaith-Bench，并通过一个新颖的自动化图像编辑管道，实现了对视觉线索的精确控制和修改。这为量化分析模型对视觉信息的依赖性提供了一个有效的方法，有助于深入理解MLLMs的“推理”是基于真实的视觉感知还是记忆偏差。这项工作对于推动MLLMs的可解释性和可靠性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管长CoT（思维链）能有效增强多模态大语言模型（MLLMs）解决复杂问题的能力，但其有效性的原因尚不明确。难以定量分析模型对视觉线索的提取及其推理过程对性能提升的贡献，因此评估MLLMs推理对视觉信息的忠实度至关重要。

**Method:** 为了解决MLLMs视觉推理忠实度的问题，本文首先提出了一个基于GPT-Image-1的线索驱动的自动化可控编辑管道，用于精确编辑特定视觉线索。接着，引入了VFaith-Bench，这是首个用于评估MLLMs视觉推理能力及其来源的基准，重点关注视觉忠实度。通过该管道，构建了比较性问答对，通过改变图像中解决原始推理问题至关重要的视觉线索来改变答案。通过测试不同细节图像的相似问题，平均准确率反映模型视觉推理能力，而编辑前后准确率的差异揭示了模型推理能力与视觉感知之间的关系。此外，设计了特定指标来揭示这种关系。VFaith-Bench包含755个条目，分为五个不同的子集，并附加了一个人工标注的感知任务。

**Result:** 通过VFaith-Bench，平均准确率可以反映模型的视觉推理能力，而测试集图像编辑前后的准确率差异有效地揭示了模型推理能力与视觉感知之间的关系。VFaith-Bench包含了755个条目，分为五个不同的子集，并附带了一个人工标注的感知任务。研究团队对现有主流旗舰模型和知名的开源模型系列/推理模型在VFaith-Bench上进行了深入测试和分析。

**Conclusion:** 本文通过VFaith-Bench基准和图像编辑管道，进一步深入探究了大型多模态模型推理能力背后的潜在因素。

> **ai_Abstract:** 本文提出VFaith-Bench，一个旨在评估大型多模态模型（MLLMs）视觉推理忠实度的新基准。为解决MLLMs推理有效性原因不明确的问题，研究团队开发了一个基于GPT-Image-1的自动化图像编辑管道，能够精确修改图像中的关键视觉线索。通过构建比较性问答对并分析模型在编辑前后图像上的表现差异，VFaith-Bench量化了MLLMs的视觉推理能力及其对视觉信息的依赖性。该基准包含755个条目和人工标注任务，并已用于深入分析主流MLLMs的推理机制。

> **摘要翻译:** 最近大量工作表明，通过引入长CoT（思维链），多模态大语言模型（MLLMs）解决复杂问题的能力可以得到有效提升。然而，这种范式有效性的原因仍不清楚。定量分析模型在推理过程中对视觉线索的具体提取及其所谓的推理对性能提升的贡献是具有挑战性的。因此，评估MLLMs推理对视觉信息的忠实度至关重要。为了解决这个问题，我们首先在GPT-Image-1的帮助下提出了一个线索驱动的自动化可控编辑管道。它能够根据指令自动精确地编辑特定的视觉线索。此外，我们引入了VFaith-Bench，这是第一个用于评估MLLMs视觉推理能力并以视觉忠实度为重点分析其能力来源的基准。通过设计的管道，我们通过改变图像中对解决原始推理问题至关重要的视觉线索，从而改变问题的答案，构建了比较性问答对。通过测试具有不同细节的图像的相似问题，平均准确率反映了模型的视觉推理能力，而测试集图像编辑前后的准确率差异有效地揭示了模型推理能力与视觉感知之间的关系。我们进一步设计了特定的指标来揭示这种关系。VFaith-Bench包含755个条目，分为五个不同的子集，并附带了一个人工标注的感知任务。我们对现有主流旗舰模型和知名的开源模型系列/推理模型在VFaith-Bench上进行了深入测试和分析，进一步调查了其推理能力的潜在因素。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [481] [Camera-based method for the detection of lifted truck axles using convolutional neural networks](https://arxiv.org/abs/2506.11574)
> *基于卷积神经网络的卡车举升轴检测的相机方法*

*Bachir Tchana Tankeu, Mohamed Bouteldja, Nicolas Grignard, Bernard Jacob* | **Main category: cs.CV**

**Keywords:** 卷积神经网络, YOLOv8s, 举升轴检测, 车辆分类, 实时检测

**Comment:** 

> **TL;DR:** 本文提出了一种基于YOLOv8s卷积神经网络的相机方法，用于实时检测卡车图像中的卡车举升轴，并取得了良好的性能。

**AI_Comments:** 该研究提出了一种新颖且实用的方法来解决现有交通控制系统中车辆分类的痛点，特别是在检测举升轴方面。YOLOv8s的应用使其具备了实时处理能力，具有重要的实际应用价值。未来的改进方向明确，即通过数据量和增强技术提升性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有技术（如动态称重系统WIM）难以准确分类带有举升轴的车辆，且市场上缺乏有效的商业和技术方法来检测举升轴。

**Method:** 作为欧洲SETO项目的一部分，本文提出了一种基于卷积神经网络（CNN）的方法，具体使用了YOLOv8s模型，通过垂直于交通方向放置的相机捕获的卡车图像来检测举升轴。

**Result:** 所提出的方法表现出87%的精确度、91.7%的召回率和1.4毫秒的推理时间，使其非常适合实时部署。

**Conclusion:** 该方法适用于实时部署，并且可以通过增加数据集大小和/或使用各种图像增强方法来进一步改进。

> **ai_Abstract:** 本文提出了一种基于YOLOv8s卷积神经网络的相机方法，用于实时检测卡车图像中的举升轴。该方法在精确度、召回率和推理时间方面表现良好，证明了其在交通执法中识别复杂车辆类别的潜力。

> **摘要翻译:** 车辆的识别和分类在控制-制裁系统的各个方面都发挥着至关重要的作用。当前的称重（WIM）系统可以对大多数车辆类别进行分类，但它们难以准确分类带有举升轴的车辆。此外，很少有商业和技术方法用于检测举升轴。在本文中，作为欧洲SETO（智能交通操作执法）项目的一部分，提出了一种基于卷积神经网络（CNN）（即YOLOv8s）的方法，用于检测由垂直于交通方向放置的相机捕获的卡车图像中的举升轴。对所提出方法的性能进行了评估，结果发现其精确度为87%，召回率为91.7%，推理时间为1.4毫秒，这使其非常适合实时部署。这些结果表明可以进一步改进，可能通过增加数据集大小和/或使用各种图像增强方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [484] [OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots](https://arxiv.org/abs/2506.11585)
> *OV-MAP：面向机器人的开放词汇零样本三维实例分割地图*

*Juno Kim, Yesol Park, Hye-Jung Yoon, Byoung-Tak Zhang* | **Main category: cs.CV**

**Keywords:** 开放词汇, 零样本, 3D实例分割, 机器人, 3D映射

**Comment:** Accepted at IROS 2024

> **TL;DR:** OV-MAP通过将2D掩码投影到3D空间并结合3D掩码投票机制，实现了机器人开放世界3D地图的零样本3D实例分割。

**AI_Comments:** OV-MAP的创新之处在于其无需3D监督即可实现零样本3D实例分割，这对于机器人感知领域具有重要意义。通过将2D分割与3D投票机制结合，有效解决了特征溢出问题。其在开放世界和真实环境中的鲁棒性也值得关注，为未来机器人应用提供了强大的感知基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在相邻体素特征重叠时，实例级精度降低，因为特征会溢出体素边界，导致相邻区域混合。OV-MAP旨在解决这一挑战，以提高开放世界3D映射中对象识别的实例级精度。

**Method:** OV-MAP采用类无关分割模型将2D掩码投影到3D空间，结合通过合并原始和合成点云深度创建的补充深度图像。此外，它还使用3D掩码投票机制，从而实现准确的零样本3D实例分割，而无需依赖3D监督分割模型。

**Result:** 在ScanNet200和Replica等公共数据集上表现出卓越的零样本性能、鲁棒性和在不同环境中的适应性。通过真实世界实验，进一步证明了其在多样真实环境中的适应性和鲁棒性。

**Conclusion:** OV-MAP通过创新的2D到3D投影和3D投票机制，有效解决了开放世界3D实例分割中特征重叠导致的精度问题，实现了无需3D监督的零样本性能，并在多种环境和真实世界中展现出强大的适应性和鲁棒性，为移动机器人提供了增强的对象识别能力。

> **ai_Abstract:** OV-MAP是一种针对移动机器人的开放世界3D映射新方法，通过将开放特征集成到3D地图中，旨在增强对象识别能力并解决相邻体素特征重叠导致的实例级精度下降问题。该方法利用类无关的2D分割模型将2D掩码投影到3D空间，并结合补充的深度图像和3D掩码投票机制，实现了无需3D监督的零样本3D实例分割。实验证明，OV-MAP在公共数据集和真实世界环境中均表现出卓越的零样本性能、鲁棒性和适应性。

> **摘要翻译:** 我们引入了OV-MAP，这是一种通过将开放特征集成到3D地图中以增强对象识别能力，从而为移动机器人提供开放世界3D映射的新颖方法。一个重大挑战是当来自相邻体素的重叠特征降低实例级精度时，因为特征会溢出体素边界，将相邻区域混合在一起。我们的方法通过采用类无关分割模型将2D掩码投影到3D空间，并结合通过合并原始和合成点云深度创建的补充深度图像来克服这个问题。这种方法，以及3D掩码投票机制，实现了准确的零样本3D实例分割，而无需依赖3D监督分割模型。我们通过在ScanNet200和Replica等公共数据集上进行的全面实验评估了我们方法的有效性，展示了卓越的零样本性能、鲁棒性和在不同环境中的适应性。此外，我们还进行了真实世界实验，以证明我们的方法在应用于不同真实世界环境时的适应性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [487] [EasyARC: Evaluating Vision Language Models on True Visual Reasoning](https://arxiv.org/abs/2506.11595)
> *EasyARC：评估视觉语言模型的真实视觉推理能力*

*Mert Unsal, Aylin Akkus* | **Main category: cs.CV**

**Keywords:** 视觉语言模型, 视觉推理, 基准测试, EasyARC, 多模态推理

**Comment:** CVPR2025 Workshop on Test-time Scaling for Computer Vision

> **TL;DR:** 引入了一个名为EasyARC的新视觉语言基准，用于评估多图像、多步骤推理和自我纠正能力，旨在解决现有基准缺乏真实视觉推理的问题。

**AI_Comments:** 该论文通过引入EasyARC基准，有效解决了当前视觉语言模型评估中缺乏“真实视觉推理”的问题，强调了多步骤推理和自我纠正的重要性。其程序化生成、可验证和可扩展的特性使其在研究和强化学习领域具有重要价值。开源数据集和代码将促进社区在该方向的进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态基准主要测试视觉提取与基于文本的推理结合，缺乏视觉与语言之间更复杂交互的真实视觉推理能力。

**Method:** 引入了EasyARC，这是一个需要多图像、多步骤推理和自我纠正的视觉语言基准。EasyARC是程序化生成、完全可验证和可扩展的，并包含渐进式难度级别，使其适用于强化学习管道和结构化评估。

**Result:** 对最先进的视觉语言模型进行了基准测试并分析了它们的失败模式。EasyARC为评估视觉语言模型的真实推理和测试时扩展能力设定了新标准。

**Conclusion:** EasyARC为评估视觉语言模型中的真实推理和测试时扩展能力设定了新标准，并开源了基准数据集和评估代码。

> **ai_Abstract:** 该论文提出了一个新的视觉语言基准EasyARC，旨在解决现有基准在评估视觉语言模型真实视觉推理能力方面的不足。EasyARC受ARC挑战启发，要求模型进行多图像、多步骤推理和自我纠正。它通过程序化生成，确保可验证性和可扩展性，并包含渐进式难度级别，适用于强化学习。研究者使用EasyARC对当前最先进的视觉语言模型进行了测试，并分析了它们的局限性，认为EasyARC为评估真实推理和测试时扩展能力提供了新标准，并已开源其数据集和代码。

> **摘要翻译:** 在基于语言的推理模型最新进展的基础上，我们探索了整合视觉和文本的多模态推理。现有的多模态基准主要测试视觉提取与基于文本的推理相结合，缺乏视觉与语言之间更复杂交互的真实视觉推理。受ARC挑战的启发，我们引入了EasyARC，这是一个需要多图像、多步骤推理和自我纠正的视觉语言基准。EasyARC是程序化生成、完全可验证和可扩展的，使其非常适合强化学习（RL）管道。生成器包含渐进式难度级别，可以对任务类型和复杂性进行结构化评估。我们对最先进的视觉语言模型进行了基准测试并分析了它们的失败模式。我们认为EasyARC为评估视觉语言模型的真实推理和测试时扩展能力设定了新标准。我们开源了我们的基准数据集和评估代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [490] [A$^2$LC: Active and Automated Label Correction for Semantic Segmentation](https://arxiv.org/abs/2506.11599)
> *A$^2$LC: 语义分割的主动与自动化标签校正*

*Youjin Jeon, Kyusik Cho, Suhan Woo, Euntai Kim* | **Main category: cs.CV**

**Keywords:** 语义分割, 主动学习, 标签校正, 自动化, 长尾类

**Comment:** Preprint. Under review. 22 pages, 8 figures

> **TL;DR:** A$^2$LC是一个新的主动和自动化标签校正框架，通过整合自动化校正阶段和自适应平衡获取函数，显著提高了语义分割标签校正的效率和效果，超越了现有SOTA方法。

**AI_Comments:** 该论文的创新点在于将自动化校正机制引入主动标签校正流程，并结合自适应平衡获取函数来解决长尾类问题，从而显著提升了语义分割中标签校正的效率和效果。其在效率上的巨大提升（仅用20%预算超越SOTA）和在性能上的显著进步（27.23%提升）都表明了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的主动标签校正（ALC）方法在语义分割中尽管通过伪标签提高了效率，但手动像素级标注成本高、易出错，且仍存在显著的效率低下问题。

**Method:** 提出A$^2$LC框架，将自动化校正阶段整合到传统ALC流程中，利用标注者反馈对查询样本之外的数据进行标签校正。此外，引入自适应平衡获取函数，强调代表性不足的长尾类，补充自动化校正机制。

**Result:** 在Cityscapes和PASCAL VOC 2012数据集上，A$^2$LC显著优于现有最先进方法。A$^2$LC仅用20%的预算就超越了现有方法，并在Cityscapes数据集上同等预算下性能提升了27.23%。

**Conclusion:** A$^2$LC通过引入自动化校正和自适应平衡获取函数，大幅提升了语义分割中标签校正的效率和有效性。

> **ai_Abstract:** 本文提出了A$^2$LC，一个用于语义分割的新型主动与自动化标签校正框架。该框架通过整合自动化校正阶段来提高成本效率，该阶段利用标注者反馈对查询样本之外的数据进行标签校正。同时，引入自适应平衡获取函数以关注长尾类。实验结果表明，A$^2$LC在效率和有效性上均显著优于现有最先进方法，例如在Cityscapes数据集上，仅用20%的预算即可超越现有方法，或在同等预算下性能提升27.23%。

> **摘要翻译:** 主动标签校正（ALC）已成为解决语义分割中手动像素级标注成本高、易出错问题的有前景方案，它通过选择性地识别和纠正错误标注数据。尽管最近的工作通过使用基础模型生成伪标签提高了校正效率，但仍存在显著的效率低下问题。在本文中，我们提出了一种用于语义分割的主动与自动化标签校正（A$^2$LC），这是一个新颖高效的ALC框架，它将自动化校正阶段整合到传统流程中。具体而言，自动化校正阶段利用标注者反馈对查询样本之外的数据执行标签校正，从而最大限度地提高成本效率。此外，我们进一步引入了一种自适应平衡获取函数，该函数强调代表性不足的长尾类，并补充了自动化校正机制。在Cityscapes和PASCAL VOC 2012上的大量实验表明，A$^2$LC显著优于以前的最先进方法。值得注意的是，A$^2$LC通过仅使用20%的预算就超越了以前的方法，实现了高效率；并在Cityscapes数据集上在同等预算约束下，性能提高了27.23%，展示了强大的有效性。代码将在接收后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation](https://arxiv.org/abs/2506.11621)
> *SignAligner：协调互补姿态模态以实现连贯手语生成*

*Xu Wang, Shengeng Tang, Lechao Cheng, Feng Li, Shuo Wang, Richang Hong* | **Main category: cs.CV**

**Keywords:** 手语生成, 姿态模态, 多模态校正, SignAligner, PHOENIX14T+

**Comment:** 

> **TL;DR:** 本文提出SignAligner方法，通过协调多种姿态模态，显著提升手语视频生成的准确性和表现力，并引入扩展的PHOENIX14T+数据集。

**AI_Comments:** SignAligner的创新之处在于其三阶段协同生成和校正框架，特别是引入在线协同校正机制，有效解决了手语多模态信息融合中的时空冲突和一致性问题。通过扩展PHOENIX14T+数据集并利用Transformer和跨模态注意力，该工作为生成更真实、更具表现力的手语提供了新的SOTA方案，对手语生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手语生成旨在基于口语生成多样化的手语表示，但由于手语的复杂性（包含手势、面部表情和身体动作），实现真实和自然的手语生成仍然是一个重大挑战。

**Method:** 本文引入了PHOENIX14T+数据集，增加了姿态、Hamer和Smplerx三种新的手语表示。提出了一种名为SignAligner的新方法，用于真实手语生成，包含三个阶段：1. 文本驱动的姿态模态协同生成：通过Transformer编码器和跨模态注意力机制，联合生成姿态坐标、手势动作和身体动作。2. 在线协同校正多模态：使用动态损失加权策略和跨模态注意力，精炼生成的姿态模态，消除时空冲突并确保语义一致性和动作连贯性。3. 真实手语视频合成：将校正后的姿态模态输入预训练的视频生成网络。

**Result:** 广泛的实验表明，SignAligner显著提高了生成手语视频的准确性和表现力。

**Conclusion:** SignAligner通过其多阶段方法和对多模态姿态的有效协调，成功解决了手语生成中的真实性和自然性挑战，并提升了生成视频的质量。

> **ai_Abstract:** 本研究针对手语生成中真实性和自然性不足的挑战，引入了扩展数据集PHOENIX14T+，并提出了一种名为SignAligner的新方法。SignAligner通过文本驱动的多模态姿态协同生成、在线协同校正以及高质量视频合成三个阶段，有效地协调了互补姿态模态。实验证明，该方法显著提升了生成手语视频的准确性和表现力。

> **摘要翻译:** 手语生成旨在基于口语生成多样化的手语表示。然而，由于手语的复杂性，包括复杂的手势、面部表情和身体动作，实现真实和自然的手语生成仍然是一个重大挑战。在这项工作中，我们引入了PHOENIX14T+，这是广泛使用的RWTH-PHOENIX-Weather 2014T数据集的扩展版本，其特点是包含三种新的手语表示：姿态（Pose）、Hamer和Smplerx。我们还提出了一种新的方法——SignAligner，用于真实手语生成，该方法包括三个阶段：文本驱动的姿态模态协同生成、多模态在线协同校正以及真实手语视频合成。首先，通过融入文本语义，我们设计了一个联合手语生成器，以同时产生姿态坐标、手势动作和身体动作。基于Transformer架构的文本编码器提取语义特征，而跨模态注意力机制整合这些特征以生成多样化的手语表示，确保准确映射并控制模态特征的多样性。接下来，引入在线协同校正，使用动态损失加权策略和跨模态注意力来精炼生成的姿态模态，促进模态间信息的互补性，消除时空冲突，并确保语义连贯性和动作一致性。最后，将校正后的姿态模态输入预训练的视频生成网络，以产生高保真手语视频。广泛的实验表明，SignAligner显著提高了生成手语视频的准确性和表现力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [501] [Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression](https://arxiv.org/abs/2506.11627)
> *评估机器学习中的公平性与偏见缓解：一种使用张量数据和贝叶斯回归的新技术*

*Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker, Yiannis Papadopoulos* | **Main category: cs.CV**

**Keywords:** 机器学习公平性, 偏见缓解, 张量数据, 贝叶斯回归, 肤色

**Comment:** 

> **TL;DR:** 本文提出一种新方法，通过将皮肤颜色张量数据转换为概率分布并结合贝叶斯回归，评估和缓解机器学习图像分类中皮肤颜色偏见，无需标注。

**AI_Comments:** 本文的创新点在于其处理肤色这一特殊敏感属性的方式，即将其视为张量数据而非分类数据，并通过概率分布和统计距离来捕捉细微的公平性差异。同时，结合贝叶斯回归来缓解偏见，提供了一种无需标注的新颖方法，对于提升图像分类模型在肤色方面的公平性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于敏感群体公平性的研究主要关注分类特征（如性别、种族），但皮肤颜色是张量数据，且以往方法将皮肤颜色僵硬分类，无法捕捉细微差别，导致传统皮肤色调分类存在潜在偏见。

**Method:** 本文提出一种用于图像分类任务中评估机器学习公平性的新技术，无需标注。具体方法为：1. 将皮肤颜色等张量数据转换为概率分布，并应用统计距离测量。2. 提出一种创新的训练方法，利用通过多项式函数贝叶斯回归计算的颜色距离估计来缓解传统皮肤色调分类中存在的潜在偏见。

**Result:** Not mentioned in abstract

**Conclusion:** 该方法能够捕捉公平性在传统上被认为是不同群体内部和跨群体的细微差别，并确保机器学习模型中皮肤颜色处理的更细致和公平。

> **ai_Abstract:** 本文提出了一种评估和缓解机器学习图像分类任务中肤色偏见的新技术。针对肤色作为张量数据的特性，该方法避免了僵硬分类，而是将其转换为概率分布并使用统计距离测量来评估公平性。此外，还引入了一种创新的训练方法，利用贝叶斯回归计算的颜色距离估计来缓解潜在偏见，从而实现对肤色的更细致和公平的处理，且无需标注。

> **摘要翻译:** 公平性是可信人工智能的关键组成部分。在本文中，我们关注机器学习（ML）以及模型在处理肤色时的预测性能。与其他敏感属性不同，肤色的性质显著不同。在计算机视觉中，肤色表示为张量数据，而不是分类值或单个数值点。然而，许多关于跨敏感群体的公平性研究都集中在分类特征上，例如性别和种族。本文介绍了一种用于评估机器学习在图像分类任务中公平性的新技术，特别是无需使用标注。为了解决先前工作的局限性，我们处理诸如肤色之类的张量数据，而不是对其进行僵硬分类。相反，我们将其转换为概率分布并应用统计距离测量。这种新颖的方法使我们能够捕获公平性在传统上被认为是不同群体内部和跨群体的细微差别。此外，我们提出了一种创新的训练方法来缓解传统肤色分类中存在的潜在偏见。该方法利用通过多项式函数贝叶斯回归计算的颜色距离估计，确保机器学习模型中肤色处理的更细致和公平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [505] [DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation](https://arxiv.org/abs/2506.11653)
> *DISCO：利用条件距离相关性减轻深度学习中的偏差*

*Emre Kavak, Tom Nuno Wolf, Christian Wachinger* | **Main category: cs.CV**

**Keywords:** 深度学习, 偏差缓解, 条件距离相关性, 正则化, 因果推断

**Comment:** 

> **TL;DR:** DISCO是一种新的正则化策略，利用条件距离相关性来优化回归任务中的条件独立性，旨在减轻深度学习模型在预测时利用因果无关信号导致的偏差。

**AI_Comments:** DISCO的创新之处在于提出了一种基于条件距离相关性的新型正则化策略，以解决深度学习模型中的偏差问题。它提供了一种不同于经典核方法的替代方案，通过优化条件独立性来确保模型关注直接的因果路径，从而提高了模型的可解释性和鲁棒性。其在偏差缓解实验中的竞争力结果突显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在预测任务中，模型可能会利用因果无关的信号（如图像中的光照条件）作为捷径来区分不同对象，这会导致不期望的偏差。例如，一个模型可能依赖光照而不是物体本身的细节进行预测。

**Method:** 本文引入了一种标准反因果预测模型（SAM），为分析预测器在反因果设置中受到的信息路径影响创建了一个因果框架。研究表明，满足特定条件独立性标准的分类器将仅关注从标签到图像的直接因果路径。在此基础上，提出了DISCO，一种利用条件距离相关性优化回归任务中条件独立性的新型正则化策略。

**Result:** DISCO在不同的偏差缓解实验中取得了有竞争力的结果。

**Conclusion:** DISCO被认为是一种替代经典基于核方法的有效选择。

> **ai_Abstract:** 本研究旨在解决深度学习模型在预测任务中利用因果无关信号导致的偏差问题。为此，作者提出了标准反因果预测模型（SAM）来分析因果信息路径，并证明满足特定条件独立性的分类器能够专注于直接因果路径。在此基础上，提出了一种名为DISCO的新型正则化策略，它利用条件距离相关性来优化回归任务中的条件独立性。实验结果表明，DISCO在偏差缓解方面表现出色，并被视为经典核方法的有效替代方案。

> **摘要翻译:** 在预测任务中，模型可以使用它接收到的任何信号来得出最终答案——包括因果无关的信号。例如，在从图像预测物体时，光照条件可能通过选择偏差与不同的目标相关联，而一个不知情的模型可能会使用这些信号作为捷径来区分各种物体。一个使用光照条件而不是真实物体特定细节的预测器显然是不可取的。为了解决这个挑战，我们引入了一个标准反因果预测模型（SAM），它创建了一个因果框架，用于分析在反因果设置中影响我们预测器的信息路径。我们证明了一个满足特定条件独立性标准的分类器将只关注从标签到图像的直接因果路径，对剩余变量具有反事实不变性。最后，我们提出了DISCO，一种利用条件距离相关性来优化回归任务中条件独立性的新型正则化策略。我们能够证明DISCO在不同的偏差缓解实验中取得了有竞争力的结果，使其成为经典基于核方法的有效替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [508] [Prohibited Items Segmentation via Occlusion-aware Bilayer Modeling](https://arxiv.org/abs/2506.11661)
> *违禁品分割：基于遮挡感知的双层建模*

*Yunhan Ren, Ruihuang Li, Lingbo Liu, Changwen Chen* | **Main category: cs.CV**

**Keywords:** 违禁品分割, X射线图像, 实例分割, 遮挡感知, 双层建模

**Comment:** Accepted by ICME 2025

> **TL;DR:** 本文提出了一种遮挡感知的实例分割方法，通过集成SAM和设计双层掩码解码器，有效解决了X射线图像中违禁品分割的挑战，特别是在外观差异和严重重叠方面。

**AI_Comments:** 该论文的创新点在于将先进的SAM模型引入X射线图像分析领域，以解决违禁品与自然物体之间的表示差距问题。同时，提出的遮挡感知双层掩码解码器模块有效解决了X射线图像中常见的物体严重重叠问题，并通过手动标注遮挡区域来提供监督，为该领域的实例分割提供了新的思路和有效方案。

<details>
  <summary>Details</summary>

**Motivation:** X射线图像中的违禁品实例分割是一项关键但具有挑战性的任务，主要原因在于X射线图像中的违禁品与自然物体之间存在显著的外观差异，以及物体之间严重的重叠问题。

**Method:** 为解决表示差距，将Segment Anything Model (SAM) 集成到管道中，利用其丰富的先验知识和零样本泛化能力。为解决违禁品之间的重叠问题，设计了一个遮挡感知的双层掩码解码器模块，明确建模遮挡关系。为监督遮挡估计，手动标注了两个大型X射线图像分割数据集（PIDray和PIXray）中违禁品的遮挡区域，并将其与原始信息一起重组为两个带遮挡标注的数据集PIDray-A和PIXray-A。

**Result:** 在这些带遮挡标注的数据集上进行的大量实验结果证明了所提出方法的有效性。

**Conclusion:** 所提出的遮挡感知双层建模方法能够有效解决X射线图像中违禁品分割的挑战，特别是在处理外观差异和物体重叠方面表现出色。

> **ai_Abstract:** 本文提出了一种针对X射线图像中违禁品实例分割的遮挡感知双层建模方法。该方法通过整合Segment Anything Model (SAM) 来弥合外观表示差距，并设计了一个遮挡感知的双层掩码解码器来显式建模物体重叠关系。为支持遮挡估计，研究人员对现有大型X射线数据集进行了手动遮挡标注，创建了PIDray-A和PIXray-A。实验结果验证了该方法的有效性。

> **摘要翻译:** 安全X射线图像中违禁品的实例分割是一项关键但具有挑战性的任务。这主要是由于X射线图像中违禁品与自然物体之间存在显著的外观差异，以及X射线图像中物体之间严重的重叠。为了解决这些问题，我们提出了一种遮挡感知的实例分割流程，旨在识别X射线图像中的违禁品。具体来说，为了弥合表示差距，我们将Segment Anything Model (SAM) 集成到我们的流程中，利用其丰富的先验知识和零样本泛化能力。为了解决违禁品之间的重叠问题，我们设计了一个遮挡感知的双层掩码解码器模块，明确建模遮挡关系。为了监督遮挡估计，我们手动标注了两个大型X射线图像分割数据集PIDray和PIXray中违禁品的遮挡区域。然后，我们将这些额外的标注与原始信息一起重组为两个带遮挡标注的数据集PIDray-A和PIXray-A。在这些带遮挡标注的数据集上进行的大量实验结果证明了我们所提出方法的有效性。数据集和代码可在以下网址获取：https://github.com/Ryh1218/Occ

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning](https://arxiv.org/abs/2506.11672)
> *用于持续多模态指令微调的课程LoRA专家动态混合*

*Chendi Ge, Xin Wang, Zeyang Zhang, Hong Chen, Jiapei Fan, Longtao Huang, Hui Xue, Wenwu Zhu* | **Main category: cs.CV**

**Keywords:** 持续学习, 多模态大语言模型, LoRA, 动态架构, 模态不平衡

**Comment:** Accepted by ICML 2025

> **TL;DR:** D-MoLE是一种新方法，通过动态调整LoRA专家架构和平衡模态更新，使多模态大语言模型（MLLM）能够持续适应新任务。

**AI_Comments:** 本文的创新点在于首次从架构而非仅仅算法层面，探索多模态大语言模型（MLLM）的持续学习问题，并提出了动态调整LoRA专家架构以适应新任务的D-MoLE方法。其引入的动态层级专家分配器和基于梯度的跨模态持续课程，有效解决了任务架构冲突和模态不平衡这两个关键挑战，为持续学习领域带来了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在多模态大语言模型（MLLM）持续适应新任务时，采用固定架构导致模型容量静态，难以适应新任务。这带来了两个挑战：任务架构冲突（不同任务需要不同的层级适应）和模态不平衡（不同任务对模态的依赖不均导致更新不平衡）。

**Method:** 本文提出了一种名为动态课程LoRA专家混合（D-MoLE）的新方法。该方法在受控参数预算下自动演进MLLM的架构，以持续适应新任务并保留先前知识。具体包括：1) 动态层级专家分配器，自动在各层分配LoRA专家以解决架构冲突，并按层路由指令以促进专家间知识共享。2) 基于梯度的跨模态持续课程，根据任务中每种模态的难度调整MLLM各模块的更新比例，以缓解模态不平衡问题。

**Result:** D-MoLE显著优于现有最先进的基线方法，平均性能比最佳基线提高了15%。

**Conclusion:** D-MoLE是首个从架构角度研究多模态大语言模型（MLLM）持续学习的方法，有效解决了持续多模态指令微调中的任务架构冲突和模态不平衡问题。

> **ai_Abstract:** 本文提出D-MoLE，一种新颖的动态课程LoRA专家混合方法，用于持续多模态指令微调。该方法旨在解决现有MLLM在适应新任务时面临的固定架构和模态不平衡问题。D-MoLE通过动态层级专家分配器自动调整模型架构以解决任务冲突，并通过基于梯度的跨模态持续课程来平衡模态更新。实验结果表明，D-MoLE显著优于现有基线，平均性能提升15%，是首次从架构角度研究MLLM持续学习。

> **摘要翻译:** 持续多模态指令微调对于使多模态大语言模型（MLLM）适应不断演进的任务至关重要。然而，大多数现有方法采用固定架构，由于静态模型容量而难以适应新任务。我们提出在参数预算下演进架构以实现动态任务适应，这仍然未被探索并带来了两个挑战：1）任务架构冲突，即不同任务需要不同的层级适应；2）模态不平衡，即不同任务对模态的依赖不均，导致更新不平衡。为了解决这些挑战，我们提出了一种新颖的动态课程LoRA专家混合（D-MoLE）方法，该方法在受控参数预算下自动演进MLLM的架构，以持续适应新任务，同时保留先前学习到的知识。具体来说，我们提出了一种动态层级专家分配器，它自动在各层分配LoRA专家以解决架构冲突，并按层路由指令以促进专家间知识共享。然后，我们提出了一种基于梯度的跨模态持续课程，它根据任务中每种模态的难度调整MLLM各模块的更新比例，以缓解模态不平衡问题。大量实验表明，D-MoLE显著优于最先进的基线方法，比最佳基线平均提高了15%。据我们所知，这是首次从架构角度研究MLLM的持续学习。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [516] [Cross-Modal Clustering-Guided Negative Sampling for Self-Supervised Joint Learning from Medical Images and Reports](https://arxiv.org/abs/2506.11674)
> *跨模态聚类引导的负采样用于医学图像和报告的自监督联合学习*

*Libin Lan, Hongxing Li, Zunhui Xia, Juan Zhou, Xiaofei Zhu, Yongmei Li, Yudong Zhang, Xin Luo* | **Main category: cs.CV**

**Keywords:** 跨模态学习, 自监督学习, 负采样, 医学图像分析, 多模态学习

**Comment:** This work has been submitted to the IEEE TMI for possible
  publication. Our code is available at https://github.com/violet-42/CM-CGNS

> **TL;DR:** 该论文提出了CM-CGNS方法，通过解决现有自监督多模态学习中负样本选择、全局特征与局部细节以及低级特征保留的问题，改进了从医学图像和报告中学习医学视觉表征的能力。

**AI_Comments:** 这篇论文提供了一种创新的方法来改进医学图像分析中的自监督学习，通过专门解决多模态学习中的常见限制：负样本的质量、细粒度局部特征的重要性以及低级信息的保留。涉及跨模态聚类用于负采样和掩蔽图像重建以获取局部细节和交互的双重方法似乎是一个重要的贡献，可能导致更鲁棒和准确的医学诊断工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有从配对医学图像和报告中进行多模态自监督学习的模型存在严重局限性：1) 忽视负样本选择，导致硬负样本稀缺和假负样本包含；2) 侧重全局特征提取，忽视医学图像识别任务中关键的细粒度局部细节；3) 对比学习主要针对高级特征，忽略了对准确医学分析至关重要的低级细节。

**Method:** 本文提出了跨模态聚类引导的负采样（CM-CGNS）方法，包含两点：1) 通过跨模态注意力将用于单模态域局部文本特征的k-means聚类扩展到多模态域，以增加负样本数量并提升模型表示能力。2) 引入跨模态掩蔽图像重建（CM-MIR）模块，利用通过跨模态注意力获得的局部文本到图像特征来重建掩蔽的局部图像区域，从而显著增强模型的跨模态信息交互能力并保留低级图像特征。

**Result:** 在五个下游数据集上的分类、检测和分割任务的广泛实验结果表明，所提出的方法在多个指标上优于最先进的方法。

**Conclusion:** 所提出的CM-CGNS方法能够很好地处理现有方法的局限性，学习到有效且鲁棒的医学视觉表征，适用于各种识别任务，并已通过实验验证其卓越性能。

> **ai_Abstract:** 该论文针对现有从医学图像和报告中进行多模态自监督学习的局限性，特别是负样本选择、局部细节关注和低级特征保留问题，提出了一种名为跨模态聚类引导的负采样（CM-CGNS）的新方法。CM-CGNS通过将k-means聚类扩展到多模态域来改进负样本采样，并引入了一个跨模态掩蔽图像重建（CM-MIR）模块，利用局部文本到图像特征重建图像区域，从而增强跨模态交互并保留低级特征。在五个数据集上的分类、检测和分割任务的广泛实验结果表明，CM-CGNS在多项指标上优于现有最先进的方法。

> **摘要翻译:** 学习医学视觉表征直接从配对的图像和报告中通过多模态自监督学习，已成为近年来数字诊断的一种新颖且高效的方法。然而，现有模型存在几个严重的局限性。1) 忽视负样本的选择，导致硬负样本稀缺和假负样本的包含；2) 侧重于全局特征提取，但忽视了对医学图像识别任务至关重要的细粒度局部细节；以及3) 对比学习主要针对高级特征，但忽略了对准确医学分析至关重要的低级细节。受这些关键问题的启发，本文提出了一种跨模态聚类引导的负采样（CM-CGNS）方法，其包含两方面的思想。首先，它通过跨模态注意力将用于单模态域局部文本特征的k-means聚类扩展到多模态域。这一改进增加了负样本的数量并提升了模型的表示能力。其次，它引入了一个跨模态掩蔽图像重建（CM-MIR）模块，该模块利用通过跨模态注意力获得的局部文本到图像特征来重建掩蔽的局部图像区域。该模块显著增强了模型的跨模态信息交互能力，并保留了下游任务所需的低级图像特征。通过很好地处理上述局限性，所提出的CM-CGNS可以学习适用于各种识别任务的有效且鲁棒的医学视觉表征。在五个下游数据集上的分类、检测和分割任务的广泛实验结果表明，我们的方法在多个指标上优于最先进的方法，验证了其卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [520] [Predicting Patient Survival with Airway Biomarkers using nn-Unet/Radiomics](https://arxiv.org/abs/2506.11677)
> *使用nn-Unet/放射组学预测气道生物标志物对患者生存率的影响*

*Zacharia Mesbah, Dhruv Jain, Tsiry Mayet, Romain Modzelewski, Romain Herault, Simon Bernard, Sebastien Thureau, Clement Chatelain* | **Main category: cs.CV**

**Keywords:** 气道生物标志物, 生存预测, nn-Unet, 放射组学, 肺纤维化

**Comment:** 8 pages

> **TL;DR:** 本研究使用nn-Unet和放射组学预测肺纤维化患者的生存率，并取得了良好的分割和分类分数。

**AI_Comments:** 该研究结合了深度学习（nn-Unet）和传统机器学习（SVM/放射组学）方法，为肺纤维化患者生存预测提供了一个多模态的分析框架。其创新点在于将气道区域的放射组学特征作为生存预测的生物标志物，并取得了不错的初步效果。

<details>
  <summary>Details</summary>

**Motivation:** 评估气道相关影像生物标志物在确定肺纤维化患者生存结果中的预测意义，并探索气管区域和气道结构尺寸中可能存在的关键生存相关信息。

**Method:** 采用三阶段方法：首先使用nn-Unet分割气道结构边界；随后从以气管为中心和围绕气道的边界框内的放射组学图像中提取关键特征；最后将从分割区域获得的放射组学特征整合到SVM分类器中。

**Result:** 在任务1（分割）中获得0.8601的总分，在任务2（分类）中获得0.7346的总分。

**Conclusion:** 该方法在预测肺纤维化患者生存率方面表现出有效的性能，分割和分类均达到较高分数，证实了气道生物标志物的预测潜力。

> **ai_Abstract:** 本研究针对AIIB 2023竞赛，旨在评估气道影像生物标志物对肺纤维化患者生存率的预测价值。研究提出一个三阶段方法：首先使用nn-Unet分割气道，接着从气管区域和气道边界框中提取放射组学特征，最后将这些特征输入SVM分类器。实验结果显示，分割任务得分0.8601，分类任务得分0.7346，表明该方法在预测患者生存方面具有潜力。

> **摘要翻译:** AIIB 2023竞赛的主要目标是评估气道相关影像生物标志物在确定肺纤维化患者生存结果中的预测意义。本研究介绍了一种全面的三阶段方法。首先，采用分割网络nn-Unet来描绘气道的结构边界。随后，从以气管为中心和围绕气道的外包围盒的放射组学图像中提取关键特征。这一步的动机是气管区域内可能存在关键的生存相关信息，以及气道结构和尺寸中编码的相关信息。最后，将从分割区域获得的放射组学特征整合到SVM分类器中。我们在任务1的分割中获得了0.8601的总分，在任务2的分类中获得了0.7346的总分。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [524] [Pose Matters: Evaluating Vision Transformers and CNNs for Human Action Recognition on Small COCO Subsets](https://arxiv.org/abs/2506.11678)
> *姿态很重要：评估视觉Transformer和CNN在小型COCO子集上的人体动作识别*

*MingZe Tang, Madiha Kazi* | **Main category: cs.CV**

**Keywords:** 人体动作识别, Vision Transformer, 卷积神经网络, COCO数据集, 可解释性AI

**Comment:** 7 pages, 9 figures

> **TL;DR:** 研究发现Vision Transformer在小型COCO子集上的人体动作识别中表现远超CNN，并且能更准确地关注姿态信息。

**AI_Comments:** 该研究强调了Vision Transformer在处理姿态相关任务上的优越性，特别是在数据量有限的情况下。其创新之处在于结合了可解释性技术来诊断模型失败的原因，揭示了ViT能够更有效地关注关键的姿态信息，而传统模型则容易被背景噪声干扰。这对于理解深度学习模型的工作机制及其在特定应用中的局限性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索在小型COCO图像子集上，从简单全连接网络到Transformer架构的不同模型在人体动作识别任务上的性能，并分析其成功和失败的原因。

**Method:** 本研究使用COCO图像语料库的三分类子集进行人体动作识别，并对Vision Transformer (ViT)、卷积网络 (CNNs)、CLIP-based模型和简单全连接网络进行了基准测试。通过单向ANOVA进行统计显著性检验，并利用SHAP解释器和LeGrad热图进行定性分析，以理解模型关注的区域。

**Result:** 二元Vision Transformer (ViT) 实现了90%的平均测试准确率，显著高于卷积网络（约35%）和CLIP-based模型（约62-64%）。这些差异经单向ANOVA检验（F = 61.37, p < 0.001）证实具有统计显著性。定性分析表明，ViT能够定位姿态特定区域（如行走或跑步的下肢），而较简单的前馈模型常关注背景纹理，导致错误。

**Conclusion:** 研究结果强调了Transformer表示的数据效率及其在人体动作识别中的优越性，并指出可解释性技术在诊断特定类别失败方面的重要性。ViT在识别姿态相关特征方面表现出色。

> **ai_Abstract:** 本研究评估了在小型COCO子集上进行人体动作识别的各种模型。结果显示，Vision Transformer (ViT) 在准确性上显著优于卷积网络和CLIP模型，达到了90%的准确率。通过可解释性分析发现，ViT能够准确识别与姿态相关的区域，而其他模型则倾向于关注背景。研究强调了Transformer的数据效率和可解释性技术的重要性。

> **摘要翻译:** 本研究探讨了使用COCO图像语料库的三分类子集进行人体动作识别，对从简单全连接网络到Transformer架构的模型进行了基准测试。二元视觉Transformer (ViT) 实现了90%的平均测试准确率，显著超过了多分类器，如卷积网络（约35%）和基于CLIP的模型（约62-64%）。单向ANOVA（F = 61.37，p < 0.001）证实这些差异具有统计显著性。使用SHAP解释器和LeGrad热图进行的定性分析表明，ViT能定位姿态特定区域（例如，行走或跑步的下肢），而较简单的前馈模型通常关注背景纹理，这解释了它们的错误。这些发现强调了Transformer表示的数据效率以及可解释性技术在诊断特定类别故障方面的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [528] [MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space](https://arxiv.org/abs/2506.11684)
> *MTabVQA：评估语言模型在视觉空间中的多表格推理能力*

*Anshul Singh, Chris Biemann, Jan Strich* | **Main category: cs.CV**

**Keywords:** 多表格推理, 视觉-语言模型, MTabVQA, 视觉问答, 指令微调

**Comment:** 

> **TL;DR:** MTabVQA引入了一个新的基准测试，用于评估视觉-语言模型（VLMs）在多表格视觉问答方面的多跳推理能力，并展示了通过指令微调可以显著提高性能。

**AI_Comments:** MTabVQA填补了现有基准测试在评估VLM多表格视觉推理能力方面的空白，特别是在真实世界场景中常见的复杂多表格数据上。引入MTabVQA-Instruct数据集和指令微调方法，为提升VLM在这一挑战性任务上的性能提供了有效的途径，对推动VLM在文档理解和信息抽取等领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）在解释视觉布局和文本方面表现出色，但在解释和推理以图像形式呈现的多表格数据（如网页和数字文档）时仍面临重大挑战。现有基准测试通常只涉及单一表格或非视觉数据，这导致无法评估VLM解析多样表格图像、关联信息和执行多跳推理的能力。

**Method:** 研究引入了MTabVQA，一个专门为多表格视觉问答设计的基准测试，包含3,745个需要跨多个视觉渲染表格图像进行多跳推理的复杂问答对。研究提供了最先进VLM在MTabVQA上的广泛基准测试结果，并进一步研究了后训练技术以增强推理能力。此外，研究发布了MTabVQA-Instruct，一个大规模的指令微调数据集。

**Result:** 最先进的视觉-语言模型在MTabVQA上表现出显著的性能局限性。通过使用MTabVQA-Instruct对VLM进行微调，它们的视觉多表格推理性能得到了显著提升。

**Conclusion:** MTabVQA基准测试揭示了当前视觉-语言模型在多表格视觉推理方面的局限性，并通过指令微调证明了显著提升模型性能的可行性。

> **ai_Abstract:** 本文介绍了MTabVQA，一个用于评估视觉-语言模型（VLMs）在视觉空间中多表格推理能力的新型基准测试。该基准包含3,745个复杂的多跳问答对，要求模型跨多个表格图像进行推理。研究发现当前VLMs在该任务上存在显著性能限制，但通过使用MTabVQA-Instruct（一个大规模指令微调数据集）进行微调，可以显著提高模型的视觉多表格推理能力。

> **摘要翻译:** 视觉-语言模型（VLMs）在解释视觉布局和文本方面表现出卓越的能力。然而，它们在稳健地解释和推理以图像形式呈现的多表格数据方面仍然面临重大挑战，这在网页和数字文档等现实世界场景中非常常见。现有的基准测试通常处理单一表格或非视觉数据（文本/结构化数据）。这留下了一个关键的空白：它们没有评估解析多样表格图像、关联信息以及对组合视觉数据执行多跳推理的能力。我们引入了MTabVQA，一个专门为多表格视觉问答设计的新型基准测试，以弥补这一空白。MTabVQA包含3,745个复杂的问答对，这些问题需要跨多个视觉渲染的表格图像进行多跳推理。我们提供了最先进VLM在MTabVQA上的广泛基准测试结果，揭示了显著的性能局限性。我们进一步研究了后训练技术以增强这些推理能力，并发布了MTabVQA-Instruct，一个大规模的指令微调数据集。我们的实验表明，使用MTabVQA-Instruct对VLM进行微调可以显著提高它们在视觉多表格推理方面的性能。代码和数据集（https://huggingface.co/datasets/mtabvqa/MTabVQA-Eval）可在网上获取（https://anonymous.4open.science/r/MTabVQA-EMNLP-B16E）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [531] [DMAF-Net: An Effective Modality Rebalancing Framework for Incomplete Multi-Modal Medical Image Segmentation](https://arxiv.org/abs/2506.11691)
> *DMAF-Net：一种用于不完整多模态医学图像分割的有效模态再平衡框架*

*Libin Lan, Hongxing Li, Zunhui Xia, Yudong Zhang* | **Main category: cs.CV**

**Keywords:** 多模态图像分割, 模态不平衡, 深度学习, 缺失数据, 医学图像分析

**Comment:** 12 pages, 4 figures, 3 tables

> **TL;DR:** DMAF-Net是一个用于不完整多模态医学图像分割的新模型，它通过动态模态感知融合、关系与原型蒸馏以及动态训练监控策略，解决了模态不平衡和缺失问题，并在实验中表现优异。

**AI_Comments:** DMAF-Net的创新之处在于其综合性的解决方案，通过三个核心模块（DMAF、关系与原型蒸馏、DTM）系统地解决了不完整多模态医学图像分割中的复杂挑战。特别是，结合Transformer注意力与自适应掩蔽处理模态贡献、通过蒸馏确保特征和语义一致性，以及动态监控训练过程以应对不平衡缺失率，这些都显示了其方法设计的精妙和全面性。该框架对于提升真实临床场景下医学图像分割的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在不完整多模态医学图像分割中表现不佳，因为它们依赖于完整的模态可用性，未能动态平衡模态贡献，并且忽略了模态间的结构关系，导致在真实临床场景中性能不理想。

**Method:** 本文提出了动态模态感知融合网络（DMAF-Net），其包含三个关键思想：1. 引入动态模态感知融合（DMAF）模块，通过结合Transformer注意力与自适应掩蔽，并动态加权模态贡献来抑制缺失模态干扰。2. 设计协同关系蒸馏和原型蒸馏框架，通过协方差一致性和掩蔽图注意力强制全局-局部特征对齐，并通过跨模态类特异性原型对齐确保语义一致性。3. 提出动态训练监控（DTM）策略，通过实时跟踪蒸馏间隙来稳定不平衡缺失率下的优化，并通过自适应重新加权损失和缩放梯度来平衡模态间的收敛速度。

**Result:** 在BraTS2020和MyoPS2020数据集上的大量实验表明，DMAF-Net在不完整多模态医学图像分割方面优于现有方法。

**Conclusion:** DMAF-Net有效解决了不完整多模态医学图像分割中的模态不平衡挑战，并通过其创新的模块和策略实现了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为DMAF-Net的新型框架，旨在解决不完整多模态医学图像分割中存在的模态不平衡（包括缺失率不平衡和贡献异构）问题。该框架通过引入动态模态感知融合（DMAF）模块来处理缺失模态干扰，设计协同关系与原型蒸馏框架以确保特征和语义一致性，并采用动态训练监控（DTM）策略来稳定优化和平衡收敛速度。实验证明，DMAF-Net在多个医学图像数据集上优于现有方法。

> **摘要翻译:** 不完整多模态医学图像分割面临模态不平衡带来的严峻挑战，包括模态缺失率不平衡和异构模态贡献。由于现有方法依赖于完整模态可用的理想化假设，它们无法动态平衡贡献并忽略模态间的结构关系，导致在真实临床场景中性能不理想。为了解决这些限制，我们提出了一种名为动态模态感知融合网络（DMAF-Net）的新颖模型。DMAF-Net采用了三个关键思想。首先，它引入了动态模态感知融合（DMAF）模块，通过结合Transformer注意力与自适应掩蔽，并通过注意力图动态加权模态贡献来抑制缺失模态干扰。其次，它设计了一个协同关系蒸馏和原型蒸馏框架，通过协方差一致性和掩蔽图注意力强制全局-局部特征对齐，同时通过跨模态类特异性原型对齐确保语义一致性。第三，它提出了一种动态训练监控（DTM）策略，通过实时跟踪蒸馏间隙来稳定不平衡缺失率下的优化，并通过自适应重新加权损失和缩放梯度来平衡模态间的收敛速度。在BraTS2020和MyoPS2020上的大量实验表明，DMAF-Net在不完整多模态医学图像分割方面优于现有方法。我们的代码可在https://github.com/violet-42/DMAF-Net获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model](https://arxiv.org/abs/2506.11737)
> *Quizzard@INOVA 挑战 2025 -- A 赛道：交错多图像模型中的即插即用技术*

*Dinh Viet Cuong, Hoang-Bao Le, An Pham Ngoc Nguyen, Liting Zhou, Cathal Gurrin* | **Main category: cs.CV**

**Keywords:** LLaVA-NeXT-interleave, 即插即用技术, 多图像模型, 密集通道集成, 多模态通信

**Comment:** 

> **TL;DR:** 本文评估了LLaVA-NeXT-interleave模型在多图像任务中的性能，并探索了通过添加DCI连接器来增强其能力。研究发现标准模型在视觉密集型任务中表现最佳，而DCI增强版在需要深层语义理解的任务中表现突出。

**AI_Comments:** 本文探索了在多图像模型中应用即插即用技术的潜力，通过对比标准模型和DCI增强版的表现，揭示了不同技术在处理不同类型任务时的优势。这种模块化增强方法对于未来多模态模型的发展具有重要意义，尤其是在平衡通用性能和特定任务优化方面提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 旨在评估LLaVA-NeXT-interleave模型在多图像推理、文档和知识理解以及交互式多模态通信等任务中的性能，并探索即插即用技术（如DCI连接器）对其性能的影响。

**Method:** 首先，在22个数据集上评估了LLaVA-NeXT-interleave模型在多图像推理、文档和知识理解以及交互式多模态通信这三种任务上的性能。其次，将密集通道集成（DCI）连接器添加到LLaVA-NeXT-Interleave模型中，并将其性能与标准模型进行比较。

**Result:** 标准的LLaVA-NeXT-interleave模型在整体准确性上表现最佳，尤其擅长VISION、NLVR2和Fashion200K等视觉密集型任务。DCI增强版在需要更深层语义连贯性或结构化变化理解的数据集（如MIT-States_PropertyCoherence和SlideVQA）上表现出特别的优势。

**Conclusion:** 结合强大的基础模型与即插即用技术在交错任务中具有巨大潜力。

> **ai_Abstract:** 本文评估了LLaVA-NeXT-interleave模型在多图像推理、文档理解和多模态通信等任务中的性能。研究通过引入密集通道集成（DCI）连接器来增强模型，并与标准模型进行对比。结果显示，标准模型在视觉密集型任务中表现优异，而DCI增强版在需要深层语义理解的任务中更具优势。这表明将基础模型与即插即用技术相结合在处理交错任务方面具有广阔前景。

> **摘要翻译:** 本文旨在解决两个主要目标。首先，我们展示了LLaVA-NeXT-interleave在22个数据集上，跨多图像推理、文档和基于知识的理解以及交互式多模态通信这三种不同任务中的出色性能。其次，我们将密集通道集成（DCI）连接器添加到LLaVA-NeXT-Interleave中，并将其性能与标准模型进行比较。我们发现标准模型实现了最高的整体准确性，在VISION、NLVR2和Fashion200K等视觉密集型任务中表现出色。同时，DCI增强版在需要更深层语义连贯性或结构化变化理解的数据集（如MIT-States_PropertyCoherence和SlideVQA）上显示出特别的优势。我们的结果强调了将强大基础模型与即插即用技术相结合用于交错任务的潜力。代码可在https://github.com/dinhvietcuong1996/icme25-inova获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [541] [MambaVSR: Content-Aware Scanning State Space Model for Video Super-Resolution](https://arxiv.org/abs/2506.11768)
> *MambaVSR：内容感知扫描状态空间模型用于视频超分辨率*

*Linfeng He, Meiqin Liu, Qi Tang, Chao Yao, Yao Zhao* | **Main category: cs.CV**

**Keywords:** 视频超分辨率, 状态空间模型, 内容感知扫描, 时空交互, MambaVSR

**Comment:** 

> **TL;DR:** MambaVSR是首个将内容感知扫描机制引入视频超分辨率（VSR）的状态空间模型（SSM）框架，通过创新的模块解决了现有方法在处理大运动和长序列时效率低下的问题，并在性能和参数效率上超越了基于Transformer的方法。

**AI_Comments:** MambaVSR的创新点在于首次将状态空间模型引入视频超分辨率领域，并针对其特性设计了内容感知扫描机制。通过SCC、CAS和GLSSB等模块，它成功克服了传统Mamba模型在视觉任务中僵硬的1D处理限制，实现了动态时空交互。其在性能提升的同时显著降低了参数量，显示出极高的计算效率，这对于实际应用具有重要意义。该工作为VSR领域提供了一个有前景的新方向，即利用SSM的优势来有效处理视频中的长距离依赖和运动。

<details>
  <summary>Details</summary>

**Motivation:** 视频超分辨率（VSR）在有效建模未对齐帧之间的非局部依赖性同时保持计算效率方面面临严峻挑战。现有VSR方法通常依赖于光流策略或Transformer架构，这些方法在处理大运动位移和长视频序列时表现不佳。

**Method:** 本文提出了MambaVSR，这是首个将内容感知扫描机制引入VSR的状态空间模型框架。与传统视觉Mamba方法中僵硬的1D序列处理不同，MambaVSR通过共享指南针构建（SCC）和内容感知序列化（CAS）实现动态时空交互。具体来说，SCC模块通过高效的稀疏注意力构建帧内语义连接图，并通过谱聚类生成自适应空间扫描序列。在此基础上，CAS模块通过沿学习到的空间顺序交错时间特征，有效地对齐和聚合多帧间的非局部相似内容。为了连接全局依赖性与局部细节，全局-局部状态空间块（GLSSB）将窗口自注意力操作与基于SSM的特征传播协同集成，从而在全局依赖性指导下恢复高频细节。

**Result:** MambaVSR在REDS数据集上比基于Transformer的方法在PSNR上高出0.58 dB，并且参数量减少了55%。

**Conclusion:** MambaVSR通过引入内容感知扫描的状态空间模型，有效地解决了VSR中非局部依赖建模和计算效率的挑战，并在性能和参数效率上显著优于现有基于Transformer的方法。

> **ai_Abstract:** MambaVSR是首个将状态空间模型（SSM）应用于视频超分辨率（VSR）的框架，旨在解决现有方法在处理大运动和长视频序列时建模非局部依赖性及计算效率的不足。该模型引入了内容感知扫描机制，通过共享指南针构建（SCC）和内容感知序列化（CAS）模块实现动态时空交互，其中SCC构建帧内语义图并生成自适应扫描序列，CAS则基于此对齐并聚合跨帧内容。此外，全局-局部状态空间块（GLSSB）结合自注意力和SSM进行特征传播，以恢复高频细节。实验证明，MambaVSR在REDS数据集上优于Transformer基线，PSNR提升0.58 dB，同时参数量减少55%。

> **摘要翻译:** 视频超分辨率（VSR）在有效建模未对齐帧之间的非局部依赖性同时保持计算效率方面面临严峻挑战。现有VSR方法通常依赖于光流策略或Transformer架构，这些方法在处理大运动位移和长视频序列时表现不佳。为了解决这个问题，我们提出了MambaVSR，这是首个将创新内容感知扫描机制纳入VSR的状态空间模型框架。与传统视觉Mamba方法中僵硬的1D序列处理不同，我们的MambaVSR通过共享指南针构建（SCC）和内容感知序列化（CAS）实现了动态时空交互。具体来说，SCC模块通过高效的稀疏注意力构建帧内语义连接图，并通过谱聚类生成自适应空间扫描序列。在SCC的基础上，CAS模块通过沿学习到的空间顺序交错时间特征，有效地对齐和聚合多帧间的非局部相似内容。为了连接全局依赖性与局部细节，全局-局部状态空间块（GLSSB）将窗口自注意力操作与基于SSM的特征传播协同集成，从而在全局依赖性指导下恢复高频细节。广泛的实验验证了MambaVSR的优越性，在REDS数据集上，其PSNR比基于Transformer的方法高出0.58 dB，且参数量减少了55%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [544] [CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection](https://arxiv.org/abs/2506.11772)
> *CLIP遇上扩散模型：一种协同的异常检测方法*

*Byeongchan Lee, John Won, Seunghyun Lee, Jinwoo Shin* | **Main category: cs.CV**

**Keywords:** 异常检测, CLIP, 扩散模型, 多模态融合, 深度学习

**Comment:** 

> **TL;DR:** CLIPFUSION结合判别式CLIP和生成式扩散模型，有效解决异常检测中数据稀缺和特征捕捉的挑战，在基准数据集上表现优异。

**AI_Comments:** CLIPFUSION的创新之处在于将CLIP的判别能力与扩散模型的生成能力相结合，实现对异常的全面捕捉，尤其是在数据稀缺场景下。其利用扩散模型特有的交叉注意力图和特征图进行异常检测，为该领域提供了新的视角。该方法在实际应用中具有很高的可扩展性，对于解决复杂多样的异常检测问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 异常检测因异常定义模糊、类型多样以及训练数据稀缺而复杂，需要一种能够捕捉低级和高级特征的综合模型，即使在有限数据下也能工作。

**Method:** 提出CLIPFUSION方法，结合基于CLIP的判别式模型（捕捉全局特征）和基于扩散的生成式模型（捕捉局部细节），形成协同互补的方法。特别引入了利用从扩散模型中提取的交叉注意力图和特征图进行异常检测的机制。

**Result:** 在MVTec-AD和VisA基准数据集上的实验结果表明，CLIPFUSION持续优于基线方法，在异常分割和分类方面均取得了出色的性能。

**Conclusion:** 该方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为实际应用提供了可扩展的解决方案。

> **ai_Abstract:** 本文提出CLIPFUSION，一种结合判别式CLIP模型和生成式扩散模型的新型异常检测方法。该方法旨在解决异常定义模糊、类型多样和数据稀缺等挑战。CLIP负责全局特征，扩散模型捕捉局部细节，并创新性地利用扩散模型的交叉注意力图和特征图。实验结果表明，CLIPFUSION在MVTec-AD和VisA数据集上显著优于现有方法，在异常分割和分类任务上表现卓越，证明了多模态和多模型融合在异常检测领域的潜力。

> **摘要翻译:** 异常检测是一个复杂的问题，原因在于异常定义的模糊性、异常类型的多样性（例如，局部和全局缺陷）以及训练数据的稀缺性。因此，它需要一个能够捕捉低级和高级特征的综合模型，即使在有限的数据下也能工作。为了解决这个问题，我们提出了CLIPFUSION，一种利用判别式和生成式基础模型的方法。具体来说，基于CLIP的判别式模型擅长捕捉全局特征，而基于扩散的生成式模型有效地捕捉局部细节，从而创建了一种协同互补的方法。值得注意的是，我们引入了一种专门用于异常检测的利用从扩散模型中提取的交叉注意力图和特征图的方法。在基准数据集（MVTec-AD、VisA）上的实验结果表明，CLIPFUSION持续优于基线方法，在异常分割和分类方面均取得了出色的性能。我们相信，我们的方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为实际应用提供了可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [553] [GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers](https://arxiv.org/abs/2506.11784)
> *GPLQ：一种通用、实用且闪电般的视觉Transformer QAT方法*

*Guang Liang, Xinyao Liu, Jianxin Wu* | **Main category: cs.CV**

**Keywords:** 视觉Transformer, 模型量化, 量化感知训练, 低比特量化, GPLQ

**Comment:** 

> **TL;DR:** GPLQ是一种快速高效的ViT量化感知训练方法，通过两阶段策略实现4比特高精度和强泛化性。

**AI_Comments:** GPLQ的创新在于其“激活优先，权重靠后”的两阶段量化策略，并成功地将激活量化与保持模型优化“盆地”的概念结合，显著提升了量化效率和泛化能力。其100倍的速度提升和低于FP32训练的内存占用，以及对下游任务的良好泛化性，使其成为ViT实用量化的重要进展，尤其解决了QAT高成本和泛化差的痛点。开源工具包的发布将进一步促进其应用。

<details>
  <summary>Details</summary>

**Motivation:** 视觉Transformer计算密集，现有量化方法（PTQ和QAT）存在局限：PTQ精度下降大，QAT计算成本高、泛化性差、训练不稳定且缺乏开源代码。

**Method:** GPLQ基于激活量化重要性和保持模型原始优化“盆地”的洞察。采用两阶段策略：阶段1，权重保持FP32，仅用1个epoch通过特征模仿损失量化激活，以保持泛化性；阶段2，使用PTQ方法量化权重。

**Result:** GPLQ比现有QAT方法快100倍，内存占用低于FP32训练，4比特模型在ImageNet精度和对下游任务（如细粒度视觉分类和目标检测）的泛化性方面与FP32模型高度竞争。将发布易于使用的开源工具包。

**Conclusion:** GPLQ成功解决了ViT量化的挑战，提供了一种高效、高精度且泛化性强的4比特量化方案。

> **ai_Abstract:** 本文提出了一种名为GPLQ的新型ViT量化框架，旨在解决现有量化方法在效率和精度上的不足。GPLQ基于“先激活，后权重”的两阶段策略，通过仅1个epoch的训练量化激活，并保持模型泛化性。实验表明，GPLQ比现有QAT方法快100倍，内存占用更低，且4比特模型在精度和泛化性方面与FP32模型相当。

> **摘要翻译:** 视觉Transformer (ViT) 在计算机视觉中至关重要，但也计算密集。模型量化，特别是低比特宽度如4比特量化，旨在缓解这一困难，但现有的训练后量化 (PTQ) 和量化感知训练 (QAT) 方法存在显著局限性。PTQ 通常会导致显著的精度下降，而 QAT 尽管能实现高精度，但却面临着高昂的计算成本、对下游任务泛化能力有限、训练不稳定以及缺乏开源代码库等问题。为了应对这些挑战，本文引入了通用、实用且闪电般量化 (GPLQ)，这是一个专为高效和有效 ViT 量化设计的新颖框架。GPLQ 基于两个关键的经验洞察：激活量化的至关重要性以及保持模型原始优化“盆地”以维持泛化能力的必要性。因此，GPLQ 采用顺序的“先激活，后权重”策略。阶段1 保持权重为 FP32，同时仅用1个 epoch 使用特征模仿损失量化激活，以使其保持在相同的“盆地”中，从而保留泛化能力。阶段2 使用 PTQ 方法量化权重。结果，GPLQ 比现有 QAT 方法快 100 倍，内存占用甚至低于 FP32 训练水平，并且在 ImageNet 精度和对各种下游任务（包括细粒度视觉分类和目标检测）的泛化能力方面，其 4 比特模型性能与 FP32 模型具有高度竞争力。我们将发布一个支持多种视觉任务的易于使用的开源工具包。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [557] [Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation](https://arxiv.org/abs/2506.11820)
> *重新思考多语言视觉-语言翻译：数据集、评估与适应*

*Xintong Wang, Jingheng Pan, Yixiao Liu, Xiaohu Zhao, Chenyang Lyu, Minghao Wu, Chris Biemann, Longyue Wang, Linlong Xu, Weihua Luo, Kaifu Zhang* | **Main category: cs.CV**

**Keywords:** 视觉-语言翻译, 多语言, 数据集, 评估, 大型视觉-语言模型

**Comment:** 

> **TL;DR:** 本文通过引入新的数据集AibTrans、基准测试多模态模型并提出密度感知评估方法，全面研究了多语言视觉-语言翻译（VLT）的局限性，并提出了一种平衡的多语言微调策略以提高LVLM在VLT任务上的性能。

**AI_Comments:** 这篇论文通过构建高质量数据集、全面基准测试和提出创新评估方法，对多语言视觉-语言翻译领域做出了重要贡献。AibTrans数据集的引入解决了现有数据在语义和文化保真度上的不足，为后续研究提供了坚实基础。密度感知评估方法的提出，特别是DA分数的引入，提高了VLT评估的鲁棒性。此外，关于微调策略对跨语言性能影响的发现，并提出平衡微调策略，为LVLMs在VLT任务上的实际应用和优化提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管最近的大型视觉-语言模型（LVLMs）展示了强大的多语言和视觉理解能力，但目前缺乏对其在视觉-语言翻译（VLT）任务上性能的系统评估和理解。现有的数据集存在语义和文化保真度方面的局限性。

**Method:** 本研究从三个关键角度对VLT进行了全面研究：1. 数据质量：识别现有数据集的局限性，并引入了AibTrans，一个多语言、并行、人工验证且经过OCR校正标注的数据集。2. 模型架构：基准测试了11个商业LVLMs/LLMs和6个最先进的开源模型，涵盖端到端和级联架构。3. 评估指标：提出了密度感知评估（Density-Aware Evaluation）和DA分数，以解决不同上下文复杂性下的度量可靠性问题。基于这些发现，建立了一个新的VLT评估基准。此外，还提出了一种平衡的多语言微调策略来适应LVLMs到VLT。

**Result:** 1. 识别了现有VLT数据集在语义和文化保真度方面的关键局限性。2. 引入了AibTrans数据集，该数据集具有OCR校正标注。3. 对LVLMs/LLMs的基准测试揭示了它们的OCR依赖性以及生成与推理行为的对比。4. 提出了DA分数作为更鲁棒的翻译质量衡量标准。5. 观察到在资源丰富语言对上微调LVLMs会降低跨语言性能。6. 提出了一种平衡的多语言微调策略，该策略能有效适应LVLMs到VLT而不牺牲其泛化能力。

**Conclusion:** 本文全面研究了多语言视觉-语言翻译，解决了数据质量、模型架构和评估指标方面的挑战。通过引入新的数据集、评估基准和微调策略，本研究为LVLMs在VLT任务上的未来发展提供了宝贵的见解和方向。

> **ai_Abstract:** 本文深入探讨了多语言视觉-语言翻译（VLT）的挑战，指出现有大型视觉-语言模型（LVLMs）在此领域缺乏系统评估。为此，研究从数据、模型和评估三方面展开：首先，提出并发布了高质量、人工验证的AibTrans数据集，以弥补现有数据集的不足；其次，对多种商业和开源LVLMs/LLMs进行了基准测试，揭示了它们的OCR依赖性及行为差异；最后，引入了密度感知评估（DA Score）以提高评估的可靠性。研究还发现，在高资源语言对上微调LVLMs可能损害其跨语言性能，并提出了一种平衡的多语言微调策略，以在VLT任务上有效适应模型而不牺牲其泛化能力。

> **摘要翻译:** 视觉-语言翻译（VLT）是一项具有挑战性的任务，它需要准确识别图像中嵌入的多语言文本，并在视觉上下文的支持下将其翻译成目标语言。尽管最近的大型视觉-语言模型（LVLMs）展示了强大的多语言和视觉理解能力，但目前缺乏对其在VLT上性能的系统评估和理解。在这项工作中，我们从数据质量、模型架构和评估指标三个关键角度对VLT进行了全面研究。(1) 我们识别了现有数据集中的关键局限性，特别是在语义和文化保真度方面，并引入了AibTrans——一个多语言、并行、人工验证且经过OCR校正标注的数据集。(2) 我们对11个商业LVLMs/LLMs和6个最先进的开源模型进行了基准测试，涵盖了端到端和级联架构，揭示了它们的OCR依赖性以及生成与推理行为的对比。(3) 我们提出了密度感知评估（Density-Aware Evaluation），以解决在不同上下文复杂性下度量可靠性问题，引入了DA分数作为更鲁棒的翻译质量衡量标准。基于这些发现，我们建立了一个新的VLT评估基准。值得注意的是，我们观察到在资源丰富语言对上微调LVLMs会降低跨语言性能，并且我们提出了一种平衡的多语言微调策略，该策略能有效适应LVLMs到VLT而不牺牲其泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [560] [Vision-based Lifting of 2D Object Detections for Automated Driving](https://arxiv.org/abs/2506.11839)
> *自动驾驶中基于视觉的二维目标检测到三维的提升*

*Hendrik Königshof, Kun Li, Christoph Stiller* | **Main category: cs.CV**

**Keywords:** 3D目标检测, 自动驾驶, 摄像头, 2D CNN, KITTI

**Comment:** https://ieeexplore.ieee.org/document/9190325

> **TL;DR:** 该论文提出了一种仅使用摄像头将2D目标检测结果提升为3D检测的管道，作为LiDAR的经济替代方案，并在KITTI基准测试中实现了与SOTA图像方法相当的性能和更低的运行时间。

**AI_Comments:** 这篇论文的创新点在于提出了一个经济高效的3D目标检测方案，通过巧妙地利用2D CNN处理点云来降低计算成本，这对于资源受限的自动驾驶系统来说非常重要。其能够处理所有类型的道路使用者也增加了方法的普适性。在性能与效率之间取得了良好的平衡，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶需要3D目标检测，但目前最先进的方法依赖昂贵的LiDAR数据。由于车载摄像头成本低廉且普遍存在，因此需要一种仅基于视觉的经济高效的3D目标检测替代方案。

**Method:** 论文提出了一种管道，将现有基于视觉的2D目标检测算法的结果提升为3D检测，仅使用摄像头。该方法不仅关注汽车，还涵盖所有类型的道路使用者。创新点在于首次使用2D CNN处理每个2D检测对应的点云，以降低计算量。

**Result:** 在KITTI 3D目标检测基准测试中，该方法取得了与最先进的图像基方法相当的结果，同时运行时间仅为后者的三分之一。

**Conclusion:** 该论文成功开发了一种经济高效的基于视觉的3D目标检测方法，通过创新性地使用2D CNN处理点云，在保持性能的同时显著降低了计算成本和运行时间，为自动驾驶提供了实用的替代方案。

> **ai_Abstract:** 该论文提出了一种名为“基于视觉的2D目标检测到3D提升”的管道，旨在为自动驾驶提供一种经济高效的3D目标检测方案，替代昂贵的LiDAR。该方法仅利用车载摄像头，将现有的2D检测结果提升为3D信息，并首次采用2D CNN处理每个2D检测对应的点云，以最小化计算开销。实验结果表明，该方法在KITTI 3D目标检测基准测试上实现了与现有最先进图像方法相当的性能，同时运行时间显著缩短至三分之一。

> **摘要翻译:** 基于图像的3D目标检测是自动驾驶不可或缺的一部分，因为廉价的车载摄像头已在大多数现代汽车中普及。由于精确的深度信息，目前大多数最先进的3D目标检测器严重依赖LiDAR数据。在本文中，我们提出了一种管道，该管道仅使用摄像头将现有基于视觉的2D算法的结果提升为3D检测，作为LiDAR的一种经济高效的替代方案。与现有方法不同，我们不仅关注汽车，还关注所有类型的道路使用者。据我们所知，我们是第一个使用2D CNN处理每个2D检测的点云以尽可能降低计算量的方法。我们在具有挑战性的KITTI 3D目标检测基准测试上的评估显示，其结果与最先进的基于图像的方法相当，同时运行时间仅为三分之一。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [SphereDrag: Spherical Geometry-Aware Panoramic Image Editing](https://arxiv.org/abs/2506.11863)
> *球体拖拽：球形几何感知全景图像编辑*

*Zhiao Feng, Xuewei Li, Junjie Yang, Yuxin Peng, Xi Li* | **Main category: cs.CV**

**Keywords:** 全景图像编辑, 球形几何, SphereDrag, 图像畸变, PanoBench

**Comment:** 

> **TL;DR:** 提出SphereDrag框架，通过利用球形几何知识解决全景图像编辑中的边界不连续、轨迹变形和像素密度不均等挑战，并构建了PanoBench基准，实验证明其在几何一致性和图像质量上优于现有方法。

**AI_Comments:** 这篇论文的创新点在于将球形几何知识系统地应用于全景图像编辑，提出了针对性的AR、GCTA和SSRT方法来解决现有挑战。构建PanoBench基准也为未来全景编辑研究提供了标准化评估工具，具有重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 平面图像编辑已取得巨大进展，但全景图像编辑仍未充分探索。由于其球形几何特性和投影畸变，全景图像编辑面临边界不连续、轨迹变形和像素密度不均三大挑战。

**Method:** 提出SphereDrag，一个利用球形几何知识实现精确可控的全景编辑框架。具体方法包括：自适应重投影（AR）处理不连续性；大圆轨迹调整（GCTA）更准确地跟踪移动轨迹；球形搜索区域跟踪（SSRT）根据球形位置自适应调整搜索范围以解决像素密度不均。此外，构建了PanoBench全景编辑基准，用于标准化评估。

**Result:** 实验表明，SphereDrag在几何一致性和图像质量方面比现有方法有显著改进，相对提升高达10.5%。

**Conclusion:** SphereDrag通过引入球形几何感知的方法，有效解决了全景图像编辑中的核心挑战，并在性能上超越了现有技术。

> **ai_Abstract:** 本文提出了SphereDrag，一个创新的全景图像编辑框架，旨在解决全景图像因其球形几何和投影畸变导致的边界不连续、轨迹变形和像素密度不均等问题。SphereDrag通过引入自适应重投影、大圆轨迹调整和球形搜索区域跟踪等技术，利用球形几何知识实现精确可控的编辑。为评估效果，作者还构建了PanoBench全景编辑基准。实验结果显示，SphereDrag在几何一致性和图像质量上显著优于现有方法，最高提升10.5%。

> **摘要翻译:** 图像编辑在平面图像上取得了巨大进展，但全景图像编辑仍未得到充分探索。由于其球形几何特性和投影畸变，全景图像面临三个关键挑战：边界不连续性、轨迹变形和像素密度不均匀。为了解决这些问题，我们提出了SphereDrag，一个利用球形几何知识进行精确和可控编辑的新型全景编辑框架。具体来说，自适应重投影（AR）使用自适应球形旋转来处理不连续性；大圆轨迹调整（GCTA）更准确地跟踪运动轨迹；球形搜索区域跟踪（SSRT）根据球形位置自适应缩放搜索范围以解决像素密度不均匀问题。此外，我们构建了PanoBench，一个全景编辑基准，包括涉及多个对象和多种风格的复杂编辑任务，它提供了一个标准化的评估框架。实验表明，与现有方法相比，SphereDrag在几何一致性和图像质量方面获得了显著改进，实现了高达10.5%的相对提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [567] [O2Former:Direction-Aware and Multi-Scale Query Enhancement for SAR Ship Instance Segmentation](https://arxiv.org/abs/2506.11913)
> *O2Former：面向SAR舰船实例分割的方向感知与多尺度查询增强*

*F. Gao, Y Li, X He, J Sun, J Wang* | **Main category: cs.CV**

**Keywords:** SAR图像, 实例分割, O2Former, 方向感知, 多尺度

**Comment:** 12 pages, 7 figures

> **TL;DR:** O2Former是一个针对SAR图像舰船实例分割的框架，通过优化查询生成器（OQG）和方向感知嵌入模块（OAEM）来解决尺度变化、目标密度和模糊边界等挑战，并超越了现有方法。

**AI_Comments:** O2Former的创新点在于其针对SAR图像特有的挑战（如尺度变化、模糊边界和不均匀方向）设计了专门的模块OQG和OAEM。这些模块能够有效利用SAR图像的结构特性，从而显著提升了舰船实例分割的性能。其方法基于Mask2Former进行扩展，显示了在现有先进架构上进行针对性优化的潜力，对于SAR图像处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** SAR图像中的舰船实例分割对于海洋监测、环境分析和国家安全等应用至关重要。然而，SAR舰船图像面临尺度变化、目标密度和模糊目标边界等挑战，现有方法常忽视这些问题，导致性能不佳。

**Method:** 本文提出了O2Former，一个专门的实例分割框架，它扩展了Mask2Former并充分利用SAR图像的结构特性。O2Former包含两个关键组件：1. 优化查询生成器（OQG），通过联合编码浅层位置线索和高层语义信息实现多尺度特征交互，以提高查询质量和收敛效率。2. 方向感知嵌入模块（OAEM），通过方向感知卷积和极坐标编码增强方向敏感性，以解决SAR场景中目标方向不均匀的挑战。这些模块共同促进精确特征对齐并增强模型捕获细粒度结构细节的能力。

**Result:** 大量实验表明，O2Former在SAR舰船数据集上优于最先进的实例分割基线，验证了其有效性和泛化能力。

**Conclusion:** O2Former通过引入优化查询生成器（OQG）和方向感知嵌入模块（OAEM），有效地解决了SAR图像舰船实例分割中的尺度变化、目标密度和目标方向不均匀等挑战，并在SAR舰船数据集上实现了超越现有SOTA方法的性能。

> **ai_Abstract:** O2Former是一个为SAR图像舰船实例分割设计的框架，它通过引入优化查询生成器（OQG）和方向感知嵌入模块（OAEM）来增强Mask2Former。OQG旨在提升多尺度特征交互和查询质量，而OAEM则通过方向感知和极坐标编码解决了目标方向不均匀问题。实验证明O2Former在SAR舰船数据集上表现优异，超越了现有SOTA方法。

> **摘要翻译:** 合成孔径雷达（SAR）图像中的舰船实例分割对于海洋监测、环境分析和国家安全等应用至关重要。SAR舰船图像面临尺度变化、目标密度和模糊目标边界等挑战，这些在现有方法中常被忽视，导致性能不佳。在这项工作中，我们提出了O2Former，一个专门的实例分割框架，它扩展了Mask2Former，充分利用了SAR图像的结构特征。我们引入了两个关键组件。第一个是优化查询生成器（OQG）。它通过联合编码浅层位置线索和高层语义信息来实现多尺度特征交互。这提高了查询质量和收敛效率。第二个组件是方向感知嵌入模块（OAEM）。它通过方向感知卷积和极坐标编码增强方向敏感性。这有效地解决了SAR场景中目标方向不均匀的挑战。这些模块共同促进了从主干网络到解码器的精确特征对齐，并增强了模型捕获细粒度结构细节的能力。大量实验表明，O2Former优于最先进的实例分割基线，验证了其在SAR舰船数据集上的有效性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [570] [Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation](https://arxiv.org/abs/2506.11924)
> *通过跨模态注意力注入实现对齐的新视角图像与几何合成*

*Min-Seop Kwak, Junho Kim, Sangdoo Yun, Dongyoon Han, Taekyoung Kim, Seungryong Kim, Jin-Hwa Kim* | **Main category: cs.CV**

**Keywords:** 新视角合成, 几何生成, 扩散模型, 跨模态注意力, 3D补全

**Comment:** 

> **TL;DR:** 该文提出一个基于扩散的框架，通过扭曲-修复方法和跨模态注意力蒸馏，实现新视角图像和几何的对齐生成。

**AI_Comments:** 该论文通过引入跨模态注意力蒸馏，巧妙地解决了新视角图像和几何生成中的对齐难题，实现了图像与几何的协同生成，这对于提升3D重建和渲染的质量具有重要意义。其利用现成几何预测器并将其转化为修复任务的思路也很有新意，展现了在资源有限情况下的高效解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法需要密集的姿态图像或受限于域内视角的姿态嵌入生成模型。

**Method:** 该方法引入了一个基于扩散的框架，通过扭曲-修复方法进行新视角合成（包括图像和几何）。它利用现成的几何预测器预测参考图像的部分几何，并将新视角合成表述为图像和几何的修复任务。为确保图像和几何的准确对齐，提出了跨模态注意力蒸馏，在训练和推理过程中将图像扩散分支的注意力图注入到平行的几何扩散分支。此外，还引入了基于邻近度的网格条件，以整合深度和法线线索，插值点云并过滤错误预测的几何对生成过程的影响。

**Result:** 该方法在各种未见场景中，实现了图像和几何的高保真外推视角合成；在插值设置下，提供了具有竞争力的重建质量；并生成了几何对齐的彩色点云，用于全面的3D补全。

**Conclusion:** 该方法通过多任务协同效应，实现了几何鲁棒的图像合成以及清晰的几何预测，并在新视角合成和3D补全方面均取得了出色的表现。

> **ai_Abstract:** 该论文提出一个基于扩散的框架，通过新颖的扭曲-修复方法和创新的跨模态注意力蒸馏技术，实现新视角图像和几何的对齐生成。该方法克服了现有技术对密集姿态图像或域内视角限制的依赖，通过将图像扩散分支的注意力图注入到几何分支，确保了图像与几何的精确对齐，实现了协同效应。此外，引入基于邻近度的网格条件进一步提升了生成质量。实验结果表明，该方法在图像和几何外推视角合成、重建质量以及3D补全方面均表现出高保真度和竞争力。

> **摘要翻译:** 我们引入了一个基于扩散的框架，通过扭曲-修复方法执行对齐的新视角图像和几何生成。与需要密集姿态图像或受限于域内视角的姿态嵌入生成模型的现有方法不同，我们的方法利用现成的几何预测器预测参考图像的部分几何，并将新视角合成表述为图像和几何的修复任务。为确保生成图像和几何之间的准确对齐，我们提出了跨模态注意力蒸馏，在训练和推理过程中将图像扩散分支的注意力图注入到平行的几何扩散分支。这种多任务方法实现了协同效应，促进了几何鲁棒的图像合成以及清晰的几何预测。我们进一步引入了基于邻近度的网格条件，以整合深度和法线线索，插值点云并过滤错误预测的几何对生成过程的影响。经验上，我们的方法在各种未见场景中，实现了图像和几何的高保真外推视角合成，在插值设置下提供了具有竞争力的重建质量，并生成了几何对齐的彩色点云，用于全面的3D补全。项目页面可在https://cvlab-kaist.github.io/MoAI获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [575] [How Visual Representations Map to Language Feature Space in Multimodal LLMs](https://arxiv.org/abs/2506.11976)
> *多模态LLM中视觉表示如何映射到语言特征空间*

*Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda* | **Main category: cs.CV**

**Keywords:** 多模态LLM, 视觉-语言对齐, 线性适配器, 稀疏自编码器, 特征空间映射

**Comment:** 

> **TL;DR:** 本研究通过冻结大型语言模型（LLM）和视觉转换器（ViT），并训练一个线性适配器，来探究多模态LLM中视觉表示如何映射到语言特征空间。研究发现视觉表示在中后期层逐步与语言特征对齐，但ViT输出与LLM早期层之间存在错位，对当前适配器架构的优化提出了疑问。

**AI_Comments:** 这项研究通过冻结LLM和ViT并仅训练线性适配器的方法，提供了一个独特且受控的环境来分析视觉-语言对齐过程，避免了微调带来的混淆。利用SAEs作为探测工具是其创新点。研究结果揭示了视觉信息在LLM内部的层级对齐模式，特别是早期层的错位，对未来多模态LLM的架构设计和训练策略具有重要指导意义。它强调了在多模态融合中，简单地将视觉特征“插入”到语言模型中可能不是最优解。

<details>
  <summary>Details</summary>

**Motivation:** 有效的多模态推理依赖于视觉和语言表示的对齐，然而，视觉-语言模型（VLMs）实现这种对齐的机制仍然知之甚少。

**Method:** 引入一个方法论框架，该框架特意保持大型语言模型（LLM）和视觉转换器（ViT）的冻结状态，仅通过在视觉指令微调期间训练一个线性适配器来连接它们。利用LLM的预训练稀疏自编码器（SAEs）作为分析探针，系统分析SAE重建误差、稀疏模式和特征SAE描述。

**Result:** 视觉表示逐步与语言特征表示对齐，并在中后期层收敛。ViT输出和早期LLM层之间存在根本性错位。

**Conclusion:** 当前基于适配器的架构是否能最佳地促进跨模态表示学习，这是一个重要问题。

> **ai_Abstract:** 本文提出一个方法框架，通过训练一个连接冻结LLM和ViT的线性适配器来探究多模态LLM中视觉与语言表示的对齐机制。研究利用LLM的稀疏自编码器作为分析工具，发现视觉特征逐步映射到LLM的语言特征空间，并在中后期层实现对齐，但早期层存在错位。这引发了对现有适配器架构在跨模态学习中效率的质疑。

> **摘要翻译:** 有效的多模态推理依赖于视觉和语言表示的对齐，然而，视觉-语言模型（VLMs）实现这种对齐的机制仍然知之甚少。我们引入了一个方法论框架，该框架特意保持大型语言模型（LLM）和视觉转换器（ViT）的冻结状态，仅通过在视觉指令微调期间训练一个线性适配器来连接它们。这种设计对我们的方法至关重要：通过保持语言模型冻结，我们确保它在不适应视觉数据的情况下保持其原始语言表示。因此，线性适配器必须将视觉特征直接映射到LLM现有的表示空间中，而不是允许语言模型通过微调发展专门的视觉理解。我们独特的实验设计使得可以使用LLM的预训练稀疏自编码器（SAEs）作为分析探针。这些SAEs与未改变的语言模型完美对齐，并作为学习到的语言特征表示的快照。通过对SAE重建误差、稀疏模式和特征SAE描述的系统分析，我们揭示了视觉表示如何逐步与语言特征表示对齐的层级进展，并在中后期层收敛。这表明ViT输出和早期LLM层之间存在根本性错位，对当前基于适配器的架构是否能最佳地促进跨模态表示学习提出了重要问题。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [578] [Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal](https://arxiv.org/abs/2506.11989)
> *基于思维图遍历的放射学VLLM测试时扩展*

*Yue Yao, Zelin Wen, Yan Tong, Xinyu Tian, Xuqing Li, Xiao Ma, Dongliang Xu, Tom Gedeon* | **Main category: cs.CV**

**Keywords:** 放射学VLLM, 测试时扩展, 思维图遍历, 报告生成, 医学影像

**Comment:** arXiv admin note: text overlap with arXiv:2404.11209 by other authors

> **TL;DR:** 本文提出了一种简单但有效的测试时扩展方法，通过思维图遍历（TGT）框架和推理预算强制策略，在不额外训练的情况下，提升放射学VLLM生成报告的推理性能、准确性和一致性。

**AI_Comments:** 本文的创新点在于将测试时扩展和结构化医学先验知识（通过思维图遍历）应用于放射学VLLM，且无需模型再训练。这为在医疗影像等关键领域提升模型推理能力和可解释性（通过可追溯的推理路径）提供了一种实用方法。其中“推理预算强制”策略也是一个有趣的深度推理技术。其简便性和对冻结模型的有效性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了在不额外训练的情况下，提高视觉语言大模型（VLLMs）在放射学报告生成中的推理性能，并实现更深入、更逻辑化的分析。

**Method:** 本文引入了一种轻量级的思维图遍历（Thought Graph Traversal, TGT）框架，该框架通过将结构化医学先验知识整合到提示中，引导模型按照医学上连贯的顺序对器官特异性发现进行推理。为进一步增强推理深度，还应用了一种推理预算强制策略，通过动态扩展模型的生成过程来调整其在测试时的推理深度。这种组合使得冻结的放射学VLLM能够自我纠正。

**Result:** 该方法在标准基准测试中优于基线提示方法，生成了更准确、更一致的胸部X光报告，并通过可追溯的推理路径揭示了数据集偏差。

**Conclusion:** 通过将思维图遍历框架与推理预算强制策略相结合，本文提出了一种简单而有效的方法，显著提升了放射学VLLM在测试时生成报告的准确性和一致性，而无需对底层模型进行任何修改。

> **ai_Abstract:** 本文提出了一种简单而有效的测试时扩展方法，用于改善放射学视觉语言大模型（VLLMs）的报告生成能力。核心是轻量级的思维图遍历（TGT）框架，它通过在提示中嵌入结构化医学先验知识，引导模型以医学逻辑顺序推理器官特异性发现。结合推理预算强制策略动态扩展生成过程，该方法使冻结的VLLM能够自我纠正，从而生成更准确、更一致的胸部X光报告。实验证明，该方法优于现有基线提示方法，并能通过可追溯的推理路径揭示数据集偏差。

> **摘要翻译:** 测试时扩展提供了一种有前景的方法，可以在不额外训练的情况下提高视觉语言大模型（VLLMs）的推理性能。在本文中，我们探索了一种简单但有效的方法，将测试时扩展应用于放射学报告生成。具体来说，我们引入了一个轻量级的思维图遍历（Thought Graph Traversal, TGT）框架，该框架引导模型按照医学上连贯的顺序对器官特异性发现进行推理。这个框架将结构化医学先验知识整合到提示中，从而在不改变底层模型的情况下实现更深入、更逻辑化的分析。为了进一步增强推理深度，我们应用了一种推理预算强制策略，通过动态扩展模型的生成过程来调整模型在测试时的推理深度。这种简单而强大的组合使得冻结的放射学VLLM能够自我纠正并生成更准确、更一致的胸部X光报告。我们的方法在标准基准测试中优于基线提示方法，并通过可追溯的推理路径揭示了数据集偏差。代码和提示已开源，以便在https://github.com/glerium/Thought-Graph-Traversal 上进行复现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [580] [VGR: Visual Grounded Reasoning](https://arxiv.org/abs/2506.11991)
> *VGR：视觉基础推理*

*Jiacong Wang, Zijiang Kang, Haochen Wang, Haiyong Jiang, Jiawen Li, Bohong Wu, Ya Wang, Jiao Ran, Xiao Liang, Chao Feng, Jun Xiao* | **Main category: cs.CV**

**Keywords:** VGR, 视觉基础推理, 多模态大语言模型, 链式思考, 细粒度视觉感知

**Comment:** 9 pages, 4 figures

> **TL;DR:** VGR是一个新型多模态大语言模型（MLLM），通过增强细粒度视觉感知能力，解决了现有链式思考（CoT）推理中语言偏见和视觉理解不足的问题，并在多模态基准测试中取得了显著的性能提升。

**AI_Comments:** VGR的创新之处在于其通过显式地将视觉区域检测和重放机制整合到推理流程中，克服了传统多模态CoT方法中纯语言推理的局限性，有效解决了语言偏见并提升了对图像细节的理解能力。此外，其在减少图像token使用量的同时实现性能提升，显示出其在效率和效果上的双重优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态链式思考（CoT）推理方法主要依赖纯语言空间，导致语言偏见，且大多局限于数学或科学领域，限制了其处理需要全面理解图像细节的复杂视觉推理任务的能力。

**Method:** 本文提出了VGR，一种新型的推理多模态大语言模型（MLLM），具有增强的细粒度视觉感知能力。VGR首先检测可能有助于解决问题的相关区域，然后基于重放的图像区域提供精确的答案。为此，作者构建了一个名为VGR-SFT的大规模SFT数据集，其中包含混合了视觉基础和语言推导的推理数据。VGR的推理流程允许模型选择用于视觉参考的边界框，并引入了一个重放阶段，将相应的区域整合到推理过程中，从而增强多模态理解。

**Result:** 在LLaVA-NeXT-7B基线上进行的实验表明，VGR在需要全面理解图像细节的多模态基准测试上取得了卓越的性能。与基线相比，VGR仅使用30%的图像token数量，但在MMStar上得分提高了4.1，在AI2D上提高了7.1，在ChartQA上提高了12.9。

**Conclusion:** VGR通过引入细粒度视觉感知和区域重放机制，有效克服了现有链式思考方法中语言偏见和视觉理解不足的限制，显著提升了模型在复杂视觉推理任务上的表现。

> **ai_Abstract:** 本文提出了VGR，一种新型多模态大语言模型，旨在解决现有链式思考（CoT）方法中存在的语言偏见和对图像细节理解不足的问题。VGR通过检测图像中的相关区域并基于这些区域进行推理，增强了细粒度视觉感知能力。研究者构建了VGR-SFT数据集以支持视觉基础和语言推导的混合推理。实验结果显示，VGR在多个多模态基准测试上表现优于基线模型，且能显著减少图像token的使用量。

> **摘要翻译:** 在多模态链式思考（CoT）推理领域，现有方法主要依赖纯语言空间进行推理，这固有地受到语言偏见的影响，并且主要局限于数学或科学领域。这种狭窄的焦点限制了它们处理需要全面理解图像细节的复杂视觉推理任务的能力。为了解决这些局限性，本文引入了VGR，一种具有增强细粒度视觉感知能力的新型推理多模态大语言模型（MLLM）。与传统的仅在语言空间中回答问题或推理的MLLM不同，我们的VGR首先检测可能有助于解决问题的相关区域，然后根据重放的图像区域提供精确的答案。为了实现这一点，我们构建了一个名为VGR-SFT的大规模SFT数据集，其中包含混合了视觉基础和语言推导的推理数据。VGR的推理流程允许模型选择用于视觉参考的边界框，并引入了一个重放阶段，将相应的区域整合到推理过程中，从而增强多模态理解。在LLaVA-NeXT-7B基线上进行的实验表明，VGR在需要全面理解图像细节的多模态基准测试上取得了卓越的性能。与基线相比，VGR仅使用30%的图像token数量，但在MMStar上得分提高了4.1，在AI2D上提高了7.1，在ChartQA上提高了12.9。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [582] [Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery](https://arxiv.org/abs/2506.11996)
> *通过整合自动化身体成分分析改善手术风险预测：一项关于结肠切除术的回顾性试验*

*Hanxue Gu, Yaqian Chen, isoo Lee, Diego Schaps, Regina Woody, Roy Colglazier, Maciej A. Mazurowski, Christopher Mantyh* | **Main category: cs.CV**

**Keywords:** 身体成分分析, 结肠切除术, 手术风险预测, CT扫描, 死亡率

**Comment:** 32 pages, 5 figures

> **TL;DR:** 本研究旨在评估术前CT扫描自动提取的身体成分指标是否能预测结肠切除术后的预后。

**AI_Comments:** 该研究的创新点在于尝试将自动化的身体成分分析整合到手术风险预测中，这可能提供比传统临床变量更客观和全面的风险评估。其重要性在于如果成功，可以为结肠切除术患者提供更精准的个性化风险评估，从而优化术前准备和术后管理。摘要中未提及具体结果，因此无法评估其有效性或局限性。

<details>
  <summary>Details</summary>

**Motivation:** 评估术前从CT扫描中自动提取的身体成分指标，无论是单独使用还是与临床变量或现有风险预测因子结合使用，是否能预测结肠切除术后的预后。

**Method:** 本研究采用回顾性试验设计。主要终点是结肠切除术后1年全因死亡率的预测性能，使用1年随访的Cox比例风险模型，并以一致性指数（C-index）和综合Brier分数（IBS）评估性能。次要终点包括术后并发症、计划外再入院、输血和严重感染，通过逻辑回归使用AUC和Brier分数进行评估。使用优势比（OR）描述个体CT衍生身体成分指标与结局之间的关联。从术前CT扫描中提取了300多个特征，包括骨骼肌面积、密度、脂肪面积和组织间指标。2012年后的所有手术均有NSQIP评分。

**Result:** 摘要中未提及。

**Conclusion:** 摘要中未提及。

> **ai_Abstract:** 本研究旨在评估通过CT扫描自动提取的术前身体成分指标在预测结肠切除术后预后方面的效用。主要关注点是1年全因死亡率的预测性能，使用Cox模型评估。次要结局包括并发症、再入院、输血和感染，使用逻辑回归评估。研究从CT中提取了300多个身体成分特征，并结合了NSQIP评分。

> **摘要翻译:** 目的：评估术前从CT扫描中自动提取的身体成分指标，无论是单独使用还是与临床变量或现有风险预测因子结合使用，是否能预测结肠切除术后的预后。主要结局和测量指标：主要结局是结肠切除术后1年全因死亡率的预测性能。采用带有1年随访的Cox比例风险模型，并使用一致性指数（C-index）和综合Brier分数（IBS）评估性能。次要结局包括术后并发症、计划外再入院、输血和严重感染，通过逻辑回归使用AUC和Brier分数进行评估。优势比（OR）描述了个体CT衍生身体成分指标与结局之间的关联。从多个椎体水平的术前CT中提取了300多个特征，包括骨骼肌面积、密度、脂肪面积和组织间指标。2012年后的所有手术均有NSQIP评分。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [584] [Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale](https://arxiv.org/abs/2506.12009)
> *Affogato: 通过大规模自动化数据生成学习开放词汇的行动能力定位*

*Junha Lee, Eunha Park, Chunghyun Park, Dahyun Kang, Minsu Cho* | **Main category: cs.CV**

**Keywords:** 行动能力定位, 开放词汇, 数据集, 视觉-语言模型, 自动化数据生成

**Comment:** 

> **TL;DR:** Affogato引入了一个包含15万实例的大规模数据集，用于开放词汇的行动能力定位，并开发了在此数据集上表现良好且能跨域泛化的模型。

**AI_Comments:** 本论文通过引入大规模、自动化生成的数据集Affogato，在开放词汇的行动能力定位方面取得了显著进展。该数据集有效地解决了细粒度定位和数据稀缺的关键挑战。所开发的视觉-语言模型展示了强大的泛化能力，对于智能代理理解和交互环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 行动能力定位（根据自然语言描述定位物体区域）是使智能代理理解并与其环境交互的关键挑战。然而，由于需要细粒度的部分级定位、多个有效交互区域导致的歧义以及大规模数据集的稀缺，这项任务仍然充满挑战。

**Method:** 本研究引入了Affogato，一个包含15万个实例的大规模基准数据集，其标注了开放词汇的文本描述和相应的3D行动能力热图，涵盖了多样化的物体和交互。在此基准之上，作者开发了简单而有效的视觉-语言模型，这些模型利用了预训练的部件感知视觉骨干网络和文本条件热图解码器。

**Result:** 使用Affogato数据集训练的模型在现有的2D和3D基准测试中取得了有希望的性能，并显著展示了在开放词汇跨域泛化方面的有效性。

**Conclusion:** Affogato数据集及其开发的模型在开放词汇的行动能力定位方面取得了进展，解决了数据稀缺问题并展示了强大的泛化能力。

> **ai_Abstract:** 本论文介绍了Affogato，一个包含15万实例的创新性大规模数据集，该数据集带有开放词汇的文本描述和3D行动能力热图，旨在解决行动能力定位领域的数据稀缺问题。作者还开发了利用部件感知视觉骨干和文本条件热图解码器的视觉-语言模型。这些模型在Affogato数据集上训练后，在现有基准测试中表现出色，并展现出显著的开放词汇跨域泛化能力。

> **摘要翻译:** 行动能力定位——根据自然语言描述的交互来定位物体区域——是使智能代理理解并与其环境交互的关键挑战。然而，由于需要细粒度的部分级定位、多个有效交互区域导致的歧义以及大规模数据集的稀缺，这项任务仍然充满挑战。在这项工作中，我们引入了Affogato，一个包含15万个实例的大规模基准数据集，其标注了开放词汇的文本描述和相应的3D行动能力热图，涵盖了多样化的物体和交互。在此基准之上，我们开发了简单而有效的视觉-语言模型，这些模型利用了预训练的部件感知视觉骨干网络和文本条件热图解码器。我们使用Affogato数据集训练的模型在现有的2D和3D基准测试中取得了有希望的性能，并显著展示了在开放词汇跨域泛化方面的有效性。Affogato数据集已公开发布：https://huggingface.co/datasets/project-affogato/affogato

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [10] [Needling Through the Threads: A Visualization Tool for Navigating Threaded Online Discussions](https://arxiv.org/abs/2506.11276)
> *穿针引线：一个用于导航在线串联讨论的可视化工具*

*Yijun Liu, Frederick Choi, Eshwar Chandrasekharan* | **Main category: cs.HC**

**Keywords:** 在线讨论, 串联讨论, 可视化, 审核, 可视化分析

**Comment:** 

> **TL;DR:** Needle是一个可视化工具，通过总结关键指标和减少认知负荷，帮助版主导航大型复杂的在线串联讨论。

**AI_Comments:** Needle的创新之处在于它将交互式可视化分析与人工参与审核相结合，解决了大规模在线讨论管理中的关键需求。它在减少版主认知负荷和提供决策支持方面的实际应用是一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 由于用户生成内容的速度快、数量大，导航大规模在线讨论非常困难。版主难以跟踪多个同时进行的讨论，并理解对话的整体轨迹，这阻碍了及时有效的审核。尽管Reddit等平台使用串联结构，但深层嵌套的串联仍会使讨论变得模糊。

**Method:** 本文提出了一个名为Needle的交互式系统，旨在支持对串联讨论中复杂话语的更好导航和理解。Needle使用可视化分析来总结关键对话指标（如活动、毒性水平和投票趋势），提供高层见解和详细的讨论线程分解。通过对十名Reddit版主进行用户研究来评估其效果。

**Result:** 用户研究表明，Needle通过减少理解大型讨论的认知负荷，帮助优先处理需要关注的区域，并提供决策支持，从而支持审核工作。

**Conclusion:** 根据研究结果，论文提出了一套设计指南，以指导未来的可视化驱动审核工具和社会技术系统。Needle是首批将交互式可视化分析与人工参与审核相结合的系统之一。

> **ai_Abstract:** 本文介绍了一个名为Needle的交互式可视化工具，旨在帮助版主导航和理解复杂的在线串联讨论。该工具利用可视化分析总结活动、毒性和投票趋势等关键指标，提供高层和详细视图。一项针对Reddit版主的用户研究表明，Needle能够减少认知负荷，有助于优先级排序，并支持决策。论文还为未来的审核工具提供了设计指南，并强调了Needle在结合交互式可视化分析与人工参与审核方面的创新性。

> **摘要翻译:** 由于用户生成内容的速度快、数量大，导航大规模在线讨论非常困难。CSCW的先前工作表明，版主经常难以跟踪多个同时进行的讨论，跟踪不断演变的对话，并保持上下文理解——所有这些都阻碍了及时有效的审核。虽然Reddit等平台使用串联结构来组织话语，但深层嵌套的串联仍然会模糊讨论，并使其难以掌握对话的整体轨迹。在本文中，我们提出了一个名为Needle的交互式系统，以支持对串联讨论中复杂话语的更好导航和理解。Needle使用可视化分析来总结关键对话指标——如活动、毒性水平和投票趋势——随时间的变化，提供高层见解和详细的讨论线程分解。通过对十名Reddit版主进行用户研究，我们发现Needle通过减少理解大型讨论的认知负负荷，帮助优先处理需要关注的区域，并提供决策支持，从而支持审核工作。根据我们的发现，我们提供了一套设计指南，以指导未来的可视化驱动审核工具和社会技术系统。据我们所知，Needle是首批将交互式可视化分析与人工参与审核相结合的系统之一。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [38] [Combining Log Data and Collaborative Dialogue Features to Predict Project Quality in Middle School AI Education](https://arxiv.org/abs/2506.11326)
> *中学人工智能教育中结合日志数据和协作对话特征预测项目质量*

*Conrad Borchers, Xiaoyi Tian, Kristy Elizabeth Boyer, Maya Israel* | **Main category: cs.HC**

**Keywords:** 项目式学习, AI教育, 日志数据, 对话特征, 项目质量预测, 多模态学习分析

**Comment:** Research paper accepted to the 9th Educational Data Mining in
  Computer Science Education (CSEDM) Workshop

> **TL;DR:** 该研究结合日志数据和对话特征来预测中学人工智能项目学习中的项目质量，发现不同数据模态对不同质量指标的预测效果不同，多模态融合的效果也因指标而异。

**AI_Comments:** 这项研究创新性地结合了行为日志和语言对话数据来评估开放式项目学习中的学生表现，并揭示了不同数据模态对不同学习成果预测的差异性，强调了多模态融合的复杂性和价值依赖性，对学习分析领域具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 项目式学习在计算教育中至关重要，但其开放性使得项目进展追踪和成功评估具有挑战性。

**Method:** 研究调查了94名中学学生在结对协作式AI学习中，对话和系统交互日志如何预测项目质量。使用了对话记录的语言特征和系统日志的行为特征来预测三个项目质量结果：生产力（训练短语数量）、内容丰富度（词密度）和词汇变异性（词多样性）。比较了每种模态及其融合的预测准确性。

**Result:** 日志数据能更好地预测生产力，对话数据对内容丰富度更有效。两种模态对词汇变异性的预测能力一般。多模态融合改善了对生产力和词汇变异性的预测，但未改善内容丰富度。

**Conclusion:** 多模态融合的价值取决于具体的学习成果。这项研究通过展示行为和语言数据在评估开放式AI学习环境中学生学习进展时的细微相互作用，为多模态学习分析做出了贡献。

> **ai_Abstract:** 本文研究了中学AI教育中项目式学习的项目质量预测问题。通过分析94名中学生的协作对话和系统日志数据，提取语言和行为特征，预测了聊天机器人训练短语的生产力、内容丰富度和词汇变异性。研究发现，日志数据更适合预测生产力，对话数据对内容丰富度更有效，而多模态融合能提升生产力和词汇变异性的预测，但对内容丰富度无显著改善。这表明多模态融合的价值依赖于具体的学习成果，并为多模态学习分析提供了新的见解。

> **摘要翻译:** 项目式学习在计算教育中扮演着至关重要的角色。然而，其开放性使得追踪项目发展和评估成功变得具有挑战性。我们研究了在94名中学学生结对协作式AI学习中，对话和系统交互日志如何预测项目质量。我们使用对话记录中的语言特征和系统日志中的行为特征来预测聊天机器人训练短语的三个项目质量结果：生产力（训练短语的数量）、内容丰富度（词密度）和词汇变异性（词多样性）。我们比较了每种模态和模态融合的预测准确性。结果表明，日志数据能更好地预测生产力，而对话数据对内容丰富度更有效。两种模态对词汇变异性的预测能力一般。多模态融合改善了对训练短语生产力和词汇变异性的预测，但未改善内容丰富度。这些发现表明，多模态融合的价值取决于具体的学习成果。这项研究通过展示行为和语言数据在评估开放式AI学习环境中学生学习进展时的细微相互作用，为多模态学习分析做出了贡献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [66] [Meeting Patients Where They're At: Toward the Expansion of Chaplaincy Care into Online Spiritual Care Communities](https://arxiv.org/abs/2506.11366)
> *在患者所在地提供服务：将牧师关怀扩展到在线精神关怀社区的探索*

*Alemitu Bezabih, Shadi Nourriz, Anne-Marie Snider, Rosalie Rauenzahn, C. Estelle Smith* | **Main category: cs.HC**

**Keywords:** 牧师关怀, 在线精神关怀社区, 精神关怀, 可及性, 扎根理论

**Comment:** 

> **TL;DR:** 研究了如何将牧师精神关怀扩展到在线社区，发现其具有可及性和可扩展性，但也存在局限性，并提出了“关怀循环”模型和设计建议。

**AI_Comments:** 这项研究创新性地将牧师关怀这一传统领域与在线社区相结合，填补了CSCW/HCI研究在该领域的空白。其提出的“关怀循环”模型为未来在线精神关怀服务的设计和实施提供了有价值的框架。研究通过混合方法深入探讨了专业人员的视角，既肯定了在线平台的潜力，也务实地指出了技术局限性和实际挑战，为后续研究和实践提供了重要的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管美国对精神关怀的需求日益增长，但其服务往往不足、难以获取或被误解，且CSCW/HCI研究中几乎没有涉及专业牧师和精神关怀提供者。

**Method:** 采用探索性混合方法研究，对22位牧师进行访谈和用户测试，中心围绕Reddit支持社区，以了解他们对技术的看法以及对在线精神关怀社区（OSCCs）中牧师角色的构想。采用扎根理论分析方法，并使用现有的牧师技术分类法。

**Result:** OSCCs的益处包括：在患者所在地提供服务；可及性和可扩展性；促进患者发起关怀。牧师认为他们在OSCCs中可以帮助塑造同伴互动、进行调节、提供小组同步聊天以及转介外部资源。同时也提出了可行性问题、风险和未来设计与研究的需求。发现一些精神关怀策略适用于在线空间，但技术在完全中介精神关怀方面存在局限性，需要开发新的在线牧师干预措施。

**Conclusion:** 提出了“关怀循环”模型，连接机构化正式关怀和平台社区关怀，以扩大精神关怀的可及性和利用率。还贡献了指导未来在线精神关怀工作的设计启示。

> **ai_Abstract:** 这项跨学科研究探讨了如何将牧师精神关怀扩展到匿名、异步和基于文本的在线社区。通过对22位牧师的访谈和用户测试，研究发现在线精神关怀社区（OSCCs）具有可及性和可扩展性，并能促进患者发起关怀。牧师认为他们可以在OSCCs中发挥塑造互动、调节和转介资源的作用，但也指出了技术局限性和可行性问题。研究提出了一个“关怀循环”模型，旨在连接机构化和平台社区关怀，以扩大精神关怀的可及性，并提供了未来在线精神关怀的设计启示。

> **摘要翻译:** 尽管美国对精神关怀的需求日益增长，但其服务往往不足、难以获取或被误解，而CSCW/HCI研究中几乎没有涉及专业牧师和精神关怀提供者。这项跨学科研究旨在建立对精神关怀如何（或可能不）扩展到在线空间的基础理解——特别关注匿名、异步和基于文本的在线社区。我们对22位牧师进行了一项探索性混合方法研究，包括围绕Reddit支持社区的访谈和用户测试，以了解参与者对技术的看法以及他们对未来在线精神关怀社区（OSCCs）中牧师角色的构想。我们的扎根理论分析方法强调了OSCCs的益处，包括：在患者所在地提供服务；可及性和可扩展性；以及促进患者发起关怀。牧师们强调，他们在OSCCs中的存在有助于塑造同伴互动、进行调节、进行小组同步聊天以及转介外部资源，同时也提出了重要的可行性问题、风险以及未来设计和研究的需求。我们使用现有的牧师技术分类法来表明某些精神关怀策略可能适用于在线空间，但我们也揭示了技术在完全中介精神关怀方面的局限性，以及开发新的在线牧师干预措施的必要性。基于这些发现，我们提出了一个“关怀循环”模型，连接机构化正式关怀和基于平台的社区关怀，以扩大精神关怀的可及性并提高其认知度和利用率。我们还贡献了指导未来在线精神关怀工作的设计启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [94] [Co-Designing a Chatbot for Culturally Competent Clinical Communication: Experience and Reflections](https://arxiv.org/abs/2506.11393)
> *共同设计用于文化能力临床沟通的聊天机器人：经验与反思*

*Sandro Radovanović, Shuangyu Li* | **Main category: cs.HC**

**Keywords:** 聊天机器人, 文化能力, 临床沟通, 医疗培训, AI

**Comment:** 19 pages, 7 figures

> **TL;DR:** 开发并试用了一个AI聊天机器人，用于培养医学生的文化能力沟通技能，结果显示其有潜力但也有局限性。

**AI_Comments:** 创新性：将AI聊天机器人应用于文化能力临床沟通培训是一个新颖且有前景的方向，解决了传统培训的扩展性问题。重要性：强调了文化能力在医疗领域的重要性，并提出了一个潜在的解决方案来提升医疗专业人员的此项技能。局限性：文章坦诚地指出了当前AI聊天机器人的局限性，如非语言线索的缺失和虚拟患者行为的过度顺从，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统临床沟通培训（模拟病人）资源密集且难以扩展，尤其是在资源不足的环境中。需要探索AI工具来支持医学生的文化能力沟通培训。

**Method:** 开发了一个AI驱动的聊天机器人，旨在模拟真实的病人对话，并根据ACT文化能力模型提供结构化反馈。于2024年在英国一所医学院对一小群三年级医学生进行了试点，但未采用正式的实验设计。

**Result:** 聊天机器人为学生提供了有益的机会，以反思他们的沟通，特别是在同理心和人际理解方面。在处理系统性问题和历史背景方面更具挑战性。早期版本揭示了一些有趣的模式，但也存在局限性，如缺乏非语言线索和虚拟病人过于顺从的倾向。总体而言，它揭示了AI工具在沟通培训中的潜力和当前局限性。

**Conclusion:** AI工具在沟通培训中具有潜力，但也存在明显的局限性，需要进一步研究以理解其影响并改进学习体验。

> **ai_Abstract:** 本文探讨了共同设计一个AI驱动的聊天机器人，用于培养医学生的文化能力临床沟通技能。该聊天机器人旨在模拟病人对话并提供反馈。在英国一所医学院对三年级医学生进行的试点表明，该工具在促进学生反思同理心和人际理解方面具有潜力，但同时存在缺乏非语言线索和处理复杂系统性问题等局限性。研究强调了AI在沟通培训中的前景与挑战。

> **摘要翻译:** 临床沟通技能对于培养医疗专业人员提供跨文化公平护理至关重要。然而，传统的模拟患者培训资源密集且难以扩展，尤其是在资源不足的环境中。在这个项目中，我们探索了使用AI驱动的聊天机器人来支持医学生的文化能力沟通培训。该聊天机器人旨在模拟真实的患者对话，并根据ACT文化能力模型提供结构化反馈。我们于2024年在英国一所英国医学院的一小群三年级医学生中试用了该聊天机器人。尽管我们没有遵循正式的实验设计，但我们的经验表明，该聊天机器人为学生提供了有益的机会，以反思他们的沟通，特别是在同理心和人际理解方面。更具挑战性的领域包括解决系统性问题和历史背景。尽管这个早期版本的聊天机器人帮助揭示了一些有趣的模式，但局限性也很明显，例如缺乏非语言线索和虚拟患者过于顺从的倾向。总的来说，这项反思强调了AI工具在沟通培训中的潜力和当前局限性。需要更多的工作来更好地理解它们的影响并改善学习体验。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [121] [Do Not Immerse and Drive? Prolonged Effects of Cybersickness on Physiological Stress Markers And Cognitive Performance](https://arxiv.org/abs/2506.11536)
> *不要沉浸并驾驶？晕动症对生理应激标志物和认知表现的长期影响*

*Daniel Zielasko, Ben Rehling, Bernadette von Dawans, Gregor Domes* | **Main category: cs.HC**

**Keywords:** 晕动症, 虚拟现实, 生理应激, 认知表现, 后遗症

**Comment:** 

> **TL;DR:** 本研究发现，VR诱发的晕动症对生理应激和认知表现有长期影响，部分症状在暴露后90分钟仍可能达到高峰。

**AI_Comments:** 本研究的重要性在于它强调了晕动症常常被忽视的“长期”影响，这种影响超出了即时VR暴露。发现症状延迟进展和生理应激标志物（如皮质醇）持续升高是特别创新的，挑战了症状迅速消退的假设。这对于用户在VR使用后可能执行关键任务的专业VR/XR应用的安全具有重要意义。这也表明当前研究中的“清除”期可能不足。

<details>
  <summary>Details</summary>

**Motivation:** 长时间暴露于虚拟现实环境会诱发晕动症，这可能导致生理应激反应和认知表现受损。本研究旨在调查VR诱发晕动症的后遗症，重点关注生理应激标志物和工作记忆表现。

**Method:** 研究使用旋转木马模拟来引发晕动症，并在暴露后90分钟内评估了主观不适感（SSQ、FMS）、生理应激（唾液皮质醇、α-淀粉酶、皮肤电活动、心率）和认知表现（n-Back任务）。

**Result:** VR暴露后，主观和生理应激指标均显著增加，并伴随工作记忆表现下降。相当一部分参与者出现了延迟的症状进展，有些人在刺激后长达90分钟才报告症状达到高峰。唾液皮质醇水平在整个观察期内保持升高，表明应激恢复时间延长。

**Conclusion:** 研究结果强调了XR研究中需要更长的清除期，并对涉及暴露后任务表现的专业应用提出了安全担忧。

> **ai_Abstract:** 本研究调查了VR诱发晕动症对生理应激和认知表现的长期后遗症。研究人员通过旋转木马模拟发现，VR暴露导致主观和生理应激（如皮质醇升高）显著增加，并损害了工作记忆，部分症状在暴露后长达90分钟仍达到高峰。研究结果强调了XR研究中需要更长的恢复期，并对专业VR应用提出了安全担忧。

> **摘要翻译:** 长时间暴露于虚拟现实环境会诱发运动病，通常称为晕动症，这可能导致生理应激反应和认知表现受损。本研究调查了VR诱导的晕动症的后遗症，重点关注生理应激标志物和工作记忆表现。我们使用旋转木马模拟来引发晕动症，在暴露后90分钟内评估了主观不适感（SSQ、FMS）、生理应激（唾液皮质醇、α-淀粉酶、皮肤电活动、心率）和认知表现（n-Back任务）。我们的研究结果表明，VR暴露后主观和生理应激指标均显著增加，并伴随工作记忆表现下降。值得注意的是，相当一部分参与者出现了延迟的症状进展，有些人在刺激后长达90分钟才报告症状达到高峰。唾液皮质醇水平在整个观察期内保持升高，表明应激恢复时间延长。这些结果强调了XR研究中需要更长的清除期，并对涉及暴露后任务表现的专业应用提出了安全担忧。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [146] ["If we misunderstand the client, we misspend 100 hours": Exploring conversational AI and response types for information elicitation](https://arxiv.org/abs/2506.11610)
> *“如果我们误解了客户，就会浪费100小时”: 探索会话式AI和响应类型在信息获取中的应用*

*Daniel Hove Paludan, Julie Fredsgård, Kasper Patrick Bährentz, Ilhan Aslan* | **Main category: cs.HC**

**Keywords:** 会话式AI, 需求获取, 客户-设计师协作, 用户体验, 选择式响应

**Comment:** 27 pages, 8 figures

> **TL;DR:** 本研究探讨了会话式AI和选择式响应如何影响客户-设计师协作中的需求获取，发现它们会降低用户体验的可靠性但提高客户输入的清晰度，并提供了设计启示。

**AI_Comments:** 这项研究通过多阶段的实证方法，深入探讨了会话式AI和选择式响应在设计需求获取中的作用。其创新之处在于量化了这些技术对用户体验和信息清晰度的具体影响，特别是指出了一个权衡：虽然可能降低用户体验的某些方面，但却能提升关键的输入质量。这为未来设计更有效、更智能的需求获取工具提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 客户与设计师的对齐对于设计项目的成功至关重要，然而很少有研究探讨数字技术如何影响这种对齐。本研究旨在填补这一空白，探索数字系统如何支持专业设计实践中的需求获取。

**Method:** 本研究分三阶段进行：第一阶段通过半结构化访谈调查10家设计公司的当前实践，为系统设计提供信息。第二阶段使用2x2因子设计，对50名模拟客户评估系统，量化会话式AI和响应类型对用户体验和感知准备度的影响。第三阶段向7家原始公司展示系统，收集对其价值、局限性以及潜在实践整合的反馈。

**Result:** 研究发现会话式AI和选择式响应都会导致用户体验问卷上的可靠性得分降低，但会使客户输入具有更高的清晰度。

**Conclusion:** 本文为将会话式AI和选择式响应集成到需求获取工具中提供了设计启示，以支持早期客户-设计师协作中的相互理解。

> **ai_Abstract:** 本研究探讨了会话式AI和选择式响应在数字需求获取工具中如何影响早期客户与设计师的协作。通过对10家设计公司的访谈、对50名模拟客户的系统评估以及向7家公司展示系统，研究发现虽然这两种技术可能降低用户体验的可靠性，但显著提高了客户输入的清晰度。论文提出了将这些技术集成到需求获取工具中的设计启示，以促进客户与设计师之间的相互理解。

> **摘要翻译:** 客户与设计师的对齐对于设计项目的成功至关重要，然而很少有研究探讨数字技术如何影响这种对齐。为了弥补这一空白，本文提出了一个三阶段研究，调查数字系统如何支持专业设计实践中的需求获取。具体来说，它研究了将会话代理和基于选择的响应格式集成到数字获取工具中如何影响早期客户与设计师的协作。研究的第一阶段通过半结构化访谈调查了10家设计公司的当前实践，为系统设计提供了信息。第二阶段使用2x2因子设计对50名模拟客户评估了该系统，量化了会话式AI和响应类型对用户体验和感知准备度的影响。在第三阶段，该系统被展示给原始10家公司中的7家，以收集对其价值、局限性以及潜在实践整合的反馈。研究结果表明，会话式AI和基于选择的响应都会导致用户体验问卷上的可靠性得分降低，但会使客户输入具有更高的清晰度。我们为将会话式AI和基于选择的响应集成到获取工具中提供了设计启示，以支持早期客户与设计师协作中的相互理解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [168] [Perspectives on Explanation Formats From Two Stakeholder Groups in Germany: Software Providers and Dairy Farmers](https://arxiv.org/abs/2506.11665)
> *德国两个利益相关者群体（软件供应商和奶农）对解释格式的看法*

*Mengisti Berihu Girmay, Felix Möhrle* | **Main category: cs.HC**

**Keywords:** 解释格式, 数字决策支持系统, 奶农, 软件供应商, 用户需求分析

**Comment:** Accepted at IJCAI 2024, Explainable AI Workshop

> **TL;DR:** 本研究调查了德国奶业中软件供应商和奶农对数字决策支持系统解释格式的看法，发现两组之间存在显著差异，软件供应商对农民偏好的假设不准确，强调了用户需求分析的重要性。

**AI_Comments:** 本文通过比较软件供应商和农民对解释格式的看法，揭示了数字农业技术推广中存在的一个关键问题：开发者对用户需求的误判。其创新点在于从双向视角探讨了技术采纳的障碍。尽管样本量较小，但其研究结果具有重要的实践意义，强调了在软件开发过程中充分进行用户需求分析的必要性，这对于提高数字系统在农业领域的接受度和有效性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查德国奶业中软件供应商和奶农对数字决策支持系统解释格式的看法，并假设两组之间可能存在差异，以期找到农民不愿采用数字系统的原因。

**Method:** 研究设计了四种解释格式（文本、基于规则、牛群比较和时间序列），并分别对14位德国奶农和13位德国奶业软件供应商进行了问卷调查，询问他们对这些格式的接受度，最后比较了两组的反馈。

**Result:** 两组的反馈比较支持了存在差异的假设，结果显示软件供应商倾向于对农民的偏好做出不一定准确的假设。

**Conclusion:** 尽管样本量小，但本研究强调了进行彻底的用户需求分析（农民需求）对于改进软件适应性和用户接受度的潜在益处。

> **ai_Abstract:** 本研究考察了德国奶业中软件供应商和奶农对数字决策支持系统解释格式的看法。通过设计四种解释格式并分别对两组进行调查，研究发现软件供应商对农民偏好的假设与农民的实际需求存在差异，这可能导致数字系统采用率低。研究结果强调了进行彻底的用户需求分析对于提升软件适应性和用户接受度的重要性。

> **摘要翻译:** 本论文探讨了德国乳制品行业的软件供应商关于奶农对数字决策支持系统解释需求方面的观点。这项研究基于使用假想的牛群管理系统对奶牛乳腺炎检测进行。我们设计了四种乳腺炎评估的示例性解释格式，具有不同的呈现类型（文本、基于规则、牛群比较和时间序列）。在我们之前的研究中，德国的14位奶农根据可理解性和他们对提供每种格式的系统的信任度对这些格式进行了评分。在本研究中，我们对活跃在德国乳制品行业的13家软件供应商重复了这项调查。我们询问他们认为这些格式将如何被农民接受。我们假设两组的观点之间可能存在值得调查的差异，部分是为了找出不愿采用数字系统的原因。对两组反馈的比较支持了这一假设，并需要进一步调查。结果表明，软件供应商倾向于对农民的偏好做出不一定准确的假设。我们的研究，尽管由于样本量小而不具有代表性，但强调了进行彻底的用户需求分析（农民需求）以改善软件适应性和用户接受度的潜在益处。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [186] [Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration](https://arxiv.org/abs/2506.11718)
> *交互、流程、基础设施：一种人机协作的统一架构*

*Yun Wang, Yan Lu* | **Main category: cs.HC**

**Keywords:** 人机协作, 统一架构, 流程管理, AI系统, 分层框架

**Comment:** 

> **TL;DR:** 提出了一种分层框架，将交互、流程和基础设施集成到人机协作系统中，以解决当前AI工具碎片化的问题，并使协作更加持续和适应。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的分层架构，将人机协作的核心从单纯的任务辅助提升到对“流程”的显式管理和适应性。这为构建更智能、更具协调性的人机系统提供了新的范式，克服了当前AI工具在持续协作方面的局限性。其重要性在于为未来的人机协作系统设计提供了理论基础和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI工具（如聊天机器人和副驾驶）虽然功能日益强大，但仍是碎片化的，仅支持孤立的任务，缺乏持续、适应性协作的架构支撑。

**Method:** 提出了一种分层框架，用于整合交互、流程和基础设施这三个相互依赖的维度。该架构将流程提升为主要焦点，使其变得明确、可检查和可适应。

**Result:** 该模型阐明了当前工具的局限性，统一了新兴的系统设计方法，并为研究人员和AI系统构建者揭示了新的机会。

**Conclusion:** 通过将智能行为建立在结构化协作之上，本文将人机协作重新构想为一种连贯且一致的真实世界工作系统，而非任务特定的增强。

> **ai_Abstract:** 本文提出了一种名为“交互、流程、基础设施”的分层框架，旨在解决当前AI工具在人机协作中存在的碎片化问题。该统一架构通过将流程提升为核心关注点，使其明确、可检查和适应性强，从而使人类和AI代理能够更好地协调并适应不断变化的目标。这一模型不仅揭示了现有工具的局限性，还统一了新兴系统设计方法，并为未来的研究和开发提供了新方向，将人机协作从任务特定增强转变为连贯的真实世界工作系统。

> **摘要翻译:** 随着AI工具在各个领域的普及，从聊天机器人和副驾驶到新兴代理，它们越来越多地支持专业的知识工作。然而，尽管这些系统的能力不断增长，它们仍然是碎片化的：它们协助孤立的任务，但缺乏持续、适应性协作的架构支架。我们提出了一种分层框架，用于人机系统，该框架整合了交互、流程和基础设施这三个相互依赖的维度。至关重要的是，我们的架构通过使流程明确、可检查和可适应，将其提升为主要焦点，使人类和代理能够随着目标演变而保持一致并进行长时间的协调。该模型阐明了当前工具的局限性，统一了新兴的系统设计方法，并为研究人员和AI系统构建者揭示了新的机会。通过将智能行为建立在结构化协作之上，我们将人机协作重新构想为一种连贯且一致的真实世界工作系统，而非任务特定的增强。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [206] [GeoPandas-AI: A Smart Class Bringing LLM as Stateful AI Code Assistant](https://arxiv.org/abs/2506.11781)
> *GeoPandas-AI：一个将大型语言模型作为有状态AI代码助手的智能类*

*Gaspard Merten, Gilles Dejaegere, Mahmoud Sakr* | **Main category: cs.HC**

**Keywords:** GeoPandas-AI, LLM, 地理空间数据分析, 代码助手, GeoDataFrame

**Comment:** Submitted to ACM SIGSPATIAL 2025

> **TL;DR:** GeoPandas-AI通过将LLM集成到GeoPandas工作流程中，将其GeoDataFrame类转变为一个智能、有状态的类，用于地理空间数据分析和代码开发，解决了使用GeoPandas需要专业知识的问题。

**AI_Comments:** GeoPandas-AI的创新之处在于其将LLMs与特定领域库（GeoPandas）深度结合，创造了一个有状态的智能代码助手。这不仅降低了地理空间数据分析的门槛，也为其他专业领域软件的AI辅助开发提供了新的思路。其开源实现也利于社区的进一步发展和应用。

<details>
  <summary>Details</summary>

**Motivation:** 地理空间数据分析在解决城市规划和气候建模等复杂社会挑战中至关重要。然而，使用GeoPandas等工具需要复杂的领域特定语法和工作流程的专业知识。GeoPandas-AI旨在弥补这一空白。

**Method:** GeoPandas-AI通过将LLMs直接集成到GeoPandas工作流程中，将GeoDataFrame类转换为一个智能的、有状态的类。它结合了对话式界面和LLMs的有状态利用，用于代码生成和数据分析。该论文形式化了这种智能类的设计，并提供了GeoPandas-AI的开源实现。

**Result:** GeoPandas-AI引入了代码副驾驶的新范式，并将其应用于地理空间开发，使得地理空间数据分析和代码开发更加便捷。

**Conclusion:** GeoPandas-AI通过集成LLMs，将GeoPandas的GeoDataFrame类转变为一个智能、有状态的类，极大地简化了地理空间数据分析和代码开发过程，为代码副驾驶提供了新的范式。

> **ai_Abstract:** GeoPandas-AI是一个创新的项目，旨在通过将大型语言模型（LLMs）集成到GeoPandas库中，简化地理空间数据分析和代码开发。它将GeoDataFrame类转变为一个智能、有状态的实体，允许用户通过对话式界面进行数据分析和代码生成，从而降低了使用GeoPandas所需的专业知识门槛，并为代码副驾驶工具开辟了新的可能性。

> **摘要翻译:** 地理空间数据分析在解决城市规划和气候建模等复杂的社会挑战中发挥着关键作用。然而，使用GeoPandas（一个用于地理空间数据操作的著名Python库）等工具需要复杂的领域特定语法和工作流程的专业知识。GeoPandas-AI通过将大型语言模型（LLMs）直接集成到GeoPandas工作流程中来解决这一差距，将GeoDataFrame类转换为一个智能的、有状态的类，用于数据分析和地理空间代码开发。本文形式化了这种智能类的设计，并提供了GeoPandas-AI在PyPI包管理器中的开源实现。通过其对话式界面和LLMs在代码生成和数据分析方面的有状态利用的创新组合，GeoPandas-AI为代码副驾驶引入了一种新范式，并将其实例化用于地理空间开发。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [223] [Digital Labor: Challenges, Ethical Insights, and Implications](https://arxiv.org/abs/2506.11788)
> *数字劳动：挑战、伦理洞察与影响*

*ATM Mizanur Rahman, Sharifa Sultana* | **Main category: cs.HC**

**Keywords:** 数字劳动, 众包平台, 零工经济, 伦理挑战, AI系统

**Comment:** 

> **TL;DR:** 论文通过文献综述分析了数字零工劳动者面临的低薪、不公等问题，并提出了改进建议。

**AI_Comments:** 这篇论文通过其广泛的文献综述，系统地揭示了数字劳动领域的核心伦理和实践挑战，尤其关注数字零工劳动者的困境。其创新之处在于提供了一个全面的现状图景，并为多方利益相关者提供了实用的干预方向。对于理解AI发展中“人”的因素及其社会影响具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数字众包平台上的数字劳动者在训练和改进AI系统方面发挥关键作用，但他们常常面临低薪、不公平的条件以及贡献未被认可的问题。本研究旨在梳理现有文献中的这些问题。

**Method:** 作者选择了2015年至2024年间发表的300多篇数字劳动研究论文，并将其范围缩小到143篇数字零工劳动相关论文进行详细分析，以概述该领域的关键挑战、关注点和趋势。

**Result:** 分析揭示了数字劳动中零工劳动者的代表性和话语权模式是如何被构建和管理的。

**Conclusion:** 本研究为研究人员、平台设计者和政策制定者提供了新的见解，帮助他们更好地理解数字劳动者的经验，并指出了亟需干预和未来调查的关键领域。它有助于对当代和未来AI生态系统中的数字劳动形成更连贯和批判性的理解。

> **ai_Abstract:** 这篇论文通过对2015-2024年间143篇数字零工劳动研究论文的系统性文献回顾，深入分析了数字众包平台劳动者面临的低薪、不公和缺乏认可等核心挑战。研究揭示了数字劳动中零工劳动者代表性和话语权的结构化模式，并为研究人员、平台设计者和政策制定者提供了新的见解，旨在促进对数字劳动者经验的理解，并指出未来干预和研究的重点领域，以期对AI生态系统中的数字劳动形成更批判性的认识。

> **摘要翻译:** 数字众包平台（例如Amazon Mechanical Turk、Appen、Clickworker、Prolific）上的数字劳动者在训练和改进AI系统方面发挥着关键作用，但他们常常面临低薪、不公平的条件以及贡献未被认可的问题。为了梳理计算机科学、人工智能及相关学术领域现有文献中的这些问题，我们选取了2015年至2024年间发表的300多篇数字劳动研究论文，并将其范围缩小到143篇数字零工劳动相关论文进行详细分析。这项分析提供了该领域关键挑战、关注点和趋势的广泛概述。我们的综合研究揭示了数字劳动中零工劳动者的代表性和话语权模式是如何持续构建和管理的。我们为研究人员、平台设计者和政策制定者提供了新的见解，帮助他们更好地理解数字劳动者的经验，并指出了亟需干预和未来调查的关键领域。通过梳理过去十年该领域的发展发现及其可能的影响，本文有助于对当代和未来AI生态系统中的数字劳动形成更连贯和批判性的理解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [238] [Conversational AI as a Catalyst for Informal Learning: An Empirical Large-Scale Study on LLM Use in Everyday Learning](https://arxiv.org/abs/2506.11789)
> *对话式AI作为非正式学习的催化剂：一项关于LLM在日常学习中使用的实证性大规模研究*

*Nađa Terzimehić, Babette Bühler, Enkelejda Kasneci* | **Main category: cs.HC**

**Keywords:** 大型语言模型, 非正式学习, 日常学习, 用户采纳, 实证研究

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）已被广泛用于日常非正式学习，尤其是年轻成年人，尽管存在信任悖论。本研究调查了776名参与者，以了解其使用模式和影响。

**AI_Comments:** 这项研究通过大规模调查提供了关于LLM在非正式学习中广泛应用的实证证据，对用户群体和新兴学习模式提供了宝贵见解。关于信任悖论的发现尤其引人关注，其大规模的调查方法增强了研究结果的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的出现引发了我们学习方式的深刻反思，并改变了日常非正式学习。本研究旨在探究谁在使用LLMs进行自主学习，谁仍然犹豫，他们采用或规避的原因是什么，以及在这种新型技术环境下出现了哪些学习模式。

**Method:** 本研究通过对776名参与者进行大规模调查，进行了深入分析。

**Result:** 调查显示，88%的受访者已将LLMs融入其日常学习中，用于各种学习任务。年轻成年人是LLMs采用的先行者，他们主要利用LLMs不受时间和空间限制地提升学习体验。根据使用LLMs执行的任务和访问设备的不同，在不同学习情境中出现了四种类型的学习者。有趣的是，受访者在对LLMs准确性和隐私保护措施的信任方面表现出矛盾的行为。

**Conclusion:** 研究结果强调了在学习中包含不同媒体类型、实现协作学习、提供资源以及满足不同类型学习者需求和通过设计进行学习的重要性。

> **ai_Abstract:** 这项大规模的实证研究调查了大型语言模型（LLMs）在日常非正式学习中的采纳和影响，共涉及776名参与者。研究发现，88%的受访者，特别是年轻成年人，已将LLMs整合到他们的日常学习中，用于各种任务，主要目的是提高学习的灵活性。研究识别出四种学习者类型，并注意到用户在LLM准确性和隐私方面的信任存在矛盾行为。研究启示强调了多样化媒体、协作学习、资源提供以及定制化学习设计的重要性。

> **摘要翻译:** 大型语言模型不仅吸引了公众的想象力，也引发了我们学习方式的深刻反思。在ChatGPT突破性发布后的第三年，随着不同用户群体探索这些新颖工具，日常非正式学习已经发生了转变。谁正在利用LLM进行自主学习，谁又仍然犹豫不决？他们采用或规避的原因是什么？在这种新颖的技术环境中出现了哪些学习模式？我们对776名参与者进行了大规模调查，并进行了深入分析，结果显示我们88%的受访者已经将LLM融入到他们的日常学习中，用于各种（学习）任务。年轻成年人是采用LLM的先行者，他们主要是为了独立于时间和空间地提升学习体验。根据他们使用LLM执行的任务和访问设备的类型，在不同的学习情境中出现了四种类型的学习者。有趣的是，我们的受访者在对LLM的准确性和隐私保护措施的信任方面表现出矛盾的行为。我们的启示强调了在学习中包含不同媒体类型、实现协作学习、提供资源以及满足不同类型学习者需求和通过设计进行学习的重要性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [254] [Enter: Graduated Realism: A Pedagogical Framework for AI-Powered Avatars in Virtual Reality Teacher Training](https://arxiv.org/abs/2506.11890)
> *进入：分级真实感：虚拟现实教师培训中AI驱动头像的教学框架*

*Judson Leroy Dean Haynes IV* | **Main category: cs.HC**

**Keywords:** 虚拟现实, 教师培训, AI头像, 分级真实感, 认知负荷

**Comment:** 

> **TL;DR:** 本文提出“分级真实感”框架，建议虚拟现实教师培训中AI头像的真实感应随学习者技能发展逐步提高，而非一味追求超真实感，以优化教学效果并降低认知负荷，并提出了一个可计算实现的架构。

**AI_Comments:** 本文创新性地提出了“分级真实感”框架，解决了VR教师培训中AI头像真实感与教学效果之间的矛盾。其亮点在于将学习理论（如认知负荷理论）与技术实现（如“Crazy Slots”架构）相结合，为未来VR教育工具的设计提供了实用的指导原则。这对于平衡技术进步与实际教学需求具有重要意义，尤其是在避免新手学习者认知超载方面。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实模拟器在教师培训中潜力巨大，但AI驱动的学生头像在教学中如何确定最佳真实感水平是一个关键挑战。现有技术追求照片级真实感与教学支架式学习需求之间存在显著差距，超真实感可能增加新手认知负荷。

**Method:** 通过系统性文献综述，回顾了VR教师培训中头像真实感的发展，从人类控制头像到生成式AI原型。应用认知负荷理论等学习理论，论证超真实感并非总是最佳。提出了“分级真实感”教学框架，并概述了一种名为“Crazy Slots”的单调用架构来实现计算可行性。

**Result:** 提出了“分级真实感”框架，主张从低保真头像开始，随技能发展逐步增加行为复杂性。为实现计算可行性，设计了“Crazy Slots”单调用架构，利用概率引擎和检索增强生成数据库，实现低延迟、低成本的实时响应。强调了教学驱动的真实感方法对于可扩展、有效教师教育工具的重要性。

**Conclusion:** 设计下一代AI模拟器时，以教学为基础的真实感方法至关重要，能创建可扩展且有效的教师教育工具。超真实感并非总是最优，应采用分级方法以优化学习效果。

> **ai_Abstract:** 本文针对虚拟现实教师培训中AI头像的真实感问题，通过文献综述和理论分析，提出了“分级真实感”教学框架。该框架主张根据学习者技能发展，逐步提高AI头像的真实感和行为复杂性，以避免超真实感带来的认知负荷。为实现该框架，文章还提出了一种名为“Crazy Slots”的单调用计算架构。研究强调，教学需求应主导AI模拟器中真实感的设计，而非单纯追求技术上的高保真，以构建更有效、可扩展的教师教育工具。

> **摘要翻译:** 虚拟现实模拟器为教师培训提供了强大的工具，但AI驱动的学生头像的整合面临一个关键挑战：确定头像的最佳真实感水平以实现有效的教学。本文通过文献综述审视了VR教师培训中头像真实感的发展，综合了其理论含义，并提出了一个新的教学框架来指导未来的设计。通过系统性回顾，本文追溯了从人类控制头像到生成式AI原型的演变。应用认知负荷理论等学习理论，我们认为超真实感并非总是最佳选择，因为高保真头像可能对新手施加过多的额外认知负荷，这一观点得到了近期实证研究的支持。技术追求照片级真实感与教学中支架式学习的需求之间存在显著差距。为了弥补这一差距，我们提出了“分级真实感”（Graduated Realism），这是一个倡导让受训者从较低保真度的头像开始，并随着技能的发展逐步增加行为复杂性的框架。为了使其在计算上可行，我们概述了一种新颖的单调用架构“Crazy Slots”，它使用概率引擎和检索增强生成数据库来生成真实、实时的响应，而无需多步推理模型的延迟和成本。本文为设计下一代AI模拟器提供了基于证据的原则，认为以教学为基础的真实感方法对于创建可扩展且有效的教师教育工具至关重要。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [5] [Gradients of unitary optical neural networks using parameter-shift rule](https://arxiv.org/abs/2506.11565)
> *使用参数偏移规则计算酉光学神经网络的梯度*

*Jinzhe Jiang, Yaqian Zhao, Xin Zhang, Chen Li, Yunlong Yu, Hailing Liu* | **Main category: cs.ET**

**Keywords:** 参数偏移规则, 酉光学神经网络, 梯度计算, 光学计算, 硬件训练

**Comment:** 8 pages, 3 figures

> **TL;DR:** 本文探讨了如何利用参数偏移规则（PSR）在酉光学神经网络（UONN）中计算梯度，以克服传统反向传播在光学系统中的物理限制，并实现高效的硬件级训练。

**AI_Comments:** 本文的创新之处在于将参数偏移规则（PSR）引入到酉光学神经网络（UONN）的梯度计算中，从而克服了传统反向传播在光学硬件实现中的难题。其重要性在于提供了一种直接从硬件测量中获取精确解析梯度的途径，为光学计算的硬件级训练提供了一条可行且高效的路径，有望加速光学计算技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统神经网络训练中常用的反向传播算法在光学神经网络（ONN）的物理实现中面临显著挑战，这主要是由于光学系统的物理限制。因此，需要一种新的方法来有效地计算ONN的梯度。

**Method:** 本文提出将参数偏移规则（PSR）应用于酉光学神经网络（UONN）中梯度的计算。PSR通过在偏移参数值处评估函数来计算梯度。该方法利用马赫-曾德尔干涉仪网格构建的UONN中光学干涉固有的傅里叶级数特性，直接从硬件测量中计算出精确的解析梯度。

**Result:** 研究展示了PSR可以有效地应用于训练由马赫-曾德尔干涉仪网格构建的UONN。该方法能够直接从硬件测量中计算出精确的解析梯度，提供了一种有前景的替代传统软件模拟训练方法，并规避了有限差分近似和全光反向传播实现的局限性。

**Conclusion:** 将参数偏移规则应用于光学神经网络的梯度计算，为开发高效的基于硬件的光计算系统训练策略提供了可能，有望推动光计算领域的发展。

> **ai_Abstract:** 本文提出了一种利用参数偏移规则（PSR）在酉光学神经网络（UONN）中计算梯度的方法，以应对传统反向传播在光学系统中的实现挑战。研究展示了PSR如何通过利用光学干涉的傅里叶级数特性，直接从硬件测量中计算出精确的解析梯度。这种方法为光学计算系统提供了一种有前景的、无需软件模拟的硬件级训练策略，规避了现有方法的局限性。

> **摘要翻译:** 本文探讨了参数偏移规则（PSR）在酉光学神经网络（UONN）中计算梯度的应用。尽管反向传播是训练传统神经网络的基础，但由于光学系统的物理限制，其在光学神经网络中的实现面临重大挑战。我们展示了如何将PSR（通过评估偏移参数值处的函数来计算梯度）有效地应用于由马赫-曾德尔干涉仪网格构建的UONN的训练。该方法利用这些系统中光学干涉固有的傅里叶级数性质，直接从硬件测量中计算出精确的解析梯度。这种方法为传统的软件模拟训练方法提供了一种有前景的替代方案，并规避了有限差分近似和全光反向传播实现的局限性。我们提出了将PSR应用于优化光学神经网络中相位参数的理论框架和实践方法，这可能促进高效的基于硬件的光计算系统训练策略的发展。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [9] [Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality](https://arxiv.org/abs/2506.10984)
> *使用LLM进行应用现代化：解决可靠性、安全性与质量的核心挑战*

*Ahilan Ayyachamy Nadar Ponnusamy* | **Main category: cs.SE**

**Keywords:** LLM, 应用现代化, 代码生成, 可靠性, 安全性

**Comment:** 

> **TL;DR:** AI辅助代码生成工具虽高效但存在可靠性、安全性、质量问题。本文提出一个结合LLM代码推理与生成能力及人类专业知识的框架，以有效解决应用现代化中的挑战，并通过案例研究验证其效用。

**AI_Comments:** 这篇论文的创新之处在于它强调了LLM的代码推理和生成能力与人类专业知识相结合的重要性，以解决AI生成代码的固有挑战。它通过一个实际案例研究来验证其框架，这增加了其实用性和可信度。该工作对于提升AI辅助软件开发的质量和可靠性具有重要意义，并为未来研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** AI辅助代码生成工具虽高效，但面临安全漏洞、可靠性问题及代码不一致等挑战。现有LLM在缓解这些问题上仍有显著差距，尤其是在确保高质量、可信赖输出方面。解决这些问题对于充分发挥该技术的潜力至关重要。

**Method:** 本文基于现有研究，提出一种强调LLM代码推理和代码生成两种核心能力的方法。该框架将这些能力与人类专业知识相结合，以有效应对应用现代化挑战。通过一个详细的案例研究来展示框架的实用性，并提供了逐步分析和替代方法评估。

**Result:** 论文展示了一个详细的案例研究，逐步分析了所提出的框架在真实场景中的应用，并评估了替代方法。这旨在提供可操作的见解和未来研究的坚实基础。

**Conclusion:** 论文的结论是，通过结合LLM的代码推理和生成能力与人类专业知识，可以有效解决应用现代化中的可靠性、安全性和质量挑战。人类的参与和指导在AI辅助过程中是不可或缺的。

> **ai_Abstract:** 本文探讨了在应用现代化中使用LLM以解决代码生成中存在的可靠性、安全性及质量挑战。提出了一种结合LLM的代码推理与生成能力以及人类专业知识的框架，强调了人类在AI辅助过程中的关键作用。通过一个详细的真实世界案例研究验证了该框架的有效性，并旨在为AI驱动的应用现代化研究提供实践指导和基础。

> **摘要翻译:** AI辅助代码生成工具彻底改变了软件开发，提供了前所未有的效率和可扩展性。然而，多项研究一致强调了诸如安全漏洞、可靠性问题以及生成代码不一致等挑战。解决这些问题对于充分发挥这项变革性技术的全部潜力至关重要。虽然基础和代码专用语言模型的进步在缓解其中一些问题方面取得了显著进展，但仍存在显著差距，尤其是在确保高质量、可信赖的输出方面。
本文建立在利用大型语言模型（LLMs）进行应用现代化的现有研究基础之上。它探索了一种有主见的方法，强调了LLM的两个核心能力：代码推理和代码生成。所提出的框架将这些能力与人类专业知识相结合，以有效应对应用现代化挑战。它强调了人类参与和指导在确保AI辅助过程成功中的不可或缺作用。
为了展示该框架的实用性，本文提出了一个详细的案例研究，逐步演示了其在真实场景中的应用。分析包括逐步分解，并在适用情况下评估替代方法。这项工作旨在为AI驱动的应用现代化提供可操作的见解和坚实的基础，以供未来研究。为本文创建的参考实现可在GitHub上获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [37] [Collaboration Tools and their Role in Agile Software Projects](https://arxiv.org/abs/2506.10985)
> *协作工具及其在敏捷软件项目中的作用*

*Raman Mohammed Hussein, Bryar A. Hassan* | **Main category: cs.SE**

**Keywords:** 协作工具, 敏捷软件项目, Slack, Microsoft Teams, Confluence

**Comment:** https://www.middleeastconference.org/_files/ugd/614b1f_82fa5f91169a44278723a921b27e2864.pdf
  ISBN: 979-8-89695-015-8

> **TL;DR:** 本综述探讨了Slack、Microsoft Teams和Confluence等协作工具在敏捷软件项目中的重要性，强调它们如何促进沟通、协调和知识共享，以提高项目效率，尤其是在远程工作环境中。

**AI_Comments:** 该论文强调了协作工具在当前敏捷开发实践中的实用性和重要性，尤其是在远程工作日益普遍的背景下。其价值在于明确指出了特定工具（Slack、Microsoft Teams、Confluence）在促进敏捷协作方面的具体作用，为团队选择和利用这些工具提供了指导。然而，作为一篇综述，它可能缺乏实证数据或案例研究来量化这些工具带来的具体效益，也未深入探讨潜在的局限性或最佳实践。

<details>
  <summary>Details</summary>

**Motivation:** 尽管员工和团队远程工作，但许多团队在协作和沟通方面仍面临巨大问题。本研究旨在理解协作工具在敏捷和软件项目中的重要性，以解决这一痛点，提高项目效率。

**Method:** 本研究通过综述（review）的方式，考察了Slack、Microsoft Teams和Confluence等协作工具如何适应敏捷原则，如何促进迭代开发，以及如何有效启动和跟踪任务。研究深入分析了这些工具在任务协调、知识共享和跨职能环境中采纳敏捷价值观方面的关键作用。

**Result:** 协作工具（如Slack、Microsoft Teams、Confluence）能够更好地组织工作、提高相互理解的开放性，并实现快速高效的团队内部和人际互动，从而将项目成果转化为生产力。它们对于实现更好的任务协调、支持知识共享以及在跨职能环境中采纳敏捷价值观至关重要。

**Conclusion:** 协作工具在敏捷软件项目中扮演着至关重要的角色，它们通过改善沟通、促进协调和知识共享，显著提升了团队协作效率和项目生产力，尤其适用于远程工作环境。

> **ai_Abstract:** 本论文综述了Slack、Microsoft Teams和Confluence等协作工具在敏捷软件项目中的关键作用。鉴于当前团队协作和沟通面临的挑战，尤其是远程工作场景，研究探讨了这些工具如何通过优化工作组织、增强开放性、加速团队间互动来提升项目生产力。论文进一步分析了这些工具如何与敏捷原则契合，支持迭代开发，并有效管理任务，强调它们在任务协调、知识共享和敏捷价值观推广方面的核心价值。

> **摘要翻译:** 本综述旨在理解协作工具（如Slack、Microsoft Teams、Confluence）在敏捷和软件项目中的重要性。敏捷方法论依赖于灵活性，在开发周期的各个层面使用周期和集成。然而，即使员工和团队远程工作，许多团队在协作和沟通方面仍然是一个大问题。在协作方面，应用程序和技术意味着更好地组织工作、增加相互理解的开放性以及快速高效的团队内部和人际互动，以提高项目成果的生产力。本文探讨了这些工具如何适应敏捷原则，如何促进迭代开发，以及如何鼓励在小型和大型项目中有效启动和跟踪任务。洞察力集中于Slack、Microsoft Teams和Confluence如何对于获得更好的任务协调、支持知识共享以及在跨职能环境中采纳敏捷价值观至关重要。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [61] [From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools](https://arxiv.org/abs/2506.11141)
> *从过度依赖到智能集成：使用大型语言模型作为专业建模与仿真工具之间的翻译器*

*Philippe J. Giabbanelli, John Beverley, Istvan David, Andreas Tolk* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 建模与仿真, 工具集成, 互操作性, 低秩适应

**Comment:** Accepted at the Winter Simulation conference 2025, December, Seattle
  USA

> **TL;DR:** 论文提出将大型语言模型（LLMs）作为专业建模与仿真（M&S）工具之间的翻译器或中间件，以克服过度依赖LLMs的风险并提高互操作性，确保LLMs是补充而非替代。

**AI_Comments:** 这篇论文提出了一个重要的观点，即如何在使用大型语言模型时避免“过度依赖”并实现“智能集成”。其创新点在于将LLMs定位为专业建模与仿真工具之间的“翻译器”或“中间件”，这提供了一个实用的框架来利用LLMs的优势同时规避其固有的缺陷（如幻觉和逻辑错误）。强调LLMs作为补充而非替代的理念，对于确保M&S领域的质量和可靠性至关重要。该方法通过解决互操作性挑战和提出高效集成架构（如LoRA），为LLMs在复杂科学计算领域的应用提供了有益的指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）通过自然语言接口为建模与仿真（M&S）提供了变革性潜力，但过度依赖LLMs可能因歧义、逻辑捷径和幻觉而损害质量。

**Method:** 论文提倡将LLMs作为专业工具之间的中间件或翻译器进行集成，以减轻M&S任务的复杂性。具体方法包括：解决识别适当语言和工具的挑战；开发高效的软件架构以集成LLMs而无性能瓶颈；探索LLM介导的工作流程；强调结构化工具集成；推荐基于低秩适应（Low-Rank Adaptation, LoRA）的架构进行高效的任务特定适应。

**Result:** Not mentioned in abstract

**Conclusion:** 这种方法确保了大型语言模型是补充而非替代专业工具，从而促进高质量、可靠的建模与仿真过程。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在建模与仿真（M&S）领域的应用，指出尽管LLMs潜力巨大，但过度依赖可能导致质量问题。为解决此问题，论文提出将LLMs作为专业M&S工具之间的翻译器或中间件，以增强互操作性并降低任务复杂性。研究关注如何选择合适的工具语言以及构建高效的LLM集成架构，并推荐使用低秩适应（LoRA）技术实现任务特定优化，旨在使LLMs成为专业工具的有效补充而非替代。

> **摘要翻译:** 大型语言模型（LLMs）通过简化工作流程的自然语言接口，为建模与仿真（M&S）提供了变革性潜力。然而，过度依赖存在因歧义、逻辑捷径和幻觉而损害质量的风险。本文主张将LLMs作为专业工具之间的中间件或翻译器进行集成，以减轻M&S任务的复杂性。作为翻译器，LLMs可以增强多形式、多语义和多范式系统之间的互操作性。我们解决了两个关键挑战：识别适合建模与仿真任务的语言和工具，以及开发高效的软件架构以集成LLMs而无性能瓶颈。为此，本文探讨了LLM介导的工作流程，强调了结构化工具集成，并推荐基于低秩适应（Low-Rank Adaptation, LoRA）的架构进行高效的任务特定适应。这种方法确保了LLMs是补充而非替代专业工具，从而促进高质量、可靠的M&S过程。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [65] [CoMRAT: Commit Message Rationale Analysis Tool](https://arxiv.org/abs/2506.10986)
> *CoMRAT：提交信息理由分析工具*

*Mouna Dhaouadi, Bentley James Oakes, Michalis Famelis* | **Main category: cs.SE**

**Keywords:** 提交信息, 理由分析, CoMRAT, 工具, 开源开发

**Comment:** 

> **TL;DR:** 提出了CoMRAT工具，用于分析提交信息中的决策和理由，对研究人员和开发者都有用。

**AI_Comments:** 该论文提出CoMRAT工具，填补了提交信息中理由分析研究的空白，具有创新性。它为研究人员提供了量化和分析理由信息的能力，同时也为开发者提供了改进提交信息质量的途径，具有重要意义。然而，目前仅进行了初步评估，未来需要更广泛的验证。

<details>
  <summary>Details</summary>

**Motivation:** 提交信息是代码变更理由的丰富来源，但对提交信息中理由的研究仍然有限。

**Method:** 提出了CoMRAT工具，用于分析提交信息中的决策和理由句子。该工具使研究人员能够生成关于GitHub模块中理由信息的指标和分析，并使开发人员能够检查其提交信息中理由的数量。

**Result:** 初步评估表明该工具在研究和开发环境中都具有实用性和可用性。

**Conclusion:** CoMRAT工具能够有效地分析提交信息中的决策和理由，对研究和开发社区都有益。

> **ai_Abstract:** 本文介绍了CoMRAT，一个专门用于分析提交信息中决策和理由句子的工具。该工具旨在帮助研究人员生成关于GitHub模块中理由信息的指标和分析，并协助开发人员检查其提交信息中理由的多少。初步评估结果表明CoMRAT在研究和开发场景中均表现出良好的实用性和可用性。

> **摘要翻译:** 在协作开源开发中，代码变更的理由通常记录在提交信息中，使其成为有价值信息的丰富来源。然而，对提交信息中理由的研究仍然有限。在本文中，我们提出了CoMRAT，一个用于分析提交信息中决策和理由句子的工具。CoMRAT使a)研究人员能够生成关于任何Github模块中理由信息的指标和分析，以及b)开发人员能够检查其提交信息中理由的数量。初步评估表明该工具在研究和开发这两种背景下都具有实用性和可用性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [72] [On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances](https://arxiv.org/abs/2506.10990)
> *论“跟随太阳”策略在减轻云实例中人工智能碳足迹方面的有效性*

*Roberto Vergallo, Luís Cruz, Alessio Errico, Luca Mainetti* | **Main category: cs.SE**

**Keywords:** 跟随太阳, 碳足迹, 人工智能, 云计算, 能源效率

**Comment:** 24 pages, 4 figures, 10 tables

> **TL;DR:** 本研究通过实验证明，“跟随太阳”策略能有效减少AI训练的碳排放，平均可达14.6%，同时不影响训练时间。

**AI_Comments:** 该论文通过实验数据首次验证了“跟随太阳”策略在AI碳足迹缓解方面的有效性，填补了现有研究空白。其创新之处在于将理论模型应用于实际AI工作负载，并提供了量化减排数据。这项工作对于推动绿色AI和可持续云计算具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）的巨大功耗及其碳足迹日益受到关注，而现有文献缺乏关于“跟随太阳”（FtS）策略在减轻AI工作负载碳足迹方面的科学证据，因此本研究旨在填补这一空白。

**Method:** 研究在一个部分合成场景中进行了实验，对异常检测领域的四种AI算法进行了基准测试。实验比较了四种情况下的碳排放差异：无策略、FtS、灵活启动（Flexible Start）和暂停与恢复（Pause and Resume）。实验利用了2021年七个欧洲城市的历史碳强度数据。

**Result:** 实验结果表明，FtS策略不仅平均减少了高达14.6%的碳排放（峰值达16.3%），而且有助于保持训练所需的时间。

**Conclusion:** “跟随太阳”策略是一种有效减轻AI训练碳足迹的方法，同时不损害训练效率。

> **ai_Abstract:** 本研究旨在填补“跟随太阳”（FtS）策略在减轻AI工作负载碳足迹方面缺乏科学证据的空白。通过在一个部分合成场景中对四种AI算法进行实验，并比较FtS、无策略及两种现有策略的碳排放，研究发现FtS策略能有效减少AI训练的碳排放，平均降幅达14.6%（峰值16.3%），同时保持训练时间不变。这证明了FtS在绿色AI计算中的潜力。

> **摘要翻译:** “跟随太阳”（FtS）是一种旨在最小化计算机工作负载碳足迹的理论计算模型。它涉及随着需求增加和能源生产更多依赖化石燃料时，将工作负载动态地转移到能源更清洁的区域。鉴于人工智能（AI）的巨大功耗已成为广泛争论的话题，FtS被提议作为一种减轻AI模型训练碳足迹的策略。然而，现有文献缺乏关于FtS减轻AI工作负载碳足迹优势的科学证据。在本文中，我们展示了在部分合成场景中进行的实验结果，以解决这一研究空白。我们对异常检测领域的四种AI算法进行了基准测试，并测量了四种情况下的碳排放差异：无策略、FtS，以及先前在现有技术中引入的两种策略，即灵活启动（Flexible Start）和暂停与恢复（Pause and Resume）。为了进行实验，我们利用了2021年七个欧洲城市的历史碳强度数据。我们的结果表明，FtS策略不仅平均减少了高达14.6%的碳排放（峰值达16.3%），而且有助于保持训练所需的时间。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [73] [Contract-based Verification of Digital Twins](https://arxiv.org/abs/2506.10993)
> *基于契约的数字孪生验证*

*Muhammad Naeem, Cristina Seceleanu* | **Main category: cs.SE**

**Keywords:** 数字孪生, 模型检测, 契约验证, 黑盒验证, UPPAAL

**Comment:** Accepted at ICECCS 2025, to appear in Lecture Notes in Computer
  Science (LNCS), Springer

> **TL;DR:** 本文提出了一种将模型检测集成到数字孪生模型验证中的创新方法，通过定义系统级契约来验证其行为，无需了解数字孪生内部设计，并成功应用于锅炉系统案例。

**AI_Comments:** 本文的创新之处在于将形式化验证工具（模型检测）与数字孪生技术相结合，以解决其验证难题。其“黑盒”验证能力尤其重要，因为它允许在不深入了解数字孪生复杂内部机制的情况下进行验证，这对于实际工业应用非常有利。通过引入“系统级契约”的概念，为数字孪生的行为验证提供了一个清晰且可验证的框架。该方法对于确保数字孪生在关键应用中的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 数字孪生在工业应用中日益强大，但由于其可能使用大量数据集，这些模型的验证仍然是一个重大挑战。

**Method:** 本文提出了一种创新的方法，通过将模型检测集成到过程中，以黑盒方式验证基于神经网络的数字孪生模型。该方法依赖于定义和应用捕获系统需求的系统级契约，以验证在Simulink中实现的数字孪生模型的行为。开发了一种自动化解决方案，模拟数字孪生模型以获取特定输入，并将预测输出与输入一起馈送到在UPPAAL模型检测器中描述为定时自动机网络的契约模型中，该模型验证预测输出是否满足指定的契约。

**Result:** 该方法无需数字孪生内部设计细节，即可识别数字孪生行为未能满足契约的场景。将该方法应用于锅炉系统案例研究，并通过契约验证识别了预测错误。

**Conclusion:** 我们的工作证明了将模型检测与数字孪生模型集成以实现持续改进的有效性。

> **ai_Abstract:** 本文提出了一种基于契约的黑盒验证方法，用于基于神经网络的数字孪生模型。该方法通过将模型检测（特别是使用UPPAAL中的定时自动机）与系统级契约相结合，来验证数字孪生模型的行为。它能够识别数字孪生未能满足契约的场景，且无需了解其内部设计。通过一个锅炉系统案例研究，验证了该方法在识别预测错误方面的有效性，并强调了模型检测与数字孪生集成对持续改进的重要性。

> **摘要翻译:** 数字孪生正在成为工业应用中强大的工具，提供网络物理系统的虚拟表示。然而，由于数字孪生可能使用大量数据集，这些模型的验证仍然是一个重大挑战。本文介绍了一种创新的方法，通过将模型检测集成到过程中，以黑盒方式验证基于神经网络的数字孪生模型。后者依赖于定义和应用捕获系统需求的系统级契约，以验证在Simulink中实现的数字孪生模型的行为。我们开发了一种自动化解决方案，模拟数字孪生模型以获取特定输入，并将预测输出与输入一起馈送到在UPPAAL模型检测器中描述为定时自动机网络的契约模型中。后者验证预测输出是否满足指定的契约。这种方法允许我们识别数字孪生行为未能满足契约的场景，而无需数字孪生内部设计细节。我们将我们的方法应用于一个锅炉系统案例研究，通过契约验证识别了预测错误。我们的工作证明了将模型检测与数字孪生模型集成以实现持续改进的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [89] [Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering](https://arxiv.org/abs/2506.11176)
> *模型发现与图仿真：混沌工程的轻量级替代方案*

*Anatoly A. Krasnovsky, Alexander Zorkin* | **Main category: cs.SE**

**Keywords:** 微服务, 弹性, 混沌工程, 模型发现, 图仿真

**Comment:** 

> **TL;DR:** 该论文提出了一种轻量级的混沌工程替代方案，通过自动化模型发现和图仿真来预测微服务弹性。研究表明，从跟踪数据中提取的简单依赖图可以准确预测弹性，与实际混沌实验结果高度吻合。

**AI_Comments:** 该论文的创新之处在于提出了一种轻量级、自动化的方法（模型发现和图仿真），可以有效替代或补充传统资源密集型的混沌工程，用于微服务弹性预测。其重要性在于提供了一种更快、更经济有效的方式来获得系统弹性的设计时洞察，有望加速开发周期并减少测试开销。

<details>
  <summary>Details</summary>

**Motivation:** 微服务应用程序由于服务间密集的依赖关系而容易发生级联故障，而确保弹性通常需要耗费资源的故障注入实验。因此，需要一种轻量级的替代方案来预测微服务弹性。

**Method:** 该研究提出了“模型发现”——一个自动化的CI/CD步骤，用于从跟踪数据中提取实时依赖图。然后，利用该图通过蒙特卡洛方法模拟故障，并与在DeathStarBench社交网络上运行的实际混沌实验进行比较验证。

**Result:** 图模型与实际情况高度吻合：在没有复制的情况下，16次试验观察到的弹性为0.186，预测值为0.161；在有复制的情况下，观察值和预测值均收敛到0.305（平均绝对误差≤0.0004）。这些结果表明，即使是简单的、自动发现的图也能高精度地估计微服务可用性。

**Conclusion:** 即使是一个简单的、自动发现的依赖图也能高精度地估计微服务可用性，无需进行全面的故障测试即可提供快速的设计时洞察，为传统的混沌工程提供了一种轻量级替代方案。

> **ai_Abstract:** 该论文提出“模型发现”和图仿真作为混沌工程的轻量级替代方案，用于微服务弹性预测。通过从跟踪数据中自动提取依赖图，所提出的方法能够准确模拟和预测级联故障。在DeathStarBench社交网络上的实验结果表明，图模型的预测与实际混沌实验高度吻合，无需全面的故障注入即可为微服务可用性提供快速的设计时洞察。

> **摘要翻译:** 微服务应用程序由于服务间密集的依赖关系而容易发生级联故障。确保弹性通常需要在类似生产的环境中进行故障注入实验。我们提出了“模型发现”——一个自动化的CI/CD步骤，从跟踪数据中提取实时依赖图——并表明这种轻量级表示足以准确预测弹性。我们使用DeathStarBench社交网络构建了图，通过蒙特卡洛模拟了故障，并在真实系统上运行了匹配的混沌实验。图模型与现实非常吻合：在没有复制的情况下，16次试验观察到的弹性为0.186，预测值为0.161；在有复制的情况下，观察值和预测值都收敛到0.305（平均绝对误差≤0.0004）。这些结果表明，即使是一个简单的、自动发现的图也可以高精度地估计微服务可用性，无需全面的故障测试即可提供快速的设计时洞察。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [93] [Chain of Draft for Software Engineering: Challenges in Applying Concise Reasoning to Code Tasks](https://arxiv.org/abs/2506.10987)
> *软件工程中的草稿链：将简洁推理应用于代码任务的挑战*

*Shaoyi Yang* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 草稿链, 软件工程, 提示策略, 效率, 代码质量

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）在软件开发中常需冗长推理，导致高延迟和成本。本研究将草稿链（CoD）方法扩展到软件工程，设计并评估了多种CoD变体。实验证明，CoD变体显著减少了token使用量（基线CoD为CoT的55.4%），同时保持了90%以上的代码质量，为LLM驱动的软件开发提供了高效实用的替代方案。

**AI_Comments:** 该论文为LLM在软件开发中的应用提供了一个实用的解决方案，有效解决了效率与质量之间的权衡问题。通过将草稿链方法应用于软件工程领域，它显著降低了计算成本和延迟，同时基本保持了解决方案的质量。论文认识到软件任务比数学任务需要更详细的推理，这一洞察力突出了该领域的特定挑战。这项工作在将CoD应用于新领域方面具有创新性，并为优化软件工程中LLM提示策略提供了宝贵的实证依据。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在处理复杂的代码任务时，通常需要冗长的中间推理，这导致了高延迟和高成本。

**Method:** 本研究将草稿链（CoD）方法扩展到软件工程领域，设计并评估了多种针对代码任务量身定制的CoD变体。通过对SWE-bench基准测试中的所有300个样本进行了全面实验。

**Result:** 所有CoD变体使用的token数量均显著少于思维链（CoT）。其中，基线CoD的效率最高，仅为CoT token量的55.4%，相当于处理时间与API成本减少了约45%。尽管效率提升幅度不如原始CoD论文中数学推理的极端（7.6%），但CoD变体在正确性、兼容性和可维护性等关键指标上保持了CoT代码质量的90%以上。

**Conclusion:** CoD变体是效率至关重要的实际开发场景中的实用替代方案。本研究展示了领域特定特性如何影响提示策略的有效性，并提供了一个在软件工程应用中平衡效率与解决方案质量的框架，为优化基于LLM的开发工作流提供了实用指导。

> **ai_Abstract:** 本论文将草稿链（CoD）方法应用于软件工程领域，旨在解决大型语言模型（LLM）在处理复杂代码任务时因冗长推理导致的高延迟和高成本问题。研究设计并评估了多种CoD变体，并通过SWE-bench基准测试的全面实验证明，CoD变体相较于思维链（CoT）显著减少了token使用量，其中基线CoD的token量仅为CoT的55.4%，从而实现了约45%的处理时间与API成本降低。尽管效率提升幅度低于数学推理领域的报告，但CoD变体在代码质量方面（包括正确性、兼容性和可维护性）保持了CoT的90%以上。这表明CoD变体是实际软件开发中平衡效率与解决方案质量的实用替代方案，并为优化基于LLM的开发工作流提供了指导。

> **摘要翻译:** 大型语言模型（LLM）已成为软件开发的重要工具，但它们通常需要冗长的中间推理来完成复杂的代码任务，这会导致高延迟和高成本。本研究将草稿链（CoD）方法扩展到软件工程领域，设计并评估了针对代码任务量身定制的多种CoD变体。通过对SWE-bench基准测试中所有300个样本进行的全面实验，我们发现所有CoD变体使用的token数量均显著少于思维链（CoT），其中基线CoD的效率最高，仅为CoT token量的55.4%。虽然这代表了显著的效率提升——转化为处理时间与API成本约45%的减少——但这与原始CoD论文中报告的数学推理的极端7.6%有所不同。这种差异源于软件任务固有的复杂性和上下文依赖性，需要更详细的推理来维持解决方案质量。我们的多维度质量评估显示，CoD变体在正确性、兼容性和可维护性等关键指标上保持了CoT代码质量的90%以上，使其成为效率至关重要的实际开发场景中的实用替代方案。本研究展示了领域特定特性如何影响提示策略的有效性，并提供了一个在软件工程应用中平衡效率与解决方案质量的框架。我们的研究结果为通过根据项目需求选择适当的提示策略来优化基于LLM的开发工作流提供了实用指导。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [116] [Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing](https://arxiv.org/abs/2506.11180)
> *超越能力和技能的形式语义：制造中的模型上下文协议*

*Luis Miguel Vieira da Silva, Aljosha Köcher, Felix Gehlhoff* | **Main category: cs.SE**

**Keywords:** 模型上下文协议, 大型语言模型, 工业自动化, 制造, 能力建模

**Comment:** 

> **TL;DR:** 该论文提出了一种基于模型上下文协议（MCP）的新方法，使大型语言模型（LLMs）能够直接消费系统功能，从而在制造领域实现灵活的工业自动化，而无需显式语义模型。

**AI_Comments:** 该论文提出了一种创新的方法，通过模型上下文协议（MCP）直接将系统功能暴露给LLM，从而避免了传统显式语义建模的复杂性和局限性。这种方法对于推动LLM在工业自动化领域的应用具有重要意义，尤其是在实现更灵活、更自主的生产系统方面。其创新点在于绕过了复杂的语义表示层，使得LLM能够更直接地与物理系统交互。

<details>
  <summary>Details</summary>

**Motivation:** 现有的能力和技能显式建模方法（如本体论、资产管理外壳）需要大量手动工作，并且生成的表示形式LLM难以访问。

**Method:** 本文提出了一种基于模型上下文协议（MCP）的替代方法。MCP允许系统通过标准化接口暴露功能，LLM代理可以直接使用。研究人员在一个实验室规模的制造系统上进行了原型评估，通过MCP提供资源功能，并让通用LLM规划和执行多步骤过程，包括约束处理和通过MCP调用资源功能。

**Result:** 结果表明，这种方法可以在不依赖显式语义模型的情况下实现灵活的工业自动化。

**Conclusion:** 这种方法为LLM驱动的生产系统中外部工具集成的进一步探索奠定了基础。

> **ai_Abstract:** 本研究提出了一种名为模型上下文协议（MCP）的新方法，旨在解决现有能力和技能建模方法对大型语言模型（LLM）不友好且需大量手动工作的问题。通过MCP，系统功能可以直接暴露给LLM代理。在实验室规模的制造系统上的原型评估表明，这种方法能够实现灵活的工业自动化，且无需依赖显式语义模型，为LLM在生产系统中的工具集成提供了基础。

> **摘要翻译:** 显式建模能力和技能——无论是基于本体论、资产管理外壳还是其他技术——都需要大量的体力劳动，并且通常会导致大型语言模型（LLM）难以访问的表示。在这篇正在进行的工作论文中，我们提出了一种基于最近引入的模型上下文协议（MCP）的替代方法。MCP允许系统通过标准化接口暴露功能，该接口可以直接被基于LLM的代理消费。我们对一个实验室规模的制造系统进行了原型评估，其中资源功能通过MCP提供。然后，一个通用LLM负责规划和执行一个多步骤过程，包括约束处理和通过MCP调用资源功能。结果表明，这种方法可以在不依赖显式语义模型的情况下实现灵活的工业自动化。这项工作为LLM驱动的生产系统中外部工具集成的进一步探索奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [120] [You Only Train Once: A Flexible Training Framework for Code Vulnerability Detection Driven by Vul-Vector](https://arxiv.org/abs/2506.10988)
> *你只训练一次：一种由Vul-Vector驱动的代码漏洞检测灵活训练框架*

*Bowen Tian, Zhengyang Xu, Mingqiang Wu, Songning Lai, Yutai Yue* | **Main category: cs.SE**

**Keywords:** 代码漏洞检测, 深度学习, 训练框架, 参数融合, YOTO

**Comment:** Under Review

> **TL;DR:** YOTO（你只训练一次）是一个代码漏洞检测框架，通过参数融合集成多种模型，无需联合训练，从而快速适应新漏洞并减少更新资源。

**AI_Comments:** YOTO框架的创新之处在于其“你只训练一次”的理念，通过参数融合而非联合训练来集成多种漏洞检测模型。这对于快速迭代和频繁出现新漏洞的代码安全领域具有重要意义，能够显著提高模型部署和更新的效率，降低资源消耗，使其在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于深度学习的代码漏洞检测方法面临挑战：需要大量标注数据集、训练周期长，且新漏洞频繁出现导致模型需要频繁再训练，这消耗大量资源并限制了其在尖端场景的应用。

**Method:** 本文提出了YOTO（你只训练一次）框架。该方法通过参数融合实现多种漏洞检测模型的集成，无需进行联合训练。

**Result:** YOTO框架能够快速适应新发现的漏洞，显著减少模型更新所需的时间和计算资源。

**Conclusion:** YOTO框架通过参数融合解决了现有深度学习漏洞检测方法对大量数据、长时间训练及频繁再训练的依赖，从而实现了对新漏洞的快速适应并降低了资源消耗。

> **ai_Abstract:** 本论文提出了YOTO（你只训练一次）框架，旨在解决现有深度学习代码漏洞检测方法在数据需求、训练时间和模型更新方面的挑战。YOTO通过参数融合技术，允许集成多种漏洞检测模型而无需联合训练，从而实现对新漏洞的快速适应，并显著降低模型更新所需的时间和计算资源。

> **摘要翻译:** 随着计算机应用程序在各行各业的普及，代码库中存在的漏洞构成了重大风险。软件生态系统的多样性以及现代软件工程的复杂性，使得代码漏洞识别从手动转向采用自动化工具。其中，基于深度学习的方法因其卓越的准确性而日益突出；然而，这些方法遇到了几个障碍。首先，它们需要大量的标注数据集和漫长的训练周期，并且鉴于新漏洞的快速出现，模型的频繁再训练成为一项资源密集型工作，从而限制了它们在尖端场景中的适用性。为了缓解这些挑战，本文引入了YOTO——你只训练一次框架。这种创新方法通过参数融合促进了多种类型漏洞检测模型的集成，消除了联合训练的需要。因此，YOTO能够快速适应新发现的漏洞，显著减少模型更新所需的时间和计算资源。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [145] [Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs](https://arxiv.org/abs/2506.10989)
> *提示工程与框架：基于LLM的代码可靠性提升指南实现*

*Rogelio Cruz, Jonatan Contreras, Francisco Guerrero, Ezequiel Rodriguez, Carlos Valdez, Citlali Carrillo* | **Main category: cs.SE**

**Keywords:** 提示工程, 大型语言模型, 代码生成, Python, 可靠性

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的提示工程方法，旨在提高大型语言模型生成Python代码的准确性和可靠性，并在HumanEval数据集上表现优于零样本和思维链方法，同时显著降低了token使用量。

**AI_Comments:** 该论文的创新点在于提出了一种定制化的提示工程方法，通过优化提示模板来显著提高LLMs生成代码的可靠性和效率。其重要性在于不仅提升了代码质量，还降低了计算成本和环境足迹，这对于LLM在AI编程领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提升大型语言模型（LLMs）生成准确Python代码的能力，使其生成的代码能够通过测试并产生可靠结果。

**Method:** 提出了一种新颖的提示工程方法，具体是一种提示模板，旨在提高生成代码片段的质量和正确性。通过在HumanEval数据集上使用两种最先进的LLMs进行实验。

**Result:** 该方法在Pass@k指标上优于广泛研究的零样本（zero-shot）和思维链（Chain-of-Thought, CoT）方法。与CoT方法相比，显著减少了token使用量。

**Conclusion:** 定制的提示策略具有优化代码生成性能的潜力，为AI驱动的编程任务的更广泛应用铺平了道路。

> **ai_Abstract:** 本研究提出了一种新颖的提示工程方法，通过引入一个特定的提示模板来提升大型语言模型（LLMs）生成Python代码的准确性和可靠性。实验结果表明，该方法在HumanEval数据集上，在Pass@k指标上优于零样本和思维链（CoT）方法，并且显著降低了token使用量，证明了其在提高代码生成性能方面的有效性和资源效率。

> **摘要翻译:** 在本文中，我们提出了一种新颖的提示方法，旨在增强大型语言模型（LLMs）生成准确Python代码的能力。具体来说，我们引入了一个提示模板，旨在提高生成代码片段的质量和正确性，使其能够通过测试并产生可靠的结果。通过在HumanEval数据集上对两种最先进的LLMs进行的实验，我们证明了我们的方法在Pass@k指标上优于广泛研究的零样本和思维链（CoT）方法。此外，我们的方法在实现这些改进的同时，与CoT方法相比显著减少了token使用量，使其既有效又资源高效，从而降低了计算需求并改善了LLM能力的生态足迹。这些发现突出了定制提示策略优化代码生成性能的潜力，为AI驱动的编程任务的更广泛应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [185] [What is Business Process Automation Anyway?](https://arxiv.org/abs/2506.10991)
> *业务流程自动化到底是什么？*

*Hoang Vu, Henrik Leopold, Han van der Aa* | **Main category: cs.SE**

**Keywords:** 业务流程自动化, 机器人流程自动化, 市场分析, 数字化自动化, 自动化能力

**Comment:** Accepted at HICSS 2023

> **TL;DR:** 本文通过对领先供应商进行市场分析，全面概述了工业界提供的业务流程自动化能力，并指出了未来的发展方向。

**AI_Comments:** 该论文通过对市场进行广泛分析，拓宽了对业务流程自动化的理解，超越了学术界普遍关注的机器人流程自动化（RPA）的狭隘视角。它为行业实践者和研究人员提供了一个全面的能力图谱和未来发展方向，具有重要的实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多组织致力于提高业务流程的自动化水平，但学术界主要关注机器人流程自动化（RPA）。鉴于领先供应商提供的自动化能力远超RPA，本文旨在深入理解工业界中的业务流程自动化。

**Method:** 对Gartner确定的18家主要的业务流程自动化解决方案供应商进行了结构化的市场分析。

**Result:** 提供了一份关于工业供应商目前提供的业务流程自动化能力的全面概述。揭示了存在哪些类型的自动化和方面，以及哪些方面代表了未来有前景的方向。

**Conclusion:** 通过市场分析，本文对工业界业务流程自动化的现状和未来发展方向提供了全面且深入的理解。

> **ai_Abstract:** 本文旨在深入理解工业界中的业务流程自动化，通过对Gartner确定的18家主要业务流程自动化解决方案供应商进行结构化市场分析。研究结果提供了一份全面的概述，展示了当前工业供应商提供的自动化能力，并揭示了自动化的类型、方面以及未来有前景的发展方向，以此弥补了学术界对业务流程自动化理解的局限性。

> **摘要翻译:** 许多组织致力于提高其业务流程的自动化水平。虽然自动化在历史上主要关注物理劳动自动化，但当前的自动化工作主要集中在数字化自动化，从而针对人机交互相关的工作。这种自动化，通常被称为业务流程自动化，具有多方面的特点。然而，学术文献主要关注机器人流程自动化，这是一种特定的自动化能力。认识到领先供应商提供的自动化能力远远超出这一点，我们利用本文来详细了解工业界中的业务流程自动化。为此，我们对Gartner确定的18家主要的业务流程自动化解决方案供应商进行了结构化的市场分析。结果是，我们提供了工业供应商目前提供的业务流程自动化能力的全面概述。我们展示了存在哪些类型的自动化和方面，以及哪些方面代表了未来有前景的方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [205] [Towards a Theory on Process Automation Effects](https://arxiv.org/abs/2506.10992)
> *流程自动化效果理论的探索*

*Hoang Vu, Jennifer Haase, Henrik Leopold, Jan Mendling* | **Main category: cs.SE**

**Keywords:** 流程自动化, 人机交互, 业务流程, 参与模型, 自动化效果

**Comment:** Accepted at HICSS 2023

> **TL;DR:** 论文通过回顾人机交互文献，探讨流程自动化操作后的影响，提出一个有效的技术-人员互动模型，并为组织优化自动化使用提供见解和建议。

**AI_Comments:** 这篇论文的创新点在于填补了流程自动化运行后效果研究的空白，特别是通过结合人机交互领域的文献来构建理论。它不仅提出了一个实用的参与模型，还为未来的研究指明了方向，对于推动流程自动化理论和实践的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管流程自动化是改善业务流程的关键策略，但对于自动化投入运行后的实际效果，学界关注甚少。本文旨在解决这一研究空白。

**Method:** 本文通过回顾人机交互领域的文献来解决研究问题。分析侧重于人类在流程中如何感知自动化技术，并在此基础上提出关于流程自动化效果的命题。

**Result:** 论文提出了一个技术、流程参与者、流程经理和软件开发人员之间有效的参与模型。它还为组织优化流程自动化使用提供了见解和建议，并引出了流程自动化社区内部讨论的新研究问题。

**Conclusion:** 论文通过文献回顾，提出了流程自动化效果的命题和有效的参与模型，旨在帮助组织优化自动化使用，并为未来的研究奠定基础。

> **ai_Abstract:** 本文旨在弥补流程自动化在运行后效果研究的不足。通过回顾人机交互文献，论文分析了人类对自动化技术的感知，并提出了一个有效的人与自动化技术之间的互动模型。此外，论文还为组织提供了优化流程自动化使用的见解和建议，并提出了新的研究问题，以促进流程自动化领域的讨论。

> **摘要翻译:** 流程自动化是改进业务流程的关键策略，但对于自动化投入运行后的效果却鲜有关注。本文通过回顾人机交互领域的文献来解决这一研究问题。尽管该领域中的许多研究是在不同领域进行的，但它们为发展关于流程自动化效果的命题提供了基础。我们的分析侧重于人类在流程中工作时如何感知自动化技术，从而使我们能够提出一个技术、流程参与者、流程经理和软件开发人员之间有效的参与模型。本文提供了可以帮助组织优化其流程自动化使用的见解和建议。我们进一步为流程自动化社区内的讨论推导出新的研究问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [215] [LeanExplore: A search engine for Lean 4 declarations](https://arxiv.org/abs/2506.11085)
> *LeanExplore：一个用于Lean 4声明的搜索引擎*

*Justin Asher* | **Main category: cs.SE**

**Keywords:** Lean 4, 搜索引擎, 语义搜索, 混合排名, LLM集成

**Comment:** 16 pages, 1 figure. Project website: https://www.leanexplore.com/ ,
  Code: https://github.com/justincasher/lean-explore

> **TL;DR:** LeanExplore是一个针对Lean 4声明的搜索引擎，它通过混合排名策略实现语义搜索，并支持与LLM集成，旨在提升Lean 4工作流和AI驱动的数学研究。

**AI_Comments:** LeanExplore的创新之处在于其混合排名策略，该策略综合了语义理解、关键词匹配和声明重要性，以提供更精准的搜索结果。此外，其与大型语言模型（LLM）的集成是其重要亮点，这不仅提升了用户与Lean声明交互的方式，也为AI驱动的数学研究和定理证明代理的开发提供了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 不断扩展的Lean 4生态系统给浏览其庞大的库带来了挑战，需要一个有效的工具来查找和理解其中的声明。

**Method:** LeanExplore是一个基于混合排名策略的搜索引擎。该策略结合了多源语义嵌入模型（捕获形式化Lean代码、文档字符串、AI生成的非正式翻译和声明标题的概念意义）、BM25+（用于基于关键词的词汇相关性）和基于PageRank的分数（反映声明重要性和互联性）。它通过专用网站和Python API提供访问，数据库可下载用于自托管。此外，LeanExplore通过模型上下文协议（MCP）与LLM集成。

**Result:** LeanExplore实现了在选定的Lean 4包（包括Batteries, Init, Lean, Mathlib, PhysLean, 和 Std）中对声明进行形式化和非形式化的语义搜索。它通过网站和API提供服务，并允许用户下载数据库进行自托管。它还能够与LLM集成，支持与AI助手聊天或构建定理证明代理。

**Conclusion:** LeanExplore有望增强Lean 4工作流和AI驱动的数学研究。

> **ai_Abstract:** 本文介绍了LeanExplore，一个专为Lean 4声明设计的搜索引擎，旨在解决Lean 4生态系统库导航的挑战。LeanExplore采用创新的混合排名策略，结合了语义嵌入、BM25+和PageRank，实现了对Lean 4包中声明的语义搜索。该引擎可通过网站、Python API访问，并支持自托管。值得注意的是，LeanExplore还集成了LLM，为用户提供了与AI助手交互和开发定理证明代理的能力，从而有望显著提升Lean 4的工作效率和AI在数学研究中的应用。

> **摘要翻译:** 不断扩展的Lean 4生态系统给浏览其庞大的库带来了挑战。本文介绍了LeanExplore，一个用于Lean 4声明的搜索引擎。LeanExplore使用户能够跨选定的Lean 4包（包括Batteries、Init、Lean、Mathlib、PhysLean和Std）对声明进行语义搜索，无论是形式化的还是非形式化的。这种搜索能力由一种混合排名策略提供支持，该策略整合了来自多源语义嵌入模型（捕获形式化Lean代码、文档字符串、AI生成的非正式翻译和声明标题的概念意义）的分数、用于基于关键词的词汇相关性的BM25+以及反映声明重要性和互联性的基于PageRank的分数。该搜索引擎可通过专用网站（https://www.leanexplore.com/）和Python API（https://github.com/justincasher/lean-explore）访问。此外，数据库可以下载，允许用户自托管服务。LeanExplore通过模型上下文协议（MCP）轻松与大型语言模型（LLM）集成，使用户能够与AI助手就Lean声明进行聊天或利用搜索引擎构建定理证明代理。这项工作详细介绍了LeanExplore的架构、数据处理、功能及其增强Lean 4工作流和AI驱动数学研究的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [225] [Rethinking Technological Readiness in the Era of AI Uncertainty](https://arxiv.org/abs/2506.11001)
> *人工智能不确定性时代的技术准备就绪度再思考*

*S. Tucker Browne, Mark M. Bailey* | **Main category: cs.SE**

**Keywords:** 人工智能准备就绪, 军事系统, 技术准备就绪度, 风险评估, 可信赖AI

**Comment:** 12 pages

> **TL;DR:** 现有技术准备评估方法不足以评估军用AI系统，本文提出了一个新的AI准备就绪框架来解决此问题。

**AI_Comments:** 本文创新性地指出了现有技术准备就绪度评估在AI时代面临的局限性，并提出了一个针对AI特性的新框架。其重要性在于为军事领域AI系统的安全可靠部署提供了新的评估范式，对于国防技术管理和风险控制具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）有望彻底改变军事作战系统，但确保这些AI赋能的能力真正做好任务准备带来了新的挑战。当前的评估方法未能捕捉AI特有的关键因素，导致部署存在潜在风险。

**Method:** 本文提出了一个新的AI准备就绪框架（AI Readiness Framework），类似于传统的“技术准备就绪度”（TRL）但为AI进行了扩展，用于评估军事系统中AI组件的成熟度和可信度。该框架利用当前的数据评估工具和测试实践。

**Result:** 本文证明了所提出的AI准备就绪框架在近期实施的可行性。该框架为军事决策者提供了更清晰的洞察，以判断AI赋能的系统是否已达到性能、透明度和人机集成等必要标准，从而可以自信地部署。

**Conclusion:** 一个量身定制的AI准备就绪框架可以更好地衡量AI系统的可靠性、安全性以及是否适合作战使用，从而推进国防技术管理和风险评估领域的发展。

> **ai_Abstract:** 本文探讨了在军事领域部署AI系统时，现有技术准备就绪度评估的不足之处。作者提出了一个名为“AI准备就绪框架”的新方法，该框架扩展了传统的TRL概念，以更全面地评估AI组件在军事系统中的成熟度、可信度、可靠性、安全性和作战适用性。该框架被证明具有近期实施的可行性，旨在帮助军事决策者更自信地部署AI系统，提升国防技术管理和风险评估水平。

> **摘要翻译:** 人工智能（AI）有望彻底改变军事作战系统，但确保这些AI赋能的能力真正做好任务准备带来了新的挑战。我们认为，当前的技术准备就绪度评估未能捕捉到AI特有的关键因素，导致部署存在潜在风险。我们提出了一个新的AI准备就绪框架，用于评估军事系统中AI组件的成熟度和可信度。核心论点是，一个量身定制的框架——类似于传统的“技术准备就绪度”（TRL）但为AI进行了扩展——可以更好地衡量AI系统的可靠性、安全性以及是否适合作战使用。利用当前的数据评估工具和测试实践，我们证明了该框架在近期实施的可行性。这种结构化方法为军事决策者提供了更清晰的洞察，以判断AI赋能的系统是否已达到性能、透明度和人机集成等必要标准，从而可以自信地部署，进而推动国防技术管理和风险评估领域的发展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [237] [Improving Software Team Communication Through Social Interventions in Project Management Tools](https://arxiv.org/abs/2506.10994)
> *通过项目管理工具中的社会干预改进软件团队沟通*

*April Clarke* | **Main category: cs.SE**

**Keywords:** 软件团队沟通, 社会干预, 项目管理工具, 社交网络分析, 团队协作

**Comment:** ICSE 2025 Doctoral Track. arXiv admin note: substantial text overlap
  with arXiv:2502.01923

> **TL;DR:** 本文旨在开发基于社交网络分析的项目管理工具功能，以引导软件工程小组项目中的学生改善沟通和协作。

**AI_Comments:** 这项研究的创新点在于将社交网络分析与项目管理工具相结合，以社会干预的方式主动引导学生改进团队沟通。这对于培养未来软件工程师的软技能具有重要意义。鉴于其处于计划阶段，实际效果和普适性尚待进一步的实验验证。

<details>
  <summary>Details</summary>

**Motivation:** 高效的软件工程团队需要有效的沟通和成员之间平衡的贡献，但团队在这方面往往效率低下，这不利于项目成功。大学项目课程是学生练习这些技能的机会，但目前尚不清楚如何指导学生改进沟通和协作。

**Method:** 研究人员将首先评估社交网络分析技术在识别团队沟通改进领域方面的适用性。然后，他们将在项目管理工具中开发功能，帮助学生识别和解决这些改进领域，并在软件工程小组项目中进行评估。

**Result:** 摘要中未提及

**Conclusion:** 摘要中未提及

> **ai_Abstract:** 本文提出了一项研究计划，旨在通过在项目管理工具中引入社会干预措施来改善软件工程团队的沟通和协作。研究将利用社交网络分析来识别团队沟通中的不足之处，并在此基础上开发和评估新的工具功能，以期引导学生培养更有效的团队行为。

> **摘要翻译:** 高效的软件工程团队需要有效的沟通和团队成员之间平衡的贡献。然而，团队在这些技能上往往效率低下，这不利于项目的成功。基于项目的大学课程为学生提供了练习这些技能的机会，但我们尚未确定如何指导学生改善他们的沟通和协作。我们的目标是开发基于社交网络分析的项目管理工具功能，以引导软件工程小组项目中的学生采取有益的行为。为此，我们将首先评估社交网络分析技术在识别团队沟通改进领域方面的适用性。然后，我们将在项目管理工具中开发功能，帮助学生识别和解决这些改进领域，并在软件工程小组项目中进行评估。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [253] [Evaluating Small-Scale Code Models for Code Clone Detection](https://arxiv.org/abs/2506.10995)
> *评估小型代码模型用于代码克隆检测*

*Jorge Martinez-Gil* | **Main category: cs.SE**

**Keywords:** 代码克隆检测, 小型代码模型, 软件维护, 代码重构, 深度学习

**Comment:** 20 pages

> **TL;DR:** 小型代码模型在代码克隆检测中表现良好，但仍存在一些挑战性案例。

**AI_Comments:** 该论文通过系统评估小型代码模型在代码克隆检测中的性能，为该领域提供了深刻见解，揭示了它们的有效性和局限性。识别出持续存在的挑战性案例，突出了未来研究在区分超越结构相似性的功能等价性方面的方向。

<details>
  <summary>Details</summary>

**Motivation:** 代码克隆检测对软件维护和代码重构至关重要，但仍存在未解决的案例，尤其是在结构相似性不反映功能等价性时。鉴于最近代码模型的潜力，需要评估新引入的小型代码模型。

**Method:** 本研究系统地衡量了CodeBERT、GraphCodeBERT、Salesforce T5、UniXCoder、PLBART和Polycoder等几种新引入的小型代码模型在将代码对分类为克隆或非克隆方面的性能。评估基于BigCloneBench、CodeJam、Karnalim、POJ104和PoolC五个数据集，并使用准确率、精确率、召回率和F1分数等标准指标。

**Result:** 大多数模型在标准指标上表现良好。然而，一小部分克隆仍然难以检测，特别是当代码看起来相似但执行不同操作时。

**Conclusion:** 小型代码模型在代码克隆检测中表现出有效性，但对于代码结构相似但功能不同等挑战性案例，仍有待改进。

> **ai_Abstract:** 本论文评估了CodeBERT、GraphCodeBERT、Salesforce T5、UniXCoder、PLBART和Polycoder等几种小型代码模型在代码克隆检测中的性能。研究使用了BigCloneBench、CodeJam、Karnalim、POJ104和PoolC五个数据集，并采用标准指标进行评估，结果显示大多数模型表现良好。然而，一些代码看起来相似但功能不同的挑战性案例仍然难以检测。

> **摘要翻译:** 检测代码克隆与软件维护和代码重构相关。这项挑战仍然存在未解决的案例，主要是在结构相似性不反映功能等价性时，尽管最近的代码模型显示出潜力。因此，本研究旨在系统地衡量几种新引入的小型代码模型在将代码对分类为克隆或非克隆方面的性能。评估基于五个数据集：BigCloneBench、CodeJam、Karnalim、POJ104和PoolC，以及六个代码模型：CodeBERT、GraphCodeBERT、Salesforce T5、UniXCoder、PLBART和Polycoder。大多数模型在标准指标（包括准确率、精确率、召回率和F1分数）上表现良好。然而，一小部分克隆仍然难以检测，特别是当代码看起来相似但执行不同操作时。说明我们方法的源代码可在以下网址获取：https://github.com/jorge-martinez-gil/small-code-models

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [256] [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org/abs/2506.11059)
> *CodeMirage：一个用于检测生产级大型语言模型生成的和转述的源代码的多语言基准*

*Hanxi Guo, Siyuan Cheng, Kaiyuan Zhang, Guangyu Shen, Xiangyu Zhang* | **Main category: cs.SE**

**Keywords:** AI生成代码检测, 代码抄袭, 多语言基准, 大型语言模型, CodeMirage

**Comment:** 

> **TL;DR:** CodeMirage是一个多语言基准，用于检测LLM生成的和转述的源代码，涵盖10种语言和10个生产级LLM的输出，并评估了现有检测器。

**AI_Comments:** CodeMirage的创新之处在于其前所未有的综合性，涵盖了广泛的编程语言、多样化的代码类型（原始和转述）以及最新的生产级LLMs输出。这使得它能够更真实地反映现实世界的检测挑战，对于推动AI生成代码检测技术的发展具有重要意义。该基准的发布有望加速鲁棒和通用检测器的研发，从而有效缓解LLM代码生成带来的潜在风险。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的代码带来了抄袭、许可证违规和不安全程序传播等风险，因此需要强大的AI生成代码检测器。然而，现有基准存在局限性，例如语言覆盖范围有限和依赖能力较弱的生成模型。

**Method:** 本文提出了CodeMirage，一个全面的基准，具有三大改进：1) 涵盖10种常用编程语言；2) 包含原始和转述的代码样本；3) 整合了来自6家主要提供商的10个最先进的生产级LLM的输出。该研究使用CodeMirage评估了四种方法范式下的十个代表性检测器，并在四种现实评估配置下报告了结果。

**Result:** 分析揭示了九个关键发现，揭示了当前检测器的优缺点，并确定了未来工作的关键挑战。

**Conclusion:** CodeMirage提供了一个严格而实用的测试平台，以推动鲁棒和通用AI生成代码检测器的发展。

> **ai_Abstract:** 本文介绍了CodeMirage，一个针对AI生成和转述源代码检测的综合多语言基准。鉴于LLMs生成代码带来的潜在风险，该基准旨在弥补现有检测基准的不足。CodeMirage涵盖10种编程语言，包含原始和转述代码，并使用了来自10个生产级LLMs（包括推理和非推理模型）的输出。研究利用CodeMirage评估了十个代表性检测器，并揭示了九个关键发现，明确了当前检测器的优缺点及未来挑战，为AI生成代码检测器的发展提供了严谨的测试平台。

> **摘要翻译:** 大型语言模型（LLMs）已成为现代软件开发不可或缺的一部分，产生了大量的AI生成源代码。虽然这些模型提高了编程效率，但其滥用带来了关键风险，包括代码抄袭、许可证违规和不安全程序的传播。因此，对AI生成代码的稳健检测至关重要。为了支持此类检测器的开发，一个能够反映真实世界条件的综合基准至关重要。然而，现有基准存在不足——大多数只涵盖有限的编程语言，并且依赖能力较弱的生成模型。在本文中，我们提出了CodeMirage，一个通过三项重大进展解决这些限制的综合基准：(1) 它涵盖了十种广泛使用的编程语言，(2) 包含原始和转述的代码样本，以及 (3) 整合了来自六个主要提供商的十个最先进的生产级LLM的输出，包括推理和非推理模型。使用CodeMirage，我们评估了四种方法范式下的十个代表性检测器，并在四种现实评估配置下报告了结果，使用三种互补的指标。我们的分析揭示了九个关键发现，揭示了当前检测器的优缺点，并确定了未来工作的关键挑战。我们相信CodeMirage提供了一个严格而实用的测试平台，以推动鲁棒和通用AI生成代码检测器的发展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [259] [A Theory-driven Interpretation and Elaboration of Verification and Validation](https://arxiv.org/abs/2506.10997)
> *验证与确认的理论驱动解释与阐述*

*Hanumanthrao Kannan, Alejandro Salado* | **Main category: cs.SE**

**Keywords:** 验证与确认, 动态认知模态逻辑, 系统工程, 知识构建, 形式化理论

**Comment:** 

> **TL;DR:** 本文提出了一种基于动态认知模态逻辑的验证与确认（V&V）形式化理论，旨在澄清传统V&V实践中的模糊性，并提升系统工程方法的精度和一致性。

**AI_Comments:** 本文的创新之处在于将验证与确认（V&V）置于知识构建的公理基础上，并首次引入动态认知模态逻辑来形式化V&V过程。这种理论驱动的方法为解决传统V&V实践中的模糊性提供了严谨的框架，有望显著提升系统工程方法的精确性和一致性。其重要性在于为V&V的理解和应用提供了坚实的理论基础，对于工程知识的生成和管理具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 传统验证与确认（V&V）实践中存在模糊性，需要一个结构化的框架来提高系统工程方法的精度和一致性。本文旨在为V&V提供一个形式化基础。

**Method:** 本文在系统工程领域内，基于V&V是知识构建活动这一公理，运用动态认知模态逻辑，发展了验证与确认的精确定义，并阐明了它们在确认和情境化系统知识中的作用。该理论形式化了认知状态、证据和推理过程之间的相互作用，从而能够推导出阐明V&V概念基础的定理。

**Result:** 本文提供了一个V&V的形式化基础，解决了传统V&V实践中的模糊性，并提供了一个结构化框架来增强系统工程方法的精度和一致性。

**Conclusion:** 该研究通过提供一个形式化的V&V理论，加深了对V&V作为工程知识生成关键组成部分的理解，对学术研究和实际应用都具有重要意义。

> **ai_Abstract:** 本文提出了一种基于动态认知模态逻辑的验证与确认（V&V）形式化理论，将V&V视为知识构建活动。该理论明确定义了V&V在系统工程中确认和情境化知识的作用，并形式化了认知状态、证据和推理的相互作用，从而推导出相关定理。这项工作旨在解决传统V&V实践的模糊性，提供一个结构化框架以提高精度和一致性，对学术界和实践应用均有重要启示。

> **摘要翻译:** 本文在系统工程领域内，提出了一种验证与确认（V&V）的形式化理论，该理论以V&V本质上是知识构建活动这一公理为基础。我们使用动态认知模态逻辑，发展了验证与确认的精确定义，阐明了它们在确认和情境化系统知识中的作用。该理论形式化了认知状态、证据和推理过程之间的相互作用，从而能够推导出阐明V&V概念基础的定理。通过提供一个形式化基础，这项工作解决了传统V&V实践中的模糊性，提供了一个结构化的框架来增强系统工程方法的精度和一致性。所获得的见解对学术研究和实际应用都具有重要意义，促进了对V&V作为工程知识生成关键组成部分的更深理解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [267] [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org/abs/2506.11022)
> *迭代AI代码生成中的安全退化——对悖论的系统分析*

*Shivani Shukla, Himanshu Joshi, Romilla Syed* | **Main category: cs.SE**

**Keywords:** AI代码生成, 安全漏洞, LLM, 迭代改进, 人工验证

**Comment:** Keywords - Large Language Models, Security Vulnerabilities,
  AI-Generated Code, Iterative Feedback, Software Security, Secure Coding
  Practices, Feedback Loops, LLM Prompting Strategies

> **TL;DR:** 研究发现，LLM迭代生成代码会显著增加安全漏洞，挑战了迭代改进代码安全性的假设，强调了人工验证的重要性。

**AI_Comments:** 该研究揭示了一个重要的“悖论”：AI迭代改进代码反而可能引入更多安全漏洞，这对于依赖LLM进行代码开发的实践者具有重要的警示意义。其受控实验设计严谨，数据支持有力。强调人工干预的重要性，为未来AI辅助开发的安全实践提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在代码生成中的快速应用改变了软件开发，但很少关注安全漏洞如何通过迭代LLM反馈演变。本文旨在分析AI生成代码中的安全退化。

**Method:** 通过一项受控实验，使用四种不同的提示策略，对400个代码样本进行了40轮“改进”的分析。

**Result:** 结果显示，仅经过五次迭代，关键漏洞增加了37.6%，并且不同的提示方法出现了独特的漏洞模式。

**Conclusion:** 研究结果挑战了迭代LLM优化能提高代码安全性的假设，强调了人工专业知识在循环中的重要作用。论文提出了缓解风险的实用指南，强调在LLM迭代之间进行强有力的人工验证的必要性，以防止在看似有益的代码“改进”过程中引入新的安全问题。

> **ai_Abstract:** 本研究系统分析了迭代AI代码生成中的安全退化现象。通过对400个代码样本进行多轮LLM“改进”实验，发现关键安全漏洞在短短五次迭代后显著增加，且不同提示策略导致不同的漏洞模式。这挑战了LLM迭代能提升代码安全性的普遍认知，强调了人工验证在AI辅助代码开发流程中不可或缺的关键作用，并提出了相应的风险缓解指南。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成中的快速采用已经改变了软件开发，但很少有人关注安全漏洞如何通过迭代的LLM反馈演变。本文通过一项受控实验，使用四种不同的提示策略，对400个代码样本进行了40轮“改进”的分析，研究了AI生成代码中的安全退化。我们的发现表明，仅经过五次迭代，关键漏洞增加了37.6%，并且在不同的提示方法中出现了独特的漏洞模式。这一证据挑战了迭代LLM优化能够提高代码安全性的假设，并强调了人工专业知识在循环中的重要作用。我们为开发人员提出了缓解这些风险的实用指南，强调在LLM迭代之间需要进行强有力的人工验证，以防止在看似有益的代码“改进”过程中，悖论性地引入新的安全问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [269] [Evaluating LLMs for Visualization Tasks](https://arxiv.org/abs/2506.10996)
> *评估大型语言模型在可视化任务中的表现*

*Saadiq Rauf Khan, Vinit Chandak, Sougata Mukherjea* | **Main category: cs.SE**

**Keywords:** LLMs, 可视化, 代码生成, 信息可视化, 评估

**Comment:** 

> **TL;DR:** 本文评估了大型语言模型（LLMs）在信息可视化任务中的能力，发现它们可以生成可视化代码并回答相关问题，但也存在局限性。

**AI_Comments:** 该研究是探索LLMs在信息可视化这一实用领域应用的重要一步，它不仅展示了LLMs的潜能，也清晰地指出了其当前局限性。这对于指导未来LLMs与数据可视化工具的融合与发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 信息可视化被用于从复杂数据中获取洞察，而大型语言模型（LLMs）近期在许多任务中表现出色。因此，研究LLMs在可视化任务中的能力变得有意义。

**Method:** 研究通过展示不同流行LLMs基于简单提示生成可视化代码的能力，并分析LLMs通过回答简单问题来理解常见可视化的能力来评估其表现。

**Result:** 研究表明LLMs可以为一些可视化生成代码，并回答关于它们的问题。然而，LLMs也存在一些局限性。

**Conclusion:** 本研究的见解可以用于改进大型语言模型（LLMs）和信息可视化系统。

> **ai_Abstract:** 本文评估了大型语言模型（LLMs）在信息可视化任务中的应用潜力。研究通过测试LLMs生成可视化代码和理解常见可视化的能力，发现它们能够执行这些任务，但也存在显著局限性。这些发现为未来改进LLMs和信息可视化系统提供了宝贵见解。

> **摘要翻译:** 信息可视化已被用于从复杂数据中获取洞察。近年来，大型语言模型（LLMs）在许多任务中表现出色。在本文中，我们展示了不同流行LLMs基于简单提示生成可视化代码的能力。我们还通过回答简单问题，分析了LLMs理解一些常见可视化的能力。我们的研究表明，LLMs可以为一些可视化生成代码，并回答关于它们的问题。然而，LLMs也存在一些局限性。我们相信我们的见解可以用于改进LLMs和信息可视化系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [294] [Towards Automated Formal Verification of Backend Systems with LLMs](https://arxiv.org/abs/2506.10998)
> *利用大型语言模型实现后端系统自动化形式化验证*

*Kangping Xu, Yifan Luo, Yang Yuan, Andrew Chi-Chih Yao* | **Main category: cs.SE**

**Keywords:** 形式化验证, 大型语言模型, 后端系统, 软件测试, 自动化

**Comment:** 

> **TL;DR:** 提出一个利用LLM进行后端系统形式化验证的框架，可自动化一半测试工作并降低成本。

**AI_Comments:** 该论文提出了一种创新的方法，将形式化验证与大型语言模型结合，旨在解决传统自动化测试的局限性。其核心创新在于将高级语言代码转换为形式化表示，并利用LLM进行定理证明，从而实现更高程度的自动化和可靠性。其重要性在于显著提高了软件测试的效率和准确性，尤其是在后端系统复杂性日益增加的背景下。这项工作为未来的AI辅助软件开发和验证开辟了新的途径，但其对LLM证明器准确性和鲁棒性的依赖可能是一个潜在的局限性，特别是在面对极其复杂或模糊的业务逻辑时。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化测试方法存在测试局部性、缺乏通用可靠性、以及业务逻辑盲点等关键局限性，难以匹敌人类工程师的能力。

**Method:** 提出一个新颖框架，利用函数式编程和类型系统将Scala后端代码转换为形式化的Lean表示。该流程自动生成指定API和数据库操作预期行为的定理，并使用基于LLM的证明器进行验证。当定理被证明时，逻辑被保证正确；若否定被证明，则确认存在错误；若两者皆不能证明，则需人工干预。

**Result:** 该方法能够形式化验证超过50%的测试需求，表明可自动化一半测试工程师的工作量。每个API的平均成本仅为2.19美元，比手动测试更具成本效益且易于通过并行执行扩展。

**Conclusion:** 结果表明这是一个可扩展的、AI驱动的软件测试的有前景方向，随着模型的不断进步，有潜力大大提高工程生产力。

> **ai_Abstract:** 本文提出一个新颖的框架，利用函数式编程和类型系统将Scala后端代码转换为形式化的Lean表示，并结合LLM证明器实现后端系统的自动化形式化验证。该方法能自动生成和验证API及数据库操作的预期行为定理，有效发现错误或确保正确性。实验表明，该方法可自动化超过50%的测试工作，且成本效益高，为AI驱动的软件测试提供了新的方向。

> **摘要翻译:** 软件测试在确保系统按预期运行方面发挥着关键作用。然而，现有的自动化测试方法由于测试局部性、缺乏通用可靠性以及业务逻辑盲点等关键局限性，难以与人类工程师的能力相匹配。在这项工作中，我们提出了一个新颖的框架，该框架利用函数式编程和类型系统将Scala后端代码转换为形式化的Lean表示。我们的流程自动生成指定API和数据库操作预期行为的定理，并使用基于大型语言模型（LLM）的证明器来验证它们。当一个定理被证明时，相应的逻辑被保证是正确的，并且不需要进一步的测试。如果定理的否定被证明，则确认存在一个错误。在两者都无法证明的情况下，需要人工干预。我们对实际的后端系统评估了我们的方法，发现它能够形式化验证超过50%的测试需求，这表明一半的测试工程师工作量可以实现自动化。此外，每个API的平均成本仅为2.19美元，基于LLM的验证比手动测试显著更具成本效益，并且可以通过并行执行轻松扩展。我们的结果表明，这是一个可扩展的、AI驱动的软件测试的有前景方向，随着模型的不断进步，有潜力大大提高工程生产力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [307] [Automated Validation of COBOL to Java Transformation](https://arxiv.org/abs/2506.10999)
> *COBOL到Java转换的自动化验证*

*Atul Kumar, Diptikalyan Saha, Toshikai Yasue, Kohichi Ono, Saravanan Krishnan, Sandeep Hans, Fumiko Satoh, Gerald Mitchell, Sachin Kumar* | **Main category: cs.SE**

**Keywords:** COBOL, Java, 代码转换, 自动化验证, 符号执行

**Comment:** arXiv admin note: text overlap with arXiv:2504.10548

> **TL;DR:** 该研究提出一个框架和工具，通过符号执行生成测试用例来自动化验证LLM将COBOL代码转换为Java代码的语义等效性，并可用于代码修复和模型改进。

**AI_Comments:** 该论文的创新点在于利用符号执行来自动化生成测试用例，以验证LLM进行代码转换的正确性和语义等效性。这解决了当前LLM在代码翻译领域面临的核心挑战之一——即生成代码的可信度问题。对于企业遗留系统现代化改造而言，确保自动转换代码的正确性至关重要，因此这项工作具有重要的实际应用价值。其反馈机制也为未来LLM的改进提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于大语言模型（LLM）的生成式AI技术使得将COBOL等遗留语言代码转换为Java等现代语言成为可能，但LLM自动转换产生的代码并不可靠，无法确保其正确性。

**Method:** 提出一个框架和工具，用于验证COBOL与翻译后的Java代码的等效性。具体方法是：开发基于符号执行的测试生成技术，自动为源COBOL程序生成单元测试，并模拟外部资源调用；然后为Java代码生成等效的JUnit测试用例，并进行等效模拟，运行这些测试以检查原始程序和翻译程序之间的语义等效性。

**Result:** 所提出的框架和工具能够帮助验证COBOL到Java转换的等效性。其结果还可以帮助修复代码中存在的问题，并向AI模型提供反馈以进行改进。

**Conclusion:** 通过基于符号执行的测试生成和语义等效性检查，可以自动化验证LLM驱动的COBOL到Java代码转换的正确性，从而提高转换结果的可靠性，并有助于代码修复和模型改进。

> **ai_Abstract:** 本文提出了一个框架和工具，旨在解决大语言模型（LLM）在COBOL到Java代码转换中生成代码可靠性不足的问题。该方法通过基于符号执行自动为COBOL程序生成单元测试，并为翻译后的Java代码生成等效的JUnit测试，然后运行这些测试来验证两种语言代码之间的语义等效性。该工具不仅能够验证转换的正确性，还能辅助代码修复并为LLM提供改进反馈。

> **摘要翻译:** 最近，基于大语言模型（LLM）的生成式AI技术的进步使得将企业级代码从COBOL等遗留语言翻译到Java或Python等现代语言成为可能。虽然基于LLM的自动转换结果令人鼓舞，但不能完全信任所生成的代码能够正确翻译原始代码。我们提出了一个框架和一个工具来帮助验证COBOL和翻译后的Java代码的等效性。如果存在一些问题，结果还可以帮助修复代码，并向AI模型提供反馈以进行改进。我们开发了一种基于符号执行的测试生成方法，可以自动为源COBOL程序生成单元测试，该方法还模拟了外部资源调用。我们生成了与COBOL等效的JUnit测试用例，并进行了等效模拟，然后运行它们以检查原始程序和翻译程序之间的语义等效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [316] [Ever-Improving Test Suite by Leveraging Large Language Models](https://arxiv.org/abs/2506.11000)
> *利用大型语言模型持续改进测试套件*

*Ketai Qiu* | **Main category: cs.SE**

**Keywords:** 测试套件增强, 大型语言模型, 软件测试, E-Test, 生产行为

**Comment:** Accepted by 33rd ACM International Conference on the Foundations of
  Software Engineering (FSE Companion '25), June 23--28, 2025, Trondheim,
  Norway

> **TL;DR:** E-Test是一种利用大型语言模型增量式地增强测试套件的方法，它能识别生产环境中未被测试的行为并优化测试套件，性能优于现有方法。

**AI_Comments:** E-Test的创新之处在于其首次将大型语言模型应用于增量式测试套件增强，以识别和覆盖生产环境中未被测试的行为。这对于维护长期软件系统的质量具有重要意义，因为它能帮助测试套件随着软件的实际使用而持续改进。其局限性可能在于对LLM能力的依赖以及LLM生成测试用例的质量和效率。

<details>
  <summary>Details</summary>

**Motivation:** 为了保持长期软件系统的质量，使用反映软件系统实际使用情况的测试用例来增强测试套件至关重要。本文旨在解决如何增量式地增强测试套件，以覆盖生产环境中出现但尚未被测试的行为。

**Method:** 本文提出了E-Test方法，该方法利用大型语言模型（LLMs）来识别已测试、未测试和易出错的单元执行场景，并相应地增强测试套件。E-Test能够增量式地用测试用例增强测试套件，这些测试用例能够测试在生产环境中出现但尚未被测试的行为。

**Result:** 实验评估表明，E-Test在识别测试不足的行为和优化测试套件方面优于主要的现有最先进方法。

**Conclusion:** E-Test通过利用大型语言模型，能够有效地识别并弥补测试套件的不足，从而持续改进测试套件的质量和覆盖率，优于现有技术。

> **ai_Abstract:** 本文提出了一种名为E-Test的方法，旨在通过利用大型语言模型（LLMs）增量式地增强测试套件。E-Test能够识别并针对生产环境中出现但尚未被测试的行为生成新的测试用例，从而优化测试套件。实验结果表明，E-Test在识别测试不足的行为和优化测试套件方面，其性能优于当前最先进的方法。

> **摘要翻译:** 通过反映软件系统实际使用情况的测试用例来增强测试套件对于维持长期软件系统的质量至关重要。在本文中，我们提出了E-Test，这是一种增量式地用测试用例增强测试套件的方法，这些测试用例能够测试在生产环境中出现但尚未被测试的行为。E-Test利用大型语言模型来识别已测试、未测试和易出错的单元执行场景，并相应地增强测试套件。我们的实验评估表明，E-Test在识别测试不足的行为和优化测试套件方面优于主要的现有最先进方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [334] [Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer](https://arxiv.org/abs/2506.11002)
> *撰写有效实证软件工程论文的注意事项：一份有主见的入门指南*

*Roberto Verdecchia, Justus Bogner* | **Main category: cs.SE**

**Keywords:** 实证软件工程, 科学写作, 论文写作, 指南, 学术出版

**Comment:** 

> **TL;DR:** 一份关于如何撰写实证软件工程论文的实用指南，旨在帮助学生和研究人员提高写作质量。

**AI_Comments:** 这篇论文的创新之处在于其“有主见”的定位，它不追求普遍客观性，而是基于作者的个人成功经验提供实用建议，这在缺乏明确写作指导的实证软件工程领域显得尤为重要。其价值在于填补了该领域在写作实践指导方面的空白，特别是对学生群体具有直接的教育意义。

<details>
  <summary>Details</summary>

**Motivation:** 实证软件工程（ESE）研究中良好的科学写作实践很少被讨论和记录，但它们却是会议和期刊的隐性或显性评估标准。许多人对撰写ESE论文感到不知所措或困惑。

**Method:** 作者提供了一份实用的、以教育为先的文档，其中包含主观且个人化的写作建议集合。

**Result:** 形成了一份关于撰写实证软件工程论文的指南。

**Conclusion:** 作者希望这份指南能帮助其他人在撰写实证软件工程论文时取得成功，就像对他们自己一样。

> **ai_Abstract:** 本文旨在为实证软件工程（ESE）领域的研究人员和学生提供一份关于撰写有效科学论文的实用指南。鉴于ESE写作实践缺乏公开讨论，作者分享了其主观但经验证有效的写作建议，以帮助读者应对论文写作的挑战，并提高论文质量，尤其针对初学者和经验不足的作者。

> **摘要翻译:** 尽管有些人已经掌握，但在实证软件工程（ESE）研究中，良好的科学写作实践似乎很少被讨论和记录。尽管如此，这些实践却是典型软件工程会议和期刊的隐性甚至显性评估标准。在这份务实、教育优先的文档中，我们旨在为那些可能因撰写ESE论文而感到不知所措或困惑的人提供指导，同时也为那些更有经验但仍可能觉得这份有主见的写作建议集有用的读者提供帮助。我们撰写本文时主要考虑的读者是我们自己的本科生、硕士生和博士生，以及其他人的学生。因此，我们记录的建议反映了撰写ESE论文的主观和个人愿景。我们绝不声称自己是完全客观、普遍适用或代表整个学科的。话虽如此，以这种方式撰写论文对我们来说迄今为止效果很好。我们希望这份指南至少能部分地为其他人带来同样的效果。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [339] [EmbedAgent: Benchmarking Large Language Models in Embedded System Development](https://arxiv.org/abs/2506.11003)
> *EmbedAgent：评估大型语言模型在嵌入式系统开发中的表现*

*Ruiyang Xu, Jialun Cao, Mingyuan Wu, Wenliang Zhong, Yaojie Lu, Ben He, Xianpei Han, Shing-Chi Cheung, Le Sun* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 嵌入式系统, 基准测试, EmbedAgent, Embedbench

**Comment:** 21 pages

> **TL;DR:** 本文介绍了EmbedAgent和Embedbench，用于评估大型语言模型在嵌入式系统开发中的能力，揭示了当前局限性并提出了改进策略。

**AI_Comments:** 这篇论文的创新之处在于首次创建了专用于评估大型语言模型在复杂嵌入式系统开发领域能力的基准测试Embedbench，有效地弥合了数字系统与物理系统之间的鸿沟。它揭示了当前LLM即使在看似简单的任务中也存在的关键局限性，并深入分析了其失败原因（例如，未能充分利用预训练知识、过度思考）。论文提出的改进策略具有很强的实用性，并展现出积极的效果，为未来提升LLM在该专业领域的能力指明了方向。其重要性在于为LLM在关键工程领域的应用奠定了评估基础，并指明了明确的改进路径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在各种任务中展现出潜力，但很少有基准测试评估它们在嵌入式系统开发中的能力。目前缺乏能够测试LLM在连接数字和物理系统任务中的综合评估方法。

**Method:** 本文引入了EmbedAgent范式，旨在模拟嵌入式系统开发中的真实世界角色（如程序员、架构师、集成商），以测试LLM的能力。为此，提出了Embedbench，这是首个针对嵌入式系统编程、电路设计和跨平台迁移的综合基准测试，包含126个案例，涵盖9种电子元件和3个硬件平台。研究对10个主流LLM进行了广泛实验。基于实验结果，提出了检索增强生成和编译器反馈两种策略来提升LLM性能。

**Result:** 实验发现，即使案例简单，DeepSeek-R1在提供原理图信息时通过率为55.6%，在生成原理图时通过率为50.0%。在跨平台迁移任务中，LLM在Raspberry Pi Pico上使用MicroPython表现较好（最佳模型通过率73.8%），但在ESP-IDF上表现不佳（最佳模型通过率29.4%）。通用聊天LLM（如DeepSeek-V3）常未能利用相关预训练知识，而推理LLM则倾向于过度思考。提出的检索增强生成和编译器反馈策略显著提升了性能：Deepseek-R1在提供正确原理图时通过率达到65.1%，未提供时为53.1%；Arduino到ESP32迁移任务的准确性从21.4%提高到27.8%。

**Conclusion:** 大型语言模型在嵌入式系统开发任务中，尤其是在原理图生成和特定跨平台迁移（如ESP-IDF）等复杂领域，存在显著局限性。通用型和推理型LLM表现出特定的缺陷。然而，检索增强生成和编译器反馈等策略能够显著提升LLM在该领域的性能，这预示着未来改进的潜力。

> **ai_Abstract:** 本文提出了EmbedAgent范式和Embedbench基准测试，旨在首次全面评估大型语言模型（LLMs）在嵌入式系统开发（包括编程、电路设计和跨平台迁移）中的能力。通过对10个主流LLM的广泛实验，研究揭示了LLM在该领域的显著局限性，尤其是在原理图生成和特定跨平台任务上，并指出通用型和推理型LLM存在的具体问题。为解决这些问题，论文提出了检索增强生成和编译器反馈两种策略，并证明它们能有效提升LLM的性能。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中展现出潜力，但很少有基准测试评估它们在嵌入式系统开发中的能力。在本文中，我们引入了EmbedAgent，一个旨在模拟嵌入式系统开发中真实世界角色的范式，例如嵌入式系统程序员、架构师和集成商。这种范式使得LLM能够在连接数字和物理系统的任务中进行测试，从而对其能力进行更全面的评估。为了评估LLM在这些任务上的表现，我们提出了Embedbench，这是第一个用于嵌入式系统编程、电路设计和跨平台迁移的综合基准测试。Embedbench包含126个案例，涵盖3个硬件平台上的9个电子元件。通过对10个主流LLM进行广泛实验，我们发现了几个关键发现。令人惊讶的是，尽管案例很简单，DeepSeek-R1在提供原理图信息时仅达到55.6%的pass@1率，而在要求其自身生成原理图时则为50.0%。在跨平台迁移任务中，LLM在使用MicroPython在Raspberry Pi Pico上表现相对较强（最佳模型达到73.8%的pass@1），但在ESP-IDF上表现不佳，最佳模型仅达到29.4%的pass@1。有趣的是，我们观察到像DeepSeek-V3这样的通用聊天LLM通常未能利用该领域相关的预训练知识，而推理LLM则倾向于过度思考并忽略预训练期间的有效知识。基于这些见解，我们提出了两种策略：检索增强生成和编译器反馈——以提高LLM的性能。这些策略带来了显著的改进，Deepseek-R1在提供正确原理图的情况下达到65.1%的pass@1，在没有提供的情况下达到53.1%。此外，Arduino到ESP32迁移任务的准确性从21.4%提高到27.8%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [347] [Automated Extraction and Analysis of Developer's Rationale in Open Source Software](https://arxiv.org/abs/2506.11005)
> *开源软件中开发者理由的自动化提取与分析*

*Mouna Dhaouadi, Bentley Oakes, Michalis Famelis* | **Main category: cs.SE**

**Keywords:** 开发者理由, 自动化提取, 开源软件, 决策冲突, 大型语言模型

**Comment:** 

> **TL;DR:** 提出一种自动化方法，用于从开源软件中提取和分析开发者的决策理由，以检测潜在冲突和设计侵蚀，并通过实验验证了其可行性和有效性。

**AI_Comments:** 这项研究提出了一种新颖的自动化方法来解决开源软件开发中理解历史决策和避免冲突的关键挑战。其创新性在于结合了现有架构Kantara、预训练模型和LLMs，并专注于检测设计侵蚀。该方法对于提高开源项目维护效率和代码质量具有重要意义，尤其是在大型复杂项目中。

<details>
  <summary>Details</summary>

**Motivation:** 开源软件贡献者需要深入理解项目历史以做出连贯决策，但检查相关变更需要大量手动工作，且现有研究缺乏自动化机制来暴露和分析决策冲突。

**Method:** 提出一种基于Kantara（现有高层理由提取和管理架构）的自动化理由分析方法。该方法利用预训练模型和大型语言模型，并包含基于结构的机制来检测可能导致项目设计侵蚀的推理冲突和问题。

**Result:** 在Linux内核的OOM-Killer模块上验证了提取和分析方法的可行性，并将其推广到其他五个活跃的开源项目。结果证实，该自动化方法能够以合理的性能支持理由分析，发现有趣的关系并检测潜在冲突和推理问题。还展示了决策和理由句自动化提取的有效性及其推广到其他开源项目的前景。

**Conclusion:** 提出的自动化方法可以帮助开源软件开发者主动解决隐藏问题，确保新变更与过去的决策不冲突。

> **ai_Abstract:** 本文提出了一种自动化方法，用于从开源软件中提取和分析开发者的决策理由，旨在帮助贡献者理解项目历史并避免与过去决策冲突。该方法基于Kantara架构，利用预训练模型和大型语言模型，并结合结构化机制来检测可能导致设计侵蚀的推理冲突。通过在Linux内核和其他开源项目上的实验，验证了该方法在支持理由分析、发现关系和检测潜在问题方面的可行性和有效性，并展示了其泛化能力。

> **摘要翻译:** 开源软件的贡献者必须深入理解项目的历史，才能做出与过去推理不冲突的连贯决策。然而，检查与拟议贡献相关的所有变更需要大量手动工作，并且之前的研究尚未产生一种自动化机制来揭示和分析这些冲突。在本文中，我们提出了一种基于现有高层理由提取和管理架构Kantara实例的自动化理由分析方法。我们的实现利用了预训练模型和大型语言模型，并包含了基于结构的机制来检测可能随时间推移导致项目设计侵蚀的推理冲突和问题。我们使用Linux内核项目的OOM-Killer模块展示了我们提取和分析方法的可行性，并研究了该方法对其他五个高度活跃的开源项目的泛化能力。结果证实，我们的自动化方法能够以合理的性能支持理由分析，通过发现有趣的关系并检测潜在冲突和推理问题。我们还展示了决策和理由句自动化提取的有效性以及将其推广到其他开源项目的前景。因此，这种自动化方法可以被开源软件开发者用来主动解决隐藏问题，并确保新的变更与过去的决策不冲突。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [355] [A Step-by-Step Guide to Creating a Robust Autonomous Drone Testing Pipeline](https://arxiv.org/abs/2506.11400)
> *构建稳健自主无人机测试流程的分步指南*

*Yupeng Jiang, Yao Deng, Sebastian Schroder, Linfeng Liang, Suhaas Gambhir, Alice James, Avishkar Seth, James Pirrie, Yihao Zhang, Xi Zheng* | **Main category: cs.SE**

**Keywords:** 自主无人机, 测试流程, SIL, HIL, 真实世界测试

**Comment:** 

> **TL;DR:** 本文提供了一个分步指南，用于建立一个稳健的自主无人机测试流程，涵盖了软件在环（SIL）、硬件在环（HIL）、受控真实世界和现场测试，以确保其安全性、可靠性和效率。

**AI_Comments:** 本文针对自主无人机从原型向实际应用过渡的关键阶段，提出了一个实用且全面的测试流程。其创新之处在于将传统的SIL、HIL、真实世界测试与新兴的神经符号AI、LLM和数字孪生技术相结合，为未来的无人机测试指明了方向。该指南结构清晰，对开发者和研究人员具有很高的指导价值，有助于提高无人机系统的安全性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 随着自主无人机从研究原型向任务关键型平台过渡，确保这些系统的安全性、可靠性和效率至关重要。本文旨在提供一个稳健的测试流程来解决这一需求。

**Method:** 本文提出了一个分步指南，建立了稳健的自主无人机测试流程，涵盖了四个关键阶段：软件在环（SIL）仿真测试、硬件在环（HIL）测试、受控真实世界测试和现场测试。通过标记点自主着陆系统等实际例子，演示了如何系统地验证无人机系统行为、识别集成问题并优化性能。此外，还强调了塑造无人机测试未来的新兴趋势，包括神经符号和大型语言模型的集成、创建协同仿真环境以及数字孪生驱动的仿真测试技术。

**Result:** 通过遵循本文提出的测试流程，开发者和研究人员可以实现全面的验证，最大程度地降低部署风险，并为自主无人机在真实世界中的安全可靠运行做好准备。它展示了如何系统地验证无人机系统行为、识别集成问题并优化性能。

**Conclusion:** 遵循本文提出的分步测试流程，可以帮助开发者和研究人员实现自主无人机的全面验证，最小化部署风险，并使其为安全可靠的真实世界操作做好准备。

> **ai_Abstract:** 本文提供了一个构建稳健自主无人机测试流程的分步指南，旨在确保无人机的安全性、可靠性和效率。该流程涵盖了软件在环（SIL）、硬件在环（HIL）、受控真实世界和现场测试四个关键阶段。论文通过实际案例演示了如何系统地验证系统行为、识别集成问题和优化性能。此外，还探讨了神经符号、大型语言模型集成、协同仿真和数字孪生等新兴测试趋势，旨在帮助开发者和研究人员实现全面验证并降低部署风险。

> **摘要翻译:** 自主无人机正在迅速重塑从空中运送和基础设施检查到环境监测和灾害响应等各个行业。随着这些系统从研究原型过渡到任务关键型平台，确保其安全性、可靠性和效率至关重要。本文提出了一个建立稳健自主无人机测试流程的分步指南，涵盖了每个关键阶段：软件在环（SIL）仿真测试、硬件在环（HIL）测试、受控真实世界测试和现场测试。通过标记点自主着陆系统等实际例子，我们演示了如何系统地验证无人机系统行为、识别集成问题并优化性能。此外，我们强调了塑造无人机测试未来的新兴趋势，包括神经符号和大型语言模型的集成、创建协同仿真环境以及数字孪生驱动的仿真测试技术。通过遵循此流程，开发者和研究人员可以实现全面的验证，最大程度地降低部署风险，并为自主无人机在真实世界中的安全可靠运行做好准备。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [356] [Test code generation at Ericsson using Program Analysis Augmented Fine Tuned LLMs](https://arxiv.org/abs/2506.11006)
> *爱立信使用程序分析增强型微调大型语言模型进行测试代码生成*

*Sai Krishna, Balvinder Singh, Sujoy Roychowdhury, Giriprasad Sridhara, Sourav Mazumdar, Magnus Sandelin, Dimitris Rentas, Maciej Nalepa, Karol Sawicki, Jakub Gajda* | **Main category: cs.SE**

**Keywords:** 测试代码生成, 大型语言模型, 检索增强生成, 程序分析, 微调

**Comment:** Accepted at International Conference on Evaluation and Assessment in
  Software Engineering (EASE), 2025

> **TL;DR:** 本文介绍了爱立信如何利用程序分析增强的检索增强生成（RAG）和微调大型语言模型（LLMs）来生成测试代码，提高了生成代码与人工编写代码的一致性。

**AI_Comments:** 本文的创新点在于结合了程序分析、RAG和LLM微调来解决特定领域（测试代码生成）中LLM的局限性。通过提供丰富的上下文信息和定制化微调，有效提升了生成代码的实用性和一致性。这项工作对于在企业环境中应用LLM进行代码自动化生成具有重要的实践意义，尤其是在资源有限的情况下，证明了较小模型经过优化后也能达到高性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型直接生成测试代码时，会假设不存在的函数和签名，导致生成代码不符合代码库规范。因此需要改进LLM的测试代码生成能力。

**Method:** 1. 使用检索增强生成（RAG）结合提示工程，通过静态程序分析提供额外的上下文信息，以解决LLM假设不存在函数的问题。2. 进一步通过微调底层LLM来提高性能。微调基于自定义的提示模板，该模板包含预依赖类、其公共方法以及RAG获得的两个示例输出。3. 使用了8x7b的混合专家（MoE）模型进行微调。

**Result:** 微调后的模型在生成代码与原始开发者编写的测试代码的一致性方面有所改善，通过基于生成代码中使用的方法的F1分数传统指标进行衡量。对8x7b混合专家（MoE）模型进行微调，比基础模型平均提高了8%，并且与更大的8x22b MoE模型的分数相当。

**Conclusion:** 通过结合程序分析增强的RAG和定制微调，可以显著提高LLM在特定领域（如测试代码生成）的性能和代码一致性，即使是较小的模型也能达到与更大模型相当的效果。

> **ai_Abstract:** 本文介绍了爱立信在测试代码生成方面的实践，通过将自然语言测试步骤转换为Java代码。研究发现，直接使用大型语言模型（LLM）存在生成不符合现有代码库规范的问题。为解决此问题，作者团队结合了检索增强生成（RAG）与静态程序分析的提示工程来提供上下文信息。进一步的改进是通过对LLM进行微调实现的，微调使用了包含依赖类、公共方法和RAG示例输出的定制模板。实验结果表明，微调后的模型显著提高了生成代码与人工编写代码的一致性，其中8x7b MoE模型比基础模型平均提升了8%，且性能媲美更大的8x22b MoE模型。

> **摘要翻译:** 我们描述了爱立信使用大型语言模型（LLM）生成测试代码的情况。我们的输入是自然语言（英语）的测试步骤，输出是完成该测试步骤的代码（Java）。我们描述了直接提示为什么不足以满足需求，以及LLM如何假设代码库中不存在的函数和签名。然后，我们展示了如何通过结合检索增强生成（RAG）和提示工程来缓解这个问题，通过静态程序分析扩展简单提示，增加额外的上下文信息。接着，我们描述了通过微调底层LLM获得的进一步改进。微调是基于自定义设计的提示模板进行的，该模板包含预依赖类、它们的公共方法以及从RAG获得的两个示例输出。我们的结果表明，我们微调后的模型有助于提高与原始开发者编写的测试代码的对应性或一致性，这是通过基于生成代码中使用的方法的F1分数传统指标来衡量的。对8x7b混合专家（MoE）模型进行微调，比基础模型平均提高了8%，并且与更大的8x22b MoE模型的分数相当。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [364] [Impact of Comments on LLM Comprehension of Legacy Code](https://arxiv.org/abs/2506.11007)
> *评论对LLM理解遗留代码的影响*

*Rock Sabetto, Emily Escamilla, Devesh Agarwal, Sujay Kandwal, Justin F. Brunelle, Scott Rosen, Nitin Naik, Samruddhi Thaker, Eric O. Scott, Jacob Zimmer, Amit Madan, Arun Sridharan, Doug Wendt, Michael Doyle, Christopher Glasz, Jasper Phillips, William Macke, Colin Diggs, Michael Bartholf, Zachary Robin, Paul Ursino* | **Main category: cs.SE**

**Keywords:** LLM, 遗留代码, 注释, 代码理解, 多项选择问答 (MCQA)

**Comment:** 

> **TL;DR:** 本文探讨了注释（包括注释数量和不准确注释）对大型语言模型（LLM）理解遗留代码能力的影响，并提出了初步发现。

**AI_Comments:** 这项研究切中了LLM在实际软件工程应用中的一个重要痛点：遗留代码的理解。其创新点在于采用了MCQA这种定量评估方法来客观衡量LLM在特定场景下的表现，并着重分析了注释这一关键因素的影响。初步发现虽然未详述，但为后续深入研究奠定了基础，对于提升LLM在遗留系统维护中的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在软件工程任务中表现出色，但在理解遗留代码方面存在研究空白，尤其是在缺乏或包含不准确文档的真实世界遗留系统中，这可能会影响LLM的理解能力。因此，需要一种客观、高效、定量的评估方法来衡量LLM对遗留语言的理解。

**Method:** 作者利用多项选择问答（MCQA）这一新兴的LLM评估方法，来评估LLM对遗留代码的理解，以及注释普及率和不准确注释的影响。

**Result:** 本文提出了关于文档对LLM理解遗留代码影响的初步发现。

**Conclusion:** 论文提出了关于文档对LLM理解遗留代码影响的初步发现，并概述了未来工作的战略目标。

> **ai_Abstract:** 本文旨在探讨大型语言模型（LLM）在理解遗留代码方面的能力，特别关注注释（包括注释的数量和准确性）对其理解的影响。鉴于LLM在处理现代代码方面的成功以及遗留系统文档不足的挑战，研究人员采用多项选择问答（MCQA）作为评估方法，并提出了关于文档对LLM理解遗留代码影响的初步发现，同时指明了未来的研究方向。

> **摘要翻译:** 大型语言模型（LLM）因其在软件工程任务中的高性能和对现代编程语言的强大理解能力，已被越来越多地整合到软件工程和维护任务中。然而，LLM理解用遗留语言编写的代码的能力仍然是一个研究空白，这受到缺乏或包含不准确文档的真实世界遗留系统的挑战，这些文档可能会影响LLM的理解。为了评估LLM对遗留语言的理解，需要进行客观的LLM评估。为了客观地衡量LLM对遗留语言的理解，我们需要一种高效、定量的评估方法。我们利用多项选择问答（MCQA）这一新兴的LLM评估方法，来评估LLM对遗留代码的理解以及注释普及率和不准确注释的影响。在这项工作中，我们提出了关于文档对LLM理解遗留代码影响的初步发现，并概述了未来工作的战略目标。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [369] [Encoding Software For Perpetuity: A Compact Representation Of Apollo 11 Guidance Code](https://arxiv.org/abs/2506.11008)
> *软件永续编码：阿波罗11号制导代码的紧凑表示*

*David Noever* | **Main category: cs.SE**

**Keywords:** 阿波罗11号, 二维码, 软件保存, 计算遗产, 数字文物

**Comment:** 

> **TL;DR:** 将阿波罗11号制导代码编码成一个紧凑的二维码，便于通过移动设备访问和保存。

**AI_Comments:** 这项工作具有创新性，因为它提出了一种将历史软件（阿波罗11号制导代码）以高度紧凑和可访问的二维码形式进行编码和保存的方法。其重要性在于，它使重要的计算遗产能够通过普遍的移动设备即时访问，解决了传统数字保存方法可能存在的访问限制。这种方法为数字文物档案提供了一个新颖且实用的补充途径。

<details>
  <summary>Details</summary>

**Motivation:** 使具有历史意义的软件文物通过现代移动设备可访问，而无需专门的硬件或互联网连接。同时平衡可访问性与历史意义，作为传统档案技术的补充。

**Method:** 应用令牌化、选择性内容保存和最小HTML/JavaScript技术，将原始汇编语言代码（AGC）的关键组件压缩成一个可共享、可保存、可扫描的3千字节（KB）图像（QR码）。评估了多种压缩策略及其在大小、可读性和历史意义方面的权衡。

**Result:** 成功将阿波罗11号登月舱制导计算机代码的关键组件压缩成一个3KB的单一、紧凑的二维码格式，创建了一个可访问的数字文物，用于传输和存档。

**Conclusion:** 这项工作通过展示如何通过当代移动技术即时访问地标性软件，为更广泛的计算遗产保护领域做出了贡献。

> **ai_Abstract:** 本论文介绍了一种新颖方法，将历史性的阿波罗11号登月舱制导代码编码成一个紧凑的3KB二维码。通过令牌化、选择性内容保存和最小HTML/JavaScript技术，该方法旨在使这一重要的软件文物易于通过现代移动设备访问和保存，无需特殊硬件或网络连接。它平衡了可访问性与历史意义，为计算遗产保护提供了一种创新的补充方案。

> **摘要翻译:** 这篇简短的笔记提出了一种将历史性阿波罗11号登月舱制导计算机代码编码成单一、紧凑的快速响应码（QR码）格式的新颖方法，从而创建了一个可用于传输和存档的易于访问的数字文物。通过应用令牌化、选择性内容保存和最小HTML/JavaScript技术，我们成功地将原始汇编语言代码（AGC）的关键组件压缩成一个可共享、可保存、可扫描的3千字节（KB）图像。我们评估了多种压缩策略及其在大小、可读性和历史意义方面的权衡。这种方法解决了在不要求专用硬件或互联网连接的情况下，通过现代移动设备提供具有历史意义的软件文物的问题。尽管存在许多针对历史软件的数字保存方法，但这种方法平衡了可访问性与历史意义，为传统档案技术提供了一种补充方法。这项工作通过展示如何通过当代移动技术即时访问地标性软件，为更广泛的计算遗产保护领域做出了贡献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [375] [Human-In-The-Loop Software Development Agents: Challenges and Future Directions](https://arxiv.org/abs/2506.11009)
> *人机协作软件开发代理：挑战与未来方向*

*Jirat Pasuksmit, Wannita Takerngsaksiri, Patanamon Thongtanunam, Chakkrit Tantithamthavorn, Ruixiong Zhang, Shiyan Wang, Fan Jiang, Jing Li, Evan Cook, Kun Chen, Ming Wu* | **Main category: cs.SE**

**Keywords:** 人机协作,软件开发代理,LLM,评估,Jira

**Comment:** The International Conference on Mining Software Repositories (MSR)
  2025, Industry track

> **TL;DR:** 论文探讨了Atlassian部署人机协作软件开发代理的挑战，主要涉及单元测试的高计算成本和LLM评估的变异性，并提出了未来的研究方向。

**AI_Comments:** 这篇论文揭示了在实际应用中部署LLM驱动的软件开发代理所面临的具体挑战，特别是评估成本和可靠性问题，这对于该领域未来的研究和实践具有重要指导意义。其创新之处在于结合了实际部署经验来识别问题，并提出了针对性的未来方向。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发中多智能体LLM驱动系统日益普及，为提高生产力提供了新机会。作者部署了人机协作软件开发代理并评估其代码质量，旨在识别和解决相关挑战。

**Method:** 作者在Atlassian部署了人机协作软件开发代理来解决Jira工作项，并使用功能正确性测试和基于GPT的相似性评分来评估生成的代码质量。

**Result:** 论文指出了两个主要挑战：单元测试的高计算成本和基于LLM评估的变异性。

**Conclusion:** 论文提出了改进人机协作软件开发工具评估框架的未来研究方向。

> **ai_Abstract:** 本文探讨了在Atlassian部署人机协作软件开发代理的经验。研究发现，尽管此类系统有潜力提高生产力，但面临单元测试计算成本高昂和LLM评估结果不稳定的挑战。论文最后提出了未来研究方向，以期改进人机协作软件开发工具的评估框架。

> **摘要翻译:** 多智能体LLM驱动的软件开发系统正迅速普及，为提高生产力提供了新的机会。在Atlassian，我们部署了人机协作软件开发代理来解决Jira工作项，并使用功能正确性测试和基于GPT的相似性评分来评估生成的代码质量。本文强调了两个主要挑战：单元测试的高计算成本和基于LLM评估的变异性。我们还提出了改进人机协作软件开发工具评估框架的未来研究方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [380] [Enhancing Inventory Management with Progressive Web Applications (PWAs): A Scalable Solution for Small and Large Enterprises](https://arxiv.org/abs/2506.11011)
> *使用渐进式Web应用程序（PWA）增强库存管理：中小型和大型企业的可扩展解决方案*

*Abhi Desai* | **Main category: cs.SE**

**Keywords:** 库存管理, 渐进式Web应用程序, PWA, 可扩展解决方案, 企业应用

**Comment:** 

> **TL;DR:** 本研究开发并实现了一个PWA，用于改进库存管理，提供离线能力、响应式体验和跨平台适应性，是传统软件的可扩展且经济高效的替代方案，但也存在与原生应用相比的性能限制。

**AI_Comments:** 这项研究的创新之处在于将PWA技术应用于库存管理，提供了一种无需安装、跨平台、具备离线能力的解决方案，这对于追求成本效益和灵活部署的企业具有重要意义。尽管论文指出了PWA在性能上可能不如原生应用，但其可扩展性和经济性使其成为中小企业的有力选择。为未来开发者提供路线图也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 高效的库存管理对于中小型和大型企业优化运营流程和降低开销成本至关重要。本文旨在探索开发和实现一个渐进式Web应用程序（PWA）以增强库存管理体验。

**Method:** 本文开发并实现了一个渐进式Web应用程序（PWA），该应用集成了条形码和二维码扫描、基于地理定位的仓库识别以及跨设备可访问性等关键功能。通过利用PWA技术，该解决方案确保了离线能力、响应式用户体验和跨各种平台的无缝适应性。

**Result:** 该PWA解决方案通过利用PWA技术，确保了离线能力、响应式用户体验和跨各种平台的无缝适应性。它为基于网络的库存解决方案领域做出了贡献，提供了一种可扩展且经济高效的传统库存管理软件替代方案。研究也讨论了PWA在性能方面与原生应用程序相比的局限性。

**Conclusion:** 本研究为基于网络的库存解决方案领域做出了贡献，提供了一种可扩展且经济高效的传统库存管理软件替代方案。开发过程中的见解为未来开发者将PWA技术集成到企业应用中提供了路线图。

> **ai_Abstract:** 本研究开发并实现了一个渐进式Web应用程序（PWA），旨在提升企业的库存管理效率。该PWA集成了条形码/二维码扫描、地理定位仓库识别和跨设备访问等功能，并利用PWA技术实现了离线操作、响应式用户体验和跨平台兼容性。论文探讨了实施PWA的挑战与优势，包括其相对于原生应用的性能限制，并提出PWA是传统库存管理软件的一种可扩展且经济高效的替代方案。

> **摘要翻译:** 高效的库存管理对于中小型和大型企业优化运营流程和降低开销成本至关重要。本文探讨了为增强库存管理体验而设计的渐进式Web应用程序（PWA）的开发和实施。该应用程序集成了条形码和二维码扫描、基于地理定位的仓库识别以及跨设备可访问性等关键功能。通过利用PWA技术，该解决方案确保了离线能力、响应式用户体验以及跨各种平台的无缝适应性。该研究讨论了在库存管理系统中实施PWA的挑战和益处，包括与原生应用程序相比在性能方面的局限性。开发过程中的见解为未来希望将PWA技术集成到企业应用程序中的开发者提供了路线图。这项研究为不断发展的基于网络的库存解决方案领域做出了贡献，为传统库存管理软件提供了一种可扩展且经济高效的替代方案。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [386] [Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.11013)
> *迈向量子软件工程的巴西研究议程：一项系统性文献映射研究*

*Filipe Fernandes, Cláudia Werner* | **Main category: cs.SE**

**Keywords:** 量子软件工程, 系统性文献映射, 巴西研究议程, 研究趋势, 量子计算

**Comment:** 11 pages, 13 figures

> **TL;DR:** 本研究通过系统性文献映射，揭示了量子软件工程领域的现状、研究趋势和差距，并提出了一个巴西量子软件工程研究议程，以促进巴西在该领域的发展。

**AI_Comments:** 这篇论文通过系统性文献映射，不仅清晰地描绘了量子软件工程领域的全球研究图景，更创新性地提出了针对巴西的具体研究议程。其重要性在于，它不仅指出了该领域的普遍性挑战（如知识碎片化和缺乏实证验证），还特别关注了发展中国家（以巴西为例）在该领域参与度不足的问题，并提供了切实的解决方案。这对于促进区域性科研发展、缩小全球技术差距具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子软件工程（QSE）是支持可靠、可维护和可扩展量子应用的关键领域，但其知识分散，缺乏标准化方法、工具和指南。此外，巴西等国家在该领域的参与有限。因此，本研究旨在通过映射QSE的现有技术水平，识别当前研究趋势、常见贡献和现有差距，从而指导未来的研究和战略举措。

**Method:** 采用系统性文献映射研究方法，根据纳入和排除标准分析了选定的出版物。文章按研究类型、研究性质和与SWEBOK知识领域的对齐情况进行分类。

**Result:** 大多数审查的研究是英文撰写的基础研究文章，主要集中在软件工程模型与方法、软件架构和软件测试。概念性提案和技术解决方案占主导地位，而实证验证有限。

**Conclusion:** 量子软件工程是一个有前景但仍在成熟的领域。实践标准化、实证研究扩展以及发展中国家研究人员的参与至关重要。巴西的贡献仍然稀少，迫切需要建立国家研究议程。本研究提出了巴西量子软件工程研究议程，概述了优先领域和机会，以促进当地科学界发展并加速该领域进步。

> **ai_Abstract:** 本研究通过一项系统性文献映射，全面审视了量子软件工程（QSE）领域的当前研究现状、趋势和存在的不足。研究发现，QSE知识分散，缺乏标准化实践，且实证研究有限，尤其在巴西等发展中国家参与度较低。为解决这些问题，本研究提出了一项巴西量子软件工程研究议程，旨在明确优先发展领域，以促进巴西本土科研社区的成长并加速该新兴领域的发展。

> **摘要翻译:** 背景：量子软件工程（QSE）已成为支持可靠、可维护和可扩展量子应用开发的关键领域，它将量子计算的进步与软件工程的既定实践相结合。
问题：尽管该领域不断发展，但仍面临知识分散的问题，缺乏针对量子范式独特特征的标准化方法、工具和指南。此外，巴西等国家在该新兴领域的发展中参与有限。
目标：本研究旨在通过识别当前研究趋势、常见贡献和现有差距来映射QSE的现有技术水平，从而指导未来的研究和战略举措。
方法：进行了一项系统性文献映射研究，根据纳入和排除标准分析了选定的出版物。文章按研究类型、研究性质和与SWEBOK知识领域的对齐情况进行分类。
结果：大多数审查的研究是英文撰写的基础研究文章，主要集中在软件工程模型与方法、软件架构和软件测试。概念性提案和技术解决方案占主导地位，而实证验证仍然有限。
结论：研究结果证实，QSE是一个有前景但仍在成熟的领域。实践的标准化、实证研究的扩展以及发展中国家研究人员的参与对于推进该学科至关重要。此外，巴西的贡献仍然稀少，这突出表明迫切需要建立国家研究议程。作为一项主要贡献，本研究提出了巴西量子软件工程研究议程，概述了优先领域和机会，以促进当地科学界发展并加速该新兴领域的进步。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [392] [MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants](https://arxiv.org/abs/2506.11014)
> *MultiMind：AI助手辅助开发任务实施的插件*

*Benedetta Donato, Leonardo Mariani, Daniela Micucci, Oliviero Riganelli, Marco Somaschini* | **Main category: cs.SE**

**Keywords:** AI助手, IDE, 软件开发, Visual Studio Code, 插件

**Comment:** 

> **TL;DR:** MultiMind是一个VS Code插件，旨在简化AI辅助开发任务的创建，解决了AI助手在IDE中集成面临的挑战。

**AI_Comments:** 该论文提出MultiMind插件，有效解决了AI助手与IDE集成中面临的调用、协调、处理和反馈等关键挑战。其创新性在于提供了一个模块化、可扩展的框架，降低了开发者实现和实验AI驱动交互的成本和复杂性，对于推动AI在软件开发领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将AI辅助任务嵌入集成开发环境（IDEs）面临重大挑战，包括如何适时调用AI助手、协调多个助手、处理生成输出以及无缝集成反馈。

**Method:** 本文引入了MultiMind，一个Visual Studio Code插件，它提供了一个模块化和可扩展的框架，使开发者能够经济高效地实现和实验新的AI驱动交互，而无需复杂的IDE定制。

**Result:** MultiMind已在两个用例中进行测试：一个用于自动生成代码注释，另一个关于定义AI驱动的聊天。

**Conclusion:** MultiMind成功解决了AI助手在IDE中集成的挑战，并提供了一个经济高效的解决方案，简化了AI辅助开发任务的创建。

> **ai_Abstract:** MultiMind是一个为Visual Studio Code设计的插件，旨在解决AI助手在IDE中集成时的挑战。它提供了一个模块化和可扩展的框架，简化了AI辅助开发任务的创建，使得开发者可以高效地实现和测试AI驱动的交互，而无需复杂的IDE定制。该插件已在代码注释自动生成和AI驱动聊天定义两个用例中进行了测试。

> **摘要翻译:** 人工智能助手与软件开发工作流程的整合正在迅速发展，从自动化辅助任务转向开发者与人工智能之间的协作互动。大型语言模型（LLMs）在多项开发活动中展现了其有效性，包括代码补全、测试用例生成和文档制作。然而，将人工智能辅助任务嵌入集成开发环境（IDEs）带来了重大挑战。这需要设计机制以在适当时间调用人工智能助手，协调与多个助手的互动，处理生成的输出，并以与开发工作流程无缝集成的方式呈现反馈。为了解决这些问题，我们引入了MultiMind，一个Visual Studio Code插件，它简化了人工智能辅助开发任务的创建。MultiMind提供了一个模块化和可扩展的框架，使开发者能够经济高效地实现和实验新的AI驱动交互，而无需复杂的IDE定制。MultiMind已在两个用例中进行测试：一个用于自动生成代码注释，另一个关于定义AI驱动的聊天。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [397] [ZjsComponent: A Pragmatic Approach to Modular, Reusable UI Fragments for Web Development](https://arxiv.org/abs/2506.11016)
> *ZjsComponent：一种用于Web开发中模块化、可重用UI片段的实用方法*

*Lelanthran Manickum* | **Main category: cs.SE**

**Keywords:** Web组件, UI片段, 模块化, 可重用, 无依赖

**Comment:** 12 pages, 7 figures

> **TL;DR:** ZjsComponent 是一种轻量级、无框架依赖的Web组件，无需构建步骤即可创建模块化、可重用UI，简化了Web开发。

**AI_Comments:** ZjsComponent 的创新之处在于其“无构建步骤、无依赖”的实用方法，这与当前主流前端框架通常需要的复杂构建流程形成鲜明对比。它通过利用原生的Web Components能力，降低了开发门槛和项目复杂度，对于追求轻量级、高复用性和快速开发的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的组件开发方法通常需要复杂的构建步骤、转译、预编译或特定的生态系统及其他依赖，这增加了开发开销和复杂性。本文旨在提出一种更简单、更轻量级且无需这些额外依赖的Web组件解决方案。

**Method:** 本文介绍了ZjsComponent，它是一个轻量级、与框架无关的Web组件，旨在通过纯HTML创建模块化、可重用的UI元素。其方法特点是不需要构建步骤、转译、预编译或任何特定的生态系统及其他依赖，仅要求浏览器能够加载和执行Web Components所需的JavaScript。ZjsComponent允许HTML+JS片段的动态加载和隔离，提供显著的DOM和代码隔离，并支持简单的生命周期钩子以及类实例的传统方法。

**Result:** ZjsComponent 使得开发者能够以最小的开销轻松构建可重用的界面，实现了HTML+JS片段的动态加载和隔离，提供了无依赖的开发方式，显著的DOM和代码隔离，并支持简单的生命周期钩子以及传统的类实例方法。

**Conclusion:** ZjsComponent 提供了一种实用且无需依赖的解决方案，用于创建模块化、可重用且易于集成的Web UI片段，从而显著简化了Web开发过程。

> **ai_Abstract:** 本文介绍了ZjsComponent，一个轻量级、无框架依赖的Web组件，旨在解决传统Web组件开发中存在的构建步骤和依赖问题。它允许开发者通过纯HTML创建模块化、可重用UI片段，无需转译或预编译，仅依赖浏览器对Web组件JavaScript的支持。ZjsComponent提供HTML+JS片段的动态加载和隔离，实现DOM和代码的高度隔离，并支持生命周期钩子，从而简化了Web界面开发流程。

> **摘要翻译:** 在本文中，我介绍了ZjsComponent，它是一个轻量级且与框架无关的Web组件，旨在以最小的开发人员开销创建模块化、可重用的UI元素。ZjsComponent是创建可以纯粹从HTML使用的组件和对象实例的方法的一个实现示例。与传统的组件方法不同，ZjsComponent实现的方法不需要构建步骤、转译、预编译、任何特定的生态系统或任何其他依赖。所需要的只是浏览器能够根据Web组件的需求加载和执行JavaScript。ZjsComponent允许HTML+JS片段的动态加载和隔离，为开发人员提供了一种轻松构建可重用界面的简单方法。这种方法是无依赖的，提供了显著的DOM和代码隔离，并支持简单的生命周期钩子以及类实例所期望的传统方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [400] [Formation of requirements traceability in the process of information systems design](https://arxiv.org/abs/2506.11018)
> *信息系统设计过程中需求可追溯性的形成*

*Grigory Tsiperman* | **Main category: cs.SE**

**Keywords:** 需求可追溯性, 信息系统设计, 自适应聚类方法, 项目工件, 系统架构

**Comment:** 12 pages, 4 figures, 2025 the 8th International Conference on
  Information Management

> **TL;DR:** 本文提出将自适应聚类方法（ACM）应用于信息系统设计过程，以解决需求可追溯性与设计过程集成的大挑战，旨在实现项目工件的无缝互联。

**AI_Comments:** 本文提出了一种应对需求可追溯性“大挑战”的方法，即通过自适应聚类方法（ACM）实现其与信息系统设计过程的集成。其创新点在于强调无缝系统架构和不同抽象级别工件的明确互连，这对于提高系统质量、降低开发依赖性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 需求可追溯性是信息系统设计过程中项目的重要属性和质量特征，它提供软件系统的验证和确认方法，并降低系统对开发人员的依赖。然而，将可追溯性集成到设计过程中是一个“大挑战”。

**Method:** 提出应用作者开发的“信息系统自适应聚类方法（ACM）”，该方法基于无缝系统架构的理念，提供不同抽象级别项目工件的明确互连。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了信息系统设计中需求可追溯性的重要性及其作为项目质量特征的作用。鉴于将可追溯性集成到设计过程中的挑战，作者提出了一种解决方案：应用其开发的自适应聚类方法（ACM）。该方法基于无缝系统架构，旨在实现不同抽象级别项目工件的明确互连，从而应对可追溯性集成难题。

> **摘要翻译:** 信息系统设计过程中的需求可追溯性被认为是项目的重要属性，是其质量特征之一。这里的重点是可追溯性提供了软件系统的验证和确认方法，并且基于需求可追溯性的系统模型降低了系统对开发人员的依赖，总的来说，使其尽可能地简单明了。可追溯性过程的挑战之一，被可追溯性研究人员称为“可追溯性的大挑战”，是将其集成到设计过程中。在本文中，为实现这一目标，我们提出了应用作者开发的信息系统自适应聚类方法（ACM），该方法基于无缝系统架构的理念，提供不同抽象级别项目工件的明确互连。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [405] [Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)](https://arxiv.org/abs/2506.11019)
> *注意指标：基于模型上下文协议（MCP）的遥测感知型IDE内AI应用开发模式*

*Vincent Koc, Jacques Verre, Douglas Blank, Abigail Morgan* | **Main category: cs.SE**

**Keywords:** 遥测感知型IDE, 模型上下文协议, AI应用开发, LLMOps, 提示优化

**Comment:** 16 pages, 5 figures, conference preprint submission. Conceptual
  systems architecture paper on telemetry-driven prompt optimization and IDE
  design patterns for AI development. Builds on Opik MCP open-source
  architecture and Comet trace infrastructure

> **TL;DR:** 本文介绍了模型上下文协议（MCP），它能使IDE通过实时遥测数据进行AI应用开发和优化，并提出了相关设计模式。

**AI_Comments:** 这篇论文通过引入模型上下文协议（MCP），提出了一种将遥测数据深度集成到AI开发IDE中的创新方法。其重要性在于将AI开发从传统的代码-测试循环扩展到包含实时性能指标和用户反馈的“可观测性优先”范式，这对于大型语言模型（LLMs）的迭代和优化尤为关键。该架构不限于特定算法，而是提供一个通用框架，使其具有广泛的适用性。然而，抽象中未详细说明MCP的具体技术实现细节和潜在的性能开销。

<details>
  <summary>Details</summary>

**Motivation:** AI开发环境正在演变为可观测性优先的平台，需要将实时遥测、提示追踪和评估反馈集成到开发者工作流中。

**Method:** 本文引入了由模型上下文协议（MCP）支持的遥测感知型集成开发环境（IDE），该系统将IDE与提示指标、追踪日志和版本控制连接起来，以实现实时优化。提出了本地提示迭代、基于CI的优化和利用遥测数据自适应行为的自主代理的设计模式。描述了一种支持与DSPy、PromptWizard和Prompts as Programs等框架集成的架构。

**Result:** 通过Opik（一个用于LLM遥测的开源MCP服务器）对此方法进行了演示，并将该方法定位在新兴的LLMOps生态系统中。

**Conclusion:** 这项工作为未来在遥测丰富的AI开发工作流中进行提示优化、IDE代理工具和经验基准测试奠定了基础。

> **ai_Abstract:** 本文提出了基于模型上下文协议（MCP）的遥测感知型集成开发环境（IDE），旨在将实时遥测、提示追踪和评估反馈整合到AI开发工作流中。MCP连接IDE与提示指标和版本控制，实现实时优化。作者介绍了本地提示迭代、CI优化和自主代理的设计模式，并展示了一个支持多种框架的架构，通过开源的Opik服务器进行验证，为LLMOps生态系统中的未来研究奠定了基础。

> **摘要翻译:** AI开发环境正在演变为可观测性优先的平台，将实时遥测、提示追踪和评估反馈集成到开发者工作流中。本文介绍了由模型上下文协议（MCP）支持的遥测感知型集成开发环境（IDE），该系统将IDE与提示指标、追踪日志和版本控制连接起来，以实现实时优化。我们提出了本地提示迭代、基于CI的优化和利用遥测数据自适应行为的自主代理的设计模式。我们没有专注于单一算法，而是描述了一种支持与DSPy、PromptWizard和Prompts as Programs等框架集成的架构。我们通过Opik（一个用于LLM遥测的开源MCP服务器）对此进行了演示，并将我们的方法定位在新兴的LLMOps生态系统中。这项工作为未来在遥测丰富的AI开发工作流中进行提示优化、IDE代理工具和经验基准测试奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [408] [Extracting Knowledge Graphs from User Stories using LangChain](https://arxiv.org/abs/2506.11020)
> *使用LangChain从用户故事中提取知识图谱*

*Thayná Camargo da Silva* | **Main category: cs.SE**

**Keywords:** 知识图谱, 用户故事, LangChain, 大型语言模型, 自动化提取

**Comment:** Master thesis work

> **TL;DR:** 该论文提出了一种利用大型语言模型和LangChain框架从用户故事中自动提取知识图谱的新方法，旨在提升软件开发中的用户需求理解和功能对齐。

**AI_Comments:** 该论文的创新点在于将大型语言模型与LangChain框架结合，实现了从非结构化的用户故事中自动化提取结构化知识图谱，这对于软件需求工程领域具有重要意义。自动化提取和评估过程的设计也体现了其实用性。其潜力在于显著提升用户需求理解和软件开发效率。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过增强用户需求和领域概念的可视化和理解，促进软件功能与用户期望之间更好的对齐，最终为更有效和以用户为中心的软件开发过程做出贡献。

**Method:** 本论文介绍了一种利用大型语言模型（LLM）的先进能力，从用户故事中自动生成知识图谱的新颖方法。该方法以LangChain框架为基础，开发了用户故事图谱转换器模块（User Story Graph Transformer），使用LLM从用户故事中提取节点和关系，以构建准确的知识图谱。该创新技术被实现为一个脚本，以完全自动化知识图谱提取过程。此外，评估也通过一个专用评估脚本，利用一个带注释的数据集进行自动化。

**Result:** 通过增强用户需求和领域概念的可视化和理解，该方法促进了软件功能与用户期望之间更好的对齐。

**Conclusion:** 该论文提出了一种利用大型语言模型和LangChain框架从用户故事中自动提取知识图谱的新颖方法，该方法有助于提升用户需求理解并促进更有效和以用户为中心的软件开发过程。

> **ai_Abstract:** 本论文提出了一种利用大型语言模型和LangChain框架从用户故事中自动提取知识图谱的新颖方法。研究开发了用户故事图谱转换器模块，通过LLM提取用户故事中的节点和关系来构建知识图谱，并实现了自动化提取和评估过程。该方法旨在通过增强用户需求的可视化和理解，促进软件功能与用户期望的对齐，从而提升软件开发的效率和用户中心性。

> **摘要翻译:** 本论文介绍了一种利用大型语言模型先进能力，从用户故事中自动生成知识图谱的新颖方法。该方法以LangChain框架为基础，开发了用户故事图谱转换器模块，利用大型语言模型从用户故事中提取节点和关系，以构建准确的知识图谱。这项创新技术被实现为一个脚本，以完全自动化知识图谱提取过程。此外，评估也通过一个专用评估脚本，利用一个带注释的数据集进行自动化。通过增强用户需求和领域概念的可视化和理解，该方法促进了软件功能与用户期望之间更好的对齐，最终有助于更有效和以用户为中心的软件开发过程。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [412] [Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering](https://arxiv.org/abs/2506.11021)
> *使用功能聚类消除LLM代码生成中的幻觉诱导错误*

*Chaitanya Ravuri, Saman Amarasinghe* | **Main category: cs.SE**

**Keywords:** LLM代码生成, 幻觉错误, 功能聚类, 可靠性, 错误消除

**Comment:** 9 pages, 1 figure

> **TL;DR:** 提出功能聚类方法，通过对LLM生成的代码进行采样、执行和聚类来消除幻觉错误，大幅提高代码生成可靠性。

**AI_Comments:** 该论文提出了一种创新的黑盒方法“功能聚类”，通过验证和聚类来显著降低LLM代码生成中的幻觉错误。其优势在于不依赖模型内部结构，可应用于各种LLM和闭源API。通过将错误率从65%降至2%甚至0%，极大地提高了代码的可靠性，为LLM在实际编程任务中的自主部署铺平了道路。未来的工作重点在于解决提示误解问题，进一步完善规范清晰度。

<details>
  <summary>Details</summary>

**Motivation:** 现代代码生成大型语言模型（LLM）在生成代码时仍会产生微妙的幻觉错误，使得其输出不安全，无法自主部署。本研究旨在消除这些幻觉引起的错误，提高代码生成的可靠性和安全性。

**Method:** 本文提出了一种名为“功能聚类”（functional clustering）的黑盒封装方法。该方法首先采样大量候选程序，然后在自生成的测试套件上执行每个程序，接着根据I/O行为相同的候选程序进行聚类。最大聚类的经验质量被用作精确的置信度估计。通过设置一个单一的标量阈值，用户可以在覆盖率和可靠性之间进行权衡，并获得指数级的保证。

**Result:** 在LiveCodeBench基准测试中，该验证器在可解决的任务上保持了基线pass@1，同时将返回答案的错误率从约65%大幅降低到2%。在保守的阈值下，错误率甚至可以降至0%，此时仍能回答15.6%的提示。人工审计表明，少数剩余的错误源于提示误解，而非随机生成噪声。

**Conclusion:** 功能聚类方法为实现可靠、自主的代码生成提供了一条实用路径。由于该方法仅需要采样和沙盒执行，因此可以不变地应用于闭源API和未来的模型。未来的工作重点在于解决规范清晰度问题，而非随机生成噪声。

> **ai_Abstract:** 本文提出了一种名为“功能聚类”的黑盒封装方法，旨在消除大型语言模型（LLM）在代码生成中产生的幻觉错误。该方法通过采样多个候选程序，在自生成的测试套件上执行它们，并根据I/O行为进行聚类，以提供一个可调的置信度分数。在LiveCodeBench上的实验表明，该方法能将错误率从约65%显著降低至2%，甚至在保守阈值下达到0%，从而大幅提升了LLM代码生成的可靠性。由于其仅依赖采样和沙盒执行，该方法具有广泛的适用性，为实现可靠的自主代码生成提供了实用途径。

> **摘要翻译:** 现代代码生成大型语言模型（LLM）已经能够解决大部分编程问题，但它们仍然会产生微妙的幻觉错误，使得其输出不安全，无法自主部署。我们提出功能聚类，这是一种黑盒封装，可以消除几乎所有幻觉引起的错误，同时提供可调的置信度分数。该封装对许多候选程序进行采样，在自生成的测试套件上执行每个程序，并对I/O行为相同的候选程序进行聚类；最大聚类的经验质量用作精确的置信度估计。在此估计值上设置一个单一的标量阈值，允许用户以指数级保证来权衡覆盖率和可靠性。在LiveCodeBench上，我们的验证器在可解决任务上保持了基线pass@1，但将返回答案的错误率从约65%大幅降低到2%，并且在保守阈值下将其降至0%，同时仍能回答15.6%的提示。人工审计表明，少数剩余的错误源于提示误解，而非随机生成噪声，将未来的工作范围缩小到规范清晰度。由于该方法仅需要采样和沙盒执行，因此它可以不变地应用于闭源API和未来的模型，为可靠的自主代码生成提供了一条实用路径。我们的代码可在Github上获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [418] [Software Security Mapping Framework: Operationalization of Security Requirements](https://arxiv.org/abs/2506.11051)
> *软件安全映射框架：安全需求的具体化*

*Sung Une Lee, Liming Dong, Zhenchang Xing, Muhammad Ejaz Ahmed, Stefan Avgoustakis* | **Main category: cs.SE**

**Keywords:** 软件安全, 安全要求, 供应链安全, 映射框架, OSCAL

**Comment:** 28 pages, 13 figures, 6 tables

> **TL;DR:** 本文提出了一个软件安全映射框架，旨在将抽象的安全原则转化为具体的、可操作的实践，通过系统地映射安全要求到开发生命周期的操作步骤，以应对日益复杂的软件供应链安全挑战。

**AI_Comments:** 该论文的创新之处在于提出了一个系统化的框架，将抽象的安全要求具体化为可操作的步骤，有效弥补了现有框架的不足。其通过分层映射、结合KAOS目标建模以及提供实用工具（如Web导航工具和OSCAL模型）显著增强了框架的实用性和可采纳性。Log4j案例研究进一步验证了其实用性，对于提升软件供应链安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代软件开发环境的复杂性日益增加，导致供应链安全问题日益突出。现有框架在将抽象的安全原则转化为具体的、可操作的实践方面存在不足。

**Method:** 本文引入了软件安全映射框架，这是一个结构化的解决方案，旨在将安全要求分层操作化，从高级法规标准到细粒度技术活动。该框架系统地将131个精炼的安全要求映射到软件开发生命周期中400多个可操作的步骤。它以KAOS目标建模方法为基础，建立了战略目标与战术操作之间的可追溯联系。为促进采用，提供了基于网络的导航工具，并基于Log4j漏洞进行了案例研究。此外，还提供了结构化的、机器可读的OSCAL目录模型。

**Result:** 该框架成功地将131个安全要求映射到400多个可操作的步骤，并以Log4j漏洞为例，展示了其生成符合行业最佳实践的定制化清单的实用性。提供了基于网络的导航工具和OSCAL目录模型，以促进采用和自动化。

**Conclusion:** 该软件安全映射框架通过系统地将抽象安全原则转化为具体操作，增强了软件供应链安全的清晰度、问责制和实际实施能力，并通过工具和模型支持其应用和自动化。

> **ai_Abstract:** 本文提出了一个名为“软件安全映射框架”的结构化解决方案，旨在解决现代软件开发中抽象安全原则难以转化为具体实践的问题。该框架通过与学术界和工业界合作开发，系统地将131项安全要求映射到软件开发生命周期中的400多个可操作步骤，涵盖从高级法规到细粒度技术活动。它基于KAOS目标建模，并围绕安全软件环境、安全软件开发、软件可追溯性和漏洞管理四个核心目标构建。为促进应用，论文提供了一个基于网络的导航工具和一个OSCAL目录模型，并通过Log4j漏洞的案例研究展示了其生成定制化安全清单的实用性，旨在提高软件供应链安全的清晰度、问责制和实施效率。

> **摘要翻译:** 现代软件开发环境日益复杂，加剧了对供应链安全的担忧。然而，现有框架往往未能将抽象的安全原则转化为具体的、可操作的实践。本文引入了软件安全映射框架，这是一个结构化的解决方案，旨在将安全要求分层操作化——从高级监管标准（例如ISM，澳大利亚信号局发布的澳大利亚网络安全标准）到中级框架（例如NIST SSDF，美国安全软件开发框架），再到细粒度的技术活动（例如SLSA，一个软件供应链安全框架）。该框架通过与学术专家和行业从业者的合作研究开发，系统地将131项精炼的安全要求映射到跨越软件开发生命周期的400多个可操作的步骤。它以四个核心安全目标为基础：安全软件环境、安全软件开发、软件可追溯性和漏洞管理。我们的方法利用KAOS目标建模方法建立战略目标和战术操作之间的可追溯联系，从而提高清晰度、问责制和实际实施能力。为促进采用，我们提供了一个基于网络的导航工具，用于框架的交互式探索。基于Log4j漏洞的真实案例研究通过生成符合行业最佳实践的定制清单，说明了该框架的实用性。此外，我们还提供了软件安全映射框架的结构化、机器可读的OSCAL目录模型，使组织能够自动化实施、简化合规流程并有效应对不断变化的安全风险。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [421] [Refactoring Codebases through Library Design](https://arxiv.org/abs/2506.11058)
> *通过库设计重构代码库*

*Ziga Kovacic, Celine Lee, Justin Chiu, Wenting Zhao, Kevin Ellis* | **Main category: cs.SE**

**Keywords:** 代码重构, 库设计, 代码代理, 可重用性, 基准测试

**Comment:** 26 pages

> **TL;DR:** 本文介绍了一种名为Librarian的方法和Minicode基准测试，用于通过生成可重用库来重构代码，Librarian在压缩率和正确性方面优于现有代码代理。

**AI_Comments:** 本文的创新点在于提出了Librarian方法，一个专门用于通过生成可重用库来重构代码的采样和重排序机制，以及Minicode这一新颖的基准测试，它专注于评估代码代理将多个独立解决方案整合为联合库的能力。其重要性在于提升了代码代理在软件工程实践中，特别是在代码重构和库设计方面的应用潜力，有助于提高代码的可维护性和可重用性，尤其是在自动化编程日益普及的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 可维护和通用的软件允许开发者高效地构建健壮的应用，然而实现这些特性通常需要将专门的解决方案重构为可重用组件。随着代码代理在解决独立编程问题上变得越来越准确，这一挑战变得尤为重要。本文旨在调查代码代理重构代码以支持增长和可重用性的能力。

**Method:** 本文提出了一种重构方法和基准测试：Librarian，一种用于生成可重用库的采样和重排序方法；以及Minicode，一个要求代码代理将多个独立解决方案最小化并重构为一个联合库的基准测试。

**Result:** 与最先进的代码代理相比，Librarian在Minicode上在压缩和正确性方面都取得了显著成果，其压缩率比现有代码代理高1.6-2倍，同时还提高了正确性。

**Conclusion:** Librarian是一种有效的代码重构方法，能够将代码重构为可重用库，在压缩率和正确性方面均优于现有代码代理。

> **ai_Abstract:** 本文研究了代码代理重构代码以提高可重用性和可维护性的能力。作者提出了一种名为Librarian的采样和重排序方法，用于生成可重用库，并引入了Minicode基准测试来评估重构性能。实验结果表明，Librarian在Minicode基准测试上，相对于最先进的代码代理，在代码压缩率上提高了1.6-2倍，并且同时提升了代码的正确性。

> **摘要翻译:** 可维护和通用的软件允许开发者高效地构建健壮的应用，然而实现这些特性通常需要将专门的解决方案重构为可重用组件。随着代码代理在解决独立编程问题上变得越来越准确，这一挑战变得尤为重要。我们调查了代码代理以支持增长和可重用性的方式重构代码的能力。我们提出了一种重构方法和基准测试：Librarian，一种用于生成可重用库的采样和重排序方法；以及Minicode，一个要求代码代理将多个独立解决方案最小化并重构为一个联合库的基准测试。与最先进的代码代理相比，Librarian在Minicode上在压缩和正确性方面都取得了显著成果，其压缩率比现有代码代理高1.6-2倍，同时还提高了正确性。我们开源了我们的代码和基准测试，网址为https://code-refactor.github.io/。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [427] [Code Researcher: Deep Research Agent for Large Systems Code and Commit History](https://arxiv.org/abs/2506.11060)
> *代码研究员：大型系统代码和提交历史的深度研究代理*

*Ramneet Singh, Sathvik Joel, Abhav Mehrotra, Nalin Wadhwa, Ramakrishna B Bairi, Aditya Kanade, Nagarajan Natarajan* | **Main category: cs.SE**

**Keywords:** 深度研究代理, 系统代码, LLM, 崩溃修复, 上下文收集

**Comment:** 

> **TL;DR:** Code Researcher是一个基于LLM的深度研究代理，用于系统代码，它通过多步推理和深度上下文探索，显著提高了修复系统代码崩溃的成功率。

**AI_Comments:** 本文的创新点在于首次将深度研究代理的概念应用于代码领域，并针对系统代码的复杂性进行了优化。其通过多步推理和对大量文件及历史记录的深度探索，有效解决了传统LLM代理在处理大型复杂系统代码时上下文不足的问题。实验结果表明其在崩溃修复方面表现出色，并具有良好的通用性，这对于自动化系统维护和错误修复具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLM）编码代理在系统代码上的有效性尚未得到充分探索。由于系统代码的规模和复杂性，修改系统代码库是一项艰巨的任务，即使对于人类也是如此，因为它需要研究来自庞大代码库及其大量提交历史的许多上下文。

**Method:** 本文设计了Code Researcher，这是第一个用于代码的深度研究代理，并将其应用于生成用于缓解系统代码中报告的崩溃的补丁。Code Researcher通过对代码的语义、模式和提交历史进行多步推理来收集足够的上下文，并将这些上下文存储在结构化内存中以合成补丁。

**Result:** 在Linux内核崩溃基准测试kBenchSyz上，Code Researcher的崩溃解决率为58%，显著优于强基线（SWE-agent为37.5%）。平均而言，Code Researcher每次探索10个文件，而SWE-agent仅探索1.33个文件，突显了Code Researcher深度探索代码库的能力。在开源多媒体软件上的另一项实验也证明了Code Researcher的通用性。

**Conclusion:** 实验结果强调了全局上下文收集和多方面推理对于处理大型代码库的重要性。

> **ai_Abstract:** 本文介绍了Code Researcher，这是一种新颖的基于LLM的深度研究代理，专门用于解决系统代码的复杂性。针对系统代码中的崩溃修复问题，Code Researcher通过对代码语义、模式和提交历史的多步推理来收集和利用深度上下文。在Linux内核崩溃基准测试中，它以58%的解决率显著优于现有基线，并展示了在大型代码库中进行深入探索和泛化的能力，强调了全局上下文和多方面推理的重要性。

> **摘要翻译:** 大型语言模型（LLM）驱动的编码代理在编码基准测试中显示出有前景的结果，但它们在系统代码上的有效性仍未得到充分探索。由于系统代码的规模和复杂性，修改系统代码库是一项艰巨的任务，即使对于人类也是如此。在进行更改之前，它需要研究大量上下文，这些上下文来源于庞大的代码库及其大量的提交历史。受深度研究代理近期进展的启发，我们设计了第一个用于代码的深度研究代理，名为Code Researcher，并将其应用于生成补丁以缓解系统代码中报告的崩溃问题。Code Researcher对代码的语义、模式和提交历史进行多步推理，以收集足够的上下文。这些上下文存储在一个结构化内存中，用于合成补丁。我们在kBenchSyz（一个Linux内核崩溃基准测试）上评估了Code Researcher，结果表明它显著优于强大的基线，实现了58%的崩溃解决率，而SWE-agent为37.5%。平均而言，Code Researcher在每次轨迹中探索10个文件，而SWE-agent仅探索1.33个文件，这突显了Code Researcher深度探索代码库的能力。通过在开源多媒体软件上的另一个实验，我们展示了Code Researcher的通用性。我们的实验强调了全局上下文收集和多方面推理对于大型代码库的重要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [430] [CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval](https://arxiv.org/abs/2506.11066)
> *CoQuIR：一个用于代码质量感知信息检索的综合基准*

*Jiahui Geng, Fengyu Cai, Shaobo Cui, Qing Li, Liangwei Chen, Chenyang Lyu, Haonan Li, Derui Zhu, Walter Pretschner, Heinz Koeppl, Fakhri Karray* | **Main category: cs.SE**

**Keywords:** 代码检索, 软件质量, 基准测试, CoQuIR, 信息检索

**Comment:** 

> **TL;DR:** 引入了CoQuIR，一个大规模、多语言的代码质量感知信息检索基准，包含质量标注和新度量，并发现现有模型在质量识别上表现不佳，但通过质量感知训练可改进。

**AI_Comments:** CoQuIR是第一个专门为代码质量感知信息检索设计的大规模多语言基准，填补了现有基准的空白。其创新的质量标注和评估指标为该领域提供了新的研究工具。研究结果揭示了当前模型在质量识别上的局限性，并提出了有效的训练方法，对提升代码检索系统的实用性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的代码检索基准主要关注功能相关性，而忽略了软件质量的关键维度。

**Method:** 引入了CoQuIR，一个大规模、多语言的基准，包含42,725个查询和134,907个代码片段的细粒度质量标注，覆盖11种语言，并提出了两个质量中心评估指标。使用CoQuIR对23个检索模型进行基准测试，并初步研究了鼓励检索器识别代码质量的训练方法，使用合成数据集和下游代码生成实验。

**Result:** 现有顶尖模型难以区分有bug或不安全的代码；通过质量感知训练方法，在不牺牲语义相关性的前提下，显著改善了质量感知指标；下游代码生成实验进一步验证了方法的有效性。

**Conclusion:** 整合质量信号到代码检索系统中至关重要，为更可靠和健壮的软件开发工具奠定了基础。

> **ai_Abstract:** 本文介绍了CoQuIR，一个大规模、多语言的代码质量感知信息检索基准，旨在解决现有基准忽视软件质量维度的问题。CoQuIR包含丰富的质量标注和新的评估指标。研究发现现有代码检索模型在识别代码质量方面存在不足，但通过引入质量感知训练方法，可以在不影响语义相关性的前提下显著提升模型的质量识别能力，为开发更可靠的软件工具奠定了基础。

> **摘要翻译:** 代码检索在现代软件开发中至关重要，因为它能促进代码重用并加速调试。然而，当前的基准主要强调功能相关性，却忽视了软件质量的关键维度。受此差距的启发，我们引入了CoQuIR，这是第一个大规模、多语言的基准，专门设计用于评估跨四个关键维度（正确性、效率、安全性、可维护性）的代码质量感知检索。CoQuIR为11种编程语言的42,725个查询和134,907个代码片段提供了细粒度的质量标注，并附带两个以质量为中心的评估指标：成对偏好准确率（Pairwise Preference Accuracy）和基于边际的排名分数（Margin-based Ranking Score）。使用CoQuIR，我们对23个检索模型（包括开源和专有系统）进行了基准测试，发现即使是表现最好的模型也常常无法将有缺陷或不安全的代码与更健壮的代码区分开来。此外，我们对明确鼓励检索器识别代码质量的训练方法进行了初步研究。使用合成数据集，我们展示了在不牺牲语义相关性的情况下，各种模型在质量感知指标方面取得了有希望的改进。下游的代码生成实验进一步验证了我们方法的有效性。总的来说，我们的工作强调了将质量信号整合到代码检索系统中的重要性，为更值得信赖和更健壮的软件开发工具奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [434] [DCE-LLM: Dead Code Elimination with Large Language Models](https://arxiv.org/abs/2506.11076)
> *DCE-LLM：使用大型语言模型进行死代码消除*

*Minyu Chen, Guoqiang Li, Ling-I Wu, Ruibang Liu* | **Main category: cs.SE**

**Keywords:** 死代码消除, 大型语言模型, CodeBERT, 自动化, 软件开发

**Comment:** Accepted by regular paper in NAACL 2025, with 13 pages, 5 figures

> **TL;DR:** DCE-LLM是一个利用CodeBERT和大型语言模型自动消除死代码的框架，它在检测和修正死代码方面优于现有工具和GPT-4o。

**AI_Comments:** DCE-LLM的创新之处在于结合了轻量级的CodeBERT模型进行初步定位和强大的LLMs进行深度分析和修正，有效解决了传统工具难以处理的复杂死代码模式。其在性能上显著超越GPT-4o，表明了在特定任务上通过领域特定模型和微调的LLM组合的巨大潜力。该框架对于提高代码质量、减少安全漏洞和简化软件维护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 死代码在软件开发中引入了诸多挑战，如增加二进制大小、维护困难、模糊逻辑错误，并可能被用于恶意软件混淆。对于基于LLM的代码相关任务，死代码可能引入漏洞。尽管现代编译器和IDE提供死代码消除功能，但复杂模式仍能绕过这些工具。目前缺乏一个包含分类、定位、解释和修正的通用自动化方法，且现有工具需要大量手动工作。

**Method:** DCE-LLM框架使用小型CodeBERT模型和基于归因的行选择器来高效定位可疑代码。大型语言模型（LLMs）经过大规模标注死代码数据集的微调，用于生成判断、详细解释和补丁。该方法支持多种编程语言。

**Result:** DCE-LLM在未使用的代码和不可达代码上均实现了超过94%的F1分数，并且显著超越GPT-4o达30%。它在高级不可达性检测和自动化修正方面表现出色。

**Conclusion:** DCE-LLM通过结合CodeBERT和微调的LLMs，提供了一种高效、自动化的死代码消除解决方案，其性能显著优于现有工具和最新的大型语言模型，有效解决了死代码带来的挑战。

> **ai_Abstract:** 本文提出了DCE-LLM，一个利用小型CodeBERT模型和大型语言模型（LLMs）进行自动化死代码消除的框架。该框架通过归因分析定位可疑代码，并使用微调的LLMs生成解释和修正补丁。DCE-LLM在检测和修正死代码方面表现卓越，特别是在未使用的和不可达代码上取得了超过94%的F1分数，并显著优于GPT-4o，解决了现有工具在处理复杂死代码模式时的局限性。

> **摘要翻译:** 死代码在软件开发中带来了诸多挑战，例如增加二进制大小和维护困难。它还可能掩盖逻辑错误，并被利用进行恶意软件混淆。对于基于LLM的代码相关任务，死代码会引入可能误导这些模型的漏洞，从而引发安全问题。尽管现代编译器和IDE提供了死代码消除功能，但复杂的模式可以绕过这些工具。目前需要一种包括分类、定位、解释和修正的通用方法，但现有工具通常需要大量人工投入。我们提出了DCE-LLM，一个使用小型CodeBERT模型和基于归因的行选择器来高效定位可疑代码的自动化死代码消除框架。然后，大型语言模型（LLMs）会生成判断和解释，并在一个大规模、标注的死代码数据集上进行微调，以提供详细的解释和补丁。DCE-LLM在高级不可达性检测、自动化修正以及对多种编程语言的支持方面均优于现有工具。实验结果显示，DCE-LLM在未使用和不可达代码上实现了超过94%的F1分数，显著超越GPT-4o达30%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [438] [Research and Analysis of Employers' Opinion on the Necessary Skills that Students in the Field of Web Programming Should Possess](https://arxiv.org/abs/2506.11084)
> *雇主对Web编程领域学生应具备的必要技能看法的研究与分析*

*Yordan Kalmukov* | **Main category: cs.SE**

**Keywords:** Web编程, 雇主意见, 必要技能, 人工智能, 技能需求

**Comment:** 

> **TL;DR:** 本研究旨在调查IT雇主对Web编程毕业生应具备的必要技术技能的看法，以应对AI时代和现有开发工具对技能要求带来的变化。

**AI_Comments:** 该研究切合当前技术发展趋势，关注AI时代下编程技能需求的变化，具有较强的现实意义。通过直接调查雇主，能够获取一线、实用的人才需求信息。然而，摘要中并未提及具体的调查结果和分析，因此无法评估其创新性或对现有知识的贡献程度。

<details>
  <summary>Details</summary>

**Motivation:** 在人工智能（AI）和大型语言模型能够生成代码的时代，以及大量软件框架、第三方库和API提供了开箱即用的功能，雇主对毕业生的要求已经发生改变。因此，作者旨在识别IT雇主认为Web编程领域的应届毕业生应具备的必要技术技能，以便他们能够尽快有效地融入公司工作。

**Method:** 本文分析了对IT雇主进行的一项调查结果。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 鉴于人工智能和大型语言模型在代码生成方面的进步，以及现有软件框架和API提供的自动化功能，雇主对Web编程毕业生的技能要求已发生变化。本文旨在通过对IT雇主的调查，识别出Web编程领域的毕业生为快速有效地融入公司工作所必需的技术技能。

> **摘要翻译:** 在人工智能（AI）和基于大型语言模型（可以生成任何语言的编程代码、撰写文本和总结信息）的聊天机器人时代，雇主对毕业生的要求显然已经改变。现代IT世界通过软件框架和大量的第三方库及应用程序接口（API）实现了编程的显著自动化。所有这些工具都提供了大部分必要的开箱即用功能（已实现），因此很自然地提出了一个问题：对于学生来说，是教授如何使用这些现成的工具更有用，还是教授从零开始的Web应用程序工作和开发的基本原则更有用。本文分析了对IT雇主进行的一项调查结果，旨在确定在他们看来，Web编程领域的应届毕业生应具备哪些必要的技术技能，以便尽快有效地加入公司工作。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [443] [Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor](https://arxiv.org/abs/2506.11107)
> *基于代码图的调优适配器，用于去噪编程知识追踪*

*Weibo Gao, Qi Liu, Rui Li, Yuze Zhao, Hao Wang, Linan Yre, Fangzhou Yao, Zheng Zhang* | **Main category: cs.SE**

**Keywords:** 编程知识追踪, 代码图, 去噪, 噪声信号, 适配器

**Comment:** Accepted by KDD August 2025

> **TL;DR:** 本文提出Coda，一个基于代码图的调优适配器，旨在通过识别和减轻无关提交和微小修改产生的噪声信号，来增强现有编程知识追踪（PKT）模型，并在真实世界数据集中表现出优异性能。

**AI_Comments:** 该论文的创新点在于首次系统性地解决了编程知识追踪中由无关提交和微小修改引起的噪声问题。通过引入代码图和专门的噪声识别机制（语义相似性与聚类感知GCN），Coda提供了一个新颖且有效的去噪方法。其模型无关的特性大大增加了其实用性和普适性，使其能够与现有PKT模型无缝集成，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前编程知识追踪（PKT）研究主要关注代码内容与知识评估之间的隐式关系，但忽视了长期编程活动中存在的两种噪声信号：来自无关提交的无用信号和来自微小修改的微弱信号。这些噪声显著限制了模型的性能和应用。

**Method:** 本文提出了Coda，一个基于代码图的调优适配器。Coda首先将学习者提交的松散代码序列转化为紧凑的代码图。通过利用代码图，从语义相似性角度识别无用信号。然后，对代码图应用聚类感知GCN，以提高对微弱信号的辨别能力并进行聚类识别。最后，通过两个基于噪声特征的约束和一个导航正则化项进行优化，将一个轻量级但有效的适配器集成到PKT任务中，以纠正受噪声影响的知识状态。Coda框架是模型无关的。

**Result:** 在四个真实世界数据集上的大量实验结果表明，Coda在存在噪声编程记录的情况下有效地执行了PKT任务，并且优于典型的基线模型。

**Conclusion:** Coda通过有效地识别和缓解编程活动中的噪声信号，显著提高了编程知识追踪模型的性能，并且作为一个模型无关的框架，具有广泛的应用潜力。

> **ai_Abstract:** 本文针对编程知识追踪（PKT）中存在的无关提交和微小修改导致的噪声问题，提出了一个名为Coda的基于代码图的调优适配器。Coda通过将代码序列转换为紧凑的代码图，并利用语义相似性识别无用信号，同时使用聚类感知GCN增强微弱信号的识别与聚类。随后，一个轻量级适配器被集成到PKT任务中，通过噪声特征约束和导航正则化来纠正受噪声影响的知识状态。Coda框架模型无关，并在多个真实数据集上验证了其在噪声环境下优于现有基线的PKT性能。

> **摘要翻译:** 编程知识追踪（PKT）旨在根据学习者的编码活动，动态诊断他们对编程知识的掌握水平，从而促进更有效和个性化的编程教育。然而，当前的PKT研究主要关注代码内容与知识评估之间的隐式关系，常常忽视长期编程活动中的两种噪声信号：来自无关提交的无用信号和来自微小修改的微弱信号。这一实际挑战显著限制了模型的性能和应用。为了解决这个问题，我们提出了Coda，一个基于代码图的调优适配器，旨在通过识别和减轻噪声的影响来增强现有PKT模型。具体而言，Coda首先将每个学习者提交的松散代码序列转化为紧凑的代码图。通过利用此代码图，可以从语义相似性的角度识别无用信号。然后，我们对代码图应用聚类感知图卷积网络（GCN），这提高了微弱信号的辨别能力并使其能够进行聚类识别。最后，通过两个基于噪声特征的约束和一个导航正则化项进行优化，将一个轻量级但有效的适配器集成到PKT任务中，以纠正受噪声影响的知识状态。值得一提的是，Coda框架是模型无关的，可以适应大多数现有的PKT解决方案。在四个真实世界数据集上的大量实验结果表明，Coda在存在噪声编程记录的情况下有效地执行了PKT任务，并且优于典型的基线模型。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [448] [Mutual-Supervised Learning for Sequential-to-Parallel Code Translation](https://arxiv.org/abs/2506.11153)
> *互监督学习用于顺序到并行代码翻译*

*Changxin Ke, Rui Zhang, Shuo Wang, Li Ding, Guangli Li, Yuanbo Wen, Shuoming Zhang, Ruiyuan Xu, Jin Qin, Jiaming Guo, Chenxi Wang, Ling Li, Qi Guo, Yunji Chen* | **Main category: cs.SE**

**Keywords:** 互监督学习, 代码翻译, 顺序到并行, 功能等价性, 高性能计算

**Comment:** 28 pages

> **TL;DR:** 提出了一种名为互监督学习（MSL）的新框架，通过翻译器和测试器之间的迭代协作来解决顺序到并行代码翻译中的功能等价性问题，显著提高了性能。

**AI_Comments:** 本文的创新点在于提出了互监督学习（MSL）框架，通过翻译器和测试器之间的协同迭代来解决代码翻译中的功能等价性难题，这是一种新颖且高效的数据增强和模型优化策略。其重要性在于为自动顺序到并行代码翻译提供了新的解决方案，尤其是在数据稀缺的背景下，并通过实验验证了其在性能上的显著提升，对高性能计算领域的代码优化具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** GPU高性能计算的普及推动了并行编程模型的广泛采用，但其复杂性催生了自动化顺序到并行转换的需求。然而，机器学习方法面临数据稀缺的挑战，且现有回译方法未能确保翻译代码的功能等价性。

**Method:** 本文提出了一种新颖的互监督学习（MSL）框架，用于解决顺序到并行代码翻译中的功能等价性问题。MSL由一个翻译器（Translator）和一个测试器（Tester）组成。通过Co-verify和Co-evolve步骤组成的迭代循环，翻译器和测试器相互生成数据并共同改进。具体而言，测试器生成单元测试以验证和过滤功能等价的翻译代码，从而发展翻译器；同时，翻译器生成翻译代码作为增强输入来发展测试器。

**Result:** 实验结果表明，MSL显著提升了基础模型的性能：应用于Qwen2.5-Coder时，Pass@1提升高达28.91%，测试器性能提升68.90%。它在BLEU和CodeBLEU分数上分别超越了之前的最先进方法CodeRosetta 1.56和6.92，同时实现了与DeepSeek-R1和GPT-4.1相当的性能。

**Conclusion:** MSL框架通过其独特的互监督学习机制，有效地解决了顺序到并行代码翻译中的功能等价性问题，并显著提升了翻译性能，达到甚至超越了现有先进模型的水平。

> **ai_Abstract:** 本文提出了一种名为互监督学习（MSL）的新型框架，旨在解决顺序到并行代码翻译中由于数据稀缺和现有方法无法确保功能等价性而面临的挑战。MSL包含一个翻译器和一个测试器，二者通过迭代的Co-verify和Co-evolve步骤相互协作并共同提升。测试器负责验证和过滤翻译代码的功能等价性，而翻译器则生成增强输入。实验证明，MSL显著提升了基础模型的性能，在多个指标上超越了现有最先进方法，并达到了与顶级模型相当的水平。

> **摘要翻译:** GPU高性能计算（HPC）的兴起推动了CUDA等并行编程模型的广泛采用。然而，并行编程固有的复杂性催生了对自动化顺序到并行方法的巨大需求。然而，数据稀缺对基于机器学习的顺序到并行代码翻译构成了重大挑战。尽管最近的回译方法显示出前景，但它们仍未能确保翻译代码的功能等价性。在本文中，我们提出了一种新颖的互监督学习（MSL）框架，用于顺序到并行代码翻译，以解决功能等价性问题。MSL由两个模型组成：一个翻译器（Translator）和一个测试器（Tester）。通过由Co-verify和Co-evolve步骤组成的迭代循环，翻译器和测试器相互生成数据并共同改进。测试器生成单元测试来验证和过滤功能等价的翻译代码，从而发展翻译器，而翻译器生成翻译代码作为增强输入来发展测试器。实验结果表明，MuSL显著增强了基础模型的性能：当应用于Qwen2.5-Coder时，它不仅将Pass@1提高了28.91%，并将测试器性能提升了68.90%，而且在BLEU和CodeBLEU分数上分别超越了之前的最先进方法CodeRosetta 1.56和6.92，同时实现了与DeepSeek-R1和GPT-4.1相当的性能。我们的代码可在https://github.com/kcxain/musl 获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [456] [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org/abs/2506.11237)
> *LLM作为评判者：IT自动化中自然语言到Bash的无引用自动代码验证与优化*

*Ngoc Phuoc An Vo, Brent Paulovicks, Vadim Sheinin* | **Main category: cs.SE**

**Keywords:** LLM作为评判者, 代码验证, 代码优化, IT自动化, Bash代码生成

**Comment:** 10 pages

> **TL;DR:** 本文提出了一种增强型“LLM作为评判者”方法，用于IT自动化中Bash代码的无引用自动验证和优化，并通过反射代码代理实现了显著的代码改进。

**AI_Comments:** 本文创新性地将LLM作为评判者应用于IT自动化中的Bash代码验证与优化，特别是在无引用场景下。通过结合双向功能匹配和逻辑表示，提升了LLM的判断能力。更重要的是，引入反射代码代理利用LLM的反馈进行迭代优化，显著提高了代码精炼的准确性，为自动化事件修复提供了强大的工具。这一方法克服了传统评估方法的局限性，为未来LLM在代码质量管理中的应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 在IT自动化中，为了自动评估和选择最佳模型并提高代码质量以实现自动事件修复，关键在于验证生成的修复代码在语法和语义上是否正确，以及能否按预期正确执行。传统方法和基于执行的评估存在局限性，促使研究人员探索使用大型语言模型（LLMs）进行自动化评估。

**Method:** 本研究专注于增强“LLM作为评判者”的方法，通过使用双向功能匹配和逻辑表示，实现对Bash代码生成的无引用自动验证和优化，以选择IT自动化中用于自动事件修复的最佳模型。研究将基于执行的评估作为真值来评估“LLM作为评判者”指标。此外，还构建了反射代码代理，利用评估指标的判断和反馈，实现了自动代码优化。

**Result:** 结果显示，本研究提出的“LLM作为评判者”方法与基于执行的评估具有高度的准确性和一致性，并且相比基线提高了高达8%。最后，通过利用判断和反馈构建的反射代码代理，实现了显著的自动代码优化，准确性提高了高达24%。

**Conclusion:** 本文成功开发并验证了一种增强型“LLM作为评判者”框架，结合双向功能匹配和逻辑表示，实现了IT自动化中Bash代码的无引用自动验证和优化。该方法与基于执行的评估高度一致，并通过引入反射代码代理进一步显著提升了代码精炼的准确性，为自动化事件修复提供了有效工具。

> **ai_Abstract:** 本研究提出了一种增强型“LLM作为评判者”框架，用于IT自动化中自然语言到Bash代码的无引用自动验证和优化。该方法通过整合双向功能匹配和逻辑表示来提升评估能力，并以基于执行的评估作为真值进行验证。实验结果表明，该方法在代码验证方面表现出高准确性，并通过引入反射代码代理，进一步显著提升了代码精炼的准确性，为IT自动化中的自动事件修复提供了有效的解决方案。

> **摘要翻译:** 为了自动评估和选择最佳模型并提高IT自动化中自动事件修复的代码质量，验证所生成的修复代码在语法和语义上是否正确以及能否按预期正确执行至关重要。有三种方法：1）传统方法使用表面形式相似度度量（令牌匹配、精确匹配等），但存在诸多局限性；2）基于执行的评估更侧重于基于给定测试用例的通过/失败判断来评估代码功能性；3）“LLM作为评判者”方法利用大型语言模型进行自动化评估，根据预定义的指标判断是否为给定问题的正确答案。在这项工作中，我们专注于增强“LLM作为评判者”方法，利用双向功能匹配和逻辑表示，实现对Bash代码生成的无引用自动验证和优化，以选择IT自动化中用于自动事件修复的最佳模型。我们使用基于执行的评估作为真值来评估我们的“LLM作为评判者”指标。结果显示，与基于执行的评估具有高度的准确性和一致性（比基线高出高达8%）。最后，我们构建了反射代码代理，利用我们评估指标的判断和反馈，实现了自动代码优化，准确性显著提高（高达24%）。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [460] [Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](https://arxiv.org/abs/2506.11266)
> *可调用API源自NL2SQL数据集用于LLM工具调用评估*

*Benjamin Elder, Anupama Murthi, Jungkoo Kang, Ankita Rajaram Naik, Kiran Kate, Kinjal Basu, Danish Contractor* | **Main category: cs.SE**

**Keywords:** LLM, 工具调用, NL2SQL, NL2API, 数据集生成

**Comment:** 10+32 pages, 5 figures

> **TL;DR:** 本文提出了一种从NL2SQL数据集（特别是BIRD-SQL）自动创建NL2API数据集的管道，用于评估大型语言模型（LLMs）的工具调用能力。研究发现，LLMs在工具调用方面表现不佳，任务完成率较低，即使使用ReACT代理也仅略有改善，表明当前LLMs在工具调用方面仍有很大的改进空间。

**AI_Comments:** 本文通过利用现有NL2SQL数据集自动生成复杂的NL2API数据集，创新性地解决了LLM工具调用评估中高质量、大规模数据集稀缺的问题。其构建的包含2500多个可调用API的集合，为未来研究提供了宝贵的资源。对主流LLM在复杂工具调用任务上的全面评估揭示了当前模型在意图检测、函数序列化和参数填充等关键环节的显著不足，并量化了性能差距，这对于指导LLM智能体的能力提升具有重要的实践意义。研究结果强调了当前LLM在复杂企业级API交互方面仍有巨大的进步空间。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）作为智能体系统部署时，需要访问与实时环境交互的工具来完成任务。在企业部署中，这些系统需要与可能非常庞大和复杂的API集合交互，这些API通常由数据库支持。为了创建具有此类特征的数据集，本研究探索了如何利用现有NL2SQL（自然语言到SQL查询）数据集自动创建NL2API数据集。

**Method:** 本研究描述了一种新颖的数据生成管道，该管道利用SQL查询的语法来构建功能等效的API调用序列。将此管道应用于最大的NL2SQL数据集之一BIRD-SQL，创建了一个包含2500多个可作为可调用工具或REST端点的API集合。将BIRD-SQL中的自然语言查询与基于此API池的真实API序列进行配对。使用此集合研究了10个公共LLM的性能，并进行了详细的消融研究，例如评估可用工具数量以及工具和槽位名称混淆的影响。

**Result:** 所有模型在确定正确的工具集（包括意图检测、带有嵌套函数调用的序列化和槽位填充任务）方面都表现不佳。模型任务完成率极低（7-47%），当模型作为与实时API环境交互的ReACT代理时，任务完成率略微提高到50%。最佳任务完成率远低于有效通用工具调用代理所需的要求。模型有时能够比API更好地利用SQL。

**Conclusion:** 当前最先进的工具调用LLM仍有很大的改进空间，因为它们的最佳任务完成率远低于通用工具调用代理所需的有效水平。

> **ai_Abstract:** 本文提出了一种新颖的数据生成管道，能够将NL2SQL数据集转换为NL2API数据集。通过将此管道应用于BIRD-SQL，作者创建了一个包含2500多个可调用API的集合，并将其用于评估10个大型语言模型（LLMs）的工具调用能力。研究发现，LLMs在工具选择、序列化和槽位填充方面表现出显著的不足，任务完成率普遍较低（7-47%），即使采用ReACT代理也仅略有提升至50%。这表明当前LLMs在处理复杂工具调用任务时存在显著局限性，亟需改进，尤其是在构建能够有效与多样化API环境交互的通用智能体方面。

> **摘要翻译:** 大型语言模型（LLMs）通常作为智能体系统部署，可以访问与实时环境交互以完成任务的工具。在企业部署中，这些系统需要与可能极其庞大和复杂的API集合交互，这些API通常由数据库支持。为了创建具有此类特征的数据集，我们探索了如何利用现有NL2SQL（自然语言到SQL查询）数据集自动创建NL2API数据集。具体来说，这项工作描述了一种新颖的数据生成管道，该管道利用SQL查询的语法来构建功能等效的API调用序列。我们将此管道应用于最大的NL2SQL数据集之一BIRD-SQL，创建了一个包含2500多个可作为可调用工具或REST端点的API集合。我们将BIRD-SQL中的自然语言查询与基于此API池的真实API序列进行配对。我们使用此集合研究了10个公共LLM的性能，发现所有模型在确定正确的工具集（包括意图检测、带有嵌套函数调用的序列化和槽位填充任务）方面都表现不佳。我们发现模型的任务完成率极低（7-47%——取决于数据集），当模型作为与实时API环境交互的ReACT代理时，任务完成率略微提高到50%。最佳任务完成率远低于有效通用工具调用代理所需的要求，这表明当前最先进的工具调用LLM有很大的改进空间。我们还进行了详细的消融研究，例如评估可用工具数量以及工具和槽位名称混淆的影响。我们比较了模型在原始SQL生成任务上的性能，发现当前模型有时能够比API更好地利用SQL。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [464] [A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.11295)
> *双系统记：表征机器学习赋能系统的架构复杂性*

*Renato Cordeiro Ferreira* | **Main category: cs.SE**

**Keywords:** 机器学习赋能系统, 架构复杂性, 度量模型, 案例研究, 系统管理

**Comment:** 8 pages, 3 figures (3 diagrams), submitted to the ECSA2025. arXiv
  admin note: substantial text overlap with arXiv:2506.08153

> **TL;DR:** 本文旨在通过引入基于度量的架构模型来表征机器学习赋能系统（MLES）的复杂性，并以SPIRA和Ocean Guard MLES为例进行案例研究。

**AI_Comments:** 本文的创新点在于提出了一个基于度量的架构模型来量化和管理机器学习赋能系统的复杂性，这对于指导系统设计和演进具有重要意义。通过引入具体案例研究（SPIRA和Ocean Guard），增强了理论模型的实用性和可验证性。然而，抽象中并未提及模型的具体细节或初步成果，未来研究可能需要进一步阐述模型的构建过程和实际应用效果。

<details>
  <summary>Details</summary>

**Motivation:** 研究目标是调查复杂性如何影响机器学习赋能系统（MLES），以有效管理MLES的复杂性，并支持架构决策，为这些系统的启动和成长提供指导。

**Method:** 本文旨在引入一个基于度量的架构模型来表征MLES的复杂性。研究将并列呈现SPIRA和Ocean Guard MLES这两个系统的架构表示，作为创建该度量模型的案例研究。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在探讨如何有效管理机器学习赋能系统（MLES）的复杂性。为此，论文提出引入一个基于度量的架构模型来表征MLES的复杂性，以期支持架构决策并指导系统发展。文章将以SPIRA和Ocean Guard MLES这两个系统为例，进行架构表示的案例研究，以构建该度量模型。

> **摘要翻译:** 如何有效管理机器学习赋能系统（ML-enabled systems）的复杂性？本研究的目标是调查复杂性如何影响机器学习赋能系统（MLES）。为了解决这个问题，本研究旨在引入一个基于度量的架构模型来表征MLES的复杂性。目标是支持架构决策，为这些系统的启动和成长提供指导。本文并列呈现了两个系统的架构表示，它们可以作为创建基于度量架构模型的案例研究：SPIRA和Ocean Guard MLES。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [470] [ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](https://arxiv.org/abs/2506.11442)
> *ReVeal：通过迭代生成-验证实现自进化的代码智能体*

*Yiyang Jin, Kunzhao Xu, Hang Li, Xueting Han, Yanmin Zhou, Cheng Li, Jing Bai* | **Main category: cs.SE**

**Keywords:** 强化学习, 代码智能体, 自验证, 大型语言模型, 代码生成

**Comment:** 

> **TL;DR:** ReVeal是一个多轮强化学习框架，通过结合代码生成与显式自验证和工具评估，使LLM能够自进化生成和验证代码，从而提升推理能力。

**AI_Comments:** ReVeal的创新之处在于其将代码生成与显式自验证和工具评估相结合的多轮强化学习框架，有效解决了LLMs自验证的不可靠性。通过引入密集的逐轮奖励和促进生成与验证能力的协同进化，该方法显著提升了LLMs在代码推理任务上的表现，为构建更鲁棒和自主的AI智能体提供了有前景的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在大型语言模型（LLMs）的代码推理方面，缺乏来自真实环境的有意义的验证信号以及对验证的明确优化，导致自验证不可靠。

**Method:** 本文提出了ReVeal，一个多轮强化学习框架，它将代码生成与显式自验证和基于工具的评估交错进行。ReVeal使LLMs能够自主生成测试用例，调用外部工具获取精确反馈，并通过定制的强化学习算法（带有密集的逐轮奖励）来提高性能。

**Result:** ReVeal通过强化学习训练促进了模型生成和验证能力的协同进化，扩展了基础模型的推理边界，在LiveCodeBench上Pass@k指标取得了显著提升。它还支持在推理时扩展到更深层次的推理模式，代码随着推理轮次的增加而持续进化，最终超越了DeepSeek-R1-Zero-Qwen-32B。

**Conclusion:** ReVeal作为一种可扩展且有效的范式，有望构建更健壮和自主的AI智能体。

> **ai_Abstract:** ReVeal是一个针对大型语言模型（LLMs）代码推理能力的多轮强化学习框架。它通过迭代的代码生成、显式自验证和基于外部工具的评估来解决现有方法自验证不可靠的问题。ReVeal使LLMs能够自主生成测试用例并获取精确反馈，通过定制的RL算法和密集奖励来提升性能。实验证明，ReVeal促进了模型生成和验证能力的协同进化，显著提升了LLMs在LiveCodeBench上的表现，并实现了推理时的深度扩展，最终超越了现有模型。

> **摘要翻译:** 最近，可验证结果奖励的强化学习（RL）的进展显著提升了大型语言模型（LLMs）的推理能力，特别是当与多轮工具交互结合时。然而，现有方法缺乏来自真实环境的有意义的验证信号以及对验证的明确优化，导致自验证不可靠。为了解决这些限制，我们提出了ReVeal，一个多轮强化学习框架，它将代码生成与显式自验证和基于工具的评估交错进行。ReVeal使LLMs能够自主生成测试用例，调用外部工具获取精确反馈，并通过定制的强化学习算法（带有密集的逐轮奖励）来提高性能。因此，ReVeal通过强化学习训练促进了模型生成和验证能力的协同进化，扩展了基础模型的推理边界，在LiveCodeBench上Pass@k指标取得了显著提升。它还支持在推理时扩展到更深层次的推理模式，代码随着推理轮次的增加而持续进化，最终超越了DeepSeek-R1-Zero-Qwen-32B。这些发现突出了ReVeal作为构建更健壮和自主的AI智能体的可扩展且有效范式的前景。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [473] [Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic](https://arxiv.org/abs/2506.11451)
> *使用基于Transformer的BERTopic理解开源区块链软件项目中的问题类型*

*Md Nahidul Islam Opu, Md Shahidul Islam, Sara Rouhani, Shaiful Chowdhury* | **Main category: cs.SE**

**Keywords:** 区块链软件, 问题类型, BERTopic, 开源项目, 维护

**Comment:** 

> **TL;DR:** 本研究对GitHub上1,209个开源区块链项目的近50万个问题进行了大规模实证研究，使用BERTopic识别并组织了49个问题主题，发现通用软件开发问题和区块链特定问题各占一半，其中钱包管理和UI增强最突出，钱包问题解决时间最长。这些发现有助于提升区块链软件的健壮性和可维护性。

**AI_Comments:** 这项研究通过大规模数据分析，首次系统性地揭示了开源区块链项目中的问题类型及其演变趋势，其创新点在于应用了先进的BERTopic模型进行主题识别和层次化组织。研究结果对于指导区块链软件的开发、维护和工具设计具有重要意义，尤其是在识别出钱包问题作为关键瓶颈方面。其局限性可能在于数据来源仅限于GitHub，可能无法完全代表所有区块链项目的问题分布。

<details>
  <summary>Details</summary>

**Motivation:** 区块链软件系统在不同领域得到越来越多的部署，但对其开发挑战的系统理解仍然有限。

**Method:** 本研究从GitHub上的1,209个开源区块链项目中挖掘了497,742个问题，并采用基于Transformer的主题建模技术BERTopic来识别和组织问题类型。研究识别了49个不同的问题主题，并将其层次化组织成11个主要子类别。进一步分析了问题类别的演变和解决时间。

**Result:** 研究发现通用软件开发问题和区块链特定问题几乎各占一半，其中“钱包管理”和“UI增强”是最突出的主题。钱包问题不仅在频率上占主导地位，而且解决时间最长，而“机制”问题解决速度显著更快。问题频率在2016年以太坊和去中心化应用兴起后激增，但在2022年后下降。

**Conclusion:** 这些发现增强了我们对区块链软件维护的理解，为开发专门的工具和实践以提高健壮性和可维护性提供了信息。

> **ai_Abstract:** 本研究对GitHub上的1,209个开源区块链项目中的近50万个问题进行了大规模实证分析，旨在理解其开发挑战。通过使用基于Transformer的BERTopic模型，研究识别出49个问题主题，并将其归纳为11个主要子类别。结果显示，通用软件问题和区块链特定问题分布均衡，其中钱包管理和UI增强最为突出。研究还发现钱包问题出现频率高且解决时间最长，而机制问题解决速度快。此外，问题频率在2016年后显著增加，但在2022年后有所下降。这些发现为提升区块链软件的健壮性和可维护性提供了宝贵见解。

> **摘要翻译:** 区块链软件系统在不同领域得到越来越多的部署，但对其开发挑战的系统理解仍然有限。本文对从GitHub上托管的1,209个开源区块链项目中挖掘的497,742个问题进行了大规模实证研究。我们采用基于Transformer的主题建模技术BERTopic，识别出49个不同的问题主题，并将其层次化组织成11个主要子类别。我们的分析揭示，通用软件开发问题和区块链特定问题几乎各占一半，其中钱包管理和UI增强是最突出的主题。我们进一步检查了问题类别和解决时间的时间演变，发现钱包问题不仅在频率上占主导地位，而且解决时间最长。相反，机制问题解决速度显著更快。问题频率在2016年以太坊和去中心化应用兴起后激增，但在2022年后下降。这些发现增强了我们对区块链软件维护的理解，为开发专门的工具和实践以提高健壮性和可维护性提供了信息。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [477] [VulStamp: Vulnerability Assessment using Large Language Model](https://arxiv.org/abs/2506.11484)
> *VulStamp：使用大型语言模型进行漏洞评估*

*Haoshen, Ming Hu, Xiaofei Xie, Jiaye Li, Mingsong Chen* | **Main category: cs.SE**

**Keywords:** 漏洞评估, 大型语言模型, 静态分析, 强化学习, 漏洞严重性

**Comment:** 

> **TL;DR:** VulStamp是一个新颖的意图引导框架，结合静态分析、大型语言模型和强化学习来解决传统漏洞评估方法中描述质量和数据不平衡的问题，实现无描述的漏洞严重性评估。

**AI_Comments:** VulStamp的创新之处在于其“无描述”的评估方法，这直接解决了传统方法对人工描述的依赖及其固有的主观性和质量问题。结合LLM提取代码意图和RL进行提示调整以应对数据不平衡，显示了其在自动化和智能化方面的潜力。这项工作对于提高漏洞评估的效率和准确性具有重要意义，尤其是在大规模软件开发中。

<details>
  <summary>Details</summary>

**Motivation:** 现代漏洞检测工具虽然能识别大量安全缺陷，但盲目修复会导致不必要的开发开销，因为许多漏洞可利用性低或影响可忽略。现有的漏洞评估方法依赖手动描述，但描述质量和意图解释的主观性限制了其性能。因此，优化软件开发效率的关键在于漏洞严重性评估，且需要一种更有效的方法来解决现有方法的局限性。

**Method:** 本文提出了VulStamp，一个意图引导的无描述漏洞评估框架。具体来说，VulStamp结合静态分析和大型语言模型（LLM）来提取脆弱代码的意图信息。基于这些意图信息，VulStamp使用一个经过提示调整的模型进行漏洞评估。此外，为了缓解漏洞类型数据不平衡的问题，VulStamp集成了一种基于强化学习（RL）的提示调整方法来训练评估模型。

**Result:** Not mentioned in abstract

**Conclusion:** VulStamp通过结合静态分析、大型语言模型和强化学习，提供了一种新颖的、无描述的漏洞严重性评估方法，有效解决了传统方法中描述质量差和数据不平衡的挑战，从而优化了软件开发效率。

> **ai_Abstract:** VulStamp是一个创新的框架，旨在通过结合静态分析和大型语言模型（LLM）来解决现有漏洞评估方法中描述质量差和数据不平衡的问题，实现无描述的漏洞严重性评估。它利用LLM提取脆弱代码的意图信息，并使用提示调整模型进行评估，同时采用基于强化学习的提示调整方法来处理数据不平衡问题，从而优化软件开发中的漏洞修复效率。

> **摘要翻译:** 尽管现代漏洞检测工具使开发人员能够高效识别大量安全缺陷，但不加区分的修复工作往往导致不必要的开发开销。尤其考虑到很大一部分检测到的漏洞要么可利用性低，要么在实际操作环境中只会造成微不足道的冲击。因此，漏洞严重性评估已成为优化软件开发效率的关键组成部分。现有的漏洞评估方法通常依赖于与源代码工件相关联的手动编写描述。然而，由于描述质量的可变性和意图解释的主观性，这些方法的性能受到严重限制。为了解决这个问题，本文引入了VulStamp，一个新颖的意图引导框架，以促进无描述的漏洞评估。具体来说，VulStamp采用静态分析与大型语言模型（LLM）相结合的方式来提取脆弱代码的意图信息。基于这些意图信息，VulStamp使用一个经过提示调整的模型进行漏洞评估。此外，为了缓解与漏洞类型相关的数据不平衡问题，VulStamp集成了一种基于强化学习（RL）的提示调整方法来训练评估模型。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [480] [A Procedural Framework for Assessing the Desirability of Process Deviations](https://arxiv.org/abs/2506.11525)
> *评估过程偏差可取性的程序框架*

*Michael Grohs, Nadine Cordes, Jana-Rebecca Rehse* | **Main category: cs.SE**

**Keywords:** 过程偏差, 可取性评估, 程序框架, 合规性检查, 过程分析

**Comment:** 

> **TL;DR:** 本文提出了一个程序框架，旨在系统地评估过程偏差的可取性，以帮助过程分析师更有效地判断偏差是问题、可接受还是有益的。

**AI_Comments:** 该论文通过引入一个结构化的程序框架，解决了过程分析中一个关键但常被忽视的问题，即如何系统地评估过程偏差的可取性。其创新之处在于将主观的偏差评估过程标准化和程序化，并结合了理论（文献回顾）和实践（专家访谈）的见解。这对于提高过程改进的效率和准确性具有重要意义，有助于将单纯的偏差识别提升到有意义的决策支持层面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的合规性检查技术可以识别过程执行与模型之间的偏差，但无法判断这些偏差的可取性（即是问题、可接受还是有益的）。目前，过程分析师通常以手动、临时的方式进行此类评估，这种方式耗时、主观且不可复制。

**Method:** 本文提出了一个程序框架，提供了一个分步方法，用于识别需要考虑的输入因素及其顺序，以便将偏差分类为互斥的可取性类别，每个类别都链接到行动建议。该框架基于对现有偏差可取性文献的审查和概念化，并辅以对过程分析实践者和研究人员的访谈所获得的经验见解。

**Result:** 通过与实践者进行可取性评估任务，评估了该框架。结果表明，该框架有效地使实践者能够简化评估过程，实现彻底而简洁的评估。

**Conclusion:** 本文提出了一个程序框架，用于系统地评估过程偏差的可取性，解决了现有手动评估方法的局限性，并被证明能有效帮助实践者进行高效评估。

> **ai_Abstract:** 本文提出了一个系统评估过程偏差可取性的程序框架，旨在解决现有手动评估方法耗时、主观且不可复制的问题。该框架提供了一个分步指南，基于文献回顾和专家访谈，帮助过程分析师将偏差分类并提出行动建议。通过实践者评估任务，验证了该框架能有效简化评估流程，提高评估效率和一致性。

> **摘要翻译:** 合规性检查技术帮助过程分析师识别过程执行与过程模型之间的偏差发生在哪里以及如何发生。然而，它们无法确定这些偏差的可取性，即它们是否对过程有问题、可接受甚至有益。这种可取性评估对于制定行动至关重要，但过程分析师通常以手动、临时的方式进行，这可能耗时、主观且不可复制。为了解决这个问题，本文提出了一个程序框架，指导过程分析师系统地评估偏差的可取性。它提供了一种分步方法，用于识别需要考虑哪些输入因素以及按什么顺序将偏差分类为互斥的可取性类别，每个类别都与行动建议相关联。该框架基于对现有偏差可取性文献的审查和概念化，并辅以从对过程分析实践者和研究人员的访谈中获得的经验见解。我们通过与实践者进行的可取性评估任务对该框架进行了评估，结果表明该框架有效地使他们能够简化评估，实现彻底而简洁的评估。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [483] [Augmenting the Generality and Performance of Large Language Models for Software Engineering](https://arxiv.org/abs/2506.11548)
> *增强大型语言模型在软件工程领域的通用性和性能*

*Fabian C. Peña* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 软件工程, 非代码任务, 幻觉检测, 性能增强

**Comment:** 

> **TL;DR:** 本研究旨在通过深入理解LLM在非代码任务上的表现、评估其作为SE基础知识来源的能力以及检测幻觉，从而提升大型语言模型在软件工程（SE）中的通用性和性能。

**AI_Comments:** 该研究的创新点在于将LLM的应用范围从传统的代码生成和分析扩展到更广泛的软件工程非代码任务，如概念化和设计。它还关注了LLM在SE领域作为基础知识来源的潜力以及幻觉检测这一关键问题，这对于LLM在专业领域的可靠应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在软件工程（SE）领域（尤其是代码生成和分析）的应用日益广泛，但其在更广泛的SE实践（如概念化、设计和其他非代码任务）中的应用仍未被充分探索。

**Method:** 该研究旨在通过以下三点来增强LLM在SE中的通用性和性能：1) 深入理解不同特性的LLM在各种非代码任务上的表现；2) 评估LLM作为SE基础知识来源的能力；3) 有效检测SE陈述中的幻觉。预期的贡献包括在领域特定数据集上训练和评估多种LLM，SE基础知识的新基准，以及检测幻觉的方法。

**Result:** 在各种非代码任务的性能改进方面，初步结果是很有希望的。

**Conclusion:** 初步结果表明，所提出的方法在提升大型语言模型在软件工程非代码任务中的通用性和性能方面具有潜力。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLM）在软件工程（SE）领域中，尤其是在非代码任务（如概念化和设计）方面应用不足的问题。通过探究LLM在非代码任务上的表现、评估其作为SE基础知识来源的能力以及开发幻觉检测方法，该研究旨在提升LLM在SE中的通用性和性能。初步结果显示在非代码任务的性能提升上前景广阔。

> **摘要翻译:** 大型语言模型（LLM）正在彻底改变软件工程（SE），尤其是在代码生成和分析方面。然而，它们在更广泛的SE实践中的应用，包括概念化、设计和其他非代码任务，仍未被充分探索。本研究旨在通过以下方式增强LLM在SE领域的通用性和和性能：（1）深入理解不同特性的LLM在各种非代码任务上的表现，（2）评估它们作为SE基础知识来源的能力，以及（3）有效检测SE陈述中的幻觉。预期的贡献包括在领域特定数据集上训练和评估的各种LLM、SE基础知识的新基准，以及检测幻觉的方法。在各种非代码任务的性能改进方面，初步结果是很有希望的。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [486] [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](https://arxiv.org/abs/2506.11559)
> *利用 GPT-4 生成漏洞见证单元测试*

*Gábor Antal, Dénes Bán, Martin Isztin, Rudolf Ferenc, Péter Hegedűs* | **Main category: cs.SE**

**Keywords:** GPT-4, 单元测试生成, 软件漏洞, 自动化测试, 大型语言模型

**Comment:** 

> **TL;DR:** 本文探讨了利用 GPT-4 自动生成用于识别软件漏洞的单元测试的能力，发现它能够生成语法正确的测试用例和有用的模板。

**AI_Comments:** 本文探索了大型语言模型 GPT-4 在软件安全领域的一个实用应用，即自动生成漏洞见证单元测试。其创新之处在于直接评估了 GPT-4 在此任务上的能力，而无需进行领域特定的预训练。然而，一个明显的局限性是自动验证语义正确性的比率较低，这表明在实际应用中仍需要人工干预或更复杂的验证机制来确保测试的有效性。尽管如此，研究结果为利用 LLM 辅助软件测试和安全提供了积极的初步证据。

<details>
  <summary>Details</summary>

**Motivation:** 在软件开发生命周期中，测试对于质量保证至关重要，但创建此类测试是一个复杂、耗费资源的手动过程。本文旨在探索利用大型语言模型 GPT-4 自动生成单元测试以帮助识别潜在漏洞。

**Method:** 本文从漏洞的角度，探讨了 GPT-4 自动生成单元测试的能力。研究人员检查了 VUL4J 数据集的一个子集，其中包含真实的漏洞及其对应的修复，以确定 GPT-4 是否能够根据修复前后的代码生成语法和/或语义正确的单元测试。研究重点关注代码上下文的影响、GPT-4 自我修正能力的有效性以及生成测试用例的主观可用性。

**Result:** GPT-4 在未经领域特定预训练的情况下，生成语法正确测试用例的成功率为 66.5%。尽管语义正确性只能在 7.5% 的情况下自动验证，但主观评估表明 GPT-4 通常能生成测试模板，这些模板只需相对较少的手动工作即可进一步开发成功能齐全的漏洞见证测试。

**Conclusion:** 尽管数据有限，但初步发现表明 GPT-4 可以有效地用于生成漏洞见证测试。它可能无法完全自主运行，但在部分自动化过程中肯定发挥着重要作用。

> **ai_Abstract:** 本文研究了利用 GPT-4 自动生成用于识别软件漏洞的单元测试，以应对传统手动测试的复杂性和资源消耗。通过在 VUL4J 数据集上进行测试，研究发现 GPT-4 能够生成 66.5% 的语法正确测试用例。尽管只有 7.5% 的测试能自动验证语义正确性，但主观评估表明 GPT-4 提供的测试模板具有高可用性，只需少量手动修改即可成为功能性漏洞见证测试。研究结论认为，GPT-4 能在半自动化漏洞测试流程中发挥重要作用。

> **摘要翻译:** 在软件开发生命周期中，测试在质量保证中扮演着关键角色。适当的测试不仅能提高代码覆盖率并防止回归，还能确保识别并有效修复软件中任何潜在的漏洞。然而，创建此类测试是一个复杂、耗费资源的手动过程。为了帮助开发人员和安全专家，本文从漏洞的角度探讨了最广泛使用的大型语言模型之一 GPT-4 的自动单元测试生成能力。我们检查了 VUL4J 数据集的一个子集，其中包含真实的漏洞及其对应的修复，以确定 GPT-4 是否能够根据修复前后的代码（作为漏洞缓解的证据）生成语法和/或语义正确的单元测试。我们重点关注代码上下文的影响、GPT-4 自我修正能力的有效性以及生成测试用例的主观可用性。我们的结果表明，在没有领域特定预训练的情况下，GPT-4 能够生成语法正确的测试用例的成功率为 66.5%。尽管修复的语义正确性只能在 7.5% 的情况下自动验证，但我们的主观评估显示，GPT-4 通常能生成测试模板，这些模板只需相对较少的手动工作即可进一步开发成功能齐全的漏洞见证测试。因此，尽管数据有限，但我们的初步发现表明 GPT-4 可以有效地用于生成漏洞见证测试。它可能无法完全自主运行，但在部分自动化过程中肯定发挥着重要作用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [489] [Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study](https://arxiv.org/abs/2506.11561)
> *识别LLM驱动的漏洞修复中的有效上下文：一项初步研究*

*Gábor Antal, Bence Bogenfürst, Rudolf Ferenc, Péter Hegedűs* | **Main category: cs.SE**

**Keywords:** LLM, 漏洞修复, GPT-4o, 上下文信息, 提示工程

**Comment:** 

> **TL;DR:** 本研究探讨了GPT-4o在Java漏洞修复中的表现，发现特定上下文信息（如CVE和手动提取的代码上下文）能显著提高修复率，且集成提示策略优于基线。

**AI_Comments:** 这项初步研究为LLM在漏洞修复领域的应用提供了宝贵的见解。其创新点在于系统地评估了不同上下文信息对修复效果的影响，并发现结合CVE信息和手动代码上下文的集成提示策略能显著提升性能。研究结果表明，仅仅依靠模型本身的迭代更新可能不足以带来性能的线性提升，而精心设计的提示工程和上下文管理对于优化LLM在特定任务中的表现至关重要。未来研究可以进一步探索更智能的上下文提取方法和更复杂的提示组合策略。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大型语言模型（LLMs）在自动化漏洞检测和修复方面的潜力，本文旨在探究不同上下文信息如何影响GPT-4o在自动漏洞修复（AVR）任务中的能力。

**Method:** 研究使用GPT-4o模型，在Vul4J数据集上对Java漏洞进行修复。通过对比GPT-4o与GPT-4在相同提示下的表现，并评估了9个包含不同上下文信息（如CWE、CVE信息和手动提取的代码上下文）的自定义提示。每个提示对42个漏洞执行三次，修复候选方案通过Vul4J的自动化测试框架进行验证。

**Result:** 结果显示，GPT-4o在相同提示下平均表现比GPT-4差11.9%，但在三次运行中总共修复了10.5%更多的独特漏洞。CVE信息显著提高了修复率，而任务描述的长度影响最小。将CVE指导与手动提取的代码上下文相结合，产生了最佳性能。使用前三名提示，GPT-4o至少修复了26个（62%）漏洞，优于原始基线（40%）和其复现（45%）。

**Conclusion:** 集合提示策略可以显著提高零样本设置下的漏洞修复能力。

> **ai_Abstract:** 本研究探讨了GPT-4o在Java漏洞修复中的表现，特别关注不同上下文信息对自动化漏洞修复能力的影响。通过与GPT-4对比并测试包含CWE/CVE及代码上下文的新提示，发现尽管GPT-4o在单次运行时表现略逊，但其在多轮运行中能修复更多独特漏洞。研究强调CVE信息和手动提取代码上下文对提升修复率的关键作用，并指出结合这些信息的集成提示策略能显著提高零样本设置下的漏洞修复效果。

> **摘要翻译:** 近期大型语言模型（LLMs）的进步在软件系统的自动化漏洞检测和修复方面展现出前景。本文调查了GPT-4o在修复广泛使用的Vul4J数据集中Java漏洞的性能，探索了不同上下文信息如何影响自动化漏洞修复（AVR）能力。我们比较了最新GPT-4o与之前GPT-4在相同提示下的表现。我们评估了我们精心设计的九个额外提示，这些提示包含各种上下文信息，例如CWE或CVE信息，以及手动提取的代码上下文。每个提示在42个漏洞上执行三次，生成的修复候选方案使用Vul4J的自动化测试框架进行验证。 我们的结果显示，GPT-4o在相同提示下平均表现比GPT-4差11.9%，但在三次运行中总共修复了10.5%更多的独特漏洞。CVE信息显著提高了修复率，而任务描述的长度影响最小。将CVE指导与手动提取的代码上下文相结合，产生了最佳性能。使用我们的前三名提示，GPT-4o至少修复了26个（62%）漏洞，优于原始基线（40%）及其复现（45%），这表明集合提示策略可以在零样本设置下改善漏洞修复。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [493] [MBSR at Work: Perspectives from an Instructor and Software Developers](https://arxiv.org/abs/2506.11588)
> *工作中的MBSR：一位导师和软件开发人员的视角*

*Simone Romano, Alberto Conforti, Gloria Guidetti, Sara Viotti, Rachele Ceschin, Giuseppe Scanniello* | **Main category: cs.SE**

**Keywords:** MBSR, 软件开发, 压力管理, 定性研究, 工作场所健康

**Comment:** 

> **TL;DR:** 尽管最初持怀疑态度，软件开发人员在工作中参与MBSR后个人有所改善，但将其融入工作仍具挑战。

**AI_Comments:** 这项研究的创新之处在于首次将MBSR应用于软件开发这一高压工作环境进行定性研究，填补了现有研究的空白。其重要性在于揭示了MBSR对开发人员个人改善的潜力，同时也指出了在工作环境中整合MBSR的实际挑战，为未来MBSR在特定职业群体中的推广和优化提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** MBSR在其他工作环境中已有研究，但在软件开发（SD）这一充满压力的领域（如时间压力和任务不确定性）中，MBSR的应用尚未被研究。本研究旨在通过定性方法深入了解MBSR在SD工作环境中的应用以及关键利益相关者（开发者和导师）的感知。

**Method:** 本研究采用定性研究方法，具体为半结构化访谈，以收集参与MBSR项目的跨国公司软件开发人员以及项目导师的初步发现和观点。

**Result:** 研究结果显示，尽管最初持怀疑态度，参与MBSR的软件开发人员认识到个人因MBSR练习而有所改善。然而，将MBSR技术整合到工作环境中仍然面临挑战。

**Conclusion:** MBSR实践能为软件开发人员带来个人层面的改善，但其在工作环境中的实际整合仍是一个难题。

> **ai_Abstract:** 本研究通过对软件开发人员和MBSR导师进行半结构化访谈，初步探讨了正念减压（MBSR）项目在软件开发工作环境中的应用感知。研究发现，尽管软件开发人员最初持怀疑态度，但他们普遍认为MBSR实践带来了个人改善，然而将MBSR技术有效整合到日常工作中仍面临挑战。

> **摘要翻译:** 在本文中，我们展示了一项定性研究（即半结构化访谈）的初步发现，该研究探讨了跨国公司参与MBSR项目的软件开发人员以及领导该项目的导师如何看待在软件开发（SD）工作环境中实施的正念减压（MBSR）项目。MBSR是一种深刻的个人体验式练习，旨在帮助个体管理压力，特别是在高压环境中，如工作场所、医疗保健、教育以及其他要求苛刻的专业或个人情境。尽管MBSR已在不同的工作环境中进行过实验；但令人惊讶的是，它从未在SD工作环境中进行过研究，而该环境存在开发人员经历的多种压力因素（例如，时间压力以及对特定任务内容及其结果的不确定性）。在这方面，定性研究可以为MBSR在SD工作环境中的应用提供宝贵的见解，这些见解是标准化定量测量无法捕捉的。鉴于MBSR导师和软件开发人员是MBSR项目在SD工作环境中实施的关键利益相关者，了解他们的第一手经验可以更详细地描绘所调查的现象。我们研究最重要的结论可以总结如下：尽管最初持怀疑态度，开发人员认识到由于MBSR实践带来了个人改善，尽管将MBSR技术整合到工作环境中仍然具有挑战性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [496] [Retrieval-Augmented Code Review Comment Generation](https://arxiv.org/abs/2506.11591)
> *检索增强型代码审查评论生成*

*Hyunsun Hong, Jongmoon Baik* | **Main category: cs.SE**

**Keywords:** 代码审查, 评论生成, 检索增强生成, 预训练语言模型, 信息检索

**Comment:** 

> **TL;DR:** 本文提出一种检索增强生成（RAG）方法用于代码审查评论生成（RCG），结合了生成式和信息检索式方法的优点，在性能上超越了两者。

**AI_Comments:** 这项工作通过引入检索增强生成（RAG）框架到代码审查评论生成（RCG）领域，提供了一种新颖且有效的方法。它巧妙地结合了大型语言模型在语义理解和生成方面的能力，以及信息检索在处理稀有词汇和提供具体上下文方面的优势。这种混合方法解决了单一范式固有的局限性，特别是在生成低频但关键的领域特定术语方面。该研究的重要性在于其在提高自动化代码审查质量方面的潜力，能显著辅助开发者，提高软件开发效率和代码质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的代码审查评论生成方法（RCG）主要分为基于生成的和基于信息检索的。基于生成的方法在生成低频但语义重要的词汇时表现不佳；基于信息检索的方法擅长恢复稀有标记但缺乏适应新代码上下文的灵活性。为了弥合这两种方法的差距，需要一种结合两者优点的新方法。

**Method:** 本文提出利用检索增强生成（RAG）来改进代码审查评论生成（RCG），通过将预训练语言模型与检索到的代码审查范例进行条件化处理。通过提供相关示例，模型能够更好地生成准确的审查评论。

**Result:** 在Tufano et al.基准测试上，RAG-based RCG优于生成式和信息检索式RCG。与生成式RCG相比，其精确匹配率提高了1.67%，BLEU分数提高了4.25%。它还将低频真实标记的生成率提高了24.01%。此外，检索到的范例数量增加时，性能也会提高。

**Conclusion:** 检索增强型代码审查评论生成（RAG-based RCG）能够有效地结合生成式和信息检索式方法的优势，显著提升了代码审查评论生成的质量，特别是在处理低频词汇和适应新代码上下文方面。

> **ai_Abstract:** 本文提出了一种检索增强生成（RAG）方法，用于自动化代码审查评论生成（RCG），旨在结合现有生成式和信息检索式方法的优点。生成式方法擅长语义理解但难以生成低频词，而信息检索式方法能处理稀有词但缺乏灵活性。RAG方法通过将预训练语言模型与检索到的代码审查范例相结合，有效解决了这些问题。实验结果表明，RAG-based RCG在精确匹配、BLEU分数以及低频词生成方面均显著优于现有方法。

> **摘要翻译:** 自动代码审查评论生成（RCG）旨在通过自动为代码更改生成自然语言反馈来协助开发人员。现有方法主要分为基于生成的（使用预训练语言模型）或基于信息检索（IR）的（重用过去类似示例中的评论）。虽然基于生成的方法利用在大型代码-自然语言语料库上的代码特定预训练来学习代码和自然语言之间的语义关系，但由于其概率性质，它们通常难以生成低频但语义重要的标记。相比之下，基于IR的方法通过从现有示例中复制来擅长恢复此类稀有标记，但缺乏适应新代码上下文的灵活性——例如，当输入代码包含检索数据库中不存在的标识符或结构时。为了弥合基于生成和基于IR的方法之间的差距，这项工作提出利用检索增强生成（RAG）进行RCG，通过对检索到的代码审查范例对预训练语言模型进行条件化处理。通过提供相关示例，说明类似代码之前是如何被审查的，模型能够更好地生成准确的审查评论。我们在Tufano et al.基准测试上的评估表明，基于RAG的RCG优于基于生成和基于IR的RCG。与基于生成的RCG相比，它实现了高达+1.67%的精确匹配率和+4.25%的BLEU分数。它还将低频真实标记的生成率提高了24.01%。我们还发现，随着检索到的范例数量的增加，性能也会提高。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [500] [Further Evidence on a Controversial Topic about Human-Based Experiments: Professionals vs. Students](https://arxiv.org/abs/2506.11597)
> *关于人因实验争议性话题的进一步证据：专业人士 vs. 学生*

*Simone Romano, Francesco Paolo Sferratore, Giuseppe Scanniello* | **Main category: cs.SE**

**Keywords:** 软件工程, 学生, 专业人士, 实验有效性, 缺陷修复

**Comment:** 

> **TL;DR:** 一项比较学生和专业人士在缺陷修复任务中表现的研究发现，学生表现优于专业人士，这与现有证据有所不同，旨在引发关于学生参与实验的讨论。

**AI_Comments:** 这篇论文通过实证研究为软件工程领域中学生作为实验参与者的外部有效性争议提供了新的视角。其创新之处在于，在相对更真实的专业人士实验环境下，学生出人意料地表现优于专业人士，挑战了普遍的看法。这强调了实验设置和情境复杂性对结果可能产生的重要影响。论文的价值在于它没有强行得出确定性结论，而是旨在引发更深入的讨论，并促使未来的研究关注影响SE任务的复杂因素和实验的真实性，这对于提升软件工程实验研究的质量和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 软件工程（SE）中基于人类的受控实验大多依赖学生作为参与者，这引发了对其外部有效性的担忧，特别是学生实验结果的真实性及其在软件行业的适用性受到质疑。本研究旨在为这一争议点提供进一步证据。

**Method:** 研究比较了62名计算机科学专业的本科生和42名来自两家跨国公司的软件专业人士在同一Java程序的缺陷修复任务中的表现。实验设置存在一些差异，例如，专业人士的实验环境更真实，面临了中断等压力因素。

**Result:** 考虑到两组参与者之间的差异，收集到的数据显示学生在缺陷修复方面表现优于专业人士。这在一定程度上与过去的经验证据不同。

**Conclusion:** 本研究结果并非提供确定性结论，而是旨在激发关于在实验中使用学生的讨论，并为未来的研究铺平道路。具体而言，结果鼓励研究者检查影响软件工程任务的复杂因素，并尽可能使实验更真实。

> **ai_Abstract:** 本文旨在解决软件工程领域中人因实验外部有效性的争议，即学生作为实验参与者的适用性问题。通过比较62名学生和42名软件专业人士在Java缺陷修复任务中的表现，研究发现学生在缺陷修复方面优于专业人士，这与现有的一些经验证据相悖。研究强调，此结果并非最终结论，而是旨在激发关于学生参与实验的讨论，并鼓励未来的研究关注影响SE任务的复杂因素以及实验的真实性。

> **摘要翻译:** 大多数软件工程（SE）中基于人类的受控实验都依赖学生作为参与者，这引发了对其外部有效性的担忧。具体来说，从学生那里获得的结果的真实性及其对软件行业的适用性仍然存在疑问。在这篇简短的论文中，我们为这一争议点提供了进一步的证据。为此，我们比较了62名学生和42名软件专业人士在同一Java程序上的缺陷修复任务中的表现。学生是计算机科学学士课程的在读生，而专业人士则受雇于两家跨国公司（其中一家公司的专业人士来自两个办事处）。两组（学生和专业人士）的实验设置存在一些差异。例如，专业人士实验的实验环境更真实；即，他们在缺陷修复任务中面临一些压力因素，例如中断。考虑到两组参与者之间的差异，收集到的数据显示学生在缺陷修复方面表现优于专业人士。这在一定程度上与过去的经验证据有所不同。我们的结果并非旨在提供明确的结论，而是旨在促进关于在实验中使用学生的讨论，并为未来的研究铺平道路。具体来说，我们的结果鼓励我们检查影响SE任务的复杂因素，使实验尽可能真实。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [504] [Understanding API Usage and Testing: An Empirical Study of C Libraries](https://arxiv.org/abs/2506.11598)
> *理解API使用和测试：一项针对C库的实证研究*

*Ahmed Zaki, Cristian Cadar* | **Main category: cs.SE**

**Keywords:** API使用, API测试, C库, 实证研究, LibProbe

**Comment:** The 29th International Conference on Evaluation and Assessment in
  Software Engineering, 17 to 20 June, 2025, Istanbul, Turkey

> **TL;DR:** 一项对21个流行C库的实证研究发现，库开发者并未根据API的实际使用情况来优先测试，导致流行API经常测试不足，并提出可利用客户端测试套件来改进库测试。

**AI_Comments:** 这项研究的创新之处在于它是首次大规模比较C/C++生态系统中API使用和API测试的研究。它揭示了当前库开发中普遍存在的测试盲点，即流行API可能测试不足，这对于提升软件质量和效率具有重要意义。LibProbe框架的开发也为后续相关研究提供了有力的工具。研究结果为库开发者提供了直接且可操作的建议，强调了利用真实世界使用数据来优化测试策略的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 对于库开发者而言，了解其API在实际应用中的使用情况至关重要，这有助于他们根据数据驱动的决策来优先处理错误报告、功能请求和测试活动。

**Method:** 本研究进行了一项实证研究，分析了21个流行的开源C库（及其3,061个C/C++客户端）的API使用情况。研究比较了客户端的API使用情况与库测试套件对API的测试程度。为此，研究开发了一个名为LibProbe的框架，用于分析大量客户端并生成相关指标。

**Result:** 研究发现库开发者并未根据客户端对API的使用情况来优先分配精力，导致流行API经常测试不足。例如，在LMDB中，45%被客户端使用的API未被库测试套件测试。研究还表明，可以利用客户端测试套件来改进库测试，例如在LMDB中将覆盖率提高14.7%，且这些测试能更好地反映API的实际使用情况。

**Conclusion:** 库开发者在API测试优先级上未能充分考虑API的实际使用情况，导致重要API可能测试不足。利用客户端测试套件是改进库测试有效且实际的方法，因为它能提供更具代表性的使用模式。

> **ai_Abstract:** 本研究对21个流行的开源C库及其3061个C/C++客户端进行了实证分析，探讨了API的使用情况与测试覆盖之间的关系。研究发现，库开发者在API测试中未能充分考虑API的实际使用频率，导致许多常用API测试不足。为此，研究开发了LibProbe框架以支持大规模分析。研究还指出，利用客户端测试套件可以有效提升库的测试覆盖率和实用性，弥补了库自身测试的不足。

> **摘要翻译:** 对于库开发者而言，了解其应用程序编程接口（API）在实际应用中的使用情况具有不可估量的价值。了解客户端如何使用其API，可以帮助他们根据数据驱动的决策来优先处理错误报告、功能请求和测试活动。例如，关于某个API的错误报告的优先级可以部分地由该API的使用广泛程度来决定。
在本文中，我们提出了一项实证研究，分析了21个流行的开源C库（如OpenSSL和SQLite）的API使用情况，这些库总共有3,061个C/C++客户端。我们比较了客户端的API使用情况与库测试套件对API的测试程度，为库开发者提供了可操作的见解。据我们所知，这是首次大规模比较C/C++生态系统中API使用和API测试的研究。我们的研究表明，库开发者并未根据客户端如何使用其API来优先分配他们的精力，流行的API往往测试不足。例如，在流行的键值存储系统LMDB中，45%的API被客户端使用但未被库测试套件测试。我们进一步表明，可以利用客户端测试套件来改进库测试，例如在LMDB中将覆盖率提高14.7%，其重要优势在于这些测试代表了API在实际领域中的使用方式。
为了我们的实证研究，我们开发了LibProbe，这是一个可用于分析给定库的大量客户端并生成对库开发者有用的各种指标的框架。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [507] [Accelerating Delta Debugging through Probabilistic Monotonicity Assessment](https://arxiv.org/abs/2506.11614)
> *加速Delta调试通过概率单调性评估*

*Yonggang Tao, Jingling Xue* | **Main category: cs.SE**

**Keywords:** Delta Debugging, Probabilistic Monotonicity Assessment, Program Reduction, Debugging Efficiency, DDMIN

**Comment:** Accepted by EASE 2025 (The 29th International Conference on
  Evaluation and Assessment in Software Engineering), 17-20 June 2025,
  Istanbul, Turkey. 11 pages

> **TL;DR:** 本文提出概率单调性评估（PMA），通过动态建模和评估搜索空间的单调性，显著加速Delta调试算法，同时保持或提高其有效性。

**AI_Comments:** 本文的创新点在于引入概率单调性评估（PMA）来解决Delta调试中非单调性假设的问题，这使得算法能够更智能地跳过冗余测试。其重要性在于显著提升了Delta调试的效率，这对于软件调试和错误定位具有实际应用价值。通过量化单调性并进行概率性排除，PMA在不牺牲质量的前提下实现了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** Delta调试假设搜索空间单调性，但在实践中此假设不总是成立。这导致冗余测试，降低效率。

**Method:** 引入概率单调性评估（PMA），它基于先前的测试动态建模和评估搜索空间的单调性，并使用置信函数量化单调性，从而允许概率性排除非故障诱导程序的子集。

**Result:** 相较于CHISEL，PMA处理时间减少59.2%，还原过程加速3.32倍，最终还原程序大小减少6.7%。相较于ProbDD，PMA处理时间减少22.0%，还原过程加速1.34倍，最终还原程序大小减少3.0%。

**Conclusion:** PMA显著提高了Delta调试的效率，同时保持或增强了其有效性。

> **ai_Abstract:** 本文提出概率单调性评估（PMA），旨在解决Delta调试中搜索空间非单调性导致效率低下的问题。PMA通过动态评估单调性并概率性地排除冗余测试，显著加速了DDMIN风格算法。实验结果表明，PMA在处理时间、缩减速度和最终程序大小方面均优于现有工具，证明了其在提高Delta调试效率和有效性方面的潜力。

> **摘要翻译:** Delta调试假设搜索空间单调性：如果一个程序导致故障，那么该程序的任何超集也将导致相同的故障，从而允许排除不引起故障的程序子集。然而，这个假设在实践中并非总是成立。本文引入了概率单调性评估（PMA），在不牺牲有效性的前提下，提高了DDMIN风格算法的效率。PMA根据调试过程中尝试过的先前测试动态建模和评估搜索空间的单调性，并使用置信函数量化单调性，从而能够概率性地排除不引起故障的程序子集。我们的方法显著减少了原本会执行的冗余测试，同时不影响缩减的质量。
我们对照两种领先的DDMIN风格工具CHISEL和ProbDD评估了PMA。我们的发现表明，与CHISEL相比，PMA将处理时间缩短了59.2%，将缩减过程（即每秒删除的令牌数量）加速了3.32倍，并将最终缩减程序的尺寸减小了6.7%。与ProbDD相比，PMA将处理时间缩短了22.0%，在缩减过程中实现了1.34倍的加速，并进一步将最终缩减程序的尺寸减小了3.0%。这些发现证实了PMA在显著提高Delta调试效率的同时保持或增强其有效性的作用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [511] [An Empirical study on LLM-based Log Retrieval for Software Engineering Metadata Management](https://arxiv.org/abs/2506.11659)
> *基于LLM的软件工程元数据管理日志检索的实证研究*

*Simin Sun, Yuchuan Jin, Miroslaw Staron* | **Main category: cs.SE**

**Keywords:** LLM, 日志检索, 自动驾驶系统, 自然语言处理, 软件工程

**Comment:** 

> **TL;DR:** 本文提出了一种基于大型语言模型（LLM）的方法，通过结合日志数据和视频记录，实现自动驾驶系统日志的自然语言检索，提高了检索效率和可靠性。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于自动驾驶系统的日志检索，通过结合多模态数据（日志和视频）和自然语言处理能力，极大地简化了复杂日志数据的查询过程。这对于软件工程中的元数据管理具有重要意义，尤其是在处理高维、异构数据时。其提出的量化可靠性指标也增加了结果的可信度。该方法有望提高开发者的工作效率，降低ADS开发的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 开发自动驾驶系统会产生大量日志数据，但由于信号种类繁多、开发者对信号意义不熟悉以及传统SQL查询要求领域和数据库专业知识，导致开发者难以有效定位特定驾驶场景。

**Method:** 本文提出了一种LLM辅助的方法，将信号日志数据与测试驾驶视频记录相结合，实现基于自然语言的场景搜索。该方法利用场景距离图和相对差距指标来评估查询结果的可靠性，并实现为一个API，用于高效的数据库查询和记录检索，同时配合视频帧进行可视化。

**Result:** 在开放工业数据集上的评估表明，该方法提高了场景检索的效率和可靠性，并消除了对单一数据源和传统SQL的依赖。

**Conclusion:** 该研究成功地提出并验证了一种基于LLM的日志检索方法，有效解决了自动驾驶系统日志管理中场景定位的挑战，显著提升了检索的便利性和准确性。

> **ai_Abstract:** 本文提出了一种LLM辅助的日志检索方法，旨在解决自动驾驶系统海量日志数据中特定驾驶场景难以定位的问题。通过结合信号日志和视频记录，并利用自然语言查询，该方法显著降低了对专业领域知识和SQL技能的依赖。研究引入了场景距离图和相对差距指标来量化查询结果的可靠性，并将其实现为API，提供高效的检索和可视化。在实际数据集上的评估证明，该方法有效提升了场景检索的效率和可靠性，摆脱了传统SQL和单一数据源的限制。

> **摘要翻译:** 开发自动驾驶系统（ADS）涉及生成和存储来自测试驾驶的大量日志数据，这对于验证、研究和模拟至关重要。然而，这些以不同持续时间记录的高频日志给开发者定位特定驾驶场景带来了挑战。这种困难源于代表各种车辆组件和驾驶条件的广泛信号，以及一些开发者对这些信号详细含义的不熟悉。传统的基于SQL的查询加剧了这一挑战，因为它要求领域专业知识和数据库知识，并且通常产生难以验证准确性的结果。
本文介绍了一种由大型语言模型（LLM）支持的方法，该方法将信号日志数据与测试驾驶的视频记录相结合，实现了基于自然语言的场景搜索，同时减少了对专业知识的需求。通过利用场景距离图和相对差距指标，它提供了可量化的指标来评估查询结果的可靠性。该方法被实现为一个API，用于高效的数据库查询和相关记录的检索，并与视频帧配对以进行直观的可视化。在开放工业数据集上的评估表明，该方法提高了场景检索的效率和可靠性，消除了对单一数据源和传统SQL的依赖。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [515] [SoK: Automated Vulnerability Repair: Methods, Tools, and Assessments](https://arxiv.org/abs/2506.11697)
> *SoK: 自动化漏洞修复：方法、工具与评估*

*Yiwei Hu, Zhen Li, Kedie Shu, Shenghua Guan, Deqing Zou, Shouhuai Xu, Bin Yuan, Hai Jin* | **Main category: cs.SE**

**Keywords:** 自动化漏洞修复, 漏洞修复, Vul4C, 系统化知识, 软件漏洞

**Comment:** The full version of "SoK: Automated Vulnerability Repair: Methods,
  Tools, and Assessments" accepted by the 34th USENIX Security Symposium
  (USENIX Security 2025)

> **TL;DR:** 本文系统性地综述了自动化漏洞修复（AVR）的方法、工具，并使用新构建的C/C++基准数据集（Vul4C）和现有的Java数据集（Vul4J）对它们进行了评估。

**AI_Comments:** 作为一篇“知识系统化”（SoK）论文，本文通过提供一个关键领域的结构化概述而具有重要意义。其最具创新性的贡献在于创建了Vul4C，这是第一个全面的C/C++漏洞修复基准数据集，直接解决了现有研究中的一个主要限制（缺乏标准化、大规模的评估数据集）。该基准对于C/C++程序AVR领域的未来比较研究和进展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着软件复杂性的增加，漏洞数量稳步增长。手动漏洞修复耗时耗力，因此自动化漏洞修复（AVR）变得至关重要。

**Method:** 本文通过AVR工作流的三个步骤（漏洞分析、补丁生成、补丁验证）系统化地介绍了AVR方法。针对C/C++程序，构建了首个C/C++漏洞修复基准数据集Vul4C（包含144个漏洞、利用和补丁）。使用Vul4C评估了七个C/C++ AVR工具，并使用第三方Vul4J数据集评估了两个Java AVR工具。

**Result:** 本文系统化地总结了AVR方法。构建了第一个C/C++漏洞修复基准数据集Vul4C。评估了七个C/C++ AVR工具和两个Java AVR工具的性能。

**Conclusion:** 本文全面概述并评估了自动化漏洞修复（AVR）领域，强调了标准化基准数据集（如Vul4C）的重要性，并讨论了未来的研究方向。

> **ai_Abstract:** 本SoK论文通过将自动化漏洞修复（AVR）的工作流分为漏洞分析、补丁生成和补丁验证来系统地进行综述。为解决C/C++ AVR工具缺乏标准化评估的问题，作者引入了Vul4C，一个包含144个C/C++漏洞及其利用和补丁的新型基准数据集。论文使用Vul4C评估了七个C/C++ AVR工具，并使用Vul4J数据集评估了两个Java AVR工具，最后讨论了AVR未来的研究方向。

> **摘要翻译:** 软件复杂性的增加导致漏洞的稳步增长。漏洞修复研究如何修复软件漏洞。由于依赖于人工专家，手动漏洞修复是劳动密集型且耗时的，这突出了自动化漏洞修复（AVR）的重要性。在本SoK中，我们通过AVR工作流的三个步骤：漏洞分析、补丁生成和补丁验证，系统化地介绍了AVR方法。我们评估了C/C++和Java程序的AVR工具，因为它们已被社区广泛研究。由于现有C/C++程序的AVR工具使用不同的数据集进行评估，这些数据集通常包含少量漏洞，因此我们构建了第一个C/C++漏洞修复基准数据集，名为Vul4C，其中包含144个漏洞及其利用和补丁。我们使用Vul4C评估了七个C/C++程序的AVR工具，并使用第三方Vul4J数据集评估了两个Java程序的AVR工具。我们还讨论了未来的研究方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [519] [Classification of Quality Characteristics in Online User Feedback using Linguistic Analysis, Crowdsourcing and LLMs](https://arxiv.org/abs/2506.11722)
> *使用语言分析、众包和大型语言模型对在线用户反馈中的质量特性进行分类*

*Eduard C. Groen, Fabiano Dalpiaz, Martijn van Vliet, Boris Winter, Joerg Doerr, Sjaak Brinkkemper* | **Main category: cs.SE**

**Keywords:** 质量特性分类, 在线用户反馈, 众包, 大型语言模型, 低数据量

**Comment:** Accepted at the Journal of Systems and Software (JSS); online
  appendix and supplementary material available at
  https://doi.org/10.5281/zenodo.15604749

> **TL;DR:** 本文研究了在低数据量环境下，使用众包和大型语言模型能有效分类在线用户反馈中的软件质量特性，优于基于语言模式的方法。

**AI_Comments:** 本文的创新点在于探讨了在训练数据稀缺的真实场景下，利用众包和大型语言模型进行文本分类的可能性。其重要性体现在为软件开发过程提供了一种有效利用在线用户反馈，识别质量特性的自动化手段，尤其是在缺乏标记数据的情况下。研究结果表明众包和LLMs在低资源环境下的实用性，并指出了其在语料构建方面的潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 在线用户反馈是宝贵的质量相关信息来源，但其异构性和缺乏训练语料限制了监督机器学习的适用性，因此需要探索在低数据量环境下有效的自动化质量特性识别方法。

**Method:** 研究了三种在低数据量环境下可能有效的方法：基于质量相关关键词的语言模式（LPs）、众包微任务指令和大型语言模型（LLM）提示。对每种方法的可行性进行了评估并比较了它们的准确性。

**Result:** 对于复杂的质量特性多类别分类：基于语言模式的方法精度（0.38-0.92）因质量特性而异，召回率低；众包方法在两个连续阶段取得了最佳平均准确率（0.63，0.72）；大型语言模型最佳表现条件下的准确率（0.66）和基于多数投票的预测（0.68）与众包方法相当。

**Conclusion:** 在低数据量环境下，众包和大型语言模型（无需专家参与）能实现准确的分类，而基于语言模式的方法潜力有限。众包和大型语言模型在该背景下的潜力甚至可以扩展到构建训练语料。

> **ai_Abstract:** 本文研究了在数据量有限的情况下，对在线用户反馈中的软件质量特性进行分类的三种方法：基于语言模式、众包和大型语言模型。结果表明，众包和大型语言模型在分类准确性方面表现优异，且无需专家参与，这两种方法在低数据量设置下比基于语言模式的方法更具潜力，甚至有望用于构建训练语料。

> **摘要翻译:** 软件质量，如可用性或可靠性，是移动应用用户满意度的最强决定因素之一，构成了软件产品在线用户反馈的重要部分，使其成为指导开发过程的宝贵质量相关反馈来源。在线用户反馈的丰富性保证了质量特性的自动化识别，但在线用户反馈的异构性和缺乏适当的训练语料限制了监督机器学习的适用性。因此，我们研究了三种在低数据量环境下可能有效的方法的可行性：基于质量相关关键词的语言模式（LPs）、众包微任务指令和大型语言模型（LLM）提示。我们确定了每种方法的可行性，然后比较了它们的准确性。对于质量特性的复杂多类别分类，基于语言模式的方法根据质量特性实现了不同的精度（0.38-0.92），召回率较低；众包在两个连续阶段取得了最佳平均准确率（0.63，0.72），这与表现最佳的LLM条件（0.66）和基于LLM多数投票的预测（0.68）相匹配。我们的发现表明，在这种低数据量环境下，使用众包或LLM而不是涉及专家的方法实现了准确的分类，而基于LP的方法潜力有限。众包和LLM在此背景下的前景甚至可能扩展到构建训练语料。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [523] [A Short Survey on Formalising Software Requirements using Large Language Models](https://arxiv.org/abs/2506.11874)
> *使用大型语言模型形式化软件需求的简短综述*

*Arshad Beg, Diarmuid O'Donoghue, Rosemary Monahan* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 软件需求, 形式化规范, 文献综述, VERIFAI

**Comment:** Submitted to SAIV 2025 as extended abstract and received valuable
  comments improving our draft. This version is the improved one after
  addressing suggestions from reviewers for improving the draft

> **TL;DR:** 本文对使用大型语言模型（LLM）协助编写软件形式化规范的文献进行了综述，总结了35篇关键论文，并提供了未来方向。

**AI_Comments:** 这是一篇有价值的综述性论文，它系统地梳理了大型语言模型在软件需求形式化方面的应用现状，并指出了未来的研究方向。其重要性在于为该领域的研究人员提供了一个清晰的概览和潜在的研究切入点。该论文的贡献在于其全面的文献回顾和对实践案例的总结，对于推动LLM在软件工程领域的应用具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决从自然语言需求编写形式化规范所面临的挑战，该研究源于VERIFAI项目。

**Method:** 本研究采用多学术数据库识别相关研究，并利用AI辅助工具Elicit进行初步论文筛选，最终进行人工筛选。

**Result:** 本文总结了35篇关键论文，其中包括使用Dafny、C和Java编写程序规范的示例。

**Conclusion:** 该综述为在形式化软件需求时利用大型语言模型提供了宝贵的见解和未来方向。

> **ai_Abstract:** 本文对利用大型语言模型（LLM）协助编写软件形式化规范的现有文献进行了综述。该综述总结了35篇重要论文，并提供了在Dafny、C和Java中指定程序的例子。研究源于VERIFAI项目，旨在解决将自然语言需求转化为形式化规范的挑战。研究方法包括使用多个学术数据库和AI工具Elicit进行论文筛选。该综述为未来利用LLM形式化软件需求提供了见解和方向。

> **摘要翻译:** 本文对使用大型语言模型（LLM）协助编写软件形式化规范的文献进行了重点调查。本文总结了三十五篇关键论文，包括用Dafny、C和Java编写程序规范的示例。本文源于VERIFAI项目——自然语言需求的可追溯性和验证，该项目旨在解决从自然语言表达的需求中编写形式化规范的挑战。我们的方法采用多个学术数据库来识别相关研究。AI辅助工具Elicit促进了初步的论文选择，然后进行人工筛选以最终确定。该调查为在形式化软件需求时利用大型语言模型提供了宝贵的见解和未来方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [527] [LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?](https://arxiv.org/abs/2506.11928)
> *LiveCodeBench Pro：奥林匹克奖牌获得者如何评估大型语言模型在竞技编程中的表现？*

*Zihan Zheng, Zerui Cheng, Zeyu Shen, Shang Zhou, Kaiyuan Liu, Hansen He, Dongruixuan Li, Stanley Wei, Hangyi Hao, Jianzhu Yao, Peiyao Sheng, Zixuan Wang, Wenhao Chai, Aleksandra Korolova, Peter Henderson, Sanjeev Arora, Pramod Viswanath, Jingbo Shang, Saining Xie* | **Main category: cs.SE**

**Keywords:** 竞技编程, 大型语言模型, 基准测试, 算法推理, 代码生成

**Comment:** Project Page at https://livecodebenchpro.com/

> **TL;DR:** 尽管有声称LLM在竞技编程中表现超越人类精英，但本研究通过新的基准测试LiveCodeBench Pro发现，LLM在面对中等和困难的算法问题时仍存在显著局限性，特别是在没有外部工具的情况下。

**AI_Comments:** 该论文的创新之处在于利用奥林匹克奖牌获得者对问题进行标注和逐行失败分析，提供了超越简单通过率的、由人类专家驱动的LLM能力诊断。这种方法有助于准确识别LLM在算法推理方面的具体弱点，这对于指导未来的研究至关重要。LiveCodeBench Pro中问题的持续更新也解决了数据污染问题，使其成为一个更稳健的基准测试。

<details>
  <summary>Details</summary>

**Motivation:** 最近的报告声称大型语言模型（LLMs）在竞技编程中已超越人类精英。本文的动机是重新审视这一主张，检查LLMs与人类专家有何不同，以及仍存在哪些局限性。

**Method:** 本文引入了LiveCodeBench Pro，这是一个由Codeforces、ICPC和IOI问题组成的基准测试，这些问题持续更新以减少数据污染的可能性。一个奥林匹克奖牌获得者团队对每个问题进行算法类别标注，并对失败的模型生成提交进行逐行分析。

**Result:** 前沿模型仍存在显著局限性：在没有外部工具的情况下，最佳模型在中等难度问题上的通过率仅为53%（pass@1），在困难问题上为0%，而这些领域人类专家仍然表现出色。LLMs在实现密集型问题上表现出色，但在细致的算法推理和复杂案例分析方面表现挣扎，经常生成自信但错误的解释。高性能似乎主要由实现精度和工具增强驱动，而非卓越的推理能力。

**Conclusion:** LiveCodeBench Pro突出了LLMs与人类大师级别之间的显著差距，同时提供了细粒度的诊断，以指导未来以代码为中心的LLM推理的改进。

> **ai_Abstract:** 本文介绍了LiveCodeBench Pro，这是一个由奥林匹克奖牌获得者策划和分析的新的竞技编程基准测试，旨在评估大型语言模型（LLMs）。与LLM超越人类的说法相反，研究表明，当前的前沿模型仍远未达到人类专家的水平，尤其是在中等到困难的算法问题上，在没有外部工具的情况下，中等难度问题的通过率仅为53%，困难问题为0%。LLMs擅长实现密集型任务，但在复杂的算法推理方面表现不佳。研究结果表明，LLM在编码方面的性能主要由精确的实现和工具使用驱动，而非高级推理能力，这表明与人类大师级水平之间存在显著差距。

> **摘要翻译:** 最近的报告声称大型语言模型（LLMs）在竞技编程中已超越人类精英。我们借鉴了一群国际算法竞赛奖牌获得者的知识，重新审视了这一主张，审视了LLMs与人类专家有何不同以及仍存在哪些局限性。我们引入了LiveCodeBench Pro，这是一个由Codeforces、ICPC和IOI问题组成的基准测试，这些问题持续更新以减少数据污染的可能性。一个奥林匹克奖牌获得者团队对每个问题进行算法类别标注，并对失败的模型生成提交进行逐行分析。利用这些新数据和基准，我们发现前沿模型仍然存在显著局限性：在没有外部工具的情况下，最佳模型在中等难度问题上的通过率仅为53%（pass@1），在困难问题上为0%，而这些领域人类专家仍然表现出色。我们还发现LLMs在实现密集型问题上表现出色，但在细致的算法推理和复杂案例分析方面表现挣扎，经常生成自信但错误的解释。高性能似乎主要由实现精度和工具增强驱动，而非卓越的推理能力。因此，LiveCodeBench Pro突出了与人类大师级别之间的显著差距，同时提供了细粒度的诊断，以指导未来以代码为中心的LLM推理的改进。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [8] [Temporal Dynamics of Emotions in Italian Online Soccer Fandoms](https://arxiv.org/abs/2506.11934)
> *意大利在线足球粉丝情绪的时间动态*

*Salvatore Citraro, Giovanni Mauro, Emanuele Ferragina* | **Main category: cs.SI**

**Keywords:** 情绪动态, 足球粉丝, 情感分析, 爆发性, 球队表现

**Comment:** 

> **TL;DR:** 本研究通过计算分析意大利足球粉丝在Instagram上的情绪动态，发现喜悦呈现反爆发性模式，而愤怒则表现出爆发性模式，且愤怒的爆发性与球队表现显著相关。

**AI_Comments:** 该论文将复杂系统理论（爆发性/反爆发性）创新性地应用于分析球迷情绪，展示了其在预测球队表现方面的作用。发现愤怒的爆发性与表现相关尤具洞察力，为体育分析和球迷参与研究提供了新的衡量标准。该方法论通过使用来自多个联赛的大型数据集，体现了其稳健性。

<details>
  <summary>Details</summary>

**Motivation:** 调查意大利足球粉丝的情绪动态，并理解粉丝情绪表达与球队表现之间的关系。

**Method:** 对2023-24赛季意大利83支足球队（意甲、意乙、意丙）官方Instagram账户的用户生成内容进行计算分析。通过情感分析提取球迷评论中的情绪时间模式，并根据季前期望识别出不同的球迷群体。借鉴复杂系统理论，将喜悦特征化为反爆发性时间分布，将愤怒特征化为明显的爆发性模式。分析情绪信号、季前期望、社会经济因素和最终联赛排名之间的相关性。

**Result:** 喜悦表现出反爆发性时间分布，而愤怒则表现出明显的爆发性模式。情绪信号、季前期望、社会经济因素和最终联赛排名之间存在显著相关性。爆发性指标（特别是愤怒的爆发性）是球队表现的一个有意义的相关因素；排除该参数的统计模型显示决定系数下降了32%。

**Conclusion:** 这些发现为球迷情绪表达与球队表现之间的关系提供了新颖的见解，为体育分析、社交媒体动态和球迷参与研究提供了潜在的研究途径。

> **ai_Abstract:** 本文通过计算分析意大利足球粉丝在Instagram评论中的情绪动态。研究利用情感分析和复杂系统理论，揭示了喜悦呈现反爆发性模式，而愤怒则表现出爆发性模式。研究发现，粉丝情绪、季前期望、社会经济因素与球队排名之间存在显著相关性，并强调情绪的爆发性（尤其是愤怒的爆发性）是预测球队表现的重要指标。

> **摘要翻译:** 本研究通过对2023-24赛季意甲、意乙和意丙联赛83支球队官方Instagram账户的用户生成内容进行计算分析，调查了意大利足球粉丝的情绪动态。通过对球迷评论进行情感分析，我们提取了情绪的时间模式，并识别出具有相似季前期望的球迷群体。借鉴复杂系统理论，我们将喜悦描述为呈现反爆发性时间分布，而愤怒则表现出明显的爆发性模式。我们的分析揭示了这些情绪信号、季前期望、社会经济因素和最终联赛排名之间存在显著相关性。特别是，爆发性指标成为球队表现的一个有意义的相关因素；排除该参数的统计模型显示决定系数下降了32%。这些发现为球迷情绪表达与球队表现之间的关系提供了新颖的见解，为体育分析、社交媒体动态和球迷参与研究提供了潜在的研究途径。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [13] [Efficient Traffic Classification using HW-NAS: Advanced Analysis and Optimization for Cybersecurity on Resource-Constrained Devices](https://arxiv.org/abs/2506.11319)
> *使用HW-NAS的高效流量分类：针对资源受限设备网络安全的先进分析与优化*

*Adel Chehade, Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino* | **Main category: cs.NI**

**Keywords:** 流量分类, 硬件感知神经架构搜索, 深度神经网络, IoT安全, 资源受限设备

**Comment:** 

> **TL;DR:** 本文提出了一种通过硬件感知神经架构搜索（HW-NAS）优化的硬件高效深度神经网络（DNN），用于在资源受限的IoT和边缘设备上分类会话级加密流量，实现了高精度和显著的资源效率提升。

**AI_Comments:** 本文的创新点在于将硬件感知神经架构搜索（HW-NAS）应用于加密流量分类，以解决IoT和边缘设备上的资源限制问题。其重要性体现在实现了极高的资源效率（参数、FLOPs、内存占用大幅减少）和出色的分类准确率。这为在严格硬件约束下部署先进的网络安全解决方案提供了可行途径。局限性可能在于其对特定数据集的依赖性，以及预处理和会话长度选择对性能的敏感性，这可能需要根据具体应用场景进行精细调整。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的物联网（IoT）和边缘设备上对加密流量进行分类，以增强网络安全，面临内存和计算限制的挑战。现有方法可能无法满足这些严格的硬件约束。

**Method:** 本文提出了一种通过硬件感知神经架构搜索（HW-NAS）优化的硬件高效深度神经网络（DNN）。具体而言，通过HW-NAS在ISCX VPN-nonVPN数据集上定制了一个一维卷积神经网络（1D CNN），以满足严格的内存和计算限制。此外，还探讨了深度级别的预处理策略和会话长度缩减对性能的影响。

**Result:** 优化后的模型在ISCX VPN-nonVPN数据集上达到了96.59%的准确率，仅有88.26K参数、10.08M FLOPs和20.12K的最大张量大小。与现有最先进模型相比，这些指标分别减少了高达444倍、312倍和15.6倍。该模型在VPN区分、VPN类型分类、更广泛的流量类别和应用识别等分类任务中也表现出高达99.64%的准确率。深度级别的预处理策略证实了模型在各种配置下的出色性能。将会话长度缩短高达75%可显著提高效率，同时保持高精度，仅有1-2%的轻微下降。然而，不当的预处理设置或激进的会话长度缩减可能导致整体准确率下降7%。

**Conclusion:** 该方法通过为受硬件严格限制的加密流量实时分析提供可扩展、高效的解决方案，有效增强了IoT网络的网络安全。研究结果强调了HW-NAS在优化深度学习模型以适应资源受限环境方面的有效性，但同时也指出了仔细预处理和会话长度选择的重要性。

> **ai_Abstract:** 本文提出了一种基于硬件感知神经架构搜索（HW-NAS）优化的硬件高效深度神经网络（DNN），用于在资源受限的IoT和边缘设备上进行会话级加密流量分类。该方法通过定制一维卷积神经网络，在保持高准确率（最高99.64%）的同时，显著减少了模型参数、FLOPs和内存占用，与现有技术相比，资源消耗大幅降低。研究还探讨了预处理策略和会话长度对性能的影响，证明了该模型在不同配置下的鲁棒性，并强调了预处理的重要性。该工作为IoT网络中的实时加密流量分析提供了高效且可扩展的网络安全解决方案。

> **摘要翻译:** 本文提出了一种硬件高效的深度神经网络（DNN），通过硬件感知神经架构搜索（HW-NAS）进行优化；该DNN支持在资源受限的物联网（IoT）和边缘设备上对会话级加密流量进行分类。得益于HW-NAS，一个一维卷积神经网络（CNN）在ISCX VPN-nonVPN数据集上进行了定制，以满足严格的内存和计算限制，同时实现了稳健的性能。优化后的模型以仅88.26K参数、10.08M FLOPs和20.12K的最大张量大小，达到了96.59%的准确率。与现有最先进模型相比，它在这些指标上分别实现了高达444倍、312倍和15.6倍的减少，显著最小化了内存占用和运行时要求。该模型还在分类任务中展示了多功能性，在VPN区分、VPN类型分类、更广泛的流量类别和应用识别中实现了高达99.64%的准确率。此外，深度级别的头部预处理策略证实，优化后的模型即使在更严格的隐私考虑场景下，也能在各种配置中提供显著的性能。同样，将会话长度缩短高达75%可显著提高效率，同时保持高精度，仅有1-2%的轻微下降。然而，原始流量数据分类中仔细的预处理和会话长度选择的重要性仍然存在，因为不当的设置或激进的缩减可能导致整体准确率下降7%。这些结果突出了该方法在通过为受硬件严格限制的加密流量实时分析提供可扩展、高效的解决方案方面，有效增强了IoT网络的网络安全。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [41] [Scheduling Agile Earth Observation Satellites with Onboard Processing and Real-Time Monitoring](https://arxiv.org/abs/2506.11556)
> *具有星载处理和实时监测的敏捷地球观测卫星调度*

*Antonio M. Mercado-Martínez, Beatriz Soret, Antonio Jurado-Navas* | **Main category: cs.NI**

**Keywords:** 敏捷地球观测卫星, 调度, 星载处理, 实时监测, 优化

**Comment:** This paper has been submitted to GLOBECOM 2025

> **TL;DR:** 提出一种结合星载处理和实时监测的敏捷地球观测卫星调度算法，通过优化观测顺序和提高数据质量，显著优于传统方法。

**AI_Comments:** 这篇论文的创新点在于将星载数据处理和实时监测集成到敏捷地球观测卫星的调度问题中，这对于实现近实时地球观测数据交付至关重要。所提出的结合启发式和局部搜索的方法在提升数据质量和监测均匀性方面表现出色，为未来的地球观测任务调度提供了有效方案。

<details>
  <summary>Details</summary>

**Motivation:** 敏捷地球观测卫星提供了更高的数据采集灵活性。星载计算和通信技术进步提高了数据压缩效率，降低了网络延迟。研究旨在解决敏捷地球观测卫星调度问题，以最大化观测收益并支持近实时信息交付。

**Method:** 提出敏捷地球观测卫星调度问题（AEOSSP），旨在确定最佳目标观测序列以最大化总观测收益。方法整合了用于实时远程监测的星载数据处理到多卫星优化问题中。定义了一组优先级指标，开发了一种建设性启发式方法，并辅以局部搜索（LS）策略。

**Result:** 提出的算法与先进先出（FIFO）方法相比，平均可将收集到的帧分辨率提高多达10%，同时将实例中目标监测频率的方差降低多达83%，确保整个数据集的信息更及时。

**Conclusion:** 提出的算法能够提供高质量信息，显著提升数据分辨率和监测频率的均匀性，优于传统方法，支持敏捷地球观测卫星的近实时监测需求。

> **ai_Abstract:** 本文研究了敏捷地球观测卫星调度问题，旨在通过优化目标观测序列来最大化观测收益。研究整合了星载数据处理以实现实时远程监测。提出了一种结合建设性启发式方法和局部搜索策略的算法。实验结果表明，该算法显著提高了数据分辨率并降低了监测频率的方差，优于传统的FIFO方法，从而提供了更及时和高质量的地球观测信息。

> **摘要翻译:** 敏捷地球观测卫星（AEOSs）的出现标志着地球观测（EO）领域的一个重要转折点，它提供了增强的数据采集灵活性。与此同时，星载卫星计算和通信技术的进步极大地提高了数据压缩效率，减少了网络延迟和拥塞，同时支持近实时信息交付。在本文中，我们解决了敏捷地球观测卫星调度问题（AEOSSP），该问题涉及确定最佳目标观测序列以最大化总观测收益。我们的方法将用于实时远程监测的星载数据处理整合到多卫星优化问题中。为此，我们定义了一组优先级指标，并开发了一种建设性启发式方法，并通过局部搜索（LS）策略进一步增强。结果表明，与先进先出（FIFO）方法相比，所提出的算法通过平均将收集到的帧分辨率提高多达10%，同时将实例中目标监测频率的方差降低多达83%，确保了整个数据集的更及时信息，从而提供了高质量信息。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [69] [Generalised Rate Control Approach For Stream Processing Applications](https://arxiv.org/abs/2506.11710)
> *流处理应用的通用速率控制方法*

*Ziren Xiao* | **Main category: cs.NI**

**Keywords:** 流处理, 速率控制, 图神经网络, 深度强化学习, 系统过载

**Comment:** 

> **TL;DR:** 本文提出了一种基于图神经网络的深度强化学习方法，通过控制数据生成速率来避免分布式流处理系统过载，实验结果显示吞吐量和端到端延迟均有显著改善。

**AI_Comments:** 这项工作通过引入图神经网络（GNN）到深度强化学习框架中进行流处理速率控制，展现了创新性。它解决了传统方法在处理实时流数据时面临的过载、状态依赖和适应性差等问题。GNN的应用使得模型能够更好地理解系统指标之间的关系，实现更主动、更高效的过载避免。该方法在吞吐量和延迟方面的显著改进凸显了其重要性，为分布式流处理系统的稳定性和效率提供了新的解决方案。其能够适应多种场景和应用的能力也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 分布式流处理系统在处理实时数据时面临过载挑战，这会导致系统不稳定并消耗额外资源。现有方法可能存在存储历史状态、等待长间隔以及适应性差的问题。

**Method:** 本文采用基于图神经网络（GNN）的深度强化学习方法，协同控制流源的数据发射速率，以主动避免过载。与传统的多层感知器（MLP）网络不同，GNN用于处理从流处理引擎收集的系统指标。这种方法具有以下优点：1) 避免存储可能影响当前状态的过去状态；2) 无需长时间等待当前动作完全生效并反映在系统指标中；3) 能够适应多种场景下的多个流应用程序。

**Result:** 将速率控制方法部署到三个应用中，实验结果表明吞吐量提高了13.5%，端到端延迟降低了30%。

**Conclusion:** 本文提出的基于图神经网络的深度强化学习速率控制方法能有效解决分布式流处理系统过载问题，显著提升系统性能。

> **ai_Abstract:** 本文提出了一种基于图神经网络（GNN）的深度强化学习方法，用于分布式流处理系统的通用速率控制，以主动避免系统过载。该方法通过协同控制流源数据发射速率，利用GNN处理系统指标，相比传统方法，避免了历史状态存储和长等待时间，并增强了多应用和多场景适应性。实验结果显示，在三个应用中，吞吐量提升高达13.5%，端到端延迟降低高达30%。

> **摘要翻译:** 分布式流处理系统被广泛部署以处理各种设备（如传感器和软件系统）生成的实时数据。系统中的一个关键挑战是过载，这会导致系统状态不稳定并消耗额外的系统资源。在本文中，我们使用基于图神经网络的深度强化学习来协同控制流源生成数据的发射速率，以主动避免过载情况。本文不使用传统的多层感知器样式网络来控制速率，而是使用图神经网络来处理从流处理引擎收集的系统指标。因此，学习代理（i）避免存储过去的状态，即先前的动作可能会影响当前状态，（ii）无需长时间等待当前动作完全生效并反映在系统的特定指标中，更重要的是，（iii）能够适应多种场景下的多个流应用程序。我们将速率控制方法部署在三个应用程序上，实验结果表明吞吐量和端到端延迟分别提高了13.5%和30%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [97] [Adaptive determinantal scheduling with fairness in wireless networks](https://arxiv.org/abs/2506.11738)
> *无线网络中具有公平性的自适应行列式调度*

*H. P. Keeler, B. Błaszczyszyn* | **Main category: cs.NI**

**Keywords:** 行列式过程, 无线网络, 调度, 公平性, 凸优化

**Comment:** 8 pages, 2 plots, 1 diagram. WiOpt 2025

> **TL;DR:** 提出一种利用行列式过程实现无线网络中公平调度的框架，该方法数学上优雅且计算上易于处理。

**AI_Comments:** 本文创新性地将行列式点过程（一种在机器学习中已显示价值的工具）引入到无线网络调度领域，特别是解决了公平性问题。其将调度问题转化为凸优化，提供了一种数学上严谨且计算上可行的解决方案，这对于实际网络部署具有重要意义。该工作成功地将机器学习的理论进展与无线通信的实际需求相结合。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Aloha协议独立调度传输，本文旨在通过引入行列式过程的排斥特性来推广这些协议，并解决无线网络调度中的公平性问题。

**Method:** 提出一种基于行列式（点）过程的新型无线网络调度框架，该方法利用行列式过程的排斥特性，并将其公式化为L-集合上凸优化问题，以实现公平性。还演示了其在基于SINR的网络模型中的适用性。

**Result:** 结果表明，行列式调度与公平性相结合具有潜力，并且行列式过程适用于基于信噪比（SINR）的网络模型。

**Conclusion:** 这项工作将机器学习的最新进展与无线通信相结合，为网络调度提供了一种数学上优雅且计算上易于处理的方法。

> **ai_Abstract:** 本文提出一种基于行列式（点）过程的无线网络公平调度新框架。该方法利用行列式过程的排斥特性，并将其公式化为L-集合上的凸优化问题以优化公平性。研究证明了行列式过程在基于SINR的网络模型中的适用性，并强调了行列式调度与公平性结合的潜力，为网络调度提供了一种数学优雅且计算可行的方案，桥接了机器学习与无线通信。

> **摘要翻译:** 我们提出了一种利用行列式（点）过程在无线网络中实现公平调度的创新框架。我们的方法结合了行列式过程的排斥特性，推广了独立调度传输的传统Aloha协议。我们使用代表公平性的效用函数来制定调度问题。然后，我们将此公式重新表述为一类称为L-集合的行列式点过程上的凸优化问题，L-集合特别适合统计和数值处理。这些行列式过程在子集学习中已被证明具有价值，为网络资源调度和分配提供了一种有吸引力的方法。我们证明了行列式过程适用于基于信噪比（SINR）的网络模型。我们的结果突出了行列式调度与公平性相结合的潜力。这项工作将机器学习的最新进展与无线通信相结合，为网络调度提供了一种数学上优雅且计算上易于处理的方法。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [117] [Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?](https://arxiv.org/abs/2506.12003)
> *升级还是转换：我们是否需要为AI智能体互联网构建新的注册架构？*

*Ramesh Raskar, Pradyumna Chari, Jared James Grogan, Mahesh Lambe, Robert Lincourt, Raghu Bala, Abhishek Singh, Ayush Chopra, Rajesh Ranjan, Shailja Gupta, Dimitris Stripelis, Maria Gorskikh, Sichao Wang* | **Main category: cs.NI**

**Keywords:** AI智能体, 注册架构, 互联网基础设施, DNS, PKI, 混合方法

**Comment:** 

> **TL;DR:** 现有网络基础设施无法满足AI智能体互联网的需求，本文分析了升级现有系统或构建新注册架构的利弊，并提出混合方法是未来的趋势。

**AI_Comments:** 这篇论文深入探讨了AI智能体对现有互联网基础设施带来的根本性挑战，并提出了关于未来注册架构的深刻见解。其创新点在于将AI智能体的需求视为“质的改变”而非“增量改变”，并类比拨号到宽带的过渡，为理解这种范式转变提供了直观的视角。提出的混合注册架构方案也具有实际指导意义，平衡了兼容性、性能和部署速度。

<details>
  <summary>Details</summary>

**Motivation:** 现有的为人类规模交互设计的Web基础设施无法满足新兴的AI智能体互联网对毫秒级发现、即时凭证撤销和加密行为证明的需求，因此需要分析是升级现有基础设施还是实现专门的注册架构。

**Method:** 本文分析了现有基础设施（DNS/PKI、IPv4/IPv6）的关键故障点，并评估了三种方法：(1) 升级路径，(2) 转换选项，(3) 混合注册表。通过与拨号到宽带的过渡进行类比。

**Result:** AI智能体的需求是质的而非增量的变化。升级提供兼容性和更快的部署，而全新解决方案提供更好的性能但需要更长的采用时间。分析表明混合方法将会出现。

**Conclusion:** 未来的AI智能体互联网注册架构将是混合方法，即关键智能体使用集中式注册表，而专业用例使用联邦网格。

> **ai_Abstract:** 本文探讨了现有互联网基础设施在支持新兴AI智能体互联网方面的局限性，这些智能体需要快速发现、即时凭证撤销和行为证明。作者分析了升级现有系统、切换到新架构或采用混合方案的优缺点，指出AI智能体的需求是质变而非量变。研究结果倾向于混合方法，即结合集中式注册表和联邦网格以满足不同智能体的需求。

> **摘要翻译:** 新兴的AI智能体互联网对为人类规模、反应式交互设计的现有Web基础设施提出了挑战。与传统的Web资源不同，自主AI智能体能够发起行动、维持持久状态、生成子智能体并直接与对等体协商：这要求毫秒级的发现、即时凭证撤销和超出当前DNS/PKI能力的加密行为证明。本文分析了是升级现有基础设施还是为自主智能体实施专用注册架构。我们确定了关键故障点：DNS传播（24-48小时对比所需的毫秒级）、证书撤销无法扩展到万亿实体，以及IPv4/IPv6寻址不足以满足智能体规模的路由。我们评估了三种方法：（1）升级路径，（2）转换选项，（3）混合注册表。通过与拨号到宽带的过渡进行类比，我们发现智能体需求是质的而非增量的变化。虽然升级提供兼容性和更快的部署，但全新解决方案提供更好的性能但需要更长时间才能被采用。我们的分析表明，混合方法将会出现，即关键智能体使用集中式注册表，而专业用例使用联邦网格。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [124] [Enabling Next-Generation Cloud-Connected Bionic Limbs Through 5G Connectivity](https://arxiv.org/abs/2506.11744)
> *通过5G连接实现下一代云连接仿生肢体*

*Ozan Karaali, Hossam Farag, Strahinja Dosen, Cedomir Stefanovic* | **Main category: cs.NI**

**Keywords:** 5G, 仿生肢体, 云计算, 边缘计算, 辅助技术

**Comment:** 

> **TL;DR:** 本文提出利用5G连接和云/边缘计算来克服当前仿生肢体的计算能力和延迟限制，通过概念验证验证了其可行性，为实现云连接仿生肢体迈出了第一步。

**AI_Comments:** 该论文通过利用5G和分布式计算来解决仿生肢体的根本性限制，提出了一种创新方法，有望彻底改变其功能和用户体验。其通过5G测试平台进行实际验证的重点是一个亮点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人机交互取得了进展，但当前的辅助仿生肢体面临计算能力有限、延迟高和控制机制不直观等关键挑战，导致用户体验不佳和弃用率高。

**Method:** 本文提出了一种概念性方法，通过利用5G的普及连接以及云和边缘服务器的强大计算能力来改造仿生肢体。该系统采用分层分布式计算架构，整合了本地、边缘和云计算层。时间敏感型任务由本地处理单元处理，而计算密集型任务则利用先进蜂窝网络的高数据速率、可靠和低延迟能力，卸载到边缘和云服务器。

**Result:** 在5G测试平台进行的初步概念验证表明，此类网络能够达到自然假肢控制所需的数据速率并满足延迟要求，从而允许将计算密集型任务卸载到边缘/云服务器。

**Conclusion:** 这项工作是实现和实际验证云连接仿生肢体系统的第一步。

> **ai_Abstract:** 本文提出了一种概念框架，通过将5G连接与云和边缘计算相结合来增强仿生肢体。它通过分层分布式计算架构，利用5G的高数据速率和低延迟特性，将计算密集型任务卸载到远程服务器，从而解决了当前仿生肢体计算能力有限和高延迟等问题。在5G测试平台进行的初步验证证实了满足自然假肢控制所需数据速率和延迟的可行性，标志着向实际云连接仿生肢体迈出了基础性的一步。

> **摘要翻译:** 尽管人机交互取得了最新进展，但当前的辅助仿生肢体面临关键挑战，包括有限的计算能力、高延迟和不直观的控制机制，导致用户体验不佳和弃用率高。解决这些挑战需要向由物联网系统（特别是无线连接和边缘/云计算）进步所驱动的智能互联解决方案转变。本文提出了一种概念性方法，通过利用5G的普及连接以及云和边缘服务器的强大计算能力来改造仿生肢体，赋予它们迄今为止不具备的能力。该系统采用分层分布式计算架构，整合了本地、边缘和云计算层。时间敏感型任务由本地处理单元处理，而计算密集型任务则利用先进蜂窝网络的高数据速率、可靠和低延迟能力，卸载到边缘和云服务器。我们在5G测试平台进行了概念验证，结果表明此类网络能够达到自然假肢控制所需的数据速率并满足延迟要求，从而允许将计算密集型任务卸载到边缘/云服务器。这是实现和实际验证云连接仿生肢体系统的第一步。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [149] [The Throughput Gain of Hypercycle-level Resource Reservation for Time-Triggered Ethernet](https://arxiv.org/abs/2506.11745)
> *时间触发以太网中超周期级资源预留的吞吐量增益*

*Peng Wang, Suman Sourav, Binbin Chen, Hongyan Li, Feng Wang, Fan Zhang* | **Main category: cs.NI**

**Keywords:** 时间触发以太网, 资源预留, 灵活调度, 吞吐量增益, 超周期

**Comment:** 

> **TL;DR:** 提出了一种超周期级灵活调度（HFS）方案，显著提升了时间触发以太网的吞吐量，比现有方法能接纳多达6倍的流量，且求解速度快万倍。

**AI_Comments:** 这项工作提出了一种创新的调度策略，通过在超周期级别上引入灵活性，有效解决了时间触发以太网中资源预留的兼容性问题，显著提升了系统吞吐量。其理论上的无界增益和实验中6倍的性能提升显示了其重要性。此外，针对NP-Hard问题的启发式算法在保持高性能的同时，提供了极高的计算效率，使其在实际应用中具有可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间触发以太网的固定循环调度（FCS）方案在共享链路上存在资源预留不兼容问题，限制了可接纳流量的总数。

**Method:** 提出了一种超周期级灵活调度（HFS）方案，允许流的资源预留在超周期内跨循环改变。将HFS下的联合路径查找和调度问题公式化为NP-Hard的整数线性规划（ILP）问题。为高效求解，进一步提出了一种最小负载优先启发式算法（HFS-LLF），通过一系列最短路径问题来解决HFS。

**Result:** HFS方案可显著增加可接纳的流量数量，理论上相对于FCS可提供无界容量增益。实验表明，HFS可接纳的流量数量是FCS的6倍。此外，所提出的HFS-LLF算法比使用通用求解器求解HFS的速度快10^4倍。

**Conclusion:** 超周期级灵活调度（HFS）方案通过提供更多调度选项，显著提高了时间触发以太网的流量接纳能力和吞吐量，且与现有系统兼容，其高效的启发式算法也使其具有实用性。

> **ai_Abstract:** 本文提出了一种针对时间触发以太网的超周期级灵活调度（HFS）方案，旨在克服传统固定循环调度（FCS）在共享链路资源预留上的限制。HFS允许流的资源预留在一个超周期内灵活变化，从而显著增加了可接纳的流量数量，实验证明可达FCS的6倍。作者将问题建模为NP-Hard的ILP问题，并开发了高效的最小负载优先启发式算法（HFS-LLF），该算法比通用求解器快10^4倍，且HFS与现有时间触发以太网系统完全兼容。

> **摘要翻译:** 时间触发通信是许多安全关键系统的关键技术，应用范围涵盖航空航天和工业控制领域。这种通信依赖于时间触发流，每个流由源节点发出并流向目的节点的周期性数据包组成。每个数据包都需要在其截止日期前到达目的节点。不同的流可以具有不同的周期长度。为了实现时间触发流的可靠传输，现有努力将流的数据包约束为沿相同路径循环传输。在这种固定循环调度（FCS）下，具有不同周期长度的流的预留可能在共享链路上变得不兼容，从而限制了可接纳流的总数。考虑到不同流的周期长度，超周期的长度等于它们的最小公倍数（LCM）。它确定了可以检查不同流调度兼容性的时间长度。在这项工作中，我们提出了一种更灵活的调度方案，称为超周期级灵活调度（HFS）方案，其中流的资源预留可以在一个超周期内跨循环改变。HFS可以通过提供更多的调度选项来显著增加可接纳流的数量，同时与现有时间触发以太网系统完全兼容。我们理论上证明了HFS相对于FCS可能提供的容量增益是无界的。我们将HFS下的联合路径查找和调度问题公式化为一个整数线性规划（ILP）问题，并证明其是NP-Hard的。为了高效求解HFS，我们进一步提出了一种最小负载优先启发式算法（HFS-LLF），将HFS解决为一系列最短路径问题。广泛研究表明，HFS接纳的流量数量是FCS的6倍。此外，我们提出的HFS-LLF比使用通用求解器求解HFS的速度快10^4倍。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [171] [Distributed Learning for Reliable and Timely Communication in 6G Industrial Subnetworks](https://arxiv.org/abs/2506.11749)
> *6G工业子网络中可靠及时通信的分布式学习*

*Samira Abdelrahman, Hossam Farag, Gilberto Berardinelli* | **Main category: cs.NI**

**Keywords:** 6G工业网络, 分布式学习, 随机接入, 及时通信, 碰撞避免

**Comment:** 

> **TL;DR:** 本文提出了一种基于分布式学习的随机接入协议，用于6G工业子网络中，通过隐式协调减少冲突，提高关键数据包的及时交付率，尤其适用于资源受限的工业环境。

**AI_Comments:** 这篇论文的创新点在于提出了一个分布式学习框架来解决6G工业子网络中的随机接入问题，通过隐式协调和轻量级在线学习模型，使其适用于资源受限的工业环境。其重要性在于为未来6G工业自动化提供了可靠和及时的通信解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 新兴的6G工业网络中，支持事件驱动的关键控制流量的及时传输面临挑战，原因在于无线资源有限、设备活动动态以及高移动性。

**Method:** 本文提出了一种分布式、基于学习的随机接入协议。该协议通过建立隐式的子网络间协调来最小化碰撞概率并提高及时交付。每个子网络独立地基于中央接入点广播的竞争签名信号学习并选择接入配置，从而实现在动态流量和移动性条件下的自适应、碰撞感知接入。该方法采用轻量级神经网络模型和在线训练。

**Result:** 仿真结果表明，该方法显著提高了数据包及时交付的概率，尤其是在密集和高负载场景下。例如，在包含60个子网络和5个无线信道的工业设置中，与经典的Multi-Armed Bandit (MAB)方法相比，数据包及时交付的概率提高了21%。

**Conclusion:** 本文提出的分布式学习方法能有效解决6G工业子网络中关键控制流量及时传输的挑战，显著提高数据包的及时交付率，并且其轻量级和在线训练的特性使其非常适合部署在受限的工业子网络中。

> **ai_Abstract:** 本文针对6G工业子网络中关键控制流量的及时传输挑战，提出了一种分布式、基于学习的随机接入协议。该协议通过子网络独立学习和基于竞争信号的接入配置选择，实现隐式子网络间协调，以减少碰撞并提高及时交付率。该方法采用轻量级神经网络模型和在线训练，仿真结果显示其在密集和高负载场景下显著优于基线方法，例如，相比MAB，及时交付率提高了21%。

> **摘要翻译:** 新兴的6G工业网络设想了自主的in-X子网络，以支持自主控制操作中高效、经济的短距离、本地化连接。在此类网络中，支持事件驱动的关键控制流量的及时传输具有挑战性，因为无线资源有限、设备活动动态且移动性高。在本文中，我们提出了一种分布式、基于学习的随机接入协议，该协议建立了隐式的子网络间协调，以最小化碰撞概率并提高及时交付。每个子网络根据中央接入点广播的竞争签名信号独立学习和选择接入配置，从而在动态流量和移动性条件下实现自适应、碰撞感知的接入。所提出的方法具有轻量级神经网络模型和在线训练的特点，使其适用于受限的工业子网络部署。仿真结果表明，与基线方法相比，我们的方法显著提高了数据包及时交付的概率，尤其是在密集和高负载场景下。例如，在包含60个子网络和5个无线信道的工业设置中，我们的方法与经典的Multi-Armed Bandit (MAB)方法相比，数据包及时交付的概率提高了21%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [188] [A Tale of Two Mobile Generations: 5G-Advanced and 6G in 3GPP Release 20](https://arxiv.org/abs/2506.11828)
> *移动通信两代记：3GPP Release 20 中的 5G-Advanced 和 6G*

*Xingqin Lin* | **Main category: cs.NI**

**Keywords:** 5G-Advanced, 6G, 3GPP Release 20, 移动通信

**Comment:** 9 pages, 5 figures, 1 table, submitted for possible publication

> **TL;DR:** 3GPP Release 20 是 5G-Advanced 到 6G 过渡的关键，它平衡了现有技术增强与未来标准奠基。

**AI_Comments:** 本文的重要性在于其对3GPP Release 20在5G向6G演进过程中所扮演的关键角色的及时分析，揭示了行业标准制定者如何平衡现有技术优化与未来技术前瞻性布局。

<details>
  <summary>Details</summary>

**Motivation:** 移动通信行业正处于5G和6G之间的十字路口，3GPP Release 20作为关键的过渡点，旨在平衡增强5G-Advanced能力和为6G奠定基础。

**Method:** 本文审视了3GPP Release 20在增强5G-Advanced能力和为6G奠定基础方面的双重目标，概述了其关键增强、背后的动机以及对未来移动通信的影响。

**Result:** Not mentioned in abstract

**Conclusion:** 3GPP Release 20作为5G-Advanced和6G之间的过渡点，通过平衡两代移动通信的需求，为未来的移动通信标准和部署奠定了关键基础。

> **ai_Abstract:** 本文探讨了3GPP Release 20在移动通信发展中的关键作用，该版本旨在平衡对5G-Advanced能力的增强与为未来6G技术奠定基础。它分析了Release 20的双重目标，包括其主要增强功能、背后的驱动因素以及对未来移动通信格局的深远影响，强调其作为未来标准和部署基石的重要性。

> **摘要翻译:** 随着电信行业站在第五代（5G）和第六代（6G）移动通信的十字路口，第三代合作伙伴计划（3GPP）Release 20成为了一个关键的过渡点。通过在增强5G-Advanced能力和为6G奠定基础之间取得平衡，Release 20为未来的移动通信标准和部署提供了至关重要的基础。本文审视了这些双重目标，概述了关键的增强、其背后的动机以及它们对未来移动通信的影响。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [208] [Intractable Cookie Crumbs: Unveiling the Nexus of Stateful Banner Interaction and Tracking Cookies](https://arxiv.org/abs/2506.11947)
> *难以处理的Cookie碎片：揭示有状态横幅交互与跟踪Cookie的关联*

*Ali Rasaii, Ha Dao, Anja Feldmann, Mohammadmadi Javid, Oliver Gasser, Devashish Gosain* | **Main category: cs.NI**

**Keywords:** 跟踪Cookie, 隐私, 同意横幅, 跨站跟踪, GDPR

**Comment:** Code, analysis scripts, and datasets available at:
  https://bannerclick.github.io

> **TL;DR:** 尽管有同意横幅，跨站跟踪仍通过“难以处理的Cookie”发生，这些Cookie在一个网站上设置，并在用户未明确同意的情况下发送给其他网站上的跟踪器。约50%的网站发送此类Cookie，通常长期有效，且同意管理平台（CMPs）加剧了这一问题。

**AI_Comments:** 这篇论文意义重大，因为它揭示了当前隐私法规（GDPR、ePrivacy）和同意机制（横幅、CMPs）中的一个关键漏洞。“难以处理的Cookie”的概念突出了看似合规的做法如何仍可能导致未经同意的跟踪。定量发现（50%的网站、长期过期、CMP影响）为问题规模提供了有力证据。它表明当前的同意系统不足，甚至可能加剧隐私问题。关于Cookie付费墙的发现尤其有见地，表明即使对于注重隐私的用户也存在持续的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为了响应《ePrivacy指令》和GDPR的同意要求，网站开始部署同意横幅。然而，由于共享的第三方服务和技术漏洞，未经同意的跨站点跟踪仍然可能发生。用户在一个网站上的同意决定可能会影响其他网站上的跟踪行为，这与用户期望的独立性相悖。本研究旨在调查这些差异背后的技术和行为机制。

**Method:** 本研究调查了一种利用网络Cookie的持久跟踪机制，称之为“难以处理的Cookie”。研究人员进行了一项广泛的测量研究，对来自Tranco热门列表的2万多个域名进行了有状态爬取，策略性地在前半部分域名中接受横幅，并在后半部分测量难以处理的Cookie。

**Result:** 约50%的网站发送至少一个难以处理的Cookie，其中大多数设置在10天后过期。启用全球隐私控制（GPC）信号最初平均减少了30%的难以处理的Cookie数量，通过在后续访问中拒绝横幅，可以进一步减少32%。与使用原生横幅的网站相比，使用同意管理平台（CMP）横幅的网站平均发送6.9倍的难以处理的Cookie。即使用户拒绝所有其他横幅，他们仍然会收到由带有Cookie付费墙的网站设置的大量难以处理的Cookie。

**Conclusion:** 本文揭示了一种普遍且持久的跨站跟踪机制（“难以处理的Cookie”），该机制规避了用户同意和隐私法规，尤其受到同意管理平台（CMPs）和Cookie付费墙的加剧。

> **ai_Abstract:** 本文揭示了一种新的跨站跟踪机制，称之为“难以处理的Cookie”，它规避了GDPR和ePrivacy的同意要求。这些Cookie在接受横幅的网站上设置，持久存在，并在用户未明确同意的情况下发送给其他网站上的跟踪器。一项对2万个域名进行的大规模测量研究发现，约50%的网站传输此类Cookie，且通常具有较长的有效期。研究还强调，与原生横幅相比，同意管理平台（CMPs）显著增加了难以处理的Cookie的普及率，即使当用户拒绝其他同意选项时，Cookie付费墙也进一步助长了它们的扩散。

> **摘要翻译:** 为了响应《ePrivacy指令》和GDPR引入的同意要求，网站开始部署同意横幅以获取用户数据收集和处理的权限。然而，由于共享的第三方服务和技术漏洞，未经同意的跨站点跟踪仍然可能发生。事实上，与用户期望的看似独立的同意相反，用户在一个网站上的决定可能会影响其他网站上的跟踪行为。在本研究中，我们调查了这些差异背后的技术和行为机制。具体来说，我们揭示了一种利用网络Cookie的持久跟踪机制。我们称这些Cookie为“难以处理的”，它们最初在接受横幅的网站上设置，并在浏览器中持久存在，然后在美国用户在其他网站上提供明确同意之前发送给跟踪器。为了细致分析这种隐蔽的跟踪行为，我们进行了一项广泛的测量研究，对来自Tranco热门列表的2万多个域名进行了有状态爬取，策略性地在前半部分域名中接受横幅，并在后半部分测量难以处理的Cookie。我们的发现揭示，大约50%的网站发送至少一个难以处理的Cookie，其中大多数设置在10天后过期。此外，启用全球隐私控制（GPC）信号最初平均减少了30%的难以处理的Cookie数量，通过在后续访问中拒绝横幅，可以进一步减少32%。此外，与使用原生横幅的网站相比，使用同意管理平台（CMP）横幅的网站平均发送6.9倍的难以处理的Cookie。我们的研究进一步揭示，即使用户拒绝所有其他横幅，他们仍然会收到由带有Cookie付费墙的网站设置的大量难以处理的Cookie。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [224] [Minimum-hop Constellation Design for Low Earth Orbit Satellite Networks](https://arxiv.org/abs/2506.11995)
> *低地球轨道卫星网络的最小跳数星座设计*

*Chirag Rao, Eytan Modiano* | **Main category: cs.NI**

**Keywords:** 低地球轨道卫星网络, 星间链路, 拓扑优化, 平均最短路径长度, 星座设计

**Comment:** To be published at IEEE INFOCOM 2025

> **TL;DR:** 该研究通过优化星间链路拓扑，旨在最小化低地球轨道卫星网络的平均最短路径长度，并为不同拓扑类型提供了接近最优的结构设计。

**AI_Comments:** 这篇论文的创新之处在于其系统地研究了低地球轨道卫星网络中星间链路拓扑的优化问题，特别关注了平均最短路径长度的最小化。它不仅为两种重要的拓扑类型（顶点对称和一般规则）建立了理论下限，还提供了实际可行的构造方法，这对于未来LEO卫星星座的设计具有重要的指导意义。论文还指出了传统网格拓扑的局限性，并提出了更优的方案，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为了优化低地球轨道（LEO）卫星网络的拓扑结构，以最小化平均最短路径长度（ASPL），从而提高卫星间的通信效率。

**Method:** 研究方法包括：
1. 考虑具有星间链路（ISL）连接的LEO卫星网络。
2. 通过重新定向ISL连接来优化网络拓扑，以最小化平均最短路径长度（ASPL）。
3. 在两种拓扑家族中表征最佳ASPL ISL拓扑：1) 顶点对称拓扑，其中ISL连接模式在所有卫星节点重复；2) 一般规则拓扑，其中不需要存在这种重复模式。
4. 为两种场景建立了ASPL下限，并展示了在假设每颗卫星进行3或4个ISL连接时可以实现这些下限的构造。
5. 通过仿真验证了所提出的拓扑结构在网络规模扩展时能接近下限。

**Result:** 1. 对于对称情况，网格拓扑在ASPL和直径方面都是次优的。
2. 存在可以保持轨道内ISL连接，同时仍能实现接近最优ASPL性能的构造。
3. 对于一般情况，当网络足够密集时，可以构建ASPL接近一般下限的网络。
4. 仿真结果表明，对于这两种情况，随着网络规模的扩大，可以找到非常接近下限的拓扑结构。

**Conclusion:** 该研究成功地为低地球轨道卫星网络设计了优化的星间链路拓扑，以最小化平均最短路径长度。研究为顶点对称和一般规则拓扑两种情况建立了ASPL下限，并展示了在可控的ISL连接数下，能够构建出性能接近理论最优的卫星网络拓扑，证明了所提出设计的有效性和可扩展性。

> **ai_Abstract:** 该论文专注于低地球轨道（LEO）卫星网络的星间链路（ISL）拓扑优化，旨在最小化平均最短路径长度（ASPL）。研究在顶点对称和一般规则两种拓扑家族中表征了最优ASPL ISL拓扑，并建立了相应的ASPL下限。论文展示了在每个卫星具有3或4个ISL连接时能够实现这些下限的构造，并指出网格拓扑在对称情况下是次优的。此外，研究还提出了在保持轨道内ISL连接的同时实现近最优ASPL性能的构造。仿真结果验证了所提出的拓扑在网络规模扩展时能接近理论下限。

> **摘要翻译:** 我们考虑一个低地球轨道（LEO）卫星网络，其中每颗卫星都能够建立星间链路（ISL）连接以进行卫星间通信。由于ISL可以重新定向以改变拓扑结构，我们优化了拓扑结构以最小化平均最短路径长度（ASPL）。我们描述了两种拓扑家族中的最佳ASPL ISL拓扑：1）顶点对称拓扑，其中卫星节点处的ISL连接代表一种在所有其他卫星节点重复的模式；2）一般规则拓扑，其中不需要存在这种重复模式。我们为这两种情况建立了ASPL下限，并展示了在假设每颗卫星进行3或4个ISL连接时可以实现这些下限的构造。对于对称情况，我们表明网格拓扑在ASPL和直径方面都是次优的。此外，我们表明存在可以保持轨道内ISL连接，同时仍能实现接近最优ASPL性能的构造。对于一般情况，我们表明当网络足够密集时，可以构建ASPL接近一般下限的网络。仿真结果表明，对于这两种情况，随着网络规模的扩大，可以找到非常接近下限的拓扑结构。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [12] [Bounds and New Constructions for Girth-Constrained Regular Bipartite Graphs](https://arxiv.org/abs/2506.11268)
> *具有周长约束的正则二分图的界限和新构造*

*Sheida Rabeti, Mohsen Moradi, Hessam Mahdavifar* | **Main category: cs.IT**

**Keywords:** 正则二分图, 周长约束, LDPC码, 图构造, 界限

**Comment:** 

> **TL;DR:** 本文研究了具有周长约束的正则二分图的设计和分析，推导了顶点大小的界限，并提出了两种新的周长为8的构造方法，这些方法对高码率LDPC码设计有潜在贡献。

**AI_Comments:** 本文在图论层面为具有周长约束的正则二分图提供了理论界限和实用的构造方法。其创新之处在于提出了两种新的周长为8的二分图构造，特别是第二种基于无等差数列的整数序列的方法，实现了渐近最优性。尽管研究侧重于图论，但其成果直接针对LDPC码设计中的关键挑战——高周长和稀疏性，这对于提高LDPC码的性能（如最小距离）至关重要，显示了其重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究正则二分图的设计和分析，因为它们在低密度奇偶校验（LDPC）码中的应用，特别是在受限周长和高码率情况下。

**Method:** 本文推导了正则二分图中顶点大小的界限，并提出了两种周长为8的二分图构造方法：一种基于(wc, wr)-正则图的贪婪构造，另一种基于半正则图，该图利用了没有长度为3等差数列的整数序列且渐近最优。

**Result:** 导出了正则二分图中顶点大小的界限，揭示了随着周长增大，校验节点数相对于变量节点数的增长关系。提出了两种周长为8的二分图新构造方法，其中第二种是渐近最优的。这两种构造都能为具有中等到大块长度的高码率代码提供稀疏奇偶校验矩阵。

**Conclusion:** 本研究结果主要集中在图论问题，但有望为设计高周长和最小距离的LDPC码（特别是在高码率下）的持续努力做出贡献。

> **ai_Abstract:** 本文研究了具有周长约束的正则二分图，旨在应用于高码率LDPC码。作者推导了图周长与节点大小关系的界限，并提出了两种周长为8的二分图新构造方法，其中一种是渐近最优的。这些构造有助于为高码率码设计稀疏奇偶校验矩阵，并对LDPC码的设计具有潜在贡献。

> **摘要翻译:** 在本文中，我们探讨了正则二分图的设计和分析，其动机是它们在低密度奇偶校验（LDPC）码中的应用，特别是在受限周长和高码率情况下。我们关注图的周长与变量节点和校验节点集合大小之间的关系。我们推导了正则二分图中顶点大小的界限，展示了随着周长增大，所需校验节点数如何随变量节点数增长。此外，我们提出了两种周长为$\mathcal{G} = 8$的二分图构造方法；一种基于$(w_c, w_r)$-正则图的贪婪构造，另一种基于半正则图，该图具有均匀列权重分布和亚线性数量的校验节点。第二种构造利用了没有长度为3等差数列的整数序列，并且在保持周长为8的同时渐近最优。此外，这两种构造都可以为具有中等到大块长度的高码率代码提供稀疏奇偶校验矩阵。我们的结果仅关注图论问题，但可能有助于当前设计具有高周长和最小距离的LDPC码的努力，特别是在高码率下。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [40] [Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul](https://arxiv.org/abs/2506.11284)
> *免蜂窝MIMO有限前传下行链路自适应压缩*

*Zehua Li, Jingjie Wei, Raviraj Adve* | **Main category: cs.IT**

**Keywords:** 免蜂窝MIMO, 上行链路压缩, 自适应压缩, 去中心化, 有限前传

**Comment:** Presented in IEEE International Conference on Communications (ICC)
  2025, 6 pages, 2 figures

> **TL;DR:** 本文研究了免蜂窝MIMO网络中有限前传容量下的上行链路压缩问题。提出了一种基于速率的自适应压缩方法，能够同时确定维度和压缩比，并在去中心化实现中表现出与中心化方法相当的性能。

**AI_Comments:** 这篇论文的创新点在于提出了基于速率的自适应压缩方法，而非传统的基于变换的方法，从而使得压缩过程能够更好地适应网络动态变化。此外，实现去中心化处理是其重要贡献，这对于实际部署具有重要意义，因为它降低了对中心单元的计算和通信负担，并提高了系统的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 在免蜂窝多输入多输出（MIMO）网络中，远程无线电头（RRH）需要将接收到的信号压缩并转发到中央单元进行联合处理，但前传容量有限。以往工作多采用基于变换的方法，本文旨在提出一种更灵活的、能适应网络流量和前传限制的压缩方案。

**Method:** 本文提出了一种基于速率的自适应压缩方法，该方法能够同时自适应地确定压缩维度和压缩比。以互信息为目标，推导了自适应压缩的理论网络容量，并解耦表达式以实现去中心化。此外，利用信道统计信息和用户流量密度，提出了计算有效旁侧信息表示的方法，该信息总结了全局信道状态信息并与RRH共享以辅助压缩。

**Result:** 获得了自适应压缩的理论网络容量，并实现了表达式的去中心化。去中心化实现的自适应压缩在保持低信息交换开销的同时，与中心化方法相比，显示出具有竞争力的整体网络性能。

**Conclusion:** 本文提出的去中心化自适应压缩方法，在有限前传容量的免蜂窝MIMO网络中，能够有效应对网络流量和前传限制的变化，并取得了与中心化方法相当的性能。

> **ai_Abstract:** 本文针对有限前传容量的免蜂窝MIMO网络上行链路压缩问题，提出了一种基于速率的去中心化自适应压缩方法。该方法能够根据网络流量和前传限制动态调整压缩维度和比率，并通过解耦互信息目标函数实现去中心化。研究还探讨了如何有效生成和共享全局信道状态信息作为辅助压缩的旁侧信息。实验结果表明，该去中心化方法在低信息交换开销下，仍能实现与中心化方法相当的网络性能。

> **摘要翻译:** 我们研究了具有有限前传容量的免蜂窝多输入多输出网络中的上行链路压缩问题。在压缩转发模式下，远程无线电头（RRH）压缩接收到的信号并将其转发到中央单元进行联合处理。虽然之前的工作主要集中在基于变换的方法上，该方法优化了将高维信号降至静态预定低维的变换矩阵，但我们提出了一种基于速率的方法，该方法能够同时自适应地找到维度和压缩。我们的方法适应了网络流量和前传限制的变化。以互信息为目标，我们获得了自适应压缩的理论网络容量，并解耦了表达式以实现去中心化。此外，利用信道统计和用户流量密度，我们展示了计算旁侧信息有效表示的不同方法，该信息总结了全局信道状态信息并与RRH共享以辅助压缩。在保持信息交换开销低的同时，我们去中心化的自适应压缩实现在整体网络性能上显示出与中心化方法相当的竞争力。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [68] [On the High-Rate FDPC Codes: Construction, Encoding, and a Generalization](https://arxiv.org/abs/2506.11345)
> *关于高速率FDPC码：构造、编码及泛化*

*Mohsen Moradi, Sheida Rabeti, Hessam Mahdavifar* | **Main category: cs.IT**

**Keywords:** FDPC码, 高速率, 纠错性能, 编码, 泛化

**Comment:** 

> **TL;DR:** 该论文介绍了一种针对高速率FDPC码的新颖构造方法、一种泛化形式以及一种低复杂度编码算法，并指出FDPC码在相同解码迭代次数下比5G LDPC码具有更优的纠错性能，且消息传递解码器收敛速度快。

**AI_Comments:** 该论文通过提出新的构造方法、泛化形式和高效编码算法，对FDPC码的改进做出了贡献，满足了高速率应用的需求。与5G LDPC码的性能对比突出了其实用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 公平密度奇偶校验（FDPC）码最近被引入，旨在高速率应用中提供卓越的纠错性能（ECP），在相同数量的消息传递解码迭代次数下，其性能优于5G低密度奇偶校验（LDPC）码。本研究旨在进一步探索和改进FDPC码。

**Method:** 本文提出了一种新颖的FDPC码构造方法，引入了这些码的泛化，并提出了一种低复杂度的编码算法。

**Result:** 数值结果表明FDPC码的消息传递解码器收敛速度快。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对高速率公平密度奇偶校验（FDPC）码，提出了一种新颖的构造方法、一种泛化形式以及一种低复杂度的编码算法。研究表明，FDPC码在相同解码迭代次数下比5G低密度奇偶校验（LDPC）码具有更优的纠错性能，并且其消息传递解码器展现出快速收敛的特性。

> **摘要翻译:** 最近引入的公平密度奇偶校验（FDPC）码，针对高速率应用，在相同数量的消息传递解码迭代次数下，与5G低密度奇偶校验（LDPC）码相比，提供了卓越的纠错性能（ECP）。在本文中，我们提出了一种新颖的FDPC码构造方法，引入了这些码的泛化，并提出了一种低复杂度的编码算法。数值结果表明FDPC码的消息传递解码器收敛速度快。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [96] [The complete weight distribution of a family of irreducible cyclic codes of dimension two](https://arxiv.org/abs/2506.11349)
> *二维不可约循环码族的全重量分布*

*Gerardo Vega, Félix Hernández* | **Main category: cs.IT**

**Keywords:** 循环码, 全重量分布, 不可约循环码, 有限域, 认证码

**Comment:** 

> **TL;DR:** 本文提出了一种无需复杂指数和计算的方法，确定了一类二维不可约循环码的全重量分布，并将其应用于构建最优或接近最优的认证码。

**AI_Comments:** 本文的创新之处在于提出了一种无需评估复杂指数和的方法来确定一类特定循环码的全重量分布，这克服了该领域的一个主要难点。其重要性体现在为循环码理论提供了新的工具，并展示了其在实际应用（如认证码设计）中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 循环码在数据存储、密码学、消费电子和网络编码中至关重要，但其完整的重量分布通常难以获得且已知情况甚少。获取这些分布对于许多研究领域和实际应用具有重要价值。

**Method:** 首先，确定了任意有限域$\bbbf_q$上形如$x^{q+1}-c$（其中$c \in \bbbf_{q}^*$）的多项式的显式因式分解。然后，利用此结果，无需评估任何指数和，获得了任意有限域上二维不可约循环码族的全重量分布。

**Result:** 成功确定了任意有限域上二维不可约循环码族的全重量分布，且无需评估复杂的指数和。作为应用，利用这些全重量分布构建了系统认证码，并表明它们是最优或接近最优的。

**Conclusion:** 本文解决了确定一类特定循环码全重量分布的难题，提供了一种无需复杂计算的方法，并展示了其在构建高效认证码方面的实际应用价值。

> **ai_Abstract:** 本文研究了循环码的全重量分布，指出其重要性和获取的难度。作者首先给出了有限域上特定形式多项式的显式因式分解，并以此为基础，无需复杂的指数和计算，成功确定了一类二维不可约循环码的全重量分布。研究结果被应用于构建最优或接近最优的系统认证码。

> **摘要翻译:** 用于数据存储系统、密码学、消费电子和网络编码中错误控制的重要代码族是所谓的循环码。这类线性码由于其高效的编码和解码算法也很重要。正因为如此，循环码已经被研究了很多年，然而它们的完整重量分布仅在少数情况下已知。完整重量分布在许多研究领域中具有广泛的应用，因为它所包含的信息在实际应用中至关重要。不幸的是，获得这些分布通常是一个非常困难的问题，通常涉及评估复杂的指数和，这使得这个问题对大多数循环码来说仍然是开放的。在本文中，我们确定了对于任何有限域$\bbbf_q$，形如$x^{q+1}-c$（其中$c \in \bbbf_{q}^*$）的任意多项式的显式因式分解。然后我们利用这个结果，无需评估任何类型的指数和，获得了任意有限域上二维不可约循环码族的全重量分布。作为我们发现的应用，我们利用这里提出的一些不可约循环码的完整重量分布来构建系统认证码，表明它们是最优或接近最优的。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [123] [Black-Box Edge AI Model Selection with Conformal Latency and Accuracy Guarantees](https://arxiv.org/abs/2506.11391)
> *具备共形延迟和精度保证的黑盒边缘AI模型选择*

*Anders E. Kalør, Tomoaki Ohtsuki* | **Main category: cs.IT**

**Keywords:** 边缘AI, 黑盒模型选择, 共形风险控制, 6G, 延迟保证

**Comment:** Submitted to IEEE for publication

> **TL;DR:** 提出一种用于可靠实时6G边缘AI的黑盒模型选择框架，通过共形风险控制确保延迟和精度，并在图像分类任务上得到验证。

**AI_Comments:** 该论文通过引入共形风险控制，为边缘AI的黑盒模型选择提供了一种创新方法，这对于提供可量化的延迟和精度保证至关重要。这对于关键的6G应用尤为重要。固定和动态双重方案增加了灵活性。考虑到许多已部署ML系统的特性，其对黑盒模型的关注具有实用意义。

<details>
  <summary>Details</summary>

**Motivation:** 6G边缘AI需要延迟和精度保证，但黑盒ML模型、任务复杂性和无线信道交互带来了挑战。

**Method:** 一种新颖的用于可靠实时无线边缘AI的黑盒模型选择框架，利用共形风险控制和非参数统计选择最佳模型组合。包括固定（基于信道统计）和动态（信道自适应）两种方案。

**Result:** 数值结果验证了该框架在受截止日期限制的图像分类任务上的有效性，并满足了最大误分类概率要求。

**Conclusion:** 所提出的框架有潜力在6G中提供可靠的实时边缘AI服务。

> **ai_Abstract:** 本文提出了一种新颖的黑盒模型选择框架，以解决6G边缘AI中提供延迟和精度保证的挑战。该框架利用共形风险控制和非参数统计，智能地选择最佳的黑盒特征提取和推理模型组合。它支持固定和动态（信道自适应）两种方案。在受截止日期限制的图像分类任务上进行的验证表明，该框架有潜力在6G中提供可靠的实时边缘AI服务。

> **摘要翻译:** 边缘人工智能（AI）将成为6G的核心组成部分，强大的边缘服务器支持设备执行机器学习（ML）推理。然而，提供自动驾驶和机器人等6G应用所需的延迟和精度保证具有挑战性。这源于ML模型的黑盒特性、任务的复杂性以及传输数据质量、所选推理模型和随机无线信道之间的相互作用。本文提出了一种新颖的黑盒模型选择框架，用于可靠的实时无线边缘AI，旨在满足预定义的截止日期违规概率和预期损失要求。我们的框架利用共形风险控制和非参数统计，从一系列不同复杂度和计算时间的黑盒特征提取和推理模型中智能地选择最佳模型组合。我们提出了固定（依赖信道统计）和动态（信道自适应）两种模型选择方案。数值结果在受截止日期限制的图像分类任务上验证了该框架，同时满足了最大误分类概率要求。这些结果表明所提出的框架有潜力在6G中提供可靠的实时边缘AI服务。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [148] [On Differential and Boomerang Properties of a Class of Binomials over Finite Fields of Odd Characteristic](https://arxiv.org/abs/2506.11486)
> *关于奇特征有限域上一类二项式的微分和回旋性质*

*Namhun Koo, Soonhak Kwon* | **Main category: cs.IT**

**Keywords:** 微分均匀性, 回旋均匀性, 有限域, 二项式, 密码学函数

**Comment:** 

> **TL;DR:** 研究了一类在奇特征有限域上的二项式的微分和回旋性质，发现它们在特定条件下具有低回旋均匀性，并提供了详细的谱分类。

**AI_Comments:** 该论文对一类特定二项式函数的密码学性质进行了深入研究。其主要创新点在于发现了在奇特征域上具有零回旋均匀性的非PN函数，填补了该领域的一个空白。这对于设计具有良好密码学抗性的S盒具有重要意义，尤其是在高阶微分和回旋攻击背景下。研究结果提供了详细的谱分类，有助于理解这些函数的行为。

<details>
  <summary>Details</summary>

**Motivation:** 研究一类特殊二项式在奇特征有限域上的微分和回旋性质，这些性质对于密码学中的S盒设计至关重要。

**Method:** 通过分析特定参数下函数$F_{r,u}(x)$的性质，计算其微分和回旋均匀性，并对微分和回旋谱进行完整分类。

**Result:** 1. 当$p^n \equiv 3 \pmod{8}$时，$F_{r,\pm1}$是局部PN函数，回旋均匀性为0。
2. 这是第二个已知的非PN函数类，其回旋均匀性为0，也是第一个在$p > 3$的奇特征域上的此类例子。
3. 当$p^n \equiv 7 \pmod{8}$时，$F_{r,\pm1}$是局部APN函数，回旋均匀性至多为2。
4. 提供了$F_{r,\pm1}$的微分和回旋谱的完整分类。
5. 深入研究了当$u\in \mathbb{F}_{p^n}^* \setminus \{\pm1\}$时$F_{r,u}$的微分均匀性。

**Conclusion:** 论文成功地刻画了所研究二项式在奇特征有限域上的微分和回旋性质，揭示了其在特定条件下的优良密码学特性，尤其是在回旋均匀性方面取得了重要发现。

> **ai_Abstract:** 本文深入分析了一类定义在奇特征有限域上的二项式$F_{r,u}(x) = x^r(1 + u\chi(x))$的微分和回旋性质。研究发现，当$p^n \equiv 3 \pmod{8}$时，$F_{r,\pm1}$是局部PN函数且回旋均匀性为0，这是在该领域的一个重要发现。当$p^n \equiv 7 \pmod{8}$时，它表现为局部APN函数，回旋均匀性至多为2。论文还给出了$F_{r,\pm1}$的微分和回旋谱的完整分类，并探讨了其他参数$u$下的微分均匀性。

> **摘要翻译:** 在本文中，我们研究了一类在有限域$\mathbb{F}_{p^n}$上的二项式$F_{r,u}(x) = x^r(1 + u\chi(x))$的微分和回旋性质，其中$r = \frac{p^n+1}{4}$，$p^n \equiv 3 \pmod{4}$，并且$\chi(x) = x^{\frac{p^n -1}{2}}$是$\mathbb{F}_{p^n}$中的二次特征。我们表明，当$p^n \equiv 3 \pmod{8}$时，$F_{r,\pm1}$是局部PN函数，回旋均匀性为0。据我们所知，这是第二个已知的回旋均匀性为0的非PN函数类，并且是第一个在$p > 3$的奇特征域上的此类例子。此外，我们表明，当$p^n \equiv 7 \pmod{8}$时，$F_{r,\pm1}$是局部APN函数，回旋均匀性至多为2。我们还提供了$F_{r,\pm1}$的微分和回旋谱的完整分类。此外，我们还深入研究了当$u\in \mathbb{F}_{p^n}^* \setminus \{\pm1\}$时$F_{r,u}$的微分均匀性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [170] [Last-Pair Swapping Polar Codes: A Structure to Improve Polarization on Channels with Memory](https://arxiv.org/abs/2506.11535)
> *末对交换极化码：一种提高记忆信道极化效率的结构*

*Yinuo Mei, Yangyong Zhang, Daiming Qu* | **Main category: cs.IT**

**Keywords:** 极化码, 记忆信道, 极化效率, 网格信道, 交换矩阵

**Comment:** 23 pages, 15 figures

> **TL;DR:** 本文提出了一种新的极化码结构（末对交换结构），用于记忆信道，以提高极化效率，并在某些特定记忆信道上达到与无记忆信道上传统极化码相同的性能。

**AI_Comments:** 本文的创新点在于提出了“末对交换结构”来应对记忆信道上的极化性能下降问题。通过对网格信道的细致分类，并针对性地引入交换矩阵，有效提高了极化效率。其重要性在于为极化码在更复杂的信道环境下的应用提供了新的思路和性能提升。文章不仅通过仿真验证了其有效性，还在特定条件下提供了理论证明，增加了研究的严谨性。同时，对局限性的分析也体现了研究的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 为了在记忆信道上提高极化效率，并使其接近传统极化码在无记忆信道上的极化效率。

**Method:** 本文将网格信道分为子内射网格信道和非子内射网格信道。对于子内射网格信道，通过用交换矩阵替换极化编码结构中每层的最后一个核，提出了名为“末对交换结构”的新编码结构。

**Result:** 仿真结果表明，在子内射网格信道上，所提出的极化码的极化效率超过了传统极化码。在称为双射网格信道的特殊子内射网格信道上，所提出的结构实现了与无记忆信道上传统极化码相同的极化效率，并得到了理论证明。在连续相位调制（CPM）与附加高斯白噪声（AWGN）信道上的误码率仿真结果显示，与传统极化码相比，所提出的极化码具有显著的信噪比增益，并且在双射网格信道上，所提出的极化码与无记忆信道上的传统极化码性能相同。

**Conclusion:** 所提出的末对交换极化码结构能够显著提高记忆信道上的极化效率，尤其是在子内射网格信道上表现优越，并且在双射网格信道上能达到与无记忆信道上传统极化码相同的性能。

> **ai_Abstract:** 本文提出了一种名为“末对交换结构”的新型极化码，旨在改善记忆信道上的极化效率。通过将网格信道分类为子内射和非子内射类型，并针对子内射网格信道，用交换矩阵替换极化编码层中的最后一个核。仿真结果表明，该结构在子内射网格信道上表现出更高的极化效率和显著的信噪比增益。特别地，在双射网格信道上，该结构能够达到与无记忆信道上传统极化码相同的极化效率，并得到了理论验证。论文还分析了该结构的局限性。

> **摘要翻译:** 提出了一种用于记忆信道的新型极化码结构，以提高极化效率并接近传统极化码在无记忆信道上的极化效率。我们将一种特定类型的有限状态信道——网格信道——分为两类：子内射网格信道和非子内射网格信道，其中在前一类中观察到明显的极化损失。对于子内射网格信道，我们将极化编码结构中每层的最后一个核替换为交换矩阵，从而形成了我们提出的名为“末对交换结构”的编码结构。仿真结果表明，在子内射网格信道上，所提出的极化码的极化效率超过了传统极化码。此外，我们指出了一种特殊类型的子内射网格信道，称为双射网格信道，并表明在此类信道上，所提出的结构实现了与无记忆信道上传统极化码相同的极化效率，这一点后来得到了理论证明。此外，本文还分析了所提出结构的局限性。在连续相位调制（CPM）与附加高斯白噪声（AWGN）信道上给出了误码率仿真结果，显示所提出的极化码比传统极化码具有显著的信噪比（SNR）增益，并且在双射网格信道上，所提出的极化码与无记忆信道上的传统极化码性能相同。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [11] [Design and Implementation of Washing Machine HUD Using FPGAs](https://arxiv.org/abs/2506.11287)
> *基于FPGA的洗衣机HUD设计与实现*

*Norman Stites, D. G. Perera* | **Main category: cs.AR**

**Keywords:** FPGA, 洗衣机, HUD, 硬件模拟, VGA接口

**Comment:** 16 pages, 4 figures

> **TL;DR:** 该项目使用FPGA开发板设计并实现了一个家用洗衣机控制器的硬件模拟，并通过VGA接口显示实时信息。

**AI_Comments:** 该论文展示了一个将FPGA应用于实际设备控制的教育项目，强调了实践性在数字设计中的重要性。其创新点在于将HUD概念引入到家用电器控制界面中，并利用FPGA实现硬件级模拟，为学生提供了一个真实的实践平台。其重要性在于提供了一个具体的案例，说明如何将理论知识转化为实际可操作的硬件系统。

<details>
  <summary>Details</summary>

**Motivation:** 在当代数字设计教育中，实用的现场可编程门阵列（FPGA）项目对于将理论概念与实际应用联系起来是不可或缺的。

**Method:** 该项目使用Xilinx Spartan-3E开发板开发了一个家用洗衣机控制器的硬件模拟。设计中的一个关键组件是图形平视显示器（HUD），它通过VGA接口实时显示机器的运行状态和周期选择。

**Result:** 成功开发了一个洗衣机控制器的硬件模拟，并实现了通过VGA接口渲染实时操作状态和周期选择信息的图形HUD。

**Conclusion:** 该项目成功地将FPGA技术应用于家用洗衣机控制器的硬件模拟，并通过图形HUD提供了实时的操作信息，展示了FPGA在数字设计教育和实际应用中的价值。

> **ai_Abstract:** 本项目旨在利用Xilinx Spartan-3E FPGA开发板，设计并实现一个家用洗衣机控制器的硬件模拟。该模拟包含一个关键的图形平视显示器（HUD），通过VGA接口实时显示洗衣机的运行状态和周期选择信息，旨在弥合数字设计理论与实际应用之间的差距。

> **摘要翻译:** 在当代数字设计教育中，实用的现场可编程门阵列（FPGA）项目对于将理论概念与实际应用联系起来是不可或缺的。本项目致力于使用Xilinx Spartan-3E开发板开发一个家用洗衣机控制器的硬件模拟。设计中的一个关键组件是图形平视显示器（HUD），它通过VGA接口实时显示机器的运行状态和周期选择。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [39] [A4: Microarchitecture-Aware LLC Management for Datacenter Servers with Emerging I/O Devices](https://arxiv.org/abs/2506.11329)
> *A4：面向新兴I/O设备的微架构感知LLC管理在数据中心服务器中的应用*

*Haneul Park, Jiaqi Lou, Sangjin Lee, Yifan Yuan, Kyoung Soo Park, Yongseok Son, Ipoom Jeong, Nam Sung Kim* | **Main category: cs.AR**

**Keywords:** LLC管理, 微架构, I/O设备, 数据中心, 缓存争用

**Comment:** 

> **TL;DR:** 本文揭示了英特尔至强CPU中由新兴高带宽I/O设备触发的两种未被识别的LLC争用问题（C1和C2），并提出了一个名为\design的运行时LLC管理框架，该框架利用隐藏的硬件特性来缓解这些争用，从而将高优先级工作负载的性能提升了51%。

**AI_Comments:** 本文的创新点在于揭示了英特尔至强CPU中两种以前未被识别的LLC争用机制，特别是利用了“隐藏旋钮”这一未公开的硬件特性进行LLC管理，这对于优化数据中心服务器性能具有重要意义。通过对微架构深层次的理解，该工作为解决I/O密集型工作负载下的缓存性能瓶颈提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现代服务器CPU中的末级缓存（LLC）不仅作为上层私有缓存的受害者缓存，还通过直接缓存访问（DCA）作为CPU核心与I/O设备之间低延迟DMA传输的缓冲区。然而，现有的研究表明，高带宽网络I/O设备会迅速淹没LLC，导致与并发工作负载的显著争用。本文进一步探索了英特尔至强CPU中隐藏的微架构特性，揭示了两种以前未被识别的由新兴高带宽I/O设备触发的LLC争用问题。

**Method:** 本文提出了一个名为\design的运行时LLC管理框架，旨在缓解由新兴高带宽I/O设备引起的两种新的LLC争用（C1和C2），以及其他已知的网络I/O驱动的LLC争用。该框架利用了这些CPU中实现的隐藏旋钮和其他硬件特性。

**Result:** \design框架将延迟敏感型高优先级工作负载的性能提高了51%，同时并未显著损害低优先级工作负载的性能。

**Conclusion:** 本文揭示了英特尔至强CPU中由新兴高带宽I/O设备引起的两种新的LLC争用问题，并提出了一个有效的运行时LLC管理框架\design，该框架能够显著提升高优先级工作负载的性能。

> **ai_Abstract:** 本文深入研究了英特尔至强CPU的微架构，揭示了由新兴高带宽I/O设备引发的两种此前未被识别的末级缓存（LLC）争用问题：C1是DMA写入的DCA通道缓存行在被CPU访问时迁移到包含通道，与非I/O缓存行发生争用；C2是高带宽存储I/O设备在DCA通道中与网络I/O设备争用，而自身获益甚微。为解决这些问题，论文提出了一个名为\design的运行时LLC管理框架，该框架利用CPU的隐藏硬件特性来缓解这些争用，并展示了其能将高优先级工作负载的性能提升51%，同时不明显影响低优先级工作负载。

> **摘要翻译:** 在现代服务器CPU中，末级缓存（LLC）不仅作为更高级别私有缓存的受害者缓存，还作为CPU核心与I/O设备之间通过直接缓存访问（DCA）进行低延迟DMA传输的缓冲区。然而，先前的研究表明，高带宽网络I/O设备会迅速用数据包淹没LLC，经常导致与并发工作负载的显著争用。本文进一步探索了英特尔至强CPU中隐藏的微架构特性，揭示了两种以前未被识别的由新兴高带宽I/O设备触发的LLC争用。具体来说，（C1）当CPU核心访问DCA指定LLC通道（称为DCA通道）中的DMA写入缓存行时，这些缓存行会迁移到某些LLC通道（称为包含通道），意外地与包含通道内的非I/O缓存行发生争用。此外，（C2）数据中心服务器中日益普遍的高带宽存储I/O设备从DCA中获益甚微，却与DCA通道内的（延迟敏感型）网络I/O设备发生争用。为此，我们提出了\design，一个运行时LLC管理框架，旨在利用这些CPU中实现的隐藏旋钮和其他硬件特性，缓解各种并发工作负载之间的（C1）和（C2）问题。此外，我们证明了\design还可以缓解其他先前已知的网络I/O驱动的LLC争用。总的来说，它将延迟敏感型高优先级工作负载的性能提高了51%，而没有显著损害低优先级工作负载的性能。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [67] [DPUV4E: High-Throughput DPU Architecture Design for CNN on Versal ACAP](https://arxiv.org/abs/2506.11441)
> *DPUV4E：面向Versal ACAP上CNN的高吞吐量DPU架构设计*

*Guoyu Li, Pengbo Zheng, Jian Weng, Enshan Yang* | **Main category: cs.AR**

**Keywords:** DPU, CNN, Versal ACAP, FPGA, 高吞吐量

**Comment:** 10 pages, 9 figures

> **TL;DR:** 本文提出了一种名为DPUV4E的高吞吐量DPU架构，专为AMD Versal ACAP设计，通过优化计算单元和数据流，显著提升了CNN推理的性能和资源利用率，解决了现有FPGA和Versal平台面临的挑战。

**AI_Comments:** 本文的创新点在于针对AMD Versal ACAP的AI引擎特性，设计了专门的DPU架构DPUV4E，并通过细致的计算单元（Conv PE和DWC PE）和数据流优化，有效缓解了内存带宽瓶颈并提升了数据重用。此外，利用AIE处理非卷积操作，进一步提高了资源利用率。这些优化使得DPUV4E在性能和资源效率上取得了显著提升，对于在异构FPGA平台上部署CNN具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 卷积神经网络（CNN）在计算机视觉应用中依然普遍，而FPGA因其灵活性和能效成为异构加速系统的重要组成部分。然而，传统FPGA在性能和通用性之间难以平衡，且片上资源有限。AMD的Versal ACAP架构虽然专为AI设计并集成了AI引擎（AIE），但其内存带宽不足，限制了AIE理论性能的充分发挥。

**Method:** 本文提出了针对Versal架构的DPUV4E，提供从2PE（32.6 TOPS）到8PE（131.0 TOPS）的配置。设计了Conv PE和DWC PE两种计算单元以支持不同的计算模式。每个计算单元的数据流都高效利用数据重用机会以缓解带宽瓶颈。此外，扩展了每个PE的功能，利用AIE进行非卷积操作，从而减少了资源开销。

**Result:** 在超过50个模型上的实验表明，与以往设计相比，DPUV4E的TOPS/W是传统基于FPGA的DPU设计的8.6倍，同时DSP使用量减少95.8%，LUT使用量减少44.7%，单批次条件下延迟降低到68.5%。对于端到端推理，DPUV4E将深度可分离卷积模型的吞吐量提高了2.2倍，标准模型的吞吐量提高了1.3倍。

**Conclusion:** DPUV4E架构通过专门的计算单元设计和高效的数据流管理，显著提升了在AMD Versal ACAP上CNN推理的性能和资源效率，有效克服了现有FPGA和Versal平台面临的内存带宽和资源限制问题。

> **ai_Abstract:** 本文提出了一种名为DPUV4E的高吞吐量DPU架构，专为AMD Versal ACAP设计，旨在解决传统FPGA资源限制和Versal平台内存带宽不足的问题。DPUV4E通过设计Conv PE和DWC PE两种计算单元，优化数据流以提高数据重用，并利用AI引擎进行非卷积操作，显著提升了CNN推理的性能和资源效率。实验结果显示，DPUV4E在TOPS/W、资源利用率和吞吐量方面均大幅优于现有设计。

> **摘要翻译:** 卷积神经网络（CNN）在计算机视觉应用中依然普遍，而FPGA因其灵活性和能效，已成为异构加速系统的重要组成部分。然而，传统FPGA由于片上资源有限，在平衡性能和通用性方面面临挑战。AMD的Versal ACAP架构专为AI应用量身定制，集成了AI引擎（AIE）以提供高计算能力。尽管如此，该平台存在内存带宽不足的问题，阻碍了AIE理论性能的充分利用。在本文中，我们提出了用于Versal架构的DPUV4E，提供从2PE（32.6 TOPS）到8PE（131.0 TOPS）的配置。我们设计了两种计算单元，Conv PE和DWC PE，以支持不同的计算模式。每个计算单元的数据流都有效利用数据重用机会以缓解带宽瓶颈。此外，我们扩展了每个PE的功能，利用AIE进行非卷积操作，减少了资源开销。在超过50个模型上的实验表明，与以往设计相比，我们的设计提供了传统基于FPGA的DPU设计8.6倍的TOPS/W，同时DSP使用量减少95.8%，LUT使用量减少44.7%，单批次条件下延迟降低到68.5%。对于端到端推理，我们的设计将深度可分离卷积模型的吞吐量提高了高达2.2倍，标准模型的吞吐量提高了高达1.3倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [95] [Topology-Aware Virtualization over Inter-Core Connected Neural Processing Units](https://arxiv.org/abs/2506.11446)
> *核间互联神经网络处理单元上的拓扑感知虚拟化*

*Dahu Feng, Erhu Feng, Dong Du, Pinjie Xu, Yubin Xia, Haibo Chen, Rong Zhao* | **Main category: cs.AR**

**Keywords:** 核间互联NPU, 虚拟化, 拓扑感知, 资源利用率, 性能

**Comment:** 

> **TL;DR:** vNPU是一种针对核间互联NPU的全面虚拟化设计，通过集成路由、内存虚拟化和拓扑映射技术，显著提高了机器学习模型的性能和资源利用率，且硬件成本极低。

**AI_Comments:** 这项研究的创新之处在于它是首个针对核间互联NPU的全面虚拟化设计，填补了现有研究的空白。通过引入路由、内存虚拟化和拓扑映射等独特技术，vNPU有效地解决了这类复杂硬件的资源利用率和性能瓶颈。其在提供显著性能提升的同时保持极低的硬件成本，显示了其潜在的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI应用的快速发展，核间互联神经网络处理单元（NPU）被广泛采用。然而，这些NPU通常需要大量硬件资源，导致因任务硬件需求不平衡而造成的资源利用率低下。现有研究虽探索了单片NPU的虚拟化技术，但忽略了具有硬件拓扑的核间互联NPU。

**Method:** 本文提出了vNPU，这是首个针对核间互联NPU的全面虚拟化设计，集成了三种新颖技术：1) NPU路由虚拟化，将指令和数据流从虚拟NPU核心重定向到物理核心，创建虚拟拓扑；2) NPU内存虚拟化，旨在最大限度地减少SRAM中心和配备NoC的NPU核心的转换停顿，从而最大化内存带宽；3) 最佳努力拓扑映射，从所有候选虚拟拓扑中确定最佳映射，平衡资源利用率和端到端性能。研究人员在FPGA平台（Chipyard+FireSim）和模拟器（DCRA）上开发了vNPU原型。

**Result:** 评估结果表明，与统一虚拟内存和MIG等其他虚拟化方法相比，vNPU在各种机器学习模型上实现了高达2倍的性能提升，而硬件成本仅为2%。

**Conclusion:** vNPU是首个针对核间互联神经网络处理单元的全面虚拟化设计，通过其创新技术有效解决了资源利用率低下的问题，并在保持低硬件成本的同时显著提升了性能。

> **ai_Abstract:** 本文提出vNPU，这是首个针对核间互联神经网络处理单元（NPU）的全面虚拟化设计，旨在解决现有NPU因任务硬件需求不平衡导致的资源利用率低下问题。vNPU集成了NPU路由虚拟化、NPU内存虚拟化和最佳努力拓扑映射三项关键技术，能够创建虚拟拓扑、最大化内存带宽并优化资源利用与性能。在FPGA平台和模拟器上的原型评估显示，vNPU相较于其他虚拟化方法，在多种机器学习模型上实现了高达2倍的性能提升，而硬件成本仅为2%。

> **摘要翻译:** 随着人工智能（AI）应用的快速发展，一类新兴的AI加速器，即核间互联神经网络处理单元（NPU），已被云端和边缘计算环境采用，如Graphcore IPU、Tenstorrent等。尽管其设计具有创新性，但这些NPU通常需要大量的硬件资源，由于各种任务的硬件需求不平衡，导致资源利用率低下。为了解决这个问题，先前的研究探索了单片NPU的虚拟化技术，但忽略了具有硬件拓扑的核间互联NPU。
本文介绍了vNPU，这是首个针对核间互联NPU的全面虚拟化设计，集成了三项新颖技术：(1) NPU路由虚拟化，它将指令和数据流从虚拟NPU核心重定向到物理核心，创建虚拟拓扑；(2) NPU内存虚拟化，旨在最大限度地减少SRAM中心和配备NoC的NPU核心的转换停顿，从而最大限度地提高内存带宽；(3) 最佳努力拓扑映射，它从所有候选虚拟拓扑中确定最佳映射，平衡资源利用率和端到端性能。我们已经在FPGA平台（Chipyard+FireSim）和模拟器（DCRA）上开发了vNPU原型。评估结果表明，与统一虚拟内存和MIG等其他虚拟化方法相比，vNPU在各种ML模型上实现了高达2倍的性能提升，而硬件成本仅为2%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [122] [FractalSync: Lightweight Scalable Global Synchronization of Massive Bulk Synchronous Parallel AI Accelerators](https://arxiv.org/abs/2506.11668)
> *FractalSync: 大规模体同步并行AI加速器的轻量级可扩展全局同步*

*Victor Isachi, Alessandro Nadalini, Riccardo Fiorani Gallotta, Angelo Garofalo, Francesco Conti, Davide Rossi* | **Main category: cs.AR**

**Keywords:** AI加速器, 全局同步, 体同步并行, 硬件加速, FractalSync

**Comment:** 

> **TL;DR:** FractalSync是一种硬件加速的同步机制，用于大规模体同步并行（BSP）AI加速器，相比软件原子内存操作，可实现高达43倍的同步加速，且面积开销可忽略不计。

**AI_Comments:** 这篇论文的创新之处在于提出了FractalSync，一个专门针对大规模AI加速器同步问题的硬件加速解决方案。其重要性体现在通过硬件层面的优化，显著提升了同步效率，同时保持了极低的面积开销，这对于构建高性能、高能效的AI计算平台至关重要。研究还通过在不同规模的PE网格上进行评估，验证了其可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 随着技术扩展的放缓和人工智能（AI）工作负载的出现，计算机架构师越来越多地利用并行化结合硬件加速来提升性能。然而，这种方案面临着大规模异构多核平台中处理单元（PE）同步的挑战。

**Method:** 本文提出了一种名为FractalSync的硬件加速同步机制，专为体同步并行（BSP）系统设计。该机制被集成到一个可扩展的基于瓦片的AI加速器MAGIA中，每个瓦片包含一个RISC-V处理器、矩阵乘法（MatMul）加速器、暂存存储器（SPM）以及连接到全局网状片上网络（NoC）的DMA。研究通过在2x2到16x16 PE的瓦片网格上评估其设计边界，来研究所提出的屏障同步方案的可扩展性。

**Result:** 与基于软件原子内存操作（AMOs）的同步方案相比，所提出的解决方案在同步方面实现了高达43倍的加速，同时引入了可忽略不计的面积开销（<0.01%）。FractalSync在MAGIA的目标1GHz频率下达到了时序收敛。

**Conclusion:** FractalSync为大规模体同步并行AI加速器提供了一种高效、可扩展且低开销的硬件加速同步解决方案，显著提升了同步性能。

> **ai_Abstract:** 本研究提出FractalSync，一种硬件加速的同步机制，旨在解决大规模异构多核AI加速器中的处理单元同步挑战。该机制被集成到基于瓦片的AI加速器MAGIA中，并在不同规模的瓦片网格上进行了评估。实验结果表明，与基于软件原子内存操作的方案相比，FractalSync在同步速度上实现了显著提升（高达43倍），同时面积开销极小（<0.01%），并在目标频率下表现稳定，证明了其作为高效、可扩展同步解决方案的潜力。

> **摘要翻译:** 技术扩展的放缓和人工智能（AI）工作负载的出现，促使计算机架构师越来越多地利用并行化与硬件加速相结合来不断提升性能。然而，这种解决方案面临着大规模异构多核平台中处理单元（PE）同步的挑战。为解决这一挑战，我们提出了FractalSync，一种用于体同步并行（BSP）系统的硬件加速同步机制。我们将FractalSync集成到MAGIA中，这是一种可扩展的基于瓦片的AI加速器，每个瓦片都配备了一个RISC-V处理器、矩阵乘法（MatMul）加速器、暂存存储器（SPM）以及连接到全局网状片上网络（NoC）的DMA。我们研究了所提出的屏障同步方案在从2x2 PE到16x16 PE的瓦片网格上的可扩展性，以评估其设计边界。与基于软件原子内存操作（AMOs）的同步方案相比，所提出的解决方案在同步方面实现了高达43倍的加速，同时引入了可忽略不计的面积开销（<0.01%）。FractalSync在MAGIA的目标1GHz频率下达到了时序收敛。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [147] [Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference](https://arxiv.org/abs/2506.11925)
> *基于知识图谱嵌入和贝叶斯推理的换道预测架构的真实世界部署*

*M. Manzour, Catherine M. Elias, Omar M. Shehata, R. Izquierdo, M. A. Sotelo* | **Main category: cs.AR**

**Keywords:** 换道预测, 知识图谱嵌入, 贝叶斯推理, 真实世界部署, 自动驾驶安全

**Comment:** 

> **TL;DR:** 本文在真实硬件上部署并验证了一个基于知识图谱嵌入和贝叶斯推理的换道预测系统，该系统能提前3-4秒预测换道，并触发车辆制动以确保安全。

**AI_Comments:** 本文的创新点在于将换道预测算法从模拟和数据集层面推进到真实世界的硬件部署，有效弥合了理论与实践之间的鸿沟。其重要性在于通过提前预测并结合制动动作，显著提升了自动驾驶系统的安全性。

<details>
  <summary>Details</summary>

**Motivation:** 大多数换道预测研究局限于模拟或数据集，导致算法进展与实际道路部署之间存在差距。本文旨在弥合这一差距。

**Method:** 开发了一个基于知识图谱嵌入（KGEs）和贝叶斯推理的换道预测系统。该系统包含两个模块：感知模块（感知环境、转换特征为语言类别）和预训练的预测模块（执行KGE和贝叶斯推理模型，将预测转化为纵向制动动作）。

**Result:** 该预测系统能够在目标车辆换道前3到4秒进行预测，为自车提供了充足的反应时间，并允许目标车辆安全地完成换道。

**Conclusion:** 在真实硬件上的实验验证表明，该基于知识图谱嵌入和贝叶斯推理的换道预测系统是有效的，并能提高道路安全，成功地将算法进展应用于实际部署。

> **ai_Abstract:** 本文旨在弥合换道预测算法研究与实际部署之间的差距。研究人员在真实硬件上部署了一个基于知识图谱嵌入（KGEs）和贝叶斯推理的换道预测系统。该系统包含感知模块和预测模块，能够将环境感知转化为预测并触发纵向制动。实验结果表明，该系统能提前3-4秒准确预测目标车辆的换道，从而为自车提供充足的反应时间，确保换道安全。

> **摘要翻译:** 在过去几年中，换道预测的研究取得了长足的进展。然而，大多数研究仅限于模拟或从数据集中获得的结果，这在算法进步和道路部署之间留下了空白。这项工作通过在真实硬件上演示一个基于知识图谱嵌入（KGEs）和贝叶斯推理的换道预测系统来弥补这一空白。此外，自车采用纵向制动动作，以确保自身和周围车辆的安全。我们的架构由两个模块组成：(i) 感知模块，用于感知环境，导出输入数值特征，并将其转换为语言类别；并将其传达给预测模块；(ii) 预训练的预测模块，执行KGE和贝叶斯推理模型，以预测目标车辆的机动，并将预测转化为纵向制动动作。真实世界硬件实验验证表明，我们的预测系统能够提前三到四秒预测目标车辆的换道，为自车提供足够的反应时间，并允许目标车辆安全地完成换道。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [15] [SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding](https://arxiv.org/abs/2506.11309)
> *SwiftSpec：通过扩展异步推测解码实现超低延迟LLM解码*

*Ziyi Zhang, Ziheng Jiang, Chengquan Jiang, Menghan Yu, Size Zheng, Haibin Lin, Henry Hoffmann, Xin Liu* | **Main category: cs.DC**

**Keywords:** LLM解码, 推测解码, 低延迟, 张量并行, 异步处理

**Comment:** 

> **TL;DR:** SwiftSpec通过异步和解耦的推测解码管道，解决了现有推测解码与张量并行结合的挑战，显著提升了LLM的低延迟解码速度，尤其在大规模模型服务中表现出色。

**AI_Comments:** SwiftSpec的创新之处在于其异步和解耦的推测解码管道设计，这有效地解决了大规模LLM在低延迟场景下，推测解码与张量并行难以同时应用的瓶颈。通过将草稿模型从关键路径中移除并优化资源分配，该系统显著提升了解码效率，对于需要快速响应的LLM应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的低延迟解码对于聊天机器人和代码助手等应用至关重要，但生成长输出在单查询设置下仍然很慢。现有的推测解码和张量并行方法无法同时应用，因为存在计算需求不平衡、KV缓存不一致以及小批量张量并行下的通信开销。

**Method:** SwiftSpec通过异步和解耦的方式重新设计了推测解码管道，使每个组件都能灵活扩展，并从关键路径中移除草稿开销。为实现此设计，它提出了并行树生成、树感知KV缓存管理和融合的、延迟优化的内核。

**Result:** SwiftSpec在5个模型系列和6个数据集上比最先进的推测解码系统平均加速1.75倍。它在8块Nvidia Hopper GPU上以348 tokens/s的速度服务Llama3-70B，是该规模下已知最快的低延迟LLM服务系统。

**Conclusion:** SwiftSpec通过其创新的异步和解耦设计，显著提升了LLM的低延迟解码性能，尤其是在大规模模型服务方面表现出色，解决了现有推测解码与张量并行结合的挑战。

> **ai_Abstract:** SwiftSpec是一个旨在实现LLM超低延迟解码的系统。它通过重新设计推测解码管道，采用异步和解耦的方式，解决了现有推测解码与张量并行结合时面临的计算不平衡、KV缓存不一致和通信开销等挑战。该系统引入了并行树生成、树感知KV缓存管理和优化的内核。实验结果表明，SwiftSpec比现有推测解码系统平均提速1.75倍，并在8块Nvidia Hopper GPU上以348 tokens/s的速度服务Llama3-70B，达到了该规模下的最快速度。

> **摘要翻译:** 大型语言模型（LLMs）的低延迟解码对于聊天机器人和代码助手等应用至关重要，然而在单查询设置下生成长输出仍然很慢。先前的推测解码（将小型草稿模型与大型目标模型结合）和张量并行化工作都加速了解码。然而，传统方法由于计算需求不平衡（草稿模型和目标模型之间）、KV缓存不一致以及小批量张量并行下的通信开销，未能同时应用这两种技术。本文介绍了SwiftSpec，一个旨在实现LLM解码超低延迟的系统。SwiftSpec以异步和解耦的方式重新设计了推测解码管道，以便每个组件都可以灵活扩展，并从关键路径中消除草稿开销。为了实现这一设计，SwiftSpec提出了并行树生成、树感知KV缓存管理以及融合的、延迟优化的内核，以克服上述挑战。在5个模型家族和6个数据集上，SwiftSpec比最先进的推测解码系统平均实现了1.75倍的加速，突出的是，它在8块Nvidia Hopper GPU上以348 tokens/s的速度服务Llama3-70B，使其成为该规模下已知最快的低延迟LLM服务系统。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [43] [Capsule: Efficient Player Isolation for Datacenters](https://arxiv.org/abs/2506.11483)
> *Capsule：数据中心高效玩家隔离*

*Zhouheng Du, Nima Davari, Li Li, Nodir Kodirov* | **Main category: cs.DC**

**Keywords:** 云游戏, GPU共享, 数据中心利用率, 玩家隔离, Capsule

**Comment:** 

> **TL;DR:** Capsule是一种机制，允许多个玩家共享一个GPU，从而显著提高数据中心的游戏资源利用率，且不影响玩家体验。

**AI_Comments:** Capsule的创新之处在于解决了云游戏领域GPU资源利用率低下的痛点，通过多玩家共享GPU的机制，显著提高了数据中心的吞吐量和效率。其应用无关性使其具有广泛的推广价值。对于云服务提供商而言，这可以带来显著的成本效益和更高的服务能力。

<details>
  <summary>Details</summary>

**Motivation:** 云游戏日益普及，但由于游戏引擎主要设计为单玩家运行，导致云数据中心GPU资源利用率低下，云提供商面临如何提高数据中心利用率的挑战。

**Method:** 论文引入了Capsule，一种允许多个玩家无缝共享一个GPU的机制。该机制在O3DE开源游戏引擎中实现。

**Result:** Capsule可以将数据中心资源利用率提高，容纳多达2.25倍的玩家，且不降低玩家游戏体验。Capsule与应用程序无关，在没有应用程序更改的情况下运行了四种应用。

**Conclusion:** Capsule的设计可以被其他游戏引擎采用，以提高云提供商的数据中心利用率。

> **ai_Abstract:** 论文提出了Capsule，一种针对云游戏数据中心资源利用率低下的解决方案。Capsule允许单个GPU被多个玩家共享，显著提高了资源利用率，能在不影响玩家体验的前提下容纳更多玩家。该机制在O3DE引擎中实现并验证其有效性和应用无关性，表明其具有广泛的推广潜力。

> **摘要翻译:** 云游戏越来越受欢迎。云提供商面临的一个挑战是保持数据中心高利用率：由于应用程序种类繁多，这是一项非平凡的任务。这些应用程序形状和大小各异。云数据中心资源也是如此，例如CPU、GPU、NPU。
部分挑战源于游戏引擎主要设计为只运行一个玩家。一个轻量级游戏中的一个玩家可能只利用云服务器GPU的一小部分。剩余的GPU容量将被闲置，这对云提供商来说是不可取的结果。我们引入了Capsule，一种允许多个玩家无缝共享一个GPU的机制。
我们在流行的开源游戏引擎O3DE中实现了Capsule。我们的评估表明，Capsule可以在不降低玩家游戏体验的情况下，通过容纳多达2.25倍的玩家来提高数据中心资源利用率。Capsule也与应用程序无关。我们在基于Capsule的O3DE上运行了四种应用程序，无需进行任何应用程序更改。我们的经验表明，Capsule设计可以被其他游戏引擎采用，以提高云提供商的数据中心利用率。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [71] [Bounded Memory in Distributed Networks](https://arxiv.org/abs/2506.11644)
> *分布式网络中的有限内存*

*Ran Ben Basat, Keren Censor-Hillel, Yi-Jun Chang, Wenchen Han, Dean Leitersdorf, Gregory Schwartzman* | **Main category: cs.DC**

**Keywords:** 分布式网络,有限内存,$\mu$-CONGEST,流式算法,团列表

**Comment:** Accepted at The 37th ACM Symposium on Parallelism in Algorithms and
  Architectures (SPAA '25). 22 pages

> **TL;DR:** 引入了考虑内存限制的$\mu$-CONGEST模型，并提供了两种方法来设计在有限内存下高效运行的分布式算法，包括处理内存密集型算法和模拟流式算法，从而能在受限网络中高效生成组合结构统计信息。

**AI_Comments:** 本文的创新点在于引入了更贴近现实的$\mu$-CONGEST模型，弥合了理论CONGEST模型与实际部署之间的差距。通过对内存密集型算法的分析和流式算法的模拟，为在资源受限的分布式环境中设计高效算法提供了新的思路和理论基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CONGEST模型算法在实际数据中心网络部署时存在理论与实践间的鸿沟，尤其是在节点内存受限的情况下。

**Method:** 引入了$\mu$-CONGEST模型，该模型在带宽限制之外，还将节点内存限制为$\mu$字。在此模型下，研究了两种主要算法：一是针对内存密集型算法（如团列表算法），提出新颖技术以在给定内存限制内工作，并建立了运行时间与内存之间的紧密权衡；二是展示了在$\mu$-CONGEST中高效模拟各类流式算法（如p-pass、随机顺序流和可合并流式算法）的可能性。

**Result:** 揭示了内存密集型算法（如团列表）在$\mu$-CONGEST模型中无法在不增加轮次复杂度的情况下解决内存问题，并提供了运行时间与内存之间的紧密权衡。此外，证明了在$\mu$-CONGEST中可以高效模拟多种流式算法。

**Conclusion:** 结合研究贡献，论文表明可以使用流式算法在有限内存的分布式网络中高效生成关于组合结构的统计信息，例如识别和提供频繁单色三角形的每颜色频率。

> **ai_Abstract:** 本文针对分布式网络中CONGEST算法在实际部署时面临的内存限制问题，提出了$\mu$-CONGEST模型，该模型在CONGEST基础上引入了有限内存约束。作者研究了两种类型的算法：一是针对内存密集型算法，通过新颖技术解决了其在有限内存下的运行问题，并给出了运行时间与内存的紧密权衡；二是展示了在$\mu$-CONGEST中高效模拟各类流式算法的可能性。综合来看，这些工作使得在有限内存的分布式网络中，能够高效地生成关于复杂组合结构的统计信息。

> **摘要翻译:** 近期可编程交换机的出现使得分布式算法能够轻易地部署到现实世界的数据中心网络中。然而，理论与实践之间仍然存在差距，阻碍了CONGEST算法在这些环境中的顺利适应。在本文中，我们关注现实部署中出现的内存限制。我们引入了$\mu$-CONGEST模型，在该模型中，除了带宽限制外，节点的内存也被限制为$\mu$个字，这与现实世界的系统保持一致。我们提供了两种主要类型的快速算法。首先，我们观察到CONGEST模型中的许多算法是内存密集型的，无法在$\mu$-CONGEST中工作。使用大内存的算法族的一个主要例子是团列表算法。我们通过建立$\mu$-CONGEST中列表团的轮次复杂度的下限，表明这里出现的内存问题无法在不增加轮次复杂度的情况下解决。我们引入了新颖的技术来克服这些问题，并将算法推广到在给定内存限制内工作。结合我们的下限，这些提供了运行时间与节点内存之间的紧密权衡。其次，我们表明可以在$\mu$-CONGEST中高效模拟各种流式算法族。这包括p-pass算法、随机顺序流和各种类型的可合并流式算法的快速模拟。结合我们的贡献，我们表明我们可以使用流式算法来高效生成网络中组合结构的统计信息。这种类型的一个最终结果示例是，我们可以在$\mu$-CONGEST中高效识别并提供频繁单色三角形的每颜色频率。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [99] [A retrospective on DISPEED -- Leveraging heterogeneity in a drone swarm for IDS execution](https://arxiv.org/abs/2506.11800)
> *DISPEED回顾——利用无人机群的异构性进行IDS执行*

*Vincent Lannurien, Camélia Slimani, Louis Morge-Rollet, Laurent Lemarchand, David Espes, Frédéric Le Roy, Jalil Boukhobza* | **Main category: cs.DC**

**Keywords:** 无人机群, 网络入侵检测系统, 异构性, 嵌入式平台, 部署策略

**Comment:** 

> **TL;DR:** DISPEED项目利用无人机群的异构性，在资源受限的环境中部署网络入侵检测系统（NIDS），通过表征和映射阶段，成功为不同上下文选择合适的NIDS。

**AI_Comments:** 这篇论文解决了在资源受限的无人机群中部署复杂NIDS的关键挑战，其创新点在于利用了无人机本身的异构性。通过系统性的表征和映射方法，为实际部署提供了可行的策略，具有重要的实践意义。然而，抽象中未详细说明所选择NIDS的具体类型以及性能对比的详细数据，这可能是未来研究可以深入的方向。

<details>
  <summary>Details</summary>

**Motivation:** 无人机群在任务中日益自主和高效，但安全威胁可能扰乱其任务进程。传统的网络入侵检测系统（NIDS）依赖于资源密集型机器学习技术，难以部署在无人机群上。因此，需要一种方法来克服在资源受限的无人机群中部署NIDS的挑战。

**Method:** DISPEED项目分为两个阶段：1) 表征阶段：在多种嵌入式平台上表征各种IDS实现（如Raspberry Pi 4B、Jetson Xavier、Pynq-Z2）。2) IDS实现映射阶段：开发选择策略，根据上下文选择最相关的NIDS，包括独立和分布式策略。

**Result:** 在表征阶段，识别了在三种不同嵌入式平台上36种相关的IDS实现。在IDS实现映射阶段，设计了独立和分布式策略来选择最佳NIDS。项目成果包括三篇国际会议论文和一篇期刊论文。

**Conclusion:** DISPEED项目成功地利用了无人机群的异构性，解决了在资源受限环境中部署NIDS的挑战，并通过表征和映射阶段，实现了根据上下文选择和部署最相关NIDS的目标。

> **ai_Abstract:** DISPEED项目旨在通过利用无人机群的异构性（如执行平台和内存），解决在资源受限的无人机群中部署网络入侵检测系统（NIDS）的挑战。该项目分为两个主要阶段：首先是表征阶段，对不同嵌入式平台上的多种IDS实现进行性能评估；其次是IDS实现映射阶段，开发出根据特定上下文选择最合适NIDS的策略。研究成果包括识别了36种相关IDS实现，并设计了独立和分布式部署策略，最终促成了多篇国际会议和期刊论文的发表。

> **摘要翻译:** 无人机群在任务中获得了越来越高的自主性和效率。然而，安全威胁可能会扰乱其任务的进展。为了克服这个问题，网络入侵检测系统（(N)IDS）是检测网络流量中恶意行为的有前景的解决方案。然而，现代NIDS依赖于资源消耗大的机器学习技术，这可能难以部署在无人机群上。DISPEED项目旨在利用构成无人机群的无人机的异构性（执行平台、内存）来部署NIDS。它分为两个阶段：(1) 表征阶段，包括表征各种IDS在不同嵌入式平台上的实现，以及(2) IDS实现映射阶段，旨在开发选择策略以根据上下文选择最相关的NIDS。一方面，表征阶段使我们能够识别在三种不同嵌入式平台（Raspberry Pi 4B、Jetson Xavier和Pynq-Z2）上的36种相关IDS实现。另一方面，IDS实现映射阶段使我们能够设计独立和分布式策略，根据上下文选择最佳的NIDS进行部署。该项目的成果已在国际会议上发表了三篇论文，并在期刊上发表了一篇论文。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [126] [Secure API-Driven Research Automation to Accelerate Scientific Discovery](https://arxiv.org/abs/2506.11950)
> *安全的API驱动研究自动化以加速科学发现*

*Tyler J. Skluzacek, Paul Bryant, A. J. Ruckman, Daniel Rosendo, Suzanne Prentice, Michael J. Brim, Ryan Adamson, Sarp Oral, Mallikarjun Shankar, Rafael Ferreira da Silva* | **Main category: cs.DC**

**Keywords:** 服务网格, 科学自动化, API驱动, 高性能计算, 安全

**Comment:** PEARC 2025, 5 pages

> **TL;DR:** S3M是一个安全的API驱动服务网格，通过自动化研究工作流加速科学发现，同时确保HPC访问的安全性。

**AI_Comments:** 这篇论文提出了一种创新的服务网格架构S3M，通过API驱动和安全机制解决了传统科学计算中资源访问和工作流自动化的挑战。其创新性在于将安全、自动化和HPC访问紧密结合，为AI增强的自主科学奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的科学计算基础设施在研究人员、计算资源和实验设施之间存在障碍，需要一种新的框架来加速实验生命周期并实现AI增强的自主科学。

**Method:** S3M通过API驱动的基础设施实现，整合了近实时流媒体、智能工作流编排和细粒度授权，构建在服务网格架构之上，以安全地访问高性能计算（HPC）。

**Result:** S3M革命性地改变了对HPC的编程访问，同时保持安全性。它允许智能代理和实验设施动态配置资源并执行复杂工作流，加速实验生命周期，并释放AI增强的自主科学的潜力。

**Conclusion:** S3M开创了科学计算基础设施的新时代，消除了传统障碍，加速了科学发现。

> **ai_Abstract:** 安全科学服务网格（S3M）是一个API驱动的框架，旨在通过自动化研究工作流来加速科学发现。它通过整合实时流、智能工作流编排和细粒度授权，在服务网格架构中安全地实现对高性能计算（HPC）的程序化访问。S3M使智能代理和实验设施能够动态管理资源和执行复杂任务，从而缩短实验周期并促进AI驱动的自主科学。

> **摘要翻译:** 安全科学服务网格（S3M）提供API驱动的基础设施，通过自动化研究工作流加速科学发现。通过在服务网格架构内整合近实时流媒体能力、智能工作流编排和细粒度授权，S3M在保持 uncompromising 安全性的同时，彻底改变了对高性能计算（HPC）的程序化访问。该框架允许智能代理和实验设施动态配置资源并执行复杂工作流，从而加速实验生命周期，并释放AI增强自主科学的全部潜力。S3M标志着科学计算基础设施的一个新时代，它消除了研究人员、计算资源和实验设施之间的传统障碍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [18] [The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI](https://arxiv.org/abs/2506.11015)
> *记忆悖论：在人工智能时代我们的大脑为何需要知识*

*Barbara Oakley, Michael Johnston, Ken-Zen Chen, Eulho Jung, Terrence J. Sejnowski* | **Main category: cs.CY**

**Keywords:** 记忆悖论, 人工智能, 认知心理学, 神经科学, 内部模型

**Comment:** 50 pages, 8 figures

> **TL;DR:** 在人工智能和数字工具普及的时代，人类认知面临“记忆悖论”，即对外部AI的过度依赖可能导致内部记忆系统退化。本文探讨了这种风险，并强调了构建强大内部模型对有效人机交互的重要性。

**AI_Comments:** 这篇论文提出了一个非常及时且重要的观点，即在AI日益普及的时代，我们不应忽视人类内部知识和记忆的重要性。其创新之处在于将认知心理学和神经科学的见解与AI时代的人类学习和认知挑战相结合，并提出了“内部模型”作为有效人机交互的关键。这对于教育政策和未来技能培养具有深刻的启示。

<details>
  <summary>Details</summary>

**Motivation:** 在生成式AI和普及的数字工具时代，人类认知面临一个结构性悖论：随着外部辅助工具变得越来越强大，内部记忆系统面临萎缩的风险。本文旨在探讨对AI系统和发现式教学法的过度依赖如何损害声明性记忆和程序性记忆的巩固，这些记忆对于专业知识、批判性思维和长期记忆至关重要。

**Method:** 本文借鉴神经科学和认知心理学，探讨了对AI系统和发现式教学法的过度依赖如何损害记忆巩固。文章回顾了ChatGPT和计算器等工具如何短路神经编码所需的检索、纠错和图式构建过程。此外，还对比了深度学习现象（如“grokking”）与过度学习和直觉的神经科学，并讨论了实证研究结果。

**Result:** 实证研究表明，在学习过程中过早依赖AI会抑制程序化和直觉掌握。论文指出，有效的人机交互取决于强大的内部模型（生物“图式”和神经流形），这些模型使用户能够评估、完善和引导AI输出。

**Conclusion:** 本文的结论是，在大型语言模型时代，有效的人机交互依赖于强大的内部模型——生物“图式”和神经流形，这些模型使用户能够评估、完善和引导AI输出。文章最后提出了对教育和劳动力培训的政策影响。

> **ai_Abstract:** 这篇论文探讨了在AI普及时代，人类认知面临的“记忆悖论”：外部AI工具的强大可能导致内部记忆系统的退化。文章结合神经科学和认知心理学，分析了过度依赖AI如何损害记忆巩固、批判性思维和专业知识的形成。通过讨论实证研究，论文指出过早依赖AI会阻碍学习过程中的程序化和直觉掌握。最终，论文强调了建立强大内部模型对有效人机交互的重要性，并提出了对教育和劳动力培训的政策建议。

> **摘要翻译:** 在生成式人工智能和无处不在的数字工具时代，人类认知面临一个结构性悖论：随着外部辅助工具变得越来越强大，内部记忆系统面临萎缩的风险。本文借鉴神经科学和认知心理学，探讨了过度依赖人工智能系统和基于发现的教学法如何损害声明性记忆和程序性记忆的巩固——这些系统对于专业知识、批判性思维和长期记忆至关重要。我们回顾了ChatGPT和计算器等工具如何短路强大的神经编码所需的检索、纠错和图式构建过程。值得注意的是，我们强调了深度学习现象（如“格鲁金”现象）与过度学习和直觉神经科学之间惊人的相似之处。文章讨论了实证研究，这些研究表明在学习过程中过早依赖人工智能会抑制程序化和直觉掌握。我们认为，有效的人机交互取决于强大的内部模型——生物“图式”和神经流形——这些模型使用户能够评估、完善和引导人工智能的输出。本文最后提出了大型语言模型时代教育和劳动力培训的政策影响。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [46] [Social Scientists on the Role of AI in Research](https://arxiv.org/abs/2506.11255)
> *社会科学家对人工智能在研究中作用的看法*

*Tatiana Chakravorti, Xinyu Wang, Pranav Narayanan Venkit, Sai Koneru, Kevin Munger, Sarah Rajtmajer* | **Main category: cs.CY**

**Keywords:** 研究中的AI, 社会科学家, 生成式AI, 机器学习, 伦理担忧

**Comment:** 

> **TL;DR:** 社会科学家在研究中越来越多地使用人工智能，特别是生成式人工智能，但对其伦理和信任存在显著担忧，更倾向于传统机器学习的透明度。

**AI_Comments:** 本论文及时地洞察了AI，特别是生成式AI在社会科学领域的采纳情况和所面临的挑战。其通过区分“AI”和“ML”框架的创新方法，为理解研究人员的看法和信任提供了细致入微的视角。论文提出的实用性建议对于促进AI在学术研究中负责任的整合具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）融入社会科学研究实践引发了重大的技术、方法和伦理问题。本研究旨在了解社会科学家对在其领域中使用AI的熟悉程度、对其有用性的看法以及伦理担忧。

**Method:** 一项以社区为中心的研究，收集了284份调查问卷回复和15次社会科学家的半结构化访谈。研究设计中的一个关键创新是将调查样本分成两半，对每一半提出相同的问题，但随机分配参与者被问及“AI”还是“机器学习”（ML）。

**Result:** 研究发现，AI（特别是生成式AI）在社会科学家研究环境中的使用显著增加，用于总结文献和起草论文等任务。一些受访者出于好奇使用但结果不满意，而另一些则已整合到工作流程中。参与者对在研究环境中使用AI，特别是生成式AI，表示担忧，涉及自动化偏见、技能退化、研究不当行为、复杂可解释性和代表性伤害。他们对传统ML算法表现出更大的信任，因其统计基础和透明度。

**Conclusion:** 论文为AI开发者、研究人员、教育工作者和政策制定者提供了建议，重点关注可解释性、透明度、伦理保障、可持续性以及将生活经验融入AI设计和评估过程，以指导AI在社会科学研究中的负责任应用。

> **ai_Abstract:** 本研究通过调查和访谈，包括一项独特的“AI”与“ML”框架比较设计，探讨了社会科学家对AI在研究中作用的看法。研究发现AI，特别是生成式AI，在各种任务中的应用有所增加，但也存在显著的伦理担忧，如偏见和可解释性问题，导致研究人员更青睐透明的传统ML。论文最后提出了对利益相关者的建议，以指导AI的负责任整合。

> **摘要翻译:** 人工智能（AI）融入社会科学研究实践引发了重大的技术、方法和伦理问题。我们进行了一项以社区为中心的研究，收集了284份调查问卷回复和15次社会科学家的半结构化访谈，描述了他们对在其领域中使用AI的熟悉程度、对其有用性的看法以及伦理担忧。研究设计中的一个关键创新是将调查样本分成两半，对每一半提出相同的问题——但随机分配参与者被问及“AI”还是“机器学习”（ML）。我们发现，随着生成式AI（genAI）的广泛普及，AI在社会科学家研究环境中的使用显著增加。这些工具已被用于从总结文献综述到起草研究论文等一系列任务。一些受访者出于好奇使用这些工具，但对结果不满意，而另一些人现在已将它们整合到他们的日常工作流程中。然而，参与者也报告了在研究环境中使用AI的担忧。这与他们认为具有统计基础的更传统的ML算法有所不同。参与者对ML表现出更大的信任，理由是与黑盒genAI系统相比，ML具有相对透明度。与genAI相关的伦理担忧，特别是围绕自动化偏见、技能退化、研究不当行为、复杂可解释性和代表性伤害的问题被提出。为了指导这一转变，我们为AI开发者、研究人员、教育工作者和政策制定者提供了建议，重点关注可解释性、透明度、伦理保障、可持续性以及将生活经验融入AI设计和评估过程。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [74] [WIP: Exploring the Value of a Debugging Cheat Sheet and Mini Lecture in Improving Undergraduate Debugging Skills and Mindset](https://arxiv.org/abs/2506.11339)
> *WIP: 探索调试备忘录和迷你讲座在提高本科生调试技能和思维模式方面的价值*

*Andrew Ash, John Hu* | **Main category: cs.CY**

**Keywords:** 调试技能, 微电子教育, 迷你讲座, 备忘录, 思维模式

**Comment:** This is the accepted version of a paper accepted for presentation at
  the 2025 IEEE Frontiers in Education Conference (FIE). The final version will
  be available via IEEE Xplore at: https://ieeexplore.ieee.org

> **TL;DR:** 一项初步研究表明，为本科生提供调试迷你讲座和备忘录可以提高他们的调试速度和成功率，并改变他们对调试的看法，尽管结果尚未达到统计显著性。

**AI_Comments:** 该论文提出了一种实用的教育干预措施，以解决本科生调试技能不足的问题。其创新点在于结合了理论讲解（迷你讲座）和实践指导（备忘录），并关注了思维模式的转变。尽管目前是初步结果，但其潜在的教育价值和对学生未来职业准备的积极影响值得关注。未来的研究需要扩大样本量并进行更严格的统计分析以确认其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索一种小规模的微电子调试教育干预措施（调试“迷你讲座”和调试备忘录）对提高本科生调试技能和思维模式的有效性，以帮助他们更好地为职场调试做好准备。

**Method:** 研究采用准实验设计，在三年级电气和计算机工程（ECE）学生的入门微电子课程中进行。实验组接受了涵盖两种常见电路误差的调试“迷你讲座”，并获得了包含测试和假设形成建议的调试备忘录。对照组未接受干预。通过三个调试问题评估两组学生的表现和思维模式。

**Result:** 在三个调试问题上，实验组学生的调试速度平均快了1分43秒，成功率比对照组高7%。两组都表现出强大的普遍成长型思维模式，而实验组还表现出调试思维模式的转变，认为调试具有更大的价值。尽管这些差异尚未达到统计显著性，但初步结果表明干预措施是朝着正确方向迈进的。

**Conclusion:** 初步结果表明，迷你讲座和调试备忘录有助于提高学生在职场中进行调试的准备能力，是改善学生调试技能和思维模式的正确方向。

> **ai_Abstract:** 这项正在进行的研究评估了在本科微电子课程中，通过提供调试“迷你讲座”和备忘录对学生调试技能和思维模式的影响。采用准实验设计，结果显示实验组学生在调试速度和成功率上均优于对照组，且对调试的价值认知有所提升。尽管统计学意义尚未确立，但初步数据表明该干预措施有望提升学生调试能力，为职场做好准备。

> **摘要翻译:** 这项正在进行中的研究论文探讨了一种小规模微电子调试教育干预措施的有效性，该干预措施在为三年级电气和计算机工程（ECE）学生开设的入门微电子课程中采用了准实验设计。在研究的第一学期，实验组参加了一个调试“迷你讲座”，内容涵盖两种常见的电路错误来源，并收到了一份调试备忘录，其中包含测试和假设形成的建议。在三个调试问题中，实验组学生的平均速度快了1分43秒，成功率比对照组高7%。两组都表现出强大的普遍成长型思维模式，而实验组还通过认为调试具有更大的价值，表现出其调试思维模式的转变。尽管这些差异尚未达到统计显著性，但初步结果表明，迷你讲座和调试备忘录是朝着提高学生在职场中调试准备能力方向迈出的正确一步。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [101] [The Strategic Imperative for Healthcare Organizations to Build Proprietary Foundation Models](https://arxiv.org/abs/2506.11412)
> *医疗机构构建专有基础模型的战略必要性*

*Naresh Tiwari* | **Main category: cs.CY**

**Keywords:** 医疗机构, 基础模型, 专有AI, 数据治理, 战略优势

**Comment:** 

> **TL;DR:** 论文分析了医疗机构开发专有基础模型而非依赖商业替代方案的战略必要性，强调了其在临床性能、数据治理、竞争优势和创新方面的优势。

**AI_Comments:** 这篇论文强调了医疗领域AI发展的特殊性，指出了专有基础模型对于数据安全、合规性以及实现真正领域深度优化的重要性。其创新之处在于将“自建”而非“购买”AI能力提升到战略高度，并提供了多维度的论证。对于医疗机构而言，这提供了一个强有力的理由来投资内部AI能力建设，而非仅仅作为技术消费者。

<details>
  <summary>Details</summary>

**Motivation:** 医疗领域数据表示的特定要求、关键数据主权和治理考量、专有AI基础设施带来的战略竞争优势以及医疗专用基础模型对患者护理和组织运营的变革潜力是驱动医疗机构构建专有基础模型的原因。

**Method:** 通过分析实证证据、经济框架和组织案例研究。

**Result:** 专有多模态基础模型使医疗机构能够实现卓越的临床性能、保持强大的数据治理、创造可持续的竞争优势并加速创新路径。拥有专有AI能力的组织表现出可衡量的结果改善、更快的创新周期和更强的战略定位。

**Conclusion:** 专有基础模型开发是前瞻性医疗机构的基石能力，为医疗领导者评估基础模型实施的“自建”与“购买”决策提供了全面的框架。

> **ai_Abstract:** 本文深入探讨了医疗机构构建自身专有基础模型的战略必要性，而非仅依赖商业解决方案。文章从数据特性、数据主权、竞争优势和变革潜力四个方面论证了这一必要性。通过实证分析和案例研究，论文指出专有模型能显著提升临床表现、强化数据治理、建立竞争优势并加速创新。最终，文章将专有基础模型开发视为医疗机构未来发展的核心能力，并为相关决策提供了指导框架。

> **摘要翻译:** 本论文全面分析了医疗机构开发专有基础模型而非完全依赖商业替代方案的战略必要性。我们考察了驱动这一必要性的四个基本考量：医疗数据表示的领域特定要求、医疗领域独有的关键数据主权和治理考量、专有AI基础设施带来的战略竞争优势，以及医疗专用基础模型对患者护理和组织运营的变革潜力。通过分析实证证据、经济框架和组织案例研究，我们证明了专有多模态基础模型使医疗机构能够实现卓越的临床性能、保持强大的数据治理、创造可持续的竞争优势并加速创新路径。尽管承认实施挑战，我们提供的证据表明，拥有专有AI能力的组织在不断发展的医疗生态系统中表现出可衡量的结果改善、更快的创新周期和更强的战略定位。本分析为医疗领导者评估基础模型实施的“自建”与“购买”决策提供了全面的框架，将专有基础模型开发定位为前瞻性医疗机构的基石能力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [128] [Expert Insight-Based Modeling of Non-Kinetic Strategic Deterrence of Rare Earth Supply Disruption:A Simulation-Driven Systematic Framework](https://arxiv.org/abs/2506.11645)
> *基于专家见解的非动能战略威慑稀土供应中断建模：一种模拟驱动的系统框架*

*Wei Meng* | **Main category: cs.CY**

**Keywords:** 非动能威慑, 稀土供应中断, 战略建模, 专家见解, 模拟框架

**Comment:** This paper pioneers a dynamic AI-driven modelling framework that
  transforms rare earth supply risks into quantifiable non-kinetic deterrence
  strategies with real-world policy impact

> **TL;DR:** 本研究构建了一个可量化的模型框架，用于模拟稀土供应中断情景下的非动能战略威慑路径。该框架整合了多种数学和AI方法，并基于专家访谈数据，旨在帮助政策制定者理解和预测战略能力退化。

**AI_Comments:** 该论文的创新之处在于首次提出了一个统一的非动能威慑建模系统，并结合了多源数据（专家访谈）和多种复杂建模技术（ODE、LSTM等）。其重要性在于为国家安全领域的政策制定者和分析师提供了量化分析和预测工具，以应对关键资源供应中断和战略竞争。模型的适应性和可扩展性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在构建一个可量化的建模框架，以模拟稀土供应中断情景下的非动能战略威慑路径，特别关注对国家安全系统的影响，并为政策制定者和分析师提供方法论支持，以应对制度化的战略竞争。

**Method:** 本研究基于稀土交易所CEO Daniel O'Connor博士主导的专家访谈结构化响应，构建了一个可量化的建模框架。该框架提出了四个核心建模组件：安全关键区（SCZ）、战略信号注入功能（SSIF）、系统能力迁移功能（SCIF）和政策能力转移功能（PCTF）。它整合了参数化常微分方程（ODEs）、分段函数建模、路径重叠协方差矩阵和LSTM网络，以模拟由政权信号触发的非线性抑制轨迹。数据来源于以美中动态为中心的ISR、电子战和稀土控制方面的专家访谈和情景分析。

**Result:** 结果表明，制度信号具有强大的节奏和路径耦合效应，能够导致战略能力的快速退化。该模型可适应不同的国家资源框架，并可扩展到AI沙盒引擎，用于态势模拟和反事实推理。

**Conclusion:** 本研究引入了第一个用于建模、可视化和预测非动能威慑的统一系统，为应对制度化战略竞争的政策制定者和分析师提供了方法论支持。

> **ai_Abstract:** 本研究提出了一种基于专家见解的系统框架，用于模拟稀土供应中断下的非动能战略威慑。该框架包含SCZ、SSIF、SCIF、PCTF四个核心组件，并结合ODE、分段函数、协方差矩阵和LSTM网络，以量化和预测制度信号对战略能力的影响。研究结果表明制度信号能快速导致战略能力退化，且模型具有普适性和可扩展性。该工作首次提供了统一的非动能威慑建模系统，旨在为政策制定者提供决策支持。

> **摘要翻译:** 本研究基于稀土交易所（REE）首席执行官Daniel O'Connor博士主导的专家访谈的结构化回应，构建了一个可量化的建模框架，以模拟稀土供应中断情景下的非动能战略威慑路径。研究重点关注中断对国家安全系统的影响，提出了四个核心建模组件：安全关键区（SCZ）、战略信号注入功能（SSIF）、系统能力迁移功能（SCIF）和政策能力转移功能（PCTF）。该框架整合了参数化常微分方程（ODEs）、分段函数建模、路径重叠协方差矩阵和LSTM网络，以模拟由政权信号触发的非线性抑制轨迹。数据来源于以美中在ISR、电子战和稀土控制方面的动态为中心的专家访谈和情景分析。结果表明，制度信号具有强大的节奏和路径耦合效应，能够导致战略能力的快速退化。该模型可适应不同的国家资源框架，并可扩展到AI沙盒引擎，用于态势模拟和反事实推理。本研究引入了第一个用于建模、可视化和预测非动能威慑的统一系统，为应对制度化战略竞争的政策制定者和分析师提供了方法论支持。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [152] [Malicious LLM-Based Conversational AI Makes Users Reveal Personal Information](https://arxiv.org/abs/2506.11680)
> *恶意LLM驱动的对话式AI诱使用户泄露个人信息*

*Xiao Zhan, Juan Carlos Carrillo, William Seymour, Jose Such* | **Main category: cs.CY**

**Keywords:** LLM, 对话式AI, 隐私泄露, 恶意攻击, 个人信息提取

**Comment:** This paper has been accepted at USENIX Security '25

> **TL;DR:** 恶意LLM对话式AI能有效诱使用户泄露个人信息，其中利用社交隐私策略最有效且风险感知最低。

**AI_Comments:** 这项研究揭示了LLM滥用的一种新的、令人担忧的模式，即恶意设计用于窃取用户个人信息。其创新之处在于系统性地构建并评估了不同策略的恶意CAI，并量化了其有效性。研究结果对于提高LLM用户和开发者对潜在隐私风险的认识至关重要，并为防御此类攻击提供了实践指导。

<details>
  <summary>Details</summary>

**Motivation:** LLM驱动的对话式AI（CAI）日益普及，但用户在使用过程中存在泄露个人信息的隐私风险。现有研究虽已表明LLM可用于恶意目的，但专门设计用于从用户处提取个人信息的恶意LLM-based CAI仍未被探索，这构成了一种新颖且特别令人担忧的潜在威胁，因此本研究旨在填补这一空白。

**Method:** 研究人员基于系统提示创建了采用不同策略的恶意LLM-based CAI，旨在鼓励用户披露个人信息。通过一项包含502名参与者的随机对照试验，系统性地调查了CAI在对话过程中提取个人信息的能力。同时，评估了不同恶意和良性CAI提取个人信息的有效性，并分析了参与者与CAI互动后的感知。

**Result:** 研究发现，恶意CAI比良性CAI提取了显著更多的个人信息。其中，基于隐私社交性质的策略被证明是最有效的，同时最大限度地降低了用户感知到的风险。

**Conclusion:** 这项研究强调了这种新型恶意LLM驱动的CAI所带来的严重隐私威胁，并为指导未来的研究和实践提供了可操作的建议，以应对此类风险。

> **ai_Abstract:** 本文研究了一种新型恶意LLM驱动的对话式AI，该AI旨在从用户处窃取个人信息。通过一项包含502名参与者的随机对照试验，研究人员创建并测试了不同策略的恶意CAI。结果显示，恶意CAI比良性CAI能显著提取更多个人信息，其中利用社交隐私特性的策略最为有效且用户感知风险最低。研究强调了此类恶意CAI的隐私威胁，并提出了未来研究和实践的建议。

> **摘要翻译:** LLM驱动的对话式AI（CAI），也称为生成式AI聊天机器人，如ChatGPT，正越来越多地应用于各个领域，但它们带来了隐私风险，因为用户在与CAI对话期间可能会泄露个人信息。最近的研究表明，LLM驱动的CAI可用于恶意目的。然而，一种新颖且特别令人担忧的恶意LLM应用类型仍未被探索：一种故意设计用于从用户那里提取个人信息的LLM驱动的CAI。

在本文中，我们报告了我们创建的恶意LLM驱动的CAI，这些CAI基于系统提示，使用不同的策略鼓励用户披露个人信息。我们通过对502名参与者进行随机对照试验，系统地调查了CAI在对话过程中从用户那里提取个人信息的能力。我们评估了不同恶意和良性CAI从参与者那里提取个人信息的有效性，并分析了参与者在与CAI互动后的感知。我们的发现表明，恶意CAI比良性CAI提取了显著更多的个人信息，其中基于隐私社交性质的策略最有效，同时最大限度地降低了感知风险。这项研究强调了这种新型恶意LLM驱动的CAI带来的隐私威胁，并提供了可操作的建议，以指导未来的研究和实践。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [172] [Designing Effective LLM-Assisted Interfaces for Curriculum Development](https://arxiv.org/abs/2506.11767)
> *设计有效的LLM辅助课程开发界面*

*Abdolali Faraji, Mohammadreza Tavakoli, Mohammad Moein, Mohammadreza Molavi, Gábor Kismihók* | **Main category: cs.CY**

**Keywords:** 大型语言模型, 用户界面设计, 课程开发, 直接操作, 可用性, 人机交互

**Comment:** This is the preprint version of a paper accepted at AIED 2025. The
  final version will be published by Springer

> **TL;DR:** 本文介绍了两种基于直接操作原则的新型UI设计（UI Predefined和UI Open），旨在简化教师与LLM互动进行课程开发的过程，并通过用户研究发现UI Predefined在可用性和降低任务负荷方面优于ChatGPT和UI Open。

**AI_Comments:** 本文的创新点在于提出了两种专门为教育工作者设计的、基于直接操作原则的LLM辅助界面，有效解决了传统LLM接口在课程开发中面临的提示工程复杂性和可用性差的问题。通过用户研究量化了新设计的优势，特别是UI Predefined在可用性和降低任务负荷方面的显著提升，这对于推动LLM在教育领域的实际应用具有重要意义。该研究为未来开发更高效、更人性化的AI辅助工具提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）有潜力改变课程交付方式，但教育工作者在使用它们时面临复杂提示工程、可用性差、工作量增加以及LLM输出不准确等挑战。

**Method:** 本文引入了两种基于直接操作（DM）原则的新型用户界面（UI）设计：UI Predefined和UI Open，旨在减少对复杂提示工程的依赖，提高可用性。通过一项有20名参与者的受控用户研究，将这两种UI与标准ChatGPT界面在可用性和认知负荷方面进行了评估。

**Result:** 研究结果表明，UI Predefined在可用性和降低任务负荷方面显著优于ChatGPT和UI Open。UI Open虽然提供了更大的灵活性，但学习曲线更陡峭。

**Conclusion:** 研究强调了在采用AI驱动工具时以用户为中心设计的重要性，并为在线学习环境中更直观、高效的教育工作者-LLM交互奠定了基础。

> **ai_Abstract:** 本文针对教育工作者在使用大型语言模型（LLMs）进行课程开发时遇到的挑战，如复杂的提示工程和可用性问题，提出了两种基于直接操作原则的新型用户界面（UI Predefined和UI Open）。通过一项20名参与者的用户研究，评估了这两种UI相对于标准ChatGPT界面的表现。结果表明，UI Predefined在可用性和降低认知负荷方面显著优于其他两者，而UI Open则提供了更大的灵活性。研究强调了用户中心设计在AI工具采纳中的关键作用，并为未来教育领域中人机协作提供了新的方向。

> **摘要翻译:** 大型语言模型（LLMs）有潜力改变动态课程的交付方式。然而，教育工作者在与这些模型互动时面临显著挑战，特别是由于复杂的提示工程和可用性问题，这增加了工作量。此外，LLM输出的不准确性可能引发教育内容交付中的输出质量和伦理问题。解决这些问题需要仔细的监督，通过人机协作的方法可以最好地实现。本文介绍了两种新颖的用户界面（UI）设计，UI Predefined和UI Open，两者都基于直接操作（DM）原则来解决这些挑战。通过减少对复杂提示工程的依赖，这些UI提高了可用性，简化了交互，并降低了工作量，为教育工作者与LLM互动提供了更有效的途径。在一项有20名参与者的受控用户研究中，所提出的UI在可用性和认知负荷方面与标准ChatGPT界面进行了评估。结果显示，UI Predefined显著优于ChatGPT和UI Open，表现出卓越的可用性和降低的任务负荷，而UI Open提供了更大的灵活性，但学习曲线更陡峭。这些发现强调了在采用AI驱动工具时用户中心设计的重要性，并为在线学习环境中更直观、高效的教育工作者-LLM交互奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [191] [Development of a Smart Autonomous Irrigation System Using Iot and AI](https://arxiv.org/abs/2506.11835)
> *基于物联网和人工智能的智能自主灌溉系统开发*

*Yunus Emre Kunt* | **Main category: cs.CY**

**Keywords:** 自主灌溉, 物联网, 人工智能, 农业, 水管理

**Comment:** 13 pages main text plus 3 pages appendix, 12 figures

> **TL;DR:** 该研究开发了一个基于物联网和人工智能的智能自主滴灌系统，旨在提高灌溉效率、节约水资源并支持可持续农业实践。

**AI_Comments:** 该研究将成熟的滴灌技术与前沿的物联网和人工智能相结合，提供了一个实用的智能农业解决方案。其创新点在于将AI（LSTM模型）应用于环境数据预测以优化灌溉，并支持用户手动与AI自主控制的混合模式。该系统在节水和提高农业生产力方面具有重要意义，尤其是在当前全球水资源日益紧张的背景下。未来可关注其在实际大规模应用中的鲁棒性和经济效益评估。

<details>
  <summary>Details</summary>

**Motivation:** 传统农业灌溉管理不当会导致水资源浪费和农业生产力下降。尽管滴灌系统效率高，但仍有提升空间。本研究旨在通过结合物联网和人工智能来解决这些问题，以提高效率并防止水资源浪费。

**Method:** 该系统将传统滴灌系统与物联网和人工智能相结合。它使用ESP32微控制器、雨水和土壤湿度传感器、DHT11温湿度传感器、继电器、电磁阀和12V电源。环境数据通过USB从ESP32传输到计算机，并使用LSTM模型进行处理，以执行学习和预测。用户可以通过Blynk应用程序手动控制或将其委托给人工智能。

**Result:** 该系统旨在提高灌溉效率、防止水资源浪费、提高劳动生产率（使工人专注于灌溉以外的任务）、支持可持续农业实践并增加农业生产力。系统原型在3行3列的设置中进行了测试，并设计为适用于不同的农业生产区域。

**Conclusion:** 开发的智能自主灌溉系统通过整合物联网和人工智能，能够有效节约水资源、提高农业生产力并推广可持续农业实践，从而实现水资源保护和劳动力效率提升的目标。

> **ai_Abstract:** 本研究开发了一个基于物联网和人工智能的智能自主滴灌系统，旨在解决传统灌溉中水资源浪费和生产力低下的问题。该系统利用ESP32微控制器和多种传感器收集环境数据，并通过LSTM模型进行数据处理和预测，实现自动化灌溉控制。用户可通过Blynk应用手动或AI控制系统。该系统旨在提高灌溉效率、节约水资源、提升劳动生产率，并支持可持续农业实践。

> **摘要翻译:** 农业灌溉确保植物生长所需的水分以受控方式输送到土壤中。然而，不受控制的管理会导致水资源浪费，同时降低农业生产力。滴灌系统自20世纪70年代以来一直是最有效的方法之一，本研究通过物联网和人工智能对其进行现代化改造，旨在提高效率并防止水资源浪费。所开发的系统设计用于不同的农业生产区域，并使用由3行3列组成的原型进行了测试。该项目将从ESP32微控制器通过USB连接将环境数据传输到计算机开始，数据将在计算机上使用LSTM模型进行处理，以执行学习和预测。用户将能够通过Blynk应用程序手动控制系统或将其委托给人工智能。该系统包括ESP32微控制器、雨水和土壤湿度传感器、DHT11温湿度传感器、继电器、电磁阀和12V电源。该系统旨在提高劳动生产率，并通过使农业和温室工人专注于灌溉以外的过程来促进水资源保护。此外，开发的自主灌溉系统将支持可持续农业实践的推广并提高农业生产力。关键词：自主灌溉、物联网、人工智能、农业、水管理

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [210] [Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?](https://arxiv.org/abs/2506.11945)
> *AI系统中的主观体验：AI研究人员和公众的看法如何？*

*Noemi Dreksler, Lucius Caviola, David Chalmers, Carter Allen, Alex Rand, Joshua Lewis, Philip Waggoner, Kate Mays, Jeff Sebo* | **Main category: cs.CY**

**Keywords:** 主观体验, AI系统, 公众意见, AI伦理, 治理

**Comment:** 109 pages, 27 figures

> **TL;DR:** 一项针对AI研究人员和公众的调查显示，双方都认为AI系统在本世纪内可能出现主观体验，但在时间线和治理方式上存在分歧，尽管都支持立即采取保障措施。

**AI_Comments:** 这篇论文通过对AI研究人员和公众的问卷调查，提供了关于AI主观体验这一前沿且复杂的伦理议题的实证数据，具有重要意义。其创新之处在于系统地量化了不同群体对此的认知和态度，揭示了共识与分歧，为未来AI伦理政策制定和公众讨论提供了宝贵基础。

<details>
  <summary>Details</summary>

**Motivation:** 了解AI研究人员和公众对于可能发展出主观体验的AI系统及其应如何被对待和管理持有的看法。

**Method:** 研究人员对582名在领先AI会议上发表过论文的AI研究人员和838名具有全国代表性的美国公众参与者进行了调查。

**Result:** AI研究人员和公众对AI系统在2100年拥有主观体验的概率中位数分别为70%和60%。公众认为此类系统永远不会存在的可能性（25%）高于AI研究人员（10%）。双方都认为评估AI主观体验需要多学科专业知识。对AI福利保护的支持远低于对动物或环境的保护。在道德和治理问题上（如是否应创建此类系统以及应获得何种权利或保护），双方观点存在分歧。然而，多数受访者同意AI开发者现在就应实施防范此类AI系统潜在风险的保障措施，且若创建，此类AI系统应善待他人、行为符合道德并承担责任。

**Conclusion:** 总的来说，这些结果表明AI研究人员和公众都认为具有主观体验的AI系统在本世纪出现是可能的，尽管在时间线和适当的应对措施上仍存在很大的不确定性和分歧。

> **ai_Abstract:** 本研究调查了AI研究人员和公众对具有主观体验的AI系统出现及其治理的看法。结果显示，两组都认为本世纪内AI可能发展出主观体验，但在具体时间预测上存在差异，且在道德和治理问题上存在显著分歧。尽管如此，多数受访者支持立即实施风险保障措施，并要求此类AI系统行为符合道德且负责。

> **摘要翻译:** 我们调查了582名在领先AI场所发表过论文的AI研究人员和838名具有全国代表性的美国参与者，了解他们对具有主观体验的AI系统潜在发展的看法，以及此类系统应如何被对待和治理。当被问及估计此类系统在特定日期存在的可能性时，中位数回答是：到2024年，AI研究人员为1%，公众为5%；到2034年，分别为25%和30%；到2100年，分别为70%和60%。公众中位数认为具有主观体验的AI系统永远不会存在的可能性（25%）高于AI研究人员中位数（10%）。两组都认为评估AI主观体验需要多学科专业知识。尽管对此类AI系统福利保护的支持超过了反对，但仍远低于对动物或环境保护的支持。两组对道德和治理问题的态度存在分歧，尤其是在是否应该创建此类系统以及它们应该获得何种权利或保护方面。然而，两组的大多数受访者都同意，AI开发者现在就应实施防范具有主观体验的AI系统潜在风险的保障措施，并且如果创建，具有主观体验的AI系统应该善待他人、行为符合道德并承担责任。总的来说，这些结果表明AI研究人员和公众都认为具有主观体验的AI系统在本世纪出现是可能的，尽管在时间线和适当的应对措施上仍存在很大的不确定性和分歧。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [16] [Convergence of physics-informed neural networks modeling time-harmonic wave fields](https://arxiv.org/abs/2506.11395)
> *物理信息神经网络模拟时谐波场的收敛性*

*Stefan Schoder, Aneta Furmanová, Viktor Hruška* | **Main category: cs.CE**

**Keywords:** 物理信息神经网络, 时谐波场, 收敛性, 房间声学, 亥姆霍兹方程

**Comment:** 

> **TL;DR:** 本文研究了物理信息神经网络（PINNs）在模拟三维低频时谐波场时的收敛性，并发现为了准确训练和预测，每波长至少需要六个训练点。

**AI_Comments:** 本文深入探讨了物理信息神经网络在复杂三维声场建模中的实际应用问题，特别是其收敛性。它通过具体的实验验证了训练点密度对PINN性能的关键影响，为PINN在实际工程问题中的应用提供了重要的指导原则，尤其是在低频房间声学领域。强调了从理论到实际应用过程中需要克服的挑战，并提供了量化的收敛性标准。

<details>
  <summary>Details</summary>

**Motivation:** 物理信息神经网络（PINNs）在二维简单几何中模拟声波场取得了有希望的结果，但其正向问题在收敛性方面面临挑战，尤其是在考虑物理维度（从2D到3D）、真实声源、声硬（诺伊曼）边界条件和复数解量时。本文旨在解决这些挑战并评估其收敛行为。

**Method:** 研究了三维房间声学低频情况，改变了声源定义和边界条件集的数量，并使用复数声速模型以考虑一定程度的吸收。通过分析PINN架构的损失景观以及与有限元参考模拟的L2误差来评估收敛行为。

**Result:** 收敛性研究表明，为了PINN的准确训练和后续预测，每波长至少需要六个训练点。

**Conclusion:** 为了准确模拟时谐波场，PINNs需要每波长至少六个训练点来保证收敛性。

> **ai_Abstract:** 该论文研究了物理信息神经网络（PINNs）在模拟三维低频时谐波场时的收敛性问题。针对从二维到三维、真实声源、边界条件和复数解量等挑战，作者通过改变声源定义和边界条件集，并引入复数声速模型，在3D房间声学案例中进行了评估。研究发现，为了实现PINN的准确训练和预测，每波长至少需要六个训练点。

> **摘要翻译:** 物理信息神经网络（PINNs）在二维域中对偏微分方程进行建模以求解声波场的研究，已在简单几何形状方面产生了有希望的结果。其中一种选择是使用亥姆霍兹方程计算时谐波场。与现有数值模型相比，物理信息神经网络正向问题必须克服与优化收敛到“真实”解相关的几个问题。这些问题包括考虑物理维度（从2D到3D）、真实声源（从自相似声源到真实的受限点声源）的建模、声硬（诺伊曼）边界条件的建模以及通过考虑复数解量来建模完整波场。在本贡献中，我们研究了低频下的3D房间声学案例，改变了声源定义和边界条件集的数量，并使用复数声速模型来解释一定程度的吸收。我们通过观察PINN架构的损失景观以及与每个网络架构和配置的有限元参考模拟相比的$L^2$误差来评估收敛行为。收敛性研究表明，为了PINN的准确训练和后续预测，每波长至少需要六个训练点。这些进展是旨在模拟包括吸声体在内的房间声学低频行为的倡议的一部分。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [44] [CLEAN-MI: A Scalable and Efficient Pipeline for Constructing High-Quality Neurodata in Motor Imagery Paradigm](https://arxiv.org/abs/2506.11830)
> *CLEAN-MI：一种用于构建高质量运动想象范式神经数据的可扩展高效流程*

*Dingkun Liu, Zhu Chen, Dongrui Wu* | **Main category: cs.CE**

**Keywords:** 运动想象, 脑机接口, 数据质量, EEG, 数据预处理

**Comment:** 10 pages, 6 figures

> **TL;DR:** CLEAN-MI是一个可扩展且高效的数据构建流程，旨在解决运动想象脑机接口中EEG数据质量差、异构性和个体差异大的问题，通过集成多种处理步骤，显著提升了数据质量和分类性能。

**AI_Comments:** CLEAN-MI的创新之处在于其系统化的数据构建流程，整合了多种预处理和标准化技术，以解决MI-BCI中EEG数据固有的复杂性和异质性。这种方法对于构建高质量的基础模型至关重要，特别是考虑到现有数据集的质量问题。其可扩展性和在多个公共数据集上的有效性表明了该方法的潜在实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 运动想象（MI）脑机接口中，构建大规模、高质量的神经数据集是开发鲁棒且通用基础模型的先决条件。然而，不同受试者和设备采集的EEG信号常存在低信噪比、电极配置异构性以及显著的个体间差异，这些问题对有效的模型训练构成了巨大挑战。

**Method:** 本文提出了CLEAN-MI，一个可扩展且系统化的数据构建流程。CLEAN-MI集成了频带滤波、通道模板选择、受试者筛选和边缘分布对齐，以系统地过滤掉不相关或低质量的数据，并标准化多源EEG数据集。

**Result:** CLEAN-MI在多个公共MI数据集上展示了其有效性，在数据质量和分类性能方面均实现了持续改进。

**Conclusion:** CLEAN-MI能够有效解决运动想象范式中EEG数据质量差和异构性的问题，显著提升了数据质量和模型分类性能，为构建高质量的脑机接口数据集提供了一个可扩展且系统化的解决方案。

> **ai_Abstract:** CLEAN-MI是一个为运动想象（MI）脑机接口（BCI）设计的数据构建流程，旨在解决EEG数据中存在的低信噪比、电极配置异构性和个体差异等问题。该流程通过整合频带滤波、通道模板选择、受试者筛选和边缘分布对齐等步骤，能够系统地筛选并标准化多源EEG数据，从而构建大规模、高质量的神经数据。实验证明，CLEAN-MI在多个公共MI数据集上有效提升了数据质量和分类性能。

> **摘要翻译:** 大规模、高质量数据集的构建是开发基于运动想象（MI）的脑机接口（BCI）中鲁棒和通用基础模型的根本前提。然而，从不同受试者和设备收集的EEG信号常常受到低信噪比、电极配置异构性和显著的受试者间变异性的困扰，这对有效的模型训练提出了重大挑战。在本文中，我们提出了CLEAN-MI，一个可扩展且系统化的数据构建流程，用于在MI范式中构建大规模、高效和准确的神经数据。CLEAN-MI集成了频带滤波、通道模板选择、受试者筛选和边缘分布对齐，以系统地过滤掉不相关或低质量的数据并标准化多源EEG数据集。我们证明了CLEAN-MI在多个公共MI数据集上的有效性，在数据质量和分类性能方面取得了持续的改进。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [17] [Reversible Pebble Transducers](https://arxiv.org/abs/2506.11334)
> *可逆卵石变换器*

*Luc Dartois, Paul Gastin, L. Germerie Guizouarn, Shankaranarayanan Krishna* | **Main category: cs.FL**

**Keywords:** 卵石变换器, 可逆变换器, 函数组合, 多正则函数, 复杂性分析

**Comment:** 

> **TL;DR:** 论文引入了可逆卵石变换器，并提供了将非确定性卵石变换器统一为可逆卵石变换器以及可逆卵石变换器的有效组合技术，以解决现有卵石变换器组合的复杂性问题。

**AI_Comments:** 这项工作通过引入“可逆卵石变换器”的概念，并提出高效的统一化和组合技术，显著改进了卵石变换器组合操作的效率，解决了长期存在的双指数复杂性问题。这对于多正则函数理论和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有卵石变换器的组合操作存在双指数级的复杂性膨胀，并且缺乏精确的复杂度分析。

**Method:** 引入了可逆卵石变换器，并开发了将非确定性卵石变换器统一为可逆变换器的有效技术，以及可逆卵石变换器的有效组合方法。

**Result:** 实现了将非确定性卵石变换器有效统一为可逆卵石变换器，以及可逆卵石变换器的有效组合。

**Conclusion:** 论文通过引入可逆卵石变换器和提供相应的统一化及组合技术，有效地解决了卵石变换器组合操作中存在的复杂性问题。

> **ai_Abstract:** 本文引入了可逆卵石变换器，旨在解决现有卵石变换器组合操作中存在的双指数级复杂性问题。通过开发将非确定性卵石变换器统一为可逆形式的有效技术，以及实现可逆卵石变换器的有效组合，论文成功地降低了组合操作的复杂性。

> **摘要翻译:** 卵石变换器（也称为卵石变换器）捕获了多正则函数类，该类扩展了字符串到字符串的正则函数，允许多项式增长而非线性增长。函数最基本的操作之一是组合，并且（多）正则函数可以实现为几个更简单函数的组合。通常，确定性双向变换器的组合会导致输入大小的双指数级膨胀。达托瓦斯等人[10]的基本结果在这个方向上取得了重大进展，他们展示了可逆双向变换器组合的多项式构造。目前，卵石变换器现有组合技术的精确复杂性分析缺失。但它们依赖于经典的双向变换器组合，并继承了双指数复杂性。为了克服这个问题，我们引入了可逆卵石变换器。我们的主要结果是针对非确定性卵石变换器到可逆卵石变换器的有效统一化技术，以及可逆卵石变换器的有效组合。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [21] [Smart Predict-Then-Control: Integrating identification and control via decision regret](https://arxiv.org/abs/2506.11279)
> *智能预测-然后-控制：通过决策后悔整合辨识与控制*

*Jiachen Li, Shihao Li, Dongmei Chen* | **Main category: eess.SY**

**Keywords:** 智能预测-然后-控制, 系统辨识, 控制, 决策后悔, 预测误差

**Comment:** 

> **TL;DR:** 本文提出了智能预测-然后-控制（SPC）框架，通过利用决策后悔来整合系统辨识和控制，以解决传统方法中建模误差与控制成本不对齐的问题。

**AI_Comments:** SPC框架的创新之处在于引入了“决策后悔”的概念，将系统辨识与控制紧密结合，解决了传统方法中建模误差与控制目标不一致的问题。通过优化对控制性能影响最大的预测误差，提高了控制系统的整体性能。这一方法在理论上提供了后悔界限的保证，并在实践中得到了验证，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统系统辨识和控制方法存在建模误差与控制成本不对齐的局限性。

**Method:** 本文提出了智能预测-然后-控制（SPC）框架，该框架通过利用决策后悔来优先处理与控制相关的动态，并根据预测误差对控制性能的影响来优化预测误差。

**Result:** 理论上证明了后悔界限的存在性，并在线性系统和非线性系统上验证了所提出的SPC框架。

**Conclusion:** SPC框架通过整合系统辨识和控制，并利用决策后悔来优化预测误差，从而有效解决了传统方法的局限性。

> **ai_Abstract:** 本文提出了一种名为智能预测-然后-控制（SPC）的新框架，旨在整合系统辨识与控制。该框架通过利用决策后悔来解决传统方法中建模误差与控制成本不一致的问题，从而优先优化对控制性能影响最大的预测误差。研究还理论证明了后悔界限的存在，并通过在线性和非线性系统上的验证，展示了SPC的有效性。

> **摘要翻译:** 本文提出了智能预测-然后-控制（SPC）框架，用于整合系统辨识和控制。这种新颖的SPC框架解决了传统方法的局限性，即建模误差与控制成本不对齐的问题。它利用决策后悔来优先处理与控制相关的动态，根据预测误差对控制性能的影响来优化预测误差。此外，理论上证明了后悔界限的存在性。所提出的SPC在线性系统和非线性系统上都得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [49] [Influence Functions for Data Attribution in Linear System Identification and LQR Control](https://arxiv.org/abs/2506.11293)
> *线性系统辨识与LQR控制中数据归因的影响函数*

*Jiachen Li, Shihao Li, Jiamin Xu, Soovadeep Bakshi, Dongmei Chen* | **Main category: eess.SY**

**Keywords:** 影响函数, 数据归因, 线性系统辨识, LQR控制, 计算效率

**Comment:** 

> **TL;DR:** 本文提出了一种利用影响函数来高效近似训练数据点对学习到的系统动力学和LQR控制性能影响的方法，经验证与再训练结果高度相关，为数据归因提供了计算可行的方法。

**AI_Comments:** 本文的创新之处在于将影响函数引入到线性系统辨识和LQR控制的数据归因问题中，解决了传统留一法再训练的计算效率低下的问题。通过区分对模型预测精度（IF1）和控制性能（IF2）的影响，提供了更细致的分析。其重要性在于为开发更可靠、可解释的基于机器学习的控制系统提供了工具。

<details>
  <summary>Details</summary>

**Motivation:** 开发可靠的基于机器学习的控制系统，理解单个训练数据点的影响至关重要。然而，传统的留一法再训练对于大型数据集计算上不可行。

**Method:** 本文引入了一个使用影响函数（IF）的框架，以高效近似移除特定训练轨迹对学习到的系统动力学和下游控制性能的影响。提出了两种影响函数：IF1用于估计对学习到的线性动力学模型预测精度的影响；IF2用于量化对使用这些学习到的动力学设计的线性二次调节器（LQR）控制器成本的后续影响。这些涉及通过离散代数黎卡提方程（DARE）解来追踪敏感性。

**Result:** 结果显示，影响预测与通过再训练获得的真实变化之间存在很强的正相关性。

**Conclusion:** 本文提出的框架为数据归因提供了一种计算上可行的方法。

> **ai_Abstract:** 本文提出了一种基于影响函数（IFs）的框架，旨在高效评估单个训练数据点对线性系统辨识和LQR控制性能的影响。针对传统留一法再训练的计算瓶颈，该框架引入了IF1来衡量对系统动力学模型预测精度的影响，以及IF2来量化对LQR控制器成本的后续影响。通过追溯离散代数黎卡提方程（DARE）解的敏感性，该方法在模拟机器人机械手系统上得到了验证，结果表明其预测与实际变化高度相关，为数据归因提供了一种计算上可行且高效的解决方案。

> **摘要翻译:** 理解单个训练数据点的影响对于开发可靠的基于机器学习的控制系统至关重要。然而，传统的留一法再训练对于大型数据集而言在计算上是不可行的。本文引入了一个使用影响函数（IF）的框架，以高效近似移除特定训练轨迹对学习到的系统动力学和下游控制性能的影响。我们提出了两种影响函数：IF1，用于估计对学习到的线性动力学模型预测精度的影响；IF2，用于量化对使用这些学习到的动力学设计的线性二次调节器（LQR）控制器成本的后续影响。这些涉及通过离散代数黎卡提方程（DARE）解来追踪敏感性。我们在模拟的线性系统上对我们的方法进行了实证验证，这些系统类似于机器人机械手。结果显示，影响预测与通过再训练获得的真实变化之间存在很强的正相关性。我们的框架为数据归因提供了一种计算上可行的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [77] [A Hybrid Adaptive Nash Equilibrium Solver for Distributed Multi-Agent Systems with Game-Theoretic Jump Triggering](https://arxiv.org/abs/2506.11304)
> *具有博弈论跳跃触发的分布式多智能体系统混合自适应纳什均衡求解器*

*Qiuyu Miao, Zhigang Wu* | **Main category: eess.SY**

**Keywords:** 分布式多智能体系统, 纳什均衡, 博弈论, 混合系统, 跳跃触发

**Comment:** Submitted to Asian Journal of Control. 15 pages, 5 figures. This work
  extends hybrid dynamical systems theory to multi-agent coordination through
  distributed Nash equilibrium computation with game-theoretic jump triggering
  mechanisms

> **TL;DR:** 本文提出了一种混合自适应纳什均衡求解器 (HANES)，通过博弈论跳跃触发机制解决分布式多智能体系统的可扩展性和计算挑战，并在仿真中表现出显著的性能提升。

**AI_Comments:** 这篇论文通过引入博弈论跳跃触发机制，为分布式多智能体系统的纳什均衡求解提供了一种创新的混合自适应方法。其创新点在于将博弈论与混合系统设计相结合，有效解决了传统方法的扩展性和计算效率瓶颈。所提供的严格稳定性保证和仿真结果的显著性能提升，凸显了该方法在实际应用中的潜力，特别是在需要快速响应和高效率的复杂多智能体系统中。

<details>
  <summary>Details</summary>

**Motivation:** 解决多智能体混合系统中的可扩展性和计算挑战。

**Method:** 提出了一种混合自适应纳什均衡求解器 (HANES) 算法，该算法集成了分布式博弈论优化与系统混合系统设计，并引入了一种新颖的博弈论跳跃触发机制来协调多智能体间的离散模式转换。

**Result:** 建立了在分布式信息约束下指数收敛到共识的充分条件；通过耦合的Hamilton-Jacobi-Bellman方程提供了严格的稳定性保证；通过协调跳跃动力学实现了快速应急响应能力；在追逐-规避和领导者-跟随者共识场景的仿真研究中，与现有方法相比，显著改善了收敛时间、计算效率和可扩展性。

**Conclusion:** 提出的HANES框架通过博弈论跳跃触发机制有效解决了分布式多智能体系统的可扩展性和计算挑战，并提供了严格的稳定性保证和显著的性能提升。

> **ai_Abstract:** 本文介绍了一种名为HANES的混合自适应纳什均衡求解器，专为分布式多智能体系统设计，并引入了博弈论跳跃触发机制。该方法旨在解决多智能体混合系统的可扩展性和计算效率问题，通过整合分布式博弈论优化和系统混合系统设计实现。HANES算法能协调智能体间的模式转换，同时保持其自主性。研究证明了其在分布式信息约束下的指数收敛性与稳定性，并通过仿真验证了其在收敛时间、计算效率和可扩展性方面优于现有方法的性能。

> **摘要翻译:** 本文提出了一种混合自适应纳什均衡求解器，用于包含博弈论跳跃触发机制的分布式多智能体系统。该方法通过将分布式博弈论优化与系统混合系统设计相结合，解决了多智能体混合系统中的基本可扩展性和计算挑战。一种新颖的博弈论跳跃触发机制协调多个智能体之间的离散模式转换，同时保持分布式自主性。混合自适应纳什均衡求解器 (HANES) 算法整合了这些方法。在分布式信息约束下，建立了指数收敛到共识的充分条件。该框架通过耦合的Hamilton-Jacobi-Bellman方程提供了严格的稳定性保证，同时通过协调的跳跃动力学实现了快速应急响应能力。在追逐-规避和领导者-跟随者共识场景中的仿真研究表明，与现有的集中式和分布式方法相比，收敛时间、计算效率和可扩展性方面均有显著改善。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [104] [Deception Against Data-Driven Linear-Quadratic Control](https://arxiv.org/abs/2506.11373)
> *对抗数据驱动的线性二次控制的欺骗*

*Filippos Fotiadis, Aris Kanellopoulos, Kyriakos G. Vamvoudakis, Ufuk Topcu* | **Main category: eess.SY**

**Keywords:** 欺骗, 数据驱动控制, 线性二次控制, Riccati方程, Lyapunov方程

**Comment:** 16 pages, 5 figures

> **TL;DR:** 本文研究了一种防御策略，通过注入欺骗性输入，使信息劣势的攻击者学习并选择次优的攻击策略，并提出了数值求解方法。

**AI_Comments:** 本文的创新点在于将防御者的欺骗行为建模为求解耦合的Riccati和Lyapunov方程，并提出了一种数值求解方法，解决了分析上的挑战。这对于对抗信息劣势的智能攻击者具有重要意义，特别是在控制系统安全领域。其贡献在于提供了一种理论上可行且数值上可实现的欺骗策略，以降低攻击效果。

<details>
  <summary>Details</summary>

**Motivation:** 欺骗是针对信息劣势对手的常见防御机制，可以迫使对手选择次优策略。本文旨在设计一种欺骗性输入，以引导攻击者学习预设的次优攻击，从而保护系统。

**Method:** 将欺骗设计问题转化为求解耦合的代数Riccati方程和Lyapunov方程，并提出了一种块逐次过松弛算法进行数值求解，同时证明了该算法在特定条件下的收敛性。

**Result:** 在基准飞机模拟中，所提出的算法能够成功误导攻击者学习性能下降较少的攻击策略。

**Conclusion:** 提出的欺骗设计算法能够有效地误导信息劣势的攻击者学习次优攻击，从而有利于防御者。

> **ai_Abstract:** 本文研究了针对数据驱动线性二次控制系统的欺骗防御策略。防御者通过注入精心设计的欺骗性输入，旨在误导信息劣势的攻击者学习并执行预设的次优攻击，而非最优攻击。研究将此欺骗设计问题转化为求解耦合的代数Riccati和Lyapunov方程，并提出了一种块逐次过松弛算法进行数值求解，证明了其收敛性。仿真结果表明，该算法能有效诱导攻击者选择性能损害较小的攻击。

> **摘要翻译:** 欺骗是针对信息劣势对手的常见防御机制。它可以迫使此类对手为防御者选择次优策略。我们考虑一个场景，其中攻击者试图学习针对某个系统的最优线性二次攻击，但它不知道该系统的动态特性。另一方面，了解系统动态的防御者利用其信息优势，向系统注入欺骗性输入以误导攻击者。防御者的目标是战略性地设计这种欺骗性输入：它应该迫使攻击者尽可能接近地学习一个预先选择的、与最优攻击不同的攻击。我们表明，这种欺骗设计问题归结为耦合代数Riccati方程和Lyapunov方程的解，然而，这些方程难以进行解析处理。尽管如此，我们使用块逐次过松弛算法对其进行数值求解，并证明了该算法在某些条件下的收敛性。我们在一个基准飞机上进行了模拟，展示了所提出的算法如何误导攻击者学习性能下降较少的攻击。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [131] [Design and Simulation of Vehicle Motion Tracking System using a Youla Controller Output Observation System](https://arxiv.org/abs/2506.11386)
> *采用Youla控制器输出观测系统的车辆运动跟踪系统设计与仿真*

*Rongfei Li, Francis Assadian. Iman Soltani* | **Main category: eess.SY**

**Keywords:** Youla控制器, 车辆跟踪, 观测系统, 运动估计, 线性观测器

**Comment:** 20 pages, 13 figures, Journal. Accepted for publication in:
  Measurement and Control, SAGE Publishing, 2025

> **TL;DR:** 本文提出了一种新颖的线性鲁棒Youla控制器输出观测系统，用于车辆运动轨迹跟踪，该系统使用三个线性观测器，并在仿真中表现出准确和鲁棒的估计性能。

**AI_Comments:** 这项工作的创新点在于首次将Youla控制器输出观测器应用于车辆跟踪估计，并成功地将所需观测器数量从四个非线性观测器减少到三个线性观测器，同时引入切换技术解决了控制器切换时的平稳性问题，显著提升了系统的效率和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法需要四个非线性观测器，且可能在控制器切换时出现颠簸。本文旨在提出一种更高效、平稳的车辆运动轨迹跟踪系统。

**Method:** 提出了一种新颖的线性鲁棒Youla控制器输出观测系统，结合简单的非线性运动学车辆模型和雷达传感器位置数据。该系统使用三个线性观测器，并引入切换技术以确保控制器和观测器之间平稳过渡。

**Result:** 通过仿真评估，系统在各种标准驾驶操作（包括变道和交叉路口）中，能够从传感器测量中准确、鲁棒地估计纵向和横向位置、车辆方向和速度。

**Conclusion:** 首次将Youla控制器输出观测器应用于车辆跟踪估计，并证明了其在车辆运动轨迹跟踪中的有效性和鲁棒性。

> **ai_Abstract:** 本文提出了一种创新的线性鲁la控制器输出观测系统，用于车辆运动轨迹跟踪。该系统结合简单的非线性车辆模型和雷达数据，仅用三个线性观测器实现了全轨迹范围的跟踪，相比传统方法减少了观测器数量并提高了效率。通过引入切换技术，确保了控制器切换的平稳性。仿真结果表明，该系统在多种驾驶场景下能准确鲁棒地估计车辆状态，其核心创新在于Youla控制器输出观测器在车辆跟踪估计中的首次应用。

> **摘要翻译:** 本文提出了一种新颖的线性鲁棒Youla控制器输出观测系统，用于使用简单的非线性运动学车辆模型并辅以雷达传感器位置数据来跟踪车辆运动轨迹。所提出的系统在整个车辆轨迹范围内仅使用三个线性观测器，改进了以前需要四个非线性观测器的方法。为了确保Youla控制器和观测器之间的平稳过渡，引入了一种切换技术，以防止控制器更改时出现颠簸。所提出的观测系统通过仿真进行评估，在各种标准驾驶操作中，从传感器测量中准确、鲁棒地估计了纵向和横向位置、车辆方向和速度。结果提供了不同驾驶场景的数据，包括变道和交叉路口，在这些场景中车辆方向发生显著变化。这项工作的创新之处在于首次将Youla控制器输出观测器应用于车辆跟踪估计。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [155] [Compositional and Equilibrium-Free Conditions for Power System Stability -- Part I: Theory](https://arxiv.org/abs/2506.11406)
> *电力系统稳定性组合式与无平衡条件 -- 第一部分：理论*

*Peng Yang, Xiaoyu Peng, Xi Ru, Hua Geng, Feng Liu* | **Main category: eess.SY**

**Keywords:** 电力系统稳定性, 组合式分析, 无平衡, Delta耗散性, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种组合式且无平衡的电力系统稳定性分析理论，旨在解决传统方法的扩展性问题。该理论基于delta耗散性，允许在不知系统全局平衡点的情况下，通过局部条件证明系统范围的稳定性，并能验证平衡集合的稳定性。第一部分通过单机单负荷基准验证了该理论。

**AI_Comments:** 本文的核心创新在于提出了“无平衡”和“组合式”的稳定性分析方法，这显著提升了传统分析在大型复杂电力系统中的扩展性。利用“delta耗散性”概念来避免对全局平衡点的依赖是其关键的理论贡献。这项工作对于管理日益复杂的现代电网具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统集中式稳定性分析在大型复杂现代电网中难以扩展。

**Method:** 提出了一种组合式、无平衡的电力系统稳定性分析方法。该方法基于新发展的delta耗散性概念，可以在不知道系统范围平衡点的情况下得出局部稳定性条件，从而能够证明异构非线性设备和保结构有损网络的系统范围稳定性，并验证平衡集合的稳定性。

**Result:** 证明了利用无平衡的局部条件可以证明具有异构非线性设备和保结构有损网络的电力系统的系统范围稳定性。通过单机单负荷基准验证了该理论，并展示了其有前景的含义，有助于更好地解释组合式和面向平衡集合的稳定性分析。

**Conclusion:** 所提出的理论为稳定性分析提供了一种更具扩展性和适应性的方法，并阐明了如何调节并网设备以保证系统范围的稳定性。

> **ai_Abstract:** 本文针对传统电力系统稳定性分析在大型复杂电网中扩展性差的问题，提出了一种组合式且无平衡的稳定性分析理论。第一部分主要阐述了该理论，证明了基于delta耗散性的无平衡局部条件能够证明异构非线性设备和有损网络的系统范围稳定性，并且能够验证平衡集合的稳定性。该理论通过单机单负荷基准进行了验证，为电力系统稳定性分析提供了更具扩展性和适应性的新方法，并为电网设备的调节提供了指导。

> **摘要翻译:** 传统集中式稳定性分析在大型复杂现代电网中难以扩展。这篇分为两部分的论文提出了一种组合式且无平衡的电力系统稳定性分析方法。在第一部分中，我们证明了使用无平衡的局部条件可以证明具有异构非线性设备和保结构有损网络的电力系统的系统范围稳定性。这建立在最近发展的delta耗散性概念之上，该概念在不知道系统范围平衡点的情况下得出局部稳定性条件。因此，我们提出的理论可以证明平衡集合而非单个平衡点的稳定性。在第一部分中，我们通过单机单负荷基准验证了我们的理论并展示了有前景的含义，这有助于更好地解释组合式和面向平衡集合的稳定性分析。本文的第二部分将提供将我们的理论应用于复杂电网的方法，以及广泛系统规模的案例研究。我们的结果使得稳定性分析方法更具扩展性和适应性。它还阐明了如何调节并网设备以保证系统范围的稳定性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [175] [Compositional and Equilibrium-Free Conditions for Power System Stability -- Part II: Method and Application](https://arxiv.org/abs/2506.11411)
> *电力系统稳定性的组合式与无平衡条件——第二部分：方法与应用*

*Peng Yang, Yifan Su, Xiaoyu Peng, Hua Geng, Feng Liu* | **Main category: eess.SY**

**Keywords:** 电力系统稳定性, 组合式, 无平衡, delta耗散性, ADMM

**Comment:** 

> **TL;DR:** 本文提出了将组合式、无平衡的稳定性分析方法应用于复杂电力系统，并利用ADMM等方法验证了其有效性。

**AI_Comments:** 本文作为系列研究的第二部分，详细阐述了将创新性的组合式、无平衡稳定性理论应用于复杂电力系统的方法论。其亮点在于提出了针对异构设备的局部条件验证和基于ADMM的耦合条件验证方法，并展示了在实际应用场景（如多平衡点和分布式计算）中的潜力，对于提升电力系统稳定性分析的实用性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提出一种组合式且无平衡的方法来分析电力系统稳定性，并专注于将该理论应用于复杂的电力系统，解决其稳定性评估问题。

**Method:** 本文提出了一种验证电力系统中异构设备局部条件（即delta耗散性）的方法，并提出了一种基于交替方向乘子法（ADMM）的耦合条件验证方法。最后，研究了该理论的三个应用：多平衡点稳定性评估、不同运行条件下的稳定性评估以及分布式计算框架。

**Result:** 在修改后的IEEE 9总线、39总线和118总线基准案例研究中，本理论和方法得到了充分验证。

**Conclusion:** 本文提出的理论和方法在复杂电力系统稳定性分析中得到了有效验证。

> **ai_Abstract:** 本文是关于电力系统稳定性分析的两部分论文的第二部分。它主要关注如何将第一部分中提出的基于delta耗散性的组合式、无平衡稳定性理论应用于复杂的电力系统。文章详细介绍了验证异构设备局部条件和基于ADMM验证耦合条件的方法，并探讨了该理论在多平衡点、变运行条件下的稳定性评估以及分布式计算框架中的应用。通过对IEEE标准测试系统的案例研究，验证了所提出理论和方法的有效性。

> **摘要翻译:** 这篇分为两部分的论文提出了一种组合式且无平衡的方法来分析电力系统稳定性。在第一部分中，我们建立了稳定性理论并提出了基于delta耗散性的稳定性条件。在第二部分中，我们专注于将我们的理论应用于复杂电力网格的方法。我们首先提出了一种验证电力系统中异构设备局部条件（即delta耗散性）的方法。然后，我们提出了一种基于交替方向乘子法（ADMM）的耦合条件验证方法。最后，我们研究了我们理论的三个应用，包括多平衡点稳定性评估、不同运行条件下的稳定性评估以及分布式计算框架。对修改后的IEEE 9总线、39总线和118总线基准的案例研究充分验证了我们的理论和方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [194] [Symmetric Sliding-Mode Control of Grid-Forming Inverters With Controllable Region Under AC and DC Sides Varying](https://arxiv.org/abs/2506.11504)
> *交流和直流侧变化下具有可控区域的并网逆变器对称滑模控制*

*Qianxi Tang, Li Peng* | **Main category: eess.SY**

**Keywords:** 对称滑模控制, 并网逆变器, 可控区域, 电压跟踪, 直流母线电压

**Comment:** 10 pages, 10 figures. This copyright will belong to IEEE if the paper
  is accepted

> **TL;DR:** 本文提出了一种对称滑模控制（SSMC）方法，用于并网逆变器，以解耦电压形成与功率流和直流源动态，从而在交流和直流侧变化下实现更快、更鲁棒、更准确的电压跟踪。

**AI_Comments:** 本文提出了一种新颖的对称滑模控制方法，其创新点在于识别了逆变器非对称性导致的低频电压跟踪误差，并通过对称补偿结构直接解决，避免了传统滑模控制的复杂设计。其价值在于实现了并网逆变器在交流和直流侧变化下的快速、鲁棒和高精度电压跟踪，这对于提升电网稳定性具有重要意义。同时，明确的可控区域推导和物理量化解释也增强了该方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的并网型（GFM）控制常常将电压形成与功率流和直流源动态纠缠在一起，这在电网扰动、负载瞬变和直流侧扰动下会降低电压跟踪性能和稳定性。

**Method:** 开发了一种对称滑模控制（SSMC）方法，并推导了其显式电压可控区域。该方法识别出电力线频率误差主要源于逆变器非对称特性、延迟效应和计算不准确性。在此基础上，提出了一种对称补偿结构，以避免增加设计复杂性并直接减轻低频电压跟踪误差。该控制设计得到了物理和定量解释的支持，有助于参数调整。

**Result:** 仿真和实验结果表明，所提出的方法在直流母线电压和交流侧电流变化下，实现了数百微秒量级的更快跟踪响应，同时保持了鲁棒和更准确的跟踪。传统的并网型和经典滑模控制器无法达到这种结合了速度和鲁棒性的性能。此外，电压可控性分析得到了明确验证。

**Conclusion:** 所提出的对称滑模控制（SSMC）方法在交流和直流侧变化下，能够实现比传统控制方法更快、更鲁棒、更准确的电压跟踪性能。

> **ai_Abstract:** 本文针对传统并网型（GFM）控制中电压形成与功率流和直流源动态纠缠导致性能下降的问题，提出了一种对称滑模控制（SSMC）方法。该方法通过识别逆变器非对称性、延迟和计算不准确性导致的低频电压跟踪误差，并设计对称补偿结构来直接消除这些误差，从而避免了复杂设计。研究推导了显式电压可控区域，并提供了物理和定量解释以辅助参数调整。仿真和实验结果表明，与传统方法相比，所提出的SSMC在交流和直流侧变化下，能实现更快（微秒级）、更鲁棒、更准确的电压跟踪响应。

> **摘要翻译:** 传统的并网型（GFM）控制常常将电压形成与功率流和直流源动态纠缠在一起，这在电网扰动、负载瞬变和直流侧扰动下会降低电压跟踪性能和稳定性。为解决此问题，本文开发了一种对称滑模控制（SSMC）方法，并推导了其显式电压可控区域。它阐明了交流侧功率动态和直流母线电压变化如何与电压调节任务解耦，这有助于预测何时出现纠缠。传统的滑模控制通过复杂的滑模面设计、重复校正技术或特殊趋近律来解决电压跟踪误差，而这项工作则指出电力线频率的误差主要源于逆变器非对称特性、延迟效应和计算不准确性。受此启发，本文提出了一种对称补偿结构，避免了增加设计复杂性，并直接减轻了低频电压跟踪误差。此外，控制设计得到了物理和定量解释的支持，有助于参数调整。仿真和实验结果表明，所提出的方法在直流母线电压和交流侧电流变化下，实现了数百微秒量级的更快跟踪响应，同时保持了鲁棒和更准确的跟踪。传统的并网型和经典滑模控制器，它们单独处理这些扰动，无法匹配这种结合了速度和鲁棒性的性能。此外，电压可控性分析得到了明确验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [213] [Vectorized Sparse Second-Order Forward Automatic Differentiation for Optimal Control Direct Methods](https://arxiv.org/abs/2506.11537)
> *用于最优控制直接方法的向量化稀疏二阶前向自动微分*

*Yilin Zou, Fanghua Jiang* | **Main category: eess.SY**

**Keywords:** 最优控制, 自动微分, 稀疏计算, 直接配置法, 向量化

**Comment:** 

> **TL;DR:** 本文提出了一种向量化稀疏二阶前向自动微分框架，用于最优控制的直接配置方法，旨在高效计算大规模非线性规划问题的导数，并已开源实现。

**AI_Comments:** 本文的创新点在于提出了一个专门用于最优控制直接方法的向量化稀疏二阶前向自动微分框架。它通过利用问题固有的稀疏性，并结合标量和向量节点来优化并行计算和内存访问，显著提高了大规模最优控制问题中导数计算的效率。其开源实现也极大地促进了该领域的理论研究和实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 最优控制问题通过离散化转化为大规模非线性规划问题，需要高效计算一阶和二阶导数。为了实现计算效率，这些导数必须以稀疏和向量化的形式计算，并利用问题的固有稀疏结构。

**Method:** 本文提出了一种向量化稀疏二阶前向自动微分框架，专为最优控制中的直接配置方法设计。该方法利用问题的稀疏结构，跨多个网格点高效计算导数。通过在表达式图中结合标量和向量节点，该方法实现了有效的并行化和优化的内存访问模式，同时保持了解决复杂问题的灵活性。

**Result:** 该方法通过应用于一个原型最优控制问题得到了验证。一个用于多阶段最优控制问题的完整实现已作为一个开源软件包提供。

**Conclusion:** 该开源软件包支持理论研究和实际应用，为解决最优控制问题提供了高效的导数计算方法。

> **ai_Abstract:** 本文提出了一种用于最优控制直接方法的向量化稀疏二阶前向自动微分框架。该框架旨在高效计算由最优控制问题离散化产生的大规模非线性规划问题的一阶和二阶导数。通过利用问题的稀疏结构，并结合标量和向量节点实现并行化和优化内存访问，该方法能够高效地跨多个网格点计算导数。其有效性已通过原型问题得到验证，并提供了一个开源实现，支持理论研究和实际应用。

> **摘要翻译:** 直接配置方法是解决最优控制问题中广泛使用的数值技术。连续时间最优控制问题的离散化将其转化为大规模非线性规划问题，这需要高效计算一阶和二阶导数。为了实现计算效率，这些导数必须以稀疏和向量化的形式计算，并利用问题的固有稀疏结构。本文提出了一种向量化稀疏二阶前向自动微分框架，专为最优控制中的直接配置方法设计。该方法利用问题的稀疏结构，跨多个网格点高效计算导数。通过在表达式图中结合标量和向量节点，该方法实现了有效的并行化和优化的内存访问模式，同时保持了解决复杂问题的灵活性。该方法通过应用于一个原型最优控制问题得到了验证。一个用于多阶段最优控制问题的完整实现已作为一个开源软件包提供，支持理论研究和实际应用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [227] [Harvest and Jam: Optimal Self-Sustainable Jamming Attacks against Remote State Estimation](https://arxiv.org/abs/2506.11606)
> *能量收集与干扰：针对远程状态估计的最优自可持续干扰攻击*

*Yuxing Zhong, Yuzhe Li, Daniel E. Quevedo, Ling Shi* | **Main category: eess.SY**

**Keywords:** 干扰攻击, 远程状态估计, 最优功率分配, 自可持续, 马尔可夫决策过程

**Comment:** 

> **TL;DR:** 本文研究了自可持续干扰攻击者针对远程状态估计的最优功率分配问题，旨在最大化估计误差，并提出了基于马尔可夫决策过程的算法来计算最优策略。

**AI_Comments:** 本文的创新点在于将自可持续能量收集与干扰攻击相结合，并利用马尔可夫决策过程为远程状态估计系统设计了最优的干扰策略。其重要性在于为对抗恶意干扰提供理论基础和算法，尤其是在能量受限的场景下。研究了两种不同信道知识的情况，增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究自可持续干扰攻击者如何最优地分配其攻击功率，以最大化融合中心的估计误差，从而有效对抗远程状态估计系统。

**Method:** 将问题建模为马尔可夫决策过程（MDP），并针对攻击者拥有完美信道知识和信道模型未知两种情况，开发了计算最优分配策略的算法。这些算法被证明可以收敛到最优策略。

**Result:** 证明了最优确定性平稳策略的存在性。所提出的算法对于两种情况（完美信道知识和未知信道模型）都能够收敛到最优策略。此外，最优策略表现出某些结构特性，可以加速算法的运行。

**Conclusion:** 本文成功地为自可持续干扰攻击者针对远程状态估计提出了最优功率分配策略和相应的算法，证明了最优策略的存在性及其可计算性，并通过数值例子验证了主要结果。

> **ai_Abstract:** 本文研究了自可持续干扰攻击者对远程状态估计的最优功率分配问题。攻击者的目标是最大化融合中心的估计误差。论文考虑了完美信道知识和未知信道模型两种场景，并将问题公式化为马尔可夫决策过程。研究证明了最优确定性平稳策略的存在性，并开发了收敛到最优策略的算法。此外，还发现最优策略具有可加速算法的结构特性，并通过数值例子进行了验证。

> **摘要翻译:** 本文考虑了干扰攻击者针对远程状态估计的最优功率分配问题。攻击者是自可持续的，可以从环境中收集能量来发起攻击。目标是仔细分配其攻击功率，以最大化融合中心的估计误差。关于攻击者对系统的了解，讨论了两种情况：(i) 完美的信道知识和 (ii) 未知的信道模型。对于这两种情况，我们将问题表述为马尔可夫决策过程（MDP），并证明了最优确定性平稳策略的存在性。此外，对于这两种情况，我们开发了计算分配策略的算法，并证明了所提出的两种情况的算法随着时间的推移收敛到最优策略。此外，最优策略表现出某些结构特性，可以利用这些特性来加速两种算法。给出了数值例子来说明主要结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [242] [5G-Enabled Smart Prosthetic Hand: Connectivity Analysis and Assessment](https://arxiv.org/abs/2506.11729)
> *5G智能假肢手：连接性分析与评估*

*Ozan Karaali, Hossam Farag, Strahinja Dosen, Cedomir Stefanovic* | **Main category: eess.SY**

**Keywords:** 5G, 智能假肢, 边缘计算, 延迟, 连接性

**Comment:** 

> **TL;DR:** 本文展示了一个5G/WiFi边缘连接智能假肢手的概念验证，评估了其控制环路延迟，证明了其在实际场景下的可行性。

**AI_Comments:** 这项工作具有创新性，因为它首次展示了5G赋能假肢系统的可行性。通过利用边缘计算和5G连接，该系统能够实现低延迟的控制，这对于假肢的自然控制至关重要。未来的工作可以探索更复杂的AI算法在边缘端的部署以及更广泛的用户体验评估。

<details>
  <summary>Details</summary>

**Motivation:** 开发并展示一个边缘连接的假肢系统框架，并评估其连接性能。

**Method:** 本文实现了一个概念验证框架，该框架包括一个配备摄像头的仿生手，通过Jetson设备连接到边缘服务器。连接方式可以是直接的5G链路（边缘服务器兼作5G基站）或WiFi链路。系统处理接收到的视频流并反馈环境信息。研究评估了系统控制环路闭合的延迟。

**Result:** 在实际使用场景中，连接和计算的总延迟远低于125毫秒，这符合自然控制范围。

**Conclusion:** 首次分析展示了5G假肢系统的可行性。

> **ai_Abstract:** 本文提出并实现了一个5G/WiFi边缘连接智能假肢手的概念验证框架。该系统通过仿生手、Jetson设备和边缘服务器协同工作，处理视觉信息并提供环境反馈。研究评估了其控制环路的延迟，发现连接和计算总延迟远低于125毫秒，证明了5G赋能假肢系统在实际应用中的可行性。

> **摘要翻译:** 在本文中，我们展示了一个用于开发边缘连接假肢系统的概念验证实现框架。该框架由一个配备摄像头的仿生手组成，该仿生手连接到一个Jetson设备，该设备与边缘服务器建立无线连接，处理接收到的视频流并反馈推断出的环境信息。手与边缘服务器的连接可以通过直接的5G链路获得（其中边缘服务器也充当5G基站），也可以通过WiFi链路获得。我们评估了系统中控制环路闭合的延迟，结果表明，在实际使用场景中，连接和计算延迟的总和远低于125毫秒，这属于自然控制范围。据我们所知，这是首次展示5G假肢系统可行性的分析。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [19] [Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention](https://arxiv.org/abs/2506.11179)
> *Brain2Vec：一种基于CNN-LSTM-Attention的脑电图压力检测深度学习框架*

*Md Mynoddin, Troyee Dev, Rishita Chakma* | **Main category: eess.SP**

**Keywords:** EEG, 压力检测, 深度学习, CNN-LSTM-Attention, Brain2Vec

**Comment:** 

> **TL;DR:** Brain2Vec是一种新的深度学习模型，结合CNN、LSTM和注意力机制，用于从原始脑电图信号中检测压力状态，并在DEAP数据集上表现出良好性能。

**AI_Comments:** 该论文提出了一种新颖的深度学习框架Brain2Vec，通过结合CNN、LSTM和注意力机制，有效处理了EEG信号的复杂性，实现了非侵入性压力检测。其创新性在于融合了多种网络结构，以捕捉EEG信号的空间和时间特征，并通过注意力机制聚焦关键信息。该模型的潜在应用价值在于其可集成到可穿戴设备中，为个性化健康监测提供支持，对于心理健康领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 心理压力已成为影响认知健康和整体福祉的普遍因素，因此需要开发稳健、非侵入性的诊断工具。脑电图（EEG）信号提供了了解神经活动的直接窗口，但其非平稳和高维性质带来了显著的建模挑战。

**Method:** 本文引入了Brain2Vec，一种新的深度学习工具，它利用卷积、循环和注意力机制的混合架构从原始脑电图记录中分类压力状态。该模型首先通过一系列卷积层捕获局部空间依赖性，然后是LSTM层建模序列时间模式，最后通过注意力机制强调信息性时间区域。在DEAP数据集上评估了Brain2Vec，并应用了带通滤波、Z分数归一化和分段作为全面的预处理流程的一部分。

**Result:** 与传统的CNN-LSTM基线相比，我们提出的模型实现了0.68的AUC分数和81.25%的验证准确率。

**Conclusion:** 这些发现证明了Brain2Vec在可穿戴压力监测平台和个性化医疗保健系统中的集成潜力。

> **ai_Abstract:** Brain2Vec是一个创新的深度学习框架，专为基于脑电图（EEG）的压力检测而设计。该框架利用CNN、LSTM和注意力机制的混合架构，能够直接从原始EEG信号中分类压力状态。通过在DEAP数据集上的评估，Brain2Vec在压力检测方面取得了优于传统CNN-LSTM模型的性能，验证准确率达到81.25%，AUC分数为0.68。这项研究强调了Brain2Vec在开发可穿戴压力监测和个性化医疗解决方案方面的巨大潜力。

> **摘要翻译:** 心理压力已成为影响认知健康和整体福祉的普遍因素，因此需要开发稳健、非侵入性的诊断工具。脑电图（EEG）信号提供了了解神经活动的直接窗口，但其非平稳和高维性质带来了显著的建模挑战。本文引入了Brain2Vec，一种新的深度学习工具，它利用卷积、循环和注意力机制的混合架构从原始脑电图记录中分类压力状态。该模型首先通过一系列卷积层捕获局部空间依赖性，然后是LSTM层建模序列时间模式，最后通过注意力机制强调信息性时间区域。我们在DEAP数据集上评估了Brain2Vec，并应用了带通滤波、Z分数归一化和分段作为全面的预处理流程的一部分。与传统的CNN-LSTM基线相比，我们提出的模型实现了0.68的AUC分数和81.25%的验证准确率。这些发现证明了Brain2Vec在可穿戴压力监测平台和个性化医疗保健系统中的集成潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [47] [Design of 3D Beamforming and Deployment Strategies for ISAC-based HAPS Systems](https://arxiv.org/abs/2506.11294)
> *基于ISAC的HAPS系统三维波束赋形与部署策略设计*

*Xue Zhang, Bang Huang, Mohamed-Slim Alouini* | **Main category: eess.SP**

**Keywords:** HAPS, ISAC, 波束赋形, 部署策略, SAR成像

**Comment:** 

> **TL;DR:** 本研究探讨了基于ISAC的高空平台站(HAPS)系统，通过联合优化HAPS部署策略（准静止或动态）和三维波束赋形，旨在最大化通信用户吞吐量的同时满足合成孔径雷达(SAR)成像要求。针对非凸优化问题，提出了高效的算法来获得高质量的次优解。

**AI_Comments:** 该论文的创新点在于将ISAC技术应用于HAPS系统，并首次系统地探讨了HAPS的部署策略（准静止与动态）与三维波束赋形的联合优化问题。其重要性体现在为未来HAPS在通信与感知一体化应用中提供了理论基础和实用方法，尤其是在解决复杂非凸优化问题上提出的算法具有通用性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探索集成感知与通信(ISAC)在高空平台站(HAPS)系统中的应用，特别是在HAPS同时传输通信信号和合成孔径雷达(SAR)成像信号以支持多用户通信和地面目标感知时，如何通过优化部署和波束赋形来提高系统性能。

**Method:** 该研究考虑了两种HAPS部署策略：(i)准静止HAPS，在SAR操作期间固定在优化位置；(ii)动态HAPS，沿圆形路径连续调整飞行轨迹。针对每种策略，通过联合优化HAPS部署（位置或轨迹）和三维(3D)发射波束赋形，在发射功率限制、能耗和飞行动力学等实际约束下，旨在最大化通信用户的加权和速率吞吐量，同时满足SAR成像要求（如波束图增益和信噪比）。针对所提问题的非凸性，提出了利用凸和非凸优化技术的高效算法来获得高质量的次优解。

**Result:** 数值结果表明，所提出的方法相对于基准方案具有有效性和优势。

**Conclusion:** 该论文成功设计了基于ISAC的HAPS系统中的三维波束赋形和部署策略，通过联合优化实现了通信和感知性能的平衡，并提出了有效的算法来解决复杂的非凸优化问题，验证了其在实际应用中的潜力。

> **ai_Abstract:** 本研究聚焦于基于集成感知与通信（ISAC）的高空平台站（HAPS）系统，该系统需同步进行通信和合成孔径雷达（SAR）成像。论文提出了两种HAPS部署策略：准静止和动态，并针对每种策略，在满足SAR成像要求的同时，联合优化HAPS部署和三维波束赋形，以最大化通信吞吐量。鉴于优化问题的非凸性，论文开发了结合凸和非凸优化技术的高效算法来求解。数值结果验证了所提方法的优越性。

> **摘要翻译:** 本文探讨了集成感知与通信（ISAC）赋能的高空平台站（HAPS）系统，其中HAPS同时传输通信信号和合成孔径雷达（SAR）成像信号，以支持多用户通信，同时执行地面目标感知。考虑到SAR成像的操作特性，我们考虑了两种HAPS部署策略：（i）准静止HAPS，在SAR操作期间遵循停走扫描模型，固定在优化位置；（ii）动态HAPS，沿圆形路径连续调整其飞行轨迹。对于每种策略，我们的目标是在确保SAR成像要求（如波束图增益和信噪比）得到满足的同时，最大化通信用户的加权和速率吞吐量。这通过联合优化HAPS部署策略（即其位置或轨迹）以及三维（3D）发射波束赋形来实现，同时考虑发射功率限制、能耗和飞行动力学等实际约束。然而，针对两种部署策略所形成的优化问题本质上是非凸的。为了解决这个问题，我们提出了利用凸和非凸优化技术的高效算法，以获得高质量的次优解。数值结果表明，所提出的方法相对于基准方案具有有效性和优势。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [75] [A Compact Dynamic Omnidirectional Antenna](https://arxiv.org/abs/2506.11351)
> *一种紧凑型动态全向天线*

*Sheng Huang, Jacob R. Randall, Cory Hilton, Jeffrey A. Nanzer* | **Main category: eess.SP**

**Keywords:** 全向天线, 定向调制, 物理层安全, 紧凑型天线, 动态切换

**Comment:** 

> **TL;DR:** 本文提出了一种紧凑型动态全向天线，通过定向调制实现安全的窄平面信息传输，在E平面获得窄信息波束，在H平面保持全向特性。

**AI_Comments:** 该论文的创新点在于将紧凑型全向天线设计与动态定向调制相结合，以实现物理层安全。通过差分功率激励和实时切换进行相位图调制是其核心技术。天线的紧凑尺寸和易于集成性也使其具有实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现安全的窄平面信息传输，并增强平面物理信息安全，本文提出了一种结合定向调制的新型全向天线设计。

**Method:** 该天线通过使用两个紧密间隔的印刷弯曲线单极天线作为单个辐射元件，实现了紧凑尺寸和稳定的全向辐射性能。通过双端口差分功率激励和实时动态切换，实现了仅沿电极化方向的相位图调制，从而在E平面形成方向受限的信息可恢复区域，同时H平面保持高度恒定或静态的全向模式。天线设计并制造在单层Rogers RO4350B材料上，在2.7 GHz下实现了0.36 × 0.5 λ0^2的微型平面尺寸。通过射频（RF）开关系统以10 dB的功率比直接馈电，并评估了在高信噪比（SNR）环境下的16-QAM和256-QAM传输性能。

**Result:** 实验结果表明，对于16-QAM传输，获得了大约34°的窄E平面信息波束（IB）和全向H平面IB；对于256-QAM传输，获得了大约15°的更窄E平面IB。

**Conclusion:** 所提出的天线提供了一种简单而有效的方法，通过紧凑型动态天线系统增强平面物理信息安全。

> **ai_Abstract:** 本文提出了一种新型紧凑型动态全向天线，其通过结合定向调制，旨在实现安全的窄平面信息传输。该设计采用两个紧密间隔的印刷弯曲线单极天线作为单一辐射元件，并利用双端口差分功率激励和实时动态切换，在E平面形成方向受限的信息可恢复区域，同时保持H平面全向特性。天线在Rogers RO4350B上制造，尺寸紧凑。通过16-QAM和256-QAM传输的实验验证显示，在E平面实现了窄信息波束（16-QAM为34°，256-QAM为15°），并在H平面保持全向，证实了该天线系统在增强平面物理信息安全方面的有效性。

> **摘要翻译:** 我们提出了一种结合定向调制的新型全向天线设计，用于安全的窄平面信息传输。所提出的天线通过采用两个紧密间隔的印刷弯曲线单极天线作为单个辐射元件，具有紧凑的尺寸和稳定的全向辐射性能。为了实现窄信息安全区域，所提出的天线通过双端口的差分功率激励和实时动态切换进行馈电。这导致仅沿电极化方向的相位图调制，从而在E平面形成方向受限的信息可恢复区域，同时保持高度恒定或静态的全向H平面模式，从而产生一个360°信息可恢复区域。该动态天线设计并制造在单层Rogers RO4350B上，在2.7 GHz下提供了0.36 × 0.5 λ0^2的微型平面尺寸，并易于集成。为了验证无线通信性能，将制造的天线通过射频（RF）开关系统以10 dB的功率比直接馈电，并在高信噪比（SNR）环境下评估了16-QAM和256-QAM传输。实验结果表明，对于16-QAM传输，获得了大约34°的窄E平面信息波束（IB）和全向H平面IB；对于256-QAM，实现了大约15°的更窄E平面IB。这些结果证实了所提出的天线提供了一种简单而有效的方法，通过紧凑型动态天线系统增强平面物理信息安全。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [102] [Movable-Antenna Array Enhanced Downlink NOMA](https://arxiv.org/abs/2506.11438)
> *可移动天线阵列增强下行NOMA*

*Nianzu Li, Peiran Wu, Lipeng Zhu, Derrick Wing Kwan Ng* | **Main category: eess.SP**

**Keywords:** 可移动天线, 非正交多址, 资源分配, 和速率, 波束成形

**Comment:** Accepted in 2025 IEEE ICC Workshops

> **TL;DR:** 该研究提出了一种可移动天线（MA）阵列增强的下行非正交多址（NOMA）系统，通过联合优化发射波束成形和MA位置来最大化和速率，并通过仿真验证其性能优于固定位置天线（FPA）和正交多址（OMA）系统。

**AI_Comments:** 该论文的创新点在于将新兴的可移动天线技术与非正交多址（NOMA）系统相结合，通过联合优化物理层参数来提升系统性能。解决了高度非凸的优化问题，并通过仿真验证了其有效性，为未来无线通信系统设计提供了新的思路和潜在的性能增益。

<details>
  <summary>Details</summary>

**Motivation:** 可移动天线（MA）因其通过局部天线移动主动重构无线信道的卓越能力，在无线通信领域受到越来越多的关注。本文旨在利用MA的优势，提高下行非正交多址（NOMA）系统的性能。

**Method:** 本文研究了可移动天线（MA）阵列基站服务多用户的下行非正交多址（NOMA）系统的资源分配设计。目标是通过联合优化发射波束成形和基站所有MA的位置来最大化所有用户的和速率，同时受到发射功率预算、有限天线移动区域以及连续干扰消除解码速率条件的约束。该高度非凸问题通过连续凸逼近（SCA）和交替优化方法来获得高质量的次优解。

**Result:** 仿真结果表明，所提出的MA增强下行NOMA系统与固定位置天线（FPA）系统和传统正交多址（OMA）系统相比，能显著提高和速率性能。

**Conclusion:** 可移动天线（MA）阵列能够显著提升下行非正交多址（NOMA）系统的和速率性能，优于传统的固定位置天线和正交多址系统。

> **ai_Abstract:** 本文提出了一种可移动天线（MA）阵列增强的下行非正交多址（NOMA）系统。通过联合优化发射波束成形和MA位置，旨在最大化多用户系统的总和速率，并考虑了功率预算、天线移动范围和连续干扰消除的约束。针对所构建的非凸优化问题，采用了连续凸逼近（SCA）和交替优化方法进行求解。仿真结果表明，与固定位置天线（FPA）系统和传统正交多址（OMA）系统相比，所提出的MA-NOMA系统能够显著提升系统和速率性能。

> **摘要翻译:** 可移动天线（MA）因其通过局部天线移动主动重构无线信道的卓越能力，在无线通信领域受到越来越多的关注。在本文中，我们研究了可移动天线阵列基站服务多个单天线用户的下行非正交多址（NOMA）系统中的资源分配设计。我们的目标是通过联合优化发射波束成形和基站所有MA的位置来最大化所有用户的和速率，同时受到发射功率预算、有限天线移动区域以及连续干扰消除解码速率条件的约束。所构建的问题本质上是高度非凸的，通过连续凸逼近（SCA）和交替优化方法来获得高质量的次优解。仿真结果表明，所提出的MA增强下行NOMA系统与固定位置天线（FPA）系统和传统正交多址（OMA）系统相比，能显著提高和速率性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [129] [Joint Angle and Velocity-Estimation for Target Localization in Bistatic mmWave MIMO Radar in the Presence of Clutter](https://arxiv.org/abs/2506.11497)
> *双基地毫米波MIMO雷达在杂波存在下的目标定位中的联合角度和速度估计*

*Priyanka Maity, Suraj Srivastava, Aditya K. Jagannatham, Lajos Hanzo* | **Main category: eess.SP**

**Keywords:** 稀疏贝叶斯学习, 双基地MIMO雷达, 角度-多普勒域, 目标定位, 杂波抑制

**Comment:** 

> **TL;DR:** 本文提出了一种基于稀疏贝叶斯学习（SBL）的算法，用于在存在杂波的双基地毫米波MIMO雷达系统中进行目标定位，并通过引入超分辨率离网SBL框架，实现了对目标角度和速度参数的精确估计，性能优于现有算法。

**AI_Comments:** 本文的创新点在于将稀疏贝叶斯学习应用于双基地毫米波MIMO雷达系统，并特别考虑了杂波环境。其提出的角度-多普勒域表示和改进的离网SBL框架，有效地解决了实际场景中参数估计的精度问题，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在存在未知杂波的情况下，对双基地毫米波MIMO雷达系统中的目标进行精确参数估计和定位是一个挑战。

**Method:** 本文提出了一种稀疏贝叶斯学习（SBL）辅助的目标定位方法。该方法首先构建了目标加杂波回波模型的角度-多普勒（AD）域表示，然后利用散射场景在AD域中的三维稀疏性，并采用SBL框架估计目标参数（如离去角AoD、到达角AoA和速度）。为处理实际中参数偏离有限分辨率网格的情况，开发了一种基于超分辨率的改进离网SBL框架，用于递归更新参数网格，从而逐步细化估计。此外，还确定了目标参数估计的克拉美-罗下界（CRB）和贝叶斯CRB，以衡量估计性能。

**Result:** 仿真结果证实，与现有算法相比，所提出方法具有卓越的性能，并且其性能能够接近导出的理论界限。

**Conclusion:** 本文提出的基于稀疏贝叶斯学习的联合角度和速度估计算法，在存在杂波的双基地毫米波MIMO雷达系统中，能够实现优异的目标定位和参数估计性能。

> **ai_Abstract:** 本文针对存在未知杂波的双基地毫米波MIMO雷达系统，提出了一种基于稀疏贝叶斯学习（SBL）的目标定位方法。该方法利用角度-多普勒（AD）域的三维稀疏性进行目标参数（AoD、AoA、速度）估计，并引入了超分辨率的离网SBL框架来处理参数偏离网格的问题，从而逐步提高估计精度。仿真结果表明，所提方法性能优于现有算法，并能接近理论界限。

> **摘要翻译:** 本文提出了一种稀疏贝叶斯学习（SBL）辅助的目标定位方法，用于存在未知杂波的双基地毫米波MIMO雷达系统。随后，开发了目标加杂波回波模型的角度-多普勒（AD）域表示，以实现精确的目标参数估计。所提出的算法利用了散射场景在AD域中出现的三维稀疏性，并采用强大的SBL框架来估计目标参数，例如离去角（AoD）、到达角（AoA）和速度。为了处理实际场景中目标实际参数通常偏离其有限分辨率网格的情况，本文开发了一种基于超分辨率的改进离网SBL框架，用于递归更新参数网格，从而逐步细化估计。我们还确定了目标参数估计的克拉美-罗下界（CRB）和贝叶斯CRB，以衡量估计性能。我们的仿真结果证实，与现有算法相比，所提出方法具有卓越的性能，并且其性能能够接近导出的界限。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [153] [MMWiLoc: A Multi-Sensor Dataset and Robust Device-Free Localization Method Using Commercial Off-The-Shelf Millimeter Wave Wi-Fi Devices](https://arxiv.org/abs/2506.11540)
> *MMWiLoc：一个多传感器数据集及使用商用毫米波Wi-Fi设备的鲁棒无设备定位方法*

*Wenbo Ding, Yang Li, Dongsheng Wang, Bin Zhao, Yunrong Zhu, Yibo Zhang, Yumeng Miao* | **Main category: eess.SP**

**Keywords:** 毫米波Wi-Fi, 无设备定位, 多传感器数据集, MMWiLoc, 角度到达(AoA), 压缩感知

**Comment:** 8 pages, 8 figures

> **TL;DR:** 该研究提出了MMWiLoc，一种利用商用毫米波Wi-Fi设备实现厘米级精度的无设备定位方法，并发布了一个多传感器数据集以促进相关研究。

**AI_Comments:** 本论文的创新之处在于首次将商用毫米波Wi-Fi设备应用于无设备定位，并提出了MMWiLoc这一高效的定位算法。同时，发布多传感器数据集对于推动该领域的研究具有重要意义，它为不同感知模式的性能比较提供了基准，有利于研究的可复现性。该方法在精度上达到了厘米级，且计算成本低，展现了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管无设备Wi-Fi感知在实际应用中具有诸多优势，且毫米波Wi-Fi设备已商业化并展现出巨大的潜力（更高带宽和波束成形能力），但目前仍缺乏利用毫米波Wi-Fi进行高精度定位的方法。

**Method:** 本研究主要贡献有二：首先，构建了一个全面的多传感器数据集，同步捕获毫米波Wi-Fi、2.4GHz Wi-Fi和毫米波雷达传感器的人体运动数据，以支持不同感知模式的性能比较和可复现研究。其次，提出了MMWiLoc，一种新颖的定位方法，通过期望最大化进行波束模式校准，并通过多尺度压缩感知进行目标定位。该系统处理波束成形过程中的波束信噪比（beamSNR）信息来确定目标到达角（AoA），然后将不同设备的AoA信息融合以实现定位。

**Result:** MMWiLoc实现了厘米级精度，性能优于2.4GHz Wi-Fi系统，并与高精度雷达系统保持了竞争力。相关数据集和示例处理代码将在论文接收后发布。

**Conclusion:** 本研究成功开发了MMWiLoc，一种利用商用毫米波Wi-Fi设备进行厘米级精度无设备定位的鲁棒方法，并首次提供了一个多传感器数据集，为毫米波Wi-Fi感知和室内定位研究奠定了基础。

> **ai_Abstract:** MMWiLoc是一项关于使用商用毫米波Wi-Fi设备进行无设备定位的研究。该论文贡献了两个主要方面：一是发布了一个综合的多传感器数据集，包含了毫米波Wi-Fi、2.4GHz Wi-Fi和毫米波雷达的数据，以便进行性能比较和可复现研究；二是提出了一种名为MMWiLoc的新型定位方法，该方法结合了期望最大化和多尺度压缩感知技术，利用波束信噪比信息实现厘米级精度的定位。实验结果表明，MMWiLoc的性能优于2.4GHz Wi-Fi系统，并与高精度雷达系统相当。

> **摘要翻译:** 无设备Wi-Fi感知在实际环境中具有诸多优势，因为它无需专用感知设备，并且可以使用当前的低成本Wi-Fi设备完成。随着Wi-Fi标准的发展，工作频率为60GHz、带宽高达4GHz的毫米波Wi-Fi设备已商业化。尽管毫米波Wi-Fi凭借其增加的带宽和波束成形能力，在无设备Wi-Fi感知方面展现出巨大潜力，但仍缺乏使用毫米波Wi-Fi进行定位的方法。在此，我们提出了两大主要贡献：首先，我们提供了一个全面的多传感器数据集，同步捕获来自毫米波Wi-Fi、2.4GHz Wi-Fi和毫米波雷达传感器的人体运动数据。该数据集能够实现不同感知模式之间的直接性能比较，并促进室内定位领域的可复现研究。其次，我们引入了MMWiLoc，一种新颖的定位方法，以低计算成本实现厘米级精度。MMWiLoc包含两个组件：使用期望最大化进行波束模式校准，以及通过多尺度压缩感知进行目标定位。该系统处理波束成形过程中的波束信噪比（beamSNR）信息来确定目标到达角（AoA），然后将不同设备的数据融合以进行定位。我们的大量评估表明，MMWiLoc实现了厘米级精度，优于2.4GHz Wi-Fi系统，同时与高精度雷达系统保持了竞争力。该数据集和示例处理代码将在本文被接受后在https://github.com/wowoyoho/MMWiLoc上发布。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [173] [Energy Efficiency Optimization of Finite Block Length STAR-RIS-aided MU-MIMO Broadcast Channels](https://arxiv.org/abs/2506.11594)
> *有限块长STAR-RIS辅助MU-MIMO广播信道的能效优化*

*Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Robert Schober, Lajos Hanzo* | **Main category: eess.SP**

**Keywords:** STAR-RIS, 能效优化, 有限块长, MU-MIMO, 广播信道

**Comment:** Accepted at IEEE SPAWC 2025

> **TL;DR:** 本文提出了在有限块长下，STAR-RIS辅助的多用户MIMO广播信道的能效设计，研究表明STAR-RIS能显著提升能效，且在更严格的时延和可靠性要求下增益更大。

**AI_Comments:** 该论文创新性地将STAR-RIS技术应用于有限块长MU-MIMO广播信道，并着重于能效优化。其重要性在于揭示了STAR-RIS在满足严格时延和可靠性要求的通信系统中，能够提供显著的能效提升，这对于未来高速低延迟通信系统的设计具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为多用户多输入多输出（MU-MIMO）广播信道（BC）提出节能设计，该信道由同时传输和反射（STAR）可重构智能表面（RIS）在有限块长（FBL）下辅助。

**Method:** 通过最大化总和能效（EE）来设计，并展示STAR-RIS如何显著增强能效。

**Result:** 研究结果表明，采用STAR-RIS的增益随着码字长度的减少和最大可容忍误码率的降低而增加。这意味着在具有更严格时延和可靠性要求的系统中，STAR-RIS的能效更高。

**Conclusion:** STAR-RIS在有限块长MU-MIMO广播信道中能显著提升能效，并且在系统对时延和可靠性要求越严格时，其能效增益越明显。

> **ai_Abstract:** 本文提出并优化了有限块长下STAR-RIS辅助的多用户MIMO广播信道的能效设计。通过最大化总和能效，研究发现STAR-RIS能显著提升系统能效，并且在码字长度更短、误码率要求更低（即时延和可靠性要求更严格）的情况下，STAR-RIS带来的能效增益更为显著。

> **摘要翻译:** 本文针对有限块长（FBL）下由同步传输和反射（STAR）可重构智能表面（RIS）辅助的多用户（MU）多输入多输出（MIMO）广播信道（BC），提出了节能设计。具体而言，我们最大化了总和能效（EE），结果表明STAR-RIS可以显著增强能效。我们的研究结果表明，当码字长度和最大可容忍误码率降低时，采用STAR-RIS的增益会增加，这意味着STAR-RIS在具有更严格时延和可靠性要求的系统中能效更高。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [192] [FieldFormer: Self-supervised Reconstruction of Physical Fields via Tensor Attention Prior](https://arxiv.org/abs/2506.11629)
> *FieldFormer：通过张量注意力先验自监督重建物理场*

*Panqi Chen, Siyuan Li, Lei Cheng, Xiao Fu, Yik-Chung Wu, Sergios Theodoridis* | **Main category: eess.SP**

**Keywords:** 物理场重建, 自监督学习, 张量分解, 注意力机制, FieldFormer

**Comment:** 

> **TL;DR:** FieldFormer 是一种自监督的神经网络方法，利用张量Tucker模型和注意力机制，仅通过现场观测数据就能重建物理场，无需离线训练，且表现优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了FieldFormer，一个无需离线训练的自监督神经先验，有效解决了传统深度学习方法在物理场重建中面临的模型不匹配问题。其结合张量分解和注意力机制的设计，使得模型能够灵活适应不同类型的物理场，并从有限数据中学习，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 从有限且有噪声的现场观测数据重建物理场对于环境感知决策至关重要。现有基于深度神经网络的重建方法存在训练和测试阶段模型不匹配的挑战。

**Method:** FieldFormer 是一种自监督的神经先验，无需离线训练，仅从有限的现场观测数据中学习。它首先使用高多线性秩的张量Tucker模型对物理场进行建模，确保通用逼近性；然后，结合注意力机制学习核心张量下的稀疏模式以减少解空间，从而获得基于Tucker分解的“复杂度自适应”神经表示。

**Result:** 理论分析支持了所提出设计的可恢复性。广泛的实验表明，与最先进的基线方法相比，所提出的方法在各种物理场张量重建上表现出优越性。

**Conclusion:** FieldFormer 提供了一种有效且灵活的自监督方法，能够从有限的现场观测数据中重建物理场，克服了传统深度学习方法的局限性，并实现了卓越的性能。

> **ai_Abstract:** FieldFormer 提出了一种自监督的神经网络先验，用于从有限的现场观测数据重建物理场。它通过结合高多线性秩的张量Tucker模型和注意力机制来学习核心张量的稀疏模式，从而实现了一种复杂度自适应的神经表示。该方法无需离线训练，且实验证明其性能优于现有技术。

> **摘要翻译:** 从现场观测数据中重建物理场张量，例如无线电图和海洋声速场，对于在各种应用中（例如无线通信和水声学）实现环境感知决策至关重要。由于观测数据的有限性和噪声特性，现场数据重建通常具有挑战性，因此需要结合先验信息来辅助重建过程。基于深度神经网络的数据驱动结构约束（例如“深度学习先验”）已显示出有希望的性能。然而，这类技术面临着训练和测试阶段之间模型不匹配等挑战。这项工作引入了FieldFormer，这是一种仅从有限的现场观测数据中学习而无需离线训练的自监督神经先验。具体来说，所提出的框架首先使用高多线性秩的张量Tucker模型对感兴趣的场进行建模，这确保了所有场的通用逼近特性。随后，结合注意力机制来学习核心张量下的稀疏模式，以减少解空间。通过这种方式，获得了基于Tucker分解的“复杂度自适应”神经表示，可以灵活地表示各种类型的场。提供了理论分析来支持所提出设计的可恢复性。此外，使用各种物理场张量进行的广泛实验表明，与最先进的基线方法相比，所提出的方法具有优越性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [207] [Deep Learning-based mmWave MIMO Channel Estimation using sub-6 GHz Channel Information: CNN and UNet Approaches](https://arxiv.org/abs/2506.11714)
> *基于深度学习的毫米波MIMO信道估计：利用6GHz以下信道信息，采用CNN和UNet方法*

*Faruk Pasic, Lukas Eller, Stefan Schwarz, Markus Rupp, Christoph F. Mecklenbräuker* | **Main category: eess.SP**

**Keywords:** 深度学习, 毫米波MIMO, 信道估计, CNN, UNet

**Comment:** Submitted to IEEE Conference on Computer Communications Workshops
  (INFOCOM WKSHPS), 2025

> **TL;DR:** 本文提出两种基于深度学习（CNN和UNet）的方法，利用6GHz以下频段的带外信息来估计毫米波MIMO信道，并在仿真中显示出在频谱效率方面优于现有方法。

**AI_Comments:** 这篇论文的创新点在于提出了利用跨频段（6GHz以下到毫米波）信息进行毫米波信道估计的深度学习方法。通过利用6GHz以下频段的更可靠信息，有效克服了毫米波频段低信噪比带来的挑战，提高了信道估计的准确性和频谱效率，对于未来多频段集成MIMO系统的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 未来的无线MIMO系统将整合6GHz以下和毫米波频段以满足高数据速率需求。然而，毫米波频段由于低信噪比，其MIMO信道估计尤其具有挑战性，因此需要更准确的估计方法。

**Method:** 本文提出两种新颖的基于深度学习的方法来估计毫米波MIMO信道，通过利用6GHz以下频段的带外信息。第一种方法采用卷积神经网络（CNN），第二种方法利用UNet架构。这些方法与仅依赖带内信息的深度学习方法以及其他最先进的带外辅助方法进行了比较。

**Result:** 仿真结果表明，所提出的带外辅助深度学习方法在可实现频谱效率方面优于现有替代方案。

**Conclusion:** 利用6GHz以下频段的带外信息辅助的深度学习方法，能够有效提高毫米波MIMO信道估计的性能，特别是在频谱效率方面，从而克服了毫米波频段低信噪比带来的挑战。

> **ai_Abstract:** 本文提出两种新颖的深度学习方法（CNN和UNet），利用6GHz以下频段的带外信息来解决毫米波MIMO信道估计在低信噪比下的挑战。通过与现有方法（包括仅依赖带内信息的深度学习方法和其他带外辅助方法）的比较，仿真结果显示所提出的方法在可实现频谱效率方面表现更优。

> **摘要翻译:** 未来的无线多输入多输出（MIMO）系统将整合6GHz以下和毫米波（mmWave）频段，以满足日益增长的高数据速率需求。MIMO链路建立通常需要准确的信道估计，这在毫米波频率下由于低信噪比（SNR）而尤其具有挑战性。本文提出了两种新颖的基于深度学习的方法，通过利用6GHz以下频段的带外信息来估计毫米波MIMO信道。第一种方法采用卷积神经网络（CNN），而第二种方法利用UNet架构。我们将这些提出的方法与仅依赖带内信息的深度学习方法以及其他最先进的带外辅助方法进行了比较。仿真结果表明，我们提出的带外辅助深度学习方法在可实现频谱效率方面优于现有替代方案。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [211] [Recursive KalmanNet: Deep Learning-Augmented Kalman Filtering for State Estimation with Consistent Uncertainty Quantification](https://arxiv.org/abs/2506.11639)
> *递归卡尔曼网络：用于状态估计与一致不确定性量化的深度学习增强卡尔曼滤波*

*Hassan Mortada, Cyril Falcon, Yanis Kahil, Mathéo Clavaud, Jean-Philippe Michel* | **Main category: eess.SP**

**Keywords:** 状态估计, 卡尔曼滤波, 深度学习, 循环神经网络, 不确定性量化

**Comment:** 5 pages, 3 figures. Accepted for publication in EUSIPCO 2025
  proceedings

> **TL;DR:** 本文提出Recursive KalmanNet，一个结合卡尔曼滤波和深度学习的RNN，用于在非高斯噪声下进行准确的状态估计和误差协方差量化，性能优于传统方法和现有深度学习方法。

**AI_Comments:** 这篇论文的创新点在于将卡尔曼滤波的理论框架（特别是误差协方差的传播）与深度学习的强大非线性建模能力相结合，形成一个“卡尔曼滤波启发”的循环神经网络。其重要性在于解决了传统卡尔曼滤波在非理想（如非高斯噪声）条件下性能下降的问题，并通过深度学习提升了状态估计的准确性和不确定性量化的一致性。

<details>
  <summary>Details</summary>

**Motivation:** 在具有噪声测量的随机动态系统中进行状态估计是一个挑战。传统卡尔曼滤波对线性系统和高斯白噪声最优，但实际情况常偏离这些假设，因此需要数据驱动的滤波技术。

**Method:** 本文引入Recursive KalmanNet，一个受卡尔曼滤波启发的循环神经网络。该方法使用递归约瑟夫公式传播误差协方差，并优化高斯负对数似然。

**Result:** 在非高斯测量白噪声的实验中，Recursive KalmanNet的性能优于传统的卡尔曼滤波和现有最先进的基于深度学习的估计器。

**Conclusion:** Recursive KalmanNet能够有效处理非高斯噪声下的状态估计问题，并提供一致的误差协方差量化，显著优于现有方法。

> **ai_Abstract:** 本文提出Recursive KalmanNet，一种结合卡尔曼滤波和循环神经网络的新型深度学习模型，用于解决随机动态系统在非高斯噪声下的状态估计问题。该模型通过递归约瑟夫公式传播误差协方差并优化高斯负对数似然，实现了准确的状态估计和一致的误差不确定性量化。实验证明，Recursive KalmanNet在非高斯测量白噪声环境下，性能超越了传统卡尔曼滤波和现有先进的深度学习估计器。

> **摘要翻译:** 标题：递归卡尔曼网络：用于状态估计与一致不确定性量化的深度学习增强卡尔曼滤波

摘要：
在具有噪声测量的随机动态系统中进行状态估计是一个挑战。虽然卡尔曼滤波对于具有独立高斯白噪声的线性系统是最佳的，但现实世界条件通常偏离这些假设，这促使了数据驱动滤波技术的兴起。本文介绍了递归卡尔曼网络（Recursive KalmanNet），一个受卡尔曼滤波启发的循环神经网络，旨在实现准确的状态估计和一致的误差协方差量化。我们的方法使用递归约瑟夫公式传播误差协方差并优化高斯负对数似然。在非高斯测量白噪声的实验中，我们的模型表现优于传统的卡尔曼滤波和现有的最先进的基于深度学习的估计器。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [240] [Semantic Communications in 6G: Coexistence, Multiple Access, and Satellite Networks](https://arxiv.org/abs/2506.11779)
> *6G中的语义通信：共存、多址接入和卫星网络*

*Ishtiaque Ahmed, Yingzhuo Sun, Jingwen Fu, Alper Kose, Leila Musavian, Ming Xiao, Berna Ozbek* | **Main category: eess.SP**

**Keywords:** 语义通信, 6G, 共存, 多址接入, 卫星网络

**Comment:** 

> **TL;DR:** 该论文探讨了在异构网络中将语义通信（SemCom）与传统比特通信（BitCom）集成，分析了多址接入技术（包括NOMA）以支持两者的共存，并讨论了多模态SemCom在卫星网络中的应用，以应对带宽限制和恶劣信道条件，最后指出了未来发展方向。

**AI_Comments:** 该论文旨在解决下一代网络中通信效率和资源分配的关键问题，通过引入语义通信的概念，并在实际场景（如卫星网络）中探讨其应用，具有重要的理论和实践意义。其创新点在于关注SemCom与BitCom的共存以及多模态和多址接入技术的结合，为6G及未来网络的发展提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 随着无线用户数量的指数级增长和带宽限制，下一代网络需要创新的通信范式。语义通信（SemCom）作为一种通过传输提取的含义而非原始比特来提高频谱效率和实现智能资源分配的有前景的解决方案应运而生。

**Method:** 该论文探讨了语义通信（SemCom）与传统比特通信（BitCom）在异构网络中的集成，分析了包括非正交多址接入（NOMA）在内的多址接入技术以支持SemCom和BitCom用户的共存。此外，还研究了处理不同数据类型的多模态SemCom框架，并讨论了它们在卫星网络中的应用。

**Result:** 论文指出了SemCom与BitCom集成在异构网络中的关键挑战和机遇。通过分析多址接入技术和多模态SemCom框架，展示了语义技术在缓解带宽限制和恶劣信道条件方面的潜力，特别是在卫星网络中。

**Conclusion:** 该论文识别了在6G及未来部署语义感知系统的未来方向，强调了语义通信在提升下一代网络效率和韧性方面的关键作用。

> **ai_Abstract:** 本论文探讨了在无线用户激增和带宽受限背景下，将语义通信（SemCom）与传统比特通信（BitCom）集成到6G异构网络中的重要性。文章分析了包括NOMA在内的多址接入技术，以实现两者的共存，并研究了多模态SemCom框架及其在卫星网络中的应用，以应对带宽挑战。最终，论文提出了未来语义感知系统的发展方向。

> **摘要翻译:** 随着无线用户数量的指数级增长和带宽限制，下一代网络需要创新的通信范式。语义通信（SemCom）作为一种通过传输提取的含义而非原始比特来增强频谱效率和实现智能资源分配的有前景的解决方案应运而生。本文探讨了在异构网络中将SemCom与传统基于比特的通信（BitCom）集成，强调了关键挑战和机遇。我们分析了包括非正交多址接入（NOMA）在内的多址接入技术，以支持SemCom和BitCom用户的共存。此外，我们研究了用于处理不同数据类型的多模态SemCom框架，并讨论了它们在卫星网络中的应用，其中语义技术可以减轻带宽限制和恶劣的信道条件。最后，我们确定了在6G及未来部署语义感知系统的未来方向。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [257] [Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection](https://arxiv.org/abs/2506.11815)
> *基于扩散的心电图噪声量化与异常检测*

*Tae-Seong Han, Jae-Wook Heo, Hakseung Kim, Cheol-Hui Lee, Hyub Huh, Eue-Keun Choi, Dong-Joo Kim* | **Main category: eess.SP**

**Keywords:** 心电图噪声量化, 扩散模型, 异常检测, Wasserstein-1距离, 信号处理

**Comment:** This manuscript contains 17 pages, 10 figures, and 3 tables

> **TL;DR:** 本研究提出了一种基于扩散模型的框架，通过重建异常检测来量化心电图噪声，解决了传统方法的局限性，并实现了高精度和泛化能力。

**AI_Comments:** 这项研究通过引入扩散模型和Wasserstein-1距离进行噪声量化，为心电图信号处理提供了一个新颖且有效的方法，尤其在解决标注不一致和泛化性方面具有创新性。其仅需少量逆向扩散步骤即可实现鲁棒量化，显示出较高的效率和实用价值，对于提高临床诊断准确性和实时监测能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 心电图 (ECG) 信号常受噪声干扰，影响临床诊断；传统方法存在标注不一致和泛化能力有限的问题。

**Method:** 本文提出一个基于扩散模型的框架，通过重建异常检测来量化心电图噪声。为解决标注不一致问题，引入了使用Wasserstein-1 ($W_1$) 距离的分布评估方法，比较干净和噪声心电图的重建误差分布。该模型仅使用三个逆向扩散步骤。

**Result:** 模型在基准测试中实现了1.308的宏观平均 $W_1$ 分数，优于次优方法48%以上。外部验证显示出强大的泛化能力，支持排除低质量片段以提高诊断准确性并实现对信号降级的及时临床响应。

**Conclusion:** 所提出的方法增强了临床决策、诊断准确性和实时心电图监测能力，支持未来在临床和可穿戴心电图应用中的发展。

> **ai_Abstract:** 本文提出了一种新颖的基于扩散模型的框架，用于通过重建异常检测来量化心电图（ECG）信号中的噪声。该方法通过引入Wasserstein-1距离来评估重建误差分布，有效解决了传统方法的标注不一致和泛化能力差的问题。实验结果表明，该模型仅用三个逆向扩散步骤就实现了高精度的噪声量化，并在基准测试中表现出色，显著优于现有方法。其强大的泛化能力有助于提高诊断准确性并支持实时心电图监测。

> **摘要翻译:** 心电图 (ECG) 信号常被噪声降级，这使得临床和可穿戴设备中的诊断复杂化。本研究提出了一种基于扩散的框架，通过基于重建的异常检测来量化心电图噪声，解决了传统方法中存在的标注不一致和泛化能力有限的问题。我们引入了一种使用 Wasserstein-1 距离 ($W_1$) 的分布评估方法，比较干净和噪声心电图之间的重建误差分布，以减轻不一致的标注。我们的最终模型仅使用三个逆向扩散步骤就实现了鲁棒的噪声量化。该模型在基准测试中取得了1.308的宏观平均 $W_1$ 分数，优于次优方法48%以上。外部验证显示出强大的泛化能力，支持排除低质量片段以提高诊断准确性并实现对信号降级的及时临床响应。所提出的方法增强了临床决策、诊断准确性和实时心电图监测能力，支持未来在临床和可穿戴心电图应用中的进步。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [272] [Interference in Spectrum-Sharing Integrated Terrestrial and Satellite Networks: Modeling, Approximation, and Robust Transmit Beamforming](https://arxiv.org/abs/2506.11851)
> *频谱共享天地一体化网络中的干扰：建模、近似与鲁棒发射波束成形*

*Wenjing Cao, Yafei Wang, Tianxiang Ji, Tianyang Cao, Wenjin Wang, Symeon Chatzinotas, Björn Ottersten* | **Main category: eess.SP**

**Keywords:** 频谱共享，天地一体化网络，鲁棒波束成形，干扰抑制，统计CSI

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文研究了基于统计CSI的卫星到用户终端的鲁棒发射波束成形，旨在减轻频谱共享天地一体化网络中的卫星到地面干扰，并提出了两种优化方案和一种干扰评估近似方法。

**AI_Comments:** 本文的创新点在于提出了基于统计CSI的鲁棒发射波束成形，以有效减轻天地一体化网络中的干扰。通过考虑两种不同的优化准则，提供了性能与计算复杂度之间的权衡。此外，提出的基站位置辅助近似方法有效解决了复杂积分计算和对用户分布信息依赖的问题，增强了方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在减轻频谱共享天地一体化网络中卫星到地面系统的干扰。

**Method:** 本文首先利用地面用户终端的分布信息，建立了一个没有共享CSI的卫星到地面系统干扰模型。在此基础上，在干扰门限和功率预算下开发了鲁棒发射波束成形方案，并考虑了卫星加权和速率最大化和均方误差最小化两种优化准则。为避免复杂的积分计算和对用户分布信息的依赖，提出了一种地面基站位置辅助的近似方法。

**Result:** 数值仿真验证了所提出方案的有效性。卫星加权和速率最大化方案通过迭代优化框架实现了优越的可达速率性能，而均方误差最小化方案提供了低复杂度的闭式解，但速率有所降低，并通过二分法满足了干扰约束。文章还分析了近似误差。

**Conclusion:** 本文提出的鲁棒发射波束成形方案和干扰近似方法在频谱共享天地一体化网络中有效减轻了卫星到地面系统的干扰，并提供了性能与复杂度之间的权衡。

> **ai_Abstract:** 本文针对频谱共享天地一体化网络中的卫星到地面干扰问题，提出了一种基于统计CSI的鲁棒发射波束成形设计。研究建立了卫星到地面干扰模型，并开发了在干扰门限和功率预算下的两种优化方案：加权和速率最大化（高性能迭代解）和均方误差最小化（低复杂度闭式解）。为简化干扰评估，还引入了地面基站位置辅助的近似方法。数值仿真验证了所提方案的有效性。

> **摘要翻译:** 本文研究了基于统计信道状态信息（CSI）的卫星到用户终端（UTs）的鲁棒发射（TX）波束成形。所提出的设计专门旨在减轻频谱共享天地一体化网络中的卫星到地面干扰。通过利用地面用户终端的分布信息，我们首先建立了一个没有共享CSI的卫星到地面系统的干扰模型。在此基础上，在干扰门限和功率预算下开发了鲁棒TX波束成形方案。考虑了两种优化准则：卫星加权和速率最大化和均方误差最小化。前者通过迭代优化框架实现了优越的可达速率性能，而后者以降低速率为代价实现了低复杂度的闭式解，并通过二分法满足了干扰约束。为了避免复杂的积分计算以及在系统间干扰评估中对用户分布信息的依赖，我们提出了一种地面基站位置辅助的近似方法，并随后分析了近似误差。数值仿真验证了我们所提出方案的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [284] [DMRS-Based Uplink Channel Estimation for MU-MIMO Systems with Location-Specific SCSI Acquisition](https://arxiv.org/abs/2506.11899)
> *基于DMRS的MU-MIMO系统上行信道估计与位置特定SCSI采集*

*Jiawei Zhuang, Hongwei Hou, Minjie Tang, Wenjin Wang, Shi Jin, Vincent K. N. Lau* | **Main category: eess.SP**

**Keywords:** MU-MIMO, 信道估计, DMRS, SCSI, 张量分解

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出了一种基于位置特定统计信道状态信息（SCSI）的贝叶斯信道估计算法（SA-BCE及其窗式版本SA-WBCE），用于MU-MIMO系统上行信道估计，并通过张量分解构建SCSI数据库，显著提升了性能并降低了复杂度。

**AI_Comments:** 本文的创新点在于提出了SCSI辅助的贝叶斯信道估计算法，并通过窗化处理有效降低了计算复杂度。更重要的是，它引入了一种基于网格的空间一致性SCSI数据库构建方法，利用张量分解和Vandermonde结构解决了实时SCSI采集的难题，这对于实际系统部署具有重要意义。该研究在提升MU-MIMO系统信道估计性能和效率方面取得了显著进展。

<details>
  <summary>Details</summary>

**Motivation:** 随着多用户多输入多输出（MU-MIMO）系统用户数量的增长，需要高效地多路复用解调参考信号（DMRS）以确保正交性并最小化导频干扰。同时，传统的信道估计算法可能存在计算复杂度高或性能不足的问题。

**Method:** 本文提出了一种SCSI辅助的贝叶斯信道估计算法（SA-BCE），该算法基于最小均方误差准则，旨在抑制导频干扰和噪声。为降低SA-BCE的立方计算复杂度，作者将其扩展为窗式版本（SA-WBCE），通过结合天线-频率域窗和波束-时延域处理来利用渐近稀疏性并减轻能量泄漏。为了避免频繁的实时SCSI采集，论文基于空间一致性原理构建了一个基于网格的位置特定SCSI数据库，并利用每个网格内的上行接收信号来提取SCSI。SCSI采集问题被表述为张量分解问题，其中因子矩阵由多径功率、时延和角度参数化，通过利用因子矩阵的Vandermonde结构显著降低了计算复杂度。

**Result:** 仿真结果表明，所提出的位置特定SCSI数据库构建方法实现了高精度。SA-BCE和SA-WBCE在MU-MIMO系统中显著优于现有最先进的基准算法。

**Conclusion:** 本文成功提出了高效且高精度的上行DMRS-based信道估计算法（SA-BCE和SA-WBCE），并通过创新的位置特定SCSI数据库构建方法，有效解决了MU-MIMO系统中导频干扰和实时SCSI采集的挑战，显著提升了系统性能和效率。

> **ai_Abstract:** 本文针对MU-MIMO系统上行DMRS信道估计中导频干扰和计算复杂度问题，提出了两种SCSI辅助的贝叶斯信道估计算法：SA-BCE和SA-WBCE。SA-BCE基于MMSE准则抑制干扰，而SA-WBCE通过窗化处理降低了计算复杂度。为避免实时SCSI采集，文章还提出了一种基于网格的空间一致性SCSI数据库构建方法，将SCSI采集问题建模为张量分解，并利用其Vandermonde结构降低复杂度。仿真结果验证了所提SCSI数据库的高精度以及SA-BCE和SA-WBCE优于现有技术的性能。

> **摘要翻译:** 随着多用户多输入多输出（MU-MIMO）系统用户数量的增长，解调参考信号（DMRS）通过正交覆盖码（OCC）在码域中高效复用，以确保正交性并最小化导频干扰。本文研究了在3GPP Release 18中标准化的Type II OCC模式下，利用位置特定统计信道状态信息（SCSI）来增强性能的MU-MIMO系统上行DMRS信道估计。具体来说，我们提出了一种基于最小均方误差准则的SCSI辅助贝叶斯信道估计算法（SA-BCE），以抑制导频干扰和噪声，尽管其由于矩阵求逆而导致立方计算复杂度。为了在保持性能的同时降低这种复杂度，我们将该方案扩展到窗式版本（SA-WBCE），它结合了天线-频率域窗和波束-时延域处理，以利用渐近稀疏性并减轻实际系统中的能量泄漏。为了避免频繁的实时SCSI采集，我们基于空间一致性原理构建了一个基于网格的位置特定SCSI数据库，随后利用每个网格内的上行接收信号来提取SCSI。在无线信道多线性结构的帮助下，我们将每个网格内的SCSI采集问题表述为张量分解问题，其中因子矩阵由多径功率、时延和角度参数化。通过利用因子矩阵的Vandermonde结构，可以显著降低SCSI采集的计算复杂度。仿真结果表明，所提出的位置特定SCSI数据库构建方法实现了高精度，而SA-BCE和SA-WBCE在MU-MIMO系统中显著优于现有基准。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [20] [Grids Often Outperform Implicit Neural Representations](https://arxiv.org/abs/2506.11139)
> *网格通常优于隐式神经表示*

*Namhoon Kim, Sara Fridovich-Keil* | **Main category: eess.IV**

**Keywords:** 隐式神经表示, 网格, 性能比较, 数据表示, 信号处理

**Comment:** 

> **TL;DR:** 研究表明，在大多数任务和信号上，简单的正则化网格比隐式神经表示（INRs）训练更快且质量更高，INRs仅在拟合具有低维结构的信号时表现出优势。

**AI_Comments:** 这项研究对于理解隐式神经表示（INRs）的实际应用价值具有重要意义。它挑战了INRs在所有场景下都优越的普遍看法，明确指出在许多常见任务中，传统的网格表示更具优势。这为研究人员和实践者在选择数据表示方法时提供了宝贵的指导，避免了对INRs的盲目追捧，并强调了INRs的特定适用领域。

<details>
  <summary>Details</summary>

**Motivation:** 隐式神经表示（INRs）最近表现出色，但其基本容量、隐式偏置和缩放行为仍知之甚少。

**Method:** 作者通过对各种2D和3D真实及合成信号（具有不同有效带宽）以及过拟合和泛化任务（包括断层扫描、超分辨率和去噪）进行性能调查。他们根据模型大小、信号类型和带宽对性能进行分层分析。

**Result:** 研究发现，对于大多数任务和信号，一个简单的正则化网格（带插值）比具有相同参数数量的任何隐式神经表示训练更快，并达到更高质量。同时，也发现隐式神经表示在有限设置下（即拟合具有底层低维结构，如形状轮廓的信号）优于网格。

**Conclusion:** 对于大多数任务，正则化网格在训练速度和质量上优于隐式神经表示。隐式神经表示在处理具有低维结构的信号时表现出优势，这指导了其未来的应用方向。

> **ai_Abstract:** 本研究旨在探究隐式神经表示（INRs）的性能极限及其与传统网格表示的对比。通过在多样化的2D和3D信号及多项任务上进行广泛实验，研究发现，在大多数情况下，具有插值的简单正则化网格在训练速度和质量上均优于参数量相同的INRs。然而，INRs在处理具有低维结构（如形状轮廓）的信号时表现出独特优势，这为INRs的未来应用提供了指导。

> **摘要翻译:** 隐式神经表示（INRs）最近表现出令人印象深刻的结果，但其基本容量、隐式偏置和缩放行为仍知之甚少。我们调查了各种INRs在2D和3D真实及合成信号（具有不同有效带宽）以及过拟合和泛化任务（包括断层扫描、超分辨率和去噪）中的性能。通过根据模型大小以及信号类型和带宽对性能进行分层，我们的结果揭示了不同INRs和网格表示如何分配其容量。我们发现，对于大多数任务和信号，一个简单的正则化网格（带插值）比具有相同参数数量的任何INRs训练更快，并达到更高质量。我们还发现INRs在有限设置下（即拟合具有底层低维结构，如形状轮廓的信号）优于网格，这指导了未来INRs在最有利应用中的使用。我们分析中使用的代码和合成信号可在https://github.com/voilalab/INR-benchmark 获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [48] [ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator](https://arxiv.org/abs/2506.11150)
> *ADAgent：用于阿尔茨海默病分析的LLM代理，带协作协调器*

*Wenlong Hou, Gangqian Yang, Ye Du, Yeung Lau, Lihao Liu, Junjun He, Ling Long, Shujun Wang* | **Main category: eess.IV**

**Keywords:** 阿尔茨海默病, LLM代理, 多模态, 诊断, 预后

**Comment:** 

> **TL;DR:** ADAgent是一个基于LLM的AI代理，用于阿尔茨海默病的多模态诊断和预后分析，它通过整合推理引擎、专业医疗工具和协作协调器，显著优于现有SOTA方法。

**AI_Comments:** ADAgent的创新之处在于它是首个将LLM应用于阿尔茨海默病分析的专用AI代理，并能处理多模态数据和整合多种医疗工具。其重要性在于提升了AD诊断和预后的准确性和全面性，更接近医疗专家的多方面诊断方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的阿尔茨海默病诊断方法大多依赖单一模态数据，或多模态方法受限于特定任务和输入组合，难以处理多样化的AD相关任务、多模态或缺失输入，且无法有效整合多种高级方法以提升性能。因此，需要一个能够解决这些问题的系统。

**Method:** 本文提出了ADAgent，首个专门用于AD分析的AI代理，它基于大型语言模型（LLM）构建，用于处理用户查询和支持决策。ADAgent集成了推理引擎、专业医疗工具和协作结果协调器，以促进AD中的多模态诊断和预后任务。

**Result:** ADAgent在多模态诊断中准确率提高了2.7%，在多模态预后中提高了0.7%，并在MRI和PET诊断任务中也有所提升，总体表现优于SOTA方法。

**Conclusion:** ADAgent作为首个基于LLM的专业AI代理，通过整合多模态数据和先进工具，显著提高了阿尔茨海默病的诊断和预后准确性，证明了其在AD分析领域的优越性。

> **ai_Abstract:** ADAgent是首个基于大型语言模型（LLM）的阿尔茨海默病（AD）专业AI代理，旨在解决现有诊断方法在处理多模态数据和多样化任务上的局限性。它整合了推理引擎、专业医疗工具和协作结果协调器，能够处理多模态或缺失输入，并支持AD的诊断和预后。实验结果表明，ADAgent在多模态诊断、预后以及MRI和PET诊断任务上均显著优于现有SOTA方法，提高了诊断准确性。

> **摘要翻译:** 阿尔茨海默病（AD）是一种进行性和不可逆的神经退行性疾病。早期和精确诊断AD对于及时干预和治疗计划以缓解进行性神经退行性病变至关重要。然而，大多数现有方法依赖单一模态数据，这与医学专家使用的多方面方法形成对比。尽管一些深度学习方法处理多模态数据，但它们仅限于特定任务和少量输入模态，无法处理任意组合。这突显了需要一个能够处理多样化AD相关任务、处理多模态或缺失输入，并整合多种高级方法以提高性能的系统。在本文中，我们提出了ADAgent，第一个专门用于AD分析的AI代理，它建立在大型语言模型（LLM）之上，以解决用户查询并支持决策。ADAgent集成了推理引擎、专业医疗工具和协作结果协调器，以促进AD中的多模态诊断和预后任务。广泛的实验表明，ADAgent优于SOTA方法，在准确性方面取得了显著改进，包括多模态诊断提高了2.7%，多模态预后提高了0.7%，以及在MRI和PET诊断任务中均有所增强。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [76] [Vector Representations of Vessel Trees](https://arxiv.org/abs/2506.11163)
> *血管树的向量表示*

*James Batten, Michiel Schaap, Matthew Sinclair, Ying Bai, Ben Glocker* | **Main category: eess.IV**

**Keywords:** 血管树, 向量表示, Transformer, 自编码器, 拓扑结构

**Comment:** 

> **TL;DR:** 提出了一种名为VeTTA的两阶段Transformer自编码器框架，用于学习3D血管网络的向量表示，显著降低GPU内存并实现高保真重建和拓扑保留。

**AI_Comments:** 该论文提出了一种新颖的两阶段Transformer自编码器方法来处理复杂的树状几何数据，特别是3D血管网络。其创新之处在于将几何细节和拓扑结构分别编码，并有效结合，同时显著解决了3D卷积模型在处理此类数据时面临的GPU内存消耗大的问题，这对于大规模医学图像分析具有重要意义。该框架在重建精度和拓扑一致性方面的表现也令人印象深刻，为医学成像领域的解剖结构建模提供了有前景的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理3D血管网络等树状几何数据时可能存在局限性，特别是GPU内存消耗大，限制了大规模训练。因此需要一种新的框架来学习这些数据的向量表示，并解决内存效率问题。

**Method:** 提出了一种名为VeTTA的框架，该框架包含两个顺序训练的基于Transformer的自编码器。第一阶段，血管自编码器从每个血管段的采样点学习嵌入，以捕获连续的几何细节。第二阶段，血管树自编码器利用第一阶段的段级嵌入，将血管网络的拓扑结构编码为单个向量表示。通过递归解码过程确保重建的拓扑是有效的树结构。

**Result:** 与3D卷积模型相比，该方法显著降低了GPU内存需求，从而便于大规模训练。在2D合成树数据集和3D冠状动脉数据集上的实验结果表明，该方法具有卓越的重建保真度、准确的拓扑保留能力以及在潜在空间中实现逼真的插值。

**Conclusion:** 提出的可扩展框架VeTTA为医学成像中的解剖树结构提供了精确、灵活且拓扑一致的建模能力。

> **ai_Abstract:** 本文介绍了一个名为VeTTA的创新框架，用于学习3D血管网络等树状几何数据的向量表示。该框架采用两阶段Transformer自编码器：首先，血管自编码器学习单个血管段的几何嵌入；其次，血管树自编码器将整个网络的拓扑编码为单一向量。通过递归解码确保结构有效性。与传统方法相比，VeTTA显著降低了GPU内存需求，支持大规模训练，并在重建保真度、拓扑保留和潜在空间插值方面表现出色，为医学成像中的解剖树结构建模提供了精确、灵活且拓扑一致的解决方案。

> **摘要翻译:** 我们引入了一个新颖的框架，用于学习树状几何数据（特别是3D血管网络）的向量表示。我们的方法采用了两个顺序训练的基于Transformer的自编码器。在第一阶段，血管自编码器通过从每条曲线上的采样点学习嵌入来捕获单个血管段的连续几何细节。在第二阶段，血管树自编码器利用第一个模型的段级嵌入，将血管网络的拓扑结构编码为单个向量表示。一个递归解码过程确保重建的拓扑是有效的树结构。与3D卷积模型相比，这种提出的方法大大降低了GPU内存需求，从而便于大规模训练。在2D合成树数据集和3D冠状动脉数据集上的实验结果表明，该方法具有卓越的重建保真度、准确的拓扑保留能力以及在潜在空间中实现逼真的插值。我们可扩展的框架，命名为VeTTA，为医学成像中的解剖树结构提供了精确、灵活且拓扑一致的建模。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [103] [DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning](https://arxiv.org/abs/2506.11183)
> *DiffPR：基于扩散模型的频率解耦学习相位重建*

*Yi Zhang* | **Main category: eess.IV**

**Keywords:** 相位重建, 扩散模型, 频率解耦学习, 定量相位成像, 过平滑

**Comment:** 

> **TL;DR:** DiffPR提出一种两阶段频率解耦框架，利用扩散模型克服QPI中深度学习导致的过平滑问题，优于传统U-Net。

**AI_Comments:** 本文的创新点在于提出了一个新颖的两阶段频率解耦学习框架DiffPR，巧妙地将低频和高频信息的处理分离开来。通过移除U-Net中导致频谱偏差的高层跳跃连接来处理低频内容，并利用扩散模型专门恢复高频细节，有效地解决了定量相位成像中的过平滑问题。这种将不同频率信息处理解耦的思路，以及引入扩散模型进行细节合成，为相位重建领域提供了新的视角和有效的解决方案，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 在离轴定量相位成像（QPI）中，深度学习应用存在过平滑问题，端到端U-Net偏爱低频内容，导致精细诊断细节不足。该问题源于频谱偏差，且高层跳跃连接会强化此偏差。

**Method:** 提出DiffPR，一个两阶段频率解耦框架。第一阶段：一个取消高频跳跃连接的非对称U-Net从干涉图预测四分之一尺寸的相位图，捕获可靠的低频结构并避免频谱偏差。第二阶段：通过无条件扩散模型迭代恢复缺失的高频残差，该模型对第一阶段上采样的预测图（轻微添加高斯噪声）进行反向去噪细化。

**Result:** 在四个QPI数据集（B-Cell、WBC、HeLa、3T3）上的实验表明，DiffPR优于强大的U-Net基线，PSNR提高高达1.1 dB，MAE降低11%，同时生成更清晰的膜脊和斑点图案。

**Conclusion:** 取消高层跳跃连接并将细节合成委托给扩散先验，是解决限制传统相位重建网络频谱偏差的有效方法。

> **ai_Abstract:** 本论文针对离轴定量相位成像（QPI）中深度学习导致的过平滑问题，提出了一个名为DiffPR的两阶段频率解耦框架。研究发现过平滑源于U-Net的频谱偏差及高层跳跃连接的强化作用。DiffPR的第一阶段使用一个移除了高频跳跃连接的U-Net预测低分辨率相位图，以避免频谱偏差。第二阶段则利用无条件扩散模型通过反向去噪迭代恢复缺失的高频细节。实验结果显示，DiffPR在多个QPI数据集上显著优于传统U-Net基线，提高了PSNR并降低了MAE，同时生成了更清晰的图像细节，证明了其在解决相位重建网络频谱偏差方面的有效性。

> **摘要翻译:** 在离轴定量相位成像（QPI）中应用深度学习时，过平滑仍然是一个持续存在的问题。端到端U-Net偏爱低频内容，并且对精细的诊断细节表示不足。我们将这个问题追溯到频谱偏差，并表明高层跳跃连接将高频特征直接馈送到解码器中，从而强化了这种偏差。因此，移除那些最深的跳跃连接，仅在低分辨率下监督网络，显著提高了泛化能力和保真度。基于这一见解，我们引入了DiffPR，一个两阶段频率解耦框架。第一阶段：一个取消了高频跳跃连接的非对称U-Net从干涉图预测四分之一尺寸的相位图，捕获可靠的低频结构，同时避免频谱偏差。第二阶段：通过无条件扩散模型迭代恢复缺失的高频残差，该模型对上采样的预测图（轻微添加高斯噪声）进行细化，通过反向去噪。在四个QPI数据集（B-Cell、WBC、HeLa、3T3）上的实验表明，DiffPR优于强大的U-Net基线，PSNR提高高达1.1 dB，MAE降低11%，同时生成更清晰的膜脊和斑点图案。结果表明，取消高层跳跃连接并将细节合成委托给扩散先验，是解决限制传统相位重建网络频谱偏差的有效方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [130] [Joint Denoising of Cryo-EM Projection Images using Polar Transformers](https://arxiv.org/abs/2506.11283)
> *使用极性Transformer联合去噪冷冻电镜投影图像*

*Joakim Andén, Justus Sagemüller* | **Main category: eess.IV**

**Keywords:** Cryo-EM, Denoising, Transformers, Class Averaging

**Comment:** 

> **TL;DR:** 提出了一种基于Transformer的神经网络架构，用于同时聚类、对齐和去噪冷冻电镜图像，在合成数据上显示出显著的去噪性能提升。

**AI_Comments:** 该论文的创新之处在于将Transformer架构应用于冷冻电镜图像的联合去噪，并巧妙地将传统的类平均方法的聚类、对齐和去噪步骤整合到一个端到端的神经网络中。这对于处理高噪声冷冻电镜数据，提高图像质量具有重要意义。在信噪比极低的情况下仍能大幅降低误差，表明其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度神经网络在冷冻电镜（cryo-EM）投影图像等高噪声环境下效果有限。传统去噪方法（如类平均）利用数据冗余性，但需要更有效的方法来整合这些步骤，以应对高噪声挑战。

**Method:** 提出了一种基于Transformer的神经网络架构，该架构通过同时进行冷冻电镜图像的聚类、对齐和去噪，扩展了传统的类平均方法。

**Result:** 在合成数据上的结果显示，该架构实现了准确的去噪性能，在信噪比（SNR）为0.03时，相对于单图像深度神经网络，相对均方误差（MSE）降低了45%。

**Conclusion:** 该基于Transformer的神经网络架构能够有效地对冷冻电镜投影图像进行联合去噪，在高噪声条件下表现出显著的性能提升。

> **ai_Abstract:** 本研究提出一种基于Transformer的神经网络架构，旨在解决冷冻电镜（cryo-EM）投影图像在高噪声环境下深度神经网络去噪效果有限的问题。该架构通过同时进行图像的聚类、对齐和去噪，扩展了传统的类平均方法。在合成数据上的实验结果表明，该方法能够实现准确的去噪，在信噪比为0.03时，相比单图像DNN，相对均方误差降低了45%，证明了其在高噪声冷冻电镜图像去噪中的有效性。

> **摘要翻译:** 深度神经网络（DNN）已被证明在去噪方面功能强大，但它们在冷冻电子显微镜（cryo-EM）投影图像等高噪声环境中的使用最终受到限制。然而，在这种设置下，数据集包含大量相同分子的投影，每个投影都来自不同的观察方向。这种信息冗余在被称为类平均方法的传统去噪技术中很有用，这些方法将图像聚类、对齐，然后平均以降低噪声水平。我们提出了一种基于Transformer的神经网络架构，通过同时对冷冻电镜图像进行聚类、对齐和去噪，扩展了这些类平均方法。合成数据上的结果表明，使用这种架构可以实现准确的去噪性能，在信噪比（SNR）为0.03时，相对于单图像DNN，相对均方误差（MSE）降低了45%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [154] [Score-based Generative Diffusion Models to Synthesize Full-dose FDG Brain PET from MRI in Epilepsy Patients](https://arxiv.org/abs/2506.11297)
> *基于分数生成扩散模型从癫痫患者的MRI合成全剂量FDG脑PET图像*

*Jiaqi Wu, Jiahong Ouyang, Farshad Moradi, Mohammad Mehdi Khalighi, Greg Zaharchuk* | **Main category: eess.IV**

**Keywords:** 生成扩散模型, FDG PET, MRI, 癫痫, 图像合成

**Comment:** 

> **TL;DR:** 研究表明，基于分数的生成扩散模型（SGMs）可以有效地从MRI合成诊断质量的FDG脑PET图像，尤其在结合超低剂量PET时，为减少癫痫患者的辐射暴露提供了可能。

**AI_Comments:** 这项研究的创新之处在于将基于分数的生成扩散模型应用于医学图像合成，特别是针对癫痫患者的FDG PET图像生成，旨在解决辐射剂量问题。其重要性在于为临床实践提供了一种潜在的非侵入性或低侵入性替代方案，减少患者的辐射暴露，同时保持诊断质量。未来可以探索在更大数据集和不同疾病类型上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 癫痫患者的FDG PET/MRI检查需要同时评估脑结构和代谢，但PET的辐射剂量对年轻患者不理想。目前从MRI或超低剂量PET合成诊断质量PET图像的研究较少，尤其是针对癫痫患者的临床评估。

**Method:** 本研究比较了基于扩散和非基于扩散的深度学习模型在癫痫影像中MRI到PET图像转换任务的性能。使用了52名受试者的同步PET/MRI数据（40训练/2验证/10测试）。测试了三种模型：两种基于分数的生成扩散模型（SGM-Karras Diffusion和SGM-variance preserving）和一个Transformer-Unet。通过标准图像处理指标和临床相关指标（包括评估半球代谢不对称性的一致性测量）进行评估。

**Result:** SGM-Karras Diffusion模型在仅使用T1w和T2 FLAIR图像合成PET时，产生了最佳的定性和定量结果，具有最低的全脑特异性摄取值比率（SUVR）平均绝对误差和最高的组内相关系数。当输入中包含1%的低剂量PET图像时，所有模型的性能都显著提高，并且在定量性能和视觉质量上变得可互换。

**Conclusion:** 基于分数的生成模型（SGMs）在纯MRI到PET转换方面具有巨大潜力，而所有三种模型类型都能利用MRI和超低剂量PET准确合成全剂量FDG-PET。

> **ai_Abstract:** 这项研究探讨了利用基于分数的生成扩散模型从癫痫患者的MRI数据合成全剂量FDG脑PET图像的可能性，以减少辐射暴露。研究比较了扩散模型（SGM-Karras Diffusion, SGM-VP）和非扩散模型（Transformer-Unet）的性能。结果显示，SGM-Karras Diffusion在纯MRI合成方面表现最佳，而当结合1%的超低剂量PET输入时，所有模型都能准确合成全剂量PET，且性能相当。这表明生成扩散模型在医学图像合成领域具有广阔的应用前景，尤其是在降低患者辐射剂量的背景下。

> **摘要翻译:** 氟脱氧葡萄糖 (FDG) PET 在评估癫痫患者方面是同步 PET/MRI 最常见的应用之一，因为需要同时对大脑结构和代谢进行成像，但由于对年轻人群的辐射剂量而言，这并非最佳选择。目前很少有研究利用先进的生成式人工智能方法（如扩散模型）从 MRI 数据或结合超低剂量 PET 的 MRI 数据中合成诊断质量的 PET 图像，并关注针对癫痫人群的临床评估。在此，我们比较了基于扩散和非基于扩散的深度学习模型在 52 名受试者（40 名训练/2 名验证/10 名保留测试）的同步 PET/MRI 数据上进行癫痫影像 MRI 到 PET 图像转换任务的性能。我们测试了三种不同的模型：2 种基于分数的生成扩散模型（SGM-Karras Diffusion [SGM-KD] 和 SGM-variance preserving [SGM-VP]）和一种 Transformer-Unet。我们报告了标准图像处理指标以及临床相关指标的结果，包括评估半球代谢不对称性的一致性测量（一致性指数和一致性平均绝对误差），这是这些图像临床分析的关键部分。当仅从 T1w 和 T2 FLAIR 图像合成 PET 时，SGM-KD 产生了最佳的定性和定量结果，具有最低的全脑特异性摄取值比率 (SUVR) 平均绝对误差和最高的组内相关系数。当输入中包含 1% 的低剂量 PET 图像时，所有模型都显著改善，并且在定量性能和视觉质量方面变得可互换。总之，SGM 在纯 MRI 到 PET 转换方面具有巨大潜力，而所有 3 种模型类型都可以使用 MRI 和超低剂量 PET 准确合成全剂量 FDG-PET。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [174] [Hadamard Encoded Row Column Ultrasonic Expansive Scanning (HERCULES) with Bias-Switchable Row-Column Arrays](https://arxiv.org/abs/2506.11443)
> *哈达玛编码行-列超声波扩展扫描 (HERCULES) 与偏置可切换行-列阵列*

*Darren Olufemi Dahunsi, Randy Palmar, Tyler Henry, Mohammad Rahim Sobhani, Negar Majidi, Joy Wang, Afshin Kashani Ilkhechi, Jeremy Brown, Roger Zemp* | **Main category: eess.IV**

**Keywords:** 超声成像, HERCULES, 哈达玛编码, 行-列阵列, 3D扫描

**Comment:** 10 pages, 10 figures, 6 supplementary videos

> **TL;DR:** HERCULES是一种新型超声成像技术，利用偏置可切换行-列阵列和哈达玛编码接收，实现超越孔径阴影的广阔3D扫描，并在仿真和实验中展示了高分辨率和高速成像能力。

**AI_Comments:** HERCULES的创新之处在于结合了偏置可切换行-列阵列和哈达玛编码接收，从而克服了传统超声成像的孔径限制，实现了更广阔的3D扫描范围。这种方法对于全器官成像和复杂组织结构的3D可视化具有重要意义，尤其是在通过有限窗口进行观察时。该研究通过仿真和实验验证了其可行性和高性能，为未来的超声诊断和研究提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统非偏置可切换行-列阵列无法实现某些成像技术。HERCULES旨在解决这一限制，实现超越传统孔径阴影的广阔3D扫描，并可能实现全器官成像和组织形态的3D可视化。

**Method:** HERCULES是一种利用偏置可切换行-列阵列 (TOBE阵列) 的新型成像技术。它通过发射平面或圆柱波前，并使用哈达玛编码读出 (HERO) 进行接收，以在有效的全2D合成接收孔径上执行波束形成。研究通过仿真进行了演示，并通过使用定制的TOBE阵列、定制偏置电子设备和研究超声系统进行实验实现验证。此外，还通过对商业体模成像以及对异种移植小鼠模型成像来评估成像能力。

**Result:** 仿真结果表明，HERCULES能够以数百帧每秒的速度实现与现有行-列阵列成像方法相当的分辨率。实验验证了这些仿真结果，成功地使用定制设备实现了HERCULES。通过对商业体模成像，结果与传统行-列阵列成像方法进行了比较。成功地对异种移植小鼠模型进行了成像，验证了对真实组织成像的能力。

**Conclusion:** HERCULES是一种可行且有效的超声成像技术，能够实现超越传统孔径限制的广阔3D扫描，并以高分辨率和高帧率对真实组织进行成像。

> **ai_Abstract:** 本文介绍了一种名为HERCULES的新型超声成像技术，该技术利用偏置可切换行-列阵列和哈达玛编码接收，实现了超越传统孔径限制的广阔3D扫描。通过仿真和实验验证，HERCULES展示了在数百帧每秒的速度下，能够提供与现有方法相当的高分辨率成像，并成功应用于商业体模和真实组织（异种移植小鼠模型）成像，有望实现全器官和3D组织形态可视化。

> **摘要翻译:** 顶部正交底部电极 (TOBE) 阵列，也称为偏置可切换行-列阵列 (RCA)，允许实现非偏置可切换RCA无法实现的成像技术。哈达玛编码行-列超声波扩展扫描 (HERCULES) 是一种新颖的成像技术，通过发射平面或圆柱波前并使用哈达玛编码读出 (HERO) 进行接收，以在有效的全2D合成接收孔径上执行波束形成，从而实现广阔的3D扫描。这使得成像能够超越RCA阵列孔径的阴影，可能实现全器官成像和组织形态的3D可视化。它还能够通过有限的窗口观察大体积。在这项工作中，我们通过仿真证明我们能够以数百帧每秒的速度实现与现有RCA成像方法相当的分辨率。我们通过使用定制制造的TOBE阵列、定制偏置电子设备和研究超声系统演示HERCULES的实验实现来验证了这些仿真。此外，我们通过对商业体模成像并将其结果与传统RCA成像方法的结果进行比较来评估我们的成像能力。最后，我们通过对异种移植小鼠模型成像来验证我们对真实组织成像的能力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [193] [FAD-Net: Frequency-Domain Attention-Guided Diffusion Network for Coronary Artery Segmentation using Invasive Coronary Angiography](https://arxiv.org/abs/2506.11454)
> *FAD-Net：用于冠状动脉分割的频域注意力引导扩散网络，基于侵入性冠状动脉造影*

*Nan Mu, Ruiqi Song, Xiaoning Li, Zhihui Xu, Jingfeng Jiang, Chen Zhao* | **Main category: eess.IV**

**Keywords:** 冠状动脉分割, 频域注意力, 扩散网络, 侵入性冠状动脉造影, 深度学习

**Comment:** 35 pages, 12 figures

> **TL;DR:** FAD-Net是一种基于频域注意力和扩散策略的深度学习模型，用于提高冠状动脉造影中冠状动脉分割和狭窄检测的准确性。

**AI_Comments:** FAD-Net的创新之处在于其将频域分析与注意力机制及扩散策略相结合，有效利用了图像的频率信息来提高冠状动脉分割的精度，尤其是在处理细小血管分支和边缘方面。这对于临床诊断和治疗规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉疾病（CAD）是全球主要的死亡原因之一。从侵入性冠状动脉造影（ICA）中精确分割冠状动脉对于有效的临床决策至关重要。本研究旨在提出一种新的基于频域分析的深度学习模型，以提高ICA中冠状动脉分割和狭窄检测的准确性，从而为CAD的狭窄检测和治疗提供强有力的支持。

**Method:** 本文提出了FAD-Net（频域注意力引导扩散网络），该网络集成了基于频域的注意力机制和级联扩散策略，以充分利用频域信息来提高分割精度。具体而言，FAD-Net在频域中采用多级自注意力（MLSA）机制，计算ICA中高频和低频分量之间查询和键的相似性。此外，还加入了低频扩散模块（LFDM），通过多级小波变换将ICA分解为低频和高频分量。随后，它通过逆融合重新整合高频细节，细化细小的动脉分支和边缘，从而持续增强解剖精度。

**Result:** FAD-Net在冠状动脉分割中实现了0.8717的平均Dice系数，优于现有最先进方法。在狭窄检测中，其真阳性率为0.6140，阳性预测值为0.6398。

**Conclusion:** FAD-Net在冠状动脉分割和狭窄检测中表现出色，具有辅助CAD准确诊断和治疗计划的巨大潜力。

> **ai_Abstract:** 本文提出了FAD-Net，一个利用频域注意力机制和级联扩散策略的深度学习模型，用于侵入性冠状动脉造影（ICA）中的冠状动脉精确分割和狭窄检测。FAD-Net通过多级自注意力机制处理高低频信息，并使用低频扩散模块细化细节，显著提高了分割精度和狭窄检测性能，展现出辅助冠状动脉疾病诊断和治疗的巨大潜力。

> **摘要翻译:** 背景：冠状动脉疾病（CAD）仍然是全球主要的死亡原因之一。从侵入性冠状动脉造影（ICA）中精确分割冠状动脉对于有效的临床决策至关重要。
目的：本研究旨在提出一种基于频域分析的新型深度学习模型，以提高ICA中冠状动脉分割和狭窄检测的准确性，从而为CAD的狭窄检测和治疗提供强有力的支持。
方法：我们提出了频域注意力引导扩散网络（FAD-Net），它集成了基于频域的注意力机制和级联扩散策略，以充分利用频域信息来提高分割精度。具体而言，FAD-Net在频域中采用多级自注意力（MLSA）机制，计算ICA中高频和低频分量之间查询和键的相似性。此外，还加入了低频扩散模块（LFDM），通过多级小波变换将ICA分解为低频和高频分量。随后，它通过逆融合重新整合高频细节，细化细小的动脉分支和边缘，从而持续增强解剖精度。
结果和结论：大量实验表明，FAD-Net在冠状动脉分割中实现了0.8717的平均Dice系数，优于现有最先进方法。此外，它在狭窄检测中达到了0.6140的真阳性率和0.6398的阳性预测值，突出了其临床适用性。这些发现表明FAD-Net在辅助CAD的准确诊断和治疗规划方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [212] [Taming Stable Diffusion for Computed Tomography Blind Super-Resolution](https://arxiv.org/abs/2506.11496)
> *驯服Stable Diffusion用于计算机断层扫描盲超分辨率*

*Chunlei Li, Yilei Shi, Haoxi Hu, Jingliang Hu, Xiao Xiang Zhu, Lichao Mou* | **Main category: eess.IV**

**Keywords:** CT超分辨率, Stable Diffusion, 盲超分辨率, 医学成像, 深度学习

**Comment:** 

> **TL;DR:** 高分辨率CT成像需要高辐射，而传统深度学习方法在处理复杂退化和有限数据时面临挑战。本文提出了一种新颖的框架，将Stable Diffusion应用于CT盲超分辨率，通过合成低质量图像和生成文本描述来条件化模型。实验证明，该方法优于现有方法，有望在降低辐射剂量的同时实现高质量CT成像。

**AI_Comments:** 该论文的创新之处在于将强大的大规模预训练扩散模型Stable Diffusion应用于CT盲超分辨率这一特定的医学图像任务。该任务受限于数据稀缺和复杂退化。利用实用退化模型和视觉语言模型来条件化Stable Diffusion，是一种新颖的方法，可以利用其生成能力来增强医学图像，从而有可能实现更安全的CT成像。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率CT成像对医学诊断至关重要，但会导致辐射暴露增加，需要在图像质量和患者安全之间进行权衡。现有深度学习方法在CT超分辨率中面临复杂退化和医学训练数据有限的挑战。大规模预训练扩散模型（特别是Stable Diffusion）在合成精细细节方面表现出色，这促使作者探索将其应用于CT盲超分辨率。

**Method:** 本文提出了一种新颖的框架，将Stable Diffusion应用于CT盲超分辨率。该方法首先采用实用的退化模型合成逼真的低质量图像，然后利用预训练的视觉语言模型生成相应的描述。最后，使用带有专门控制策略的Stable Diffusion进行超分辨率，该策略以低分辨率输入和生成的文本描述为条件。

**Result:** 广泛的实验表明，所提出的方法优于现有方法。

**Conclusion:** 该方法展示了在降低辐射剂量的同时实现高质量CT成像的潜力。

> **ai_Abstract:** 本文针对CT成像中图像质量与辐射暴露的权衡问题，提出了一种基于Stable Diffusion的CT盲超分辨率新框架。鉴于传统深度学习方法在处理复杂退化和稀缺医学数据方面的局限性，并受大规模扩散模型细节合成能力的启发，作者将Stable Diffusion应用于此任务。该方法通过实用退化模型合成低质量图像，并利用视觉语言模型生成相应的文本描述，然后使用Stable Diffusion在低分辨率输入和文本描述的条件下进行超分辨率。实验结果表明，该方法优于现有技术，有望在降低辐射剂量的同时实现高质量CT扫描。

> **摘要翻译:** 高分辨率计算机断层扫描（CT）成像对于医学诊断至关重要，但需要增加辐射暴露，这在图像质量和患者安全之间造成了关键的权衡。尽管深度学习方法在CT超分辨率方面显示出前景，但它们面临复杂退化和有限医疗训练数据的挑战。与此同时，大规模预训练扩散模型，特别是Stable Diffusion，在各种视觉任务中展示了合成精细细节的卓越能力。受此启发，我们提出了一种新颖的框架，用于将Stable Diffusion应用于CT盲超分辨率。我们采用实用的退化模型合成逼真的低质量图像，并利用预训练的视觉语言模型生成相应的描述。随后，我们使用Stable Diffusion以及专门的控制策略进行超分辨率，该策略以低分辨率输入和生成的文本描述为条件。广泛的实验表明，我们的方法优于现有方法，证明了其在减少辐射剂量下实现高质量CT成像的潜力。我们的代码将公开发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [226] [FCA2: Frame Compression-Aware Autoencoder for Modular and Fast Compressed Video Super-Resolution](https://arxiv.org/abs/2506.11545)
> *FCA2：模块化快速压缩视频超分辨率的帧压缩感知自编码器*

*Zhaoyang Wang, Jie Li, Wen Lu, Lihuo He, Maoguo Gong, Xinbo Gao* | **Main category: eess.IV**

**Keywords:** 压缩视频超分辨率, 自编码器, 帧压缩, 降维, 快速推理

**Comment:** This work has been submitted to the IEEE TMM for possible publication

> **TL;DR:** 提出FCA2，一个受高光谱图像启发的帧压缩感知自编码器，用于快速且高性能的压缩视频超分辨率，解决了现有方法推理时间长和复杂性高的问题。

**AI_Comments:** 这项工作通过引入压缩驱动的降维策略和模块化架构，有效解决了当前CVSR模型面临的推理效率和复杂性问题。其创新点在于从高光谱图像处理中获得灵感，并将压缩感知与自编码器结合，实现了性能与速度的平衡，具有较强的实用价值和集成潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的压缩视频超分辨率（CVSR）模型面临推理时间长、训练流程复杂、依赖辅助信息等挑战。随着视频帧率的不断增加，帧间差异的减小进一步暴露了传统帧间信息利用方法的局限性，这些方法不足以满足当前视频超分辨率（VSR）的需求。

**Method:** 提出一种高效且可扩展的解决方案，该方案受到高光谱图像（HSI）和视频数据之间结构和统计相似性的启发。引入一种压缩驱动的降维策略，以降低计算复杂度、加速推理并增强帧间时间信息提取。所提出的模块化架构旨在与现有VSR框架无缝集成，确保强大的适应性和可移植性。

**Result:** 实验结果表明，该方法性能与当前SOTA模型相当或超越，同时显著缩短了推理时间。

**Conclusion:** 通过解决压缩视频超分辨率（CVSR）中的关键瓶颈，该工作为推进视频超分辨率（VSR）技术提供了一条实用且高效的途径。

> **ai_Abstract:** 本文提出了FCA2，一个帧压缩感知自编码器，旨在解决当前压缩视频超分辨率（CVSR）模型推理时间长和训练复杂的问题。受高光谱图像与视频数据相似性的启发，FCA2采用压缩驱动的降维策略来降低计算复杂度、加速推理并有效提取时间信息。其模块化设计使其能与现有VSR框架无缝集成。实验证明，FCA2在保持或超越SOTA性能的同时，显著减少了推理时间，为VSR技术发展提供了高效实用的新途径。

> **摘要翻译:** 当前最先进的（SOTA）压缩视频超分辨率（CVSR）模型面临持续的挑战，包括推理时间过长、训练流程复杂以及对辅助信息的依赖。随着视频帧率的不断提高，帧间差异的减小进一步暴露了传统帧到帧信息利用方法的局限性，这些方法不足以满足当前视频超分辨率（VSR）的需求。为了克服这些挑战，我们提出了一种高效且可扩展的解决方案，该方案受到高光谱图像（HSI）和视频数据之间结构和统计相似性的启发。我们的方法引入了一种压缩驱动的降维策略，该策略降低了计算复杂度，加速了推理，并增强了跨帧的时间信息提取。所提出的模块化架构旨在与现有VSR框架无缝集成，确保在不同应用中具有强大的适应性和可移植性。实验结果表明，我们的方法性能与当前SOTA模型相当或超越，同时显著缩短了推理时间。通过解决CVSR中的关键瓶颈，我们的工作为推进VSR技术提供了一条实用且高效的途径。我们的代码将在https://github.com/handsomewzy/FCA2公开。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [241] [Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis](https://arxiv.org/abs/2506.11671)
> *基于微调自监督模型的脑网络分析用于脑疾病诊断*

*Yifei Tang, Hongjie Jiang, Changhong Jing, Hieu Pham, Shuqiang Wang* | **Main category: eess.IV**

**Keywords:** 脑网络分析, 自监督学习, 脑疾病诊断, 微调模型, fMRI

**Comment:** 13 pages, 3 figures, International Conference on Neural Computing for
  Advanced Applications

> **TL;DR:** 提出一种基于自监督学习和多维特征扩展的微调脑网络模型，用于脑疾病诊断，并在实验中表现出优越性能。

**AI_Comments:** 该研究创新性地将多维特征扩展和自监督预训练引入脑网络分析的基础模型构建中，解决了现有模型泛化能力受限的问题。其提出的适配器模块和基于Transformer的特征提取方法有望提升脑疾病诊断的准确性和效率，为神经科学领域的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑网络基础模型研究有限且局限于单一维度，限制了其在神经科学中的广泛应用。

**Method:** 提出一个微调脑网络模型，通过适配器模块扩展脑区多维特征，并基于自监督学习和大规模fMRI数据预训练，其Transformer块能有效提取特征并计算区域间关联，最终得到紧凑的脑网络潜在表示。

**Result:** 提出的模型在脑疾病诊断的下游实验中表现出优越性能。

**Conclusion:** 该模型为脑网络分析研究提供了一种有前景的方法。

> **ai_Abstract:** 本文提出了一种用于脑疾病诊断的微调脑网络模型，旨在解决现有脑网络基础模型单一维度限制的问题。该模型通过适配器模块扩展脑区特征至多维，并利用自监督学习在大量fMRI数据上进行预训练，其Transformer块能有效提取脑区特征和计算关联。实验结果表明，该模型在脑疾病诊断任务中表现优异，为脑网络分析提供了新方法。

> **摘要翻译:** 功能性脑网络分析已成为脑疾病分析不可或缺的工具。它深受深度学习方法的影响，能够表征ROI之间复杂的连接。然而，脑网络基础模型的研究有限且受限于单一维度，这限制了它们在神经科学中的广泛应用。在本研究中，我们提出了一种用于脑疾病诊断的微调脑网络模型。它在原始脑网络模型的基础上，将脑区表示扩展到多个维度，从而增强了其泛化能力。我们的模型包含两个关键模块：(1)一个适配器模块，用于在不同维度上扩展脑区特征。(2)一个微调的基础脑网络模型，基于自监督学习，并在数千名参与者的fMRI数据上进行预训练。具体来说，其Transformer块能够有效提取脑区特征并计算区域间关联。此外，我们推导出了一个用于脑疾病诊断的脑网络的紧凑潜在表示。本研究中的下游实验表明，所提出的模型在脑疾病诊断中取得了优越的性能，这可能为脑网络分析研究提供一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [245] [MindGrab for BrainChop: Fast and Accurate Skull Stripping for Command Line and Browser](https://arxiv.org/abs/2506.11860)
> *MindGrab for BrainChop：命令行和浏览器上的快速准确颅骨剥离*

*Armina Fani, Mike Doan, Isabelle Le, Alex Fedorov, Malte Hoffmann, Chris Rorden, Sergey Plis* | **Main category: eess.IV**

**Keywords:** 颅骨剥离, 深度学习, 体积, 效率, 多模态

**Comment:** 12 pages, 1 table, 4 figures. 2 supplementary tables, 1 supplementary
  figure. Brainchop-cli: https://pypi.org/project/brainchop/ . Brainchop web:
  https://brainchop.org/

> **TL;DR:** MindGrab是一种新型深度学习模型，用于颅骨剥离，具有快速、准确和资源高效的特点，性能优于传统方法，并且在保持相近精度的同时大幅减少资源消耗。

**AI_Comments:** MindGrab的关键创新在于以显著降低的计算资源（参数、内存、推理时间）实现最先进的颅骨剥离精度。这使得高级脑图像处理更具可访问性，特别是对于没有高端GPU的系统，这对于在临床或研究环境中更广泛的应用是一个重要的实际优势。其在模态无关合成数据上的训练也突显了一种稳健和可推广的方法。

<details>
  <summary>Details</summary>

**Motivation:** 需要一个参数和内存高效的深度全卷积模型，用于对任何模态的头部图像进行体积颅骨剥离，特别是能在更广泛的硬件上运行的模型。

**Method:** 开发了MindGrab，一个深度全卷积模型，其架构受膨胀卷积的谱解释启发，并完全在模态无关的合成数据上训练。在包含606个多模态成人脑部扫描的回顾性数据集上进行评估，并与SynthStrip、ROBEX和BET使用Dice分数和Wilcoxon符号秩检验进行基准测试。

**Result:** MindGrab在不同模态上平均Dice分数为95.9 (SD 1.6)，显著优于ROBEX (89.1 SD 7.7, P < 0.05) 和 BET (85.2 SD 14.4, P < 0.05)。与SynthStrip (96.5 SD 1.1, P=0.0352) 相比，在近一半测试场景中性能相当或更优，其他场景差异微小 (<3% Dice)。MindGrab使用的参数比SynthStrip少95% (146,237 vs 2,566,561)，推理速度至少快2倍，GPU内存使用量降低50%，并实现了卓越性能 (例如，10-30倍的速度提升和高达30倍的内存减少)，可在更广泛的硬件上访问。

**Conclusion:** MindGrab以显著降低的资源需求实现了最先进的颅骨剥离精度，使其具有高度的可访问性和效率。

> **ai_Abstract:** MindGrab是一种新颖的、深度全卷积颅骨剥离模型，在参数和内存方面均高效。它在各种成像模态上实现了最先进的精度，同时显著降低了计算资源需求，提高了在不同硬件上的可访问性，优于经典方法，并以更少的资源达到或接近其他深度学习方法（如SynthStrip）的性能。

> **摘要翻译:** 我们开发了 MindGrab，这是一种参数和内存效率高的深度全卷积模型，用于对任何模态的头部图像进行体积颅骨剥离。其架构受膨胀卷积的谱解释启发，并完全在模态无关的合成数据上进行训练。MindGrab 在一个包含 606 个多模态成人脑部扫描（T1、T2、DWI、MRA、PDw MRI、EPI、CT、PET）的回顾性数据集上进行了评估，这些数据来源于 SynthStrip 数据集。使用 Dice 分数和 Wilcoxon 符号秩显著性检验，其性能与 SynthStrip、ROBEX 和 BET 进行了基准测试。MindGrab 在不同模态上实现了 95.9 的平均 Dice 分数，标准差 (SD) 为 1.6，显著优于经典方法（ROBEX：89.1 SD 7.7，P < 0.05；BET：85.2 SD 14.4，P < 0.05）。与 SynthStrip（96.5 SD 1.1，P=0.0352）相比，MindGrab 在近一半的测试场景中提供了同等或更优的性能，在其他场景中差异微小（<3% Dice）。MindGrab 使用的参数比 SynthStrip 少 95%（146,237 对比 2,566,561）。这种效率使得推理速度至少提高 2 倍，GPU 内存使用量降低 50%，并实现了卓越的性能（例如，10-30 倍的速度提升和高达 30 倍的内存减少），并可在更广泛的硬件上实现可访问性，包括没有高端 GPU 的系统。MindGrab 以显着降低的资源需求提供了最先进的准确性，并在 brainchop-cli (https://pypi.org/project/brainchop/) 和 brainchop.org 上得到支持。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [258] [Exploring the Effectiveness of Deep Features from Domain-Specific Foundation Models in Retinal Image Synthesis](https://arxiv.org/abs/2506.11753)
> *探索特定领域基础模型深度特征在视网膜图像合成中的有效性*

*Zuzanna Skorniewska, Bartlomiej W. Papiez* | **Main category: eess.IV**

**Keywords:** 视网膜图像合成, 深度特征, 基础模型, 边缘检测, 生成模型

**Comment:** To be published and presented at the MIUA 2025 conference

> **TL;DR:** 研究发现，在视网膜图像合成中，来自特定领域基础模型的深度特征并未提升图像生成效果，而传统边缘检测滤波器能有效提高血管结构的清晰度。

**AI_Comments:** 这项研究提出了一个反直觉但重要的发现，即在视网膜图像合成这一特定医疗图像任务中，来自大型领域特定基础模型的复杂深度特征并未带来性能提升。相反，传统的边缘检测滤波器在关键的血管结构清晰度方面表现出优越性。这表明在医疗图像领域，并非越复杂的模型或特征就越有效，有时简单的、经过验证的方法可能更具实用性和效率。其局限性可能在于未能充分利用基础模型中更高级别的语义信息，或者其损失函数设计未能完全捕捉医疗图像所需的精细结构。

<details>
  <summary>Details</summary>

**Motivation:** 医疗成像中神经网络模型的应用受隐私法规、数据稀缺、获取成本高和人口偏见等因素限制。深度生成模型通过生成合成数据来规避隐私问题并解决数据不平衡，但医疗图像合成不仅需要保真度，还需要形态学和临床准确性，特别是视网膜图像需精确复制血管网络。

**Method:** 研究团队调查了一种基于大型特定领域基础模型深度激活层的距离损失函数，以评估其在视网膜图像合成中是否优于感知损失和基于边缘检测的损失函数。他们建立了一个广泛的验证流程，包括领域无关和领域特定的任务。

**Result:** 实验结果表明，特定领域的深度特征并未改善自动编码器的图像生成效果。相反，研究发现传统的边缘检测滤波器在提高合成样本中血管结构的清晰度方面表现出有效性。

**Conclusion:** 特定领域基础模型的深度特征在视网膜图像合成中未能展现出优势，而传统的边缘检测方法在改善血管结构清晰度方面更为有效。这可能意味着在某些特定医疗图像合成任务中，简单的、经过验证的方法可能比复杂的基础模型特征更具实用性。

> **ai_Abstract:** 本研究旨在解决医学图像合成中数据隐私、可用性和准确性验证的挑战。特别针对视网膜图像合成，研究比较了基于特定领域基础模型深度特征的距离损失函数与传统感知损失和边缘检测损失的效果。结果显示，特定领域的深度特征并未能提升图像生成质量，反而传统边缘检测滤波器在增强合成视网膜图像的血管结构清晰度方面表现出更佳的效果。

> **摘要翻译:** 神经网络模型在医学成像中的应用受到严格的隐私法规、有限的数据可用性、高昂的采集成本和人口偏见的限制。深度生成模型通过生成合成数据来规避隐私问题，并通过为代表性不足的群体生成样本来解决公平性问题，从而提供了一个有前景的解决方案。然而，与自然图像不同，医学成像不仅需要验证保真度（例如，Fréchet Inception Score），还需要验证形态学和临床准确性。对于彩色眼底视网膜成像尤其如此，它需要精确复制视网膜血管网络，包括血管拓扑结构、连续性和厚度。在本研究中，我们调查了基于在大量领域数据（彩色眼底成像）上训练的大型基础模型的深度激活层的距离损失函数是否比感知损失和基于边缘检测的损失函数具有优势。我们基于领域无关和领域特定任务的广泛验证流程表明，特定领域的深度特征并未改善自动编码器的图像生成。相反，我们的研究结果强调了传统边缘检测滤波器在提高合成样本中血管结构清晰度方面的有效性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [273] [Framework of a multiscale data-driven digital twin of the muscle-skeletal system](https://arxiv.org/abs/2506.11821)
> *多尺度数据驱动肌肉骨骼系统数字孪生框架*

*Martina Paccini, Simone Cammarasana, Giuseppe Patanè* | **Main category: eess.IV**

**Keywords:** 肌肉骨骼疾病, 数字孪生, 生物力学, 患者特异性, 康复

**Comment:** 

> **TL;DR:** 本文提出了一个肌肉骨骼数字孪生（MS-DT）框架，通过整合多尺度生物力学数据和计算模型，实现对肌肉骨骼系统的患者特异性高精度建模和实时可视化，以改善肌肉骨骼疾病的诊断和治疗。

**AI_Comments:** 该论文提出了一种创新的多尺度数据驱动数字孪生框架，将异构生物力学数据整合到患者特异性模型中，这对于个性化医疗和康复具有重要意义。其创新性在于结合了多种数据源和实时可视化能力，有望显著提高肌肉骨骼疾病的诊断精度和治疗效果。

<details>
  <summary>Details</summary>

**Motivation:** 肌肉骨骼疾病（MSDs）是全球致残的主要原因，需要先进的诊断和治疗工具进行个性化评估和治疗。MSDs的有效管理涉及异构数据源的交互，数字孪生（DT）范式成为一个有价值的选择。

**Method:** 本文提出了肌肉骨骼数字孪生（MS-DT）框架，该框架将多尺度生物力学数据与计算建模相结合，以创建肌肉骨骼系统详细的患者特异性表示。通过结合运动捕捉、超声成像、肌电图和医学成像，MS-DT能够分析脊柱运动学、姿势和肌肉功能。一个交互式可视化平台为临床医生和研究人员提供了探索生物力学参数和跟踪患者特异性变化的直观界面。

**Result:** 结果表明MS-DT在提取精确的运动学和动态组织特征方面是有效的，为监测脊柱生物力学和康复提供了一个全面的工具。

**Conclusion:** 该框架提供了高保真建模和实时可视化，以改善患者特异性诊断和干预规划。

> **ai_Abstract:** 本文提出了一个新颖的肌肉骨骼数字孪生（MS-DT）框架，旨在解决肌肉骨骼疾病的个性化诊断和治疗挑战。该框架通过整合多尺度生物力学数据（如运动捕捉、超声、肌电图、医学成像）与计算模型，创建了患者特异性的肌肉骨骼系统数字表示。MS-DT能够分析脊柱运动学、姿势和肌肉功能，并通过交互式可视化平台提供直观的数据探索。研究结果证实了MS-DT在提取精确运动学和动态组织特征方面的有效性，为脊柱生物力学监测和康复提供了高保真建模和实时可视化工具，从而改善患者特异性诊断和干预规划。

> **摘要翻译:** 肌肉骨骼疾病（MSDs）是全球致残的主要原因，需要先进的诊断和治疗工具进行个性化评估和治疗。MSDs的有效管理涉及异构数据源的交互，这使得数字孪生（DT）范式成为一个有价值的选择。本文介绍了肌肉骨骼数字孪生（MS-DT），这是一个新颖的框架，它将多尺度生物力学数据与计算建模相结合，以创建肌肉骨骼系统的详细、患者特异性表示。通过结合运动捕捉、超声成像、肌电图和医学成像，MS-DT能够分析脊柱运动学、姿势和肌肉功能。一个交互式可视化平台为临床医生和研究人员提供了探索生物力学参数和跟踪患者特异性变化的直观界面。结果表明MS-DT在提取精确的运动学和动态组织特征方面是有效的，为监测脊柱生物力学和康复提供了一个全面的工具。该框架提供了高保真建模和实时可视化，以改善患者特异性诊断和干预规划。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [285] [Structural Similarity-Inspired Unfolding for Lightweight Image Super-Resolution](https://arxiv.org/abs/2506.11823)
> *结构相似性启发式展开用于轻量级图像超分辨率*

*Zhangkai Ni, Yang Zhang, Wenhan Yang, Hanli Wang, Shiqi Wang, Sam Kwong* | **Main category: eess.IV**

**Keywords:** 图像超分辨率, 模型展开, 结构相似性, 轻量级, 数据驱动

**Comment:** Accepted to IEEE Transactions on Image Processing

> **TL;DR:** 本文提出了一种名为SSIU的轻量级图像超分辨率方法，它结合了数据驱动和模型驱动的优点，通过展开一个受结构相似性约束的优化函数来实现，并在参数量和内存消耗方面优于现有SOTA模型。

**AI_Comments:** 这项工作通过将结构相似性约束集成到展开式模型驱动框架中，为轻量级图像超分辨率提供了一种新颖且高效的解决方案。其创新点在于巧妙地结合了数据驱动和模型驱动方法的优点，通过迭代展开和模块化设计（MSGM、ESAM、MoE-FS）实现了性能与效率的平衡。该方法在降低模型复杂度的同时提升了图像质量，对于资源受限的设备具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据驱动图像超分辨率方法通常通过加深网络或使用Transformer机制来扩大感受野，但这会增加模型复杂性。基于展开范式的模型驱动方法在保持模型紧凑性的同时显示出提升性能的潜力。因此，本文旨在结合这两种方法的优点，开发一种高效且轻量级的图像超分辨率方法。

**Method:** 本文提出了一种结构相似性启发式展开（SSIU）方法。该方法通过展开一个受结构相似性约束的超分辨率优化函数来设计，旨在结合数据驱动和模型驱动方法的优点。模型遵循展开范式逐步操作，每个迭代包含多个混合尺度门控模块（MSGM）和一个高效稀疏注意力模块（ESAM）。MSGM实现对特征的综合约束，包括结构相似性约束；ESAM旨在实现稀疏激活。此外，还设计了一个基于专家混合的特征选择器（MoE-FS），通过组合不同步骤的特征来充分利用多级特征信息。

**Result:** 广泛的实验验证了本文提出的展开式网络的有效性和效率。该模型在参数量和内存消耗方面均低于当前最先进的模型，并且性能优于它们。

**Conclusion:** 本文提出的结构相似性启发式展开（SSIU）方法成功结合了数据驱动和模型驱动方法的优势，在实现高性能图像超分辨率的同时，显著降低了模型复杂度和资源消耗，证明了其在轻量级SR领域的优越性。

> **ai_Abstract:** 本文提出了一种名为结构相似性启发式展开（SSIU）的轻量级图像超分辨率方法，旨在结合数据驱动和模型驱动方法的优势。SSIU通过展开一个受结构相似性约束的优化函数实现，其迭代过程包含混合尺度门控模块（MSGM）和高效稀疏注意力模块（ESAM），并引入了基于专家混合的特征选择器（MoE-FS）以充分利用多级特征。实验证明，SSIU在性能优于现有SOTA模型的同时，显著降低了参数量和内存消耗。

> **摘要翻译:** 数据驱动图像超分辨率（SR）的主要努力集中在扩大模型的感受野以更好地捕获上下文信息。然而，这些方法通常通过堆叠更深的网络或利用基于Transformer的注意力机制来实现，这会因此增加模型复杂性。相比之下，基于展开范式的模型驱动方法通过复杂巧妙的模块设计，在提高性能的同时有效保持模型紧凑性，显示出前景。基于这些见解，我们提出了一种结构相似性启发式展开（SSIU）方法，用于高效图像超分辨率。该方法通过展开一个受结构相似性约束的SR优化函数来设计，旨在结合数据驱动和模型驱动方法的优点。我们的模型遵循展开范式逐步操作。每次迭代由多个混合尺度门控模块（MSGM）和一个高效稀疏注意力模块（ESAM）组成。前者对特征实施全面约束，包括结构相似性约束，而后者旨在实现稀疏激活。此外，我们设计了一个基于专家混合的特征选择器（MoE-FS），通过组合不同步骤的特征来充分利用多级特征信息。广泛的实验验证了我们展开式网络的有效性和效率。我们的模型优于当前最先进的模型，拥有更低的参数计数和更少的内存消耗。我们的代码将在https://github.com/eezkni/SSIU提供。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [297] [3D Skin Segmentation Methods in Medical Imaging: A Comparison](https://arxiv.org/abs/2506.11852)
> *医学成像中的三维皮肤分割方法：一项比较*

*Martina Paccini, Giuseppe Patanè* | **Main category: eess.IV**

**Keywords:** 三维皮肤分割, 医学成像, 深度学习, 区域增长, 比较

**Comment:** 

> **TL;DR:** 本文比较了医学成像中AI和基于图形的三维皮肤分割方法，突出了它们在不同模态下的优缺点。

**AI_Comments:** 本文通过比较传统算法和AI驱动方法，揭示了三维皮肤分割在医学成像中的实际应用挑战。其创新性在于对比分析了不同技术路径的优缺点，特别是AI方法在自动化方面的优势及对特定模态（如MRI）的局限性，为临床实践中选择合适的分割策略提供了重要参考。

<details>
  <summary>Details</summary>

**Motivation:** 自动分割解剖结构在医学图像分析中至关重要，有助于诊断和治疗规划。皮肤分割在多模态成像数据配准和可视化中起关键作用，支持个性化医疗、手术规划和远程监控。

**Method:** 该论文分析并比较了算法（迭代区域增长算法）和AI驱动（TotalSegmentator，基于深度学习）的皮肤分割方法。它们在不同的成像模态（CT、MRI）和解剖区域上进行了评估。

**Result:** AI分割在自动化方面表现出色，但由于其基于CT的训练，在MRI上表现不佳。基于图形的方法在MRI上表现更好，但引入更多噪声。AI驱动的分割还能自动移除CT中的患者床，而基于图形的方法需要手动干预。

**Conclusion:** 选择皮肤分割策略需考虑数据可用性和应用需求，AI和传统方法各有优劣，尤其在不同成像模态下表现差异显著。

> **ai_Abstract:** 本文比较了医学成像中三维皮肤分割的算法（迭代区域增长）和AI驱动（TotalSegmentator）方法。研究发现，AI方法在自动化方面表现优异，但对MRI支持不足；而基于图形的方法在MRI上效果较好，但会引入更多噪声。AI方法还能自动处理CT图像中的患者床移除，而传统方法需要手动干预。

> **摘要翻译:** 解剖结构的自动分割在医学图像分析中至关重要，有助于诊断和治疗规划。皮肤分割在多模态成像数据的配准和可视化中起着关键作用。三维皮肤分割使得个性化医疗、手术规划和远程监控等应用成为可能，为治疗模拟、程序可视化和持续病情跟踪提供逼真的患者模型。本文分析并比较了算法和AI驱动的皮肤分割方法，强调了根据数据可用性和应用要求选择策略时需要考虑的关键因素。我们评估了迭代区域增长算法和TotalSegmentator（一种基于深度学习的方法）在不同成像模态和解剖区域上的表现。我们的测试表明，AI分割在自动化方面表现出色，但由于其基于CT的训练，在MRI上表现不佳，而基于图形的方法在MRI上表现更好但引入更多噪声。AI驱动的分割还能自动移除CT中的患者床，而基于图形的方法需要手动干预。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [318] [crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)
> *crossMoDA 挑战赛：2021年至2023年间前庭神经鞘瘤和耳蜗分割的跨模态域适应技术演变*

*Navodini Wijethilake, Reuben Dorent, Marina Ivory, Aaron Kujawa, Stefan Cornelissen, Patrick Langenhuizen, Mohamed Okasha, Anna Oviedova, Hexin Dong, Bogyeong Kang, Guillaume Sallé, Luyi Han, Ziyuan Zhao, Han Liu, Tao Yang, Shahad Hardan, Hussain Alasmawi, Santosh Sanjeev, Yuzhou Zhuang, Satoshi Kondo, Maria Baldeon Calisto, Shaikh Muhammad Uzair Noman, Cancan Chen, Ipek Oguz, Rongguo Zhang, Mina Rezaei, Susana K. Lai-Yuen, Satoshi Kasai, Chih-Cheng Hung, Mohammad Yaqub, Lisheng Wang, Benoit M. Dawant, Cuntai Guan, Ritse Mann, Vincent Jaouen, Ji-Wung Han, Li Zhang, Jonathan Shapey, Tom Vercauteren* | **Main category: eess.IV**

**Keywords:** 跨模态域适应, 医学图像分割, 前庭神经鞘瘤, 耳蜗, 挑战赛

**Comment:** 

> **TL;DR:** crossMoDA挑战赛系列专注于无监督跨模态医学图像分割，从2021年到2023年，其数据集和任务复杂性不断演变，旨在推动前庭神经鞘瘤和耳蜗的自动化分割。研究发现数据集扩大和异质性增加有助于减少异常值，但耳蜗分割性能有所下降，表明需要更具挑战性的任务。

**AI_Comments:** crossMoDA挑战赛系列通过在临床相关背景下（VS和耳蜗分割）建立跨模态域适应的长期基准，展现了创新性。挑战赛的演变（从单一机构到多机构，从基本分割到亚分割）是其优势，推动了该领域的发展。这项工作突出了在实际医学图像中应用无监督域适应的实践挑战和进展，特别是数据异质性方面。发现数据异质性增加可以提高即使在同质数据上的性能，对数据集设计和模型泛化具有重要意义。然而，耳蜗Dice分数因复杂性增加而下降，表明现有方法在处理精细注释和复杂任务方面的局限性。未来需要更具挑战性的任务，因为现有任务的性能可能已达到平台期。

<details>
  <summary>Details</summary>

**Motivation:** crossMoDA挑战赛旨在为无监督跨模态分割提供一个有意义且具有启发性的基准，特别是从对比增强T1（ceT1）图像学习并迁移到T2 MRI图像。从临床应用角度，其目标是实现T2扫描上前庭神经鞘瘤（VS）和耳蜗的自动化分割，以提高VS管理的成本效益。挑战赛的目标也随时间演变，以增强其临床相关性。

**Method:** crossMoDA挑战赛系列专注于无监督跨模态分割，即从ceT1 MRI到T2 MRI的图像转换。挑战赛从2021年使用单一机构数据和基本分割，演变为2022年包含多机构数据和Koos分级，到2023年进一步纳入异构常规数据和肿瘤内、外耳道成分的亚分割。本文报告了2022年和2023年挑战赛的结果，并对多年来的挑战进展进行了回顾性分析。

**Result:** 研究观察表明，随着数据集的扩展，异常值的数量减少，尽管扫描协议的多样性同时增加。2023年获胜的方法在2021年和2022年测试数据上减少了异常值数量，证明了数据异质性的增加可以提高即使在同质数据上的分割性能。然而，2023年耳蜗的Dice分数有所下降，这可能归因于肿瘤亚注释增加了任务复杂性。

**Conclusion:** 尽管在临床可接受的前庭神经鞘瘤（VS）分割方面仍需取得进展，但性能趋于平稳表明，未来可能需要更具挑战性的跨模态任务来更好地服务基准测试。

> **ai_Abstract:** 这篇论文回顾了2021年至2023年跨模态域适应（crossMoDA）挑战赛的演变，该挑战赛旨在推动前庭神经鞘瘤和耳蜗在T2 MRI上的无监督跨模态分割。挑战赛从单一机构数据和基本分割发展到包含多机构、异构数据和复杂的肿瘤亚分割任务。研究发现，随着数据集的扩大和异质性的增加，异常值数量减少，表明数据多样性有助于提高分割性能。然而，耳蜗分割性能在后期挑战中有所下降，可能由于任务复杂性增加。文章指出，尽管VS分割仍需改进，但当前性能瓶颈提示未来基准测试可能需要更具挑战性的跨模态任务。

> **摘要翻译:** cross-Modality Domain Adaptation (crossMoDA) 挑战赛系列于2021年与国际医学图像计算和计算机辅助干预大会（MICCAI）同期启动，专注于无监督跨模态分割，从对比增强T1（ceT1）图像学习并迁移到T2 MRI图像。这项任务是领域偏移的一个极端例子，被选作一个有意义且具有启发性的基准。从临床应用角度来看，它旨在实现T2扫描上前庭神经鞘瘤（VS）和耳蜗的自动化分割，以实现更具成本效益的VS管理。随着时间的推移，挑战目标已经演变以增强其临床相关性。该挑战赛从2021年使用单一机构数据和基本分割，发展到2022年整合多机构数据和Koos分级，到2023年，它包括异构常规数据以及肿瘤内和外耳道成分的亚分割。在这项工作中，我们报告了2022年和2023年挑战赛的结果，并对多年来的挑战进展进行了回顾性分析。连续挑战贡献的观察结果表明，随着数据集的扩展，异常值的数量减少。这一点值得注意，因为数据集的扫描协议多样性同时增加。2023年获胜的方法减少了2021年和2022年测试数据上的异常值数量，这表明数据异质性的增加如何能够提高甚至在同质数据上的分割性能。然而，2023年耳蜗的Dice分数下降，这可能是由于肿瘤亚注释增加了复杂性，影响了整体分割性能。尽管在临床可接受的VS分割方面仍需取得进展，但性能趋于平稳表明，更具挑战性的跨模态任务可能更好地服务于未来的基准测试。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [23] [PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding](https://arxiv.org/abs/2506.11064)
> *PMF-CEC：基于音素增强多模态融合的上下文感知ASR纠错与错误特异性选择解码*

*Jiajun He, Tomoki Toda* | **Main category: eess.AS**

**Keywords:** ASR错误纠正, 多模态融合, 音素增强, 上下文感知, 同音异形词

**Comment:** Accepted by IEEE TASLP 2025

> **TL;DR:** 本文提出PMF-CEC方法，通过音素增强多模态融合和选择性解码，改进了ASR对同音异形词的纠错能力，并解决了过检测问题，在保持推理速度的同时降低了词错误率。

**AI_Comments:** PMF-CEC的创新点在于引入音素增强的多模态融合来解决同音异形词的混淆问题，并优化了错误检测的过检测问题。这对于提升ASR在实际应用中对专业词汇和稀有词的识别准确率具有重要意义。与LLM-based方法相比，其在推理速度和大规模偏置列表下的鲁棒性优势使其在特定场景下更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的端到端ASR模型难以准确识别稀有词，特别是发音相似但拼写不同的稀有词（同音异形词）。此前的ED-CEC方法在处理同音异形词时准确率仍低，且ASR错误检测模块存在过检测问题。

**Method:** 提出PMF-CEC（Phoneme-augmented Multimodal Fusion for Context-aware error correction）方法，它基于ED-CEC，通过音素增强的多模态融合来更好地区分目标稀有词和同音异形词。此外，引入保留概率机制，过滤掉置信度低于阈值的编辑操作，以改善错误检测准确率。

**Result:** 在五个数据集上的实验表明，PMF-CEC与ED-CEC相比，保持了合理的推理速度，进一步降低了偏置词错误率，在纠正同音异形词方面显示出更强的优势。此外，该方法优于其他上下文偏置方法，并且在推理速度和在大型偏置列表下的鲁棒性方面，相对于基于LLM的方法仍有价值。

**Conclusion:** PMF-CEC通过结合音素增强的多模态融合和改进的错误检测机制，有效提升了ASR在稀有词，特别是同音异形词上的纠错性能，并在效率和鲁棒性方面优于或可与现有方法竞争。

> **ai_Abstract:** 本文提出PMF-CEC（音素增强多模态融合的上下文感知ASR纠错）方法，旨在解决现有ASR模型在识别稀有词特别是同音异形词时的准确性问题。PMF-CEC在ED-CEC基础上，通过引入音素增强的多模态融合来更好地区分同音异形词，并采用保留概率机制优化了错误检测模块的过检测问题。实验结果表明，PMF-CEC在保持推理速度的同时，显著降低了词错误率，尤其在纠正同音异形词方面表现出更强的优势，且在效率和鲁棒性方面优于其他方法。

> **摘要翻译:** 端到端自动语音识别（ASR）模型通常难以准确识别稀有词。此前，我们引入了一种名为错误检测和上下文感知纠错（ED-CEC）的ASR后处理方法，该方法利用命名实体和技术术语等上下文信息来提高ASR转录的准确性。尽管ED-CEC在纠正稀有词方面取得了显著成功，但在处理发音相似但拼写不同的稀有词时，其准确性仍然较低。为了解决这个问题，我们在ED-CEC的基础上提出了一种用于上下文感知纠错的音素增强多模态融合方法（PMF-CEC），该方法可以更好地区分目标稀有词和同音异形词。此外，我们观察到之前的ASR错误检测模块存在过检测问题。为了缓解这个问题，我们引入了一种保留概率机制，用于过滤掉置信度低于设定阈值的编辑操作，从而保留原始操作以提高错误检测准确性。在五个数据集上进行的实验表明，我们提出的PMF-CEC在保持合理推理速度的同时，与ED-CEC相比进一步降低了偏置词错误率，在纠正同音异形词方面显示出更强的优势。此外，我们的方法优于其他上下文偏置方法，并且在更快的推理速度和在大型偏置列表下更好的鲁棒性方面，相对于基于LLM的方法仍有价值。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [51] [Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition](https://arxiv.org/abs/2506.11069)
> *保护隐私的构音障碍和老年人语音识别的正则化联邦学习*

*Tao Zhong, Mengzhe Geng, Shujie Hu, Guinan Li, Xunying Liu* | **Main category: eess.AS**

**Keywords:** 联邦学习, 构音障碍语音识别, 老年人语音识别, 正则化, 隐私保护

**Comment:** 

> **TL;DR:** 本文系统研究了正则化联邦学习技术在保护隐私的构音障碍和老年人语音识别中的应用，通过参数、嵌入和基于损失的正则化方法，显著提高了识别性能，甚至接近集中式训练水平。

**AI_Comments:** 这篇论文的创新点在于将正则化技术系统地应用于联邦学习框架，以解决特殊人群（构音障碍和老年人）语音识别中的隐私保护和数据挑战。其重要性体现在为医疗健康领域中敏感语音数据的处理提供了有效且保护隐私的解决方案。通过探索不同层面的正则化方法，为未来联邦学习在复杂真实世界应用中的性能提升提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 准确识别构音障碍和老年人语音仍然具有挑战性。尽管联邦学习（FL）解决了数据隐私问题，但它加剧了数据稀缺、数据分布不平衡和说话人异质性等挑战，因此需要改进FL方法来应对这些问题。

**Method:** 本文系统研究了正则化联邦学习（FL）技术，通过三种不同层面的正则化方法来解决FL过程中的挑战：1) 基于参数的正则化，2) 基于嵌入的正则化，以及 3) 新颖的基于损失的正则化。

**Result:** 在UASpeech构音障碍语音语料库和DementiaBank Pitt老年语音语料库上的实验表明，正则化联邦学习系统始终优于基线FedAvg系统，词错误率（WER）绝对降低高达0.55%（相对降低2.13%），具有统计学显著性。进一步将通信频率增加到每批次一次交换可以接近集中式训练的性能。

**Conclusion:** 正则化联邦学习是解决构音障碍和老年人语音识别中数据隐私、数据稀缺、分布不平衡和说话人异质性等挑战的有效方法，能够显著提高识别性能，并有望在增加通信频率的情况下达到集中式训练的水平。

> **ai_Abstract:** 本文系统研究了将正则化技术应用于保护隐私的联邦学习，以提升构音障碍和老年人语音识别的准确性。研究通过参数、嵌入和损失函数层面的正则化方法，有效缓解了联邦学习在处理此类语音数据时面临的数据稀缺、分布不平衡和说话人异质性等问题。实验结果表明，正则化联邦学习系统显著优于基线FedAvg，并在增加通信频率后性能接近集中式训练。

> **摘要翻译:** 迄今为止，准确识别构音障碍和老年人语音仍然具有挑战性。尽管隐私问题促使人们从集中式方法转向联邦学习（FL）以确保数据机密性，但这进一步加剧了数据稀缺、数据分布不平衡和说话人异质性等挑战。为此，本文对用于保护隐私的构音障碍和老年人语音识别的正则化联邦学习技术进行了系统研究，通过1）基于参数、2）基于嵌入和3）新颖的基于损失的正则化来解决联邦学习过程的不同层面问题。在基准UASpeech构音障碍和DementiaBank Pitt老年语音语料库上进行的实验表明，正则化联邦学习系统始终优于基线FedAvg系统，词错误率（WER）统计学显著降低高达0.55%（相对降低2.13%）。进一步将通信频率增加到每批次一次交换可以接近集中式训练的性能。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [79] [Embedded Acoustic Intelligence for Automotive Systems](https://arxiv.org/abs/2506.11071)
> *汽车系统嵌入式声学智能*

*Renjith Rajagopal, Peter Winzell, Sladjana Strbac, Konstantin Lindström, Petter Hörling, Faisal Kohestani, Niloofar Mehrzad* | **Main category: eess.AS**

**Keywords:** 声学智能, 汽车系统, 路面分类, 深度神经网络, ADAS

**Comment:** 

> **TL;DR:** 该研究利用嵌入式声学智能，通过分析车载麦克风收集的声学特征，利用深度神经网络和预训练模型来分类路面类型，以支持自动驾驶和高级驾驶辅助系统，并为城市规划提供见解。

**AI_Comments:** 该论文的创新点在于将声学智能应用于汽车领域，特别是利用车载麦克风数据和深度学习技术进行路面类型识别。这不仅对AD/ADAS系统有直接应用价值，还为城市规划提供了新的数据维度，具有重要的实际意义。其利用Open AI生态系统预训练模型的做法，也体现了对现有先进技术的有效整合。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在将声音洞察转化为可操作的数据流，以增强汽车系统智能，从而解决路面类型识别问题，并支持自动驾驶、高级驾驶辅助系统、主动道路降噪以及城市规划。

**Method:** 该研究通过从安装在汽车轴距内的麦克风中提取和解释声学特征，利用深度神经网络和来自Open AI生态系统（通过Hugging Face）的预训练模型进行路面类型分类。

**Result:** 研究结果支持了下一代汽车系统的有力商业案例。

**Conclusion:** 通过将声学智能嵌入汽车系统，不仅有望重新定义乘客舒适度、提高车辆安全性，还为智能、数据驱动的城市道路管理铺平了道路，使未来的出行变得可行和可持续。

> **ai_Abstract:** 本研究提出一种嵌入式声学智能方法，通过分析车载麦克风捕捉到的声学特征，利用深度神经网络和预训练模型对路面类型进行分类。该技术旨在增强自动驾驶和高级驾驶辅助系统，支持道路噪声消除和城市规划，并为未来汽车系统提供商业价值，最终提升驾乘体验和城市交通管理。

> **摘要翻译:** 将声音洞察转化为可操作的数据流，本摘要利用学位论文研究成果来增强汽车系统智能，使我们能够识别路面类型[1]。通过提取和解释安装在汽车轴距内麦克风的声学特征，我们专注于路面类型分类。利用深度神经网络和由Open AI生态系统（通过Hugging Face [2]）的预训练模型提供支持的特征提取，我们的方法使自动驾驶和高级驾驶辅助系统（AD/ADAS）能够预测路面，支持主动道路噪声消除的自适应学习，并为城市规划生成有价值的见解。本研究的结果专门用于支持下一代汽车系统的有力商业案例。这种前瞻性方法不仅有望重新定义乘客舒适度并提高车辆安全性，而且为智能、数据驱动的城市道路管理铺平了道路，使未来的出行既可行又可持续。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [106] [Can We Trust Machine Learning? The Reliability of Features from Open-Source Speech Analysis Tools for Speech Modeling](https://arxiv.org/abs/2506.11072)
> *我们能相信机器学习吗？开源语音分析工具特征在语音建模中的可靠性*

*Tahiya Chowdhury, Veronica Romero* | **Main category: eess.AS**

**Keywords:** 机器学习, 语音分析工具, 可靠性, 偏见, 自闭症

**Comment:** 5 pages, 1 figure, 3 tables

> **TL;DR:** 本研究评估了开源语音分析工具（OpenSMILE和Praat）提取的语音特征在自闭症青少年中的可靠性，发现工具间特征存在显著差异，并影响模型性能，强调了在临床应用中进行领域相关验证的重要性。

**AI_Comments:** 这篇论文揭示了机器学习在临床应用中一个关键但常被忽视的问题：输入特征的可靠性。其创新之处在于明确指出了开源工具在缺乏验证时可能引入的偏见和对模型性能的影响。重要性在于它呼吁在将机器学习应用于敏感领域（如医疗）时，必须对数据预处理工具进行严格的领域特定验证，这对确保模型的公平性、可信赖性和可重现性至关重要。论文的局限性在于只评估了两种工具和特定人群（自闭症青少年），但其提出的问题具有普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 基于机器学习的行为模型依赖于从音视频记录中提取的特征，但用于提取这些特征的开源工具通常缺乏验证，无法确保其在捕获行为相关信息方面的可靠性。这种空白引发了对跨不同人群和环境的可重现性和公平性的担忧，尤其是在设计上下文之外使用时，可能导致偏见。

**Method:** 研究评估了从OpenSMILE和Praat这两种广泛使用的语音分析工具中提取的语音特征，以评估它们在考虑自闭症青少年时的可靠性。

**Result:** 研究观察到不同工具提取的特征之间存在显著差异，这些差异影响了跨上下文和人口统计群体的模型性能。

**Conclusion:** 本研究鼓励进行领域相关的验证，以提高机器学习模型在临床应用中的可靠性。

> **ai_Abstract:** 本研究探讨了开源语音分析工具OpenSMILE和Praat提取的语音特征在机器学习行为模型中的可靠性问题，特别是在自闭症青少年群体中。研究发现，不同工具提取的特征存在显著差异，这些差异进而影响了模型的性能，并可能导致偏见。鉴于此，论文强调了在临床应用中对这些工具进行领域相关验证的重要性，以确保机器学习模型的可靠性。

> **摘要翻译:** 基于机器学习的行为模型依赖于从视听记录中提取的特征。这些记录使用开源工具进行处理，以提取语音特征用于分类模型。这些工具通常缺乏验证，无法确保其在捕获行为相关信息方面的可靠性。这一空白引发了对跨不同人群和环境的可重现性和公平性的担忧。语音处理工具在超出其设计上下文使用时，可能无法公平地捕获行为变异，进而导致偏见。我们评估了从两种广泛使用的语音分析工具OpenSMILE和Praat中提取的语音特征，以评估其在考虑自闭症青少年时的可靠性。我们观察到工具间特征存在相当大的差异，这影响了跨上下文和人口统计群体的模型性能。我们鼓励进行领域相关的验证，以增强机器学习模型在临床应用中的可靠性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [133] [Challenges in Automated Processing of Speech from Child Wearables: The Case of Voice Type Classifier](https://arxiv.org/abs/2506.11074)
> *儿童可穿戴设备语音自动处理的挑战：以语音类型分类器为例*

*Tarek Kunze, Marianne Métais, Hadrien Titeux, Lucas Elbert, Joseph Coffey, Emmanuel Dupoux, Alejandrina Cristia, Marvin Lavechin* | **Main category: eess.AS**

**Keywords:** 儿童语音, 可穿戴设备, 语音类型分类, 数据质量, 自动化处理

**Comment:** 5 pages, 3 figures

> **TL;DR:** 针对儿童可穿戴设备语音数据，语音类型分类器的自动化处理面临挑战，模型改进效果有限，数据质量和数量更为关键。

**AI_Comments:** 这篇论文揭示了在处理儿童可穿戴设备语音数据时，数据本身的重要性远超模型或算法的微调。其创新点在于强调了“数据为王”的理念在这一特定领域的体现，并指出了数据共享在推动研究进展中的关键作用，这对于未来的研究方向具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在解决儿童可穿戴设备收集的大量语音数据转化为可用信息所面临的挑战，特别是语音类型分类这一基础任务的自动化处理问题。

**Method:** 通过总结三年来的实验，研究了表示特征、架构和参数搜索对语音类型分类器性能的影响，并探讨了数据相关性和数量的重要性。

**Result:** 实验表明，改进表示特征、架构和参数搜索对性能提升贡献微乎其微。更显著的进展来自于关注数据的相关性和数量。

**Conclusion:** 自动化处理儿童可穿戴设备语音数据的关键在于高质量和足够数量的数据，而非仅仅依赖于模型或特征的改进；同时强调了数据共享的重要性。

> **ai_Abstract:** 本文探讨了儿童可穿戴设备语音数据自动化处理的挑战，特别是针对语音类型分类任务。研究发现，尽管在模型特征、架构和参数优化上投入努力，性能提升却很小。相反，数据的相关性和数量对性能提升至关重要，这强调了获取适当许可进行数据共享的重要性。

> **摘要翻译:** 儿童可穿戴设备收集的录音有望通过轻松捕捉儿童的自然语言环境和语言产出来彻底改变基础和应用语音科学。这一承诺取决于能够将收集到的大量数据转化为可用信息的语音技术。本文通过总结旨在改进一项基本任务——语音类型分类——的三年实验，展示了阻碍进展的几个障碍。我们的实验表明，表示特征、架构和参数搜索的改进对性能的提升贡献微乎其微。通过关注数据的相关性和数量取得了更大的进展，这突出了在获得适当许可的情况下收集数据以允许共享的重要性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [157] [Fifteen Years of Child-Centered Long-Form Recordings: Promises, Resources, and Remaining Challenges to Validity](https://arxiv.org/abs/2506.11075)
> *儿童中心长时录音的十五年：前景、资源与有效性的挑战*

*Loann Peurey, Marvin Lavechin, Tarek Kunze, Manel Khentout, Lucas Gautheron, Emmanuel Dupoux, Alejandrina Cristia* | **Main category: eess.AS**

**Keywords:** 儿童语言研究, 长时录音, 数据质量, 自动化分析, 故障排除

**Comment:** 5 pages, 3 figures

> **TL;DR:** 本文总结了儿童语言研究中长时录音技术的发展，探讨了其前景、现有资源、数据质量挑战，并提出了数据质量评估和改进策略。

**AI_Comments:** 这篇论文的重要性在于它对儿童语言研究中一个关键数据收集方法——长时录音——进行了全面的回顾和反思。它不仅总结了现有资源和该技术的优点，更重要的是，它直面了数据量大、自动化分析挑战以及数据质量控制的痛点。提出故障排除指标和实用策略，为研究人员提供了宝贵的指导，有助于提升该领域研究的严谨性和有效性。其创新之处在于对现有问题进行了系统梳理并提出了务实的解决方案，而非仅仅停留在技术介绍层面。

<details>
  <summary>Details</summary>

**Motivation:** 儿童语言研究中，通过儿童佩戴设备收集的长时间音频记录是基本工具，具有捕获儿童输入和输出、减少观察者偏差的潜力。但大量数据需要自动化分析，且存在自动化标注准确性和结果解释的误差来源，因此需要总结现有知识并解决数据质量问题。

**Method:** 本文总结了该技术的集体知识，提供了现有资源的入口；强调了威胁自动化标注准确性和结果解释的各种误差来源；提出了潜在的故障排除指标来帮助用户评估数据质量；并概述了研究人员改进数据收集和分析的实用策略。

**Result:** 本文没有呈现具体实验结果，而是总结了集体知识，指出了误差来源，并提出了解决数据质量问题的指标和策略。

**Conclusion:** 尽管完全自动化的质量控制系统不可行，但研究人员可以通过采纳本文概述的实用策略来提高数据收集质量并更好地情境化其分析。

> **ai_Abstract:** 这篇论文总结了儿童语言研究中长时音频记录技术十五年来的发展。它探讨了这种通过儿童佩戴设备收集数据的潜力，即以最小偏见捕获儿童语言数据，并指出自动化分析的必要性。论文识别并强调了自动化标注和指标解释中可能出现的误差来源，并提出了评估数据质量的故障排除指标。最终，本文为研究人员提供了改进数据收集和分析的实用策略，尽管完全自动化的质量控制系统仍不可行。

> **摘要翻译:** 采用儿童佩戴设备收集的音频记录是儿童语言研究的基本工具。全天候收集的长时录音有望以最小的观察者偏见捕获儿童的输入和产出，从而具有高有效性。由此产生的数据量巨大，需要自动化分析来为研究人员和临床医生提取相关指标。本文总结了这项技术的集体知识，提供了现有资源的入口。我们还强调了各种误差来源，它们威胁着自动化标注的准确性以及由此产生指标的解释。为了解决这个问题，我们提出了潜在的故障排除指标，以帮助用户评估数据质量。虽然完全自动化的质量控制系统不可行，但我们概述了研究人员改进数据收集和情境化其分析的实用策略。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [176] [Improving Child Speech Recognition and Reading Mistake Detection by Using Prompts](https://arxiv.org/abs/2506.11079)
> *通过使用提示词改进儿童语音识别和阅读错误检测*

*Lingyun Gao, Cristian Tejedor-Garcia, Catia Cucchiarini, Helmer Strik* | **Main category: eess.AS**

**Keywords:** 儿童语音识别, 阅读错误检测, 提示词, Whisper, 大型语言模型

**Comment:** This paper is accepted to Interspeech 2025. This publication is part
  of the project Responsible AI for Voice Diagnostics (RAIVD) with file number
  NGF.1607.22.013 of the research programme NGF AiNed Fellowship Grants which
  is financed by the Dutch Research Council (NWO)

> **TL;DR:** 本文提出一种新颖的多模态方法，通过使用提示词改进Whisper和LLM，显著提高了儿童语音识别和阅读错误检测的性能。

**AI_Comments:** 本文创新性地将提示词技术应用于Whisper和LLM，以解决儿童语音识别和阅读错误检测的挑战，提供了一种有效且高效的自动化评估方案，对教育技术领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动朗读评估能为教师提供有效支持，但相关研究和应用有限。

**Method:** 提出一种新颖的多模态方法，结合音频和文本资源知识，特别是探索了使用提示词改进Whisper和指令微调的大型语言模型（LLMs），以提高儿童语音转录和阅读错误检测的有效性。

**Result:** 相比无提示词的基线Whisper模型，使用提示词显著提高了性能。最佳系统在荷兰语儿童朗读语音识别上达到5.1%的词错误率（WER），将基线WER从9.4%提高；阅读错误检测的F1分数从0.39显著提高到0.73。

**Conclusion:** 结合提示词的Whisper和LLM方法能有效提高儿童语音识别和阅读错误检测的准确性，达到先进水平。

> **ai_Abstract:** 本文提出了一种新颖的多模态方法，通过结合音频和文本资源知识，并利用提示词改进Whisper模型和指令微调的大型语言模型（LLMs），旨在提高儿童语音识别的转录质量及后续阅读错误检测的准确性。实验结果表明，该方法显著优于无提示词的基线模型，在荷兰语儿童朗读语音识别中将词错误率从9.4%降至5.1%，并在阅读错误检测中将F1分数从0.39提升至0.73，达到了先进水平。

> **摘要翻译:** 自动朗读评估可以通过更高效地评分阅读练习，为教师提供宝贵支持。然而，关于阅读评估系统和应用的研究仍然有限。我们提出了一种新颖的多模态方法，利用音频和文本资源的知识。特别是，我们探索了使用Whisper和指令微调的大型语言模型（LLMs）结合提示词来改进儿童语音识别的转录，以及它们在后续阅读错误检测中的有效性。我们的结果表明，与没有使用提示词的基线Whisper模型相比，对Whisper和LLM进行提示词处理是有效的。表现最佳的系统在荷兰语儿童朗读语音方面取得了最先进的识别性能，词错误率（WER）为5.1%，将基线WER从9.4%提高。此外，它显著改善了阅读错误检测，将F1分数从0.39提高到0.73。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [195] [Intelligibility of Text-to-Speech Systems for Mathematical Expressions](https://arxiv.org/abs/2506.11086)
> *数学表达式文本转语音系统可懂度研究*

*Sujoy Roychowdhury, H. G. Ranjani, Sumit Soman, Nishtha Paul, Subhadip Bandyopadhyay, Siddhanth Iyengar* | **Main category: eess.AS**

**Keywords:** 文本转语音, 数学表达式, 可懂度, 大型语言模型, 语音合成

**Comment:** Accepted at Interspeech 2025

> **TL;DR:** 评估了五种TTS模型处理数学表达式的可懂度，发现其性能不佳，且远低于人工朗读，需要改进。

**AI_Comments:** 这项研究填补了TTS模型在数学表达式处理方面评估的空白，揭示了当前TTS技术在此领域的局限性。其创新在于结合了LLMs处理LaTeX输入，并提出了多维度评估方法。研究结果对于未来TTS系统在科学、工程等领域应用具有重要指导意义，强调了提升数学表达式语音合成质量的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 目前对处理数学表达式（MX）的高级文本转语音（TTS）模型的评估有限，需要对其质量和可懂度进行深入评估。

**Method:** 设计实验评估五种TTS模型对不同类别MX的质量和可懂度。使用两个大型语言模型（LLMs）从LaTeX MX生成英文发音，因为TTS模型无法直接处理LaTeX。通过用户评分的平均意见得分（MOS）和转录正确性（使用三种指标）量化可懂度。还将TTS输出与人类专家朗读进行听觉偏好比较。

**Result:** TTS模型对MX的输出不一定可懂，可懂度差距因TTS模型和MX类别而异。对于大多数类别，TTS模型的性能显著差于专家朗读。LLM选择的影响有限。

**Conclusion:** 迫切需要改进用于数学表达式的文本转语音（TTS）模型。

> **ai_Abstract:** 本文评估了五种文本转语音（TTS）模型在处理数学表达式（MX）时的可懂度。研究通过听力和转录测试，并结合平均意见得分和转录正确性指标进行量化。结果显示，TTS模型对MX的可懂度普遍不高，且显著低于人类专家朗读，同时大型语言模型（LLM）的选择影响有限。研究强调了改进数学表达式TTS模型的必要性。

> **摘要翻译:** 目前对处理数学表达式（MX）的高级文本转语音（TTS）模型的评估有限。在这项工作中，我们设计实验，通过听力和转录测试，评估了五种TTS模型对各种类别MX的质量和可懂度。我们使用两个大型语言模型（LLMs）从LaTeX MX生成英文发音，因为TTS模型无法直接处理LaTeX。我们使用用户评分的平均意见得分（Mean Opinion Score）并通过三种指标的转录正确性来量化可懂度。我们还将TTS输出与人类专家对相同MX的朗读进行听觉偏好比较。结果表明，TTS模型对MX的输出不一定可懂，可懂度差距因TTS模型和MX类别而异。对于大多数类别，TTS模型的性能显著差于专家朗读。LLM选择的影响有限。这表明需要改进用于MX的TTS模型。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [214] [Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM](https://arxiv.org/abs/2506.11089)
> *通过多ASR融合和SpeechLLM纠错改进伪标签*

*Jeena Prakash, Blessingh Kumar, Kadri Hacioglu, Bidisha Sharma, Sindhuja Gopalan, Malolan Chetlur, Shankar Venkatesan, Andreas Stolcke* | **Main category: eess.AS**

**Keywords:** ASR, 伪标签, LLM, 多ASR融合, 错误纠正

**Comment:** 

> **TL;DR:** 本文提出了一个统一的多ASR提示驱动框架，利用文本或基于语音的大型语言模型（LLM）进行后处理，以改进伪标签的生成，从而显著提高了转录准确性，并提升了半监督ASR模型的性能。

**AI_Comments:** 该论文的创新之处在于利用大型语言模型（LLM）来统一处理多ASR输出的融合和错误纠正，取代了传统的投票或仲裁机制。这种方法有效地解决了现有伪标签生成过程中错误传播和优化分离的问题，为半监督ASR训练提供了更准确的数据。

<details>
  <summary>Details</summary>

**Motivation:** 自动语音识别（ASR）模型依赖高质量的转录数据进行有效训练。为大量未标记音频数据集生成伪标签通常依赖于复杂的管道，这些管道通过多阶段处理结合多个ASR输出，导致错误传播、信息丢失和不连贯的优化。

**Method:** 我们提出了一个统一的多ASR提示驱动框架，通过文本或基于语音的大型语言模型（LLM）进行后处理，取代了投票或其他仲裁逻辑来协调集成输出。

**Result:** 我们对有无LLM的多种架构进行了比较研究，结果显示与传统方法相比，转录准确性显著提高。此外，我们使用各种方法生成的伪标签来训练不同数据集的半监督ASR模型，再次表明与基线相比，文本和SpeechLLM转录的性能有所改善。

**Conclusion:** 通过利用大型语言模型进行多ASR融合和错误纠正，可以有效改善伪标签的质量，从而显著提高转录准确性，并提升半监督ASR模型的性能。

> **ai_Abstract:** 本研究提出了一种创新的统一多ASR提示驱动框架，利用大型语言模型（LLM），包括文本和基于语音的LLM，对多ASR输出进行后处理，以生成更高质量的伪标签。该方法旨在解决传统多ASR融合管道中存在的错误传播和信息丢失问题。实验结果表明，与传统方法相比，该框架显著提高了转录准确性，并且使用由此生成的伪标签训练的半监督ASR模型也表现出更好的性能。

> **摘要翻译:** 自动语音识别（ASR）模型依赖高质量的转录数据进行有效训练。为大量未标记音频数据集生成伪标签通常依赖于复杂的管道，这些管道通过多阶段处理结合多个ASR输出，导致错误传播、信息丢失和不连贯的优化。我们提出了一个统一的多ASR提示驱动框架，通过文本或基于语音的大型语言模型（LLM）进行后处理，取代了投票或其他仲裁逻辑来协调集成输出。我们对有无LLM的多种架构进行了比较研究，结果显示与传统方法相比，转录准确性显著提高。此外，我们使用各种方法生成的伪标签来训练不同数据集的半监督ASR模型，再次表明与基线相比，文本和SpeechLLM转录的性能有所改善。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [228] [Tracking of Intermittent and Moving Speakers : Dataset and Metrics](https://arxiv.org/abs/2506.11145)
> *间歇性移动说话人追踪：数据集与评估指标*

*Taous Iatariene, Alexandre Guérin, Romain Serizel* | **Main category: eess.AS**

**Keywords:** 间歇性说话人, 说话人追踪, 不连续轨迹, LibriJump, 关联指标

**Comment:** 

> **TL;DR:** 本论文探讨了间歇性移动声源的追踪问题，引入了一个新数据集LibriJump和一套从计算机视觉领域改编的评估指标，以处理不连续的轨迹。

**AI_Comments:** 该论文通过关注间歇性移动说话人这一真实但常被忽视的场景，填补了说话人追踪研究中的一个重要空白。LibriJump数据集的引入是一项宝贵贡献，为该领域的研究提供了急需的资源。从计算机视觉领域借鉴评估指标是一种创新方法，有助于更准确地评估身份分配，突显了该问题的跨学科性质。研究结果表明，该论文为说话人追踪提供了一个更稳健的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数追踪方法依赖于连续的空间观测来管理追踪身份，但在声源不活跃时改变位置（导致不连续空间轨迹）的情况下，这些方法难以维持可靠的身份分配性能。这个问题鲜有探索。

**Method:** 引入了LibriJump数据集，这是一个以一阶声场格式呈现的声学场景数据集，专门用于模拟说话人在不活跃期间改变位置的场景。提出了使用从计算机视觉领域改编的追踪关联指标来衡量身份分配性能。

**Result:** 实验结果表明，所提出的关联指标与先前使用的追踪指标在处理连续和不连续空间轨迹时具有互补性。

**Conclusion:** 该论文通过提供一个新数据集和适配的评估指标，有效解决了间歇性移动说话人追踪这一具有挑战性的问题，特别是对不连续轨迹的追踪。

> **ai_Abstract:** 本论文旨在解决间歇性移动说话人的追踪难题，即声源在不活跃期间位置可能发生变化，导致空间轨迹不连续。针对现有方法在此类复杂情况下的身份保持困境，作者引入了LibriJump数据集，该数据集以一阶声场格式，专门模拟了说话人位置在静默期发生变化的情景。为准确评估身份分配性能，论文提出采用源自计算机视觉领域的追踪关联指标。实验证明，这些新引入的关联指标与传统追踪指标互补，尤其适用于处理不连续的空间轨迹。

> **摘要翻译:** 这篇论文提出了追踪间歇性移动声源的问题，即那些在不活跃时可能改变位置的声源。这个问题鲜有探索，大多数当前的追踪方法依赖于空间观测来管理追踪身份。它们要么基于先前的定位步骤，要么旨在通过预测有序位置估计来执行联合定位和追踪。这引发了人们的担忧，即当处理不连续的空间轨迹（可能由静默期间的方向改变引起）时，这些方法能否保持可靠的追踪身份分配性能。我们引入了LibriJump，这是一个新颖的声学场景数据集，采用一阶声场格式，专注于说话人追踪。该数据集包含在不活跃期间位置发生变化的说话人，从而模拟不连续轨迹。为了衡量身份分配性能，我们建议使用从计算机视觉领域改编的追踪关联指标。我们提供的实验表明，在给定连续和不连续空间轨迹的情况下，关联指标与先前使用的追踪指标具有互补性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [243] [Improved in-car sound pick-up using multichannel Wiener filter](https://arxiv.org/abs/2506.11157)
> *使用多通道维纳滤波器改进车载拾音*

*Juhi Khalid, Martin Bouchard* | **Main category: eess.AS**

**Keywords:** 车载拾音, 多通道维纳滤波器, 语音增强, 噪声抑制, 双麦克风系统

**Comment:** 6 pages

> **TL;DR:** 本文提出了一种利用多通道维纳滤波器（Multichannel Wiener Filter）在车载双麦克风系统中增强语音质量的方法，旨在减轻回声引起的陷波滤波效应并改善背景噪声抑制，实验证明该方法优于简单的麦克风信号混合。

**AI_Comments:** 该论文解决了车载环境下语音拾音的关键挑战，即回声和背景噪声。其创新之处在于应用多通道维纳滤波器来优化双麦克风系统，并考虑了实际使用中的头部运动效应，这对于车载通信和语音控制的实际应用具有重要意义。该方法相较于简单的信号混合有显著提升，显示了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 随着汽车电子和传感器的发展，多麦克风拾音在车载免提电话和语音命令应用中变得可行。然而，由于带宽或处理限制，有效处理多麦克风信号仍然面临挑战。

**Method:** 本文研究了在车载双麦克风系统中使用多通道维纳滤波器算法，以增强驾驶员和乘客语音的语音质量，即减轻由回声引起的陷波滤波效应并改善背景噪声抑制。通过使用现代客观指标（如深度噪声抑制平均意见得分）在各种噪声条件下评估其性能，并调查了驾驶员/乘客头部运动的影响。

**Result:** 所提出的方法与简单的麦克风信号混合相比，显示出显著的改进。

**Conclusion:** 使用多通道维纳滤波器在车载双麦克风系统中可以显著改善语音质量，优于简单的麦克风信号混合。

> **ai_Abstract:** 本文提出了一种利用多通道维纳滤波器在车载双麦克风系统中改善语音拾音质量的方法。该方法旨在减轻回声造成的陷波滤波效应并增强背景噪声抑制。通过在不同噪声条件下使用客观指标（如Deep Noise Suppression Mean Opinion Score）评估，并考虑头部运动的影响，结果表明该方法相比简单的麦克风信号混合有显著提升。

> **摘要翻译:** 随着汽车电子和传感器的发展，使用多个麦克风进行拾音已在车载免提电话和语音命令应用中变得可行。然而，由于带宽或处理限制，有效处理多个麦克风信号仍然面临挑战。本工作探索了在车载双麦克风系统中使用多通道维纳滤波器算法，以增强驾驶员和乘客语音的语音质量，即减轻由回声引起的陷波滤波效应并改善背景噪声抑制。我们使用现代客观指标（如深度噪声抑制平均意见得分）在各种噪声条件下评估其性能。还研究了驾驶员/乘客头部运动的影响。结果表明，所提出的方法比简单的麦克风信号混合提供了显著的改进。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [260] [S2ST-Omni: An Efficient and Scalable Multilingual Speech-to-Speech Translation Framework via Seamlessly Speech-Text Alignment and Streaming Speech Decoder](https://arxiv.org/abs/2506.11160)
> *S2ST-Omni：一种通过无缝语音-文本对齐和流式语音解码器实现的有效且可扩展的多语言语音到语音翻译框架*

*Yu Pan, Yuguang Yang, Yanni Hu, Jianhao Ye, Xiang Zhang, Hongbin Zhou, Lei Ma, Jianjun Zhao* | **Main category: eess.AS**

**Keywords:** 多语言语音到语音翻译, S2ST, 语音-文本对齐, 流式解码器, 预训练模型

**Comment:** Working in progress

> **TL;DR:** S2ST-Omni是一种高效且可扩展的多语言语音到语音翻译框架，通过将语音到文本翻译和文本到语音合成统一到一个端到端模型中，并利用预训练模型和流式解码器来提高质量并减少对大规模并行语料库的依赖。

**AI_Comments:** S2ST-Omni的创新之处在于其将复杂的S2ST任务分解为S2TT和TTS，并通过整合大型预训练模型（如Whisper和Qwen 3.0）并引入轻量级语音适配器，有效缓解了对大规模并行语音语料库的依赖，同时提升了翻译质量。采用流式语音解码器也确保了实时性能，使其在实际部署中具有很强的实用价值。这种模块化且高效的架构为多语言S2ST领域提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有多语言语音到语音翻译（S2ST）面临两大挑战：1) 难以实现高质量和低延迟的S2ST；2) 严重依赖难以收集的大规模并行语音语料库。

**Method:** 本文提出了S2ST-Omni框架。该框架将S2ST任务分解为语音到文本翻译（S2TT）和文本到语音合成（TTS），并将其统一到单个端到端语音-语言模型中。为实现高质量S2TT并减少对并行语料库的依赖，利用了大型预训练模型（Whisper用于音频理解，Qwen 3.0用于文本理解）。引入了一个轻量级语音适配器来对齐语音和文本表示。在TTS阶段采用预训练流式语音解码器以自回归方式生成目标语音，确保翻译质量和实时性能。

**Result:** 在CVSS基准测试中，S2ST-Omni优于最先进的S2ST基线，同时保持了可比的延迟。

**Conclusion:** S2ST-Omni框架在多语言语音到语音翻译方面表现出有效性和实际部署潜力，解决了高质量、低延迟和数据依赖的问题。

> **ai_Abstract:** 本文提出了S2ST-Omni，一个高效且可扩展的多语言语音到语音翻译框架，旨在解决现有S2ST方法面临的高质量、低延迟和大规模并行语料库依赖问题。该框架将S2ST任务分解为S2TT和TTS，并统一于一个端到端语音-语言模型。通过利用Whisper和Qwen 3.0等大型预训练模型以及轻量级语音适配器进行语音-文本对齐，并结合流式语音解码器，S2ST-Omni在CVSS基准测试上取得了优于SOTA基线的性能，并保持了可比的延迟，展现了其在实际应用中的巨大潜力。

> **摘要翻译:** 多语言语音到语音翻译（S2ST）旨在将多种源语言的口语表达直接转换为目标语言中自然且可理解的语音。尽管最近取得了进展，但仍存在重大挑战：(1) 实现高质量和低延迟的S2ST仍然是一个关键障碍；(2) 现有S2ST方法严重依赖大规模并行语音语料库，而这些语料库极难收集。为了解决这些问题，我们提出了S2ST-Omni，一个高效且可扩展的多语言语音到语音翻译框架。具体来说，我们将S2ST任务分解为语音到文本翻译（S2TT）和文本到语音合成（TTS），并将它们统一到一个单一的端到端语音-语言模型中。为了在减少对并行语料库依赖的同时实现高质量S2TT，我们利用大型预训练模型——用于音频理解的Whisper和用于文本理解的Qwen 3.0。引入了一个轻量级语音适配器来对齐语音和文本表示，从而有效利用预训练的多模态知识。为了确保翻译质量和实时性能，我们在TTS阶段采用了一个预训练的流式语音解码器，以自回归方式生成目标语音。在CVSS基准测试上的大量实验表明，S2ST-Omni优于最先进的S2ST基线，同时保持了可比的延迟，突显了其在实际部署中的有效性和潜在价值。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [274] [Advances in Small-Footprint Keyword Spotting: A Comprehensive Review of Efficient Models and Algorithms](https://arxiv.org/abs/2506.11169)
> *小型关键字识别的进展：高效模型和算法的综合回顾*

*Soumen Garai, Suman Samui* | **Main category: eess.AS**

**Keywords:** 小型关键字识别, 边缘设备, 深度学习, 模型压缩, TinyML

**Comment:** 61 pages, 21 figures

> **TL;DR:** 本文综述了小型关键字识别（SF-KWS）领域的高效模型和算法，旨在为在边缘设备上部署SF-KWS提供指导，并识别未来的研究方向。

**AI_Comments:** 这篇综述论文具有重要意义，因为它系统地分类并分析了小型关键字识别（SF-KWS）在边缘设备上部署所需的各种高效技术。鉴于智能边缘设备市场的增长，其对TinyML效率的关注尤其及时和相关，为该领域的研究人员提供了清晰的指导和潜在的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 小型关键字识别（SF-KWS）在智能语音设备和物联网应用中日益普及，但将其部署到低功耗、内存受限的边缘设备上需要高效的微型机器学习（TinyML）框架。本研究旨在提供一个全面的综述，以理解、利用或促进SF-KWS领域的发展。

**Method:** 本研究探讨了七种适用于开发SF-KWS系统的不同技术类别：模型架构、学习技术、模型压缩、注意力感知架构、特征优化、神经网络搜索和混合方法。通过对这些技术的全面概述和分析，旨在识别潜在的研究方向。

**Result:** 本文提供了一个关于SF-KWS高效模型和算法的全面概述，并将其分为七个主要类别。分析结果揭示了众多潜在的研究方向，这些方向融合了自动语音识别和口语SF-KWS领域的见解。

**Conclusion:** 这份全面的综述为理解、利用或为SF-KWS领域做出贡献提供了宝贵的资源，并有助于识别未来的研究方向。

> **ai_Abstract:** 本文对小型关键字识别（SF-KWS）领域的高效模型和算法进行了全面综述。论文系统地探讨了七类关键技术，包括模型架构、学习技术、模型压缩、注意力感知架构、特征优化、神经网络搜索和混合方法，这些技术对于在低功耗、有限内存的边缘设备上部署SF-KWS至关重要。该综述旨在为SF-KWS领域提供宝贵资源，并结合自动语音识别的见解，识别未来的研究方向。

> **摘要翻译:** 小型关键字识别（SF-KWS）在当今智能语音激活设备、智能手机和物联网（IoT）应用领域已广受欢迎。这一兴起得益于深度学习的进步，使得从连续的词流中识别预定义的词或关键字成为可能。为了在真实场景中，将SF-KWS模型部署到低功耗、有限内存的边缘设备上，高效的微型机器学习（TinyML）框架至关重要。在本研究中，我们探讨了七种不同的技术类别，即模型架构、学习技术、模型压缩、注意力感知架构、特征优化、神经网络搜索和混合方法，这些技术都适用于开发SF-KWS系统。这份全面的综述将为那些希望了解、利用或为SF-KWS领域做出贡献的人提供宝贵的资源。本研究中进行的分析有助于识别出众多潜在的研究方向，其中包括来自自动语音识别研究的见解以及与口语SF-KWS领域特别相关的见解。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [286] [Efficient Speech Enhancement via Embeddings from Pre-trained Generative Audioencoders](https://arxiv.org/abs/2506.11514)
> *基于预训练生成式音频编码器嵌入的高效语音增强*

*Xingwei Sun, Heinrich Dinkel, Yadong Niu, Linzhang Wang, Junbo Zhang, Jian Luan* | **Main category: eess.AS**

**Keywords:** 语音增强, 音频嵌入, 生成式音频编码器, 去噪, 声码器

**Comment:** Accepted by Interspeech 2025

> **TL;DR:** 本文提出了一种高效且可扩展的语音增强方法，通过预训练生成式音频编码器提取并去噪嵌入，然后用声码器合成清晰语音，实验证明其在性能和感知质量上优于现有方法。

**AI_Comments:** 该论文的创新点在于将预训练的生成式音频编码器引入语音增强领域，并结合紧凑的去噪网络和声码器，形成一个高效且可扩展的端到端系统。其重要性在于提供了一种替代传统时频域方法的、基于嵌入的语音增强范式，并在性能和感知质量上取得了显著提升，尤其是在参数效率方面的验证，为未来相关研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音增强研究开始利用预训练模型的音频嵌入，而非传统的时间-频率掩蔽或信号预测技术。本文旨在引入一种高效且可扩展的语音增强方法，以提高性能和效率。

**Method:** 该方法首先使用预训练音频编码器从带噪语音中提取音频嵌入，然后通过紧凑的编码器网络对这些嵌入进行去噪。最后，声码器从去噪后的嵌入中合成清晰语音。

**Result:** 消融研究证实了去噪编码器结合预训练音频编码器和声码器的参数效率。在语音增强和说话人保真度方面的实验结果表明，基于生成式音频编码器的语音增强系统优于使用判别式音频编码器的模型。主观听力测试也验证了所提出的系统在感知质量上超越了现有的最先进语音增强模型。

**Conclusion:** 本文提出的基于预训练生成式音频编码器嵌入的语音增强系统，在效率、参数利用率、语音增强性能、说话人保真度以及感知质量方面均表现出色，并优于使用判别式编码器和现有最先进模型。

> **ai_Abstract:** 本文提出了一种高效的语音增强（SE）方法，它利用预训练生成式音频编码器提取的嵌入。该方法首先从带噪语音中提取音频嵌入，通过紧凑网络进行去噪，最后利用声码器合成清晰语音。实验证明，该方法在参数效率、语音增强性能和说话人保真度上优于判别式模型，并在感知质量上超越了现有先进技术。

> **摘要翻译:** 最近的研究深入探索了利用预训练模型音频嵌入的语音增强（SE）方法，这与时间-频率掩蔽或信号预测技术不同。本文介绍了一种高效且可扩展的SE方法。我们的方法包括：首先使用预训练音频编码器从带噪语音中提取音频嵌入，然后通过紧凑的编码器网络对这些嵌入进行去噪。随后，声码器从去噪后的嵌入中合成清晰语音。消融研究证实了去噪编码器与预训练音频编码器和声码器结合的参数效率。在语音增强和说话人保真度方面的实验结果表明，我们基于生成式音频编码器的SE系统优于使用判别式音频编码器的模型。此外，主观听力测试验证了我们提出的系统在感知质量上超越了现有的最先进SE模型。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [299] [From Sharpness to Better Generalization for Speech Deepfake Detection](https://arxiv.org/abs/2506.11532)
> *从锐度到语音深度伪造检测的更好泛化*

*Wen Huang, Xuechen Liu, Xin Wang, Junichi Yamagishi, Yanmin Qian* | **Main category: eess.AS**

**Keywords:** 语音深度伪造检测, 泛化, 锐度, 锐度感知最小化, 鲁棒性

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 本文提出锐度是语音深度伪造检测泛化能力的理论指标，并通过锐度感知最小化（SAM）提高了模型在未知数据集上的泛化性能和鲁棒性。

**AI_Comments:** 本文的创新之处在于首次将模型锐度作为语音深度伪造检测泛化的理论代理进行研究，并成功应用锐度感知最小化（SAM）来提升模型的泛化能力和鲁棒性。这为理解和改进SDD模型的泛化性能提供了一个新的理论视角和实用的训练策略，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 语音深度伪造检测（SDD）中，泛化能力仍是关键挑战，且目前缺乏解释模型性能的理论框架。

**Method:** 研究将锐度作为SDD中泛化的理论代理，分析锐度如何响应领域偏移，并应用锐度感知最小化（SAM）来显式降低锐度。

**Result:** 发现锐度在未知条件下增加，表明模型敏感性更高；SAM导致在多样化的未知测试集上获得更好、更稳定的性能；相关性分析证实锐度与泛化之间存在显著统计关系。

**Conclusion:** 锐度可以作为SDD中泛化的理论指标，锐度感知训练是提高鲁棒性的一种有前景的策略。

> **ai_Abstract:** 本文探讨了锐度在语音深度伪造检测（SDD）中作为泛化能力理论代理的潜力。研究发现锐度随领域偏移而增加，表明模型敏感性。通过应用锐度感知最小化（SAM）显式降低锐度，模型在多样化的未知测试集上表现出更优异且稳定的泛化性能。相关性分析进一步证实了锐度与泛化之间的显著关联。这些结果表明锐度是SDD泛化的有效理论指标，且锐度感知训练是提升模型鲁棒性的有效策略。

> **摘要翻译:** 泛化能力仍然是语音深度伪造检测（SDD）中的一个关键挑战。尽管各种方法旨在提高鲁棒性，但泛化能力通常通过等错误率等性能指标进行评估，而缺乏解释模型性能的理论框架。这项工作将锐度作为SDD中泛化的理论代理进行研究。我们分析了锐度如何响应领域偏移，发现它在未知条件下增加，表明模型敏感性更高。基于此，我们应用锐度感知最小化（SAM）来显式降低锐度，从而在多样化的未知测试集上获得更好、更稳定的性能。此外，相关性分析证实了在大多数测试设置中，锐度与泛化之间存在统计学上的显著关系。这些发现表明，锐度可以作为SDD中泛化能力的理论指标，并且锐度感知训练为提高鲁棒性提供了一种有前景的策略。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [311] [Lightweight and Robust Multi-Channel End-to-End Speech Recognition with Spherical Harmonic Transform](https://arxiv.org/abs/2506.11630)
> *轻量级、鲁棒的多通道端到端语音识别，基于球谐变换*

*Xiangzhu Kong, Huang Hao, Zhijian Ou* | **Main category: eess.AS**

**Keywords:** 球谐变换, 多通道语音识别, 跨阵列泛化, 轻量级, 鲁棒性

**Comment:** Interspeech 2025

> **TL;DR:** SHTNet是一种轻量级且鲁棒的多通道ASR框架，利用球谐变换、Spatio-Spectral Attention Fusion Network和Rand-SHT训练来解决跨阵列泛化问题，并显著减少计算量。

**AI_Comments:** SHTNet的创新点在于其利用球谐变换实现几何不变性，以及通过SSAFN和Rand-SHT在无需传统波束形成的情况下实现高效且鲁棒的跨阵列泛化。计算量的大幅减少是其重要优势，表明其在实际部署中具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决多通道自动语音识别（ASR）中跨阵列泛化的挑战。

**Method:** 该论文提出了SHTNet框架，包含三项关键创新：1. 基于SHT的空间声场分解，将麦克风信号转换为几何不变的球谐系数。2. Spatio-Spectral Attention Fusion Network（SSAFN）结合坐标感知空间建模、精炼的自注意力通道组合器和频谱噪声抑制，无需传统波束形成。3. Rand-SHT训练通过随机通道选择和阵列几何重建增强鲁棒性。

**Result:** 在Aishell-4、Alimeeting和XMOS等数据集上的异构阵列（如圆形、方形、双耳）上，实现了39.26%的平均CER。计算量比传统神经波束形成器减少97.1%。

**Conclusion:** 该论文提出的SHTNet通过创新的球谐变换方法，有效解决了多通道ASR的跨阵列泛化问题，并显著降低了计算成本，展现了其轻量级和鲁棒性。

> **ai_Abstract:** SHTNet是一个创新的多通道ASR框架，利用球谐变换将麦克风信号转换为几何不变的系数，并通过Spatio-Spectral Attention Fusion Network进行空间和频谱处理，无需传统波束形成。此外，Rand-SHT训练增强了系统的鲁棒性。该方法在异构阵列上表现出优异的性能（39.26% CER），并显著降低了计算成本（减少97.1%），有效解决了跨阵列泛化问题。

> **摘要翻译:** 这篇论文介绍了SHTNet，一个基于轻量级球谐变换（SHT）的框架，旨在通过三项关键创新解决多通道自动语音识别（ASR）中的跨阵列泛化挑战。首先，基于SHT的空间声场分解将麦克风信号转换为几何不变的球谐系数，从而将信号处理与阵列几何分离。其次，时空-频谱注意力融合网络（SSAFN）结合了坐标感知空间建模、精炼的自注意力通道组合器和频谱噪声抑制，而无需传统的波束形成。第三，Rand-SHT训练通过随机通道选择和阵列几何重建增强了鲁棒性。该系统在包含Aishell-4、Alimeeting和XMOS等数据集上的异构阵列（例如圆形、方形和双耳）上实现了39.26%的平均CER，计算量比传统神经波束形成器减少了97.1%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [319] [Tracking of Spatially Dynamic Room Impulse Responses Along Locally Linearized Trajectories](https://arxiv.org/abs/2506.11703)
> *沿局部线性化轨迹跟踪空间动态房间脉冲响应*

*Kathleen MacWilliam, Thomas Dietzen, Toon van Waterschoot* | **Main category: eess.AS**

**Keywords:** 房间脉冲响应, 轨迹跟踪, 线性化, 声学测量, 空间动态

**Comment:** 8 pages, 6 figures. Accepted paper for conference: Forum Acousticum
  Euronoise 2025 (fa-euronoise2025)

> **TL;DR:** 本文提出了一种通过将长轨迹分段为较小的线性区间，来扩展现有方法以估计更复杂房间环境中空间动态房间脉冲响应（RIRs）的方法，并在真实房间数据上验证了其有效性。

**AI_Comments:** 本文通过对现有方法的巧妙扩展，解决了其在实际应用中遇到的轨迹限制问题。通过将复杂轨迹分解为一系列可管理的线性段，极大地提高了方法的实用性和适用范围。在真实数据集上的验证也增加了研究的可信度。其创新点在于对复杂问题的分而治之策略，使得原本受限的方法能够应对更广泛的场景，对于需要动态RIRs的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 测量多空间点的房间脉冲响应（RIRs）耗时，而模拟RIRs需要详细的房间声学环境知识。先前的线性轨迹RIRs估计方法存在适用范围小且未经验证真实数据的限制。

**Method:** 本文提出了一种将现有方法实际扩展到更真实场景的方法。通过将较长的轨迹分段为较小的线性区间，并在这些分段上分段应用该方法，从而使之前的假设（直达声和单个反射的时间间隔不重叠）近似成立。

**Result:** 研究人员使用trajectoRIR数据库（包含移动麦克风记录和真实房间中受控L形轨迹上离散点的RIR测量数据）验证了该方法的有效性。

**Conclusion:** 通过将轨迹分段为局部线性区间并分段应用现有方法，可以将其适用性扩展到更复杂的房间环境，从而有效地跟踪空间动态房间脉冲响应。

> **ai_Abstract:** 本研究针对现有房间脉冲响应（RIRs）估算方法在复杂声学场景中适用性受限的问题，提出了一种改进方案。通过将较长的RIRs测量轨迹细分为多个局部线性区间，并在每个区间内分段应用原有的RIRs估算方法。这种分段策略有效地扩展了该方法在更复杂房间环境下的应用范围，并利用真实世界的trajectoRIR数据库验证了其有效性。

> **摘要翻译:** 在多个空间点测量房间脉冲响应（RIRs）是一项耗时的任务，而模拟则需要详细了解房间的声学环境。在之前的工作中，我们提出了一种在静态声源和麦克风匀速移动的时变声学场景中，沿线性轨迹估计RIRs早期部分的方法。这种方法依赖于轨迹起点和终点测量的RIRs，并假设沿轨迹的直达声和单个反射所占据的时间间隔不重叠。因此，该方法的适用性仅限于房间内相对较小的区域，并且其性能尚未通过真实世界数据进行验证。在本文中，我们通过将更长的轨迹分段为较小的线性区间（其中假设近似成立），提出了该方法在更真实场景中的实际扩展。沿着这些分段分段应用该方法，将其适用性扩展到更复杂的房间环境。我们使用trajectoRIR数据库证明了其有效性，该数据库包含在真实房间中受控L形轨迹沿线的移动麦克风记录和离散点RIR测量。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [31] [TeleEval-OS: Performance evaluations of large language models for operations scheduling](https://arxiv.org/abs/2506.11017)
> *TeleEval-OS：大型语言模型在运营调度中的性能评估*

*Yanyan Wang, Yingying Wang, Junli Liang, Yin Xu, Yunlong Liu, Yiming Xu, Zhengwang Jiang, Zhehe Li, Fei Li, Long Zhao, Kuang Xu, Qi Song, Xiangyang Li* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 电信运营调度, 性能评估, 基准测试, TeleEval-OS

**Comment:** 

> **TL;DR:** 本文提出了首个电信运营调度评估基准TeleEval-OS，用于全面评估大型语言模型在该领域的性能，并发现开源LLM在特定场景下可超越闭源LLM。

**AI_Comments:** 本文的创新点在于构建了首个专门针对电信运营调度领域的大型语言模型评估基准TeleEval-OS，填补了该领域LLM评估的空白。其重要性在于为未来LLM在电信OS领域的应用和发展提供了标准化的评估工具和方法，并揭示了开源LLM在该领域的巨大潜力，这对于推动行业智能化转型具有积极意义。论文的局限性可能在于评估的LLM数量有限，且结果可能受特定数据集和评估方法的影响。

<details>
  <summary>Details</summary>

**Motivation:** 电信运营调度（OS）是电信行业的关键环节，但其固有的复杂性和领域特异性，以及缺乏全面的评估基准，阻碍了大型语言模型（LLMs）在该领域的应用潜力探索。

**Method:** 研究提出了首个电信运营调度评估基准TeleEval-OS，该基准包含15个数据集和13个子任务，模拟了智能工单创建、处理、关闭和评估四个关键运营阶段。为评估LLMs在不同复杂任务上的表现，将LLM能力分为四个难度递增的层级：基础NLP、知识问答、报告生成和报告分析。使用零样本和少样本评估方法，对10个开源LLM和4个闭源LLM进行了全面评估。

**Result:** 实验结果表明，在特定场景下，开源大型语言模型能够超越闭源大型语言模型。

**Conclusion:** 开源大型语言模型在电信运营调度领域展现出巨大的潜力和价值。

> **ai_Abstract:** 本文提出了首个电信运营调度评估基准TeleEval-OS，旨在解决大型语言模型在电信运营调度领域应用缺乏全面评估标准的问题。该基准包含15个数据集和13个子任务，模拟了电信运营的四个关键阶段，并根据任务难度将LLM能力分为四个层级。研究评估了10个开源和4个闭源LLM，发现开源LLM在特定场景下表现优于闭源LLM，显示出其在该领域的巨大潜力。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展极大地推动了人工智能的进步，并在多个专业领域展现出巨大的应用潜力。电信运营调度（OS）是电信行业的关键环节，涉及网络、服务、风险和人力资源的协调管理，以优化生产调度并确保统一的服务控制。然而，OS任务固有的复杂性和领域特异性，加上缺乏全面的评估基准，阻碍了LLMs在该关键领域应用潜力的深入探索。为了弥补这一研究空白，我们提出了首个电信运营调度评估基准（TeleEval-OS）。具体而言，该基准包含15个数据集和13个子任务，全面模拟了四个关键运营阶段：智能工单创建、智能工单处理、智能工单关闭和智能评估。为了系统地评估LLMs在不同复杂性任务上的表现，我们将LLMs在电信运营调度中的能力分为四个难度递增的层级：基础NLP、知识问答、报告生成和报告分析。在TeleEval-OS上，我们利用零样本和少样本评估方法，在不同场景下全面评估了10个开源LLMs（例如DeepSeek-V3）和4个闭源LLMs（例如GPT-4o）。实验结果表明，开源LLMs在特定场景下能够超越闭源LLMs，突显了它们在电信运营调度领域的巨大潜力和价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [45] [Consistent Autoformalization for Constructing Mathematical Libraries](https://arxiv.org/abs/2410.04194)
> *构建数学库的一致性自动形式化*

*Lan Zhang, Xin Quan, Andre Freitas* | **Main category: cs.CL**

**Keywords:** 自动形式化, 大型语言模型, 数学库, 一致性, 检索增强生成

**Comment:** EMNLP 2024 camera-ready

> **TL;DR:** 本文提出了一种结合最相似检索增强生成（MS-RAG）、去噪步骤和语法错误反馈自动校正（Auto-SEF）的方法，以提高自动形式化的一致性和质量，尤其适用于构建大型数学库。

**AI_Comments:** 本文的创新之处在于提出了一套组合机制来解决LLMs在自动形式化中存在的“一致性”问题，这对于构建可靠的数学知识库至关重要。通过引入检索增强、去噪和语法反馈自校正，有效地提升了形式化结果的准确性和稳定性。这对于推动数学知识形式化和自动化推理领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在形式语言方面的解释能力不断增强，降低了自动形式化的门槛，但LLMs单独无法在复杂和专业领域中提供一致可靠的自动形式化。随着该领域向系统化应用于大型数学库的方向发展，提高句法、术语和语义控制的需求日益增加。

**Method:** 本文提出了协调使用三种机制来提高自动形式化质量：最相似检索增强生成（MS-RAG）、去噪步骤和语法错误反馈自动校正（Auto-SEF）。

**Result:** 跨不同模型的实证分析表明，这些机制可以提供在句法、术语和语义上更一致的自动形式化结果。这些机制可以应用于不同的LLMs，并已显示出在不同模型类型中都能带来改进的结果。

**Conclusion:** 通过协调使用MS-RAG、去噪步骤和Auto-SEF，可以显著提高自动形式化的质量和一致性，这对于构建大型数学库至关重要。

> **ai_Abstract:** 本文提出了一种改进自动形式化质量的方法，该方法旨在解决大型语言模型在处理复杂数学内容时一致性不足的问题。通过整合最相似检索增强生成（MS-RAG）、去噪步骤和语法错误反馈自动校正（Auto-SEF）这三种机制，研究表明可以显著提高自动形式化结果在句法、术语和语义上的一致性。该方法适用于不同类型的LLMs，为构建大规模数学库提供了更可靠的工具。

> **摘要翻译:** 自动形式化是自动将自然语言编写的数学内容翻译成形式语言表达式的任务。大型语言模型（LLMs）日益增长的语言解释能力，包括在形式语言方面的能力，正在降低自动形式化的门槛。然而，LLMs单独无法一致可靠地提供自动形式化，特别是在目标领域的复杂性和专业性增加时。随着该领域向系统化地将自动形式化应用于大型数学库的方向发展，提高句法、术语和语义控制的需求日益增加。本文提出了协调使用三种机制，即最相似检索增强生成（MS-RAG）、去噪步骤和语法错误反馈自动校正（Auto-SEF），以提高自动形式化质量。跨不同模型的实证分析表明，这些机制可以提供在句法、术语和语义上更一致的自动形式化结果。这些机制可以应用于不同的LLMs，并已显示出在不同模型类型中都能带来改进的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [59] [Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2506.11063)
> *聚光灯下是谁：破坏多模态检索增强生成系统的隐藏偏见*

*Jiayu Yao, Shenghua Liu, Yiwei Wang, Lingrui Mei, Baolong Bi, Yuyao Ge, Zhecheng Li, Xueqi Cheng* | **Main category: cs.CL**

**Keywords:** 多模态RAG, 位置偏见, 检索增强生成, 证据排序, 性能稳定性

**Comment:** 

> **TL;DR:** 本文首次全面研究了多模态RAG系统中的位置偏见问题，发现其对证据呈现顺序高度敏感，导致性能不稳定和偏见推理。研究引入了位置敏感指数（PSIp）来量化偏见，并通过实验揭示了U形准确性曲线和多模态交互加剧偏见的现象。结果强调了需要证据重排序或去偏见策略来构建更可靠的生成系统。

**AI_Comments:** 这项研究首次系统地揭示了多模态RAG系统中隐藏的位置偏见，填补了该领域的一个重要空白。通过引入$PSI_p$和可视化框架，为量化和理解这种偏见提供了新工具。发现U形准确性曲线和多模态交互加剧偏见的结论具有重要的理论和实践意义，为未来开发更鲁棒、更公平的RAG系统指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态检索增强生成（RAG）系统对证据呈现的顺序高度敏感，导致性能不稳定和有偏见的推理，尤其是在检索项数量或模态多样性增加时。本研究旨在回答核心问题：检索到的证据位置如何影响多模态RAG的性能？

**Method:** 本文首次对多模态RAG系统中的位置偏见进行了全面研究。通过在纯文本、纯图像和混合模态任务上进行受控实验，观察证据位置对性能的影响。为量化这种偏见，引入了位置敏感指数（$PSI_p$），并开发了一个可视化框架来追踪解码器层中的注意力分配模式。

**Result:** 研究观察到证据位置与准确性之间存在一致的U形曲线关系。结果表明，与单模态设置相比，多模态交互会加剧位置偏见，并且这种偏见随检索范围的增加呈对数增长。

**Conclusion:** 研究结果为RAG中的位置感知分析提供了理论和经验基础，强调需要证据重排序或去偏见策略来构建更可靠和公平的生成系统。

> **ai_Abstract:** 本文首次全面研究了多模态检索增强生成（RAG）系统中的位置偏见问题。研究发现，多模态RAG模型对检索证据的呈现顺序高度敏感，导致性能不稳定和推理偏差。通过在纯文本、纯图像和混合模态任务上的受控实验，揭示了证据位置与准确性之间的U形关系，并引入了位置敏感指数（$PSI_p$）来量化偏见。结果表明，多模态交互会加剧位置偏见，且偏见随检索范围呈对数增长。这些发现为位置感知分析提供了理论和经验基础，强调了在构建可靠RAG系统时，需要考虑证据重排序或去偏见策略。

> **摘要翻译:** 多模态检索增强生成（RAG）系统在知识密集型和开放域任务中变得至关重要。随着检索复杂性的增加，确保这些系统的鲁棒性变得至关重要。然而，当前的RAG模型对证据呈现的顺序高度敏感，这通常导致性能不稳定和有偏见的推理，特别是在检索项数量或模态多样性增加时。这提出了一个核心问题：检索到的证据位置如何影响多模态RAG的性能？为了回答这个问题，我们首次对多模态RAG系统中的位置偏见进行了全面研究。通过在纯文本、纯图像和混合模态任务上的受控实验，我们观察到证据位置与准确性之间存在一致的U形曲线关系。为了量化这种偏见，我们引入了位置敏感指数（$PSI_p$），并开发了一个可视化框架来追踪解码器层中的注意力分配模式。我们的结果表明，与单模态设置相比，多模态交互会加剧位置偏见，并且这种偏见随检索范围的增加呈对数增长。这些发现为RAG中的位置感知分析提供了理论和经验基础，强调需要证据重排序或去偏见策略来构建更可靠和公平的生成系统。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [64] [A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems](https://arxiv.org/abs/2506.11467)
> *低资源语言机器翻译系统的游戏化评估与招聘平台*

*Carlos Rafael Catalan* | **Main category: cs.CL**

**Keywords:** 低资源语言, 机器翻译, 游戏化评估, 人类评估, 招聘平台

**Comment:** 7 pages, 7 figures, presented at the HEAL Workshop at CHI

> **TL;DR:** 针对低资源语言机器翻译系统缺乏人类评估员和数据集的问题，本文提出了一个游戏化的评估和招聘平台设计方案。

**AI_Comments:** 该论文的创新点在于提出了一个游戏化的平台来解决低资源语言机器翻译领域长期存在的评估员和数据集短缺问题，这对于促进该领域的发展具有重要意义。通过游戏化机制，有望提高评估员的参与度和积极性。然而，如何有效地评估该平台本身的性能和其引入的游戏化机制对评估质量的影响，将是一个关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化指标无法全面评估低资源语言机器翻译系统，而人类评估员和数据集又极度匮乏，导致开发人员难以找到合适的资源。

**Method:** 本文首先全面回顾了现有评估流程，然后基于此提出了一个旨在弥补低资源语言机器翻译系统开发中数据集和评估员资源差距的平台设计方案。

**Result:** 本文提出了一个针对机器翻译系统开发者的招聘和游戏化评估平台的设计。

**Conclusion:** 论文讨论了评估该平台所面临的挑战，以及其在更广泛的自然语言处理（NLP）研究中的潜在应用。

> **ai_Abstract:** 本文针对低资源语言机器翻译系统面临的人类评估员和数据集短缺问题，在回顾现有评估流程的基础上，提出并设计了一个游戏化的招聘与评估平台。该平台旨在弥补资源差距，并讨论了其评估挑战及在自然语言处理领域的应用潜力。

> **摘要翻译:** 人类评估员在评估大型语言模型方面提供了必要的贡献。在低资源语言（LRLs）机器翻译（MT）系统的背景下，这一点变得更加明显，因为流行的自动化指标往往是基于字符串的，因此无法全面反映系统行为的细微差别。人类评估员，如果具备必要的语言专业知识，将能够测试充分性、流畅性以及其他重要指标。然而，语言的低资源性质意味着数据集和评估员都供不应求。这提出了以下难题：这些低资源语言的机器翻译系统开发者如何找到足够的人类评估员和数据集？本文首先对现有评估程序进行了全面回顾，旨在为解决机器翻译系统开发中数据集和评估员资源差距的平台提出设计建议。结果是为机器翻译系统开发者设计了一个招聘和游戏化评估平台。论文还讨论了评估该平台所面临的挑战，以及其在更广泛的自然语言处理（NLP）研究中的可能应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [87] [Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study](https://arxiv.org/abs/2506.11065)
> *看你的另一个世界！通过生成模型复活已消亡的皮钦语：以俄挪语为例*

*Alexey Tikhonov, Sergei Shteiner, Anna Bykova, Ivan P. Yamshchikov* | **Main category: cs.CL**

**Keywords:** 俄挪语, 皮钦语, 大型语言模型, 语言分析, 语言重建

**Comment:** ACL Findings 2025

> **TL;DR:** 本文利用大型语言模型（LLMs）分析并尝试复活已消亡的俄挪语（Russenorsk），一种俄语和挪威语之间的皮钦语，通过构建词典、形成语言结构假设以及开发翻译代理。

**AI_Comments:** 本文的创新之处在于将先进的大型语言模型应用于研究和“复活”一种已消亡的皮钦语，这在计算语言学和历史语言学领域具有重要意义。它展示了LLMs在处理稀有、低资源甚至“死亡”语言方面的巨大潜力，为语言重建和语言演变研究提供了新颖的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 俄挪语（Russenorsk）作为一种独特的语言现象，历史上在俄语和挪威语使用者之间的贸易互动中使用，但现已消亡。本研究的动机是利用现代大型语言模型（LLMs）分析其词汇，以理解并尝试“复活”这种皮钦语。

**Method:** 本研究基于现存的文学资料，使用大型语言模型（LLMs）分析俄挪语的词汇。具体方法包括：构建一个按同义词和词源分组的结构化语言词典；利用该词典形成关于俄挪语构词和语法结构核心原则的假设；比较LLM生成的假设与学术文献中先前提出的假设；开发一个“重建”翻译代理，用于生成当代俄语和挪威语文本的假设性俄挪语版本。

**Result:** 研究结果表明，大型语言模型（LLMs）生成的一些假设与学术文献中先前提出的假设相符。此外，研究成功开发了一个能够生成当代俄语和挪威语文本假设性俄挪语版本的“重建”翻译代理。

**Conclusion:** 本研究的结论是，大型语言模型（LLMs）能够有效地用于分析和潜在地“复活”已消亡的皮钦语，如俄挪语。通过构建词典和验证语言结构假设，LLMs为历史语言学和语言重建提供了新的工具和方法。

> **ai_Abstract:** 本文探讨了如何利用大型语言模型（LLMs）对已消亡的皮钦语——俄挪语进行语言学分析。研究人员基于现有文献构建了俄挪语的结构化词典，并利用LLMs形成了关于其构词和语法结构的假设，随后与现有学术理论进行了对比验证。此外，研究还开发了一个翻译代理，能够将当代俄语和挪威语文本“重建”为假设性的俄挪语版本。

> **摘要翻译:** 俄挪语（Russenorsk）是一种历史上在俄罗斯和挪威语使用者之间贸易互动中使用的皮钦语，代表着一种独特的语言现象。在本文中，我们尝试基于现存的文学资料，使用现代大型语言模型（LLMs）分析其词汇。我们构建了一个按同义词和词源分组的结构化语言词典。随后，我们使用该词典来阐述关于俄挪语构词和语法结构核心原则的假设，并展示了大型语言模型生成的哪些假设与学术文献中先前提出的假设相对应。我们还开发了一个“重建”翻译代理，用于生成当代俄语和挪威语文本的假设性俄挪语版本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [114] [A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes](https://arxiv.org/abs/2506.11067)
> *基于大型语言模型的临床笔记系统综述实体识别流水线*

*Hieu Nghiem, Hemanth Reddy Singareddy, Zhuqi Miao, Jivan Lamichhane, Abdulaziz Ahmed, Johnson Thomas, Dursun Delen, William Paiva* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 临床笔记, 系统综述实体识别, 医疗保健, 开源LLM

**Comment:** 

> **TL;DR:** 开发了一个基于LLM的流水线，用于从临床笔记中自动提取ROS实体，并发现开源LLM在成本效益方面表现良好。

**AI_Comments:** 这篇论文的创新点在于提出了一个端到端的LLM-based流水线来解决ROS实体识别的挑战，同时强调了开源LLM在实际医疗环境中的应用潜力，解决了成本和部署的限制。其重要性在于能够显著减轻临床医生在ROS文档方面的负担，提高效率。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在开发一个成本效益高、基于大型语言模型（LLM）的流水线，用于从临床笔记中自动提取系统综述（ROS）实体。

**Method:** 该流水线首先使用SecTag提取ROS部分，然后利用少样本LLM识别ROS实体范围、其阳性/阴性状态以及相关的身体系统。实施时使用了开源LLM（Mistral、Llama、Gemma）和ChatGPT，并在36份包含341个标注ROS实体的内科笔记上进行了评估。

**Result:** 当集成ChatGPT时，该流水线在检测ROS实体范围及其对应状态/系统方面取得了最低的错误率（分别为28.2%和14.5%）。开源LLM实现了流水线的本地化、成本高效执行，并提供了有前景的性能，错误率相似（范围：30.5-36.7%；状态/系统：24.3-27.3%）。

**Conclusion:** 该流水线提供了一个可扩展且可本地部署的解决方案，以减少ROS文档负担。在资源有限的医疗环境中，开源LLM是商业模型的替代选择。

> **ai_Abstract:** 本文提出了一种基于大型语言模型（LLM）的流水线，用于从临床笔记中自动识别系统综述（ROS）实体。该流水线结合了SecTag进行部分提取和少样本LLM进行实体识别、状态判断及系统关联。实验结果表明，无论是使用ChatGPT还是开源LLM（如Mistral、Llama、Gemma），该流水线都能有效地降低ROS实体识别的错误率，并提供一个可扩展、成本效益高的解决方案，尤其对于资源受限的医疗环境，开源LLM展现出作为商业模型可行替代方案的潜力。

> **摘要翻译:** 目标：开发一个成本效益高、基于大型语言模型（LLM）的流水线，用于自动从临床笔记中提取系统综述（ROS）实体。材料与方法：该流水线首先使用SecTag提取ROS部分，然后利用少样本LLM识别ROS实体范围、其阳性/阴性状态以及相关的身体系统。我们使用开源LLM（Mistral、Llama、Gemma）和ChatGPT实现了该流水线。评估在36份包含341个标注ROS实体的内科笔记上进行。结果：当集成ChatGPT时，该流水线在检测ROS实体范围及其对应状态/系统方面取得了最低的错误率（分别为28.2%和14.5%）。开源LLM实现了流水线的本地化、成本高效执行，同时提供了有前景的性能，错误率相似（范围：30.5-36.7%；状态/系统：24.3-27.3%）。讨论与结论：我们的流水线提供了一个可扩展且可本地部署的解决方案，以减少ROS文档负担。在资源有限的医疗环境中，开源LLM是商业模型的替代选择。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://arxiv.org/abs/2506.11068)
> *义务论关键词偏见：情态表达对语言模型规范性判断的影响*

*Bumjin Park, Jinsil Lee, Jaesik Choi* | **Main category: cs.CL**

**Keywords:** 义务论关键词偏见, 语言模型, 情态表达, 规范性判断, 语言框架

**Comment:** 20 pages including references and appendix; To appear in ACL 2025
  main conference

> **TL;DR:** 大型语言模型（LLMs）在提示中包含“必须”或“应该”等情态词时，会强烈倾向于将非义务性情境判断为义务，这种现象被称为义务论关键词偏见（DKB），且此偏见普遍存在。研究提出了一种通过少样本示例和推理提示来缓解此偏见的策略。

**AI_Comments:** 这项研究识别并命名了一种新颖且重要的LLM偏见——义务论关键词偏见（DKB），这对于理解LLM的道德和伦理推理至关重要。发现简单的情态词就能显著影响LLM的规范性判断，揭示了语言细微之处对模型行为的深远影响。所提出的缓解策略为未来LLM对齐研究提供了实用方向。该偏见在不同模型和格式中的一致性表明其普遍性，强调了解决此问题的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地参与道德和伦理推理，但其判断标准，即使对人类而言，也常常不明确。虽然LLM对齐研究涵盖了许多领域，但LLMs如何对义务做出判断是一个重要但未被充分探索的领域。本研究旨在揭示情态表达如何影响LLMs的规范性判断，并强调解决此类偏见对确保判断对齐的重要性。

**Method:** 本研究通过在提示中加入“必须”或“应该”等情态表达，揭示了LLMs将非义务性情境判断为义务的强烈倾向，并将此现象命名为义务论关键词偏见（DKB）。研究评估了这种倾向在不同LLM家族、问题类型和答案格式下的一致性。为缓解DKB，研究提出了一种结合少样本示例和推理提示的判断策略。

**Result:** 研究发现，当提示中存在情态表达时，LLMs会将超过90%的常识情境判断为义务。这种义务论关键词偏见（DKB）在各种LLM家族、问题类型和答案格式中都保持一致。为缓解DKB，研究提出了一种结合少样本示例和推理提示的判断策略。

**Conclusion:** 情态表达作为一种语言框架，显著影响LLMs的规范性决策，导致了义务论关键词偏见（DKB）。解决此类偏见对于确保LLMs的判断对齐至关重要。

> **ai_Abstract:** 本研究揭示了大型语言模型（LLMs）中存在一种“义务论关键词偏见”（DKB），即当提示中包含“必须”或“应该”等情态表达时，LLMs会强烈倾向于将非义务性情境判断为义务。研究发现，在存在情态表达的情况下，LLMs对超过90%的常识情境做出义务性判断，且这种倾向在不同LLM家族、问题类型和答案格式中均保持一致。为缓解DKB，研究提出了一种结合少样本示例和推理提示的判断策略。这项工作突出了语言框架对LLMs规范性决策的影响，并强调了解决此类偏见对于确保LLM判断对齐的重要性。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地参与道德和伦理推理，其中判断标准即使对人类而言也常常不明确。虽然LLM对齐研究涵盖了许多领域，但LLMs如何对义务做出判断是一个重要但未被充分探索的领域。这项工作揭示了LLMs在提示中加入“必须”或“应该”等情态表达时，会强烈倾向于将非义务性情境判断为义务。我们将这种现象命名为义务论关键词偏见（DKB）。我们发现，当情态表达存在时，LLMs在超过90%的常识情境中会做出义务性判断。这种倾向在各种LLM家族、问题类型和答案格式中都保持一致。为了缓解DKB，我们提出了一种结合少样本示例和推理提示的判断策略。这项研究揭示了情态表达作为一种语言框架如何影响LLMs的规范性决策，并强调了解决此类偏见对于确保判断对齐的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [164] [Targeted control of fast prototyping through domain-specific interface](https://arxiv.org/abs/2506.11070)
> *通过领域特定界面实现快速原型设计的精确控制*

*Yu-Zhe Shi, Mingchen Liu, Hanlu Ma, Qiao Xu, Huamin Qu, Kun He, Lecheng Ruan, Qining Wang* | **Main category: cs.CL**

**Keywords:** 快速原型, 领域特定界面, 大语言模型, 自然语言控制, 目标控制

**Comment:** In International Conference on Machine Learning (ICML'25)

> **TL;DR:** 本文提出了一种领域特定界面架构，旨在弥合设计师自然语言与建模语言之间的鸿沟，从而使大语言模型能够精确有效地控制原型模型，通过机器评估和用户研究证明了其潜力。

**AI_Comments:** 该论文的创新点在于提出了一个领域特定接口来弥合设计师自然语言与复杂建模语言之间的差距，有效提升了大型语言模型在快速原型控制中的应用潜力。这种方法有望显著简化工业设计流程，降低设计师的技术门槛，使其能够更直观、高效地进行原型迭代。其重要性在于为自然语言与复杂设计工具的交互提供了一个新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 工业设计师长期以来寻求一种自然直观的方式来精确控制原型模型，即通过简单的自然语言指令来配置和调整模型，而无需依赖复杂的建模命令。尽管大型语言模型在此领域展现出潜力，但其通过语言控制原型模型的能力尚未完全发挥，这源于设计师语言和建模语言之间存在抽象级别不匹配、语义精度波动以及词汇范围差异等鸿沟。

**Method:** 为弥合设计师语言和建模语言之间的鸿鸿沟，本文提出了一种接口架构，作为两者之间的媒介。该接口的设计基于对快速原型实践的系统调查所获得的设计原则，并开发了其操作机制和用于自动化领域规范的算法。

**Result:** 通过在各种产品设计领域进行的基于机器的评估和人类研究，结果表明该接口能够作为大型语言模型的辅助模块，从而实现对原型模型的精确有效的目标控制。

**Conclusion:** 本文提出的领域特定界面能够弥合设计师语言与建模语言之间的差距，有效提升大型语言模型在快速原型设计中实现精确控制的能力。

> **ai_Abstract:** 本文提出了一种领域特定接口架构，旨在解决工业设计师在使用自然语言控制原型模型时，大型语言模型与建模语言之间存在的抽象、语义和词汇差异问题。该接口基于快速原型实践的设计原则，通过其操作机制和自动化领域规范算法，能够作为大型语言模型的辅助模块，实现对原型模型的精确有效控制。机器评估和人类研究均证实了其在多产品设计领域的潜力。

> **摘要翻译:** 工业设计师长期以来一直寻求一种自然直观的方式来实现对原型模型的精确控制——即使用简单的自然语言指令根据他们的意图无缝地配置和调整模型，而无需依赖复杂的建模命令。尽管大型语言模型在此领域展现出潜力，但其通过语言控制原型模型的能力尚未完全发挥。这种局限性源于设计师语言和建模语言之间的鸿沟，包括抽象级别的不匹配、语义精度的波动以及词汇范围的分歧。为了弥合这些鸿沟，我们提出了一种接口架构，作为这两种语言之间的媒介。该接口的设计基于对快速原型实践的系统调查所获得的设计原则，我们设计了接口的操作机制，并开发了其自动化领域规范的算法。在各种产品设计领域进行的基于机器的评估和人类研究都表明，该接口有潜力作为大型语言模型的辅助模块，从而实现对原型模型的精确有效的目标控制。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [169] [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org/abs/2506.11105)
> *通过输入驱动的显著性适应实现设备端医疗AI助手*

*Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 模型压缩, 医疗AI, 边缘计算, 显著性剪枝

**Comment:** 

> **TL;DR:** 本文提出了一种通用的压缩框架，通过神经元显著性剪枝和后训练量化来优化大型语言模型，使其能够在资源受限的边缘设备上部署为医疗AI助手，并实现了实时、节能的推理。

**AI_Comments:** 该论文提出了一种创新的、通用的LLM压缩框架，特别适用于医疗AI领域。其亮点在于结合了领域特定数据驱动的神经元显著性剪枝和后训练量化，有效解决了LLMs在边缘设备上部署的尺寸和能耗问题。这种方法对于推动医疗AI在实际应用中的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在医疗保健领域具有重要影响，但由于其庞大的模型尺寸，难以在实时、资源受限的边缘设备上部署。

**Method:** 本文引入了一种新颖的医疗助手系统，通过通用压缩框架进行优化。该方法通过测量领域特定数据上的神经元显著性来积极剪枝不相关的神经元，以减小模型尺寸同时保持性能。剪枝后，应用后训练量化进一步减少内存占用。

**Result:** 压缩后的模型在MedMCQA、MedQA和PubMedQA等医疗基准测试中进行了评估。成功将50%压缩的Gemma模型和67%压缩的LLaMA3模型部署到Jetson Orin Nano和Raspberry Pi 5上，在硬件约束下实现了实时、节能的推理。

**Conclusion:** 通过神经元显著性剪枝和后训练量化，可以有效压缩大型语言模型，使其能够在资源受限的边缘设备上作为医疗AI助手进行实时、高效的部署。

> **ai_Abstract:** 本文提出了一种通用的LLM压缩框架，旨在解决大型语言模型在资源受限边缘设备上部署医疗AI助手的挑战。该方法结合了输入驱动的神经元显著性剪枝和后训练量化，以显著减小模型尺寸并降低能耗，同时保持性能。实验证明，压缩后的Gemma和LLaMA3模型能够在Jetson Orin Nano和Raspberry Pi 5等设备上实现高效的实时推理。

> **摘要翻译:** 大型语言模型（LLMs）对医疗保健场景产生了重大影响，但对于在边缘设备等实时、资源受限的环境中部署而言，它们仍然过于庞大。在这项工作中，我们引入了一种新颖的医疗助手系统，通过我们通用的压缩框架进行优化，该框架为在专业领域部署大型语言模型（LLMs）量身定制。通过测量领域特定数据上的神经元显著性，我们的方法可以积极剪枝不相关的神经元，在减小模型尺寸的同时保持性能。剪枝后，我们应用后训练量化以进一步减少内存占用，并在包括MedMCQA、MedQA和PubMedQA在内的医疗基准测试中评估了压缩后的模型。我们还在Jetson Orin Nano（峰值18.7W）和Raspberry Pi 5（峰值6.3W）上部署了50%压缩的Gemma模型和67%压缩的LLaMA3模型，在硬件约束下实现了实时、节能的推理。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [177] [Large Language Models and Emergence: A Complex Systems Perspective](https://arxiv.org/abs/2506.11135)
> *大型语言模型与涌现：一个复杂系统视角*

*David C. Krakauer, John W. Krakauer, Melanie Mitchell* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 涌现, 复杂系统, 涌现智能, 量化

**Comment:** 

> **TL;DR:** 本文从复杂系统角度探讨大型语言模型是否展现涌现能力和涌现智能。

**AI_Comments:** 抽象部分明确了论文的研究范围，即从复杂系统理论的“涌现”概念出发，审视大型语言模型的能力。其创新点在于将复杂系统理论引入LLM研究，但抽象未提及具体方法或发现，故无法评估其重要性或局限性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在从复杂系统视角，审视关于大型语言模型（LLMs）展现涌现能力的主张，并探讨LLMs是否具备涌现智能。

**Method:** 本文首先审视关于大型语言模型展现涌现能力的主张，并回顾几种量化涌现的方法；其次，探讨大型语言模型是否具备涌现智能。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文从复杂系统视角探讨大型语言模型（LLMs）是否具备涌现能力和涌现智能。文章首先审视了关于LLMs展现涌现能力的主张，并回顾了量化涌现的方法，随后深入探讨了LLMs是否真正拥有涌现智能。

> **摘要翻译:** 涌现是复杂性科学中的一个概念，它描述了多体系统如何表现出新颖的高层属性，这些属性可以通过用低维有效变量和理论替代高维机制来描述。这被“多即不同”的思想所概括。智能是一种完美的涌现属性，它体现了越来越高效——更便宜、更快——地利用涌现能力来解决问题。这被“少即是多”的思想所概括。在本文中，我们首先审视了关于大型语言模型表现出涌现能力的主张，回顾了几种量化涌现的方法，其次探讨了大型语言模型是否具备涌现智能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [182] [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)
> *CLAIM：通过跨语言注意力干预减轻大型视觉-语言模型中的多语言对象幻觉*

*Zekai Ye, Qiming Li, Xiaocheng Feng, Libo Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin* | **Main category: cs.CL**

**Keywords:** 多语言对象幻觉, 大型视觉-语言模型, 跨语言注意力干预, 免训练, 注意力对齐

**Comment:** ACL2025 Main

> **TL;DR:** 提出CLAIM方法，通过对齐注意力模式，减轻大型视觉-语言模型中的多语言对象幻觉，无需大量训练。

**AI_Comments:** 本文提出了一种新颖且高效的解决方案，通过“注意力干预”而非传统的资源密集型预训练或微调来解决LVLMs中的多语言对象幻觉问题，其“近乎免训练”的特性是重要的创新点。研究还揭示了中间层在多语言注意力分歧中的关键作用，为未来的研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在使用非英语查询时更容易产生与视觉输入不一致的多语言对象幻觉，而现有的解决方案（如预训练或微调）资源消耗大。

**Method:** 受跨语言跨模态注意力模式差异的启发，本文提出了一种名为CLAIM的近乎免训练方法。CLAIM首先识别特定语言的跨模态注意力头，然后估计从英语到目标语言的语言偏移向量，最后在推理过程中干预注意力输出，以促进跨语言视觉感知能力的对齐。

**Result:** CLAIM在POPE基准上平均实现了13.56%的改进（西班牙语高达30%），在MME基准的幻觉子集上实现了21.75%的改进。进一步分析表明，多语言注意力分歧在中间层最为显著。

**Conclusion:** CLAIM方法有效减轻了大型视觉-语言模型中的多语言对象幻觉，且多语言注意力分歧在中间层最为显著，突出了它们在多语言场景中的关键作用。

> **ai_Abstract:** 本文针对大型视觉-语言模型（LVLMs）在非英语查询下易产生多语言对象幻觉的问题，提出了一种名为CLAIM的近乎免训练方法。该方法通过识别语言特定的跨模态注意力头、估计语言偏移向量并干预推理阶段的注意力输出，以对齐跨语言的视觉感知能力。实验结果显示，CLAIM在多个基准测试上显著减轻了多语言对象幻觉，并指出中间层在多语言注意力分歧中扮演关键角色。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）展现了令人印象深刻的多模态能力，但仍然容易出现多语言对象幻觉，与使用英语查询相比，使用非英语语言查询时生成与视觉输入不一致响应的可能性更高。大多数现有解决这些问题的方法依赖于预训练或微调，这些方法资源密集。在本文中，受到观察到跨语言跨模态注意力模式差异的启发，我们提出了一种新颖的、近乎免训练的方法——跨语言注意力干预以减轻LVLMs中的多语言对象幻觉（CLAIM），通过对齐注意力模式来实现。CLAIM首先识别特定语言的跨模态注意力头，然后估计从英语到目标语言的语言偏移向量，最后在推理过程中干预注意力输出，以促进跨语言视觉感知能力的对齐。广泛的实验表明，CLAIM在POPE基准上实现了平均13.56%的改进（西班牙语高达30%），在MME基准的幻觉子集上跨多种语言实现了21.75%的改进。进一步分析揭示，多语言注意力分歧在中间层最为显著，突出了它们在多语言场景中的关键作用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [202] [CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling](https://arxiv.org/abs/2506.11077)
> *CyclicReflex：通过周期性反思令牌调度改进大型推理模型*

*Chongyu Fan, Yihua Zhang, Jinghan Jia, Alfred Hero, Sijia Liu* | **Main category: cs.CL**

**Keywords:** 大型推理模型, 反思令牌, 周期性调度, 解码策略, 资源分配

**Comment:** 

> **TL;DR:** 提出CyclicReflex，一种动态调度反思令牌的解码策略，显著提升大型推理模型的性能。

**AI_Comments:** 该论文的创新点在于将反思令牌的调度问题类比于深度学习中的学习率调度，并提出了一种新颖的周期性调制方法。这为优化大型推理模型的推理过程提供了一个有效且直观的视角。通过动态管理“资源”，它解决了过度或不足反思导致的性能瓶颈，对提升LRM的实际应用性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型在多步推理中依赖反思令牌，但过度或不足使用都会损害性能，因此需要优化反思令牌的频率和位置。

**Method:** 将反思令牌视为“资源”，并将其使用类比于优化中的学习率调度。提出CyclicReflex策略，通过位置相关的三角波形动态调制反思令牌的logits。

**Result:** 在MATH500、AIME2024/2025和AMC2023数据集上的实验表明，CyclicReflex持续提升了不同模型尺寸（1.5B-8B）的性能，优于标准解码和其他最新方法（如TIP和S1）。

**Conclusion:** CyclicReflex通过优化反思令牌的调度，有效提高了大型推理模型在复杂问题解决中的性能。

> **ai_Abstract:** 本文针对大型推理模型中反思令牌使用不当导致性能下降的问题，提出了一种名为CyclicReflex的周期性反思令牌调度策略。该策略将反思令牌视为资源，并借鉴学习率调度概念，通过位置相关的三角波形动态调整反思令牌的生成频率。实验结果表明，CyclicReflex在多个数学推理数据集上显著提升了不同规模模型的性能，优于现有方法。

> **摘要翻译:** 大型推理模型（LRM），如OpenAI的o1和DeepSeek-R1，利用测试时缩放来执行多步推理以解决复杂问题。这个在产生最终答案之前执行的推理过程，通常由特殊的连接令牌或文本段落引导，这些令牌或段落会提示自我评估的反思。我们将这些过渡标记和反思提示称为“反思令牌”（例如，“wait”、“but”、“alternatively”）。在这项工作中，我们将反思令牌视为一种“资源”，并引入了资源分配问题，旨在通过自适应地调节反思令牌的频率和位置来提高LRM的测试时计算性能。通过实证分析，我们发现反思令牌的过度使用和不足使用（分别称为过度反思和不足反思）都会降低模型性能。为了更好地理解和管理这种权衡，我们将反思令牌的使用类比于优化中的学习率调度。基于这一见解，我们提出了周期性反思令牌调度（称为CyclicReflex），这是一种解码策略，它使用位置相关的三角波形动态调制反思令牌的logits。在MATH500、AIME2024/2025和AMC2023上的实验表明，CyclicReflex在不同模型尺寸（1.5B-8B）上持续提高了性能，优于标准解码和更近期的AIME2024/2025和AMC2023方法（如TIP和S1）。代码可在https://github.com/OPTML-Group/CyclicReflex获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [220] [RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs](https://arxiv.org/abs/2506.11078)
> *RoE-FND：一种结合双重验证的基于案例推理的LLM假新闻检测方法*

*Yuzhou Yang, Yangming Zhou, Zhiying Zhu, Zhenxing Qian, Xinpeng Zhang, Sheng Li* | **Main category: cs.CL**

**Keywords:** 假新闻检测, 大型语言模型, 基于案例推理, 经验学习, 双重验证

**Comment:** 

> **TL;DR:** RoE-FND是一个基于案例推理的假新闻检测框架，它结合LLM和经验学习，通过自反思知识构建和动态标准检索来解决现有FND和LLM-FND的局限性，并实现了卓越的泛化性和有效性。

**AI_Comments:** RoE-FND的创新点在于将LLM与案例推理和经验学习相结合，特别是其“自反思知识构建”和“动态标准检索”阶段，这有助于解决LLM的幻觉问题和现有FND方法的泛化性挑战。其“无需训练”的特性使其在应对不断变化的假新闻类型方面具有很强的适应性和实用价值。双通道验证机制也增加了检测的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 线上欺骗性内容的泛滥需要强大的假新闻检测系统。现有基于证据的方法存在证据选择噪声、泛化瓶颈和决策过程不清晰等局限性。利用大型语言模型（LLMs）进行假新闻检测也引入了幻觉推理和结论偏差等新挑战。

**Method:** 提出RoE-FND框架，将基于证据的假新闻检测重构为逻辑演绎任务，结合LLM和经验学习。该框架包含两个阶段：1) 自反思知识构建（探索阶段），通过分析过去的推理错误来建立知识库；2) 动态标准检索，在部署过程中从历史案例中合成任务特定的推理指导作为经验。此外，它还通过设计的双通道程序，根据内部经验对推理进行交叉检查。该方法是无需训练的。

**Result:** RoE-FND在三个数据集上经验验证了其优于现有最先进方法的泛化性和有效性。

**Conclusion:** RoE-FND提供了一个有效的、无需训练的基于案例推理框架，通过结合LLM和经验学习，成功解决了现有假新闻检测方法和基于LLM的FND所面临的挑战，并表现出卓越的性能和适应性。

> **ai_Abstract:** 本文提出了RoE-FND，一个结合大型语言模型和经验学习的基于案例推理框架，用于假新闻检测。它通过自反思知识构建和动态标准检索两个阶段，解决现有证据选择噪声、泛化性差及LLM的幻觉推理等问题。RoE-FND无需训练，并通过双通道程序进行内部经验交叉验证，经验证在泛化性和有效性方面优于现有SOTA方法。

> **摘要翻译:** 在线欺骗性内容的泛滥使得强大的假新闻检测（FND）系统变得必要。尽管基于证据的方法利用外部知识来验证声明，但现有方法面临关键限制：证据选择噪声、泛化瓶颈和决策过程不清晰。最近利用大型语言模型（LLMs）进行FND的努力引入了新的挑战，包括幻觉推理和结论偏差。为了解决这些问题，我们提出了\textbf{RoE-FND}（\textbf{\underline{R}}eason \textbf{\underline{o}}n \textbf{\underline{E}}xperiences FND），一个通过将LLMs与经验学习相结合，将基于证据的FND重构为逻辑演绎任务的框架。RoE-FND包含两个阶段：（1）\textit{自反思知识构建}，即探索阶段，通过分析过去的推理错误来建立知识库；（2）\textit{动态标准检索}，在部署过程中从历史案例中综合任务特定的推理指南作为经验。它还通过设计的双通道程序，根据内部经验对推理进行交叉检查。主要贡献包括：一个解决多个现有挑战的基于案例的FND推理框架，一种无需训练的方法，能够适应不断变化的情况，以及在三个数据集上对该框架优于最先进方法的卓越泛化性和有效性进行的经验验证。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [229] [C-SEO Bench: Does Conversational SEO Work?](https://arxiv.org/abs/2506.11097)
> *C-SEO Bench：会话式SEO有效吗？*

*Haritz Puerto, Martin Gubri, Tommaso Green, Seong Joon Oh, Sangdoo Yun* | **Main category: cs.CL**

**Keywords:** 会话式SEO, C-SEO Bench, 搜索引擎优化, 大型语言模型, 基准测试

**Comment:** 

> **TL;DR:** 该论文介绍了C-SEO Bench，这是一个评估会话式SEO（C-SEO）方法在多任务、多领域和多参与者场景下有效性的基准。研究发现，大多数当前C-SEO方法无效，而传统SEO更有效，并且随着C-SEO采用者数量的增加，整体收益会下降。

**AI_Comments:** 该论文及时且批判性地评估了会话式SEO（C-SEO）在现实竞争环境中的有效性。其发现，即传统SEO仍然更有效以及C-SEO采用的零和性质，是重要的贡献，挑战了当前的假设。C-SEO Bench的推出也为未来的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有会话式搜索引擎优化（C-SEO）方法通常只在有限的应用领域进行测试，并且仅考虑单参与者场景，因此对于它们在广泛领域中的有效性以及在多参与者竞争环境中的表现缺乏深入理解。

**Method:** 本文提出了C-SEO Bench，这是第一个旨在评估C-SEO方法在多个任务（问答、产品推荐）、多个领域（每个任务三个领域）和不同参与者数量下的基准。它还正式化了一种新的评估协议，其中涉及参与者之间不同的采用率。

**Result:** 实验表明，大多数当前的C-SEO方法基本无效，这与文献中报道的结果相反。相反，旨在提高LLM上下文中来源排名的传统SEO策略更有效。研究还观察到，随着C-SEO采用者数量的增加，总体收益会减少，这描绘了该问题的拥堵和零和性质。

**Conclusion:** 在广泛且竞争激烈的环境中，当前的会话式SEO（C-SEO）方法大多无效，而传统SEO策略则更为有效。随着C-SEO采用者数量的增加，收益呈下降趋势，表明该问题具有零和性质。

> **ai_Abstract:** 随着大型语言模型（LLMs）将搜索引擎转变为会话式搜索引擎（CSE），搜索引擎优化（SEO）也演变为会话式搜索引擎优化（C-SEO）。本文介绍了C-SEO Bench，这是第一个旨在评估C-SEO方法在多任务、多领域和多参与者竞争场景下有效性的基准。研究发现，大多数当前C-SEO方法效果不佳，而传统SEO策略更为有效。此外，随着C-SEO采用者数量的增加，整体收益会下降，揭示了该问题的拥堵和零和性质。

> **摘要翻译:** 大型语言模型（LLMs）正在将搜索引擎转变为会话式搜索引擎（CSE）。因此，搜索引擎优化（SEO）正在转向会话式搜索引擎优化（C-SEO）。我们开始看到专门的C-SEO方法，用于修改网页文档以提高其在CSE响应中的可见性。然而，这些方法通常只在有限的应用领域进行测试；我们不清楚某些C-SEO方法是否对广泛的领域有效。此外，现有评估只考虑单参与者场景，即只有一个网页文档采用C-SEO方法；而在现实中，多个参与者可能会竞争性地采用尖端的C-SEO技术，这与我们在SEO中看到的动态类似。我们提出了C-SEO Bench，这是第一个旨在评估C-SEO方法在多个任务、领域和参与者数量上的基准。我们考虑了两种搜索任务：问答和产品推荐，每种任务包含三个领域。我们还正式化了一种新的评估协议，其中涉及参与者之间不同的采用率。我们的实验表明，大多数当前的C-SEO方法基本无效，这与文献中报道的结果相反。相反，传统SEO策略，即那些旨在提高LLM上下文中来源排名的策略，效果显著更好。我们还观察到，随着C-SEO采用者数量的增加，总体收益会减少，这描绘了该问题的拥堵和零和性质。我们的代码和数据可在https://github.com/parameterlab/c-seo-bench和https://huggingface.co/datasets/parameterlab/c-seo-bench获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [234] [MANBench: Is Your Multimodal Model Smarter than Human?](https://arxiv.org/abs/2506.11080)
> *MANBench：你的多模态模型比人类更聪明吗？*

*Han Zhou, Qitong Xu, Yiheng Dong, Xin Yang* | **Main category: cs.CL**

**Keywords:** 多模态大语言模型, 基准测试, MANBench, 跨模态推理, 人工智能评估

**Comment:** Multimodal Benchmark, Project Url: https://github.com/micdz/MANBench,
  ACL2025 Findings

> **TL;DR:** 多模态大语言模型（MLLMs）在多模态任务中仍未达到人类水平，MANBench基准测试揭示了它们的优缺点。

**AI_Comments:** 本文通过构建一个新颖的双语多模态基准测试MANBench，系统地评估了MLLMs与人类在多模态任务上的表现。其创新之处在于强调直观推理、跨模态集成和真实世界复杂性，并结合了人类实验进行对比。研究结果清晰地指出了当前MLLMs的优势和不足，尤其是在深层跨模态推理和复杂任务上的差距，为未来MLLMs的发展提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 为响应关于多模态大语言模型（MLLMs）在多模态任务中超越人类表现潜力的讨论，本文旨在通过引入一个严格的评估框架来评估MLLMs的能力。

**Method:** 本文引入了MANBench（多模态能力规范基准），一个包含1,314个问题、涵盖9个任务（跨越知识和非知识领域）的双语（英语和中文）基准测试。该基准强调直观推理、无缝跨模态集成和真实世界复杂性。通过广泛的人类实验，将人类表现与最先进的MLLMs进行了比较。

**Result:** 结果显示，MLLMs在知识和图文理解等任务中表现出色，但在更深层次的跨模态推理任务（如变形理解、图像一致性和多图理解）中表现不佳。此外，人类和MLLMs在高度复杂的任务（如谜题和空间想象）中都面临挑战。研究表明，即使是先进的MLLMs也未能达到许多领域的人类水平。

**Conclusion:** MANBench揭示了多模态大语言模型（MLLMs）的优点和局限性，表明即使是先进的模型也未能达到许多领域的人类水平。本文希望MANBench能激发弥合MLLMs与人类多模态能力之间差距的努力。

> **ai_Abstract:** 本文引入了MANBench，一个包含1,314个问题的双语多模态基准测试，旨在评估多模态大语言模型（MLLMs）与人类在多模态任务中的表现。实验结果显示，MLLMs在知识和图文理解方面表现良好，但在更深层次的跨模态推理任务（如变形理解、图像一致性和多图理解）以及高度复杂的任务（如谜题和空间想象）中仍逊于人类。MANBench揭示了当前MLLMs的局限性，并强调了弥合其与人类多模态能力之间差距的必要性。

> **摘要翻译:** 多模态大语言模型（MLLMs）的快速发展引发了关于它们在多模态任务中超越人类表现潜力的讨论。为此，我们引入了MANBench（多模态能力规范基准），这是一个包含1,314个问题、涵盖九个任务（跨越基于知识和非基于知识领域）的双语（英语和中文）基准测试。MANBench强调直观推理、无缝跨模态集成和真实世界复杂性，提供了一个严格的评估框架。
通过涉及不同参与者的广泛人类实验，我们将人类表现与最先进的MLLMs进行了比较。结果表明，尽管MLLMs在知识和图文理解等任务中表现出色，但它们在更深层次的跨模态推理任务（如变形理解、图像一致性和多图理解）中表现不佳。此外，人类和MLLMs在高度复杂的任务（如谜题和空间想象）中都面临挑战。
MANBench突出了MLLMs的优点和局限性，揭示了即使是先进的模型也未能达到许多领域的人类水平。我们希望MANBench能激发弥合MLLMs与人类多模态能力之间差距的努力。代码和数据集可在https://github.com/micdz/MANBench获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [244] [Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking](https://arxiv.org/abs/2506.11106)
> *基于图的RAG增强：通过全局查询消歧和依赖感知重排序*

*Ningyuan Li, Junrui Liu, Yi Shan, Minghui Huang, Tong Li* | **Main category: cs.CL**

**Keywords:** 图基RAG, 查询消歧, 依赖感知重排序, 检索增强生成, 知识图谱

**Comment:** 

> **TL;DR:** PankRAG通过全局查询消歧和依赖感知重排序，解决了现有图基RAG方法中因过度依赖实体提取导致的信息丢失和幻觉问题，显著提升了性能。

**AI_Comments:** 这篇论文通过引入全局查询消歧和依赖感知重排序，创新性地解决了图基RAG中实体级提取的局限性。其核心创新在于构建多级解析路径来处理查询的复杂依赖关系，并通过依赖感知重排序来优化检索结果，从而显著减少了幻觉并提高了生成响应的质量。这对于提升RAG系统在处理复杂查询时的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图的RAG方法过度依赖实体级提取，导致潜在关键信息和关系的误解或遗漏，检索内容可能不相关或矛盾，并排除必要知识，从而加剧幻觉风险并降低生成响应的保真度。

**Method:** PankRAG框架结合了全局感知、分层查询解析策略和新颖的依赖感知重排序机制。它首先构建一个多级解析路径，捕获查询中的并行和顺序相互依赖关系，引导大型语言模型进行结构化推理。然后，它应用其依赖感知重排序器，利用已解析子问题之间的依赖结构，丰富和验证后续子问题的检索结果。

**Result:** 经验评估表明，PankRAG在多个基准测试中始终优于最先进的方法，突出了其鲁棒性和通用性。

**Conclusion:** PankRAG通过其创新的查询解析和重排序机制，成功解决了现有图基RAG方法的局限性，显著提高了生成响应的准确性和相关性。

> **ai_Abstract:** 本文提出了PankRAG框架，旨在解决现有基于图的RAG方法中因过度依赖实体级提取而导致的信息丢失和幻觉问题。PankRAG通过结合全局感知、分层查询解析策略和依赖感知重排序机制来工作，它构建多级解析路径以捕捉查询依赖，并利用依赖结构来丰富和验证检索结果。实验证明，PankRAG在多个基准测试中表现优于现有SOTA方法。

> **摘要翻译:** 当代基于图的检索增强生成（RAG）方法通常首先从用户查询中提取实体，然后利用预构建的知识图谱来检索相关关系和元数据。然而，这种管道对实体级提取的独家依赖可能导致对潜在但关键信息和关系的误解或遗漏。结果是，检索到的内容可能不相关或矛盾，并且可能会排除必要的知识，从而加剧幻觉风险并降低生成响应的保真度。为了解决这些局限性，我们引入了PankRAG，这是一个结合了全局感知、分层查询解析策略和新颖的依赖感知重排序机制的框架。PankRAG首先构建一个多级解析路径，捕获查询中的并行和顺序相互依赖关系，引导大型语言模型（LLM）进行结构化推理。然后，它应用其依赖感知重排序器，利用已解析子问题之间的依赖结构，丰富和验证后续子问题的检索结果。经验评估表明，PankRAG在多个基准测试中始终优于最先进的方法，突出了其鲁棒性和通用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [250] [SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs](https://arxiv.org/abs/2506.11081)
> *SAGE：面向LLM自动测试用例生成的规范感知语法提取*

*Aditi, Hyunwoo Park, Sicheol Sung, Yo-Sub Han, Sang-Ki Ko* | **Main category: cs.CL**

**Keywords:** 语法提取, 测试用例生成, 大型语言模型, 上下文无关计数语法, 强化学习

**Comment:** 

> **TL;DR:** SAGE提出了一种基于LLM的方法，通过微调和强化学习（GRPO）从规范中推断上下文无关计数语法（CCFGs），用于自动测试用例生成，在语法质量和测试有效性方面优于其他LLM。

**AI_Comments:** 这篇论文创新性地将大型语言模型和强化学习（特别是GRPO）应用于软件测试中一个特定且具有挑战性的问题：从自然语言规范中生成精确的语法。使用上下文无关计数语法（CCFGs）以及对可验证奖励引导学习的关注是其显著特点。该方法在性能上显著优于现有技术和其他LLMs，突显了其在实际应用中的潜力以及所提出的两阶段微调和强化学习方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 基于语法的测试用例生成在竞技编程问题中已被证明是有效的，但从自然语言规范中生成有效且通用的语法仍然是一个关键挑战，尤其是在有限监督下。上下文无关计数语法（CCFGs）作为一种形式化方法被引入，用于表示带有逻辑约束的规范，但在给定规范的情况下推断CCFGs仍然是一个难题。

**Method:** 本研究探索使用开源大型语言模型（LLMs）通过少量标注示例和可验证的奖励引导强化学习来从规范中推断CCFGs。该方法首先微调一个开源LLM以执行规范到语法的转换，然后应用组相对策略优化（GRPO）来增强语法的有效性和通用性。研究还探讨了迭代反馈对于开源和闭源LLMs在纠正生成语法中的句法和语义错误方面的有效性。

**Result:** 实验结果表明，SAGE方法实现了更强的泛化能力，并在语法质量和测试有效性方面优于17个开源和闭源LLM。它在语法有效性方面比现有技术提高了15.92%p，在测试有效性方面提高了12.34%p。

**Conclusion:** SAGE是一种利用LLMs和强化学习从规范中推断CCFGs的有效方法，显著提高了自动测试用例生成的语法质量和测试有效性。

> **ai_Abstract:** SAGE是一种新颖的方法，利用开源大型语言模型（LLMs）从自然语言规范中推断上下文无关计数语法（CCFGs），用于自动测试用例生成。它采用两阶段过程：首先微调LLM进行初步翻译，然后应用组相对策略优化（GRPO）来提高语法的有效性和通用性。该方法还研究了迭代反馈在纠正错误方面的作用。实验结果表明，SAGE在泛化能力和性能上优于众多LLMs，在语法有效性和测试有效性方面取得了显著提升。

> **摘要翻译:** 基于语法的测试用例生成已被证明对竞技编程问题有效，但从自然语言规范中生成有效和通用的语法仍然是一个关键挑战，尤其是在有限监督下。上下文无关计数语法（CCFGs）最近被引入作为一种形式化方法，通过在推导过程中存储和重用计数器值来表示带有逻辑约束的此类规范。在这项工作中，我们探索使用开源大型语言模型（LLMs）通过少量标注示例和可验证的奖励引导强化学习从规范中推断CCFGs。我们的方法首先微调一个开源LLM以执行规范到语法的转换，然后进一步应用组相对策略优化（GRPO）来增强语法的有效性和通用性。我们还检查了迭代反馈对于开源和闭源LLMs在纠正生成语法中的句法和语义错误方面的有效性。实验结果表明，我们的方法SAGE实现了更强的泛化能力，并在语法质量和测试有效性方面优于17个开源和闭源LLM，在语法有效性方面比现有技术提高了15.92%p，在测试有效性方面提高了12.34%p。我们在以下匿名仓库提供我们的实现和数据集：https://anonymous.4open.science/r/SAGE-5714

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [261] [Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)](https://arxiv.org/abs/2506.11112)
> *Dagstuhl 视角研讨会 24352 宣言——对话式智能体：一个评估框架 (CAFE)*

*Christine Bauer, Li Chen, Nicola Ferro, Norbert Fuhr, Avishek Anand, Timo Breuer, Guglielmo Faggioli, Ophir Frieder, Hideo Joho, Jussi Karlgren, Johannes Kiesel, Bart P. Knijnenburg, Aldo Lipani, Lien Michiels, Andrea Papenmeier, Maria Soledad Pera, Mark Sanderson, Scott Sanner, Benno Stein, Johanne R. Trippas, Karin Verspoor, Martijn C Willemsen* | **Main category: cs.CL**

**Keywords:** 对话式智能体, 评估框架, CONIAC, CAFE, 对话式信息访问

**Comment:** 43 pages; 10 figures; Dagstuhl manifesto

> **TL;DR:** 本文提出了一个名为 CAFE 的对话式信息访问 (CONIAC) 系统评估框架，包含六个主要组成部分。

**AI_Comments:** 该论文的关键创新在于为对话式信息访问 (CONIAC) 系统提供了一个结构化的、全面的评估框架。CAFE 框架的提出填补了该领域评估方法上的空白，对于推动对话式智能体技术的发展和成熟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研讨会深入讨论了对话式信息访问 (CONIAC) 及其独特特征，并提出了一个抽象的 CONIAC 世界模型，旨在为 CONIAC 系统定义一个评估框架。

**Method:** 通过讨论 CONIAC 的概念、特点和抽象世界模型，本文定义了对话式智能体评估框架 (CAFE)，该框架由六个主要组成部分构成：1) 系统利益相关者的目标；2) 评估中要研究的用户任务；3) 执行任务的用户的方面；4) 要考虑的评估标准；5) 要应用的评估方法；6) 所选定量标准的衡量指标。

**Result:** 本文定义了对话式智能体评估框架 (CAFE)，该框架包含六个主要组成部分，用于评估对话式信息访问 (CONIAC) 系统。

**Conclusion:** CAFE 框架的提出为 CONIAC 系统的评估提供了一个结构化、全面的方法。

> **ai_Abstract:** 本文是 Dagstuhl 视角研讨会 24352 的宣言，旨在深入探讨对话式信息访问 (CONIAC) 的概念与特性，并提出了一个抽象的 CONIAC 世界模型。核心贡献是定义了对话式智能体评估框架 (CAFE)，这是一个用于评估 CONIAC 系统的六组件框架，涵盖了系统目标、用户任务、用户方面、评估标准、评估方法和定量衡量指标。

> **摘要翻译:** 在研讨会期间，我们深入讨论了什么是对话式信息访问 (CONIAC) 及其独特特征，提出了一个抽象它的世界模型，并定义了用于评估 CONIAC 系统的对话式智能体评估框架 (CAFE)，该框架由六个主要组成部分构成：1) 系统利益相关者的目标；2) 评估中要研究的用户任务；3) 执行任务的用户的方面；4) 要考虑的评估标准；5) 要应用的评估方法；6) 所选定量标准的衡量指标。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [266] [PRISM: A Transformer-based Language Model of Structured Clinical Event Data](https://arxiv.org/abs/2506.11082)
> *PRISM：一种基于Transformer的结构化临床事件数据语言模型*

*Lionel Levine, John Santerre, Alex S. Young, T. Barry Levine, Francis Campion, Majid Sarrafzadeh* | **Main category: cs.CL**

**Keywords:** 临床事件数据, Transformer, 语言模型, 序列预测, 临床决策支持

**Comment:** 15 pages, 4 Figures, 1 Table

> **TL;DR:** PRISM是一个基于Transformer的模型，用于预测临床事件序列的下一步，旨在支持医疗决策。

**AI_Comments:** PRISM的创新之处在于将临床事件序列视为语言序列进行建模，并利用Transformer架构进行自回归预测，这与传统孤立诊断分类方法不同。它展示了生成式语言模型在医疗领域的潜力，特别是对于理解和预测复杂纵向患者数据方面。其重要性在于为临床决策支持、模拟和教育提供了新的工具，并为未来的序列化医疗保健建模奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法依赖孤立的诊断分类，而PRISM旨在建模临床决策过程的顺序进展，预测患者诊断旅程中最可能的下一步，从而弥合机器学习与真实世界诊断推理之间的差距。

**Method:** PRISM是一种基于Transformer的自回归架构。它将临床轨迹（包括诊断测试、实验室结果和诊断）视为标记化的事件序列，并利用大型自定义临床词汇和自回归训练目标来学习预测下一步。

**Result:** 实验结果显示，在下一个标记预测任务中，PRISM比随机基线有显著改进。生成的序列反映了真实的诊断路径、实验室结果进展和临床医生订购行为。

**Conclusion:** 这些发现突出了将生成式语言建模技术应用于结构化医疗事件数据的可行性，支持临床决策支持、模拟和教育等应用。PRISM为未来基于序列的医疗保健建模的进步奠定了基础。

> **ai_Abstract:** PRISM是一种基于Transformer的语言模型，用于建模结构化临床事件数据。它将临床轨迹视为事件序列，并利用自回归训练预测患者诊断旅程的下一步。该模型在预测任务中表现优于基线，生成的序列真实可靠，有望应用于临床决策支持、模拟和教育。

> **摘要翻译:** 我们引入了PRISM（Predictive Reasoning in Sequential Medicine），这是一种基于Transformer的架构，旨在模拟临床决策过程的顺序进展。与依赖孤立诊断分类的传统方法不同，PRISM将临床轨迹框定为事件的标记化序列——包括诊断测试、实验室结果和诊断——并学习预测患者诊断旅程中最可能的下一步。PRISM利用大型自定义临床词汇和自回归训练目标，展示了捕获纵向患者时间线上复杂依赖关系的能力。实验结果表明，在下一个标记预测任务中，与随机基线相比，PRISM取得了显著改进，生成的序列反映了真实的诊断路径、实验室结果进展和临床医生订购行为。这些发现突出了将生成式语言建模技术应用于结构化医疗事件数据的可行性，从而支持临床决策支持、模拟和教育等应用。PRISM为未来基于序列的医疗保健建模的进步奠定了基础，弥合了机器学习架构与真实世界诊断推理之间的差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [275] [ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research](https://arxiv.org/abs/2506.11117)
> *ScIRGen：为科学研究合成真实大规模RAG数据集*

*Junyong Lin, Lu Dai, Ruiqian Han, Yijie Sui, Ruilin Wang, Xingliang Sun, Qinglin Wu, Min Feng, Hao Liu, Hui Xiong* | **Main category: cs.CL**

**Keywords:** 科学研究, RAG, 数据集生成, 问答, 信息检索

**Comment:** KDD 2025 Accepted

> **TL;DR:** ScIRGen创建了一个大型真实RAG数据集（ScIRGen-Geo），用于科学研究，解决了现有QA/检索数据集与实际研究需求不符的问题，并发现现有方法在复杂问题推理上仍有不足。

**AI_Comments:** ScIRGen的创新点在于其系统性地解决了科学领域RAG数据集的真实性问题，通过结合多项技术（信息抽取、认知分类问题生成、LLM困惑度过滤）来模拟真实研究场景下的复杂信息需求。其创建的ScIRGen-Geo数据集为评估和开发更高级的科学信息检索和问答系统提供了宝贵的资源。论文揭示了当前方法在处理复杂问题上的局限性，指出了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有科学检索和问答（QA）数据集通常处理直接问题，与现实世界研究查询的信息需求分布不符，科学研究人员需要更符合其隐含信息需求的工具。

**Method:** 开发了ScIRGen框架，包含：设计了以数据集为导向的信息抽取方法，利用学术论文增强数据集表示；提出了一个问题生成框架，采用认知分类法确保合成问题质量；设计了基于LLMs困惑度漂移的自动过滤合成答案的方法，以确保答案有效性。

**Result:** 创建了一个包含61k个问答对的ScIRGen-Geo数据集。在ScIRGen-Geo数据集上对代表性方法进行基准测试，发现当前方法在复杂问题推理方面仍然存在不足。

**Conclusion:** 这项工作推动了更复杂工具的开发，以支持科学界复杂的、错综复杂的信息需求。

> **ai_Abstract:** 本文介绍了ScIRGen，一个用于生成大规模、真实科学检索增强生成（RAG）数据集的框架，旨在弥补现有科学QA/检索数据集与实际研究需求之间的差距。ScIRGen通过结合数据集导向的信息提取、基于认知分类的问题生成以及基于LLM困惑度漂移的答案过滤等方法，创建了包含61k个问答对的ScIRGen-Geo数据集。对该数据集进行的基准测试表明，当前方法在处理复杂问题时仍面临挑战。这项工作为满足科学界复杂的、隐含的信息需求提供了新的工具和方向。

> **摘要翻译:** 科学研究人员需要关于数据集的密集信息，以有效评估和开发理论和方法。对数据集的信息需求隐含在特定的研究任务中，而不是明确地通过搜索查询表达。然而，现有的科学检索和问答（QA）数据集通常解决直接问题，这与现实世界研究查询的分布不符。为了弥合这一差距，我们开发了ScIRGen，一个用于科学问答和检索的数据集生成框架，它更准确地反映了专业科学研究人员的信息需求，并用它创建了一个包含真实查询、数据集和论文的大规模科学检索增强生成（RAG）数据集。在技术上，我们设计了一种以数据集为导向的信息抽取方法，该方法利用学术论文来增强数据集表示。然后，我们提出了一个问题生成框架，通过采用认知分类法来确保合成问题的质量。我们还设计了一种基于大型语言模型（LLMs）困惑度漂移来自动过滤合成答案的方法，该方法与人类对答案有效性的判断高度一致。总的来说，这些方法最终促成了61k问答数据集ScIRGen-Geo的创建。我们对ScIRGen-Geo数据集上的代表性方法进行了问答和检索能力的基准测试，发现当前方法在复杂问题推理方面仍然存在不足。这项工作促进了更复杂工具的开发，以支持科学界复杂的、错综复杂的信息需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [279] [RedDebate: Safer Responses through Multi-Agent Red Teaming Debates](https://arxiv.org/abs/2506.11083)
> *RedDebate：通过多智能体红队辩论实现更安全的响应*

*Ali Asad, Stephen Obadinma, Radin Shayanfar, Xiaodan Zhu* | **Main category: cs.CL**

**Keywords:** 多智能体, 红队, AI安全, 大型语言模型, 辩论框架

**Comment:** 

> **TL;DR:** RedDebate是一个多智能体辩论框架，通过LLM之间的对抗性辩论和长期记忆，自动识别并减少不安全行为，从而提高AI安全性，无需人工干预。

**AI_Comments:** 该论文提出了一个新颖且重要的全自动化AI安全增强框架。其创新点在于将多智能体辩论和自动化红队技术相结合，并引入长期记忆机制，使得LLM能够自我发现并纠正不安全行为，显著降低了对昂贵人工干预的依赖。这对于未来AI系统的可扩展性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI安全方法严重依赖昂贵的人工评估或孤立的单模型评估，存在可扩展性限制和监督风险。

**Method:** RedDebate是一个新颖的多智能体辩论框架，利用大型语言模型（LLMs）之间的对抗性辩论，使多个LLMs批判性地审查彼此的推理，并通过自动化红队系统地发现不安全盲点，并迭代地改进响应。该框架还整合了长期记忆模块，以保留从辩论交互中学习到的安全见解。

**Result:** 在HarmBench等安全基准上评估，仅通过辩论可减少17.7%的不安全行为，结合长期记忆模块可减少超过23.5%。

**Conclusion:** RedDebate是首个结合多智能体辩论和红队技术，无需直接人工干预即可逐步增强AI安全性的全自动化框架，有效提高了AI的安全性。

> **ai_Abstract:** RedDebate是一个创新的多智能体辩论框架，旨在通过LLM之间的对抗性辩论和自动化红队来自动提升AI安全性。它解决了传统人工评估的局限性，通过迭代改进和整合长期记忆，显著减少了LLM的不安全行为，实现了无需人工干预的AI安全增强。

> **摘要翻译:** 我们提出了RedDebate，一个新颖的多智能体辩论框架，它利用大型语言模型（LLMs）之间的对抗性辩论，主动识别并减轻自身的不安全行为。现有的AI安全方法通常严重依赖昂贵的人工评估或孤立的单模型评估，两者都受到可扩展性限制和监督风险的影响。RedDebate则采用协作性异议，使多个LLMs能够批判性地审查彼此的推理，并通过自动化红队系统地发现不安全盲点，并迭代地改进它们的响应。我们进一步整合了不同类型的长期记忆，以保留从辩论交互中学习到的安全见解。在HarmBench等已建立的安全基准上进行评估，我们证明了所提出方法的有效性。仅通过辩论就可以减少17.7%的不安全行为，当与长期记忆模块结合时，减少幅度超过23.5%。据我们所知，RedDebate构成了第一个完全自动化的框架，它结合了多智能体辩论和红队技术，无需直接人工干预即可逐步增强AI安全性。(Github仓库：https://github.com/aliasad059/RedDebate)

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [280] [The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs](https://arxiv.org/abs/2506.11094)
> *正义的天平：大型语言模型安全评估的综合调查*

*Songyang Liu, Chaozhuo Li, Jiameng Qiu, Xi Zhang, Feiran Huang, Litian Zhang, Yiming Hei, Philip S. Yu* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 安全评估, 综述, 毒性, 偏见

**Comment:** 21 pages, preprint

> **TL;DR:** 该调查全面回顾了大型语言模型（LLMs）的安全评估进展，涵盖了评估原因、内容、地点和方法，并指出了挑战和未来方向，强调LLMs安全评估的重要性。

**AI_Comments:** 这是一篇重要的综述性论文，它系统地梳理了大型语言模型（LLMs）安全评估领域的现状。其创新之处在于提出了“为何”、“评估什么”、“在哪里”和“如何”这四个结构化的问题来组织评估内容，这为后续研究提供了一个清晰的框架。论文的重要性在于它填补了现有研究缺乏系统性总结的空白，并明确指出了未来的研究方向和挑战，对于推动LLMs的安全发展和实际应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的广泛部署，其生成内容中出现的毒性、偏见等不安全因素引发了广泛关注。尽管已有大量关于LLMs安全风险评估的研究，但目前缺乏系统性的综述来总结这些研究进展。

**Method:** 本调查通过提出“为何评估”、“评估什么”、“在哪里评估”和“如何评估”四个核心问题，系统性地回顾了LLMs安全评估的最新进展。具体包括：探讨安全评估的背景和意义；根据关键能力（如毒性、鲁棒性、伦理、偏见与公平、真实性等）对现有安全评估任务进行分类；总结当前使用的评估指标、数据集和基准；审查现有评估工具包，并根据评估者的角色对主流评估方法进行分类。

**Result:** 本调查提供了一个全面而系统的LLMs安全评估最新进展概述，涵盖了安全评估的背景、与通用LLMs评估的区别、评估任务的分类（如毒性、鲁棒性、伦理、偏见与公平、真实性等维度）、评估指标、数据集、基准、现有评估工具包以及主流评估方法。此外，它还识别了LLMs安全评估中的挑战并提出了潜在的研究方向。

**Conclusion:** 论文识别了大型语言模型安全评估中的挑战，并提出了潜在的研究方向，以促进该领域的进一步发展。作者强调优先进行LLMs安全评估的重要性，以确保这些模型在实际应用中的安全部署。

> **ai_Abstract:** 本调查全面回顾了大型语言模型（LLMs）安全评估的最新进展。鉴于LLMs在内容生成中表现出的安全问题（如毒性和偏见），以及现有研究缺乏系统性总结的现状，该工作旨在提供一个结构化的视角。调查涵盖了“为何评估”（背景与重要性）、“评估什么”（任务分类，如毒性、偏见、真实性等）、“在哪里评估”（指标、数据集、基准）和“如何评估”（工具包、方法）四个核心方面。最终，论文提出了LLMs安全评估面临的挑战和未来的研究方向，并强调了确保LLMs安全部署的重要性。

> **摘要翻译:** 随着人工智能技术的飞速发展，大型语言模型（LLMs）在自然语言处理（NLP）领域展现出卓越潜力，包括内容生成、人机交互、机器翻译和代码生成等。然而，它们的广泛部署也引发了显著的安全担忧。近年来，LLM生成的内容偶尔表现出不安全元素，如毒性和偏见，特别是在对抗性场景中，这引起了学术界和工业界的广泛关注。尽管已为评估LLMs相关的安全风险做出了大量努力，但仍缺乏系统性综述来总结这些研究工作。本调查旨在对LLMs安全评估的最新进展提供一个全面而系统的概述，重点关注几个关键方面：(1)“为何评估”，探讨LLMs安全评估的背景、它们与通用LLMs评估的区别以及此类评估的重要性；(2)“评估什么”，检查并根据关键能力对现有安全评估任务进行分类，包括毒性、鲁棒性、伦理、偏见与公平、真实性等维度；(3)“在哪里评估”，总结当前安全评估中使用的评估指标、数据集和基准；(4)“如何评估”，回顾现有评估工具包，并根据评估者的角色对主流评估方法进行分类。最后，我们识别了LLMs安全评估中的挑战，并提出了潜在的研究方向，以促进该领域的进一步发展。我们强调优先进行LLMs安全评估的重要性，以确保这些模型在实际应用中的安全部署。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [283] [The Biased Samaritan: LLM biases in Perceived Kindness](https://arxiv.org/abs/2506.11361)
> *有偏见的撒玛利亚人：大型语言模型在感知善良方面的偏见*

*Jack H Fagan, Ruhaan Juyaal, Amy Yue-Ming Yu, Siya Pun* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 偏见评估, 人口统计学偏见, 感知善良, 道德主体

**Comment:** 

> **TL;DR:** 本文提出一种新方法来量化评估大型语言模型（LLM）在感知善良方面的人口统计学偏见，发现LLM将白人中年/青年男性视为基线，但普遍认为非基线人口比基线更乐于助人。

**AI_Comments:** 本文创新性地提出了一种评估LLM人口统计学偏见的方法，特别在于区分了基线偏见和非基线人群的感知差异，这对于理解和减轻LLM中的复杂偏见具有重要意义。其结果揭示了LLM对特定人口群体的潜在刻板印象，为未来LLM的开发和应用提供了关键的指导，以实现更公平的AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 理解和减轻大型语言模型（LLM）的偏见是一个持续存在的问题。本文旨在提供一种评估生成式AI模型人口统计学偏见的新方法，并定量评估不同LLM对各种性别、种族和年龄的偏见，以理解这些偏见是积极、中性还是消极，以及其强度。

**Method:** 通过提示模型评估道德主体进行建设性干预的意愿，定量评估不同LLM对各种性别、种族和年龄的偏见。该方法旨在确定各种商业模型的基线人口统计学身份以及基线与其他人口统计学之间的关系，并区分两种经常混淆的偏见。

**Result:** 模型将白人中年或青年男性视为基线人口统计学特征；然而，模型普遍趋势表明，非基线人口统计学特征比基线更乐于助人。

**Conclusion:** 本研究有助于客观评估大型语言模型中的偏见，并使用户或开发者能够考虑这些偏见，无论是在LLM输出中还是在未来LLM的训练中。

> **ai_Abstract:** 本文提出一种新颖方法，量化评估大型语言模型在感知善良方面的人口统计学偏见。通过提示模型评估道德主体干预意愿，研究发现LLM将白人中年/青年男性视为基线，但普遍认为非基线人口更乐于助人。该研究有助于客观评估和减轻LLM偏见。

> **摘要翻译:** 大型语言模型（LLMs）已在许多领域普及，但理解和减轻LLM偏见仍是一个持续存在的问题。本文提供了一种新颖的方法来评估各种生成式AI模型的人口统计学偏见。通过提示模型评估道德主体进行建设性干预的意愿，我们旨在定量评估不同LLM对各种性别、种族和年龄的偏见。我们的工作与现有工作的不同之处在于，旨在确定各种商业模型的基线人口统计学身份以及基线与其他人口统计学之间的关系。我们努力理解这些偏见是积极的、中性的还是消极的，以及这些偏见的强度。本文有助于客观评估大型语言模型中的偏见，并赋予用户或开发者在LLM输出或未来LLM训练中考虑这些偏见的能力。我们的分析提出了两个关键发现：模型将基线人口统计学特征视为白人中年或青年男性；然而，模型普遍趋势表明，非基线人口统计学特征比基线更乐于助人。这些方法使我们能够区分这两种经常混淆的偏见。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [291] [Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing](https://arxiv.org/abs/2506.11088)
> *一石二鸟：通过动态交互子空间编辑提升大型语言模型的真实性和忠实性*

*Pengbo Wang, Chaozhuo Li, Chenxu Wang, Liwen Zheng, Litian Zhang, Xi Zhang* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 幻觉, 真实性, 忠实性, 子空间编辑

**Comment:** 

> **TL;DR:** LLMs的幻觉（真实性和忠实性问题）源于共享的激活子空间；本文提出SPACE框架，通过编辑这些共享子空间来同时解决这两个问题，并取得优异效果。

**AI_Comments:** 该论文的创新点在于揭示了LLMs中事实性和忠实性幻觉的共享子空间，并提出了一种统一的编辑框架SPACE，避免了现有方法在独立解决问题时可能带来的性能权衡。这种“一石二鸟”的方法对于提升LLMs的可靠性和实际应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在实际部署中受到事实性（factuality）和忠实性（faithfulness）幻觉的阻碍。现有方法独立解决这些问题时会产生性能权衡，即解决一个问题可能加剧另一个问题。

**Method:** 通过对LLMs激活空间动态的实证和理论分析，发现这些幻觉类别在神经表示中共享重叠子空间。基于此，提出统一框架SPACE，通过编辑共享激活子空间来共同提升真实性和忠实性。SPACE通过双任务特征建模建立共享子空间存在的几何基础，并通过结合谱聚类和注意力头显著性评分的混合探针策略识别和编辑这些子空间。

**Result:** 在多个基准数据集上的实验结果表明，该方法具有优越性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出一种名为SPACE的统一框架，旨在同时解决大型语言模型中普遍存在的事实性与忠实性幻觉问题。研究发现，这两种幻觉在LLMs的激活空间中共享重叠子空间。SPACE框架通过双任务特征建模建立共享子空间的存在基础，并结合谱聚类和注意力头显著性评分识别和编辑这些共享子空间，从而有效提升模型的真实性和忠实性。实验结果证明了该方法的优越性。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言处理方面展现出前所未有的能力，但其实际部署仍受到持续的事实性（factuality）和忠实性（faithfulness）幻觉的阻碍。尽管现有方法独立地解决了这些幻觉类型，但它们无意中导致了性能权衡，因为针对一种类型的干预往往会加剧另一种类型。通过对LLMs激活空间动态的实证和理论分析，我们揭示这些幻觉类别在神经表示中共享重叠子空间，这为同时缓解它们提供了机会。为了利用这一见解，我们提出了SPACE，一个通过编辑共享激活子空间来共同增强事实性和忠实性的统一框架。SPACE通过双任务特征建模为共享子空间的存在建立了几何基础，然后通过结合谱聚类和注意力头显著性评分的混合探针策略识别和编辑这些子空间。在多个基准数据集上的实验结果表明，我们的方法具有优越性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [300] [DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](https://arxiv.org/abs/2506.11763)
> *DeepResearch Bench：深度研究智能体的综合基准*

*Mingxuan Du, Benfeng Xu, Chiwei Zhu, Xiaorui Wang, Zhendong Mao* | **Main category: cs.CL**

**Keywords:** 深度研究智能体, LLM智能体, 基准, 评估, 信息检索

**Comment:** 31 pages, 5 figures

> **TL;DR:** 本文提出了DeepResearch Bench，一个用于评估深度研究智能体的综合基准，包含100个博士级研究任务，并引入了两种新颖的评估方法。

**AI_Comments:** 该论文的创新点在于构建了一个针对深度研究智能体的综合性、高难度（博士级）基准，并提出了两种与人类判断高度一致的新颖评估方法，解决了当前LLM驱动智能体评估的痛点。其重要性在于为未来深度研究智能体的开发和比较提供了标准化的工具和方法，有望显著加速该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前缺乏一个用于系统评估深度研究智能体能力的综合基准。

**Method:** 本文提出了DeepResearch Bench，一个包含100个由领域专家在22个不同领域精心设计的博士级研究任务的基准。此外，还提出了两种新颖的评估方法：一种是基于参考的自适应标准方法，用于评估生成研究报告的质量；另一种框架用于通过评估有效引用计数和整体引用准确性来评估DRA的信息检索和收集能力。

**Result:** 作者已经开源了DeepResearch Bench和这些框架的关键组件。

**Conclusion:** 该研究旨在加速实用LLM驱动代理的开发。

> **ai_Abstract:** 本文介绍了DeepResearch Bench，这是一个旨在解决当前深度研究智能体评估基准缺失问题的综合性基准。该基准包含100个由领域专家创建的博士级研究任务，涵盖22个不同领域。为应对评估的复杂性，研究提出了两种新颖的评估方法：一种是基于参考的自适应标准方法，用于评估研究报告质量；另一种框架用于评估信息检索和引用能力。该项目已开源，旨在加速LLM驱动智能体的开发。

> **摘要翻译:** 深度研究智能体是基于LLM（大型语言模型）的智能体中一个突出的类别。通过自主协调多步骤网络探索、目标检索和高阶合成，它们能将大量的在线信息转化为分析师级别的、引用丰富的报告——将数小时的手动桌面研究压缩到几分钟内完成。然而，目前仍缺乏一个系统评估这些智能体能力的综合基准。为了弥补这一空白，我们提出了DeepResearch Bench，一个由100个博士级研究任务组成的基准，每个任务都由来自22个不同领域的领域专家精心制作。评估DRA（深度研究智能体）本身就是复杂且劳动密集型的。因此，我们提出了两种新颖的方法，它们与人类判断具有很强的一致性。第一种是基于参考的自适应标准方法，用于评估生成研究报告的质量。另一个框架旨在通过评估其有效引用计数和整体引用准确性来评估DRA的信息检索和收集能力。我们已在https://github.com/Ayanami0730/deep_research_bench上开源了DeepResearch Bench和这些框架的关键组件，以加速实用LLM驱动代理的开发。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [304] [Customizing Speech Recognition Model with Large Language Model Feedback](https://arxiv.org/abs/2506.11091)
> *利用大型语言模型反馈定制语音识别模型*

*Shaoshi Ling, Guoli Ye* | **Main category: cs.CL**

**Keywords:** 语音识别, 大型语言模型, 强化学习, 域适应, 命名实体

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的方法，利用大型语言模型（LLM）的反馈来对自动语音识别（ASR）模型进行无监督域适应，以提高对稀有命名实体的识别能力，并在实体词错误率上实现了21%的改进。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型作为奖励信号源引入到语音识别模型的强化学习微调过程中，以实现无监督域适应。这种方法有效地利用了LLM强大的领域泛化能力来弥补ASR在特定领域命名实体识别上的不足，为ASR的定制化和领域适应提供了一个新颖且有效途径。其重要性体现在为解决实际应用中ASR模型在特定领域表现不佳的问题提供了可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 自动语音识别（ASR）系统在通用转录任务上表现良好，但在识别稀有命名实体和适应领域不匹配方面仍面临挑战。相比之下，大型语言模型（LLM）在广泛的领域中更有效。

**Method:** 本文提出了一种基于强化学习的无监督域适应方法。该方法利用未标记数据，通过LLM的反馈来提高转录质量，特别是受域不匹配影响的命名实体。给定上下文信息，框架将LLM用作奖励模型，对ASR模型的假设进行评分。这些分数作为奖励信号，通过强化学习微调ASR模型。

**Result:** 该方法在实体词错误率上比传统的自训练方法提高了21%。

**Conclusion:** 本文提出的利用大型语言模型反馈进行强化学习的方法，能有效提高语音识别模型在无监督域适应中对命名实体的识别性能。

> **ai_Abstract:** 本文提出了一种创新的基于强化学习的无监督域适应方法，旨在解决自动语音识别（ASR）系统在识别稀有命名实体和处理领域不匹配方面的不足。该方法利用大型语言模型（LLM）作为奖励模型，通过评估ASR假设来提供反馈信号，进而通过强化学习微调ASR模型。实验结果显示，该方法在实体词错误率上比传统自训练方法有显著的21%的提升。

> **摘要翻译:** 自动语音识别（ASR）系统在通用转录任务上取得了强大的性能。然而，它们在识别稀有命名实体和适应领域不匹配方面仍然面临困难。相比之下，在海量互联网规模数据集上训练的大型语言模型（LLMs）通常在广泛的领域中更有效。在这项工作中，我们提出了一种基于强化学习的无监督域适应方法，利用未标记数据通过来自LLM的反馈来提高转录质量，特别是受领域不匹配影响的命名实体。给定上下文信息，我们的框架将LLM用作奖励模型，对ASR模型的假设进行评分。这些分数作为奖励信号，通过强化学习微调ASR模型。我们的方法在实体词错误率上比传统的自训练方法提高了21%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [308] [Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation](https://arxiv.org/abs/2506.11092)
> *动态上下文调优用于检索增强生成：增强多轮规划和工具适应性*

*Jubin Abhishek Soni, Amit Anand, Rajesh Kumar Pandey, Aniket Abhishek Soni* | **Main category: cs.CL**

**Keywords:** 检索增强生成, 动态上下文调优, 多轮对话, 工具适应, 大语言模型

**Comment:** 6 pages, 5 figures, 3 tables. This manuscript has been submitted to
  IEEE conference. Researchers are welcome to read and build upon this work;
  please cite it appropriately. For questions or clarifications, feel free to
  contact me

> **TL;DR:** 本文提出了动态上下文调优（DCT）框架，扩展了检索增强生成（RAG）以支持多轮对话和动态工具环境，无需重新训练。DCT通过上下文缓存、LoRA检索和上下文压缩，显著提高了规划准确性和减少了幻觉，成本更低，并能泛化到新工具。

**AI_Comments:** 这项研究的创新之处在于提出了一个轻量级框架DCT，它通过无需重新训练的方式，有效解决了RAG在动态、多轮对话和工具环境中的适应性问题。其结合上下文缓存、LoRA检索和上下文压缩的策略，为RAG的实际应用开辟了新途径，特别是在需要持续交互和工具变化的领域。性能提升和成本效益也凸显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有检索增强生成（RAG）系统通常受限于静态、单轮交互和固定工具集，这使得它们不适用于医疗保健和智能家居等动态领域，因为在这些领域中，用户意图、可用工具和上下文因素会随时间演变。

**Method:** 本文提出了动态上下文调优（DCT）框架，它是一个轻量级框架，无需重新训练即可将RAG扩展到支持多轮对话和演化工具环境。DCT集成了基于注意力的上下文缓存来跟踪相关的历史信息，基于LoRA的检索来动态选择特定领域的工具，以及高效的上下文压缩以将输入保持在LLM上下文限制内。

**Result:** 实验表明，DCT在合成和真实世界基准上将规划准确性提高了14%，并将幻觉减少了37%，同时以显著更低的成本达到了GPT-4的性能。此外，DCT能够泛化到以前未见过的工具。

**Conclusion:** DCT框架显著增强了RAG系统在多轮对话和动态工具环境中的性能，提高了规划准确性并减少了幻觉，同时具有成本效益和良好的泛化能力，为可扩展和适应性强的AI助手提供了支持。

> **ai_Abstract:** 本文提出了动态上下文调优（DCT）框架，旨在解决现有检索增强生成（RAG）系统在动态多轮对话和演变工具环境中的局限性。DCT通过集成注意力上下文缓存、基于LoRA的动态工具检索和高效上下文压缩，实现了无需重新训练的多轮支持和工具适应性。实验证明，DCT在规划准确性、减少幻觉和成本效益方面均优于现有方法，并展现出对新工具的泛化能力，为构建适应性强的AI助手提供了有效途径。

> **摘要翻译:** 检索增强生成（RAG）通过将大型语言模型（LLMs）的输出建立在外部工具和知识源之上，显著推动了其发展。然而，现有的RAG系统通常受限于静态、单轮交互和固定的工具集，这使得它们不适用于医疗保健和智能家居等动态领域，因为在这些领域中，用户意图、可用工具和上下文因素会随时间演变。我们提出了动态上下文调优（DCT），这是一个轻量级框架，它扩展了RAG以支持多轮对话和演变的工具环境，而无需重新训练。DCT集成了基于注意力的上下文缓存来跟踪相关的历史信息，基于LoRA的检索来动态选择特定领域的工具，以及高效的上下文压缩以将输入保持在LLM上下文限制内。在合成和真实世界基准上的实验表明，DCT将规划准确性提高了14%，并将幻觉减少了37%，同时以显著更低的成本达到了GPT-4的性能。此外，DCT能够泛化到以前未见过的工具，从而在广泛的动态环境中实现可扩展和适应性强的AI助手。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [331] [Persistent Homology of Topic Networks for the Prediction of Reader Curiosity](https://arxiv.org/abs/2506.11095)
> *基于主题网络的持久同调在读者好奇心预测中的应用*

*Manuel D. S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley Jach, Kou Murayama* | **Main category: cs.CL**

**Keywords:** 读者好奇心, 持久同调, 主题网络, 信息差距, 文本分析

**Comment:** 

> **TL;DR:** 本文提出了一种利用BERTopic主题建模和持久同调分析文本语义网络拓扑特征来量化信息差距并预测读者好奇心的方法，实验证明其预测效果显著优于基线模型。

**AI_Comments:** 本文的创新点在于将持久同调这一拓扑数据分析工具引入到自然语言处理领域，用于量化文本中的语义信息差距，并将其应用于读者好奇心的预测。这种跨学科的方法为理解文本复杂结构与认知过程之间的关系提供了新颖的计算视角，具有重要的理论和应用价值。其显著优于基线模型的预测效果也验证了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 读者好奇心是文本参与度的关键因素，但在自然语言处理领域仍未得到充分探索。

**Method:** 本文基于Loewenstein的信息差距理论，提出了一种量化文本语义结构中信息差距的框架。该方法利用BERTopic启发式主题建模和持久同调来分析从文本片段中派生的动态语义网络的演化拓扑结构（连通分量、循环、空隙），并将这些拓扑特征作为信息差距的代理。为了评估该方法，研究人员收集了49名参与者阅读《饥饿游戏》时产生的读者好奇心评分，并使用这些拓扑特征作为自变量来预测评分。

**Result:** 实验结果表明，与基线模型相比，该方法显著提高了好奇心预测的准确性（解释偏差从30%提高到73%），验证了该方法的有效性。

**Conclusion:** 该研究提出的管道为分析文本结构及其与读者参与度的关系提供了一种新的计算方法。

> **ai_Abstract:** 本文提出了一种新颖的计算框架，通过结合BERTopic主题建模和持久同调来量化文本中的语义信息差距，从而预测读者好奇心。该方法将文本片段构建成动态语义网络，并分析其拓扑特征（如连通分量、循环）作为信息差距的度量。通过对49名参与者阅读《饥饿游戏》时好奇心评分的预测实验，结果显示该方法相较于基线模型能显著提升预测性能（解释偏差从30%增至73%），为理解文本结构与读者参与度之间的关系提供了新的视角。

> **摘要翻译:** 读者好奇心，即寻求信息的驱动力，对于文本参与至关重要，但在自然语言处理（NLP）领域仍相对未被充分探索。本文基于洛温斯坦的信息差距理论，引入了一个框架，通过量化文本语义结构中的语义信息差距来建模读者好奇心。我们的方法利用受BERTopic启发的主题建模和持久同调，分析从文本片段中提取的动态语义网络的演化拓扑结构（连通分量、循环、空隙），并将这些特征视为信息差距的代理。为了实证评估这一流程，我们收集了49名参与者在阅读S.柯林斯的《饥饿游戏》小说时的读者好奇心评分。然后，我们使用我们流程中的拓扑特征作为自变量来预测这些评分，实验结果表明，与基线模型相比，这些特征显著改善了好奇心预测（解释偏差从30%提高到73%），验证了我们的方法。这一流程为分析文本结构及其与读者参与度的关系提供了一种新的计算方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [344] [Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech](https://arxiv.org/abs/2506.11119)
> *基准测试用于从自发语音中检测阿尔茨海默病及相关痴呆症的基础语音和语言模型*

*Jingyu Li, Lingchao Mao, Hairong Wang, Zhendong Wang, Xi Mao, Xuelei Sherry Ni* | **Main category: cs.CL**

**Keywords:** 阿尔茨海默病, 痴呆症检测, 基础模型, 自发语音, 基准测试

**Comment:** 

> **TL;DR:** 本研究对基础语音和语言模型进行了基准测试，以从自发语音中早期检测阿尔茨海默病及相关痴呆症，发现基于声学的方法（特别是ASR派生的嵌入）表现出强大潜力。

**AI_Comments:** 这篇论文的创新点在于首次对基础语音和语言模型在ADRD检测中的应用进行了系统性的基准测试。其重要性体现在强调了自发语音作为非侵入性生物标志物的潜力，并指出基于声学的方法，特别是ASR派生的嵌入，在临床应用中的前景。研究还揭示了非语义特征（如停顿模式）在文本分类中的价值。

<details>
  <summary>Details</summary>

**Motivation:** 阿尔茨海默病及相关痴呆症 (ADRD) 是进行性神经退行性疾病，早期检测对于及时干预和护理至关重要。自发语音包含丰富的声学和语言标记，可作为认知能力下降的非侵入性生物标志物。基础模型（预训练于大规模音频或文本数据）能产生编码上下文和声学特征的高维嵌入。

**Method:** 使用PREPARE挑战赛数据集，包含来自1600多名参与者的音频记录，分为健康对照 (HC)、轻度认知障碍 (MCI) 和阿尔茨海默病 (AD) 三种认知状态。排除了非英语、非自发或质量差的记录。最终数据集包含703例HC、81例MCI和405例AD。对一系列开源基础语音和语言模型进行基准测试，以将认知状态分类为这三类。

**Result:** Whisper-medium模型在语音模型中表现最佳（准确率=0.731，AUC=0.802）。在语言模型中，带有停顿标注的BERT表现最佳（准确率=0.662，AUC=0.744）。使用最先进的自动语音识别 (ASR) 模型生成的音频嵌入进行ADRD检测优于其他方法。包含非语义特征（如停顿模式）持续改进了基于文本的分类。

**Conclusion:** 本研究引入了一个使用基础模型和临床相关数据集的基准测试框架。基于声学的方法——特别是ASR派生的嵌入——展示了在ADRD可扩展、非侵入性和成本效益高的早期检测方面的强大潜力。

> **ai_Abstract:** 本研究对多种开源基础语音和语言模型进行了基准测试，以评估它们从自发语音中检测阿尔茨海默病及相关痴呆症（ADRD）的性能。研究使用了PREPARE挑战赛数据集，对健康对照、轻度认知障碍和阿尔茨海默病患者的语音进行分类。结果显示，Whisper-medium模型在语音模型中表现最佳，而带有停顿标注的BERT在语言模型中表现最佳。特别指出，基于ASR模型生成的音频嵌入在ADRD检测中表现出色，且非语义特征（如停顿模式）对文本分类有持续改进。研究表明，基于声学的方法在ADRD的早期、可扩展、非侵入性和成本效益高的检测方面具有巨大潜力。

> **摘要翻译:** 背景：阿尔茨海默病及相关痴呆症（ADRD）是进行性神经退行性疾病，早期检测对于及时干预和护理至关重要。自发语音包含丰富的声学和语言标记，可作为认知能力下降的非侵入性生物标志物。基础模型，预训练于大规模音频或文本数据，产生编码上下文和声学特征的高维嵌入。
方法：我们使用了PREPARE挑战赛数据集，其中包含来自1600多名参与者的音频记录，这些参与者具有三种认知状态：健康对照（HC）、轻度认知障碍（MCI）和阿尔茨海默病（AD）。我们排除了非英语、非自发或质量差的录音。最终数据集包括703例（59.13%）HC、81例（6.81%）MCI和405例（34.06%）AD病例。我们对一系列开源基础语音和语言模型进行了基准测试，以将认知状态分类为这三类。
结果：Whisper-medium模型在语音模型中表现最佳（准确率=0.731，AUC=0.802）。在语言模型中，带有停顿标注的BERT表现最佳（准确率=0.662，AUC=0.744）。使用最先进的自动语音识别（ASR）模型生成的音频嵌入进行ADRD检测优于其他方法。包含非语义特征（如停顿模式）持续改进了基于文本的分类。
结论：本研究引入了一个使用基础模型和临床相关数据集的基准测试框架。基于声学的方法——特别是ASR派生的嵌入——展示了在ADRD可扩展、非侵入性和成本效益高的早期检测方面的强大潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [345] [Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey](https://arxiv.org/abs/2506.11102)
> *基于LLM的AI智能体评估的演化视角：一项全面综述*

*Jiachen Zhu, Menghui Zhu, Renting Rui, Rong Shan, Congmin Zheng, Bo Chen, Yunjia Xi, Jianghao Lin, Weiwen Liu, Ruiming Tang, Yong Yu, Weinan Zhang* | **Main category: cs.CL**

**Keywords:** LLM, AI智能体, 评估, 演化视角, 基准

**Comment:** 

> **TL;DR:** 本文从演化角度全面综述了基于LLM的AI智能体评估方法，区分了LLM聊天机器人与AI智能体，并提供了评估基准的选择指南。

**AI_Comments:** 本文的创新之处在于其“演化视角”，清晰地界定了LLM聊天机器人与AI智能体的区别，并提供了结构化的评估框架，对于规范和指导AI智能体评估具有重要意义。它弥补了当前领域中概念混淆的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估框架常常模糊了大型语言模型（LLM）聊天机器人和AI智能体之间的区别，导致研究人员在选择合适的基准时感到困惑，本文旨在弥合这一差距。

**Method:** 本文从演化视角出发，对当前的评估方法进行了系统分析。提供了一个详细的分析框架，从五个关键方面（复杂环境、多源指令者、动态反馈、多模态感知和高级能力）清晰地区分了AI智能体和LLM聊天机器人。此外，根据外部环境驱动力和由此产生的先进内部能力对现有评估基准进行了分类，并概述了通过环境、智能体、评估者和指标这四个关键视角展望未来的评估方法。

**Result:** 本文提供了一个详细的分析框架，从五个关键方面（复杂环境、多源指令者、动态反馈、多模态感知和高级能力）明确区分了AI智能体和LLM聊天机器人。对现有评估基准进行了分类，并为每个类别阐述了评估属性。综合了当前趋势，并提出了通过四个关键视角（环境、智能体、评估者、指标）的未来评估方法。

**Conclusion:** 本研究为研究人员提供了可操作的指导，有助于他们在AI智能体评估中明智地选择和应用基准，从而促进该快速发展领域的持续进步。

> **ai_Abstract:** 本综述从演化视角出发，系统分析了基于大型语言模型（LLM）的AI智能体评估方法。针对现有评估框架混淆LLM聊天机器人与AI智能体的问题，论文提出了一个详细的分析框架，从复杂环境、多源指令者、动态反馈、多模态感知和高级能力五个方面明确区分二者。同时，论文根据外部环境驱动力和内部能力对现有评估基准进行分类，并提出了未来的评估方法，旨在为研究人员提供AI智能体评估基准选择与应用的指导。

> **摘要翻译:** GPT、Gemini和DeepSeek等大型语言模型（LLM）的出现极大地推动了自然语言处理的发展，催生了能够执行各种语言相关任务的复杂聊天机器人。从这些传统的LLM聊天机器人到更高级的AI智能体的转变代表了一个关键的演进步骤。然而，现有的评估框架常常模糊了LLM聊天机器人和AI智能体之间的区别，导致研究人员在选择合适的基准时感到困惑。为了弥合这一差距，本文从演化视角出发，对当前的评估方法进行了系统分析。我们提供了一个详细的分析框架，从五个关键方面清晰地区分了AI智能体和LLM聊天机器人：复杂环境、多源指令者、动态反馈、多模态感知和高级能力。此外，我们根据外部环境驱动力和由此产生的先进内部能力对现有评估基准进行了分类。对于每个类别，我们都详细阐述了相关的评估属性，并以实用的参考表格形式全面呈现。最后，我们综合了当前趋势，并通过环境、智能体、评估者和指标这四个关键视角概述了未来的评估方法。我们的研究结果为研究人员提供了可操作的指导，有助于他们在AI智能体评估中明智地选择和应用基准，从而促进这一快速发展研究领域的持续进步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [352] [SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR](https://arxiv.org/abs/2506.11121)
> *SUTA-LM：弥合测试时自适应与语言模型重评分以实现鲁棒ASR*

*Wei-Ping Huang, Guan-Ting Lin, Hung-yi Lee* | **Main category: cs.CL**

**Keywords:** 测试时自适应, 语言模型重评分, 鲁棒ASR, 领域不匹配, SUTA-LM

**Comment:** 

> **TL;DR:** 提出SUTA-LM，一种结合测试时自适应和语言模型重评分的方法，以提高ASR在领域不匹配时的鲁棒性。

**AI_Comments:** 本文的创新点在于识别并解决了测试时自适应与语言模型重评分结合时可能出现的冲突，并提出了一个简单有效的框架SUTA-LM来克服这一挑战。其重要性在于提高了ASR系统在复杂实际领域中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管端到端ASR取得了进展，但现实世界中的领域不匹配仍会导致性能下降。测试时自适应（TTA）旨在缓解此问题。现有工作探索了将TTA与外部语言模型结合，但本文发现TTA可能会干扰语言模型重评分，这揭示了有效结合这两种方法的非平凡性。

**Method:** 本文提出了SUTA-LM，是SUTA（一种基于熵最小化的测试时自适应方法）的简单而有效的扩展。SUTA-LM首先应用一个受控的自适应过程，该过程由利用声学和语言信息的自动步骤选择机制引导，然后通过语言模型重评分来细化输出。

**Result:** 在18个不同的ASR数据集上进行的实验表明，SUTA-LM在广泛的领域中都取得了鲁棒的结果。

**Conclusion:** SUTA-LM成功解决了测试时自适应与语言模型重评分结合的挑战，提高了ASR系统在领域不匹配情况下的鲁棒性。

> **ai_Abstract:** 本文提出了SUTA-LM，一种结合测试时自适应（TTA）和语言模型重评分的新方法，旨在解决端到端ASR在领域不匹配时的性能下降问题。研究发现TTA可能干扰语言模型重评分，因此SUTA-LM设计了一个受控的自适应过程，结合声学和语言信息进行自动步骤选择，随后进行语言模型重评分以优化输出。实验证明SUTA-LM在多个ASR数据集上表现出鲁棒性。

> **摘要翻译:** 尽管端到端ASR取得了进展，但现实世界中的领域不匹配仍然导致性能下降，测试时自适应（TTA）旨在通过在推理过程中调整模型来缓解这一问题。最近的工作探索了将TTA与外部语言模型结合，使用了束搜索重评分或生成式错误校正等技术。在这项工作中，我们发现了一个以前被忽视的挑战：TTA可能会干扰语言模型重评分，这揭示了有效结合这两种方法的非平凡性。基于这一见解，我们提出了SUTA-LM，一个简单而有效的SUTA扩展，SUTA是一种基于熵最小化的TTA方法，并结合了语言模型重评分。SUTA-LM首先应用一个受控的自适应过程，该过程由利用声学和语言信息的自动步骤选择机制引导，然后通过语言模型重评分来细化输出。在18个不同ASR数据集上的实验表明，SUTA-LM在广泛的领域中都取得了鲁棒的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [354] [You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model](https://arxiv.org/abs/2506.11103)
> *你只需微调一次：大型语言模型的多样本情境微调*

*Wenchong He, Liqian Peng, Zhe Jiang, Alex Go* | **Main category: cs.CL**

**Keywords:** 多样本情境微调, 大型语言模型, 情境学习, 灾难性遗忘, 微调

**Comment:** 16 pages, 6 figures

> **TL;DR:** 本文提出了一种名为ManyICL的新方法，通过将情境中的每个答案视为监督训练目标，显著缩小了大型语言模型情境学习与专用微调之间的性能差距，并缓解了灾难性遗忘。

**AI_Comments:** 这项研究的创新之处在于提出了ManyICL方法及其独特的训练目标，即将情境中的所有答案作为监督信号，而非仅仅是最终答案。这有效地将多样本示例从简单的提示转化为更丰富的训练数据，极大地提升了情境学习的效率和效果。其重要性在于，它为弥合情境学习与传统专用微调之间的性能鸿沟提供了一个有前景的解决方案，同时缓解了LLMs在多任务学习中常见的灾难性遗忘问题。这对于开发更通用、更高效的LLMs具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的情境学习（ICL）能力虽然强大，但现有的少数样本情境微调方法仍落后于为每个任务单独训练模型的专用微调。此外，处理包含大量情境示例的长序列效率低下。

**Method:** 本文提出了一种新颖的方法：多样本情境微调（ManyICL）。为解决处理长序列的低效性，作者提出了一种新的训练目标：将情境中的每个答案都视为一个监督训练目标，从而将多样本示例的角色从提示转变为自回归学习的目标。

**Result:** ManyICL在分类、摘要、问答、自然语言推理和数学等多种下游任务上，显著优于零样本/少数样本微调，并且性能接近专用微调。此外，ManyICL显著缓解了零样本/少数样本微调中观察到的灾难性遗忘问题。

**Conclusion:** ManyICL是一种有效的方法，它通过将情境中的所有答案作为训练目标，显著缩小了大型语言模型情境学习与专用微调之间的性能差距，并有效缓解了灾难性遗忘问题。

> **ai_Abstract:** 本文提出了一种名为ManyICL（多样本情境微调）的新方法，旨在缩小大型语言模型（LLMs）情境学习与专用微调之间的性能差距。ManyICL通过将情境中的所有答案视为监督训练目标，而非仅仅是提示，从而有效利用多样本示例进行自回归学习。实验结果表明，ManyICL在多种下游任务上显著优于零样本/少数样本微调，性能接近专用微调，并有效缓解了灾难性遗忘问题。

> **摘要翻译:** 大型语言模型（LLMs）具备显著的情境学习（ICL）能力，这使它们能够同时处理多个下游任务，而无需进行针对特定任务的微调。最近的研究表明，即使是中等规模的LLMs，如Mistral 7B、Gemma 7B和Llama-3 8B，也能通过一次性对所有任务进行少量样本的情境微调来实现ICL。然而，这种方法仍然落后于专用微调，即为每个单独任务训练一个单独的模型。
在本文中，我们提出了一种新颖的方法，多样本情境微调（ManyICL），它通过将ICL的原则扩展到多样本设置，显著缩小了这一性能差距。为了充分发挥ManyICL的潜力并解决处理包含大量情境示例的长序列的固有低效率问题，我们提出了一种新颖的训练目标。我们的方法不是仅仅预测最终答案，而是将情境中的每个答案都视为一个监督训练目标。这有效地将多样本示例的角色从提示转变为自回归学习的目标。通过在包括分类、摘要、问答、自然语言推理和数学在内的多种下游任务上进行广泛实验，我们证明了ManyICL显著优于零样本/少量样本微调，并且性能接近专用微调。此外，ManyICL显著缓解了在零样本/少量样本微调中观察到的灾难性遗忘问题。代码将在发表后公开。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [361] [A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data](https://arxiv.org/abs/2506.11130)
> *使用TTS合成数据增强ASR的自精炼框架*

*Cheng Kang Chou, Chan-Jan Hsu, Ho-Lam Chung, Liang-Hsuan Tseng, Hsi-Chun Cheng, Yu-Kuan Fu, Kuan Po Huang, Hung-Yi Lee* | **Main category: cs.CL**

**Keywords:** ASR增强, TTS合成数据, 自精炼框架, 伪标签, 低资源语音识别

**Comment:** 

> **TL;DR:** 提出一种自精炼框架，通过生成伪标签训练TTS，再用TTS合成数据回传增强ASR模型，尤其适用于低资源场景，并在普通话和中英混杂语中显著降低了错误率。

**AI_Comments:** 该研究提出了一种新颖的自精炼框架，通过结合ASR和TTS技术，实现了在仅有大量未标注数据的情况下提升ASR性能，这对于低资源语言或特定领域ASR的发展具有重要意义。其闭环自举机制有效避免了对大量人工标注数据的依赖，并展现了优于传统伪标签方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在仅利用未标注数据集提升ASR（自动语音识别）性能，特别是在资源匮乏或特定领域环境下改进ASR表现。

**Method:** 该框架是一个闭环自改进过程：首先，现有ASR模型在未标注语音上生成伪标签；接着，这些伪标签用于训练高保真TTS（文本到语音）系统；然后，TTS合成的语音-文本对被重新输入到原始ASR系统中进行自举训练，完成性能提升。

**Result:** 在台湾普通话语音上验证了该框架的有效性。利用6000小时未标注语音和适量文本数据，将Whisper-large-v2模型优化为Twister。Twister在普通话基准测试中错误率降低高达20%，在中英混杂语基准测试中错误率降低高达50%，优于Whisper。

**Conclusion:** 该框架是伪标签自蒸馏方法的一个有吸引力的替代方案，为在低资源或特定领域环境中提升ASR性能提供了一条实用途径。

> **ai_Abstract:** 本文提出一个自精炼框架，利用未标注语音数据提升ASR性能。该框架通过现有ASR模型生成伪标签训练高保真TTS系统，再将TTS合成的语音-文本对回传训练ASR，形成闭环自改进。实验表明，该方法在台湾普通话上将Whisper-large-v2模型优化为Twister，在普通话和中英混杂语识别上分别降低了20%和50%的错误率，为低资源或特定领域ASR改进提供了有效途径。

> **摘要翻译:** 我们提出了一个自精炼框架，仅使用未标注数据集即可提升ASR性能。该过程始于现有ASR模型在未标注语音上生成伪标签，这些伪标签随后用于训练一个高保真文本到语音（TTS）系统。然后，合成的语音-文本对被引导回原始ASR系统，完成闭环自改进循环。我们在台湾普通话语音上展示了该框架的有效性。利用6000小时的未标注语音、适量的文本数据以及AI模型合成的内容，我们将Whisper-large-v2改造为一个专门模型Twister。与Whisper相比，Twister在普通话基准测试中错误率降低高达20%，在普通话-英语混杂语基准测试中错误率降低高达50%。结果突出表明，该框架是伪标签自蒸馏方法的一个引人注目的替代方案，并为在低资源或特定领域环境中提高ASR性能提供了一条实用途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [363] [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://arxiv.org/abs/2506.11104)
> *DAM：用于长上下文大型语言模型推理加速的动态注意力掩码*

*Hanzhi Zhang, Heng Fan, Kewei Sha, Yan Huang, Yunhe Feng* | **Main category: cs.CL**

**Keywords:** 动态注意力掩码, 长上下文, 大型语言模型, 推理加速, 稀疏注意力

**Comment:** 

> **TL;DR:** 本文提出了DAM，一种用于大型语言模型的动态注意力掩码机制，通过自适应地掩盖注意力来加速长上下文推理，在不进行微调的情况下保持性能。

**AI_Comments:** DAM的创新点在于其动态和自适应的注意力掩码机制，解决了传统稀疏注意力静态掩码的局限性，特别是在捕获异构注意力模式方面的不足。其无需微调的特性大大降低了应用门槛，使其成为LLM推理加速领域一个有前景且实用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 长上下文理解对NLP应用至关重要，但Transformer的自注意力机制具有二次复杂度，导致效率低下。现有稀疏注意力方法使用静态预定义掩码，无法捕获异构注意力模式，限制了长序列任务的适应性和检索准确性。

**Method:** 本文引入了一种动态稀疏注意力机制——DAM（Dynamic Attention Mask），它在注意力图级别分配自适应掩码，以保留跨层和头部的异构模式。该方法通过学习上下文感知的注意力结构，无需微调和预定义的掩码结构，同时保持计算效率。

**Result:** DAM实现了与全注意力模型的高度对齐，确保了最小的性能下降，并显著减少了内存和计算开销。它为全注意力提供了一种可扩展的替代方案。

**Conclusion:** DAM通过提供一种可扩展且高效的动态注意力机制，使得大规模大型语言模型（LLM）在长上下文任务中的实际部署成为可能，且不牺牲检索性能。

> **ai_Abstract:** 本文提出了一种名为DAM的动态注意力掩码机制，旨在解决长上下文大型语言模型推理中Transformer自注意力机制的二次复杂度问题。与现有静态稀疏注意力不同，DAM在注意力图级别自适应地学习并应用掩码，从而捕获异构注意力模式。该方法无需微调和预定义掩码结构，同时保持计算效率，实现了与全注意力模型相似的性能，显著降低了内存和计算开销，为LLM在长序列任务中的实际部署提供了可扩展且高效的解决方案。

> **摘要翻译:** 长上下文理解对于许多自然语言处理应用至关重要，然而由于自注意力的二次复杂度，Transformer在效率方面面临挑战。稀疏注意力方法可以缓解这一成本，但通常会施加静态的、预定义的掩码，未能捕获异构注意力模式。这导致次优的令牌交互，限制了长序列任务中的适应性和检索准确性。这项工作引入了一种动态稀疏注意力机制，在注意力图级别分配自适应掩码，保留跨层和头部的异构模式。与现有方法不同，我们的方法无需微调和预定义的掩码结构，同时保持计算效率。通过学习上下文感知的注意力结构，它实现了与全注意力模型的高度对齐，确保性能下降最小化，同时减少内存和计算开销。这种方法为全注意力提供了一种可扩展的替代方案，使得大规模大型语言模型 (LLM) 的实际部署成为可能，而不会牺牲检索性能。DAM 可在以下网址获取：https://github.com/HanzhiZhang-Ulrica/DAM。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [379] [History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM](https://arxiv.org/abs/2506.11108)
> *历史感知交叉注意力强化：基于vLLM的自监督多轮对话和思维链微调*

*Andrew Kiruluta, Andreas Lemos, Priscilla Burity* | **Main category: cs.CL**

**Keywords:** 交叉注意力, 强化学习, 自监督, 多轮对话, 思维链, vLLM

**Comment:** 

> **TL;DR:** 介绍CAGSR-vLLM-MTC，一个在vLLM上实现的历史感知交叉注意力强化框架，用于多轮对话和思维链推理的自监督微调，通过捕获注意力权重并泛化奖励函数实现。

**AI_Comments:** 这项工作通过将历史感知交叉注意力强化引入高性能vLLM运行时，为多轮对话和思维链推理提供了一种新颖的自监督微调方法。其创新之处在于能够异步捕获注意力权重并将其整合到泛化的奖励函数中，从而利用整个对话历史进行学习。这对于提升大型语言模型在复杂交互和推理任务中的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决多轮对话和思维链推理的挑战。

**Method:** 将自监督交叉注意力引导强化 (CAGSR) 框架扩展为 CAGSR-vLLM-MTC，并在高性能 vLLM 运行时上实现。通过修改 vLLM 的 C++/CUDA 内核异步捕获每层、每头的交叉注意力权重，并泛化自监督奖励函数以累积整个对话历史和思维链步骤的注意力信号。还讨论了基于熵的钳制机制以防止早期上下文的注意力崩溃。

**Result:** 成功在vLLM上实现了历史感知的交叉注意力强化，使其能够处理多轮对话和思维链推理，并提出了防止注意力崩溃的机制。

**Conclusion:** 本文成功地扩展了自监督交叉注意力引导强化框架，使其能够通过历史感知的注意力信号处理复杂的多轮对话和思维链推理任务，并在高性能vLLM运行时上进行了实现。

> **ai_Abstract:** 本文介绍了 CAGSR-vLLM-MTC，一个在高性能 vLLM 运行时上实现的自监督交叉注意力引导强化 (CAGSR) 框架的扩展，旨在处理多轮对话和思维链推理。该方法通过修改 vLLM 内核来异步捕获交叉注意力权重，并泛化自监督奖励函数以累积整个对话历史和思维链步骤的注意力信号。研究还讨论了防止注意力崩溃的实用机制。

> **摘要翻译:** 我们提出了 CAGSR-vLLM-MTC，这是我们自监督交叉注意力引导强化 (CAGSR) 框架的一个扩展，现在已在高性能 vLLM 运行时上实现，以解决多轮对话和思维链推理问题。在我们最初的单轮方法基础上，我们首先对 vLLM 的 C++/CUDA 内核进行了修改，以在生成过程中异步捕获每层、每头的交叉注意力权重。然后，我们泛化了自监督奖励函数，以累积整个对话历史和中间思维链步骤的注意力信号。我们讨论了实际的权衡，包括一种基于熵的钳制机制，以防止早期上下文的注意力崩溃，并概述了多方对话和分层推理的未来方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [385] [Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization](https://arxiv.org/abs/2506.11109)
> *通过语义位置Token化增强用于出行分析的大型语言模型*

*Yile Chen, Yicheng Tao, Yue Jiang, Shuai Liu, Han Yu, Gao Cong* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 出行分析, 语义位置Token化, 下一位置预测, 出行恢复

**Comment:** Accepted by KDD'25

> **TL;DR:** QT-Mob通过语义位置Token化和专门的微调，增强了大型语言模型（LLMs）在出行分析方面的能力，性能优于现有方法。

**AI_Comments:** 这篇论文通过将语义Token化应用于位置数据，有效地弥合了离散位置ID与LLM语义理解能力之间的鸿沟，提出了一种创新方法。专门的微调目标的整合进一步增强了模型解释复杂出行模式的能力，使其成为利用LLM进行城市出行分析方面的一个重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于出行分析的大型语言模型（LLMs）方法存在两个主要限制：一是位置的语义表示不足（即使用离散ID），二是LLMs中出行信号建模不充分（即单一模板指令微调）。

**Method:** 本文提出了QT-Mob框架，该框架通过引入一个位置Token化模块来学习紧凑且语义丰富的位置Token，从而保留上下文信息并确保与LLMs的兼容性。此外，QT-Mob还结合了一系列互补的微调目标，以使学习到的Token与LLMs的内部表示对齐，从而提高模型对序列移动模式和位置语义的理解。

**Result:** 在三个真实世界数据集上的实验表明，QT-Mob在下一位置预测和出行恢复任务中均表现出卓越的性能，优于现有的深度学习和基于LLM的方法。

**Conclusion:** QT-Mob框架不仅增强了大型语言模型（LLMs）解释出行数据的能力，而且为各种出行分析任务提供了一种更通用的方法，并在实验中展示了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为QT-Mob的新颖框架，旨在增强大型语言模型（LLMs）在出行分析方面的能力。该框架通过引入语义位置Token化模块和互补的微调目标，解决了现有方法中位置语义表示不足和出行信号建模不充分的问题。QT-Mob学习紧凑且语义丰富的位置Token，并将其与LLM的内部表示对齐，从而提高了对移动模式的理解。在真实世界数据集上的实验表明，QT-Mob在下一位置预测和出行恢复任务中表现出卓越的性能，为出行分析提供了一种更通用的方法。

> **摘要翻译:** 基于位置服务的广泛采用导致了大量出行数据的生成，为在城市环境中建模用户移动动态提供了重要机会。最近的进展集中于将大型语言模型（LLMs）应用于出行分析。然而，现有方法面临两个主要限制：位置语义表示不足（即离散ID）和LLMs中出行信号建模不充分（即单一模板指令微调）。为了解决这些问题，我们提出了QT-Mob，一个显著增强LLMs用于出行分析的新颖框架。QT-Mob引入了一个位置Token化模块，该模块学习紧凑、语义丰富的Token来表示位置，在保留上下文信息的同时确保与LLMs的兼容性。此外，QT-Mob结合了一系列互补的微调目标，使学习到的Token与LLMs中的内部表示对齐，从而提高了模型对序列移动模式和位置语义的理解。所提出的QT-Mob框架不仅增强了LLMs解释出行数据的能力，而且为各种出行分析任务提供了一种更通用的方法。在三个真实世界数据集上的实验表明，在下一位置预测和出行恢复任务中，QT-Mob表现出卓越的性能，优于现有的深度学习和基于LLM的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [391] [AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models](https://arxiv.org/abs/2506.11110)
> *AssertBench：评估大型语言模型自我主张能力的基准*

*Jaeho Lee, Atharv Chowdhary* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 自我主张, 基准测试, 事实一致性, 框架效应

**Comment:** 15 pages, 4 figures, appendix contains 2 additional figures and 2
  tables

> **TL;DR:** AssertBench是一个新基准，旨在评估大型语言模型（LLMs）在用户提出矛盾主张时，能否坚持其对事实的真实性判断，而非随用户而变。

**AI_Comments:** 该论文的创新点在于关注大型语言模型的“自我主张”能力，即在面对用户带有倾向性的引导时，模型能否坚持其对事实的独立判断。这对于提升LLM的可靠性和用户信任至关重要。通过设计两种方向性框架的提示并结合结果分层，AssertBench提供了一种有效的方法来隔离并测量框架对模型判断的影响，从而更精确地评估模型的核心事实知识与外部影响之间的关系。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准已探究大型语言模型（LLMs）的事实一致性和修辞稳健性，但对于事实陈述的方向性框架如何影响模型认同，存在知识空白，而这在LLM用户场景中是一个常见情况。

**Method:** AssertBench通过从事实验证数据集FEVEROUS中采样有证据支持的事实。对于每个事实，构建两种框架提示：一种是用户声称该陈述事实正确，另一种是用户声称其不正确。然后记录模型的认同和推理。通过根据模型在中立呈现相同主张时的准确性来分层结果，从而将框架引起的变异性与模型潜在的事实知识隔离开来。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** AssertBench是一个新颖的基准，旨在评估大型语言模型（LLMs）在面对用户对同一事实的矛盾主张时，能否保持其对事实的真实性判断并“坚持己见”。该基准从FEVEROUS数据集中抽取有证据支持的事实，并为每个事实构建两种不同方向性框架的提示（用户声称正确或不正确），以测试模型的一致性。通过根据模型在中立情境下的准确性对结果进行分层，AssertBench能够隔离并测量框架对模型判断的影响，从而评估LLM的自我主张能力。

> **摘要翻译:** 最近的基准已经探究了大型语言模型（LLMs）的事实一致性和修辞稳健性。然而，关于事实性真实陈述的方向性框架如何影响模型认同存在知识空白，而这对于LLM用户来说是一个常见场景。AssertBench通过从事实验证数据集FEVEROUS中采样有证据支持的事实来解决这个问题。对于每个（有证据支持的）事实，我们构建两种框架提示：一种是用户声称该陈述事实正确，另一种是用户声称其不正确。然后我们记录模型的认同和推理。期望的结果是模型能够自我主张，在两种框架下保持一致的真实性评估，而不是改变其评估以迎合用户。AssertBench通过根据模型在中立呈现相同主张时的准确性来分层结果，从而将框架引起的变异性与模型潜在的事实知识隔离开来。通过这样做，该基准旨在衡量LLM在面对用户对同一事实的矛盾主张时“坚持己见”的能力。完整的源代码可在https://github.com/achowd32/assert-bench获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [396] [Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](https://arxiv.org/abs/2506.11111)
> *评估和提升大型语言模型鲁棒性：一项综述与未来方向*

*Kun Zhang, Le Wu, Kui Yu, Guangyi Lv, Dacao Zhang* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 鲁棒性, 综述, 对抗鲁棒性, OOD鲁棒性

**Comment:** 33 pages, 5 figures

> **TL;DR:** 这篇综述论文全面回顾了大型语言模型（LLMs）的鲁棒性，并提出了未来的研究方向。

**AI_Comments:** 这篇综述论文对大型语言模型鲁棒性领域进行了及时且全面的梳理。其创新之处在于系统地定义了鲁棒性概念，并根据扰动类型进行了清晰的分类，这对于理解和组织该领域的复杂研究具有重要意义。论文还展望了未来的研究方向，并提供了一个资源项目，对研究社区具有很高的实用价值和指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的快速发展和广泛应用，其鲁棒性问题日益受到关注。LLMs作为许多AI应用的核心，需要确保在处理意外场景（如恶意提示、有限噪声数据、分布外应用）时，不仅能生成一致的内容，还能保证内容的正确性和稳定性。因此，有必要对LLM的鲁棒性进行全面的综述。

**Method:** 本文首先给出了LLM鲁棒性的正式定义，并介绍了综述的收集协议。然后，根据扰动输入的类型，将综述内容分为以下几个方面：1) 对抗鲁棒性（处理有意操纵的提示）；2) OOD鲁棒性（处理意外的真实世界应用场景）；3) 鲁棒性评估（总结新的评估数据集、指标和工具）。在回顾了每个方面的代表性工作后，讨论并强调了该领域的未来机遇和研究方向。

**Result:** 本文对大型语言模型的鲁棒性进行了全面回顾，系统地定义了相关概念和方法，并从对抗鲁棒性、OOD鲁棒性和鲁棒性评估三个主要方面对现有工作进行了组织和总结。此外，还讨论了未来的研究方向，并提供了一个相关工作的项目（Awesome-LLM-Robustness-papers）以支持社区。

**Conclusion:** 论文总结了大型语言模型鲁棒性的现状，并展望了该领域的未来研究机遇和方向，旨在为社区提供全面的术语和方法，并促进该领域的发展。

> **ai_Abstract:** 这篇综述论文全面探讨了大型语言模型（LLMs）的鲁棒性，鉴于其在广泛应用中面临的意外场景挑战。论文首先定义了LLM鲁棒性，并根据扰动输入的类型，将现有研究分为对抗鲁棒性、分布外（OOD）鲁棒性和鲁棒性评估三个主要类别进行系统回顾。最后，论文讨论了未来的研究方向，并为社区提供了一个资源库。

> **摘要翻译:** 近年来，大型语言模型（LLMs）因其理解和生成自然语言的能力而受到广泛关注。随着其快速发展和广泛应用（例如，智能体、具身智能），LLMs的鲁棒性也受到了越来越多的关注。作为许多AI应用的核心大脑，LLMs的鲁棒性要求模型在处理意外应用场景（例如，恶意提示、有限噪声领域数据、分布外（OOD）应用等）时，不仅要生成一致的内容，还要确保生成内容的正确性和稳定性。在这篇综述论文中，我们对LLMs的鲁棒性进行了彻底的回顾，旨在提供该领域概念和方法的全面术语，并促进社区发展。具体来说，我们首先给出了LLM鲁棒性的正式定义，并介绍了本综述论文的收集协议。然后，根据扰动输入的类型，我们从以下几个方面组织了本综述：1）对抗鲁棒性：解决提示被有意操纵的问题，例如噪声提示、长上下文、数据攻击等；2）OOD鲁棒性：处理意外的真实世界应用场景，例如OOD检测、零样本迁移、幻觉等；3）鲁棒性评估：总结用于验证LLMs鲁棒性的新评估数据集、指标和工具。在回顾了每个方面的代表性工作后，我们讨论并强调了该领域的未来机遇和研究方向。同时，我们还整理了相关工作并提供了一个易于搜索的项目（https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers）以支持社区。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [404] [Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](https://arxiv.org/abs/2506.11113)
> *攻破审稿人：评估大型语言模型在文本对抗性攻击下自动化同行评审的脆弱性*

*Tzu-Ling Lin, Wei-Chih Chen, Teng-Fang Hsiao, Hou-I Liu, Ya-Hsin Yeh, Yu Kai Chan, Wen-Sheng Lien, Po-Yen Kuo, Philip S. Yu, Hong-Han Shuai* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 自动化同行评审, 对抗性攻击, 脆弱性, 学术质量

**Comment:** 

> **TL;DR:** 本文评估了大型语言模型（LLM）在自动化同行评审中面对文本对抗性攻击时的脆弱性，发现其存在显著漏洞，并强调了解决对抗性风险的重要性。

**AI_Comments:** 本文的创新之处在于首次系统地评估了大型语言模型在自动化同行评审这一关键学术环节中，面对文本对抗性攻击的脆弱性。其重要性在于揭示了在将AI技术应用于学术高风险领域时，必须充分考虑其鲁棒性和安全性，以避免潜在的学术诚信风险。这对于确保AI技术能够真正赋能而非损害学术交流的完整性具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 同行评审对维护学术质量至关重要，但日益增长的投稿量给审稿人带来了巨大负担。大型语言模型（LLM）有潜力协助这一过程，但其对文本对抗性攻击的易感性引发了可靠性担忧。因此，本文旨在调查LLM作为自动化审稿人在存在此类攻击时的鲁棒性。

**Method:** 本文通过调查大型语言模型作为自动化审稿人在文本对抗性攻击下的鲁棒性来展开研究。具体而言，研究聚焦于三个关键问题：1) LLM生成评审与人类评审员相比的有效性；2) 对抗性攻击对LLM生成评审可靠性的影响；3) 基于LLM的评审所面临的挑战和潜在缓解策略。研究对LLM在自动化同行评审中的表现及其对抗性攻击的鲁棒性进行了全面评估。

**Result:** 评估结果揭示了显著的脆弱性，文本操纵可以扭曲LLM的评估结果。

**Conclusion:** 研究结果强调了解决对抗性风险的重要性，以确保人工智能能够加强而非损害学术交流的完整性。

> **ai_Abstract:** 本研究评估了大型语言模型（LLM）在自动化同行评审中面对文本对抗性攻击时的脆弱性。论文探讨了LLM生成评审的有效性、对抗性攻击对其可靠性的影响以及潜在的缓解策略。结果表明，LLM在对抗性攻击下表现出显著的漏洞，强调了在将AI应用于学术交流时解决这些风险的必要性。

> **摘要翻译:** 同行评审对于维护学术质量至关重要，但日益增长的投稿量给审稿人带来了巨大的负担。大型语言模型（LLM）在此过程中提供了潜在的帮助，但它们对文本对抗性攻击的易感性引发了可靠性担忧。本文研究了LLM作为自动化审稿人在存在此类攻击时的鲁棒性。我们聚焦于三个关键问题：（1）LLM生成评审与人类评审员相比的有效性。（2）对抗性攻击对LLM生成评审可靠性的影响。（3）基于LLM的评审所面临的挑战和潜在缓解策略。我们的评估揭示了显著的脆弱性，因为文本操纵可以扭曲LLM的评估。我们对LLM在自动化同行评审中的表现进行了全面评估，并分析了其对抗性攻击的鲁棒性。我们的发现强调了解决对抗性风险的重要性，以确保人工智能能够加强而非损害学术交流的完整性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [407] [KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations](https://arxiv.org/abs/2506.11114)
> *KokushiMD-10：用于评估大型语言模型在十项日本国家医疗执照考试中表现的基准*

*Junyu Liu, Kaiqi Yan, Tianyang Wang, Qian Niu, Momoko Nagai-Tanima, Tomoki Aoyama* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 医疗执照考试, 多模态基准, 日本, AI评估

**Comment:** 9pages, 3 figures

> **TL;DR:** 引入了KokushiMD-10，一个包含十项日本医疗执照考试的多模态基准，用于评估LLM在医疗领域的表现，发现当前LLM仍无法稳定通过考试。

**AI_Comments:** 这篇论文通过引入KokushiMD-10，填补了当前LLM医疗评估基准的空白，特别是其多模态和多语言（日语）特性，使其在评估LLM在真实临床场景中的推理能力方面具有创新性和重要性。它不仅提供了大量高质量的真实考试数据，还强调了当前LLM在复杂医疗任务中仍存在的局限性，为未来医疗AI的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准通常是文本、英语中心且主要关注药物，限制了对更广泛医疗知识和多模态推理的评估，尤其是在高风险临床场景中全面评估LLM仍是挑战。

**Method:** 构建了KokushiMD-10，第一个多模态基准，包含来自十项日本国家医疗执照考试的超过11588个真实考试问题，涵盖医学、牙科、护理、药学和相关健康专业，并包含临床图像和专家标注的理由，以评估文本和视觉推理。使用该基准测试了超过30个最先进的LLM。

**Result:** 尽管取得了有希望的结果，但没有模型能在所有领域持续达到及格分数。

**Conclusion:** KokushiMD-10为评估和推进多语言、多模态临床任务中的以推理为中心的医疗AI提供了一个全面且基于语言的资源，并强调了医疗AI面临的持续挑战。

> **ai_Abstract:** 该论文介绍了KokushiMD-10，一个用于评估大型语言模型（LLM）在医疗领域表现的多模态基准。该基准包含来自十项日本国家医疗执照考试的超过11588个问题，涵盖多个医疗专业，并结合了文本和视觉推理元素。研究人员使用该基准测试了30多个最先进的LLM，发现尽管表现有进步，但没有模型能够持续通过所有领域的考试，表明医疗AI仍面临重大挑战。KokushiMD-10旨在成为推进多语言、多模态医疗AI的重要资源。

> **摘要翻译:** 大型语言模型（LLM）的最新进展已在医疗执照考试中展现出显著性能。然而，在各种医疗保健角色中，特别是在高风险临床场景中，对LLM进行全面评估仍然是一个挑战。现有基准通常是基于文本、以英语为中心，并且主要关注药物，这限制了它们评估更广泛医疗保健知识和多模态推理的能力。为了解决这些差距，我们引入了KokushiMD-10，这是第一个由十项日本国家医疗执照考试构建的多模态基准。该基准涵盖多个领域，包括医学、牙科、护理、药学和相关健康专业。它包含超过11588个真实考试问题，融合了临床图像和专家标注的理由，以评估文本和视觉推理。我们使用文本和基于图像的设置对包括GPT-4o、Claude 3.5和Gemini在内的30多个最先进的LLM进行了基准测试。尽管结果喜人，但没有模型能持续达到所有领域的及格分数，这凸显了医疗AI面临的持续挑战。KokushiMD-10为评估和推进多语言、多模态临床任务中的以推理为中心的医疗AI提供了一个全面且基于语言的资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [411] [Incorporating Domain Knowledge into Materials Tokenization](https://arxiv.org/abs/2506.11115)
> *将领域知识融入材料分词*

*Yerim Oh, Jun-Hyung Park, Junho Kim, SungHo Kim, SangKeun Lee* | **Main category: cs.CL**

**Keywords:** 材料科学, 分词, 领域知识, 语言模型, MATTER

**Comment:** 

> **TL;DR:** 提出MATTER，一种将材料领域知识融入分词的新方法，解决了现有方法在材料科学文本中分词过度碎片化和语义丢失的问题，并在生成和分类任务中表现更优。

**AI_Comments:** 这项工作通过将特定领域的知识融入到分词过程中，为材料科学领域的语言模型提供了重要的改进。其创新点在于提出了MATTER方法，利用MatDetector和重排序机制来维护材料概念的完整性，有效解决了传统频率分词的局限性。这对于提升材料科学文本处理的准确性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语言模型在材料科学中使用的分词方法（基于频率）导致过度碎片化和语义丢失，未能保持材料概念的结构和语义完整性。

**Method:** 提出MATTER，一种新的分词方法，它将材料知识整合到分词中。它基于在材料知识库上训练的MatDetector和一个在token合并时优先考虑材料概念的重排序方法。

**Result:** MATTER在生成任务中平均性能提升4%，在分类任务中平均性能提升2%，优于现有分词方法。

**Conclusion:** 实验结果强调了领域知识对于科学文本处理中分词策略的重要性。

> **ai_Abstract:** 本文提出了一种名为MATTER的新型分词方法，旨在解决现有语言模型在材料科学领域中因频率中心分词导致的过度碎片化和语义丢失问题。MATTER通过整合材料领域知识，并利用MatDetector和概念重排序策略，有效保持了材料概念的结构和语义完整性。实验证明，MATTER在生成和分类任务中均优于现有方法，凸显了领域知识在科学文本分词中的关键作用。

> **摘要翻译:** 标题：将领域知识融入材料分词
摘要：尽管语言模型在材料科学中得到越来越多的应用，但典型的模型依赖于最初为自然语言处理开发的以频率为中心的分词方法。然而，这些方法经常产生过度碎片化和语义丢失，未能保持材料概念的结构和语义完整性。为了解决这个问题，我们提出了MATTER，一种将材料知识整合到分词中的新型方法。MATTER基于在我们的材料知识库上训练的MatDetector和一个在token合并时优先考虑材料概念的重排序方法，它保持了已识别材料概念的结构完整性，并防止了分词过程中的碎片化，确保了其语义意义的完整性。实验结果表明，MATTER优于现有的分词方法，在生成和分类任务中分别实现了4%和2%的平均性能提升。这些结果强调了领域知识对于科学文本处理中分词策略的重要性。我们的代码可在https://github.com/yerimoh/MATTER获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [415] [Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models](https://arxiv.org/abs/2506.11116)
> *Infinity Instruct：扩展指令选择与合成以增强语言模型*

*Jijie Li, Li Du, Hanyu Zhao, Bo-wen Zhang, Liangdong Wang, Boyan Gao, Guang Liu, Yonghua Lin* | **Main category: cs.CL**

**Keywords:** 大语言模型, 指令微调, 数据集, Infinity-Instruct, 开源模型

**Comment:** 

> **TL;DR:** 引入Infinity-Instruct数据集，通过两阶段方法（基础指令选择和聊天指令合成）提升开源大语言模型的性能，使其在指令遵循和基础能力上超越现有模型，甚至在某些任务上优于GPT-4。

**AI_Comments:** 该论文通过构建大规模高质量的指令数据集Infinity-Instruct，有效解决了现有开源数据集领域狭窄、泛化能力不足的问题。其两阶段的数据选择与合成方法新颖且有效，尤其是在指令遵循任务上超越GPT-4-0314的成果，展示了其在提升开源模型竞争力方面的巨大潜力。这对于推动开源LLM生态发展具有重要意义，并为LLM的全面发展提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有开源指令数据集集中于狭窄领域，限制了大语言模型的泛化能力，并拉大了与专有模型的差距。

**Method:** 引入Infinity-Instruct数据集，采用两阶段流程：第一阶段，从超过1亿样本中，使用混合数据选择技术筛选出7.4M高质量基础指令（InfInstruct-F-7.4M）；第二阶段，通过指令选择、演化和诊断过滤的两阶段过程，合成1.5M高质量聊天指令（InfInstruct-G-1.5M）。随后使用该数据集微调Mistral、LLaMA、Qwen和Yi等开源模型。

**Result:** 微调后的模型在基础能力和指令遵循基准测试中表现出显著性能提升，持续超越官方指令微调的对应模型。InfInstruct-LLaMA3.1-70B在指令遵循任务上比GPT-4-0314高出8.6%，同时基础性能相当。

**Conclusion:** 基础训练和聊天训练之间存在协同作用，为全面的大语言模型开发提供了新见解。

> **ai_Abstract:** 本文介绍了Infinity-Instruct，一个旨在通过两阶段流水线提升开源大语言模型基础和聊天能力的高质量指令数据集。第一阶段筛选7.4M基础指令，第二阶段合成1.5M聊天指令。实验结果表明，使用该数据集微调的模型在指令遵循和基础能力上均取得显著提升，甚至在某些任务上超越GPT-4，凸显了基础与聊天训练的协同效应。

> **摘要翻译:** 大型语言模型（LLMs）在实际应用中表现出强大的性能，然而，现有的开源指令数据集往往集中在狭窄领域，例如数学或编程，这限制了泛化能力并扩大了与专有模型之间的差距。为了弥合这一差距，我们引入了Infinity-Instruct，这是一个高质量的指令数据集，旨在通过两阶段流水线增强LLMs的基础和聊天能力。在第一阶段，我们使用混合数据选择技术从超过1亿个样本中筛选出7.4M高质量的基础指令（InfInstruct-F-7.4M）。在第二阶段，我们通过涉及指令选择、演化和诊断过滤的两阶段过程合成了1.5M高质量的聊天指令（InfInstruct-G-1.5M）。我们通过微调包括Mistral、LLaMA、Qwen和Yi在内的几个开源模型，对Infinity-Instruct进行了实证评估，并观察到在基础能力和指令遵循基准测试中均有显著的性能提升，持续超越官方指令微调的对应模型。值得注意的是，InfInstruct-LLaMA3.1-70B在指令遵循任务上比GPT-4-0314高出8.6%，同时实现了可媲美的基础性能。这些结果强调了基础训练和聊天训练之间的协同作用，并为全面的LLM开发提供了新见解。我们的数据集和代码已公开发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [424] [SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models](https://arxiv.org/abs/2506.11120)
> *SDMPrune：面向高效大型语言模型的自蒸馏MLP剪枝*

*Hourun Zhu, Chengchao Shen* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 模型剪枝, 自蒸馏, MLP模块, 模型压缩

**Comment:** 

> **TL;DR:** SDMPrune通过在剪枝阶段引入自蒸馏损失并专注于MLP模块剪枝，显著提高了大型语言模型的压缩效率和性能。

**AI_Comments:** SDMPrune的创新点在于将自蒸馏损失引入到LLM的剪枝阶段，这与传统的后训练蒸馏不同，能够更有效地利用原始模型的预测信息来指导剪枝，从而解决传统梯度剪枝方法信息丢失的问题。此外，其专注于MLP模块的剪枝策略是基于对LLM结构敏感度的洞察，这使得压缩效率更高，因为MLP模块参数量大且对性能影响相对较小。该研究对于降低LLM部署成本具有重要意义，提供了一种高效的压缩方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的部署成本高昂，而现有基于梯度的剪枝方法在计算梯度时忽略了其他词的潜在预测，导致在生成能力方面信息缺失。

**Method:** 提出SDMPrune方法，在剪枝阶段（而非训练后）引入自蒸馏损失，以充分利用原始模型的预测，从而获得更准确的剪枝梯度信息。此外，专注于多层感知器（MLP）模块的剪枝，因为LLM的预测对MLP模块的敏感度较低，且MLP模块占据了大量参数。

**Result:** 在广泛的零样本基准测试中，SDMPrune方法显著优于现有剪枝方法。此外，该方法在1B规模的开源LLM中取得了非常有竞争力的性能。

**Conclusion:** SDMPrune通过自蒸馏和对MLP模块的聚焦剪枝，有效地压缩了大型语言模型，同时保持了良好的性能。

> **ai_Abstract:** 本研究提出SDMPrune，一种用于高效大型语言模型的自蒸馏MLP剪枝方法。针对现有基于梯度剪枝方法在信息利用上的不足，SDMPrune在剪枝阶段引入自蒸馏损失，以获取更准确的梯度信息。同时，鉴于MLP模块在LLM中占据大量参数且对预测敏感度较低，该方法重点对其进行剪枝。实验证明，SDMPrune在零样本基准测试中显著优于现有方法，并在1B规模LLM中表现出强竞争力，实现了LLM的有效压缩。

> **摘要翻译:** 尽管大型语言模型（LLMs）取得了强大的性能，但其部署成本却令人望而却步。对于LLMs的压缩，基于梯度的剪枝方法展现出有前景的有效性。然而，在这些方法中，使用one-hot标签计算梯度忽略了其他词的潜在预测，从而丢失了原始模型生成能力的关键信息。为了解决这个问题，我们引入了一种在剪枝阶段（而非训练后）的自蒸馏损失，以充分利用原始模型的预测，从而获得更准确的剪枝梯度信息。此外，我们发现，与注意力模块相比，LLM的预测对多层感知器（MLP）模块的敏感度较低，而MLP模块占据了超过5倍的参数（LLaMA3.2-1.2B）。为此，我们专注于MLP模块的剪枝，以在不明显降低性能的情况下显著压缩LLM。在广泛的零样本基准测试上的实验结果表明，我们的方法显著优于现有剪枝方法。此外，我们的方法在1B规模的开源LLM中取得了非常有竞争力的性能。源代码和训练权重可在https://github.com/visresearch/SDMPrune获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [429] [ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams](https://arxiv.org/abs/2506.11125)
> *ASRJam：人性化AI语音干扰以防范自动化电话诈骗*

*Freddie Grabovski, Gilad Gressel, Yisroel Mirsky* | **Main category: cs.CL**

**Keywords:** 语音钓鱼, ASR干扰, 对抗性音频, EchoGuard, 电话诈骗

**Comment:** 

> **TL;DR:** 论文提出了ASRJam和EchoGuard，一种利用自然失真来干扰语音诈骗中ASR系统的技术，同时不影响人类通话，并在用户研究中表现出最佳效果。

**AI_Comments:** ASRJam和EchoGuard的创新之处在于其“人性化”的设计，解决了以往对抗性音频技术在实际应用中体验不佳的问题。通过利用自然声学现象（如混响和回声）来干扰ASR，同时保持人类可理解性，该方法具有很高的实用价值和部署潜力，为防范基于AI的自动化语音诈骗提供了一种新颖且有效的防御手段。

<details>
  <summary>Details</summary>

**Motivation:** 自动化语音钓鱼（vishing）诈骗日益猖獗，利用LLMs、TTS和ASR技术，具有可扩展性和说服力，构成重大安全威胁。

**Method:** 论文提出了ASRJam框架，通过向受害者的音频注入对抗性扰动来干扰攻击者的ASR转录步骤，从而打破诈骗的反馈循环，同时不影响人类通话。进一步提出了EchoGuard，一种利用混响和回声等自然失真来干扰ASR但对人类可容忍的新型干扰器。

**Result:** 通过对39人进行的用户研究，将EchoGuard与三种最先进的攻击进行比较，结果显示EchoGuard实现了最高的整体效用，提供了ASR干扰和人类聆听体验的最佳组合。

**Conclusion:** EchoGuard成功地提供了一种对人类友好的方式来有效干扰自动化电话诈骗中的ASR系统，从而提高了防范这类威胁的实用性和有效性。

> **ai_Abstract:** 本文针对大型语言模型、文本到语音和自动语音识别技术在自动化语音钓鱼诈骗中的应用所带来的安全威胁，提出了一种名为ASRJam的主动防御框架。该框架通过在受害者音频中注入对抗性扰动来干扰诈骗者的ASR系统，旨在中断诈骗的反馈循环而不影响人类听者。特别地，论文还引入了EchoGuard，一种利用混响和回声等自然失真来有效干扰ASR同时对人类听感友好的新型干扰器。一项39人的用户研究表明，EchoGuard在ASR干扰效果和人类聆听体验之间取得了最佳平衡，展现出最高的综合效用。

> **摘要翻译:** 大型语言模型（LLM）结合文本到语音（TTS）和自动语音识别（ASR），正越来越多地被用于自动化语音钓鱼（vishing）诈骗。这些系统具有可扩展性和说服力，构成了重大的安全威胁。我们识别出ASR转录步骤是诈骗流程中最脆弱的环节，并引入了ASRJam，一个主动防御框架，它向受害者的音频注入对抗性扰动，以干扰攻击者的ASR。这打破了诈骗的反馈循环，同时不影响人类通话者，他们仍然可以理解对话。虽然之前的对抗性音频技术通常令人不快且不适用于实时使用，但我们还提出了EchoGuard，一种新颖的干扰器，它利用混响和回声等自然失真，这些失真对ASR具有破坏性但对人类是可容忍的。为了评估EchoGuard的有效性和可用性，我们进行了一项39人的用户研究，将其与三种最先进的攻击进行了比较。结果显示，EchoGuard实现了最高的整体效用，提供了ASR干扰和人类聆听体验的最佳组合。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [433] [GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions](https://arxiv.org/abs/2506.11127)
> *GUIRoboTron-Speech：迈向基于语音指令的自动化GUI代理*

*Wenkang Han, Zhixiong Zeng, Jing Huang, Shu Jiang, Liming Zheng, Longrong Yang, Haibo Qiu, Chang Yao, Jingyuan Chen, Lin Ma* | **Main category: cs.CL**

**Keywords:** GUI代理, 语音指令, 端到端, 文本转语音, 模态不平衡

**Comment:** 

> **TL;DR:** GUIRoboTron-Speech是首个端到端接受语音指令和屏幕截图来预测动作的GUI代理，通过文本转语音生成数据并采用混合指令训练策略，在基准数据集上表现出色。

**AI_Comments:** 该论文的创新点在于提出了首个端到端直接接受语音指令的GUI代理，解决了传统文本指令的局限性。其通过文本转语音生成训练数据和引入混合指令训练策略来应对数据稀缺和模态不平衡问题，显示了强大的实用性和对未来免提人机交互的贡献潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的GUI自主代理依赖于基于文本的指令，这限制了其可访问性和便利性，特别是在免提场景下。

**Method:** 提出GUIRoboTron-Speech，首个直接接受语音指令和设备截图来预测动作的端到端自主GUI代理。针对语音GUI代理数据集稀缺问题，利用随机音色文本转语音（TTS）模型将现有文本指令转换为高质量语音指令进行训练。通过渐进式接地和规划训练阶段开发其能力。关键贡献是启发式混合指令训练策略，旨在缓解预训练基础模型中固有的模态不平衡问题。

**Result:** 在多个基准数据集上的综合实验验证了GUIRoboTron-Speech的鲁棒性和卓越性能。

**Conclusion:** 语音作为驱动GUI代理的有效指令模态，具有显著的潜力与广泛的适用性。

> **ai_Abstract:** GUIRoboTron-Speech是一个创新的端到端GUI自主代理，旨在通过直接处理语音指令和设备截图来克服传统文本指令的局限性。为应对语音数据集的不足，研究人员利用文本转语音技术生成训练数据，并引入了一种启发式混合指令训练策略以解决模态不平衡问题。实验结果表明，该系统在多个基准测试中表现出卓越的性能，证明了语音作为GUI代理指令模态的巨大潜力。

> **摘要翻译:** 图形用户界面（GUI）的自主代理正在彻底改变人机交互，然而，它们对基于文本指令的依赖限制了可访问性和便利性，特别是在免提场景中。为解决这一差距，我们提出了GUIRoboTron-Speech，这是第一个端到端自主GUI代理，它直接接受语音指令和设备屏幕截图来预测动作。面对基于语音的GUI代理数据集的稀缺性，我们首先利用随机音色文本转语音（TTS）模型转换现有文本指令，生成高质量的语音指令用于训练。然后，我们通过渐进式接地和规划训练阶段开发GUIRoboTron-Speech的能力。一个关键贡献是启发式混合指令训练策略，旨在缓解预训练基础模型中固有的模态不平衡。在几个基准数据集上的全面实验验证了GUIRoboTron-Speech的鲁棒性和卓越性能，展示了语音作为驱动GUI代理的有效指令模态的显著潜力和广泛适用性。我们的代码和数据集可在https://github.com/GUIRoboTron/GUIRoboTron-Speech获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [437] [Stronger Language Models Produce More Human-Like Errors](https://arxiv.org/abs/2506.11128)
> *更强的语言模型产生更像人类的错误*

*Andrew Keenan Richardson, Ryan Othniel Kearns, Sean Moss, Vincent Wang-Mascianica, Philipp Koralus* | **Main category: cs.CL**

**Keywords:** 语言模型, 类人错误, 推理谬误, 逆向扩展, 疑问理论

**Comment:** 

> **TL;DR:** 语言模型越强大，其错误越趋向于模仿人类可预测的推理谬误，这与普遍认为的扩展模型能获得规范理性的观点相悖。

**AI_Comments:** 这项研究提出了一个反直觉且重要的发现：随着语言模型能力的增强，它们的错误反而变得更像人类。这挑战了模型扩展能带来完美理性的普遍假设，并突显了其可能固有的向人类认知模式（包括偏见）的趋同。ETR的运用为这项分析提供了坚实的框架。这项研究对于理解AI智能的真实本质及其潜在局限性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 探究语言模型在改进过程中是否会趋向于人类的推理模式，特别是其错误的性质。

**Method:** 研究应用了推理的疑问理论（ETR）及其开源包PyETR，生成人类可预测出错的逻辑推理问题。评估了38个语言模型在383个推理任务中的响应，并使用Chatbot Arena分数衡量模型复杂性。

**Result:** 随着模型能力的提升，其错误答案中与ETR预测的人类谬误一致的比例趋于增加（$ho = 0.360, p = 0.0265$）。这种错误模式向人类相似性的转变与整体错误率无关，因为模型复杂性与逻辑正确性之间没有相关性。研究还证实了语言模型推理中的顺序效应。

**Conclusion:** 这些发现挑战了扩展语言模型自然获得规范理性的普遍观点，反而表明模型正趋向于包含人类特有偏见和局限性的人类认知。

> **ai_Abstract:** 本研究揭示了一种逆向扩展现象：尽管整体推理能力有所提高，但更强的语言模型所犯的错误越来越模仿人类推理谬误。通过在38个模型和383个任务上应用推理的疑问理论（ETR），研究发现，先进模型表现出更高比例的类人错误，且这与它们的总体错误率无关。这表明，扩展模型可能趋向于类人认知，包括其偏见，而非纯粹的理性。

> **摘要翻译:** 语言模型在改进过程中是否会趋向于人类的推理模式？我们提供了令人惊讶的证据，表明虽然整体推理能力随着模型复杂性的提高而增强，但错误的性质却越来越反映出可预测的人类推理谬误：这是一种以前未观察到的逆向扩展现象。为了研究这个问题，我们应用了推理的疑问理论（ETR），这是一个具有经验支持的正式认知框架，用于预测人类推理结果。使用开源软件包 PyETR，我们生成了人类可预测出错的逻辑推理问题，评估了来自 38 个语言模型在 383 个推理任务中的响应。我们的分析表明，随着模型在一般能力上的提升（通过 Chatbot Arena 分数衡量），它们错误答案中与 ETR 预测的人类谬误一致的比例趋于增加（$\rho = 0.360, p = 0.0265$）。值得注意的是，由于我们没有观察到模型复杂性与这些任务的逻辑正确性之间存在相关性，因此这种错误模式向人类相似性的转变与错误率无关。这些发现挑战了普遍存在的观点，即扩展语言模型自然会获得规范理性，相反，它表明了向人类认知（包括我们特有的偏见和局限性）的趋同，我们通过展示语言模型推理中的顺序效应进一步证实了这一点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [441] [Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK](https://arxiv.org/abs/2506.11129)
> *医学领域的可信人工智能：使用CHECK进行持续幻觉检测与消除*

*Carlos Garcia-Fernandez, Luis Felipe, Monique Shotande, Muntasir Zitu, Aakash Tripathi, Ghulam Rasool, Issam El Naqa, Vivek Rudrapatna, Gilmer Valdes* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 幻觉检测, 医疗AI, 持续学习, 可信AI

**Comment:** 

> **TL;DR:** CHECK是一个持续学习框架，通过整合临床数据库和信息论分类器来检测并消除大型语言模型在医疗领域中的幻觉，显著降低了幻觉率并提高了模型性能。

**AI_Comments:** 该论文提出了一种创新的方法来解决LLM在医疗领域应用中的核心挑战——幻觉问题。CHECK框架的持续学习能力和基于信息论的分类器是其亮点。通过将幻觉率降低到临床可接受的水平，该工作为LLM在关键医疗场景中的实际部署奠定了基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在医疗保健领域前景广阔，但幻觉问题仍然是其临床应用的主要障碍。

**Method:** 本研究提出了CHECK框架，这是一个持续学习框架，它将结构化临床数据库与基于信息论的分类器相结合，用于检测事实性和推理性幻觉。该框架还利用幻觉概率来指导GPT-4o的改进并明智地提升计算资源。

**Result:** CHECK将LLama3.3-70B-Instruct的幻觉率从31%降低到0.3%。其分类器在医学基准测试中表现出良好的泛化能力，AUC达到0.95-0.96（包括MedQA (USMLE) 基准）。通过引导GPT-4o的改进，CHECK将其USMLE通过率提高了5个百分点，达到92.1%。

**Conclusion:** CHECK通过将幻觉抑制到可接受的临床错误阈值以下，为大型语言模型在医学及其他高风险领域安全部署提供了可扩展的基础。

> **ai_Abstract:** 本研究提出了CHECK，一个用于医学领域可信人工智能的持续学习框架。CHECK通过整合结构化临床数据库和基于信息论的分类器，有效检测并消除大型语言模型（LLMs）中的事实性和推理性幻觉。实验结果表明，CHECK显著降低了LLMs的幻觉率（如将LLama3.3-70B-Instruct的幻觉率从31%降至0.3%），并提升了模型在医学基准测试中的表现，例如将GPT-4o的USMLE通过率提高至92.1%。该框架为LLMs在医疗等高风险领域的安全部署提供了可扩展的解决方案。

> **摘要翻译:** 大型语言模型（LLMs）在医疗保健领域展现出广阔前景，但幻觉仍然是其临床应用的主要障碍。我们提出了CHECK，一个持续学习框架，它将结构化临床数据库与基于信息论的分类器相结合，以检测事实性和推理性幻觉。在来自100项关键临床试验的1500个问题上进行评估，CHECK将LLama3.3-70B-Instruct的幻觉率从31%降低到0.3%——使一个开源模型达到了最先进水平。其分类器在医学基准测试中具有泛化能力，AUC达到0.95-0.96，包括在MedQA（USMLE）基准和HealthBench逼真多轮医学问答中。通过利用幻觉概率来指导GPT-4o的改进并明智地提升计算资源，CHECK将其USMLE通过率提高了5个百分点，达到了92.1%的最先进水平。通过将幻觉抑制到可接受的临床错误阈值以下，CHECK为大型语言模型在医学及其他高风险领域安全部署提供了可扩展的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [447] [Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models](https://arxiv.org/abs/2506.11137)
> *使用大型语言模型从电子健康记录中可扩展地提取药物信息并识别停药*

*Chong Shao, Douglas Snyder, Chiran Li, Bowen Gu, Kerry Ngan, Chun-Ting Yang, Jiageng Wu, Richard Wyss, Kueiyu Joshua Lin, Jie Yang* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 药物提取, 停药识别, 电子健康记录, 可扩展性

**Comment:** preprint, under review

> **TL;DR:** 本研究评估了大型语言模型（LLMs）从电子健康记录中提取药物并识别停药的能力，发现LLMs表现出良好性能，其中GPT-4o表现最佳，开源模型也具有可扩展的潜力。

**AI_Comments:** 该论文的创新点在于系统评估了多种先进的开源和专有大型语言模型在医疗领域特定任务（药物提取和停药识别）中的性能，并关注了其在无人工标注下的可扩展性。其重要性体现在为临床医生和研究人员提供了一种高效、自动化的工具，以处理电子健康记录中非结构化的药物信息，从而提高患者安全。论文结果显示通用领域LLMs优于医学专用LLMs，这一发现值得进一步探究。同时，其对少样本学习和CoT推理效果的分析也为未来LLM在医疗领域的应用提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 在电子健康记录（EHRs）中识别药物停用对患者安全至关重要，但由于信息隐藏在非结构化笔记中，这一过程常受阻碍。本研究旨在评估先进的开源和专有大型语言模型（LLMs）在从EHR笔记中提取药物并分类其药物状态方面的能力，重点关注其在无人工标注情况下的药物信息提取的可扩展性。

**Method:** 研究收集了来自不同来源的三个EHR数据集以构建评估基准。评估了12个先进的LLMs，并探索了多种LLM提示策略。系统比较了药物提取、药物状态分类及其联合任务（先提取后分类）在所有实验中的性能。

**Result:** LLMs在从EHR笔记中提取药物和停药分类方面表现出良好的性能。GPT-4o在零样本设置下所有任务中始终获得最高的平均F1分数：药物提取为94.0%，停药分类为78.1%，联合任务为72.7%。开源模型紧随其后，Llama-3.1-70B-Instruct在MIV-Med数据集上的药物状态分类中表现最佳（68.7%），并在Re-CASI（76.2%）和MIV-Med（60.2%）数据集的联合任务中表现最佳。医学专用LLMs的性能低于先进的通用领域LLMs。少样本学习通常能提高性能，而CoT推理的增益不一致。

**Conclusion:** 大型语言模型在从电子健康记录中提取药物和识别停药方面显示出巨大潜力，其中开源模型为专有系统提供了可扩展的替代方案，少样本学习可以进一步提高LLMs的能力。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在从非结构化电子健康记录（EHR）笔记中提取药物信息并识别药物停用方面的能力，旨在解决传统方法中人工标注的限制。研究构建了包含三个EHR数据集的评估基准，并测试了12种先进的LLMs及多种提示策略。结果显示，LLMs在该任务上表现出良好性能，尤其GPT-4o在零样本设置下表现最佳，F1分数在药物提取、停药分类和联合任务中分别为94.0%、78.1%和72.7%。开源模型也表现出竞争力，且具有可扩展性。研究还发现少样本学习通常能提高性能，而医学专用LLMs的性能低于通用领域LLMs。这表明LLMs，尤其是开源模型，在药物信息提取和停药识别方面具有巨大的应用潜力。

> **摘要翻译:** 在电子健康记录（EHRs）中识别药物停用对患者安全至关重要，但由于信息隐藏在非结构化笔记中，这一过程常受阻碍。本研究旨在评估先进的开源和专有大型语言模型（LLMs）在从EHR笔记中提取药物并分类其药物状态方面的能力，重点关注其在无人工标注情况下的药物信息提取的可扩展性。我们收集了来自不同来源的三个EHR数据集以构建评估基准。我们评估了12个先进的LLMs，并探索了多种LLM提示策略。药物提取、药物状态分类及其联合任务（先提取后分类）的性能在所有实验中进行了系统比较。我们发现LLMs在从EHR笔记中提取药物和停药分类方面表现出良好的性能。GPT-4o在零样本设置下所有任务中始终获得最高的平均F1分数——药物提取为94.0%，停药分类为78.1%，联合任务为72.7%。开源模型紧随其后，Llama-3.1-70B-Instruct在MIV-Med数据集上的药物状态分类中表现最佳（68.7%），并在Re-CASI（76.2%）和MIV-Med（60.2%）数据集的联合任务中表现最佳。医学专用LLMs的性能低于先进的通用领域LLMs。少样本学习通常能提高性能，而CoT推理的增益不一致。LLMs在从EHR笔记中提取药物和识别停药方面显示出巨大潜力，其中开源模型为专有系统提供了可扩展的替代方案，少样本学习可以进一步提高LLMs的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [450] [RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?](https://arxiv.org/abs/2506.11243)
> *RETUYT-INCO 参加 BEA 2025 共享任务：轻量级模型在 AI 驱动的导师评估中能走多远？*

*Santiago Góngora, Ignacio Sastre, Santiago Robaina, Ignacio Remersaro, Luis Chiruzzo, Aiala Rosá* | **Main category: cs.CL**

**Keywords:** 轻量级模型, AI导师评估, 计算资源受限, BEA 2025, 共享任务

**Comment:** This paper will be presented at the 20th BEA Workshop (Innovative Use
  of NLP for Building Educational Applications) at ACL 2025

> **TL;DR:** RETUYT-INCO 团队在 BEA 2025 共享任务中证明，即使使用参数少于 10 亿的轻量级模型，在 AI 驱动的导师评估任务中也能保持竞争力，尤其适用于计算资源受限的环境。

**AI_Comments:** 这项研究的创新之处在于其明确关注轻量级模型在资源受限环境下的可行性，这对于促进全球南方地区的 AI 研究和应用具有重要意义。它挑战了“越大越好”的模型范式，并证明了在特定任务中，通过优化和限制模型大小，仍能实现有竞争力的性能。这对于普及 AI 技术和降低研究门槛具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在模拟全球南方地区计算能力受限的实验室或机构所面临的条件，探索轻量级模型在 AI 驱动的导师评估任务中的潜力。

**Method:** RETUYT-INCO 团队参加了 BEA 2025 共享任务，并有意识地选择使用参数少于 10 亿的相对小型模型进行 AI 驱动的导师评估。

**Result:** 尽管使用了轻量级模型，RETUYT-INCO 团队的模型在 BEA 2025 共享任务中与获胜团队的 $exact\ F_1$ 分数差距在 Track 1 为 6.46，Track 2 为 10.24，Track 3 为 7.85，Track 4 为 9.56，Track 5 为 13.13。

**Conclusion:** 研究表明，参数小于 10 亿的模型在 AI 驱动的导师评估任务中具有竞争力，并且可以在配备低预算 GPU 甚至没有 GPU 的计算机上运行。

> **ai_Abstract:** 本文介绍了 RETUYT-INCO 团队在 BEA 2025 共享任务中的参与情况，其核心策略是使用参数少于 10 亿的轻量级模型，旨在模拟计算资源受限的环境。研究结果显示，尽管模型规模较小，但其性能与获胜团队的 $exact\ F_1$ 分数差距在 6.46 至 13.13 之间，证明了轻量级模型在 AI 驱动的导师评估任务中的竞争力，并且可以在计算资源有限的设备上有效运行。

> **摘要翻译:** 本文介绍了 RETUYT-INCO 团队参加 BEA 2025 共享任务的情况。我们的参与特点是决定使用相对较小的模型，参数少于 10 亿。这种自我设定的限制旨在代表全球南方许多研究实验室或机构所处的条件，在那里，由于计算成本过高，计算能力不易获得。即使在这种限制性的自我设定下，我们的模型仍设法与参与共享任务的其他团队保持竞争力。根据组织者公布的 $exact\ F_1$ 分数，我们的模型与获胜者之间的性能差距如下：Track 1 为 6.46；Track 2 为 10.24；Track 3 为 7.85；Track 4 为 9.56；Track 5 为 13.13。考虑到与获胜团队的最小差异为 6.46 分——最大差异为 13.13 分——根据 $exact\ F_1$ 分数，我们发现大小小于 10 亿参数的模型对于这些任务具有竞争力，所有这些任务都可以在配备低预算 GPU 甚至没有 GPU 的计算机上运行。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [453] [Iterative Multilingual Spectral Attribute Erasure](https://arxiv.org/abs/2506.11244)
> *迭代多语言谱属性擦除*

*Shun Shao, Yftah Ziser, Zheng Zhao, Yifu Qiu, Shay B. Cohen, Anna Korhonen* | **Main category: cs.CL**

**Keywords:** 多语言, 去偏, 偏见, 谱擦除, SVD

**Comment:** 8 pages, 3 figures

> **TL;DR:** 现有去偏方法多为单语。本文提出IMSAE，一种迭代的基于SVD的方法，用于减轻多语言间的联合偏见。它在八种语言和多种模型上表现出有效性，优于现有方法并保持模型效用。

**AI_Comments:** IMSAE具有创新性，因为它解决了现有去偏方法的一个关键局限性，即通过多语言操作来利用共享语义空间以传递去偏效应。其迭代的基于SVD的方法是识别和减轻跨语言联合偏见的新颖方式。在零样本设置中证明的有效性尤为重要，因为它允许在目标语言数据稀缺时进行去偏。

<details>
  <summary>Details</summary>

**Motivation:** 现有的去偏方法作用于单个语言，无法利用多语言表征中词义相似的词共享共同语义空间的机会，从而在语言之间传递去偏效应。

**Method:** 本文提出了迭代多语言谱属性擦除（IMSAE），通过迭代的基于SVD的截断来识别和减轻多语言中的联合偏见子空间。该方法在八种语言和五个人口统计维度上进行了评估。

**Result:** IMSAE在标准设置和零样本设置中都显示出有效性。对BERT、LLaMA、Mistral等不同语言模型的全面实验表明，IMSAE优于传统的单语和跨语方法，同时保持了模型效用。

**Conclusion:** IMSAE通过多语言操作成功解决了现有去偏方法的局限性，有效地减轻了跨语言的联合偏见，并在不牺牲模型效用的情况下实现了卓越的性能。

> **ai_Abstract:** 本文介绍了迭代多语言谱属性擦除（IMSAE），这是一种旨在减轻多语言表征中联合偏见的新方法。与现有仅作用于单一语言的去偏技术不同，IMSAE利用迭代的基于SVD的截断来识别并减少跨多种语言的共享偏见子空间。IMSAE在八种语言和不同人口统计维度上进行了评估，在标准和零样本场景中均表现出卓越性能，优于传统的单语和跨语方法，同时在BERT、LLaMA和Mistral等多种语言模型中保持了模型效用。

> **摘要翻译:** 标题：迭代多语言谱属性擦除
摘要：多语言表征将意义相似的词嵌入到跨语言的共同语义空间中，从而为在语言之间传递去偏效应创造了机会。然而，现有的去偏方法无法利用这一机会，因为它们作用于单个语言。我们提出了迭代多语言谱属性擦除（IMSAE），它通过迭代的基于SVD的截断来识别和减轻多语言中的联合偏见子空间。通过在八种语言和五个人口统计维度上评估IMSAE，我们证明了其在标准设置和零样本设置中的有效性，其中目标语言数据不可用，但可以使用语言相似的语言进行去偏。我们对不同语言模型（BERT、LLaMA、Mistral）的全面实验表明，IMSAE优于传统的单语和跨语方法，同时保持了模型效用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [455] [No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning](https://arxiv.org/abs/2506.11246)
> *没有通用提示：通过自适应提示统一时间表推理*

*Kushagra Dixit, Abhishek Rajgaria, Harshavardhan Kalalbandi, Dan Roth, Vivek Gupta* | **Main category: cs.CL**

**Keywords:** 时间表推理, 大型语言模型, 自适应提示, SEAR, 表格结构

**Comment:** 21 pages, 19 Tables, 9 Figures

> **TL;DR:** 大型语言模型（LLMs）在时间表推理中面临挑战，现有提示方法表现不一。本文引入了SEAR，一个受人类推理启发的自适应提示框架，它能根据上下文动态调整，并在所有表格类型上取得了优异性能。研究还发现统一的表格表示能增强模型推理。

**AI_Comments:** 该论文解决了大型语言模型在时间表推理中的一个重要难题，并提出了一个创新的自适应提示框架SEAR，其灵感来源于人类的推理过程。发现“没有通用提示”这一结论至关重要，它推动了该领域向更动态、更具上下文感知能力的提示策略发展。此外，对表格结构重构以实现统一表示的探索也增加了实用价值，为数据预处理提供了潜在的改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 时间表推理是大型语言模型（LLMs）面临的一个关键挑战，需要有效的提示技术来提取相关见解。尽管存在多种提示方法，但它们对表格推理的影响在很大程度上仍未被探索。此外，这些模型的性能在不同的表格和上下文结构中差异巨大，使得难以确定最佳方法。

**Method:** 本文研究了多种提示技术在不同表格类型上的表现，以确定不同场景下的最佳方法。为此，引入了SEAR，一个受人类推理启发的自适应提示框架，它根据上下文特征动态调整并整合结构化推理。此外，还探索了表格结构重构的影响。

**Result:** 研究发现，性能根据实体类型、表格结构、是否需要额外上下文以及问题复杂性而变化，没有单一方法能持续优于其他方法。与基线提示技术相比，SEAR在所有表格类型上都取得了卓越的性能。此外，研究发现统一的表示形式能增强模型的推理能力。

**Conclusion:** 没有单一的通用提示方法能适用于所有时间表推理场景。通过引入自适应提示框架SEAR，可以显著提高大型语言模型在不同表格类型上的推理性能。统一的表格表示也有助于增强模型的推理能力。

> **ai_Abstract:** 大型语言模型在时间表推理中面临挑战，因为缺乏通用的有效提示策略。本文调查了多种提示技术，发现没有单一方法能普遍适用。为此，论文引入了SEAR，一个受人类推理启发的自适应提示框架，能够根据上下文动态调整提示。实验结果表明，SEAR在所有表格类型上均优于现有基线方法。此外，研究还发现统一的表格结构表示能有效提升模型的推理能力。

> **摘要翻译:** 时间表推理是大型语言模型（LLMs）面临的一个关键挑战，需要有效的提示技术来提取相关见解。尽管存在多种提示方法，但它们对表格推理的影响在很大程度上仍未被探索。此外，这些模型的性能在不同的表格和上下文结构中差异巨大，使得难以确定最佳方法。这项工作研究了多种提示技术在不同表格类型上的表现，以确定不同场景下的最佳方法。我们发现性能根据实体类型、表格结构、是否需要额外上下文以及问题复杂性而变化，没有单一方法能持续优于其他方法。为了缓解这些挑战，我们引入了SEAR，一个受人类推理启发的自适应提示框架，它根据上下文特征动态调整并整合结构化推理。我们的结果表明，与所有其他基线提示技术相比，SEAR在所有表格类型上都取得了卓越的性能。此外，我们探索了表格结构重构的影响，发现统一的表示形式能增强模型的推理能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [459] [Learning a Continue-Thinking Token for Enhanced Test-Time Scaling](https://arxiv.org/abs/2506.11274)
> *学习一个“继续思考”令牌以增强测试时扩展*

*Liran Ringel, Elad Tolochinsky, Yaniv Romano* | **Main category: cs.CL**

**Keywords:** 测试时扩展, 语言模型, 强化学习, 令牌学习, 推理

**Comment:** 

> **TL;DR:** 通过学习一个专门的“继续思考”令牌，可以显著提高语言模型在推理时的准确性，该方法优于使用固定令牌。

**AI_Comments:** 本文提出了一种新颖且高效的测试时扩展方法，通过强化学习训练一个专用的“继续思考”令牌，而非依赖预设的固定令牌。这种仅训练令牌嵌入而冻结模型权重的方法具有很高的效率。实验结果表明，该方法在提升语言模型推理能力方面取得了显著的性能优势，特别是在与固定令牌方法的对比中，其表现出更强的改进潜力，这对于提高大型语言模型的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的测试时扩展方法通过使用固定令牌来延长推理步骤，但本文旨在探索是否可以通过学习一个专用的“继续思考”令牌来更有效地触发扩展推理并提高模型性能。

**Method:** 作者在一个蒸馏版的DeepSeek-R1模型中增加了一个可学习的“<|continue-thinking|>”令牌。他们仅通过强化学习训练该令牌的嵌入，而模型的其余权重保持冻结。

**Result:** 实验表明，与基线模型以及使用固定令牌进行预算强制的测试时扩展方法相比，所学习的令牌在标准数学基准测试上取得了更高的准确性。特别是在固定令牌方法能提升基线模型准确性的情况下，本文方法实现了更显著的提升。例如，在GSM8K基准测试上，固定令牌方法带来了1.3%的绝对准确率提升，而本文学习令牌方法比未使用预算强制的基线模型提升了4.2%。

**Conclusion:** 通过强化学习学习一个专用的“继续思考”令牌，是增强语言模型在测试时扩展性能的一种高效策略，它显著优于传统的固定令牌方法。

> **ai_Abstract:** 本文提出了一种新的测试时扩展方法，通过学习一个专用的“继续思考”令牌来增强语言模型的推理能力。研究人员将该令牌嵌入到DeepSeek-R1模型中，并仅通过强化学习训练其嵌入，同时保持模型权重不变。实验结果表明，与基线模型和使用固定令牌的传统测试时扩展方法相比，这种学习到的令牌显著提高了模型在数学基准测试上的准确性，尤其在GSM8K上表现出显著优势。

> **摘要翻译:** 测试时扩展已成为一种通过在推理时利用额外计算来提高语言模型性能的有效方法。最近的研究表明，覆盖“思考结束”令牌（例如，用“Wait”替换“</think>”）可以延长推理步骤并提高准确性。在这项工作中，我们探索是否可以学习一个专用的“继续思考”令牌来触发扩展推理。我们用一个单独学习到的“<|continue-thinking|>”令牌增强了DeepSeek-R1的一个蒸馏版本，仅通过强化学习训练其嵌入，同时保持模型权重冻结。我们的实验表明，与基线模型和使用固定令牌（例如“Wait”）进行预算强制的测试时扩展方法相比，这个学习到的令牌在标准数学基准测试上取得了更高的准确性。特别是，我们观察到在固定令牌方法能提升基线模型准确性的情况下，我们的方法实现了显著更大的改进。例如，在GSM8K基准测试上，固定令牌方法带来了1.3%的绝对准确率提升，而我们学习令牌的方法比未使用预算强制的基线模型提升了4.2%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [463] [Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning](https://arxiv.org/abs/2506.11300)
> *超越随机采样：通过课程学习实现高效语言模型预训练*

*Yang Zhang, Amr Mohamed, Hadi Abdine, Guokan Shang, Michalis Vazirgiannis* | **Main category: cs.CL**

**Keywords:** 课程学习, 语言模型预训练, 数据排序, 训练效率, 难度指标

**Comment:** 

> **TL;DR:** 本文首次系统性研究课程学习在语言模型预训练中的应用，发现其能显著提高收敛速度和性能，并识别出有效的难度指标，强调数据排序的重要性。

**AI_Comments:** 本文创新性地将课程学习应用于语言模型预训练，填补了该领域系统性研究的空白。其重要性在于证明了数据排序对大规模预训练的显著影响，并提供了具体的有效难度指标，为未来高效、可扩展的语言模型开发提供了宝贵的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 课程学习在其他机器学习领域已显示出提高训练效率和泛化能力的潜力，但在语言模型预训练中的潜力尚未得到充分探索，因此本文进行了首次系统性研究。

**Method:** 实验了包括普通课程学习、基于步调的采样和交错式课程等不同设置，并使用了六种涵盖语言学和信息论视角的难度指标进行指导。在这些设置下训练模型，并在八个不同基准上评估性能。

**Result:** 课程学习在早期和中期训练阶段持续改善收敛，作为热身策略时可带来高达3.5%的持续增益。压缩比、词汇多样性和可读性被确定为跨设置的有效难度信号。

**Conclusion:** 研究结果强调了大规模预训练中数据排序的重要性，并为在现实训练场景下开发可扩展、数据高效的模型提供了可操作的见解。

> **ai_Abstract:** 本文首次系统性地探讨了课程学习在语言模型预训练中的应用，旨在提高训练效率和模型性能。研究团队实验了多种课程学习策略，并利用六种难度指标指导训练过程。实验结果表明，课程学习能显著加速模型收敛，并作为热身策略时带来高达3.5%的性能提升。研究还识别出压缩比、词汇多样性和可读性是有效的难度信号。这些发现强调了大规模预训练中数据排序的关键作用，并为开发高效语言模型提供了实用指导。

> **摘要翻译:** 课程学习在各种机器学习领域中已显示出提高训练效率和泛化能力的潜力，然而其在预训练语言模型中的潜力仍未得到充分探索，这促使我们进行了首次系统性研究。我们实验了不同的设置，包括普通课程学习、基于步调的采样以及由六种涵盖语言学和信息论视角的难度指标指导的交错式课程。我们在这些设置下训练模型，并在八个不同的基准上评估它们的性能。我们的实验表明，课程学习在训练的早期和中期阶段持续改善收敛，并且当用作热身策略时，可以产生高达3.5%的持久增益。值得注意的是，我们发现压缩比、词汇多样性和可读性是跨设置的有效难度信号。我们的研究结果强调了数据排序在大规模预训练中的重要性，并为在现实训练场景下开发可扩展、数据高效的模型提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [467] [Don't Pay Attention](https://arxiv.org/abs/2506.11305)
> *不要使用注意力机制*

*Mohammad Hammoud, Devang Acharya* | **Main category: cs.CL**

**Keywords:** Avey, Transformer, 长距离依赖, 神经网络架构, 注意力机制

**Comment:** 

> **TL;DR:** 本文提出了一种名为 Avey 的新型神经网络架构，它完全摆脱了注意力机制和循环结构，旨在解决 Transformer 在处理长序列时面临的挑战，并在长距离依赖任务上表现出色。

**AI_Comments:** 该论文的创新点在于提出了一种完全脱离了当前主流模型（如 Transformer）核心组件（注意力机制和循环结构）的新型架构。Avey 能够有效处理任意长序列，并擅长捕获长距离依赖，这对于未来的大型语言模型发展具有重要意义，可能为高效处理超长文本开辟新路径。

<details>
  <summary>Details</summary>

**Motivation:** Transformer 架构在处理超出固定上下文窗口的序列和其注意力机制的二次复杂度方面面临挑战，而 RNN 架构虽然能线性扩展但并行性有限。因此，需要一种新的基础架构来有效处理任意长序列。

**Method:** 本文提出了 Avey 架构，它是一种不依赖注意力机制和循环的新型神经基础架构。Avey 由一个排序器和一个自回归神经处理器组成，它们协同工作以识别和语境化最相关的令牌，无论其在序列中的位置如何。Avey 通过将序列长度与上下文宽度解耦，从而能够处理任意长的序列。

**Result:** 实验结果表明，Avey 在各种标准短程自然语言处理（NLP）基准测试中与 Transformer 相比表现良好，并且在捕获长距离依赖方面表现尤为突出。

**Conclusion:** Avey 是一种有效的新型神经网络架构，它通过避免注意力机制和循环结构，成功克服了 Transformer 在处理长序列时的局限性，尤其擅长处理长距离依赖。

> **ai_Abstract:** 本文提出了一种名为 Avey 的新型神经基础架构，旨在解决 Transformer 在处理长序列时面临的上下文窗口限制和注意力机制的二次复杂度问题。Avey 创新性地避免了注意力机制和循环结构，通过一个排序器和一个自回归神经处理器协同工作，实现对任意长序列的有效处理，并能识别和语境化最相关的令牌。实验证明，Avey 在短程 NLP 任务上与 Transformer 表现相当，尤其在捕获长距离依赖方面表现出色。

> **摘要翻译:** Transformer 已成为大型语言模型以及各种领域内广泛下游任务的事实标准。尽管它具有固有的训练并行性等众多优点，但 Transformer 仍面临关键挑战，因为它无法有效处理超出固定上下文窗口的序列，并且其注意力机制具有二次复杂性。这些挑战重新激发了人们对类 RNN 架构的兴趣，这些架构提供了与序列长度呈线性扩展的能力，并改进了对长距离依赖关系的处理，尽管由于其固有的循环性质而并行性有限。在本文中，我们提出了 Avey，一种新的神经基础架构，它摆脱了注意力机制和循环。Avey 包含一个排序器和一个自回归神经处理器，它们协同工作，无论序列中令牌的位置如何，都能识别并语境化任何给定令牌最相关的令牌。具体而言，Avey 将序列长度与上下文宽度解耦，从而能够有效处理任意长的序列。实验结果表明，Avey 在各种标准短程 NLP 基准测试中与 Transformer 相比表现出色，并且在捕获长距离依赖方面表现尤为突出。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [469] [Surprisal from Larger Transformer-based Language Models Predicts fMRI Data More Poorly](https://arxiv.org/abs/2506.11338)
> *大型Transformer语言模型的Surprisal对fMRI数据的预测能力更差*

*Yi-Chien Lin, William Schuler* | **Main category: cs.CL**

**Keywords:** Transformer模型, 惊奇度, fMRI, 困惑度, 语言处理

**Comment:** 

> **TL;DR:** 大型Transformer语言模型的惊奇度对fMRI数据的预测能力较差，与阅读时间的研究结果一致。

**AI_Comments:** 这项研究的重要性在于它将之前在行为数据（阅读时间）中观察到的现象推广到了神经数据（fMRI），提供了更强的证据。它挑战了“越大越好”的直觉，提示我们更大的语言模型可能并不总是更好地模拟人类认知过程。未来的研究可以深入探讨为什么会出现这种负相关，以及如何构建更能反映人类脑活动的计算模型。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究发现，基于Transformer的语言模型，其参数越多、训练数据越多，对人类阅读时间的预测能力越差，但这些研究主要集中于预测基于潜伏期的测量（如阅读时间和眼动持续时间）。本研究旨在验证这一趋势是否也适用于脑成像数据。

**Method:** 本研究评估了来自17个预训练的Transformer语言模型（涵盖三个不同语言家族）的惊奇度估计值，在两个功能性磁共振成像（fMRI）数据集上的预测能力。

**Result:** 结果表明，模型困惑度与模型拟合度之间的正相关关系依然存在，这表明这种趋势并非仅限于基于潜伏期的测量，而是可以推广到神经测量。

**Conclusion:** 大型Transformer语言模型对人类语言处理的预测能力较差的趋势，不仅在行为潜伏期数据中存在，在脑成像数据中也同样成立。

> **ai_Abstract:** 本研究旨在探究大型Transformer语言模型中惊奇度与人类脑活动（fMRI数据）之间的关系。研究发现，与之前对阅读时间的研究结果一致，模型困惑度越高，其惊奇度对fMRI数据的预测能力越差。这表明，Transformer模型在规模增大时，其对人类语言处理的神经基础的建模能力可能反而下降，且这一现象不仅限于行为潜伏期数据，也适用于神经测量。

> **摘要翻译:** 随着Transformer模型在自然语言处理任务中得到更广泛的应用，人们对使用这些模型的惊奇度作为人类句子处理难度的预测因子产生了浓厚兴趣。最近的研究发现，基于Transformer的模型的困惑度与它们的惊奇度估计值对阅读时间的预测能力之间存在正相关关系，表明参数更多、训练数据更多的语言模型对人类阅读时间的预测能力较差。然而，这些研究主要集中于使用基于Transformer的语言模型的惊奇度估计值来预测基于潜伏期的测量（即自定进度阅读时间和眼动持续时间）。这一趋势尚未在脑成像数据上进行测试。因此，本研究评估了来自三个不同语言家族的17个预训练Transformer模型的惊奇度估计值在两个功能性磁共振成像数据集上的预测能力。结果表明，模型困惑度与模型拟合度之间的正相关关系依然存在，这表明这种趋势并非仅限于基于潜伏期的测量，而是可以推广到神经测量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [472] [From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](https://arxiv.org/abs/2506.11343)
> *从复制到重新设计：探索基于大型语言模型的同行评审中的成对比较*

*Yaohui Zhang, Haijing Zhang, Wenlong Ji, Tianyu Hua, Nick Haber, Hancheng Cao, Weixin Liang* | **Main category: cs.CL**

**Keywords:** LLM, 同行评审, 成对比较, 学术评价, 偏差

**Comment:** 

> **TL;DR:** 本文提出一种基于大型语言模型的同行评审新范式，利用LLM代理进行手稿的成对比较而非独立评分，实验表明其在识别高影响力论文方面优于传统方法，但存在新颖性降低和机构不平衡等偏差。

**AI_Comments:** 本文的创新点在于提出了基于LLM的成对比较而非传统评分的同行评审新范式，这为克服现有LLM作为人类审稿人替代的局限性提供了新思路。该方法在识别高影响力论文方面表现出色，展现了LLM在学术评审中的巨大潜力。然而，研究也坦诚地揭示了由此产生的新颖性降低和机构不平衡等关键偏差，这为未来LLM辅助评审系统的设计和部署提供了重要的警示和研究方向，强调了在追求效率的同时必须兼顾公平性和多样性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的同行评审主要复制传统工作流程，将LLM作为人类审稿人的替代，但很少探索LLM参与学术评审过程的新范式，限制了其潜力。

**Method:** 引入并探索一种新机制，利用LLM代理对手稿进行成对比较，而非单独评分。通过聚合大量成对评估的结果，实现对稿件相对质量更准确和稳健的衡量。

**Result:** 实验表明，该比较方法在识别高影响力论文方面显著优于传统的基于评分的方法。然而，分析也揭示了选择过程中出现的偏差，特别是研究主题新颖性降低和机构不平衡加剧。

**Conclusion:** 重新思考基于LLM的同行评审具有变革潜力，但未来的系统必须解决关键挑战，以确保公平性和多样性。

> **ai_Abstract:** 本文提出一种新颖的基于LLM的同行评审方法，即利用LLM代理进行手稿的成对比较，而非传统的单独评分。实验证明该方法在识别高影响力论文方面优于传统方法，但也揭示了潜在偏差，如研究主题新颖性降低和机构不平衡。研究强调了LLM在同行评审中的变革潜力与需解决的公平性、多样性挑战。

> **摘要翻译:** 大型语言模型（LLM）的出现为超越传统工作流程限制的同行评审提供了前所未有的机会。尽管有这些机会，但之前的努力主要集中于复制传统的评审工作流程，将LLM作为人类审稿人的直接替代品，而很少关注探索能够从根本上重新思考LLM如何参与学术评审过程的新范式。在本文中，我们介绍并探索了一种新颖的机制，该机制利用LLM代理对手稿进行成对比较而不是单独评分。通过聚合大量成对评估的结果，这种方法能够更准确、更稳健地衡量手稿的相对质量。我们的实验表明，这种比较方法在识别高影响力论文方面显著优于传统的基于评分的方法。然而，我们的分析也揭示了选择过程中出现的偏差，特别是研究主题的新颖性降低和机构不平衡加剧。这些发现突出了重新思考基于LLM的同行评审的变革潜力，以及未来系统为确保公平性和多样性必须解决的关键挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [476] [Do We Still Need Audio? Rethinking Speaker Diarization with a Text-Based Approach Using Multiple Prediction Models](https://arxiv.org/abs/2506.11344)
> *我们还需要音频吗？一种基于文本的多预测模型说话人日志化新方法*

*Peilin Wu, Jinho D. Choi* | **Main category: cs.CL**

**Keywords:** 说话人日志化, 文本方法, 句子级说话人变化检测, 多预测模型, 语义理解

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于文本的说话人日志化方法，通过利用对话转录本进行说话人变化检测，特别是多预测模型（MPM）在短对话中表现出色，并与最先进的基于音频的系统具有竞争力。

**AI_Comments:** 本文的创新之处在于提出了一种完全基于文本的说话人日志化方法，挑战了传统上对音频的依赖。这种方法解决了音频质量和说话人相似性带来的挑战，为在转录数据丰富的场景（如会议记录、客服对话）中应用SD开辟了新途径。多预测模型（MPM）的提出及其在短对话中的优越性能是值得关注的亮点。该研究的局限性可能在于其对高质量文本转录本的依赖，以及在没有文本或文本质量不佳的情况下可能面临的挑战。然而，它为多模态和语义驱动的SD研究指明了方向，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于音频的说话人日志化系统常受音频质量和说话人相似性的挑战。本文旨在探索一种不依赖音频、仅利用对话转录本的替代方法来解决这些问题。

**Method:** 本文提出了一种新颖的基于文本的说话人日志化（SD）方法，专注于对话中的句子级说话人变化检测。开发了两种模型：单一预测模型（SPM）和多预测模型（MPM），它们都利用对话转录本进行说话人识别。

**Result:** 基于文本的说话人日志化方法，特别是多预测模型（MPM），在识别说话人变化方面表现出显著改进，尤其是在短对话中。它与最先进的基于音频的说话人日志化系统相比具有竞争力，并在短对话场景中表现出卓越的性能。

**Conclusion:** 本文展示了利用语言特征进行说话人日志化的潜力，并强调了将语义理解整合到说话人日志化系统中的重要性，为多模态和基于语义特征的日志化研究开辟了新途径。

> **ai_Abstract:** 本文提出了一种创新的基于文本的说话人日志化（SD）方法，通过分析对话转录本来检测句子级别的说话人变化，旨在克服传统音频SD系统面临的挑战。研究开发了单一预测模型（SPM）和多预测模型（MPM），并在短对话中显示出显著的说话人变化识别能力。实验结果表明，该文本方法，尤其是MPM，在性能上与现有最先进的音频SD系统相当，在短对话场景中表现更优。该研究强调了利用语言和语义特征进行SD的潜力，并为未来的多模态和语义特征日志化研究奠定了基础。

> **摘要翻译:** 我们提出了一种新颖的说话人日志化（SD）方法，通过利用专注于对话中句子级说话人变化检测的文本方法。与常受音频质量和说话人相似性挑战的基于音频的SD系统不同，我们的方法仅使用对话转录本。开发了两种模型：单一预测模型（SPM）和多预测模型（MPM），两者都在识别说话人变化方面表现出显著改进，特别是在短对话中。我们基于包含不同对话场景的精选数据集的发现表明，基于文本的SD方法，特别是MPM，与最先进的基于音频的SD系统相比具有竞争力，并在短对话环境中表现出卓越的性能。本文不仅展示了利用语言特征进行SD的潜力，还强调了将语义理解整合到SD系统中的重要性，为未来多模态和基于语义特征的日志化研究开辟了途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [482] [A Variational Approach for Mitigating Entity Bias in Relation Extraction](https://arxiv.org/abs/2506.11381)
> *一种用于缓解关系抽取中实体偏见的变分方法*

*Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley* | **Main category: cs.CL**

**Keywords:** 实体偏见, 关系抽取, 变分信息瓶颈, 泛化, 最先进性能

**Comment:** Accepted at ACL 2025 Main

> **TL;DR:** 本文提出了一种基于变分信息瓶颈（VIB）框架的新方法，用于缓解关系抽取（RE）中的实体偏见，该方法通过压缩实体特定信息同时保留任务相关特征，在多个领域和设置中实现了最先进的性能，提高了模型的泛化能力。

**AI_Comments:** 该论文引入了一种基于理论基础的方法（VIB）来解决关系抽取中的重要问题（实体偏见），这对于提高模型泛化能力至关重要。其在不同领域和设置（域内/域外）的适用性突显了其鲁棒性和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 关系抽取（RE）中，模型常过度依赖实体，导致泛化能力差，缓解实体偏见是一个关键挑战。

**Method:** 本文提出一种新颖的方法，通过采用变分信息瓶颈（VIB）框架来压缩实体特定信息，同时保留任务相关特征。

**Result:** 该方法在通用、金融和生物医学领域的关系抽取数据集上，无论是在域内（原始测试集）还是域外（通过类型约束实体替换修改的测试集）设置中，都达到了最先进的性能。

**Conclusion:** 该方法为缓解关系抽取中的实体偏见提供了一种鲁棒、可解释且具有理论基础的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的变分信息瓶颈（VIB）框架，旨在缓解关系抽取中的实体偏见。该方法通过压缩实体特有的信息同时保留任务相关特征，在通用、金融和生物医学等多个领域的关系抽取数据集上，无论是在域内还是域外设置中，都取得了最先进的性能，提供了一种鲁棒、可解释且具有理论基础的解决方案。

> **摘要翻译:** 缓解实体偏见是关系抽取（RE）中的一个关键挑战，其中模型经常过度依赖实体，导致泛化能力差。本文提出了一种新颖的方法来解决这个问题，通过采用变分信息瓶颈（VIB）框架。我们的方法在保留任务相关特征的同时，压缩实体特有的信息。它在通用、金融和生物医学领域的关系抽取数据集上，无论是在域内（原始测试集）还是域外（通过类型约束实体替换修改的测试集）设置中，都达到了最先进的性能。我们的方法提供了一种鲁棒、可解释且具有理论基础的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [485] [Curriculum-Guided Layer Scaling for Language Model Pretraining](https://arxiv.org/abs/2506.11389)
> *课程引导的层级缩放用于语言模型预训练*

*Karanpartap Singh, Neil Band, Ehsan Adeli* | **Main category: cs.CL**

**Keywords:** 语言模型预训练, 课程学习, 层级缩放, 学习效率, 泛化能力

**Comment:** 

> **TL;DR:** CGLS是一种计算高效的预训练框架，通过逐步增加模型层数和数据难度来提高大型语言模型的学习效率和泛化能力。

**AI_Comments:** CGLS的创新之处在于将课程学习与模型结构增长（层堆叠）相结合，模拟了人类认知发展的过程，从而在预训练阶段实现了计算效率的提升和模型性能的优化。这种方法为大型语言模型的训练提供了一个简单而有效的策略，对于降低预训练成本和提高模型泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型预训练成本的增加，人们持续关注提高核心训练阶段学习效率的策略。受到人类认知发展中逐步构建知识的启发，本研究旨在提出一种更高效的预训练方法。

**Method:** 本文提出了课程引导的层级缩放（CGLS）框架，这是一种计算高效的预训练方法。它通过渐进式层堆叠（在训练期间逐步增加层）将数据难度的增加与模型增长同步。在100M参数规模上，使用从合成短故事到通用网络数据的课程；在1.2B参数规模上，使用DistilBERT分类器对DataComp-LM语料库进行分层，从通用文本进展到高度专业化内容。

**Result:** 在100M参数规模上，CGLS在问答基准PIQA和ARC上优于基线方法。在1.2B参数规模的预训练中，逐步增加模型深度和样本难度，导致在各种下游基准测试上实现更好的泛化和零样本性能。

**Conclusion:** CGLS展示了渐进式堆叠的潜力，为提高知识密集型和推理任务的泛化能力提供了一种简单而有效的策略。

> **ai_Abstract:** 本文提出了一种名为课程引导的层级缩放（CGLS）的新型预训练框架，旨在提高大型语言模型的学习效率。CGLS受人类认知发展的启发，通过在训练过程中逐步增加模型层数（渐进式层堆叠）并同步提升数据难度来实现。实验结果表明，在100M和1.2B参数规模下，CGLS在问答和各种下游任务上均超越了基线方法，显著提高了模型的泛化能力和零样本性能，尤其是在知识密集型和推理任务上。

> **摘要翻译:** 随着大型语言模型预训练成本的增加，人们持续关注在这一核心训练阶段提高学习效率的策略。受认知发展（人类随着大脑成熟逐渐积累知识）的启发，我们提出了课程引导的层级缩放（CGLS），这是一个计算高效的预训练框架，它通过渐进式层堆叠（即在训练期间逐步增加层）将数据难度的增加与模型增长同步。在100M参数规模下，使用从合成短故事到通用网络数据的课程，CGLS在问答基准PIQA和ARC上优于基线方法。在1.2B规模的预训练中，我们使用基于DistilBERT的分类器对DataComp-LM语料库进行分层，并从通用文本进展到高度技术性或专业化内容。我们的结果表明，随着样本难度的增加而逐步增加模型深度，可以导致在各种下游基准测试上实现更好的泛化和零样本性能。总而言之，我们的发现表明CGLS释放了渐进式堆叠的潜力，为提高知识密集型和推理任务的泛化能力提供了一种简单而有效的策略。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [488] [Predicting Early-Onset Colorectal Cancer with Large Language Models](https://arxiv.org/abs/2506.11410)
> *预测大型语言模型在早发性结直肠癌预测中的应用*

*Wilson Lau, Youngwon Kim, Sravanthi Parasa, Md Enamul Haque, Anand Oka, Jay Nanduri* | **Main category: cs.CL**

**Keywords:** 早发性结直肠癌, 大型语言模型, 机器学习, 癌症预测, 敏感性特异性

**Comment:** Paper accepted for the proceedings of the 2025 American Medical
  Informatics Association Annual Symposium (AMIA)

> **TL;DR:** 研究利用微调大型语言模型预测早发性结直肠癌，结果显示其具有高灵敏度和特异性，为早期筛查提供了新方法。

**AI_Comments:** 本文的创新之处在于首次将大型语言模型应用于早发性结直肠癌的预测，并取得了令人鼓舞的结果。这对于改进现有筛查策略，实现更早期的诊断具有重要意义。未来研究可以探索更大规模的数据集和更复杂的LLM架构，以进一步提高预测精度和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 早发性结直肠癌（EoCRC）发病率逐年上升，但该人群年龄低于国家指南推荐的癌症筛查年龄，导致现有筛查手段无法覆盖。

**Method:** 研究应用了10种不同的机器学习模型，并与先进的大型语言模型（LLM）进行性能比较，利用患者在结直肠癌诊断前6个月内的健康状况、实验室结果和观察数据。研究回顾性地识别了来自美国多个医疗系统的1,953名结直肠癌患者。

**Result:** 微调后的LLM平均达到了73%的敏感性和91%的特异性。

**Conclusion:** 微调后的大型语言模型在预测早发性结直肠癌方面表现出良好的性能，有望为早期诊断提供有效工具。

> **ai_Abstract:** 本文旨在解决早发性结直肠癌（EoCRC）发病率上升但现有筛查指南未覆盖的问题。研究比较了10种传统机器学习模型与微调大型语言模型（LLM）在预测EoCRC方面的性能，数据来源于1,953名患者的健康记录。结果显示，微调后的LLM表现出色，敏感性达到73%，特异性达到91%，为EoCRC的早期预测提供了新的有效途径。

> **摘要翻译:** 早发性结直肠癌（EoCRC，年龄<45岁）的发病率逐年增加，但该人群比国家指南推荐的癌症筛查年龄更年轻。在本文中，我们应用了10种不同的机器学习模型来预测EoCRC，并将其性能与先进的大型语言模型（LLM）进行了比较，使用了患者在结直肠癌诊断前6个月内的健康状况、实验室结果和观察数据。我们回顾性地识别了来自美国多个医疗系统的1,953名结直肠癌患者。结果表明，微调后的LLM平均达到了73%的敏感性和91%的特异性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [492] [Efficient Long-Context LLM Inference via KV Cache Clustering](https://arxiv.org/abs/2506.11418)
> *高效长上下文LLM推理通过KV缓存聚类*

*Jie Hu, Shengnan Wang, Yutong He, Ping Gong, Jiawei Yi, Juncheng Zhang, Youhui Bai, Renhai Chen, Gong Zhang, Cheng Li, Kun Yuan* | **Main category: cs.CL**

**Keywords:** KV缓存聚类, 长上下文LLM, 推理优化, 内存效率, Chelsea

**Comment:** 

> **TL;DR:** 本文提出Chelsea框架，通过在线KV缓存聚类显著减少长上下文LLM的内存使用并加速推理。

**AI_Comments:** Chelsea框架通过创新的在线KV缓存聚类方法，有效解决了长上下文LLM部署中的关键内存瓶颈和推理效率问题。其核心创新在于利用键状态的相似性并引入“分块软匹配”策略，实现了显著的内存缩减和速度提升，同时保持了模型性能，这对于未来大规模LLM的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 长上下文LLMs需要大量的KV缓存，这带来了显著的部署挑战。现有方法要么丢弃关键信息，要么因高计算开销而效率提升有限。

**Method:** 本文引入Chelsea框架，一个简单而有效的在线KV缓存聚类方法。该方法基于键状态在序列维度上表现出高度相似性的观察。为实现高效聚类，将序列分成块，并提出分块软匹配（Chunked Soft Matching），其在每个块内采用交替分区策略，并根据相似性识别簇。Chelsea随后将每个簇内的KV缓存合并成一个单一的质心。此外，还提供了计算复杂度和块内分区策略最优性的理论分析。

**Result:** Chelsea在各种模型和长上下文基准测试中，将KV缓存内存使用量减少高达80%，同时保持可比的模型性能。在极小的计算开销下，Chelsea将推理的解码阶段加速高达3.19倍，并将端到端延迟降低高达2.72倍。

**Conclusion:** Chelsea框架通过高效的在线KV缓存聚类方法，有效解决了长上下文LLM的内存和推理效率问题，显著提升了其部署的可行性和性能。

> **ai_Abstract:** 本文提出Chelsea，一个用于长上下文LLM的高效在线KV缓存聚类框架。它利用键状态在序列维度上的相似性，通过分块软匹配将KV缓存聚类并合并为质心，从而显著减少KV缓存内存使用（高达80%），并在最小计算开销下加速推理解码（高达3.19倍）并降低端到端延迟（高达2.72倍），同时保持模型性能。

> **摘要翻译:** 长上下文窗口的大型语言模型（LLMs）在处理复杂任务方面变得越来越普遍。然而，长上下文LLMs所需的大量键值（KV）缓存带来了显著的部署挑战。现有方法要么丢弃未来生成可能需要的关键信息，要么由于计算开销高而效率提升有限。在本文中，我们引入了Chelsea，一个简单而有效的在线KV缓存聚类框架。我们的方法基于一个观察：键状态沿序列维度表现出高度相似性。为了实现高效聚类，我们将序列分成块，并提出了分块软匹配（Chunked Soft Matching），它在每个块内采用交替分区策略，并根据相似性识别簇。然后，Chelsea将每个簇内的KV缓存合并成一个单一的质心。此外，我们提供了计算复杂度和块内分区策略最优性的理论分析。在各种模型和长上下文基准上的大量实验表明，Chelsea在保持可比模型性能的同时，将KV缓存内存使用量减少高达80%。此外，在极小的计算开销下，Chelsea将推理的解码阶段加速高达3.19倍，并将端到端延迟降低高达2.72倍。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [495] [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](https://arxiv.org/abs/2506.11425)
> *Agent-RLVR：通过指导和环境奖励训练软件工程智能体*

*Jeff Da, Clinton Wang, Xiang Deng, Yuntao Ma, Nikhil Barhate, Sean Hendryx* | **Main category: cs.CL**

**Keywords:** 软件工程, 强化学习, 大型语言模型, 智能体, 指导

**Comment:** 

> **TL;DR:** Agent-RLVR通过引入指导机制，解决了传统RLVR在复杂智能体环境中奖励稀疏的问题，显著提升了软件工程任务中大型语言模型的性能。

**AI_Comments:** 本文的创新点在于引入了“智能体指导”机制，有效地解决了传统RLVR在复杂、奖励稀疏的智能体环境中的局限性。通过模拟人类教学过程，为智能体提供了更丰富的反馈和引导，使其能够更有效地探索和学习。这对于提升大型语言模型在实际复杂任务（如软件工程）中的应用能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习从可验证奖励（RLVR）在智能体环境中效果不佳，因为这些多步复杂问题解决任务导致奖励稀疏，使得模型训练困难。

**Method:** 提出Agent-RLVR框架，引入“智能体指导”机制，通过利用高层战略计划、错误动态反馈和环境互动等信息线索，主动引导智能体走向成功轨迹。训练循环包括：智能体尝试解决任务生成初始轨迹，通过单元测试验证并补充指导，智能体在指导下重新尝试，最后通过RLVR根据这些有指导的轨迹奖励更新智能体策略。

**Result:** Agent-RLVR将Qwen-2.5-72B-Instruct在SWE-Bench Verified上的pass@1性能从9.4%提升到22.4%。指导增强的RLVR数据对测试时奖励模型训练也有用，进一步将pass@1提升到27.8%。

**Conclusion:** Agent-RLVR为在传统RL方法难以应对的复杂真实世界环境中，使用RLVR训练智能体奠定了基础。

> **ai_Abstract:** 本文介绍了Agent-RLVR，一个旨在解决传统强化学习从可验证奖励（RLVR）在复杂智能体环境中（如软件工程）奖励稀疏问题的框架。Agent-RLVR通过引入“智能体指导”机制，模仿人类教学法，利用多样化的信息线索引导智能体生成成功的解决方案轨迹。实验结果表明，Agent-RLVR显著提升了大型语言模型在软件工程任务上的性能，并为在复杂真实世界环境中训练智能体奠定了基础。

> **摘要翻译:** 从可验证奖励中进行强化学习（RLVR）已被广泛采纳为增强大型语言模型推理能力的事实标准方法，并在数学和竞技编程任务等可验证领域取得了显著成功。然而，当应用于智能体环境时，RLVR的效力显著降低。这些环境以多步、复杂问题解决为特征，即使对于前沿的大型语言模型，也导致高失败率，因为奖励格局过于稀疏，无法通过传统的RLVR进行有效模型训练。在这项工作中，我们引入了Agent-RLVR，一个使RLVR在具有挑战性的智能体设置中变得有效的框架，初步侧重于软件工程任务。受人类教学法的启发，Agent-RLVR引入了智能体指导，这是一种通过利用多样化的信息线索主动引导智能体走向成功轨迹的机制。这些线索，从高层战略计划到智能体错误和环境交互的动态反馈，模拟了教师的指导，使智能体能够导航困难的解决方案空间，并通过额外的环境探索促进积极的自我改进。在Agent-RLVR训练循环中，智能体首先尝试解决任务以生成初始轨迹，然后通过单元测试进行验证并补充智能体指导。然后智能体在指导下重新尝试，并根据这些有指导的轨迹的奖励通过RLVR更新智能体策略。Agent-RLVR将Qwen-2.5-72B-Instruct在SWE-Bench Verified上的pass@1性能从9.4%提升到22.4%。我们发现我们指导增强的RLVR数据对于测试时奖励模型训练也很有用，表现为进一步将pass@1提升到27.8%。Agent-RLVR为在传统RL方法难以应对的复杂真实世界环境中，使用RLVR训练智能体奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [499] [KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models](https://arxiv.org/abs/2506.11432)
> *KoGEC：使用预训练翻译模型进行韩语语法纠错*

*Taeeun Kim, Semin Jeong, Youngsook Song* | **Main category: cs.CL**

**Keywords:** 韩语语法纠错, 预训练翻译模型, NLLB, KoGEC, LLM作为评判

**Comment:** 11 pages, 2 figures

> **TL;DR:** KoGEC是一个使用预训练翻译模型（NLLB）进行韩语语法纠错的系统，在韩语语法纠错任务中优于GPT-4o和HCX-3，并展示了紧凑型模型在特定任务中与大型通用模型竞争的潜力。

**AI_Comments:** 这项研究的创新之处在于利用预训练翻译模型进行语法纠错，并成功证明了针对特定任务微调的紧凑型模型可以超越大型通用模型。其贡献包括提出一个高效的韩语GEC系统、一种新的评估方法以及强调了模型大小与任务特异性之间的权衡。开发Chrome扩展也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个高效、专门的韩语语法纠错（GEC）系统，并通过微调预训练翻译模型来解决韩语语法错误纠正问题，并与大型语言模型（如GPT-4和HCX-3）进行性能比较。

**Method:** 研究引入了KoGEC系统，通过使用特殊语言标记区分原始和纠正后的韩语句子，微调NLLB（No Language Left Behind）模型进行韩语GEC。训练和测试使用了两个社交媒体对话数据集。评估采用BLEU分数和“LLM作为评判”的方法来分类错误类型。此外，还开发了Chrome扩展，并探索了词汇扩展。

**Result:** 微调后的NLLB（KoGEC）模型在韩语GEC任务中表现优于GPT-4o和HCX-3。KoGEC在各种错误类型上表现出更平衡的纠错能力，而大型LLM对标点符号错误的关注较少。研究还开发了一个Chrome扩展。然而，探索词汇扩展反而降低了模型性能。

**Conclusion:** 本研究为自然语言处理领域贡献了一个高效、专门的韩语GEC系统和一种新的评估方法。它强调了紧凑型、任务特定模型在专业NLP任务中与大型通用语言模型竞争的潜力。

> **ai_Abstract:** KoGEC是一个专注于韩语语法纠错的系统，它通过微调NLLB预训练翻译模型实现。研究使用社交媒体数据集进行训练和评估，发现KoGEC在韩语GEC任务中表现优于GPT-4o和HCX-3，尤其在错误类型平衡性上更优。尽管词汇扩展尝试未能提升性能，但该研究成功开发了一个高效的专用系统，并展示了小型任务特定模型在特定NLP领域超越大型通用模型的潜力，同时提供了一种新的评估方法和一个Chrome扩展。

> **摘要翻译:** 这项研究引入了KoGEC，一个使用预训练翻译模型进行韩语语法纠错的系统。我们针对韩语GEC任务微调了NLLB（No Language Left Behind）模型，并将其性能与GPT-4和HCX-3等大型语言模型进行了比较。该研究使用两个社交媒体对话数据集进行训练和测试。NLLB模型通过使用特殊语言标记进行微调，以区分原始和纠正后的韩语句子。评估使用BLEU分数和“LLM作为评判”的方法来分类错误类型。结果显示，微调后的NLLB（KoGEC）模型在韩语GEC任务中优于GPT-4o和HCX-3。KoGEC在各种错误类型上表现出更平衡的纠错能力，而大型LLM往往较少关注标点符号错误。我们还开发了一个Chrome扩展，使用户可以访问KoGEC系统。最后，我们探索了词汇扩展以进一步改进模型，但发现它会降低模型性能。这项研究通过提供一个高效、专门的韩语GEC系统和一种新的评估方法，为自然语言处理领域做出了贡献。它还强调了紧凑型、任务特定模型在专业NLP任务中与大型通用语言模型竞争的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [503] [AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org/abs/2506.11440)
> *AbsenceBench：语言模型无法判断缺失内容*

*Harvey Yiyun Fu, Aryan Shrivastava, Jared Moore, Peter West, Chenhao Tan, Ari Holtzman* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 缺失信息检测, AbsenceBench, Transformer注意力, 能力评估

**Comment:** 23 pages, 8 figures. Code and data are publicly available at
  https://github.com/harvey-fin/absence-bench

> **TL;DR:** 大型语言模型在识别文档中缺失信息方面表现不佳，即使是先进模型也难以胜任，这可能是由于Transformer注意力机制的根本限制。

**AI_Comments:** 该论文通过引入AbsenceBench，揭示了大型语言模型（LLMs）在识别缺失信息这一看似简单任务上的根本性局限。其创新之处在于提出了一个专门针对“缺失”而非“存在”信息的评估基准。这对于理解LLMs的注意力机制和未来模型设计具有重要意义，因为它指出了模型在处理非显式信息时的盲点，这与它们在“大海捞针”等任务中的超人表现形成了鲜明对比，为LLMs的能力边界提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在处理长输入和定位特定信息（如“大海捞针”测试）方面表现出色，但它们在识别明确省略的信息时仍然存在困难。本研究旨在评估LLMs检测缺失信息的能力。

**Method:** 研究引入了AbsenceBench基准测试，用于评估LLMs在三个领域（数字序列、诗歌和GitHub拉取请求）检测缺失信息的能力。该测试要求模型在给定原始和编辑上下文的情况下，识别文档中被故意删除的部分。

**Result:** 实验表明，即使是先进的模型（如Claude-3.7-Sonnet）在平均上下文长度为5K token的任务中，F1分数也仅达到69.6%。

**Conclusion:** LLMs在识别缺失信息方面的表现不佳，这可能源于Transformer注意力机制的根本限制，即它们难以关注文档中的“空白”或“缺失”部分。这表明模型在某些任务上表现超人，但在其他看似简单的相关任务上却意外崩溃。

> **ai_Abstract:** 本研究引入了AbsenceBench基准测试，旨在评估大型语言模型（LLMs）识别文档中缺失信息的能力。与LLMs在定位现有信息方面的出色表现（如“大海捞针”测试）形成对比，实验结果显示，即使是当前最先进的模型，在识别数字序列、诗歌和GitHub拉取请求中故意移除的内容时，表现也远低于预期，F1分数仅为69.6%。研究分析指出，这种局限性可能源于Transformer注意力机制无法有效处理“空白”或“缺失”信息。这揭示了LLMs在看似相似但需要识别“不存在”内容的任务上存在的根本性弱点。

> **摘要翻译:** 大型语言模型（LLMs）在处理长输入并定位其中特定信息方面的能力日益增强，这在“大海捞针”（NIAH）测试中的表现得到了证明。然而，尽管模型在回忆令人惊讶的信息方面表现出色，但它们仍然难以识别明确省略的信息。我们引入了AbsenceBench来评估LLMs在三个领域（数字序列、诗歌和GitHub拉取请求）检测缺失信息的能力。AbsenceBench要求模型在给定原始和编辑上下文的情况下，识别文档中被故意删除的部分。尽管这些任务看似简单，但我们的实验表明，即使是像Claude-3.7-Sonnet这样的最先进模型，在平均上下文长度为5K token的情况下，F1分数也仅达到69.6%。我们的分析表明，这种糟糕的性能源于一个根本限制：Transformer注意力机制无法轻易地关注文档中的“空白”，因为这些缺失不对应于任何可以被关注的特定键。总的来说，我们的结果和分析提供了一个案例研究，说明了模型已经超人的任务（NIAH）与模型意外崩溃的任务（AbsenceBench）之间的紧密联系。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [510] [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org/abs/2506.11474)
> *Med-PRM: 具有逐步、指南验证过程奖励的医疗推理模型*

*Jaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe Koo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, Jaewoo Kang* | **Main category: cs.CL**

**Keywords:** 医疗推理, 大型语言模型, 过程奖励模型, 检索增强生成, 临床决策

**Comment:** 

> **TL;DR:** Med-PRM是一个利用检索增强生成和医疗知识库来验证每一步推理的框架，显著提高了医疗问答和诊断任务中大型语言模型的性能。

**AI_Comments:** Med-PRM的创新之处在于其引入了逐步、指南验证的过程奖励机制，这对于医疗领域至关重要，因为它能够提高推理过程的透明度和可信度。通过结合检索增强生成，它有效利用了外部医疗知识，增强了模型的可靠性。在小规模模型上实现SOTA性能也显示了其高效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型在临床决策中难以定位和纠正推理过程中的具体错误，这在医学领域至关重要。

**Method:** 引入Med-PRM，一个过程奖励建模框架，它利用检索增强生成技术，根据已建立的医疗知识库验证每个推理步骤。通过从临床指南和文献中检索证据来验证中间推理步骤，模型可以细粒度地评估推理质量。

**Result:** Med-PRM在五个医疗问答基准和两个开放式诊断任务上实现了最先进的性能，将基础模型的性能提高了高达13.50%。首次使用80亿参数的小规模模型在MedQA上实现了超过80%的准确率，通过即插即用的方式与Meerkat等强大的策略模型集成，证明了其通用性。

**Conclusion:** Med-PRM通过逐步、指南验证的过程奖励机制，有效解决了大型语言模型在医疗推理中错误定位和纠正的难题，显著提升了医疗决策的准确性和可靠性。

> **ai_Abstract:** Med-PRM是一个新颖的过程奖励建模框架，旨在解决大型语言模型在医疗推理中难以定位和纠正错误的问题。它通过检索增强生成技术，利用医疗知识库和临床指南对推理的每个中间步骤进行验证，从而实现对推理质量的细粒度评估。实验证明，Med-PRM在多个医疗问答和诊断任务上取得了最先进的性能，显著提升了基础模型的准确性，并展示了其与现有策略模型的良好兼容性。

> **摘要翻译:** 大型语言模型在临床决策中展现出潜力，但当前方法难以在推理过程的具体步骤中定位和纠正错误。这一局限在医学领域至关重要，因为识别和解决推理错误对于准确诊断和有效患者护理至关重要。我们引入了Med-PRM，一个过程奖励建模框架，它利用检索增强生成技术，根据已建立的医疗知识库验证每个推理步骤。通过从临床指南和文献中检索证据来验证中间推理步骤，我们的模型能够以细粒度的方式精确评估推理质量。在五个医疗问答基准和两个开放式诊断任务上的评估表明，Med-PRM实现了最先进的性能，使用Med-PRM将基础模型的性能提高了高达13.50%。此外，我们通过以即插即用的方式将其与Meerkat等强大的策略模型集成，证明了Med-PRM的通用性，首次使用80亿参数的小规模模型在MedQA上实现了超过80%的准确率。我们的代码和数据可在以下网址获取：https://med-prm.github.io/

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [514] [ImmunoFOMO: Are Language Models missing what oncologists see?](https://arxiv.org/abs/2506.11478)
> *免疫FOMO：语言模型是否错过了肿瘤学家所见？*

*Aman Sinha, Bogdan-Valentin Popescu, Xavier Coubez, Marianne Clausel, Mathieu Constant* | **Main category: cs.CL**

**Keywords:** 语言模型, 肿瘤学, 免疫疗法, 乳腺癌, 自然语言处理

**Comment:** 

> **TL;DR:** 预训练语言模型在识别乳腺癌摘要中免疫疗法特征的特定（低级）概念方面，可能优于大型语言模型。

**AI_Comments:** 这项研究的创新之处在于它直接比较了不同类型的语言模型（预训练模型与大型模型）在高度专业化医学概念识别任务上的表现。它揭示了大型语言模型可能在识别非常具体、低级概念方面存在局限性，而预训练的、可能更专业的模型则表现更佳，这对于医学NLP应用的开发具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在调查各种语言模型在识别乳腺癌摘要中免疫疗法特征方面的医学概念基础，并将其与专家临床医生进行比较。

**Method:** 研究通过将各种语言模型与专家临床医生进行对比，以识别乳腺癌摘要中免疫疗法的关键特征来评估其医学概念基础。

**Result:** 结果表明，预训练语言模型在识别非常具体（低级）的概念方面，有潜力超越大型语言模型。

**Conclusion:** 预训练语言模型在识别医学领域中非常具体的低级概念方面可能更有效，这表明在特定领域应用中，并非越大越好。

> **ai_Abstract:** 本研究调查了语言模型在识别乳腺癌摘要中免疫疗法特征的医学概念基础，并将其表现与专家临床医生进行比较。结果显示，预训练语言模型在识别特定（低级）概念方面，可能优于大型语言模型。

> **摘要翻译:** 在过去十年中，语言模型（LMs）的能力迅速增长，这使得生物医学研究等各个领域的研究人员越来越多地探索语言模型在日常应用中的效用。特定领域的语言模型已经用于生物医学自然语言处理（NLP）应用。然而，最近人们对医学语言模型及其理解能力越来越感兴趣。在本文中，我们针对专家临床医生，研究了各种语言模型在乳腺癌摘要中识别免疫疗法特征的医学概念基础。我们的结果表明，预训练语言模型在识别非常具体（低级）概念方面，有潜力超越大型语言模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [518] [Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models](https://arxiv.org/abs/2506.11485)
> *BERT中的关系图式是可诱导而非涌现的：语言模型中性能与能力的研究*

*Cole Gawin* | **Main category: cs.CL**

**Keywords:** BERT, 关系图式, 语言模型, 微调, 概念能力

**Comment:** 15 pages, 4 figures, 3 tables

> **TL;DR:** BERT对关系图式的理解并非仅通过预训练自动涌现，而是需要通过有监督的微调任务来诱导形成。

**AI_Comments:** 这项研究深入探讨了大型语言模型能力的核心问题，区分了“性能”与“能力”的区别。其创新之处在于通过实验证明了BERT对关系图式的理解并非自然涌现，而是需要通过有监督的微调来“诱导”。这对于理解和改进LLM的训练范式具有重要意义，提示我们在设计模型时应更注重任务导向的训练，以促进更深层次的语义理解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型如BERT在语义任务上表现出色，但其性能是否反映了真正的概念能力，还是仅仅停留在表面统计关联，这一点尚不明确。

**Method:** 研究通过检查BERT在分类、整体和功能关系上概念对的内部表示，来探究BERT是否编码了抽象的关系图式。通过比较BERT的关系分类性能与[CLS]标记嵌入中的表示结构进行分析。

**Result:** 预训练的BERT模型能够实现高分类准确率，表明存在潜在的关系信号。然而，概念对在微调有监督关系分类任务后，才能在高维嵌入空间中按关系类型组织。

**Conclusion:** 关系图式并非仅从预训练中涌现，而是可以通过任务支架（如微调）来诱导形成。这表明行为性能不一定意味着结构化的概念理解，但模型可以通过适当的训练获得接地关系抽象的归纳偏置。

> **ai_Abstract:** 本研究探讨了BERT等大型语言模型在语义任务上的高表现是否代表真正的概念能力。通过分析BERT对概念对（涵盖分类、整体、功能关系）的内部表示，发现预训练的BERT虽能识别潜在关系信号，但概念对在嵌入空间中按关系类型组织的能力，仅在有监督的关系分类任务微调后才出现。这表明，关系图式并非仅通过预训练自动涌现，而是需要通过特定任务的诱导才能形成。研究强调，模型的外在性能不必然等同于结构化的概念理解，但适当的训练能帮助模型习得深层的关系抽象能力。

> **摘要翻译:** 虽然像BERT这样的大型语言模型在语义任务上表现出强大的经验性能，但这种表现是否反映了真正的概念能力还是表面级的统计关联仍不清楚。我通过检查概念对在分类、整体和功能关系中的内部表示，来研究BERT是否编码了抽象的关系图式。我将BERT的关系分类性能与[CLS]标记嵌入中的表示结构进行比较。结果表明，预训练的BERT能够实现高分类准确率，表明存在潜在的关系信号。然而，概念对只有在对有监督关系分类任务进行微调后，才能在高维嵌入空间中按关系类型组织。这表明关系图式并非仅从预训练中涌现，而是可以通过任务支架来诱导。这些发现表明，行为性能不一定意味着结构化的概念理解，尽管模型可以通过适当的训练获得接地关系抽象的归纳偏置。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [522] [Lag-Relative Sparse Attention In Long Context Training](https://arxiv.org/abs/2506.11498)
> *滞后相对稀疏注意力在长上下文训练中的应用*

*Manlai Liang, Wanyi Huang, Mandi Liu, Huaijun Li, Jinlong Li* | **Main category: cs.CL**

**Keywords:** 滞后相对稀疏注意力, 长上下文训练, 大型语言模型, 键值压缩, 效率

**Comment:** 

> **TL;DR:** 为解决大型语言模型在长上下文训练中注意力计算的二次复杂度和内存限制，本文提出了滞后相对稀疏注意力（LRSA）结合LagKV压缩方法，用于长上下文后训练，无需额外参数，开销小，并通过选择固定大小滞后窗口中的Top K相关键值对，显著增强了LLM的鲁棒性，并在问答任务中取得了更好的微调效果。

**AI_Comments:** 本文提出的滞后相对稀疏注意力（LRSA）在解决大型语言模型长上下文处理效率问题方面具有创新性。其主要亮点在于将键值压缩技术与后训练相结合，且实现了无额外参数和低计算开销，这对于实际部署和模型优化具有重要意义。通过“滞后窗口”和“Top K选择”机制，模型能够有效聚焦于关键历史信息，提升了压缩上下文下的鲁棒性和微调性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在处理长上下文输入时，受到注意力计算的二次复杂度和键值内存占用线性增长的限制。现有的键值缓存压缩技术虽然常用于推理阶段，但会导致严重的性能下降，且更复杂的压缩方法不适用于基于梯度优化或计算开销过高的后训练。

**Method:** 本文提出了滞后相对稀疏注意力（LRSA），该方法以LagKV压缩为基础，用于长上下文后训练。LRSA通过分块预填充（chunk-by-chunk prefilling）实现，在固定大小的滞后窗口中选择Top K个最相关的键值对，使模型能够专注于重要的历史上下文，同时保持效率，且无需额外参数，计算开销小。

**Result:** 实验结果表明，该方法显著增强了大型语言模型在键值压缩下的鲁棒性，并在问答调优任务中取得了更好的微调结果。

**Conclusion:** 滞后相对稀疏注意力（LRSA）结合LagKV压缩，有效解决了大型语言模型在长上下文后训练中的效率和鲁棒性问题，且无需额外参数和低计算开销，提升了模型在压缩环境下的性能。

> **ai_Abstract:** 本文提出了一种名为滞后相对稀疏注意力（LRSA）的新方法，结合LagKV压缩，以解决大型语言模型在长上下文训练中面临的二次注意力复杂度和内存限制问题。LRSA通过分块预填充和在固定大小滞后窗口中选择最相关的K个键值对来提高效率。该方法无需额外参数且计算开销小，特别适用于长上下文的后训练。实验结果表明，LRSA显著增强了LLM在键值压缩下的鲁棒性，并在问答调优任务中取得了更好的微调效果。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言处理和生成方面取得了显著进展，但其处理长上下文输入的能力仍受限于注意力计算的二次复杂性和键值内存占用线性增长。为了降低计算成本和内存消耗，键值缓存压缩技术通常应用于推理阶段，但这常常导致严重的性能下降，因为模型并未针对压缩上下文进行训练。尽管存在更复杂的压缩方法，但它们通常不适用于后训练，因为它们与基于梯度的优化不兼容或计算开销过高。为了在不增加额外参数和少量计算开销的情况下弥补这一空白，我们提出了以LagKV压缩方法为基础的滞后相对稀疏注意力（LRSA），用于长上下文后训练。我们的方法执行分块预填充，在固定大小的滞后窗口中选择最相关的Top K个键值对，使模型能够专注于显著的历史上下文，同时保持效率。实验结果表明，我们的方法显著增强了LLM在键值压缩下的鲁棒性，并在问答调优任务中取得了更好的微调结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [526] [On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval](https://arxiv.org/abs/2506.11499)
> *多模态对话响应检索中集成方法的有效性研究*

*Seongbo Jang, Seonghyeon Lee, Dongha Lee, Hwanjo Yu* | **Main category: cs.CL**

**Keywords:** 多模态对话, 响应检索, 集成方法, 端到端, 参数共享

**Comment:** 9 pages, 1 figure

> **TL;DR:** 本文探讨了多模态对话响应检索的集成方法，提出了一种端到端方法，并发现参数共享策略能提升性能并减少参数。

**AI_Comments:** 这项工作探讨了多模态对话响应检索的关键问题，特别是在集成不同模态信息方面。提出端到端方法并验证其有效性，以及引入参数共享策略来提升效率和性能，是其创新点。这对于推动多模态对话系统的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态聊天机器人是对话系统领域的热点，研究人员开始关注响应和对话上下文的多模态性。本文旨在探索对话系统如何输出文本和图像等多种模态的响应。

**Method:** 本文首先将多模态对话响应检索任务公式化为三个子任务的组合。然后，提出了三种基于两步法和端到端法的集成方法，并比较了它们的优缺点。

**Result:** 在两个数据集上的实验结果表明，端到端方法无需两步法中的中间步骤即可获得可比的性能。此外，参数共享策略不仅减少了参数数量，还通过跨子任务和模态的知识迁移提升了性能。

**Conclusion:** 端到端方法在多模态对话响应检索中是有效的，并且参数共享策略能显著提升性能和效率。

> **ai_Abstract:** 本文研究了多模态对话响应检索的集成方法，旨在使对话系统能输出文本和图像等多模态响应。作者将该任务定义为三个子任务的组合，并提出了两步法和端到端法两种集成策略。实验证明，端到端方法在性能上与两步法相当，且无需中间步骤。此外，引入参数共享策略不仅能减少模型参数，还能通过知识迁移进一步提升性能。

> **摘要翻译:** 多模态聊天机器人在研究界和工业界都已成为对话系统的主要课题之一。最近，研究人员已经开始关注响应以及对话上下文的多模态性。这项工作探讨了对话系统如何输出文本和图像等各种模态的响应。为此，我们首先将基于检索系统的多模态对话响应检索任务公式化为三个子任务的组合。然后，我们提出了三种基于两步法和端到端法的集成方法，并比较了每种方法的优缺点。在两个数据集上的实验结果表明，端到端方法无需两步法中的中间步骤即可获得可比的性能。此外，参数共享策略不仅减少了参数数量，还通过跨子任务和模态的知识迁移提升了性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [530] [From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation](https://arxiv.org/abs/2506.11557)
> *从角色到个人：在个性化对话生成中通过多语篇关系图学习增强自然度*

*Chih-Hao Hsu, Ying-Jia Lin, Hung-Yu Kao* | **Main category: cs.CL**

**Keywords:** 个性化对话生成, 语篇关系, 图学习, 大语言模型, 自然度

**Comment:** Accepted by PAKDD 2025

> **TL;DR:** MUDI利用大语言模型辅助标注语篇关系并将对话数据转化为结构化图，通过DialogueGAT和连贯性感知注意力策略，显著提升了个性化对话生成的自然度。

**AI_Comments:** 该论文的创新点在于将大语言模型引入语篇关系标注，并将对话数据转化为图结构进行学习，有效地捕捉了对话中的隐式语篇关系和个性化信息。通过结合图神经网络和连贯性感知注意力机制，显著提升了个性化对话的自然度和连贯性，为个性化对话生成领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在对话生成中，响应的自然度对于有效的人机交互至关重要。个性化响应生成面临更大的挑战，因为响应必须与用户的个人特质或角色描述保持连贯和一致。

**Method:** 我们提出了MUDI（多语篇关系图学习）用于个性化对话生成。利用大语言模型辅助标注语篇关系，并将对话数据转化为结构化对话图。我们提出的图编码器DialogueGAT模型捕捉结构中的隐式语篇关系和角色描述。在个性化响应生成阶段，实施新颖的连贯性感知注意力策略，以增强解码器对语篇关系的考量。

**Result:** 我们的实验证明个性化响应的质量显著提高，从而更接近人类对话交流。

**Conclusion:** 本研究提出的MUDI方法通过利用大语言模型辅助语篇关系标注和图学习，显著提升了个性化对话生成的自然度和响应质量，使其更接近人类对话水平。

> **ai_Abstract:** 本研究提出MUDI框架，旨在通过多语篇关系图学习提升个性化对话生成的自然度。该方法利用大型语言模型标注语篇关系，将对话数据转换为结构化图，并引入DialogueGAT模型捕获隐式语篇关系和角色描述。此外，在响应生成阶段采用连贯性感知注意力策略。实验结果表明，MUDI显著改善了个性化响应的质量，使其更接近人类对话水平。

> **摘要翻译:** 在对话生成中，响应的自然度对于有效的人机交互至关重要。个性化响应生成面临更大的挑战，因为响应必须与用户的个人特质或角色描述保持连贯和一致。我们提出了MUDI（多语篇关系图学习）用于个性化对话生成。我们利用一个大语言模型辅助标注语篇关系，并将对话数据转化为结构化对话图。我们提出的图编码器DialogueGAT模型捕捉结构中的隐式语篇关系，以及角色描述。在个性化响应生成阶段，实施新颖的连贯性感知注意力策略，以增强解码器对语篇关系的考量。我们的实验证明个性化响应的质量显著提高，从而更接近人类对话交流。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [532] [Are LLMs Good Text Diacritizers? An Arabic and Yorùbá Case Study](https://arxiv.org/abs/2506.11602)
> *大型语言模型是优秀的文本注音器吗？一项阿拉伯语和约鲁巴语的案例研究*

*Hawau Olamide Toyin, Samar M. Magdy, Hanan Aldarmaki* | **Main category: cs.CL**

**Keywords:** LLMs, 文本注音, 阿拉伯语, 约鲁巴语, 微调

**Comment:** 

> **TL;DR:** 本研究调查了大型语言模型（LLMs）在阿拉伯语和约鲁巴语文本注音方面的有效性，发现许多现成LLMs表现优于专业模型，但小型模型存在幻觉；微调可改善性能并减少幻觉。

**AI_Comments:** 这项研究通过引入新颖的多语言数据集MultiDiac，为LLMs在低资源语言文本注音领域的应用提供了有价值的见解。其创新之处在于对比了LLMs与专业模型的性能，并揭示了微调对于提升小型LLMs性能和减少幻觉的重要性，对未来LLMs在多语言文本处理中的应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究大型语言模型（LLMs）在两种类型学上截然不同的语言（阿拉伯语和约鲁巴语）中进行文本注音的有效性。

**Method:** 引入了一个新的多语言数据集MultiDiac用于严格评估。评估了14个不同大小、可访问性和语言覆盖范围的LLMs，并与6个专门的注音模型进行基准测试。此外，使用LoRA对四个小型开源模型进行了约鲁巴语的微调。

**Result:** 许多现成的LLMs在阿拉伯语和约鲁巴语的文本注音方面表现优于专门的注音模型。然而，较小的模型容易出现幻觉问题。

**Conclusion:** 在小型数据集上进行微调可以有效提高注音性能并降低LLMs的幻觉率。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在阿拉伯语和约鲁巴语文本注音任务上的表现。研究引入了一个新的多语言数据集MultiDiac，并对14个LLMs与6个专业注音模型进行了对比评估。结果显示，多数现成LLMs在两种语言上的注音效果优于专业模型，但小型LLMs易产生幻觉。研究还发现，在小型数据集上进行微调能有效提升注音性能并减少幻觉。

> **摘要翻译:** 我们研究了大型语言模型（LLMs）在两种类型学上截然不同的语言：阿拉伯语和约鲁巴语中进行文本注音的有效性。为了实现严格的评估，我们引入了一个新颖的多语言数据集MultiDiac，其中包含捕获一系列注音歧义的多样化样本。我们评估了14个大小、可访问性和语言覆盖范围各异的LLMs，并将其与6个专门的注音模型进行了基准测试。此外，我们使用LoRA对四个小型开源模型进行了约鲁巴语的微调。我们的结果表明，许多现成的LLMs在阿拉伯语和约鲁巴语方面都优于专门的注音模型，但较小的模型存在幻觉问题。在小型数据集上进行微调可以帮助提高注音性能并降低幻觉率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [535] [SceneGram: Conceptualizing and Describing Tangrams in Scene Context](https://arxiv.org/abs/2506.11631)
> *SceneGram：场景语境下七巧板的概念化与描述*

*Simeon Junker, Sina Zarrieß* | **Main category: cs.CL**

**Keywords:** 场景语境, 七巧板, 概念化, 多模态大型语言模型, 人类指称

**Comment:** To appear in ACL Findings 2025

> **TL;DR:** 本文提出了SceneGram数据集，用于研究场景语境如何影响人类对七巧板形状的概念化，并指出多模态大型语言模型未能捕捉到这种人类概念化的丰富性和变异性。

**AI_Comments:** 本文的创新之处在于创建了SceneGram数据集，为系统研究场景语境对物体概念化的影响提供了独特资源。它揭示了当前多模态大型语言模型在模拟人类基于语境的认知理解方面存在的局限性，对未来开发更具人类感知能力的AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 关于指称和命名的研究表明，人类可以以非常不同的方式对同一物体进行概念化和指称，例如，同一个抽象的七巧板形状可以是“螃蟹”、“水槽”或“宇宙飞船”。认知科学中普遍认为场景语境从根本上塑造了我们对物体的视觉感知和概念预期。本文旨在系统分析场景语境对概念化的影响，并评估多模态大型语言模型在此方面的表现。

**Method:** 本文贡献了SceneGram数据集，该数据集包含人类在不同场景语境下对七巧板形状的指称。基于此数据，研究分析了多模态大型语言模型生成的七巧板形状指称。

**Result:** 分析结果表明，多模态大型语言模型未能考虑到人类指称中发现的概念化的丰富性和变异性。

**Conclusion:** 多模态大型语言模型目前未能捕捉到人类在场景语境下对物体进行概念化时所展现的丰富性和变异性，这突显了它们在理解人类感知和指称方面存在的不足。

> **ai_Abstract:** 本文介绍了SceneGram数据集，该数据集收集了人类在不同场景语境下对七巧板形状的概念化指称，旨在系统分析场景语境对概念化的影响。研究进一步分析了多模态大型语言模型在此任务上的表现，结果表明这些模型未能像人类一样，充分捕捉到概念化过程中因场景语境而产生的丰富性和变异性。

> **摘要翻译:** 关于指称和命名的研究表明，人类可以以非常不同的方式对同一物体进行概念化和指称，例如，同一个抽象的七巧板形状可以是“螃蟹”、“水槽”或“宇宙飞船”。认知科学中的另一个常见假设是，场景语境从根本上塑造了我们对物体的视觉感知和概念预期。本文贡献了SceneGram，这是一个关于人类在不同场景语境下指称七巧板形状的数据集，允许系统地分析场景语境对概念化的影响。基于这些数据，我们分析了多模态大型语言模型生成的七巧板形状指称，结果表明这些模型没有考虑到人类指称中发现的概念化的丰富性和变异性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [537] [LoRA-Gen: Specializing Large Language Model via Online LoRA Generation](https://arxiv.org/abs/2506.11638)
> *LoRA-Gen：通过在线LoRA生成实现大型语言模型专业化*

*Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Yixiao Ge, Xiu Li, Ying Shan* | **Main category: cs.CL**

**Keywords:** LoRA-Gen, 大型语言模型, 边缘计算, 模型专业化, LoRA

**Comment:** 

> **TL;DR:** LoRA-Gen框架利用云端大型模型为边缘端模型生成LoRA参数，实现灵活专业化，无需专门训练，即可提高推理效率并超越传统LoRA微调。

**AI_Comments:** LoRA-Gen提出了一种创新的在线LoRA生成机制，使得边缘端模型无需传统训练即可实现专业化。其核心优势在于提高了效率和灵活性，并且在不牺牲性能的前提下实现了加速和压缩，这对于资源受限的边缘设备应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型在应用于特定领域任务，尤其是小型边缘端模型时，在有效性和效率方面仍面临局限性。

**Method:** LoRA-Gen框架使用云端大型模型根据任务描述为边缘端模型生成LoRA参数。通过重参数化技术，将LoRA参数合并到边缘端模型中，以实现灵活的专业化。该方法通过减少输入上下文长度来显著提高专业化模型的推理效率。

**Result:** LoRA-Gen在无需专门训练的情况下，性能优于传统LoRA微调，在推理任务中，使用TinyLLaMA-1.1B实现了具有竞争力的准确性和2.1倍的速度提升。此外，在智能代理任务中，使用Gemma-2B实现了10.1倍的压缩比。

**Conclusion:** LoRA-Gen通过在线生成LoRA参数，为边缘端模型提供了高效且灵活的专业化方法，在不进行专门训练的情况下，优于传统微调方法，并显著提升了推理效率和模型压缩率。

> **ai_Abstract:** LoRA-Gen是一个新颖的框架，旨在解决大型语言模型在边缘端设备上进行领域特定任务时的效率和有效性限制。该框架通过云端大型模型为边缘端模型生成LoRA参数，并利用重参数化技术将这些参数合并，从而实现模型的灵活专业化。LoRA-Gen无需传统微调，即可实现知识迁移，显著提升推理效率，并在实验中展现出优于传统LoRA微调的性能，包括在推理任务中2.1倍的速度提升和在智能代理任务中10.1倍的压缩比。

> **摘要翻译:** 最近的进展突出了扩展语言模型以增强各种NLP任务性能的益处。然而，这些方法在应用于特定领域任务时，特别是对于小型边缘端模型，在有效性和效率方面仍然面临局限性。我们提出了LoRA-Gen框架，该框架利用云端大型模型根据任务描述为边缘端模型生成LoRA参数。通过采用重参数化技术，我们将LoRA参数合并到边缘端模型中，以实现灵活的专业化。我们的方法促进了模型之间的知识转移，同时通过减少输入上下文长度显著提高了专业化模型的推理效率。在没有专门训练的情况下，LoRA-Gen优于传统的LoRA微调，在推理任务中，使用TinyLLaMA-1.1B实现了具有竞争力的准确性和2.1倍的速度提升。此外，我们的方法在智能代理任务中，使用Gemma-2B实现了10.1倍的压缩比。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [539] [Converting Annotated Clinical Cases into Structured Case Report Forms](https://arxiv.org/abs/2506.11666)
> *将标注的临床病例转换为结构化病例报告表*

*Pietro Ferrazzi, Alberto Lavelli, Bernardo Magnini* | **Main category: cs.CL**

**Keywords:** 病例报告表, CRF槽填充, 临床笔记, 数据集转换, 大型语言模型

**Comment:** to be published in BioNLP 2025

> **TL;DR:** 该论文提出了一种半自动方法，将现有的标注数据集转换为结构化病例报告表（CRF），以解决CRF槽填充任务的数据稀缺问题，并表明即使是先进的大型语言模型也难以完成此任务。

**AI_Comments:** 该论文通过利用现有标注数据集，为解决医学研究（CRF槽填充）特定领域的数据稀缺问题提供了一种创新方法。其半自动转换方法是一种实用的解决方案。研究结果突出了CRF槽填充任务的难度，即使对于先进的大型语言模型也是如此，这对于医学自然语言处理的未来研究具有重要意义。数据集的发布是对社区的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 公开可用的、标注良好的病例报告表（CRF）数据集稀缺，这限制了从临床笔记中填充CRF的系统开发。

**Method:** 提出了一种半自动转换方法，将现有的信息提取任务标注数据集（具体应用于英语和意大利语的E3C数据集）转换为结构化的CRF。随后，他们在新创建的数据集上使用大型语言模型进行了实验。

**Result:** 转换生成了一个新的高质量数据集。在闭源大型语言模型（零样本）上，意大利语的槽填充准确率为59.7%，英语为67.3%，而在开源模型上的表现更差。这表明即使对于最新的先进大型语言模型来说，填充CRF仍然具有挑战性。该数据集已公开发布。

**Conclusion:** 从临床笔记中填充病例报告表是一项具有挑战性的任务，即使对于先进的大型语言模型也是如此，并且可以通过转换现有标注数据来缓解高质量数据集的缺乏。

> **ai_Abstract:** 本文旨在解决标注病例报告表（CRF）数据集稀缺的问题，该问题阻碍了CRF槽填充系统的开发。作者提出了一种半自动方法，将现有的信息提取数据集（如英语和意大利语的E3C数据集）转换为结构化CRF。对新创建数据集的实验表明，CRF槽填充任务具有挑战性，即使是零样本的闭源大型语言模型，意大利语的准确率为59.7%，英语为67.3%，而开源模型的表现更差。该数据集已公开发布。

> **摘要翻译:** 病例报告表 (CRFs) 在医学研究中被广泛使用，因为它们确保了临床研究结果的准确性、可靠性和有效性。然而，公开可用的、标注良好的CRF数据集稀缺，这限制了能够从临床笔记中填充CRF的CRF槽填充系统的开发。为了缓解CRF数据集的稀缺性，我们建议利用已有的用于信息提取任务的标注数据集，并将其转换为结构化的CRF。我们提出了一种半自动转换方法，该方法已应用于两种语言（英语和意大利语）的E3C数据集，从而为CRF槽填充生成了一个新的高质量数据集。通过对所创建数据集的几次实验，我们报告了在闭源大型语言模型（零样本）上，意大利语的槽填充准确率为59.7%，英语为67.3%，而在三类开源模型上的表现更差，这表明即使对于最新的最先进的LLM来说，填充CRF仍然具有挑战性。我们已在https://huggingface.co/collections/NLP-FBK/e3c-to-crf-67b9844065460cbe42f80166发布了数据集。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [540] [code_transformed: The Influence of Large Language Models on Code](https://arxiv.org/abs/2506.12014)
> *代码_变革：大型语言模型对代码的影响*

*Yuliang Xu, Siming Huang, Mingmeng Geng, Yao Wan, Xuanhua Shi, Dongping Chen* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 代码风格, 编程实践, GitHub, snake_case

**Comment:** We release all the experimental dataset and source code at:
  https://github.com/ignorancex/LLM_code

> **TL;DR:** 本研究提供了首个大规模实证证据，表明大型语言模型（LLMs）正在影响真实世界的编程风格，例如Python代码中snake_case变量名的使用比例有所增加。

**AI_Comments:** 该研究的创新之处在于首次大规模实证分析了LLMs对真实世界代码风格的具体影响，而非仅停留在理论层面。其重要性在于揭示了LLMs不仅是代码生成工具，更是代码风格演变的重要驱动力。然而，研究也指出，由于LLMs的多样性和使用场景复杂，精确估计LLM生成或辅助代码的比例仍然困难，这可能是未来研究需要克服的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）代码生成能力的快速发展，它们正在显著重塑编程实践。这引发了一个核心问题：LLMs是否改变了代码风格，以及这种改变如何体现？

**Method:** 本研究通过分析2020年至2025年间与arXiv论文相关的19,000多个GitHub仓库的代码，调查了LLMs对代码风格（包括命名约定、复杂性、可维护性和相似性）的影响。此外，研究还通过检查LLMs的推理过程来探究它们如何处理算法问题。

**Result:** 研究识别出与LLM生成代码特征一致的编码风格演变的可衡量趋势。例如，Python代码中snake_case变量名的比例从2023年第一季度的47%增加到2025年第一季度的51%。

**Conclusion:** 实验结果首次提供了大规模的实证证据，表明LLMs正在影响真实世界的编程风格。

> **ai_Abstract:** 本研究是一项开创性工作，旨在量化大型语言模型（LLMs）对代码风格的影响。通过分析超过19,000个GitHub仓库的代码，研究发现LLMs正在改变编程实践，例如Python代码中snake_case变量名的使用比例有所增加。该研究提供了首个大规模实证证据，证明LLMs确实影响了真实世界的编程风格。

> **摘要翻译:** 编码仍然是人机交互最基本的方式之一。随着大型语言模型（LLMs）的快速发展，代码生成能力已开始显著重塑编程实践。这种发展引出了一个核心问题：LLMs是否改变了代码风格，以及这种改变如何表征？在本文中，我们提出了一项开创性研究，旨在调查LLMs对代码风格的影响，重点关注命名约定、复杂性、可维护性和相似性。通过分析2020年至2025年间与arXiv论文相关的19,000多个GitHub仓库的代码，我们识别出与LLM生成代码特征一致的编码风格演变的可衡量趋势。例如，Python代码中snake_case变量名的比例从2023年第一季度的47%增加到2025年第一季度的51%。此外，我们通过检查LLMs的推理过程来探究它们如何处理算法问题。考虑到LLMs的多样性、使用场景以及其他因素，精确估计由LLMs生成或辅助的代码比例是困难甚至不可能的。我们的实验结果首次提供了大规模的实证证据，表明LLMs正在影响真实世界的编程风格。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [543] [Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE](https://arxiv.org/abs/2506.11673)
> *改进遗忘式探测中因果干预的均值投影或LEACE方法*

*Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer* | **Main category: cs.CL**

**Keywords:** 遗忘式探测, 因果干预, 均值投影, LEACE, 信息移除

**Comment:** 

> **TL;DR:** 本文提出均值投影（MP）和LEACE两种方法，以更精确地移除特定信息，从而改进遗忘式探测中因果干预的准确性。

**AI_Comments:** 本文提出了两种新的信息移除方法（MP和LEACE），解决了遗忘式探测中现有技术（INLP）引入随机修改的问题，提高了因果干预的精确性，对于理解模型内部机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遗忘式探测中，现有方法（如迭代零空间投影INLP）在移除目标信息时会引入随机修改，导致无法准确评估特定语言信息对模型行为的影响。

**Method:** 本文提出并展示了均值投影（Mean Projection, MP）和LEACE这两种替代方法，用于更精确地移除模型中的特定信息。

**Result:** 均值投影（MP）和LEACE能以更具目标性的方式移除信息，从而增强通过遗忘式探测获取行为解释的潜力。

**Conclusion:** 均值投影（MP）和LEACE是改进遗忘式探测中因果干预的有效方法，有助于更准确地理解模型行为。

> **ai_Abstract:** 遗忘式探测旨在通过移除特定语言信息来评估其对模型行为的影响。然而，现有技术如迭代零空间投影（INLP）在移除信息时会引入不必要的随机修改。本文提出均值投影（MP）和LEACE作为替代方案，并证明它们能更精确地移除目标信息，从而提高遗忘式探测在获取模型行为解释方面的有效性。

> **摘要翻译:** 遗忘式探测是一种用于检查特定语言信息对模型行为影响的技术。这包括识别并移除相关信息，然后评估模型在主要任务上的性能是否发生变化。如果移除的信息是相关的，模型的性能应该会下降。这种方法的难点在于只移除目标信息，同时保持其他信息不变。研究表明，迭代零空间投影（INLP）——一种广泛使用的移除技术——在消除目标信息时会引入对表示的随机修改。我们证明了均值投影（MP）和LEACE这两种提出的替代方法能以更具目标性的方式移除信息，从而增强通过遗忘式探测获取行为解释的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [546] [LLMs for Sentence Simplification: A Hybrid Multi-Agent prompting Approach](https://arxiv.org/abs/2506.11681)
> *LLMs用于句子简化：一种混合多智能体提示方法*

*Pratibha Zunjare, Michael Hsiao* | **Main category: cs.CL**

**Keywords:** 句子简化, 大型语言模型, 多智能体, 混合方法, 提示工程

**Comment:** 

> **TL;DR:** 本文提出了一种结合高级提示和多智能体架构的混合方法，利用大型语言模型（LLMs）简化复杂句子，并在视频游戏设计应用中取得了70%的成功率，优于单智能体方法。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合高级提示和多智能体架构的混合方法来解决句子简化问题。通过引入多智能体协作，它有效地提高了LLMs在保持语义和逻辑完整性前提下简化复杂句子的能力，并在特定应用领域（视频游戏设计）展现出显著的性能提升，这对于需要清晰表达的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决如何利用大型语言模型将复杂句子转化为逻辑、简化的句子序列，同时保持语义和逻辑完整性的挑战。

**Method:** 提出了一种混合方法，该方法结合了高级提示（advanced prompting）和多智能体架构（multi-agent architectures）来增强句子简化过程。

**Result:** 实验结果表明，所提出的方法能够成功简化70%的为视频游戏设计应用编写的复杂句子。相比之下，单智能体方法在同一任务上的成功率为48%。

**Conclusion:** 结合高级提示和多智能体架构的混合方法在句子简化方面表现出显著优于单智能体方法的性能，证明了其在处理复杂语言任务方面的有效性。

> **ai_Abstract:** 本文提出了一种利用大型语言模型进行句子简化的混合方法。该方法结合了高级提示与多智能体架构，旨在将复杂句子转化为语义和逻辑一致的简化序列。实验证明，该混合方法在视频游戏设计应用中实现了70%的成功率，显著优于传统的单智能体方法（48%）。

> **摘要翻译:** 本文解决了在大型语言模型的帮助下，将复杂句子转换为逻辑、简化的句子序列，同时保持语义和逻辑完整性的挑战。我们提出了一种结合了高级提示和多智能体架构的混合方法，以增强句子简化过程。实验结果表明，我们的方法能够成功简化70%为视频游戏设计应用编写的复杂句子。相比之下，单智能体方法在同一任务上的成功率为48%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [548] [Configurable Preference Tuning with Rubric-Guided Synthetic Data](https://arxiv.org/abs/2506.11702)
> *可配置的偏好调优与基于评分标准的合成数据*

*Víctor Gallego* | **Main category: cs.CL**

**Keywords:** 偏好调优, 合成数据, 语言模型, AI对齐, 评分标准

**Comment:** Accepted to ICML 2025 Workshop on Models of Human Feedback for AI
  Alignment

> **TL;DR:** 本文提出了可配置偏好调优（CPT）框架，允许语言模型根据人类可解释的指令动态调整其行为，通过使用基于结构化评分标准的合成偏好数据进行微调实现。

**AI_Comments:** 这项研究的创新之处在于它挑战了现有偏好模型中单一静态偏好的假设，并引入了一种通过评分标准引导的合成数据实现动态偏好调整的新颖方法。这种方法为语言模型提供了前所未有的细粒度控制，使其能够根据具体指令调整输出，这对于构建更灵活、更符合上下文的AI系统具有重要意义。通过合成数据而非真实人类反馈来训练模型，也可能大大降低数据收集成本和复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI对齐人类反馈模型（如DPO）通常采用单一、静态的偏好设置，限制了模型的适应性。

**Method:** 本文引入了可配置偏好调优（CPT）框架。CPT利用基于定义期望属性的结构化、细粒度评分标准的系统提示来生成合成偏好数据。通过使用这些评分标准引导的偏好数据进行微调，大型语言模型（LLM）能够在推理时根据系统提示调整其输出，而无需重新训练。

**Result:** CPT方法不仅提供了细粒度的控制，而且为建模更细致和上下文相关的用户反馈提供了一种机制。相关的实验代码、生成的数据集和微调模型已发布。

**Conclusion:** 可配置偏好调优（CPT）提供了一种新颖的框架，使语言模型能够根据明确、人类可解释的指令动态调整其行为，从而实现对模型输出的细粒度控制，并更好地模拟细致入微的上下文相关的人类反馈。

> **ai_Abstract:** 本文提出了一种名为可配置偏好调优（CPT）的新框架，旨在解决现有AI对齐模型中偏好设置单一且静态的问题。CPT通过利用基于结构化、细粒度评分标准生成的合成偏好数据来微调语言模型。这使得大型语言模型能够在推理时根据系统提示动态调整其输出，无需重新训练，从而实现对行为的细粒度控制，并更好地模拟细致入微的人类反馈。

> **摘要翻译:** 用于AI对齐的人类反馈模型，例如支持直接偏好优化（DPO）的模型，通常固化了单一、静态的偏好设置，从而限制了适应性。本文通过引入可配置偏好调优（CPT）来挑战单一偏好的假设，CPT是一个新颖的框架，旨在赋予语言模型根据明确的、人类可解释的指令动态调整其行为的能力。CPT利用合成生成的偏好数据，这些数据以源自结构化、细粒度评分标准（定义了如写作风格等所需属性）的系统提示为条件。通过使用这些评分标准引导的偏好进行微调，大型语言模型（LLM）学习在推理时响应系统提示来调节其输出，而无需重新训练。这种方法不仅提供了细粒度的控制，还为建模更细致和上下文相关的人类反馈提供了一种机制。多个实验性产物，例如训练代码、生成的数据集和微调模型已在https://github.com/vicgalle/configurable-preference-tuning发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [550] [The Cambrian Explosion of Mixed-Precision Matrix Multiplication for Quantized Deep Learning Inference](https://arxiv.org/abs/2506.11728)
> *量化深度学习推理中混合精度矩阵乘法的寒武纪大爆发*

*Héctor Martínez, Adrián Castelló, Francisco D. Igual, Enrique S. Quintana-Ortí* | **Main category: cs.CL**

**Keywords:** 混合精度, 矩阵乘法, 深度学习推理, 量化, GEMM

**Comment:** 16 pages, 7 tables, 7 figures

> **TL;DR:** 随着硬件转向混合精度整数运算以加速深度学习推理，本文提出并展示了新的微内核设计和数据布局，以优化GEMM在现代CPU架构上的性能，取代了传统的浮点实现。

**AI_Comments:** 这篇论文通过提出适应混合精度整数运算的GEMM优化策略，解决了深度学习推理在现代异构硬件上遇到的性能瓶颈。其创新之处在于针对量化推理优化硬件的特点，设计了新的微内核和数据布局，而非沿用旧的浮点优化范式。这对于边缘设备等资源受限环境的深度学习部署具有重要意义，预示着未来矩阵乘法优化将更多地围绕低精度和混合精度运算展开。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习计算正从高精度浮点转向低精度格式和混合精度运算，以提高吞吐量、减少内存和能耗，特别是在资源受限的边缘设备上。现有硬件已适应这一趋势，但传统的GEMM优化方法已不再适用，需要新的策略来充分利用为量化推理优化的混合精度点积运算。

**Method:** 论文重新审视了传统的高性能GEMM，并描述了将其适应于现代ISA（包括x86_64、ARM和RISC-V）上的混合精度整数（MIP）算术的策略。具体来说，提出了新颖的微内核设计和数据布局，以更好地利用当今的专用硬件。

**Result:** 研究结果表明，与浮点实现相比，在三种代表性CPU架构上，混合精度整数（MIP）算术在性能上取得了显著提升。

**Conclusion:** 本文的贡献突显了GEMM优化进入了一个新时代，由异构架构上深度学习推理的需求驱动，标志着矩阵乘法的“寒武纪时期”的到来。

> **ai_Abstract:** 本文探讨了深度学习中从高精度浮点计算向混合精度整数计算的转变，以提高性能和效率。针对硬件发展对传统GEMM优化方法的淘汰，作者提出了新的微内核设计和数据布局，将GEMM适应于现代CPU架构上的混合精度整数运算。实验结果表明，这种方法在多种CPU架构上显著优于传统的浮点实现，标志着矩阵乘法优化进入了一个新阶段。

> **摘要翻译:** 深度学习（DL）的最新进展导致计算从传统的64位浮点（FP64）转向降精度格式，如FP16、BF16以及8位或16位整数，并结合混合精度算术。这种转变提高了计算吞吐量，减少了内存和带宽使用，并提高了能源效率，为资源受限的边缘设备提供了显著优势。为了支持这一转变，硬件架构也相应发展，现在包括适应性的ISA（指令集架构），这些ISA暴露了专为DL工作负载定制的混合精度向量单元和矩阵引擎。许多DL和科学计算任务的核心是通用矩阵-矩阵乘法GEMM，这是一个历史上使用SIMD（单指令，多数据）单元上的axpy向量指令进行优化的基本内核。然而，随着硬件转向为量化推理优化的混合精度点积中心操作，这些传统方法正在被淘汰。为了应对这一挑战，我们的论文重新审视了传统的高性能GEMM，并描述了在现代ISA（包括x86_64、ARM和RISC-V）上将其适应于混合精度整数（MIP）算术的策略。具体来说，我们展示了新颖的微内核设计和数据布局，它们能更好地利用当今的专用硬件，并证明了MIP算术在三种代表性CPU架构上比浮点实现取得了显著的性能提升。这些贡献突显了GEMM优化进入了一个新时代——由异构架构上DL推理的需求驱动，标志着我们称之为矩阵乘法“寒武纪时期”的到来。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [552] [DART: Distilling Autoregressive Reasoning to Silent Thought](https://arxiv.org/abs/2506.11752)
> *DART：将自回归推理蒸馏为无声思维*

*Nan Jiang, Ziming Wu, De-Chuan Zhan, Fuming Lai, Shaobing Lian* | **Main category: cs.CL**

**Keywords:** 思维链, 大语言模型, 蒸馏, 效率, 推理

**Comment:** 

> **TL;DR:** DART是一种自蒸馏框架，通过用非自回归的无声思维（ST）取代自回归的思维链（CoT），显著提高了大语言模型推理的效率，同时保持了相似的性能。

**AI_Comments:** DART的创新之处在于其自蒸馏框架，通过用非自回归的无声思维取代传统的自回归思维链，有效解决了大语言模型推理的计算开销问题。这种方法在保持性能的同时显著提高了效率，对于LLMs在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 思维链（CoT）推理虽然显著提升了大语言模型（LLMs）在复杂任务上的表现，但其自回归范式导致巨大的计算开销，限制了其在延迟敏感型应用中的部署。

**Method:** 本文提出了DART（将自回归推理蒸馏为无声思维），一个自蒸馏框架，使LLMs能够用非自回归的无声思维（ST）取代自回归的CoT。DART引入了两个训练路径：用于传统推理的CoT路径和用于直接从少量ST标记生成答案的ST路径。ST路径利用一个轻量级的推理演化模块（REM）来使其隐藏状态与CoT路径对齐，使ST标记能够演化为信息丰富的嵌入。在推理过程中，只激活ST路径，利用演化的ST标记直接给出答案。

**Result:** DART在推理性能上与现有基线相当，同时提供了显著的效率提升。

**Conclusion:** DART作为一种有效的推理替代方案，具有可行性。

> **ai_Abstract:** DART是一个旨在解决思维链（CoT）推理计算开销问题的自蒸馏框架。它通过引入无声思维（ST）路径，在训练阶段利用CoT路径进行知识蒸馏，使模型能直接从少量ST标记生成答案。推理时仅激活ST路径，从而在保持与CoT相当的推理性能的同时，显著提高效率，为延迟敏感型应用提供了可行方案。

> **摘要翻译:** 思维链（CoT）推理显著推动了大型语言模型（LLMs）在解决复杂任务方面的进展。然而，其自回归范式导致显著的计算开销，阻碍了其在延迟敏感型应用中的部署。为了解决这个问题，我们提出了DART（将自回归推理蒸馏为无声思维），一个自蒸馏框架，使LLMs能够用非自回归的无声思维（ST）取代自回归的CoT。具体来说，DART引入了两个训练路径：用于传统推理的CoT路径和用于直接从少量ST标记生成答案的ST路径。ST路径利用一个轻量级的推理演化模块（REM）来使其隐藏状态与CoT路径对齐，使ST标记能够演化为信息丰富的嵌入。在推理过程中，只激活ST路径，利用演化的ST标记直接给出答案。广泛的实验结果表明，DART在实现与现有基线相当的推理性能的同时，提供了显著的效率提升，可作为高效推理的可行替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [556] [Long-Short Alignment for Effective Long-Context Modeling in LLMs](https://arxiv.org/abs/2506.11769)
> *长短对齐：LLMs中有效长上下文建模的关键*

*Tianqi Du, Haotian Huang, Yifei Wang, Yisen Wang* | **Main category: cs.CL**

**Keywords:** 长上下文建模, LLMs, 长度泛化, 长短对齐, 输出分布

**Comment:** ICML 2025

> **TL;DR:** 大型语言模型（LLMs）在处理长上下文时面临长度泛化问题。本文提出“长短对齐”的新视角，即不同长度序列输出分布的一致性，并开发了一种正则化项来促进训练中的对齐，有效提升了长上下文建模能力。

**AI_Comments:** 该论文的创新点在于将长度泛化的研究重点从输入侧（如位置编码）转移到输出侧的分布一致性，即“长短对齐”。通过引入可量化的“长短不一致性”度量和相应的正则化项，提供了一个新颖且实用的方法来解决LLMs的长上下文问题，为模型设计和训练提供了新的方向，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的有效性受限于Transformer架构的固定上下文窗口，这给长上下文建模带来了挑战。其中，长度泛化——即模型泛化到比训练时更长序列的能力——是一个经典且根本的问题。

**Method:** 本研究提出了一个关于长度泛化的新视角，将重点从传统的输入特征（如位置编码或数据结构）转移到模型的输出分布。具体而言，通过对合成任务的案例研究，突出了“长短对齐”（即不同长度序列输出分布的一致性）的关键作用。将此见解扩展到自然语言任务，提出了一种名为“长短不一致性”的度量来量化这种现象，并揭示了该度量与长度泛化性能之间的强相关性。基于这些发现，开发了一个在训练期间促进长短对齐的正则化项。

**Result:** 广泛的实验验证了该方法的有效性，为实现LLMs中更有效的长上下文建模提供了新见解。

**Conclusion:** 本研究通过引入长短对齐的概念、量化方法和正则化项，有效提升了LLMs的长上下文建模能力，并为未来的研究提供了新的方向。

> **ai_Abstract:** 该论文旨在解决大型语言模型（LLMs）在长上下文建模中面临的长度泛化问题。作者提出了一种新颖的“长短对齐”视角，关注模型在不同长度序列上的输出分布一致性。他们通过合成任务案例研究验证了长短对齐的重要性，并为自然语言任务开发了“长短不一致性”度量。在此基础上，提出了一种正则化项以在训练中促进长短对齐。实验证明该方法有效，为提升LLMs的长上下文建模能力提供了新思路。

> **摘要翻译:** 大型语言模型（LLMs）展现出令人印象深刻的性能和惊人的涌现特性。然而，它们的有效性仍受限于Transformer架构的固定上下文窗口，这给长上下文建模带来了挑战。在这些挑战中，长度泛化——即泛化到比训练时更长序列的能力——是一个经典且根本的问题。在这项工作中，我们提出了一个关于长度泛化的新视角，将重点从传统的对输入特征（如位置编码或数据结构）的强调转移到模型的输出分布。具体而言，通过对合成任务的案例研究，我们强调了“长短对齐”（即不同长度序列输出分布的一致性）的关键作用。将这一见解扩展到自然语言任务，我们提出了一种名为“长短不一致性”的度量来量化这种现象，揭示了该度量与长度泛化性能之间的强相关性。基于这些发现，我们开发了一个在训练期间促进长短对齐的正则化项。广泛的实验验证了我们方法的有效性，为实现LLMs中更有效的长上下文建模提供了新见解。代码可在https://github.com/PKU-ML/LongShortAlignment获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [559] [Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models](https://arxiv.org/abs/2506.11798)
> *基于大语言模型的人格驱动的欧洲议会投票行为模拟*

*Maximilian Kreutner, Marlene Lutz, Markus Strohmaier* | **Main category: cs.CL**

**Keywords:** 大语言模型, 投票行为模拟, 欧洲议会, 人格提示, 零样本学习

**Comment:** 

> **TL;DR:** 本研究利用大语言模型和零样本人格提示来模拟欧洲议会议员的投票行为，并取得了约0.793的加权F1分数。

**AI_Comments:** 这项工作创新性地将大语言模型的人格提示技术应用于政治行为模拟，特别是在投票预测方面，为理解和预测政治动态提供了一个新颖且有效的方法。它克服了LLM固有偏见的问题，并通过量化指标验证了其有效性，具有重要的研究价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在理解和生成政治话语方面表现出色，但普遍存在左倾偏见。同时，人格或身份提示已被证明可以使LLM的行为与基础模型不一致的社会经济群体保持一致。因此，本研究旨在分析零样本人格提示是否能准确预测个人投票决策和欧洲团体立场。

**Method:** 本研究使用有限信息的零样本人格提示来预测欧洲议会议员的个人投票决策和欧洲团体的政策立场。研究评估了预测结果对反事实论点、不同人格提示和生成方法的稳定性。

**Result:** 研究发现，可以合理地模拟欧洲议会议员的投票行为，加权F1分数约为0.793。

**Conclusion:** 通过人格驱动的模拟，大语言模型能够较好地预测和模拟欧洲议会议员的投票行为。

> **ai_Abstract:** 本研究探讨了如何利用大语言模型（LLMs）结合零样本人格提示来模拟欧洲议会议员的投票行为。鉴于LLMs固有的政治偏见，研究利用人格提示来调整模型行为，使其与特定社会经济群体保持一致。通过评估，发现这种方法能有效地预测个体投票决策及聚合后的团体立场，并达到了约0.793的加权F1分数，证明了其在政治行为模拟方面的潜力。

> **摘要翻译:** 大语言模型（LLMs）在理解甚至生成政治话语方面展现出卓越的能力，但被发现持续表现出渐进的左倾偏见。与此同时，所谓的角色或身份提示已被证明可以使LLM行为与基础模型不一致的社会经济群体保持一致。在这项工作中，我们分析了使用有限信息的零样本角色提示是否能准确预测个体投票决策，并通过聚合，准确预测欧洲团体在不同政策上的立场。我们评估了预测结果对反事实论点、不同角色提示和生成方法的稳定性。最后，我们发现我们可以合理地模拟欧洲议会议员的投票行为，加权F1分数约为0.793。我们关于2024年欧洲议会政治家的人格数据集和代码可在https://github.com/dess-mannheim/european_parliament_simulation 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [562] [Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?](https://arxiv.org/abs/2506.11807)
> *多模态大型语言模型在简单指代消解任务中是否具备语用能力？*

*Simeon Junker, Manar Ali, Larissa Koch, Sina Zarrieß, Hendrik Buschmeier* | **Main category: cs.CL**

**Keywords:** 多模态大型语言模型, 指代消解, 语用能力, 颜色描述, 上下文解释

**Comment:** To appear in ACL Findings 2025

> **TL;DR:** 研究发现，即使在涉及颜色描述的简单指代消解任务中，多模态大型语言模型（MLLMs）在基本的语用能力方面仍面临重大挑战。

**AI_Comments:** 这项研究通过使用看似简单但实际能有效揭示语用能力的任务，提供了一个新颖的视角来评估多模态大型语言模型。其重要性在于揭示了即使是先进的MLLMs在基本的语用推理方面仍存在缺陷，这对于未来MLLM的发展方向具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究多模态大型语言模型（MLLMs）在指代消解任务中的语言能力，特别关注其语用能力，尽管任务对于人类而言简单，但被认为是探测MLLM语用能力的关键。

**Method:** 研究通过让多模态大型语言模型参与涉及简单但抽象视觉刺激（如色块和颜色网格）的指代消解任务来进行调查。

**Result:** 研究结果和分析表明，对于最先进的多模态大型语言模型而言，基本的语用能力（如颜色描述的上下文依赖性解释）仍然构成主要挑战。

**Conclusion:** 多模态大型语言模型在处理简单的指代消解任务时，其基本的语用能力，特别是上下文依赖的解释能力，仍有待提高。

> **ai_Abstract:** 本文探讨了多模态大型语言模型在简单指代消解任务中的语用能力，这些任务使用抽象的视觉刺激如色块。研究发现，尽管任务看似简单，但MLLMs在处理上下文依赖的颜色描述等基本语用能力方面仍面临显著挑战，表明当前MLLMs在语用理解上存在局限性。

> **摘要翻译:** 我们研究了多模态大型语言模型在涉及简单但抽象视觉刺激（如色块和颜色网格）的指代消解任务中的语言能力。尽管这项任务对于今天的语言模型来说可能看起来不具挑战性，对于人类双向对话来说也很直接，但我们认为它是探测多模态大型语言模型语用能力的一个高度相关的探针。我们的结果和分析确实表明，基本的语用能力，例如颜色描述的上下文依赖性解释，仍然对最先进的多模态大型语言模型构成重大挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [565] [Post Persona Alignment for Multi-Session Dialogue Generation](https://arxiv.org/abs/2506.11857)
> *多轮对话生成中的后置角色对齐*

*Yi-Pei Chen, Noriki Nishida, Hideki Nakayama, Yuji Matsumoto* | **Main category: cs.CL**

**Keywords:** 多轮对话生成, 角色对齐, 大型语言模型, 对话一致性, 对话多样性

**Comment:** 

> **TL;DR:** PPA是一种新的两阶段框架，通过先生成通用回复再进行角色对齐，解决了多轮对话中角色一致性、多样性和个性化的问题，并显著优于现有方法。

**AI_Comments:** PPA的创新之处在于其“后置对齐”策略，颠覆了传统的“先检索再生成”模式，有效解决了多轮对话中角色信息提前引入可能导致的多样性受限问题。这种方法为长期个性化对话生成提供了一个有前景的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 多轮基于角色的对话生成在维持长期一致性和生成多样化、个性化响应方面面临挑战。现有方法在生成响应前检索角色信息，这会限制多样性并导致通用输出。

**Method:** 提出后置角色对齐（PPA）框架，这是一个两阶段过程：首先仅基于对话上下文生成一个通用响应；然后使用该响应作为查询检索相关的角色记忆；最后细化响应以与说话者的角色对齐。

**Result:** 在多轮LLM生成的对话数据上的实验表明，PPA在一致性、多样性和角色相关性方面显著优于现有方法。

**Conclusion:** PPA为长期个性化对话生成提供了一种更灵活、更有效的范式。

> **ai_Abstract:** 本文提出了一种名为后置角色对齐（PPA）的新型两阶段框架，旨在解决多轮对话生成中角色一致性、多样性和个性化响应的挑战。PPA通过先生成通用响应，再基于该响应检索并对齐角色信息，从而促进对话的自然性和多样性，同时保持一致性。实验证明，PPA在多轮对话中显著优于现有方法，提升了对话的一致性、多样性和角色相关性。

> **摘要翻译:** 多轮基于角色的对话生成在维持长期一致性和生成多样化、个性化响应方面面临挑战。虽然大型语言模型（LLMs）在单轮对话中表现出色，但它们在跨扩展交互中难以保持角色忠实度和对话连贯性。现有方法通常在响应生成前检索角色信息，这会限制多样性并导致通用输出。我们提出了后置角色对齐（PPA），这是一种新颖的两阶段框架，它颠倒了这一过程。PPA首先仅基于对话上下文生成一个通用响应，然后使用该响应作为查询检索相关的角色记忆，最后细化响应以与说话者的角色对齐。这种后置对齐策略在保持一致性和个性化的同时，促进了自然性和多样性。在多轮LLM生成的对话数据上的实验表明，PPA在一致性、多样性和角色相关性方面显著优于现有方法，为长期个性化对话生成提供了一种更灵活、更有效的范式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [566] [Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache](https://arxiv.org/abs/2506.11886)
> *超越同质注意力：通过傅里叶近似KV缓存实现内存高效的LLM*

*Xiaoran Liu, Siyang He, Qiqi Wang, Ruixiao Li, Yuerong Song, Zhigeng Liu, Linlin Li, Qun Liu, Zengfeng Huang, Qipeng Guo, Ziwei He, Xipeng Qiu* | **Main category: cs.CL**

**Keywords:** FourierAttention, KV缓存, LLM, 内存效率, 长上下文

**Comment:** 10 pages, 7 figures, work in progress

> **TL;DR:** FourierAttention通过傅里叶近似KV缓存，利用Transformer头维度异质性，实现内存高效的LLM，且无需训练，在长上下文准确性上表现最佳。

**AI_Comments:** 该论文的创新点在于利用Transformer头部维度的异质性来优化KV缓存，并巧妙地引入傅里叶近似进行压缩，这种方法无需额外训练，显著降低了实现成本和复杂性。它在保持甚至提升长上下文准确性的同时，有效解决了LLM的内存效率问题，并通过自定义Triton内核进一步优化了实际部署性能，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）随着上下文长度的增加，其键值（KV）缓存的内存需求也随之增长，这导致了内存瓶颈。现有压缩方法通常会使头部维度同质化或依赖注意力引导的令牌剪枝，这往往会牺牲准确性或引入计算开销。

**Method:** 本文提出了FourierAttention，一个无需训练的框架，它利用了Transformer头部维度的异质性（较低维度优先处理局部上下文，较高维度捕获长距离依赖）。通过将对长上下文不敏感的维度投影到正交傅里叶基上，FourierAttention用固定长度的频谱系数来近似它们的时间演变。此外，还设计了一个自定义的Triton内核FlashFourierAttention，通过简化读写操作来优化内存，从而实现高效部署而不影响性能。

**Result:** 在LLaMA模型上的评估表明，FourierAttention在LongBench和Needle-In-A-Haystack (NIAH)基准测试中，实现了最佳的长上下文准确性。

**Conclusion:** FourierAttention提供了一种无需训练、内存高效且不牺牲性能的解决方案，有效应对LLM在长上下文处理中的内存挑战，并在长上下文准确性方面表现优异。

> **ai_Abstract:** FourierAttention通过利用Transformer头部维度的异质性（低维度关注局部，高维度关注长距离），并采用傅里叶近似将对长上下文不敏感的维度投影到正交傅里叶基上，以固定长度的频谱系数近似其时间演变，从而解决了LLM在长上下文处理中KV缓存的内存瓶颈。作为一个无需训练的框架，它还结合了自定义的Triton内核FlashFourierAttention以优化内存操作。评估结果显示，FourierAttention在LLaMA模型上，于LongBench和NIAH基准测试中实现了最佳的长上下文准确性，同时保证了高效部署且不牺牲性能。

> **摘要翻译:** 大型语言模型（LLM）随着上下文长度的增加，其键值（KV）缓存的内存需求也随之增长，这导致了内存瓶颈。现有压缩方法通常会使头部维度同质化或依赖注意力引导的令牌剪枝，这往往会牺牲准确性或引入计算开销。我们提出了FourierAttention，一个无需训练的框架，它利用了Transformer头部维度的异质性：较低维度优先处理局部上下文，而较高维度捕获长距离依赖。通过将对长上下文不敏感的维度投影到正交傅里叶基上，FourierAttention用固定长度的频谱系数来近似它们的时间演变。对LLaMA模型的评估表明，FourierAttention在LongBench和Needle-In-A-Haystack (NIAH)上实现了最佳的长上下文准确性。此外，我们还设计了一个自定义的Triton内核FlashFourierAttention，通过简化读写操作来优化内存，从而实现高效部署而不影响性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [569] [GeistBERT: Breathing Life into German NLP](https://arxiv.org/abs/2506.11903)
> *GeistBERT：为德语自然语言处理注入活力*

*Raphael Scheible-Schmitt, Johann Frei* | **Main category: cs.CL**

**Keywords:** GeistBERT, 德语NLP, 预训练语言模型, Transformer, 最先进

**Comment:** 

> **TL;DR:** GeistBERT 是一个针对德语优化的新型预训练语言模型，通过在多样化语料库上增量训练并结合现代架构，在多项德语NLP任务中取得了最先进的性能。

**AI_Comments:** GeistBERT的创新之处在于其针对德语的精细化预训练策略，特别是在多样化语料库上的增量训练和对GottBERT权重的利用。其重要性体现在它在多项德语NLP任务中达到了新的SOTA，并证明了基础模型在特定任务上超越大型模型的潜力。该项目通过开源模型，对德语NLP社区做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进德语自然语言处理（NLP），因为德语NLP可以从更新的架构和针对其语言特性定制的现代数据集中受益。

**Method:** GeistBERT 使用fairseq以标准超参数从GottBERT权重初始化，并在大型德语语料库上使用全词掩蔽（WWM）进行增量训练。基于此预训练模型，还派生了支持长达8k令牌序列的Nyströmformer和Longformer扩展输入变体。模型在NER（CoNLL 2003, GermEval 2014）和文本分类（GermEval 2018 fine/coarse, 10kGNAD）任务上使用F1分数和准确率进行评估。

**Result:** GeistBERT模型表现出色，在所有任务中均领先于基础模型，并创造了新的最先进（SOTA）性能。值得注意的是，基础模型在多项任务中甚至超越了更大的模型。

**Conclusion:** GeistBERT模型在德语NLP任务中实现了强大的性能，建立了新的最先进水平，并且该模型已以MIT许可发布，以支持德语NLP研究社区。

> **ai_Abstract:** GeistBERT是一个针对德语优化的新型Transformer语言模型。它通过在多样化的大规模德语语料库上进行增量训练，并从GottBERT初始化，显著提升了德语NLP的性能。该模型在多种NER和文本分类任务中取得了领先的基础模型性能和新的最先进成果，甚至超越了更大的模型。此外，项目还发布了支持长序列的变体，并以MIT许可开源，以促进德语NLP社区的发展。

> **摘要翻译:** 基于Transformer的语言模型的进步突显了在高质量语料库上进行特定语言预训练的优势。在此背景下，德语自然语言处理（NLP）有望从更新的架构和针对德语语言特征定制的现代数据集中获益。GeistBERT旨在通过在多样化语料库上进行增量训练并优化各种NLP任务中的模型性能来改进德语语言处理。它使用fairseq以标准超参数进行预训练，从GottBERT权重初始化，并在一个大型德语语料库上使用全词掩蔽（WWM）进行训练。基于该预训练模型，我们使用Nyströmformer和Longformer架构派生了扩展输入变体，支持长达8k令牌的序列。虽然这些长上下文模型未在专门的长上下文基准上进行评估，但它们已包含在我们的发布中。我们使用F1分数和准确率在NER（CoNLL 2003，GermEval 2014）和文本分类（GermEval 2018 fine/coarse，10kGNAD）上评估了所有模型。GeistBERT模型取得了强大的性能，在基础模型中领先所有任务并创造了新的最先进（SOTA）水平。值得注意的是，基础模型在多项任务中超越了更大的模型。为了支持德语NLP研究社区，我们以MIT许可发布GeistBERT。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [572] [Effectiveness of Counter-Speech against Abusive Content: A Multidimensional Annotation and Classification Study](https://arxiv.org/abs/2506.11919)
> *反击言论对抗辱骂内容的有效性：一项多维度标注与分类研究*

*Greta Damo, Elena Cabrio, Serena Villata* | **Main category: cs.CL**

**Keywords:** 反击言论, 仇恨言论, 有效性分类, 多维度标注, 计算框架

**Comment:** 

> **TL;DR:** 本文提出了一个基于社会科学概念的反击言论有效性计算框架，定义了六个核心维度，并利用这些维度标注了4,214个反击言论实例，创建了一个新的语言资源。研究还提出了两种分类策略，在专家和用户撰写的反击言论上均取得了SOTA结果（平均F1分数分别为0.94和0.96），并揭示了维度间的强相互依赖性。

**AI_Comments:** 这项研究通过引入多维度标注和分类框架，为评估反击言论有效性提供了量化方法，弥补了现有研究中评估标准模糊的不足。其创建的新语言资源和高性能的分类模型，对在线仇恨言论的缓解和相关研究具有重要意义。多维度间的相互依赖性发现也为未来更深入的研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 评估反击言论（Counter-speech）有效性的标准尚不明确，这是一个开放的挑战。

**Method:** 本文提出了一个基于社会科学概念的反击言论有效性计算框架，该框架定义了清晰度、证据、情感诉求、反驳、受众适应性和公平性六个核心维度。研究人员使用这些维度标注了来自两个基准数据集的4,214个反击言论实例，并发布了一个新的语言资源。此外，论文还提出了多任务（multi-task）和基于依赖（dependency-based）的两种分类策略来评估反击言论的有效性。

**Result:** 提出的两种分类策略（多任务和基于依赖）在专家和用户撰写的反击言论上分别取得了0.94和0.96的平均F1分数，性能优于标准基线。研究还揭示了所定义维度之间存在很强的相互依赖性，并创建了一个新的语言资源。

**Conclusion:** 本文提出的计算框架和分类策略能够有效评估反击言论的有效性，并揭示了其多维度特征间的相互作用，为在线仇恨言论的缓解提供了新的工具和见解。

> **ai_Abstract:** 本文旨在解决在线反击言论有效性评估标准不明确的问题，提出了一个新颖的、基于社会科学概念的计算框架。该框架定义了清晰度、证据、情感诉求、反驳、受众适应性和公平性六个核心维度，并利用这些维度对4,214个反击言论实例进行了大规模标注，构建了一个新的语言资源。研究进一步提出了多任务和基于依赖的两种分类策略，在反击言论有效性分类任务上取得了显著优于基线的结果（平均F1分数分别为0.94和0.96），并揭示了各维度间的强相互依赖性。

> **摘要翻译:** 反击言论（CS）是减轻网络仇恨言论（HS）的关键策略，然而，定义评估其有效性的标准仍然是一个悬而未决的挑战。我们提出了一个新颖的计算框架，用于反击言论有效性分类，该框架以社会科学概念为基础。我们的框架定义了六个核心维度——清晰度、证据、情感诉求、反驳、受众适应性和公平性——我们用这些维度标注了来自两个基准数据集的4,214个反击言论实例，从而为社区发布了一个新的语言资源。此外，我们提出了两种分类策略，即多任务和基于依赖的策略，在专家和用户撰写的反击言论上均取得了优异的结果（平均F1分数分别为0.94和0.96），优于标准基线，并揭示了维度之间存在很强的相互依赖性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [574] [Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback](https://arxiv.org/abs/2506.11930)
> *反馈摩擦：大型语言模型难以完全吸收外部反馈*

*Dongwei Jiang, Alvin Zhang, Andrew Wang, Nicholas Andrews, Daniel Khashabi* | **Main category: cs.CL**

**Keywords:** LLMs, 反馈, 自我改进, 反馈摩擦, 推理

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）即使在理想条件下也难以完全吸收外部反馈，这种现象被称为“反馈摩擦”。

**AI_Comments:** 这篇论文揭示了LLMs在自我纠正能力方面的一个关键限制，即使在提供高质量反馈的情况下也是如此。“反馈摩擦”这一概念的提出，为观察到的这一现象提供了一个具体术语，具有重要价值。系统性的实验设置以及对潜在原因的探索是本研究的优点。研究结果表明，仅仅提供反馈可能不足以实现LLM的稳健改进，这暗示了模型在处理和整合新信息或纠正内部表征方面存在更深层次的问题。这对于开发更可靠、更具自我改进能力的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LLMs在获得外部反馈时表现出一定的改进能力，但目前尚不清楚这些模型能多有效地、多彻底地吸收外部反馈，尤其是在它们应完全纠正错误的理想情境下。

**Method:** 研究人员设计了一个受控的实验环境，系统地调查了LLMs吸收反馈的能力。实验中，一个求解器模型首先尝试解决问题，然后一个拥有近乎完整真实答案的反馈生成器提供有针对性的反馈，之后求解器再次尝试。该流程在多种任务上进行了评估，包括数学推理、知识推理、科学推理和通用多领域评估，并使用了包括Claude 3.7在内的最先进语言模型。此外，还尝试了基于采样的缓解策略（如渐进式温度升高和明确拒绝错误答案），并探索了“反馈摩擦”的潜在原因。

**Result:** 令人惊讶的是，即使在近乎理想的条件下，求解器模型也始终表现出对反馈的抵制，这种限制被称为“反馈摩擦”。基于采样的缓解策略虽然带来了改进，但未能帮助模型达到目标性能。研究还排除了模型过度自信和数据熟悉度等因素作为“反馈摩擦”的原因。

**Conclusion:** LLMs存在一个显著的限制，即“反馈摩擦”，它们难以完全吸收外部反馈。突出这一问题并排除一些明显的原因，旨在指导未来在LLM自我改进方面的研究。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）在理想条件下吸收外部反馈的有效性。通过一个受控实验，研究发现即使给予近乎完美的反馈，LLMs也普遍存在一种“反馈摩擦”现象，即它们难以完全整合反馈。实验评估了包括数学、知识和科学推理在内的多种任务，并使用了最先进的LLMs。尽管尝试了基于采样的缓解策略，性能仍未达到目标。研究还排除了模型过度自信和数据熟悉度等潜在原因，旨在为LLM的自我改进研究提供方向。

> **摘要翻译:** 最近的研究表明，大型语言模型（LLMs）在获得外部反馈时，具备一定程度改进其回应的能力。然而，目前尚不清楚这些模型能多有效地、多彻底地吸收外部反馈。在一个理想的场景中，如果LLMs收到近乎完美且完整的反馈，我们期望它们能完全整合反馈，并将错误的答案改为正确的。在本文中，我们通过设计一个受控的实验环境，系统地研究了LLMs吸收反馈的能力。对于每个问题，一个求解器模型尝试给出解决方案，然后一个能够访问近乎完整真实答案的反馈生成器会产生有针对性的反馈，之后求解器再次尝试。我们通过各种任务，包括数学推理、知识推理、科学推理和通用多领域评估，使用包括Claude 3.7（有无扩展思考）在内的最先进语言模型，评估了这一流程。令人惊讶的是，即使在这些近乎理想的条件下，求解器模型也始终表现出对反馈的抵制，我们将这种限制称为“反馈摩擦”（FEEDBACK FRICTION）。为了减轻这种限制，我们尝试了基于采样的策略，如渐进式温度升高和明确拒绝先前尝试的错误答案，这些策略虽然带来了改进，但仍未能帮助模型达到目标性能。我们还对“反馈摩擦”的潜在原因进行了严格探索，排除了模型过度自信和数据熟悉度等因素。我们希望突出LLMs的这一问题并排除一些明显的原因，能有助于未来在自我改进方面的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [577] [Improving Large Language Model Safety with Contrastive Representation Learning](https://arxiv.org/abs/2506.11938)
> *使用对比表示学习提升大型语言模型安全性*

*Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 对抗性攻击, 对比表示学习, 模型安全, 表示工程

**Comment:** 

> **TL;DR:** 本文提出了一种基于对比表示学习的防御框架，通过微调模型以区分良性与有害表示，有效提升了大型语言模型对抗对抗性攻击的鲁棒性，且不影响标准性能。

**AI_Comments:** 该论文的创新点在于将LLM的安全性防御问题转化为对比表示学习任务，并通过引入三元组损失和对抗性硬负样本挖掘来增强模型区分安全与不安全表示的能力。这种方法提供了一种通用的防御机制，能够有效应对多种类型的对抗性攻击，且在不牺牲模型原有性能的前提下提升鲁棒性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）尽管功能强大，但其对多样化和不受控输入的响应能力使其容易受到对抗性攻击。现有防御方法难以泛化，而表示工程提供了有前景的替代方案。

**Method:** 本文提出了一种将模型防御视为对比表示学习（CRL）问题的防御框架。该方法使用基于三元组的损失结合对抗性硬负样本挖掘来微调模型，以促进良性表示和有害表示之间的分离。

**Result:** 实验结果表明，该方法优于先前的基于表示工程的防御方法，提高了模型对输入级和嵌入空间攻击的鲁棒性，同时不损害标准性能。

**Conclusion:** 通过将模型防御构建为对比表示学习问题，并采用三元组损失和对抗性硬负样本挖掘，可以有效提升大型语言模型的安全性，使其在面对多种对抗性攻击时表现出更强的鲁棒性，且不牺牲其正常性能。

> **ai_Abstract:** 本文提出了一种基于对比表示学习（CRL）的防御框架，旨在提高大型语言模型（LLMs）的安全性。该方法通过使用三元组损失和对抗性硬负样本挖掘来微调模型，以有效区分良性与有害表示。实验证明，该方法在对抗输入级和嵌入空间攻击方面，优于现有基于表示工程的防御方案，显著提升了模型鲁棒性，且不影响其正常性能。

> **摘要翻译:** 大型语言模型（LLMs）是功能强大的工具，具有深远的社会影响，但它们生成对多样化和不受控制的输入作出响应的能力使其容易受到对抗性攻击。虽然现有防御方法通常难以泛化到不同类型的攻击，但表示工程的最新进展提供了有前景的替代方案。在这项工作中，我们提出了一种防御框架，将模型防御表述为对比表示学习（CRL）问题。我们的方法使用基于三元组的损失结合对抗性硬负样本挖掘来微调模型，以鼓励良性表示和有害表示之间的分离。我们在多个模型上的实验结果表明，我们的方法优于先前的基于表示工程的防御方法，在不损害标准性能的情况下，提高了对输入级和嵌入空间攻击的鲁棒性。我们的代码可在 https://github.com/samuelsimko/crl-llm-defense 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [22] [String Matching with a Dynamic Pattern](https://arxiv.org/abs/2506.11318)
> *动态模式下的字符串匹配*

*Bruno Monteiro, Vinicius dos Santos* | **Main category: cs.DS**

**Keywords:** 字符串匹配, 动态模式, 后缀数组, 字符增删, 在线算法

**Comment:** 

> **TL;DR:** 提出了一种基于后缀数组的算法，用于解决动态模式下的字符串匹配问题，支持多种模式操作和在线文本，具有高效的时间复杂度。

**AI_Comments:** 这项工作在传统字符串匹配领域引入了动态模式的概念，具有较高的实用价值和创新性。利用后缀数组实现高效的动态模式匹配是其核心贡献，并且能够支持多种复杂的模式编辑操作以及在线文本处理，显示了其方案的鲁棒性和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统字符串匹配问题的一个变体，即当模式串P在静态文本T中发生字符增删等动态变化时，如何高效地计算其出现次数。

**Method:** 核心方法是使用后缀数组（Suffix Arrays）实现一个简单实用的算法。该算法支持对模式的字符添加和删除操作。此外，解决方案还可以扩展以支持子串删除、转置（将子串移动到模式的另一个位置）和复制（复制一个子串并将其粘贴到特定位置），并能进一步扩展到支持在线文本（在文本的一端添加字符）。

**Result:** 预处理时间为$\mathcal O(|T|)$。字符添加和删除的更新时间为$\mathcal O(\log |T|)$。扩展的子串操作（删除、转置、复制）也保持相同的时间复杂度。支持在线文本时，能保持相同的均摊时间界限。

**Conclusion:** 该研究成功开发了一种高效且实用的算法，能够处理动态模式下的字符串匹配问题，并支持多种复杂的模式和文本操作，具有良好的时间性能。

> **ai_Abstract:** 本文提出了一种针对动态模式字符串匹配问题的新算法。该算法利用后缀数组，在静态文本T和动态模式P的设定下，支持模式的字符增删操作，并能高效计算模式在文本中的出现次数。其在$\mathcal O(|T|)$预处理后，更新时间为$\mathcal O(\log |T|)$。此外，该方案还可扩展以支持子串的删除、转置和复制等复杂操作，以及在线文本的场景，均能保持高效的时间复杂度。

> **摘要翻译:** 在这项工作中，我们解决了字符串匹配问题的一个自然变体，即动态模式的情况。给定一个静态文本T和一个模式P，我们希望支持对模式的字符添加和删除操作，并在每次操作后计算其在文本中出现的次数。我们展示了一种使用后缀数组的简单实用算法，该算法在$\mathcal O(|T|)$的预处理时间后，实现了$\mathcal O(\log |T|)$的更新时间。我们展示了如何将我们的解决方案扩展到支持子串删除、转置（将子串移动到模式的另一个位置）和复制（复制一个子串并将其粘贴到特定位置），并保持相同的时间复杂度。我们的解决方案还可以扩展到支持在线文本（在文本的一端添加字符），并保持相同的均摊界限。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [50] [Isometric-Universal Graphs for Trees](https://arxiv.org/abs/2506.11704)
> *树的等距普适图*

*Edgar Baucher, François Dross, Cyril Gavoille* | **Main category: cs.DS**

**Keywords:** 等距普适图, 树, 森林, 算法, NP完全性

**Comment:** 

> **TL;DR:** 本文研究了两个树/森林的最小等距普适图问题，并提出了高效算法，证明对于两个树，该图本质上是树。但对于三个森林/树，该问题变为NP完全，且最小图不一定是树。

**AI_Comments:** 该论文为特定情况（两个树/森林）提供了高效的解决方案，同时通过证明NP完全性和结构差异，清晰地划定了其适用范围，突出了问题复杂度的跳跃。对于两个树，最小等距普适图本质上是一棵树的发现是一个优雅且重要的结果。

<details>
  <summary>Details</summary>

**Motivation:** 寻找包含两个输入树（或森林）且保持它们距离的最小图，即具有最少顶点数的等距普适图。

**Method:** 提出了在O(n^{5/2}log{n})时间内解决两个树的最小等距普适图问题的算法。将该结果扩展到森林，提出了O(n^{7/2}log{n})的算法。关键在于证明了两个树的最小等距普适图本质上是一棵树。

**Result:** 解决了两个树的最小等距普适图问题，时间复杂度为O(n^{5/2}log{n})。将结果扩展到森林，时间复杂度为O(n^{7/2}log{n})。证明了两个树的最小等距普适图本质上是一棵树。证明了决定是否存在一个具有t个顶点的三个森林的等距普适图是NP完全的。证明了对于某些三棵树的族，任何最小等距普适图都不能是一棵树。

**Conclusion:** 对于两个树或森林，可以高效地找到其最小等距普适图，且这些图通常是树。然而，这些结果无法扩展到三个森林或树，此时问题变为NP完全，且最小图可能不是树，这影响了贪婪策略。

> **ai_Abstract:** 本文研究了为给定两个树或森林寻找最小等距普适图的问题，旨在保持它们的距离。它提出了多项式时间复杂度的算法（两个树为O(n^{5/2}log{n})，两个森林为O(n^{7/2}log{n})），并指出对于两个树，最小的此类图本质上是一棵树。然而，论文也表明这些结果无法扩展到三个森林或树，证明了为三个森林寻找等距普适图是NP完全的，并且对于某些三棵树的族，最小图不是树，这对贪婪算法有影响。

> **摘要翻译:** 我们考虑寻找包含两个输入树的最小图的问题，每个树最多有n个顶点并保持它们的距离。换句话说，我们寻找具有最少顶点数的两个给定树的等距普适图。我们证明这个问题可以在O(n^{5/2}log{n})时间内解决。我们将此结果扩展到森林而不是树，并提出了一种运行时间为O(n^{7/2}log{n})的算法。作为一个关键要素，我们表明两个树的最小等距普适图本质上是一棵树。此外，我们证明这些结果无法扩展。首先，我们证明决定是否存在一个具有t个顶点的三个森林的等距普适图是NP完全的。其次，我们证明对于某些三棵树的族，任何最小等距普适图都不能是一棵树。后一个结果对解决最小等距普适图问题的贪婪策略具有影响。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [78] [Practical colinear chaining on sequences revisited](https://arxiv.org/abs/2506.11750)
> *重新审视序列上的实用共线链*

*Nicola Rizzo, Manuel Cáceres, Veli Mäkinen* | **Main category: cs.DS**

**Keywords:** 共线链, 序列比对, 最优算法, ChainX, 锚定对角距离

**Comment:** 13 pages, 4 figures, 2 tables, 1 algorithm. Accepted at ISBRA2025, to
  be updated with author accepted manuscript

> **TL;DR:** 该研究重新审视了共线链，发现现有实用算法ChainX可能存在次优性，并提出了一种在相同平均时间复杂度下实现最优的算法，通过真实数据集验证了其有效性和低计算开销。

**AI_Comments:** 该论文通过解决现有实用共线链算法（ChainX）的次优性，对序列比对领域做出了重要贡献。引入“锚定对角距离”的概念是其创新点之一。作者不仅提出了理论上最优的算法，还在保持良好平均时间复杂度的前提下，通过真实数据集验证了其在实践中的优越性，这使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** Jain et al.提出的实用共线链解决方案（ChainX）不能保证是最优的。

**Method:** 作者研究了ChainX的失败案例，引入了锚定对角距离（anchor diagonal distance）的概念，并找到并实现了一个在相同平均时间复杂度下实现最优的算法。他们还通过使用真实长读数据集验证了结果。

**Result:** 作者发现了一个最优算法，其平均时间复杂度与ChainX相同（$O(n 	extit{OPT} + n 	ext{log} n)$）。他们验证了Jain et al.的结果，并表明ChainX在真实长读数据集上可能是次优的。他们的新解决方案显示出最小的计算减速。

**Conclusion:** 本研究开发了一种最优的共线链算法，该算法在解决现有实用解决方案次优性的同时，保持了其良好的平均时间复杂度，并在真实数据集上得到了验证。

> **ai_Abstract:** 本文重新审视了序列上的实用共线链问题，指出Jain et al.提出的ChainX算法在实际应用中可能存在次优性。为此，作者通过分析ChainX的失败案例并引入锚定对角距离，开发了一个新的最优共线链算法。该新算法在平均时间复杂度上与ChainX相同，并且在真实长读数据集上验证了ChainX的次优性，同时证明了自身方案的计算开销极小。

> **摘要翻译:** 共线链是序列比对的经典启发式算法，广泛应用于现代实用比对器中。Jain 等人（J. Comput. Biol. 2022）提出了一种 $O(n 	ext{log}^3 n)$ 时间算法，用于链式连接 $n$ 个锚点，使得当锚点是最大精确匹配时，链式连接成本与输入序列的编辑距离相匹配。此外，假设锚点均匀稀疏分布，他们提供了一个实用的解决方案（ChainX），其平均时间复杂度为 $O(n 	ext{SOL} + n 	ext{log} n)$，其中 SOL 是输出链的成本，n 是输入中锚点的数量。该实用解决方案不能保证最优：我们研究了失败案例，引入了锚定对角距离（anchor diagonal distance），并找到并实现了一个在相同 $O(n 	ext{OPT} + n 	ext{log} n)$ 平均时间复杂度下工作的最优算法，其中 OPT 是最优链式连接成本；然后，我们验证了 Jain 等人的结果，表明 ChainX 在真实长读数据集上可能是次优的，并显示我们的解决方案计算减速极小。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [105] [Breaking the O(mn)-Time Barrier for Vertex-Weighted Global Minimum Cut](https://arxiv.org/abs/2506.11926)
> *打破顶点加权全局最小割的 O(mn) 时间壁垒*

*Julia Chuzhoy, Ohad Trabelsi* | **Main category: cs.DS**

**Keywords:** 全局最小顶点割, 随机算法, 时间复杂度, 图论, 组合优化

**Comment:** 

> **TL;DR:** 本文提出了一个随机算法，打破了顶点加权全局最小割问题长达28年的 O(mn) 时间复杂度界限，实现了更快的运行时间。

**AI_Comments:** 本文通过提出一种新的随机算法，成功打破了顶点加权全局最小割问题长达28年的 O(mn) 时间复杂度界限，这是组合优化和图论领域的一个重要突破，显著提升了该基本问题的计算效率。

<details>
  <summary>Details</summary>

**Motivation:** 顶点加权全局最小割问题的现有最快算法具有 $\tilde{O}(mn)$ 的运行时间，该界限已保持28年未被打破，尽管单位顶点权重的情况最近有所改进，但通用加权情况仍需突破。

**Method:** 本文提出了一种随机算法来解决顶点加权全局最小割问题。

**Result:** 本文提出的随机算法将通用加权全局最小顶点割问题的运行时间改进为 $O(\min\{mn^{0.99+o(1)}},m^{1.5+o(1)}\})$。

**Conclusion:** 本文成功打破了通用加权全局最小顶点割问题长达28年的计算时间壁垒，显著提升了该基本问题的算法效率。

> **ai_Abstract:** 本文研究了全局最小顶点割问题，该问题是组合优化和图论中的一个基本问题。尽管其边版本已有接近线性的算法，但顶点加权版本的最佳算法已保持 $\tilde{O}(mn)$ 的时间复杂度长达28年。虽然最近在单位顶点权重情况下有所突破，但本文通过引入一种新的随机算法，成功地将通用加权全局最小顶点割问题的运行时间改进到 $O(\min\{mn^{0.99+o(1)}},m^{1.5+o(1)}\})$，打破了长期存在的 O(mn) 时间壁垒。

> **摘要翻译:** 我们考虑全局最小顶点割问题：给定一个无向顶点加权图 G，计算其顶点的一个最小权重子集，其移除会使 G 不连通。该问题与全局最小边割密切相关，后者将权重置于图的边上，目标是计算一个最小权重边子集，其移除会使图不连通。全局最小割是组合优化和图论中最基本和被广泛研究的问题之一。虽然该问题的边版本早已存在一个接近线性的时间算法（Karger, STOC 1996 和 J. ACM 2000），但顶点版本的现有最快算法（Henzinger, Rao 和 Gabow, FOCS 1996 和 J. Algorithms 2000）的运行时间为 $\tilde{O}(mn)$，其中 m 和 n 分别表示输入图中的边数和顶点数。对于单位顶点权重的特殊情况，这个界限直到最近才被打破（Li 等人, STOC 2021）；他们的结果，结合最近最大 s-t 流的突破性接近线性时间算法（Chen 等人, FOCS 2022, van den Brand 等人, FOCS 2023），使得单位顶点权重的全局最小顶点割问题获得了接近线性的时间算法。在本文中，我们通过为该问题提供一个运行时间为 $O(\min\{mn^{0.99+o(1)}},m^{1.5+o(1)}\})$ 的随机算法，打破了 Henzinger 等人长达 28 年的通用加权全局最小顶点割的界限。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [132] [Engineering Fast and Space-Efficient Recompression from SLP-Compressed Text](https://arxiv.org/abs/2506.12011)
> *从SLP压缩文本中工程化快速且节省空间的重压缩*

*Ankith Reddy Adudodla, Dominik Kempa* | **Main category: cs.DS**

**Keywords:** 重压缩, RLSLP, 压缩索引, 文本索引, LZ77

**Comment:** 

> **TL;DR:** 开发了一种新的RLSLP重压缩算法，比现有方法快46倍，内存使用少17倍，解决了大规模文本索引构建的瓶颈。

**AI_Comments:** 这项工作通过在压缩域内操作，显著解决了大规模文本数据索引构建中的实际性能瓶颈。其创新之处在于首次实现了压缩时间内的RLSLP重压缩构建，这对于处理大数据集尤其重要，并为未来压缩计算在索引构建领域的应用提供了有力的证据。

<details>
  <summary>Details</summary>

**Motivation:** 现有压缩索引虽然理论上高效，但实际构建（特别是RLSLP等复杂组件）仍是瓶颈，尤其需要支持广泛使用的后缀数组查询。

**Method:** 提出了第一个在压缩时间内运行的RLSLP重压缩构建实现，该实现基于输入数据的LZ77类近似。

**Result:** 与现有未压缩时间方法相比，该方法在大型重复输入上实现了高达46倍的速度提升和17倍的内存使用量降低。

**Conclusion:** 这些改进使得处理更大规模数据集成为可能，并证实了压缩计算是快速索引构建的实用途径。

> **ai_Abstract:** 本文提出了一种在压缩时间内运行的RLSLP重压缩构建方法，该方法基于LZ77类近似，旨在解决大规模重复文本数据集上压缩索引构建的实际瓶颈。实验结果表明，与现有方法相比，该方法在速度上提升了46倍，内存使用降低了17倍，显著提高了索引构建的可扩展性和效率。

> **摘要翻译:** 压缩索引使得对海量重复文本数据集进行强大的查询成为可能，其空间占用与压缩输入成比例。尽管理论上的进步带来了高效的索引结构，但它们的实际构建仍然是一个瓶颈（特别是对于像重压缩RLSLP这样的复杂组件），RLSLP是一种基于语法的表示，对于构建支持广泛使用的后缀数组查询的强大文本索引至关重要。
在这项工作中，我们首次实现了重压缩RLSLP的构建，它在压缩时间内运行，并对输入的LZ77类近似进行操作。与最先进的未压缩时间方法相比，我们的方法在大型重复输入上实现了高达46倍的速度提升和17倍的内存使用量降低。这些增益解锁了对更大规模数据集的可扩展性，并肯定了压缩计算是快速索引构建的实用途径。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [24] [Anti-Aliased 2D Gaussian Splatting](https://arxiv.org/abs/2506.11252)
> *抗锯齿二维高斯泼溅*

*Mae Younes, Adnane Boukhayma* | **Main category: cs.GR**

**Keywords:** 2D高斯泼溅, 抗锯齿, 新型视图合成, 渲染质量, Mip滤波器

**Comment:** Code will be available at https://github.com/maeyounes/AA-2DGS

> **TL;DR:** 本文提出了AA-2DGS，一种抗锯齿的二维高斯泼溅方法，解决了传统2DGS在不同采样率渲染时出现的严重锯齿伪影问题，显著提升了不同尺度下的渲染质量。

**AI_Comments:** 该论文创新性地解决了2D高斯泼溅在实际应用中面临的严重锯齿问题，通过结合频率约束和高效的抗锯齿滤波，显著提升了渲染质量和实用性。这对于需要相机变焦或视场变化的场景尤其重要，弥补了现有2DGS方法的局限性。其提出的世界空间平滑核和对象空间Mip滤波器是关键的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 二维高斯泼溅（2DGS）在新型视图合成和表面重建方面表现出色，但当渲染采样率与训练时不同时，会产生严重的锯齿伪影，限制了其在相机变焦或视场变化等场景中的实际应用。这些伪影源于表示中缺乏频率约束和无效的屏幕空间钳制方法。

**Method:** 本文提出了AA-2DGS，通过引入世界空间平面平滑核来约束2D高斯基元的频率内容，基于训练视图的最大采样频率来消除放大时的伪影。此外，通过利用射线-泼溅交叉映射的仿射近似，推导了一种新颖的对象空间Mip滤波器，从而在每个泼溅的局部空间中高效应用适当的抗锯齿。

**Result:** AA-2DGS在保持2DGS几何优势的同时，显著提升了跨不同尺度的渲染质量，有效消除了放大时的高频伪影。

**Conclusion:** 本文提出了AA-2DGS，一种抗锯齿的二维高斯泼溅方法，通过引入世界空间平滑核和对象空间Mip滤波器，成功解决了传统2DGS的锯齿伪影问题，显著提升了不同尺度下的渲染质量和实用性。

> **ai_Abstract:** 本文针对二维高斯泼溅（2DGS）在不同采样率渲染时出现的严重锯齿伪影问题，提出了一种名为AA-2DGS的抗锯齿方法。该方法通过引入世界空间平面平滑核来约束2D高斯基元的频率内容，并利用射线-泼溅交叉映射推导了新颖的对象空间Mip滤波器，从而在保持2DGS几何优势的同时，显著提升了不同尺度下的渲染质量，有效解决了高频伪影问题，增强了其实际应用潜力。

> **摘要翻译:** 二维高斯泼溅（2DGS）最近作为一种有前途的新型视图合成和表面重建方法出现，与体积3DGS相比，它提供了更好的视图一致性和几何精度。然而，当渲染采样率与训练时使用的采样率不同时，2DGS会遭受严重的锯齿伪影，这限制了其在需要相机变焦或不同视场的场景中的实际应用。我们发现这些伪影源于两个关键限制：表示中缺乏频率约束和无效的屏幕空间钳制方法。为了解决这些问题，我们提出了AA-2DGS，一种二维高斯泼溅的抗锯齿公式，它在保持其几何优势的同时，显著增强了跨不同尺度的渲染质量。我们的方法引入了一个世界空间平面平滑核，该核根据训练视图的最大采样频率来约束二维高斯基元的频率内容，有效消除了放大时的高频伪影。此外，我们通过利用射线-泼溅交叉映射的仿射近似，推导了一种新颖的对象空间Mip滤波器，这使我们能够直接在每个泼溅的局部空间中高效应用适当的抗锯齿。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [52] [On Ray Reordering Techniques for Faster GPU Ray Tracing](https://arxiv.org/abs/2506.11273)
> *关于更快GPU光线追踪的光线重排序技术*

*Daniel Meister, Jakub Bokšanský, Michael Guthe, Jiří Bittner* | **Main category: cs.GR**

**Keywords:** 光线追踪, GPU, 光线重排序, 性能优化, 波前路径追踪

**Comment:** 

> **TL;DR:** 研究了光线重排序技术以提升GPU光线追踪性能，发现其能显著提高追踪速度（1.3-2.0倍），但重排序开销的弥补是个问题。

**AI_Comments:** 这项研究提出了一个在GPU光线追踪中提高性能的实用方法，即光线重排序。其创新点在于提出了一种适用于次级光线追踪的改进方法。尽管性能提升显著，但如何有效管理重排序带来的额外开销是其局限性，也是未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 提高现有GPU光线追踪实现的性能。

**Method:** 研究光线重排序作为提高性能的工具，专注于与特定追踪核函数无关的光线重排序。总结现有计算光线排序键的方法并讨论其特性。提出一种新的修改方法，使用终止点估计，适用于追踪次级光线。在RTX追踪核函数的波前路径追踪背景下评估光线重排序技术。

**Result:** 光线重排序在近期GPU上能显著提高追踪速度（1.3-2.0倍)。

**Conclusion:** 光线重排序能提升GPU光线追踪速度，但其重排序开销在硬件加速追踪阶段难以弥补。

> **ai_Abstract:** 本文研究了光线重排序技术在提升GPU光线追踪性能方面的应用。作者总结了现有光线排序键的计算方法，并提出了一种新的、基于终止点估计的重排序方法，特别适用于次级光线追踪。通过在RTX核函数下进行波前路径追踪评估，结果显示光线重排序能显著提升追踪速度（1.3-2.0倍），但同时也指出在硬件加速追踪阶段弥补重排序开销仍是一个挑战。

> **摘要翻译:** 我们研究光线重排序作为提高现有GPU光线追踪实现性能的工具。我们专注于完全独立于特定追踪核函数的光线重排序。我们总结了计算光线排序键的现有方法并讨论了它们的特性。我们提出了一种对先前提出的方法的创新性修改，该方法使用终止点估计，非常适合追踪次级光线。我们在使用RTX追踪核函数的波前路径追踪背景下评估了光线重排序技术。我们表明，光线重排序在近期GPU上产生了显著更高的追踪速度（1.3-2.0倍），但要在硬件加速追踪阶段弥补重排序开销是成问题的。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [80] [Adaptive Tetrahedral Grids for Volumetric Path-Tracing](https://arxiv.org/abs/2506.11510)
> *用于体素路径追踪的自适应四面体网格*

*Anis Benyoub, Jonathan Dupuy* | **Main category: cs.GR**

**Keywords:** 自适应四面体网格, 体素路径追踪, GPU渲染, 空间划分, 最长边二分

**Comment:** 

> **TL;DR:** 该论文提出使用自适应四面体网格在GPU上进行体素路径追踪，与常规网格相比，性能显著提升。

**AI_Comments:** 该论文的创新之处在于将四面体网格，特别是通过最长边二分法构建的网格，应用于GPU上的体素路径追踪。其重要性在于对复杂体素数据实现了显著的性能提升（高达30倍）和实时渲染能力，解决了内存效率和计算速度的问题。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是利用路径追踪高效渲染体素数据，特别是解决内存占用问题以及对自适应空间划分优化算法的需求。

**Method:** 该方法涉及使用通过最长边二分算法构建的四面体网格。他们利用这些网格的特性（自适应空间划分，每个单元格固定数量的邻居）来设计优化的算法和数据结构，用于GPU计算和路径追踪。

**Result:** 其GPU实现比常规网格性能提升高达30倍，并能以每像素32个样本实时渲染生产资产。

**Conclusion:** 该论文得出结论，自适应四面体网格为体素路径追踪提供了显著优势，提供高度自适应的空间划分，并支持优化的GPU算法以实现实时渲染。

> **ai_Abstract:** 本文介绍了自适应四面体网格（通过最长边二分算法生成）在高效体素路径追踪中的应用。该方法提供了一种高度自适应的空间划分表示，可最大限度地减少内存使用，并具有每个单元格固定数量的邻居。通过利用这些特性，作者开发了优化的GPU算法和数据结构。他们的GPU实现与常规网格相比，性能提升高达30倍，能够以每像素32个样本实时渲染生产资产。

> **摘要翻译:** 我们推荐使用通过最长边二分算法构建的四面体网格，用于路径追踪体素数据。这种网格的关键优势有两点。首先，它们提供了一种高度自适应的空间划分表示，限制了体素资产的内存占用。其次，每个（四面体）单元格在体积内恰好有4个邻居（每个四面体的一个面对应一个邻居），在边界处则更少。我们利用这些特性来设计优化的算法和数据结构，以在GPU上计算和路径追踪自适应四面体网格。在实践中，我们的GPU实现比常规网格性能提升高达30倍，并能以每像素32个样本实时渲染生产资产。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [107] [CGVQM+D: Computer Graphics Video Quality Metric and Dataset](https://arxiv.org/abs/2506.11546)
> *CGVQM+D: 计算机图形视频质量度量和数据集*

*Akshay Jindal, Nabil Sadaka, Manu Mathew Thomas, Anton Sochenov, Anton Kaplanyan* | **Main category: cs.GR**

**Keywords:** 视频质量, 合成内容, 渲染伪影, 数据集, 全参考度量

**Comment:** 

> **TL;DR:** 该研究提出了一个名为CGVQM+D的新视频质量数据集，专注于合成内容和现代渲染伪影，并引入了CGVQM，一个全参考视频质量度量标准，其性能显著优于现有度量标准。

**AI_Comments:** 该论文的创新之处在于关注了此前未被充分研究的合成内容和现代渲染伪影的视频质量评估。通过构建专门的数据集和提出新的度量标准，它填补了现有质量度量在处理这些新型失真时的不足，对于计算机图形学和视觉感知领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频和图像质量数据集主要研究自然视频和传统失真，而合成内容和现代渲染伪影的感知仍未得到充分探索。

**Method:** 研究团队提出了一个新颖的视频质量数据集，专注于由高级渲染技术引入的失真，并提出了CGVQM，一个全参考视频质量度量标准。该度量标准利用预训练的3D CNN的特征空间，并能生成逐像素错误图和全局质量分数。

**Result:** 评估结果显示，现有全参考质量度量在这些新型失真上的表现不佳，最大皮尔逊相关系数仅为0.78。研究发现，预训练3D CNN的特征空间与人类对视觉质量的感知高度一致。所提出的CGVQM度量标准显著优于现有度量标准。

**Conclusion:** 该研究通过引入CGVQM+D数据集和CGVQM度量标准，解决了合成内容和现代渲染伪影视频质量评估的不足，并证明了其在这些特定失真上的优越性能。

> **ai_Abstract:** 该论文介绍了CGVQM+D数据集和CGVQM度量标准，旨在解决合成视频内容和现代渲染伪影质量评估的空白。CGVQM+D数据集包含了由多种高级渲染技术引入的失真，而CGVQM是一个全参考视频质量度量，利用3D CNN特征空间，在评估这些特定失真时表现优于现有度量，并能提供详细的逐像素错误信息。

> **摘要翻译:** 虽然现有的视频和图像质量数据集已广泛研究了自然视频和传统失真，但合成内容和现代渲染伪影的感知仍未得到充分探索。我们提出了一个新颖的视频质量数据集，专注于由高级渲染技术引入的失真，包括神经超采样、新视图合成、路径追踪、神经去噪、帧插值和可变速率着色。我们的评估表明，现有全参考质量度量在这些失真上的表现不佳，最大皮尔逊相关系数为0.78。此外，我们发现预训练3D CNN的特征空间与人类对视觉质量的感知高度一致。我们提出了CGVQM，一个全参考视频质量度量，它显著优于现有度量，同时生成逐像素错误图和全局质量分数。我们的数据集和度量实现可在https://github.com/IntelLabs/CGVQM获取。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [25] [Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems](https://arxiv.org/abs/2506.11421)
> *实时推荐系统深度学习模型加速与优化策略*

*Junli Shao, Jing Dong, Dingzhou Wang, Kowei Shih, Dannier Li, Chengrui Zhou* | **Main category: cs.IR**

**Keywords:** 实时推荐系统, 深度学习, 模型加速, 性能优化, 推理延迟

**Comment:** 

> **TL;DR:** 本文提出模型级和系统级加速优化策略，显著降低实时推荐系统深度学习模型的推理延迟并提高吞吐量，同时保持推荐质量。

**AI_Comments:** 该论文的创新点在于提出了模型级和系统级相结合的综合优化策略，解决了实时推荐系统中的关键性能瓶颈。其重要性在于提供了一个在保持推荐准确性下，显著提高系统效率的实用解决方案，对于部署大规模在线推荐服务具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 面对海量用户请求和复杂模型架构，实时推荐系统面临如何降低推理延迟、提高系统吞吐量而不牺牲推荐质量的关键挑战。

**Method:** 结合模型级和系统级加速优化策略。模型级包括轻量级网络设计、结构化剪枝和权重量化以减少参数和计算需求。系统级包括集成异构计算平台、高性能推理库，并设计基于实时负载特性的弹性推理调度和负载均衡机制。

**Result:** 在保持原有推荐准确性的前提下，延迟降低到基线的30%以下，系统吞吐量提高一倍以上。

**Conclusion:** 本文提出的方法为部署大规模在线推荐服务提供了一个实用的解决方案。

> **ai_Abstract:** 本文针对实时推荐系统中深度学习模型面临的高计算成本和资源瓶颈，提出了一套综合的模型级和系统级加速优化策略。通过模型轻量化（网络设计、剪枝、量化）和系统优化（异构平台集成、弹性调度、负载均衡），在不牺牲推荐质量的前提下，显著降低了推理延迟并提高了系统吞吐量，为大规模在线推荐服务提供了实用部署方案。

> **摘要翻译:** 随着互联网服务的快速增长，推荐系统在提供个性化内容方面发挥着核心作用。面对海量用户请求和复杂的模型架构，实时推荐系统的关键挑战是如何在不牺牲推荐质量的情况下减少推理延迟和提高系统吞吐量。本文通过提出一套结合模型级和系统级的加速和优化策略，解决了实时设置中深度学习模型的高计算成本和资源瓶颈问题。在模型层面，我们通过轻量级网络设计、结构化剪枝和权重 量化，大幅减少了参数数量和计算需求。在系统层面，我们集成了多个异构计算平台和高性能推理库，并设计了基于实时负载特性的弹性推理调度和负载均衡机制。实验表明，在保持原有推荐准确性的同时，我们的方法将延迟降低到基线的30%以下，系统吞吐量提高一倍以上，为部署大规模在线推荐服务提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [53] [Leveraging Reference Documents for Zero-Shot Ranking via Large Language Models](https://arxiv.org/abs/2506.11452)
> *利用参考文档通过大型语言模型进行零样本排序*

*Jieran Li, Xiuyuan Hu, Yang Zhao, Shengyao Zhuang, Hao Zhang* | **Main category: cs.IR**

**Keywords:** 文本排序, 大型语言模型, 零样本排序, 计算效率, 信息检索

**Comment:** 

> **TL;DR:** RefRank是一种新的基于固定参考文档的比较排序方法，它解决了LLM文本排序中效率和准确性之间的权衡，实现了线性时间复杂度并保持了比较评估的优势。

**AI_Comments:** RefRank的创新点在于它巧妙地解决了LLM文本排序中效率与准确性的两难困境。通过引入“参考锚点”这一概念，它在保持比较优势的同时，将计算复杂度从平方级降至线性级，这是一个重要的突破。这种方法为大规模信息检索场景下LLM的应用提供了更实用的路径，具有很高的潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在文本排序任务中表现出色，但Pointwise方法存在偏差，而Pairwise方法计算成本高昂（O(n^2)）。为了解决效率和准确性之间的权衡，本文提出了RefRank。

**Method:** RefRank是一种基于固定参考文档的简单有效的比较排序方法。它不比较所有文档对，而是提示LLM评估每个候选文档相对于一个共享参考锚点。通过选择封装核心查询意图的参考锚点，RefRank隐式捕获相关性线索，并通过这个共同锚点实现文档间的间接比较。这使得计算成本降低到线性时间（O(n)）。为了增强鲁棒性，RefRank还通过对不同参考选择的加权平均方案聚合多个输出。

**Result:** 在多个基准数据集和各种LLM上的实验表明，RefRank显著优于Pointwise基线，并且能够以显著更低的计算成本实现至少与Pairwise方法相当的性能。

**Conclusion:** RefRank通过引入固定的参考文档进行比较评估，成功地在LLM文本排序中平衡了计算效率和排名准确性，提供了一种有效且可扩展的解决方案。

> **ai_Abstract:** 本文提出了RefRank，一种利用大型语言模型（LLMs）进行零样本排序的新方法。针对Pointwise排序的偏差和Pairwise排序的高计算成本问题，RefRank引入了基于固定参考文档的比较评估机制。它通过让LLM评估候选文档相对于一个选定参考锚点的相关性，实现了文档间的间接比较。这种方法将计算复杂度从O(n^2)降低到O(n)，同时保持了比较评估的准确性。实验证明，RefRank在性能上优于Pointwise方法，并可与Pairwise方法媲美，但成本显著降低。

> **摘要翻译:** 大型语言模型（LLMs）在信息检索的文本排序任务中表现出卓越的性能。虽然Pointwise排序方法通过独立评分文档提供了计算效率，但由于缺乏文档间的比较，它们通常会产生有偏见的相关性估计。相比之下，Pairwise方法通过明确比较文档对来提高排序准确性，但却遭受二次复杂度（O(n^2)）带来的巨大计算开销。为了解决这种权衡，我们提出RefRank，这是一种基于固定参考文档的简单有效的比较排序方法。RefRank不比较所有文档对，而是提示LLM评估每个候选文档相对于一个共享参考锚点。通过选择封装核心查询意图的参考锚点，RefRank隐式捕获相关性线索，从而通过这个共同锚点实现文档之间的间接比较。这使得计算成本降低到线性时间（O(n)），同时重要的是，保留了比较评估的优势。为了进一步增强鲁棒性，我们使用跨不同参考选择的加权平均方案聚合多个RefRank输出。在几个基准数据集和各种LLM上的实验表明，RefRank显著优于Pointwise基线，并且能够以显著更低的计算成本实现至少与Pairwise方法相当的性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [81] [A Reference Model and Patterns for Production Event Data Enrichment](https://arxiv.org/abs/2506.11502)
> *生产事件数据富集的一个参考模型与模式*

*Mark van der Pas, Remco Dijkman, Alp Akçay, Ivo Adan, John Walker* | **Main category: cs.IR**

**Keywords:** 生产事件数据, 数据富集, 参考模型, ISA-95, 事件知识图谱

**Comment:** Extended version of the paper submitted to EDOC 2025

> **TL;DR:** 提出一个参考模型和一组模式，用于标准化和自动化生产事件数据富集过程，以解决现有数据预处理的随意性、耗时和劳动密集型问题。

**AI_Comments:** 该论文通过提出一个结合行业标准（ISA-95）和前沿技术（事件知识图谱）的参考模型以及一套具体模式，旨在解决生产事件数据预处理中的实际痛点。其创新性在于提供了一种结构化、可自动化的数据富集方法，这对于提高工业数据分析的效率和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着数字化转型，组织生成大量来自不同系统的数据，集成这些数据对过程监控和分析至关重要。然而，数据预处理和工程阶段通常是随意、耗时且劳动密集型的。

**Method:** 引入了一个参考模型和一组模式来富集生产事件数据。参考模型结合了ISA-95工业标准和事件知识图谱形式，用于存储和提取生产事件数据。模式基于制造业事件数据集的经验观察开发，并使用参考模型进行形式化，描述了常见的信息提取任务及其自动化方法。

**Result:** 通过将这些模式应用于实际用例，评估了它们的关联性和适用性。

**Conclusion:** 该研究提出的参考模型和模式为生产事件数据富集提供了一种标准化和自动化的方法，从而简化了数据预处理过程。

> **ai_Abstract:** 本文针对数字化转型中生产事件数据预处理随意、耗时且劳动密集的问题，提出了一个参考模型和一套模式来富集生产事件数据。该参考模型结合了ISA-95标准和事件知识图谱，用于标准化数据存储与提取；模式则基于经验观察，描述并自动化常见的信息提取任务。研究通过用例验证了其相关性和适用性。

> **摘要翻译:** 随着数字化转型的到来，组织通过在不同系统上执行各种流程，生成了大量的事件数据。通过整合来自这些异构源的数据，可以获得对过程性能监控和分析等任务至关重要的新见解。通常，这些信息是在数据预处理或工程阶段提取的。然而，这一步骤往往是临时性的，耗时且劳动密集型。为了简化这一过程，我们引入了一个参考模型和一系列旨在富集生产事件数据的模式。该参考模型提供了一种存储和提取生产事件数据的标准方法。这些模式描述了常见的信息提取任务以及如何有效地自动化这些任务。该参考模型是通过将ISA-95行业标准与事件知识图谱形式相结合而开发的。这些模式是基于对源自制造过程的事件数据集的经验观察而开发的，并使用参考模型进行形式化。我们通过演示它们在用例中的应用来评估这些模式的相关性和适用性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [92] [Forgetful by Design? A Critical Audit of YouTube's Search API for Academic Research](https://arxiv.org/abs/2506.11727)
> *设计使然的遗忘？对YouTube搜索API用于学术研究的批判性审查*

*Bernhard Rieder, Adrian Padilla, Oscar Coromina* | **Main category: cs.IR**

**Keywords:** YouTube API, 学术研究, 数据完整性, 时效性衰减, 搜索偏差

**Comment:** 34 pages, 2 tables and 4 figures

> **TL;DR:** YouTube的搜索API不适合学术研究，因为它在完整性、代表性、一致性和偏差方面存在严重缺陷，且视频可发现性随时间迅速衰减。

**AI_Comments:** 这篇论文通过实证研究揭示了流行API在学术使用中的潜在陷阱，对依赖此类平台数据进行研究的研究者提出了重要警告。其创新之处在于系统性地量化了API的局限性，并强调了数据新鲜度优先于完整性的设计缺陷，这对数字社会研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** YouTube的Data API (v3)搜索端点是学术研究的常用工具，但其有效性、完整性、代表性、一致性和偏差方面存在疑问，因此需要进行批判性审查。

**Method:** 研究人员在六个月内每周使用十一个查询对YouTube的Data API (v3)搜索端点进行系统性搜索，并对欧洲议会选举进行案例研究。

**Result:** 发现主要限制包括：完整性、代表性、一致性和偏差问题；相关性与日期等排名参数在视频召回率和精确度上存在显著差异，相关性常检索到大量不相关视频；严重的时效性衰减，即视频在发布后20-60天内可发现数量急剧下降；搜索结果缺乏一致性，相同查询在不同时间产生不同视频集，影响可重复性；案例研究突出这些问题对研究结果的影响。

**Conclusion:** YouTube搜索API可能优先考虑“新鲜度”而非全面检索，不足以支持严谨的学术研究，尤其不符合《数字服务法》的要求。

> **ai_Abstract:** 本文对YouTube Data API (v3)的搜索功能进行了批判性审查，发现其在学术研究中存在严重缺陷。研究通过六个月的系统性搜索揭示了API在完整性、代表性、一致性和偏差方面的局限性，包括搜索结果的时效性衰减和不一致性。结论认为，该API不适合严谨的学术研究，尤其是在遵守《数字服务法》方面。

> **摘要翻译:** 本论文批判性地审查了YouTube数据API (v3)的搜索端点，该端点是学术研究的常用工具。通过在六个月内每周使用十一个查询进行系统性搜索，我们发现了其在完整性、代表性、一致性和偏差方面的主要局限性。我们的发现揭示了相关性和日期等排名参数在视频召回率和精确度方面存在显著差异，其中相关性常检索到大量不相关的视频。我们还发现严重的时效性衰减，因为特定时期可找到的视频数量在发布日期后仅20-60天内就急剧减少，这可能阻碍许多不同的研究设计。此外，搜索结果缺乏一致性，相同的查询随着时间的推移会产生不同的视频集，从而损害了可重复性。一项关于欧洲议会选举的案例研究强调了这些问题如何影响研究成果。尽管论文提供了一些缓解策略，但它得出结论，API的搜索功能可能优先考虑“新鲜度”而非全面检索，不足以支持严谨的学术研究，特别是关于《数字服务法》的要求。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [108] [Dual-View Disentangled Multi-Intent Learning for Enhanced Collaborative Filtering](https://arxiv.org/abs/2506.11538)
> *双视图解耦多意图学习用于增强协同过滤*

*Shanfan Zhang, Yongyi Lin, Yuan Rao, Chenlong Zhang* | **Main category: cs.IR**

**Keywords:** 协同过滤, 多意图学习, 解耦, 双视图, 推荐系统

**Comment:** 26 pages, 11 figures

> **TL;DR:** 本文提出了DMICF，一个用于协同过滤的双视图框架，通过显式建模意图对齐和利用用户与物品的双重视角结构信号来解耦用户意图，从而提高推荐准确性和可解释性。

**AI_Comments:** DMICF的创新之处在于其双视图架构和显式的交互层面意图对齐，这有效地解决了现有方法中意图独立建模和缺乏监督的问题。通过结合用户和物品的结构信号并引入细粒度意图交互编码器，它提高了模型在数据稀疏和长尾场景下的鲁棒性和泛化能力。其判别性训练信号也为语义解耦提供了有效手段。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通常独立建模用户意图且缺乏显式监督，未能捕捉驱动用户-物品交互的联合语义，这限制了推荐准确性和可解释性的提升，尤其是在数据稀疏和长尾场景下。

**Method:** DMICF是一个统一框架，采用双视图架构，从用户和物品两侧共同编码交互图，实现双向信息融合。它引入了意图交互编码器，在每个视图内执行子意图对齐，以建模细粒度的用户-物品兼容性。此外，DMICF集成了意图感知评分机制，聚合匹配意图对的兼容性信号。为促进语义解耦，通过多负采样和softmax归一化设计了判别性训练信号。

**Result:** 大量实验表明，DMICF在具有不同交互分布的数据集上始终提供鲁棒的性能。

**Conclusion:** DMICF通过显式建模交互层面的意图对齐和利用双视图结构信号，有效增强了推荐准确性和可解释性，并在各种数据集上表现出鲁棒性。

> **ai_Abstract:** DMICF是一个统一的框架，通过明确建模交互层面的意图对齐并利用用户和物品的双视图结构信号来增强协同过滤。它采用双视图架构实现双向信息融合，并引入意图交互编码器进行细粒度意图对齐。该模型还包含意图感知评分机制和判别性训练信号，以提高推荐准确性、可解释性、泛化能力和在数据稀疏及长尾场景下的鲁棒性。实验证明其在不同数据集上表现出色。

> **摘要翻译:** 解耦用户意图与隐式反馈已成为提高推荐准确性和可解释性的一种有前景的策略。现有方法通常独立建模意图，缺乏显式监督，因此未能捕捉驱动用户-物品交互的联合语义。为解决这些局限性，我们提出了DMICF，一个统一的框架，它明确建模交互层面的意图对齐，同时利用来自用户和物品视角的结构信号。DMICF采用双视图架构，从两侧共同编码用户-物品交互图，实现双向信息融合。这种设计通过允许一个视图的结构冗余补偿另一个视图的局限性来增强数据稀疏性下的鲁棒性。为了建模细粒度的用户-物品兼容性，DMICF引入了一个意图交互编码器，在每个视图内执行子意图对齐，揭示用户决策背后的共享语义结构。这种局部对齐能够根据交互上下文自适应地完善意图嵌入，从而提高模型的泛化能力和表达能力，特别是在长尾场景中。此外，DMICF集成了一个意图感知评分机制，该机制聚合来自用户和物品子空间中匹配意图对的兼容性信号，实现基于语义一致性而非纠缠表示的个性化预测。为了促进语义解耦，我们通过多负采样和softmax归一化设计了一种判别性训练信号，该信号将语义对齐的意图对拉近，同时将不相关或噪声意图对推开。大量实验表明，DMICF在具有不同交互分布的数据集上始终提供鲁棒的性能。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [135] [GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news](https://arxiv.org/abs/2506.11600)
> *GraphRAG-Causal：一种用于新闻因果推理和标注的新型图增强框架*

*Abdul Haque, Umm e Hani, Ahmad Din, Muhammad Babar, Ali Abbas, Insaf Ullah* | **Main category: cs.IR**

**Keywords:** 因果推理, 图增强框架, 大型语言模型, 新闻分析, Neo4j

**Comment:** 18 pages, 8 figures

> **TL;DR:** GraphRAG-Causal是一个结合图检索和大型语言模型的新框架，通过将新闻转换为因果知识图谱并在Neo4j中进行混合检索，显著提高了新闻因果推理的准确性，在少量样本下F1分数达到82.1%。

**AI_Comments:** GraphRAG-Causal的创新之处在于其将因果知识图谱与大型语言模型和混合检索系统相结合，有效地解决了新闻文本中复杂、隐含因果关系识别的挑战。特别是在低数据量场景下，其通过图结构化和少样本学习实现了显著的性能提升，这对于实时新闻分析和假信息检测具有重要应用价值。该方法利用Neo4j进行图存储和查询，体现了其在处理结构化数据方面的优势。

<details>
  <summary>Details</summary>

**Motivation:** 传统自然语言处理方法在识别复杂、隐含的因果关系方面（尤其是在数据量少的情况下）存在困难。

**Method:** GraphRAG-Causal框架将标注过的新闻标题转换为结构化的因果知识图谱，并采用混合检索系统，结合语义嵌入和基于图的结构线索（利用Neo4j）来匹配和检索相关事件。该框架分为三个阶段：数据准备（标注新闻并转换为因果图）、图检索（在Neo4j中存储图及其嵌入，并使用混合Cypher查询进行检索）和LLM推理（利用检索到的因果图和基于XML的提示进行少样本学习，实现因果关系分类和标记）。

**Result:** GraphRAG-Causal在因果分类上取得了82.1%的F1分数，仅使用了20个少样本示例。该方法显著提高了准确性和一致性。

**Conclusion:** GraphRAG-Causal框架通过结合图检索和大型语言模型，有效解决了新闻中复杂因果关系识别的挑战，并在少样本学习场景下展现出高准确性，适用于新闻可靠性评估、虚假信息检测和政策分析等实时应用。

> **ai_Abstract:** GraphRAG-Causal是一个新颖的图增强框架，旨在通过结合图检索和大型语言模型来提高新闻中的因果推理和标注能力。它通过将新闻转换为结构化因果知识图谱，并利用Neo4j进行混合检索，克服了传统NLP在识别复杂因果关系上的不足。该框架包含数据准备、图检索和LLM推理三个阶段，实验证明在少量样本下能显著提高因果分类的准确性，F1分数达到82.1%，适用于新闻可靠性评估和虚假信息检测。

> **摘要翻译:** GraphRAG-Causal引入了一个创新的框架，该框架结合了基于图的检索与大型语言模型，以增强新闻分析中的因果推理能力。传统的自然语言处理方法在识别复杂、隐含的因果链接方面常常面临困难，尤其是在数据量不足的情况下。我们的方法通过将标注过的新闻标题转换为结构化的因果知识图谱来解决这些挑战。然后，它采用一个混合检索系统，将语义嵌入与基于图的结构线索相结合，利用Neo4j精确匹配和检索相关事件。该框架建立在一个三阶段的管道上：首先，在数据准备阶段，新闻句子被精细标注并转换为捕获因果、效应和触发关系的因果图。接着，图检索阶段将这些图及其嵌入存储在Neo4j数据库中，并利用混合Cypher查询高效地识别与给定查询共享语义和结构相似性的事件。最后，LLM推理阶段在少样本学习设置中，利用这些检索到的因果图结合基于XML的提示，实现因果关系的稳健分类和标记。实验评估表明，GraphRAG-Causal在仅使用20个少样本示例的情况下，在因果分类上取得了令人印象深刻的82.1%的F1分数。这种方法显著提高了准确性和一致性，使其非常适用于新闻可靠性评估、虚假信息检测和政策分析等实时应用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [158] [TongSearch-QR: Reinforced Query Reasoning for Retrieval](https://arxiv.org/abs/2506.11603)
> *TongSearch-QR：用于检索的强化查询推理*

*Xubo Qin, Jun Bai, Jiaqi Li, Zixia Jia, Zilong Zheng* | **Main category: cs.IR**

**Keywords:** 查询推理, 强化学习, 小型语言模型, 信息检索, TongSearch QR

**Comment:** 

> **TL;DR:** TongSearch-QR引入了小型语言模型，通过强化学习和半规则奖励函数，实现了与大型语言模型相当的查询推理性能，同时显著降低了推理成本，特别适用于推理密集型检索任务。

**AI_Comments:** TongSearch-QR的创新之处在于它成功地将强化学习与小型语言模型结合，通过设计巧妙的半规则奖励函数，解决了大型语言模型在推理密集型检索任务中成本高昂的部署问题。这对于实际应用具有重要意义，因为它提供了一个更经济、更高效的解决方案，使得高级查询推理能力得以广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统信息检索方法在需要多跳推理或复杂语义理解的推理密集型检索任务中表现不佳。虽然大型语言模型（LLMs）可以通过重写或增强查询来解决这个问题，但其高昂的推理成本和有限的部署能力使其在实际应用中不切实际。

**Method:** 本研究引入了TongSearch QR，一个用于查询推理和重写的小型语言模型家族。它采用了一种新颖的半规则奖励函数，并结合强化学习方法，使Qwen2.5-7B-Instruct和Qwen2.5-1.5B-Instruct等小型语言模型能够达到与大型语言模型相当的查询推理性能。

**Result:** 在BRIGHT基准测试中，结合BM25作为检索器，TongSearch QR-7B和TongSearch QR-1.5B模型显著优于现有基线，包括基于提示的查询推理器和一些为推理密集型检索任务训练的最新密集检索器。

**Conclusion:** TongSearch QR通过利用小型语言模型和强化学习，成功解决了大型语言模型在推理密集型检索任务中成本高昂的限制，为实际部署提供了更好的适应性。

> **ai_Abstract:** 本文介绍了TongSearch QR，一个利用小型语言模型进行推理密集型检索中查询推理和重写的新框架。针对大型语言模型成本高昂的挑战，TongSearch QR通过结合强化学习和创新的半规则奖励函数，使得小型模型（如Qwen2.5-7B/1.5B）能够达到与大型模型相当的性能，同时大幅降低了推理成本。实验结果表明，TongSearch QR在BRIGHT基准测试上显著优于现有基线，展现了在实际部署中的高适应性。

> **摘要翻译:** 传统信息检索（IR）方法擅长文本和语义匹配，但在需要查询和文档之间进行多跳推理或复杂语义理解的推理密集型检索任务中表现不佳。一个有前景的解决方案是使用大型语言模型（LLMs）显式地重写或增强查询，以在检索前引出与推理相关的内容。然而，由于GPT-4或LLaMA3-70B等大规模语言模型的高昂推理成本和在实际系统中的部署能力有限，它们的广泛使用仍然不切实际。在这项工作中，我们引入了TongSearch QR（以前称为“TongSearch Reasoner”），这是一个用于推理密集型检索中查询推理和重写的小型语言模型家族。通过一种新颖的半规则奖励函数，我们采用强化学习方法，使Qwen2.5-7B-Instruct和Qwen2.5-1.5B-Instruct等小型语言模型能够在没有高昂推理成本的情况下，实现与大规模语言模型相媲美的查询推理性能。在BRIGHT基准测试中的实验结果表明，在以BM25作为检索器的情况下，TongSearch QR-7B和TongSearch QR-1.5B模型均显著优于现有基线，包括基于提示的查询推理器和一些为推理密集型检索任务训练的最新密集检索器，为实际部署提供了卓越的适应性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [196] [Generative Representational Learning of Foundation Models for Recommendation](https://arxiv.org/abs/2506.11999)
> *推荐领域基础模型的生成式表征学习*

*Zheli Zhou, Chenxu Zhu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu* | **Main category: cs.IR**

**Keywords:** 推荐基础模型, 生成式学习, 多任务学习, 表征学习, RecFound

**Comment:** Project page is available at https://junkfood436.github.io/RecFound/

> **TL;DR:** RecFound是一个新的推荐基础模型框架，通过解决多任务学习的挑战，在生成和嵌入任务上都取得了最先进的性能。

**AI_Comments:** RecFound通过在一个多任务学习框架内明确处理生成和嵌入任务，填补了推荐基础模型中的一个关键空白。其提出的解决方案（TMoLE、S2Sched、Model Merge）在解决常见的多任务学习难题方面具有创新性，是构建更强大、更通用推荐系统的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐基础模型在生成任务上有所探索，但常忽略关键的嵌入任务，且在多任务学习中面临知识共享与冲突、收敛速度不一致等复杂挑战。

**Method:** 提出了RecFound，一个用于推荐基础模型的生成式表征学习框架。构建了首个涵盖生成和嵌入任务的综合数据集。基于该数据集，提出了一种新颖的多任务训练方案，包括用于处理知识共享与冲突的Task-wise Mixture of Low-rank Experts (TMoLE)，用于解决收敛不一致的Step-wise Convergence-oriented Sample Scheduler (S2Sched)，以及用于平衡任务性能的Model Merge模块。

**Result:** 实验表明RecFound在各种推荐任务中取得了最先进的性能，优于现有基线。

**Conclusion:** RecFound通过整合生成和嵌入任务并克服多任务学习挑战，有效解决了现有推荐基础模型的局限性，实现了卓越的性能。

> **ai_Abstract:** RecFound是一个用于推荐基础模型的生成式表征学习框架。它通过构建首个涵盖生成和嵌入任务的综合数据集，并提出新颖的多任务训练方案（包括TMoLE、S2Sched和Model Merge）来解决现有模型在多任务学习中面临的知识共享冲突和收敛不一致等问题。实验证明RecFound在多种推荐任务上达到了最先进的性能。

> **摘要翻译:** 开发一个能够在各种任务中表现出色的单一基础模型是人工智能领域的一个长期目标。随着通用基础模型浪潮席卷各个领域，它们的影响已显著扩展到推荐系统领域。尽管最近的努力探索了用于各种生成任务的推荐基础模型，但它们往往忽视了关键的嵌入任务，并且难以应对多任务学习的复杂性，包括知识共享与冲突解决以及收敛速度不一致等问题。为了解决这些局限性，我们引入了RecFound，一个用于推荐基础模型的生成式表征学习框架。我们构建了第一个涵盖生成和嵌入任务的全面推荐基础模型数据集，覆盖了多种场景。基于此数据集，我们提出了一种新颖的多任务训练方案，其特点是：采用任务级低秩专家混合（TMoLE）来处理知识共享与冲突，采用步进式收敛导向样本调度器（S2Sched）来解决收敛不一致问题，以及采用模型合并模块来平衡各项任务的性能。实验表明，RecFound在各种推荐任务中取得了最先进的性能，超越了现有基线。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [26] [Is the Fitness Dependent Optimizer Ready for the Future of Optimization?](https://arxiv.org/abs/2506.10983)
> *适应度依赖优化器是否已为未来优化做好准备？*

*Ardalan H. Awlla, Tarik A. Rashid, Ronak M. Abdullah* | **Main category: cs.NE**

**Keywords:** 适应度依赖优化器, 元启发式算法, 群智能, 优化, 综述

**Comment:** 21 pages

> **TL;DR:** 本文全面回顾了适应度依赖优化器（FDO），评估其性能、优缺点，并提出未来研究方向。

**AI_Comments:** 这篇综述性论文对于理解FDO算法的当前状态及其在未来优化领域的潜力至关重要。它提供了一个结构化的分析框架，帮助研究人员了解FDO的优缺点，并指明了进一步改进和研究的方向，这对于推动元启发式算法的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于适应度依赖优化器（FDO）在解决复杂优化问题中的潜力，本文旨在对其进行全面审查，评估其性能，识别其优缺点，并为未来的研究提供指导。

**Method:** 本文通过系统地收集和审查所有相关论文，对FDO及其主要变体和应用进行了全面回顾。研究采用比较分析来评估FDO及其变体在解决实际优化问题中的表现。

**Result:** 论文评估了FDO在多个维度上的性能，识别了其优缺点，并展示了FDO及其变体在解决实际优化问题中的有效性。

**Conclusion:** 本文对适应度依赖优化器（FDO）进行了全面评估，识别了其优势与劣势，并提出了未来研究方向，以帮助研究人员进一步提升FDO的性能。

> **ai_Abstract:** 本文对2019年提出的基于蜜蜂群智能的适应度依赖优化器（FDO）进行了全面回顾。研究系统地收集并分析了相关文献，旨在评估FDO在解决复杂优化问题中的性能、识别其优缺点，并通过比较分析展示其在实际问题中的应用效果。最后，论文提出了FDO未来的研究方向，以期提升其性能。

> **摘要翻译:** 元启发式算法是受自然界真实现象或生物（如动物）行为启发而用于解决工程、能源优化、医疗保健等复杂问题的优化方法。其中之一是2019年创建的适应度依赖优化器（FDO），它基于蜜蜂启发式群智能，并提供了高效的优化。本文旨在对FDO进行全面回顾，包括其基本概念、主要变体和从一开始的应用。它系统地收集并审查了每一篇相关论文，提供了对该算法优缺点的深刻见解。目的是评估FDO在多个维度上的性能，并识别其优势和劣势。本研究使用比较分析来展示FDO及其变体在解决实际世界优化问题中的表现如何，这有助于我们理解它们的能力。最后，本文提出了未来的研究方向，可以帮助研究人员进一步提升FDO的性能。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [54] [Mapping and Scheduling Spiking Neural Networks On Segmented Ladder Bus Architectures](https://arxiv.org/abs/2506.11286)
> *在分段梯形总线架构上映射和调度脉冲神经网络*

*Phu Khanh Huynh, Francky Catthoor, Anup Das* | **Main category: cs.NE**

**Keywords:** 脉冲神经网络, 分段总线, 神经形态架构, 控制平面, 可扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种针对分段梯形总线架构的场景感知控制平面设计方法，旨在最小化控制开销并优化能耗和面积利用率，实验证明该方法有效减少了控制平面的面积并保持了网络规模的可扩展性。

**AI_Comments:** 该论文提出了一种针对分段梯形总线架构的创新性控制平面设计方法，旨在解决神经形态系统中通信效率和资源利用的挑战。其亮点在于“场景感知”的设计理念，这对于处理脉冲神经网络固有的稀疏和突发性通信模式至关重要。通过FPGA实现和软件仿真验证了其有效性，特别是在减小控制平面面积和保持可扩展性方面。这对于开发更高效、更节能的未来神经形态硬件具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大规模神经形态架构中的计算单元通过共享互连通信，其通信模式稀疏、异步且局部化，需要优化的互连来处理高活动突发同时在空闲时段消耗最小功率。动态分段总线因其结构简单、可扩展性和能效而受到关注，但其优势的发挥需要一个可高效随网络扩展的简化控制平面。

**Method:** 本文提出了一种针对分段梯形总线量身定制的场景感知控制平面设计方法，旨在最小化控制开销并优化能量和面积利用率。通过结合FPGA实现和软件仿真来评估其可扩展性。

**Result:** 结果表明，与数据平面相比，所提出的设计过程有效减小了控制平面的面积，同时保持了网络规模的可扩展性。

**Conclusion:** 本文提出的针对分段梯形总线架构的场景感知控制平面设计方法，在神经形态系统中有效降低了控制开销，优化了资源利用，并保持了良好的可扩展性。

> **ai_Abstract:** 本文提出了一种针对大规模神经形态架构中分段梯形总线的场景感知控制平面设计方法。该方法旨在解决脉冲神经网络稀疏、突发通信模式下的互连效率和功耗问题，通过优化控制平面来最小化开销并提高能量和面积利用率。研究通过FPGA实现和软件仿真评估了其可扩展性，结果显示该设计有效减小了控制平面面积，并保持了随网络规模的良好可扩展性。

> **摘要翻译:** 大规模神经形态架构由计算单元组成，这些单元使用共享互连通信脉冲。这些系统中的通信模式本质上是稀疏、异步和局部的，因为神经活动的特点是时间上的稀疏性，偶尔会出现高流量的爆发。这些特性要求优化的互连来处理高活动爆发，同时在空闲期间消耗最小的功率。在提出的互连解决方案中，动态分段总线因其结构简单、可扩展性和能效而受到关注。由于动态分段总线的优势源于其简单性，因此开发一个能够随网络高效扩展的精简控制平面至关重要。在本文中，我们提出了一种针对分段梯形总线量身定制的场景感知控制平面设计方法，旨在最小化控制开销并优化能量和面积利用率。我们结合使用FPGA实现和软件仿真来评估我们的方法以评估可扩展性。结果表明，我们的设计过程与数据平面相比，有效减小了控制平面的面积，同时保持了网络规模的可扩展性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [82] [FeNN: A RISC-V vector processor for Spiking Neural Network acceleration](https://arxiv.org/abs/2506.11760)
> *FeNN：一种用于脉冲神经网络加速的RISC-V向量处理器*

*Zainab Aizaz, James C. Knight, Thomas Nowotny* | **Main category: cs.NE**

**Keywords:** 脉冲神经网络, RISC-V, FPGA, 向量处理器, 硬件加速

**Comment:** 7 pages, 4 figures. Accepted in Proceedings of Neuro Inspired
  Computational Elements Conference 2025

> **TL;DR:** FeNN是一个基于RISC-V的软向量处理器，专为FPGA上的脉冲神经网络加速设计，比现有方案更快更高效。

**AI_Comments:** 这篇论文的创新点在于提出了一个针对SNN优化的RISC-V软向量处理器，并将其部署在FPGA上，实现了可编程性和高性能。它填补了SNN加速领域中通用性与效率之间的空白，尤其强调了其在低硬件利用率下实现高精度以及优于现有解决方案的性能，这对于边缘AI和低功耗计算具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲神经网络（SNNs）有潜力大幅降低AI系统的能耗，但主流加速器（如GPU和TPU）不适合SNN仿真，而FPGA虽然适合低算术强度应用，但需要定制的处理器来高效仿真SNN。

**Method:** 本文提出了一种名为FeNN的RISC-V软向量处理器，专为在FPGA上仿真SNN而定制。FeNN是完全可编程的，设计用于与从边缘到云端的标准计算机上运行的应用程序集成。通过使用随机舍入和饱和技术，FeNN可以在低硬件利用率下实现高数值精度。

**Result:** FeNN在低硬件利用率下实现了高数值精度。单个FeNN核心可以比嵌入式GPU和Loihi神经形态系统更快地仿真SNN分类器。

**Conclusion:** FeNN提供了一种高效、可编程且适用于SNN仿真的RISC-V向量处理器解决方案，其性能优于现有的一些主流和专用硬件，对于低功耗AI系统具有重要意义。

> **ai_Abstract:** 本文提出了一种名为FeNN的RISC-V软向量处理器，专为在FPGA上高效仿真脉冲神经网络（SNN）而设计。FeNN旨在解决主流加速器不适合SNN的挑战，并通过采用随机舍入和饱和技术，在低硬件利用率下实现了高数值精度。实验结果表明，单个FeNN核心在SNN分类器仿真方面超越了嵌入式GPU和Loihi神经形态系统。

> **摘要翻译:** 脉冲神经网络（SNN）有潜力大幅降低AI系统的能耗需求。然而，主流加速器如GPU和TPU是为标准ANN的高算术强度设计的，因此不适合SNN仿真。FPGA非常适合低算术强度的应用，因为它们具有高片外内存带宽和大量片上内存。本文介绍了一种新颖的基于RISC-V的软向量处理器（FeNN），专为在FPGA上仿真SNN而定制。与大多数专用神经形态硬件不同，FeNN是完全可编程的，并设计用于与从边缘到云端的标准计算机上运行的应用程序集成。我们证明，通过使用随机舍入和饱和，FeNN可以在低硬件利用率下实现高数值精度，并且单个FeNN核心可以比嵌入式GPU和Loihi神经形态系统更快地仿真SNN分类器。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [109] [Smart Buildings Energy Consumption Forecasting using Adaptive Evolutionary Ensemble Learning Models](https://arxiv.org/abs/2506.11864)
> *使用自适应进化集成学习模型进行智能建筑能耗预测*

*Mehdi Neshat, Menasha Thilakaratne, Mohammed El-Abd, Seyedali Mirjalili, Amir H. Gandomi, John Boland* | **Main category: cs.NE**

**Keywords:** 智能建筑, 能耗预测, 集成学习, 进化算法, Bagging

**Comment:** 

> **TL;DR:** 本研究提出并评估了三种混合集成预测模型，用于智能建筑的能耗预测，其中自适应进化Bagging模型在准确性和学习误差方面表现最佳。

**AI_Comments:** 本文的创新点在于提出了结合进化超参数调整器的混合集成学习模型，特别是自适应进化Bagging模型在复杂能耗数据预测上的显著性能提升。其重要性在于为智能建筑的能源效率管理提供了更准确、可靠的预测工具，有助于实现脱碳目标。局限性可能在于模型的泛化能力在不同类型建筑或不同气候区域的数据集上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 智能建筑能提高能源效率、降低成本并改善环境。建筑部门消耗大量全球能源，对未来脱碳至关重要。为了管理能耗和提高效率，开发可靠准确的能源需求预测模型至关重要。然而，由于时间波动和复杂的线性和非线性模式，扩展有效的建筑级电器总能耗预测模型具有挑战性。

**Method:** 本文提出了三种混合集成预测模型，结合了Bagging、Stacking和Voting机制，并与一个快速有效的进化超参数调整器相结合。该模型在一个包含气象参数、电器能耗、温度、湿度和照明能耗的混合数据集上进行了评估，数据来自比利时Stambroek蒙斯一栋建筑的18个传感器。为了进行比较，研究将该模型与15种流行的机器学习模型（包括经典ML模型、神经网络、决策树、随机森林、深度学习和集成模型）进行了比较。

**Result:** 预测结果表明，自适应进化Bagging模型在准确性和学习误差方面均优于其他预测模型。与Extreme Gradient Boosting (XGB)、Categorical Boosting (CatBoost)、GBM、LGBM和Random Forest (RF)相比，它分别实现了12.6%、13.7%、12.9%、27.04%和17.4%的准确性提升。

**Conclusion:** 本研究提出的自适应进化Bagging模型在智能建筑能耗预测方面表现出卓越的性能，能够有效应对预测挑战并显著提高准确性。

> **ai_Abstract:** 本研究旨在通过开发有效的预测模型来解决智能建筑能耗预测的挑战。论文提出了三种结合Bagging、Stacking和Voting机制以及进化超参数调整器的混合集成模型。通过与15种主流机器学习模型的比较，实验结果表明，自适应进化Bagging模型在准确性和学习误差方面均表现最佳，显著优于其他模型，为智能建筑的能源管理提供了可靠的解决方案。

> **摘要翻译:** 智能建筑因其能够提高能源效率、降低成本、改善安全性并为建筑居住者提供更舒适便捷的环境而日益普及。全球能源供应的相当一部分消耗在建筑部门，并在未来的脱碳途径中发挥着关键作用。为了管理智能建筑的能耗和提高能源效率，开发可靠准确的能源需求预测至关重要且意义重大。然而，由于时间波动以及复杂的线性和非线性模式，将有效的预测模型扩展到建筑层面电器总能耗具有挑战性。本文提出了三种混合集成预测模型，结合了Bagging、Stacking和Voting机制，并与一个快速有效的进化超参数调整器相结合。所提出的能耗预测模型的性能通过一个混合数据集进行评估，该数据集包含气象参数、电器能耗、温度、湿度以及来自比利时蒙斯Stambroek一栋建筑不同区域的照明能耗，由18个传感器收集。为了提供比较框架并研究所提出预测模型的效率，本文比较了15种流行的机器学习（ML）模型，包括两种经典ML模型、三种神经网络（NN）、一个决策树（DT）、一个随机森林（RF）、两种深度学习（DL）和六种集成模型。预测结果表明，自适应进化Bagging模型在准确性和学习误差方面均优于其他预测模型。值得注意的是，与Extreme Gradient Boosting (XGB)、Categorical Boosting (CatBoost)、GBM、LGBM和Random Forest (RF)相比，它分别实现了12.6%、13.7%、12.9%、27.04%和17.4%的准确性提升。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [30] [Analysis of Floating-Point Matrix Multiplication Computed via Integer Arithmetic](https://arxiv.org/abs/2506.11277)
> *通过整数算术计算浮点矩阵乘法的分析*

*Ahmad Abdelfattah, Jack Dongarra, Massimiliano Fasi, Mantas Mikaitis, Françoise Tisseur* | **Main category: math.NA**

**Keywords:** 浮点矩阵乘法, 整数算术, 混合精度, 误差分析, GPU计算

**Comment:** 

> **TL;DR:** 本文分析了一种将浮点矩阵乘法转换为整数矩阵乘法的方法，该方法适用于支持整数运算的混合精度单元。研究了性能与精度之间的权衡，并提出了一种估算所需乘法次数的方法，同时指出该算法在矩阵缩放不当时的局限性。

**AI_Comments:** 该论文的创新点在于提出了估算所需最小乘法次数的廉价方法，从而优化了性能与精度之间的权衡。其重要性在于为利用现代混合精度硬件（如NVIDIA Tensor Cores）进行浮点矩阵乘法提供了一种有效途径。然而，论文也指出了一个关键局限性：当输入矩阵缩放不当时，算法的准确性和效率会受到影响，这可能限制其在某些实际应用中的普适性。

<details>
  <summary>Details</summary>

**Motivation:** Ootomo、Ozaki 和 Yokota 提出了一种将浮点矩阵乘法转换为整数矩阵乘法的方法，该方法特别适用于支持整数运算的混合精度矩阵乘累加单元（如 NVIDIA Tensor Cores 或 AMD Matrix Cores）。本文旨在分析和改进这种技术，特别是解决其性能-精度权衡问题。

**Method:** 该方法将浮点矩阵 A 和 B 分割成整数切片，精确计算这些切片的乘积，然后通过浮点算术累加这些整数乘积来近似计算 AB。本文提出了一种廉价的方法来估算达到预定精度水平所需的最小乘法次数。此外，还进行了误差分析和数值实验（包括模拟和在最新 NVIDIA GPU 上进行），以验证分析并揭示算法的优缺点。

**Result:** 误差分析表明，如果矩阵 A 的行或矩阵 B 的列缩放不当，该算法可能会变得不准确或效率低下。数值实验（在模拟和最新 NVIDIA GPU 上进行）证实了理论分析，并揭示了该算法的优势和劣势。

**Conclusion:** 通过将浮点矩阵乘法转换为整数算术计算，可以利用混合精度硬件的优势，但需要仔细权衡性能和精度。算法的准确性和效率受矩阵缩放的影响，需要通过精确的乘法次数估算来优化。

> **ai_Abstract:** 本文分析并改进了 Ootomo、Ozaki 和 Yokota 提出的一种将浮点矩阵乘法转换为整数矩阵乘积的策略。该方法通过将矩阵分割成整数切片并精确计算其乘积，然后进行浮点累加来近似结果。这种技术特别适用于具有整数支持的混合精度硬件。研究揭示了性能与精度之间的权衡，并提出了一种低成本的方法来估算达到目标精度所需的最小乘法次数。误差分析表明，当输入矩阵的行或列缩放不当时，算法的准确性和效率会受到影响。数值实验在模拟和 NVIDIA GPU 上验证了这些发现，并突出了该算法的优缺点。

> **摘要翻译:** Ootomo、Ozaki 和 Yokota [Int. J. High Perform. Comput. Appl., 38 (2024), p. 297-313] 提出了一种将浮点矩阵乘法重构为整数矩阵乘积的策略。因子 A 和 B 被分割成整数切片，这些切片的乘积被精确计算，然后通过浮点算术累加这些整数乘积来近似计算 AB。该技术特别适用于支持整数运算的混合精度矩阵乘累加单元，例如 NVIDIA Tensor Core 或 AMD Matrix Core。切片数量允许在性能-精度之间进行权衡：更多切片可获得更好的精度，但需要更多乘法，这反过来会降低性能。我们提出了一种廉价的方法来估算达到预定精度水平所需的最小乘法次数。我们的误差分析表明，如果 A 的行或 B 的列缩放不当，该算法可能会变得不准确（或效率低下）。我们进行了一系列数值实验，包括模拟和在最新 NVIDIA GPU 上，这些实验证实了分析并说明了算法的优点和缺点。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [58] [Regularization for time-dependent inverse problems: Geometry of Lebesgue-Bochner spaces and algorithms](https://arxiv.org/abs/2506.11291)
> *时间相关反问题的正则化：Lebesgue-Bochner空间的几何学和算法*

*Gesa Sarnighausen, Thorsten Hohage, Martin Burger, Andreas Hauptmann, Anne Wald* | **Main category: math.NA**

**Keywords:** 时间相关反问题, 正则化, Lebesgue-Bochner空间, Tikhonov正则化, 变分正则化

**Comment:** 

> **TL;DR:** 本文利用Lebesgue-Bochner空间研究时间相关反问题，提出了两种正则化方法（Tikhonov和变分正则化），并探讨了这些空间的几何特性，通过动态计算机断层扫描示例进行了测试。

**AI_Comments:** 本文通过利用Lebesgue-Bochner空间的数学结构，为时间相关反问题提供了一种创新方法。对这些空间几何特性的深入研究，特别是针对Tikhonov正则化，是一个重要贡献，它允许在正则化过程中更细致地区分时间和空间的正则性。这有望为复杂的、时间相关的恢复任务带来更准确和鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决时间相关反问题，即从给定观测数据中恢复依赖于时间的函数或数据，并有效结合时间和空间的不同性质。

**Method:** 本文在Lebesgue-Bochner空间中提出了两种不同的正则化方法：1. Banach空间中的经典Tikhonov正则化；2. 通过惩罚时间导数进行的变分正则化。对于Tikhonov正则化，研究了Lebesgue-Bochner空间的几何特性，计算了对偶映射并证明了这些空间是幂型光滑的，从而可以在时间和空间上使用不同的正则性实现Tikhonov正则化。

**Result:** 两种方法都通过动态计算机断层扫描的例子进行了测试。

**Conclusion:** 本文开发并测试了两种基于Lebesgue-Bochner空间的正则化方法，用于解决时间相关反问题，通过利用这些空间的几何特性，能够有效处理时间和空间的不同正则性，并在动态计算机断层扫描中进行了验证。

> **ai_Abstract:** 本文针对时间相关反问题，利用Lebesgue-Bochner空间有效整合时间和空间的不同特性。文中提出了两种正则化方法：经典的Tikhonov正则化和通过惩罚时间导数实现的变分正则化。研究深入探讨了Lebesgue-Bochner空间的几何特性，尤其是在Tikhonov正则化中，计算了对偶映射并证明了这些空间是幂型光滑的，这使得Tikhonov正则化可以在时间和空间上应用不同的正则性。两种方法均通过动态计算机断层扫描的实例进行了验证。

> **摘要翻译:** 我们考虑在数学环境中，使用Lebesgue-Bochner空间处理时间相关反问题。当目标是从给定观测数据中恢复函数，且该函数或数据依赖于时间时，就会出现此类问题。Lebesgue-Bochner空间可以轻松地整合时间和空间的不同性质。在本手稿中，我们提出了两种在Lebesgue-Bochner空间中不同的正则化方法：1. Banach空间中的经典Tikhonov正则化；2. 通过惩罚时间导数进行的变分正则化。在第一种情况下，我们还研究了Lebesgue-Bochner空间的几何特性。特别是，我们计算了对偶映射，并表明这些空间是幂型光滑的。因此，我们可以在Lebesgue-Bochner空间中实现Tikhonov正则化，对时间和空间使用不同的正则性。我们使用动态计算机断层扫描的例子测试了这两种方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [86] [On existence of a variational regularization parameter under Morozov's discrepancy principle](https://arxiv.org/abs/2506.11397)
> *关于Morozov偏差原则下变分正则化参数的存在性*

*Liang Ding, Long Li, Weimin Han, Wei Wang* | **Main category: math.NA**

**Keywords:** Morozov偏差原则, 正则化参数, 存在性, 非线性逆问题, Tikhonov正则化

**Comment:** 24 pages, 10 figures

> **TL;DR:** 本文证明了在Morozov偏差原则下，当$	au_2 	au_1$满足特定条件时，正则化参数$\alpha$的存在性，并给出了正则化解的收敛性结果。

**AI_Comments:** 本文解决了在非线性逆问题背景下，Morozov偏差原则在选择Tikhonov正则化参数时面临的一个关键理论问题——参数的存在性。其创新点在于明确给出了参数存在所需的具体条件$\tau_2\ge (3+2\gamma)\tau_1$，并提供了相应的理论证明。这对于确保Morozov偏差原则在更广泛的非线性问题中的适用性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在Tikhonov正则化中，Morozov偏差原则常用于选择正则化参数。然而，对于一般的非线性逆问题，偏差不连续依赖于$\alpha$，导致正则化参数$\alpha$是否存在使得$\tau_1\delta\leq \|F(x_{\alpha}^{\delta})-y^{\delta}\|_Y\leq \tau_2 \delta$成为一个问题。

**Method:** 本文通过数学证明，在Morozov偏差原则下，当$\tau_2\ge (3+2\gamma)\tau_1$时，证明了正则化参数$\alpha$的存在性。

**Result:** 证明了当$\tau_2\ge (3+2\gamma)\tau_1$时，正则化参数$\alpha$的存在性。给出了在Morozov偏差原则下正则化解的收敛性结果。数值结果表明了所提出方法的有效性。

**Conclusion:** 本文证明了在Morozov偏差原则下，特定条件下正则化参数的存在性，并提供了正则化解的收敛性理论支持，且数值实验验证了方法的有效性。

> **ai_Abstract:** 本文针对Tikhonov正则化中Morozov偏差原则下正则化参数$\alpha$存在性问题进行了研究。鉴于非线性逆问题中偏差对$\alpha$的非连续依赖性，作者证明了在满足$\tau_2\ge (3+2\gamma)\tau_1$条件时，$\alpha$的存在性。此外，文章还探讨了正则化解的收敛性，并通过数值实验验证了方法的有效性。

> **摘要翻译:** Morozov偏差原则常被Tikhonov正则化用于选择正则化参数。然而，对于一般的非线性逆问题，偏差$\|F(x_{\alpha}^{\delta})-y^{\delta}\|_Y$并不连续依赖于$\alpha$，因此是否存在正则化参数$\alpha$使得$\tau_1\delta\leq \|F(x_{\alpha}^{\delta})-y^{\delta}\|_Y\leq \tau_2 \delta$（其中$1\le \tau_1<\tau_2$）是值得怀疑的。在本文中，我们证明了在Morozov偏差原则下，如果$\tau_2\ge (3+2\gamma)\tau_1$，则$\alpha$的存在性成立，其中$\gamma>0$是非线性算子$F$的切锥条件中的一个参数。此外，我们还给出了在Morozov偏差原则下正则化解的收敛性结果。数值结果报告了所提出方法的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [113] [Transformed Diffusion-Wave fPINNs: Enhancing Computing Efficiency for PINNs Solving Time-Fractional Diffusion-Wave Equations](https://arxiv.org/abs/2506.11518)
> *变换扩散波分数阶物理信息神经网络（tDWfPINNs）：提升PINNs求解时间分数阶扩散波方程的计算效率*

*Jing Li, Zhengqi Zhang* | **Main category: math.NA**

**Keywords:** 分数阶扩散波方程, 物理信息神经网络, 计算效率, 积分变换, 自适应采样

**Comment:** 

> **TL;DR:** 提出tDWfPINNs，通过引入积分变换技术，显著提高求解时间分数阶扩散波方程的PINNs的计算效率和精度。

**AI_Comments:** 这篇论文通过引入积分变换技术，有效地解决了物理信息神经网络（PINNs）在处理时间分数阶导数时计算成本过高的问题，是PINNs在分数阶方程领域应用的一个重要创新。其无网格特性和高效率使其成为求解复杂分数阶模型的有前景的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统数值方法在求解时间分数阶扩散波方程时，要么牺牲物理信息神经网络（PINNs）的无网格优势，要么在计算分数阶导数时产生高计算成本。

**Method:** 本文提出变换扩散波分数阶物理信息神经网络（tDWfPINNs），通过引入积分变换技术避免在正交点处进行一阶导数计算，从而显著降低分数阶导数评估的计算成本。该方法结合了蒙特卡洛积分和高斯-雅可比正交方案，并应用于各种时间分数阶偏微分方程，还将其整合到基于残差的自适应分布（RAD）等自适应采样方法中。

**Result:** tDWfPINNs在不牺牲精度的情况下实现了卓越的计算效率。实验表明，高斯-雅可比方法通常优于蒙特卡洛方法，但需要仔细选择正交点数量。

**Conclusion:** 所提出的tDWfPINNs在时间分数阶扩散波方程的数值求解方面取得了显著进展，为具有挑战性的分数阶模型提供了一种准确且可扩展的无网格替代方案。

> **ai_Abstract:** 本文提出变换扩散波分数阶物理信息神经网络（tDWfPINNs），旨在高效求解时间分数阶扩散波方程。针对传统方法在计算分数阶导数时的高成本问题，该方法引入积分变换技术，避免一阶导数计算，显著降低了计算成本并保持精度。通过与蒙特卡洛和高斯-雅可比正交方案结合的比较分析，证明了tDWfPINNs在计算效率上的优越性。此外，该方法还被整合到自适应采样策略中，进一步验证了其在复杂分数阶模型中的准确性和可扩展性。

> **摘要翻译:** 我们提出了变换扩散波分数阶物理信息神经网络（tDWfPINNs），用于高效求解分数阶数 \(\alpha\in(1,2)\) 的时间分数阶扩散波方程。这些方程的传统数值方法通常会损害物理信息神经网络（PINNs）的无网格优势，或在计算分数阶导数时产生高计算成本。所提出的方法通过引入一种积分变换技术，避免在正交点处进行一阶导数计算，从而显著降低了与分数阶导数评估相关的计算成本，同时保持了精度。我们对这种积分变换结合蒙特卡洛积分和高斯-雅可比正交方案在各种时间分数阶偏微分方程中的应用进行了全面的比较分析。我们的结果表明，tDWfPINNs 在不牺牲精度的情况下实现了卓越的计算效率。此外，我们将所提出的方法整合到自适应采样方法中，例如用于阶数 \(\alpha\in(1,2)\) 的时间分数阶Burgers方程的基于残差的自适应分布（RAD），该方程表现出复杂的解动力学。实验表明，高斯-雅可比方法通常优于蒙特卡洛方法；然而，在选择正交点数量时需要仔细考虑。总的来说，所提出的 tDWfPINNs 在时间分数阶扩散波方程的数值解方面取得了显著进展，为具有挑战性的分数阶模型提供了一种准确且可扩展的无网格替代方案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [140] [Error Analysis of Truncation Legendre Method for Solving Numerical Differentiation](https://arxiv.org/abs/2506.11529)
> *截断勒让德方法求解数值微分的误差分析*

*Maksym Kyselov* | **Main category: math.NA**

**Keywords:** 数值微分, 截断勒让德方法, 误差分析, 加权维纳类, 最优收敛率

**Comment:** 25 pages, 4 sections. Extends previous results on Legendre-based
  numerical differentiation to arbitrary derivative orders and L_q metrics

> **TL;DR:** 研究了加权维纳类函数的数值微分问题，构建并分析了一种截断勒让德方法，以恢复任意阶导数，并建立了精确的误差界限和最优收敛率。

**AI_Comments:** 该论文创新性地将截断勒让德方法应用于恢复加权维纳类函数的任意阶导数，并进行了全面的误差分析，超越了以往仅关注一阶导数和特定函数空间的研究。其重要性在于为数值微分提供了更精确和普遍适用的工具，对于信号处理、图像分析等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究主要集中在函数的一阶导数和特定函数空间，而本文旨在对更广泛的函数正则性参数和多种误差度量进行全面分析，以解决任意阶导数的恢复问题。

**Method:** 构建并分析了一种截断勒让德方法来恢复加权维纳类函数的任意阶导数。该方法关注在积分和均匀度量中获取误差估计，并确定了最优截断参数。

**Result:** 建立了截断方法在C和L_q (2 <= q <= infinity) 度量下的精确误差界限。确定了作为误差水平和光滑度参数函数的最佳截断参数。结果表明，该截断方法在加权维纳类上实现了最优收敛率，并且需要最优数量的扰动傅里叶-勒让德系数来有效恢复导数。

**Conclusion:** 截断勒让德方法在加权维纳类函数数值微分中表现出优异的性能，能够以最优收敛率恢复任意阶导数，并通过最优数量的傅里叶-勒让德系数实现有效恢复。

> **ai_Abstract:** 本文研究了加权维纳类函数的数值微分问题，提出并分析了一种截断勒让德方法以恢复任意阶导数。研究建立了在C和L_q度量下的精确误差界限，并确定了最优截断参数。结果表明该方法在加权维纳类上实现了最优收敛率，且仅需最优数量的傅里叶-勒让德系数即可有效恢复导数，填补了之前研究在导数阶数和函数空间上的空白。

> **摘要翻译:** 我们研究了加权维纳类函数的数值微分问题。我们构建并分析了一种截断勒让德方法来恢复任意阶导数。主要关注点是在积分和均匀度量中获取误差估计。与之前主要关注一阶导数和特定函数空间的研究不同，我们对广泛的函数正则性参数和各种误差度量进行了全面分析。我们建立了截断方法在C和L_q（2 ≤ q ≤ ∞）度量下的精确误差界限，并确定了作为误差水平和光滑度参数函数的最佳截断参数。我们的结果表明，截断方法在加权维纳类上实现了最优收敛率，需要最优数量的扰动傅里叶-勒让德系数才能有效恢复导数。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [163] [Refined stability estimates for mixed problems by exploiting semi norm arguments](https://arxiv.org/abs/2506.11566)
> *利用半范数论证的混合问题改进稳定性估计*

*Nicolas Gauger, Alexander Linke, Christian Merdon* | **Main category: math.NA**

**Keywords:** 稳定性估计, 混合问题, 半范数, 物理区域, 离散化

**Comment:** 

> **TL;DR:** 本文为经典的混合问题推导了改进的稳定性估计，强调数据泛函上半范数的重要性，并展示其核与物理区域的联系，从而获得了更尖锐的稳定性估计。

**AI_Comments:** 该论文通过引入和利用半范数论证，为混合问题的稳定性分析提供了新的视角。其创新之处在于将半范数的核与物理区域和一致性误差联系起来，从而在特定条件下获得了更精细、更尖锐的稳定性估计，这对于提高数值离散化的精度和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 受不可压缩Navier-Stokes方程压力鲁棒离散化最新进展的启发，该研究强调了数据泛函上半范数的重要性，并旨在获得针对经典混合问题更尖锐的稳定性估计。

**Method:** 通过利用半范数论证，研究了数据泛函上半范数的重要性。具体地，展示了这些半范数的核与应用中的物理区域相关联，并且与经典混合问题离散化中一些众所周知的相容性误差有关。

**Result:** 获得了针对接近这些物理区域的解的显著更尖锐的稳定性估计。

**Conclusion:** 通过利用半范数并揭示其核与物理区域及相容性误差的联系，可以为经典混合问题推导出显著更尖锐的稳定性估计。

> **ai_Abstract:** 本文针对经典的混合问题，推导了改进的稳定性估计。研究强调了数据泛函上半范数的重要性，其灵感来源于不可压缩Navier-Stokes方程压力鲁棒离散化的最新进展。研究表明，这些半范数的核与实际应用中的物理区域以及经典混合问题离散化中的一致性误差有关。最终，这使得能够获得针对接近这些物理区域的解的显著更尖锐的稳定性估计。

> **摘要翻译:** 经典混合问题的改进稳定性估计被推导出来。新颖的重点在于数据泛函上半范数的重要性，这受到了不可压缩Navier-Stokes方程压力鲁棒离散化最新进展的启发。事实上，这些半范数的核被证明与应用中的物理区域相关联，并且与经典混合问题离散化中一些众所周知的相容性误差有关。因此，获得了针对接近这些物理区域的解的显著更尖锐的稳定性估计。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [181] [Quasi-Monte Carlo hyperinterpolation](https://arxiv.org/abs/2506.11622)
> *拟蒙特卡罗超插值*

*Congpei An, Mou Cai, Takashi Goda* | **Main category: math.NA**

**Keywords:** 拟蒙特卡罗, 超插值, 高维近似, 维度灾难, Lasso

**Comment:** 

> **TL;DR:** 本文提出了一种新的拟蒙特卡罗超插值方法，用于解决高维超插值中传统精确求积规则的限制，并展示了其与传统方法相当的精度，同时避免了维度灾难。

**AI_Comments:** 这篇论文通过引入 QMC 规则，成功地将超插值方法推广到高维空间，解决了传统方法中精确求积假设的局限性，具有重要的理论和实际意义。其创新之处在于利用 QMC 的优势来处理高维问题，并进一步通过 Lasso 方法增强了算法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统超插值方法在高维背景下依赖于精确求积假设，这变得不切实际。因此，需要一种新的方法来克服这一限制。

**Method:** 本文通过用拟蒙特卡罗 (QMC) 规则替换精确求积规则，提出了一种新颖的近似方案，称为范围为 I 的 QMC 超插值。具体地，提供了使用某些格点规则构建 QMC 超插值的具体算法。此外，还引入了一种基于 Lasso 的方法来提高 QMC 超插值对采样过程噪声的鲁棒性。

**Result:** QMC 超插值实现了与传统超插值相当的精度，同时避免了维度灾难。数值实验验证了所提出方法的有效性，显示出近似精度的显著提高。

**Conclusion:** QMC 超插值是一种有效且鲁棒的高维近似方法，能够克服传统超插值在高维环境下的局限性，并保持高精度。

> **ai_Abstract:** 本文针对高维超插值中传统精确求积规则不切实际的问题，提出了一种基于拟蒙特卡罗 (QMC) 规则的新型超插值方法，称为 QMC 超插值。该方法通过引入 QMC 规则和新颖的近似方案，克服了对精确求积的依赖。研究表明，QMC 超插值在保持与传统方法相当精度的同时，有效地避免了维度灾难。此外，通过引入基于 Lasso 的方法，进一步增强了其对噪声的鲁棒性。数值实验验证了所提方法的有效性和精度提升。

> **摘要翻译:** 本文研究了高维单位超立方体上超插值的推广。m 次超插值作为相同次数 L2-正交投影的离散近似，它使用通过正权求积规则评估的傅里叶系数，该规则能精确积分所有次数高达 2m 的多项式。传统的超插值方法通常依赖于精确求积假设，这在高维背景下可能不切实际。我们通过用拟蒙特卡罗 (QMC) 规则替换精确求积规则，解决了超插值中的挑战和进步，绕过了求积规则精确性的假设，并提出了一种带有索引集 I 的新型近似方案，称为范围为 I 的 QMC 超插值。特别是，我们提供了使用某些格点规则构建 QMC 超插值的具体算法。因此，我们表明 QMC 超插值实现了与传统超插值相当的精度，同时避免了维度灾难。此外，我们引入了一种基于 Lasso 的方法来提高 QMC 超插值对采样过程噪声的鲁棒性。数值实验验证了我们所提出方法的有效性，显示出近似精度的显著提高。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [201] [Deep Symmetric Autoencoders from the Eckart-Young-Schmidt Perspective](https://arxiv.org/abs/2506.11641)
> *基于Eckart-Young-Schmidt视角的深度对称自编码器*

*Simone Brivio, Nicola Rares Franco* | **Main category: math.NA**

**Keywords:** 深度自编码器, 对称自编码器, Eckart-Young-Schmidt定理, 初始化策略, 奇异值分解

**Comment:** 28 pages, 10 figures

> **TL;DR:** 本文通过引入Eckart-Young-Schmidt定理，为深度对称自编码器提供了理论基础，并开发了一种基于SVD的初始化策略。

**AI_Comments:** 本文的创新之处在于，它首次将Eckart-Young-Schmidt (EYS) 定理引入到深度对称自编码器的理论分析中，为这类广泛使用的深度学习架构提供了坚实的数学基础。提出的EYS初始化策略也具有重要的实践意义，有望提高对称自编码器的性能和训练稳定性。这项工作对于理解深度学习模型的内在机制及其理论边界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度自编码器在各种机器学习应用中取得了经验上的成功，但其表达能力的坚实理论基础仍然难以捉摸，特别是与经典的基于投影的技术相比。

**Method:** 本文对对称自编码器进行了全面分析，形式上区分了不同类别的对称架构，并从数学角度分析了它们的优缺点。研究表明，带有正交性约束的对称自编码器的重建误差可以通过Eckart-Young-Schmidt (EYS) 定理来理解。作为分析的副产品，开发了一种基于奇异值分解 (SVD) 迭代应用的EYS初始化策略。

**Result:** 研究发现，带有正交性约束的对称自编码器的重建误差可以利用Eckart-Young-Schmidt (EYS) 定理来理解。同时，开发了EYS初始化策略。数值实验验证了所提出的方法与传统深度自编码器相比的有效性。

**Conclusion:** 本文讨论了模型设计和初始化的重要性，并为深度对称自编码器提供了理论上的理解和新的初始化方法。

> **ai_Abstract:** 本文旨在为深度对称自编码器提供一个坚实的理论基础，弥补其在表达能力理论分析方面的不足。研究通过引入Eckart-Young-Schmidt (EYS) 定理，证明了带有正交性约束的对称自编码器的重建误差与EYS定理的关联性。在此基础上，提出了一种基于奇异值分解 (SVD) 迭代应用的EYS初始化策略。数值实验验证了该方法的有效性，并强调了模型设计和初始化的重要性。

> **摘要翻译:** 深度自编码器已成为各种机器学习应用中的基本工具，从降维、偏微分方程的降阶建模到异常检测和神经机器翻译。尽管它们取得了经验上的成功，但其表达能力的坚实理论基础仍然难以捉摸，特别是与经典的基于投影的技术相比。在这项工作中，我们旨在朝着这个方向迈出一步，对我们所称的对称自编码器进行全面分析，这是一类在文献中普遍存在的深度学习架构。具体来说，我们形式上区分了不同类别的对称架构，从数学角度分析了它们的优势和局限性。例如，我们展示了带有正交性约束的对称自编码器的重建误差可以通过利用著名的Eckart-Young-Schmidt (EYS) 定理来理解。作为我们分析的副产品，我们最终开发了用于对称自编码器的EYS初始化策略，该策略基于奇异值分解 (SVD) 的迭代应用。为了验证我们的发现，我们进行了一系列数值实验，将我们的提议与传统的深度自编码器进行了基准测试，讨论了模型设计和初始化的重要性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [219] [Fast parallel transient electromagnetic modeling using a uniform-in-time approximation to the exponential](https://arxiv.org/abs/2506.11657)
> *快速并行瞬变电磁建模，利用指数函数的均匀时间近似*

*Ralph-Uwe Börner, Stefan Güttel* | **Main category: math.NA**

**Keywords:** 瞬变电磁, 并行建模, 矩阵指数, 有理近似, 部分分式分解

**Comment:** 

> **TL;DR:** 提出了一种新的并行瞬变电磁（TEM）场正演建模方法，该方法基于矩阵指数函数的均匀时间有理近似，实现了高并行效率，且并行求解的线性系统数量不依赖于时间通道或空间离散化。

**AI_Comments:** 这项研究的创新之处在于利用具有公共分母的均匀时间有理近似以及部分分式分解，有效地解耦了计算复杂性与时间通道和空间离散化之间的依赖关系。这对于大规模瞬变电磁模拟而言，可能意味着显著的并行效率提升，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种用于瞬变电磁（TEM）场并行正演建模的新方法，以提高计算速度和并行效率。

**Method:** 该方法基于矩阵指数函数的一族均匀时间有理近似，这些近似共享一个与评估时间点无关的公共分母。通过利用该族近似的部分分式分解，设计了一个具有高并行效率的快速求解器。并行求解所需的移位线性系统数量不依赖于所需的时间通道数量或空间离散化。

**Result:** 开发出一种具有高并行效率的快速求解器，其并行求解的线性系统数量不依赖于所需的时间通道数量或空间离散化。此外，预计在解决TEM反演问题时也能获得类似的并行效率增益。

**Conclusion:** 该论文提出了一种利用均匀时间有理近似的瞬变电磁正演建模新方法，实现了高并行效率，且其计算复杂性独立于时间通道和空间离散化，有望在正演和反演问题中都带来显著的效率提升。

> **ai_Abstract:** 本文介绍了一种针对瞬变电磁（TEM）场并行正演建模的新方法。该方法利用了矩阵指数函数的一族均匀时间有理近似，其特点是共享一个与评估时间点无关的公共分母。通过对这些近似进行部分分式分解，该方法能够构建一个具有高并行效率的快速求解器。值得注意的是，并行求解所需的移位线性系统数量与所需的时间通道数量或空间离散化无关。作者还指出，在解决TEM反演问题时，预期也能获得类似的并行效率增益。

> **摘要翻译:** 提出了一种用于瞬变电磁（TEM）场并行正演建模的新方法。该方法基于矩阵指数函数的一族均匀时间有理近似，这些近似共享一个与评估时间点无关的公共分母。利用该族近似的部分分式分解来设计一种具有高并行效率的快速求解器。并行求解所需的移位线性系统数量不依赖于所需的时间通道数量或空间离散化。我们还认为，在解决TEM反演问题时，也可以预期类似的并行效率增益。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [233] [Automatic differentiation for Lax-Wendroff-type discretizations](https://arxiv.org/abs/2506.11719)
> *Lax-Wendroff型离散化的自动微分*

*Arpit Babbar, Valentin Churavy, Michael Schlottke Lakemper, Hendrik Ranocha* | **Main category: math.NA**

**Keywords:** 自动微分, Lax-Wendroff方法, 双曲守恒律, 间断Galerkin, 数值模拟

**Comment:** 

> **TL;DR:** 本文将自动微分（AD）引入Lax-Wendroff方法中的局部时间平均通量计算步骤，以解决双曲守恒律问题。该方法适用于任意阶数，无需正性校正，且性能与现有近似方法相当。

**AI_Comments:** 这项工作的创新之处在于将自动微分引入到Lax-Wendroff方法的关键步骤中，从而极大地简化了高阶方法的实现，并消除了对复杂正性校正的需求。这种方法提高了Lax-Wendroff算法的通用性和易用性，使其能够更直接地应用于各种物理通量函数。其“无雅可比矩阵”和“与问题无关”的特性也显著提升了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的近似Lax-Wendroff过程需要针对不同阶数使用不同的有限差分公式，并且在预测步骤中对通量进行正性校正，这限制了其通用性和便捷性。本文旨在通过引入自动微分来克服这些局限性。

**Method:** 作者在Lax-Wendroff方法结合间断Galerkin/通量重构空间离散化的背景下，将自动微分（AD）引入到单元局部时间平均通量计算步骤（预测步骤）中。该方法是无雅可比矩阵且与问题无关的。

**Result:** 引入自动微分的Lax-Wendroff方法适用于任意阶数，且在预测步骤中不需要正性校正。该方法是无雅可比矩阵且与问题无关的，可以直接应用于任何物理通量函数。数值实验证明了该方法的阶数和正性保持能力。性能比较表明，自动微分的墙钟时间始终与近似Lax-Wendroff方法相当。

**Conclusion:** 将自动微分应用于Lax-Wendroff方法的预测步骤，提供了一种高阶、单阶段、无求积的有效且通用的求解双曲守恒律的方法。它简化了不同阶数方法的应用，消除了预测步骤中的正性校正需求，并保持了与现有方法相当的性能。

> **ai_Abstract:** 本文提出了一种将自动微分（AD）应用于Lax-Wendroff方法中局部时间平均通量计算（预测）步骤的新方法，用于求解双曲守恒律。与传统方法不同，该AD方法适用于任意阶数，无需在预测步骤中进行正性校正，并且是无雅可比矩阵且与问题无关的。数值实验验证了其阶数和正性保持能力，并显示其计算效率与现有近似Lax-Wendroff方法相当。

> **摘要翻译:** Lax-Wendroff方法结合间断Galerkin/通量重构空间离散化，为求解双曲守恒律提供了一种高阶、单阶段、无求积的方法。在这项工作中，我们将在Lax-Wendroff方法的单元局部时间平均通量计算步骤（预测步骤）中引入自动微分（AD）。AD的应用对于任何阶数的方法都是相似的，并且在预测步骤中不需要正性校正。这与近似Lax-Wendroff过程形成对比，后者需要针对不同阶数的方法使用不同的有限差分公式，并且在预测步骤中对只能在可接受状态下计算的通量进行正性校正。该方法是无雅可比矩阵且与问题无关的，允许直接应用于任何物理通量函数。数值实验证明了该方法的阶数和正性保持能力。此外，性能比较表明，自动微分的墙钟时间始终与近似Lax-Wendroff方法相当。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [249] [Data-driven approaches to inverse problems](https://arxiv.org/abs/2506.11732)
> *数据驱动的逆问题方法*

*Carola-Bibiane Schönlieb, Zakhar Shumaylov* | **Main category: math.NA**

**Keywords:** 逆问题, 数据驱动, 深度学习, 对抗性正则化, 即插即用去噪器

**Comment:** Notes from Machine Learning: From Data to Mathematical Understanding
  (CIME 2023)

> **TL;DR:** 本文介绍了逆问题的数据驱动方法，强调其在解决传统方法局限性方面的准确性和计算效率。

**AI_Comments:** 这篇论文（笔记）系统地介绍了逆问题的数据驱动方法，突出了其在解决传统方法局限性方面的创新性和重要性。通过结合理论分析和数值示例，为读者提供了全面的理解。特别关注对抗性正则化和即插即用去噪器，表明其关注当前前沿研究。

<details>
  <summary>Details</summary>

**Motivation:** 逆问题在多个领域至关重要，但通常是不适定的。经典方法虽然严谨，但在模型化解的属性和高效实现方面存在局限性，这促使了数据驱动方法的兴起，以实现更高的精度和计算效率。

**Method:** 本文（笔记）首先介绍逆问题和经典求解策略，并给出应用。然后深入探讨现代数据驱动方法，重点关注对抗性正则化和可证明收敛的线性即插即用去噪器。在介绍这些方法时，将讨论它们的理论性质并提供数值示例。

**Result:** 本文（笔记）将展示数据驱动方法在逆问题求解中实现的精度和计算效率，这些是传统方法难以企及的。通过理论讨论和数值示例，阐明这些方法的有效性。最后将讨论开放问题和未来展望。

**Conclusion:** 本系列讲座将总结逆问题领域中悬而未决的问题和未来的展望。

> **ai_Abstract:** 本文（笔记）旨在介绍逆问题的数据驱动方法，以应对经典方法在处理不适定问题时的局限性。它将涵盖逆问题的基础、经典求解策略及其应用，并重点探讨现代数据驱动范式，特别是对抗性正则化和可证明收敛的线性即插即用去噪器。文章将讨论这些方法的理论特性并提供数值示例，最后展望该领域的开放问题和未来方向。

> **摘要翻译:** 逆问题关注利用间接测量重建未知物理量，是医学成像、遥感和材料科学等多个领域的基础。这些问题是可视化肉眼不可见内部结构的关键工具，能够实现量化、诊断、预测和发现。然而，大多数逆问题都是不适定的，需要鲁棒的数学处理才能得到有意义的解。虽然经典方法提供了数学上严谨且计算稳定的解，但它们受限于准确建模解的属性和高效实现的能力。
  一种更新的范式考虑以数据驱动的方式推导逆问题的解。这种方法不再依赖于经典的数学建模，而是利用高度过参数化的模型，通常是深度神经网络，通过精心选择的训练数据适应特定的逆问题。遵循这种新范式的当前方法以其解决方案的准确性与以前难以想象的计算效率相结合而著称。
  这些笔记旨在介绍逆问题的数据驱动范式。笔记的第一部分将介绍逆问题，讨论经典的求解策略，并展示一些应用。第二部分将深入探讨现代数据驱动方法，特别关注对抗性正则化和可证明收敛的线性即插即用去噪器。在介绍这些方法的过程中，将讨论它们的理论性质，并提供数值示例。本系列讲座将以对该领域开放问题和未来展望的讨论作结。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [265] [Learning to Integrate](https://arxiv.org/abs/2506.11801)
> *学习积分*

*Oliver G. Ernst, Hanno Gottschalk, Toni Kowalewitz, Patrick Krüger* | **Main category: math.NA**

**Keywords:** 不确定性量化, 传输映射, 稀疏网格, 神经网络, 归一化流

**Comment:** 

> **TL;DR:** 本研究提出了一种结合学习到的传输映射和稀疏网格技术的方法，用于对具有复杂输入分布的资源密集型模拟进行不确定性量化。通过将复杂分布转换为多元标准正态分布，从而能够应用高效的稀疏网格积分。

**AI_Comments:** 这项工作的创新之处在于，它通过引入学习到的传输映射，有效地弥合了高效稀疏网格积分方法（通常仅限于简单分布）与实际中遇到的复杂输入分布之间的鸿沟。这极大地扩展了稀疏网格技术在不确定性量化领域的适用范围，使其能够处理更广泛的实际问题。论文中对方法数学假设和局限性的讨论也增加了其严谨性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的高效数值方法（如基于稀疏网格的积分方法）主要适用于高维高斯分布或其他可分离分布，但实际中遇到的输入数据往往不属于此类，导致不确定性量化面临挑战。

**Method:** 本研究采用传输映射将复杂的输入分布转换为多元标准正态分布。这些映射通过生成式学习中的神经网络架构（例如仿射耦合流和基于常微分方程的网络如条件流匹配）近似学习得到。为了计算感兴趣量的期望，该方法对学习到的传输映射的逆函数与模拟代码输出的组合进行数值积分。由于积分是在多元高斯分布上进行的，因此可以应用稀疏网格（SG）技术。稀疏网格求积节点的图像被视为给定复杂分布的学习求积节点。

**Result:** 该方法在总阶数单项式上得到了验证，对于这些单项式，未映射的稀疏网格规则是精确的。它还应用于具有指数化Lévy随机场建模系数的稳态扩散方程，使用了9和25模式的Karhunen-Loève类模态展开。通过一系列数值实验，研究了学习精度、求积、统计估计、输入随机场模态系列截断以及三种归一化流（ACF、条件流匹配和最优传输流匹配）的训练数据大小所引起的误差。

**Conclusion:** 本研究提出了一种有效的方法，通过学习传输映射将复杂输入分布转换为标准正态分布，从而使得稀疏网格积分技术能够应用于资源密集型模拟中的不确定性量化问题。该方法讨论了其数学假设，并指出了在这些假设被违反时的局限性。

> **ai_Abstract:** 本论文提出了一种针对资源密集型模拟中复杂输入分布的不确定性量化方法。该方法利用神经网络学习的传输映射将非高斯或复杂分布转换成多元标准正态分布，从而能够应用高效的稀疏网格积分技术。具体而言，它对学习到的传输映射的逆函数与模拟输出的组合进行积分。论文通过数值实验验证了该方法在不同问题上的有效性，包括扩散方程，并分析了学习精度、求积和数据量等因素对误差的影响，同时讨论了方法的数学前提及其局限性。

> **摘要翻译:** 这项工作处理的是针对某些资源密集型模拟（例如需要求解偏微分方程的模拟）的通用输入分布的不确定性量化问题。虽然存在基于稀疏网格（SG）的有效数值方法来计算高维高斯分布和其他可分离分布的积分，但实际中出现的输入数据通常不属于此类。因此，我们采用传输映射将复杂分布转换为多元标准正态分布。在生成式学习中，已经引入了许多神经网络架构来近似完成这项任务。例如仿射耦合流（ACF）和基于常微分方程的网络，如条件流匹配（CFM）。为了计算感兴趣量的期望，我们对学习到的传输映射的逆函数与模拟代码输出的组合进行数值积分。由于此映射是在多元高斯分布上进行积分的，因此可以应用稀疏网格技术。将稀疏网格求积节点的图像视为给定复杂分布的学习求积节点，这启发了我们的标题。我们展示了我们的方法在总阶数单项式上的应用，对于这些单项式，未映射的稀疏网格规则是精确的。我们还将我们的方法应用于具有指数化Lévy随机场建模系数的稳态扩散方程，使用9和25模式的Karhunen-Loève类模态展开。在一系列数值实验中，我们研究了由学习精度、求积、统计估计、输入随机场模态系列截断以及三种归一化流（ACF、条件流匹配和最优传输流匹配）的训练数据大小所引起的误差。我们讨论了我们方法所基于的数学假设，并展示了当这些假设被违反时的缺点。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [278] [Random Batch Methods for Discretized PDEs on Graphs](https://arxiv.org/abs/2506.11809)
> *随机批处理方法用于图上的离散偏微分方程*

*Martín Hernández, Enrique Zuazua* | **Main category: math.NA**

**Keywords:** 随机批处理方法, 图上PDEs, 热方程, 离散化, 计算效率

**Comment:** 

> **TL;DR:** 提出了一种名为“discretize+RBM”的随机批处理方法，用于在图上高效地求解离散PDEs，特别是在热方程上，并通过数值实验验证了其收敛性和计算效率。

**AI_Comments:** 该算法是域分解的一种随机变体，专门适用于图上的PDEs，并具有广泛的适用性，可应用于各种线性PDEs，同时保持可比的分析保证和收敛性。其创新之处在于将RBM与PDE离散化结合，有效解决了图上PDEs的计算效率问题，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决图结构上偏微分方程（PDEs）通常需要大量内存和计算资源。随机批处理方法（RBM）可以显著降低计算成本，模拟大规模系统。

**Method:** 提出了一种名为“discretize+RBM”的两步方法，首先将PDE离散化为有限维问题，然后应用RBM，特别针对一维图上的热方程。

**Result:** 建立了该方法在期望意义上的收敛性，并将研究结果扩展到图上热方程的最优控制。数值实验证实了该方法的有效性和计算效率，展示了收敛性并显著降低了计算成本。

**Conclusion:** 该算法可视为域分解的一种随机变体，专门适用于图结构上的PDEs，并具有普适性，可应用于各种线性PDEs，并保持可比的分析保证和收敛性。

> **ai_Abstract:** 本文提出了一种创新的“discretize+RBM”方法，用于解决图结构上偏微分方程（PDEs）的计算挑战。该方法通过将PDE离散化为有限维问题，然后应用随机批处理方法（RBM），显著降低了大规模系统模拟所需的内存和计算资源。研究证明了该方法在期望意义上的收敛性，并将其扩展到图上热方程的最优控制。数值实验验证了其有效性、收敛性及显著的计算成本降低。该算法可视为域分解的随机变体，具有广泛的适用性，可应用于多种线性PDEs。

> **摘要翻译:** 气体传输及其他复杂的实际挑战常需解决和控制图结构上定义的偏微分方程（PDEs），这通常需要大量的内存和计算资源。随机批处理方法（RBM）通过以降低的计算成本模拟大规模系统，显著缓解了这些需求。
在本文中，我们分析了RBM在解决一维图上PDEs的应用，特别关注热方程。我们的方法涉及一个两步过程：首先将PDE离散化以将其转化为有限维问题，然后应用RBM。我们将这种集成方法称为“discretize+RBM”。我们建立了该方法在期望意义上的收敛性，前提是适当选择和同时减少RBM中的切换参数和离散化参数。此外，我们将这些发现扩展到包括图上热方程的最优控制，增强了我们方法的实用性。所提出解决方案的有效性和计算效率通过数值实验得到了证实，这些实验不仅证明了收敛性，还显示出计算成本的显著降低。
我们的算法可以看作是域分解的一种随机变体，专门适用于图结构上定义的PDEs。它足够通用，可以应用于各种线性PDEs——不仅仅是热方程——同时保持可比的分析保证和收敛性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [290] [Second-Order Linear Relaxation Schemes for Time-Fractional Phase-Field Models](https://arxiv.org/abs/2506.11817)
> *时间分数阶相场模型的二阶线性松弛格式*

*Hui Yu, Zhaoyang Wang, Ping Lin* | **Main category: math.NA**

**Keywords:** 时间分数阶,相场模型,线性松弛,数值格式,能量稳定

**Comment:** 

> **TL;DR:** 本文提出了一种用于时间分数阶Allen-Cahn和Cahn-Hilliard方程的二阶线性松弛数值格式，该格式线性、时间二阶精确，且被证明是无条件能量稳定的。

**AI_Comments:** 这项工作提出了一种新颖的线性松弛方法来处理时间分数阶相场模型中的非线性项，通过将非线性项转化为代数方程求解，显著简化了计算复杂性，并避免了IEQ和SAV方法中可能存在的数值稳定性问题。其证明的无条件能量稳定性是该方法的重要优势，确保了数值模拟的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为时间分数阶Allen-Cahn和Cahn-Hilliard方程开发高效的数值格式。

**Method:** 采用线性松弛方法，利用L1+-CN公式离散分数阶导数，并通过引入辅助变量将非线性项近似为代数方程求解，而非微分方程，从而避免了IEQ和SAV方法的复杂性。

**Result:** 提出的半离散格式是线性的，时间上二阶精确，辅助变量与原始变量之间的不一致性不随时间恶化，且被证明是无条件能量稳定的。数值结果证实了该格式的有效性。

**Conclusion:** 所提出的线性松弛数值格式对于时间分数阶相场模型是有效且无条件能量稳定的。

> **ai_Abstract:** 本文提出了一种针对时间分数阶Allen-Cahn和Cahn-Hilliard方程的二阶线性松弛数值格式。该方法通过L1+-CN公式离散分数阶导数，并巧妙地引入辅助变量将非线性项转化为代数方程求解，避免了传统IEQ和SAV方法的复杂性。该格式具有线性、时间二阶精度、不一致性不恶化以及无条件能量稳定性的优点，并通过数值实验验证了其有效性。

> **摘要翻译:** 这项工作使用线性松弛方法为时间分数阶Allen-Cahn和Cahn-Hilliard方程开发了高效的数值格式。L1+-CN公式用于离散分数阶导数，并引入了一个辅助变量，通过求解代数方程而不是像不变能量二次化（IEQ）和标量辅助变量（SAV）方法那样求解微分方程来近似非线性项。所提出的半离散格式是线性的，时间上二阶精确，并且辅助变量与原始变量之间的不一致性不会随时间恶化。此外，我们证明了该格式是无条件能量稳定的。数值结果证明了所提出格式的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [303] [Fourth- and Higher-order Interface Tracking of Three or More Materials with Arbitrarily Complex Topology and Geometry](https://arxiv.org/abs/2506.11897)
> *三种或更多材料具有任意复杂拓扑和几何形状的四阶及更高阶界面跟踪*

*Yan Tan, Yixiao Qian, Zhiqi Li, Qinghai Zhang* | **Main category: math.NA**

**Keywords:** 界面跟踪, 多相流, MARS方法, 高阶精度, 复杂拓扑

**Comment:** 

> **TL;DR:** 提出了一种多相三次MARS方法，用于对具有任意复杂拓扑和几何形状的多材料进行高阶、准确、高效的界面跟踪，能够轻松处理传统方法难以应对的交界点。

**AI_Comments:** 这项研究通过引入多相三次MARS方法，显著提升了多材料界面跟踪的精度和效率，尤其在处理复杂拓扑、几何以及关键的交界点方面展现出创新性。其高阶精度和对复杂情况的鲁棒性使其在计算流体力学等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理二维中任意数量材料的界面跟踪时面临挑战，尤其是在精确表示复杂拓扑和几何结构，以及处理各类交界点方面。

**Method:** 本文提出了一种多相三次MARS方法。该方法通过图、循环和三次样条精确高效地表示界面拓扑和几何结构；维持界面的(r,h)正则条件，确保相邻标记间距在指定范围内；适用于具有任意复杂拓扑和几何的多材料；并在时间和空间上均达到四阶、六阶和八阶精度。该方法能轻松处理对VOF方法和水平集方法构成挑战的各类交界点。

**Result:** 该方法在MARS框架下被证明具有四阶及更高阶的收敛率。经典基准测试结果证实了理论分析，并展示了所提出方法卓越的准确性和效率。

**Conclusion:** 所提出的多相三次MARS方法在多材料界面跟踪方面具有卓越的准确性、效率和高阶收敛性，能够有效处理复杂拓扑和几何以及各类交界点，克服了传统方法的局限。

> **ai_Abstract:** 本文提出了一种多相三次MARS方法，用于二维多材料界面的高精度跟踪。该方法通过图、循环和三次样条有效地表示复杂界面，并保持(r,h)正则性，实现了时间和空间上的四阶、六阶和八阶精度。它能轻松处理传统方法难以解决的各类交界点。理论分析和基准测试均证实了该方法的优越准确性和效率。

> **摘要翻译:** 对于二维中任意数量材料的界面跟踪，我们提出了一种多相三次MARS方法，该方法(a)通过图、循环和三次样条精确高效地表示界面的拓扑和几何结构，(b)保持界面的(r,h)正则条件，使得任意一对相邻标记之间的距离在一个用户指定范围内，该范围可根据局部曲率变化，(c)适用于具有任意复杂拓扑和几何的多材料，并且(d)在时间和空间上均达到四阶、六阶和八阶精度。特别是，所有可能的交界点类型（对VOF方法和水平集方法构成挑战）都可以轻松处理。所提出方法的四阶及更高阶收敛率在MARS框架下得到证明。经典基准测试结果证实了分析并展示了所提出方法卓越的准确性和效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [314] [A visco-plastic constitutive model for accurate densification and shape predictions in powder metallurgy hot isostatic pressing](https://arxiv.org/abs/2506.11946)
> *粉末冶金热等静压中用于精确致密化和形状预测的粘塑性本构模型*

*Subrato Sarkar, Jason R Mayeur, KPK Ajjarapu, Fred A List III, Soumya Nag, Ryan R Dehoff* | **Main category: math.NA**

**Keywords:** 粉末冶金热等静压, 粘塑性模型, 本构模型, 形状预测, 致密化

**Comment:** 

> **TL;DR:** 提出了一种新的粘塑性本构模型，用于准确预测粉末冶金热等静压（PM-HIP）过程中的致密化和形状，解决了现有塑性模型的局限性，并采用了一种数据需求更低的校准方法。

**AI_Comments:** 该论文的创新点在于提出了一个改进的粘塑性本构模型，并引入了一种新颖的校准方法，显著降低了数据需求，使其与更简单的塑性模型具有相同的数据成本。这不仅解决了现有塑性模型在预测精度上的局限性，还首次实现了对粘塑性模型和塑性模型的定量比较，对PM-HIP过程的精确建模和预测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** PM-HIP 在大型部件应用中受限，因为对其复杂机制理解不足导致不可预测的形状变形。现有塑性模型在HIP条件稍有变化时会产生不准确的预测。

**Method:** 提出了一种新的粘塑性本构模型，并采用了一种改进的校准方法，该方法比现有方法需要更少的实验数据，使其与塑性模型的数据需求相同。该方法还支持对塑性模型和粘塑性模型进行定量比较。

**Result:** 新的粘塑性模型解决了塑性模型的局限性。与塑性模型校准时数据需求相同。当使用相同的实验数据校准时，两种模型产生相似的结果。校准后的粘塑性模型应用于复杂几何形状时，预测结果与实验观察结果吻合良好。

**Conclusion:** 该粘塑性模型能够准确预测粉末冶金热等静压过程中的致密化和形状，克服了现有塑性模型的局限性，并促进了对该过程的更好理解和预测。

> **ai_Abstract:** 本文提出了一种新的粘塑性本构模型，用于解决粉末冶金热等静压（PM-HIP）过程中塑性模型在预测致密化和形状方面的局限性。该模型采用了一种改进的校准方法，显著减少了实验数据需求，使其与塑性模型的数据需求相当，并首次实现了两种模型的定量比较。实验结果表明，新模型在复杂几何形状的预测上与实际观察吻合良好。

> **摘要翻译:** 粉末冶金热等静压（PM-HIP）是一种先进的制造工艺，能够生产具有高材料利用率和均匀微观结构的近净形零件。尽管PM-HIP常用于生产小型部件，但由于对其复杂机制的理解不足导致不可预测的HIP后形状变形，其在大型部件中的应用受到限制。计算模型可以提供HIP过程中间和最终阶段的必要信息，有助于更好地理解并进行准确预测。通常，PM-HIP模拟采用两种计算模型：塑性模型和粘塑性模型。其中，塑性模型因其校准方法成本较低且所需的实验数据较少而受到青睐。然而，当实际情况中HIP条件稍有变化时，塑性模型有时会产生不正确的预测。因此，本工作提出了一种粘塑性模型来解决塑性模型的这些局限性。该粘塑性模型采用了一种新颖的改进校准方法，与现有方法相比，其所需的实验数据更少。采用新方法后，塑性模型和粘塑性模型的数据需求相同。这也使得过去仅进行定性比较的塑性模型和粘塑性模型能够进行定量比较。当使用相同的实验数据进行校准时，发现两种模型产生相似的结果。校准后的粘塑性模型应用于几种复杂几何形状，其预测结果与实验观察结果吻合良好。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [322] [Analysis of BDDC preconditioners for non-conforming polytopal hybrid discretisation methods](https://arxiv.org/abs/2506.11956)
> *非协调多边形混合离散化方法中BDDC预处理器的分析*

*Santiago Badia, Jerome Droniou, Jordi Manyer, Jai Tushar* | **Main category: math.NA**

**Keywords:** BDDC预处理器, 多边形离散化, 域分解, 条件数界, 不连续骨架方法

**Comment:** 

> **TL;DR:** 本文基于离散迹理论，分析了非协调多边形混合离散化方法生成的BDDC预处理器的收敛速度，证明了与网格参数和子域数量无关的多对数条件数界，并通过数值实验验证了理论。

**AI_Comments:** 本文通过利用离散迹理论，将BDDC预处理器的分析扩展到非协调多边形混合离散化方法，证明了与网格和子域数量无关的多对数条件数界，这是其创新之处。在完全离散多边形设置中证明面截断算子的连续性是重要的理论贡献。这项工作对于在复杂几何结构（多边形网格）上使用先进离散化方法高效求解偏微分方程具有重要意义，其证明的鲁棒条件数界对于BDDC预处理器在高性能计算中的实际应用和可伸缩性至关重要。摘要中未提及明显的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 分析非协调多边形混合离散化方法生成的约束平衡域分解（BDDC）预处理器的收敛速度和性能。

**Method:** 基于离散迹理论，证明了BDDC预处理器的多对数条件数界，这些界独立于网格参数和子域数量，并在多边形网格上成立。分析的关键在于证明了面截断算子在完全离散多边形设置中的连续性。通过两个数值实验验证理论：一个验证截断估计，另一个（弱可伸缩性测试）验证BDDC条件数界在应用于使用不连续骨架方法（HDG和HHO）离散化的二阶椭圆问题时的鲁棒性。

**Result:** 证明了BDDC预处理器的多对数条件数界，这些界独立于网格参数和子域数量，并在多边形网格上成立。在完全离散的多边形设置中证明了面截断算子的连续性。数值实验验证了截断估计，并证实了BDDC条件数界在应用于使用HDG和HHO方法离散化的二阶椭圆问题时的鲁棒性。

**Conclusion:** 本文成功分析了非协调多边形混合离散化方法中BDDC预处理器的收敛速度，证明了与网格参数和子域数量无关的鲁棒条件数界，并通过数值实验验证了理论的有效性和方法的鲁棒性。

> **ai_Abstract:** 本文基于离散迹理论，对非协调多边形混合离散化方法生成的BDDC预处理器的收敛速度进行了深入分析。研究证明了BDDC预处理器的多对数条件数界，这些界独立于网格参数和子域数量，且适用于多边形网格。分析的关键在于证明了面截断算子在完全离散多边形设置下的连续性。通过两个数值实验，包括截断估计验证和BDDC条件数界在处理二阶椭圆问题时的鲁棒性弱可伸缩性测试，验证了所提出的理论。

> **摘要翻译:** 在这项工作中，我们以[Badia, Droniou, Tushar, arXiv (2024)]中开发的离散迹理论为基础，分析了由非协调多边形混合离散化方法生成的约束平衡域分解（BDDC）预处理器的收敛速度。我们证明了预处理器的多对数条件数界，这些界独立于网格参数和子域数量，并且在多边形网格上成立。该分析取决于面截断算子的连续性，我们证明了其在完全离散的多边形设置中的连续性。为了验证该理论，我们提出了两个数值实验：第一个验证了截断估计，第二个（一个弱可伸缩性测试）验证了BDDC条件数界在应用于使用不连续骨架方法（特别是可混合不连续伽辽金（HDG）和混合高阶（HHO）方法）离散化的二阶椭圆问题时的鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [330] [Learning the Analytic Geometry of Transformations to Achieve Efficient Computation](https://arxiv.org/abs/2506.11990)
> *学习变换的解析几何以实现高效计算*

*Pei-Chun Su, Ronald R. Coifman* | **Main category: math.NA**

**Keywords:** 积分运算, 隐藏几何, 低秩结构, 蝴蝶算法, 矩阵分解

**Comment:** 

> **TL;DR:** 该论文提出了一种数据驱动的新框架，通过揭示运算符中的隐藏几何结构，实现快速积分运算和高效矩阵计算，并将存储复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N \log N)$。

**AI_Comments:** 该论文的创新点在于提出了一个完全数据驱动的方法来发现和利用运算符中的隐藏几何结构和低秩特性，从而避免了对先验几何知识的依赖。通过结合自适应分层分区树、蝴蝶算法和最佳平铺，显著降低了计算复杂度和存储需求，使其在处理大规模不规则数据方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过揭示底层运算符中隐藏的行和列结构几何，实现快速积分运算和高效计算。

**Method:** 提出了一种新颖的框架。通过迭代过程构建自适应分层分区树，揭示潜在的多尺度组织和局部低秩结构。在此几何指导下，采用蝴蝶算法和自适应最佳平铺（在广义Haar-Walsh小波包树的所有层级上进行空间和频率的平铺）两种互补技术，实现高效的矩阵分解和乘法。该方法是完全数据驱动的，不依赖先验几何知识。

**Result:** 成功将存储复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N \log N)$。在声学异构势算子和正交多项式相关的矩阵上验证了方法的有效性。

**Conclusion:** 所提出的框架通过学习隐藏的几何结构，实现了存储复杂度的显著降低，从而支持快速计算和可扩展的实现，并且适用于来自不规则或未知分布的矩阵。

> **ai_Abstract:** 本文提出了一种创新的数据驱动框架，通过迭代构建自适应分层分区树来揭示运算符中的隐藏几何和低秩结构。结合蝴蝶算法和自适应最佳平铺技术，该框架能高效地进行矩阵分解和乘法。与传统方法不同，它不依赖先验几何知识，适用于复杂分布数据。实验证明，该方法能将存储复杂度从$\mathcal{O}(N^2)$降至$\mathcal{O}(N \log N)$，实现快速计算和可扩展应用。

> **摘要翻译:** 我们提出了一种新颖的框架，通过揭示底层算子中行和列结构中隐藏的几何形状，实现快速积分运算。这通过一个迭代过程来完成，该过程构建自适应分层分区树，揭示潜在的多尺度组织并暴露数据中的局部低秩结构。在此几何形状的指导下，我们采用了两种互补技术：（1）蝴蝶算法，它利用学习到的分层低秩结构；（2）使用广义Haar-Walsh小波包树的所有层级在空间和频率上进行自适应最佳平铺。这些技术能够实现高效的矩阵分解和乘法。与依赖底层几何先验知识的经典方法不同，我们的方法是完全数据驱动的，适用于来自不规则或未知分布的矩阵。我们在与声学异构势算子和正交多项式族相关的矩阵上证明了我们方法的有效性。由此产生的压缩表示将存储复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N \log N)$，从而实现快速计算和可扩展的实现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [29] [End-to-End Diarization utilizing Attractor Deep Clustering](https://arxiv.org/abs/2506.11090)
> *利用吸引子深度聚类的端到端说话人日志*

*David Palzer, Matthew Maciejewski, Eric Fosler-Lussier* | **Main category: cs.SD**

**Keywords:** 说话人日志, 深度聚类, Conformer, 吸引子, 端到端

**Comment:** To appear at INTERSPEECH 2025

> **TL;DR:** 提出一种新的端到端说话人日志框架，结合Conformer、Transformer更新的吸引子和深度聚类角度损失，实现低错误率和参数效率。

**AI_Comments:** 该论文的创新点在于将Conformer、Transformer更新的吸引子和深度聚类风格的角度损失巧妙地集成到一个端到端日志框架中。特别是在深度聚类中引入标签-吸引子向量和对活跃吸引子施加正交性约束，以及抑制非活跃吸引子的策略，对于提升说话人表示的结构性和分离效果具有重要意义。在保持参数效率的同时实现低错误率，表明了该方法的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 说话人日志面临挑战，需要结构化的说话人表示、高效建模以及对不同条件的鲁棒性。

**Method:** 提出一个集成了Conformer解码器、Transformer更新的吸引子和深度聚类风格角度损失的紧凑日志框架。该方法通过增强的Conformer结构（包含对吸引子的交叉注意力及额外卷积模块）优化说话人表示；通过构建标签-吸引子向量并对齐其方向结构与音频嵌入来扩展深度聚类；对活跃吸引子施加正交性约束以更好分离说话人，并抑制非活跃吸引子；最后使用置换不变训练二元交叉熵损失来优化说话人检测。

**Result:** 实验表明，该方法在保持参数数量的同时，实现了低的日志错误率。

**Conclusion:** 该论文成功提出了一种新颖的端到端说话人日志框架，有效解决了说话人表示、建模效率和鲁棒性等挑战，并在实验中验证了其在低错误率和参数效率方面的优越性。

> **ai_Abstract:** 本文提出一种名为“利用吸引子深度聚类的端到端日志”的新型紧凑框架，旨在解决说话人日志中结构化表示、高效建模和鲁棒性难题。该框架结合了Conformer解码器、Transformer更新的吸引子和一种深度聚类风格的角度损失。通过增强Conformer结构、引入标签-吸引子向量扩展深度聚类、施加吸引子正交性约束以及采用置换不变训练的二元交叉熵损失，该方法有效优化了说话人表示和分离。实验结果验证了其在实现低日志错误率的同时，能有效控制模型参数数量。

> **摘要翻译:** 说话人日志仍然具有挑战性，因为需要结构化的说话人表示、高效建模以及对不同条件的鲁棒性。我们提出一个高性能、紧凑的日志框架，它集成了Conformer解码器、Transformer更新的吸引子和深度聚类风格的角度损失。我们的方法通过增强的Conformer结构来优化说话人表示，该结构包含对吸引子的交叉注意力和一个额外的卷积模块。为了强制执行结构化嵌入，我们通过构建标签-吸引子向量来扩展深度聚类，使其方向结构与音频嵌入对齐。我们还在活跃吸引子上施加正交性约束，以实现更好的说话人分离，同时抑制非活跃吸引子以防止错误激活。最后，置换不变训练的二元交叉熵损失优化了说话人检测。实验表明，我们的方法在保持参数数量的同时实现了低的日志错误率。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [57] [Assessing the Impact of Anisotropy in Neural Representations of Speech: A Case Study on Keyword Spotting](https://arxiv.org/abs/2506.11096)
> *评估语音神经表征中各向异性的影响：以关键词识别为例*

*Guillaume Wisniewski, Séverine Guillaume, Clara Rosina Fernández* | **Main category: cs.SD**

**Keywords:** 各向异性, 语音表征, 关键词识别, Wav2vec2, 预训练

**Comment:** 

> **TL;DR:** 预训练语音表征（如wav2vec2和HuBERT）存在各向异性，但本文研究表明，尽管如此，wav2vec2在关键词识别任务中仍能有效识别词语，突出了其鲁棒性和预训练的重要性。

**AI_Comments:** 该论文解决了预训练语音表征中一个已知特性（各向异性）对其下游任务影响的疑问。其发现，即尽管存在各向异性，模型仍能保持鲁棒性并有效执行关键词识别任务，这对于理解和应用这些模型具有重要价值，进一步凸显了预训练的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管预训练语音表征（如wav2vec2和HuBERT）普遍存在各向异性（导致随机嵌入之间的高度相似性），但这种特性对下游任务的影响尚不明确。

**Method:** 本研究使用动态时间规整（Dynamic Time Warping, DTW）评估了计算文献语言学中关键词识别任务中各向异性的影响，并利用wav2vec2相似性度量来识别词语。

**Result:** 尽管存在各向异性，wav2vec2相似性度量仍能有效地识别无需转录的词语。这些表征具有鲁棒性，能够捕获语音结构并泛化到不同的说话者。

**Conclusion:** 预训练对于学习丰富且不变的语音表征至关重要。

> **ai_Abstract:** 本文探讨了预训练语音表征（如wav2vec2）中各向异性对关键词识别的影响。研究发现，尽管随机嵌入之间存在高度相似性，但结合动态时间规整，wav2vec2的相似性度量仍能有效地识别无需转录的词语。这表明这些表征具有强大的鲁棒性，能够捕获语音结构并跨说话者泛化，从而强调了预训练在学习高质量语音表征中的关键作用。

> **摘要翻译:** 预训练语音表征，如wav2vec2和HuBERT，表现出很强的各向异性，导致随机嵌入之间的高度相似性。尽管这种特性被广泛观察到，但其对下游任务的影响仍不明确。这项工作评估了计算文献语言学中关键词识别任务中的各向异性。我们使用动态时间规整（Dynamic Time Warping）表明，尽管存在各向异性，wav2vec2相似性度量仍能有效地识别无需转录的词语。我们的结果突出了这些表征的鲁棒性，它们能够捕获语音结构并跨说话者泛化。我们的结果强调了预训练在学习丰富和不变的语音表征方面的重要性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [85] [GLAP: General contrastive audio-text pretraining across domains and languages](https://arxiv.org/abs/2506.11350)
> *GLAP：跨领域和语言的通用对比音文预训练*

*Heinrich Dinkel, Zhiyong Yan, Tianzi Wang, Yongqing Wang, Xingwei Sun, Yadong Niu, Jizhong Liu, Gang Li, Junbo Zhang, Jian Luan* | **Main category: cs.SD**

**Keywords:** 对比学习, 音频-文本预训练, 多语言, 多领域, 语音检索

**Comment:** 

> **TL;DR:** GLAP通过扩展CLAP，实现了多语言和多领域的音频-文本预训练，在多项音频检索、分类和零样本任务中表现出色，尤其是在语音内容和多语言关键词识别方面。

**AI_Comments:** GLAP的创新性在于将CLAP扩展到多语言和多领域，解决了现有方法在非英语语音内容上的不足。其重要性体现在为多语言音频理解和检索提供了更通用的预训练模型，尤其在语音内容和零样本识别方面表现出色，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的对比语言音频预训练（CLAP）方法主要支持英文的音频和音乐检索，忽略了多语言口语内容。为了解决这一局限性，本文提出了GLAP。

**Method:** 本文引入了通用语言音频预训练（GLAP），它通过扩展CLAP，使其具备了多语言和多领域的能力。

**Result:** GLAP在Clotho和AudioCaps等标准音频-文本检索基准上取得了有竞争力的性能。在语音检索和分类任务中显著超越现有方法。在常用声事件零样本基准上取得了良好结果，同时在语音内容基准上超越了现有方法。在50种语言的关键词识别评估中，GLAP展现了先进的多语言能力。对四种语言的多语言声音和音乐理解也进行了评估。

**Conclusion:** GLAP通过引入多语言和多领域能力，成功扩展了CLAP，并在多种音频-文本任务中展现出卓越的性能，尤其是在处理多语言语音内容方面。

> **ai_Abstract:** 本文提出了GLAP（通用对比音文预训练），旨在解决现有CLAP（对比语言音频预训练）方法在多语言和多领域语音内容处理上的局限性。GLAP通过扩展CLAP，使其具备多语言和多领域能力，并在音频-文本检索、语音检索与分类、零样本声事件识别以及多语言关键词识别等任务中表现出优异性能，显著超越了现有方法，尤其在处理多语言语音内容方面展现出强大的能力。

> **摘要翻译:** 对比语言音频预训练（CLAP）是一种广泛用于弥合音频和文本领域之间鸿沟的方法。当前的CLAP方法支持英文的声音和音乐检索，但忽略了多语言口语内容。为了解决这个问题，我们引入了通用语言音频预训练（GLAP），它通过扩展CLAP，使其具备多语言和多领域的能力。GLAP通过在Clotho和AudioCaps等标准音频-文本检索基准上取得有竞争力的性能，展示了其多功能性，同时在语音检索和分类任务中显著超越现有方法。此外，GLAP在广泛使用的声事件零样本基准上取得了良好结果，同时在语音内容基准上超越了现有方法。对50种语言的关键词识别评估进一步强调了GLAP先进的多语言能力。最后，对四种语言的多语言声音和音乐理解进行了评估。检查点和源代码：https://github.com/xiaomi-research/dasheng-glap。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [112] [A correlation-permutation approach for speech-music encoders model merging](https://arxiv.org/abs/2506.11403)
> *语音-音乐编码器模型合并的关联置换方法*

*Fabian Ritter-Gutierrez, Yi-Cheng Lin, Jeremy H. M Wong, Hung-yi Lee, Eng Siong Chng, Nancy F. Chen* | **Main category: cs.SD**

**Keywords:** 模型合并, 语音编码器, 音乐编码器, 关联置换, Transformer

**Comment:** Under review

> **TL;DR:** 提出一种关联置换方法，通过对齐层来有效合并独立的语音和音乐编码器，显著提升音乐性能并保持语音能力，避免昂贵的预训练。

**AI_Comments:** 这项工作的创新之处在于提出了一种针对模型合并中权重空间未对齐问题的有效解决方案，特别是将其应用于Transformer层。通过引入关联置换来最大化特征级交叉关联，它提供了一种计算效率高且性能优越的替代方案，避免了昂贵的预训练成本。这对于在资源有限的环境下构建多模态或统一模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 创建统一的语音和音乐模型需要昂贵的预训练；模型合并能以最小计算量实现，但当模型权重空间未对齐时直接合并具有挑战性。

**Method:** 提出一种受Git Re-Basin启发的关联置换方法，用于对齐音乐编码器与语音编码器的内部层，并将其扩展到Transformer层合并。该方法逐层计算置换矩阵，以最大化模型的特征级交叉关联，从而有效融合原本不相干的模型。

**Result:** 合并后的模型通过此方法保留了语音能力，同时显著提升了音乐性能，与线性插值模型合并相比，平均得分提高了14.83点。

**Conclusion:** 这项工作允许从独立训练的编码器创建统一的音频模型。

> **ai_Abstract:** 本文提出一种新颖的关联置换方法，用于有效合并独立的语音和音乐编码器，以替代昂贵的统一模型预训练。该方法受Git Re-Basin启发，通过逐层计算置换矩阵来对齐不同编码器（包括Transformer层）的内部特征，从而最大化其交叉关联。实验结果表明，该方法在保持语音性能的同时显著提升了音乐性能，相较于线性插值合并方法，平均得分提高了14.83点，成功实现了从独立训练编码器创建统一音频模型的目标。

> **摘要翻译:** 创建统一的语音和音乐模型需要昂贵的预训练。模型合并可以以最小的计算开销创建统一的音频模型。然而，当模型在权重空间中未对齐时，直接合并具有挑战性。受Git Re-Basin的启发，我们引入了一种关联置换方法，该方法将音乐编码器的内部层与语音编码器对齐。我们将先前的工作扩展到合并Transformer层的情况。该方法逐层计算置换矩阵，以最大化模型的特征级交叉关联，从而实现这些原本不相干模型的有效融合。通过这种方法，合并后的模型保留了语音能力，同时显著增强了音乐性能，与线性插值模型合并相比，平均得分提高了14.83点。这项工作允许从独立训练的编码器创建统一的音频模型。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [139] [LiLAC: A Lightweight Latent ControlNet for Musical Audio Generation](https://arxiv.org/abs/2506.11476)
> *LiLAC：一种用于音乐音频生成的轻量级潜在ControlNet*

*Tom Baker, Javier Nistal* | **Main category: cs.SD**

**Keywords:** 音乐生成, ControlNet, 扩散模型, 轻量级, 音频控制

**Comment:** Accepted at ISMIR 2025

> **TL;DR:** LiLAC提出了一种轻量级、模块化的架构，用于文本到音频扩散模型中的细粒度、时变控制，显著减少了参数量和内存使用，同时保持了音频质量。

**AI_Comments:** 这项工作通过提出LiLAC，有效地解决了ControlNet在文本到音频生成领域应用时面临的内存效率和控制灵活性问题。其创新点在于采用了轻量级、模块化的架构，这对于资源受限的环境和需要多样化控制的音乐制作场景具有重要意义。通过显著降低参数量和内存使用，LiLAC有望促进更广泛、更高效的音乐生成应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到音频扩散模型虽然能生成高质量音乐，但缺乏音乐制作所需的细粒度、时变控制。ControlNet虽然能添加外部控制，但其内存占用大且限制了用户使用固定的控制集。

**Method:** 我们提出了一种轻量级、模块化的架构，通过克隆和微调编码器，显著减少了参数数量，同时在音频质量和条件依从性方面与ControlNet相当。该方法提供了更大的灵活性和显著更低的内存使用。

**Result:** 我们的方法在音频质量和条件依从性方面与ControlNet相当，同时提供了更大的灵活性和显著更低的内存使用，从而实现了更高效的独立控制训练和部署。我们进行了广泛的客观和主观评估。

**Conclusion:** LiLAC成功地为文本到音频扩散模型提供了高效、灵活的细粒度控制，解决了现有ControlNet方法内存占用大和控制受限的问题。

> **ai_Abstract:** LiLAC是一种为文本到音频扩散模型设计的轻量级潜在ControlNet，旨在解决现有SOTA模型缺乏细粒度、时变控制以及ControlNet内存占用大、灵活性不足的问题。该研究提出了一种模块化架构，显著减少了参数量和内存消耗，同时在音频质量和条件依从性上与传统ControlNet相当，实现了更高效的独立控制训练和部署。

> **摘要翻译:** 文本到音频扩散模型能够生成高质量和多样化的音乐，但许多（如果不是大多数）SOTA模型缺乏音乐制作所必需的细粒度、时变控制。ControlNet通过克隆和微调其编码器以适应新的条件，从而能够将外部控制附加到预训练的生成模型上。然而，这种方法会产生较大的内存占用，并限制用户使用固定的控制集。我们提出了一种轻量级、模块化的架构，它显著减少了参数数量，同时在音频质量和条件依从性方面与ControlNet相当。我们的方法提供了更大的灵活性和显著更低的内存使用，从而能够更有效地训练和部署独立控制。我们进行了广泛的客观和主观评估，并在随附的网站 https://lightlatentcontrol.github.io 上提供了大量音频示例。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [162] [Amplifying Artifacts with Speech Enhancement in Voice Anti-spoofing](https://arxiv.org/abs/2506.11542)
> *语音反欺骗中利用语音增强放大伪影*

*Thanapat Trachu, Thanathai Lertpetchpun, Ekapol Chuangsuwanich* | **Main category: cs.SD**

**Keywords:** 语音反欺骗, 伪影放大, 语音增强, 噪声提取, 欺骗检测

**Comment:** Accepted to Interspeech2025

> **TL;DR:** 该研究提出一种模型无关的管道，通过噪声添加、提取和放大来增强语音欺骗中的伪影，显著提高了欺骗检测性能。

**AI_Comments:** 这篇论文的创新点在于其独特的视角，即不单纯依赖模型架构改进，而是通过主动增强欺骗语音中的固有伪影来提升检测能力。其模型无关性使其具有较好的普适性，可以与现有多种语音增强和反欺骗系统结合。通过物理层面的特征增强，为语音反欺骗领域提供了一种新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 欺骗语音中包含生成模型引入的伪影，但现有反制措施主要关注架构改进，未能有效显现这些隐藏的伪影，导致欺骗检测性能受限。

**Method:** 提出一种模型无关的管道，利用语音增强和不同类型的噪声来放大伪影。该方法包括三个关键步骤：首先，向原始语音中添加噪声；然后，应用语音增强技术提取纠缠的噪声和伪影；最后，放大这些提取出的特征。该管道兼容不同的语音增强模型和反制措施架构。

**Result:** 该方法在ASVspoof2019数据集上将欺骗检测性能提高了44.44%，在ASVspoof2021数据集上提高了26.34%。

**Conclusion:** 通过增强欺骗语音中的伪影，可以显著提升语音反欺骗系统的检测性能，证明了该方法在模型无关性方面的有效性和普适性。

> **ai_Abstract:** 本文提出了一种新颖的模型无关管道，旨在通过增强欺骗语音中由生成模型引入的伪影来提高语音反欺骗性能。该方法包括噪声添加、噪声提取和噪声放大三个步骤，利用语音增强技术从原始语音中分离并放大这些关键的伪影特征。实验结果表明，该方法显著提升了在ASVspoof2019和ASVspoof2021数据集上的欺骗检测准确率，且具有良好的模型兼容性。

> **摘要翻译:** 欺骗性语音总是包含由生成模型引入的伪影。虽然已经提出了几种检测欺骗性语音的对策，但大多数主要关注架构改进。在这项工作中，我们研究了伪影如何在欺骗性语音中保持隐藏以及如何增强它们的存在。我们提出了一种模型无关的管道，该管道使用语音增强和各种类型的噪声来放大伪影。我们的方法包括三个关键步骤：噪声添加、噪声提取、和噪声放大。首先，我们将噪声引入原始语音。然后，我们应用语音增强来提取纠缠的噪声和伪影。最后，我们放大这些提取的特征。此外，我们的管道兼容不同的语音增强模型和对策架构。我们的方法在ASVspoof2019上将欺骗检测性能提高了44.44%，在ASVspoof2021上提高了26.34%。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [180] [Dissecting the Segmentation Model of End-to-End Diarization with Vector Clustering](https://arxiv.org/abs/2506.11605)
> *剖析端到端矢量聚类说话人日志中的分割模型*

*Alexis Plaquet, Naohiro Tawara, Marc Delcroix, Shota Horiguchi, Atsushi Ando, Shoko Araki, Hervé Bredin* | **Main category: cs.SD**

**Keywords:** 说话人日志, 分割模型, WavLM, Conformer, 架构分析

**Comment:** 37 pages, 18 figures. Submitted to Computer Speech & Language

> **TL;DR:** 该研究深入分析了端到端说话人日志分割模型中不同架构选择（编码器、解码器、损失函数、块大小）的影响，发现微调后的WavLM编码器和Conformer解码器表现最佳，并在多个数据集上达到了SOTA性能。

**AI_Comments:** 该论文对端到端说话人日志分割模型的关键组件进行了全面而系统的评估，填补了现有研究中对不同增强方案协同作用评估不足的空白。其创新之处在于通过详尽的实验揭示了不同编码器、解码器、损失函数和块大小对性能的具体影响，尤其是确认了微调WavLM与Conformer解码器的优越组合，并提供了实用的指导。研究成果对推动说话人日志技术的发展具有重要意义，为未来的模型设计提供了坚实的实验依据。

<details>
  <summary>Details</summary>

**Motivation:** 端到端神经网络说话人日志（End-to-End Neural Diarization with Vector Clustering）是一种强大且实用的方法，但其分割模型的多种增强方案的协同作用尚未得到彻底评估。本研究旨在深入分析主要架构选择对流水线性能的影响。

**Method:** 本研究对端到端说话人日志分割模型中的主要架构选择进行了深入分析。具体调查了不同的编码器（SincNet、预训练和微调的WavLM）、不同的解码器（LSTM、Mamba和Conformer）、不同的损失函数（多标签和多类别幂集损失）以及不同的块大小。通过涵盖九个数据集的深入实验进行评估。

**Result:** 研究发现，基于微调WavLM的编码器总是能带来最佳系统性能，且优势明显。LSTM解码器被Mamba和Conformer解码器超越，其中Mamba对其他架构选择更具鲁棒性，但略逊于使用Conformer编码器的最佳架构。多标签和多类别幂集损失的错误分布不同，多类别损失有助于几乎所有模型获得卓越性能，但在微调WavLM时，多标签是更好的选择。较新的架构能更好地处理长块大小，这能显著提升流水线性能。最佳系统在五个广泛使用的说话人日志数据集上取得了最先进的结果。

**Conclusion:** 微调后的WavLM编码器与Conformer解码器的组合是端到端说话人日志分割模型的最佳选择，能够显著提升性能并达到最先进水平。损失函数的选择和块大小对模型性能也有重要影响，且与具体架构选择相关。

> **ai_Abstract:** 本研究深入剖析了端到端矢量聚类说话人日志分割模型中的关键架构选择。通过对不同编码器（SincNet, WavLM）、解码器（LSTM, Mamba, Conformer）、损失函数和块大小在九个数据集上进行广泛实验，发现微调后的WavLM编码器与Conformer解码器组合性能最佳，并在多个数据集上实现了SOTA结果。研究还揭示了不同损失函数对性能的影响以及长块大小对新架构的优势。

> **摘要翻译:** 端到端矢量聚类神经网络说话人日志是一种强大而实用的说话人日志方法。虽然已经提出了多种针对这些流水线分割模型的增强方案，但它们之间的协同作用尚未得到彻底评估。在这项工作中，我们对主要架构选择对流水线性能的影响进行了深入分析。我们研究了不同的编码器（SincNet、预训练和微调的WavLM）、不同的解码器（LSTM、Mamba和Conformer）、不同的损失函数（多标签和多类别幂集）以及不同的块大小。通过涵盖九个数据集的深入实验，我们发现基于微调WavLM的编码器总是能以显著优势获得最佳系统。LSTM解码器被基于Mamba和Conformer的解码器超越，虽然我们发现Mamba对其他架构选择更具鲁棒性，但它略逊于我们使用Conformer编码器的最佳架构。我们发现多标签和多类别幂集损失的错误分布不同。我们证实多类别损失有助于几乎所有模型获得优越性能，但当微调WavLM时，多标签是更好的选择。我们还评估了块大小对所有上述架构选择的影响，发现较新的架构倾向于更好地处理长块大小，这可以大大提高流水线性能。我们最好的系统在五个广泛使用的说话人日志数据集上取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [200] [(SimPhon Speech Test): A Data-Driven Method for In Silico Design and Validation of a Phonetically Balanced Speech Test](https://arxiv.org/abs/2506.11620)
> *SimPhon言语测试：一种用于语音平衡言语测试的计算机模拟设计与验证的数据驱动方法*

*Stefan Bleeck* | **Main category: cs.SD**

**Keywords:** 言语测试, 数据驱动, 计算机模拟, 语音平衡, 听力学, ASR

**Comment:** 

> **TL;DR:** 该研究提出了一种名为SimPhon言语测试的新型计算方法，用于在计算机上设计和验证语音平衡的言语测试，以更准确地诊断听力损失对言语理解的影响。

**AI_Comments:** 该论文的创新之处在于其“计算机模拟（in silico）”的数据驱动方法，利用ASR系统作为人类听觉的代理来设计和验证言语测试，这大大提高了测试开发的效率和客观性。该方法能够识别传统测试可能忽略的感知缺陷，具有重要的诊断潜力。该研究为听力学测试的未来发展提供了一个高效且更具特异性的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 传统听力测定法在表征听力损失对言语理解的功能性影响方面存在不足，尤其是在老年性耳聋常见的阈上缺陷方面，这促使人们开发出更具诊断特异性的言语感知测试。

**Method:** 本研究引入了SimPhon言语测试方法，这是一个新颖的多阶段计算流程，用于在计算机上设计和验证语音平衡的最小对言语测试。该方法利用现代自动语音识别（ASR）系统作为人类听觉的代理，模拟感音神经性听力损失的感知效应。通过在受控声学降级下处理言语刺激，首先识别出最常见的音素混淆模式。这些模式随后指导从综合语言语料库中数据驱动地筛选出大量的候选词对。后续阶段包括模拟诊断测试、专家人工筛选和最终的有针对性的敏感性分析，系统地将候选词对减少到最终优化的25对（SimPhon言语测试-25）。

**Result:** 一个关键发现是，SimPhon言语测试-25测试项目的诊断性能与标准言语清晰度指数（SII）的预测没有显著相关性。这表明SimPhon言语测试能够捕获超越简单可听度范围的感知缺陷，并且该计算优化的测试集显著提高了听力学测试开发的效率。

**Conclusion:** 这种计算优化的测试集显著提高了听力学测试开发的效率，并已准备好进行初步的人体试验。

> **ai_Abstract:** 本研究提出了一种名为SimPhon言语测试的新型数据驱动方法，用于在计算机上设计和验证语音平衡的言语测试，旨在解决传统听力测定法在诊断听力损失对言语理解影响方面的不足。该方法通过多阶段计算流程，利用ASR系统模拟听力损失，识别音素混淆模式，并数据驱动地筛选和优化词对，最终得到一个包含25对词的测试集。研究结果表明，SimPhon言语测试-25的诊断性能与标准言语清晰度指数（SII）无显著相关性，表明其能捕捉超越简单可听度的感知缺陷，且该方法显著提高了听力学测试开发的效率。

> **摘要翻译:** 传统听力测定法在表征听力损失对言语理解的功能性影响方面往往不完整，特别是对于老年性耳聋中常见的阈上缺陷。这促使人们开发更具诊断特异性的言语感知测试。我们引入了模拟音素言语测试（SimPhon言语测试）方法，这是一种新颖的多阶段计算流程，用于语音平衡最小对言语测试的计算机模拟设计和验证。该方法利用现代自动语音识别（ASR）系统作为人类听觉的代理，模拟感音神经性听力损失的感知效应。通过在受控声学降级下处理言语刺激，我们首先识别最常见的音素混淆模式。然后，这些模式指导从综合语言语料库中数据驱动地筛选出大量的候选词对。后续阶段包括模拟诊断测试、专家人工筛选和最终的有针对性的敏感性分析，系统地将候选词对减少到最终优化的25对（SimPhon言语测试-25）。一个关键发现是，SimPhon言语测试-25测试项目的诊断性能与标准言语清晰度指数（SII）的预测没有显著相关性，这表明SimPhon言语测试能够捕获超越简单可听度范围的感知缺陷。这种计算优化的测试集显著提高了听力学测试开发的效率，并已准备好进行初步的人体试验。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [218] [Enabling automatic transcription of child-centered audio recordings from real-world environments](https://arxiv.org/abs/2506.11747)
> *实现对真实环境中以儿童为中心的录音的自动转录*

*Daniil Kocharov, Okko Räsänen* | **Main category: cs.SD**

**Keywords:** 自动语音识别, 儿童录音, 长时间录音, 语音转录, 词错误率

**Comment:** pre-print

> **TL;DR:** 本文提出了一种新方法，通过自动识别可可靠转录的片段，实现对以儿童为中心的长时间录音的自动转录，显著提高了在真实世界噪声环境下的转录准确性，为自动化语言分析迈出了重要一步。

**AI_Comments:** 本论文的创新之处在于其突破了传统ASR对整个录音进行处理的假设，转而采用选择性转录策略，即只处理那些ASR能够可靠识别的语音片段。这一点对于处理真实世界中嘈杂、无约束的儿童音频至关重要，因为它能有效规避低质量语音对整体准确性的影响。其重要性在于，它为大规模自动化分析儿童语言发展提供了可行方案，极大地降低了数据处理的时间和人力成本，有望加速该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 以儿童为中心的长时间录音是研究儿童语言发展的重要方法，但大规模语料库的手动标注耗时巨大。现有自动语音识别（ASR）系统难以处理真实世界中嘈杂、无约束的儿童音频，且以往尝试都假设必须处理整个录音，导致效果不佳。因此，需要一种能够可靠自动转录此类数据的方法。

**Method:** 本文提出了一种新方法，用于自动检测长时间录音中可以被现代ASR系统可靠转录的语音片段。该方法允许对典型长时间数据中相当比例的语音进行自动且相对准确的转录。该方法在四个英语长时间音频语料库上进行了验证。

**Result:** 该方法在转录数据集中13%的总语音时，实现了0%的中位数词错误率（WER）和18%的平均WER。相比之下，未经任何过滤转录所有语音的中位数WER为52%，平均WER为51%。自动转录的词语对数频率与手动标注的词语对数频率相关性良好，所有转录词语的皮尔逊相关系数r=0.92，在自动转录中出现至少五次的词语相关系数r=0.98。

**Conclusion:** 这项工作为实现对以儿童为中心的长时间录音进行日益详细的自动化语言分析迈出了坚实的一步。

> **ai_Abstract:** 本研究提出了一种创新方法，旨在解决以儿童为中心的长时间录音自动转录的难题。鉴于手动标注耗时且现有ASR系统难以应对真实世界音频的噪声，研究者开发了一种能够自动识别并仅转录高质量、可可靠识别的语音片段的系统。该方法在四个英语语料库上进行了验证，结果显示，在转录13%的语音数据时，实现了显著的准确性提升（平均WER 18% vs. 51%），并且自动转录的词频与手动标注高度相关。这标志着向自动化、大规模儿童语言数据分析迈出了关键一步。

> **摘要翻译:** 通过儿童佩戴麦克风获得的长时间录音——也称为以儿童为中心的日间录音——已成为研究儿童语言经验及其对后续语言发展影响的标准方法。长时间语音录音的转录将能够进行各种语言层面的丰富分析，但典型长时间语料库的巨大规模使得全面的手动标注变得不可能。与此同时，基于自动语音识别（ASR）的转录由于真实世界音频的嘈杂、无约束性质而面临重大挑战，并且现有研究尚未成功将ASR应用于转录此类数据。然而，之前的尝试都假设ASR必须完整处理每个长时间录音。在这项工作中，我们提出了一种方法，可以自动检测长时间音频中那些可以用现代ASR系统可靠转录的言语，从而实现对典型长时间数据中相当比例的语音进行自动且相对准确的转录。我们在四个英语长时间音频语料库上验证了该方法，结果显示，在转录数据集中13%的总语音时，该方法实现了0%的中位数词错误率（WER）和18%的平均WER。相比之下，未经任何过滤转录所有语音的中位数WER为52%，平均WER为51%。我们还将自动转录中派生的词语对数频率与手动标注的词语对数频率进行了比较，结果显示所有转录词语的频率相关系数r=0.92（皮尔逊），在自动转录中出现至少五次的词语相关系数r=0.98。总的来说，这项工作为实现对以儿童为中心的长时间录音进行日益详细的自动化语言分析迈出了坚实的一步。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [232] [Abstract Sound Fusion with Unconditioned Inversion Model](https://arxiv.org/abs/2506.11811)
> *抽象声音融合与无条件反演模型*

*Jing Liu, EnQi Lian* | **Main category: cs.SD**

**Keywords:** 抽象声音融合, 反演模型, SDE, ODE, DPMSolver++

**Comment:** 

> **TL;DR:** 本文提出了一种基于SDE和ODE反演模型的新方法，用于抽象声音融合，无需提示词条件即可实现可控合成。

**AI_Comments:** 这篇论文的创新点在于提出了无需提示词条件的SDE和ODE反演模型，用于抽象声音融合。这种方法通过消除噪声预测项的循环依赖，简化了声音合成过程，并提供了可控性，对于生成超越传统叠加效果的独特声音具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过声音融合生成具有超越简单叠加的听觉特征的新颖声音，特别针对抽象声音，同时实现可控合成。

**Method:** 提出了基于DPMSolver++采样器的新型SDE和ODE反演模型。这些模型通过将模型输出配置为常量来逆转采样过程，从而消除了噪声预测项引起的循环依赖。该方法无需提示词条件，但在采样过程中保持灵活的引导。

**Result:** 实现了可控合成，并且在采样过程中无需提示词条件即可保持灵活引导。

**Conclusion:** 该论文引入了一种使用无条件反演模型进行抽象声音融合的新颖方法，该方法无需提示词条件即可提供可控的合成能力。

> **ai_Abstract:** 本文提出了一种使用无条件反演模型进行抽象声音融合的新方法。该方法旨在通过融合原始和参考声音来创建具有超越简单叠加的新颖听觉特征的声音。研究引入了基于DPMSolver++采样器的新型SDE和ODE反演模型，这些模型通过将模型输出设置为常量来逆转采样过程，从而避免了噪声预测项的循环依赖。该反演方法的一大优势是无需提示词条件，但仍能提供灵活的采样引导。

> **摘要翻译:** 抽象声音被定义为不向听者揭示可识别的真实世界声音事件的声音。声音融合旨在合成原始声音和参考声音，以生成一种新颖的声音，其听觉特征超越了声音成分的简单叠加。为了实现这种融合，我们采用了反演技术，该技术在保留原始样本基本特征的同时，实现了可控合成。我们提出了基于DPMSolver++采样器的新型SDE和ODE反演模型，这些模型通过将模型输出配置为常量来逆转采样过程，从而消除了噪声预测项引起的循环依赖。我们的反演方法不需要提示词条件，同时在采样过程中保持灵活的引导。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [248] [Confidence-Based Self-Training for EMG-to-Speech: Leveraging Synthetic EMG for Robust Modeling](https://arxiv.org/abs/2506.11862)
> *基于置信度的肌电图到语音自训练：利用合成肌电图进行鲁棒建模*

*Xiaodan Chen, Xiaoxue Gao, Mathias Quoy, Alexandre Pitti, Nancy F. Chen* | **Main category: cs.SD**

**Keywords:** 肌电图到语音, 自训练, 合成数据, 置信度, V-ETS

**Comment:** 

> **TL;DR:** 本文提出了一种名为CoM2S的基于置信度的多说话人自训练方法，通过利用合成肌电图数据和音素级置信度过滤机制，解决了配对肌电图-语音数据稀缺的问题，并显著提高了V-ETS模型的性能。

**AI_Comments:** 该论文的创新点在于提出了基于置信度的自训练方法CoM2S，并利用合成肌电图数据来解决真实配对数据稀缺的问题。这种方法为V-ETS领域的数据增强提供了一个有效途径，对于促进神经喉科诊断等应用的发展具有重要意义。同时，数据集的公开发布也将极大推动该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管语音肌电图到语音 (V-ETS) 模型在神经喉科诊断等应用中具有潜力，但其发展受到配对肌电图-语音数据稀缺的阻碍。

**Method:** 本文提出了一种新颖的基于置信度的多说话人自训练 (CoM2S) 方法，并构建了一个新的Libri-EMG数据集。该方法利用预训练模型生成的合成肌电图数据，并通过基于音素级置信度的过滤机制，通过所提出的自训练技术来增强ETS模型。

**Result:** 实验表明，该方法提高了音素准确率，减少了音素混淆，并降低了词错误率。

**Conclusion:** 实验结果证实了CoM2S方法在V-ETS中的有效性。

> **ai_Abstract:** 本文提出了一种名为CoM2S的基于置信度的多说话人自训练方法，旨在解决语音肌电图到语音（V-ETS）模型训练中配对肌电图-语音数据稀缺的问题。该方法利用预训练模型生成的合成肌电图数据，并通过音素级置信度过滤机制进行数据增强，从而提升ETS模型的性能。实验结果表明，CoM2S方法能有效提高音素准确率，减少音素混淆，并降低词错误率。研究者还将发布相关代码和Libri-EMG数据集以支持未来研究。

> **摘要翻译:** 语音肌电图到语音（V-ETS）模型从肌肉活动信号中重建语音，促进了神经喉科诊断等应用。尽管其潜力巨大，但V-ETS的发展受到配对肌电图-语音数据稀缺的阻碍。为了解决这个问题，我们提出了一种新颖的基于置信度的多说话人自训练（CoM2S）方法，以及一个新整理的Libri-EMG数据集。这种方法利用预训练模型生成的合成肌电图数据，然后通过一个基于音素级置信度的过滤机制，通过所提出的自训练技术来增强ETS模型。实验表明，我们的方法提高了音素准确率，减少了音素混淆，并降低了词错误率，证实了我们CoM2S方法在V-ETS中的有效性。为了支持未来的研究，我们将发布代码和所提出的Libri-EMG数据集——一个开放获取的、时间对齐的、多说话人语音肌电图和语音录音。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [264] [Reimagining Dance: Real-time Music Co-creation between Dancers and AI](https://arxiv.org/abs/2506.12008)
> *重新构想舞蹈：舞者与AI之间的实时音乐共同创作*

*Olga Vechtomova, Jeff Bos* | **Main category: cs.SD**

**Keywords:** 舞蹈, AI, 音乐共同创作, 实时, 多模态, 人机协作

**Comment:** Accepted for publication at ICCC 2025 (International Conference on
  Computational Creativity)

> **TL;DR:** 该系统使舞者能通过动作实时共同创作音乐，将AI从编舞工具转变为响应式协作伙伴。

**AI_Comments:** 这篇论文通过引入舞者与AI实时音乐共同创作的概念，极大地创新了舞蹈表演和AI在艺术领域的应用。其核心贡献在于将传统单向的“动作响应音乐”转变为双向的“舞者即时塑造音乐”，赋予舞者作曲家的角色。多模态架构和对新兴交流模式的发现，为未来人机协作艺术创作提供了新的范式，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的舞蹈表演中，动作响应音乐是单向关系；尽管AI在创意领域有进展，但在舞蹈中主要用于从音乐输入生成编舞。本研究旨在改变这种单向关系，实现舞者与AI之间的双向音乐共同创作。

**Method:** 本文提出了一个多模态架构，该系统通过智能地组合预先录制的音乐片段来响应舞蹈动作，从而创建连贯的音乐作品。

**Result:** 通过对表演数据的相关性分析，研究表明动作质量和音频特征之间出现了新兴的交流模式。

**Conclusion:** 这种方法重新定义了AI在表演艺术中的角色，使其成为一个响应式的合作者，扩展了专业舞蹈表演和更广泛人群的即兴艺术表达的可能性。

> **ai_Abstract:** 本文提出了一个创新系统，实现了舞者与AI之间的实时音乐共同创作。该系统采用多模态架构，使舞者能通过动作动态地塑造音乐环境，智能组合预录音乐片段以生成连贯的音乐作品。这打破了传统舞蹈中动作单向响应音乐的模式，使舞者同时扮演表演者和作曲家的角色。研究通过数据分析揭示了动作与音频特征间的新兴交流模式，重新定义了AI在表演艺术中作为响应式合作者的潜力，拓宽了专业和即兴舞蹈的表达界限。

> **摘要翻译:** 舞蹈表演传统上遵循一种单向关系，即动作响应音乐。尽管人工智能在各种创意领域取得了进展，但其在舞蹈中的应用主要集中于从音乐输入生成编舞。我们提出了一个系统，使舞者能够通过他们的动作动态地塑造音乐环境。我们的多模态架构通过智能地组合预先录制的音乐片段以响应舞蹈动作，创造出连贯的音乐作品，从而建立了一种双向的创意伙伴关系，舞者既是表演者又是作曲家。通过对表演数据的相关性分析，我们展示了动作质量和音频特征之间新兴的交流模式。这种方法重新构想了人工智能在表演艺术中的作用，使其成为一个响应式的合作者，扩展了专业舞蹈表演和更广泛人群的即兴艺术表达的可能性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [36] [Social Networks: Enumerating Maximal Community Patterns in $c$-Closed Graphs](https://arxiv.org/abs/2506.11437)
> *社交网络：枚举 $c$-闭合图中的最大社群模式*

*Gabriela Bourla, Kaixin Wang, Fan Wei, Runtian Zhou* | **Main category: math.CO**

**Keywords:** c-闭合图, 社交网络, 最大模式, 图膨胀, 枚举

**Comment:** 38 pages

> **TL;DR:** 本文研究了在 $c$-闭合图中枚举任意图 $H$ 的最大膨胀（blow-ups），证明了对于固定的 $H$，其数量受限于多项式，并对诱导膨胀（induced blow-ups）进行了精确刻画。

**AI_Comments:** 本文的创新之处在于，它将 $c$-闭合图中可枚举模式的研究从简单的结构（如团和二分图）扩展到了任意图 $H$ 的“膨胀”形式。鉴于 $c$-闭合图是社交网络的重要模型，理解更复杂模式（即社群结构）的枚举复杂度具有重要意义。这一工作为社交网络中复杂社群结构的算法分析提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是 $c$-闭合图模型，这是一个由Fox等人（SICOMP 2020）引入的无分布模型，受社交网络中普遍存在的结构特征——三元闭包（triadic closure）的启发。虽然在一般图中枚举最大团可能需要指数时间，但已知在 $c$-闭合图中，最大团和最大完全二分图子图总能在多项式时间内枚举。这些结构对应于简单模式（单个顶点或单条边，其中一些顶点需要形成团）的膨胀。本文旨在探索一个自然的扩展，即研究 $c$-闭合图中任意有限图 $H$ 的最大膨胀。

**Method:** 本文研究了在 $c$-闭合图中任意有限图 $H$ 的最大膨胀（maximal blow-ups）的枚举问题。具体方法包括证明对于任意固定图 $H$，在 $n$ 个顶点的 $c$-闭合图中，最大 $H$-膨胀的数量受限于 $n$ 的多项式。此外，还深入探讨了诱导膨胀（induced blow-ups）的情况，并对图 $H$ 进行了精确刻画，使得最大诱导膨胀的数量也受限于 $n$ 的多项式。最后，研究了当 $H$ 遍历无限图族时的类似问题。

**Result:** 研究结果表明，对于任何固定的图 $H$，在 $n$ 个顶点的 $c$-闭合图中，最大 $H$-膨胀的数量总是受限于 $n$ 的多项式。此外，论文还提供了对图 $H$ 的精确刻画，对于这些图 $H$，最大诱导膨胀的数量也受限于 $n$ 的多项式。

**Conclusion:** 本文得出的结论是，在 $c$-闭合图中，对于任何固定的图 $H$，最大膨胀的数量在 $n$ 个顶点的图中总是受限于多项式时间。此外，论文还为诱导膨胀的情况提供了精确的 $H$ 图刻画，使得其数量也受限于多项式。这扩展了之前关于简单模式可枚举性的研究，将之推广到任意模式。

> **ai_Abstract:** 本文在 $c$-闭合图模型（一种受社交网络三元闭包启发的无分布模型）中，扩展了对最大社群模式的枚举研究。此前已知，简单模式（如最大团和完全二分图）可在多项式时间内枚举。本研究进一步证明，对于任意固定的图 $H$，其最大膨胀（maximal blow-ups）的数量在 $n$ 个顶点的 $c$-闭合图中也受限于多项式。此外，论文还精确刻画了哪些图 $H$ 的最大诱导膨胀（maximal induced blow-ups）数量也呈多项式增长，并探讨了 $H$ 属于无限图族的情况。

> **摘要翻译:** Fox、Seshadhri、Roughgarden、Wei和Wein（SICOMP 2020）引入了 $c$-闭合图模型——一个受三元闭包（社交网络中最普遍的结构特征之一）启发而来的无分布模型。虽然在一般图中枚举最大团可能需要指数时间，但已知在 $c$-闭合图中，最大团和最大完全二分图子图总能在多项式时间内枚举。这些结构对应于简单模式（单个顶点或单条边，其中一些顶点需要形成团）的膨胀。在这项工作中，我们探索了一个自然的扩展：我们研究 $c$-闭合图中任意有限图 $H$ 的最大膨胀。我们证明，对于任何固定的图 $H$，在 $n$ 个顶点的 $c$-闭合图中，最大 $H$-膨胀的数量总是受限于 $n$ 的多项式。我们进一步研究了诱导膨胀的情况，并对图 $H$ 进行了精确刻画，使得最大诱导膨胀的数量也受限于 $n$ 的多项式。最后，我们研究了当 $H$ 遍历无限图族时的类似问题。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [119] [Symmetries of weighted networks: weight approximation method and its application to food webs](https://arxiv.org/abs/2506.11824)
> *权重网络的对称性：权重近似方法及其在食物网中的应用*

*Julia Korol, Mateusz Iskrzyński* | **Main category: physics.soc-ph**

**Keywords:** 加权网络, 对称性, 权重近似, 食物网, 群论

**Comment:** 22 pages, 6 figures

> **TL;DR:** 本文提出了一种权重近似方法来研究加权网络的对称性，并将其应用于食物网，发现即使在弱近似下也能识别出具有相似角色的对称顶点。

**AI_Comments:** 本文创新性地提出了一种权重近似方法来处理加权网络的对称性分析，有效地解决了传统群论方法在处理真实世界加权网络时遇到的挑战。该方法在生态食物网中的应用展示了其识别具有功能可替代性物种的潜力，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在真实世界的加权网络中，边权重很少相等，导致精确对称性不常见。了解复杂系统各部分的相同作用有助于简化计算并揭示网络结构模式，因此需要一种方法来研究加权网络的对称性。

**Method:** 为了研究加权网络中的对称性，该方法将边权重聚合成少量离散类别，然后识别这些聚合网络的对称性以确定原始加权网络中具有相似作用的顶点。该方法被应用于250个经验食物网，并使用三种对称性度量来比较网络层面的结构模式。

**Result:** 即使在弱近似下，对称顶点也会出现，通常形成大小为二或三的小轨道。这些对称顶点可以出现在任何营养级别或网络位置。此外，还应用了三种对称性度量来比较网络层面的结构模式。

**Conclusion:** 该权重近似方法能够有效地识别加权网络中的对称性，有助于量化食物网中的生态共存和竞争，并通过评估物种的功能可替代性来揭示具有相似作用的顶点。

> **ai_Abstract:** 本文提出了一种新颖的权重近似方法来研究加权网络的对称性，旨在克服传统群论方法在处理真实世界加权网络时遇到的精确对称性不常见的问题。该方法通过将边权重聚合成离散类别，从而识别原始网络中具有相似角色的顶点。研究将此方法应用于250个经验食物网，发现即使在弱近似条件下也能识别出对称顶点，这些顶点通常形成小型轨道并可出现在网络的任何位置。此外，研究还利用三种对称性度量对网络层面的结构模式进行了比较，突显了该方法在量化生态共存和竞争方面的应用潜力。

> **摘要翻译:** 了解复杂系统中有哪些部分具有相同的作用，可以简化计算并揭示其网络结构中的模式。群论已被应用于研究无权网络中的对称性。然而，在现实世界的加权网络中，边权重很少相等，这使得精确对称性不常见。为了研究加权网络中的对称性，我们将边权重聚合成少量离散类别。这些聚合网络的对称性识别了原始加权网络中具有相似作用的顶点。在食物网中，这种方法通过评估物种的功能可替代性，有助于量化生态共存和竞争。我们将我们的方法应用于250个经验食物网，发现即使在弱近似下，对称顶点也会出现，通常形成大小为二或三的小轨道。这些对称顶点可以出现在任何营养级别或网络位置。我们还应用了三种对称性度量来比较网络层面的结构模式。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [136] [A Framework for Non-Linear Attention via Modern Hopfield Networks](https://arxiv.org/abs/2506.11043)
> *通过现代霍普菲尔德网络实现非线性注意力的框架*

*Ahmed Farooq* | **Main category: stat.ML**

**Keywords:** 现代霍普菲尔德网络, 非线性注意力, Transformer, 能量函数, 序列建模

**Comment:** 15 pages

> **TL;DR:** 本文提出了一个框架，通过现代霍普菲尔德网络（MNH）统一了Vaswani注意力机制，从而实现了非线性注意力，旨在增强Transformer模型在序列建模任务中的能力。

**AI_Comments:** 该论文通过能量函数巧妙地统一了现代霍普菲尔德网络和Transformer的注意力机制，为注意力提供了一个新颖的、基于能量景观的数学解释。其创新性在于将注意力视为能量景观的梯度下降过程，并引入了“上下文井”的概念。这种非线性注意力机制的提出，有望显著提升Transformer模型的表达能力和性能，克服传统线性注意力的局限性。其重要性在于为当前最先进的NLP模型提供了新的理论基础和潜在的性能改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强Transformer模型在各种序列建模任务中的能力，通过改善模型对复杂关系的理解、表示学习以及整体效率和性能。现有线性模型可能不足以捕获复杂的非线性关系。

**Method:** 提出了一种基于现代霍普菲尔德网络（MNH）的能量函数，其驻点对应于Vaswani等人的注意力机制，从而实现了两个框架的统一。这个能量景观的最小值形成了“上下文井”，封装了令牌之间的上下文关系，其梯度对应于注意力计算。

**Result:** 该框架成功统一了现代霍普菲尔德网络和Vaswani注意力机制。所提出的非线性注意力机制能够增强Transformer模型在序列建模任务中的表现，具体体现在对复杂关系的更深理解、更有效的表示学习以及整体效率和性能的提升。该方法可用于在基于Transformer的模型（如BERT）中引入非线性注意力头。

**Conclusion:** 通过统一现代霍普菲尔德网络和Vaswani注意力机制，本文提出了一个非线性注意力的框架，有望显著提升Transformer模型在序列建模任务中的能力和表现。

> **ai_Abstract:** 本文提出了一个通过现代霍普菲尔德网络（MNH）实现非线性注意力的框架，该框架将MNH与Vaswani等人的注意力机制统一起来。通过引入一个能量函数，其驻点对应于注意力，并且其最小值形成捕获令牌之间关系的“上下文井”。这个能量景观的梯度对应于注意力计算，从而实现了非线性注意力。这种非线性注意力机制能够增强Transformer模型在各种序列建模任务中的能力，提高其对复杂关系的理解、表示学习能力以及整体效率和性能，类似于三次样条对非线性数据的丰富表示。该方法可应用于在BERT等基于Transformer的模型中引入非线性注意力头。

> **摘要翻译:** 在这项工作中，我们提出了一种沿着现代霍普菲尔德网络（MNH）思路的能量函数，其驻点对应于Vaswani等人[12]的注意力，从而统一了这两个框架。这个景观的最小值形成了“上下文井”——封装了令牌之间上下文关系的稳定配置。一个引人注目的图景出现了：在n个令牌嵌入中定义了一个能量景观，其梯度对应于注意力计算。非线性注意力机制提供了一种增强Transformer模型在各种序列建模任务中能力的方法，通过改善模型对复杂关系的理解、表示学习以及整体效率和性能。一个粗略的类比可以通过三次样条看到，它提供了非线性数据更丰富的表示，而简单的线性模型可能不足。这种方法可以用于在基于Transformer的模型（如BERT [6]等）中引入非线性头。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [151] [On the performance of multi-fidelity and reduced-dimensional neural emulators for inference of physiologic boundary conditions](https://arxiv.org/abs/2506.11683)
> *关于多保真和降维神经模拟器在生理边界条件推断中的性能*

*Chloe H. Choi, Andrea Zanoni, Daniele E. Schiavazzi, Alison L. Marsden* | **Main category: stat.ML**

**Keywords:** 多保真, 神经模拟器, 贝叶斯推断, 心血管建模, 降维

**Comment:** 

> **TL;DR:** 该论文探索了使用低保真近似（神经模拟器、降维）来降低心血管逆问题中贝叶斯参数估计计算成本的方法，并在测试案例和心血管示例上进行了验证。

**AI_Comments:** 该论文通过结合多保真建模与神经网络和降维技术，解决了计算心血管建模中的一个重要挑战。建模模型差异或近似误差分布的想法对于在不牺牲过多准确性的前提下提高效率具有深刻的见解。其在患者特定模型上的应用突显了其实际相关性。

<details>
  <summary>Details</summary>

**Motivation:** 解决心血管建模中的逆问题计算成本高昂，特别是运行高保真模拟的成本。本研究的动机是通过利用低保真近似来降低从后验分布中采样的计算成本。

**Method:** 研究了多种降低计算成本的方法：1. 为高保真模拟本身构建代理模型。2. 为高保真和低保真模型之间的差异构建代理，使用全连接神经网络或非线性降维技术。3. 将高保真模型和代理模型之间的差异视为随机噪声，并使用归一化流估计其分布，从而修改似然函数以纳入近似误差。论文验证了五种不同的方法变体，通过与仅从高保真模型导出的后验分布进行比较，评估了准确性和计算成本。最后，在集总参数Windkessel模型和患者特定三维解剖结构这两个心血管示例上进行了演示。

**Result:** 论文在分析测试案例上验证了五种不同的方法，并将其与仅从高保真模型导出的后验分布进行了比较，评估了准确性和计算成本。此外，这些方法还在两个复杂度递增的心血管示例上得到了演示。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本论文旨在解决心血管建模中逆问题的高计算成本问题，特别是贝叶斯参数估计。它提出并探索了多种多保真和降维神经模拟器方法，以降低从后验分布中采样的成本。这些方法包括为高保真模拟构建代理、使用神经网络或降维技术对高低保真模型之间的差异进行建模，以及通过归一化流纳入近似误差。论文在分析测试案例上验证了五种方法变体的准确性和计算成本，并在Windkessel模型和患者特定心血管模型上进行了演示。

> **摘要翻译:** 解决心血管建模中的逆问题特别具有挑战性，因为运行高保真模拟的计算成本很高。在这项工作中，我们专注于贝叶斯参数估计，并探索通过利用低保真近似来降低从后验分布中采样的计算成本的不同方法。一种常见的方法是为高保真模拟本身构建代理模型。另一种方法是为高保真和低保真模型之间的差异构建代理。这种差异通常更容易近似，通过全连接神经网络或非线性降维技术进行建模，从而可以在较低维空间中构建代理。第三种可能的方法是将高保真模型和代理模型之间的差异视为随机噪声，并使用归一化流估计其分布。这使我们能够通过修改似然函数将近似误差纳入贝叶斯逆问题。我们通过将上述五种不同方法的变体与仅从高保真模型导出的后验分布进行比较，在分析测试案例上验证了它们，评估了准确性和计算成本。最后，我们在两个复杂度递增的心血管示例上演示了我们的方法：一个集总参数Windkessel模型和一个患者特定的三维解剖结构。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [395] [Spectral Estimation with Free Decompression](https://arxiv.org/abs/2506.11994)
> *自由解压的谱估计*

*Siavash Ameli, Chris van der Heide, Liam Hodgkinson, Michael W. Mahoney* | **Main category: stat.ML**

**Keywords:** 谱估计, 自由概率论, 自由解压, 大型矩阵, 难以触及矩阵

**Comment:** 

> **TL;DR:** 本文提出了一种名为“自由解压”的新方法，利用自由概率论的原理，从小型子矩阵的经验谱密度推断出无法直接访问的超大型矩阵的特征谱。

**AI_Comments:** 这项研究的创新之处在于将自由概率论引入到大型矩阵的谱估计问题中，特别是在矩阵数据“难以触及”的极端情况下。它提供了一种在传统方法失效时仍能进行谱分析的独特视角和工具，对于处理分布式和隐式定义的大规模数据具有重要意义。其局限性可能在于自由概率理论的适用范围和“自由解压”方法的计算效率。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习应用中，计算超大型矩阵的特征值至关重要，但随着数据集规模的增长，协方差和核矩阵变得过于庞大，难以直接形成。现有技术依赖矩阵-向量乘积，但在分布式学习或矩阵间接定义等场景下，即使是矩阵-向量乘积也可能无法获得，因为我们只能访问原始矩阵的掩码快照或非常小的子矩阵（即“难以触及”的矩阵）。

**Method:** 本文借鉴自由概率论的原理，引入了一种名为“自由解压”的新方法来估计此类“难以触及”矩阵的谱。该方法能够从小型子矩阵的经验谱密度推断出超大型（难以触及）矩阵的特征谱，这些矩阵无法形成或甚至无法通过完整的矩阵-向量乘积进行评估。

**Result:** 通过一系列例子验证了该方法的有效性。在合成设置中，将其性能与随机矩阵理论中已知的极限分布进行了比较；在真实世界数据集中，将其应用于子矩阵，并与它们的完整经验特征谱进行了匹配。

**Conclusion:** 该研究提出了一种有效的方法，可以在传统方法受限的场景下（即无法直接访问或形成完整矩阵，甚至无法进行矩阵-向量乘积）估计超大型矩阵的特征谱，从而为解决大规模机器学习中的谱估计问题提供了新途径。

> **ai_Abstract:** 本文针对大型矩阵特征值计算在机器学习中的挑战，特别是当矩阵“难以触及”时（即无法直接形成或进行矩阵-向量乘积），提出了一种基于自由概率论的“自由解压”新方法。该方法通过分析小规模子矩阵的经验谱密度，推断出大规模矩阵的特征谱。实验结果表明，该方法在合成数据和真实世界数据集上均能有效估计矩阵谱，为处理无法直接访问的超大型矩阵提供了可行方案。

> **摘要翻译:** 计算超大型矩阵的特征值是许多机器学习应用中的一项关键任务，包括对数行列式、矩阵函数迹以及其他重要指标的评估。随着数据集规模的持续增长，相应的协方差和核矩阵变得越来越大，其量级常常使得直接形成变得不切实际或不可能。现有技术通常依赖于矩阵-向量乘积，如果矩阵谱表现良好，这可以提供有效的近似。然而，在分布式学习等环境中，或者当矩阵仅间接定义时，对完整数据集的访问可能仅限于原始矩阵的非常小的子矩阵。在这些情况下，名义上的目标矩阵甚至不作为隐式算子可用，这意味着即使是矩阵-向量乘积也可能不可用。在这种情况下，矩阵是“难以触及的”，因为我们只能访问其掩码快照。我们借鉴自由概率论的原理，引入了一种名为“自由解压”的新颖方法来估计此类矩阵的谱。我们的方法可以用于从小型子矩阵的经验谱密度推断出超大型（难以触及的）矩阵的特征谱（这些矩阵我们无法形成，甚至无法通过完整的矩阵-向量乘积进行评估）。我们通过一系列例子展示了这种方法的有效性，在合成设置中将其性能与随机矩阵理论中已知的极限分布进行了比较，并将其应用于真实世界数据集的子矩阵，使其与完整的经验特征谱相匹配。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [608] [Collaborative Prediction: To Join or To Disjoin Datasets](https://arxiv.org/abs/2506.11271)
> *协同预测：合并还是分离数据集*

*Kyung Rok Kim, Yansong Wang, Xiaocheng Li, Guanting Chen* | **Main category: stat.ML**

**Keywords:** 数据集选择, 协同预测, 总体损失, 机器学习, 理论保证

**Comment:** To be published in the 41st Conference on Uncertainty in Artificial
  Intelligence (UAI 2025)

> **TL;DR:** 本文研究如何选择高质量数据集以最小化预测模型的总体损失，并提出了一个具有理论保证的实用算法，该算法通过合并或分离数据集来提高预测性能。

**AI_Comments:** 这篇论文解决了机器学习中一个关键但未被充分探索的问题：如何有效选择和组合数据集以提高预测模型的性能。其创新之处在于提出了一个具有理论保证的实用算法，能够智能地决定数据集的合并或分离。该方法利用了预言不等式和数据驱动估计器，为实际应用提供了坚实的理论基础。其在多种机器学习应用中的有效性也表明了其潜在的广泛影响。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI的兴起，选择高质量数据集以改进机器学习模型的需求日益增长。然而，即使对于简单的预测模型，如何有效选择数据集以最小化预测模型的总体损失这一问题仍未得到充分探索。

**Method:** 作者研究了何时可以将来自不同来源的数据集有效合并以增强预测模型性能的问题，并提出了一个具有理论保证的实用算法。该算法利用预言不等式和数据驱动估计器来减少总体损失。

**Result:** 该算法能够以高概率减少总体损失。数值实验表明，该算法在标准线性回归和更广泛的机器学习应用中都有效。

**Conclusion:** 本文提出了一个具有理论保证的实用算法，用于选择适当的数据集以最小化预测模型的总体损失，并通过实验证明了其有效性。

> **ai_Abstract:** 本文探讨了在机器学习模型中选择高质量数据集以最小化预测模型总体损失的问题。研究人员提出了一个实用的算法，该算法具有理论保证，能够判断何时合并或分离来自不同来源的数据集以优化预测性能。该算法通过利用预言不等式和数据驱动估计器，能够以高概率降低总体损失，并在各种机器学习应用中展现出有效性。

> **摘要翻译:** 随着生成式人工智能（AI）的兴起，选择高质量数据集以改进机器学习模型的需求日益受到关注。然而，即使对于简单的预测模型，这一主题的某些部分仍未得到充分探索。在这项工作中，我们研究了开发实用算法的问题，这些算法选择适当的数据集，以高概率最小化我们预测模型的总体损失。广义而言，我们调查了何时可以有效地合并来自不同来源的数据集以增强预测模型的性能，并提出了一个具有理论保证的实用算法。通过利用预言不等式和数据驱动估计器，该算法以高概率减少了总体损失。数值实验证明了其在标准线性回归和更广泛的机器学习应用中的有效性。代码可在 https://github.com/kkrokii/collaborative_prediction 获取。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [610] [Fast Bayesian Optimization of Function Networks with Partial Evaluations](https://arxiv.org/abs/2506.11456)
> *函数网络快速贝叶斯优化与部分评估*

*Poompol Buathong, Peter I. Frazier* | **Main category: stat.ML**

**Keywords:** 贝叶斯优化, 函数网络, 部分评估, p-KGFN, 计算开销

**Comment:** 16 pages, 8 figures, 1 table

> **TL;DR:** 本文提出了一种加速的p-KGFN算法，通过廉价的全局蒙特卡罗模拟生成节点特定的候选输入，显著降低了计算开销，同时保持了查询效率，比原始p-KGFN算法提速高达16倍。

**AI_Comments:** 本文的创新点在于通过巧妙地引入全局蒙特卡罗模拟来生成节点特定的候选输入，有效地解决了p-KGFN算法计算开销过大的问题。这种方法在保证查询效率的同时，显著提升了算法的实用性，对于需要优化复杂且昂贵函数网络的实际应用具有重要意义。其贡献在于提供了一个更高效的贝叶斯优化工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统的贝叶斯优化函数网络（BOFN）在处理具有独立可评估节点和不同成本的函数网络时，尽管p-KGFN变体能够利用部分评估来减少昂贵的函数评估次数，但其计算开销巨大，需要为网络中每个节点优化基于嵌套蒙特卡罗的采集函数。本文旨在解决p-KGFN的这一高计算开销问题。

**Method:** 我们提出了一种加速的p-KGFN算法。其核心在于通过一次廉价的全局蒙特卡罗模拟，为网络中的每个节点生成节点特定的候选输入，从而减少了计算开销。

**Result:** 数值实验表明，我们的方法在保持竞争性查询效率的同时，比原始的p-KGFN算法实现了高达16倍的加速。

**Conclusion:** 本文成功开发了一种加速的p-KGFN算法，显著降低了贝叶斯优化函数网络的计算开销，同时保持了高效的查询性能，使其在实际应用中更具可行性。

> **ai_Abstract:** 本文针对贝叶斯优化函数网络（BOFN）中p-KGFN算法计算开销大的问题，提出了一种加速算法。该算法通过一次全局蒙特卡罗模拟生成节点特定的候选输入，显著降低了计算复杂性。实验结果显示，新方法在保持查询效率的同时，实现了比原始p-KGFN算法高达16倍的速度提升，为昂贵的函数网络优化提供了更高效的解决方案。

> **摘要翻译:** 函数网络贝叶斯优化（BOFN）是一种优化结构化为网络的昂贵评估目标函数的框架，其中某些节点的输出作为其他节点的输入。许多实际应用，例如制造业和药物发现，涉及具有额外属性的函数网络——可以独立评估并产生不同成本的节点。最近的BOFN变体p-KGFN利用了这种结构并实现了成本感知的部分评估，在每次迭代中选择性地查询节点的子集。p-KGFN减少了所需昂贵目标函数评估的数量，但计算开销很大：选择在哪里评估需要为网络中的每个节点优化基于嵌套蒙特卡罗的采集函数。为了解决这个问题，我们提出了一种加速的p-KGFN算法，该算法在查询效率仅有适度损失的情况下减少了计算开销。我们方法的关键是通过一次廉价的全局蒙特卡罗模拟为网络中的每个节点生成节点特定的候选输入。数值实验表明，我们的方法在保持竞争性查询效率的同时，比原始的p-KGFN算法实现了高达16倍的加速。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [614] [Using Deep Operators to Create Spatio-temporal Surrogates for Dynamical Systems under Uncertainty](https://arxiv.org/abs/2506.11761)
> *使用深度算子为不确定性动力系统创建时空代理模型*

*Jichuan Tang, Patrick T. Brewick, Ryan G. McClarren, Christopher Sweet* | **Main category: stat.ML**

**Keywords:** 深度算子网络, 时空代理, 动力系统, 结构动力学, 不确定性

**Comment:** 

> **TL;DR:** 提出了一种新的深度算子网络(FExD)，用于为不确定性下的动力系统创建高效准确的时空代理模型。

**AI_Comments:** 该研究提出了FExD，一个针对时空数据预测的深度算子网络新变体，其创新点在于通过增强分支和主干网络的表达能力，实现了对复杂动力系统完整解算子的有效学习。其重要性体现在为处理不确定性下的时空响应预测提供了一种高效且准确的工具，尤其适用于土木基础设施等需要精确模拟的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有科学机器学习（SciML）方法在处理单个时间历史的响应预测方面取得了显著进展，但创建完整的时空代理模型仍然是一个挑战。

**Method:** 本研究提出了一种新型的深度算子网络（DeepONets）变体，即全场扩展深度算子网络（FExD），作为时空代理模型。FExD通过增强分支网络的表达能力和扩展主干网络的预测能力，有效地学习了跨多个自由度的完整解算子。该模型被部署用于同时捕获斜拉桥试验台模型在随机地面运动下多个传感位置的动力学。

**Result:** FExD产生的响应预测与标准DeepONet和修改后的时空Extended DeepONet进行了全面比较，结果表明FExD在准确性和计算效率方面均表现出卓越性。

**Conclusion:** 提出的FExD模型在结构动力学应用的算子学习方面取得了显著进展，能够实现更高的准确性和计算效率。

> **ai_Abstract:** 本文提出了一种名为全场扩展深度算子网络（FExD）的新型深度算子网络，旨在解决在不确定性下为动力系统创建完整时空代理模型的挑战。FExD通过改进网络结构来增强其学习完整解算子的能力，并在斜拉桥模型上进行了验证。实验结果表明，FExD在准确性和计算效率方面均优于现有方法，为结构动力学中的算子学习提供了显著改进。

> **摘要翻译:** 时空数据由在不同时间和位置收集的响应或测量组成，在民用基础设施的各种应用中无处不在。虽然科学机器学习（SciML）方法在解决单个时间历史的响应预测问题上取得了显著进展，但创建完整的时空代理模型仍然是一个挑战。本研究提出了一种新型的深度算子网络（DeepONets）变体，即全场扩展深度算子网络（FExD），以作为时空代理模型，为动力系统提供多输出响应预测。所提出的FExD代理模型通过增强分支网络的表达能力和扩展主干网络的预测能力，有效地学习了跨多个自由度的完整解算子。所提出的FExD代理被部署用于同时捕获受随机地面运动影响的斜拉桥试验台模型沿多个传感位置的动力学。FExD产生的响应预测与标准DeepONet和修改后的时空Extended DeepONet进行了全面比较。结果表明，所提出的FExD能够实现卓越的准确性和计算效率，代表了结构动力学应用中算子学习的重大进步。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [615] [Bayesian Optimization with Inexact Acquisition: Is Random Grid Search Sufficient?](https://arxiv.org/abs/2506.11831)
> *贝叶斯优化中的不精确采集：随机网格搜索是否足够？*

*Hwanwoo Kim, Chong Liu, Yuxin Chen* | **Main category: stat.ML**

**Keywords:** 贝叶斯优化, 采集函数, 不精确最大化, 随机网格搜索, 累积遗憾

**Comment:** This paper is accepted to UAI 2025

> **TL;DR:** 针对贝叶斯优化中采集函数最大化计算昂贵的问题，本文研究了不精确最大化器的影响，证明在一定条件下不精确BO算法仍能达到次线性累积遗憾，并提出随机网格搜索是一种有效且高效的求解器。

**AI_Comments:** 本文的创新点在于首次系统地分析了贝叶斯优化中采集函数不精确最大化的影响，并从理论上证明了其在一定条件下的性能保证。这对于实际应用中计算资源有限的场景具有重要意义，因为它放宽了对精确求解的严格要求，并提出了随机网格搜索这一实用且高效的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 贝叶斯优化（BO）中，每次迭代都需要最大化一个采集函数，但找到这些最大化问题的精确解通常是难以处理且计算成本高昂的。本文旨在探究不精确采集函数最大化器的影响。

**Method:** 本文定义了采集解决方案中不精确性的度量，并为GP-UCB和GP-TS建立了累积遗憾界，无需采集函数最大化的精确解。此外，提供了随机网格搜索作为采集函数求解器的理论证明和数值验证。

**Result:** 研究结果表明，在累积不精确度满足适当条件的情况下，不精确的BO算法仍然可以实现次线性的累积遗憾。

**Conclusion:** 即使采集函数最大化不精确，贝叶斯优化算法在特定条件下仍能保持良好的性能（次线性累积遗憾）。随机网格搜索被证明是一种有效且计算高效的采集函数求解器。

> **ai_Abstract:** 本文探讨了贝叶斯优化（BO）中采集函数最大化不精确对算法性能的影响。研究定义了不精确度量，并为GP-UCB和GP-TS建立了累积遗憾界，证明了在一定不精确条件下BO算法仍能达到次线性累积遗憾。此外，文章还从理论和数值两方面验证了随机网格搜索作为一种高效的采集函数求解方法。

> **摘要翻译:** 贝叶斯优化（BO）是一种广泛使用的迭代算法，用于优化黑盒函数。每次迭代都需要最大化一个采集函数，例如上限置信度（UCB）或来自高斯过程（GP）后验的样本路径，如Thompson采样（TS）中所示。然而，找到这些最大化问题的精确解通常是难以处理且计算成本高昂的。为了反映这种现实情况，在本文中，我们深入研究了采集函数不精确最大化器的影响。通过定义采集解决方案中不精确性的度量，我们为GP-UCB和GP-TS建立了累积遗憾界，而无需采集函数最大化的精确解。我们的结果表明，在累积不精确度满足适当条件的情况下，不精确的BO算法仍然可以实现次线性的累积遗憾。受这些发现的启发，我们为随机网格搜索作为一种有效且计算高效的采集函数求解器提供了理论依据和数值验证。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [616] [Learning Overspecified Gaussian Mixtures Exponentially Fast with the EM Algorithm](https://arxiv.org/abs/2506.11850)
> *使用EM算法指数级快速学习过参数高斯混合模型*

*Zhenisbek Assylbekov, Alan Legg, Artur Pak* | **Main category: stat.ML**

**Keywords:** EM算法, 高斯混合模型, 过参数化, 指数收敛, Polyak-Łojasiewicz不等式

**Comment:** ECML PKDD 2025

> **TL;DR:** 本研究表明，在特定结构配置下，当高斯混合模型被过参数化时，EM算法的收敛速度是指数级的，这比传统方法快得多，并提供了理论证明和实践见解。

**AI_Comments:** 这项工作的重要创新在于证明了EM算法在特定过参数化高斯混合模型设置下能够实现指数级快速收敛，打破了传统上认为EM收敛慢的观念。通过结合强凸性和Polyak-Łojasiewicz不等式，提供了严格的理论保证，并得到了数值实验的验证，这对于理解EM的复杂行为及其在实际应用中的潜力具有重要意义。它不仅是理论突破，也为高维数据分析提供了实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究EM算法应用于过参数化高斯混合模型时的收敛特性，即当拟合模型中的组件数量超过真实潜在分布的组件数量时，并证明其能够实现指数级快速收敛。

**Method:** 研究聚焦于一种结构化配置：组件均值位于正单纯形的顶点，并且混合权重满足非退化条件。分析利用负对数似然函数在最优值附近区域的强凸性，并应用Polyak-Łojasiewicz不等式来建立收敛性。此外，将这些结果扩展到有限样本设置，并进行了数值实验验证。

**Result:** 在指定配置下，总体EM算法以Kullback-Leibler (KL) 距离衡量，实现指数级快速收敛。ε-精确近似可在O(log(1/ε))次迭代中实现。推导出了有限样本设置下的明确统计收敛保证。数值实验证实了理论发现，显示出与传统次线性速率相比显著的收敛加速。

**Conclusion:** 这项工作不仅加深了对EM算法在过参数化设置中行为的理解，而且为高维聚类和密度估计任务中的初始化策略和模型设计提供了实践见解。

> **ai_Abstract:** 本论文深入探讨了EM算法在过参数化高斯混合模型中的收敛行为。通过在特定结构化配置（组件均值在单纯形顶点，权重非退化）下，利用负对数似然的强凸性和Polyak-Łojasiewicz不等式，证明了总体EM算法在KL距离上实现指数级快速收敛，达到ε-精度仅需O(log(1/ε))次迭代。研究还扩展到有限样本，提供了统计收敛保证。数值实验支持理论，揭示了相较于传统方法的显著加速。这项工作提升了对EM算法在过参数化情境下理解，并为高维聚类和密度估计提供了实用的初始化和模型设计指导。

> **摘要翻译:** 我们研究了EM算法应用于过参数化高斯混合模型时的收敛特性——即当拟合模型中的组件数量超过真实潜在分布的组件数量时。本文聚焦于一种结构化配置，其中组件均值位于正单纯形的顶点，并且混合权重满足非退化条件，我们证明了总体EM算法在Kullback-Leibler (KL) 距离方面以指数级速度收敛。我们的分析利用了负对数似然函数在最优值附近区域的强凸性，并利用Polyak-Łojasiewicz不等式来建立在O(log(1/ε))次迭代中可以实现ε-精确近似。此外，我们通过推导明确的统计收敛保证，将这些结果扩展到有限样本设置。合成数据集上的数值实验证实了我们的理论发现，突出了与传统次线性速率相比收敛的显著加速。这项工作不仅加深了对EM算法在过参数化设置中行为的理解，而且为高维聚类和密度估计任务中的初始化策略和模型设计提供了实践见解。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [617] [How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?](https://arxiv.org/abs/2506.11869)
> *概率图模型和图神经网络如何看待网络数据？*

*Michela Lapenna, Caterina De Bacco* | **Main category: stat.ML**

**Keywords:** 概率图模型, 图神经网络, 链路预测, 异质性, 鲁棒性

**Comment:** 

> **TL;DR:** 本文通过链路预测任务，比较了概率图模型（PGMs）和图神经网络（GNNs）在处理网络数据时的表现，发现PGMs在低维、噪声输入特征和高异质性图上表现优于GNNs。

**AI_Comments:** 本文通过实证研究，对概率图模型（PGMs）和图神经网络（GNNs）在处理网络数据方面的优劣进行了深入比较。其创新之处在于，不仅关注了在理想条件下的性能，更深入探讨了PGMs在面对低维、噪声特征和高异质性图等真实世界复杂场景时的潜在优势，这对于理解两种模型的适用边界具有重要意义。研究结果挑战了GNNs在所有图任务中都占据主导地位的普遍认知，为实际应用中选择合适的模型提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 概率图模型（PGMs）和图神经网络（GNNs）都能利用图结构数据，但其内在运作方式不同。研究动机是比较它们在捕获网络数据集信息方面的表现。

**Method:** 通过解决链路预测任务来比较PGMs和GNNs。进行了三项主要实验，分别在合成和真实网络上：1) 关注它们如何处理输入特征；2) 调查它们对噪声特征的鲁棒性；3) 调查它们对图异质性增加的鲁棒性。此外，还比较了它们的计算复杂度和可解释性。

**Result:** 1. PGMs不一定需要节点特征，而GNNs不能单独利用网络边缘，输入特征的选择很重要。2. 当输入特征为低维或有噪声时（模拟真实场景），GNNs的表现不如PGMs。3. 当图的异质性增加时，PGMs比GNNs更具鲁棒性。

**Conclusion:** 在处理网络数据时，特别是在输入特征低维、噪声或图异质性较高的情况下，概率图模型（PGMs）在链路预测任务中的表现和鲁棒性优于图神经网络（GNNs）。此外，研究还比较了它们的计算复杂度和可解释性。

> **ai_Abstract:** 本文比较了概率图模型（PGMs）和图神经网络（GNNs）在处理网络数据时的能力差异。研究通过链路预测任务，在合成和真实网络上，从输入特征处理、对噪声特征的鲁棒性以及对图异质性的鲁棒性三个方面进行了实验。结果表明，当输入特征低维或有噪声时，以及图异质性增加时，PGMs的表现和鲁棒性优于GNNs。文章还对两种框架的计算复杂度和可解释性进行了比较。

> **摘要翻译:** 图是一种强大的数据结构，用于表示关系数据，并广泛用于描述复杂的现实世界系统。概率图模型（PGMs）和图神经网络（GNNs）都可以利用图结构数据，但它们的内在功能不同。问题是它们在捕获网络数据集所包含的信息方面如何比较？我们通过解决链路预测任务来解决这个目标，并在合成和真实网络上进行了三个主要实验：一个侧重于PGMs和GNNs如何处理输入特征，而另外两个则调查它们对噪声特征和图异质性增加的鲁棒性。PGMs不一定需要节点特征，而GNNs不能单独利用网络边缘，并且输入特征的选择很重要。我们发现，当输入特征是低维或有噪声时，PGMs的表现优于GNNs，这模仿了许多节点属性可能是标量或有噪声的真实场景。然后，我们发现当图的异质性增加时，PGMs比GNNs更具鲁棒性。最后，为了评估预测任务之外的性能，我们还在计算复杂度和可解释性方面比较了这两个框架。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [156] [Few Single-Qubit Measurements Suffice to Certify Any Quantum State](https://arxiv.org/abs/2506.11355)
> *少量单量子比特测量足以认证任何量子态*

*Meghal Gupta, William He, Ryan O'Donnell* | **Main category: quant-ph**

**Keywords:** 量子态认证, 单量子比特测量, 量子信息科学, 复杂度

**Comment:** 

> **TL;DR:** 本研究表明，只需对O(n)个实验室制备的量子态副本进行O(n^2)次单量子比特测量，即可认证任何纯假设态，解决了黄、普雷斯基尔和索莱马尼法尔提出的主要开放问题。

**AI_Comments:** 这项工作在量子态认证领域取得了重要突破，首次证明了仅需多项式数量的单量子比特测量即可认证任何纯量子态，显著提高了认证效率，并解决了长期存在的开放问题，对量子信息科学具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子信息科学中的一项基本任务是态认证：测试实验室制备的n量子比特态是否接近给定的假设态。此前，尚不清楚是否连亚指数级的单量子比特测量就足以认证任意态。

**Method:** 该研究表明，通过对O(n)个实验室制备的量子态副本应用O(n^2)次单量子比特测量，即可认证每一个纯假设态。

**Result:** 该研究证明，只需对O(n)个实验室制备的量子态副本进行O(n^2)次单量子比特测量，即可认证每一个纯假设态。

**Conclusion:** 这项工作解决了黄、普雷斯基尔和索莱马尼法尔（FOCS 2024, QIP 2024）提出的主要开放问题。

> **ai_Abstract:** 本研究解决了量子信息科学中态认证的关键问题，证明了只需O(n)个量子态副本和O(n^2)次单量子比特测量，即可有效地认证任何纯量子态。此前，关于是否能用亚指数级的单量子比特测量认证任意态的问题一直未解，本工作为此提供了肯定的答案，解决了黄、普雷斯基尔和索莱马尼法尔提出的主要开放问题。

> **摘要翻译:** 量子信息科学中的一项基本任务是态认证：测试实验室制备的n量子比特态是否接近给定的假设态。在这项工作中，我们证明了每一个纯假设态都可以仅通过对O(n)个实验室制备的量子态副本进行O(n^2)次单量子比特测量来认证。在我们工作之前，尚不清楚是否连亚指数级的单量子比特测量就足以认证任意态。这解决了黄、普雷斯基尔和索莱马尼法尔（FOCS 2024, QIP 2024）提出的主要开放问题。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [166] [Knapsack and Shortest Path Problems Generalizations From A Quantum-Inspired Tensor Network Perspective](https://arxiv.org/abs/2506.11711)
> *背包问题和最短路径问题的泛化：一个量子启发张量网络视角*

*Sergio Muñiz Subiñas, Jorge Martínez Martín, Alejandro Mata Ali, Javier Sedano, Ángel Miguel García-Vico* | **Main category: quant-ph**

**Keywords:** 张量网络, 量子启发, 背包问题, 最短路径, 组合优化

**Comment:** 14 pages, 14 figures, extended version of the presented and published
  at the 1st International Conference on Quantum Software (IQSOFT)

> **TL;DR:** 本文提出了两种基于量子启发张量网络的算法，用于精确求解背包问题和最短路径问题及其变体，并通过引入对称性和中间计算复用降低了计算复杂度，实验证明其效率优于经典算法。

**AI_Comments:** 本文的创新点在于将量子启发式张量网络方法应用于解决经典的组合优化问题（背包问题和最短路径问题），并能获得精确解。通过引入对称性和复用中间计算来降低计算复杂度是其亮点。这项工作为解决这些NP-hard问题提供了一个新的视角和潜在更高效的精确算法。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决背包问题和最短路径问题及其变体，并提供一种精确的量子启发算法。

**Method:** 本文提出了两种张量网络量子启发算法，用于解决背包问题和最短路径问题。这些方法基于虚时间演化和张量网络中的限制实现，并引入了对称性和中间计算的复用以降低计算复杂度。

**Result:** 所提出的方法提供了一个返回问题最优解的精确方程。性能实验表明，这些实现是高效的，并且结果优于其他经典算法。

**Conclusion:** 本文提出的量子启发张量网络算法能够精确有效地解决背包问题和最短路径问题及其变体，并通过优化方法降低了计算复杂度。

> **ai_Abstract:** 本文提出了两种基于量子启发张量网络的算法，用于精确求解背包问题和最短路径问题及其变体。这些算法利用虚时间演化、张量网络限制、对称性以及中间计算复用，有效降低了计算复杂度。实验结果表明，与传统算法相比，所提出的方法具有更高的效率。

> **摘要翻译:** 在本文中，我们提出了两种张量网络量子启发算法来解决背包问题和最短路径问题，并能够解决其一些变体。这些方法提供了一个返回问题最优解的精确方程。与其他用于组合优化问题的张量网络算法一样，该方法基于虚时间演化和张量网络中限制的实现。此外，我们引入了对称性的使用和中间计算的复用，从而降低了这两个问题的计算复杂度。为了展示我们实现的效率，我们进行了一些性能实验，并将结果与其他经典算法进行了比较。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [187] [Controlling quantum chaos via Parrondo strategies on NISQ hardware](https://arxiv.org/abs/2506.11225)
> *通过Parrondo策略在NISQ硬件上控制量子混沌*

*Aditi Rath, Dinesh Kumar Panda, Colin Benjamin* | **Main category: quant-ph**

**Keywords:** 量子混沌, NISQ, 量子游走, Parrondo策略, 动态解耦

**Comment:** 18 pages, 22 figures, 6 tables

> **TL;DR:** 该论文探讨并控制了NISQ系统中的量子混沌，通过量子游走和Parrondo策略，实验性地展示了从混沌到有序的转变。

**AI_Comments:** 该论文提出了一种在当前NISQ硬件上控制量子混沌的创新方法，这对于处理噪声是一个重大挑战。Parrondo策略和DTQW的运用，结合QFT和动态解耦等优化技术，为探索复杂的量子动力学提供了一条实用的途径。其对未来量子算法和密码学的潜在影响值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 探索和控制NISQ系统中的量子混沌，利用NISQ计算的进步，为未来基于量子游走的量子算法和密码协议奠定基础。

**Method:** 使用循环图上的离散时间量子游走（DTQW），通过量子傅里叶变换（QFT）优化电路深度和保真度，并采用Parrondo悖论策略在三种不同的NISQ设备上实现，同时对3周期图使用动态解耦脉冲以提高保真度。

**Result:** 成功实现了通过DTQW动力学从量子混沌到有序的转变，4周期图表现出高保真度量子演化，3周期实现通过动态解耦脉冲显著提高了保真度。

**Conclusion:** 该研究展示了一种在真实量子硬件上探测和利用受控混沌动力学的实用方法，为未来基于量子游走的量子算法和密码协议奠定了基础。

> **ai_Abstract:** 这篇论文研究了在噪声中等规模量子（NISQ）硬件上控制量子混沌的方法。它利用循环图上的离散时间量子游走（DTQW），并通过量子傅里叶变换（QFT）进行优化，以在NISQ硬件上高效实现。通过应用Parrondo悖论策略，作者在三种不同的NISQ设备上，对3周期和4周期图实验性地展示了从量子混沌到有序的转变。研究强调了4周期图的高保真度演化，以及通过动态解耦对3周期图的保真度改进，展示了一种利用受控混沌动力学以开发未来量子算法和密码协议的实用方法。

> **摘要翻译:** NISQ（噪声中等规模量子）计算的进步正在稳步推动这些系统在特定、明确的计算任务上超越经典超级计算机。在这项工作中，我们使用循环图上的离散时间量子游走（DTQW）探索和控制NISQ系统中的量子混沌。为了在NISQ硬件上高效实现量子游走，我们采用量子傅里叶变换（QFT）来对条件位移算符进行对角化，从而优化电路深度和保真度。我们通过在三个不同的NISQ设备上使用反直觉的Parrondo悖论策略，在奇数和偶数循环图（特别是3周期和4周期图）上，通过DTQW动力学实验性地实现了从量子混沌到有序的转变。虽然4周期图表现出高保真度的量子演化，但3周期实现通过动态解耦脉冲增强后显示出显著的保真度改进。我们的结果展示了一种在真实量子硬件上探测和利用受控混沌动力学的实用方法，为未来基于量子游走的量子算法和密码协议奠定了基础。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [593] [HQFNN: A Compact Quantum-Fuzzy Neural Network for Accurate Image Classification](https://arxiv.org/abs/2506.11146)
> *HQFNN：一种用于精确图像分类的紧凑型量子模糊神经网络*

*Jianhong Yao, Yangming Guo* | **Main category: quant-ph**

**Keywords:** 量子模糊神经网络, 图像分类, 参数效率, 噪声容忍, 可解释性

**Comment:** 

> **TL;DR:** HQFNN是一种紧凑的量子模糊神经网络，在浅层量子电路中实现模糊推理，并结合轻量级CNN，在图像分类任务中表现优于现有基线，具有高参数效率、鲁棒性和可解释性。

**AI_Comments:** HQFNN的创新点在于将模糊推理的整个流程集成到浅层量子电路中，并与经典CNN结合，实现了量子计算在图像分类中的应用，同时兼顾了参数效率、鲁棒性和可解释性。这为未来构建更紧凑、高效且鲁棒的量子-经典混合视觉系统提供了有价值的探索方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习视觉系统在处理噪声输入或模型需要解释自身置信度时表现不佳。模糊推理和参数化量子电路各自提供了潜在的解决方案。

**Method:** 本文提出了一种创新的高度量子化模糊神经网络（HQFNN），它在浅层量子电路中实现了整个模糊推理流程，并将所产生的量子信号与轻量级CNN特征提取器耦合。图像特征首先通过重复角度重上传映射到单量子比特隶属度状态，然后紧凑的规则层细化这些幅度，最后聚类CNOT去模糊器将它们折叠成一个清晰值，该值在分类前与经典特征融合。

**Result:** HQFNN在标准图像基准测试中始终超越经典、模糊增强和纯量子基线；使用的可训练权重数量少几个数量级；在模拟去极化和振幅衰减噪声下，其精度仅略微下降，显示出固有的鲁棒性；门计数分析表明电路深度随输入维度亚线性增长，证实了模型对大图像的实用性。

**Conclusion:** HQFNN被定位为传统视觉骨干网络的紧凑、可解释和噪声容忍的替代方案，并为未来的量子原生模糊学习框架提供了模板。

> **ai_Abstract:** 本文提出了一种名为HQFNN的紧凑型量子模糊神经网络，旨在解决深度学习在噪声环境和可解释性方面的不足。HQFNN将模糊推理过程完全嵌入浅层量子电路中，并与轻量级CNN结合。该模型通过量子比特隶属度、规则层和CNOT去模糊器处理图像特征。实验结果表明，HQFNN在图像分类任务上优于现有基线，同时显著减少了可训练参数，并展现出对噪声的鲁棒性以及对大图像的实用性，为量子原生模糊学习提供了新范式。

> **摘要翻译:** **摘要：**
深度学习视觉系统在模式识别方面表现出色，但在输入存在噪声或模型必须解释其自身置信度时则表现不佳。模糊推理及其分级隶属度和规则透明性提供了一种补救措施，而参数化量子电路则能以惊人的参数效率在高度纠缠的希尔伯特空间中嵌入特征。本研究将这些思想结合起来，引入了一种创新的高度量子化模糊神经网络（HQFNN），该网络在浅层量子电路中实现了整个模糊管道，并将所产生的量子信号与轻量级CNN特征提取器耦合。每个图像特征首先通过重复角度重上传映射到单个量子比特隶属度状态。然后，紧凑的规则层细化这些幅度，一个聚类的CNOT去模糊器将它们折叠成一个清晰值，该值在分类前与经典特征融合。在标准图像基准测试中进行评估，HQFNN始终超越了经典、模糊增强和纯量子基线，同时使用的可训练权重数量少了几个数量级，并且其精度在模拟去极化和振幅衰减噪声下仅略微下降，这证明了其固有的鲁棒性。门计数分析进一步表明，电路深度随输入维度亚线性增长，证实了该模型对于更大图像的实用性。这些结果将该模型定位为传统视觉骨干网络的紧凑、可解释和噪声容忍的替代方案，并为未来的量子原生模糊学习框架提供了模板。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [612] [Learning Encodings by Maximizing State Distinguishability: Variational Quantum Error Correction](https://arxiv.org/abs/2506.11552)
> *学习通过最大化状态可区分性进行编码：变分量子纠错*

*Nico Meyer, Christopher Mutschler, Andreas Maier, Daniel D. Scherer* | **Main category: quant-ph**

**Keywords:** 量子纠错, 变分量子纠错, 状态可区分性, 噪声结构, 机器学习

**Comment:** 50 pages, 24 figures, 7 tables

> **TL;DR:** 本文提出了一种变分量子纠错（VarQEC）方法，通过最大化噪声通道后量子态的可区分性来为特定噪声结构定制资源高效的纠错码，并在理论和硬件上进行了验证。

**AI_Comments:** 本文提出了一个新颖的视角，即通过最大化状态可区分性来设计量子纠错码，这为量子纠错领域提供了一个新的机器学习优化框架。VarQEC方法有望为近中期量子设备提供更高效、更具适应性的纠错方案，其在实际硬件上的概念验证也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量子纠错码（如表面码）需要大量开销，不适用于近期的早期容错设备。因此，需要为特定噪声结构定制更高效的纠错码。

**Method:** 提出了一种新的目标函数——可区分性损失函数，作为机器学习目标，通过最大化噪声通道后量子态的可区分性来发现资源高效的编码电路。该方法通过变分技术实现，称为变分量子纠错（VarQEC）。

**Result:** 该方法产生的代码具有理想的理论和实践特性，并在各种情况下优于标准代码。同时，在IBM和IQM硬件设备上提供了概念验证演示。

**Conclusion:** 变分量子纠错（VarQEC）通过最大化状态可区分性，为特定噪声结构提供了资源高效的纠错码，在理论和实践中均表现出色，对于保护量子信息免受退相干具有重要意义。

> **ai_Abstract:** 本文提出了一种名为变分量子纠错（VarQEC）的新方法，旨在解决传统量子纠错码在近中期量子设备上开销过大的问题。VarQEC通过引入一个“可区分性损失函数”作为机器学习目标，最大化噪声通道后量子态的可区分性，从而为特定噪声结构发现资源高效的编码电路。实验结果表明，该方法在理论和实践上均表现良好，且在多种场景下优于标准编码，并在实际硬件上进行了概念验证。

> **摘要翻译:** 量子纠错对于保护量子信息免受退相干至关重要。传统的编码，如表面码，需要大量的开销，这使得它们对于近期的、早期的容错设备来说不切实际。我们提出了一种新颖的目标函数，通过最大化噪声通道后量子态之间的可区分性来为特定噪声结构量身定制纠错码，从而确保高效的恢复操作。我们将这一概念形式化为可区分性损失函数，作为机器学习目标，用于发现针对给定噪声特性优化的资源高效编码电路。我们使用变分技术实现了这种方法，称之为变分量子纠错（VarQEC）。我们的方法产生的编码具有理想的理论和实践特性，并在各种情况下优于标准编码。我们还在IBM和IQM硬件设备上提供了概念验证演示，突出了我们程序的实际相关性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [623] [Interpretable representation learning of quantum data enabled by probabilistic variational autoencoders](https://arxiv.org/abs/2506.11982)
> *通过概率变分自编码器实现量子数据的可解释表示学习*

*Paulin de Schoulepnikoff, Gorka Muñoz-Gil, Hendrik Poulsen Nautrup, Hans J. Briegel* | **Main category: quant-ph**

**Keywords:** 可解释机器学习, 变分自编码器, 量子数据, 潜在表示, 概率损失

**Comment:** Main text 10 pages, total document 16 pages, 10 figures

> **TL;DR:** 本文提出了一种改进的变分自编码器（VAEs），通过引入能够忠实再现量子态的解码器和定制的概率损失函数，使其能够学习量子数据的可解释物理表示，并在基准模型和实验数据上表现出色，自主揭示相结构。

**AI_Comments:** 这篇论文通过专门解决量子数据的概率性质，在将变分自编码器应用于量子数据方面取得了重要进展。其核心创新在于其专门设计的解码器和概率损失函数，这使得能够提取物理上有意义且可解释的潜在表示。这项工作意义重大，因为它为量子物理学中的科学发现提供了一个强大的无监督工具，特别是在无需大量先验知识的情况下分析复杂实验数据。

<details>
  <summary>Details</summary>

**Motivation:** 现有变分自编码器（VAEs）在处理量子数据时，由于其内在的随机性和复杂关联性，往往忽略了其概率性质，导致难以提取有意义的物理描述符和可解释的表示，从而限制了其在科学发现中的应用潜力。

**Method:** 作者对变分自编码器（VAEs）进行了两项关键修改：一是设计了一个能够忠实再现量子态的解码器；二是引入了一个为此任务量身定制的概率损失函数。

**Result:** 改进后的方法在使用基准量子自旋模型时，能够识别出标准方法失效的区域，而其学习到的表示仍然有意义且可解释。应用于Rydberg原子阵列的实验数据时，该模型在没有先验标签、哈密顿量细节或相关序参数知识的情况下，自主揭示了相结构。

**Conclusion:** 本研究提出的方法为量子系统研究提供了一个无监督且可解释的工具，通过学习量子数据的物理上有意义的潜在表示。

> **ai_Abstract:** 本文旨在解决使用变分自编码器（VAEs）从量子数据中学习可解释表示的挑战。作者提出了两项新颖的修改：一个能忠实再现量子态的解码器和一个定制的概率损失函数。这些增强功能使VAEs能够准确地考虑量子数据的概率性质。改进后的模型在基准量子自旋模型上表现出优于标准方法的性能，产生了有意义且可解释的潜在表示。此外，当应用于Rydberg原子阵列的实验数据时，它能自主识别相结构，无需依赖先验知识，展示了其作为量子系统研究的无监督和可解释工具的潜力。

> **摘要翻译:** 可解释机器学习正迅速成为科学发现的关键工具。在现有方法中，变分自编码器 (VAEs) 已在无需监督或系统先验知识的情况下，从某些输入数据中提取隐藏的物理特征方面显示出前景。然而，VAEs 创建有意义、可解释表示的能力依赖于它们对其输入底层概率分布的准确近似。在处理量子数据时，VAEs 因此必须考虑其内在的随机性和复杂的关联。虽然 VAEs 以前曾应用于量子数据，但它们往往忽略了其概率性质，阻碍了有意义物理描述符的提取。在此，我们证明了两个关键修改使 VAEs 能够学习物理上有意义的潜在表示：一个能够忠实再现量子态的解码器和一个为此任务量身定制的概率损失。使用基准量子自旋模型，我们确定了标准方法失败而我们方法学习到的表示仍然有意义且可解释的区域。应用于 Rydberg 原子阵列的实验数据时，该模型在没有访问先验标签、哈密顿量细节或相关序参数知识的情况下，自主揭示了相结构，突显了其作为研究量子系统的无监督和可解释工具的潜力。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [159] [Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis](https://arxiv.org/abs/2506.11062)
> *解码皮层微电路：一种用于潜在空间探索和受控合成的生成模型*

*Xingyu Liu, Yubin Li, Guozhang Chen* | **Main category: q-bio.NC**

**Keywords:** 皮层微电路, 生成模型, 潜在空间, 神经回路, 大脑发育

**Comment:** 

> **TL;DR:** 本研究引入了一种生成模型，用于从小鼠皮层微电路的连接图中学习潜在的低维表示，从而能够探索其设计原则并受控合成具有特定结构特征的新微电路。

**AI_Comments:** 这项研究的创新之处在于利用生成模型在低维潜在空间中发现大脑微电路的“蓝图”，并实现了对合成微电路结构的可控生成。这不仅为理解大脑发育和结构-功能关系提供了新的工具，也为设计更高效、更仿生的AI神经网络提供了潜在方向。其重要性在于将复杂的生物系统简化为可操作的数学模型，从而开启了通过设计而非仅仅观察来理解生物智能的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 理解大脑和构建人工智能的核心思想是结构决定功能。然而，大脑的复杂结构如何从有限的基因指令中产生仍是一个关键问题。神经连接的超高维细节远超基因的信息存储能力，这表明必须有一个紧凑的低维蓝图来指导大脑发育。本研究的动机是揭示这个蓝图。

**Method:** 本研究引入了一种生成模型，用于从小鼠皮层微电路的详细连接图中学习其潜在的低维表示。在此基础上，通过导航这个潜在空间，展示了一种可控地生成具有所需结构特征的新合成微电路的新方法。

**Result:** 该模型成功地在压缩的潜在空间中捕获了这些电路的基本结构信息。研究发现，该空间中特定、可解释的方向与可理解的网络属性直接相关。此外，本研究成功演示了通过导航潜在空间来可控地生成具有所需结构特征的新合成微电路。

**Conclusion:** 这项工作提供了一种调查神经回路设计原则和探索结构如何产生功能的新方法，并可能为开发更先进的人工神经网络提供信息。

> **ai_Abstract:** 本研究提出了一种生成模型，旨在揭示大脑皮层微电路的低维结构蓝图。通过学习小鼠皮层微电路的连接图，该模型成功地将复杂的结构信息压缩到潜在空间中。研究发现，潜在空间中的特定方向与网络属性相关，并展示了如何利用该模型可控地生成具有特定结构特征的合成微电路。这项工作为理解神经回路的设计原则和促进先进人工智能的发展提供了新视角。

> **摘要翻译:** 理解大脑和构建人工智能的一个核心思想是结构决定功能。然而，大脑的复杂结构如何从有限的基因指令中产生仍然是一个关键问题。神经连接的超高维细节远远超出了基因的信息存储能力，这表明一个紧凑的、低维的蓝图必须指导大脑发育。我们的动机是揭示这个蓝图。我们引入了一个生成模型，用于从小鼠皮层微电路的详细连接图中学习这种潜在的表示。我们的模型成功地在压缩的潜在空间中捕获了这些电路的基本结构信息。我们发现，该空间中特定、可解释的方向直接与可理解的网络属性相关。在此基础上，我们展示了一种通过导航这个潜在空间，可控地生成具有所需结构特征的新型合成微电路的方法。这项工作为研究神经回路的设计原则和探索结构如何产生功能提供了一种新途径，并可能为开发更先进的人工神经网络提供信息。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [590] [Sparse Autoencoders Bridge The Deep Learning Model and The Brain](https://arxiv.org/abs/2506.11123)
> *稀疏自编码器连接深度学习模型与大脑*

*Ziming Mao, Jia Xu, Zeqi Zheng, Haofang Zheng, Dabing Sheng, Yaochu Jin, Guoyuan Yang* | **Main category: q-bio.NC**

**Keywords:** 稀疏自编码器, 深度学习, fMRI, 模型可解释性, 视觉皮层

**Comment:** 54 pages, 41 figures

> **TL;DR:** SAE-BrainMap框架使用稀疏自编码器直接将深度学习视觉模型表征与人脑fMRI响应对齐，揭示了模型与大脑之间的对应关系，并提供了模型可解释性的新视角。

**AI_Comments:** SAE-BrainMap框架通过引入稀疏自编码器，提供了一种新颖且直接的方法来连接深度学习模型和人脑活动，无需依赖下游任务，这在模型可解释性领域具有重要意义。其创新之处在于利用SAE的稀疏性和可解释性来桥接不同模态的数据，并能揭示模型内部信息处理与大脑功能区域的对应关系，为理解AI模型的工作机制提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在建立深度神经网络与人类视觉皮层之间直接的、无需下游任务的桥梁，以提供模型可解释性的新见解。

**Method:** 该研究提出了SAE-BrainMap框架。首先，在模型激活上训练层级稀疏自编码器（SAEs），并计算SAE单元激活与相同自然图像刺激引起的皮层fMRI信号之间的余弦相似性相关性。其次，通过将最相似的SAE特征分配给每个体素来构建体素字典。最后，通过将体素字典激活投影到个体皮层表面，建立了模型层与人腹侧视觉通路之间的精细分层映射，并可视化了深度学习模型中视觉信息的动态转换。

**Result:** 研究发现SAE单元激活与皮层fMRI信号之间存在强烈的激活对应关系（最大相似度高达0.76）。SAE单元保留了预定义感兴趣区域（ROIs）的功能结构，并表现出ROI一致的选择性。建立了模型层与人类腹侧视觉通路之间的精细分层映射。发现ViT-B/16$_{CLIP}$在早期层倾向于利用低级信息生成高级语义信息，并在后期重建低维信息。

**Conclusion:** 研究结果建立了深度神经网络与人类视觉皮层之间直接的、无需下游任务的桥梁，为模型可解释性提供了新的见解。

> **ai_Abstract:** 本研究提出了SAE-BrainMap框架，利用稀疏自编码器（SAEs）将深度学习视觉模型表征与人脑fMRI响应进行直接对齐。通过训练SAEs并分析其单元激活与fMRI信号的关联，发现模型与大脑之间存在显著的对应关系。研究构建了体素字典，揭示SAE单元能保留大脑功能区的结构和选择性。此外，还建立了模型层与人类视觉通路之间的分层映射，并观察到ViT-B/16$_{CLIP}$在不同层级处理信息的动态过程。这项工作为理解深度神经网络与人类视觉皮层之间的关系提供了直接的桥梁，并增强了模型的可解释性。

> **摘要翻译:** 我们提出了SAE-BrainMap，一个新颖的框架，它使用稀疏自编码器（SAEs）直接将深度学习视觉模型表征与体素级fMRI响应对齐。首先，我们在模型激活上训练层级SAEs，并计算SAE单元激活与相同自然图像刺激引起的皮层fMRI信号之间的余弦相似性相关性，揭示了强烈的激活对应关系（最大相似度高达0.76）。根据这种对齐，我们通过将最相似的SAE特征最优地分配给每个体素来构建体素字典，这表明SAE单元保留了预定义感兴趣区域（ROIs）的功能结构并表现出ROI一致的选择性。最后，我们通过将体素字典激活投影到个体皮层表面，建立了模型层与人类腹侧视觉通路之间的精细分层映射，也可视化了深度学习模型中视觉信息的动态转换。结果发现ViT-B/16$_{CLIP}$倾向于在早期层利用低级信息生成高级语义信息，并在后期重建低维信息。我们的结果在深度神经网络和人类视觉皮层之间建立了直接的、无需下游任务的桥梁，为模型可解释性提供了新的见解。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [601] [Voxel-Level Brain States Prediction Using Swin Transformer](https://arxiv.org/abs/2506.11455)
> *基于Swin Transformer的体素级脑状态预测*

*Yifei Sun, Daniel Chahine, Qinghao Wen, Tianming Liu, Xiang Li, Yixuan Yuan, Fernando Calamante, Jinglei Lv* | **Main category: q-bio.NC**

**Keywords:** Swin Transformer, 脑状态预测, fMRI, 时空学习, 脑机接口

**Comment:** 

> **TL;DR:** 使用4D Swin Transformer预测高分辨率的未来静息态脑状态，准确度高，有望缩短fMRI扫描时间并开发脑机接口。

**AI_Comments:** 该论文的创新点在于首次将4D Swin Transformer应用于fMRI数据，实现了高分辨率的体素级脑状态预测。其重要性体现在为理解大脑动力学提供了新工具，并为减少fMRI扫描时间和开发脑机接口奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 理解大脑动力学对神经科学和精神健康至关重要。功能性磁共振成像（fMRI）可以测量代表大脑状态的神经活动。本研究旨在利用fMRI预测未来的静息态人脑状态。

**Method:** 提出了一种新颖的架构，该架构采用4D移位窗口（Swin）Transformer作为编码器以有效学习时空信息，并使用卷积解码器以与输入fMRI数据相同的空间和时间分辨率实现脑状态预测。使用了来自人类连接组计划（HCP）的100名无关受试者进行模型训练和测试。

**Result:** 该模型能够基于先前的23.04秒fMRI时间序列准确预测7.2秒的静息态脑活动。预测的脑状态与BOLD对比和动态高度相似。

**Conclusion:** 这项工作提供了有前景的证据，表明人脑的时空组织可以通过Swin Transformer模型以高分辨率学习，这为未来减少fMRI扫描时间以及开发脑机接口提供了潜力。

> **ai_Abstract:** 本研究提出了一种基于4D Swin Transformer编码器和卷积解码器的新颖架构，用于利用fMRI数据预测未来的体素级静息态脑状态。该模型能够高效学习fMRI数据的时空信息，并以高精度预测未来的脑活动，与实际BOLD信号高度相似。研究结果表明Swin Transformer在学习人脑时空组织方面的潜力，为缩短fMRI扫描时间和脑机接口的发展提供了可能性。

> **摘要翻译:** 理解大脑动力学对神经科学和精神健康至关重要。功能性磁共振成像（fMRI）通过血氧水平依赖（BOLD）信号测量神经活动，这些信号代表了大脑状态。在本研究中，我们旨在利用fMRI预测未来的人体静息脑状态。鉴于fMRI数据具有3D体素级别的空间组织和时间依赖性，我们提出了一种新颖的架构，该架构采用4D移位窗口（Swin）Transformer作为编码器，以有效学习时空信息，并使用卷积解码器，以与输入fMRI数据相同的空间和时间分辨率实现脑状态预测。我们使用来自人类连接组计划（HCP）的100名无关受试者进行模型训练和测试。我们的新模型在基于先前的23.04秒fMRI时间序列预测7.2秒静息态脑活动时显示出高精度。预测的脑状态与BOLD对比和动态高度相似。这项工作显示了有前景的证据，表明人脑的时空组织可以被Swin Transformer模型以高分辨率学习，这为未来减少fMRI扫描时间以及开发脑机接口提供了潜力。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [270] [Jelly: a fast and convenient RDF serialization format](https://arxiv.org/abs/2506.11298)
> *Jelly：一种快速便捷的RDF序列化格式*

*Piotr Sowinski, Karolina Bogacka, Anastasiya Danilenka, Nikita Kozlov* | **Main category: cs.DB**

**Keywords:** RDF序列化, Jelly, 知识图谱, 语义网, 二进制格式

**Comment:** 

> **TL;DR:** Jelly是一种基于Protocol Buffers的二进制RDF序列化格式，旨在解决现有格式在性能、压缩和流处理方面的不足，提供快速、高效且易于集成的解决方案。

**AI_Comments:** Jelly的创新之处在于其二进制格式和对RDF流的本地支持，结合Protocol Buffers提高了效率和易用性。它通过解决现有RDF序列化格式的性能和流处理瓶颈，为知识图谱和语义网应用提供了重要的性能优化潜力。其开放协议、开源实现和多语言支持也增强了其实用性和影响力，使其成为语义网工具栈中一个有价值的补充。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RDF序列化格式（如Turtle、N-Triples、JSON-LD）在性能、压缩比和对RDF流的本地支持方面存在局限性。

**Method:** 本文引入了Jelly，一种快速便捷的RDF数据二进制序列化格式，支持批处理和流式用例。Jelly基于Protocol Buffers构建，旨在最大化序列化吞吐量，通过轻量级流压缩减少文件大小，并最小化计算资源使用。为了最大限度地提高可重用性，Jelly具有开放协议规范、与流行RDF库集成的Java和Python开源实现以及多功能命令行工具。

**Result:** Jelly能够最大化序列化吞吐量，通过轻量级流压缩减少文件大小，并最小化计算资源使用。

**Conclusion:** Jelly结合了实用性与最先进的效率，是对语义网工具栈的重要贡献。

> **ai_Abstract:** 本文介绍了一种名为Jelly的二进制RDF序列化格式，旨在克服现有格式如Turtle、N-Triples和JSON-LD在性能、压缩和流处理方面的不足。Jelly基于Protocol Buffers构建，支持批处理和流式用例，并通过轻量级流压缩优化吞吐量、文件大小和资源利用。它提供开放规范和多语言实现，旨在成为语义网工具栈中高效且易于集成的解决方案。

> **摘要翻译:** 现有RDF序列化格式如Turtle、N-Triples和JSON-LD在知识图谱和语义网应用中广泛用于通信和存储。然而，它们在性能、压缩比以及缺乏对RDF流的本地支持方面存在局限性。为了解决这些缺点，我们引入了Jelly，一种快速便捷的RDF数据二进制序列化格式，支持批处理和流式用例。Jelly旨在最大化序列化吞吐量，通过轻量级流压缩减少文件大小，并最小化计算资源使用。Jelly基于Protocol Buffers构建，易于与现代编程语言和RDF库集成。为了最大限度地提高可重用性，Jelly具有开放协议规范、与流行RDF库集成的Java和Python开源实现以及多功能命令行工具。为了说明其有用性，我们概述了Jelly可以提供实际利益的具体用例。通过将实用性与最先进的效率相结合，Jelly是对语义网工具栈的重要贡献。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [323] [PermRust: A Token-based Permission System for Rust](https://arxiv.org/abs/2506.11701)
> *PermRust：一个用于Rust的基于令牌的权限系统*

*Lukas Gehring, Sebastian Rehms, Florian Tschorsch* | **Main category: cs.PL**

**Keywords:** PermRust, 权限系统, Rust, 令牌, 能力系统

**Comment:** 11 pages

> **TL;DR:** PermRust是一个基于令牌的Rust权限系统，它利用Rust的类型系统，实现了库级别的资源访问管理，以增强安全性。

**AI_Comments:** PermRust的创新之处在于将权限系统下沉到编程语言级别，特别是利用Rust的类型系统实现了“零成本抽象”，这对于提升使用第三方库的软件安全性具有重要意义。它解决了传统操作系统权限系统只能在进程级别控制的局限性，提供了一种更细粒度的安全控制方式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的操作系统权限系统只能在进程级别管理访问，但现代软件广泛重用第三方库代码，这使得在库级别管理权限以增强安全性变得必要。

**Method:** 该论文借鉴了能力系统（capability systems）的概念，构建了编程语言层面权限系统的新理论基础。在此基础上，开发了PermRust，一个基于令牌的Rust编程语言权限系统，它作为Rust类型系统之上的零成本抽象。

**Result:** PermRust能够实现对系统资源的按库管理访问。

**Conclusion:** PermRust提供了一个新颖的、基于令牌的Rust编程语言权限系统，通过利用其类型系统，实现了库级别的资源访问管理。

> **ai_Abstract:** 本文提出PermRust，一个针对Rust编程语言的基于令牌的权限系统。鉴于现有操作系统权限系统仅限于进程级别管理，且现代软件广泛使用第三方库，PermRust通过借鉴能力系统概念，在编程语言层面构建了新的权限管理理论基础，并作为Rust类型系统上的零成本抽象实现。该系统能够实现对系统资源的按库访问管理，从而提升软件安全性。

> **摘要翻译:** 权限系统，用于限制对系统资源的访问，是操作系统中一项成熟的技术，尤其是在智能手机领域。然而，由于此类系统是在操作系统中实现的，它们最多只能在进程级别管理访问。鉴于现代软件经常（重）使用第三方库的代码，一个针对库的权限系统对于增强安全性而言是可取的。在这篇短论文中，我们借鉴了能力系统（capability systems）的概念，为编程语言层面的权限系统构建了一个新颖的理论基础。这催生了PermRust，一个用于Rust编程语言的基于令牌的权限系统，作为其类型系统之上的零成本抽象。有了它，对系统资源的访问可以按库进行管理。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [326] [Bias and Identifiability in the Bounded Confidence Model](https://arxiv.org/abs/2506.11751)
> *边界置信模型中的偏差与可识别性*

*Claudio Borile, Jacopo Lenti, Valentina Ghidini, Corrado Monti, Gianmarco De Francisci Morales* | **Main category: stat.ME**

**Keywords:** 边界置信模型, 参数估计, 最大似然估计, 偏差, 可识别性

**Comment:** 13 pages, 8 figures

> **TL;DR:** 本文研究了边界置信模型中两个关键参数（置信边界和收敛速率）的最大似然估计器的统计特性，发现存在偏差和可识别性问题，并强调了似然函数分析的重要性。

**AI_Comments:** 这篇论文通过深入分析最大似然估计在边界置信模型中的应用，揭示了参数估计中常见的偏差和可识别性问题。其创新之处在于强调了似然函数分析作为一种通用方法，不仅能识别估计的局限性，还能为基于代理模型的校准提供理论保障，这对于将理论模型应用于实际数据具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 将意见动力学模型（如边界置信模型）与真实数据连接，以理解现象和检验模型假设，其中参数估计是关键，最大似然估计提供了一种原则性的方法。

**Method:** 采用最大似然估计方法，分析了边界置信模型中置信边界和收敛速率这两个关键参数的统计估计器的特性，并通过分析似然函数来理解估计的局限性和可能性。

**Result:** 发现置信边界的最大似然估计器存在小样本偏差但具有一致性，而收敛速率的估计器表现出持续偏差。此外，联合参数估计在参数空间的特定区域受到可识别性问题的影响，因为似然函数存在多个局部最大值。

**Conclusion:** 似然函数分析是理解意见动力学模型（以及更普遍的基于代理模型）参数估计的陷阱和可能性，并为模型校准提供形式保证的有效方法。

> **ai_Abstract:** 本文探讨了边界置信模型中两个核心参数（置信边界和收敛速率）的最大似然估计器的统计特性。研究发现置信边界的估计器存在小样本偏差但渐近一致，而收敛速率的估计器则表现出持续偏差。此外，联合参数估计面临可识别性问题，因为似然函数存在多个局部最大值。研究强调了似然函数分析对于理解参数估计挑战和确保模型校准的重要性。

> **摘要翻译:** 意见动力学模型，例如边界置信模型（BCMs），描述了人群如何根据几个参数达到共识、分裂或两极分化。将此类模型与真实世界数据联系起来有助于理解此类现象，并检验模型假设。为此，模型参数的估计是一个关键方面，最大似然估计提供了一种原则性的方法来解决它。本文的目标是概述边界置信模型中两个关键参数：置信边界和收敛速率的统计估计器的特性。我们发现它们的最大似然估计器呈现出不同的特征：置信边界的估计器存在小样本偏差但具有一致性，而收敛速率的估计器则表现出持续偏差。此外，联合参数估计在参数空间的特定区域受到可识别性问题的影响，因为似然函数中存在多个局部最大值。我们的结果表明，似然函数分析是一种富有成效的方法，可以更好地理解意见动力学模型（更普遍地说是基于代理模型）参数估计的陷阱和可能性，并为其校准提供形式保证。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [605] [Measuring multi-calibration](https://arxiv.org/abs/2506.11251)
> *测量多重校准*

*Ido Guy, Daniel Haimovich, Fridolin Linder, Nastaran Okati, Lorenzo Perini, Niek Tax, Mark Tygert* | **Main category: stat.ME**

**Keywords:** 多重校准, Kuiper统计量, 信噪比, 概率预测, 度量

**Comment:** 25 pages, 12 tables

> **TL;DR:** 本文提出了一种基于经典Kuiper统计量的新型多重校准度量方法，该方法通过考虑信噪比来避免传统方法的缺陷。

**AI_Comments:** 本文的创新之处在于将经典的Kuiper统计量应用于多重校准的度量，并引入了信噪比加权机制，有效解决了传统校准度量中常见的因分箱或核密度估计带来的问题，提升了度量的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在实践中，预测概率很少能完美地进行多重校准，因此需要一个统计量来衡量与完美多重校准的距离，以提供有用的信息。

**Method:** 本文提出了一种基于经典Kuiper统计量的新型多重校准度量方法，该方法避免了基于分箱或核密度估计的度量中存在的已知问题。新提出的度量根据不同子群的信噪比来加权其贡献。

**Result:** 数据分析的消融实验表明，如果从度量中省略信噪比，该度量会变得嘈杂，这证明了信噪比的重要性。基准数据集上的数值示例也说明了新度量的有效性。

**Conclusion:** 本文提出了一种基于Kuiper统计量并考虑信噪比的新型多重校准度量，它能够有效地衡量与完美多重校准的距离，并解决了现有方法的问题。

> **ai_Abstract:** 本文提出了一种用于衡量多重校准的新型标量度量。多重校准是指预测概率在多个子群体中同时达到完美校准的状态。鉴于实际中完美多重校准难以实现，该研究基于经典的Kuiper统计量构建了一个新度量，以量化与完美多重校准的距离，并克服了传统分箱或核密度估计方法的缺陷。该度量根据子群体的信噪比进行加权，并通过消融实验证明了信噪比在保持度量鲁棒性方面的重要性。数值示例进一步验证了新度量的有效性。

> **摘要翻译:** 一个合适的标量度量可以帮助测量多重校准，其定义如下。当观测响应的期望值等于相应的预测概率时，概率预测被称为“完美校准”。当预测概率在几个子群体中同时完美校准时，概率预测被称为“完美多重校准”。在实践中，预测概率很少能完美地进行多重校准，因此，一个衡量与完美多重校准距离的统计量是有益的。最近提出的一种基于经典Kuiper统计量的校准度量，是构建多重校准新度量的自然基础，并避免了基于分箱或核密度估计的度量中存在的众所周知的问题。新提出的度量根据不同子群体的信噪比来加权其贡献；数据分析的消融实验表明，当从度量中省略信噪比时，该度量会变得嘈杂。在基准数据集上的数值示例说明了这种新度量。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [337] [Physical Constraint Preserving Higher Order Finite Volume Schemes for Divergence-Free Astrophysical MHD and RMHD](https://arxiv.org/abs/2506.11181)
> *物理约束保持高阶有限体积方案，用于无散天体物理磁流体动力学和相对论磁流体动力学*

*Dinshaw S. Balsara, Deepak Bhoriya, Chetan Singh, Harish Kumar, Roger Käppeli, Federico Gatti* | **Main category: astro-ph.IM**

**Keywords:** 物理约束保持, 有限体积方案, 磁流体动力学, 相对论磁流体动力学, 天体物理模拟

**Comment:** Accepted in "The Astrophysical Journal (ApJ)"

> **TL;DR:** 本文提出了一种物理约束保持（PCP）的高阶有限体积方案，用于解决极端天体物理条件下磁流体动力学（MHD）和相对论磁流体动力学（RMHD）模拟中现有高阶方法不稳定的问题。

**AI_Comments:** 这项研究的创新之处在于提出了物理约束保持（PCP）方法，有效解决了高阶有限体积方案在极端天体物理MHD和RMHD模拟中遇到的稳定性问题。引入新颖的二维黎曼求解器是其关键组成部分，且该方法能保持磁场的无散特性。其重要性在于，它使得在传统方法容易崩溃的苛刻条件下进行高精度天体物理模拟成为可能，从而推动了对宇宙极端现象的理解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的用于磁流体动力学（MHD）和相对论磁流体动力学（RMHD）的高阶有限体积方案在处理具有大马赫数、高洛伦兹因子和强磁场等极端条件的天体物理问题时，容易变得脆弱并导致代码崩溃。

**Method:** 本文提出了一种物理约束保持（PCP）方法来处理数值MHD和RMHD问题。该方法描述了允许磁场无散演化的高阶方法，并引入了一种新颖的二维黎曼求解器，该求解器在PCP方案设计中起关键作用。PCP公式被设计得非常简单，并与面心磁场的演化相结合，且该方法是时间显式的，计算成本不高。

**Result:** 所提出的方法达到了其设计精度，并能有效处理对于计算天体物理学中典型的更高阶Godunov方法而言过于极端的MHD和RMHD问题。

**Conclusion:** 本文提出的物理约束保持（PCP）高阶有限体积方案有效解决了极端天体物理条件下磁流体动力学和相对论磁流体动力学模拟中现有高阶方案的稳定性问题，使其能够准确且鲁棒地处理此类挑战性问题。

> **ai_Abstract:** 本文提出了一种物理约束保持（PCP）的高阶有限体积方案，专为解决天体物理磁流体动力学（MHD）和相对论磁流体动力学（RMHD）模拟在极端条件下（如高马赫数、高洛伦兹因子和强磁场）的稳定性问题。该方案引入了一种新颖的二维黎曼求解器，并确保磁场的无散演化。所提出的PCP方法简单且计算高效，已被证明能在传统高阶Godunov方法失效的极端问题上保持设计精度并表现出色。

> **摘要翻译:** 用于磁流体动力学（MHD）和相对论磁流体动力学（RMHD）的高阶有限体积方案非常有价值，因为它们使我们能够以非常高的精度进行天体物理模拟。然而，天体物理问题有时具有异常大的马赫数、异常高的洛伦兹因子和非常强的磁场。所有这些效应都会导致高阶代码变得脆弱并容易崩溃。在本文中，我们记录了用于处理数值MHD和RMHD的物理约束保持（PCP）方法。虽然对于标准问题来说并非必需，但对于严苛的天体物理问题，这些方法显示出其价值。我们描述了允许磁场无散演化的高阶方法。我们提出了一种新颖的二维黎曼求解器。这种二维黎曼求解器在MHD和RMHD的PCP方案设计中起着关键作用。我们提出了一种非常简单的PCP公式，并展示了它如何与面心磁场的演化相结合。这里提出的方法是时间显式的，并且不会增加太多计算成本。我们表明这些方法达到了其设计精度，并且在对于计算天体物理学中使用的典型高阶Godunov方法而言可能被认为过于极端的问题上表现良好。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [353] [A fast mesh-free boundary integral method for two-phase flow with soluble surfactant](https://arxiv.org/abs/2506.11282)
> *双相流中可溶性表面活性剂的快速无网格边界积分法*

*Samantha G. Evans, Michael Siegel, Johannes Tausch, Michael R. Booty* | **Main category: physics.flu-dyn**

**Keywords:** 双相流, 边界积分法, 可溶性表面活性剂, 快速多极方法, 大Péclet数

**Comment:** 35 pages, 16 figures

> **TL;DR:** 开发了一种基于改进快速多极方法的无网格边界积分法，用于高效准确地模拟大Péclet数下含可溶性表面活性剂的双相流。

**AI_Comments:** 这项工作通过引入一种新颖的因果快速多极方法，有效地解决了在大Péclet数下含可溶性表面活性剂的双相流模拟中，时间卷积积分计算效率低的问题。其创新之处在于将复杂的非线性问题在特定物理条件下进行简化，并结合高效算法，实现了无网格且精确的模拟。这对于流体力学和界面现象的数值模拟具有重要意义，尤其是在需要考虑表面活性剂作用的工业和生物应用中。

<details>
  <summary>Details</summary>

**Motivation:** 模拟含可溶性表面活性剂的双相流中液滴和气泡的变形是一个挑战，因为表面活性剂的平流-扩散方程是非线性的，阻碍了标准的边界积分法中格林函数公式的应用。同时，时间卷积的快速评估也是一个难题。

**Method:** 该方法在大Péclet数极限下，通过对表面活性剂动力学进行分析简化，使得表面活性剂浓度C的格林函数公式能够表示为每个拉格朗日界面点上的Abel型时间卷积积分。为了快速评估这个时间卷积，开发了一种新颖的、因果的快速多极方法（FMM），将计算成本从O(P^2)降低到O(P log_2^2 P)。该方法在体相中是无网格的。

**Result:** 该方法在体相中是无网格的，并为含可溶性表面活性剂的完全耦合移动界面问题提供了准确的解决方案。

**Conclusion:** 所提出的方法为高Péclet数区域中更广泛的平流-扩散问题提供了自然延伸的解决方案。

> **ai_Abstract:** 这篇论文提出了一种针对含可溶性表面活性剂的双相流的快速无网格边界积分（BI）方法。该方法利用大Péclet数极限下表面活性剂动力学的分析简化，将非线性平流-扩散方程转化为可用于BI方法的格林函数形式。为解决时间卷积积分的计算效率问题，作者开发了一种新颖的因果快速多极方法，显著降低了计算复杂度。该方法在体相中无网格，能够准确模拟完全耦合的移动界面问题，并可推广至其他高Péclet数下的平流-扩散问题。

> **摘要翻译:** 我们提出了一种精确高效的边界积分（BI）方法，用于模拟斯托克斯流中含可溶性表面活性剂的液滴和气泡变形。可溶性表面活性剂在本体流体中对流和扩散，同时在界面处吸附和解吸。由于流体速度与表面活性剂浓度耦合，控制本体表面活性剂浓度C的平流-扩散方程是非线性的，这排除了边界积分方法所需的格林函数公式。然而，在物理上具有代表性的大Péclet数极限下，表面活性剂动力学的分析简化允许C的格林函数公式表示为每个拉格朗日界面点处的Abel型时间卷积积分。基于此公式开发实用数值方法的一个挑战是时间卷积的快速评估，因为核函数取决于界面处量的时间历史，而这只能在时间步进过程中获得。为了解决这个问题，我们开发了一种新颖的、因果的快速多极方法，将时间卷积直接评估的计算成本从O(P^2)降低到每个表面网格点的O(P log_2^2 P)，其中P是时间步数。在体相中，由此产生的方法是无网格的，并为含可溶性表面活性剂的完全耦合移动界面问题提供了准确的解决方案。该方法自然地扩展到高Péclet数区域中更广泛的平流-扩散问题。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [362] [Phase-Field Modeling and Energy-Stable Schemes for Osmotic Flow through Semi-Permeable](https://arxiv.org/abs/2506.11374)
> *半透膜渗透流的相场建模与能量稳定方案*

*Ruihan Guo, Jie Shen, Shixin Xu, Xianmin Xu* | **Main category: physics.flu-dyn**

**Keywords:** 相场模型, 渗透流, 半透膜, 能量稳定方案, 数值方法

**Comment:** 28 pages, 9 figures

> **TL;DR:** 本文提出了一个热力学一致的相场模型来模拟跨半透膜的流体输运，重点关注渗透压效应。该模型扩展了经典的Navier-Stokes-Cahn-Hilliard系统，引入了由化学势不平衡驱动的Allen-Cahn型跨膜通量。为有效求解该强耦合系统，作者开发了高阶、能量稳定的数值方案，结合局部间断伽辽金（LDG）方法进行空间离散，并采用半隐式谱延迟校正（SDC）方法进行时间积分。数值实验验证了方案的理论性质，并展示了渗透压和膜渗透性对液滴形态的影响。

**AI_Comments:** 本文的创新点在于提出了一个热力学一致的相场模型，并将其应用于模拟半透膜的渗透流，特别关注渗透压效应。通过扩展NSCH系统并引入Allen-Cahn型跨膜通量，建立了更为全面的强耦合系统。此外，为解决该复杂系统，作者开发了高阶、能量稳定的数值方案，结合了LDG空间离散和SDC时间积分，这对于确保数值模拟的准确性和稳定性至关重要。该框架的鲁棒性和通用性使其在生物和工业应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了模拟跨半透膜的流体输运，特别是渗透压效应，并提供一个鲁棒且通用的工具来建模生物和工业应用中的跨膜流体输运。

**Method:** 本文提出了一个热力学一致的相场模型，扩展了经典的Navier-Stokes-Cahn-Hilliard (NSCH) 系统，引入了由化学势不平衡驱动的Allen-Cahn型跨膜通量。为了高效准确地求解这个强耦合系统，作者开发了高阶、能量稳定的数值方案。空间离散采用局部间断伽辽金 (LDG) 方法，时间积分则首先构建了一个具有严格能量稳定性的一阶解耦方案，然后通过半隐式谱延迟校正 (SDC) 方法提高了时间精度。

**Result:** 数值实验证实了所提出方案的理论性质，并展示了渗透压和膜渗透性对平衡时液滴形态的影响。

**Conclusion:** 该框架为模拟跨膜流体输运提供了一个鲁棒且通用的工具，适用于生物和工业应用。

> **ai_Abstract:** 本文提出了一个热力学一致的相场模型，用于模拟跨半透膜的流体输运，特别关注渗透压效应。该模型通过引入Allen-Cahn型跨膜通量扩展了Navier-Stokes-Cahn-Hilliard系统，形成一个流体、溶质和界面动力学强耦合系统。为有效求解，开发了高阶、能量稳定的数值方案，结合局部间断伽辽金进行空间离散，并使用半隐式谱延迟校正方法进行时间积分。数值实验验证了方案的理论性质，并揭示了渗透压和膜渗透性对液滴形态的影响。该框架为跨膜流体输运建模提供了强大的工具。

> **摘要翻译:** 我们提出了一个热力学一致的相场模型，用于模拟跨半透膜的流体输运，特别关注渗透压效应。该模型通过引入由化学势不平衡控制的Allen-Cahn型跨膜通量，扩展了经典的Navier-Stokes-Cahn-Hilliard (NSCH) 系统，从而形成了一个涉及流体运动、溶质输运和界面动力学的强耦合系统。为了高效准确地求解该系统，我们开发了高阶、能量稳定的数值方案。空间离散采用了局部间断伽辽金 (LDG) 方法，该方法提供了高阶精度和几何灵活性。对于时间积分，我们首先构建了一个具有严格能量稳定性的一阶解耦方案，然后通过半隐式谱延迟校正 (SDC) 方法提高了时间精度。数值实验证实了所提出方案的理论性质，并展示了渗透压和膜渗透性对平衡时液滴形态的影响。该框架为生物和工业应用中的跨膜流体输运建模提供了一个鲁棒且通用的工具。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [620] [Bubble Dynamics Transformer: Microrheology at Ultra-High Strain Rates](https://arxiv.org/abs/2506.11936)
> *气泡动力学变换器：超高应变率下的微流变学*

*Lehu Bu, Zhaohan Yu, Shaoting Lin, Jan N. Fuhg, Jin Yang* | **Main category: physics.flu-dyn**

**Keywords:** 激光诱导空化, 微流变学, 机器学习, 粘弹性, 超高应变率

**Comment:** 

> **TL;DR:** 该研究利用激光诱导空化和一种名为气泡动力学变换器（BDT）的神经网络，实现了对生物材料在超高应变率下的快速、准确、非接触式微流变学表征。

**AI_Comments:** 这篇论文的创新之处在于将激光诱导空化（LIC）与深度学习模型（BDT）相结合，解决了传统流变学在超高应变率下表征材料的挑战。BDT作为一种数据驱动的方法，避免了复杂的迭代拟合过程，显著提高了表征效率和准确性。其非接触性和适用于极端条件的特性，使其在生物医学和材料科学领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统流变学工具在超高应变率（>1000 1/s）下受到加载速度、分辨率或侵入性的限制，无法有效研究软生物材料的力学行为。

**Method:** 研究引入了基于机器学习的微流变框架，利用激光诱导惯性空化（LIC）现象。通过超高速成像捕获不同软粘弹性材料中LIC事件期间气泡半径随时间变化的动态。这些测量数据随后由新开发的、基于物理模拟数据训练的神经网络——气泡动力学变换器（BDT）进行分析，以推断材料的粘弹性参数。

**Result:** BDT能够准确推断材料的粘弹性参数，无需迭代拟合或复杂的反演过程。这实现了在极端载荷条件下对软材料的快速、准确、非接触式表征。

**Conclusion:** 该方法为研究软材料在极端载荷条件下的力学行为提供了一种有效手段，对生物医学应用和材料科学具有重要意义。

> **ai_Abstract:** 本文提出了一种创新的基于机器学习的微流变框架，称为气泡动力学变换器（BDT），用于在超高应变率下表征软生物材料的粘弹性。该方法结合了激光诱导惯性空化（LIC）和超高速成像技术，捕获气泡动力学数据，并通过训练于物理模拟数据的BDT神经网络进行分析，从而实现对材料参数的快速、准确、非接触式推断，克服了传统流变学工具的局限性。

> **摘要翻译:** 激光诱导惯性空化（LIC）——即微米级蒸汽气泡由于聚焦的高能脉冲激光而形核，随后在周围高局部压力下剧烈坍塌——提供了一个独特的机会，以研究超高应变率（>1000 1/s）下的软生物材料力学。传统的流变学工具在这些条件下常受限于加载速度、分辨率或侵入性。在此，我们引入了新颖的基于机器学习（ML）的微流变框架，该框架利用LIC来表征生物材料在超高应变率下的粘弹性特性。我们利用超高速成像技术来捕捉不同软粘弹性材料中LIC事件期间气泡半径随时间变化的动态。这些气泡半径与时间测量值随后使用新开发的气泡动力学变换器（BDT）进行分析，BDT是一个基于物理模拟数据训练的神经网络。BDT能够准确推断材料的粘弹性参数，无需迭代拟合或复杂的反演过程。这使得在极端载荷条件下对软材料进行快速、准确、非接触式表征成为可能，对生物医学应用和材料科学具有重要意义。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [374] [A stochastic Galerkin method for optimal Dirichlet boundary control problems with uncertain data](https://arxiv.org/abs/2506.11479)
> *不确定数据下最优狄利克雷边界控制问题的随机伽辽金方法*

*Max Winkler, Hamdullah Yücel* | **Main category: math.OC**

**Keywords:** 随机伽辽金方法, 狄利克雷边界控制, 不确定数据, 误差估计, 预处理器

**Comment:** 28 pages, 5 figures

> **TL;DR:** 本文提出了一种随机伽辽金方法，用于解决具有随机输入数据的椭圆狄利克雷边界控制问题，并推导了误差估计，提出了预处理器，并通过数值实验验证了其有效性。

**AI_Comments:** 本文的创新点在于将随机伽辽金方法应用于具有不确定数据的最优狄利克雷边界控制问题，并针对性地开发了有效的预处理器以处理由此产生的大型线性系统。这对于在实际应用中处理不确定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 处理具有随机输入数据的椭圆狄利克雷边界控制问题，并最小化跟踪成本泛函的期望值。

**Method:** 采用随机伽辽金近似方法，并针对无约束和有约束情况提出了合适的预处理器来解决大型线性系统。

**Result:** 推导了控制变量在$L^2(\partial \mathcal D)$-范数下的误差估计和状态变量在$L^2(\Omega\times\mathcal D)$-范数下的误差估计。数值实验证明了所提出方法的有效性和效率。

**Conclusion:** 所提出的随机伽辽金方法及其预处理器对于解决具有不确定数据的最优狄利克雷边界控制问题是有效且高效的。

> **ai_Abstract:** 本文提出了一种用于解决具有随机输入数据的椭圆狄利克雷边界控制问题的随机伽辽金近似方法。该方法旨在最小化带有确定性约束控制的跟踪成本泛函的期望。研究中推导了控制变量和状态变量的误差估计，并为解决大型线性系统提出了适用于无约束和有约束场景的预处理器。通过数值实验验证了所提出方法的有效性和效率。

> **摘要翻译:** 本文研究了具有随机输入数据的椭圆狄利克雷边界控制问题的随机伽辽金近似。最小化了具有确定性约束控制的跟踪成本泛函的期望。推导了控制变量在$L^2(\partial \mathcal D)$-范数和状态变量在$L^2(\Omega\times\mathcal D)$-范数下的误差估计。为了解决大型线性系统，针对无约束和有约束情况提出了合适的预处理器。为了说明所提出方法的有效性和效率，进行了一些数值实验。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [384] [A DC-Reformulation for Gradient-$L^0$-Constrained Problems in Function Spaces](https://arxiv.org/abs/2506.11917)
> *函数空间中梯度-$L^0$约束问题的DC重构*

*Bastian Dittrich, Evelyn Herberg, Roland Herzog, Georg Müller* | **Main category: math.OC**

**Keywords:** $L^0$约束, DC重构, 梯度稀疏性, 分段常数函数, 优化

**Comment:** 

> **TL;DR:** 该论文将处理$L^0$约束的DC重构方法扩展到梯度具有$L^0$型基数约束的问题，旨在获得分段常数函数。

**AI_Comments:** 该论文的创新点在于将DC重构方法从处理函数本身的稀疏性扩展到处理梯度的稀疏性。这很重要，因为它为获得具有良好性质（如分段常数）的函数提供了一种新的优化途径。

<details>
  <summary>Details</summary>

**Motivation:** 优化中的基数约束通常是$L^0$型的，它们导致稀疏支持的优化器。现有方法可以有效处理凸目标泛函的$L^0$约束，但需要将其扩展到梯度具有$L^0$型约束的问题，以实现梯度稀疏性并得到分段常数函数。

**Method:** 该研究扩展了DC重构方法。这种方法通过使用合适的$L^1$范数和最大$K$范数之差来重构$L^0$约束，然后解决一系列惩罚的凸差（DC）子问题。本文将此方法应用于梯度支持上的$L^0$型基数约束问题。

**Result:** 成功地将DC重构方法扩展到梯度支持上具有$L^0$型基数约束的问题，从而能够以梯度稀疏性为目标并得到分段常数函数。

**Conclusion:** 该论文成功地将一种已知的DC重构方法扩展到处理梯度上的$L^0$型约束问题，这对于获得分段常数函数非常有用。

> **ai_Abstract:** 本文将一种用于处理$L^0$型基数约束的差分凸（DC）重构方法进行了扩展，使其适用于梯度支持上具有$L^0$约束的问题。这种扩展旨在通过利用$L^1$范数和最大$K$范数之差重构约束并求解惩罚子问题，从而实现梯度稀疏性并得到分段常数函数。

> **摘要翻译:** 优化中的基数约束通常是$L^0$型的，它们导致稀疏支持的优化器。当目标泛函为凸时，一种有效处理这些约束的算法方法是使用合适的$L^1$范数和最大$K$范数之差来重构约束，然后解决一系列惩罚子问题，这些子问题属于凸差（DC）类别。我们将这种DC重构方法扩展到梯度支持上具有$L^0$型基数约束的问题，即以梯度稀疏性为目标并因此得到分段常数函数的问题。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [603] [Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise](https://arxiv.org/abs/2506.11214)
> *重尾噪声下带动量的归一化随机一阶方法的复杂度*

*Chuan He, Zhaosong Lu, Defeng Sun, Zhanwang Deng* | **Main category: math.OC**

**Keywords:** 归一化随机方法, 动量, 重尾噪声, 复杂度, 无约束优化

**Comment:** 

> **TL;DR:** 本文提出了在重尾噪声下解决无约束优化问题的归一化随机一阶动量方法，并在理论上和实验上证明了其有效性和优越的复杂度。

**AI_Comments:** 本文的创新点在于提出了动态更新算法参数的归一化随机一阶动量方法，这使得方法无需显式的Lipschitz常数或噪声界等先验知识。此外，在比常用假设更弱的重尾噪声和弱平均平滑条件下建立了复杂度结果，提升了方法的普适性。其复杂度界优于或匹配现有最佳结果，显示了其理论上的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有随机优化方法常需要Lipschitz常数或噪声界等问题相关量的先验知识，且通常假设有界方差和均方平滑性。本文旨在提出不需要这些先验知识，且能在更弱的重尾噪声和弱平均平滑条件下工作的实用方法。

**Method:** 本文提出了实用的归一化随机一阶方法，结合了Polyak动量、多重外推动量和递归动量。这些方法采用动态更新的算法参数，不需要显式的问题相关量知识。

**Result:** 在重尾噪声和弱平均平滑条件下，本文建立了寻找近似随机驻点的一阶预言机复杂度结果。所得到的复杂度界优于或匹配了现有文献中的最佳结果。数值实验也证明了所提出方法的实际有效性。

**Conclusion:** 本文提出的归一化随机一阶动量方法在重尾噪声和弱平均平滑条件下，表现出优越或匹配现有最佳结果的理论复杂度，并且在实践中也有效。

> **ai_Abstract:** 本文提出了一系列实用的归一化随机一阶动量方法，包括Polyak、多重外推和递归动量，用于解决无约束优化问题。这些方法采用动态更新的参数，无需问题相关量的先验知识。研究在重尾噪声和弱平均平滑条件下，建立了寻找近似随机驻点的一阶预言机复杂度，其复杂度界优于或匹配了现有最佳结果。数值实验进一步验证了这些方法的实际有效性。

> **摘要翻译:** 在本文中，我们提出了实用的归一化随机一阶方法，结合了Polyak动量、多重外推动量和递归动量，用于解决无约束优化问题。这些方法采用动态更新的算法参数，不需要显式的问题相关量知识，例如Lipschitz常数或噪声界。我们在重尾噪声和弱平均平滑条件下建立了寻找近似随机驻点的一阶预言机复杂度结果——这两个条件都比常用的有界方差和均方平滑假设更弱。我们的复杂度界优于或匹配了文献中的最佳已知结果。数值实验表明了所提出方法的实际有效性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [613] [Quantum Learning and Estimation for Distribution Networks and Energy Communities Coordination](https://arxiv.org/abs/2506.11730)
> *面向配电网与能源社区协调的量子学习与估计*

*Yingrui Zhuang, Lin Cheng, Yuji Cao, Tongxin Li, Ning Qi, Yan Xu, Yue Chen* | **Main category: math.OC**

**Keywords:** 量子学习, 量子估计, 配电网, 能源社区, 协调

**Comment:** This is a manuscript submitted to PROTECTION AND CONTROL OF MODERN
  POWER SYSTEMS

> **TL;DR:** 本文提出了一种量子学习和估计方法，以改善配电网和能源社区之间的协调，并在准确性、模型规模和计算时间方面优于传统方法。

**AI_Comments:** 该研究的创新之处在于将量子叠加和纠缠等先进量子特性应用于配电网与能源社区的协调问题，特别是在学习和估计方面。其提出的Q-TCN-LSTM模型和QAE方法在提高精度、大幅减少模型规模、计算时间和资源需求方面表现出显著优势，展示了量子计算在解决能源系统复杂优化问题上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 配电网（DNs）与能源社区（ECs）之间的协调面临挑战，原因在于信息可用性有限（DNs只能获取ECs的聚合能源使用量）以及考虑不确定性及相关风险时面临的巨大计算负担。

**Method:** 本文提出了一种量子学习与估计方法。具体而言，开发了一种混合量子时间卷积网络-长短期记忆（Q-TCN-LSTM）模型，用于建立ECs响应与DNs价格激励之间的端到端映射。此外，开发了一种基于量子振幅估计（QAE）和两个相位旋转电路的量子估计方法，以显著加速在大量不确定性场景下的优化过程。

**Result:** 数值实验表明，与传统神经网络相比，所提出的Q-TCN-LSTM模型将映射精度提高了69.2%，同时将模型大小减少了99.75%，计算时间减少了93.9%。与传统蒙特卡洛模拟相比，QAE在计算时间上大幅减少（高达99.99%），并需要显著更少的计算资源，同时实现了可比的精度。

**Conclusion:** 本文提出的量子学习与估计方法通过提高精度、减少计算负担并降低资源需求，显著增强了配电网与能源社区之间的协调，展示了量子计算在电力系统运行中的潜力。

> **ai_Abstract:** 本文针对配电网（DNs）与能源社区（ECs）协调中信息有限和计算负担重的问题，提出了一种量子学习与估计方法。通过开发混合量子时间卷积网络-长短期记忆（Q-TCN-LSTM）模型实现端到端映射，并利用量子振幅估计（QAE）加速不确定性场景下的优化。实验结果表明，与传统方法相比，Q-TCN-LSTM显著提高了映射精度并减少了模型大小和计算时间，而QAE则大幅降低了计算时间并减少了资源需求，同时保持了精度，有效提升了DNs与ECs的协调效率。

> **摘要翻译:** 配电网（DNs）的价格信号引导能源社区（ECs）调整能源使用，从而实现有效协调以确保电力系统可靠运行。然而，由于信息可用性有限（即DNs只能获取ECs的聚合能源使用量）以及通过大量场景考虑不确定性及相关风险所带来的高计算负担，这种协调面临重大挑战。为了应对这些挑战，我们提出了一种量子学习和估计方法，以增强DNs和ECs之间的协调。具体而言，我们利用量子叠加和纠缠等先进量子特性，开发了一种混合量子时间卷积网络-长短期记忆（Q-TCN-LSTM）模型，以建立ECs响应与DNs价格激励之间的端到端映射。此外，我们开发了一种基于量子振幅估计（QAE）和两个相位旋转电路的量子估计方法，以显著加速在大量不确定性场景下的优化过程。数值实验表明，与传统神经网络相比，所提出的Q-TCN-LSTM模型将映射精度提高了69.2%，同时将模型大小减少了99.75%，计算时间减少了93.9%。与传统蒙特卡洛模拟相比，QAE在计算时间上大幅减少（高达99.99%），并需要显著更少的计算资源，同时实现了可比的精度。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [619] [Convergence of Momentum-Based Optimization Algorithms with Time-Varying Parameters](https://arxiv.org/abs/2506.11904)
> *具有时变参数的动量优化算法的收敛性*

*Mathukumalli Vidyasagar* | **Main category: math.OC**

**Keywords:** 动量优化, 随机梯度下降, 收敛性, 时变参数, 零阶方法

**Comment:** 32 pages

> **TL;DR:** 本文提出了一种统一的、具有时变动量项的随机优化算法，并给出了其收敛的充分条件。

**AI_Comments:** 本文的主要创新在于提出了一个统一的动量优化算法框架，并允许动量参数随时间变化。更重要的是，它放宽了对随机梯度的严格假设，允许其有偏且方差无界增长，这使得理论能够应用于更广泛的场景，特别是零阶方法，增强了算法的普适性和实用性。对另一个不切实际方法的分析也提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种统一的随机优化算法，该算法使用动量项，并允许动量项随时间变化，同时放宽对随机梯度的假设，使其适用于零阶方法。

**Method:** 本文提出了一种统一的随机优化算法，该算法包含随机重球（SHB）和随机Nesterov加速梯度（SNAG）算法作为特例。该算法的动量项允许随时间变化，并且对随机梯度的假设是最普遍的，即梯度可以是有偏的，并且条件方差可以无界增长。文章还分析了文献中另一种针对SHB算法的时变动量参数方法。

**Result:** 本文提出了一组统一算法收敛的充分条件，这些条件是标准随机梯度下降的Robbins-Monro和Kiefer-Wolfowitz-Blum条件的自然推广。此外，研究发现文献中另一种针对SHB算法的时变动量参数方法是不切实际的。

**Conclusion:** 本文成功提出了一个统一的、具有时变参数的动量随机优化算法，并为其收敛性提供了普适的条件，扩展了现有理论的适用范围。同时，指出了现有文献中某些方法的局限性。

> **ai_Abstract:** 本文提出了一种统一的随机优化算法，该算法引入了随时间变化的动量项，并将SHB和SNAG算法作为特例。该算法在对随机梯度最普遍的假设下（允许有偏且条件方差无界增长）进行设计，使其适用于零阶方法。文章给出了该统一算法收敛的充分条件，并指出这些条件是现有Robbins-Monro和Kiefer-Wolfowitz-Blum条件的推广。此外，论文还分析了文献中另一种时变动量SHB算法的实用性，并认为其不切实际。

> **摘要翻译:** 在本文中，我们提出了一种利用“动量”项的随机优化统一算法；换句话说，随机梯度不仅取决于目标函数当前的真实梯度，还取决于上一次迭代的真实梯度。我们的公式将随机重球（SHB）和随机Nesterov加速梯度（SNAG）算法作为特例。此外，在我们的公式中，动量项允许随时间（即迭代计数器）变化。对随机梯度的假设是文献中最普遍的，因为它可能是有偏的，并且条件方差可以随时间无界增长。最后一个特性对于使理论适用于“零阶”方法至关重要，在这些方法中，梯度仅使用两次函数评估进行估计。
我们给出了一组统一算法收敛的充分条件。这些条件是标准随机梯度下降的Robbins-Monro和Kiefer-Wolfowitz-Blum条件的自然推广。我们还分析了文献中另一种针对具有时变动量参数的SHB算法的方法，并表明它是不切实际的。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [377] [HoToPy: A toolbox for X-ray holo-tomography in Python](https://arxiv.org/abs/2506.11567)
> *HoToPy：一个用于Python中X射线全息断层成像的工具箱*

*Jens Lucht, Paul Meyer, Leon Merten Lohse, Tim Salditt* | **Main category: physics.optics**

**Keywords:** X射线成像, 全息断层成像, 相位恢复, Python工具箱, 同步辐射

**Comment:** 

> **TL;DR:** HoToPy是一个Python工具箱，用于X射线全息和断层成像，包含多种相位恢复算法和辅助功能，模块化设计使其适用于算法开发和集成。

**AI_Comments:** HoToPy工具箱的创新之处在于其将多种X射线全息和断层成像的相位恢复算法及辅助功能整合到一个统一、直观的Python框架中。其模块化设计提升了灵活性，使得算法的开发、测试以及与现有同步辐射和XFEL仪器的集成变得更加便捷。这对于推动X射线相位成像领域的研究和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个用于全息和断层X射线成像的Python工具箱，以提供统一、直观的界面，集合多种相位恢复算法和辅助功能，并支持算法开发和集成到其他同步辐射/XFEL仪器的重建流程中。

**Method:** 该工具箱HoToPy包含用于深度全息和直接对比成像模式的相位恢复算法，包括非线性方法、扩展的正则化、约束集和优化器选择，所有这些都通过统一和直观的界面实现。此外，它还具有用于（断层）对准、图像处理和成像实验模拟的辅助功能。

**Result:** 该工具箱的功能通过在PETRA III储存环（DESY，汉堡）P10光束线的“GINIX”仪器上，以催化纳米粒子在深度全息模式下成像的例子进行了说明。

**Conclusion:** HoToPy工具箱由于其模块化设计，可以灵活地用于算法开发和基准测试，也可以与其他同步辐射或XFEL仪器的基于传播的相位成像重建流程进行接口和集成。

> **ai_Abstract:** HoToPy是一个基于Python的X射线全息和断层成像工具箱。它集成了多种相位恢复算法，支持非线性方法、多种正则化和优化器选择，并提供统一的直观界面。此外，该工具箱还包含图像对准、处理和模拟等辅助功能。通过对催化纳米粒子在同步辐射设施中的成像实例，展示了其能力。HoToPy的模块化设计使其能够灵活应用于算法开发、基准测试，并易于集成到其他X射线成像设备的重建流程中。

> **摘要翻译:** 我们提出了一个用于全息和断层X射线成像的Python工具箱。它包含一系列用于深度全息和直接对比成像模式的相位恢复算法，包括非线性方法和扩展的正则化、约束集和优化器选择，所有这些都以统一和直观的界面实现。此外，它还具有用于（断层）对准、图像处理和成像实验模拟的辅助功能。该工具箱的功能通过在PETRA III储存环（DESY，汉堡）P10光束线的“GINIX”仪器上，以催化纳米粒子在深度全息模式下成像的例子进行了说明。由于其模块化设计，该工具箱可以灵活地用于算法开发和基准测试，也可以与其他同步辐射或XFEL仪器的基于传播的相位成像重建流程进行接口和集成。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [378] [On scattering for NLS: rigidity properties and numerical simulations via the lens transform](https://arxiv.org/abs/2506.11560)
> *关于NLS散射：刚性性质和通过透镜变换的数值模拟*

*Rémi Carles, Georg Maierhofer* | **Main category: math.AP**

**Keywords:** 散射算子, 非线性薛定谔方程, 透镜变换, 数值模拟, 长程散射

**Comment:** 27 pages

> **TL;DR:** 该研究通过首次将透镜变换应用于数值模拟，提出了一种高效可靠的方法来计算非聚焦非线性薛定谔方程的散射算子，并探讨了其在各种情况下的性质，包括长程散射。

**AI_Comments:** 该论文的创新点在于首次将透镜变换应用于散射算子的数值模拟，极大地提高了计算效率和可靠性。这为解决非线性薛定谔方程的散射问题提供了一个新的、强大的工具。该方法不仅在数值上表现出色，还在理论上提出了新的恒等式和性质，并基于模拟结果提出了富有启发性的新猜想，这对于推动该领域的分析理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 散射算子的渐近性质（涉及无限时间）使得其计算极具挑战性。本文旨在克服这一挑战，并开发一种高效可靠的方法来计算散射算子。

**Method:** 通过利用透镜变换提供的时空紧化来计算散射算子，这是该技术首次用于数值模拟。研究还引入并证明了散射算子的几个新恒等式和理论性质。通过数值实验支持了该方法，并探讨了已知分析性质以及一维三次薛定谔方程的长程散射情况。

**Result:** 开发出一种高效可靠的散射算子计算方法。数值模拟结果与散射算子的已知分析性质一致。模拟允许探索超出当前分析理解的范围，并提出了关于算子的固定点和旋转点以及在散焦和聚焦情况下的长程设置中其存在性的新猜想。

**Conclusion:** 通过利用透镜变换，成功开发了一种计算非线性薛定谔方程散射算子的高效可靠方法，并在此过程中发现了新的理论性质，提出了新的猜想，从而扩展了对散射现象的理解。

> **ai_Abstract:** 本研究提出了一种通过透镜变换进行数值模拟的创新方法，以高效可靠地计算非聚焦非线性薛定谔方程的散射算子。该方法克服了传统计算散射算子所面临的挑战，并首次将透镜变换应用于此领域。研究不仅开发了新的计算技术，还发现了散射算子的新理论性质，并通过数值实验验证了其有效性。此外，模拟结果还促进了对超出当前分析理解范围的探索，并提出了关于算子性质的新猜想，尤其是在长程散射情境下。

> **摘要翻译:** 我们分析了与非聚焦非线性薛定谔方程相关的散射算子，该算子捕捉了在方程非线性流作用下解在无限时间间隔内的演变。散射算子的渐近性质（涉及无限时间）使其计算特别具有挑战性。我们通过利用透镜变换提供的时空紧化来克服了这一点，这标志着该技术首次用于数值模拟。这导致了一种高效可靠的方法，用于在各种情况下计算散射算子。在开发这种方法时，我们引入并证明了散射算子的几个新恒等式和理论性质。我们通过几个数值实验支持了我们的构造，这些实验表明与散射算子的已知分析性质一致，并且还解决了了一维三次薛定谔方程的长程散射情况。我们的模拟使我们能够进一步探索超出当前分析理解的范围，并引导我们提出了关于算子的固定点和旋转点以及在散焦和聚焦情况下长程设置中其存在性的新猜想。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

### [390] [Optimal trace norms for Helmholtz problems](https://arxiv.org/abs/2506.11944)
> *亥姆霍兹问题的最优迹范数*

*Benedikt Gräßle* | **Main category: math.AP**

**Keywords:** 亥姆霍兹问题, 迹范数, 加权Sobolev-Slobodeckij范数, 边界积分算子, 波数

**Comment:** 

> **TL;DR:** 本文对亥姆霍兹问题中波数加权的迹范数进行了严格分析，通过加权 Sobolev-Slobodeckij 范数对其进行明确表征，并证明了在这些范数下边界积分算子具有不随波数趋零而恶化的改进连续性估计。

**AI_Comments:** 本文的创新之处在于对波数加权迹范数进行了严格的数学分析，并证明了这些范数能够使得边界积分算子在波数趋近于零时，其连续性估计不会恶化。这对于亥姆霍兹问题在低频情况下的数值求解具有重要的理论和实际意义，有助于提高数值方法的稳定性和精度。

<details>
  <summary>Details</summary>

**Motivation:** 为了对亥姆霍兹问题中波数加权的迹范数进行严格分析和明确表征，并改进边界积分算子的连续性估计，尤其是在波数趋零时保持其性能。

**Method:** 本文对波数加权的迹范数进行了严格的数学分析，通过加权 Sobolev-Slobodeckij 范数对其进行了明确表征和尺度估计，并确定了其内在条件。

**Result:** 研究明确表征了波数加权的迹范数，突出了它们对扩展集几何形状和权重$\\sigma$的依赖性；确定了这些迹范数内在于孤立边界分量的条件；提供了加权空间中迹不等式的$\\sigma$-显式估计；在这些自然波数加权范数中，边界积分算子允许改进的连续性估计，且不随$\\sigma\\to 0$而恶化。

**Conclusion:** 通过对亥姆霍兹问题中波数加权迹范数的严格分析，可以获得边界积分算子在小波数极限下性能不恶化的改进连续性估计，这对于数值稳定性至关重要。

> **ai_Abstract:** 本文对亥姆霍兹问题中波数加权的迹范数进行了深入的数学分析。研究明确了这些迹范数与加权 Sobolev-Slobodeckij 范数的关系，并揭示了它们对几何形状和波数的依赖性。重要的是，研究发现这些加权迹范数使得边界积分算子在波数趋近于零时，其连续性估计不会出现恶化，这对于相关数值方法的稳定性和精度具有重要意义。

> **摘要翻译:** 亥姆霍兹问题的自然 $H^1(\\Omega)$ 能量范数用波数模量 $\\sigma$ 加权，并通过最小扩展到 $\\Omega\\subset\\mathbb R^n$ 在迹空间 $H^{\\pm1/2}(\\Gamma)$ 上引入自然的加权范数。本文对这些迹范数进行了严格分析，通过加权 Sobolev-Slobodeckij 范数对其进行了明确表征和尺度估计，突出了它们对扩展集 $\\Omega\\subset\\mathbb R^n$ 的几何形状和权重 $\\sigma$ 的依赖性。该分析确定了这些迹范数内在_于_孤立边界分量 $\\Gamma\\subset\\partial\\Omega$ 的条件，并为加权空间中的迹不等式提供了 $\\sigma$-显式估计。在这些自然的波数加权范数中，边界积分算子允许改进的连续性估计，这些估计不会随着 $\\sigma\\to 0$ 而恶化。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='q-biogn'></a>
## q-bio.GN 

### [602] [Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data](https://arxiv.org/abs/2506.11182)
> *基于基础模型和染色质可及性数据对CRISPR-Cas12活性进行多模态建模*

*Azim Dehghani Amirabad, Yanfei Zhang, Artem Moskalev, Sowmya Rajesh, Tommaso Mansi, Shuwei Li, Mangal Prakash, Rui Liao* | **Main category: q-bio.GN**

**Keywords:** CRISPR-Cas12, gRNA活性, 基础模型, 染色质可及性, 多模态建模

**Comment:** This manuscript has been accepted by ICML workshop 2025

> **TL;DR:** 本研究利用预训练的生物学基础模型和染色质可及性数据，显著提升了CRISPR-Cas12中gRNA活性预测的准确性，解决了现有方法数据有限和PAM变异的挑战。

**AI_Comments:** 这项研究的创新之处在于，它首次展示了利用非领域特异性预训练的生物学基础模型（如在转录组数据上训练的模型）结合染色质可及性数据，能够有效提升CRISPR-Cas12 gRNA活性预测的准确性。这为解决基因编辑中数据稀缺和复杂生物背景下的预测难题提供了新颖且高效的解决方案，具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 预测引导RNA（gRNA）活性对于有效的CRISPR-Cas12基因组编辑至关重要，但由于数据有限、PAM（原间隔区相邻基序）变异以及依赖大规模训练，这一任务仍然具有挑战性。

**Method:** 研究人员利用在转录组数据上训练的预训练生物学基础模型的嵌入作为轻量级回归器的输入，并整合了染色质可及性数据以捕捉调控背景，从而改进gRNA活性预测。

**Result:** 结果显示，与传统基线相比，使用预训练基础模型取得了显著的性能提升。整合染色质可及性数据进一步提高了预测性能。

**Conclusion:** 本研究结果强调了预训练基础模型和染色质可及性数据在gRNA活性预测中的有效性。

> **ai_Abstract:** 本研究旨在解决CRISPR-Cas12基因组编辑中gRNA活性预测的挑战，这些挑战源于数据限制、PAM变异和对大规模训练的依赖。研究人员探索了使用预训练生物学基础模型（最初在转录组数据上训练）来改进gRNA活性估计，即使没有进行特定领域预训练。通过将现有RNA基础模型的嵌入作为轻量级回归器的输入，并进一步整合染色质可及性数据以捕获调控背景，该方法显示出比传统基线显著的性能提升。研究结果强调了预训练基础模型和染色质可及性数据在准确预测gRNA活性方面的有效性。

> **摘要翻译:** 预测引导RNA（gRNA）活性对于有效的CRISPR-Cas12基因组编辑至关重要，但由于数据有限、原间隔区相邻基序（PAMs——Cas结合的短序列要求）的变异以及依赖大规模训练，这一任务仍然具有挑战性。我们研究了最初在转录组数据上训练的预训练生物学基础模型是否可以在没有特定领域预训练的情况下改进gRNA活性估计。使用现有RNA基础模型的嵌入作为轻量级回归器的输入，我们展示了相对于传统基线的显著增益。我们还整合了染色质可及性数据以捕捉调控背景，进一步提高了性能。我们的结果突出了预训练基础模型和染色质可及性数据在gRNA活性预测中的有效性。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

### [606] [HEIST: A Graph Foundation Model for Spatial Transcriptomics and Proteomics Data](https://arxiv.org/abs/2506.11152)
> *HEIST：一种用于空间转录组学和蛋白质组学数据的图基础模型*

*Hiren Madhu, João Felipe Rocha, Tinglin Huang, Siddharth Viswanath, Smita Krishnaswamy, Rex Ying* | **Main category: q-bio.GN**

**Keywords:** 空间转录组学, 图基础模型, 分层图Transformer, 基因调控网络, 微环境影响

**Comment:** 

> **TL;DR:** HEIST是一种用于空间转录组学和蛋白质组学数据的分层图Transformer基础模型，它将组织建模为细胞邻域图，将细胞建模为基因调控网络，通过捕获微环境影响并在下游任务中取得最先进的结果，优于现有模型。

**AI_Comments:** HEIST的创新之处在于其分层图Transformer架构，能够同时建模组织层面的空间邻域和细胞内部的基因调控网络，并通过跨层消息传递整合这些信息。这种方法有效地解决了现有模型在处理空间转录组学数据时忽略空间或基因调控信息的问题，并捕获了微环境对细胞行为的影响，这对于深入理解生物学机制至关重要。其在大规模数据集上的预训练和在多项下游任务中SOTA的表现，证明了其作为基础模型的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有空间转录组学模型忽略空间分辨率或基因调控信息，且未能考虑具有分层依赖关系的基因调控模式，因此无法生成细胞和基因的语境化表示。

**Method:** HEIST是一种基于分层图Transformer的基础模型。它将组织建模为空间细胞邻域图，并将每个细胞建模为基因调控网络图。该框架包含一个分层图Transformer，执行跨层和层内消息传递。HEIST使用空间感知对比学习和掩码自编码目标，在来自15个器官的124个组织中的22.3M个细胞上进行预训练。

**Result:** HEIST有效地将微环境影响编码到细胞嵌入中，从而能够发现现有模型无法区分的空间信息亚群。它在临床结果预测、细胞类型注释、基因插补和空间信息细胞聚类这四项下游任务上，跨多种技术取得了最先进的结果。

**Conclusion:** 研究结果突出了分层建模和基于基因调控网络（GRN）的表示对于空间转录组学和蛋白质组学数据的重要性。

> **ai_Abstract:** HEIST是一种新颖的分层图Transformer基础模型，专为空间转录组学和蛋白质组学数据设计。它通过将组织建模为空间细胞邻域图并将每个细胞建模为基因调控网络图来解决现有模型忽略空间分辨率、基因调控信息或分层依赖性的问题。HEIST利用跨层和层内消息传递机制，并在一组大规模数据集上进行预训练。实验结果表明，HEIST能有效捕获微环境影响，识别空间信息亚群，并在多项下游任务中实现最先进的性能，验证了其分层和GRN-based表示的有效性。

> **摘要翻译:** 单细胞转录组学已成为数据驱动生物学见解的重要来源，使得能够使用先进的深度学习方法来理解单细胞水平的细胞异质性和转录调控。随着空间转录组学数据的出现，我们有望在组织背景下了解细胞，因为它提供了空间坐标和转录组读数。然而，现有模型要么忽略空间分辨率，要么忽略基因调控信息。细胞中的基因调控可能会根据来自邻近细胞的微环境线索而变化，但现有模型忽略了具有跨抽象层级依赖关系的基因调控模式。为了从空间转录组学数据中创建细胞和基因的语境化表示，我们引入了HEIST，这是一种基于分层图Transformer的空间转录组学和蛋白质组学数据基础模型。HEIST将组织建模为空间细胞邻域图，每个细胞又被建模为基因调控网络图。该框架包括一个分层图Transformer，它执行跨层消息传递和层内消息传递。HEIST使用空间感知对比学习和掩码自编码目标，在来自15个器官的124个组织中的22.3M个细胞上进行预训练。对HEIST细胞表示的无监督分析表明，它有效地将微环境影响编码到细胞嵌入中，从而能够发现现有模型无法区分的空间信息亚群。此外，HEIST在四项下游任务（如临床结果预测、细胞类型注释、基因插补和空间信息细胞聚类）上取得了最先进的结果，突出了分层建模和基于GRN的表示的重要性。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

### [607] [Brain-wide interpolation and conditioning of gene expression in the human brain using Implicit Neural Representations](https://arxiv.org/abs/2506.11158)
> *运用隐式神经表示对人脑基因表达进行全脑插值和条件化*

*Xizheng Yu, Justin Torok, Sneha Pandya, Sourav Pal, Vikas Singh, Ashish Raj* | **Main category: q-bio.GN**

**Keywords:** 隐式神经表示, 基因表达, 空间转录组学, 人脑, 插值

**Comment:** 

> **TL;DR:** 该研究探讨了使用隐式神经表示（INR）对稀疏采样的人脑基因表达数据进行全脑高分辨率空间图谱生成的可行性。

**AI_Comments:** 该论文的创新之处在于将隐式神经表示（INR）这一新兴技术应用于人脑基因表达的空间插值和图谱生成，解决了稀疏采样数据的挑战。这对于理解基因在全脑范围内的分布及其与疾病（如AD）的关系具有重要意义。该方法有望为神经科学研究提供更高分辨率的基因表达数据视图。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在利用非局部、非线性图像插值和外推算法（特别是基于隐式神经表示的方法）来分析空间转录组数据，并利用健康人脑中稀疏采样的微阵列基因表达数据，生成任何给定基因在全脑范围内的体素级高分辨率空间图谱。

**Method:** 研究首先获取了100个顶级AD风险基因，并从艾伦人脑图谱（AHBA）中获取了它们的基线空间转录谱。然后，他们调整了隐式神经表示模型，使管道能够生成所有基因的稳健的体素分辨率定量图谱。他们还使用从Abagen获得的插值作为基线/参考进行了多种实验。

**Result:** 论文展示了使用隐式神经表示模型成功地从稀疏数据生成全脑、体素级分辨率的基因表达空间图谱。并与Abagen获得的插值进行了比较实验。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了隐式神经表示（INR）在分析稀疏空间转录组数据中的应用，旨在将健康人脑中稀疏采样的基因表达数据插值和条件化，生成全脑体素级分辨率的基因表达空间图谱。研究选取了100个AD风险基因，并利用艾伦人脑图谱数据调整INR模型，以实现稳健的基因表达图谱生成，并与Abagen的插值结果进行了对比验证。

> **摘要翻译:** 在本文中，我们研究了非局部、非线性图像插值和外推算法（特别是基于隐式神经表示（INR）的思想）作为空间转录组数据分析工具的有效性和实用性。我们旨在利用健康人脑中稀疏采样的微阵列基因表达数据，生成任何给定基因在全脑范围内的体素级高分辨率空间图谱。为此，我们首先获得了100个顶级AD风险基因，其基线空间转录谱来自艾伦人脑图谱（AHBA）。我们调整了隐式神经表示模型，以便该流程能够生成所有基因的稳健的体素分辨率定量图谱。我们提出了各种实验，使用从Abagen获得的插值作为基线/参考。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

### [611] [SemanticST: Spatially Informed Semantic Graph Learning for1 Clustering, Integration, and Scalable Analysis of Spatial2 Transcriptomics](https://arxiv.org/abs/2506.11491)
> *SemanticST：用于空间转录组学聚类、整合和可扩展分析的空间感知语义图学习*

*Roxana Zahedi, Ahmadreza Argha, Nona Farbehi, Ivan Bakhshayeshi, Youqiong Ye, Nigel H. Lovell, Hamid Alinejad-Rokny* | **Main category: q-bio.GN**

**Keywords:** 空间转录组学, 图神经网络, 语义图学习, 可扩展性, 细胞聚类

**Comment:** 6 Figures

> **TL;DR:** SemanticST是一个可扩展的图学习框架，通过构建多语义图和注意力融合，显著提升了空间转组学数据的分析性能和可解释性。

**AI_Comments:** SemanticST的创新点在于其多语义图构建和注意力融合策略，以及社区感知最小割损失的应用，这使其能够更全面地捕获生物学信息并提高对稀疏数据的鲁棒性。其支持mini-batch训练是解决大规模空间转录组数据可扩展性问题的关键突破，使其成为首个能处理Xenium等大型数据集的图神经网络。该框架的生物学解释性和在临床数据中发现稀有病理特征的能力，凸显了其在推动空间解析组织图谱和精准医学方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前空间转录组学分析方法面临数据噪声、可扩展性有限以及复杂细胞关系建模不足的问题。

**Method:** SemanticST是一个生物学知情的、基于图的深度学习框架。它通过构建多个上下文特定的图（捕获空间邻近性、基因表达相似性和组织域结构），并学习解耦嵌入。这些嵌入通过注意力启发策略融合，生成统一的生物学有意义的表示。它使用社区感知最小割损失以提高鲁棒性，并支持mini-batch训练以实现可扩展性。

**Result:** SemanticST在四种平台（Visium、Slide-seq、Stereo-seq、Xenium）和多种人类及小鼠组织上，ARI、NMI和轨迹保真度比DeepST、GraphST和IRIS一致提高20%。在乳腺癌Xenium数据分析中，揭示了稀有且具临床意义的生态位，包括三受体阳性簇、空间上独特的DCIS-to-IDC过渡区和FOXC2肿瘤相关肌上皮细胞。

**Conclusion:** SemanticST为空间转录组学分析提供了一个可扩展、可解释且具有生物学基础的框架，能够实现跨组织类型和疾病的稳健发现，并为空间解析的组织图谱和下一代精准医学铺平道路。

> **ai_Abstract:** SemanticST是一个新型的、基于图的深度学习框架，旨在解决空间转录组数据分析中的噪声、可扩展性和复杂关系建模挑战。它通过构建和融合多语义图来捕获细胞上下文信息，并利用社区感知最小割损失增强鲁棒性。该框架支持大规模数据处理，并在多平台基准测试中展现出卓越的聚类和轨迹推断性能，同时在乳腺癌数据分析中揭示了重要的生物学发现，为精准医学提供了有力的工具。

> **摘要翻译:** 空间转录组学（ST）技术能够以空间分辨率进行基因表达谱分析，为组织结构和疾病异质性提供了前所未有的见解。然而，当前的分析方法常常面临数据噪声、可扩展性有限以及复杂细胞关系建模不足的问题。我们提出了SemanticST，一个生物学知情的、基于图的深度学习框架，它通过多语义图构建来建模多样化的细胞环境。SemanticST构建了多个上下文特定的图，捕获空间邻近性、基因表达相似性和组织域结构，并为每个图学习解耦的嵌入。这些嵌入通过注意力启发策略进行融合，以产生统一的、具有生物学意义的表示。社区感知最小割损失提高了相对于对比学习的鲁棒性，尤其是在稀疏的ST数据中。SemanticST支持mini-batch训练，使其成为第一个可扩展到大型数据集（如Xenium，500,000个细胞）的图神经网络。在四种平台（Visium、Slide-seq、Stereo-seq、Xenium）以及多种人类和小鼠组织上的基准测试显示，与DeepST、GraphST和IRIS相比，ARI、NMI和轨迹保真度一致提高20%。在乳腺癌Xenium数据的重新分析中，SemanticST揭示了稀有且具有临床意义的生态位，包括三受体阳性簇、空间上独特的DCIS-to-IDC过渡区以及FOXC2肿瘤相关肌上皮细胞，这表明存在非典型的EMT程序，具有干细胞样特征。因此，SemanticST为空间转录组学分析提供了一个可扩展、可解释且具有生物学基础的框架，能够实现跨组织类型和疾病的稳健发现，并为空间解析的组织图谱和下一代精准医学铺平道路。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

<a id='nlinao'></a>
## nlin.AO 

### [604] [Solving Inverse Problems in Stochastic Self-Organising Systems through Invariant Representations](https://arxiv.org/abs/2506.11796)
> *通过不变表示解决随机自组织系统中的逆问题*

*Elias Najarro, Nicolas Bessone, Sebastian Risi* | **Main category: nlin.AO**

**Keywords:** 自组织系统, 逆问题, 随机性, 不变表示, 视觉嵌入

**Comment:** Preprint. Under review

> **TL;DR:** 本文提出了一种新颖的逆向建模方法，利用视觉嵌入生成不变表示，以解决随机自组织系统中的逆问题，即使在存在强随机性的情况下也能可靠地恢复未知参数。

**AI_Comments:** 该论文的创新之处在于利用视觉嵌入和不变表示来解决传统方法难以处理的随机自组织系统中的逆问题。这种方法避免了对复杂随机模式进行像素级比较的局限性，提供了一种更鲁棒的参数恢复机制，对于理解和建模自然界中广泛存在的自组织现象具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自组织系统中的逆问题（从宏观观测中寻找未知因果参数）是一个基本挑战，尤其当观测具有强随机分量时，传统方法因无法捕获变量结果之间的特征相似性而失败。

**Method:** 本文引入了一种新颖的逆向建模方法，专门用于处理可观测空间中的随机性。该方法利用视觉嵌入生成鲁棒的表示，捕获感知不变性，并通过将模式表示映射到不变嵌入空间来有效恢复未知因果参数，无需手工设计目标函数或启发式方法。

**Result:** 该方法在两种典型模型（反应扩散系统和基于代理的社会隔离模型）上进行了评估，结果表明即使在结果具有随机性的情况下，它也能可靠地恢复参数。此外，该方法还应用于真实的生物模式。

**Conclusion:** 该研究提出的方法能够可靠地解决随机自组织系统中的逆问题，即使在存在强随机性的情况下也能恢复未知参数，为理论家和实验家研究复杂随机模式形成背后的动力学提供了工具。

> **ai_Abstract:** 本文提出了一种新颖的逆向建模方法，旨在解决随机自组织系统中的逆问题。该方法利用视觉嵌入技术，将宏观观测的模式映射到不变嵌入空间，从而在无需手工设计目标函数的情况下，有效恢复具有强随机性的系统中的未知因果参数。研究通过在反应扩散系统和代理模型上的验证，并应用于真实生物模式，证明了其在处理随机性方面的鲁棒性和有效性，为理解复杂随机模式形成提供了新工具。

> **摘要翻译:** 自组织系统展示了简单的局部规则如何生成复杂的随机模式。许多自然系统依赖于这种动力学，使得自组织成为理解自然复杂性的核心。建模此类系统的一个基本挑战是解决逆问题：从宏观观测中寻找未知因果参数。当观测具有强随机分量，产生多样但等效的模式时，这项任务变得特别困难。传统逆方法在此设置中失败，因为像素级度量无法捕获变量结果之间的特征相似性。在这项工作中，我们引入了一种新颖的逆向建模方法，专门设计用于处理可观测空间中的随机性，利用视觉嵌入的能力来产生捕获感知不变性的鲁棒表示。通过将模式表示映射到不变嵌入空间，我们可以有效地恢复未知因果参数，而无需手工设计目标函数或启发式方法。我们在两种典型模型——反应扩散系统和基于代理的社会隔离模型——上评估了该方法，结果表明即使在结果具有随机性的情况下，它也能可靠地恢复参数。我们进一步将该方法应用于真实的生物模式，凸显了其作为理论家和实验家研究复杂随机模式形成背后动力学的工具的潜力。

</details>

[⬆️ 返回分类顶部](#nlinao) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [609] [Polymorphism Crystal Structure Prediction with Adaptive Space Group Diversity Control](https://arxiv.org/abs/2506.11332)
> *具有自适应空间群多样性控制的多晶型晶体结构预测*

*Sadman Sadeed Omee, Lai Wei, Sourin Dey, Jianjun Hu* | **Main category: cond-mat.mtrl-sci**

**Keywords:** 多晶型, 晶体结构预测, 遗传算法, 空间群多样性, 神经网络势

**Comment:** 

> **TL;DR:** 本文提出了一种名为ParetoCSP2的多目标遗传算法，用于多晶型晶体结构预测，通过自适应空间群多样性控制和改进的初始化方法，显著提高了预测性能和收敛速度，优于现有基线算法。

**AI_Comments:** 本文的创新点在于引入了自适应空间群多样性控制技术，并将其与多目标遗传算法相结合，有效解决了多晶型晶体结构预测中常见的多样性不足和早熟收敛问题。该方法在预测准确性和效率上均取得了显著提升，为材料科学中新材料的发现和合成提供了强大的计算工具，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 计算方法在材料科学中对预测多晶型晶体结构至关重要，有助于理解稳定性关系、指导合成并发现新材料，避免大量试错。然而，目前用于无机多晶型结构的有效晶体结构预测（CSP）算法仍然有限。

**Method:** 本文提出了ParetoCSP2，一种多目标遗传算法，用于多晶型晶体结构预测。该算法引入了自适应空间群多样性控制技术，由神经网络原子间势引导，防止任何单一空间群在群体中过度表示。通过改进的种群初始化方法和迭代结构弛豫，ParetoCSP2不仅缓解了早熟收敛，还提高了收敛速度。

**Result:** ParetoCSP2在多晶型预测中表现出色，对于具有相同晶胞原子数量但有两种多晶型的配方，其空间群和结构相似性准确率接近完美。在基准数据集上，它在这些准确性方面比基线算法高出2.46-8.62倍，并在常规CSP的关键性能指标上提高了44.8%-87.04%。

**Conclusion:** ParetoCSP2是一种有效且高性能的多晶型晶体结构预测算法，通过其独特的多样性控制和优化策略，显著优于现有方法，为材料科学中的多晶型探索提供了强大的工具。

> **ai_Abstract:** 本文提出了一种新颖的多目标遗传算法ParetoCSP2，用于解决无机多晶型晶体结构预测的挑战。该算法通过引入自适应空间群多样性控制技术和改进的种群初始化与迭代弛豫方法，有效防止了早熟收敛并显著提高了收敛速度。实验结果表明，ParetoCSP2在多晶型预测方面表现出卓越性能，尤其在空间群和结构相似性准确率上接近完美，并且在多项关键指标上显著优于现有基线算法。

> **摘要翻译:** 晶体材料可以以相同的化学成分形成不同的结构排列（即多晶型），根据它们的合成方式或操作条件表现出不同的物理特性。例如，碳可以以石墨（软、导电）或金刚石（硬、绝缘）的形式存在。能够预测这些多晶型的计算方法在材料科学中至关重要，它们有助于理解稳定性关系、指导合成工作以及发现具有所需特性的新材料，而无需进行大量的试错实验。然而，用于无机多晶型结构的有效晶体结构预测（CSP）算法仍然有限。我们提出了ParetoCSP2，一种用于多晶型CSP的多目标遗传算法，它结合了自适应空间群多样性控制技术，在神经网络原子间势的指导下，防止任何单一空间群在群体中过度表示。通过改进的种群初始化方法和执行迭代结构弛豫，ParetoCSP2不仅缓解了早熟收敛，而且提高了收敛速度。我们的结果表明，ParetoCSP2在多晶型预测方面取得了优异的性能，包括对于具有相同晶胞原子数量但有两种多晶型的配方，其空间群和结构相似性准确率接近完美。在基准数据集上进行评估，它在这些准确性方面比基线算法高出2.46-8.62倍，并在常规CSP的关键性能指标上提高了44.8%-87.04%。我们的源代码可在https://github.com/usccolumbia/ParetoCSP2免费获取。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [618] [Decadal sink-source shifts of forest aboveground carbon since 1988](https://arxiv.org/abs/2506.11879)
> *1988年以来森林地上碳的年代际汇-源转变*

*Zhen Qian, Sebastian Bathiany, Teng Liu, Lana L. Blaschke, Hoong Chen Teo, Niklas Boers* | **Main category: physics.geo-ph**

**Keywords:** 森林碳循环, 地上碳, 汇-源转变, 深度学习, 卫星观测

**Comment:** 

> **TL;DR:** 研究发现全球森林总体仍是碳汇，但湿润热带和北方森林已转变为碳源，且热带森林在陆地碳循环中的作用日益增强。

**AI_Comments:** 这项研究通过整合多源卫星数据和先进的深度学习模型，为长期、高分辨率的全球森林地上碳动态分析提供了可靠的方法，解决了现有观测不确定性问题。其创新之处在于能够同时估计AGC及其不确定性，并揭示了全球不同森林类型在过去三十年间复杂的汇-源转变。研究结果对于理解全球碳循环、评估气候变化影响以及指导森林管理和保护策略具有重要意义，尤其是在揭示热带森林未受影响区域碳损失增加方面具有警示作用。

<details>
  <summary>Details</summary>

**Motivation:** 森林地上碳（AGC）的长期动态及其汇-源转变存在高度不确定性，这主要是由于干扰机制的变化以及观测、数据处理和分析方法的不一致性。

**Method:** 通过整合多源卫星观测数据与概率深度学习模型，以高空间分辨率估算了1988年至2021年全球森林可靠、统一的地上碳储量和通量，并同时估计了AGC及其不确定性。

**Result:** 全球森林在30年间仍是6.2 PgC的AGC汇；湿润热带森林在2001年至2010年间转变为重要的AGC源，并与北方森林在2011-2021年间趋向源；温带、干旱热带和亚热带森林的AGC储量普遍增加，尽管欧洲和澳大利亚在2011年后成为源；过去三十年中，热带森林发生了显著的汇-源转变；全球大气CO2增长率与热带AGC通量变异性之间的年际关系变得越来越负相关，在最近十年达到Pearson's r = -0.63 (p < 0.05)；在巴西亚马逊地区，毁林区域对AGC损失的贡献从1989-2000年的60%下降到2011-2021年的13%，而未受影响区域的份额从33%增加到76%。

**Conclusion:** 研究结果表明热带森林地上碳在调节陆地碳循环变异性方面发挥着越来越重要的作用，人为气候变化可能越来越多地导致AGC变化，特别是在以前未受影响的区域。

> **ai_Abstract:** 本研究利用多源卫星观测和概率深度学习模型，以高空间分辨率揭示了1988-2021年全球森林地上碳（AGC）的动态及其汇-源转变。尽管全球森林总体保持碳汇，但湿润热带和北方森林已转变为碳源，而温带和部分热带森林仍在积累碳。研究强调了热带森林AGC在全球碳循环中的日益重要的调节作用，并指出人为气候变化可能加剧了未受影响区域的AGC变化。

> **摘要翻译:** 作为持久的碳汇，森林生态系统对陆地碳循环至关重要，并有助于减缓全球变暖。然而，由于干扰机制的变化以及观测、数据处理和分析方法的不一致性，森林中地上碳（AGC）的长期动态及其汇-源转变仍存在高度不确定性。本研究通过整合多源卫星观测数据与概率深度学习模型，以高空间分辨率估算了1988年至2021年全球森林可靠、统一的地上碳储量和通量。我们的方法同时估算了AGC及其相关不确定性，显示出在空间和时间上的高可靠性。我们发现，尽管全球森林在30年间仍是6.2 PgC的AGC汇，但湿润热带森林在2001年至2010年间转变为重要的AGC源，并与北方森林在2011-2021年间趋向源。温带、干旱热带和亚热带森林的AGC储量普遍增加，尽管欧洲和澳大利亚在2011年后成为源。在区域层面，过去三十年中热带森林发生了显著的汇-源转变。全球大气CO2增长率与热带AGC通量变异性之间的年际关系变得越来越负相关，在最近十年达到Pearson's r = -0.63 (p < 0.05)。在巴西亚马逊地区，毁林区域对AGC损失的贡献从1989-2000年的60%下降到2011-2021年的13%，而未受影响区域的份额从33%增加到76%。我们的研究结果表明热带森林地上碳在调节陆地碳循环变异性方面发挥着越来越重要的作用，人为气候变化可能越来越多地导致AGC变化，特别是在以前未受影响的区域。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [621] [Automated Treatment Planning for Interstitial HDR Brachytherapy for Locally Advanced Cervical Cancer using Deep Reinforcement Learning](https://arxiv.org/abs/2506.11957)
> *深度强化学习在局部晚期宫颈癌腔内高剂量率近距离放射治疗自动计划中的应用*

*Mohammadamin Moradi, Runyu Jiang, Yingzi Liu, Malvern Madondo, Tianming Wu, James J. Sohn, Xiaofeng Yang, Yasmin Hasan, Zhen Tian* | **Main category: physics.med-ph**

**Keywords:** 深度强化学习, 近距离放射治疗, 宫颈癌, 治疗计划, 自动化

**Comment:** 12 pages, 2 figures, 3 tables

> **TL;DR:** 本文提出了一种基于深度强化学习的自动化治疗计划框架，用于局部晚期宫颈癌的腔内高剂量率近距离放射治疗，旨在提高计划的一致性和效率。

**AI_Comments:** 这项研究通过将深度强化学习引入到复杂的放射治疗计划中，展示了显著的创新性。它解决了当前手动计划依赖专业知识、效率和一致性不足的问题。通过分层两阶段的方法，智能体学习了临床有意义的TPP调整，并在性能上超越了人工计划。其重要性在于能够提高治疗计划的自动化水平、质量和标准化，对临床实践具有潜在的积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 高剂量率（HDR）近距离放射治疗在局部晚期宫颈癌的治疗中至关重要，但其治疗计划高度依赖手动专业知识。本研究旨在开发一个全自动的HDR近距离放射治疗计划框架，以提高计划的一致性和效率。

**Method:** 提出了一个分层两阶段的自动计划框架。第一阶段，一个基于深度Q网络（DQN）的强化学习（RL）智能体迭代选择治疗计划参数（TPPs），以平衡靶区覆盖和危及器官（OAR）保护。智能体的状态表示包括剂量-体积直方图（DVH）指标和当前TPPs值，奖励函数整合了临床剂量目标和安全约束。第二阶段，一个定制的基于Adam的优化器使用临床知情的损失函数计算选定TPPs的相应停留时间分布。

**Result:** 该框架成功学习了在不同患者解剖结构下的临床有意义的TPPs调整。对于未见的测试患者，基于RL的自动化计划方法取得了93.89%的平均得分，优于平均91.86%的临床计划。这些分数提升是在保持靶区完全覆盖并减少大多数病例中CTV热点的情况下实现的。

**Conclusion:** 所提出的基于深度强化学习的自动化治疗计划框架能够生成临床可接受的计划，并在一致性和效率方面优于手动计划，同时保持靶区覆盖并减少热点。

> **ai_Abstract:** 本文提出了一种基于深度强化学习和剂量优化的两阶段自动化框架，用于局部晚期宫颈癌的腔内高剂量率近距离放射治疗计划。该框架利用DQN智能体选择治疗参数，并结合Adam优化器计算剂量分布。实验结果表明，该自动化方法在计划质量得分上优于临床计划，提高了治疗计划的一致性和效率，同时保持了靶区覆盖并减少了热点。

> **摘要翻译:** 高剂量率（HDR）近距离放射治疗在局部晚期宫颈癌的治疗中起着关键作用，但仍高度依赖于手动治疗计划专业知识。本研究的目的是开发一个完全自动化的HDR近距离放射治疗计划框架，该框架整合了强化学习（RL）和基于剂量的优化，以生成具有更高一致性和效率的临床可接受的治疗计划。我们提出了一个分层两阶段的自动计划框架。在第一阶段，一个基于深度Q网络（DQN）的强化学习（RL）智能体迭代选择治疗计划参数（TPPs），这些参数控制着靶区覆盖和危及器官（OAR）保护之间的权衡。智能体的状态表示包括剂量-体积直方图（DVH）指标和当前TPPs值，其奖励函数包含了临床剂量目标和安全约束，包括靶区的D90、V150、V200，以及所有相关危及器官（膀胱、直肠、乙状结肠、小肠和大肠）的D2cc。在第二阶段，一个定制的基于Adam的优化器使用临床知情的损失函数计算选定TPPs的相应停留时间分布。该框架在具有复杂施源器几何形状的患者队列中进行了评估。所提出的框架成功地学习了跨不同患者解剖结构的临床有意义的TPPs调整。对于未见的测试患者，基于RL的自动化计划方法取得了93.89%的平均得分，优于平均91.86%的临床计划。这些发现意义重大，因为在保持靶区完全覆盖并减少大多数病例中CTV热点的情况下，实现了分数提升。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ex'></a>
## hep-ex 

### [622] [Learning Before Filtering: Real-Time Hardware Learning at the Detector Level](https://arxiv.org/abs/2506.11981)
> *过滤前学习：探测器层面的实时硬件学习*

*Boštjan Maček* | **Main category: hep-ex**

**Keywords:** 实时学习, 硬件架构, 神经网络训练, 探测器, FPGA

**Comment:** 

> **TL;DR:** 本文提出了一种用于探测器层面实时神经网络训练的数字硬件架构，旨在解决传统过滤方法在动态数据下的局限性，并在FPGA上验证了其可行性与准确性。

**AI_Comments:** 该论文的创新点在于提出了一个能够在探测器层面进行实时神经网络训练的硬件架构，这对于处理海量实时数据具有重要意义。它克服了传统过滤方法的局限性，并通过硬件实现确保了效率和精度。概念验证在FPGA上展示了其可行性，并给出了具体的资源估算，为未来的极端边缘计算应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 随着传感器技术和自动化发展，数据量激增，实时识别和提取相关信息变得至关重要。传统依赖先验知识的过滤方法难以适应动态或不可预测的数据特征。机器学习提供了一个有吸引力的替代方案，尤其是在探测器处或附近进行训练。

**Method:** 本文提出了一种专为高吞吐量数据摄取而优化的数字硬件架构，用于实时神经网络训练。设计以独立于实现的方式描述，并详细分析了每个架构组件及其性能影响。通过系统参数化，研究探讨了处理速度、模型复杂性和硬件资源利用之间的权衡。在FPGA上进行了概念验证实现。

**Result:** 概念验证的FPGA实现在原位训练中保持了与传统软件方法相当的计算精度。资源估计表明，当前一代FPGA每芯片可训练大约3,500个神经元的网络。该架构具有可扩展性和适应性。

**Conclusion:** 该架构代表了将学习直接集成到探测器系统中的重大进步，并能够实现一类新型的极端边缘、实时信息处理。

> **ai_Abstract:** 本文提出了一种用于实时神经网络训练的数字硬件架构，旨在解决大数据时代传统过滤方法的局限性。该架构优化了高吞吐量数据处理，并进行了详细的组件分析和系统参数化，以探索性能权衡。FPGA上的概念验证实现证明了其在原位训练中保持了与软件相当的计算精度，并显示了在当前硬件上训练大规模网络的能力。这项工作为在探测器层面直接集成学习、实现极端边缘实时信息处理奠定了基础。

> **摘要翻译:** 传感器技术和自动化的进步开启了数据丰富的时代，其中实时识别和提取相关信息的能力变得越来越关键。依赖先验知识的传统过滤方法往往难以适应动态或不可预测的数据特征。机器学习提供了一个引人注目的替代方案——尤其是在训练可以直接在探测器处或附近进行时。本文提出了一种专为实时神经网络训练设计的数字硬件架构，该架构专门针对高吞吐量数据摄取进行了优化。该设计以独立于实现的方式进行描述，并详细分析了每个架构组件及其性能影响。通过系统参数化，该研究探讨了处理速度、模型复杂性和硬件资源利用之间的权衡。实际示例说明了这些参数如何影响各种用例的适用性。在FPGA上进行的概念验证实现展示了原位训练，证实了计算精度相对于传统基于软件的方法得到了保持。此外，资源估算表明，当前一代FPGA每芯片可以训练大约3,500个神经元的网络。该架构既可扩展又具适应性，代表着将学习直接集成到探测器系统中并实现一类新型极端边缘实时信息处理的重大进展。

</details>

[⬆️ 返回分类顶部](#hep-ex) | [⬆️ 返回总目录](#toc)

