<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 66]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data](https://arxiv.org/abs/2504.17039)
*Ruben Gonzalez Avilés,Linus Scheibenreif,Damian Borth*

Main category: cs.CV

TL;DR: 本文提出了一种新的密集估计技术，用于高效且可扩展地估算全球环境中的氮氧化物（NO$_2$）浓度，显著降低了计算资源需求并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有卫星空气质量估算方法在计算大范围区域时存在计算强度高的问题，本研究旨在解决这一局限性。

Method: 采用均匀随机偏移采样策略，将地面真实数据像素位置均匀分散到更大的区域，并在推理时一步生成密集估计网格。

Result: 新方法在平均绝对误差（MAE）上比现有点方法显著降低9.45%，达到4.98 μg/m³，兼具高精度和计算效率。

Conclusion: 该方法为大规模环境监测提供了可行的解决方案，展示了其适应性和鲁棒性。

Abstract: This paper addresses the critical environmental challenge of estimating
ambient Nitrogen Dioxide (NO$_2$) concentrations, a key issue in public health
and environmental policy. Existing methods for satellite-based air pollution
estimation model the relationship between satellite and in-situ measurements at
select point locations. While these approaches have advanced our ability to
provide air quality estimations on a global scale, they come with inherent
limitations. The most notable limitation is the computational intensity
required for generating comprehensive estimates over extensive areas. Motivated
by these limitations, this study introduces a novel dense estimation technique.
Our approach seeks to balance the accuracy of high-resolution estimates with
the practicality of computational constraints, thereby enabling efficient and
scalable global environmental assessment. By utilizing a uniformly random
offset sampling strategy, our method disperses the ground truth data pixel
location evenly across a larger patch. At inference, the dense estimation
method can then generate a grid of estimates in a single step, significantly
reducing the computational resources required to provide estimates for larger
areas. Notably, our approach also surpasses the results of existing point-wise
methods by a significant margin of $9.45\%$, achieving a Mean Absolute Error
(MAE) of $4.98\ \mu\text{g}/\text{m}^3$. This demonstrates both high accuracy
and computational efficiency, highlighting the applicability of our method for
global environmental assessment. Furthermore, we showcase the method's
adaptability and robustness by applying it to diverse geographic regions. Our
method offers a viable solution to the computational challenges of large-scale
environmental monitoring.

</details>


### [2] [DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs](https://arxiv.org/abs/2504.17040)
*Zhenhailong Wang,Senthil Purushwalkam,Caiming Xiong,Silvio Savarese,Heng Ji,Ran Xu*

Main category: cs.CV

TL;DR: DyMU是一个无需训练的高效框架，动态减少视觉语言模型的计算负担，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型中固定长度输出的低效问题，动态适应图像内容以减少计算成本。

Method: 结合动态令牌合并（DToMe）和虚拟令牌解合并（VTU），动态调整视觉令牌数量并模拟完整序列的注意力动态。

Result: 在图像和视频理解任务中，视觉令牌数量减少32%-85%，性能与完整模型相当。

Conclusion: DyMU提供了一种无需训练的动态令牌压缩方法，适用于多种视觉语言模型架构，并允许用户控制计算成本。

Abstract: We present DyMU, an efficient, training-free framework that dynamically
reduces the computational burden of vision-language models (VLMs) while
maintaining high task performance. Our approach comprises two key components.
First, Dynamic Token Merging (DToMe) reduces the number of visual token
embeddings by merging similar tokens based on image complexity, addressing the
inherent inefficiency of fixed-length outputs in vision transformers. Second,
Virtual Token Unmerging (VTU) simulates the expected token sequence for large
language models (LLMs) by efficiently reconstructing the attention dynamics of
a full sequence, thus preserving the downstream performance without additional
fine-tuning. Unlike previous approaches, our method dynamically adapts token
compression to the content of the image and operates completely training-free,
making it readily applicable to most state-of-the-art VLM architectures.
Extensive experiments on image and video understanding tasks demonstrate that
DyMU can reduce the average visual token count by 32%-85% while achieving
comparable performance to full-length models across diverse VLM architectures,
including the recently popularized AnyRes-based visual encoders. Furthermore,
through qualitative analyses, we demonstrate that DToMe effectively adapts
token reduction based on image complexity and, unlike existing systems,
provides users more control over computational costs. Project page:
https://mikewangwzhl.github.io/dymu/.

</details>


### [3] [PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation](https://arxiv.org/abs/2504.17067)
*Xinqi Xiong,Andrea Dunn Beltran,Jun Myeong Choi,Marc Niethammer,Roni Sengupta*

Main category: cs.CV

TL;DR: 提出了一种结合Stable Diffusion和ControlNet的图像翻译框架，利用Per-Pixel Shading (PPS) 图生成更真实的纹理，提升深度估计效果。


<details>
  <summary>Details</summary>
Motivation: 临床环境中获取真实深度数据困难，合成数据训练存在领域差距，需改进图像翻译方法以提升深度估计的泛化能力。

Method: 整合Stable Diffusion与ControlNet，以PPS图提取的潜在表示作为条件，保留结构并生成真实纹理。

Result: 实验表明，该方法比基于GAN的MI-CycleGAN生成更真实的图像，并提升了深度估计精度。

Conclusion: 提出的框架通过PPS图的结构约束，有效提升了图像翻译的真实性和深度估计性能。

Abstract: Accurate depth estimation enhances endoscopy navigation and diagnostics, but
obtaining ground-truth depth in clinical settings is challenging. Synthetic
datasets are often used for training, yet the domain gap limits generalization
to real data. We propose a novel image-to-image translation framework that
preserves structure while generating realistic textures from clinical data. Our
key innovation integrates Stable Diffusion with ControlNet, conditioned on a
latent representation extracted from a Per-Pixel Shading (PPS) map. PPS
captures surface lighting effects, providing a stronger structural constraint
than depth maps. Experiments show our approach produces more realistic
translations and improves depth estimation over GAN-based MI-CycleGAN. Our code
is publicly accessible at https://github.com/anaxqx/PPS-Ctrl.

</details>


### [4] [Distilling semantically aware orders for autoregressive image generation](https://arxiv.org/abs/2504.17069)
*Rishav Pramanik,Antoine Poupon,Juan A. Rodriguez,Masih Aminbeidokhti,David Vazquez,Christopher Pal,Zhaozheng Yin,Marco Pedersoli*

Main category: cs.CV

TL;DR: 论文提出了一种改进的自回归图像生成方法，通过训练模型以任意顺序生成图像块，并利用推断的顺序优化生成质量，优于传统的栅格扫描顺序。


<details>
  <summary>Details</summary>
Motivation: 传统的栅格扫描顺序（从左到右、从上到下）在图像生成中忽略了内容的因果关系，导致生成顺序不合理（如先云后太阳）。本文旨在解决这一问题。

Method: 1. 训练模型以任意顺序生成图像块；2. 推断生成顺序；3. 利用推断的顺序微调模型以提升图像质量。

Result: 实验表明，该方法在两个数据集上生成的图像质量优于传统栅格扫描顺序，且训练成本和额外标注需求相同。

Conclusion: 通过优化生成顺序，自回归图像生成模型可以更合理地反映图像内容的因果关系，从而提升生成质量。

Abstract: Autoregressive patch-based image generation has recently shown competitive
results in terms of image quality and scalability. It can also be easily
integrated and scaled within Vision-Language models. Nevertheless,
autoregressive models require a defined order for patch generation. While a
natural order based on the dictation of the words makes sense for text
generation, there is no inherent generation order that exists for image
generation. Traditionally, a raster-scan order (from top-left to bottom-right)
guides autoregressive image generation models. In this paper, we argue that
this order is suboptimal, as it fails to respect the causality of the image
content: for instance, when conditioned on a visual description of a sunset, an
autoregressive model may generate clouds before the sun, even though the color
of clouds should depend on the color of the sun and not the inverse. In this
work, we show that first by training a model to generate patches in
any-given-order, we can infer both the content and the location (order) of each
patch during generation. Secondly, we use these extracted orders to finetune
the any-given-order model to produce better-quality images. Through our
experiments, we show on two datasets that this new generation method produces
better images than the traditional raster-scan approach, with similar training
costs and no extra annotations.

</details>


### [5] [Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection](https://arxiv.org/abs/2504.17076)
*Jens Petersen,Davide Abati,Amirhossein Habibian,Auke Wiggers*

Main category: cs.CV

TL;DR: 论文提出了一种场景感知的概率位置模型，用于预测新物体在现有场景中的合理位置，并通过生成模型在这些位置填充物体，从而显著提升数据增强性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成图像模型在视觉任务中的数据增强中，通常忽视物体在场景中的合理布局，导致增强效果不佳。本文旨在通过优化布局增强，提升数据增强性能。

Method: 引入场景感知的概率位置模型，预测新物体在场景中的合理位置，并利用生成模型在这些位置填充物体。

Result: 在两项汽车目标检测任务中，实现了比现有方法更高的性能提升（+1.4 vs. +0.5 mAP），并在实例分割任务中展示了显著改进。

Conclusion: 通过优化布局增强，生成数据增强的性能显著提升，为视觉任务提供了更有效的数据增强方法。

Abstract: Generative image models are increasingly being used for training data
augmentation in vision tasks. In the context of automotive object detection,
methods usually focus on producing augmented frames that look as realistic as
possible, for example by replacing real objects with generated ones. Others try
to maximize the diversity of augmented frames, for example by pasting lots of
generated objects onto existing backgrounds. Both perspectives pay little
attention to the locations of objects in the scene. Frame layouts are either
reused with little or no modification, or they are random and disregard realism
entirely. In this work, we argue that optimal data augmentation should also
include realistic augmentation of layouts. We introduce a scene-aware
probabilistic location model that predicts where new objects can realistically
be placed in an existing scene. By then inpainting objects in these locations
with a generative model, we obtain much stronger augmentation performance than
existing approaches. We set a new state of the art for generative data
augmentation on two automotive object detection tasks, achieving up to
$2.8\times$ higher gains than the best competing approach ($+1.4$ vs. $+0.5$
mAP boost). We also demonstrate significant improvements for instance
segmentation.

</details>


### [6] [Transferring Spatial Filters via Tangent Space Alignment in Motor Imagery BCIs](https://arxiv.org/abs/2504.17111)
*Tekin Gunasar,Virginia de Sa*

Main category: cs.CV

TL;DR: 提出了一种通过黎曼流形对齐协方差矩阵并计算新的CSP空间滤波器的方法，以改进运动想象BCI中的主题迁移。


<details>
  <summary>Details</summary>
Motivation: 解决运动想象BCI中主题迁移性能不足的问题，尤其是在训练数据有限时。

Method: 在黎曼流形上对齐协方差矩阵，然后计算新的CSP空间滤波器，并探索多主题信息整合方式。

Result: 在三个数据集上表现略优于标准CSP，训练数据有限时改进更显著。

Conclusion: 该方法在数据有限时能显著提升性能，为BCI主题迁移提供了有效解决方案。

Abstract: We propose a method to improve subject transfer in motor imagery BCIs by
aligning covariance matrices on a Riemannian manifold, followed by computing a
new common spatial patterns (CSP) based spatial filter. We explore various ways
to integrate information from multiple subjects and show improved performance
compared to standard CSP. Across three datasets, our method shows marginal
improvements over standard CSP; however, when training data are limited, the
improvements become more significant.

</details>


### [7] [Latent Video Dataset Distillation](https://arxiv.org/abs/2504.17132)
*Ning Li,Antai Andy Liu,Jingran Zhang,Justin Cui*

Main category: cs.CV

TL;DR: 提出了一种新的视频数据集蒸馏方法，在潜在空间中操作，结合多样性感知数据选择和训练免费压缩技术，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集蒸馏方法主要在像素空间压缩，忽略了潜在空间的进展，本文旨在填补这一空白。

Method: 使用变分编码器在潜在空间进行蒸馏，采用多样性感知数据选择策略，并引入训练免费的压缩方法。

Result: 在HMDB51 IPC 1上性能提升2.6%，在MiniUCF IPC 5上提升7.8%，达到新SOTA。

Conclusion: 潜在空间操作和多样性选择策略显著提升了视频数据集蒸馏的性能。

Abstract: Dataset distillation has demonstrated remarkable effectiveness in
high-compression scenarios for image datasets. While video datasets inherently
contain greater redundancy, existing video dataset distillation methods
primarily focus on compression in the pixel space, overlooking advances in the
latent space that have been widely adopted in modern text-to-image and
text-to-video models. In this work, we bridge this gap by introducing a novel
video dataset distillation approach that operates in the latent space using a
state-of-the-art variational encoder. Furthermore, we employ a diversity-aware
data selection strategy to select both representative and diverse samples.
Additionally, we introduce a simple, training-free method to further compress
the distilled latent dataset. By combining these techniques, our approach
achieves a new state-of-the-art performance in dataset distillation,
outperforming prior methods on all datasets, e.g. on HMDB51 IPC 1, we achieve a
2.6% performance increase; on MiniUCF IPC 5, we achieve a 7.8% performance
increase.

</details>


### [8] [A Comprehensive Review on RNA Subcellular Localization Prediction](https://arxiv.org/abs/2504.17162)
*Cece Zhang,Xuehuan Zhu,Nick Peterson,Jieqiong Wang,Shibiao Wan*

Main category: cs.CV

TL;DR: 本文综述了基于AI/ML的RNA亚细胞定位预测方法的最新进展，涵盖多种RNA类型及不同方法，并讨论了其挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验室方法耗时耗力，AI/ML方法为RNA亚细胞定位提供了高效替代方案。

Method: 综述了基于序列、图像及混合方法的AI/ML技术。

Result: AI/ML方法能加速RNA研究，揭示分子通路，指导疾病治疗。

Conclusion: 本文为RNA亚细胞定位领域的研究者提供了宝贵资源，并指出了未来发展方向。

Abstract: The subcellular localization of RNAs, including long non-coding RNAs
(lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs,
plays a critical role in determining their biological functions. For instance,
lncRNAs are predominantly associated with chromatin and act as regulators of
gene transcription and chromatin structure, while mRNAs are distributed across
the nucleus and cytoplasm, facilitating the transport of genetic information
for protein synthesis. Understanding RNA localization sheds light on processes
like gene expression regulation with spatial and temporal precision. However,
traditional wet lab methods for determining RNA localization, such as in situ
hybridization, are often time-consuming, resource-demanding, and costly. To
overcome these challenges, computational methods leveraging artificial
intelligence (AI) and machine learning (ML) have emerged as powerful
alternatives, enabling large-scale prediction of RNA subcellular localization.
This paper provides a comprehensive review of the latest advancements in
AI-based approaches for RNA subcellular localization prediction, covering
various RNA types and focusing on sequence-based, image-based, and hybrid
methodologies that combine both data types. We highlight the potential of these
methods to accelerate RNA research, uncover molecular pathways, and guide
targeted disease treatments. Furthermore, we critically discuss the challenges
in AI/ML approaches for RNA subcellular localization, such as data scarcity and
lack of benchmarks, and opportunities to address them. This review aims to
serve as a valuable resource for researchers seeking to develop innovative
solutions in the field of RNA subcellular localization and beyond.

</details>


### [9] [PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition](https://arxiv.org/abs/2504.17163)
*Kai Cui,Jia Li,Yu Liu,Xuesong Zhang,Zhenzhen Hu,Meng Wang*

Main category: cs.CV

TL;DR: PhysioSync是一个新的预训练框架，利用时间和跨模态对比学习，通过EEG和PPS的动态同步提升情绪识别性能。


<details>
  <summary>Details</summary>
Motivation: EEG信号虽然能反映情绪状态，但存在噪声和个体差异问题，而现有的多模态方法忽略了模态间的动态同步和语义一致性。

Method: 提出PhysioSync框架，结合跨模态一致性对齐（CM-CA）和长短时时间对比学习（LS-TCL），捕捉模态间和时间分辨率上的情绪同步。

Result: 在DEAP和DREAMER数据集上，PhysioSync在单模态和跨模态条件下均表现出优越性能。

Conclusion: PhysioSync通过动态同步和对比学习，显著提升了EEG为中心的情绪识别效果。

Abstract: Electroencephalography (EEG) signals provide a promising and involuntary
reflection of brain activity related to emotional states, offering significant
advantages over behavioral cues like facial expressions. However, EEG signals
are often noisy, affected by artifacts, and vary across individuals,
complicating emotion recognition. While multimodal approaches have used
Peripheral Physiological Signals (PPS) like GSR to complement EEG, they often
overlook the dynamic synchronization and consistent semantics between the
modalities. Additionally, the temporal dynamics of emotional fluctuations
across different time resolutions in PPS remain underexplored. To address these
challenges, we propose PhysioSync, a novel pre-training framework leveraging
temporal and cross-modal contrastive learning, inspired by physiological
synchronization phenomena. PhysioSync incorporates Cross-Modal Consistency
Alignment (CM-CA) to model dynamic relationships between EEG and complementary
PPS, enabling emotion-related synchronizations across modalities. Besides, it
introduces Long- and Short-Term Temporal Contrastive Learning (LS-TCL) to
capture emotional synchronization at different temporal resolutions within
modalities. After pre-training, cross-resolution and cross-modal features are
hierarchically fused and fine-tuned to enhance emotion recognition. Experiments
on DEAP and DREAMER datasets demonstrate PhysioSync's advanced performance
under uni-modal and cross-modal conditions, highlighting its effectiveness for
EEG-centered emotion recognition.

</details>


### [10] [A Genealogy of Multi-Sensor Foundation Models in Remote Sensing](https://arxiv.org/abs/2504.17177)
*Kevin Lane,Morteza Karimzadeh*

Main category: cs.CV

TL;DR: 本文综述了遥感领域中基础模型的发展现状，探讨了其与计算机视觉方法的异同，并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析遥感领域中基础模型的现有方法及其优缺点，以推动该领域的进一步发展。

Method: 方法包括比较不同基础模型在遥感中的应用，并探讨如何减少计算资源需求。

Result: 结果表明，多传感器数据的利用和季节性数据的潜力尚未充分开发。

Conclusion: 结论指出，未来应更充分利用未标记和多传感器数据，以优化遥感基础模型。

Abstract: Foundation models have garnered increasing attention for representation
learning in remote sensing, primarily adopting approaches that have
demonstrated success in computer vision with minimal domain-specific
modification. However, the development and application of foundation models in
this field are still burgeoning, as there are a variety of competing approaches
that each come with significant benefits and drawbacks. This paper examines
these approaches along with their roots in the computer vision field in order
to characterize potential advantages and pitfalls while outlining future
directions to further improve remote sensing-specific foundation models. We
discuss the quality of the learned representations and methods to alleviate the
need for massive compute resources. We place emphasis on the multi-sensor
aspect of Earth observations, and the extent to which existing approaches
leverage multiple sensors in training foundation models in relation to
multi-modal foundation models. Finally, we identify opportunities for further
harnessing the vast amounts of unlabeled, seasonal, and multi-sensor remote
sensing observations.

</details>


### [11] [We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback](https://arxiv.org/abs/2504.17180)
*Minkyu Choi,S P Sharan,Harsh Goel,Sahil Shah,Sandeep Chinchali*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的零样本视频优化方法，通过神经符号反馈提升文本到视频生成的语义和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频（T2V）生成模型在处理复杂提示时难以保证语义和时间一致性，且计算成本高。

Method: 提出了一种神经符号反馈驱动的视频优化流程，通过分析视频表示并定位不一致事件和对象，指导针对性编辑。

Result: 实验表明，该方法显著提升了时间与逻辑对齐效果，改进幅度达40%。

Conclusion: 该方法为T2V生成提供了一种高效且无需训练的优化方案。

Abstract: Current text-to-video (T2V) generation models are increasingly popular due to
their ability to produce coherent videos from textual prompts. However, these
models often struggle to generate semantically and temporally consistent videos
when dealing with longer, more complex prompts involving multiple objects or
sequential events. Additionally, the high computational costs associated with
training or fine-tuning make direct improvements impractical. To overcome these
limitations, we introduce \(\projectname\), a novel zero-training video
refinement pipeline that leverages neuro-symbolic feedback to automatically
enhance video generation, achieving superior alignment with the prompts. Our
approach first derives the neuro-symbolic feedback by analyzing a formal video
representation and pinpoints semantically inconsistent events, objects, and
their corresponding frames. This feedback then guides targeted edits to the
original video. Extensive empirical evaluations on both open-source and
proprietary T2V models demonstrate that \(\projectname\) significantly enhances
temporal and logical alignment across diverse prompts by almost $40\%$.

</details>


### [12] [Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation](https://arxiv.org/abs/2504.17207)
*Phillip Y. Lee,Jihyeon Je,Chanho Park,Mikaela Angelina Uy,Leonidas Guibas,Minhyuk Sung*

Main category: cs.CV

TL;DR: 提出了一种基于心理意象模拟的视角感知推理框架（APC），用于提升视觉语言模型（VLM）的视角转换能力。


<details>
  <summary>Details</summary>
Motivation: 现代VLM在视角感知推理方面存在显著不足，且偏向自我中心解释，需要弥补与人类感知的差距。

Method: 通过抽象视角变换（APC）框架，利用视觉基础模型（如目标检测、分割和方向估计）构建场景抽象并实现视角转换。

Result: 在合成和真实图像基准测试中，APC显著提升了视角感知推理能力，优于微调的空间推理模型和新视角合成方法。

Conclusion: APC框架有效提升了VLM的视角感知能力，为环境交互和自主代理协作提供了更接近人类水平的视觉理解。

Abstract: We present a framework for perspective-aware reasoning in vision-language
models (VLMs) through mental imagery simulation. Perspective-taking, the
ability to perceive an environment or situation from an alternative viewpoint,
is a key benchmark for human-level visual understanding, essential for
environmental interaction and collaboration with autonomous agents. Despite
advancements in spatial reasoning within VLMs, recent research has shown that
modern VLMs significantly lack perspective-aware reasoning capabilities and
exhibit a strong bias toward egocentric interpretations. To bridge the gap
between VLMs and human perception, we focus on the role of mental imagery,
where humans perceive the world through abstracted representations that
facilitate perspective shifts. Motivated by this, we propose a framework for
perspective-aware reasoning, named Abstract Perspective Change (APC), that
effectively leverages vision foundation models, such as object detection,
segmentation, and orientation estimation, to construct scene abstractions and
enable perspective transformations. Our experiments on synthetic and real-image
benchmarks, compared with various VLMs, demonstrate significant improvements in
perspective-aware reasoning with our framework, further outperforming
fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.

</details>


### [13] [MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing](https://arxiv.org/abs/2504.17213)
*Shiwen Cao,Zhaoxing Zhang,Junming Jiao,Juyi Qiao,Guowen Song,Rong Shen*

Main category: cs.CV

TL;DR: MCAF是一种基于代理的无训练框架，通过多模态粗到细注意力聚焦实现视频理解，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 视频理解，尤其是长视频，信息冗余且复杂，需要全局注意力分配以提高准确性。

Method: MCAF通过多模态信息分层聚焦相关帧，并采用扩张时间扩展机制避免遗漏细节，结合自反馈机制迭代优化注意力。

Result: 在多个数据集上表现优异，如EgoSchema提升5%，Next-QA和IntentQA分别提升0.2%和0.3%，在长视频数据集Video-MME上也优于其他方法。

Conclusion: MCAF通过创新的注意力聚焦策略，显著提升了视频理解的准确性和效率。

Abstract: Even in the era of rapid advances in large models, video understanding,
particularly long videos, remains highly challenging. Compared with textual or
image-based information, videos commonly contain more information with
redundancy, requiring large models to strategically allocate attention at a
global level for accurate comprehension. To address this, we propose MCAF, an
agent-based, training-free framework perform video understanding through
Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its
ability to sense and prioritize segments of the video that are highly relevant
to the understanding task. First, MCAF hierarchically concentrates on highly
relevant frames through multimodal information, enhancing the correlation
between the acquired contextual information and the query. Second, it employs a
dilated temporal expansion mechanism to mitigate the risk of missing crucial
details when extracting information from these concentrated frames. In
addition, our framework incorporates a self-reflection mechanism utilizing the
confidence level of the model's responses as feedback. By iteratively applying
these two creative focusing strategies, it adaptively adjusts attention to
capture highly query-connected context and thus improves response accuracy.
MCAF outperforms comparable state-of-the-art methods on average. On the
EgoSchema dataset, it achieves a remarkable 5% performance gain over the
leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms
the current state-of-the-art standard by 0.2% and 0.3% respectively. On the
Video-MME dataset, which features videos averaging nearly an hour in length,
MCAF also outperforms other agent-based methods.

</details>


### [14] [Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion](https://arxiv.org/abs/2504.17223)
*Mengyu Qiao,Runze Tian,Yang Wang*

Main category: cs.CV

TL;DR: 提出了一种结合多尺度空间-频率分析的新型深度伪造检测框架，显著提升了检测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖空间域分析，未能充分利用频率域特征和空间-频率交互，导致对未见伪造的检测性能下降。

Method: 框架包含局部和全局频谱特征提取管道，以及多阶段跨模态融合机制，结合块状离散余弦变换和多尺度卷积。

Result: 在广泛采用的基准测试中，该方法在准确性和泛化性上优于现有技术。

Conclusion: 该框架通过多尺度空间-频率分析有效提升了深度伪造检测的性能。

Abstract: The rapid evolution of deep generative models poses a critical challenge to
deepfake detection, as detectors trained on forgery-specific artifacts often
suffer significant performance degradation when encountering unseen forgeries.
While existing methods predominantly rely on spatial domain analysis, frequency
domain operations are primarily limited to feature-level augmentation, leaving
frequency-native artifacts and spatial-frequency interactions insufficiently
exploited. To address this limitation, we propose a novel detection framework
that integrates multi-scale spatial-frequency analysis for universal deepfake
detection. Our framework comprises three key components: (1) a local spectral
feature extraction pipeline that combines block-wise discrete cosine transform
with cascaded multi-scale convolutions to capture subtle spectral artifacts;
(2) a global spectral feature extraction pipeline utilizing scale-invariant
differential accumulation to identify holistic forgery distribution patterns;
and (3) a multi-stage cross-modal fusion mechanism that incorporates
shallow-layer attention enhancement and deep-layer dynamic modulation to model
spatial-frequency interactions. Extensive evaluations on widely adopted
benchmarks demonstrate that our method outperforms state-of-the-art deepfake
detection methods in both accuracy and generalizability.

</details>


### [15] [Visual and textual prompts for enhancing emotion recognition in video](https://arxiv.org/abs/2504.17224)
*Zhifeng Wang,Qixuan Zhang,Peter Zhang,Wenjia Niu,Kaihao Zhang,Ramesh Sankaranarayana,Sabrina Caldwell,Tom Gedeon*

Main category: cs.CV

TL;DR: SoVTP框架通过整合空间标注、生理信号和上下文提示，提升VLLMs在视频情感识别中的零样本能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLLMs在视频情感识别中因空间和上下文意识不足而受限，传统方法忽视非语言线索。

Method: 提出SoVTP框架，结合空间标注、生理信号和上下文提示，形成统一提示策略。

Result: 实验显示SoVTP显著优于现有视觉提示方法，提升VLLMs的情感识别能力。

Conclusion: SoVTP通过多模态整合有效解决了视频情感识别中的局限性。

Abstract: Vision Large Language Models (VLLMs) exhibit promising potential for
multi-modal understanding, yet their application to video-based emotion
recognition remains limited by insufficient spatial and contextual awareness.
Traditional approaches, which prioritize isolated facial features, often
neglect critical non-verbal cues such as body language, environmental context,
and social interactions, leading to reduced robustness in real-world scenarios.
To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel
framework that enhances zero-shot emotion recognition by integrating spatial
annotations (e.g., bounding boxes, facial landmarks), physiological signals
(facial action units), and contextual cues (body posture, scene dynamics,
others' emotions) into a unified prompting strategy. SoVTP preserves holistic
scene information while enabling fine-grained analysis of facial muscle
movements and interpersonal dynamics. Extensive experiments show that SoVTP
achieves substantial improvements over existing visual prompting methods,
demonstrating its effectiveness in enhancing VLLMs' video emotion recognition
capabilities.

</details>


### [16] [Range Image-Based Implicit Neural Compression for LiDAR Point Clouds](https://arxiv.org/abs/2504.17229)
*Akihiro Kuwabara,Sorachi Kato,Takuya Fujihashi,Toshiaki Koike-Akino,Takashi Watanabe*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经表示（INR）的LiDAR点云压缩方法，通过深度和掩码图像的分块处理，显著提升了低比特率下的3D重建和检测质量。


<details>
  <summary>Details</summary>
Motivation: 传统图像压缩技术在处理LiDAR的2D范围图像（RIs）时效率有限，因为其与自然图像在比特精度和像素值分布上存在差异。

Method: 将RIs分为深度和掩码图像，分别采用分块和逐像素的INR架构，结合模型剪枝和量化进行压缩。

Result: 在KITTI数据集上，该方法在低比特率和解码延迟下，优于现有图像、点云、RI和INR压缩方法。

Conclusion: 该方法为高效压缩LiDAR点云提供了新思路，支持高精度3D场景存档。

Abstract: This paper presents a novel scheme to efficiently compress Light Detection
and Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives,
and such archives pave the way for a detailed understanding of the
corresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweight
format for representing 3D LiDAR observations. Although conventional image
compression techniques can be adapted to improve compression efficiency for
RIs, their practical performance is expected to be limited due to differences
in bit precision and the distinct pixel value distribution characteristics
between natural images and RIs. We propose a novel implicit neural
representation~(INR)--based RI compression method that effectively handles
floating-point valued pixels. The proposed method divides RIs into depth and
mask images and compresses them using patch-wise and pixel-wise INR
architectures with model pruning and quantization, respectively. Experiments on
the KITTI dataset show that the proposed method outperforms existing image,
point cloud, RI, and INR-based compression methods in terms of 3D
reconstruction and detection quality at low bitrates and decoding latency.

</details>


### [17] [Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment](https://arxiv.org/abs/2504.17234)
*Zhiqiang Lao,Heather Yu*

Main category: cs.CV

TL;DR: 提出一种结合深度学习与传统IQA方法的新型图像质量评估模型，通过分离高、低层次特征并整合，更贴近人类视觉感知。


<details>
  <summary>Details</summary>
Motivation: 随着AI和智能手机的普及，图像数据激增，传统IQA方法难以评估DNN处理的图像质量，需更贴近人类感知的评估方法。

Method: 模型将深度特征分解为高层次语义和低层次感知细节，结合传统IQA指标，通过MLP生成质量评分。

Result: 实验表明，该方法比现有IQA模型更符合人类视觉判断。

Conclusion: 新方法通过整合多层次特征，显著提升了图像质量评估的准确性。

Abstract: The rapid advancement of artificial intelligence and widespread use of
smartphones have resulted in an exponential growth of image data, both real
(camera-captured) and virtual (AI-generated). This surge underscores the
critical need for robust image quality assessment (IQA) methods that accurately
reflect human visual perception. Traditional IQA techniques primarily rely on
spatial features - such as signal-to-noise ratio, local structural distortions,
and texture inconsistencies - to identify artifacts. While effective for
unprocessed or conventionally altered images, these methods fall short in the
context of modern image post-processing powered by deep neural networks (DNNs).
The rise of DNN-based models for image generation, enhancement, and restoration
has significantly improved visual quality, yet made accurate assessment
increasingly complex. To address this, we propose a novel IQA approach that
bridges the gap between deep learning methods and human perception. Our model
disentangles deep features into high-level semantic information and low-level
perceptual details, treating each stream separately. These features are then
combined with conventional IQA metrics to provide a more comprehensive
evaluation framework. This hybrid design enables the model to assess both
global context and intricate image details, better reflecting the human visual
process, which first interprets overall structure before attending to
fine-grained elements. The final stage employs a multilayer perceptron (MLP) to
map the integrated features into a concise quality score. Experimental results
demonstrate that our method achieves improved consistency with human perceptual
judgments compared to existing IQA models.

</details>


### [18] [DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks](https://arxiv.org/abs/2504.17253)
*Yinqi Li,Hong Chang,Ruibing Hou,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种利用预训练扩散模型进行判别性任务（如目标检测）的方法，通过反转布局到图像的扩散模型，并结合梯度优化和先验分布模型，性能与基础判别性基线相当，且速度更快。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用预训练的生成扩散模型执行判别性任务，扩展其从分类到更复杂的目标检测任务的能力。

Method: 提出梯度离散优化方法替代繁重的预测枚举过程，并设计先验分布模型以更准确地应用贝叶斯规则。

Result: 在COCO数据集上，性能与基础判别性目标检测基线相当，同时显著加速了基于扩散的分类方法。

Conclusion: 该方法展示了预训练扩散模型在判别性任务中的潜力，且效率更高。

Abstract: Diffusion models have shown remarkable progress in various generative tasks
such as image and video generation. This paper studies the problem of
leveraging pretrained diffusion models for performing discriminative tasks.
Specifically, we extend the discriminative capability of pretrained frozen
generative diffusion models from the classification task to the more complex
object detection task, by "inverting" a pretrained layout-to-image diffusion
model. To this end, a gradient-based discrete optimization approach for
replacing the heavy prediction enumeration process, and a prior distribution
model for making more accurate use of the Bayes' rule, are proposed
respectively. Empirical results show that this method is on par with basic
discriminative object detection baselines on COCO dataset. In addition, our
method can greatly speed up the previous diffusion-based method for
classification without sacrificing accuracy. Code and models are available at
https://github.com/LiYinqi/DIVE .

</details>


### [19] [Precision Neural Network Quantization via Learnable Adaptive Modules](https://arxiv.org/abs/2504.17263)
*Wenqiang Zhou,Zhendong Yu,Xinyu Liu,Jiaming Yang,Rong Xiao,Tao Wang,Chenwei Tang,Jiancheng Lv*

Main category: cs.CV

TL;DR: ASQ是一种自适应神经网络量化方法，通过动态调整量化参数和非均匀量化方案，显著提升量化模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统QAT中量化参数固定导致激活值分布差异大时的性能下降问题。

Method: 提出ASQ方法，动态调整量化缩放因子，并采用POST非均匀量化方案处理权重分布。

Result: ASQ在4位量化ResNet34上比全精度基线提升1.2%准确率，优于现有QAT方法。

Conclusion: ASQ通过自适应量化参数和非均匀量化，有效平衡了模型性能与计算效率。

Abstract: Quantization Aware Training (QAT) is a neural network quantization technique
that compresses model size and improves operational efficiency while
effectively maintaining model performance. The paradigm of QAT is to introduce
fake quantization operators during the training process, allowing the model to
autonomously compensate for information loss caused by quantization. Making
quantization parameters trainable can significantly improve the performance of
QAT, but at the cost of compromising the flexibility during inference,
especially when dealing with activation values with substantially different
distributions. In this paper, we propose an effective learnable adaptive neural
network quantization method, called Adaptive Step Size Quantization (ASQ), to
resolve this conflict. Specifically, the proposed ASQ method first dynamically
adjusts quantization scaling factors through a trained module capable of
accommodating different activations. Then, to address the rigid resolution
issue inherent in Power of Two (POT) quantization, we propose an efficient
non-uniform quantization scheme. We utilize the Power Of Square root of Two
(POST) as the basis for exponential quantization, effectively handling the
bell-shaped distribution of neural network weights across various bit-widths
while maintaining computational efficiency through a Look-Up Table method
(LUT). Extensive experimental results demonstrate that the proposed ASQ method
is superior to the state-of-the-art QAT approaches. Notably that the ASQ is
even competitive compared to full precision baselines, with its 4-bit quantized
ResNet34 model improving accuracy by 1.2\% on ImageNet.

</details>


### [20] [Towards Generalized and Training-Free Text-Guided Semantic Manipulation](https://arxiv.org/abs/2504.17269)
*Yu Hong,Xiao Cai,Pengpeng Zeng,Shuai Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种名为GTF的新方法，用于文本引导的语义图像编辑，支持多种语义操作且无需训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法效率低、扩展性差且通用性有限，而扩散模型中噪声的几何特性与语义变化强相关。

Method: 通过控制噪声的几何关系实现语义编辑，支持多种操作且无需调优。

Result: 实验证明GTF能高效生成高保真结果，支持多种语义操作。

Conclusion: GTF在语义编辑领域具有潜力，可推动技术发展。

Abstract: Text-guided semantic manipulation refers to semantically editing an image
generated from a source prompt to match a target prompt, enabling the desired
semantic changes (e.g., addition, removal, and style transfer) while preserving
irrelevant contents. With the powerful generative capabilities of the diffusion
model, the task has shown the potential to generate high-fidelity visual
content. Nevertheless, existing methods either typically require time-consuming
fine-tuning (inefficient), fail to accomplish multiple semantic manipulations
(poorly extensible), and/or lack support for different modality tasks (limited
generalizability). Upon further investigation, we find that the geometric
properties of noises in the diffusion model are strongly correlated with the
semantic changes. Motivated by this, we propose a novel $\textit{GTF}$ for
text-guided semantic manipulation, which has the following attractive
capabilities: 1) $\textbf{Generalized}$: our $\textit{GTF}$ supports multiple
semantic manipulations (e.g., addition, removal, and style transfer) and can be
seamlessly integrated into all diffusion-based methods (i.e., Plug-and-play)
across different modalities (i.e., modality-agnostic); and 2)
$\textbf{Training-free}$: $\textit{GTF}$ produces high-fidelity results via
simply controlling the geometric relationship between noises without tuning or
optimization. Our extensive experiments demonstrate the efficacy of our
approach, highlighting its potential to advance the state-of-the-art in
semantics manipulation.

</details>


### [21] [EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy](https://arxiv.org/abs/2504.17280)
*Haodi Yao,Fenghua He,Ning Hao,Chen Xie*

Main category: cs.CV

TL;DR: EdgePoint2是一种轻量级关键点检测和描述神经网络，专为边缘计算设计，通过优化架构和训练方法，在保持高精度的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在关键点提取中表现优异，但计算成本高且高维描述符不适用于分布式应用，因此需要紧凑且高效的解决方案。

Method: 采用优化的网络架构，结合正交Procrustes损失和相似性损失训练紧凑描述符，并提供14个子模型以满足多样化需求。

Result: 实验显示EdgePoint2在多种场景下均达到SOTA精度和效率，且使用低维描述符（32/48/64）。

Conclusion: EdgePoint2在灵活性、鲁棒性和多功能性方面表现突出，是适应多样化计算和通信限制的理想选择。

Abstract: The field of keypoint extraction, which is essential for vision applications
like Structure from Motion (SfM) and Simultaneous Localization and Mapping
(SLAM), has evolved from relying on handcrafted methods to leveraging deep
learning techniques. While deep learning approaches have significantly improved
performance, they often incur substantial computational costs, limiting their
deployment in real-time edge applications. Efforts to create lightweight neural
networks have seen some success, yet they often result in trade-offs between
efficiency and accuracy. Additionally, the high-dimensional descriptors
generated by these networks poses challenges for distributed applications
requiring efficient communication and coordination, highlighting the need for
compact yet competitively accurate descriptors. In this paper, we present
EdgePoint2, a series of lightweight keypoint detection and description neural
networks specifically tailored for edge computing applications on embedded
system. The network architecture is optimized for efficiency without
sacrificing accuracy. To train compact descriptors, we introduce a combination
of Orthogonal Procrustes loss and similarity loss, which can serve as a general
approach for hypersphere embedding distillation tasks. Additionally, we offer
14 sub-models to satisfy diverse application requirements. Our experiments
demonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA)
accuracy and efficiency across various challenging scenarios while employing
lower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2
offers significant advantages in flexibility, robustness, and versatility.
Consequently, EdgePoint2 emerges as a highly competitive option for visual
tasks, especially in contexts demanding adaptability to diverse computational
and communication constraints.

</details>


### [22] [Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+](https://arxiv.org/abs/2504.17306)
*Meher Boulaabi,Takwa Ben Aïcha Gader,Afef Kacem Echi,Sameh Mbarek*

Main category: cs.CV

TL;DR: 提出了一种针对糖尿病视网膜病变病灶的二元分割方法，通过结合多个病灶类型的模型输出，优化参数并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决数据集限制和标注复杂性带来的挑战，提升病灶分割的精确度。

Method: 采用DeepLabv3+模型，结合特定预处理（裁剪和CLAHE）及数据增强技术。

Result: 分割准确率达到99%，验证了方法的有效性。

Conclusion: 创新策略在医学图像分析中具有显著效果，特别是在糖尿病视网膜病变病灶的精确分割上。

Abstract: To improve the segmentation of diabetic retinopathy lesions (microaneurysms,
hemorrhages, exudates, and soft exudates), we implemented a binary segmentation
method specific to each type of lesion. As post-segmentation, we combined the
individual model outputs into a single image to better analyze the lesion
types. This approach facilitated parameter optimization and improved accuracy,
effectively overcoming challenges related to dataset limitations and annotation
complexity. Specific preprocessing steps included cropping and applying
contrast-limited adaptive histogram equalization to the L channel of the LAB
image. Additionally, we employed targeted data augmentation techniques to
further refine the model's efficacy. Our methodology utilized the DeepLabv3+
model, achieving a segmentation accuracy of 99%. These findings highlight the
efficacy of innovative strategies in advancing medical image analysis,
particularly in the precise segmentation of diabetic retinopathy lesions. The
IDRID dataset was utilized to validate and demonstrate the robustness of our
approach.

</details>


### [23] [DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model](https://arxiv.org/abs/2504.17315)
*Zhanglin Wu,Tengfei Song,Ning Xie,Weidong Zhang,Pengfei Li,Shuang Wu,Chong Li,Junhao Zhu,Hao Yang*

Main category: cs.CV

TL;DR: 华为翻译服务中心提出了一种基于开源大视觉语言模型的端到端文档图像翻译解决方案，结合多任务学习和感知链式思维，支持OCR和无OCR任务。


<details>
  <summary>Details</summary>
Motivation: 解决复杂布局文档图像的端到端机器翻译问题，提升翻译系统的能力。

Method: 采用多任务学习和感知链式思维的训练框架，结合最小贝叶斯解码和后处理策略。

Result: 展示了有效的文档图像机器翻译方法，支持统一框架下的OCR和无OCR任务。

Conclusion: 该方案为复杂布局文档图像翻译提供了系统化的解决方案。

Abstract: This paper presents the technical solution proposed by Huawei Translation
Service Center (HW-TSC) for the "End-to-End Document Image Machine Translation
for Complex Layouts" competition at the 19th International Conference on
Document Analysis and Recognition (DIMT25@ICDAR2025). Leveraging
state-of-the-art open-source large vision-language model (LVLM), we introduce a
training framework that combines multi-task learning with perceptual
chain-of-thought to develop a comprehensive end-to-end document translation
system. During the inference phase, we apply minimum Bayesian decoding and
post-processing strategies to further enhance the system's translation
capabilities. Our solution uniquely addresses both OCR-based and OCR-free
document image translation tasks within a unified framework. This paper
systematically details the training methods, inference strategies, LVLM base
models, training data, experimental setups, and results, demonstrating an
effective approach to document image machine translation.

</details>


### [24] [TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos](https://arxiv.org/abs/2504.17343)
*Linli Yao,Yicheng Li,Yuancheng Wei,Lei Li,Shuhuai Ren,Yuanxin Liu,Kun Ouyang,Lean Wang,Shicheng Li,Sida Li,Lingpeng Kong,Qi Liu,Yuanxing Zhang,Xu Sun*

Main category: cs.CV

TL;DR: TimeChat-Online是一种新型在线视频大语言模型，通过创新的差分令牌丢弃（DTD）模块高效处理实时视频流，减少冗余帧，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 在线视频平台的快速增长需要实时视频理解系统，但现有视频大语言模型在流媒体场景中因无法高效处理冗余帧而受限。

Method: 提出DTD模块，受人类视觉感知启发，保留有意义的时间变化，过滤静态冗余内容。

Result: 实验显示DTD减少82.8%的视频令牌，同时保持98%的性能，表明流媒体视频中80%以上内容冗余。

Conclusion: TimeChat-Online在流媒体基准测试中表现优异，并在长视频任务中保持竞争力。

Abstract: The rapid growth of online video platforms, particularly live streaming
services, has created an urgent need for real-time video understanding systems.
These systems must process continuous video streams and respond to user queries
instantaneously, presenting unique challenges for current Video Large Language
Models (VideoLLMs). While existing VideoLLMs excel at processing complete
videos, they face significant limitations in streaming scenarios due to their
inability to handle dense, redundant frames efficiently. We introduce
TimeChat-Online, a novel online VideoLLM that revolutionizes real-time video
interaction. At its core lies our innovative Differential Token Drop (DTD)
module, which addresses the fundamental challenge of visual redundancy in
streaming videos. Drawing inspiration from human visual perception's Change
Blindness phenomenon, DTD preserves meaningful temporal changes while filtering
out static, redundant content between frames. Remarkably, our experiments
demonstrate that DTD achieves an 82.8% reduction in video tokens while
maintaining 98% performance on StreamingBench, revealing that over 80% of
visual content in streaming videos is naturally redundant without requiring
language guidance. To enable seamless real-time interaction, we present
TimeChat-Online-139K, a comprehensive streaming video dataset featuring diverse
interaction patterns including backward-tracing, current-perception, and
future-responding scenarios. TimeChat-Online's unique Proactive Response
capability, naturally achieved through continuous monitoring of video scene
transitions via DTD, sets it apart from conventional approaches. Our extensive
evaluation demonstrates TimeChat-Online's superior performance on streaming
benchmarks (StreamingBench and OvOBench) and maintaining competitive results on
long-form video tasks such as Video-MME and MLVU.

</details>


### [25] [DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition](https://arxiv.org/abs/2504.17349)
*Yiyan Xu,Wuqiang Zheng,Wenjie Wang,Fengbin Zhu,Xinting Hu,Yang Zhang,Fuli Feng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: DRC框架通过解耦表示组合提升个性化图像生成，解决了现有方法在风格和语义意图融合上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以准确捕捉和融合用户的风格偏好与语义意图，尤其是LMM方法存在视觉特征纠缠问题。

Method: DRC采用解耦表示组合，分两阶段学习：解耦学习和个性化建模，分别分离风格与语义特征并优化生成。

Result: 实验表明DRC在性能上具有竞争力，有效缓解了指导崩溃问题。

Conclusion: 解耦表示学习对可控且有效的个性化图像生成至关重要。

Abstract: Personalized image generation has emerged as a promising direction in
multimodal content creation. It aims to synthesize images tailored to
individual style preferences (e.g., color schemes, character appearances,
layout) and semantic intentions (e.g., emotion, action, scene contexts) by
leveraging user-interacted history images and multimodal instructions. Despite
notable progress, existing methods -- whether based on diffusion models, large
language models, or Large Multimodal Models (LMMs) -- struggle to accurately
capture and fuse user style preferences and semantic intentions. In particular,
the state-of-the-art LMM-based method suffers from the entanglement of visual
features, leading to Guidance Collapse, where the generated images fail to
preserve user-preferred styles or reflect the specified semantics.
  To address these limitations, we introduce DRC, a novel personalized image
generation framework that enhances LMMs through Disentangled Representation
Composition. DRC explicitly extracts user style preferences and semantic
intentions from history images and the reference image, respectively, to form
user-specific latent instructions that guide image generation within LMMs.
Specifically, it involves two critical learning stages: 1) Disentanglement
learning, which employs a dual-tower disentangler to explicitly separate style
and semantic features, optimized via a reconstruction-driven paradigm with
difficulty-aware importance sampling; and 2) Personalized modeling, which
applies semantic-preserving augmentations to effectively adapt the disentangled
representations for robust personalized generation. Extensive experiments on
two benchmarks demonstrate that DRC shows competitive performance while
effectively mitigating the guidance collapse issue, underscoring the importance
of disentangled representation learning for controllable and effective
personalized image generation.

</details>


### [26] [I-INR: Iterative Implicit Neural Representations](https://arxiv.org/abs/2504.17364)
*Ali Haider,Muhammad Salman Ali,Maryam Qamar,Tahir Khalil,Soo Ye Kim,Jihyong Oh,Enzo Tartaglione,Sung-Ho Bae*

Main category: cs.CV

TL;DR: 提出了一种名为I-INRs的迭代隐式神经表示框架，通过迭代细化提升信号重建质量，解决了传统INRs在细节保留和高频信息处理上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统隐式神经表示（INRs）因回归问题的固有特性，容易回归均值，难以捕捉细节和高频信息，且对噪声敏感。

Method: 提出I-INRs框架，通过迭代细化过程增强信号重建，兼容现有INRs架构。

Result: 实验表明，I-INRs在图像恢复、去噪和物体占据预测等任务中优于基线方法（如WIRE、SIREN和Gauss）。

Conclusion: I-INRs显著提升了信号重建质量，具有广泛的应用潜力。

Abstract: Implicit Neural Representations (INRs) have revolutionized signal processing
and computer vision by modeling signals as continuous, differentiable functions
parameterized by neural networks. However, their inherent formulation as a
regression problem makes them prone to regression to the mean, limiting their
ability to capture fine details, retain high-frequency information, and handle
noise effectively. To address these challenges, we propose Iterative Implicit
Neural Representations (I-INRs) a novel plug-and-play framework that enhances
signal reconstruction through an iterative refinement process. I-INRs
effectively recover high-frequency details, improve robustness to noise, and
achieve superior reconstruction quality. Our framework seamlessly integrates
with existing INR architectures, delivering substantial performance gains
across various tasks. Extensive experiments show that I-INRs outperform
baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision
applications such as image restoration, image denoising, and object occupancy
prediction.

</details>


### [27] [TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation](https://arxiv.org/abs/2504.17365)
*Ling You,Wenxuan Huang,Xinni Xie,Xiangyi Wei,Bangyan Li,Shaohui Lin,Yang Li,Changbo Wang*

Main category: cs.CV

TL;DR: TimeSoccer是首个端到端的足球MLLM，用于全场比赛视频的单锚点密集视频字幕生成（SDVC），通过联合预测时间戳和生成字幕，实现了全局上下文建模。


<details>
  <summary>Details</summary>
Motivation: 现有足球MLLM依赖时间先验生成字幕，无法端到端处理视频；传统方法复杂且无法捕捉全局上下文。TimeSoccer旨在解决这些问题。

Method: 提出TimeSoccer，结合MoFA-Select（训练无关的运动感知帧压缩模块）和互补训练范式，支持长视频理解。

Result: TimeSoccer在SDVC任务上达到最先进性能，生成高质量评论，时间对齐准确且语义相关性强。

Conclusion: TimeSoccer为足球视频的端到端字幕生成提供了高效解决方案，显著提升了性能。

Abstract: Soccer is a globally popular sporting event, typically characterized by long
matches and distinctive highlight moments. Recent advances in Multimodal Large
Language Models (MLLMs) offer promising capabilities in temporal grounding and
video understanding, soccer commentary generation often requires precise
temporal localization and semantically rich descriptions over long-form video.
However, existing soccer MLLMs often rely on the temporal a priori for caption
generation, so they cannot process the soccer video end-to-end. While some
traditional approaches follow a two-step paradigm that is complex and fails to
capture the global context to achieve suboptimal performance. To solve the
above issues, we present TimeSoccer, the first end-to-end soccer MLLM for
Single-anchor Dense Video Captioning (SDVC) in full-match soccer videos.
TimeSoccer jointly predicts timestamps and generates captions in a single pass,
enabling global context modeling across 45-minute matches. To support long
video understanding of soccer matches, we introduce MoFA-Select, a
training-free, motion-aware frame compression module that adaptively selects
representative frames via a coarse-to-fine strategy, and incorporates
complementary training paradigms to strengthen the model's ability to handle
long temporal sequences. Extensive experiments demonstrate that our TimeSoccer
achieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end
form, generating high-quality commentary with accurate temporal alignment and
strong semantic relevance.

</details>


### [28] [Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset](https://arxiv.org/abs/2504.17371)
*Oussema Dhaouadi,Johannes Meier,Luca Wahl,Jacques Kaiser,Luca Scalerandi,Nick Wandelburg,Zhuolun Zhou,Nijanthan Berinpanathan,Holger Banzhaf,Daniel Cremers*

Main category: cs.CV

TL;DR: DSC3D是一个高质量、无遮挡的3D轨迹数据集，通过无人机捕捉，覆盖多样场景，旨在提升自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 传统数据集因固定传感器和遮挡问题受限，无法全面捕捉动态环境。

Method: 采用单目相机无人机追踪管道，采集14类交通参与者的175,000多条轨迹。

Result: 数据集在多样性和规模上超越现有数据集，包含复杂场景如高密度城市街道交互。

Conclusion: DSC3D通过详细3D环境表征提升自动驾驶系统，支持多项应用研究，数据公开可用。

Abstract: Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,
traditional datasets are usually captured by fixed sensors mounted on a car and
are susceptible to occlusion. Additionally, such an approach can precisely
reconstruct the dynamic environment in the close vicinity of the measurement
vehicle only, while neglecting objects that are further away. In this paper, we
introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,
occlusion-free dataset of 6 degrees of freedom bounding box trajectories
acquired through a novel monocular camera drone tracking pipeline. Our dataset
includes more than 175,000 trajectories of 14 types of traffic participants and
significantly exceeds existing datasets in terms of diversity and scale,
containing many unprecedented scenarios such as complex vehicle-pedestrian
interaction on highly populated urban streets and comprehensive parking
maneuvers from entry to exit. DSC3D dataset was captured in five various
locations in Europe and the United States and include: a parking lot, a crowded
inner-city, a steep urban intersection, a federal highway, and a suburban
intersection. Our 3D trajectory dataset aims to enhance autonomous driving
systems by providing detailed environmental 3D representations, which could
lead to improved obstacle interactions and safety. We demonstrate its utility
across multiple applications including motion prediction, motion planning,
scenario mining, and generative reactive traffic agents. Our interactive online
visualization platform and the complete dataset are publicly available at
app.deepscenario.com, facilitating research in motion prediction, behavior
modeling, and safety validation.

</details>


### [29] [SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting](https://arxiv.org/abs/2504.17395)
*Yiming Zhao,Guorong Li,Laiyun Qing,Amin Beheshti,Jian Yang,Michael Sheng,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: 论文提出了一种名为SDVPT的框架，通过两阶段视觉提示学习策略提升预训练视觉语言模型在开放世界物体计数任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练时仅关注文本-图像一致性，导致对未见类别的泛化能力有限。

Method: SDVPT框架包含类别特定提示初始化（CSPI）和拓扑引导提示细化（TGPR）两阶段策略，动态合成未见类别的视觉提示。

Result: 实验表明，SDVPT在FSC-147、CARPK和PUCPR+数据集上均表现出色。

Conclusion: SDVPT通过语义驱动的视觉提示调优，显著提升了开放世界物体计数的泛化能力。

Abstract: Open-world object counting leverages the robust text-image alignment of
pre-trained vision-language models (VLMs) to enable counting of arbitrary
categories in images specified by textual queries. However, widely adopted
naive fine-tuning strategies concentrate exclusively on text-image consistency
for categories contained in training, which leads to limited generalizability
for unseen categories. In this work, we propose a plug-and-play Semantic-Driven
Visual Prompt Tuning framework (SDVPT) that transfers knowledge from the
training set to unseen categories with minimal overhead in parameters and
inference time. First, we introduce a two-stage visual prompt learning strategy
composed of Category-Specific Prompt Initialization (CSPI) and Topology-Guided
Prompt Refinement (TGPR). The CSPI generates category-specific visual prompts,
and then TGPR distills latent structural patterns from the VLM's text encoder
to refine these prompts. During inference, we dynamically synthesize the visual
prompts for unseen categories based on the semantic correlation between unseen
and training categories, facilitating robust text-image alignment for unseen
categories. Extensive experiments integrating SDVPT with all available
open-world object counting models demonstrate its effectiveness and
adaptability across three widely used datasets: FSC-147, CARPK, and PUCPR+.

</details>


### [30] [Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models](https://arxiv.org/abs/2504.17397)
*Francesc Marti-Escofet,Benedikt Blumenstiel,Linus Scheibenreif,Paolo Fraccaro,Konrad Schindler*

Main category: cs.CV

TL;DR: 本文探讨了参数高效微调（PEFT）技术在地球观测（EO）领域的应用，通过实验验证其在减少计算资源需求的同时保持或超越传统微调性能的能力。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型规模的增大，传统微调方法面临计算资源消耗大、成本高的问题，且可能导致预训练特征遗忘和泛化能力下降。PEFT技术为解决这些问题提供了可能。

Method: 通过多种基础模型架构和PEFT技术在五个不同EO数据集上进行实验，评估其有效性，并探讨架构选择（如解码器类型和元数据使用）的影响。

Result: 实验表明，PEFT技术不仅匹配甚至超越传统微调性能，还能增强模型对未见地理区域的泛化能力，同时减少训练时间和内存需求。UNet解码器和不使用元数据的配置表现最佳。

Conclusion: PEFT技术为EO领域提供了一种高效、可扩展的模型微调方案，相关模型和技术已集成到开源工具TerraTorch中，支持快速、低成本的模型适配。

Abstract: Earth observation (EO) is crucial for monitoring environmental changes,
responding to disasters, and managing natural resources. In this context,
foundation models facilitate remote sensing image analysis to retrieve relevant
geoinformation accurately and efficiently. However, as these models grow in
size, fine-tuning becomes increasingly challenging due to the associated
computational resources and costs, limiting their accessibility and
scalability. Furthermore, full fine-tuning can lead to forgetting pre-trained
features and even degrade model generalization. To address this,
Parameter-Efficient Fine-Tuning (PEFT) techniques offer a promising solution.
In this paper, we conduct extensive experiments with various foundation model
architectures and PEFT techniques to evaluate their effectiveness on five
different EO datasets. Our results provide a comprehensive comparison, offering
insights into when and how PEFT methods support the adaptation of pre-trained
geospatial models. We demonstrate that PEFT techniques match or even exceed
full fine-tuning performance and enhance model generalisation to unseen
geographic regions, while reducing training time and memory requirements.
Additional experiments investigate the effect of architecture choices such as
the decoder type or the use of metadata, suggesting UNet decoders and
fine-tuning without metadata as the recommended configuration. We have
integrated all evaluated foundation models and techniques into the open-source
package TerraTorch to support quick, scalable, and cost-effective model
adaptation.

</details>


### [31] [S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception](https://arxiv.org/abs/2504.17399)
*Sven Teufel,Jörg Gamerdinger,Oliver Bringmann*

Main category: cs.CV

TL;DR: 该论文提出了一种名为S2S-Net的传感器域鲁棒架构，用于解决车辆间集体感知中的Sensor2Sensor域差距问题，并在SCOPE数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 集体感知在自动驾驶中具有潜力，但不同传感器系统导致的Sensor2Sensor域差距问题尚未解决。缺乏异构传感器设置的数据集进一步加剧了这一挑战。

Method: 提出S2S-Net架构，并在SCOPE数据集上进行了深入的Sensor2Sensor域适应能力分析。

Result: S2S-Net在未见过的传感器域中保持了高性能，并在SCOPE数据集上达到了最先进的结果。

Conclusion: S2S-Net有效解决了Sensor2Sensor域差距问题，为车辆间集体感知提供了可行的解决方案。

Abstract: Collective Perception (CP) has emerged as a promising approach to overcome
the limitations of individual perception in the context of autonomous driving.
Various approaches have been proposed to realize collective perception;
however, the Sensor2Sensor domain gap that arises from the utilization of
different sensor systems in Connected and Automated Vehicles (CAVs) remains
mostly unaddressed. This is primarily due to the paucity of datasets containing
heterogeneous sensor setups among the CAVs. The recently released SCOPE
datasets address this issue by providing data from three different LiDAR
sensors for each CAV. This study is the first to tackle the Sensor2Sensor
domain gap in vehicle to vehicle (V2V) collective perception. First, we present
our sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the
Sensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is
conducted. S2S-Net demonstrates the capability to maintain very high
performance in unseen sensor domains and achieved state-of-the-art results on
the SCOPE dataset.

</details>


### [32] [StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies](https://arxiv.org/abs/2504.17401)
*Xu Wang,Jialang Xu,Shuai Zhang,Baoru Huang,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: 论文提出StereoMamba架构，用于机器人辅助微创手术中的立体视差估计，通过FE-Mamba和MFF模块提升性能，在多个指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在立体视差估计中难以平衡准确性、鲁棒性和推理速度，StereoMamba旨在解决这一问题。

Method: 采用FE-Mamba模块增强空间依赖关系，结合MFF模块融合多尺度特征。

Result: 在SCARED基准测试中，EPE为2.64 px，深度MAE为2.55 mm，推理速度为21.28 FPS，SSIM和PSNR表现最佳。

Conclusion: StereoMamba在准确性、鲁棒性和效率上达到最优平衡，并展示了强大的零样本泛化能力。

Abstract: Stereo disparity estimation is crucial for obtaining depth information in
robot-assisted minimally invasive surgery (RAMIS). While current deep learning
methods have made significant advancements, challenges remain in achieving an
optimal balance between accuracy, robustness, and inference speed. To address
these challenges, we propose the StereoMamba architecture, which is
specifically designed for stereo disparity estimation in RAMIS. Our approach is
based on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances
long-range spatial dependencies both within and across stereo images. To
effectively integrate multi-scale features from FE-Mamba, we then introduce a
novel Multidimensional Feature Fusion (MFF) module. Experiments against the
state-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba
achieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the
second-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining
an inference speed of 21.28 FPS for a pair of high-resolution images
(1280*1024), striking the optimum balance between accuracy, robustness, and
efficiency. Furthermore, by comparing synthesized right images, generated from
warping left images using the generated disparity maps, with the actual right
image, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761),
exhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS
datasets.

</details>


### [33] [3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models](https://arxiv.org/abs/2504.17414)
*Min Wei,Chaohui Yu,Jingkai Zhou,Fan Wang*

Main category: cs.CV

TL;DR: 3DV-TON是一种基于扩散的框架，用于生成高质量且时间一致的视频试穿效果，通过动态3D网格和矩形掩码策略解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂服装图案和多样身体姿势下难以生成高质量且时间一致的结果。

Method: 使用生成的动画纹理3D网格作为帧级指导，结合自适应管道生成动态3D指导，并引入矩形掩码策略减少伪影传播。

Result: 定量和定性结果表明，3DV-TON在性能上优于现有方法。

Conclusion: 3DV-TON通过动态3D指导和掩码策略，显著提升了视频试穿的质量和一致性。

Abstract: Video try-on replaces clothing in videos with target garments. Existing
methods struggle to generate high-quality and temporally consistent results
when handling complex clothing patterns and diverse body poses. We present
3DV-TON, a novel diffusion-based framework for generating high-fidelity and
temporally consistent video try-on results. Our approach employs generated
animatable textured 3D meshes as explicit frame-level guidance, alleviating the
issue of models over-focusing on appearance fidelity at the expanse of motion
coherence. This is achieved by enabling direct reference to consistent garment
texture movements throughout video sequences. The proposed method features an
adaptive pipeline for generating dynamic 3D guidance: (1) selecting a keyframe
for initial 2D image try-on, followed by (2) reconstructing and animating a
textured 3D mesh synchronized with original video poses. We further introduce a
robust rectangular masking strategy that successfully mitigates artifact
propagation caused by leaking clothing information during dynamic human and
garment movements. To advance video try-on research, we introduce HR-VVT, a
high-resolution benchmark dataset containing 130 videos with diverse clothing
types and scenarios. Quantitative and qualitative results demonstrate our
superior performance over existing methods. The project page is at this link
https://2y7c3.github.io/3DV-TON/

</details>


### [34] [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org/abs/2504.17432)
*Tiancheng Gu,Kaicheng Yang,Ziyong Feng,Xingjun Wang,Yanzhao Zhang,Dingkun Long,Yingda Chen,Weidong Cai,Jiankang Deng*

Main category: cs.CV

TL;DR: UniME提出了一种新的两阶段框架，利用MLLM学习可迁移的多模态表示，解决了CLIP的局限性，并在多个任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: CLIP框架在多模态表示学习中存在文本截断、孤立编码和组合性不足等问题，而MLLM的潜力尚未充分挖掘。

Method: UniME通过两阶段方法：1) 从LLM教师模型进行知识蒸馏；2) 引入硬负样本增强的指令调优，提升判别性和组合性。

Result: 在MMEB基准和多个检索任务中，UniME表现一致优于现有方法，展示了更强的判别和组合能力。

Conclusion: UniME通过两阶段设计有效提升了多模态表示学习的性能，为下游任务提供了更强大的嵌入能力。

Abstract: The Contrastive Language-Image Pre-training (CLIP) framework has become a
widely used approach for multimodal representation learning, particularly in
image-text retrieval and clustering. However, its efficacy is constrained by
three key limitations: (1) text token truncation, (2) isolated image-text
encoding, and (3) deficient compositionality due to bag-of-words behavior.
While recent Multimodal Large Language Models (MLLMs) have demonstrated
significant advances in generalized vision-language understanding, their
potential for learning transferable multimodal representations remains
underexplored.In this work, we present UniME (Universal Multimodal Embedding),
a novel two-stage framework that leverages MLLMs to learn discriminative
representations for diverse downstream tasks. In the first stage, we perform
textual discriminative knowledge distillation from a powerful LLM-based teacher
model to enhance the embedding capability of the MLLM\'s language component. In
the second stage, we introduce hard negative enhanced instruction tuning to
further advance discriminative representation learning. Specifically, we
initially mitigate false negative contamination and then sample multiple hard
negatives per instance within each batch, forcing the model to focus on
challenging samples. This approach not only improves discriminative power but
also enhances instruction-following ability in downstream tasks. We conduct
extensive experiments on the MMEB benchmark and multiple retrieval tasks,
including short and long caption retrieval and compositional retrieval. Results
demonstrate that UniME achieves consistent performance improvement across all
tasks, exhibiting superior discriminative and compositional capabilities.

</details>


### [35] [Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object Understanding](https://arxiv.org/abs/2504.17441)
*Mingxuan Wu,Huang Huang,Justin Kerr,Chung Min Kim,Anthony Zhang,Brent Yi,Angjoo Kanazawa*

Main category: cs.CV

TL;DR: POD框架通过预测-优化-蒸馏的循环自我提升机制，结合多视角扫描和长视频数据，实现了对物体4D状态的持续优化理解。


<details>
  <summary>Details</summary>
Motivation: 人类通过长时间观察物体运动来预测其3D状态，现有系统依赖多视角观察或监督数据集训练。POD旨在通过自我提升框架解决这一问题。

Method: POD框架通过预测局部姿态、全局优化和蒸馏合成数据的循环，结合准多视角挖掘策略减少深度模糊性。

Result: 在14个真实和5个合成对象上测试，POD显著优于纯优化基线，性能随视频长度和迭代次数提升。

Conclusion: POD展示了通过循环自我提升和长视频利用，显著提升对复杂物体姿态配置的理解能力。

Abstract: Humans can resort to long-form inspection to build intuition on predicting
the 3D configurations of unseen objects. The more we observe the object motion,
the better we get at predicting its 3D state immediately. Existing systems
either optimize underlying representations from multi-view observations or
train a feed-forward predictor from supervised datasets. We introduce
Predict-Optimize-Distill (POD), a self-improving framework that interleaves
prediction and optimization in a mutually reinforcing cycle to achieve better
4D object understanding with increasing observation time. Given a multi-view
object scan and a long-form monocular video of human-object interaction, POD
iteratively trains a neural network to predict local part poses from RGB
frames, uses this predictor to initialize a global optimization which refines
output poses through inverse rendering, then finally distills the results of
optimization back into the model by generating synthetic self-labeled training
data from novel viewpoints. Each iteration improves both the predictive model
and the optimized motion trajectory, creating a virtuous cycle that bootstraps
its own training data to learn about the pose configurations of an object. We
also introduce a quasi-multiview mining strategy for reducing depth ambiguity
by leveraging long video. We evaluate POD on 14 real-world and 5 synthetic
objects with various joint types, including revolute and prismatic joints as
well as multi-body configurations where parts detach or reattach independently.
POD demonstrates significant improvement over a pure optimization baseline
which gets stuck in local minima, particularly for longer videos. We also find
that POD's performance improves with both video length and successive
iterations of the self-improving cycle, highlighting its ability to scale
performance with additional observations and looped refinement.

</details>


### [36] [FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding](https://arxiv.org/abs/2504.17447)
*De-An Huang,Subhashree Radhakrishnan,Zhiding Yu,Jan Kautz*

Main category: cs.CV

TL;DR: 论文提出了一种名为FRAG的框架，通过选择输入中的相关帧而非处理长上下文，显著提升了大型多模态模型在长视频和多页文档任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前长上下文多模态模型因计算成本高而受限，作者探索了一种无需长上下文处理的替代方法。

Method: FRAG框架通过独立评分选择相关帧（Top-K选择），仅基于选定帧生成输出，无需微调现有模型。

Result: 实验表明，FRAG在长视频和文档任务中均显著提升性能，如InternVL2-76B在MLVU上提升5.8%，在MP-DocVQA上提升超20%。

Conclusion: FRAG是一种简单有效的框架，适用于长输入任务，且无需额外训练，性能优于现有长上下文模型。

Abstract: There has been impressive progress in Large Multimodal Models (LMMs). Recent
works extend these models to long inputs, including multi-page documents and
long videos. However, the model size and performance of these long context
models are still limited due to the computational cost in both training and
inference. In this work, we explore an orthogonal direction and process long
inputs without long context LMMs. We propose Frame Selection Augmented
Generation (FRAG), where the model first selects relevant frames within the
input, and then only generates the final outputs based on the selected frames.
The core of the selection process is done by scoring each frame independently,
which does not require long context processing. The frames with the highest
scores are then selected by a simple Top-K selection. We show that this
frustratingly simple framework is applicable to both long videos and multi-page
documents using existing LMMs without any fine-tuning. We consider two models,
LLaVA-OneVision and InternVL2, in our experiments and show that FRAG
consistently improves the performance and achieves state-of-the-art
performances for both long video and long document understanding. For videos,
FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on
Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA
compared with recent LMMs specialized in long document understanding. Code is
available at: https://github.com/NVlabs/FRAG

</details>


### [37] [Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks](https://arxiv.org/abs/2504.17457)
*Zhiying Li,Yeying Jin,Fan Shen,Zhi Liu,Weibin Chen,Pengju Zhang,Xiaomei Zhang,Boyu Chen,Michael Shen,Kejian Wu,Zhaoxin Fan,Jin Dong*

Main category: cs.CV

TL;DR: 论文提出了一种名为Tangible Attack (TBA)的新框架，通过Dual Heterogeneous Noise Generator (DHNG)和自定义对抗损失函数，显著提高了对抗攻击的有效性，揭示了当前EHPS模型的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注减少估计误差，但忽视了鲁棒性和安全性，导致系统易受对抗攻击。

Method: 提出TBA框架，结合DHNG（利用VAE和ControlNet生成多样化噪声）和自定义对抗损失函数，通过多梯度信号迭代优化对抗样本。

Result: 实验表明TBA显著提升了对抗攻击效果，估计误差增加了41.0%，平均提升约17.0%。

Conclusion: 当前EHPS模型存在重大安全漏洞，需加强数字人生成系统的防御能力。

Abstract: Expressive human pose and shape estimation (EHPS) is crucial for digital
human generation, especially in applications like live streaming. While
existing research primarily focuses on reducing estimation errors, it largely
neglects robustness and security aspects, leaving these systems vulnerable to
adversarial attacks. To address this significant challenge, we propose the
\textbf{Tangible Attack (TBA)}, a novel framework designed to generate
adversarial examples capable of effectively compromising any digital human
generation model. Our approach introduces a \textbf{Dual Heterogeneous Noise
Generator (DHNG)}, which leverages Variational Autoencoders (VAE) and
ControlNet to produce diverse, targeted noise tailored to the original image
features. Additionally, we design a custom \textbf{adversarial loss function}
to optimize the noise, ensuring both high controllability and potent
disruption. By iteratively refining the adversarial sample through
multi-gradient signals from both the noise and the state-of-the-art EHPS model,
TBA substantially improves the effectiveness of adversarial attacks. Extensive
experiments demonstrate TBA's superiority, achieving a remarkable 41.0\%
increase in estimation error, with an average improvement of approximately
17.0\%. These findings expose significant security vulnerabilities in current
EHPS models and highlight the need for stronger defenses in digital human
generation systems.

</details>


### [38] [Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data](https://arxiv.org/abs/2504.17474)
*Weiran Pan,Wei Wei,Feida Zhu,Yong Deng*

Main category: cs.CV

TL;DR: 提出了一种基于模型预测置信度趋势的样本选择方法，用于解决噪声标签下图像分类中的样本选择问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将小损失样本视为正确标签，但部分正确标签样本因难以学习而表现出高损失，导致样本选择在精度和召回率之间存在权衡。

Method: 通过跟踪标注标签与其他类别之间的置信度差距趋势，利用Mann-Kendall Test评估趋势，选择置信度差距增加的样本作为潜在正确标签。

Result: 实验表明，该方法能有效提升现有噪声标签学习方法的性能。

Conclusion: 该方法作为一种即插即用组件，可无缝集成到现有样本选择技术中，缓解了样本选择的权衡问题。

Abstract: We propose a novel sample selection method for image classification in the
presence of noisy labels. Existing methods typically consider small-loss
samples as correctly labeled. However, some correctly labeled samples are
inherently difficult for the model to learn and can exhibit high loss similar
to mislabeled samples in the early stages of training. Consequently, setting a
threshold on per-sample loss to select correct labels results in a trade-off
between precision and recall in sample selection: a lower threshold may miss
many correctly labeled hard-to-learn samples (low recall), while a higher
threshold may include many mislabeled samples (low precision). To address this
issue, our goal is to accurately distinguish correctly labeled yet
hard-to-learn samples from mislabeled ones, thus alleviating the trade-off
dilemma. We achieve this by considering the trends in model prediction
confidence rather than relying solely on loss values. Empirical observations
show that only for correctly labeled samples, the model's prediction confidence
for the annotated labels typically increases faster than for any other classes.
Based on this insight, we propose tracking the confidence gaps between the
annotated labels and other classes during training and evaluating their trends
using the Mann-Kendall Test. A sample is considered potentially correctly
labeled if all its confidence gaps tend to increase. Our method functions as a
plug-and-play component that can be seamlessly integrated into existing sample
selection techniques. Experiments on several standard benchmarks and real-world
datasets demonstrate that our method enhances the performance of existing
methods for learning with noisy labels.

</details>


### [39] [RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image Generation](https://arxiv.org/abs/2504.17502)
*Aviv Slobodkin,Hagai Taitelbaum,Yonatan Bitton,Brian Gordon,Michal Sokolik,Nitzan Bitton Guetta,Almog Gueta,Royi Rassin,Itay Laish,Dani Lischinski,Idan Szpektor*

Main category: cs.CV

TL;DR: RefVNLI是一种新的自动评估指标，用于评估主题驱动的文本到图像生成任务中的文本对齐和主题一致性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主题驱动的文本到图像生成缺乏可靠的自动评估方法，现有方法要么仅评估单一任务，要么与人类判断不一致，或依赖昂贵的API评估。

Method: 引入RefVNLI，通过大规模视频推理基准和图像扰动数据集训练，同时评估文本对齐和主题一致性。

Result: RefVNLI在多个基准测试和主题类别中表现优于或匹配现有基线，文本对齐提升6.4分，主题一致性提升8.5分，且在冷门概念上表现优异。

Conclusion: RefVNLI是一种高效且与人类判断高度一致的评估指标，解决了现有方法的局限性。

Abstract: Subject-driven text-to-image (T2I) generation aims to produce images that
align with a given textual description, while preserving the visual identity
from a referenced subject image. Despite its broad downstream applicability --
ranging from enhanced personalization in image generation to consistent
character representation in video rendering -- progress in this field is
limited by the lack of reliable automatic evaluation. Existing methods either
assess only one aspect of the task (i.e., textual alignment or subject
preservation), misalign with human judgments, or rely on costly API-based
evaluation. To address this, we introduce RefVNLI, a cost-effective metric that
evaluates both textual alignment and subject preservation in a single
prediction. Trained on a large-scale dataset derived from video-reasoning
benchmarks and image perturbations, RefVNLI outperforms or matches existing
baselines across multiple benchmarks and subject categories (e.g.,
\emph{Animal}, \emph{Object}), achieving up to 6.4-point gains in textual
alignment and 8.5-point gains in subject consistency. It also excels with
lesser-known concepts, aligning with human preferences at over 87\% accuracy.

</details>


### [40] [Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2504.17515)
*Zihan Cheng,Jintao Guo,Jian Zhang,Lei Qi,Luping Zhou,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 论文提出了一种基于Mamba架构的新框架Mamba-Sea，用于解决医学图像分割中的分布偏移问题，通过全局到局部的序列增强提升模型的泛化能力，并在Prostate数据集上取得了超过90%的Dice系数。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中，分布偏移问题影响模型在未见目标域上的表现。现有方法主要基于CNN或ViT架构，而Mamba因其长程依赖捕捉能力和线性复杂度显示出潜力。

Method: 提出Mamba-Sea框架，结合全局和局部序列增强机制：全局增强模拟不同站点间的外观变化，抑制域特定信息学习；局部增强通过扰动连续子序列的风格统计提升鲁棒性。

Result: 在Prostate数据集上，Mamba-Sea首次超过90%的Dice系数，优于之前88.61%的SOTA。

Conclusion: Mamba-Sea是首个探索Mamba在医学图像分割中泛化能力的工作，提供了对分布偏移具有强鲁棒性的先进架构。

Abstract: To segment medical images with distribution shifts, domain generalization
(DG) has emerged as a promising setting to train models on source domains that
can generalize to unseen target domains. Existing DG methods are mainly based
on CNN or ViT architectures. Recently, advanced state space models, represented
by Mamba, have shown promising results in various supervised medical image
segmentation. The success of Mamba is primarily owing to its ability to capture
long-range dependencies while keeping linear complexity with input sequence
length, making it a promising alternative to CNNs and ViTs. Inspired by the
success, in the paper, we explore the potential of the Mamba architecture to
address distribution shifts in DG for medical image segmentation. Specifically,
we propose a novel Mamba-based framework, Mamba-Sea, incorporating
global-to-local sequence augmentation to improve the model's generalizability
under domain shift issues. Our Mamba-Sea introduces a global augmentation
mechanism designed to simulate potential variations in appearance across
different sites, aiming to suppress the model's learning of domain-specific
information. At the local level, we propose a sequence-wise augmentation along
input sequences, which perturbs the style of tokens within random continuous
sub-sequences by modeling and resampling style statistics associated with
domain shifts. To our best knowledge, Mamba-Sea is the first work to explore
the generalization of Mamba for medical image segmentation, providing an
advanced and promising Mamba-based architecture with strong robustness to
domain shifts. Remarkably, our proposed method is the first to surpass a Dice
coefficient of 90% on the Prostate dataset, which exceeds previous SOTA of
88.61%. The code is available at https://github.com/orange-czh/Mamba-Sea.

</details>


### [41] [Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios](https://arxiv.org/abs/2504.17522)
*Anyi Xiao,Cihui Yang*

Main category: cs.CV

TL;DR: TableCenterNet提出了一种单阶段端到端的表格结构解析网络，统一了表格空间和逻辑结构的预测，通过共享特征提取层和任务特定解码的协同架构，实现了高效训练和推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨场景适应性、鲁棒性和计算效率之间难以平衡，TableCenterNet旨在解决这一问题。

Method: 提出单阶段端到端网络TableCenterNet，统一预测表格空间和逻辑结构，通过共享特征提取层和任务特定解码实现。

Result: 在TableGraph-24k数据集上达到最先进性能，且训练和推理更高效。

Conclusion: TableCenterNet在多样场景中有效解析表格结构，性能优越且计算高效。

Abstract: Table structure recognition aims to parse tables in unstructured data into
machine-understandable formats. Recent methods address this problem through a
two-stage process or optimized one-stage approaches. However, these methods
either require multiple networks to be serially trained and perform more
time-consuming sequential decoding, or rely on complex post-processing
algorithms to parse the logical structure of tables. They struggle to balance
cross-scenario adaptability, robustness, and computational efficiency. In this
paper, we propose a one-stage end-to-end table structure parsing network called
TableCenterNet. This network unifies the prediction of table spatial and
logical structure into a parallel regression task for the first time, and
implicitly learns the spatial-logical location mapping laws of cells through a
synergistic architecture of shared feature extraction layers and task-specific
decoding. Compared with two-stage methods, our method is easier to train and
faster to infer. Experiments on benchmark datasets show that TableCenterNet can
effectively parse table structures in diverse scenarios and achieve
state-of-the-art performance on the TableGraph-24k dataset. Code is available
at https://github.com/dreamy-xay/TableCenterNet.

</details>


### [42] [ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting](https://arxiv.org/abs/2504.17524)
*Junyan Zhang,Yan Li,Mengxiao Geng,Liu Shi,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出了一种基于编码策略的扩散模型，用于少样本学习的彩色图像修复，通过虚拟掩码和高维对象构建，提升了细节和结构完整性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以保留复杂细节，深度学习模型需要大量数据，因此提出一种少样本学习方法以解决这些问题。

Method: 采用编码策略，利用虚拟掩码构建高维对象，结合低秩方法和扩散模型实现精确修复。

Result: 实验表明，该方法在定量指标和图像质量（纹理和结构完整性）上优于现有技术。

Conclusion: 该方法通过少样本学习实现了更精确和一致的图像修复效果。

Abstract: Image inpainting is a technique used to restore missing or damaged regions of
an image. Traditional methods primarily utilize information from adjacent
pixels for reconstructing missing areas, while they struggle to preserve
complex details and structures. Simultaneously, models based on deep learning
necessitate substantial amounts of training data. To address this challenge, an
encoding strategy-inspired diffusion model with few-shot learning for color
image inpainting is proposed in this paper. The main idea of this novel
encoding strategy is the deployment of a "virtual mask" to construct
high-dimensional objects through mutual perturbations between channels. This
approach enables the diffusion model to capture diverse image representations
and detailed features from limited training samples. Moreover, the encoding
strategy leverages redundancy between channels, integrates with low-rank
methods during iterative inpainting, and incorporates the diffusion model to
achieve accurate information output. Experimental results indicate that our
method exceeds current techniques in quantitative metrics, and the
reconstructed images quality has been improved in aspects of texture and
structural integrity, leading to more precise and coherent results.

</details>


### [43] [Text-to-Image Alignment in Denoising-Based Models through Step Selection](https://arxiv.org/abs/2504.17525)
*Paul Grimal,Hervé Le Borgne,Olivier Ferret*

Main category: cs.CV

TL;DR: 提出一种在关键去噪步骤选择性增强信号的方法，优化基于输入语义的图像生成。


<details>
  <summary>Details</summary>
Motivation: 解决视觉生成AI模型中文本-图像对齐和推理限制的挑战。

Method: 在后期去噪阶段调整信号，而非早期阶段，以优化图像生成。

Result: 在Diffusion和Flow Matching模型上验证了方法的有效性，实现了最先进的性能。

Conclusion: 选择合适的采样阶段对提升性能和图像对齐至关重要。

Abstract: Visual generative AI models often encounter challenges related to text-image
alignment and reasoning limitations. This paper presents a novel method for
selectively enhancing the signal at critical denoising steps, optimizing image
generation based on input semantics. Our approach addresses the shortcomings of
early-stage signal modifications, demonstrating that adjustments made at later
stages yield superior results. We conduct extensive experiments to validate the
effectiveness of our method in producing semantically aligned images on
Diffusion and Flow Matching model, achieving state-of-the-art performance. Our
results highlight the importance of a judicious choice of sampling stage to
improve performance and overall image alignment.

</details>


### [44] [An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm](https://arxiv.org/abs/2504.17540)
*Ahmadreza Shateri,Negar Nourani,Morteza Dorrigiv,Hamid Nasiri*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的框架，用于从皮肤病变图像中自动检测猴痘，结合迁移学习、降维和优化算法，取得了高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 猴痘在全球非传统流行地区的传播引发公共卫生担忧，早期准确诊断对疾病管理至关重要。

Method: 使用Xception架构提取特征，PCA降维，NGBoost分类，并引入AVOA算法优化超参数。

Result: 模型准确率达97.53%，F1分数97.72%，AUC 97.47%，并通过Grad-CAM和LIME增强可解释性。

Conclusion: 该框架为资源有限环境提供了高效诊断工具，有助于早期检测和诊断。

Abstract: The recent global spread of monkeypox, particularly in regions where it has
not historically been prevalent, has raised significant public health concerns.
Early and accurate diagnosis is critical for effective disease management and
control. In response, this study proposes a novel deep learning-based framework
for the automated detection of monkeypox from skin lesion images, leveraging
the power of transfer learning, dimensionality reduction, and advanced machine
learning techniques. We utilize the newly developed Monkeypox Skin Lesion
Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to
train and evaluate our models. The proposed framework employs the Xception
architecture for deep feature extraction, followed by Principal Component
Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting
(NGBoost) algorithm for classification. To optimize the model's performance and
generalization, we introduce the African Vultures Optimization Algorithm (AVOA)
for hyperparameter tuning, ensuring efficient exploration of the parameter
space. Our results demonstrate that the proposed AVOA-NGBoost model achieves
state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%
and an AUC of 97.47%. Additionally, we enhance model interpretability using
Grad-CAM and LIME techniques, providing insights into the decision-making
process and highlighting key features influencing classification. This
framework offers a highly precise and efficient diagnostic tool, potentially
aiding healthcare providers in early detection and diagnosis, particularly in
resource-constrained environments.

</details>


### [45] [When Gaussian Meets Surfel: Ultra-fast High-fidelity Radiance Field Rendering](https://arxiv.org/abs/2504.17545)
*Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.CV

TL;DR: Gaussian-enhanced Surfels (GESs) 是一种双尺度表示方法，用于辐射场渲染，通过2D不透明面元和3D高斯分布结合，实现快速、高质量的渲染。


<details>
  <summary>Details</summary>
Motivation: 解决传统辐射场渲染中速度与质量难以兼顾的问题，提供一种高效且高保真的渲染方案。

Method: 使用2D面元表示粗尺度几何和外观，3D高斯分布补充细节；两阶段渲染（面元光栅化+高斯分布叠加）；通过多视图图像优化实现粗到细的捕捉。

Result: GESs 实现了超快速的高保真渲染，避免了视角变化时的闪烁问题，并支持多种扩展（如抗锯齿、加速渲染等）。

Conclusion: GESs 是一种高效且灵活的辐射场表示方法，显著提升了渲染速度和图像质量。

Abstract: We introduce Gaussian-enhanced Surfels (GESs), a bi-scale representation for
radiance field rendering, wherein a set of 2D opaque surfels with
view-dependent colors represent the coarse-scale geometry and appearance of
scenes, and a few 3D Gaussians surrounding the surfels supplement fine-scale
appearance details. The rendering with GESs consists of two passes -- surfels
are first rasterized through a standard graphics pipeline to produce depth and
color maps, and then Gaussians are splatted with depth testing and color
accumulation on each pixel order independently. The optimization of GESs from
multi-view images is performed through an elaborate coarse-to-fine procedure,
faithfully capturing rich scene appearance. The entirely sorting-free rendering
of GESs not only achieves very fast rates, but also produces view-consistent
images, successfully avoiding popping artifacts under view changes. The basic
GES representation can be easily extended to achieve anti-aliasing in rendering
(Mip-GES), boosted rendering speeds (Speedy-GES) and compact storage
(Compact-GES), and reconstruct better scene geometries by replacing 3D
Gaussians with 2D Gaussians (2D-GES). Experimental results show that GESs
advance the state-of-the-arts as a compelling representation for ultra-fast
high-fidelity radiance field rendering.

</details>


### [46] [A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task](https://arxiv.org/abs/2504.17547)
*Jiaqi Deng,Zonghan Wu,Huan Huo,Guandong Xu*

Main category: cs.CV

TL;DR: 该论文是一篇关于知识驱动的视觉问答（KB-VQA）的综述，系统整理了现有方法，提出了分类框架，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: KB-VQA结合视觉、文本和广泛知识，具有重要应用价值，但目前缺乏系统性综述。

Method: 通过建立分类框架，将KB-VQA方法分为知识表示、知识检索和知识推理三个阶段。

Result: 综述了现有技术，总结了知识整合方法，并指出了持续挑战。

Conclusion: 为KB-VQA模型的进一步发展提供了基础，并提出了未来研究方向。

Abstract: Knowledge-based Vision Question Answering (KB-VQA) extends general Vision
Question Answering (VQA) by not only requiring the understanding of visual and
textual inputs but also extensive range of knowledge, enabling significant
advancements across various real-world applications. KB-VQA introduces unique
challenges, including the alignment of heterogeneous information from diverse
modalities and sources, the retrieval of relevant knowledge from noisy or
large-scale repositories, and the execution of complex reasoning to infer
answers from the combined context. With the advancement of Large Language
Models (LLMs), KB-VQA systems have also undergone a notable transformation,
where LLMs serve as powerful knowledge repositories, retrieval-augmented
generators and strong reasoners. Despite substantial progress, no comprehensive
survey currently exists that systematically organizes and reviews the existing
KB-VQA methods. This survey aims to fill this gap by establishing a structured
taxonomy of KB-VQA approaches, and categorizing the systems into main stages:
knowledge representation, knowledge retrieval, and knowledge reasoning. By
exploring various knowledge integration techniques and identifying persistent
challenges, this work also outlines promising future research directions,
providing a foundation for advancing KB-VQA models and their applications.

</details>


### [47] [Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior](https://arxiv.org/abs/2504.17551)
*Lin Che,Yizi Chen,Tanhua Jin,Martin Raubal,Konrad Schindler,Peter Kiefer*

Main category: cs.CV

TL;DR: 该论文提出了一种基于地理先验的无监督对比聚类模型，用于街景图像的土地利用分类，解决了传统方法在复杂城市环境中缺乏精度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有遥感技术因缺乏地面细节而在复杂城市环境中精度不足，而街景图像能捕捉更多人类和社会活动信息，但现有监督分类方法受限于高质量标注数据的稀缺性和泛化能力不足。

Method: 提出了一种结合地理先验的无监督对比聚类模型，并通过简单的视觉分配实现土地利用分类。

Result: 实验证明，该方法能够从两个城市的街景图像数据集中生成土地利用地图。

Conclusion: 该方法基于地理数据的空间一致性，可适用于各种街景图像可用场景，实现可扩展的无监督土地利用分类与更新。

Abstract: Urban land use classification and mapping are critical for urban planning,
resource management, and environmental monitoring. Existing remote sensing
techniques often lack precision in complex urban environments due to the
absence of ground-level details. Unlike aerial perspectives, street view images
provide a ground-level view that captures more human and social activities
relevant to land use in complex urban scenes. Existing street view-based
methods primarily rely on supervised classification, which is challenged by the
scarcity of high-quality labeled data and the difficulty of generalizing across
diverse urban landscapes. This study introduces an unsupervised contrastive
clustering model for street view images with a built-in geographical prior, to
enhance clustering performance. When combined with a simple visual assignment
of the clusters, our approach offers a flexible and customizable solution to
land use mapping, tailored to the specific needs of urban planners. We
experimentally show that our method can generate land use maps from geotagged
street view image datasets of two cities. As our methodology relies on the
universal spatial coherence of geospatial data ("Tobler's law"), it can be
adapted to various settings where street view images are available, to enable
scalable, unsupervised land use mapping and updating. The code will be
available at https://github.com/lin102/CCGP.

</details>


### [48] [Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images](https://arxiv.org/abs/2504.17582)
*Zebo Huang,Yinghui Wang*

Main category: cs.CV

TL;DR: 提出了一种针对内窥镜场景的自监督单目深度估计网络，通过遮挡感知框架和语义分割提升深度重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设光照一致，但内窥镜场景中动态光照和遮挡导致几何解释错误，需改进。

Method: 引入遮挡感知自监督框架，结合遮挡掩模数据增强和语义分割，提升特征学习和分割精度。

Result: 在SCARED数据集上达到SOTA性能，并在Endo-SLAM和SERV-CT数据集上表现优异。

Conclusion: 方法有效解决了内窥镜场景中的光照和遮挡问题，具有强泛化能力。

Abstract: We propose a self-supervised monocular depth estimation network tailored for
endoscopic scenes, aiming to infer depth within the gastrointestinal tract from
monocular images. Existing methods, though accurate, typically assume
consistent illumination, which is often violated due to dynamic lighting and
occlusions caused by GI motility. These variations lead to incorrect geometric
interpretations and unreliable self-supervised signals, degrading depth
reconstruction quality. To address this, we introduce an occlusion-aware
self-supervised framework. First, we incorporate an occlusion mask for data
augmentation, generating pseudo-labels by simulating viewpoint-dependent
occlusion scenarios. This enhances the model's ability to learn robust depth
features under partial visibility. Second, we leverage semantic segmentation
guided by non-negative matrix factorization, clustering convolutional
activations to generate pseudo-labels in texture-deprived regions, thereby
improving segmentation accuracy and mitigating information loss from lighting
changes. Experimental results on the SCARED dataset show that our method
achieves state-of-the-art performance in self-supervised depth estimation.
Additionally, evaluations on the Endo-SLAM and SERV-CT datasets demonstrate
strong generalization across diverse endoscopic environments.

</details>


### [49] [Tamper-evident Image using JPEG Fixed Points](https://arxiv.org/abs/2504.17594)
*Zhaofeng Si,Siwei Lyu*

Main category: cs.CV

TL;DR: JPEG重复压缩和解压会达到一个稳定点（固定点），本文证明了固定点的存在性，并利用这一特性开发了一种防篡改图像方法。


<details>
  <summary>Details</summary>
Motivation: 研究JPEG压缩过程中的固定点现象，以开发防篡改图像技术。

Method: 分析JPEG压缩和解压过程，证明固定点的存在性，并利用固定点开发防篡改方法。

Result: 固定点存在且可在几次迭代内达到，图像视觉质量保持良好，失真最小。

Conclusion: 固定点可用于开发防篡改图像技术，通过检测与固定点的偏差来暴露篡改操作。

Abstract: An intriguing phenomenon about JPEG compression has been observed since two
decades ago- after repeating JPEG compression and decompression, it leads to a
stable image that does not change anymore, which is a fixed point. In this
work, we prove the existence of fixed points in the essential JPEG procedures.
We analyze JPEG compression and decompression processes, revealing the
existence of fixed points that can be reached within a few iterations. These
fixed points are diverse and preserve the image's visual quality, ensuring
minimal distortion. This result is used to develop a method to create a
tamper-evident image from the original authentic image, which can expose
tampering operations by showing deviations from the fixed point image.

</details>


### [50] [RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network](https://arxiv.org/abs/2504.17595)
*Boyue Xu,Yi Xu,Ruichao Hou,Jia Bei,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

TL;DR: HMAD网络通过层次化模态聚合与分布，提升了RGB-D跟踪的鲁棒性和效率，实现了实时性能。


<details>
  <summary>Details</summary>
Motivation: 当前RGB-D跟踪器效率低且仅关注单层特征，导致融合鲁棒性差且速度慢，无法满足实际应用需求。

Method: 提出HMAD网络，利用RGB和深度模态的独特特征表示优势，采用层次化特征分布与融合方法。

Result: 在多个RGB-D数据集上实现最优性能，并在实时场景中有效应对多种跟踪挑战。

Conclusion: HMAD通过层次化模态处理，显著提升了RGB-D跟踪的鲁棒性和实时性。

Abstract: The integration of dual-modal features has been pivotal in advancing
RGB-Depth (RGB-D) tracking. However, current trackers are less efficient and
focus solely on single-level features, resulting in weaker robustness in fusion
and slower speeds that fail to meet the demands of real-world applications. In
this paper, we introduce a novel network, denoted as HMAD (Hierarchical
Modality Aggregation and Distribution), which addresses these challenges. HMAD
leverages the distinct feature representation strengths of RGB and depth
modalities, giving prominence to a hierarchical approach for feature
distribution and fusion, thereby enhancing the robustness of RGB-D tracking.
Experimental results on various RGB-D datasets demonstrate that HMAD achieves
state-of-the-art performance. Moreover, real-world experiments further validate
HMAD's capacity to effectively handle a spectrum of tracking challenges in
real-time scenarios.

</details>


### [51] [STCL:Curriculum learning Strategies for deep learning image steganography models](https://arxiv.org/abs/2504.17609)
*Fengchun Liu,Tong Zhang,Chunying Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于课程学习的隐写训练策略（STCL），通过逐步增加训练难度，提升深度学习隐写模型的图像质量和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 针对深度学习隐写模型图像质量差和网络收敛慢的问题，提出了一种改进的训练策略。

Method: 1. 基于教师模型的难度评估策略；2. 基于拐点的训练调度策略。通过逐步扩展训练子集从易到难，避免过拟合并加速训练。

Result: 在ALASKA2、VOC2012和ImageNet数据集上，STCL策略显著提升了模型的PSNR、SSIM和解码准确率，同时降低了隐写分析得分。

Conclusion: STCL策略有效提升了深度学习隐写模型的性能，生成的隐写图像质量高且安全性强。

Abstract: Aiming at the problems of poor quality of steganographic images and slow
network convergence of image steganography models based on deep learning, this
paper proposes a Steganography Curriculum Learning training strategy (STCL) for
deep learning image steganography models. So that only easy images are selected
for training when the model has poor fitting ability at the initial stage, and
gradually expand to more difficult images, the strategy includes a difficulty
evaluation strategy based on the teacher model and an knee point-based training
scheduling strategy. Firstly, multiple teacher models are trained, and the
consistency of the quality of steganographic images under multiple teacher
models is used as the difficulty score to construct the training subsets from
easy to difficult. Secondly, a training control strategy based on knee points
is proposed to reduce the possibility of overfitting on small training sets and
accelerate the training process. Experimental results on three large public
datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image
steganography scheme is able to improve the model performance under multiple
algorithmic frameworks, which not only has a high PSNR, SSIM score, and
decoding accuracy, but also the steganographic images generated by the model
under the training of the STCL strategy have a low steganography analysis
scores. You can find our code at
\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.

</details>


### [52] [Enhancing CNNs robustness to occlusions with bioinspired filters for border completion](https://arxiv.org/abs/2504.17619)
*Catarina P. Coutinho,Aneeqa Merhab,Janko Petkovic,Ferdinando Zanchetta,Rita Fioresi*

Main category: cs.CV

TL;DR: 利用视觉皮层边界补全机制设计CNN滤波器，改进LeNet 5在遮挡MNIST图像上的性能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉皮层机制在CNN中的应用，提升模型对遮挡图像的识别能力。

Method: 基于视觉皮层边界补全的数学模型设计自定义滤波器，改进LeNet 5。

Result: 在遮挡MNIST图像测试中，准确率显著提升。

Conclusion: 视觉皮层机制可有效优化CNN滤波器设计，提升模型性能。

Abstract: We exploit the mathematical modeling of the visual cortex mechanism for
border completion to define custom filters for CNNs. We see a consistent
improvement in performance, particularly in accuracy, when our modified LeNet 5
is tested with occluded MNIST images.

</details>


### [53] [Improving Open-World Object Localization by Discovering Background](https://arxiv.org/abs/2504.17626)
*Ashish Singh,Michael J. Jones,Kuan-Chuan Peng,Anoop Cherian,Moitreya Chatterjee,Erik Learned-Miller*

Main category: cs.CV

TL;DR: 论文提出了一种在开放世界场景中定位对象的新方法，通过利用背景信息指导对象性学习，显著提升了定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决在训练时仅有限类别对象标注的情况下，如何在推理时定位所有对象（包括未见类别）的问题。

Method: 提出了一种新框架，通过发现图像中的背景区域并训练对象提议网络不在这些区域检测对象，背景发现任务被定义为识别非判别性区域。

Result: 在标准基准测试中，该方法显著优于现有最优方法。

Conclusion: 通过利用背景信息指导对象性学习，该方法在开放世界对象定位任务中取得了显著改进。

Abstract: Our work addresses the problem of learning to localize objects in an
open-world setting, i.e., given the bounding box information of a limited
number of object classes during training, the goal is to localize all objects,
belonging to both the training and unseen classes in an image, during
inference. Towards this end, recent work in this area has focused on improving
the characterization of objects either explicitly by proposing new objective
functions (localization quality) or implicitly using object-centric
auxiliary-information, such as depth information, pixel/region affinity map
etc. In this work, we address this problem by incorporating background
information to guide the learning of the notion of objectness. Specifically, we
propose a novel framework to discover background regions in an image and train
an object proposal network to not detect any objects in these regions. We
formulate the background discovery task as that of identifying image regions
that are not discriminative, i.e., those that are redundant and constitute low
information content. We conduct experiments on standard benchmarks to showcase
the effectiveness of our proposed approach and observe significant improvements
over the previous state-of-the-art approaches for this task.

</details>


### [54] [A Guide to Structureless Visual Localization](https://arxiv.org/abs/2504.17636)
*Vojtech Panek,Qunjie Zhou,Yaqing Ding,Sérgio Agostinho,Zuzana Kukelova,Torsten Sattler,Laura Leal-Taixé*

Main category: cs.CV

TL;DR: 本文综述并比较了无结构视觉定位方法，发现基于经典几何推理的方法在姿态精度上优于基于姿态回归的方法，但灵活性以稍低的精度为代价。


<details>
  <summary>Details</summary>
Motivation: 现有基于结构的视觉定位方法虽精确但缺乏灵活性，而无结构方法更易更新但研究较少，本文旨在填补这一空白。

Method: 通过实验比较多种无结构方法，包括基于经典几何推理和姿态回归的方法。

Result: 基于经典几何推理的方法（如绝对或半广义相对姿态估计）在姿态精度上显著优于基于姿态回归的方法。

Conclusion: 无结构方法在灵活性上优于基于结构的方法，但精度稍低，为未来研究提供了方向。

Abstract: Visual localization algorithms, i.e., methods that estimate the camera pose
of a query image in a known scene, are core components of many applications,
including self-driving cars and augmented / mixed reality systems.
State-of-the-art visual localization algorithms are structure-based, i.e., they
store a 3D model of the scene and use 2D-3D correspondences between the query
image and 3D points in the model for camera pose estimation. While such
approaches are highly accurate, they are also rather inflexible when it comes
to adjusting the underlying 3D model after changes in the scene. Structureless
localization approaches represent the scene as a database of images with known
poses and thus offer a much more flexible representation that can be easily
updated by adding or removing images. Although there is a large amount of
literature on structure-based approaches, there is significantly less work on
structureless methods. Hence, this paper is dedicated to providing the, to the
best of our knowledge, first comprehensive discussion and comparison of
structureless methods. Extensive experiments show that approaches that use a
higher degree of classical geometric reasoning generally achieve higher pose
accuracy. In particular, approaches based on classical absolute or
semi-generalized relative pose estimation outperform very recent methods based
on pose regression by a wide margin. Compared with state-of-the-art
structure-based approaches, the flexibility of structureless methods comes at
the cost of (slightly) lower pose accuracy, indicating an interesting direction
for future work.

</details>


### [55] [CLIPSE -- a minimalistic CLIP-based image search engine for research](https://arxiv.org/abs/2504.17643)
*Steve Göring*

Main category: cs.CV

TL;DR: CLIPSE是一个自托管的图像搜索引擎，主要用于研究，利用CLIP嵌入处理图像和文本查询，设计简单易扩展。


<details>
  <summary>Details</summary>
Motivation: 为研究提供一个简单高效的图像搜索工具。

Method: 使用CLIP嵌入处理图像和文本查询，设计简洁框架。

Result: 在小型数据集上表现良好，大型数据集需分布式处理。

Conclusion: CLIPSE适合小型数据集，大型数据集需扩展为分布式架构。

Abstract: A brief overview of CLIPSE, a self-hosted image search engine with the main
application of research, is provided. In general, CLIPSE uses CLIP embeddings
to process the images and also the text queries. The overall framework is
designed with simplicity to enable easy extension and usage. Two benchmark
scenarios are described and evaluated, covering indexing and querying time. It
is shown that CLIPSE is capable of handling smaller datasets; for larger
datasets, a distributed approach with several instances should be considered.

</details>


### [56] [DiMeR: Disentangled Mesh Reconstruction Model](https://arxiv.org/abs/2504.17670)
*Lutao Jiang,Jiantao Lin,Kanghao Chen,Wenhang Ge,Xin Yang,Yifan Jiang,Yuanhuiyi Lyu,Xu Zheng,Yingcong Chen*

Main category: cs.CV

TL;DR: DiMeR是一种新型的双流解耦前馈模型，用于稀疏视图网格重建，通过分离几何和纹理部分，显著提升了重建性能。


<details>
  <summary>Details</summary>
Motivation: RGB图像在几何重建中可能导致训练目标冲突且缺乏清晰度，因此需要一种更有效的方法来分离几何和纹理信息。

Method: DiMeR将输入和框架解耦为几何和纹理两部分，几何分支使用法线图作为输入，纹理分支使用RGB图像，并改进了网格提取算法。

Result: DiMeR在稀疏视图重建、单图像到3D和文本到3D任务中表现优异，Chamfer Distance在GSO和OmniObject3D数据集上提升了30%以上。

Conclusion: DiMeR通过解耦几何和纹理，显著降低了训练难度并提升了重建效果，为3D生成模型提供了新思路。

Abstract: With the advent of large-scale 3D datasets, feed-forward 3D generative
models, such as the Large Reconstruction Model (LRM), have gained significant
attention and achieved remarkable success. However, we observe that RGB images
often lead to conflicting training objectives and lack the necessary clarity
for geometry reconstruction. In this paper, we revisit the inductive biases
associated with mesh reconstruction and introduce DiMeR, a novel disentangled
dual-stream feed-forward model for sparse-view mesh reconstruction. The key
idea is to disentangle both the input and framework into geometry and texture
parts, thereby reducing the training difficulty for each part according to the
Principle of Occam's Razor. Given that normal maps are strictly consistent with
geometry and accurately capture surface variations, we utilize normal maps as
exclusive input for the geometry branch to reduce the complexity between the
network's input and output. Moreover, we improve the mesh extraction algorithm
to introduce 3D ground truth supervision. As for texture branch, we use RGB
images as input to obtain the textured mesh. Overall, DiMeR demonstrates robust
capabilities across various tasks, including sparse-view reconstruction,
single-image-to-3D, and text-to-3D. Numerous experiments show that DiMeR
significantly outperforms previous methods, achieving over 30% improvement in
Chamfer Distance on the GSO and OmniObject3D dataset.

</details>


### [57] [PICO: Reconstructing 3D People In Contact with Objects](https://arxiv.org/abs/2504.17695)
*Alpár Cseke,Shashank Tripathi,Sai Kumar Dwivedi,Arjun Lakshmipathy,Agniv Chatterjee,Michael J. Black,Dimitrios Tzionas*

Main category: cs.CV

TL;DR: 论文提出了一种从单张彩色图像中恢复3D人-物交互（HOI）的方法，通过构建新数据集PICO-db和开发优化方法PICO-fit，解决了深度模糊、遮挡和物体多样性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法需已知物体形状和接触信息，且仅适用于有限物体类别。本文旨在开发适用于自然图像和新型物体类别的通用方法。

Method: 1. 构建PICO-db数据集，利用视觉基础模型检索3D物体网格，并通过2次点击投影接触标签。2. 提出PICO-fit方法，通过渲染-比较优化拟合3D人体和物体网格。

Result: PICO-fit能处理多种物体类别，显著提升了HOI理解的泛化能力。

Conclusion: 该方法为自然场景中的HOI理解提供了可扩展的解决方案，数据集和代码已开源。

Abstract: Recovering 3D Human-Object Interaction (HOI) from single color images is
challenging due to depth ambiguities, occlusions, and the huge variation in
object shape and appearance. Thus, past work requires controlled settings such
as known object shapes and contacts, and tackles only limited object classes.
Instead, we need methods that generalize to natural images and novel object
classes. We tackle this in two main ways: (1) We collect PICO-db, a new dataset
of natural images uniquely paired with dense 3D contact on both body and object
meshes. To this end, we use images from the recent DAMON dataset that are
paired with contacts, but these contacts are only annotated on a canonical 3D
body. In contrast, we seek contact labels on both the body and the object. To
infer these given an image, we retrieve an appropriate 3D object mesh from a
database by leveraging vision foundation models. Then, we project DAMON's body
contact patches onto the object via a novel method needing only 2 clicks per
patch. This minimal human input establishes rich contact correspondences
between bodies and objects. (2) We exploit our new dataset of contact
correspondences in a novel render-and-compare fitting method, called PICO-fit,
to recover 3D body and object meshes in interaction. PICO-fit infers contact
for the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db
for that object, and uses the contact to iteratively fit the 3D body and object
meshes to image evidence via optimization. Uniquely, PICO-fit works well for
many object categories that no existing method can tackle. This is crucial to
enable HOI understanding to scale in the wild. Our data and code are available
at https://pico.is.tue.mpg.de.

</details>


### [58] [Hierarchical and Multimodal Data for Daily Activity Understanding](https://arxiv.org/abs/2504.17696)
*Ghazal Kaviani,Yavuz Yarici,Seulgi Kim,Mohit Prabhushankar,Ghassan AlRegib,Mashhour Solh,Ameya Patil*

Main category: cs.CV

TL;DR: DARai是一个多模态、分层标注的数据集，用于研究真实环境中的人类活动，包含50名参与者在10种环境中的200多小时数据，覆盖20种传感器。


<details>
  <summary>Details</summary>
Motivation: 理解人类活动的复杂性，支持多模态传感器融合和分层任务分析。

Method: 构建包含脚本和非脚本记录的多模态数据集，标注分为三个层次（活动、动作、步骤），并进行多模态传感器融合实验。

Result: 实验展示了DARai在识别、时间定位和未来动作预测中的价值，并揭示了单个传感器的局限性。

Conclusion: DARai为人类中心应用提供了重要挑战和解决方案的数据支持，代码和数据集已公开。

Abstract: Daily Activity Recordings for Artificial Intelligence (DARai, pronounced
"Dahr-ree") is a multimodal, hierarchically annotated dataset constructed to
understand human activities in real-world settings. DARai consists of
continuous scripted and unscripted recordings of 50 participants in 10
different environments, totaling over 200 hours of data from 20 sensors
including multiple camera views, depth and radar sensors, wearable inertial
measurement units (IMUs), electromyography (EMG), insole pressure sensors,
biomonitor sensors, and gaze tracker.
  To capture the complexity in human activities, DARai is annotated at three
levels of hierarchy: (i) high-level activities (L1) that are independent tasks,
(ii) lower-level actions (L2) that are patterns shared between activities, and
(iii) fine-grained procedures (L3) that detail the exact execution steps for
actions. The dataset annotations and recordings are designed so that 22.7% of
L2 actions are shared between L1 activities and 14.2% of L3 procedures are
shared between L2 actions. The overlap and unscripted nature of DARai allows
counterfactual activities in the dataset.
  Experiments with various machine learning models showcase the value of DARai
in uncovering important challenges in human-centered applications.
Specifically, we conduct unimodal and multimodal sensor fusion experiments for
recognition, temporal localization, and future action anticipation across all
hierarchical annotation levels. To highlight the limitations of individual
sensors, we also conduct domain-variant experiments that are enabled by DARai's
multi-sensor and counterfactual activity design setup.
  The code, documentation, and dataset are available at the dedicated DARai
website:
https://alregib.ece.gatech.edu/software-and-datasets/darai-daily-activity-recordings-for-artificial-intelligence-and-machine-learning/

</details>


### [59] [Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields](https://arxiv.org/abs/2504.17712)
*Zhuo He,Paul Henderson,Nicolas Pugeault*

Main category: cs.CV

TL;DR: 论文提出了一种基于生成场理论的新方法，改进了StyleGAN中特征合成的控制能力，利用通道风格潜在空间S实现解耦控制。


<details>
  <summary>Details</summary>
Motivation: 解决StyleGAN中由于潜在空间纠缠导致的生成图像特征控制困难问题，提升特征合成的直接性和灵活性。

Method: 引入生成场理论解释StyleGAN的层次特征合成，提出基于通道风格潜在空间S的图像编辑流程，利用CNN的固有结构特征实现解耦控制。

Result: 通过生成场理论和S空间，实现了对StyleGAN特征合成的更直接和灵活控制。

Conclusion: 生成场理论和S空间的应用为StyleGAN提供了更高效的特征控制方法，扩展了其实际应用潜力。

Abstract: StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic
faces of imaginary people from random noise. One limitation of GAN-based image
generation is the difficulty of controlling the features of the generated
image, due to the strong entanglement of the low-dimensional latent space.
Previous work that aimed to control StyleGAN with image or text prompts
modulated sampling in W latent space, which is more expressive than Z latent
space. However, W space still has restricted expressivity since it does not
control the feature synthesis directly; also the feature embedding in W space
requires a pre-training process to reconstruct the style signal, limiting its
application. This paper introduces the concept of "generative fields" to
explain the hierarchical feature synthesis in StyleGAN, inspired by the
receptive fields of convolution neural networks (CNNs). Additionally, we
propose a new image editing pipeline for StyleGAN using generative field theory
and the channel-wise style latent space S, utilizing the intrinsic structural
feature of CNNs to achieve disentangled control of feature synthesis at
synthesis time.

</details>


### [60] [DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt State Space Model](https://arxiv.org/abs/2504.17732)
*Zhanwen Liu,Sai Zhou,Yuchao Dai,Yang Wang,Yisheng An,Xiangmo Zhao*

Main category: cs.CV

TL;DR: DPMambaIR是一个新型的All-in-One图像修复框架，通过Degradation-Aware Prompt State Space Model和High-Frequency Enhancement Block实现细粒度退化建模和高频细节增强，显著提升多任务修复性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法针对每种退化类型设计专用模型，成本高且复杂。现有方法缺乏细粒度退化建模和多任务冲突平衡能力。

Method: 结合DP-SSM（细粒度退化特征建模）和HEB（高频细节补充），动态整合退化信息并增强全局修复效果。

Result: 在包含七种退化类型的混合数据集上，DPMambaIR取得最佳性能（PSNR 27.69dB，SSIM 0.893）。

Conclusion: DPMambaIR作为统一解决方案，展示了All-in-One图像修复的潜力和优越性。

Abstract: All-in-One image restoration aims to address multiple image degradation
problems using a single model, significantly reducing training costs and
deployment complexity compared to traditional methods that design dedicated
models for each degradation type. Existing approaches typically rely on
Degradation-specific models or coarse-grained degradation prompts to guide
image restoration. However, they lack fine-grained modeling of degradation
information and face limitations in balancing multi-task conflicts. To overcome
these limitations, we propose DPMambaIR, a novel All-in-One image restoration
framework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)
and a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained
modeling of complex degradation information and efficient global integration,
while mitigating the loss of high-frequency details caused by task competition.
Specifically, the DP-SSM utilizes a pre-trained degradation extractor to
capture fine-grained degradation features and dynamically incorporates them
into the state space modeling process, enhancing the model's adaptability to
diverse degradation types. Concurrently, the HEB supplements high-frequency
information, effectively addressing the loss of critical details, such as edges
and textures, in multi-task image restoration scenarios. Extensive experiments
on a mixed dataset containing seven degradation types show that DPMambaIR
achieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,
respectively. These results highlight the potential and superiority of
DPMambaIR as a unified solution for All-in-One image restoration.

</details>


### [61] [EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an Egocentric IMU Sensor](https://arxiv.org/abs/2504.17735)
*Akhil Padmanabha,Saravanan Govindarajan,Hwanmun Kim,Sergio Ortiz,Rahul Rajan,Doruk Senkal,Sneha Kadetotad*

Main category: cs.CV

TL;DR: EgoCHARM是一种资源高效的机器学习算法，用于通过头戴式IMU识别高、低层次活动，采用半监督学习策略，性能优越且模型轻量。


<details>
  <summary>Details</summary>
Motivation: 当前以自我为中心的活动识别方法性能低或资源消耗大，EgoCHARM旨在解决这一问题。

Method: 采用分层算法和半监督学习策略，利用高层次活动标签训练，学习通用低层次运动嵌入。

Result: 在9种高层次和3种低层次活动上，F1分数分别为0.826和0.855，模型参数仅63k和22k。

Conclusion: EgoCHARM展示了在资源受限设备上高效活动识别的潜力，同时分析了其机会与限制。

Abstract: Human activity recognition (HAR) on smartglasses has various use cases,
including health/fitness tracking and input for context-aware AI assistants.
However, current approaches for egocentric activity recognition suffer from low
performance or are resource-intensive. In this work, we introduce a resource
(memory, compute, power, sample) efficient machine learning algorithm,
EgoCHARM, for recognizing both high level and low level activities using a
single egocentric (head-mounted) Inertial Measurement Unit (IMU). Our
hierarchical algorithm employs a semi-supervised learning strategy, requiring
primarily high level activity labels for training, to learn generalizable low
level motion embeddings that can be effectively utilized for low level activity
recognition. We evaluate our method on 9 high level and 3 low level activities
achieving 0.826 and 0.855 F1 scores on high level and low level activity
recognition respectively, with just 63k high level and 22k low level model
parameters, allowing the low level encoder to be deployed directly on current
IMU chips with compute. Lastly, we present results and insights from a
sensitivity analysis and highlight the opportunities and limitations of
activity recognition using egocentric IMUs.

</details>


### [62] [Step1X-Edit: A Practical Framework for General Image Editing](https://arxiv.org/abs/2504.17761)
*Shiyu Liu,Yucheng Han,Peng Xing,Fukun Yin,Rui Wang,Wei Cheng,Jiaqi Liao,Yingming Wang,Honghao Fu,Chunrui Han,Guopeng Li,Yuang Peng,Quan Sun,Jingwei Wu,Yan Cai,Zheng Ge,Ranchen Ming,Lei Xia,Xianfang Zeng,Yibo Zhu,Binxing Jiao,Xiangyu Zhang,Gang Yu,Daxin Jiang*

Main category: cs.CV

TL;DR: 论文提出了一种名为Step1X-Edit的开源图像编辑模型，旨在缩小与闭源模型（如GPT-4o和Gemini2 Flash）的性能差距。通过多模态LLM处理图像和用户指令，结合扩散图像解码器生成目标图像，并在新基准GEdit-Bench上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在图像编辑领域取得显著进展，但开源算法与闭源模型之间仍存在较大差距。本文旨在填补这一空白，提供性能接近闭源模型的开源解决方案。

Method: 采用多模态LLM处理参考图像和用户指令，提取潜在嵌入并与扩散图像解码器结合生成目标图像。通过数据生成管道构建高质量训练数据集。

Result: 在GEdit-Bench基准测试中，Step1X-Edit显著优于现有开源基线，并接近领先闭源模型的性能。

Conclusion: Step1X-Edit为图像编辑领域提供了高性能的开源替代方案，缩小了与闭源模型的差距。

Abstract: In recent years, image editing models have witnessed remarkable and rapid
development. The recent unveiling of cutting-edge multimodal models such as
GPT-4o and Gemini2 Flash has introduced highly promising image editing
capabilities. These models demonstrate an impressive aptitude for fulfilling a
vast majority of user-driven editing requirements, marking a significant
advancement in the field of image manipulation. However, there is still a large
gap between the open-source algorithm with these closed-source models. Thus, in
this paper, we aim to release a state-of-the-art image editing model, called
Step1X-Edit, which can provide comparable performance against the closed-source
models like GPT-4o and Gemini2 Flash. More specifically, we adopt the
Multimodal LLM to process the reference image and the user's editing
instruction. A latent embedding has been extracted and integrated with a
diffusion image decoder to obtain the target image. To train the model, we
build a data generation pipeline to produce a high-quality dataset. For
evaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world
user instructions. Experimental results on GEdit-Bench demonstrate that
Step1X-Edit outperforms existing open-source baselines by a substantial margin
and approaches the performance of leading proprietary models, thereby making
significant contributions to the field of image editing.

</details>


### [63] [The Fourth Monocular Depth Estimation Challenge](https://arxiv.org/abs/2504.17787)
*Anton Obukhov,Matteo Poggi,Fabio Tosi,Ripudaman Singh Arora,Jaime Spencer,Chris Russell,Simon Hadfield,Richard Bowden,Shuaihang Wang,Zhenxin Ma,Weijie Chen,Baobei Xu,Fengyu Sun,Di Xie,Jiang Zhu,Mykola Lavreniuk,Haining Guan,Qun Wu,Yupei Zeng,Chao Lu,Huanran Wang,Guangyuan Zhou,Haotian Zhang,Jianxiong Wang,Qiang Rao,Chunjie Wang,Xiao Liu,Zhiqiang Lou,Hualie Jiang,Yihao Chen,Rui Xu,Minglang Tan,Zihan Qin,Yifan Mao,Jiayang Liu,Jialei Xu,Yifan Yang,Wenbo Zhao,Junjun Jiang,Xianming Liu,Mingshuai Zhao,Anlong Ming,Wu Chen,Feng Xue,Mengying Yu,Shida Gao,Xiangfeng Wang,Gbenga Omotara,Ramy Farag,Jacket Demby,Seyed Mohamad Ali Tousi,Guilherme N DeSouza,Tuan-Anh Yang,Minh-Quang Nguyen,Thien-Phuc Tran,Albert Luginov,Muhammad Shahzad*

Main category: cs.CV

TL;DR: 第四版单目深度估计挑战赛（MDEC）聚焦于零样本泛化到SYNS-Patches基准测试，改进了评估协议和基线方法，24个提交结果优于基线，其中10个提供了方法描述，获胜者将3D F-Score从22.58%提升至23.05%。


<details>
  <summary>Details</summary>
Motivation: 挑战赛旨在推动单目深度估计在复杂自然和室内环境中的零样本泛化能力。

Method: 修订了评估协议，采用最小二乘对齐支持视差和仿射不变预测，并引入Depth Anything v2和Marigold作为基线方法。

Result: 24个提交结果优于基线，获胜方法将3D F-Score从22.58%提升至23.05%。

Conclusion: 挑战赛展示了仿射不变预测方法的有效性，并推动了单目深度估计技术的进步。

Abstract: This paper presents the results of the fourth edition of the Monocular Depth
Estimation Challenge (MDEC), which focuses on zero-shot generalization to the
SYNS-Patches benchmark, a dataset featuring challenging environments in both
natural and indoor settings. In this edition, we revised the evaluation
protocol to use least-squares alignment with two degrees of freedom to support
disparity and affine-invariant predictions. We also revised the baselines and
included popular off-the-shelf methods: Depth Anything v2 and Marigold. The
challenge received a total of 24 submissions that outperformed the baselines on
the test set; 10 of these included a report describing their approach, with
most leading methods relying on affine-invariant predictions. The challenge
winners improved the 3D F-Score over the previous edition's best result,
raising it from 22.58% to 23.05%.

</details>


### [64] [Dynamic Camera Poses and Where to Find Them](https://arxiv.org/abs/2504.17788)
*Chris Rockwell,Joseph Tung,Tsung-Yi Lin,Ming-Yu Liu,David F. Fouhey,Chen-Hsuan Lin*

Main category: cs.CV

TL;DR: DynPose-100K是一个大规模动态互联网视频数据集，标注了相机位姿，解决了现有方法的局限性，并提出了新的采集和标注流程。


<details>
  <summary>Details</summary>
Motivation: 动态互联网视频的相机位姿标注对视频生成和模拟等领域至关重要，但现有数据集和方法难以满足需求。

Method: 结合任务特定和通用模型进行视频筛选，并采用点跟踪、动态掩码和运动结构恢复技术进行位姿估计。

Result: DynPose-100K数据集规模大且多样化，优于现有方法，为下游应用提供了新机会。

Conclusion: DynPose-100K为动态视频位姿标注提供了有效解决方案，推动了相关领域的发展。

Abstract: Annotating camera poses on dynamic Internet videos at scale is critical for
advancing fields like realistic video generation and simulation. However,
collecting such a dataset is difficult, as most Internet videos are unsuitable
for pose estimation. Furthermore, annotating dynamic Internet videos present
significant challenges even for state-of-theart methods. In this paper, we
introduce DynPose-100K, a large-scale dataset of dynamic Internet videos
annotated with camera poses. Our collection pipeline addresses filtering using
a carefully combined set of task-specific and generalist models. For pose
estimation, we combine the latest techniques of point tracking, dynamic
masking, and structure-from-motion to achieve improvements over the
state-of-the-art approaches. Our analysis and experiments demonstrate that
DynPose-100K is both large-scale and diverse across several key attributes,
opening up avenues for advancements in various downstream applications.

</details>


### [65] [Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models](https://arxiv.org/abs/2504.17789)
*Xu Ma,Peize Sun,Haoyu Ma,Hao Tang,Chih-Yao Ma,Jialiang Wang,Kunpeng Li,Xiaoliang Dai,Yujun Shi,Xuan Ju,Yushi Hu,Artsiom Sanakoyeu,Felix Juefei-Xu,Ji Hou,Junjiao Tian,Tao Xu,Tingbo Hou,Yen-Cheng Liu,Zecheng He,Zijian He,Matt Feiszli,Peizhao Zhang,Peter Vajda,Sam Tsai,Yun Fu*

Main category: cs.CV

TL;DR: Token-Shuffle是一种新方法，通过减少Transformer中的图像标记数量，解决了自回归模型在图像合成中的效率问题，支持高分辨率图像生成。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在图像合成中因标记数量多而效率低下，限制了分辨率和性能。

Method: 提出Token-Shuffle和Token-Unshuffle操作，利用视觉词汇的维度冗余减少标记数量，结合文本提示联合训练。

Result: 在2048x2048分辨率下实现高效生成，性能优于其他自回归和扩散模型。

Conclusion: Token-Shuffle为MLLMs中的高效高分辨率图像生成提供了基础设计。

Abstract: Autoregressive (AR) models, long dominant in language generation, are
increasingly applied to image synthesis but are often considered less
competitive than Diffusion-based models. A primary limitation is the
substantial number of image tokens required for AR models, which constrains
both training and inference efficiency, as well as image resolution. To address
this, we present Token-Shuffle, a novel yet simple method that reduces the
number of image tokens in Transformer. Our key insight is the dimensional
redundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),
where low-dimensional visual codes from visual encoder are directly mapped to
high-dimensional language vocabularies. Leveraging this, we consider two key
operations: token-shuffle, which merges spatially local tokens along channel
dimension to decrease the input token number, and token-unshuffle, which
untangles the inferred tokens after Transformer blocks to restore the spatial
arrangement for output. Jointly training with textual prompts, our strategy
requires no additional pretrained text-encoder and enables MLLMs to support
extremely high-resolution image synthesis in a unified next-token prediction
way while maintaining efficient training and inference. For the first time, we
push the boundary of AR text-to-image generation to a resolution of 2048x2048
with gratifying generation performance. In GenAI-benchmark, our 2.7B model
achieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen
by 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human
evaluations also demonstrate our prominent image generation ability in terms of
text-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle
can serve as a foundational design for efficient high-resolution image
generation within MLLMs.

</details>


### [66] [LiDPM: Rethinking Point Diffusion for Lidar Scene Completion](https://arxiv.org/abs/2504.17791)
*Tetiana Martyniuk,Gilles Puy,Alexandre Boulch,Renaud Marlet,Raoul de Charette*

Main category: cs.CV

TL;DR: 论文提出LiDPM方法，证明在场景级别完成时，无需局部扩散近似，标准DDPM即可实现更好效果。


<details>
  <summary>Details</summary>
Motivation: 解决在室外场景中直接训练扩散模型生成精细点云的挑战，弥合局部扩散与对象级别扩散的差距。

Method: 采用标准DDPM，选择合适的起始点，避免局部扩散的近似。

Result: 在SemanticKITTI上取得更好的场景完成效果。

Conclusion: LiDPM方法验证了标准DDPM在场景级别任务中的有效性。

Abstract: Training diffusion models that work directly on lidar points at the scale of
outdoor scenes is challenging due to the difficulty of generating fine-grained
details from white noise over a broad field of view. The latest works
addressing scene completion with diffusion models tackle this problem by
reformulating the original DDPM as a local diffusion process. It contrasts with
the common practice of operating at the level of objects, where vanilla DDPMs
are currently used. In this work, we close the gap between these two lines of
work. We identify approximations in the local diffusion formulation, show that
they are not required to operate at the scene level, and that a vanilla DDPM
with a well-chosen starting point is enough for completion. Finally, we
demonstrate that our method, LiDPM, leads to better results in scene completion
on SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [67] [ePBR: Extended PBR Materials in Image Synthesis](https://arxiv.org/abs/2504.17062)
*Yu Guo,Zhiqiang Lao,Xiyun Song,Yubin Zhou,Zongfang Lin,Heather Yu*

Main category: cs.GR

TL;DR: 论文提出了一种扩展的物理渲染（ePBR）材料方法，结合反射和透射特性，用于合成透明材料（如玻璃和窗户），并通过明确的本征合成框架实现可控的图像合成。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理的渲染（PBR）材料难以处理高镜面和透明表面，而本征图像表示在可控合成方面提供了平衡的解决方案。

Method: 扩展本征图像表示以包含反射和透射特性，提出明确的合成框架（ePBR材料）以实现精确控制。

Result: 能够有效编辑透明材料，提供确定性和可解释的图像合成。

Conclusion: ePBR材料为复杂表面（如透明材料）的合成提供了高效且可控的解决方案。

Abstract: Realistic indoor or outdoor image synthesis is a core challenge in computer
vision and graphics. The learning-based approach is easy to use but lacks
physical consistency, while traditional Physically Based Rendering (PBR) offers
high realism but is computationally expensive. Intrinsic image representation
offers a well-balanced trade-off, decomposing images into fundamental
components (intrinsic channels) such as geometry, materials, and illumination
for controllable synthesis. However, existing PBR materials struggle with
complex surface models, particularly high-specular and transparent surfaces. In
this work, we extend intrinsic image representations to incorporate both
reflection and transmission properties, enabling the synthesis of transparent
materials such as glass and windows. We propose an explicit intrinsic
compositing framework that provides deterministic, interpretable image
synthesis. With the Extended PBR (ePBR) Materials, we can effectively edit the
materials with precise controls.

</details>


### [68] [Bolt: Clothing Virtual Characters at Scale](https://arxiv.org/abs/2504.17614)
*Jonathan Leaf,David Sebastian Minor,Gilles Daviet,Nuttapong Chentanez,Greg Klar,Ed Quigley*

Main category: cs.GR

TL;DR: Bolt系统通过三阶段（转移、悬挂、绑定）自动将服装从源身体适配到新身体形状，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 服装虚拟角色是耗时且通常需要手动完成的任务，尤其是当角色形状差异大时，适配问题变得复杂。

Method: 1. 转移：优化3D网格和2D缝纫图案；2. 悬挂：模拟服装逐步悬挂和解缠；3. 绑定：将服装绑定到新角色。

Result: 系统实现了自动化服装适配，适用于大规模角色服装需求。

Conclusion: Bolt系统显著提高了服装适配效率，适用于游戏、动画等多种应用。

Abstract: Clothing virtual characters is a time-consuming and often manual process.
Outfits can be composed of multiple garments, and each garment must be fitted
to the unique shape of a character. Since characters can vary widely in size
and shape, fitting outfits to many characters is a combinatorially large
problem. We present Bolt, a system designed to take outfits originally authored
on a source body and fit them to new body shapes via a three stage transfer,
drape, and rig process. First, our new garment transfer method transforms each
garment's 3D mesh positions to the new character, then optimizes the garment's
2D sewing pattern while maintaining key features of the original seams and
boundaries. Second, our system simulates the transferred garments to
progressively drape and untangle each garment in the outfit. Finally, the
garments are rigged to the new character. This entire process is automatic,
making it feasible to clothe characters at scale with no human intervention.
Clothed characters are then ready for immediate use in applications such as
gaming, animation, synthetic generation, and more.

</details>


### [69] [CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos](https://arxiv.org/abs/2504.17728)
*Shucheng Gong,Lingzhe Zhao,Wenpu Li,Hong Xie,Yin Zhang,Shiyu Zhao,Peidong Liu*

Main category: cs.GR

TL;DR: 提出了一种名为CasualHDRSplat的单阶段方法，用于从随意拍摄的视频中重建3D HDR场景，解决了现有方法依赖固定曝光和多视角图像的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有HDR场景重建方法需要固定相机位置和多曝光图像，耗时且不灵活。CasualHDRSplat旨在通过随意拍摄的视频实现高效、鲁棒的HDR重建。

Method: 提出了一种统一的微分物理成像模型，结合连续时间轨迹约束，联合优化曝光时间、相机响应函数、相机位姿和清晰3D HDR场景。

Result: 实验表明，CasualHDRSplat在鲁棒性和渲染质量上优于现有方法。

Conclusion: CasualHDRSplat提供了一种灵活高效的HDR场景重建方案，适用于实际应用。

Abstract: Recently, photo-realistic novel view synthesis from multi-view images, such
as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered
widespread attention due to their superior performance. However, most works
rely on low dynamic range (LDR) images, which limits the capturing of richer
scene details. Some prior works have focused on high dynamic range (HDR) scene
reconstruction, typically require capturing of multi-view sharp images with
different exposure times at fixed camera positions during exposure times, which
is time-consuming and challenging in practice. For a more flexible data
acquisition, we propose a one-stage method: \textbf{CasualHDRSplat} to easily
and robustly reconstruct the 3D HDR scene from casually captured videos with
auto-exposure enabled, even in the presence of severe motion blur and varying
unknown exposure time. \textbf{CasualHDRSplat} contains a unified
differentiable physical imaging model which first applies continuous-time
trajectory constraint to imaging process so that we can jointly optimize
exposure time, camera response function (CRF), camera poses, and sharp 3D HDR
scene. Extensive experiments demonstrate that our approach outperforms existing
methods in terms of robustness and rendering quality. Our source code will be
available at https://github.com/WU-CVGL/CasualHDRSplat

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [70] [Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity](https://arxiv.org/abs/2504.16956)
*Cong Qi,Hanzhang Fang,Tianxing Hu,Siqi Jiang,Wei Zhi*

Main category: cs.CL

TL;DR: GeneMamba是一种基于状态空间建模的单细胞转录组学基础模型，通过Bi-Mamba架构实现线性时间复杂度的双向基因上下文捕捉，优于传统Transformer方法。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序（scRNA-seq）的高维度、稀疏性和批次效应带来了计算挑战，现有Transformer模型因二次复杂度和长程依赖处理不足而受限。

Method: GeneMamba采用Bi-Mamba架构，结合生物学目标（如通路感知对比损失和基于排名的基因编码），在3000万细胞上预训练。

Result: 在多批次整合、细胞类型注释和基因-基因相关性等任务中表现优异，具有强健性和可解释性。

Conclusion: GeneMamba是Transformer方法的实用替代方案，推动了大规模单细胞数据分析工具的发展。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of
cellular heterogeneity, but its complexity, which is marked by high
dimensionality, sparsity, and batch effects, which poses major computational
challenges. Transformer-based models have made significant advances in this
domain but are often limited by their quadratic complexity and suboptimal
handling of long-range dependencies. In this work, we introduce GeneMamba, a
scalable and efficient foundation model for single-cell transcriptomics built
on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba
captures bidirectional gene context with linear-time complexity, offering
substantial computational gains over transformer baselines. The model is
pretrained on nearly 30 million cells and incorporates biologically informed
objectives, including pathway-aware contrastive loss and rank-based gene
encoding. We evaluate GeneMamba across diverse tasks, including multi-batch
integration, cell type annotation, and gene-gene correlation, demonstrating
strong performance, interpretability, and robustness. These results position
GeneMamba as a practical and powerful alternative to transformer-based methods,
advancing the development of biologically grounded, scalable tools for
large-scale single-cell data analysis.

</details>


### [71] [Tokenization Matters: Improving Zero-Shot NER for Indic Languages](https://arxiv.org/abs/2504.16977)
*Priyaranjan Pattnayak,Hitesh Laxmichand Patel,Amit Agarwal*

Main category: cs.CL

TL;DR: 论文比较了BPE、SentencePiece和字符级分词策略在低资源印度语言NER任务中的表现，发现SentencePiece在跨语言零样本设置中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究BPE在低资源印度语言NER任务中的适用性不足，尤其是对形态复杂语言的处理。

Method: 使用IndicBERT对多种印度语言（如阿萨姆语、孟加拉语等）进行BPE、SentencePiece和字符级分词的对比实验。

Result: SentencePiece在跨语言零样本设置中表现优于BPE，尤其在形态丰富的语言（如Santali、Manipuri）中。

Conclusion: SentencePiece是低资源印度语言NER任务中更有效的分词策略。

Abstract: Tokenization is a critical component of Natural Language Processing (NLP),
especially for low resource languages, where subword segmentation influences
vocabulary structure and downstream task accuracy. Although Byte Pair Encoding
(BPE) is a standard tokenization method in multilingual language models, its
suitability for Named Entity Recognition (NER) in low resource Indic languages
remains underexplored due to its limitations in handling morphological
complexity. In this work, we systematically compare BPE, SentencePiece, and
Character Level tokenization strategies using IndicBERT for NER tasks in low
resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as
extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We
assess both intrinsic linguistic properties tokenization efficiency, out of
vocabulary (OOV) rates, and morphological preservation as well as extrinsic
downstream performance, including fine tuning and zero shot cross lingual
transfer.
  Our experiments show that SentencePiece is a consistently better performing
approach than BPE for NER in low resource Indic Languages, particularly in zero
shot cross lingual settings, as it better preserves entity consistency. While
BPE provides the most compact tokenization form, it is not capable of
generalization because it misclassifies or even fails to recognize entity
labels when tested on unseen languages. In contrast, SentencePiece constitutes
a better linguistic structural preservation model, benefiting extremely low
resource and morphologically rich Indic languages, such as Santali and
Manipuri, for superior entity recognition, as well as high generalization
across scripts, such as Sindhi, written in Arabic. The results point to
SentencePiece as the more effective tokenization strategy for NER within
multilingual and low resource Indic NLP applications.

</details>


### [72] [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org/abs/2504.17025)
*Luca Moroni,Giovanni Puccetti,Pere-Lluis Huguet Cabot,Andrei Stefan Bejgu,Edoardo Barba,Alessio Miaschi,Felice Dell'Orletta,Andrea Esuli,Roberto Navigli*

Main category: cs.CL

TL;DR: 论文提出了一种名为SAVA的新方法，用于优化英语大语言模型（LLM）在意大利语中的表现，通过词汇替换减少token数量并提升效率。


<details>
  <summary>Details</summary>
Motivation: 当前大多数LLM主要针对英语设计，对其他语言的支持不足，导致编码效率低和推理速度慢。

Method: 提出了SAVA方法，利用神经映射进行词汇替换，优化词汇表并减少参数。

Result: 在多个下游任务中表现优异，减少了token数量（如Mistral-7b-v0.1减少25%）和参数（如Llama-3.1-8B减少10亿）。

Conclusion: SAVA方法能有效优化LLM对非英语语言的支持，并通过少量持续训练恢复性能。

Abstract: The number of pretrained Large Language Models (LLMs) is increasing steadily,
though the majority are designed predominantly for the English language. While
state-of-the-art LLMs can handle other languages, due to language contamination
or some degree of multilingual pretraining data, they are not optimized for
non-English languages, leading to inefficient encoding (high token "fertility")
and slower inference speed. In this work, we thoroughly compare a variety of
vocabulary adaptation techniques for optimizing English LLMs for the Italian
language, and put forward Semantic Alignment Vocabulary Adaptation (SAVA), a
novel method that leverages neural mapping for vocabulary substitution. SAVA
achieves competitive performance across multiple downstream tasks, enhancing
grounded alignment strategies. We adapt two LLMs: Mistral-7b-v0.1, reducing
token fertility by 25\%, and Llama-3.1-8B, optimizing the vocabulary and
reducing the number of parameters by 1 billion. We show that, following the
adaptation of the vocabulary, these models can recover their performance with a
relatively limited stage of continual training on the target language. Finally,
we test the capabilities of the adapted models on various multi-choice and
generative tasks.

</details>


### [73] [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org/abs/2504.17052)
*Shariar Kabir,Kevin Esterling,Yue Dong*

Main category: cs.CL

TL;DR: 论文提出了一种评估大型语言模型（LLM）政治立场深度的方法，发现其响应更多是主题特定的稳定性，而非统一的意识形态立场。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM的政治响应是真实信念还是表面与训练数据对齐。

Method: 通过分析（1）论证一致性和（2）不确定性量化，评估12个LLM在19项经济政策上的表现。

Result: 结果显示，左倾和右倾模型的响应在挑战下分别有95%和89%的一致性，语义熵能有效区分表面对齐与真实信念（AUROC=0.78）。

Conclusion: 结论指出LLM未必具有稳定的人类意识形态，强调需进行主题特定的可靠性评估。

Abstract: Large Language Models (LLMs) are increasingly shaping political discourse,
yet their responses often display inconsistency when subjected to scrutiny.
While prior research has primarily categorized LLM outputs as left- or
right-leaning to assess their political stances, a critical question remains:
Do these responses reflect genuine internal beliefs or merely surface-level
alignment with training data? To address this, we propose a novel framework for
evaluating belief depth by analyzing (1) argumentative consistency and (2)
uncertainty quantification. We evaluate 12 LLMs on 19 economic policies from
the Political Compass Test, challenging their belief stability with both
supportive and opposing arguments. Our analysis reveals that LLMs exhibit
topic-specific belief stability rather than a uniform ideological stance.
Notably, up to 95% of left-leaning models' responses and 89% of right-leaning
models' responses remain consistent under the challenge, enabling semantic
entropy to achieve high accuracy (AUROC=0.78), effectively distinguishing
between surface-level alignment from genuine belief. These findings call into
question the assumption that LLMs maintain stable, human-like political
ideologies, emphasizing the importance of conducting topic-specific reliability
assessments for real-world applications.

</details>


### [74] [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org/abs/2504.17075)
*Arjun Subramonian,Vagrant Gautam,Preethi Seshadri,Dietrich Klakow,Kai-Wei Chang,Yizhou Sun*

Main category: cs.CL

TL;DR: 本文研究了LLM性别错误评估方法的收敛效度，发现不同方法在实例、数据集和模型层面上存在不一致，且自动评估与人类评估存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探讨现有LLM性别错误评估方法是否具有收敛效度，即不同方法的结果是否一致。

Method: 对三个现有数据集进行系统元评估，提出一种方法以支持并行概率和生成评估，并自动评估6个模型。

Result: 发现评估方法之间存在20.2%的实例冲突，自动评估未能捕捉性别错误的复杂性。

Conclusion: 建议未来评估需改进方法，并质疑LLM评估中广泛假设不同方法一致性的惯例。

Abstract: Numerous methods have been proposed to measure LLM misgendering, including
probability-based evaluations (e.g., automatically with templatic sentences)
and generation-based evaluations (e.g., with automatic heuristics or human
validation). However, it has gone unexamined whether these evaluation methods
have convergent validity, that is, whether their results align. Therefore, we
conduct a systematic meta-evaluation of these methods across three existing
datasets for LLM misgendering. We propose a method to transform each dataset to
enable parallel probability- and generation-based evaluation. Then, by
automatically evaluating a suite of 6 models from 3 families, we find that
these methods can disagree with each other at the instance, dataset, and model
levels, conflicting on 20.2% of evaluation instances. Finally, with a human
evaluation of 2400 LLM generations, we show that misgendering behaviour is
complex and goes far beyond pronouns, which automatic evaluations are not
currently designed to capture, suggesting essential disagreement with human
evaluations. Based on our findings, we provide recommendations for future
evaluations of LLM misgendering. Our results are also more widely relevant, as
they call into question broader methodological conventions in LLM evaluation,
which often assume that different evaluation methods agree.

</details>


### [75] [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org/abs/2504.17083)
*Rendi Chevi,Kentaro Inui,Thamar Solorio,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 研究发现，LLM的语言风格（如权威性、确定性、表达清晰度等）显著影响用户偏好，但具体影响因用户群体和个体特质而异。需注意样本局限，未来将扩大研究范围和多样性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM的语言风格如何影响用户偏好，以及这种影响的潜在双刃剑效应（提升体验与增加风险）。

Method: 通过探索性和实验性用户研究，分析不同语言风格对用户偏好的影响。

Result: 语言风格确实影响用户偏好，但具体影响因用户群体和个体特质而异。样本局限需谨慎解读。

Conclusion: 初步研究表明语言风格对用户偏好有影响，未来需扩大样本并深入分析变量间的因果关系。

Abstract: What makes an interaction with the LLM more preferable for the user? While it
is intuitive to assume that information accuracy in the LLM's responses would
be one of the influential variables, recent studies have found that inaccurate
LLM's responses could still be preferable when they are perceived to be more
authoritative, certain, well-articulated, or simply verbose. These variables
interestingly fall under the broader category of language style, implying that
the style in the LLM's responses might meaningfully influence users'
preferences. This hypothesized dynamic could have double-edged consequences:
enhancing the overall user experience while simultaneously increasing their
susceptibility to risks such as LLM's misinformation or hallucinations. In this
short paper, we present our preliminary studies in exploring this subject.
Through a series of exploratory and experimental user studies, we found that
LLM's language style does indeed influence user's preferences, but how and
which language styles influence the preference varied across different user
populations, and more interestingly, moderated by the user's very own
individual traits. As a preliminary work, the findings in our studies should be
interpreted with caution, particularly given the limitations in our samples,
which still need wider demographic diversity and larger sample sizes. Our
future directions will first aim to address these limitations, which would
enable a more comprehensive joint effect analysis between the language style,
individual traits, and preferences, and further investigate the potential
causal relationship between and beyond these variables.

</details>


### [76] [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org/abs/2504.17091)
*Seunghyun Yoo*

Main category: cs.CL

TL;DR: 提出了一种交互式思维链框架，通过透明化、模块化和用户可编辑的推理过程，提升AI的可解释性和负责任使用。


<details>
  <summary>Details</summary>
Motivation: 短内容泛滥和AI快速普及导致深度思考机会减少，削弱用户批判性思维和对AI输出的理解。

Method: 设计交互式思维链框架，分解推理为可检查、修改和重新执行的模块，并集成轻量级编辑适应机制。

Result: 框架增强了用户认知参与，支持多样化认知风格和意图，同时确保伦理透明和隐私保护。

Conclusion: 该框架为促进AI系统中的批判性参与、负责任互动和包容性适应提供了设计原则和架构。

Abstract: Due to the proliferation of short-form content and the rapid adoption of AI,
opportunities for deep, reflective thinking have significantly diminished,
undermining users' critical thinking and reducing engagement with the reasoning
behind AI-generated outputs. To address this issue, we propose an Interactive
Chain-of-Thought (CoT) Framework that enhances human-centered explainability
and responsible AI usage by making the model's inference process transparent,
modular, and user-editable. The framework decomposes reasoning into clearly
defined blocks that users can inspect, modify, and re-execute, encouraging
active cognitive engagement rather than passive consumption. It further
integrates a lightweight edit-adaptation mechanism inspired by preference
learning, allowing the system to align with diverse cognitive styles and user
intentions. Ethical transparency is ensured through explicit metadata
disclosure, built-in bias checkpoint functionality, and privacy-preserving
safeguards. This work outlines the design principles and architecture necessary
to promote critical engagement, responsible interaction, and inclusive
adaptation in AI systems aimed at addressing complex societal challenges.

</details>


### [77] [The Rise of Small Language Models in Healthcare: A Comprehensive Survey](https://arxiv.org/abs/2504.17119)
*Muskan Garg,Shaina Raza,Shebuti Rayana,Xingyi Liu,Sunghwan Sohn*

Main category: cs.CL

TL;DR: 本文综述了小型语言模型（SLMs）在医疗保健领域的应用，提出了一个分类框架，分析了其在资源受限环境中的优势，并提供了模型优化的最新进展和实验结果。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在医疗保健应用中取得了进展，但数据隐私和资源限制问题促使小型语言模型（SLMs）成为更具可扩展性和临床可行性的解决方案。

Method: 通过分类框架分析SLMs在三个维度（NLP任务、利益相关者角色和护理连续性）的表现，并探讨了模型构建、优化和压缩技术。

Result: 实验结果表明SLMs在医疗保健NLP任务中具有变革性潜力，并提供了更新的资源库。

Conclusion: SLMs为资源受限的医疗保健环境提供了高效解决方案，未来研究和开发可基于此框架进一步推进。

Abstract: Despite substantial progress in healthcare applications driven by large
language models (LLMs), growing concerns around data privacy, and limited
resources; the small language models (SLMs) offer a scalable and clinically
viable solution for efficient performance in resource-constrained environments
for next-generation healthcare informatics. Our comprehensive survey presents a
taxonomic framework to identify and categorize them for healthcare
professionals and informaticians. The timeline of healthcare SLM contributions
establishes a foundational framework for analyzing models across three
dimensions: NLP tasks, stakeholder roles, and the continuum of care. We present
a taxonomic framework to identify the architectural foundations for building
models from scratch; adapting SLMs to clinical precision through prompting,
instruction fine-tuning, and reasoning; and accessibility and sustainability
through compression techniques. Our primary objective is to offer a
comprehensive survey for healthcare professionals, introducing recent
innovations in model optimization and equipping them with curated resources to
support future research and development in the field. Aiming to showcase the
groundbreaking advancements in SLMs for healthcare, we present a comprehensive
compilation of experimental results across widely studied NLP tasks in
healthcare to highlight the transformative potential of SLMs in healthcare. The
updated repository is available at Github

</details>


### [78] [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org/abs/2504.17130)
*Hannah Cyberey,David Evans*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）的审查机制，通过表示工程技术找到控制模型输出审查的向量，并揭示了“思维抑制”这一额外维度。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs如何通过审查机制拒绝有害请求，并研究如何检测和控制这种审查行为。

Method: 使用表示工程技术，找到拒绝-服从向量以检测和控制模型输出的审查水平，并分析推理LLMs中的“思维抑制”现象。

Result: 发现了一种可以控制模型审查水平的向量，并揭示了“思维抑制”作为审查的额外维度。

Conclusion: 通过表示工程技术可以有效检测和控制LLMs的审查行为，为模型安全性和透明度提供了新视角。

Abstract: Large language models (LLMs) have transformed the way we access information.
These models are often tuned to refuse to comply with requests that are
considered harmful and to produce responses that better align with the
preferences of those who control the models. To understand how this
"censorship" works. We use representation engineering techniques to study
open-weights safety-tuned models. We present a method for finding a
refusal--compliance vector that detects and controls the level of censorship in
model outputs. We also analyze recent reasoning LLMs, distilled from
DeepSeek-R1, and uncover an additional dimension of censorship through "thought
suppression". We show a similar approach can be used to find a vector that
suppresses the model's reasoning process, allowing us to remove censorship by
applying the negative multiples of this vector

</details>


### [79] [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org/abs/2504.17137)
*Chanhee Park,Hyeonseok Moon,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: MIRAGE是一个专门为RAG系统评估设计的问答数据集，包含7,560个实例和37,800条检索条目，并引入了新的评估指标以衡量RAG的适应性。


<details>
  <summary>Details</summary>
Motivation: 由于RAG系统中检索与生成组件的复杂交互，现有评估方法存在局限性，缺乏详细的组件特定评估基准。

Method: 提出了MIRAGE数据集，包含大量实例和检索条目，并设计了新的评估指标（如噪声脆弱性、上下文可接受性等）。

Result: 通过实验揭示了RAG系统中模型对的最优对齐及其内部动态。

Conclusion: MIRAGE为RAG系统提供了高效的评估工具，数据集和代码已公开，便于研究使用。

Abstract: Retrieval-Augmented Generation (RAG) has gained prominence as an effective
method for enhancing the generative capabilities of Large Language Models
(LLMs) through the incorporation of external knowledge. However, the evaluation
of RAG systems remains a challenge, due to the intricate interplay between
retrieval and generation components. This limitation has resulted in a scarcity
of benchmarks that facilitate a detailed, component-specific assessment. In
this work, we present MIRAGE, a Question Answering dataset specifically
designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped
to a retrieval pool of 37,800 entries, enabling an efficient and precise
evaluation of both retrieval and generation tasks. We also introduce novel
evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions
such as noise vulnerability, context acceptability, context insensitivity, and
context misinterpretation. Through comprehensive experiments across various
retriever-LLM configurations, we provide new insights into the optimal
alignment of model pairs and the nuanced dynamics within RAG systems. The
dataset and evaluation code are publicly available, allowing for seamless
integration and customization in diverse research settings\footnote{The MIRAGE
code and data are available at https://github.com/nlpai-lab/MIRAGE.

</details>


### [80] [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org/abs/2504.17192)
*Minju Seo,Jinheon Baek,Seongyun Lee,Sung Ju Hwang*

Main category: cs.CL

TL;DR: PaperCoder是一个多智能体LLM框架，将机器学习论文转化为功能性代码仓库，分为规划、分析和生成三个阶段，并通过协作的智能体实现。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究中代码实现常不可用，导致复现和扩展工作耗时费力，而LLMs在理解科学文档和生成高质量代码方面表现出色。

Method: PaperCoder通过三个阶段实现：规划（设计架构、依赖关系和配置文件）、分析（解析实现细节）和生成（生成模块化代码），每个阶段由专门智能体协作完成。

Result: PaperCoder在生成高质量代码实现方面表现优异，在PaperBench基准测试中显著超越基线方法。

Conclusion: PaperCoder能有效生成高质量的代码实现，为机器学习研究提供实用工具。

Abstract: Despite the rapid growth of machine learning research, corresponding code
implementations are often unavailable, making it slow and labor-intensive for
researchers to reproduce results and build upon prior work. In the meantime,
recent Large Language Models (LLMs) excel at understanding scientific documents
and generating high-quality code. Inspired by this, we introduce PaperCoder, a
multi-agent LLM framework that transforms machine learning papers into
functional code repositories. PaperCoder operates in three stages: planning,
where it constructs a high-level roadmap, designs the system architecture with
diagrams, identifies file dependencies, and generates configuration files;
analysis, which focuses on interpreting implementation-specific details; and
generation, where modular, dependency-aware code is produced. Moreover, each
phase is instantiated through a set of specialized agents designed to
collaborate effectively across the pipeline. We then evaluate PaperCoder on
generating code implementations from machine learning papers based on both
model-based and human evaluations, specifically from the original paper
authors, with author-released repositories as ground truth if available. Our
results demonstrate the effectiveness of PaperCoder in creating high-quality,
faithful implementations. Furthermore, it consistently shows strengths in the
recently released PaperBench benchmark, surpassing strong baselines by
substantial margins.

</details>


### [81] [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org/abs/2504.17200)
*Yangxinyu Xie,Bowen Jiang,Tanwi Mallick,Joshua David Bergerson,John K. Hutchison,Duane R. Verner,Jordan Branham,M. Ross Alexander,Robert B. Ross,Yan Feng,Leslie-Anne Levy,Weijie Su,Camillo J. Taylor*

Main category: cs.CL

TL;DR: 提出了一种基于检索增强生成（RAG）的多智能体LLM系统WildfireGPT，用于自然灾害决策支持，显著优于现有LLM方案。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在提供特定领域（如自然灾害）的上下文信息时表现不足，需改进以支持决策。

Method: 采用RAG框架整合灾害数据、观测资料和科学文献，设计多智能体系统WildfireGPT，为用户提供定制化风险分析。

Result: 在十项专家案例研究中，WildfireGPT显著优于现有LLM决策支持方案。

Conclusion: WildfireGPT通过RAG和多智能体设计，有效提升了LLM在自然灾害领域的实用性和准确性。

Abstract: Large language models (LLMs) are a transformational capability at the
frontier of artificial intelligence and machine learning that can support
decision-makers in addressing pressing societal challenges such as extreme
natural hazard events. As generalized models, LLMs often struggle to provide
context-specific information, particularly in areas requiring specialized
knowledge. In this work we propose a retrieval-augmented generation (RAG)-based
multi-agent LLM system to support analysis and decision-making in the context
of natural hazards and extreme weather events. As a proof of concept, we
present WildfireGPT, a specialized system focused on wildfire hazards. The
architecture employs a user-centered, multi-agent design to deliver tailored
risk insights across diverse stakeholder groups. By integrating natural hazard
and extreme weather projection data, observational datasets, and scientific
literature through an RAG framework, the system ensures both the accuracy and
contextual relevance of the information it provides. Evaluation across ten
expert-led case studies demonstrates that WildfireGPT significantly outperforms
existing LLM-based solutions for decision support.

</details>


### [82] [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org/abs/2504.17220)
*Kaidong Feng,Zhu Sun,Jie Yang,Hui Fang,Xinghua Qu,Wenyuan Liu*

Main category: cs.CL

TL;DR: 研究探讨了知识蒸馏（KD）在LLM捆绑生成中的应用，旨在降低计算成本同时保持性能，提出了一个综合框架并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模LLM在捆绑生成中效率低下，计算成本高，知识蒸馏提供了一种高效解决方案。

Method: 提出一个综合KD框架，逐步提取知识、捕获不同量的知识，并结合LLM适应技术。

Result: 实验表明知识格式、数量及利用方法共同影响性能，KD在高效捆绑生成中潜力显著。

Conclusion: 知识蒸馏能显著提升LLM捆绑生成的效率与效果，为实际应用提供了可行方案。

Abstract: LLMs are increasingly explored for bundle generation, thanks to their
reasoning capabilities and knowledge. However, deploying large-scale LLMs
introduces significant efficiency challenges, primarily high computational
costs during fine-tuning and inference due to their massive parameterization.
Knowledge distillation (KD) offers a promising solution, transferring expertise
from large teacher models to compact student models. This study systematically
investigates knowledge distillation approaches for bundle generation, aiming to
minimize computational demands while preserving performance. We explore three
critical research questions: (1) how does the format of KD impact bundle
generation performance? (2) to what extent does the quantity of distilled
knowledge influence performance? and (3) how do different ways of utilizing the
distilled knowledge affect performance? We propose a comprehensive KD framework
that (i) progressively extracts knowledge (patterns, rules, deep thoughts);
(ii) captures varying quantities of distilled knowledge through different
strategies; and (iii) exploits complementary LLM adaptation techniques
(in-context learning, supervised fine-tuning, combination) to leverage
distilled knowledge in small student models for domain-specific adaptation and
enhanced efficiency. Extensive experiments provide valuable insights into how
knowledge format, quantity, and utilization methodologies collectively shape
LLM-based bundle generation performance, exhibiting KD's significant potential
for more efficient yet effective LLM-based bundle generation.

</details>


### [83] [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org/abs/2504.17238)
*Jinfeng Zhou,Yuxuan Chen,Jianing Yin,Yongkang Huang,Yihan Shi,Xikun Zhang,Libiao Peng,Rongsheng Zhang,Tangjie Lv,Zhipeng Hu,Hongning Wang,Minlie Huang*

Main category: cs.CL

TL;DR: CRDial是一个新框架，通过多轮对话实现认知重构，结合支持性对话策略和多通道循环机制，生成高质量双语数据集Crisp，并训练出表现优异的对话模型Crispers。


<details>
  <summary>Details</summary>
Motivation: 临床医生短缺和心理健康污名化促使开发人机交互心理治疗工具，现有方法未能有效模拟心理治疗过程。

Method: 提出CRDial框架，设计多轮对话阶段（识别与重构负面思想），整合支持性对话策略和多通道循环机制，生成数据集Crisp并训练对话模型Crispers。

Result: Crispers在点对点、成对和干预评估中表现优异。

Conclusion: CRDial和Crispers为认知重构提供了高效的人机交互解决方案。

Abstract: Cognitive Restructuring (CR) is a psychotherapeutic process aimed at
identifying and restructuring an individual's negative thoughts, arising from
mental health challenges, into more helpful and positive ones via multi-turn
dialogues. Clinician shortage and stigma urge the development of human-LLM
interactive psychotherapy for CR. Yet, existing efforts implement CR via simple
text rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to
align with the psychotherapeutic process for effective CR. To address this gap,
we propose CRDial, a novel framework for CR, which creates multi-turn dialogues
with specifically designed identification and restructuring stages of negative
thoughts, integrates sentence-level supportive conversation strategies, and
adopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we
distill Crisp, a large-scale and high-quality bilingual dialogue dataset, from
LLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and
14B scales. Extensive human studies show the superiority of Crispers in
pointwise, pairwise, and intervention evaluations.

</details>


### [84] [Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo](https://arxiv.org/abs/2504.17252)
*Ocheme Anthony Ekle,Biswarup Das*

Main category: cs.CL

TL;DR: 研究开发了基于RNN和Transformer的英语-伊博语翻译模型，通过迁移学习提升性能，BLEU分数提高4.83，达到70%的翻译准确率。


<details>
  <summary>Details</summary>
Motivation: 解决低资源非洲语言伊博语的机器翻译问题，填补性能差距。

Method: 使用RNN架构（LSTM和GRU）结合注意力机制，并应用迁移学习（MarianNMT预训练模型）。

Result: RNN模型表现接近现有基准，迁移学习使BLEU分数提升4.83，准确率达70%。

Conclusion: RNN结合迁移学习能有效提升低资源语言翻译性能。

Abstract: In this study, we develop Neural Machine Translation (NMT) and
Transformer-based transfer learning models for English-to-Igbo translation - a
low-resource African language spoken by over 40 million people across Nigeria
and West Africa. Our models are trained on a curated and benchmarked dataset
compiled from Bible corpora, local news, Wikipedia articles, and Common Crawl,
all verified by native language experts. We leverage Recurrent Neural Network
(RNN) architectures, including Long Short-Term Memory (LSTM) and Gated
Recurrent Units (GRU), enhanced with attention mechanisms to improve
translation accuracy. To further enhance performance, we apply transfer
learning using MarianNMT pre-trained models within the SimpleTransformers
framework. Our RNN-based system achieves competitive results, closely matching
existing English-Igbo benchmarks. With transfer learning, we observe a
performance gain of +4.83 BLEU points, reaching an estimated translation
accuracy of 70%. These findings highlight the effectiveness of combining RNNs
with transfer learning to address the performance gap in low-resource language
translation tasks.

</details>


### [85] [JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning](https://arxiv.org/abs/2504.17264)
*Zhaolu Kang,Hongtian Cai,Xiangyang Ji,Jinzhe Li,Nanfei Gu*

Main category: cs.CL

TL;DR: JurisCTC是一种新型模型，用于提升法律判决预测任务的准确性，通过对比学习实现跨法律领域的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 解决法律文本复杂且标注数据有限的问题，探索无监督领域适应在法律领域的应用。

Method: 提出JurisCTC模型，采用对比学习区分不同法律领域的样本，实现民事与刑事法律领域的知识迁移。

Result: JurisCTC在准确率上表现优异，分别达到76.59%和78.83%。

Conclusion: JurisCTC在法律判决预测任务中展现出显著优势，为跨法律领域知识迁移提供了有效解决方案。

Abstract: In recent years, Unsupervised Domain Adaptation (UDA) has gained significant
attention in the field of Natural Language Processing (NLP) owing to its
ability to enhance model generalization across diverse domains. However, its
application for knowledge transfer between distinct legal domains remains
largely unexplored. To address the challenges posed by lengthy and complex
legal texts and the limited availability of large-scale annotated datasets, we
propose JurisCTC, a novel model designed to improve the accuracy of Legal
Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC
facilitates effective knowledge transfer across various legal domains and
employs contrastive learning to distinguish samples from different domains.
Specifically, for the LJP task, we enable knowledge transfer between civil and
criminal law domains. Compared to other models and specific large language
models (LLMs), JurisCTC demonstrates notable advancements, achieving peak
accuracies of 76.59% and 78.83%, respectively.

</details>


### [86] [Evaluating and Mitigating Bias in AI-Based Medical Text Generation](https://arxiv.org/abs/2504.17279)
*Xiuying Chen,Tairan Wang,Juexiao Zhou,Zirui Song,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 研究探讨了医疗领域文本生成中的公平性问题，提出了一种选择性优化算法以减少偏见，显著降低了不同群体间的性能差异。


<details>
  <summary>Details</summary>
Motivation: AI系统在医疗应用中表现出色，但可能放大人类偏见，尤其在文本生成领域公平性问题研究不足。

Method: 提出一种选择性优化算法，考虑词级准确性和病理准确性，确保过程可微分以有效训练模型。

Result: 算法将不同群体间的性能差异减少30%以上，整体生成准确率变化在2%以内。

Conclusion: 该算法有效提升了文本生成的公平性，同时保持了整体性能，有望缓解医疗诊断中的偏见问题。

Abstract: Artificial intelligence (AI) systems, particularly those based on deep
learning models, have increasingly achieved expert-level performance in medical
applications. However, there is growing concern that such AI systems may
reflect and amplify human bias, and reduce the quality of their performance in
historically under-served populations. The fairness issue has attracted
considerable research interest in the medical imaging classification field, yet
it remains understudied in the text generation domain. In this study, we
investigate the fairness problem in text generation within the medical field
and observe significant performance discrepancies across different races,
sexes, and age groups, including intersectional groups, various model scales,
and different evaluation metrics. To mitigate this fairness issue, we propose
an algorithm that selectively optimizes those underperformed groups to reduce
bias. The selection rules take into account not only word-level accuracy but
also the pathology accuracy to the target reference, while ensuring that the
entire process remains fully differentiable for effective model training. Our
evaluations across multiple backbones, datasets, and modalities demonstrate
that our proposed algorithm enhances fairness in text generation without
compromising overall performance. Specifically, the disparities among various
groups across different metrics were diminished by more than 30% with our
algorithm, while the relative change in text generation accuracy was typically
within 2%. By reducing the bias generated by deep learning models, our proposed
approach can potentially alleviate concerns about the fairness and reliability
of text generation diagnosis in medical domain.
  Our code is publicly available to facilitate further research at
https://github.com/iriscxy/GenFair.

</details>


### [87] [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org/abs/2504.17309)
*Junyan Zhang,Shuliang Liu,Aiwei Liu,Yubo Gao,Jungang Li,Xiaojie Gu,Xuming Hu*

Main category: cs.CL

TL;DR: CoheMark是一种高级句子级水印技术，通过利用句子间的连贯关系提升逻辑流畅性，同时保持高文本质量和强水印检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有句子级水印技术依赖随意分割或生成过程，可能限制合适句子的可用性，从而影响生成内容的质量。

Method: CoheMark采用模糊c均值聚类选择句子，并应用特定下一句选择标准。

Result: 实验表明，CoheMark在保持高文本质量的同时实现了强水印强度。

Conclusion: CoheMark有效平衡了文本质量与水印检测的挑战。

Abstract: Watermarking technology is a method used to trace the usage of content
generated by large language models. Sentence-level watermarking aids in
preserving the semantic integrity within individual sentences while maintaining
greater robustness. However, many existing sentence-level watermarking
techniques depend on arbitrary segmentation or generation processes to embed
watermarks, which can limit the availability of appropriate sentences. This
limitation, in turn, compromises the quality of the generated response. To
address the challenge of balancing high text quality with robust watermark
detection, we propose CoheMark, an advanced sentence-level watermarking
technique that exploits the cohesive relationships between sentences for better
logical fluency. The core methodology of CoheMark involves selecting sentences
through trained fuzzy c-means clustering and applying specific next sentence
selection criteria. Experimental evaluations demonstrate that CoheMark achieves
strong watermark strength while exerting minimal impact on text quality.

</details>


### [88] [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org/abs/2504.17311)
*Yulia Otmakhova,Hung Thinh Truong,Rahmad Mahendra,Zenan Zhai,Rongxin Zhu,Daniel Beck,Jey Han Lau*

Main category: cs.CL

TL;DR: FLUKE是一个任务无关的框架，通过系统性地生成测试数据的微小变化来评估模型鲁棒性，涵盖从拼写到方言和风格的多层次语言变化。


<details>
  <summary>Details</summary>
Motivation: 当前模型在语言变化下的鲁棒性缺乏系统性评估，FLUKE旨在填补这一空白。

Method: FLUKE利用大语言模型（LLMs）和人工验证生成多层次的受控语言变化，并在四个NLP任务中评估模型。

Result: 研究发现：(1)语言变化的影响高度依赖任务；(2)LLMs整体鲁棒性更强，但对某些变化仍脆弱；(3)所有模型对否定修改普遍脆弱。

Conclusion: 系统性的鲁棒性测试对理解模型行为至关重要。

Abstract: We present FLUKE (Framework for LingUistically-driven and tasK-agnostic
robustness Evaluation), a task-agnostic framework for assessing model
robustness through systematic minimal variations of test data. FLUKE introduces
controlled variations across linguistic levels - from orthography to dialect
and style varieties - and leverages large language models (LLMs) with human
validation to generate modifications. We demonstrate FLUKE's utility by
evaluating both fine-tuned models and LLMs across four diverse NLP tasks, and
reveal that (1) the impact of linguistic variations is highly task-dependent,
with some tests being critical for certain tasks but irrelevant for others; (2)
while LLMs have better overall robustness compared to fine-tuned models, they
still exhibit significant brittleness to certain linguistic variations; (3) all
models show substantial vulnerability to negation modifications across most
tasks. These findings highlight the importance of systematic robustness testing
for understanding model behaviors.

</details>


### [89] [Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation Detection](https://arxiv.org/abs/2504.17332)
*Zihan Wang,Lu Yuan,Zhengxuan Zhang,Qing Zhao*

Main category: cs.CL

TL;DR: 提出了一种结合认知与情感共情的双方面共情框架（DAE），用于更全面的虚假信息检测。


<details>
  <summary>Details</summary>
Motivation: 传统虚假信息检测方法忽视人类共情在传播中的作用，DAE填补了这一空白。

Method: DAE整合认知与情感共情，分析虚假信息的创作者和读者视角，并引入共情感知过滤机制。

Result: 实验表明DAE优于现有方法，为多模态虚假信息检测提供了新范式。

Conclusion: DAE为虚假信息检测提供了更人性化和全面的解决方案。

Abstract: In the digital era, social media has become a major conduit for information
dissemination, yet it also facilitates the rapid spread of misinformation.
Traditional misinformation detection methods primarily focus on surface-level
features, overlooking the crucial roles of human empathy in the propagation
process. To address this gap, we propose the Dual-Aspect Empathy Framework
(DAE), which integrates cognitive and emotional empathy to analyze
misinformation from both the creator and reader perspectives. By examining
creators' cognitive strategies and emotional appeals, as well as simulating
readers' cognitive judgments and emotional responses using Large Language
Models (LLMs), DAE offers a more comprehensive and human-centric approach to
misinformation detection. Moreover, we further introduce an empathy-aware
filtering mechanism to enhance response authenticity and diversity.
Experimental results on benchmark datasets demonstrate that DAE outperforms
existing methods, providing a novel paradigm for multimodal misinformation
detection.

</details>


### [90] [M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction](https://arxiv.org/abs/2504.17353)
*Chengguang Gan,Sunbowen Lee,Zhixi Cai,Yanbin Wei,Lei Zheng,Yunhao Liang,Shiwen Ni,Tatsunori Mori*

Main category: cs.CL

TL;DR: 论文将互增强效应（MRE）扩展到多模态领域，提出多模态互增强效应（M-MRE）任务，并设计Prompt Format Adapter（PFA）适配大型视觉语言模型，验证了MRE在多模态任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索互增强效应（MRE）在多模态信息提取领域的适用性，填补视觉和多模态领域的研究空白。

Method: 提出多模态互增强效应（M-MRE）任务，构建相应数据集，并设计Prompt Format Adapter（PFA）适配大型视觉语言模型。

Result: 实验证明MRE在多模态任务中同样有效，支持多任务间的互增强。

Conclusion: MRE在多模态领域具有普适性，能够促进多任务间的相互增益。

Abstract: Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection
of information extraction and model interpretability. MRE aims to leverage the
mutual understanding between tasks of different granularities, enhancing the
performance of both coarse-grained and fine-grained tasks through joint
modeling. While MRE has been explored and validated in the textual domain, its
applicability to visual and multimodal domains remains unexplored. In this
work, we extend MRE to the multimodal information extraction domain for the
first time. Specifically, we introduce a new task: Multimodal Mutual
Reinforcement Effect (M-MRE), and construct a corresponding dataset to support
this task. To address the challenges posed by M-MRE, we further propose a
Prompt Format Adapter (PFA) that is fully compatible with various Large
Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can
also be observed in the M-MRE task, a multimodal text-image understanding
scenario. This provides strong evidence that MRE facilitates mutual gains
across three interrelated tasks, confirming its generalizability beyond the
textual domain.

</details>


### [91] [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org/abs/2504.17360)
*Jose G. Moreno,Jesus Lovon,M'Rick Robin-Charlet,Christine Damase-Michel,Lynda Tamine*

Main category: cs.CL

TL;DR: PatientDx框架通过模型合并技术，无需微调即可提升LLM在医疗预测任务中的性能，同时避免数据隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLM微调需要大量敏感数据的问题，尤其是在医疗领域，数据隐私至关重要。

Method: 基于模型合并技术，优化构建块合并策略，使用数值推理模型调整超参数，无需训练数据。

Result: 在MIMIC-IV数据集上，AUROC提升7%，且比微调模型更少出现数据泄露问题。

Conclusion: PatientDx提供了一种高效且隐私安全的LLM优化方案，适用于医疗预测任务。

Abstract: Fine-tuning of Large Language Models (LLMs) has become the default practice
for improving model performance on a given task. However, performance
improvement comes at the cost of training on vast amounts of annotated data
which could be sensitive leading to significant data privacy concerns. In
particular, the healthcare domain is one of the most sensitive domains exposed
to data privacy issues. In this paper, we present PatientDx, a framework of
model merging that allows the design of effective LLMs for health-predictive
tasks without requiring fine-tuning nor adaptation on patient data. Our
proposal is based on recently proposed techniques known as merging of LLMs and
aims to optimize a building block merging strategy. PatientDx uses a pivotal
model adapted to numerical reasoning and tunes hyperparameters on examples
based on a performance metric but without training of the LLM on these data.
Experiments using the mortality tasks of the MIMIC-IV dataset show improvements
up to 7% in terms of AUROC when compared to initial models. Additionally, we
confirm that when compared to fine-tuned models, our proposal is less prone to
data leak problems without hurting performance. Finally, we qualitatively show
the capabilities of our proposal through a case study. Our best model is
publicly available at https://huggingface.co/ Jgmorenof/mistral\_merged\_0\_4.

</details>


### [92] [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org/abs/2504.17366)
*Yongxuan Wu,Runyu Chen,Peiyu Liu,Hongjin Qian*

Main category: cs.CL

TL;DR: 论文构建了一个基于直播的冗余丰富的口语长文本数据集，评估了现有方法在长上下文理解中的表现，并提出了一种新基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能反映真实对话的复杂性，限制了大型语言模型在实际场景中的应用。

Method: 构建了首个口语长文本数据集，设计了检索依赖、推理依赖和混合任务，评估了流行LLM和专用方法。

Result: 现有方法在冗余输入上表现不佳，新基线方法在任务中表现优异。

Conclusion: 研究揭示了当前方法的局限性，并为改进长上下文理解提供了方向，同时填补了口语长文本评估的空白。

Abstract: Long-context understanding poses significant challenges in natural language
processing, particularly for real-world dialogues characterized by speech-based
elements, high redundancy, and uneven information density. Although large
language models (LLMs) achieve impressive results on existing benchmarks, these
datasets fail to reflect the complexities of such texts, limiting their
applicability to practical scenarios. To bridge this gap, we construct the
first spoken long-text dataset, derived from live streams, designed to reflect
the redundancy-rich and conversational nature of real-world scenarios. We
construct tasks in three categories: retrieval-dependent, reasoning-dependent,
and hybrid. We then evaluate both popular LLMs and specialized methods to
assess their ability to understand long-contexts in these tasks. Our results
show that current methods exhibit strong task-specific preferences and perform
poorly on highly redundant inputs, with no single method consistently
outperforming others. We propose a new baseline that better handles redundancy
in spoken text and achieves strong performance across tasks. Our findings
highlight key limitations of current methods and suggest future directions for
improving long-context understanding. Finally, our benchmark fills a gap in
evaluating long-context spoken language understanding and provides a practical
foundation for developing real-world e-commerce systems. The code and benchmark
are available at https://github.com/Yarayx/livelongbench.

</details>


### [93] [PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona](https://arxiv.org/abs/2504.17390)
*Jihyun Lee,Yejin Jeon,Seungyeon Seo,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 论文提出了PicPersona-TOD数据集和Pictor模型，通过用户图像实现个性化对话响应，提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向对话系统常生成单调、通用的响应，缺乏个性化和对用户属性的适应。

Method: 结合用户图像作为人物设定，利用第一印象、对话策略引导提示和外部知识减少幻觉，构建PicPersona-TOD数据集，并开发Pictor模型。

Result: 人类评估证实个性化响应提升了用户体验，Pictor模型在未见领域表现稳健。

Conclusion: PicPersona-TOD和Pictor模型有效实现了个性化对话，增强了交互体验。

Abstract: Task-Oriented Dialogue (TOD) systems are designed to fulfill user requests
through natural language interactions, yet existing systems often produce
generic, monotonic responses that lack individuality and fail to adapt to
users' personal attributes. To address this, we introduce PicPersona-TOD, a
novel dataset that incorporates user images as part of the persona, enabling
personalized responses tailored to user-specific factors such as age or
emotional context. This is facilitated by first impressions, dialogue
policy-guided prompting, and the use of external knowledge to reduce
hallucinations. Human evaluations confirm that our dataset enhances user
experience, with personalized responses contributing to a more engaging
interaction. Additionally, we introduce a new NLG model, Pictor, which not only
personalizes responses, but also demonstrates robust performance across unseen
domains https://github.com/JihyunLee1/PicPersona.

</details>


### [94] [Creating Targeted, Interpretable Topic Models with LLM-Generated Text Augmentation](https://arxiv.org/abs/2504.17445)
*Anna Lieb,Maneesh Arora,Eni Mustafaraj*

Main category: cs.CL

TL;DR: 论文探讨了利用LLM生成文本增强主题模型的实用性，通过政治学案例验证了GPT-4增强的主题模型能生成高度可解释的类别。


<details>
  <summary>Details</summary>
Motivation: 解决主题模型在解释性和针对特定社会科学研究问题实用性上的局限性。

Method: 使用LLM（如GPT-4）生成文本增强主题模型，并通过政治学案例评估效果。

Result: GPT-4增强的主题模型生成了高度可解释的类别，适用于特定领域研究问题。

Conclusion: LLM生成的文本增强显著提升了主题模型的实用性和解释性，适用于社会科学研究。

Abstract: Unsupervised machine learning techniques, such as topic modeling and
clustering, are often used to identify latent patterns in unstructured text
data in fields such as political science and sociology. These methods overcome
common concerns about reproducibility and costliness involved in the
labor-intensive process of human qualitative analysis. However, two major
limitations of topic models are their interpretability and their practicality
for answering targeted, domain-specific social science research questions. In
this work, we investigate opportunities for using LLM-generated text
augmentation to improve the usefulness of topic modeling output. We use a
political science case study to evaluate our results in a domain-specific
application, and find that topic modeling using GPT-4 augmentations creates
highly interpretable categories that can be used to investigate domain-specific
research questions with minimal human guidance.

</details>


### [95] [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org/abs/2504.17480)
*Xin Yi,Shunfan Zhengc,Linlin Wanga,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 论文提出了一种名为CDG-KD的统一框架，用于在未经授权的知识蒸馏中进行双向攻击（擦除和伪造水印），同时保持模型的通用性能。


<details>
  <summary>Details</summary>
Motivation: 水印在大型语言模型（LLMs）中用于对抗错误信息和保护知识产权，但其在未经授权知识蒸馏中的鲁棒性和不可伪造性尚未充分研究。

Method: 使用对比解码从学生模型中提取被破坏或放大的水印文本，并通过双向蒸馏训练新的学生模型，分别实现水印擦除和伪造。

Result: 实验表明，CDG-KD能有效执行攻击，同时保持蒸馏模型的通用性能。

Conclusion: 研究强调了开发鲁棒且不可伪造的水印方案的迫切需求。

Abstract: Watermarking has emerged as a critical technique for combating misinformation
and protecting intellectual property in large language models (LLMs). A recent
discovery, termed watermark radioactivity, reveals that watermarks embedded in
teacher models can be inherited by student models through knowledge
distillation. On the positive side, this inheritance allows for the detection
of unauthorized knowledge distillation by identifying watermark traces in
student models. However, the robustness of watermarks against scrubbing attacks
and their unforgeability in the face of spoofing attacks under unauthorized
knowledge distillation remain largely unexplored. Existing watermark attack
methods either assume access to model internals or fail to simultaneously
support both scrubbing and spoofing attacks. In this work, we propose
Contrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified
framework that enables bidirectional attacks under unauthorized knowledge
distillation. Our approach employs contrastive decoding to extract corrupted or
amplified watermark texts via comparing outputs from the student model and
weakly watermarked references, followed by bidirectional distillation to train
new student models capable of watermark removal and watermark forgery,
respectively. Extensive experiments show that CDG-KD effectively performs
attacks while preserving the general performance of the distilled model. Our
findings underscore critical need for developing watermarking schemes that are
robust and unforgeable.

</details>


### [96] [HalluLens: LLM Hallucination Benchmark](https://arxiv.org/abs/2504.17550)
*Yejin Bang,Ziwei Ji,Alan Schelten,Anthony Hartshorn,Tara Fowler,Cheng Zhang,Nicola Cancedda,Pascale Fung*

Main category: cs.CL

TL;DR: 论文提出了一个全面的幻觉基准，通过新定义的外在和内在评估任务，解决了LLM生成内容偏离用户输入或训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: LLM生成的幻觉内容损害用户信任并阻碍生成式AI系统的采用，因此需要解决这一问题以推动LLM发展。

Method: 论文引入了一个基于清晰分类的幻觉基准，包括动态测试集生成以防止数据泄漏，并分析了现有基准的局限性。

Result: 提出了区分外在和内在幻觉的清晰分类法，并开发了动态生成测试集的方法，增强了基准的鲁棒性。

Conclusion: 该工作为LLM幻觉研究提供了统一的框架和工具，促进了未来研究的进展。

Abstract: Large language models (LLMs) often generate responses that deviate from user
input or training data, a phenomenon known as "hallucination." These
hallucinations undermine user trust and hinder the adoption of generative AI
systems. Addressing hallucinations is essential for the advancement of LLMs.
This paper introduces a comprehensive hallucination benchmark, incorporating
both new extrinsic and existing intrinsic evaluation tasks, built upon clear
taxonomy of hallucination. A major challenge in benchmarking hallucinations is
the lack of a unified framework due to inconsistent definitions and
categorizations. We disentangle LLM hallucination from "factuality," proposing
a clear taxonomy that distinguishes between extrinsic and intrinsic
hallucinations, to promote consistency and facilitate research. Extrinsic
hallucinations, where the generated content is not consistent with the training
data, are increasingly important as LLMs evolve. Our benchmark includes dynamic
test set generation to mitigate data leakage and ensure robustness against such
leakage. We also analyze existing benchmarks, highlighting their limitations
and saturation. The work aims to: (1) establish a clear taxonomy of
hallucinations, (2) introduce new extrinsic hallucination tasks, with data that
can be dynamically regenerated to prevent saturation by leakage, (3) provide a
comprehensive analysis of existing benchmarks, distinguishing them from
factuality evaluations.

</details>


### [97] [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org/abs/2504.17562)
*Rei Higuchi,Ryotaro Kawata,Naoki Nishikawa,Kazusato Oko,Shoichiro Yamaguchi,Sosuke Kobayashi,Seiya Tokui,Kohei Hayashi,Daisuke Okanohara,Taiji Suzuki*

Main category: cs.CL

TL;DR: 研究探讨了在预训练数据前添加元数据对语言模型性能的影响，发现其效果取决于下游任务提示是否能推断潜在语义。


<details>
  <summary>Details</summary>
Motivation: 理解预训练时添加元数据如何影响模型性能，尤其是在下游任务中表现不一致的现象。

Method: 使用人工生成的数据（如概率上下文无关文法）分析模型行为，研究元数据在不同上下文长度下的效果。

Result: 元数据在上下文足够长时能提升性能，但在信息不足时反而会降低性能。

Conclusion: 元数据的有效性依赖于下游任务提示是否能推断潜在语义，需根据任务特点谨慎使用。

Abstract: The ability to acquire latent semantics is one of the key properties that
determines the performance of language models. One convenient approach to
invoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at
the beginning of texts in the pre-training data, making it easier for the model
to access latent semantics before observing the entire text. Previous studies
have reported that this technique actually improves the performance of trained
models in downstream tasks; however, this improvement has been observed only in
specific downstream tasks, without consistent enhancement in average next-token
prediction loss. To understand this phenomenon, we closely investigate how
prepending metadata during pre-training affects model performance by examining
its behavior using artificial data. Interestingly, we found that this approach
produces both positive and negative effects on the downstream tasks. We
demonstrate that the effectiveness of the approach depends on whether latent
semantics can be inferred from the downstream task's prompt. Specifically,
through investigations using data generated by probabilistic context-free
grammars, we show that training with metadata helps improve model's performance
when the given context is long enough to infer the latent semantics. In
contrast, the technique negatively impacts performance when the context lacks
the necessary information to make an accurate posterior inference.

</details>


### [98] [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org/abs/2504.17565)
*Xiaoyu Tian,Sitong Zhao,Haotian Wang,Shuaiting Chen,Yiping Peng,Yunjie Ji,Han Zhao,Xiangang Li*

Main category: cs.CL

TL;DR: 论文通过构建大规模难度分级的推理数据集，优化数据选择方法，显著提升了基础语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决学术界对基础模型训练过程和数据质量缺乏深入理解的问题。

Method: 构建包含340万独特查询和4000万蒸馏响应的大规模数据集，利用通过率和变异系数选择高质量数据，并调整学习率。

Result: 在AIME2024数学推理基准上达到79.2%的通过率，超越多数蒸馏模型。

Conclusion: 公开数据集和方法，推动开源长推理语言模型的快速发展。

Abstract: Although large language models (LLMs) have recently achieved remarkable
performance on various complex reasoning benchmarks, the academic community
still lacks an in-depth understanding of base model training processes and data
quality. To address this, we construct a large-scale, difficulty-graded
reasoning dataset containing approximately 3.34 million unique queries of
varying difficulty levels and about 40 million distilled responses generated by
multiple models over several passes. Leveraging pass rate and Coefficient of
Variation (CV), we precisely select the most valuable training data to enhance
reasoning capability. Notably, we observe a training pattern shift, indicating
that reasoning-focused training based on base models requires higher learning
rates for effective training. Using this carefully selected data, we
significantly improve the reasoning capabilities of the base model, achieving a
pass rate of 79.2\% on the AIME2024 mathematical reasoning benchmark. This
result surpasses most current distilled models and closely approaches
state-of-the-art performance. We provide detailed descriptions of our data
processing, difficulty assessment, and training methodology, and have publicly
released all datasets and methods to promote rapid progress in open-source
long-reasoning LLMs. The dataset is available at:
https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M

</details>


### [99] [RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore](https://arxiv.org/abs/2504.17574)
*Zhenkai Qin,Guifang Yang,Dongze Wu*

Main category: cs.CL

TL;DR: RAGAT-Mind是一种基于MindSpore框架的中文谣言检测模型，结合多粒度建模方法，在微博谣言数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上虚假信息泛滥，谣言检测成为自然语言处理领域的迫切需求。

Method: 模型整合了TextCNN、双向GRU、多头自注意力机制和双向图卷积网络（BiGCN），用于提取局部语义、学习序列上下文、聚焦全局依赖和表示词共现图结构。

Result: 在Weibo1-Rumor数据集上，模型准确率达99.2%，宏F1分数为0.9919。

Conclusion: RAGAT-Mind通过结合层次化语言特征和图语义结构，展现了强大的泛化能力和可解释性，具有实际应用价值。

Abstract: As false information continues to proliferate across social media platforms,
effective rumor detection has emerged as a pressing challenge in natural
language processing. This paper proposes RAGAT-Mind, a multi-granular modeling
approach for Chinese rumor detection, built upon the MindSpore deep learning
framework. The model integrates TextCNN for local semantic extraction,
bidirectional GRU for sequential context learning, Multi-Head Self-Attention
for global dependency focusing, and Bidirectional Graph Convolutional Networks
(BiGCN) for structural representation of word co-occurrence graphs. Experiments
on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior
classification performance, attaining 99.2% accuracy and a macro-F1 score of
0.9919. The results validate the effectiveness of combining hierarchical
linguistic features with graph-based semantic structures. Furthermore, the
model exhibits strong generalization and interpretability, highlighting its
practical value for real-world rumor detection applications.

</details>


### [100] [Towards a comprehensive taxonomy of online abusive language informed by machine leaning](https://arxiv.org/abs/2504.17653)
*Samaneh Hosseini Moghaddam,Kelly Lyons,Cheryl Regehr,Vivek Goel,Kaitlyn Regehr*

Main category: cs.CL

TL;DR: 本文提出了一种用于区分在线文本中辱骂语言关键特征的分类法，通过整合18个多标签数据集的分类系统，构建了一个包含5个类别和17个维度的层次化分类法。


<details>
  <summary>Details</summary>
Motivation: 在线辱骂语言的泛滥对个人和社区的健康与福祉构成重大风险，亟需识别和减轻有害内容的方法。

Method: 采用系统性分类法开发方法，整合18个现有多标签数据集的分类系统，构建层次化分类法。

Result: 最终分类法包含5个类别和17个维度，涵盖辱骂语言的背景、目标、强度、直接性和主题等特征。

Conclusion: 该分类法为研究者、政策制定者等提供了共享理解，有助于推动在线辱骂检测与减轻领域的进展。

Abstract: The proliferation of abusive language in online communications has posed
significant risks to the health and wellbeing of individuals and communities.
The growing concern regarding online abuse and its consequences necessitates
methods for identifying and mitigating harmful content and facilitating
continuous monitoring, moderation, and early intervention. This paper presents
a taxonomy for distinguishing key characteristics of abusive language within
online text. Our approach uses a systematic method for taxonomy development,
integrating classification systems of 18 existing multi-label datasets to
capture key characteristics relevant to online abusive language classification.
The resulting taxonomy is hierarchical and faceted, comprising 5 categories and
17 dimensions. It classifies various facets of online abuse, including context,
target, intensity, directness, and theme of abuse. This shared understanding
can lead to more cohesive efforts, facilitate knowledge exchange, and
accelerate progress in the field of online abuse detection and mitigation among
researchers, policy makers, online platform owners, and other stakeholders.

</details>


### [101] [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org/abs/2504.17665)
*Zena Al-Khalili,Nick Howell,Dietrich Klakow*

Main category: cs.CL

TL;DR: 论文分析了代码辅助LLMs在数学推理任务中生成的程序，发现其数学规则基础性对性能有重要影响，且不同模型表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注代码辅助LLMs的执行正确性，缺乏对其生成程序的深入评估，本文旨在填补这一空白。

Method: 通过手动和自动评估五种LLMs在两个数学数据集上的生成程序，分析其数学规则基础性。

Result: 数学规则基础性因模型能力和问题难度而异，闭源模型表现更优，开源模型表现较差。

Conclusion: 需超越执行准确性，深入评估代码辅助LLMs在数学领域的表现，以全面理解其能力与局限。

Abstract: Assisting LLMs with code generation improved their performance on
mathematical reasoning tasks. However, the evaluation of code-assisted LLMs is
generally restricted to execution correctness, lacking a rigorous evaluation of
their generated programs. In this work, we bridge this gap by conducting an
in-depth analysis of code-assisted LLMs' generated programs in response to math
reasoning tasks. Our evaluation focuses on the extent to which LLMs ground
their programs to math rules, and how that affects their end performance. For
this purpose, we assess the generations of five different LLMs, on two
different math datasets, both manually and automatically. Our results reveal
that the distribution of grounding depends on LLMs' capabilities and the
difficulty of math problems. Furthermore, mathematical grounding is more
effective for closed-source models, while open-source models fail to employ
math rules in their solutions correctly. On MATH500, the percentage of grounded
programs decreased to half, while the ungrounded generations doubled in
comparison to ASDiv grade-school problems. Our work highlights the need for
in-depth evaluation beyond execution accuracy metrics, toward a better
understanding of code-assisted LLMs' capabilities and limits in the math
domain.

</details>


### [102] [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org/abs/2504.17671)
*Yuanchang Ye,Weiyan Wen*

Main category: cs.CL

TL;DR: 提出了一种基于Split Conformal Prediction（SCP）的框架，用于减少大型视觉语言模型（LVLM）在视觉问答（VQA）任务中的幻觉问题，通过动态阈值校准和跨模态一致性验证实现不确定性量化。


<details>
  <summary>Details</summary>
Motivation: LVLM在多模态推理中表现出色，但其输出常伴随高置信度的幻觉内容，对安全关键应用构成风险。

Method: 采用SCP框架，通过数据分区（校准集和测试集）计算非一致性分数，构建具有统计保证的预测集，动态调整预测集大小并消除先验分布假设。

Result: 在ScienceQA和MMMU等基准测试中，SCP框架在所有α值下均实现了理论保证，并在不同校准-测试分割比例下表现稳定。

Conclusion: 该框架为多模态AI系统提供了可扩展的幻觉检测和不确定性感知决策方案，适用于医疗、自动驾驶等安全敏感领域。

Abstract: This study addresses the critical challenge of hallucination mitigation in
Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks
through a Split Conformal Prediction (SCP) framework. While LVLMs excel in
multi-modal reasoning, their outputs often exhibit hallucinated content with
high confidence, posing risks in safety-critical applications. We propose a
model-agnostic uncertainty quantification method that integrates dynamic
threshold calibration and cross-modal consistency verification. By partitioning
data into calibration and test sets, the framework computes nonconformity
scores to construct prediction sets with statistical guarantees under
user-defined risk levels ($\alpha$). Key innovations include: (1) rigorous
control of \textbf{marginal coverage} to ensure empirical error rates remain
strictly below $\alpha$; (2) dynamic adjustment of prediction set sizes
inversely with $\alpha$, filtering low-confidence outputs; (3) elimination of
prior distribution assumptions and retraining requirements. Evaluations on
benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces
theoretical guarantees across all $\alpha$ values. The framework achieves
stable performance across varying calibration-to-test split ratios,
underscoring its robustness for real-world deployment in healthcare, autonomous
systems, and other safety-sensitive domains. This work bridges the gap between
theoretical reliability and practical applicability in multi-modal AI systems,
offering a scalable solution for hallucination detection and uncertainty-aware
decision-making.

</details>


### [103] [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org/abs/2504.17674)
*Jared Fernandez,Clara Na,Vashisth Tiwari,Yonatan Bisk,Sasha Luccioni,Emma Strubell*

Main category: cs.CL

TL;DR: 该论文分析了大型语言模型（LLM）推理效率优化对能源消耗的影响，提出了一种建模方法，并揭示了优化策略可显著降低能源使用。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模和使用的增加，其计算和环境成本上升，但现有研究多关注理想化场景的延迟优化，忽视了实际工作负载对能源的影响。

Method: 通过输入输出令牌分布和批量大小的分箱策略，建模真实LLM工作流，并分析软件框架、解码策略、GPU架构等多种因素。

Result: 研究发现推理优化的效果对工作负载、软件和硬件高度敏感，优化策略可减少高达73%的能源消耗。

Conclusion: 研究为可持续LLM部署和未来AI基础设施的节能设计提供了依据。

Abstract: As large language models (LLMs) scale in size and adoption, their
computational and environmental costs continue to rise. Prior benchmarking
efforts have primarily focused on latency reduction in idealized settings,
often overlooking the diverse real-world inference workloads that shape energy
use. In this work, we systematically analyze the energy implications of common
inference efficiency optimizations across diverse Natural Language Processing
(NLP) and generative Artificial Intelligence (AI) workloads, including
conversational AI and code generation. We introduce a modeling approach that
approximates real-world LLM workflows through a binning strategy for
input-output token distributions and batch size variations. Our empirical
analysis spans software frameworks, decoding strategies, GPU architectures,
online and offline serving settings, and model parallelism configurations. We
show that the effectiveness of inference optimizations is highly sensitive to
workload geometry, software stack, and hardware accelerators, demonstrating
that naive energy estimates based on FLOPs or theoretical GPU utilization
significantly underestimate real-world energy consumption. Our findings reveal
that the proper application of relevant inference efficiency optimizations can
reduce total energy use by up to 73% from unoptimized baselines. These insights
provide a foundation for sustainable LLM deployment and inform energy-efficient
design strategies for future AI infrastructure.

</details>


### [104] [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org/abs/2504.17685)
*Haru-Tada Sato,Fuka Matsuzaki,Jun-ichiro Takahashi*

Main category: cs.CL

TL;DR: 通过集成小型语言模型（SLM）和贝叶斯推理（EBI），研究实现了与大型专有语言模型（LLM）相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索在有限计算资源下构建高性能AI系统的可能性，并有效利用性能较低的模型。

Method: 提出Ensemble Bayesian Inference（EBI），通过贝叶斯估计结合多个SLM的预测结果。

Result: 实验证明EBI在多种任务（如能力评估和消费者分析）中有效，甚至能通过集成性能较差的模型提升整体表现。

Conclusion: EBI为资源有限的高性能AI系统提供了新思路，并展示了低性能模型的潜在价值。

Abstract: This study explores the potential of small language model(SLM) ensembles to
achieve accuracy comparable to proprietary large language models (LLMs). We
propose Ensemble Bayesian Inference (EBI), a novel approach that applies
Bayesian estimation to combine judgments from multiple SLMs, allowing them to
exceed the performance limitations of individual models. Our experiments on
diverse tasks(aptitude assessments and consumer profile analysis in both
Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze
cases where incorporating models with negative Lift values into ensembles
improves overall performance, and we examine the method's efficacy across
different languages. These findings suggest new possibilities for constructing
high-performance AI systems with limited computational resources and for
effectively utilizing models with individually lower performance. Building on
existing research on LLM performance evaluation, ensemble methods, and
open-source LLM utilization, we discuss the novelty and significance of our
approach.

</details>


### [105] [Safety in Large Reasoning Models: A Survey](https://arxiv.org/abs/2504.17704)
*Cheng Wang,Yue Liu,Baolong Li,Duzhen Zhang,Zhongzhi Li,Junfeng Fang*

Main category: cs.CL

TL;DR: 本文综述了大型推理模型（LRMs）的安全风险、攻击方式和防御策略，旨在为未来研究提供清晰的结构化理解。


<details>
  <summary>Details</summary>
Motivation: 随着LRMs在数学和编码等任务中展现强大推理能力，其安全漏洞和风险成为实际应用中的重大挑战。

Method: 通过详细分类法，系统梳理了LRMs的安全风险、攻击方式和防御策略。

Result: 提出了一个全面的安全分类框架，为LRMs的安全研究提供了结构化指导。

Conclusion: 本文为提升LRMs的安全性和可靠性提供了重要参考，推动了未来相关研究的发展。

Abstract: Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks
like mathematics and coding, leveraging their advanced reasoning capabilities.
Nevertheless, as these capabilities progress, significant concerns regarding
their vulnerabilities and safety have arisen, which can pose challenges to
their deployment and application in real-world settings. This paper presents a
comprehensive survey of LRMs, meticulously exploring and summarizing the newly
emerged safety risks, attacks, and defense strategies. By organizing these
elements into a detailed taxonomy, this work aims to offer a clear and
structured understanding of the current safety landscape of LRMs, facilitating
future research and development to enhance the security and reliability of
these powerful models.

</details>


### [106] [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org/abs/2504.17720)
*Vansh Gupta,Sankalan Pal Chowdhury,Vilém Zouhar,Donya Rooein,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 论文评估了大型语言模型（LLMs）在非英语教育任务中的表现，发现其性能与训练数据中的语言资源量相关，建议部署前验证目标语言的表现。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在非英语教育环境中的适用性，填补当前以英语为主的LLMs在多语言教育任务中的研究空白。

Method: 评估了多个流行LLMs在六种非英语语言（印地语、阿拉伯语、波斯语、泰卢固语、乌克兰语、捷克语）及英语中的四种教育任务表现。

Result: 模型性能与语言训练数据量相关，低资源语言表现较差，且非英语任务性能普遍低于英语。

Conclusion: 建议在教育任务部署前验证LLMs在目标语言中的表现，以确保其有效性。

Abstract: Large language models (LLMs) are increasingly being adopted in educational
settings. These applications expand beyond English, though current LLMs remain
primarily English-centric. In this work, we ascertain if their use in education
settings in non-English languages is warranted. We evaluated the performance of
popular LLMs on four educational tasks: identifying student misconceptions,
providing targeted feedback, interactive tutoring, and grading translations in
six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to
English. We find that the performance on these tasks somewhat corresponds to
the amount of language represented in training data, with lower-resource
languages having poorer task performance. Although the models perform
reasonably well in most languages, the frequent performance drop from English
is significant. Thus, we recommend that practitioners first verify that the LLM
works well in the target language for their educational task before deployment.

</details>


### [107] [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org/abs/2504.17753)
*Anuja Tayal,Devika Salunke,Barbara Di Eugenio,Paula Allen-Meares,Eulalia Puig Abril,Olga Garcia,Carolyn Dickens,Andrew Boyd*

Main category: cs.CL

TL;DR: 比较了两种对话助手（基于神经符号架构和基于ChatGPT）在帮助心衰患者查询食物盐含量时的表现，发现各有优劣，但患者无明显偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，对话助手在医疗领域的应用增多，需通过真实用户评估比较传统架构与生成式AI的优缺点。

Method: 采用组内用户研究，比较基于神经符号架构的自研系统和基于ChatGPT的助手在任务完成度、准确性等方面的表现。

Result: 自研系统更准确、任务完成度更高且更简洁；ChatGPT版本语音错误更少、需澄清次数更少。患者对两者无偏好。

Conclusion: 两种架构各有优势，需根据具体需求选择；患者无明显偏好，表明两者均可接受。

Abstract: Conversational assistants are becoming more and more popular, including in
healthcare, partly because of the availability and capabilities of Large
Language Models. There is a need for controlled, probing evaluations with real
stakeholders which can highlight advantages and disadvantages of more
traditional architectures and those based on generative AI. We present a
within-group user study to compare two versions of a conversational assistant
that allows heart failure patients to ask about salt content in food. One
version of the system was developed in-house with a neurosymbolic architecture,
and one is based on ChatGPT. The evaluation shows that the in-house system is
more accurate, completes more tasks and is less verbose than the one based on
ChatGPT; on the other hand, the one based on ChatGPT makes fewer speech errors
and requires fewer clarifications to complete the task. Patients show no
preference for one over the other.

</details>


### [108] [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org/abs/2504.17768)
*Piotr Nawrot,Robert Li,Renjie Huang,Sebastian Ruder,Kelly Marchisio,Edoardo M. Ponti*

Main category: cs.CL

TL;DR: 稀疏注意力是扩展Transformer LLMs长上下文能力的有效方法，但其可行性、效率-准确性权衡及系统性扩展研究尚未充分探索。本文通过实验比较不同模型规模、序列长度和稀疏度的训练无关稀疏注意力方法，揭示了关键发现，并提出了针对稀疏注意力的新缩放规律。


<details>
  <summary>Details</summary>
Motivation: 探索稀疏注意力在Transformer LLMs中的潜力，填补其在可行性、效率-准确性权衡及系统性扩展研究上的空白。

Method: 通过实验比较不同模型规模、序列长度和稀疏度的训练无关稀疏注意力方法，分析其在多样长序列任务中的表现。

Result: 1) 对于超长序列，更大且高度稀疏的模型优于小且密集的模型；2) 解码阶段的稀疏度上限高于预填充阶段，且与模型规模相关；3) 不同任务和阶段需要不同的稀疏化策略；4) 提出了针对稀疏注意力的新缩放规律。

Conclusion: 稀疏注意力是增强Transformer LLMs处理长序列能力的关键工具，但需仔细权衡性能与效率。

Abstract: Sparse attention offers a promising strategy to extend long-context
capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy
trade-offs, and systematic scaling studies remain unexplored. To address this
gap, we perform a careful comparison of training-free sparse attention methods
at varying model scales, sequence lengths, and sparsity levels on a diverse
collection of long-sequence tasks-including novel ones that rely on natural
language while remaining controllable and easy to evaluate. Based on our
experiments, we report a series of key findings: 1) an isoFLOPS analysis
reveals that for very long sequences, larger and highly sparse models are
preferable to smaller and dense ones. 2) The level of sparsity attainable while
statistically guaranteeing accuracy preservation is higher during decoding than
prefilling, and correlates with model size in the former. 3) There is no clear
strategy that performs best across tasks and phases, with different units of
sparsification or budget adaptivity needed for different scenarios. Even
moderate sparsity levels often result in significant performance degradation on
at least one task, highlighting that sparse attention is not a universal
solution. 4) We introduce and validate novel scaling laws specifically tailored
for sparse attention, providing evidence that our findings are likely to hold
true beyond our range of experiments. Through these insights, we demonstrate
that sparse attention is a key tool to enhance the capabilities of Transformer
LLMs for processing longer sequences, but requires careful evaluation of
trade-offs for performance-sensitive applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [109] [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org/abs/2504.17004)
*Amin Karbasi,Omar Montasser,John Sous,Grigoris Velegkas*

Main category: cs.LG

TL;DR: 本文探讨了自动检测大型语言模型（LLM）幻觉的可行性，提出理论框架，证明仅使用正确样本训练时检测不可行，但加入专家标注反馈后可行。


<details>
  <summary>Details</summary>
Motivation: 研究自动检测LLM幻觉的可能性，为可靠部署LLM提供理论支持。

Method: 基于Gold-Angluin框架，将幻觉检测与语言识别任务等价，分析不同训练数据（仅正确样本 vs. 专家标注正负样本）的影响。

Result: 仅用正确样本训练时，幻觉检测不可行；加入专家标注反馈后，对所有可数语言集合均可行。

Conclusion: 专家标注反馈对训练幻觉检测器至关重要，支持基于反馈的方法（如RLHF）。

Abstract: Is automated hallucination detection possible? In this work, we introduce a
theoretical framework to analyze the feasibility of automatically detecting
hallucinations produced by large language models (LLMs). Inspired by the
classical Gold-Angluin framework for language identification and its recent
adaptation to language generation by Kleinberg and Mullainathan, we investigate
whether an algorithm, trained on examples drawn from an unknown target language
$K$ (selected from a countable collection) and given access to an LLM, can
reliably determine whether the LLM's outputs are correct or constitute
hallucinations.
  First, we establish an equivalence between hallucination detection and the
classical task of language identification. We prove that any hallucination
detection method can be converted into a language identification method, and
conversely, algorithms solving language identification can be adapted for
hallucination detection. Given the inherent difficulty of language
identification, this implies that hallucination detection is fundamentally
impossible for most language collections if the detector is trained using only
correct examples from the target language.
  Second, we show that the use of expert-labeled feedback, i.e., training the
detector with both positive examples (correct statements) and negative examples
(explicitly labeled incorrect statements), dramatically changes this
conclusion. Under this enriched training regime, automated hallucination
detection becomes possible for all countable language collections.
  These results highlight the essential role of expert-labeled examples in
training hallucination detectors and provide theoretical support for
feedback-based methods, such as reinforcement learning with human feedback
(RLHF), which have proven critical for reliable LLM deployment.

</details>


### [110] [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org/abs/2504.17449)
*Jun Zhang,Jue Wang,Huan Li,Lidan Shou,Ke Chen,Gang Chen,Qin Xie,Guiming Xie,Xuejian Gong*

Main category: cs.LG

TL;DR: HMI是一种基于分层知识管理的多租户推理系统，旨在高效管理不同PLM的租户，通过分层知识提取和存储减少GPU内存使用，支持单GPU上运行多达10,000个hPLM。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型（PLM）的高计算需求在多租户环境中效率低下，需专用硬件支持。HMI旨在解决这一问题，实现资源高效管理。

Method: 1. 将PLM知识分为通用、领域特定和任务特定三类，构建分层PLM（hPLM）；2. 通过频率更新领域知识树和参数交换管理任务知识；3. 系统优化包括分层知识预取和批量矩阵乘法。

Result: 实验显示，HMI在单GPU上可高效运行10,000个hPLM（hBERT和hGPT），准确性损失可忽略。

Conclusion: HMI通过分层知识管理和系统优化，显著提升了多租户环境中PLM的资源利用率和推理吞吐量。

Abstract: The significant computational demands of pretrained language models (PLMs),
which often require dedicated hardware, present a substantial challenge in
serving them efficiently, especially in multi-tenant environments. To address
this, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant
Inference system, designed to manage tenants with distinct PLMs
resource-efficiently. Our approach is three-fold: Firstly, we categorize PLM
knowledge into general, domain-specific, and task-specific. Leveraging insights
on knowledge acquisition across different model layers, we construct
hierarchical PLMs (hPLMs) by extracting and storing knowledge at different
levels, significantly reducing GPU memory usage per tenant. Secondly, we
establish hierarchical knowledge management for hPLMs generated by various
tenants in HMI. We manage domain-specific knowledge with acceptable storage
increases by constructing and updating domain-specific knowledge trees based on
frequency. We manage task-specific knowledge within limited GPU memory through
parameter swapping. Finally, we propose system optimizations to enhance
resource utilization and inference throughput. These include fine-grained
pipelining via hierarchical knowledge prefetching to overlap CPU and I/O
operations with GPU computations, and optimizing parallel implementations with
batched matrix multiplications. Our experimental results demonstrate that the
proposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a
single GPU, with only a negligible compromise in accuracy.

</details>


### [111] [Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications](https://arxiv.org/abs/2504.16972)
*Hossein Ahmadi,Sajjad Emdadi Mahdimahalleh,Arman Farahat,Banafsheh Saffari*

Main category: cs.LG

TL;DR: 本文综述了自编码器和视觉变换器在无监督信号分析中的应用，探讨了其架构、应用及趋势，并指出了可解释性、可扩展性和领域泛化等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信、雷达、生物医学工程和物联网等领域中未标记时间序列数据的快速增长，无监督学习的进展推动了信号分析的需求。

Method: 通过综述自编码器和视觉变换器的架构和应用，分析其在特征提取、异常检测和分类中的表现，并探讨混合架构和自监督学习的优势。

Result: 研究发现这些模型在多种信号类型（如心电图、雷达波形和物联网传感器数据）中表现良好，但面临可解释性、可扩展性和领域泛化的挑战。

Conclusion: 本文为开发鲁棒、自适应的信号智能模型提供了路线图，强调了方法创新与实际应用的结合。

Abstract: The rapid growth of unlabeled time-series data in domains such as wireless
communications, radar, biomedical engineering, and the Internet of Things (IoT)
has driven advancements in unsupervised learning. This review synthesizes
recent progress in applying autoencoders and vision transformers for
unsupervised signal analysis, focusing on their architectures, applications,
and emerging trends. We explore how these models enable feature extraction,
anomaly detection, and classification across diverse signal types, including
electrocardiograms, radar waveforms, and IoT sensor data. The review highlights
the strengths of hybrid architectures and self-supervised learning, while
identifying challenges in interpretability, scalability, and domain
generalization. By bridging methodological innovations and practical
applications, this work offers a roadmap for developing robust, adaptive models
for signal intelligence.

</details>


### [112] [OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection](https://arxiv.org/abs/2504.17160)
*Alberto Fernández-Hernández,Jose I. Mestre,Manuel F. Dolz,Jose Duato,Enrique S. Quintana-Ortí*

Main category: cs.LG

TL;DR: OUI是一种新工具，用于监控DNN训练动态并识别最佳正则化超参数，无需验证数据即可判断过拟合或欠拟合。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖验证数据调整超参数，OUI旨在提供更快速、更直接的过拟合/欠拟合指示。

Method: 通过实验验证OUI在多种DNN和数据集上的有效性，指导Weight Decay超参数的选择。

Result: OUI能更快收敛并显著提升泛化性能，帮助早期确定最佳超参数。

Conclusion: OUI是高效的工具，可优化DNN训练过程，提升模型性能。

Abstract: We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for
monitoring the training dynamics of Deep Neural Networks (DNNs) and identifying
optimal regularization hyperparameters. Specifically, we validate that OUI can
effectively guide the selection of the Weight Decay (WD) hyperparameter by
indicating whether a model is overfitting or underfitting during training
without requiring validation data. Through experiments on DenseNet-BC-100 with
CIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K,
we show that maintaining OUI within a prescribed interval correlates strongly
with improved generalization and validation scores. Notably, OUI converges
significantly faster than traditional metrics such as loss or accuracy,
enabling practitioners to identify optimal WD (hyperparameter) values within
the early stages of training. By leveraging OUI as a reliable indicator, we can
determine early in training whether the chosen WD value leads the model to
underfit the training data, overfit, or strike a well-balanced trade-off that
maximizes validation scores. This enables more precise WD tuning for optimal
performance on the tested datasets and DNNs. All code for reproducing these
experiments is available at https://github.com/AlbertoFdezHdez/OUI.

</details>


### [113] [Group Downsampling with Equivariant Anti-aliasing](https://arxiv.org/abs/2504.17258)
*Md Ashiqur Rahman,Raymond A. Yeh*

Main category: cs.LG

TL;DR: 论文研究了在群等变架构（如G-CNNs）中推广均匀下采样层的方法，提出了一种针对有限群的下采样算法，并展示了其在图像分类任务中的优势。


<details>
  <summary>Details</summary>
Motivation: 下采样层是CNN架构中的关键组件，但现有方法在群等变架构中的通用性不足。本文旨在解决这一问题，提出适用于有限群的下采样方法。

Method: 提出了一种算法，针对有限群和给定的下采样率选择合适的子群，并研究了带限性和抗混叠方法。方法基于经典采样理论，适用于周期性信号。

Result: 实验表明，提出的下采样操作在G-等变网络中提高了准确性，更好地保持了等变性，并减少了模型大小。

Conclusion: 本文的方法推广了经典下采样理论，适用于群等变架构，并在实际任务中验证了其有效性。

Abstract: Downsampling layers are crucial building blocks in CNN architectures, which
help to increase the receptive field for learning high-level features and
reduce the amount of memory/computation in the model. In this work, we study
the generalization of the uniform downsampling layer for group equivariant
architectures, e.g., G-CNNs. That is, we aim to downsample signals (feature
maps) on general finite groups with anti-aliasing. This involves the following:
(a) Given a finite group and a downsampling rate, we present an algorithm to
form a suitable choice of subgroup. (b) Given a group and a subgroup, we study
the notion of bandlimited-ness and propose how to perform anti-aliasing.
Notably, our method generalizes the notion of downsampling based on classical
sampling theory. When the signal is on a cyclic group, i.e., periodic, our
method recovers the standard downsampling of an ideal low-pass filter followed
by a subsampling operation. Finally, we conducted experiments on image
classification tasks demonstrating that the proposed downsampling operation
improves accuracy, better preserves equivariance, and reduces model size when
incorporated into G-equivariant networks

</details>


### [114] [Class-Conditional Distribution Balancing for Group Robust Classification](https://arxiv.org/abs/2504.17314)
*Miaoyun Zhao,Qiang Zhang,Chenrong Li*

Main category: cs.LG

TL;DR: 论文提出了一种无需偏差标注或预测的鲁棒学习方法，通过重新加权样本平衡类条件分布，有效消除虚假相关性。


<details>
  <summary>Details</summary>
Motivation: 虚假相关性导致模型基于错误原因做出预测，现有方法依赖昂贵的偏差标注或大规模数据，难以在资源有限领域应用。

Method: 通过减少虚假因素与标签信息的互信息，采用样本重新加权策略平衡类条件分布，自动突出少数群体和类别。

Result: 实验表明，该方法性能优异，媲美依赖偏差监督的方法。

Conclusion: 该方法简单有效，无需额外标注或数据，适用于资源有限场景。

Abstract: Spurious correlations that lead models to correct predictions for the wrong
reasons pose a critical challenge for robust real-world generalization.
Existing research attributes this issue to group imbalance and addresses it by
maximizing group-balanced or worst-group accuracy, which heavily relies on
expensive bias annotations. A compromise approach involves predicting bias
information using extensively pretrained foundation models, which requires
large-scale data and becomes impractical for resource-limited rare domains. To
address these challenges, we offer a novel perspective by reframing the
spurious correlations as imbalances or mismatches in class-conditional
distributions, and propose a simple yet effective robust learning method that
eliminates the need for both bias annotations and predictions. With the goal of
reducing the mutual information between spurious factors and label information,
our method leverages a sample reweighting strategy to achieve class-conditional
distribution balancing, which automatically highlights minority groups and
classes, effectively dismantling spurious correlations and producing a debiased
data distribution for classification. Extensive experiments and analysis
demonstrate that our approach consistently delivers state-of-the-art
performance, rivaling methods that rely on bias supervision.

</details>


### [115] [The effects of Hessian eigenvalue spectral density type on the applicability of Hessian analysis to generalization capability assessment of neural networks](https://arxiv.org/abs/2504.17618)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: 本文研究了神经网络Hessian矩阵特征值谱密度（HESD）的行为及其对泛化能力的影响，提出了统一的HESD分析方法，并探讨了训练过程中HESD的变化。


<details>
  <summary>Details</summary>
Motivation: Hessian矩阵特征值谱密度（HESD）能反映神经网络损失曲面的曲率，进而估计泛化能力。本文旨在进一步研究HESD的适用性及其影响因素。

Method: 通过实验分析不同优化器、数据集、预处理和数据增强对HESD的影响，提出判断HESD类型的标准，并结合先前提出的泛化准则形成统一分析方法。

Result: 发现HESD主要为正值（MP-HESD）时适用于先前方法，而负值（MN-HESD）则与外部梯度操作相关。此外，训练中会出现准奇异（QS）HESD，影响传统假设。

Conclusion: 提出了一种统一的HESD分析方法，并揭示了HESD类型及其变化对神经网络泛化能力评估的重要性。

Abstract: Hessians of neural network (NN) contain essential information about the
curvature of NN loss landscapes which can be used to estimate NN generalization
capabilities. We have previously proposed generalization criteria that rely on
the observation that Hessian eigenvalue spectral density (HESD) behaves
similarly for a wide class of NNs. This paper further studies their
applicability by investigating factors that can result in different types of
HESD. We conduct a wide range of experiments showing that HESD mainly has
positive eigenvalues (MP-HESD) for NN training and fine-tuning with various
optimizers on different datasets with different preprocessing and augmentation
procedures. We also show that mainly negative HESD (MN-HESD) is a consequence
of external gradient manipulation, indicating that the previously proposed
Hessian analysis methodology cannot be applied in such cases. We also propose
criteria and corresponding conditions to determine HESD type and estimate NN
generalization potential. These HESD types and previously proposed
generalization criteria are combined into a unified HESD analysis methodology.
Finally, we discuss how HESD changes during training, and show the occurrence
of quasi-singular (QS) HESD and its influence on the proposed methodology and
on the conventional assumptions about the relation between Hessian eigenvalues
and NN loss landscape curvature.

</details>


### [116] [Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction](https://arxiv.org/abs/2504.17655)
*Farhad Pourkamali-Anaraki*

Main category: cs.LG

TL;DR: 本文对共形预测方法在复杂真实世界场景中的有效性进行了实证分析，发现即使数据有限，共形预测仍能提供有价值的预测集，同时揭示了温度缩放对预测集大小的影响不一致。


<details>
  <summary>Details</summary>
Motivation: 研究共形预测在数据稀缺且高度变化的真实世界环境中的表现，以验证其在实际应用中的可靠性和效率。

Method: 利用预训练模型（MobileNet、DenseNet、ResNet）进行微调，生成预测集，并通过两种校准管道（带/不带温度缩放）评估性能。

Result: 共形预测在有限标记数据下仍能提供可靠的预测集，但温度缩放对预测集大小的影响不一致。模型压缩技术在资源受限环境中具有潜力。

Conclusion: 未来研究应关注噪声或模糊标签对共形预测的影响，并探索有效的模型压缩策略。

Abstract: This paper presents a comprehensive empirical analysis of conformal
prediction methods on a challenging aerial image dataset featuring diverse
events in unconstrained environments. Conformal prediction is a powerful
post-hoc technique that takes the output of any classifier and transforms it
into a set of likely labels, providing a statistical guarantee on the coverage
of the true label. Unlike evaluations on standard benchmarks, our study
addresses the complexities of data-scarce and highly variable real-world
settings. We investigate the effectiveness of leveraging pretrained models
(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to
generate informative prediction sets. To further evaluate the impact of
calibration, we consider two parallel pipelines (with and without temperature
scaling) and assess performance using two key metrics: empirical coverage and
average prediction set size. This setup allows us to systematically examine how
calibration choices influence the trade-off between reliability and efficiency.
Our findings demonstrate that even with relatively small labeled samples and
simple nonconformity scores, conformal prediction can yield valuable
uncertainty estimates for complex tasks. Moreover, our analysis reveals that
while temperature scaling is often employed for calibration, it does not
consistently lead to smaller prediction sets, underscoring the importance of
careful consideration in its application. Furthermore, our results highlight
the significant potential of model compression techniques within the conformal
prediction pipeline for deployment in resource-constrained environments. Based
on our observations, we advocate for future research to delve into the impact
of noisy or ambiguous labels on conformal prediction performance and to explore
effective model reduction strategies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2504.16939)
*Emre Can Acikgoz,Cheng Qian,Hongru Wang,Vardhan Dongre,Xiusi Chen,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的对话代理的现状、挑战及未来发展方向，提出了一个分类框架，并指出了关键研究空白。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的对话代理取得了显著进展，但其能力、局限性和未来发展路径仍存在许多未解问题。本文旨在系统分析这些代理的能力，并提出下一代对话代理的需求。

Method: 通过将对话代理的能力分为三个维度（推理、监控、控制），并围绕这些维度对现有研究进行分类，提出新的分类法。

Result: 识别了关键研究空白，如长期多轮推理能力、自我进化能力、多代理协作等，并提出了未来研究方向。

Conclusion: 本文为对话代理的研究提供了结构化基础，指出了现有局限性，并为未来研究提供了方向，以推动人工通用智能（AGI）的发展。

Abstract: Recent advances in Large Language Models (LLMs) have propelled conversational
AI from traditional dialogue systems into sophisticated agents capable of
autonomous actions, contextual awareness, and multi-turn interactions with
users. Yet, fundamental questions about their capabilities, limitations, and
paths forward remain open. This survey paper presents a desideratum for
next-generation Conversational Agents - what has been achieved, what challenges
persist, and what must be done for more scalable systems that approach
human-level intelligence. To that end, we systematically analyze LLM-driven
Conversational Agents by organizing their capabilities into three primary
dimensions: (i) Reasoning - logical, systematic thinking inspired by human
intelligence for decision making, (ii) Monitor - encompassing self-awareness
and user interaction monitoring, and (iii) Control - focusing on tool
utilization and policy following. Building upon this, we introduce a novel
taxonomy by classifying recent work on Conversational Agents around our
proposed desideratum. We identify critical research gaps and outline key
directions, including realistic evaluations, long-term multi-turn reasoning
skills, self-evolution capabilities, collaborative and multi-agent task
completion, personalization, and proactivity. This work aims to provide a
structured foundation, highlight existing limitations, and offer insights into
potential future research directions for Conversational Agents, ultimately
advancing progress toward Artificial General Intelligence (AGI). We maintain a
curated repository of papers at:
https://github.com/emrecanacikgoz/awesome-conversational-agents.

</details>


### [118] [AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models](https://arxiv.org/abs/2504.17179)
*Mohammad Zarei,Melanie A Jutras,Eliana Evans,Mike Tan,Omid Aaramoon*

Main category: cs.AI

TL;DR: 本文提出了一种利用生成和可解释AI技术理解自动驾驶车辆（AVs）中罕见故障模式（RFMs）的新方法，通过生成多样化的环境图像和自然语言描述，提升AV系统的鲁棒性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆（AVs）在检测罕见故障模式（RFMs）时存在困难，这被称为“长尾挑战”。本文旨在通过生成和可解释AI技术解决这一问题。

Method: 提取对象分割掩码并反转生成环境掩码，结合文本提示输入定制扩散模型，利用稳定扩散修复模型和对抗噪声优化生成多样化图像，暴露AI系统的漏洞。

Result: 生成的环境图像和自然语言描述能够帮助开发者和政策制定者识别并改进AV系统的安全性和可靠性。

Conclusion: 该方法为理解和解决AVs中的罕见故障模式提供了有效工具，有望提升自动驾驶技术的安全性。

Abstract: Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately
detect objects and interpret their surroundings. However, even when trained
using millions of miles of real-world data, AVs are often unable to detect rare
failure modes (RFMs). The problem of RFMs is commonly referred to as the
"long-tail challenge", due to the distribution of data including many instances
that are very rarely seen. In this paper, we present a novel approach that
utilizes advanced generative and explainable AI techniques to aid in
understanding RFMs. Our methods can be used to enhance the robustness and
reliability of AVs when combined with both downstream model training and
testing. We extract segmentation masks for objects of interest (e.g., cars) and
invert them to create environmental masks. These masks, combined with carefully
crafted text prompts, are fed into a custom diffusion model. We leverage the
Stable Diffusion inpainting model guided by adversarial noise optimization to
generate images containing diverse environments designed to evade object
detection models and expose vulnerabilities in AI systems. Finally, we produce
natural language descriptions of the generated RFMs that can guide developers
and policymakers to improve the safety and reliability of AV systems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [119] [Seeing The Words: Evaluating AI-generated Biblical Art](https://arxiv.org/abs/2504.16974)
*Hidde Makimei,Shuai Wang,Willem van Peursen*

Main category: cs.CY

TL;DR: 本文探讨了AI生成图像是否能准确反映圣经文本的背景和内容，并提供了一个包含7K图像的数据集，通过多种神经网络工具评估其准确性。


<details>
  <summary>Details</summary>
Motivation: 研究AI生成图像在圣经文本背景下的准确性，填补系统性评估的空白。

Method: 使用圣经文本作为提示生成7K图像，并通过多种神经网络工具评估其准确性、宗教性和美学性。

Result: 提供了图像准确性评估，并从宗教和美学角度进行了分析。

Conclusion: 讨论了生成图像的用途，并反思了AI生成器的表现。

Abstract: The past years witnessed a significant amount of Artificial Intelligence (AI)
tools that can generate images from texts. This triggers the discussion of
whether AI can generate accurate images using text from the Bible with respect
to the corresponding biblical contexts and backgrounds. Despite some existing
attempts at a small scale, little work has been done to systematically evaluate
these generated images. In this work, we provide a large dataset of over 7K
images using biblical text as prompts. These images were evaluated with
multiple neural network-based tools on various aspects. We provide an
assessment of accuracy and some analysis from the perspective of religion and
aesthetics. Finally, we discuss the use of the generated images and reflect on
the performance of the AI generators.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [120] [SCALAR: A Part-of-speech Tagger for Identifiers](https://arxiv.org/abs/2504.17038)
*Christian D. Newman,Brandon Scholten,Sophia Testa,Joshua A. C. Behler,Syreen Banabilah,Michael L. Collard,Michael J. Decker,Mohamed Wiem Mkaouer,Marcos Zampieri,Eman Abdullah AlOmar,Reem Alsuhaibani,Anthony Peruma,Jonathan I. Maletic*

Main category: cs.SE

TL;DR: SCALAR是一个专门用于将源代码标识符名称映射到其对应词性标记序列的工具，通过训练模型提升标注准确性。


<details>
  <summary>Details</summary>
Motivation: 开发者使用的自然语言结构独特，现有词性标注工具无法准确标注源代码标识符，因此需要专门工具。

Method: 使用scikit-learn的GradientBoostingClassifier训练模型，结合手动整理的标识符名称和语法模式数据集。

Result: SCALAR在标注标识符方面优于先前版本和现代通用词性标注工具。

Conclusion: SCALAR为源代码标识符的词性标注提供了更准确的解决方案，代码已开源。

Abstract: The paper presents the Source Code Analysis and Lexical Annotation Runtime
(SCALAR), a tool specialized for mapping (annotating) source code identifier
names to their corresponding part-of-speech tag sequence (grammar pattern).
SCALAR's internal model is trained using scikit-learn's
GradientBoostingClassifier in conjunction with a manually-curated oracle of
identifier names and their grammar patterns. This specializes the tagger to
recognize the unique structure of the natural language used by developers to
create all types of identifiers (e.g., function names, variable names etc.).
SCALAR's output is compared with a previous version of the tagger, as well as a
modern off-the-shelf part-of-speech tagger to show how it improves upon other
taggers' output for annotating identifiers. The code is available on Github

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [121] [Can deep neural networks learn biological vision?](https://arxiv.org/abs/2504.16940)
*Drew Linsley,Pinyuan Feng,Thomas Serre*

Main category: q-bio.NC

TL;DR: 现代深度神经网络（DNNs）在视觉任务中与灵长类神经反应的匹配度下降，表明其依赖的特征与生物视觉系统不同。未来生物视觉模型需脱离人工智能范式，专注于生物视觉的数据和训练方式。


<details>
  <summary>Details</summary>
Motivation: 探讨DNNs与生物视觉系统匹配度下降的原因，并提出未来研究方向。

Method: 提出需设计更贴近生物视觉系统的算法，包括数据、训练和目标。

Result: 现代DNNs依赖的特征与灵长类不同，导致匹配度下降。

Conclusion: 未来生物视觉模型需基于生物视觉的数据和训练方式，而非传统AI范式。

Abstract: Deep neural networks (DNNs) once showed increasing alignment with primate
neural responses as they improved on computer vision benchmarks. This trend
raised the exciting possibility that better models of biological vision would
come as a byproduct of the deep learning revolution in artificial intelligence.
However, the trend has reversed over recent years as DNNs have scaled to human
or superhuman recognition accuracy, a divergence that may stem from modern DNNs
learning to rely on different visual features than primates to solve tasks.
Where will better computational models of biological vision come from? We
propose that vision science must break from artificial intelligence to develop
algorithms that are designed with biological visual systems in mind instead of
internet data benchmarks. We predict that the next generation of deep learning
models of biological vision will be trained with data diets, training routines,
and objectives that are closer to those that shape human vision than those that
are in use today.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [122] [Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation](https://arxiv.org/abs/2504.17114)
*Valentin Langer,Kartikay Tehlan,Thomas Wendler*

Main category: eess.IV

TL;DR: 提出一种基于多器官分割的方法，整合主动脉、门静脉、肺动脉和输尿管的图像衍生输入函数（IDIFs），以提高动态PET成像的动力学建模准确性。


<details>
  <summary>Details</summary>
Motivation: 传统IDIFs仅从主动脉获取，忽略了解剖变异和复杂血管贡献，限制了动力学分析的准确性。

Method: 利用高分辨率CT分割肝脏、肺、肾脏和膀胱，整合器官特异性血液供应源，改进动力学建模。

Result: 在9例患者的动态PET数据中，肝脏和肺的均方误差（MSE）分别降低了13.39%和10.42%。

Conclusion: 多IDIFs方法有望改善解剖建模，推动示踪动力学建模在临床中的应用。

Abstract: Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron
emission tomography (PET) requires anatomically constrained modelling of
image-derived input functions (IDIFs). Traditionally, IDIFs are obtained from
the aorta, neglecting anatomical variations and complex vascular contributions.
This study proposes a multi-organ segmentation-based approach that integrates
IDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using
high-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we
incorporate organ-specific blood supply sources to improve kinetic modelling.
Our method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,
resulting in a mean squared error (MSE) reduction of $13.39\%$ for the liver
and $10.42\%$ for the lungs. These initial results highlight the potential of
multiple IDIFs in improving anatomical modelling and fully leveraging dynamic
PET imaging. This approach could facilitate the integration of tracer kinetic
modelling into clinical routine.

</details>


### [123] [Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET](https://arxiv.org/abs/2504.17122)
*Kartikay Tehlan,Thomas Wendler*

Main category: eess.IV

TL;DR: 提出了一种基于隐式神经表示（INRs）的生理神经表示方法，用于个性化动力学参数估计，解决了传统方法和深度神经网络（DNNs）在计算和数据需求上的限制。


<details>
  <summary>Details</summary>
Motivation: 动态PET成像中传统方法计算量大且空间分辨率有限，DNNs需要大量数据和计算资源，因此需要一种更高效、数据需求更少的方法。

Method: 利用INRs学习连续函数，结合3D CT基础模型的解剖先验，实现高效、高分辨率的参数成像。

Result: 在[$^{18}$F]FDG动态PET/CT数据集上验证，结果显示更高的空间分辨率、更低的均方误差和更好的解剖一致性，尤其在肿瘤和高血管区域。

Conclusion: INRs在个性化、数据高效的示踪动力学建模中具有潜力，可用于肿瘤表征、分割和预后评估。

Abstract: Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables
non-invasive quantification of glucose metabolism through kinetic analysis,
often modelled by the two-tissue compartment model (TCKM). However, voxel-wise
kinetic parameter estimation using conventional methods is computationally
intensive and limited by spatial resolution. Deep neural networks (DNNs) offer
an alternative but require large training datasets and significant
computational resources. To address these limitations, we propose a
physiological neural representation based on implicit neural representations
(INRs) for personalized kinetic parameter estimation. INRs, which learn
continuous functions, allow for efficient, high-resolution parametric imaging
with reduced data requirements. Our method also integrates anatomical priors
from a 3D CT foundation model to enhance robustness and precision in kinetic
modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset
and compare it to state-of-the-art DNNs. Results demonstrate superior spatial
resolution, lower mean-squared error, and improved anatomical consistency,
particularly in tumour and highly vascularized regions. Our findings highlight
the potential of INRs for personalized, data-efficient tracer kinetic
modelling, enabling applications in tumour characterization, segmentation, and
prognostic assessment.

</details>


### [124] [A Spatially-Aware Multiple Instance Learning Framework for Digital Pathology](https://arxiv.org/abs/2504.17379)
*Hassan Keshvarikhojasteh,Mihail Tifrea,Sibylle Hess,Josien P. W. Pluim,Mitko Veta*

Main category: eess.IV

TL;DR: GABMIL改进ABMIL框架，通过显式捕捉实例间依赖关系提升性能，在计算效率不变的情况下显著优于ABMIL。


<details>
  <summary>Details</summary>
Motivation: 传统MIL方法（如ABMIL）忽视病理诊断中关键的patch间空间交互，而TransMIL虽引入空间上下文但计算复杂度高。

Method: 提出GABMIL，在ABMIL框架中集成交互感知表示，显式建模实例间依赖关系。

Result: 在乳腺癌和肺癌亚型分类任务中，GABMIL的AUPRC提升7%，Kappa分数提升5%，计算开销几乎不变。

Conclusion: 显式建模patch交互对MIL框架性能提升至关重要，GABMIL在效率和性能间取得平衡。

Abstract: Multiple instance learning (MIL) is a promising approach for weakly
supervised classification in pathology using whole slide images (WSIs).
However, conventional MIL methods such as Attention-Based Deep Multiple
Instance Learning (ABMIL) typically disregard spatial interactions among
patches that are crucial to pathological diagnosis. Recent advancements, such
as Transformer based MIL (TransMIL), have incorporated spatial context and
inter-patch relationships. However, it remains unclear whether explicitly
modeling patch relationships yields similar performance gains in ABMIL, which
relies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs
Transformer-based layers, introducing a fundamental architectural shift at the
cost of substantially increased computational complexity. In this work, we
enhance the ABMIL framework by integrating interaction-aware representations to
address this question. Our proposed model, Global ABMIL (GABMIL), explicitly
captures inter-instance dependencies while preserving computational efficiency.
Experimental results on two publicly available datasets for tumor subtyping in
breast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage
point improvement in AUPRC and a 5 percentage point increase in the Kappa score
over ABMIL, with minimal or no additional computational overhead. These
findings underscore the importance of incorporating patch interactions within
MIL frameworks.

</details>


### [125] [Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with Self-attention Diffusion Models and the Potential for Text-Guided Customization](https://arxiv.org/abs/2504.17628)
*Abderrachid Hamrani,Daniela Leizaola,Renato Sousa,Jose P. Ponce,Stanley Mathis,David G. Armstrong,Anuradha Godavarty*

Main category: eess.IV

TL;DR: ADZUS是一种基于文本引导的扩散模型，用于糖尿病足溃疡的无监督分割，无需标注数据，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 糖尿病足溃疡的精确评估对患者治疗至关重要，但传统方法依赖大量标注数据，限制了灵活性和适应性。

Method: ADZUS利用零样本学习和文本引导的动态分割，无需标注训练数据，直接根据描述性提示进行分割。

Result: ADZUS在慢性伤口数据集上达到86.68%的IoU和94.69%的精确度，显著优于FUSegNet等监督方法。

Conclusion: ADZUS为医学影像提供了一种高效、可扩展的解决方案，但计算成本和潜在微调仍需改进。

Abstract: Diabetic foot ulcers (DFUs) pose a significant challenge in healthcare,
requiring precise and efficient wound assessment to enhance patient outcomes.
This study introduces the Attention Diffusion Zero-shot Unsupervised System
(ADZUS), a novel text-guided diffusion model that performs wound segmentation
without relying on labeled training data. Unlike conventional deep learning
models, which require extensive annotation, ADZUS leverages zero-shot learning
to dynamically adapt segmentation based on descriptive prompts, offering
enhanced flexibility and adaptability in clinical applications. Experimental
evaluations demonstrate that ADZUS surpasses traditional and state-of-the-art
segmentation models, achieving an IoU of 86.68\% and the highest precision of
94.69\% on the chronic wound dataset, outperforming supervised approaches such
as FUSegNet. Further validation on a custom-curated DFU dataset reinforces its
robustness, with ADZUS achieving a median DSC of 75\%, significantly surpassing
FUSegNet's 45\%. The model's text-guided segmentation capability enables
real-time customization of segmentation outputs, allowing targeted analysis of
wound characteristics based on clinical descriptions. Despite its competitive
performance, the computational cost of diffusion-based inference and the need
for potential fine-tuning remain areas for future improvement. ADZUS represents
a transformative step in wound segmentation, providing a scalable, efficient,
and adaptable AI-driven solution for medical imaging.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [126] [BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring](https://arxiv.org/abs/2504.17693)
*Asier Bikandi,Muhammad Shaheer,Hriday Bavle,Jayan Jevanesan,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 提出了一种基于BIM的漂移校正方法，用于解决建筑工地AR应用中因环境特征不足和动态变化导致的跟踪漂移问题。


<details>
  <summary>Details</summary>
Motivation: 建筑工地环境特征少、动态变化多，传统跟踪方法易产生漂移，导致数字模型与物理世界对齐不准确。

Method: 通过将实际检测到的平面与BIM中的计划平面对齐，利用优化技术计算SLAM与BIM坐标系间的变换，减少漂移。

Result: 实验显示，该方法平均减少52.24%的角度偏差和60.8%的距离误差。

Conclusion: 结合BIM的先验结构知识，显著提升了AR可视化在嘈杂建筑环境中的长期定位准确性。

Abstract: Augmented reality (AR) applications for construction monitoring rely on
real-time environmental tracking to visualize architectural elements. However,
construction sites present significant challenges for traditional tracking
methods due to featureless surfaces, dynamic changes, and drift accumulation,
leading to misalignment between digital models and the physical world. This
paper proposes a BIM-aware drift correction method to address these challenges.
Instead of relying solely on SLAM-based localization, we align ``as-built"
detected planes from the real-world environment with ``as-planned"
architectural planes in BIM. Our method performs robust plane matching and
computes a transformation (TF) between SLAM (S) and BIM (B) origin frames using
optimization techniques, minimizing drift over time. By incorporating BIM as
prior structural knowledge, we can achieve improved long-term localization and
enhanced AR visualization accuracy in noisy construction environments. The
method is evaluated through real-world experiments, showing significant
reductions in drift-induced errors and optimized alignment consistency. On
average, our system achieves a reduction of 52.24% in angular deviations and a
reduction of 60.8% in the distance error of the matched walls compared to the
initial manual alignment by the user.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [127] [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org/abs/2504.16936)
*Yusheng Zhao,Junyu Luo,Xiao Luo,Weizhi Zhang,Zhiping Xiao,Wei Ju,Philip S. Yu,Ming Zhang*

Main category: cs.MM

TL;DR: 该论文对多模态大语言模型（MLLMs）的音频-视觉能力进行了多维度评估，发现其在零样本和小样本任务中表现优异，但对视觉模态依赖性强，且对抗样本攻击下仍显脆弱。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多模态信息处理中表现出色，但缺乏对其音频-视觉能力的全面评估，尤其是在分布偏移和对抗攻击等多样化场景中。

Method: 通过四个关键维度（有效性、效率、泛化性和鲁棒性）对MLLMs进行多角度评估，并进行大量实验。

Result: MLLMs在零样本和小样本任务中表现优异，但对视觉模态依赖性强，视觉输入受损时性能下降；对抗样本攻击下表现优于传统模型。

Conclusion: 研究揭示了MLLMs的音频-视觉能力现状，为未来改进和研究提供了方向。

Abstract: Multi-modal large language models (MLLMs) have recently achieved great
success in processing and understanding information from diverse modalities
(e.g., text, audio, and visual signals). Despite their growing popularity,
there remains a lack of comprehensive evaluation measuring the audio-visual
capabilities of these models, especially in diverse scenarios (e.g.,
distribution shifts and adversarial attacks). In this paper, we present a
multifaceted evaluation of the audio-visual capability of MLLMs, focusing on
four key dimensions: effectiveness, efficiency, generalizability, and
robustness. Through extensive experiments, we find that MLLMs exhibit strong
zero-shot and few-shot generalization abilities, enabling them to achieve great
performance with limited data. However, their success relies heavily on the
vision modality, which impairs performance when visual input is corrupted or
missing. Additionally, while MLLMs are susceptible to adversarial samples, they
demonstrate greater robustness compared to traditional models. The experimental
results and our findings provide insights into the audio-visual capabilities of
MLLMs, highlighting areas for improvement and offering guidance for future
research.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [128] [Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline](https://arxiv.org/abs/2504.16979)
*Masoud Tafavvoghi,Lars Ailo Bongo,André Berli Delgado,Nikita Shvetsov,Anders Sildnes,Line Moi,Lill-Tove Rasmussen Busund,Kajsa Møllersen*

Main category: q-bio.QM

TL;DR: 研究构建了一个端到端的肿瘤浸润淋巴细胞（TILs）评估流程，利用QuPath实现全自动复杂任务，验证了现有软件的实用性。


<details>
  <summary>Details</summary>
Motivation: 探索利用易获取工具（如QuPath）实现复杂任务（如TILs评估）的自动化解决方案。

Method: 1. 训练像素分类器分割肿瘤相关基质；2. 使用预训练StarDist模型检测细胞并训练二元分类器区分TILs；3. 计算TIL密度并分类为低、中、高。

Result: 与病理学家评分对比，Cohen's kappa达0.71，验证了流程的可靠性。

Conclusion: 现有软件可提供乳腺癌H&E染色全切片图像中TILs评估的实用解决方案。

Abstract: In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)
assessment pipeline within QuPath, demonstrating the potential of easily
accessible tools to perform complex tasks in a fully automatic fashion. First,
we trained a pixel classifier to segment tumor, tumor-associated stroma, and
other tissue compartments in breast cancer H&E-stained whole-slide images (WSI)
to isolate tumor-associated stroma for subsequent analysis. Next, we applied a
pre-trained StarDist deep learning model in QuPath for cell detection and used
the extracted cell features to train a binary classifier distinguishing TILs
from other cells. To evaluate our TILs assessment pipeline, we calculated the
TIL density in each WSI and categorized them as low, medium, or high TIL
levels. Our pipeline was evaluated against pathologist-assigned TIL scores,
achieving a Cohen's kappa of 0.71 on the external test set, corroborating
previous research findings. These results confirm that existing software can
offer a practical solution for the assessment of TILs in H&E-stained WSIs of
breast cancer.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [129] [Plasma State Monitoring and Disruption Characterization using Multimodal VAEs](https://arxiv.org/abs/2504.17710)
*Yoeri Poels,Alessandro Pau,Christian Donner,Giulio Romanelli,Olivier Sauter,Cristina Venturini,Vlado Menkovski,the TCV team,the WPTE team*

Main category: physics.plasm-ph

TL;DR: 本文提出了一种基于变分自编码器（VAE）的数据驱动方法，用于表征托卡马克中等离子体状态的可解释表示，以预测和区分不同类型的等离子体破裂。


<details>
  <summary>Details</summary>
Motivation: 等离子体破裂是未来托卡马克装置面临的主要挑战之一，但目前对其理解有限，且数据驱动模型的可解释性不足。本文旨在通过可解释的表示方法改进破裂预测和特征分析。

Method: 扩展了VAE框架，包括连续投影等离子体轨迹、多模态结构分离操作状态，以及基于统计特性的破裂率指标。方法在1600次TCV放电数据上验证。

Result: 方法能够有效识别不同操作状态及其与破裂的关联，并通过反事实分析识别与破裂相关的参数。

Conclusion: 该方法以可解释的方式区分了不同操作状态，为破裂预测和特征分析提供了新工具。

Abstract: When a plasma disrupts in a tokamak, significant heat and electromagnetic
loads are deposited onto the surrounding device components. These forces scale
with plasma current and magnetic field strength, making disruptions one of the
key challenges for future devices. Unfortunately, disruptions are not fully
understood, with many different underlying causes that are difficult to
anticipate. Data-driven models have shown success in predicting them, but they
only provide limited interpretability. On the other hand, large-scale
statistical analyses have been a great asset to understanding disruptive
patterns. In this paper, we leverage data-driven methods to find an
interpretable representation of the plasma state for disruption
characterization. Specifically, we use a latent variable model to represent
diagnostic measurements as a low-dimensional, latent representation. We build
upon the Variational Autoencoder (VAE) framework, and extend it for (1)
continuous projections of plasma trajectories; (2) a multimodal structure to
separate operating regimes; and (3) separation with respect to disruptive
regimes. Subsequently, we can identify continuous indicators for the disruption
rate and the disruptivity based on statistical properties of measurement data.
The proposed method is demonstrated using a dataset of approximately 1600 TCV
discharges, selecting for flat-top disruptions or regular terminations. We
evaluate the method with respect to (1) the identified disruption risk and its
correlation with other plasma properties; (2) the ability to distinguish
different types of disruptions; and (3) downstream analyses. For the latter, we
conduct a demonstrative study on identifying parameters connected to
disruptions using counterfactual-like analysis. Overall, the method can
adequately identify distinct operating regimes characterized by varying
proximity to disruptions in an interpretable manner.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [130] [S2Vec: Self-Supervised Geospatial Embeddings](https://arxiv.org/abs/2504.16942)
*Shushman Choudhury,Elad Aharoni,Chandrakumari Suvarna,Iveel Tsogsuren,Abdul Rahman Kreidieh,Chun-Ta Lu,Neha Arora*

Main category: cs.SI

TL;DR: S2Vec是一种自监督框架，用于学习通用的地理空间嵌入，通过S2几何库分区和掩码自编码技术生成任务无关的嵌入，并在社会经济预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建可扩展的通用地理空间表示对地理空间人工智能应用至关重要。

Method: 使用S2几何库将大区域划分为离散的S2单元，将特征向量栅格化为图像，并应用掩码自编码技术生成嵌入。

Result: 在三个大规模社会经济预测任务中表现优异，且与图像嵌入结合可进一步提升性能。

Conclusion: S2Vec能生成有效的地理空间表示，并与其他数据模态互补。

Abstract: Scalable general-purpose representations of the built environment are crucial
for geospatial artificial intelligence applications. This paper introduces
S2Vec, a novel self-supervised framework for learning such geospatial
embeddings. S2Vec uses the S2 Geometry library to partition large areas into
discrete S2 cells, rasterizes built environment feature vectors within cells as
images, and applies masked autoencoding on these rasterized images to encode
the feature vectors. This approach yields task-agnostic embeddings that capture
local feature characteristics and broader spatial relationships. We evaluate
S2Vec on three large-scale socioeconomic prediction tasks, showing its
competitive performance against state-of-the-art image-based embeddings. We
also explore the benefits of combining S2Vec embeddings with image-based
embeddings downstream, showing that such multimodal fusion can often improve
performance. Our results highlight how S2Vec can learn effective
general-purpose geospatial representations and how it can complement other data
modalities in geospatial artificial intelligence.

</details>
